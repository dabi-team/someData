9
1
0
2

n
u
J

2

]

R
P
.
h
t
a
m

[

1
v
3
7
4
0
0
.
6
0
9
1
:
v
i
X
r
a

PERSISTENCE VERSUS STABILITY
FOR AUTO-REGRESSIVE PROCESSES

AMIR DEMBO⋆, JIAN DING†, AND JUN YAN‡

Abstract. The stability of an Auto-Regressive (ar) time sequence of ﬁnite order L, is determined
by the maximal modulus r⋆ among all zeros of its generating polynomial.
If r⋆ < 1 then the
eﬀect of input and initial conditions decays rapidly in time, whereas for r⋆ > 1 it is exponentially
magniﬁed (with constant or polynomially growing oscillations when r⋆ = 1). Persistence of such
ar sequence (namely staying non-negative throughout [0, N ]) with decent probability, requires the
largest positive zero of the generating polynomial to have the largest multiplicity among all zeros
of modulus r⋆. These objects are behind the rich spectrum of persistence probability decay for
arL with zero initial conditions and i.i.d. Gaussian input, all the way from bounded below to
exponential decay in N , with intermediate regimes of polynomial and stretched exponential decay.
In particular, for ar3 the persistence decay power is expressed via the tail probability for Brownian
motion to stay in a cone, exhibiting the discontinuity of such power decay between the ar3 whose
generating polynomial has complex zeros of rational versus irrational angles.

The estimation of persistence probability, that is, the probability that a sequence of random

1. Introduction

variables stay positive,

pN = P(Ω+

N ) := P(Xn > 0,

n

∀

∈

[0, N )) ,

is one of the central themes of research in the theory of probability. This topic goes back more
than ﬁfty years, to the seminal works by Rice [24] and Sleipan [28], that ushered and motivated
some of the most widely used general tools in the study of Gaussian processes. See also the
inﬂuential early contribution [23] on persistence probabilities for Gaussian processes and [22] listing
a host of applications in diverse areas of physics and engineering. Indeed, there is much interest
in this phenomena in theoretical physics (e.g.
[16], or the review [27] and references therein),
and in the mathematical literature (see the survey [3] and the many references therein). One
focal theme has been the study of pN for a centered Gaussian Stationary Process (gsp), either
in discrete or continuous time, where of particular note is the recent progress, beginning with
[17, 20], on conditions for the exponential decay of pN for such case. The law of a gsp is completely
determined by its spectral measure and naturally, the persistence probability is often studied by
spectral techniques (often in combination with tools from harmonic analysis), see [17, 19, 18].
Another line of research focuses on pN for nearly stationary, Markov sequences and processes. Here
too, one expects an exponential rate of decay of pN . This direction, which falls within the classical

Date: June 4, 2019.
2010 Mathematics Subject Classiﬁcation. Primary 60G15; Secondary 60J65.
Key words and phrases. Persistence probabilities, Auto-regressive processes, Gaussian processes, Brownian motion

in a cone.

⋆

‡Research partially supported by NSF grant DMS-1613091.

†Research partially supported by NSF grant DMS-1313596.

1

 
 
 
 
 
 
2

A. DEMBO, J. DING, AND J. YAN

general theory of quasi-stationary distributions, has been explored successfully in [2, 6, 5], advancing
our understanding of the relation between the Markov chain parameters and
limN log pN . The
key here is the ability to express the latter limit in terms of the leading eigenvalue of a suitable
sub-Markov operator (c.f. the review of such a relation in [6]). We mention in passing the related
active research on large holes in the distribution of zeros for certain families of complex-valued
Gaussian random analytic functions, and the work on persistence exponents in models of random
environment, media, or scenery (e.g. [4] where time-reversibility compensates for the loss of Markov
and Gaussian structure).

−

Our focus here is on the persistence probability for auto-regressive processes. More precisely, for

a (random) sequence

ξn}
{

and

Q(z) = zL

we deﬁne the ar(Q), an auto-regressive process

L

ajzL

j,

−

−

Xj=1
Xn}
{

n

generated by Q(z) and

, by

ξn}
{

(1.1)

(1.2)

Xn =

L

Xj=1

ajXn

−

j + ξn =

Xj=0

hn

−

jξj,

n > 0,

∀

where the right equality holds for zero initial conditions, namely with X
Further, let

−

L = . . . = X

−

1 = 0.

r⋆ := max

|

λ

∈

{|

: λ

(1.3)

, Λ :=

λ : Q(λ) = 0
}
{

0, if and only if r⋆ < 1. Taking hereafter for

Λ
}
denote the maximum modulus among the L zeros of Q(z). Recall that the corresponding linear
system is stable, namely with
i.i.d.
hn| →
|
variables yields an RL-valued Markov chain, which for a stable ar admits a stationary distribution.
, an exponential decay of the persistence probability ensues for
Assuming also light-tails for
ξn}
{
for stable ar processes is used by
such processes. Indeed, the study of properties of limN {−
[6] to showcase the main themes of this operator-based approach. However, among the unstable ar
sequences one ﬁnds a host of stochastic processes of much interest. Perhaps the most prominent one
1/2 is well known
1) sequence), for which sharp decay rate pN ∼
is the random walk (ie. ar(z
[3]). Going further, [14]
to hold under minimal conditions on the law of the increments ξn (c.f.
1)2)), universally
establishes a persistence power exponent for integrated random walk (ie. ar((z
over all mean-zero, square-integrable ξn. A diﬀerent extension is provided in [1] which utilizes
the invariance principle to establish the persistence power exponent for weighted random walks.
However, not much is known beyond these isolated special cases, with this paper being the ﬁrst
systematic study of the rich persistence behavior across the unstable Gaussian ar processes.

log pN }

ξn}
{

N −

−

−

Speciﬁcally, assume wlog that aL 6

in the set Λ of zeros of Q(z), now represented as

= 0 and let m(λ) > 1 denote the multiplicity of each value λ

To better relate persistence and stability, we further use the notations

Λ :=

.
λ1|m(λ1), . . . , λℓ|m(λℓ)}
{

Λ :

Λ⋆ :=

, m⋆ := max
λ
m(λ) : λ
{
∈
{
Then, focusing on the Gaussian case, namely with i.i.d. ξn ∼

N (0, 1), we show in the sequel that:
When r⋆ = 1,
grows polynomially and could be decomposed to a strictly positive
part and an oscillatory part. Correspondingly, we decompose Xn as the sum of a zero-angle
component - an integrated random walk (irw), an oscillatory component - a rotated random

Λ⋆

.

}

∈

hn|
|

= r⋆

λ
|

•

}

|

(1.4)

(1.5)

PERSISTENCE FOR AR

3

•

walk, and small order terms. The persistence probability decay is then determined by the
interaction between the ﬁrst two parts.
When r⋆ > 1,
exponentially, yielding a highly unstable process. In particular, if
hn| → ∞
|
m(r⋆) > m(λ) for all λ
Λ⋆, then hn stay positive for n large enough, with a signiﬁcant
∈
contribution to (Xn) from the ﬁrst ξn’s yielding a non-decaying in N persistence probabilty.
Λ⋆, the oscillatory component competes
In contrast, when m(λ0) > m(r⋆) > 1 for some λ0 ∈
well with the unstable zero-angle part, resulting with a roughly polynomial decay of pN .

More precisely, our ﬁrst theorem describes the qualitative behavior of pN for the diﬀerent regimes

).
of the set of zeros of Q(
·

Theorem 1.1. The decay of the persistence probabilities pN for a Gaussian ar(Q) ﬁt exactly one
of the following classes:
(a) Constant regime: if r⋆ > 1, m(r⋆) = m⋆, then infN {
(b) Exponential regime: if either r⋆ < 1 or m(r⋆) = 0, then for some C <

pN }

> 0.

∞

CN 6 pN 6 Ce−
(c) Stretched exponential regime: if r⋆ = 1, m(r⋆)

1e−

C −

N/C ,

−
(d) Unstable positive mode dominated by an oscillatory one: if r⋆ > 1, m(r⋆)

−

[1, m⋆), then

pN = exp(

N α+o(1)) ,

α = 1

[1, m⋆), then

∈

N

∀

N .

∈

m(r⋆)
m⋆

.

pN = N −

α+o(1) ,

α =

1
2

(m(λ)

−

m(r⋆))+(m(λ)

−

Λ⋆
Xλ
∈

(e) Approximate irw: if r⋆ = 1, m(r⋆) = m⋆, then for some C <

,

∞

C −

1N −

C 6 pN 6 CN −

1/C ,

N

∀

∈

N .

∈
m(r⋆) + 1)+ .

(1.6)

(1.7)

(1.8)

(1.9)

Remark 1.2. Theorem 1.1 does not establish the existence of exponents in part (b) and (e). In
the stable case of part (b) with r⋆ < 1, starting the process at stationary initial conditions, one has
the existence and formula for the exponent from [2]. While a power exponent is to be expected in
part (e), its existence in such full generality remains an open problem.

Part (a)–(e) of Theorem 1.1 are established in Section 2-6 respectively.

Recall that a ﬂexible condition for the continuity of the persistence exponent of centered gsp’s
is derived in [15]. In contrast, our next theorem demonstrates the possibly highly discontinuous
nature of the power exponent in part (e), by analyzing the special case of ar(Q) processes with
. Its proof in Section 7, further elaborates the connection in this case between pN
Λ =
}
and the probability that a Brownian motion stays for a long time in a generalized cone.

1, eiθ, e−
{

iθ

Theorem 1.3. Denote by
where Qℓ →
βQ > 0 such that the persistence probabilities of the Gaussian ar(Q) process satisfy

if the corresponding angles converge. To each Q

the collection of real polynomials Q(z) = (z

−
∈ Q

Q in

1)(z

Q

Q

eiθ)(z

iθ),
corresponds a ﬁnite

e−

−

−

pN = N −

βQ+o(1) .

(1.10)

Furthermore, if the angle θ for Q is such that θ/2π
such that lim inf ℓ

∈
βQℓ > βQ. In contrast, for θ/2π

→∞

Q, then there exist some Qℓ ∈ Q
6∈

Q any Qℓ →

Q results with βQℓ →

with Qℓ →
βQ.

Q

C, we

∈

(2.1)

(2.2)

4

A. DEMBO, J. DING, AND J. YAN

Acknowledgment. We thank S.R.S. Varadhan for stimulating discussions and for pointing
out reference [9], and we thank Nike Sun and Allan Sly for interesting discussions. The work was
initiated when J.D. was a postdoc at MSRI program on Random Spacial Processes.

2. Bounded persistence probability: Theorem 1.1 (a)

Using throughout the convention λ :=

[0, 2π) denoting the angle of λ

start with a few standard linear algebra facts (e.g. see [10, Section 3.6]).

λ
|

eiθλ , with θλ ∈
|

Lemma 2.1. (a). The solution of the diﬀerence equation

L

qℓ =

Xj=1

ajqℓ

j ,

−

ℓ > L ,

qℓ =

−

βλ,jλℓℓj ,

Λ
Xλ
∈

Xj=0

with

aj}
{

) of (1.1), is for Λ of (1.4), of the form
the coeﬃcients of the polynomial Q(
·
m(λ)

1

where βλ,j ∈
(q0, q1, . . . , qL
∈
βλ,j = βλ,j corresponds (q0, q1, . . . , qL
hn}
(b) The solution
{

−

of (1.2) is of the form

−

∈

C are uniquely chosen so (2.2) matches the initial conditions (q0, q1, . . . , qL
−
1
1)
}

RL then βλ,j = βλ,j. Conversely, to any
1)

βλ,j : λ
{
RL such that (2.2) holds.

Λ, 0 6 j 6 m(λ)

−

∈

1). If
with

hℓ =

m(λ)

−

1

Λ
Xλ
∈

Xj=0

λ
aλ,j|

ℓℓj cos(ℓθλ + θλ,j),
|

(2.3)

= 0, aλ,j = a¯λ,j,

1 6

for some aλ,j ∈
θλ,j =
−

C and θλ,j ∈

R that are determined by Q(
), such that aλ,m(λ)
·

−

θλ,j and wlog we set θλ,j = 0 if θλ = 0.

Equipped with Lemma 2.1, we next show that pN is uniformly bounded away from zero when

r⋆ > 1 and m(r⋆) = m⋆ of (1.5).

Proof of Theorem 1.1(A). Denote bn,i := hn

−
6 C(r⋆)n

i. From (2.3)
i(n

−

i)m(r⋆)
−

bn,i|
|

for a constant C <
2.1 and Lemma A.1, we can verify that for n > n1

−
. wlog we assume that ar⋆,m(r⋆)

∞

1,

(2.4)

1 > 0 and θr⋆,m(r⋆)

−

1 = 0. With Lemma

−

n1

n1

bn,i(r⋆)i =

ar⋆,m(r⋆)

1(r⋆)n(n

−

−

i)m(r⋆)
−

1 + o

(r⋆)nnm(r⋆)
−

1

,

(cid:16)
which further implies that there exists n1 suﬃciently large such that

Xi=1

Xi=1

n1

bn,i(r⋆)i > 2(r⋆)nnm(r⋆)
−

1 for all n > n1.

Applying Lemma 2.1, we have that for some C <

Xi=1

n1

Xi=1

bn,i|

|

n1

(r⋆)i 6 C

(r⋆)n(n

Xi=1

−

,

∞
i)m(r⋆)
−

1 6 Cn1(r⋆)nnm(r⋆)
−

1.

(cid:17)

(2.5)

(2.6)

PERSISTENCE FOR AR

5

Writing ξi = (r⋆)i + (ξi −
Aδ :=
that under the event

n1

1 + 2δ 6 (r⋆)−
{
bn,iξi > 2(r⋆)nnm(r⋆)
−

1

iξi 6 1 + 3δ, i = 1, ..., n1}
,
1 > (r⋆)nnm(r⋆)
−

3δCn1(r⋆)nnm(r⋆)
−

(r⋆)i), in light of (1.2), (2.5) and (2.6), choosing δ = 1/(3Cn1), we have

1,

for all n > n1 .

(2.7)

Xi=1

Deﬁne

−

n

n1

∧

Xn :=

Xi=1

bn,iξi and X ⋆

n = Xn −

Xn.

By (2.7) we can see that for a constant c > 0,

b

P(

Xn > (r⋆)nnm(r⋆)
−

b
1 for all n > n1) > P(

Note that
there exists a set B

Xn ∈
b

Xn1+1, . . . ,
span
Xn1+L}
b
{
(R+)L with positive Lebesgue measure such that
⊆
b
b
Xn > (r⋆)nnm(r⋆)
1 for all n > n1 + L if (
−

Xn1+1, . . . ,

Aδ) > c.
for all n > n1 + L. Combined with (2.7), it follows that

(2.8)

Xn1+L)

B .

∈

(2.9)

X1, . . . ,
b

Xn1+L) is a Gaussian vector of full rank (the covariance matrix is strictly positive
b
Xn1+L) is
X1, . . . ,

Note that (
deﬁnite), and thus the conditional Gaussian vector of (
also of full rank. Combined with (2.8) and (2.9), it follows that for a constant c′ > 0
1 for all n > n1 and Xn > 0 for 1 6 n 6 n1) > c′.

b
Xn1) given (

b

(2.10)

Xn1+1, . . . ,

P(

b

b

b

b

b

Under the event
n

X ⋆
n|
|

=

|

:=

Xn > (r⋆)nnm(r⋆)
−
1
6 C −
0 (1
ξi|
{|
n
6
bn,iξi|

B
b

Xi=n1+1

−
C(r⋆)n

α/r⋆)αi for all i > n1 + 1
, for ﬁxed α
}

i(n

−

−

i)m(r⋆)
−

1C −

1
0 (1

−

α/r⋆)αi 6

(1, r⋆), we have

(r⋆)n nm(r⋆)
−

1,

∈
C1
C0

Xi=n1+1
∞

B

for some C1 <

independent of n. We can choose C0 > 0 such that
6 (r⋆)nnm(r⋆)
1 for all n > n1} ⊇ B
−
1
By standard Gaussian bounds the sequence P(
0 (1
ξi|
|
independence P(

) > 0. Therefore with (2.11) we get for a constant c′′ > 0

X ⋆
n|

> C −

−

{|

.

(2.11)
α/r⋆)αi) is summable, hence by

6 (r⋆)nnm(r⋆)
−
Combined with (2.10), by independence of X ⋆

X ⋆
P(
n|
|

1 for all n > n1) > P(

) > 0.

B

n and

Xn the proof is completed.

We start by an easy exponential lower bound.

3. Exponential decay: Theorem 1.1 (b)

b

Lemma 3.1. For (Xn) ar(Q), there exists 0 < c < 1 such that pN > cN for all N

(cid:3)

N.

∈

Proof. Conditioned on
with

6

0 6 Xi 6 1 for all 1 6 i 6 n
{

and variance 1. Therefore,

µ
|

|

L
i=1 |

ai|

, the Gaussian variable Xn+1 has mean µ
}

P

P(0 6 Xn+1 6 1

0 6 Xi 6 1 for all 1 6 i 6 n

| {

) > c
}

for a constant c > 0. Recursively applying this inequality yields the desired lower bound.

(cid:3)

Brieﬂy, there are two forces resulting in an exponentially persistence probability upper bound:
1 + ξn, which we handle in Lemma 3.2; and almost

negative dependence with archetype Xn =
independence with archetype Xn = ξn, which we deal with in Corollary 3.4.

Xn

−

−

6

A. DEMBO, J. DING, AND J. YAN

3.1. Negative dependence: r⋆ > 1 and m(r⋆) = 0 . For a polynomial

L

P (z) =

cizi,

Xi=0

we deﬁne the operation P on a sequence x = (xn) by P (x)n =
L+i. We claim that
Lj
i=0 cjizi for j = 1, 2, then it is straightforward
(P1P2)(x) = P1(P2(x)), since if we denote Pj(z) =
P
L+i in (P1P2)(x)n and in P1(z)P2(z) are same for all 0 6 i 6
to verify that the coeﬃcients of xn
L1 + L2. We say a polynomial is a non-negative polynomial if it has non-negative coeﬃcients for
each term. Now we are ready to prove the main result in this subsection.

P

−

−

L
i=0 cixn

) with r⋆ > 1 and m(r⋆) = 0. Then, pN 6 Ce−
Lemma 3.2. Let (Xn) be ar(Q) for Q(
·
some c > 0, C <

and all N

N.

cN for

Proof. For λ

∈

∞

∈

Λ⋆, let Yλ = (Yn,λ) be an auto-regressive process satisfying

Pλ,m(λ)(Yλ)n =

d(λ)

Xk=0

γλ,kξn

k,

−

where

for λ

Λ⋆
∈
r⋆ (if

\{−

r⋆
, Pλ,m(λ) := (z
}
r⋆

Λ), P

r⋆,m(

−

−

∈

−

−

λ)m(λ)(z

−
r⋆) := (z + r⋆)m(
−

−

¯λ)m(λ), d(λ) := 2m(λ)
r⋆), d(λ) := m(

−
r⋆)

1,

−

1,

−

for λ =

and γλ,k’s are coeﬃcients to be determined later. By Lemma 2.1, we can choose proper γλ,k’s such
that

λ

aλ,j |

n
|

i (n

−

−

i)k cos((n

−

i)θλ + θλ,j).

n

Yn,λ =

bλ,n,iξi,

bλ,n,i =

m(λ)

1

−

Xj=0

Xi=0

∞

e
Compared with Lemma 2.1, we could write Xn = Yn + Zn where Yn =
Cr2n for constants C <

and 1 < r < r⋆. We ﬁrst claim that

e

λ

Λ⋆ Yn,λ and Var(Zn) 6
∈

P(Yn > 0 for all N/2 6 n 6 N ) 6 e−

(3.1)
To this end, we apply Corollary A.3 and deduce that for each λ, there exists a polynomial P ′λ,m(λ)
such that Pλ,m(λ)P ′λ,m(λ) is non-negative. We can further request that for all λ, Pλ,m(λ)P ′λ,m(λ)’s
equal to the same non-negative polynomial P , because if this doesn’t hold, we can consider the
following polynomials which achieve this request,

cN , for a constant c > 0 .

P

P ′λ,m(λ) = P ′λ,m(λ)

Pλ′,m(λ′)P ′λ′,m(λ′).

Write Y = (Yn). On the event

e

Yn > 0 : n
{

∈

0 < P (Y)n =

}

λ

Λ⋆
Yλ′∈
\{
, we have
[N ]
}
P ′λ,m(λ)(Pλ,m(λ)(Yλ))n.

(3.2)

Notice that
exist

λ
bi : i = 1, . . . , K
P
{

}

Λ⋆
Xλ
∈
Λ⋆ P ′λ,m(λ)(Pλ,m(λ)(Yλ))n =
∈
such that

P

K
i=0 ciξn

−

i for some K and ci’s, it follows that there

ζj :=

j(K+1)+K

Xi=j(K+1)

biξjK+i > 0 on

Yn > 0 : n
{

[N ]
}

∈

PERSISTENCE FOR AR

7

⌉

,
⌉

+ 1, . . . ,

N/2K
⌈

N/2K
⌈

N/K
for j =
. If bi’s are all 0, obviously the probability that ζj > 0 is
⌊
⌋
0 for all j. If bi’s are not all 0, since ζj are i.i.d. centered Gaussian variables, it is easy to see that
r < r⋆, then the fact that Var(Yn) > C1(r⋆)2n for some C1 > 0
(3.1) holds. Choosing
and Var(Zn) 6 Cr2n implies that for some constants c0 and C0 > 0
e
[(P(
Yn|
|

rn) + P(Zn >

rn)] 6 C0e−

r with r <

c0N .

(3.3)

6

e

XN/26n6N
Combining now (3.1), (3.3) and

e

N

e

N

Ω+

N ⊂ 


{
\n=N/2

Yn > 0

}





[

{|

[n=N/2

Yn|

6 (

rn)

}


completes the proof of the lemma.


3.2. Nearly independence: r⋆ < 1 or r⋆ = 1, m(r⋆) = 0.







e

N




{
[n=N/2

[



Zn > (

rn)

}


e



(cid:3)

Lemma 3.3. Let
tion coeﬃcients
such that

Zn : n = 1, . . . , N
{
}
ρi,j}16i,j6N such that
{

∞

be a mean zero Gaussian process with non-negative correla-
N
i,j ρi,j 6 ∆N . Then there exists a constant C = C(∆) <

P(Zn > 0 for all 1 6 n 6 N ) 6 Ce−

P

N/200∆ .

Proof. wlog we assume that Var(Zi) = 1. For convenience of notation, denote by
0 for all 1 6 n 6 N
), and
on z in [0,

Zn >
{
AN )/P(Zi > 0) is an increasing function

. Clearly Γi(z) := P(
}
∞0 Γi(z)pZi(z)dz = 0 (since

AN :=

). Hence

∞

R
0 6

∞

zΓi(z)pZi(z)dz = P(

E [Zi |

−

Zi > 0]) .

(3.4)

AN |

P(
Zi = z)
−
Zi > 0
AN ⊂ {
}
AN ) (E [Zi | AN ]
2/π, we deduce from (3.4) that
E [Zi | AN ] >

2/π .

p

Noting that E [Zi |

0
Z
Zi > 0] =

By assumption SN =
recalling that for G standard Gaussian P(G > x) 6 exp(
1N ) 6 e−

N
i=1 Zi is a centered Gaussian with Var(SN ) =
x2/2), we have

−
N/(200∆).

P(SN > 10−

P

p

(3.5)
i,j ρi,j 6 ∆N . Hence,

P

Noting that

it thus suﬃces to show that

P(

AN ) 6

P(SN > 10−
1N

P(SN > 10−

1N )
| AN )

,

To this end, by FKG we know that P(
get by simple Gaussian calculation that

P(SN > 10−

1N
AN )>2−

| AN ) > 1/(100√∆).
(3.6)
N . Hence, recalling that υN :=Var(SN ) 6 ∆N , we

E

SN 1SN >10√∆N | AN

Further, by (3.5),

h

6 2N E

SN 1SN >10√∆N

i

h

i

6 2N √υN
√2π

e−

(10√∆N)2

2υN 6 e−

N .

(3.7)

2
π

r

N 6 E [SN | AN ] .

(3.8)

8

A. DEMBO, J. DING, AND J. YAN

Breaking the range of SN into [0, 10−
E [SN | AN ] 6 10−
In view of (3.7) and (3.8) yields (3.6).

1N + 10√∆N P(SN > 10−

1N

| AN ) + E

h

∞
SN 1SN >10√∆N | AN

.

i

(cid:3)

1N ), [10−

1N, 10√∆N ) and [10√∆N,

), we deduce that

We record here the following comparison result of Slepian [28], which will be used repeatedly.

Slepian’s Lemma Let
with

Ui : 1 6 i 6 n
{

}

and

Vi : 1 6 i 6 n
{

}

be centered zero Gaussian variables

Var(Ui) = Var(Vi), and Cov(Ui, Uj) 6 Cov(Vi, Vj) for all 1 6 i, j 6 n .

(3.9)

Then for all real numbers λ1, . . . , λn,

P(Ui 6 λi for all 1 6 i 6 n) 6 P(Vi 6 λi for all 1 6 i 6 n) .
Corollary 3.4. If r⋆ < 1, or r⋆ = 1 with m(r⋆) = 0, then there exist constants c, C > 0 such that
pN 6 Ce−

cN for all N

N.

∈

Proof. First write Q = Q1Q2 where Q1 has no positive zeroes and Q2 has only positive zeroes. By
Corollary A.3, there exists a non-negative polynomial P1 such that P1Q1 is non-negative. Now,
let (ζn) be an auto-regressive process generated by Q2 and (ξn). Then (Xn) can be viewed as an
auto-regressive process generated by Q1 and (ζn), since Q2(Q1(Xn)n)n = ξn and Q2(ζn)n = ξn
imply that(easy to verify the boundary) Q1(Xn)n = ζn. Analogues to the proof of Lemma 3.2,
there exist k > 0 and

such that

bi : 1 6 i 6 k
{

}

Xn > 0 : 1 6 n 6 N
{

} ⊆ {

χj > 0 : 1 6 j 6 [N/k]
}

,

(3.10)

j(k+1)+k
i=j(k+1) biζjk+i. If bi’s are all 0, then this corollary is automatically true by (3.10).
where χj =
If bi’s are not all 0, since Q2 has only positive zeroes strictly less than 1, it is easy to verify that
P
there exists constants c <

and 0 < r < 1 such that the correlation coeﬃcients of

satisfy

ρ(χi, χj)
|
|
Note that we can ﬁnd a positive integer k0 such that the matrix An := (aij)n
k0
|
is positive deﬁnite for each n, thus we can construct a Gaussian vector (Z ′1, ..., Z ′n) whose covariance
matrix is An. Since 0 < r < 1, we can apply Lemma 3.3 to (Z ′1, ..., Z ′n), and it completes the proof
with (3.11) and Slepian’s Lemma, by noting that Ω+
(cid:3)

n with aij = cr|

χjk0 > 0 : 1 6 j 6 [N/(k

| for all i, j.

(3.11)

×

−

−

j

i

6 cr|

i

j

.
k0)]
}

×

N ⊆ {

4. Stretched exponential decay: Theorem 1.1 (c)

Assume λ0 = 1 with multiplicity m := m(1). Let Λ = Λ⋆

and Λ⋆ =
Gaussian random variable Z and n1 6 n2, we denote the contribution of
as

λ0|m, λ1|m1, . . . , λℓ|mℓ }
{

where λj = e√

−

∪ {

λq|m(eλq)}
λ1|m(eλ1), ...,
λi|
|
1θj , such that m′ = maxj>1{
> m. For a
mj}
e
e
e
ξn : n1 6 n 6 n2}
in Z
{

where

< 1,

Z(n1, n2) := E(Z

ξn : n1 6 n 6 n2}
).
1)M ), irw of order M , that is,

| {

For M

∈

Z+, denote by (Zn,M ) the ar((z

−

where

Zn,M :=

n

Xi=1

bn,i,M

1ξi,

−

bn+1,i,M := bn,i,M + bn+1,i,M

−

1 and bn,i,0 := 1 for all i 6 n.

(4.1)

(4.2)

(4.3)

χi}
{

∞

For j

0, ..., ℓ

∈ {

}
n

and k

[mj]

−

∈

Tj,n,k :=

bn,i,k cos((n

Xi=1
Hereafter, θj,k = θλj ,k, and for p

−

PERSISTENCE FOR AR

9

1, deﬁne −→T j,n,k = [Tj,n,k, T′

j,n,k]T , where

i)θj + θλj,k)ξi , T′j,n,k :=

bn,i,k sin((n

n

Xi=1

∈

[q], k

n

[m(

λp)]

1, let

−

∈

i)θj + θλj,k)ξi.

(4.4)

−

n

ibn,i,k cos((n

e

−

i)θ

+ θ

eλp,k)ξi.

eλp

−

(4.5)

The upper and lower bounds are established in Sections 4.1 and 4.2, respectively.

Zp,n,k :=

λp|
|
e

Xi=1

4.1. Upper bound. Comparing (4.4), (4.5) with (2.1), we have the decomposition

Xn = X (0)

n + X (1)

n + X (2)

n :=

1

m

−

c0,kT0,n,k +

ℓ

mj −

1

cj,kTj,n,k +

q

m(eλq)

−

1

cp,kZp,n,k,

(4.6)

Xk=0

Xj=1
R where cj1,k = cj2,k if θj1 =

Xk=0

−

θj2 (and
m′ −
2m′

m

1/2 + α, α =

for some real cj,k,

cp,k ∈

e

Deﬁne the event ΞN := Ξ(0)

N ∩

γ1 = m

−

Ξ(1)

N where
N

p=1
X
cp1,k =

Xk=0
cp2,k if

e
θp1 =

θp2). Set

−

e

e

e

(4.7)

.
e

N

Ξ(0)
N

: =

Ξ(1)
N

: =

X (0)
n |

{|

6 N γ1( log N )−

2

ξn|
{|

6√N

,
}

}

\

n=1
\

X (1)
{

n 6

−

N γ1

.

}

\n=N/2
3N/4

[n=N/2

Note that under ΞN ,
maxN

X (2)
n

n=N/2{

}

ξn|
|

6√N , by (4.5), (4.6), (4.7) and the fact that

< 1, we have that

= o(N γ1), hence Ω+

(ΞN )c for all N large enough, so it suﬃces to prove

N ⊆

λi|
|
e

and

P(Ξ(0)

N ) 6 e−

N 2α+o(1)

P(Ξ(1)

N ) 6 e−

N 2α+o(1)

.

(4.8)

(4.9)

Note that Var(X (0)
n ) = O(N 2m
−
Next we show (4.9). Deﬁne the rotation matrix

1) and Var(ξn) = 1, having 2α < 1, (4.8) follows by a union bound.

Notice that by (4.4) and our assumption on θj,k’s in Lemma 2.1, we have

Rθ :=

(cid:20)

cos θ
sin θ

sin θ
−
cos θ

.

(cid:21)

θj2,
and for n′ > n, iterating over i = 1, ..., k we get from (4.3) that

Tj1,n,k = Tj2,n,k if θj1 =

−

−→T j,n′+1,k(0, n) = Rθj −→T j,n′,k(0, n) + Rθj,k−

θj,k−1 −→T j,n′+1,k

1 (0, n)

−

(4.10)

(4.11)

(4.12)

10

A. DEMBO, J. DING, AND J. YAN

i=0
X
Further iterating over n′ = n, n + 1, ..., n + s

k

= Rθj (

−→T j,n+s,k(0, n) =

Rθj

s (

Xi=0
) as in (A.7). Thus, letting
as in (A.6), for Ps(
·

(cid:1)

(cid:0)

Dn,s :=

{|

by Lemma A.5

ℓ

mj −

1

Xj=1

Xk=0

Rθj,k−

θj,i−→T j,n′,i)(0, n).

Z+ yields the identity

1, s

∈

−
k

Ps(k

i)Rθj,k−

−

θj,i−→T j,n,i)(0, n),

(4.13)

cj,kTj,n+s,k(n, n + s)
|

6 N γ1

,
}

3N/4

−

M

Ξ(1)

N ⊇

X (1)
n |

{|

>

2
C′

N γ1

} ∩

3N/4

−

M

M

Dn,s.

s=1
[n=N/2
\
Since M is a constant independent of N , by a union bound we have

\n=N/2

3N/4

M

M

−

P(

[n=N/2

s=1
[

C
n,s) 6 e−

D

N 2γ1 +o(1)

.

(4.14)

(4.15)

Set β =

ℓ
j=1

P

P

γ1
1/2 . Conditioning on the σ-ﬁeld σ(ξ1, . . . , ξ[N/2+(i
m′−
1

mj −
k=0 cj,kTj,[N/2+iN β],k ∼ N (µN , σ2

N ) where σ2

N = O(N 2γ1). Note that

−

1)N β ]),

it is easy to see that

δ > 0 such that

∃

sup
µ {

N (µ, σ2
P(
|

N )
|

6 2

σ2
N /C ′)
}

6 1

δ.

−

q
Thus we obtain that there exists 0 < ε < 1 such that
ℓ

1

1

ℓ

mj −

mj −

1

P(
|

cj,kTj,[N/2+iN β ],k|

6

2
C′

N γ1

i
−

|

|

cj,kTj,[N/2+sN β],k|

6

2
C′

N γ1) 6 ε,

j=1
X

Xk=0
for all 1 6 i 6 [N 1
the upper bound.

s=1
\
β/4]. Recalling that γ1 = m

−

Xk=0

j=1
X
1/2 + α, we get (4.9), completing the proof on

−

4.2. Lower bound. The intuition for the lower bound comes from the fact that the event of
persistence will present if the irw sits above a certain curve while the rotated (integrated) random
walk sits below it. Furthermore, the probability for the intersection of the two events is close to
the product of each of the probabilities. The latter claim requires a careful justiﬁcation, to which
end we use the following lemma.

Lemma 4.1. Assume that (U1, U2, V1, ..., Vd) is a multivariate Gaussian random vector, with mean
(µU1, ..., µVd) and correlation matrix (not the covariance matrix)

U,V
Write ΣUi,V as the ith row of ΣU,V for i = 1, 2. Then for the conditional expectation we have

(cid:19)

(cid:18)

ΣU,U ΣU,V
ΣV,V
ΣT

.

E[U1 |
|

V1, ..., Vd]

µU1|

−

6 d

Var(U1)

Σ−
||

1
V,V ||op||

ΣU1,V ||∞||

(Vi/

Var(Vi))i

.

[d]||∞
∈

p

p

PERSISTENCE FOR AR

11

What’s more, for the conditional covariance we have

Cov[U1, U2 |

|

V1, ..., Vd]

Cov[U1, U2]
|

−

6 d

Var(U1) Var(U2)

ΣU1,V ||∞||
||

ΣU2,V ||∞||

1

Σ−
V,V ||op.

Proof. Recall that from the conditional multivariate Gaussian formula we have

p

E[U1 |

V1, ..., Vd] = µU1 +

Var(U1)ΣU1,V Σ−

1
V,V (Vi/

Var(Vi))T
[d],
i
∈

p

p

and

Cov[U1, U2 |

V1, ..., Vd] = Cov[U1, U2]

−

Var(U1) Var(U2)ΣU1,V Σ−
1
V,V

ΣU2,V .

Lemma 4.1 is a direct result from (4.16) and (4.17).

p

(4.16)

(4.17)

(cid:3)

It is easy to check that for s1, s2 ∈

[m]

1,

−

Corr(T0,nk+1,s1(nk, nk+1), T0,nk+1,s2(nk, nk+1)) =

2

(s1 + 1/2) (s2 + 1/2)

+ o(1).

s1 + s2 + 1

1). Then we can ﬁnd

(4.18)

1)T =
Σm = I. Letting ε be suﬃciently small gives (4.18). Consider nk = 2k for

m (a0, ..., am

−

1

p
1/2) (j
i

1

−

∀

−
∈

−
1, then

(i
−
ε, ai + ε]

1/2)/(i + j
[m]

Write Σm as a m
×
ε > 0 and a0, ..., am

m matrix with Σm(i, j) = 2
[ai −
1 > ε, such that if bi ∈
p
Σ−
1)T > 0 entrywisely.
m (b0, ..., bm
To see this, we can choose ai = Σm(i + 1, 1) + ... + Σm(i + 1, m), in which case Σ−
(1, 1, ..., 1)T since Σ−
1
m
k = 1, . . . , [log2 N ]. Let
m′ −
2m′

k , and γ2(ℓ) :=

, nk,α = nγ1

γ1
m′ −
For convenience of notation, we write

1)nβ

, β =

Tj,r,s = T

α =

2m′

1/2

2ℓ

m

−

−

−

k ,s(nk + (r

−

Zp,nk+rnβ

k ,s(nk + (r
Ωk,0 :=

1)nβ

k , nk + rnβ

−
T0,nk+1,s(nk, nk+1)

{

j,nk+rnβ
k ). Deﬁne the events

e
nk,α(log N )10ns
−
k

∈

m

(as −

ε, as + ε) for all s

[m]

1

,

}

−

∈

10.

−

−
k , nk + rnβ

k ), and

Zp,r,s =

e

β

n1
k

−

Ωk,T :=

r=1
\
β

n1
k

−

{
(cid:12)
(cid:12)
(cid:12)e

Tj,r,s

6 N γ2(mj ) : j

(cid:12)
(cid:12)
(cid:12)
6 N γ2(m(eλj )) : p

and

Ωk,Z :=

\r=1

Zp,r,s

{
(cid:12)
(cid:12)
(cid:12) e

(cid:12)
(cid:12)
(cid:12)

[ℓ], s

[mj]

,

1
}

−

∈

∈

[q], s

∈

∈

[m(

λj)]

,

1
}

−

e

\
Lemma 4.2. Using the above deﬁnitions, there exists a constant C > 0 such that for all 1 6 k 6
[log2 N ],

\

Ωk := Ωk,0

Ωk,T

Ωk,Z.

P(Ωk) > e−

C(log N

·

β

n1
k +(log N )20n2α
−

k ) .

12

A. DEMBO, J. DING, AND J. YAN

Proof. It suﬃces to consider K0 6 k 6 log2 N for a large number K0 independent of N . Fix such
a k. From the deﬁnition of
1, thus we
can verify that there exists C > 0 such that for any j

Tj,r,s we can verify that Var

2)
s
∀
1 and r

[mj]
−
β
[n1
],
−
k

∈
∈

e

Tj,r,s 6 O(N 2mj −
[mj]
[ℓ], s
∈
∈
e
N γ2(mj )) > N −

C.

−

1
√c1

Tj,r,s
(cid:12)
(cid:12)
(cid:12)e
Similarly for some C0 > 0 and any p

P(

(cid:12)
(cid:12)
[q], s
(cid:12)

6

(4.19)

(4.20)

[n1
−
k

β

], we have

[m(

λj)]

1, r

−
N γ2(m(eλj ))) > N −

∈

e

C0.

∈
Zp,r,s

P(

6

∈
1
√c1

(cid:12)
(cid:12)
(cid:12) e

(cid:12)
(cid:12)
(cid:12)

[d], we can write
Note the fact that for multivariate Gaussian (W1, ..., Wd) with Var(Wi) = 1
each Wi as a linear combination with i.i.d. standard Gaussian random variables U1, ..., Ud with
each coeﬃcient having absolute value smaller than 1. Thus for any w1, ..., wd > 0,

∈

∀

i

P(
Wi|
|
By normalizing

i

6 wi ∀
Tj,r,s and

[d]) > P(
Ui|
|

6 min(wi)/d

i

[d]) = P(
|

U1|

∈
Zp,r,s to have variance 1 and using the above argument, we have that

∈

∀

6 min(wi)/d)d.

∀
for some C1 > 0. By independence we further see that for some C > 0,

−

∈

∈

6 N γ2,
e

j

[ℓ], s1 ∈

[m(λj )]

1, p

P(

Tj,r,s1
e
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)e
(cid:12)

,

Zp,r,s2
(cid:12)
(cid:12)
(cid:12) e

(cid:12)
(cid:12)
(cid:12)

e

[q], s2 ∈

[m(

λp)]

1) > N −

C1,

−

P(Ωk,T, Ωk,Z) > e−

C log N

With Lemma A.1, for all j

[ℓ], r

∈

∈
ρ(T0,nk+1,s(nk + (r
ρ(T0,nk+1,s(nk + (r

Deﬁne

β

[n1
−
k
1)nβ
1)nβ

], s
[m]
−
∈
k , nk + rnβ
k ),
k , nk + rnβ
k ),

−

−

β

n1
k

−

·

[m(λj)]

.
1 and s1 ∈
Tj,r,s1) = O(n−
k
Zp,r,s2) = O(n−
k
e

(4.21)

−
(β+1)/2

1, s2 ∈
)

1/2

) .

[m(

λj)]

1,

−

e

(4.22)

F

T := σ(

Tj,r,s1,

Zp,r,s2 : j

[ℓ], s1 ∈
By (4.22), considering the conditional distribution blockwisely for (nk + (r
r
such that for all s

k ) where
], with Lemma 4.1, we can verify that there exist constants c, C > 0 (independent of N )

1, r
−
1)nβ

[q], s2 ∈

[n1
]).
−
k
∈
k , nk + rnβ

[m(λj)]

[n1
−
k

λp)]

[m(

[m]

−

−

∈

∈

∈

e

e

e

β

β

e
1, p

∈

1,
−
cn2s+1
k

6 Var(T0,nk+1,s(nk, nk+1)

T) 6 Cn2s+1

k

| F

and

E(T0,nk+1,s(nk, nk+1)

It follows that for a constant C ′ > 0,
P(Ωk,0 |

Ωk,T, Ωk,Z) = O(1).

|

Ωk,T, Ωk,Z) > e−

C′(log N )20n2α

k .

Combined with (4.21), this completes the proof of the lemma.

,

(cid:3)

Now, we further deﬁne Ω⋆

k to be the intersection of Ωk and Ωk,R, where

Ωk,R :=

nk+1

{

t=nk
\
nk+1

T0,t,s(nk, t) >

−

κ(log N )10nk,α, for any s

[m]

1

}

−

∈

Tj,t,s(nk, t)
|

{|

6 κ(log N )10nk,α, for all j

[ℓ], s

∈

∈

[m(λj)]

1

}

−

\

t=nk
\

PERSISTENCE FOR AR

13

nk+1

Zp,t,s(nk, t)
|

{|

6 κ(log N )10nk,α, for all p

[q], s

∈

∈

[m(

λj )]

,

1

}

−

\

t=nk
\

∞

independent of N
m′.

10

Ωk,T

converges to Σm as k

and κ is a small positive constant independent of N . By calculating blockwisely the correlation and
T, the conditional correlation matrix
using Lemma 4.1, it is easy to verify that: (1) Conditioned on
T0,nk+1,0, ..., T0,nk+1,m
T such
of
{
−
m′
10
that ω
∞
and Corr(T0,r,s1, T0,nk+1,s2) > 0 for any r

F
independent of N such that E[T0,r,s |
[n1
−
k
∈

. (2) Conditioned on any ω
ω] >

1}
Ωk,Z, there exists C <

Now instead of the condition of ω, we further condition on Ωk,0 and thus get Ωk. First we
Ωk]. Recall our choice of ai and ε. With (1) and (2) above and (4.16), regarding
[m], we can notice that the second term in the right

consider E[T0,r,s |
U1 = T0,r,s |
hand side of (4.16) is positive, thus for some C <

ω and Yi = T0,nk+1,i

] and s1, s2 ∈

∈ F
CN −

ω for i

→ ∞

[m]

1 |

−

−

1.

∩

∈

∈

−

−

β

e

Ωk] >

E[T0,r,s |
. With similar method to above analysis, for any nk + rtnβ
}
ξt0, T0,nk+1,0, ..., T0,nk+1,m
{
−
Ωk,Z, and then condition on Ωk,0, we can verify that there exists C <

ℓ : nk + rnβ
{
k , by ﬁrst calculating the joint distribution of
Ωk,T

k 6 t

CN −

−

−

(4.23)

Writing rt := max
t0 < nk + (rt + 1)nβ
conditioned on ω
∩
independent of N such that for any nk 6 t0 < nk+1,
6 Cnα
−
k

∈

1/2

|

Ωk,0]
|

E[ξt0 |
From (4.23) and (4.24), with (4.13) it is easy to check that for some C1 <
(log N )10.
Ωk) = O(n2s+1

C1nβ(s+1)+α
−
k
Combined with the fact that β < 1 and Var(T0,t,s(nk, t)
variance is always smaller than variance), we have
nk+1

E[T0,t,s(nk, t)

Ωk] >

∞

1/2

−

k

|

|

(log N )10.

k 6
1}
∞

(4.24)

) (since conditional

independent of N ,

P(T0,t,s(nk, t) 6

κ(log N )10nk,α |

−

Ωk) = O(1/N ) .

(4.25)

t=nk
X

For s

[mj]

−

∈

1, By the deﬁnition of Ωk we see that on Ωk

Tj,t,s(nk, t)
|

|

6 1 +

Tj,t,s(nk + rtnβ

.

k , t)
(cid:12)
(cid:12)
(cid:12)
∈

It is easy to check that Corr(Tj,t,s(nk + rtnβ
With Lemma 4.1, we can further notice that
1/2
rtnβ
k , t), T0,nk+1,s1(nk, nk+1)
Tj,t,s(nk + rtnβ
k , t)
independent of N

|
ω, Vi = T0,nk+1,i

ω) = O(n−
k

−

|

(cid:12)
(cid:12)
(cid:12)
∈ F

k , t), T0,nk+1,s1(nk, nk+1)) = O(n−
1.
s1 ∈
k
Ωk,Z, Corr(Tj,t,s(nk +
Ωk,T
∀
). Therefore applying Lemma 4.1 again with U1 =

T such that ω

[m]

−

∩

ω

∀

)

1/2

1(nk, nk+1)

ω for i

|

∈

[m], we see that for some C3 <

∞

E[Tj,t,s(nk + rtnβ
|

k , t)

Ωk]
|

|

where the last step is due to β(m′ −
O(nβ(2m′−
k
κ > 0 there exists a constant K0 = K0(κ) such that for all k > K0,

) = O(nk,α) for all s

[m′]

1, since β(2s + 1) 6 m + α

−

∈

1)

−

k , t)

Ωk) =
1/2. Thus for any

|

6 C3(log N )10nβ(s+1/2)+α
= o((log N )10nk,α),
−
1/2) < m. Note that Var(Tj,t,s(nk + rtnβ

1/2

k

(4.26)

nk+1

t=nk
X

Tj,t,s(nk, t)
P(
|
|

> κ(log N )10nk,α |

Ωk) = O(1/N ).

14

A. DEMBO, J. DING, AND J. YAN

Similarly we can show that

nk+1

t=nk
X

P(
Zp,t,s(nk, t)
|
|

> κ(log N )10nk,α |

Ωk) = O(1/N ).

Combined with Lemma 4.2 and (4.25), it follows that for a constant C <
all k > K0,

∞

independent of N and

k) > P(Ω⋆
P(Ω⋆
k |
k. Under Ω⋆,

log2 N
k=1 Ω⋆

∀
1. Breaking Xt into Xt(0, nk + rnβ

Now let Ω⋆ =
∩
β
where r 6 n1
−
k −
Ω⋆, with (4.19) it is direct to check Ω⋆
and independence, we deduce that P(Ω⋆) > e−
lower bound.

−

·

β

n1
k +(log N )20n2α
−

C(log N

k ) .
Ωk)P(Ωk) > e−
t 6 N, we can ﬁnd k, r such that nk +rnβ
k

(4.27)
6 t < nk +(r +1)nβ
k
k , t), then by the deﬁnition of
N when κ is a suﬃciently small constant. Using (4.27)
, and it completes the proof of the

k ) and Xt(nk + rnβ

β+o(1)+N 2α+o(1)

Ω+

N 1

⊆

5. Dominating unstable oscillatory mode: Theorem 1.1 (d)

We ﬁrst establish an important lemma below, and then give the proofs for the lower bound and

Let

Λ =

the upper bound in Subsection 5.1 and 5.2 respectively.
∂D. Denote by
Λ
\

λ/r⋆, λ
∂D and Λ2 =
, Λ1 =
Λ
}
{
polynomials with zero set
Λ, Λ1, Λ2 respectively. In addition, write
and let (ζn) be an auto-regressive process generated by Q2 and (
norm less than 1, there exist C ′ <

and r > 1 such that

Λ

∩

∈

b

b

b

b

∞
Var ζn 6 C ′(r)−

n for all n

b
N .

∈

Q(z), Q1(z), Q2(z) monic
n
ξn = ξn(r⋆)−
ξn). Since all the zeroes of Q2 has

Xn = Xn(r⋆)−
b

n,

b

b

(5.1)

b

Q(z) = Q1(z)Q2(z), we see that (

Xn) is an auto-regressive process generated by Q1(z) and
Due to
Xn), thus
(ζn). Obviously the persistence of the process (Xn) is equivalent to the persistence of (
in what follows we will only consider the process (
Xn), and for convenience we drop the “hat” in
the notation. That is to say, in the rest of this subsection we assume (Xn) is an auto-regressive
n for a
process generated by Q1(z) and Gaussian sequence (ζn), where Λ
certain r > 1.

b
∂D and Var ζn 6 C ′r−

⊆

b

b

[Xn
polynomial P (z) =

−

Assume that the degree for Q1(z), Q2(z) and Q(z) are L1, L2, L respectively. Denote by Yn =
L1+1, . . . , Xn]T for n > L1, and denote by Σn the covariance matrix of Yn. For a degree-ℓ

ℓ
i=1 aizℓ

i, deﬁne an ℓ
A1,j = aj for 1 6 j 6 ℓ; Ai,i

−

ℓ matrix A = A(P ) by

×
1 = 1 for 2 6 i 6 ℓ; Ai,j = 0 otherwise.

P

(5.2)
The following lemma provides estimates on λmin(Σn) and λmax(Σn), the minimum and maximum
eigenvalues for Σn.
Lemma 5.1. Write m⋆ = max

. There exist constants C, c > 0 such that

−

m(λ) : λ
{

∈

Λ1}

cn2m⋆
Proof. Let A(1) := A(Q1) as in (5.2) and note that

−

2 6 λmin(Σn) 6 λmax(Σn) 6 Cn2L for all n

N ,

∈

Yn = An

L1

(1) YL1 +
−

n

Xj=L1+1

j

An
(1) ζjeL1,
−

(5.3)

PERSISTENCE FOR AR

15

RL1 is a vector with a unique nonzero entry in the ﬁrst coordinate (whose value is 1).
where eL1 ∈
Note that the set of eigenvalues of A(1) is exactly Λ1. Thus by (5.1) and (5.3), we get that for any
0 6 i, j 6 L1, there is a constant C ′ <
(Σn)(i,j)
(cid:12)
(cid:12)
(cid:12)

−
= O(1)kL1 due to Lemma A.6. This gives

where in the last inequality we use the fact that
the upper bound λmax (Σn) 6 Cn2L.

Cov(Xn
|

6 C ′n2L,

−
Ak
k

such that

(1)k∞

i, Xn

∞
=

j)
|

(cid:12)
(cid:12)
(cid:12)

For the lower bound, we just need to show that there exists c > 0 such that for any ν = (ν1, ..., νL1 )

with

ν

k2 = 1,

k

L1

Var(

νjXn+1

−

j) > cn2m⋆

2.

−

Xj=1

Notice that it is enough to prove it for n large enough. Since Xn =

n
j=1 bn,jξj, we have

L1

Xj=1

νjXn+1

−

L1

j =

νj

n+1

−

j

P

j,iξi,

bn+1

−

Xj=1

Xi=1

which implies that for any ﬁxed K, when n is large enough we have

L1

Var(

νjXn+1

−

j) > Var(

Λ1, m(λ) = m⋆

λ
{

∈

K

L1

(
Xj=1
Xi=1
, then
}

Xj=1
If we denote Λ3 :=

νjbn+1

j,i)ξi) > r−

K

K

L1

(
Xj=1
Xi=1

νjbn+1

−

j,i)2.

−

1 (n + 1

−

i

−

−

j)m⋆

1 cos((n + 1

−

i

−

−

j) θλ + θλ,i) + o(nm⋆

1)

−

aλ,m⋆

−

1 cos((n + 1

i

−

−

j) θλ + θλ,i) + o(nm⋆

1),

−

bn+1

−

j,i =

aλ,m⋆

Λ3
Xλ
∈
= nm⋆

−

1

which implies that

Λ3
Xλ
∈

L1

Xj=1

L1

|

Xj=1 Xλ
Λ3

∈

νjbn+1

−

j,i = nm⋆

−

1

νjaλ,m⋆

−

1 cos((n + 1

i

−

−

j) θλ + θλ,i) + o(nm⋆

1).

−

L1

Xj=1 Xλ
Λ3

∈

Now, applying Lemma A.4, we can see that there exists K1 > 0 such that for any n, there exists
1 6 i 6 K1 such that

νjaλ,m⋆

−

1 cos((n + 1

i

j) θλ + θλ,i)
|

−

−

>

1
4

max
16j6L1,λ

Λ3 |

∈

νjaλ,m⋆

.
1|

−

(5.4)

Since

ν
||

||2 = 1 implies maxL

j=1 {|

νj|}

> 1/(4√L1), setting K = K1 we conclude that

L1

Var(

Xj=1

νjXn+1

−

which gives the desired result.

L1

j) > r−

K1(

Xj=1
K1n2m⋆

= r−

νjbn+1

j,i)2

−

2 1
16L1

−

aλ,m⋆

min
λ
∈

Λ3 |

2 + o(n2m⋆

1|

−

2),

−

(cid:3)

16

A. DEMBO, J. DING, AND J. YAN

5.1. Upper bound. We now provide the proof of the upper bound on the persistence probability.
Proof of the upper bound: case (d). Continue to write A
(1) = A(Q1). We note that since Q1(1) = 0,
it follows that λ = 1 is an eigenvalue of A(1) with eigenvector 1. In light of (5.1), we can choose
13L for all n > n′, combined
n′ := κ log N with κ > 0 a large enough constant such that Var ζn 6 N −
with (5.3) Corr

= O(1)kL1 6 O(1)N L1, we get

Ak
k

(1)k∞

for some C ′ <

∞

An
(1) Yn′k∞
. Therefore, we deduce that for a suitably large constant C <

Yn −
k
(cid:16)

6 C ′N −

10L,

Var

(cid:17)

n′

−

n′ 6 n 6 N :

P(

∃

Yn −
k

n′

An
(1) Yn′k∞

−

> N −

4L) 6 Ce−

N ,

∞

(5.5)

which suggests that the persistence of the process until time N is mainly determined by Yn′. Let
vλ,j : λ
(1) as in the statement of Lemma A.6,
{
∈
then for y

Λ1, j
[m(λ)]
}
RL1, there exists a unique

be a basis (of unit norm) for A

such that

∈

Λ1, r

∈

cλ,r(y) : λ
{

∈

m(λ)

[m(λ)]
}

∈

y =

cλ,r(y)vλ,r .

(5.6)

Λ1
Xλ
∈

r=1
X

r(log N )20L),

Deﬁne Π

RL1 as

⊆

Π :=

y :
{
B(log N )4L

6 (N m
−

cλ,r(y)
|
|
Π where B(log N )4L

∈

For y
(5.7) there exists (λ⋆, r⋆) such that
exists a constant c > 0 and N ⋆

\

RL1 is a L
∞
> (N m
−
N/L, 2N/L, . . . , N

⊆
cλ⋆,r⋆(y)
|
|

for all λ

∈

, r
1
Λ1 \ {
}

(5.7)
∈
ball of radius (log N )4L, by the deﬁnition
r⋆
(log N )20L). Then by Lemma A.7, there

[m(λ)]

.
}

such that

}

(λ⋆)−

jcλ⋆,j+1(y)
|

> cN m
−

1(log N )20L .

(5.8)

∈ {
(N ⋆)j
j!

m(λ⋆)

−

1

|

Xj=0

Denoting by 1
cλ,r 6 (log N )4L, by Lemma A.6 we have that for all N ⋆

RL1 where each coordinate takes value 1. Noting that

log N 6 N ′ 6 N ⋆,

vλ,rk∞
k

∈

6

vλ,rk2 = 1 and

k

AN ′
(1)y 6 (log N )5LN m
−

11 + (1 + O(log N/N ))

−
m(λ)

m(λ)

−

r

Λ1
Xλ
\{
∈

1

}

r=1
X

Xj=0

N ⋆j
j!

λN ′−

jcλ,r+j(y)vλ,r ,

(5.9)

where the ”6” means entry-wise less than or equal to. For each λ
λN ′−
using (5.8), with (5.9) we deduce that for large enough N there exists a N ⋆
such that

we can write
j)θλ), recalling that ¯cλ,j = c¯λ,j, applying Lemma A.4 and
log N, N ⋆)

j)θλ) + i sin((N ′ −

j = cos((N ′ −

1
Λ1 \ {
}

(N ⋆

−

∈

∈

N m
−

1(log N )20L .

(5.10)

(AN ⋆

(1) y)j 6

c
8

−

min
[L1]
j
∈

From the fact that Var Xn = O(n2L) and Gaussian estimate, we have P(Yn′
C ′e−
C <

B(log N )4L) 6
, thus combined with (5.10) and (5.5), it follows that there exists

(log N )2/2 for some C ′ <

such that

6∈

∞

pN 6 Ce−

6 Ce−

∞
N + P(Yn′ 6∈

(log N )2

+ P(Yn′ ∈

B(log N )4L) + P(Yn′ ∈
Π) .
B(log N )4L

B(log N )4L

Π)

\

(5.11)

\

PERSISTENCE FOR AR

17

It remains to bound the last term on the right hand side. Using (5.7), we deduce that

vol(B(log N )4L

Π) = O((log N )4L2

)N −

α ,

m)+(m(λ)
where α =
probability as an integral against Gaussian density, it follows that

Λ⋆(m(λ)
∈

−

−

λ

\
m + 1)+/2. Combined with Lemma 5.1, by writing the

P

P(Yn′ ∈

B(log N )4L

Π) 6 (log N )8L2

N −

α .

Plugging the preceding inequality into (5.11) completes the proof on the upper bound.

\

(cid:3)

5.2. Lower bound. We next turn to the proof of the lower bound. For C0 > 1 and 0 < δ < 1/r⋆
to be selected, deﬁne N1 := C0 log log N and N2 := C0 log N , and the event

N1

ΩN1,δ :=

Xn −
{|

1
|

6 δn

.

}

n=1
\
Recall that 1 is an eigenvalue of A(Q) of eigenvector 1. With the fact that Var ξn = (r⋆)−
easy to verify that for some C1, C2 > 0 we have

P(
Xn −
|

1
|

6 δn

|

n

1

−

\k=n
−

L

Xk −
|

1
|

6 δk) > C1(r⋆δ)

n
2 e−

C2(r⋆δ)n

,

which implies that for N large enough we have

P(ΩN1,δ) > (δ/4)N 2
1 .

n it is

(5.12)

. Denote by

the conditional covariance matrix of YN2 given the σ-ﬁeld
ξn = ξn+N1. Then
ξn) = (r⋆)−

In addition, we denote by Σ⋆
FN1
N2
generated by
Xn := Xn+N1 −
ξ1, . . . , ξN1}
Xn
{
(n+N1)
is a regressive process generated by Q and
with r⋆ > 1. Revoking the proof of Lemma 5.1 and using the aforementioned information, it is easy
e
e
to see that we can keep the same upper bound of λmax(Σ⋆
); and the only change for the lower
N2
bound of λmin(Σ⋆
ξn). Thus by the last equation in the
) is caused by the diﬀerent order of Var(
N2
proof of Lemma 5.1 we get λmin(Σ⋆
c′
N2
and consequently for some C <
we have
N 2m⋆
2

E[Xn+N1 | FN1] and

. In addition by (5.1) we have Var(

ξn}
{
e

for some c′ <

N1)2m⋆
e

6 λmin(Σ⋆

2 (N2 −

2 > N 2m⋆

) > c(r⋆)−

(5.13)

∞
2

∞

N1

e

e

−

−

−

−

−

c′

2

2

,

.

wlog we assume γ0 := m⋆

ΠN2 :=

y :

{

y : c1,1(y)

∩{

|

cλ,r(y)
|
(1

∈

−

1

−
6 N γ0
2
N γ0
2

−
1
−

1

−

c′/2 6

−

r

(N m
−
/3, 1 + N γ0
2

∧

N2) 6 CN 2L
2
RL1 as

N2) 6 λmax(Σ⋆
10L. We deﬁne ΠN2 ⊆
, r
1), for all λ
1

∈
/3), c1,j(y)

Λ1 \ {
1
N γ0
2
∈

}
−

−

1

[m(λ)]

∈

}
(2L, 3L) for 2 6 j 6 m

,

}

(5.14)

where we use the expansion of y as in (5.6) and c1,1 is the coeﬃcient of 1 for y in the expansion.
Let α =

m + 1)+/2. It is clear that

m)+(m(λ)

λ

Λ⋆(m(λ)
∈

−

−

P

vol(ΠN2) > N −

α+o(1) .

(5.15)

We are now ready to provide

18

A. DEMBO, J. DING, AND J. YAN

Proof of the lower bound: Case (d). Using the same method of (5.5), with the deﬁnition of N1, N2
we see that there exists C <

∞
[N1, N2] :

[N2, N ] :

such that
Yn −
k
Yn −
k

P(

∃
P(

n

∈

n

∈

∃

−

N2

N1

An
(1) YN1k∞
An
(1) YN2k∞
vλ,r}

> N −
2
> N −
of A(1) as

{

−

4L

) 6 Ce−

(log N )2

,

4L) 6 Ce−

N .

Expanding YN1 −

1 in the basis of eigenvectors

we have that under ΩN1,δ,

YN1 −

1 =

m(λ)

cλ,rvλ,r,

Λ1
Xλ
∈

r=1
X

e

m(λ)

c2
λ,r =

Λ1
Xλ
∈
Λ1 and r

Xr=1

e

YN1 −
k

k2 6 L1δ2N1
1

2L1,

−

consequently for any λ

∈

L1.
For any N1 < n 6 N2, in light of Lemma A.6 we have that

cλ,r|
|

L1δN1

p

6

−

(5.16)

(5.17)

N1

An
(1) YN1 −

−

1 =

e
m(λ)

m(λ)

−

r

n

−
j

λn

−

N1

−

j

cλ,r+jvλ,r.

(5.18)

N1

(cid:19)

r=1
X
6 1 and (5.17) we see that

Xj=0 (cid:18)

Λ1
Xλ
∈

Hence, with the fact that

|
An
(1) YN1 −

N1

−

λ

|

1

∞
At this point, we choose δ = em⋆

(cid:13)
(cid:13)
(cid:13)

L1

−

N1

n

−
j

6 L1 max

−

(cid:13)
(cid:13)
(cid:13)
3
1 N L1
2

L

2 δN1

−

j6L1 (cid:18)
c′/2

2

−

e−

∧
L1 < (N γ0

vλ,rk∞
cλ,r+j| k
|
2 and consequently

(cid:19)

e

1

N −

2 )/3 as N

.

→ ∞

2 ∧

e

6 L

3
2

1 N L1

2 δN1

L1.

−

(5.19)

(5.20)

Hence when N is large enough, under ΩN1,δ, for any N1 < n 6 N2 we have
and consequently An
N2
have An

(1) YN1 > 1/2
−
(1) YN2 > 1/2
−

< 1/2,
1. Similarly, under ΠN2 of (5.14), for any N2 < n 6 N we

1. Therefore, we deduce from (5.16) that for N large enough

An
(1) YN1 −

||∞

×

N1

N1

1

||

−

×

pN > P(ΩN1,δ

YN2 ∈
{

)
ΠN2}

−

O(1)e−

(log N )2

.

(5.21)

From (5.13), (5.14), (5.19) and (5.20), we observe that for any
as N is large enough

\

yN1 −
k

1

k∞

6 δN1 and yN2 ∈

ΠN2,

N1

AN2
(1)

yN2 −
k

AN2
(1)
k
Hence, there exists C > 0 such that the conditional density of YN2 restricted to ΠN2 given yN1with
in ΩN1,δ satisﬁes

λmin(Σ⋆
N2

yN2 −
k

yN1k∞

yN1 −

2 6

< N γ0

k∞

k∞

q

+

6

N1

).

1

1

−

−

pYN2 |
= (2π)−

YN1
L1
2

(yN2 |
det(Σ⋆

yN1)

N2)

(cid:0)

(cid:1)

1
2 exp

−

1
2

(cid:16)

−

(cid:18)

yN2 −

N1

AN2
(1)

−

yN1

T

(cid:17)

(Σ⋆

N2)−

1

yN2 −
(cid:16)

N1

AN2
(1)

−

yN1

(cid:17)(cid:19)

PERSISTENCE FOR AR

> C(λmax(Σ⋆

N2))−

L1
2 ,

where the last inequality is due to

v′Σ−

1v 6 ||

2
v
2
||
λmin(Σ)

2
v
6 L1 ||
||
∞λmin(Σ)

6 L1.

Therefore, from (5.12), (5.13) and (5.15) we see that for a constant C > 0

P(ΩN1,δ

ΠN2}
Thus (5.21) completes the proof.

YN2 ∈
{
\

) > P(ΩN1,δ)

C(λmax(Σ⋆

N2))−

L1
2 vol(ΠN2 ) > N −

α+o(1) .

·

19

(cid:3)

6. Approximately irw: Theorem 1.1 (e)

We ﬁrst show the upper bound in Subsection 6.1, by comparing the process with an order m
irw. For the lower bound, we prove it for two diﬀerent cases: the case with dominant zero-
angle component, and the case with competing oscillatory components, in Subsection 6.3 and 6.2
respectively.

6.1. Upper bound. Next lemma states that the persistence probability for an irw of any order
has polynomial decay, which we need later.

Lemma 6.1. Let
Then there exist constants c,C > 0 such that for any N > K,

Yn : n = 1, . . . , N
{

be ar((z

−

}

1)m+1), and assume K is a ﬁxed positive integer.

P(Yn > 0 for all K 6 n 6 N ) 6 cN −

C.

(6.1)

Proof. It is obvious that we just need to show (6.1) for N large enough. We denote nk = 2k, and
> 0 for all [log K] + 1 6 k 6 [log N ]
. We
notice that
}
calculate the correlation between Yni and Ynj (i < j) as follows,

Yn > 0 for all K 6 n 6 N
{

Ynk
{

implies

}

ni

nj

ρ(Yni, Ynj ) = ρ(

bni,ℓξℓ,

bnj,ℓξℓ) =

Xℓ=1

Xℓ=1

ni
ℓ=1 bni,ℓbnj,ℓ
nj
ℓ=1 b2

ni,ℓ

ni
ℓ=1 b2
P

nj,ℓ

.

Since bn,ℓ = a1,m(n

ℓ)m(1 + o(n

ℓ)), we get for large i, j that

qP

qP

ρ(Yni , Ynj ) =

ni

−
ℓ=1(ni −
ℓ)2m

ni

ℓ=1(ni −
P

−
ℓ)m(nj −

ℓ)m
ℓ=1(nj −

nj

(1 + o(1)) 6 2

ℓ)2m

1
2

ni
nj (cid:19)

(cid:18)

(1 + o(1)) = 21

i
−
−|

j

/2(1 + o(1)).

|

pP

(6.2)
From (6.2) we see that there exists K0 > 0 such that ρ(Yni, Ynj ) > 0 for all i, j > K0, and
and all k > K0. Combined with Lemma 3.3, we

K0) for some ∆ <

ρ(Yni, Ynj ) 6 ∆(k

qP

k
i,j>K0

−

∞

see that there exist c, C > 0 such that
P

P(Yn > 0 for all K0 6 n 6 N ) 6 P(Ynk

> 0 for all K0 < k 6 [log N ]) 6 ce−

C log N = cN −

C.

Since K0 is independent of N , the proof is completed.

(cid:3)

Now we give an upper bound on the persistence probability.

Lemma 6.2. Suppose that Λ
c, C > 0 such that pN 6 cN −

⊂

C for all N

D and m(1) > m(λ) for all λ

Λ⋆. Then there exist constants

∈

N.

∈

20

A. DEMBO, J. DING, AND J. YAN

Proof. By our assumption, the zero set Λ for the generating polynomial Q(z) satisﬁes that Λ
Let m = maxλ
Λ m(λ), and let (Yn) be ar((z
∈
Lemma 2.1 and verify that for a number K > 0 (independent of N ),
ρ(Xn, Xm) 6 ρ(Yn, Ym) for all n, m > K .

D.
It is then straightforward to apply

1)m+1).

−

⊆

Combined with Slepian’s Lemma, it follows that

pN 6 P(Yn > 0 for all K 6 n 6 N ) ,

which completes the proof together with Lemma 6.1.

(cid:3)

6.2. Lower bound with competing oscillatory components. Here we show the lower bound
of ﬁrst case in part (e), where r⋆ = 1 and
such that m(λ) = m(1). In the proof
∈
the key is Lemma 6.3. Before stating the lemma let’s introduce some notations. Suppose that
where λ0 = 1. Write λj = e√
Λ⋆ =
λ0|m(1), λ1|m1 , . . . , λℓ|mℓ }
[ℓ]. By Lemma 2.1, we
{
could write

1θj for j

1
}
\ {

Λ⋆

∈

λ

∃

−

ℓ

where cj 6
Now, for j

= 0, Tj,n :=

[ℓ] we deﬁne

n

i=1 bn,i,mj−

∈

Xn =

cjTj,n + Rn ,

(6.3)

1 cos((n

Xj=0
i)θj + θλj ,mj−
−

1)ξi and Rn =

n
i=1 O((n

−

i)m(1)

−

2)ξi.

P

T ′j,n :=

bn,i,mj−

1 sin((n

i)θj + θλj,mj−

−

1)ξi and Tj,n := [Tj,n, T ′j,n]T .

(6.4)

In addition, for k > 1 we write Tj,n,k = [Tj,n,k, T ′j,n,k]T where

n

Tj,n,k =

bn,i,k cos((n

i)θj + θλj,mj−

−

n

1)ξi , T ′j,n,k =

bn,i,k sin((n

i)θj + θλj,mj−

1)ξi .

−

(6.5)

Xi=1

Xi=1

The diﬀerence between (6.5) and (4.4) is that here we replace θλj ,k by θλj ,mj−
easy to see that for all k > 2

1. Due to (4.3) it is

(6.6)

by noting that Tj,n = Tj,n,mj−

Tj,n+1,k = Rθj Tj,n,k + Tj,n+1,k

1 ,

−

1, especially

Tj,n+1 = Rθj Tj,n + Tj,n+1,mj−
Write Tn as a 2ℓ-dimensional vector such that Tn = [T1,n, . . . , Tℓ,n]T , and in the similar manner
write t = [t1, . . . , tℓ]T where tj ∈
R by

N, deﬁne φK : R2ℓ

[ℓ]. For any ﬁxed K

R2 for each j

(6.7)

2 .

7→

∈

P
n

Xi=1

φK(t) := min
06i6K

[1, 0]

cj(Rθj )itj for t

R2ℓ .

∈

(6.8)

∈
ℓ

Xj=1

The following lemma is stronger than what we need in the current section, and will be used later

in establishing the power law.

Lemma 6.3. Assume
be independent while
as

λ
∃
˜T0,
{
Tj,
. Then for any ε > 0 and K
{
∈
N ) 6 P(c0(1 + ε) ˜T0,n + φK ( ˜Tn) >
P(Ω+

∈
·}

·}

Λ⋆
has the same distribution as

1
}
\{

such that m(λ) = m(1). Let

˜T0,
{
and

T0,
{

·}
N, there exists C > 0 such that for any N

·}

and

·}
˜Tj,
{

˜Tj,
{

·}

(for j = 1, . . . , ℓ)
has the same distribution
N,
∈
C(log N )2
K) + e−

,

−

εnm(1)
−

1/2 , for log N 6 n 6 N

−

P(Ω+

N ) > Ce−

C(log N )3/4

(P(c0(1

−

ε) ˜T0,n + φK ( ˜Tn) > εnm(1)
−

1/2, for 1 6 n 6 N )

PERSISTENCE FOR AR

21

) .

C(log N )4/3

e−

−

Proof. We ﬁrst prove the upper bound. Deﬁne Λ0 :=
and Lemma A.1 we get

λ
{

∈

Λ⋆, m(λ) = m(1)
. With Lemma 2.1
}

Var [Xn] =

n

(
Λ
Xλ
∈

Xℓ=0

m(λ)

−

1

Xj=0

λ
aλ,j|

ℓℓj cos(ℓθλ + θλ,j))2 =
|

Λ0
Xλ
∈

a2
λ,m(1)

−

1n2m(1)
−

1 + O(n2m(1)
−

2), (6.9)

and similarly

Var[(1+ε)c0 ˜T0,n+

ℓ

Xj=1
For any ε > 0, because

cj ˜Tj,n] = ((1+ε)2a2

1,m(1)

1+

Λ0
Xλ
\{
∈

1

}

a2
λ,m(1)

−

1)n2m(1)
−

1+O(n2m(1)
−

2). (6.10)

−

(1 + ε)2a2

1,m(1)

1 +

λ

Λ0

∈

1

\{

}

a2
λ,m(1)

−

1

< (1 + ε)2,

−
λ

∈

a2
P
λ,m(1)

Λ0

1

−

N and κε < 1 such that for all
combining with (6.9) and (6.10) it follows that there exists n1 ∈
n > n1, we can ﬁnd εn < κεε such that Wn := ((1 + ε)c0 ˜T0,n +
j=1 cj ˜Tj,n)/(1 + εn) has the same
variance as Xn. Furthermore by Lemma 2.1 and Lemma A.1 it is not hard to verify that there
exists nε > n1 such that

P

P

ℓ

Therefore, by Slepian’s Lemma we obtain that

Cov(Xn, Xn′) 6 Cov(Wn, Wn′) for all n, n′ > nε .

P(Xn > 0 for nε 6 n 6 N ) 6 P(Wn > 0 for nε 6 n 6 N ) .

(6.11)

Consider N large enough such that log N > nε. Denote by
c0(1 + ε) ˜T0,n + φK ( ˜Tn) >
{
N

εnm(1)
−

E :=

1/2 , for all log N 6 n 6 N

K

,

}

−

−
2k2 > cεK −

1nm(1)
−

1/2

.

}

F :=

[n=log N

{
P

l
j=1k

˜Tj,n,mj−

Note that under F c, for any log N 6 n 6 N

−

K and i 6 K, by (6.7) we have

ℓ

i

[1, 0]

|

ℓ

j=1
X

cj(Rθj )i ˜Tj,n −

ℓ

j=1
X

cj ˜Tj,n+i|

6 max

16j6ℓ {|

cj|}

˜Tj,n+p,mj −

k

2k2 6 εℓc max

16j6ℓ {|

cj|}

nm(1)

1/2.

−

j=1
X

p=1
X

Choose c such that cℓ max16j6ℓ {|
cj|}
deﬁnition of φK, it follows that Ec
∩
Wn > 0 for log N 6 n 6 N
E
{
∪
some C > 0, yielding the desired upper bound together with (6.11).

(6.12)
< 1/2. Combining with (6.12), the deﬁnition of Wn and the
c, which implies that
F c
}
F . A simple union bound gives that P(F ) 6 e−
for

Wn > 0 for log N 6 n 6 N

C(log N )2

⊆ {

} ⊆

We next turn to the proof of the lower bound. With the similar method to the proof of the upper
N and κ′ε < 1 such that for all n > n′ε, we
ε′n) has the same variance as

bound, we can show that for any ε > 0, there exist n′ε ∈
can ﬁnd εn < κ′εε such that Un = ((1
Xn, and

j=1 cj ˜Tj,n)/(1

ε)c0 ˜T0,n +

−

−

ℓ

Cov(Xn, Xn′) > Cov(Un, Un′) for all n, n′ > n′ε.

P

22

A. DEMBO, J. DING, AND J. YAN

Therefore, by Slepian’s Lemma we obtain that

P(Xn > 0 for n′ε 6 n 6 N ) > P(Un > 0 for n′ε 6 n 6 N ) .

(6.13)

Denote by

E := A

where A :=
(6.13) and a union bound on

Xn > 0 for n′ε 6 n 6 N
{

\
Xn|
, B :=
b
{|
}
> (log N )2/3
, we get that
}

Xn|
{|

B,
6 (log N )2/3 for n′ε −

L + 1 6 n 6 n′ε}

. By

P(

E) > P(Un > 0 for n′ε 6 n 6 N )

C2(log N )4/3

,

(6.14)

e−

−

for some C2 > 0. For i
hi,i = 1, hj,i = 0 for j
the regressive relation we can see that starting from
Xn′ε−

L+i in Xn′ is hn

∈ {
b
1, ..., L

1, ..., L

∈ {

−

denote hn,i as the solution to (2.1) with initial condition
}
1), and by
. Then by Lemma 2.1 we have hn,i = O(nm(1)
i
−
}
} \{
, the coeﬃcient of

Xn : n′ε −
{

L + 1 6 n 6 n′ε}

n′ε+L,i. Thus under B, for all n′ > n′ε we have

Xn : n′ε −

E(Xn′ | {
Xi=0
Denote by n⋆ = (log N )3/4. For some M, δ > 0 to be determined later, deﬁne

L 6 n 6 n′ε}

L+i 6 O(1)(log N )2/3(n′

n′ε+L,iXn′ε−

) =

hn

−

n′ε)m(1)
−

1 . (6.15)

−

L

L

p

Ep =

b

M 6 Xn 6 (1 + δ) M
{
\n=1

}

\

1 6 ξn 6 1 + δ
{
\n=L+1

.

}

(6.16)

−

C1δM nm(1)
−

From Lemma 2.1 and the fact that 1 is a root of Q, for n > L there exists C1 > 0 such that
1. By Lemma 2.1 and Lemma A.1, it is easy to see that there exists
Xn(1, L) > M
C2, C3 > 0 and N1 ∈
C3
if n 6 N1. Choosing M = 2C3 + 1, δ = (2C1N m(1)
1, one can then verify that
−
En⋆, one can verify that there
for any p
exists L′ > L such that Xn(1, L′) > 0 for n large enough, and there exists C > 0 such that for all
1 as N is large enough, where the exponent
n⋆)m(1)
n′ > n⋆, Xn′(L′ + 1, n⋆) > C(log N )17/24(n′ −
17/24 is an arbitrarily chosen number between 2/3 and 3/4. Thus as N is large enough

Z+, such that Xn(L + 1, n) > C2nm(1) if n > N1, and Xn(L + 1, n) >
1

)−
p . In the following we consider

Ep ⊂
b

C2(2C1M )−

En⋆. Under

Z+,

Ω+

−

∈

∧

b

b

−

1

1

E(Xn′ | {

) > C(log N )17/24(n′
Xn : n⋆
L + 1 6 n 6 n⋆
}
E(Xn′ | {
Xn : n′ε −
Note that for all n′ > n′ε, the distribution of Xn′ −
L + 1 6 n 6 n⋆
the distribution of Xn′−
n′ε+n⋆
n′ε+n⋆
−
and (6.17) it yields that for N large enough
n′ε + n⋆

P(Xn > 0 for all n⋆ 6 n 6 N

E(Xn′−

Xn : n⋆

| {

−

−

(6.17)

1 .

n⋆)m(1)
−
−
L + 1 6 n 6 n′ε}

) is same as
), combined with (6.15)
}

−

|

En⋆) > P(Xn > 0 for all n′ε 6 n 6 N

B).

(6.18)

|

Further we can choose N large enough such that n⋆ > n′ε, thus with (6.18) the following holds,
b
En⋆) > P(A

B) > P(A, B) = P(

E).

Note that obviously P(

P(Xn > 0 for all n⋆ 6 n 6 N
En⋆) > (Cδδ)n⋆

|

|

for some Cδ > 0. Recalling that Ω+
n⋆
En⋆) > P(

En⋆)P(

⊂
E) > (Cδδ)n⋆ P(

b

b

En⋆, we have

E) .

pN > P(

En⋆)P(Xn > 0 for all n⋆ 6 n 6 N

b

|

Combined with (6.14) and the fact that
completes the proof of the lemma.

b

ℓ

j=1 cj ˜Tj,n > φK ( ˜Tn) by the deﬁnition of φK at (6.8), it
b
(cid:3)

b

b

b

Here we show the lower bound in case r⋆ = 1, m(1) = m(λ) for some λ

P

b

Λ⋆.

∈

PERSISTENCE FOR AR

23

Lemma 6.4. For any constant C > 0, there exist c, C ′ > 0 such that for all j 6 ℓ

Tj,nk2 6 Cnm(λj )
P(
k

−

1
2 for all 1 6 n 6 N ) > cN −

C′ for all N

N .

∈

(6.19)

Proof. Applying (6.7) and the triangle inequality, we see that

Tj,nk2 6 Cnm(λj )

−

{k

By (6.7) we have that

1
2 for all 1 6 n 6 N

} ⊇ {k

Tj,n,0k2 6 C√n for all 1 6 n 6 N

.

}

(6.20)

n

Tj,n,0 =

(Rθj )n

i[cos θλj,mj , θλj,mj ]T ξi ,

−

and therefore

Write S1,n = [1, 0]

Xi=1

n

Tj,n,0k2 6
k
n
i=0(Rθj )−

k

(Rθj )−

i[1, 0]T ξik2 +
i[1, 0]T ξi and S2,n = [0, 1]

Xi=0

k

n

(Rθj )−

Xi=0
n
i=0(Rθj )−

i[0, 1]T ξik2.
i[1, 0]T ξi. Deﬁne

(6.21)

P

Γk :=

S1,γk+1

< C

γk+1/4
P
.
}

{
(cid:12)
(cid:12)

Noting that Var(S1,n) = n + o(n), by the independence of S1,γk+1
see that there exists a γ > 1 just depending on C and a constant C0 > 0, such that P(Γk |
z) > C0 for each k and any z with
[logγ N
n 6 N
Γk) as the multiplication of a sequence of
k=1
conditional probability, with previous upper bound of the conditional probability we see that there
exist c, C ′ > 0 such that

S1,γk and S1,γk , it is easy to
S1,γk =
6 C√n/4 for all 1 6

Γk. Then by writing P(
p

γk/4. We can check that

S1,n|
{|

[logγ N
k=1

} ⊂ ∩

6 C

z
|

p

−

∩

(cid:12)
(cid:12)

−

−

1]

1]

|

P(
S1,n|
|
6 C√n/4 for all 1 6 n 6 N ). By Gaussian correlation inequality (see
Same applies for P(
S2,n|
|
[25], and weaker versions in [21, 26] which would also work for our proof), we have

6 C√n/4 for all 1 6 n 6 N ) > c1/4N −

C′/4.

µ(A

B) > µ(A)µ(B) for all convex symmetric sets A and B ,

(6.22)

where µ is a Gaussian measure on Euclidean space. Applying (6.22) with

\

A =

we have

S1,n|
{|

6 C√n/4 for all 1 6 n 6 N

, B =
}

S1,n|
{|

6 C√n/4 for all 1 6 n 6 N

,
}

n

(Rθj )−

P(
k

Xi=0
>P(
S1,n|
|

i[1, 0]T ξik2 6 C√n/2 for all 1 6 n 6 N )

6 C√n/4 for all 1 6 n 6 N )P(
S2,n|
|
n
i=0(Rθj )−
C′/2. Using
Similar argument applies to show that P(
k
(6.21) and applying (6.22) again gives a desired lower bound for the probability of the event in the
(cid:3)
right hand side of (6.20). Hence with (6.20), the desired estimates follows.

6 C√n/4 for all 1 6 n 6 N ) > c1/2N −
i[0, 1]T ξik2 6 C√n/2) > c1/2N −

C′/2 .

P

Write T0,n,0 =

n
i=1 ξi. For a Brownian motion B and a constant C > 0, we consider the
following intervals [2k, 2k+1], k = 0, ..., [log N ], which obviously cover [1, N ]. Deﬁne the following
events for each k,

P

Λk :=

B(t)
{

−

B(2k) > C√t

−

2C√2k for any t

∈

[2k, 2k+1] and B(2k+1)

B(2k) > 2C√2k

.
}

−

24

A. DEMBO, J. DING, AND J. YAN

By scaling, it is easy to see that there exists a C0 > 0, such that for any k we have P(Λk) > C0.
B(1) >
Noting that by the deﬁnition of Λk’s we can check that
[log N ]
k=1 Λk. With the independence of Λk’s and the fact that we can regard T0,n,0 as a Brownian
C
motion at integer times, we see that there exists c > 0 such that

B(t) > C√t for all t
{

[0, N ]

} ∈ {

}∩∩

∈

P(T0,n,0 > 2Cm(1)!√n for all 1 6 n 6 N ) > cN −

1/c.

(6.23)

Observing that

T0,n,0 > 2Cm(1)!√n for all 1 6 n 6 N
{

combined with (6.23) we get

T0,n > Cnm(1)
−

} ⊂ {

1/2 for all 1 6 n 6 N

,
}

P(T0,n > Cnm(1)
−

1/2 for all 1 6 n 6 N ) > cN −

1/c .

(6.24)

Noting that φK(t) >
bound.

−

ℓ

1

−

j=2 cjk

tjk

, with Lemmas 6.3 and 6.4, we complete the proof on the lower

P

6.3. Lower bound with dominant zero-angle component. Here we complete the proof of
lower bound of part (e) in Theorem 1.1, for the case r⋆ = 1 and m(1) > m(λ) for all λ
.
1
}
\{

Λ⋆

∈

Lemma 6.5. If m(λ) < m(1) for all λ
any N ,

∈

Λ⋆

, then there exist constants c, C > 0 such that for
1
}
\ {

pN > cN −

C .

Proof. First we assume m(1) > 1. Denote by m = m(1), γ = m
m, then by (6.24) there exist constants c1, C1 > 0 such that

−

3/2. Let S(m)

n

be an irw of order

P(S(m)

n > 0 for n = 1, ..., N ) > c1N −

C1.

(6.25)

By Lemma 2.1 we can write

Denote by

Xn = c0S(m)

n + Yn, where Var(Yn) = O(n2γ).

n⋆ := [log N ]2, n′ := [log log N ]2,

m

E1 :=

S(j)
n⋆ > (log N )2j
{
\j=1

2

−

.
}

Note that under E1, there exists C2 > 0 such that S(m)
n⋆ 6 n 6 N . Let
obviously

S(m)
n

for k

1 > C2nγ log N for all
n (0, n⋆) > C2nm
−
1)m and ξn1n>n⋆, then

−
Z, and we have that under E1

be an auto-regressive process generated by (z

∈

n⋆+k has the same distribution as S(m)
S(m)
n⋆+k + S(m)
S(m)
n⋆+k(0, n⋆) >

e
S(m)
n > C2nγ log N for all n⋆ 6 n 6 N
{

e
S(m)
n⋆+k =

k

Let E0 :=

e
E1) > P(
P(E0 |
S(j)
m
Similarly, let E4 :=
j=1{
n′
exists C3 > 0 such that S(j)
n (0, n′) > C3C5n(j
1(log log N )2 for all n′ 6 n 6 n⋆, S(j)
n > nm
S(m)
−
{

> C5(log log N )2j
e

E2 :=

∩

e

}

−

S(m)
n⋆+k + C2(n⋆ + k)γ log N.

, thus with (6.25) and (6.26) we get
}

S(m)
n > 0 for n = 1, ..., N ) > c1N −

C1.

(6.26)

(6.27)

with C5 to be determined later. Under E4 there

1)(log log N )2 for all n′ 6 n 6 N and j
2 for all j
n⋆ > (log N )2j

−

[m]. Let

.
[m]
}

∈

∈

(6.29)

(6.30)

(6.31)

P(F c

0 ).

−

PERSISTENCE FOR AR

Choosing C5 = 1/C3, with the similar argument to (6.27) we see that
P(E2 |

E4) > c3(log N )−

C3 > c3N −

C3,

25

(6.28)

for some c3, C3 > 0. Let

E3 :=

Xn > 0 for all 1 6 n 6 n′, S(j)
n′
{

Recalling the deﬁnition of

Ep (6.16), it is easy to see that

> C5(log log N )2j for all j

∈
E3 for n′ large enough, thus

.
[m]
}

P(E3) > c4e−

C4n′.

En′ ⊂
b

Further deﬁne

b

: =

: =

F0
F1

{
Then by simple union bound there exist C6, C7 > 0 such that

−

{

Yn >
Yn >

−

(C2/c0)nγ log N for all n⋆ 6 n 6 N
(1/c0)nγ(log log N )2 for all n′ 6 n 6 n⋆

}

,

.

}

P(F c

0 ) 6 e−

C6(log N )2

, P(F c

1 ) 6 e−

C7(log log N )4

.

By deﬁnition it is straightforward to see that
pN > P(E3, E2, E0, F1, F0) > (P(E3)P(E2 |

E3)

−

F1, E2, E3)

P(F c

1 ))P(E0 |
S(j)
n⋆ , j
{

, and the similar holds
[m]
Note that E1 is independent of σ(ξ1, ..., ξn′ ) conditioned on
}
for E2. Plugging (6.27), (6.28), (6.29) and (6.30) into (6.31), we see that the lemma is true in this
case.

∈

Now if m(1) = 1, then according to the condition we get Λ⋆ =

, and thus by Lemma 2.1 we
1
}
{

can write

Consider

E0

E2
F0

: =

: =

: =

Xn = c0S(1)

n + Yn, where Var(Yn) 6 C0 for some C0 <

.

∞

S(1)
n > (log N )/2 for all log N 6 n 6 N
{
Xn > 0 for all 1 6 n 6 log N , S(1)
{
Yn >
{

(log N )/(2c0) for all log N 6 n 6 N

−

S(1)
log N > (log N )/2
,
, E1 :=
}
{
}
log N > (log N )/2
,
}

.
}

Then by the similar argument to above, there exist c2, C2, c3, C3, C4 > 0 such that

P(E0 |

E1) > c2N −

C2, P(E2) > c3e−

C3 log N , P(F c

0 ) 6 e−

C4(log N )2

.

Thus the proof is completed by

pN > P(E0, E2, F0) > P(E0 |

E2)P(E2)

−

P(F c

0 ) > c2c3N −

C2

−

C3

C4(log N )2

.

e−

−

(cid:3)

7. Persistence power exponent for ar3: Theorem 1.3

First, in Subsection 7.1 we reduce the persistence probability for regressive processes considered
in Theorem 1.3 to the probability for a 3-dimensional Brownian motion to stay in a generalized
cone. Then, in Subsection 7.2, we show the existence of the persistence power exponents in the case
(0, π), and analyze the continuity and discontinuity of the power
Λ =
}
exponents depending on θ is rational or not.

1, e√
{

1θ, e−

for θ

∈

1θ

√

−

−

26

A. DEMBO, J. DING, AND J. YAN

7.1. AR processes and the Brownian motion in a cone. We start with the following lemma.

n ) of order m, and an arbitrary deterministic sequence (fn), there

0 0 such that the following holds for all N

N,

∈
n > fn , for all 1 6 n 6 N ))1+cεN −
1/2 , for all 1 6 n 6 N ) > (P(S(m)

cε .

Lemma 7.1. For an irw (S(m)
exist cε →ε
P(S(m)

→

n > fn + εnm
−
S(m)
n > fn for all 1 6 n 6 N
{

Proof. Let Ξ :=
N (Cεn−
(ξn), and let Pε to be the law of independent sequence (ξ′n) such that ξ′n ∼
n. Then it is easy to check that there exists C > 0 depending only on m such that

. Let P0 be the original law of an i.i.d. sequence of
}
1/2, 1) for each

P(Sm

Using the fact that dPε
dP0

n > fn + εnm
−
((xn)) = ePk(Cεxkk−
dPε
dP0
By H¨older inequality and Radon-Nikodym theorem, we obtain that for all 0 < δ < 1,

1/2 , for all 1 6 n 6 N ) > Pε(Ξ) .
C2ε2/2k), for any δ > 1 we get

6 N C2ε2/δ2

EP0

(cid:0)(cid:0)

1/δ

1/2

(cid:1)

(cid:1)

−

−

1

.

(7.1)

(7.2)

P0(Ξ) = EPε(

dP0
dPε

1Ξ) 6 (Pε(Ξ))1
−

δ(EPε

dP0
dPε

1/δ

)δ = (Pε(Ξ))1
−

δ(EP0

dPε
dP0

1/δ

1

−

)δ .

(7.3)

(cid:0)(cid:0)
Setting δ = √ε and plugging (7.2) into (7.3), by (7.1) we complete the proof of the lemma.

(cid:0)(cid:0)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:0)

(cid:3)

In the rest of the paper, we assume that Λ =

1, e√
{
1θ. Recall the deﬁnition of θλ,1 in Lemma 2.1.

λ = e√

−

1θ, e−

−

√

−

1θ

for θ

}

∈

(0, π), and denote

i[1, 0]T ξi. Then,
Lemma 7.2. Let W be a planar Brownian motion, and let Tn :=
for all ε > 0, there exists a coupling of (W, T) and c > 0 depending only on ε such that for all N ,

Rθλ,1(Rθ)−

n
i=1

n

P(

∃

∈

[N ] :

1
√2

k

Wn −

Tnk

> (log N )4 + ε√n) 6 e−

c(log N )2

.

P

Proof. Let nk := [k (log N )2] for 1 6 k 6 [N/ (log N )2]. Writing I as an identity matrix of size 2,
by Lemma A.1 and the deﬁnition of Tn we see that the covariance matrix Bk of (Tnk+1 −
Tnk )
satisﬁes

Bk −
k
where C is a constant depending only on θ. Therefore, there exists C ′ > 0 such that

I
k∞

6 C,

(log N )2
2

Bk =

C ′

−

I + Ak ,

(log N )2
2
Akk∞
k

where Ak is a positive deﬁnite matrix with
in R2 with covariance matrix Ak, and let Yn =

Tnk : 1 6 k 6 N/ (log N )2
{

}

law
=

1
√2

{

(1

−

6 C ′. Let ζk be an independent Gaussian vector
n
k=1 ζk. Therefore, we see that
(log N )2 )1/2Wnk + Yk : 1 6 k 6 N/ (log N )2

(7.4)

C ′
P

}

,

where W is independent of Y. By a simple union bound, for a constant c′ > 0 we have that
Ykk
k

> ε log N √k/4) 6 e−

[N/ (log N )2] :

c′(log N )2

P(

∈

∃

k

,

and

k

P(

∃

∈

[N/ (log N )2] :

Wnk k
k

> ε (log N )2 √nk/

4C ′

) 6 e−

c′(log N )2

.

(cid:0)

(cid:1)

(7.5)

(7.6)

PERSISTENCE FOR AR

27

From (7.4) and the fact that

(0, 1), we see that

k

{∃

k

⊂ {∃

∈

∈

[N/ (log N )2] :

[N/ (log N )2] :

k

k

x)1/2

< x for x

(1
|
1
√2
Wnk k

1
|
∈
> (log N )4/2 + ε√nk/2

−
−
Wnk −
Tnk k
1
ε (log N )2 √nk} ∪ {∃
>
k
4C′

}

[N/ (log N )2] :

∈

>

Ykk

k

1
4

ε log N √k

.

}

Thus combined with (7.5) and (7.6) we get

k

P(

∃

∈

[N/ (log N )2] :

1
√2

k

Wnk −

Tnkk

> (log N )4/2 + ε√nk/2) 6 2e−

c′(log N )2

.

(7.7)

Similarly, by a union bound again it is easy to verify that for some constant c′′ > 0,

k, p :

P(

∃

1
√2

k

(Wnk+p −

Wnk )

(Tnk+p −

−

Tnk )

k

> (log N )4/2 + ε√nk/2) 6 e−

c′′(log N )2

.

(7.8)

Combined with (7.7) and (7.8), it completes the proof of the lemma.

(cid:3)

) in (6.8), where in what follows we specify ℓ = 1. We denote by
Recall the deﬁnition of φK(
·
φK(t) for all t
∈

φ(t) = limK

Lemma 7.3. Let W be a planar Brownian motion independent of a Brownian motion B. Then
for K

N large enough independent of N , we have

R2.

→∞

∈

lim sup

ε

0

→

log pN
log N

lim
N
→∞

6 lim inf
0
ε
→

lim
N
→∞

lim inf
→

0

ε

log pN
log N

lim
N
→∞

> lim sup
ε
→

0

lim
N
→∞

P(c0(1

−

P(c0(1 + ε)Bt + φ( 1
√2

Wt) > 0 , for (log N )9 6 t 6 N

ε)Bt + φ( 1
√2

log N
Wt) > 0 , for 1 6 t 6 N )
log N

K)

,

−

.

Proof. Obviously it is enough to show that there exist c, cε > 0 with cε →ε
N

N,

0 0, such that for any

→

∈
pN 6N cε(P(c0(1 + ε)Bt + φ( 1
√2
C(log N )3/4
cεP(c0(1

pN >Ce−

N −

Wt) > 0 , for (log N )9 6 t 6 N

−

ε)Bt + φK(Wt) > 0, for 1 6 t 6 N

−

K)1

−

cε + e−

c(log N )2

) ,

(7.9)

(log N )9)1+cε + e−

−

C(log N )4/3

.
(7.10)

T1,n = (Rθ)nTn and thus φ(

Let Tn be deﬁned as in Lemma 7.2 and let
can construct a coupling such that
of φ(t), we see that for any ε1 > 0, we can choose K large enough such that φK(t) = φ(t) if θ
and φK (t) 6 (1
φK (t1)
|
that

T1,n be deﬁned as in Lemma 6.3. By the deﬁnition we
T1,n) = φ(Tn). By the deﬁnition
Q,
Q. Furthermore, by the deﬁnition of φK , for any K we have that
e
only depending on Q, which further implies

∞
Wn/√2
k
Wn) 6 C1((log N )4 + ε2√n) + φ(Tn) 6 C1((log N )4 + ε2√n) + φK(Tn),

ε1)φ(t) if θ /
∈
−
6 C1 ||
t1 −
φK(t2)
t2||
|
6 C1 ||
t2||
t1 −
φ(t2)
|

for some C1 <
. Therefore, if

6 (log N )4 + ε2√n, then

Tnk

φ(

−

∈

e

e

−
φ(t1)
−
|
1
√2

(1

−

ε1)φ(

1
√2

Wn) >

C1(1

−

−

ε1)((log N )4 + ε2√n) + φK (Tn).

Note that there is a natural coupling of Bn and T0,n deﬁned in Lemma 6.3. Therefore for any
ε > 0, letting ε1 = ε and ε2 = ε/(3C1), by (7.12) we have that when N is large enough, for any
n > (log N )9

φK(Tn) 6 (1

ε)φ(

−

1
√2

Wn) +

ε
2

√n.

(7.11)

(7.12)

28

A. DEMBO, J. DING, AND J. YAN

By Lemma 6.3 and Lemma 7.2 we see that there exists c > 0 such that

Let ζn = maxs

pN 6 P(c0

Bn + φ(

Wn) >

1 + ε
1
ε
−
Bs −
[n,n+1](
|
∈

1
√2
+
Bn|
P(

n

∃

∈

2ε

√n, for (log N )9 6 n 6 N

K) + e−

c(log N )2

.

ε
1
−
−
−
Ws −
Wnk
). Clearly, for N large enough a union bound gives
k
[N ] : ζn > (log N )2) 6 e−

(log N )2

.

Combining the last two inequalities and with Lemma, 7.1 (7.9) is implied directly.

Denote by n⋆ := (log N )9. Deﬁne

A :=

B :=

c0(1
{

−

c0(1
−
{
ε)Bn + φ( 1
√2

ε)Bn + φ( ˜Tn) > (ε(1 + C1) + C1)√n, for 1 6 n 6 n⋆

,
}
Wn) > ε(1 + C1)√n + C1(log N )4, for n⋆ 6 n 6 N

D :=

n

{∃

∈

[N ] :

1
√2

k

Wn −

Tnk

> (log N )4 + ε√n

.
}

K

,
}

−

Recall that for any ε > 0, when K is large enough φK(t) 6 (1
above analysis, with Lemmas 6.3, 7.2 and (7.12) we obtain that there exists C > 0 such that

ε)φ(t) for any t. Similar to the

−

C(log N )4/3

P(Ω+) > Ce−

C(log N )3/4

P(A, B, Dc)

e−

−
Wk := Wn⋆+k −
Denote by
motions. Note that by the deﬁnition of φ we have
f
Wn⋆+k) > φ( 1
φ( 1
√2
√2

Bk := Bn⋆+k −
e

Bn⋆,

> Ce−

C(log N )3/4

P(B

|

Wn⋆, then obviously

Bn,

A, Dc)P(A, Dc)

C(log N )4/3

.

e−

−

(7.13)
Wn are still Brownian

Wk) + φ( 1
√2

Wn⋆).

e

f

(7.14)

Under

A, Dc
{
c0(1

it is easy to see that

}

ε)Bn⋆ + φ( 1
√2

Wn⋆) > c0(1

−

−

f
ε)Bn⋆ + φ( ˜Tn⋆)

combined with (7.14) and the fact that 2√n > √n + n⋆

− k

Wn⋆

1
√2
2√n⋆, we get

−

Tn⋆

k

−

> 2ε√n⋆,

P(B

|

A, Dc) > P(c0(1

−

ε)

Bn + φK(

Wn) >

ε
2

(√n + n⋆

−

2√n⋆), for 1 6 n 6 N

n⋆

−

−

K)

Note that φ(t) >
c1(n⋆)−
Lemma 7.1 and Lemma 7.2, the proof is completed.

e
C1 for some c1, C1 > 0. Noting that P(A, Dc) > P(A)

(7.15)
−
for some c > 0. Thus by Lemma 6.4 and (6.24), we see that P(A) >
P(D), combined with (7.13), (7.15),
(cid:3)

Wn) > ε√n, for 1 6 n 6 N
f

> P(c0(1
c

Bn + φK(
e

K).

f

ε)

−

−

−

−

k

k

t

n⋆

7.2. Continuities and discontinuities of the power with no multiple zeroes. In this sub-
section, we will use estimates on the probability for a Brownian motion to stay in a generalized
be a domain in the unit
cone to deduce persistence probability of our regressive process. Let
sphere S2 of R3. Denote by λ(
with
Dirichlet boundary condition. In addition, deﬁne the generalized cone
) be the set of all rays
(
M
emanating from the origin 0 and passing through
. It was proved in [7] (see also [11, 12, 13, 8])
that for a 3-dimensional Brownian motion B and any compact set

) the principle eigenvalue for Laplace-Beltrami operator on

in the interior of

M

M

M

M

C

) for all 0 6 s 6 t)

√λ(
x
k

≍ k

)+1/4/2t−

√λ(

M

M

)+1/4/2 for all x

where

means the lhs and the rhs are up to a constant. Furthermore, we have

M

f

) for all 0 6 s 6 t) 6 C

√λ(
x
k

Mk

)+1/4/2t−

√λ(

M

)+1/4/2 for all x

M

M

),

(
M

(7.16)

∈ C

f
(
M

∈ C

),

(7.17)

(
M

Px(Bs ∈ C
≍
Px(Bs ∈ C

(
M

PERSISTENCE FOR AR

29

where C
M
we deﬁne
x
MΛ =
{
It is clear that

∈

is a constant depending only on

. In view of the preceding estimates and Lemma 7.3,

M

S2 : c0x1 + φ( 1
√2

[x2, x3]T ) > 0
,
}

MΛ,ε =
MΛ, so we have (see, e.g., [9])
→ε
→
Applying Lemma 7.3, (7.16) and (7.17), sending ε

MΛ,ε converges to

MΛ,ε)

x
{

0 λ(

λ(

∈

MΛ) .
0 and with (7.18) we obtain that

→

(7.18)

(7.19)

pN = N −

√λ(

MΛ)+1/4/2+o(1) , where o(1)

→N

→∞

0 .

S2 : c0(1 + ε)x1 + φ( 1
√2

[x2, x3]T ) > 0
}

.

This establishes the existence of the power decay for the persistence probability. In what follows,
Q, then for
we address the continuity and discontinuity issues for the power. First consider θ/2π
Q denote by Λℓ the zero set of Qℓ and by θℓ the angle of the complex zero in
any sequence Qℓ →
Λℓ. We have

6∈

φ(ℓ)(t)

φ(t) =

t
−k

k2 ,

→

→∞

K (t) and φ(ℓ)
φ(ℓ)

where φ(ℓ)(t) = limK
This implies that
continuity of the power follows.

K is deﬁned as in (6.8) but with respect to θℓ (instead of θ).
MΛ). Combined with (7.19), the
MΛℓ → MΛ, thereby yielding λ(
Q. We see that φ(ℓ)(t) =
Q. Take Qℓ →
for
Next, we consider θ/2π
∈
6∈
all ℓ while we have φ(t) >
t
for almost surely all t
MΛ ⊂ MΛℓ and
k
−k
MΛℓ \ MΛ is lower bounded by a positive number for all ℓ. By [9,
the Lebesgue measure of the set
Theorem 2.4], we deduce that limℓ
MΛ. Combined with (7.19), the discontinuity of
the power follows.

MΛℓ )
Q such that θℓ/2π

R2. This implies that

MΛℓ ) < λ

t
k

→∞

→

λ(

λ(

∈

k

We collect here elementary facts from linear algebra and analysis that we use in this paper.

Appendix A. Elementary facts

Lemma A.1. Fix 0 < θ < 2π and k > 0. There exists a constant C <

such that for all θ0 ∈

∞

R,

(A.1)

Proof. We ﬁrst consider the case θ0 = 0, in which obviously the lemma holds for θ = π, and thus
we assume in what follows θ

= π. Because

n
i=1 cos(iθ + θ0)ik

|

6 Cnk , for all n

N .

∈

|
P

sin θ

n
i=1 cos(iθ)ik = 1
2

n
i=1(sin((i + 1)θ)

= 1

P
2 (nk sin(θ(n + 1)) +

n
P

sin(iθ)((i

1)k

−

Xi=1

−

−

sin((i

−

1)θ))ik

n

(i + 1)k)) = O(nk) +

O(ik

−

1) = O(nk) ,

(A.2)

Xi=1

dividing both sides by sin θ completes the proof of this case. With the similar argument we can see
that

Expanding cos(iθ + θ0) as cos(θ0) cos(iθ)
P

−

n
i=1 sin(iθ)ik = O(nk).

(A.3)
sin(θ0) sin(iθ), (A.1) is implied by (A.2) and (A.3). (cid:3)

Lemma A.2. Consider a polynomial P (z) = z2 + bz + c with b2
R+ such that
ﬁnite n0 and b0, . . . bn0 ∈

n0
k=0 bkzkP (z) is a non-negative polynomial.

−

4c < 0. Then, there exists a

P

6
30

A. DEMBO, J. DING, AND J. YAN

Proof. Let b0 = 1, b1 =

n

b/c, and bk =

−

bbk

1+bk
c

−

2

−

−

for k > 2. It is straightforward to verify that

Qn(z) △=

bkzkP (z) = c + (bn

1 + bbn)zn+1 + bnzn+2 = Qn

1(z) + bnznP (z) .

(A.4)

−

−

Xk=0
k : bk 6 0
1. Recalling that c > 0, it follows from (A.4) that
Let τ = min
}
{
bτ czτ , having all terms non-negative. Thus, it remains to show that
Qn0(z) = c + bn0zn0+2
. By our assumption that b2 < 4c, we see that the polynomial cx2 + bx + 1 has two conjugate
τ <
zeroes, for which we denote by λ and ¯λ. A standard analysis on our recursive procedure on bk
yields that

and n0 = τ

∞

−

−

bk = a1λk + a1¯λk = 2Re(a1λk) ,

where a1 and a2 are determined by the boundary conditions b0 = 1 and b1 =
it is clear that τ <

, as desired.

∞

b/c. Since λ

−

C

R,
(cid:3)

\

∈

The next corollary is an immediate consequence of Lemma A.2.

Corollary A.3. Suppose that a polynomial Q(z) has no positive zero. Then, there exists a non-
negative polynomial P (z) such that Q(z)P (z) is also a non-negative polynomial.

k
i=1(z + ai)

n
i=1(z2 + biz + ci) such that ai > 0 and
Proof. By assumption, we can write Q(z) =
b2
i < 4ci for all i. By Lemma A.2, for each i there exists non-negative polynomial Pi(z) such that
n
Pi(z)(z2 + biz + ci) has non-negative coeﬃcients for all terms. Letting P (z) =
i=1 Pi(z), we have
k
(cid:3)
Q(z)P (z) =
i=1(z + ai)
Lemma A.4. Given distinct θ1, . . . , θℓ ∈
Q
with the constraint that γj ∈ {

n
i=1(Pi(z)(z2 + biz + ci)) is non-negative, as required.
Q

(0, π], there exists K > 0 such that for any (rj, γj)j=1,...,ℓ

if θj = π, there exists 0 6 i 6 K such that

0, π

Q

Q

Q

}
ℓ

Xj=1

rj cos(iθj + γj) 6

1
4

−

max
j

.

rj|
|

ℓ

Proof. Write αi :=
and belong to (0, π], we can apply Lemma A.1 and see that there exists a constant C <
that for all K

j=1 rj cos(iθj + γj) and r := maxj |

. Due to the fact that θj’s are distinct
such

rj|

N,

P

∞

∈

αi 6 Crℓ,

K

Xi=0

cos(2iθj + 2γj) 6 Cℓ, for those θj 6

= π,

K

ℓ

Xi=0

Xj=1

K

(cos(i(θj1 ±

Xi=0

θj2) + γj1 + γj2)) 6 C for all j1, j2 ∈ {
K
i=0 cos(2iθj + 2γj) = K + 1. Choosing K = 12ℓ2(C

1, ..., ℓ

}

with j1 6

= j2.

(A.5)

1)2, by (A.5) and

∨

Note that if θj = π then
direct expansion we have

P
(rj cos(iθj + γj))2 +

K

ℓ

K

α2

i =

i=0
X

j=1
X

i=0
X

K

=j2
Xj1

i=0
X

(rj1 cos(iθj1 + γj1 )(rj2 cos(iθj2 + γj2 )

6
PERSISTENCE FOR AR

31

K

>

r2
j
2

i=0
=r
rj|
X|
X
+ cos(i(θj1 −
K
C)r2
> (
2 −

(1 + cos(2iθj + 2γj))

θj2 ) + γj1 −
Cℓ2r2 >

−

γj2 ))
K
3

r2.

r2
2

−

K

=j2
Xj1

i=0
X

(cos(i(θj1 + θj2 ) + γj1 + γj2 )

Combined with the fact that
the lemma easily follows.

P

K
i=0 αi 6 Crℓ, with the method of contradiction, the conclusion of
(cid:3)

Lemma A.5. Let θj’s, θj,k’s be within [0, 2π) such that θλj1 ,k =
if λ = 0 or π, and let real cj1,k’s satisfy cj1,k = cj2,k if θj1 =
−
−→S j,n+s,k, s
depending only on θj’s, cj,k’s, θj,k’s and m′, such that for any
{
[Sj,n+s,k, S′j,n+s,k] and

θλj2 ,k if θj1 =

θj2, θλ,j = 0
−
θj2. There exist M and C > 0
with −→S j,n+s,k :=

−

N

∈

}

for

−→S j,n+s,k =

Rθj

s (

k

(cid:0)

(cid:1)

Xi=0

Ps(k

i)Rθj,k−

−

θj,i−→S j,n,i)

Ps(x) :=

s

−

1 + x
x

,

(cid:19)

(cid:18)

there exists s

1, ..., M

∈ {

}

such that

ℓ

mj −

1

cj,kSj,n+s,k 6

ℓ

mj −

1

C

−

||

cj,k−→S j,n,k||
.

(A.6)

(A.7)

(A.8)

Xj=1

Xj=1

Xk=0
Xk=0
for some
Proof. It suﬃces to upper bound the left hand side of (A.8) by
C ′ depending only on θj’s, cj,k’s, θj,k’s and m′. We use induction on m′ = maxj>1 mj to show
θj2 then cj1,kSj1,n+s,k = cj2,kSj2,n+s,k. Thus we can just
this. By our condition on cj,k’s, if θj1 =
consider those θj’s
(0, π]. Due to Ps(1) = 1 for all s, it is easy to see that when m′ = 1 this
lemma is implied by Lemma A.4. Assume that the lemma holds for m′ −
2, if mj = m′

−→S j,n,k||
||

1. Deﬁne

mj −
k=0

ℓ
j=1

C ′

P

P

−

−

∈

1

⋆
j,n,k, =

−→S

−→S j,n,k+1for k = 0, ..., mj −

−→S j,n,k, if mj < m′

(

,

and similarly deﬁne −→S ⋆
deﬁnition of −→S ⋆
1, ..., M ′}
s

∈ {

j,n+s,k by relation (A.6) for s

j,n,k, we can ﬁnd M ′ and C ′′ > 0 such that for any
such that

∈

Z+. Then by induction for m′ −
−→S j,n+s,k, s
{

Z+

∈

, there exists
}

1 and the

mj −

1

cj,kSj,n+s,k +

mj −

1

cj,kSj,n+s,k

j:mj=m′}
X{

Xk=1

6

−

C ′′(

mj −

1

−→S j,n,k||
||

+

j:mj <m′}
X{

Xk=0

mj −

1

j:mj=m′}
X{

Xk=1

j:mj<m′}
X{

Xk=0

−→S j,n,k||
).
||

(A.9)

6
A. DEMBO, J. DING, AND J. YAN

32

Thus if

j:mj =m′
X{

−→S j,n,0

6

C′′(

j:mj =m′

{

}

P

1

mj −
k=1
||
4 (ℓ maxj{
P

−→S j,n,k||
cj,0}

+

{

j:mj <m′
}
C′′)

∨

PM ′ (m′)
P

1

mj−
k=1

−→S j,n,k||

)

||

,

(A.10)

P

by (4.13) and (A.9) it is easy to verify that this lemma holds by letting C ′ = C ′′/4. Now we consider
the case when (A.10) doesn’t hold. By Lemma A.4 we see that there exist M ′′ and C ′′′ > 0 such
that for any K1 ∈

Z+ we can always ﬁnd s

with

∈ {
cj,m′+1[1, 0](Rθj )sRθj,m′ −

K1, ..., K1 + M ′′}
θj,1−→S j,n,0 <
C ′′′

−

} (cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)

j:mj=m′}
X{

−→S j,n,0

.

(A.11)

j:mj=m′} (cid:13)
(cid:13)
X{
(cid:13)
(cid:13)
(cid:13)
(cid:13)
for any k < m′. Thus by (A.6)
as s
Z+ only depending on M ′ and cj,k’s such

→ ∞

Note that from (A.7) we have that Ps(m′)/Ps(k)
and the fact that (A.10) doesn’t hold, there exists K
that when s > K

→ ∞
∈

ℓ
j=1

cj,m′+1(Rθj )sRθj,m
Choosing K1 = K, then by (A.11) and (A.12) we can always ﬁnd s

cj,k−→S j,n+s,k −

j:mj =m′

P

P

P

||

mj −
k=0

{

1

′

−

Ps(m′)

{
P
Ps(m′)

j:mj =m′

}

−→S j,n,0
(cid:13)
(cid:13)
(cid:13)

}

(cid:13)
(cid:13)
(cid:13)

ℓ

mj −

1

cj,kSj,n+s,k 6

3
4

−

Ps(m′)C′′′

−→S j,n,0

<

C1

>

4
C′′′

.

θj,1−→S j,n,0||
K1, ..., K1 + M ′′}

∈ {
ℓ

mj −

1

−→S j,n,k||

,

||

−

(A.12)

such that

Xk=0

j=1
X

j:mj =m′
X{
for some C1 > 0, where the rightmost inequality is again by the fact that (A.10) doesn’t hold.
(cid:3)
Letting M = M ′ ∨
Lemma A.6. For a polynomial P , let Λ be its zero set and for λ
of the eigenvalue λ. Deﬁne an ℓ

Λ denote by m(λ) the multiplicity

M ′′, the proof is completed.

ℓ matrix A = A(P ) by

} (cid:13)
(cid:13)
(cid:13)

j=1
X

Xk=0

(cid:13)
(cid:13)
(cid:13)

∈

×

A1,j = aj for 1 6 j 6 ℓ; Ai,i
vλ,j : λ
Then there exist a basis
{
tors of A such that for any x =

Λ and j = 1, . . . , m(λ)
}

m(λ)
j=1 cλ,jvλ,j, we have

Λ

∈
λ

∈

−

1 = 1 for 2 6 i 6 ℓ; Ai,j = 0 otherwise.

(A.13)
in RL which contains all the eigenvec-

P
Anx =

m(λ)
P

m(λ)

−

r

Λ
Xλ
∈

Xr=1

Xj=0 (cid:18)

λn

−

jcλ,r+jvλ,r .

n
j

(cid:19)

(A.14)

∈

−

6∈
ker(A

= 0 we know that 0

λI) implies that xk = λ−

Λ. Also, the special form of A results with each λ

Furthermore, we have ¯vλ,j = v¯λ,j and ¯cλ,j = c¯λ,j.
Proof. With aL 6
Λ having
geometric multiplicity one (as x
1).
Recall that A = VJV−
1, with J the Jordan normal form of A, consisting here of one (maximal)
Λ. Speciﬁcally, the block Jλ △= λI + N (m(λ)) with nilpotent
block of dimension m(λ) per λ
∈
1 such that N r(m) = 1k=i+r for i = 1, . . . , m
r for 1 6 r 6 m.
Ni,k(m) = 1k=i+1 for i = 1, . . . , m
−
The columns of V =
are such that vλ,1 is the eigenvector of A for
vλ,j : j = 1, . . . , m(λ), λ
{
1 for j = 2, . . . , m(λ). It is easy to verify that the power Jn
λI)vλ,j = vλ,j
eigenvalue λ and (A
−
of such a Jordan normal form consists of block diagonal upper-triangular matrices of dimension
n
m(λ), where Jn
r. Thus,
j
−
Anx = VJn(V−
1x = [cλ,j]λ
Λ,16j6m(λ). This then
∈
(cid:3)
completes the proof of the lemma.Before the proof we need the following lemma.

j at positions (r, r + j) for 1 6 r 6 m(λ) and 1 6 j 6 m(λ)

λn
λ =
−
1x), so writing x =

λ,j cλ,jvλ,j, we have that V−

1xk+1 for k = 1, . . . , L

Λ
}

−

−

∈

∈

(cid:1)

(cid:0)

−

P

PERSISTENCE FOR AR

33

Lemma A.7. Assume L > m > 0. Then there exists a C > 0, such that for any polynomial
1/L, 2/L, ..., 1
g(x) =
}

m
j=0 cj+1xj, we can ﬁnd a y
−

such that

∈ {

1

P

g(y)
|
|

> C max

16j6m |

.
cj|

Proof. For any i
δij. Therefore we have that

∈

[m], we can ﬁnd ai,k, k = 1, 2, ..., L, such that for j

L

L
k=1 ai,k(k/L)j

1 =

−

[m],

∈

P

(A.15)

ai,kg((k

−

1)/L) = ci.

Xj=1

Denote by M := max16i,k6m |
obviously we can ﬁnd y

ai,k|
1/L, 2/L, ..., 1
}

. wlog we assume that ci+1 = max16j6m |
g(y)
|

> max16j6m |

such that

cj|
/(LM ).

cj|

|

∈ {

, thus by (A.15)
(cid:3)

References

[1] F. Aurzada and C. Baumgarten. Survival probabilities of weighted random walks. ALEA Lat. Am. J. Probab.

Math. Stat., 8:235–258, 2011.

[2] F. Aurzada and S. Mukherjee. Persistence exponents in markov chains. arXiv:1703.06447, 2017.
[3] F. Aurzada and T. Simon. Persistence probabilities and exponents. Levy matters V, Lecture Notes in Math.

2149, pages 183–221, 2015.

[4] Frank Aurzada and Nadine Guillotin-Plantard. Persistence exponent for discrete-time, time-reversible processes.

arXiv preprint arXiv:1502.06799, 2015.

[5] Frank Aurzada and Marvin Kettner. Persistence exponents via perturbation theory: Ar (1)-processes. arXiv

preprint arXiv:1810.09861, 2018.

[6] Frank Aurzada, Sumit Mukherjee, and Ofer Zeitouni. Persistence exponents in markov chains. arXiv preprint

arXiv:1703.06447, 2017.

[7] R. Ba˜nuelos and R.G. Smits. Brownian motion in cones. Probab. Theory Related Fields, 108(3):299–319, 1997.
[8] R. Bass and K. Burdzy. Eigenvalue expansions for Brownian motion with an application to occupation times.

Electron. J. Probab., 1:no. 3, approx. 19 pp. (electronic), 1996.

[9] H. Berestycki, L. Nirenberg, and S.R.S. Varadhan. The principal eigenvalue and maximum principle for second-

order elliptic operators in general domains. Comm. Pure Appl. Math., 47(1):47–92, 1994.

[10] P.J. Brockwell and R.A. Davis. Time series: theory and methods. Springer Series in Statistics. Springer, New

York, 2006. Reprint of the second (1991) edition.

[11] D.L. Burkholder. Exit times of Brownian motion, harmonic majorization, and Hardy spaces. Advances in Math.,

26(2):182–205, 1977.

[12] R.D. DeBlassie. Exit times from cones in Rn of Brownian motion. Probab. Theory Related Fields, 74(1):1–29,

1987.

[13] R.D. DeBlassie. Remark on: “Exit times from cones in Rn of Brownian motion”. Probab. Theory Related Fields,

79(1):95–97, 1988.

[14] A. Dembo, J. Ding, and F. Gao. Persistence of iterated partial sums. Ann. Inst. H. Poincar´e Probab. Statist.,

49(3):873–884, 2013.

[15] A. Dembo and S. Mukherjee. No zero-crossings for random polynomials and the heat equation. Ann. Probab.,

43(1):85–118, 2015.

[16] GCMA Ehrhardt, Satya N Majumdar, and Alan J Bray. Persistence exponents and the statistics of crossings

and occupation times for gaussian stationary processes. Physical Review E, 69(1):016106, 2004.

[17] N. Feldheim and O. Feldheim. Long gaps between sign-changes of gaussian stationary processes. Int. Math. Res.

Notices, pages 3021–3034, 2015.

[18] Naomi Feldheim, Ohad Feldheim, Benjamin Jaye, Fedor Nazarov, and Shahaf Nitzan. On the probability
that a stationary gaussian process with spectral gap remains non-negative on a long interval. arXiv preprint
arXiv:1801.10392, 2018.

[19] Naomi Feldheim, Ohad Feldheim, and Shahaf Nitzan. Persistence of gaussian stationary processes: a spectral

perspective. arXiv preprint arXiv:1709.00204, 2017.

34

A. DEMBO, J. DING, AND J. YAN

[20] M. Krishna and M. Krishnapur. Persistence probabilities in centered, stationary, gaussian processes in discrete

time. Indian Journal of Pure and Applied Mathematics, pages 183–194, 2016.

[21] W.V. Li. A Gaussian correlation inequality and its applications to small ball probabilities. Electron. Comm.

Probab., 4:111–118 (electronic), 1999.

[22] Michael Selwyn Longuet-Higgins. The distribution of intervals between zeros of a stationary random func-
tion. Philosophical Transactions of the Royal Society of London. Series A, Mathematical and Physical Sciences,
254(1047):557–599, 1962.

[23] G.F. Newell and M. Rosenblatt. Zero crossing probabilities for gaussian stationary processes. Ann. Math. Statist.,

pages 1306–1313, 1962.

[24] Stephen O Rice. Mathematical analysis of random noise. Bell System Technical Journal, 24(1):46–156, 1945.
[25] T. Royen. A simple proof of the gaussian correlation conjecture extended to some multivariate gamma distribu-

tions. Far East J. Theor. Stat., 48:139–145, 2014.

[26] G. Schechtman, Th. Schlumprecht, and J. Zinn. On the Gaussian measure of the intersection. Ann. Probab.,

26(1):346–357, 1998.

[27] G. Schehr and S.N. Majumdar. Real roots of random polynomials and zero crossing properties of diﬀusion

equation. J. of Stat. Phys., 132(2):253–273, 2008.

[28] D. Slepian. The one-sided barrier problem for Gaussian noise. Bell System Tech. J., 41:463–501, 1962.

⋆Department of Mathematics, Stanford University, Building 380, Sloan Hall, Stanford, CA 94305,

USA

†Department of Statistics, Wharton, 3730 Walnut St, Philadelphia, PA 19104, USA

‡Department of Statistics, Stanford University, Sequoia Hall, Stanford, CA 94305, USA

