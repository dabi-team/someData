9
1
0
2

v
o
N
2

]
E
M

.
t
a
t
s
[

1
v
2
0
7
0
0
.
1
1
9
1
:
v
i
X
r
a

Bayesian inference for dynamic vine copulas in
higher dimensions

Alexander Kreuzer ∗

Claudia Czado

Zentrum Mathematik, Technische Universit¨at M¨unchen

March 21, 2022

Abstract

We propose a class of dynamic vine copula models. This is an extension of static vine
copulas and a generalization of dynamic C-vine and D-vine copulas studied by Almeida
et al (2016) and Goel and Mehra (2019). Within this class, we allow for time-varying
dependence by driving the vine copula parameters with latent AR(1) processes. This
modeling approach is very ﬂexible but estimation is not straightforward due to the high-
dimensional parameter space. We propose a Bayesian estimation approach, which relies
on a novel approximation of the posterior distribution. This approximation allows to use
Markov Chain Monte Carlo methods, such as elliptical slice sampling, in a sequential way.
In contrast to other Bayesian sequential estimation procedures for vine copula models as
proposed by Gruber and Czado (2015), there is no need to collapse copula parameters to
point estimates before proceeding to the next tree. Thus more information and uncertainty
is propagated from lower to higher trees. A simulation study shows satisfactory perfor-
mance of the Bayesian procedure. This dynamic modeling and inference approach can be
applied in various ﬁelds, where static vine copulas have already proven to be successful,
including environmental sciences, medicine and ﬁnance. Here we study the dependence
among 21 exchange rates. For comparison we also estimate a static vine copula model and
dynamic C-vine and D-vine copula models. This comparison shows superior performance
of the proposed dynamic vine copula model with respect to one day ahead forecasting
accuracy.

Keywords: vine copula, ﬁnancial time series, time-varying parameters, Bayesian inference

1 Introduction

Appropriate models for dependence are crucial in many areas. For example, the risk of a
portfolio, consisting of several ﬁnancial assets, is inﬂuenced by the dependence among those
assets (Embrechts et al (2002)). The multivariate normal distribution is often not suﬃcient to
describe complex dependence structures. It does not allow for tail dependence or asymmetry
in the tails. A more ﬂexible framework is provided by copulas. Sklar’s theorem (Sklar (1959))
states that any multivariate distribution can be decomposed into its marginal distributions and
the corresponding copula. So the modeling process can be divided into two parts: the marginals
and the dependence model. After modeling the margins we can focus entirely on the dependence
structure, i.e. on ﬁnding an appropriate copula model. In higher dimensions, the class of vine
copulas (Bedford and Cooke (2001), Aas et al (2009), Czado (2019)) is especially useful. Vine
copulas are constructed from bivariate copula models. These bivariate copula models can
be chosen individually from diﬀerent classes of copulas, such as elliptical and Archimedean
copulas. Due to their ﬂexibility, vine copula models have gained huge popularity. They have
been successfully applied in many ﬁelds, including environmental sciences (Erhardt et al (2015),
M¨oller et al (2018)), medicine (Barthel et al (2018)) and ﬁnance (Brechmann and Czado (2013),
Aas (2016), St¨ubinger et al (2018)).

∗Corresponding author: a.kreuzer@tum.de, Boltzmannstr. 3, 85748 Garching b. M¨unchen, Germany

1

 
 
 
 
 
 
Although in many of these applications it is assumed that the dependence does not change
over time, this assumption is often not appropriate. For example, there is evidence that the cor-
relations between the returns of stocks and bonds change over time (Baele et al (2010)). Popular
models for ﬁnancial data that account for dynamic dependence are multivariate GARCH mod-
els with time-varying correlations, such as the DCC-GARCH (Engle (2002)) and multivariate
factor stochastic volatility models (Harvey et al (1994), Pitt and Shephard (1999), Kastner et al
(2017)). But these models again rely (conditionally) on multivariate normal distributions. New
models have been proposed to overcome the shortcomings of the multivariate normal distribu-
tion and to allow for more ﬂexible time-varying dependence structures. One example for such
a model is the dynamic copula model of Oh and Patton (2018). Another approach to construct
dynamic dependence models in higher dimensions is to extend the ﬂexible class of vine copulas.
As already mentioned above, vine copulas are constructed from bivariate copulas. So the vine
copula framework allows us to scale dynamic bivariate copula models to arbitrary dimensions.
Acar et al (2019) use nonparametric smoothing techniques to allow for time-variation in bivari-
ate copula models and extend this bivariate approach to higher dimensions using vine copulas.
Vatter and Chavez-Demoulin (2015) propose a bivariate copula model, where the copula pa-
rameters depend on covariates through generalized additive models. Using the vine copula
framework, this bivariate model is extended to higher dimensions by Vatter and Nagler (2018).
Similarly the bivariate dynamic copula model as proposed by Almeida and Czado (2012) and
Hafner and Manner (2012) is extended to dynamic D-vine copulas by Almeida et al (2016) and
later to dynamic C-vine copulas by Goel and Mehra (2019).

The bivariate dynamic copula model of Almeida and Czado (2012) provides a ﬂexible build-
ing block by modeling time-varying dependencies with latent AR(1) processes. However, esti-
mation is no longer straightforward since the likelihood involves high-dimensional integration.
Goel and Mehra (2019) follow Almeida et al (2016), who use a frequentist estimation approach
with approximation of the likelihood utilizing eﬃcient importance sampling (Richard and Zhang
(2007)). In this approach, parameters are estimated sequentially tree by tree. For estimating
parameters of higher trees, the parameters of lower trees are ﬁxed at point estimates. Thus un-
certainty of parameters in lower trees is ignored and therefore uncertainty quantiﬁcation cannot
be provided.

The paper contains two major contributions: So far dynamic vine copula models, as gener-
alization of the dynamic bivariate copula model of Almeida and Czado (2012), were restricted
to D-vine (Almeida et al (2016)) and C-vine (Goel and Mehra (2019)) structures. First we
develop an approach to allow for general regular vine tree structures. D-vine structures are
especially suited to describe temporal dependence. But when it comes to cross-sectional depen-
dence structures, such as the dependence among several stocks, the D-vine structure might be
too restrictive. General regular vine tree structures are more ﬂexible and include C-vine and
D-vine structures as special cases.

Second, we present a novel Bayesian estimation approach. To our knowledge Bayesian
estimation of vine copula models, including structure selection, was only tackled by Gruber
and Czado (2015) and Gruber and Czado (2018). These approaches only allow for static pair
copulas and have not been applied in more than 10 dimensions, while our approach allows for
static as well as dynamic pair copulas and can handle higher dimensions.

Our methodology is based on an approximation of the posterior distribution. Approxima-
tions to the posterior are also used in variational Bayesian inference (Wainwright et al (2008))
and have become popular since they make estimation feasible in high-dimensional settings.
Variational Bayesian approaches assume that the posterior distribution belongs to some fam-
ily of distributions, such as the multivariate normal distribution. Our approach does not rely
on such an assumption. We propose an approximation, which uses ideas of the frequentist
sequential procedure of Dissmann et al (2013) and which allows to estimate pair copulas of
one tree independently of each other using Markov Chain Monte Carlo (MCMC) schemes de-
veloped in Kreuzer and Czado (2019). The MCMC schemes rely on elliptical slice sampling
(Murray et al (2010)) to exploit the underlying autoregressive dependence structure and on an
ancillarity-suﬃciency interweaving strategy (Yu and Meng (2011)). The posterior approxima-
tion also enables the user to run several MCMC chains in parallel leading to faster computation
and making the approach applicable to higher dimensions than the approach of Gruber and
Czado (2018). Further our Bayesian approach includes pair copula family selection based on

2

a set of candidate families. Here we exploit the fact that for several copula families, there is
a one-to-one correspondence between the copula parameter and Kendall’s τ . This allows to
share the Kendall’s τ parameter among diﬀerent copula families, which reduces the parameter
space and simpliﬁes estimation. Additionally, our approach also contributes to the selection of
sparse models by assessing, whether a pair copula term needs to be modeled dynamically or
not. For this the information criteria of Watanabe (2010) is adapted. Another advantage of
our Bayesian approach is that it is not necessary to ﬁx copula parameters at point estimates
although our procedure is sequential. Uncertainty of parameter estimates and information in
lower trees is no longer ignored, but propagated as we move up to higher trees in the estimation
procedure. All ideas are investigated through simulation and illustrated with real data.

The outline of the paper is as follows: Section 2 discusses the bivariate building blocks that
are needed to construct the dynamic vine copula model. We introduce dynamic and static
building blocks and show how to select among them. The selection procedure is illustrated
with a small simulation study. Section 3 introduces the dynamic vine copula model and a novel
algorithm for parameter estimation. The performance of the estimation procedure is evaluated
with simulated data. In Section 4 we model the dependence among 21 exchange rates. Within
this application, we compare the predictive accuracy of the proposed dynamic vine copula model
to competitor models: a static vine copula, a dynamic C-vine copula and a dynamic D-vine
copula. We conclude with providing ideas for future research in Section 5.

2 Bivariate building blocks for the dynamic vine copula

model

The dynamic vine copula model, we introduce in Section 3, relies on dynamic and static bivariate
copula models. These bivariate models are introduced in Sections 2.1 and 2.2. Section 2.3
discusses selection among diﬀerent bivariate copula models.

2.1 Dynamic bivariate copulas

Model speciﬁcation

We extend the (time-) dynamic bivariate copula model introduced by Almeida and Czado
(2012) and Hafner and Manner (2012) by a model indicator m to allow for Bayesian copula
family selection. We consider a set M of single-parameter copula families for which there is a
one-to-one correspondence between the copula parameter and Kendall’s τ . The mapping from
the copula parameter to the corresponding Kendall’s τ is denoted by gm(·) depending on the
copula family m ∈ M, e.g. for the Gumbel copula it holds that gGumbel(θ) = 1 − 1
θ . It is more
convenient to work with the corresponding values of Kendall’s τ , since parameters of diﬀerent
families may live on diﬀerent domains and may posses diﬀerent interpretations. Further, we
transform Kendall’s τ , which is restricted to the interval (−1, 1), to the unconstrained scale
using the Fisher’s Z transformation FZ(x) = 1
2 log
. The transformed Kendall’s τ at time
t is denoted by st and its dynamics is modeled by an AR(1) process. More precisely, the AR(1)
process with states s0, . . . , sT , mean µ ∈ R, persistence parameter φ ∈ (−1, 1) and standard
deviation parameter σ ∈ (0, ∞) satisﬁes

(cid:16) 1+x
1−x

(cid:17)

st = µ + φ(st−1 − µ) + σηt

(1)

for t = 1, . . . , T . Here we assume that the errors are ηt ∼ N (0, 1) iid and the initial distribution
t of the copula family
is s0|µ, φ, σ ∼ N
m at time t as follows

. The state st is mapped to the parameter θm

µ, σ2
1−φ2

(cid:17)

(cid:16)

m (F −1
(2)
We now study the following model for T bivariate random vectors (Ut1, Ut2)t=1,...,T ∈ [0, 1]T ×2

t = g−1
θm

Z (st)).

(Ut1, Ut2)|m, st ∼ cm(ut1, ut2; θm

t ) independently,

(3)

for t = 1, . . . , T . Here cm(·, ·; θm
as speciﬁed in (1) and (2). The copula parameter θm
t

t ) is the bivariate density of copula family m with parameter θm
t
is a function of the model indicator m and

3

the state st. The state st has the same interpretation for diﬀerent copula families as the Fisher’s
Z transform of the corresponding Kendall’s τ value. This allows us to share the parameters
s0:T = (s0, . . . , sT ), µ, φ, σ among diﬀerent copula families, which keeps the parameter space
smaller and simpliﬁes estimation. More details about parameter sharing are given in Appendix
A.

A Bayesian model speciﬁcation is complete by introducing priors for the model parameters.
N ormal) denote the density of the univariate normal distribution with mean
N ormal. This allows us to express the prior for s0:T conditional on µ, φ

Let ϕ(·|µN ormal, σ2
µN ormal and variance σ2
and σ, implied by the AR(1) process in (1), as

π(s0:T |µ, φ, σ) = ϕ(s0|µ, σ2(1 − φ2)−1)

T
(cid:89)

t=1

ϕ(st|µ + φ(st−1 − µ), σ2).

(4)

Further, we assume that

µ ∼ N (0, 100),

φ + 1
2

∼ Beta(5, 1.5), σ2 ∼ Gamma

(cid:19)

(cid:18) 1
2

,

1
2

(5)

as in Kreuzer and Czado (2019). These are the same priors that Kastner (2016) recommend
for the latent AR(1) process of the stochastic volatility model. For µ we utilize a vague prior.
But for φ we use a rather informative prior, which gives more prior probability to larger values
within (−1, 1). Thus we favor trajectories of Kendall’s τ , where there is positive dependence
among two subsequent time points (cor(st, st−1) = φ). The Gamma prior for the variance
parameter σ2 is diﬀerent to the frequently used inverse Gamma prior. The Gamma prior has
more mass close to zero compared to the inverse Gamma prior. So we give more probability
to smoother trajectories that do not oscillate a lot. For m ∈ M we assume a discrete uniform
prior, i.e.

π(m) =

.

(6)

1
|M|

We further assume prior independence among the parameters µ, φ, σ and m.

Bayesian inference

Model selection procedures often have to deal with model speciﬁc parameters. They might
have diﬀerent dimensions. A popular approach in this context is reversible jump MCMC (see
Green (1995)), which requires dimension matching. Min and Czado (2011) and Gruber and
Czado (2015) use reversible jump MCMC for selection among vine copula models, while Tan
et al (2019) apply it for model selection among static single factor copula models. The way
we constructed our model, dimension matching is not needed, since we share the parameters
s0, . . . , sT , µ, φ and σ among diﬀerent models. This allows us to use an eﬃcient Gibbs approach
as outlined in the following.

Here the likelihood given the data U = (ut1, ut2)t=1,...,T can be expressed as

(cid:96)(µ, φ, σ, s0:T , m|U ) =

T
(cid:89)

t=1

(cid:96)t(st, m|ut1, ut2) =

T
(cid:89)

t=1

cm(ut1, ut2; θm

t ).

(7)

The quantity (cid:96)t(st, m|ut1, ut2) = cm(ut1, ut2; θm
and θm

t = g−1

m (F −1

Z (st)).

t ) is the contribution to the likelihood at time t

We now employ a Gibbs sampler for parameter estimation. The indicator m is sampled

from its full conditional, given by

P (m|U, µ, φ, σ, s0:T ) =

f (U |µ, φ, σ, s0:T , m)π(µ, φ, σ, s0:T )π(m)
m(cid:48)∈M f (U |µ, φ, σ, s0:T , m(cid:48))π(µ, φ, σ, s0:T )π(m(cid:48))

(cid:80)

=

(cid:80)

=

(cid:80)

(cid:96)(µ, φ, σ, s0:T , m|U )
m(cid:48)∈M (cid:96)(µ, φ, σ, s0:T , m(cid:48)|U )
t=1 cm(ut1, ut2; θm
t )
(cid:81)T

(cid:81)T

t=1 cm(cid:48)(ut1, ut2; θm(cid:48)
t )

m(cid:48)∈M

(8)

,

4

where π(µ, φ, σ, s0:T ) = π(s0:T |µ, φ, σ)π(µ)π(φ)π(σ) and π(·) as speciﬁed in (4), (5) and (6).
Here the presence of the shared parameters simpliﬁes the updates of the copula family indicator
m considerably. To sample µ, φ, σ, s0:T conditioned on the indicator m, we use the same
approach as described in Kreuzer and Czado (2019) for multivariate state space models with
a univariate autoregressive state equation. This sampler relies on an interweaving strategy
(Yu and Meng (2011)), elliptical slice sampling (Murray et al (2010)) and adaptive Metropolis-
Hastings updates (Garthwaite et al (2016)).

2.2 Static bivariate copulas

Model speciﬁcation

To allow for static (time-constant) copulas we consider a static state s ∈ R which is mapped to
the copula parameter similar to (2), i.e.

θm = g−1

m (F −1

Z (s))

(9)

for a copula family m ∈ M. We assume that T bivariate random vectors (Ut1, Ut2)t=1,...,T are
generated as follows

(Ut1, Ut2)|m, s ∼ cm(·, ·; θm), independently.

(10)

The prior for the state parameter s is chosen such that the corresponding Kendall’s τ is uni-
formly distributed on (−1, 1). The prior for m is chosen as above in (6). The priors reﬂect the
fact that we do not have any prior information about the parameters.

Bayesian inference

The parameters of this reduced model are also estimated utilizing a Gibbs sampling approach.
Here we sample m|U, s directly from its full conditional, which can be derived similar to (8).
The parameter s is updated conditional on (U, m) with random walk Metropolis-Hasting with
Gaussian proposal and adaptive proposal variance as in Garthwaite et al (2016).

2.3 Model selection among dynamic and static pair copulas using the

widely applicable information criteria (WAIC)

One might be interested in how the dynamic copula model compares to the static copula
model and to the independence model. We refer to these model classes as dynamic, static and
zero dependence, respectively. To also allow for bivariate static and independence copulas is
especially important, if the bivariate dynamic copula is used as a building block for vine copula
models in higher dimensions. For vine copula models, independence copulas might be useful in
higher trees to avoid overﬁtting.

Bayes factors or the commonly used information critera AIC and BIC are here not tractable
choices for selecting the type of dependence (dynamic, static or zero), since their evaluation
would require high-dimensional integration. Instead, we rely on the widely applicable informa-
tion criteria (WAIC) introduced by Watanabe (2010). For the proposed dynamic copula model
it is given by

WAIC = −2

(cid:32) T

(cid:88)

t=1

ln(E((cid:96)t(st, m|ut1, ut2))) −

Var (ln((cid:96)t(st, m|ut1, ut2)))

(11)

(cid:33)

T
(cid:88)

t=1

with (cid:96)t as in (7). The expectation and variance are taken with respect to P (st, m), the proba-
bility measure of the posterior distribution of st and m, i.e.

E((cid:96)t(st, m|ut1, ut2)) =

(cid:90)

R×M

(cid:96)t(st, m|ut1, ut2)dP (st, m)

and

Var(ln((cid:96)t(st, m|ut1, ut2))) =

(cid:90)

R×M

(ln((cid:96)t(st, m|ut1, ut2)))2dP (st, m)−(E(ln((cid:96)t(st, m|ut1, ut2))))2 .

5

The WAIC can be seen as a Bayesian version of the AIC, where (cid:80)T
is used as a penalty instead of the number of parameters.

t=1 Var(ln((cid:96)t(st, m|ut1, ut2))

For R observed quantities (xr)r=1,...,R we denote by ˆE((xr)r=1,...,R) = 1
R

r=1 xr the sam-
r=1(xr − ˆE((xr)r=1,...,R))2 the sample variance.
ple mean and by (cid:100)Var((xr)r=1,...,R) = 1
R−1
Following Vehtari et al (2017), the WAIC can be estimated from R samples of the posterior
distribution (s1

t , mR) with t = 1, . . . , T , by

(cid:80)R

(cid:80)R

t , m1), . . . , (sR
(cid:32) T

(cid:92)WAIC = −2

(cid:88)

(cid:16) ˆE(((cid:96)r
ln

t )r=1,...,R)

where (cid:96)r

t = (cid:96)t(sr

t=1
t , mr|ut1, ut2). By setting
(cid:16) ˆE(((cid:96)r
ln

(cid:92)WAICt = −2

(cid:16)

(cid:17)

−

T
(cid:88)

t=1

(cid:16)

(cid:100)Var

(ln((cid:96)r

t ))r=1,...,R

(cid:33)

(cid:17)

,

(12)

t )r=1,...,R)

(cid:17)

(cid:16)

− (cid:100)Var

(ln((cid:96)r

t ))r=1,...,R

(cid:17)(cid:17)

,

we can express (cid:92)WAIC as (cid:92)WAIC = (cid:80)T

t=1

(cid:92)WAICt.

To compare between two models with estimated WAIC values (cid:92)WAIC

A

and (cid:92)WAIC

B

, Vehtari

et al (2017) suggest to consider the diﬀerence in the estimated WAIC given by

A

(cid:92)WAIC

− (cid:92)WAIC

B

=

( (cid:92)WAICt

A

− (cid:92)WAICt

B

)

T
(cid:88)

t=1

(13)

with corresponding standard error estimate

ˆse((cid:92)WAIC

A

− (cid:92)WAIC

B

) =

(cid:113)

T · (cid:91)VAR(( (cid:92)WAICt

A

− (cid:92)WAICt

B

)t=1,...,T ).

(14)

To estimate the standard error, Vehtari et al (2017) assume independence among the compo-
nents (cid:92)WAICt, t = 1, . . . , T . For the static copula model we use (cid:96)t(s, m|ut1, ut2) = cm(ut1, ut2; θm).
Further, WAIC is zero for the independence copula. In our framework the dynamic model is
considered to be more complex than the static model. Similarly, the static and the dynamic
model are considered to be more complex than the independence model. Here, we select the
more complex model if its estimated WAIC is at least 2 standard errors smaller than the WAIC
of the other model.

Dynamic model:
(dynamic dependence)
Estimate a bivariate dynamic
copula model as explained
in Section 2.1. This procedure
includes Bayesian copula family
selection.

Data: U ∈ [0, 1]T ×2

Static model:
(static dependence)
Estimate a bivariate
static copula model as
explained in Section 2.2 .
This procedure includes
Bayesian copula family
selection.

Independence model:
(zero dependence)
Here is no estimation
required.

Select the type of dependence:
Use WAIC as explained above to select among the dynamic,
the static and the zero dependence.

Figure 1: Model selection procedure for bivariate copula models.

Alternatively we could have incorporated the independence, the static and the dynamic
copula within one sampler. In this case we would need to move between models with diﬀerent
dimensions by employing e.g. reversible jump MCMC. But proposing moves eﬃciently from the

6

parameter free independence copula or from the static copula to dynamic copulas with more
than T parameters is diﬃcult and chains might take very long to converge. Another alternative
is to select among all models, including family choices, with WAIC. But this would require to
estimate a dynamic bivariate copula model for each copula family, which is computationally
expensive. So we propose to use the Gibbs sampler to move between models with the same
dimension, where the parameters can be shared among the diﬀerent models. The WAIC is used
to select between models with diﬀerent parameter dimensions where parameters can not be
shared. The whole selection procedure for the bivariate copula models is visualized in Figure 1.

2.4 Simulation study

We conduct a small simulation study to investigate the ability of WAIC to select the type
of dependence. We consider ﬁve scenarios speciﬁed in Table 1.
In Scenarios 1 and 2 we
simulate from the dynamic model speciﬁed in (3), in Scenarios 3 and 4 from the static one
speciﬁed in (10) and in Scenario 5 from the bivariate independence copula. For each scenario
we simulate T = 1000 observations. Based on these observations we ﬁt the dynamic and the
static model and select among diﬀerent models with WAIC as explained in Section 2.3. We
consider the following set for copula family selection M = {Independence, Gaussian, Student
t(df=4), eClayton, eGumbel}. Here eClayton and eGumbel are extended Clayton and Gumbel
copulas that also allow for negative Kendall’s τ values as in Kreuzer and Czado (2019). We
repeat the simulations for each scenario 100 times. From Table 2 we see that in each scenario,
the correct type of dependence was selected at least in 84 out of 100 cases. The correct family
was selected in at least 98 out of 100 cases according to Table 2. We conclude that our Bayesian
family selection procedure performs well and that WAIC can be utilized to select the appropriate
type of dependence.

Dynamic

Static

Scenario 1

m Gaussian
0.4
µ
0.95
φ
σ
0.1
s

Scenario 2
eClayton
0.4
0.8
0.2

Scenario 3
Student t(df=4)

Scenario 4
eGumbel

1

0.4

Independence
Scenario 5
Independence

Table 1: Parameter speciﬁcation for the simulation study for bivariate copula models.

Copula family

Scenario
Independence
Gaussian
Student t(df=4)
eClayton
eGumbel
Type of dependence Dynamic

Static
Zero

Dynamic
2
0
2
0
98
0
100
0
0

1
0
100
0
0
0
100
0
0

Static
3
0
1
99
0
0
16
84
0

4
0
0
0
0
100
0
100
0

Independence
5
100
0
0
0
0
1
0
100

Table 2: For each scenario of the simulation study, we show how often the diﬀerent copula
families were selected and how often each type of dependence (dynamic, static and zero) was
selected. The selected copula family is the marginal posterior mode estimate of m, i.e. the
family that occurs most frequently among the posterior samples for m. The true copula family
and the true type of dependence, which we used for simulation, is marked in bold.

7

3 Dynamic vine copulas

3.1 Model speciﬁcation

Vine copulas (Bedford and Cooke (2001), Aas et al (2009), Joe (2014), Czado (2019)) are a
popular class in dependence modeling. They allow for great ﬂexibility by constructing a density
of arbitrary dimension from two-dimensional densities.

For this construction, vine copulas are represented as graphical models. A regular vine (R-
vine) tree sequence is a sequence of trees V = T1, . . . , Td−1 satisfying the following conditions

• each tree is connected,

• T1 is a tree with nodes N1 = {1, . . . d} and set of edges E1,

• Tj with j ≥ 2 is a tree with nodes Nj = Ej−1 and edges Ej and

• for j = 2, . . . d − 1 and {a, b} ∈ Ej, it holds that a and b as edges in tree Tj−1 share a

common node (proximity condition).

Furthermore, the complete union of an edge e ∈ Ei is deﬁned as

Ae := {j ∈ N1|∃e1 ∈ E1, . . . , ei−1 ∈ Ei−1; j ∈ e1 ∈ . . . ∈ ei−1 ∈ e}.

The conditioning set of edge e = {a, b} is obtained as

De := Aa ∩ Ab,

and the conditioned sets are given by

ae := Aa \ De, be := Ab \ De.

Bivariate copulas of conditional distributions of the marginally uniformly distributed random
vector (U1, . . . , Ud) can be identiﬁed with the conditioning and the conditioned sets. For an
edge e we denote by cae,be;De the density of the bivariate copula of (Uae Ube )|UDe = uDe ,
where uF = (ui)i∈F for a set F . Many researchers assume that cae,be;De does not depend on
uDe , which is called the simplifying assumption (Haﬀ et al (2010), Stoeber et al (2013)). This
assumption allows for sequential estimation and selection of vine copula models (Brechmann
and Czado (2013), Dissmann et al (2013)).

Based on these graphical deﬁnitions, Bedford and Cooke (2001) build a d-dimensional vine

copula model with joint density

c(u1, . . . ud) =

d−1
(cid:89)

(cid:89)

i=1

e∈Ei

cae,be;De (uae|De , ube|De ).

(15)

It is a simpliﬁed vine copula model, since cae,be;De does not depend on the conditioning value
uDe . Here, uae|De and ube|De are called pseudo data. They are obtained as uae|De =
Cae|De (uae |uDe ) and ube|De = Cbe|De (ube |uDe), where Cae|De and Cbe|De are the conditional
distribution functions of Uae|UDe = uDe and Ube |UDe = uDe, respectively. In the ﬁrst tree
De is the empty set and the pseudo data of the ﬁrst tree is just u1, . . . ud. Note that the class
of simpliﬁed vine copulas is broad, including multivariate Gaussian and Student t copulas (Joe
(2014), Chapter 3).

To evaluate the conditional distribution functions and to obtain the corresponding pseudo

data for all trees, the h functions (Aas et al (2009)) for an edge e are deﬁned as

hae|be;De (u1|u2) =

d
du2
d
du1
If the copula Cae,be;De depends on a set of parameters δ we write hae|be;De (u1|u2; δ) and
hbe|ae;De (u2|u1; δ). Based on pseudo data uae|De and ube|De , we obtain pseudo data for the
next tree as

hbe|ae;De (u2|u1) =

Cae,be;De (u1, u2).

Cae,be;De (u1, u2)

(16)

uae|be∪De = hae|be;De (uae|De |ube|De ),
ube|ae∪De = hbe|ae;De (ube|De |uae|De ).

(17)

8

So for the calculation of pseudo data only bivariate copulas from lower trees are involved.

Figure 2 visualizes the ﬁrst three trees of a six-dimensional vine copula. Assuming that
there are only independence copulas in trees higher than Tree 3, the associated density is given
by

c(u1, . . . , u6) =c12(u1, u2) · c26(u2, u6) · c36(u3, u6) · c46(u4, u6) · c56(u5, u6)

·c45;6(u4|6, u5|6) · c35;6(u3|6, u5|6) · c25;6(u2|6, u5|6) · c16;2(u1|2, u6|2)
·c3,4;5,6(u3|5,6, u4|5,6) · c2,4;5,6(u2|5,6, u4|5,6) · c1,5;2,6(u1|2,6, u5|2,6).

(18)

The pseudo data of the vine copula model can be determined as outlined in (17). E.g. u4|6 =
h4|6(u4|u6), u5|6 = h5|6(u5|u6) and u4|56 = h4|5;6(u4|6|u5|6) = h4|5;6(h4|6(u4|u6)|h5|6(u5|u6)).

Such vine copulas, where pair copulas above a certain tree level are set to the independence
copula, are called truncated (Brechmann et al (2012)). With truncation we can achieve diﬀerent
levels of sparsity.

T1

1

2

1,2

2,6

5

6

4

5,6

4,6

3,6

3

T2

4, 6

4,5;6

5, 6

3,5;6

3, 6

2,5;6

1,6;2

2, 6

1, 2

T3

3, 5; 6

3,4;5,6

4, 5; 6

2,4;5,6

2, 5; 6

1,5;2,6

1, 6; 2

Figure 2: Tree structure of a vine copula model

Within the vine copula framework, we only need to specify bivariate copulas and can scale
to arbitrary dimensions. Here, we replace each bivariate copula in (15) by the dynamic bi-
variate copula model speciﬁed in (3), the static bivariate copula model speciﬁed in (10) or the
independence copula. We denote by Edyn
, Estatic
the set of edges in the i-th tree
i
where the corresponding pair copulas are dynamic, static or independence copulas, respectively.
For each edge e ∈ Edyn
, i = 1, . . . , d − 1 we have a corresponding family indicator me and a
i
corresponding latent AR(1) process given by

and Eind

i

i

st,e = µe + φe(st−1,e − µe) + σeηt,e, ηt,e ∼ N (0, 1) iid,

(19)

with µe, φe σe and s0,e as in Section 2.1. For each edge e in Estatic
we have a corresponding
family indicator me and a state se as in Section 2.2. The states st,e and se are mapped to the
copula parameter as in (2) and (9), i.e.

i

θme
t,e = g−1
me

(F −1

Z (st,e)) and θme

e = g−1
me

(F −1

Z (se)), respectively.

(20)

This yields the following parameter set for a d-dimensional dynamic vine copula model

θV = {µe, φe, σe, s0,e, . . . , sT,e, me|e ∈ Edyn

i

, i = 1, . . . , d−1}∪{se, me|e ∈ Estatic

i

, i = 1, . . . , d−1}

Within the dynamic vine copula model, we assume that T random vectors of dimension d,

(Ut1, . . . , Utd)t=1,...,T are generated as follows

9

(Ut1, . . . Utd)|θV ∼

d−1
(cid:89)

(cid:89)

cme
ae,be;De

(ut,ae|De , ut,be|De ; θme

t,e )·

i=1

eEdyn
i

d−1
(cid:89)

·

(cid:89)

i=1

e∈Estatic
i

cme
ae,be;De

(ut,ae|De , ut,be|De ; θme

e

), independently

(21)

for t = 1, . . . , T . Further, we assume that parameters for diﬀerent edges are a priori independent
and we use the same priors as speciﬁed in Sections 2.1 and 2.2 for the parameters of dynamic
and static pair copulas, respectively. Here, the conditioned and conditioning sets ae, be and De
do not depend on the time, i.e. the tree structure does not change over time.

3.2 Sequential estimation

2 ·2(d−2

2 ) diﬀerent regular vine tree structures in d dimensions (Morales-N´apoles
Since there exist d!
(2010)), model selection is complex and it is not possible to take all possible structures into
account as the dimension grows. Gruber and Czado (2018) estimate all trees and parameters
jointly using a Bayesian approach, but their procedure is only suitable in lower dimensions
and requires substantial computations. Earlier, in a frequentist setup, Dissmann et al (2013)
proposed a sequential selection and estimation approach for static copula parameters. This
sequential approach makes model selection feasible in higher dimensions and therefore this
idea is often used for vine copula based models. Gruber and Czado (2015) employ a Bayesian
approach, where they estimate parameters of static vine copula models tree by tree and ﬁx
parameters at point estimates before proceeding to the next tree. Vatter and Nagler (2018)
sequentially estimate the parameters of a vine copula model, where the copula parameters are
modeled by generalized additive models. We propose a Bayesian procedure, where the copula
parameters do not need to be collapsed to point estimates before proceeding to the next tree.
The procedure is based on an approximation of the posterior density inspired by the frequentist
sequential approach of Dissmann et al (2013).

To simplify notation we denote by θTi the parameters of a dynamic vine copula correspond-

ing to tree Ti , i.e.

θTi = {µe, φe, σe, s0,e, . . . , sT,e, me, e ∈ Edyn

i

} ∪ {se, me, e ∈ Estatic

i

}.

(22)

Further, we deﬁne by U = (utj)t=1,...,T,j=1,...,d the data matrix and the likelihood contribution
of the i-th tree is given by

(cid:96)i(θT1, . . . , θTi|U ) =

(cid:89)

e∈Edyn
i
(cid:89)

·

cme
ae,be;De

(ut,ae|De, ut,be|De ; θme

t,e )·

cme
ae,be;De

(ut,ae|De , ut,be|De; θme

e

).

e∈Estatic
i

The complete likelihood is obtained as

(cid:96)(θT1, . . . , θTd−1 |U ) =

d−1
(cid:89)

i=1

(cid:96)i(θT1, . . . , θTi|U ),

and the posterior density is proportional to

f (θT1 , . . . , θTd−1|U ) ∝

d−1
(cid:89)

i=1

(cid:96)i(θT1 , . . . , θTi |U )π(θTi ).

(23)

(24)

(25)

Note that the posterior density is a joint density of continuous and discrete parameters. For
discrete parameters δdisc and continuous parameters δcont the joint density is obtained as

f (δcont, δdisc) = f (δcont|δdisc)f (δdisc),

where f (δcont|δdisc) is a joint probability density function and f (δdisc) is a joint probability
mass function.

10

Four-dimensional illustration for a model with static pair copulas and known tree
structure

To illustrate our idea in four dimensions, we consider only static pair copulas and the tree
structure to be known. The tree structure contains the pair copulas as speciﬁed in (26), (27)
and (28). We assume, that we observe data U = (utj)t=1,...,T,j=1,...,4. The contributions to the
likelihood corresponding to trees 1, 2 and 3 are given by

(cid:96)1(θT1 |U ) =

T
(cid:89)

t=1

13 (ut1, ut3; θm13
cm13

13 )cm23

23 (ut2, ut3; θm23

23 )cm34

34 (ut3, ut4; θm34

34 ),

(cid:96)2(θT1, θT2 |U ) =

T
(cid:89)

t=1

12;3 (ut1|3, ut2|3; θm12;3
cm12;3

12;3 )cm24;3

24;3 (ut2|3, ut4|3; θm24;3

24;3 ),

(cid:96)3(θT1 , θT2 , θT3|U ) =

T
(cid:89)

t=1

14;23 (ut1|23, ut4|23; θm14;23
cm14;23

14;23 ).

(26)

(27)

(28)

In a frequentist sequential procedure the parameters of the ﬁrst tree are estimated by consid-
ering the part of the likelihood corresponding to the ﬁrst tree as given in (26), ignoring the likeli-
hood contributions of higher trees (27) and (28) to the parameters of the ﬁrst tree. This allows
to maximize (cid:81)T
34 (ut3, ut4; θm34
t=1 cm23
34 )
independently.

23 (ut2, ut3; θm23

13 (ut1, ut3; θm13

23 ) and (cid:81)T

13 ), (cid:81)T

t=1 cm13

t=1 cm34

In the Bayesian setup the marginal posterior density of the parameters corresponding to the

ﬁrst tree is obtained by integrating out parameters of higher trees, i.e.

f (θT1 |U ) ∝ (cid:96)1(θT1 |U )π(θT1 )

(cid:90)

3
(cid:89)

domain(θT2 ,θT3 )

i=2

(cid:96)i(θT1, . . . , θTi|U )π(θTi )dθT2 dθT3 ,

(29)

where domain(θT2 , θT3) is the domain of the parameters θT2 , θT3 (For the family indicator me
the integral is replaced by a sum). While in this illustrative example it might be possible to
work with the marginal posterior (29), its complexity grows fast if we consider more dimensions
or allow for dynamic copulas. For example, if the second and third tree were modeled with
dynamic bivariate copulas, we would need to integrate out several thousand parameters for
T = 1000. To reduce complexity, we approximate f (θT1 |U ). We make use of the following
notation

g(δ) ≈ h(δ)

to denote that a density g is approximately proportional to a non negative and integrable
function h. This means that the density g is approximated by the density hnormalized given by
hnormalized(δ) = h(δ)

(cid:17)−1

(cid:16)(cid:82)

.

domain(δ) h(δ)dδ

Following the idea of a frequentist sequential estimation we approximate the marginal pos-
terior θT1 |U by considering only the part of the likelihood corresponding to the ﬁrst tree, i.e.

f (θT1|U ) ≈ (cid:96)1(θT1 |U )π(θT1 ) =

13 (ut1, ut3; θm13
cm13
13 )

π(s13)π(m13)

(cid:33)

(cid:32) T
(cid:89)

t=1
(cid:33)

(cid:32) T
(cid:89)

t=1

23 (ut2, ut3; θm23
cm23
23 )

π(s23)π(m23)

34 (ut3, ut4; θm34
cm34
34 )

π(s34)π(m34).

(cid:33)

(cid:32) T
(cid:89)

t=1

(30)

This approximation simpliﬁes sampling enormously. We do not only get rid of the integral,
but in addition, the parameters corresponding to diﬀerent edges are independent. To obtain
samples from the posterior approximation in (30) we can sample parameters of diﬀerent static
bivariate copula models independently by utilizing the algorithm of Section 2.2. In particular
the parameters m13, s13 are sampled from a static bivariate copula model with corresponding
π(s13)π(m13). Approximations of
posterior density proportional to
the posterior distribution that induce independence among parameters are commonly used in

(cid:17)
13 (ut1, ut3; θm13 )

t=1 cm13

(cid:16)(cid:81)T

11

variational Bayesian approaches (Wainwright et al (2008)). For example in mean ﬁeld varia-
tional inference it is assumed that all parameters are independent in the posterior distribution.
Our assumptions are less restrictive, since we do not assume that parameters corresponding to
one pair copula are independent. Further, these parameters are updated jointly.

When estimating parameters of higher trees in a sequential frequentist procedure, we con-

dition on estimates from lower trees. Therefore we consider now the following density

f (θT2|θT1 , U ) ∝ (cid:96)2(θT1, θT2|U )π(θT2 )

(cid:90)

domain(θT3 )

(cid:96)3(θT1, θT2 , θT3 |U )π(θT3 )dθT3.

(31)

We utilize a similar approximation as in (30) and obtain

f (θT2|θT1 , U ) ≈ (cid:96)2(θT1 , θT2|U )π(θT2) =

12;3 (ut1|3, ut2|3; θm12;3
cm12;3
12;3 )

π(s12;3)π(m12;3)

(cid:33)

24;3 (ut2|3, ut4|3; θm24;3
cm24;3
24;3 )

π(s24;3)π(m24;3).

(cid:33)

(cid:32) T
(cid:89)

t=1
(cid:32) T
(cid:89)

t=1

(32)

13 , m13) = d
du3
23 , m23) and ut4|3 = h4|3(ut4|ut3, θm34

(cid:12)
13 (ut1, u3; θm13
The pseudo data ut1|3 = h1|3(ut1|ut3; θm13
(cid:12)
13 )
(cid:12)u3=ut3
h2|3(ut2|ut3; θm23
34 , m34), t = 1, . . . , T only depend on param-
eters of the ﬁrst tree, on which we condition on. Further, the posterior density factorizes as in
(30) and we can sample parameters corresponding to diﬀerent edges independently. In particu-
lar s12;3, m12;3 are sampled from a static bivariate copula model with posterior density propor-
(cid:17)
12;3 (ut1|3, ut2|3; θm12;3
π(s12;3)π(m12;3), where {ut1|3, ut2|3, t = 1, . . . , T } is
12;3 )
tional to
interpreted as observed data. For the third tree we obtain

t=1 cm12;3

, ut2|3 =

(cid:16)(cid:81)T

C m13

f (θT3 |θT1, θT2 , U ) ∝ (cid:96)3(θT1 , θT2 , θT3|U )π(θT3)
(cid:32) T
(cid:89)

=

14;23 (ut1|23, ut4|23; θm14;23
cm14;23
14;23 )

(cid:33)

.
π(s14;23)π(m14;23)

(33)

t=1

As before, ut1|23 and ut4|23 only depend on parameters from lower trees, on which we
condition on. Interpreting {ut1|23, ut4|23, t = 1, . . . , T } as observed data, (33) is the posterior
density of a static bivariate copula model as introduced in Section 2.2.

To obtain samples from the posterior density f (θT1, θT2, θT3 |U ), we utilize the approxi-
mations above to ﬁrst sample θT1 from f (θT1 |U ), then θT2 from f (θT2 |θT1 , U ) and then θT3
from f (θT3 |θT2, θT1 , U ), i.e. we employ a collapsed Gibbs sampler (Liu (1994)). To update the
parameters we use the sampling procedure of Section 2.2. This sampler simulates a Markov
chain, where subsequent draws are autocorrelated. So, by applying this sampler we obtain a
, which depends on the previous value θr−1
sample of θTi in the r-th iteration, denoted by θr
.
Ti
While this is not a problem for conventional Gibbs samplers, as in Metropolis-Hastings within
Gibbs, this can lead to undesired samples for collapsed Gibbs schemes as shown by Van Dyk and
Jiao (2015). Following Van Dyk and Jiao (2015), we can circumvent this problem by running
the updates for θTi with starting value θr−1
equal to the update
will be almost independent of θr−1
obtained in the k-th step. If we choose k large enough, θr
.
Ti
Thus, in total, R · k draws are obtained and R draws are stored for each parameter. We obtain
the following procedure

for k iterations. We set θr
Ti

Ti

Ti

Ti

– Set starting values θ0
T1

, θ0
T2

, θ0
T3

– For r = 1, . . . , R do

– For i = 1, . . . , 3 do

– Use the sampler of Section 2.2 to sample from f (θT1 |U ) if i = 1, from f (θT2|θr
T1

, U ) if
, U ) if i = 3. The sampler is run for k iterations using θr−1
equal to the sample obtained in the k-th iteration.

Ti

i = 2 or from f (θT3|θr
, θr
T2
T1
as starting value. We set θr
Ti

12

– The pseudo data for the next tree is constructed utilizing the h functions deﬁned in (16).
t2|3 =

t1|3 = h1|3(ut1|ut3; (θm13

13), ur

For i = 1 the pseudo data is determined as ur
h2|3(ut2|ut3; (θm23
For i = 2 the pseudo data is determined as ur
t4|23 = h4|2;3(ur
ur

t2|3; (θm24;3

24;3 )r, mr

23) and ur

23 )r, mr

t4|3, ur

24;3) , t = 1, . . . , T.

t4|3 = h4|3(ut4|ut3; (θm34

34 )r, mr

13 )r, mr
34), t = 1, . . . , T .
t2|3; (θm12;3

t1|23 = h1|2;3(ur

t1|3, ur

12;3 )r, mr

12;3) and

In this procedure, no point estimates of the copula parameters θ1, θ2, θ3 are required. We

can further extend the procedure in the following ways.

• a) The loops over i and r can be exchanged. We can ﬁrst obtain R samples from the ﬁrst
tree, then obtain R samples from the second tree and then all R samples from the third
tree. This is visualized in Figure 3. If the tree structure was not known we could select
the tree structure of the ﬁrst tree, then obtain R samples from the parameters of the ﬁrst
tree. Based on these samples, we can construct the pseudo data, which can be used to
select the tree structure of the second tree and so on. Based on the (pseudo) data of a
certain tree level, the corresponding structure can be selected as a maximum spanning
tree. This is similar to the algorithm of Dissmann et al (2013).

• b) The parameters of diﬀerent edges of a tree are sampled independently by utilizing the
sampler of Section 2.2 for the static copula model. If we did not know that Kendall’s τ
was static we could in addition run the sampler of Section 2.1 for the dynamic bivariate
copula model. We can decide between the dynamic, the static and the independence
model as outlined in Section 2.3. Here it is important that these decisions for the type of
dependence can be made independently for each edge of the tree.

Tree 1 sampling:

U

k iterations

1 · k

2 · k

3 · k

. . .

θ1
T1

θ2
T1

θ3
T1

Tree 2 pseudo data:

U 1
2

U 2
2

U 3
2

Tree 2 sampling:

1 · k

2 · k

3 · k

θ1
T2

θ2
T2

θ3
T2

Tree 3 pseudo data:

U 1
3

U 2
3

U 3
3

...

Tree d − 1 sampling:

1 · k

2 · k

3 · k

θ1

Td−1

θ2

Td−1

θ3

Td−1

R · k

θR
T1

U R
2

R · k

θR
T2

U R
3

R · k

θR

Td−1

Figure 3: Graphical representation of the proposed sampler without selection of the type of
dependence and without structure selection. Here U ∈ [0, 1]T ×d denotes the data matrix used
for ﬁtting the model and U r
l denotes the pseudo data for tree l obtained from parameter draws
of the previous tree (tree l − 1) in iteration r.

The general procedure in d dimensions with vine structure selection

Based on the four-dimensional illustration, we now formulate our procedure for a d-dimensional
dynamic vine copula as introduced in Section 3.1, incorporating extensions a) and b). The tree

13

i

, Estatic
i

structure and the sets Edyn
are selected sequentially as we move up the trees and
are ﬁxed at point estimates. In Gruber and Czado (2018) searching among diﬀerent structures
within a full Bayesian procedure resulted in very long computation times for static copula
models. Here it would be even worse, since we deal with more complex dynamic pair copulas.
Note that both, the sets Edyn

and the tree structure do not change over time.

, Eind
i

, Estatic
i

, Eind
i

We propose the following approach with iterations parameter R, burn-in parameter burnin
and thinning parameter k for structure selection and parameter estimation. Note that, as
mentioned above, R·k draws are obtained in total and R iterations are stored for each parameter.

i

1. Select the tree structure of tree T1: For all edges e that are allowed in the ﬁrst tree T1,
i.e. for all pairs (ae, be) with 1 ≤ ae < be ≤ d, estimate τae,be by the empirical Kendall’s
τ using {ut,ae , ut,be , t = 1, . . . , T }. The structure of tree T1 is selected as the maximum
spanning tree among those edges, where the absolute value of empirical Kendall’s τ serves
as the corresponding weight.

2.

(a) For each edge e ∈ E1 in tree T1, with corresponding observations {ut,ae , ut,be , t =
1, . . . , T }, run the samplers of Sections 2.1 and 2.2 for the bivariate dynamic and
static copula models. The samplers are run for R · k iterations and we thin the
samples with factor k.

(b) For each edge e ∈ E1, we select among the bivariate dynamic, static and the bivariate

independence copula model as discussed in Section 2.3.

(c) For each edge e ∈ E1, the pseudo data for the next tree is obtained as

ur
t,ae|be
ur
t,be|ae

= hae|be (ut,ae|ut,be ; (θme
= hbe|ae (ut,be|ut,ae ; (θme

t,e )r, mr
t,e )r, mr

e),
e),

(34)

for r = 1, . . . , R, t = 1, . . . , T , if the dynamic copula was selected for edge e. If the
static copula was selected we replace θme
in (34). For the independence
= ut,ae and ur
copula model we use ur

t,e by θme
t,be|ae

e
= ut,be.

t,ae|be

3. Set l = 2.

4. Select the tree structure of tree Tl: For all edges that are allowed in tree Tl according to
the proximity condition, estimate Kendall’s τ of edge e = (ae, be; De) denoted by τae,be;De
by the empirical Kendall’s τ . Therefore we use posterior mode estimates of the pseudo
data {ˆut,ae|De , ˆut,be|De , t = 1, . . . , T }, where ˆut,ae|De is the mode of the univariate kernel
density estimate of {ur
, r = burnin + 1, . . . , R} and ˆut,be|De is obtained similarly.
Here the posterior mode pseudo data {ˆut,ae|De , ˆut,be|De , t = 1, . . . , T } are treated as an
i.i.d. sample for the estimation of τae,be;De. The structure of tree Tl is selected as the max-
imum spanning tree among those edges, where the absolute value of empirical Kendall’s
τ serves as the corresponding weight.

t,ae|De

5.

(a) For each edge e ∈ El in tree Tl, with corresponding pseudo data {ur

,
t,be|De
t = 1, . . . , T, r = 1, . . . , R}, obtain R samples (based on a total of R · k MCMC
draws) from the bivariate dynamic and static copula models utilizing the approaches
of Sections 2.1 and 2.2. For the static bivariate copula we proceed as follows for an
edge e.

t,ae|De

, ur

e, m0
e.

– Set starting values s0
– For r = 1, . . . , R: obtain k samples of se, me from a static bivariate copula model
as starting

, t = 1, . . . , T }. We use sr−1

, mr−1
e
e to the sample obtained in the k-th iteration.

based on data {ur
value and set sr

e, mr

t,ae|De

t,be|De

, ur

e

For the dynamic copula model we proceed similarly.

(b) We select for each edge e ∈ El among the bivariate dynamic, static and the bivariate

independence copula model as explained in Section 2.3.

(c) For each edge e ∈ El, the pseudo data for the next tree is obtained as

ur
t,ae|be∪De
ur
t,be|ae∪De

= hae|be;De (ur
= hbe|ae;De (ur

|ur
|ur

t,ae|De

t,be|De

t,be|De

t,ae|De

; (θme
; (θme

t,e )r, mr
t,e )r, mr

e),
e),

(35)

14

for r = 1, . . . , R, t = 1, . . . , T , if the dynamic copula was selected for edge e. If the
static copula was selected we replace θme
in (35). For the independence
copula model we set ur

t,e by θme
e
and ur

= ur

= ur

.

t,ae|be∪De

t,ae|De

t,be|ae∪De

t,be|De

6. If l < d − 1, set l = l + 1 and go to 4.

Runtime and scalability

The MCMC samplers in step 2.(a) and the ones in step 5.(a) can be run in parallel, respectively.
The MCMC samplers are the main drivers for the runtime and therefore parallelization speeds
up computation a lot. When enough cores, i.e. at least d − 1 cores for d-dimensional data, are
available, we observed that the computation time for one tree is no more than 40 minutes for
time series data of length T = 1000 with R = 1100, burnin = 100, k = 25, independently of d.
For estimating a full vine (i.e. a vine without truncation), we expect that the computation time
grows roughly linearly with the dimension d and a full vine in 11 dimension (containing 10 trees)
should take no more than 10 · 40 minutes. But in higher dimensions it is often not necessary to
estimate all trees, e.g. we expect the runtime for a 100-dimensional vine, truncated after the
10-th tree, to be not much more than 10 · 40 minutes. Thus, in combination with truncation,
we expect our method to scale very well to higher dimensions.

3.3 Simulation study

With this simulation study, we aim to obtain a ﬁrst impression of the ability of the procedure
proposed in Section 3.2 to recover trajectories of Kendall’s τ and of the ability to select copula
families and the type of dependence (dynamic, static, zero). A more extensive simulation study
to investigate the potential of the novel approach in more detail is planned for the future.

First, we assume the tree structure to be known and the steps for the vine structure selection
in our procedure are left out. This allows to compare the true and estimated Kendall’s τ values
for each pair copula. Afterwards we allow for vine structure selection. In this case our procedure
might select diﬀerent tree structures. Thus the true trajectories of Kendall’s τ and the copula
family for some pair copulas included in the selected vine structure may not be directly known.
We deal with this case by comparing simulations from the true and the estimated model. In
addition we compare average log likelihoods of true and estimated models.

Known tree structure

We consider the tree structure presented in Figure 2. The corresponding families are chosen
from the set: {Independence, Gaussian, Student t(df=2), Student t(df=4), Student t(df=8),
eGumbel, eClayton}. For each pair copula we simulate one trajectory of length T = 1000 for
Kendall’s τ from an AR(1) process. The chosen copula families and the parameters of the
AR(1) processes are speciﬁed in Appendix B. We keep the tree structure, the choice of the
families and the trajectories for Kendall’s τ ﬁxed and simulate 100 times from this model.

For each of the 100 simulated data sets we run the algorithm proposed in Section 3.2. Within
our sequential procedure, we set R = 1100, k = 25 and burnin = 100. This means that within
the procedure 1100 · 25 draws have been obtained for each parameter, whereas 1100 iterations
are stored. Of these 1100 stored iterations the ﬁrst 100 are discarded for burn-in. From Table
3 we see that for each pair copula in the ﬁrst two trees the correct family was selected in at
least 94 out of 100 cases. In Tree 3, the two independence copulas were detected in 69 and
100 out of 100 cases. The static copula in Tree 3 was detected in 88 out of 100 cases. The
independence copulas in Trees 4 and 5 were detected every time. Here we count a Student
t copula as correctly detected if it was selected as a Student t copula, independently of the
degrees of freedom parameter. Table 3 also shows how often the correct type of dependence
(dynamic, static, zero) was selected. For one pair copula in the ﬁrst tree the correct type was
only detected in 75 out of 100 cases. The corresponding Kendall’s τ is shown in the ﬁfth row,
third column in Figure 4. We see that this Kendall’s τ does not change a lot over time. So it is
diﬃcult to distinguish between the dynamic and the static model for this pair copula. Except
for this pair copula, the type of dependence of pair copulas in the ﬁrst two trees was detected in
at least 93 out of 100 cases. In trees, higher than tree 2, the correct type was selected in at least

15

69 out of 100 cases. We think that these are reasonable results for the selection of the family
and of the type of dependence for the pair copulas, that make up the dynamic vine copula. In
addition, Figures 4 and 5 illustrate that our procedure can recover the simulated trajectories
of Kendall’s τ .
In these ﬁgures, we show marginal (univariate) posterior mode estimates of
Kendall’s τ parameters, which will be utilized later (Section 4) as point estimates.

Tree
5
4
3
2
1

100
100
69
100
94

Copula family

Type of dependence

100
88
100
100

100
94
100

100
99

100

100
100
69
100
100

100
78
96
93

100
97
75

100
98

97

Table 3: This table shows how often the correct copula family and how often the correct type of
dependence (dynamic, static, zero) was selected out of the 100 simulations for each pair copula
of the dynamic vine copula. There are 6 − i pair copulas in the i-th tree. The selected copula
family for an edge e is the marginal posterior mode estimate of me, i.e. the family that occurs
most frequently among the posterior samples for me.

Figure 4: This plot corresponds to a ﬁtted model for one simulated data set. Posterior mode
estimates of Kendall’s τ at time t are plotted against t for each pair copula (black lines). The
posterior mode estimates are obtained from marginal (univariate) kernel density estimates of
the corresponding Kendall’s τ parameter. A 90% credible region constructed from the estimated
5% and 95% posterior quantiles is added in grey. True values of Kendall’s τ are added in red.

16

02006001000−0.50.5Tree 5timet02006001000−0.50.5Tree 4timet02006001000−0.50.5timet02006001000−0.50.5Tree 3timet02006001000−0.50.5timet02006001000−0.50.5timet02006001000−0.50.5Tree 2timet02006001000−0.50.5timet02006001000−0.50.5timet02006001000−0.50.5timet02006001000−0.50.5Tree 1timet02006001000−0.50.5timet02006001000−0.50.5timet02006001000−0.50.5timet02006001000−0.50.5timetFigure 5: In this plot we consider 100 estimated models. The mean of 100 posterior mode
estimates of Kendall’s τ at time t is plotted against t for each pair copula (black line). The
posterior mode estimates are obtained from marginal (univariate) kernel density estimates of
the corresponding Kendall’s τ parameter. The blue region is constructed from the empirical 5%
and 95% quantiles of the 100 posterior mode estimates. True values of Kendall’s τ are added
in red.

Unknown tree structure

We use the same 100 simulated data sets as in the case with known tree structure but allow
here for structure selection within our procedure. As already mentioned, evaluating our results
is not straightforward in this case. Our estimated model may contain pair copulas for which we
do not know the true copula families and Kendall’s τ values directly. In this case we simulate
500 times from the true model and from the estimated model. Then we can calculate empirical
Kendall’s τ values for each of the 6·5
2 = 15 pairs (U1, U2), (U1, U3), . . .. We compare trajectories
of the empirical Kendall’s τ values in Figures 6 and 7. These trajectories look similar for the
true and the estimated models. We see that also our procedure with structure selection is able
to recover the simulated trajectories of Kendall’s τ .

For further evaluation of the proposed procedure we compare log-likelihoods of estimated
and true models, as in Gruber and Czado (2015). To save computation time, we evaluate the
likelihoods of estimated models based on point estimates (marginal posterior mode estimates)
of the parameters, instead of evaluating the likelihoods for all posterior draws. The average log-
likelihood of models without structure selection was 94% of the log-likelihood of the true model,
whereas the log-likelihood of the models estimated with structure selection was on average 89%
of the log-likelihood of the true model.
It is not surprising that we perform a bit better if
we assume the vine structure to be known. But the diﬀerence is not very big and in both
cases, with and without vine structure selection, we obtain reasonable results. For further
comparison we also estimated dynamic C-vine and D-vine copulas. Therefore we just restrict
our structure selection procedure in Section 3.2 to C-vine and D-vine structures, respectively.
The dynamic C-vine and D-vine copulas achieved 86% and 88% of the log-likelihood of the true
model, respectively. Thus, in this scenario, allowing for general vine structures improves the ﬁt
compared to restricting the structure to C-vines or D-vines.

17

02006001000−0.50.5Tree 5timet02006001000−0.50.5Tree 4timet02006001000−0.50.5timet02006001000−0.50.5Tree 3timet02006001000−0.50.5timet02006001000−0.50.5timet02006001000−0.50.5Tree 2timet02006001000−0.50.5timet02006001000−0.50.5timet02006001000−0.50.5timet02006001000−0.50.5Tree 1timet02006001000−0.50.5timet02006001000−0.50.5timet02006001000−0.50.5timet02006001000−0.50.5timetFigure 6: This plot corresponds to a ﬁtted model for one simulated data set. The empirical
unconditional Kendall’s τ estimate at time t, obtained from simulations from the ﬁtted model,
is plotted against t for each pair (Ui, Uj), i, j ∈ {1, . . . , 6}, i < j (black line). True Kendall’s τ
values determined by simulating from the true model 500 times are added in red.

Figure 7: In this plot we consider 100 ﬁtted models. The mean of 100 empirical estimates
of the unconditional Kendall’s τ at time t, obtained from simulations of the ﬁtted model, is
plotted against t for each pair (Ui, Uj), i, j ∈ {1, . . . , 6}, i < j (black line). The blue region is
constructed from the 5% and 95% empirical quantiles of the 100 empirical estimates of Kendall’s
τ . True Kendall’s τ values determined by simulating from the true model 500 times are added
in red.

4 Application: Dynamic exchange rates dependence

We employ the proposed dynamic vine copula model to model the dependence among 21 ex-
change rates with respect to the US Dollar (USD). For this we use data obtained from the FRED
database of the Federal Reserve Bank of St. Louis (https://fred.stlouisfed.org/categories/94)
which comprises daily log returns of 21 exchange rates with respect to the USD from 2007 to
2018, resulting in 3130 observations. The 21 currencies and their ticker symbols are summarized
in Appendix C. We estimate our model based on the ﬁrst 1500 observations and evaluate its
predictive performance based on the remaining 1630 observations. First the data is demeaned
based on the ﬁrst 1500 observations and we collect the demeaned log returns in the data matrix
Y = (ytj)t=1,....,3130,j=1,...,21 ∈ R3130×21.

18

02006001000−0.50.51 2timet02006001000−0.50.51 3timet02006001000−0.50.52 3timet02006001000−0.50.51 4timet02006001000−0.50.52 4timet02006001000−0.50.53 4timet02006001000−0.50.51 5timet02006001000−0.50.52 5timet02006001000−0.50.53 5timet02006001000−0.50.54 5timet02006001000−0.50.51 6timet02006001000−0.50.52 6timet02006001000−0.50.53 6timet02006001000−0.50.54 6timet02006001000−0.50.55 6timet02006001000−0.50.51 2timet02006001000−0.50.51 3timet02006001000−0.50.52 3timet02006001000−0.50.51 4timet02006001000−0.50.52 4timet02006001000−0.50.53 4timet02006001000−0.50.51 5timet02006001000−0.50.52 5timet02006001000−0.50.53 5timet02006001000−0.50.54 5timet02006001000−0.50.51 6timet02006001000−0.50.52 6timet02006001000−0.50.53 6timet02006001000−0.50.54 6timet02006001000−0.50.55 6timetFor the marginals we use skew Student t stochastic volatility models, i.e. we assume that

(cid:15)st
tj

(cid:19)

(cid:18) sst
tj
2
j (sst
j + φst

Ytj = exp

tj =µst
sst

t−1j − µst

j ) + σst

j ηst
tj

(36)

j ∈ R, φst

with ηtj ∼ N (0, 1) independently, µst
j ∈ (0, ∞) for t = 1, . . . , 3130.
The error (cid:15)tj follows marginally a standardized skew Student t distribution with skewness
parameter αj ∈ R and degrees of freedom parameter dfj ∈ (2, ∞) (see Kreuzer and Czado
(2019)). The corresponding density and distribution functions are denoted by sst(·|αj, dfj) and
SST (·|αj, dfj), respectively. The joint distribution among the errors is modeled by the proposed
dynamic vine copula model.

j ∈ (−1, 1), σst

We follow ideas of the two step approach, commonly used in copula modeling, and assume
independence among the errors (cid:15)st
tj for estimating the margins. But instead of collapsing pa-
rameters of the marginal skew Student t stochastic volatility models to point estimates and
obtain the copula data based on these point estimates we follow ideas from Section 3.2. For
each of the 21 marginal time series y1j, . . . , y1500j we estimate a skew Student t stochastic
volatility model as explained in Kreuzer and Czado (2019). The sampler is run for 1100 · 25
iterations and then we thin the samples with factor 25. The parameter draws of the skewness
parameters, of the degrees of freedom parameters and of the latent log variances are denoted by
1500j)r, r = 1, . . . , 1100. For each parameter draw, we obtain pseudo
(αst
copula data as follows

0j)r, . . . , (sst

j )r, (df st

j )r, (sst

ur
tj = SST

(cid:18)

(cid:18)

ytj exp

−

(sst
tj)r
2

(cid:19)(cid:12)
(cid:12)(αst
(cid:12)

j )r, (df st

j )r

(cid:19)

(37)

for t = 1, . . . , 1500, j = 1, . . . , 21, r = 1, . . . , 1100.

Based on these pseudo copula data sets we ﬁt a dynamic vine copula model. The algorithm
of Section 3.2 is slightly modiﬁed. We start with Step 3. and set l = 1 since we ﬁt our
model with a collection of copula data sets instead of only one copula data set. Further we set
R = 1100, k = 25 and burnin = 100. The copula families are selected from the following set
M = {Independence, Gaussian, Student t(df=2), Student t(df=4), Student t(df=8), eGumbel,
eClayton}. The estimated dynamic vine copula model is analyzed in more detail in the following.
The ﬁrst tree of the selected vine tree structure is shown in Figure 8. We see that some
currencies that are connected by an edge are from countries of the same region. For example,
the currencies GBP/USD (British Pound to USD) and DKK/USD (Danish Krone to USD)
are connected to the EUR/USD (Euro to USD). Since the vine structure is selected as the
maximum spanning tree, where the absolute value of Kendall’s τ serves as weight, this indicates
high dependence among those currencies. Further, we see that the selected vine structure is
neither a C-vine nor a D-vine structure. The generalization of C-vine and D-vine structures to
R-vine structures seems to be necessary.

In Table 4 we show the selected types of dependence per tree level. Above tree nine, all
selected copulas are equal to the independence copula, i.e. the type of dependence is estimated
to be zero. Further we see that only few static copulas were selected. The number of dynamic
copulas selected decreases as we move up to higher tree levels. In total 20·21
2 = 210 pair copulas
are estimated, of which 150 were set equal to the independence copula. Our proposed procedure
is able to detect sparse structures. Note that the level of sparsity can be increased by adjusting
the selection of the type of dependence accordingly. As mentioned in Section 2.3, we decide
for the more complex type of dependence if the WAIC of the more complex model is at least
2 standard errors smaller. By increasing 2 to for example 4 standard errors, we achieve more
sparsity. This might be interesting in higher dimensional settings. Since for most pair copulas
in the ﬁrst trees the dynamic type of dependence is selected, a vine copula model with static
dependence might not be appropriate for those selected pair copula terms with time-varying
dependence.

19

Figure 8: The ﬁrst tree of the vine tree structure selected for the 21-dimensional exchange rates
data set. Nodes which belong to the same region have the same color (Europe: grey, Asia:
white, America: green, Australasia: orange, Africa: yellow).

Tree Dynamic
18
16
7
6
2
3
2
1
1

1
2
3
4
5
6
7
8
9

Static Zero
0
2
11
10
14
12
12
12
11

2
1
0
1
0
0
0
0
0

Table 4: We show how often the diﬀerent types of dependence (dynamic, static, zero) were
selected per tree level for the ﬁrst nine trees.

Figure 9 shows how the dynamic Kendall’s τ values evolve over time. We see that the
dependence between the exchange rates AUD/USD (Australian Dollar to USD) and ZAR/USD
(South African Rand to USD) varies more in 2007 and 2008, during the ﬁnancial crisis, and
remains almost constant after that period. Further we observe that the Kendall’s τ between
SGD/USD (Singapore Dollar to USD) and THB/USD (Thai Baht to USD) is close to zero
in 2007 and then starts to increase after 2007. The dependence between DKK/USD (Danish
Krone to USD) and CHF/USD (Swiss Franc to USD) is rather high but decreases in 2010 and
reaches its lowest point in 2011. This might be the eﬀect of the introduction of the cap on
the Swiss Franc on 6 September 2011 by the Swiss National Bank. The minimum exchange
rate was set at 1.2 CHF (Swiss Franc) per EUR (Euro). The second row of Figure 9 shows
ﬁtted conditional Kendall’s τ values. For example, we see how the Kendall’τ of the exchange
rates DKK/USD (Danish Krone to USD) and JPY/USD (Japanese Yen to USD) conditional on
CHF/USD (Swiss Franc to USD) evolves over time. The conditional dependence varies between
−0.5 and 0. We also provide quantiﬁcation of uncertainty of the Kendall’s τ values through
credible intervals. This is an advantage of our Bayesian approach compared to the frequentist
approach of Almeida et al (2016) for dynamic D-vine copulas, where uncertainty quantiﬁcation
was not provided.

20

Tree 1CNYHKDNTDTHBINRKRWBRLJPYCHFDKKGBPEURNOKMYRMXNCADSEKZARSGDAUDNZDFigure 9: Visualization of the dynamic Kendall’s τ for some chosen pair copulas of the dynamic
vine copula model estimated for the 21-dimensional exchange rates data set. Rows 1 and 2
of this plot correspond to pair copulas in Trees 1 and 2, respectively. The black line shows
marginal posterior mode estimates of Kendall’s τ plotted against time t. A 90% credible region
constructed from the estimated 5% and 95% posterior quantiles is added in grey.

As already mentioned, the proposed dynamic vine copula model can be seen as a general-
ization of static vine copulas and as a generalization of the dynamic C-vine and D-vine copula
models of Goel and Mehra (2019) and Almeida et al (2016). We would like to further support
the hypothesis that our proposed dynamic vine copula model is a needed generalization and is
able to describe the dependence structure more appropriate than its competitor models: a dy-
namic C-vine, a dynamic D-vine and a static vine copula. Therefore we compare these models
with respect to their predictive accuracy. To estimate the dynamic C-vine and D-vine copula
model, we adjust our structure selection procedure in Section 3.2 accordingly. The families
are selected from the same set M that we used for the dynamic vine copula. The static vine
copula model is estimated with the algorithm of Dissmann et al (2013), as implemented in the
R-package rvinecopulib (Nagler and Vatter (2018)). Here we allow for all parametric copula
families that are implemented in the rvinecopulib package. For all models we use skew Stu-
dent t stochastic volatility models for the margins. For the static vine copula model the pseudo
copula data is obtained by ﬁxing the parameters of the skew Student t stochastic volatility mod-
els at marginal posterior mode estimates. The competitor models are also estimated based on
the ﬁrst 1500 observations of our data. For all models we obtain one day ahead predictive scores
for the other 1630 days in our data set. We proceed as in Kreuzer and Czado (2019). Instead
of reﬁtting the models 1629 times, we keep static model parameters ﬁxed at point estimates
(marginal posterior mode estimates for the dynamic models, maximum likelihood estimates for
the static vine copula) and only update dynamic parameters. This reduces computation time
a lot. To further reduce computation time, we evaluate the log predictive likelihoods at point
estimates instead of averaging over all posterior draws. Similar to Kastner (2019), we call this
pseudo log predictive scores (plps). The plps at time t > 1500 has the following structure

plpst(y1, . . . , y21) = ln(ˆct(ˆu1, . . . , ˆu21)) +

21
(cid:88)

j=1

(cid:18)

(cid:18)

(cid:18)

ln

sst

yj exp

−

ˆsst
tj
2

(cid:19)(cid:12)
(cid:12)ˆαst
(cid:12)

j , ˆdf

st
j

(cid:19)(cid:19)

−

ˆsst
tj
2

,

(38)

(cid:16)

where ˆct is the estimated copula density of one of the four considered models obtained by ﬁxing
the corresponding parameters at point estimates (marginal posterior mode estimates for the
dynamic models, maximum likelihood estimates for the static vine copula). Further ˆuj =
(cid:17)(cid:12)
j , ˆdf
(cid:12)
(cid:12)ˆαst
SST
ˆsst
1, . . . , 21. The marginal contribution (cid:80)21
tj
2 is the same
for all considered models. So we compare the models with respect to the copula contributions

with marginal posterior mode estimates ˆsst
tj, ˆαst
(cid:17)(cid:17)

(cid:17)(cid:12)
(cid:12)
(cid:12)ˆαst

for j =

j=1 ln

j , ˆdf

j , ˆdf

yj exp

yj exp

ˆsst
tj
2

ˆsst
tj
2

sst

st
j

st
j

st
j

−

−

−

(cid:17)

(cid:16)

(cid:16)

(cid:16)

(cid:16)

21

−1.00.01.0AUD ZARtimet200720092011−1.00.01.0SGD THBtimet200720092011−1.00.01.0DKK CHFtimet200720092011−1.00.01.0MYR NTD ; SGDtimet200720092011−1.00.01.0DKK JPY ; CHFtimet200720092011−1.00.01.0AUD MXN ; ZARtimet200720092011ln(ˆc(ˆu1, . . . , ˆu21)) to which we refer as copula plps. Note that a higher (copula) plps is an
indication for better forecasting accuracy.

Table 6 shows the cumulative copula plps, i.e. the sum over all 1630 plps. We see that the
two vine copula models with ﬂexible tree structure outperform the dynamic C-vine and D-vine
copulas. Further the dynamic vine copula, for which the selected structure deviates clearly
from a C-vine and a D-vine structure and for which many pair copulas have a dynamic type
of dependence provides the most accurate forecasts. Our conclusion is that the dynamic vine
copula model provides a useful generalization of static vine copula models as well as of dynamic
C-vine and D-vine copula models.

copula plps

Dynamic vine Dynamic C-vine Dynamic D-vine
11126

11643

11132

Static vine
11267

Table 5: Cumulative one day ahead copula plps for the four considered models: Dynamic vine,
dynamic C-vine, dynamic D-vine and static vine copula.

5 Conclusion and future research

We introduced a class of dynamic vine copula models and provided a novel Bayesian estimation
procedure based on an approximation of the posterior distribution allowing for simpliﬁcation
of the sampler. Here we allowed for the selection of the pair copula family, the selection of the
type of dependence for each pair copula term and the sequential selection of a static (time-
constant) vine structure. The application showed that the dynamic vine copula model is a
useful extension of static vine copulas and of dynamic C-vine and D-vine copulas.

Our estimation procedure propagates uncertainty of copula parameter estimation from lower
to higher trees. But the type of dependence is selected with WAIC and then ﬁxed before we move
to the next tree. Instead of using the WAIC or any other information criteria, shrinkage priors
as proposed by Bitto and Fr¨uhwirth-Schnatter (2019) that allow to shrink dynamic parameters
to static ones might be an interesting alternative to be studied in future research.

One restriction of our approach is that both the vine tree structure as well as the pair copula
families are assumed not to change over time. In the future we are interested in overcoming
these restrictions.

Further, it would be interesting to study in more detail how the dynamic vine copula model
performs in situations, where appropriate dependence modeling is crucial, for example in ﬁnan-
cial risk management. The dynamic vine copula model might lead to more accurate value at
risk predictions than those obtained from static vine copula models. Another example is pairs
trading. St¨ubinger et al (2018) showed that proﬁtable trading strategies can be constructed
with static vine copula models. These strategies might be improved by allowing for dynamic
dependencies.

Lastly, we think that the ability of the vine copula framework to scale bivariate copula models
to copula models of arbitrary dimensions has not been fully exploited yet. We are sure that
there is a variety of useful extensions of static vine copula models that build on sophisticated
bivariate copula models. For example, one could allow for bivariate copula families with more
than one parameter such as the BB1 family or for bivariate dynamic mixture copulas as studied
by Kreuzer and Czado (2019), where both mixture components share the same dynamic on
Kendall’s τ . Alternatively one could also study bivariate mixture copula models with one
dynamic and one static component.

A Additional material for parameter sharing (Section 2.1)

Our procedure in Section 2.1 shares parameters among diﬀerent copula families. This is moti-
vated by the fact that the parameter st, the Fisher’s Z transform of Kendall’s τ , is similar for
diﬀerent copula families. To support this statement, we conduct the following experiment: We
simulate 100 bivariate data sets, each containing 1000 observations, from the bivariate Student
t copula with 4 degrees of freedom and copula parameter ρtrue. The corresponding Kendall’s τ

22

is obtained as τtrue = 2
π arcsin(ρtrue). For each data set, we estimate the copula parameter of
the Gaussian, Student t, Clayton and Gumbel copula by maximizing the likelihood and trans-
form the estimates to the corresponding Kendall’s τ values. We obtain 100 estimated Kendall’s
τ values for each copula family and take the average of those 100 values, which we denote by
ˆτ . This results in four diﬀerent ˆτ values corresponding to four diﬀerent copula families. This
procedure is repeated for diﬀerent values of τtrue and the average Kendall’s τ estimate, ˆτ , is
shown in Figure 10 for each value of τtrue. We see that the estimated Kendall’s τ values for the
Gaussian, Student t and Gumbel copula are very close to each other. Although the Kendall’s τ
estimates for the Clayton copula are a bit further apart, we think that they are still reasonable
close such that parameter sharing is justiﬁed.

Figure 10: This plot shows average Kendall’s τ estimates, ˆτ , for diﬀerent copula families (Gaus-
sian, Student t(df=4), Clayton, Gumbel) plotted against the Kendall’s τ that was used for
simulation, τtrue.

B Parameter speciﬁcation for the simulation study in Sec-

tion 3.3

Parameters of a dynamic vine copula model are here speciﬁed through matrices. The last row
shows parameters corresponding to pair copulas in the ﬁrst tree, the second last row parameters
corresponding to pair copulas in the second tree and so on. If we set the dispersion parameter
and the standard deviation parameter to zero, we obtain a static copula model.

µ =











0.0
0.0
0.0
0.0 0.3 0.0
0.3 0.4 0.3
0.9 0.6 0.8

σ =

0.0
0.8



1.0









0.00
0.00
0.00
0.05
0.10











φ =











0.00
0.00
0.00
0.98
0.95

0.00
0.00
0.90
0.98

0.00
0.00
0.90

0.00
0.00

0.00





















0.00
0.00

0.00

0.00
0.00
0.10
0.03

0.00
0.00
0.05

23

0.20.40.60.80.20.40.60.8ttruet^GaussianStudent tClaytonGumbelfamily =











Independence
Independence
Independence
Gaussian
Gaussian

Independence
eClayton
Student t(df=4)
Student t(df=4)

Independence
eGumbel
eClayton

Independence
eGumbel

Gaussian











Note that, within the dynamic bivariate copula model, the stationary distribution of the AR(1)
process is given by

s|µ, φ, σ ∼ N

µ,

(cid:18)

σ2
1 − φ2

(cid:19)

.

for a state s. Using the density transformation rule this implies the following density for
Kendall’s τ (the Fisher’s Z transform of s)

f (τ |µ, φ, σ) = ϕ

FZ(τ )|µ,

(cid:18)

σ2
1 − φ2

(cid:19) 1

1 − τ 2 , τ ∈ (−1, 1).

(39)

To obtain an understanding of what diﬀerent choices of µ, φ and σ imply for τ , we show
the density given in (39) in Figure 11. We consider the values of µ, φ and σ which are used in
the ﬁrst tree.

Figure 11: We show the stationary density of τ given in (39) for diﬀerent values of µ, φ and σ.
Each line is associated with a vector (µ, φ, σ) given in the legend.

24

−0.50.00.51.00123456tDensity of t(0.5,0.95,0.1)(0.6,0.98,0.03)(0.8,0.9,0.05)C Exchange rates (to the US Dollar) data set

Brazilian Real
Canadian Dollar
Chinese Yuan
Danish Krone
Hong Kong Dollar
Indian Rupees
Japanese Yen

Ticker Currency
BRL
CAD
CNY
DKK
HKD
INR
JPY
KRW South Korean Won
MYR Malaysian Ringgit
MXN Mexican New Pesos
NOK
SEK
ZAR
SGD
CHF
NTD
THB
AUD
EUR
NZD
GBP

Norwegian Krone
Swedish Krona
South African Rand
Singapore Dollar
Swiss Franc
New Taiwan Dollar
Thai Baht
Australian Dollar
Euro
New Zealand Dollar
British Pound

Table 6: The 21 currencies with corresponding ticker symbols used in the application in Section
4.

Acknowledgements

The second author is supported by the German Research Foundation (DFG grant CZ 86/4-
1). Computations were performed on a Linux cluster supported by DFG grant INST 95/919-1
FUGG.

References

Aas K (2016) Pair-copula constructions for ﬁnancial applications: A review. Econometrics

4(4):43

Aas K, Czado C, Frigessi A, Bakken H (2009) Pair-copula constructions of multiple dependence.

Insurance: Mathematics and Economics 44(2):182–198

Acar EF, Czado C, Lysy M (2019) Flexible dynamic vine copula models for multivariate time

series data. Econometrics and Statistics 12:181–197

Almeida C, Czado C (2012) Eﬃcient Bayesian inference for stochastic time-varying copula

models. Computational Statistics & Data Analysis 56(6):1511–1527

Almeida C, Czado C, Manner H (2016) Modeling high-dimensional time-varying dependence
using dynamic D-vine models. Applied Stochastic Models in Business and Industry 32(5):621–
638

Baele L, Bekaert G, Inghelbrecht K (2010) The determinants of stock and bond return comove-

ments. The Review of Financial Studies 23(6):2374–2428

Barthel N, Geerdens C, Czado C, Janssen P (2018) Dependence modeling for recurrent event

times subject to right-censoring with D-vine copulas. Biometrics 75:439–451

25

Bedford T, Cooke RM (2001) Probability density decomposition for conditionally dependent
random variables modeled by vines. Annals of Mathematics and Artiﬁcial Intelligence 32(1-
4):245–268

Bitto A, Fr¨uhwirth-Schnatter S (2019) Achieving shrinkage in a time-varying parameter model

framework. Journal of Econometrics 210(1):75–97

Brechmann EC, Czado C (2013) Risk management with high-dimensional vine copulas: An

analysis of the Euro Stoxx 50. Statistics & Risk Modeling 30(4):307–342

Brechmann EC, Czado C, Aas K (2012) Truncated regular vines in high dimensions with

application to ﬁnancial data. Canadian Journal of Statistics 40(1):68–85

Czado C (2019) Analyzing Dependent Data with Vine Copulas. Lecture Notes in Statistics,

Springer

Dissmann J, Brechmann EC, Czado C, Kurowicka D (2013) Selecting and estimating regular
vine copulae and application to ﬁnancial returns. Computational Statistics & Data Analysis
59:52–69

Embrechts P, McNeil A, Straumann D (2002) Correlation and dependence in risk management:

properties and pitfalls. Risk Management: Value at Risk and Beyond 1:176–223

Engle R (2002) Dynamic conditional correlation: A simple class of multivariate generalized au-
toregressive conditional heteroskedasticity models. Journal of Business & Economic Statistics
20(3):339–350

Erhardt TM, Czado C, Schepsmeier U (2015) R-vine models for spatial time series with an

application to daily mean temperature. Biometrics 71(2):323–332

Garthwaite PH, Fan Y, Sisson SA (2016) Adaptive optimal scaling of Metropolis–Hastings algo-
rithms using the Robbins–Monro process. Communications in Statistics-Theory and Methods
45(17):5098–5111

Goel A, Mehra A (2019) Analyzing Contagion Eﬀect in Markets During Financial Crisis Using
Stochastic Autoregressive Canonical Vine Model. Computational Economics 53(3):921–950

Green PJ (1995) Reversible jump Markov chain Monte Carlo computation and Bayesian model

determination. Biometrika 82(4):711–732

Gruber LF, Czado C (2015) Sequential Bayesian model selection of regular vine copulas.

Bayesian Analysis 10(4):937–963

Gruber LF, Czado C (2018) Bayesian model selection of regular vine copulas. Bayesian Analysis

13(4):1107–1131

Haﬀ IH, Aas K, Frigessi A (2010) On the simpliﬁed pair-copula construction—simply useful or

too simplistic? Journal of Multivariate Analysis 101(5):1296–1310

Hafner CM, Manner H (2012) Dynamic stochastic copula models: Estimation, inference and

applications. Journal of Applied Econometrics 27(2):269–295

Harvey A, Ruiz E, Shephard N (1994) Multivariate stochastic variance models. The Review of

Economic Studies 61(2):247–264

Joe H (2014) Dependence modeling with copulas. CRC Press

Kastner G (2016) Dealing with stochastic volatility in time series using the R package stochvol.

Journal of Statistical Software 69(5):1–30

Kastner G (2019) Sparse Bayesian time-varying covariance estimation in many dimensions.

Journal of Econometrics 210(1):98–115

26

Kastner G, Fr¨uhwirth-Schnatter S, Lopes HF (2017) Eﬃcient Bayesian inference for multivari-
ate factor stochastic volatility models. Journal of Computational and Graphical Statistics
26(4):905–917

Kreuzer A, Czado C (2019) Eﬃcient Bayesian inference for univariate and multivariate non
linear state space models with univariate autoregressive state equation. arXiv e-prints
arXiv:1902.10412

Liu JS (1994) The collapsed Gibbs sampler in Bayesian computations with applications to a
gene regulation problem. Journal of the American Statistical Association 89(427):958–966

Min A, Czado C (2011) Bayesian model selection for D-vine pair-copula constructions. Canadian

Journal of Statistics 39(2):239–258

M¨oller A, Spazzini L, Kraus D, Nagler T, Czado C (2018) Vine copula based post-processing

of ensemble forecasts for temperature. arXiv preprint arXiv:181102255

Morales-N´apoles O (2010) Counting vines. In: Dependence modeling: Vine copula handbook,

World Scientiﬁc, pp 189–218

Murray I, Adams RP, MacKay DJ (2010) Elliptical slice sampling. Proceedings of the 13th

International Conference on Artiﬁcial Intelligence and Statistics (AISTATS) 9:541–548

Nagler T, Vatter T (2018) rvinecopulib: High performance algorithms for vine copula modeling.

R package version 02 8(0)

Oh DH, Patton AJ (2018) Time-varying systemic risk: Evidence from a dynamic copula model

of cds spreads. Journal of Business & Economic Statistics 36(2):181–195

Pitt M, Shephard N (1999) Time varying covariances: a factor stochastic volatility approach.

Bayesian Statistics 6:547–570

Richard JF, Zhang W (2007) Eﬃcient high-dimensional importance sampling. Journal of Econo-

metrics 141(2):1385–1411

Sklar M (1959) Fonctions de repartition an dimensions et leurs marges. Publ inst statist univ

Paris 8:229–231

Stoeber J, Joe H, Czado C (2013) Simpliﬁed pair copula constructions—limitations and exten-

sions. Journal of Multivariate Analysis 119:101–118

St¨ubinger J, Mangold B, Krauss C (2018) Statistical arbitrage with vine copulas. Quantitative

Finance 18(11):1831–1849

Tan BK, Panagiotelis A, Athanasopoulos G (2019) Bayesian inference for the one-factor copula

model. Journal of Computational and Graphical Statistics 28(1):155–173

Van Dyk DA, Jiao X (2015) Metropolis-Hastings within partially collapsed Gibbs samplers.

Journal of Computational and Graphical Statistics 24(2):301–327

Vatter T, Chavez-Demoulin V (2015) Generalized additive models for conditional dependence

structures. Journal of Multivariate Analysis 141:147–167

Vatter T, Nagler T (2018) Generalized additive models for pair-copula constructions. Journal

of Computational and Graphical Statistics 27(4):715–727

Vehtari A, Gelman A, Gabry J (2017) Practical Bayesian model evaluation using leave-one-out

cross-validation and WAIC. Statistics and Computing 27(5):1413–1432

Wainwright MJ, Jordan MI, et al (2008) Graphical models, exponential families, and variational

inference. Foundations and Trends R(cid:13) in Machine Learning 1(1–2):1–305

Watanabe S (2010) Asymptotic equivalence of Bayes cross validation and widely applicable
information criterion in singular learning theory. Journal of Machine Learning Research
11(Dec):3571–3594

27

Yu Y, Meng XL (2011) To center or not to center: That is not the question—an Ancillarity–
Suﬃciency Interweaving Strategy (ASIS) for boosting MCMC eﬃciency. Journal of Compu-
tational and Graphical Statistics 20(3):531–570

28

