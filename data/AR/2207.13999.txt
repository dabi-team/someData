Robot-Assisted Drilling on Curved Surfaces with Haptic Guidance
under Adaptive Admittance Control*

Alireza Madani1, Pouya P. Niaz1, Berk Guler1, Yusuf Aydin2, and Cagatay Basdogan1

2
2
0
2

l
u
J

8
2

]

O
R
.
s
c
[

1
v
9
9
9
3
1
.
7
0
2
2
:
v
i
X
r
a

Abstract— Drilling a hole on a curved surface with a desired
angle is prone to failure when done manually, due to the
difﬁculties in drill alignment and also inherent instabilities of
the task, potentially causing injury and fatigue to the workers.
On the other hand, it can be impractical to fully automate
such a task in real manufacturing environments because the
parts arriving at an assembly line can have various complex
shapes where drill point locations are not easily accessible,
making automated path planning difﬁcult. In this work, an
adaptive admittance controller with 6 degrees of freedom is
developed and deployed on a KUKA LBR iiwa 7 cobot such
that the operator is able to manipulate a drill mounted on the
robot with one hand comfortably and open holes on a curved
surface with haptic guidance of the cobot and visual guidance
provided through an AR interface. Real-time adaptation of
the admittance damping provides more transparency when
driving the robot in free space while ensuring stability during
drilling. After the user brings the drill sufﬁciently close to the
drill target and roughly aligns to the desired drilling angle, the
haptic guidance module ﬁne tunes the alignment ﬁrst and then
constrains the user movement to the drilling axis only, after
which the operator simply pushes the drill into the workpiece
with minimal effort. Two sets of experiments were conducted
to investigate the potential beneﬁts of the haptic guidance
module quantitatively (Experiment I) and also the practical
value of the proposed pHRI system for real manufacturing
settings based on the subjective opinion of the participants
(Experiment II). The results of Experiment I, conducted with
3 naive participants, show that the haptic guidance improves
task completion time by 26% while decreasing human effort
by 16% and muscle activation levels by 27% compared to
no haptic guidance condition. The results of Experiment II,
conducted with 3 experienced industrial workers, show that
the proposed system is perceived to be easy to use, safe, and
helpful in carrying out the drilling task.

Index

Terms— Robot-assisted manufacturing,
physical
human-robot interaction, adaptive admittance control, haptic
guidance, augmented reality, collaborative robotic drilling

I. INTRODUCTION

In the near future, humans and robots are expected to
perform collaborative tasks involving physical interaction in
various different environments such as homes, hospitals, and
factories.

To this end, impedance and admittance controllers are
often used for regulating the physical interaction between

*This work was supported by the Scientiﬁc and Technological Research

Council of Turkey (TUBITAK) under contract number EEEAG-117E645

1A.M., P.P.N., B.G., and C.B.

(Corresponding Author) are with
the Robotics
and Mechatronics Laboratory and KUIS AI-Center,
Koc University, Istanbul, Turkey, 34450 {amadani20, pniaz20,
berkguler20, cbasdogan}@ku.edu.tr

2Y.A. is with the Department of Electrical and Electronics Engineering,

MEF University, Istanbul, Turkey, 34396 aydiny@mef.edu.tr

Fig. 1. Our pHRI system designed for drilling on a curved surface consists
of a cobot, a drill attached to it, two force sensors, and a Hololens AR
goggle.

the human and the robot (pHRI). In admittance control, the
input is the interaction force between human, robot, and the
environment, and the output is the reference velocity which
the robot is to follow [1], [2].

One of the application areas where pHRI can be used
for improving task efﬁciency is the manufacturing industry.
Robots have been used in industrial settings at an increasing
rate since the 1980s as a result of the improvements in their
capabilities and ease of use [3], [4]. Many large-scale man-
ufacturing tasks have therefore been successfully automated
thanks to these advances in robotics. In the meantime, several
small-batch tasks requiring higher level decision-making and
supervision are still performed by humans. In recent years
though, pHRI has enabled humans to collaborate with robots,
resulting in such tasks being done more efﬁciently [5], [6].
In fact, the number of pHRI studies that focus on im-
proving task performance, practicality, completion time and
ergonomics in manufacturing industries has increased dra-
matically during the last few years [7], [8]. For instance,
Cherubini et al. [9] used pHRI for mitigating muscular pain
in an automotive assembly line. Zhang et al. [10] proposed
a framework for task planning in pHRI settings for mini-
mizing fatigue. Lamon et al. [11] introduced a visuo-haptic
guidance interface for mobile manipulators to understand
human instructions better in manufacturing environments.
Guerin et al. [12] proposed a pHRI framework with different
levels of autonomy for collaborative tasks in manufacturing
settings. Later on, they used a similar framework to make
pHRI more convenient in tasks such as bending metallic
pieces and spot welding, based on predeﬁned sets of robot
capabilities [13]. Ochoa et al. [14] proposed an impedance
control scheme that captured human skills in a glass mold

 
 
 
 
 
 
microdrilling task, then programmed a robot to automate
the drilling. Kana et al. [15] also proposed an impedance
control scheme for pHRI-enabled curve tracing techniques
in edge chamfering and polishing. Perez-Ubeda et al. [16]
used the milling of soft materials as a practical example for
determining the capabilities and limitations of collaborative
robots in machining applications.

Despite many studies on automated robotic drilling in the
literature [17], [18], the number of studies on robotic-assisted
drilling with physical human guidance is limited. However,
fully automated drilling does not always obviate the demands
of numerous realistic scenarios in manufacturing settings
such as opening a hole on a curved piece in which the robot
does not have any prior knowledge of what may be located
beneath the drilling surface with which collision should be
avoided. In another scenario, we have the human trying to
keep a piece of another assembly part on the workpiece and
drill both of them together. Under all such circumstances,
the human operator will not be able to work alongside a
pre-programmed robot. In the meantime, manual drilling,
requiring the stabilization of the workpiece with ﬁxtures,
is time-consuming yet not precise enough. Accounting for
the abovementioned rationales, fusing the human intelligence
and supervision with robot’s robustness and precision is
the key to our concerns. Aydin et al. [19] worked on a
collaborative drilling task by identifying the suitable control
parameters of an admittance controller and adapting them for
a safe and stable operation. Sirintuna et al. [20] utilized a
fractional-order admittance control scheme to better balance
the trade-off between transparency (minimal resistance to the
human) during free motion and stability during drilling with
a cobot. Both of the drilling studies mentioned above only
considered drilling on a ﬂat surface using a single degree of
freedom admittance controller.

In this study, a pHRI system was developed for performing
small-batch manufacturing tasks with haptic guidance of
cobot, visual feedback provided through an AR interface, and
an interaction controller for admittance adaptation. Drilling
holes on a curved surface with a desired angle was selected as
a case study to demonstrate the potential use of the proposed
pHRI system in manufacturing settings (Fig. 1). It is difﬁcult
to open a hole on a curved surface at a custom angle using
a manual drill. On the other hand, even with full knowledge
of drill point location and drilling angle, workpieces with
different curvature and material properties may arrive at
the station in an assembly line, some with protrusions and
cavities, some with sensitive or loose pieces attached to them,
making full automation unfeasible. Hence, we propose to
use a cobot for haptic guidance, weight compensation, and
precise alignment, an augmented reality (AR) interface for
visual guidance, and an adaptive controller for admittance
adaptation to assist the human operator in opening holes on
a curved surface. We therefore aim to fuse the intellectual
capacity of the human (where, at what angle, and how deep
the hole should be drilled, as well as how the robot should
be guided to that location) with the mechanical precision
to execute the task. In our
and robustness of the robot

drilling scenario, the user brings the drill attached to the robot
sufﬁciently close to the target point on the curved surface
utilizing an augmented reality (AR) interface, and then the
robot aligns the drill bit with the selected drilling angle using
the so-called haptic guidance module, allowing the human
to drill the selected hole with exact desired angle by simply
pushing the drill forwards to the target point.

In this work, two sets of human experiments were con-
ducted aiming to evaluate the effectiveness of haptic guid-
ance in task performance, and to assess the user’s will-
ingness to accept the technology, as well as feasibility of
the proposed system. The ﬁrst experiment was conducted
with three naive participants who had no prior experience
with our system. Their drilling task performance under
haptic guidance condition was compared with that of no
haptic guidance condition using some quantitative metrics
including accuracy in drill orientation, task completion time,
and effort made by the operator. In the second experiment,
the focus was on the subjective experience of the user about
the proposed system under haptic guidance condition. This
experiment was performed with three industrial workers who
had extensive experience in drilling. Following the experi-
ments, the participants were asked to ﬁll out a questionnaire
regarding their subjective opinions about the system and its
potential use in real manufacturing environments.

In this study, an adaptive 6-DoF admittance controller is
used for drilling a curved surface. The adaptation mecha-
nism enables a good balance between transparency (minimal
resistance to the human) and stability (see [21], [22], [20]).
It keeps the pHRI system transparent as long as the robot
is driven freely in space. Once it is sufﬁciently close to the
target point (i.e. within a predeﬁned radius), the robot be-
comes stiffer to prevent collision with the curved workpiece
and help the human with the rough alignment of the drill bit.
For the ﬁnal drilling phase, after the robot aligns the drill bit
precisely and conﬁnes the human movement to the desired
drilling axis, the robot becomes even stiffer, to maximize
stability during the drilling to open a hole.

The remainder of this paper is organized as follows:
Section 2 presents our approach including the hardware
components, the control architecture, and the details of our
drilling application. Section 3 presents our ﬁrst experiment,
where we compare the task performance of 3 naive partici-
pants when they perform the drilling task with and without
haptic guidance. Section 4 presents our second experiment,
where we examine the feasibility of deploying the proposed
system in real manufacturing settings based on the subjective
opinion of 3 well-experienced industrial workers. Finally,
Section 5 discusses the experimental results and presents our
ﬁnal remarks.

II. APPROACH

We propose a solution for the task of drilling holes on
curved surfaces with potentially unknown geometries, at
locations marked by the user and for user-deﬁned drilling
angles. To this end, we developed a pHRI system whose

components and their inner workings are explained below in
detail.

A. Hardware

The major hardware components of our system are (1) a
cobot: a 7R, KUKA LBR iiwa 7 R800 robot, (2) a powered
drill: includes a DC motor operable between 0 and 48 Volts,
and a drill bit, (3) two ATI Mini45 force/torque sensors: one
of them is attached between the drill and the robot’s end-
effector, measuring interaction forces applied to it, while the
other is attached between the drill and the handle which is
held by the operator, measuring human force, and (4) an
AR goggle: a Microsoft Hololens augmented reality interface
(Fig. 2).

in the ﬁgure, which include 3 components of force and 3
components of torque, with respect to the three orthogonal
axes.

C. Admittance Controller

We utilize 6 decoupled admittance controllers, one for
each degree of freedom, to regulate the translational and
rotational interactions between the robot and the human.
For each translational degree of freedom, the admittance
controller can be expressed in the Laplace domain as below:

Y (s) =

Vref(s)
Fint(s)

=

1
ms + b

(1)

where Vref(s) is the reference velocity in the Laplace domain
that is given by the controller, and will be followed by the
robot, Fint(s) is the input interaction force in the Laplace
domain, m and b are the admittance mass and damping
respectively, and s is the Laplace variable. A similar rela-
tionship can be written between torque and reference angular
velocity for each rotational degree of freedom as well.

Fig. 2. A closer shot of the hardware components used in our study.

B. Control Loop

The closed-loop control system used in this study is shown
in Fig. 3. Here, G(s) is the transfer function of the robot and
its internal controller, whose output is the actual velocity
of the robot’s end-effector v. The mechanical impedance
of human and environment are shown as Zh(s) and Zenv(s)
respectively. Resultant of the environmental force Fenv and
the force applied by human Fh is the interaction force Fint,
which is sent to the admittance controller Y(s), whose output
is the reference end-effector velocity vref. In Fig. 3, vdes is
the desired velocity of the human operator. When there is
no haptic guidance, the operator has to manually align the
drill with the desired drill orientation. Therefore, switches
S1 and L1 are closed. However, when haptic guidance is
activated, switch S1 and L1 are closed only when driving
the robot
in free space. When the robot reaches the 5-
cm vicinity of the drill target, it locks for the automatic
alignment, at which point switch S1 is opened. During a
4 second interval during which the robot aligns itself with
the desired drilling orientation, the admittance control is
not active. After alignment, switches S1 and L2 are closed,
admittance control is reactivated, and the robot’s motion is
conﬁned to the drilling axis, so that the operator can push
the drill forwards to the drill target to open a hole.

In Fig. 3, all variables are 6D vectors, including three
translational terms and three rotational terms. For example,
the velocity vectors in the ﬁgure are expressed as v =
[vx vy vz ωx ωy ωz](cid:62) where v and ω stand for linear and angular
velocities, respectively. The same applies to wrench vectors

Fig. 3. Closed-loop control system used in our pHRI study.

D. Extracting Surface Information

The scenario explored in this study includes a curved
workpiece with an arbitrary shape arriving at the station,
after which the operator marks a point on it for drilling,
and selects an appropriate drilling angle (not necessarily
perpendicular). In order to open a hole at the marked point
(drill target) with a desired drilling axis, the location of the
drill target and the tangent plane at the drill target must be
known with respect to the base frame of the robot. For this
purpose, a 3D surface mesh model of the workpiece was
obtained by a depth camera ﬁrst and then registered with
the real surface using a virtual tag attached to it (Fig. 1).
Alternatively, the drill target and a few points around it can
be sampled with the tip of the drill bit manually to register
the target location and to estimate the tangent plane at the
target location. Though time consuming and not as accurate
as optical scanning techniques, this approach, which was
tested by us, eliminates the need for a complete 3D surface
mesh model of the curved surface.

E. Haptic Guidance

Using the tangent plane at the drill target, the surface
normal vector can be estimated and a coordinate frame,
whose origin is at the drill target, with one of its axes being

the surface normal and another axis is parallel to the tangent
plane at the target point, can be deﬁned. After deﬁning a
coordinate frame at the target point, any arbitrary drilling axis
can be deﬁned with respect to it. As shown in Fig. 4, a vector
for the drilling axis can be expressed by a pair of polar (φ )
and azimuth (θ ) angles. When the operator selects the desired
angle and brings the drill sufﬁciently close to the drill target
and roughly aligns the drill bit using the visual feedback
provided by the AR interface, the robot can align the drill
bit precisely and quickly with the selected angle. After this
alignment, the user movement (and hence the movement of
the drill bit) is restricted to the drilling vector (axis) only.
The user can then simply push the drill bit forward to open
a hole on the curved surface in a safe manner.

top of the real ones (Fig. 5). In a manufacturing environment
involving a scenario such as ours, it can be difﬁcult for the
operator to remember the steps of the whole task and the
sequence of drill targets. In our implementation, the text and
images displayed through the AR interface guides the user
throughout the task. Furthermore, it can be hard to visualize
how one should roughly align the drill bit in 3D space before
the ﬁnal and precise alignment made by the robot. A white
colored and semi-transparent arrow with its tip pointing to
the drill target is displayed through the AR interface to
help the user with the rough alignment and reduce the task
execution time. Furthermore, the AR interface highlights the
current drill target by displaying a red colored hemisphere
at its location (Fig. 5a). This hemisphere also informs the
operator about how close the drill tip is to the target before
the robot takes over the control for the ﬁner alignment of the
drilling axis.

Fig. 4.
Polar (φ ) and azimuth (θ ) angles are required for deﬁning the
drilling axis. To this end, the surface normal nd and another auxiliary vector
ud normal to it are required for constructing a coordinate system at the drill
target d.

F. Admittance Adaptation

In order to cope with the varying requirements of the
task in its different phases, adaptive admittance control is
utilized in this study. As long as the drill bit is far from
the drill target, low admittance damping is used to keep the
system transparent to human input, so the robot can be driven
faster in free space. To prevent accidental contacts with the
workpiece and help the user roughly align the drill bit in a
more controlled manner, medium admittance damping was
used when drill tip is sufﬁciently close (10 cm) to the target.
Once the drill bit is at the 5-cm vicinity of the target, the
robot
takes over the control and aligns the drilling axis
precisely. After this point, the user is constrained to move
along the drilling axis only under high admittance damping
for maximum stability during drilling to open a hole. It
is noteworthy that transition of damping values follows a
ramp proﬁle with a length of 1 second. Using the analysis
conducted in our earlier work [23] we observed that this will
not lead to instability of the pHRI system. The values used
for admittance damping in this study are tabulated in Table I.

TABLE I
CONTROL PARAMETERS USED IN THE 6D DRILLING EXPERIMENTS.

Phase

Degrees of
Freedom

Free Motion
Close to Target
Drilling

6
6
1

Translational
Mass
[kg]
50
50
50

Translational
Damping
[Ns/m]
100
600
1000

Rotational
Mass
[kgm2]
10
10
–

Rotational
Damping
[Nms]
5
20
–

G. Augmented Reality Interface

The AR interface used in this study assists the operator
during the drilling task by superimposing visual images on

Fig. 5. The visual feedback displayed to the user by the augmented reality
(AR) interface under (a) haptic guidance and (b) no haptic guidance

III. EXPERIMENT I

In this experiment, the goal was to investigate the potential
beneﬁts of haptic guidance in task performance by comparing
it with no guidance condition (i.e. manually aligning the drill
bit with the desired drilling angle). Three naive subjects with
an average age of 29.7 ± 4.6 participated in this experiment.
To monitor the muscle activation levels of participants dur-
ing the task execution, surface electromyography (sEMG)
sensors were attached to their Flexor Carpi muscle. The
procedures for sensor placement and data acquisition are
identical to those presented in [24].

A. Experimental Conditions

There were two experimental conditions in this experi-
ment: 1) haptic guidance by the robot and limited visual
guidance by the AR interface and 2) no haptic guidance by
the robot but more visual guidance by the AR interface with
respect to the ﬁrst condition. Under the second condition,
the participant had to manipulate the drill manually to bring
it to the drill target and align it with the desired drilling
angle. Because there was no automated alignment, the system
was not restricted to 1D motion in the drilling phase, unlike
in the haptic guidance condition (condition 1). Under this
condition, again for giving haptic feedback to the operator
and easing the subtle orientation adjustments, as soon as the

drill bit gets closer than 10 cm to the drilling point, the
damping increases to its high value (b = 1000 Ns/m). This
ensures safe and stable contact interaction with our work-
piece as well. Also, there was no red hemisphere displayed
on top of the drill target in condition 2 since the participants
needed to visually see the exact target location without any
visual obstacles on the way. The white transparent arrow
remained still active under this condition, pointing to the
drill target and showing the axis with which the participants
should align the robot as precisely as they can. Furthermore,
to compensate for the lack of haptic guidance in condition 2,
the orientation errors with respect to the desired azimuth and
polar angles were displayed as horizontal bars, which were
updated in real-time as the user rotated the drill bit. Finally,
two virtual arrows (one for the azimuth angle and one for
polar angle) showed which way the drill needs to be rotated
to get closer to the desired orientation. The values for the
parameters used in this experiment are tabulated in Table II.

B. Protocol

We ﬁrst present the protocol followed by the participants

under the haptic guidance condition below (see Fig. 6).1

1) The participant approaches the robot, and stands on a
marked space on the ground, waiting for the system to
initialize (Fig. 6:1).

2) After being told to do so, the participant grabs the
handle of the robot, and moves the drill bit close
to a red transparent hemisphere shown in the AR
goggle (Fig. 5), while roughly aligning it with a white
transparent arrow (i.e. desired drilling axis) displayed
through the AR interface (Fig. 6:2).

3) When the drill tip touches the red hemisphere, the
robot takes over the control, while the message “Please
do not touch the robot” is displayed to the participant
through the visor of the AR interface. The participant
stands clear of the robot (Fig. 6:3).

4) The robot aligns the drill bit with the drilling axis

automatically in 4 seconds (Fig. 6:4).

5) When the alignment is over and the robot is ready
to be guided towards the target for drilling, the user
is restricted to 1D forwards/backwards movements
along the drilling axis. At
the message
“Continue...” is displayed to the participant.

this point,

6) The participant grabs the handle again and simply
pushes the drill into the workpiece to open a hole.
The haptic guidance provided by the robot keeps the
movement on the drilling axis. After drilling the hole,
the participant retracts the drill out of the workpiece by
moving back along the same axis again (Fig. 6:5-6).
After the ﬁrst point is drilled, the user is ready to go to
the next drilling point. The 6-DoF admittance controller is
reactivated, the hemisphere and arrow are displayed at the
next target location, and the same steps are repeated for the
new drill target.

1A demonstrative video of the proposed system can be found at https:

//www.yusuf-aydin.com/iros-2022-robot-assisted-drilling/

target

to prevent

target only. Moreover,

Under condition 2 (no haptic guidance), the participants
were asked to align the drill manually as accurately as
possible using the white transparent arrow pointing to the
drill
the red hemisphere was not
displayed to the participants through the AR interface at
the drill
the obstruction of their view.
Furthermore, to assist the user during alignment, angular
deviations from the desired drilling angles were displayed
through the AR interface in the form of real-time error bars
as well as guiding arrows which help them correct those
deviations (Fig. 5b). These features (horizontal bars and
guiding arrows) were not displayed to the participants under
haptic guidance condition (Fig. 5a).

Before the actual experiments, participants were given two
training trials, executed with and without haptic guidance, to
familiarize themselves with the setup and the experimental
procedures, without opening a hole on the workpiece. Then,
each participant performed two trials of each condition,
amounting to 4 trials in total; two trials with haptic guidance
and two without haptic guidance.

Fig. 6.
guidance condition.

Steps followed by the participants in Experiment I under haptic

TABLE II
PARAMETERS USED IN EXPERIMENT I.

Item
Control adaptation distance from drill target
Locking distance from the drill target (radius of red hemisphere)
Distance from target after alignment
Autopilot alignment time
First drill target polar angle φ1
First drill target azimuth angle θ1
Second drill target polar angle φ2
Third drill target polar angle φ3
Second and third drill target azimuth angles θ2 and θ3

Value
10
5
5
4
5
0
30
45
10

Unit
cm
cm
cm
sec
deg
deg
deg
deg
deg

C. Results

The quantitative metrics used for comparing the exper-
imental conditions (with and without haptic guidance) are
the following:

• Task completion time, ttot [sec]
• Average linear speed, savg
lin = 1
ttot
• Average angular speed, savg
ang = 1
ttot
• Average Flexor Carpi muscle

||vtool||dt [m/s]

(cid:82) ttot
0
(cid:82) ttot
||ωtool||dt [rad/s]
0
activation, Vavg =

1
ttot

(cid:82) ttot
0 v(t)dt [Volts]

• Human effort caused by forces, EF [J]
• Human effort caused by torques, Eτ [J]
• Total human effort, Etot [J] = EF + Eτ
• Average alignment error, ε avg

azimuth angle [deg]

for polar, and ε avg

for

θ

φ

and ε avg

lin (savg

Task completion time ttot refers to the entire time span of a
drilling session where the participant has to use the robot and
the AR interface to drill 3 holes on the curved surface. Since
it takes 4 seconds per hole (Table II) for the robot to align
the drill to the desired orientation under the haptic guidance
condition, a total of 12 seconds was spent by the robot for
the alignment process. Linear (angular) Speed savg
ang) is
simply the mean magnitude of the linear (angular) velocity
vector vtool (ωtool) of the drill bit throughout one full session.
Average alignment errors ε avg
are calculated at
φ
the time of drilling, just before the drilling starts, for every
one of the three points. This metric is obviously close to
zero when the haptic guidance is enabled since the robot
automatically brings the drill to the desired orientation. To
calculate the total human effort, Etot, ﬁrst, each component
of the wrench vector, Fh = [F x
h], is mul-
tiplied with the corresponding component of the velocity
vector, v = [vx, vy, vz, ωx, ωy, ωz], and sum of the absolute
value of aforementioned element-wise products are computed
which gives us the instantaneous human power. Ultimately,
this instantaneous power is integrated over time, Etot =
(cid:82)
t ∑6
(cid:12) dt. Average muscle activation Vavg is simply the
mean activation level of the Flexor Carpi muscle as measured
by the sEMG sensors, throughout the trial.

(cid:12)
hvi(cid:12)
(cid:12)F i

h , F y

h , F z

h, τ y

h , τ x

h, τ z

i=1

θ

Fig. 7 shows the average task performances of the par-
ticipants under both experimental conditions based on the
aforementioned metrics. To test the null hypothesis, one-
way ANOVA (Analysis of Variance) with repeated measures

Fig. 7.
Performance metrics for Experiment I, with and without haptic
guidance (labeled as “WH” and “WOH” respectively). Vertical bars show
population means, and vertical lines show 95% conﬁdence intervals. Hor-
izontal lines with asterisks on top show statistically signiﬁcant pairwise
comparisons with p = 0.05 as the threshold.

φ

θ

was performed by considering the experimental conditions
(with/without haptic guidance) as the main factor. According
to the ANOVA results, the effect of the experimental condi-
tions was signiﬁcant on human effort (the middle column
in Fig. 7) and average alignment errors (ε avg
and ε avg
).
Speciﬁcally, both linear and angular components of the
human effort were signiﬁcantly lower under haptic guidance.
The alignment errors were between 3◦ and 16◦ without haptic
guidance. According to Fig. 7, average speeds, savg
lin and savg
ang,
are generally higher under haptic guidance (though the differ-
ence between the conditions is not statistically signiﬁcant),
leading to a lower task completion time ttot. The same applies
to average muscle activation Vavg, whose population mean is
lower under haptic guidance, but the difference between the
conditions is not statistically signiﬁcant. A large amount of
variance can be observed in task completion time ttot in Fig.
7 when not using haptic guidance since the whole alignment
is done manually by the participant, and the time it takes to
do the alignment can vary considerably between the trials of
the same participant and also between the participants.

IV. EXPERIMENT II

In this experiment,

the objective was to examine the
acceptability of the proposed pHRI system and the drilling
scenario,
if deployed in real manufacturing settings and
used by real industrial workers. For this reason, three in-
dustrial workers with extensive experience in small-batch
manufacturing tasks including drilling were invited to our
lab for experimentation. They were asked to open holes on
the curved surface under haptic guidance condition only.
The target locations and drilling angles were the same as
the ones used in Experiment I (Table II). Following the
experiment, the participants were asked to ﬁll out a detailed
questionnaire designed to acquire their subjective opinions
about
the developed system and its applicability in real
manufacturing settings.

A. Protocol

The protocol followed in this experiment is identical to the
one mentioned in Section 3 for the haptic guidance condition.
After the training, every participant performed one trial (3
holes) of the experiment under haptic guidance only.

B. Questionnaire

Methods suggested by [25], [26] were utilized for de-
signing a subjective questionnaire2 that utilizes a 7-point
Likert scale for collecting the personal opinions of the
participants about the developed pHRI system. A series of
statements were put forth in the questionnaire, with which
the participants can specify to what extent they agree. The 7-
point Likert scale varied from a scale of 1 (strongly disagree)
to 7 (strongly agree). The statements were arranged in a ﬁxed
but shufﬂed order, and asked twice with different wordings,
meaning every statement also has a paraphrased opposite pair
in the questionnaire.

2Full text of the questionnaire can be found at https://www.yusuf-aydin.

com/iros-2022-robot-assisted-drilling/#questionnaire

In the ﬁrst part of the questionnaire, demographic data
were collected from the participants about their gender, age,
and years of work experience in the manufacturing industry.
This section also included a question asking whether the
participant believes drilling holes on a curved surface using
a manual drill is difﬁcult, and if so, why.

In the second section of the questionnaire, ﬁrst, four
general questions were asked about how much prior expe-
rience the participant had with mechanical tools (such as
screwdrivers, chain saws, etc.), robots, and AR/VR interfaces
in general. Then, 11 questions about our pHRI system and
3 questions about our AR interface were asked in particular,
along with their opposite pairs. Therefore, this section of
the questionnaire included a total of 2 × (11 + 3) + 4 = 32
questions. The questions in this section were related to the
following topics:

• Personal prior experience with: non-motorized de-
vices (hammer, screwdriver, etc.), motorized devices
(drill, chain saw, polisher, etc.), robotic arms, aug-
mented/virtual reality interfaces

• Using the robot in the experiments: Overall task suc-
cess, ease of use, being in control, task performance,
trust, feeling natural, enjoyment, safety, fear, exhaustion,
willingness to use again

• Using the AR interface in the experiments: Ease of use,

enjoyment, and utility (helpfulness)

Fig. 8.
means and vertical lines indicate standard deviations.

Subjective questionnaire results in Experiment II. Bars indicate

C. Results

1) Personal Background: The average age of the workers
was 31.67 ± 8.62 years. They had 15.67 ± 9.02 years
of experience in the manufacturing industry. None of the
participants stated that they encountered any problem during
the experiments. 2 out of the 3 participants stated that drilling
holes on curved surfaces with custom drilling angles is
hard because it is difﬁcult to manually align a drill to a
deﬁned orientation by hand. All 3 participants stated that they
had extensive experience with non-motorized and motorized
mechanical devices (Strongly Agree; 7.0/7.0). The average
Likert score for experience with robotic arms was 6.7/7.0,
the participants had worked with robotic
indicating that
arms before. The mean score for prior experience with AR
interfaces was 3.7/7.0. The participants later indicated that
they became familiar with AR/VR interfaces as they have
attended technical fairs and exhibits.

2) Subjective Questionnaire: Fig. 8 shows the mean re-
sponses of the 3 participants to the questions. Despite low
scores occasionally, all questions were scored higher than
5.0/7.0 on average by the participants, suggesting that they
generally had a positive opinion about our pHRI system.

According to the results shown in Fig. 8, the participants
on average found the robot easy to use, safe, convenient, and
natural. They were not afraid of using the robot, and were
willing to use it again. The questions about the AR interface
received scores on average higher than 6.0/7.0, suggesting
that the participants found the AR goggle to be user-friendly,
and helpful in carrying out the task.

V. DISCUSSION AND CONCLUSION

In this study, a pHRI system was developed to per-
form small-batch manufacturing tasks efﬁciently using haptic
guidance, an AR interface, and an adaptive admittance con-
troller. As a case study, collaborative drilling of holes on a
curved surface was selected. The proposed system provides
haptic guidance to the user by constraining the user’s move-
ment to the drilling axis and visual guidance through the AR
interface for the steps of the drilling task and rough alignment
of the drill bit to the desired angle. Furthermore, the damping
parameter of the admittance controller that regulates the
interaction between the robot and the human was adapted
based on the instantaneous position of drill tip with respect
to the location of drill target. During the free motion, in
which the user brings the drill to the 5-cm vicinity of target
point, low admittance damping was utilized so that the robot
showed minimal resistance to the human. On the other hand,
high admittance damping was used during the drilling phase
for stable and safe operation.

The beneﬁts of haptic guidance were investigated in
Experiment I by comparing the task performance of the
participants with and without haptic guidance. In order to
compensate for the lack of haptic guidance under no haptic
guidance condition, more visual guidance was provided to
the participants through the AR interface. Since the partic-
ipants manually adjusted the drill bit by themselves under
no haptic guidance condition, the angular deviations of drill
bit from the desired drill orientation were displayed through
the AR interface and guiding arrows were used to help the
participant make corrections for those deviations.

The results of Experiment I showed that the task perfor-
mance under haptic guidance was superior to that of the
no haptic guidance condition. Fig. 9 presents the relative
differences in percentage between the performance metrics
of the two conditions. According to this ﬁgure, the haptic
guidance condition led to 26% shorter task completion
time, and 16% less human effort. Furthermore, 27% less
muscle activation was observed in the participants under the
haptic guidance condition, suggesting that haptic guidance
could potentially improve the ergonomics in pHRI tasks by
decreasing the chances of muscular fatigue in the users.

The focus of Experiment II was to test the potential use
of the proposed system in real manufacturing environments
based on the subjective opinions of industrial workers. For

[8] Y. Hu, M. Benallegue, G. Venture, and E. Yoshida, “Interact with me:
An exploratory study on interaction factors for active physical human-
robot interaction,” IEEE Robotics and Automation Letters, vol. 5, no. 4,
pp. 6764–6771, 2020.

[9] A. Cherubini, R. Passama, A. Crosnier, A. Lasnier, and P. Fraisse,
“Collaborative manufacturing with physical human-robot interaction,”
Robotics and Computer-Integrated Manufacturing, vol. 40, pp. 1–13,
2016.

[10] M. Zhang, C. Li, Y. Shang, and Z. Liu, “Cycle time and human
fatigue minimization for human-robot collaborative assembly cell,”
IEEE Robotics and Automation Letters, pp. 1–1, 2022.

[11] E. Lamon, F. Fusaro, P. Balatti, W. Kim, and A. Ajoudani, “A visuo-
haptic guidance interface for mobile collaborative robotic assistant
(moca),” in 2020 IEEE/RSJ International Conference on Intelligent
Robots and Systems (IROS), 2020, pp. 11 253–11 260.

[12] K. R. Guerin, S. D. Riedel, J. Bohren, and G. D. Hager, “Adjutant:
A framework for ﬂexible human-machine collaborative systems,” in
2014 IEEE/RSJ International Conference on Intelligent Robots and
Systems, 2014, pp. 1392–1399.

[13] K. R. Guerin, C. Lea, C. Paxton, and G. D. Hager, “A framework for
end-user instruction of a robot assistant for manufacturing,” in 2015
IEEE International Conference on Robotics and Automation (ICRA),
2015, pp. 6167–6174.

[14] H. Ochoa and R. Cortes˜ao, “Impedance control architecture for
robotic-assisted micro-drilling tasks,” Journal of Manufacturing Pro-
cesses, vol. 67, pp. 356–363, 2021.

[15] S. Kana, S. Lakshminarayanan, D. M. Mohan, and D. Campolo,
“Impedance controlled human–robot collaborative tooling for edge
chamfering and polishing applications,” Robotics and Computer-
Integrated Manufacturing, vol. 72, p. 102199, 2021.

[16] R. Perez-Ubeda, S. Gutierrez, R. Zotovic, and J. Lluch-Cerezo,
“Study of the application of a collaborative robot for machining
tasks,” Procedia Manufacturing, vol. 41, pp. 867–874, 2019, 8th
Manufacturing Engineering Society International Conference, MESIC
2019, 19-21 June 2019, Madrid, Spain. [Online]. Available: https:
//www.sciencedirect.com/science/article/pii/S2351978919311710
[17] A. Frommknecht, J. Kuehnle, I. Effenberger, and S. Pidan, “Multi-
robotic drilling,” Robotics and

sensor measurement system for
Computer-Integrated Manufacturing, vol. 47, pp. 4–10, oct 2017.
[18] Y. Bu, W. Liao, W. Tian, J. Zhang, and L. Zhang, “Stiffness analysis
and optimization in robotic drilling application,” Precision Engineer-
ing, vol. 49, pp. 388–400, jul 2017.

[19] Y. Aydin, D. Sirintuna, and C. Basdogan, “Towards collaborative
drilling with a cobot using admittance controller:,” Transactions of the
Institute of Measurement and Control, vol. 43, no. 8, pp. 1760–1773,
jul 2020.

[20] D. Sirintuna, Y. Aydin, O. Caldiran, O. Tokatli, V. Patoglu, and
C. Basdogan, “A variable-fractional order admittance controller for
pHRI,” in IEEE International Conference on Robotics and Automation,
2020, pp. 10 162–10 168.

[21] Y. Aydin, O. Tokatli, V. Patoglu, and C. Basdogan, “Stable physical
human-robot interaction using fractional order admittance control,”
IEEE Transactions on Haptics, vol. 11, no. 3, pp. 464–475, 2018.

[22] ——, “A computational multicriteria optimization approach to con-
troller design for physical human-robot interaction,” IEEE Transac-
tions on Robotics, vol. 36, no. 6, pp. 1791–1804, dec 2020.

[23] B. Guler, P. P. Niaz, A. Madani, Y. Aydin, and C. Basdogan,
“An adaptive admittance controller for collaborative drilling with
robot based on subtask classiﬁcation via deep learning,”
a
Mechatronics, vol. 86, p. 102851, 2022. [Online]. Available: https:
//www.sciencedirect.com/science/article/pii/S0957415822000800
[24] D. Sirintuna, I. Ozdamar, Y. Aydin, and C. Basdogan, “Detecting
human motion intention during pHRI using artiﬁcial neural networks
trained by EMG signals,” in 29th IEEE International Conference on
Robot and Human Interactive Communication, RO-MAN 2020, 2020,
pp. 1280–1287.

[25] C. Basdogan, C. H. Ho, M. A. Srinivasan, and M. Slater, “An Exper-
imental Study on the Role of Touch in Shared Virtual Environments,”
ACM Transactions on Computer-Human Interaction, vol. 7, no. 4, pp.
443–460, dec 2000.

[26] A. Kucukyilmaz, T. M. Sezgin, and C. Basdogan, “Intention recog-
nition for dynamic role exchange in haptic collaboration,” IEEE
Transactions on Haptics, vol. 6, no. 1, pp. 58–68, 2013.

Fig. 9. Percent relative difference in the performance metrics of the partici-
pants under the experimental conditions of with and without haptic guidance
in Experiment I. The negative (positive) values in the plot indicate decrease
(increase) in the metrics of haptic guidance condition with respect to the
no haptic guidance condition. Vertical bars show average differences among
the three subjects, and vertical lines indicate their standard deviations.

this reason, Experiment II was conducted with 3 industrial
workers who had extensive experience in performing small-
batch tasks such as drilling. The results of Experiment II
showed that the workers found the system easy to use and
helpful in carrying out the drilling task. Also, the results
showed that they enjoyed the system, felt safe and successful,
and were willing to use it again.

For future work, a depth camera can be attached to the
robot for extracting surface information locally only rather
than for the whole surface, as was done in our study. More-
over, the workpiece could be tracked in real time, thereby
eliminating the need to rigidly ﬁx it in place. Consequently,
a signiﬁcant amount of time can be saved when working on
a part with unknown geometry held in human hand.

ACKNOWLEDGMENT

A.M., P.P.N., and B.G. acknowledge the research fellow-
ship provided by the KUIS AI-Center. The authors would
like to thank the project’s partner company, As-Metal Inc.,
for providing the curved workpieces used in both experi-
ments and the industrial workers participated in the second
experiment.

REFERENCES

[1] V. Duchaine and C. M. Gosselin, “General model of human-robot
cooperation using a novel velocity based variable impedance control,”
in Second Joint EuroHaptics Conference and Symposium on Haptic
Interfaces for Virtual Environment and Teleoperator Systems, World
Haptics 2007, 2007, pp. 445–451.

[2] V. Duchaine and C. Gosselin, “Safe, stable and intuitive control
for physical human-robot interaction,” in 2009 IEEE International
Conference on Robotics and Automation.
IEEE, 2009, pp. 3383–
3388.

[3] C. Heyer, “Human-robot interaction and future industrial robotics ap-
plications,” in IEEE/RSJ 2010 International Conference on Intelligent
Robots and Systems, IROS 2010.

IEEE, 2010, pp. 4749–4754.

[4] M. Ben-Ari and F. Mondada, Elements of robotics (robots and their

applications), 2017.

[5] A. Ajoudani, A. Zanchettin, S.

Ivaldi, A. Albu-sch¨affer, and
K. Kosuge, “Progress and prospects of the human-robot collaboration,”
Autonomous Robots, vol. 42, pp. 957–975, 2018. [Online]. Available:
https://doi.org/10.1007/s10514-017-9677-2

[6] M. Selvaggio, M. Cognetti, S. Nikolaidis, S. Ivaldi, and B. Siciliano,
“Autonomy in physical human-robot interaction: A brief survey,” IEEE
Robotics and Automation Letters, vol. 6, no. 4, pp. 7989–7996, oct
2021.

[7] E. Matheson, R. Minto, E. G. G. Zampieri, M. Faccio, and G. Rosati,
collaboration in manufacturing applications: A
[Online]. Available:

“Human–robot
review,” Robotics, vol. 8, no. 4, 2019.
https://www.mdpi.com/2218-6581/8/4/100

