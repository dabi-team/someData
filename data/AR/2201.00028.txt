1
2
0
2

c
e
D
1
3

]
E
M

.
t
a
t
s
[

1
v
8
2
0
0
0
.
1
0
2
2
:
v
i
X
r
a

The validity of bootstrap testing in the threshold
framework

Simone Giannerini1, Greta Goracci1,2, and Anders
Rahbek3

1Department of Statistical Sciences, University of Bologna, Italy
2Faculty of Economics and Management, Free University of
Bozen-Bolzano, Italy
3Department of Economics, University of Copenhagen, Denmark

January 4, 2022

Abstract

We consider bootstrap-based testing for threshold eﬀects in non-linear
threshold autoregressive (TAR) models. It is well-known that classic tests
based on asymptotic theory tend to be oversized in the case of small, or
even moderate sample sizes, or when the estimated parameters indicate
non-stationarity, as often witnessed in the analysis of ﬁnancial or climate
data. To address the issue we propose a supremum Lagrange Multiplier
test statistic (sLMb), where the null hypothesis speciﬁes a linear autore-
gressive (AR) model against the alternative of a TAR model. We consider
a recursive bootstrap applied to the sLMb statistic and establish its valid-
ity. This result is new, and requires the proof of non-standard results for
bootstrap analysis in time series models; this includes a uniform bootstrap
law of large numbers and a bootstrap functional central limit theorem.
These new results can also be used as a general theoretical framework
that can be adapted to other situations, such as regime-switching pro-
cesses with exogenous threshold variables, or testing for structural breaks.
The Monte Carlo evidence shows that the bootstrap test has correct em-
pirical size even for small samples, and also no loss of empirical power
when compared to the asymptotic test. Moreover, its performance is not
aﬀected if the order of the autoregression is estimated based on informa-
tion criteria. Finally, we analyse a panel of short time series to assess the
eﬀect of warming on population dynamics.

1

Introduction

The problem of testing for a linear time series model versus its threshold ex-
tension has attracted considerable attention for a number of reasons. First

1

 
 
 
 
 
 
and foremost, threshold autoregressive models (TAR) are among the simplest
nonlinear speciﬁcations and retain a good interpretability. Second, they can en-
compass many complex features such as jumps, limit-cycles, time irreversibility
and chaos, see e.g. Tong [1990, 2011]. Petruccelli [1992] proved that TAR mod-
els approximate a wide range of nonlinear autoregressive processes. Moreover,
they have been proven to describe successfully many real-world phenomena in
economics and ﬁnance, see e.g. Chan et al. [2017], Hansen [2011], Tong [2017].
For population biology and climate studies see e.g. Stenseth et al. [1998], Yao
et al. [2000].

Seminal works on asymptotic quasi-likelihood ratio tests for threshold au-
toregression include Chan [1990], Chan and Tong [1990], Chan [1991]. Other
contributions include those of Petruccelli and Davies [1986], Su and Chan [2017]
and that of Tsay [1998] for the multivariate case. Tests based upon Lagrange
Multipliers were proposed in Luukkonen et al. [1988] for the smooth transi-
tion case and Wong and Li [1997, 2000] for TAR models with conditional het-
eroscedasticity, see also Tong [2011] for a review.

The main theoretical problem associated with testing for threshold autore-
gression is the nuisance parameter (the threshold) being present only under the
alternative hypothesis, as adduced in Davies [1977, 1987] and Andrews [1993].
In the present context, one solution is to derive the test statistic as a random
function of the nuisance parameter. Then, the overall test statistic is the supre-
mum (or some other convenient function) of the statistic over the grid of values
of the nuisance parameter. The derivation of the null distribution of the overall
test statistic requires proving the stochastic equicontinuity (tightness) of the
sequence of random functions, see e.g. van der Vaart [1998], and this is often
the most challenging task.

One key issue with asymptotic tests is the sample size requirement to deliver
a good performance. Typically, the rate of convergence towards the asymptotic
null distribution depends upon the true parameters values of the data gener-
ating process and might produce a size bias that can be severe, for instance
when the processes are close to non-stationarity and/or non-invertibility, see
e.g. Goracci et al. [2021]. Furthermore, the null distribution, which has no
closed analytical form, depends both upon the threshold range and the number
of tested parameters, so that one has to make use of simulated critical values for
each combination of the threshold grid and number of parameters, see Andrews
[2003]. One way to overcome the aforementioned problems is to resort to resam-
pling methods. Hansen [1996] proposes tests based on a stochastic permutation
device where the score function is randomly perturbed through an auxiliary
random variable. The same approach has been deployed in Li and Li [2011] to
test a linear model against its threshold ARMA extension by means of a quasi
likelihood ratio statistic. More recently, Hill [2021] adopts a similar approach
to introduce robust conditional moment tests of omitted nonlinearity. To the
best of our knowledge, to date, there are no available results on the validity of
the classical bootstrap (both parametric and nonparametric) for testing a linear
AR model against a TAR model.

In this paper we ﬁll this gap and provide a proof of the validity of the

2

In particular, we consider a supremum
test based on a residual bootstrap.
Lagrange Multiplier test statistic (sLMb) where the null hypothesis speciﬁes
a linear AR(p) model against the alternative of a TAR(p) model. One of the
main advantages of Lagrange multiplier tests over likelihood ratio tests is that
the former only need estimating the model under the null hypothesis and avoid
direct estimation of the TAR model.

We prove that, under the null hypothesis, the bootstrap distribution of the
test statistic coincides with the asymptotic distribution derived in Chan [1990]
for the likelihood ratio test, namely, a functional of a centered Gaussian process.
Note that, as also shown for instance in Hansen [1996], the Wald, the supLM
and the likelihood-ratio test statistics share the same asymptotic distribution.
The inherent diﬃculties associated with working in the bootstrap framework,
i.e. simultaneously coping with the two kinds of randomness (the ﬁrst one is
the sampling variability and the second one is the bootstrap variability) are
ampliﬁed by the discontinuity of the threshold function and the absence of
the nuisance parameter under the null hypothesis. To this end, we provide
a uniform bootstrap law of large numbers and a functional bootstrap central
limit theorem that can be used as a general theoretical framework that can be
adapted to other situations, such as regime-switching processes with exogenous
threshold variables or testing for structural breaks.

The simulation study shows that the bootstrap test (sLMb) has a correct
empirical size for a series’ length as small as 50, even when the data generating
process is close to non-stationarity, a situation that produces a severe oversize
in the asymptotic version of the test. Moreover, the behaviour of the bootstrap
test is not inﬂuenced by treating the order of the tested process as unknown
and estimating it by means of the AIC. Again, this is not the case with the
asymptotic test, which results oversized. The good performance of the bootstrap
test in small samples makes it applicable to many applied situations where
either data collection/production is expensive, as in the experimental context,
or longer series are simply not available, as in e.g. Yao et al. [2000].

We apply our test to a panel of 12 short time series of populations of larvae of
the pyralid moth Plodia interpunctella under diﬀerent experimental conditions.
The data come from Laughton and Knell [2019a] where the aim was to assess
the eﬀect of warming, which is one of the consequences of climate change, in
connection to age structure, density, and generation cycles. We ﬁnd a signiﬁcant
threshold eﬀect and an appropriate speciﬁcation that accounts for the 6-week
characteristic asymmetric cycle.

The rest of the paper is organised as follows. Section 2 introduces the prob-
In
lem and describes the theory behind the standard asymptotic sLM test.
Section 3 we present the bootstrap version of the test, together with the main
results on its validity. Section 4 shows the ﬁnite sample behaviour of the tests
where our bootstrap test (sLMb) is compared to the asymptotic test (sLMa),
also when the order of the tested process is unknown and has to be estimated.
Section 5 is devoted to the real application. All the proofs are detailed in Sec-
tion 6.

3

1.1 Notation

We write P ∗(·), E∗[·] to indicate probability and expectation conditional on
the data, respectively; w∗
denotes the weak convergence in probability and

−−−−→
n→∞ p

Y or, equivalently, Y ∗

n − Y = op∗ (1), means that, for any δ > 0,

Y ∗
n

p∗
−−−−→
n→∞ p

p
−−−−→
n→∞

n − Y (cid:107) > δ)

P ∗((cid:107)Y ∗
0; lastly, Y ∗
n = Op∗ (1) means that, for any δ > 0,
there exists M > 0 such that P (P ∗((cid:107)Y ∗
n (cid:107) > M ) < δ) is arbitrarily close to one
for suﬃciently large n. Here, (cid:107) · (cid:107) is the L2 matrix norm (the Frobenius’ norm,
j=1 |aij|2, where A is a n × m matrix); (cid:107)A(cid:107) = (E[A]r)1/r
i.e. (cid:107)A(cid:107) =
is the Lr norm of a random matrix. Moreover, let DR(a, b), a < b be the space
of functions from (a, b) to R that are right continuous with left-hand limits.

(cid:113)(cid:80)n

(cid:80)m

i=1

2 Preliminaries

Let the time series {Xt} follow the threshold autoregressive TAR(p) model
deﬁned by the diﬀerence equation:

Xt = φ0 +

(cid:32)

φiXt−i +

Ψ0 +

p
(cid:88)

i=1

p
(cid:88)

i=1

(cid:33)

ΨiXt−i

I(Xt−d ≤ r) + εt.

(1)

The positive integers p and d are the autoregressive order and the delay pa-
rameter, respectively; we assume p and d to be known. Moreover I(·) indicates
the indicator function and r ∈ R is the threshold parameter. The innova-
tions {εt} are independent and identically distributed (iid) with E[εt] = 0 and
E[ε2
t ] = σ2 < ∞. For each t, εt is independent of Xt−1, Xt−2, . . . . Clearly,
Eq. (1) speciﬁes a regime-switching process where each regime follows a linear
autoregressive process. The parameters are given by

φ = (φ0, φ1, . . . , φp)(cid:124) ∈ Θφ;
Ψ = (Ψ0, Ψ1, . . . , Ψp)(cid:124) ∈ ΘΨ;
η = (φ(cid:124), Ψ(cid:124), σ2)(cid:124) ∈ Θ = Θφ × ΘΨ × (0, +∞),

with Θφ and ΘΨ being subsets of Rp+1. We use η = (φ(cid:124), Ψ(cid:124), σ2)(cid:124) to refer to
unknown parameters, whereas the true parameters are indicated by

(cid:124)
0 , Ψ
η0 = (φ

(cid:124)
0 , σ2

0)(cid:124) = (φ0,0, φ0,1, . . . , φ0,p, Ψ0,0, Ψ0,1, . . . , Ψ0,p, σ2

0)(cid:124).

We test whether the TAR model ﬁts the data signiﬁcantly better than its linear
counterpart. As Ψ contains the diﬀerences of the autoregressive parameters in
the two regimes, the system of hypotheses reduces to

(cid:40)

H0
H1

: Ψ = 0
: Ψ (cid:54)= 0,

4

where 0 is the vector of zeros. Suppose we observe {Xt, t = 1, . . . , n}. We
develop the Lagrange Multiplier (hereafter LM) test based on the quasi Gaussian
log-likelihood conditional on the initial values X0, X−1, . . . , X−p+1:

(cid:96)n(η, r) = −

1
2σ2

n
(cid:88)

t=1

ε2
t (η, r),

(2)

where

(cid:40)

εt(η, r) = Xt −

φ0 +

(cid:41)

(cid:40)

φiXt−i

−

Ψ0 +

p
(cid:88)

i=1

p
(cid:88)

i=1

(cid:41)

ΨiXt−i

I (Xt−d ≤ r) .

(3)

Under the null hypothesis, model (1) reduces to an AR(p) model:

p
(cid:88)

Xt = φ0 +

φiXt−i + εt,

(4)

i=1
and let ˜φ = ( ˜φ0, ˜φ1, . . . , ˜φp)(cid:124) be the Maximum Likelihood Estimator (hereafter
MLE) of the autoregressive parameters in Eq. (4) based upon the Gaussian
likelihood, i.e.:

˜φ = argmin
φ∈Θφ

−

1
2σ2

n
(cid:88)

t=1

t ((φ, 0, σ2), r).
ε2

The associated residuals (restricted residuals) are

˜εt = Xt − ˜φ0 −

p
(cid:88)

i=1

˜φiXt−i = (φ0,0 − ˜φ0) +

p
(cid:88)

(φ0,i − ˜φi)Xt−i + εt.

i=1

Moreover, σ2 is estimated by

˜σ2 =

1
n − p − 1

n
(cid:88)

t=1

˜ε2
t .

(5)

(6)

Lastly, deﬁne ˜η = ( ˜φ
hypothesis.

(cid:124)

, 0(cid:124), ˜σ2), i.e. ˜η is the resticted MLE under the null

In order to test the null hypothesis deﬁne:

∂ ˜(cid:96)n
∂η

(r) =

(cid:32)

∂ ˜(cid:96)n
∂φ

,

∂ ˜(cid:96)n
∂Ψ

(cid:33)

(r)

=

∂(cid:96)n(η, r)
∂η

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)η=˜η

i.e. the score function, evaluated at the restricted estimators. The supremum
Lagrange multipliers test statistic (hereafter supLM) is

Tn = sup

Tn(r),

r∈[rL,rU ]

where

Tn(r) =

(cid:32)

∂ ˜(cid:96)n
∂Ψ

(cid:33)(cid:124)

(r)

(cid:0)In,22(r) − In,21(r)I −1

n,11In,12(r)(cid:1)−1 ∂ ˜(cid:96)n

∂Ψ

(7)

(r)

(8)

5

with [rL, rU ] being a data driven interval, e.g. rL and rU can be some percentiles
of the observed data. Deﬁne the information matrix as follows:

In(r) =

(cid:18) In,11
In,21(r)

(cid:19)

In,12(r)
In,22(r)

:=

(cid:32)

− ∂2(cid:96)n(η,r)
∂φ∂φ(cid:124)
− ∂2(cid:96)n(η,r)
∂Ψ∂φ(cid:124)

− ∂2(cid:96)n(η,r)
∂φ∂Ψ(cid:124)
− ∂2(cid:96)n(η,r)
∂Ψ∂Ψ(cid:124)

(cid:33)

,

and

I∞(r) =

(cid:18) I∞,11
I∞,21(r)

(cid:19)

I∞,12(r)
I∞,22(r)

(9)

(10)

where I∞,22(r) = I∞,12(r) = I
whose (i + 1, j + 1)th element is

(cid:124)
∞,21(r) are (p + 1) × (p + 1) symmetric matrices

E[I(Xt−d ≤ r)],
E[Xt−jI(Xt−d ≤ r)],
E[Xt−iXt−jI(Xt−d ≤ r)],

if i = 0, j = 0

if i = 0, j (cid:54)= 0

if i (cid:54)= 0, j (cid:54)= 0

and I∞,11 = I∞,22(∞). Here and in the following, P (·) and E[·] are, respectively,
the probability and expectation taken under the true probability distribution
for which the null hypothesis holds. As in Chan [1990], the null distribution
of the supLM test statistic is a functional of the centered Gaussian process
{ξ(r), r ∈ R} with covariance kernel

Σ(r1, r2) = σ−2

0

(cid:8)I∞,22(r1 ∧ r2) − I∞,21(r1)I −1

∞,11I∞,12(r2)(cid:9) ,

where a1 ∧ a2 = min{a1, a2}, for any a1, a2 ∈ R. Under standard regularity
conditions as in Chan [1990], it holds that

Tn

w−−−−→
n→∞

sup
r∈[rL,rU ]

ξ(r)(cid:124)Σ(r, r)−1ξ(r) := T∞,

(11)

means the convergence in distribution as the sample size n in-

where
creases.

w−−−−→
n→∞

3 The bootstrap

We focus on the following residual-based bootstrap approach. Let {ε∗
t } be sam-
pled with replacement from the re-centred residuals ˜εc
t=1 ˜εt,
where ˜εt are deﬁned in Eq. (5). Consider the recursively deﬁned bootstrap
process generated by the bootstrap parameters φ∗ = (φ∗

t := ˜εt − n−1 (cid:80)n

0, φ∗

1, . . . , φ∗

p)(cid:124):

X ∗

t = φ∗

0 +

p
(cid:88)

i=1

i X ∗
φ∗

t−i + ε∗
t ,

(12)

where the initial values X ∗
−p+1, are equal to the sample counterpart.
We consider the case where the bootstrap parameters are the restricted MLE,

1 , . . . , X ∗

0 , X ∗

6

i.e. φ∗ = ˜φ; therefore the process deﬁned in Eq. (12) equals:

X ∗

t = ˜φ0 +

p
(cid:88)

i=1

˜φiX ∗

t−i + ε∗
t ,

(13)

which is an example of the so-called restricted bootstrap, see Cavaliere and
Rahbek [2021]. Given the bootstrap sample in Eq. (13), {X ∗
t , t = 1, . . . , n}, the
bootstrap log-likelihood function results:

(cid:96)∗
n(η, r) = −

1
2σ2

n
(cid:88)

t=1

ε∗2
t (η, r),

(14)

where ε∗

t (η, r) is deﬁned as in Eq. (3) with X being replaced by X ∗:
(cid:41)

(cid:40)

(cid:40)

(cid:41)

t (η, r) = X ∗
ε∗

t −

φ0 +

φiX ∗

t−i

−

Ψ0 +

ΨiX ∗

t−i

I (cid:0)X ∗

t−d ≤ r(cid:1) .

p
(cid:88)

p
(cid:88)

i=1

i=1

(15)

Moreover, let D∗
to η. It follows that:

t (r) denote the ﬁrst-order derivative of ε∗

t+1(η, r) with respect

D∗

t (r) = (cid:0)−1, −X ∗
t I(X ∗
−X ∗

t−p+1, −I(X ∗

t , . . . , −X ∗
t−d+1 ≤ r), . . . , −X ∗

t−d+1 ≤ r),

t−p+1I(X ∗

t−d+1 ≤ r)(cid:1)(cid:124)

.

(16)

Similar to Eq. (9), the bootstrap observed information matrix is deﬁned by:

I ∗
n(r) =

=

(cid:19)

(cid:18) I ∗
n,11
I ∗
n,21(r)
− ∂2(cid:96)∗
− ∂2(cid:96)∗

(cid:32)

n(η,r)

∂φ∂φ(cid:124)

n(η,r)

∂Ψ∂φ(cid:124)

I ∗
n,12(r)
I ∗
n,22(r)
− ∂2(cid:96)∗
− ∂2(cid:96)∗

n(η,r)

∂φ∂Ψ(cid:124)

n(η,r)
∂Ψ∂Ψ(cid:124)

(cid:33)

=

1
σ∗2

n
(cid:88)

t=1

D∗

t−1(r)D∗(cid:124)

t−1(r).

(17)

0, ˜φ∗

= ( ˜φ∗

p) be the MLE computed upon {X ∗

∗
Let ˜φ
1, . . . , ˜φ∗
in Eq. (12) and ˜σ∗2 = (n−p−1)−1 (cid:80)n−p−1
bootstrap restricted residuals.
we deﬁne ˜η∗ = ( ˜φ
bootstrap loglikelihood function in Eq. (14). Let

t , t = 1, . . . , n} deﬁned
t being the corresponding
In analogy with standard asymptotic theory,
, 0(cid:124), ˜σ∗2) to be the bootstrap estimator maximising the

t , with ˜ε∗2
˜ε∗2

t=1

∗(cid:124)

∂(cid:96)∗
n
∂η

(r) =

∂(cid:96)∗

n(η, r)
∂η

(cid:12)
(cid:12)
(cid:12)
(cid:12)η=˜η

,

∂ ˜(cid:96)∗
n
∂η

(r) =

∂(cid:96)∗

n(η, r)
∂η

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)η=˜η∗

(18)

be the bootstrap score function evaluated in ˜η and ˜η∗, respectively. The partial
derivative of (cid:96)∗(η, r) with respect to φ does not depend upon r and, as before,
we partition ∂(cid:96)∗
∂η (r) according to φ and Ψ:
(cid:32)

(cid:33)

n

n

∂η (r) and ∂ ˜(cid:96)∗
(cid:18) ∂(cid:96)∗
n
∂φ

(r) =

,

∂(cid:96)∗
n
∂η

∂(cid:96)∗
n
∂Ψ

∂ ˜(cid:96)∗
n
∂η

(r) =

∂ ˜(cid:96)∗
n
∂φ

,

∂ ˜(cid:96)∗
n
∂Ψ

(r)

.

(19)

(cid:19)

(r)

,

7

Let

(cid:26) ∂(cid:96)∗
n
∂η

(cid:27)

(r)

=

(cid:26) ∂(cid:96)∗
n
∂η

(r), rL ≤ r ≤ rU

(cid:27)

(20)

be the bootstrap score process as a function of r, evaluated in η = ˜η. We
compute the bootstrap supLM statistic T ∗

n as:

T ∗
n = sup

T ∗
n (r);

r∈[rL,rU ]
(cid:32)
∂ ˜(cid:96)∗
n
∂Ψ

(r)

(cid:33)(cid:124)

T ∗
n (r) =

(cid:0)I ∗

n,22(r) − I ∗

n,21(r)(I ∗

n,11)−1I ∗

n,12(r)(cid:1)−1 ∂ ˜(cid:96)∗

n
∂Ψ

(21)

(r).

(22)

Finally, the bootstrap p-value is given by

B−1

B
(cid:88)

b=1

I(T ∗b

n ≥ Tn),

where T ∗b
supLM statistic computed on the original sample, deﬁned in Eq. (7).

n , b = 1, . . . B is the bootstrap test statistics and Tn is the value of the

3.1 Bootstrap asymptotic theory

In order to derive the bootstrap asymptotic theory we rely on the following
assumption, which is customary in this setting.

Assumption 1. {εt} is a sequence of independent and identically distributed
(hereafter iid) random variables with E[εt] = 0, E[ε2
t ] =
κ < ∞; {Xt} is stationary and ergodic under the null hypothesis.

t ] = σ2 < ∞ and E[ε4

n/∂Ψ(r) in terms of ∂(cid:96)∗

Under Assumption 1, in Theorem 9 we prove that T ∗
n converges weakly in prob-
ability to T∞, namely, the proposed bootstrap is valid. To this aim, in Propo-
sition 3 we derive a new uniform bootstrap law of large numbers (hereafter
UBLLN) that allows us to (i) verify that n−1I ∗
n(r) converges in probability (in
probability) to I∞(r) uniformly on r (Proposition 5) and (ii) derive an approxi-
mation of ∂ ˜(cid:96)∗
n/∂η(r) (Proposition 6). We next state the
UBLLN in Proposition 3 that establishes a new result which is of independent
interest since it is the ﬁrst proof of the validity of the bootstrap when testing
for a regime switching mechanism where a nuisance parameter is absent under
the null hypothesis. The main diﬃculty here resides in the indicator function
I(y ≤ r) being not diﬀerentiable. Hence, standard methods based upon Tay-
lor’s expansion cannot be applied. Notice that in Hansen [1996], the problem
is circumvented by adopting a stochastic permutation of the score vector for
which no UBLLN is required. Our proof of the bootstrap validity also extends
the approach of Chan et al. [2020]. We approximate the step function with a
parameterised sequence of continuous and diﬀerentiable functions.

Remark 2. The results provide a general theoretical framework that can be
adapted to other kinds of nonlinear processes such as regime-switching processes
with exogenous threshold variables or testing for structural breaks.

8

Proposition 3. (UBLLN) Let {Xt} and {X ∗
Eq. (13), respectively. Under Assumption 1, it holds that:

t } be deﬁned in Eq. (4) and

1. If E[|Xt|u] < ∞, for u ≥ 0, then:

sup
r∈[rL,rU ]

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
n

n
(cid:88)

t=1

X ∗u

t I(X ∗

t ≤ r) − E[X u

(cid:12)
(cid:12)
(cid:12)
t I(Xt ≤ r)]
(cid:12)
(cid:12)

p∗
−−−−→
n→∞ p

0.

(23)

2. If E[|Xt|u] < ∞, for u = 1, 2, then, for every i, j, d:

sup
r∈[rL,rU ]

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
n

n
(cid:88)

t=1

X ∗

t−iX ∗

t−jI(X ∗

(cid:12)
(cid:12)
(cid:12)
t−d ≤ r) − E[Xt−iXt−jI(Xt−d ≤ r)]
(cid:12)
(cid:12)

p∗
−−−−→
n→∞ p

0.

(24)

Remark 4. Under the null hypothesis and Assumption 1, E[εt] = 0 and E[εt] =
σ2 < ∞ imply that E[|Xt|u] < ∞, for u = 1, 2.

Proposition 5. Let {Xt} and {X ∗
Under the null hypothesis and Assumption 1, it holds

t } be deﬁned in (4) and Eq. (13), respectively.

sup
r∈[rL,rU ]

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
n

1
σ∗2

n
(cid:88)

t=1

D∗

t−1(r)D∗(cid:124)

(cid:12)
(cid:12)
(cid:12)
t−1(r) − I∞(r)
(cid:12)
(cid:12)

p∗
−−−−→
n→∞ p

0,

with D∗

t (r) and I∞(r) being deﬁned in Eq. (16) and Eq. (10), respectively.

Proposition 6. Let {Xt} and {X ∗
t } be deﬁned in Eq. (4) and Eq. (13), re-
spectively. Under the null hypothesis, it holds that the bootstrap score deﬁned in
Eq. (19) satisﬁes:

∂ ˜(cid:96)∗
n
∂Ψ

(r) =

∂(cid:96)∗
n
∂Ψ

(r) − In,21(r)I −1
n,11

∂(cid:96)∗
n
∂φ

.

Remark 7. By analogy with standard, non-bootstrap, asymptotics [Chan, 1990,
Ling and Tong, 2005, Goracci et al., 2021], thanks to Proposition 6 the asymp-
totic null distribution of T ∗
n is predominantly determined by the asymptotic
(cid:110) ∂(cid:96)∗
behaviour of
deﬁned in Eq. (18) and this sim-
rather than
∂η (r)
pliﬁes substantially the derivations.

∂η (r)

(cid:110) ∂ ˜(cid:96)∗

(cid:111)

(cid:111)

n

n

Next, in Proposition 8 we prove a bootstrap central limit theorem (hereafter

BCLT) for

, the bootstrap score process deﬁned in Eq. (20).

(cid:110) ∂(cid:96)∗

n

∂η (r)

(cid:111)

Proposition 8. (BCLT) Under the null hypothesis and Assumption 1, for any
ﬁxed r, it holds that

1
√
n

∂(cid:96)∗
n
∂η

(r) w∗

−−−−→
n→∞ p

Z(r),

n

where ∂(cid:96)∗
∂η (r) is deﬁned in Eq. (18), Z(r) is a Gaussian distributed 2(p + 1)-
dimensional random vector with zero-mean and variance-covariance matrix equal
to σ−2

0 I∞(r), deﬁned in Eq. (10).

9

The next theorem contains the main result, namely, the bootstrap functional
central limit theorem (BFCLT), where we prove that the conditional asymptotic
null distribution of the bootstrap test statistic T ∗
n is the same of the uncondi-
tional asymptotic null distribution of the non-bootstrap test statistic Tn. This
guarantees the validity of the proposed bootstrap method.

Theorem 9. (BFCLT) Let T ∗
Under the null hypothesis and Assumption 1, it holds that T ∗
n

n be the supLM statistic deﬁned in Eq. (21).
T∞, with

w∗
−−−−→
n→∞ p

T∞ being deﬁned in Eq. (11).

4 Finite sample performance

In this section we investigate the ﬁnite sample performance of the bootstrap sLM
test and compare it with the asymptotic counterpart for series whose length is
n = 50, 100, 200. These are small to moderate sample sizes that are quite com-
mon in many ﬁelds, especially when the cost of producing the data is not neg-
ligible. Hereafter εt, t = 1, . . . , n is generated from a standard Gaussian white
noise, the nominal size is α = 5% and the number of Monte Carlo replications
is 1000. For the asymptotic tests we have used the tabulated values of Andrews
[2003], whereas the bootstrap p-values are based on B = 1000 resamples. The
threshold is searched from percentile 25th to 75th of the sample distribution. In
Section 4.1 and Section 4.2 we study the size and the power of the tests. Then,
in Section 4.3 we assess the behaviour of the tests when the order of the AR
process tested is treated as unknown and is selected through the AIC. All the
results are presented as percentages as to enhance the readability of the tables.

4.1 Empirical size of the tests

To study the size of the tests, we generate time series from 21 diﬀerent simulation
settings of the following AR(1) model:

Xt = φ0 + φ1Xt−1 + εt

(25)

where φ0 = −1, 0, +1 and φ1 = 0, ±0.3, ±0.6, ±0.9. Table 1 shows the rejection
percentages for the three sample sizes in use. As expected, the intercept φ0 has
no impact upon the size of the tests and the variability observed reﬂects the
joint sampling and simulation ﬂuctuation. Our bootstrap test sLMb has a good
size even for a sample size as small as 50 and is not inﬂuenced by the value
of the autoregressive parameter close to non-stationarity. On the contrary, the
asymptotic test results severely oversized as φ1 approaches unity and the bias
persists for n = 200.

10

φ0

-1
-1
-1
-1
-1
-1
-1

0
0
0
0
0
0
0

1
1
1
1
1
1
1

φ1

-0.9
-0.6
-0.3
0.0
0.3
0.6
0.9

-0.9
-0.6
-0.3
0.0
0.3
0.6
0.9

-0.9
-0.6
-0.3
0.0
0.3
0.6
0.9

n = 50

n = 100

n = 200

sLMa

sLMb

sLMa

sLMb

sLMa

sLMb

14.7
4.6
4.6
4.4
7.3
16.6
42.2

17.0
4.4
3.6
4.4
6.6
13.9
42.6

16.4
3.8
2.6
3.5
6.5
14.7
40.9

4.2
4.9
5.7
4.3
5.4
6.9
7.5

5.5
5.2
4.6
5.1
4.6
5.6
6.3

3.5
3.8
3.6
3.8
4.4
4.9
6.6

9.6
4.6
2.8
4.3
4.4
8.5
30.9

9.0
3.7
3.7
4.3
3.4
8.5
28.8

9.7
3.9
3.6
4.2
5.9
8.6
33.1

4.8
5.5
3.8
5.1
4.3
5.3
6.2

3.8
4.8
4.7
5.1
2.7
4.6
4.9

4.0
4.6
4.6
5.6
5.3
5.0
5.0

7.4
4.6
4.0
5.0
4.6
6.5
21.8

6.9
3.1
4.7
4.2
4.8
6.0
18.5

8.6
4.9
5.0
4.2
4.4
5.7
19.9

6.1
6.0
5.3
5.3
5.0
5.6
7.3

4.4
4.3
5.9
5.2
5.3
5.1
4.7

5.7
5.7
6.2
5.1
4.9
4.2
5.6

Table 1: Empirical size at nominal level α = 5% for the AR(1) process of
Eq. (25) for the asymptotic test statistic sLMa of Eq. (7) and the bootstrap test
statistic sLMb of Eq. (21).

11

n = 50

n = 100

n = 200

Ψ sLMa

sLMb

sLMa

sLMb

sLMa

sLMb

M1

M2

0.0
0.3
0.6
0.9

0.0
0.3
0.6
0.9

5.0
6.1
15.7
37.4

5.0
6.3
9.5
14.0

5.0
9.5
28.2
55.5

5.0
6.0
9.2
14.1

5.0
11.2
51.3
88.2

5.0
7.5
14.9
33.4

4.9
15.0
58.2
91.0

5.0
7.8
14.5
33.5

5.0
41.0
93.8
100.0

5.0
8.6
36.3
67.7

5.0
43.1
93.8
100.0

5.0
8.6
36.5
67.7

Table 2: Size corrected power at nominal level α = 5% for the TAR(1) process
of Eq. (26) for the asymptotic test statistic sLMa of Eq. (7) and the bootstrap
test statistic sLMb of Eq. (21).

4.2 Empirical power of the tests

In this section we study the power of the supLM tests and highlight the diﬀer-
ences between them. We simulate from the following TAR(1) model:

Xt = φ1,0 + φ1,1Xt−1 + (Ψ + ΨXt−1) I(Xt−1 ≤ 0) + εt.

(26)

where φ1,0 and φ1,1 are as follows:

φ1,0

φ1,1

M1 −0.1 −0.8
0.8 −0.2
M2

and Ψ = (0.0, 0.3, 0.6, 0.9) as to obtain 8 diﬀerent parameter settings. Note that
the parameter Ψ represents the departure from the null hypothesis and in all
the simulations below we take sequences of increasing distance from H0 in all of
its components. The case Ψ = 0 corresponds to H0. Table 2 presents the size
corrected power at nominal level 5% where the ﬁrst and the ﬁfth rows correspond
to the null hypothesis and reﬂect the size of the tests, while the subsequent three
rows represent increasing departures from H0 and reﬂect the power of the tests.
Small deviations from the 5% nominal level are due to discretization eﬀects
when size-correcting the bootstrap p-values. The table shows clearly that the
bootstrap sLM test has superior power. As the sample size increases the power
of the two tests is similar but the bootstrap version has always a small margin
of advantage. The uncorrected power is reported in Table 1 of the Supplement
and shows that our bootstrap test has correct size for the ﬁrst row and n = 50
where the TAR(1) model reduces to a AR(1) model with parameter -0.8 and
the asymptotic test shows some oversize.

12

φ1

-0.65
-0.95
-0.35
1.15
0.45
0.45
-0.90

φ2

0.25
-0.25
-0.45
-0.55
0.25
-0.55
-0.25

n = 50

n = 100

n = 200

sLMa

sLMb

sLMa

sLMb

sLMa

sLMb

25.2
8.1
3.6
9.2
21.8
5.8
6.6

5.0
4.9
3.7
4.4
4.7
4.9
5.2

15.3
6.1
3.6
6.0
14.6
4.6
4.6

4.0
6.0
4.4
4.6
5.4
6.1
5.2

10.1
5.2
4.6
5.9
10.5
5.6
5.5

4.7
5.0
5.2
4.7
5.4
6.4
6.2

Table 3: Empirical size at nominal level α = 5% for the AR(2) process of
Eq. (27) for the asymptotic test statistic sLMa of Eq. (7) and the bootstrap test
statistic sLMb of Eq. (21). Here the true order of the autoregression is used.

4.3 The impact of order selection

In practical situations, the order of the autoregressive model to be tested is
unknown and has to be estimated. This can impinge on the performance of the
tests so that we assess the impact of treating the order p of the AR model as
unknown and selecting it by means of the AIC. We study the impact on the size
of the tests by simulating from the following AR(2) model.

Xt = φ0 + φ1Xt−1 + φ2Xt−2 + εt

(27)

where φ0 = 0, whereas φ1 and φ2 are presented on the ﬁrst two columns of
Table 3 that shows the rejection percentages when using the true order of the
autoregression in the tests. The results conﬁrm that the bootstrap test has cor-
rect size also for n = 50 irrespective of the parameters, while the asymptotic test
is biased when the parameters are close to the non-stationary region. Table 4
is as Table 3 but in such a case the order of the autoregression is treated as
unknown and selected through the AIC. This produces a noticeable oversize in
the asymptotic test but has no eﬀects upon the bootstrap version of the sLM
test, no matter the sample size.

We study the impact of model selection upon the power of the tests by

simulating from the following TAR(2) process:

Xt = φ1,0+φ1,1Xt−1+φ1,2Xt−2+(Ψ + ΨXt−1 + ΨXt−2) I(Xt−1 ≤ 0)+εt. (28)

where φ1,0 = 0, φ1,1 = −0.35, φ1,1 = −0.45 and, as before, Ψ = (0.0, 0.2, 0.6, 0.8)
represents the level of departure from H0. The rejection percentages are shown
in Table 5. Here, for n = 50 the asymptotic test is more powerful than the
bootstrap version, whereas the power of the two tests is very similar for n =
100, 200. Also the size is similar and close to the nominal 5% level so that the
size corrected power reported in the lower panel of the table is very similar
to the uncorrected power. Table 6 reports the empirical power (upper panel)
and its size corrected version (lower panel) when the order of the tested model

13

φ1

-0.65
-0.95
-0.35
1.15
0.45
0.45
-0.90

φ2

0.25
-0.25
-0.45
-0.55
0.25
-0.55
-0.25

n = 50

n = 100

n = 200

sLMa

sLMb

sLMa

sLMb

sLMa

sLMb

22.5
11.8
10.5
16.7
20.0
14.0
12.1

4.2
4.3
4.0
5.0
5.3
5.0
4.3

18.3
13.0
10.8
13.2
18.8
10.5
11.2

4.3
5.7
4.0
4.6
5.0
6.2
5.3

15.2
11.3
10.4
13.8
17.8
12.8
11.7

5.0
4.4
4.8
5.6
5.7
6.1
4.7

Table 4: As Table 3 but here the order of the autoregression has been treated
as unknown and selected through the AIC.

is selected by means of the AIC. As before, this produces an oversize in the
asymptotic test and the size-corrected power conﬁrms the superiority of our
bootstrap test for small to moderate sample sizes.

5 An application: the eﬀect of warming on pop-

ulations of larvae

In this section we analyse a panel of 12 short experimental time series of popu-
lations of Plodia interpunctella, a pyralid moth which infests at the global level
many diﬀerent stored food. While it is well known that global warming is one
of the consequences of climate change, its eﬀects on insects’ populations can
have important economic consequences and are still not completely clear. One
of the main features of many economically important insects and other animals
(e.g. salmons) is the appearance of generation cycles. Typically, these are non-
seasonal asymmetric cycles linked to delayed density dependence mediated by
competition or diet quality. Generation cycles can also be caused by age-speciﬁc
interactions between the insect and its enemies or cannibalism phenomena be-
tween larvae and eggs and pupas.
In many diﬀerent species of insects, the
mechanism of generation cycling is similar to that of P. interpunctella so that
the latter can be taken as a reference model.

The data come from Laughton and Knell [2019a], where the authors estab-
lished 18 populations of larvae, reﬂecting diﬀerent experimental conditions on
temperature (27, 30, 33°C) and food quality (poor, standard/good). Each of
the 6 experimental combinations has been replicated 3 times as to obtain 18
series of population counts followed for 82 weeks. The ﬁrst 10 weeks have been
treated as transient and discarded so that the series tested have 71 observations.
Since only the populations at 27 and 30°C persisted for the entire time span, we
focus on the 12 series corresponding to these two temperature level. The time
plots are shown in Figure 5 of the Supplementary Material.

Table 7 shows the results of the application of the sLM tests to the panel of 12

14

n = 50

n = 100

n = 200

Ψ sLMa

sLMb

sLMa

sLMb

sLMa

sLMb

0.0
0.2
0.6
0.8

4.2
5.3
32.5
58.6

4.8
5.2
25.7
40.6

3.8
10.8
71.8
95.5

4.8
11.7
71.5
94.7

3.9
20.4
98.3
100.0

4.5
21.7
98.5
100.0

size corrected

Ψ sLMa

sLMb

sLMa

sLMb

sLMa

sLMb

0.0
0.2
0.6
0.8

5.0
6.6
35.3
60.2

4.9
5.3
26.1
41.2

5.0
12.8
75.9
96.9

5.0
11.9
72.8
95.2

5.0
24.6
98.9
100.0

5.0
25.1
98.7
100.0

Table 5: Power at nominal level α = 5% for the TAR(2) process of Eq. (28) for
the asymptotic test statistic sLMa of Eq. (7) and the bootstrap test statistic
sLMb of Eq. (21). The lower panel reports the size corrected version of the
upper panel.

n = 50

n = 100

n = 200

Ψ sLMa

sLMb

sLMa

sLMb

sLMa

sLMb

0.0
0.2
0.6
0.8

12.5
13.1
25.0
30.6

4.0
5.1
18.8
23.5

11.5
19.2
55.5
59.8

4.2
10.9
50.8
64.8

10.0
28.7
90.0
91.3

4.0
20.5
90.6
94.8

size corrected

Ψ sLMa

sLMb

sLMa

sLMb

sLMa

sLMb

0.0
0.2
0.6
0.8

5.0
5.1
6.9
10.7

5.0
6.5
22.5
26.3

5.0
9.2
38.0
46.4

4.7
11.6
52.4
66.7

5.0
16.2
83.9
82.9

5.0
23.8
92.3
95.9

Table 6: As Table 5 but here the order of the autoregression has been treated
as unknown and selected through the AIC.

15

temp.

diet

repl.

statistic

p.value

27
27
27

27
27
27

30
30
30

30
30
30

poor
poor
poor

good
good
good

poor
poor
poor

good
good
good

1
2
3

1
2
3

1
2
3

1
2
3

6.23
18.97
4.27

3.49
14.78
6.64

7.83
8.70
9.17

11.63
10.78
9.79

0.254
0.001
0.521

0.619
0.010
0.236

0.132
0.094
0.076

0.033
0.042
0.066

Table 7: Results of the application of the sLM tests to the time series of 12
populations of larvae of the pyralid moth P. interpunctella under diﬀerent ex-
perimental conditions: temperature (ﬁrst column), quality of the diet (second
column). For each combination, there are 3 laboratory replications (third col-
umn). The fourth column reports the value of the sLM test statistic, whereas
the last column contains the bootstrap p-values of our test.

series. The ﬁrst two columns of the table indicate the experimental conditions,
the third column indicates the replication, whereas the fourth column contains
the value of the sLM statistic. Finally, the last column reports the bootstrap
p-value of the tests. The threshold is searched between percentiles 25th-75th of
the data and the delay parameter is d = 2 weeks. Despite the small sample size,
the bootstrap test is able to reject in 7 out of the 12 series at 90% level. By
using the asymptotic critical values of Andrews [2003], the test rejects in 6 out
of 12 series and this conﬁrms the slightly superior power of the bootstrap test
in small samples found in the simulation studies.

Next, we ﬁt a threshold model to the 4 time series obtained by averaging
over the 3 experimental replications. The time plots of series and the results of
the tests are presented in Figure 1 and Table 8, respectively. Clearly, warming
has a noticeable eﬀect on the mean of the series (dashed red lines). Figure 2
reports the power spectral density of the series. The frequency corresponding to
the characteristic asymmetric 6-week generation cycle is evidenced with a red
dashed line.
The series are likely to be aﬀected by measurement error so that a thresh-
old ARMA speciﬁcation is more appropriate than the TAR model (see Chan
et al. [2021] for the theoretical justiﬁcation). Typically, the MA parameters
greatly enhance the ﬂexibility of the model, while retaining parsimony Goracci

16

temp.

diet

statistic

p.value

27
27

30
30

poor
good

poor
good

10.67
15.68

22.13
8.02

0.055
0.006

0.000
0.120

Table 8: Results of the application of the sLM tests to the time series of 4
populations of larvae of the pyralid moth P. interpunctella under diﬀerent ex-
perimental conditions: temperature (ﬁrst column), quality of the diet (second
column). The fourth column reports the value of the sLM test statistic, whereas
the last column contains the bootstrap p-values of our test.

Figure 1: Time series of 4 populations of P. interpunctella from week 11 to 82
for diﬀerent experimental conditions. The series have been square-root trans-
formed.

17

1020304050607080681012141618weekTemp:27–Diet:bad1020304050607080681012141618weekTemp:27–Diet:good1020304050607080681012141618weekTemp:30–Diet:bad1020304050607080681012141618weekTemp:30–Diet:goodFigure 2: Power spectrum of the time series of 4 populations of P. interpunctella
corresponding to diﬀerent experimental conditions. The frequency correspond-
ing to the characteristic 6-week cycle is evidenced with a vertical dashed line.

[2020a,b]. Hence, we ﬁt the following TARMA model

Xt =

(cid:40)

φ1,0 + φ1,1Xt−1 + φ1,5Xt−5 + θ1,1εt−1 + εt,
φ2,0 + φ2,1Xt−1 + φ2,5Xt−5 + θ2,3εt−3 + εt,

if Xt−2 ≤ r,
otherwise.

(29)

The results are shown in Table 9, where the standard error are reported in
parenthesis below the estimates. The last column reports the estimated thresh-
old ˆr. Due to the length of the series, the standard errors are quite large, still,
there are both common features and diﬀerences across regimes and for diﬀerent
temperatures. Most importantly, the three-lag speciﬁcation is consistent with
the ﬁndings of Briggs et al. [2000] and manages to reproduce the characteristic
6-week generation cycle, especially for the series corresponding to a temper-
ature of 27°. This is shown in Figure 3 (left) that shows the power spectral
density computed on a series of 100,000 observations simulated from the second
ﬁt. The right panel of the ﬁgure shows also the histogram of the data with
the density of the ﬁtted model, estimated upon the simulated series (blue line).
The plots for the other series can be found in the Supplement, Figures 6–8.
The fourth series (30° - good diet) seems to present diﬀerent periodicities and
the model ﬁt is less satisfactory. This could be an indication of the eﬀect of
warming producing a qualitative change in the population dynamics. The diag-
nostic analysis performed both on the residuals and on the squared residuals of
the ﬁtted models does not show any unaccounted dependence, see Figures 9–12
of the Supplementary Material. Finally, the Shapiro-Wilk test applied to the
residuals (see Table 2 of the Supplementary Material) does not show departures
from normality, except for the last series whose p-value 0.046 somehow conﬁrms
that the combined action of warming and diet conditions can alter signiﬁcantly
the population dynamics of larvae.

18

0.00.10.20.30.40.510020050010002000500010000frequencyspectrum1/627-poor27-good30-poor30-goodtemp

diet

27

poor

27

good

30

poor

30

good

ˆφ1,0
1.15
(2.38)

0.73
(2.47)

3.39
(2.64)

7.00
(5.43)

ˆφ1,1
0.60
(0.21)

0.69
(0.30)

0.58
(0.19)

0.10
(0.42)

ˆφ1,5
0.32
(0.15)

0.31
(0.14)

0.22
(0.12)

0.32
(0.19)

ˆθ1,1
0.61
(0.21)

0.24
(0.41)

0.32
(0.23)

0.40
(0.35)

ˆφ2,0
0.17
(1.37)

0.24
(1.53)

1.29
(2.29)

7.62
(2.09)

ˆφ2,1
0.79
(0.13)

0.72
(0.12)

0.66
(0.12)

0.44
(0.13)

ˆφ2,5
0.15
(0.09)

0.19
(0.11)

0.11
(0.12)

-0.09
(0.13)

ˆθ2,3
-0.36
(0.18)

-0.06
(0.17)

0.40
(0.20)

-0.18
(0.15)

ˆr

9.18

8.89

11.93

10.72

Table 9: Estimated parameters for the threshold ARMA model of Eq. (29)
ﬁtted to the time series of populations of larvae under four diﬀerent experimental
conditions. The standard errors are reported in parenthesis below the estimates.

Figure 3: (Left) Power spectral density of the simulated time series of 100k
observations from the model ﬁt of the second time series (temp: 27°, diet: good).
The frequency corresponding to the characteristic 6-week cycle is evidenced
with a vertical dashed line.(Right) Histogram of the data (yellow) with the
superimposed density of the ﬁtted model, estimated upon the simulated series
(blue line).

19

0.00.10.20.30.40.50.51.02.05.010.020.0frequencyspectrum1/6XtDensity681012140.000.050.100.150.20simulatedFigure 4: Gα(y) for α = 1, 0.5, 0.1, together with the limit value α = 0 for which
Gα(y) = I(y ≤ r) almost surely.

6 Proofs

Proof of Proposition 3

PART 1. The proof is divided in two parts: ﬁrst, we show Eq. (23) for a given
r and then we prove that the result holds also uniformly for r ∈ [rL, rU ].

Pointwise convergence. We assume r to be ﬁxed and, for each η > 0, we

show that

P ∗

(cid:32)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
n

n
(cid:88)

t=1

X ∗u

t I(X ∗

t ≤ r) − E[X u

(cid:12)
(cid:12)
(cid:12)
t I(Xt ≤ r)]
(cid:12)
(cid:12)

(cid:33)

> 2η

p
−−−−→
n→∞

0.

(30)

Since the indicator function I(y ≤ r) is not diﬀerentiable, standard methods
based upon Taylor’s expansion cannot be applied. We exploit the fact that the
function is discontinuous only at r. By extending the approach used in Chan
et al. [2020], we approximate the step function with a sequence of continuous
and diﬀerentiable functions Gα(y), parameterized by α ≥ 0:

Gα(y) =

(cid:40) 1

2 + 1

π arctan( r−y
α )

1
2

if y (cid:54)= r
if y = r

(31)

In Figure 4 we show the plot of Gα(y) for three values of α, together with the
limit value α = 0 for which Gα(y) = I(y ≤ r) almost surely. For each δ > 0,
deﬁne the interval

where qα,δ = α tan(π(δ − 1/2)). This implies:

[Lα,δ, Uα,δ] := r ± qα,δ,

|I(y ≤ r) − Gα(y)| < δ if y /∈ [Lα,δ, Uα,δ];
|I(y ≤ r) − Gα(y)| < 1 if y ∈ [Lα,δ, Uα,δ].

20

(32)

(33)

(34)

-10-505100.00.20.40.60.81.0yGα(y)rα=1α=0.5α=0.1α=0Conditions Eq. (32)–(34) assure that, when α and δ approach zero, the interval
[Lα,δ, Uα,δ] collapses on r and the distance between Gα(·) and I(· ≤ r), which
is bounded by δ, vanishes. Now, it holds that:

P ∗

(cid:32)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ P ∗

1
n
(cid:32)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

n
(cid:88)

t=1

X ∗u

t I(X ∗

t ≤ r) − E[X u

(cid:12)
(cid:12)
(cid:12)
t I(Xt ≤ r)]
(cid:12)
(cid:12)

(cid:33)

> 2η

1
n

n
(cid:88)

t=1

X ∗u

t I(X ∗

t ≤ r) −

1
n

n
(cid:88)

X ∗u

t Gα(X ∗
t )

− E[X u

t I(Xt ≤ r)] + E[X u

+ P ∗

(cid:32)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
n

n
(cid:88)

t=1

X ∗u

t Gα(X ∗

t ) − E[X u

t=1

(cid:12)
(cid:12)
t Gα(Xt)]
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
t Gα(Xt)]
(cid:12)
(cid:12)

(cid:19)

> η

(cid:33)

> η

.

(35)

(36)

Markov’s inequality implies that, in order to prove that Eq. (35) is op∗ (1), it
suﬃces to show that the following two expectations vanish in probability:

E∗ [|E[X u
t I(Xt ≤ r)] − E[X u
(cid:34)(cid:12)
n
(cid:12)
1
(cid:88)
(cid:12)
(cid:12)
n
(cid:12)

t ≤ r) −

t I(X ∗

X ∗u

1
n

E∗

t=1

t Gα(Xt)]|] ,
n
(cid:88)

t=1

X ∗u

t Gα(X ∗
t )

(37)

(38)

(cid:35)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

.

As for Eq. (37): let fX (·) be the stationary probability density function of the
AR(p) process {Xt}. Since it is continuous [see e.g. Andˇel and Hrach, 2000,
theorem 1.3] and E[|Xt|u] < ∞, by using the same argument developed in Ling
and Tong [2005], it is possible to show that there exists a positive ﬁnite constant,
say M , such that supx∈R |x|ufX (x) < M . It holds that:

t Gα(Xt)]|] = |E[X u

t I(Xt ≤ r)] − E[X u
t | · |I(Xt ≤ r) − Gα(Xt)|]
t | · |I(Xt ≤ r) − Gα(Xt)|I(Xt /∈ [Lα,δ, Uα,δ])]
t | · |I(Xt ≤ r) − Gα(Xt)|I(Xt ∈ [Lα,δ, Uα,δ])]

E∗ [|E[X u
≤ E[|X u
= E[|X u
+ E[|X u
≤ δE[|Xt|u] + M (Uα,δ − Lα,δ),

t I(Xt ≤ r)] − E[X u

t Gα(Xt)]|

where the last inequality follows from Eq. (32), Eq. (33) and Eq. (34). Hence,
Eq. (37) can be made arbitrarily small in probability by choosing α and δ

21

suﬃciently small. A similar argument handles Eq. (38):

E∗

(cid:34)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
n
(cid:34)

≤ E∗

(cid:34)

(cid:34)

= E∗

+ E∗

n
(cid:88)

t=1

X ∗u

t I(X ∗

t ≤ r) −

1
n

n
(cid:88)

t=1

(cid:35)

X ∗u

(cid:12)
(cid:12)
t Gα(X ∗
(cid:12)
t )
(cid:12)
(cid:12)

| · |I(X ∗

t ≤ r) − Gα(X ∗

(cid:35)
t )|

| · |I(X ∗

t ≤ r) − Gα(X ∗

t )|I(X ∗

(cid:35)
t /∈ [Lα,δ, Uα,δ])

|X ∗u
t

|X ∗u
t

| · |I(X ∗

t ≤ r) − Gα(X ∗

t )|I(X ∗

(cid:35)
t ∈ [Lα,δ, Uα,δ])

|X ∗u
t

1
n

1
n

1
n

n
(cid:88)

t=1
n
(cid:88)

t=1
n
(cid:88)

t=1

≤ δ

1
n

n
(cid:88)

t=1

E∗[|X ∗u

t

|] + M

1
n

n
(cid:88)

t=1

P ∗(X ∗

t ∈ [Lα,δ, Uα,δ]),

where M = max{|Lα,δ|u, |Uα,δ|u, 1}. Lemma 10 implies that n−1 (cid:80)n
t ∈
[Lα,δ, Uα,δ]) ≤ n−1 with probability 1, hence Eq. (38) is op∗ (1). Lastly, in order
to show that also Eq. (36) is op∗ (1), we use the following two expansions:

t=1 P ∗(X ∗

t ) = Gα(Xt) + gα(Y ∗

Gα(X ∗
Gα(Xt) = Gα(qα,δ + 2r) + gα(Yt)(Xt − qα,δ − 2r)

t − Xt);

t )(X ∗

(39)

(40)

where qα,δ is deﬁned in Eq. (32), Y ∗
(1 − λ2,t)(qδ + 2r) for some λj,t with 0 ≤ λj,t ≤ 1 and j = 1, 2; moreover,

t + (1 − λ1,t)Xt and Yt = λ2,tXt +

t = λ1,tX ∗

gα(y) =

∂Gα(y)
∂y

=

(cid:40)

−

0

α
π(α2+(r−y)2)

if y (cid:54)= r

if y = r.

Note that gα(y) −−−→
α→0

0 for each y. Since the ergodicity of {Xt} implies that

1
n

n
(cid:88)

t=1

X u

t Gα(Xt)

p
−−−−→
n→∞

E[X u

t Gα(Xt)],

it suﬃces to prove that

P ∗

(cid:32)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
n

n
(cid:88)

t=1

X ∗u

t Gα(X ∗

t ) −

1
n

n
(cid:88)

t=1

X u

(cid:12)
(cid:12)
(cid:12)
t Gα(Xt)
(cid:12)
(cid:12)

(cid:33)

> η/2

p
−−−−→
n→∞

0,

(41)

which can be achieved by using Markov’s inequality. Indeed, by using Eq. (39),

22

Eq. (40) and since Gα(qδ + 2r) = δ we have

E∗

(cid:34)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

n
(cid:88)

t=1

X ∗u

t Gα(X ∗

t ) −

1
n

n
(cid:88)

t=1

(cid:35)

X u

(cid:12)
(cid:12)
(cid:12)
t Gα(Xt)
(cid:12)
(cid:12)

1
n

1
n

n
(cid:88)

t=1
n
(cid:88)

t=1

(X ∗u

t − X u

t ) {δ + gα(Yt)(Xt − qδ − 2r)}

X ∗u

t gα(Y ∗

t )(X ∗

(cid:12)
(cid:12)
(cid:12)
t − Xt)
(cid:12)
(cid:12)

(cid:35)

(cid:12)
(cid:35)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
n
(cid:34)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:34)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ E∗

+ E∗

which can be made arbitrarily small in probability by taking α and δ suﬃciently
small and this completes the proof.

Uniform convergence. By deploying arguments similar to Cavaliere et al.

[2017], we show that for each η > 0

(cid:32)

P ∗

sup
r∈[rL,rU ]

|∆∗

n(r)| > 2η

(cid:33)

p
−−−−→
n→∞

0,

(42)

n(r) = n−1 (cid:80)n

t=1 X ∗u

where ∆∗
t I(Xt ≤ r)]. Since [rL, rU ] is a
compact subset of R, for any c > 0, there exists a ﬁnite coverage {[ri−1, ri]; i =
1, . . . , m}, with m being a constant, such that rL = r0 < r1 < . . . < rm−1 <
rm = rU ad ri − ri−1 ≤ c, for each i = 1, . . . , m. Therefore, it holds that

t ≤ r) − E[X u

t I(X ∗

sup
r∈[rL,rU ]

|∆∗

n(r)| ≤ max

i=0,...,m

|∆∗

n(ri)| + max

i=1,...,m

sup
r∈[ri−1,ri]

|∆∗

n(r) − ∆∗

n(ri−1)|

which implies:

(cid:32)

(cid:33)

P ∗

sup
r∈[rL,rU ]

|∆∗

n(r)| > 2η

(cid:18)

≤ P ∗

max
i=0,...,m

|∆∗

n(ri)| > η

(cid:19)

+ P ∗

(cid:32)

max
i=1,...,m

sup
r∈[ri−1,ri]

|∆∗

n(r) − ∆∗

n(ri−1)| > η

(cid:33)

(43)

By combining Bonferroni’s inequality, the pointwise convergence and the ﬁnite-
ness of m, we have that

(cid:18)

P ∗

max
i=1,...,m

|∆∗

n(ri)| > η

(cid:19)

≤

m
(cid:88)

i=1

P ∗ (|∆∗

n(ri)| > η)

p
−−−−→
n→∞

0.

It remains to show that the second term of the RHS of Eq. (43) converges to

23

zero in probability (in probability), which is the case because:

(cid:34)

E∗

sup
r∈[ri−1,ri]

|∆∗

n(r) − ∆∗

(cid:35)
n(ri−1)|

(cid:34)

≤ E∗

sup
r∈[ri−1,ri]

1
n

n
(cid:88)

t=1

|X ∗u
t

|I(ri−1 < X ∗

t ≤ r)

(cid:35)
E[|Xt|uI(ri−1 < Xt ≤ r)]

+ sup

r∈[ri−1,ri]

≤ E∗

(cid:34)

1
n

n
(cid:88)

t=1

|X ∗u
t

|I(ri−1 − c < X ∗

(cid:35)
t ≤ ri−1 + c) + E[|Xt|uI(ri−1 < Xt ≤ ri)]

≤

M1
n

n
(cid:88)

t=1

P ∗(ri−1 − c < X ∗

t ≤ ri−1 + c) + M2P (ri−1 < Xt ≤ r),

with M1 = max{|ri−1 − c|u, |ri−1 + c|u, 1} and M2 = max{|ri−1|u, |ri|u, 1}. By
combining Lemma 10 and Markov’s inequality, the proof is completed since c
can be chosen arbitrarily small.

PART 2. The proof follows via the same arguments used in 1. and, hence,

it is omitted.

Proof of Proposition 5

By routine algebra it holds that I ∗
symmetric matrices whose (i + 1, j + 1)th element is

n,22(r) = I ∗

n,12(r) = I ∗ (cid:124)

n,21(r) are (p+1)×(p+1)

n
(cid:88)

t=1
n
(cid:88)

t=1
n
(cid:88)

t=1

I(X ∗

t−d ≤ r),

X ∗

t−jI(X ∗

t−d ≤ r),

X ∗

t−iX ∗

t−jI(X ∗

t−d ≤ r),

if i = 0, j = 0

if i = 0, j (cid:54)= 0

if i (cid:54)= 0, j (cid:54)= 0

n,11 = I ∗

and I ∗
n,22(∞). The results readily follows by combining Proposition 3
with u = 0, 1, 2 for point 1 and standard results of bootstrap asymptotic anal-
ysis.

24

Proof of Proposition 6

The proof is based upon verifying the following two equalities:

√

∗
n( ˜φ − ˜φ

) = −

1
√
n

∂ ˜(cid:96)∗
n
∂Ψ

(r) =

(cid:18) I ∗
n,11
n
∂(cid:96)∗
n
∂Ψ

(cid:19)−1 1
∂(cid:96)∗
n
√
∂φ
n
I ∗
n,21(r)
n

(r) +

1
√
n

√

n( ˜φ − ˜φ

∗

),

(44)

(45)

n

n

n

∂φ , ∂(cid:96)∗

∂Ψ (r) and ∂ ˜(cid:96)∗

where ∂(cid:96)∗
n,21(r)
in Eq. (17). As previously state we use φ as to refer to a generic parameter and
let ∂(cid:96)∗
∂φ (φ) be the partial derivative of the bootstrap log-likelihood computed
under the null hypothesis, i.e.:

∂Ψ (r) are deﬁned in Eq. (19) whereas I ∗

n,11 and I ∗

n

∂(cid:96)∗
n
∂φ

(φ) =

∂(cid:96)∗

n(η, r)
∂η

(cid:12)
(cid:12)
(cid:12)
(cid:12)Ψ=0,σ2=˜σ2

.

Next, we derive two ﬁrst order Taylor expansions of the function ∂(cid:96)∗
∗
at the true bootstrap value ˜φ ad the other at the bootstrap MLE ˜φ
that, since the ν(cid:48) partial derivatives of (cid:96)∗
expansion of ∂(cid:96)∗
the Jacobian matrix of ∂(cid:96)∗
depend on φ. Hence it results that:

∂φ (φ): one
. Note
n(η, r) are zero for ν > 2, the Taylor
∂φ (φ) coincides with its ﬁrst-order Taylor polynomial; moreover,
n,11, deﬁned in Eq. (17), which does not

∂φ (φ) is −I ∗

n

n

∂(cid:96)∗
n
∂φ
∂(cid:96)∗
n
∂φ

(φ) =

(φ) =

∗

∂(cid:96)n
∂φ
∂ ˜(cid:96)∗
n
∂φ

− In,11(φ − ˜φ),

− In,11(φ − ˜φ

∗

)

(46)

(47)

n

with ∂ ˜(cid:96)∗
∂φ and ∂(cid:96)∗
Eq. (46) and dividing by

n

√

n, we get

∂φ being deﬁned in Eq. (18). By subtracting Eq. (47) from

1
√
n

∂ ˜(cid:96)∗
n
∂φ

=

1
√
n

∂(cid:96)∗
n
∂φ

+

√

I ∗
n,11
n

n( ˜φ − ˜φ

∗

).

(48)

∗
Since ˜φ
thence Eq. (48) implies

is the bootstrap MLE obtained under the null hypothesis, ∂ ˜(cid:96)∗

n

∂φ = 0

√

I ∗
n,11
n

∗
n( ˜φ

− ˜φ) = −

1
√
n

∂(cid:96)∗
n
∂φ

.

and hence Eq. (44) follows. We prove Eq. (45) componentwise. We detail below
the argument only for the ﬁrst component since it can be easily adapted to the

25

other ones. Therefore, we show that:

1
√
n

∂ ˜(cid:96)∗
n
∂Ψ0

(r) =

1
√
n

∂(cid:96)∗
n
∂Ψ0

√

(r) +

n( ˜φ0 − ˜φ∗
0)

1
n

n
(cid:88)

t=1

I(X ∗

t−d ≤ r)

p
(cid:88)

√

+

i=1

n( ˜φi − ˜φ∗
i )

1
n

n
(cid:88)

t=1

X ∗

t−iI(X ∗

t−d ≤ r).

(49)

t be the residuals obtained from the ML ﬁt upon the bootstrap sample

Let ˜ε∗
{X ∗

t , t = 1 . . . , n}, i.e.:

t = X ∗
˜ε∗

t − ˜φ∗

0 −

p
(cid:88)

i=1

˜φ∗
i X ∗

t−i = ( ˜φ0 − ˜φ∗

0) +

p
(cid:88)

i=1

( ˜φi − ˜φ∗

i )Xt−i + ε∗
t .

Clearly:

t − ˜ε∗
ε∗

t = ( ˜φ∗

0 − ˜φ0) +

p
(cid:88)

( ˜φ∗

i − ˜φi)X ∗

t−i.

(50)

i=1

t (η, r), deﬁned in Eq. (15), does not depend on σ2 and ˜ε∗
t (η, r) evaluated at φ = ˜φ

Note that ε∗
correspond to the function ε∗
Ψ = 0, respectively. Consider the partial derivatives of the function ε∗
and denote:

t and ε∗
t
, Ψ = 0 and φ = ˜φ,
t (η, r)

∗

D∗

Ψ0t(r) =

∂ε∗

t (η, r)
∂Ψ0

(cid:12)
(cid:12)
(cid:12)
(cid:12)φ= ˜φ,Ψ=0

,

˜D∗

Ψ0t(r) =

∂ε∗

t (η, r)
∂Ψ0

(cid:12)
(cid:12)
(cid:12)
(cid:12)φ= ˜φ∗,Ψ=0

.

Note that:

D∗

Ψ0t(r) = ˜D∗

Ψ0t(r) = −I(X ∗

t−d ≤ r)

therefore, we get:

1
√
n

∂ ˜(cid:96)∗
n
∂Ψ0

(r) = −

= −

1
√
n

1
√
n

n
(cid:88)

t=1
n
(cid:88)

t=1

˜ε∗
t

˜D∗

Ψ0t(r) = −

1
√
n

n
(cid:88)

t=1

˜ε∗
t D∗

Ψ0t(r)

t D∗
˜ε∗

Ψ0t(r) −

1
√
n

n
(cid:88)

t=1

t D∗
ε∗

Ψ0t(r) +

1
√
n

n
(cid:88)

t=1

t D∗
ε∗

Ψ0t(r)

=

1
√
n

∂(cid:96)∗
n
∂Ψ0

(r) +

1
√
n

n
(cid:88)

(ε∗

t − ˜ε∗

t )D∗

Ψ0t(r).

t=1

26

t ) in Eq. (50) implies that
(cid:40)

n
(cid:88)

1
√
n

( ˜φ∗

0 − ˜φ0) +

( ˜φ∗

i − ˜φi)X ∗

t−i

p
(cid:88)

(cid:41)

D∗

Ψ0t(r)

t=1

i=1

The expression of (ε∗

t − ˜ε∗

(r) +

(r)

1
√
n

1
√
n

1
√
n

1
√
n

∂(cid:96)∗
n
∂Ψ0
∂(cid:96)∗
n
∂Ψ0
n
(cid:88)

t=1
∂(cid:96)∗
n
∂Ψ0

1
√
n

∂ ˜(cid:96)∗
n
∂Ψ0

(r) =

=

+

=

+

(cid:40)

( ˜φ∗

0 − ˜φ0) +

p
(cid:88)

i=1

( ˜φ∗

i − ˜φi)X ∗

t−i

(cid:41)

(cid:8)−I(X ∗

t−d ≤ r)(cid:9)

√

(r) +

n( ˜φ0 − ˜φ∗
0)

1
n

n
(cid:88)

t=1

I(X ∗

t−d ≤ r)

p
(cid:88)

√

i=1

n( ˜φi − ˜φ∗
i )

1
n

n
(cid:88)

t=1

X ∗

t−iI(X ∗

t−d ≤ r)

and this completes the proof.

n

Proof of Proposition 8
Since ∂(cid:96)∗
∂η (r) = − (cid:80)n
a sequence of martingale diﬀerence arrays with respect to the ﬁltration F ∗
t−1, X ∗
σ{X ∗
two conditions:

t (r) being deﬁned in Eq. (16), forms
t−1 :=
t−2, . . . }, the result holds upon proving, uniformly on r, the following

t−1(r), with D∗

t=1 ε∗

t D∗

1
n

1
n

n
(cid:88)

t=1
n
(cid:88)

t=1

E∗ (cid:2)ε∗2

t (D∗

t−1(r))(D∗

t−1(r))(cid:124)|F ∗

t−1

(cid:3)

p∗
−−−−→
n→∞ p

σ2I∞(r);

E∗ (cid:2)ε∗2

t Λ∗2

t−1(r)I (cid:0)(cid:12)

(cid:12)ε∗

t Λ∗

t−1(r)(cid:12)

(cid:12) > η

√

n(cid:1) |F ∗

t−1

(cid:3)

p∗
−−−−→
n→∞ p

0,

(51)

(52)

t (r) := (λ1, . . . , λ2(p+1)) · D∗

with Λ∗
numbers. In order to prove Eq. (51) note that the independence between ε∗
X ∗

t (r), with λi, i = 1, . . . , 2(p + 1), being real
t and

t−j, j ≥ 1 implies that

1
n

n
(cid:88)

t=1

E∗ (cid:2)ε∗2

t (D∗

t−1(r))(D∗

t−1(r))(cid:124)|F ∗

t−1

(cid:3) = E∗ (cid:2)ε∗2

t

(cid:3) 1
n

n
(cid:88)

t=1

D∗

t−1(r)(D∗

t−1(r))(cid:124),

which converges in probability (in probability) to σ2I∞(r) uniformly on r by
Lemma 11 and Proposition 5. As for Eq. (52) ﬁrst observe that, by using
Jensen’s inequality and Proposition 3, n−1 (cid:80)n

t−1(r) is bounded by

t=1 Λ∗2

2(p + 1)
n

n
(cid:88)

(cid:34)
(cid:0)λ2

1 + λ2

p+2

(cid:0)λ2

i + λ2

i+p+1

(cid:35)

(cid:1) X ∗2

t−i+1

= Op∗ (1),

(53)

(cid:1) +

p+1
(cid:88)

i=2

t=1
whereas n−1 (cid:80)n

t=1 Λ∗4
(cid:34)
n
(cid:88)
(cid:0)λ4

t=1

1 + λ4

p+2

8(p + 1)3
n

t−1(r) is bounded by

(cid:0)λ4

i + λ4

i+p+1

(cid:35)

(cid:1) X ∗4

t−i+1

= Op∗ (1).

(54)

(cid:1) +

p+1
(cid:88)

i=2

27

Now, since |xy| ≤ x2 + y2, it follows that

1
n

n
(cid:88)

t=1

E∗ (cid:2)ε∗2

t Λ∗2

t−1(r)I (cid:0)(cid:12)

(cid:12)ε∗

t Λ∗

t−1(r)(cid:12)

(cid:12) > η

√

n(cid:1) |F ∗

t−1

(cid:3)

≤

+

1
n

1
n

n
(cid:88)

t=1
n
(cid:88)

t=1

E∗ (cid:2)ε∗2

t Λ∗2

t−1(r)I (cid:0)Λ2∗

t−1(r) > 2−1η

√

n(cid:1) |F ∗

t−1

(cid:3)

E∗ (cid:2)ε∗2

t Λ∗2

t−1(r)I (cid:0)ε∗2

t > 2−1η

√

n(cid:1) |F ∗

t−1

(cid:3)

≤

2
√

η

n

(cid:40)

1
n

n
(cid:88)

t=1

Λ∗4

t−1(r)E∗[ε∗2

t ] +

(cid:41)

Λ∗2

t−1(r)E∗[ε∗4
t ]

1
n

n
(cid:88)

t=1

which is op∗ (1) by combing Eq. (53), Eq. (54) and Lemma 11.

Proof of Theorem 9

In view of Proposition 8 and Theorem 18.14, p. 261 of van der Vaart [1998],
it suﬃces to prove the stochastic equicontinuity of ∂(cid:96)∗
t=1 ε∗
t−1(r),
t−1(r) is L2 integrable
where D∗
t−1(r) is deﬁned in Eq. (16). The envelope of ε∗
in probability:

∂η (r) = − (cid:80)n

t D∗

t D∗

n

1
n

n
(cid:88)

t=1

E∗

=

≤

=

1
n

2
n

2
n

n
(cid:88)

t=1
n
(cid:88)

t=1
n
(cid:88)

t=1

(cid:34)

sup
r∈[rL,rU ]

(cid:34)

E∗

sup
r∈[rL,rU ]
(cid:40)

(cid:34)

E∗

ε∗2
t

1 +

(cid:107)ε∗

t x∗

t−1(r)(cid:107)2

(cid:35)

=

(cid:34)

E∗

1
n

n
(cid:88)

t=1

sup
r∈[rL,rU ]

(ε∗

t x∗

t−1(r))(cid:124)(ε∗

t x∗

t−1(r))

(cid:35)

(cid:40)

ε∗2
t

1 +

p
(cid:88)

i=1
(cid:41)(cid:35)

X ∗2
t−i

=

p
(cid:88)

i=1

X ∗2

t−i + I(X ∗

t−d ≤ r) +

(cid:41)(cid:35)

X ∗2

t−iI(X ∗

t−d ≤ r)

p
(cid:88)

i=1

(cid:34)

E∗

E∗

(cid:34)
ε∗2
t

(cid:40)

1 +

p
(cid:88)

(cid:41)

(cid:35)(cid:35)

X ∗2
t−i

|F ∗

t−1

2
n

n
(cid:88)

t=1

(cid:34)

E∗

1 +

(cid:35)

X ∗2
t−i

p
(cid:88)

i=1

E∗ (cid:2)ε∗2

t |F ∗

t−1

(cid:3) = E∗ (cid:2)ε∗2

t

(cid:3) E∗

(cid:34)

2
n

i=1
(cid:40)

n
(cid:88)

t=1

1 +

p
(cid:88)

i=1

(cid:41)(cid:35)

X ∗2
t−i

= Op∗ (1).

Deﬁne the norms:

ρ∗
n(r1, r2) =

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)2
and ρ(r1, r2) = (cid:107)εtDt−1(r2) − εtDt−1(r1)(cid:107)2 ,

(cid:18) ∂(cid:96)∗
∂η

∂(cid:96)∗
∂η

1
√
n

(r2) −

(r1)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

where, in analogy with Eq. (16), Dt(r) is the ﬁrst-order derivative of the function
εt(η, r) deﬁned in Eq. (3), i.e.:

Dt(r) = (−1, −Xt, . . . , −Xt−p+1,

(cid:124)
−I(Xt−d+1 ≤ r), −XtI(Xt−d+1 ≤ r), . . . , −Xt−p+1I(Xt−d+1 ≤ r))

.

28

It holds that

n (r1, r2) = E∗
ρ∗2
(cid:34)

(cid:18) ∂(cid:96)∗
∂η

1
√
n

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:32)

(r2) −

∂(cid:96)∗
∂η

(r1)

(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

= E∗

ε∗2
t

I(r1 < X ∗

t−d ≤ r2) +

1
n

n
(cid:88)

t=1

X ∗2

t−iI(r1 < X ∗

t−d ≤ r2)

(cid:33)(cid:35)

.

p
(cid:88)

i=1

By using the law of iterated expectations and Proposition 3, ρ∗
uniformly to

n(r1, r2) converges

(cid:40)

σ2P (r1 < Xt ≤ r2) + σ2

p
(cid:88)

i=1

E[X 2

t−iI(r1 < Xt−d ≤ r2)]

= ρ2(r1, r2).

(cid:41)

Thence the same argument of Theorem 2 of Hansen [1996] holds, and this com-
pletes the proof.

References

D.W.K. Andrews. Tests for parameter instability and structural change with
unknown change point. Econometrica, 61(4):821–856, 1993. ISSN 00129682,
14680262. URL http://www.jstor.org/stable/2951764.

D.W.K. Andrews. Tests for parameter instability and structural change with
unknown change point: A corrigendum. Econometrica, 71(1):395–397, 2003.
doi: 10.1111/1468-0262.00405.

J. Andˇel and K. Hrach. On calculation of stationary density of autoregressive

processes. Kybernetika, 3:311–319, 01 2000.

C.J. Briggs, S.M. Sait, M. Begon, D.J. Thompson, and H.C.J. Godfray. What
Jour-
causes generation cycles in populations of stored-product moths?
nal of Animal Ecology, 69(2):352–366, 2000. doi: https://doi.org/10.1046/
j.1365-2656.2000.00398.x.
URL https://besjournals.onlinelibrary.
wiley.com/doi/abs/10.1046/j.1365-2656.2000.00398.x.

G. Cavaliere and A. Rahbek. A primer on bootstrap testing of hypotheses
in time series models: with an application to double autoregressive models.
Econometric Theory, 37(1):1—-48, 2021. doi: 10.1017/S0266466620000067.

G. Cavaliere, H. B. Nielsen, and A. Rahbek. On the Consistency of Bootstrap
Testing for a Parameter on the Boundary of the Parameter Space. Journal of
Time Series Analysis, 38(4):513–534, 2017. doi: https://doi.org/10.1111/jtsa.
12214. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/jtsa.
12214.

K.-S. Chan. Testing for threshold autoregression. Ann. Statist., 18(4):1886–
1894, 12 1990. doi: 10.1214/aos/1176347886. URL https://doi.org/10.
1214/aos/1176347886.

29

K. S. Chan. Percentage points of likelihood ratio tests for threshold autore-
gression. J. R. Stat. Soc. Ser. B. Stat. Methodol., 53(3):691–696, 1991. ISSN
00359246. URL http://www.jstor.org/stable/2345598.

K.-S. Chan and H. Tong. On likelihood ratio tests for threshold autoregression.
J. R. Stat. Soc. Ser. B. Stat. Methodol., 52(3):469–476, 1990. ISSN 00359246.
URL http://www.jstor.org/stable/2345670.

K.-S. Chan, B.E. Hansen, and A. Timmermann. Guest editors’ introduction:
Regime switching and threshold models. Journal of Business & Economic
Statistics, 35(2):159–161, 2017. doi: 10.1080/07350015.2017.1236521. URL
http://dx.doi.org/10.1080/07350015.2017.1236521.

K.-S. Chan, S. Giannerini, G. Goracci, and H. Tong. Unit-root test within
a threshold ARMA framework. Technical report, University of Iowa and
University of Bologna, 2020. URL https://arxiv.org/abs/2002.09968v2.

K.-S. Chan, S. Giannerini, G. Goracci, and H. Tong. Testing for threshold
regulation in presence of measurement error with an application to the PPP
hypothesis, 2021. URL https://arxiv.org/abs/2002.09968.

R.B. Davies. Hypothesis testing when a nuisance parameter is present only
under the alternative. Biometrika, 64(2):247–254, 1977. ISSN 00063444. URL
http://www.jstor.org/stable/2335690.

R.B. Davies. Hypothesis testing when a nuisance parameter is present only
under the alternatives. Biometrika, 74(1):33–43, 1987. ISSN 00063444. URL
http://www.jstor.org/stable/2336019.

G. Goracci. Revisiting the canadian lynx time series analysis through TARMA
models. Statistica, 80(4):357–394, 2020a. doi: 10.6092/issn.1973-2201/11478.
URL https://rivista-statistica.unibo.it/article/view/11478.

G. Goracci.

An empirical

power of tarma models.
doi:
s10260-020-00516-8.

10.1007/s10260-020-00516-8.

study on the parsimony and descriptive
Statistical Methods & Applications, 02 2020b.
URL https://doi.org/10.1007/

G. Goracci, S. Giannerini, K.-S. Chan, and H. Tong. Testing for threshold
eﬀects in the TARMA framework. Statistica Sinica, in press, 2021. URL
https://doi.org/10.5705/ss.202021.0120.

B.E. Hansen.

Inference when a nuisance parameter is not identiﬁed under
ISSN 00129682,

the null hypothesis. Econometrica, 64(2):413–430, 1996.
14680262. URL http://www.jstor.org/stable/2171789.

B.E. Hansen. Threshold autoregression in economics. Statistics and its Interface,

4(2):123–127, 2011.

30

J.B. Hill. Weak-identiﬁcation robust wild bootstrap applied to a consistent
model speciﬁcation test. Econometric Theory, 37(3):409–463, 2021. doi: 10.
1017/S0266466620000201.

A.M. Laughton and R.J. Knell. Warming at the population level: Eﬀects on
age structure, density, and generation cycles. Ecology and Evolution, 9(8):
4403–4420, 2019a. URL https://doi.org/10.1002/ece3.4972.

A.M. Laughton and R.J. Knell. Data from: Warming at the population level:
Eﬀects on age structure, density, and generation cycles. Dryad, Dataset,
2019b. URL https://doi.org/10.5061/dryad.4fg24s2.

G. Li and W.K. Li. Testing a linear time series model against its threshold
ISSN 0006-3444. doi: 10.

extension. Biometrika, 98(1):243–250, 02 2011.
1093/biomet/asq074.

S. Ling and H. Tong. Testing for a linear MA model against threshold MA
models. Ann. Statist., 33(6):2529–2552, 12 2005. URL https://doi.org/
10.1214/009053605000000598.

R. Luukkonen, P. Saikkonen, and T. Ter¨asvirta. Testing linearity against smooth
ISSN

transition autoregressive models. Biometrika, 75(3):491–499, 1988.
00063444. URL http://www.jstor.org/stable/2336599.

J. Petruccelli and N. Davies. A portmanteau test for self-exciting threshold
autoregressive-type nonlinearity in time series. Biometrika, 73(3):687–694, 12
1986. ISSN 0006-3444. doi: 10.1093/biomet/73.3.687.

J.D. Petruccelli. On the approximation of time series by threshold autoregressive
models. Sankhy¯a: The Indian Journal of Statistics, Series B (1960-2002), 54
(1):106–113, 1992. URL http://www.jstor.org/stable/25052727.

N. C. Stenseth, W. Falck, K.-S. Chan, O. Bjornstad, M. O’Donoghue, H. Tong,
R. Boonstra, S. Boutin, C. Krebs, and N. Yoccoz. From patterns to processes:
Phase and density dependencies in the canadian lynx cycle. Proceedings of
the National Academy of Sciences, 95:15430–15435, 12 1998. doi: 10.1073/
pnas.95.26.15430.

F. Su and K.-S. Chan. Testing for threshold diﬀusion. J. Bus. Econom. Statist.,

35:218–227, 04 2017. doi: 10.1080/07350015.2015.1073594.

H. Tong. Non-linear Time Series: A Dynamical System Approach. Clarendon

Press, 1990.

H. Tong. Threshold models in time series analysis–30 years on. Statistics and

its Interface, 4(2):107–118, 2011.

H. Tong. Threshold models in time series analysis—some reﬂections. Jour-
nal of Econometrics, 189(2):485 – 491, 2017. doi: https://doi.org/10.1016/
j.jeconom.2015.03.039. URL http://www.sciencedirect.com/science/
article/pii/S0304407615001177.

31

R.S. Tsay. Testing and modeling multivariate threshold models. J. Amer.
Statist. Assoc., 93(443):1188–1202, 1998. ISSN 01621459. URL http://www.
jstor.org/stable/2669861.

A.W. van der Vaart. Asymptotic statistics. Cambridge series in statistical and

probabilistic Mathematics, Cambridge University Press, 1998.

C. S. Wong and W.K. Li. Testing for threshold autoregression with conditional
heteroscedasticity. Biometrika, 84(2):407–418, 1997. ISSN 00063444. URL
http://www.jstor.org/stable/2337466.

C. S. Wong and W.K. Li. Testing for double threshold autoregressive conditional
heteroscedastic model. Statist. Sinica, 10(1):173–189, 2000. ISSN 10170405,
19968507. URL http://www.jstor.org/stable/24306711.

Q. Yao, H. Tong, B. Finkenstadt, and N.C. Stenseth. Common Structure in
Panels of Short Ecological Time-Series. Proceedings: Biological Sciences,
267(1460):2459–2467, 2000. ISSN 09628452. URL http://www.jstor.org/
stable/2665657.

32

Supplement for:
The validity of bootstrap testing in the
threshold framework

Simone Giannerini, Greta Goracci, Anders Rahbek

Abstract
This Supplement has 3 sections. In Section A we present auxiliary technical
lemmas used in the proofs. Section B contains supplementary results from the
simulation study. Section C presents supplementary results on the analysis of
larvae population dynamics under the eﬀect of warming.

A Auxiliary Lemmas

Lemma 10. Let {X ∗
b2(c) to be two continuous functions in c such that

t , t = 1, . . . , n} be deﬁned in Eq. (13) and assume b1(c) and

lim
c→0

b1(c) = lim
c→0

b2(c) = C,

with C being a real number. Then, for each γ > 0 we can choose c suﬃciently
small such that

P ∗(b1(c) ≤ X ∗

t ≤ b2(c)) ≤

with probability one.

1
n

+ γ

(55)

Proof. From the deﬁnition of limit, for each γ > 0 we can choose c suﬃciently
small such that

P ∗(b1(c) ≤ X ∗

t ≤ b2(c)) ≤ P ∗(X ∗

t = C) + γ;
t = C) ≤ 1/n in probability. Deﬁne A∗

hence it remains to show that P ∗(X ∗
be the set of values that X ∗
fact that: (i) for any real number κ ∈ R, P ∗(ε∗
one and (ii) (cid:80)
P ∗(X ∗

t to
t can assume conditionally to the data. By using the
t = κ) ≤ 1/n with probability

s = a) = 1, for any integer s, it holds that

a∈A∗
s

P ∗(X ∗
t = C)
(cid:88)

=

=

≤

P ∗(X ∗

t = C|X ∗

t−1 = a)P ∗(X ∗

t−1 = a)

t−1

a∈A∗
(cid:88)

P ∗(ε∗

t = C − ˜φ0 − ˜φ1a)P ∗(X ∗

t−1 = a)

a∈A∗

t−1
(cid:88)

1
n

a∈A∗

t−1

P ∗(X ∗

t−1 = a) =

1
n

1

and the proof is completed.

Lemma 11. (LLN) Let {ε∗
holds that:

t } be deﬁned in Section 3. Under Assumption 1 , it

E∗[ε∗2
t ]

p
−−−−→
n→∞

σ2

and E∗[ε∗4
t ]

p
−−−−→
n→∞

κ.

Proof. Since

˜εt = (φ0,0 − ˜φ0) +

p
(cid:88)

i=1

(φi,0 − ˜φi)Xt−i + εt

and ( ˜φ − φ0) = Op(n−1/2), it follows that

¯˜ε :=

1
n

n
(cid:88)

t=1

˜εt =

1
n

(cid:34)

n
(cid:88)

t=1

(φ0,0 − ˜φ0) +

p
(cid:88)

(φi,0 − ˜φi)Xt−i + εt

(cid:35)

i=1

converges in probability to zero. Similarly, by routine algebra, it is possible to
t=1 (˜εt − ¯˜ε)4 converge
t ] = 1
show that E∗[ε∗2
n
in probability to σ2 and κ respectively.

t=1 (˜εt − ¯˜ε)2 and E∗[ε∗4

t ] = 1
n

(cid:80)n

(cid:80)n

B Supplementary Monte Carlo results

B.1 Empirical (uncorrected) power of the tests

Table 1 reports the (uncorrected) power of the tests at nominal level α = 5%
for the TAR(1) process of Eq. (26).

n = 50

n = 100

n = 200

Ψ ARa ARi ARa ARi ARa

ARi

0.0
0.3
0.6
0.9

0.0
0.3
0.6
0.9

9.1
12.0
26.3
52.5

3.5
4.3
6.5
10.1

4.9
9.0
27.3
54.8

4.4
5.0
8.0
12.1

6.8
17.4
59.8
91.3

3.8
5.9
12.4
32.1

6.2
18.3
62.4
92.2

5.4
8.2
14.9
34.1

5.2
42.1
94.1
100.0

3.9
7.3
33.8
65.8

5.2
44.3
94.4
100.0

5.2
8.6
36.8
68.1

Table 1: Empirical power at nominal level α = 5% for the TAR(1) process of
Eq. (26).

2

C Supplementary results from the real applica-
tion: the eﬀect of warming on populations of
larvae

The data come from the study published in Laughton and Knell [2019a] and are
publicly available at Laughton and Knell [2019b].

Figure 5: Time series of 12 populations of P. interpunctella from week 11 to 82
for diﬀerent experimental conditions. The series have been square-root trans-
formed.

3

10203040506070805101520weekTemp:27–Diet:poor–Rep:110203040506070805101520weekTemp:27–Diet:poor–Rep:210203040506070805101520weekTemp:27–Diet:poor–Rep:310203040506070805101520weekTemp:27–Diet:good–Rep:110203040506070805101520weekTemp:27–Diet:good–Rep:210203040506070805101520weekTemp:27–Diet:good–Rep:310203040506070805101520weekTemp:30–Diet:poor–Rep:110203040506070805101520weekTemp:30–Diet:poor–Rep:210203040506070805101520weekTemp:30–Diet:poor–Rep:310203040506070805101520weekTemp:30–Diet:good–Rep:110203040506070805101520weekTemp:30–Diet:good–Rep:210203040506070805101520weekTemp:30–Diet:good–Rep:3Figure 6: (Left) Power spectral density of the simulated time series of 100k
observations from the model ﬁt of the ﬁrst time series (temp: 27°, diet: poor).
The frequency corresponding to the characteristic 6-week cycle is evidenced
with a vertical dashed line.(Right) Histogram of the data (yellow) with the
superimposed density of the ﬁtted model, estimated upon the simulated series
(blue line).

Figure 7: (Left) Power spectral density of the simulated time series of 100k
observations from the model ﬁt of the third time series (temp: 30°, diet: poor).
The frequency corresponding to the characteristic 6-week cycle is evidenced
with a vertical dashed line.(Right) Histogram of the data (yellow) with the
superimposed density of the ﬁtted model, estimated upon the simulated series
(blue line).

4

0.00.10.20.30.40.50.51.02.05.010.020.050.0frequencyspectrum1/6XtDensity4681012140.000.050.100.150.20simulated0.00.10.20.30.40.50.51.02.05.010.020.0frequencyspectrum1/6XtDensity6810121416180.000.050.100.15simulatedFigure 8: (Left) Power spectral density of the simulated time series of 100k
observations from the model ﬁt of the third time series (temp: 30°, diet: poor).
The frequency corresponding to the characteristic 6-week cycle is evidenced
with a vertical dashed line.(Right) Histogram of the data (yellow) with the
superimposed density of the ﬁtted model, estimated upon the simulated series
(blue line).

5

0.00.10.20.30.40.52468frequencyspectrum1/6XtDensity810121416180.000.050.100.150.200.25simulatedFigure 9: Temperature: 27° - Diet: poor. Correlograms of the residuals of
the TARMA model of Eq. (29). Autocorrelation function (left) and partial
autocorrelation function (right). The blue dashed lines indicate the rejection
bands at 99% level.

6

05101520-1.0-0.50.00.51.0LagACFResiduals5101520-1.0-0.50.00.51.0LagPartialACFResiduals05101520-1.0-0.50.00.51.0LagACFSquaredresiduals5101520-1.0-0.50.00.51.0LagPartialACFSquaredresidualsFigure 10: Temperature: 27° - Diet: good. Correlograms of the residuals of
the TARMA model of Eq. (29). Autocorrelation function (left) and partial
autocorrelation function (right). The blue dashed lines indicate the rejection
bands at 99% level.

7

05101520-1.0-0.50.00.51.0LagACFResiduals5101520-1.0-0.50.00.51.0LagPartialACFResiduals05101520-1.0-0.50.00.51.0LagACFSquaredresiduals5101520-1.0-0.50.00.51.0LagPartialACFSquaredresidualsFigure 11: Temperature: 30° - Diet: poor. Correlograms of the residuals of
the TARMA model of Eq. (29). Autocorrelation function (left) and partial
autocorrelation function (right). The blue dashed lines indicate the rejection
bands at 99% level.

8

05101520-1.0-0.50.00.51.0LagACFResiduals5101520-1.0-0.50.00.51.0LagPartialACFResiduals05101520-1.0-0.50.00.51.0LagACFSquaredresiduals5101520-1.0-0.50.00.51.0LagPartialACFSquaredresidualsFigure 12: Temperature: 30° - Diet: good. Correlograms of the residuals of
the TARMA model of Eq. (29). Autocorrelation function (left) and partial
autocorrelation function (right). The blue dashed lines indicate the rejection
bands at 99% level.

temp.

diet

W p-value

27
27

30
30

poor
good

poor
good

0.989
0.984

0.987
0.963

0.849
0.578

0.730
0.046

Table 2: Shapiro Wilk normality test statistic and p-values for the residuals of
the ﬁtted threshold ARMA models.

9

05101520-1.0-0.50.00.51.0LagACFResiduals5101520-1.0-0.50.00.51.0LagPartialACFResiduals05101520-1.0-0.50.00.51.0LagACFSquaredresiduals5101520-1.0-0.50.00.51.0LagPartialACFSquaredresiduals