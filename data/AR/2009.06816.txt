MICROSCOPE BASED HER2 SCORING SYSTEM

A PREPRINT

Jun Zhang
Tencent AI Lab
Shenzhen, Guangdong,
China
junejzhang@tencent.com

Kuan Tian
Tencent AI Lab
Shenzhen, Guangdong,
China
kuantian@tencent.com

Pei Dong
Tencent AI Lab
Shenzhen, Guangdong,
China
peidong@tencent.com

Haocheng Shen
Tencent AI Lab
Shenzhen, Guangdong,
China
hcshen@tencent.com

Kezhou Yan
Tencent AI Lab
Shenzhen, Guangdong,
China
kezhouyan@tencent.com

Jianhua Yao
Tencent AI Lab
Shenzhen, Guangdong,
China
jianhuayao@tencent.com

Junzhou Huang
Tencent AI Lab
Shenzhen, Guangdong,
China
joehhuang@tencent.com

Xiao Han
Tencent AI Lab
Shenzhen, Guangdong,
China
haroldhan@tencent.com

September 16, 2020

ABSTRACT

The overexpression of human epidermal growth factor receptor 2 (HER2) has been established as
a therapeutic target in multiple types of cancers, such as breast and gastric cancers. Immunohisto-
chemistry (IHC) is employed as a basic HER2 test to identify the HER2-positive, borderline, and
HER2-negative patients. However, the reliability and accuracy of HER2 scoring are affected by
many factors, such as pathologists’ experience. Recently, artiﬁcial intelligence (AI) has been used
in various disease diagnosis to improve diagnostic accuracy and reliability, but the interpretation
of diagnosis results is still an open problem. In this paper, we propose a real-time HER2 scoring
system, which follows the HER2 scoring guidelines to complete the diagnosis, and thus each step is
explainable. Unlike the previous scoring systems based on whole-slide imaging, our HER2 scoring
system is integrated into an augmented reality (AR) microscope that can feedback AI results to the
pathologists while reading the slide. The pathologists can help select informative ﬁelds of view
(FOVs), avoiding the confounding regions, such as DCIS. Importantly, we illustrate the intermediate
results with membrane staining condition and cell classiﬁcation results, making it possible to evaluate
the reliability of the diagnostic results. Also, we support the interactive modiﬁcation of selecting
regions-of-interest, making our system more ﬂexible in clinical practice. The collaboration of AI and
pathologists can signiﬁcantly improve the robustness of our system. We evaluate our system with 285
breast IHC HER2 slides, and the classiﬁcation accuracy of 95% shows the effectiveness of our HER2
scoring system.

0
2
0
2

p
e
S
5
1

]

V

I
.
s
s
e
e
[

1
v
6
1
8
6
0
.
9
0
0
2
:
v
i
X
r
a

1

Introduction

Human epidermal growth factor receptor 2 (HER2) overexpression has been discovered implicative in the development
of multiple types of cancers (e.g., breast and gastric cancers). For example, HER2 is a protein that promotes the growth
of breast cancer cells, and it is overexpressed in around 20-30% of breast cancer tumors [1]. The ampliﬁcation or

 
 
 
 
 
 
Microscope Based HER2 Scoring System

A PREPRINT

Table 1: Breast HER2 scoring guidelines.

HER2 score
IHC 3+ (positive)
IHC 2+ (equivocal)
IHC 1+ (negative)
IHC 0 (negative)

Staining condition
Circumferential membrane staining that is complete and intense
Weak to moderate complete membrane staining
Incomplete membrane staining that is faint/barely

Proportion
≥ 10% of tumor cells
≥ 10% of tumor cells
≥ 10% of tumor cells
No staining/membrane staining that is incomplete and is faint/barely < 10% of tumor cells

overexpression of this oncogene can cause aggressive breast cancer, which has a high recurrence rate and short survival.
Therefore, the HER2 protein has been employed as a signiﬁcant biomarker/target of selecting a proper therapy plan
(e.g., trastuzumab therapy) for breast cancer patients.

Immunohistochemistry (IHC) HER2 test is a basic test to see whether a cancer cell has too much of the HER2 receptor
protein on the surface (i.e., membrane). Currently, the HER2 score is non-quantitatively (or at most half-quantitatively)
provided by pathologists according to membranous staining of the HER2 protein. The score is given from 0 to 3+ based
on the scoring guidelines, such as the American Society of Clinical Oncology and the College of American Pathologists
(ASCO/CAP) guidelines for breast cancer (as shown in Table 1). However, visual estimation usually has the problem of
intraobserver/interobserver variability.

Artiﬁcial intelligence (AI) is widely used in disease analysis. Many studies have approved that end-to-end training
for disease diagnosis is efﬁcient and accurate [2, 3, 4, 5]. However, the interpretation of diagnostic results is still an
open problem. For some special applications that the diagnoses of the disease have clear guidelines, it would be more
convincing to calculate the clinically deﬁned measurements for the quantitative analysis. HER2 scoring is one speciﬁc
clinical application that has clear guidelines to follow to complete the diagnosis.

Currently, there are two ways of using AI to assist pathologists. One solution is utilizing the whole-slide images that are
typically acquired at magniﬁcations of 20× or 40×, generating gigapixel two-dimensional images that are challenging
for computer calculation in an exhaustive manner. Also, it is not easy to distinguish some confounding regions, such as
ductal carcinoma in situ (DCIS), from inﬁltrating carcinoma without seeing H&E and other immunohistochemistries
(e.g., p63, Calponin, SMMHC, SMA, and CD10). Differently, with the use of real-time imaging of microscope,
pathologists can help AI system to select typical ﬁelds of view (FOVs). In return, pathologists can further beneﬁt
from the AI-assisted microscope by presenting both qualitative cell/membrane illustration and quantitative statistics.
Furthermore, the interaction between pathologists and AI helps achieve accurate and robust diagnostic results. Notably,
fully automatic may not that necessary in current clinical practice.

In this paper, we propose a real-time HER2 scoring system based on an augmented reality (AR) microscope for breast
cancer, which follows the breast HER2 scoring guidelines (see Table 1) to make the diagnosis, and thus each step
is explainable. Besides analyzing the staining membrane only, we perform a cell-level classiﬁcation to accomplish
the scoring target. Importantly, we illustrate the intermediate results with membrane staining condition and cell
classiﬁcation results, making it possible to evaluate the reliability of the diagnostic results. Our system also supports the
interactive modiﬁcation of tumor regions and a slight adjustment of cell classiﬁcation results, improving its robustness
and ﬂexibility in the clinical application. Overall, our system has the following features.

• Our scoring system is integrated into the microscope, which adapts the existing workﬂow of the pathologists.
• Our diagnostic results are obtained according to the current HER2 scoring guidelines, which has legible

interpretability.

• Besides membrane delineating, our AI results also contain cell-level detection and classiﬁcation, which

provides accurate quantitative analysis.

• The intermediate results of membrane extraction and cell classiﬁcation are visually illustrated to the patholo-

gists, which can be used to evaluate/rectify the correctness of results.

• Our system also supports interactive modiﬁcation, which makes our system more robust in clinical practice.

2 Related Work

As shown in Table 1, ASCO/CAP breast HER2 interpretation guidelines classify the slides into four scores (i.e., 0, 1+,
2+, and 3+), according to the staining patterns of the membrane and the proportions of these staining patterns. The
scores of 1+/0, 2+, and 3+ are deﬁned as HER2-negative, borderline, and HER2-positive, respectively. The existing
HER2 scoring methods achieve the classiﬁcation task using two types of categories, including conventional image
processing-based and machine-learning-based methods (especially for deep learning).

2

Microscope Based HER2 Scoring System

A PREPRINT

Figure 1: Typical views in breast cancer HER2 slides with different HER2 scores.

2.1 Methods based on conventional image processing

A typical method for HER2 scoring is the ImmunoMembrane [6]. The method performs the HER2 scoring by identifying
the completeness and area proportion of the staining membrane. The membrane staining condition is transformed
into an IM-score for further classiﬁcation (0/1+, 2+, or 3+). Another software named HER2-CONNECTTM [7] was
developed for HER2 scoring based on the connectivity of membrane in region-of-interest (ROI). Very high overall
percentage agreement between automated scoring and ground-truth labels was achieved. There are also some other
studies using computer-aided diagnosis software for calculating quantitative measures [8, 9, 10]. Most of the methods
rely on manual intervention (e.g., delineating regions-of-interest). Besides, some commercial analysis systems (e.g.,
BLISS from Bacus Laboratories, ACIS from Clarient, and ScanScope from DakoCytomation) are developed for the
scoring of HER2. With such quantitative software, studies have performed quantitative digital image analysis for
HER2 ROIs/WSI, and the results suggested that such quantitative measures have good concordance with experienced
pathologists’ read and could reduce HER2 IHC equivocal (2+) cases [11, 7, 12, 13, 14]. However, these methods
analyze the stained membranes only, and the scoring strategies is different from the criteria in HER2 scoring guidelines.

2.2 Methods based on machine learning

Masmoudi et al. proposed to extract quantitative features (i.e., membrane completeness and average membrane intensity)
related to HER2 membrane staining for ROI images, and a minimum cluster distance (MCD) classiﬁer is employed
to construct the automated IHC assessment of HER2 score in the breast cancer tissue WSI [15]. Vandenberghe et
al. developed an automated HER2 scoring method based on deep learning [16]. The cancer cell types (i.e., immune
cells, stromal cells, artifacts, tumor 0 cells, tumor 1+ cells, tumor 2+ cells, and tumor 3+ cells) are automatically
classiﬁed by neural network model. Thus, the HER2 scores could be estimated with the percentage of these cells.
However, accurate annotations of these different types of cells are challenging. Saha et al. proposed a Her2Net for
both nuclei and membrane segmentation, followed by a HER2 score classiﬁcation [17]. However, the method was
evaluated in small patch-level image classiﬁcation. Khameneh et al. developed a deep learning framework for WSI
image classiﬁcation [18]. First, the epithelial tissue is identiﬁed using a superpixel-based support vector machine (SVM)
classiﬁer. Then, a neural network (i.e., U-Net) is employed for membrane segmentation. Finally, the overall score based
on intensity and completeness of the WSI can be calculated to perform the ﬁnal classiﬁcation of HER2 scores. Qaiser et
al. presented a method based on deep reinforcement learning to simulated a sequential learning task [4]. The model can
identify diagnostically relevant ROIs and then learn discriminative features, and the next relevant location is estimated
as well. These methods achieve state-of-the-art scoring performance on WSIs (or ROIs from WSIs). However, very few
HER2 scoring systems were designed for an AI-assisted microscope so far.

3 Microscope HER2 Scoring System

Our algorithm is integrated into an augmented reality (AR) microscope. Similar to the AR microscope developed by
Google [19], our microscope has the AR display and screen display. As shown in Fig. 2 (a), the pathologist reads the
slide normally, stays in the ﬁeld of view that needs to see the AI results, and presses the foot pedal button (returns a
signal to the computer to start the calculation). Then, the computer feeds back the calculated results to the AR screen
and the computer screen in real-time. The results of multiple typical FOVs are aggregated to calculate the HER2 score.

To obtain a convincing interpretation of the image, we perform the HER2 scoring strictly following the diagnostic
guidelines. As shown in Fig. 1, IHC HER2 slides can monitor the cell membrane overexpression. The IHC provides a

3

03+2+1+Microscope Based HER2 Scoring System

A PREPRINT

Figure 2: Framework of our microscope-based HER2 scoring system.

score from 0 to 3+ that measures the amount of HER2 proteins on the membrane of cells in a breast cancer tissue sample.
Generally, the tumor cells with HER2 overexpression are stained with diaminobenzidine (DAB) that is shown in brown,
and all nuclei are stained in blue. In order to complete the HER2 scoring according to the diagnostic guidelines, we
should identify the tumor cells and perform HER2 scoring according to the membrane staining condition (i.e., intensity
and completeness).

Speciﬁcally, as shown in Fig. 2, the AI results for each view includes the detection and classiﬁcation results in tumor
cells. We employ a deep learning algorithm for tumor nucleus detection and utilize the threshold-based segmentation
method to segment the cell membranes. The cell membranes are further rectiﬁed into several staining masks by image
skeletonization and morphological operation. Finally, the cells are classiﬁed into ﬁve categories according to the
associations between the detected nuclei and the staining masks. The AI results contain the recognized cells (shown in
distinct color points for each category) and contours of membranes (shown in distinct color lines for the complete and
incomplete cell membranes). After receiving AI results from multiple views, the proportion of each cell category is
employed to calculate the HER2 score according to the HER2 guidelines.

3.1 Training data preparation

In order to train a robust and accurate tumor nucleus detection model, cell-level point/bounding box annotations are
necessary. However, manually annotating nuclei in images are labor-expensive. For example, there are usually thousands
of nuclei in an image captured in the view of 20 power objective. Therefore, we propose to use a semiautomatic
annotation method from scratch. We ﬁrst employ an image-processing-based method to extract rough tumor nuclei
from images with the simple ﬁltering strategies.

For the standard staining, even if cancer cells are stained with intense/moderate membranes, stromal/immune cells
will not have brown membrane staining. As shown in 3 (a), we would like to detect the nuclei for regions with and
without stained membranes separately. With a color deconvolution method [20], we can rectify the RGB image to
Haematoxylin-Eosin-DAB (HED) color space. Then, the H channel and DAB channel images (i.e., IH, and IDAB) are
ﬁltered and enhanced separately by bilateral ﬁltering. Bilateral ﬁltering is a nonlinear ﬁlter that can achieve the effects
of maintaining edges and reducing noise and smoothing. With the enhanced images, we can identify the nuclei by
ﬁnding local maximums in IH and ﬁnding local minimums in IDAB. For the intensive DAB stained region, we would
like to use the nuclei from the DAB channel and nuclei from H channel otherwise. However, nuclei from H channel are
the nuclei from not only tumor cells but also from stromal/immune cells. Therefore, we perform simple segmentation
and remove stromal/immune nuclei by removing nuclei with small areas. Finally, we can merge the two types of nuclei
(from IH and IDAB) by whether they belong to the DAB regions. Fig. 3 (b) shows the nucleus detection results for two
images with intense staining and no staining, respectively. As shown in the ﬁgure, most of the nuclei can be correctly
detected.

With the initial coarse locations of tumor nuclei, pathologists also manually correct these detected results with our
online annotation tool, as shown in Fig. 4 (a), where false positive detections will be removed, and missing nuclei will
be added. By doing so, we will receive plenty of effective cell-level point annotations in a short period.

4

...View SelectionProportion of stained cellsIntense&complete: 0%Intense&incomplete: 20.0%Morderate(weak)&complete: 8.5%Morderate(weak)&incomplete: 79.3%No staining|weak: 2.2%HER2 score2+...Cell detection and  classification(a)SinglefieldofviewMembranedescriptionTumor nucleus DetectionTumorcellclassificationCellclassificationofmultipleviewsProportionofeachcategoryHER2scoreCellClassificationforeachviewHER2scoring(b)Microscope Based HER2 Scoring System

A PREPRINT

Figure 3: Initial rough nucleus generation based on image processing.

3.1.1 Heatmap Regression

Currently, there are many object/instance detection algorithms can be used for nucleus detection. In our algorithm, we
employ the heatmap regression using fully convolutional networks (FCN) in an end-to-end manner [21, 22]. Speciﬁcally,
the RGB image is input, and the output is a heatmap, where each nucleus has a Gaussian-like response centered on the
nucleus (as shown in Fig. 4 (b)). The mean square error constraint is used as the loss function to train the model. In the
inference stage, all tumor nuclei can be identiﬁed by ﬁnding the local maximum response position of the predicted
heatmap. To facilitate subsequent cell classiﬁcation, we denote the set of detected nuclei as Ddetected.

3.2 Tumor Membrane Description

Our membrane extraction is similar to the existing methods based on the segmentation of the stained membrane and
skeletonization of the segmentation mask. With the extracted contours by skeletonization, the completeness of the
membrane can be identiﬁed. Different from previous methods, we extract several segmentation masks to identify the
cells with varying styles of stains(intense/weak in membrane intensity and complete/incomplete in membrane contours).

3.2.1 Membrane Segmentation

We segment the membrane in the DAB channel image using a thresholding strategy. We ﬁrst perform the image
enhancement for IDAB. We employ a threshold tintense to obtain a intense-stained mask Mintense. Then, another
threshold tweak (< tintense) is used to segment the image IDAB to obtain a weakly/moderately brown-stained (DAB-
stained) image mask Mweak. Note that, this segmentation mask Mweak also contains intense-stained regions.

3.2.2 Skeletonization of Membrane

We employ the skeletonize algorithm [23] to extract the contour map Cweak from the segmented mask Mweak to
describe the cell membrane. We then analyze the skeleton by the contour connection. If the closed contour is the
innermost contour, we mark the contour as a complete cell membrane, and incomplete otherwise. Too avoid perform
the skeletonization for intense mask again, we obtain the skeleton (i.e., Cintense) of Mintense by ﬁnding the intersection
of Cweak and Mintense. It is not strict, but the bias is not large.

5

Immune cell removalIH, IE, IDABColor DeconvolutionEnhanced IHBilateral filterMembrane maskEnhanced IDABBinary SegmentationNuclei from H channel Nuclei from DAB channel Local MaximumLocal MinimumInput imageNucleiNucleus MaskOtsu’s segmentation Tumor nucleus maskTumor nucleiIntersectionNuclei in DAB region DAB stained regionDilation and filling holesNone DAB stained regionReversingTumor Nuclei outside DAB regionMergingIntersectionIntersectionImageNucleiImageNuclei(a) Framework of rough nucleus generation  (b) Results of rough nucleus generation Microscope Based HER2 Scoring System

A PREPRINT

Figure 4: Nucleus detection using deep neural networks.

3.2.3 Mask Extraction

We ﬁll the enclosed skeleton in Cweak to generate an enclosed area mask, named Mweak,enclosed (Figure 5), and
we deﬁne the set of coordinates of all foreground pixels in Mweak,enclosed as Pweak,enclosed. Similarly, we ﬁll the
enclosed area in Cintense to obtain Mintense,enclosed, and we deﬁne the set of coordinates of all foreground pixels in
Mintense,enclosed as Pintense,enclosed.
Besides extracting the two masks to represent enclosed area, we dilate the masks Mweak and Mintense with a kernel of
d to obtain the expanded masks of Eweak and Eintense respectively. The coordinates of all foreground pixels in Eweak
and Eintense consist of two point sets Pweak and Pintense respectively. The kernel d is a kind of distance parameter that
is related to the radius of the cancer cells. The example masks are shown in Fig. 5.

3.3 Strategy-based Cell Classiﬁcation

To classify the detected tumor cells, it is necessary to quantify the cell staining (whether it is completely wrapped
by intense, moderate/weak cell membranes). We recognize the cell types by a set of foreground coordinates (i.e.,
Pweak,enclosed, Pintense,enclosed, Pweak, Pintense) from multiple segmentation masks. We denote the set of all points in
the entire image is U.

1. Intense & complete tumor cells. The set of this type of cells is denoted as Tintense,complete, which is calculated

(cid:84) Pintense,enclosed. The number of this category is marked as card(Tintense,complete).

as Ddetected

2. Intense & incomplete tumor cells. The set of this type of cells is denoted as Tintense,incomplete, which
(cid:84) Pintense. The number of this category is marked as

(cid:84) CUPintense,enclosed

is calculated as Ddetected
card(Tintense,incomplete).

3. Moderate (weak) & complete tumor cells. The set of this type of cells is denoted as Tweak,complete, which
(cid:83) Tintense,incomplete) (cid:84) Pweak,enclosed. The number of this

(cid:84) CU(Tintense,complete

is calculated as Ddetected
category is marked as card(Tweak,complete).

4. Moderate (weak) & incomplete tumor cells. The set of this type of cells is denoted as Tweak,incomplete, which is
(cid:83) Tweak,complete) (cid:84) Pweak,enclosed. The

(cid:84) CU(Tintense,complete

(cid:83) Tintense,incomplete

calculated as Ddetected
number of this category is marked as card(Tweak,incomplete).

6

FCNImageHeatmapRough estimationsManual correctionCorrected annotations (a) Data preparation(b) Nucleus detection using deep neural networksMicroscope Based HER2 Scoring System

A PREPRINT

Figure 5: Extracted image masks for HER2 scoring.

5. No staining tumor cells. The set of this type of cells is denoted as Tnostaining, which is calculated as
(cid:83) Tweak,incomplete). The number of

(cid:83) Tintense,incomplete

(cid:83) Tweak,complete

(cid:84) CU(Tintense,complete
Ddetected
this category is marked as card(Tnostaining).

3.4 HER2 Scoring

The HER2 scoring guidelines (such as breast cancer guidelines) are deﬁned on the whole slide of HER2, and the
microscope provides several FOVs selected by pathologists. Therefore, it is difﬁcult to stitch these FOVs to a whole
slide image. In view of this, we require the pathologists to select multiple typical FOVs that approximately represent
the whole slide for HER2 scoring. Speciﬁcally, our HER2 scoring has the following steps:

1. A radiologist is responsible for reading the whole slide and collecting multiple microscopic FOVs that typically
include invasive cancer (because the HER2 score is deﬁned on the staining of invasive cancer cells), such as
5-10 microscopic FOVs (both 20 and 40 power objectives can be selected).

2. During the reading, our AI algorithm provides both quantitative counts and qualitative illustration of cell

locations and membranes for each view in real-time.

3. After selecting necessary typical FOVs, our system calculates the overall proportion of cells with different

staining patterns for all FOVs.

4. According to the scoring criteria in guidelines, we can determine the HER2 score. For example, if the

proportion of intense&complete cells exceeds 10%, it will be a 3+ HER2 slide.

3.5

Implementation Details

The size of image for each FOV is 3008 × 3008, with the pixel size of 0.212 × 0.212µm2 and 0.424 × 0.424µm2
for 40x and 20x respectively. The nucleus detection model is trained from 2927 image patches (with the size of
2048 × 2048) cropped from around 500 WSIs scanned in 40x magniﬁcation. We train the model for the pixel size of
0.212 × 0.212µm2 and 0.424 × 0.424µm2, respectively. The data augmentation includes slightly scaling, rotation,
ﬂipping, grammar transform, and smoothing. We employ the LinkNet [24] with Mean Square Error (MSE) loss for
nucleus detection. Adam optimizer is selected with a learning rate of 0.001. In order to speed up the algorithm, we
perform the nucleus detection in the original resolution, but the downsampled image (1504 × 1504) for all the other
processings.

7

IIDABMweakMintenseMweak,enclosedMintense,enclosedEweakEintenseMicroscope Based HER2 Scoring System

A PREPRINT

Table 2: Results for tumor nucleus detection

Method
Recall
Precision
F1-score

20x
0.92
0.73
0.81

40x
0.91
0.76
0.82

Table 3: Classiﬁcation results for whole slides.

Method
khameneh et al. [18]
Qaiser et al. [4]
Ours

Data
127 WSIs
86WSIs
285 slides

Accuracy
0.87
0.79
0.95

4 Results

We quantitatively evaluate the nucleus detection and ﬁnal HER2 scoring. The nucleus detection is evaluated in terms of
Recall, Precision, and F1-score. The distance between detected nucleus and ground-truth nucleus less than 5µm is
regarded as the true positive detections. For HER2 coring, we employ the evaluation for each view and whole slide,
respectively. Note that, it is not preciseness to deﬁne the score for each view, but the scoring for each view can evaluate
the algorithm exhaustively. Note that, it would be good to evaluate the classiﬁcation performance of cells. However, it
is challenging to manually annotate the cells with speciﬁc class labels. Therefore, we directly evaluate the performance
of HER2 scoring.

4.1 Results for nucleus detection

We evaluate the tumor nucleus detection performance on the independent dataset, which contains 20 images captured
from 20x FOVs and 20 images captured from 40x FOVs. Note that, the FOVs do not include the DCIS regions. As shown
in Table 2, the tumor nuclei could be detected in a very high recall for both 20x and 40x FOVs. Compared with the results
in 20x FOVs, slightly better precision could be achieved for 40x FOVs, due to more detailed structural information
could be captured. Overall, the tumor nucleus detection method using heatmap regression can achieve satisfactory
detection performance and can distinguish the tumor cells from others, such as stromal cells and lymphocytes.

4.2 Results for slide-level HER2 scoring

We evaluate our system with 285 breast HER2 slides. The pathologists read each slide regularly and save necessary
views (by pressing the foot pedal) for our AI system. To our knowledge, most of the existing HER2 scoring methods
perform the classiﬁcation task on the image patches (from WSI) or WSI. It is difﬁcult to ﬁnd a fair application scenario
to compare different methods. As shown in Table 3, we only report several methods for the classiﬁcation of WSI in their
studies. Compared with the existing methods, our microscope-based system achieves superior scoring performance on a
much larger dataset.

5 Discussion

5.1 Pathologist-AI Interaction

Our system is integrated into the microscope that relies on the interactive FOV selection by pathologists. Taking
advantage of the knowledge of pathologists, we can tackle the tough problem of distinguishing ductal carcinoma
in situ (DCIS). On the one hand, the pathologists can avoid selecting FOVs having DCIS as well as inﬂammation
regions. If it is difﬁcult to avoid such confounding areas, we also provide a tool that can manually outline regions of
interest. On the other hand, AI helps pathologists count cells accurately, which is almost impossible for pathologists to
complete the counting task in multiple views. Because of the collaboration between pathologists and AI, the accurate
and robust diagnoses could be achieved. Hopefully, precise quantization can help provide more explicit information for
the following treatment.

8

Microscope Based HER2 Scoring System

A PREPRINT

Table 4: Computational cost for each FOV in our HER2 scoring system.

Total Nucleus Detection Membrane Description Cell Classiﬁcation
0.6s

0.1s

0.2s

0.3s

5.2 Thresholds for membrane segmentation

Both the intense threshold tintense and moderate/weak threshold tweak were jointly adjusted to classify the 1000 FOVs,
including challenging cases. Therefore, we select two thresholds that achieve the best classiﬁcation performance.
However, the staining style for IHC is not that consistent for using different staining reagents and types of equipment.
In response to this, we have a tool bar for pathologists to further ﬁnetune these two thresholds subjectively to adjust
various staining condition.

5.3 Extension to have more speciﬁc quantization levels

In this version of the HER2 scoring system, the moderate/weak staining membrane is regarded as a merged category for
simplicity. It is easy to extend our method to classify the tumor cells into more speciﬁc categories to further differentiate
the weak and moderate staining membrane. We have quantitatively evaluated the system with complex cell categories,
there was no signiﬁcant performance difference but slightly increasing the computational time.

5.4 Extension to other cancer types

Currently, we develop the algorithm according to the breast guidelines. Our method can be potentially extended to other
cancer types, such as gastric and gastroesophageal junction cancer. However, the deﬁnition of HER2 scores may be
different in different cancer guidelines. Slightly modiﬁcation of the scoring criteria will be necessary.

5.5 Computational cost

We also analyze the computational cost of our HER2 scoring system. Since our system is integrated to the microscope,
the efﬁciency is an important indicator for clinical application. Table 4 reports the computational cost for each module
W-2133, 3.6GHz) and a GPU (Geforce RTX 2080, 8G) are employed in this
of our system. A CPU (Intel
experiment.

Xeon

(cid:114)

(cid:114)

6 Conclusion

In this paper, we presented a HER2 scoring system based on the microscope, which can be integrated to pathologists’
the routine workﬂow. Notably, we followed the HER2 scoring guidelines to perform the interpretation, making it easy
to understand. Moreover, the pathologists can also help select informative FOVs and reduce the effect of confounding
regions of DCIS. The validation on a set of 285 HER2 slides showed the effectiveness of our system. Hopefully, our
method can improve diagnostic accuracy and both the inter-/intra-observer reliability.

References

[1] Zahi Mitri, Tina Constantine, and Ruth O’Regan. The HER2 receptor in breast cancer: pathophysiology, clinical

use, and new advances in therapy. Chemotherapy Research and Practice, 2012, 2012.

[2] Zizhao Zhang, Pingjun Chen, Mason McGough, Fuyong Xing, Chunbao Wang, Marilyn Bui, Yuanpu Xie, Manish
Sapkota, Lei Cui, Jasreman Dhillon, et al. Pathologist-level interpretable whole-slide cancer diagnosis with deep
learning. Nature Machine Intelligence, 1(5):236–245, 2019.

[3] Gabriele Campanella, Matthew G Hanna, Luke Geneslaw, Allen Miraﬂor, Vitor Werneck Krauss Silva, Klaus J
Busam, Edi Brogi, Victor E Reuter, David S Klimstra, and Thomas J Fuchs. Clinical-grade computational
pathology using weakly supervised deep learning on whole slide images. Nature Medicine, 25(8):1301–1309,
2019.

[4] Talha Qaiser and Nasir M Rajpoot. Learning where to see: A novel attention model for automated immunohisto-

chemical scoring. IEEE Transactions on Medical Imaging, 38(11):2620–2631, 2019.

9

Microscope Based HER2 Scoring System

A PREPRINT

[5] Chunfeng Lian, Mingxia Liu, Jun Zhang, and Dinggang Shen. Hierarchical fully convolutional network for joint
atrophy localization and Alzheimer’s disease diagnosis using structural MRI. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 42(4), 2020.

[6] Vilppu J Tuominen, Teemu T Tolonen, and Jorma Isola. Immunomembrane: a publicly available web application

for digital image analysis of HER2 immunohistochemistry. Histopathology, 60(5):758–767, 2012.

[7] Anja Brügmann, Mikkel Eld, Giedrius Lelkaitis, Søren Nielsen, Michael Grunkin, Johan D Hansen, Niels T
Foged, and Mogens Vyberg. Digital image analysis of membrane connectivity is a robust measure of HER2
immunostains. Breast Cancer Research and Treatment, 132(1):41–49, 2012.

[8] Kristina A Matkowskyj, Dan Schonfeld, and Richard V Benya. Quantitative immunohistochemistry by measuring
cumulative signal strength using commercially available software photoshop and matlab. Journal of Histochemistry
& Cytochemistry, 48(2):303–311, 2000.

[9] Hans-Anton Lehr, Timothy W Jacobs, Hadi Yaziji, Stuart J Schnitt, and Allen M Gown. Quantitative evaluation of
her-2/neu status in breast cancer by ﬂuorescence in situ hybridization and by immunohistochemistry with image
analysis. American Journal of Clinical Pathology, 115(6):814–822, 2001.

[10] Yutaka Hatanaka, Kaoru Hashizume, Yuki Kamihara, Hitoshi Itoh, Hitoshi Tsuda, R Yoshiyuki Osamura, and
Yoichi Tani. Quantitative immunohistochemical evaluation of HER2/neu expression with herceptesttm in breast
carcinoma by image analysis. Pathology International, 51(1):33–36, 2001.

[11] Aidan C Li, Jing Zhao, Chao Zhao, Zhongliang Ma, Ramon Hartage, Yunxiang Zhang, Xiaoxian Li, and Anil V
Parwani. Quantitative digital imaging analysis of HER2 immunohistochemistry predicts the response to anti-HER2
neoadjuvant chemotherapy in HER2-positive breast carcinoma. Breast Cancer Research and Treatment, pages
1–9, 2020.

[12] Henrik Holten-Rossing, Maj-Lis Møller Talman, Martin Kristensson, and Ben Vainer. Optimizing HER2
assessment in breast cancer: application of automated image analysis. Breast Cancer Research and Treatment,
152(2):367–375, 2015.

[13] Aida Laurinaviciene, Darius Dasevicius, Valerijus Ostapenko, Sonata Jarmalaite, Juozas Lazutka, and Arvydas
Laurinavicius. Membrane connectivity estimated by digital image analysis of HER2 immunohistochemistry is
concordant with visual scoring and ﬂuorescence in situ hybridization results: algorithm evaluation on breast cancer
tissue microarrays. Diagnostic Pathology, 6(1):87, 2011.

[14] Henrik O Helin, Vilppu J Tuominen, Onni Ylinen, Heikki J Helin, and Jorma Isola. Free digital image analysis
software helps to resolve equivocal scores in HER2 immunohistochemistry. Virchows Archiv, 468(2):191–198,
2016.

[15] Hela Masmoudi, Stephen M Hewitt, Nicholas Petrick, Kyle J Myers, and Marios A Gavrielides. Automated
quantitative assessment of HER-2/neu immunohistochemical expression in breast cancer. IEEE Transactions on
Medical Imaging, 28(6):916–925, 2009.

[16] Michel E Vandenberghe, Marietta LJ Scott, Paul W Scorer, Magnus Söderberg, Denis Balcerzak, and Craig Barker.
Relevance of deep learning to facilitate the diagnosis of HER2 status in breast cancer. Scientiﬁc Reports, 7:45938,
2017.

[17] Monjoy Saha and Chandan Chakraborty. Her2net: A deep framework for semantic segmentation and classiﬁcation
of cell membranes and nuclei in breast cancer evaluation. IEEE Transactions on Image Processing, 27(5):2189–
2200, 2018.

[18] Fariba Damband Khameneh, Salar Razavi, and Mustafa Kamasak. Automated segmentation of cell membranes to
evaluate HER2 status in whole slide images using a modiﬁed deep learning network. Computers in Biology and
Medicine, 110:164–174, 2019.

[19] Po-Hsuan Cameron Chen, Krishna Gadepalli, Robert MacDonald, Yun Liu, Shiro Kadowaki, Kunal Nagpal, Timo
Kohlberger, Jeffrey Dean, Greg S Corrado, Jason D Hipp, et al. An augmented reality microscope with real-time
artiﬁcial intelligence integration for cancer diagnosis. Nature Medicine, 25(9):1453–1457, 2019.

[20] Arnout C Ruifrok, Dennis A Johnston, et al. Quantiﬁcation of histochemical staining by color deconvolution.

Analytical and quantitative cytology and histology, 23(4):291–299, 2001.

[21] Christian Payer, Darko Štern, Horst Bischof, and Martin Urschler. Regressing heatmaps for multiple landmark
localization using CNNs. In International Conference on Medical Image Computing and Computer-Assisted
Intervention, pages 230–238. Springer, 2016.

[22] Jun Zhang, Mingxia Liu, Li Wang, Si Chen, Peng Yuan, Jianfu Li, Steve Guo-Fang Shen, Zhen Tang, Ken-
Chung Chen, James J Xia, et al. Context-guided fully convolutional networks for joint craniomaxillofacial bone
segmentation and landmark digitization. Medical Image Analysis, 60:101621, 2020.

10

Microscope Based HER2 Scoring System

A PREPRINT

[23] TY Zhang and Ching Y. Suen. A fast parallel algorithm for thinning digital patterns. Communications of the ACM,

27(3):236–239, 1984.

[24] Abhishek Chaurasia and Eugenio Culurciello. Linknet: Exploiting encoder representations for efﬁcient semantic
segmentation. In 2017 IEEE Visual Communications and Image Processing (VCIP), pages 1–4. IEEE, 2017.

11

