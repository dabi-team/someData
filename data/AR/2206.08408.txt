SUBMITTED TO IEEE TRANSACTIONS ON AUTOMATIC CONTROL, JUNE 2022

1

A behavioral approach to data-driven control
with noisy input-output data

H.J. van Waarde, J. Eising, M.K. Camlibel, Senior Member, IEEE, and H.L. Trentelman, Life Fellow, IEEE

2
2
0
2

n
u
J

6
1

]

C
O
.
h
t
a
m

[

1
v
8
0
4
8
0
.
6
0
2
2
:
v
i
X
r
a

Abstract— This paper deals with data-driven stability
analysis and feedback stabillization of linear input-output
systems in autoregressive (AR) form. We assume that noisy
input-output data on a ﬁnite time-interval have been ob-
tained from some unknown AR system. Data-based tests
are then developed to analyse whether the unknown sys-
tem is stable, or to verify whether a stabilizing dynamic
feedback controller exists. If so, stabilizing controllers are
computed using the data. In order to do this, we employ
the behavioral approach to systems and control, meaning
a departure from existing methods in data driven control.
Our results heavily rely on a characterization of asymp-
totic stability of systems in AR form using the notion of
quadratic difference form (QDF) as a natural framework
for Lyapunov functions of autonomous AR systems. We
introduce the concepts of informative data for quadratic
stability and quadratic stabilization in the context of input-
output AR systems and establish necessary and sufﬁcient
conditions for these properties to hold. In addition, this
paper will build on results on quadratic matrix inequalties
(QMIs) and a matrix version of Yakubovich’s S-lemma.

Index Terms— Data-driven control, behavioral approach,
quadratic matrix inequalities, S-procedure, robust control.

I. INTRODUCTION

Data-driven analysis and control is a research topic that has
received a lot of attention in the past few years. The idea that
lies at the core of this research area is to use data obtained
from an unknown dynamical system to verify certain system
properties and to design control laws for that system. The main
challenge is to do the analysis and design without the usual
ﬁrst step of establishing a mathematical model of the system
(for example by using ﬁrst principles modeling or system
identiﬁcation), but work directly with the data instead. This
has been the subject of many recent publications in the area,
for a large part in the context of input-state-output systems
and under the assumption that the system’s state is measured,
see e.g. [1]–[7].

There are different contributions that extend these results
to input-output measurements [8]–[11]. A general strategy,
adopted by all of these papers, is to rely on an artiﬁcial state-
space representation of the system with a state comprised
of shifts of the inputs and outputs. This leads to an input-
state-output system to which techniques for state data are

H.J. van Waarde, M.K. Camlibel and H.L. Trentelman are with
the Bernoulli Institute for Mathematics, Computer Science and Arti-
ﬁcial Intelligence, University of Groningen, The Netherlands (e-mail:
h.j.van.waarde@rug.nl, m.k.camlibel@rug.nl, h.l.trentelman@rug.nl).

J. Eising is with the Department of Mechanical and Aerospace Engi-

neering, UC San Diego, USA (e-mail: jeising@ucsd.edu).

applicable. A potential downside of this approach is that the
obtained state-space systems are non-minimal and of high
dimension, thus requiring a large amount of data to control
(see e.g. [8, Section VIC]). In addition, the system matrices
of the state-space representation are structured and consist
of a combination of known and unknown blocks. Often,
this structure is not taken fully into account, which leads to
rather conservative conditions for data-driven control design.
Exploiting this prior knowledge of the system matrices is an
important problem, which has recently been studied in [11].
Motivated by the limitations of state-space, the main pur-
pose of this paper is to develop a theory for the data-driven
design of feedback controllers on the basis of input-output
data, without relying on state construction. We will
thus
abandon the paradigm of systems in state-space form, and will,
instead, work directly with the model class of all input-output
systems described by higher order difference equations, also
called auto-regressive (AR) systems. The unknown dynamical
system that we want to analyse or control is assumed to be a
member of this model class of AR systems. We will assume
that noisy input-output data on a given ﬁnite time-interval have
been obtained from this unknown AR system. These data are
employed to check stability or to verify whether a dynamic
feedback controller exists that stabilizes the unknown system
and, if so, to compute a stabilizing controller.

Essential to our development is a method that allows the
veriﬁcation of asymptotic stability of systems described by
higher order difference equations. For this, we will heavily
rely on the behavioral approach to systems and control. In
particular, we will adopt the notion of quadratic difference
form (QDF) as a natural framework for Lyapunov functions
of autonomous AR systems, see [12]–[14] for the origins of
this theory in continuous time and [15], [16] for the discrete
time counterpart.

Contributions of the paper

The contributions of this paper are summarized as follows:
1) Following the general framework of [17], we introduce
the concepts of informative data for quadratic stability
and quadratic stabilization in the context of input-output
AR systems.

2) We provide necessary and sufﬁcient conditions under
which the data are informative for quadratic stability and
quadratic stabilization. These conditions are formulated in
terms of data-based linear matrix inequalities (LMIs). If
the LMI for quadratic stabilization is feasible, a controller
can be extracted from one of its solutions.

 
 
 
 
 
 
2

SUBMITTED TO IEEE TRANSACTIONS ON AUTOMATIC CONTROL, JUNE 2022

3) Using projection results in [18], we separate the computa-
tion of the controller and Lyapunov function, which leads
to lower-dimensional LMIs for the Lyapunov function,
and an explicit formula for a dynamic controller.

Rm and Rp, respectively. The term v(t) represents unknown
noise. The parameters of the model are real p × p matrices
P0, P1, . . . , PL−1 and p × m matrices Q0, Q1, . . . , QL. Using
the shift operator (σf )(t) = f (t + 1), (1) can be written as

Related work

We note that behavioral theory has been popularized before
in the context of data-driven control. Based on Willems’
fundamental lemma [19] and its various extensions [20]–
[23], a number of control problems were solved, such as
output matching [24] and predictive control [25]–[28]. The
control design typically involves the computation of (open-
loop) sequences of control inputs that live in the image of data
Hankel matrices. The results of this paper complement these
methods by providing behavioral results for the data-based
computation of dynamic feedback controllers. Other relevant
results at the intersection of behaviors and data-driven control
include [29] that considers control by interconnection, and [30]
in which data-driven dissipativity analysis is performed using
QDFs, both in the exact data setting.

Informativity for stability and stabilization have been stud-
ied before in the context of state space systems with noiseless
input-state data in [17] and for noisy input-state data in [3].
We stress that in the present paper we deal with noisy input-
output data. The behavioral approach followed in this article is
a radical departure from existing work on input-output systems
[8]–[11], which enables, among others, the formulation of
necessary and sufﬁcient conditions for data-driven analysis and
control problems.

In order to cope with noise-corrupted measurements, this
paper will build on results on quadratic matrix inequalties
(QMIs) and a matrix version of Yakubovich’s S-lemma that
were established in [3], [31] and [18].

Notation

The set of nonnegative integers will be denoted by Z+. We
will denote by Rn the n-dimensional Euclidean space. For
given positive integers m and n the linear space of all real
m×n matrices will be denoted by Rm×n. The subset of Rn×n
consisting of all symmetric matrices will be denoted by Sn.
For vectors x and y we will denote
by col(x, y).
For given integer n we denote by In the n × n identity matrix
and 0n the n × n zero matrix. In order to enhance readability,
we sometimes denote the n × m zero matrix by 0n×m. Given
a real matrix M , we will denote its Moore-Penrose pseudo-
inverse by M †. For given T > 0, the discrete-time interval
{0, 1, . . . , T } is denoted by [0, T ].

x⊤ y⊤

⊤

(cid:3)

(cid:2)

II. SYSTEMS REPRESENTED BY AR MODELS

In this paper we consider input-output systems with noise

represented by auto-regressive (AR) models of the form

y(t + L) + PL−1y(t + L − 1) + · · · + P0y(t) =
QLu(t + L) + QL−1u(t + L − 1) + · · · + Q0u(t) + v(t).

(1)
Here L is a positive integer, called the order of the system. The
input u(t) and output y(t) are assumed to take their values in

P (σ)y = Q(σ)u + v,

(2)

where P (ξ) and Q(ξ) are the real p × p and p × m polynomial
matrices deﬁned by

P (ξ) = IξL + PL−1ξL−1 + · · · + P1ξ + P0,
Q(ξ) = QLξL + QL−1ξL−1 + · · · + Q1ξ + Q0.

(3)

Since the leading coefﬁcient matrix of P (ξ) is the p × p iden-
tity matrix, P (ξ) is nonsingular and P −1(ξ)Q(ξ) is proper.
Thus, indeed, (2) represents a causal input-output system with
control input u, noise input v and output y.

In this paper we will freely use terminology and notation
originating from the behavioral approach, see e.g [32], [33].
In particular, we denote

R(ξ) :=

−Q(ξ) P (ξ)

and w := col(u, y).

(4)

Clearly, R(ξ) is a real p×q polynomial matrix with q := p+m,
(cid:2)
The equation (2) can be written as

(cid:3)

R(σ)w = v.

(5)

The homogeneous (i.e. noise free) system associated with (5)
is given by R(σ)w = 0. Within the behavioral approach, this
is called a kernel representation of its space of solutions w :
Z+ → Rq. This space of solutions is called the behavior of
the system, and is denoted by B(R). The variable w is called
the manifest variable of the behavior. In the special case that
m = 0, i.e. the system has no control inputs, the polynomial
matrix Q(ξ) is void and R(ξ) = P (ξ). In that case R(σ)w = 0
reduces to the autonomous system represented by P (σ)y =
0. Its associated behavior, denoted by B(P ), is then a ﬁnite
dimensional linear space.

This paper deals with analysis and control design for
systems of the form (2), where the polynomial matrices P (ξ)
and Q(ξ) are unknown. We do assume that the order L and
the dimensions m and p are known. We assume that we have
noisy input-output data on a given ﬁnite time interval. These
data are assumed to be obtained from an underlying true (but
unknown) system of the form (2). In particular, in case this
unknown system has no control inputs, we want to use the
output data to check whether it is stable, in the sense that
if the noise v = 0 then all solutions y tend to zero as time
tends to inﬁnity. On the other hand, in case that control inputs
are present we want to use the input-output data to check
whether there exists a stabilizing feedback controller and, if
so, determine such controller using only the data.

III. QUADRATIC MATRIX INEQUALITIES

An important role in this paper is played by solution sets of
quadratic matrix inequalities (QMIs) and the so-called matrix
S-lemma. For an extensive treatment of these, we refer to [3],
[31], [34], and more recently [18]. In particular, for proofs of
the propositions that are collected in this section we refer to
Section 3 and Appendix A in [18].

VAN WAARDE et al.: A BEHAVIORAL APPROACH TO DATA-DRIVEN CONTROL, JUNE 2022

3

We consider symmetric partitioned matrices of the form

Π =

Π11 Π12
Π21 Π22(cid:21)
where Π11 ∈ Sq and Π22 ∈ Sr and, obviously, Π21 = Π⊤
12. We
deﬁne the generalized Schur complement of Π with respect to
Π22 as

∈ Sq+r,

(6)

(cid:20)

Π | Π22 := Π11 − Π12Π†

22Π21,

where Π†
22 is the Moore-Penrose pseudo-inverse of Π22.
Deﬁne the following subset all partitioned matrices in Sq+r
of the form (6).

Πq,r :=

Π11 Π12
Π21 Π22(cid:21)

(cid:26)(cid:20)

∈ Sq+r | Π22 6 0, Π | Π22 > 0

(7)

and ker Π22 ⊆ ker Π12

.

We will be interested in the solution sets of quadratic matrix
inequalities associated with matrices Π ∈ Πq,r. In particular,
consider the sets

(cid:27)

Zr(Π) :=

(

Z ∈ Rr×q |

Z +

r (Π) :=

(

Z ∈ Rr×q |

Iq
Z

(cid:20)

⊤

(cid:21)

Π

Iq
Z

(cid:20)

(cid:21)

⊤

Iq
Z

(cid:20)

(cid:21)

Π

Iq
Z

(cid:20)

(cid:21)

> 0

,

)

> 0

.

)

(8)

(9)

Proposition 1: Let Π ∈ Πq,r. Then the following hold:
1) Zr(Π) is nonempty if and only if Π | Π22 > 0.
2) Z +

r (Π) is nonempty if and only if Π | Π22 > 0. In
22Π21 +
T for some

r (Π) if and only if Z = −Π†
I − Π†
(cid:16)

that case, Z ∈ Z +
(−Π22)†
2 +
S, T ∈ Rr×q with S⊤S < I.
(cid:16)

S (Π | Π22)

22Π22

(cid:17)

(cid:17)

1
2

1

Proposition 2: Let A ∈ Rr×q and B ∈ Rp×q. Assume that
B has full column rank. Then A⊤A < B⊤B if and only if
there exists S such that

A = SB and S⊤S < I

(10)

In that case S := AB† satisﬁes (10).

The following result gives necessary and sufﬁcient condi-
tions under which the solution set of one QMI is contained in
that of second, strict, QMI. These conditions are in terms of
feasibility of a linear matrix inequality (LMI).

Proposition 3 (Strict matrix S-lemma): Let M, N ∈ Sq+r.
If there exists a real scalar α > 0 such that M − αN > 0
r (M ). Next, assume that N ∈ Πq,r and
then Zr(N ) ⊆ Z +
N22 < 0. Then Zr(N ) ⊆ Z +
r (M ) if and only if there exists
a real scalar α > 0 such that M − αN > 0.

Another result that will be instrumental in this paper is the

following.

Let W ∈ Rq×p and for S ⊆ Rr×q deﬁne SW := {SW |

S ∈ S}. Also, for Π ∈ Sq+r deﬁne ΠW ∈ Sp+r by

0

Π

ΠW :=

W ⊤ 0
Ir(cid:21)

W ⊤Π11W W ⊤Π12
W 0
Ir(cid:21)
0
Π22 (cid:21)
(11)
Note that ΠW ∈ Πp,r if Π ∈ Πq,r. The relation between the
sets Zr(Π) and Zr(ΠW ) is as follows.

Π21W

=

(cid:20)

(cid:20)

(cid:20)

.

Proposition 4: Let Π ∈ Πq,r and W ∈ Rq×p. Then the
inclusion Zr(Π)W ⊆ Zr(ΠW ) holds. If, in addition, at least
one of the following two conditions hold

1) Π22 is nonsingular,
2) W has full column rank,

then Zr(Π)W = Zr(ΠW ).
A complementary result holds for the solution sets of strict
QMIs:

Proposition 5: Let Π ∈ Πq,r and W ∈ Rq×p. If W has full

column rank and Π | Π22 > 0 then Z +

r (Π)W = Z +

r (ΠW ).

IV. INPUT-OUTPUT AR SYSTEMS AND DATA

In this section we will discuss the type of noisy data that
we will be dealing with in this paper. In the ﬁrst part of this
section we will assume that inputs are present, so m > 1. As
announced in Section II, in that case we assume that we have
noisy input-output data

u(0), u(1), . . . , u(T ), y(0), y(1), . . . , y(T )

(12)

on a given time interval [0, T ] with T > L. These noisy
data are obtained from the true system. Assume that this
true system is represented by (unknown) polynomial matrices
Ps(ξ) and Qs(ξ) of the form (3). In other words, the true
system is represented by the equation Ps(σ)y = Qs(σ)u + v,
with v unknown noise.

More concretely, we assume that u(0), u(1), . . . , u(T ),
y(0), y(1), . . . , y(T ) are samples on the interval [0, T ] of u
and y that satisfy

Ps(σ)y = Qs(σ)u + v

for some unknown noise signal v. We do make the following
assumption on the noise v during the interval on which we
collect data.

Assumption 6: The noise samples v(0), v(1), . . . , v(T −L),

collected in the real p × (T − L + 1) matrix

V :=

v(0)

v(1)

· · ·

v(T − L)

satisfy the quadratic matrix inequality
(cid:2)

(cid:3)

⊤

Π

I
V ⊤

I
V ⊤
(cid:20)

> 0,

(13)

(cid:21)
where Π ∈ Sp+T −L+1 is a known partitioned matrix

(cid:21)

(cid:20)

Π =

Π11 Π12
Π21 Π22(cid:21)

,

(cid:20)
with Π11 ∈ Sp, Π12 ∈ Rp×(T −L+1), Π21 = Π⊤
12 and
Π22 ∈ ST −L+1. We assume that Π22 < 0 and Π | Π22 > 0.
In particular this implies that Π ∈ Πp,T −L+1 and that the set
ZT −L+1(Π) of matrices V that satisfy (13) is nonempty (see
Proposition 1).

Assumption (6) on the noise samples v(0), . . . , v(T − L)

captures, for instance,

1. Energy bounds: Π22 = −I and Π12 = 0 imply V V ⊤ =
T −L
t=0 v(t)v(t)⊤ 6 Π11, which means that the energy of

v on the time interval [0, T − L] is bounded by Π11;
P
2. Individual noise sample bounds: Π22 = −I, Π12 = 0 and
Π11 = ǫ(T − L + 1)I imply that kv(t)k2 6 ǫ ∀t. This

4

SUBMITTED TO IEEE TRANSACTIONS ON AUTOMATIC CONTROL, JUNE 2022

means that the individual noise samples at every time
instant are bounded in norm;

1

3. Sample covariance bounds: Π22 =

T −L+1 1111⊤ − I,
Π11 = (T − L + 1)M with M ∈ Sp, M > 0 and
T −L
1
Π12 = 0. Deﬁning the average µ :=
t=0 v(t),
T −L+1
T −L
t=0 (v(t) − µ)(v(t) − µ)⊤ =
1
this leads to
T −L+1
T −L+1 1111⊤)V ⊤ 6 M where 11 denotes the
T −L+1 V (I − 1
T − L + 1-vector of ones: the sample covariance matrix
of v is bounded by M ;

P

P

1

4. Exact measurements: Π11 = 0, Π12 = 0, and Π22 = −I

leads to V = 0, i.e., the noise is zero.

An additional example of special cases of Assumption (6) can
be found in [18].

Again denote q := p + m, R(ξ) =

−Q(ξ) P (ξ)

and

w = col(u, y) and recall that (2) can be written as

(cid:2)

R(σ)w = v.

(cid:3)

(14)

Collect the (unknown) coefﬁcient matrices of R(ξ) in the p ×
(qL + m) matrix

(cid:2)

R :=

−Q0 P0 −Q1 P1

· · · −QL−1 PL−1 −QL
(15)
(cid:3)
Note that, with a slight abuse of notation, we denote both the
polynomial matrix and its coefﬁcient matrix by R. Also, ar-
range the data u(0), u(1), . . . , u(T ), y(0), y(1), . . . , y(T ) into
the vectors

w(t) =

,

(t = 0, 1, . . . , T )

u(t)
y(t)

(cid:21)
and deﬁne the associated depth L + 1 Hankel matrix by

(cid:20)

w(0)
w(1)
...

w(1)
w(2)
...

H(w) := 




Furthermore, we partition

w(L) w(L + 1)

w(T − L)

· · ·
· · · w(T − L + 1)

...
w(T )

· · ·








.

(16)

H(w) =

,

(17)

H1(w)
H2(w)

(cid:20)
where H1(w) contains the ﬁrst qL + m rows and H2(w) the
last p rows. It is then easily veriﬁed that any input-output
system (14) for which the coefﬁcient matrix R deﬁned in (15)
satisﬁes

(cid:21)

Then by combining (13) and (18) we see that the system
corresponding to the coefﬁcient matrix R is compatible with
the data if and only if R⊤ satisﬁes the QMI

equivalently

I
R⊤

(cid:20)

⊤

N

(cid:21)

(cid:20)

I
R⊤

(cid:21)

> 0,

R⊤ ∈ ZqL+m(N ).

(20)

Since the true system is compatible with the data, the set
ZqL+m(N ) is nonempty.

A. Uncontrolled AR systems and data

In this subsection we will take a more detailed look at the
case that there are no control inputs, i.e. m = 0. In that case
(1) reduces to

y(t+L)+PL−1y(t+L−1)+· · ·+P1y(t+1)+P0y(t) = v(t)
(21)

and (2) to

P (σ)y = v,

(22)

with P (ξ) a nonsingular polynomial matrix. In this section we
will brieﬂy discuss the notion of noisy data for this special
case. In fact, in this case we have only output data

y(0), y(1), . . . , y(T )

(23)

on a time-interval [0, T ] with T > L. We assume that these
data come from an unknown true system. Suppose this true
system is represented by the unknown polynomial matrix
Ps(ξ), with Ps(ξ) of the form (3). The true system is then
represented by Ps(σ)y = v. Again we assume that the noise
v is unknown, but on the time interval [0, T − L] its samples
satisfy Assumption 6 .

Any system in the model class of systems of the form
(22) with ﬁxed dimension p and order L is parametrized
by its coefﬁcient matrices P0, P1, . . . , PL−1. We collect these
matrices in the p × pL matrix

P :=

P0 P1

· · · PL−1

.

(24)

(cid:2)

Recalling that there are no control inputs, we have w = y.
Therefore we denote the Hankel matrix associated with the
data as given by (16) by H(y) and as before partition this
matrix as

(cid:3)

H(y) =

H1(y)
H2(y)
(cid:21)

,

H1(w)
H2(w)
(cid:20)

(cid:21)

= V

(18)

(cid:20)
where H1(y) contains the ﬁrst pL rows and H2(y) the last p
rows. Also deﬁne

R I

(cid:2)

(cid:3)

for some V ∈ ZT −L+1(Π), could have generated the noisy
input-output data (12). In other words, w(0), w(1), . . . , w(T )
are also samples on the interval [0, T ] of a w that satisﬁes
R(σ)w = v for some v satisfying Assumption 6. Therefore,
if R satisﬁes (18) for some V ∈ ZT −L+1(Π), we call the AR
system corresponding to the matrix R compatible with the
data. Recall that, in particular, the true system is compatible
with the data. Now deﬁne

N :=

I H2(w)
0 H1(w)

(cid:20)

Π

(cid:21)

(cid:20)

I H2(w)
0 H1(w)

⊤

.

(cid:21)

(19)

N :=

I H2(y)
0 H1(y)
(cid:21)
Then as in Section IV, the autonomous system with coefﬁcient
matrices collected in the matrix P is compatible with the data
if and only if

I H2(y)
0 H1(y)
(cid:21)

(25)

Π

(cid:20)

(cid:20)

.

⊤

⊤

N

I
P ⊤

I
P ⊤

> 0,

(26)

(cid:20)
equivalently P ⊤ ∈ ZpL(N ). Since the true system is assumed
to be compatible with the data, the set ZpL(N ) is nonempty.

(cid:21)

(cid:21)

(cid:20)

VAN WAARDE et al.: A BEHAVIORAL APPROACH TO DATA-DRIVEN CONTROL, JUNE 2022

5

V. QUADRATIC DIFFERENCE FORMS

Studying stability and stabilization in the context of input-
output AR systems requires the notion of Lyapunov functions
given by quadratic difference forms (QDFs). In this section
we will review the basic material and establish some useful
preliminary results. For more details, we refer to [12], [13],
[15], [16].

Let N and q be positive integers and for i, j = 0, 1, . . . , N
let Φi,j ∈ Rq×q be such that Φi,i ∈ Sq and Φi,j = Φ⊤
j,i for
all i 6= j. Arrange these matrices into the partitioned matrix
Φ ∈ S(N +1)q given by

Φ0,0 Φ0,1
Φ1,0 Φ1,1
...
...
ΦN,0 ΦN,1

· · · Φ0,N
· · · Φ1,N
...
. . .
· · · ΦN,N








Φ := 





Then the quadratic difference form associated with Φ is the
operator QΦ that maps Rq-valued functions w on Z+ to R-
valued functions QΦ(w) on Z+ deﬁned by

N

QΦ(w)(t) :=

w(t + k)⊤Φk,ℓ w(t + ℓ).

(27)

Xk,ℓ=0
In terms of the matrix Φ this can be written as

w(t)
w(t + 1)
...
w(t + N )

⊤








Φ 





w(t)
w(t + 1)
...
w(t + N )








QΦ(w)(t) = 





We deﬁne the degree of the QDF (27) as the smallest integer
d such that Φij = 0 for all i > d or j > d. This degree
is denoted by deg(QΦ). The matrix Φ is called a coefﬁcient
matrix of the QDF. Note that a given QDF does not determine
the coefﬁcient matrix uniquely. However, if the degree of the
QDF is d, it allows a coefﬁcient matrix Φ ∈ S(d+1)q.

The QDF QΦ is called nonnegative if QΦ(w) > 0 for all
w : Z+ → Rq. We denote this as QΦ > 0. Clearly, this
holds if and only if Φ > 0. The QDF is called positive if
it is nonnegative and, in addition, QΦ(w) = 0 if and only
if w = 0. This is denoted as QΦ > 0. Likewise we deﬁne
nonpositivity and negativity.

For a given QDF QΦ, its rate of change along a given w :
Z+ → Rq is given by QΦ(w)(t + 1) − QΦ(w)(t). It turns
out that the rate of change deﬁnes a QDF itself. Indeed, by
deﬁning the matrix ∇Φ ∈ S(N +2)q by

∇Φ :=

0q×q
0

0
Φ

−

(cid:21)

(cid:20)

Φ
0

0
0q×q(cid:21)

,

(cid:20)
it is easily veriﬁed that

Q∇Φ(w)(t) = QΦ(w)(t + 1) − QΦ(w)(t)

for all w : Z+ → Rq and t ∈ Z+.

Quadratic difference forms are particularly relevant in com-
bination with behaviors deﬁned by AR systems. Let R(ξ) be
a real p × q polynomial matrix and consider the AR system
represented by R(σ)w = 0. Let B(R) be the behavior of
this system. The QDF QΦ is called nonnegative on B(R) if

QΦ(w) > 0 for all w ∈ B(R). It is called positive on B(R)
if, in addition, QΦ(w) = 0 if and only if w = 0. We denote
this as QΦ > 0 on B(R) and QΦ > 0 on B(R), respectively.
Likewise we deﬁne nonpositivity and negativity on B(R).

Two given QDFs QΦ1 and QΦ2 are called B(R)-equivalent
if they coincide on solutions of R(σ)w = 0, i.e. QΦ1(w) =
QΦ2(w) for all w ∈ B(R).

We now return to the setup of AR systems introduced in
Section II, and in particular consider QDFs for autonomous
systems. In that case every QDF turns out to be equivalent to
a QDF with degree at most the order of the system. Indeed,
let P (ξ) be a square polynomial matrix as given in (3) with
corresponding autonomous system P (σ)y = 0 of order L.
Let B(P ) be its behavior. Deﬁne the restricted behavior on
the interval [0, L − 1] by

y(0)
y(1)
...
y(L − 1)

B(P )|[0,L−1] := 

















.

∈ RpL | y ∈ B(P )



It is easily seen that B(P)|[0,L−1] = RpL. Using this fact, we
obtain the following lemma (see also [12], Prop 4.9).

Lemma 7: For any QDF QΦ′ (y) there exists a B(P )-
equivalent QDF QΦ(y) with degree at most L−1. In addition,
if QΦ′ > 0 on B(P ) then QΦ > 0, equivalently, Φ > 0.

Proof: Let d = deg(QΦ′ ) and let y ∈ B(P ). Then, we

.

have

QΦ′ (y)(t) =

d

d

Xk=0

Xl=0

y⊤(t + k)Φ′

k,ly(t + l).

(29)

First consider the case that d 6 L − 1. Since B(P ) |[0,L−1]=
RpL, we readily have that if QΦ′ > 0 on B(P ) then Φ′ > 0.
Next, suppose that d > L. Let k be such that L 6 k 6 d.
Then we have

y(t + k) = −PL−1y(t + k − 1) − · · · − P0y(t + k − L).

Therefore, one can substitute y(t + k) for k = d, d − 1, . . . , L
into (29) to obtain

L−1

L−1

QΦ′(y)(t) =

y⊤(t + k)Φk,ly(t + l).

(30)

Xk=0

Xl=0

(28)

where Φi,j are suitable p × p matrices. Deﬁne

Φ0,0
Φ1,0
...

· · ·
· · ·

Φ0,1
Φ1,1
...

Φ0,L−1
Φ1,L−1
...

ΦL−1,0 ΦL−1,1

· · · ΦL−1,L−1



.






Φ := 





It follows from (30) that QΦ(y) = QΦ′ (y) for all y ∈ B(P ).
Moreover, again by the fact that B(P ) |[0,L−1]= RpL, we see
that if QΦ > 0 on B(P ) we have Φ > 0, equivalently, QΦ > 0.

6

SUBMITTED TO IEEE TRANSACTIONS ON AUTOMATIC CONTROL, JUNE 2022

VI. STABILITY OF AUTONOMOUS AR SYSTEMS

Any such Ψ deﬁnes a Lyapunov function QΨ.

In this section we review some facts on stability and
Lyapunov theory in the context of autonomous systems repre-
sented by AR models. We ﬁrst deﬁne stability.

Deﬁnition 8: Let P (ξ) be a nonsingular polynomial matrix.
The corresponding autonomous system P (σ)y = 0 is called
stable if y(t) → 0 as t → ∞ for all solutions y on Z+.

Stability of autonomous AR systems can be characterized
in terms of quadratic difference forms. In fact, the following
proposition holds (see [12], [15]).

Proposition 9: Let P (ξ) be a nonsingular polynomial ma-
trix. The corresponding autonomous system P (σ)y = 0 is
stable if and only if there exists a QDF QΨ(y) such that
QΨ > 0 on B(P ) and Q∇Ψ < 0 on B(P ).

For obvious reasons, we refer to QΨ as a Lyapunov function.
In principle, the above theorem does not specify the degree of
QΨ. However, it turns out that if P (ξ) is of the form as in (3)
(with leading coefﬁcient matrix the identity matrix) and the
corresponding system P (σ)y = 0 of order L is stable, there
exists a Lyapunov function of degree at most L − 1.

Lemma 10: Let P (ξ) be a polynomial matrix of the form
(3). The corresponding autonomous system P (σ)y = 0 order
L is stable if and only if there exists a QDF QΨ(y) of degree
at most L − 1 such that QΨ > 0 and Q∇Ψ < 0 on B(P ).

Proof: We only need to prove the ‘only if’ direction. By
Proposition 9, there exists a QDF QΨ′ such that QΨ′ > 0 on
B(P ) and Q∇Ψ′ < 0 on B(P ). By Lemma 7 there exists a
QDF QΨ of degree at most L − 1 that is B(P )-equivalent to
QΨ′ and QΨ > 0. Finally, Q∇Ψ and Q∇Ψ′ are also B(P )-
equivalent and therefore Q∇Ψ < 0 on B(P ).

VII. DATA-DRIVEN STABILITY ANALYSIS OF
AUTONOMOUS AR SYSTEMS

In this section we study data-based stability analysis for
autonomous systems of the form (22). Our aim is to develop
a test on the output data y(0), y(1), . . . , y(T ) that determines
whether the true system is stable (in the sense that if the noise
v = 0 then all solutions y tend to zero as time tends to
inﬁnity). As we saw in Section IV, the data do not necessarily
determine the true system uniquely. Thus we are forced to test
stability for all systems that are compatible with the data, that
is, for all systems for which the corresponding matrix P (see
(24)) is in ZpL(N ), where N given by (25).

In order to proceed, we will ﬁrst express the existence
of a Lyapunov function QΨ for the autonomous system
P (σ)y = 0 in terms of a quadratic matrix inequality. This
QMI involves a symmetric matrix Ψ of dimensions pL × pL
leading to a Lyapunov function QΨ, and the matrix P =
P0 P1
. Again, for ease of notation we denote
both the polynomial matrix and its coefﬁcient matrix by P .
(cid:2)
Then we have:

· · · PL−1

(cid:3)

Theorem 11: Let P (ξ) = IξL +PL−1ξL−1 +. . .+P1ξ +P0
and let P (σ)y = 0 be the corresponding autonomous system.
This system is stable if and only if there exists Ψ ∈ SpL such
that Ψ > 0 and
⊤

I
−P

(cid:20)

(cid:21)

(cid:18)(cid:20)

0
0p
0 Ψ

−

(cid:21)

(cid:20)

Ψ 0
0

0p(cid:21)(cid:19) (cid:20)

I
−P

< 0.

(31)

(cid:21)

Proof: We ﬁrst prove the ‘if’ part by showing that the
QDF QΨ associated with the matrix Ψ is a Lyapunov function.
Since Ψ > 0 we have QΨ > 0 so by Proposition 9 it sufﬁces to
show that Q∇Ψ < 0 on B(P ). As in (28), denote the matrix
in the middle of (31) by ∇Ψ. Let y ∈ B(P ). Then for all
t ∈ Z+ we have

y(t + L) + PL−1y(t + L − 1) + · · · + P1y(t + 1) + P0y(t) = 0.

This implies



y(t)
...
y(t + L)
for all t ∈ Z+. Thus we compute
⊤

I
−P







=



(cid:20)

(cid:21)






y(t)
...
y(t + L − 1)






Q∇Ψ(y)(t) = 

y(t)
...
y(t + L − 1)

= 












∇Ψ 

y(t)
...
y(t + L)



y(t)
...
y(t + L)
⊤





⊤

I
−P

(cid:20)

∇Ψ

(cid:21)

(cid:20)



y(t)
...
y(t + L − 1)



I
−P

(cid:21)






.






This implies Q∇Ψ(y)(t) 6 0 for all t ∈ Z+ and Q∇Ψ(y)(t) =
0 for all t ∈ Z+ if and only if y(t) = 0 for all t ∈ Z+, which
shows that Q∇Ψ < 0 on B(P ).

Next, we turn to proving the ‘only if’ part. Suppose the
system is stable. According to Lemma 10 there exists a
Lyapunov function QΨ of degree at most L−1 such that QΨ >
0. This QDF allows a coefﬁcient matrix Ψ ∈ SpL, Ψ > 0. We
claim that Ψ satisﬁes (31). Indeed, take any y0, y1, . . . , yL−1
not all equal to zero. Clearly, since B(P)|[0,L−1] = RpL there
exists y ∈ B(P ) such that y(t) = yt, t = 0, 1, . . . , L − 1.
Finally,

⊤

I
−P

(cid:20)

(cid:21)

∇Ψ

I
−P

(cid:20)

(cid:21)

y0
...
yL−1











⊤

⊤

y0
...
yL−1

y(0)
...
y(L)



















y(0)
...
y(L)









= 

∇Ψ 

= Q∇Ψ(y)(0) < 0.

We now return to our problem of verifying stability on the
basis of the output data. To this end, we give the following
deﬁnition of informativity for quadratic stability.

P0 P1

· · · PL−1

Deﬁnition 12: The noisy output data y(0), y(1), . . . , y(T )
are called informative for quadratic stability if there exists a
matrix Ψ ∈ SpL such that Ψ > 0 and the QMI (31) holds
for all P =
that satisfy the QMI (26),
with N deﬁned by (25).
(cid:2)

Informativity for quadratic stability thus implies that there
exists a matrix Ψ ∈ SpL such that the QDF QΨ is a Lyapunov
function for all systems that are compatible with the data, i.e.,
all systems in ZpL(N ) are stable with a common Lyapunov
function.

(cid:3)

VAN WAARDE et al.: A BEHAVIORAL APPROACH TO DATA-DRIVEN CONTROL, JUNE 2022

7

In the sequel, our aim is to establish necessary and sufﬁcient
conditions on the data y(0), y(1), . . . , y(T ) to be informative
in this manner. The idea is to apply the strict matrix S-lemma
in Proposition 3 to obtain such conditions in the form of
feasibility of a linear matrix inequality. Note however that the
QMI (26) is in terms of the matrix P ⊤ whereas (31) is in
terms of P . Therefore, immediate application of the matrix
S-lemma is not possible. Below, we will resolve this issue by
reformulating the QMI (31) in terms of the variable P ⊤. We
ﬁrst formulate the following instrumental lemma.

Lemma 13: Let P (ξ) = IξL + PL−1ξL−1 + · · · + P1ξ + P0
P0 P1
. Deﬁne the

· · · PL−1

and, as before, let P =
p(L − 1) × pL matrix J by
(cid:2)

(cid:3)

J :=

0p(L−1)×p

Ip(L−1)

.

(32)

Then Ψ satisﬁes (31) if and only it satisﬁes the standard
Lyapunov inequality

(cid:2)

(cid:3)

⊤

Ψ

J
−P

J
−P

− Ψ < 0.

(33)

(cid:21)
Moreover, if Ψ > 0 satisﬁes (31) then Ψ > 0.

(cid:20)

(cid:21)

(cid:20)

Proof: By inspection,

it can be seen that (31) can
equivalently be reformulated as (33). Suppose Ψ > 0 satisﬁes
(31). It then immediately follows that

Ψ > Ψ −

⊤

J
−P

(cid:20)

(cid:21)

Ψ

J
−P

(cid:20)

(cid:21)

> 0.

Using a Schur complement argument twice, the strict Lya-

punov inequality (33) can be seen to be equivalent to

Ψ−1 −

J
−P

Ψ−1

J
−P

⊤

> 0, Ψ > 0.

(34)

(cid:21)
Using as an intermediate step that, obviously,

(cid:21)

(cid:20)

(cid:20)

J
−P

(cid:20)

=

(cid:21)

(cid:20)

J
0

−

(cid:21)

(cid:20)

0
P

(cid:21)

it can be seen that (34) holds if and only if Ψ > 0 and

IpL
0 −Ip

P ⊤

⊤

M

IpL
0 −Ip

P ⊤

(cid:21)
where the 2pL × 2pL matrix M is deﬁned by
(cid:3)
(cid:3)

(cid:20)

(cid:20)

(cid:21)

(cid:2)

(cid:2)

> 0,

(35)

M := 

Ψ−1 −

Ψ−1

J
0

(cid:20)
(cid:21)
Ψ−1

(cid:20)

⊤

J
0

(cid:21)

(cid:20)





⊤

J
0

(cid:21)

(cid:20)

J
0

Ψ−1

(cid:21)
−Ψ−1







.

(36)

From the above we see that informativity for quadratic stability
is equivalent to the existence of Ψ > 0 such that the QMI (35)
· · · PL−1
holds for all coefﬁcient matrices P =
that satisfy the QMI (26). In terms of solutions sets of QMIs
(cid:3)
as discussed in Section III this can now be restated as

P0 P1

(cid:2)

P ⊤ ∈ ZpL(N ) =⇒ P ⊤

0 −Ip

∈ Z +

pL(M ),

or equivalently,

ZpL(N )

0 −Ip

(cid:2)

(cid:3)

⊆ Z +

pL(M ).

(37)

(cid:2)

(cid:3)

In order to be able to apply the strict matrix S-lemma formu-
lated in Proposition 3 we want to express the (projected) set
on the left in (37) as the solution set of a QMI. To this end,
deﬁne

¯N :=

0 −Ip
0

⊤

N

0
IpL(cid:21)

0 −Ip
0

.

0
IpL(cid:21)

(38)

(cid:3)
Then, indeed, we have the following lemma.

(cid:20)(cid:2)

(cid:20)(cid:2)

(cid:3)

Lemma 14: Assume that the Hankel matrix H1(y) of depth

L has full row rank. Then ZpL(N )

0 −Ip

Proof: Note that N is partitioned as

= ZpL( ¯N ).

(cid:2)

(cid:3)

N =

N11 N12
N21 N22(cid:21)

(cid:20)

with N22 = H1(y)Π22H1(y)⊤. By Assumption 6 we have
Π22 < 0 and therefore N22 < 0. The true system is
compatible with the data and therefore ZpL(N ) is nonempty.
By Proposition 1 we thus have that N | N22 > 0. The result
then follows from Proposition 4.

Summarizing our ﬁndings up to now, we see that under
the assumption that H1(y) has full row rank, informativity for
quadratic stability is equivalent to the existence of Ψ > 0 such
that the inclusion ZpL( ¯N ) ⊆ Z +
pL(M ). holds. This inclusion
is dealt with by Proposition 3.

Lemma 15: Let Ψ > 0 and let M be given by (36). Assume
pL(M ) if and

that H1(y) has full row rank. Then ZpL( ¯N ) ⊆ Z +
only if there exist α > 0 such that

(39)
Proof: We check the conditions of Proposition 3 on ¯N .

M − α ¯N > 0.

Note that

¯N11 =

0
−Ip(cid:21)

(cid:20)

¯N =

¯N11
¯N21

(cid:20)

N11

0 −Ip

¯N12
¯N22(cid:21)
¯N12 =
,

(40)

N12.

0
−Ip(cid:21)

(cid:20)

We have ¯N22 = H1(y)Π22H1(y)⊤ < 0. Finally, the Schur
complement ¯N | ¯N22 > 0 since N | N22 > 0. This completes
the proof.

(cid:2)

(cid:3)

Thus, informativity for quadratic stability is equivalent to
the existence of a scalar α > 0 and a matrix Ψ > 0 such that
(39) holds. Note that due to the negative deﬁnite lower right
block in M , the scalar α is necessarily positive. By scaling
the inequality (39) we can therefore take α = 1. Putting
Φ := Ψ−1 we then ﬁnally obtain the following necessary and
sufﬁcient condition in terms of feasibility of an LMI. Recall
the deﬁnition (32) of the matrix J.

Theorem 16: Let ¯N be given by (38), where N is deﬁned
by (25). Assume that H1(y) has full row rank. Then the
output data y(0), y(1), . . . , y(T ) are informative for quadratic
stability if and only if there exists Φ ∈ SpL such that Φ > 0
and

⊤

J
0

Φ

(cid:20)
⊤

(cid:21)

J
0
(cid:21)
J
0

(cid:20)

(cid:20)
Φ

(cid:21)

Φ −







J
0

Φ

(cid:20)
(cid:21)
−Φ





− ¯N > 0.



(41)

In that case the QDF QΨ with Ψ := Φ−1 is a Lyapunov
function for all systems of the form (22) compatible with the
data.

8

SUBMITTED TO IEEE TRANSACTIONS ON AUTOMATIC CONTROL, JUNE 2022

Remark 17: Note that the size of the LMI (41) is 2pL
whereas the number of unknowns is 1
2 pL(pL + 1). These are
independent of the length T + 1 of the interval on which the
input-output data are collected, and only depend on the order
of the system and the number of outputs.

VIII. DATA-DRIVEN STABILIZATION OF INPUT-OUTPUT AR
SYSTEMS

In this section we will discuss data-driven stabilization of
input-output systems in AR form. We will work in the setup
of Section IV, with systems of the form (1), or equivalently
(2), with polynomial matrices as in (3) of given degree L. In
order to obtain well-posed feedback interconnections we will
slightly restrict our model class and assume that the leading
coefﬁcient matrix QL of Q(ξ) is equal to zero. In other words,
we will consider systems of the form

P (σ)y = Q(σ)u + v

with

P (ξ) = IξL + PL−1ξL−1 + · · · + P1ξ + P0,
Q(ξ) = QL−1ξL−1 + · · · + Q1ξ + Q0.

(42)

(43)

This means that P (ξ)−1Q(ξ) is assumed to be strictly
proper. We assume that we have noisy input-output data
u(0), u(1), . . . , u(T ), y(0), y(1), . . . , y(T ) on the interval
[0, T ] with T > L. These are samples of u and y obtained
from the unknown true system

Ps(σ)y = Qs(σ)u + v

The noise v is unknown, but its samples are assumed to satisfy
Assumption 6. Since we have assumed that QL = 0, our
model class is now parametrized by P0, P1, . . . , PL−1 and
Q0, Q1, . . . , QL−1. Again denote R(ξ) =
,
q = p + m, and collect the coefﬁcient matrices in the p × qL
(cid:3)
coefﬁcient matrix

−Q(ξ) P (ξ)

(cid:2)

R =

−Q0 P0 −Q1 P1

.
(44)
(cid:3)
Associated with the input-output data, we consider the slightly
adapted Hankel matrix H ′(w) deﬁned by

· · · −QL−1 PL−1

(cid:2)

w(0)
w(1)
...
w(L − 1)
y(L)










w(1)
w(2)
...
w(L)
y(L + 1)

w(T − L)

· · ·
· · · w(T − L + 1)

...
w(T − 1)
y(T )

· · ·
· · ·

.










H ′(w) :=

Partition

H ′(w) =

H ′
H ′
(cid:20)

1(w)
2(w)

(cid:21)

,

1(w) contains the ﬁrst qL rows and H ′

where H ′
2(w) the last
p rows. Clearly, the system with coefﬁcient matrices collected
in R is compatible with the data if and only if

equivalently

I
R⊤

(cid:20)

⊤

N

(cid:21)

(cid:20)

I
R⊤

(cid:21)

> 0,

R⊤ ∈ ZqL(N ),

(45)

where

N :=

I H ′
0 H ′

2(w)
1(w)

I H ′
0 H ′

2(w)
1(w)

⊤

.

(cid:21)

Π

(cid:21)

(cid:20)

(cid:20)

(46)

Next, we will address the stabilization problem. A feedback
controller for the input-output system (42) with P (ξ) and Q(ξ)
of the form (43) will be taken to be of the form

G(σ)u = F (σ)y

(47)

with

G(ξ) = IξL + GL−1ξL−1 + · · · + G1ξ + G0,
F (ξ) = FL−1ξL−1 + · · · + F1ξ + F0.

The leading coefﬁcient matrix of G(ξ) is assumed to be the
m × m identity matrix and Gi ∈ Rm×m, Fi ∈ Rm×p for
i = 0, 1, . . . , L − 1. The closed loop system obtained by
interconnecting a system of the form (42) and the controller
is represented by

G(σ) −F (σ)
P (σ)
−Q(σ)

u
y

=

v.

0
Ip(cid:21)
(cid:20)

(cid:21)

(48)

(cid:21) (cid:20)

(cid:20)

Since the leading coefﬁcient matrix is the q×q identity matrix,
the controlled system with noise equal to zero is autonomous.
We call
the controller (47) a stabilizing controller if the
controlled system (48) is stable, in the sense that if v = 0,
then all solutions u and y tend to zero as time tends to inﬁnity.
Now deﬁne

C(ξ) :=

G(ξ) −F (ξ)

,

and recall that w = col(u, y). Then (48) can equivalently be
written as

(cid:3)

(cid:2)

C(σ)
R(σ)

w =

(cid:21)

(cid:20)

0
Ip(cid:21)

(cid:20)

v.

(49)

Collect the coefﬁcient matrices of F (ξ) and G(ξ) in the matrix
C deﬁned by

C :=

G0 −F0 G1 −F1

· · · GL−1 −FL−1

(50)

(cid:2)

and recall deﬁnition (44) of the matrix R associated like-
wise with R(ξ). Recall that the leading coefﬁcient matrix of
C(ξ)⊤ R(ξ)⊤
is the q × q identity matrix. Furthermore,
collects the remaining coefﬁcient
the matrix
(cid:2)
matrices.

C⊤ R⊤
(cid:3)

⊤

⊤

(cid:3)

(cid:2)

(cid:3)

An immediate application of Theorem 11 then yields:
Lemma 18: The controlled system (49) is stable if and only

if there exists Ψ ∈ SqL such that Ψ > 0 and

⊤

IqL
−C
−R

Moreover, if Ψ > 0 satisﬁes (51), then Ψ > 0.

IqL
−C
−R


0q
0
0 Ψ

Ψ 0
0

0q(cid:21)(cid:19)

(cid:18)(cid:20)

−









(cid:20)

(cid:21)

< 0.

(51)

This leads to the following deﬁnition of informativity for

quadratic stabilization.

Deﬁnition 19: The noisy input-output data u(0), u(1), . . . ,
for
u(T ), y(0), y(1), . . . , y(T )
are
there exist C ∈ Rm×qL and
quadratic stabilization if
Ψ ∈ SqL with Ψ > 0 such that the QMI (51) holds for all R
that satisfy the QMI (45), with N deﬁned by (46).

informative

called

VAN WAARDE et al.: A BEHAVIORAL APPROACH TO DATA-DRIVEN CONTROL, JUNE 2022

9

Informativity for quadratic stabilization thus means that
there exist a controller C(σ)w = 0 (equivalently, G(σ)u =
F (σ)y) and a matrix Ψ ∈ SqL such that the QDF QΨ is
a common Lyapunov function for all closed loop systems
obtained by interconnecting the controller with an arbitrary
system that is compatible with the data.

Below, we will derive necessary and sufﬁcient conditions
for informativity for quadratic stabilization. Similar to Section
VII, the QMI (45) is in terms of the matrix R⊤ whereas (51)
is in terms of R. We will therefore ﬁrst reformulate the QMI
(51) in terms of the variable R⊤.

Deﬁne the q(L − 1) × qL matrix J by

J :=

0q(L−1)×q

Iq(L−1)

.

(52)

By Lemma 13, Ψ ∈ SqL, Ψ > 0 satisﬁes (51) if and only if
Ψ > 0 and satisﬁes the strict Lyapunov inequality

(cid:3)

(cid:2)

⊤

J
−C
−R






which is equivalent to

Ψ

J
−C
−R






− Ψ < 0,

Ψ−1 −

By writing

Ψ−1

J
−C
−R






⊤

J
−C
−R






> 0, Ψ > 0.

(53)

J
−C
−R






J
−C
0 


=





−

0
0

R



it can be seen that (53) holds if and only if Ψ > 0 and

IqL

0 0 −Ip

⊤

M

IqL

R⊤

0 0 −Ip

(cid:21)
where the 2qL × 2qL matrix M is deﬁned by
(cid:3)

(cid:20)

(cid:2)

(cid:2)

R⊤
(cid:20)

> 0.

(54)

(cid:21)

(cid:3)

Ψ−1 −



M :=









⊤

J
−C
0 




⊤



Ψ−1



J
−C
0 

J
−C
0 



Ψ−1




Ψ−1

J
−C
0 

−Ψ−1















Thus we see that informativity for quadratic stabilization
is equivalent to the existence of an m × qL matrix C and a
matrix Ψ ∈ SqL, Ψ > 0 such that the QMI (54) holds for all
coefﬁcient matrices R that satisfy the QMI (45). The matrix C
is then the coefﬁcient matrix of a suitable controller. In terms
of solutions sets of QMIs this can be restated as

R⊤ ∈ ZqL(N ) =⇒ R⊤

0

0 −Ip

∈ Z +

qL(M ),

or equivalently,

(cid:2)

(cid:3)

ZqL(N )

0 0 −Ip

⊆ Z +

qL(M ).

(56)

As before, in order to be able to apply the strict matrix S-
lemma in Proposition 3, we want to express the set on the left

(cid:2)

(cid:3)

in (56) as the solution set of a QMI. Deﬁne the 2qL × 2qL
matrix ¯N by

¯N :=

0 0 −Ip
0

(cid:3)

(cid:20)(cid:2)

⊤

0
IqL(cid:21)

N

0

0 −Ip

(cid:20)(cid:2)

0

(cid:3)

Then we have the following lemma.

.

0
IqL(cid:21)

(57)

Lemma 20: Assume that the Hankel matrix H ′
= ZqL( ¯N ).
0

row rank. Then ZqL(N )

0 −Ip

1(w) has full

Proof: The proof is similar to that of Lemma 14.

(cid:2)

(cid:3)

From the above we see that, under the assumption that
H ′
1(w) has full row rank, informativity for quadratic stabi-
lization requires the existence of C and Ψ > 0 such that the
inclusion ZqL( ¯N ) ⊆ Z +
qL(M ). holds. This inclusion is dealt
with by Proposition 3.

(55). Assume that H ′
Z +

Lemma 21: Let Ψ > 0, C ∈ Rm×qL and let M be given by
1(w) has full row rank. Then ZqL( ¯N ) ⊆
qL(M ) if and only if there exists a scalar α > 0 such that
M − α ¯N > 0.
Proof: The proof is similar to that of Lemma 15.

(58)

Note that the unknowns C and Ψ appear in the matrix M
in a nonlinear way, and even in the form of an inverse. By
putting Φ := Ψ−1 we can get rid of the inverse, and rewrite
the condition M − α ¯N > 0 as
⊤

Φ −













J
−C
0 


Φ



⊤


J
−C
0 

J
−C
0 





Φ


J
−C
Φ
0 

−Φ















− α ¯N > 0.

(59)

Thus, informativity for quadratic stabilization holds if and
only if there exists Φ > 0, a matrix C and a scalar α > 0
such that (59) holds. Note that α must be positive due to the
negative deﬁnite lower right block in (59). By scaling Φ we
can therefore take α = 1. By introducing the new variable
D := −CΦ and taking a suitable Schur complement, (59) can
then be reformulated as the following LMI in the unknowns
Φ and D:

.

(55)

Φ



JΦ
D
0 






−Φ

0

⊤

⊤





0

JΦ
D
0 

















Φ
















JΦ
D
0 

JΦ
D
0 










−

¯N
0

(cid:20)

0
0qL(cid:21)

> 0.

(60)

This then immediately leads to the following characterization
of informativity for quadratic stabilization and a method to
compute a suitable feedback controller together with a com-
mon Lyapunov function.

Theorem 22: Assume that H ′

1(w) has full row rank. Let the
matrix ¯N be given by (57), with N deﬁned by (46). Then the
input-output data u(0), u(1), . . . , u(T ), y(0), y(1), . . . , y(T )
are informative for quadratic stabilization if and only if there

10

SUBMITTED TO IEEE TRANSACTIONS ON AUTOMATIC CONTROL, JUNE 2022

exist matrices D ∈ Rm×qL and Φ ∈ SqL such that Φ > 0 and
the LMI (60) holds.

In that case, the feedback controller with coefﬁcient matrix
C := −DΦ−1 stabilizes all systems of the form (42) that are
compatible with the input-output data. Moreover, the QDF QΨ
with Ψ := Φ−1 is a common Lyapunov function for all closed
loop systems.

Remark 23: Thus, in order to compute a controller that
stabilizes all systems compatible with the data and which gives
a common Lyapunov function, ﬁrst compute the matrix ¯N
using the Hankel matrix associated with the data. Next, check
feasibility of the LMI (60) and, if it is feasible, compute D
and Φ. An AR representation of the controller with coefﬁcient
matrix C = −DΦ−1 is then obtained as follows: partition
C :=
with
Fi ∈ Rm×p and Gi ∈ Rm×m. Next deﬁne F (ξ)
:=
(cid:3)
FL−1ξL−1 + · · · + F0 and G(ξ) := IξL + GL−1ξL−1 +
· · · + G0. The corresponding controller is then given in AR
representation by G(σ)u = F (σ)y.

G0 −F0 G1 −F1

· · · GL−1 −FL−1

(cid:2)

IX. REDUCTION OF COMPUTATIONAL COMPLEXITY

In this section we will again take a look at the data-driven
stabilization problem. In Section VIII we showed that ﬁnding a
controller that stabilizes all systems that are compatible with
the data requires checking feasibility of the LMI (60). The
size of this LMI is 3qL, while the number of unknowns is
1
2 qL(qL + 2m + 1), both independent of the time horizon T .
The unknowns in the LMI (60) are the matrices Φ and D that
together lead to a controller and a common Lyapunov function.
In the present section we will decouple the computation of the
common Lyapunov function from that of the controller. This
will lead to checking feasibility of an LMI of smaller size and
with a smaller number of unknowns.

In order to proceed, we will need the following lemma.
Lemma 24: Let Π ∈ Πq,r and let W ∈ Rq×p have full
column rank. Let Y ∈ Rr×p. Then there exists a matrix Z ∈
Rr×q such that
1) Z ∈ Z +
2) ZW = Y

r (Π),

if and only if Π | Π22 > 0 and Y ∈ Z +
conditions hold and, in addition, Π22 < 0 then the matrix
Z := −Π−1

Y + Π−1

r (ΠW ). If these two

22 Π21W

22 Π21+

(ΠW | Π22)†W ⊤(Π | Π22)
(61)

(cid:0)
satisﬁes 1) and 2).

(cid:1)

Proof:

For the ‘only if’ part, note that 1) implies
nonemptyness of Z +
r (Π) and hence Π | Π22 > 0. Moreover,
r (Π) and ZW = Y clearly imply that Y ∈ Z +
Z ∈ Z +
r (ΠW ).
Conversely, if Π | Π22 > 0 and W has full column rank,
then by Proposition 5 we have Z +
r (ΠW ), which
proves the claim.

r (Π)W = Z +

Next, under the assumption that Π22 < 0, by Proposition 1

any Z ∈ Z +

r (Π) can be written as

Z = −Π−1

22 Π21 + (−Π22)− 1

2 S (Π | Π22)

1
2 ,

where S⊤S < I. Thus there exist S with S⊤S < I such that

Y = −Π−1

22 Π21W + (−Π22)− 1

2 S (Π | Π22)

1

2 W,

equivalently,

(−Π22)

1

2 Y − (−Π22)− 1

2 Π21W = S (Π | Π22)

1
2 W.

Hence, by Proposition 2, the matrix

S =

(−Π22)

1

2 Y − (−Π22)− 1

2 Π21W

(Π | Π22)

†

1
2 W

does the job. It can be shown that

(cid:16)

(cid:17) (cid:16)

(cid:17)

(Π | Π22)

†

1
2 W

= (ΠW | Π22)† W ⊤ (Π | Π22)

1
2 .

(cid:16)

(cid:17)
Therefore S is equal to
2 Y −(−Π22)− 1

1

(−Π22)
(cid:16)
Plugging this expression for S into the formula of Z then
ﬁnally yields (61).

(ΠW | Π22)† W ⊤(Π | Π22)
(cid:17)

2 Π21W

1
2 .

Now consider the inequality (59) and recall that the exis-
tence of Φ > 0 and C satisfying this inequality with α = 1 is
equivalent to informativity for quadratic stabilization. We can
reformulate (59) as
⊤





(cid:20)

Φ 0
0
0
(cid:21)
0

− ¯N 0

0
IqL



⊤

IqL
0
J
−C
0 


0
IqL

⊤



> 0.

IqL
0
J
−C
0 



−Φ















IqL











(62)

Then by applying Lemma 24 we now obtain necessary and
sufﬁcient conditions for informativity for quadradric stabiliza-
tion, together with a formula for a stabilizing controller. Deﬁne
the 2qL × (2qL − m) matrix W by







IqL



Iq(L−1)
0
0
0

0
0m×p
Ip
0

0
0
0
IqL



.





W := 





In addition, partition the matrix ¯N as in (40), where ¯N11 and
¯N22 are in SqL and ¯N12 = ¯N ⊤
Theorem 25: Assume that H ′

21 ∈ RqL×qL.
1(w) has full row rank. Let the
matrix ¯N be given by (57), with N deﬁned by (46). Then the
input-output data u(0), u(1), . . . , u(T ), y(0), y(1), . . . , y(T )
are informative for quadratic stabilization if and only if there
exists Φ ∈ SqL such that

(63)

> 0.

Φ > ¯N | ¯N22

and

W
J ⊤ 0 IqL

(cid:21)

W
J ⊤ 0 IqL

(cid:20)
(cid:2)

⊤



Φ 0
0
0
(cid:21)
0

(cid:20)

(cid:21)
(cid:3)

− ¯N 0

−Φ
(cid:20)




(64)
Moreover, if Φ satisﬁes these two LMIs, then the controller
with coefﬁcient matrix C deﬁned by (CONT) satisiﬁes (62).
As a consequence, this controller stabilizes all systems com-
patible with the data, and the resulting closed loop systems
have common Lyapunov function QΨ with Ψ := Φ−1.

(cid:2)

(cid:3)

Proof: We ﬁrst prove the ‘only if’ statement. Since −Φ >

0, it follows immediately from (62) that

Φ 0
0
0

(cid:20)

(cid:21)

− ¯N > 0.

(65)

VAN WAARDE et al.: A BEHAVIORAL APPROACH TO DATA-DRIVEN CONTROL, JUNE 2022

11

C⊤ := −

J ⊤ 0

IqL

W ⊤

(cid:2)

(cid:18)

(cid:3)

(cid:18)(cid:20)

Φ 0
0
0

−1

− ¯N

W

W ⊤

(cid:21)

(cid:19)

(cid:19)

0q(L−1)×m
Im
0(p+qL)×m

Φ 0
0
0

(cid:20)

(cid:21)





In turn, this implies Φ > ¯N | ¯N22. By multiplying (62) from
the right by W and from the left by its transpose, we obtain
the inequality (64).

To prove the converse implication, recall that ¯N | ¯N22 > 0.
Hence it follows from (63) that Φ > 0, and, using the fact that
¯N22 < 0, that (65) holds. From this it follows that the matrix
Π deﬁned by

x

φ

M

u

(CONT)





ℓ

m

(cid:20)



Π :=

− ¯N 0

Φ 0
0
0
(cid:21)
0
is in the set Π2qL,qL. Then, applying Lemma 24 to Π, W and
shows that there exists a matrix C such
Y :=
that (62) is satisﬁed. In other words, the data are informative
for quadratic stabilization.

−Φ


J ⊤ 0

IqL



(cid:3)

(cid:2)

Finally, we will prove the formula (CONT) for C⊤. To this
.

end, again apply Lemma 24 to Π, W and Y =
Introduce the shorthand notation

J ⊤ 0 IqL

∆ :=

W ⊤

(cid:18)

(cid:18)(cid:20)

(cid:2)
−1

W

− ¯N

Φ 0
0
0
(cid:21)
(cid:19)
J ⊤ −C⊤ 0 IqL

(cid:19)

.

(cid:3)

in the set

By (61), a ‘structured’ element
Z +

qL(Π) is given by

(cid:2)

J ⊤ −C⊤ 0 IqL

=

J ⊤ 0 IqL

∆W ⊤

(cid:2)
As such, a controller is given by

(cid:3)

(cid:2)

(cid:3)

(cid:3)
Φ 0
0
0

(cid:18)(cid:20)

− ¯N

(cid:21)

(cid:19)

C⊤ = −

J ⊤ 0

IqL

∆W ⊤

(cid:3)
It is easily veriﬁed that

(cid:2)

Φ 0
0
0
(cid:21)

(cid:18)(cid:20)

− ¯N

¯N

0q(L−1)×m
Im
0(p+qL)×m





= 0,

0q(L−1)×m
Im
0(p+qL)×m

(cid:19)





.





Thus we conclude that C⊤ is given by (CONT) as claimed.





Remark 26: Note that we have indeed managed to reduce
the size and the number of unknowns. The total size of the
LMIs (63) and (64) is equal to 3qL−m, whereas the number of
unknowns has been reduced to 1
2 qL(qL+1). The computation
of the controller has been decoupled from that of Φ. Indeed, a
stabilizing controller is now computed using (CONT) in terms
of Φ.

X. SIMULATION EXAMPLE

In this example we will obtain a stabilizing controller for
an inverted pendulum on a cart from collected measurements.
We consider a standard inverted pendulum on a cart as
depicted in Figure 1. Here, m and ℓ denote the mass and

Fig. 1. The cart and pendulum, with the parameters noted.

length of the pendulum. The mass and coefﬁcient of friction
of the cart are denoted by M and b. Lastly, we consider the
following variables: the horizontal displacement of the cart is
given by x, the angle of the pendulum from the (unstable)
equilibrium is φ, and the force applied to the cart is denoted
by u.

Assuming that M , m, and ℓ are nonzero, it is straightfor-

ward to derive the following equations of motion:

(M + m) ¨x + b ˙x − mℓ ¨φ cos(φ) + mℓ ˙φ2 sin(φ) = u
ℓ ¨φ − g sin(φ) = ¨x cos(φ)

In order to bring this model into the form used in this
paper, we discretize and then linearize it. We denote the step
size of the discretization by δ and obtain the linear discrete
time model in (66). After incorporating an additive noise term
v(t) = (v1(t) v2(t))⊤ in (66), we obtain an input-output
system in AR form as in (42), where L = 2 and

y =

x
φ

.

(cid:18)
For this example we let the parameters take the following

(cid:19)

values:

M = 1kg, m = 0.7kg,
g = 9.8 m
s2 ,

l = 0.5m,

b = 0.1 N
m/s ,
δ = 0.01s.

The resulting system (66) with additive unknown noise term
v will now be considered as the ‘true’, unknown system.

A. Measurements from the linearization

In the ﬁrst simulation example, we collect measurements
from the noisy linearized system, i.e. the system (66) with
additive noise. We take T = 20, provide 2 initial conditions,
and generate random inputs from the interval [−1, 1].

As for the matrix of noise samples V , we will assume a
noise model of the form (13) by considering V V ⊤ 6 ǫI2. Note
that, in order to discretize the system and make the leading
coefﬁcient equal to I2, the dynamics were multiplied by a
factor of δ2. Indeed, it is seen in (66) that the effect of the

12

SUBMITTED TO IEEE TRANSACTIONS ON AUTOMATIC CONTROL, JUNE 2022

input u on the dynamics is proportional to δ2. Therefore, it is
reasonable to assume that the same holds for the noise signal
v. Consequently, ǫ can be assumed to be proportional to δ4.
In the present example, we therefore take ǫ = 10−2δ4.

We now generate a random noise signal that satisﬁes the
noise model and apply the initial conditions,
inputs and
noise to the linearized system (66) with added noise. The
measurements resulting from this are shown in (67).

1, H ′

We will use Theorem 22 to show that these measurements
are informative for quadratic stabilization. For this, we ﬁrst
2 and ¯N . It is straightforward to
form the matrices H ′
see that H ′
1 has full row rank. We now use Yalmip with
Mosek as a solver in order to ﬁnd matrices D ∈ R1×6, and
Φ ∈ S6, such that Φ > 0 and the LMI (60) holds. Indeed,
such matrices exist, and therefore the data are informative for
quadratic stabilization. We can ﬁnd a stabilizing controller by
taking C = −DΦ−1, which results in

0.76 29168.72 −18360.21 0.68 −29515.03 19264.40

.

(cid:3)
(cid:2)
This corresponds to the controller of the form (47) given by

u(t + 2) +0.68

u(t + 1) +0.76

u(t)

=

29515.03 x(t + 1) −19264.40 φ(t + 1)

−29168.72 x(t)

+18360.21 φ(t).

The large difference in magnitude of the gains corresponding
to x and φ and those corresponding to u is caused by the
discretization.

In Figure 2 we can see the results of applying this controller
to the linear discretized model, with noise v = 0. To be
precise, we plot both x (Figure 2(a)) and φ (Figure 2(b))
for 200 steps originating from a given initial condition. This
illustrates that the controller stabilizes the linearized system,
as was guaranteed by Theorem 22.

B. Measurements from the nonlinear system

In this example, instead of measuring the linear system (66)
with a bounded noise term, we will perform measurements
on the (discretized) nonlinear system directly. This means
that we interpret the noise term v(t) of the linear system as
the effect of the nonlinearities. Again, we provide 2 initial
conditions and take T = 20. We will generate measurements
close to the equilibrium, in order to keep the effect of the
nonlinearities relatively small. As such, we will assume that
V V ⊤ 6 10−4δ4I2, which we will validate experimentally.

We now generate random inputs from the interval [−1, 1]
and apply them to the nonlinear system with the given initial
conditions. The measurements resulting from applying this can
be seen in (68). For the sake of simulations, we note that
the effects of the nonlinearities for these initial conditions and
inputs, as captured in the matrix V , indeed satisfy the assumed
noise model.

Similar to earlier, we note that H ′

1 has full row rank, and
we can ﬁnd Φ and D such that (60) holds. This means that
the data are informative for quadratic stabilization. By taking
C = −DΦ−1, we obtain

1.03 27778.78 −19129.66 0.85 −27967.57 20120.40

.

(cid:2)

(cid:3)

This corresponds to a controller given by:

u(t + 2) +0.85

u(t + 1) +1.03

u(t)

=

27967.57 x(t + 1) −20120.40 φ(t + 1)

−27778.78 x(t)

+19129.66 φ(t).

As before, we apply the resulting controller to both the
discretization of the nonlinear model and its linearization (66)
without noise. For both models and a given initial condition
the values of the position of the cart for 200 steps are shown in
Figure 2(c). In Figure 2(d) we show the corresponding angles
of the pendulum for the same interval of time.

XI. CONCLUSION

In this paper we have studied data-driven stability analysis
and feedback stabilization of linear input-output systems in
autoregressive (AR) form. On the basis of noisy input-output
data obtained from some unknown ‘true’ AR system, it is in
general not possible to identify this system uniquely. Indeed,
we have shown that a given set of data gives rise to a whole set
of systems that are compatible with these data, and this set is
equal to the solution set of a certain QMI that is given in terms
of the data and the noise model that we use. Next, in order
to study stability and feedback stabilization we have given a
characterization of asymptotic stability of systems in AR form
using quadratic difference forms (QDFs) as a framework for
Lyapunov functions of autonomous AR systems. This has led
to necessary and sufﬁcient conditions for stability in terms
of a second, strict, QMI. We have then deﬁned informativity
for quadratic stability as the property that all systems whose
coefﬁcient matrix satisfy the ﬁrst QMI above also satisfy
the second, strict, QMI. This has the interpretation that all
systems that are compatible with the given data are stable
with a common Lyapunov function. Using a version of the
so-called strict matrix S-lemma, this set inclusion has been
characterized in terms of feasibility of a strict LMI, again
given in terms of the data. Feasibility of this LMI is then
equivalent to the fact that all system compatible with the data
are stable with a common Lyapunov function, so in particular
the unknown ‘true’ system is stable. Subsequently we have
used this framework to study data-driven stabilization. We
have deﬁned informativity of the given data for quadratic
stabilization as the property that there exists a single feedback
controller that stabilizes all systems that are compatible with
the data, while leading to a common Lyapunov function for all
closed loop systems. We have shown that, again, this property
can be characterized in terms of feasibility of a strict LMI
that is given in terms of the data. Solutions of this LMI
then immediately yield a controller together with a common
Lyapunov function. In order to reduce the size of the LMIs and
the number of variables, we have also provided an alternative
characterization of informativity in terms of feasibilty of an
LMI of reduced size. Finally, our results have been illustrated
using an example in which noisy input-output data are used
to compute a stabilizing controller for an inverted pendulum
set-up.

VAN WAARDE et al.: A BEHAVIORAL APPROACH TO DATA-DRIVEN CONTROL, JUNE 2022

x(t + 2)
φ(t + 2)

−2+ δb
δb
Mℓ

M 0
−2

+

(cid:19)

(cid:20)

(cid:21) (cid:18)

(cid:18)

x(t + 1)
φ(t + 1)

+

1 − δb
M
− δb
Mℓ

"

− δ
1 − δ

2

2

gm
M
g(M+m)

M

x(t)
φ(t)

# (cid:18)

=

(cid:19)

2

δ
M
2
δ
Mℓ !

u(t)

(cid:19)

y(0)
(cid:2)
y(11)
(cid:2)
u(0)
u(10)
(cid:2)
(cid:2)

· · ·

y(10)

· · ·

y(20)
(cid:3)
· · · u(9)
· · · u(19)

(cid:3)

(cid:3)
(cid:3)

y(0)

· · ·

y(10)

y(11)

u(0)
u(10)

(cid:2)

(cid:2)

(cid:2)
(cid:2)

· · ·

y(20)
(cid:3)
· · · u(9)
· · · u(19)

(cid:3)

(cid:3)
(cid:3)

=

=

=
=

(cid:20)

(cid:20)

(cid:2)
(cid:2)

=

=

=
=

(cid:20)

(cid:20)

(cid:2)
(cid:2)

0.1010
0.0990
0.1134
0.1035

0.1000
0.1000
0.1121
0.1017
−0.9960 −0.7388 −0.6322
0.6225
0.6413

0.1020
0.0981
0.1149
0.1058

0.4309

0.1029
0.0974
0.1165
0.1085

0.1039
0.0969
0.1182
0.1116

0.1061
0.0970
0.1219
0.1192

0.1050
0.0969
0.1200
0.1153

0.1072
0.0974
0.1238
0.1235
0.1023 −0.7179 −0.0428 −0.8528
0.7475 −0.1559 −0.5855 −0.7585 −0.3562 −0.6643

0.1096
0.0991
0.1277
0.1327 (cid:21)

0.1084
0.0982
0.1258
0.1279

0.1108
0.1003 (cid:21)

0.6612 −0.8090 −0.2520
0.2019

(cid:3)
(cid:3)

0.1010
0.0390
0.1121
0.0331

0.1000
0.0400
0.1111
0.0332
−0.6358 −0.2516
−0.0440 −0.2577

0.1020
0.0380
0.1132
0.0330

0.1029
0.0371
0.1143
0.0332

0.1040
0.0364
0.1155
0.0336
0.6150 −0.1941 −0.4534 −0.8523
0.5910 −0.1870
0.3739

0.1050
0.0358
0.1167
0.0340

0.1061
0.0353
0.1180
0.0346

0.1090
0.1081
0.1070
0.0337
0.0342
0.0347
0.1218
0.1205
0.1192
0.0352
0.0370 (cid:21)
0.0361
0.1926 −0.6554 −0.0237
0.7050 −0.3602

0.2488 −0.6610

0.1100
0.0333 (cid:21)

0.3687
0.1016

(cid:3)
(cid:3)

13

(66)

(67)

(68)

1.4

1.2

1

0.8

0.6

0.4

0.2

0

1

0.8

0.6

0.4

0.2

0

Linearized model
Nonlinear model

0.6

0.4

0.2

0

−0.2

−0.4

Linearized model
Nonlinear model

0

20

40

60

80

100

120

140

160

180

200

0

20

40

60

80

100

120

140

160

180

200

(a) The position x of the cart for Section X-A.

(b) The angle φ of the pendulum for Section X-A.

Linearized model
Nonlinear model

0.2

0

−0.2

−0.4

−0.6

Linearized model
Nonlinear model

0

20

40

60

80

100

120

140

160

180

200

0

20

40

60

80

100

120

140

160

180

200

(c) The position x of the cart for Section X-B.

(d) The angle φ of the pendulum for Section X-B.

Fig. 2. The results of interconnecting the controllers of Section X-A (top) and Section X-B (bottom) to the linearized and nonlinear model.

REFERENCES

[1] T. Dai and M. Sznaier, “A moments based approach to designing MIMO
data driven controllers for switched systems,” in Proceedings of the IEEE
Conference on Decision and Control, 2018, pp. 5652–5657.

[2] H. L. Trentelman, H. J. Van Waarde, and M. K. Camlibel, “An
informativity approach to the data-driven algebraic regulator problem,”
IEEE Transactions on Automatic Control, pp. 1–1, 2021.

[3] H. J. van Waarde, M. K. Camlibel, and M. Mesbahi, “From noisy data
to feedback controllers: Nonconservative design via a matrix S-lemma,”
IEEE Transactions on Automatic Control, vol. 67, no. 1, pp. 162–175,
2022.

[4] F. Celi, G. Baggio, and F. Pasqualetti, “Distributed learning of optimal
controls for linear systems,” in Proceedings of the IEEE Conference on
Decision and Control, 2021, pp. 5771–5776.

[5] D. Gagliardi and G. Russo, “On a probabilistic approach to synthe-
size control policies from example datasets,” Automatica, vol. 137, p.
110121, 2022.

[6] A. Luppi, C. De Persis, and P. Tesi, “On data-driven stabilization of
systems with nonlinearities satisfying quadratic constraints,” Systems &
Control Letters, vol. 163, p. 105206, 2022.

[7] Z. Yuan and J. Cortés, “Data-driven optimal control of bilinear systems,”

IEEE Control Systems Letters, vol. 6, pp. 2479–2484, 2022.

[8] C. De Persis and P. Tesi, “Formulas for data-driven control: Stabilization,

 
14

SUBMITTED TO IEEE TRANSACTIONS ON AUTOMATIC CONTROL, JUNE 2022

optimality, and robustness,” IEEE Transactions on Automatic Control,
vol. 65, no. 3, pp. 909–924, 2020.

[33] J. Polderman and J. Willems, Introduction to Mathematical Systems

Theory: a behavioral approach. Springer Verlag, 1997.

[9] A. Koch, J. Berberich, and F. Allgöwer, “Provably robust veriﬁcation of
dissipativity properties from data,” To appear in IEEE Transactions on
Automatic Control, 2021.

[34] H. J. van Waarde, M. K. Camlibel, P. Rapisarda, and H. L. Trentelman,
“Data-driven dissipativity analysis: Application of the matrix S-lemma,”
IEEE Control Systems Magazine, vol. 42, no. 3, pp. 140–149, 2022.

[10] T. Steentjes, M. Lazar, and P. Van den Hof, “On data-driven control:
Informativity of noisy input-output data with cross-covariance bounds,”
IEEE Control Systems Letters, vol. 6, pp. 2192–2197, 2022.

[11] J. Berberich, C.

Scherer,
data

and
for

F. Allgöwer,
robust

controller

“Combining
design,”

knowledge

prior
https://arxiv.org/abs/2009.05253v3, 2021.

and

[12] J. C. Willems and H. L. Trentelman, “On quadratic differential forms,”
SIAM Journal on Control and Optimization, vol. 36, no. 5, pp. 1703–
1749, 1998.

[13] ——, “Synthesis of dissipative systems using quadratic differential
forms: Part I,” IEEE Transactions on Automatic Control, vol. 47, no. 1,
pp. 53–69, 2002.

[14] ——, “Synthesis of dissipative systems using quadratic differential
forms: Part II,” IEEE Transactions on Automatic Control, vol. 47, no. 1,
pp. 70–86, 2002.

[15] C. Kojima and K. Takaba, “A generalized Lyapunov stability theorem
for discrete-time systems based on quadratic difference forms,” in
Proceedings of the 44th IEEE Conference on Decision and Control,
2005, pp. 2911–2916.

[16] ——, “An LMI condition for asymptotic stability of discrete-time system
the IEEE
based on quadratic difference forms.” in Proceedings of
Conference on Computer Aided Control System Design, 2006, pp. 1139–
1143.

[17] H. J. van Waarde, J. Eising, H. L. Trentelman, and M. K. Camlibel, “Data
informativity: a new perspective on data-driven analysis and control,”
IEEE Transactions on Automatic Control, vol. 65, no. 11, pp. 4753–
4768, 2020.

[18] H. J. van Waarde, M. Camlibel, J. Eising, and H. L. Trentelman,
“Quadratic matrix inequalities with applications to data-based control,”
https://arxiv.org/abs/2203.12959, 2022.

[19] J. C. Willems, P. Rapisarda, I. Markovsky, and B. L. M. De Moor, “A
note on persistency of excitation,” Systems & Control Letters, vol. 54,
no. 4, pp. 325–329, 2005.

[20] M. Ferizbegovic, H. Hjalmarsson, P. Mattsson, and T. B. Schön,
“Willems’ fundamental
lemma based on second-order moments,” in
Proceedings of the IEEE Conference on Decision and Control, 2021,
pp. 396–401.

[21] P. Schmitz, T. Faulwasser, and K. Worthmann, “Willems’ fundamental
lemma for linear descriptor systems and its use for data-driven output-
feedback MPC,” IEEE Control Systems Letters, vol. 6, pp. 2443–2448,
2022.

[22] A. Martinelli, M. Gargiani, M. Draskovic, and J. Lygeros, “Data-driven
optimal control of afﬁne systems: A linear programming perspective,”
https://arxiv.org/abs/2203.12044, 2022.

[23] V. G. Lopez and M. A. Müller, “On a continuous-time version of

Willems’ lemma,” https://arxiv.org/abs/2203.03702, 2022.

[24] I. Markovsky and P. Rapisarda, “Data-driven simulation and control,”
International Journal of Control, vol. 81, no. 12, pp. 1946–1959, 2008.
[25] J. Coulson, J. Lygeros, and F. Dörﬂer, “Data-enabled predictive control:
In the shallows of the DeePC,” in Proceedings of the European Control
Conference, June 2019, pp. 307–312.

[26] J. Coulson, J. Lygeros, and F. Dörﬂer, “Distributionally robust chance
constrained data-enabled predictive control,” IEEE Transactions on
Automatic Control, pp. 1–1, 2021.

[27] A. Alanwar, Y.

Stürz,

and K. H.

Johansson,

data-driven
predictive
https://arxiv.org/abs/2103.14110, 2021.

control

using

reachability

“Robust
analysis,”

[28] M. Yin, A. Iannelli, and R. S. Smith, “Maximum likelihood signal
matrix model for data-driven predictive control,” in Proceedings of the
Conference on Learning for Dynamics and Control, vol. 144, June 2021,
pp. 1004–1014.

[29] T. M. Maupong and P. Rapisarda, “Data-driven control: A behavioral
approach,” Systems & Control Letters, vol. 101, pp. 37–43, 2017.
[30] T. Maupong, J. Mayo-Maldonado, and P. Rapisarda, “On Lyapunov
functions and data-driven dissipativity,” IFAC-PapersOnLine, vol. 50,
no. 1, pp. 7783–7788, 2017, 20th IFAC World Congress.

[31] H. J. van Waarde and M. K. Camlibel, “A matrix Finsler’s lemma
with applications to data-driven control,” in Proceedings of the IEEE
Conference on Decision and Control, 2021, pp. 5777–5782.

[32] J. C. Willems, “Paradigms and puzzels in the theory of dynamical
systems,” IEEE Transactions on Automatic Control, vol. 36, no. 3, pp.
259–294, 1991.

