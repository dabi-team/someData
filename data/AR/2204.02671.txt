Behavioral uncertainty quantiﬁcation for data-driven control

Alberto Padoan, Jeremy Coulson, Henk J. van Waarde, John Lygeros, and Florian D¨orﬂer

2
2
0
2

r
p
A
6

]

C
O
.
h
t
a
m

[

1
v
1
7
6
2
0
.
4
0
2
2
:
v
i
X
r
a

Abstract— This paper explores the problem of uncertainty
quantiﬁcation in the behavioral setting for data-driven control.
Building on classical ideas from robust control, the problem
is regarded as that of selecting a metric which is best suited
to a data-based description of uncertainties. Leveraging on
Willems’ fundamental lemma, restricted behaviors are viewed
as subspaces of ﬁxed dimension, which may be represented
by data matrices. Consequently, metrics between restricted
behaviors are deﬁned as distances between points on the
Grassmannian, i.e., the set of all subspaces of equal dimension
in a given vector space. A new metric is deﬁned on the
set of restricted behaviors as a direct ﬁnite-time counterpart
of the classical gap metric. The metric is shown to capture
parametric uncertainty for the class of autoregressive (AR)
models. Numerical simulations illustrate the value of the metric
with a data-driven mode recognition and control case study.

I. INTRODUCTION

In a typical control design problem, the role of data (time
series) has been long dictated by indirect approaches [1 , 2],
where system identiﬁcation is sequentially followed by
model-based control. However, the advent of large data sets
and the ever-increasing computing power, combined with
the ongoing revolution brought about by machine learning
technologies, has recently triggered a renewed appreciation
for direct approaches, where the objective is to infer optimal
decisions directly from measured data.

A cornerstone of this newly emerging trend in control
is a far-reaching result due to Willems and co-authors [3],
commonly known as the fundamental lemma. Leveraging
on the behavioral approach to system theory [4 , 5],
the
fundamental lemma establishes that parametric models of a
data-generating linear time-invariant (LTI) system may be
replaced by raw data, provided the dynamics are sufﬁciently
excited. Following the contributions [6 – 8], the number of
new data-driven control algorithms has boomed over the past
few years, see, e.g., [9] for a recent overview. A convincing
demonstration of the potential of direct approaches to data-
driven control is the successful implementation of the DeePC
algorithm [6] in a wide range of experimental case studies,
including aerial robotics [10], synchronous motor drives [11],
grid-connected power converters [12].

The new wave of data-driven control algorithms has
[10 , 13 – 17].

primarily modeled uncertainty by ellipsoids

A. Padoan, J. Coulson, J. Lygeros, F. D¨orﬂer are with the De-
partment of
Information Technology and Electrical Engineering at
ETH Z¨urich, Z¨urich, Switzerland {apadoan, jcoulson, lygeros,
dorfler}@control.ee.ethz.ch. H. J. van Waarde is with the
Bernoulli
Institute for Mathematics, Computer Science and Artiﬁcial
Intelligence, University of Groningen, Groningen, The Netherlands.
h.j.van.waarde@rug.nl. Research supported by the Swiss National
Science Foundation under the NCCR Automation.

1

While effective in many circumstances, this approach dis-
regards the geometric structure of the data, leading to a
possibly coarse characterization of uncertainty.

This paper explores the problem of uncertainty quantiﬁca-
tion in data-driven control of LTI systems. We seek a data-
based behavioral description of uncertainty. Building on the
rich legacy of robust control theory [18 – 21], we identify
the problem of uncertainty quantiﬁcation with that of select-
ing a “natural” metric to study robustness questions. The
starting point of our analysis is a seemingly elementary, yet
profound consequence of the fundamental lemma: restricted
behaviors may be regarded as subspaces of ﬁxed dimension
and represented directly by data matrices. Building on this
premise, we identify restricted behaviors with points on
the Grassmannian Gr(k, N ), i.e., the set of all subspaces
of dimension k in RN , endowed with the structure of a
(quotient) manifold. The L-gap metric is then introduced as a
direct ﬁnite-time counterpart of the classical gap metric [18 –
21], which measures the distance between graphs of input-
output operators and allows one to compare the closed-loop
behavior of different systems subject to the same feedback
controller.

Contributions: The contributions of the paper are four-
fold: (i) we deﬁne a new (representation free) metric on
the set of restricted behaviors; we show that the metric is
easily computed via measured data and readily understood
in terms of trajectories; (ii) we show the our metric can be
used for uncertainty quantiﬁcation for behaviors described
by AR models; (iii) we connect the L-gap to the classical
ℓ2-gap from robust control theory; and (iv) we demonstrate
the beneﬁts brought by the L-gap in a data-driven mode
recognition and control case study.

Paper organization: The remainder of this paper is
organized as follows. Section II provides basic deﬁnitions
regarding behavioral systems. Section III introduces a new
metric between restricted behaviors, which is then used for
uncertainty quantiﬁcation purposes and shown to be closely
connected to the classical ℓ2-gap. Section IV illustrates the
theory with a numerical case study. Section V provides
a summary of the main results and an outlook to future
research directions.

{

1, . . . , p

is denoted by p for all p

Notation: The set of positive and non-negative integers
are denoted by N and Z+, respectively. The set of positive
N. The set
integers
of real numbers is denoted by R. The transpose, image, and
Rp×m are denoted by M T, im M ,
kernel of the matrix M
and ker M , respectively. A map f from X to Y is denoted
Y ; (Y )X denotes the set of all such maps. The
by f : X
Z+.
t-shift is deﬁned as (σtf )(t′) = f (t + t′) for all t, t′

→

∈

∈

}

∈

 
 
 
 
 
 
II. BEHAVIORAL SYSTEMS

A. Preliminaries in behavioral system theory

Following [5], we introduce some basic notions and results

on behavioral systems.

B ⊆

Deﬁnition 1. A dynamical system Σ is a triple Σ =
), where Z+ is the time set, Rq is the signal space,
(Z+, Rq,
B
(Rq)Z+ is the behavior of the system.
and
Deﬁnition 2. A dynamical system Σ = (Z+, Rq,
linear if
if σt(
)
the topology of pointwise convergence.

) is
is a linear subspace of (Rq)Z+ , time invariant
Z+, and complete if
is closed in

B
⊆ B

for all t

∈

B

B

B

The structure of an LTI dynamical system is characterized
by a set of integer invariants known as structure indices [4,
Section 7]. The most important ones are the number of inputs
(or free variables) m, the lag l, and the order n. The structure
indices are intrinsic properties of a dynamical system, as
they do not depend on its representation. The complexity of
a dynamical system is deﬁned as c = (m, l, n). The class of
all complete linear, time invariant systems (with complexity
q,c). By a convenient abuse of notation,
c) is denoted by
L
we shall also write

q,c).

q (

q (

Deﬁnition 3. Let
B ∈ L
behavior (in the interval [1, T ]) is the set
RqT
col(w1, . . . , wT )
A vector w
system

N. The restricted
w =
T =
T
.
t
∈
}
T is a T -length trajectory of the dynamical

B|
: wt = vt,

∈ B|

∈ B

{
∈

| ∃

∈

∀

v

.

L
B ∈ L

B ∈ L
q and T

B

The following lemma characterizes the dimension of a

restricted behavior

L

q,c in terms of its complexity.

B|

∈ L
[22, Lemma 2.1]

Lemma 1.

L is a subspace of RqL,

L = mL + n, for L > l.

B|
dim

B|

Let

q,c. Then
B ∈ L
the dimension of which is
y

Deﬁnition 4. A dynamical system
if for every T
T ′
∈
wt = w2

∈ B|
∈ B
t−T −T ′ for t > T + T ′.

∈
Z+, and w

T , and w2

B ∈ L
∈ B
such that wt = w1
t

N, w1

q is controllable
there exists
T and

for t

∈

In other words, a dynamical system is controllable if any two
trajectories can be patched together in ﬁnite time.

B. The fundamental lemma

Given a T -length trajectory w

RqT of a controllable
q, one may obtain a non-parametric
dynamical system
representation of the restricted behavior using a result ﬁrst
presented in [3], which over time became known as the
fundamental lemma. To state this result, we introduce some
preliminary notions.

B ∈ L

∈

Deﬁnition 5. The Hankel matrix of depth L
with w

RqT is deﬁned as

∈

w2
w3
...

w1
w2
...
wL wL+1

wT −L+1
wT −L+2
...
wT

· · ·
· · ·
. . .

· · ·

∈








HL(w) = 





T associated

∈

R(qL)×(T −L+1).

2

RmT is persistently exciting of
Deﬁnition 6. A vector u
order L if HL(u) is full row rank, i.e., rank HL(u) = mL.

∈

Persistency of excitation plays a key role in system identiﬁ-
cation and adaptive control [1 , 2 , 23]. A necessary condition
RmT to be persistently exciting of order L is
for u
i.e.,
that HL(u) has at
1. We are now ready to state the
T
Tmin = (m + 1)L
fundamental lemma [3].

least as many columns as rows,

≥

−

∈

Lemma 2 (Fundamental
lable dynamical system
w = (u, y). Assume wd = (ud, yd)
tently exciting of order L + n. Then

lemma). Consider a control-
q, with input/output partition
T and ud is persis-
L = im HL(wd). y

B ∈ L

∈ B|
B|

Lemma 2 is of paramount importance in data-driven con-
trol [24]. It provides conditions for the restricted behavior
L to be completely characterized by the image of the
B|
Hankel matrix HL(wd). As a result, the subspace im HL(wd)
can be regarded as a non-parametric representation of the
, so long as L-length trajectories are
dynamical system
considered. The controllability and persistency of excitation
assumptions can be removed by focusing on behaviors of
ﬁxed complexity and using the rank condition

B

rank HL(wd) = mL + n.

(1)

Lemma 3.

q,c and an associated T -length trajectory wd

[24, Corollary 19] Consider a dynamical system
T .
y

L = im HL(wd) if and only if (1) holds.

∈ B|

B ∈ L
For L > l,

B|

For convenience, in the sequel a T -length trajectory wd of
q,c is said to be sufﬁciently excited
a dynamical system
of order L if it satisﬁes the rank condition (1). All of these
“low rank” results hold obviously for the deterministic LTI
case, but they can also be used to design effective de-noising
schemes by low-rank approximation [9].

B ∈ L

III. A METRIC ON RESTRICTED BEHAVIORS

This section explores the issue of uncertainty quantiﬁ-
cation using a data-based behavioral description of uncer-
tainties. The starting point of our analysis is a seemingly
elementary, yet profound consequence of the fundamental
lemma: restricted behaviors may be regarded as subspaces
of equal dimension, which may be represented directly by
data matrices. Thus, restricted behaviors may be identiﬁed
with points on the Grassmannian Gr(k, N ), i.e., the set
of all subspaces of dimension k in RN , endowed with
the structure of a (quotient) manifold [25, p.63]. Metrics
between restricted behaviors thus arise from the underlying
Grassmannian structure.

Proposition 1. The function d is a metric on the set of all
q,c, with L > l, whenever d is
restricted behaviors
∈ L
y
a metric on Gr(mL + n, qL).

B|

L

Proof. Let L > l and let d be a metric on Gr(mL + n, qL).
q,c
By Lemma 1, the set of all restricted behaviors
is a subset of Gr(mL + n, qL). Then the set of all restricted
q,c endowed with the metric d is also a
behaviors
metric space, since any subset of a metric space is itself a

∈ L

∈ L

B|

B|

L

L

metric space with respect to the induced metric [26, p.38].

With these premises, a natural question is: what is a good
notion of distance for restricted behaviors? Ideally, a metric
should be intrinsic, easily computed, and readily understood
in system-theoretic terms. The aforementioned properties
provide an identikit of the desired distance and pave the way
for the discussion in this section, where we explore a notion
of distance between restricted behaviors.

A. The gap between restricted behaviors

The gap metric plays a pivotal role in control theory [18 –
21] and, in many ways, it reﬂects the intuitive notion of
distance between subspaces. This section introduces the L-
gap metric as a direct ﬁnite-time counterpart of the classical
gap metric. To this end, we recall a few preliminary notions.
and
is

be a normed space with norm

. The distance between v and

S
be subspace of

. Let v

k · k

∈ S

Let

let
deﬁned as [27, p.7]

W

S

W

δ(v,

) = inf

v

w

.

k

−

W

w∈W k
k · k2 is the Euclidean 2-norm in RN , the distance between
If
v and
,
is the distance between v and its projection onto
W
W
i.e., δ(v,
k2 , where PW is the orthogonal
PW )v
) =
projector onto the subspace
W

W

(I

−

k

.

Deﬁnition 7.
of a Hilbert space
as

H

[19, p.30] Let

and

W
V
. The gap between

be closed subspaces
is deﬁned

and

W
where PV and PW are the orthogonal projectors onto

gapH(
V

,

) =

PV −
k

(2)

and

V

W

V
PW k

,

, respectively.

W
The gap between

and

may be expressed as [19, p.30]

V
) = max

W
(I

,

W

gapH(
PW )PV k
V
In particular, 0
. To
)
W
streamline the exposition, we also recall the notion of di-
rected gap between

PV )PW k}
and

{k
gapH(
V

which is deﬁned as

1 for all

(I
k

and

W

≤

−

−

≤

V

.

,

,

⇀
gapH(
V

,

W

V
) = sup
v∈V
kvk=1

W
δ(v,

) =

(I

k

PW )PV k

.

−

W

(3)

⇀
gapH(

⇀
gapH(
V

,

,

,

)

),

W

W

) = max

.
Clearly, gapH(
}
{
V
Note that no explicit mention to any particular choice of
is
is actually needed when the ambient Hilbert space
k · k
RN , since all the gap functions are equivalent [28, p.91].
Throughout the paper, we denote by gap the gap metric
corresponding the Euclidean 2-norm
k · k2 to streamline the
notation.
We are now ready to introduce a notion of distance

W

H

V

between restricted behaviors.

Deﬁnition 8. Let
L-gap between

q,c and ˜
B ∈ L
is deﬁned as

q,c. For L

B ∈ L
and ˜
B
, ˜
B

B

B
gapL(

) = gap(

L, ˜
B|

L).

B|

Z+, the

∈

(4)

3

The directed L-gap between
⇀
⇀
gap(
gapL(

) =

L).

L, ˜
B|

B|

, ˜
B

B

and ˜
B

B

is deﬁned as

Remark 1. The L-gap can also be deﬁned for behaviors with
different lags. However, for clarity of exposition we deﬁne
△
it here for behaviors of the same complexity c.

By Proposition 1 and since gap is a metric on Gr(k, N ) for
N [28, p.93], we have the following result.
k, N

∈

Corollary 1. The set of all restricted behaviors
B|
with L > l, equipped with gapL is a metric space.

L

q,c,
y

∈ L

Remark 2 (Geometry). The gap metric has a well-known ge-
ometric interpretation in terms of the sine of the largest prin-
cipal angle between two subspaces. In particular, as an imme-
diate consequence of [28, Theorem 4.5], for L > l, the L-gap
between
) = sin θmax,
where θmax is the largest principal angle between the sub-
L (see Appendix A for more detail on
spaces
B|
△
principal angles).

B ∈ L
L and ˜
B|

q,c is gapL(
B

q,c and ˜

B ∈ L

, ˜
B

Remark 3 (Data-based computation). The L-gap between
behaviors can be directly computed from the knowledge of
sufﬁciently excited trajectories. Let wd
T
be sufﬁciently excited T -length trajectories of order L, with
L > l. Let

T and ˜wd

∈ B|

˜
B|

∈

HL(wd) = [ U1 U2 ]

HL( ˜wd) = [ ˜U1 ˜U2 ]

S 0
0
0
˜S 0
0
0

(cid:20)

(cid:20)

V1
V2(cid:21)
˜V1
˜V2(cid:21)

(cid:21) (cid:20)

(cid:21) (cid:20)

,

be the singular value decomposition (SVD) of the Hankel
RqL×(mL+n) and
matrices HL(wd) and HL( ˜wd) with U1 ∈
˜U1 ∈
RqL×(mL+n), respectively. Then

T

T

) =

˜U1 ˜U

gapL(

U1U

k

T
1 −

, ˜
B
B
where
the ﬁrst
, ˜
gapL(
) =
B
B
P ˜B|L = ˜U1 ˜U T
Thm 2.5.1].

1 k2 =
2 U1k2
k
from the
fact
and since PB|L = U1U T

PB|L −

equality comes
P ˜B|L k2

that
1 and
1 [29, p.82]. The second identity is due to [29,
△

(5)

˜U

k

Remark 4 (Interpretation in terms of trajectories). Given
q,c, consider the problem of estimating the closest
RqL
∈
q,c, i.e.,

B ∈ L
trajectory w
which belongs to a possibly distinct behavior ˜

L to a given measured trajectory ˜w

∈ B|

B ∈ L

minimize
w∈B|L
subject to

w

k
˜w

˜w

2
2,

k
L.

−
˜
B|

∈

By Lemma 1,

B|

L is a subspace and the estimation error is

inf
w∈B|L k

w

˜w

k2 =

−

(I

−

PB|L ) ˜w

is known to be such that gapL(

(cid:13)
(cid:13)

2 .
(cid:13)
(cid:13)

(6)

, ˜
)
B

≤

ǫ.

B

Now suppose ˜
B
Then

sup
˜w∈ ˜B|L
k ˜wk26=0

inf
w∈B|L

w
k

˜w
k2
−
˜w
k2 ≤
k

ǫ.

(9)

,

.

To prove the upper bound on the gap,
inequality of (8), we again use (5) to obtain
(I + ˜F ˜F ⊤)− 1
˜F
F

, ˜
)
B

gapL(

k2 k

k2 k

≤ k

˜F

−

B

F

2

i.e.,

the right

(I +F ⊤F )− 1

2

k2

1.
since both
k2 ≤
This establishes the upper bound in (8), which proves the
theorem.

k2 ≤

1 and

(I +F ⊤F )− 1

k

k

2

2

k2
≤ k
−
(I + ˜F ˜F ⊤)− 1

We have the following corollary for AR models.

q and ˜

Z+,
q,c. Given L
Corollary 2. Let
L and ˜
with L > l, assume
L are deﬁned by the single-
B|
input, single-output AR models with real valued coefﬁcients
ak, bk, ˜ak, ˜bk

B ∈ L
B|

B ∈ L

∈

L−1
k=0 , respectively:
L−2

}

L−1

{

yt+L−1 =

akyt+k +

bkut+k,

k=0
X
L−2

yt+L−1 =

˜akyt+k +

k=0
X

k=0
X
L−1

k=0
X

˜bkut+k.

Assume

F =
˜F =

(cid:2)
are such that
(cid:2)

a0

˜a0

F

b0
˜b0
˜F

k

k2 ≤
Proof. Note that
L = ker
of F , given any trajectory

B|

−

. . . aL−2

bL−2
˜aL−2 ˜bL−2

. . .

bL−1
˜bL−1
, ˜
)
B

(cid:3)
ǫ.
(cid:3)

ǫ. Then gapL(
I

F

B

≤
. Indeed, by deﬁnition

y

−

(cid:3)

(cid:2)

w = col(y0, u0, . . . , yL−2, uL−2, uL−1, yL−1)

I

F

w = 0. Note that ker
=
. The same can be shown for ˜F . Leveraging on

−

−

F

(cid:2)

(cid:3)

(cid:2)

(cid:3)

we have
I
F

im

(cid:20)

(cid:21)

Theorem 1 yields the desired result.

L,

∈ B|
I

Remark 5. We presented Corollary 2 for single-input single-
output models for clarity of exposition, but the result holds
for more general multi-input multi-output systems. Corol-
lary 2 raises the natural open question of how to relate
the L-gap to classical uncertainty models [18 – 21] including
additive, multiplicative, and coprime factor uncertainties.
△
This is left as an area of future work.

C. Connection with the ℓ2-gap metric

The gap metric plays a central role in robust control
theory [18 – 21], where ﬁnite-dimensional, LTI systems are
regarded as operators acting on a given Hilbert space
(such
as1 ℓ2 or H2(Dc)). In this context, the distance between ﬁnite-
dimensional, LTI systems Σ and ˜Σ is deﬁned in terms of the

H

, ˜
B

B

In other words, gapL(
) is an upper bound for the
worst case relative estimation error. The domain of the L-
gap metric may be extended to measure distances between
subspaces of different dimension [30], so these results may
be used, e.g., for smoothing of a noisy trajectory ˜w. We
△
elaborate more on this in Section V.

B. Uncertainty quantiﬁcation

The following theorem, which is inspired by [31, Prop. 7],
provides an upper and a lower bound on the L-gap in case
the restricted behaviors have a speciﬁc form.

Theorem 1. Let
with L > l, assume

B ∈ L

q,c and ˜

q,c. Given L

B ∈ L

Z+,

∈

L = im

B|

I
F

(cid:20)

(cid:21)

and ˜
B|

L = im

I
˜F

.

(cid:21)

(cid:20)

Then

1 +

q

F

k
F

k

˜F

k2
1 +

−
2
2
k

q

gapL(

B

, ˜
)
B

F

˜F

k2.

−

≤ k

≤

˜F

2
2

k

k

(7)

(8)

y

Proof. We ﬁrst prove the left inequality, i.e., the lower bound
on the L-gap. By (5),

I
F

gapL(

) =

, ˜
B

(I + ˜F ˜F ⊤)− 1

2

˜F I

(I +F ⊤F )− 1

2

≥

−
(cid:2)

B
k
σmin((I + ˜F ˜F ⊤)− 1

k2
k2,
where σmin(X) denotes the smallest singular value of a given
matrix X. Next, we will work out σmin((I + ˜F ˜F ⊤)− 1
2 ). Note
that

2 ) σmin((I + F ⊤F )− 1
2 )

(cid:20)
(cid:3)

˜F

−

F

(cid:21)

k

σmin((I + ˜F ˜F ⊤)− 1

2 ) =

=

=

1
σmax((I + ˜F ˜F ⊤) 1
2 )
1
σmax(I + ˜F ˜F ⊤)

q

1

,

(I + ˜F ˜F ⊤)

k2

k
q

where σmax(X) denotes the largest singular value of X.
Finally, note that for any eigenvalue λ and corresponding
eigenvector v of ˜F ˜F ⊤, we have that

(I + ˜F ˜F ⊤)(I + ˜F ˜F ⊤)v = (1 + λ)2v.
Therefore, every singular value of (I + ˜F ˜F ⊤) is of the form
1 + σ, where √σ is a singular value of ˜F . We conclude that
I + ˜F ˜F ⊤

2
2. This establishes that

˜F

k

k2 = 1 +
k
σmin((I + ˜F ˜F ⊤)− 1

k

2 ) =

q
In similar fashion, we can prove that

1 +

˜F

2
2

k

k

σmin((I + F ⊤F )− 1

2 ) =

.

2
2

1 +

F

k

k

By substituting the latter two equalities in the lower bound
on gapL(

) we obtain the left inequality of (8).

p

, ˜
B

B

1

1

.

2 is the Hilbert space of square summable sequences u : Z+ → Rm,

1ℓm
with norm

kukℓ2

∞

=

kutk2
2.

Xt=0
H2(Dc)m is the Hardy space of functions f : C → Cm which are analytic
in the complement of the closed unit disk D, with norm [19, p.13]

kf kH2(Dc ) = sup

>1 (cid:18)

r

|

|

4

2π

1
2π Z

0

f (reiθ)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1/2

.

2

2

dθ

(cid:19)

gap between the graphs of the corresponding input-output
operators.

some data matrix D serving as a predictive model for
allowable trajectories:

[19, p.30] Let2
Deﬁnition 9.
Y
Hilbert spaces. Let P : dom(P )
→ Y
be closed operators, with dom(P ) and dom( ˜P ) being sub-
spaces of

. The gap between P and ˜P is deﬁned as

, with
U × Y
and ˜P : dom( ˜P )

H
→ Y

and

=

U

U
gapH(P, ˜P ) = gapH(graph(P ), graph( ˜P )).

We now show that, under certain assumptions, the L-gap
metric can be connected to the classical ℓ2-gap metric. The
proof is deferred to Appendix B.

Theorem 2. Let
graphℓ2(P ) and
linear operators on ℓm

q and ˜

=
B ∈ L
= graphℓ2( ˜P ), with P and ˜P bounded
2 . Then

q,c. Assume

B ∈ L

B

B

lim
L→∞

gapL(

B

, ˜
)
B

≤

gapℓ2(P, ˜P ).

y

Remark 6. The problem of uncertainty quantiﬁcation has
a long history in robust control [18 – 21], where systems
are classically deﬁned over an inﬁnite time horizon. The
comparison between the ℓ2-gap and the L-gap thus requires
. We observe that a “data-driven gap metric” is
L
deﬁned and linked to the H2(Dc)-gap metric [32, Lemma
6]. Theorem 2 provides a representation free version of the
argument given in [32, Lemma 6]. The connection between
the L-gap metric and the H2(Dc)-gap metric is left as a
△
question for future research.

→ ∞

IV. APPLICATION: MODE RECOGNITION AND CONTROL

We envision many applications of the L-gap metric, e.g.,
prediction error quantiﬁcation, robustiﬁcation in data-driven
control, and fault detection and isolation. In the following
case study, we use it as an analysis tool in the spirit of mode
recognition and control. Namely, we determine the mode of a
switched autoregressive exogenous (SARX) system directly
from data for the purpose of data-driven control.

Consider a SARX system [33] with 2 modes given by

yt = 0.2yt−1 + 0.24yt−2 + 2ut−1 + nt,
yt = 0.7yt−1 −
0.12yt−2 + 1ut−1 + nt,
R and yt

where ut
time t
σ = 10−4 and truncated to the interval [

∈
Z+, and nt

∈
∼ N

∈

R are the inputs and outputs at
(0, σ2) is observation noise with

3σ, 3σ].

(10)

We consider the problem of performing data-driven con-
trol [6], while recognizing switches in the system’s mode.
To this end, we use DeePC [6] which solves the following
optimal control problem in a receding horizon fashion for

−

2Given a mapping P : U → Y, then its graph is the subset graph(P ) of
U × Y deﬁned as graph(P ) = {(u, P u) : u ∈ U } [19, p.17]. If P is an
operator deﬁned on a normed subspace of U , then that subspace is called
the domain of the operator P and is denoted by dom(P ) [19, p.18]. To
simplify the exposition, if U = ℓm
2, we write domℓ2 (P ) =
and graphℓ2
: u ∈
2

(P ) = {(u, P u) ∈ ℓm+p

2 and Y = ℓp

2 : P u ∈ ℓp

2

u ∈ ℓm
domℓ2 (P )}.
(cid:8)

(cid:9)

minimize
y,u,g

2000

y

r

2 +

u

2 + 20

k
subject to Dg = col(uini, u, yini, y),

−

k

k

k

2

g

k

k

(11)

∈

where (uini, yini) is the most recent Tini-length trajectory of
the system (used to implicitly ﬁx the initial condition from
RTf
which the Tf-length prediction, (u, y) evolves), and r
is a given reference trajectory. We select Tini = 2 and Tf = 5.
By Lemma 3, any data matrix D containing sufﬁciently
exciting data from a particular system mode describes (ap-
proximately due to noise) the subspace in which trajectories
live for that mode. By performing an SVD of D, we can
identify a large decrease in the singular values indicating the
dimension of the subspace of allowable trajectories. Note
that SVD does not necessarily preserve structure, but we
only require a basis for the restricted behavior. In this case,
the subspace dimension is given by (1) and is equal to
Tini + Tf + n = 9 (see Fig 1). Distinguishing the modes
would not be possible by looking at the singular values of
the data matrices alone. We propose the use of the L-gap to
distinguish the modes.

100

10-5

0

2

4

6

8

10

12

14

Fig. 1. Singular values of data matrices representing restricted behaviors
of each mode of system (10).

≥

We propose the following data-driven mode recognition
0 denote the
and control strategy. Before starting, let t
current time, and ﬁx the matrix D in (11). The ﬁrst step is to
compute an SVD of D and form a basis Dbasis using the ﬁrst
Tini + Tf + n left singular vectors. Next compute an SVD of a
matrix with M columns containing the most recent Tini + Tf-
length trajectories, denoted Ht, and form a basis, denoted
Ht,basis, using the ﬁrst Tini + Tf + n left singular vectors. Fix
a threshold ǫ > 0. If gapTini+Tf(im Ht,basis, im Dbasis) > ǫ,
set D = Ht. This can be thought of as adopting the most
recent data as the predictive model in (11) only when the gap
between the predictive model D and the most recent data Ht
is larger than some pre-deﬁned threshold. Equipped with the
data matrix D, solve (11) for the optimal predicted input
trajectory (u⋆
1 to the system.
Measure yt and set (uini, yini) in (11) to the most recent
Tini-length trajectory of the system. Update Ht by deleting
the ﬁrst column and adding the most recent Tini + Tf-length
trajectory as the last column. This process is repeated in
order to perform simultaneous data-driven mode recognition
and control.

Tf) and apply ut = u⋆

1, . . . , u⋆

The strategy above has been simulated with ǫ = 0.3
[0, 70]. We arbitrarily initialize

on system (10) for t

∈

5

6

4

2

0

0

10

20

30

40

50

60

70

2

1

0

0

10

20

30

40

50

60

70

Fig. 2. Performance of mode recognition and control strategy on the SARX
system with switches between modes compared to data-driven control
without mode recognition.

the predictive model D in (11) to be a matrix containing
sufﬁciently exciting data from mode 1. However, the system
starts in mode 2 and only switches to mode 1 at t = 40. The
strategy is compared to data-driven control without mode
recognition, i.e., where D is kept constant in (11). The results
are shown in Figures 2 and 3. We observe in Figure 2 that
the controlled output trajectory is offset from the desired
reference. This is due to the fact that we are using the wrong
data set in (11) for predicting optimal trajectories. However,
the L-gap between Dbasis and Ht,basis quickly increases above
the threshold ǫ, thus successfully recognizing a discrepancy
between the current mode of the system and the data being
used for control (see Figure 3). During this transient phase,
the moving window contains a mixture of data containing
trajectories from mode 2, and mode 1. However, at approx-
imately t = 22, the L-gap successfully recognizes that the
data matrix D used in (11) is consistent with the current
mode of the system (mode 2). The control performance after
this transient phase then improves. This is again illustrated
during the mode switch at t = 40. On the other hand, the
data-driven control strategy with no mode recognition does
not adapt to mode switches and has poor performance until
t = 40 where the system switches incidentally to mode 1
thus matching with the ﬁxed data matrix D being used in this
strategy. This case study suggests that the L-gap is a suitable
tool for data-driven online mode recognition and control.

V. CONCLUSION

This paper has explored the issue of uncertainty quan-
tiﬁcation in the behavioral setting. A new metric has been
deﬁned on the set of restricted behaviors and shown to
capture parametric uncertainty for the class of AR models.
The metric is a direct ﬁnite-time counterpart of the classical
gap metric. A data-driven control case study has illustrated
the value of the new metric through numerical simulations.
The paper has shown that the gap induces a metric space
structure on the set of restricted behaviors. However, there

1

0.8

0.6

0.4

0.2

0

0

10

20

30

40

50

60

70

Fig. 3. Distance computed with the L-gap between Ht,basis and Dbasis for
L = Tini + Tf.

are many other common metrics deﬁned on Grassmanni-
ans [34]. Table I recalls some of these metrics, as well as
formulae to compute them. The fact that all distances in
Table I depend on the principal angles is not a coincidence.
In fact, the geometry of the Grassmannian is such that any ro-
tationally invariant metric between k-dimensional subspaces
in RN (i.e., dependent only on the relative the position of
subspaces) is necessarily a function of the principal angles.

.

,

{

}

V

θi

Theorem 3.
invariant3 metric on Gr(k, N ). Then d(
of the principal angles

[30, Theorem 2] Let d be a rotationally
) is a function
and
y

V
i∈k between the subspaces

W

W
Each metric induces a particular geometry, which comes
with its own advantages and disadvantages. For example, the
Grassmann metric is the geodesic distance on Gr(k, N ) [30,
Theorem 2], viewed as a Riemannian (quotient) manifold
with metric gZ(V, W ) = trace((Z TZ)−1V TW ). The corre-
sponding geodesics admit an explicit expression [35], which
allows for a number of optimization-based problems to be
solved (e.g., regression [36]). This, in turn, suggests that
the choice of the metric structure on the set of restricted
behaviors is crucial, raising a number of important questions.
For instance, any metric on Gr(k, N ) that induces a differen-
tiable structure opens up the possibility of directly optimizing
over behaviors. So can one exploit any such structure to
improve the performance of data-driven control algorithms
(e.g., DeePC)? In practice, non-parametric representations
of restricted behaviors are typically constructed from noisy
measurements. This can be a serious drawback, because
noisy restricted behaviors may appear to be far apart, even
when close and/or of the same dimension. This issue may
be elegantly resolved by extending the metrics in Table I
to inﬁnite Grassmannians [30]. So can one leverage these
results in an online, real-time, noisy setting where behaviors
are constantly changing? We leave the exploration of these

3A metric d on Gr(k, N ) is rotationally invariant if

d(Q · V, Q · W) = d(V, W)

for all Q ∈ O(N ) and V, W ∈ Gr(k, N ) [30, p.1179], where the left
action of
the orthogonal group O(N ) on Gr(k, N ) is deﬁned as
Q · V = im(QV ) for Q ∈ O(N ) and V ∈ Gr(k, N ).

6

METRICS BETWEEN SUBSPACES V AND W IN Gr(k, N ) IN TERMS OF THE CORRESPONDING PRINCIPAL ANGLES {θi}i

k AND IN TERMS OF

MATRICES V AND W WHOSE COLUMNS ARE ORTHONORMAL BASES FOR V AND W , WITH V TW = U SZ T

A (FULL) SVD.

∈

TABLE I

Metric

Asimov

Binet-Cauchy

Chordal

Fubini-Study

Grassmann

Martin

Procrustes

Projection (gap)
Spectral

Principal angles
dα(V, W) = θk
dβ(V, W) =

1 −

dκ(V, W) =
(cid:16)P
dφ(V, W) = cos−

dγ (V, W) =

dµ(V, W) =

1/2

(cid:16)

k
i=1(cos θi)2
(cid:17)
1/2

Q

k
i=1(sin θi)2
(cid:17)
k
1
i=1(cos θi)
(cid:16)P
1/2
k
i=1 θ2
i
(cid:16)P
(cid:17)
k
i=1 1/(cos θi)2
log
(cid:16)Q
k
i=1(sin(θi/2))2

(cid:17)

(cid:17)(cid:17)
1/2

(cid:17)

(cid:16)
dρ(V, W) = 2
(cid:16)P
dπ(V, W) = sin θk
dσ(V, W) = 2 sin(θk/2)

Matrix representations

1

V V T − W W T
sin−
(cid:13)
1/2
1 − det(V TW )2
(cid:13)
(cid:0)
(cid:1)
V V T − W W T
1
√2
(cid:13)
1 | det V TW |
cos−
(cid:13)

(cid:13)
(cid:13)

F

2
(cid:13)
(cid:13)

1/2

1 Σ

cos−
F
(cid:13)
(cid:13)
(−2 log det V TW )1/2
(cid:13)
(cid:13)

kV U − W ZkF
V V T − W W T
kV U − W Zk2
(cid:13)
(cid:13)

2
(cid:13)
(cid:13)

important questions as future research directions.

APPENDIX

A. The principal angles

Let
For i
recursively, as the solution of the optimization problem

Gr(k, N ) and
Gr(l, N ). Let r = min(k, l).
the i-th principal vectors (pi, qi) are deﬁned,

V ∈
r,
∈

W ∈

maximize pTq
subject to p
q

≤

≤

θr

. . .

∈ V
∈ W

, pTp1 = . . . = pTpi−1 = 0,
, qTq1 = . . . = qTqi−1 = 0,

k2 = 1,
p
k
k2 = 1.
q
k
and
The principal angles between the subspaces
are deﬁned as θi = arccos(pT
r. Clearly,
i qi) for i
W
π
2 . Principal vectors and principal an-
θ1 ≤
0
gles may be easily computed using, e.g., the SVD [29]. Let
RN ×k and W
V
Gr(k, N )
∈
and an l-frame of
respectively. Let
V TW = U SZ T be a (full) SVD of the matrix V TW , i.e.
Rk×l with
, U
O(k), V
0.
S1 = diag(σ1, . . . , σr)
σr
The principal angles can be computed as θi = arccos(σi),
with i

O(l), S = block-diag(S1)
Rr×r, where σ1 ≥

RN ×l be a k-frame of
Gr(l, N ),

r. See [29] for further detail.

W ∈

∈
. . .

V ∈

≥

≤

≥

∈

∈

∈

∈

∈

V

∈

B. Proof of Theorem 2

The proof of the theorem requires some preliminary re-
sults. We ﬁrst establish a one-to-one correspondence between
RqL and the subspace of Rq-valued sequences with ﬁnitely
many non-zero elements, as well as additional elementary
results (omitting the proof of those that may be established
by direct computation).

Let (Rq)∞ be the space of Rq-valued sequences with

T

i.e., (Rq)∞ =
T

ﬁnitely many non-zero elements,
∈
(Rq)Z+ :
Z+ s.t. wt = 0,
N,
t
∃
∈
∀
(Rq)∞ be the inclusion map, deﬁned as
let ιL : RqL
ιL(w) = (w1, . . . , wL, 0, 0, . . .) . Then we have (Rq)∞ =
L=0 ιL(RqL). Thus, each image ιL(RqL) may be identi-
∈
RqL. Furthermore, the

ﬁed with RqL by identifying each (w1, . . . , wL, 0, 0, . . .)
S
(Rq)∞ with w = col (w1, . . . , wL)

{
. For L

→

≥

w

∈

∞

}

∈

7

subspace topology on ιL(RqL), the quotient topology in-
duced by the map ιL, and the Euclidean topology on RqL,
all coincide.

4. Let w

w

Lemma
k2 =
k
Lemma 5. Let

ιL(w)
k

.

kℓ2

RqL. Then

ιL(w)

∈

ℓq
2

∈

and
y

S

S

is

S

S ⊆

such that

sequence

supSL f

R be a continuous function. Assume

be a subset of a topological space and let f :
. . . is
L) then
y

S0 ⊆ S1 ⊆
S →
∞
a sequence of subsets of
cl (
L=0 S
supS f = limL→∞ supSL f, whenever the limit exists.
Proof. The
non-decreasing,
limL→∞ supSL f
by
assumption,
supS f
inequality, consider a sequence wL
f (wL)
such that f (w) > f (wL)
with

so
= supL∈Z+ supSL f. Furthermore,
so
L
reverse
such that
Z+ there is ǫL > 0
ǫL (wL),
ǫL (wL) an ǫL-neighborhood of wL. By assumption,
ǫL (wL) contains a point
supS f . This, in

for
∈
supL∈Z+ supSL f. To prove the

supS f . Then, for every L

∈
1/L for every w

L), so every

every L

∈ S

Z+,

N
cl (

∈ N

⊆ S

→

−

≥

S

N
kL . Thus, f ( ¯wL)
→
supL∈Z+ supSL f.

∈ S

∞
L=1 S
S ⊆
kL for some
¯wL
S
turn, implies supS f

S
≤
Z+, let ΠL : (Rq)
operator, deﬁned as [37, p.13]

Given L

∈

(Rq)Z+ be the truncation

→

ΠL(w) =

wt,
0,

(

[0, L

for t
∈
otherwise,

1]

∩

−

Z+,

with the convention that Π0(w) = w for all w

Lemma 6. Let

Lemma 7. Let

q. Then ιL(
B ∈ L
q
B ∈ L

ℓq
2. Then
∩
(Rq)∞ =

B

). Since

⊆

B ∩

Proof. (

∞

cl

L=0
[

ΠL(

B

)
!

= cl (

B ∩

= cl(

)

B

∩

(Rq)Z+ .

∈
).

B|

L) = ΠL(
B
∞
L=0 ΠL(

= cl (

y

)). y

B

∞
L=0 ΠL(
S

B

S
(Rq)∞)

cl(

)

⊆

B
(Rq)Z+ = cl(
B

), we have

cl ((Rq)∞)

∩

) =

,

B

where we have used (Rq)Z+ = cl ((Rq)∞) [38, p151] and
the completeness of

.

B

 
∞
L=0 ΠL(

(

∈

⊇

cl (

∈ B

). Let w

and recall that w

)) if
and only if w is the limit of some sequence of points
). Consider the sequence ¯wL = ΠL(w) for
in
). Furthermore, since
L

∞
L=0 ΠL(
B
Z+. Clearly, ¯wL
∈
S
ℓq
q
2, ¯wL
B ∈ L
Proof of Theorem 2. By assumption, P and ˜P are bounded
linear operators, so gapℓ2 (P, ˜P ) is well-deﬁned. Then

w, as desired.
S

∞
L=0 ΠL(

→

S

∩

∈

B

B

lim
L→∞

⇀
gapL(

B

, ˜
)
B

(4)
= lim
L→∞

(3)
= lim
L→∞

= lim
L→∞

⇀
gap(

B|

L, ˜
B|

L)

sup
w∈B|L
kwk2 =1
sup
w∈ιL (B|L )

kwkℓ

=1

2

inf
˜w∈ ˜B|L k

w

˜w

k2

−

inf
˜w∈ιL( ˜B|L) k

w

−

˜w

kℓ2

= lim
L→∞

sup
w∈ΠL (B))
kwkℓ
=1

2

inf
˜w∈ΠL( ˜B) k

w

−

˜w

kℓ2

sup
w∈ΠL (B))
kwkℓ
=1

2
inf
˜w∈ ˜B k

lim
L→∞

≤

= sup
w∈B

=1

2

kwkℓ
⇀

inf
˜w∈ ˜B k

w

−

˜w

kℓ2

w

˜w

kℓ2

−

=

(12)

gapℓ2(P, ˜P ),
where the third identity is a consequence of Lemma 4, the
fourth identity follows from Lemma 6, the ﬁfth inequality
is implied by inf ˜w∈ΠL( ˜B) k
w
),
for w
B
Lemma 5, and the last
= graphℓ2 (P ) and
since
Finally, the function (x, y)

kℓ2
kℓ2 ≤
the sixth equality is a consequence of
identity holds by Deﬁnition 9,
= graphℓ2( ˜P ), by assumption.
max(x, y) is continuous, thus

inf ˜w∈ ˜B k

ΠL(

−

−

w

˜w

˜w

∈

B

B
7→
max
{

⇀
gapL(

B
gapℓ2 (P, ˜P ),

⇀

⇀

, ˜
gapL( ˜
),
,
B
B
⇀
gapℓ2( ˜P , P )
}

)
}

B

(12)

max

≤
{
= gapℓ2 ( ˜P , P ).

lim
L→∞

gapL(

B

, ˜
B

) = lim
L→∞

REFERENCES

[1] L. Ljung, System identiﬁcation - Theory for the user (2nd edition).

Upper Saddle River, NJ, USA: Prentice-Hall, 1999.

[2] P. Van Overschee and B. De Moor, Subspace identiﬁcation for linear
Dordrecht, The

systems: theory - implementation - applications.
Netherlands: Kluwer, 1996.

[3] J. C. Willems, P. Rapisarda, I. Markovsky, and B. L. M. De Moor, “A
note on persistency of excitation,” Syst. Control Lett., vol. 54, no. 4,
pp. 325–329, 2005.

[4] J. C. Willems, “From time series to linear system—Part I. Finite
dimensional linear time invariant systems,” Automatica, vol. 22, no. 5,
pp. 561–580, 1986.

[5] J. C. Willems and J. W. Polderman, Introduction to mathematical
New York, NY, USA:

systems theory: a behavioral approach.
Springer, 1997.

[6] J. Coulson, J. Lygeros, and F. D¨orﬂer, “Data-enabled predictive control:
In the shallows of the deepc,” in Proc. Eur. Control Conf., Naples, Italy,
2019, pp. 307–312.

[7] C. De Persis and P. Tesi, “Formulas for data-driven control: Stabiliza-
tion, optimality, and robustness,” IEEE Trans. Autom. Control, vol. 65,
no. 3, pp. 909–924, 2019.

[8] H. J. van Waarde, J. Eising, H. L. Trentelman, and M. K. Camlibel,
“Data informativity: a new perspective on data-driven analysis and
control,” IEEE Transactions on Automatic Control, vol. 65, no. 11, pp.
4753–4768, 2020.

8

[9] I. Markovsky and F. D¨orﬂer, “Behavioral systems theory in data-driven
analysis, signal processing, and control,” Ann. Rev. Control, vol. 52,
pp. 42–64, 2021.

[10] J. Coulson, J. Lygeros, and F. D¨orﬂer, “Distributionally robust chance
constrained data-enabled predictive control,” IEEE Trans. Autom. Con-
trol, 2021.

[11] P. G. Carlet, A. Favato, S. Bolognani, and F. D¨orﬂer, “Data-driven
predictive current control for synchronous motor drives,” in IEEE
Energy Conversion Congress and Exposition, Detroit, MI, USA, 2020,
pp. 5148–5154.

[12] L. Huang, J. Coulson, J. Lygeros, and F. D¨orﬂer, “Data-enabled
predictive control for grid-connected power converters,” in Proc. 58th
Conf. Decision Control, Naples, Italy, 2019, pp. 8130–8135.

[13] J. Berberich, A. Koch, C. W. Scherer, and F. Allg¨ower, “Robust data-
driven state-feedback design,” in Proc. Amer. Control Conf., Denver,
CO, USA, 2020, pp. 1532–1538.

[14] H. J. van Waarde, M. K. Camlibel, and M. Mesbahi, “From noisy
data to feedback controllers: Nonconservative design via a matrix S-
lemma,” IEEE Transactions on Automatic Control, vol. 67, no. 1, pp.
162–175, 2022.

[15] A. Xue and N. Matni, “Data-driven system level synthesis,” in Learn-

ing for Dynamics and Control. PMLR, 2021, pp. 189–200.

[16] A. Bisofﬁ, C. De Persis, and P. Tesi, “Data-driven control via Pe-

tersen’s lemma,” arXiv:2109.12175, 2021.

[17] L. Huang, J. Zhen, J. Lygeros, and F. D¨orﬂer, “Robust data-enabled
predictive control: Tractable formulations and performance guaran-
tees,” arXiv preprint arXiv:2105.07199, 2021.

[18] G. Zames and A. El-Sakkary, “Uncertainty in unstable systems: The
gap metric,” in Proc. 8th IFAC World Congr., vol. 14, no. 2, 1981, pp.
149–152.

[19] J. R. Partington, Linear operators and linear systems: an analytical
Cambridge, U. K.: Cambridge Univ.

approach to control theory.
Press, 2004.

[20] K. Zhou, J. C. Doyle, and K. Glover, Robust and optimal control.

New Jersey, NJ, USA: Prentice Hall, 1996.

[21] G. Vinnicombe, Uncertainty and feedback: H

loop-shaping and the

ν-gap metric. London, U.K.: Imperial College Press, 2001.

∞

[22] F. Dorﬂer, J. Coulson, and I. Markovsky, “Bridging direct & indirect
data-driven control formulations via regularizations and relaxations,”
IEEE Trans. Autom. Control, 2022.

[23] K. J.

˚Astr¨om and B. Wittenmark, Adaptive control (2nd edition).

Reading, MA, USA: Addison-Wesley, 1995.

[24] I. Markovsky and F. D¨orﬂer, “Identiﬁability in the behavioral setting,”
Vrije Universiteit Brussel, Tech. Rep, 2020.
[Online]. Available:
http://homepages.vub.ac.be/∼imarkovs/publications/identiﬁability.pdf.
[25] W. M. Boothby, An introduction to differentiable manifolds and
Riemannian geometry (2nd Edition). London, U. K.: Academic Press,
1986.

[26] N. L. Carothers, Real analysis. Cambridge, U. K.: Cambridge Univ.

Press, 2000.

[27] T. Kato, Perturbation theory for linear operators (2nd Edition). New

York, NY, USA: Springer, 1980.

[28] G. Stewart and J. Sun, Matrix Perturbation Theory. New York, NY,

USA: Academic Press, 1990.

[29] G. H. Golub and C. F. Van Loan, Matrix computations (4th Ed.).

Baltimore, MD, USA: Johns Hopkins Univ. Press, 2013.

[30] K. Ye and L. H. Lim, “Schubert varieties and distances between
subspaces of different dimensions,” SIAM J. Mat. Anal. Appl., vol. 37,
no. 3, pp. 1176–1197, 2016.

[31] L. Qui and E. J. Davison, “Pointwise gap metrics on transfer matrices,”
IEEE Trans. Autom. Control, vol. 37, no. 6, pp. 741–758, 1992.
[32] T. Koenings, M. Krueger, H. Luo, and S. X. Ding, “A data-driven
computation method for the gap metric and the optimal stability
margin,” IEEE Trans. Autom. Control, vol. 63, no. 3, pp. 805–810,
2017.

[33] Z. Du, L. Balzano, and N. Ozay, “A robust algorithm for online
switched system identiﬁcation,” IFAC-PapersOnLine, vol. 51, no. 15,
pp. 293–298, 2018.

[34] M. M. Deza and E. Deza, Encyclopedia of distances. New York, NY,

USA: Springer, 2009.

[35] P. A. Absil, R. Mahony, and R. Sepulchre, Optimization algorithms on
matrix manifolds. Princeton, NJ, USA: Princeton Univ. Press, 2009.
[36] Y. Hong, R. Kwitt, N. Singh, B. Davis, N. Vasconcelos, and M. Ni-
ethammer, “Geodesic regression on the grassmannian,” in Eur. Conf.
Comp. Vision. Springer, 2014, pp. 632–646.

[37] J. C. Willems, The analysis of feedback systems. London, U. K.: MIT

Press, 1971.

[38] J. R. Munkres, Topology (2nd Edition). Upper Saddle River, NJ,

USA: Prentice Hall, 2000.

9

