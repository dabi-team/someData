Differentiable Control Barrier Functions for
Vision-based End-to-End Autonomous Driving
Wei Xiao∗, Tsun-Hsuan Wang∗, Makram Chahine, Alexander Amini, Ramin Hasani and Daniela Rus

1

2
2
0
2

r
a

M
4

]

O
R
.
s
c
[

1
v
1
0
4
2
0
.
3
0
2
2
:
v
i
X
r
a

Abstract—Guaranteeing safety of perception-based learning
systems is challenging due to the absence of ground-truth state
information unlike in state-aware control scenarios. In this paper,
we introduce a safety guaranteed learning framework for vision-
based end-to-end autonomous driving. To this end, we design
a learning system equipped with differentiable control barrier
functions (dCBFs) that is trained end-to-end by gradient de-
scent. Our models are composed of conventional neural network
architectures and dCBFs. They are interpretable at scale, achieve
great test performance under limited training data, and are
safety guaranteed in a series of autonomous driving scenarios
such as lane keeping and obstacle avoidance. We evaluated
our framework in a sim-to-real environment, and tested on a
real autonomous car, achieving safe lane following and obstacle
avoidance via Augmented Reality (AR) and real parked vehicles.

I. INTRODUCTION

Neural networks are powerful tools for learning relevant
representations in complex scenarios. However, applying such
learning systems in decision and control problems such as
autonomous driving is signiﬁcantly hindered by the absence
of safety assurance. This is due to the learning systems
being a black box that makes it complex to perform root
cause analysis. Thus, a single mistake made by a learned
neural controller can potentially lead to catastrophic outcomes.
Ensuring safety (e.g., providing guarantees that a self-driving
car will never collide with obstacles) of a learning system is
therefore very important. Nevertheless, as the dimensionality
of the observations and action space for a real-world problem
increases, deﬁning safety criteria and guarantees for learning
systems increases dramatically. Take for instance a vision-
based autonomous driving algorithm; even identifying the
contributions of every single pixel to making driving decisions
in every scenario is computationally intractable. In this case,
how can we ensure the safety of the learning system?

In this paper we leverage theoretical results in differentiable
control barrier functions (dCBF) to equip end-to-end vision-
based learning systems with safety guarantees. Barrier func-
tions (BFs) have been widely used in optimization formula-
tions to guarantee the satisfaction of some constraints [26],
and have recently been extended to Lyapunov-like functions
[42, 47]. They have been employed to prove set invariance
[7, 38, 48] and regulate multi-objective control [33]. Control
Barrier Functions (CBFs) are extensions of BFs for control
systems, and are used to map a constraint deﬁned over system

∗The authors are with equal contributions.
The authors are with the Computer Science and Artiﬁcial Intelligence Lab,
Massachusetts Institute of Technology {weixy, tsunw, chahine,
amini, rhasani, rus}@mit.edu

Fig. 1: Vision-based end-to-end autonomous driving with dif-
ferentiable CBFs in a BarrierNet. Lane keeping and collision
avoidance are guaranteed.

states onto a constraint on the control input [1]. The satis-
faction of the control constraint thus implies the satisfaction
of the original safety constraint. Recently, it has been shown
that by optimizing a quadratic cost and satisfying state and
control constraints, CBFs can be used to form quadratic
programs (QPs) [32], [1], [45] which can be solved in real
time. Prior work also introduced differentiable CBFs as novel
CBF formulations whose parameters are trainable [51], [34].
They have been incorporated into differentiable QPs [5] which
can in turn be combined with learning systems [53].

dCBFs are introduced to mitigate the conservativeness of
CBFs for safety guarantees. In CBFs, a system tends to
stay far away from the unsafe set boundary, and thus may
deviate largely from a desired trajectory. A BarrierNet [53]
is constructed by incorporating dCBFs into a differentiable
QP. In a BarrierNet, all QP parameters, including those origi-
nating in CBFs, are trainable. Thus, we obtain a ubiquitous
safety guaranteed barrier layer that can be combined with
any learning system [24, 23, 44, 29, 21, 27, 20]. BarrierNet
addresses the conservativeness of CBFs and allows the safety
constraints of a neural controller to be adaptable to changing
environments.

SimulationSim-to-RealRealFront view imageAcceleration Steering rateNeural Nets + Differentiable CBFs with safety guaranteesAn End-to-End Learning System with a BarrierNetSafe lane-keeping & obstacle avoidance 
 
 
 
 
 
Although BarrierNets show promise in guaranteeing safety
for shallow neural controllers, they have not been studied
in the context of high-dimensional observation spaces such
as vision-based control. In this paper, we investigate the
effectiveness and conditions for using BarrierNets in end-to-
end vision-based autonomous driving scenarios (see Fig. 1).
In this example, a neural network receives a camera input
stream and outputs acceleration and steering rate commands to
navigate the vehicle along the center of the driving lane, while
avoiding obstacles. The system and environment observations
are inputs to the upstream network whose outputs serve as
arguments to the BarrierNet layer. Finally, BarrierNet outputs
the controls that guarantee collision avoidance.
Contributions: (i) We present a new end-to-end learning
pipeline composed of conventional deep learning models and
BarrierNets for vision-based end-to-end autonomous driving
to achieve safe maneuvering. (ii) Our algorithm is multi-
level
interpretable and can achieve good test performance
under limited training data. (iii) We design a vision-based
state estimation module within our pipeline and study how
BarrierNet works in the absence of ground truth information
(iv) We train and verify our proposed framework in a sim-
to-real environment; we also deploy our model on a full-
scale autonomous vehicle for safe lane following and obstacle-
avoidance via Augmented Reality (AR) and physically parked
vehicles.

II. RELATED WORK

Safety-critical control and learning. A large body of work
studied CBF-based safety guarantees [1, 32, 45, 12, 41].
Many existing works [1, 32, 57] combine CBFs for systems
with quadratic costs to form optimization problems. Time is
discretized and an optimization problem with constraints given
by the CBFs is solved at each time step. Replacing CBFs
by High Order Control Barrie Functions (HOCBFs) allows us
to handle constraints with arbitrary relative degree [50]. The
common observation is that CBFs tend to make the system’s
behavior excessively conservative if they are not properly
deﬁned. This conservativeness is usually characterized by
how close the system state can (but not necessarily) stay to
the unsafe set boundary or a desired reference trajectory in
obstacle-clustered environment.

In order to address the conservativeness of the CBF method,
the work in [51] proposed to parameterize the deﬁnition
of CBFs, and use machine learning methods to learn CBF
parameters for a certain type of unsafe sets such that safety
is guaranteed without control being excessively conservative.
This form of CBFs is differentiable. In [34] learning CBF
parameters using a differential policy over a time horizon is
proposed. Adaptive CBFs (AdaCBFs) [52] allow for time-
varying CBF parameters. It has been shown that the satis-
faction of the AdaCBF constraint is a necessary and sufﬁcient
condition for the satisfaction of the original safety constraint.
All these related works require the design of proper policies
and models, which is tedious and non-trivial. In contrast, we
propose to use an end-to-end differentiable framework to learn
neural network controllers for safety-critical systems.

2

At the intersection of CBFs and learning, supervised learn-
ing techniques have been proposed to learn safe set deﬁnitions
from demonstrations [39] which can be then enforced by
CBFs. The authors in [41] used data to learn system dynamics
for CBFs. In [56], neural network controllers are trained using
CBFs in the presence of disturbances. These prior works focus
on learning safe sets and dynamics, whereas we focus on the
design of environment dependent and trainable CBFs.
Differentiable optimization-based safety frameworks. Re-
cent advances in differentiable optimization methods show
promise for safety guaranteed neural network controllers
[5, 36, 6, 53]. In [5], a differentiable quadratic program (QP)
layer, called OptNet, was introduced. OptNet with CBFs has
been used in neural networks as a ﬁlter for safe controls
[36], but OptNet is not trainable, thus, potentially limiting
the system’s learning performance. In [14, 25, 59, 16, 17],
safety guaranteed neural network controllers have been learned
through veriﬁcation-in-the-loop training. A safe neural net-
work ﬁlter has been proposed in [15] for a speciﬁc vehicle
model using veriﬁcation methods. The veriﬁcation approaches
cannot ensure coverage of the entire state space. They are
ofﬂine methods, unable to adapt to environment changes (such
as varying size of the unsafe sets) [31]. By comparison,
the BarrierNet in [53] incorporates differentiable CBFs into
neural network controllers. In this work, we address the
challenges of using BarrierNet to achieve vision-based end-
to-end autonomous driving.
Sim-to-real end-to-end autonomous driving. Many works
have demonstrated the ability to learn end-to-end (perception-
to-control) driving policies directly from real-world perception
data using imitation learning (IL) [37, 9]. Such approaches
have been demonstrated to be successfully deployed in both
real-world ofﬂine passive datasets [55, 43, 2] as well as real
closed-loop control test environments [35, 13, 29, 22].

However, these works have focused on “reactive” scenarios
such as lane-keeping [9, 55, 43], lane-changing [10], and
navigation [35, 13, 2, 22], but
lack the ability to plan a
path around other objects in the scene due to signiﬁcantly
larger data requirements of IL to achieve sufﬁcient coverage
of the testing distribution. Simulation has emerged as a viable
candidate to overcome this challenge and render a continuum
of scenarios for learning in the presence of other objects and
agents in the environment. Works that learn object avoidance
in simulation have leveraged both imitation learning [54]
as well as reinforcement learning [8, 28, 11, 58, 19] but
often face limited to no deployment capabilities in reality due
to large sim-to-real gaps present in model-based simulation.
In this work, we leverage recent advances in data-driven
simulation [3, 30, 46, 4] to overcome the sim-to-real gap to
learn robust end-to-end controllers capable of transferring to
real scenarios with other agents.

III. BACKGROUND

In this section, we brieﬂy introduce control barrier functions
(CBF) and refer interested readers to [1] for detailed for-
mulations. Intuitively, CBFs are a means to translate state
constraints to control constraints under afﬁne dynamics. The

3

controls that satisfy those constraints can be efﬁciently solved
for by formulating a quadratic program. We start with the
deﬁnition of class K functions.

Deﬁnition 1: (Class K function [26]) A continuous func-
tion α : [0, a) → [0, ∞), a > 0 is said to belong to class K if
it is strictly increasing and α(0) = 0. A continuous function
β : R → R is said to belong to extended class K if it is strictly
increasing and β(0) = 0.
Consider an afﬁne control system of the form

x(0) ∈ C1∩, . . . , ∩Cm, then any Lipschitz continuous con-
troller u(t) that satisﬁes the constraint in (4), ∀t ≥ 0 renders
C1∩, . . . , ∩Cm forward invariant for system (1).
Combining CBFs with a quadratic cost (cid:82) tf
t0

uT (t)Hu(t),
where H is positive deﬁnite, we can formulate CBF-based
QPs:

u(t)T Hu(t)

(6)

u∗(t) = arg min
u(t)

s.t.

1
2

˙x = f (x) + g(x)u

(1)

f b(x) + [LgLm−1
Lm

f

b(x)]u+O(b(x)) + αm(ψm−1(x)) ≥ 0

where x ∈ Rn, f : Rn → Rn and g : Rn → Rn×q are
locally Lipschitz, and u ∈ U ⊂ Rq, where U denotes a control
constraint set.

Deﬁnition 2: A set C ⊂ Rn is forward invariant for system
(1) if its solutions for some u ∈ U starting at any x(0) ∈ C
satisfy x(t) ∈ C, ∀t ≥ 0.

Deﬁnition 3: (Relative degree) The relative degree of a
(sufﬁciently many times) differentiable function b : Rn → R
with respect to system (1) is the number of times it needs to be
differentiated along its dynamics until the control u explicitly
shows in the corresponding derivative.
Since function b is used to deﬁne a (safety) constraint b(x) ≥
0, we will also refer to the relative degree of b as the relative
degree of the constraint. For a constraint b(x) ≥ 0 with relative
degree m, b : Rn → R, and ψ0(x) := b(x), we deﬁne a
sequence of functions ψi : Rn → R, i ∈ {1, . . . , m}:

ψi(x) := ˙ψi−1(x) + αi(ψi−1(x)),

i ∈ {1, . . . , m},

(2)

where αi(·), i ∈ {1, . . . , m} denotes a (m − i)th order
differentiable class K function.

We further deﬁne a sequence of sets Ci, i ∈ {1, . . . , m}

associated with (2) in the form:

Ci := {x ∈ Rn : ψi−1(x) ≥ 0},

i ∈ {1, . . . , m}.

(3)

Deﬁnition 4: (High Order Control Barrier Function
(HOCBF)
[50]) Let C1, . . . , Cm be deﬁned by (3) and
ψ1(x), . . . , ψm(x) be deﬁned by (2). A function b : Rn → R
is a High Order Control Barrier Function (HOCBF) of relative
degree m for system (1) if there exist (m − i)th order
differentiable class K functions αi, i ∈ {1, . . . , m − 1} and
a class K function αm such that

sup
u∈U

(cid:104)
f b(x) + [LgLm−1
Lm

f

b(x)]u + O(b(x))

+αm(ψm−1(x))

(cid:105)

≥ 0,

(4)

for all x ∈ C1∩, . . . , ∩Cm. In (4), Lm
(Lg) denotes Lie
f
derivatives along f (g) m (one) times, and O(b(x)) =
(cid:80)m−1
i=1 Li
f (αm−i ◦ ψm−i−1)(x). Further, b(x) is such that
LgLm−1
b(x) (cid:54)= 0 on the boundary of the set C1∩, . . . , ∩Cm.
f
Note that by setting m = 1 in a HOCBF, we can get a

relative-degree-one CBF constraint:

Lf b(x) + Lgb(x) + α1(b(x)) ≥ 0.

(5)

Theorem 1: ([50]) Given a HOCBF b(x) from Def. 4
if

with the associated sets C1, . . . , Cm deﬁned by (3),

u ∈ U,

t = k∆t + t0,

IV. PROBLEM FORMULATION

We now formally deﬁne learning of safety-critical control for
autonomous driving.

Problem 1: Given (i) front-view RGB camera images of
the vehicle, (ii) a nominal controller k(cid:63)(x) = u(cid:63) (such as a
model predictive controller) (iii) vehicle dynamics in the form
of (1), (iv) a set of safety constraints bj(x) ≥ 0, j ∈ S (where
bj is continuously differentiable). Typical safety constraints
include obstacle avoidance and lane keeping. (v) control
bounds umin ≤ u ≤ umax of the vehicle, and (vi) a neural
network controller k(x|θ) = u parameterized by θ, our goal
is to take (i) as input and ﬁnd the optimal parameters

θ(cid:63) = arg min

θ

Ex[l(k(cid:63)(x), k(x|θ))]

(7)

while guaranteeing the satisfaction of the safety constraints
in (iv) and control bounds in (v). E(·) is the expectation and
l(·, ·) denotes a similarity measure. Note that state estimation
required in (iii) and (iv) is implicitly done in the neural
network by inferring from the vision inputs (i).

V. SAFETY-AWARE DIFFERENTIABLE FRAMEWORK

In this section, we propose a safety-guaranteed neural
network controller for vision-based end-to-end autonomous
driving based on BarrierNet. We ﬁrst study where the two
”ends” should be deﬁned in this framework in order to learn
a good model based on limited data.

A. Interpretable End-to-End Design

System’s Inputs Setup. In human-driving, the majority of the
information human drivers rely on comes from the front vision
view. Therefore, we let the input of the end-to-end architecture
be front view images, which contain enough information for
executing safe driving.
System’s Outputs Setup At the output end, where BarrierNet
is implemented, high-relative-degree control variables (such
as acceleration, jerk, steering rate or steering acceleration)
are generated for driving the vehicle. The ﬁrst advantage
of using high-relative-degree control variables is to ensure
the smoothness of the vehicle states (such as speed), which
ensure the vehicle is maneuvered in a smooth manner so that
passenger comfort is met. Another advantage is to ensure
the controller works with accurate maneuvering due to the

4

B. Differentiable Control Barrier Functions

In this subsection, we brieﬂy introduce BarrierNet [53] that
incorporates differentiable CBFs, and propose solutions for
some of the challenges that arise in autonomous driving with
BarrierNet.
Differentiable CBFs are motivated by the fact that the tradi-
tional CBFs can easily make the system overly conservative.
In order to address this conservativeness, we multiply the class
K functions in (2) in the deﬁnition of a HOCBF with some
observation-dependent functions pi(z), i ∈ {1, . . . , m}:
ψi(x, z) := ˙ψi−1(x, z) + pi(z)αi(ψi−1(x, z)),
i ∈ {1, . . . , m},

(8)

where ψ0(x, z) = b(x) and z ∈ Rd is the input (such as front
view images in autonomous driving) of the neural network
(d ∈ N is the dimension of the features), pi : Rd → R>0, i ∈
{1, . . . , m} are the outputs of the previous layer, where R>0
denotes the set of positive scalars. The above formulation is
similar to that of AdaCBF [52], but, contrary to the latter, is
trainable and does not require the design of auxiliary dynamics
for pi (a non-trivial process). To ensure the validity of the
above deﬁned CBFs, we require that each pi be continuously
differentiable. Then, we have a differentiable HOCBF as in
Def. 4 in the form:

f b(x) + [LgLm−1
Lm

f

b(x)]u+O(b(x), z)

+pm(z)αm(ψm−1(x, z)) ≥ 0,

(9)

Note that it is possible to add additional training parameters
to the above class K functions. For example, we may take
the powers as training parameters if the class K functions are
power functions. However, this may decrease the stability of
the system as the values of the class K functions are more
sensitive to powers than to coefﬁcients.
BarrierNet. Eventually, we can incorporate the above softened
HOCBFs into differentiable QPs, and obtain a BarrierNet:

u∗(t) = arg min
u(t)

1
2

s.t.

u(t)T H(z|θh)u(t) + F T (z|θf )u(t) (10)

f bj(x) + [LgLm−1
Lm
+pm(z|θm

bj(x)]u+O(bj(x), z|θp)
p )αm(ψm−1(x, z|θp)) ≥ 0, j ∈ S

f

(11)

umin ≤ u ≤ umax,

p, . . . , θm

t = k∆t + t0,
where F (z|θf ) ∈ Rq could be interpreted as a reference
control (can be the output of previous network layers) and
θh, θf , θp = (θ1
p ) are trainable parameters. S denotes
a set of safety constraints including obstacle avoidance and
lane keeping. The above differentiable QPs formulate a neuron
in BarrierNet. We let both H(z|θh) and F (z|θf ) be parame-
terized and dependent on the network input z, but H and F
can also be directly trainable parameters that do not depend
on the previous layer (i.e., we have H and F ). The same
applies to pi, i ∈ {1, . . . , m}. The trainable parameters are
θ = {θh, θf , θp} (or θ = {H, F, pi, ∀i ∈ {1, . . . , m}} if H, F
and pi do not depend on the previous layer). The solution u∗ is

Fig. 2: Multi-level interpretable end-to-end autonomous driv-
ing framework with differentiable CBFs. The entire pipeline
is end-to-end differentiable. Each depth of the model learns
different vehicle and environment information. The outputs of
BarrierNet are high-relative-degree controls.

physical inertia of the vehicle. If we take vehicle speed as
one of the controls, and the controller requires the speed
to suddenly change to a large different value, the vehicle
powertrain system will fail to respond. In this case the vehicle
control becomes inaccurate, affecting the performance and
even the safety of the vehicle.

The main challenge in an end-to-end autonomous driving
with high-relative-degree control variables is that it requires a
very large training data set with high diversity. This is because
more vehicle state variables are involved in higher-relative-
degree controls, and thus, the vehicle may have different states
under the same observation. This will cause confusion in the
training process. If the training dataset is not large and diverse
enough, the poor generalization of the trained controller (from
open-loop to closed-loop, or from sim-to-real) would make the
controller fail to achieve its task. Thus, we propose a multi-
level interpretable model under limited training data set as
shown next.

Setting up an interpretable framework. In order to make the
model interpretable, we take training loss outputs at different
depths of the model. Following the CNN or LSTM, we may
take part of the neurons as the loss outputs for the locations
of the vehicle itself and the obstacles. This way, we train
neurons at this level to learn position information. In a deeper
setting, we may take part of the neurons as another loss
outputs for the speed and steering angle of the vehicle, training
these neurons to learn speed and steering angle information.
By adding derivative layers following these neurons, we get
acceleration and steering rate information of the vehicle. The
acceleration and steering rate could be taken as reference
controls in the BarrierNet which is also trainable, and we take
the output of the BarrierNet as the ﬁnal loss output in the
training process. In this framework, different depths of neurons
learn different vehicle information, which makes the whole
structure consistent with the vehicle physical dynamics. This
architecture ensures the neural network model is interpretable
[18]. We present the whole model structure in Fig. 2.

LSTMCNNPositions (loss 1)DerivativeMLPMLPBarrierNetSpeed and steering angle (loss 2)ControlsFront view imagesAcc. and steering rate (loss 3)dCBFsthe output of the neuron. The BarrierNet layer is differentiable
with respect to its parameters [5].
Safety with an unknown number of constraints. One of the
challenges in autonomous driving with BarrierNet is that we
have to deﬁne the exact number of the HOCBFs when design-
ing the BarrierNet layer as it connects with previous layers.
However, a vehicle may encounter time-varying number of
obstacles (constraints) in a complex environment. In order to
address this problem, we proceed as follows.

Fig. 3: Large disk covering approach for obstacle avoidance.
Collision can be avoided if the center of the vehicle never
enters the disks (for a correct design of disk locations and
sizes). Sorted disks are used to cover corresponding sorted
obstacles as they present themselves.

Suppose N ∈ N denotes the maximum number of obstacles
(such as other vehicles) a vehicle may encounter in driving.
We cover each of the obstacles with an off-the-center disk, as
shown in Fig. 3. The deviation direction of the disk depends on
the direction of the obstacle with respect to the lane center.
In this manner, we may use large disks to cover obstacles
while making sure that the ego vehicle will not be overly
conservative in driving through. We may use multiple small
disks to cover a single obstacle. However, this increases the
number of safety constraints required. Another advantage of
using a large off-the-center disks is to ensure the smoothness of
the vehicle trajectory and to avoid getting stuck in local traps
that may appear with small disks. In this setting, we only have
N safety constraints, one for each obstacle. We sort them in
a speciﬁc order in the connection with the previous layer, and
enforce them using the above differentiable HOCBFs.

When there are no actual obstacles on the road, as in the
case depicted on the left-hand side of Fig. 3, we just move the
covering disks off the road in which case they play the role of
lane keeping. These disks move along the road as the vehicle
progresses at the same speed. While the vehicle drives on the
road, these disks do not affect its motion as the corresponding
HOCBF constraints are not activated. However, if the vehicle
is about to leave the road, these constraints can prevent it from
doing so due to the safety guarantees of HOCBFs.

When there is one or more obstacles on the road, as in
the case depicted on the right-hand side of Fig. 3, we ﬁrst
sort the obstacles according to their distance with respect to
the ego vehicle. Then, we use the sorted disks to cover the
corresponding sorted obstacles. The sorted covering approach
can make sure that vehicle may leave the road in order

5

to avoid collision with obstacles. In this setting, although
we may have redundant differentiable HOCBFs in terms of
obstacle avoidance, these HOCBFs always play an important
role in guiding the vehicle, either in lane keeping or obstacle
avoidance.
Tackling potential conﬂicts of HOCBF constraints and
control bounds. Another challenge for BarrierNet is that the
differentiable QPs can easily become infeasible to solve during
training due to the possible conﬂict between the HOCBF
constraints and the control bounds. In order to address this,
we need to require that the nominal control provides control
labels that strictly satisfy the safety constraints and control
bounds. Then, during training in the BarrierNet layer, we
can relax/remove control bounds. After the neural network
converges, the differentiable QPs would be feasible when we
add control bounds in the testing or implementation. However,
there is still possibility that the QP could be infeasible as the
BarrierNet may have some inputs that it has never seen before.
In order to address this, we can ﬁnd sufﬁcient conditions of
feasibility, as shown in [49]. Brieﬂy, this approach ﬁnds a
feasibility constraint on the state of system and the penalties
pi(z), i ∈ {1, . . . , m}, and then enforces this feasibility
constraint using another CBF.

VI. EXPERIMENTS

In this section, we show experiments with the proposed
vision-based end-to-end autonomous driving framework in
both sim-to-real environments and a full-scale autonomous
vehicle. We start by introducing the hardware platform and
data collection, followed by implementation details of the
proposed model. We then demonstrate extensive analysis in
the sim-to-real environment VISTA [4]. Finally, we showcase
results with real-car deployment.

A. Hardware Setup and Real-world Data Collection

We deploy our models onboard a full-scale autonomous
vehicle (2019 Lexus RX 450H) equipped with a NVIDIA
2080Ti GPU and an AMD Ryzen 7 3800X 8-Core Processor.
We use a RGB camera BFS-PGE-23S3C-CS as the primary
perception sensor, which runs in 30Hz, with a resolution of
960×600, and has 130◦ horizontal ﬁeld-of-view. Other on-
board sensors include inertial measurement sensor (IMUs) and
wheel encoders to measure steering feedback and odometry.
Also, we use a differential global positioning system (dGPS)
for evaluation purpose. To run the data-driven simulation
VISTA [4], we collect real-world data from a wide-range
time of day, weather
of environments,
conditions, and seasons of a year. The entire dataset consists
of roughly 2 hour of driving data, which is further augmented
with our training dataset generation pipeline using VISTA.

including different

B. Synthetic Training Dataset Generation

We train our model with guided policy learning, which has
been shown to improve effectiveness for direct model transfer
to real-car deployment. The data generation process follows
(a) in VISTA, randomly initializing both ego- and ado-car

Disks1234………N-1N………1234………………N-1NEgoEgoNo obstacleTwo obstacles6

Fig. 5: Lane following probabilistic comparisons of deviation
from the lane center in a BarrierNet with/without lane keeping
CBFs.

Implementation Details. Based on the aforementioned gen-
eral framework in Sec. V-B, we speciﬁcally deﬁne dCBFs for
lane following as blef t
lf = dlf −d and bright
lf = dlf +d (besides
the disk covering lane following approach shown in the left
case of Fig. 3 as we only study single obstacle avoidance),
and for obstacle avoidance as bobs = ∆s2 + (d − dobs)2 − r2
D,
where dlf is a preset bound, ∆s is relative progress between
ego-car and obstacle, rD is disk size, and dobs is the lateral
displacement from lane center of the obstacle. We compute Lie
derivative to construct dCBF constraints in QP with vehicle dy-
namics mentioned above. Overall, the model takes in a front-
view image, infers speed v and steering angle δ to compute
reference control with derivative and state (d, dobs, µ, ∆s),
predicts dCBFs parameters, and obtains ﬁnal control (a, ω)
by solving QP with dCBFs. The learning supervision in-
cludes Mean Squared Error loss on v, δ, d, dobs, µ, ∆s, a, ω.
We bound the derivative of v, δ (reference control) to stabilize
learning. We cap loss on ∆s, dobs when the obstacle is absent
or too far away, to ensure states can be reasonably predicted.

C. Evaluation In Sim-to-Real Environments

Open-loop control error (i.e., difference between predicted
and ground-truth control) has been shown to be a poor
indicator to evaluate the performance of a driving policy since
it only measures error around ground-truth trajectories and
ignores accumulated errors that gradually drift the vehicle to
out-of-distribution regions. Hereby, we presents closed-loop
testing results in the sim-to-real environment VISTA [4].
Lane Keeping As Safety Constraints. In Fig. 5, we show the
probability of ego-vehicle deviating away from the lane center
for larger than 1m. We run 1000 episodes with maximal 200
steps if not crashed (off-lane more than 2m) prematurely. In
each episode, the vehicle is randomly initialized at a point
in the trace and we compute average deviation at every point
to ensure sufﬁciently large sample size for the statistics. The
model with lane keeping CBFs achieves signiﬁcantly better
performance since they can encourage the autonomous vehicle
to stay close to the lane center by decreasing the boundary
values due to the Lyapunov property of CBFs.
Obstacle Avoidance. In Table I, we show crash rate and
minimal clearance of models with or without BarrierNet and
with or without access to ground-truth states. Minimal clear-
ance is computed as the closest distance between polygons

Fig. 4: Coordinates of ego w.r.t a reference trajectory.

with different conﬁgurations like relative poses, geographical
locations associated with the real dataset, appearance of the
vehicle, etc (b) running an optimal controller with access to
privileged information to steer the ego-vehicle and collect
ground-truth control outputs with corresponding states, and (c)
collecting RGB images at viewpoints along the trajectories.
We choose nonlinear Model Predictive Control (NMPC) as
the privileged (nominal) controller. While NMPC is usually
computationally expensive and hard to solve, it is tractable
ofﬂine and, with jerk ujerk and steering acceleration usteer
as controls, provides smooth acceleration a and steering rate
w, which is used as learning targets in BarrierNet. Vehicle
dynamics of NMPC and BarrierNet (1) are deﬁned with
respect to a reference trajectory [40]. It measures the along-
trajectory distance s ∈ R and the lateral distance d ∈ R of the
vehicle Center of Gravity (CoG) with respect to the closest
point on the reference trajectory,























˙s
˙d
˙µ
˙v
˙a
˙δ
˙ω
(cid:124) (cid:123)(cid:122) (cid:125)
˙x

=













(cid:124)

v
lr

1−dκ

v cos(µ+β)
1−dκ
v sin(µ + β)
sin β − κ v cos(µ+β)
a
0
ω
0
(cid:123)(cid:122)
f (x)













(cid:125)

+












(cid:124)

0
0
0
0
1
0
0

0
0
0
0
0
0
1

(cid:123)(cid:122)
g(x)












(cid:125)

(cid:20) ujerk
usteer
(cid:123)(cid:122)
u

(cid:124)

(cid:21)

,

(cid:125)

(12)

where µ is the vehicle local heading error determined by
the difference of the global vehicle heading θ ∈ R and the
tangent angle φ ∈ R of the closest point on the reference
trajectory (i.e., θ = φ + µ) as shown in Fig. 4; v, a denote the
vehicle linear speed and acceleration; δ, ω denote the steering
angle and steering rate, respectively; κ is the curvature of the
reference trajectory at the closest point; lr is the length of the
vehicle from the tail to the CoG; and ujerk, usteer denote the
two control inputs for jerk and steering acceleration (in the
, where lf is
nominal controller). β = arctan
the length of the vehicle from the head to the CoG. We set
the receding horizon of the NMPC to 20 time steps during
data sampling, and it is implemented in a virtual simulation
environment in MATLAB. We augment the real-world dataset
using VISTA and NMPC with synthetic obstacle avoidance
the training dataset has
and lane following data. In total,
around 400k images.

(cid:16) lr
lr+lf

tan δ

(cid:17)

Curvature centerReference trajectory   ̇         w/o dCBF100 mw/ dCBF100 m0.00.20.40.60.81.0P (Deviation > 1m)TABLE I: Crash rate and clearance with/without BarrierNet,
using or not using ground truth obstacle information.

Method

Crash Rate ↓ Min. Clearance (m) ↑

w/o dCBF
w/ dCBF
w/ dCBF (with gt)

0.53
0.28
0.03

0.43
0.55
0.61

7

Fig. 7: Statistics for crash rate in obstacle avoidance under
different levels of prediction error from front vision view.

Fig. 6: Line plot
with/without BarrierNet.

for clearance in obstacle avoidance

of ego- and ado-car within an episode. The introduction of
obstacle avoidance dCBFs signiﬁcantly reduces crash rate and
increases clearance. The remaining failures mainly come from
the imprecise or even erroneous state and obstacle information
inferred from the front-view camera only. With access to
ground-truth information (an ideal state estimator), the crash
rate is close to yet not zero. This might be due to misaligned
dynamics and inter-sampling effects of CBFs which have been
extensively studied in CBFs [41, 52]. To look deeper into how
BarrierNet improves safety distance, we plot the distribution
of clearance larger than a varying threshold among all time
steps in Fig. 6, where larger area under the curve indicates
better safety.

Furthermore, in Fig. 7, we investigate how imperfect state
estimation introduces error in dCBFs and affects crash rate.
We show the four output prediction from the state estimation
module, including deviation from lane center of ego-car d,
local heading error µ with respect to road curvature, relative
progress along the road between ego-car and the obstacle ∆s,
and lateral displacement of obstacle from lane center dobs. As
expected, the overall trend shows increasing failure with larger
state estimation error. The performance drops drastically with
large dobs since roughly it indicates whether the obstacle is
at the left or right with respect to the ego-car and thus has
great inﬂuence within obstacle avoidance dCBFs. Note that
bins at large error can have fewer samples (e.g., the tail in
histogram of d) and may lead to high variance in the estimator.
We still keep the results for completeness. The results highlight
the importance of handling state estimation error and suggest
future research on uncertainty calibration, which will be the
focus of our continued effort.
BarrierNet Provides Safe Maneuvers. In Fig. 8, we bench-
marked for different
learning systems, with and without
to provide driving trajectories under the same
BarrierNet,
conﬁguration except for arbitrary initial pose on a road. We

Fig. 8: Vehicle trajectories in obstacle avoidance with/without
BarrierNet in VISTA.

show 10 variants of initial states for each model. It can be
observed that trajectories from the two models mostly align
with each other in the beginning as the ego-vehicle starts with
different lateral displacement from the lane center and tries
to recover. Then, the two set of trajectories diverges while
approaching the obstacle. This is the consequence of correction
from the activated dCBFs over the reference unsafe control.
With BarrierNet, the safety is guaranteed.
BarrierNet With Different Proﬁles. We also notice that the
BarrierNet may learn different CBF parameters when the ego
vehicle approaches an obstacle. In Fig. 9, we present two
possible variations of penalty functions p1(z), p2(z) when
the ego vehicle is around an obstacle. The penalty functions
p1(z), p2(z) adapt to the obstacle when the ego vehicle is
close to an obstacle, and they recover to some values when
the ego leaves the obstacle. This shows the ﬂexibility of the
BarrierNet. Another observation is that the outputs of the
BarrierNet tend to deviate from the reference controls (from
the previous LSTM layer) when the ego vehicle is close to the
obstacle. This shows the safety guarantee property of CBFs. In
order to avoid this deviation, we need to improve the learned
model with better reference controls and CBF parameters.

0.00.51.01.52.02.53.03.5Clearance Threshold ()0.00.20.40.60.81.0P (clearance > )w/o dCBFw/ dCBF012340.00.10.20.30.40.5Crash RateError d (m)0.050.100.150.200.250.00.10.20.30.4Crash RateError  (rad)05101520250.00.10.20.30.4Crash RateError s (m)0246810120.00.20.40.6Crash RateError dobs (m)252015105051015x(m)0510152025303540y(m)w/ dCBFw/o dCBFRoad boundariesObstacle8

VII. CONCLUSION

We proposed an end-to-end learning framework for obtain-
ing safety-guaranteed perception-based autonomous driving
agents. Our method is constructed by combining a deep neural
model with a differentiable higher-order control barrier func-
tion to ensure safe lane-keeping and obstacle avoidance. We
showed how various modules of our pipeline can contribute to
the understanding of the learning system’s behavior while driv-
ing. Our sim-to-real and real-world experiments demonstrated
the effectiveness of our approach in many driving scenarios
where we could strictly reduce the probability of crash and
interventions, when our pipeline is activated.

We hope that our method can inspire future research on
endowing real-world robot learning schemes with fundamental
control theory modules to enhance interpretability, robustness
and safety.

ACKNOWLEDGMENTS

This work was partially supported by Capgemini Engineer-
ing. This research was also sponsored by the United States Air
Force Research Laboratory and the United States Air Force
Artiﬁcial Intelligence Accelerator and was accomplished un-
der Cooperative Agreement Number FA8750-19-2-1000. The
views and conclusions contained in this document are those
of the authors and should not be interpreted as representing
the ofﬁcial policies, either expressed or implied, of the United
States Air Force or the U.S. Government. The U.S. Govern-
ment is authorized to reproduce and distribute reprints for
Government purposes notwithstanding any copyright notation
herein.

REFERENCES

[1] Aaron D Ames, Jessy W Grizzle, and Paulo Tabuada.
Control barrier function based quadratic programs with
In 53rd IEEE
application to adaptive cruise control.
Conference on Decision and Control, pages 6271–6278.
IEEE, 2014.

[2] Alexander Amini, Guy Rosman, Sertac Karaman, and
Daniela Rus. Variational end-to-end navigation and lo-
calization. In 2019 International Conference on Robotics
and Automation (ICRA), pages 8958–8964. IEEE, 2019.
[3] Alexander Amini, Igor Gilitschenski, Jacob Phillips, Julia
Moseyko, Rohan Banerjee, Sertac Karaman, and Daniela
Rus. Learning robust control policies for end-to-end
autonomous driving from data-driven simulation. IEEE
Robotics and Automation Letters, 5(2):1143–1150, 2020.
[4] Alexander Amini, Tsun-Hsuan Wang, Igor Gilitschenski,
Wilko Schwarting, Zhijian Liu, Song Han, Sertac Kara-
man, and Daniela Rus. Vista 2.0: An open, data-driven
simulator for multimodal sensing and policy learning for
autonomous vehicles. arXiv preprint arXiv:2111.12083,
2021.

[5] Brandon Amos and J. Zico Kolter. Optnet: Differentiable
optimization as a layer in neural networks. In Proceed-
ings of the 34th International Conference on Machine
Learning - Volume 70, pages 136–145, 2017.

Fig. 9: Penalty p1(z), p2(z) variation in a dCBF (BarrierNet)
when approaching an obstacle under two (different) trained
BarrierNets. The relative degree of the safety constraint is
two, and thus we have two CBF parameters in one CBF. The
segments inside the dotted boxes denote intervals when the
ego vehicle is near the obstacle. The box sizes are different as
the ego has different speeds when passing the obstacle.

D. Physical Autonomous Car Experiments

To verify the effectiveness of the proposed vision-based end-
to-end framework with dCBFs, we deploy the trained models
on a full-scale autonomous driving car. The experiments are
conducted in a test site with rural road type. We majorly test
the algorithm with augmented reality (AR) and only perform
minimal experiment with real-car obstacle for safety reasons.
We use a pre-collected map of the test site and vehicle pose
from the differential GPS (dGPS) to place virtual obstacles in
the front of the ego-vehicle on road with AR. Note that the
tested models are still using vision inputs only to steer the
autonomous vehicle without any access to ground-truth state.
Fig. 10 is an illustration of the real-car experimental setup.
Another thing worth mentioning is that the scene is covered
with snow at the time we conducted real-car experiment. The
icy road surface at the track and heavy snow at the side of the
road introduce tire slippage and pose additional challenges
to our self-driving system. Also, the reﬂection of sunlight
on the ice makes it hard to recognize road boundaries even
from human judgement. With high-precision dGPS in the site
(covariance < 1cm), we provides qualitative analysis with
side-by-side comparison between models with and without
BarrierNet.
BarrierNet In Challenging Sharp Turns. In Fig. 11, we
demonstrate driving trajectories of BarrierNet with and without
lane keeping CBFs in sharp left and right turns. We show the
footprint of vehicle through time and indicate forward direc-
tion with arrows. Without lane keeping CBFs (red), the car is
more prone to get off-road, while roughly correct estimates of
deviation from lane center (d) imposes an additional layer of
safety with lane keeping CBFs (blue).
Obstacle Avoidance In Real World. We also did experiments
on the autonomous car in obstacle avoidance, as shown in Fig.
12. The ﬁrst example (left) demonstrates that with reasonable
reference control (both models successfully avoid the obsta-
cle), the model with obstacle avoidance dCBFs (blue) creates
more clearance to achieve better safety. The second example
(right) highlights the effectiveness of BarrierNet (blue) when
the reference control (red) fails to avoid the front car and
requires correction from activated dCBF constraints.

0246810t(s)10123p1(z)p2(z)aarefref0246810t(s)43210123p1(z)p2(z)aarefref9

Fig. 10: An illustration of real-car experiments.

2016.

[10] Mariusz Bojarski, Chenyi Chen, Joyjit Daw, Alperen
De˘girmenci, Joya Deri, Bernhard Firner, Beat Flepp,
Sachin Gogri, Jesse Hong, Lawrence Jackel, et al.
arXiv preprint
The nvidia pilotnet experiments.
arXiv:2010.08776, 2020.

[11] Axel Brunnbauer, Luigi Berducci, Andreas Brandst¨atter,
Mathias Lechner, Ramin Hasani, Daniela Rus, and Radu
Grosu. Latent imagination facilitates zero-shot transfer
in autonomous racing. arXiv preprint arXiv:2103.04909,
2021.

[12] Jason Choi, Fernando Casta˜neda, Claire J Tomlin, and
Koushil Sreenath. Reinforcement learning for safety-
critical control under model uncertainty, using control
In
lyapunov functions and control barrier functions.
Robotics: Science and Systems (RSS), 2020.

[13] Felipe Codevilla, Matthias Miiller, Antonio L´opez,
Vladlen Koltun, and Alexey Dosovitskiy. End-to-End
In IEEE
Driving via Conditional Imitation Learning.
International Conference on Robotics and Automation
(ICRA), 2018.

[14] Jyotirmoy V. Deshmukh, James P. Kapinski, Tomoya
Yamaguchi, and Danil Prokhorov. Learning deep neural
network controllers for dynamical systems with safety
guarantees: Invited paper. In 2019 IEEE/ACM Interna-
tional Conference on Computer-Aided Design (ICCAD),
pages 1–7, 2019.

[15] James Ferlez, Mahmoud Elnaggar, Yasser Shoukry, and
Cody Fleming. Shieldnn: A provably safe nn ﬁlter for
unsafe nn controllers. preprint arXiv:2006.09564, 2020.
[16] Sophie Gruenbacher, Ramin Hasani, Mathias Lechner,
Jacek Cyranka, Scott A Smolka, and Radu Grosu. On
the veriﬁcation of neural odes with stochastic guarantees.
arXiv preprint arXiv:2012.08863, 2020.

[17] Sophie Gruenbacher, Mathias Lechner, Ramin Hasani,
Daniela Rus, Thomas A Henzinger, Scott Smolka,
and Radu Grosu. Gotube: Scalable stochastic veri-
arXiv preprint
ﬁcation of continuous-depth models.
arXiv:2107.08467, 2021.

[18] Ramin Hasani. Interpretable Recurrent Neural Networks
in Continuous-time Control Environments. PhD thesis,
Technische Universit¨at Wien, 2020.

[19] Ramin Hasani, Mathias Lechner, Alexander Amini,
Daniela Rus, and Radu Grosu. A natural lottery ticket
learning with ordinary neural
winner: Reinforcement

Fig. 11: Two cases of experimental vehicle trajectories in
obstacle avoidance with/without lane keeping CBFs in the
BarrierNet. Tire slipping happens on the icy road.

Fig. 12: Two cases of experimental vehicle trajectories in
obstacle avoidance with/without BarrierNet. In the left case,
the heavy snow by the road is preventing the vehicle from
getting back to the road due to tire slipping, and thus the
vehicle recovers slowly even when the steering wheel is at its
left limit.

[6] Brandon Amos, Ivan Dario Jimenez Rodriguez, Jacob
Sacks, Byron Boots, and J. Zico Kolter. Differentiable
mpc for end-to-end planning and control. In Proceedings
of the 32nd International Conference on Neural Infor-
mation Processing Systems, page 8299–8310. Curran
Associates Inc., 2018.

[7] Jean-Pierre Aubin. Viability theory. Springer, 2009.
[8] Steven Bohez, Tim Verbelen, Elias De Coninck, Bert
Vankeirsbilck, Pieter Simoens, and Bart Dhoedt. Sensor
Fusion for Robot Control through Deep Reinforcement
In IEEE/RSJ International Conference on
Learning.
Intelligent Robots and Systems (IROS), 2017.

[9] Mariusz

Bojarski, Davide Del

Testa, Daniel
Dworakowski, Bernhard Firner, Beat Flepp, Prasoon
Goyal, Lawrence D Jackel, Mathew Monfort, Urs
Muller, Jiakai Zhang, et al. End to end learning for
arXiv preprint arXiv:1604.07316,
self-driving cars.

Front-view Image With A Real ObstacleFront-view Image With An Obstacle In ARTop-Down View4020020020406080w/o dCBFw/ dCBF6050403020100302010010w/o dCBFw/ dCBF10010203040500102030w/o dCBFw/ dCBFObstacle1001020301050510152025w/o dCBFw/ dCBFObstaclecircuits. In Proceedings of the 2020 International Con-
ference on Machine Learning (ICML). JMLR. org, 2020.
[20] Ramin Hasani, Mathias Lechner, Alexander Amini, Lu-
cas Liebenwein, Max Tschaikowski, Gerald Teschl, and
Daniela Rus. Closed-form continuous-depth models.
arXiv preprint arXiv:2106.13898, 2021.

[21] Ramin Hasani, Mathias Lechner, Alexander Amini,
Daniela Rus, and Radu Grosu. Liquid time-constant
the AAAI Conference
networks.
on Artiﬁcial Intelligence, volume 35, pages 7657–7666,
2021.

In Proceedings of

[22] Jeffrey Hawke, Richard Shen, Corina Gurau, Siddharth
Sharma, Daniele Reda, Nikolay Nikolov, Przemysław
Mazur, Sean Micklethwaite, Nicolas Grifﬁths, Amar
Shah, and Alex Kendall. Urban Driving with Conditional
Imitation Learning. In IEEE International Conference on
Robotics and Automation (ICRA), 2020.

[23] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
In
Sun. Deep residual learning for image recognition.
Proceedings of the IEEE conference on computer vision
and pattern recognition, pages 770–778, 2016.

[24] Sepp Hochreiter and J¨urgen Schmidhuber. Long short-
term memory. Neural computation, 9(8):1735–1780,
1997.

[25] Wanxin Jin, Zhaoran Wang, Zhuoran Yang,

and
Shaoshuai Mou. Neural certiﬁcates for safe control
policies. preprint arXiv:2006.08465, 2020.

[26] Hassan K. Khalil. Nonlinear Systems. Prentice Hall, third

edition, 2002.

[27] Mathias Lechner and Ramin Hasani. Mixed-memory
rnns for learning long-term dependencies in irregularly
sampled time series. 2021.

[28] Mathias Lechner, Ramin Hasani, Manuel Zimmer,
Thomas A Henzinger, and Radu Grosu. Designing
worm-inspired neural networks for interpretable robotic
In 2019 International Conference on Robotics
control.
and Automation (ICRA), pages 87–94. IEEE, 2019.
[29] Mathias Lechner, Ramin Hasani, Alexander Amini,
Thomas A Henzinger, Daniela Rus, and Radu Grosu.
Neural circuit policies enabling auditable autonomy. Na-
ture Machine Intelligence, 2(10):642–652, 2020.
[30] Wei Li, Chengwei Pan, Rong Zhang, Jiaping Ren,
Yuexin Ma, Jin Fang, Feilong Yan, Qichuan Geng,
Xinyu Huang, Huajun Gong, et al. Aads: Augmented
autonomous driving simulation using data-driven algo-
rithms. arXiv:1901.07849, 2019.

[31] Zhichao Li. Comparison between safety methods control
barrier function vs. reachability analysis. arXiv preprint
arXiv:2106.13176, 2021.

[32] Quan Nguyen and Koushil Sreenath. Exponential con-
trol barrier functions for enforcing high relative-degree
In 2016 American Control
safety-critical constraints.
Conference (ACC), pages 322–328. IEEE, 2016.
[33] Dimitra Panagou, Duˇsan M. Stipanoviˇc, and Petros G.
Voulgaris. Multi-objective control for multi-agent sys-
tems using lyapunov-like barrier functions. In Proc. of
52nd IEEE Conference on Decision and Control, pages
1478–1483, Florence, Italy, 2013.

10

[34] Hardik Parwana and Dimitra Panagou. Recursive feasi-
bility guided optimal parameter adaptation of differential
convex optimization policies for safety-critical systems.
preprint arXiv:2109.10949, 2021.

[35] Naman Patel, Anna Choromanska, Prashanth Krishna-
murthy, and Farshad Khorrami. Sensor Modality Fusion
with CNNs for UGV Autonomous Driving in Indoor
Environments. In IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS), 2017.

[36] Marcus Aloysius Pereira, Ziyi Wang, Ioannis Exarchos,
and Evangelos A. Theodorou. Safe optimal control using
stochastic barrier functions and deep forward-backward
sdes. In Conference on Robot Learning, 2020.

[37] Dean A Pomerleau. Alvinn: An autonomous land vehicle
in a neural network. Technical report, CARNEGIE-
MELLON UNIV PITTSBURGH PA ARTIFICIAL IN-
TELLIGENCE AND PSYCHOLOGY . . . , 1989.
[38] Stephen Prajna, Ali Jadbabaie, and George J. Pappas.
A framework for worst-case and stochastic safety veri-
ﬁcation using barrier certiﬁcates. IEEE Transactions on
Automatic Control, 52(8):1415–1428, 2007.

[39] Alexander Robey, Haimin Hu, Lars Lindemann, Hanwen
Zhang, Dimos V. Dimarogonas, Stephen Tu, and Nikolai
Matni. Learning control barrier functions from expert
In 2020 59th IEEE Conference on
demonstrations.
Decision and Control (CDC), pages 3717–3724, 2020.

[40] Alessandro Rucco, Giuseppe Notarstefano, and John
Hauser. An efﬁcient minimum-time trajectory generation
strategy for two-track car vehicles. IEEE Transactions on
Control Systems Technology, 23(4):1505–1519, 2015.
[41] Andrew Taylor, Andrew Singletary, Yisong Yue, and
Aaron Ames. Learning for safety-critical control with
control barrier functions. In Learning for Dynamics and
Control, pages 708–717. PMLR, 2020.

[42] Keng Peng Tee, Shuzhi Sam Ge, and Eng Hock Tay.
Barrier lyapunov functions for the control of output-
constrained nonlinear systems. Automatica, 45(4):918–
927, 2009.

[43] Marin Toromanoff, Emilie Wirbel, Fr´ed´eric Wil-
helm, Camilo Vejarano, Xavier Perrotton, and Fabien
Moutarde. End to end vehicle lateral control using
In IEEE/RSJ International
a single ﬁsheye camera.
Conference on Intelligent Robots and Systems (IROS),
2018.

[44] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser,
and Illia Polosukhin. Attention is all you need. In Ad-
vances in neural information processing systems, pages
5998–6008, 2017.

[45] Li Wang, Evangelos A Theodorou, and Magnus Egerst-
edt. Safe learning of quadrotor dynamics using barrier
In 2018 IEEE International Conference
certiﬁcates.
on Robotics and Automation (ICRA), pages 2460–2465.
IEEE, 2018.

[46] Tsun-Hsuan Wang, Alexander Amini, Wilko Schwarting,
Igor Gilitschenski, Sertac Karaman, and Daniela Rus.
Learning interactive driving policies via data-driven sim-
ulation. arXiv preprint arXiv:2111.12137, 2021.

11

[47] Peter Wieland and Frank Allg¨ower. Constructive safety
In Proc. of 7th IFAC

using control barrier functions.
Symposium on Nonlinear Control System, 2007.

[48] Rafael Wisniewski and Christoffer Sloth.

Converse
In Proc. of 52nd IEEE
barrier certiﬁcate theorem.
Conference on Decision and Control, pages 4713–4718,
Florence, Italy, 2013.

[49] W. Xiao, C. Belta, and C. G. Cassandras. Sufﬁcient
conditions for feasibility of optimal control problems
using control barrier functions. Automatica, 135:109960,
2022.

[50] Wei Xiao and Calin Belta. Control barrier functions for
systems with high relative degree. In Proc. of 58th IEEE
Conference on Decision and Control, pages 474–479,
Nice, France, 2019.

[51] Wei Xiao, Calin Belta, and Christos G. Cassandras. Fea-
sibility guided learning for constrained optimal control
problems. In Proc. of 59th IEEE Conference on Decision
and Control, pages 1896–1901, 2020.

[52] Wei Xiao, Calin Belta, and Christos G. Cassandras.
Adaptive control barrier functions. In IEEE Transactions
on Automatic Control, DOI: 10.1109/TAC.2021.3074895,
2021.

[53] Wei Xiao, Ramin Hasani, Xiao Li, and Daniela Rus. Bar-
riernet: A safety-guaranteed layer for neural networks.
preprint arXiv:2111.11277, 2021.

[54] Yi Xiao, Felipe Codevilla, Akhil Gurram, Onay Urfali-
oglu, and Antonio M L´opez. Multimodal End-to-End
Autonomous Driving. arXiv:1906.03199, 2019.

[55] Huazhe Xu, Yang Gao, Fisher Yu, and Trevor Darrell.
End-to-End Learning of Driving Models from Large-
Scale Video Datasets. In IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), 2017.

[56] Shakiba Yaghoubi, Georgios Fainekos, and Sriram
Sankaranarayanan. Training neural network controllers
using control barrier functions in the presence of dis-
In IEEE 23rd International Conference on
turbances.
Intelligent Transportation Systems (ITSC), pages 1–6,
2020.

[57] Guang Yang, Calin Belta, and Roberto Tron.

Self-
triggered control for safety critical systems using control
the American Control
barrier functions.
Conference, pages 4454–4459, 2019.

In Proc. of

[58] Catherine Zeng, Jordan Docter, Alexander Amini, Igor
Gilitschenski, Ramin Hasani, and Daniela Rus. Dreaming
with transformers. 2022.

[59] Hengjun Zhao, Xia Zeng, Taolue Chen, Zhiming Liu, and
Jim Woodcock. Learning safe neural network controllers
with barrier certiﬁcates. Form Asp Comp, 33:437–455,
2021.

