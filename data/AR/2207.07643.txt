ARShopping: In-Store Shopping Decision Support
Through Augmented Reality and Immersive Visualization

Bingjie (Jenny) Xu*
Northwestern University

Shunan Guo†
Adobe Research

Eunyee Koh†
Adobe Research

Jane Hoffswell†
Adobe Research

Ryan Rossi†
Adobe Research

Fan Du†
Adobe Research

2
2
0
2

l
u
J

5
1

]

C
H
.
s
c
[

1
v
3
4
6
7
0
.
7
0
2
2
:
v
i
X
r
a

ABSTRACT

Online shopping gives customers boundless options to choose from,
backed by extensive product details and customer reviews, all from
the comfort of home; yet, no amount of detailed, online information
can outweigh the instant gratiﬁcation and hands-on understanding
of a product that is provided by physical stores. However, making
purchasing decisions in physical stores can be challenging due to a
large number of similar alternatives and limited accessibility of the
relevant product information (e.g., features, ratings, and reviews).
In this work, we present ARShopping: a web-based prototype to
visually communicate detailed product information from an online
setting on portable smart devices (e.g., phones, tablets, glasses),
within the physical space at the point of purchase. This prototype
uses augmented reality (AR) to identify products and display detailed
information to help consumers make purchasing decisions that fulﬁll
their needs while decreasing the decision-making time. In particular,
we use a data fusion algorithm to improve the precision of the
product detection; we then integrate AR visualizations into the scene
to facilitate comparisons across multiple products and features. We
designed our prototype based on interviews with 14 participants to
better understand the utility and ease of use of the prototype.

Index Terms: Human-centered computing—Visualization—Visu-
alization systems and tools; Human-centered computing—Human
computer interaction (HCI)—Interaction paradigms—Mixed / aug-
mented reality

1 INTRODUCTION

Purchasing decisions are often inﬂuenced by the product information
provided at the point of sale [29]. As online shopping becomes more
popular, consumers increasingly rely on the comprehensive and
precise product information available online (e.g., detailed product
features, historical reviews, price trends, etc.) to make purchasing
decisions [18]. For example, consumers on a diet usually need to
review and compare the nutrition information of their groceries to
select foods that best ﬁt their nutrition goals. When online shopping,
the shopping context and product information can be easily retrieved
from the product database and web logs; many prior systems have
therefore used this information to help online shoppers make better
purchase decisions and provide product recommendations [2, 20, 32].
The situation of in-store purchases, however, introduces new chal-
lenges for retrieving and displaying product information on site.

Recent advancements in augmented reality (AR) provide new
opportunities to bridge online product information with physical
in-store products, and better communicate information to support
comparisons and help shoppers make faster purchasing decisions.
Existing work has explored the use of augmented reality in product
information retrieval [9, 11, 27], shopping navigation [12, 25], and
real-time product recommendation [1], which are all demonstrated

*e-mail: jenny.xu@u.northwestern.edu
†e-mail: {sguo, eunyee, jhoffs, rrossi, fdu}@adobe.com

to be helpful in improving consumers’ in-store shopping experi-
ence. However, most existing AR applications focus on detecting
one product at a time, while consumers in physical stores are often
exposed to many similar product alternatives [19] and expected to
make a reasonable decision between them. In addition, customers
may need to consider multiple factors to make purchasing decisions
(e.g., nutrition, price, ratings, etc.). Thus, there is a need for fu-
ture AR systems to better support decision-making by facilitating
comparisons of multiple products across multiple relevant features.
In this work, we contribute a web-based prototype, ARShopping,
for augmenting the in-store shopping experience with online product
information (e.g., product features, ratings, etc.) through portable
smart devices (e.g., phones, tablets, glasses). Inspired by the success-
ful practice of applying data visualization to facilitating multivariate
data comparison [6, 10], we present the product information in the
form of visual glyphs that can represent multiple features and en-
able intuitive comparisons across different products. In particular,
we developed a product detection algorithm that fuses results from
object detection and product marker detection to support better po-
sitioning of the glyphs in the space. We conﬁrmed the needs for
in-store decision support and product comparison via interviews
with 14 participants, and implemented the prototype based on their
feedback. To evaluate the usefulness and usability of the prototype,
we conducted a second interview study with the participants to col-
lect feedback and investigate their experience with using the system
prototype in a virtual grocery shopping environment.

2 RELATED WORK

AR + In-Store Shopping. Mobile augmented reality contributes to
smart retail settings by improving the value for both customers and
retailers alike [7]. Ganapathy et al. [9] developed a system to retrieve
product information by matching photos taken by the customer to
the product image database. Similarly, Spreer et al. [27] utilized
mobile AR applications to display product information at the point
of sale. Rashid et al. [24] combined AR and RFID to allow users to
browse the shelf and search for a given product in an AR interface.
While our prototype provides a similar data intervention experience,
we allow customers to scan multiple products at the same time and
visualize the results to facilitate product comparisons.

Sayed et al. [25] provided situated and abstract information repre-
sentation with real-time analytical interaction for shopping. Differ-
ent from our focus on product comparison, this system focuses more
on product searching and navigation. Another category of AR shop-
ping systems focuses on recommending products to customers while
shopping. For example, Junho et al. [1] developed a mobile app to
recommend and warn shoppers of grocery items in the current isle
based on their personal and family health proﬁles and the nutrition
information of the grocery items. The Easy Shopping app developed
by Jayananda et al. [12] demonstrated a similar usage scenario with
integrated product navigation. This system directs users to the aisles
of the products, and recommends similar items while displaying the
relevant health alerts. These systems focus on only a single product
at a time, whereas our system requires detection of multiple prod-
ucts at the same time that can then have the information extracted,
visualized, and compared by the user to facilitate decision-making.

 
 
 
 
 
 
Decision Support for In-Store Shopping. Providing information
to customers while shopping can inﬂuence their purchasing behav-
ior [17]. The advancement of Mobile Commerce [21] and Ubiqui-
tous Commerce [26] has enabled mobile decision support for in-store
shopping. Early implementations introduced location-based agents
(e.g., Shopper’s Eye [8], Impulse [31]) and sensor network-based
agents (e.g., MyGrocer [16]) to retrieve product information at the
point of purchase. Shoppers may also retrieve data by scanning
product barcodes or QR-codes with their phone camera [15, 30].

On top of these technologies, decision support systems (DSS)
have been developed to help consumers interact with physical prod-
ucts to retrieve and compare product information [5, 13]. They
utilize consumers’ requests for speciﬁc product attributes to support
decision-making. Similarly, product recommendation agents (RA)
aim to support consumers in choosing the right product among sev-
eral alternatives and distractions during in-store shopping [3, 22].
Most of the DSSs or RAs are developed with a mobile user interface,
separate from the shopping environment. Recent advancements in
eye-tracking [23] and AR [11] for shopping have enabled new op-
portunities to provide more context-aware decision support, which
could have a large impact on consumers’ decision strategy [4]. While
mobile shopping agents were proved to be generally useful in prior
work [22], there is a research trend highlighting the importance of un-
derstanding how mobile services may impact consumers’ shopping
experience and decision-making [14]. In this paper, we incorporate
comparative data visualization into AR for shopping decision sup-
port and build an understanding of consumers’ potential acceptance
towards an AR-based shopping decision support system.

3 FORMATIVE INTERVIEWS

To understand the general needs of in-store customers and how aug-
mented reality can help improve the in-store shopping experience
and decision-making, we conducted preliminary interviews with
14 participants (P1–14, 6 males, 8 females, aged 23 to 52). Partic-
ipants were recruited via advertisement on social media platform
with backgrounds ranging from graduate student, teacher, software
engineer, research scientist and speech-language pathologist, under
the condition that they had recent experience shopping both online
and in-store. All interviews were conducted remotely and recorded;
each interview took about 30 minutes. The interviews were semi-
structured covering questions including their shopping frequency
and habits, purchasing categories, and key product information for
making purchasing decisions. Based on the feedback from partic-
ipants, we identify the following key insights and further infer the
needs for in-store shopping assistance.

Shopping Habits and Categories. We found the product categories
that people chose to purchase in-store are relatively ﬁxed and they
have a regular frequency of visiting physical stores. For example,
nearly all interviewees (13/14) described a regular in-store cadence
for grocery shopping (1–4 times per week). In contrast, people have
more diverse shopping categories and ﬂexible frequency online.

When deciding between in-store or online shopping, the most
commonly mentioned factors are the product categories and urgency
of the need. In particular, participants usually choose to buy fresh
goods (13/14) and household essentials (7/14 participants) in-store.
Three interviewees also mentioned that they would visit physical
stores for products they found online but would like to try out in
person, such as clothes, footwear, glasses, and instruments. Partic-
ipants would also choose to buy products in urgent need, such as
medicine or other necessities through physical stores. One partici-
pant noted that differences in price can contribute to the decision of
whether to shop in-store or online: “Sometimes the brick-and-mortar
store offers better price to compete with online store” (P12). These
results suggest that even with the rapid evolution of e-commerce,
people still have regular demand for visiting brick-and-mortar stores,
especially for products that are fresh and in urgent need.

Pain Points of In-Store Shopping. When asked about the difﬁ-
culties participants experienced during in-store shopping, the most
common ones include travel time and cost, limited product variety,
and the difﬁculty of making purchasing decisions. In particular, three
participants mentioned that they may need to “visit multiple stores
due to the lack of supply” (P8, 13, 14) and two mentioned that “it
takes multiple days decide among products in different stores” (P10,
11). P1 described difﬁculty deciding between different products,
often resulting in a less than satisfactory outcome: “I sometimes
need to pickup stuffs on my way back home that my family need
immediately with a short notice. It’s difﬁcult to choose the best one
without researching beforehand so I often have to pick up a random
one.” P6 described a similar experience: “It’s hard to determine
which brand to buy when purchasing household goods that I do not
often use.” P13 also recalled his experience of searching for product
information online while purchasing it in-store: “I had to search
the product online with my mobile phone to compare the reviews of
different brand.” While the cost of travel are the natural defects of
in-store shopping, the hardship of making decisions when shopping
in-store raises a need for providing decision assistance support in
brick-and-mortar stores.

Shopping Decision-Making. We asked participants to recall a re-
cent shopping experience and describe how they decided on the
product(s) they purchased. In these conversations, we noticed sev-
eral key pieces of information that they often referred to when
making decisions, including the composition, efﬁciency, historical
reviews, prices, and discounts across platforms. For example, P1
recalled his recent experience purchasing medications and noted that
he referred to the chemical composition and historical reviews for
different brands. Similarly, P5 recalled her habit of reading nutrition
labels when purchasing snacks. While this information is easily
accessible online, oftentimes it is not available or is more difﬁcult
to browse when customers are purchasing in-store. In fact, seven
participants brought up searching online for this information before
visiting a physical store, and ﬁve participants mentioned a pressing
need to be able to conduct this research while being in-store in order
to decide which one to buy. For example, P9 said that “There were
several times when I could not decide which one to buy in-store and
also felt inconvenient to research on my phone, so I took a picture of
all the available brand and returned home to look them up.” These
results reinforce the need for providing decision assistance in-store
that can better enable customers to access and compare relevant
online information for the products immediately available.

4 ARSHOPPING PROTOTYPE

Our system, ARShopping, includes two modules (as shown in Fig. 1):
a product detection module and a user interaction module with the
mobile interface. The product detection module (Sec. 4.1) retrieves
the product ID and position by leveraging both the marker that is
attached to the product price tag and the image of the products in
the scene captured from the mobile camera. The product detection
module also identiﬁes the 3D position, rotation, and actual size of
each product for the placement of our comparative visualization. The
user interaction module (Sec. 4.2) includes the main functionality
for the user interface, including the comparative visualizations.

4.1 Product Detection

As our prototype needs to include multiple products in the scene
and detect them at the same time, there may be mutual interference
between different products when they are jammed on the shelf. To
enhance the stability and applicability of the detection, we incorpo-
rate an additional marker with each product and combine the results
of marker detection and product image detection.

Implementation. For marker detection, we utilized the built-in
marker tracking function from the AR.js library. We print a marker

Figure 1: The architecture of the ARShopping prototype.

Figure 2: The ARShopping Interface. (a) Filtering. (b) Multivariate
data glyphs. (c) Adding products to favorites. (d) Comparison view.

with a unique ID encoded for each product and assume the marker
will be placed close to the corresponding physical product (e.g.,
on the price tag) and also on the same surface of the product shelf.
In this way, we can infer the product ID based on the encoded
information and the 3D position, rotation, and actual size of the
physical product based on the detected size, transformation, and
rotation of the marker. The product object detection is implemented
based on an object detection model trained by online images of each
product and transfer learning from the TensorFlow object detection
model [28]. For each object detected, the model outputs the matched
product ID, product’s center position, and the size of the bounding
box. To reduce the overlap of the immersive data visualizations for
multiple products (Sec. 4.2), it is necessary to properly layout the
visualization as users interact with the system. Therefore, we fur-
ther determine the layout of the visualization by ﬁnding the closest
product near the marker and use the area of the product to overlay
the visualization. The objects’ locations are transferred from screen
coordinates to world coordinates to calculate their distance to the
marker, assuming that the product is at the same distance as the
marker from the camera.

Online Database Query. With the detected product IDs, we can
retrieve the online information of products in the camera scene from
the online database. For this initial prototype, we crawl grocery in-
formation from Target.com to establish our database, which includes
the price, ratings, in-store deals/coupons, and speciﬁcations (e.g., nu-
trition, size, weight, etc.) of each product. After detecting products
through the camera, the system sends the corresponding product IDs
in the scene to the online database to query the product information.
At the same time, the system will also search the database to see
if the products are on sale or has any in-store coupons that can be
applied, and push the coupon to users in real-time.

Data Fusion Algorithm. For each product, we utilize a data fusion
algorithm to determine its existence and position. Note that prod-
ucts’ position refers to a broad deﬁnition of position, including the
product’s center position, size, transformation, and rotation. There
are four different cases for each product: (1) When both methods
have detected this product, its center position and size are from the
object detection results and its transformation and rotation are from
the marker detection, assuming the product’s front surface is parallel
to the marker. (2) When the product has only been detected by the
marker detection, its position is calculated only from marker’s center
position, size, transformation, and rotation with a ﬁxed relative posi-
tion between the marker and the product (e.g., the product is on the
top of the marker) and a ﬁxed scale between the marker’s size and
the product’s size. (3) When the product was only detected by object
detection, its position only contains the center position and size from
the object detection result assuming it has no transformation and
rotation relative to the camera. (4) When both methods have not
detected this product, it is considered to not exist in the scene.

Figure 3: A comparison of product detection and glyph placement
results with (a) marker detection only and (b) marker+object detection.

4.2 User Interface

Visualizing product information. ARShopping utilizes radar
charts to represent multivariate product data. After preliminary
screening and ﬁltering (Fig. 2a), users can analyze qualiﬁed prod-
ucts’ information by visualizing glyphs overlaid on the physical
products (Fig. 2b). The layout of the glyph is calculated based on
the resulting product position determined by our product detection
method. For marker detection only, the glyphs may experience some
overlap and visually clutter the space due to the placement of the
marker (Fig. 3a). By leveraging the object detection, we can create
a more natural integration of the physical product and the virtual
marker. In particular, we leverage the orientation of the marker as
read from the camera to tell the orientation of the customer. The
canvas of the glyphs will be distorted to better reﬂect the customer’s
point of focus (Fig. 3b).

Regardless of which method is employed, our glyph placement
algorithm creates a direct mapping between products and the critical
online information necessary to make an informed purchasing deci-
sion; this way, customers can ﬁnd information appropriately situated
in the space and easily select the desired product once a purchasing
decision is made. Glyphs can be triggered on and off by clicking
the glyph button on the menu. When glyphs are shown, users can
decide what information to show by clicking the database button
and selecting information of interest on the dropdown list next to the
button. Each axis of the radar chart has the same scale that considers
all products of the same type in the store, which assists users in
comparing products’ information by observing the relative amount
of products’ speciﬁc data intuitively.

Comparison view. The main view presents the glyphs in juxtapo-
sition, which gives an overview of the features across all products.
However, it may hinder customers from ﬁnding the optimal one when
mutliple products have similar features. To further help customers
make ﬁnal purchase decision, ARShopping also enables users to
make more detailed comparisons via the comparison view (Fig. 2d),
in which the glyphs are placed in superposition for more thorough
feature comparison. Users can add products they want to compare
to the favorite list (Fig. 2c), and the comparison view will show the
overlaid radar charts for feature comparison with subjective features
such as ratings and customer reviews.

5 EVALUATION OF ARSHOPPING
To assess the usability and usefulness of our ARShopping prototype
for assisting with decision making during in-store shopping, we
conducted a second round interview through a case study in a virtual
grocery shopping setting with the 14 participants we recruited from
the formative interviews (Sec. 3).

5.1 Study Procedure
In each interview, we ﬁrst demonstrated the prototype’s usage and
functionalities through an introduction video with a usage scenario
of purchasing protein bars in the grocery store. The introduction
video is included in the Supplemental Material. After that, we sent
the participant a picture of milk bottles on shelves in the grocery
store, which was preprocessed with a marker attached next to the
price tag of each product. We asked the participant to display the
picture in full screen on a laptop. The prototype was deployed on
a remote web server, and the participants could access it through a
web link with the browser on their phone. We asked the participants
to scan the picture with the prototype as if they were purchasing milk
in the grocery stores and freely explore the prototype’s functionali-
ties. Participants were encouraged to think out loud, give feedback,
and raise questions about the prototype. After the prototype try-out,
we further interviewed the participants to collect their subjective
feedback in terms of the usefulness, ease of use, and directions for
enhancing the current prototype. In the end, we asked participants
to answer a post-study questionnaire with eight questions (shown
in Fig. 4) on a 7-point Likert scale designed following the Technol-
ogy Acceptance Model (TAM) to measure participants’ perceived
usefulness (Q1–Q4), ease of use (Q5–Q7), and intention of use (Q8).

5.2 Acceptance
As shown in Fig. 4, participants generally agreed the prototype was
useful and easy to use, and also showed their willingness to use
the prototype in their daily life. Speciﬁcally, the average perceived
usefulness, ease of use, and intention of use of all responses were
5.78, 5.45, and 6.07, respectively. For the usefulness and ease of
use, we also tested the reliability of the responses with Cronbach’s
alpha scoring 0.682 and 0.881, respectively, which indicates that the
observed acceptance towards the prototype is reliable (> 0.6).

5.3

Feedback and Implications

Perceived usefulness. As reported in Sec. 5.2, participants gener-
ally found the prototype to be useful. In particular, seven participants
commented that this prototype can “save their time of comparing”
(P1, 5, 7, 8, 12, 13, 14). Three participants felt the prototype can
help them “get to know the product better” and it can be particularly
useful when they are “making purchasing decisions on products they
are not familiar with” while “increasing the conﬁdence of purchas-
ing” (P2, 10, 14). For example, one participant noted that “This
prototype provides a data-driven perspective which is more trustwor-
thy than other people’s opinion” (P10). In terms of which feature
participants felt was most useful, twelve participants voted for the
comparative visualization and six voted for the overall ﬁltering func-
tionality. As P9 said: “I really like how ﬁltering and comparative
visualization work together. As the ﬁltering roughly set the range of
my purchasing options, the comparative visualization can provide
decision support in much ﬁner detail.”

While many participants were positive about the utility of the sys-
tem for decision-making, several participants raised concerns about
the usefulness of integrating data-driven comparisons. For example,
P4 noted that “Showing data is probably not friendly enough for
novice users. I would need more text description of the product to
make decisions.” Other participants remained more neutral about
the usefulness of the prototype, as they think it may depend on the
“value of the product” (P3), “precision of the scanning” (P7, 8, 9),
and the “familiarity of the product” (P2, 10).

Figure 4: Post-study survey results with Technology Acceptance
Model (TAM) instruments. Responses were made on a 7-point Likert
scale (1=“strongly disagree”, 7=“strongly agree”). Q1–Q4 explore the
perceived usefulness (in red), Q5–Q7 explore the perceived ease of
use (in blue), and Q8 asks about intention of use (in orange).

Ease of use. Participants did not experience much difﬁculty when
trying out the prototype, which could be due to the simplicity of the
prototype in the current stage. While most participants appreciated
that the prototype was a web-based application that could eliminate
the need to download and install a separate application, two partici-
pants (P8, 14) raised their concern about the internet connection in
physical stores and wondered if the prototype can be used ofﬂine.
One participant (P7) noted that the prototype might consume a lot
of phone battery as the camera needs to be constantly turned on. P8
also brought up that the comparative visualization may be difﬁcult
to investigate when the number of parameters is large.

Desired features. We asked participants about the functionalities
they wished to have besides the features of the prototype. Many of
them brought up product recommendation, either by a predeﬁned
user need or the purchases of other relevant customers. Participants
also expressed a desire to have price comparisons both online and
ofﬂine across purchase channels, and to show the historical trends
of the price. P4 pointed out that the application could use more text
descriptions to make the data-driven analysis and visualization more
friendly to novice users. P14 also suggested to incorporate more text
descriptions to explain the meaning of the product speciﬁcations.

6 LIMITATIONS AND FUTURE WORK

While our prototype is implemented as a web application and can be
used on any smart devices with a camera, we only tested its usage on
smartphones, leaving the use on tablets and smart glasses for future
investigation. In addition, since this study was conducted during the
pandemic, we decided to employ the virtual setting, which may have
covered up some potential usability issues that could arise during
real-world usage. For example, there could be some interference
in a real-world environment that would affect the stability of the
product identiﬁcation, such as natural light and shadows, and the
size of the markers and products in the scene. In fact, our pro-
posed product detection solution was partially motivated by these
issues (i.e., combining marker detection and object detection results
to improve detection precision). However, the real-world experience
and performance still needs to be evaluated in future work.

7 CONCLUSION

ARShopping provides new possibilities for a better in-store shopping
experience augmented with data visualizations and online product
details. Compared with existing in-store shopping AR applications,
ARShopping aims to help consumers make better purchasing deci-
sions across multiple similar alternatives. To enhance the stability
and precision of the product detection, we propose to incorporate
marker detection and object detection for product information re-
trieval. We also integrate data visualization to help with displaying
and comparing comprehensive product speciﬁcations. Our interview
studies with consumers point out several future research directions,
including comparing price throughout time and across different pur-
chase channels, improving the design of visualization to make it
more understandable to novice users, and incorporating more narra-
tives to make the comparison results more intuitive.

1234567Q1. Using this app would enable me to make shopping decisions more quickly.Q2. Using this app would help me make better shopping decisions.Q3. Using this app makes it easier to shopping in-store.Q4. I would ﬁnd this app useful in my life.Q5. I would ﬁnd it easy to learn how to use this app.Q6. I would ﬁnd this app to be ﬂexible to interact with.Q7. I think ﬁnding the information I want for shopping in-store is easy through this app.Q8. Assuming I had access to this app, I intend to use it.REFERENCES

2011.

[21] B. E. Mennecke and T. J. Strader. Mobile Commerce: Technology,
Theory and Applications: Technology, Theory and Applications. IGI
Global, 2002.

[22] B. N. Miller, I. Albert, S. K. Lam, J. A. Konstan, and J. Riedl. Movie-
lens unplugged: experiences with an occasionally connected recom-
mender system. In Proceedings of the 8th international conference on
Intelligent user interfaces, pp. 263–266, 2003.

[23] J. Pfeiffer, T. Pfeiffer, and M. Meißner. Towards attentive in-store
recommender systems. In Reshaping society through analytics, collab-
oration, and decision support, pp. 161–173. Springer, 2015.

[24] Z. Rashid, E. Peig, and R. Pous. Bringing online shopping experience
to ofﬂine retail through augmented reality and rﬁd. 10 2015. doi: 10.
1109/IOT.2015.7356547

[25] N. Sayed, B. Thomas, K. Marriott, J. Piantadosi, and R. Smith. Situated
analytics. pp. 1–8, 09 2015. doi: 10.1109/BDVA.2015.7314302
[26] H. Sheng, F. F.-H. Nah, and K. Siau. An experimental study on ubiq-
uitous commerce adoption: Impact of personalization and privacy
concerns. Journal of the Association for Information Systems, 9(6):15,
2008.

[27] P. Spreer, K. Kallweit, and K. Gutknecht.

Improving the in-store
customer information process using mobile augmented reality. 06
2012.

[28] M. Tan, R. Pang, and Q. V. Le. Efﬁcientdet: Scalable and efﬁcient
In Proceedings of the IEEE/CVF conference on

object detection.
computer vision and pattern recognition, pp. 10781–10790, 2020.
[29] G. J. Tellis and G. J. Gaeth. Best value, price-seeking, and price
aversion: The impact of information and learning on consumer choices.
Journal of marketing, 54(2):34–45, 1990.

[30] H. Van der Heijden. Mobile decision support for in-store purchase

decisions. Decision support systems, 42(2):656–663, 2006.

[31] J. Youll, J. Morris, R. Krikorian, and P. Maes. Impulse: Location-
based agent assistance. In Proceedings of the Fourth International
Conference on Autonomous Agents, 2000.

[32] P. Zhong, Z. Li, Q. Chen, Y. Wang, L. Wang, M. H. Ahmed, and
F. Fan. Poolside: An online probabilistic knowledge base for shopping
decision support. In Proceedings of the 2017 ACM on Conference on
Information and Knowledge Management, pp. 2559–2562, 2017.

[1] J. Ahn, J. Williamson, M. Gartrell, R. Han, Q. Lv, and S. Mishra.
Supporting healthy grocery shopping via mobile augmented reality.
ACM Transactions on Multimedia Computing, Communications, and
Applications (TOMM), 12(1s):1–24, 2015.

[2] M. K. Al-nawayseh, M. M. Alnabhan, M. M. Al-Debei, and W. Bal-
achandran. An adaptive decision support system for last mile logistics
in e-commerce: a study on online grocery shopping. IJDSST, 5(1):40–
65, 2013.

[3] A. Bamis, A. Boukerche, I. Chatzigiannakis, and S. Nikoletseas. A
mobility aware protocol synthesis for efﬁcient routing in ad hoc mobile
networks. Computer Networks, 52(1):130–154, 2008.

[4] J. R. Bettman, M. F. Luce, and J. W. Payne. Constructive consumer
choice processes. Journal of consumer research, 25(3):187–217, 1998.
[5] P. Broeckelmann and A. Groeppel-Klein. Usage of mobile price com-
parison sites at the point of sale and its inﬂuence on consumers’ shop-
ping behaviour. The International Review of Retail, Distribution and
Consumer Research, 18(2):149–166, 2008.

[6] N. Cao, Y.-R. Lin, D. Gotz, and F. Du. Z-glyph: Visualizing outliers in
multivariate data. Information Visualization, 17(1):22–40, 2018.
[7] S. G. Dacko. Enabling smart retail settings via mobile augmented
reality shopping apps. Technological Forecasting and Social Change,
124:243–256, 2017.

[8] A. E. Fano. Shopper’s eye: using location-based ﬁltering for a shopping
agent in the physical world. In Proceedings of the second international
conference on Autonomous agents, pp. 416–421, 1998.

[9] S. Ganapathy, G. J. Anderson, and I. V. Kozintsev. Mar shopping
assistant usage: Delay, error, and utility. In 2011 IEEE Virtual Reality
Conference, pp. 207–208. IEEE, 2011.

[10] M. Gleicher, D. Albers, R. Walker, I. Jusuﬁ, C. D. Hansen, and J. C.
Roberts. Visual comparison for information visualization. Information
Visualization, 10(4):289–309, 2011.

[11] F. Guti´errez, K. Verbert, and N. N. Htun. Phara: an augmented real-
ity grocery store assistant. In Proceedings of the 20th International
Conference on Human-Computer Interaction with Mobile Devices and
Services Adjunct, pp. 339–345, 2018.

[12] P. Jayananda, D. Seneviratne, P. Abeygunawardhana, L. Dodampege,
and A. Lakshani. Augmented reality based smart supermarket system
with indoor navigation using beacon technology (easy shopping android
mobile app). In 2018 IEEE International Conference on Information
and Automation for Sustainability (ICIAfS), pp. 1–6, 2018.

[13] N. Jeong, Y. Yoo, and T.-Y. Heo. Moderating effect of personal innova-
tiveness on mobile-rﬁd services: Based on warshaw’s purchase inten-
tion model. Technological Forecasting and Social Change, 76(1):154–
164, 2009.

[14] V. Kalnikait˙e, J. Bird, and Y. Rogers. Decision-making in the aisles:
informing, overwhelming or nudging supermarket shoppers? Personal
and Ubiquitous Computing, 17(6):1247–1259, 2013.

[15] T. Kawamura, S. Nagano, M. Inaba, and Y. Mizoguchi. Wom scouter:
mobile service for reputation extraction from weblogs. International
Journal of Metadata, Semantics and Ontologies, 3(2):132–141, 2008.
[16] P. Kourouthanassis and G. Roussos. Developing consumer-friendly
pervasive retail systems. IEEE Pervasive Computing, 2(02):32–39,
2003.

[17] T. Kowatsch and W. Maass. In-store consumer behavior: How mobile
recommendation agents inﬂuence usage intentions, product purchases,
and store preferences. Computers in Human Behavior, 26(4):697–704,
2010.

[18] T. Kowatsch and W. Maass. Mobile purchase decision support sys-
tems for in-store shopping environments. In Advanced Technologies
Management for Retailing: Frameworks and Cases, pp. 270–288. IGI
Global, 2011.

[19] Y. E. Lee and I. Benbasat.

Interaction design for mobile product
recommendation agents: Supporting users’ decisions in retail stores.
ACM Transactions on Computer-Human Interaction (TOCHI), 17(4):1–
32, 2010.

[20] J. Li and Y. Feng. Construction of multi-agent system for decision
support of online shopping. In International Conference on Artiﬁcial
Intelligence and Computational Intelligence, pp. 318–324. Springer,

