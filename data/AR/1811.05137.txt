8
1
0
2

v
o
N
3
1

]
E
M

.
t
a
t
s
[

1
v
7
3
1
5
0
.
1
1
8
1
:
v
i
X
r
a

Multiscale Information Storage of Linear Long-Range Correlated Stochastic Processes

Luca Faes,1, ∗ Margarida Almeida Pereira,2, 3 Maria Eduarda Silva,4, 5 Riccardo
Pernice,1 Alessandro Busacca,1 Michal Javorka,6, 7 and Ana Paula Rocha2, 3
1Department of Energy, Information engineering and Mathematical models (DEIM),
University of Palermo, Viale delle Scienze, Bldg. 9, 90128 Palermo, Italy
2Faculdade de Ciˆencias, Universidade do Porto, Rua Campo Alegre, Porto, Portugal
3Centro de Matem´atica da Universidade do Porto (CMUP)
4Faculdade de Economia, Universidade do Porto, Rua Dr. Roberto Frias, Porto, Portugal
5Centro de Investiga¸c˜ao e Desenvolvimento em Matem´atica e Aplica¸c˜oes (CIDMA)
6Department of Physiology, Comenius University in Bratislava,
Jessenius Faculty of Medicine, Mala Hora 4C, 03601 Martin, Slovakia
7Biomedical Center Martin, Comenius University in Bratislava,
Jessenius Faculty of Medicine, Mala Hora 4C, 03601 Martin, Slovakia
(Dated: November 14, 2018)

Information storage, reﬂecting the capability of a dynamical system to keep predictable infor-
mation during its evolution over time, is a key element of intrinsic distributed computation, useful
for the description of the dynamical complexity of several physical and biological processes. Here
we introduce a parametric framework which allows to compute information storage across multiple
time scales in stochastic processes displaying both short-term dynamics and long-range correlations
(LRC). The framework exploits the theory of state space models to provide the multiscale repre-
sentation of linear fractionally integrated autoregressive (ARFI) processes, from which information
storage is computed at any given time scale relating the process variance to the prediction error
variance. This enables the theoretical assessment and a computationally reliable quantiﬁcation of a
complexity measure which incorporates the eﬀects of LRC together with that of short-term dynam-
ics. The proposed measure is ﬁrst assessed in simulated ARFI processes reproducing diﬀerent types
of autoregressive (AR) dynamics and diﬀerent degrees of LRC, studying both the theoretical values
and the ﬁnite sample performance. We ﬁnd that LRC alter substantially the complexity of ARFI
processes even at short time scales, and that reliable estimation of complexity can be achieved at
longer time scales only when LRC are properly modeled. Then, we assess multiscale information
storage in physiological time series measured in humans during resting state and postural stress,
revealing unprecedented responses to stress of the complexity of heart period and systolic arterial
pressure variability, which are related to the diﬀerent role played by LRC in the two conditions.

PACS numbers: 02.50.Ey, 05.45.Tp, 87.10.Mn, 87.19.ug

I.

INTRODUCTION

Several physical and biological systems, such as cli-
matic systems, econometric systems, the brain or the
cardiovascular system, exhibit a rich dynamical activity
that stems from the coexistence of self-sustained oscilla-
tors, interacting subsystems and feedback loops reacting
to internal and external inputs [1–4]. This multifaceted
organization results in a complex system evolution over
time, which is often revealed by the time course of a
systemic variable like the global temperature, the stock
market, the brain wave amplitude, or the heart period.
In the recent past, several techniques have been proposed
which aim at quantifying the richness of a dynamic pro-
cess, usually indicated as dynamical complexity [5–10].
These methods have potentially important applications
regarding both the characterization of the system state
and the extraction of diagnostic parameters; for instance,
a reduction of dynamical complexity may be associated
with a reduced capability of subsystems to interact and,

∗ luca.faes@unipa.it

in physiological systems, has been proposed as a feature
of pathologic behaviors [11, 12].

A common approach to assess the complexity of a time
series intended as a realization of a dynamic process is
that of quantifying the degree of irregularity, or unpre-
dictability, of patterns extracted from the series. This
approach has been pursued by studies proposing mea-
sures derived from linear or nonlinear prediction [13–15],
or based on the concept of conditional entropy [5–7], to
quantify the dynamical complexity of a process. On the
other hand a complementary measure, which has been
taking place recently in the frame of information theory,
is the amount of information stored in a dynamic sys-
tem. The so-called information storage is deﬁned as the
information contained in the past history of a stochas-
tic process that can be used to predict its future [16].
This measure has a straightforward information-theoretic
formulation as it quantiﬁes the information shared be-
tween the current state of a process and its past states.
Moreover, besides reﬂecting the regularity of a dynamic
process intended as a complementary measure of its com-
plexity, this quantity is recognized as one of the three key
component processes constituting every act of informa-

 
 
 
 
 
 
tion processing in a network of interacting systems (i.e.,
information storage, transfer, and modiﬁcation) [17]. As
such, information storage is considered as a crucial as-
pect of the dynamics of several processes ranging from
human brain networks [18] to artiﬁcial networks [19] and
robot motion [20], and has been successfully proposed to
describe the regularity of brain [17], cerebrovascular [21],
cardiorespiratory [15] and cardiovascular [22] dynamics.
The present work addresses the question of comput-
ing information storage across multiple temporal scales.
While it is widely acknowledged that a large variety of
complex systems exhibit peculiar oscillatory activities
which span several diﬀerent temporal scales [10, 23–25],
methods to assess the information stored in a process
across time scales have not been yet introduced explicitly.
The most standard method to analyze the dynamics of a
process at diﬀerent time scales is the so-called multiscale
entropy [10], which is based on computing the process
complexity (through the Sample Entropy measure [7]) af-
ter eliminating the fast temporal scales through a lowpass
ﬁlter and downsampling the ﬁltered process. Although
very popular, this approach suﬀers from some shortcom-
ings which led to numerous reﬁnements [26, 27]. A main
issue with this measure, that is its inapplicability to short
time series, has been overcome only recently with the in-
troduction of an approach based on linear autoregressive
(AR) models [25]. This approach computes complexity
from the parameters of a state space (SS) model which
represents the rescaled version of the original AR process
obtained through the ﬁltering and downsampling steps.
In this study we implement this approach for the com-
putation of information storage and, most importantly,
we extend it to account for the eﬀect of long range cor-
relations (LRC). LRC characterize the scaling properties
displayed across time scales by a broad class of dynamic
processes [23, 28–30], and are thus a fundamental aspect
of multiscale processes. Moreover, LRC are manifested
also at short time scales and within the short time win-
dows typically used for the computation of complexity
measures, thus coexisting with short-term dynamics and
having an impact on the assessment of their complexity
[30]. In spite of this, methods are lacking which are able
to describe quantitatively the multiscale complexity or
regularity of stochastic processes in the presence of LRC.
Here, we ﬁll this gap by providing theoretical formula-
tions and practical estimation of multiscale information
storage for stochastic processes which are suitably de-
scribed by fractionally integrated autoregressive (ARFI)
models.

II. METHODS

A. Linear Stochastic Processes with Long Range
Correlations

2

hibiting both short-term dynamics and long-range corre-
lations, which is based on representing a discrete-time,
zero-mean stochastic process Xn, −∞ < n < ∞, as
a fractionally integrated autoregressive (ARFI) process
fed by uncorrelated Gaussian innovations En. The ARFI
process takes the form:

A(L)(1 − L)dXn = En

(1)

where L is the back-shift operator (LiXn = Xn−i),
AiLi is an autoregressive (AR) polyno-

AL = 1 −

p
(cid:80)
i=1

mial of order p and (1 − L)d is the fractional diﬀerencing
operator deﬁned by [31]:

(1 − L)d =

∞
(cid:88)

k=0

GkLk

, Gk =

Γ(k − d)
Γ(−d)Γ(k + 1)

,

(2)

with Γ(·) denoting the gamma (generalized factorial)
function. The parameter d in (1) determines the long-
term behavior of the process, while the coeﬃcients of the
polynomial A(L), i.e. Ai, i = 1, . . . , p, allow description
of the short-term dynamical properties. Note that the
process deﬁned in (1) is a particular case of the broader
class of ARFIMA(p,d,l ) processes, which contain also a
moving average (MA) polynomial of order l that makes
the innovation process En non-white; here we restrict
our analysis to the description of the ARFIMA(p,d,0)
process, which we denote as an ARFI(p,d ) process.

The parameters of the ARFI model (1), namely the
coeﬃcients of A(L) and the variance of the innovations
ΣE, are obtained from process realizations of ﬁnite length
ﬁrst estimating the diﬀerencing parameter d by means of
the Whittle semi-parametric local estimator [31], then
deﬁning the ﬁltered data X (f )
n = (1 − L)dXn, and ﬁ-
nally estimating the AR parameters from the ﬁltered
data X (f )
using the ordinary least squares method to
solve the AR model A(L)X (f )
n = En, with model order p
assessed through the Bayesian information criterion [32].

n

B. Linear Measures of Information Storage

The information storage of a dynamical system that
produces entropy with a non-zero rate is a quantity re-
lated to how much the system is able to share information
during its evolution across time. Considering a system
X whose activity is deﬁned by the stochastic process X,
let us deﬁne as Xn the random variable describing the
present state of the system, and as X −
n = [X1X2...Xn−1]
the vector variable describing its past states. Then, the
information stored in the system is deﬁned as

SX = I(Xn; X −

n ) = E

(cid:20)

log

p(x1, . . . , xn)
p(x1, . . . , xn−1)p(xn)

(cid:21)

, (3)

We start recalling the classic parametric approach to
the description of linear Gaussian stochastic processes ex-

where I(·; ·) denotes mutual information, p(·) denotes
probability density function, and the expectation is taken

over several realizations (x1, . . . , xn) of the random vari-
ables (X1, . . . , Xn).

Even though information storage has been long recog-
nized as an important aspect of the dynamics of complex
systems, it has been formalized only recently as in Eq. (3)
as the amount of information shared between the present
and the past states of a dynamic process [16]. From the
point of view of the dynamic update of the state of a
time-evolving system, the information storage is comple-
mentary to a well-known measure of system complexity
quantiﬁed in terms of entropy rate, i.e. the conditional
entropy of the present state of the system given its past
states, CX = H(Xn|X −
n ) which indeed can be related to
SX by simple information-theoretic rules:

SX = H(Xn) − H(Xn|X −

n ) = HX − CX ,

(4)

where HX = H(Xn) is the entropy of the present system
state. Here, we exploit the relation stated in (4) and
particularize it to the case of linear systems which can
be fully described using an ARFI dynamic process in the
form of Eq.
(1). Speciﬁcally we note that, given the
ARFI representation, the entropy of the present state of
the process and the conditional entropy of the present
given the past can be expressed analytically in terms of
the variance of the process Xn, ΣX , and the variance of
the innovations En, ΣE, as [15, 33, 34]:

H(Xn) =

H(Xn|X −

n ) =

1
2
1
2

ln 2πeΣX ,

ln 2πeΣE,

(5a)

(5b)

from which the analytical formulation of the information
storage follows immediately:

SX =

1
2

ln

ΣX
ΣE

.

(6)

To compute the information storage according to Eq.
(6), we need to ﬁnd an expression for the process vari-
ance ΣX starting from the ARFI parameters d and A(L)
obtained as described in Sect. II.A (which allows com-
putation also of the innovation variance ΣE). To do this,
ﬁrst we approximate the ARFI process (1) with a ﬁnite
order AR process by truncating the fractional integration
part at a ﬁnite lag q:

(1 − L)d ≈ G(L) =

q
(cid:88)

k=0

GkLk,

(7)

so that the ARFI(p, d) process can be rewritten as an
AR(p + q) process:

B(L)Xn = En,

(8a)

B(L) = A(L)G(L) =

1 −

(cid:32)

p
(cid:88)

i=1

AiLi

(cid:33) q

(cid:88)

k=0

GkLk.

(8b)

3

The coeﬃcients of the AR polynomial B(L) = 1 −
p+q
(cid:80)
k=0
nomials in (8b), which in the case q ≥ p yields:

BkLk result from the multiplication of the two poly-

B0 = 1 ,

Bk =






−Gk +

−Gk +

p+q−k
(cid:80)
i=0

k
(cid:80)
i=1
p
(cid:80)
i=1

Gk−iAi,

k = 1, . . . , p

Gk−iAi,

k = p + 1, . . . , q

Gq−iAi+k−q,

k = q + 1, . . . , q + p

.

(9)

Once the ARFI process with parameters d and p is ap-
proximated by an AR process of order m = p + q, we
derive the expression for the process variance using the
theory of state space (SS) models [34]. The SS formula-
tion of the AR(m) process of Eq. (8) is given by

Zn+1 = BZn + KEn
Xn = CZn + En

(10a)
(10b)

where Zn = [Xn−1 · · · Xn−m+1Xn−m]T
the m-
dimensional state (unobserved) process and the vectors
K and C and the matrix B are deﬁned as:

is



B =






B1 . . . Bm−1 Bm
0
1 . . .
...
...
. . .
0
0 . . .
C = (cid:2)B1 . . . Bm−1 Bm

0
...
1

(cid:3)








, K =









1
0


...


0

(11)

The quantities in Eq. (11) are ﬁnally exploited to com-
pute analytically the process variance ΣX from the so-
lution of the following discrete-time Lyapunov equation
[34]:

Ω = BΩBT + ΣEK T K

ΣX = CΩC T + ΣE,

(12)

from which the information storage is computed using
Eq. (6).

C. Multiscale Information Storage

In this section we extend to multiple temporal scales
the computation of information storage for stochastic
processes which have an ARFI representation. To obtain
the rescaled version of a stochastic process at the tem-
poral scale deﬁned by the scale factor τ , the approach
originally designed in [10] corresponds to simply take the
average of the process over τ consecutive samples; this
procedure has been reﬁned later on [26, 35] by recogniz-
ing that it actually entails the two subsequent steps of

ﬁltering the process with a lowpass ﬁlter with cutoﬀ fre-
quency fτ = 1/(2τ ), and then downsampling the ﬁltered
process using a decimation factor τ . According to this
reﬁned method, we ﬁrst apply a linear ﬁnite impulse re-
sponse (FIR) ﬁlter to the original process Xn obtaining
the following ﬁltered process:

X (r)

n = D(L)Xn

,

(13)

where r denotes the ﬁlter order and the ﬁlter coeﬃcients
DkLk are chosen to set up a lowpass FIR con-
D(L) =

r
(cid:80)
k=0

ﬁguration with cutoﬀ frequency 1/2τ . The ﬁltering step
transforms the AR(m) process (which approximates the
original ARFI(p,d ) process) into an ARMA(m,r ) process
with moving average (MA) part determined by the ﬁlter
coeﬃcients:

B(L)X (r)

n = D(L)B(L)Xn = D(L)En

.

(14)

Then, we exploit the connection between ARMA pro-
cesses and state space processes [36] to evidence that the
ARMA process (14) can be expressed in SS form as:

Z (r)
n+1 = B(r)Z (r)
n = C (r)Z (r)
X (r)

n + K (r)E(r)
n
n + E(r)
n

(15a)

(15b)

n−1 · · · X (r)

n = [X (r)

where Z (r)
n−mEn−1 · · · En−r]T is the
(m + r)-dimensional state process, E(r)
n = D0En is the
SS innovation process, and the vectors K (r) and C (r) and
the matrix B(r) are given by:
C (r) = (cid:2)B1 · · · BmD1 · · · Dr
K (r) = (cid:2)1 01×(m−1) D−1
C (r)
Im−1
01×(m+r)
0(r−1)×m

01×(m+r) 0(r−1)×1

0(m−1)×(r+1)

0 01×(r−1)

B(r) =

Ir−1













(cid:3)

(cid:3)

(16)

with Ia and 0a×b indicating the a-dimensional
iden-
tity matrix and the null matrix of dimension a × b.
The parameters of the SS process are the three quan-
tities deﬁned in (16) and the variance of the innova-
tions ΣE(r) = D2
(15) deﬁnes an
0ΣE, whereby Eq.
SS(B(r), C (r), K (r), ΣE(r) ) process.

The second step of the rescaling procedure is to down-
sample the ﬁltered process in order to complete the mul-
tiscale representation. To do this, we make use of re-
cent theoretical ﬁndings showing that the downsampled
version of an SS process has itself an SS representation
[34, 37]. Here, downsampling the SS process (15) with a
factor τ yields the process X (τ )
nτ , which has the
following SS representation:

n = X (r)

Yn+1 = B(τ )Yn + Wn
n = C (τ )Yn + Vn
X (τ )

(17a)

(17b)

4

where Vn and Wn are diﬀerent white noise processes with
variances ΣW and ΣV and covariance ΣV W , respectively
serving as innovations for the downsampled process X (τ )
and for the state process Yn. Thus, the process (17) is an
SS(B(τ ), C (τ ), ΣW , ΣV , ΣV W ) process whose parameters
can be obtained as [34, 37]:
B(r)(cid:17)τ

B(τ ) =

(cid:16)

n

C (τ ) = C (r)
ΣV = ΣE(r)
(cid:16)

ΣV W =

ΣW (1) = ΣE(r)

K (r)ΣE(r)

B(r)(cid:17)τ −1
(cid:16)

K (r)(cid:17)T

ΣW (τ ) = B(r)ΣW (τ − 1)
K (r)(cid:17)T

+ ΣE(r)

(cid:16)

τ = 1

K (r),
B(r)(cid:17)T

(cid:16)

K (r),

τ ≥= 2

(18)

Then, the SS(B(τ ), C (τ ), ΣW , ΣV , ΣV W ) process can be
converted in a form similar to that of Eq.
(15)
which evidences
the innovations, yielding the SS
(B(τ ), C (τ ), K (τ ), ΣE(τ ) ) process:

Z (τ )
n+1 = B(τ )Z (τ )
n = C (τ )Z (τ )
X (τ )

n + K (τ )E(τ )
n
n + E(τ )
n ,

(19a)

(19b)

which provides the SS form of the ﬁltered and downsam-
pled version of the original ARFI(p, d) process. To move
from (17) to (19) it is necessary to consider a discrete
algebraic Ricatti equation [34, 37]:

P = B(τ )P(B(τ ))T + ΣW − (B(τ )PC (τ ) + ΣV W )·
· (C (τ )P(C (τ ))T + ΣV )−1(C (τ )P(B(τ ))T +
+ (ΣV W )T ),

(20)

which leads, after solving for P, to the derivation of the
two remaining parameters in (19):

ΣE(τ ) = C (τ )P(C (τ ))T + ΣV

K (τ ) =

B(τ )P(C (τ ))T + ΣV W
ΣV

.

(21a)

(21b)

Finally, the variance of the downsampled process can be
computed analytically solving a discrete-time Lyapunov
equation similar to that of Eq. (12)

Ω = B(τ )Ω(B(τ ))T + ΣE(τ ) (K (τ ))T K (τ )

ΣX (τ ) = C (τ )Ω(C (τ ))T + ΣE(τ )

(22a)

(22b)

The derivations above lead to compute analytically the
(19), which con-
parameters of the SS process of Eq.
stitutes a rescaled version derived through ﬁltering (Eq.
(15) ) followed by downsampling (Eq. (17) ) of the AR
(8)) of the original ARFI process
approximation (Eq.

(Eq.(1)). Among the SS parameters, the ones relevant for
the computation of the information storage are the vari-
ance of the downsampled process, ΣX (τ ), and the variance
of the corresponding innovations, ΣE(τ ) . These variances
can be combined in a similar way to that of Eq.
(6)
to yield the expression of the information stored in the
original process Xn when it is observed at scale τ :

SX (τ ) =

1
2

ln

ΣX (τ )
ΣE(τ )

.

(23)

III. SIMULATION STUDY

This section is devoted to assess the behavior of the
proposed multiscale measure of information storage in
stochastic processes with known dynamics. The behav-
ior is assessed both theoretically, computing the measure
for predetermined values of the parameters inﬂuencing
short term dynamics and long range correlations of lin-
ear stochastic processes, and numerically, studying the
performance of the adopted estimators from ﬁnite length
realizations of such processes.

A. Theoretical Analysis

Here we investigate the properties of multiscale infor-
mation storage by varying the parameters which deter-
mine the dynamics of ARFI processes. These parameters
are the diﬀerencing parameter d and the AR coeﬃcients
composing the polynomial A(L) in Eq. (1), which are
related to long range correlations and short-term dynam-
ics, respectively. Here, the strength of long-range corre-
lations was varied changing the parameter d in the set
{0, 0.05, 0.4, 0.7} so as to move from absent (d = 0) to
long lasting mean reverting (d = 0.7) memory eﬀects.
Moreover the AR coeﬃcients were set in order to gen-
erate stochastic oscillations with assigned frequency and
spectral radius. This was achieved setting pairs of com-
plex conjugate poles in the complex plane as the roots of
the AR polynomial, where the modulus (ρ) or the phase
(φ = 2πf , where f is the frequency) of the pole was
changed to reproduce varying strength and frequency of
the stochastic oscillations. Two conﬁgurations were con-
sidered: (a) an AR polynomial of order p = 2, with two
poles having ﬁxed frequency f = 0.1 Hz and varying
modulus ρ ∈ {0, 0.5, 0.8, 0.9}; (b) an AR polynomial of
order p = 4 with two pairs of poles, the ﬁrst with ﬁxed
modulus ρ1 = 0.8 and frequency f1 = 0.1 Hz, and the sec-
ond with ﬁxed modulus ρ2 = 0.8 and varying frequency
f2 ∈ {0.15, 0.2, 0.25, 0.3} Hz.

In each simulation, starting from the imposed theo-
retical values of the ARFI parameters, the analysis was
performed according to the procedures described in Sect.
II.B and II.C; the free parameters were set in accordance
with the literature, indicating q = 50 as an appropriate
value for truncating the ARFI process to a ﬁnite order

5

[38], and r = 48 as a viable choice for the order of the
lowpass ﬁlter used to implement the change of scale [25].
The results, obtained for time scales increasing from 1
to 50 (fτ decreasing from 0.5 to 0.01 Hz), are reported
in Figs. 1,2. In general, long range correlations tend to
bring information storage into the dynamic process, to
an extent proportional to the long memory of the pro-
cess:
indeed, for an assigned time scale τ , SX (τ ) tends
to increase at increasing the parameter d. This occurs
both at the original time scale (fτ = 0.5 Hz) and at
longer time scales, regardless of the type of the AR pro-
cess (Fig.1 and Fig. 2); the only exception is the pres-
ence of a strong stochastic oscillation (ρ = 0.9 in Fig. 1),
where an increase of d corresponds to a decrease of SX
at the original time scale. This ﬁnding has an implica-
tion for the evaluation of entropy measures on dynamic
processes in which short term dynamics coexist with long
range correlations [30, 39]. In these situations one should
remember that, since long memory properties have an im-
portant eﬀect on the dynamics, such properties should be
accounted for to make a proper evaluation of the com-
plexity of the observed process; if one is interested in
short-term complexity only [9], long-range correlations
should be removed prior to entropy analysis [30].

FIG. 1. Theoretical proﬁles of multiscale information stor-
age for simulated ARFI processes with varying amplitude of
stochastic oscillations. Plots depict the information storage
SX computed as a function of the cutoﬀ frequency fτ of the
lowpass ﬁlter used to change the time scale for an ARFI pro-
cess characterized by two complex conjugate poles with ﬁxed
phase φ = 2π0.1 and variable modulus ρ = 0 (a), ρ = 0.5
(b), ρ = 0.8 (c), and ρ = 0.9 (d), and variable diﬀerencing
parameter d = 0, 0.05, 0.4, 0.7.

Another general result is that the information storage

6

We investigated also the eﬀects of the approximation
of the ARFI process with a ﬁnite order AR process, ob-
tained setting a ﬁxed value for the parameter q (see Eq.
(7)). Fig. 3 reports the curves of multiscale informa-
tion storage obtained in four representative AR parame-
ter settings when assessed by the typical value q = 50 [38]
(solid lines) and with the reduced value q = 10 (dashed
lines). Overall, we note that excessive truncation leads
to an underestimation of the information storage and to
smooth of non-monotonic trends of the storage with the
time scale. The bias is more evident for higher values of
the diﬀerencing parameter d at long time scales (lower
fτ ). Therefore, high values of the parameter q are rec-
ommended to obtain a good approximation of the long
memory properties of the observed process, so to limit
the negative bias of information storage and to preserve
the ability to discern multiscale patterns.

tends to decrease at decreasing fτ , as a result of the fact
that lengthening the time scale corresponds to removing
regular oscillatory components and making the process
more complex (i.e., less predictable); at very long time
scales the process is left with no predictable dynamics
and SX decays to zero. While the decrease of SX with
the time scale is monotonic in the absence of long range
correlations (see the curves with d = 0 in Figs. 1,2), the
simultaneous presence of short and long memory eﬀects
may complicate the multiscale behavior of information
storage. In fact, the ARFI process tends to store more
information at intermediate time scales (fτ ≈ 0.05 Hz)
than at lower time scales when long range correlations
occur simultaneously with an appreciable stochastic os-
cillation (d = 0.4, 0.7 and ρ = 0.8, 0.9, Fig. 1), or with a
mismatch between the frequencies of two stochastic os-
cillations with the same amplitude (Fig. 2). These pat-
terns were not revealed by the utilization of multiscale
complexity measures not accounting for long range cor-
relations [25]. Therefore, it seems that the multiscale
evaluation of complexity may beneﬁt from the use of an
approach able to model dynamical eﬀects occurring at
diﬀerent temporal scales such as short and long range
correlations.

FIG. 2. Theoretical proﬁles of multiscale information stor-
age for simulated ARFI processes with varying frequency of
stochastic oscillations. Plots depict the information storage
SX computed as a function of the cutoﬀ frequency fτ of the
lowpass ﬁlter used to change the time scale for an ARFI pro-
cess characterized by a pair of complex conjugate poles with
ﬁxed modulus and phase (ρ1 = 0.8, φ1 = 2π0.1), and another
pair of complex conjugate poles with ﬁxed modulus ρ2 = 0.8
and variable phase φ2 = 2πf2, where f2 = 0.15 (a), f2 = 0.2
(b), f2 = 0.25 (c), and f2 = 0.3 Hz (d), as well as variable
diﬀerencing parameter d = 0, 0.05, 0.4, 0.7.

FIG. 3.
Dependence of the theoretical proﬁles of multi-
scale information storage on the approximation of a simulated
ARFI process with a ﬁnite-order AR process. Plots depict the
information storage SX computed as a function of the cutoﬀ
frequency fτ of the lowpass ﬁlter used to change the time
scale for an ARFI process characterized by two complex con-
jugate poles with phase φ = 2π0.1 and modulus ρ = 0 (a) or
ρ = 0.8 (b), or by two pairs of complex conjugate poles with
modulus ρ1 = ρ2 = 0.8 and phases φ1 = 2π0.1, φ2 = 2π0.15
(c) or φ1 = 2π0.1, φ2 = 2π0.3 (d). In each panel, results are
plotted for values of the diﬀerencing parameter d = 0, 0.4, 0.7
and two values for the truncation parameter: q = 10 (dashed
lines) and q = 50 (solid lines).

B. Finite Sample Performance

Here we describe the practical estimation of multiscale
information storage computed for the processes simulated
as in Sect. III.A. The focus of this analysis was on as-
sessing the computational reliability of the proposed esti-
mator in comparison with two alternative approaches for
the multiscale assessment of dynamical complexity: (i)
linear multiscale analysis, based on performing pure AR
identiﬁcation without the modeling of long range corre-
lations [25], and (ii) reﬁned multiscale entropy analysis,
based on computing entropy measures after the practical
implementation of rescaling executed through the appli-
cation of a lowpass ﬁlter followed by downsampling [26].
The analysis was performed for a representative example
of the simulation described above, where the AR poly-
nomial was obtained from a pair of complex conjugate
poles with modulus ρ = 0.8 and frequency f = 0.1 Hz,
and for values of the fractional diﬀerencing parameter
d ∈ {0, 0.4, 0.7}. In each analyzed case, 100 realizations
of the simulation were generated deriving the polyno-
mial G(L) according to Eq. (2), truncating it to q = 50
terms (Eq. (7)), and feeding the model of Eq. (8) with
independent samples drawn from the standard normal
distribution. Then, for each realization, multiscale in-
formation storage analysis was performed for time scales
τ = 1, . . . , 50 (fτ = 0.5, . . . , 0.01 Hz): (i) according to the
procedure described in Sect. II (ARFI identiﬁcation), ap-
plying a FIR lowpass ﬁlter of order r = 48; (ii) according
to linear multiscale complexity analysis, i.e.
following
the procedure of Sect. II but after forcing d = 0 in Eq.
(6) (AR identiﬁcation); (iii) according to reﬁned multi-
scale complexity analysis, i.e. ﬁltering the time series
with a 6th order Butterworth lowpass ﬁlter, resampling
the ﬁltered series with a downsampling factor equal to τ ,
and computing Sample Entropy [7] on the downsampled
time series with standard parameter setting (embedding
dimension m = 2, similarity tolerance r = 0.2ΣE(τ ) ). To
allow comparison, the complexity measures CX (τ ) de-
rived from the complexity analyses (ii) and (iii) were con-
verted into values of information storage exploiting the
equivalence SX (τ ) = 0.5 ln 2πe − CX (τ ) that holds for
Gaussian processes. All estimates were compared also
with the exact patterns of multiscale information storage
obtained from the true values of the parameters.

First, we compared the distribution of SX (τ ) estimated
from realizations of N = 300 samples with its theoreti-
cal values for the three estimation approaches. The re-
sults depicted in Fig. 4 show that all approaches return
a biased estimate of the information storage, with the
bias generally increasing with the diﬀerencing parameter
d and with the time scale τ . The bias is limited with the
proposed approach based on ARFI models, as the true
values of SX is contained within the dispersion interval of
10th −90th percentiles of the estimates (Fig. 4a,d,g). The
linear multiscale method based on pure AR identiﬁcation
is highly biased, in the presence of long range correlations
(Fig. 4e,h), at intermediate time scales (fτ ≤ 0.1 Hz) and

7

becomes unreliable at longer time scales (fτ ≤ 0.05 Hz),
returning very low values of information storage. Never-
theless, this method is highly reliable in the absence of
long-range correlations (Fig. 4b), performing even better
than the ARFI estimator which shows a certain bias (Fig.
4a); this small bias can be related to the variability in the
estimation of the parameter d, which in turn shows non-
negligible bias and variance for these estimates obtained
with N = 300 (the estimation improves for longer time
series, results not shown). On the other hand, the tra-
ditional approach based on multiscale complexity analy-
sis is highly unreliable at increasing time scales, as the
estimates of SX are strongly biased, display a variance
that grows dramatically with the time scale, and could
not even be computed for fτ ≤ 0.1 Hz. These results
document the necessity of the proposed approach based
on ARFI models to capture the dynamical complexity of
processes showing both stochastic oscillations and long
memory properties.

FIG. 4. Estimation of multiscale information storage over
ﬁnite length realizations of simulated ARFI processes. Plots
depict the theoretical values (red) and the distributions (me-
dian and 10th − 90th percentiles (dispersion interval, D.I.)
over 100 realizations) of the information storage SX computed
as a function of the cutoﬀ frequency fτ of the lowpass ﬁlter
used to change the time scale for an ARFI process character-
ized by two complex conjugate poles with modulus and phase
ρ = 0.8, φ = 2π0.1 for values of the diﬀerencing parameters
d = 0 (a,b,c), d = 0.4 (d,e,f) and d = 0.7 (g,h,i), using the pro-
posed ARFI method (a,d,g), the linear multiscale AR method
[25] (b,e,h), and the reﬁned multiscale complexity approach
[26] (c,f,i).

Next, we studied the dependence of the estimates of in-
formation storage on the sample size, repeating the anal-
yses described above for time series of diﬀerent length
in the range N ∈ {300, 512, 1024, 2048, 4096}. As shown

in Fig. 5, a general expected result is that the bias of
SX decreases at increasing the time series length. The
improvement is such that the measure based on ARFI
models becomes progressively more accurate at all time
scales (Fig. 5a,d,g), while it does not help to obtain
a good approximation of SX at long time scales for the
measure based on AR models (Fig. 5e,h). As to the mea-
sure based on multiscale complexity, the improvement
brought by analyzing longer time series is only slight and
not always clear (Fig. 5c,f,i), conﬁrming the unsuitability
of model-free approaches to assess dynamical complexity
at long time scales.

FIG. 5. Estimation of multiscale information storage as a
function of the length of simulated ARFI processes. Plots
depict the theoretical values (red) and the average estimated
values (median over 100 realizations, other colors) of the in-
formation storage SX computed as a function of the cutoﬀ
frequency fτ of the lowpass ﬁlter used to change the time
scale for an ARFI process characterized by two complex con-
jugate poles with modulus and phase ρ = 0.8, φ = 2π0.1 for
values of the diﬀerencing parameters d = 0 (a,b,c), d = 0.4
(d,e,f) and d = 0.7 (g,h,i), using the proposed ARFI method
(a,d,g), the linear multiscale AR method [25] (b,e,h), and the
reﬁned multiscale complexity approach [26] (c,f,i).

IV. APPLICATION TO PHYSIOLOGICAL
PROCESSES

This section reports the application of multiscale in-
formation storage in the ﬁeld of cardiovascular and car-
diorespiratory physiology. In this ﬁeld, it is well known
that the dynamics of the cardiac, vascular and respira-
tory systems, typically assessed from the variability se-
ries of the heart period (HP), systolic arterial pressure
(SAP) and lung volume (LV), reﬂect the activity of phys-

8

iological mechanisms operating across multiple temporal
scales.
In particular, the assessment of HP and SAP
dynamics over temporal scales ranging from seconds to a
few minutes allows the detection of short-term cardiovas-
cular regulation, and is typically accomplished through
complexity measures like approximate entropy and Sam-
ple Entropy [5, 7], or even using the information stor-
age [15, 40]. On the other hand, it is also known that
cardiovascular oscillations exhibit long-range correlations
properties that are manifested in scaling behavior and
power law correlations which are commonly assessed us-
ing fractal techniques [23, 28]. Given this coexistence
of short-term dynamics and long-range correlations, the
evaluation of the dynamical complexity of cardiovascular
and respiratory processes remains a challenge that can be
thoroughly faced only employing multiscale approaches.
Here we investigate how the dynamical complexity of
HP, SAP and LV, assessed with our measure of infor-
mation storage quantiﬁed from ARFI processes, varies
across multiple time scales reﬂecting separate but simul-
taneously active physiological mechanisms. Moreover we
address the issue of quantifying the impact of long-range
correlations, typically manifested in short cardiovascular
time series in terms of slow trends superimposed to the
short-term dynamics, on the values of information stor-
age computed from short cardiovascular recordings.

A. Experimental Protocol and Measurement of
Physiological Time series

We consider the time series of HP, SAP and LV, inter-
preted as realizations of the stochastic processes descrip-
tive of the cardiac, vascular and respiratory dynamics,
measured in a group of 61 healthy subjects (17.5 ± 2.4
years old, 37 females) monitored in the resting supine
position (SU) and in the upright position (UP) reached
through passive head-up tilt [41]. The acquired signals
were the surface electrocardiogram (ECG), the ﬁnger ar-
terial blood pressure recorded noninvasively by the pho-
toplethysmographic method, and the respiration signal
recorded through respiratory inductive plethysmography.
For each subject and experimental condition, the values
of HP, SAP and LV were measured on a beat-to-beat ba-
sis respectively as the sequences of the temporal distances
between consecutive R peaks of the ECG, the maximum
values of the arterial pressure waveform taken within the
consecutively detected heart periods, and the values of
the respiratory signal sampled at the onset of the con-
secutively detected heart periods. A detailed description
of experimental protocol and signal measurement is re-
ported in Ref. [41].

The analysis was performed on segments of N = 300
consecutive points, free of artifacts and deemed as weak-
inspection, extracted
sense stationary through visual
from the time series for each subject and condition.
Three diﬀerent approaches were followed to compute
multiscale information storage: (i) the eAR approach,

based on pure AR model identiﬁcation, i.e. performing
the whole procedure described in Sect. II after forcing
d =0 in Eq. (6); (ii) the eARd approach, based on pure
AR identiﬁcation as in (i), but applied to the ﬁltered
data X (f )
n = (1 − L)dXn, after estimating the parameter
d from the original time series; (iii) the eARFI approach,
based on complete ARFI model identiﬁcation, i.e., fol-
lowing the whole procedure described in Sect. II with d
estimated from the original time series and considered in
the computations. Pursuing these approaches we com-
pare, respectively, (i) the traditional complexity analysis
where long-range correlations are neither removed nor
modeled, (ii) the analysis performed only on the short-
term dynamics after removing long-range correlations,
and (iii) the complexity analysis performed by model-
ing the long range correlations and considering them to-
gether with the short-term dynamics. Such a comparison
is meant to infer the role of long-range correlations vs.
that of short-term dynamics in contributing to the infor-
mation storage and to its variation between conditions.
The ARFI model ﬁtting each individual time series
was identiﬁed ﬁrst estimating the fractional diﬀerencing
parameter d using the Whittle estimator, then ﬁltering
the time series with the fractional integration polynomial
truncated at a lag q = 50, and ﬁnally estimating the pa-
rameters of the polynomial relevant to the short-term
dynamics through least squares AR identiﬁcation. The
AR model order p was selected as the minimum of the
BIC ﬁgure of merit [42] in the range 2-16. Then, mul-
tiscale information storage was computed implementing
a FIR lowpass ﬁlter of order r = 48, for time scales τ
in the range (1,. . . ,400), which corresponds to lowpass
cutoﬀ frequencies fτ = (0.5, ..., 0.00125) Hz.

Here the eﬀects of SU and UP conditions on the infor-
mation storage proﬁles are assessed at any assigned time
scale by means of paired comparisons.

B. Results and Discussion

The results of the multiscale computation of informa-
tion storage for the HP, SAP and LV time series are de-
picted respectively in Figs. 6, 7, and 8, reporting the dis-
tribution across subjects of the index SX (left column)
computed following the eAR (ﬁrst row), eARd (second
row) and eARFI (third row) estimation approaches and
evaluated as a function of the time scale in the two an-
alyzed physiological states (SU and UP). In each ﬁgure,
results of the statistical analysis are also visualized (right
column) reporting the mean and 95% conﬁdence intervals
of the paired diﬀerence between the values of SX com-
puted in the UP and SU conditions; a statistically sig-
niﬁcant variation from SU to UP is detectable at a given
time scale if the conﬁdence intervals do not encompass
the zero line.

Fig. 6 reports the results of multiscale information
storage analysis for the HP time series. Using the eAR
method whereby long range correlations are not modeled

9

(Fig. 6a), at scale 1 (fτ = 0.5) the information stored in
the HP process is signiﬁcantly higher in the UP condition
compared with SU. This reﬂects a widely known behav-
ior of heart rate variability, whose complexity is known
to decrease with head-up tilt due to an activation of the
sympathetic nervous system which has a regularizing ef-
fect on the cardiac dynamics [43, 44]. Higher values of SX
during orthostatic stress are observed also at increasing
the time scale, and are detectable up to fτ ∼ 0.1 Hz (Fig.
6b), reﬂecting the results obtained in Ref.
[25] where a
lower multiscale entropy is detected in the same data.
Here we see also that the tilt-induced increase of the in-
formation storage is present also when the slow trends
aﬀecting HP, likely due to long-range correlations, are
ﬁltered out using the eARd method (Fig.6c); in this case
the increase of SX from SU to UP is signiﬁcant also for
intermediate time scales (0.05 Hz < fτ < 0.1 Hz, Fig.
6d)). This behavior is less evident when long range cor-
relations are modeled, as SX increases during UP only at
scale 1, and is even reverted at longer time scales, as SX
decreases during UP for 0.01 Hz < fτ < 0.1 Hz (Fig.6e,f).
This behavior, documenting that the complexity of heart
rate variability increases during tilt if observed at long
time scales, has been previously observed using multi-
scale entropy [45]. Here, it becomes visible only model-
ing long-range correlations through the eARFI approach
and indicates that long-range correlations are likely less
important during head-up tilt. Thus, the utilization of
the modeling approach proposed in this study suggests
that postural stress augments the capability of HP to
store information at low time scales but also diminish
such capability at longer time scales.

Fig. 7 reports the results of multiscale information
storage analysis for the SAP time series. According to
the eAR method (Fig. 7a,b), moving from SU to UP
the index SX increases signiﬁcantly at scale 1 (fτ = 0.5
Hz) and decreases signiﬁcantly at scale 2 (fτ = 0.25 Hz),
conﬁrming in terms of information storage the results
reported in Ref. [25] based on a linear complexity mea-
sure. These two opposite behaviors of the information
stored in the SAP process are here explained in terms of
long-range correlations, which are removed or explicitly
considered respectively through detrending or through
performing ARFI identiﬁcation.
In fact, according to
the eARd method (Fig. 7c,d), SX is still signiﬁcantly
higher during UP when fτ = 0.5 Hz, but is not signiﬁ-
cantly diﬀerent from SU for any other value of fτ . On
the contrary, according to the eARFI method (Fig. 7e,f),
SX does not show signiﬁcant diﬀerences between SU and
UP when fτ = 0.5 Hz, but is signiﬁcantly smaller when
fτ = 0.25 Hz. These results suggest that the higher ca-
pability of SAP to store information during tilt observed
at scale 1 is related exclusively to short-term dynamics,
while the lower storage capability observed at intermedi-
ate scales (fτ ∼ 0.25 Hz, where respiration-related com-
ponents are suppressed) is driven by long-range correla-
tions. Thus, head-up tilt induces scale-dependent varia-
tions in the complexity of arterial pressure, with higher

10

FIG. 6. Multiscale Information Storage for the heart period
time series. Plots report the conﬁdence interval (C.I.) for the
mean of the index of information storage computed across
subjects using the eAR approach (a), the eARd method (c)
and the eARFI method (e) as a function of the cutoﬀ fre-
quency of the rescaling ﬁlter in the supine (SU) and upright
(UP) body positions. For each estimation method, the paired
C.I. of UP−SU are also plotted in panels (b,d,f).

FIG. 7. Multiscale Information Storage for the systolic pres-
sure time series. Plots report the conﬁdence interval (CI) for
the mean of the index of information storage computed across
subjects using the eAR approach (a), the eARd method (c)
and the eARFI method (e) as a function of the cutoﬀ fre-
quency of the rescaling ﬁlter in the supine (SU) and upright
(UP) body positions. For each estimation method, the paired
CI of UP−SU are also plotted in panels (b,d,f).

complexity (lower SX ) associated with slow oscillations,
and lower complexity (higher SX ) associated to the ef-
fects of respiration.

Fig. 8 reports the results of multiscale information
storage analysis for the RESP time series. In this case
we ﬁnd that, using all methods, at short time scales the
respiration process stores more information during UP
than during SU, while at longer time scales the amount
of information stored in the process does not change sig-
niﬁcantly with head-up tilt. This larger regularity of the
respiration dynamics and its multiscale behavior conﬁrm
previous ﬁndings [8, 25], further suggesting that long-
range correlations do not have signiﬁcant inﬂuence on the

complexity of respiratory patterns. These results may be
expected since respiration is usually strongly evident in
the so-called high-frequency band (> 0.15 Hz) [46] and
is thus ﬁltered out almost entirely for time scales ≥ 2.

To further elucidate the role played by long-range cor-
relations in determining the information stored in the
considered processes, we analyze the values of the diﬀer-
encing parameter d computed in the various conditions
using the Whittle semi-parametric estimator [31]. Fig. 9
reports, for any given process and condition, the individ-
ual values of d plotted for each of the analyzed subjects,
together with their 95th conﬁdence intervals relevant to
the zero level (derived from the asymptotic statistic given

11

icantly diﬀerent for RESP (p = 0.377). These changes
correspond to situations in which the eARFI method de-
tects a statistically signiﬁcant decrease of the informa-
tion storage at intermediate/long time scales (Fig. 6 and
Fig. 7). This suggests that when the importance of long-
range correlations decreases for a time series (lower d),
the slow dynamics of the series become more complex
(lower SX ), supporting the argument that long-range cor-
relations play a regularizing role for the process dynamics
[30].

FIG. 8. Multiscale Information Storage for the respiratory
time series. Plots report the conﬁdence interval (CI) for the
mean of the index of information storage computed across
subjects using the eAR approach (a), the eARd method (c)
and the eARFI method (e) as a function of the cutoﬀ fre-
quency of the rescaling ﬁlter in the supine (SU) and upright
(UP) body positions. For each estimation method, the paired
CI of UP−SU are also plotted in panels (b,d,f).

by Eq. (6) of Ref.
[47]). We ﬁnd that the diﬀerencing
parameter computed for the HP series and for the SAP
series is statistically signiﬁcant (i.e., outside of the con-
ﬁdence intervals) in a lower number of subjects in the
UP condition (Fig. 9b,d) compared with SU (Fig. 9a,c);
this seems not to be the case for the RESP time series
(Fig. 9e vs. Fig. 9f). These results are conﬁrmed by
the application of a Student t-test for paired data ap-
plied to the distributions of SX computed during SU and
during UP, which returns p−values lower than the crit-
ical 0.05 level for HP and SAP (respectively p = 0.0037
and p = 0.0192), while the distributions were not signif-

FIG. 9. Values of the diﬀerencing parameter d estimated
for each subject (index 1,...,61) for the heart period (a,b),
systolic pressure (c,d) and respiration (e,f) time series in the
supine (SU, a,c,e) and upright (UP, b,d,f) body positions.
Each panel reports also the 95th conﬁdence intervals (solid
lines) of the distribution of d computed around the zero level
(dashed line).

V. CONCLUSIONS

We have introduced an approach to assess across mul-
tiple temporal scales the amount of information stored in

a dynamic process, intended as the degree to which infor-
mation is preserved in a time-evolving dynamical system
in a way such that it can be retrieved from the past sys-
tem states. Thanks to its parametric formulation, the
proposed approach inherits the computational reliability
of linear multiscale entropy [25], exploiting it for the as-
sessment of regularity and most importantly allowing
the simultaneous description of short-term dynamics and
long memory properties. Our simulations show that the
state space formulation implemented here, though being
restricted to the description of linear dynamics, outper-
forms model-free multiscale complexity analysis [26] and,
thanks to the incorporation of long-range correlations,
leads to a more reliable evaluation of the information
storage at long time scales if compared with linear mul-
tiscale entropy [25].

Since long-range correlations are a fundamental aspect
of multiscale dynamics, the present work opens the ways
to a reliable computation of the dynamical complexity of
several natural and man-made processes where diﬀerent
mechanisms coexist, operating across multiple temporal
scales. Here, the application to cardiovascular dynam-
ics led to unprecedented physiological results, such as

12

the observation that, at temporal scales compatible with
sympathetic neural activity, postural stress blunts the ca-
pability of heart rate and arterial pressure variability to
actively store information.

Future developments should focus on extending the
formulations proposed in this work to the multiscale rep-
resentation of vector ARFI models, in order to attain a
complete decomposition across time scales of the other
constitutive elements of information processing in dy-
namical networks, i.e.
information transfer and infor-
mation modiﬁcation [16, 17].

ACKNOWLEDGMENTS

Work partially supported by UID/MAT/00144/2013
(CMUP), UID/MAT/04106/2013 (CIDMA), which are
funded by FCT with national (MEC) and European
structural
funds through the program FEDER, un-
der PT2020, and project STRIDE-NORTE-01-0145-
FEDER-000033 funded by ERDF-NORTE 2020.

[1] J. F. Donges, Y. Zou, N. Marwan,

and J. Kurths,
The European Physical Journal Special Topics 174, 157
(2009).

[2] J. B. Rosser, Journal of economic Perspectives 13, 169

(1999).

[3] D. R. Chialvo, Nature physics 6, 744 (2010).
[4] D. Kaplan, M. Furman, S. Pincus, S. Ryan, L. Lipsitz,
and A. Goldberger, Biophysical journal 59, 945 (1991).
[5] S. M. Pincus, Proceedings of the National Academy of

Sciences 88, 2297 (1991).

[6] A. Porta, G. Baselli, D. Liberati, N. Montano,
and

C. Cogliati, T. Gnecchi-Ruscone, A. Malliani,
S. Cerutti, Biological cybernetics 78, 71 (1998).

[7] J. S. Richman and J. R. Moorman, American Jour-
nal of Physiology-Heart and Circulatory Physiology 278,
H2039 (2000).

[8] M. Valente, M. Javorka, A. Porta, V. Bari, J. Krohova,
B. Czippelova, Z. Turianikova, G. Nollo, and L. Faes,
Physiological measurement 39, 014002 (2018).

[9] A. Porta, P. Castiglioni, M. D. Rienzo, V. Bari, T. Bas-
sani, A. Marchi, A. C. Takahashi, E. Tobaldini, N. Mon-
tano, A. M. Catai, et al., Journal of Applied Physiology
113, 1810 (2012).

[10] M. Costa, A. L. Goldberger, and C.-K. Peng, Phys. Rev.

Lett. 89, 068102 (2002).

[11] S. M. Pincus, Mathematical biosciences 122, 161 (1994).
[12] A. L. Goldberger, C.-K. Peng, and L. A. Lipsitz, Neu-

robiology of aging 23, 23 (2002).

[13] A. Porta, S. Guzzetti, R. Furlan, T. Gnecchi-Ruscone,
and A. Malliani, IEEE Transactions on

N. Montano,
Biomedical Engineering 54, 94 (2007).

[14] S. Erla, L. Faes, E. Tranquillini, D. Orrico, and G. Nollo,

Medical engineering & physics 33, 504 (2011).

[16] J. T. Lizier, M. Prokopenko, and A. Y. Zomaya, Infor-

mation Sciences 208, 39 (2012).

[17] M. Wibral, J. Lizier, S. V¨ogler, V. Priesemann,

and

R. Galuske, Frontiers in neuroinformatics 8, 1 (2014).
[18] M. G. Kitzbichler, M. L. Smith, S. R. Christensen, and
E. Bullmore, PLoS computational biology 5, e1000314
(2009).

[19] J. Boedecker, O. Obst, N. M. Mayer, and M. Asada,

HFSP journal 3, 340 (2009).

[20] N. Ay, N. Bertschinger, R. Der, F. G¨uttler, and E. Ol-
brich, The European Physical Journal B 63, 329 (2008).
[21] L. Faes, A. Porta, G. Rossato, A. Adami, D. Tonon,
A. Corica, and G. Nollo, Autonomic Neuroscience 178,
76 (2013).

[22] L. Faes, A. Porta, G. Nollo, and M. Javorka, Entropy

19, 5 (2016).

[23] P. C. Ivanov, L. A. N. Amaral, A. L. Goldberger,
S. Havlin, M. G. Rosenblum, Z. R. Struzik, and H. E.
Stanley, Nature 399, 461 (1999).

[24] J. Wang, P. Shang, X. Zhao, and J. Xia, International
Journal of Modern Physics C 24, 1350006 (2013).
[25] L. Faes, A. Porta, M. Javorka, and G. Nollo, Complexity

2017 (2017).

[26] J. Valencia, A. Porta, M. Vallverd´u, F. Clari´a, R. Bara-
nowski, E. Or(cid:32)lowska-Baranowska, and P. Caminal, IEEE
Trans. Biomed. Eng. 56, 2202 (2009).

[27] A. Humeau-Heurtier, Entropy 17, 3110 (2015).
[28] P. Bernaola-Galv´an, P. C. Ivanov, L. A. N. Amaral, and
H. E. Stanley, Physical review letters 87, 168105 (2001).
[29] Z. Chen, K. Hu, P. Carpena, P. Bernaola-Galvan, H. E.
Stanley, and P. C. Ivanov, Physical Review E 71, 011104
(2005).

[30] W. Xiong, L. Faes, and P. C. Ivanov, Physical Review

[15] L. Faes, A. Porta, and G. Nollo, Entropy 17, 277 (2015).

E 95, 062114 (2017).

13

[31] J. Beran, Y. Feng, S. Ghosh, and R. Kulik, Statistics
for Long-Memory Processes: Probabilistic Properties and
Statistical Methods (Springer, 2012).

[41] M. Javorka, B. Czippelova, Z. Turianikova, Z. Lazarova,
I. Tonhajzerova, and L. Faes, Medical & biological engi-
neering & computing 55, 179 (2017).

[32] L. Faes, S. Erla, and G. Nollo, Computational and math-

[42] P. Stoica and Y. Selen, IEEE Signal Processing Magazine

ematical methods in medicine 2012 (2012).

21, 36 (2004).

[33] T. M. Cover, J. A. Thomas, and J. Kieﬀer, SIAM Review

36, 509 (1994).

[34] L. Barnett and A. K. Seth, Phys. Rev. E 91, 040101

(2015).

[35] L. Faes, G. Nollo, S. Stramaglia,

and D. Marinazzo,

Physical Review E 96, 042150 (2017).

[36] M. Aoki and A. Havenner, Econ. Rev. 10, 1 (1991).
[37] V. Solo, Neural computation 28, 914 (2016).
[38] J.-M. Bardet, G. Lang, G. Oppenheim, A. Philippe, and
M. S. Taqqu, Theory and applications of long-range de-
pendence , 579 (2003).

[39] C. W. Granger and R. Joyeux, Journal of time series

analysis 1, 15 (1980).

[40] D. Widjaja, A. Montalto, E. Vlemincx, D. Marinazzo,
and L. Faes, PLoS One 10, e0129112

S. Van Huﬀel,
(2015).

[43] A. Porta, B. De Maria, V. Bari, A. Marchi, and L. Faes,
IEEE Transactions on Biomedical Engineering 64, 1287
(2017).

[44] A. Porta, T. Gnecchi-Ruscone, E. Tobaldini, S. Guzzetti,
R. Furlan, and N. Montano, Journal of applied physiol-
ogy 103, 1143 (2007).

[45] Z. Turianikova, K. Javorka, M. Baumert, A. Calkovska,
and M. Javorka, Physiological measurement 32, 1425
(2011).

[46] A. Camm, M. Malik, J. Bigger, G. Breithardt, S. Cerutti,
R. Cohen, P. Coumel, E. Fallen, H. Kennedy, R. Kleiger,
et al., Circulation 93, 1043 (1996).

[47] A. Leite, A. Paula Rocha, and M. Eduarda Silva, Chaos:
An Interdisciplinary Journal of Nonlinear Science 23,
023103 (2013).

