0
2
0
2

g
u
A
8
1

]

C
H
.
s
c
[

1
v
9
4
6
1
0
.
9
0
0
2
:
v
i
X
r
a

Augmented Reality Chess Analyzer
(ARChessAnalyzer): In-Device Inference of
Physical Chess Game Positions through Board
Segmentation and Piece Recognition using
Convolutional Neural Networks

Anav Mehta
Cupertino High School
Cupertino, CA, USA

September 4, 2020

Abstract

Chess game position analysis is important in improving ones game. It requires
entry of moves into a chess engine which is, cumbersome and error prone. We
present ARChessAnalyzer, a complete pipeline from live image capture of a phys-
ical chess game, to board and piece recognition, to move analysis and ﬁnally to
Augmented Reality (AR) overlay of the chess diagram position and move on the
physical board. ARChessAnalyzer is like a scene analyzer - it uses an ensemble of
traditional image and vision techniques to segment the scene (ie the chess game)
and uses Convolution Neural Networks (CNNs) to predict the segmented pieces
and combine it together to analyze the game. This paper advances the state of the
art in the ﬁrst of its kind end to end integration of robust detection and segmentation
of the board, chess piece detection using the ﬁne-tuned AlexNet CNN and chess
engine analyzer in a handheld device app. The accuracy of the entire chess position
prediction pipeline is 93.45% and takes 3-4.5sec from live capture to AR overlay.
We also validated our hypothesis that ARChessAnalyzer, is faster at analysis than
manual entry for all board positions for valid outcomes. Our hope is that the in-
stantaneous feedback this app provides will help chess learners worldwide at all
levels improve their game.

 
 
 
 
 
 
1

Introduction

For a player to improve ones chess game, its important to record the moves, so that you
can analyze the game later perhaps in the chess club either with a coach or using an
online chess engine. The recording of moves during a chess game is a tedious manual
task that is error prone and impedes the ﬂow of the game and also hinders eﬃcient
use of time.
Instead, imagine if, you can capture a live image of the game, detect
the board and all the pieces, predicting the board position and analyze it to provide
immediate feedback of the best move available to the player. In an age when much
analysis and storage of chess games is done on computers, chess players at all levels can
beneﬁt from the ability to analyze a game immediately by taking a picture of a real-life
board, as opposed to manual input. This paper describes exactly that novel approach of
identifying the chess position and next move through the simple means of live picture.
This advances several technologies board and piece detection and ties them together on
a mobile device to generate a position for a chess engine to analyze the best best move
to display on an augmented reality overlay.

Advances in powerful algorithms and hardware computing units, have allowed for
deep learning algorithms to solve a wide variety of tasks which were previously deemed
diﬃcult for computers to tackle. Challenging problems such as playing strategic games
like Go and poker, and visual object recognition [1] are now possible using modern com-
pute environments. A type of artiﬁcial neural network, called a Convolutional Neural
Network (CNN), has demonstrated capabilities for highly accurate image classiﬁcation
after being trained on a large data set of samples [3].

In the ﬁrst part of the detection pipeline, a simple binary image classiﬁer is built to
detect a chessboard, and image and vision techniques from OpenCV library are used to
segment the board. The popular deep CNN architecture, AlexNet [4] - the winner of the
2012 ImageNet Large Scale Visual Recognition Competition, is ﬁne-tuned with a data
set of chess pieces. This model is used for piece recognition from the segmented board.
The output of the piece detector - a a Forsyth–Edwards Notation(FEN) [9] position string
- is used by the popular chess engine Stockﬁsh [2] for analysis, and ﬁnally the best move
from the engine is https://www.overleaf.com/project/5e850192a900400001e484ecoverlayed
along with the chess diagram on the physical board. This ensemble of algorithms is
integrated in an iOS mobile app in that is an augmented reality chess analysis engine.
The app provides immediate feedback and helping chess players with their game.

The remainder of this paper is organized as follows. We will ﬁrst cover the previous
research work and then discuss the implementation and our unique contributions of the
diﬀerent pieces of ARChessAnalyzer pipeline. Finally, we present the app development
details, discuss the experimental setup, results and conclusions.

2 Previous Work

Chess position detection can be broadly separated into two areas. The ﬁrst, board
recognition and segmentation, refers to the detection of the chess board within the
image and segmentation of the board into 64 images. This is a prerequisite to the
second step - piece recognition which is a classiﬁcation of those images - as empty or
any of the 12 categories of chess pieces.

2.1 Chessboard Recognition and Segmentation

Chessboard detection has traditionally been solved in the context of camera calibration
using hints such as marking the corners at the expense of its versatility. There have
also been dedicated hardware attempts for chessboard detection [5]. Recent computer
vision advances have led to general techniques for board recognition can be separated
into corner-based or line-based approaches [6]. Corner-based approaches identify
the corners of the chess board, then either perform Hough transforms to identify the
lines or assign coordinates to the corners directly . These approaches either assume
a plain background, so as to reduce the number of corner-generating artifacts; use a
top down overhead view; or require the absence of pieces from the board, in order to
prevent the occlusion of corners or lattice points by pieces. Line-based approaches
use edge detection on the input image to identify lines of the chess board. Domain
knowledge, such as the fact that the board can be identiﬁed by 18 total lines and the
orientations of half those lines will be orthogonal to the other half, makes line-based
approaches more robust to noise, and is therefore the more popular technique [8]. Some
proposed corner based approaches which averaged the quality of results while some have
utilized exclusively line-based methods [7]. [8] introduced the classiﬁcation of such
methods into line-based and corner-based approaches but were limited to recognizing
chessboards without chess pieces on them.

2.2 Chess Piece Recognition

Initial attempts at piece recognition were game-tracking applications assume the starting
positions of the pieces, and there can use diﬀerences in intensity values after each move
to track the movement of pieces [5]. Techniques that do not assume a starting position
focus on color segmentation to detect pieces and then use shape descriptors to identify
them. However, color segmentation often relies on square and piece color combinations,
so unreasonable constraints are place on type of chessboard or a sideview that relies on
depth but occludes most of the pieces. This paper uses a more robust piece recognition
solution using trained object detection CNN models.

3

3 Materials and Methods

3.1 Position Detection Pipeline

Figure 1: Position detection pipeline

We have designed an ensemble of methods and tools with engineering tradeoﬀs,
while advancing the state of the art to develop the entire chess position pipeline in an
iOS app (Figure 1). The following are the major steps.

• Detect Chessboard: This is a precursor to the entire pipeline, determines the

presence of a chessboard using simple binary image classiﬁer.

• Segment Chessboard: OpenCV image and vision techniques are used to deter-
mine the outer bounds of the chessboard and segment the image into 64 pieces.

• Predict Chessboard: An pretrained CNN object detector model is used to predict

the 64 image and form the position string.

• Analyze Chessboard: The string is fed into an open source chess engine -

StockFish to determine the next best move.

• Augment Reality OverLay Chessboard The next move and position are over-

layed on top of the existing chessboard for the player.

4

3.2 Detecting and Segmenting Chessboard

3.2.1 Detecting Chessboard

In order to begin predicting the board, it is necessary to detect a chessboard. In order to
begin detecting, we developed a simple binary image classiﬁer trained using 95 images
with a 80/20% training/test split. We provide user feedback for allowing the user to stay
stable while the object is detected. This took less than 1sec from start of the pointing
of the board.

3.2.2 Segmenting Chessboard

The algorithm consists of ﬁve main steps (Figure 2).

• Detecting straight and parallel lines Besides standard line detector, the addi-
tional objective is to merge all small segments that are nearly colinear into long
straight lines and then identify the parallel lines.

– Edge detection: Smoothen the image and then use adaptive Canny edge
detection similar to using gradient threshold and adaptive histogram equal-
ization mask.

– Line detection: Using HoughLines ﬁlter the segments removing small

lines and merge gaps between adjacent collinear lines.

– Grouping: Separate segments into groups of nearly collinear segments and

merging their ends.

– Merging: Analyze and merge the segments in each group utilizing the

M-estimator, resulting in one normalized straight line.

– Filtering: Remove non-parallel lines. In this case, the segments are bound

within 10◦ of horizontal and vertical

• Determining the Bounding box. After the lines have been detected, the next step
is ﬁnding the intersections of those lines. After the points have been determines,
they are merged using K-cluster. Minimum and maximum of those intersecting
points gives the box. After this, all is needed to do a projective transform to
((0, 0), (227x8, 227x8)) for all the three color channels. AlexNet [4], which is the
next stage of the chess piece detection pipeline, expects the size of each image to
be 227 × 227.. This removes any camera distortion.

• Segmenting into 8x8 squares An array of 8x8 images is created to be fed into

the piece detection estimator

3.3 Piece Detection

Figure 3 summarizes the ﬁve steps in the development of the model. We will now cover
each of these steps in detail.

5

Orig

Figure 2: Segmentation pipeline
Gray

Blur

Canny

Hough

Points

Bounded

Transformed

Segmented

6

Figure 3: ARChessAnalayzer model generation pipeline

Table 1: Chess piece database

empty

123

br

212

bn

205

bb

204

bq

215

bk

214

bp

201

wr

202

wn

207

wb

210

wq

212

wk

210

wp

207

tot

2622

Label

Figure 4: Model preparation and training

3.3.1 Data Collection and Labeling

Since there was a lack of labeled chess pieces, a database of approximately 2,600 chess
pieces was manually constructed from one tournament chess set (Table 1). They were
image of individual piece places on the board and manually labelled with one of 13

7

classes – white and black of pawn, knight, bishop, rook, queen, king, and empty (Figure
9).

3.3.2 Data Preprocessing

Figure 4 gives a summary of the preprocessing steps. Images are resized to 227 by 227
by 3 (color channels) to ﬁt the input of the AlexNet. To improve the performance of
the CNN [13], the data set is also augmented with transformations such as cropped,
ﬂipped and blur (Figure 5) resulting in a total size of approx 2 × 2600. The data is then
partitioned into training (80%) and validation (20%) sets.

Orig

Figure 5: Augmentation

Cropped

Flipped

Blurred

3.3.3 Model Generation and Training

AlexNet (Figure 6) is considered one of the most inﬂuential papers published, employing
CNNs and GPUs to accelerate deep learning [4]. It contains eight layers; the ﬁrst ﬁve
were convolutional layers, some of them followed by max-pooling layers, and the last
three were fully connected layers and the activation function is a SoftMax. While we
did try other CNNs, they overﬁt on the data almost immediately, unlike AlexNet. This
is possibly due to the combination of imbalance and small size of the data set.

• Transfer Learning Huge data sets with upwards of a million images are necessary
to train a CNN from scratch with randomly initialized weights. Too little data,
such as our case, would cause a model to overﬁt. The original AlexNet model
was trained using approximately 1.3 million images (1000 object classes) from
the 2012 ImageNet data set. Weights and layers from original AlexNet were used
as a starting point and ﬁne-tuned with pre-processed images with a batch size
of 64. Transfer learning [11] leverages the previously learned low level features
(such as lines, edges and curves) and requires less data to arrive at a satisfactory
CNN.

8

Figure 6: AlexNet [4]

• Model Precision The AlexNet model was ﬁne tuned with 32b (FP32), but it was
reduced down to 16b (FP16) with CoreML tool, during model conversion, to ﬁt in
the size of the app. The state-of-the-art hardware deep neural networks (DNNs)
are moving from 32-bit computations towards 16-bit precision, due to energy
eﬃciency and smaller associated storage. Recently [10] showed the successful
training of DNNs using 8b (FP8) while fully maintaining the accuracy on a
spectrum of models and datasets.

3.4 Tools

Many tools went into this research. AlexNet was trained using Caﬀe framework with
Nvidia Tesla K80 GPUs on Google Colaboratory platform using Python 3.7. The
OpenCV library was used for board segmentation. A standard iOS mobile development
setup was used.
It was built using the Swift 5 programming language and Xcode
integrated development environment with bridges to OpenCV and StockFish. In ﬁgure
7 are some of the screen shots.

9

Initial screenshot

Figure 7: Screen shots of ARChessAnalyzer app
Canny edges and
Hough line segmentation

Augmented Reality
overlay

10

4 Experiments And Results

A total of 720 positions were analyzed. Each board image was tagged with an expected
FEN string like the following starting board position
rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq e3 0 1
and that was compared to the following observed string.
B
rnbqkbnr/pppppppp/8/8/4(cid:0)(cid:18)
As seen above, there is a mismatch in one position - i.e. a white pawn at a center
square e4 was mischaracterized as a white bishop. From this mismatch it is possible to
determine the pieces which were mispredicted, the types of board positions (starting,
middle, end game) and at what position in the board (edge, corners, centers) the pieces
mismatched. The capture and predict routines were wrapped in a test program and
results were gathered and analyzed.

P3/8/PPPP1PPP/RNBQKBNR b KQkq e3 0 1

4.1 Data Augmentation

Accuracy on the piece pipeline increased approximately 1.97% with augmentation (Fig
8). For the rest of the paper, the augmented model is used.

Figure 8: Increase in accuracy after data augmentation

100

99

98

97

y
c
a
r
u
c
c
a

e
g
a
t
n
e
c
r
e
P

e m pty

br

bn

bb

bq

bk

bp

wr

w n

w b

w q

w k

w p

Pieces

4.2 Accuracy and Model Precision

AlexNet was ﬁne-tuned using 32b precision and later downsized to 16b (using coreml)
due to size constraints of the iOS app store. The degradation in accuracy is 0.78%
(Table 2). For the rest of the paper FP16 is used.

Table 2: Accuracy and model precision

AlexNet model (bit)
FP32
FP16
FP8 .

Size
221MB
106MB
48MB .

Accuracy
94.23%
93.45%
93.15%

11

4.3 Saliency Maps

Saliency maps help visualize the inner workings of CNNs via a heat map highlighting
the image features that the model is focused on [14]. Saliency maps were generated on
a few images to conﬁrm that the classiﬁers are identifying the correct regions of interest
for a particular labels (Figure 9).

Label

Figure 9: Saliency maps
Saliency

Label

Saliency

Black

White

Rook

Bishop

Knight

King

Queen

Pawn

12

4.4 Classiﬁcation Metrics

Generalization properties for multiclass classiﬁcation derived from the confusion matrix
(Table 3) of a classiﬁer are used as a measure of its quality. The following performance
metrics are evaluated - accuracy (Eq 2), sensitivity (Eq 3), speciﬁcity (Eq 4), and F1
Score (Eq 5). Figure 10 displays all of the scores.

(1)

(2)

(3)

(4)

true pos+true neg
true pos+true neg+false pos+false neg

=

accuracy = all correct
all samples
sensitivity = true pos
all pos
speciﬁcity = true neg
all neg

=

=

true pos
true pos + false neg

true neg
true neg + false pos

F1score = 2 ×

sensitivity × speciﬁcity
sensitivity + speciﬁcity

Table 3: Confusion matrix between actual and predicted pieces

empty

31454
0
0
4
0
3
0
3
0
0
2
0
0

br

5
1345
0
50
0
0
0
0
0
0
0
0
0

bn

4
0
1330
0
0
0
0
0
0
0
0
0
0

bb

5
50
1
1370
100
0
51
0
0
0
0
0
0

empty
br
bn
bb
bq
bk
bp
wr
wn
wb
wq
wk
wp

Predicted cells
bp

bk

1
21
2
37
50
735
5
0
0
0
0
0
0

4
35
0
24
0
0
5540
0
1
0
0
0
0

bq

0
16
4
54
760
0
10
0
0
0
0
0
0

wr

4
0
0
0
0
0
0
1955
0
0
0
0
34

wn

0
0
0
0
0
0
0
0
1955
0
0
0
27

wb

0
0
0
0
0
0
0
0
0
1650
0
0
43

wq

0
0
0
0
0
0
0
0
0
35
754
0
34

wk

0
0
0
0
0
0
0
0
5
37
0
765
10

wp

0
0
0
0
0
0
0
0
0
45
0
35
5634

Figure 10: Accuracy, sensitivity, speciﬁcity and F1score

Accuracy

Sensitivity

1
0.998

0.996
0.994

0.992

0.99

1
0.998

0.996
0.994

0.992

0.99

e m pty

e m pty

accuracy

br

bn

bb

bq

bk

bp

wr

w n

w b

w q

w k

w p

all

Speciﬁcity

br

bn

bb

bq

bk

bp

wr

w n

w b

w q

w k

w p

all

speciﬁcity

1

0.95

0.9

0.85

0.8

1

0.95

0.9

0.85

0.8

e m pty

e m pty

13

sensitivity

br

bn

bb

bq

bk

bp

wr

w n

w b

w q

w k

w p

all

F1score

br

bn

bb

bq

bk

bp

wr

w n

w b

w q

w k

w p

all

F1score

4.5 Accuracy of Overall Pipeline

The overall accuracy of the position prediction string is 93.45%. A detailed analysis
of the mismatched FEN strings was done considering the types of pieces on the board,
the distribution of the pieces on the board and the population of the board,. There
is high rate of mis-classiﬁcation among certain types of pieces especially between
queen, bishop, pawn and king 3. Secondly, boards with center distribution had a higher
accuracy than those at the edges or corners (Table 4). This is because of the bound
clipping and projective transform and less training images of pieces from the sides.
The last source of error is piece population (Opening, Midgame, Endgame) (Table 5)
This is possibly because as the game proceeds from opening to end, there are less
mis-classiﬁcation possibilities. More training images especially among pieces with
high rate of mis-classiﬁcation and also not just using the top view but also from the
sides, a slight board expansion after segmentation to incorporate the edge ring could
help capture all the features, and a two-step window algorithm processing the edge and
corner pieces separately would possibly alleviate these issues. We will this address this
in our future work.

Table 4: Accuracy of piece prediction based on position
Position Accuracy
91.45%
Corner
92.87%
Edge
96.73%
Center
93.45%
Total

Corner: More than 50% of the four corners are occupied
Edge: If not Corner and more than 50% of the 28 edges are occupied
Center: If not Corner or Edge

Pos

Open
-ing

Mid-
game

End-
game

Table 5: Model of positions calculated expected and actual accuracy
Act %

Exp %

wn

wb

wq

wk

wp

wr

bk

bp

bb

bn

bq

br

empty

32
32
39
42
43
45
48
49
49
47
56
59
57
59
60

2
2
2
1
0
1
1
0
1
1
1
0
0
0
0

2
2
2
2
2
1
1
1
1
1
0
0
1
1
1

2
2
2
2
2
2
1
1
1
1
0
0
0
0
0

1
1
1
1
1
1
1
1
1
1
1
1
1
1
0

1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

8
6
5
4
4
3
3
3
2
3
1
0
0
0
0

2
2
1
2
2
2
1
2
2
2
1
0
0
0
0

2
2
2
2
2
1
1
1
1
1
0
0
1
0
0

2
2
2
2
2
2
1
1
1
1
0
0
1
0
0

1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

1
1
1
1
1
1
1
1
1
1
1
1
1
1
1

8
6
5
3
3
3
3
2
2
3
1
1
0
0
0

89.72
90.88
91.12
92.13
92.36
92.24
93.02
93.57
93.49
93.01
94.71
95.13
95.29
95.50
95.83

91.02

93.47

95.24

Full board: 32 pieces
Opening: Full board - approx 8-10 pieces
Middle Game: Full board - approx 15-20 pieces
End Game: 0-1 rooks, bishops, knights, 0-2 pawns, 0-1 queen.
Expected accuracy of 5 sample calculations in each category use Figure 10.
Actual accuracy are mean of those accuracy of those positions.

14

4.6 Hypothesis Testing For Speed of Analysis

Our hypothesis was that ARChessAnalyzer would be signiﬁcantly faster than manual
entry into a chess engine for valid outcomes. To verify our hypothesis, we setup our
experiment as follows. For chess diagram entry and analysis, we chose the chess.com,
which uses Stockﬁsh as its back engine. In order to pick a variety of chess diagrams
we chose ﬁve from beginning positions, mid-game positions and end game positions
as follows (Table 6). The results for manual entry and ARChessAnalyzer are tabulated
in (Table 7). Two parameters µ0 and µa corresponding to the average time taken for
direct entry and via the app are calculated, and so are the standard deviation (σ) (Table
7). Since, the number of sample size of each set is small (n = 5) we use the student
distribution t-statistic. Our Ha is one tailed, and using n − 1 = 4 degrees of freedom we
see all the sets meet t > 8.610 corresponding to 99.9995%. We accept the hypothesis.
The highest conﬁdence is for mid-games because the entry of the pieces are more and
random. In the case of endgame, the change in number of pieces is small from an empty
board, and in beginning, the change in number of pieces is small from from a full board.
Hypothesis H1 µa ≥ µ0: Using ARChessAnalyzer is faster to analyze the chess

game than using manual entries for valid outcomes.

Null Hypothesis H0 µa < µ0: Using ARChessAnalyzer has no improvement over

direct StockFish entry analysis for valid outcomes.

Table 6: Game Number, Types and Number of Pieces

Chess Diagram
n
1
2
3
4
5

Beginning

Ruy Lopez
Italian
Siclian Defense
French Defense
Caro Kann

Game Number, Types and Number of Pieces
Midgame
Polish Immortal
Stamma
Ponziani
Abu Naim
Damiano

Endgame
Reti End Game
Lasker’s Pin
Saavedra position
Lucena position
Philidor position

30(5)
32(6)
32(2)
30(6)
32(3)

31
21
14
10
11

4
6
4
5
5

For beginning position, both the number of pieces on the board and change in pieces from starting position are shown

Table 7: Analysis Times (in sec) and Hypothesis Testing Results

Chess Diagram
n
1
2
3
4
5
µ
σ
t-value

Manual Entry to StockFish

ARChessAnalyzer

Endgame Beginning Midgame
3.20
2.60
4.50
3.50
2.90
3.34
0.73
18.23

3.22
3.12
4.25
2.78
3.23
3.32
0.55
311.82

15.90
12.45
32.67
15.32
25.67
20.40
8.48

Endgame
3.40
3.50
3.30
2.20
3.10
3.10
0.52
32.99

Beginning Midgame

15.21
18.42
16.80
17.24
15.56
16.65
1.30

347.92
222.79
107.91
100.87
96.24
175.15
109.98

15

5 Conclusions And Future Work

This paper improves the state of the art in areas of chessboard segmentation and
chess piece detection using convolutional neural networks, making trade-oﬀs in model
accuracy and memory footprint for integration in an handheld device on an ﬁrst of
its kind iOS app. The piece detection accuracy is greater than 99% and the accu-
racy of prediction pipeline is 93.45%. The AR pipeline takes about 3-4.5sec from
pointing the live view camera at the chessboard to AR Overlay. We also validated
our hypothesis that ARChessAnalyzer is signiﬁcantly faster at analysis than man-
ual entry for valid outcomes. The project source code can be found at https:
//github.com/anavmehta/ARChessAnalyzer. The app is also available on the
iOS store.

Our hope is that the instantaneous feedback this app provides will help chess learners

at all levels all over the world.

The following are the areas of focus of future research.

• Chessboard segmentation

The algorithm can be improved to make the camera angle more tolerant to roll,
yaw, and pitch and infer hidden points and lines to detect partially hidden pieces.

• Chess piece detection

More images of chessboards and pieces, from diﬀerent chess sets - with variation
of top and side angles to better capture the shape of the piece, will improve
the robustness of classiﬁers to occlusions, artifacts and intra-class variations.
AlexNet was chosen based on ease of training and accuracy. A more systematic
evaluation of recent research of in-device models will help further reduce memory
footprint while retaining accuracy.

• Chess engine and game state recognition

The state of the board sometimes requires knowledge of previous immediate
moves (e.g en-passant or castling). This would require deeper analysis, and/or
the user overrides. StockFish is the most popular and was easy to integrate in iOS.
However, players may want to switch to other engines based on their preference
or engine strengths.

Finally, for worldwide acceptance as a learning chess app it has to be ported to

Android.

16

References

[1] J. Deng, W. Dong, R. Socher, L. J. Li, L. Kai and L. Fei-Fei, ”ImageNet: A
large-scale hierarchical image database,” IEEE Conference on Computer Vision
and Pattern Recognition, 2009.

[2] https://stockfishchess.org/

[3] Y. LeCun, Y. Bengio and G. Hinton, ”Deep learning,” Nature, vol. 521, pp. 436-444,

2015.

[4] https://neurohive.io/en/popular-networks/alexnet-imagenet-classification-with-deep-convolutional-neural-networks/

[5] C. Koray and E. Sumer, ”A Computer Vision System for Chess Game Tracking,”
presented at the 21st Computer Vision Winter Workshop, Rimske Toplice, Slovenia,
2016

[6] Duda, R.O., Hart, P.E., 1972. Use of the hough transformation to detect lines and
curves in pictures. Commun. ACM 15, 11–15. http://doi.acm.org/10.1145/
361237.361242, doi:10.1145/361237.361242.

[7] Raghuveer Kanchibail, Supreeth Suryaprakash, Suhas Jagadish, Chess Board
Recognition, http://vision.soic.indiana.edu/b657/sp2016/projects/
rkanchib/paper.pdf

[8] Tam, K.Y., Lay, J.A., Levy, D., 2008. Automatic grid segmentation of populated
chessboard taken at a lower angle view, in: Computing: Techniques and Applica-
tions, 2008. DICTA’08. Digital Image, IEEE. pp. 294–299.

[9] https://en.wikipedia.org/wiki/Forsyth%E2%80%93Edwards_Notation

[10] Naigang Wang, Jungwook Choi, Daniel Brand, Chia-Yu Chen, Kailash Gopalakr-
ishnan, “Training Deep Neural Networks with 8-bit Floating Point Numbers”,
Conference on Neural Information Processing Systems (NeurIPS)

[11] A. Karpathy, ”Transfer Learning,” Stanford University. [Online]. Available:

http://cs231n.github.io/transfer-learning

[12] Alex Krizhevsky, Ilya Sutskever, Geoﬀrey E. Hinton, ImageNet Classiﬁcation
with Deep Convolutional Neural Networks
https://papers.nips.cc/paper/
4824-imagenet-classification-with-deep-convolutional-neural-networks.
pdf

[13] Jason Wang, Luis Perez The Eﬀectiveness of Data Augmentation in Image Classi-
ﬁcation using Deep Learning http://cs231n.stanford.edu/reports/2017/
pdfs/300.pdf

[14] K. Simoyan, A. Vedaldi and A. Zisserman, ”Deep Inside Convolutional Networks:
Visualising Image Classiﬁcation Models and Saliency Maps,” arXiv preprint
arXiv:1312.6034, 2014.

17

