6
1
0
2

v
o
N
4
1

]
P
A

.
t
a
t
s
[

1
v
8
4
2
4
0
.
1
1
6
1
:
v
i
X
r
a

Asymptotic Inference for AR(1) Penal Data∗

Jianfei Shen and Tianxiao Pang

Zhejiang University

Abstract. A general asymptotic theory is given for the panel data AR(1) model with

time series independent in diﬀerent cross sections. The theory covers the cases of stationary

process, nearly non-stationary process, unit root process, mildly integrated, mildly explosive

and explosive processes. It is assumed that the cross-sectional dimension and time-series

dimension are respectively N and T . The results in this paper illustrate that whichever the

process is, with an appropriate regularization, the least squares estimator of the autoregres-

sive coeﬃcient converges to a normal distribution with rate at least O(N −

1/3). Since the

variance is the key to characterize the normal distribution, it is important to discuss the

variance of the least squares estimator. We will show that when the autoregressive coeﬃcient

ρ satisﬁes

< 1, the variance declines at the rate O((N T )−

ρ
|
|
1) when ρ = 1 and O(N −
1/2T −

O(N −

1/2ρ−

T +2) when

ρ
|
|

> 1. ρ = 1 is the critical point

1/2), while the rate changes to

where the convergence rate changes radically. The transition process is studied by assuming

ρ depending on T and going to 1. An interesting phenomenon discovered in this paper is

that, in the explosive case, the least squares estimator of the autoregressive coeﬃcient has

a standard normal limiting distribution in panel data case while it may not has a limiting

distribution in univariate time series case.

Keywords: AR(1) model, Limiting distribution, Least squares estimator, Non-stationray,

Panel data.

AMS 2010 subject classiﬁcation: 62E20.

∗This research was partly supported by the Department of Education of Zhejiang Province (N20140202).

Address correspondence to Tianxiao Pang, School of Mathematical Sciences, Yuquan Campus, Zhejiang

University, Hangzhou 310027, P.R.China; email: txpang@zju.edu.cn.

1

 
 
 
 
 
 
1 Introduction

Dynamic models are useful in modeling time series data and have been well studied in the

past few decades. One of the dynamic models is the AR(1) model which is given by

yt = ρyt

−

1 + εt,

t = 1, 2, ..., T.

(1.1)

For simplicity, in the sequel, we assume y0 = 0 and
cally distributed (i.i.d.) random variables with E[ε1] = 0 and E[ε2

εt, t
{

1
}

≥

1] = 1.

are independent and identi-

Although the model (1.1) is simple, it is very useful and important in time series and

econometrics literatures since the model can be used to model some kinds of stationary or

non-stationary time series data. The parameter ρ is the main concern in the model (1.1)

since whether the model is stationary is determined by the value of ρ.

It is well-known

that the necessary and suﬃcient condition for the stationarity of (1.1) is

< 1 if y0 is an

ρ
|
|

appropriate random variable or a constant. In this paper, we still call (1.1) with y0 = 0 a

stationary AR(1) model when

ρ
|
|

< 1, since this modiﬁcation will not change the limiting

distribution of the least squares estimator (LSE) of ρ which is given by

For the stationary AR(1) model, Mann and Wald (1943) proved that

P

ˆρ =

T
t=1 ytyt
−
T
t=1 y2
t
−

1

1

.

P

(1.2)

√T
1

−

(ˆρ

−

ρ)

ρ2

d
−→

N (0, 1).

When ρ stisﬁes

ρ
|
|

> 1, model (1.1) is non-stationary and is called the explosive AR(1)

p

model. For this model, Anderson (1959) showed that if εt’s are independent and normal

distributed random variables, then

ρT

ρ2

−

(ˆρ

1

−

ρ)

d
−→

C,

where C is a standard Cauchy variate. However, for general εt’s, Anderson (1959) showed

that the limiting distribution of ˆρ may not exist. The interesting case is ρ = 1, the corre-

sponding AR(1) model is called the unit root model in econometrics. For this model, the

central limit theorem is no longer applicable when exploring the limiting distribution of ˆρ.

Instead, by applying functional central limit theorem, White (1958) and Rao (1978) showed

that

T (ˆρ

ρ)

−

d
−→

1
2

W 2(1)
1
−
1
0 W 2(t)dt
(cid:2)

(cid:3)

,

R

2

where

W (t), 0
{

t

1
}

≤

≤

standard. Noting that P (ˆρ

not even symmetric.

is a standard Wiener process. The limiting distribution is not

ρ

−

≤

0) = P (W 2(1)

1)

≈

≤

0.684, the limiting distribution is

In order to bridge the gaps of asymptotic theories between the stationary AR(1) model

and the unit root model, Chan and Wei (1987) and Phillips (1987) independently studied

the following model called nearly non-stationary AR(1) model:

yt = ρyt

−

1 + εt,

y0 = 0,

ρ = ρT = 1

−

c/T,

t = 1, 2, ..., T,

(1.3)

where c is a ﬁxed constant. Of late, in order to bridge the gaps of asymptotic theories

between the unit root model and the explosive AR(1) model, Phillips and Magdalinos (2007)

studied the following AR(1) model:

yt = ρyt

−

1 + εt,

y0 = 0,

ρ = ρT = 1

c/kT ,

−

t = 1, 2, ..., T,

(1.4)

where c is a ﬁxed constant and kT is a sequence of positive constants increasing to

such

∞

that kT = o(T ). Model (1.4) with c > 0 and with c < 0 is called mildly integrated AR(1)

model and mildly explosive AR(1) model respectively according to Phillips and Magdalinos

(2007).

In models (1.3) and (1.4), we denote ˆρT the LSE of ρT and also suppose that

1
}
1] = 1. It is worth noting that the limiting

εt, t
{

≥

are i.i.d. random variables with E[ε1] = 0 and E[ε2

distributions of ˆρT are diﬀerent from those in the stationary AR(1) model, unit root model

and explosive model. Speciﬁcally, Chan and Wei (1987) proved that when ρ = ρT = 1

c/T

−

with c

R,

∈

T (ˆρT −

ρT )

d
−→

2c
b R

1
0 (1 + bt)−

1
0 (1 + bt)−

1W (t)dW (t)
2W 2(t)dt

,

where b = e2c

1 ( 2c
b

−

in the above limiting distribution is replaced by 1 if c = 0), while

R

Phillips and Magdalinos (2007) proved that when ρ = ρT = 1

c/kT with c > 0,

−

T kT (ˆρT −

ρT )

d
−→

N (0, 2c)

and when ρ = ρT = 1

p

c/kT with c < 0,

−

[kT ρT

T /(

−

2c)](ˆρT −

ρT )

d
−→

C,

where, as before, C stands for a standard Cauchy variate.

It is clear that the limiting distribution of the LSE of ρ varies in AR(1) models under

diﬀerent assumptions on ρ. Further, one can ﬁnd that the limiting distribution is not

3

standard in nearly non-stationary AR(1) model which includes the unit root model as a

special case. This is harmful for making further statistical inferences, for example, conﬁdence

intervals of ρ.

However, with the penal data, the results may be extremely simple. A panel data set

is the one that follows a given sample of individuals over time, and thus provides multiple

observations on each individual in the sample. A panel data AR(1) model is formulated by

yit = ρyi,t

−

1 + εit,

t = 1, 2, ..., T,

i = 1, 2, ..., N,

(1.5)

where, for simplicity, we suppose in this paper that yi0 = 0 for any i
are i.i.d. random variables with E[ε11] = 0 and E[ε2

1, t

≥
11] = 1. The dimension of

≥

εit, i
{

1 and

1
}

≥

individual, N , is usually called cross-sectional dimension. There is no common eﬀect on

individuals in the model (1.5). Thus each individual generates an independent time series

and the central limit theorem may be applied on cross-sectional dimension. For this panel

data AR(1) model, Levin and Lin (1992) proved that, when ρ = 1 (unit root case) and an

additional moment condition is fulﬁlled, that is, E

2+λ <

ε11|
|

∞

for some λ > 0, one has

√N T (ˆρ

ρ)

−

d
−→

N (0, 2),

N, T

.

→ ∞

(1.6)

Obviously, the limiting distribution of ˆρ in panel data unit root model is simpler than that

in univariate time series unit root model. What is more important is the former is standard

while the latter is not. This comparison motivates us to study other panel data AR(1)

models.

Therefore, the aim of this paper is to study the limiting distribution of the LSE of ρ

in various panel data AR(1) models. We are interested in the following question: whether,

like the panel data unit root case, all the limiting distributions are normal in panel data

stationary, nearly non-stationary, mildly integrated, mildly explosive and explosive cases.

The rest of the paper is organized as follows. We will extend the conclusion (1.6) to

general cases for ρ

∈

R in Section 2, and provide some applications in Section 3. Note that,

in Section 3, all the limiting distributions have the form of normal distribution only with

diﬀerent rates of convergence. When ρ = 1, our result coincides with that in Levin and Lin

ε11|
(1992), but the moment condition E[
|
, in our paper.

weaker one, that is, E[ε2

11] <

2+λ] <

∞

for some λ > 0 is replaced by a more

∞

4

2 Asymptotics for the LSE of ρ

Consider the panel data AR(1) model:

yit = ρyi,t

−

1 + εit,

t = 1, 2, ..., T,

i = 1, 2, ..., N,

(2.1)

where yi0 = 0 for all i
≥
with E[ε11] = 0 and E[ε2

1 and the innovations

εit, i
{

≥

1, t

0
}

≥

are i.i.d. random variables

11] = 1. In this model, the LSE of ρ is

ˆρ =

N
i=1
N
i=1

P

P

T
t=1 yityi,t
−
T
t=1 y2
i,t

1

−

1

.

It is true that

P

P

ρ =

ˆρ

−

P

N
i=1
N
i=1

P

T
t=1 yi,t
−
T
t=1 y2
i,t

1εit

.

1

−

(2.2)

(2.3)

To obtain a non-degenerated limiting distribution for (2.3), we can apply the central limit

P

P

theorem to the numerator and the law of the large numbers to the denominator, respec-

tively. Before doing so, we need to put the normalizing constants on

T
t=1 yi,t
−

1εit’s and

T
t=1 y2
i,t

−

1’s such that they become bounded in probability. The following is our main result

P

in this section.
P

Theorem 2.1 In the model (2.1), we suppose yi0 = 0 for all i

1 and the innovations

≥

1, t

εit, i
{
we assume there exist two positive functions of T , Q(T) and P(T), such that

are i.i.d. random variables with E[ε11] = 0 and E[ε2

0
}

≥

≥

11] = 1. In addition,

and

T

t=1
X

T

AT
i

:= P (T )

BT
i

:= Q(T )

yi,t

−

1εit

!

d
−→

Ai,

T

,

→ ∞

y2
i,t

−

1

!

d
−→

Bi,

T

,

→ ∞

t=1
X

where Ai’s and Bi’s are random variables.

(1) If, as T

→ ∞
and 0 < E[Bi] <

, E[(AT

i )r]
for all i

∞

E[Ar

i ] for r = 1, 2 and E[BT
i ]

E[Bi] with 0 < E[A2

i ] <

∞

→

1. Then we have

→

≥

√N

P (T )
Q(T )

ρ)

(ˆρ

−

d
−→

N

0,

(cid:18)

V ar(A1)
(E[B1])2

,

(cid:19)

N, T

.

→ ∞

(2.4)

(2) If the conditions in (1) are fulﬁlled, and in addition, as T

∞
1. Then we have, as long as T is large enough,

→ ∞

→

, E[(BT

i )2]

E[B2

i ] <

3]

Ai|
E[
|

3] <

→

∞

for all i

≥

AT
and E[
i |
|
√N P (T )
Q(T ) (ˆρ

−

ρ) converges to a normal distribution with the rate at least O(N −

5

1
3 ) as N

.

→ ∞

 
 
Remark 2.1 We assume the cross section dimension N and the time series dimension T

are independent in this paper. However, if N depends on T and is a monotonic function

of T , one could still have the all results in this paper by some limit theorems for triangular

arrays (for example, central limit theorem for triangular arrays in Levin and Lin (1992) and

the law of large numbers for triangular arrays in Sung (1999)).

Proof.

(1) Apparently,

AT
{

i , i

1
}

≥

are i.i.d. random variables with E[AT

i ] = 0. Moreover,

it follows from the conditions of moment convergence that there exists some T0 > 0 such
that when T > T0, 0 < E[(AT

. Denote

i )2] <

∞

ST

N =

1
√N

= 0 and V ar

N

AT
i
V ar(AT
1 )

Xi=1
q
AT
i
√V ar(AT
1 )

(cid:18)

(cid:19)

Note that E

AT
i
√V ar(AT
1 )

(cid:21)

(cid:20)

.

(2.5)

= 1. Hence, when T > T0, applying the

central limit theorem for i.i.d. random variables with zero mean and ﬁnite second moment

leads to

ST
N

d
−→

N (0, 1),

N

,

→ ∞

which, in view of characteristic function arguments, further implies that

ST
N

d
−→

N (0, 1),

N, T

.

→ ∞

(2.6)

(2.7)

In addition, noting that

T1 > 0 such that E[BT

i , i

BT
{
i ] <

1
}

are also i.i.d. random variables and there exists some

≥
when T > T1 by the conditions of moment convergence, it

∞
follows from the law of large numbers that when T > T1,

This easily yields

1
N

N

Xi=1

BT
i

P
−→

E[BT

1 ],

N

.

→ ∞

1
N

N

Xi=1

BT
i

P
−→

E[B1],

N, T

.

→ ∞

(2.8)

(2.9)

Combining (2.7) with (2.9) immediately leads to (2.4) by observing the following equality

√N

P (T )
Q(T )

(ˆρ

−

ρ) = √N

N
i=1 AT
i
N
i=1 BT
i

P

= ST

N q
1
N

V ar(AT
1 )
N
i=1 BT
i

.

(2) It follows from the conditions of moment convergence that there exists some T2 > 0 such

P

P

AT
that, when T > T2, E[
i |
|

]3 <

∞

and (2.6) is still true. Denote

AT
γT = E[
i |
|

3],

T = E[(AT
σ2

i )2].

6

Then, according to the well-known Berry-Esseen bound for i.i.d. random variables with

ﬁnite third moment, the speed of convergence for (2.6), when T > T2, is characterized by

the following inequality:

sup
x |

P (ST

N ≤

x)

−

Φ(x)

| ≤

c0γT
σ3
√N
T

,

(2.10)

where c0 is some positive constant and Φ(x) is the distribution function of a standard

normal random variable. In addition, by virtue of the conditions of moment convergence

again, there esixts some T3 > 0 such that E[BT

i ] > 0 and E[(BT

i )2] <

when T > T3.

∞

Denote

RT

N =

1
N

N
i=1 BT
i
E[BT
1 ]
P

.

Note that RT

N is a non-negative random variable and E[RT
inequality, we have for any 0 < δ < 1
2 ,

N ] = 1. By applying Chebyshev’s

RT
P (
|

N −

1
| ≥

δ)

≤

V ar(RT
δ2

N )

=

1
N δ2

V ar(BT
1 )
(E[BT
1 ])2

.

(2.11)

Next, we will explore the convergence rate of ST

N /RT

N for T > max

.
T2, T3}
{

First, when x

0, one has

≥

< δ

+ P

(cid:19)
< δ

−

(cid:18)
Φ(x)

(cid:1)

(cid:12)
(cid:12)
Φ(x), Φ(x)

ST
N
RT
N

< x,

RT
|

N −

δ

1
| ≥

−

(cid:19)

Φ(x)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

N −

δ

1
| ≥

RT
|
(cid:0)
ST

+ P

P

−

N < (1

(cid:1)
δ)x,

−

RT
|

N −

1
|

< δ

(cid:0)

(cid:1)(cid:9)

Φ(x), Φ(x)

P

ST

N < (1

δ)x

−

RT
+ P (
|

N −

1
| ≥

δ)

−

(cid:0)

(cid:1)

(cid:9)

(cid:18)

< x

ST
N
RT
N
ST
N
RT
N
(cid:18)
N < RT
ST

< x,

≥

P

sup
0 (cid:12)
x
(cid:12)
(cid:12)
P
= sup
(cid:12)
0 (cid:12)
x
≥
(cid:12)
(cid:12)
P
sup
(cid:12)
0
x

≤

−

(cid:19)

Φ(x)
(cid:12)
(cid:12)
(cid:12)
1
(cid:12)
|

N −

RT
|

N x,

RT
|

N −

1
|

(cid:12)
(cid:0)
(cid:12)
max

P

ST

N < (1 + δ)x

(cid:0)
(cid:8)
RT
1
N −
| ≥
|
(cid:0)
ST
N < (1 + δ)x
P
max

(cid:1)

δ

−

−

(cid:1)

(cid:1)

≤

≤

≥
sup
0
x

≥
+ P

sup
0
x

≥
+ P

max

≤

δ

(cid:1)

(cid:0)
(cid:8)
RT
1
N −
| ≥
|
(cid:0)
ST

P

sup
0
x

(cid:26)

P

≥
(cid:12)
(cid:0)
(cid:12)
ST
N < (1

sup
0
x

≥

(cid:0)

(cid:12)
(cid:12)

N < (1 + δ)x

Φ((1 + δ)x)

−

δ)x

−

−

(cid:1)

(cid:1)
Φ((1

δ)x)

−

(cid:12)
(cid:12)

(cid:12)
(cid:12)
+ sup
0 |
x

≥

+ sup
0 |
x

≥

Φ((1 + δ)x)

Φ(x)
|

−

+ P

Φ((1

δ)x)

Φ(x)
|

−

−

+ 2P

N −

RT
|
(cid:0)
N −

1
| ≥

δ

,

1
| ≥

(cid:1)

δ

.

(cid:27)
(cid:1)
(2.12)

RT
|
(cid:0)

Note that Φ(x) =

x

−∞

1
√2π

e−

t2
2 dt satisﬁes the following smooth conditions:

R
Φ((1 + δ)x)

sup
0 |
x

≥

Φ(x)
|

−

= sup
x

0 Z
x

≥

(1+δ)x

t2
2 dt

e−

1
√2π

≤

sup
0
x

≥

x2
2

xe−

δ
√2π

δ
√2πe

≤

(2.13)

7

and similarly,

Φ(x)

sup
0 |
x

≥

Φ((1

δ)x)

| ≤

−

−

δ
√2πe

δ

<

2δ
√2πe

.

1

−

1

Substituting (2.10), (2.11), (2.13) and (2.14) into (2.12) and taking δ = N −

(2.14)

1
3 (N > 8), one

has

P

≥

sup
0 (cid:12)
x
(cid:12)
(cid:12)
(cid:12)

ST
N
RT
N

(cid:18)

< x

−

(cid:19)

Φ(x)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

+

≤

c0γ3
T
σ3
√N
T
=: C1(T )N −

V ar(BT
2
1 )
(E[BT
N δ2
1 ])2
1
1
3 ,
2 + C2(T )N −

+

2δ
√2πe

(2.15)

where C1(T ) = c0γ3
T
σ3
T
bounded when T > max

and C2(T ) = 2V ar(BT
(E[BT
.
T2, T3}
{

1 )

1 ])2 + 2
√2πe

By the same arguments, when x < 0, one has

. Note that both C1(T ) and C2(T ) are

ST
N
RT
N

(cid:18)

P

sup
x<0

< x

−

(cid:19)
N < (1

ST

Φ(x)
(cid:12)
(cid:12)
(cid:12)
δ)x
(cid:12)

−

P

sup
x<0 (cid:12)
(cid:12)
(cid:12)
max
(cid:12)

(cid:26)
P

sup
x<0

≤

Φ((1

δ)x)

−

+ sup
x<0 |

Φ((1

−

δ)x)

Φ(x)
|

−

−

+ P

(cid:0)

(cid:12)
(cid:12)
ST
N < (1 + δ)x

(cid:1)

Φ((1 + δ)x)

−

(cid:12)
(cid:12)
+ sup
x<0 |

Φ((1 + δ)x)

Φ(x)
|

−

+ 2P

(cid:12)
(cid:0)
(cid:12)
C1(T )N −

≤

(cid:1)
1
1
3 .
2 + C2(T )N −

(cid:12)
(cid:12)

Thus we can unify (2.15) and (2.16) as

N −

RT
|
(cid:0)
N −

1
| ≥

δ

,

1
| ≥

(cid:1)

δ

(cid:27)
(cid:1)
(2.16)

RT
|
(cid:0)

ST
N
RT
N
where both C1(T ) and C2(T ) are bounded when T > max

C1(T )N −

< x

−

≤

(cid:18)

(cid:19)

P

Φ(x)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

sup
R (cid:12)
x
∈
(cid:12)
(cid:12)
(cid:12)

.
T2, T3}
{

1
2 + C2(T )N −

1
3 ,

(2.17)

Noting that

√N

P (T )
Q(T )

(ˆρ

−

ρ) =

ST
N
N · q
RT

V ar(AT
1 )
E[BT
1 ]

,

(2.18)

it is true that √N P (T )

Q(T ) (ˆρ

−

least O(N −

1
3 ) as long as T is large enough.

ρ) also converges to a standard normal distribution with rate at

(cid:3)

Remark 2.2 Generally the requirements of 0 < E[A2

i ] <

,0 < E[Bi] <

∞

∞

and conver-

gence of moments are not strong They can be fulﬁlled in most of models we will discuss.

Theorem 2.1 illustrates that N determines the form of the limiting distribution while

T portrays the speed of convergence (with P (T ) and Q(T )). Considering the limiting

distribution is normal, it can be totally depicted by its variance. So the rest of this paper

devotes to study the variance of the limiting distribution in various cases.

8

3 Applications

In this section, the limiting distribution of the LSE of ρ in model (2.1) will be introduced

one by one whenever ρ is a ﬁxed constant or a constant depending on T .

The results in the following lemma are taken from Mann and Wald (1943) and Rao

(1978), respectively.

Lemma 3.1 In the model (1.1), we suppose y0 = 0 and the innovations
random variables with E[ε1] = 0 and E[ε2

1] = 1. Then,

εt, t
{

≥

1
}

are i.i.d.

(1) when

ρ
|
|

< 1, one has

1

−
T

r

T

ρ2

1εt

d
−→

N (0, 1),

T

→ ∞

yt

−

y2
t
−

1

P
−→

1,

T

;

→ ∞

Xt=1
T
ρ2

t=1
X

1

−
T

T

y2
t
−

1

!

d
−→

1
2

(W (1)2

1),

−

t=1
X
is a standard Wiener process.

(cid:18)

1

0

Z

W 2(t)dt

,

(cid:19)

T

,

→ ∞

(2) when ρ = 1, one has

1
T

T

t=1
X

1εt,

yt

−

1
T 2

where

W (t) : 0
{

≤

t

≤

1
}

Note that the LSE of ρ in model (2.1) is (2.2). With Theorem 2.1 and Lemma 3.1, the

following results can be gotten.

Theorem 3.1 In the model (2.1), we suppose yi0 = 0 for all i

are i.i.d. random variables with E[ε11] = 0 and E[ε2

11] = 1. Then,

1 and the innovations

≥

1, t

εit, i
≥
{
(1) when

0
}

≥
< 1, one has

ρ
|
|

√N T
1

−

ρ2

ρ)

(ˆρ

−

d
−→

N (0, 1),

N, T

;

→ ∞

(2) when ρ = 1, one has

p

√N T (ˆρ

ρ)

−

d
−→

N (0, 2),

N, T

.

→ ∞

Proof. (1) is easy and omitted. (2) is true because for any i

1,

≥

E

1
T

"

T

t=1
X

yi,t

−

1εt

#

= 0, E

yi,t

−

1εt

!

2





=

1
T 2

T

(t

t=1
X

1)

−

→

1
2

,





1
T

T

t=1
X

9

 
 
E

1
T 2

"

T

t=1
X

y2
t
−

1

#

=

1
T 2

T

(t

t=1
X

1)

−

→

1
2

,

1
2

E

(cid:20)
and

(W (1)2

−

1)

= 0,

V ar

(cid:21)

1
2

(cid:16)

E

(W (1)2

−

1)

= E

(cid:17)

1

W 2(t)dt

=

0

h Z

0

Z

i

"(cid:18)

1

tdt =

(W (1)2

1
2

2

1)

#

(cid:19)

−

=

1
4 ×

(3

−

1) =

1
2

1
2

.

(cid:3)

Remark 3.1 The result (2) in Theorem 3.1 is indeed one of the main results in Levin and

Lin (1992), but the moment conditions in this paper are weaker than those in Levin and Lin

(1992).

Remark 3.2 In lemma 3.1, the case of

ρ
|
|

> 1 is excluded. Anderson (1959) proved that,

if

εt, t
{

1
}

≥

are i.i.d. normal random variables with mean zeros and variance ones, then

T

(T

ρ−

−

2)

1εt

d
−→

ξη,

yt

−

t=1
X
T

(ρ2

−

1)ρ−

2(T

1)

−

ρT

ρ2

−

t=1
X
(ˆρ

1

y2
t
−

1

d
−→

ξ2,

ρ)

−

d
−→

C,

T

,

→ ∞

T

,

→ ∞

where, ξ and η are independent and obey N (0, ρ2/(ρ2

1)) and C stands for a standard

−

Cauchy variate. In general case, ˆρ

−

ρ may not has a limiting distribution. Consequently,

the case of

ρ
|
|

> 1 is also excluded in Theorem 3.1.

Next, we will study the case of

ρ
|
|

Theorem 2.1.

> 1 in panel data AR(1) model without the help of

Theorem 3.2 In the model (2.1) with

> 1, we suppose yi0 = 0 for all i

1 and the

ρ
|
|

≥

are i.i.d. random variables with E[ε11] = 0 and E[ε2

11] = 1.

innovations

εit, i
{

≥

1, t

0
}

≥

Then

√N ρT

2(ˆρ

−

ρ)

−

d
−→

N (0, 1),

N, T

.

→ ∞

(3.1)

10

Proof. Denote β = 1/ρ, and

uiT = εi1 + βεi2 +

+ βT

−

· · ·

viT = εiT + βεi,T

+ βT

−

1 · · ·

−

2εi,T

1,

−
2εi2 + βT

i

−

1

≥
1εi1,

1.

i

≥

Then, following the proofs of Theorem 2.1 and Theorem 2.2 in Anderson (1959), one imme-

diately has

As a result,

1
N (cid:12)
(cid:12)
(cid:12)
(cid:12)
1
(cid:12)
N (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

yi,t

1εit −

−

uiT viT

N

T

βT

−

2

Xt=1
Xi=1
T
N
2)

−

β2(T

Xi=1

t=1
X

y2
i,t

−

1 −

P
−→

0,

(cid:12)
(cid:12)
(cid:12)
(cid:12)
P
(cid:12)
−→

0.

N

Xi=1
N

Xi=1

u2
iT

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

N
i=1
N
P
i=1
N
i=1

1εit

T
t=1 yi,t
−
T
t=1 y2
i,t
1
−
T
t=1 yi,t
−
T
t=1 y2
i,t

P
N
P
i=1

1εit

1

−

√N ρT

2(ˆρ

−

−

ρ) = √N ρT

2

−

P
2 1
βT
P
−
N
2) 1
β2(T
P
N
N
i=1 uiT viT
P
N
i=1 u2
iT

P

−

= √N

=

1
√N
1
N

P

(1 + oP (1)).

(3.2)

That is to say, we only need to derive the limiting distribution of

P

1
√N P
1
N P

N
i=1 uiT viT
N
i=1 u2
iT

in order to

derive the limiting distribution of √NρT

2(ˆρ

−

ρ).

−

First, for any ﬁxed T

≥

2, it follows from the law of large numbers that

which yields

Second, denote

1
N

N

Xi=1

u2
iT

1

P
−→

−
1

1)

β2(T
−
β2

−

, N

,

→ ∞

1
N

N

Xi=1

u2
iT

P
−→

1

1

−

β2 , N, T

.

→ ∞

u∗iT =

[T /2]

t=1
X

βt
−

1εit,

v∗iT =

βT

tεit,

−

T

Xt=[T /2]+1

(3.3)

(3.4)

here the symbol [x] denote the largest integer not greater than x. Then, by the proof of

Theorem 2.3 in Anderson (1959), we have for any i

1,

≥

uiT −
|

u∗iT |

P
−→

0 and

uiT −
|

u∗iT |

P
−→

0,

T

.

→ ∞

11

It follows that

1
√N

N

uiT viT =

1
√N

N

u∗iT v∗iT (1 + oP (1)).

Note that the sequences

Xi=1
u∗iT , i
1
{
}
Then, by virtue of the central limit theorem we have

Xi=1
v∗iT , i
{

1
}

and

≥

≥

are independent for any ﬁxed T

1
√N

N

Xi=1

u∗iT v∗iT

N (0,

(1

−

d
−→

β2[T /2])(1
(1

−

β2(T

−
β2)2

[T /2]))

−

), N

,

→ ∞

which further implies that

1
√N

N

Xi=1

u∗iT v∗iT

d
−→

N (0,

(1

1
β2)2 ), N, T

−

→ ∞

(3.5)

2.

≥

(3.6)

(3.7)

by characteristic function arguments. Now, combining (3.2), (3.4), (3.5) with (3.7) yields

(3.1).

(cid:3)

Remark 3.3 It is interesting to see that ˆρ

−

ρ has a limiting distribution in panel data case

while it may not has a limiting distribution in univariate time series case.

Though in penal data, the form of limiting distribution is stable, noticing that the scale

of ˆρ

−
when

ρ
|
|

ρ declines from O(

1
√N T

) when

ρ
|
|

< 1, to O(

1
√N T

) when ρ = 1 and to O(

1
√N ρT

2 )

−

> 1, the rate of convergence changes radically at ρ = 1. Hence, it is necessary to

discuss the case when ρ is near 1. In the rest of the paper, we suppose ρ depends on T , so

it is natural to use the notation ˆρT to denote the LSE of ρ, that is, (2.2).

We ﬁrst follow the proposal of Chan and Wei (1987) and Phillips (1987) to study the

case where ρ = ρT = 1

−

c
T , where c is a ﬁxed constant. Consider the model

yit = ρT yi,t

−

1 + εit,

ρT = 1

c
T

,

−

t = 1, 2, ..., T,

i = 1, 2, ..., N,

where yi0 = 0 for all i

and E[ε2

11] = 1.

1 and

εit, i
{

≥

1, t

1
}

≥

≥

are i.i.d. random variables with E[ε11] = 0

The following lemma is not explicitly formulated in Chan and Wei (1987), but can be

easily obtained by the proofs in Chan and Wei (1987), technique of change of variable and

It´o formula. Thus, the details are omitted here.

Lemma 3.2 Let ρT = 1

c
T , where c
following reparameterized AR(1) model,

−

= 0 is a ﬁxed constant. Suppose yt comes from the

yt = ρT yt

−

1 + εt,

t = 1, 2, ...T,

12

6
where y0 = 0 and

εt, t
{

1
}

≥

are i.i.d. random variables with E[ε1] = 0 and E[ε2

1] = 1. Then

T

t=1
X
T

1

T −

2

T −

Xt=1
W (t), 0
{

1εt

yt

−

d
−→

b
2c

y2
t
−

1

d
−→

b
2c

(cid:18)

1

(1 + bt)−

1W (t)dW (t),

0

Z
2

1

(cid:19)

0
Z

(1 + bt)−

2W 2(t)dt,

t

1
}

≤

≤

is a standard Wiener process.

(3.8)

(3.9)

where b = e2c

1 and

−

With the help of the above lemma and Theorem 2.1, we have the following result.

Theorem 3.3 Let ρ = ρT = 1

c
T , where c

−

= 0 is a ﬁxed constant. For t = 1, 2, ..., T and

i = 1, 2, ..., N , we suppose yit satisﬁed the following reparameterized AR(1) model,

yit = ρT yi,t

−

1 + εit,

i = 1, 2, ..., N,

t = 1, 2, ...T,

where yi0 = 0 for all i

and E[ε2

11] = 1. Then

1 and

εit, i
{

≥

1, t

1
}

≥

≥

are i.i.d random variables with E[ε11] = 0

√N T (ˆρT −

ρT )

d
−→

N

0,

(cid:18)

2c

−

4c2
1 + e−

2c

.

(cid:19)

(3.10)

Proof.

It follows from Theorem 2.1 and Lemma 3.2 that we only need to verify the

corresponding conditions of moment convergence and calculate the variance of the right

hand side of (3.8) and the expectation of the right hand side of (3.9). To verify the conditions

of moment convergence. It is true that for every i

1

≥

1

T −

E

"

T

Xt=1

yi,t

−

1εit

#

= 0,

1

T −

T

t=1
X

E





yi,t

−

1εit

!

2





1)

ρ2(t
−
T
ρ2
T

−

−
1

1
T 2

T

1

t=1
X
1

T 2(1
2c

−

ρ2
T )
−
1 + e−
4c2

2

1
1

ρ2T
T
ρ2
T (cid:19)

,

−
−

−

(cid:18)
2c

T

,

2c

−

1 + e−
4c2

2c

,

=

=

→

T

13

E

T −

"

T

2

Xt=1

y2
i,t

−

1

#

= E



1

T −


(1 + bt)−

1

E

b
2c

(cid:20)

0
Z

yi,t

−

1εit



→

!



Xt=1

1W (t)dW (t)
(cid:21)

= 0,

6
 
 
1

b
2c

E

"(cid:18)

0
Z

(1 + bt)−

1W (t)dW (t)

(cid:19)

2

#

=

=

=

=

according to It´o isometry theorem, and

b
2c

E

"(cid:18)

2

1

(cid:19)

0

Z

(1 + bt)−

2W 2(t)dt

= E

#

(1 + bt)−

1W (t)

2

dt

(cid:21)

(cid:1)

t
(1 + bt)2 dt

1

(cid:0)

0
(cid:20)Z
1

b2
4c2 E
b2
4c2
1
4c2 [ln(1 + b)
1 + e−
2c
4c2

−

Z

2c

0

b/(1 + b)]

−

1

(1 + bt)−

1W (t)dW (t)

2c

.

(cid:19)

2

#

b
2c

0
Z
1 + e−
4c2

"(cid:18)

2c

−

=

To calculate the variance of the right hand side of (3.8) and the expectation of the right

hand side of (3.9). Note that the latter has just been done. For the former, it is easy to see

that

V ar

1

b
2c

(cid:18)

0

Z

(1 + bt)−

1W (t)dW (t)

= E

(cid:19)

b
2c

"(cid:18)

1

(1 + bt)−

2

1W (t)dW (t)

#

(cid:19)

2c

−

=

0

Z
1 + e−
4c2

2c

.

The proof is complete.

(cid:3)

Remark 3.4 It is easy to see that

4c2
1 + e−

2c = 2.

lim
0
c
→

2c

−

Thus, the second part of Theorem 3.1 can be regarded as a complementary of Theorem 3.3.

Now we investigate the case where ρ = 1

c
kT , where c

−

= 0 and kT = o(T ) is an

increasing function of T diverging to inﬁnity. First, we introduce a result about the limiting

distribution of ˆρT in univariate time seires AR(1) model which is taken from Philips and

Magdalinos (2007).

Lemma 3.3 Let ρT = 1

c
kT , where c

−

= 0 is a ﬁxed constant and kT = o(T ) is an

increasing function of T diverging to inﬁnity. For t = 1, 2, ..., T , suppose yt satisﬁed the

following reparameterized AR(1) model,

yt = ρT yt

−

1 + εt,

t = 1, 2, ...T,

14

6
6
where y0 = 0 and

εt, t
{

1
}

≥

Then, for c > 0,

are i.i.d. random variables with E[ε1] = 0 and E[ε2

1] = 1.

1
√T kT

T

t=1
X

1εt

yt

−

d
−→

N (0,

1
2c

),

1
T kT

T

t=1
X

y2
t
−

1

P
−→

1
2c

;

(3.11)

(3.12)

and for c < 0,

1
ρT
T kT

T

t=1
X

yt

−

1εt, −
(ρT

2c
T kT )2

T

t=1
X

y2
t
−

1

!

d
−→

(XY, Y 2),

(3.13)

where X and Y are independent random variables obeying N (0, 1/(

−

2c)).

We now study the panel data case. By employing Theorem 2.1 and Lemma 3.3, we

immediately have the following result.

Theorem 3.4 Let ρT = 1

c
kT , where c

−

= 0 is a ﬁxed constant and kT = o(T ) is an

increasing function of T diverging to inﬁnity. For t = 1, 2, ..., T and i = 1, 2, .., N , suppose

yit satisﬁed the following reparameterized AR(1) model,

yit = ρT yi,t

−

1 + εit,

t = 1, 2, ..., T,

i = 1, 2, ..., N,

where yi0 = 0 for all i

1 and

and E[ε2

≥
11] = 1. Then, for c > 0 we have

≥

εit, i
{

1, t

1
}

≥

are i.i.d. random variables with E[ε11] = 0

and for c < 0 we have

p

N T kT ( ˆρT −

ρT )

d
−→

N (0, 2c)

√N kT ρT

T (ˆρ

ρ)

−

d
−→

N (0, 4c2).

(3.14)

(3.15)

Proof. The proofs of (3.14) and (3.15) are similar, so we only prove (3.15) here. To do so,

it follows from Theorem 2.1 and Lemma 3.2 that we only need to verify the corresponding

conditions of moment convergence and calculate the variance of XY and the expectation

of Y 2 in the right hand side of (3.13). Noting that ρ−

T
T = o(kT /T ) by Proposition A.1 in

Phillips and Magdalinos (2007), it is true that for every i

1,

≥

E

1
ρT
T kT

"

T

t=1
X

yi,t

−

1εit

#

= 0,

15

 
6
1
ρT
T kT

T

t=1
X

yi,t

−

1εit

!

E





2





=

=

1
T k2
ρ2T
T

T

1

1)

ρ2(t
−
T
ρ2
T

−

−
1

t=1
X
1
T (1

−

ρ2T
T k2

T

−

1
1

ρ2T
T
ρ2
T (cid:19)

−
−

ρ2
T )
1

(cid:18)

= o(1) +

k2
T (1

ρ2
T )2

−

E

2c
−
(ρT
T kT )2

"

T

t=1
X

y2
i,t

−

1

#

2c
= −
T k2
ρ2T
T

→

1

T

t=1
X

−
1

E [XY ] = 0,

V ar

(XY )2

= E

1
4c2 ,
ρ2(t
−
T
ρ2
T

1)

= o(1) +

2c

−
k2
T (1

−
1
4c2 , E[Y 2] =

ρ2
T )2 → −
1
2c

−

.

1
2c

,

−
(XY )2

=

The proof is complete.

(cid:0)

(cid:1)

(cid:2)

(cid:3)

(cid:3)

References

[1] Anderson.T.W. (1959). On asymptotic distributions of estimates of parameters of stochastic diﬀerence

equations. Ann. Math. Statist., 1, 676-687.

[2] Chan, N. H. and Wei, C. Z. (1987). Asymptotic inference for nearly nonstationary AR (1) processes.

Ann. Statist., 1, 1050-1063.

[3] Levin, A. T. and Lin, C. F. (1992). Unit root tests in panel data: asymptotic and ﬁnite-sample

properties. Economics Working Paper Series.

[4] Mann, H. B. and Wald, A.

(1943). On the statistical treatment of linear stochastic diﬀerence

equations. Econometrica, 11, 173-220.

[5] Phillips, P. C. B. (1987). Towards a uniﬁed asymptotic theory for autoregression. Biometrika, 74

(3), 535-547.

[6] Phillips, P. C. B. and Magdalinos, T. (2007). Limit theory for moderate deviations from a unit

root. Journal of Econometrics, 1, 115-130.

[7] Rao, M. M. (1978). Asymptotic distribution of an estimator of boundary parameter of an unstable

process. Ann. Statist., 6, 185-190.

[8] Sung, S. H. (1999). Weak law of large numbers for arrays of random variables. Statistics & Probability

Letters, 42, 293-298.

[9] White, J. S. (1958). The limiting distribution of the serial correlation coeﬃcient in the explosive case.

Ann. Math. Statist., 29, 1188-1197.

16

 
