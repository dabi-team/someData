9
1
0
2

p
e
S
0
1

]

R
P
.
h
t
a
m

[

2
v
1
6
8
9
0
.
0
1
8
1
:
v
i
X
r
a

Persistence exponents via perturbation theory:
AR(1)-processes

Frank Aurzada1

Marvin Kettner1

September 11, 2019

Abstract

N, where ρ

For AR(1)-processes Xn = ρXn−1 + ξn, n

R and
(ξi)i∈N is an i.i.d. sequence of random variables, we study the persis-
tence probabilities P(X0
. For a wide
class of Markov processes a recent result [3] shows that these proba-
bilities decrease exponentially fast and that the rate of decay can be
identiﬁed as an eigenvalue of some integral operator. We discuss a per-
turbation technique to determine a series expansion of the eigenvalue
in the parameter ρ for normally distributed AR(1)-processes.

0, . . . , XN

0) for N

→ ∞

≥

≥

∈

∈

Keywords. autoregressive process; eigenvalue problem; integral equation;
Markov chain; persistence; perturbation theory

1

Introduction

The major question in persistence is to understand the behaviour of a stochas-
tic process in the case it has an unusually long excursion. A ﬁrst goal in this
context is to compute the rate of decay of the probability

P(X0 ≥

0, . . . , XN

0),

≥

as N

,

→ ∞

∈

N is a real-valued stochastic process.

where (Xn)n
Persistence probabilities have received signiﬁcant attention both classically
and recently. We refer to the surveys [7] (from a theoretical physics point of
view) and [4] (for a mathematics point of view) as well as to the monographs
[21, 22].

1Technische Universität Darmstadt, Schlossgartenstraße 7,

64287 Darmstadt,
aurzada@mathematik.tu-darmstadt.de, kettner@mathematik.tu-

Germany.
darmstadt.de

E-mail:

1

 
 
 
 
 
 
The guiding idea for the relevance of persistence in the context of physical
systems can be sketched as follows. Consider a complicated spatial physical
system started in some disordered state. When looking at some speciﬁc
spatial point, one can ask the question when the state of this point has
changed signiﬁcantly compared to the initial state. The probability of this
taking rather long, which is clearly a persistence probability, is considered to
be a measure for the relaxation time of the system. Even though the system
may be very complicated due to non-trivial interactions, this quantity might
still be accessible, contrary to global quantities.
The present paper deals with discrete time Markov chains on a general state
space. It is well-known that in the case of Markov processes, non-exit prob-
abilities should have close relations to eigenvalues of operators. However, es-
tablishing such a connection is often non-trivial. The purpose of the present
paper is to establish such a connection for a speciﬁc class of Markov chains
and use it to apply results from perturbation theory for linear operators [15].
The setup is as follows.
Let (ξi)i
ρ
∈
(ξi)i

1 be a sequence of i.i.d. random variables with density φ and let
R be a constant. Moreover, let X0 be a random variable independent of

1. A one-dimensional autoregressive process is deﬁned by

≥

≥

Xn := ρXn

1 + ξn, n

1.

−

A φ(y

ρx) dy.

≥
N is a Markov chain with starting point X0 and transition
∈

The process (Xn)n
probabilities p(x, A) =
Although the structure of this process is quite simple, it is diﬃcult to obtain
asymptotic results of the persistence probabilities and the exact asymptotic
behaviour is still an open problem. Very often these probabilities tend to
zero exponentially fast and we are interested in the rate of the decay, the
so-called persistence exponent. Let P : L∞(R)
L∞(R) be deﬁned by
P f (x) :=

R f (y)p(x, dy). Furthermore, we set

→

−

R

R

P + : L∞([0,

))

∞

→

L∞([0,

∞

)), P +(f )(x) := P (f 1l[0,

))(x)

∞

and let X0 ∼

µ. Based on the observation

P(X0 ≥

0, . . . , XN

0) =

≥

0
Z

∞

(P +)N (1l) dµ,

(1)

we relate the persistence exponent to an eigenvalue of (a modiﬁcation of)
P +.
In addition, we aim to give a series expansion (in the parameter ρ)
of the desired persistence exponent. Since the proofs depend on a certain

2

≥

1 are Gaussian.

transform of the integral operator, we will however restrict our attention to
the case where the (ξi)i
The outline of this paper is as follows. Section 2.1 establishes the relation be-
tween the persistence exponent and the largest eigenvalue of some self-adjoint
Hilbert-Schmidt integral operator. It is worth pointing out that Lemma 3,
which is stated also in that section, may make it possible to generalize results
of this paper to other Markov processes. In Section 2.2, our main result, the
series expansion of the persistence exponent, is stated. Section 2.3 contains
related work, possible generalizations, and further remarks. Section 3 is de-
voted to the proofs. In Appendix A we give a brief exposition of auxiliary
results from perturbation theory.

2 Results

2.1 Connection between persistence probabilities and an

eigenvalue problem

≥

Unless otherwise stated we assume that ξ1 and X0 are standard normally
distributed. The canonical integral operator P + is not suitable to relate the
persistence exponent to an eigenvalue, due to compactness problems, i.e. for
1, the integral operator (P +)n is not compact [2, Remark
ρ > 0 and any n
2.13]. For this reason, we consider a modiﬁcation of the canonical integral
operator which satisﬁes a certain compactness and irreducibility condition
and allows to establish the connection between the persistence exponent
and an eigenvalue. Moreover, this operator is very suitable for perturbation
theory.
Deﬁnition. Let γ be the standard Gaussian measure on R, i.e. dγ(x) =

1
√2π

e−

x2
2 dx. For

−

1 < ρ < 1, let Mρ be given by

Mρ : L2([0,

), γ)

∞

→

L2([0,

∞

), γ), Mρf (x) =

where mρ(x, y) := 1
√1
−

ρ2

e−

ρ2x2+ρ2y2−2ρxy
2(1−ρ2)

.

f (y)mρ(x, y) dγ(y),

∞

0

Z

The operator Mρ is well-deﬁned, self-adjoint and compact, which is proved
in Section 3. Moreover, by the Mehler formula [19], [13, Section 4.2], we
have

hn(x)hn(y)ρn.

mρ(x, y) =

∞

n=0
X

1
n!

3

1)ne

Here, hn denotes the n-th Hermite polynomial given by the formula hn(x) :=
x2
2 , i.e. the ﬁrst Hermite polynomials are h0(x) = 1, h1(x) =
1.

x2
2 dn
(
−
x, h2(x) = x2
We can now formulate the connection between the persistence probabilities
and the eigenvalue problem of Mρ.

dxn e−
−

Theorem 1. Let

1 < ρ < 1. Then

−
cρλN

ρ ≤

P(X0 ≥

0, . . . , XN

0)

≥

≤

CρλN
ρ ,

where λρ

∈

(0, 1) is the largest eigenvalue of Mρ and cρ, Cρ > 0.

2.2 Perturbation theory for the persistence exponent

In the following theorem, we prove the existence of a power series for the
desired persistence exponent.

Theorem 2. For λρ from Theorem 1 we have

λρ =

∞

n=0
X

Knρn, Kn

R,

∈

for ρ

(
−

∈

r0, r0), where

1
3

.

r0 ≥
Remark. Based on numerical calculations, we expect that the radius of con-
vergence is signiﬁcantly larger than the value 1
3 that we can prove analyt-
ically.
It remains an interesting open problem to determine the radius of
convergence.
However, the radius of convergence can be at most 1. It was proved e.g. in
[6] that for ρ
1 the persistence probability tends to a constant so that one
has λρ = 1 for any ρ
One may further ask whether a power series for the persistence exponent
can be obtained if ρ
1. By [11], the behaviour of the persistence proba-
bilities is also exponential. It would be very interesting to ﬁnd any further
information about the persistence exponent there.

≤ −

1.

≥

≥

As stated above, the kernel mρ can be expressed as a power series in ρ.
Theorem 2 shows that the largest eigenvalue can also be expressed as a power
series in ρ. In addition, the corresponding eigenfunction can be expressed

4

as a power series in ρ (Appendix A, Theorem 4). Hence, the eigenvalue
equation

can be rewritten as

λρfρ =

∞

0
Z

fρ(y)mρ(x, y) dγ(y)

∞

ρnKn

∞

ρigi(x) =

∞

∞

∞

ρigi(y)

ρnan(x, y) dy

n=0
X

i=0
X

0
Z

i=0
X

n=0
X

with an(x, y) = 1
n! hn(x)hn(y). Because in our case the quantity an(x, y) has
a “nice” product form, a comparison of the coeﬃcients in ρ and x yields that
R and we get the following
gj(x) =
equations

j
i=0 Gi,jhi(x) for some constants Gi,j

∈

P

k

i=j
X

Kk

−

iGj,i =

k

j

−

i=0
X

Gi,k

−

jψi,j,

0

j

≤

≤

k,

k

N,

∈

(2)

where

ψi,j =

1
j!

Z

∞

0

hi(y)hj(y) dγ(y),

i, j

0.

≥

With this iterative formula we are able to compute the coeﬃcients (Kn)n
explicitly. The ﬁrst coeﬃcients are given by

K0 =

K1 =

K2 =

K3 =

K4 =

K5 =

K6 =

K7 =

K8 =

,

,

1
2
1
π
1
π −
7
6π −
1
π −
43
40π −
7
6π −
117
112π −
1
π −

40
π4 ,

2
π2 ,
6
π2 +
35
3π2 +
19
π2 +
5149
180π2 +
799
20π2 +

8
π3 ,
40
π3 −
116
π3 −
790
3π3 −
7762
15π3 −

8843
168π2 +

16541
18π3 −

224
280
π5 ,
π4 +
3260
3π4 +
3164
π4 +
23147
3π4 +

1344
π6 ,

2016
π5 −
29456
3π5 −
34944

π5 −

14784
π6 +
86688
π6 +

8448
π7 ,
109824

π7 −

54912
π8

.

Unfortunately, we could not ﬁnd a helpful structure to obtain a closed-form
expression for the n-th coeﬃcient.

5

2.3 Related work and discussion

The idea of relating the persistence exponent to an eigenvalue of an inte-
gral operator has already received great attention (see [2, 3, 12, 17], also see
[8, 9, 20, 25, 26] for the quasi-stationary approach). Among these, [12] is
a very recent work, which uses functional analytical methods, such as the
Fredholm alternative to obtain a precise asymptotic behaviour of the per-
sistence probabilities. However, the persistence exponent is given there only
implicitly. For a completely diﬀerent approach to persistence probabilities of
autoregressive processes via their generating polynomials we refer the reader
to [11]. Nevertheless, quantitative statements about the persistence expo-
nent are known only in a few examples (see [3]).
We believe that our techniques and results have a greater generality. In par-
ticular, we conjecture that Theorem 1, Theorem 2, and equations of type (2)
are valid more generally, e.g. for other innovation distributions and also for
moving average processes (see e.g. [3, 18]). For this, suitable transformations
of the integral operator P + must be found. Another possible generalization
is to use these methods for two-sided exit problems.

Remark. Firstly, note that (X0, X1, X2, . . .)T = S−

1(X0, ξ1, ξ2, . . .)T , where

S =

1
ρ
−
0
...
0

0
1
ρ

−

. . .

0
0
1
. . .
0

. . . 0
. . . 0
0
...
. . .
ρ 1

−










.










Secondly, observe that since the innovation vector (X0, ξ1, ξ2, . . .) is i.i.d.
Gaussian, it is in particular isotropic, so that U := (X0,ξ1,...,ξN )
is uniformly
(X0,ξ1,...,ξN )
||
distributed on the unit sphere of RN +1. Therefore, the persistence probability,

||

≥

0, . . . , XN

0) = P(S−

1(X0, ξ1, . . . , ξN )

P(X0 ≥
is the same as the normalized area of the intersection of the unit sphere of
RN +1 with the cone SRN +1
0 .
Our results thus carry over to any isotropic vector (X0, ξ1, ξ2, . . .). However,
this vector generates an AR(1)-process (i.e. the innovations are i.i.d.) if and
only if the innovations are Gaussian [16].

0 ) = P(U

SRN +1
≥

RN +1
≥

∈

∈

≥

0 ),

6

3 Proofs

3.1 Proofs of the results of Section 2.1

We begin by proving the properties of the operator Mρ. Since mρ(x, y) =

ρ2x2+ρ2y2−2ρxy
2(1−ρ2)

, we obtain

e−

1
√1

−

ρ2

∞

∞

mρ(x, y)2 dγ(y) dγ(x)

0 Z
0
Z
1
=

1

−

ρ2
1

0 Z
0
Z

=

=

2π(1

2π(1

ρ2)

ρ2)

0

Z

0

Z

−
1

−

∞

∞

e

−ρ2y2−ρ2x2+2ρxy
1−ρ2

dγ(y) dγ(x)

∞

e−

1+ρ2
2(1−ρ2)

x2

1+ρ2
2(1−ρ2)

y2

∞

e−

2ρxy
1−ρ2 dy dx

e

0
Z
x2 √π

1+ρ2
2(1−ρ2)

∞

e−

ρ2)

2(1
−
(1 + ρ2)

2

p
√2ρx
p
ρ2)(1 + ρ2) !

2ρ2x2

e

(1−ρ2)(1+ρ2) dx

Erfc

−
−

·

(1
−(1+ρ2)2x2+4ρ2x2

p
2(1−ρ2)(1+ρ2) dx

∞

e

(1−ρ2)
2(1+ρ2)

x2

∞

e−

dx

C

≤

= C

<

∞

0

Z

0

Z

·

·
.

L2(γ

)
·

So mρ(
γ) and hence, the operator Mρ is a Hilbert-Schmidt
,
·
integral operator [23, Chapter IV, Proposition 6.5] and thus well-deﬁned
and compact. In addition, the operator is obviously self-adjoint.

⊗

∈

In preparation for the proof of Theorem 1, we begin by relating the integral
operator Mρ to the persistence problem of the AR(1)-process.
X0 and ˜ξi := c
Let ˜X0 := c
·
trivially we have P(X0 ≥
N
the kernel

(0, c2) for a constant c > 0. Then
∼ N
0, . . . , ˜XN
0) = P( ˜X0 ≥
0) for all
≥
N. The transition operator ˜P of the Markov chain ( ˜Xn)n is given by

ξi, i.e. ˜ξi
0, . . . , XN

≥

∈

·

˜p(x, dy) =

1
√2π√c2

y2+ρ2x2−2ρxy
2c2

e−

dy.

Write ˜P + : L∞([0,

))

∞

→

L∞([0,

∞

)), ˜P +(f )(x) = ˜P (f 1l[0,

))(x) as in the

∞

7

 
introduction. For c =

ρ2 we obtain

1

−

˜p(x, dy) =

√2π

p
1

1

ρ2

−

ρ2x2+ρ2y2−2ρxy
2(1−ρ2)

e−

y2
2 dy = mρ(x, y) dγ(y).

e−

This and the fact that L2(γ) contains all bounded functions yield ˜P +1l =
Mρ1l and hence by equation (1),

p

P(X0 ≥

0, . . . , XN

0) =

≥

∞

M N

ρ (1l) d˜µ,

0

Z

−

N

(0, 1

ρ2). Note that we related the persistence problem to
where ˜µ =
an L2-operator, contrary to relation (1). This has two advantages: Mρ is
compact and allows to use perturbation theory, contrary to P +.
The proof of Theorem 1 is based on a Perron-Frobenius statement for integral
operators [14]. We use the following version of this theorem as stated in [23,
Chapter V, Theorem 6.6].

Proposition. Let E = Lp(Ω,
p
space and 1
given by a measurable kernel k

≤ ∞

≤

. Suppose T : E

, ν), where (Ω,

, ν) is a σ-ﬁnite measure
E is a bounded integral operator
0 satisfying the following two assumptions:

→

F

F

≥

(a) some power of T is compact,

(b) for all B

∈ F

such that ν(B) > 0 and ν(BC) > 0 it holds that

k(x, y) dν(x) dν(y) > 0.

ZBC

ZB

Then λ(T ), the spectral radius of T , is an eigenvalue of T with a unique
normalized, positive eigenfunction f , i.e.
kLp(ν) = 1 and f > 0 ν-a.e. and
any eigenfunction ˜f with these two properties coincides with f ν-a.e.

f
k

To obtain a relation between the persistence exponent and the largest eigen-
value of some integral operator, we will use the following lemma which may
be of interest when generalizing our results to other situations.

Lemma 3. Under the hypotheses of the above proposition, if moreover 1l
E,
the eigenfunction f is bounded and µ is a ﬁnite measure with dµ = g dν,
g

, ν) with 1

Lq(Ω,

∈

p + 1

q = 1, then

∈

F

T N (1l)(x) dµ(x) = λ(T )N +o(N ).

ZΩ

8

Additionally, if p = 2 and the operator T is normal, i.e. T T ∗ = T ∗T , where
by T ∗ the adjoint operator is denoted, we get

cλ(T )N

≤

ZΩ

T N (1l)(x) dµ(x)

Cλ(T )N

≤

for some constants c, C > 0.

Proof of Lemma 3. Upper bound: We deﬁne a functional by ϕµ : Lp(ν)
R, f
7→
We obtain
R

Ω f (x)g(x) dν(x). It holds that

Ω f (x) dµ(x) =

ϕµ
k

g
k

=

k

→
kLq (ν).

R
T N (1l)(x) dµ(x) = ϕµ(T N (1l))

ZΩ

ϕµ

T N (1l)

k · k

≤ k
g
kLq (ν) · k
≤ k
= λ(T )N +o(N ),

T N

kLp(ν)
1l

k · k

kLp(ν)

∈

Lp(ν), g

1
since 1l
N . If
∈
= λ(T N ) = λ(T )N due to the
p = 2 and T is normal, then we have
spectral mapping theorem (see e.g. [10, Chapter VIII, Theorem 2.7]) and
thus

Lq(ν) by assumption and λ(T ) = limN
T N
k

Cλ(T )N .

→∞ k

T N

k

k

Ω T N (1l) dµ(x)

≤

Lower bound: Since the eigenfunction f is bounded by assumption, we have
1l(x)

R

≥

f (x)
f

∞ . Hence,
k

k

T N (1l)(x) dµ(x)

ZΩ

T N

≥

ZΩ
= λ(T )N

(cid:18)

f (x)
f
k∞ (cid:19)
k
f (x)
f
k

k∞

dµ(x)

dµ(x)

ZΩ
λ(T )N ,

= c

·

where the ﬁrst inequality is due to the non-negativity of the kernel k.

Proof of Theorem 1. The assertion of the theorem is a consequence of Lemma
3 applied to Mρ. Therefore, we need to check that we are in the setting of
Lemma 3.
The operator Mρ is compact and, since mρ(x, y) > 0 for all x, y, condition
(b) of the above proposition is satisﬁed. So the spectral radius λ(Mρ) is
an eigenvalue of Mρ with a unique normalized, positive eigenfunction. To
obtain the boundedness of this eigenfunction, note that we get an eigenfunc-
)) of the operator ˜P + which is positive with corresponding
tion f

L∞([0,

∈

∞

9

eigenvalue λρ due to [3, Theorem 2.1 & Theorem 2.3]. (In [3] only a non-
negative eigenfunction is obtained, but since in our case the operator ˜P +
is irreducible, an application of the above proposition yields that the eigen-
function is actually positive.) Since ˜P +g = Mρg for bounded g, the positive
function f is an eigenfunction of Mρ. Therefore, the corresponding eigen-
value λρ is the largest one, i.e. λρ = λ(Mρ). To summarize, λρ is the largest
eigenvalue of Mρ with a positive and bounded eigenfunction.
In addition, we have

and clearly g

∈

g(x) :=

d˜µ
dγ

(x) =

ρ2x2
2(1−ρ2 )

e−

1

ρ2

1

−

L2(γ). Therefore, Lemma 3 yields

p

cρ

λN
ρ ≤

P(X0 ≥

·

0, . . . , XN

0)

Cρ

·

≤

≥

λN
ρ ,

where λρ is the largest eigenvalue of the self-adjoint Hilbert-Schmidt integral
operator Mρ.

3.2 Proofs of the results of Section 2.2

The proof of Theorem 2 is based on methods from perturbation theory. A
brief introduction including relevant deﬁnitions and theorems can be found
in Appendix A.

Proof of Theorem 2. First, we want to show that Mρ is holomorphic. Let us
consider the operator norm of the integral operator M (n) on L2([0,
), γ)
with kernel an(x, y) := 1

n! hn(x)hn(y). We compute

∞

∞

∞

an(x, y)2 dγ(x) dγ(y)

Z

0

0 Z
∞
=

∞

2

hn(x)hn(y)

dγ(x) dγ(y)

1
n!

Z

0 Z
0 (cid:18)
1
∞
hn(x)2 dγ(x)
n!

(cid:19)
∞

1
n!

·

0

Z

hn(y)2 dγ(y)

=

=

This implies

0
Z
1
4

.

M (n)
k

k ≤

1
2

.

10

(3)

n

N ρnM (n) exists on the disc
∈

Accordingly, ˜Mρ :=
< 1. The holo-
morphicity of Mρ will be proved, if we show that Mρ = ˜Mρ. Let B :=
hn(x)1l[0,N ](x) : n, N
N is a
{
fundamental subset of L2([0,
B
for every n
B.
For f

∈
[13, Chapter 2]) and hn
N. Hence it is suﬃcient to show Mρf = ˜Mρf for all f

. B is a fundamental subset since (hn)n
}

), γ) (see e.g.

∈
B and x

) we get

P
∈

∈
∈

ρ
|
|

[0,

∞

N

∈

∈

∞

Mρf (x) =

∞

mρ(x, y)f (y) dγ(y)

0

Z

0

Z

=

∞

∞

n=0
X

By [13, Equation (4.15)], we have

ρnan(x, y)f (y) dγ(y)

(4)

ρnan(x, y)
|

| ≤

∞

n=0
X

E

e|

ρ
|

(x+

η

|

|

)(y+

ζ

)

|

|

=: C(x, y)

h

i

where η, ζ are i.i.d. random variables with standard normal distribution. Let
us denote f (x) = hk(x)1l[0,N ](x). We can exchange sum and integral in (4)
since

ρnan(x, y)f (y)
|
|

dγ(y)

C(x, y)

f (y)
|

|

dγ(y)

C(x, y) dγ(y)
hk(y)
|
|

N

·

0
Z

hk(y)
|
|

dγ(y)

∞

∞

n=0
X
∞

0
Z

N

0
Z
C(x, N )

.

∞

0
Z

≤

=

≤
<

So, we obtain

Mρf =

∞

ρn

∞

an(x, y)f (y) dγ(y) = ˜Mρf,

n=0
X

0

Z

showing that Mρ is holomorphic. Furthermore, λ0 is an eigenvalue with
algebraic multiplicity equal to 1 [23, Chapter V, Theorem 5.2]. The assertion
of the theorem now follows from Appendix A Theorem 4 and Corollary 6 by
using equation (3).

11

Acknowledgement. We would like to thank two anonymous referees for
their comments that helped to improve the exposition of this paper.
This work was supported by the Deutsche Forschungsgemeinschaft (grant
AU370/4).

Appendix A Collection of auxiliary results from per-

turbation theory

A.1 Overview

The aim of this appendix is to give the reader a simple and almost self-
contained introduction to the relevant results of perturbation theory for this
paper. The appendix is based on the classical work [15].
(X) for the set of
Let X be a Banach space with norm
X . We write
bounded linear operators on X. For T
the
operator norm of T , i.e.
X
c
.
}
{
For a sequence (Tn)n of operators on X and an operator T on X, we write
C be a domain.
limn

(X) we will denote by
∈ L
x
c
T x
0 :
k
k

T
k
X for all x
k

= 0. Moreover, let D

Tn = T if limn

:= inf

k
∈

T
k

k · k

X
k

Tn

≤

≥

L

T

k

→∞

→∞ k

−

k

⊆

Deﬁnition. The operator-valued function
phic if limh

exists for all t

−T

(t)

0 T

(t+h)
h

: D

T
D.

→ L

(X) is called holomor-

→

∈

Throughout the appendix, we will make use of properties of holomorphic
operator-valued functions. Roughly speaking, the results of complex-valued
functions can be generalized to operator-valued functions by considering
scalar-valued functions deﬁned via the dual space. For an overview of this
topic we refer to [5, Section 3.3, Section 10.1] and [1, Appendix A].
A holomorphic operator-valued function on a disc can be expressed as a
power series on this disc. Conversely, a convergent power series on a disc
deﬁnes a holomorphic function. To simplify notation we continue to write
Tt for
(t). The key to prove Theorem 2 are the following results from
perturbation theory.

T

T

: D

→ L

(X) is holomorphic. Let t0 ∈

Theorem 4. Assume that
D and
λ0 be an isolated eigenvalue of Tt0 with algebraic multiplicity equal to one.
Then there exists an open neighbourhood U
D of t0 and a holomorphic
function λ : U
In addition, there exists an open neighbourhood U ′ ⊆
phic function g : U ′ →
U ′ ∩
λt for t

U .
D of t0 and a holomor-
X such that gt is an eigenvector of Tt with eigenvalue

C such that λt is an eigenvalue of Tt for t

U .

→

⊆

∈

∈

12

acn

k ≤

T (n)
k

1 for all n

Theorem 5. Under the conditions of Theorem 4 with Tt =
N(t
n
−
∈
N with a, c
t0)nT (n) assume that
0. The
−
following lower bound for the radius of convergence r of the power series of
λt at t0 holds:

1
R0(λ)
k
k
) is the resolvent operator of Tt0 and Γ is an arbitrary closed
where R0(
·
curve that lies outside Σ(Tt0 ) with positive direction which encloses λ0, where
Σ(Tt0 ) is the spectrum of Tt0 .

min
λ
Γ
∈

+ c

P
≥

≥

∈

a

r

,

Corollary 6. Under the assumptions of Theorem 5, and if moreover X is a
Hilbert space and Tt0 is normal, we get

r

≥

1
2a
d + c

,

where d := dist (λ0, Σ(Tt0 )

λ0}
).

\ {

A.2 Preliminaries

Lemma 7. Let T
converges in the operator norm and we have

(X) with

T
k

∈ L

k

< 1. Then the Neumann series

∞n=0 T n

P

(Id

−

T )−

1 =

∞

T n.

n=0
X

This is a well-known result in functional analysis and can be found for in-
stance in [24, Propostion I.1.6].

Deﬁnition. For T
such that (T
The operator-valued function R : σ(T )
the resolvent operator of T .

∈ L

λ Id) has a bounded inverse.

−

(X) the resolvent set σ(T ) is the set of all λ

C

∈

(X), λ

(T

−

7→

→ L

λ Id)−

1 is called

For abbreviation, we write T
arise.

−

λ instead of T

−

λ Id when no confusion can

Lemma 8. We have

R(λ′)

−

R(λ) = (λ′

−

λ)R(λ′)R(λ)

for all λ, λ′ ∈

σ(T ). In particular, R(λ) and R(λ′) commute.

13

Proof. The following easy computation shows the statement:

R(λ′)

−

R(λ) = R(λ′)(T

R(λ′)(T
λ)R(λ)
R(λ′)λR(λ) + R(λ′)λ′R(λ)

−

−

λ′)R(λ)

−

=
−
= (λ′

λ)R(λ′)R(λ).

−

Proposition. Let λ, λ0 ∈
λ
σ(T ) with
|
ﬁrst Neumann series for the resolvent
In this case, we have

<
λ0|
−
∞n=0(λ

1 then the so-called
R(λ0)
k
λ0)nR(λ0)n+1 is convergent.
−

k−

R(λ) =

∞

(λ

λ0)nR(λ0)n+1.

P

−

n=0
X
) is holomorphic on σ(T ).
This shows that R(
·
σ(T ). By Lemma 8 we obtain

Proof. Let λ, λ0 ∈

R(λ) = R(λ0) (1

(λ

−

−

λ0)R(λ0))−

1 .

If

(λ
k

λ0)R(λ0)
k

−

< 1, Lemma 7 implies that

R(λ) = R(λ0)

λ0)nR(λ0)n,

∞

(λ

n=0
X

−

which proves the statement.

A.3 Perturbation of the resolvent operator

We deﬁne

R(t, λ) = (Tt

1

λ)−

−

for any (t, λ) with λ
σ(Tt). We already know from the last proposition
that R(t, λ) is holomorphic in λ for each ﬁxed t. Now we will show that
R(t, λ) is holomorphic in both variables.

∈

Proposition. Let
→ L
phic in both variables t and λ.

: D

T

(X) be holomorphic. Then R(t, λ) is holomor-

14

σ(Tt0 ). Since
Proof. Let (t0, λ0) such that λ0 ∈
t0)n for
∞n=0 T (n)(t
t
write Tt =
|

t0|

−

−

T

small. We have

is holomorphic we can

P
λ = Tt0 −

Tt

−

λ0 −

(λ

−

λ0) +

∞

T (n)(t

t0)n

−

= (Tt0 −

λ0)

1

(cid:16)

λ

−

−

(cid:0)

∞

T (n)(t

n=1
X

−

t0)n

R(t0, λ0)

.

(cid:1)

(cid:17)

n=1
X
λ0 −

Thus,

R(t, λ) = (Tt

If

λ)−

−

1 = R(t0, λ0)
(cid:16)

1

λ

λ0 −

−

−

(cid:0)

∞

T (n)(t

n=1
X

−

t0)n

R(t0, λ0)

1

−

.

(cid:1)

(cid:17)

∞

T (n)(t

λ

λ0 −

−

k
(cid:0)

n=1
X

(cid:1)

t0)n

−

R(t0, λ0)
k

< 1,

(5)

the last expression can be written as a double series in λ and t by Lemma 7.
This condition is satisﬁed if

∞

+

n=1
X
λ0|

λ
|

−

λ0|

t
|

−

n

t0|

T (n)
k

k

<

R(t0, λ0)
−
k
k

1,

(6)

which is the case if

t0|
−
Remark. If we ﬁx λ and write R(t, λ) as a power series in t at t0 we get

are small enough.

and

λ
|

t
|

−

R(t, λ) = R(t0, λ)

We can rewrite this as

(cid:16)

Xk=0

(cid:0)

∞

∞

T (n)(t

−

t0)nR(t0, λ)

k

.

(cid:17)

(cid:1)

−

n=1
X

R(t, λ) =

∞

(t

Xk=0

−

t0)kR(k)(λ),

(7)

with

R(k)(λ) =

k1+
ki

+kn=k
X
···
1, n
≥

≥

1

1)nR(t0, λ)T (k1)R(t0, λ)T (k2)

(
−

T (kn)R(t0, λ).

· · ·

The right-hand side of equation (7) is called the second Neumann series for
the resolvent.

15

A.4 Perturbation of the eigenprojection, eigenvalue, and eigen-

vector

Proposition. Let T
(X) and λ0 be a simple isolated eigenvalue of T0.
Let Γ be a closed curve in σ(T ) with positive direction which encloses λ0.
Then

∈ L

P0 :=

−

1
2πi

ZΓ

R(λ) dλ

is a projection on the eigenspace of λ0.

Proof. We need to show that:

(i) P0 is a projection, i.e. P 2

0 = P0.

(ii) R(P0) = M0, where R(P0) is the range of P0 and M0 is the eigenspace

of λ0.

Let Γ′ be a closed curve in σ(T ) with positive direction which encloses λ0
and lies outside Γ. Then

Γ′ R(λ) dλ and we have

Γ R(λ) dλ =

R

R

R(λ) dλ

R(µ) dµ

·

ZΓ′
R(λ)R(µ) dλ dµ

2πi)2P 2

0 =

(
−

=

=

=

ZΓ

ZΓ′

ZΓ

µ

ZΓ
0 dµ

ZΓ′

ZΓ′

2πi

=

−
= (

−

ZΓ
2πi)2P0,

R(µ) dλ dµ

1

−

λ

−

ZΓ ZΓ′

µ

1

−

λ

R(λ) dµ dλ

2πiR(λ) dλ

−

ZΓ
R(λ) dλ

where the third equality follows by Lemma 8. This shows (i). To prove (ii),
we begin by showing M0 ⊆

M0, i.e. T (x) = λ0x. Then

R(P0). Let x

∈

P0(x) =

1
2πi

−

(T

−

ZΓ

λ Id)−

1(x) dλ =

1
2πi

−

(λ0 −

ZΓ

λ)−

1(x) dλ = x.

16

Now, we proceed to show that R(P0)

M0. We compute

⊆

2πi)T P0 =

T (T

(
−

λ)−

1 dλ

−

=

ZΓ

ZΓ

Id +λ(T

λ)−

1 dλ

−

λ)−

1 dλ

λ)−

1)
1)
λ)−

=

λ(T

ZΓ

−
= Resλ0(λ(T
−
= λ0 Resλ0((T

−
R(λ) dλ

ZΓ
2πi)λ0P0.

= λ0

= (

−

Hence, for all x

X we get P0(x)

M0, which completes the proof.

∈
(X) is holomorphic and that λ0
In what follows, we assume that
T
D, with algebraic multiplicity equal to
is an isolated eigenvalue of Tt0 , t0 ∈
one. Let Γ be a closed curve in σ(Tt0 ) with positive direction which encloses
λ0.

∈
: D

→ L

Proposition. The operator-valued function

Pt :=
Γ R(t, λ) dλ is holomorphic at an open neighbourhood of t0. It holds

(t) =

→ L

(X),

: D

→

P

t

P
that dim(P0X) = dim(PtX).

R(t0, λ)

R
1 > 0, from (6) it follows that the second
Proof. Since inf λ
Γ k
∈
Neumann series for the resolvent is uniformly convergent for λ if
is
In particular, R(λ, t) is well-deﬁned for such (λ, t) and
suﬃciently small.
t
thus, Γ
small and due to the
|
proposition in A.3 we get that Pt is holomorphic at an open neighbourhood
of t0. The equality of the dimensions follows by [15, Lemma I.4.10].

σ(Tt). Hence, Pt is well-deﬁned for

t0|

t0|

k−

t
|

−

−

⊆

Proof of Theorem 4. Combining the last two propositions we see that Pt is
the eigenprojection for Tt on the eigenspace of a simple eigenvalue λt and
that Pt is holomorphic in t. Accordingly, we deduce a perturbation series for
the eigenvalue λt via the formula λt = trace(TtPt).
Let g0 be an eigenfunction of λ0. Then gt = Ptg0 ∈
element of the eigenspace of λt. If gt
holomorphic and hence gt is holomorphic. Since g0 6
at least for

PtX and thus an
= 0 it is an eigenfunction of λt. Pt is
= 0

= 0, we have that gt

small.

t
|

t0|

−

17

6
6
A.5 Lower bound for the radius of convergence

∈

−

P

∞n=0(t

t0)nT (n) for t

Let Tt =
Tt0 with algebraic multiplicity equal to one.
that for a ﬁxed λ the power series
∞n=1 T (n)(t
< 1.
R(t0, λ)
k
Proof of Theorem 5. Assume that
power series is convergent if

P
T (n)
k

t0)n

k ≤

P

−

k

D and λ0 be an isolated eigenvalue of
It follows from equation (5)
t0)n is convergent, if

∞n=0 R(n)(λ)(t

−

acn

1 with a, c

−

≥

0. Then the

t
|

−

t0|

<

1
R(t0, λ)
k

k ·

.

a + c

Γ

< inf λ
∈

Γ R(t, λ) dλ can be expressed as a power series if
a+c .
R
k·

Consequently, Pt =
1
t0|
R(t0,λ)
k
The so obtained lower bound of the radius of convergence of Pt, and there-
with of λt, depends crucially on the chosen curve Γ. It is worthwhile to get
this bound as large as possible.

t
|

−

Proof of Corollary 6. If Tt0 is a normal operator on a Hilbert space we have
that R(t0, λ) is normal and as a consequence the operator norm of R(t0, λ)
is equal to the spectral radius of R(t0, λ). From this we conclude

R(t0, λ)
k
k

= dist(λ, Σ(Tt0 ))−

1,

where Σ(Tt0) is the spectrum of Tt0 and dist is the Hausdorﬀ distance. Let
d := dist(λ0, Σ(Tt0 )
2 and center
R(t0, λ)
λ0. Then
k
k

) and let Γ be a circle with radius d
Γ and we get

λ0}
d for every λ

\ {
= 2

∈

r

≥

1
2a
d + c

.

References

[1] W. Arendt, C. J. Batty, M. Hieber, and F. Neubrander. Vector-valued
Laplace transforms and Cauchy problems, volume 96 of Monographs in
Mathematics. Birkhäuser/Springer Basel AG, Basel, 2011.

[2] F. Aurzada and C. Baumgarten. Survival probabilities of weighted ran-
dom walks. ALEA, Lat. Am. J. Probab. Math. Stat., 8:235–258, 2011.

18

[3] F. Aurzada, S. Mukherjee, and O. Zeitouni. Persistence exponents in

Markov chains. arXiv preprint arXiv:1703.06447, 2017.

[4] F. Aurzada and T. Simon. Persistence probabilities and exponents. In
Lévy matters. V, volume 2149 of Lecture Notes in Math., pages 183–224.
Springer, Cham, 2015.

[5] H. Baumgärtel. Analytic perturbation theory for matrices and operators,
volume 15 of Operator Theory: Advances and Applications. Birkhäuser
Verlag, Basel, 1985.

[6] C. Baumgarten.

Survival probabilities of autoregressive processes.

ESAIM: Probability and Statistics, 18:145–170, 2014.

[7] A. Bray, S. N. Majumdar, and G. Schehr. Persistence and ﬁrst-passage
properties in non-equilibrium systems. Advances in Physics, 62(3):225–
361, 2013.

[8] N. Champagnat and D. Villemonais. General criteria for the study of

quasi-stationarity. arXiv preprint arXiv:1712.08092, 2017.

[9] P. Collet, S. Martínez, and J. San Martín. Quasi-stationary distri-
butions: Markov chains, diﬀusions and dynamical systems. Springer
Science & Business Media, 2012.

[10] J. B. Conway. A course in functional analysis, volume 96 of Graduate
Texts in Mathematics. Springer Science & Business Media, 2007.

[11] A. Dembo, J. Ding, and J. Yan. Persistence versus stability for auto-

regressive processes. arXiv preprint arXiv:1906.00473, 2019.

[12] G. Hinrichs, M. Kolb, and V. Wachtel. Persistence of one-dimensional

AR(1)-sequences. arXiv preprint arXiv:1801.04485, 2018.

[13] S. Janson. Gaussian Hilbert spaces, volume 129 of Cambridge Tracts in

Mathematics. Cambridge University Press, Cambridge, 1997.

[14] R. Jentzsch. Über Integralgleichungen mit positivem Kern. Journal für

die reine und angewandte Mathematik, 141:235–244, 1912.

[15] T. Kato. Perturbation theory for linear operators, volume 132 of Die
Grundlehren der mathematischen Wissenschaften. Springer-Verlag New
York, Inc., New York, 1966.

19

[16] G. Letac. Isotropy and sphericity: Some characterisations of the normal

distribution. The Annals of Statistics, 9(2):408–417, 1981.

[17] S. N. Majumdar, A. J. Bray, and G. C. Ehrhardt. Persistence of a con-
tinuous stochastic process with discrete-time sampling. Physical Review
E, 64, 015101(R), 2001.

[18] S. N. Majumdar and D. Dhar. Persistence in a stationary time series.

Physical Review E, 64, 046123, 2001.

[19] F. G. Mehler. Ueber die Entwicklung einer Function von beliebig vielen
Variablen nach Laplaceschen Functionen höherer Ordnung. Journal für
die reine und angewandte Mathematik, 66:161–176, 1866.

[20] S. Méléard and D. Villemonais. Quasi-stationary distributions and pop-

ulation processes. Probability Surveys, 9:340–410, 2012.

[21] R. Metzler, G. Oshanin, and S. Redner. First-passage Phenomena and

their applications. World Scientiﬁc, 2014.

[22] S. Redner. A Guide to First-Passage Processes. Cambridge University

Press, Cambridge, 2001.

[23] H. H. Schaefer. Banach Lattices and Positive Operators. Springer,

Berlin, Heidelberg, 1974.

[24] M. Takesaki. Theory of operator algebras I, volume 124 of Encyclopaedia

of Mathematical Sciences. Springer-Verlag, Berlin, 2002.

[25] R. L. Tweedie. Quasi-stationary distributions for Markov chains on a
general state space. Journal of Applied Probability, 11(4):726–741, 1974.

[26] R. L. Tweedie. R-theory for Markov chains on a general state space I:
solidarity properties and R-recurrent chains. The Annals of Probability,
2(5):840–864, 1974.

20

