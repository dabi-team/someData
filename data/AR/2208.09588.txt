Highlights

A Review on Action Recognition for Accident Detection in Smart City Transportation Systems
Victor Adewopo,Nelly Elsayed,Zag ElSayed,Murat Ozer,Ahmed Abdelgawad,Magdy Bayoumi

• Computer Vision in Accident Detection in Smart City Transportation System.

• Action Recognition for Accident Detection in Autonomous Transportation.

• Smart City Traﬃc Monitoring and Safety.

2
2
0
2

g
u
A
0
2

]

V
C
.
s
c
[

1
v
8
8
5
9
0
.
8
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
A Review on Action Recognition for Accident Detection in Smart
City Transportation Systems⋆,⋆⋆

Victor Adewopoa,∗, Nelly Elsayeda, Zag ElSayeda, Murat Ozera, Ahmed Abdelgawadb and
Magdy Bayoumic

aSchool of Information Technology, University of Cincinnati, Cincinnati, OH, United States
bSchool of Engineering and Technology, Central Michigan University, MI, United States
cDepartment of Electrical and Computer Engineering, University of Louisiana at Lafayette, LA, United States

A R T I C L E I N F O

A B S T R A C T

Keywords:
Accident detection
Action recognition
Smart city
Smart transportation

Action detection and public traﬃc safety are crucial aspects of a safe community and a better
society. Monitoring traﬃc ﬂows in a smart city using diﬀerent surveillance cameras can play a
signiﬁcant role in recognizing accidents and alerting ﬁrst responders. The utilization of action
recognition (AR) in computer vision tasks has contributed towards high-precision applications
in video surveillance, medical imaging, and digital signal processing. This paper presents an
intensive review focusing on action recognition in accident detection and autonomous trans-
portation systems for a smart city. In this paper, we focused on AR systems that used diverse
sources of traﬃc video capturing, such as static surveillance cameras on traﬃc intersections,
highway monitoring cameras, drone cameras, and dash-cams. Through this review, we identiﬁed
the primary techniques, taxonomies, and algorithms used in AR for autonomous transportation
and accident detection. We also examined data sets utilized in the AR tasks, identifying the main
sources of datasets and features of the datasets. This paper provides potential research direction
to develop and integrate accident detection systems for autonomous cars and public traﬃc safety
systems by alerting emergency personnel and law enforcement in the event of road accidents to
minimize human error in accident reporting and provide a spontaneous response to victims.

1. Introduction

In the ﬁeld of computer vision, action recognition is a domain that has gained much attention since the advancement
of convolution neural networks (CNNs) as a tool for solving complex computer vision problems and has received much
attention in the research community over the past few years Chattopadhyay, Sarkar, Howlader and Balasubramanian
(2017). Action recognition has been used in several real-life applications such as safety and security AI Al-Faris,
Chiverton, Ndzi and Ahmed (2020); Bo, Fuqi, Rong, Peng and Xuzhu (2021), healthcare AI Muhammad, Ullah,
Imran, Sajjad, Kiran, Sannino, de Albuquerque et al. (2021); Gabrielli, Leo, Renzi and Bergamaschi (2019), and media
AI Ren and Xu (2002); Gedamu, Ji, Yang, Gao and Shen (2021). Developing algorithms that can intuitively detect
actions in video streams presents an opportunity to advance the research frontier using AI for human action recognition.
Action recognition cuts across three major activities: feature detection, action representation, and action classiﬁcation.
Detecting actions in a sequence of images or video streams presents a unique challenge based on cluttered background,
occlusion, and diﬃculties labeling human actions that are distinct from one person to another Vrigkas, Nikou and
Kakadiaris (2015).

Action recognition with a single action class in a video stream lags in practical applications. However, action
localization in untrimmed video is a more tedious task. It involves developing architectures that can accurately set
boundaries and end-to-end train algorithms that recognize action classes in an untrimmed video stream Lv and Nevatia
(2007). Pose estimation algorithms have been widely proposed in action recognition problem solving to help recognize
and understand how each action happens Jhuang, Gall, Zuﬃ, Schmid and Black (2013). Pose estimation has successful
results in multiple human action recognition tasks such as Yao, Gall, Fanelli and Van Gool (2011), Xiaohan Nie,
Xiong and Zhu (2015), Chéron, Laptev and Schmid (2015), and Raja, Laptev, Pérez and Oisel (2011). However, the

adewopva@mail.uc.edu (V. Adewopo); elsayeny@ucmail.uc.edu (N. Elsayed); elsayezs@ucmail.uc.edu (Z. ElSayed);

ozermm@ucmail.uc.edu (M. Ozer); abdel1a@cmich.edu (A. Abdelgawad); magdy.bayoumi@louisiana.edu (M. Bayoumi)

https://www.linkedin.com/in/adewopo-victor/ (V. Adewopo)

orcid(s): 0000-0002-1700-5241 (V. Adewopo); 0000-0003-0082-1450 (N. Elsayed); 0000-0001-9094-1469 (Z. ElSayed);

0000-0002-2518-3398 (M. Ozer); 0000-0002-6655-2065 (A. Abdelgawad); 0000-0002-0630-5273 (M. Bayoumi)

Adewopo et al.: Preprint submitted to Elsevier

Page 1 of 16

Review on Action Recognition for Accident Detection in Smart City

pose estimation has not shown signiﬁcance in vehicle accident detection due to the speciﬁcity of the problem and the
diﬀerences between human and vehicle actions and physical construction.

Transfer learning is a commonly used technique in extracting features of deep neural networks that have been trained
on a speciﬁc domain with robust data set to a new domain/area of application with reduced computational resources.
Previous research has leveraged the transfer learning approach to improve video stream action localization. Iqbal,
Richard and Gall (2019) experimented with action localization on pre-selected frames by leveraging transfer learning
from the existing model. The overarching goal was to simplify the complex architectures, expensive computation cost,
and ineﬃcient inferencing in existing methodologies.

The current research trend in action recognition is focused on a classical deep neural network with two stream
architectures (RGB and Optical ﬂow) Sevilla-Lara, Liao, Güney, Jampani, Geiger and Black (2018). Transferring
features from the pre-trained model on small action classes signiﬁcantly improves AR models’ performance, while
other areas of focus have been on temporal localization and segmentation of actions in the untrimmed video. Hidden
Markov’s model has been used to capture long-range dependencies in frame-wise action recognition Kuehne, Arslan
and Serre (2014). In contrast, Spatio-temporal convolution and semi-hidden Markov model were used in capturing
multiple actions transitions in untrimmed video Lea, Reiter, Vidal and Hager (2016). Iqbal et al. (2019) utilized the
transfer learning technique with the I3D network on the temporarily untrimmed video to localize all action class
instances in a video stream. Their experimental research using deep vanilla temporal convolutions network on features
extracted from the I3D yielded the state-of-the-art result with a lightweight model and simple convolution network to
extract features from the existing model without multiple layers and gated convolutions Iqbal et al. (2019).

This paper provides a comprehensive review of action recognition focusing on accident detection and autonomous
transportation in smart city transportation system. This review includes the state-of-the-art techniques that researchers
have proposed, taxonomies of AR tasks, AR applications domain, and transfer learning algorithms from complex
architectures. In addition, we provide the potential future research questions in new application domains leveraging
existing model architecture. The main contribution of this paper can be summarized by:

• Providing a comprehensive comparison of diﬀerent action recognition techniques and taxonomies used in smart
city transportation systems and synthesizing the state-of-the-art research ﬁndings within the past ten years on
autonomous transportation.

• Interpret and analyze the currently used datasets, algorithms, and metrics used by relevant research in the traﬃc

control and accident detection domain.

• Explore literature gaps in existing methodology that can be addressed by current technological advancement.

• Identiﬁed potential future research questions that leverage existing methodology with reduced model complexities

and computation resources.

The structure of this paper is organized in the following: Section (2) presents background and existing literature
review on the domain mentioned above. The literature search, methodology, inclusion, and exclusion criteria are
discussed in Section (3). The results of our research and detailed analysis are discussed in Section (4). Finally,
Sections (5 and 6) elaborated on the limitations and conclusion of the study.

2. Action Recognition Applications

Action Recognition is a revolutionary topic in machine learning and computer vision that has been utilized in
intelligent systems such as Human Assisted AI (e.g., surgery Sharghi, Haugerud, Oh and Mohareri (2020); Ahmidi,
Tao, Sefati, Gao, Lea, Haro, Zappella, Khudanpur, Vidal and Hager (2017), sports Zhou and Zhang (2020); Davar,
de Campos, Windridge, Kittler and Christmas (2011), education Ren and Xu (2002)), smart cities al Zamil, Samarah,
Rawashdeh, Karime and Hossain (2019), safety and security Dhulekar, Gandhe, Chitte and Pardeshi (2017); Kamthe
and Patil (2018), crisis informatics Yan, Yan, Zhao, Wang and Liang (2019), medical imaging Khan, Van De Weĳer,
Anwer, Felsberg and Gatta (2014), and robotics Krüger, Kragic, Ude and Geib (2007); Rodríguez-Moreno, Martínez-
Otzeta, Goienetxea, Rodriguez-Rodriguez and Sierra (2020). Considering the wide application area of AR, in this
research, we limit our scope to the application of Action Recognition addressing the accident detection in smart city
autonomous transportation.

Adewopo et al.: Preprint submitted to Elsevier

Page 2 of 16

Review on Action Recognition for Accident Detection in Smart City

2.1. Action Recognition in Smart City

A futuristic direction in computer vision tasks is the application of the intelligent system in autonomously per-

forming human activities that are somewhat repetitive in nature and capital intensive.

In a smart city surveillance system, violence can easily be spotted to alert appropriate enforcement agencies
with automated analysis of video contents in surveillance camera Fortun, Bouthemy and Kervrann (2015). The
community-based monitoring paradigm focuses on tracking users, monitoring emergencies, and responding to them.
The SenSquare system was implemented using crowd-sensing heterogeneous data sources for gathering data and
developing classiﬁcation algorithms in order to detect potential hazardous behavior in the environment Elsayed,
Zaghloul, Azumah and Li (2021); Montori, Bedogni and Bononi (2018); Azumah, Elsayed, Adewopo, Zaghloul and
Li (2021). Law enforcement agencies continuously face an uphill battle in controlling the increase in crime rates, and
gun violence, the deployment of intelligent surveillance cameras can assist in the automatic detection of ﬁrearms and
alert security agencies in real-time when a ﬁrearm has been detected. Romero and Salamea (2019) developed an object
detection model that can detect ﬁrearms and crime scenes in dangerous situations based on Yolo’s object detection
framework using surveillance cameras.

Human behavior and speciﬁc human actions can be analyzed and classiﬁed using imaging and AI technologies. The
application of AR models in understanding human behavior oﬀers possibilities for smart city safety, especially in the
aspect of tracking drivers’ behavior. The National Highway Traﬃc Safety Administration (NHTSA) report highlighted
an increase in the number of fatalities caused by distracted drivers between 2019 and 2020, which is higher than the
number of fatalities caused by total accidents in 2017. The number of fatalities caused by distracted drivers rose to more
than 8.5% of total fatalities during 2017 Stewart (2022). Celaya-Padilla, Galván-Tejada, Lozano-Aguilar, Zanella-
Calzada, Luna-García, Galván-Tejada, Gamboa-Rosales, Velez Rodriguez and Gamboa-Rosales (2019) proposed a
deep convolution neural network for detecting texting and driving behavior using a car-mounted wide-angle with a
pre-trained Inception v3 model. Emerging technologies such as the AR model can be integrated with CCTV cameras
to reduce ﬁre accidents in smart cities. As described in Avazov, Mukhiddinov, Makhmudov and Cho (2021) on ﬁre
detection method in smart city environments using the Yolo4 algorithm, a robust model based on augmented data
(diﬀerent weather environments) as well as a reduced network structure demonstrated excellent performance and is
highly eﬀective for detecting ﬁre disasters. In this paper, we focus on accident detection from data obtained from
diﬀerent types of surveillance cameras used to monitor a smart city’s transportation system.

2.2. Action Recognition in Autonomous Transportation and Accident Detection

Robotics and auto navigation has also beneﬁted from the use of AR system for automatic guidance, speciﬁcally
in obstacle detection, accident prevention, and lane departure assistance Fortun et al. (2015). Accident detection in
autonomous transportation systems is essential for tracking vehicles and identifying anomalies in traﬃc patterns. Cai,
Wang, Chen and Jiang (2015) discussed the detection of abnormal traﬃc ﬂow using clustering techniques on main ﬂow
direction vectors and a k-means clustering algorithm to identify outliers that deviates from normal trajectory pattern
or motion ﬂow in highways. Previous research has explored intelligent visual descriptions of scenes with connected
image points using spatio-temporal dynamics in the Hidden Markov Model Morris and Trivedi (2011). More recent
research work approached this challenge using machine learning algorithms and deep learning algorithms Huang,
He, Rangarajan and Ranka (2019); Saunier and Sayed (2007); Robles-Serrano, Sanchez-Torres and Branch-Bedoya
(2021). Robles-Serrano et al. (2021) combined convolution layers and long short-term memory LSTM architectures in
capturing spatio-temporal features from a sequence of images in video streams that have been proven to achieve better
performance Lim, Jang and Lee (2016); Elsayed, Maida and Bayoumi (2019) due to the capability of the convolutional
layers to extract the features from each image in the video stream Kattenborn, Leitloﬀ, Schiefer and Hinz (2021) and
the capability of the LSTM to learn the temporal information between images in the video sequence Greﬀ, Srivastava,
Koutník, Steunebrink and Schmidhuber (2016); Elsayed, Maida and Bayoumi (2020).

Accident detection task includes the detection of the spatiotemporal dependencies in multiple frames from video
surveillance. Hence correctly classifying video input as an accident is a more challenging task in developing an
accident detection model. Carreira and Zisserman (2017) introduce a new two-stream inﬂated 3D ConvNet (I3D)
based on a 2D ConvNet inﬂation. The authors seek to unravel the correlation of training on a more extensive network
with performance boost by inﬂating the pooling kernel of pre-trained image classiﬁcation architectures to an inﬂated
two-stream inﬂated 3D ConvNets (I3D). The results of their proposed framework suggest that there is always a boost
in performance by pre-training on a model. However, the extent of the boost varies signiﬁcantly with the type of
architecture.

Adewopo et al.: Preprint submitted to Elsevier

Page 3 of 16

Review on Action Recognition for Accident Detection in Smart City

2.3. Accident Detection Methods

In action recognition tasks, it has been found that many researchers propose their own datasets and evaluation
criteria, making it challenging to identify the most appropriate datasets and results. Performance metrics also vary
across multiple research works; developing a standardized evaluation technique will lead to more robust research in
the application of Action Recognition tasks. Current methods allow some data samples to be repeated/duplicated
in train/test data which directly causes bias in actual performance when evaluating a new research work Jordao,
Nazare, Sena and Robson Schwartz. Stisen, Blunck, Bhattacharya, Prentow, Kjærgaard, Dey, Sonne and Jensen (2015)
examined the eﬀects of heterogeneous devices on the ﬁnal performance of the classiﬁer on diﬀerent activities using
handcrafted features and employed popular classiﬁers such as nearest-neighbor, support vector machines, and random
forest. They noticed sampling instabilities occurred across various devices.

The dataset video source also plays a signiﬁcant role in designing accident detection models. Videos that are
captured by a dashcam hold diﬀerent data trajectories and street vision than the highway or traﬃc lights surveillance
cameras. The dashcams capture the traﬃc video from a horizontal view. In such captured videos, both the camera
and the surrounding objects are moving. This increases the problem complexity, especially when determining the
approaching objects towards the dashcam and the objects that are approached by the car that has the dashcam itself.
The traﬃc light and highway cameras record the scene in a vertical view, with the camera in a ﬁxed position, while
moving objects are recorded at a ﬁxed point. Therefore, addressing each type of video content plays a signiﬁcant role
in calculating the trajectories, the acceleration of objects, and the moving directions.

2.3.1. Machine Learning and Statistical Models

Most machine learning algorithms focus on vehicle trajectory, motion, acceleration, and car position in detecting
car accidents. Singh and Mohan (2018) combined two algorithms using object detection and anomaly algorithm
detection to identify accidents. Singh and Mohan (2018) proposed a framework that extracts deep representation using
autoencoders and an unsupervised model (SVM) to detect the possibility of an accident. The vehicle’s trajectories at
the intersection points were used to increase the proposed architecture’s precision and reliability. Joshua and Garber
(1990) proposed mathematical relationships obtained through multiple linear and Poisson regression analyses to
identify factors contributing to signiﬁcant truck accidents on the highway using an accident dataset from Virginia
highway traﬃc in combination with other geometric variables to model the percentage of trucks involved in a road
accident. Arvin, Kamrani and Khattak (2019) leveraged the availability of extensive data from interconnected devices
in making correlations between erratic driving volatility and historical crash datasets from intersections in Michigan.
Statistical variables such as ﬁxed parameter, random parameter, and geographically weighted Poisson regressions,
longitudinal and lateral acceleration were used in identifying road accident crash hotspots.

2.3.2. Deep Machine Learning Models

Most deep learning algorithms focus on vehicle trajectory, motion/acceleration, and car position for detecting
car accidents. Chan, Chen, Xiang and Sun (2016) proposed a Dynamic-Spatial-Attention (DSA) Recurrent Neural
Network (RNN) for anticipating accidents in dashcam videos based on the vehicle trajectory and motion. The developed
algorithm contains an objects detector to dynamically gather subtle cues and the temporal dependencies of all cues
to predict accidents two seconds before they occur with a recall of 80% and low precision of 56.14%. The model
generalizability in detecting accidents in varying weather conditions was not measured based on limited videos with
rain, snow, and day/night, among other weather conditions. Robles-Serrano et al. (2021) explored the Deep Neural
Networks for accident detection using a three-stage approach by ﬁrstly segmenting visual characteristics of objects in
the dataset, building on the Inception V4 model architecture to extract the temporal components of the dataset used
in detecting accidents followed by the temporal video segmentation. A structural similarity index was applied to the
dataset at preprocessing time to accurately select image frames within the data representing an accident or no accident
as part of the temporal video segmentation to eliminate frames that do not contain event occurrence or repetition of
the selected event. During the preprocessing, pixel-to-pixel comparisons were made to select a certain number of
consecutive frames that contained features to train the model based on a speciﬁed threshold. Finally, the framework
was designed to detect accidents automatically using Convolution LSTM (ConvLSTM) layers to capture spatial and
temporal dependencies in input data Shi, Chen, Wang, Yeung, Wong and Woo (2015); Elsayed, Maida and Bayoumi
(2018). This type of neural network has been proven to have a better performance compared to the LSTM and CNN
architectures when dealing with datasets that have both spatial and temporal structures. One of the potential limitations
is a model bias based on vehicle types and other environmental conditions such as vehicle variety and the absence of

Adewopo et al.: Preprint submitted to Elsevier

Page 4 of 16

Review on Action Recognition for Accident Detection in Smart City

pedestrians and cyclists.

2.3.3. Social Network and Geosocial Media Data

The enormous amount of information being constantly shared daily across various social media platforms contains
artifacts that can be analyzed to generate meaningful insights for traﬃc events Rashidi, Abbasi, Maghrebi, Hasan and
Waller (2017). Although the ability to monitor and analyze the exploding information manually seems impossible
based on the high volume and unstructured formats of the information being presented Adewopo, Gonen, Elsayed,
Ozer and Elsayed (2022). Monitoring traﬃc-related information on social media has been proven to be beneﬁcial in
detecting traﬃc events. Xu, Li and Wen (2018) provided a synthesis of research work that explored the usage of
geosocial media data for detecting traﬃc events. Events such as road accidents, road closures, and traﬃc conditions
are typically shared among a network of people through social media platforms. Such events can be tracked down
with the aid of GPS in getting ﬁrst responders to the event location and also often contain information that triggered
such events. Xu, Li, Wen and Huang (2019) utilized Twitter data for mining and ﬁltering noisy data by association
rules among words related to traﬃc events. The proposed framework achieved 81% accuracy in classifying data into
non-traﬃc events, traﬃc accidents, roadwork, and severe weather conditions. Similarly, Salas, Georgakis, Nwagboso,
Ammari and Petalas (2017) developed a framework leveraging social media data to crawl, process, and ﬁlter social
media data for implying traﬃc incidents and real-time detection of traﬃc events with text classiﬁcation algorithm Gu,
Qian and Chen (2016).

3. Literature Search

The literature search process, which has been performed, consists of four steps, including i) selecting eligibility
criteria (Inclusion and Exclusion criteria), ii) formulating research objectives, iii) identifying search strategy, and iv)
data extraction Harris, Quatman, Manring, Siston and Flanigan (2014); Wright, Brand, Dunn and Spindler (2007).
This study employed the systematic review methodology to address the research questions posited through a systematic
and replicable process Gough, Oliver and Thomas (2017). Speciﬁcally, the Preferred Reporting Items for Systematic
Reviews and Meta-Analyses (PRISMA) Statement was used as a model for this review Page, McKenzie, Bossuyt,
Boutron, Hoﬀmann, Mulrow et al. (2021). Based on the established eligibility criteria, the papers selected were
analyzed and synthesized to address the research questions postulated in the following subsection.

3.1. Research Questions and Objectives

Developing an AR model for speciﬁc tasks will enhance the use of AI systems in automating human actions and
autonomously detecting actions in live feeds. Once the inclusion selection process has been carried out, based on
pre-established criteria, the main results of the selected works are codiﬁed and extracted in order to synthesize and
guide this research, the following research questions will be addressed in this study:

• RQ1: What are the main Action Recognition techniques/application in accident detection and autonomous

transportation?

• RQ2: What are the main taxonomies and algorithms used in Action Recognition for accident detection and

autonomous transportation?

• RQ3: What are the main datasets, features, and metrics used in Action Recognition for accident detection task?

3.2. Selecting Eligibility Criteria

This review includes the research articles related to Action Recognition.

It includes topics in (Autonomous
Transportation, Traﬃc Control, and Accident Detection using computer vision published in peer-reviewed journals
and published between 2012 and 2022. Based on the continuous evolving advancement in the technical ﬁeld, the
articles selected were published ten years before this review. Only research articles published in the English language
were used. The inclusion and exclusion criteria were detailed in Subsection 3.3 and Subsection 3.4, respectively. This
systematic review is based primarily on computer vision tasks using the AR model in autonomous transportation and
smart city accident detection for further clariﬁcations.

Adewopo et al.: Preprint submitted to Elsevier

Page 5 of 16

Review on Action Recognition for Accident Detection in Smart City

Table 1
Article Data source

Database
IEEE Xplore
ACM

ID
D1
D2
D3 Web of Science
D4
D5

Springer Link
Science Direct

Link
http://ieeexplore.ieee.org/
http://dl.acm.org/
http://www.webofscience.com/
http://link.springer.com/
http://sciencedirect.com/

Number of Articles
299
181
445
572
533

3.3. Inclusion Criteria

The publications needed to meet the following characteristics in order to be included:

1. Articles should be in Action Recognition and Computer Vision domain.
2. Studies with validation of the proposed techniques.
3. Published within 2012-2022 (10 Years).
4. Full papers that are peer-reviewed.
5. Contains Video/Motion analysis.

Figure 1: Proportion of selected studies

3.4. Exclusion Criteria

The following exclusions were implemented:

1. Does not contain video/motion analysis.
2. Published before 2012.
3. Not peer reviewed or does not provide clear ﬁndings and analysis of results.
4. Written in other languages excluding English.
5. Duplicated studies.
6. Non peer-reviewed paper.

3.5. Information Sources

The papers included in this review were identiﬁed by searching electronic databases published in English. The

databases in Table 1 were used as the primary source of articles for this review.

These databases provide impactful articles from full-text journals and conferences relevant to Action Recognition
tasks in smart city automation, autonomous transportation, and accident detection. The ﬁrst phase includes searching
the databases in Table 1 with advanced search and ﬁltering techniques to limit search results to only relevant studies.
Two teaching assistants did a manual review of the search results in the second phase to ensure their validity of
the search results. The number of articles retrieved from each database and the ﬁnal number of papers selected is
showcased in Figure 1. Only accessible articles are included in the search result. More details of the search term and
strategy for validating and selecting relevant materials are discussed in Subsection 3.6.

Adewopo et al.: Preprint submitted to Elsevier

Page 6 of 16

Review on Action Recognition for Accident Detection in Smart City

3.6. Search Strategy

Combining the following keywords with conjunctions “AND" and disjunctions “OR" resulted in a total of 2,030

papers in an automated search, as shown in Table 1. The most common terms used for our search were:

1. Action Recognition.
2. Transportation.
3. Traﬃc control.
4. Accident Detection.

The results of our search and the corresponding query that has been used are as follows:

• IEEE Xplore: We received 299 papers from IEEE using the search string:[(("All Metadata":Action Recognition
) AND ("All Metadata":Transportation) OR ("All Metadata":Action Recognition ) AND ("All Metadata":Traﬃc)
OR ("All Metadata":Action Recognition ) AND ("All Metadata":Accident Detection))] between 2013-2022

• ACM: We received 181 papers from ACM using the search string: [AllField:("Action Recognition") AND
AllField:("Transportation") OR AllField:("Action Recognition") AND AllField:("Traﬃc") OR AllField:("Action
Recognition") AND AllField:("Accident Detection")]

• Web of Science: We received 445 papers from Web of Science using the search string:[((ALL=(Action Recog-
nition) AND ALL=(Transportation OR Traﬃc OR Accident Detection))) AND (PY==("2022" OR "2021" OR
"2020" OR "2019" OR "2018" OR "2017" OR "2016" OR "2015" OR "2014" OR "2013" ))]

• Springer Link: We received 572 papers from Springer Link using the search string: [("Action Recognition")

AND (("Transportation") OR ("Traﬃc") OR ("Accident Detection"))] between 2013-2022

• Science Direct: We received 533 papers from Science Direct using the search string: [("Action Recognition"
AND ’Transportation’) OR ("Action Recognition" AND ’Traﬃc’) OR ("Action Recognition" AND ’Accident
Detection’)] between 2013-2022

3.7. Study Selection

Figure 2: Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) ﬂow chart of the systematic review.

The articles were evaluated and selected according to the mentioned criteria in Section (3). After the preliminary
database search using the approved search strategy conducted by the student researchers and eliminating duplicates,

Adewopo et al.: Preprint submitted to Elsevier

Page 7 of 16

Review on Action Recognition for Accident Detection in Smart City

a total of 1830 articles were screened by two faculty researchers and one student researcher independently who are
domain experts. The abstracts, titles, and keywords from selected articles were reviewed for relevance based on the
inclusion and exclusion criteria. Articles that did not meet the eligibility criteria or were not relevant to address the
research question were removed. The independent researchers rated each article based on the inclusion criteria and
eligibility criteria. The painstaking protocol observed in the selection process ensures that all articles included are
relevant to this study. A total of 1650 papers were excluded because they do not contain video analysis or employ AR
techniques in detecting accidents. Thirty-three papers were excluded because they lacked validation techniques for the
proposed methodology, 108 papers identiﬁed as review papers were excluded, and 17 papers contained only abstracts.
Finally, only 22 papers were selected for analysis, as shown in Figure 2.

3.8. Coding, Data Extraction and Analysis

For the data extraction phase, the full text of chosen paper was shared among the authors for review and tagging
the key contributions. Microsoft spreadsheet Niglas (2007), Airtable Dirk and Maddox (2018) and Mendeley Zaugg,
West, Tateishi and Randall citation manager were used to coordinate workﬂow and analyze the papers. This research
aims to retrieve action recognition research articles relevant to accident detection and autonomous transportation. In
addition, duplicate studies that cover the same issues are excluded from the study. Figure 1 shows the proportion of
initial articles and ﬁnal articles selected from each of the ﬁve online data sources listed in Table 1.

4. Results

Following PRISMA guidelines, 2030 publications were identiﬁed through the ﬁve databases included, and the
results of the 22 papers selected for review are presented in this section. Figure 3 showcases the publication year for
the selected papers. It is noteworthy that the majority of the selected papers were published between 2019 and 2021.
Taking advantage of the advancement in technology and smart city automation, more research is now being conducted
on which deep learning algorithms are developed to model traﬃc-related activities in a smart city utilizing computers
equipped with high-performance GPU processors.

Figure 3: Number of papers published per year surveyed.

4.1. RQ1: Main Action Recognition Techniques in Smart City Transportation

The ﬁrst research question of our study is to examine the main AR techniques and applications within smart cities
and autonomous transportation, as shown in Table 3.1. Many researchers have proposed other methods to model traﬃc
management and traﬃc prediction, including the use of Vector Auto-Regression, Support Vector Regression, Auto-
Regressive Integrated Moving Average (ARIMA), Kalman Filter, and, most recently, LSTM, and RNN Smola and
Schölkopf (2004); Wang, Ma, Wang, Jin, Wang, Tang, Jia and Yu (2020b). In time series data, such as traﬃc control
data, the approaches have not been able to capture both spatial and temporal information concisely. Recent eﬀorts
have improved the accuracy performance of GNN and GaAN Zhang, Shi, Xie, Ma, King and Yeung (2018); Zhao,
Song, Zhang, Liu, Wang, Lin, Deng and Li (2019). Ijjina, Chand, Gupta and Goutham (2019) proposed a supervised
deep learning framework to detect and identify road-side vehicular accidents by extracting feature points based on

Adewopo et al.: Preprint submitted to Elsevier

Page 8 of 16

Review on Action Recognition for Accident Detection in Smart City

local features such as trajectory intersection and velocity by detecting anomalies in real-time accident conditions such
as daylight variations. Fernández-Llorca, Biparva, Izquierdo-Gonzalo and Tsotsos (2020) study utilized a visual cue
derived from a camera to detect lane change or vehicle maneuvers by utilizing a disjoint two-stream convolutional
network and a spatiotemporal multiplier network. You and Han (2020) discovered that time segmentation methods such
as SS-TCN and MS-TCN were more successful at higher IoU thresholds. Their experiment also suggests that the R-
C3D algorithm has a comparable result when compared to segmentation-based approaches. Although newer methods
like R(2+1)D and SlowFast have improved accuracy, most techniques fail to capture traﬃc anomalies accurately on
DoTA datasets, suggesting the problem of traﬃc anomaly classiﬁcation is challenging. Yao, Wang, Xu, Pu, Wang,
Atkins and Crandall (2022) suggest that distant anomalies and occluded objects are diﬃcult to classify because of
their low visibility. Collisions with moving vehicles present a similar problem since, at times, the vehicle ahead is
substantially obscured by the vehicle it impacts. There may be instances when a vehicle hits obstacles that are not
detected, such as bumpers or traﬃc cones. Most often, anomalous vehicles are responsible for occluding the obstacles.
It is hard to detect horizontal vehicle collisions due to their slow vertical trajectory, making the anomaly subtle and
thus hard to detect. The JSM-based method extracts motion trajectory to evaluate traﬃc scenes but ignores events
that occurred in an unusual manner min Xia, jie Hu and Wang (2018); Yao et al. (2022). Srinivasan, Srikanth, Indrajit
and Narasimhan (2020) developed a scalable algorithm for high-speed object detection (DETR), with a less complex
architecture and a higher level of accuracy compared to other object detection algorithms that are based on correlations
between all objects in the video data. Table 2 addresses the research question on main Action Recognition techniques
and application in autonomous transportation. The notation “-" indicates that the corresponding research paper did
not address our research question.

4.2. RQ2:Algorithms and Taxonomies in Autonomous Transportation

In order to answer our second research question, we have identiﬁed the most critical taxonomies and algorithms
used in the AR systems for autonomous transportation and accident detection, respectively. Table 3 shows the models,
architecture, features used by other researchers, and the evaluation metrics for evaluating the performance of proposed
models. It is noteworthy that most researchers employed diﬀerent metrics to evaluate their algorithm’s performance,
especially research work that develops a new novel algorithm or benchmark. More than 60% of the reviewed
paper evaluated their algorithms using Mean Absolute Percentage Error (MAPE), Mean Absolute Error (MAE),
Mean Average Precision (MAP), Intersection over Union (IOU) Nowozin (2014), and Detection Rate (DR). Yao
et al. (2022) proposed a novel FOL-based method for unsupervised video anomaly detection (VAD). A metric for
computing anomaly scores using the spatial-temporal area under the curve (STAUC) was introduced. Reddy et al.
(2021) developed a Spatio-Temporal Graph Neural Network for managing and predicting traﬃc ﬂow, while RNN,
LSTM, and other architectures were unable to fully capture it. Their study combined GNN, RNN, and a transformer
layer to model complex topological and temporal relationships among traﬃc data, including adjacent traﬃc ﬂows. Yu
et al. proposed a new graph-based Spatio-temporal model to predict future traﬃc accidents. The integration of
spatial, temporal, and external features in predicting accidents achieved a performance improvement of around 5%
over the SAE. Ali et al. (2022) developed a Graph Convolutional Network coupled with DHST-Net, called GCN-
DHSTNet, which is an enhanced GCN model for learning the spatial dependence of dynamic traﬃc ﬂow by applying
LSTM to capture dynamic temporal correlations with other external features.
In terms of RMSE and MAPE, the
proposed model is 27.2% and 11.2% better than AAtt-DHSTNet, which is the current state of the art. Wang et al.
(2020b) study focused on accident prediction that takes into account Spatio-temporal dependence and other external
factors in anticipating accident occurrence. Research work done in Reddy et al. (2021) proposed a hybrid method
for detecting and recognizing stationary and moving vehicles, traﬃc lights, and road signs using Deep Q-Learning
and YOLOv3. Bortnikov et al. (2020) study developed an HRNN for detecting accidents from CCTV surveillance
by exploiting temporal and spatial features in the classiﬁcation of the video footage. Yang et al. (2021) proposed a
feature-fused SSD and a new tracking-based object detection technique TDO with greatly improved detection results
over state-of-the-art and also established a vehicle dataset for highway scene analysis. Huang et al. (2019) developed a
supervised learning algorithm to detect crash patterns from historical traﬃc data. They examined diﬀerent prediction
methods to estimate crash risk or occurrence. You and Han (2020) also created a benchmark of traﬃc accident data
based on cause and eﬀect events with temporal intervals in each accident event. The dataset provides atomic cues
for reasoning in a complex environment and planning future actions, including mitigating legal ambiguity among
agents. The framework developed by Tang, Huang, Sun, Dong, Zhang, Gao and Liu (2017) can classify traﬃc data
into diﬀerent categories, such as detecting a vehicle turning directions, bicycle lanes, and pedestrians within the two

Adewopo et al.: Preprint submitted to Elsevier

Page 9 of 16

Review on Action Recognition for Accident Detection in Smart City

Table 2
Studies were used to address the research question on main Action Recognition techniques and
application in autonomous transportation. The notation “-“ means the research paper did not
address our research question.

Article

Actions Considered

Learning Method

Category

RQ1

RQ2

RQ3

Key Notes

Yao et al. (2022)

Yu, Du, Hu, Sun, Han and Lv

Wang et al. (2020b)

Vehicle Collision

Car Trajectory

Vehicle Collision

Road Condition

Traﬃc Speed

Traﬃc Flow

Traﬃc Speed

Unsupervised Learning

Traﬃc Anomaly Detection ✓

✓

✓

The researchers developed a benchmark dataset to assess the quality of traﬃc accident detection and anomaly detection for nine action classes

Deep Learning

Accident Prediction

✓

✓

✓

Traﬃc accidents can be caused by many factors, including driver behavior, weather conditions, traﬃc ﬂow, and road structures.

The authors investigated spatial-temporal relationships on heterogeneous data to develop a road-level accident prediction system.

Graph Neural Network

Traﬃc Flow Pattern

-

✓

✓

with a 14.1% improvement in MAPE compared to other baselines.

The goal of this project is to develop a framework for analyzing stationary time series traﬃc data. In addition, it is able to predict traﬃc information

Bao, Yu and Kong (2020)

Traﬃc Anomaly Detection ✓

✓

✓

Car Trajectory

Graph Convolution Network

Using GCN and BNN, the developed model can handle the challenges of relational feature learning and uncertainty anticipation from video data

Inconsistent Motion

Bayesian Neural Network

to anticipate an accident in 3.53 seconds with an average precision of 72.22%.

Reddy, Chella, Ravi Teja, Rose Baby and Kodali (2021)

Car distance limit

Deep Learning

Accident Detection

✓

✓

-

Traﬃc Signals,

The research investigates how to extract road features relevant to the trajectory of an autonomous vehicle from real-world road conditions using

Deep Q-Learning in a real-world environment setting.

Fernández-Llorca et al. (2020)

Traﬃc Speed

Driver Intention Detection

Lane Maneuver

Deep Learning

Traﬃc Anomaly Detection ✓

✓

✓

network and a spatiotemporal multiplier network.

This study utilized a visual cue derived from a camera to detect lane change / vehicle maneuvers by utilizing a disjoint two-stream convolutional

The authors propose a hybrid model combining GCN and DHSTNet that is eﬀective in forecasting short-term traﬃc patterns in urban areas in

Ali, Zhu and Zakarya (2022)

Traﬃc Flow

Graph Convolution Network

Traﬃc Flow Pattern

✓

✓

Wang, Chen and Gong (2020a)

Alkandari and Aljandal (2015)

Riaz, Chenqiang, Azeem, Saifullah, Bux and Ullah (2022)

Wang et al. (2020b)

Huang, Wang and Sharma (2020)

Car Detection

Accident Detection

Traﬃc Flow

Traﬃc Pattern

Traﬃc Speed

Car Distance

Accident Detection

Car Trajectory

Car Position

Traﬃc volume

Traﬃc Speed

Car Collision

Graph Convolution Network

Accident Detection

✓

✓

Fuzzy Logic Technique

Accident Detection

-

✓

Deep Learning

Traﬃc Anomaly Detection ✓

✓

Probabilistic

Traﬃc Flow Pattern

Deep Learning

Accident Detection

Bortnikov, Khan, Khattak and Ahmad (2020)

Deep Learning

Accident Detection

Gupta, Singh, Singh Patel and Ojha (2021)

Accident Detection

Car Collision

Accident Detection

Deep Learning

Accident Detection

Yang, Song, Sun, Zhang, Chen, Rakal and Fang (2021)

Accident Detection

Deep Learning

Accident Detection

Traﬃc Speed

-

-

-

-

✓

-

✓

✓

✓

order to improve traﬃc management.

The researchers developed a new dataset and proposed a method for safety prediction.

The main aim of this study is to develop a methodology for controlling the length of time that a vehicle stays in traﬃc based on the ﬂow

of traﬃc and congestion.

This study implemented the FWPredNet framework for accident and anomaly prediction, which outperformed the previous state-of-the-art framework.

Researchers developed a framework for conceptually describing components of surveillance video, separating them into smaller components, and

detecting activities from some short clips of two seconds.

The authors present a comparative analysis of diﬀerent statistical and deep learning models for solving traﬃc safety problems through the detection

of collisions and estimating crash risk in urban Interstate highways.

Through the use of video games under diﬀerent weather conditions and scene conditions, the study generated traﬃc data that was then processed

and trained with a 3D CNN. This model yielded comparable results to real-life traﬃc videos from YouTube.

Using time-dependent frames in a video, the developed model was able to evaluate the eﬀectiveness of the model on trimmed unlabelled video.

In this paper, researchers propose developing a feature-fused SSD in order to improve detection accuracy of vehicles from the ImageNet video database.

✓

✓

✓

✓

✓

-

-

-

✓

✓

Ijjina et al. (2019)

Traﬃc Trajectory

Deep Learning

✓

✓

✓

Traﬃc Anomaly Detection

The proposed supervised deep learning framework detects and identiﬁes road-side vehicular accidents by extracting feature points based on local

Accident Detection

features such as trajectory intersection and velocity, and by detecting anomalies in real-time accident conditions such as daylight variations.

You and Han (2020)

Car Distance

Car Trajectory

Vehicle Detection

Deep Learning

Accident Detection

✓

✓

✓

In this study, the authors discovered that time segmentation methods such as SS-TCN and MS-TCN were more successful on the dataset at higher

IoU thresholds. In addition, the R-C3D algorithm has a comparable result when compared to segmentation-based approaches.

Srinivasan et al. (2020)

Vehicle Detection

Deep Learning

✓

✓

✓

Accident Detection

The authors developed a scalable algorithm for high-speed object detection (DETR), with a less complex architecture and a higher level of accuracy

Accident Classiﬁcation

compared to other object detection algorithms that are based on correlations between all objects in the video data.

Hui, Xie, Lu and Fu (2015)

min Xia et al. (2018)

Vatti, Vatti, Vatti and Garde (2018)

Vehicle Trajectory

Traﬃc Speed

Traﬃc Pattern

Traﬃc Trajectory

Car Collision

Lane Maneuver

Deep Learning

Accident Detection

✓

-

-

The authors proposed using a Gaussian Mixture Model to extract foreground and background information from video streams in order to create a vision-based accident detection model.

Probabilistic

Traﬃc Flow pattern

✓

✓

✓

The authors applied the SIFT ﬂow method to improve dense trajectories and generate visual words that can be utilized in detecting traﬃc ﬂow.

The data from the experiments demonstrate that the SIFT method is eﬀective.

Statistical Model

Traﬃc Flow Pattern

-

✓

-

The authors developed an electronic notiﬁcation system that can alert relatives when a vehicle accident is detected based on the vehicle’s trajectory, position, and acceleration.

seconds of traﬃc footage.
occurrence. Wang et al. (2020b) take into account Spatio-temporal dependence in their proposed methodology.

In order to correctly predict accidents and classify external factors leading to accident

4.3. RQ3: Main Dataset, Features and Metrics Used in Action Recognition for Accident Detection

Task

Our third research question focused on exploring the dataset used for accident detection. Table 4 showcase the
dataset features, type of sensors/video data, and the link to publicly available datasets for accident detection in a
smart city. Yao et al. (2022) developed a benchmark dataset to assess the quality of traﬃc accident detection and
anomaly detection for nine action classes. Based on the scarcity of annotated real-life accident datasets, Bortnikov
et al. (2020) utilized simulated game video data with varied weather and scene conditions and yielded comparable
results to real-life traﬃc videos on YouTube, as shown in Table 4. The majority of the dataset used in accident
detection and autonomous vehicles are collected from dashcams, traﬃc surveillance cameras, drones such as HighD,
InD, or Interaction datasets Krajewski, Bock, Kloeker and Eckstein (2018); Zhan, Sun, Wang, Shi, Clausse, Naumann,
Kummerle, Konigshof, Stiller, de La Fortelle et al. (2019) and cameras installed on buildings. For example, NGSIM
HW101 and NGSIM I-80 datasets Colyar and Halkias (2007); Halkias and Colyar (2006) contain 45 minutes of images
recorded from a building for eight synchronized cameras at 10 Hz. Fernández-Llorca et al. (2020) suggest that this

Adewopo et al.: Preprint submitted to Elsevier

Page 10 of 16

Review on Action Recognition for Accident Detection in Smart City

Table 3
Identifying the main taxonomies and algorithms used in AR for autonomous transportation based
on relevant studies to our second research question. The notation “-“ means the metric is not
applicable.

Authors

Model

Architecture

Model Features

ACC/AUC/DR/IOU

RMSE/MAP/MAPE

Precision

F1score

Recall Model Comparison

ACC/AUC/DR/IOU MAPE/MAE

Citation

73

-

-

-

-

ConvLSTMAE

ConvAE

Yao et al. (2022)

Future Object Localization

Two Stream RNN

Ego Motion RNN

Object Localization

Object Detection

Yu et al.

Deep Spatio-Temporal Graph Convolutional Network( DSTGCN) Graph Convolution Network

Weather, Road Network

Wang et al. (2020b)

Spatial Temporal Graph Neural Network

Spatial-GNN + GRU + Transformer

Traﬃc Speed

Spatiotemporal Dependencies

Bao et al. (2020)

Spatio Temporal GCN (Graph Convolution Network)

Graph Convolution +RNN

Accident Relevant Cues

Reddy et al. (2021)

Deep Q-Learning

Fernández-Llorca et al. (2020)

Two-Stream Network

Deep Q-Learning

YOLOv3

Two- Stream Convolutio\textbf{-}l Networks

Spatiotemporal Multiplier Networks

Ali et al. (2022)

Dynamic deep spatio-temporal neural network (DHSTNet)

Graph Convolution Network + LSTM

Wang et al. (2020a)

Spatial-Temporal Mixed Attention

Graph-based Convolution model (STMAG)

GRU+Mixed Attention Mechanism

Huang et al. (2020)

CNN-Traﬃc Incident Management (TIM)

Bortnikov et al. (2020)

3D Convolutional Neural Network (CNN)

Gupta et al. (2021)

Time-Distributed RNN

CNN

CNN

LSTM

Car Speed

Distance and Position

Lane Change

Weather Condition

Traﬃc Flow

Object Detection

Lane Marking

Car Speed

Road Occupancy

Optical Flow

Vehicle Trajectory

Temporal Features

Hierarchical Features

Yang et al. (2021)

Feature-Fused SSD Detector

Single Shot MultiBox Detector (SSD)

Detection box

-

-

-

90

90.3

-

-

80

-

94

-

Ijjina et al. (2019)

Mask R-CNN

Deep CNN

Car Speed

Vehicle Trajectory

DR- 71

You and Han (2020)

Single-Stream Temporal Action Proposals (SST)

Temporal Segment Networks (TSN)

-

IOU - 42.07

Srinivasan et al. (2020)

Detection Transformers and Random Forest Classiﬁer (DETR)

DETR + CNN

Object Detection

Hui et al. (2015)

Gaussian Mixture Model (GMM)

-

Vehicle Detection

Object Tracking

78.7

-

min Xia et al. (2018)

Sparse Topic Model

Scale-invariant Feature Transform

(SIFT) ﬂow

Motion Pattern

AUC - 91.2

Vatti et al. (2018)

Accident Detection and Communication System

-

Motion Pattern

-

0.34

82

85

89

3.99

53.7

-

-

11.08

3.23

-

-

-

70.5

-

-

-

-

-

-

-

-

87

-

-

-

-

-

95

-

-

-

-

-

-

-

-

-

78

71

84

-

-

-

-

-

-

-

-

-

-

-

75

-

-

-

77

77

78

-

-

-

-

-

-

-

-

-

AnoPred

SVM

SdAE

TARPML

FC-LSTM

STGNN

adaLEA

DSA

Yolo 3

64.3

67.5

64.8

0.79

0.81

0.83

-

-

-

85

Disjoint Two-Stream Convolution

89.6

DHSTNet

Aatt-DHSTNet

XGBOOST

SVR

LSTM

RF

-

-

SSD

TPN

-

-

76

-

-

-

Deep Spatio Temporal Network

DR-77

R-C3D

MS-TCN

ARRS

CVABTS

-

GPR

JSM

BiLSTM

-

-

DR- 50

DR- 71

-

85.5

80.2

88.1

-

-

-

3.44

2.62

52.3

48.1

-

-

12.80

13.72

3.71

3.99

3.43

-

-

-

-

-

-

-

-

-

-

16

25

82

15

-

7

4

7

31

13

1

2

24

10

1

39

5

16

dataset (NGSIM HW101) is not fully applicable for onboard detection applications even though it is beneﬁcial for
understanding and assessing the motion and behavior of vehicles and drivers under diﬀerent traﬃc conditions. PKU
dataset includes more than 5700 environmental trajectories collected using multiple horizontal 2-D lidars covering
360◦, including vehicles’ trajectory data over 64 km and 19 hours of footage Zhao, Wang, Lin, Guillemard, Geronimi
and Aioun (2017). The Prevention dataset includes data from three radars, two cameras, and one light detection and
ranging (LiDAR), covering a range of 80 meters around an ego-vehicle, to support the development of intelligent
In a
systems for vehicle detection and tracking Izquierdo, Quintanar, Parra, Fernández-Llorca and Sotelo (2019).
similar fashion, the apolloscape dataset was developed to support automatic driving and navigation in smart cities. The
dataset contains about 100K image frames and 1000km trajectories collected using four cameras and two laser scanners
utilizing 3D perception LiDAR object detection, and tracking Wang, Huang, Cheng, Zhou, Geng and Yang (2019).
Ijjina et al. (2019) compiled surveillance videos at 30 frames per second (FPS) trimmed down to 20 seconds video
chunks collected from CCTV videos recorded at road intersections from diﬀerent parts of the world with diversiﬁed
ambient conditions such as harsh sunlight, daylight hours, snow and night hours.

5. Limitation

Our research focused on research papers relevant to action recognition, accident detection, and autonomous
transportation published within the last ten years that developed a novel framework or benchmark dataset. According
to our inclusion and exclusion criteria, we excluded research papers in languages other than English and those that did
not include video/motion analysis. Consequently, only a fraction of the articles surveyed in the study were considered.
The vast majority of AR techniques developed in another domain can also easily be applied in a new domain (such
as Accident Detection).
In light of this, it is recommended to conduct a research project that combines Action
Recognition Techniques for objects and human action classiﬁcation since both have been developed using similar
model architectures.

Adewopo et al.: Preprint submitted to Elsevier

Page 11 of 16

Review on Action Recognition for Accident Detection in Smart City

Table 4
Overview of datasets used in AR for autonomous transportation, features of the datasets and
download links to the datasets.

Authors

Model

Dataset

Fps

Dataset Feature

Accesibility

Data Collection Approach

Yao et al. (2022)

Future Object localization

DoTA (Detection of Traﬃc Anomaly)

10

4,677 videos

Yu et al.

Deep Spatio-Temporal Graph Convolutional Network ( DSTGCN)

Traﬃc Accident Data, Taxi GPS Data

Wang et al. (2020b)

Spatial Temporal Graph Neural Network

Bao et al. (2020)

Spatio Temporal GCN (Graph Convolution Network)

Reddy et al. (2021)

Deep Q-Learning

Fernández-Llorca et al. (2020)

Two-Stream Network

Ali et al. (2022)

Dynamic deep spatio-temporal neural network (DHSTNet)

Meteorological data

PEMS-BAY

META-LA

CCD (Car Crash Dataset)

DAD and A3D

Traﬃc Driving data

PREVENTION dataset

TaxiBj

Bike NYC

Wang et al. (2020a)

Spatial-Temporal Mixed Attention Graph-based Convolution model (STMAG)

Curated Traﬃc Data

Alkandari and Aljandal (2015)

Dynamic Webster with dynamic Cycle Time algorithm (DWDC)

Riaz et al. (2022)

FWPredNet

-

KITTI

HTA

D2City

-

-

-

-

-

-

-

-

Varied weather (Cloudy, Snow, etc.)

Road network and PoI (Point of interest)

53116 videos from 325 sensors

34272 videos from 207 sensors

6.35 hours

Yes-link

NA

Yes-link

Dashcam

Sensors

Traﬃc Surveillance

Sensors

Traﬃc Surveillance

Varied weather conditions (snow, day and night)

Yes-link

Dashcam

2.43 hours and 3.56 hours

182 drive sequences

6 hours video (80 meters around ego-vehicle)

3 radars 2 cameras and 1 LiDAR

NA

Yes-link

Dashcam

LiDAR Rada

DashCam

16 months video recordings

NA

Sensors

2000 videos

-

600 frames from Kitti

65

286 clips

65 frames and 678 video

No-Future Release

Dashcam

NA

Sensors

Yes-link

Dashcam

Wang et al. (2020b)

Mixure LDA and Expectation–maximization algorithm

40- seconds traﬃc video

15

600*800 frame dimension

NA

Traﬃc Surveillance

Huang et al. (2020)

CNN-Traﬃc Incident Management (TIM)

Bortnikov et al. (2020)

3D Convolutional Neural Network (CNN)

Traﬃc Management Centers report

IOWA DOT radar sensors

Video game GTA V

YouTube Car Accident Video

Gupta et al. (2021)

Time-distributed RNN

DETRAC dataset

Yang et al. (2021)

Feature-fused SSD Detector

Ijjina et al. (2019)

Mask R-CNN

Highway vehicle dataset

ImageNet VID dataset

YouTube Accident Videos

You and Han (2020)

Single-Stream Temporal Action Proposals (SST)

Causality in Traﬃc Accident (CTA)

Srinivasan et al. (2020)

Detection Transformers and Random Forest Classiﬁer (DETR)

Hui et al. (2015)

Gaussian Mixture Model (GMM)

min Xia et al. (2018)

Sparse Topic Model

Vatti et al. (2018)

Accident Detection and Communication System

CADP

-

QMUL Junction dataset

AVSS dataset

-

-

-

25

-

30

-

-

-

25

856 crash reports

29 sensors

5 hours recording

10 hours recording of 376 videos

99 frames selected from each video

32938 vehicle samples

5354 videos

20 seconds video chunks

Varied weather (harsh sunlight, daylight hours)

9.53 hours video from 1935 videos.

18 semantic cause and 7 semantic eﬀect labels

1416 Accident footage

-

52 mins traﬃc video

4 seconds chunks

Yes- link

Sensors

NA

Traﬃc Surveillance

Dashcam

Yes-link

Traﬃc Surveillance

Yes-link

Traﬃc Surveillance

NA

Traﬃc Surveillance

Yes-link

Dashcam

Yes-link

NA

Yes-link

Traﬃc Surveillance

Sensors

Traﬃc Surveillance

-

-

NA

Sensors

6. Conclusion

This systematic literature review aims to determine state-of-the-art Action Recognition for accident detection and
In order to achieve this, we used the PRISMA guideline for selecting
autonomous transportation in smart cities.
seminary articles related to our topic domain. This guideline was based on the Inclusion and Exclusion criteria
discussed in Section 3. We selected 22 papers from an initial list of 2030 publications, and we categorized and
analyzed the relevant literature based on the three pillars of our research question. This paper discussed the leading
techniques and applications of action recognition in autonomous transportation. The study also explored the main
taxonomies and algorithms used in AR for autonomous transportation. Finally, we presented an overview of datasets
used in AR for autonomous transportation, features of the datasets, and download links to the datasets.

In the quest for a smart city, automating city traﬃc by capturing spatial and temporal information from DNN is a
signiﬁcant step in smart city automation. Bao et al. (2020) developed a model to handle the challenges of relational
feature learning and uncertainty anticipation from traﬃc video to predict accident occurrence within 3.53 seconds with
an average precision of 72.22% using Graph Convolution Network (GCN) and Bayesian Neural Networks (BNN).
Many factors are involved in traﬃc accidents, including driver behavior, weather conditions, traﬃc ﬂow, and road
structure. Yu et al. examined spatial-temporal relationships on heterogeneous data to develop a road-level accident
prediction system. Besides sequential patterns in the temporal dimension, traﬃc ﬂows on the road are strongly aﬀected
by other road networks in the spatial dimension. Studies have been conducted on traﬃc ﬂow prediction; however,
many of them lack the ability to account for spatial and temporal dependencie Wang et al. (2020b). Reddy et al. (2021)
aimed to extract roadway characteristics that are relevant to the trajectory of an autonomous vehicle from real-world
road conditions using Deep Q-Learning. Analyzing and forecasting dynamic traﬃc patterns within smart cities are
necessary for planning and managing transportation. Forecasting traﬃc ﬂow has become more diﬃcult because of
the volatility of vehicle ﬂow in the temporal dimension and the uncertainty related to accident occurrence and traﬃc
movements. Ali et al. (2022) proposed a hybrid model composed of GCN and DHSTNet, which can forecast short-term

Adewopo et al.: Preprint submitted to Elsevier

Page 12 of 16

Review on Action Recognition for Accident Detection in Smart City

traﬃc patterns in urban areas for improved traﬃc management. Similarly, Alkandari and Aljandal (2015) developed a
methodology for determining how long a vehicle stays in traﬃc based on traﬃc ﬂow and congestion.

Automation of accident detection using AI systems based on security cameras will be a step towards the security of
more lives. It will also support the transformation of traﬃc cameras to support smart city automation and provide ﬁrst
responders and law enforcement agencies with information about road accidents. We recommend future research focus
on scaling up accident detection systems that can be integrated into smart city automation for alerting ﬁrst responders
about road accidents and providing a quick response to victims thereby reducing human error and response time by
adopting a spontaneous model for reporting accidents.

Acknowledgment

The authors would thank Annu Prabhakar for her recommendations regarding writing a systematic review. Also,
we would like to thank Sylvia Azumah, Jones Yeboah, and Izunna Okpala for their help reviewing the search results
and selecting papers based on the inclusion and exclusion criteria.

Funding statement

This research did not receive any speciﬁc grant from funding agencies in the public, commercial, or not-for-proﬁt

sectors.

Declaration of Competing Interest

The authors declare that there are no conﬂicts of interest.

References
Adewopo, V., Gonen, B., Elsayed, N., Ozer, M., Elsayed, Z.S., 2022. Deep learning algorithm for threat detection in hackers forum (deep web).

arXiv preprint arXiv:2202.01448 .

Ahmidi, N., Tao, L., Sefati, S., Gao, Y., Lea, C., Haro, B.B., Zappella, L., Khudanpur, S., Vidal, R., Hager, G.D., 2017. A dataset and benchmarks

for segmentation and recognition of gestures in robotic surgery. IEEE Transactions on Biomedical Engineering 64, 2025–2041.

Al-Faris, M., Chiverton, J., Ndzi, D., Ahmed, A.I., 2020. A review on computer vision-based methods for human action recognition. Journal of

imaging 6, 46.

Ali, A., Zhu, Y., Zakarya, M., 2022. Exploiting dynamic spatio-temporal graph convolutional neural networks for citywide traﬃc ﬂows prediction.
Neural Networks 145, 233–247. URL: https://doi.org/10.1016/j.neunet.2021.10.021, doi:10.1016/j.neunet.2021.10.021.
Alkandari, A.A., Aljandal, M., 2015. Theory of dynamic fuzzy logic traﬃc light integrated system with accident detection and action, in: 2015
2nd International Conference on Computing Technology and Information Management, ICCTIM 2015, Institute of Electrical and Electronics
Engineers Inc.. pp. 62–68. doi:10.1109/ICCTIM.2015.7224594.

Arvin, R., Kamrani, M., Khattak, A.J., 2019. How instantaneous driving behavior contributes to crashes at intersections: extracting useful

information from connected vehicle message data. Accident Analysis & Prevention 127, 118–133.

Avazov, K., Mukhiddinov, M., Makhmudov, F., Cho, Y.I., 2021. Fire detection method in smart city environments using a deep-learning-based

approach. Electronics 11, 73.

Azumah, S.W., Elsayed, N., Adewopo, V., Zaghloul, Z.S., Li, C., 2021. A deep lstm based approach for intrusion detection iot devices network in

smart home, in: 2021 IEEE 7th World Forum on Internet of Things (WF-IoT), IEEE. pp. 836–841.

Bao, W., Yu, Q., Kong, Y., 2020. Uncertainty-based Traﬃc Accident Anticipation with Spatio-Temporal Relational Learning,

in: MM
2020 - Proceedings of the 28th ACM International Conference on Multimedia, Association for Computing Machinery, Inc. pp. 2682–
2690. URL: http://arxiv.org/abs/2008.00334http://dx.doi.org/10.1145/3394171.3413827, doi:10.1145/3394171.3413827,
arXiv:2008.00334.

Bo, W., Fuqi, M., Rong, J., Peng, L., Xuzhu, D., 2021. Skeleton-based violation action recognition method for safety supervision in the operation

ﬁeld of distribution network based on graph convolutional network. CSEE Journal of Power and Energy Systems .

Bortnikov, M., Khan, A., Khattak, A.M., Ahmad, M., 2020. Accident Recognition via 3D CNNs for Automated Traﬃc Monitoring in Smart Cities,
in: Advances in Intelligent Systems and Computing, Springer Verlag. pp. 256–264. URL: https://link-springer-com.uc.idm.oclc.
org/chapter/10.1007/978-3-030-17798-0_22, doi:10.1007/978-3-030-17798-0_22.

Cai, Y., Wang, H., Chen, X., Jiang, H., 2015. Trajectory-based anomalous behaviour detection for intelligent traﬃc surveillance. IET Intelligent

Transport Systems 9, 810–816. doi:10.1049/IET-ITS.2014.0238.

Carreira, J., Zisserman, A., 2017. Quo Vadis, action recognition? A new model and the kinetics dataset, in: Proceedings - 30th IEEE Conference on
Computer Vision and Pattern Recognition, CVPR 2017, pp. 4724–4733. URL: https://arxiv.org/abs/1705.07750, doi:10.1109/CVPR.
2017.502, arXiv:1705.07750.

Celaya-Padilla, J.M., Galván-Tejada, C.E., Lozano-Aguilar, J.S.A., Zanella-Calzada, L.A., Luna-García, H., Galván-Tejada, J.I., Gamboa-Rosales,
N.K., Velez Rodriguez, A., Gamboa-Rosales, H., 2019. “texting & driving” detection using deep convolutional neural networks. Applied
Sciences 9, 2962.

Adewopo et al.: Preprint submitted to Elsevier

Page 13 of 16

Review on Action Recognition for Accident Detection in Smart City

Chan, F.H., Chen, Y.T., Xiang, Y., Sun, M., 2016. Anticipating accidents in dashcam videos, in: Asian Conference on Computer Vision, Springer.

pp. 136–153.

Chattopadhyay, A., Sarkar, A., Howlader, P., Balasubramanian, V.N., 2017. Grad-cam: Improved visual explanations for deep convolutional

networks. arXiv: 1710.11063 .

Chéron, G., Laptev, I., Schmid, C., 2015. P-cnn: Pose-based cnn features for action recognition, in: Proceedings of the IEEE international

conference on computer vision, pp. 3218–3226.

Colyar, J., Halkias, J., 2007. Ngsim-us highway 101 dataset. Federal Highway Administration (FHWA), Tech. Rep. FHWA-HRT-07-030, DC, USA

.

Davar, N.F., de Campos, T., Windridge, D., Kittler, J., Christmas, W., 2011. Domain adaptation in the context of sport video action recognition, in:

Domain Adaptation Workshop, in conjunction with NIPS.

Dhulekar, P., Gandhe, S., Chitte, H., Pardeshi, K., 2017. Human action recognition: an overview, in: Proceedings of the international conference

on data engineering and communication technology, Springer. pp. 481–488.

Dirk, K., Maddox, J., 2018. Archives and airtable: Using cloud-based tools for archival survey and workﬂow management .
Elsayed, N., Maida, A.S., Bayoumi, M., 2018. Empirical activation function eﬀects on unsupervised convolutional lstm learning, in: 2018 IEEE

30th International Conference on Tools with Artiﬁcial Intelligence (ICTAI), IEEE. pp. 336–343.

Elsayed, N., Maida, A.S., Bayoumi, M., 2019. Reduced-gate convolutional lstm architecture for next-frame video prediction using predictive coding,

in: 2019 international joint conference on neural networks (ĳcnn), IEEE. pp. 1–9.

Elsayed, N., Maida, A.S., Bayoumi, M., 2020. Reduced-gate convolutional long short-term memory using predictive coding for spatiotemporal

prediction. Computational Intelligence 36, 910–939.

Elsayed, N., Zaghloul, Z.S., Azumah, S.W., Li, C., 2021. Intrusion detection system in smart home network using bidirectional lstm and convolutional

neural networks hybrid model, in: 2021 IEEE International Midwest Symposium on Circuits and Systems (MWSCAS), IEEE. pp. 55–58.

Fernández-Llorca, D., Biparva, M., Izquierdo-Gonzalo, R., Tsotsos, J.K., 2020. Two-Stream Networks for Lane-Change Prediction of Surrounding
Vehicles, in: 2020 IEEE 23rd International Conference on Intelligent Transportation Systems, ITSC 2020, Institute of Electrical and Electronics
Engineers Inc. doi:10.1109/ITSC45102.2020.9294326, arXiv:2008.10869.

Fortun, D., Bouthemy, P., Kervrann, C., 2015. Optical ﬂow modeling and computation: A survey. Computer Vision and Image Understanding 134,

1–21. URL: https://hal.inria.fr/hal-01104081v2, doi:10.1016/j.cviu.2015.02.008.

Gabrielli, M., Leo, P., Renzi, F., Bergamaschi, S., 2019. Action recognition to estimate activities of daily living (adl) of elderly people, in: 2019

IEEE 23rd International Symposium on Consumer Technologies (ISCT), IEEE. pp. 261–264.

Gedamu, K., Ji, Y., Yang, Y., Gao, L., Shen, H.T., 2021. Arbitrary-view human action recognition via novel-view action generation. Pattern

Recognition 118, 108043.

Gough, D., Oliver, S., Thomas, J., 2017. An introduction to systematic reviews. Sage.
Greﬀ, K., Srivastava, R.K., Koutník, J., Steunebrink, B.R., Schmidhuber, J., 2016. Lstm: A search space odyssey. IEEE transactions on neural

networks and learning systems 28, 2222–2232.

Gu, Y., Qian, Z.S., Chen, F., 2016. From twitter to detector: Real-time traﬃc incident detection using social media data. Transportation research

part C: emerging technologies 67, 321–342.

Gupta, G., Singh, R., Singh Patel, A., Ojha, M., 2021. Accident detection using time-distributed model in videos, in: Advances in Intelligent Systems
and Computing. Springer Science and Business Media Deutschland GmbH. volume 1184, pp. 214–223. URL: https://link-springer-com.
uc.idm.oclc.org/chapter/10.1007/978-981-15-5859-7_21, doi:10.1007/978-981-15-5859-7_21.

Halkias, J., Colyar, J., 2006. Ngsim interstate 80 freeway dataset. US Federal Highway Administration, FHWA-HRT-06-137, Washington, DC,

USA .

Harris, J.D., Quatman, C.E., Manring, M., Siston, R.A., Flanigan, D.C., 2014. How to write a systematic review. The American journal of sports

medicine 42, 2761–2768.

Huang, T., Wang, S., Sharma, A., 2020. Highway crash detection and risk estimation using deep learning. Accident Analysis and Prevention 135.

URL: https://doi.org/10.1016/j.aap.2019.105392, doi:10.1016/j.aap.2019.105392.

Huang, X., He, P., Rangarajan, A., Ranka, S., 2019. Intelligent Intersection: Two-Stream Convolutional Networks for Real-time Near Accident
Detection in Traﬃc Video. ACM Transactions on Spatial Algorithms and Systems 6, 23. URL: https://arxiv.org/abs/1901.01138v1,
doi:10.1145/3373647, arXiv:1901.01138.

Hui, Z., Xie, Y., Lu, M., Fu, J., 2015. Vision-based real-time traﬃc accident detection, in: Proceedings of the World Congress on Intelligent Control

and Automation (WCICA), Institute of Electrical and Electronics Engineers Inc.. pp. 1035–1038. doi:10.1109/WCICA.2014.7052859.

Ijjina, E.P., Chand, D., Gupta, S., Goutham, K., 2019. Computer Vision-based Accident Detection in Traﬃc Surveillance, in: 2019 10th International
Conference on Computing, Communication and Networking Technologies, ICCCNT 2019, Institute of Electrical and Electronics Engineers Inc.
doi:10.1109/ICCCNT45670.2019.8944469, arXiv:1911.10037.

Iqbal, A., Richard, A., Gall, J., 2019. Enhancing temporal action localization with transfer learning from action recognition, in: Proceedings - 2019
International Conference on Computer Vision Workshop, ICCVW 2019, Institute of Electrical and Electronics Engineers Inc.. pp. 1533–1540.
doi:10.1109/ICCVW.2019.00191.

Izquierdo, R., Quintanar, A., Parra, I., Fernández-Llorca, D., Sotelo, M., 2019. The prevention dataset: a novel benchmark for prediction of vehicles

intentions, in: 2019 IEEE Intelligent Transportation Systems Conference (ITSC), IEEE. pp. 3114–3121.

Jhuang, H., Gall, J., Zuﬃ, S., Schmid, C., Black, M.J., 2013. Towards understanding action recognition, in: Proceedings of the IEEE international

conference on computer vision, pp. 3192–3199.

Jordao, A., Nazare, A.C., Sena, J., Robson Schwartz, W., . Human Activity Recognition Based on Wearable Sensor Data: A Standardiza-
tion of the State-of-the-Art. Technical Report. URL: http://www.sense.dcc.ufmg.br/activity-recognition-based-wearable-,
arXiv:1806.05226v3.

Joshua, S.C., Garber, N.J., 1990. Estimating truck accident rate and involvements using linear and poisson regression models. Transportation

Adewopo et al.: Preprint submitted to Elsevier

Page 14 of 16

Review on Action Recognition for Accident Detection in Smart City

planning and Technology 15, 41–58.

Kamthe, U., Patil, C., 2018. Suspicious activity recognition in video surveillance system, in: 2018 Fourth international conference on computing

communication control and automation (ICCUBEA), IEEE. pp. 1–6.

Kattenborn, T., Leitloﬀ, J., Schiefer, F., Hinz, S., 2021. Review on convolutional neural networks (cnn) in vegetation remote sensing. ISPRS Journal

of Photogrammetry and Remote Sensing 173, 24–49.

Khan, F.S., Van De Weĳer, J., Anwer, R.M., Felsberg, M., Gatta, C., 2014. Semantic pyramids for gender and action recognition. IEEE transactions

on image processing 23, 3633–3645.

Krajewski, R., Bock, J., Kloeker, L., Eckstein, L., 2018. The highd dataset: A drone dataset of naturalistic vehicle trajectories on german highways
for validation of highly automated driving systems, in: 2018 21st International Conference on Intelligent Transportation Systems (ITSC), IEEE.
pp. 2118–2125.

Krüger, V., Kragic, D., Ude, A., Geib, C., 2007. The meaning of action: A review on action recognition and mapping. Advanced robotics 21,

1473–1501.

Kuehne, H., Arslan, A., Serre, T., 2014. The language of actions: Recovering the syntax and semantics of goal-directed human activities, in:

Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 780–787.

Lea, C., Reiter, A., Vidal, R., Hager, G.D., 2016. Segmental spatiotemporal cnns for ﬁne-grained action segmentation, in: European Conference on

Computer Vision, Springer. pp. 36–52.

Lim, W., Jang, D., Lee, T., 2016. Speech emotion recognition using convolutional and recurrent neural networks, in: 2016 Asia-Paciﬁc signal and

information processing association annual summit and conference (APSIPA), IEEE. pp. 1–4.

Lv, F., Nevatia, R., 2007. Single view human action recognition using key pose matching and viterbi path searching, in: 2007 IEEE Conference on

computer vision and pattern recognition, IEEE. pp. 1–8.

Montori, F., Bedogni, L., Bononi, L., 2018. A collaborative internet of things architecture for smart cities and environmental monitoring. IEEE

Internet of Things Journal 5, 592–605. doi:10.1109/JIOT.2017.2720855.

Morris, B.T., Trivedi, M.M., 2011. Trajectory learning for activity understanding: Unsupervised, multilevel, and long-term adaptive approach.

IEEE transactions on pattern analysis and machine intelligence 33, 2287–2301.

Muhammad, K., Ullah, A., Imran, A.S., Sajjad, M., Kiran, M.S., Sannino, G., de Albuquerque, V.H.C., et al., 2021. Human action recognition

using attention based lstm network with dilated cnn features. Future Generation Computer Systems 125, 820–830.

Niglas, K., 2007. Media review: Microsoft oﬃce excel spreadsheet software. Journal of Mixed Methods Research 1, 297–299.
Nowozin, S., 2014. Optimal decisions from probabilistic models: the intersection-over-union case, in: Proceedings of the IEEE conference on

computer vision and pattern recognition, pp. 548–555.

Page, M., McKenzie, J., Bossuyt, P., Boutron, I., Hoﬀmann, T., Mulrow, C., et al., 2021. The prisma 2020 statement: An updated guideline for

reporting systematic reviews [internet]. vol. 372, the bmj.

Raja, K., Laptev, I., Pérez, P., Oisel, L., 2011. Joint pose estimation and action recognition in image graphs, in: 2011 18th IEEE International

Conference on Image Processing, IEEE. pp. 25–28.

Rashidi, T.H., Abbasi, A., Maghrebi, M., Hasan, S., Waller, T.S., 2017. Exploring the capacity of social media data for modelling travel behaviour:

Opportunities and challenges. Transportation Research Part C: Emerging Technologies 75, 197–211.

Reddy, D.R., Chella, C., Ravi Teja, K.B., Rose Baby, H., Kodali, P., 2021. Autonomous Vehicle Based on Deep Q-Learning and YOLOv3 with Data
Augmentation, in: ICCISc 2021 - 2021 International Conference on Communication, Control and Information Sciences, Proceedings, Institute
of Electrical and Electronics Engineers Inc. doi:10.1109/ICCISc52257.2021.9484954.

Ren, H., Xu, G., 2002. Human action recognition in smart classroom, in: Proceedings of ﬁfth IEEE international conference on automatic face

gesture recognition, IEEE. pp. 417–422.

Riaz, W., Chenqiang, G., Azeem, A., Saifullah, Bux, J.A., Ullah, A., 2022. Traﬃc Anomaly Prediction System Using Predictive Network.
Remote Sensing 14, 447. URL: https://www.mdpi.com/2072-4292/14/3/447/htmhttps://www.mdpi.com/2072-4292/14/3/447,
doi:10.3390/rs14030447.

Robles-Serrano, S., Sanchez-Torres, G., Branch-Bedoya, J., 2021. Automatic detection of traﬃc accidents from video using deep learning techniques.

Computers 10. doi:10.3390/COMPUTERS10110148.

Rodríguez-Moreno, I., Martínez-Otzeta, J.M., Goienetxea, I., Rodriguez-Rodriguez, I., Sierra, B., 2020. Shedding light on people action recognition

in social robotics by means of common spatial patterns. Sensors 20, 2436.

Romero, D., Salamea, C., 2019. Convolutional models for the detection of ﬁrearms in surveillance videos. Applied Sciences 9, 2965.
Salas, A., Georgakis, P., Nwagboso, C., Ammari, A., Petalas, I., 2017. Traﬃc event detection framework using social media. 2017 IEEE International

Conference on Smart Grid and Smart Cities (ICSGSC) , 303–307.

Saunier, N., Sayed, T., 2007. Automated analysis of road safety with video data. Transportation Research Record , 57–64URL: https:

//journals-sagepub-com.uc.idm.oclc.org/doi/10.3141/2019-08, doi:10.3141/2019-08.

Sevilla-Lara, L., Liao, Y., Güney, F., Jampani, V., Geiger, A., Black, M.J., 2018. On the integration of optical ﬂow and action recognition, in:

German conference on pattern recognition, Springer. pp. 281–297.

Sharghi, A., Haugerud, H., Oh, D., Mohareri, O., 2020. Automatic operating room surgical activity recognition for robot-assisted surgery, in:

International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer. pp. 385–395.

Shi, X., Chen, Z., Wang, H., Yeung, D.Y., Wong, W.K., Woo, W.c., 2015. Convolutional lstm network: A machine learning approach for precipitation

nowcasting. Advances in neural information processing systems 28.

Singh, D., Mohan, C.K., 2018. Deep spatio-temporal representation for detection of road accidents using stacked autoencoder. IEEE Transactions

on Intelligent Transportation Systems 20, 879–887.

Smola, A.J., Schölkopf, B., 2004. A tutorial on support vector regression. Statistics and computing 14, 199–222.
Srinivasan, A., Srikanth, A., Indrajit, H., Narasimhan, V., 2020. A Novel Approach for Road Accident Detection using DETR Algorithm, in:
2020 International Conference on Intelligent Data Science Technologies and Applications, IDSTA 2020, Institute of Electrical and Electronics

Adewopo et al.: Preprint submitted to Elsevier

Page 15 of 16

Review on Action Recognition for Accident Detection in Smart City

Engineers Inc.. pp. 75–80. doi:10.1109/IDSTA50958.2020.9263703.

Stewart, T., 2022. Overview of Motor Vehicle Crashes in 2020. Technical Report.
Stisen, A., Blunck, H., Bhattacharya, S., Prentow, T.S., Kjærgaard, M.B., Dey, A., Sonne, T., Jensen, M.M., 2015. Smart devices are diﬀerent:
Assessing and mitigatingmobile sensing heterogeneities for activity recognition, in: Proceedings of the 13th ACM conference on embedded
networked sensor systems, pp. 127–140.

Tang, X., Huang, X.L., Sun, S.Y., Dong, H., Zhang, X., Gao, Y., Liu, N., 2017. Intelligent recognition of traﬃc video based on mixture LDA model,
in: Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST, Springer Verlag.
pp. 356–363. doi:10.1007/978-3-319-52730-7_36.

Vatti, N.R., Vatti, P., Vatti, R., Garde, C., 2018. Smart Road Accident Detection and communication System, in: Proceedings of the 2018
International Conference on Current Trends towards Converging Technologies, ICCTCT 2018, Institute of Electrical and Electronics Engineers
Inc. doi:10.1109/ICCTCT.2018.8551179.

Vrigkas, M., Nikou, C., Kakadiaris, I.A., 2015. A review of human activity recognition methods. Frontiers in Robotics and AI 2. URL:

https://www.frontiersin.org/article/10.3389/frobt.2015.00028, doi:10.3389/frobt.2015.00028.

Wang, J., Chen, Q., Gong, H., 2020a. STMAG: A spatial-temporal mixed attention graph-based convolution model for multi-data ﬂow safety
prediction. Information Sciences 525, 16–36. URL: https://doi.org/10.1016/j.ins.2020.03.040, doi:10.1016/j.ins.2020.03.040.
Wang, P., Huang, X., Cheng, X., Zhou, D., Geng, Q., Yang, R., 2019. The apolloscape open dataset for autonomous driving and its application.

IEEE transactions on pattern analysis and machine intelligence .

Wang, X., Ma, Y., Wang, Y., Jin, W., Wang, X., Tang, J., Jia, C., Yu, J., 2020b. Traﬃc Flow Prediction via Spatial Temporal Graph Neural Network,
in: The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020, Association for Computing Machinery, Inc. pp.
1082–1092. URL: https://doi.org/10.1145/3366423.3380186, doi:10.1145/3366423.3380186.

Wright, R.W., Brand, R.A., Dunn, W., Spindler, K.P., 2007. How to write a systematic review. Clinical Orthopaedics and Related Research

(1976-2007) 455, 23–29.

min Xia, L.,

jie Hu, X., Wang, J., 2018. Anomaly detection in traﬃc surveillance with sparse topic model.

Journal of Central
South University 25, 2245–2257. URL: https://link-springer-com.uc.idm.oclc.org/article/10.1007/s11771-018-3910-9,
doi:10.1007/s11771-018-3910-9.

Xiaohan Nie, B., Xiong, C., Zhu, S.C., 2015. Joint action recognition and pose estimation from video, in: Proceedings of the IEEE Conference on

Computer Vision and Pattern Recognition, pp. 1293–1301.

Xu, S., Li, S., Wen, R., 2018. Sensing and detecting traﬃc events using geosocial media data: A review. Computers, Environment and Urban

Systems 72, 146–160.

Xu, S., Li, S., Wen, R., Huang, W., 2019. Traﬃc event detection using twitter data based on association rules. ISPRS Annals of the Photogrammetry,

Remote Sensing and Spatial Information Sciences 4, 543–547.

Yan, J., Yan, S., Zhao, L., Wang, Z., Liang, Y., 2019. Research on human-machine task collaboration based on action recognition, in: 2019 IEEE

International Conference on Smart Manufacturing, Industrial & Logistics Engineering (SMILE), IEEE. pp. 117–121.

Yang, Y., Song, H., Sun, S., Zhang, W., Chen, Y., Rakal, L., Fang, Y., 2021. A fast and eﬀective video vehicle detection method leveraging
feature fusion and proposal temporal link, in: Journal of Real-Time Image Processing, Springer Science and Business Media Deutschland
GmbH. pp. 1261–1274. URL: https://link-springer-com.uc.idm.oclc.org/article/10.1007/s11554-021-01121-y, doi:10.
1007/s11554-021-01121-y.

Yao, A., Gall, J., Fanelli, G., Van Gool, L., 2011. Does human action recognition beneﬁt from pose estimation?”, in: Proceedings of the 22nd

British machine vision conference-BMVC 2011, BMV press.

Yao, Y., Wang, X., Xu, M., Pu, Z., Wang, Y., Atkins, E., Crandall, D., 2022. DoTA: Unsupervised Detection of Traﬃc Anomaly in Driving Videos.

IEEE Transactions on Pattern Analysis and Machine Intelligence doi:10.1109/TPAMI.2022.3150763.

You, T., Han, B., 2020. Traﬃc Accident Benchmark for Causality Recognition, in: Lecture Notes in Computer Science (including sub-
series Lecture Notes in Artiﬁcial Intelligence and Lecture Notes in Bioinformatics), Springer Science and Business Media Deutsch-
land GmbH. pp. 540–556. URL: https://link-springer-com.uc.idm.oclc.org/chapter/10.1007/978-3-030-58571-6_32,
doi:10.1007/978-3-030-58571-6_32.

Yu, L., Du, B., Hu, X., Sun, L., Han, L., Lv, W., . Deep spatio-temporal graph convolutional network for traﬃc accident prediction URL:

https://doi.org/10.1016/j.neucom.2020.09.043, doi:10.1016/j.neucom.2020.09.043.

al Zamil, M.G., Samarah, S., Rawashdeh, M., Karime, A., Hossain, M.S., 2019. Multimedia-oriented action recognition in smart city-based iot

using multilayer perceptron. Multimedia Tools and Applications 78, 30315–30329.

Zaugg, H., West, R.E., Tateishi, I., Randall, D., . Creating communities of scholarly inquiry through research collaboration. TechTrends55132–

3610.1007/s11528-011-0467-y .

Zhan, W., Sun, L., Wang, D., Shi, H., Clausse, A., Naumann, M., Kummerle, J., Konigshof, H., Stiller, C., de La Fortelle, A., et al., 2019.
Interaction dataset: An international, adversarial and cooperative motion dataset in interactive driving scenarios with semantic maps. arXiv
preprint arXiv:1910.03088 .

Zhang, J., Shi, X., Xie, J., Ma, H., King, I., Yeung, D.Y., 2018. Gaan: Gated attention networks for learning on large and spatiotemporal graphs.

arXiv preprint arXiv:1803.07294 .

Zhao, H., Wang, C., Lin, Y., Guillemard, F., Geronimi, S., Aioun, F., 2017. On-road vehicle trajectory collection and scene-based lane change

analysis: Part i. IEEE Transactions on Intelligent Transportation Systems 18, 192–205. doi:10.1109/TITS.2016.2571726.

Zhao, L., Song, Y., Zhang, C., Liu, Y., Wang, P., Lin, T., Deng, M., Li, H., 2019. T-gcn: A temporal graph convolutional network for traﬃc

prediction. IEEE Transactions on Intelligent Transportation Systems 21, 3848–3858.

Zhou, E., Zhang, H., 2020. Human action recognition toward massive-scale sport sceneries based on deep multi-model feature fusion. Signal

Processing: Image Communication 84, 115802.

Adewopo et al.: Preprint submitted to Elsevier

Page 16 of 16

