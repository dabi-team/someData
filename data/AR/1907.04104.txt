9
1
0
2

l
u
J

9

]

C
H
.
s
c
[

1
v
4
0
1
4
0
.
7
0
9
1
:
v
i
X
r
a

User Guidance for Interactive Camera
Calibration

Pavel Rojtberg1,2

1 Fraunhofer IGD, Darmstadt, Germany
pavel.rojtberg@igd.fraunhofer.de
2 TU Darmstadt, Germany

Abstract. For building a Augmented Reality (AR) pipeline, the most
crucial step is the camera calibration as overall quality heavily depends
on it. In turn camera calibration itself is inﬂuenced most by the choice
of camera-to-pattern poses – yet currently there is only little research
on guiding the user to a speciﬁc pose. We build upon our novel cam-
era calibration framework that is capable to generate calibration poses
in real-time and present a user study evaluating diﬀerent visualization
methods to guide the user to a target pose. Using the presented method
even novel users are capable to perform a precise camera calibration in
about 2 minutes.

Keywords: Augmented Reality and Environments, Interaction in Virtual and
Augmented Reality environments

1 Motivation

Camera calibration in the context of Augmented Reality (AR) is the process of
determining the internal camera geometrical and optical characteristics (intrinsic
parameters) and optionally the position and orientation of the camera frame in
the world coordinate system (extrinsic parameters). The performance of the 3D
vision algorithms which AR builds upon directly depends on the quality of this
calibration. Furthermore, calibration is a recurring task that has to be performed
each time the camera setup is changed. Even if a camera is replaced by an
equivalent from the same series, the intrinsics will vary due to build inaccuracies.
The prevalent approach to camera calibration is based on acquiring multiple
images of a planar pattern of known size [6]. In contrast to 3D calibration objects
that were used earlier, 2D patterns are easy to obtain as conventional printers
can produce them at high precision.

The pattern is then used to establish correspondences between known 3D
world points and measured 2D image points. The point correspondences form a
over-determined system of equations which constrains the camera model.

However, due to the projective nature of the transform multiple images must
be acquired from diﬀerent poses. Here, special pose conﬁgurations [5] that lead
to an unreliable solutions and should be explicitly avoided.

 
 
 
 
 
 
Fig. 1: Exemplary set of 9 target poses and the user guidance overlay, projecting
for the bottom right camera.

Therefore a user interface is desirable which guides users through the cali-
bration process. The guidance allows to select to a minimal set of ”good” frames
that result in a fast and reproducible calibration.

2 Background

The ﬁrst step to camera calibration is to detect the calibration pattern. Typically
chessboard patterns (Fig. 2a) are used, which have strong gradients that can be
detected even under diﬃcult lighting conditions. Additionally, the 2D points can
be located with sub-pixel accuracy.

(a) Chessboard

(b) ChArUco pattern

Fig. 2: Common planar calibration patterns

However, the detection process usually involves the time consuming task
of ordering the detected rectangles to a canonical topology. This slows down

frame acquisition to below 30Hz and impedes the interactivity of the method.
Furthermore the board needs to be fully visible for the corner identiﬁcation to
work.

Therefore new methods interleave ﬁducial markers [2] within the chessboard
pattern (Fig. 2b). The markers encode an unique id and are designed to be
rotationally invariant - hence the detection of a single marker allows deducing
the location and orientation of the whole board. However the marker positions
become imprecise at steep view angles. Hence only chessboard corners are used,
which generate measurements at sub-pixel accuracy.

The second step in calibration is to capture a calibration set of multiple
images. This set needs suﬃciently constrain the camera model for the calibration
to succeed. For instance the pattern vies must not be all parallel to the image
plane. As both pattern distance and camera focal length (”zoom level”) are
estimated simultaneously, there is no unique solution in this case. Consequently
popular calibration toolboxes like ROS3 or OpenCV 4 impose some heuristics
on pose variance or screen space coverage to alleviate the problem (see ﬁgure 3).

(a) The ROS toolbox showing the variance
in position and size.

(b) OpenCV showing the current screen cov-
erage

Fig. 3: User interfaces of popular, non-interactive, systems.

As these systems are not capable of generating pose suggestions, their user
interfaces only visualize statistics about the data captured so far. The user is
responsible to reason about an optimal next pose that would improve on the
imposed heuristics. Furthermore the unreliable pose conﬁgurations are not ex-
plicitly addressed — therefore degraded performance is still possible.

In contrast, new calibration systems [3, 4] are capable to guide users to
speciﬁc target poses by displaying an overlay (see ﬁgure 1). This explicitly avoids
unreliable conﬁgurations and reduces intrisic cognitive load [1]. While both [3, 4]

3 http://wiki.ros.org/camera_calibration/Tutorials/MonocularCalibration
4 https://docs.opencv.org/master/d7/d21/tutorial_interactive_calibration.

html

(a) Target pose wireframe and real-board
overpaint as used by [3]

(b) Target pose projection as used by [4]

Fig. 4: User guidance overlays used by interactive calibration systems

performed user surveys, they merely showed operability of their methods by
novice users.

Additionally the user interfaces implemented by each method are very diﬀer-
ent. [4] only display highlighted projection of the real pattern to tag the target
pose, while [3] display an abstractly colored, wireframe of the board at the target
pose and additionally overpaint the real board with squares of matching color
(see Figure 4).

Therefore this work focuses on the question how which user interface is best
suited to guide users to speciﬁc calibration poses. At this we take the speciﬁc
geometric properties of the calibration problem into account, namely:

– Only the relative pose between camera and pattern matters
– The pattern can be arbitrarily ﬂipped horizontally and vertically.

Indeed, these properties make the calibration guidance signiﬁcantly diﬀerent
from typical AR guidance use-cases where a pose needs to be matched exactly.

2.1 Calibration Poses

In general a rigid pose has six degrees of freedom (DOF); yaw, pitch, roll for
the orientation and the three dimensional position. However the underlying al-
gorithm [4] generates more restricted poses, based on the calibration objective.
These fall in the following two categories:

Intrinsic calibration pose To estimate the intrinsic camera parameters, the goal
is to maximize the angular spread of the measurement points. Here the pattern
is placed in the central image region and tilted along one primary axis. Addi-
tionally the board needs to be tilted and rotated along the remaining axes to
avoid ambiguous conﬁgurations (see Figure 5a). Therefore there are only three
rotational DOF.

(a) Intrinsic calibration pose

(b) Distortion calibration pose

Fig. 5: Exemplary view from the two pose categories

Distortion calibration pose To estimate the lens distortion parameters, the pat-
tern must be placed in regions with highest distortion which are typically the cor-
ners. Here a parallel view is used and the distance and relative position changes
(see Figure 5b). Therefore there are only three positional DOF.

Therefore a user only ever has to change 3 DOF when starting from a central,

parallel view on the pattern.

3 Method

To evaluate diﬀerent user guidance options, we performed two user surveys,
measuring the time the users required to match a series of target poses. The
participants were students and co-workers at our lab. Most of them had never
performed a camera calibration before and all users were using the tool for the
ﬁrst time. The pose sequence was given by our system [4].

The only instruction given was that the calibration pattern should be matched

with the displayed overlay.

We triggered the time measurement only after the ﬁrst target pose was
reached. This explicitly discards the time the users needed to accommodate
to the calibration scenario and the system setup.

For each question a separate survey was performed. The surveys were several
months apart time-wise. Hence there is no overlap of participants and the pose
setup varies slightly.

3.1 Relative motion survey

The goal of the ﬁrst survey was to determine whether moving the camera or
moving the calibration pattern is preferable. This takes advantage of the fact

that only the relative orientation and translation between camera and pattern
matters. Therefore we evaluated the following two scenarios:

1. Fixing the camera position at the screen and let the user move the pattern

like in front of a virtual mirror.

2. Fixing the pattern position and let the user move the camera in a ﬁrst-

person-view like fashion.

There were 5 participants in this survey which successively tried both op-
tions. To exclude the eﬀect of familiarization we randomized the the order of the
options. The user guidance consisted only of the target pose overlay as shown in
Figure 5. There were 9 target poses that had to be matched.

3.2 Pattern appearance survey

(a) The default ”chessboard” pattern

(b) The ”quadrille paper” pattern

Fig. 6: The two overlay patterns we evaluated in our second user survey. Note
that we now do overpaint the real board in the video stream.

Complementing the ﬁrst survey, the second survey determined whether one
can take advantage of the geometric property that the pattern can be ﬂipped
horizontally and vertically. To this end we chosen two diﬀerent visualization of
the calibration pattern as follows:

1. The asymmetric chessboard as in used for the preceding survey.
2. A quadrille paper visualization, which is fully symmetric yet still contains

the necessary perspective cues.

To keep the connection between the target pose overlay and the physical cali-
bration board when using the new visualization, we overpaint the actual calibra-
tion target in the video stream - similarly to [3]. We also apply the over-painting

to the ﬁrst option (see ﬁgure 6) to exclude the eﬀect of tracking imprecision from
the survey.

There were 7 Participants in this survey which had to reach 10 target poses.
As with the preceding survey the order of the options was randomized so 3
participants started with option 1 and 3 participants started with option 2.

We only used the ”virtual mirror” setup based on the results from the ﬁrst

survey.

4 Results

In the following the results of our user surveys are shown. First we discuss the
quantitative timings of each experiment. Then we also present some qualitative
observations made during the trials.

4.1 Quantitative results

Table 1 shows the quantitative results of the ﬁrst survey, giving the per-user
times as well as the overall average.

t (ﬁrst-person view) t (virtual mirror)

User 1
User 2
User 3
User 4
User 5
Mean

1:39 min
3:17 min
2:46 min
7:22 min
2:22 min
3:29 min

1:44 min
1:08 min
1:55 min
1:36 min
1:25 min
1:33 min

Table 1: time the users required to reach 9 given target poses.

The average calibration time of 1:33 min to complete the calibration show
a strong advantage of the virtual mirror scenario over the ﬁrst-person view ap-
proach with an average time of 3:29 min. Looking at the individual results we
see that only User 1 is slightly faster using the ﬁrst-person view, while all other
Users were considerably faster using the virtual mirror approach. User 4 even
struggles to complete the calibration using in the ﬁrst-person view. Therefore
we conclude that the virtual mirror approach is preferable.

Table 2 shows the results of the second survey, again giving the average as
well as the per user times. There are only 6 results given as one participant failed
to match the ﬁrst intrinsic pose within 3 min with any method. Therefore we
aborted the trial and no results are given.

The average time of 1:56 min to complete the calibration using the quadrille
paper visualization shows a slight advantage over the chessboard visualization
with 2:24 min. However looking at the individual results there are 2 participants
being faster using the chessboard visualization. Furthermore there is strong vari-
ation between the individual users. Therefore no clear conclusion can be given.

t (chessboard) t (quadrille paper)

User 1
User 2
User 3
User 4
User 5
User 6
Mean

2:14 min
2:07 min
3:06 min
3:43 min
1:21 min
1:52 min
2:24 min

1:00 min
1:20 min
2:11 min
3:20 min
1:44 min
2:00 min
1:56 min

Table 2: time the users required to reach 10 given target poses with diﬀerent
visualizations

4.2 Qualitative results

Additionally to the times presented above we made the following qualitative
observations:

– It took the participants much longer to match the intrinsic pose then the

distortion pose.

– With the ”quadrille paper” pattern, some users did not rotate the pattern
to match the distortion calibration pose, but rather moved it out of view.
– The users reached a target pose faster if it was from the same category as the
previous one; e.g. if a distortion pose followed a distortion pose. Conversely
the needed to re-orient if e.g. a distortion pose followed a intrinsic pose.
– When asked about the experience users preferred the ”quadrille paper” vi-

sualization - even if their calibration time was higher in this mode.

Here the time it took the participants to match the intrinsic pose was the

determining factor in overall calibration time.

5 Conclusion

We have presented an evaluation of diﬀerent user guidance methods for camera
calibration. This allows us to give a recommendation that the ”virtual mirror”
setup is preferable for camera calibration. However the results of our second
survey only hint that using the simpliﬁed ”quadrille paper” overlay is of advan-
tage. While the user feedback was generally positive and we measured a slight
advantage in the average calibration time, there was a strong variation between
the individual participants. Therefore a larger scale survey is necessary to give
a deﬁnitive answer here.

However our qualitative observations indicate that larger gains are to be
expected from adapting the pose sequence then from modifying the pattern
visualization. Particularly the arbitrary switching between the pose categories
requires physical and mental switching on the user side. Additionally we ob-
served that matching 3 arbitrary rotations of the pattern to the target pose took
considerably longer then to match the position.

Therefore the pose sequence should adapted to further improvements on user
guidance. Currently the poses optimize the algorithmic constrains while neglect-
ing the user. One option would be to ﬁnd for a better compromise between these
two objectives. Alternatively one could introduce ”guidance only” poses that are
placed between the current pattern position and the target pose. Those would
not be used for calibration, but rather to give the user more hints on how to
reach the target pose. Trivially one could insert the neutral pose between two
calibration poses s.t. only 3 DOF change between each two displayed targets.

Bibliography

[1] Paul Chandler and John Sweller. Cognitive load theory and the format of

instruction. Cognition and instruction, 8(4):293–332, 1991.

[2] S Garrido-Jurado, Rafael Mu˜noz-Salinas, Francisco Jos´e Madrid-Cuevas, and
Manuel Jes´us Mar´ın-Jim´enez. Automatic generation and detection of highly
reliable ﬁducial markers under occlusion. Pattern Recognition, 47(6):2280–
2292, 2014.

[3] Andrew Richardson, Johannes Strom, and Edwin Olson. AprilCal: Assisted
and repeatable camera calibration. In Proceedings of the IEEE/RSJ Inter-
national Conference on Intelligent Robots and Systems (IROS), November
2013.

[4] P. Rojtberg and A. Kuijper. Eﬃcient pose selection for interactive camera
In 2018 IEEE International Symposium on Mixed and Aug-

calibration.
mented Reality (ISMAR), pages 31–36, Oct 2018.

[5] Peter F Sturm and Stephen J Maybank. On plane-based camera calibra-
tion: A general algorithm, singularities, applications. In Computer Vision
and Pattern Recognition, IEEE Computer Society Conference on., volume 1.
IEEE, 1999.

[6] Zhengyou Zhang. A ﬂexible new technique for camera calibration. Pat-
tern Analysis and Machine Intelligence, IEEE Transactions on, 22(11):1330–
1334, 2000.

