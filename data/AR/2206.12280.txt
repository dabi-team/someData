Bayesian Circular Lattice Filters for
Computationally Eﬃcient Estimation of
Multivariate Time-Varying Autoregressive
Models

Yuelei Sui1, Scott H. Holan23, and Wen-Hsi Yang4 5,

Abstract

Nonstationary time series data exist in various scientiﬁc disciplines, including environ-
mental science, biology, signal processing, econometrics, among others. Many Bayesian
models have been developed to handle nonstationary time series. The time-varying vector
autoregressive (TV-VAR) model is a well-established model for multivariate nonstationary
time series. Nevertheless, in most cases, the large number of parameters presented by the
model results in a high computational burden, ultimately limiting its usage. This paper
proposes a computationally eﬃcient multivariate Bayesian Circular Lattice Filter to extend
the usage of the TV-VAR model to a broader class of high-dimensional problems. Our fully
Bayesian framework allows both the autoregressive (AR) coeﬃcients and innovation covari-
ance to vary over time. Our estimation method is based on the Bayesian lattice ﬁlter (BLF),
which is extremely computationally eﬃcient and stable in univariate cases. To illustrate the
eﬀectiveness of our approach, we conduct a comprehensive comparison with other competing
methods through simulation studies and ﬁnd that, in most cases, our approach performs su-
perior in terms of average squared error between the estimated and true time-varying spectral
density. Finally, we demonstrate our methodology through applications to quarterly Gross
Domestic Product (GDP) data and Northern California wind data.

Keywords: Bayesian hierarchical model, nonstationary time series, partial autocorrelation,
time-varying spectral density, vector autoregressive model

1(to whom correspondence should be addressed) SAS Institute, North Carolina, USA
2Department of Statistics, University of Missouri, Missouri, USA
3Oﬃce of the Associate Director for Research and Methodology, U.S. Census Bureau, Washington, D.C.,

USA

4School of Agriculture and Food Sciences, The University of Queensland, Queensland, Australia
5School of Mathematics and Physics, The University of Queensland, Queensland, Australia

2
2
0
2

n
u
J

4
2

]
E
M

.
t
a
t
s
[

1
v
0
8
2
2
1
.
6
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
1

Introduction

Multivariate time series data are measured and recorded for inquiries of interest in subject-

matter disciplines such as biology, ecology, economics, ﬁnance, and medicine. For example,

multivariate nonstationary time series models work well for modeling correlated economic

indicators by using time-varying parameters to evaluate the eﬀects of policy changes and the

resulting private sector behavioral changes. In addition, these models are also well-suited for

measuring the eﬀect of policy changes on other factors of the economy (Huerta and Lopes,

2000; Primiceri, 2005; Nakajima et al., 2011; Hunter et al., 2017). Another example in which

these models are useful is multi-channel electroencephalography (EEG) data, where the data

are analyzed through their time-frequency representation to reveal how the neuronal activity

in one area of the human brain may inﬂuence another (Ombao et al., 2005; Zhao and Prado,

2020; Zhao, 2022). In the era of big data, the number of series and series length within a

multivariate time series have been increasing due to technological advances. Consequently,

there has also been a fundamental increase in data complexity. Thus, developing eﬃcient

methods that scale to such an enormous amount of time series data is imperative.

Parametric and nonparametric approaches for analyzing multivariate time series have

been developed to reveal features both between multiple time series and within a single time

series. Some parametric methods, e.g., vector autoregressive (VAR) models, are designed

for stationary time series. Time-varying vector autoregressive (TV-VAR) models and many

other parametric models (Ombao et al., 2005; Kowal et al., 2017), deal with multivariate

nonstationary time series. There are also nonparametric methods, e.g., multivariate time-

dependent spectral analysis (Guo and Dai, 2006) and multivariate polynomial regression

(Masry, 1996; Fan and Yao, 2008).

Parametric models for nonstationary multivariate time series play an increasingly impor-

tant role when modern techniques make high-dimensional data available for analysis. They

1

have several advantages: 1) easy to make forecasts, 2) straightforward to build assessment

of uncertainty, and 3) concise descriptions of the underlying model scheme. The TV-VAR

model is arguably the most widely used model among the parametric methods. In the time

domain, such models have been developed and applied to correlated economic and ﬁnancial

data (Primiceri, 2005; Del Negro and Primiceri, 2015; Nakajima et al., 2011; Nakajima and

West, 2013). In contrast, in the frequency domain, the spectral density and the coherence

can often reveal features of each time series that are not readily apparent in the time do-

main. For example, frequency domain approaches to multi-channel EEG data can aid in the

understanding of connective activities within the brain by estimating their spectrum and

coherence (Ombao et al., 2001, 2005; Zhao and Prado, 2020; Zhao, 2022).

Some of the current methods for TV-VAR models assume that the standard deviations

of the innovations evolve as geometric random walks and, therefore, belong to the class

of stochastic volatility models (Shephard, 2005; Primiceri, 2005; Del Negro and Primiceri,

2015; Nakajima et al., 2011). In the Bayesian setting, these methods typically require Markov

chain Monte Carlo (MCMC) methods for estimation and are, therefore, computationally ex-

pensive. Alternatively, other methods assume that the innovation variance follows a random

walk process. Gersch and Stone (1995) proposed an eﬃcient closed-form method to Bayesian

inference. Their method used a two-stage estimation approach and assumed a constant inno-

vation covariance. The multivariate dynamic linear models (MDLMs) proposed by West and

Harrison (1997) allow both the coeﬃcients and the innovation variance to change over time

and have been applied to multivariate economic index data (Primiceri, 2005; Del Negro and

Primiceri, 2015; Nakajima et al., 2011). However, this method is computationally expensive

due to sequential computation of matrix inversions.

Zhao and Prado (2020) extended the Bayesian lattice ﬁlter (BLF) of Yang et al. (2016)

to TV-VAR models with a constant innovation covariance by implementing the multivariate

Durbin–Levison algorithm (Brockwell and Davis, 2009) and using MDLMs on the forward

2

and backward time-varying partial autocorrelation coeﬃcient matrices (TV-VPARCOR).

Additionally, Zhao (2022) introduced a shrinkage prior and variational approach in the TV-

VPARCOR to deal with overﬁtting. The constant innovation covariance was estimated using

an approximation (Triantafyllopoulos, 2007). However, the assumption of constant innova-

tion covariance may not be reasonable for many types of data. Moreover, these approaches

need to calculate inverse matrices sequentially and the computation time still increases ex-

ponentially with the increase of the dimension of the data.

To overcome the drawbacks of the high computation cost and the constant innovation

covariance assumption, we propose an approach that uses a “one channel at-a-time” scheme

(Pagano, 1978) to transform the multivariate time series model into a periodic univariate

process. This “one channel at-a-time” algorithm eﬃciently reduces the computation cost

and makes parallel computing possible for high-dimensional data. Sakai (1982) developed a

circular lattice structure to estimate the AR coeﬃcients iteratively based on Pagano (1978).

This approach allows us to estimate the AR coeﬃcients one series at a time and, therefore,

minimizes the need to calculate big matrices. This strategy makes the computational cost

increase linearly, rather than exponentially, with the model order. Gersch and Stone (1995)

applied this circular lattice to the time-varying multivariate AR model using a smoothness

prior (Kitagawa and Gersch, 1996) on the AR coeﬃcients. This method uses a two-stage

estimation approach for the coeﬃcients and innovation covariance and only allows coeﬃcients

to be time-varying. The assumption of constant innovation covariance limits application for

many types of data. Our new approach uses dynamic linear models (DLMs) to facilitate

the estimation in each stage of the lattice structure, allowing both the coeﬃcients and the

innovation variances to vary with time (see also, Sui (2021)). By modeling the time-varying

innovation covariance, the resulting models are more broadly applicable. Additionally, we

adopt the methods by Levy and Lopes (2021) to address the problem of ordering uncertainty

within the multivariate time series.

3

The remainder of the paper is organized as follows. First, we introduce Bayesian cir-

cular lattice ﬁlters in Section 2 and evaluate the method via extensive simulation studies

in Section 3. In Section 4, we apply the method to two applications, modeling quarterly

GDP for ﬁve countries and modeling wind speed from three stations in Northern California.

Finally, Section 5 contains conclusion and discussion. Comprehensive details and algorithms

for parameter estimation, model selection, and forecasting are provided in the Appendix.

2 Methodology

The Bayesian circular lattice ﬁlters (BCLFs) we propose are computationally eﬃcient for

order identiﬁcation and parameter estimation of TV-VAR models with time-varying inno-

vation covariances. This approach takes advantages of a “one channel at-a-time” scheme

and Bayesian lattice structure to achieve its computational eﬃciency. To introduce this

approach, we begin with a general description of TV-VAR models.

2.1 Time-varying Vector Autoregressive Model and Bayesian In-

ference

Suppose an observed K-variate time series of length T is deﬁned as xt = (x1,t, . . . , xK,t)(cid:48) for

t = 1, . . . , T . For this time series, we deﬁne the time-varying vector AR model with order P

(TV-VAR(P )) as

P
(cid:88)

Φp,txt−p + ut, ut ∼ N (0, Σt),

xt =

p=1

(1)

where Φp,t and ut are the K × K AR coeﬃcient matrix for lag p and the K × 1 innovation

vector at time t, respectively. The innovation ut is assumed to follow a multivariate Gaussian

distribution with zero-mean and time-dependent covariance matrix, Σt. This deﬁnition for

the TV-VAR model results in nonstationary behavior as a consequence of the coeﬃcient and

4

innovation covariance matrices varying over time.

Among many Bayesian inference approaches to TV-VAR models, the elements of Φp,t are

often assumed to follow random walk processes over time. The prior distributions are often

assumed on the decomposed innovation covariance matrix. After applying an LDL decom-

position (also called modiﬁed Cholesky decomposition) on the innovation covariance matrix,

there are diﬀerent assumptions on the elements of the diagonal matrix D. The stochastic

volatility class of TV-VAR models (Primiceri, 2005; Del Negro and Primiceri, 2015; Naka-

jima et al., 2011) assume the logarithm of the diagonal elements of the innovation covari-

ance follow a random walk or an AR process. As such, these models can capture changing

innovation variances. Alternatively, MDLMs provide full posterior inference for TV-VAR

parameters and assume the diagonal elements of the innovation covariance follow random

walk processes. However, the inference of MDLMs requires expensive matrix computations.

Thus, the usage is limited to those time series with a small number of series and TV-VAR

models of low orders. Zhao and Prado (2020) proposed a multivariate BLF in which the

computational cost increases linearly with the model order, but the computational cost of

their approach still increases exponentially with the number of series. In contrast, we propose

methods that avoid cumbersome matrix calculations in the BLFs.

2.2 Time-varying Periodic Time Series

Pagano (1978) proposed a “one-channel-at-a-time” modeling approach to break the VAR

model into scalar periodic AR processes. This approach makes the computational cost in-

crease linearly rather than exponentially with the model order. For a K-variate TV-VAR

model such as (1), we consider an LDL decomposition such that Σt = LtWtL(cid:48)

t, where Lt is

a lower unit triangular matrix and Wt is a diagonal matrix. With both sides of (1) premul-

tiplied by the inverse of Lt, the covariance matrix reduces to a diagonal matrix Wt, such

5

that Wt = diag(σ2

1,t, . . . , σ2

K,t). As such, we obtain the instantaneous response-orthogonal

innovations model (Gersch and Stone, 1994, 1995; Kitagawa and Gersch, 1996)

L−1

t xt =

P
(cid:88)

p=1

Ap,txt−p + εt,

εt ∼ N (0, Wt),

(2)

where Ap,t = L−1

t Φp,t and (cid:15)t = L−1

t ut. (2) is the model we actually estimate. Since Wt

is diagonal, (2) can be modeled as a set of uncorrelated AR processes. By interlacing the

multiple series of xt, we obtain an equivalent periodic TV-AR model, in which it is deﬁned

that yk+(t−1)K = xk,t, k = 1, . . . , K, t = 1, . . . , T . This K-channel periodic TV-AR model is

given as

yk+(t−1)K =

Mk(cid:88)

m=1

am,k+(t−1)Kyk+(t−1)K−m + (cid:15)k+(t−1)K,

(3)

where am,k+(t−1)K is the mth AR coeﬃcient at time t, (cid:15)k+(t−1)K is the innovation with variance

k+(t−1)K = σ2
σ2

k,t−1 and Mk = KP + k − 1 is the order of the kth series, yk+(t−1)K, for

t = 1, . . . , T . Therefore, the TV-VAR model given by (1) can be rewritten as a periodic

TV-AR model deﬁned by (3). The periodic TV-AR can be expressed in a K-vector form.

For example, for K = 3, P = 2, (3) can be written in matrix form as








1

−a1,3(t−1)+2

0

1

0

0






















y3(t−1)+1

y3(t−1)+2

y3(t−1)+3

=








a3,3(t−1)+1 a2,3(t−1)+1 a1,3(t−1)+1

y3(t−1)−2

a4,3(t−1)+2 a3,3(t−1)+2 a2,3(t−1)+2

y3(t−1)−1






















−a2,3(t−1)+3 −a1,3(t−1)+3 1

a5,3(t−1)+3 a4,3(t−1)+3 a3,3(t−1)+3

y3(t−1)








a6,3(t−1)+1 a5,3(t−1)+1 a4,3(t−1)+1

y3(t−1)−5

+

a7,3(t−1)+2 a6,3(t−1)+2 a5,3(t−1)+2

y3(t−1)−4

a8,3(t−1)+3 a7,3(t−1)+3 a6,3(t−1)+3

y3(t−1)−3






















+








(cid:15)3(t−1)+1

(cid:15)3(t−1)+2

(cid:15)3(t−1)+3








,

t = 1, . . . , T.

(4)

As in (4), each channel has its own process. As such, the K-channel periodic TV-AR process

is named in the sense that it is obtained by interlacing K uncorrelated TV-AR processes.

The parameters in (1) and the parameters in the corresponding periodic TV-AR model

6

given by (3) have the relationship

Φp,t = −LtAp,t

Σt = LtWtL(cid:48)
t.

(5)

(6)

This relationship allows us to rewrite a TV-VAR model as a periodic TV-AR model, and

vice versa.

2.3 Circular Lattice Filter

We propose a BCLF model, which can handle both time-varying coeﬃcients and time-varying

innovation covariance. According to the Durbin-Levinson algorithm, there exists a unique

correspondence between the PARCOR coeﬃcients and the AR coeﬃcients, (Shumway and

Stoﬀer, 2006; Kitagawa, 2010; Yang et al., 2016). This provides a direct way of estimating

AR models through the PARCOR coeﬃcients (see Hayes (1996) and the Supplementary

Appendix of Yang et al. (2016)). Here, we modify the above approach for TV-VAR models.

In the periodic TV-AR model deﬁned by (3), the series is ﬁtted by TV-AR models itera-

tively. The PARCOR coeﬃcients are estimated through TV-AR models in every stage of the

circular lattice structure. Finally, the PARCOR coeﬃcients are transformed into TV-VAR

coeﬃcients. We denote f (Mk)

k+(t−1)K and b(Mk)

k+(t−1)K to be the prediction error of kth series at

time t for the forward and backward time-varying AR(Mk) models, respectively, where

f (Mk)
k+(t−1)K = yk+(t−1)K −

b(Mk)
k+(t−1)K = yk+(t−1)K −

Mk(cid:88)

m=1

Mk(cid:88)

m=1

a(Mk)
m,k+(t−1)Kyk+(t−1)K−m

d(Mk)
m,k+(t−1)Kyk+(t−1)K+m

and a(Mk)

m,k+(t−1)K and b(Mk)

m,k+(t−1)K are the forward and backward AR coeﬃcients of the corre-

sponding time-varying periodic AR(Mk) models. Then, at the mth stage of the lattice ﬁlter,

for m = 1, . . . , Mk, the forward and the backward coeﬃcients and the forward and backward

7

prediction errors have the relationship

k+(t−1)K = f (m−1)
f (m)

k+(t−1)K − α(m)

f,m,k+(t−1)Kb(m−1)

k−1+tK,

k+(t−1)K = b(m−1)
b(m)

k−1+tK − α(m)

b,m,k+(t−1)Kf (m−1)

k+(t−1)K,

(7)

(8)

with the initial condition, f (0)

k+(t−1)K = b(0)

k+(t−1)K = yk+(t−1)K, and where α(m)

f,m,k+(t−1)K and

α(m)
b,m,k+(t−1)K are the lag m forward and backward PARCOR coeﬃcients of the kth series at

time t, respectively. The kth series jth lag forward and backward AR coeﬃcients at time t,

j,k+(t−1)K and d(m)
a(m)

j,k+(t−1)K, can be obtained according to the following equations

j,k+(t−1)K = a(m−1)
a(m)

j,k+(t−1)K − a(m)

m,k+(t−1)Kd(m−1)

m−j,k+(t−1)K,

j,k+(t−1)K = d(m−1)
d(m)

j,k+(t−1)K − d(m)

m,k+(t−1)Ka(m−1)

m−j,k+(t−1)K,

with j = 1, . . . , m − 1, a(m)

m,k+(t−1)K = α(m)

f,m,k+(t−1)K and d(m)

m,k+(t−1)K = α(m)

b,m,k+(t−1)K. Going

from the ﬁrst stage through the end, {a(Mk)

m,k+(t−1)K}, t = 1, . . . , T , m = 1, . . . , Mk, are the

coeﬃcients in (3). The estimated AR coeﬃcients are then obtained through (5) and (6).

For the kth series, when the true process is TV-AR(Mk), the forward innovation variance at

stage Mk, {(σ(Mk)

f,k+(t−1)K)2} is equal to the innovation variance {σ2

k,t} for t = 1, . . . , T .

2.4 Model Speciﬁcation and Bayesian Inference

To estimate the forward and backward PARCOR coeﬃcients and innovation variances in (7)

and (8), we assume random walks for the PARCOR coeﬃcients and multiplicative random

walks for the innovation variance. The PARCOR coeﬃcients are modeled as

f,m,k+tK = α(m)
α(m)

f,m,k+(t−1)K + (cid:15)f,m,k+tK,

(cid:15)f,m,k+tK ∼ N (0, ζf,m,k+tK),

b,m,k+tK = α(m)
α(m)

b,m,k+(t−1)K + (cid:15)b,m,k+tK,

(cid:15)b,m,k+tK ∼ N (0, ζb,m,k+tK),

where ζf,m,k+tK and ζb,m,k+tK are time dependent evolution variances. These evolution vari-

ances are deﬁned via the discount factors γf,k,m and γb,k,m within the range (0, 1), respectively

8

(see West and Harrison (1997) and the Supplementary Appendix of Yang et al. (2016) for

details). The discount factor γ controls the smoothness of PARCOR coeﬃcients. Here, we

assume γf,k,m = γb,k,m = γk,m at each stage m and select their value through a grid-search

based on the likelihood of the ﬁtted TV-AR model at each stage. Similarly, the forward and

backward innovation variances are modeled as

f,m,k+tK = σ2
σ2

f,m,k+(t−1)K(δf,m/ηf,m,k+tK),

ηf,m,k+tK ∼ Beta(gf,m,k+tK, hf,m,k+tK),

b,m,k+tK = σ2
σ2

b,m,k+(t−1)K(δb,m/ηb,m,k+tK),

ηb,m,k+tK ∼ Beta(gb,m,k+tK, hf,m,k+tK),

where δf,m and δb,m are also discount factors in the range (0,1), and the multiplicative innova-

tions, ηf,m,k+tK and ηb,m,k+tK, follow beta distributions with parameters (gf,m,k+tK, hf,m,k+tK)

and (gb,m,k+tK, hb,m,k+tK), respectively (see West and Harrison (1997) and the Supplementary

Appendix of Yang et al. (2016) for details). The smoothness of the innovation variance is con-

trolled by both γ and δ. Similar to the PARCOR coeﬃcients, we assume δf,k,m = δb,k,m = δk,m

at each stage. Note that (cid:15)b,m,k+tK, (cid:15)b,m,k+tK, ηf,m,k+tK and ηb,m,k+tK are mutually independent

and are also independent of any other variables in the model.

We use conjugate normal priors for the forward and backward PARCOR coeﬃcients, so

that

p(αf,m,k−K|Df,m,k−K) ∼ N (µf,m,k−K, Cf,m,k−K),

p(αb,m,k−K|Db,m,k−K) ∼ N (µb,m,k−K, Cb,m,k−K),

where m = 1, . . . , Mk, k = 1, . . . , K, Df,m,k−K and Db,m,k−K denotes the information avail-

able at the initial time t = 0, µf,m,k−K and Cf,m,k−K are the mean and the variance of

the normal prior distribution. We also specify conjugate initial priors for the forward and

backward innovation variance, so that

p(σ2

f,m,k−K|Df,m,k−K) ∼ G(νf,m,k−K/2, κf,m,k−K/2),

p(σ2

b,m,k−K|Db,m,k−K) ∼ G(νb,m,k−K/2, κb,m,k−K/2),

9

where G(·, ·) is the gamma distribution, and νf,m,k−K/2 and κf,m,k−K/2 are the shape and

rate parameters of the gamma prior distribution. Typically, we specify these starting values

as constants over all stages. In order to reduce the eﬀect of the prior distribution, we choose

µf,m,k−K/2 and Cf,m,k−K to be zero and one, respectively and ﬁx νf,m,0 = 1 and set κf,m,k−K

to equal to the sample variance of the initial part of each series. Following these settings,

we can obtain the DLM sequential ﬁltering and smoothing algorithms (West and Harrison,

1997) to derive the marginal posterior distributions of the forward and backward parameter

parameters in (7) and (8). The detailed algorithm of the sequential ﬁltering and smoothing

are given in B.

2.5 Model Selection

To apply the BCLF, we need to ﬁnd not only the optimal order but also the optimal discount

factors. The selection of an optimal model order can be done numerically using model

selection criterion. We start with setting up a maximal order, Pmax, and start from the

ﬁrst stage of the lattice ﬁlter through the Mk,max-th stage (Mk,max = KPmax + k − 1) for

each series. At the mth stage, for the kth series, we search a group of pre-speciﬁed sets

of discount factors {γk,m, δk,m} to ﬁnd the set which maximizes the likelihood of the ﬁtted

DLM, and use the corresponding estimated parameters as the result. Having all the optimal

discount factors and the corresponding estimated parameters, the model selection criterion

for the order P can be computed based on the estimation obtained from the ﬁrst through the

(P K + K − 1)th stage. According to the model selection criterion values, the optimal order

is selected. For model order selection, we consider several criteria: the Bayesian Information

Criterion (BIC), the deviance information criterion (DIC) (Gelman et al., 2013), the widely

applicable Akaike information criterion (WAIC) (Watanabe, 2010) (see C for details). In

addition to these criteria, the scree plot method proposed in Yang et al. (2016) also provides

10

a good visual tool to assist the model selection in BCLF.

2.6 Forecasting

Having estimated all parameters, we consider 1-step ahead forecasts of the TV-VAR(P )

model. The 1-step ahead predictive distribution of the PARCOR coeﬃcients can be obtained

according to West and Harrison (1997). We generate J samples for each of the PARCOR

coeﬃcients from their one-step-ahead predictive distribution as {α(m)(j)

f,m,k+T K, α(m)(j)

b,m,k+T K for all

k, m}, j = 1, . . . , J. The samples of the 1-step ahead prediction of TV-VAR parameters,

Φp,T +1 can be obtained as {Φ(j)

p,T +1, j = 1, . . . , J}, for p = 1, . . . , P , by transforming the

samples of the PARCOR coeﬃcients according to (5) and (6). Finally, the 1-step ahead

forecast is can be obtained using

x(j)
T +1 =

P
(cid:88)

p=1

Φ(j)

p,T +1xT +1−p.

(9)

We use the posterior mean of x(j)

T +1 (j = 1, . . . , J) obtained through the samples in (9) as

the 1-step ahead forecast. This forecast can be easily extended to h-steps. The details for

forecasting up to h-steps ahead can be found in D.

3 Simulation Studies

To assess the eﬀectiveness of our method, we conducted similar simulation studies to Zhao

and Prado (2020) and compared our results with results obtained using their approach

and a standard TV-VAR(P ) model implementation. The comparison was conducted using

spectral analysis and forecasting.

In the spectral analysis, results are assessed using the

average squared error (ASE) (Ombao et al., 2001) between the true spectral density and the

estimated spectral density. In contrast, the mean squared prediction error (MSPE) is used

to evaluate the forecasting performance.

11

3.1 Simulation 1: Bivariate TV-VAR(2) Process

We consider 500 bivariate time series of length T = 1034 simulated from a TV-VAR model

(Zhao and Prado, 2020) as follows: xt = Φ1,txt−1 + Φ2,txt−2 + ut, ut ∼ N (0, Σt) with





Φ1,t =

r1,tcos( 2π
λ1,t

)

0



 and Φ2,t =
)

φ1,1,2,t
r2,tcos( 2π
λ2,t
T t + 0.95, r3,t = 0.2





−r2

1,t φ2,1,2,t

0

−r2
2,t



 ,

where r1,t = 0.1

T t + 0.85, r2,t = − 0.1

T t − 0.9, r4,t = 0.2

T t + 0.7, λ1,t = 15

T t + 5,

and λ2,t = − 10

T t + 15. We consider three diﬀerent cases for the values of φ1,1,2,t and φ2,1,2,t

, namely (1) φ1,1,2 = 0, φ2,1,2 = 0; (2) φ1,1,2 = −0.8, φ2,1,2 = 0; (3) φ1,1,2 = r3,t, φ2,1,2 = r4,t.

These three cases have covariances Σt = I2, 2I2, and 3I2, where I2 denotes a 2 × 2 identity

matrix. We also consider cases (4), (5), (6) with the same Φt as (1), (2), (3), respectively,

but with diﬀerent covariance Σt, such that Σ1,1,t = Σ2,2,t = 1 + t

T , Σ1,2,t = Σ2,1,t = 0 for

t = 1, . . . , T . The bivariate spectral matrix of this process can be obtained by

g(t, ω) = Ψ(t, ω)−1 × Σt × Ψ∗(t, ω)−1,

where Ψ(t, ω) = I2 −

P
(cid:80)
p=1

Φp,texp{−2pπiω}, Σt is time-varying innovation covariance and ∗

stands for the Hermitian matrix (conjugate transpose matrix). The spectral matrix g(t, ω)

is symmetric and consists of series g11(t, ω), g22(t, ω) and g12(t, ω), representing the spectrum

of the ﬁrst series, the spectrum of the second series and the cross-spectrum between the ﬁrst

and the second series, respectively. The squared coherence between the ﬁrst and the second

series is deﬁned as

ρ2
12(t, ω) =

|g12(t, ω)|2
g11(t, ω)g22(t, ω)

.

The spectral matrix can be estimated by

(cid:98)g(t, ω) = (cid:98)Ψ(t, ω)−1 × (cid:98)Σt × (cid:98)Ψ

∗

(t, ω)−1,

where (cid:98)Ψ(t, ω) = |I2 −

P
(cid:80)
p=1

(cid:98)Φp,texp{−2pπiω}| and (cid:98)Σt are estimated values. The estimated

squared coherence (cid:98)ρ2

12(t, w) can be obtained accordingly.

12

To evaluate the performance in estimating the time-frequency representations, we com-

pare diﬀerent models by the mean and standard deviations of the ASEs. We calculate ASE

for each realization as follows (Ombao et al., 2001):

ASEn = (T L)−1

T
(cid:88)

L
(cid:88)

t=1

l=1

(log((cid:98)g(t, ωl)) − log(g(t, ωl)))2 ,

where n = 1, . . . , 500, wl is the lth frequency, and L is the number of frequencies in the

time-frequency representation. We denote the average over all realizations as ASE =

1/500

ASEn.

500
(cid:80)
n=1

To evaluate the performance of our proposed method (BCLF), we choose a Pmax = 5 and

ﬁt the simulated datasets with the TV-VAR order adaptively selected based on BIC. The

other model selection criteria were also obtained and are shown in Table 1. BIC suggests

that TV-VAR(2) is the best model for most simulated datasets.

In practice, BIC works

extremely well for model selection of the BCLF and signiﬁcantly better than DIC and WAIC.

Consequently, we use BIC for model order selection of the BCLF throughout this paper.

Our method is compared with the TV-VPARCOR and the TV-VAR, as presented in Zhao

and Prado (2020). As recommended in Zhao and Prado (2020), for every dataset, TV-

VPARCOR and TV-VAR have the model orders selected based on DIC. In contrast, BCLF

has the model order selected based on BIC. All model selections have a maximum order of

5. The discount factors in all of BCLF, TV-VPARCOR, and TV-VAR are chosen from a

grid of values in [0.99, 1] based on the likelihood. We select this range to make our results

comparable to those of Zhao and Prado (2020). Note that TV-VAR and BCLF consider

time-varying covariance while TV-PARCOR assumes constant covariance. Figures 1 and 2

display boxplots which summarize the ASE for six cases compared with TV-VAR and TV-

VPARCOR. Figure 3 shows the average of the estimated spectrum of the two series and the

average of the estimated coherence between them over the 500 simulated datasets in Case

(2).

13

Further, we compare the forecast of BCLF with TV-PARCOR. The forecast method is

given in Sections 2.6 and D. We conduct one-step ahead rolling prediction for t = 1025:1034

for the ﬁrst 3 simulation cases, which have constant innovation covariances. For each case

and each method, 100 series of length 1034 are generated, the last 10 observations of the

series are held out for prediction. Table 2 shows the mean and the standard deviation of the

100 MSPEs for each case and each method. In this simulation study, BCLF one-step ahead

prediction performs better than TV-VPARCOR.

Table 3 shows the computation time of the simulation studies. The time of Simulation 1 is

the time used for ﬁtting one dataset of Case 1, including the selection of discount factors, the

selection of the model order, and the estimation of parameters. Note that the TV-VPARCOR

method is conducted using Rcpp and parallel computing while the BCLF is coded in R. If

TV-VPARCOR is estimated using R (without Rcpp), it would result in signiﬁcantly longer

computation time than that shown in this table. Moreover, the computation associated with

BCLF can be accelerated by using Rcpp and parallel computing, resulting is substantially

reduced computation time. In Simulation 1, all of the six cases take approximately the same

time and therefore, we use Case 1 as an illustration to represent all the cases.

Each of the methods TV-VAR, TV-VPARCOR, and BCLF have some drawbacks that

lower their performance. TV-VAR and TV-VPARCOR use an approximate estimator to

estimate the covariance, which does not work as well as our time-varying covariance esti-

mator in some cases. Additionally, TV-VAR uses one discount factor for all coeﬃcients.

This produces larger ASEs for the TV-VAR in most cases. The BCLF takes advantage of

the modiﬁed Cholesky decomposition due to the “one-channel-at-a-time” algorithm. This

decomposition brings the problem of ordering uncertainty (Primiceri, 2005; Zhao et al., 2016;

Lopes et al., 2021). Consequently, the priors on the parameters change with the ordering of

multiple series and, therefore, the estimated results also change. See Section 5 for additional

discussion.

14

Table 4 shows the ASEs of each method for diﬀerent coeﬃcients and innovation covari-

ances when the innovation covariances are time-invariant. This table suggests that the BCLF

performs better for spectrum estimation in most cases. In other words, the BCLF is more

robust to varying levels of the covariance. That is, when the true covariance increases from

1 to 3, the ASEs of BCLF stay at approximately the same level, while the ASEs of TV-VAR

and TV-VPARCOR become signiﬁcantly larger. Moreover, Table 5 shows that when the

innovation covariance is time-varying, the BCLF works better than the constant covariance

models TV-VAR and TV-VPARCOR, as expected.

15

Table 1: Model selection of TV-VAR model using BCLF for 500 simulated datasets from

bivariate TV-VAR(2) process. Each column gives the model order P and the percentage of

the datasets that are selected to this order according to BIC, DIC, and WAIC.

Case Criterion

1

2

P

3

4

5

1

2

3

4

5

6

BIC

DIC

0% 100% 0% 0% 0%

0%

20% 10% 23% 47%

WAIC

90% 10% 0% 0% 0%

BIC

DIC

0% 100% 0% 0% 1%

0%

92% 1% 4% 3%

WAIC

99%

1%

0% 0% 0%

BIC

DIC

0% 100% 0% 0% 0%

0%

87% 8% 0% 5%

WAIC

100% 0%

0% 0% 0%

BIC

DIC

0% 100% 0% 0% 0%

0%

18% 11% 19% 52%

WAIC

100% 0%

0% 0% 0%

BIC

DIC

0% 100% 0% 0% 0%

0%

88% 4% 0% 8%

WAIC

100% 0%

0% 0% 0%

BIC

DIC

0% 100% 0% 0% 0%

0%

82% 10% 2% 6%

WAIC

100% 0%

0% 0% 0%

16

Figure 1: Boxplots of ASEs by three methods in cases 1, 2, 3 when Σt = I2. In each plot,

the index 1, 2, and 3 denotes TV-VAR, TV-, and BCLF, respectively.

17

lllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.000.100.200.30g11Case 1lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.000.100.20g22Case 1lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.0000.0150.030r12Case 1llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.00.20.40.60.8g11Case 2llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.00.20.4g22Case 2llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.000.020.040.06r12Case 2lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.00.40.8g11Case 3llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.00.20.40.6g22Case 3llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.000.040.08r12Case 3Figure 2: Boxplots of ASEs by three methods in cases 4, 5, 6. In each plot, the index 1, 2,

and 3 denotes TV-VAR, TV-PARCOR, and BCLF, respectively.

18

llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.00.20.40.60.8g11Case 4llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.00.20.4g22Case 4llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.000.020.040.06r12Case 4llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.00.20.40.60.8g11Case 5lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.00.20.4g22Case 5llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.000.020.04r12Case 5llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.00.40.8g11Case 6lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.00.20.40.60.8g22Case 6lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1230.000.030.06r12Case 6Figure 3: Case with φ1,1,2,t = −0.8 and φ2,1,2,t = 0. Top: True log spectral density g11(t, ω)

(left), true log spectral density g22(t, ω) (middle), true squared coherence ρ2

12(t, ω) (right).
Bottom: Average of the estimated (cid:98)g11(t, ω) (left), average of the estimated (cid:98)g22(t, ω) (middle),
average of the estimated (cid:98)ρ2

12(t, ω) (right) using BCLF.

19

20060010000.00.10.20.30.40.5g11(t, w)TimeFrequency−20246820060010000.00.10.20.30.40.5g22(t, w)TimeFrequency−20246820060010000.00.10.20.30.40.5r12(t, w)TimeFrequency0.00.20.40.60.81.020060010000.00.10.20.30.40.5g11^(t, w)TimeFrequency−20246820060010000.00.10.20.30.40.5g22^(t, w)TimeFrequency−20246820060010000.00.10.20.30.40.5r12^(t, w)TimeFrequency0.00.20.40.60.81.0Table 2: MSPE values for the 1-step ahead rolling forecast (t = 1025:1034) and corresponding

standard deviations (in parentheses) obtained from BCLF and TV-VPARCOR methods for

the TV-VAR(2) simulated data.

Model

Case 1

Case 2

Case 3

TV-VPARCOR 1.046(0.332)

1.061(0.327)

1.103(0.371)

BCLF

1.038(0.317)

1.046(0.325)

1.085(0.354)

3.2 Simulation 2: 20-Dimensional TV-VAR(1)

We consider a simulation from Zhao and Prado (2020) and generate data from a 20-

dimensional nonstationary TV-VAR(1) process of length T = 300. The elements Φi,j,t of

the autoregressive coeﬃcients at time t, Φt, are given as follows:

φi,j =






0.7 + 0.2

299 × t

0.7 + 0.2

299 × t

for all

i = j, i = 1, . . . , 10,

for all

i = j, i = 1, . . . , 10,

0.9

−0.9

for

for

(i, j) ∈ [(1, 5), (2, 15)]

(i, j) ∈ [(6, 12), (15, 20)]

0

otherwise,

for t = 1, . . . , 300. Additionally, the innovation covariance is speciﬁed as Σ = 0.1I.

20

Table 3: Computation times (in seconds) of ﬁtting one simulated dataset for Simulation 1

and 2 using TV-VPARCOR and BCLF models. The times cover the selection of discount

factors, the selection of the model order, and the estimation of parameters. Note that the

TV-VPARCOR method is conducted using Rcpp and parallel computing while the BCLF is

coded in R.

Model

Simulation 1

Simulation 2

TV-VPARCOR (Rcpp)

10.83 seconds

17874.36 seconds

BCLF (R)

9.86 seconds

279.76 seconds

21

Table 4: Mean ASEs and corresponding standard deviations (in parentheses) using diﬀerent

methods for 500 simulated datasets from TV-VAR(2).

Model

g11

g22

ρ2
12

Case 1: φ1,1,2,t = 0, φ2,1,2,t = 0, Σt = I2

TV-VAR

0.05393 (0.02349)

0.05497 (0.04214)

0.00292 (0.00194)

TV-VPARCOR 0.03302 (0.01313)

0.04062 (0.02288)

0.00353 (0.00424)

BCLF

0.04037 (0.01905)

0.03643 (0.01713)

0.00123 (0.00107)

Case 1: φ1,1,2,t = 0, φ2,1,2,t = 0, Σt = 2I2

TV-VAR

0.07538 (0.03663)

0.07748 (0.0852)

0.00484 (0.00357)

TV-VPARCOR 0.04144 (0.02542)

0.04960 (0.0305)

0.00582 (0.00595)

BCLF

0.03509 (0.01680)

0.03622 (0.0169)

0.00124 (0.00112)

Case 1: φ1,1,2,t = 0, φ2,1,2,t = 0, Σt = 3I2

TV-VAR

0.10443 (0.05255)

0.10575 (0.05543)

0.00643 (0.00574)

TV-VPARCOR 0.05114 (0.04774)

0.06347 (0.05972)

0.00804 (0.00877)

BCLF

0.03513 (0.01634)

0.03623 (0.01699)

0.00124 (0.00111)

Case 2: φ1,1,2,t = −0.8, φ2,1,2,t = 0, Σt = I2

TV-VAR

0.09164 (0.08122)

0.0870 (0.070740)

0.00583 (0.00364)

TV-VPARCOR 0.06124 (0.02644)

0.0475 (0.021017)

0.00491 (0.00480)

BCLF

0.03712 (0.01255)

0.0384 (0.012639)

0.00262 (0.00133)

Case 2: φ1,1,2,t = −0.8, φ2,1,2,t = 0, Σt = 2I2

TV-VAR

0.10632 (0.07053)

0.09847 (0.07628)

0.00733 (0.00551)

TV-VPARCOR 0.19222 (0.30678)

0.12383 (0.19629)

0.01293 (0.01698)

BCLF

0.03833 (0.01303)

0.03937 (0.01285)

0.00259 (0.00125)

Case 2: φ1,1,2,t = −0.8, φ2,1,2,t = 0, Σt = 3I2

TV-VAR

0.26823 (0.96065)

0.16537 (0.28518)

0.00978 (0.00817)

TV-VPARCOR 0.28447 (0.50113)

0.17805 (0.33872)

0.01791 (0.02220)

BCLF

0.03836 (0.01304)

0.03937 (0.01285)

0.00258 (0.00125)

22

Case 3: φ1,1,2,t = r3,t, φ2,1,2,t = r4,t, Σt = I2

TV-VAR

0.09722 (0.09334)

0.09132 (0.07920)

0.00493 (0.00310)

TV-VPARCOR 0.11324 (0.12927)

0.07579 (0.07308)

0.00807 (0.01014)

BCLF

0.06804 (0.05361)

0.03902 (0.01943)

0.00442 (0.00372)

Case 3: φ1,1,2,t = r3,t, φ2,1,2,t = r4,t, Σt = 2I2

TV-VAR

0.10583 (0.07045)

0.10023 (0.08221)

0.00622 (0.00492)

TV-VPARCOR 0.19213 (0.30681)

0.12378 (0.19631)

0.01292 (0.01698)

BCLF

0.06968 (0.05467)

0.03996 (0.01970)

0.00446 (0.00377)

Case 3: φ1,1,2,t = r3,t, φ2,1,2,t = r4,t, Σt = 3I2

TV-VAR

0.19117 (0.68771)

0.15403 (0.28426)

0.00836 (0.00907)

TV-VPARCOR 0.28374 (0.49940)

0.17709 (0.33651)

0.01791 (0.02219)

BCLF

0.06980 (0.05447)

0.04005 (0.01978)

0.00445 (0.00378)

Similar to Zhao and Prado (2020), we choose a Pmax = 3 and ﬁt the simulated datasets

with the TV-VAR order adaptively selected based on BIC as we suggest. The other model

selection criteria were also obtained. All of BIC, DIC, and WAIC suggest that TV-VAR(1)

is the best model for the simulated datasets. The discount factors are chosen from a grid

of values in [0.99, 1] based on the likelihood of the ﬁtted TV-AR models in each stage.

Figures 4 and 5 summarize the posterior inference obtained from the BCLF approach on

the 100 simulated datasets. These ﬁgures show the average of the estimated spectrum

of the two series and the average of the estimated coherence between them over the 100

simulated datasets. Table 3 shows the computation time of the simulation studies, including

the selection of discount factors, the selection of the model order and the estimation of

parameters. According to the results in this simulation studies, the BCLF shows superior

performance relative to the other models considered in terms of both parameter estimation

and forecasting. Importantly, at the same time, we see unmatched computational eﬃciency.

23

Table 5: Mean ASE values and corresponding standard deviations (in parentheses) for 500

simulated datasets from TV-VAR(2).

Case 4: φ1,1,2,t = 0, φ2,1,2,t = 0

Model

g11

g22

ρ2
12

TV-VAR

0.0916 (0.0812)

0.0870 (0.0707)

0.0058 (0.0036)

TV-VPARCOR 0.0614 (0.0264)

0.0475 (0.0210)

0.0049 (0.0048)

BCLF

0.0371 (0.0126)

0.0384 (0.0126)

0.0026 (0.0013)

Case 5: φ1,1,2,t = −0.8, φ2,1,2,t = 0

Model

g11

g22

ρ2
12

TV-VAR

0.1174 (0.0819)

0.1232 (0.0701)

0.0056 (0.0034)

TV-VPARCOR 0.0938 (0.0296)

0.0871 (0.0204)

0.0048 (0.0045)

BCLF

0.0396 (0.0129)

0.0427 (0.0130)

0.0027 (0.0012)

Case 6: φ1,1,2,t = r3,t, φ2,1,2,t = r4,t

Model

g11

g22

ρ2
12

TV-VAR

0.1228 (0.0934)

0.1281 (0.0782)

0.0047 (0.0029)

TV-VPARCOR 0.1465 (0.1270)

0.1159 (0.0736)

0.0073 (0.0087)

BCLF

0.0788 (0.0660)

0.0449 (0.0206)

0.0051 (0.0040)

24

Figure 4: Top: True log spectral densities of Components 1, 2, 8, and 15. Bottom: estimated

log spectral densities of Components 1, 2, 8, and 15 using the BCLF.

25

501500.00.10.20.30.40.5True Spectrum 1Frequency−4−202468501500.00.10.20.30.40.5True Spectrum 2Frequency−4−202468501500.00.10.20.30.40.5True Spectrum 8Frequency−4−202468501500.00.10.20.30.40.5True Spectrum 15Frequency−4−202468501500.00.10.20.30.40.5Spectrum 1Frequency−4−202468501500.00.10.20.30.40.5Spectrum 2Frequency−4−202468501500.00.10.20.30.40.5Spectrum 8Frequency−4−202468501500.00.10.20.30.40.5Spectrum 15Frequency−4−202468Figure 5: Top: True coherence between Components 1 and 5, 2 and 15, 5 and 12, and 15

and 20. Bottom: Estimated coherences between Components 1 and 5, 2 and 15, 5 and 12,

and 15 and 20 using the BCLF.

26

502000.00.10.20.30.40.5True Coherence 1, 5Frequency0.00.20.40.60.81.0502000.00.10.20.30.40.5True Coherence 2, 15Frequency0.00.20.40.60.81.0502000.00.10.20.30.40.5True Coherence 5, 12Frequency0.00.20.40.60.81.0502000.00.10.20.30.40.5True Coherence 15, 20Frequency0.00.20.40.60.81.0502000.00.10.20.30.40.5Coherence 1, 5Frequency0.00.20.40.60.81.0502000.00.10.20.30.40.5Coherence 2, 15Frequency0.00.20.40.60.81.0502000.00.10.20.30.40.5Coherence 5, 12Frequency0.00.20.40.60.81.0502000.00.10.20.30.40.5Coherence 15, 20Frequency0.00.20.40.60.81.04 Case Studies

4.1 Quarterly GDP Data

We apply the BCLF to the quarterly change in seasonally adjusted GDP (in percentage) for

ﬁve countries: the United States (US), Canada (CA), United Kingdom (UK), South Korea

(KO), and Taiwan (TW) (Matteson and Tsay, 2011). We compare the out-of-sample forecast

performance of our approach with standard vector autoregressive (VAR) models. The data

can be obtained from the Organization for Economic Cooperation and Development (OECD)

website (https://www.oecd.org/). The data we use begins with the ﬁrst quarter of 1981

and goes through the second quarter of 2009. The time series plot of this dataset shows that

the US, CA, and UK are more closely correlated than KO and TW. We want to use these

correlated series to compare the prediction performance of the BCLF with standard VAR

models.

We set Pmax = 10 and consider discount factor values on a grid in the [0.90, 1] range and

assume that each country has tits own optimal discount factor values. Throughout the rolling

predictions, the BCLF always selected the order 1 as the best model order. Moreover, to

address the problem of ordering uncertainty, we use the Dynamic Ordering Selection (DOS)

and the Dynamic Ordering Averaging (DOA) approaches proposed by Levy and Lopes (2021)

in conjunction with BCLF. We use the R package MTS (Tsay and Wood, 2021) to conduct

VAR model prediction. All of AIC, BIC and the Hannan and Quinn information criterion

suggest the best model order is 1. Table 6 shows the mean square prediction error (MSPE)

of the one-step-ahead rolling predictions starting from the second quarter of 2004 through

the second quarter of 2009. From this table we can see that the BCLF provides superior

prediction on this quarterly GDP data relative to the standard VAR model in terms of

MSPE. In addition, the DOS and DOA reduce the ordering uncertainty and, thus, improves

the forecast accuracy.

27

Figure 6: The quarterly percentage change in seasonally adjusted GDP of the United States

(US), Canada (CA), United Kingdom (UK), Korea (KO), Taiwan (TW) from 1981QI through

2009QII. The vertical line is at 2004QII, which is the beginning of the out-of-sample one-

step-ahead forecasts region.

28

TimeQuarterly Change in Seasonally Adjusted GDP (%)1980198519901995200020052010−8−6−4−20246CountryUSCAUKKOTWTable 6: MSPE of rolling one-step-ahead prediction on the quarterly GDP Data. BCLF-

DOS and BCLF-DOA denote the BCLF using DOS and DOA to solve ordering uncertainty,

respectively. VAR denotes the standard VAR model. Both the VAR model with mean vector

and without mean vector are included.

Method MSPE

BCLF

2.086

BCLF-DOS

1.939

BCLF-DOA

1.944

VAR without mean vector

2.249

VAR with mean vector

2.232

4.2 Wind Data

We apply the BCLF to the wind data used by Zhao and Prado (2020) and conduct a time-

frequency analysis and make 72 hour forecasts. This dataset contains the median wind speed

and direction measurements collected every 4 hours from 6/1/2010 to 8/15/2020 in Monterey,

Salinas, and Watsonville, 3 stations located near Monterey Bay, Northern California. These

data can be obtained from a publicly available database, the Iowa Environmental Mesonet

(IEM) (see http://mesonet.agron.iastate.edu/ASOS/). ASOS stations are located at

airports and take observations and basic reports from the National Weather Service (NWS),

the Federal Aviation Administration (FAA), and the Department of Defense (DOD). We use

the BCLF approach for a multivariate analysis of the six-dimensional time series of the wind

speed component and wind direction component for the 3 stations. We set Pmax = 10 and

consider discount factor values on a grid in the (0.95, 0.99] range and assume that each station

has their own optimal discount factor values. BIC selects the model order 6 for the TV-VAR

model. After applying BCLF to ﬁt the TV-VAR(6) model to the six-dimensional data, we

29

obtain the estimate of its time-frequency representation. Figure 7 shows the estimated log

spectral densities of the X (East-West) component and the Y (North-South) component for

each location. Figure 8 shows the estimated squared coherence between each pair of wind

components across the three locations. Generally, the results reveal a 24-hour cycle in X

components and Y components and their coherence and the magnitude of the cycles vary

with time.

The TV-VPARCOR model can also be used for forecasting as described in Section 2.6.

Table 7 compares the 72 hour forecasts obtained from the Naive, TV-VAR, TV-VPARCOR

and BCLF model for the north–south wind component and east-west component in all three

locations. Note that Naive denotes the naive forecast, that is, using the previous period

to forecast for the next period (carry-forward). We see that the BCLF gives best forecasts

among the four models in terms of the mean squared prediction error (MSPE).

Moreover, the computation time of each model varies signiﬁcantly for this wind data.

As we discussed previously, the BCLF is the fastest among those considered herein, the

TV-VPARCOR model is second fastest, and the TV-VAR is signiﬁcantly slower.

Table 7: MSPE of rolling one-step-ahead prediction on the Wind Data for next 72-hours

Method MSPE

BCLF

7.2163

TV-PARCOR

7.8931

TV-VAR

9.4009

Naive

14.2487

30

Figure 7: Top Row: Estimated log-spectral densities of the X (East-West) components for

Monterey (Spectrum 1), Salinas (Spectrum 2), and Watsonville (Spectrum 3). Bottom Row:

Estimated log-spectral densities of the Y (North-South) components for Monterey (Spectrum

4), Salinas (Spectrum 5), and Watsonville (Spectrum 6). The unit of time in the plots is 4

hours.

31

1002003004000.00.10.20.30.4Estimated Spectrum 1TimeFrequency02468101002003004000.00.10.20.30.4Estimated Spectrum 2TimeFrequency0246810121002003004000.00.10.20.30.4Estimated Spectrum 3TimeFrequency024681002003004000.00.10.20.30.4Estimated Spectrum 4TimeFrequency024681002003004000.00.10.20.30.4Estimated Spectrum 5TimeFrequency02468101002003004000.00.10.20.30.4Estimated Spectrum 6TimeFrequency0246810Figure 8: Top Row: Estimated squared coherences between the X (East-West) component

and Y (North-South) component in Monterey, Salinas, and Watsonville. Middle Row: Esti-

mated squared coherences between the X (East-West) components of Monterey and Salinas,

Monterey and Watsonville, and Salinas and Watsonville. Bottom Row: Estimated squared

coherences between the Y (North-South) components of Monterey and Salinas, Monterey

and Watsonville, and Salinas and Watsonville. The unit of time in the plots is 4 hours.

32

1002003004000.00.10.20.30.4Estimated CoherenceTimeFrequency0.00.20.40.60.81.01002003004000.00.10.20.30.4Estimated CoherenceTimeFrequency0.00.20.40.60.81.01002003004000.00.10.20.30.4Estimated CoherenceTimeFrequency0.00.20.40.60.81.01002003004000.00.10.20.30.4Estimated CoherenceTimeFrequency0.00.20.40.60.81.01002003004000.00.10.20.30.4Estimated CoherenceTimeFrequency0.00.20.40.60.81.01002003004000.00.10.20.30.4Estimated CoherenceTimeFrequency0.00.20.40.60.81.01002003004000.00.10.20.30.4Estimated CoherenceTimeFrequency0.00.20.40.60.81.01002003004000.00.10.20.30.4Estimated CoherenceTimeFrequency0.00.20.40.60.81.01002003004000.00.10.20.30.4Estimated CoherenceTimeFrequency0.00.20.40.60.81.05 Discussion

We propose a computationally eﬃcient model-based parametric approach for nonstationary

multivariate time series. We use a response-orthogonal reparameterization to transform

a TV-VAR model into a scalar periodic AR model and further use the Bayesian Lattice

ﬁlter together with PARCOR to speed up the estimation. Our approach can simultaneously

estimate the time-varying coeﬃcients and the time-varying innovation covariance. The “one

channel at-a-time” modeling avoids matrix inversion computations in the estimation, which

signiﬁcantly reduces the computation cost and makes the computation time increase linearly,

rather than exponentially, with the data dimension. Additionally, this “one channel at-a-

time” modeling makes it possible for our approach to beneﬁt from parallel computing, which

is a subject of future research. Moreover, the use of Bayesian lattice ﬁlters makes the

computation time increase linearly, rather than exponentially, with the model order. We

also provide a model selection method to choose the discount factors and the optimal model

order. The simulation cases show that the parameter estimation is fairly accurate. The GDP

and Wind data examples shows that the time-varying coeﬃcients and innovation covariance

can be eﬀectively used to reveal the time-varying structure.

Our method beneﬁts from the LDL decomposition (modiﬁed Cholesky decomposition) of

the innovation covariance as in (6). This framework introduces a problem of order uncertainty

(Primiceri, 2005; Zhao et al., 2016; Lopes et al., 2021). In particular, the ordering of the

multiple variables matters because any permutation of the ordering can lead to diﬀerent

prior distributions for the AR coeﬃcients. The prior distributions are ﬁrstly assigned to the

PARCOR coeﬃcients after making a transformation through the Cholesky decomposition.

When transforming back to the original model space, these priors are transformed to the

priors of the AR coeﬃcients. This transformation depends on the order of the variables in the

multivariate model. This diﬀerence in the prior distributions does not have a signiﬁcant eﬀect

33

on the time-invariant parameter models. However, it may show a more noticeable diﬀerence

in the time-varying parameter models when using diﬀerent ordering. In Simulation 1, we

see this phenomenon. However, in both our motivating data applications and in Primiceri

(2005), diﬀerent orders of the variables led to very similar results. Levy and Lopes (2021)

provide a comprehensive discussion on the ordering uncertainty and proposes two solutions:

DOS and DOA. We adopt both in the quarterly GDP data application to address the ordering

uncertainty and ﬁnd that it improves the forecast accuracy.

Acknowledgements

This research was partially supported by the U.S. National Science Foundation (NSF) under

NSF grant SES-1853096. This article is released to inform interested parties of ongoing

research and to encourage discussion. The views expressed on statistical issues are those

of the authors and not those of the NSF or U.S. Census Bureau. The authors thank Drs.

Matteson and Zhao for their assistance with the quarterly GDP data and California Wind

data, respectively.

A Algorithm for Fitting Multivariate Time Series

We summarize the algorithm of our approach to ﬁtting a TV-VAR model as follows:

• Step 1. Interlace the multivariate times series as in (1) into a periodic time series as

in (3).

• Step 2. Set up a value for order P and a set of values for γk,m, δk,m for m = 1, . . . , Mk,

k = 1, . . . , K, where Mk = kPmax + K − 1, as well as the initial values of parameters

at t = 0.

• Step 3. Repeat Step 4 for stage m = 1, . . . , Mk, k = 1, . . . , K.

34

• Step 4. Apply the sequential ﬁltering and smoothing algorithm to the prediction errors

of last stage, f (m−1)

k,t

and b(m−1)
k,t

to obtain α(m)

t = µ(m)

t,T and σ2(m)

t

= s(m)

t,T of the forward

and backward equations, and the forward and backward prediction errors, f (m)

k,t and

b(m)
k,t

for t = 1, . . . , T .

• Step 5. To compute the model selection criterion of TV-VAR(P ), collect the computed

parameters up to order kP + K − 1 for the kth series, k = 1, 2, . . . , K. Transform the

computed parameters to obtain the estimated values of the parameters {Φp,t} and {Σt}

in (1). Compute the criterion following Section 2.5. Pick the best order according to

the model selection criterion.

• Step 6. (Optional) Compute the spectrum and cross-spectrum based on the parameter

estimation following Section 3.1.

• Step 7. (Optional) Make h-step ahead forecasting following Section 2.6.

B Sequential Filtering and Smoothing Algorithm

Suppose we need to ﬁt (7) and (8) to estimate the PARCOR coeﬃcients and innovation

variance. Their posterior distributions can be obtained by following a sequential ﬁltering

and smoothing algorithm. The algorithm given here is for the forward autoregression case

as in (7). Filtering and smoothing algorithm can be obtained for the backward case in a

similar manner. For any series, any stage, we denote the posterior distribution at time t as

(αt|Dt) ∼ Tνt(µt, Ct) a multivariate T distribution with νt df, location parameter µt, and

scale matrix Ct, and (σ−2

t

|Dt) ∼ G(νt/2, κt/2), a gamma distribution with shape parameter

νt/2 and scale parameter κt/2. These parameters can be computed for all t using the ﬁltering

equations below. Note we use st = κt/νt to denote the usual point estimate of σ2

t . ft in the

35

equation is the forward prediction error. For t = 2, . . . , T , we have

µt = µt−1 + ztet,

Ct = (Rt − ztz(cid:48)

tqt)(st/st−1),

νt = δνt−1 + 1,

κt = δκt−1 + st−1e2

t /qt,

et = ft − z(cid:48)

t−1mt−1,

qt = z(cid:48)

t−1Rtz(cid:48)

t−1 + st−1,

and

where

and

zt = Rtft−1/qt,

Rt = Ct−1 + Gt,

Gt = Ct(1 − β)/β.

After the ﬁltering equations up to T , we compute the full marginal posterior distribution

(αt|DT ) ∼ Tνt(µt,T , Ct) and (σ−2

t

|DT ) ∼ G(νt,T /2, κt,T /2) through the smoothing equations

µt,T = (1 − β)µt + βµt+1,T

Ct,T = [(1 − β)Ct + β2Ct+1,T ](st,T /st)

νt,T = (1 − δ)νt + δνt+1,T

1/st,T = (1 − δ)/st + δst+1,T

and κt,T = νt,T st,T for t = T − 1, . . . , 1.

36

C Model Selection Criteria

Bayesian Information Criterion (BIC): For a TV-VAR(P ) model with parameters de-

noted as θ, BIC is deﬁned as

BIC(P ) = −2L + nΘlog(KT ).

BIC is computed for each of the ﬁtted models of order P = 1, . . . , Pmax to a K-dimensional

time series of length T . L is the log likelihood based on multivariate time-varying AR model

of order P as (1). nΘ is the number of parameters estimated in the initial state of the state

space model. In our case, nΘ = 2P K 2 + (K − 1)K, which is the total number of estimated

time-varying variables in all stages. We use BIC for model selection criterion throughout

this paper. BIC works well for identifying the correct order on simulated examples.

Deviance Information Criterion (DIC): With parameters denoted as θ and data de-

noted as y, the DIC is deﬁned as

DIC = −2logp(y|(cid:98)θBayes) + 2pDIC,

where (cid:98)θBayes is the Bayes estimator of θ and pDIC is the eﬀective number of parameters.

The eﬀective number of parameters is given by

pDIC = 2

(cid:105)
(cid:104)
logp(y|(cid:98)θBayes) − Epost(logp(y|θ))

,

where Epost(·) is the expectation under the posterior distribution. In our case, the terms

above are estimated through MC samples θ(s) as

(cid:34)

pDIC = 2

logp(y|(cid:98)θBayes) −

(cid:35)

(logp(y|θ(s)))

,

1
S

S
(cid:88)

s=1

where samples θ(s), s = 1, . . . , S, are generated from p(θ|y), the posterior distribution of θ

by the following steps:

37

1. generate samples {αt} from Tνt(µt, Ct) and samples {σ−2

t } from G(νt/2, κt/2) for t =

1, . . . , T as Section B;

2. transform them into TV-VAR parameters, {Φp,t} and {Σt}, by (5) and (6);

3. generate S sets of samples {θ(s) = (Φ(s)

t,p , Σ(s)

t ), s = 1, . . . , S}.

Widely Applicable Akaike Information Criterion (WAIC): WAIC is a generalized

version of AIC and is more appropriate for Bayesian hierarchical models (Watanabe, 2010).

For a model with parameters denoted as θ, considering data y = (y1, . . . , yT )(cid:48), the WAIC is

deﬁned as

where

W AIC = −2logp(y|(cid:98)θBayes) + 2pW AIC,

T
(cid:88)

pW AIC = 2

t=1

(log(Epostp(yt|θ) − Epost(logp(yt|θ))) .

WAIC is estimated by using MC samples from the S posterior draws θ(s) as

T
(cid:88)

(cid:98)pW AIC = 2

t=1

(cid:32)

log(

1
S

S
(cid:88)

s=1

p(yt|θ(s)) −

(cid:33)

(logp(yt|θ(s)))

.

1
S

S
(cid:88)

s=1

θ(s) is generated from p(θ|y), the posterior distribution of θ in the same way as DIC.

To achieve a best model selection, we ﬁrst search for an order which achieves the smallest

BIC, DIC, WAIC. If the numerical criteria, BIC, DIC, WAIC, do not agree with each other,

we use the visual scree plot to assist the model selection. In practice, for BCLF, BIC works

best for selecting the model order among the numerical criteria in most of the simulation

cases we conducted.

D Forecasting

We can make h-step ahead forecasting by following these steps.

38

• For stage m = 1, . . . , Mk and series k = 1, . . . , K, compute the h-step ahead pos-

terior predictive distribution of the PARCOR coeﬃcients following West and Har-

(α(m)

f,m,k+(T +h−1)K|DT ) ∼ N (µ(m)
f,m,k+(T +h−1)K and C (m)

rison (1997):

µf,m,k+(T −1)K(h) = µ(m)
with G(m)
f,m,k+T K = C (m)

k+(T +h−1)K(1 − β)/β.

f,m,k+(T −1)K(h), C (m)

f,m,k+(T −1)K(h)) where

f,m,k+(T −1)K(h) = C (m)

f,m,k+(T −1)K +hG(m)

f,m,k+T K

• For stage m = 1, . . . , Mk and series k = 1, . . . , K, draw J samples for each of the

h-step ahead of the AR coeﬃcients {a(Mk)

m,k+(T +h−1)K, m = 1, . . . , Mk} from the samples

of {α(m)

f,m,k+(T +h−1)K} and {α(m)

b,m,k+(T +h−1)K} for series k = 1, . . . , K.

• Transform the samples of {a(Mk)

m,k+(T +h−1)K, m = 1, . . . , Mk} into the samples of TV-VAR

parameters {Φp,T +h, p = 1, . . . , P }.

• The samples of the h-step ahead forecast is obtained as

x(j)
T +h =

P
(cid:88)

p=1

where x(j)

T +h−p = xT +h−p if h − p ≤ 0.

Φ(j)

p,T +hx(j)

T +h−p,

(10)

• We use the posterior mean of xT +h obtained through the samples in (10) as the h-step

ahead forecast.

39

References

Brockwell, P. J. and Davis, R. A. Time Series: Theory and Methods. Springer, second

edition (2009).

Del Negro, M. and Primiceri, G. E. “Time varying structural vector autoregressions and

monetary policy: a corrigendum.” The Review of Economic Studies, 82(4):1342–1345

(2015).

Fan, J. and Yao, Q. Nonlinear Time Series: Nonparametric and Parametric Methods.

Springer Science & Business Media (2008).

Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., and Rubin, D. B.

Bayesian Data Analysis. Chapman & Hall/CRC (2013).

Gersch, W. and Stone, D. “One channel at-a-time multichannel autoregressive modeling

of stationary and nonstationary time series.” In Bozdogan, H., Sclove, S. L., Gupta,

A. K., Haughton, D., Kitagawa, G., Ozaki, T., and Tanabe, K. (eds.), Proceedings of the

First US/Japan Conference on the Frontiers of Statistical Modeling: An Informational

Approach: Volume 3 Engineering and Scientiﬁc Applications, 165–192. Springer (1994).

—. “Multivariate autoregressive time semes modeling: one scalar autoregressive model at-

a-time.” Communications in Statistics-Theory and Methods, 24(11):2715–2733 (1995).

Guo, W. and Dai, M. “Multivariate time-dependent spectral analysis using Cholesky de-

composition.” Statistica Sinica, 16(3):825 (2006).

Hayes, M. H. Statistical Digital Signal Processing and Modeling. John Wiley & Sons (1996).

Huerta, G. and Lopes, H. F. “Bayesian forecasting and inference in latent structure for

40

the brazilian industrial production index.” Brazilian Review of Econometrics, 20(1):1–26

(2000).

Hunter, J., Burke, S. P., and Canepa, A. Multivariate Modelling of Non-Stationary Economic

Time Series. Springer (2017).

Kitagawa, G. Introduction to Time Series Modeling. Chapman & Hall/CRC (2010).

Kitagawa, G. and Gersch, W. Smoothness Priors Analysis of Time Series. Springer (1996).

Kowal, D. R., Matteson, D. S., and Ruppert, D. “A Bayesian multivariate functional dynamic

linear model.” Journal of the American Statistical Association, 112(518):733–744 (2017).

Levy, B. P. and Lopes, H. F. “Dynamic Ordering Learning in Multivariate Forecasting.”

arXiv preprint arXiv:2101.04164 (2021).

Lopes, H. F., McCulloch, R. E., and Tsay, R. S. “Parsimony inducing priors for large scale

state–space models.” Journal of Econometrics (2021).

Masry, E. “Multivariate local polynomial regression for time series: uniform strong consis-

tency and rates.” Journal of Time Series Analysis, 17(6):571–599 (1996).

Matteson, D. S. and Tsay, R. S. “Dynamic orthogonal components for multivariate time

series.” Journal of the American Statistical Association, 106(496):1450–1463 (2011).

Nakajima, J., Kasuya, M., and Watanabe, T. “Bayesian analysis of time-varying parameter

vector autoregressive model for the Japanese economy and monetary policy.” Journal of

the Japanese and International Economies, 25(3):225–245 (2011).

Nakajima, J. and West, M. “Bayesian analysis of latent threshold dynamic models.” Journal

of Business & Economic Statistics, 31(2):151–164 (2013).

41

Ombao, H., Raz, J., Von Sachs, R., and Malow, B. “Automatic statistical analysis of

bivariate nonstationary time series.” Journal of the American Statistical Association,

96(454):543–560 (2001).

Ombao, H., Von Sachs, R., and Guo, W. “SLEX analysis of multivariate nonstationary time

series.” Journal of the American Statistical Association, 100(470):519–531 (2005).

Pagano, M. “On periodic and multiple autoregressions.” The Annals of Statistics, 6(6):1310–

1317 (1978).

Primiceri, G. E. “Time varying structural vector autoregressions and monetary policy.” The

Review of Economic Studies, 72(3):821–852 (2005).

Sakai, H.

“Circular lattice ﬁltering using Pagano’s method.”

IEEE Transactions on

Acoustics, Speech, and Signal Processing, 30(2):279–287 (1982).

Shephard, N. Stochastic Volatility: Selected Readings. Oxford University Press on Demand

(2005).

Shumway, R. H. and Stoﬀer, D. S. Time Series Analysis and Its Applications (2nd ed).

Springer (2006).

Sui, Y. “Nonstationary Bayesian Time Series Models with Time-Varying Parameters and

Regime-Switching.” Ph.D. thesis, University of Missouri (2021).

Triantafyllopoulos, K. “Covariance estimation for multivariate conditionally Gaussian dy-

namic linear models.” Journal of Forecasting, 26(8):551–569 (2007).

Tsay, R. S. and Wood, D. MTS: All-Purpose Toolkit for Analyzing Multivariate Time Series

(MTS) and Estimating Multivariate Volatility Models (2021). R package version 1.0.3.

URL https://CRAN.R-project.org/package=MTS

42

Watanabe, S. “Asymptotic equivalence of Bayes cross validation and widely applicable

information criterion in singular learning theory.” Journal of Machine Learning Research,

11(Dec):3571–3594 (2010).

West, M. and Harrison, J. Bayesian Forecasting and Dynamic Models (2nd). Springer (1997).

Yang, W.-H., Holan, S. H., and Wikle, C. K. “Bayesian lattice ﬁlters for time–varying

autoregression and time–frequency analysis.” Bayesian Analysis, 11(4):977–1003 (2016).

Zhao, W. “Eﬃcient Analysis of Multiple and Multivariate Non-stationary Time Series in

the Partial Autocorrelation Domain.” Ph.D. thesis, UC Santa Cruz (2022).

Zhao, W. and Prado, R. “Eﬀcient Bayesian PARCOR approaches for dynamic modeling of

multivariate time series.” Journal of Time Series Analysis (2020).

Zhao, Z. Y., Xie, M., and West, M. “Dynamic dependence networks: Financial time series

forecasting and portfolio decisions.” Applied Stochastic Models in Business and Industry,

32(3):311–332 (2016).

43

