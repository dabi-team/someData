0
2
0
2

n
u
J

6
1

]

M
R
.
n
i
f
-
q
[

4
v
0
9
8
3
0
.
5
0
8
1
:
v
i
X
r
a

Improving Value-at-Risk prediction under
model uncertainty

Shige Peng

Institute of Mathematics
Shandong University

Shuzhen Yang

ZhongTai Securities Institute for Financial Studies
Shandong University

Jianfeng Yao

Department of Statistics and Actuarial Science
The University of Hong Kong

Correspondence:
Jianfeng Yao
Department of Statistics and Actuarial Science
The University of Hong Kong
Pokfulam Road
HONG KONG SAR
Email: jeffyao@hku.hk

1

 
 
 
 
 
 
Abstract

Several well-established benchmark predictors exist for Value-at-Risk
(VaR), a major instrument for ﬁnancial risk management. Hybrid methods
combining AR-GARCH ﬁltering with skewed-t residuals and the extreme
value theory-based approach are particularly recommended. This study in-
troduces yet another VaR predictor, G-VaR, which follows a novel method-
ology. Inspired by the recent mathematical theory of sublinear expectation,
G-VaR is built upon the concept of model uncertainty, which in the present
case signiﬁes that the inherent volatility of ﬁnancial returns cannot be char-
acterized by a single distribution but rather by inﬁnitely many statistical dis-
tributions. By considering the worst scenario among these potential distri-
butions, the G-VaR predictor is precisely identiﬁed. Extensive experiments
on both the NASDAQ Composite Index and S&P500 Index demonstrate the
excellent performance of the G-VaR predictor, which is superior to most
existing benchmark VaR predictors.

KEYWORDS: Empirical ﬁnance, G-normal distribution, Model uncertainty, Sub-
linear expectation, Value-at-Risk.

JEL Classiﬁcation: C58, G32.

1

Introduction

Since its birth at J.P. Morgan in the 1990s, value-at-risk (VaR) has become
one of the most used (if not THE most used) instruments for assessing downside
risk in ﬁnancial markets. Every unit of risk management in today’s ﬁnancial in-
dustry routinely implements several VaR indicators to monitor its business (Jorion,
2007). The regulatory authorities also incorporate VaR measures into their recom-
mendations to the banking industry (Basel Accords I-III), which has accelerated
the spread of VaR.

The success of VaR methodology is also backed up by a rich body of litera-
ture in which the methodology is carefully evaluated and discussed in diﬀerent
model settings and for diﬀerent markets and products. The literature on VaR
is voluminous and includes several specialized books. Also any textbook treat-
ing ﬁnancial econometrics or risk management will have a chapter dedicated to
VaR. For an up-to-date account of this literature, the reader is referred to the re-
cent review papers by Kuester et al. (2006), Jorion (2010), Abad et al. (2014),

2

Nadarajah and Chan (2016), and Zhang and Nadarajah (2017), among others. In
particular, Table 4 in Abad et al. (2014) lists as many as fourteen papers that sur-
vey and compare diﬀerent VaR methodologies through empirical studies. Further,
by focusing on univariate observations, Kuester et al. (2006) oﬀer a rich review
of mainstream VaR measures and provide an extensive empirical comparison of
those measures in terms of their prediction power using the daily NASDAQ Com-
posite Index. The general conclusion they draw (see also Abad et al., 2014) is that
whatever method is used for VaR modeling, the predictions are always improved,
most of the time considerably improved, by applying that method to residuals ﬁl-
tered by an AR-GARCH model instead of the original series (rt). For example,
one of the best performers is obtained by applying extreme value theory (EVT)
to the residuals of AR-GARCH ﬁt using skewed-t innovations (AR-GARCH St-
EVT). Kuester et al. (2006) conclude that, at least for the NASDAQ Composite
Index, “conditionally heteroskedastic models yield acceptable forecasts” and that
the conditional skewed-t (AR-GARCH-St) together with the conditional skewed-t
coupled with EVT (AR-GARCH-St-EVT) perform best in general.

In this paper, we present an entirely new type of VaR. Our methodology is
inspired by a rigorous mathematical theory called nonlinear expectation. The
theory of nonlinear expectation was originally introduced in Peng (2004, 2006,
2008, 2019). The part of the theory relevant to VaR prediction is detailed in the
appendix. When applied to analysis of a time-series of returns {rt}, the central
concept of nonlinear expectation theory is an inﬁnite family of distributions inher-
ent in the return series {rt}. Traditional econometric modeling commonly assumes
that returns, at least during certain time periods, obey one stochastic process gov-
erned by one stochastic-process model P0. The task of the econometrician is to
infer this unknown, but true, P0. The distribution can be parametric, as in an AR-
ARCH model (with skewed-t or normal innovations), or made up by a family of
conditional mixture distributions (see Section 2). It can also be fully nonparamet-
ric without any particular model speciﬁcation, as in the historical simulation (HS)
approach to VaR prediction. However, a unique stochastic model is assumed so
far for the returns {rt}. The point of view of nonlinear expectation theory is radi-
cally diﬀerent: instead of assuming the existence of one unique model P0, it views
returns as originating from a large number of diﬀerent models, say {Pθ}θ∈Θ, and
this family of potential models is indeed inﬁnite (here, Θ denotes some imprecise
index set). The rationale is that data under investigation such as return series are
of a complex nature such that no single stochastic model or distribution can serve
as a perfect model: model uncertainty has to be considered, and any statistical in-
ference has to take into account such uncertainty. We name this vision of complex

3

data and the implied methodology data analysis under model uncertainty.

The concept of model uncertainty, sometimes also referred to as model ambi-
guity, has taken a long time to emerge. An early attempt in this direction was made
in the area of robust statistics, where it was argued that a statistical procedure (e.g.
parameter estimation or hypothesis testing) can gain robustness by assuming that
the data follow not a single distribution but rather a family of distributions {Fθ}θ∈Θ
(see Huber, 1981; Walley, 1991). By allowing a variable range between two ex-
treme values σmin and σmax for volatility of a stock, Avellaneda et al. (1995) pre-
sented a model for pricing and hedging derivative securities and option portfolios.
When the volatility is unknown and takes value in some convex region that can
vary with the price process and time, Lyons (1995) introduced optimal and risk-
free strategies for intermediaries in such markets to meet their obligations. Peng
(1997) later proposed a formal mathematical approach to model uncertainty, with
a nonlinear expectation called g-expectation introduced to develop the concept of
mean uncertainty and its associated mathematical tools. The g-expectation con-
cept was then adopted by Chen and Epstein (2002) to describe the continuous-time
inter-temporal version of multiple-priors utility. In particular, they established a
separate premium for ambiguity on top of the traditional premium for risk. In
addition, Epstein and Ji (2013) formulated a model of utility in a continuous-time
framework that captures aversion to ambiguity about both the volatility and the
mean of returns via the theory of sublinear expectation (SLE). Note that sublinear
expectation is a useful form of nonlinear expectation reinforced by the addition
of a sub-addivity property. All of the above theories formalize an inherent fam-
ily of distributions involving a set of probability measures {Pθ}θ∈Θ, not just one
probability measure P0, that governs the statistical distributions of a dataset. In
related work, Artzner et al. (1999) proposed the concept of coherent risk mea-
sures, which focused on measurement of both market risks and nonmarket risks,
see also F¨ollmer and Schied (2011).

Although the vision of model uncertainty has been formalized through the
rigorous mathematical theory of SLE, its implications for real data analysis have
not been fully explored. Early work by Huber (Huber, 1981) studied the model
uncertainty in the area of robust statistics. Cont (2006) considered a quantitative
framework for deﬁning model uncertainty in option pricing models, and illus-
trated the diﬀerence between model uncertainty and the more common notion
of ”market risk” through examples. By distinguishing estimation risk and mis-
speciﬁcation risk, Kerkhof et al. (2010) proposed a procedure to take model risk
into account in the computation of capital reserves which can be used to address
Value-at-Risk and expected shortfall. To the best of our knowledge, the present

4

paper on VaR prediction constitutes the ﬁrst attempt at real-life data analysis un-
der SLE-based model uncertainty. The implementation of SLE theory herein leads
to a new type of VaR predictor called G-VaR. Loosely speaking, as long as VaR
prediction is concerned and to give model uncertainty in the form of an inﬁnite
family of probability models {Pθ}θ∈Θ, G-VaR concentrates on prediction under the
worst scenario among all potential models {Pθ}. Extensive empirical analyses
of two major market indexes, namely, the NASDAQ Composite Index and S&P
500 Index, establish the superiority of the new G-VaR predictions over several
benchmark VaR predictors that are among the best performers reported in Kuester
et al. (2006). The uniform superiority of G-VaR in these empirical studies is truly
astonishing. One a posteriori explanation is that these return data do have the
kind of complex nature that can be better understood through the lens of model
uncertainty that had led to the G-VaR predictor.

The remainder of the paper is organized as follows. Section 2 brieﬂy reviews
several benchmark predictors for the VaR of return series. Section 3 introduces
the concepts of distribution family as model uncertainty and G-normal distribu-
tion. Section 4 contains the main technical contribution of the paper. The new
VaR predictor, i.e. G-VaR, is introduced under model uncertainty and its theoret-
ical properties established. The implementation of G-VaR is presented in Sec-
tion 5, in which consistent estimators are proposed for the parameters involved in
the G-VaR predictor. Note that this implementation is far non trivial and Section 5
contains the main methodological contribution of the paper. Section 6 reports the
empirical results of the G-VaR predictor for the NASDAQ Composite Index and
S&P 500 Index, with extensive comparison made with the benchmark VaR pre-
dictors reviewed in Section 2, including the AR(1)-GARCH(1,1)-Normal, AR(1)-
GARCH(1,1)-Skewed-t and AR(1)-GARCH(1,1)-Skewed-t-EVT predictors. Fi-
nally, Section 7 concludes.

2 A brief review of benchmark predictors for VaR

Before introducing our new methodology, we ﬁrst give a brief review of sev-
eral of the well-documented VaR predictors described in Kuester et al. (2006), as
they will serve as benchmarks for comparison with the new VaR predictor pro-
posed herein. As historical references for these VaR measures can be found in the
earlier review paper, only a few key references are indicated in this brief review.
Here, (rt) denotes a univariate time-series for which VaR prediction is required.
In most common situations, the series represents the daily returns of a market, or

5

price of a stock or product.

(i) The Historical Simulation method. This traditional method uses sample quan-
tiles from historical data to predict VaR. The method is well documented in classic
books such as Dowd (2002) and Christoﬀersen (2003).

A variant of HS is ﬁltered historical simulation (FHS), whereby the sample
quantiles are calculated from ﬁltered residuals using a parametric model such as
the AR-GARCH model. Classical references on FHS include Barone-Adesi et al.
(1999, 2002).

(ii) The method of Peaks over Thresholds using EVT. EVT provides a method
for estimating the high upper quantiles of a variable X, say quantiles xα such
that F X(x) = P(X > xα) = α for some small tail probability α < 0.1. From
sample data, one obtains an empirical quantile u, the threshold, such that P(X >
u) ≈ 0.1. Also those values above threshold u provide a sample for the “survival
distribution” (X|X > u). EVT ensures that for a large enough u, the survival
distribution can be approximated by a generalized Pareto distribution (GPD) that
depends on a pair of shape-scale parameters (β, ξ) (Pickands, 1975; Embrechts
et al., 1997). This GPD is thus identiﬁed using the sample, which leads to an
estimate for the initial tail probability F X(xα) for all xα > u.

For VaR prediction, the above procedure is applied to the available data {Xs =
−rs, s < t} to ﬁnd the corresponding upper quantile xα. The negative operation is
used here, as EVT considers upper quantiles whereas VaR targets lower quantiles.
Then, the prediction for VaR is (cid:100)VaRα(t) = −xα for all risk levels α < 0.1. Em-
pirical studies on VaR predictions using EVT can be found in McNeil and Frey
(2000) and Kuester et al. (2006).

(iii) The method by AR-GARCH ﬁltering (AR-GARCH). Here the returns are
assumed to follow a mean-variance decomposition of type

rt = µt + σtzt,
where the mean process (µt) follows an AR model (or, more generally, an ARMA
model) and the residual is modeled by a GARCH process (Bollerslev, 1986) with
independent and identically distributed (i.i.d.) innovations (zt). Common choices
for the distribution fz of the innovations (zt) are (i) standard normals, (ii) Student’s
t-distributions, and (iii) skewed t-distributions.

(2.1)

Once the model (2.1) is ﬁtted, a parametric estimate of the distribution fz is
obtained, say ˆfz, which leads to an estimated quantile function, say ˆQα(z) (for any
given risk level α). A level-α VaR prediction at time t is thus deﬁned as

(cid:100)VaRα(t) = −

(cid:111)
(cid:110)
ˆµt + ˆσt ˆQα(z)

.

6

(iv) The method of Conditional Mixture Modeling.
In this approach, conditional
to the information set Ft−1 at time t, the return rt follows a mixture distribution
with n components, each of which has a constant mean parameter µ j (1 ≤ j ≤ n)
and time-varying volatility (variance) parameter σ2
j,t (1 ≤ j ≤ n). Moreover, the
= (σ2
1,t, . . . , σ2
n-dimensional volatility process σ2
n,t) obeys a multidimensional
t
GARCH equation. Here, the distributions of the mixture components are usually
taken to be normal distributions or generalized exponential distributions (GED).
More references to this approach can be found in Haas et al. (2004).

(v) The method by Quantile Regression. Here a regression model is used to pre-
dict the VaR at time t using some predictable covariates Xt ∈ Ft−1; see Koenker
and Bassett (1978) and Chernozhukov and Umantsev (2001). Later, Engle and
Manganelli (2004) proposed CAViaR models, where the quantiles (or VaRs) fol-
low an autoregressive model without any exogeneous covariate.

3 G-normal distribution

When measuring the risk in a ﬁnancial time-series {Xt}0≤t≤T , it is commonly
assumed that the data follow a certain distribution F0, and the aim is to estimate
or approximate the “true” distribution F0 or some of its characteristics such as
VaR. As we saw in the survey in Section 2, many diﬀerent VaR measures exist
in the literature, including HS, EVT-VaR and their AR-GARCH-ﬁltered variants.
Now we view the data {Xt}0≤t≤T as possessing a complex nature governed not by
one distribution F0 but rather by an inﬁnite family of distributions {Fθ}θ∈Θ, each
of them capturing some properties of the data.

How can the VaR concept be extended to a new framework in which an in-
ﬁnite family of (unknown) distributions governs the data? This paper provides
an answer to this general question. To proceed, some meaningful characteristics
of the family {Fθ}θ∈Θ need to be identiﬁed. Consider the simplest features of the
distributions, namely, their mean µ and variance σ2. In general, these features are
time-varying. Here, we consider a simple case, where mean µ is constant (inde-
pendent of time) and variance σ2 is time-varying within some interval [σ2, σ2].
In the following, the interval [σ2, σ2] is used to characterize the unknown fam-
ily of distributions {Fθ}θ∈Θ. For a given canonical probability space (Ω, F , P),
Ω = C([0, T ]), and Brownian motion {Bt}0≤t≤T , we deﬁne the probability mea-
sures Pθ as follows. For A ∈ F ,

Pθ(A) = P ◦ Y −1

θ (A) = P(Yθ ∈ A),

7

where

Yθ(·) =

(cid:90) (cid:5)

0

θsdBs,

θ ∈ Θ = L2

F (Ω × [0, T ], [σ, σ]),

where Θ is the set of all progressively measurable processes taking value on [σ, σ]
The collection of Pθs is denoted as {Pθ}θ∈Θ. Let the mean µ be 0 and the distribu-
tion of {Xt}0≤t≤T under Pθ be Fθ. Thus, this inﬁnite family of stochastic process
distributions {Fθ}θ∈Θ is chosen as the family governing the dataset {Xt}0≤t≤T . In
this paper, we use the so-called G-normal distribution N(0, [σ2, σ2]) to represent
the family {Fθ}θ∈Θ.

Precisely, the expectations of data {Xt}0≤t≤T under {Pθ}θ∈Θ are

(cid:90)

Eθ[φ(Xt)] =

φ(x)dFθ(x),

(3.1)

R
where φ ∈ Cl.Lip(R, R) is a test function describing the statistic of the data Xt that
we are interested in. With VaR prediction in view, we concentrate our analysis on
the worst-case expectation of Xt under {Pθ}θ∈Θ, that is,

Eθ[φ(Xt)].

E[φ(Xt)] = sup
θ∈Θ
In general, it is diﬃcult to determine worst-case expectation E[φ(Xt)]. There is,
however, a situation in which it can be explicitly determined, as shown below.
Assumption 3.1. Suppose that {Xt}0<t<T satisﬁes the following stochastic diﬀer-
ential equation,

(3.2)

under Pθ, θ ∈ Θ = L2

F (Ω × [0, T ], [σ, σ]).

dXt = θtdBt, X0 = x,

For a given φ, we can prove that u(t, x) = E[φ(Xt)] satisﬁes the following

partial diﬀerential equation (PDE),

∂tu(t, x) − G(∂2

xxu) = 0, t ≥ 0, x ∈ R,

(3.3)

where the function G(·) is deﬁned as
σ2a+ − σ2a−(cid:17)
(cid:16)
G(a) = 1
2

,

a+ = max(a, 0),

and a− = max(−a, 0).

(3.4)

If, in addition, φ(·) is convex on R, then the following explicit solution exists for
the equation (3.3):

u(t, x) =

(cid:90) x

−∞

φ(y)

(cid:112)

1
2πtσ2

exp(

y2
2tσ2 )dy.

8

In this case, we can see that the convex function u(t, x) will reach the maximum at
parameter σ. Similarly, if φ(·) is concave on R, then the explicit solution becomes

u(t, x) =

(cid:90) x

−∞

φ(y)

(cid:112)

1

2πtσ2

exp(

y2
2tσ2 )dy.

As a time-series of returns {Xt}0≤t≤T is typically centered whereas its volatil-
ity (variance) is time-varying, we will hereafter assume that it satisﬁes Assump-
tion 3.1 under model uncertainty {Pθ}θ∈Θ and follows a G-normal distribution
N(0, [σ2, σ2]) (the reader is reminded that this is not a classical probability distri-
bution). The deﬁnitions of maximal distribution and unbiased estimator are given
as follows:

Deﬁnition 3.1. (Maximal distribution) A random variable η on a sublinear expec-
tation space (Ω, H, E) is called maximally distributed if there exists an interval
[µ, µ] ⊂ R such that

E[φ(η)] = max
y∈[µ,µ]

φ(y), ∀φ ∈ Cl.Lip(R).

Deﬁnition 3.2. Let X1, · · · , Xn be i.i.d. sample (under SLE) of size n from the
maximal distribution with interval [µ, µ]. We say f (X1, · · · , Xn) is an unbiased
estimator of µ or µ if E[ f (X1, · · · , Xn)] = µ or E[ f (X1, · · · , Xn)] = µ, respectively.

4 G-VaR: a new VaR approach under model uncer-

tainty

First recall that, given α ∈ (0, 1), the VaRα at the risk level α of a ﬁnancial

asset X is the negative of the level-α quantile of X; that is

VaRα(X) = − inf{x : F(x) > α},

(4.1)

where F(x) = P(X ≤ x) is the cumulative distribution function of X.

4.1 Robust VaR

Consider a risky position X under model uncertainty represented by a family

of distributions {Fθ(x)}θ∈Θ. The VaR of X under each Fθ is

VaRθ

α(X) = − inf{x : Fθ(x) > α}.

9

Under the distribution family considered here, it is important to design a VaR
measure that can protect itself against risk. Note that risk here takes a quite general
form; that is, no speciﬁc form or prior information is available on this family of
distributions. This generality is aligned with real market situations in which risk
factors are always diﬃcult, and perhaps impossible, to capture precisely. Hence,
any particular form or modeling of the sources of these risks could be mislead-
ing. Accordingly, it becomes natural to consider a worst-case scenario for VaR.
Formally, the worst-case VaR of X is here deﬁned as

VaR∗

α(X) := sup
θ∈Θ

VaRθ

α(X).

(4.2)

In the empirical study in Section 6, it will be shown that, despite its conservative
spirit, consideration of a worst-case scenario, allows the new VaR to capture the
risks in asset returns very eﬃciently.

The worst-case VaR (4.2) has several simple properties. Let

ˆF(x) := sup
θ∈Θ

Fθ(x).

(4.3)

For each θ, we have

VaRθ

α(X) ≤ − inf{x :

ˆF(x) > α} =: VaR ˆF

α (X),

such that VaR∗

α(X) ≤ VaR ˆF

α (X).

Remark 4.1. It is clear that ˆF is a right continuous function.
{Fθ}θ∈Θ is weakly compact,then it is easy to prove that

If, in addition,

ˆF(x) = 0,

and

lim
x→−∞

ˆF(x) = 1.

lim
x→∞

Thus in this case, ˆF is still a probability distribution function.

Proposition 4.1. Given a risky position X and a family of distributions {Fθ(x)}θ∈Θ
that is weakly compact. Then,

VaR∗

α(X) := sup
θ∈Θ

VaRθ

α(X) = VaR ˆF

α (X).

α(X) ≤ VaR ˆF
Proof. It is clear that VaR∗
suﬃces to ﬁnd an ˜F ∈ {Fθ(x)}θ∈Θ such that

α (X). To prove the reverse inequality, it

VaR ˆF

α (X) = VaR ˜F

α (X).

10

Because ˆF(x) is a right continuous non-decreasing function, we can ﬁnd an xα ∈
(−∞, ∞) such that

ˆF(xα) ≥ α > ˆF(x), for each x < xα.

i=1 be a subsequence of {Fθ}θ∈Θ such that Fθi(xα) → ˆF(xα). Because
}∞
k=1 such that

Let {Fθi}∞
{Fθ(x)}θ∈Θ is weakly compact, there exists a subsequence of {Fθik
{Fθik

k=1 weakly converges to ˜F ∈ {Fθ(x)}θ∈Θ. From
}∞

ˆF(xα) = lim
k→∞

Fθik

(xα) ≤ ˜F(xα) ≤ ˆF(xα),

it follows that ˜F(xα) = ˆF(xα). Further, for each x < xα, ˜F(x) ≤ ˆF(x) < ˆF(xα),
namely,

−VaR ˆF

α (X) = xα = inf{x :

˜F(x) > α} = −VaR ˆF

α (X).

The proof is complete.

4.2 G-VaR

(cid:3)

Based on Proposition 4.1, we now introduce the concept of G-VaR under the
family of distributions {Fθ}θ∈Θ for a risky asset X that follows a G-normal distribu-
tion N(0, [σ2, σ2]) depending on two positive parameters (σ, σ). More precisely,
G-VaR is deﬁned by replacing the classical distribution function F(x) in (4.1) with
G-expectation E[1X≤x], that is,

G-VaRα(X) := − inf{x ∈ R : E[1X≤x] > α}.

(4.4)

Note that if model uncertainty were absent, the family {Fθ}θ∈θ would reduce to a
single distribution F, and G-VaR would coincide with the traditional VaR in (4.1).
Furthermore, as X follows a G-normal distribution, we have

ˆF(x) = E[1X≤x] = u(t, x)|t=1,

where u is the solution to the nonlinear heat equation (3.3), with Cauchy initial
condition

u(t, x) = 1(0,∞)(x).

lim
t→0

(4.5)

By Proposition A.1, function ˆF has the following closed-form expressions.
(cid:34)
e− y2

2σ2 I(y ≤ 0) + e

2σ2 I(y > 0)

ˆF(x) =

(cid:90) x

dy,

− y2

√

√

(cid:35)

2
(σ + σ)

−∞

π

11

where I(A) denotes the indicator function of a set A. Moreover, evaluating the
integral leads to the following more explicit form of the function;

ˆF(x) = 2σ
σ + σ

Φ(

x
σ

) I(x ≤ 0) +

(cid:40)

1 −

2σ
σ + σ

Φ(−

(cid:41)
)

x
σ

I(x > 0),

(4.6)

where Φ denotes the distribution function of the standard normal. This G-normal
2
π (σ − σ), and a negative skew. As an exam-
distribution has a negative mean
ple, the G-normal density function with parameters (σ, σ) = (0.5, 1) is compared
to the standard normal density in Figure 1. Furthermore, as ˆF is monotonically
increasing, the G-VaR in (4.4) is equal to

(cid:113)

G-VaRα(X) = − ˆF−1(α).

(4.7)

Insert Figure 1 around here

4.3 A simple interpretation of G-VaR and some general com-

ments

Although the G-VaR is derived through the fairly sophisticated theory of SLE
and related G-normal distribution, its ﬁnal implementation shown in equations
(4.6) and (4.7) has a simple interpretation. First of all, a G-normal distribution we
assumed for the asset X can be intuitively related to an inﬁnite family of normal
distributions {N(0, σ2) : σ2 ∈ [σ2, σ2]}. Therefore the volatility interval [σ2, σ2]
corresponds to the model uncertainty considered here. As G-VaR is positive (α <
0.5), (4.7) can be rewritten as a normal VaR:

G-VaRα(X) = − ˜σΦ−1( ˜α),

(4.8)

with

σ + σ
2σ
We will call ˜σ and ˜α adjusted volatility and adjusted risk level, respectively.

(cid:17)
(cid:16)
1 + σ/σ

α = 1
2

˜σ = σ,

˜α =

α.

Therefore in absence of model uncertainty, one has ˜σ = σ = σ and ˜α = α,
the adjusted parameters coincide with the original ones and G-VaR coincides with
the traditional normal VaR. Otherwise, model uncertainty is characterized by the
interval [σ, σ] and the G-VaR becomes more conservative with a higher value, as
it should be, under the joint eﬀect of a larger value for the adjusted volatility ˜σ

12

and a smaller value of adjusted risk level ˜α < α. The degree of conservatism is
controlled by the two volatility parameters {σ, σ}: larger model uncertainty leads
to more conservative G-VaR. Note that this property of G-VaR is intuitive given
that VaR can be informally viewed as the maximum loss over a given period (after
excluding a given fraction of worst outcomes)1.

In Section 5, we will show how these parameters are estimated from return
data where a data-adaptive window W0 will eventually determine the underlying
volatility parameters (σ, σ) for a given risk level parameter α.

On a more methodological issue, one may ask whether it is reasonable to fo-
cus on the worst-case VaR among a family of distributions as we proposed in this
study. To address the question, we think that given the inherent model uncer-
tainty in ﬁnancial markets, a relevant question is to seek for a ”best” aggregation
of analyses from diﬀerent models. Our approach can be justiﬁed in two ways.
Firstly from a theoretical perspective, the theory of sublinear expectation provides
a rigourous derivation of the G-VaR under the worst-case scenario. Second, the
data analyses in Section 6 show that G-VaR empirically perform well in compari-
son to existing benchmark VaR predictors.

Indeed one can at some high level view G-VaR as a particular aggregation
method from the inﬁnite normal models {N(0, σ2) : σ2 ∈ [σ2, σ2]}. It is thus
interesting to ask “whether there are other aggregation mechanisms that would be
less conservative but still achieve a low number of violations”2. As the question
is fairly general, it seems diﬃcult to address it with full precision. Instead we
can here propose a particular comparison with a recent method for aggregation of
misspeciﬁed models proposed in Gospodinov and Maasoumi (2018). The paper
proposed a generalized aggregation approach for model averaging and applied it
to asset pricing. This method applies to a ﬁnite number of “misspeciﬁed models”
for aggregation. Note that, we deﬁne the G-VaR model via a family of distribu-
tions Fθ(·), θ ∈ L2(Ω × [0, T ], [σ2, σ2]) which are related to an inﬁnite family
of normal distributions {N(0, σ2) : σ2 ∈ [σ2, σ2]}. It is thus natural to consider
the averaging aggregation method for a ﬁnite number, say m, of normal distribu-
i ), where σi ∈ [σ, σ], i = 1, 2, · · · , m. Let Fi(·) be the cumulative
tions N(0, σ2
distribution function (c.d.f.) of the normal distribution N(0, σ2
i ) (1 ≤ i ≤ m). Im-
plementing the averaging aggregation mechanism in Gospodinov and Maasoumi

1The authors thank a referee who recommended this valuable interpretation of G-VaR.
2The authors are grateful to a referee who suggested this discussion with other aggregation

methods.

13

(2018) to VaR amounts to consider a c.d.f. of the form

˜Fω(x) =

(cid:20) m(cid:88)

i=1

ωi(Fi(x))p

(cid:21)1/p

,

x ∈ R,

(4.9)

where the weights ω = (ω1, ω2, · · · , ωm) satisfy (cid:80)m
i=1 ωi = 1, ωi ≥ 0 and p > 0 is
some “shape” parameter. Let F0(·) and Fm+1(·) be the c.d.f. of the two boundary
normal distributions N(0, σ2) and N(0, σ2), respectively. If x < 0, we have

F0(x) ≤ Fi(x) ≤ Fm+1(x),

i = 1, 2, · · · , m,

and thus

F0(x) ≤ ˜Fω(x) ≤ Fm+1(x).

For any given risk α < 0.5 and risky position X, it follows that,

− ˜F−1

ω (α) ≤ −F−1

m+1(α) ≤ G-VaRα(X),

ω (·) and F−1

where ˜F−1
m+1(·) are the inverse functions of ˜Fω(·) and Fm+1(·), respec-
tively. These results show that this particular averaging aggregation method leads
to a less conservative VaR, but with a higher average number of violations than
the G-VaR. Note that the comparison here is quite particular and the averaging ag-
gregation method is limited to a ﬁnite number of normal distributions. Therefore,
we still do not know whether there exists any other aggregation method for the
VaR that is less conservative than G-VaR but with a lower number of violations.

5

Implementation of G-VaR

In implementing G-VaR (4.4), the main task is to estimate the parameters of
the underlying G-normal distributions. Let {Xt}0≤t≤T be a return time-series from
a risky asset. At each time t, the goal is to forecast the VaR of Xt+1 at a given
level α using the history of available values {Xs}0≤s≤t. In the following, let window
W be the length of the trading days, which is used to estimate the parameters
(σ2, σ2). To forecast the VaR of Xt+1 in the G-VaR model, the data {Xs+1}t
t−W,
i.e., the history of length W before time t, are assumed to be independent and
identically distributed (i.i.d.) with a G-normal distribution, N(0, [σ2
t ]). It is
important to remind the reader that the concepts of independence and distribution
equality used here are not the classical ones but those under the theory of SLE
E[·] := supθ∈Θ Eθ[·]. The appendix provides a detailed introduction to these new

t , σ2

14

concepts. Brieﬂy, under SLE, two random variables Y1 and Y2 are identically
distributed if, for φ ∈ Cl.Lip(R),

E[φ(Y1)] = E[φ(Y2)].

A random variable Y2 is said to be independent of Y1 if, for each ψ ∈ Cl.Lip(R × R),
we have

E[ψ(Y1, Y2)] = E[E[ψ(y1, Y2)]y1=Y1].
Note the ordering of this independence: the fact that Y2 is independent of Y1 does
not imply that Y1 is independent of Y2. In general, we say that Yn is independent
of (Y1, · · · , Yn−1), if

E[φ(Y1, · · · , Yn−1, Yn)] = E[E[φ(y1, · · · , yn−1, Yn)]y1=Y1,··· ,yn−1=Yn−1],

for any φ ∈ Cl.Lip(Rn).

Theorem 24 in Jin and Peng (2016) shows that if X1, · · · , Xn form an i.i.d.
sample of size n from a maximal distribution with parameters (µ, µ), where the
i.i.d. is under SLE, then

µ ≤ min{X1, · · · , Xn} ≤ max{X1, · · · , Xn} ≤ µ.

Moreover,

ˆµ = max{X1, · · · , Xn}

is the largest unbiased estimator for the upper mean µ, and

ˆµ = min{X1, · · · , Xn}

is the smallest unbiased estimator for the lower mean µ. This estimation method
is called “Max-Mean calculation” in Peng (2017).
Precisely, we assume that Xt+1 follows N(0, [σ2

t ]), t > 0. For each ﬁxed ¯t,
¯t and σ2
the data {X¯t−s}0≤s≤W−1 are used to estimate the two parameters σ2
¯t for the
forecast of the VaR of X¯t+1. Let W0 ≤ W be the window width. The following
moving window approach is then employed. For each time s, let

t , σ2

ˆσ2

s,W0

= ˆσ2

s,W0(Xs−W0+1, · · · , Xs) = 1
W0

W0(cid:88)

j=1

X2

s− j+1

15

be the sample variance from the sample (Xs−W0+1, . . . , Xs), that is, the history of
length W0 before time s. Let k = (cid:98) W
(cid:99) be the largest integer satisfying kW0 ≤ W.
W0
Deﬁne

2
ˆσ
¯t,k
ˆσ2
¯t,k
2
ˆσ
¯t,W0
ˆσ2

¯t,W0

= max{ ˆσ2
= min{ ˆσ2

¯t−s,W0

¯t−s,W0

: s = 0, W0, 2W0, · · · , (k − 1)W0},
: s = 0, W0, 2W0, · · · , (k − 1)W0},

= max{ ˆσ2
= min{ ˆσ2

¯t−s,W0

¯t−s,W0

: 0 ≤ s ≤ W − W0},
: 0 ≤ s ≤ W − W0}.

Peng (2019) shows that the quadratic variation process of a G-Brownian motion
follows a maximal distribution (see page 60 of the reference). Thus, the quadratic
variation (cid:104)X(cid:105)t+1 follows a maximal distribution with interval [σ2
t ]. By Theorem
2
24 of Jin and Peng (2016), ˆσ
¯t,k is the largest unbiased estimator for the upper mean
σ2
¯t , and ˆσ2
¯t . In addition,
2
ˆσ
¯t,k and ˆσ2

¯t,k is the smallest unbiased estimator for the lower mean σ2
¯t,k converge to σ2

¯t as W → ∞, respectively . Also note that

¯t and σ2

t , σ2

¯t ≤ ˆσ2
σ2

¯t,W0

≤ ˆσ2

¯t,k ≤ ˆσ

2

¯t,k ≤ ˆσ

2
¯t,W0

≤ σ2
¯t ,

converge to σ2
to estimate σ2

¯t and σ2
¯t , and σ2

¯t as W → ∞. These shows that we can
¯t , under the given length of W historical

¯t,W0 and ˆσ2
¯t,W0 and ˆσ2

2
thus ˆσ
2
use ˆσ
data and W0.3

¯t,W0

¯t,W0

In summary, at a given time ¯t + 1, where a VaR forecast is required, by ac-
knowledging model uncertainty in the historical data of length W, {Xt}¯t−W<t≤¯t, X¯t+1
follows the G-normal distribution N(0, [σ2
¯t ]). Moreover, the two parameters
2
¯t and σ2
σ2
¯t,W0, respec-
tively. Consequently, by (4.7), the ﬁnal G-VaR estimate for the VaR of X¯t+1 at
level α is

¯t can be well approximated by the estimators ˆσ2

and ˆσ

¯t , σ2

¯t,W0

G-VaRW0

α,¯t (X¯t+1) = −

ˆFW0
¯t

(cid:110)

(cid:111)−1

(α),

(5.1)

where

ˆFW0
¯t

(x) =

2 ˆσ¯t,W0

ˆσ¯t,W0

+ ˆσ¯t,W0

Φ(

x
ˆσ¯t,W0

) I(x ≤ 0)+



1 −


2 ˆσ¯t,W0

ˆσ¯t,W0

+ ˆσ¯t,W0

Φ(−



)


x
ˆσ¯t,W0

I(x > 0).

(5.2)

3 Fang et al. (2019) provide a convergence rate for these estimators under sublinear expectation.

16

2
Note that, for a given W and α, we obtain diﬀerent ˆσ

depending
on W0. Thus, W0 can be interpreted as a measure of distribution uncertainty.
This parameter W0 plays a fundamental role in our analysis and we formalize
its function in the following condition.

¯t,W0 and ˆσ2

¯t,W0

Condition 5.1. The series of returns {Xt}0≤t≤T has the property that for given win-
dow W and risk level α, there exists a window size 1 ≤ W0 ≤ W such that

lim
n→∞

1
n − W

n(cid:88)

¯t=W

I(X¯t+1 < −G-VaRW0

α,¯t (X¯t+1)) = α.

When Condition 5.1 is satisﬁed, we say that the return series has an adaptive
window W0 for a given pair (α, W). The condition thus guarantees coherence
between the empirical percentages of violations and G-VaR measure G-VaRW0
α,¯t in
(5.1) for the entire dataset {Xt}1≤t≤T with historical window size W and estimation
window size W0. Based on a large amount of data analysis, Condition 5.1 appears
fairly satisﬁed in many practical situations.

As noted earlier, this paper assumes that the observations are described by
inﬁnitely many models (or distributions) rather than a single model. Using the
SLE theory and adopting a worst-case scenario, the VaR at a given risk level α
and time t can be evaluated through a G-normal distribution N(0, [σ2, σ2]). The
parameter W0 can be interpreted as the time duration for which this worst-case
scenario best ﬁts the returns data. Moreover, as will be conﬁrmed by the experi-
ments in Section 6.3, this parameter depends on both the risk level α and historical
window size W. For example, at higher conﬁdence levels (lower levels of α), a
higher degree of conservatism is reached by a lower value of W0, which gener-
ates a greater volatility interval [σ2, σ2].4 Therefore, in real data analysis, such
as that in Section 6, for a given pair (W, α), we ﬁrst check whether an adaptive
window size W0 exists, see Condition 5.1. G-VaR forecasts are possible only after
ﬁnding such W0. Anticipating the empirical study in Section 6, we will show that
for the NASDAQ Composite Index and S&P500 Index, an adaptive window W0
can indeed be found for a wide range of risk levels α. However, for the CSI300
Index, which we also analyzed, no adaptive window size W0 can be found for a
reasonable historical window size W and risk level α > 5%. For a given risk level

4It has been reported in the literature that the parameters of a VaR model can depend on the
risk level α. For example, Kuester et al. (2006) observed that the normality assumption on the data
“might have some merit for larger values of α,” but is still not adequate for a 5% risk level (see the
second paragraph on page 76 of the reference).

17

α, as discussed in Section 4.3, G-VaRα(X) is equivalent to a normal VaR with an
adjusted variance parameter ˜σ2 and downward adjusted risk level 0.5α < ˜α ≤ α.
These results indicate that the VaR under normal distribution N(0, σ2) within the
risk level parameters interval [0.5α, α] cannot cover the risk of the CSI300 Index
when α > 5%. This negative result can be interpreted as that
the model uncer-
tainty in CSI300 Index might be beyond the range that can be captured by the
proposed G-VaR.

6 Empirical results of G-VaR

In this section, the G-VaR forecasts are evaluated for the NASDAQ Composite
Index and S&P 500 Index.5 Both indexes comprise daily closing levels. The main
steps are as follows.

Step 1 - data preparation: The NASDAQ Composite Index is denoted by {Z1,t},
running from February 8,1971 to June 22, 2001, with a total of N = 7675 ob-
servations of percentages. The S&P 500 Index is denoted by {Z2,t}, running from
January 3, 2000 to February 7, 2018, with a total of N = 4550 observations. Their
daily log-returns are

ri,t = 100(ln Zi,t − ln Zi,t−1),

i = 1, 2.

Kuester et al. (2006) found that when using a historical window W = 1000, the
best VaR predictions for the NASDAQ index are obtained by AR-GARCH ﬁltered
modeling such as the recommended AR-GARCH-Skewed-t or AR-GARCH-Skewed-
t-EVT models. The G-VaR predictor proposed in this paper is compared with
these two benchmarks, as well as with a more traditional AR-GARCH-Normal
predictor using standard normals for the ﬁltered residuals.

Step 2 - AR(1) ﬁltering: To carry out the G-VaR prediction, we ﬁrst ﬁlter the data
with the following AR(1) process; that is, the series ri,t, i = 1, 2 satisfy the model
equations

ri,t = airi,t−1 + (cid:15)i

(6.1)

where the (cid:15)i follow G-normal distributions N(0, [σ2

i , σ2

i ]), i = 1, 2, respectively.

5Data are downloaded from https://ﬁnance.yahoo.com/lookup. Recall that the two indexes are
market value-weighted portfolios comprising more than 5000 and 500 selected stocks, respec-
tively.

18

Step 3 - selection of historical and estimation window lengths W and W0: The
implementation of the G-VaR in Section 5 requires the values of the two window
lengths W and W0 for a given risk level α. Note that, in our G-VaR model, W0
is dependent on α and W. Similarly to Kuester et al. (2006), we consider three
historical windows, W=1000, 500, and 250. The corresponding values of W0 are
selected empirically to ensure that Condition 5.1 holds.

6.1 NASDAQ Composite Index

We ﬁrst compare the G-VaR model with the AR(1)-GARCH(1,1)-Normal,
AR(1)-GARCH(1,1)-Skewed-t, and AR(1)-GARCH(1,1)-Skewed-t-EVT VaR mod-
els. For given windows W=1000, 500, and 250, we show how to determine a win-
dow W0 that satisﬁes Condition 5.1. For example, for a given W = 1000, α = 0.01,
and time point ¯t, we calculate the G-VaR of r1,¯t ( NASDAQ return) with diﬀerent
W0 ≤ W. Then, we choose the W0 that satisﬁes

lim
n→∞

1
n − W

n(cid:88)

¯t=W

I(r1,¯t+1 < −G-VaRW0

α,¯t (r1,¯t+1)) = 0.01.

Note that the above percentage is the violation rate of r1,t under the G-VaR model
from time W + 1 to n + 1, hereafter denoted as %Viol(n).

Figure 2 plots the evolution of %Viol(n) as time n varies. Here, α = 0.01
is used, but the ﬁndings are similar for other values of α. For all window sizes
W = 1000, 500, and 250, we ﬁnd that when 3000 ≤ n − W, the violation rate
becomes close to the target α = 0.01. All three cases use a well-calibrated value
of W0 = 350, 120, 75. In practice, as done here for the NASDAQ Index, W0
has to be calibrated, and, once ﬁxed, it is kept to forecast future G-VaR values.
Condition 5.1 technically guarantees the existence of such a converging window
size W0. Table 1 presents the summary statistics for the %Viol rates over the
converging period 3000 < n − W.

Insert Table 1 around here

Insert Figure 2 around here

To assess the predictive performance of the models under consideration, we
follow the test of unconditional coverage, or the binomial test (Kuester et al.,

19

2006). This is in fact a likelihood ratio test for a Bernoulli trial in which the null
trial success probability is equal to α. More precisely, let ˆα = m1/(m0 + m1) be
the sample violation rate %Viol, where m1 is the sample number of violations,
and the total number of observations is m0 + m1 = T − W. Using the well-known
asymptotic χ2(1) distribution, the p-value of the test is

(cid:32)

LRuc = P

χ2(1) > 2m1

ˆα
α

+ 2m0

(cid:33)

.

1 − ˆα
1 − α

Table 2 gives the empirical values of the statistics %Viol, LRuc, 100VaR for the
G-VaR with n = T , W = 1000, and α = 0.01, 0.025, 0.05. Here, 100VaR means
100 times the average VaR of the related model. The corresponding values of
%Viol, LRuc, 100VaR for the AR(1)-GARCH(1,1)-Normal, AR(1)-GARCH(1,1)-
Skewed-t, and AR(1)-GARCH(1,1)-Skewed-t-EVT models are directly imported
from Table 3 in Kuester et al. (2006). The results in Table 2 show that, for a
given W = 1000, α = 0.01, 0.025, 0.05, once we ﬁnd the corresponding W0 =
350, 650, 900, the %Viol of G-VaR is better than that of the AR(1)-GARCH(1,1)
model with Normal, Skewed-t, Skewed-t-EVT innovations. See the plot of the
p-value LRuc at the bottom of the table. In addition, the values of 100VaR in the
four models are very close to one another.

Insert Table 2 around here

Kuester et al. (2006) concluded that the AR-GARCH-Skewed-t and AR-GARCH-

Skewed-t-EVT VaR models achieve better performance with larger windows,
e.g., W = 1000, than with smaller windows, e.g., W = 500, 250. For G-VaR,
however, as suggested by Figure 2, the %Viol statistics are much more stable for
W = 500, 250, which suggests better performance with smaller windows. To ver-
ify that suggestion, Table 3 gives the empirical statistics of %Viol, LRuc, 100VaR
from the G-VaR model for windows W = 500, 250 and risk levels α=0.003, 0.005,
0.01, 0.025, 0.05, thereby conﬁrming that G-VaR indeed achieves excellent per-
formance with smaller windows. For the diﬃcult case with the lowest risk level,
α = 0.003, the empirical p-value even achieves top values of 0.96 and 1.00!

Insert Table 3 around here

20

6.2

S&P500 Index

The S&P500 Index data are analyzed using windows W = 1000, 500, 250.
The window size W0 in Condition 5.1 is determined in exactly the same way as
for the NASDAQ Composite Index data. Figure 3 replicates Figure 2, but for the
S&P500 Index. Summary statistics of %Viol from 3000 < n − W are given in
Table 4 (replicating Table 1, but for the S&P500 Index).

Insert Table 4 around here

Insert Figure 3 around here

Table 5 gives the empirical statistics of %Viol, LRuc, 100VaR for the AR(1)-
GARCH(1,1)-Normal, AR(1)-GARCH(1,1)-Skewed-t, AR(1)-GARCH(1,1)-Skewed-
t-EVT, and G-VaR models for the S&P500 data with n = T , W = 1000, and
α = 0.003, 0.005, 0.01, 0.025, 0.05. These results show that, with a well-calibrated
value for W0, G-VaR clearly outperforms the three benchmark VaR predictors us-
ing AR(1)-GARCH(1,1) ﬁlter and Normal, Skewed-t, and Skewed-t-EVT innova-
tions. See the p-value plot at the bottom of the table.

The experiments were then repeated for smaller windows, i.e., W = 500 and
250. The corresponding results for W = 500 are given in Table 6, with calibrated
values W0 = 70, 110, 120, 250, 480 for the various risk levels. With the exception
of one case, namely, α = 0.05 with the GARCH-ST-EVT model, G-VaR again
outperforms all competitors; see the plot at the bottom of the table. The results for
W = 250 are reported in Table 7. Here, the G-VaR outperforms all competitors
uniformly and signiﬁcantly.

The last plots in Figures 4 and 5 show the time evolution of the three one-step-
ahead forecasts given by the G-VaR, AR(1)-GARCH(1,1)-Skewed-t and AR(1)-
GARCH(1,1)-Skewed-t-EVT models. Each plot comprises three historical win-
dows, W = 1000, 500, 250. The risk level is α = 0.01 in Figure 4, and α = 0.05
in Figure 5. All three VaR predictors have the capacity to follow the rise-drop
patterns of the original return-series.

Insert Table 5 around here

Insert Table 6 around here

21

Insert Table 7 around here

Insert Figure 4 around here

Insert Figure 5 around here

6.3 Adaptive window size W0

The implementation of G-VaR forecasts requires the existence of an adap-
tive window W0 that enables estimation of the variance parameters (σt, σt) of the
G-Normal distribution N(0, [σ2
t ]) used at some given time point t. Figure 6
displays the values of W0 for the diﬀerent values of α given in Tables 5-7.

t , σ2

W0 increases with risk level α. As explained earlier (see comments after Con-
dition 5.1), a smaller α implies greater volatility, and a smaller window W0 is thus
needed under the worst-case scenario adopted in this paper.

Insert Figure 6 around here

The information carried by these experimental values of W0 can be pushed fur-
ther. In Figure 7, we compare the values found for both the NASDAQ Composite
Index and S&P500 Index under diﬀerent risk levels α ∈ {0.003, 0.005, 0.01, 0.025, 0.05},
with the historical window size ﬁxed at W = 500. Because under our worst-case
scenario, smaller window sizes W0 correspond to higher volatility (and thus higher
risk in the index), we can assume that the S&P500 Index return is riskier than the
NASDAQ Composite Index return at risk level α = 0.025. Their degree of risk is
comparable at risk level α = 0.01, and the S&P500 Index is probably less risky at
risk levels α = 0.003, 0.005, and 0.05.

Insert Figure 7 around here

Finally, note that we used an initial segment of 3000 data points to determine
the parameter W0 in both cases of the NASDAQ Composite Index and S&P 500
Index. Once W0 is found, it is kept ﬁxed and used for diﬀerent moving windows
W = 1000, 500, 250. Therefore, the G-VaR forecasts can be considered as in-
sample forecasts for initial 3000 + W data points, while they are out-sample ones
for the remaining n − (3000 + W) data points.

22

7 Discussion

This paper introduces a new VaR predictor, G-VaR, for ﬁnancial return series.
Our methodology is based on the model-uncertainty principle that the volatility
of returns cannot be adequately characterized by a single statistical distribution
or model. Rather, an inﬁnite family of distributions is necessary for full charac-
terization. Considering the worst-case volatility scenario among these numerous
potential distributions, and using the recent theory of SLE, we formally identity
G-VaR through a new mathematical object called G-normal distribution. Exten-
sive empirical analysis using the NASDAQ Composite Index and S&P500 Index
shows the G-VaR predictor to outperform many of the existing benchmark predic-
tors of VaR. Its superiority is particularly signiﬁcant for low risk levels, such as
α = 1% or 0.5%.

It is diﬃcult to provide a completely clear explanation for the surprising suc-
cess of G-VaR. Most likely, the concept of model uncertainty has particular strength
when considering the volatility of returns. Such volatility is time-varying, and is
reputed to be complex in nature, and thus the worst-case scenario approach taken
by G-VaR over all potential volatility distributions proves to be an excellent ﬁt to
the analysed data. Judged by the empirical results presented herein, this model-
uncertainty approach appears more powerful than many of the existing approaches
with model certainty, wherein a unique statistical distribution is assumed for the
volatility process.

However, a number of unanswered question remain to be investigated in fu-
ture. In particular, the implementation of G-VaR depends on an adaptive window
W0. Although it has been shown that this “tuning parameter” can be eﬃciently
determined empirically for the two datasets analyzed in this paper, it would be
worth investigating more its intrinsic or physical meaning. It would also be valu-
able to analyze the performance of the G-VaR predictor on other ﬁnancial series to
determine the extent to which the worst-case scenario approach under model un-
certainty remains successful. More generally, it would be useful to explore other
ﬁnancial or even non-ﬁnancial datasets in which model uncertainty is unavoid-
able. The SLE theory could also provide new data analytic tools in the vein of the
G-VaR approach developed in this paper for the volatility of returns.

Acknowledgement and note on the genesis of G-VaR

The authors are grateful to numerous detailed suggestions and comments from

23

two reviewers and the editor that have led to signiﬁcant improvements of the pa-
per. Speciﬁcally, the interpretation of G-VaR in terms of adjusted normal VaR in
(4.8) is proposed by a reviewer. The interesting comparison with an averaging
aggregation of misspeciﬁed VaRs in Section 4.3 is proposed by another reviewer.
This work on G-VaR has beneﬁted from many discussions the authors had at
various meetings and workshops organized mainly at Zhongtai Security Institute
of Finance, Shandon University. It was in a team led by S. Peng in this institute
that G-VaR was conceived in spring 2015. A ﬁrst reporting on G-VaR with some
data analysis examples on CSI300 Index is proposed by members of this team at
the Industrial Problem Solving Workshop in Finance in Shanghai Jiao Tong Uni-
versity in April 2015. By May 2015, two of the authors (S. Peng and S. Yang)
drafted a working paper (unpublished) on G-VaR where the concept was formally
deﬁned using the sublinear expectation theory. Later in October 2015 Zhongtai
Security Institute of Finance produced a report for CFFX where G-VaR is used to
analyze some data sets from Chinese markets. Another internal report of Zhongtai
Security Institute of Finance by Gong, Yang, Hu and Zhang in November 2015
proposed some experiments of G-VaR for Standard & Poor 500 Index data. It
is however important to note that all these preliminary works are mostly empiri-
cal without any theory of G-VaR and using some rudimentary implementation of
G-VaR. It is in this paper that the G-VaR concept is rigorously constructed and
justiﬁed. In addition, all the empirical studies in this paper are new and diﬀerent
of those reported in the aforementioned internal reports.
In addition, we would
like to thank L. S. Jiang and X. Y. Yue for helping with the solution of the fully
nonlinear PDE (3.3).

References

P. Abad, S. Benito, and C. Lipez. A comprehensive review of value at risk method-
ologies. The Spanish Review of Financial Economics, 12(1):15–32, 2014. ISSN
2173-1268.

P. Artzner, F. Delbaen, J.-M. Eber, and D. Heath. Coherent measures of risk.

Mathematical Finance, 9:203–228, 1999.

M. Avellaneda, A. Levy, and A. Par´as. Pricing and hedging derivative securities
in markets with uncertain volatilities. Applied Mathematical Finance, 2:73–88,
1995.

24

G. Barone-Adesi, K. Giannopoulos, and L. Vosper. VaR without correlations for
portfolios of derivative securities. Journal of Futures Markets, 19:583–602,
1999.

G. Barone-Adesi, K. Giannopoulos, and L. Vosper. Backtesting derivative port-
folios with Filtered Historical Simulation (FHS). European Financial Manage-
ment, 8:31–58, 2002.

T. Bollerslev. Generalized autoregressive conditional heteroskedasticity. Journal

of Econometrics, 31:307–327, 1986.

Z. Chen and L. Epstein. Ambiguity, risk, and asset returns in continuous time.

Econometrica, 70(4):1403–1443, 2002.

V. Chernozhukov and L. Umantsev. Conditional value-at-risk: Aspects of model-

ing and estimation. Empirical Economics, 26(1):271–292, 2001.

P. F. Christoﬀersen. Elements of Financial Risk Management. Academic Press,

Amsterdam, 2003.

R. Cont. Model uncertainty and its impact on the pricing of derivative instruments.

Mathematical Finance, 16:519–547, 2006.

L. Denis, M. Hu, and Peng. S. Function spaces and capacity related to a sublinear
expectation: application to G-Brownian motion paths. Potential Analysis, 34:
139–161, 2011.

K. Dowd. Measuring Market Risk. John Wiley & Sons, Chichester, 2002.

P. Embrechts, K. Kl¨uppelberg, and T. Mikosch. Modelling Extremal Events for

Insurance and Finance. Springer, Berlin, 1997.

R.F. Engle and S. Manganelli. CAViaR: Conditional autoregressive value at risk
by regression quantiles. Journal of Business and Economic Statistics, 22(4):
367–381, 2004.

L. G. Epstein and S. Ji. Ambiguous volatility and asset pricing in continuous time.

Review of Financial Studies, 26(7):1740–1786, 2013.

X. Fang, S. Peng, Q. Shao, and Y. Song. Limit theorems with rate of convergence

under sublinear expectations. Bernoulli, 25:1–31, 2019.

25

H. F¨ollmer and A. Schied. Stochastic Finance. An Introduction in Discrete Time.
Third revised and extended edition. Walter de Gruyter & Co., Berlin, 2011.

N. Gospodinov and E. Maasoumi.

iﬁed models: with an application to asset pricing.
https://sites.google.com/site/gospodinovfed/, 2018.

Generalized aggregation of misspec-
Technical report,

M. Haas, S. Mittnik, and M. S. Paolella. Mixed normal conditional heteroskedas-

ticity. Journal of Financial Econometrics, 2:211–250, 2004.

P. J. Huber. Robust Statistics. Wiley Series in Probability and Mathematical Statis-

tics. John Wiley & Sons, Inc., New York, 3rd edition, 1981.

H. Jin and S. Peng. Optimal unbiased estimation for maximal distribution.

arXiv:1611.07994v1, 2016.

Ph. Jorion. Value at Risk : the New Benchmark for Managing Financial Risk.

McGraw-Hill, New York, 3rd edition, 2007.

Ph. Jorion. Risk management. Annual Review of Financial Economics, 2(1):

347–365, 2010.

J. Kerkhof, B. Melenberg, and H. Schumacher. Model risk and capital reserves.

Journal of Banking & Finance, 34:267–279, 2010.

R. Koenker and G. Bassett. Regression quantiles. Econometrica, 46:33–50, 1978.

K. Kuester, S. Mittnik, and M. S. Paolella. Value-at-Risk Prediction: A compar-
ison of alternative strategies. Journal of Financial Econometrics, 4(1):53–89,
2006.

T. J. Lyons. Uncertain volatility and the risk-free synthesis of derivatives. Applied

Mathematical Finance, 2:117–133, 1995.

A. J. McNeil and R. Frey. Estimation of tail-related risk measures for het-
eroscedastic ﬁnancial time series: An extreme value approach. Journal of Em-
pirical Finance, 7:271–300, 2000.

S. Nadarajah and S. Chan. Estimation methods for value at risk. In Extreme Events
in Finance: A Handbook of Extreme Value Theory and its Applications, pages
283–356. Wiley, 2016. ISBN 9781118650318.

26

S. Peng. Backward SDE and related g-expectation. Backward stochastic diﬀer-
ential equations (Paris, 1995-1996) 141-159. Pitman Res. Notes Math. Ser.,
Longman, Harlow, 1997.

S. Peng. Filtration consistent nonlinear expectations and evaluations of contingent

claims. Acta Mathematicae Applicatae Sinica, 20:1–24, 2004.

S. Peng. Stochastic Analysis and Applications: The Abel Symposium 2005, chap-
ter ”G-expectation, G-Brownian motion and related stochastic calculus of Itˆo
type”. Springer, Berlin Heidelberg, 2006.

S. Peng. Multi-dimensional G-Brownian motion and related stochastic calculus
under G-expectation. Stochastic Processes and Their Applications, 118:2223–
2253, 2008.

S. Peng. Theory, methods and meaning of nonlinear expectation theory. Scientia

Sinica Mathematica: In Chinese, 47:1223–1254, 2017.

S. Peng. Nonlinear Expectations and Stochastic Calculus under Uncertainty.

Springer, Berlin, Heidelberg, 2019.

J. Pickands. Statistical inference using extreme order statistics. Annals of Statis-

tics, 3:119–131, 1975.

P. Walley. Statistical reasoning with imprecise probabilities. Monographs on
Statistics and Applied Probability, 42. Chapman and Hall, Ltd., London, 1991.

Y. Zhang and S. Nadarajah. A review of backtesting for value at risk. Communi-

cations in Statistics - Theory and Methods, pages 1–24, 2017.

A Relevant results from sublinear expectations

In this appendix, we introduce the relevant concepts and properties of the gen-
eral theory of sublinear expectation used in the paper. Let Ω be an arbitrarily
given set and H be a linear space of real functions, called random variables, de-
ﬁned on Ω such that, if ξ ∈ H, then |ξ| ∈ H. We also assume that 1 ∈ H.
The space H is called a vector lattice on Ω. We make the following assumption:
if ξ1, · · · , ξn ∈ H, or equivalently, ξ = (ξ1, · · · , ξn) ∈ H n, then φ(ξ) ∈ H for

27

each function φ in Cl.Lip(Rn). Here, φ corresponds to some characteristic of ξ, and
Cl.Lip(Rn) is the space of all functions φ deﬁned on Rn satisfying

|φ(x) − φ(y)| ≤ C(1 + |x|m + |y|m) |x − y| ,

x, y ∈ Rn,

for some C > 0 and m ∈ N depending on φ. Similarly, with the probability
space, we introduce a sublinear expectation E on H that was ﬁrst proposed in
Peng (2006).

Deﬁnition A.1. A function E : H → R is called a sublinear expectation on (Ω, H)
if it satisﬁes

1). Monotonicity: if X(ω) ≥ Y(ω) for each ω ∈ Ω, then E[X] ≥ E[Y];
2). E[X + c] = E[X] + c for any c ∈ R;
3). E[X + Y] ≤ E[X] + E[Y]; and
4). E[λX] = λE[X] for any λ ≥ 0.

A closely associated concept is coherent risk measures introduced in Artzner
et al. (1999). From a mathematical point of view, this concept essentially coin-
cides with that of sublinear expectation. What makes the diﬀerence is perhaps
the respective contexts where the two concepts are introduced and used. Coherent
risk measures are introduced within mathematical ﬁnance (or ﬁnancial mathemat-
ics) and dedicated to study problems and subjects in this area, for example market
risks and non-market risks. On the other hand, sublinear expectation is more ab-
stract and introduced within general probability theory. For example, objects and
concepts like Brownian motion, conditional expectation and martingale have been
developed under sublinear expectation. A related discussion is Denis et al. (2011)
where a representation theorem of a coherent risk measure is proposed.

Let X1 and X2 be two n-dimensional random vectors deﬁned on nonlinear ex-
pectation spaces (Ω1, H1, E1) and (Ω2, H2, E2), respectively. They are called iden-
tically distributed, denoted by X1 :

d= X2, if

E1[φ(X1)] = E2[φ(X2)], ∀φ ∈ Cl.Lip(Rn).

A random vector Y ∈ H n is said to be independent of X ∈ H m if, for each

φ ∈ Cl.Lip(Rm × Rn), we have

E[φ(X, Y)] = E[E[φ(x, Y)]x=X].

If the above equality holds only for a speciﬁc φ, then we say that Y is uncorre-
lated to X with respect to this function φ. Under a sublinear expectation E, the

28

independence of Y from X means that the uncertainty of distributions of Y does
not change with each realization of X(ω) = x, x ∈ Rn. It is important to note that
this independence under sublinear expectation is not symmetric; in particular “Y
is independent of X” is not equivalent to “X is independent of Y.” For illustration
we consider an example that generalizes the one in Peng (2019).
Example A.1. Let ξ, X, Y, Z ∈ H be identically distributed satisfying E[ξ] =
E[−ξ] = 0 and σ2 = E[ξ2] > σ2 = −E[−ξ2]. We suppose E[|ξ|] = E[ξ+ + ξ−] > 0,
thus

E[ξ+] = 1
2

E[|ξ| + ξ] = 1
2

E[|ξ|] > 0,

and

E[|ξ| − ξ] = 1
2
Assume that Z is independent of {X, Y} and Y is independent of X, we can show
that

E[ξ−] = 1
2

E[|ξ|] > 0.

E[XY] = 0, E[|XY|] = (E[|X|])2 > 0, E[(XY)+] = E[(XY)−] = 1
2

E[|XY|] > 0,

and

E[XYZ2] = E[(XY)+σ2 − (XY)−σ2] = (σ2 − σ2)E[(XY)+] > 0.

In contrast,
of Z, we have

if we assume that X is independent of Y and {X, Y} are independent

E[XYZ2] = E[E[XYz2]z=Z] = E[Z2]E[XY] = 0.
Therefore, by reversing the order of independence, we obtain diﬀerent values for
E[XYZ2]. This shows the asymmetry of the concept of independence under sub-
linear expectation while the concept is symmetric in classical probability theory.

Finally, further properties of the G-normal distribution are rigorously estab-

lished as follows.

Proposition A.1. The solution of the fully nonlinear PDE (3.3) with Cauchy initial
condition (4.5) has the following explicit expression;

u(t, x) =

(cid:90) x

−∞

ρ(t, y)dy,

where ρ(t, y) is a function on R+ × R deﬁned by

ρ(t, y) =

√
2
(σ + σ)

√

πt

(cid:34)
e− y2

2σ2t I(y ≤ 0) + e

− y2

(cid:35)
2σ2t I(y > 0)

.

29

Proof. Using classical analysis of the heat equation, we can prove that lim
t→0

u(t, x) =

1(0,∞)(x) for each x. If x < 0, we have ρ(t, x) =

2σ2t and can obtain that

√

2
√
(σ+σ)

πt

e− x2

∂tu(t, x) = ∂xρ(t, x) =

∂xu(t, x) = ρ(t, x) =

xxu(t, x) = ∂xρ(t, x) =
∂2

e− x2
2σ2t ,

2πt3
e− x2
2σ2t ,

√

−x
(σ + σ)
√
2
(σ + σ)
−
2x
(σ + σ)σ2

πt
√

√

√

e− x2
2σ2t .

πt3

(A.1)

Thus, we can verify

∂tu(t, x) − G(∂2

xxu(t, x)) = 0, x < 0, t > 0.

In a similar manner, we have

∂tu(t, x) − G(∂2

xxu(t, x)) = 0, x < 0, t > 0.

Note that ∂2
thus, one obtains,

xxu(t, x) is continuous on (0, ∞) × R, and ∂2

xxu(t, 0) = 0, ∂tu(t, 0) = 0,

∂tu(t, x) − G(∂2

xxu(t, x)) = 0, x = 0, t > 0.

Consequently, u(t, x) solves the PDE (3.3) on the entire (0, ∞) × R in the sense of
(cid:3)
classical solution.

30

Figure 1: Density of one distribution of G-normal distribution with variance pa-
rameters (σ, σ) = (0.5, 1) in comparison with standard normal density.

31

−4−3−2−10123400.10.20.30.40.50.6  Normal−pdfa G−normal−pdfFigure 2: NASDAQ Composite Index: convergence of the violation rate %Viol
for W = 1000, 500, 250, and α = 0.01. The adaptive window sizes are W0 =
350, 120, 75, respectively.

0100020003000400050006000700000.0020.0040.0060.0080.010.0120.014DATE% Viol of NASDAQ  with W=1000, W0=350, α=0.01  % Viol under G-VaR01000200030004000500060007000800000.0050.010.0150.020.0250.03DATE% Viol of NASDAQ  with W=500, W0=120, α=0.01  % Viol under G-VaR01000200030004000500060007000800000.0020.0040.0060.0080.010.0120.0140.0160.018DATE% Viol of NASDAQ  with W=250, W0=75, α=0.01  % Viol under G-VaR Figure 3: S&P500 Index: convergence of the violation rate %Viol for W =
1000, 500, 250, and α = 0.01.
These adaptive window sizes are W0 =
250, 120, 85, respectively.

050010001500200025003000350000.0050.010.0150.020.0250.03DATE% Viol of NASDAQ  with W=1000, W0=250, α=0.01  % Viol under G-VaR0500100015002000250030003500400000.0050.010.015DATE% Viol of S&P500  with W=500, W0=120, α=0.01  % Viol under G-VaR05001000150020002500300035004000450000.0020.0040.0060.0080.010.0120.014DATE% Viol of S&P500  with W=250, W0=85, α=0.01  % Viol under G-VaR Figure 4: For a given W = 1000, 500, 250, the VaR performance of diﬀerent
models at risk level α = 0.01..

2007012009012001101201212−20−15−10−5051015DATEVaR and Return of S&P500 with Window=1000, α=0.01  RETURN−S&P500GARCH−STGARCH−ST−EVTG−MODEL2007012009012001101201212−20−15−10−5051015DATEVaR and Return of S&P500 with Window=500, α=0.01  RETURN−S&P500GARCH−STGARCH−ST−EVTG−MODEL2007012009012001101201212−20−15−10−5051015DATEVaR and Return of S&P500 with Window=250, α=0.01  RETURN−S&P500GARCH−STGARCH−ST−EVTG−MODELFigure 5: For a given W = 1000, 500, 250, the VaR performance of diﬀerent
models at risk level α = 0.05.

2007012009012001101201212−10−5051015DATEVaR and Return of S&P500 with Window=1000, α=0.05  RETURN−S&P500GARCH−STGARCH−ST−EVTG−MODEL2007012009012001101201212−15−10−5051015DATEVaR and Return of S&P500 with Window=500, α=0.05  RETURN−S&P500GARCH−STGARCH−ST−EVTG−MODEL2007012009012001101201212−15−10−5051015DATEVaR and Return of S&P500 with Window=250, α=0.05  RETURN−S&P500GARCH−STGARCH−ST−EVTG−MODELFigure 6: S&P 500 Index data: variation of adaptive window W0 for diﬀerent risk
levels α and historical windows W.

Figure 7: For a given W = 500, α = 0.003, 0.005, 0.01, 0.025, 0.05, W0 of NAS-
DAQ and S&P500 indexes.

36

0.0030.0050.010.0250.0501002003004005006007008009001000RISK LEVELCorresponding W0 under a given W and risk level  Value of W0 under W=1000Value of W0 under W=500Value of W0 under W=2500.0030.0050.010.0250.05050100150200250300350400450500RISK LEVEL W0 under a given W and risk level  W0 of NASDAQ W0 of S&P500Table 1: NASDAQ Composite Index: Average and standard deviations of %Viol
with W=1000, 500, 250 and α = 0.01.

Model Window W Window W0 Average value Standard deviation

G-VaR:

1000
500
250

350
120
75

0.0087
0.0103
0.0104

8.1160e-04
3.9274e-04
5.9560e-04

37

Table 2: NASDAQ Composite Index: Empirical statistics of G-VaR forecast com-
pared with forecasts of three benchmark predictors reported in Kuester et al. (2006) with
W=1000. The bottom plot shows the LRuc, where LRuc is the p-values of the Binomial
test.

Model

100α %Viol. LRuc

100VaR

AR(1)-GARCH(1,1)-N:

AR(1)-GARCH(1,1)-St:








AR(1)-GARCH(1,1)-St-EVT:



G-VaR: W0=


350
650
900

1
2.5
5
1
2.5
5
1
2.5
5
1
2.5
5





2.23
3.92
6.21
1.2
2.72
5.12
0.97
2.47
5.06
0.99
2.51
5.03

0.00
0.00
0.00
0.12
0.25
0.65
0.82
0.87
0.82
0.93
0.96
0.90

2.05
1.72
1.43
2.57
2.01
1.59
2.70
2.07
1.61
2.78
2.06
1.52

38

0.010.0250.05−0.200.20.40.60.811.21.4RISK LEVELNASDAQ−Binomial Test with Window=1000  GARCH−NGARCH−STGARCH−ST−EVTG−MODELTable 3: NASDAQ Composite Index with W=500, 250

Model

100α %Viol. LRuc

100VaR

W=500: W0=

W=250: W0=










50
70
120
270
420
35
50
75
150
210

0.3
0.5
1
2.5
5
0.3
0.5
1
2.5
5

0.30
0.49
1.05
2.54
5.00
0.30
0.52
1.02
2.49
5.05

0.96
0.95
0.70
0.81
0.99
1.00
0.82
0.84
0.93
0.84

4.71
4.00
3.11
2.14
1.60
4.29
3.67
2.98
2.12
1.61

Table 4: S&P500 Index: Average and standard deviations of %Viol with W=1000,
500, 250 and α = 0.01

Model Window W Window W0 Average value Standard deviation

G-VaR:

1000
500
250

250
120
85

0.0111
0.0097
0.0099

4.1705e-04
3.6689e-04
3.0967e-04

39

Table 5: S&P 500 Index: Empirical statistics of VaR forecasts from G-VaR and three
benchmark predictors with W=1000. The bottom plot shows the LRuc.

Model

100α %Viol. LRuc

100VaR

AR(1)-GARCH(1,1)-N:

AR(1)-GARCH(1,1)-St:










AR(1)-GARCH(1,1)-St-EVT:

G-VaR: W0=






90
150
250
650
1000

0.3
0.5
1
2.5
5
0.3
0.5
1
2.5
5
0.3
0.5
1
2.5
5
0.3
0.5
1
2.5
5






1.15
1.55
2.42
3.83
6.08
0.28
0.73
1.32
3.24
5.71
0.39
0.62
1.21
2.79
4.73
0.29
0.52
1.07
2.49
4.87

0.00
0.00
0.00
0.00
0.00
0.83
0.07
0.07
0.01
0.06
0.33
0.33
0.33
0.28
0.45
0.91
0.86
0.68
0.97
0.72

2.64
2.47
2.23
1.87
1.56
3.42
3.06
2.61
2.03
1.60
3.38
3.10
2.70
2.16
1.72
7.05
5.77
4.40
2.91
1.94

0.0030.0050.010.0250.05−0.200.20.40.60.811.21.4RISK LEVELS&P500 Binomial Test with Window=1000  GARCH−NGARCH−STGARCH−ST−EVTG−MODELTable 6: S&P 500 Index: Empirical statistics of VaR forecasts from G-VaR and three
benchmark predictors with W=500. The bottom plot shows the LRuc.

Model

100α %Viol. LRuc

100VaR

AR(1)-GARCH(1,1)-N:

AR(1)-GARCH(1,1)-St:










AR(1)-GARCH(1,1)-St-EVT:

G-VaR: W0=






70
110
120
250
480

0.3
0.5
1
2.5
5
0.3
0.5
1
2.5
5
0.3
0.5
1
2.5
5
0.3
0.5
1
2.5
5






1.06
1.38
2.22
3.82
5.90
0.27
0.59
1.18
3.13
5.67
0.37
0.62
1.06
2.57
5.01
0.33
0.51
0.96
2.48
5.08

0.00
0.00
0.00
0.00
0.01
0.74
0.42
0.25
0.01
0.05
0.43
0.31
0.70
0.79
0.98
0.74
0.96
0.81
0.90
0.81

2.75
2.58
2.32
1.95
1.63
3.51
3.16
2.69
2.11
1.67
3.44
3.16
2.77
2.23
1.80
5.50
4.58
4.08
2.79
1.90

0.0030.0050.010.0250.05−0.200.20.40.60.811.21.4RISK LEVELS&P500 Binomial Test with Window=500  GARCH−NGARCH−STGARCH−ST−EVTG−MODELTable 7: S&P 500 Index: Empirical statistics of VaR forecasts from G-VaR and three
benchmark predictors with W=250. The bottom plot shows the LRuc.

Model

100α %Viol. LRuc

100VaR

AR(1)-GARCH(1,1)-N:

AR(1)-GARCH(1,1)-St:










AR(1)-GARCH(1,1)-St-EVT:

G-VaR: W0=






45
60
85
140
240

0.3
0.5
1
2.5
5
0.3
0.5
1
2.5
5
0.3
0.5
1
2.5
5
0.3
0.5
1
2.5
5






1.30
1.72
2.56
4.09
6.23
0.40
0.70
1.39
3.3
5.95
0.65
0.86
1.40
2.90
5.18
0.29
0.48
0.98
2.55
4.95

0.00
0.00
0.00
0.00
0.00
0.28
0.08
0.01
0.00
0.01
0.00
0.00
0.01
0.10
0.59
0.86
0.82
0.87
0.85
0.88

2.78
2.61
2.35
1.97
1.65
3.47
3.13
2.68
2.12
1.69
3.32
3.06
2.71
2.22
1.80
4.73
4.16
3.46
2.57
1.83

0.0030.0050.010.0250.05−0.200.20.40.60.811.21.4RISK LEVELS&P500 Binomial Test with Window=250  GARCH−NGARCH−STGARCH−ST−EVTG−MODEL