AR-BERT: Aspect-relation enhanced Aspect-level Sentiment
Classification with Multi-modal Explanations

Sk Mainul Islam
IIT Kharagpur, India

Sourangshu Bhattacharya
IIT Kharagpur, India

2
2
0
2

b
e
F
4
1

]
L
C
.
s
c
[

2
v
6
5
6
1
1
.
8
0
1
2
:
v
i
X
r
a

ABSTRACT
Aspect level sentiment classification (ALSC) is a difficult problem
with state-of-the-art models showing less than 80% macro-F1 score
on benchmark datasets. Existing models do not incorporate infor-
mation on aspect-aspect relations in knowledge graphs (KGs), e.g.
DBpedia. Two main challenges stem from inaccurate disambigua-
tion of aspects to KG entities, and the inability to learn aspect
representations from the large KGs in joint training with ALSC
models. We propose AR-BERT, a novel two-level global-local entity
embedding scheme that allows efficient joint training of KG-based
aspect embeddings and ALSC models. A novel incorrect disam-
biguation detection technique addresses the problem of inaccuracy
in aspect disambiguation. We also introduce the problem of deter-
mining mode significance in multi-modal explanation generation,
and propose a two step solution. The proposed methods show a
consistent improvement of 2.5 − 4.1 percentage points, over the
recent BERT-based baselines on benchmark datasets. The code is
available at https://github.com/mainuliitkgp/AR-BERT.git.

CCS CONCEPTS
• Information systems → Sentiment analysis; • Computing
methodologies → Natural language processing.

KEYWORDS
Sentiment Analysis, Knowledge Graph Embedding, Explainable
Deep Learning

ACM Reference Format:
Sk Mainul Islam and Sourangshu Bhattacharya. 2022. AR-BERT: Aspect-
relation enhanced Aspect-level Sentiment Classification with Multi-modal
Explanations. In Proceedings of the ACM Web Conference 2022 (WWW ’22),
April 25–29, 2022, Virtual Event, Lyon, France. ACM, New York, NY, USA,
12 pages. https://doi.org/10.1145/3485447.3511941

1 INTRODUCTION
Aspect level sentiment classification (ALSC) is an important NLP
task [7, 11, 24], where we predict the sentiment portrayed in a
sentence (also called context) towards an identified aspect phrase.
Recently, models capturing aspect-specific features, e.g., Transfor-
mation Network (TNet) [15], which constructs aspect-specific em-
bedding of context words, or BERT-based models [6], which capture
aspect-specific representations of sentences, have outperformed
previous sequential prediction models. Other recent improvements

Publication rights licensed to ACM. ACM acknowledges that this contribution was
authored or co-authored by an employee, contractor or affiliate of a national govern-
ment. As such, the Government retains a nonexclusive, royalty-free right to publish or
reproduce this article, or to allow others to do so, for Government purposes only.
WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France
© 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-9096-5/22/04. . . $15.00
https://doi.org/10.1145/3485447.3511941

include domain adaptation of the BERT model [27] and incorpo-
rating entity relationships within the same sentence using graph
convolutional networks [45]. However, existing ALSC methods do
not explicitly utilize the relations between aspects, which could
potentially lead to better performance.

We observe that many of the aspect phrases, e.g., Windows 8,
Mozzarella, Taylor Swift, etc., are mentions of named entities
appearing in knowledge graphs (KG), e.g., DBpedia, which encode
various entity-entity relations. While some of the aspects may be
unseen in the training data, their neighbors (related aspects) in
the KG may be abundant. This information can be used to infer
important signals from the context sentence, which in turn can help
in the prediction of correct polarity. For example, in the sentence, My
laptop with Windows 7 crashed and I did not want Windows
8., the aspect Windows 7 has only 17 examples in the training data.
The current state-of-the-art ALSC model [27] wrongly predicts
the aspect sentiment as positive. However, its related aspects (1-
hop neighbors in the DBpedia KG) have 209 training examples,
which can lead to the correct prediction of sentiment. Our primary
objective is to incorporate the KG relations between aspects into
ALSC models.

The main challenges in model design are: (1) end-to-end training
of ALSC models with KG embeddings is infeasible due to large
scale of KGs, and (2) most scalable off-the-shelve named entity
disambiguation techniques, e.g., wikifier [2] are highly inaccurate.
While state of the art named entity disambiguation methods [3, 14]
are accurate, they still do not scale to the entire DBpedia KG. We
solve the problem of learning aspect representations from large KGs
using a two-level graph embedding technique: one corresponding
to a higher level cluster graph, and another for subgraphs. These
embeddings can be efficiently trained jointly along with ALSC
models. The problem of inaccurate wikification [2] method for
aspect disambiguation, is ameliorated by a novel probing function
based detection of incorrect aspect disambiguations. Figure 1 shows
the overall architecture of the proposed technique.

The deep multi-modal ALSC model proposed here utilizes in-
formation from both text and graph data in an opaque manner,
thus reducing the trust in the model predictions. Hence, we seek to
design a postthoc global explanation model for predicting multi-
modal explanations from both context words, and KG-entities. A
key challenge in the prediction of multi-modal explanations is the
prediction of importance of the mode for which explanations are
being generated, since there may not be any valid explanations
from a given mode. We design an explanation model which also
predicts the mode importance, and a two-step prodecure for jointly
learning the unimodal explanation models, as well as the mode
importance predictor. To the best of our knowledge, ours is the first
model for jointly predicting multi-modal explanations from text
and graph data.

 
 
 
 
 
 
WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Sk Mainul Islam and Sourangshu Bhattacharya

Figure 1: Architecture of our framework for end-to-end training of ALSC model while incorporating aspect relations from
large KGs. Yellow backgound denotes modules trained end-to-end, green backgound denotes input.

Experimental results show that proposed ALSC models improve
the macro-F1 score and accuracy of state-of-the-art ALSC meth-
ods on three benchmark datasets by between 2.5% − 4.1%. We
also demonstrate that the scarcity of training examples is indeed
a factor for the inaccuracy of existing models. We also show that
classification accuracy of wrongly disambiguated aspects improves
significantly with the disambiguation correction method. Finally,
experimental results using the explanation prediction model show
that both predicted explanations and significant mode are effective
and intuitive. To summarize, our main contributions are: (1) AR-
BERT - a scalable aspect-relation enhanced ALSC algorithm. (2)
A novel technique for detecting incorrect entity disambiguations.
(3) A multi-modal explanation generation model with significant
mode detection.

2 RELATED WORK
ALSC with Graph Embedding: [20] uses memory networks gen-
erate aspect representations influenced by other aspects in the
same sentence. [42] uses aspect-specific GCN, and [16] uses an
“interactive” dependency graph to capture the relations between
aspect in a sentence. [32] also encodes information in dependency
graph using a transformer-like network. However, none of the
above methods can be used at a scale where we can apply it to
a knowledge graph like DBpedia. [37],[12] focus on determining
aspect specific opinion spans. In addition to the models described
in section 3.1, neural network models such as Memory Networks
[4, 31, 34], LSTM-based models [19, 35, 43], and Capsule Networks
[8] have also been explored for ALSC.

Knowledge graphs in BERT representations: Reif et al. [25]
measures the word sense similarities using a semantic probe on
word embeddings. Hewitt and Manning [10] shows that contextual
word embedding incorporates syntactic informations. Broscheit
[3] investigates entity knowledge in BERT embedding. [22, 23, 44]
propose a promising line of schemes for incorporating entity knowl-
edge in KGs into BERT embeddings. However end-to-end training
with these methods has to take entire KG into account, and is ex-
pected to be computationally expensive.

[30] modifies the BERT encoder and training procedure in order
to incorporate graphs constructed from KG and unstructured text.
However, this is not scalable. [17] augments the unstructured text
with triples from KG, and trains BERT on the resulting corpora.
This technique is also not scalable when trying to capture relations
between all entities.

Explainable models: For explaining textual and graph informa-
tion in a unimodal manner popular methods e.g. LIME [26] (extracts
important words for a particular prediction) and GNNExplainer [41]
(extracts an important subgraph for a particular node classification
prediction), cannot be used since they only learn local explanation
models. We use the recently proposed methods of concept learning
[40] for explanations using textual data, and PGExplainer [18] for
explanations using graphs data. While multi-modal explanation
generation has been studied in for image and text modes [13, 21],
to the best of our knowledge, multi-modal explanation and mode
significance has not been studied in the context of textual and graph
data.

3 EXPLAINABLE ALSC WITH ASPECT

RELATION

In this section, we describe our approach for improving the per-
formance of aspect level sentiment classification (ALSC) methods
using semantic relations between aspects which can be extracted
from Knowledge Graphs (KG), e.g. DBpedia. The key motivation
behind our work is that certain aspects are not well represented
by examples in the training set, but they have neighboring entities
in the KG which have more examples. Hence, the semantic infor-
mation learned from the neighboring aspect may be transferred to
the current aspect through aspect embeddings. For example, in the
sentence [However, I can refute that OSX is "FAST"], the
aspect OSX has the corresponding DBpedia entity MacOS, which
has only 7 examples in the training set. However, MacOS has a re-
lated entity Microsoft_Windows which has 37 examples. This leads
to the existing BERT-based ALSC method [27] misclassifying this
example as positive sentiment polarity based on the context word

AR-BERT: Aspect-relation enhanced Aspect-level Sentiment Classification with Multi-modal Explanations

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

FAST, whereas our method focusses on the context word refute and
classifies the example correctly as negative sentiment polarity.

Our method has 2 broad components: (1) disambiguating men-
tions of aspects (e.g. OSX ) to entities from a KG (e.g. DBpedia entity
MacOS), and representing them as an embedding vector, and (2)
incorporation of the vector representation of the aspects into state
of the art ALSC models, e.g. TNET and BERT, using end-to-end
training. Figure 1 describes the overall architecture of our technique.
Section 3.1 provides the background on ALSC, sections 3.2, 3.3, and
3.4 describe the proposed ALSC model, AR-BERT, and an incorrect
disambiguation detection technique. Section 3.5 describes a novel
model for multi-modal explanation generation for AR-BERT.

3.1 Background in ALSC
The task of aspect level sentiment classification (ALSC) is to de-
termine the sentiment polarity 𝑦 ∈ {𝑃, 𝑁 , 𝑂 } of an input sentence
𝑤 for an aspect phrase 𝑤𝑡 , which is a part of the input sentence.
Here, 𝑃, 𝑁 , and 𝑂 correspond to positive negative and neutral senti-
ment respectively. ALSC models take representations of the context
𝑤, (cid:174)𝑥 = (𝑥1, ..., 𝑥𝑛), and that of the aspect 𝑤𝑡 , (cid:174)𝑥𝑡 = (𝑥𝑡
𝑚) as
inputs. Most state-of-the-art ALSC models, including TNET [15],
and BERT [6] transform the context representation using an aspect
representation to finally arrive at an aspect-specific representation
for context words. Here, 𝑛 denotes the length of the (context) sen-
tence and 𝑚 denotes the length of the aspect. We briefly describe
the architectures of these methods.

1, ..., 𝑥𝑡

𝑖

𝑛 ( (cid:174)𝑥)) and (cid:174)ℎ𝑡 = (ℎ𝑡

( (cid:174)𝑥), ..., ℎ (0)
(𝑥), ℎ𝑡

TNet [15] consists of three sequential modules (sets of layers):
The first module is a Bi-LSTM layer which takes context embed-
dings (cid:174)𝑥 and aspect (target) word embeddings (cid:174)𝑥𝑡 corresponding
to each eaxmple and outputs the contextualized representations
(cid:174)ℎ (0) = (ℎ (0)
𝑚 ( (cid:174)𝑥𝑡 )) respec-
1 ( (cid:174)𝑥𝑡 ), ..., ℎ𝑡
1
tively where ℎ (0)
𝑗 (𝑥𝑡 ) ∈ R2𝐷ℎ , 𝑖 ∈ {1, . . . , 𝑛}, 𝑗 ∈ {1, . . . , 𝑚}.
The second module contains 𝐿 layers of context preserving trans-
formations (CPT) blocks. In each layer 𝑙 the aspect representa-
tion is first transformed into aspect specific representation as 𝑟𝑡
𝑖 =
(cid:205)𝑚
𝑗 ), then incorporated into context repre-
sentation as ˜ℎ𝑖
𝑟𝑡
𝑖 ), and finally passed into
context preserving LF/AS block to get the output of next layer:
ℎ (𝑙+1)
). The third module uses convolution
𝑖
and pooling layers on position-aware encodings to produce a fixed
dimensional vector 𝑧.

𝑗 ∗ SoftMax(ℎ (𝑙)
(𝑙)

= FeedForward(ℎ (𝑙)
𝑖

= 𝐿𝐹 /𝐴𝑆 (ℎ (𝑙)
𝑖

𝑗=1 ℎ𝑡

, ˜ℎ𝑖

, ℎ𝑡

(𝑙)

𝑖

BERT has been applied to ALSC by Rietzler et al. [27] and Sun
et al. [29], where they model the sentiment classification task as a
sequence-pair classification task. The input sentence ((cid:174)𝑥) and aspect
phrase ((cid:174)𝑥𝑡 ) are encoded as [CLS] (cid:174)𝑥 [SEP] (cid:174)𝑥𝑡 [SEP]. The last layer
hidden representation of CLS token ℎ [𝐶𝐿𝑆 ] ∈ R768, which is the
aspect-aware representation of the input sequence, is used for the
downstream classification task. The sentiment polarity distribution
is predicted using a feedforward layer with softmax activation and
trained using the cross-entropy loss. Recently, SDGCN-BERT [45]
has been proposed to capture sentiment dependencies between
multiple aspects in a sentence using a graph convolution network.
BERT-ADA [27] uses BERT domain-specific language model fine-
tuning for ALSC and results in best accuracy on some benchmark
datasets. In this paper we build on TNet, BERT, SDGCN-BERT, and

BERT-ADA, to incorporate knowledge from KG. Next, we describe
our framework for the scalable incorporation of KG information in
ALSC.

3.2 Aspect Relation Incorporation from KG
Incorporating aspect relation from KG into ALSC models has two
substeps: (1) Aspect to entity mapping and (2) Computation of entity
embedding. The first step involves the identification of Wikipedia
entities corresponding to an aspect word in a context. This problem
is solved by named entity disambiguation (NED) or wikification.
We use wikifier API [2] for this purpose. Note that, here we use
a freely available and computationally efficient method for entity
linking, at the cost of accuracy. We partially make up for the loss
of accuracy in the posthoc disambiguation correction described in
section 3.4.

For learning the entity embeddings (step 2), we use the popular
GraphSAGE algorithm [9], which is applicable for both supervised
and unsupervised tasks. The entity relation graph is generated us-
ing the DBpedia 1 page links knowledge graph, where each vertex
is an entity in the DBpedia KG, and an edge is a tuple of the form
< 𝑆𝑢𝑏, 𝑃𝑟𝑒𝑑, 𝑂𝑏 𝑗 > where 𝑆𝑢𝑏 and 𝑂𝑏 𝑗 are the subject and object
entities, and 𝑃𝑟𝑒𝑑 is the predicate relation between 𝑆𝑢𝑏 and 𝑂𝑏 𝑗.
However, the whole DBpedia knowledge graph (KG) is too large
(with ∼ 22 million nodes and ∼ 173 million edges) to embed using
deep NRL techniques. Another alternative is to consider the sub-
graph 𝐺 induced by entities present in the ALSC training dataset
only. The problem with this subgraph is that it is disconnected.
Hence, the similarity preserving embeddings of entities are only
consistent within the connected components of 𝐺. This may lead to
two very different entities 𝑢 and 𝑣 accidentally ending up close to
each other. In this section, we describe a two-level scalable network
embedding technique that scales to DBpedia while avoiding the
above-mentioned problems.

3.2.1 Two-level Aspect Entity Embedding. The key idea behind two-
level aspect embedding (representations) is two use two smaller
graphs constructed from the large KG: (1) a cluster graph 𝐺𝐶 (𝑉𝐶, 𝐸𝐶,𝑊𝐶 ):
which captures the global connectivity structure between clusters
of entities, and (2) the subgraph 𝐺𝑠 (𝑉𝑠, 𝐸𝑠 ) induced by aspects (en-
tities) in the training dataset. Note that since the subgraph 𝐺𝑠 can
be disconnected, we need a combination of cluster graph embedding
z𝐶 (𝑢), and subgraph embedding, z𝑠 (𝑢) for capturing the relations
between aspect entity 𝑢.
Cluster graph embedding: The weighted cluster graph 𝐺𝐶 (𝑉𝐶, 𝐸𝐶,𝑊𝐶 )
is a compact representation of the KG where each vertex 𝑣 ∈ 𝑉𝐶 is
a cluster of vertices (entities) of the knowledge graph 𝐺 = (𝑉 , 𝐸).
We use the Louvain hierarchical graph clustering [1] algorithm for
clustering the entire knowledge graph. Edge set 𝐸𝐶 is calculated
as: (𝑖, 𝑗) ∈ 𝐸𝐶 , ∀𝑖, 𝑗 ∈ 𝑉𝐶 if there is a connected pair of KG entities
from clusters 𝑖 and 𝑗. The weight between clusters 𝑖 and 𝑗, 𝑊𝐶 (𝑖, 𝑗),
is calculated as the fraction of actual edges between clusters 𝑖 and
𝑗 and the maximum edges possible between the two clusters, i.e,
|𝑖 | ∗ | 𝑗 |, where |𝑖 | is the number of nodes present in cluster 𝑖. We
use a modified GraphSAGE embedding technique to construct the
cluster embeddings z𝐶 (𝑖), 𝑖 ∈ 𝑉𝐶 of a weighted graph by optimizing

1https://wiki.dbpedia.org/downloads-2016-10

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Sk Mainul Islam and Sourangshu Bhattacharya

the following graph based loss function:

𝐽𝐶 (𝒛𝐶 (𝑖)) = −𝑙𝑜𝑔(𝜎 (𝒛𝐶 (𝑖)𝑇 𝒛𝐶 ( 𝑗))) − 𝑄 · E𝑘∼𝑃𝑛 ( 𝑗)𝑙𝑜𝑔(𝜎 (−𝒛𝐶 (𝑖)𝑇 𝒛𝐶 (𝑘)))
where 𝒛𝐶 (𝑖) is the output representation of 𝑖 ∈ 𝑉𝐶 , 𝜎 is the sigmoid
function, 𝑗 ∈ 𝑉𝐶 is a cluster co-occurring with 𝑖 on a fixed weighted
random walk defined by 𝑊𝐶 (𝑖, 𝑗), 𝑃𝑛 is the negative sampling dis-
tribution, 𝑄 is the number of negative samples, 𝑘 ∈ 𝑉𝐶 is a negative
sample.
Subgraph embedding: The vertex set 𝑉𝑠 of the entity-relation
subgraph 𝐺𝑠 (𝑉𝑠, 𝐸𝑠 ) consists of all aspect entities extracted from
instances in the training dataset, while the edge set 𝐸𝑠 is the sub-
set of induced edges from the original KG. We use the standard
GraphSAGE embedding and loss function to construct the subgraph
similarity embedding, z𝑠 (𝑢) for aspect entity 𝑢. To preserve the
local neighbourhood information as well as global graph structure
in the knowledge graph, we use the concatenation of subgraph
and cluster graph embedings as our two level entity embedding:
𝒛 (𝑢) = [𝒛𝐶 (𝑖); 𝒛𝑠 (𝑢)], where 𝑢 ∈ 𝑉𝑠 and 𝑖 ∈ 𝑉𝐶 such that 𝑢 is an
entitiy in cluster 𝑖. Figure 1 shows the methods for aspect disam-
biguation and two-level entity embedding on the left side in the
overall scheme.

3.3 ALSC with entity relation learning
In this section, we incorporate the concatenated entity embedding
proposed above into two state-of-the-art ALSC models: TNet and
BERT (described in section 3.1). We propose two ways of incorpo-
rating the information contained in entity relations from KG into
ALSC: (1) using static embeddings, and (2) by performing end-to-
end learning. For incorporation of static embedding in TNet, the
final entity embedding 𝒛(𝑢) for entity 𝑢 is concatenated with final
(𝑳)
layer CPT block output 𝒉(𝑳) as 𝒉
𝒄𝒐𝒏𝒄𝒂𝒕 = [𝒉(𝑳) ; 𝒛(𝑢)] and this
(𝑳)
new aspect specific contextual representation 𝒉
is sent as in-
𝒄𝒐𝒏𝒄𝒂𝒕
put to the convolution layer module as described in section 3.1. The
final layers and loss function is same as TNet. We call this model
Aspect Relation-TNet (AR-TNet). We incorporate the entity em-
bedding 𝒛(𝑢) into BERT by concatenating it with representation of
CLS token ℎ [𝐶𝐿𝑆 ] , as: ℎ [𝐶𝐿𝑆 ]𝑐𝑜𝑛𝑐𝑎𝑡 = [ℎ [𝐶𝐿𝑆 ] ; 𝒛(𝑢)]. Here ℎ [𝐶𝐿𝑆 ]
is the final aspect-specific sentence representation for an ALSC
instance taken from domain specific BERT model (BERT-ADA) [27],
and further fine-tuned on ALSC task. We call this model Aspect
Relation-BERT (AR-BERT). We also incorporate the static entity
embedding 𝒛(𝑢) into SDGCN-BERT [45], in an analogous way to
train the Aspect Relation-BERT-S (AR-BERT-S) model, through
finetuning on ALSC. These models are referred to in Table 2 with
‘wo end-to-end’ in parenthesis because these models are trained
without an end-to-end strategy. The end-to-end training of our
proposed models AR-BERT, AR-BERT-S, and AR-TNet (for the
base models BERT-ADA, SDGCN-BERT, and TNet, respectively)
are discussed in the following section.
End-to-end learning: Incorporation of GraphSAGE embeddings
into ALSC models provide minor improvements to polarity predic-
tion, since the aspect embeddings are not fine-tuned for the ALSC
task. This is achieved with end-to-end training of the aspect embed-
ding and ALSC models. The architecture of our end-to-end models
are same as the models proposed with static embeddings above.
Hence, for BERT based models, we calculate the final embeddings

for a sentence and aspect pair as: ℎ [𝐶𝐿𝑆 ]𝑐𝑜𝑛𝑐𝑎𝑡 = [ℎ [𝐶𝐿𝑆 ] ; 𝒛(𝑢)],
(𝑳)
where 𝒛(𝑢) = [𝒛𝐶 (𝑖); 𝒛𝑠 (𝑢)]. For TNet-based models, 𝒉
𝒄𝒐𝒏𝒄𝒂𝒕 =
[𝒉(𝑳) ; 𝒛 (𝑢)]. For both models, let L𝐴𝐿𝑆𝐶 denote the loss incurred
from ALSC training, and L𝐺𝑆 be the loss incurred from GraphSage
using the subgraph 𝐺𝑠 = (𝑉𝑠, 𝐸𝑠 ). We optimize the following loss
for joint training:

L 𝑗𝑜𝑖𝑛𝑡 (Θ𝐴𝐿𝑆𝐶, {z𝑠 (𝑢)}) = 𝛼1L𝐴𝐿𝑆𝐶 + 𝛼2L𝐺𝑆

where, Θ𝐴𝐿𝑆𝐶 are all the parameters from ALSC model, and {z𝑠 (𝑢)}
are subgraph embeddings from 𝐺𝑠 . We minimize the above loss w.r.t.
Θ𝐴𝐿𝑆𝐶, {z𝑠 (𝑢)}, while keeping z𝐶 (𝑖) fixed to pre-learned Graph-
SAGE embeddings.

3.4 Incorrect Disambiguation Detection
Many of the misclassifications using models like BERT-GS, are due
to incorrect disambiguation of aspect entities (see section 4.3). In
this section, we develop a scalable algorithm for identifying incor-
rect aspect disambiguations and mitigating their effect by setting
the corresponding (modified) embedding to zero vector. We rely on
the BERT aspect embedding vectors ℎ [𝐶𝐿𝑆 ] (called ℎ in this section
for brevity) for the same. However, BERT embeddings encode many
modalities of information including syntactic dependencies [10],
semantic similarities, and entity relations [25]. We propose to use
a learned similarity function S𝐵 (ℎ𝑖, ℎ 𝑗 ) which captures the entity
similarity between two BERT embeddings ℎ𝑖 and ℎ 𝑗 of two entity
mentions. Hence, following [25], we propose to use the following
form of similarity function:

S𝐵 (ℎ𝑖, ℎ 𝑗 ) = 𝜎 ((𝐵 · ℎ𝑖 )𝑇 (𝐵 · ℎ 𝑗 ))

where, 𝐵 ∈ 𝑅𝑑𝑖𝑚𝐵 ∗𝑑𝑖𝑚ℎ is a learned parameter. The parameter 𝐵
can be thought of as a “probing function” [25], projecting BERT
embedding ℎ into a space which only distills out the entity relations.
Algorithm 1, describes the steps for learning the probing function
parameter 𝐵, which extracts entity relational similarities from BERT
embeddings, and calculation of the modified embeddings. The key
idea is: aspects which are close in graph embedding space should also
have high similarity of BERT embeddings. The algorithm proceeds
by constructing triplets (𝑖, 𝑗, 𝑘) of aspects where aspects 𝑖 and 𝑗 are
closer, but 𝑖 and 𝑘 are not closer. It then learns 𝐵 by minimizing the
loss: (cid:205)
(𝑖,𝑗,𝑘) ∈𝜏 (S𝐵 (ℎ𝑖, ℎ𝑘 ) − S𝐵 (ℎ𝑖, ℎ 𝑗 )). For each aspect 𝑖, and for
all it’s top 𝑛 close aspects 𝑗 and rest far away aspects 𝑘, we modify
it’s corresponding concatenated entity embedding as follows:

𝒛𝑚𝑜𝑑 (𝑖) =

(cid:40)

{(cid:174)0}𝑑𝑖𝑚ℎ,
𝒛(𝑖),

if S𝐵 (ℎ𝑖, ℎ 𝑗 ) − S𝐵 (ℎ𝑖, ℎ𝑘 ) ≥ 0
otherwise

(1)
{(cid:174)0}𝑑𝑖𝑚ℎ is the zero vector of dimension 𝑑𝑖𝑚ℎ. We call ALSC models
jointly (end-to-end) trained with these corrected embeddings as:
AR-BERT-idd, AR-BERT-S-idd, and AR-TNet-idd; correspond-
ing to base models BERT-ADA, SDGCN-BERT, and TNet.

3.5 Multi-modal Explanation Generation
The ALSC models proposed above incorporate semantic and syn-
tactic information from the text data, and aspect relations from the
knowledge graphs. Since, the information from these two modes

AR-BERT: Aspect-relation enhanced Aspect-level Sentiment Classification with Multi-modal Explanations

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Algorithm 1 Incorrect Disambiguation Detection
Require: Set of aspects A (D) in Dataset D, Graph aspect embed-
dings {z(𝑢)}, 𝑢 ∈ A (D), BERT aspect embeddings { (cid:174)ℎ(𝑢)}, 𝑢 ∈
A (D)

Ensure: Probing distance fn. parameter: 𝐵, Corrected embedding:

z𝑚𝑜𝑑 (𝑢)

1: randomly initialize 𝐵
2: LIST 𝜏 ← 𝜙
3: for all 𝑖 ∈ A (D) do
4: A𝑖 (D) ← sort other aspects z(𝑢), 𝑢 ∈ A (D) in decreasing

5:

order of distance to z(𝑖)
Sample 𝑗 from top 𝑛 in A𝑖 (D), and 𝑘 from rest; emit 𝜏 ←
𝜏 ∪ (𝑖, 𝑗, 𝑘)

6: end for
7: learn 𝐵: min𝐵 (cid:205)
8: Calculate z𝑚𝑜𝑑 (𝑢) using eqn. 1

(𝑖,𝑗,𝑘) ∈𝜏 (S𝐵 (ℎ𝑖, ℎ𝑘 ) − S𝐵 (ℎ𝑖, ℎ 𝑗 )) + 𝜆 ∥𝐵∥2

are combined using a deep neural network, for a given test exam-
ple, the information content in each of the modes is not obvious.
In this section, we describe a global posthoc explanation model
for generating multi-modal explanations for predictions provided
by the proposed model architecture. For simplicity, we summarize
the proposed architecture into 3 components: (1) the text feature
extractor model for input context and aspect (cid:174)𝑥, 𝑴𝒕 ( (cid:174)𝑥) : 𝑿 → ℎ( (cid:174)𝑥),
(2) the graph embedding model 𝑴𝒈 (𝐺) : 𝑮 → 𝑧 (𝐺), and (3) the
final prediction model 𝑴𝒐 (ℎ( (cid:174)𝑥), 𝑧 (𝐺)) : [ℎ( (cid:174)𝑥); 𝑧 (𝐺)] → {𝑃, 𝑁 , 𝑂 }.
Hence, ℎ( (cid:174)𝑥) = ℎ (𝐿) ( (cid:174)𝑥) for the TNET model and ℎ(( (cid:174)𝑥) = ℎ [𝐶𝐿𝑆 ] ( (cid:174)𝑥)
for the BERT model. 𝑧 (𝐺) = z(u) (section 3.2) and 𝑴𝒐 (ℎ( (cid:174)𝑥), 𝑧 (𝐺))
is a feedforward neural network with softmax output.

For generating global explanations from text features ℎ(( (cid:174)𝑥) we
build on the method proposed in [40]. Let 𝜃𝑐𝑜𝑛 be the matrix of
𝑘-concept vectors used for explaining salient features of prediction,
and 𝜃𝑑𝑒𝑐 be the parameters of the decoder network 𝑔, which recon-
structs the original vectors from concept embeddings 𝜃𝑇
𝑐𝑜𝑛ℎ( (cid:174)𝑥). The
parameters of the text explanation model 𝐸𝑡 (𝜃𝑐𝑜𝑛, 𝜃𝑑𝑒𝑐 ) are learned
by minimizing the regularized negative log-likelihood function:

L𝐸𝑡 (𝜃𝑐𝑜𝑛, 𝜃𝑑𝑒𝑐 ) = E (cid:174)𝑥 [− log 𝑃 (𝑴𝒐 (𝑔(𝜃𝑇

𝑐𝑜𝑛ℎ( (cid:174)𝑥), 𝜃𝑑𝑒𝑐 ), 𝑧 (𝐺))] + R(𝜃𝑐𝑜𝑛)

where, 𝑅(𝜃𝑐𝑜𝑛) is the diversity regularity between concepts de-
scribed in [40]. Explanation words are extracted by selecting top
scoring words 𝑥𝑖 according to the score max𝑘 (𝜃𝑇
𝑐𝑜𝑛ℎ( (cid:174)𝑥𝑖 ). For the
graph explanation model 𝐸𝑔 with parameters 𝜃𝑔, we use parame-
terized graph explainer (PGExplainer) model [18], minimizing the
entropy loss:

L𝐸𝑔 (𝜃𝑔) = E𝐺𝑆 ∼𝑞 (𝜃𝑔) [𝐻 (𝑴𝒐 (ℎ( (cid:174)𝑥), 𝑴𝒈 (𝐺)) | 𝑴𝒐 (ℎ( (cid:174)𝑥), 𝑴𝒈 (𝐺𝑆 )))]
where 𝐺𝑆 is explanation subgraph sampled from a distribution 𝑞
parameterized by 𝜃𝑔.

A key challenge in generating multi-modal explanations is to
identify the significance of individual modes. To this end, we define
the significance variables for graph and text mode 𝑠𝑔, 𝑠𝑡 ∈ [0, 1],
respectively. Given the explanations provided by unimodal ex-
planation models, we generate the perturbed input text ˜𝑥 by re-
moving the explanation words from (cid:174)𝑥, and the perturbed input
graph ˜𝐺 by removing vertices and induced edges from the ex-
planation subgraph. The significance labels are set as: 𝑠𝑡 = 1 if

𝑴𝒐 (ℎ( ˜𝑥), 𝑧 (𝐺)) ≠ 𝑴𝒐 (ℎ( (cid:174)𝑥), 𝑧 (𝐺)) and 0 otherwise, and analo-
gously for 𝑠𝑔. We also train feed-forward neural networks with
sigmoid activation for predicting 𝑠𝑡 , 𝑠𝑔 from inputs (cid:174)𝑥), 𝑧 (𝐺): 𝑠𝑡 =
𝑆𝑡 ( (cid:174)𝑥), 𝑧 (𝐺)), and 𝑠𝑔 = 𝑆𝑔 ( (cid:174)𝑥), 𝑧 (𝐺)). Hence the joint multi-modal
explanation loss is given as:

L𝑚𝑚 (𝜃𝑐𝑜𝑛, 𝜃𝑑𝑒𝑐𝜃𝑔, 𝑆𝑡 , 𝑆𝑔) = 𝑆𝑡 ∗ L𝐸𝑡 + 𝑆𝑔 ∗ L𝐸𝑔 + 𝜆(𝐿(𝑠𝑡 , 𝑆𝑡 ) + 𝐿((𝑠𝑔, 𝑆𝑔))

The first two terms are significance weighted explanation losses for
individual modes, and the last two terms are binary cross-entropy
losses for matching significance predictors to respective signifi-
cance values generated by the unimodal explanation predictors. 𝜆
controls the weightage given to initial unimodal significance values.

4 EXPERIMENTS
In this section, we report experimental results to empirically ascer-
tain whether the proposed models indeed perform better than the
existing state of the art methods.

4.1 Experimental Setup
Datasets and baselines: We evaluate our proposed models on
the three benchmark datasets: LAPTOP and REST datasets from
SemEval 2014 Task 4 subtask 2 [24] which contains reviews from
Laptop and Restaurant domain respectively and the TWITTER
dataset [7] containing Twitter posts. For TNet-based models, we
perform the same prepossessing procedure as done in [15]. We com-
pare results of our proposed models with state-of-the-art methods
reported in table 2.
Aspect disambiguation and KG Embedding: For each aspect
in the dataset D mentioned above, we disambiguate its corre-
sponding entity in the knowledge graph using the wikifier API
[2]. We use hierarchical Louvain graph clustering [1] algorithm
for clustering the KG and constructing the weighted cluster graph
𝐺𝐶 (𝑉𝐶, 𝐸𝐶,𝑊𝐶 )(ref section 3.2.1). Statistics of the knowledge graph
and its corresponding cluster graph and sub-graphs are shown in
Table 1. For training entity sub-graph and weighted cluster graph
embedding, we use GraphSAGE mean as aggregate function. For
training GraphSage [9], we sample 25 nodes for layer 1 and 10 nodes
for layer 2 using a random walk. The output hidden representation
dimension is set as 50, and the number of negative samples 𝑄 taken
as 5. Default values are used for all other parameters.
ALSC and probing function training: For TNet-based models,
we used 20% randomly held-out training data as the development
set. We train the model for 100 epochs and select the model corre-
sponding to the maximum development-set accuracy. Following
[15], we use the same set of hyperparameters and report the max-
imum accuracy obtained on the test set over multiple runs. For
training of BERT-based models, we use the procedure suggested
in Rietzler et al. [27], for both pre-training and fine-tuning. For
end-to-end training of ALSC with entity embedding generation, we
use Adam optimizer with a learning rate of 3 · 10−5, batch size of
512 for GraphSAGE-based entity embedding generation and 32 for
ALSC task, number of epochs as 7. All the other hyper-parameters
in GraphSAGE based entity embedding generation and ALSC task
follow the same values in individual training. For training of the
probing function 𝐵, we use Adam optimizer with a learning rate
of 1 · 10−5, the batch size of 128, the number of epochs as 100,

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Sk Mainul Islam and Sourangshu Bhattacharya

the probe dimension 𝑑𝑖𝑚𝐵 as 100, and the regularization rate as
0.01. We use the same evaluation procedure suggested in Rietzler
et al. [27], e.g. we conducted 9 runs with different initializations for
all the experiments, and reported the average performance on the
given test set. The model with the best training error over 7 epochs
is taken as the final model for all runs.

Table 1: Statistics of knowledge graph, weighted cluster
graph and entity relation sub-graphs.

Knowledge Graph Embedding
#Nodes
#Edges

#Clusters Max. inter

173068197

22504204

606

Sub-graph Embedding
Dataset

#Nodes

#Edges

LAPTOP
REST
TWITTER

785
1031
120

4477
7305
429

-cluster degree
341

Max. Node
Degree
107
136
40

4.2 Comparison of ALSC Models
Table 2 reports all baseline and proposed models’ performance,
using two standard metrics: macro-accuracy (ACC) and macro-F1
score (Macro-F1). We observe that AR-BERT-idd outperforms all
the other models on the REST and TWITTER dataset, and AR-BERT-
S-idd outperforms all the other models for the LAPTOP dataset, in
terms of both Accuracy and Macro-Averaged F1 scores. Hence, we
can conclude that representation of relations between aspect entities
helps in training better ALSC models. The improvement in the perfor-
mance by the proposed AR-BERT-idd and AR-BERT-S-idd models
over other BERT-based baseline models imply that the DBpedia
knowledge graph encodes information which supplements the in-
formation contained in BERT embeddings of the aspect terms.We
also note that BERT based baseline models, e.g. BERT-ADA, perform
better than other models, e.g. TNET, as they utilize the context-
sensitive word embeddings fine-tuned on domain-related datasets.

Figure 2: Effect of number of training datapoints

Effect of training data scarcity: Figure 2 reports the accuracy of
the baseline model (BERT-ADA, blue bar) and the proposed model
(green bar), for all test aspects in the LAPTOP dataset. The test

aspects are bucketed according to their training data counts, and
the bars report average accuracy for all aspects in the buckets.
We can see that for aspects that have 0 – 20 training points, the
proposed method outperforms the baseline. Hence, we conclude
that for aspects with a low number of training data points, the
proposed method improves the performance of ALSC by borrowing
information from nearby aspects in the KG. The red line shows the
number of test data points for each of the buckets. We find that
a large fraction of test aspects have fewer than 20 training data
points.
Error Analysis: Table 3 shows the confusion matrices of predic-
tions of AR-TNet-idd and AR-BERT[idd] w.r.t. their respective base-
line models on the three datasets. The top-left and bottom-right
values report the number of correctly classified or misclassified
examples by both methods in each sub-matrix. We can see that the
proposed models do not induce any new errors which were not
present in the respective baselines. Finally, we see that the bottom
left entries in each table that report the new corrects (examples
classified wrongly by existing methods but are classified correctly
by the proposed methods) are much higher. Thus, we conclude that
the new technique is an improvement over the old methods.
Anecdotal examples: Table 5 illustrates a few examples misclas-
sified by BERT-ADA and correctly predicted by AR-BERT-idd. As-
pects in the sentences are marked in the bracket with corresponding
sentiment labels in subscript. Context words captured by the mod-
els for corresponding predictions are extracted using the context
explainer of multi-modal explanation generation model, and the
most important aspect entity (if any) is extracted using graph ex-
plainer of multi-modal explanation model (for instances where both
context and graph information is required to predict sentiment po-
larity correctly, the most important aspect entity is the node in
the explanation sub-graph with highest training example). Context
explanations verify that BERT-ADA captures context words that are
always semantically related to the aspects e.g. ‘high’ w.r.t. aspect
‘price’, whereas AR-BERT-idd considers aspect as an entity and tries
to captures context words associated with that entity or the most
important aspect entity from the given context. For each dataset,
the distribution of test examples in each mode of importance of
multi-modal explanation is given in Table 6.

4.3 Incorrect Disambiguation Detection
In this section, we demonstrate the effectiveness of our probing
function for incorrect disambiguation detection. We categorized the
aspects into 3 categories based on the disambiguation by wikifier:
(1) unknown (unk) where there was no entity found, (2) correct
disambiguation (cd) where the disambiguated aspect was mapped
to the correct entity, and (3) incorrect disambiguation (id) where
the disambiguated aspect was mapped to an incorrect entity, based
on manual annotation. Table 4 shows the number of incorrectly
classified (ic) examples (by the ALSC model) in each disambigua-
tion category out of the total number of examples in that category
(#𝑖𝑐/#𝑇𝑜𝑡𝑎𝑙). We see that compared to AR-BERT (wo end-to-end)
and AR-BERT, AR-BERT-idd has significantly fewer incorrectly
classified for the unknown and incorrect disambiguation cat-
egories. For the correct disambiguation category, all methods

AR-BERT: Aspect-relation enhanced Aspect-level Sentiment Classification with Multi-modal Explanations

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Table 2: Experiment results on various datasets(%). The marker * refers to p-value <0.01 when comparing with respective
baselines. % in bracket of best performing models implies overall gain wrt. its’ baselines.

Model

Baseline models for ALSC
TNet [15]
BERT-base [6]
SDGCN-BERT [45]
BERT-ADA [27]

LAPTOP

REST

TWITTER

ACC

Macro-F1 ACC

Macro-F1 ACC

Macro-F1

76.33
77.69
81.35
80.25

71.27
72.60
78.34
75.77

73.87★
77.07★
79.21★

79.64
84.92
83.57
87.89

70.20
76.93
76.47
81.05

78.17
78.81
78.54
78.90

77.17
77.94
77.72
77.97

83.40★
89.38★
85.27★

73.91★
82.47★
78.07★

80.52★
80.91★
79.67★

79.79★
80.15★
78.89★

ALSC with Aspect relation incorporation
AR-TNet
AR-BERT
AR-BERT-S

78.80★
81.73★
82.37★

ALSC with Aspect relation and incorrect disambiguation detection
AR-TNet-idd
AR-BERT-idd

80.09★
82.91★

75.11★
78.31★

AR-BERT-S-idd

Results with explanation concepts
AR-BERT-idd (ℎ (𝑥) = 𝑔 (𝜃𝑇
AR-BERT-S-idd (ℎ (𝑥) = 𝑔 (𝜃𝑇
AR-BERT-idd (𝐺 = 𝐺𝑆 )
AR-BERT-S-idd (𝐺 = 𝐺𝑆 )

𝑐𝑜𝑛ℎ ( (cid:174)𝑥), 𝜃𝑑𝑒𝑐 ))

𝑐𝑜𝑛ℎ ( (cid:174)𝑥), 𝜃𝑑𝑒𝑐 ))

Results with ablations of explanations
AR-BERT-idd (with ˜𝑥)
AR-BERT-S-idd (with ˜𝑥)
AR-BERT-idd (with ˜𝐺)
AR-BERT-S-idd (with ˜𝐺)

83.62★
(+2.79%)

80.43★
(+2.67%)

-
83.38
-
83.54

-
34.48
-
81.09

-
80.25
-
80.41

-
32.43
-
78.15

84.64★
90.62★
(+3.11%)
86.61★

75.17★
83.81★
(+3.40%)
79.37★

81.64★
82.08★
(+4.03%)
80.86★

80.84★
81.21★
(+4.15%)
80.03★

90.18
-
90.36
-

34.13
-
88.01
-

83.39
-
83.57
-

33.25
-
81.11
-

81.50
-
81.94
-

33.81
-
78.75
-

80.64
-
81.07
-

33.17
-
77.67
-

Table 3: Confusion matrices of predictions of AR-TNet-idd
vs TNet and AR-BERT-idd vs BERT-ADA w.r.t. correct and
incorrect classification

Table 4: Fraction of incorrectly predicted examples in disam-
biguation categories.

Baseline

AR-TNet
[idd]

AR-BERT
[idd]

Prediction Correct
LAPTOP
Correct
Incorrect

487
24

REST

Correct
Incorrect

TWITTER
Correct
Incorrect

892
56

541
24

Incorrect Correct

Incorrect

0
127

0
172

0
127

512
17

984
31

547
22

0
109

0
105

0
124

have the similar fraction of misclassification, which is much lower
than the other two categories.

Figure 3 reports the percentage i_d which were detected cor-
rectly (left bar), and the c_d which were marked incorrectly (right
bar) by the probing scheme. It can be seen that more than 80% of
i_d examples have been correctly detected, and less than 5% of
c_d examples have been wrongly flagged. Hence, we conclude that

# i_c / # u_d

# i_c / # i_d

# i_c / # c_d

AR-BERT
LAPTOP
REST
TWITTER

AR-BERT-idd
LAPTOP
REST
TWITTER

8 / 10
12 / 14
2 / 2

6 / 10
10 / 14
0 / 2

47 / 53
76 / 87
8 / 14

41 / 53
65 / 87
0 / 14

62 / 575
31 / 1019
122 / 676

62 / 575
30 / 1019
124 / 676

our incorrect disambiguation detection method shows excellent
performance, while also being highly scalable.

4.4 Effectiveness of Multi-modal Explanations
In this section, we report experimental results studying the effec-
tiveness of multi-modal explanations predicted by the proposed
model. Table 2, section Results with explanation concepts reports the
predictive performance of ALSC models with explanations as input.
The top two rows use the text concept embeddings as input, while
the next two rows use the explanation subgraph as the input. We
note that in all these cases the prediction performance remains sim-
ilar to the original model, with the maximum accuracy difference

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Sk Mainul Islam and Sourangshu Bhattacharya

Table 5: Examples of mistakes by BERT-ADA which were correctly predicted by AR-BERT-idd. Red and green backgrounds
indicate context explanations from multi-modal explanation model for BERT-ADA and AR-BERT-idd.

Sentence

LAPTOP
However, I can refute that [OSX]NEG is "FAST".
From the speed to the multi touch gestures this operating system beats [Windows]NEG easily.
Did not enjoy the new [Windows 8]NEG and touchscreen functions.
REST
Anywhere else, the [prices]POS would be 3x as high!
A beautiful atmosphere, perfect for [drinks]NEU and/or appetizers.
The [bread]POS is top notch as well.
TWITTER
noobus Turns out [Snoop Dogg]NEG is actually pretty funny .
just got hold of an [Ipod]NEU . . it will be fun learning how to use it on the bus trip to
canberra this monday
Is it just me , or does [John Boehner]NEG sound like a newsman ?
Sounds like he belongs on CBS Nightly News .

BERT AR-BERT Graph-mode
Explanation
-ADA -idd

POS
POS
NEG

NEG
POS
POS

POS
POS

NEG
NEG
NEG

POS
NEU
POS

NEG
NEU

Hard_disk_drive (39)
Software (64)
-

Service (140)
Food (365)
-

Barack_Obama (343)
IPhone (168)

NEU

NEU

-

input. The results (top two rows) clearly demonstrate that the text
mode explanation include an important portion of the text, whose
removal causes drastic drop in model performance.

Table 6 analyzes the effectiveness of prediction of important
modes of explanation. Text mode implies 𝑆𝑡 = 1 and 𝑆𝑔 = 0, and
other modes are defined analogously. We note that "Text" and "Both"
mode cover a majority of the test examples, which is expected.
Graph mode covers a miniscule number of examples for which
the ALSC prediction can be made by simply observing the aspect
graph nodes. Finally, we observe a small number of examples for
which the explanation model predicts that none of the modes are
important. A majority of these examples are ones where the ALSC
model erroneously predicts the ALSC labels, due to which there is
no possibility of improvement using any of the modes. The numbers
in brackets in table 6 show the number of cases where there has
been an improvement in label prediction by the ALSC model due
to incorporation of aspect relations from graphs. Note that all the
improvements have been in the cases of examples for which the
explanation model predicts that both modes are important. This
further demonstrates the effectiveness of the mode prediction mod-
els. Table 5 reports anecdotal examples from the three datasets
along with text mode and graph mode explanations provided by the
explanation model. Examples for each dataset shows examples with
improvement in ALSC prediction due to incorporation of graphs.
The entities corresponding to aspect graph nodes, and count of
neighboring nodes in the aspect graph are shown in the graph
mode explanation, which are intuitive.

5 CONCLUSIONS
In this paper, we present a scalable technique for incorporating
aspect relations from large knowledge graphs, into state of the
art deep learning based ALSC models. The resulting algorithm -
AR-BERT, along with a novel incorrect disambiguation detection
technique, results in consistent and significant improvements in

Figure 3: Percentage of correct / incorrect detection of dis-
ambiguation

Table 6: Distribution of test examples in each mode of multi-
modal explanation with mode importance

Important
Mode
Text (𝑆𝑡 = 1 and 𝑆𝑔 = 0)
Graph (𝑆𝑡 = 0 and 𝑆𝑔 = 1)
Both (𝑆𝑡 = 1 and 𝑆𝑔 = 1)
None (𝑆𝑡 = 0 and 𝑆𝑔 = 0)
Total

LAPTOP

REST

TWITTER

300 (0)
34 (0)
234 (15)
70 (0)

588 (0)
45 (0)
427 (31)
60 (0)

355 (0)
49 (0)
216 (22)
72 (0)

638

1120

692

of < 0.5% and maximum macro-F1 score difference of < 1.5%. This
demonstrates the effectiveness of the explanation models. We also
notice that predicting using the text concept embeddings results in
marginally lower performance compared to predicting using graph
explanation, which is expected due to the overall higher importance
of the text mode. Table 2, section-Results with ablations with expla-
nations further demonstates the effectiveness of explanations by
reporting the performance of the ALSC model with perturbations
˜𝑥 and ˜𝐺 removing the explanations of text and graph modes as

AR-BERT: Aspect-relation enhanced Aspect-level Sentiment Classification with Multi-modal Explanations

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

ALSC performance on all benchmark datasets. This work also re-
ports the first algorithm for multi-modal explanation generation
across textual and graph data.

REFERENCES
[1] Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefeb-
vre. 2008. Fast unfolding of communities in large networks. Journal of Statis-
tical Mechanics: Theory and Experiment 2008, 10 (Oct 2008), P10008. https:
//doi.org/10.1088/1742-5468/2008/10/p10008

[2] Janez Brank, Gregor Leban, and Marko Grobelnik. 2018. Semantic Annota-
Informatica (Slovenia) 42,
http://www.informatica.si/index.php/informatica/

tion of Documents Based on Wikipedia Concepts.
1 (2018).
article/view/2228

[3] Samuel Broscheit. 2019. Investigating Entity Knowledge in BERT with Simple
Neural End-To-End Entity Linking. In Proceedings of the 23rd Conference on Com-
putational Natural Language Learning, CoNLL 2019, Hong Kong, China, November
3-4, 2019, Mohit Bansal and Aline Villavicencio (Eds.). Association for Computa-
tional Linguistics, 677–685. https://doi.org/10.18653/v1/K19-1063
[4] Peng Chen, Zhongqian Sun, Lidong Bing, and Wei Yang. 2017. Recurrent
Attention Network on Memory for Aspect Sentiment Analysis. In Proceed-
ings of the 2017 Conference on Empirical Methods in Natural Language Pro-
cessing, EMNLP 2017, Copenhagen, Denmark, September 9-11, 2017. 452–461.
https://www.aclweb.org/anthology/D17-1047/

[5] Junqi Dai, Hang Yan, Tianxiang Sun, Pengfei Liu, and Xipeng Qiu. 2021. Does
syntax matter? A strong baseline for Aspect-based Sentiment Analysis with
RoBERTa. In Proceedings of the 2021 Conference of the North American Chapter
of the Association for Computational Linguistics: Human Language Technologies,
NAACL-HLT 2021, Online, June 6-11, 2021, Kristina Toutanova, Anna Rumshisky,
Luke Zettlemoyer, Dilek Hakkani-Tür, Iz Beltagy, Steven Bethard, Ryan Cotterell,
Tanmoy Chakraborty, and Yichao Zhou (Eds.). Association for Computational
Linguistics, 1816–1829. https://doi.org/10.18653/v1/2021.naacl-
main.146

[6] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:
Pre-training of Deep Bidirectional Transformers for Language Understanding. In
Proceedings of the 2019 Conference of the North American Chapter of the Associa-
tion for Computational Linguistics: Human Language Technologies, NAACL-HLT
2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers),
Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association for Com-
putational Linguistics, 4171–4186. https://doi.org/10.18653/v1/n19-
1423

[7] Li Dong, Furu Wei, Chuanqi Tan, Duyu Tang, Ming Zhou, and Ke Xu. 2014. Adap-
tive Recursive Neural Network for Target-dependent Twitter Sentiment Classifi-
cation. In Proceedings of the 52nd Annual Meeting of the Association for Computa-
tional Linguistics, ACL 2014, June 22-27, 2014, Baltimore, MD, USA, Volume 2: Short
Papers. 49–54. https://www.aclweb.org/anthology/P14-2009/
[8] Chunning Du, Haifeng Sun, Jingyu Wang, Qi Qi, Jianxin Liao, Tong Xu, and Ming
Liu. 2019. Capsule Network with Interactive Attention for Aspect-Level Sentiment
Classification. In Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on Natural
Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019,
Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan (Eds.). Association for
Computational Linguistics, 5488–5497. https://doi.org/10.18653/v1/
D19-1551

[9] William L. Hamilton, Zhitao Ying, and Jure Leskovec. 2017.
In Advances

Induc-
tive Representation Learning on Large Graphs.
in Neu-
ral
In-
Information Processing Systems 30: Annual Conference on Neural
formation Processing Systems 2017, 4-9 December 2017, Long Beach, CA,
USA. 1024–1034. http://papers.nips.cc/paper/6703-inductive-
representation-learning-on-large-graphs

[10] John Hewitt and Christopher D. Manning. 2019. A Structural Probe for Finding
Syntax in Word Representations. In Proceedings of the 2019 Conference of the
North American Chapter of the Association for Computational Linguistics: Human
Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019,
Volume 1 (Long and Short Papers), Jill Burstein, Christy Doran, and Thamar
Solorio (Eds.). Association for Computational Linguistics, 4129–4138. https:
//doi.org/10.18653/v1/n19-1419

[11] Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In
Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, Seattle, Washington, USA, August 22-25, 2004, Won
Kim, Ron Kohavi, Johannes Gehrke, and William DuMouchel (Eds.). ACM, 168–
177. https://doi.org/10.1145/1014052.1014073

[12] Bin Jiang, Jing Hou, Wanyue Zhou, Chao Yang, Shihan Wang, and Liang Pang.
2020. METNet: A Mutual Enhanced Transformation Network for Aspect-based
Sentiment Analysis. In Proceedings of the 28th International Conference on Com-
putational Linguistics. 162–172.

[13] Atsushi Kanehira, Kentaro Takemoto, Sho Inayoshi, and Tatsuya Harada. 2019.
Multimodal Explanations by Predicting Counterfactuality in Videos. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
(CVPR).

[14] Rijula Kar, Susmija Reddy, Sourangshu Bhattacharya, Anirban Dasgupta, and
Soumen Chakrabarti. 2018. Task-Specific Representation Learning for Web-Scale
Entity Disambiguation. In Proceedings of the Thirty-Second AAAI Conference on Ar-
tificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelli-
gence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial
Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018, Sheila A.
McIlraith and Kilian Q. Weinberger (Eds.). AAAI Press, 5812–5819. https://
www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17281

[15] Xin Li, Lidong Bing, Wai Lam, and Bei Shi. 2018. Transformation Networks
for Target-Oriented Sentiment Classification. In Proceedings of the 56th Annual
Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne,
Australia, July 15-20, 2018, Volume 1: Long Papers. 946–956. https://doi.
org/10.18653/v1/P18-1087

[16] Bin Liang, Rongdi Yin, Lin Gui, Jiachen Du, and Ruifeng Xu. 2020. Jointly Learning
Aspect-Focused and Inter-Aspect Relations with Graph Convolutional Networks
for Aspect Sentiment Analysis. In Proceedings of the 28th International Conference
on Computational Linguistics. 150–161.

[17] Weijie Liu, Peng Zhou, Zhe Zhao, Zhiruo Wang, Qi Ju, Haotang Deng, and Ping
Wang. 2020. K-bert: Enabling language representation with knowledge graph. In
Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 2901–2908.
[18] Dongsheng Luo, Wei Cheng, Dongkuan Xu, Wenchao Yu, Bo Zong, Haifeng
Chen, and Xiang Zhang. 2020. Parameterized explainer for graph neural network.
arXiv preprint arXiv:2011.04573 (2020).

[19] Dehong Ma, Sujian Li, Xiaodong Zhang, and Houfeng Wang. 2017. Interactive
Attention Networks for Aspect-Level Sentiment Classification. In Proceedings of
the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI
2017, Melbourne, Australia, August 19-25, 2017. 4068–4074. https://doi.org/
10.24963/ijcai.2017/568

[20] Navonil Majumder, Soujanya Poria, Alexander Gelbukh, Md Shad Akhtar, Erik
Cambria, and Asif Ekbal. 2018. IARM: Inter-aspect relation modeling with mem-
ory networks in aspect-based sentiment analysis. In Proceedings of the 2018
conference on empirical methods in natural language processing. 3402–3411.
[21] Dong Huk Park, Lisa Anne Hendricks, Zeynep Akata, Anna Rohrbach, Bernt
Schiele, Trevor Darrell, and Marcus Rohrbach. 2018. Multimodal explanations:
Justifying decisions and pointing to the evidence. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition. 8779–8788.

[22] Matthew E Peters, Mark Neumann, Robert Logan, Roy Schwartz, Vidur Joshi,
Sameer Singh, and Noah A Smith. 2019. Knowledge Enhanced Contextual Word
Representations. In Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on Natural
Language Processing (EMNLP-IJCNLP). 43–54.

[23] Nina Poerner, Ulli Waltinger, and Hinrich Schütze. 2020. E-BERT: Efficient-Yet-
Effective Entity Embeddings for BERT. In Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Processing: Findings. 803–818.

[24] Maria Pontiki, Dimitris Galanis, John Pavlopoulos, Harris Papageorgiou, Ion
Androutsopoulos, and Suresh Manandhar. 2014. SemEval-2014 Task 4: Aspect
Based Sentiment Analysis. In Proceedings of the 8th International Workshop on
Semantic Evaluation, SemEval@COLING 2014, Dublin, Ireland, August 23-24, 2014.
27–35. https://www.aclweb.org/anthology/S14-2004/

[25] Emily Reif, Ann Yuan, Martin Wattenberg, Fernanda B. Viégas, Andy Co-
enen, Adam Pearce, and Been Kim. 2019. Visualizing and Measuring the Ge-
ometry of BERT. In Advances in Neural Information Processing Systems 32:
Annual Conference on Neural Information Processing Systems 2019, NeurIPS
2019, 8-14 December 2019, Vancouver, BC, Canada, Hanna M. Wallach, Hugo
Larochelle, Alina Beygelzimer, Florence d’Alché-Buc, Emily B. Fox, and Ro-
man Garnett (Eds.). 8592–8600. http://papers.nips.cc/paper/9065-
visualizing-and-measuring-the-geometry-of-bert

[26] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. "Why Should I
Trust You?": Explaining the Predictions of Any Classifier. In Proceedings of the
22nd ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining, San Francisco, CA, USA, August 13-17, 2016. 1135–1144.

[27] Alexander Rietzler, Sebastian Stabinger, Paul Opitz, and Stefan Engl. 2020. Adapt
or Get Left Behind: Domain Adaptation through BERT Language Model Fine-
tuning for Aspect-Target Sentiment Classification. In Proceedings of The 12th
Language Resources and Evaluation Conference, LREC 2020, Marseille, France,
May 11-16, 2020, Nicoletta Calzolari, Frédéric Béchet, Philippe Blache, Khalid
Choukri, Christopher Cieri, Thierry Declerck, Sara Goggi, Hitoshi Isahara, Bente
Maegaard, Joseph Mariani, Hélène Mazo, Asunción Moreno, Jan Odijk, and
Stelios Piperidis (Eds.). European Language Resources Association, 4933–4941.
https://www.aclweb.org/anthology/2020.lrec-1.607/

[28] Emanuel H Silva and Ricardo M Marcacini. [n. d.]. Aspect-based Sentiment

Analysis using BERT with Disentangled Attention. ([n. d.]).

[29] Chi Sun, Luyao Huang, and Xipeng Qiu. 2019. Utilizing BERT for Aspect-Based
Sentiment Analysis via Constructing Auxiliary Sentence. In Proceedings of the

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Sk Mainul Islam and Sourangshu Bhattacharya

2019 Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN,
USA, June 2-7, 2019, Volume 1 (Long and Short Papers), Jill Burstein, Christy Doran,
and Thamar Solorio (Eds.). Association for Computational Linguistics, 380–385.
https://doi.org/10.18653/v1/n19-1035

[30] Tianxiang Sun, Yunfan Shao, Xipeng Qiu, Qipeng Guo, Yaru Hu, Xuan-Jing Huang,
and Zheng Zhang. 2020. CoLAKE: Contextualized Language and Knowledge
Embedding. In Proceedings of the 28th International Conference on Computational
Linguistics. 3660–3670.

[31] Duyu Tang, Bing Qin, and Ting Liu. 2016. Aspect Level Sentiment Classification
with Deep Memory Network. In Proceedings of the 2016 Conference on Empirical
Methods in Natural Language Processing, EMNLP 2016, Austin, Texas, USA, No-
vember 1-4, 2016. 214–224. https://www.aclweb.org/anthology/D16-
1021/

[32] Hao Tang, Donghong Ji, Chenliang Li, and Qiji Zhou. 2020. Dependency graph
enhanced dual-transformer structure for aspect-based sentiment classification.
In Proceedings of the 58th Annual Meeting of the Association for Computational
Linguistics. 6578–6588.

[33] Jialong Tang, Ziyao Lu, Jinsong Su, Yubin Ge, Linfeng Song, Le Sun, and Jiebo
Luo. 2019. Progressive Self-Supervised Attention Learning for Aspect-Level
Sentiment Analysis. In Proceedings of the 57th Conference of the Association for
Computational Linguistics, ACL 2019, Florence, Italy, July 28- August 2, 2019,
Volume 1: Long Papers, Anna Korhonen, David R. Traum, and Lluís Màrquez
(Eds.). Association for Computational Linguistics, 557–566. https://doi.
org/10.18653/v1/p19-1053

[34] Shuai Wang, Sahisnu Mazumder, Bing Liu, Mianwei Zhou, and Yi Chang. 2018.
Target-Sensitive Memory Networks for Aspect Sentiment Classification. In Pro-
ceedings of the 56th Annual Meeting of the Association for Computational Lin-
guistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers.
957–967. https://doi.org/10.18653/v1/P18-1088

[35] Yequan Wang, Minlie Huang, Xiaoyan Zhu, and Li Zhao. 2016. Attention-
based LSTM for Aspect-level Sentiment Classification. In Proceedings of the 2016
Conference on Empirical Methods in Natural Language Processing, EMNLP 2016,
Austin, Texas, USA, November 1-4, 2016. 606–615. https://www.aclweb.
org/anthology/D16-1058/

[36] Bowen Xing and Ivor W. Tsang. 2021. Understand me, if you refer to As-
pect Knowledge: Knowledge-aware Gated Recurrent Memory Network. CoRR
abs/2108.02352 (2021). arXiv:2108.02352 https://arxiv.org/abs/2108.
02352

[37] Lu Xu, Lidong Bing, Wei Lu, and Fei Huang. 2020. Aspect Sentiment Classifi-
cation with Aspect-Specific Opinion Spans. In Proceedings of the 2020 Confer-
ence on Empirical Methods in Natural Language Processing, EMNLP 2020, On-
line, November 16-20, 2020, Bonnie Webber, Trevor Cohn, Yulan He, and Yang
Liu (Eds.). Association for Computational Linguistics, 3561–3567.
https:
//doi.org/10.18653/v1/2020.emnlp-main.288

[38] Heng Yang, Biqing Zeng, Mayi Xu, and Tianxing Wang. 2021. Back to Reality:
Leveraging Pattern-driven Modeling to Enable Affordable Sentiment Dependency
Learning. CoRR abs/2110.08604 (2021). arXiv:2110.08604 https://arxiv.
org/abs/2110.08604

[39] Heng Yang, Biqing Zeng, Jianhao Yang, Youwei Song, and Ruyang Xu. 2021. A
multi-task learning model for Chinese-oriented aspect polarity classification
and aspect term extraction. Neurocomputing 419 (2021), 344–356. https:
//doi.org/10.1016/j.neucom.2020.08.001

[40] Chih-Kuan Yeh, Been Kim, Sercan O Arik, Chun-Liang Li, Tomas Pfister, and
Pradeep Ravikumar. 2019. On completeness-aware concept-based explanations
in deep neural networks. arXiv preprint arXiv:1910.07969 (2019).

[41] Rex Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, and Jure Leskovec. 2019.
Gnnexplainer: Generating explanations for graph neural networks. Advances in
neural information processing systems 32 (2019), 9240.

[42] Chen Zhang, Qiuchi Li, and Dawei Song. 2019. Aspect-based Sentiment Classifi-
cation with Aspect-specific Graph Convolutional Networks. In Proceedings of the
2019 Conference on Empirical Methods in Natural Language Processing and the 9th
International Joint Conference on Natural Language Processing (EMNLP-IJCNLP).
4560–4570.

[43] Yue Zhang and Jiangming Liu. 2017. Attention Modeling for Targeted Sentiment.
In Proceedings of the 15th Conference of the European Chapter of the Association
for Computational Linguistics, EACL 2017, Valencia, Spain, April 3-7, 2017, Volume
2: Short Papers. 572–577. https://www.aclweb.org/anthology/E17-
2091/

[44] Zhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang, Maosong Sun, and Qun Liu.
2019. ERNIE: Enhanced Language Representation with Informative Entities.
In Proceedings of the 57th Annual Meeting of the Association for Computational
Linguistics. 1441–1451.

[45] Pinlong Zhao, Linlin Hou, and Ou Wu. 2020. Modeling sentiment dependen-
cies with graph convolutional networks for aspect-level sentiment classifica-
tion. Knowl. Based Syst. 193 (2020), 105443. https://doi.org/10.1016/j.
knosys.2019.105443

AR-BERT: Aspect-relation enhanced Aspect-level Sentiment Classification with Multi-modal Explanations

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Table 7: Statistics of datasets.

# Positive

# Negative

# Neutral

LAPTOP

Train
Test
REST

987
341

Train
Test
TWITTER

2164
728

Train
Test

1567
174

866
128

805
196

1563
174

460
169

633
196

3127
346

Table 8: Performance comparison of our proposed models
with other competitive models.

Model
LSA+DeBERTa-V3-Large
LCF-ATEPC
ABSA-DeBERTa
RoBERTa+MLP
KaGRMN-DSG
AR-BERT-idd
AR-BERT-S-idd

LAPTOP

REST

86.21
82.29
82.76
83.78
81.87
82.91
83.62

91.07
90.18
89.46
87.37
87.35
90.62
86.61

A APPENDIX
A.1 Data Statistics
The statistics of the three datasets are given in Table 7.

A.2 Implementation Details
Our implementation is based on Tensorflow 1.X and all our experi-
ments were executed on Quadro P5000 Single core GPU (16278MiB)
with CUDA version: 10.0.

A.2.1 Aspect disambiguation. We pass the sentence to the Wikifier
using ‘POST’ method and extract the entity from the annotation of
the maximum sub-string of the aspect. If no annotation is found
we link the retrieved entity as ‘Unknown’.

A.2.2 Knowledge Graph Clustering. We extract the maximum weakly
connected component of the DBPedia Knowledge Graph (KG) by
converting the KG into a SNAP undirected graph2 (fraction of nodes
in maximum weakly connected component: 0.99983). We then clus-
ter the extracted maximum weakly connected component using
hierarchical Louvain graph clustering algorithm. This algorithm
returns a hierarchy tree with 5 levels in less than 40 minutes and
the nodes in each level is as follows:
• level 0: 22504204 nodes
• level 1: 227550 nodes
• level 2: 2938 nodes
• level 3: 769 nodes
• level 4: 606 nodes

A.2.3 Domain Specific BERT pre-training. Similar to [27], we pre-
train the BERT model on the two domain specific publicly available

datasets: Amazon electronics reviews3 for LAPTOP domain and
Yelp restaurants dataset4 for REST domain. We adopt the similar
pre-processing steps of [27] by removing reviews with less than 2
sentences to enable Next Sentence Prediction (NSP) task of BERT
language model. We also removes the reviews from Amazon review
data which appear in the LAPTOP dataset to eliminate training
bias towards those reviews. After pre-processing, we get around
1 million reviews for LAPTOP domain and we sample around 10
million reviews from pre-processed Yelp review dataset for REST
domain. We run the pre-training of BERT model for 30 epochs and
3 epochs for LAPTOP and REST domain respectively to train the
language model with significant large amount of data (equal for
both domains).

A.3 Other Competitive ALSC Models
In this section we compare our proposed models performance with
other competitive ALSC models:

• LSA+DeBERTa-V3-Large [38] This work introduces senti-
ment pattern based sentiment dependency learning frame-
work to model the sentiment dependency between the adja-
cent aspects to learn the aspect polarity of an aspect without
explicit sentiment context.

• LCF-ATEPC [39] This work focuses on multi-task learning
based aspect term extraction and aspect sentiment polarity
classification by introducing local context focusing mecha-
nism.

• ABSA-DeBERTa [28] This work introduces DeBERTa model
(Decoding-enhanced BERT with Disentangled Attention) in
the ALSC task and achieves competitive performance.
• RoBERTa+MLP [5] This work examines the effectiveness
of induced tree from the Pre-trained language model and
utilizes induced tree from fine-tuned RoBERTa on ALSC task
to acheieve competitive performance.

• KaGRMN-DSG [36] This work utilizes both local and global
syntactic representation of aspects combined with knowl-
edge representation of aspects to enhance the overall aspect
representation.

We compare our proposed models performance with other com-
petitive ALSC models in Table 8. Our models stands 2nd and 3rd
for the REST and LAPTOP domain respectively in the recent leader
board for ALSC.

A.4 Additional Results
The extended version of Table 2 is given in Table 9 where we
report the performance of our proposed ALSC models (without
end-to-end training). Table 10 illustrates anecdotal examples of
multi-modal aspect extraction on the three datasets for different
mode importance.

2https://snap.stanford.edu/snappy/doc/reference/graphs.html

3https://nijianmo.github.io/amazon/index.html
4https://www.yelp.com/dataset/download

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Sk Mainul Islam and Sourangshu Bhattacharya

Table 9: Extended experiment results on various datasets(%). The marker * refers to p-value <0.01 when comparing with re-
spective baselines. % in bracket of best performing models implies overall gain wrt. its’ baselines.

Model

Baseline models for ALSC
TNet [15]
TNet-ATT [33]
BERT-base [6]
SDGCN-BERT [45]
BERT-ADA [27]

ALSC with Aspect relation incorporation
AR-TNet (wo end-to-end)
AR-TNet
AR-BERT (wo end-to-end)
AR-BERT
AR-BERT-S (wo end-to-end)
AR-BERT-S

LAPTOP

REST

TWITTER

ACC

Macro-F1 ACC

Macro-F1 ACC

Macro-F1

76.33
77.62
77.69
81.35
80.25

77.89★
78.80★
80.87★
81.73★
81.82★
82.37★

71.27
73.84
72.60
78.34
75.77

72.96★
73.87★
76.13★
77.07★
78.75★
79.21★

79.64
81.53
84.92
83.57
87.89

82.31★
83.40★
88.21★
89.38★
84.64★
85.27★

70.20
72.90
76.93
76.47
81.05

72.97★
73.91★
81.45★
82.47★
77.34★
78.07★

78.17
78.61
78.81
78.54
78.90

79.68★
80.52★
79.83★
80.91★
79.06★
79.67★

77.17
77.72
77.94
77.72
77.97

78.83★
79.79★
79.02★
80.15★
78.36★
78.89★

ALSC with Aspect relation and incorrect disambiguation detection
AR-TNet-idd
AR-BERT-idd

80.09★
82.91★

75.11★
78.31★

AR-BERT-S-idd

Results with explanation concepts
AR-BERT-idd (ℎ (𝑥) = 𝑔 (𝜃𝑇
AR-BERT-S-idd (ℎ (𝑥) = 𝑔 (𝜃𝑇
AR-BERT-idd (𝐺 = 𝐺𝑆 )
AR-BERT-S-idd (𝐺 = 𝐺𝑆 )

𝑐𝑜𝑛ℎ ( (cid:174)𝑥), 𝜃𝑑𝑒𝑐 ))

𝑐𝑜𝑛ℎ ( (cid:174)𝑥), 𝜃𝑑𝑒𝑐 ))

Results with ablations of explanations
AR-BERT-idd (with ˜𝑥)
AR-BERT-S-idd (with ˜𝑥)
AR-BERT-idd (with ˜𝐺)
AR-BERT-S-idd (with ˜𝐺)

83.62★
(+2.79%)

80.43★
(+2.67%)

-
83.38
-
83.54

-
34.48
-
81.09

-
80.25
-
80.41

-
32.43
-
78.15

84.64★
90.62★
(+3.11%)
86.61★

75.17★
83.81★
(+3.40%)
79.37★

81.64★
82.08★
(+4.03%)
80.86★

80.84★
81.21★
(+4.15%)
80.03★

90.18
-
90.36
-

34.13
-
88.01
-

83.39
-
83.57
-

33.25
-
81.11
-

81.50
-
81.94
-

33.81
-
78.75
-

80.64
-
81.07
-

33.17
-
77.67
-

Table 10: Examples of Multi-modal Explanation Extraction. Aspect in the parenthesis, actual label in the subscript, predicted
label around the aspect with proper color code: green for positive, red for negative and yellow for neutral, context explanation
tokens are in blue color.

Sentence

Aspect
-Entity

Explanation
Node

Mode Importance: Context
[Boot time]POS is super fast, around anywhere from 35 seconds to 1 minute.
The [bread]POS is top notch as well.
i like [Britney Spears ]POS new song ... i wan na hear it now = -LRB-
Mode Importance: Both
Did not enjoy the new Windows 8 and [touchscreen functions]NEG.
Touchscreen
Did I mention that the [coffee]POS is OUTSTANDING?
Coffee
RT jaimemorelli : I would love to see a nuanced comparison of [Google]NEU television Google
vs . hooking up my television to a Mac Mini and buying a wireless keyboard

-
-
-

-
-
-

Software(64)
Drink (35)
iPhone (168)

Mode Importance: Graph
I would have given it 5 starts was it not for the fact that it had [Windows 8]NEG
The [food]NEU did take a few extra minutes to come, but the cute waiters’ jokes
and friendliness made up for it.
[Shaquille O’Neal]NEG to miss 3rd straight playoff game |
The ... : shaquille o’neal will miss his third straight play

Windows_8
Food

Software(64)
Food (365)

Shaquille_O’Neal

Los_Angeles_Lakers (157)

