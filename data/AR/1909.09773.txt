Low-Dose CT with Deep Learning Regularization
via Proximal Forward Backward Splitting
Qiaoqiao Ding∗, Gaoyu Chen, Xiaoqun Zhang, Qiu Huang, Hui Ji∗ and Hao Gao∗

9
1
0
2

p
e
S
1
2

]

V

I
.
s
s
e
e
[

1
v
3
7
7
9
0
.
9
0
9
1
:
v
i
X
r
a

Abstract—Low dose X-ray computed tomography (LDCT) is
desirable for reduced patient dose. This work develops image
reconstruction methods with deep learning (DL) regularization
for LDCT. Our methods are based on unrolling of proximal
forward-backward splitting (PFBS) framework with data-driven
image regularization via deep neural networks. In contrast with
PFBS-IR that utilizes standard data ﬁdelity updates via iterative
reconstruction (IR) method, PFBS-AIR involves preconditioned
data ﬁdelity updates that fuse analytical reconstruction (AR)
method and IR in a synergistic way, i.e., fused analytical and
iterative reconstruction (AIR). The results suggest that DL-
regularized methods (PFBS-IR and PFBS-AIR) provided better
reconstruction quality from conventional wisdoms (AR or IR),
and DL-based postprocessing method (FBPConvNet). In addition,
owing to AIR, PFBS-AIR noticeably outperformed PFBS-IR.

Index Terms—X-ray CT, Image reconstruction, Low Dose CT,

Deep Neural Networks

I. INTRODUCTION

L OW dose X-ray computed tomography (LDCT) is desir-

able for reduced patient dose. However, standard analyt-
ical reconstruction (AR) methods often yield low-dose image
artifacts due to reduced signal-to-noise ratio. Thus iterative
reconstruction (IR) methods have been actively explored to
reduce low-dose artifacts for LDCT. In the IR method, the
reconstruction problem is often formulated as an optimization
problem with a data ﬁdelity term and a regularization term. A
popular category of IR in the last decades is via the sparsity
regularization, such as total variation [1]–[3], wavelet tight
frames [4], [5], nonlocal sparsity [6], and low-rank models
[7]–[11].

Recently, deep learning (DL) methods have been studied
extensively for CT image reconstruction. A major difference
among different various DL-based postprocessing methods lies
in the choice of network architecture, e.g., residual network
[12]–[14], U-net [13], [15] and generative adversarial network
(GAN)/Wasserstein-GAN [16], [17]. Instead of deep neural
network (DNN) directly based on reconstructed images in the
image domain, DNN based on the transform coefﬁcients of
reconstructed images in the transform domain can be designed

∗

∗

Q. Ding

(e-mail:
matjh@nus.edu.sg) are with Department of Mathematics, National University
of Singapore, 119076, SINGAPORE

(e-mail: matding@nus.edu.sg)

and H.

Ji

G. Chen and Q. Huang are with School of Biomedical Engineering,

Shanghai Jiaotong University, Shanghai, 200240, CHINA

X. Zhang is with Institute of Natural Sciences and School of Mathematical

Sciences, Shanghai Jiaotong University, Shanghai, 200240, CHINA

H. Gao

(e-mail: hao.gao.2012@gmail.com)

is with Department of
Radiation Oncology, Winship Cancer Institute of Emory University, Atlanta,
Georgia, 30322, USA

∗

for further improvement, e.g., in the wavelet transform [18],
[19].

Alternative to DL-based image postprocessing, DL can be
integrated with image reconstruction. This is often done by
unrolling some iterative optimization schemes and replac-
ing conventional regularization methods with convolutional
neural networks (CNN). In [20], Yang et al. proposed a
DL-regularized method via alternating direction method of
multipliers, ADMM-net, for magnetic resonance (MR) image
reconstruction. In [21], [22], Mardani et al. proposed the prox-
imal methods for MR imaging using GAN. Similar unrolling
methods were also recently proposed for CT reconstruction.
In [23], Chen et al. developed the gradient descent based IR
method that used CNN to learn image regularization for sparse
view CT reconstruction. In [24], Adler et al. proposed an
image reconstruction method by unrolling a proximal primal-
dual optimization method, where the proximal operators were
replaced with CNN. In [25], Gupta et al. replaced the projector
in a projected gradient descent proposed method with a CNN.
In [26], He et al. proposed a DL-based IR method by unrolling
the framework of ADMM for LDCT.

The work will explore DL-regularized image reconstruction
method for LDCT using the framework of proximal forward-
backward splitting (PFBS). Our method will unroll the op-
timization by PFBS with data-driven image regularization
learned by DNN. To further improve image reconstruction
quality, a preconditioned PFBS version will be used with fused
analytical and iterative reconstruction (AIR) [27]. Thus, the
proposed method will integrate AR, IR and DL using the PFBS
framework for LDCT.

A. Preliminaries

II. METHOD

CT image reconstruction problem can be formulated as

solving an ill-posed linear system:

y = Ax + n.

(1)

Here x denotes the attenuation map with xj being the linear
attenuation coefﬁcient in the j-th pixel for j = 1, · · · , Np
and Np denotes the total number of pixels; y represents the
measured projection after correction and log transform. The
matrix A is the Nd × Np system matrix with entries aij,
Np
and [Ax]i =
j=1 aij xj denotes the line integral of the
attenuation map x along the i-th X-ray with i = 1 · · · Nd.
CT image reconstruction problem is to recover the unknown
image x, provided the system matrix A and the projection
data y in the presence of measurement noise n.

P

 
 
 
 
 
 
Although AR is fast, it suffers from the low-dose artifacts.
Alternatively, IR for image reconstruction with ﬂexible models
for both data ﬁdelity and image regularization. In its general
form, IR is formulated as solving the optimization problem:

Rλ(y) = arg min

x

L(Ax, y) + λψ(x).

(2)

Here the ﬁrst term L(Ax, y) is the data ﬁdelity term, where
x and y are elements in appropriate function space X and
Y and the forward operator is a mapping A : X → Y ; the
second term ψ(x) is the image regularization that imposes
certain prior knowledge on the image x. Rλ : Y → X denotes
the reconstruction operator with the regularization parameter
λ. For Gaussian modeled noise n weighted by W , the data
ﬁdelity term is given by

Thus, (2) can be solved by the following two-step algorithm

2

2 = xk − αA+(Axk − y),

xk+ 1
xk+1 = Proxαλψ(xk+ 1

2 ),

(

(10a)

(10b)

where A+ is the approximate of the pseudo inverse of A. For
example, if AAT and/or AT A do not exist, A+ is set as the
Moore-Penrose pseudo inverse of A, i.e.

lim
ε→0

(AT A + εI)

AT (AT A + εI)

−1AT = lim
ε→0
More precisely, A+ can be set as AR operator. The conver-
gence property of the preconditioned PFBS algorithm (10)
have been given in [27].

−1 = A+.

L(Ax, y) =

1
2

kAx − yk2

W .

(3)

C. DL-Regularized PFBS

B. Proximal Forward Backward Splitting

Operator splitting methods have been extensively studied
in the optimization community, e.g. [28]–[30]. They aim to
minimize the sum of two convex functions

min
x

L(x) + λψ(x).

(4)

The forward-backward technique based on the proximal op-
erator for general signal recovery tasks was introduced by
Combettes and Wajs. The proximal operator of a convex
functional ψ, which was originally introduced by Moreau in
[31], is deﬁned as

Proxλψ(·) = arg min
x

λψ(x) +

kx − ·k2
2.

(5)

1
2

By classic arguments of convex analysis, the solution of (4)
satisﬁes the condition

0 ∈ ∂L(x) + λ∂ψ(x).

For a positive number α, we obtain:

0 ∈ (x + αλ∂ψ(x)) − (x − α∂L(x)).

This lead to a forward and backward splitting algorithm:

xk+1 = Proxαλψ(xk − α∂L(xk)).

(6)

(7)

(8)

The forward and backward splitting algorithm (8) is equiv-

alent to




xk+ 1

2 = arg min

L(x),

x
xk+1 = arg min
x

αλψ(x) +

kx − xk+ 1

2 k,

1
2

(9a)

(9b)

where the ﬁrst subproblem is solved by gradient descent
method with initial value xk and step size α,



xk+ 1

2 = xk − αAT (Axk − y).

Inspired by Newton’s method, we consider the preconditioned
gradient descent [32] in reconstruction problem (2):

xk+ 1

2 = xk − αA+(Axk − y),

where A+ is the pseudo-inverse of A. The operator A+A is
an orthogonal projector onto the range space of A+

We present a new image reconstruction method that unrolls
PFBS with data-driven image regularization via DNN for
LDCT.

The aim of unrolling is to ﬁnd a DNN architecture Rθ :
Y → X that is suitable for approximating the operator Rλ :
Y → X deﬁned via PFBS iterative scheme. Unrolled iterative
scheme of the preconditioned PFBS algorithm consists of in
two steps. Firstly, by unrolling the k-th gradient-descent step
for data ﬁdelity of (10), we have
xk+ 1

(xk, A+(Axk − y)),

(11)

2 = Λθ1

k

k

: X × X → X is a learned operator. The learned
where Λθ1
kz,
updating in a gradient descent scheme, Λθ1
implies the step length is also learned and varies with itera-
tions.

(x, z) = x − θ1

k

Secondly, by replacing the proximal operator with a learned

operator, it yields:

xk+1 := Λθ2

k

(xk+ 1

2 , xk).

(12)

k

In equation (12), Λθ2
parameters to model Λθ2
2 , · · · xk− 1
2 , x1+ 1
xk = (x
operator in (10) is a mapping from xk+ 1
formulation of (10b), we can naturally set (12) as

: X × X k → X is a CNN with learned
that replaces the proximal of (10) and
2 ) ∈ X k. In reality, the proximal
2 to xk+1. By the

k

1

CNN(·, θ2

k) : xk+ 1

2 → xk+1.

(13)

1

2 , x1+ 1

2 , · · · xk+ 1

the applied CNN is modiﬁed by concatenating
In fact,
the latent
the in-
image as
all previous estimates of
put. We replace CNN(xk+ 1
2 , θ2
k) with a densely-connected
2 ], θ2
CNN([x
k) [33], [34], which was utilized
in our previous work for sparse-data CT [35] and shown
to outperform the standard CNN. The problem of vanishing
gradient can be addressed by the modiﬁcation. Thus, we
replace the proximal operator with learnable parameters as
(12).

To summarize, the preconditioned PFBS based unrolling

scheme is as follows.
xk+ 1
2 = Λθ1
xk+1 = Λθ2

(

k

k

(xk, A+(Axk − y)),
(xk+ 1

2 , xk).

(14a)

(14b)

3

After training the weights of the NN, we obtain an estima-
tion of θ. For a low dose input data y, the image can be
reconstructed by applying CNN([x
k) and
gradient descent, Λθ1

2 ], θ2
2 , x
(xk, A+(Axk − y)), alternatively:
kA+(Axk − y)

y → A+y → · · · → xk − θ1

2 · · · xk+ 1

k

1

3

→ CNN([x

1

2 , x1+ 1

2 · · · xk+ 1

2 ], θ2

k) → xk+1 · · · x∗,

where k = 0, · · · K − 1 and x∗ is the predicted image.

The training is performed with PyTorch [36] interface on
a NVIDIA Titan GPU. Adam optimizer is used with the
momentum parameter β = 0.9, mini-batch size set to be 4,
and the learning rate set to be 10−4. At each stage, we use a
standard CNN with the structure Conv→BN→ReLU, except
the ﬁrst block and the last block. The BN layer is omitted for
the ﬁrst and last block. For all the Conv layers in the CNN,
the kernel size is set as 3×3. The channel size is set to 64 and
the outline of CNN is shown as Fig. 2. The model is trained
with 50 epochs.

III. RESULTS

In this section, the proposed PFBS-IR and PFBS-AIR meth-
ods are evaluated using prostate CT dataset, in comparison
with TV-based IR method and a DL-based image postpro-
cessing method, namely FBPConvNet.

A. Data

To validate the performance of the proposed methods at
different dose levels, we simulated low dose projection data
from their normal-dose counterparts. The normal dose dataset
included 6400 normal-dose prostate CT images of 256 × 256
pixels per image from 100 anonymized scans. The LDCT
projection data were simulated by adding Poisson noise onto
the normal-dose projection data [37]:

¯yi ∼ Poisson{Ii exp(−[Ax]i)} + Normal(0, σ2

e ),

(20)

where Ii
is the incident X-ray intensity incorporating X-
ray source illumination and the detector efﬁciency, σ2
e is the
background electronic noise variance. The value of σ2
e was
assumed to be stable for a commercial CT scanner, and thus,
the noise level was controlled by Ii

The simulated geometry for projection data include: ﬂat-
panel detector of 0.388 mm × 0.388 mm pixel size, 600
projection views evenly spanning a 360◦ circular orbit, 512
detector bins for each projection, 100.0 cm source to detector
distance and 50.0 cm source to isocenter distance. In the
simulation, the noise level is controlled by X-ray intensity Ii,
which is set uniformly, i.e. , I1 = Ii, i = 1, · · · Nd. The noise
level was set to be uniform, i.e., Ii = 105, 5×104, 104, 5×103
respectively. Then, the projection data for reconstruction were
obtained by taking logarithm on projection data ¯y. 80 scans
were included in the training set, and the rest 20 scans were
included in the testing set.

In the iteration scheme (14), xk+ 1
2 and xk+1 are two interme-
diate iterates, where xk+ 1
2 is from the data ﬁdelity speciﬁc to
the reconstruction problem, and xk+1 is from the learning that
is data-driven. In each iteration, during the gradient descent
step (14a), the image is projected to the data domain to form
the data residual, and then backprojected to the image domain
by an AR operator, A+, to form a residual image, which is
then weighted together with previous image iterate to generate
the current image iterate; during the proximal step (14b), all
previous estimates of the image are concatenated to learn the
image priors from the training data.

Then the truncated scheme after K iterates amounts to
K−1)

K−1, θ2

0, · · · θ1

0, · · · θ2

deﬁning Rθ : Y → X with θ = (θ1
as
Rθ(y) := xK = (Λθ2

K−1 ◦ Λθ1

K−1 · · · Λθ2

0 ◦ Λθ1

0 )(x0, Ax0 − y).

(15)
The initial value x0 is set as A+y. There are totally K
stages and each stage corresponds to a outer iteration in the
scheme (10). See Fig. 1 for the diagram of the proposed
method, named PFBS-IR or PFBS-AIR, for reconstruction
LDCT images.

D. Implementation Details
The best choice of
0, · · · θ2

K−1) and
step lengths
(θ2
K−1) with K iterations can be obtained by end-to-
end supervised training. Let {xj, yj}J
j=1 denote the training
dataset with J training samples, where (xj, yj) ∈ X × Y
denotes the pair of normal dose image and low dose projection
data. Then, the parameter θ is solved by the minimization

0 · · · θ1

(θ1

J

Lθ(xj, yj),

(16)

min
θ

1
J

j=1
X

where the loss function is given as
Lθ(x, y) := kRθ(y) − xk2

X for (x, y) ∈ X × Y.

To obtain the parameter θ, the back-propagation computations
through all of the unrolled iterations are needed.

During the train process, we need to calculate gradients

about (θ1

0, · · · , θ1

K−1) and (θ2

=

=

∂Lθ
∂xK ·
∂Lθ
∂xK ·

∂Lθ
∂θ2
k
∂Lθ
∂θ2
k
where,

2

∂xK
∂xK− 1
∂xK
∂xK− 1

2

· · ·

· · ·

2

0, · · · , θ2
∂xk+2
∂xk+ 3
∂xk+2
∂xk+ 3

K−1),
∂xk+ 3
∂xk+1 ·
∂xk+ 3
∂xk+1 ·

·

·

2

2

2

∂xk+1
∂θ2
k
∂xk+1
∂θ2
k

, (17)

, (18)

2 · · · xk+ 1

2 ], θ2
k)

1

2 , x1+ 1
∂θ2
k

,

(19a)

(19b)

(19c)

= A+(y − Axk),

∂CNN([x

2

=

∂xk+1
∂θ2
k
∂xk+ 1
∂θ1
k
∂xk+ 1
∂xk = I − θ1
∂xk+1
=
∂xk+ 1
∂Lθ
∂xK = (xK − x).

2

2

∂CNN([x

kA+A,






3

2 · · · xk+ 1

2 ], θ2
k)

1

2 , x
∂xk+ 1

2

B. Methods for comparison

,

(19d)

(19e)

The performance of the proposed methods is evaluated in
comparsion with FBP (an AR method), TV (an IR method)
and FBPConvNet (a DL-based image postprocessing method).

Stage:1

x0

A+y

Λθ1

0 (x0, A+

Ax0 − y

)

(cid:0)

(cid:1)

Sinogram y

1
2

x

Λθ2

0 (x

1
2 )

x1

Stage:K

xK− 1

2

Λθ1

K−1(x

K−1

, A+

Ax

K−1

− y

)

(cid:16)

(cid:17)

4

xK

1

2 , x1+ 1

2 · · · xK− 1
2 ]

[x
K−1(xK− 1

Λθ2

2 , xK−1)

Reconstructed image xK

Fig. 1: Diagram of the proposed PFBS-(A)IR net for LDCT image reconstruction.

1
2
3
2

x
x
...
xk+ 1

2

xk+ 1

2

C
o
n
v

R
e
L
U

C
o
n
v

B
N

R
e
L
U

C
o
n
v

B
N

R
e
L
U

C
o
n
v

R
e
L
U

−

xk+1

k × 64

64 × 64

64 × 64

64 × 1

Fig. 2: Diagram of CNN in Fig. 1.

1) TV-based IR method: The TV-based IR method was

solved by ADMM:

1

2 kAx − yk2
xk+1 = arg minx
zk+1 = arg minz λkzk1 + µ
pk+1 =




pk + µ(∇xk+1 − zk+1),

2 + µ
2 kz − (∇xk+1 + pk

2 k∇x − zk + pk
µ k2
2,
µ )k2
2,

where z is the auxiliary variable, p is the dual variable, µ is

the algorithm parameter and ∇ is the gradient operator. The
parameters λ, µ of the TV-based IR method were manually
optimized. Speciﬁcally, the regularization parameter λ for the
TV-based IR method was set to 0.01 for Ii = 105 and Ii =
5 × 104, 0.03 for Ii = 104 and 0.05 for Ii = 5 × 103, which
yielded the best performance.

2) FBPConvNet: FBPConvNet [15] is a state-of-the-art DL
technique, in which a residual CNN with U-net architecture
is trained to directly denoise the FBP. It has been shown to
outperform other DL-based methods for CT reconstruction.

C. Results

For our methods, we set K = 10. For every stage, 5-block
modiﬁed CNN is applied. For PFBS-AIR, A+ is set to be the
FBP operator, while for PFBS-IR, A+ = AT .

The three metrics, peak signal to noise ratio (PSNR), root
mean square error (RMSE) and structural similarity index
measure (SSIM) [38], are chosen for quantitative evaluation
of image quality. PSNR is deﬁned as

PSNR(x, x∗

) = 10 log10

max(x. ∗ x)
kx − x∗k2

2 (cid:19)

(cid:18)

,

(21)

where .∗ denotes element-wise multiplication, x∗ is the recon-
structed image and x is the ground truth (normal dose image).
RMSE is deﬁned as

RMSE =

s

N

i=1(x∗
i − xi)2
N

,

(22)

P
where N is the number of pixels and i is the pixel index.

The quantitative results for the reconstructed images are
given in Table I. Table I shows the means and standard
deviations (STD) of PSNR, RMSE and SSIM for all the
images reconstructed with different low dose levels. The table
suggests that our method achieved superior performance for
all low-dose levels. TV had larger PSNRs, smaller RMSEs
and larger SSIMs than FBP method as expected. The DL-
based methods improved the reconstructed results from FBP
and TV, among which PFBS-AIR had the best reconstruction
quality in terms of PSNR, RMSE and SSIM.

A representative slice from all methods is showed in Fig. 3
with the dose level Ii = 5 × 104. The displayed window is set
to [−150, 150]HU for all Figures. And their zoomed-in images
are presented in Fig. 3 indicated by the arrows in Fig. 3, while
FBPConvNet and PFBS-IR method were blurred, PFBS-AIR
had superior reconstruction quality.

NDCT

FBP

TV

FBPConvNet

PFBS-IR

PFBS-AIR

Fig. 3: Reconstruction results at dose level Ii = 5 × 104.

With further reduced dose, Fig. 5 and Fig. 7 show images
reconstructed with dose level of Ii = 104 and Ii = 5 × 103,
respectively. And the corresponding zoomed-in images are
displayed in Fig. 6 and Fig. 8. These Figures suggest PFBS-

Dose level

Ii = 105

Ii = 5 × 104

Ii = 104

Ii = 5 × 103

PSNR
RMSE
SSIM
PSNR
RMSE
SSIM
PSNR
RMSE
SSIM
PSNR
RMSE
SSIM

TABLE I: Quantitative reconstruction results for all images.
PFBS-IR
45.9053 ± 1.4028
1.4028 ± 0.0021
0.9974 ± 0.0007
43.9504 ± 1.4784
0.0026 ± 0.0002
0.9947 ± 0.0008
42.6190 ± 1.4974
0.0031 ± 0.0003
0.9925 ± 0.0013
41.9751 ± 1.5488
0.0033 ± 0.0004
0.9923 ± 0.0018

TV
44.9089 ± 1.4348
0.0023 ± 0.0002
0.9971 ± 0.0007
43.5493 ± 1.4465
0.0027 ± 0.0003
0.9954 ± 0.0013
39.8860 ± 1.5873
0.0041 ± 0.0005
0.9881 ± 0.0039
38.2131 ± 1.6229
0.0050 ± 0.0007
0.9827 ± 0.0059

FBPConvNet
47.0168 ± 1.4717
0.0018 ± 0.0002
0.9975 ± 0.0007
45.9569 ± 1.4759
0.0021 ± 0.0003
0.9965 ± 0.0009
43.2968 ± 1.5592
0.0028 ± 0.0003
0.9942 ± 0.0014
41.6542 ± 1.5140
0.0034 ± 0.0004
0.9922 ± 0.0017

FBP
41.6739 ± 1.4145
0.0033 ± 0.0002
0.9933 ± 0.0008
40.5805 ± 1.4185
0.0038 ± 0.0003
0.9902 ± 0.0017
35.9736 ± 1.5382
0.0066 ± 0.0008
0.9636 ± 0.0093
33.2052 ± 1.5943
0.0092 ± 0.0012
0.9288 ± 0.0187

5

PFBS-AIR
50.1927 ± 1.7112
0.0013 ± 0.0002
0.9986 ± 0.0005
49.2162 ± 1.7964
0.0014 ± 0.0002
0.9983 ± 0.0007
45.7214 ± 1.7246
0.0021 ± 0.0003
0.9964 ± 0.0011
44.0442 ± 1.7250
0.0026 ± 0.0004
0.9951 ± 0.0015

NDCT

FBP

TV

FBPConvNet PFBS-IR PFBS-AIR

Fig. 4: Zoom-in reconstruction results at dose level Ii =
5 × 104. Three rows from up to bottom correspond to the
red, yellow and blue boxes in Figure 3 respectively, with
differences highlighted in arrows.

AIR once again had the best reconstruction quality.

On the other hand, the quantitative results corresponding to
Fig. 3 , Fig. 5, and Fig. 7 are listed in Table II, Table III and
Table IV respectively, which also shows the best performance
if PFBS-AIR in terms of PSNR, RMSE, and SSIM.

NDCT

FBP

TV

FBPConvNet

PFBS-IR

PFBS-AIR

Fig. 5: Reconstruction results at dose level Ii = 104.

TABLE II: Quantitative reconstruction results for the image
slice in Fig. 3.
Dose level

Ii = 105

Ii = 5 × 104

Ii = 104

Ii = 5 × 103

PSNR
RMSE
SSIM
PSNR
RMSE
SSIM
PSNR
RMSE
SSIM
PSNR
RMSE
SSIM

FBP
42.4985
0.0031
0.9936
41.2469
0.0036
0.9904
36.3060
0.0066
0.9638
33.3903
0.0094
0.9280

TV
45.9763
0.0021
0.9972
44.4369
0.0026
0.9953
40.4774
0.0041
0.9874
38.8149
0.0051
0.9816

FBPConvNet PFBS-IR
46.8933
47.8269
0.0021
0.0019
0.9974
0.9976
45.0650
46.8502
0.0026
0.0021
0.9949
0.9966
43.2313
43.8588
0.0031
0.0029
0.9921
0.9940
42.5498
41.3073
0.0034
0.0036
0.9913
0.9912

PFBS-AIR
51.5252
0.0013
0.9986
50.6984
0.0014
0.9984
45.3091
0.0022
0.9963
45.1596
0.0027
0.9944

TABLE III: Quantitative reconstruction results for the image
slice in Fig. 5.
Dose level

Ii = 105

Ii = 5 × 104

Ii = 104

Ii = 5 × 103

PSNR
RMSE
SSIM
PSNR
RMSE
SSIM
PSNR
RMSE
SSIM
PSNR
RMSE
SSIM

FBP
39.0351
0.0038
0.9930
38.1533
0.0042
0.9903
34.6438
0.0064
0.9689
32.0027
0.0087
0.9415

TV
42.8197
0.0025
0.9832
41.6874
0.0028
0.9887
38.3544
0.0042
0.9954
36.0595
0.0052
0.9968

FBPConvNet PFBS-IR
44.0438
44.7526
0.0022
0.0020
0.9970
0.9966
41.3381
43.4913
0.0029
0.0023
0.9937
0.9960
40.0446
40.7496
0.0034
0.0031
0.9911
0.9928
39.2485
38.8226
0.0036
0.0038
0.9903
0.9899

PFBS-AIR
48.1220
0.0014
0.9985
46.6175
0.0016
0.9980
43.0824
0.0024
0.9955
41.0346
0.0029
0.9937

IV. CONCLUSION

We have developed a DL-regularized image reconstruction
method for LDCT, using the optimization framework of PFBS,
with (A)IR for preconditioned data-ﬁdelity update, namely
PFBS-(A)IR. The preliminary results suggest PFBS-AIR had
superior reconstruction quality over FBP (an AR method),
TV (an IR method), FBPConvNet (a DL-based image post-
processing method), and PFBS-IR (a DL-regularized image

reconstruction method), owing to the synergistic integration
of AR, IR, and DL for LDCT.

REFERENCES

[1] X. Zhang and J. Froment, “Total variation based fourier reconstruction
and regularization for computer tomography,” in Nuclear Science Sym-
posium Conference Record, 2005 IEEE, vol. 4, pp. 2332–2336, IEEE,
2005.

6

NDCT

FBP

TV

FBPConvNet PFBS-IR PFBS-AIR

NDCT

FBP

TV

FBPConvNet PFBS-IR PFBS-AIR

Fig. 6: Zoom-in reconstruction results at dose level Ii = 104.
Three rows from up to bottom correspond to the red, yellow
and blue boxes in Fig. 5 respectively, with differences high-
lighted in arrows.

Fig. 8: Zoom-in reconstruction results at dose level Ii = 5 ×
103. Three rows from up to bottom correspond to the red,
yellow and blue boxes in Fig. 7 respectively, with differences
highlighted in arrows.

NDCT

FBP

TV

FBPConvNet

PFBS-IR

PFBS-AIR

Fig. 7: Reconstruction results at dose level Ii = 5 × 103.

[2] E. Y. Sidky and X. Pan, “Image reconstruction in circular cone-beam
total-variation minimization,”

computed tomography by constrained,
Physics in Medicine & Biology, vol. 53, no. 17, p. 4777, 2008.

[3] G. Chen, J. Tang, and S. Leng, “Prior image constrained compressed
sensing (PICCS): a method to accurately reconstruct dynamic CT
images from highly undersampled projection data sets,” Medical physics,
vol. 35, no. 2, pp. 660–663, 2008.

[4] X. Jia, B. Dong, Y. Lou, and S. B. Jiang, “GPU-based iterative cone-
beam CT reconstruction using tight frame regularization,” Physics in
Medicine & Biology, vol. 56, no. 13, p. 3787, 2011.

[5] H. Gao, R. Li, Y. Lin, and L. Xing, “4D cone beam CT via spatiotem-
poral tensor framelet,” Medical physics, vol. 39, no. 11, pp. 6943–6946,
2012.

[6] X. Jia, Y. Lou, B. Dong, Z. Tian, and S. Jiang, “4D computed
tomography reconstruction from few-projection data via temporal non-
local regularization,” in International Conference on Medical Image
Computing and Computer-Assisted Intervention, pp. 143–150, Springer,
2010.

TABLE IV: Quantitative results for the image slice in Fig. 7.

Dose level

Ii = 105

Ii = 5 × 104

Ii = 104

Ii = 5 × 103

PSNR
RMSE
SSIM
PSNR
RMSE
SSIM
PSNR
RMSE
SSIM
PSNR
RMSE
SSIM

FBP
39.1532
0.0036
0.9925
37.9938
0.0041
0.9889
33.4855
0.0072
0.9588
30.1080
0.0102
0.9185

TV
42.1400
0.0025
0.9961
40.7044
0.0030
0.9938
36.6776
0.0048
0.9839
35.0597
0.0058
0.9763

FBPConvNet PFBS-IR
42.6736
43.4265
0.0025
0.0023
0.9961
0.9963
40.6097
42.3560
0.0031
0.0025
0.9934
0.9949
39.2662
39.7747
0.0037
0.0035
0.9896
0.9913
37.7930
37.4600
0.0041
0.0042
0.9880
0.9879

PFBS-AIR
46.3518
0.0016
0.9978
44.9094
0.0019
0.9970
41.4380
0.0028
0.9939
39.8136
0.0033
0.9919

[7] H. Gao, J. Cai, Z. Shen, and H. Zhao, “Robust principal compo-
nent analysis-based four-dimensional computed tomography,” Physics
in Medicine & Biology, vol. 56, no. 11, p. 3181, 2011.

[8] H. Gao, H. Yu, S. Osher, and G. Wang, “Multi-energy CT based on
a prior rank, intensity and sparsity model (PRISM),” Inverse problems,
vol. 27, no. 11, p. 115012, 2011.

[9] J. Cai, X. Jia, H. Gao, S. B. Jiang, Z. Shen, and H. Zhao, “Cine cone
beam CT reconstruction using low-rank matrix factorization: algorithm
and a proof-of-principle study,” IEEE transactions on medical imaging,
vol. 33, no. 8, pp. 1581–1591, 2014.

[10] G. Chen and Y. Li, “Synchronized multiartifact reduction with tomo-
graphic reconstruction (SMART-RECON): A statistical model based
iterative image reconstruction method to eliminate limited-view artifacts
and to mitigate the temporal-average artifacts in time-resolved CT,”
Medical physics, vol. 42, no. 8, pp. 4698–4707, 2015.

[11] H. Gao, Y. Zhang, L. Ren, and F. Yin, “Principal component reconstruc-
tion (PCR) for cine CBCT with motion learning from 2D ﬂuoroscopy,”
Medical physics, vol. 45, no. 1, pp. 167–177, 2018.

[12] H. Chen, Y. Zhang, M. K. Kalra, F. Lin, Y. Chen, P. Liao, J. Zhou, and
G. Wang, “Low-dose CT with a residual encoder-decoder convolutional
neural network,” IEEE transactions on medical imaging, vol. 36, no. 12,
pp. 2524–2535, 2017.

[13] Y. S. Han, J. Yoo, and J. C. Ye, “Deep residual learning for compressed
sensing CT reconstruction via persistent homology analysis,” arXiv
preprint arXiv:1611.06391, 2016.

[14] H. Li and K. Mueller, “Low-dose CT streak artifacts removal using
deep residual neural network,” in Proc. Fully Three-Dimensional Image
Reconstruction Radiol. Nucl. Med.(Fully3D), pp. 191–194, 2017.
[15] K. H. Jin, M. T. McCann, E. Froustey, and M. Unser, “Deep con-
volutional neural network for inverse problems in imaging,” IEEE
Transactions on Image Processing, vol. 26, no. 9, pp. 4509–4522, 2017.
[16] J. M. Wolterink, T. Leiner, M. A. Viergever, and I. Iˇsgum, “Genera-
tive adversarial networks for noise reduction in low-dose CT,” IEEE
transactions on medical imaging, vol. 36, no. 12, pp. 2536–2545, 2017.
[17] Q. Yang, P. Yan, Y. Zhang, H. Yu, Y. Shi, X. Mou, M. K. Kalra,
Y. Zhang, L. Sun, and G. Wang, “Low-dose CT image denoising using a
generative adversarial network with wasserstein distance and perceptual

7

loss,” IEEE transactions on medical imaging, vol. 37, no. 6, pp. 1348–
1357, 2018.

[18] E. Kang, J. Min, and J. C. Ye, “A deep convolutional neural network us-
ing directional wavelets for low-dose X-ray CT reconstruction,” Medical
physics, vol. 44, no. 10, pp. e360–e375, 2017.

[19] J. Gu and J. C. Ye, “Multi-scale wavelet domain residual

learning
for limited-angle CT reconstruction,” in Proc. Fully Three-Dimensional
Image Reconstruction Radiol. Nucl. Med.(Fully3D), pp. 443–447, 2017.
[20] J. Sun, H. Li, Z. Xu, et al., “Deep ADMM-Net for compressive sensing
MRI,” in Advances in neural information processing systems, pp. 10–18,
2016.

[21] M. Mardani, E. Gong, J. Y. Cheng, S. Vasanawala, G. Zaharchuk, M. Al-
ley, N. Thakur, S. Han, W. Dally, J. M. Pauly, et al., “Deep generative
adversarial networks for compressed sensing automates MRI,” arXiv
preprint arXiv:1706.00051, 2017.

[22] M. Mardani, H. Monajemi, V. Papyan, S. Vasanawala, D. Donoho,
and J. Pauly, “Recurrent generative adversarial networks for proximal
learning and automated compressive image recovery,” arXiv preprint
arXiv:1711.10046, 2017.

[23] H. Chen, Y. Zhang, Y. Chen, J. Zhang, W. Zhang, H. Sun, Y. Lv,
P. Liao, J. Zhou, and G. Wang, “LEARN: Learned experts’ assessment-
based reconstruction network for sparse-data CT,” IEEE transactions on
medical imaging, vol. 37, no. 6, pp. 1333–1347, 2018.

[24] J. Adler and O.

¨Oktem, “Learned primal-dual reconstruction,” IEEE
transactions on medical imaging, vol. 37, no. 6, pp. 1322–1332, 2018.
[25] H. Gupta, K. H. Jin, H. Q. Nguyen, M. T. McCann, and M. Unser,
“CNN-based projected gradient descent for consistent CT image re-
construction,” IEEE transactions on medical imaging, vol. 37, no. 6,
pp. 1440–1453, 2018.

[26] J. He, Y. Yang, Y. Wang, D. Zeng, Z. Bian, H. Zhang, J. Sun, Z. Xu, and
J. Ma, “Optimizing a parameterized plug-and-play ADMM for iterative
low-dose CT reconstruction,” IEEE transactions on medical imaging,
vol. 38, no. 2, pp. 371–382, 2018.

[27] H. Gao, “Fused analytical and iterative reconstruction (AIR) via mod-
iﬁed proximal forward–backward splitting: a fdk-based iterative image
reconstruction example for CBCT,” Physics in Medicine & Biology,
vol. 61, no. 19, p. 7187, 2016.

[28] P. L. Combettes and V. R. Wajs, “Signal recovery by proximal forward-
backward splitting,” Multiscale Modeling & Simulation, vol. 4, no. 4,
pp. 1168–1200, 2005.

[29] J. Eckstein and D. P. Bertsekas, “On the douglas rachford splitting
method and the proximal point algorithm for maximal monotone op-
erators,” Mathematical Programming, vol. 55, no. 1-3, pp. 293–318,
1992.

[30] R. Glowinski and P. Le Tallec, Augmented Lagrangian and operator-

splitting methods in nonlinear mechanics, vol. 9. SIAM, 1989.

[31] J. J. Moreau, “Fonctions convexes duales et points proximaux dans un

espace hilbertien,” 1962.

[32] X. Zhang, M. Burger, X. Bresson, and S. Osher, “Bregmanized non-
local regularization for deconvolution and sparse reconstruction,” SIAM
Journal on Imaging Sciences, vol. 3, no. 3, pp. 253–276, 2010.
[33] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, “Densely
connected convolutional networks,” in Proceedings of the IEEE confer-
ence on computer vision and pattern recognition, pp. 4700–4708, 2017.
[34] Z. Zhang, X. Liang, X. Dong, Y. Xie, and G. Cao, “A sparse-view
CT reconstruction method based on combination of DenseNet and
deconvolution,” IEEE transactions on medical imaging, vol. 37, no. 6,
pp. 1407–1417, 2018.

[35] G. Chen, X. Hong, Q. Ding, Y. Zhang, H. Chen, S. Fu, Y. Zhao,
X. Zhang, H. Ji, G. Wang, Q. Huang*, and H. Gao, “AirNet: Fused
Analytical and Iterative Reconstruction with Densely Connected Deep
Neural Networks for Sparse-Data CT,” Submitted.

[36] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin,
A. Desmaison, L. Antiga, and A. Lerer, “Automatic differentiation in
pytorch,” 2017.

[37] Q. Ding, Y. Long, X. Zhang, and J. A. Fessler, “Statistical

image
reconstruction using mixed poisson-gaussian noise model for X-ray CT,”
arXiv preprint arXiv:1801.09533, 2018.

[38] Z. Wang, A. C. Bovik, H. R. Sheikh, E. P. Simoncelli, et al., “Image
quality assessment: from error visibility to structural similarity,” IEEE
transactions on image processing, vol. 13, no. 4, pp. 600–612, 2004.

