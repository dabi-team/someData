1
2
0
2

g
u
A
0
1

]

R
C
.
s
c
[

1
v
3
7
2
8
0
.
8
0
1
2
:
v
i
X
r
a

User configurable 3D object regeneration for spatial privacy

Arpit Nama‚àó
University of Sydney
Sydney, Australia
anam9745@uni.sydney.edu.au

Amaya Dharmasiri‚àó
University of Moratuwa
Colombo, Sri Lanka
170131R@uom.lk

Kanchana Thilakarathna
University of Sydney
Sydney, Australia
kanchana.thilakarathna@sydney.edu.au

Albert Zomaya
University of Sydney
Sydney, Australia
albert.zomaya@sydney.edu.au

Jaybie Agullo de Guzman
University of the Philippines Diliman
Quezon City, Philippines
jaybie.de.guzman@eee.upd.edu.ph

Figure 1: Overview of the proposed user configurable privacy framework for 3D point cloud sharing.

ABSTRACT
Environmental understanding capability of augmented (AR) and
mixed reality (MR) applications and devices are continuously im-
proving through advances in sensing, computer vision, and machine
learning. Various AR/MR applications have been developed that
demonstrate such capabilities: i.e. scanning a space using a hand-
held or head mounted device and capturing a digital representation
of the space that are undeniably accurate copies of the real space.
However, these capabilities impose privacy risks to users: person-
ally identifiable information can leak from captured 3D maps of
the sensitive spaces and/or captured sensitive objects within the
mapped space. Thus, in this work, we demonstrate how we can
leverage 3D object regeneration for preserving privacy of 3D point
clouds. That is, we employ an intermediary layer of protection to
transform the 3D point cloud before providing it to the third-party
applications. Specifically, we use an existing adversarial autoen-
coder to generate copies of 3D objects where the likeness of the
copies from the original can be varied. To test the viability and
performance of this method as a privacy preserving mechanism,
we use a 3D classifier to classify and identify these transformed
point clouds: i.e. perform super-class and intra-class classification.
To measure the performance of the proposed privacy framework,
we define privacy, Œ† ‚àà [0, 1], and utility metrics, ùëÑ ‚àà [0, 1], which
are desired to be maximized. Experimental evaluation shows that
the proposed privacy framework can indeed variably effect the
privacy of a 3D object by varying the privilege level ùëô ‚àà [0, 1]: i.e. if
a low ùëô < 0.17 is maintained, Œ†1, Œ†2 > 0.4 is ensured where Œ†1, Œ†2
are the super- and intra-class privacy. Lastly, the proposed privacy

‚àóThe first two authors contributed equally to the paper.

framework can ensure relatively high intra-class privacy and utility,
i.e. Œ†2 > 0.63 and ùëÑ > 0.70, if the privilege level is kept within the
range of 0.17 < ùëô < 0.25.

CCS CONCEPTS
‚Ä¢ Human-centered computing ‚Üí Mixed / augmented reality;
‚Ä¢ Security and privacy ‚Üí Information accountability and usage
control; Privacy protections.

KEYWORDS
mixed or augmented reality, privacy, 3D point clouds, point cloud
classification, and adversarial autoencoders

1 INTRODUCTION
Advanced camera systems capable of mapping 3D spatial informa-
tion is increasingly becoming popular among consumer devices.1
These improved camera systems support the recent developments
in mixed reality (MR) technology particularly in improving environ-
mental understanding capability: i.e. scan a space using a handheld
or head mounted device and, then, capture a digital representation
or mapping (i.e. spatial maps or 3D point clouds) of the space that
are undeniably accurate copies of the real space. This enables MR
applications to deliver realistic MR experiences, i.e. rendering vir-
tual augmentations that seemingly inhabit the real and physical
space.2

1For example, Apple Inc. has released the iPad Pro in 2020 with LiDAR, and subsequent
iPhone releases in 2021 also has LiDAR.
2AR/MR SDKs of popular consumer platforms: Apple ARKit (https://developer.apple.
com/documentation/arkit), Google ARCore (https://developers.google.com/ar/), and
Windows MR API (https://developer.microsoft.com/en-us/windows/mixed-reality).

Privacy-aware 3D object regeneration3rd Party ApplicationsRaw 3D Spatial DataLow Privilege[High Privacy][Low utility]High Privilege[Low Privacy][High utility]User ConÔ¨Ågurable Privilege SliderOS Camera APIsMR SDK APIs, e.g. ARCoreApp 1App 2App 3Privacy-aware 3D APIs     
 
 
 
 
 
Concurrently, 3D object detection and classification have also
become highly accurate and ubiquitous [27, 28]. While training and
running these deep learning models is still compute and resource
intensive, it is only a matter of time when such models can be run
on mobile devices to be leveraged for environmental understanding
and, hence, deliver better MR experiences. Nonetheless, the rela-
tively memory light 3D point clouds can be sent to and processed
remotely, i.e. on the edge or cloud, where deep learning models can
be run more efficiently.

While these advanced environmental understanding empow-
ers app developers to design innovative MR service, the access
to accurate 3D mapping imposes unprecedented risks to user pri-
vacy [6, 16]. With the current access controls in place with these
MR devices, regardless of the processing strategy‚Äîwhether local or
remote‚Äîthe raw 3D point clouds are freely accessed by third party
applications. As such, adversarial MR applications can easily access
and collect 3D spatial maps which may include sensitive informa-
tion: whether the captured space itself is sensitive, or portions of
the captured space is sensitive. Aside from objects being detected,
geometric and photo-metric characteristics of the objects, semantic
relationships between objects, etc. may eventually be leveraged by
adversaries which can potentially reveal personally identifiable in-
formation: whether about the device user, or the user‚Äôs association,
linkage, or relationship to these spaces, objects, or other users.

Furthermore, the problem of user privacy is exacerbated by the
fact that users do not have any control over the visual, and, now,
spatial information shared to third parties. Due to binary user per-
mission structure on current devices, the user can either share raw
visual and spatial data or completely block permission to the cam-
era. Not just users, device manufactures are also suffering from
the lack of finer granular controlled release of spatial data, e.g.
Oculus has completely blocked access to 3D point cloud data in
order to mitigate unwanted data leakage.3 While this is good for
user privacy, it significantly limits innovation and hinders the true
potential of hardware capability.

In light of that, we propose a privacy-aware 3D spatial data
sharing framework providing the user with the ability to control
the level of privacy protection required. We introduce a 3D object
regeneration mechanism as an intermediary layer of protection
before sharing the 3D point cloud to third party applications as
shown in Fig. 1. For the 3D point cloud regeneration, we employ
a Hypernetwork-based Adversarial Autoencoder (AAE) and vary
the level of likeness of the regenerated 3D object point cloud from
the original. The level of likeness is obtained from the privilege
level assigned by the user (cf. privilege slider in Fig. 1). That is,
a higher likeness means a higher privilege is afforded to third-
party applications, and lower, otherwise. The challenge is to release
minimal amount of uniquely identifiable information regarding the
3D object, while also providing enough spatial information to allow
the application to function with high quality of service. We first
formulate adversarial models, as well as privacy and utility metrics.
We then evaluate the viability of the proposed user configurable
3D regeneration approach as a privacy mechanism using a large
3D object database.

In this paper, we present the following contributions:

3https://developer.oculus.com/reference/mobile/v29/

A. Nama, A. Dharmasiri, K. Thilakarathna, A. Zomaya, and J. A. de Guzman

(1) Formalize the 3D privacy problem against a two-fold attacker
which tries to reveal the super-class and intra-class labels of a 3D
object; hence, we correspondingly define two privacy metrics,
i.e. Œ†1 ‚àà [0, 1] for super-class, and Œ†2 ‚àà [0, 1] for intra-class.
(2) Define the utility metrics on which the privacy frameworks‚Äô
output will be measured against. We present two utility metrics
based on two common MR functionalities: bounding box utility
ùëÑ1, and plane anchoring utility ùëÑ2.

(3) Leverage existing 3D adversarial autoencoders (AAE) as an
intermediary privacy-preserving mechanism for reducing 3D
privacy leakage from 3D point clouds before exposing or sharing
to third party applications.

(4) Evaluated the viability of the AAE-based privacy-preserving 3D
regeneration using existing 3D deep neural network classifier
to classify and identify the regenerated point clouds at various
attacker privilege scenarios.

(5) Experimental evaluation shows that the proposed privacy frame-
work can indeed variably effect the privacy of a 3D object by
varying the privilege level ùëô. For example, if low privilege level
ùëô < 0.17 is maintained, both Œ†1, Œ†2 > 0.4 is ensured.

(6) Lastly, the proposed privacy framework can ensure relatively
high intra-class privacy and utility, i.e. Œ†2 > 0.63 and ùëÑ > 0.70,
at a privilege level range of 0.17 < ùëô < 0.25.

Overview. The rest of the paper is organized as follows. ¬ß2 presents
the related work with emphasis and focus on recent 3D privacy
work. ¬ß3 formalizes the 3D privacy problem followed by the formu-
lation of the proposed 3D privacy framework, i.e. privacy-aware 3D
point cloud regeneration, in ¬ß4. The experimental setup is detailed
in ¬ß5, while the results are discussed in ¬ß6. We discuss the further
implications of our work in ¬ß7. Finally, we conclude the paper in
¬ß8. The appendix shows supplementary plots and figures.

2 RELATED WORK
In this section, we present a comprehensive exposition of the recent
related work aimed at privacy for 3D data, particularly related to MR.
Then, we present a breadth of relevant 3D classification approaches
followed by the adversarial attacks towards these classifiers.

2.1 3D privacy
While most of the earlier work in MR privacy were primarily aimed
at visual (i.e. image and video) data protection [8], a handful of
recent work have started to point out the potential privacy risks
with the ubiquity of 3D ‚Äúscanning‚Äù devices [3, 14, 30], and high-
lighted the ease-of-access of third-party applications and services
over these 3D point cloud or spatial data [7, 12, 18].

3D leakage and further inference. On the MR-specific case, the
actual risks brought about by indefinite access to spatial data cap-
tured by mobile MR devices has been looked into. Specifically, on
how adversaries can easily identify spaces from captured 3D point
cloud data (using Microsofot Hololens) [6, 9]. Other works have
employed machine learning to reveal original scenes from 3D point
cloud data by leveraging on additional visual information, i.e. SIFT
(scale-invariant feature transforms) and other photometric informa-
tion [26]. Subsequent work focused on a privacy-preserving method
of pose estimation to counter the scene revelation [15, 34]: instead

User configurable 3D object regeneration for spatial privacy

of using 3D point cloud data, 3D line clouds are used during pose es-
timation to obfuscate 3D structures. The same line cloud approach
has also been leveraged to translate the features to affine space to
ensure that the features are privacy-preserving [11]. Another work
also followed the same strategy in delivering privacy-preserving
SLAM (synchronous localization and mapping) [33]. However, it
has also been demonstrated that line clouds are still not immune
from further inference as dense line clouds can still reveal 3D struc-
tures which allows for original scenes to be approximately revealed
[5]. Moreover, the 3D line cloud approach only addresses specific
functionalities such as pose-estimation and does not present its
viability for surface or object detection which may be necessary for
delivering immersive experiences in MR (e.g. to detect object on
which virtual objects can be rendered or ‚Äúanchored‚Äù onto). Thus,
with current MR processing techniques, it would still be necessary
for 3D point cloud data to be exposed but, perhaps, with some
privacy-preserving transformations to hide sensitive content and
prevent further spatial recognition.

3D encryption. An earlier approach proposed the encryption of
3D point clouds using chaotic mapping to conserve utility for view
point histograms [19]. However, this method is reliant on sharing
of keys, and once the keys‚Äîand, hence, access‚Äîare provided, no
further privacy protection is ensured. Furthermore, this 3D encryp-
tion method was not tested against standard encryption approaches
which have been employed in secure multi-party computation of
3D user models from encrypted user physiometric information for
virtual clothe try-on [32]. Nonetheless, this 3D encryption approach
together with other standard encryption methods (e.g. AES, and
RSA) are essential part in providing protection along the entire MR
service pipeline.

2.2 3D classification and reconstruction
3D classification. Now, as we explore risks associated with
2.2.1
exposed 3D spatial data, we looked into the various methods that are
utilized for 3D shape analysis, classification, and recognition. Early
approaches employ description and inference by, first, computing
3D features and, then, utilizing these features for inference, say, by
matching: examples include 3D Shape histograms [2], parametrized
shape distributions [24, 25], vector field similarity [10], shape his-
tograms [20, 21], curvature self-similarity [17], or heat-kernels [36].
On the other hand, the latest 3D recognition approaches have
employed machine learning and has been more successful in 3D
classification as well as segmentation. PointNet was the first to use
deep learning, i.e. deep neural network (DNN), for 3D classifica-
tion with point clouds as input [27]. PointNet++ presented some
improvements in the underlying DNN architecture [28]. Latest de-
velopments on neural network-based 3D classification include the
following: identifying salient regions of objects that inform about
their class [41], improving robustness to rotations [22], leveraging
alternating 3D projections for point cloud alignment or registra-
tion [29], and improving 3D segmentation processing time through
point dropping [39].

3D adversarial approaches: attacks and regeneration. Unsur-
2.2.2
prisingly, 3D neural networks (NNs) are also susceptible to 3D
adversarial point clouds which can confuse 3D NNs. Recent ef-
forts focused on demonstrating 2D adversarial approaches to 3D
[23, 37], and providing defenses against such adversarial attacks

[40, 42]. These efforts are motivated by mission-critical 3D infor-
mation which requires that 3D NNs be more resilient to adversarial
attacks when classifying 3D objects, e.g. detecting pedestrians for
self-driving cars.

However, we argue that for most non-critical 3D applications,
users may desire to have less of their environments be recogniz-
able to machines (and, hence, potential adversaries). Adversarial
autoencoders (AAEs) can be used to transform and generate 3D
point clouds to potentially preserve privacy. Recent works focused
on improving AAE using hypernetworks [35], or using curvature
functions with canonical shapes as reference [38]. However, none of
these methods are originally designed for privacy-preservation, but
can be leveraged and modified to be utilized as such as we propose in
this work.

3 PROBLEM FORMULATION - 3D OBJECT

PRIVACY IN MIXED REALITY

In the following sections, we introduce the representation of 3D
spatial data used in our analysis, formulate the adversary models,
establish the intended utilities of the MR application, and define
the privacy metrics that we consolidate in our proposed solution.

3.1 3D spatial data
Current commodity MR devices use one or combination of SLAM
(simultaneous localization and mapping), SFM (Structure from mo-
tion) or visual odometry to capture and represent its surrounding
3D environment [31]. This 3D structure representation usually
comes in the form of a point cloud which contains a set of un-
ordered and permutationally invariant points, each representing a
point, i.e. an edge or part of a surface, in space (in terms of x-y-z
coordinates) with no relationship defined among the points. Al-
though the mapped 3D surroundings or objects might subsequently
be converted to different representations such as 3D voxel grids,
meshes, or oriented point clouds, the 3D point clouds which is often
the direct output of the captures still encode substantial amount
of data, and can even be directly used for processing. In this paper,
we conduct our analysis on 3D objects while representing them as
unoriented point clouds (with no normal vector attached).

3.2 Adversary models
To formally define the problem and the privacy and utility metrics
used in this work, we develop upon the formalization introduced in
[9] and [6]. We introduce ùëÜ, a representation of an object captured
from an MR user‚Äôs surrounding as the key entity of the 3D object
privacy problem. We identify ùëÜ with two key attributes; it belongs
to a super-class object category based on the practicality (e.g. chair,
and table), and it represents a unique member within its super-class
in terms of 3D shape, structure, make, brand, etc. (e.g. product code
604.169.25 from IKEA 2021 catalog).

The MR application offers a functionality ùê∫, in which the object
representation ùëÜ is processed in some way to generate the output ùëå .
The utility of the 3D object ùëÑ gives a measurement of the quality
of the produced ùëå which is required for the functionality ùê∫ to be
derived. While an adversarial attacker formulates a hypothesis ‚Ñé
on a certain attribute of ùëÜ, the privacy preserving regeneration
mechanism generates a privacy-preserved version ¬ØùëÜ corresponding
to input ùëÜ, expecting to reduce the accuracy of ‚Ñé formulated by

Table 1: Table of notations

Notation

Description

ùëÜ
ùëòùëñ
ùëö ùëó |ùëñ
ùëô
ùëÜ‚àó
¬ØùëÜ
‚Ñé1 (ùëÜ‚àó)
‚Ñé2 (ùëÜ‚àó)|ùëò
ùõæ ‚àó
ùëò
ùúÇ‚àó
ùëöùëò
ùúå1, ùúå2
ùúé1, ùúé2
L‚Ñé1 (ùëÜ ‚àó) (ùõæ ‚àó
ùëò )
L‚Ñé2 (ùëÜ ‚àó) (ùúÇ‚àó
ùëöùëò )
L‚Ñé2 (ùëÜ ‚àó) |ùëòùë• (ùúÇ‚àó
ùëöùëò )
Œ†1 (ùëÜ‚àó) , Œ†2 (ùëÜ‚àó)
ùê∫ùë£ (ùëÜ)
ùëåùë£ (ùëÜ)
ùê∏ùëüùë£:ùëÜ,ùëÜ
ùëÑùë£,ùëÜ:ùëÜ

Point cloud
ùëñùë°‚Ñé super-class label
ùëóùë°‚Ñé intra-class label given a super class ùëòùëñ
variable privilege level, i.e. ùëô ‚àà [0, 1]
Query point cloud with unknown labels
Regenerated Point cloud
hypothesis 1 for query ùëÜ‚àó
hypothesis 2 for ùëÜ‚àó, given super-class ùëò
super-class label subsets formed by hypothesis 1
intra-class label subsets formed by hypothesis 2
hypothesis subset sizes as a fraction of reference set size
attack score functions for hypothesis labelling
Likelihood function of hypothesis 1
Likelihood function of hypothesis 2
Likelihood function for hypothesis 2 given the super-class ùëòùë•
super- and intra-class privacy metrics for query ùëÜ‚àó
ùë£ùë°‚Ñé MR functionality for point cloud ùëÜ
output of ùë£ùë°‚Ñé MR functionality for input ùëÜ
Transformation error for ùë£ùë°‚Ñé utility
ùë£ùë°‚Ñé utility metric for regenerated ¬ØùëÜ w.r.t ùëÜ

the attacker. For the convenience of the reader, we include all the
notations used in our work in Tab. 1.

Formalizing the attacker. In this paper, our main focus is on object
inference attacks. More specifically, the adversarial attacker that we
present in this work attempts to identify a 3D object represented by
a point cloud in two main hierarchical levels: (1) Super-class infer-
ence, i.e. identifying the high-level category of the object according
to its practicality; and (2) Intra-class inference, i.e. identifying the
unique object within the super-class. For each scenario, the attacker
attempts to narrow down the assumed super-class/intra-class to a
subset of previously encountered references.

Let ùëÜ be a known point cloud within the reference set where ùëòùëñ
is the object‚Äôs super-class label (i.e. ùëòùëñ ‚àà ùêæ where ùêæ is the set of all
the super-class object labels), and ùëö ùëó |ùëñ is its intra-class label within
super-class ùëòùëñ (i.e. ùëö ùëó |ùëñ ‚àà ùëÄùëñ and ùëÄùëñ is the set of all the intra-class
object labels of super-class ùëòùëñ ). Note that ùëòùëñ, ùëö ùëó |ùëñ ‚àà Z+.

Now, the attacker makes two-fold hypothesis about a query point
ùëñ and intra-class label
ùëó |ùëñ , i.e. we denote with a ‚àó the unknown labels to the attacker:

cloud ùëÜ‚àó with unknown super-class label ùëò‚àó
ùëö‚àó

ùê¥ùë°ùë°ùëéùëêùëòùëíùëü : ùëÜ‚àó ‚Üí ‚Ñé1,ùúå1

, ‚Ñé2,ùúå2

Super-class hypothesis- ‚Ñé1. The attacker makes a super-class hy-
is within a

pothesis ‚Ñé1,ùúå1 that the unknown super-class label ùëò‚àó
ùëñ
‚Äúbasket‚Äù subset ùõæ ‚àó
|ùõæ ‚àó
ùëò |
‚Ñé1,ùúå1 : ùëò‚àó
|ùêæ |

ùëò ‚äÇ ùêæ of super-class labels:
ùëñ ‚àà ùõæ ‚àó

(1)
The parameter ùúå1 is the ratio of the size of the super-class hy-
ùëò to that of the known super-class set ùêæ. When

ùëò = {ùëò1, ùëò2, ...}, where ùúå1 =

ùëò = {ùëòùë• }, ùëòùë• is the top-1 super-class hypothesis.

pothesis basket ùõæ ‚àó
ùúå1|ùêæ | = 1, i.e. ùõæ ‚àó

Intra-class hypothesis- ‚Ñé2. Next, the attacker makes an intra-
class hypothesis ‚Ñé2,ùúå2 given the ‚Ñé1 super-class label ùëòùë• ‚àà ùêæ, that
the unknown intra-class label ùëö‚àó
ùëöùë• ‚äÇ ùëÄùë• of
intra-class labels:

ùëó |ùë• is within a set ùúÇ‚àó

A. Nama, A. Dharmasiri, K. Thilakarathna, A. Zomaya, and J. A. de Guzman

|ùúÇ‚àó
ùëöùë• |
|ùëÄùë• |

ùëó |ùë• ‚àà ùúÇ‚àó

‚Ñé2,ùúå2 |ùëòùë• : ùëö‚àó
(2)
Similarly, ùúå2 is the ratio of the size of the intra-class hypothesis

ùëöùë• = {ùëö1|ùë• , ùëö2|ùë• , ...}, where ùúå2 =

set ùúÇ‚àó

ùëöùë• of the known intra-class set ùëÄùë• of super-class ùëòùë• .

As ùúå increases, the attacker will identify the query ùëÜ‚àó as a mem-
ber of a larger set of possible super-classes and unique-objects.
Therefore as ùúå increases, the attacker‚Äôs ability to precisely reiden-
tify the object decreases, hence the privacy threat that the attacker
can pose to the user decreases. Hence, an attacker will ideally try to
narrow down the hypothesis to a subset with as small ùúå as possible.

3.3 MR application utility
Various functionalities are offered by MR applications that leverage
3D data from the user environments. Such functionalities vary in
terms of level of details required in the 3D scans to effectively deliver
the intended functionality. A given functionality ùê∫ùë£, requires a
particular output ùëåùë£ from the device obtained by applying some
operation on the raw point cloud scans: i.e. ùê∫ùë£ (ùëÜ) ‚Üí ùëåùë£,ùëÜ .

The privacy mechanism takes original point cloud ùëÜ as input, and
generates a privacy-preserved version ¬ØùëÜ of it. Thus, we can define
a utility metric for the regenerated point cloud with respect to the
original point cloud by using an output transformation error for the
particular application functionality, where ùê∏ùëüùë£ is a distance/error
function that quantifies the dissimilarity between ùëåùë£,ùëÜ and ùëåùë£,ùëÜ : i.e.
ùê∫ùë£ : ùê∏ùëüùë£

(cid:16)
ùëåùë£,ùëÜ, ùëåùë£,ùëÜ

‚Üí ùëÑùë£,ùëÜ:ùëÜ .

(cid:17)

In this work, we analyze two main MR application utilities that
require varying levels of details in the output ùëåùë£,ùëÜ , and we define
utility metrics separately for each.

Bounding box utility. The most basic and naive MR functionality
requires the general location of an object, often to be treated as an
obstacle in the 3D environment. We define this functionality as ùê∫1
whereas the output ùëå1,ùëÜ represents the general location and size of
the object represented by ùëÜ in the form of a 3D bounding box: i.e.
ùê∫1 ‚Üí ùëå1,ùëÜ = (ùë•ùëÜ, ùë¶ùëÜ, ùëßùëÜ, ùë•0:ùëÜ, ùë¶0:ùëÜ, ùëß0:ùëÜ ), where ùë•, ùë¶, ùëß indicate the
dimensions of the bounding box in 3 axes, and ùë•0, ùë¶0, ùëß0 indicate
the position of the center of the bounding box.

Next, we formulate the utility metric for the MR functionality
ùê∫1. Here, we can skip the intermediate error function and directly
formulate the utility metric to quantify the similarity of object
bounding boxes in terms of 3D Intersection-over-union (IoU).

ùëÑ

1:ùëÜ,ùëÜ = ùêºùëúùëà (ùëåùë£,ùëÜ, ùëåùë£,ùëÜ )

(3)

Plane anchoring utility. The second and most widely used MR
functionality ùê∫2 involves anchoring 3D virtual objects onto 2D
surfaces of real objects. For this, we define the function output: i.e.
ùê∫2 ‚Üí {ùëå2,ùëÜ : ùëù, ùëå
2,ùëÜ : ùëù}, where ùëù and ¬Øùëù indicate the point clouds
representing the most prominent 2D plane of the object from the
original and regenerated point clouds separately.

3D object anchoring in MR could be either static or dynamic. In
static anchoring, anchored object is stationary, and MR functional-
ity only requires the position and normal vector for one point on
the plane. Hence, we formulate the transformation error in terms
of the angle and distance between the planes ùëù and ¬Øùëù. For dynamic
anchoring, anchored object moves around the plane, therefore func-
tionality requires the area and the point distribution of the 2D plane.

User configurable 3D object regeneration for spatial privacy

Hence, we additionally use difference in area, and difference in point
distributions between ùëù and ¬Øùëù to define the error function.
ùê∏ùëü2:ùëÜùë°ùëéùë°ùëñùëê = 0.5|1 ‚àí ‚àí‚Üíùëõùëù .‚àí‚Üíùëõùëù | + 0.5|ùëü ùëù ‚àí ùëü ùëù |
ùê∏ùëü2:ùê∑ùë¶ùëõùëéùëöùëñùëê = 0.25|1 ‚àí ‚àí‚Üíùëõùëù .‚àí‚Üíùëõùëù | + 0.25|ùëü ùëù ‚àí ùëü ùëù |+
0.25|ùê¥(ùëù) ‚àí ùê¥(ùëù)| + 0.25ùê∂ùê∑ (ùëù, ùëù)

(4)

Here,

‚àí‚Üíùëõùëù indicates the unit normal vector to the 2D plane rep-
resented by ùëù; thus, |1 ‚àí ‚àí‚Üíùëõùëù .‚àí‚Üíùëõùëù | calculates the angle between the
planes. ùëü ùëù indicates the perpendicular vector from origin to the
plane ùëù; thus, |ùëü ùëù ‚àí ùëü ùëù | measures the distance between planes. ùê¥(ùëù)
measures the area of the 2D convex-hull formed by ùëù, and ùê∂ùê∑ (ùëù, ùëù)
returns the Chamfer distance between two point clouds ùëù and ¬Øùëù,
reflecting the point distribution discrepancy between them.

Before deriving the utility function ùëÑ

2:ùëÜ,ùëÜ from ùê∏ùëü2, we separately

apply min-max normalization for each component
|ùëü ùëù ‚àí ùëü ùëù |,

|1 ‚àí ‚àí‚Üíùëõùëù .‚àí‚Üíùëõùëù |,

|ùê¥(ùëù) ‚àí ùê¥(ùëù)|, ùê∂ùê∑ (ùëù, ùëù)

The modified error functions obtained after the said normaliza-
tion are as follows: ùê∏ùëü2:ùëÜùë°ùëéùë°ùëñùëê ‚Üí ùê∏ùëü ‚Ä≤
2:ùëÜùë°ùëéùë°ùëñùëê , and ùê∏ùëü2:ùê∑ùë¶ùëõùëéùëöùëñùëê ‚Üí
ùê∏ùëü ‚Ä≤
2:ùê∑ùë¶ùëõùëéùëöùëñùëê . Finally, we formulate the second (twofold) utility met-
ric based on the functionality ùê∫2:

Intra-class privacy. Next, given a particular hypothesis super-
3.4.2
class label ùëòùë• , attacker generates a likelihood function for the intra-
class hypothesis label set ùúÇ‚àó

ùëöùë• :

ùëöùë• ) = L‚Ñé1 (ùëÜ ‚àó) (ùëòùë• ) ¬∑ L‚Ñé2 (ùëÜ ‚àó) |ùëòùë• (ùúÇ‚àó

L‚Ñé2 (ùëÜ ‚àó) (ùúÇ‚àó
where L‚Ñé2 (ùëÜ ‚àó) |ùëòùë• (ùúÇ‚àó

ùëöùë• ) =

ùëöùë• )
(cid:0)ùëö, ùëÜ‚àó|ùëòùë• (cid:1)

‚àëÔ∏Å

ùúé2

‚àÄùëö ‚ààùúÇ‚àó

ùëöùë•

ùúé2 (ùëö, ùëÜ‚àó|ùëòùë• ) is an attacker intra-class score function for a hy-
pothesis object label ùëö and for the unknown point cloud ùëÜ‚àó within a
given super-class ùëòùë• , i.e. it represents the inclination of the attacker
to match the query ùëÜ‚àó with the particular object m, given that ùëÜ‚àó
belongs to the super-class ùëòùë• , such that those values for each object
within ùëòùë• adds up to 1:

ùúé2 (ùëö; ùëÜ‚àó|ùëòùë• ) ‚â§ 1, and

‚àëÔ∏Å

ùúé2 (ùëö; ùëÜ‚àó|ùëòùë• ) = 1.

(8)

‚àÄùëö ‚ààùëÄùë•
The intra-class privacy Œ†2 for a query point cloud ùëÜ‚àó with actual
super class label ùëòùëñ and intra-class label ùëö ùëó |ùëñ is also calculated as
the expected error of the attacker hypothesis where the error of
the super-class hypothesis affects the intra-class hypothesis:

ùëÑ2:ùëÜùë°ùëéùë°ùëñùëê = 1 ‚àí ùê∏ùëü ‚Ä≤
ùëÑ2:ùê∑ùë¶ùëõùëéùëöùëñùëê = 1 ‚àí ùê∏ùëü ‚Ä≤

2:ùëÜùë°ùëéùë°ùëñùëê

2:ùê∑ùë¶ùëõùëéùëöùëñùëê

(5)

Œ†2

(cid:0)ùëÜ‚àó(cid:1) =

‚àëÔ∏Å

‚àÄùëò‚â†ùëòùëñ

L‚Ñé1 (ùëÜ ‚àó) (ùëò)

3.4 Privacy metrics
We characterize the privacy introduced by the proposed mecha-
nism for a particular 3D point cloud ùëÜ with respect to the type of
adversarial inference attempted upon by the attacker: (1) Super-
class privacy, and (2) Intra-class privacy. We formulate the privacy
metrics for both of the above scenarios using the expected error
in hypotheses ‚Ñé1 and ‚Ñé2. Furthermore, since the hypotheses are
given as sets of labels, i.e. ùõæ ‚àó
ùëò and ùúÇ‚àó
ùëöùëò , the privacy metrics are also
dependent on the size of these label sets which are represented as
fractions of the reference sets by the parameters ùúå1 and ùúå2.
3.4.1
the attacker generates a likelihood function for ùõæ ‚àó
ùëò :

Super-class privacy. In trying to infer a query point cloud ùëÜ‚àó,

L‚Ñé1 (ùëÜ ‚àó) (ùõæ ‚àó

ùëò ) =

‚àëÔ∏Å

(cid:0)ùëò, ùëÜ‚àó(cid:1)

ùúé1

‚àÄùëò ‚ààùõæ ‚àó
ùëò
ùúé1 (ùëò, ùëÜ‚àó) is an attacker super-class score function for a hypoth-
esis super-class label ùëò and for the unknown point cloud ùëÜ‚àó, i.e.
it represents the inclination of the attacker to match the query
ùëÜ‚àó with the particular super-class, such that those values for each
super-class adds up to 1:

ùúé1

(cid:0)ùëò, ùëÜ‚àó(cid:1) ‚â§ 1, ‚àëÔ∏Å
‚àÄùëò ‚ààùêæ
Then, the super-class privacy Œ†1 for a query point cloud ùëÜ‚àó with
actual super class label ùëòùëñ can be expressed in terms of the expected
error in hypothesis set ùõæ ‚àó
ùëò ,

ùúé1 (ùëò, ùëÜ‚àó) = 1

(6)

Œ†1

(cid:0)ùëÜ‚àó(cid:1) =ùõø (ùëòùëñ, ùõæ ‚àó

ùëò )L‚Ñé1 (ùëÜ ‚àó) (ùõæ ‚àó
ùëò )

+ (1 ‚àí ùõø (ùëòùëñ, ùõæ ‚àó

ùëò ))(1 ‚àí L‚Ñé1 (ùëÜ ‚àó) (ùõæ ‚àó
ùëò ))

(7)

where ùõø (ùë†, ùëÜ) is a set membership function, i.e.

ùõø (ùë†, ùëÜ) = {1 if ùë† ‚àà ùëÜ; 0 if ùë† ‚àâ ùëÜ }

+ L‚Ñé1 (ùëÜ ‚àó) (ùëòùëñ ){ùõø (ùëö ùëó |ùëñ, ùúÇ‚àó
ùëó |ùëñ, ùúÇ‚àó
+ (1 ‚àí ùõø (ùëö‚àó

ùëöùëñ ))(1 ‚àí L‚Ñé2 (ùëÜ ‚àó) |ùëòùëñ (ùúÇ‚àó

ùëöùëñ )L‚Ñé2 (ùëÜ ‚àó) |ùëòùëñ (ùúÇ‚àó

ùëöùëñ )
ùëöùëñ ))}

(9)

We leverage the privacy metrics and the utility metrics formu-
lated in this section to measure and evaluate the performance of
the proposed framework in various contexts as given in ¬ß6.

4 3D PRIVACY FRAMEWORK
Our framework utilizes an Auto-Encoder based point cloud regen-
eration mechanism to introduce privacy preserving versions for
point cloud objects.

4.1 AAE-based point cloud regeneration
The deep neural network used in our framework is called Hyper-
Cloud [35] which consists of an Adversarial Auto-Encoder (AAE)
and a target network. The AAE works as a hyper-network (H ) for
the target network (T ) i.e. the AAE returns the weights of the target
network as output. The AAE takes a point cloud as the input (X)
which passes through an encoder (E) and a decoder (D) to return
the weights (ùúÉ ) of the target network.

In addition to E and D, the AAE also includes another neural
network called discriminator. The goal of the discriminator is to
learn to distinguish between the latent space (E (X) ‚àº Z) and the
prior distribution (P) by using a regularization loss term in the cost
function. The target network with the weights ùúÉ i.e. TùúÉ accepts a
baseline distribution (3D ball or sphere) as input and generates a
reconstruction (Y) of the original 3D point cloud. The cost function
includes the regularization term and the Chamfer pseudo-distance
between original point cloud and the reconstruction as follows:
ùëêùëúùë†ùë° (X; E, Y) = ùê∂ùê∑ (X; Y) + ùëÖùëíùëî(E (X); P)
(10)
Where ùê∂ùê∑ refers to the Chamfer pseudo-distance and ùëÖùëíùëî refers
to the regularization loss term. The Chamfer pseudo-distance can
alternatively be replaced with the Earth Mover‚Äôs distance. If P is

A. Nama, A. Dharmasiri, K. Thilakarathna, A. Zomaya, and J. A. de Guzman

corresponding to each training epoch; which is translated to the
allowed privilege level ùëô as explained above. As we can see in Fig.
3, the user input on the privilege slider determines the weights
that will be loaded into the hypernetwork from the weight bank.
After successfully loading of the weights, the original point cloud
is passed through the privacy framework which produces a regen-
eration with corresponding ùëô. This regeneration is shared with the
3rd party application.

5 EXPERIMENTAL SETUP
5.1 Dataset
For this work, we created a custom dataset by selecting a subset of
the dataset introduced by [1] where 3D CAD models of ShapeNet-
Core [4] were sampled with (area) uniform sampling. Our dataset
has 10 super-classes of household items i.e. bathtub, chair, monitor,
sofa, table, bench, cabinet, bed, bookshelf and lamp, with 100 unique
object instances within each super-class. (We have avoided large
non-household objects like airplane, ship, etc. as it would be imprac-
tical for MR devices to capture these for a normal user.) Every point
cloud object was represented by 2048 points, and was normalized.

5.2 Adversarial attacker realization/simulation
In ¬ß3.2 , we discussed the theoretical framework and the hypothesis
formulation used by an adversarial attacker to infer details about a
point cloud at both super-class and intra-class level. In this section,
we will discuss the practical simulation of such attackers in vari-
ous scenarios and using them to evaluate our privacy framework
effectiveness. In this work, we used the PointNet neural network
architecture as the 3D point cloud classifier [27] to realize the object
reidentification attacks posed by an adversarial attacker.

5.2.1 Attacker hypothesis formulation. The attackers that we real-
ize in the form of 3D point cloud classifiers formulate two consecu-
tive hypotheses for a query point cloud as explained in Eq. 1 and
Eq. 2. In this section, we will elaborate the hypothesis formulation
process followed by PointNet based classifiers.

At the last activation function of PointNet, the Softmax layer
outputs the probability distribution over predicted reference classes.
We use this Softmax output to define the scoring function in Eq. 6,
ùúé1 (ùëò; ùëÜ‚àó) for each super-class ùëò in the reference set. Then, the
attacker formulates the hypothesis in Eq. 1 by solving the following
optimization.

‚Ñé1,ùúå1 = ùõæ ‚àó

ùëò = Argmax

ùõæùëò

(cid:0)ùëò, ùëÜ‚àó(cid:1)

ùúé1

‚àëÔ∏Å

ùëò ‚ààùõæùëò

(11)

Similarly in the next step, we use the Softmax output of the intra-
class classifier trained on a particular super-class ùëòùë• to formulate
the scoring function in Eq. 8, ùúé2 (ùëö; ùëÜ‚àó|ùëòùë• ) for each object ùëö in
the intra-class reference set of super-class ùëòùë• . We formulate the
hypothesis in Eq. 2 by solving the following optimization:
ùëöùë• = Argmax

‚Ñé2,ùúå2 |ùëòùë• = ùúÇ‚àó

(cid:0)ùëö, ùëÜ‚àó|ùëòùë• (cid:1)

(12)

‚àëÔ∏Å

ùúé2

ùúÇùëöùë•

ùëö ‚ààùúÇùëöùë•

Note that the cardinalities of the subsets ùõæ ‚àó

ùëöùë• obtained
in Eq. 11 and Eq. 12 are parameterized by ùúå1 and ùúå2 as shown in
Eq. 1 and Eq. 2. We evaluate the performance of our attackers with
respect to these parameters in ¬ß6. Moreover, for this experimental
setup, the super-class reference set size |ùêæ | = 10, and intra-class
reference set size |ùëÄùëò | = 100 for each ùëò ‚àà ùêæ.

ùëò and ùúÇ‚àó

Figure 2: Training the proposed framework

Figure 3: Privacy-preserving regeneration using the pro-
posed framework

chosen to be some known distribution like Gaussian, KL-divergence
or adversarial training can be used for the regularization term.

4.2 User configurable point cloud regeneration
Our framework allows users to control the privilege, denoted by
ùëô, given to the MR application to acquire 3D data using a slider
mechanism. When high privilege is given, the third party MR appli-
cation can collect 3D information from the user‚Äôs surrounding with
high level of detail, hence can cause larger privacy risk to the user.
Similarly, when low privilege is allowed for the application, the
amount of detail in the 3D data is limited by the proposed mech-
anism, thereby minimizing the possible privacy risk. The slider
ranges from 0 to 1 where 0 refers to no privilege allowed, while 1
refers to allowing maximum privilege.

As shown in Eq. 10, the cost function directly depends on the
Chamfer pseudo-distance between the original point cloud and
the reconstruction using the architecture; so, as the loss function
decreases, Chamfer pseudo-distance also decreases implying better
and more accurate reconstructions. We have used this property
of the loss function to generate different ùëô privilege levels allowed
by the user to the MR application. The regenerations with higher
loss (usually referring to lower epoch in the architecture training)
are used for lower privilege settings, and those with lower loss
(referring to lower epoch in the architecture training) are for higher
privilege settings.

During the training of our privacy framework as shown in Fig. 2,
we save the weights of the hypernetwork to create a weight bank

EncoderDecoderDiscriminatorHyper NetworkTarget NetworkWeightsChairLamp100100Reconstructed ObjectCostEncoderDecoderDiscriminatorHyper NetworkTarget NetworkWeightsHigh PrivilegeLow PrivilegeUser Input3rd party applicationepoch 2epoch 4epoch 6Saved WeightsLoss ValuesWeightsepoch 58epoch 296epoch 298epoch 300Original Point CloudUser configurable 3D object regeneration for spatial privacy

Figure 4: Reference (training) dataset generation for the
super-class "Chair"

5.2.2 Attacker classification. Both super-class and inter-class adver-
sarial inference is done with respect to a set of reference 3D objects
that are previously encountered and learnt by the attacker in one
or many of the following ways: from publicly available data, from
the data intercepted previously from the same user or different
users, or data obtained via other potentially colluding applications.
In a situation where the query object is not present in the refer-
ences (i.e. not previously encountered by the attacker), the attacker
still attempts to identify the query as the structurally closest (most
similar) reference object.

We define the following four types of attackers based on the
approach of acquiring and the quality (in terms of the ‚Äòexposed‚Äô
privilege level ùëô) of 3D data in their reference sets:

‚Ä¢ J1 - public-aware attacker -Using publicly available data

as a set of reference 3D objects

‚Ä¢ J2 - low-privilege-aware attacker -Intercepting data from

users with low privilege settings

‚Ä¢ J3 - medium-privilege-aware attacker -intercepting data

from users with medium privilege settings

‚Ä¢ J4 - high-privilege-aware attacker -Intercepting data from

users with high privilege settings

In ¬ß6.2, we present our analysis on how the proposed framework

effectively preserve privacy against these different attackers.

Simulating attacker learning process. We created the refer-
5.2.3
ence dataset for the attacker ùêΩ1 by using publicly available dataset
as mentioned in ¬ß5.1. We created 100 normalized augmentations
for each unique object in all the super-classes by adding random
rotations and Gaussian noise to complete the reference (training)
dataset. For attackers ùêΩ2, ùêΩ3 and ùêΩ4, we used our privacy framework
to create 100 regenerations for each unique object in every super-
class at various ùëô privilege levels (allowed to each attacker) to create
the reference (training) datasets.

As explained in ¬ß4.2, the training epoch number, which the hy-
pernetwork weights are loaded from, has a direct proportional
relationship with the provided ùëô privilege level. Therefore, we di-
vided range of ùëô to three abstract privilege settings based on the
epoch ranges. The privacy framework based on Hypercloud was
trained for 300 epochs in this experimental setup.
‚Ä¢ Low privilege (0- 0.167) - epoch range (0,50]
‚Ä¢ Medium privilege (0.167- 0.232) - epoch range [50,70]
‚Ä¢ High privilege (0.232- 1) - epoch range [70,300]

This division was done based on experimental results that we ob-
tained, as will be explained in ¬ß6. For example, for the attacker ùêΩ2,
we randomly chose 100 epoch numbers within the range (0,50] with
replacement and regenerated each unique object ùëö ‚àà ùëÄùëò , for every
super-class ‚àÄùëò ‚àà ùêæ, using the hypernetwork loaded with weights

Figure 5: Classifier training process for an Attacker ùêΩ : 1√ó
super-class classifier, and 10√ó intra-class classifiers (i.e. one
for each super-class). Each attacker generates their own set
of classifiers.

Figure 6: Testset generation for the super-class "Chair"

from that particular epoch number. A similar procedure was fol-
lowed for the attackers ùêΩ3 and ùêΩ4, except the epoch ranges were
changed to [50,70] and [70,300] respectively to reflect each privilege
setting. The reference dataset generation for a single super-class
(e.g. "Chair") is shown in the Fig. 4.

Now, for each attacker, we have a reference dataset of size 10 √ó
100 √ó 100, i.e. 100 reconstructions of each of the 100 unique objects
for all the 10 super-classes. The attacker uses this reference data
for training and validation of their classification models, and uses
them to infer the super-class and intra-class attributes of a query
point cloud ùëÜ‚àó.

For super-class classification, each attacker trains one classifi-
cation model which uses the labeled dataset of size 10 √ó 100 √ó 100
where we have 100 √ó 100 samples for each super-class. For intra-
class classification, each attacker trains 10 different classification
models, i.e. one for each super-class. Each of these 10 models uses
the dataset of size 100 √ó 100, where we have 100 labeled samples (re-
generations) for each unique object. An attacker‚Äôs classifier training
process is shown in Fig. 5.

5.2.4 Evaluating the attacker performance. To assess each attacker‚Äôs
success, we test all of their classification models against a scenario
where it attempts an object reidentification attack (following the
attacker hypothesis formulation in ¬ß5.2.1) while using the proposed
privacy framework. As discussed in ¬ß4.2, according to the user input
on the privilege slider, we choose its corresponding epoch number
from within the range (0,300] and load the corresponding weights
into our framework. This network is used to create a regeneration
of the original point cloud with the privilege allowed by the user.
For each of the 100 unique objects from all the 10 super-classes,
we created 3 reconstructions at every other epoch, i.e. all the even
numbered epochs in the range (0,300]. This labeled dataset of size
10 √ó 100 √ó 150 √ó 3 was used to test all the 11 classifiers trained
by each attacker. Our testing dataset will allow us to assess the
attacker‚Äôs success at inferring both the super-class and the intra-
class attribute at various levels of privilege set by a user. The testing
dataset generation for a single super-class is shown in Fig. 6.

chair_00Privacy FrameworkSelected Epochs100100ReconstructionsUnique Objectschair_99chair_00*chair_99*‚ÄúChair‚Äù class training set (100 x 100)chair_00Privacy Framework150 x 3ReconstructionsUnique Objectschair_99chair_00*chair_99*‚ÄúChair‚Äù class testing set (100 x 150 x 3)x3x3Epochs2,4,6 ‚Ä¶ 298, 300150 x 3(a) Chair

(b) Table

(c) Bed

(d) Bench

Figure 7: Super-class and intra-class (Œ†1 and Œ†2) privacy met-
rics for the top-1 success of Attacker ùêΩ1 for selected 3D ob-
jects: (a) chair, (b) table, (c) bed, and (d) bench.

5.2.5 Baselines to evaluate the privacy preservation of proposed
framework. We simulated an object reidentification attack attempted
by Attacker ùêΩ1 on a user who does not use our framework, but re-
leases the original point clouds of the objects. In such case, the
point clouds released by the user resembles the publicly available
point clouds for those objects. We run the classifier inference on
the original point clouds from our dataset in ¬ß5.1 to simulate this
scenario. The calculated privacy metrics Œ†1,ùêµ and Œ†2,ùêµ are used
as baselines to evaluate the performance increase of the proposed
framework in terms of privacy preservation against Attacker ùêΩ1.

5.3 Utility evaluation for regenerated point

clouds

Higher privacy usually comes at a cost of quality of service. The
goal is for the privacy framework to still allow MR applications to
successfully deliver their intended functionalities while preserving
the privacy of the point cloud objects. To this end, we utilize two
utility metrics defined in ¬ß3.3, along with an additional Chamfer
distance measurement to evaluate the regenerated point clouds.

In order to realize the utility metric ùëÑ

1:ùëÜ, ¬ØùëÜ from Eq. 3, we cal-
culated the axis-aligned bounding boxes for each original point
cloud ùëÜ and compared it with the bounding boxes of regenerated
point clouds ¬ØùëÜ from each privilege level ùëô. We use the standard 3D
Intersection-over-union ‚Äì IoU as the comparison metric in ùëÑ1.

Next, to realize the utility metric ùëÑ

2:ùëÜ, ¬ØùëÜ from Eq. 5, we used a
modified implementation of RANSAC [13] algorithm to extract
the most prominent 2D plane of each point cloud object. Since
our dataset consists primarily of household objects, we conducted
our analysis for 2D horizontal planes, e.g. sitting plane of chairs
where virtual objects are most likely to be anchored on. But the
utility metric ùëÑ
2:ùëÜ, ¬ØùëÜ can be applied to any type of plane of choice.
We obtain a set of points ùëù that are fitted to the most prominent
2D plane of the object by the RANSAC algorithm, and calculate
the metrics given in the Eq. 5 separately for static and dynamic
anchoring cases.

Additionally, some MR functionalities might require near-truth
representation of the complete structure of the object. Therefore
its also important to investigate how the object structure of ùëÜ is
preserved in privacy-preserving regenerations ¬ØùëÜ created from ùëÜ. To

A. Nama, A. Dharmasiri, K. Thilakarathna, A. Zomaya, and J. A. de Guzman

Figure 8: Aggregated Œ†1 and Œ†2 metrics for the top-1 success
of Attacker ùêΩ1 for all test objects

this end, we calculate the well known Chamfer distance between
the original point cloud ùëÜ, and its regenerated point clouds ¬ØùëÜ at
each ùëô privilege level. According to Eq. 10, Chamfer distance is also
a part of the cost function in our framework. It essentially measures
the squared distance between each point in one point cloud to its
nearest neighbor in the other point cloud.

6 RESULTS AND DISCUSSION
6.1 Privacy evaluation for the top-1 hypothesis

of Attacker ùêΩ1

We evaluated the performance of our proposed privacy-preserving
regeneration separately for each super-class. In Fig. 7, x-axis indi-
cates the privilege level ùëô at which a query point cloud has been
regenerated. Each plot indicate the variation of the two privacy
metrics Œ†1 and Œ†2 from Eq. 7 and Eq. 9 for different regenerations.
For this analysis, the parametric values ùúå1 and ùúå2 are set such that
ùëò | = ùúå1|ùêæ | = 1, |ùúÇ‚àó
|ùõæ ‚àó
| = ùúå2|ùëÄùëò | = 1; that is, the attacker is nar-
ùëÄùëò
rowing down its hypothesis to a top-1 super-class and intra-class
label. The attacker used in this analysis is Attacker ùêΩ1 according
to the categorization in ¬ß5.2, who builds the reference point cloud
object sets using publicly available data.

As ùëô increases, the regeneration becomes increasingly similar to
the original point cloud: eventually decreasing the privacy for both
super-class and intra-class attack scenarios. One notable observa-
tion is that the privacy for a particular regeneration is higher for
the intra-class case than for the super-class case. This is due to the
penalization in Eq. 9 for failed super-class hypothesis in the first
step of hypothesis 2 formulation.

In Fig. 7 and Fig. 8, the baselines calculated in ¬ß5.2.5 are shown
in dashed lines. The privacy metric Œ†2 for the proposed framework
is significantly large in comparison to baseline values in all shown
super-classes, while privacy metric for Œ†1 is large in comparison to
baselines for relatively low ùëô values, and gets closer to the baseline
value for higher ùëô values. For example, according to Fig. 8, proposed
framework adds 0.58 increase in Œ†1 privacy, and 0.81 increase in
Œ†2 privacy at privilege level ùëô = 0.167, and respectively 0.23 and
0.62 increase in Œ†1 and Œ†2 at ùëô = 0.232.

A significant change in both Œ†1 and Œ†2 can be observed within
the approximate range of ùëô = 0.167 and ùëô = 0.4 followed by a
slow decay thereafter, indicating the potential of the proposed
regeneration mechanism to be used as a tunable privacy encoding
for point cloud objects.

0.00.20.40.60.81.0Privilege Level (l)0.00.51.0i(S*)1:B2:B1(S*)2(S*)0.00.20.40.60.81.0Privilege Level (l)0.00.51.0i(S*)1:B2:B1(S*)2(S*)0.00.20.40.60.81.0Privilege Level (l)0.00.51.0i(S*)1:B2:B1(S*)2(S*)0.00.20.40.60.81.0Privilege Level (l)0.00.51.0i(S*)1:B2:B1(S*)2(S*)0.00.20.40.60.81.0Privilege Level (l)0.00.20.40.60.81.0i(S*)1:B2:BLowMediumHigh1(S*)2(S*)User configurable 3D object regeneration for spatial privacy

(a) Superclass Privacy Œ†1 (S‚àó)

(b) Intraclass Privacy Œ†2 (S‚àó)

Figure 9: Aggregated Œ†1 and Œ†2 metrics for the top-1 success
of all Attackers: ùêΩ1, ùêΩ2, ùêΩ3andùêΩ4.

6.2 Privacy performance against various

attackers with different privilege levels
In ¬ß5.2, we introduced 4 different attackers based on how each
attacker obtain the reference data for its hypothesis formulation.
Out of them, Attackers ùêΩ2,ùêΩ3, and ùêΩ4 can be analyzed separately
since they use regenerated point clouds to form its reference set.
This resembles a practical situation where a user is already using
the proposed framework to transform the 3D objects prior to being
released to the MR application, an adversarial attacker can still
intercept these transformed data and learn to formulate hypotheses.
In Fig. 9, we present the analysis of the variation of privacy metrics
for different Attackers ùêΩ2, ùêΩ3 and ùêΩ4. The results are aggregated for
all super-classes and all unique-objects within each super-class.

One notable observation is the clear difference of privacy metric
values for different attackers. The regenerated point clouds show
very high privacy with respect to Attacker ùêΩ2, which is trained only
on low privilege data, while showing significantly low privacy met-
ric values for Attacker ùêΩ4, which is trained on high privilege data.
Similar to the results in ¬ß6.1, intra-class privacy metric values are
comparatively higher than that of super-class for all three attackers.
On the other hand, the privacy of regenerated point clouds with
respect to Attacker ùêΩ4 is even lower than that for Attacker ùêΩ1 that
we discussed in ¬ß6.1. The potential reason is because the features
learnt by Attacker ùêΩ4 from the regenerated point clouds with high-
est privilege are more similar to the query point clouds than the
features of original point clouds (from public datasets). The dip in
the plots for Attackers ùêΩ2 and ùêΩ3 indicate that the attackers can pose
a higher privacy threat for point clouds which are regenerated in
the similar ùëô range as their reference sets, but the threat does not
generalize well for other ùëô ranges: e.g. trained at lower ùëô but does
not perform well against query objects released at higher ùëô.

Given the difference in how Attacker ùêΩ1 and the rest of the at-
tackers (ùêΩ2,ùêΩ3 and ùêΩ4) learn their reference sets, two types of privacy
threats can be identified. Since Attackers ùêΩ2, ùêΩ3, and ùêΩ4 are only
exposed to regenerated point clouds from the proposed framework,
they lack knowledge about the unique objective features of the
original point cloud object. The inference of a query point cloud
ùëÜ‚àó by such attackers can be identified as an object reidentification
attack; where the query can be matched with one of its reference
super-classes/objects, but the attacker cannot derive further infor-
mation or pose additional threats since the regenerated objects do
not necessarily resemble their original counterparts. On the other
hand, attacker ùêΩ1 learns its reference set from publicly available
data, where additional object, semantic, and contextual features
are also possibly available for a given object. Once Attacker ùêΩ1 in-
fers a query point cloud ùëÜ‚àó with respect to such a reference set,
in addition to an object reidentification threat, revealing the true

(a) Superclass Privacy Œ†1 (S‚àó)

(b) Intraclass Privacy Œ†2 (S‚àó)
Figure 10: Œ†1 and Œ†2 metrics aggregated for varying hypoth-
esis subset sizes ùúå, and privilege levels ùëô

identity of the object can lead to multiple other privacy threats.
Although not reflected in the privacy metrics Œ†1 and Œ†2 in Fig. 9,
it is noteworthy that ùêΩ1 has comparatively larger potential to pose
additional privacy threats.

6.3 Privacy metric evaluation for varying sizes

of hypothesis sets

In Eq. 1 and Eq. 2, we introduced the hypothesis formulation in
terms of the parameters ùúå1 and ùúå2. In simple terms, given a query
point cloud ùëÜ‚àó, the attacker attempts to narrow down the possible
identity of it to a portion of its reference set, and ùúå parameterizes
the size of the hypothesized subset as a portion of the reference set.
Intuitively, when ùúå increases, the hypothesis subset size increases,
hence its becomes increasingly probable that the query point cloud
ùëÜ‚àó‚Äôs identity is included in the hypothesis subset. This behaviour is
reflected in privacy metrics Œ†1 and Œ†2 as shown in Fig. 10. But at
the same time, for large ùúå values, it becomes increasingly harder
for the attacker to pose a unique privacy threat to the user.

According to the violin plots in Fig. 10, for low privilege point
clouds, the increase in ùúå1 drastically drops the Œ†1 privacy, whereas
for high privilege point clouds, Œ†2 is already low, therefore the
increase in ùúå1 only induces a small drop in Œ†2 privacy. On the other
hand Œ†2 for low privilege point clouds is already ‚àº 1, therefore ùúå
should be increased by a significant fraction to induce a decrease
Œ†2 privacy. Another notable behaviour is that the privacy metrics
Œ†1 or Œ†2 vary non-linearly with ùúå in almost all different privilege
regions.

6.4 Utility results
In this work, we leveraged two utility metrics based on two generic
MR application functionalities that require 3D information in dif-
ferent levels of details as explained in ¬ß3.3. Fig. 11 shows the ag-
gregated utility metrics values (averaged across 10 super-classes
and 100 unique objects per each super-class) from the test dataset.

0.00.20.40.60.81.0Privilege Level (l)0.00.51.01(S*)J1J2J3J40.00.20.40.60.81.0Privilege Level (l)0.00.51.02(S*)0.10.30.50.70.10.30.50.70.10.30.50.7Low PrivilegeMedium PrivilegeHigh PrivilegePrivilege Level (l)0.00.20.40.60.81.01(S*)10.10.30.50.70.010.030.050.10.30.50.010.030.050.10.30.50.010.030.050.10.30.5Low PrivilegeMedium PrivilegeHigh PrivilegePrivilege Level (l)0.00.20.40.60.81.02(S*)20.010.030.050.10.30.5A. Nama, A. Dharmasiri, K. Thilakarathna, A. Zomaya, and J. A. de Guzman

(a) Bounding Box Q1

(b) Static Anchoring Q2

(c) Dynamic Anchoring Q2

(d) Chamfer Distance

Figure 11: Utility metrics aggregated for all test point clouds
at varying privilege levels

Additionally, we also use Chamfer distance as a measurement of
structural dissimilarity between the original point cloud and its
regenerated counterparts at different privilege levels. This measure-
ment gives insight into the success of regenerated point clouds in
delivering MR functionalities which require near-truth representa-
tions of objects.

Utility metric ùëÑ1 given in Eq. 3 calculates the IoU between the
bounding boxes that encompasses the original point cloud and the
regenerated point cloud. A higher IoU implying that the dimensions
and location of the regenerated point cloud is more similar to that
of the original. As shown in Fig. 11a, ùëÑ1 reaches 0.78 by 0.167
percentage privilege (low privilege), and 0.83 by 0.232 percentage
privilege (medium privilege), and maintains a ùëÑ1 of ‚àº 0.9 between
percentage privileges 0.332 to 1 (high privilege). It is evident that
the utility of the proposed regeneration mechanism with respect to
ùëÑ1 utility converges quickly, indicating a reasonably good utility
guaranteed even for point clouds released with lower privileges.

Figures 11b-11c shows the aggregated results for the test dataset
with respect to ùëÑ2 given in Eq. 5. We implemented a RANSAC
based plane fitting to find the point clouds corresponding to the
most prominent 2D horizontal plane in each transformed object,
and compared its attributes with the corresponding plane from the
original object. Since our dataset is limited to household objects,
and anchoring virtual objects predominantly happen for horizontal
planes, we conducted the analysis for horizontal planes. By ùëô =
0.167, ùëÑ2:ùëÜùë°ùëéùë°ùëñùëê and ùëÑ2:ùê∑ùë¶ùëõùëéùëöùëñùëê reach 0.70 and 0.69 respectively, and
by ùëô = 0.232, ùëÑ2:ùëÜùë°ùëéùë°ùëñùëê and ùëÑ2:ùê∑ùë¶ùëõùëéùëöùëñùëê reach 0.84 and 0.79.

The unexpected variations in the ùëÑ2 utilities in the very low ùëô
range, ùëô < 0.1, can be accounted for the abrupt variation of point
cloud re-generations with high loss values.

Next, Fig. 11d shows the Chamfer distance between original
and regenrated point clouds (at varying privilege levels) averaged
across all super-classes unique objects in each super-class. As shown
in the graph, by 0.167 percentage privilege, the average chamfer
distance has already decreased to 0.03, and by 0.232 percentage
privilege, to 0.01. This indicates that the regenerated point clouds
from the proposed framework are able to effectively retain the
structural properties and its associated utilities even in the point
clouds released with lesser privilege. Finally, the error margins in
every utility metric in Fig. 11 makes it evident that the proposed
framework allows the discussed utilities consistently across a large

Figure 12: Privacy and Utility metrics vs privilege level. Indi-
cates the tradeoff between offered privacy and utility levels

(a) Œ† vs Q1

(b) Œ† vs static Q1

(c) Œ† vs dynamic Q2

(d) Œ† vs Chamfer distance

Figure 13: Privacy metrics Œ†1 and Œ†2 vs the 3 Utility metrics
and Chamfer distance. Area under the plots indicates the ef-
fectiveness of the framework.

number of super-classes and objects despite the large variation in
their shapes and structures.

6.5 Privacy-utility trade-off
Fig. 12 shows how the privacy metrics Œ†1 and Œ†2, and the utility
metrics ùëÑ1, ùëÑ2:ùëÜùë°ùëéùë°ùëñùëê , and ùëÑ2:ùê∑ùë¶ùëõùëéùëöùëñùëê vary with different privilege
levels (ùëô) allowed by the privilege slider. This analysis is done over
the test dataset explained in ¬ß5.1 using the Attacker ùêΩ1 which is
trained on publicly available data, for hypothesis subset size=1.
Consistent with the results from previous sections (¬ß6.1, ¬ß6.2, and
¬ß6.4), the privacy metrics drop (with the super-class privacy drop-
ping faster than the intra-class privacy) while the utility metrics
increase drastically as the exposed privilege level ùëô is increased.
Baseline privacy metrics Œ†1:ùêµ and Œ†2:ùêµ are shown in dashed lines
for comparison.

At ùëô = 0.10, a relatively high super-class privacy, i.e. Œ†1 > 0.63,
can only be maintained at low utility values, i.e. 0.50 < ùëÑ < 0.57.
On the other hand, the same relatively high intra-class privacy, i.e.
Œ†2 > 0.63, can be maintained while providing potentially higher
utility, i.e. 0.83 < ùëÑ < 0.87, at ùëô = 0.25. For regenerations with
ùëô ‚â§ 0.25, the lower bound of Œ†1 is 0.09, and the lower bound of Œ†2
is 0.63. It implies that for privilege levels ùëô ‚â§ 0.25, although there‚Äôs
a high chance of the object‚Äôs super-class label to be exposed, it‚Äôs
uniqueness within that super-class cannot be ascertained by an
attacker.

0.00.20.40.60.81.0Privilege Level (l)0.00.51.0Q1 UtilityQ10.00.20.40.60.81.0Privilege Level (l)0.00.51.0Q2:Static UtilityQ2:Static0.00.20.40.60.81.0Privilege Level (l)0.00.51.0Q2:Dynamic UtilityQ2:Dynamic0.00.20.40.60.81.0Privilege Level (l)0.00.10.20.3CDCD0.00.20.40.60.81.0Q1 Utility0.00.51.0i(S*)1(S*)2(S*)0.00.20.40.60.81.0Q2:Static Utility0.00.51.0i(S*)1(S*)2(S*)0.00.20.40.60.81.0Q2:Dynamic Utility0.00.51.0i(S*)1(S*)2(S*)0.000.050.100.150.200.25Chamfer Distance0.00.51.0i(S*)1(S*)2(S*)User configurable 3D object regeneration for spatial privacy

Table 2: AUC Scores for Privacy-Utility curve

AuC

Œ†1 (ùëÜ‚àó)
Œ†2 (ùëÜ‚àó)

ùëÑ1
0.55
0.87

Utility or distance
ùëÑ2:ùëÜùë°ùëéùë°ùëñùëê
0.54
0.87

ùëÑ2:ùê∑ùë¶ùëõùëéùëöùëñùëê CD
0.64
0.49
0.89
0.84

In the medium privilege region (e.g, ùëô = 0.20), privacy metric
values Œ†1 = 0.21 (0.17 improvement from baseline) and Œ†2 = 0.85
(0.68 improvement from baseline) can be guaranteed for a utility
0.77 < ùëÑ < 0.81. Moreover, we can draw a ‚Äúgoldilocks‚Äù privilege
level range of 0.17 < ùëô < 0.25 which allows us to really ensure both
high intra-class privacy, i.e. Œ†2 > 0.63, and utility, i.e. ùëÑ1, ùëÑ2 > 0.70.
AUC as privacy mechanism efficiency. Fig. 13 shows the variation
of the privacy metrics vs. different utility metrics including the
Chamfer distance. The objective of the proposed privacy frame-
work is to regenerate point clouds so that the utility is maximized
(transformation error minimized) while the privacy against object
inference/reidentification attacks is also maximized. For the case of
Chamfer distance, structual similarity of regenerations should be
maximized by minimizing the Chamfer distance, while maximizing
ensured privacy. Hence, we formulate a generic measurement for
the efficiency of any privacy mechanism in terms of the Area under
the curve - AUC of the Privacy-Utility graph. Note that the AUC
measurement for chamfer distance in Fig. 13d is normalized by the
total area of the plot.

As shown in Table 2, using the AUC to measure the efficiency
of our proposed mechanism, we can see that the AUC range is at
the medium level with 0.49 < ùê¥ùëàùê∂ < 0.64 for super-class privacy,
while the AUC range is at the high level with 0.84 < ùê¥ùëàùê∂ < 0.89
for intra-class privacy. This corroborates our earlier discussion
that the proposed privacy framework can maintain high intra-class
privacy while ensuring high utility despite that an equally high
super-class privacy isn‚Äôt guaranteed. Again, the privilege level range
of 0.17 < ùëô < 0.25 ensures this performance as shown in Fig. 12.

7 LIMITATIONS & FUTURE WORK
Despite not being able to ensure the super-class privacy, the pro-
posed privacy framework can ensure relatively high intra-class
privacy and utility, i.e. Œ†2 > 0.63, ùëÑ > 0.70, at a privilege level
range of 0.17 < ùëô < 0.25. This is arguably acceptable as most non-
critical MR functionalities may not necessarily require a unique
object but only requires that the type or super-class of object be
known. Moreover, since the unique identity (i.e. intra-class label)
of the object is not exposed, the associated personally identifiable
information with the unique object identity remains unexposed.
Following the attacker descriptions from ¬ß5.2, as long as the user
maintains a relatively low privilege level of ùëô < 0.23, even with a
high-privileged attacker like ùêΩ4, we can expect that the intra-class
privacy of the regenerations are kept relatively high Œ†2 > 0.67 with
a high upper bound for both utilities ùëÑ1, ùëÑ2 < 0.83.

Temporal relationships of attacker success. So far, we have pri-
marily quantified the object reidentification privacy in terms of an
attacker formulating a hypothesis to match a query point cloud
object ùëÜ‚àó with one or set of reference point cloud objects. Quantifi-
cation was done based on the expected error in this hypothesis. On
the other hand, another type of privacy threat could be posed in

a situation where the attacker‚Äôs hypothesis on the query doesn‚Äôt
correctly match with the corresponding original point cloud, but
consistently matches with the same mismatching class over a large
number of ùëÜ‚àó queries from the same object. Here, although the
object is not correctly reidentified, the attacker can generate a
unique reference with respect to its previous queries and locate
that object in a user‚Äôs surrounding. A successful privacy-based
regeneration framework should be able to regenerate the privacy
preserved version of the same object with enough variation be-
tween each iteration such that the possible misclassifications at the
attacker‚Äôs end would not be consistent. We hope to do this analysis
and evaluate the performance of our proposed framework in this
context in future work.

Point cloud segmentation-then-transformation. Given a captured
spatial mapping represented as a point cloud, relevant features
in the point cloud needs to be detected and separated in order to
process it further. For the proposed privacy framework, it is also
necessary for the point cloud to be segmented and, then, separately
transform the different objects to improve their privacy. In this
work, we have directly explored and investigated the viability of the
framework over already separated object point clouds. We intend to
incorporate the actual segmentation task within a future iteration
of this framework and apply the privacy transformations to these
segmented point clouds.

8 CONCLUSION
Mixed reality and 3D processing technologies are steadily develop-
ing in parallel: advances in MR aim to improve the environmental
understanding of the various viable devices that can be used for
MR, while advances in 3D, particularly in machine learning, enables
better processing of 3D data (i.e. 3D segmentation, classification,
and identification). The interplay of the two technologies allows
the rapid development and delivery of better and immersive MR
experiences. However, at the same time, there is a rapid increase
in the level of privacy risks that MR users are exposed to. These
3D processing algorithms along their with ever improving accu-
racy and discriminative power can be utilized by adversaries to
reveal personally identifiable information from the 3D data that is
captured and collected by MR devices and platforms.

In this work, we leverage these state-of-the-art 3D algorithms (1)
to design a privacy framework for regenerating 3D point cloud data,
and (2) to evaluate the viability of this framework using the latest 3D
neural network-based classifiers. With the proposed privacy frame-
work, varying the privilege level allows us to variably transform
and, hence, effectively control the privacy exposure of the shared
3D data to potentially malicious third party applications. That is, as
we increase the allowed privilege level ùëô, the privacy Œ† decreases,
while the utility ùëÑ increases. Nonetheless, the proposed privacy
framework is still able to ensure a relatively high intra-class pri-
vacy and utility if the privilege level is kept within 0.17 < ùëô < 0.25.
Therefore, despite not being able to always ensure the super-class
privacy of a 3D object, the proposed privacy-aware 3D regeneration
can prevent unique intra-class reidentification of 3D objects while
maintaining high utility for common MR functionalities.

REFERENCES
[1] Panos Achlioptas, Olga Diamanti, Ioannis Mitliagkas, and Leonidas J Guibas.
2017. Learning Representations and Generative Models For 3D Point Clouds.
arXiv preprint arXiv:1707.02392 (2017).

[2] Mihael Ankerst, Gabi Kastenm√ºller, Hans-Peter Kriegel, and Thomas Seidl. 1999.
3D shape histograms for similarity search and classification in spatial databases.
In International symposium on spatial databases. Springer, 207‚Äì226.

[3] Cara Bloom, Joshua Tan, Javed Ramjohn, and Lujo Bauer. 2017. Self-driving cars
and data collection: Privacy perceptions of networked autonomous vehicles. In
Thirteenth Symposium on Usable Privacy and Security ({SOUPS} 2017). 357‚Äì375.
[4] Angel X. Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing
Huang, Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, Jianx-
iong Xiao, Li Yi, and Fisher Yu. 2015. ShapeNet: An Information-Rich 3D Model
Repository. Technical Report arXiv:1512.03012 [cs.GR]. Stanford University ‚Äî
Princeton University ‚Äî Toyota Technological Institute at Chicago.

[5] Kunal Chelani, Fredrik Kahl, and Torsten Sattler. 2021.

How Privacy-
Preserving are Line Clouds? Recovering Scene Details from 3D Lines. 1 (2021).
arXiv:2103.05086 http://arxiv.org/abs/2103.05086

[6] Jaybie A de Guzman, Kanchana Thilakarathna, and Aruna Seneviratne. 2019. A
First Look into Privacy Leakage in 3D Mixed Reality Data. In European Symposium
on Research in Computer Security. Springer, 149‚Äì169.

[7] Jaybie A de Guzman, Kanchana Thilakarathna, and Aruna Seneviratne. 2019.
SafeMR: Privacy-aware Visual Information Protection for Mobile Mixed Reality.
In 2019 IEEE 41st Conference on Local Computer Networks (LCN). IEEE.

[8] Jaybie A. De Guzman, Kanchana Thilakarathna, and Aruna Seneviratne. 2019.
Security and Privacy Approaches in Mixed Reality: A Literature Survey. ACM
Comput. Surv. 52, 6, Article 110 (Oct. 2019), 37 pages. https://doi.org/10.1145/
3359626

[9] Jaybie A de Guzman, Kanchana Thilakarathna, and Aruna Seneviratne. 2020.
Conservative Plane Releasing for Spatial Privacy Protection in Mixed Reality.
arXiv preprint arXiv:2004.08029 (2020).

[10] H Quynh Dinh and Liefei Xu. 2008. Measuring the similarity of vector fields using
global distributions. In Joint IAPR International Workshops on Statistical Techniques
in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition (SSPR).
Springer, 187‚Äì196.

[11] Mihai Dusmanu, Johannes L. Sch√∂nberger, Sudipta N. Sinha, and Marc Pollefeys.
2020. Privacy-Preserving Image Features via Adversarial Affine Subspace Em-
beddings. (2020), 14267‚Äì14277. arXiv:2006.06634 http://arxiv.org/abs/2006.06634
[12] Lucas Silva Figueiredo, Benjamin Livshits, David Molnar, and Margus Veanes.
2016. Prepose: Privacy, Security, and Reliability for Gesture-Based Programming.
In Security and Privacy (SP), 2016 IEEE Symposium on. IEEE, 122‚Äì137.

[13] Martin A. Fischler and Robert C. Bolles. 1981. Random Sample Consensus: A
Paradigm for Model Fitting with Applications to Image Analysis and Automated
Cartography. Commun. ACM 24, 6 (June 1981), 381‚Äì395. https://doi.org/10.1145/
358669.358692

[14] Batya Friedman and Peter H Kahn Jr. 2000. New directions: A Value-Sensitive
Design approach to augmented reality. In Proceedings of DARE 2000 on designing
augmented reality environments. ACM, 163‚Äì164.

[15] Marcel Geppert, Viktor Larsson, Pablo Speciale, Johannes L. Sch√∂nberger, and
Marc Pollefeys. 2020. Privacy Preserving Structure-from-Motion. Lecture Notes
in Computer Science (including subseries Lecture Notes in Artificial Intelligence and
Lecture Notes in Bioinformatics) 12346 LNCS (2020), 333‚Äì350. https://doi.org/10.
1007/978-3-030-58452-8_20

[16] Jaybie Agullo de Guzman, Aruna Seneviratne, and Kanchana Thilakarathna. 2021.
Unravelling Spatial Privacy Risks of Mobile Mixed Reality Data. Proc. ACM
Interact. Mob. Wearable Ubiquitous Technol. 5, 1, Article 14 (March 2021), 26 pages.
https://doi.org/10.1145/3448103

[17] Jing Huang and Suya You. 2012. Point cloud matching based on 3D self-similarity.
In Computer Vision and Pattern Recognition Workshops (CVPRW), 2012 IEEE Com-
puter Society Conference on. IEEE, 41‚Äì48.

[18] Suman Jana, David Molnar, Alexander Moshchuk, Alan M Dunn, Benjamin
Livshits, Helen J Wang, and Eyal Ofek. 2013. Enabling Fine-Grained Permissions
for Augmented Reality Applications with Recognizers.. In USENIX Security.
[19] Xin Jin, Zhaoxing Wu, Chenggen Song, Chunwei Zhang, and Xiaodong Li. 2016.
3D point cloud encryption through chaotic mapping. Lecture Notes in Computer
Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes
in Bioinformatics) 9916 LNCS (2016), 119‚Äì129. https://doi.org/10.1007/978-3-
319-48890-5_12

[20] Andrew Edie Johnson and Martial Hebert. 1998. Surface matching for object
recognition in complex three-dimensional scenes. Image and Vision Computing
16, 9-10 (1998), 635‚Äì651.

[21] Andrew E Johnson and Martial Hebert. 1999. Using spin images for efficient
object recognition in cluttered 3D scenes. IEEE Transactions on Pattern Analysis
& Machine Intelligence 5 (1999), 433‚Äì449.

[22] Seohyun Kim, Jaeyoo Park, and Bohyung Han. 2020. Rotation-Invariant
Local-to-Global Representation Learning for 3D Point Cloud. NeurIPS (2020).
arXiv:2010.03318 http://arxiv.org/abs/2010.03318

A. Nama, A. Dharmasiri, K. Thilakarathna, A. Zomaya, and J. A. de Guzman

[23] Daniel Liu, Ronald Yu, and Hao Su. 2019. Extending Adversarial Attacks
and Defenses to Deep 3D Point Cloud Classifiers. Proceedings - International
Conference on Image Processing, ICIP 2019-Septe (2019), 2279‚Äì2283.
https:
//doi.org/10.1109/ICIP.2019.8803770 arXiv:1901.03006

[24] Ryutarou Ohbuchi, Takahiro Minamitani, and Tsuyoshi Takei. 2005. Shape-
similarity search of 3D models by using enhanced shape functions. International
Journal of Computer Applications in Technology 23, 2-4 (2005), 70‚Äì85.

[25] Robert Osada, Thomas Funkhouser, Bernard Chazelle, and David Dobkin. 2002.
Shape distributions. ACM Transactions on Graphics (TOG) 21, 4 (2002), 807‚Äì832.
[26] Francesco Pittaluga, Sanjeev J Koppal, Sing Bing Kang, and Sudipta N Sinha.
2019. Revealing scenes by inverting structure from motion reconstructions. In
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.
145‚Äì154.

[27] Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. 2017. Pointnet: Deep
learning on point sets for 3d classification and segmentation. In Proceedings of
the IEEE Conference on Computer Vision and Pattern Recognition. 652‚Äì660.
[28] Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J Guibas. 2017. Pointnet++:
Deep hierarchical feature learning on point sets in a metric space. In Advances in
neural information processing systems. 5099‚Äì5108.

[29] Siddhant Ranade, Xin Yu, Shantnu Kakkar, Pedro Miraldo, and Srikumar Ra-
malingam. 2021. Mapping of Sparse 3D Data Using Alternating Projection.
Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial
Intelligence and Lecture Notes in Bioinformatics) 12622 LNCS (2021), 295‚Äì313.
https://doi.org/10.1007/978-3-030-69525-5_18 arXiv:2010.02516

[30] Franziska Roesner, Tadayoshi Kohno, and David Molnar. 2014. Security and
Privacy for Augmented Reality Systems. Commun. ACM 57, 4 (April 2014), 88‚Äì96.
https://doi.org/10.1145/2580723.2580730

[31] Muhamad Risqi U Saputra, Andrew Markham, and Niki Trigoni. 2018. Visual
SLAM and structure from motion in dynamic environments: A survey. ACM
Computing Surveys (CSUR) 51, 2 (2018), 37.

[32] Yoones A Sekhavat. 2017. Privacy preserving cloth try-on using mobile aug-
mented reality. IEEE Transactions on Multimedia 19, 5 (2017), 1041‚Äì1049.
[33] Mikiya Shibuya, Shinya Sumikura, and Ken Sakurada. 2020. Privacy Preserving
Visual SLAM. Lecture Notes in Computer Science (including subseries Lecture Notes
in Artificial Intelligence and Lecture Notes in Bioinformatics) 12367 LNCS, iii (2020),
102‚Äì118. https://doi.org/10.1007/978-3-030-58542-6_7 arXiv:2007.10361
[34] Pablo Speciale, Johannes L Schonberger, Sing Bing Kang, Sudipta N Sinha, and
Marc Pollefeys. 2019. Privacy preserving image-based localization. In Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition. 5493‚Äì5503.
[35] Przemys≈Çaw Spurek, Sebastian Winczowski, Jacek Tabor, Maciej Zamorski, Maciej
Zieba, and Tomasz Trzcinski. 2020. Hypernetwork approach to generating point
clouds. In Proceedings of the 37th International Conference on Machine Learning
(Proceedings of Machine Learning Research, Vol. 119), Hal Daum√© III and Aarti Singh
(Eds.). PMLR, 9099‚Äì9108. http://proceedings.mlr.press/v119/spurek20a.html
[36] Jian Sun, Maks Ovsjanikov, and Leonidas Guibas. 2009. A concise and provably
informative multi-scale signature based on heat diffusion. In Computer graphics
forum, Vol. 28. Wiley Online Library, 1383‚Äì1392.

[37] Chong Xiang, Charles R. Qi, and Bo Li. 2019. Generating 3D adversarial point
clouds. Proceedings of the IEEE Computer Society Conference on Computer Vision
and Pattern Recognition 2019-June (2019), 9128‚Äì9136. https://doi.org/10.1109/
CVPR.2019.00935 arXiv:1809.07016

[38] Z. Ye, N. Umetani, T. Igarashi, and T. Hoffmann. 2021. A Curvature and Density-
based Generative Representation of Shapes. Computer Graphics Forum 40, 1
(2021), 38‚Äì53. https://doi.org/10.1111/cgf.14094 arXiv:2009.02494

[39] Huanle Zhang, Bo Han, Cheuk Yiu Ip, and Prasant Mohapatra. 2020. Slimmer:
Accelerating 3D semantic segmentation for mobile augmented reality. Proceedings
- 2020 IEEE 17th International Conference on Mobile Ad Hoc and Smart Systems,
MASS 2020 (2020), 603‚Äì612. https://doi.org/10.1109/MASS50613.2020.00079
[40] Yu Zhang, Gongbo Liang, Tawfiq Salem, and Nathan Jacobs. 2019. Defense-
PointNet: Protecting PointNet Against Adversarial Attacks. Proceedings - 2019
IEEE International Conference on Big Data, Big Data 2019 (2019), 5654‚Äì5660. https:
//doi.org/10.1109/BigData47090.2019.9006307 arXiv:2002.11881

[41] Tianhang Zheng, Changyou Chen, Junsong Yuan, Bo Li, and Kui Ren. 2019.
Pointcloud saliency maps. Proceedings of the IEEE International Conference on
Computer Vision 2019-Octob (2019), 1598‚Äì1606. https://doi.org/10.1109/ICCV.
2019.00168 arXiv:1812.01687

[42] Hang Zhou, Kejiang Chen, Weiming Zhang, Han Fang, Wenbo Zhou, and Nenghai
Yu. 2019. DUP-net: Denoiser and upsampler network for 3D adversarial point
clouds defense. Proceedings of the IEEE International Conference on Computer
Vision 2019-Octob (2019), 1961‚Äì1970. https://doi.org/10.1109/ICCV.2019.00205
arXiv:1812.11017

User configurable 3D object regeneration for spatial privacy

A APPENDIX
A.1 Privacy metric results for the top-1 success

of Attacker ùêΩ1

For the completion of Fig. 7, here in Fig. 14 we show the privacy
metric results of Attacker ùêΩ1 top-1 case for the remaining 6 classes.

(a) Super-class Privacy Œ†1 (S‚àó) with Attacker ùêΩ2

(a) Bathtub

(b) Bookshelf

(b) Intra-class Privacy Œ†2 (S‚àó) with Attacker ùêΩ2

(c) Cabinet

(d) Lamp

(c) Super-class Privacy Œ†1 (S‚àó) with Attacker ùêΩ3

(e) Monitor

(f) Sofa

Figure 14: Super-class Œ†1 and intra-class Œ†2 privacy mea-
sures for the top-1 success of attacker 1 for some 3D objects:
(a) bathtub, (b) bookshelf, (c) cabinet, (d) lamp, (e) monitor,
and (f) sofa.

A.2 Non-aggregated utility metrics for all

super-classes

Fig. 15 shows all utility metrics including the Chamfer distance for
every super-class.

(d) Intra-class Privacy Œ†2 (S‚àó) with Attacker ùêΩ3

(e) Super-class Privacy Œ†1 (S‚àó) with Attacker ùêΩ4

(a) Bounding Box Q1

(b) Static Anchoring Q2

(c) Dynamic Anchoring Q2

(d) Chamfer Distance

Figure 15: Utility Plots

(f) Intra-class Privacy Œ†2 (S‚àó) with Attacker ùêΩ4
Figure 16: Œ†1 and Œ†2 metrics aggregated at various hypothe-
sis sizes for Attackers ùêΩ2, ùêΩ3 and ùêΩ4

A.3 Privacy metric results for varying sizes of
hypothesis sets for all the attackers

In ¬ß6.3 (as shown in Fig. 10), we discussed the aggregated varia-
tions in privacy metric as we vary the size of hypothesis sets ùúå for
Attacker ùêΩ1. In Fig. 16, we display similarly aggregated Œ† results
for Attackers ùêΩ2, ùêΩ3 and ùêΩ4.

0.00.20.40.60.81.0Privilege Level (l)0.00.51.0i(S*)1:B2:B1(S*)2(S*)0.00.20.40.60.81.0Privilege Level (l)0.00.51.0i(S*)1:B2:B1(S*)2(S*)0.00.20.40.60.81.0Privilege Level (l)0.00.51.0i(S*)1:B2:B1(S*)2(S*)0.00.20.40.60.81.0Privilege Level (l)0.00.51.0i(S*)1:B2:B1(S*)2(S*)0.00.20.40.60.81.0Privilege Level (l)0.00.51.0i(S*)1:B2:B1(S*)2(S*)0.00.20.40.60.81.0Privilege Level (l)0.00.51.0i(S*)1:B2:B1(S*)2(S*)0.00.20.40.60.81.0Privilege Level (l)0.00.51.0Q1 Utilitybathtubbedbenchbookshelfcabinetchairlampmonitorsofatable0.00.20.40.60.81.0Privilege Level (l)0.00.51.0Q2:Static Utilitybathtubbedbenchbookshelfcabinetchairlampmonitorsofatable0.00.20.40.60.81.0Privilege Level (l)0.00.51.0Q2:Dynamic Utilitybathtubbedbenchbookshelfcabinetchairlampmonitorsofatable0.00.20.40.60.81.0Privilege Level (l)0.00.20.4CDbathtubbedbenchbookshelfcabinetchairlampmonitorsofatable0.10.30.50.70.10.30.50.70.10.30.50.7Low PrivilegeMedium PrivilegeHigh PrivilegePrivilege Level (l)0.00.20.40.60.81.01(S*)10.10.30.50.70.010.030.050.10.30.50.010.030.050.10.30.50.010.030.050.10.30.5Low PrivilegeMedium PrivilegeHigh PrivilegePrivilege Level (l)0.00.20.40.60.81.02(S*)20.010.030.050.10.30.50.10.30.50.70.10.30.50.70.10.30.50.7Low PrivilegeMedium PrivilegeHigh PrivilegePrivilege Level (l)0.00.20.40.60.81.01(S*)10.10.30.50.70.010.030.050.10.30.50.010.030.050.10.30.50.010.030.050.10.30.5Low PrivilegeMedium PrivilegeHigh PrivilegePrivilege Level (l)0.00.20.40.60.81.02(S*)20.010.030.050.10.30.50.10.30.50.70.10.30.50.70.10.30.50.7Low PrivilegeMedium PrivilegeHigh PrivilegePrivilege Level (l)0.00.20.40.60.81.01(S*)10.10.30.50.70.010.030.050.10.30.50.010.030.050.10.30.50.010.030.050.10.30.5Low PrivilegeMedium PrivilegeHigh PrivilegePrivilege Level (l)0.00.20.40.60.81.02(S*)20.010.030.050.10.30.5A. Nama, A. Dharmasiri, K. Thilakarathna, A. Zomaya, and J. A. de Guzman

Figure 17: Sample 3D regenerations from each super-class at different privilege levels.

A.4 Example plots of 3D regenerations
Fig. 17 shows example 3D point clouds for all super-classes regen-
erated at different privilege levels.

A.5 Example 3D plots for the RANSAC sitting

plane for ùëÑ2 utility

Fig. 18 shows example 3D point clouds for the RANSAC-generated
sitting plane at different privilege levels.

User configurable 3D object regeneration for spatial privacy

Figure 18: RANSAC sitting plane ( ¬Øùëù) and regenerated point cloud ( ¬ØùëÜ) for Chair and Table classes at different privilege levels.

