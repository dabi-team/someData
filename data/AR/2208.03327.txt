SeamlessIterativeSemi-SupervisedCorrectionofImperfectLabelsinMicroscopyImagesMarawanElbatel?,ChristinaBornberg?,ManasiKattel,EnriqueAlmar,ClaudioMarrocco,andAlessandroBriaUniversityofCassinoandSouthernLazio,Cassino,Italymarawan.elbatel@studentmail.unicas.itAbstract.In-vitrotestsareanalternativetoanimaltestingforthetoxicityofmedicaldevices.Detectingcellsasaﬁrststep,acellexpertevaluatesthegrowthofcellsaccordingtocytotoxicitygradeunderthemicroscope.Thus,humanfatigueplaysaroleinerrormaking,makingtheuseofdeeplearningappealing.Duetothehighcostoftrainingdataan-notation,anapproachwithoutmanualannotationisneeded.WeproposeSeamlessIterativeSemi-SupervisedcorrectionofImperfectlabels(SISSI),anewmethodfortrainingobjectdetectionmodelswithnoisyandmiss-ingannotationsinasemi-supervisedfashion.Ournetworklearnsfromnoisylabelsgeneratedwithsimpleimageprocessingalgorithms,whichareiterativelycorrectedduringself-training.Duetothenatureofmissingboundingboxesinthepseudolabels,whichwouldnegativelyaﬀectthetraining,weproposetotrainondynamicallygeneratedsynthetic-likeim-agesusingseamlesscloning.Ourmethodsuccessfullyprovidesanadap-tiveearlylearningcorrectiontechniqueforobjectdetection.Thecombi-nationofearlylearningcorrectionthathasbeenappliedinclassiﬁcationandsemanticsegmentationbeforeandsynthetic-likeimagegenerationprovestobemoreeﬀectivethantheusualsemi-supervisedapproachby>15%APand>20%ARacrossthreediﬀerentreaders.Ourcodeisavailableathttps://github.com/marwankefah/SISSI.Keywords:LabelCorrection·CellDetection·Semi-SupervisedObjectDetection1IntroductionTestingmedicaldeviceswithanimalshavealongtraditionaccordingtoISO10993[1].Since2017theISO10993hasgraduallyevolvedtowardsimplement-ingalternativetestmethods.Oneofthein-vitromethodsisthetestingofcyto-toxicity,describedintheISO10993-5[3].CellexpertsanalyzecellgrowthofaﬁbroblastcelllinesuchasL929withthehelpofamicroscope.Theacceptancecriteriaformedicaldevicesis50%ofdeadcells(grade2criteria).Iftherearemorethan50%deadcells,themedicaldeviceisnotallowedtoenterthemarket.?Co-ﬁrstauthorsarXiv:2208.03327v1  [eess.IV]  5 Aug 20222Elbateletal.Faster R-CNNPseudo labelgeneration CellLabTrainSet Pseudo label1 image20 augmented versionsBB for 20 inverseaugmented versionsWBF for average BB blurred image withseamless cloned cellsFaster R-CNNTrain 1 epoch CellLabTrainSet SEMI-SUPERVISED PHASE CellposeTrainSet Mixed Batch TrainSet EARLY LEARNING PHASEFaster R-CNNPre-training CellLabTrainSet CellposeTrainSet Mixed Batch TrainSet END OF EARLYLEARNING Fig.1.OverallschemeofSISSIframework.Inthiscontext,deeplearningcanserveasasecondopinionsincehumanerrorintheworkplaceiscostlyanddependentontheleveloffatigue;thegreatertheleveloffatigue,thehighertheriskoferrorsoccurring.Especiallyintheborder-linecasesofgrade2,thecellexpertneedstobeabletoobtainasecondopinionthatisindependentofhumanfatigue.Deeplearninghasshownsubstantialben-eﬁtsindiﬀerentlifescienceandpharmaapplicationssuchaschemo-informatics,computationalgenomics,andbiomedicalimagingsuchascellsegmentation[12]andseemstobeapromisingsupplementtocytotoxicitygrading.Intheﬁrstinstance,cellsneedtobedetected,andinfuturework,anintuitivewayofclas-sifyingcellsintodeadoraliveneedstobefound.Whendealingwithimperfectdatasets,problemsincluding(partly)missing,inaccurate,orwronglabelsarise.Tohandleimperfectdatasetsinobjectdetec-tion/segmentationtasks,onecanleverageunlabelled(self/semi-supervised)orexternallabelled(transferlearning)data,regularisetraining,learnwithclasslabels,andrevisitlossfunctions(sparse/noisylabels)[15].2RelatedWorksPreviousworkhasstudiedimperfectdatasets,includingsemanticsegmentation,instancesegmentation,andobjectdetection[18,19,4].[18]proposeapipelineforsemanticsemi-supervisedsegmentationthatseparatespixelsofapseudolabelledimageintoreliableandunreliable.[6]proposeAdaptiveEarlyLearningCorrection(ADELE)forsemanticsegmentation,withasupervisedearly-learningphaseandsubsequentlyalabelcorrectionphase.[8]proposealabelminingpipelineformissingannotationsusingco-teachingforinstancesegmentation.[19]proposetogeneratemaskswiththeCircleHoughTransform(CHT)anditerativelycreatepseudolabelswithself-trainingforimageswhereCHTfailed.[20]proposetouseabackgroundcalibrationlossinspiredbyfocallossforobjectdetectionwithmissingannotations.[4]proposeonlyannotatingoneinstanceSISSI:SeamlessIterativeSemi-SupervisedCorrectionofImperfectLabels3CellPose(Source)CellLab(Target)Fig.2.Examplesofthethelabelledsourceandthenoisylabelledtargetdatasets.percategoryinanimageanditerativelygeneratingpseudo-labels.[2]proposeanobjectdetectortohandlenoisylabels,maskingthenegativesamplelossintheboxpredictortoavoidtheharmoffalse-negativelabels.Thoughadvancesindealingwithimperfectdatasetshavebeenmade,theproblemofdealingwithdatasetshavingpartlymissinglabelsthatareaddition-allynoisyinobjectdetectiontasksremains.WeproposeSISSI(SeamlessIterativeSemi-SupervisedcorrectionofImper-fectlabels)fortrainingobjectdetectionmodelswithnoisyandmissinglabelsinasemi-supervisedfashion,seeFig.1.Weperformseveralexperimentswithmixed-batchtraining,self-trainingwithiterativelabelcorrection,synthetic-likeimagegeneration,andalteringthestartingpointofself-training(ADELEvs.validationloss).3MaterialsandMethods3.1DatasetsMicroscopyimagesofﬁbroblast(L929)wereaquiredusingaNikonEclipseTS100microscopeandtheOPTOCAM-Icamera.Thistrainset(CellLabdataset)consistsof224images,andtheirnoisyannotationsaregeneratedwithsimpleim-ageprocessingpipelinessuchasCircleHoughTransform,Watershed,andEdgeDetection.AdetaileddescriptionoftheinitialweaklabelgenerationisshowninFig.5inAppendixA.TheCellLabtestsetconsistsofﬁveimages(640×480)an-notatedbythreecellexperts.Threereadersannotatedﬁveimagesindependently,resultingin(reader1)552,(reader2)565,and(reader3)477annotatedcellsfortheﬁveimages.InordertoperformdomainadaptationandenhanceourweakandnoisylabelledCellLabdataset,weusethelabelledCellpose[14]dataset.Itconsistsofalargevarietyofﬂuorescentmarkersandimagemodalities,aswellasnaturalimagesthatcanbesegmentedintorepetitivestructures/blobs.TheCellposedatasetisusedfortraining(45,215cellson539images)andvalidation(7,195cellson68images).Weextractboundingboxesfromthesegmentationmasksforourdetectiontask.WeshowexamplesofbothdatasetsinFig.2.4Elbateletal.3.2OverallFrameworkSISSIintegratesarangeofimageprocessinganddeeplearningmethodstomakeiterativelabelcorrectionpossible.Theearlylearningphaseconsistsofamixed-batchtrainingcombiningtheCellLabandCellposetrainingdatasets.WetraintheFasterR-CNNmodelinasupervisedfashionwithaBalancedGradientContribution[11],mixed-batchtraining,oftargetdatasetwithinitialnoisyannotationsandsourcedatasetuntilamemorisationphaseonthenoisyannotationsisreached.WedeterminetheendofearlylearningwithadecelerationpointbasedontheAP50curvebetweentheweakgroundtruthoftheCellLabdatasetandthemodeloutput.Inthefollowingsemi-supervisedphaseforeachcycle,ﬁrst,weapplyla-belcorrection,followedbymixed-batchtrainingwiththepseudolabelsandsynthetic-likeimages(excludingundetectedcells)oftheCellLabdatasetcom-binedwiththeoriginalCellposedataset.Pseudo-labelgenerationusestest-timeaugmentationandweightedboxesfusiontogenerateconﬁdentboundingboxes.Sincesomecellsarenotdetected,theirappearanceintheoriginalimagewillconfusethenetworkwhiletraining.Thus,wegeneratedynamicallysynthetic-likeimagesforcontinualtraining.TheoverallschemeofSISSIframeworkisshowninFig.1.3.3DeterminingtheStartoftheSemi-SupervisedPhaseWhiletrainingwithmixed-batchtraining,wenoticeatwo-stagelearningphe-nomenonpreviouslynotedinclassiﬁcationandsemanticsegmentation:inanearlylearningphase,thenetworkﬁtsthecleanannotations;then,thenetworkstartmemorisingtheinitialnoisyannotations[7,6].Toﬁndtheoptimalpointthatrepresentswhenthememorisationphasestarts,weadoptamethod,ADELE[6],thathasbeenusedinpreviousworksinthecontextofsemanticsegmenta-tion.Inourwork,werelyonthedecelerationoftheAP50trainingcurveofthemodeloutputandtheinitialnoisyannotateddataset,CellLab,todecidewhentostoptrustingtheinitialnoisyannotationsandgeneratepseudolabels.SeeFig.7inAppendixBfortheAP50trainingcurvewiththepointrepresentingwhenthememorisationphasestarts.3.4PseudoLabelGenerationPseudolabelgenerationisatechniquewhereapre-trainedneuralnetworkgen-erateslabelsforunlabelleddataorupdateslabelsfornoisylabeleddata[16].WegeneratepseudolabelstoupdatethenoisyannotationsoftheCellLabdatasetduringthesemi-supervisedphase.Self-trainingnetworkshavethedisadvantageofbeingunabletocorrecttheirownmistakes.Thereforebiasedandwronglabelscanbeampliﬁed.Toﬁlterpotentialboundingboxes,weintegratetwotechniques,test-timeaugmentation(TTA)[17]andweightedboxesfusion(WBF)[13].WeaveragepredictionsgeneratedwithTTAwhileconsideringtheconﬁdencescoreSISSI:SeamlessIterativeSemi-SupervisedCorrectionofImperfectLabels5Originaltt+3t+6t+9Fig.3.Exampleofasynthetic-likeimagewithweakblurringintrainingepochs(t).ofeachboundingboxinaWBFmanner:X1,2=PTi=1Ci·X1,2iPTi=1Ci,(1)whereTisthenumberforboundingboxesassignedtoasingleobjectinacluster,X1,2(orY1,2)istheaveragestartandendpointonthex(ory)axis.ThisyieldstheaverageoftheboundingboxcoordinatesX1,2i(orY1,2i),weightedwiththeconﬁdencescoreCiforeachboundingbox.3.5Synthetic-likeimageadaptationaccordingtopseudolabelsUndetectedcellsinthepseudolabelswouldaﬀectthefurthertrainingnegatively.Whenthenetworklocalisestrueobjectsthatarenotpresentinthepseudo-labels,thenetworkispenalisedforthoseobjectsthataretrue.Tosolvethisproblem,weproposetogeneratesynthetic-likeimagesdynamicallyaccordingtothepseudolabelsgeneratedfortheCellLabdataset,seeFig.3.Toremoveunlabeledcellsinthetrainingimageinordernottoconfusethenetwork,wecloneallthedetectedcellsofthepseudolabel(source)ontoastrongly/weaklyGaussianblurredimage(target).Toavoiddiscontinuitiesbetweenthetargetandthesource,wemixedgetextureswiththeseamlesscloningalgorithm(mixinggradient)[9].4Experiments4.1ImplementationDetailsThebackboneofourFasterR-CNNisaResNet-50,pre-trainedontheMSCOCOdataset[5].WesethyperparametersaccordingtoexistingFast/FasterR-CNNwork[10].Wedonotfreezeanylayertoallowthegradienttopropagatethroughtheearlylayers.WetrainthemodelsusingtheStochasticGradientDescent(SGD)optimiserwithamomentumof0.9,weightdecayof0.0002,andlearningrateof0.001.Weuseabatchsizeof8,withanequalnumberofimagesrandomlychosenfromtheCellLabandCellposedatasets,andresizetheimagesto512×512.Weper-formsimpleaugmentations:channelshuﬄe,Gaussianblurring,horizontalﬂip,verticalﬂip,andshift-scale-rotate.Fortest-timeaugmentationusedforlabel6Elbateletal.Algorithm1Pseudocodeforiterativeself-trainingwithSISSI,prediction(p),target(t),boundingboxes(bbs).Require:CLimg,CLbbst,CPimg,CPbbst.CellLabandCellposedatasetsRequire:NN(img).FasterR-CNNRequire:E←this.self_training_epochforeachpseudo_batchBinEdo.PseudolabelgenerationCLbbsp[n],scores[n]←NN(TTA(CLimg∈B)).GenerateboxeswithTTACLbbst←(PNn=1scores[n]·CLbbsp[n])/PNn=1scores[n].FilterbbswithWBFupdate_dataset(CLbbst).Updateﬁnalpseudolabelendforforeachmixed_batchBinEdo.TrainingCLimg_crops[n]←crop(CLimg,CLbbs).SyntheticimagegenerationCLimg_blur←blur(CLimg)CLimg_synth←seamless_clone(CLimg_blur,CLimg_crops[n])CLbbsp,CPbbsp←NN(CLimg_synth,CPimg∈B).PredictionCLCP_loss←loss([CLbbsp,CPbbsp],[CLbbst,CPbbst]).LosscalculationCLCP_loss.backprop()endforE.next()correction,weuseacombinationofscaling([0.8,0.9,1,1.1,1.2])andaugmen-tations,verticalﬂipping,horizontalﬂipping,horizontal+verticalﬂipping,ornoﬂipping.Weendupwith20versionsofthesameimage.Forbackgroundblurringinthesynthetic-likeimagegeneration,weuseGaussianblurringwithkernelsof(21,21)andkernels(12,32),referredtoasweak(W)andstrong(S)backgroundblurringrespectively.Thedatasetsareusedasfollows.Mixed-batchtrainingisappliedinboththeearlysupervisedandsemi-supervisedlearningphases,combiningtheCellLabandCellposetrainingsets.Withthestartofself-training,labelsandsynthetic-likeimagesfortheCellLabdatasetareupdatedineachfollowingepoch.Toperformvalidationforhyperparametertuning,weusetheCellposedatasetsinceonlyﬁvemanuallyannotatedimagesareavailableintheCellLabdataset,whichallareusedasatestset.Forestimatingtheendofearlylearning,theweaktraininglabelsofCellLabarecomparedtothemodeloutputasproposedinADELE.WecalculatedecelerationbytherelativechangeinthederivativeoftheAP50curve,andifitisaboveacertainthreshold,0.9,thenlabelcorrectionstarts.4.2EvaluationMetricsandResultsInTable1,wereportthreeversionsofAP,andARovertheCellLabtestset.ThemetricsincludethePascalVOCmetric(AP50),aswellasCOCOevaluationmetrics[5](AP75,andAPandARaveragedoverdiﬀerentIoUthresholds).Boldnumbersdenotethebestperformanceforeachofthethreecellexperts’annotations.WepresentthedetectionperformanceofdiﬀerentexperimentsontheCel-lLabtestset.TheBaselinemodelisﬁrsttrainedinasupervisedfashionwithSISSI:SeamlessIterativeSemi-SupervisedCorrectionofImperfectLabels7InputGroundTruthWeakLabelsADELEADELE+SISSIFig.4.Demonstrationofimprovementofresultswithourproposedmethod.mixed-batchtrainingofCellLabandCellposedatasets.Aimingtocorrectandcompletethelabels,weperformearly-stoppingbasedonthevalidationlossofthesourcedataset,Cellpose,andapplyself-trainingwithtest-timeaugmenta-tion(TTA)andweightedboxesfusion(WBF)toiterativelyupdatethepseudolabels.ThefollowingtwoexperimentsSISSI(W)andSISSI(S)additionallyusesynthetic-likeimagegenerationfortheCellLabimages,basedonthepseudola-belsgeneratedwithTTAandWBF.Theweak(W)backgroundblurringachievedbetterresultsthanthebaseline,whilestrong(S)backgroundblurringhasworseperformance.PlainA,isanadditionalexperimentsimilartobaselinesettingbutwithanadditionalalgorithm(ADELE)toﬁndanoptimalstartingpointforlabelcorrection.Thisshowsanincreaseofabout10%acrossallreadersintheARmetrics,comparedtothebaselinemodel,whiletheAPislower.Twoversionsoftheﬁnalpipelineshowthebestresults.Itcombinesallsteps(1)supervisedlearningwithmixed-batchtrainingofCellLabandCellposetillamemorisationpointisreached,(2)iterativelyapplyingpseudo-labelgenerationfortheCellLabdatasetwithtest-timeaugmentationandweightedboxesfusion,(3)generationofsynthetic-likeimagesaccordingtothepseudolabels,and(4)trainingthenetworkforanEpochwithmixed-batchtrainingoftheCellposedatasetandthepseudolabelsandsynthetic-likeimagesoftheCellLabdataset.Pseudocodefortheloopof2-4canbeseeninAlgorithm1.IncorporatingADELEwithourlabelcorrectionandsynthetic-likeimagegenerationmethodwithstrongblurringincreasestheAPbyatleast15%andARbyatleast20%comparedtothebaselineacrossallcellexperts.OnFig.4,weshowanexamplewhereSISSIsuccessfullyimprovesthedetectionresultsofPlainA(ADELE)experiment.Examplesofatrainingimagewithitspseudolabelsfordiﬀerentepochs(t)andexperimentscanbeseeninFig.8inAppendixB.5Discussion5.1FindingsTheexperimentsmadeclearthatboththestartoflabelcorrectionandtheamountofbackgroundinformationappearinginimagesduringtrainingimpacttheresults.Whenstartinglabelcorrectiontooearly,duringearlylearning,thenetworkisnotconﬁdentenoughtodetectallobjectsintheimage;thus,cor-rectinginitiallynoisyannotationsatthisstageresultsinahighrateofmissing8Elbateletal.Table1.ResultsofCellDetectionontheCellLabtestset.Annotator1Annotator2Annotator3PipelineAP50AP75APARAP50AP75APARAP50AP75APARBaseline45.615.721.332.744.316.120.231.058.628.129.741.8SISSI(W)52.823.225.937.749.521.324.434.658.529.029.742.0SISSI(S)40.38.316.232.838.47.215.231.846.69.719.237.8PlainA38.718.919.243.935.818.618.743.141.223.822.950.6A+SISSI(W)43.137.136.060.345.138.537.458.847.642.841.466.9A+SISSI(S)54.949.043.257.651.245.139.754.358.555.547.964.9targets.TraininganetworkonimageswithhighmissingtargetswithoutSISSI(PlainA)increasestheuncertaintyofthenetworkcomparedtolabelcorrectioninalatermemorizationphasewithfewermissingtargets,thebaseline.InthebasicSISSIapproach,wherelabelcorrectionisstartedonamodelchosenbasedonthevalidationlossoftheexternalCellposedataset,weakback-groundblurringworkedbetterthanastronglyblurredbackground.Webelievethisphenomenonappearsbecausetheneuralnetworkhaslearnedmorecontex-tualinformationinthememorisationstageandrequiresthebackgroundinfor-mation.Ontheotherhand,startinglabelcorrectionwhentheearlylearningphaseends,accordingtoADELE,strongblurringshowsbetterresultsthanweakblur-ring.Theinformationaboutthebackgroundislessimportant.Thiscanbeanadvantageinsynthetic-likeimagegenerationbecauseﬁguringouthowtopre-servecontextualinformationseemslesscritical.5.2LimitationsThesuccessofSISSImaybedependentonthestoppingcriteriaandthetrainingphase,earlylearning/memorisationphase.Whentheannotationsintheimagearetoonoisy,thenetworkmaynotencompasstheearlylearningphaseasinpreviousworks,ADELE.Itmaybeunabletolearnthetasktoproducenewpseudolabelsforfurthertraining.Theeﬀectofblurringduringdiﬀerenttrainingphasesneedsmoreempiricalresearchforveriﬁcation.SISSIisasimpleapproachthatworkswithonlyoneclassofinteresttodetect.Blurringwithmulti-objectneedsfurthermodiﬁcationinfutureworks.WeuseSISSIintheseexperimentswithFasterR-CNN,whichismorerobustandfriendlyforthemissinglabelscenariothanotherdetectionnetworks.5.3ConclusionThispaperpresentsamethodtotrainobjectdetectionmodelswithnoisyandmissingannotationswithsemi-supervisedlearningbyproposinganoveltech-nique.Weusedynamicallygeneratedsynthetic-likeimagesusingseamlesscloningforfurthertrainingthenetworkafterpseudo-labelgeneration.Weutilizeado-mainadaptationtechnique,BalancedGradientContribution,togeneratestableSISSI:SeamlessIterativeSemi-SupervisedCorrectionofImperfectLabels9gradientdirectionsandmitigatethesonoisyannotationproblemforoursemi-supervisedtraining.Finally,weevaluateourmethodforthecelldetectiontaskwithvarioustrainingproceduresandshowitsimprovementovertheusualsemi-supervisedapproach.Ourmethod,SISSI,canbeaddedontopofanydetectionnetwork,anditalsohelpsothermethodslikeADELEtobeleveragedforobjectdetection.Inthefuture,wewilladaptourmethodtoworkwithmulti-objectdetectionandexploreSISSIwithdiﬀerentdetectionnetworks.Moreover,wewillexploreourmethodfordiﬀerentmedicaldetectiontasksandintegrateournet-worktohelpcellexpertswiththegradingtask.AcknowledgementsWewouldliketoacknowledgeOesterreichischesForschungsin-stitutfürChemieundTechnik(OFI)forCellLabimagesandtestsetannotation.WewouldalsoliketothankDr.ThomasMohrforrevisingthemanuscript.References1.Anderson,J.M.:Futurechallengesintheinvitroandinvivoevaluationofbiomaterialbiocompatibility.RegenerativeBiomaterials3(2),73–77(032016).https://doi.org/10.1093/rb/rbw001,https://doi.org/10.1093/rb/rbw0012.Gao,J.,Wang,J.,Dai,S.,Li,L.J.,Nevatia,R.:Note-rcnn:Noisetolerantensem-blercnnforsemi-supervisedobjectdetection.In:ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision(ICCV)(October2019)3.ISO:Iso10993-5:2009-biologicalevaluationofmedicaldevices-part5:Testsforinvitrocytotoxicity(2009)4.Li,H.,Pan,X.,Yan,K.,Tang,F.,Zheng,W.S.:Siod:Singleinstanceannotatedpercategoryperimageforobjectdetection.In:ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR).pp.14197–14206(2022)5.Lin,T.Y.,Maire,M.,Belongie,S.,Bourdev,L.,Girshick,R.,Hays,J.,Perona,P.,Ramanan,D.,Zitnick,C.L.,Dollár,P.:Microsoftcoco:Commonobjectsincontext(2014),http://arxiv.org/abs/1405.03126.Liu,S.,Liu,K.,Zhu,W.,Shen,Y.,Fernandez-Granda,C.:Adaptiveearly-learningcorrectionforsegmentationfromnoisyannotations.In:ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition.pp.2606–2616(2022)7.Liu,S.,Niles-Weed,J.,Razavian,N.,Fernandez-Granda,C.:Early-learningregu-larizationpreventsmemorizationofnoisylabels.AdvancesinNeuralInformationProcessingSystems33(2020)8.Lyu,F.,Yang,B.,Ma,A.J.,Yuen,P.C.:Asegmentation-assistedmodelforuni-versallesiondetectionwithpartiallabels.In:deBruijne,M.,Cattin,P.C.,Cotin,S.,Padoy,N.,Speidel,S.,Zheng,Y.,Essert,C.(eds.)MedicalImageComput-ingandComputerAssistedIntervention–MICCAI2021.pp.117–127.SpringerInternationalPublishing,Cham(2021)9.Pérez,P.,Gangnet,M.,Blake,A.:Poissonimageediting.ACMTrans.Graph.22(3),313–318(jul2003).https://doi.org/10.1145/882262.882269,https://doi.org/10.1145/882262.88226910Elbateletal.10.Ren,S.,He,K.,Girshick,R.,Sun,J.:Fasterr-cnn:Towardsreal-timeobjectde-tectionwithregionproposalnetworks.Advancesinneuralinformationprocessingsystems28(2015)11.Ros,G.,Stent,S.,FernándezAlcantarilla,P.,Watanabe,T.:Trainingconstraineddeconvolutionalnetworksforroadscenesemanticsegmentation.CoRR(042016)12.Siegismund,D.,Tolkachev,V.,Heyse,S.,Sick,B.,Duerr,O.,Steigele,S.:Develop-ingdeeplearningapplicationsforlifescienceandpharmaindustry.Drugresearch68(06),305–310(2018)13.Solovyev,R.,Wang,W.,Gabruseva,T.:Weightedboxesfusion:Ensemblingboxesfromdiﬀerentobjectdetectionmodels.ImageandVisionComputing107,104117(2021)14.Stringer,C.,Pachitariu,M.:Cellpose2.0:howtotrainyourownmodel.bioRxiv(2022).https://doi.org/10.1101/2022.04.01.486764,https://www.biorxiv.org/content/early/2022/04/05/2022.04.01.48676415.Tajbakhsh,N.,Jeyaseelan,L.,Li,Q.,Chiang,J.N.,Wu,Z.,Ding,X.:Embracingimperfectdatasets:Areviewofdeeplearningsolutionsformedicalimagesegmen-tation.MedicalImageAnalysis63,101693(2020).https://doi.org/https://doi.org/10.1016/j.media.2020.101693,https://www.sciencedirect.com/science/article/pii/S136184152030058X16.Triguero,I.,García,S.,Herrera,F.:Self-labeledtechniquesforsemi-supervisedlearning:taxonomy,softwareandempiricalstudy.KnowledgeandInformationsys-tems42(2),245–284(2015)17.Wang,G.,Li,W.,Aertsen,M.,Deprest,J.,Ourselin,S.,Vercauteren,T.:Aleatoricuncertaintyestimationwithtest-timeaugmentationformedicalimagesegmenta-tionwithconvolutionalneuralnetworks.Neurocomputing338,34–45(2019)18.Wang,Y.,Wang,H.,Shen,Y.,Fei,J.,Li,W.,Jin,G.,Wu,L.,Zhao,R.,Le,X.:Semi-supervisedsemanticsegmentationusingunreliablepseudo-labels.In:Pro-ceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecogni-tion(CVPR).pp.4248–4257(June2022)19.Xiong,H.,Liu,S.,Sharan,R.V.,Coiera,E.,Berkovsky,S.:Weaklabelbasedbayesianu-netforopticdiscsegmentationinfundusimages.ArtiﬁcialIntelligenceinMedicine126,102261(2022)20.Zhang,H.,Chen,F.,Shen,Z.,Hao,Q.,Zhu,C.,Savvides,M.:Solvingmissing-annotationobjectdetectionwithbackgroundrecalibrationloss.ICASSP2020-2020IEEEInternationalConferenceonAcoustics,SpeechandSignalProcessing(ICASSP)pp.1888–1892(2020)Appendixfor“SeamlessIterativeSemi-SupervisedCorrectionofImperfectLabelsinMicroscopyImages”NoAuthorGivenNoInstituteGivenAInitialWeakLabelsGenerationWithImageProcessing.Fig.5.CellImagesaredividedvisuallyandmanuallyinto3categories(alive/inhibited/dead)toperformsuitableimageprocessingalgorithmstogenerateinitialweaklabels.AliveandinhibitedpipelinesareshowninthisFigure.arXiv:2208.03327v1  [eess.IV]  5 Aug 20222NoAuthorGivenFig.6.WeperformCircleHoughTransformdirectlyonthedeadcellsimage.BSISSITrainingDynamics.051015202530Epoch0510152025AP (%)Initial Noisy Annotation AP IOU-0.5Fig.7.FittedIoUcurvebetweenthemodeloutputandtheinitialnoisyannotationswiththepointwherewestartlabelcorrectionbasedontheAP50curvedeceleration.tt+3t+6t+9PlainAA+SISSI(W)Fig.8.Examplesofatrainingimagewithitspseudolabelsfordiﬀerentepochs(t)andexperiments.