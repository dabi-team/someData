GAMORRA: An API-Level Workload Model for Rasterization-based 
Graphics Pipeline Architecture 

Iman Soltani Mohammadi1, Mohammad Ghanbari2, Life Fellow, IEEE and Mahmoud Reza Hashemi3  

Abstract 

The performance of applications that require frame rendering time estimation or dynamic frequency scaling, rely on the accuracy of the workload 
model that is utilized within these applications. Existing models lack sufficient accuracy in their core model. Hence, they require changes to the 
target application or the hardware to produce accurate results. This paper introduces a mathematical workload model for a rasterization-based 
graphics Application Programming Interface (API) pipeline, named GAMORRA, which works based on the load and complexity of each stage 
of the pipeline. Firstly, GAMORRA models each stage of the pipeline based on  their operation complexity and the input data size. Then, the 
calculated workloads of the stages are fed to a Multiple Linear Regression (MLR) model as explanatory variables. A hybrid offline/online training 
scheme is proposed as well to train the model. A suite of benchmarks is also designed to tune the model parameters based on the performance of 
the  target  system.  The  experiments  were  performed  on  Direct3D  11  and on  two  different  rendering  platforms  comparing  GAMORRA  to  an 
AutoRegressive (AR) model, a Frame Complexity Model (FCM) and a frequency-based (FRQ) model. The experiments show an average of 1.27 
ms frame rendering time estimation error (9.45%) compared to an average of 1.87 ms error (13.23%) for FCM which is the best method among 
the three chosen methods. However, this comes at the cost of 0.54 ms (4.58%) increase in time complexity compared to FCM. Furthermore, 
GAMMORA improves frametime underestimations by 1.1% compared to FCM.  

Keywords: Workload modeling, rendering time estimation, graphics API, pipeline  architecture 

1.  INTRODUCTION 

In  traditional  Cloud  Gaming  (CG)  [1],  rendering  is 
performed at the server side while in graphics streaming-based 
CG  [2,  3]  all  the  frames  are  rendered  at  client  side.  As  a 
compromise between these two methods, hybrid graphics/video 
streaming  CG  [4,  5]  has  been  proposed  in  which  there  is  a 
potential for some frames to be rendered at client side. The latter 
two CG methods require to estimate the rendering time of each 
frame  to  make  sure  that  the  client  device  can  handle  the 
workload of the game for every frame that needs to be rendered 
at  client  side.  In  addition,  real  time  collaborative  rendering 
platforms  like  Kahawai  [6]  and  other  similar  platforms  [7], 
require a reliable workload model to set the graphical level of 
details of every frame based on the computational power of the 
thin  client  before  rendering  is  carried  out.  Also,  Dynamic 
Voltage  and  Frequency  Scaling 
(DVFS)-based  power 
management systems for mobile games, which reduce the power 
consumption of a processor by dynamically adjusting its voltage 
and frequency, need to take into account the amount of workload 
of  each  frame  [8-11].  These  studies  usually  rely  on  simple 
workload  models  based  on  the  number  of  triangles  [12]  or 
mostly focus on predicting the upcoming framesâ€™ workload by 
using  a  simple  linear  model  [13].  These  models  try  to 
compensate for their lack of sufficient detail in their core model 
by operating at hardware level. 

Due  to  the  high  variety  of  GPU  architectures  among 
vendors,  a  hardware 
the 
applicability  of  such  a  model  to  a  specific  hardware  device. 

level  model  effectively 

limits 

to  estimate  frame  rendering 

Although  each  graphics  driver  covers  a  certain  range  of 
hardware models, they also differ significantly from each other 
due to their hardware dependent nature and the frequent updates 
they receive. But graphics APIs usually follow a certain model 
for  their  rendering  pipeline  with  minor  differences  between 
different  APIsâ€™  pipeline  architectures.  Hence,  designing  a 
times 
mathematical  model 
(frametime) at the graphics API level covers a much wider range 
of  applications  compared  to  a  hardware  architecture  or  driver 
level  model.  Additionally,  other  proposed  methods  [14,  15] 
usually require changes to the hardware or software to provide 
an accurate estimation. Utilizing an API-level model avoids the 
need for game engine modifications or hardware-level changes 
that  are  not  possible  in  case  of  commercial  off-the-shelf 
products. Therefore, a Graphics API-level Model of Rendering 
workload 
pipeline 
Architecture, GAMORRA, is proposed in this paper. However, 
to  compensate  for  this  high-level  approach  which  would 
inevitably lead to loss of accuracy, three components are devised 
for GAMORRA to ensure an accurate prediction: (i) a detailed 
regression core model, (ii) a customized training scheme to train 
the core model weights, and (iii) a suite of benchmarks to tune 
the  model  parameters  based  on  the  performance  of  the  target 
hardware. 

for  Rasterization-based 

graphics 

Modern  API  pipelines  consist  of  fixed-function  and 
programmable  stages  as  opposed  to  the  fully  fixed-function 
pipelines  of  old  rendering  systems.  The  early  experiments  to 
determine  the  proper  core  model,  as  well  as  the  benchmark 
results  in  Section  4.1.,  indicate  a  linear  relation  between  the 

1 School of Electrical and Computer Engineering, University of Tehran, Tehran, Iran (e-mail: soltani.m@ut.ac.ir) 
2 School of Electrical and Computer Engineering, University of Tehran, Iran  (e-mail: ghan@ut.ac.ir) as well as an Emeritus Professor at the School of Computer 
Science and Electronic Engineering, University of Essex, Colchester, UK (e-mail: ghan@essex.ac.uk) 
3 School of Electrical and Computer Engineering, University of Tehran, Tehran, Iran (e-mail: rhashemi@ut.ac.ir) 

 
 
 
 
performance  of  each  stage  of  the  pipeline  and  the  overall 
rendering time of each frame. The results of these experiments 
show that each stage of the pipeline contributes differently to the 
final  rendering  time.  This  difference  which  stems  from  the 
difference in the computational complexity of the stages, despite 
the same underlying hardware, indicates their independence as 
explanatory  (independent)  variables.  Also,  the  linear  relation 
between  the  performance  of  each  stage  and  the  overall 
processing  time  of  the  pipeline  which  acts  as  the  response 
(dependent) variable, suggests that a Multiple Linear Regression 
(MLR) [16] technique has the potential to serve as a core for the 
proposed model. Hence, as opposed to previous studies such as 
[9] that consider only one explanatory variable, in GAMORRA 
which  takes  advantage  of  MLR  at  its  core,  an  explanatory 
variable is dedicated to each stage of the graphics API pipeline. 
This approach provides more flexibility and a better imitation of 
the rendering process of a rasterization-based application which 
leads to more accurate frametime estimations.  

the 

runtime  which  can  compromise 

Using  an  offline  training  scheme  to  train  model  weights 
helps with avoiding the need to train the weights  from scratch 
real-time 
during 
functionality of the model especially at the start of a rendering 
session. However, only a limited number of samples can be used 
to train the model weights prior to a  rendering  session, which 
would  not  be  representative  of  the  whole  gameplay.  Online 
training  [17]  can  be  used  to  adapt  the  weights  to  the  changes 
during runtime, on the fly. Hence, a new hybrid offline/online 
training  method  is  proposed  to  train  the  model  prior  to  a 
rendering session (offline) to obtain an acceptable set of initial 
weight  values  while  updating  the  weights  during  runtime 
(online).  This  approach  also  helps  with  avoiding  overfitting 
which  might  be  experienced  in  case  of  an  overly  complicated 
model and an extensive offline-only training scheme.  

Additionally, to accurately tune the model parameters based 
on  the  performance  of  the  target  rendering  system,  a  suite  of 
benchmarks is designed to assess the performance of each stage 
of the pipeline according to GAMORRAâ€™s workload model. 

In summary, the primary contributions of this study are as 

follows: 

-  A reliable and practical model for frametime estimation 
off-the-shelf 

commercially 

of 
rasterization-based 
software and hardware 

-  A  hybrid  offline/online  training  scheme  to  train  the 

proposed model 

-  A  benchmark  suite  to  evaluate  the  performance  of  the 
target rendering system and tune the model parameters 
accordingly 

The  rest  of  the  paper  is  organized  as  follows.  The  next 
section  discusses  notable  works 
this  field  and  how 
GAMORRA  differs  from  them.  Section  3  explains  the  core 
design  and  functionality  of  GAMORRA  in  detail.  Section  4 
focuses on the implementation details of the proposed method 

in 

and the experimental results. And finally, the paper is concluded 
in Section 5. 

2.  RELATED  WORK 

A  limited  number  of  studies  have  focused  on  estimating 
frametimes by targeting different applications for their proposed 
methods. Some of the studies in this field require hardware and 
software changes to perform properly which is not desired in the 
case of closed source software and already available hardware.  

Wimmer  et  al.  [14]  proposed  to  use  the  number  of 
transformed vertices and the number of projected pixels for each 
object  to  estimate  frametime.  They  propose  a  hardware 
extension to further improve the estimation accuracy.  

Mochocki et al. [18] proposed a signature-based model for 
workload estimation in which each signature is calculated based 
on  the  number  of  triangles  and  the  transformations  that  are 
performed  on  the  vertex  data.  Focusing  on  the  number  of 
triangles and geometrical transformations is not sufficient for a 
programmable  pipeline  in  a  realistic  scenario  and  results  in 
reduced precision.  

Gu  et  al.  [19]  proposed  a  hybrid  workload  prediction 
method 
that  switches  between  a  Proportional-Integral-
Derivative  (PID)  [20]  controller-based  and  a  frame  structure-
based prediction scheme. This method is mainly used to predict 
the  workload  of  an  upcoming  frame  to  be  used  in  a  Dynamic 
Voltage  Scaling  (DVS)  power  management  system.  In  this 
work,  rasterization  workload  is  considered  as  the  most 
significant contributing source of processing time in rendering. 
Similarly, Zhang-Jian et al. [8] proposed to use the number of 
triangles  as  a  measure  of  workload  complexity  and  a  PID 
controller to predict the workload of each frame. Dietrich et al. 
[13] further expanded PID-based methods and proposed to use 
the Least Mean Squares (LMS) method for controller parameter 
identification to avoid the need to hand-tune the parameters. 

Dietrich  et  al  [21]  also  proposed  to  predict  each  frameâ€™s 
workload  using  an  autoregressive  model  by  considering  the 
previous framesâ€™ number of cycles as the explanatory variable. 
They  further  expanded  their  work  by  proposing  a  self-tuning 
LMS  linear  predictor  to  estimate  the  parameters  of  an 
AutoRegressive  (AR)  moving  average  model  for  workload 
(number of cycles) prediction [9]. Solely relying on the previous 
framesâ€™ workload without taking the characteristics of the frame 
into  account  is  severely  misleading  due  to  the  heavily  variant 
workload of graphical scenes even in consecutive frames. These 
methods usually fail to react in time to the workload variations 
of frames.    

Cheng  et  al.  [22]  proposed  a  behavior-aware  power 
management  system  for  mobile  games  which  estimates  each 
frameâ€™s  workload  based  on  the  number  of  game  applicationâ€™s 
API calls and texture processing load.  

Song  et  al.  [23]  proposed  a  fine-grained  GPU  power 
management called Frame Complexity Model (FCM) for closed 

 
source  mobile  games  which  works  based  on  the  number  of 
vertices, the number of API commands and the size of textures. 
This  approach  does  not  take  the  impact  of  other  contributing 
factors  such  as  the  complexity  of  shader  programs  or  the 
structure and performance of the graphics API that processes all 
the aforementioned data, into account. This causes such a model 
to produce the same results for different APIs. 

Gupta et al. [10] proposed a light-weight adaptive runtime 
performance model to estimate the sensitivity of frametimes to 
the current GPU frequency. This method consists of two steps: 
first, an offline data collection process is performed where the 
required data on frametimes and GPU performance counters are 
collected.  Second,  the  collected  data  are  used  to  tune  a 
differential  frametime model and  predict  the  frametimes.  This 
method considers the overall frametime of the previous frames 
to predict future frametimes based on the changes that are made 
to  the  GPU  frequency  and  GPU  counters.  Also,  an  online 
learning  scheme  is  employed  to  update  the  parameters  at 
runtime.  In  this  work,  the  graphical  structure  of  a  frame  is 
ignored. Also, GPU counter values are unknown when a batch 
[24] is not yet processed which can be problematic for practical 
use. 

Cheng et al. [15] proposed to use the changes in frequency 
and the number of active GPU computational slices for power 
management  in  mobile  games.  This  method  requires  to  be 
implemented in GPU firmware to achieve sufficient accuracy.  

Choi et al. [25] proposed a predictive method for frametime 
estimation based on previous frametimes and the frequency at 
which  they  were  rendered.  This  study,  similar  to  other  more 
recent  studies  [26],  focuses  on  big.LITTLE  architecture  in 
mobile devices. 

To summarize, some of the proposed methods on workload 
modeling require  modifications in the application or the target 
hardware  [14,  15,  27].  GAMORRA  attempts  to  avoid  such 
requirements  by  operating  at  an  API-level.  In  order  to 
compensate for its high-level approach, GAMORRA considers 
the  workload  of  all  the  stages  of  the  pipeline  and  the  pipeline 
architecture,  unlike  numerous  studies  [8,  10,  11,  19,  28]  that 
focus on a limited number of contributing factors. Additionally, 
as opposed to multiple studies that are designed for a specific 
hardware [25, 26], GAMORRA is independent of the underlying 
architecture. 

3.  PROPOSED MODEL 

GAMORRA acts as a middleware that resides between the 
application and the graphics API software, capturing the output 
API commands produced by the applicationâ€™s rendering engine. 
Figure  1  shows  the  placement  of  GAMORRA  in  a  computer 
system. GAMORRA analyzes the graphics data stream to obtain 
the value of the contributing factors to the workload so that they 
are  fed  to  the  MLR  model  as  the  explanatory  variables.  The 
overall workload of the model and the workload of each stage is 
discussed  in  subsection  3.1.  Then,  the  training  process  is 

Figure 1 GAMORRAâ€™s placement in a rendering system 

Figure 2 The overall architecture of the Direct3d 11 pipeline 

explained  in  subsection  3.2  followed  by  some  notes  on  the 
benchmark suite in subsection 3.3. 

3.1.  Workload model 

The overall architecture of a modern graphics API pipeline 
(Direct3D 11 in this case) is shown in Figure 2. Direct3D 11â€™s 
graphics pipeline consists of 4 fixed-function stages (marked by 
rectangle  containers)  and  5  shader  stages  (marked  by  oval-
shaped  containers),  a  total  of  9  stages:  Input  Assembler  (IA), 
Vertex Shader (VS), Hull Shader (HS), Tessellator Stage (TS), 
Domain Shader (DS), Geometry Shader (GS), Rasterizer (Ras), 
Pixel Shader (PS), and Output Merger (OM). 

A  frame  is  broken  down  into  multiple  rendering  batches. 
Each batch has a different pipeline state that result in one or more 
drawcalls which draw the pixels prepared by the current batch 
[24]. Batches are rendered sequentially. Each batch can contain 
multiple drawcalls as long as these drawcalls do not cause any 
state changes to the pipeline. Since there are no state changes in 
this case,  GAMORRA considers the drawcalls in a batch as a 
the  proposed  frametime  model 
single  drawcall.  Hence, 
formulates  the  overall  estimated  processing  time  of  the  ğ‘–ğ‘¡â„ 
frame, ğ‘‡ğ‘–, as in (1) where ğµğ‘– is the number of batches for the ğ‘–ğ‘¡â„ 
frame and ğµğ‘ğ‘¡ğ‘â„ğ‘ shows the estimated processing time of the 
ğ‘ğ‘¡â„ batch: 

ğ‘‡ğ‘– = âˆ‘

ğµğ‘–âˆ’1
ğ‘=0

ğµğ‘ğ‘¡ğ‘â„ğ‘

             (1) 

In the case of Direct3D 11, there are 9 explanatory variables 
ğ‘ for the ğ‘ğ‘¡â„ batch with ğ‘› =
required which are represented by ğ‘¤ğ‘›
1, â€¦ ,9. Let ğ›½ğ‘› represent the model parameter of each stage with 
ğ‘› = 1, â€¦ ,9,  ğ›½0  represent  the  minimum  processing  time  of  the 
pipeline and ğœ€ be the overall model error, then the MLR model 
of the rendering pipeline is defined as: 

 
 
 
       
 
 
 
 
 
 
 
ğµğ‘ğ‘¡ğ‘â„ğ‘ = Î²0 + âˆ‘

9
ğ‘›=1

ğ‘¤ğ‘›

To  simplify  (2),  ğ‘¤0

+ ğœ€ 

ğ‘ğ›½ğ‘›
ğ‘   is  defined  and  set  to  1  for  all  the 

             (2) 

batches. Then (2) can be written as: 

ğµğ‘ğ‘¡ğ‘â„ğ‘ = âˆ‘

9
ğ‘›=0

ğ‘¤ğ‘›

ğ‘ğ›½ğ‘› + ğœ€

= Î²ğ‘¤ + ğœ€ 

             (3) 

where ğ‘Š and Î² are vectors containing explanatory variables of 
the model and model parameters respectively which are defined 
as: 

ğ‘, ğ‘¤2

ğ‘, ğ‘¤8
ğ‘, ğ‘¤4
ğ‘¤ = [1, ğ‘¤1
ğ›½  = [ğ›½0, ğ›½1, ğ›½2, ğ›½3, ğ›½4, ğ›½5, ğ›½6, ğ›½7, ğ›½8, ğ›½9]  

ğ‘, ğ‘¤5

ğ‘, ğ‘¤7

ğ‘, ğ‘¤3

ğ‘, ğ‘¤6

ğ‘, ğ‘¤9

ğ‘]ğ‘‡ 

             (4) 

Since  ğ‘¤  is  actually  a  1 Ã— 10  matrix,  the  ğ‘‡  superscript  in  the 
above equation represents the transpose operation. The values in 
ğ›½  are  obtained  by  using  the  Singular  Value  Decomposition 
(SVD) [29, 30]. But before obtaining the model parameters, the 
explanatory  variables  ğ‘Š  should  be  known.  These  variables 
represent  the  load  of  each  stage  in  time  unit  and  they  are 
calculated as discussed in the next sub-section.  

3.1.1.  Stage workload 

To model the workload of each stage, a generic formula is 
proposed. The formula is able to incorporate the details that may 
differ  in  various  stages  of  the  pipeline  due  to  their  unique 
   represents  the 
characteristics.  Let  us  assume  that  ğ‘ƒğ‘’ğ‘Ÿğ‘“ğ‘›
performance function of the ğ‘›ğ‘¡â„ stage in time unit, ğ¿ğ‘›
ğ‘  stands for 
the load of the ğ‘›ğ‘¡â„ stage and È  determines the number of cores 
of the GPU, then the workload of each stage is modeled as: 

ğ‘¤ğ‘›

ğ‘ = ğ‘ƒğ‘’ğ‘Ÿğ‘“ğ‘›

 (ğ¿ğ‘›

ğ‘ )/È  

             (5) 

ğ‘ƒğ‘’ğ‘Ÿğ‘“ğ‘› maps the amount of load of the ğ‘›ğ‘¡â„ stage which is the 
number of input elements (number of vertices or pixels) to the 
performance weight of the stage for that specific amount of load. 
The  value  of  this  performance  weight  roughly  estimates  the 
overall  processing  load  of  each  stage  compared  to  the  other 
stages  of  the  pipeline.  ğ‘ƒğ‘’ğ‘Ÿğ‘“ğ‘›  is  determined  by  the  custom 
that  are  designed  specifically  for 
graphics  benchmarks 
GAMORRA and are discussed in Section 3.2.  

For a fixed function stage, ğ¿ğ‘› mainly depends on the number 
of inputs or outputs of that stage. But, the overall processing load 
of shaders is strongly affected by their shader program as well. 
The  shader  compilation  is  performed  in  2  stages:  first  a  tool 
compiles  the  HLSL  code  into  the  GPU  agnostic  Intermediate 
Language  (IL).  Then  the  GPU  driver  converts  the  IL  into  the 
final shader assembly (ISA) that can be executed on a specific 
GPU. The complexity of the shader program is obtained through 
analyzing its Intermediate Language (IL) assembly code which 
comprises  a  series  of  instructions  each  of  which  performs  a 
specific operation based on its opcode. To obtain the overall time 
complexity of a shader, the time complexity of each IL opcode 
needs to be determined through benchmarking. Let the number 
of assembly operators be shown by ğ‘ğ‘œğ‘, the processing time of 
the  ğ‘—ğ‘¡â„  operator  be  represented  by  ğ‘œğ‘ğ‘—,  the  number  of  its 
occurrences  in  the  current  shader  be  represented by  ğ‘¥ğ‘—  and ğ‘ğ‘– 

represent the number of times that the shader is invoked, then 
the complexity of a programmable stage, ğ¶ğ‘–, and consequently, 
ğ¿ğ‘– is calculated as follows: 

ğ‘ = âˆ‘

ğ¶ğ‘›

ğ‘ğ‘‚ğ‘ƒâˆ’1
ğ‘—=0

ğ‘œğ‘ğ‘—

ğ‘›
ğ‘›.ğ‘¥ğ‘—

ğ‘ = {
ğ¿ğ‘›

ğ‘ğ‘›
ğ¶ğ‘›

ğ‘,          if fixed function    
ğ‘,   if Programmable  
ğ‘. ğ‘ğ‘›

             (6)  

It should be noted that the shader complexity model is not 
meant  to  act  as  an  accurate  stand-alone  model  for  shader 
processing time estimation. The goal of this model is to provide 
the  core  model  of  GAMORRA  with  a  rough  estimate  of  the 
overall complexity of each shader and still perform with enough 
accuracy  while  ensuring  real-time  functionality  of  the  overall 
model.  Since  shaders  are  invoked  per  input,  ğ‘ğ‘–  represents  the 
number of vertices for VS, HS, DS, and GS and it represents the 
number  of  pixels  for  PS.  The  IA  stage  reads  and  prepares the 
vertex data that are required for the current batch by determining 
their attributes and topology. For the IA stage, since the data is 
read  from  resource  buffers,  the  available  memory  bandwidth 
becomes the potential bottleneck. Hence, the load of the IA stage 
(LIA) is chosen to be the size of the input vertex data which might 
vary  based  on  the  number  of  vertices  and  their  attributes 
(#ğ´ğ‘¡ğ‘¡ğ‘Ÿ). 

Since  Vertex  Shader  (VS)  is  a  programmable  stage,  its 
performance depends on the complexity of its code and should 
be reflected in ğ¿ğ‘‰ğ‘†. VS program is invoked individually for each 
vertex, so  ğ¿ğ‘‰ğ‘† is also affected by the number of vertices. Let ğ¶ğ‘‰ğ‘† 
be the assembly codeâ€™s complexity, then ğ¿ğ‘‰ğ‘† is defined as: 

ğ¿ğ‘‰ğ‘† = ğ¶ğ‘‰ğ‘†.ğ‘ğ‘‰ğ‘’ğ‘Ÿğ‘¡ğ‘’ğ‘¥ 

             (7) 

For shaders, the assembly operators are profiled separately 
and a performance function is derived for each operator. Some 
operators are used exclusively in a specific stage (e.g., sampling 
operator for PS).  

Tessellation stages consist of three separate stages, HS, the 
Tessellator  and  DS  that  act  as  a  single  unit  and  turning  off 
tessellation disables all the underlying stages. These stages are 
programmed  differently  but  they  all  work  together  and  they 
manipulate the vertices in a patch. HS consists of a main shader 
program and a patch constant function (PCF) that are executed 
once per output control point and once per patch respectively. 
Hence,  the  load  of  this  stage  can  be  simply  considered  as  the 
number of vertices (ğ‘ğ‘‰ğ‘’ğ‘Ÿğ‘¡ğ‘’ğ‘¥) along with the number of patches 
(ğ‘ğ‘ƒğ¶ğ¹) as the input to the PCF which is treated like a complete 
shader stage. The complexity of HSâ€™s main shader and PCF are 
shown by ğ¶ğ»ğ‘† and ğ¶ğ‘ƒğ¶ğ¹ respectively while the load for each one 
is  represented  by  ğ¿ğ»ğ‘†  and  ğ¿ğ‘ƒğ¶ğ¹.  ğ‘ƒğ‘’ğ‘Ÿğ‘“ğ»ğ‘†  and  ğ‘ƒğ‘’ğ‘Ÿğ‘“ğ‘ƒğ¶ğ¹  are 
calculated as: 

ğ¿ğ»ğ‘† = ğ¶ğ»ğ‘†.ğ‘ğ‘‰ğ‘’ğ‘Ÿğ‘¡ğ‘’ğ‘¥ 
ğ¿ğ‘ƒğ¶ğ¹ = ğ¶ğ‘ƒğ¶ğ¹.ğ‘ğ‘ƒğ¶ğ¹ 

ğ‘ƒğ‘’ğ‘Ÿğ‘“ğ‘‡ğ»ğ‘† = ğ‘ƒğ‘’ğ‘Ÿğ‘“ğ»ğ‘†(ğ¿ğ»ğ‘†) + ğ‘ƒğ‘’ğ‘Ÿğ‘“ğ‘ƒğ¶ğ¹(ğ¿ğ‘ƒğ¶ğ¹)          

             (8) 

The  Tessellator  stage  is  also  a  fixed  function  unit  and  its 

 
 
   
      
  
 
 
  
 
 
 
      
 
 
 
 
 
inputs are the tessellation factors and patch constant data that are 
produced by PCF. For this stage, ğ¿ğ‘‡ğ‘’ğ‘ ğ‘  mainly depends on the 
total number of newly generated points in each patch where the 
total  number  of  patches  is  shown  by  ğ‘ƒ  and  the  number  of 
tessellations in the ğ‘ğ‘¡â„ patch by ğ‘ğ‘‡ğ‘’ğ‘ ğ‘ 

:  

ğ‘

ğ¿ğ‘‡ğ‘’ğ‘ ğ‘  = âˆ‘

ğ‘ƒâˆ’1
ğ‘=0

ğ‘
ğ‘ğ‘‡ğ‘’ğ‘ ğ‘ 

                           (9)  

DS stage is fed with the output of the  Tessellator and HS 
stages, namely UVW coordinates of every point in a patch from 
the  Tessellator  along  with  control  points  and  patch  constants 
from the HS stage. The DS stage produces a single tessellated 
vertex per input vertex, so ğ¿ğ·ğ‘† depends on the number of vertices 
as well as the complexity of DSâ€™s code,  ğ¶ğ·ğ‘†, and is calculated 
as: 

ğ¿ğ·ğ‘† = ğ¶ğ·ğ‘†. ğ‘ğ·ğ‘†   

           (10) 

GS is an optional stage which handles complete primitives 
instead of a single vertex. In addition to the complexity of GSâ€™s 
code, ğ¶ğºğ‘†, the load of this stage, LGS, is also dependent upon the 
number of vertices which might be different from the input of 
VS due to being processed in tessellation stages (if tessellation 
is on). Hence, ğ¿ğºğ‘† is calculated as: 

ğ¿ğºğ‘† = ğ¶ğºğ‘†. ğ‘ğºğ‘†    

           (11) 

Rasterizer generates fragments that might end up on screen 
as  pixels.  Hence,  ğ¿ğ‘…ğ‘ğ‘   which  represents  the  load  of  the 
Rasterization stage is considered to be equal to the number of 
fragments that are produced in this stage, ğ‘ğ¹ğ‘Ÿğ‘ğ‘”.  

PS or fragment shader is the last programmable stage that 
manipulates each input fragmentâ€™s color [31]. As the number of 
fragments  ğ‘ğ¹ğ‘Ÿğ‘ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡  that  are  produced  by  the  Rasterizer 
increases, the number of times that a PS is invoked increases as 
well. Also, the PS code complexity ğ¶ğ‘ƒğ‘† should be considered in 
the model. hence, ğ¿ğ‘ƒğ‘† is calculated as: 

ğ¿ğ‘ƒğ‘† =   ğ¶ğ‘ƒğ‘†.ğ‘ğ¹ğ‘Ÿğ‘ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡ 

           (12) 

OM is the last stage of the pipeline and the fragments that 
are processed by the PS are fed to this stage. Reading and writing 
to the render targets are the main cause of the performance issues 
related to the OM stage when blending is utilized. Hence, this 
stage is mostly bandwidth limited and is affected by the number 
of fragments, ğ‘ğ¹ğ‘Ÿğ‘ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡ğ‘  along with the render target resolution, 
ğ‘ğ‘Šğ‘–ğ‘‘ğ‘¡â„ Ã— ğ‘ğ»ğ‘’ğ‘–ğ‘”â„ğ‘¡. ğ¿ğ‘‚ğ‘€ is defined as: 

3.1.1.  Model parameters 

The parameter estimation method aims to minimize the least 
squares  problem  produced  by  the  ğ‘€  observations  that  are 
recorded by the benchmark. Considering (2), let ğ‘¦ğ‘š represent the 
actual output of the ğ‘šğ‘¡â„ observation in the benchmark and ğœ€ğ‘š 
represent the estimation error for the ğ‘šğ‘¡â„ observation, then the 
following linear system is obtained:   

ğ‘¦0      = Î²0 + ğ›½1ğ‘¤1
ğ‘¦1      = Î²0 + ğ›½1ğ‘¤1

0        +   â€¦ +   ğ›½9ğ‘¤9
1        +   â€¦ +   ğ›½9ğ‘¤9

0        + Îµ0    
1        + Îµ1    

.
.
.

           (15) 

{

ğ‘¦ğ‘€âˆ’1 = Î²0 + ğ›½1ğ‘¤1

ğ‘€âˆ’1  +   â€¦ +   ğ›½9ğ‘¤9

ğ‘€âˆ’1  + ÎµMâˆ’1

To obtain the matrix form of the system, similar to (3), let Y 
be the vector containing ğ‘¦ğ‘š values, ğ‘Š be the matrix that holds 
the  explanatory  variables  values  and  ğ¸  be  the  vector  for  error 
values, then the linear system in (17) can be written as: 

ğ‘Œ = ğ›½ğ‘Š + ğ¸ 

where 

                         (16) 

ğ‘Œ = [ğ‘¦0, ğ‘¦1, â€¦ , ğ‘¦ğ‘€âˆ’1]  
0 ğ‘¤0
1
ğ‘¤0
0 ğ‘¤1
1
ğ‘¤1
â‹® 
â‹®     
0 ğ‘¤8
1
ğ‘¤8
0 ğ‘¤9
1
ğ‘¤9
ğ¸ = [Îµ0, Îµ1, â€¦ , Îµğ‘€âˆ’1]  

â‹¯
â‹¯
â‹±
â‹¯
â‹¯

ğ‘Š =

[

ğ‘¤0
ğ‘¤1

ğ‘¤8
ğ‘¤9

Mâˆ’1

Mâˆ’1

Mâˆ’2 ğ‘¤0
Mâˆ’2 ğ‘¤1
â‹®  
â‹®         
Mâˆ’2 ğ‘¤8
Mâˆ’1
Mâˆ’2 ğ‘¤9

Mâˆ’1]

                         (17) 

The solution to this linear system minimizes the L2 norm of 

ğ¸ formulated as: 

min â€–ğ¸â€–2

2 = minâ€–ğ‘Œ âˆ’ ğ›½ğ‘Šâ€–2

2 = min ğ½(ğ›½0, â€¦ , ğ›½9)                (18) 

where ğ½(ğ›½) represents the cost function. 

SVD uses orthogonal transformations to reduce the problem 
to a diagonal system. If ğ‘ˆ is an ğ‘€ Ã— ğ‘€ orthogonal matrix, ğ‘† is 
an  ğ‘€ Ã— 10  diagonal  matrix  and  ğ‘‰  is  a  10 Ã— 10  orthogonal 
matrix, then in this method: 

ğ‘Šğ‘€ = ğ‘ˆğ‘†ğ‘‰ğ‘‡ 

           (19) 

Considering the above equation, ğ›½ can be formulated as: 

ğ›½ = ((ğ‘ˆğ‘†ğ‘‰ğ‘‡)ğ‘‡ğ‘ˆğ‘†ğ‘‰ğ‘‡)âˆ’1(ğ‘ˆğ‘†ğ‘‰ğ‘‡)ğ‘‡ğ‘Œ = ğ‘‰ğ‘†âˆ’1ğ‘ˆğ‘‡ğ‘Œ  

           (20) 

ğ¿ğ‘‚ğ‘€ = ğ‘ğ‘Šğ‘–ğ‘‘ğ‘¡â„.ğ‘ğ»ğ‘’ğ‘–ğ‘”â„ğ‘¡. ğ‘ğ¹ğ‘Ÿğ‘ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡ğ‘       

           (13) 

3.2.  Training the model 

Compute Shader (CS) is considered as a tool for General-
purpose  computing  on  GPUs  (GPGPU).  This  shader  has  an 
independent logical pipeline dedicated to general computations. 
Although CS is not part of the main pipeline and it is absent in 
Figure  2, this shader should be considered in the  performance 
model, following the same rule for input size, ğ‘ğ¼ğ‘›ğ‘ğ‘¢ğ‘¡, and code 
complexity, ğ¶ğ¶ğ‘†. Hence, the load of CS, ğ¿ğ¶ğ‘†, is calculated as: 

ğ¿ğ¶ğ‘† =   ğ¶ğ¶ğ‘†.ğ‘ğ¼ğ‘›ğ‘ğ‘¢ğ‘¡ 

           (14) 

An  offline  training  is  performed  before  each  rendering 
session based on a set of frames that use the graphical data of the 
current  scene  that  is  going  to  be  rendered.  An  offline-only 
training scheme can be used for some simpler games that do not 
have aggressive variations in their workload. However, it is not 
possible  to  cover  all  types  of  workload  variations  in  offline 
training  for  modern  games  that  might  have  over  100  hours  of 
gameplay and heavily variant and dynamic environments. on the 
other  hand,  an  online  only  training  scheme  can  lead  to  long 

 
 
 
 
   
 
 
  
 
 
    
 
 
   
    
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Algorithm 1 Mode decision algorithm 

Input:  Current  frametime,  predicted  frametime  using  online  and 

offline model weights 

  1:  ğ’ = ğŸ,   ğ’ğ’— = ğŸ,  

ğ‘ªğ’–ğ’“ğ’“ğ’†ğ’ğ’•ğ‘´ğ’ğ’…ğ’† = ğ‘¶ğ’‡ğ’‡ğ’ğ’Šğ’ğ’† 

ğ’ğ’ 

ğ’ğ’‡ğ’‡ 

ğ’ğ’‡ğ’‡ 

ğ’ğ’ > ğ‘¹ğ‘´ğ‘ºğ‘¬ğ’

ğ’ğ’ > ğ‘¹ğ‘´ğ‘ºğ‘¬ğ‘»ğ’‰ 

  2:  Run GAMORRAâ€™s benchmark according to 
  3:  while ğ’ < ğ‘µ 
  4:     if ğ‘ªğ’–ğ’“ğ’“ğ’†ğ’ğ’•ğ‘´ğ’ğ’…ğ’† == ğ‘¶ğ’ğ’ğ’Šğ’ğ’† 
  5:          Calculate ğ‘¹ğ‘´ğ‘ºğ‘¬ğ’
  6:          if ğ‘¹ğ‘´ğ‘ºğ‘¬ğ’
  7:            Calculate ğ‘¹ğ‘´ğ‘ºğ‘¬ğ’
  8:            if ğ‘¹ğ‘´ğ‘ºğ‘¬ğ’
  9:                 ğ’ğ’— = ğ’ğ’— + ğŸ 
10:               if ğ’ğ’— > ğ’‘ğ’‚ğ’•ğ’Šğ’†ğ’ğ’„ğ’† 
11:                  Stop online training 
12:                  Use offline training weights 
13:                   ğ‘ªğ’–ğ’“ğ’“ğ’†ğ’ğ’•ğ‘´ğ’ğ’…ğ’† = ğ‘¶ğ’‡ğ’‡ğ’ğ’Šğ’ğ’† 
14:                  ğ’ğ’—ğ’Š = ğŸ 
15:               end if 
16:            end if 
17:         end if  
18:     else if ğ‘ªğ’–ğ’“ğ’“ğ’†ğ’ğ’•ğ‘´ğ’ğ’…ğ’† == ğ‘¶ğ’‡ğ’‡ğ’ğ’Šğ’ğ’† 
19:          Calculate ğ‘¹ğ‘´ğ‘ºğ‘¬ğ’
20:          if ğ‘¹ğ‘´ğ‘ºğ‘¬ğ’
21:            Start online training  
22:             ğ‘ªğ’–ğ’“ğ’“ğ’†ğ’ğ’•ğ‘´ğ’ğ’…ğ’† = ğ‘¶ğ’ğ’ğ’Šğ’ğ’† 
23:         end if 
24:     end if 
25:     n = n+1 
26: end while 

ğ’ğ’‡ğ’‡ 
ğ’ğ’‡ğ’‡ > ğ‘¹ğ‘´ğ‘ºğ‘¬ğ‘»ğ’‰ 

initiation  times  before  a  set  of  acceptable  and  accurate  set  of 
weights  is  obtained.  In  such  cases,  using  offline  training  is 
beneficial  to  provide  the  model  with  acceptable  initial  weight 
values  to  avoid  long  initiation  times  of  online  training. 
Additionally, huge variations in consecutive frametimes that are 
not  caused  by  the  workload  of  the  frames  can  make  the 
estimation  error  during  online  training  to  raise  beyond  an 
acceptable  value.  Resetting  the  model  weights  to  weights 
obtained by the offline training in such cases can be beneficial, 
until the error of the offline mode becomes unacceptable as well. 
Hence, a hybrid offline/online training technique is used to take 
advantage of both training methods.  

Initially,  the  model  starts  in  offline  mode  which  uses  the 
weights that were obtained through offline training. If the Root 
Mean  Squared  Error  (RMSE)  value  for  frame  ğ‘›  during  the 
ğ‘œğ‘“ğ‘“)  increases  beyond  a  predetermined 
offline  mode  (ğ‘…ğ‘€ğ‘†ğ¸ğ‘›
threshold  (ğ‘…ğ‘€ğ‘†ğ¸ğ‘‡â„),  the  model  switches  to  online  mode.  The 
value  of  ğ‘…ğ‘€ğ‘†ğ¸ğ‘‡â„  determines  the  amount  of  acceptable 
estimation error. The acceptable ğ‘…ğ‘€ğ‘†ğ¸ value is generally under 
0.5 for this metric which is also used as the value for ğ‘…ğ‘€ğ‘†ğ¸ğ‘‡â„ 
in the experiments as well. However, tuning this parameter per 
game can have a positive impact on the overall accuracy. Setting 
the value of this parameter too high reduces the sensitivity of the 
system  to  estimation  error,  while  too  small  values  make  the 
system constantly switch between online and offline modes.  

Upon switching to the online mode, the online training starts 
and  the  model  weights,  which  are  initialized  to  the  offline 
weights every time this mode starts, get updated for each frame. 

ğ‘œğ‘›  with  ğ‘…ğ‘€ğ‘†ğ¸ğ‘›

ğ‘œğ‘›) violates 
During the online mode, if the RMSE value (ğ‘…ğ‘€ğ‘†ğ¸ğ‘›
ğ‘…ğ‘€ğ‘†ğ¸ğ‘‡â„, a validation step with a predetermined patience value 
(ğ‘ƒ) is performed based on the offline weights. If the comparison 
ğ‘œğ‘“  indicates  that  the  online  training 
of  ğ‘…ğ‘€ğ‘†ğ¸ğ‘›
process has reduced the accuracy in comparison to the offline 
trained  model,  a  counter  variable  that  holds  the  number  of 
violated  frames  (ğ‘›ğ‘£)  is  increased  by  one.  If  ğ‘›ğ‘£  reaches  the 
predetermined value of ğ‘ƒ, the model switches to offline mode 
which means the weights are reset back to the values obtained 
by the offline training and the online training stops temporarily, 
ğ‘œğ‘“ violates ğ‘…ğ‘€ğ‘†ğ¸ğ‘‡â„ again and the need for using the 
until ğ‘…ğ‘€ğ‘†ğ¸ğ‘›
online  training  arises.  The  mode  decision  algorithm  which 
handles the switching between the online and offline modes and 
invokes the online training phase, is described in Algorithm 1, 
with ğ‘ being the total number of frames in the current rendering 
session.  

3.3.  Benchmark notes 

GAMORRAâ€™s  benchmark  suite  also  operates  at  an  API 
level. This is the only component in GAMORRA that interacts 
with the underlying hardware and the graphics driver. Since the 
graphics APIâ€™s structure is not affected by the updates that the 
graphics  driver  receives,  GAMORRA  needs  to  rerun  the 
benchmarks to capture the performance changes that these new 
functionalities  cause.  Hence,  the  core  model  of  GAMORRA 
needs no changes in such scenarios and is the same for all the 
GPUs  that  use  a  certain  graphics  API.  To  perform  the 
benchmarks and obtain the performance function of each stage 
of the pipeline, the number of input elements and the number of 
assembly operations for shaders is increased gradually until an 
upper  bound  is  reached.  The  theoretical  upper  bound  on  the 
number  of  input  elements  is  defined  as  the  resource  limits  of 
Direct3D  11  [32].  However, running  the  benchmarks  with  the 
number  of  inputs  close  to  the  resource  limits  causes  the 
frametimes to be much higher than the normal and acceptable 
values  in  modern  applications  (e.g.  30  fps).    As  a  trade-off 
between frame rate generality and benchmark speed, 100 ms (or 
10  fps)  is  chosen  as  the  maximum  acceptable  frametime  (or 
minimum  acceptable  frame  rate)  in  the  benchmarks.  By 
choosing 100 ms, the benchmark would not run for the input load 
values  that  cause  the  frame  rate  to  drop  under  10  fps  which 
effectively improves the benchmarking time. Since 10 fps is a 
fairly low frame rate for modern real-time applications, 100 ms 
is a reasonable choice in terms of generality. 

The benchmarks to obtain the time complexity of IL shader 
assembly operators are designed such that only one opcode (e.g., 
add)  is  tested  in  each  benchmark  for  a  certain  number  of 
iterations. The recorded time for each benchmark is then divided 
by the number of iterations to obtain a rough estimate of the time 
complexity for the tested operator and stage, i.e., ğ‘‚ğ‘ƒğ‘— in (6). 

In  addition  to  each  stageâ€™s  functionality,  other  pipeline 
states,  such  as  the  presentation  model  or blend mode,  directly 
affect  the  final  performance  and  need  to  be  addressed  in  the 
11, 
benchmarks. 

Direct3D 

example, 

For 

in 

 
 
Table 1: Model parameters and important notes 
Stage 
IA 
VS 
HS 
Tessellation 
DS 
GS 
Rasterizer 
PS 
OM 
CS 

Model parameter 
#Vtx 
#Vtx, #Ops 
#Vtx, #Ops 
#Patches, #Tess 
#Vtx, #Ops 
#Vtx, #Ops 
#Frg 
#Frg, #Ops 
#Frg 
#Element 

Notes 
VS, HS, DS, GS, PS set to pass through, No rasterization 
HS, DS, GS, PS set to pass through, No rasterization 
VS, DS, GS, PS set to pass through, No rasterization 
VS, DS, GS, PS set to pass through, No rasterization 
VS, GS, PS set to pass through, No rasterization 
VS, HS, DS, PS set to pass through, No rasterization 
VS, HS, DS, GS, PS set to pass through, 4 vertices required to map a texture for rasterization 
VS, HS, DS, GS, PS set to pass through, 4 vertices required to map a texture for rasterization 
VS, HS, DS, GS, PS set to pass through, 4 vertices required to map a texture in each layer for rasterization 
VS, HS, DS, GS, PS set to pass through, No rasterization 

Table 2: Sequence characteristics for the experimented games 

Game 

Abbrv. 

Genre 

Resolution 

Bad Company 2 (2010) 
Dirt 3 (2011) 
Far Cry 3 (2012) 
Rocket League (2015) 
Splinter Cell (2013) 
Trine 4 (2019) 
Sniper Elite 4 (2017) 
Mortal Shell (2020) 
Fast and Furious (2021) 

BC2 
D3 
FC3 
RL 
SC 
T4 
SE4 
MSh 
FF 

FPS 
Racing 
FPS 
Racing/sport 
Third Person 
Side scroller 
FPS 
Third Person 
Racing 

1280x720 
1280x720 
1920x1080 
1280x720 
1280x720 
1920x1080 
1280x720 
1280x720 
1920x1080 

S1 Average 
frametime (ms) 
12.22 
07.97 
24.51 
16.13 
14.74 
16.42 
16.78 
17.95 
16.37 

S1 Standard 
deviation (ms) 
0.943 
0.588 
1.213 
1.247 
3.093 
2.582 
2.056 
2.485 
1.991 

S2 Average 
frametime (ms) 
07.47 
04.78 
10.27 
09.76 
07.90 
09.45 
10.66 
07.33 
08.28 

S2 Standard 
deviation (ms) 
0.624 
0.298 
0.743 
0.987 
2.253 
2.012 
1.596 
1.825 
1.371 

CPU 

Table 3: System configuration 
S2 
S1 
i5-
i7- 
7300HQ 
7500U 
RX 560 
950m 
2GB 
2GB 
8 GB 
8 GB 
DDR4 
DDR4 
1200MHz 
1200MHz 

RAM 

GPU 

Table 4: Training configuration 

Initial LR 
#Samples 
Batch size 
#Epochs 
Train/Test 
Patience 
RMSETh 

Offline  Online  

0.01 
720*#DC 
32 
200 
0.3 
10 
0.5 

0.01 
#DC 
#DC 
1 
- 
10 
0.5 

and 
DXGI_SWAP_EFFECT_FLIP_SEQUENTIAL 
DXGI_SWAP_EFFECT_DISCARD 
presentation  models 
would give two very different performance results based on the 
rendering resolution, which need to be taken into account while 
designing the benchmarks. 

Also, the benchmarks should account for techniques such as 
the  post  transform  cache  [33]  and  the  early-z  implemented  in 
GPUs. The post transform cache causes the VS to be invoked 
less frequently for indexed draw calls. Hence, to properly have 
a 1:1 relation between the vertices and the number of times that 
a  VS  is  invoked,  indexed  draws  should  be  avoided  unless  the 
goal is to benchmark the post transform cache performance. The 
early-z test, also referred to as the early fragment test, depends 
on the functionality of the graphics driver and the GPU itself and 
they  are  not  controlled  explicitly  by  the  API  commands  in 
Direct3D. Hence, a depth-only benchmark is used to determine 
the performance of the early-z process.  

Table 1 shows a summary of all the requirements for each 
stage of the pipeline. The model parameters are the number of 
vertices (#Vtx), the number of assembly operations (#Ops), the 
number of patches (#Patch), the number of tessellations (#Tess), 
the number of primitives (#Prim), the number of target pixels or 
resolution (Res), the number of fragments (#Frg) and the number 
of  input  elements  (#Element).  It  should  be  noted  that  for  the 

Rasterizer and its following stages, the rasterization should be 
performed. Hence, to map a rectangular texture to the screen, at 
least 4 vertices are required. Also, the Res value determines the 
maximum  resource  resolution  (texture,  depth  buffer,  stencil 
buffer and etc.) of the current batch. 

4.  IMPLEMENATION AND RESULTS 

applications 

computationally 

APITrace [34] is used to intercept API commands that are 
produced by the rendering engine. Since computer games are the 
most 
that  use 
intensive 
rasterization-based graphics APIs to their maximum capacity, all 
the tests are done on modern AAA games.  Also, the proposed 
model  and  all  the  mathematical  calculations,  including  the 
matrix multiplications, are implemented using Tensorflow-GPU 
[35]. Nine computer games were chosen for the tests, namely, 
Dirt  3  (D3),  Splinter  Cell:  Blacklist  (SC),  Battlefield  Bad 
Company 2 (BC2), Far Cry 3 (FC3), Rocket League (RL), Trine 
4 (RL), Sniper Elite 4 (SE4), Mortal Shell (MSh), and Fast and 
Furious Spy Racers: Rise of SH1FT3R (FF). Table 2 shows the 
game sequence characteristics such as genre, resolution, average 
frametime  and  the  standard  deviation  of  frametimes  on  two 
tested rendering systems. Since GAMORRA is designed to be 
independent  of  the  underlying  hardware,  it  is  mandatory  to 
perform the experiments on more than one rendering platform. 
The configurations of these tested devices are listed in Table 3.  

The  configurations  of  both  training  phases,  which  were 
determined  through  experimentation,  are  reported  in  Table  4. 
The  offline  training  process  uses  the  data  of  720  frames  of 
different sections of each level to train the model based on the 
graphics data of that level. Hence, the total number of samples 
would equal the average number of drawcalls (#DC) in a frame, 
times the number of frames. Also, the train-test ratio (Train/Test) 

 
 
 
 
 
 
 
 
 
 
 
)
s

m

(

e
m
T

i

100
80
60
40
20
0

)
s

m

(

e
m
T

i

100
80
60
40
20
0

)
s

m

(

e
m
T

i

100
80
60
40
20
0

)
s

m

(

e
m
T

i

100
80
60
40
20
0

)
s

m

(

e
m
T

i

100
80
60
40
20
0

0

480 960 1440

Input Size (Mbytes)

0 30 60 90 120

#Operations (x106)

0

30 60 90 120
#Operations (x106)

0 10 20 30 40 50 60

#Tessellations (x105)

(IA) 

(VS) 

(HS) 

(Tess) 

)
s

m

(

e
m
T

i

100
80
60
40
20
0

0

30 60 90 120
#Operations (x106)

0

20 40 60 80
#Operations(x106)

100

)
s

80

m

(
e
m
T

i

60

40

20

0

)
s

m

(

e
m
T

i

100
80
60
40
20
0

0

50 100 150 200
#Fragments (x105)

0 25 50 75 100

#Operations (x106) 

(DS) 

(GS) 

(Ras) 

(PS) 

)
s

m

(

e
m
T

i

100
80
60
40
20
0

0 50 100 150 200

#Fragments (x105)

(OM) 

Figure 3 The performance charts of IA, VS, HS, Tessellation, DS, GS, 
Rasterization, PS and OM stages 

of the offline training is set to 0.3. 

The  proposed  method  in  this  paper  focuses  on  GPUs. 
However, the main CPU also affects frametimes immensely and 
can  potentially  become  the  bottleneck  in  a  rendering  session. 
Using APITrace makes sure that a lot of CPU intensive tasks like 
processing  the  IA  is  already  carried  out  and  the  CPU  is  only 
dedicated to render-related processes. Many CPU performance 
models have been discussed in the literature [36] from as late as 
1977  and  is  much  simpler  to  obtain.  For  the  purposes  of  this 
paper,  the  proposed  method  in  [37]  is  used  for  CPU  time 
complexity  modeling.  This  model  uses  a  deep  neural  network 
specifically for Intel CPUs based on available benchmarks such 
as the SPEC CPU2006 and Geekbench 3.  

Three  methods  are  chosen  to  compare  to  GAMORRA. 
These  methods  are  the  AutoRegressive  (AR)  moving  average 
[9],  Frame  Complexity  Model  (FCM)  [23],  and  a  frequency-
based method (FRQ)  [10]. All these methods are independent 
of the underlying architecture and do not require any changes to 
the target software or hardware. Five metrics are considered in 
the experiments: Missed frames ratio (MFR) in percentage (%), 
time 
frametime  estimation  error 
complexity (ms), frametime overhead (%), and system memory 

in  milliseconds 

(ms), 

usage  in  megabytes  (MB).  MFR  reports  the  percentage  of the 
frames  that  are  falsely  estimated  to  have  a  frametime  smaller 
than the actual time they require to be rendered. In an application 
that relies on accurate  frametime estimations to prevent frame 
losses like a hybrid CG system, this type of false estimation leads 
to  frame  loss  and  have  a  negative  impact  on  the  quality  of 
experience.  Estimation  error  reports  the  maximum,  minimum 
and mean of the absolute difference between estimated and the 
actual frametimes. Too much overestimation of frametimes, as 
well as underestimation, leads to a negative impact on the target 
applicationâ€™s  performance  and  should  be  accounted  for  in  the 
experiments.  Time  complexity  determines  the  amount  of  time 
overhead  that  GAMORRA  forces  upon  the  system  which  is 
the  MLRâ€™s  parameter  estimation 
mostly  comprised  of 
processing  time.  The  frametime  overhead  determines  the 
percentage of the overall frametime that is due to GAMORRAâ€™s 
time complexity. And finally, system memory usage determines 
the amount of RAM in megabytes, required to run the model.  

It  should  be  noted  that  AR  requires  to  consider  the 
frametimes of a certain number of previous frames to predict the 
current  frametime,  referred  to  as  the  sequence  length,  which 
directly  affects  the  performance  of  the  model.  The  sequence 
length of AR is set to 10 in the experiments, which is reported to 
yield  the  best  results  in  [9].    Also,  FCM  uses  three  weight 
coefficients for the number of vertices, the number of textures 
and  the  number  of  commands  which  are  all  set  to  1
3â„   as  per 
FCMâ€™s  original  design  [23].  And  finally,  FRQ  [10]  does  not 
require any specific configurations for the experiments.  

Before  experimenting  on  the  games,  the  performance 

function of the target hardware should be known.  

4.1. Obtaining performance functions and model 

parameters 

The results of benchmarking S1 are shown in Figure 3. With 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Table 5: Active and inactive shaders for the tested games 
Game  VS  Tess.  GS  PS  CS 
âœ“ 
ïƒ» 
ïƒ» 
BC2 
ïƒ» 
âœ“  âœ“ 
D3 
âœ“  âœ“  âœ“ 
FC3 
âœ“  âœ“ 
ïƒ» 
RL 
âœ“ 
ïƒ» 
ïƒ» 
SC 
âœ“  âœ“ 
ïƒ» 
T4 
ïƒ» 
âœ“  âœ“ 
SE4 
âœ“  âœ“  âœ“ 
MSh 
âœ“  âœ“  âœ“ 
FF 

ïƒ» 
âœ“ 
âœ“ 
âœ“ 
âœ“ 
ïƒ» 
âœ“ 
âœ“ 
ïƒ» 

âœ“ 
âœ“ 
âœ“ 
âœ“ 
âœ“ 
âœ“ 
âœ“ 
âœ“ 
âœ“ 

a  ğ›½0  of  6.966  ms,  Figure  3  (IA)  shows  the  result  of  the 
performance  benchmark  of  the  IA  stage.  Since  loading  about 
1500 MBs of vertex data causes the pipeline to take more than 
100 ms, it is evident that GTX950m is struggling to load them.  

After being prepared by the IA stage, the vertices go through 
the  VS  stage.  Tens  of  opcodes  are  available  to  be  used  by 
developers at this stage and all the other programmable stages 
and  all  of  them  should  be  benchmarked.  As  an  example,  the 
performance chart of the add operator of the VS stage is shown 
in Figure 3 (VS). This benchmark shows that a VS can perform 
of  up  to  130  million  Add  operations  under  a  100-ms  time 
interval. Normally, the performance function of this stage would 
be  a  3D  chart,  but,  for  simplicity  and  more  comprehensible 
output,  the  number of  attributes  and  the  number  of vertices  is 
fixed  and  set  to  1.  For  illustration  purposes,  the  only  attribute 
considered in the test in Figure 3 (VS), is position which is a 3-
component floating point variable.  

The results for the Tessellation stages are depicted in Figure 
3 (HS), (Tess) and (DS). The results of the HS and DS stages for 
add operator are more similar to the VS stage in comparison to 
the  Tessellator  stage  which  is  a  fixed-function  stage.  For  the 
Tessellator  stage,  level  3  tessellation  was  used  and  a  total  of 
6.5*106 tessellations make the rendering time to surpass 100 ms 
as depicted in Figure 3 (Tess).   

The performance chart of the GS stage for add operator is 
depicted in Figure 3 (GS). This stage is also somewhat similar 
to  the  VS  stage,  albeit more demanding due  to  the  fact  that  it 
operates on whole primitives instead of individual vertices.  

Figure  3  (Ras)  shows  the  benchmark  results  for  the 
Rasterizer. As the number of fragments increase over 20 million, 
the Rasterizer starts to impose larger overhead on the pipeline 
and  the  GTX950m  starts  to  struggle  with  the  rasterization 
process.  When  the rasterization  benchmark  is  3  million  pixels 
short of the 30 million, the rendering time gets closer enough to 
the unacceptable 100 ms.  

The  result  of  the  PS  stage  benchmark  for  add  operator  is 
depicted  in  Figure  3  (PS).  Performing  108  operations  would 
practically increase the processing time of the pipeline to well 
over 100 ms.    

Finally, the performance chart of the OM stage is depicted 
in  Figure  3  (OM).  The  load  size  of  the  OM  stage  is  highly 
dependent upon the number of fragments and reaching 25*106 

#Vtx 

#Ops 

Game 

Table 6: The values of some of the model parameters obtained from tested 
game sequences 
#Attr 
Min  Max  Mean  Min  Max  Mean  Min  Max  Mean 
32.7 
7 
45.1 
7 
49.3 
8 
57.8 
9 
37.2 
9 
41.5 
9 
31.4 
13 
48.3 
16 
52.7 
16 

2134 
2066 
2796 
1954 
2378 
3072 
3198 
3564 
2974 

752 
615 
802 
945 
743 
1040 
1816 
1792 
1605 

3.5 
1.8 
3.9 
6.4 
7.3 
5.0 
3.7 
10.4 
9.8 

192 
204 
217 
269 
187 
228 
236 
253 
291 

8 
4 
4 
4 
8 
16 
12 
12 
12 

1 
1 
1 
1 
1 
1 
1 
1 
1 

7 
5 
9 
8 
5 
6 
7 
9 
7 

BC2 
D3 
FC3 
RL 
SC 
T4 
SE4 
MSh 
FF 

Game 

Table 7: The experimental results on MFR (%) 
S1 
FCM 
3.08 
3.69 
4.53 
3.24 
5.22 
3.27 
4.75 
4.20 
4.68 

FRQ 
12.32 
09.35 
11.47 
08.44 
12.25 
11.16 
12.13 
11.04 
10.51 

AR 
11.54 
08.79 
10.38 
09.21 
12.06 
10.94 
11.92 
10.87 
09.32 

BC2 
D3 
FC3 
RL 
SC 
T4 
SE4 
MSh 
FF 

GM 
2.35 
2.16 
3.07 
2.58 
3.90 
2.83 
3.24 
3.06 
3.11 

AR 
11.39 
09.76 
10.16 
10.09 
11.69 
09.83 
12.78 
11.80 
09.17 

S2 
FCM 
3.21 
3.62 
2.94 
2.86 
4.90 
2.68 
5.11 
4.28 
4.06 

FRQ 
11.42 
09.16 
10.76 
09.49 
11.83 
11.78 
12.66 
11.47 
10.42 

GM 
2.46 
2.33 
2.91 
2.27 
3.26 
2.69 
2.70 
2.72 
2.84 

would  violate  the  100-ms  limit  that  is  chosen  for  the 
benchmarks. 

These benchmarks show a  roughly linear relation between 
the  load  of  the pipeline  and  the  processing  time  that  this  load 
imposes  on  the  system.  If  the  input  load  is  light  enough  (e.g., 
less than 5 million pixels and 10 million primitives in the case 
of rasterization), then the overall processing time of the pipeline 
would be roughly close to the value of ğ›½0 . So, it is safe to assume 
that an MLR-based model is flexible enough to model an APIâ€™s 
pipeline  and  as  will  be  discussed  later  on,  it  is  not  too 
complicated and computationally expensive to have a negative 
impact on the performance of the system.  

If any of the tested games utilizes any of the optional stages, 
they should be also taken into account.  Table  5 represents the 
active (âœ“) and pass-through or inactive (ïƒ») shaders for the tested 
games  with  VS  and  PS  always  active  for  all  the  games. Also, 
some  of  the  important  graphics  characteristics  of  the  tested 
games are represented in Table 6. The number of vertices (#Vtx) 
determines the minimum, maximum and average values of the 
number  of  input  vertices  to  a  VS.  The  number  of  attributes 
(#Attr.)  also  determines  the  minimum,  maximum  and  average 
values  of  the  number  of  attributes  of  vertices.  The  minimum, 
maximum and average number of operations (#Ops) in shaders 
are also reported in Table 6. 

4.2. Estimating frametimes 

After  establishing  the  performance  functions  of  the  target 
graphics card and training the model parameters, GAMORRA is 
ready to be used to estimate frametimes. To experiment on the 
games,  a  5-minute  gameplay  sequence  of  each  game  was 
recorded using API Trace so it can be replayed multiple times to 

 
 
 
 
 
 
)
s

m

(

e
m

i
t

e
m
a
r
F

10.5

9.5

8.5

7.5

6.5

0

1

2

3

4

5

6

7

8

9

10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29

Frame number

FT

GM-H

GM-Of

FCM

Figure 4 Frametime estimation results for D3 on S1 

16

11

)
s

m

(

e
m

i
t

e
m
a
r
F

0

1

2

3

4

5

6

7

8

9

10

11

12 13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

Frame number

FT

GM-H

GM-Of

FCM

Figure 5 Frametime estimation results for SC on S1 

replicate the exact sequence of the gameplay.  

4.2.1.  Missed Frames Ratio (MFR) 

indicate  more 

Table  7 shows the  MFR values for each method and each 
game.  Higher  MFR  values 
frametime 
underestimations  which  can  negatively  impact  the  quality  of 
experience of frame loss sensitive applications such as computer 
games [38]. Table 7 compares the result of GAMORRA (GM) 
with  AR,  FCM,  and  FRQ.  The  results  show  that  GAMORRA 
outperforms all three methods from an MFR perspective on both 
S1 and S2 platforms. Among the tested methods, GAMORRA 
has the lowest MFR values with an average of 2.80% followed 
by FCM, AR, and FRQ with average miss rate values of 3.91%, 
10.65%, and 10.98%, for both S1 and S2 platforms. FCM which 
takes a more fine-grained approach compared to AR and FRQ 
that  rely  only  on  the  previous  framesâ€™  rendering  times, 
demonstrates  closer  results  to  GAMORRA.  This  is  due  to  the 
fact  that  FCM  considers  the  frame  structure  in  the  form  the 
number of drawcalls, the texture size and the number of vertices 
which 
to 
GAMORRA. Hence, it is outperformed by the proposed model. 
Moreover,  FCM  neither  uses  an  online  training  method  nor  a 
comprehensive  benchmark  like  GAMORRA  does.  This  puts 
FCM  at  more  of  a  disadvantage  which  leads  to  the  loss  of 
accuracy that is evident in Table 7.   

is  still  a  coarse-grained  approach  compared 

Figure  4  and  Figure  5  show  the  results  of  frametime 
estimation  for  D3  and  SC  on  S1  in  comparison  to  the  actual 
frametimes (FT) in a 30-frame sequence of gameplay for each 
game. GAMORRA is tested for both offline-only (GM-Of) and 
hybrid  (GM-H)  training  configurations  to  demonstrate  the 
impact of the online training scheme. D3 and SC are chosen as 
the best-case and worst-case scenarios since they have the lowest 
and  highest  MFR  values,  respectively.  To  keep  the  charts 
simple, AR and FRQ methods are discarded in these figures. 

and used for racing games, thus, performs efficiently on a mid-
range GPU. On the other hand, SC uses a pretty much outdated 
unreal engine 2.5 [40] which is pushed to its limits for the best 
visual  output  leading  to  a  somewhat  unstable  rendering 
performance. Hence, although GAMORRA outperforms FCM, 
still, a drop in accuracy is experienced for both GM-H and GM-
Of. Figure 4 shows that GM-H excels at modeling the rendering 
times  in  comparison  to  FCM  that  does  not  utilize  a  hybrid 
training  scheme. In  this  chart,  GAMORRA  switches  to  online 
training on frame 13 which leads to a divergence in GM-H and 
GM-Of estimations. It is evident on frames 19 and 23 that GM-
Of fails to react in time to frametime variations that are caused 
by changes other than workload variations. This also applies to 
FCM as well.  

Figure  5  shows  the  frametime  results  for  SC.  This  chart 
shows that GM-H reacts faster to the fluctuations in frametimes 
which is a result of both the more detailed core model and the 
more  sophisticated training scheme  in comparison to  FCM. In 
this chart, the system switches to online training on the second 
frame. FCM and GM-Of react to workload variations to some 
extent,  like  frame  10.  However,  GM-H  can  mimic  more 
aggressive variations better than GM-Of and FCM, like frames 
24 and 27. Using frame workload structure in conjunction with 
a  hybrid  training  scheme  results  in  faster  and  more  accurate 
reactions  to  frametime  variations  that  are  caused  by  both 
workload variations and changes in runtime conditions.  

4.2.2.  Estimation error 

The results of the estimation error are reported for each of 
the tested methods for both tested platforms in Table 8. Also, the 
percentage  of  the  estimation  error  is  reported  in  Table  9.  The 
percentage  of  estimation  error  is  highly  dependent  upon  the 
value  of  frame  rate  and  as  the  frame  rate  increases,  this 
percentage increases proportionally.  

D3 utilizes Ego engine [39] which is specifically designed 

The average estimation error reported in Table 8 shows the 

 
 
 
 
 
 
 
 
 
 
 
 
Game 

BC2 
D3 
FC3 
RL 
SC 
T4 
SE4 
MSh 
FF 

Game 

BC2 
D3 
FC3 
RL 
SC 
T4 
SE4 
MSh 
FF 

AR 
2.425 
0.810 
3.167 
1.403 
4.104 
1.938 
5.742 
3.906 
3.436 

AR 
19.84 
10.16 
12.92 
8.7 
27.84 
11.8 
34.22 
21.76 
20.99 

Table 8: The experimental results on estimation error (ms) 
S2 

S1 

FCM 
1.941 
0.682 
1.859 
1.316 
2.991 
1.853 
3.076 
2.244 
2.473 

FRQ  GM-H  GM-Of 
1.495 
1.248 
3.847 
0.638 
0.576 
1.614 
1.793 
1.108 
3.991 
1.211 
1.017 
2.753 
2.074 
1.564 
4.280 
1.798 
1.460 
2.494 
2.231 
1.953 
6.059 
2.002 
1.786 
4.271 
2.013 
1.831 
4.005 

AR 
2.375 
0.752 
2.954 
1.312 
3.761 
1.828 
5.390 
3.158 
2.782 

FCM 
1.713 
0.626 
1.451 
1.235 
2.021 
1.420 
2.708 
1.870 
2.146 

FRQ  GM-H  GM-Of 
1.217 
1.093 
2.906 
0.583 
0.45 
1.292 
1.141 
0.801 
3.293 
1.094 
0.743 
2.626 
1.569 
1.276 
4.086 
1.31 
1.143 
2.132 
1.917 
1.621 
5.597 
1.866 
1.463 
4.034 
1.954 
1.695 
3.519 

Table 9: The experimental results on estimation error (%) 
S2 

S1 

FCM 
15.88 
8.56 
7.58 
8.16 
20.29 
11.29 
18.33 
12.5 
15.11 

FRQ  GM-H  GM-Of 
12.23 
10.21 
31.48 
8.01 
7.23 
20.25 
7.32 
4.52 
16.28 
7.51 
6.31 
17.07 
14.07 
10.61 
29.04 
10.95 
8.89 
15.19 
13.3 
11.64 
36.11 
11.15 
9.95 
23.79 
12.3 
11.19 
24.47 

AR 
31.79 
15.73 
28.76 
13.44 
47.61 
19.34 
50.56 
43.08 
33.6 

FCM 
22.93 
13.1 
14.13 
12.65 
25.58 
15.03 
25.4 
25.51 
25.92 

FRQ  GM-H  GM-Of 
16.29 
14.63 
38.9 
12.2 
9.41 
27.03 
11.11 
7.8 
32.06 
11.21 
7.61 
26.91 
19.86 
16.15 
51.72 
13.86 
12.1 
22.56 
17.98 
15.21 
52.5 
25.46 
19.96 
55.03 
23.6 
20.47 
42.5 

Table 10: The experimental results on average time complexity (ms) 

Table 11: The experimental results on estimation overhead (%) 

Game 

BC2 
D3 
FC3 
RL 
SC 
T4 
SE4 
MSh 
FF 

AR 
1.63 
1.37 
1.46 
1.54 
1.82 
1.70 
1.51 
1.67 
1.49 

S1 

FCM  FRQ  GM  AR 
0.94 
1.54 
0.72 
1.17 
0.64 
1.19 
0.86 
1.26 
1.02 
1.74 
0.81 
1.41 
0.62 
1.43 
1.02 
1.41 
1.01 
1.18 

2.15 
2.02 
1.79 
2.11 
1.83 
2.04 
1.99 
2.03 
1.67 

1.47 
1.01 
1.08 
1.10 
1.65 
1.29 
1.24 
1.35 
1.01 

S2 

FCM  FRQ  GM 
1.23 
0.59 
0.66 
1.18 
0.40 
0.47 
1.03 
0.43 
0.52 
1.31 
0.53 
0.68 
1.16 
0.67 
0.83 
1.22 
0.46 
0.59 
1.19 
0.45 
0.52 
1.20 
0.49 
0.61 
1.01 
0.40 
0.44 

Game 

BC2 
D3 
FC3 
RL 
SC 
T4 
SE4 
MSh 
FF 

S1 

AR 
11.769 
14.668 
05.622 
08.715 
10.990 
09.382 
08.256 
08.512 
08.343 

FCM 
11.192 
12.801 
04.630 
07.246 
10.558 
07.908 
07.853 
07.283 
06.724 

FRQ 
10.738 
11.247 
04.220 
06.384 
10.067 
07.284 
06.881 
06.995 
05.811 

GM 
14.962 
20.220 
06.806 
11.568 
11.044 
11.051 
10.602 
10.160 
09.257 

AR 
11.177 
13.091 
05.866 
08.098 
11.435 
07.895 
05.496 
12.216 
10.872 

S2 
FCM  FRQ 
07.32 
8.118 
7.722 
8.952 
4.019 
4.819 
5.151 
6.513 
7.818 
9.507 
4.642 
5.876 
4.050 
4.651 
6.266 
7.683 
4.608 
5.046 

GM 
14.138 
19.799 
09.115 
11.834 
12.804 
11.434 
10.042 
14.068 
10.872 

dominance of GM-H for all the tested games on both S1 and S2 
platforms.  On  S1,  GM-H  has  an  average  of  4.13%  less 
estimation  error  for  the  tested  games  compared  to  FCM.  This 
value for S2 drops to 3.47%. This indicates that GM-H is capable 
of  handling  a  less  stable  rendering  session  on  weaker  devices 
such as S1 compared to a more powerful machine like S2. The 
estimation error gap between GM-H and the other two methods 
on S1 equals 9.74% and 14.79% for AR and FRQ, respectively. 
These values on S2 drop to 9.57% and 13.5% for AR and FRQ, 
respectively.  Although  GM-Of  does  not  take  advantage  of 
GAMORRAâ€™s  hybrid  training  scheme,  it  still  manages  to 
outperform all the  other methods other than GM-H. GM-Of is 
outperformed  by  GM-H  by  1.81%  and  1.64%  on  S1  and  S2, 
respectively. The larger estimation gap between GM-H and MG-
Of on S2 compared to S1 indicates that GM-Hâ€™s online training 
scheme is responsible for the larger estimation gap between GM-
H  and  the  other  models  that  do  not  utilize  an  online  training 
method.       

4.2.3.  Time complexity and overhead 

The  time  complexity  of  the  tested  methods  is  reported  in 

Table 10. FRQ only relies on the previous frametimes and the 
GPU  frequency  in  a  simple  linear  method  which  leads  to  the 
lowest complexity among the tested methods. FCM, which uses 
a scheme based on frame structure similar to GAMORRA, yet 
with  a  simpler  model,  has  lower  time  complexity  than  the 
proposed  model.  This  is  due  to  the  simpler  nature  of  its  core 
model and the absence of any online training scheme. AR relies 
on an iterative process to obtain its model parameters. Hence, it 
is  expected  to  have  a  larger  time  complexity  compared  to  the 
other two methods. GAMORRA has the largest time complexity 
among the tested models. In addition to its more complex core 
model,  the  online  training  scheme  of  the  proposed  model  is 
expected to have a slight negative impact on its time complexity. 
However,  although  GAMORRA  has  a  larger  time  complexity 
compared to the other tested methods, it still manages to perform 
acceptably and in real-time, especially considering its superior 
accuracy.   

Table 11 shows the overhead of GAMORRA in comparison 
to  the  three  tested  methods  for  both  S1  and  S2  platforms.  As 
expected from the time complexity results represented in Table 
10,  FRQ  which  is  the  least  computationally  complex  method 

 
 
 
 
 
 
 
among  all  the  tested  methods,  outperforms  the  other  methods 
from an estimation overhead standpoint.  An average overhead 
of  7.74%, 8.47%,  9.58% and 11.74% is experienced for  FRQ, 
FCM,  AR  and  GM,  respectively,  on  S1,  and  5.73%,  6.80%, 
9.57% and 12.68% for FRQ, FCM, AR and GM, respectively, 
on S2. The results of S1 are mostly similar to the results of S2. 
However, there are cases in which there is a wider gap between 
the overhead of S1 and S2, which indicates that extra processing 
power of S2 has a larger impact on the performance of the target 
game  than  it  has  on  the  performance  of  the  workload  model. 
Since  a  large  portion  of  GAMORRAâ€™s  time  complexity  is 
caused by a  serial analysis of the  shader code  complexity, the 
overhead does not scale with the processing power of the target 
device as much as the other methods. This also applies to AR 
which uses an iterative parameter estimation method.   

It  should  be  noted  that  these  games  are  designed  to  be 
rendered  in  60  fps  and  the  overhead  is  highly  affected  by  the 
value of the frametimes. As the average frametime increases, the 
overhead  would  decrease.  For  example,  if  the  experimented 
game runs at 30 fps and the frame rate is not capped artificially, 
each frame would take about 33 ms to be rendered. Hence, the 
overhead values would almost be cut in half.  

4.3. System resource usage 

GAMORRAâ€™s implementation is comprised of two distinct 
parts:  the  analyzer  and  the  core  model.  The  analyzer  analyzes 
the intercepted graphics API commands and stores the required 
data  (e.g.,  pointers  and  properties  of  buffers,  textures,  and 
resource views like size, resolution and usage). After analyzing 
the graphics data, the core model is fed with the required input 
parameters to be trained and used to predict frametimes.  

Table 12 reports the system memory usage of all the tested 
methods along with the  analyzers of  GAMORRA  (GMA)  and 
FCM (FCMA) in megabytes (MB). FRQ which is the simplest 
model  among  the  tested  models,  requires  at  most  1.0  MB  of 
system memory. FCM also requires a frame analyzer similar to 
GAMORRA, albeit much simpler, as is evident from the results 
in Table 12. FCMA requires 15.67 MB of memory on average 
while  GMA  which  needs  to  consider  more  parameters  than 
FCMA  requires  an  average  of  56.78  MB  of  system  memory. 
While  neural  networks  are  known  to  demand  large  amount  of 
system memory as their number of layers increase, the choice of 
MLR for the core model of GAMORRA ensures a limited and 
small  amount  of  memory  requirement  while  it  uses  32-bit 
floating point precision for its weights. The reported results in 
Table  12  shows  that  the  memory  usage  of  the  core  model  of 
GAMORRA will not surpass 3 MB at most. FCM uses a simpler 
core model compared to GAMORRA which has led to 0.87 MB 
less memory usage on average. Since AR only needs to consider 
the frametime of  a limited number of  previous frames, it does 
not  need  to  use  an  analyzer  like  GAMORRA  and  FCM.  The 
memory usage of the AR is directly impacted by the sequence 
length of the model. With the sequence length set to 10, the ARâ€™s 
memory  usage  is  almost  similar  to  GAMORRA.  It  should  be 

Table 12: System memory usage (MB) of the analyzer and the core 
model of GAMORRA in comparison to AR, FCM, and FRQ 

Game  AR  FCM  FCMA  FRQ  GM  GMA 

BC2 
D3 
FC3 
RL 
SC 
T4 
SE4 
MSh 
FF 

0.9 
1.2 
1.4 
0.8 
1.1 
0.6 
0.9 
1.2 
1.0 

1.4 
1.5 
1.8 
1.3 
1.7 
1.2 
1.5 
1.7 
1.6 

18 
13 
19 
10 
15 
16 
21 
17 
12 

0.7 
0.9 
1.0 
0.5 
0.8 
0.4 
0.5 
0.9 
0.7 

2.4 
2.1 
2.5 
2.3 
2.5 
2.2 
2.4 
2.6 
2.5 

64 
46 
67 
29 
48 
62 
78 
63 
54 

noted that the training sessionâ€™s memory usage is different from 
the memory usage of the model during prediction. For both AR 
and  GAMORRA  (offline),  the  training  sessionâ€™s  memory  is 
almost similar and it is equal to 1.32 gigabytes on average.  

4.4. Overall verdict 

The  experimental  results  from  the  previous  subsections 
reveals that GAMORRA can outperform the other three tested 
methods in terms of accuracy.  This comes at the cost of more 
time complexity and more memory usage compared to FRQ and 
FCM. However, the time complexity and the memory usage are 
reasonable  for  a  real-time  application  and  do  not  compromise 
the modelâ€™s performance. For less varied graphical workloads, 
GAMORRA and FCM perform similarly with a slight edge in 
accuracy for the proposed model. As the graphical workload of 
the  games  and  the  system  conditions  become  more  varied, 
GAMORRA tends to provide better estimations compared to the 
other  methods  and  adapts  to  frametime  variations  more 
accurately. The results for GAMORRA with an the offline-only 
training scheme indicates that it has some of the flaws of FCM 
in  adapting  to  changes  in  system  conditions  during  runtime. 
However,  it  still  achieves  less  estimation  error  compared  to 
FCM due to its detailed core model.  

5.  CONCLUDING REMARKS 

This  paper  proposes  GAMORRA,  an  API-level  workload 
model  for  rasterization-based  graphics  pipeline  architectures. 
Modeling  the  workload  of  a  gameâ€™s  frames  proves  useful  in 
different  applications  like  DVFS-based  power  management 
schemes in smartphones or estimation of performance measures 
like frametimes in a graphics streaming-based CG system. The 
API-level approach lets GAMORRA to work without the need 
to  modify  the  source  code  of  the  target  application  and  the 
rendering hardware which is an essential part of previous studies 
to compensate for the lack of sufficient depth in their core model. 
To account for the high-level approach of GAMORRA and its 
lack  of  accuracy,  an  MLR-based  core  model,  a  hybrid 
online/offline  training  method  to  train  the  model  and  a 
benchmark suite to tune the model parameters according to the 
performance  of  the  target  rendering  system  are  proposed. 
GAMORRA  takes  into  account  the  overall  structure  of  a 
graphics rendering pipeline using an MLR model along with the 
size of the input data, i.e., vertex numbers and texture resolution 
as the explanatory variables. Also, the complexity of each shader 

 
 
 
is taken into account as well. The experiments were performed 
on two different rendering platforms with three other workload 
models. The experimental results show a meaningful estimation 
error reduction in comparison to previously proposed methods 
while  keeping  the  time  complexity  and  the  time  overhead 
imposed  on  the  system  within  an  acceptable  range.  Also,  the 
miss rate for underestimated frames is reduced significantly.  

References 

[1]  C.-Y.  Huang,  K.-T.  Chen,  D.-Y.  Chen,  H.-J.  Hsu,  and  C.-H.  Hsu, 
"GamingAnywhere: The first open source cloud gaming system,"  ACM 
Trans. Multimedia Comput. Commun. Appl., vol. 10, no. 1s, p. Article 10, 
2014. 

[3] 

[4] 

[2]  X.  Liao,  L.  Lin,  G.  Tan,  H.  Jin,  X.  Yang,  W.  Zhang,  and  B.  Li, 
"LiveRender: A Cloud Gaming System Based on Compressed Graphics 
Streaming," IEEE/ACM Transactions on Networking, vol. 24, no. 4, pp. 
2128-2139, 2016. 
 I.  Nave,  H.  David,  A.  Shani,  Y.  Tzruya,  A.  Laikari,  P.  Eisert,  and  P. 
Fechteler, "Games@large graphics streaming architecture," in 2008 IEEE 
International Symposium on Consumer Electronics, 2008, pp. 1-4. 
 X. Nan, X. Guo, Y. Lu, Y. He, L. Guan, S. Li, and B. Guo, "A novel cloud 
gaming  framework  using  joint  video  and  graphics  streaming,"  in  2014 
IEEE International Conference on Multimedia and Expo (ICME), 2014, 
pp. 1-6. 
I.  Soltani  Mohammadi,  M.  Ghanbari,  and  M.  R.  Hashemi,  "A  hybrid 
graphics/video  rate  control  method  based  on  graphical  assets  for  cloud 
gaming," Journal of Real-Time Image Processing, pp. 1-19, 2021. 
[6]  E. Cuervo, A. Wolman, L. P. Cox, K. Lebeck, A. Razeen, S. Saroiu, and 
M.  Musuvathi,  "Kahawai:  High-Quality  Mobile  Gaming  Using  GPU 
Offload," presented at the Proceedings of the 13th Annual International 
Conference  on  Mobile  Systems,  Applications,  and  Services,  Florence, 
Italy, 
Available: 
2015. 
https://doi.org/10.1145/2742647.2742657. 

[Online]. 

[5] 

[7]  D.-Y.  Chen  and  M.  El-Zarki,  "A  Framework  for  Adaptive  Residual 
Streaming  for  Single-Player  Cloud  Gaming,"  ACM  Trans.  Multimedia 
Comput. Commun. Appl., vol. 15, no. 2s, p. Article 66, 2019. 
 D.-J.  Zhang-Jian,  C.-N.  Lee,  C.-Y.  Huang,  and  S.-R.  Kuang,  "Power 
Estimation  for  Interactive  3D  Game  Using  an  Efficient  Hierarchical-
Based  Frame  Workload  Prediction,"  in  Proceedings  of  2009  APSIPA 
Annual Summit and Conference, 2009, pp. 208-215. 

[8] 

[9]  B. Dietrich, D. Goswami, S. Chakraborty, A. Guha, and M. Gries, "Time 
Series  Characterization  of  Gaming  Workload  for  Runtime  Power 
Management," IEEE Transactions on Computers, vol. 64, no. 1, pp. 260-
273, 2015. 

[10]   U.  Gupta,  J.  Campbell,  U.  Y.  Ogras,  R.  Ayoub,  M.  Kishinevsky,  F. 
Paterna,  and  S.  Gumussoy,  "Adaptive  Performance  Prediction  for 
Integrated  GPUs,"  in  2016  IEEE/ACM  International  Conference  on 
Computer-Aided Design (ICCAD), 2016, IEEE, pp. 1-8. 

[11]   B.  Dietrich,  S.  Nunna,  D.  Goswami,  S.  Chakraborty,  and  M.  Gries, 
"LMS-based Low-Complexity Game Workload Prediction for DVFS," in 
IEEE International Conference on Computer Design, 2010, pp. 417-424. 
[12]  H.  Li,  M.  Li,  and  B.  Prabhakaran,  "Middleware  for  streaming  3D 
progressive  meshes  over  lossy  networks,"  ACM  Trans.  Multimedia 
Comput. Commun. Appl., vol. 2, no. 4, pp. 282â€“317, 2006. 

[13]   B.  Dietrich,  S.  Nunna,  D.  Goswami,  S.  Chakraborty,  and  M.  Gries, 
"LMS-based  low-complexity  game  workload  prediction  for  DVFS,"  in 
2010 IEEE International Conference on Computer Design, 2010, pp. 417-
424. 

[14]   M. Wimmer and P. Wonka, "Rendering Time Estimation for Real-Time 
Rendering,"  in  Eurographics  Symposium  on  Rendering,  2003,  Goslar, 
DEU, Eurographics Association, 2003, pp. 118-129. 

[15]   P.  Mercati,  R.  Ayoub,  M.  Kishinevsky,  E.  Samson,  M.  Beuchat,  F. 
Paterna, and T. Å . Rosing, "Multi-variable dynamic power management 
for the GPU subsystem," in Design Automation Conference, 2017, IEEE, 
pp. 1-6. 

[16]  J. D. Jobson, "Multiple Linear Regression," in Applied Multivariate Data 

Analysis: Springer New York, 1991, pp. 219-398. 

[17]  D. Sahoo, Q. Pham, J. Lu, and S. C. Hoi, "Online deep learning: Learning 
deep neural networks on the fly," arXiv preprint arXiv:1711.03705, 2017. 

[18]   B. C. Mochocki, K. Lahiri, S. Cadambi, and X. S. Hu, "Signature-based 
workload estimation for mobile 3D graphics," in 2006 43rd ACM/IEEE 
Design Automation Conference, 2006, pp. 592-597. 

[19]   Y. Gu and S. Chakraborty, "A Hybrid DVS Scheme for Interactive 3D 
Games,"  in  2008  IEEE  Real-Time  and  Embedded  Technology  and 
Applications Symposium, 2008, IEEE, pp. 3-12. 

[20]  A. Visioli, Practical PID Control. 2006. 
[21]  B.  Dietrich  and  S.  Chakraborty,  "Lightweight  graphics  instrumentation 
for  game  state-specific  power  management  in  Android,"  Multimedia 
Systems, vol. 20, no. 5, pp. 563-578, 2014. 

[22]   Z.  Cheng,  X.  Li,  B.  Sun,  J.  Song,  C.  Wang,  and  X.  Zhou,  "Behavior-
Aware Integrated CPU-GPU Power Management for Mobile Games," in 
2016  IEEE  24th  International  Symposium  on  Modeling,  Analysis  and 
Simulation  of  Computer  and  Telecommunication  Systems  (MASCOTS), 
2016, pp. 439-444. 

[23]   J. Song, X. Li, B. Sun, Z. Cheng, C. Wang, and X. Zhou, "FCM: Towards 
fine-grained GPU power management for closed source mobile games," 
in 2016 International Great Lakes Symposium on VLSI (GLSVLSI), 2016, 
pp. 353-356. 

[24]  M.  Wloka,  "Batch,  Batch,  Batch:  What  Does  It  Really  Mean?,"  Game 

Developers Conference.  

[25]   Y.  Choi,  S.  Park,  and  H.  Cha,  "Graphics-aware  power  governing  for 
mobile  devices,"  in  Proceedings  of  the  17th  Annual  International 
Conference on Mobile Systems, Applications, and Services, 2019, pp. 469-
481. 

[26]  X.  Li  and  G.  Li,  "An Adaptive  CPU-GPU  Governing  Framework  for 
Mobile  Games  on  big.  LITTLE Architectures,"  IEEE  Transactions  on 
Computers, vol. 70, no. 9, pp. 1472-1483, 2020. 

[27]   B. C. Mochockitt, K. Lahiri, S. Cadambi, and X. S. Hu, "Signature-based 
workload estimation for mobile 3D graphics," in 2006 43rd ACM/IEEE 
Design Automation Conference, 2006, IEEE, pp. 592-597. 

[28]   J. Song, X. Li, B. Sun, Z. Cheng, C. Wang, and X. Zhou, "FCM: Towards 
Fine-Grained  GPU  Power  Management  for  Closed  Source  Mobile 
Games," in International Great Lakes Symposium on VLSI, 2016, IEEE, 
pp. 353-356. 

[29]  L. N. Trefethen and I. David Ba, Numerical Linear Algebra. USA: Society 

for Industrial and Applied Mathematics, 1997, p. 373. 

[30]   Y. Zhang, Q. Li, G. Dai, and H. Zhang, "A new recursive least-squares 
identification  algorithm  based  on  singular  value  decomposition,"  in 
Proceedings  of  1994  33rd  IEEE  Conference  on  Decision  and  Control, 
1994, vol. 2, IEEE, pp. 1733-1734. 

[31]  "DirectX  Graphics  and  Gaming  |  Microsoft  Docs,"  September  2018. 
https://docs.microsoft.com/en-

Available: 

[Online]. 
us/windows/desktop/directx 

[32]  M. Satran and M. Jacobs. "Resource Limits (Direct3D 11) - Win32 apps | 
https://docs.microsoft.com/en-

Microsoft 
us/windows/win32/direct3d11/overviews-direct3d-11-resources-limits 
(accessed 2020). 

Microsoft. 

Docs." 

[33]  B. Kerbl, M. Kenzel, E. Ivanchenko, D. Schmalstieg, and M. Steinberger, 
"Revisiting  The  Vertex  Cache:  Understanding  and  Optimizing  Vertex 
Processing on the modern GPU," Proceedings of the ACM on Computer 
Graphics and Interactive Techniques, vol. 1, no. 2, pp. 1-16, 2018. 

[34]  "APITrace." https://github.com/apitrace (accessed 2020). 
[Online]. 
[35]  TensorFlow. 

Zenodo. 
https://doi.org/10.5281/zenodo.5189249 

(2021). 

Available: 

[36]  B.  L.  Peuto  and  L.  J.  Shustek,  "An  Instruction Timing  Model  of  CPU 
Performance," ACM SIGARCH Computer Architecture News, vol. 5, no. 
7, pp. 165-178, 1977. 

[37]  Y. Wang, V. Lee, G. Wei, and D. Michae, "Predicting New Workload or 
CPU Performance by Analyzing Public Datasets," ACM Transactions on 
Architecture and Code Optimization, vol. 15, no. 4, p. 21, 2019. 

[38]   S.  Zadtootaghaj,  S.  Schmidt,  and  S.  MÃ¶ller,  "Modeling  Gaming  QoE: 
Towards the Impact of Frame Rate and Bit Rate on Cloud Gaming," in 
2018  Tenth  International  Conference  on  Quality  of  Multimedia 
Experience (QoMEX), 2018, IEEE, pp. 1-6. 

[39]  "Ego 

(game  engine)."  Codemasters.  http://www.codemasters.com/ 

(accessed 2020). 

[40]  "Unreal  Engine."  Epic  Games.  https://www.unrealengine.com/en-US/ 

(accessed 2020). 

 
 
 
 
