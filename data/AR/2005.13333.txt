0
2
0
2

y
a
M
7
2

]

R
S
.
h
p
-
o
r
t
s
a
[

1
v
3
3
3
3
1
.
5
0
0
2
:
v
i
X
r
a

Draft version May 28, 2020
Typeset using LATEX twocolumn style in AASTeX62

Supervised convolutional neural networks for classiﬁcation of ﬂaring and nonﬂaring
active regions using line-of-sight magnetograms
Shamik Bhattacharjee,1 Rasha Alshehhi,2 Dattaraj B. Dhuri,1 and Shravan M. Hanasoge1, 2

1Department of Astronomy and Astrophysics, Tata Institute of Fundamental Research, Mumbai, India 400005
2Center of Space Science, New York University Abu Dhabi, Abu Dhabi, United Arab Emirates

ABSTRACT

Solar ﬂares are explosions in the solar atmosphere that release intense bursts of short-wavelength
radiation and are capable of producing severe space-weather consequences. Flares release free energy
built up in coronal ﬁelds, which are rooted in active regions (ARs) on the photosphere, via magnetic
reconnection. The exact processes that lead to reconnection are not fully known and therefore reliable
forecasting of ﬂares is challenging. Recently, photospheric magnetic-ﬁeld data has been extensively
analysed using machine learning (ML) and these studies suggest that ﬂare-forecasting accuracy does
not strongly depend on how long in advance ﬂares are predicted (Bobra & Couvidat 2015; Raboonik
et al. 2017; Huang et al. 2018). Here, we use ML to understand the evolution of AR magnetic ﬁelds
before and after ﬂares. We explicitly train convolutional neural networks (CNNs) to classify SDO/HMI
line-of-sight magnetograms into ARs producing at least one M- or X-class ﬂare or as nonﬂaring. We
ﬁnd that ﬂaring ARs remain in ﬂare-productive states — marked by recall > 60% with a peak of ∼ 80%
— days before and after ﬂares. We use occlusion maps and statistical analysis to show that the CNN
pays attention to regions between the opposite polarities from ARs and the CNN output is dominantly
decided by the total unsigned line-of-sight ﬂux of ARs. Using synthetic bipole magnetograms, we
ﬁnd spurious dependencies of the CNN output on magnetogram dimensions for a given bipole size.
Our results suggest that it is important to use CNN designs that eliminate such artifacts in CNN
applications for processing magnetograms and, in general, solar image data.

Keywords: methods: data analysis — Sun: magnetic ﬁelds — Sun: ﬂares — methods: statistical

1. INTRODUCTION

Solar ﬂares release free energy built up in the coronal
magnetic ﬁelds in the form of intense short-wavelength
radiation. Flare intensity is measured in terms of X-ray
ﬂux and major ﬂares, i.e. M- and X-class ﬂares, produce
peak X-ray ﬂux of > 10−5 W-m−2 and > 10−4 W-m−2
respectively. The short-wavelength radiation released
in ﬂares causes disruptions in GPS communication, ra-
dio blackouts and poses health hazards to astronauts
and ﬂight crew. Reliable forecasting of ﬂares and other
space-weather events is, therefore, necessary (Eastwood
et al. 2017).

Coronal magnetic ﬁelds are energized by the emer-
gence of magnetic ﬂux from the solar interior and sub-
sequent build up of electric current (Cheung & Isobe

Corresponding author: Dattaraj Dhuri
dattaraj.dhuri@tifr.res.in

2014; Stein 2012; Leka et al. 1996). Flares occur as a
consequence of magnetic reconnection of coronal ﬁelds
(Shibata & Magara 2011; Su et al. 2013). Over the past
few decades, several case studies and statistical studies
have focused on the analysis of photospheric magnetic-
ﬁeld, obtained from space as well as ground-based ob-
servatories, to understand ﬂare precursors for reliable
forecasting (Schrijver 2009; Leka & Barnes 2007; Wang
& Liu 2015). Features such as continuously emerging
ﬂux (Nitta & Hudson 2001), strong polarity inversion
line (Schrijver 2007) and accumulation of electric cur-
rent and magnetic helicity Park et al. (2008); Konto-
giannis et al. (2017) are found to be strongly correlated
with ﬂaring activity. However, no single measure of pho-
tospheric magnetic ﬁeld is suﬃcient for reliably forecast-
ing ﬂares (Leka & Barnes 2007). Operational ﬂare fore-
casts rely therefore on the analysis of AR magnetograms
and coronal images by human experts (McIntosh 1990;
Rust et al. 1994; Crown 2012) and reliable automated

 
 
 
 
 
 
2

forecasting of ﬂares is yet to be achieved (Barnes et al.
2016).

Helioseismic and Magnetic Imager (HMI) (Scherrer
et al. 2012) onboard NASA’s Solar Dynamics Observa-
tory (SDO) (Pesnell et al. 2012) provides high-resolution
photospheric vector-magnetic-ﬁeld images. With the
availability of machine learning (ML) techniques (Hastie
et al. 2001), these data have been extensively ana-
lyzed for improving ﬂare forecasting. ML approaches
have primarily relied on using magnetic-ﬁeld features
calculated from vector-magnetograms, such as space-
weather HMI active region patches (SHARPS) (Bobra
et al. 2014), known to be correlated with ﬂare activity.
These magnetic-ﬁeld features describe average charac-
teristics of ARs and are analysed by a variety of ML
algorithms trained for forecasting ﬂares (Ahmed et al.
2013; Bobra & Couvidat 2015; Raboonik et al. 2017;
Nishizuka et al. 2017; Jonas et al. 2018). Overall, these
forecasts have yielded statistically superior performance
than those based on subjective analyses of ARs (Crown
2012). The leading contributors for ﬂare forecasting in
these ML studies have been AR magnetic-ﬁeld features
corresponding to extensive AR properties, e.g. total un-
signed magnetic ﬂux (Bobra & Couvidat 2015; Dhuri
et al. 2019).

Rather than only considering AR-averaged magnetic-
ﬁeld features, advanced ML techniques such as convolu-
tional neural networks (CNNs) (Goodfellow et al. 2016;
Krizhevsky et al. 2012; LeCun et al. 2015) provide an
opportunity to directly process AR magnetograms and
characterise AR morphological features correlated with
ﬂares. CNNs trained on magnetograms may automati-
cally extract subtle and localized features in AR mag-
netic ﬁelds that are precursors to ﬂares, thereby im-
proving ﬂare forecasts and our understanding of ﬂare
mechanisms. For instance, Huang et al. (2018) used
line-of-sight magnetograms to train CNNs for forecast-
ing M- and X-class ﬂares. Their result suggests that
forecasting accuracy does not reduce appreciably as the
forward-looking-time, i.e., time in advance of the ﬂare,
is increased. This is consistent with earlier studies us-
ing features derived from AR magnetograms (Bobra &
Couvidat 2015; Raboonik et al. 2017).

Dhuri et al. (2019) explicitly trained support vector
machines (SVMs) to classify SHARP features derived
from ﬂaring and nonﬂaring ARs. They found that ﬂar-
ing ARs remain in ﬂare-productive states days before
and after M- and X-class ﬂares, marked by distinctly
high values of extensive AR features.
In the present
work, we use supervised learning to train CNNs to dis-
tinguish between line-of-sight magnetograms of ﬂaring
and nonﬂaring ARs. The CNN builds a correlation be-

tween spatial patterns identiﬁed in AR magnetograms
and ﬂaring activity. Following Dhuri et al. (2019), we
explicitly study how machine correlation changes days
before and after ﬂares. Notwithstanding their success in
performing classiﬁcation and pattern detection tasks, it
is challenging to understand the operation and compo-
nents of CNNs and deep neural networks. Here, we use
statistical analysis of the machine correlation as well as
occlusion maps to infer morphological patterns detected
by the CNN and interpret machine performance. Using
synthetic magnetograms, we ﬁnd that the CNN output
depends on systematic factors arising as a consequence
of unequal sizes of AR magnetograms.

This paper is organized as follows. In section 2, we de-
tail line-of-sight magnetic-ﬁeld data used for the analy-
sis. In section 3, we explain the CNN architectures used
— a simple CNN with two convolutional layers as a base-
line model and another with inception modules similar
to GoogleNet (Szegedy et al. 2015) that incorporates
diﬀerent spatial convolution ﬁlters in a single convolu-
tional layer. In section 4, we compare the performances
of the two CNN architectures for the classiﬁcation of
ﬂaring and nonﬂaring ARs. We explain in detail sta-
tistical analyses of CNN outputs that are performed to
understand the CNN operation. We also compare the re-
sults of the CNN with the classiﬁcation results of Dhuri
et al. (2019) using vector-magnetic-ﬁeld features. Using
synthetic data, we trace systematic errors in the CNN
classiﬁcation to unequal AR sizes. We present occlusion
maps obtained to highlight the morphological patterns
learned by the CNN. In section 5, we summarise our
ﬁndings.

2. DATA

We use line-of-sight magnetograms provided by the
Solar Dynamics Observatory (SDO) and a solar ﬂare
events catalogue provided by the Geostationary Opera-
tional Environmental Satellite (GOES). These datasets
are publicly available.

Since 2010, SDO monitors solar activity by imag-
ing the solar surface and atmosphere. Helioseismic

May’10 - Sep’15 Oct’15 - Aug’18

# ﬂaring ARs
# non-ﬂaring ARs
# M- & X-class ﬂares

Train & Val
161
696
627

Test
20
191
106

Table 1. Active region (AR) dataset used for classiﬁcation
of ﬂaring and nonﬂaring ARs using convolutional neural net-
works (CNNs).

3

Figure 1. A simple convolutional neural network (CNN), referred to as the CNN-1, used for the classiﬁcation of line-of-sight
magnetograms of ﬂaring and nonﬂaring active regions (ARs). The CNN-1 consists of two Conv2D layers as shown, which are
made up of 2D convolutional ﬁlters that scan over the image for magnetic ﬁeld features. Each convolutional layer is followed
by a max-pooling layer, which downsamples the image. The output of the second convolutional layer is ﬂattened and processed
by a fully connected (FC) layer of neurons. The FC layer is connected to the output neuron. The CNN-1 serves as a baseline
model for the classiﬁcation of ﬂaring and nonﬂaring ARs.

and Magnetic Imager (HMI) onboard SDO yields full-
disk vector-magnetograms every 12 minutes with a plate
scale of 0.5 arcsecs (∼ 380 km at the disk center). From
full-disk magnetograms, AR patches are automatically
detected and tracked as they rotate across the visible
solar disk. These AR patches are available among HMI-
derived data products Space-weather HMI Active Re-
gion Patches (SHARPs) (Bobra et al. 2014). To elimi-
nate projection eﬀects, magnetograms are remapped on
a cylindrical equal-area (CEA) grid. The CEA magne-
tograms for each AR in SHARPs data series are available
at a cadence of 12 minutes. GOES provides a catalogue
of solar ﬂares (since 1986) and also identiﬁes ARs that
produce them according to the National Oceanic and
Atmospheric Administrations’ (NOAA) AR numbering
scheme. ARs identiﬁed by SHARPs may contain more
than one AR as per the NOAA deﬁnition (Bobra et al.
2014). We consider an AR, as identiﬁed in the SHARP
data series, as ﬂaring if it contains any of the NOAA ARs
that produce at least one M- or X-class ﬂare during their
passage across the visible solar disk. Otherwise, ARs are
classiﬁed as nonﬂaring. For every AR, we consider the
magnetogram samples taken at every 1 hour.

The QUALITY keyword in the SHARP dataset indi-
cates observations and measurement conditions for the
magnetograms (Bobra et al. 2014). We consider only
those measurements for which QUALITY ≤ 10000 in
hexadecimal, indicating that Stokes vectors are reliable.
The HMI instrument-noise level is sensitive to the rela-
tive velocity between the SDO and Sun. Therefore, we
only consider observations obtained when the relative
velocity < 3500 m/s (Hoeksema et al. 2014) and within
±45◦ of the central meridian. We only include ARs
from the SHARPs series with maximum area > 25 Mm2.
This eliminates nonﬂaring ARs with very small sizes and

does not aﬀect the ﬂaring AR population. We use the
SHARP data series from the publicly accessible JSOC
data server at http://jsoc.stanford.edu/ and the GOES
ﬂare catalogue via python solar physics library Sunpy
(The SunPy Community et al. 2020).

We consider ﬂaring and nonﬂaring ARs between May
2010 and Aug 2018. We chronologically split the avail-
able data into two parts: ARs between May 2010 - Sep
2015 are used for training and validation of CNNs and
the remaining ARs, between Oct 2015 - Apr 2018, are
used as test data. The number of ARs considered in the
study is listed in Table 1. We train CNNs to classify
ARs as ﬂaring, labelled 1, and nonﬂaring, labelled 0.
Since ﬂaring activity depends on the solar cycle varia-
tion, chronologically splitting the data for training and
test may introduce a bias. Indeed, the ratio of the num-
ber of ﬂaring to nonﬂaring ARs in the test set is ap-
proximately half the training-validation set. Thus, for
the test data, identiﬁcation of ﬂaring ARs is expected
to be more challenging and identiﬁcation of nonﬂaring
ARs is expected to be easier for trained CNNs.

3. METHOD

We use CNNs (Convolutional Neural Networks) to dis-
tinguish between line-of-sight magnetograms of ﬂaring
and nonﬂaring ARs. CNNs, in contrast to widely used
fully connected networks (Hastie et al. 2001), use con-
volutional ﬁlters (also known as kernels) to scan input
images and detect patterns. The convolutional ﬁlters
that slide over the image are in the form of M × M neu-
rons where M is very small compared to the input-image
dimensions (typically a 3 × 3 ﬁlter e.g. in Simonyan &
Zisserman (2014)). Hence, there are far fewer numbers
of parameters as compared to a fully connected network.
CNNs have been hugely successful in ﬁnding patterns in

FlattenOutputConv2Dﬁlter =stride =Conv2Dﬁlter = (1,1)stride = (1,1)MaxPoolingpool_size = (2,2)stride = (2,2)InputN=64N=1N=64(3,3)(1,1)4

Figure 2. The inception module used in the CNN-2 (Figure
3). The inception module comprises of 2D convolutional ﬁl-
ters of three sizes — 3 × 3, 5 × 5 and 7 × 7. It also comprises
a 3 × 3 max-pooling layer. The convolution ﬁlters of diﬀer-
ent sizes are sensitive to magnetic-ﬁeld features of diﬀerent
length-scales. Outputs of the three convolutional layers and
the max-pooling layer are concatenated to be fed as the input
to the next layer.

images for performing tasks such as image classiﬁcation,
object detection, etc. (LeCun et al. 2015; Goodfellow
et al. 2016).

A 2D convolutional ﬁlter of M × M neurons sequen-
tially scans over input images, at a time processing a
M × M-pixel sub-region as per the neuron activation
function (see Appendix A). Each neuron in the CNN ﬁl-
ter yields y = f ((cid:80)
i wixi + b), where x are inputs with
weights w, b is the ﬁlter bias, and f is the activation
function. CNNs also comprise max-pooling layers. A
max-pooling ﬁlter of size N × N-pixel downsamples the
input by factor N, picking out the maximum value of the
N × N-pixel sub-region. As a result, each convolutional
layer is sensitive to features of larger length scales (by
factor N) in comparison to the preceding layer.

The CNN architecture for a given problem can vary
from simple to deep and complex in terms of number
and design of convolutional layers. Here, we train two
types of CNNs — a simple architecture that serves as a
baseline model and a complex architecture using incep-
tion modules similar to the one used in the GoogleNet
(Szegedy et al. 2015). The details of the CNN architec-
tures are as follows.

• CNN-1: This comprises two convolutional layers,
followed by one fully connected layer and the out-
put layer. The ﬁrst convolution layer is followed
by a 2 × 2 max-pooling layer. A schematic il-
lustration of the network architecture is shown in
Figure 1.

from the GoogleNet (Szegedy et al. 2015). Typi-
cally, in a convolution layer, we use ﬁlters of ﬁxed
size e.g. 3 × 3 (Simonyan & Zisserman 2014). De-
pending on the problem, a particular ﬁlter size
may work the best. However, the input images
may contain features correlated with ﬂaring activ-
ity over a variety of length-scales. The inception
V1 modules are designed for a situation like this.
The inception module comprises convolution ﬁl-
ters of diﬀerent sizes. The output of these con-
volution operations is concatenated and fed as an
input to the next layer. We use the inception mod-
ule with three diﬀerent convolution ﬁlters and one
max-pooling ﬁlter as shown in Figure 2. The com-
plete CNN-2 architecture is shown in Figure 3. It
consists of two conventional convolutional layers
followed by two inception modules. The two con-
ventional convolutional layers and the ﬁrst incep-
tion module is followed by a max-pooling layer.
The ﬁnal inception module is followed by a global-
average-pooling layer which is then connected to
the output neuron.

We use minibatch stochastic-gradient descent (Hastie
et al. 2001) to train the CNNs. The CNNs process the
input magnetograms and output a number between 0
and 1 which may be interpreted as a probability of the
magnetogram belonging to the ﬂaring population. The
output is compared with the true label 0 and 1 for non-
ﬂaring and ﬂaring ARs respectively and a measure of
misﬁt, i.e. loss, is calculated (see Appendix A). During
the training, the weights and biases of CNNs are tuned
to minimize the loss using gradient descent. For eﬀec-
tive training, hyper-parameters such as the learning rate
lr and minibatch size nBS also need to be tuned. We
search for and ﬁx the learning rate and minibatch size
such that the CNN classiﬁcation performance is maxi-
mized. The CNN output, a number between 0 and 1, is
thresholded at 0.5 to obtain the predicted label 0 and 1
for nonﬂaring and ﬂaring respectively. This CNN output
is categorized as follows.

• True Positives (TPs) - Sub-population of ﬂaring

magnetograms classiﬁed as ﬂaring (1).

• True Negatives (TNs) - Sub-population of nonﬂar-
ing magnetograms classiﬁed as nonﬂaring (0).

• False Positives (FPs) - Sub-population of nonﬂar-

ing magnetograms classiﬁed as ﬂaring (1).

• CNN-2: This is a complex architecture using in-
ception modules similar to inception V1 modules

• False Negatives (FNs) - Sub-population of ﬂaring

magnetograms classiﬁed as nonﬂaring (0).

Previous layer33 convolution55 convolution77 convolution33 MaxPoolingConcatenateN=8N=8N=8N=8N=325

Figure 3. A complex convolutional neural network (CNN), referred to as the CNN-2, used for the classiﬁcation of line-of-sight
magnetograms of ﬂaring and nonﬂaring active regions (ARs). The CNN-2 comprises two layers of 2D convolutional ﬁlters of
sizes 7 × 7 and 3 × 3 respectively, followed by two inception modules (Figure 2). The two convolutional layers and the ﬁrst
inception module are followed by a 3 × 3 max-pooling layer each for downsampling. The ﬁnal inception module is followed by
a global-average-pooling layer that outputs the average value from the input. The output of the global-average-pooling layer is
connected to the ﬁnal-output neuron.

the positive class.

Since the number of nonﬂaring ARs is approximately
5 times larger than the number of ﬂaring ARs, the
classiﬁcation problem considered here is class imbal-
anced. Therefore, we use performance measures that
reliably capture the classiﬁcation performance of the
minority class i.e.
(Bobra & Cou-
vidat 2015). Recall measures the fraction of accurately
classiﬁed samples for a particular class. For the posi-
tive class (ﬂaring ARs), recall = T P/ (T P + F N ). A
CNN optimized for yielding high recall may exhibit a
tendency to classify samples as positive. A better mea-
sure therefore is True Skill Statistics (TSS). TSS is cal-
culated by subtracting the false positive rate from recall
i.e. T SS = T P/ (T P + F N ) − F P/ (T N + F P ). The
value of TSS is 1 for the perfect classiﬁcation and 0 for
completely random classiﬁcation. We use recall and TSS
to measure the CNN classiﬁcation performance.

4. RESULTS AND DISCUSSION

4.1. Training

CNNs typically require input images to be of identi-
cal sizes. The line-of-sight magnetograms of ﬂaring and
nonﬂaring ARs used here are, however, varying signiﬁ-
cantly in size according to AR area . Following Huang
et al. (2018), we resize the AR magnetograms to a ﬁxed
size using bi-cubic interpolation. Resizing the magne-
tograms in this manner yields training images with dif-
ferent spatial resolution depending on the AR area (see
Figure 8). AR area is known to be a leading factor re-
lated to ﬂaring activity (Bobra & Couvidat 2015; Dhuri
et al. 2019). Resizing the images may, therefore, lead to
loss of important information about AR area, resulting
in sub-optimal CNN classiﬁcation. Also, convolutional
kernels in the CNN are designed to learn spatial features
of diﬀerent length scales from magnetograms, which are
important for the classiﬁcation. The inconsistent spatial

resolution of training images hinders CNN kernels from
accurately identifying length scales of spatial features
correlated with the ﬂaring activity. Keeping in mind
these possible drawbacks, we proceed with using resized
magnetograms for the CNN classiﬁcation and later in-
vestigate in detail the eﬀect of resizing on CNN perfor-
mance using synthetic magnetograms (see Section 4.4).
We use supervised learning to train CNNs with non-
ﬂaring and ﬂaring magnetograms as inputs and labels 0
and 1 respectively as outputs. As per Table 1, we use
ARs between May 2010 - Sep 2015 for training and vali-
dation of the CNNs. For robust training, we use 10-fold
cross-validation as follows. We randomly split the ﬂar-
ing and nonﬂaring ARs each into three parts and use
line-of-sight magnetograms from two parts for training
and the remaining part for validation. This process is
performed 10 times. Note that all magnetograms of an
AR are part of either training or validation set. Also,
each ﬂaring and nonﬂaring AR is sampled ∼ 3.3 times
on average for the 10-fold cross-validation. After every
training, we measure recall and TSS for the validation
ARs. We tune the hyperparameters — learning rate lr
and minibatch size NBS — to optimize the mean value of
TSS over the 10 cross-validation runs. We use Python’s
deep learning library keras (Chollet et al. 2015) to set
up and train the CNNs (see Appendix A for details).

Since both CNN-1 and CNN-2 require ﬁxed-size in-
puts, we use magnetograms resized to 128 × 128-pixels
for training. From Table 2, we see that CNN-2 yields
∼ 10% higher TSS at 0.45 ± 0.07 than CNN-1. By in-
creasing the size of the resized magnetograms to 256 ×
256-pixels, TSS for the classiﬁcation of ﬂaring and non-
ﬂaring ARs increases to 0.51 ± 0.06. TSS may be in-
creased further by further increasing the size of the re-
sized magnetograms. However, to limit the computa-
tional expense, we restrict the analysis to resized AR

Inception layerInception layerConv2D ﬁlter = (7,7) stride = (2,2)AvgPoolingOutputConv2D ﬁlter = (3,3) stride = (1,1)MaxPooling pool_size = (3,3) stride = (2,2)MaxPooling pool_size = (3,3) stride = (2,2)MaxPooling pool_size = (3,3) stride = (2,2)InputGlobalN=8N=8N=16N=16N=32N=32N=32N=326

# Flaring AR images
# Nonﬂaring AR images
Flaring ARs recall
Nonﬂaring ARs recall
TSS

CNN-1

CNN-2

10915
44592

0.78 ± 0.06
0.55 ± 0.04
0.33 ± 0.07

0.67 ± 0.06
0.78 ± 0.02
0.45 ± 0.07

Table 2. 10-fold cross-validation performance of CNN-1
(Figure 1) and CNN-2 (Figure 3) applied to classify ﬂaring
and nonﬂaring ARs. The AR line-of-sight magnetograms
are resized to 128 × 128-pixels as input to the CNNs. CNN-2
outperforms the baseline model CNN-1 in terms of the True
Skill Statistics (TSS) score. 1σ error bars are determined
using 10-fold cross-validation.

Resized image size
Flaring ARs recall
Nonﬂaring ARs recall
TSS

128 × 128 256 × 256
0.71 ± 0.08
0.67 ± 0.06
0.80 ± 0.04
0.78 ± 0.02
0.51 ± 0.06
0.45 ± 0.07

Table 3. 10-fold cross-validation performance of CNN-2
(Figure 3) for the classiﬁcation of ﬂaring and nonﬂaring AR
line-of-sight magnetograms resized to sizes 128 × 128-pixels
and 256 × 256-pixels. Resizing to 256 × 256-pixels yields a
higher TSS score compared to 128×128-pixels. 1σ error bars
are obtained using 10-fold cross-validation.

magnetograms of 256 × 256-pixels. Since the CNN-2 10-
fold cross-validation performance is signiﬁcantly higher
than that of CNN-1, we use only CNN-2 for the sub-
sequent analysis. CNN-2 yields ﬂaring AR recall of
0.63 ± 0.06, nonﬂaring AR recall of 0.89 ± 0.03 and clas-
siﬁcation TSS of 0.52 ± 0.04 on test data comprising
ARs between Oct 2015 - August 2018. Note that, be-
cause of more severe class imbalance in the test data,
the trained CNN performs better in classifying nonﬂar-
ing ARs and worse in classifying ﬂaring ARs, as ex-
pected. The classiﬁcation TSS, however, is comparable
with cross-validation results.

4.2. Machine correlation between line-of-sight

magnetograms and ﬂaring activity

The trained CNN-2, henceforth referred to as the
CNN, classiﬁes between the line-of-sight magnetograms
of ﬂaring and nonﬂaring ARs with TSS of ∼ 50%. Note
that the classiﬁcation TSS is indicative of the success in
identifying a magnetogram from ﬂaring ARs irrespec-
tive of the observation time relative to ﬂare. We ex-
pect that the CNN identiﬁcation is better for magne-
tograms which are observed a few hours before ﬂares
compared to those that are observed well away from the
ﬂare event (Figure 4). Thus, we expect that the popu-
lation fraction of accurately identiﬁed line-of-sight mag-

netograms increases as ﬂare time approaches. A mea-
sure of the instantaneous population fraction of accu-
rately identiﬁed magnetograms from ﬂaring ARs is the
recall or identiﬁcation rate calculated as recall(tr) =
T P (tr)/ (T P (tr) + F N (tr)), where tr is time relative
to M- or X-class ﬂares. The instantaneous recall or
identiﬁcation rate can be interpreted as a correlation
of line-of-sight magnetograms with ﬂaring activity cal-
culated using the CNN. Time evolution of the instanta-
neous recall is thus indicative of dynamics of the line-
of-sight magnetic ﬁelds before and after ﬂares. To cal-
culate the instantaneous recall, we compile time series
of magnetograms from ﬂaring ARs during a window
tr = t − TF ∈ [−72, 72] hours centered around a ﬂare
event TF . If two consecutive ﬂares on an AR are sep-
arated by < 144 hours, we split the observations be-
tween the ﬂare events in two halves and consider the
ﬁrst half as the post-ﬂare category of the ﬁrst ﬂare and
the second half as the pre-ﬂare category of the second
ﬂare. We align all such time series from ﬂaring ARs at
t − TF = tr = 0, the time of ﬂare events. Using all the
aligned time series of magnetograms, we obtain the in-
stantaneous recall for ﬂaring AR magnetograms within
±72 hours of ﬂares.

Left panel of the Figure 5 shows the temporal evolu-
tion of the instantaneous recall of magnetograms from
ﬂaring ARs in validation data from 72 hours before ﬂares
to 72 hours after. We ﬁnd that the instantaneous recall
is > 0.5 for days before and after ﬂares. This suggests
that ﬂaring ARs remain in a ﬂare-productive state for
days before and after ﬂares. The instantaneous recall
peaks at ∼ 0.8, which is consistent with reported results
for ﬂare forecasting (Huang et al. 2018). Dhuri et al.
(2019) obtained the instantaneous recall using a sup-
port vector machine (SVM) trained on the AR averaged
vector-magnetic-ﬁeld features viz. SHARP features (Bo-
bra & Couvidat 2015). The right panel of Figure 5 com-

Figure 4. Schematic time evolution of the population dis-
tribution of line-of-sight magnetogram samples from ﬂar-
ing ARs. As M- or X-class ﬂares approach, the population
fraction of True Positive samples (red) which are accurately
identiﬁed as ﬂaring is expected to increase and the popula-
tion fraction of False Negatives (FNs) which are inaccurately
identiﬁed as nonﬂaring is expected to decrease.

Time to flareIdentified as flaring (TPs)Identified as nonflaring (FNs)7

Figure 5. Left panel: Time evolution of instantaneous identiﬁcation rate or instantaneous recall(tr) = T P (tr)/(T P (tr) +
F N (tr)) as predicted by the CNN for the validation data. Here, tr represents time relative to the ﬂare event. The instantaneous
recall is high > 50% for days before and after M- or X-class ﬂares. The instantaneous recall rises from a value of ∼ 50%, 72 hours
before the ﬂares and peaks at ∼ 80%. The shaded area represents 1σ error. Right panel: Comparison of the instantaneous recall
of the CNN (blue) with a Support Vector Machine trained (Dhuri et al. 2019) using AR averaged vector-magnetic-ﬁeld SHARP
features (Bobra et al. 2014) (black) as well as SHARP features that can be reliably interpreted from line-of-sight magnetograms
viz. AR area and the total unsigned ﬂux (red). The SVM trained on full vector-magnetic-ﬁeld SHARP features outperforms the
CNN. The performance of the CNN is comparable to the SVM trained with SHARPs that may be inferred from line-of-sight
magnetograms.

pares the CNN trained on line-of-sight magnetograms
and the SVM trained on AR-averaged vector-magnetic-
ﬁeld features. We ﬁnd that the peak SVM instanta-
neous recall is ∼ 10% higher than the CNN trained on
line-of-sight magnetograms. Also, the SVM trained us-
ing AR-averaged features that may be inferred from the
line-of-sight magnetograms — namely AR area and to-
tal unsigned ﬂux — shows performance approximately
the same as the CNN. This suggests that the CNN out-
put largely depends on the AR area and total unsigned
magnetic ﬂux.

4.3. Statistical analysis of the CNN output

From the instantaneous recall in Figure 5, the CNN
output seems to primarily depend upon the total un-
signed magnetic ﬂux of ﬂaring and nonﬂaring ARs.
Therefore, we perform statistical analysis of the total un-
signed line-of-sight magnetic ﬂux of ﬂaring and nonﬂar-
ing magnetograms categorized according to CNN out-
put. Flaring and nonﬂaring magnetograms are binned
into ten buckets based on the associated CNN output as
shown in Figure 6. The left panel of Figure 6 shows the
number of magnetograms categorized according to the
bins of the CNN output. Note that magnetograms for
which the CNN output y ≥ 0.5 are identiﬁed as ﬂaring
and y < 0.5 are identiﬁed as nonﬂaring. We see that,
for a signiﬁcant number of nonﬂaring ARs, the CNN
output y ∼ 0.0 and for a signiﬁcant number of ﬂaring
ARs, y ∼ 1.0. The right panel of Figure 6 displays the

average value of total unsigned line-of-sight magnetic
ﬂux for ﬂaring and nonﬂaring magnetograms from each
bin of the CNN output. The average value of the to-
tal unsigned line-of-sight magnetic ﬂux systematically
increases for both ﬂaring as well as nonﬂaring AR mag-
netograms as a function of the CNN output. Thus, the
CNN output is highly correlated with the total unsigned
line-of-sight magnetic ﬂux.

4.4. Probing the CNN using synthetic magnetograms

We use synthetic magnetograms to further interpret
the performance of the CNN. Synthetic bipoles of circu-
lar shape with a uniform ﬁeld as shown in Figure 7 are
constructed. We analyse the dependence of the CNN
output on size, ﬁeld strength and ﬁeld conﬁguration of
synthetic bipoles.

The HMI/CEA line-of-sight magnetograms of ARs
vary in sizes with a ﬁxed spatial resolution of 0.03◦/pixel.
For training, all magnetograms are resized to 256 × 256-
pixels. Resizing yields training magnetogram images
with varying spatial resolution. Top and bottom panels
in Figure 8 show variation of the x- and y-spatial reso-
lutions respectively of the resized images. The number
of samples for ﬂaring ARs is adjusted as per the higher
penalty of misclassiﬁcation levied to counter the class
imbalance (see Appendix A). The mean x-resolution of
the resized images is 0.11◦/pixel and the distribution
may be approximated by a wide (∼ 0.10◦/pixel) skewed
Gaussian. The mean y-resolution is 0.05◦/pixel and

7260483624120122436486072 pre-flare hours                post-flare hours 0.00.10.20.30.40.50.60.70.80.91.0Identification Rate [Recall (t)]-72-60-48-36-24-120122436486072 pre-flare hours          post-flare hours 0.00.10.20.30.40.50.60.70.80.91.0Identification Rate [Recall(t)]Avg. AR vector-magnetic-field featuresAvg. AR LOS-magnetic-field featuresline-of-sight magnetograms8

Figure 6. Statistical analysis of the total unsigned line-of-sight magnetic ﬂux of ﬂaring and nonﬂaring ARs. The ﬂaring and
nonﬂaring line-of-sight magnetograms are categorized in bins depending on the corresponding CNN output. These bins are
centered at y = {0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95} and bounded by y ± ∆/2 where ∆ = 0.1. Left panel: the
histogram of ﬂaring and nonﬂaring samples binned by the CNN output. For a signiﬁcant majority of nonﬂaring AR samples,
the CNN output y < 0.5 and for a signiﬁcant majority of ﬂaring AR samples y > 0.5. Right panel: The average unsigned
line-of-sight magnetic ﬂux calculated for ﬂaring and nonﬂaring magnetograms from each bin of the CNN output. The average
unsigned line-of-sight magnetic ﬂux for both ﬂaring and nonﬂaring samples increases as the CNN output increases. 5σ error
bars are shown.

tom right). For a synthetic bipole of −+ conﬁgura-
tion with uniform ﬁeld of 2000 G on a magnetograms
with x − res. = 0.09◦/pixel and y − res. = 0.05◦/pixel

the distribution may be approximated by a narrower
(∼ 0.04◦/pixel) Gaussian. We probe the trained CNN
using synthetic bipole magnetograms with x-resolution
of 0.09◦/pixel and y-resolution of 0.05◦/pixel (768×427-
pixels), as a representative of the training data. These
results are presented in Figure 9.

The CNN output depends on the size of the synthetic
bipoles and shows low and high peaks (top left). The
value of the CNN output depends on magnetic ﬁeld
strength. The CNN output saturates for strong mag-
netic ﬁelds > 3000 G (top right). The CNN output also
depends on the conﬁguration of the synthetic bipole,
favouring the conﬁguration with −+ ﬁeld over +− ﬁeld
(bottom left). For a circular magnetic region with uni-
form + or − polarity, the CNN output is lower than
that for the synthetic bipole with −+ conﬁguration (bot-

Figure 7. A 23◦ × 12.8◦ magnetogram (728 × 427-pixels)
of a synthetic bipole with uniform ﬁeld used for probing
the CNN. The synthetic bipole has −+ conﬁguration (in-
dicated by black and white respectively) and the magnetic
ﬁeld strength is 2000 G.

Figure 8. Distributions of x-resolution (top) and y-
resolution (bottom) of the HMI/CEA magnetograms resized
to 256 × 256-pixel images for training the CNN. The x-
resolution distribution may be approximated by a Gaussian
of width 0.10◦/pixel with mean at 0.09◦/pixel and the y-
resolution may be approximated by a Gaussian of width
0.04◦/pixel with mean at 0.05◦/pixel. Note that as dimen-
sions of the original magnetograms increase, the resolution of
the resized images decreases which corresponds to increasing
◦/pixel.

0.00.10.20.30.40.50.60.70.80.91.0CNN Output010203040# (×103)Flaring ARsNonflaring ARs0.00.10.20.30.40.50.60.70.80.91.0CNN Output12345Magnetic Flux ×1023 (Mx)Flaring ARsNonflaring ARs-9°-6°-3°0°3°6°9°-5°-2.5°0°2.5°5°0.000.100.200.300.40x-resolution (°/pixel)030006000900012000#0.09all dataflaring ARsnonflaring ARs0.000.100.200.300.40y-resolution (°/pixel)05000100001500020000#0.05all dataflaring ARsnonflaring ARs9

Figure 9. Probing the trained CNN with synthetic bipoles on 768 × 427-pixel magnetograms which yield resized images with
x − res. = 0.09◦/pixel and y − res. = 0.05◦/pixel. Top left: Variation of the CNN output with the radius of the −+ synthetic
bipole for uniform ﬁeld strengths of 1000 G, 2000 G, and 3000 G. CNN output curves show a low peak at ∼ 3.5 Mm and a high
peak at ∼ 12.5 Mm. The output increases with ﬁeld strength and falls rapidly as the radius of the synthetic bipole increases
beyond ∼ 20 Mm. Top right: Variation of CNN output as a function of ﬁeld strength for a −+ conﬁguration synthetic bipole
of radius ∼ 12.5 Mm. The output increases with increasing ﬁeld strength and asymptotically approaches 1 for ﬁelds > 3000 G.
Bottom left: Dependence of CNN output on the conﬁguration of the synthetic bipole — +− conﬁguration and −+ conﬁguration
— with a uniform ﬁeld of 2000 G. The CNN output is higher for a −+ conﬁguration bipole than the +− conﬁguration bipole of
the same size. Bottom right: Variation of CNN output with size for a circular magnetic region of the uniform ﬁeld of 2000 G.
The output for a magnetic region with uniform negative (−) ﬁeld is higher than the magnetic region of the same size with
uniform positive (+) ﬁeld.

(768 × 427-pixels), a low peak of ∼ 0.5 CNN output oc-
curs at ∼ 3.5 Mm radius and a high peak of ∼ 0.8 CNN
output occurs at ∼ 12.5 Mm radius. Overall, the CNN
output increases with increasing magnetic ﬁeld strength
and up to a certain length scale, increases with increas-
ing size of the bipole, corroborating the dependence of
CNN output on the total unsigned line-of-sight magnetic
ﬂux of ARs.

Since the resolution of magnetogram images in the
training data shows a signiﬁcant variation (Figure 8),
we explicitly study the dependence of the CNN out-
put on resizing by comparing the CNN performance for
synthetic bipole magnetograms with diﬀerent x- and y-
resolutions (Figure 10). We ﬁnd that length-scales at
which low and high peaks occur in the CNN outputs
depend on the resolution of the resized images and in
turn the magnetogram dimensions.
In particular, the
position of the high peak is sensitive to x-resolution of
the resized magnetograms (left) and the position of the
low peak is sensitive to y-resolution of the resized mag-
netograms (center). The length-scale of bipole at which

low and high peaks occur increases with decreasing y-
and x-resolutions respectively. Therefore, the CNN out-
put for a synthetic bipole of a given radius is diﬀerent
depending on magnetogram dimensions, which is an ar-
tifact. We also ﬁnd that the ratio of length-scales corre-
sponding to high and low peaks is strongly correlated to
the aspect ratio (x-dimension/y-dimension) of the mag-
netograms (right). Thus, the CNN learns to infer the
resolution of the input magnetograms. The resolution
of input images here is correlated with ﬂaring activity.
Low resolution implies high original dimension of the
magnetogram, which corresponds to a large AR which
is more likely to ﬂare (Bobra & Couvidat 2015; Dhuri
et al. 2019).

We ﬁnd that the asymmetry of the CNN output with
respect to the polarity of magnetic ﬁelds is a conse-
quence of the asymmetry in the number of training
samples from ARs in the northern and southern hemi-
spheres. It is known that ARs in a hemisphere have a
preferred positive/negative leading polarity as per Hale’s
polarity law and Joy’s law. By reversing the polar-

0.05.010.015.020.025.030.035.040.0Synthetic Bipole Radius (Mm)0.00.20.40.60.81.0CNN Output1000 G2000 G3000 G010002000300040005000Synthetic Bipole Magnetic Field (G)0.00.20.40.60.81.0CNN Output0.05.010.015.020.025.030.035.040.0Synthetic Bipole Radius (Mm)0.00.20.40.60.81.0CNN Output+ Bipole+ Bipole0.05.010.015.020.025.030.035.040.0Synthetic Bipole Radius (Mm)0.00.20.40.60.81.0CNN OutputUniform + FieldUniform  Field10

Figure 10. Dependence of the CNN output on the magnetogram dimensions. Left: The CNN output variation with
the radius of the synthetic bipole with −+ conﬁguration for magnetograms which yield resized images of x − res. =
0.05◦/pixel, 0.09◦/pixel, and 0.13◦/pixel with ﬁxed y − res. = 0.05◦/pixel. The length-scale corresponding to high peak
increases as the x-resolution decreases. Center: The CNN output variation with the radius of the synthetic bipole with −+
conﬁguration for magnetograms which yield resized images of y − res. = 0.03◦/pixel, 0.05◦/pixel, and 0.07◦/pixel with ﬁxed
x − res. = 0.09◦/pixel. The length-scale corresponding to low peak increases as the y-resolution decreases. Right: Correlation
between the ratio of length-scales corresponding to high and low peaks with the aspect ratio (x-dimension/y-dimension) of the
magnetograms. The ratio of the length-scales at high and low peaks is approximately two times the aspect ratio.

netograms in the southern hemispheres modiﬁed to ac-
count for Hale’s polarity law and Joy’s law. To account
for Hale’s polarity law, we reversed the polarity of all
magnetograms in the southern hemisphere. To account
for Joy’s law, we ﬂipped all magnetograms in the south-
ern hemisphere about the horizontal axis. Even after
retraining in this manner, we obtained identical cross-
validation TSS ∼ 50%.

Thus, the trained CNN output is very sensitive to the
resolution of the training images as well as the leading
polarity bias. Because these factors diﬀer signiﬁcantly
across diﬀerent cross-validation sets, the CNN output
for diﬀerent cross-validation models also yields a large
variation (∼ 0.4), as shown in the bottom panel of Figure
11.

4.5. Occlusion maps

We generate visualisations of the CNN using tools
available for qualitative interpretation of CNNs (Si-
monyan et al. 2013; Selvaraju et al. 2017). We use
occlusion maps, which are obtained by systematically
noting changes in the CNN classiﬁcation label when dif-
ferent patches from the input magnetograms are masked
(Zeiler & Fergus 2014). A 100 × 100-pixel mask is ap-
plied to generate occlusion maps from the resized mag-
netograms. The mask size is chosen such that the resul-
tant change in CNN output adequately captures CNN
sensitivity. For a given resized magnetogram input, the
occlusion map is initialised as a 256 × 256 array with a
uniform value of the predicted class label Y pred = 1 or 0.
A 100 × 100-pixel region from the resized magnetogram
is masked i.e. all these pixel values are set to 0. We
obtain a new predicted label Y mask. From the occlusion
map, the values at the corresponding pixels are set to

Figure 11. Top: Dependence of the CNN output on the
conﬁguration of the synthetic bipole — +− conﬁguration
and −+ conﬁguration — with a uniform ﬁeld of 2000 G af-
ter reversing the training magnetograms’ polarity. Bottom:
The variation of the mean CNN output of 10-cross-validation
models with the size of the synthetic bipole of −+ conﬁgu-
ration and a uniform ﬁeld of 2000 G. 1σ standard error is
shown.

ity of the magnetograms and retraining the CNN, we
ﬁnd that the CNN output curve corresponding to the
+− and −+ conﬁguration also reverses (Figure 11 top
panel). The number of training samples from the south-
ern hemisphere are 25% more than those from the north-
ern hemispheres. We also retrained the CNN with mag-

0.05.010.015.020.025.030.035.040.0Synthetic Bipole Radius (Mm)0.00.20.40.60.81.0CNN Outputy-Res.=0.05°/pixelx-Res.=0.05°/pixel0.09°/pixel0.13°/pixel0.05.010.015.020.025.030.035.040.0Synthetic Bipole Radius (Mm)0.00.20.40.60.81.0CNN Outputx-Res.=0.09°/pixely-Res.=0.03°/pixel0.05°/pixel0.07°/pixel012345678910Aspect Ratio × 2012345678910Peak Length-Scales Ratio0510152025303540Synthetic Bipole Radius (Mm)0.00.20.40.60.81.0CNN Output+ Bipole+ Bipole0510152025303540Synthetic Bipole Radius (Mm)0.00.20.40.60.81.0CNN Output11

Figure 12. Visual explanations from the CNN using occlusion maps (Zeiler & Fergus 2014) obtained by noting the change in
the CNN output by systematically masking patches in the input line-of-sight magnetograms. Occlusion maps for ﬂaring active
regions (ARs) are shown. The area in red shows the part of the magnetogram where relative occlusion sensitivity is > 0.9,
i.e., regions to which the CNN output is most sensitive. For clarity in displaying the image here, magnetic ﬁelds are saturated
at +500 G (white) and −500 G (black). In all magnetograms, the occlusion-map region highlights area between the opposite
polarities (Schrijver 2007) irrespective of the separation distance between them.

NOAA 11718 2013-04-08 07:12 UTNOAA 11946 2014-01-05 06:00 UTNOAA 12011 2014-03-19 10:36 UTNOAA 12381 2015-07-10 05:00 UTNOAA 12017 2014-03-26 07:24 UTNOAA 12036 2014-04-14 19:36 UT12

Y pred − Y mask. The process is repeated by sliding the
mask by one pixel at a time such that all pixels from the
input resized magnetograms are masked at least once.
We also count the number of times each pixel from the
resized magnetogram is masked. The net occlusion map
is obtained by calculating the average value at each pixel
on dividing by the counts for that pixel. The occlusion
map is resized to the size of the original magnetogram
using bi-cubic interpolation and normalised by the ab-
solute maximum value.

Figure 12 shows occlusion maps for various ﬂaring
ARs. For each AR, the region with occlusion sensitivity
> 0.9, i.e., after normalisation, is shown in red. Note
that the positive value of the occlusion sensitivity in-
dicates that these regions are important for classifying
regions as ﬂaring, i.e., these regions correlate with the
ﬂaring activity. For all ARs, these regions lie between
between polarities of the positive and negative magnetic
ﬁelds, in the vicinity of the polarity inversion zone. This
is consistent with the known nature of ﬂux near po-
larity inversion line being highly correlated with ﬂaring
activity (Schrijver 2007; Huang et al. 2018). Further in-
vestigation into the morphology of regions highlighted
through the occlusion maps is worthwhile. However, it
is required that systematic factors artiﬁcially aﬀecting
the CNN output, as described in the previous section,
are eliminated before such an exercise is performed.

4.6. Comparison with other ﬂare forecasting studies

Many studies in the recent past have pursued the use
of deep learning algorithms such as CNNs for ﬂare fore-
casting. Although our work does not explicitly concern
itself with ﬂare forecasting, we analyse the output of
the trained CNN for a given forward-looking time to
infer the ﬂare forecasting performance. In Table 4, we
compare recall and TSS obtained by considering magne-
togram samples 24 h before M- and X-class ﬂares with
other studies using a roughly similar approach (but dif-
ferent training and test datasets). We ﬁnd that recall
and TSS values in our study are comparable to the top-
performing models. From the works reported in Table 4,
Nishizuka et al. (2018) yield the best classiﬁcation TSS
of ∼ 80%. They follow a slightly diﬀerent approach than
ours, using features extracted from AR magnetograms
(as well as coronal images), rather than directly training
the neural network on AR magnetograms. Other works
mentioned in Table 4 take a similar approach and also
yield broadly similar results. Therefore, our ﬁndings of
the operation of the trained CNN and artifacts that arise
as a result of resizing the images are likely applicable to
these studies as well.

5. SUMMARY

We have successfully trained CNNs to distinguish be-
tween SDO/HMI line-of-sight magnetograms of ﬂaring
and nonﬂaring ARs. We trained two CNNs — a baseline
model with a simple architecture, CNN-1 (Figure 1) and
a complex model with inception modules, CNN-2 (Fig-
ure 3). We ﬁnd that CNN-2 performs signiﬁcantly bet-
ter than CNN-1, yielding 10-fold cross-validation TSS
of ∼ 50%. We also calculated instantaneous recall of
ﬂaring ARs between ±72 hours of M- and X-class ﬂares.
We ﬁnd that the recall for ﬂaring ARs peaks at ∼ 80%,
which is consistent with reported results for forecasting
ﬂares using CNNs trained on line-of-sight magnetograms
(Huang et al. 2018). The peak recall value obtained us-
ing an SVM trained on vector-magnetic-ﬁeld features
averaged over ARs is ∼ 10% higher (Dhuri et al. 2019).
Also, an SVM trained with AR features that may be
reliably inferred from line-of-sight magnetograms gives
results similar to the CNN. Thus, the trained CNN is
mainly looking at the global (extensive) features of the
ARs, such as AR area and total magnetic ﬂux, for the
classiﬁcation. The instantaneous recall may be inter-
preted as a correlation between the line-of-sight mag-
netic ﬁeld and ﬂaring activity. Consistent with Dhuri
et al. (2019), the instantaneous recall for the CNN, de-
termined primarily by the extensive features, stays high,
> 50%, for days before and after ﬂares. Analysed for
forecasting ≥ M-class ﬂares 24 h prior, the CNN yields
a recall of ∼ 90% and a TSS of ∼ 70%, which is also
comparable to the reported results using CNNs.

We performed a statistical analysis of total unsigned
line-of-sight ﬂux of ﬂaring and nonﬂaring AR magne-
tograms binned by CNN output. We ﬁnd that the av-
erage value of total unsigned line-of-sight ﬂux increases
as CNN output increases. This suggests that the total
unsigned line-of-sight ﬂux — an extensive AR feature —
strongly dictates the CNN performance. Using synthetic
magnetograms, we ﬁnd that the CNN output shows low
and high peaks at two diﬀerent length scales of synthetic
bipoles. We show that synthetic bipole length scales cor-
responding to the low and high peaks are a characteristic
of y- and x-resolutions respectively of the resized input
magnetograms. We also obtained visualisations from the
CNN using occlusion maps (Zeiler & Fergus 2014). The
occlusion maps show the region in the magnetograms
to which the CNN output is most sensitive. We ﬁnd
that this region lies between opposite polarities of ARs,
irrespective of how far the polarities are spatially sepa-
rated. This is consistent with earlier studies that show
the ﬂux near the polarity inversion line as being strongly
correlated with ﬂaring activity (Schrijver 2007).

A detailed analysis of the morphology of regions high-
lighted by occlusion maps may shed light on the role of

13

Huang et al. (2018)

Test Dataset

2010 − 2015

Nishizuka et al. (2018)

2015

Zheng et al. (2019)

Li et al. (2020)

This work (CNN-2)

2010 − 2018
Cross-validation
2010 − 2018
Cross-validation
2010 - 2015
Cross-validation

Machine Inputs

AR magnetogram patches
Features extracted from
magnetogram and coronal
images

Recall

0.85

0.95

TSS

0.66

0.80

AR magnetogram patches

0.82 ± 0.08

0.75 ± 0.08

AR magnetogram patches

0.82 ± 0.08

0.75 ± 0.08

AR magnetogram patches

0.92 ± 0.05

0.72 ± 0.04

This work (CNN-2)

2015 - 2018

AR magnetogram patches

0.86 ± 0.01

0.72 ± 0.01

Table 4. Comparison with the ﬂare forecasting (≥ M-class) performance of the trained CNN, 24 h prior, with recently reported
works using deep learning. The trained CNN yields a ﬂaring class recall of ∼ 90% and a TSS of ∼ 70% which is comparable to
the other works.

the polarity inversion zone in triggering ﬂares. We ﬁnd,
however, using synthetic magnetograms, that the CNN
output depends on spurious factors such as the mag-
netogram dimensions (for same-sized magnetic regions).
This is a direct consequence of the resizing operation
used to prepare AR magnetograms in identical sizes as
an input to the CNN. We also ﬁnd that the CNN out-
put is asymmetric with respect to the polarity of the
magnetic ﬁeld which is due to the asymmetry in the
number of training samples of ARs from the northern
and southern hemisphere. A CNN design that elimi-
nates these systematic eﬀects has the potential to reveal
new morphological characteristics of ﬂaring ARs.
In-
cluding additional inputs to the CNN, such as coronal
and chromospheric imagery, will also improve the CNN
characterisation of local AR features for understanding

and forecasting ﬂares.
Insights from this study about
the operation of the CNN for AR magnetograms will be
useful for future applications that include more compre-
hensive AR information for reliable ﬂare forecasting.

D.B.D and S.M.H designed the research. S.B, R.A.,
and D.B.D. performed the data analysis. D.B.D and
S.M.H. contributed to the interpretation of the results.
D.B.D. wrote the manuscript with contributions from
all authors.

S.M.H acknowledges funding support from the Max-
Planck partner group program. HMI data used here
are courtesy of NASA/SDO and the HMI science team.
We thank the anonymous reviewer for their comments
and suggestions which helped improve the analysis and
presentation of the paper.

REFERENCES

Ahmed, O. W., Qahwaji, R., Colak, T., et al. 2013, Solar

Crown, M. D. 2012, Space Weather, 10,

Physics, 283, 157.
https://doi.org/10.1007/s11207-011-9896-1

Barnes, G., Leka, K. D., Schrijver, C. J., et al. 2016, The

Astrophysical Journal, 829, 89.
http://stacks.iop.org/0004-637X/829/i=2/a=89

Bobra, M. G., & Couvidat, S. 2015, The Astrophysical

Journal, 798, 135.
http://stacks.iop.org/0004-637X/798/i=2/a=135

doi:10.1029/2011SW000760.

https://doi.org/10.1029/2011SW000760

Dhuri, D. B., Hanasoge, S. M., & Cheung, M. C. M. 2019,

Proceedings of the National Academy of Sciences, 116,

11141

Eastwood, J. P., Biﬃs, E., Hapgood, M. A., et al. 2017,

Risk Analysis, 37, 206.

Bobra, M. G., Sun, X., Hoeksema, J. T., et al. 2014, Solar

http://dx.doi.org/10.1111/risa.12765

Physics, 289, 3549.
https://doi.org/10.1007/s11207-014-0529-3

Cheung, M. C. M., & Isobe, H. 2014, Living Reviews in

Solar Physics, 11, 3.
https://doi.org/10.12942/lrsp-2014-3

Goodfellow, I., Bengio, Y., & Courville, A. 2016, Deep

Learning (The MIT Press)

Hastie, T., Tibshirani, R., & Friedman, J. 2001, The

Elements of Statistical Learning, Springer Series in

Chollet, F., et al. 2015, Keras, https://keras.io, ,

Statistics (New York, NY, USA: Springer New York Inc.)

14

Hoeksema, J. T., Liu, Y., Hayashi, K., et al. 2014, Solar

Pesnell, W. D., Thompson, B. J., & Chamberlin, P. C.

Physics, 289, 3483.
https://doi.org/10.1007/s11207-014-0516-8
Huang, X., Wang, H., Xu, L., et al. 2018, The

Astrophysical Journal, 856, 7.
http://stacks.iop.org/0004-637X/856/i=1/a=7

Ioﬀe, S., & Szegedy, C. 2015, arXiv preprint

arXiv:1502.03167

Jonas, E., Bobra, M., Shankar, V., Todd Hoeksema, J., &

Recht, B. 2018, Solar Physics, 293, 48.
https://doi.org/10.1007/s11207-018-1258-9

Kontogiannis, I., Georgoulis, M. K., Park, S.-H., & Guerra,

J. A. 2017, Solar Physics, 292, 159.
https://doi.org/10.1007/s11207-017-1185-1

Krizhevsky, A., Sutskever, I., & Hinton, G. E. 2012, in
Advances in Neural Information Processing Systems

LeCun, Y., Bengio, Y., & Hinton, G. 2015, Nature, 521, 436

EP . https://doi.org/10.1038/nature14539

Leka, K. D., & Barnes, G. 2007, The Astrophysical Journal,

656, 1173.
http://stacks.iop.org/0004-637X/656/i=2/a=1173
Leka, K. D., Canﬁeld, R. C., McClymont, A. N., & van

Driel-Gesztelyi, L. 1996, The Astrophysical Journal, 462,
547

Li, X., Zheng, Y., Wang, X., & Wang, L. 2020, The

Astrophysical Journal, 891, 10.
https://doi.org/10.3847%2F1538-4357%2Fab6d04
Maas, A. L., Hannun, A. Y., & Ng, A. Y. 2013in , 3
McIntosh, P. S. 1990, Solar Physics, 125, 251.

https://doi.org/10.1007/BF00158405

Nishizuka, N., Sugiura, K., Kubo, Y., Den, M., & Ishii, M.

2018, The Astrophysical Journal, 858, 113.
https://doi.org/10.3847%2F1538-4357%2Faab9a7
Nishizuka, N., Sugiura, K., Kubo, Y., et al. 2017, The

Astrophysical Journal, 835, 156.
http://stacks.iop.org/0004-637X/835/i=2/a=156

Nitta, N. V., & Hudson, H. S. 2001, Geophysical Research

Letters, 28, 3801.
http://dx.doi.org/10.1029/2001GL013261

Park, S.-H., Lee, J., Choe, G. S., et al. 2008, The

Astrophysical Journal, 686, 1397.
http://stacks.iop.org/0004-637X/686/i=2/a=1397

2012, Solar Physics, 275, 3

Raboonik, A., Safari, H., Alipour, N., & Wheatland, M. S.

2017, The Astrophysical Journal, 834, 11.
http://stacks.iop.org/0004-637X/834/i=1/a=11

Rust, D. M., Sakurai, T., Gaizauskas, V., et al. 1994, Solar
Physics, 153, 1. https://doi.org/10.1007/BF00712489

Scherrer, P. H., Schou, J., Bush, R. I., et al. 2012, Solar

Physics, 275, 207.
https://doi.org/10.1007/s11207-011-9834-2

Schrijver, C. J. 2007, The Astrophysical Journal Letters,

655, L117.
http://stacks.iop.org/1538-4357/655/i=2/a=L117

Schrijver, C. J. 2009, Advances in Space Research, 43, 739 .

http://www.sciencedirect.com/science/article/pii/
S0273117708005942

Selvaraju, R. R., Cogswell, M., Das, A., et al. 2017, 2017
IEEE International Conference on Computer Vision
(ICCV), 618

Shibata, K., & Magara, T. 2011, Living Reviews in Solar
Physics, 8, 6. https://doi.org/10.12942/lrsp-2011-6
Simonyan, K., Vedaldi, A., & Zisserman, A. 2013, CoRR,

abs/1312.6034

Simonyan, K., & Zisserman, A. 2014, CoRR, abs/1409.1556
Stein, R. F. 2012, Living Reviews in Solar Physics, 9, 4.

https://doi.org/10.12942/lrsp-2012-4

Su, Y., Veronig, A. M., Holman, G. D., et al. 2013, Nature

Physics, 9, 489 EP .
http://dx.doi.org/10.1038/nphys2675

Szegedy, C., Wei Liu, Yangqing Jia, et al. 2015, in 2015
IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), 1–9

The SunPy Community, Barnes, W. T., Bobra, M. G.,

et al. 2020, The Astrophysical Journal, 890, 68. https:
//iopscience.iop.org/article/10.3847/1538-4357/ab4f7a

Wang, H., & Liu, C. 2015, Research in Astronomy and

Astrophysics, 15, 145.
http://stacks.iop.org/1674-4527/15/i=2/a=001

Zeiler, M., & Fergus, R. 2014in (Springer Verlag), 818–833
Zheng, Y., Li, X., & Wang, X. 2019, The Astrophysical

Journal, 885, 73.
https://doi.org/10.3847%2F1538-4357%2Fab46bd

15

APPENDIX

A. DETAILS OF THE NEURAL NETWORKS

Neural networks consist of layers of neurons. A neuron in each layer processes N-dimensional inputs x according to

the following operation and produces an output y

y = f



wjxj + b

 .





N
(cid:88)

j=1

(A1)

Here the N-dimensional vector w contains weights of the neuron and b is the bias of the neuron. The input to the
ﬁrst layer of neurons is the data. Outputs from a layer of neurons serve as inputs to the next layer. The ﬁnal layer
of neurons provides the output of the neural network. As explained in Section 3, a convolutional neural network
comprises convolutional ﬁlters with M × M neurons that slides over the input image data. Function f in Eq. A1 is the
neuron activation function. Since the magnetograms contains pixels with both positive and negative magnetic ﬁeld,
we use leaky ReLU (rectiﬁed linear unit) activation function (Maas et al. 2013). For CNN-2, we ﬁnd that the identity
activation function,

y =

N
(cid:88)

j=1

wjxj + b,

(A2)

also yields similar results.

The ﬁnal layers of CNN-1 and CNN-2 produce output Y pred which is a number between 0 and 1. We compute a
loss function L(Y, Y pred) to determine the error in the prediction. Weights and biases of all neurons in the CNN are
determined during training using minibatch stochastic gradient descent to minimize the loss L(Y, Y pred) (see Figure
13). Stochastic gradient descent is performed using a minibatch of samples n during each training step. We use the
binary cross-entropy loss function given by (Hastie et al. 2001).

LCE(Y, Y pred) = −

1
n

n
(cid:88)

(cid:104)

i=1

CYi log

(cid:16)

Y pred
i

(cid:17)

+ (1 − Yi) log

(cid:16)

1 − Y pred
i

(cid:17)(cid:105)

.

(A3)

Here, C is the additional penalty for the misclassiﬁcation of positive, i.e., ﬂaring-class magnetograms labelled as 1.
We set the value of C = 4.5 which is approximately equal to the class-imbalance ratio, i.e., the ratio of nonﬂaring to
ﬂaring samples in the data (see Table 1). For the baseline model (CNN-1), we ﬁnd the best performance (noted in
Table 2) with a custom loss function

Lcustom(Y, Y pred) =

1
nﬂ

nfl(cid:88)

i=1

λ(Y ﬂ

i − Y ﬂ,pred

i

)2 +

1
nnﬂ

nnfl(cid:88)

(Y nﬂ

i − Y nﬂ,pred

i

i=1

where

λ = Cbatch exp(HSSbatch) exp(TSSbatch).

)2,

(A4)

(A5)

In the above equation, Cbatch is the class-imbalance ratio for the minibatch used, TSS is the true-skill-statistic (see
Section 3) for the minibatch, and HSS is Heidke Skill Score for the minibatch given by (Bobra & Couvidat 2015)

HSS =

2(T P.T N − F P.F N )
(T P + F N )(F N + T N ) + (T P + F P )(F P + T N )

.

For the present classiﬁcation problem, we threshold Y pred to obtain the predicted class labels as

(cid:40)

Y pred =

1 if Y pred ≥ 0.5,
0 else.

(A6)

(A7)

We use learning rate lr = 5 × 10−6 and a minibatch size of n = 64 for the stochastic gradient descent. We also use

batch normalisation to pre-process inputs to each convolution layer (Ioﬀe & Szegedy 2015).

16

Figure 13. Variation of mean cross-validation training and validation loss with the progression of training epochs for the
CNN-2. The variation is similar for both training and validation indicating no/minimal overﬁtting. 1σ error bars are shown.

01020304050607080epochs0.00.51.01.52.02.53.0binary cross-entropytrainingvalidation