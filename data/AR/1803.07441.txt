Pre-print: Published in Multimedia Tools and Applications, Springer 

LDOP: Local Directional Order Pattern for Robust 
Face Retrieval 

Shiv Ram Dubey and Snehasis Mukherjee 

Computer Vision Group, Indian Institute of Information Technology, Sri City, Chittoor, A.P.-517646, India 

srdubey@iiits.in, snehasis.mukherjee@iiits.in 

Abstract‚Äî The local descriptors have gained wide range of attention due to  their enhanced discriminative abilities. It has been 
proved that the consideration of multi-scale local neighborhood improves the performance of the descriptor, though at the cost 
of increased dimension. This paper proposes a novel method to construct a local descriptor using multi-scale neighborhood by 
finding the local directional order among the intensity values at different scales in a particular direction. Local directional order 
is  the  multi-radius  relationship  factor  in  a  particular  direction.  The  proposed  local  directional  order  pattern  (LDOP)  for  a 
particular  pixel  is  computed  by  finding  the  relationship  between  the  center  pixel  and  local  directional  order  indexes.  It  is 
required to transform the center value into the range of neighboring orders. Finally, the histogram of  LDOP is computed over 
whole image to construct the descriptor. In contrast to the state-of-the-art descriptors, the dimension of the proposed descriptor 
does not depend upon the number of neighbors involved to compute the order; it only depends upon the number of directions. 
The introduced descriptor is evaluated over the image retrieval framework and compared with the state-of-the-art descriptors 
over challenging face databases such as PaSC, LFW, PubFig, FERET, AR, AT&T, and ExtendedYale. The experimental results 
confirm the superiority and robustness of the LDOP descriptor.  

Index Terms‚Äî Local descriptors, Face image, Local ordering, Intensity order, Image retrieval, Robustness, LBP. 

1. INTRODUCTION 
Facial image analysis such as face recognition, face retrieval and facial expression recognition is being widely studied by 
the  researchers  during  the  last  few  decades.  Recently,  face  recognition  techniques  in  the  unconstrained  environment  is 
gaining much interest of the researchers, where either the images are collected from the internet such as ‚ÄïLabeled Faces in 
the Wild‚Äñ [1] and ‚ÄïPublic Figures‚Äñ [2] or, the images are taken from the surveillance cameras and mobile devices [3]. The 
major  problem  with  face  image  analysis  is  the  sensitivity  to  the  image  capturing  environments  such  as  pose  variations, 
scale change, illumination difference, blurring effect,  viewpoint change, and noise [4], [5]. To deal with the face images 
with  these  geometric  and  photometric  challenges,  it  is  required  to  develop  robust  methods  capable  of  handling  adverse 
imaging  conditions.  The  advancement  and  recent  trends  in  the  effective  solution  for  face  image  analysis  have  been 
extensively reviewed by several researchers from time to time [6], [7], [8].  

Any  face  recognition  approach  mainly  has  two  components:  face  description  and  face  matching  using  the  multi-class 
classifiers  such  as  nearest  neighbor  (NN)  classifier  and  sparse  representation  classifier  (SRC)  [9].  The  image  feature 
description has been proved to be the backbone in most of the computer vision problems. An efficient feature descriptor is 
expected  to  have  the  following  three  properties:  a)  distinctive,  b)  robust,  and  c)  low  dimensional.  In  this  paper,  a  local 
directional order pattern (LDOP) based face representation is proposed for face retrieval as illustrated in Fig. 1. First, the 
intensity order among neighbors at different radius in a particular direction is used to get the local directional orders. Then, 
the original image is transformed into the range of local directional orders. After that, the proposed descriptor is computed 
by encoding the relationship  between transformed image and local directional orders.  At last, the  most  similar  faces  are 
retrieved from the database on the basis of the distances between the descriptors of the query image and database images. 

The  rest  of  paper  is  organized  in  following  manner:  Section  2  discusses  the  related  works;  Section  3  introduces  the 
construction process of proposed LDOP descriptor as well as multi resolution LDOP descriptor; Section 4 presents the face 
retrieval framework using multi resolution LDOP descriptor; The experimental analysis over benchmark face databases are 
carried out in Section 5; and finally, Section 6 concludes the paper with motivating remarks about LDOP descriptor. 

This paper is published in Multimedia Tools and Applications, Springer. Cite this article as: S.R. Dubey and S. Mukherjee, 
‚ÄïLDOP:  Local  Directional  Order  Pattern  for  Robust  Face  Retrieval‚Äñ,  Multimedia  Tools  and  Applications,  2019. 
https://doi.org/10.1007/s11042-019-08370-x 

1 

 
 
 
 
 
 
 
 
 
 
 
Pre-print: Published in Multimedia Tools and Applications, Springer 

Fig.1. Face retrieval framework using multi-resolution LDOP descriptor. False positives are enclosed in red rectangles. Images are taken 
from AT&T database [52]. 

2. RELATED WORKS 
Face description is required to make the face recognition approaches robust to intra-class variations and discriminative to 
inter-class similarities. The face image-descriptor based methods [10], [11], [12], [13], and deep learning based methods 
[14], [15], are the two major approaches widely adapted in the research community, for face retrieval. The advantages of 
former  methods  are  data  independence,  ease  of  use,  no  complex  computation  facility  needed  and  robustness  to  real-
situation variations like rotation, scale, expression and illumination differences.  

The  image-descriptor  based  methods  can  be  further  classified  into  two  categories,  i.e.,  hand-crafted  descriptor  and 
learning based descriptor.  The designing of hand-crafted image descriptors are the mostly followed research area for  the 
face representation. The local binary pattern (LBP) is proved as a very efficient and simple feature descriptor to capture the 
micro  information  of  the  image  [16],  [17]. The  LBP based  approaches  have  shown  promising  performance  for  different 
computer vision applications such as texture classification and retrieval [18], [19], [20], [21]. Ahonen et al. investigated the 
suitability  of  LBP  for  the  face  recognition  task  [10].  They  computed  the  LBP  descriptor  over  several  blocks  and 
concatenated  to  form  a  single  descriptor.  This  approach  outperformed  the  classical  methods  such  as  PCA,  Bayesian 
Classifier  and  Elastic  Bunch  Graph  Matching.  Recently,  Huang  et  al.  surveyed  the  LBP  based  approaches  for  face 
recognition [22] and Yang and Chen [23] have presented a comparative study over LBP based face recognition techniques. 
Several local descriptors have been investigated for face recognition inspired by the success of LBP [13], [24], [25], [26], 
[27],  [28],  [29],  [30],  [31],  [32],  [33],  [34].  Zhang  et  al.  modeled  a  Local  Gabor  Binary  Pattern  Histogram  Sequence 
(LGBPHS) by concatenating the histograms of all the local regions of all the local Gabor magnitude binary pattern maps 
for a face image [24]. The LGBPHS consists of histograms at different scale and orientation which make it more effective 
than LBP. The local ternary pattern (LTP) is proposed for illumination robust face recognition by considering ternary value 
against  binary  value  of  LBP  and  shown  promising  performance  [25].  The  LTP  descriptor  is  more  discriminant  and  less 
sensitive to noise in uniform regions. Zhang et al. did a revolutionary work over LBP and considered LBP over high-order 
derivatives of the image to introduce local derivative pattern (LDP) for face representation [26]. The pattern at high-order 
local  derivative  captures  more  detailed  information  as  compared  to  the  first  order  local  pattern.  Weber  local  descriptor 
(WLD)  is  proposed  for  faces  and  texture  recognition  with  inspiration  from  the  Weber‚Äôs  theory  [27].  Local  Gabor  XOR 
pattern  (LGXP)  is  introduced  by  utilizing  the  Gabor  magnitude  and  phase  information  in  the  LBP  framework  [28].  The 
LBP  feature  on  orientated  edge  magnitudes  is  computed  to  form  the  Patterns  of  Oriented  Edge  Magnitudes  (POEM) 
descriptor [29]. Multiscale local phase quantization (MLPQ) is proposed for blur-robust face recognition by encoding the 
blur-invariant  information  in  face  images  [30].  Local  directional  number  pattern  (LDN)  used  the  prominent  direction 
computed  from  Kirsch  masks  to  get  the  pattern  [31].  The  LDN  does  not  utilize  the  wider  neighborhood,  whereas  the 
proposed  approach  does.  The  LDN  requires  the  computation  of  edge  response,  whereas  our  approach  requires  the 

This paper is published in Multimedia Tools and Applications, Springer. Cite this article as: S.R. Dubey and S. Mukherjee, 
‚ÄïLDOP:  Local  Directional  Order  Pattern  for  Robust  Face  Retrieval‚Äñ,  Multimedia  Tools  and  Applications,  2019. 
https://doi.org/10.1007/s11042-019-08370-x 

2 

  Local Directional Orders  Retrieved Faces  Centre Pixel  Transformation ‚â•  Face Database    Query Face    LDOP Maps  
 
 
Pre-print: Published in Multimedia Tools and Applications, Springer 

computation of directional order. Recently, the concept of LDP descriptor is extended by Fan et al. into local vector pattern 
(LVP) for face representation [32]. They encoded the relationship of referenced pixel with neighbouring pixels in different 
directions  at  different  distances  over  high-order  face  image.  The  proposed  Local  Directional  Order  Pattern  (LDOP)  is 
different  from the  Local Vector Pattern (LVP). The proposed LDOP descriptor encodes  the directional ordering pattern, 
whereas the LVP descriptor encodes the relationship between the differences of intensity at different directions. Unlike the 
LDOP  descriptor,  the  LVP  descriptor  works  on  high-order  image  space.  The  only  similarity  between  both  is  that  both 
incorporate  the  directional  information.  The  unique  novelty  of  LDOP  is  that  it  uses  the  intensity  order  along  different 
directions  to  form  the  descriptor.  Basically,  it  encodes  the  relationship  among  the  directional  order  pattern.  The  semi-
structure local binary pattern (SLBP) derived the LBP over locally aggregated image (i.e. the center is replaced by sum of 
intensities  from  its  3√ó3  window)  for  facial  analysis  [33].  Other  notable  descriptors  for  face  recognition  include  local 
directional  gradient  pattern  (LDGP)  [34]  and  dual  cross  patterns  (DCP)  [13].  The  relationships  between  higher  order 
derivatives in four directions are utilized to encode the LDGP [34]. DCP works by computing the two cross patterns with 
different set of neighbors selected from two different radiuses [13]. This work uses the first derivative of Gaussian operator 
(FDG) to convert the face image into multi-directional gradient image which in terns increases the dimension of the final 
descriptor [13]. Arandjelovi has proposed the gradient edge map features for face recognition, where he directly compared 
the feature images instead of forming the descriptor [35]. This method can be used only for the frontal images. 

A harvesting visual concept is used in [56] for image search with complex queries. Researchers have also explored the 
Wavelet-based feature descriptors for different applications such as image retrieval and watermarking [57], [58], [59]. In 
recent  years, several learning-based descriptors using supervised and unsupervised techniques have evolved. Some  well-
known  descriptors  in  this  category  are  Learning-based  (LE)  Descriptor  [11],  Learned  Background  Descriptor  [12], 
AdaBoost Multi-scale Block LBP [36],  Local Quantized Patterns (LQP) [37],  Discriminant Face Descriptor  (DFD) [38], 
and Compact Binary Face Descriptor (CBFD) [39]. The learning-based descriptors are having the wider diversity in terms 
of the larger sampling size as compared to the hand-crafted descriptors. 

There are two  kinds of order based descriptors, one using  LBP framework in  high-order derivative space and another 
using intensity order among  neighboring  values  for local region  matching. Some examples of  former approach are  LDP 
[26]  and  LDGP  [34].  Recently,  the  intensity  order  based  descriptors  have  been  introduced  for  feature  description  and 
applied  mainly  to  the  local  region  matching  [40],  [41],  [42],  [43].  The  Local  Intensity  Order  Pattern  (LIOP)  is  widely 
known  due  its  simplicity  and  robustness  for  region  matching  [41].  Using  intensity  order  as  compared  to  raw  intensity 
values provides the inherent robustness to the descriptor over uniform illumination changes. The LBP descriptor [10] has 
been  successful  in  several  computer  vision  applications.  It  has  been  also  observed  that  the  performance  of  LBP  can  be 
boosted further by considering it at the higher scales at the cost of high dimensionality. The LBP is suitable for capturing 
the  micro  information,  whereas  it  fails  to  capture  the  macro  information  from  the  image  due  to  the  limited  local 
neighbourhood.  Some  LBP  variants  consider  the  multiple  scales  but  do  not  utilize  the  relationship  among  neighbours  at 
different scales which leads to high dimensionality. 

 In this work, we utilize the properties of intensity order over directional neighbors to solve the following two problems: 
to  encode the  wider neighborhood to discriminate  the inter-class similarity and to have the robustness  for the  intra-class 
variations. Next we illustrate the process of constructing the proposed LDOP descriptor. 

Fig.2. The   equally spaced local neighbors (  

 )           at a radius of   from a center pixel (    ). 

This paper is published in Multimedia Tools and Applications, Springer. Cite this article as: S.R. Dubey and S. Mukherjee, 
‚ÄïLDOP:  Local  Directional  Order  Pattern  for  Robust  Face  Retrieval‚Äñ,  Multimedia  Tools  and  Applications,  2019. 
https://doi.org/10.1007/s11042-019-08370-x 

3 

  ùêº ,            2ùúã  ùêº , 1,   ùúÉ ùêº , 2,  ùêº , ùëò,  ùêº ,  ,  ùêº , ùëò‚àí1,  ùêº , ùëò+1,  ùêº , 3,  ùêº ,  ‚àí1,   
 
 
     
 
Pre-print: Published in Multimedia Tools and Applications, Springer 

3. LOCAL DIRECTIONAL ORDER PATTERN 
We describe the proposed LDOP descriptor first, followed by the multi-resolution LDOP descriptor. 

A.  Proposed LDOP Descriptor 

In  this  sub-section,  the  construction  process  of  local  directional  order  pattern  is  described.  First,  we  discuss  the  local 
directional neighborhood extraction, then local directional order computation, then center pixel transformation, and finally 
the construction of local directional order pattern. 

Local Directional Neighbors 

Let  ùêº is an image with dimension          and having a bit-depth of    bits. Let  ùêº    represents the intensity value at co-
    is the intensity value of ùëò   neighbor of 
ordinate (    ), where           ,            and     ùêº      (   ‚àí  ). Let ùêº   
the center pixel (    ) when total   neighbors are considered equally spaced at a radius of    from the center as shown in 
 . The co-ordinates of ùëò   neighbor at 
Fig. 2. Let (  
radius   (i.e.,   

 ) is the co-ordinates of ùêº   
 ) is given as follows, 

   , then we can also say that ùêº   

      ùêº  

  and   

      ‚àí  (   (ùúÉ ))                                                                                               ( ) 
         (   (ùúÉ ))                                                                                               ( ) 
where ùúÉ        is the angular displacement of ùëò   neighbor from     neighbor in counter-clockwise direction, w.r.t. center 
pixel and computed as follows, 

ùúÉ    (ùëò ‚àí  )

 ùúã

                                                                                                  ( ) 

It  is  obvious  that  ùúÉ   represents  the  ùëò    direction  w.r.t.  the  center.  We  refer  the  intensity  value  of       neighbor  (i.e., 
   . We define    directional neighbors of center  (    ) in  ùëò   

neighbor at radius    from the  center) in  ùëò   direction by  ùêº   
. So,       
direction by a vector       

 will consist of the following neighboring values, 

    (ùêº   

     ùêº   

         ùêº   

         ùêº   

   )                                                                                    ( ) 

Local Directional Orders 

In multi-scale descriptors like LVP [32], the relationship among neighbors at different radius is not encoded. In this work, 
we  encode  the  relationship  among  the  local  neighbors  at  different  radius  (i.e.,  distance  from  the  center)  in  a  particular 
direction to encode the directional relationship among neighbors. 

Let       

 is the sorted version of       

 in the increasing order. We represent       

 as follows, 

    (    

   )                                                                                ( ) 

The order in the ùëò   direction is represented by       

 and defined as follows, 

  (    

   )                                                                                ( ) 

such that  

where 

and 

ùêº   

                                                                                                 ( ) 

                     , 

       . 
Now, we are having   distinct values in ùëò   directional order       

to represent the order using a single value.  

 for which we have to compute an index value       

This paper is published in Multimedia Tools and Applications, Springer. Cite this article as: S.R. Dubey and S. Mukherjee, 
‚ÄïLDOP:  Local  Directional  Order  Pattern  for  Robust  Face  Retrieval‚Äñ,  Multimedia  Tools  and  Applications,  2019. 
https://doi.org/10.1007/s11042-019-08370-x 

4 

 
     
    
  
   
 
 
 
      
 
 
 
 
      
         
             
             
 
      
 
         
             
             
          
      
   
    
    
          
 
 
 
 
Pre-print: Published in Multimedia Tools and Applications, Springer 

                                                                            (a)                                                                (b) 
Fig.3. The proposed idea of encoding the relationship among local neighbors at different radius using the order: (a) the local neighbors 
             ) converges to a single value       
                       of a center pixel (    ) and (b) the   neighbors in ùëò   direction (i.e. ùêº   
ùêº   
which actually represents the order among the corresponding neighbors in (a). 

Let     represents  all  the  permutations  of  the     distinct  values  between  1  and     in  lexicographical  fashion.  The  total 
possible  number  of  permutations  with     values  are    .  The               (i.e.,  the       permutation)  is  having  the  following 
values, 

     (  

 )                                                                                  ( ) 

The order index       

 in ùëò   direction with   radius for pixel (    ) is defined as follows, 

                                                                                                     ( ) 

such that 

            . 

This idea is illustrated in Fig. 3, where by encoding the relationship exist among the    neighbors in ùëò   direction (i.e., 
             ) in terms of its order, it converges to a single value       
 which represents the order index for the neighboring 
ùêº   
values in ùëò   direction. The LDOP descriptor inherently become uniform illumination robust, inherently as the directional 
order among the directional neighbors is uniform illumination invariant. Fig. 4(f-h) display the local directional order map 
 )  for                respectively,  computed  over  an  input  example  face  image  depicted  in  Fig.  4(a).  The  eight 
(i.e.,    
columns in Fig. 4(f-h) correspond to local directional order map for 8 directions staring from     with an intervals of     
           )  respectively.  The  range  of  values  in  images  of  Fig.  4(f-h)  are    ‚àí      ‚àí        ‚àí     respectively, 
(i.e.,    
because  the  maximum  possible  order  index  value  is    .  From  the  images  of  Fig.  4(f-h),  it  is  clear  that  local  directional 
orders capture the useful directional information for designing the LDOP descriptor. 

Center Pixel Transformation 

           ) from the local neighborhoods 
As of now, we have computed   local directional order index values (i.e.,       
. Our next 
of the center pixel.  In other words,  the directional relationship among the local neighbors is coded into        
goal is to make a low dimensional descriptor as well as to utilize the relationship of center with its neighbors. At this point, 
 due to the range mismatch. It can be noted that 
it is difficult to compare the center ùêº    with local directional orders       
the range of ùêº    is        ‚àí    for   bit-depth, whereas the range of       
 is        . To resolve this issue, a center pixel 
. Let         is the 
transformation scheme is developed in this paper to transform the range of  ùêº    into the range of        
transformed version of ùêº    when   directional neighbors are used to generate       

. The        is computed as follows, 

Note  that,  this  center  pixel  transformation  scheme  increases  the  tolerance  capability  of  the  descriptor  towards  noise  for 
smaller values of   such as 2, 3 and 4. 

ùêº      (   ‚àí  )
   ‚àí  

                                                                                            (  ) 

This paper is published in Multimedia Tools and Applications, Springer. Cite this article as: S.R. Dubey and S. Mukherjee, 
‚ÄïLDOP:  Local  Directional  Order  Pattern  for  Robust  Face  Retrieval‚Äñ,  Multimedia  Tools  and  Applications,  2019. 
https://doi.org/10.1007/s11042-019-08370-x 

5 

     ùêº , 1,   ùêº , 2,  ùêº , ùëò,  ùêº ,  ,  ùêº , ùëò‚àí1,  ùêº , ùëò+1,  ùêº , 3,  ùêº ,  ‚àí1,                          ùêº , ùëò,1 ùêº , ùëò,2     , , 1    , , 2   , , ùëò   , ,     , , ùëò‚àí1   , , ùëò+1   , , 3   , ,  ‚àí1          
     
         
         
 
      
 
  
        
 
 
 
 
 
 
 
        
 
 
 
 
Pre-print: Published in Multimedia Tools and Applications, Springer 

(a)                  (b)                     (c)                       (d)                      (e) 

(f) 

(g) 

(h) 

Fig.4.  The  illustration  of  the  proposed  concept  using  an  example  image  from  LFW  database  [47]  with  8  local  neighbors:  (a)  Input 
Image, ùêº, (b) LBP map, (c) LDOP map for      , (d) LDOP map for      , (e) LDOP map for      , (f) local directional order maps 
for       in 8 directions 0, 45, 90, 135, 180, 225, 270, and 315 degrees respectively, (g) local directional order maps for       in same 
8 directions respectively, and (h) local directional order maps for       in the same 8 directions respectively. 

LDOP Descriptor 

The        
converted into orders. The local directional order pattern map (     ) for center ùêº   , is defined as follows, 

             and          are  used  to  encode  the  relationship  of  transformed  center  with  its  directional  neighbors 

             ‚àë            

                                                                                     (  ) 

where   is the radius for neighbors and    is a weighting factor for the ùëò   direction and determined as follows, 

and       

 is the binary relationship factor between center and its ùëò   directional neighbors and computed as follows, 

     ( )(   )                                                                                                      (  ) 

    {

‚â•       

                                                                                       (  ) 

The LDOP maps over the input image considered in Fig. 4(a) for             are displayed in Fig. 4(c-e). The LBP map 
over the same image is displayed in Fig. 4(b). It can be observed from the Fig. 4(b-e) that the LBP is encoding too much 
useless  information,  whereas,  LDOP  is  avoiding  useless  information.  Moreover,  it  can  be  noted  that  LDOP  is  capturing 
more  detailed  information  for  lower  value  of     using  narrow  neighborhood  and  capturing  more  corus  information  for 
higher value of R using wider neighborhood. 

This paper is published in Multimedia Tools and Applications, Springer. Cite this article as: S.R. Dubey and S. Mukherjee, 
‚ÄïLDOP:  Local  Directional  Order  Pattern  for  Robust  Face  Retrieval‚Äñ,  Multimedia  Tools  and  Applications,  2019. 
https://doi.org/10.1007/s11042-019-08370-x 

6 

 
 
 
   
 
      
                  
 
                             
 
 
 
 
 
 
 
 
 
Pre-print: Published in Multimedia Tools and Applications, Springer 

Fig.5. Procedure to construct multi-resolution LDOP descriptor (i.e.        ) with              . 

The final      descriptor is the histogram computed over      map (i.e.      ) as follows, 

     ( )  

  ‚àë ‚àë  (             )

                                                               (  ) 

            ‚àí   , where,       represents the      descriptor using radius   neighborhood,   
  , and  (    ) is a function defined as follows, 

       ‚àí   ,   

       ‚àí

 (    )   {

                                                                                    (  ) 

The  dimension  of        descriptor  depends  upon  the  number  of  directions  considered  and  given  by    .  The  eight 

directions are considered in the experiments of this paper, thus the dimension of      is 256. 

B.  Multi Resolution LDOP 

The multi resolution      accumulates the      descriptors at different scales/radius. It actually exhibits the progressive 
effect  of  increasing  the  area  of  local  neighborhood  over  the        descriptor.  We  define  the  multi  resolution 
                            as follows, 

                                                                                                        (  ) 
The  dimension  of  multi  resolution        is  given  by  (   ‚àí       )     .  The  construction  of  multi  resolution       
with 2, 3 and 4 radius of neighborhoods is illustrated in Fig. 5 using the same example image considered in Fig. 4(a). The 
     maps at different radius (i.e.       ,       , and       ) are derived first and then the feature vector using 
histograms  over  each  map  is  concatenated  to  form  the  final        multi  resolution  descriptor,  which  is  used  for  face 
retrieval. 

This paper is published in Multimedia Tools and Applications, Springer. Cite this article as: S.R. Dubey and S. Mukherjee, 
‚ÄïLDOP:  Local  Directional  Order  Pattern  for  Robust  Face  Retrieval‚Äñ,  Multimedia  Tools  and  Applications,  2019. 
https://doi.org/10.1007/s11042-019-08370-x 

7 

                                                                                              
 
 
 
 
  
      
    
     
    
     
                    
                
Pre-print: Published in Multimedia Tools and Applications, Springer 

4. FACE RETRIEVAL USING LDOP  
The framework for face retrieval using the proposed multi resolution LDOP is depicted in Fig. 1. For query image as well 
as database images, LDOP based descriptors are computed. The LDOP descriptor of query face is compared with all the 
faces of the database by finding the distances between them. Based upon the lower distances, top   faces are retrieved from 
the database. In this paper, Chi-square distance is used in most of the experiments, whereas the performance of proposed 
descriptor with other distances like  Euclidean distance, Cosine distance,  L1 distance, and D1 distance is also investigated 
[20], [44]. 

A.  Evaluation Criteria 

In  face  retrieval,  the  ultimate  goal  is  to  retrieve  the  most  similar  faces  against  a  query  face  from  a  face  database.  For 
evaluation purpose, we converted each face image of the database into the query image and retrieved top    faces from the 
database. Note that, the query face image is also present in the database, thus, the first retrieved face is the query face itself. 
The  Precision  and  Recall  metrics  are  used  to  evaluate  the  performance  of  different  descriptors  for  face  retrieval.  The 
average retrieval precision (ARP) and average retrieval rate (ARR) for a given database are defined as follows, 

‚àë   ( )

‚àë   ( )

                                                                                               (  ) 

                                                                                               (  ) 

where     represent  the  total  number  of  classes  in  the  database,    ( )  and    ( )  represent  the  average  precision  and 

average recall respectively over the images of the ith class of the database and given as follows, 

   ( )            

  ( )            

‚àë

  ( )

‚àë

  ( )

                                                                                       (  ) 

                                                                                       (  ) 

where    represent the number of face images in the ith class of the database, Pr and Re represent the precision and recall 

respectively for a query face and defined as follows, 

  (ùëò)     [    ]  

  (ùëò)     [    ]  

                                                                   (  ) 

                                                                (  ) 

where   represent the number of retrieved faces when ùëò   image of     class is considered as the query face. 
We  also  computed  the  F-Score  from  ARP  and  ARR  in  terms  of  the  number  of  top  matching  retrieved  images.  The 
average normalized modified retrieval rank (ANMRR) metric is also computed and represented in percentage in this paper 
[45]. The higher value of ARP, ARR and F-Score means the better retrieval performance and vice-versa, whereas the lower 
value of ANMRR represents the better retrieval performance and vice-versa. 

B.  Face Databases 

We  have  used  seven  face  databases  namely  PaSC  [46],  LFW  [1],  [47],  PubFig  [2],  FERET  [48],  [49],  AR  [50],  [51], 
AT&T [52] and ExtendedYale [53], [54], for the face retrieval. After localization, all the face images are down-sampled in 
64√ó64 dimension.  The PaSC  still images face  database is very challenging due  to  many variations present such as  pose, 
illumination  and  blur  [46].  Total  9376  images  from  293  subjects  with  32  images  per  subject  are  present  in  the  PaSC 
database. We used Viola Jones object detection method [55] for face localization over PaSC images. Finally, we have 8718 
faces in this database where faces are successfully detected using Viola Jones detector. 

The  face  retrieval  in  unconstrained  environment  is  a  fundamental  problem.  LFW  and  PubFig  databases  contain  the 
images  collected  from  the  internet.  These  images  are  captures  in  completely  unconstrained  environments  with  non-
cooperative subjects. Thus, the variations like pose, lighting, expression, scene, camera, etc. are present. The gray-scaled 
version of LFW cropped database [47] is used in this paper. In image retrieval framework, it is required to retrieve more 
than one (typically 5, 10, etc.) best matching images. So, in our database, the sufficient number of images should be present 
in each category. Thus, we have considered only those subjects that are having at least 20 images. Finally, in this database, 

This paper is published in Multimedia Tools and Applications, Springer. Cite this article as: S.R. Dubey and S. Mukherjee, 
‚ÄïLDOP:  Local  Directional  Order  Pattern  for  Robust  Face  Retrieval‚Äñ,  Multimedia  Tools  and  Applications,  2019. 
https://doi.org/10.1007/s11042-019-08370-x 

8 

     
 
   
 
     
 
   
 
  
   
  
  
   
  
                             
 
                             
                                
Pre-print: Published in Multimedia Tools and Applications, Springer 

there are 3023 face images from 62 individuals. The PubFig (i.e. PublicFigure) database is having 60 individuals with 6472 
number of total images in the database [2]. We have downloaded the images from the internet directly following the urls 
given in this database and removed the dead urls. 

‚ÄïPortions of the research in this paper use the FERET database of facial images collected under the FERET program, 
sponsored by the DOD Counterdrug Technology Development Program Office‚Äñ [48], [49]. Due to the severe variations in 
the expression and pose (13 different poses), Color-FERET database is adopted as a challenging database. We considered 
only those subjects that are having at least 20 images, converted the color images into gray-scale images. Finally, FERET 
database  is  having  141  subjects  with  4053  total  number  of  images.  The  AR  face  databases  exhibit  different  facial 
expressions,  illumination  conditions  and  occlusions  [50].  We  have  used  the  cropped  version  of  this  database  [51]  and 
converted the color image into gray-scaled image. The AR database consists of a total 2600 images from 100 individuals 
with 26 images per individual. The AT&T face database (formerly ‚ÄïThe ORL Database of Faces‚Äñ) is having 10 images per 
subject  from  40  different  subjects  [52].  There  are  variations  in  the  lighting  conditions  and  facial  expressions  for  some 
subjects. A dark homogeneous background is used to capture the images in AT&T database with the subjects in an upright, 
frontal position. The ExtendedYale database is having gray-scaled cropped and aligned faces [53], [54]. This database is 
created in the controlled lighting environment having severe and non-uniform illumination changes. Total 38 subjects are 
present in the database. Each subject is having 64 images with 2432 total images in this database. 

(a)                                                (b) 

Fig.6.  The  F-Score  (%)  when  10  images  are  retrieved  (      )  over  (a)  LFW,  (b)  FERET,  (C)  AR,  and  (d)  AT&T  databases  using 
LDOP  descriptor  with  different  radius  and  multi  resolution.  In  the  legends,  the  radius  or  range  of  radius  (for  multi  resolution)  is 
mentioned; the single digit represents a radius, whereas double digit represents the range of radius. 

(c)                                                (d) 

This paper is published in Multimedia Tools and Applications, Springer. Cite this article as: S.R. Dubey and S. Mukherjee, 
‚ÄïLDOP:  Local  Directional  Order  Pattern  for  Robust  Face  Retrieval‚Äñ,  Multimedia  Tools  and  Applications,  2019. 
https://doi.org/10.1007/s11042-019-08370-x 

9 

LDOP with different radius combinations910111213DescriptorsF-Score (%) for 10 Top MatchesLFW Database  2323424525656463626LDOP with different radius combinations2425262728DescriptorsF-Score (%) for 10 Top MatchesFERET Database  2323424525656463626LDOP with different radius combinations151617181920DescriptorsF-Score (%) for 10 Top MatchesAR Database  2323424525656463626LDOP with different radius combinations656667686970717273DescriptorsF-Score (%) for 10 Top MatchesAT&T Database  2323424525656463626 
 
 
 
 
 
  
 
   
 
Pre-print: Published in Multimedia Tools and Applications, Springer 

(a) 

(b) 

(c) 

(d) 

(e) 

(f) 

Fig.7. The experimental retrieval results in terms of the ARP (%), ARR (%), F-Score (%), and ANMRR (%) in the 1st, 2nd, 3rd, and 4th 
columns over (a) PaSC, (b) LFW (c) PubFig, (d) FERET, (e) AR, and (f) AT&T face databases. 

This paper is published in Multimedia Tools and Applications, Springer. Cite this article as: S.R. Dubey and S. Mukherjee, 
‚ÄïLDOP:  Local  Directional  Order  Pattern  for  Robust  Face  Retrieval‚Äñ,  Multimedia  Tools  and  Applications,  2019. 
https://doi.org/10.1007/s11042-019-08370-x 

10 

1234567891020406080100Number of Top MatchesARP (%)PaSC Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP1234567891034567Number of Top MatchesARR (%)PaSC Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP1234567891067891011Number of Top MatchesF-Score (%)PaSC Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP12345678910020406080Number of Top MatchesANMRR (%)PaSC Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP1234567891020406080100Number of Top MatchesARP (%)LFW Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP1234567891034567Number of Top MatchesARR (%)LFW Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP1234567891067891011Number of Top MatchesF-Score (%)LFW Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP12345678910020406080Number of Top MatchesANMRR (%)LFW Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP1234567891020406080100Number of Top MatchesARP (%)PublicFigure Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP123456789102345Number of Top MatchesARR (%)PublicFigure Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP123456789104567Number of Top MatchesF-Score (%)PublicFigure Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP12345678910020406080Number of Top MatchesANMRR (%)PublicFigure Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP12345678910405060708090100Number of Top MatchesARP (%)FERET Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP1234567891069121518Number of Top MatchesARR (%)FERET Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP12345678910710131619222528Number of Top MatchesF-Score (%)FERET Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP123456789100102030405060Number of Top MatchesANMRR (%)FERET Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP1234567891020406080100Number of Top MatchesARP (%)AR Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP123456789104681012Number of Top MatchesARR (%)AR Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP1234567891081012141618Number of Top MatchesF-Score (%)AR Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP12345678910010203040506070Number of Top MatchesANMRR (%)AR Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP123456789105060708090100Number of Top MatchesARP (%)AT&T Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP1234567891010203040506070Number of Top MatchesARR (%)AT&T Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP12345678910203040506070Number of Top MatchesF-Score (%)AT&T Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP12345678910010203040Number of Top MatchesANMRR (%)AT&T Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP 
 
 
 
 
 
 
Pre-print: Published in Multimedia Tools and Applications, Springer 

5. EXPERIMENTS AND PERFORMANCE ANALYSIS 
In this section, first we analyze the effect of radius of local neighborhood and multi resolution over LDOP descriptor; then, 
we  compare  the  results  with  existing  descriptors  over  seven  challenging  face  databases;  and  finally,  we  investigate  the 
effect of distance measures. The Chi-square distance measure is used for the experiments until or otherwise specified. In 
order to demonstrate the improved performance of proposed LDOP descriptor for face retrieval, we compare the proposed 
method with state-of-the-art face descriptors such as LBP [10], LTP [25], LDP [26], SLBP [33], LVP [32], LDGP [34] and 
DCP  [13].  Note  that,  all  these  descriptors  have  shown  very  promising  performance  for  facial  analysis  under  different 
imaging conditions such as rotation, scale, background, blur, illumination, pose, masking, etc. We have used radius        
for  LBP,  LTP,  LDP,  SLBP  and  LDGP  and         for  LVP  and  DCP  as  per  the  source  papers  of  these  descriptors.  The 
number of local neighbors (i.e.,  ) at a fixed radius is 8 for all the descriptors in all the experiments. 

A.  Effect of Radius and Multi Resolution 

The  effect  of  radius  of  local  neighborhood  (i.e.,   )  over  LDOP  descriptor  is  observed  in  this  experiment  over  each 
database. Fig. 6 illustrates the results in terms of the F-score for top 10 retrieved images. The number of local neighbors 
(i.e.,  ) at a fixed radius is 8 for LDOP in all the experiments. In Fig. 6, the values of   considered for LDOP are 2, 3, 4, 5 
and 6, whereas the range of value of   considered for multi resolution LDOP are 23, 24, 25, 56, 46, 36, and 26. Here the 
range  written  in  two  digit  like      represents  the  multi  resolution  LDOP  with                             .  Over  LFW 
database,  the  performance  of  LDOP  is  improving  with  increase  in  the  local  neighborhood  area  with          as  best 
performing combination. It can be observed that the performance of  LDOP over FERET database is better if combining 
lower  values of R such as 23, 24, and 25. This behavior of  LDOP is due to the presence of  huge pose  variations in the 
FERET database which restricts to consider very wide local neighborhood. The best result over AR database is obtained 
for      . Due to the non-uniform illumination variations, the result for higher values of    is not improved as directional 
order is getting affected much. The AT&T database is also having some amount of pose variations, thus the performance is 
improving upto       over this database. It is observed that the best performance of LDOP is obtained at different settings 
for different databases. Still, in the rest of experiments, we use multi resolution       . 

B.  Results Comparison 

The comparison results in terms of the ARP, ARR, F-score, and ANMRR against the number of retrieved images (i.e.   ) 
are shown in Fig. 7 over PaSC, LFW, PubFig, FERET, AR and AT&T face databases. It is clear from this result that the 
performance  of  LDOP  descriptor  is  outstanding  as  compared  to  the  other  descriptors  over  these  challenging  databases. 
These databases are having pose, illumination, scale, unconstraint and expression variations, thus it is deduced that LDOP 
is more robust and discriminative as compared to LBP, LTP, LDP, SLBP, LVP, LDGP and DCP descriptors against these 
variations. DCP is the second best performing  method in  most of the cases. The PaSC  database is having  very complex 
variations like blur, illumination and pose and it is observed that LDOP is much suitable to this database. The images in 
LFW  and  PubFig  databases  are  taken  in  totally  uncontrolled  manner.  The  outperformance  of  proposed  descriptor  over 
LFW  and  PubFig  databases  evidences  the  utilization  of  wider  neighborhood  for  more  discriminability.  The  FERET 
database is having images with huge pose differences. The better performance using LDOP over FERET database suggests 
that LDOP is more robust for pose variations than state-of-the-art descriptors. Over AR database, the proposed descriptor 
has the comparable performance to DCP. The reason of such behavior is related to the complex illumination change and 
masked  faces  that  many  faces  in  AR  database  have.  The  performance  of  LDOP  under  complex  illumination  will  be 
analyzed  in  next  sub-section  over  ExtendedYale  database.  The  proposed  descriptor  is  also  good  enough  for  the  frontal 
faces  as  its  performance  is  outstanding  among  all  the  descriptors  over  AT&T  database.  It  is  also  observed  that  the 
improvement using multi resolution LDOP is more significant over LFW and AT&T databases, whereas if we use LDOP 
at lower radius then the improvement over FERET and AR databases will be also significant as suggested by the results 
analysis of Fig. 6. The main problem with LBP, LTP, LDP, SLBP, LDGP and DCP is due to the lack of utilization of the 
relationship among the dense local neighbors. Basically, these methods use only the local neighbors at a specific radius. 
Whereas, the proposed LDOP method uses the dense local neighborhood. Moreover, most of the existing descriptors miss 
to utilize the relationship among local neighbors. The LVP descriptor encodes the relationship between the differences of 
intensity at different directions, whereas, the proposed LDOP descriptor encodes the directional ordering pattern, whereas. 
Unlike the LDOP descriptor, the LVP descriptor works on high-order image space. The dimensions of the descriptors are 
as  follows:  LBP  (256),  LTP  (512),  LDP  (1024),  SLBP  (256),  LVP  (1024),  LDGP  (65),  DCP  (512),  and  LDOP  (768). 
However, the performance of LDOP is superior. It points out that the dimension alone is not the key factor that influences 
the discriminativeness of LDOP, because LDP and LVP has higher dimension than proposed method. 

This paper is published in Multimedia Tools and Applications, Springer. Cite this article as: S.R. Dubey and S. Mukherjee, 
‚ÄïLDOP:  Local  Directional  Order  Pattern  for  Robust  Face  Retrieval‚Äñ,  Multimedia  Tools  and  Applications,  2019. 
https://doi.org/10.1007/s11042-019-08370-x 

11 

Pre-print: Published in Multimedia Tools and Applications, Springer 

(a)                                                                                 (b) 

Fig.8. The performance of descriptors under extreme lighting conditions over ExtendedYale database in terms of the (a) ARP, (b) ARR, 
(c) F-Score, and (d) ANMRR in (%). The performance of proposed descriptor is the second best. 

(c)                                                                                  (d) 

Table  1:  The  ARP  (%)  for         over  PaSC,  LFW,  PubFig,  FERET,  AR,  AT&T,  and  ExtendedYale  face  datasets  using  LDOP 
descriptor  with  different  distance  measures  such  as  Euclidean,  Cosine,  L1,  D1,  and  Chi-square.  The  best  result  for  a  database  is 
presented in bold. 

Datasets 
PaSC 
LFW 
PubFig 
FERET 
AR 
AT&T 
ExtendedYale 

Euclidean 
31.34 
33.31 
35.71 
61.46 
44.49 
92.15 
48.08 

Cosine 
32.33 
33.67 
36.39 
63.75 
45.55 
92.75 
50.45 

Distance Measures 
D1 
L1 
36.80 
36.49 
38.47 
38.19 
42.37 
41.91 
75.39 
74.26 
52.72 
52.02 
94.30 
94.40 
56.15 
55.23 

Chisq 
38.16 
40.15 
44.34 
76.55 
54.55 
94.05 
59.84 

C.  Performance under Severe Illumination Changes 

Even though the intensity order is invariant to only uniform illumination change, we experiment using proposed method 
under  non-uniform  illumination  change  also.  We  conduct  an  experiment  over  ExtendedYale  face  database  to  test  the 
robustness of proposed descriptor towards non-uniform and severe illumination changes. The results in terms of the ARP, 
ARR, F-Score and ANMRR are presented in Fig. 8 over ExtendedYale face database. Despite of the sensitivity of intensity 
order  towards  non-uniform  intensity  changes,  LDOP  is  the  second  best  performing  descriptor  over  ExtendedYale  face 
database. Moreover, its performance is significantly improved as compared to DCP for more number of retrieved images. 

This paper is published in Multimedia Tools and Applications, Springer. Cite this article as: S.R. Dubey and S. Mukherjee, 
‚ÄïLDOP:  Local  Directional  Order  Pattern  for  Robust  Face  Retrieval‚Äñ,  Multimedia  Tools  and  Applications,  2019. 
https://doi.org/10.1007/s11042-019-08370-x 

12 

24681020406080100Number of Top MatchesARP (%)ExtendedYale Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP123456789102345678Number of Top MatchesARR (%)ExtendedYale Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP12345678910468101214Number of Top MatchesF-Score (%)ExtendedYale Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP123456789100204060Number of Top MatchesANMRR (%)ExtendedYale Database  LBPLTPLDPSLBPLVPLDGPDCPLDOP 
 
 
 
 
 
 
 
Pre-print: Published in Multimedia Tools and Applications, Springer 

The performance of LVP is better in this scenario due to the non-uniform light change under extreme lighting conditions. 
The LDOP uses the order which may not be preserved in case of non-uniform light change. This is one of the limitations of 
proposed method. 

D.  Effect of Distance Measure 

We also investigate the effect of different distances over the performance of proposed LDOP descriptor over each database 
in Table 1. Euclidean, Cosine, L1, D1 and Chi-square distances are used. In this table, the results are presented using ARP 
values  in  percentage  for  top  5  numbers  of  retrieved  images.  It  is  found  that  the  ARP  values  using  Chi-square  distance 
measure is more as shown in bold in Table 1 over each database except AT&T. Thus, it is suggested to use the Chi-square 
distance with LDOP descriptor for face matching. 

6. CONCLUSION  
A local directional intensity order pattern (LDOP) based descriptor is proposed in this paper for robust face retrieval.  The 
LDOP  concept  facilitates  to  utilize  wider  local  neighbors  without  increasing  the  dimension  of  the  descriptor.  The 
directional  intensity  order indexes are used to encode the relationship among directional neighbors. This also provides a 
way to converge the wider neighborhood into the compact form. The center pixel values are transformed in the range of 
directional order indexes to find the LDOP pattern. The LDOP is also investigated using multi resolution mechanism. The 
retrieval results are compared over  seven benchmark face  databases (i.e., PaSC,  LFW,  PubFig,  FERET, AR,  AT&T and 
ExtendedYale)  having  different  kind  of  variations  such  as  pose,  illumination,  scale  and  expressions.  Promising 
performance  of  proposed  LDOP  descriptor  is  observed  as compared  to  the  seven  recent  state-of-the-art  face  descriptors. 
The  experimental  results  suggest  that  LDOP  is  more  robust  to  the  intra-class  variations  and  more  discriminative  to  the 
inter-class  similarities.  It  is  investigated  that  the  performance  of  LDOP  is  better  with  lower  radius  in  case  of  huge  pose 
variations and non-uniform illumination changes are present in the images. It is also found that the results are better with 
Chi-square distance. In future, the LDOP descriptor can be used to analyze the facial expressions. It can be extended for 
the facial analysis by considering the color information also. 

ACKNOWLEDGMENT  
This research is funded by IIIT Sri City, India through the Faculty Seed Research Grant 

References 
[1]  G.B. Huang, M. Ramesh, T. Berg, and E. Learned-Miller E, ‚ÄïLabeled faces in the wild: A database for studying face recognition in 

unconstrained environments,‚Äñ Technical Report 07-49, University of Massachusetts Amherst, 2007. 

[2]  N.  Kumar,  A.C.  Berg,  P.N.  Belhumeur,  and  S.K.  Nayar,  ‚ÄïAttribute  and  simile  classifiers  for  face  verification,‚Äñ  IEEE  12th 

International Conference on Computer Vision, pp. 365-372, 2009. 

[3]  R.  Beveridge,  H.  Zhang,  B.  Draper  et  al.,  ‚ÄïReport  on  the  fg  2015  video  person  recognition  evaluation,‚Äñ  IEEE  International 

Conference on Automatic Face and Gesture Recognition, 2015. 

[4]  C. Ding, C. Xu, and D. Tao, ‚ÄïMulti-task pose-invariant face recognition,‚Äñ IEEE Transactions on Image Processing, vol. 24, no. 3, 

pp. 980-993, 2015. 

[5]  M. Kan, S. Shan, H. Zhang, S. Lao, and X. Chen, ‚ÄïMulti-view discriminant analysis,‚Äñ IEEE Transactions on Pattern Analysis and 

Machine Intelligence, vol. 38, no. 1, pp. 188-194, 2016. 

[6]  W. Zhao, R. Chellappa, P.J. Phillips, and A. Rosenfeld, ‚ÄïFace recognition: A literature survey,‚Äñ ACM Computing Surveys, vol. 35, 

no. 4, pp. 399-458, 2003. 

[7]  X. Zhang and Y. Gao, ‚ÄïFace recognition across pose: A review,‚Äñ Pattern Recognition, vol. 42, no. 11, pp. 2876-2896, 2009. 
[8]  C. Ding and D. Tao, ‚ÄïA comprehensive survey on pose-invariant face recognition,‚Äñ ACM Transactions on Intelligent Systems and 

Technology, vol. 7, no. 3, pp. 37, 2016. 

[9]  J. Wright, A. Y. Yang, A. Ganesh, S. S. Sastry, and Y. Ma, ‚ÄïRobust face recognition via sparse representation,‚Äñ IEEE Transactions 

on Pattern Analysis and Machine Intelligence, vol. 31, no. 2, pp. 210‚Äì227, Feb. 2009. 

[10] T.  Ahonen,  A.  Hadid,  and  M.  Pietikainen,  ‚ÄïFace  description  with  local  binary  patterns:  Application  to  face  recognition,‚Äñ  IEEE 

Transactions on Pattern Analysis and Machine Intelligence, vol. 28, no. 12, pp. 2037-2041, 2006. 

This paper is published in Multimedia Tools and Applications, Springer. Cite this article as: S.R. Dubey and S. Mukherjee, 
‚ÄïLDOP:  Local  Directional  Order  Pattern  for  Robust  Face  Retrieval‚Äñ,  Multimedia  Tools  and  Applications,  2019. 
https://doi.org/10.1007/s11042-019-08370-x 

13 

 
 
Pre-print: Published in Multimedia Tools and Applications, Springer 

[11] Z.  Cao,  Q.  Yin,  X.  Tang,  and  J.  Sun,  ‚ÄïFace  recognition  with  learning-based  descriptor,‚Äñ  IEEE  International  Conference  on 

Computer Vision and Pattern Recognition, pp. 2707‚Äì2714, 2010. 

[12] L.  Wolf,  T.  Hassner,  and  Y.  Taigman,  ‚ÄïEffective  unconstrained  face  recognition  by  combining  multiple  descriptors  and  learned 
background statistics,‚Äñ IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 33, no. 10, pp. 1978‚Äì1990, 2011. 
[13] C.  Ding,  J.  Choi,  D.  Tao,  and  L.S.  Davis,  ‚ÄïMulti-directional  multi-level  dual-cross  patterns  for  robust  face  recognition,‚Äñ IEEE 

Transactions on Pattern Analysis and Machine Intelligence, vol. 38, no. 3, pp. 518-531, 2016. 

[14] Y.  Taigman,  M.  Yang,  M.  Ranzato,  and  L.Wolf,  ‚ÄïDeepface:  Closing  the  gap  to  human-level  performance  in  face  verification,‚Äñ 

IEEE International Conference on Computer Vision and Pattern Recognition, pp. 1701‚Äì1708, 2014. 

[15] Y. Sun, X. Wang, and X. Tang, ‚ÄïDeep learning face representation from predicting 10,000 classes,‚Äñ IEEE International Conference 

on Computer Vision and Pattern Recognition, pp. 1891‚Äì1898, 2014. 

[16] T.  Ojala,  M.  Pietikainen,  and  D.  Harwood,  ‚ÄïA  comparative  study  of  texture  measures  with  classification  based  on  feature 

distributions,‚Äñ Pattern Recognition, vol. 29, no. 1, pp. 51‚Äì59, 1996. 

[17] T. Ojala, M. Pietikainen, and T. Maenpaa, ‚ÄïMultiresolution gray-scale and rotation invariant texture classification with local binary 

patterns,‚Äñ IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 24, no. 7, pp. 971-987, 2002. 

[18] S.  Liao,  M.W.  Law,  and  A.C.  Chung,  ‚ÄïDominant  local  binary  patterns  for  texture  classification,‚Äñ IEEE  Transactions  on  Image 

Processing, vol. 18, no. 5, pp. 1107-1118, 2009. 

[19] X.  Qi,  R.  Xiao,  C.G.  Li,  Y.  Qiao,  J.  Guo,  and  X.  Tang,  ‚ÄïPairwise  rotation  invariant  co-occurrence  local  binary  pattern,‚Äñ IEEE 

Transactions on Pattern Analysis and Machine Intelligence, vol. 36, no. 11, pp. 2199-2213, 2014. 

[20] S.  Murala,  R.P.  Maheshwari,  and  R.  Balasubramanian,  ‚ÄïLocal  tetra  patterns:  a  new  feature  descriptor  for  content-based  image 

retrieval,‚Äñ IEEE Transactions on Image Processing, vol. 21, no. 5, pp. 2874-2886, 2012. 

[21] L. Liu, Y. Long, P.W. Fieguth, S. Lao, and G. Zhao, ‚ÄïBRINT: binary rotation invariant and noise tolerant texture classification,‚Äñ 

IEEE Transactions on Image Processing, vol. 23, no. 7, pp. 3071-3084, 2014. 

[22] D. Huang, C. Shan, M. Ardabilian, Y. Wang, and L. Chen, ‚ÄïLocal binary patterns and its application to facial image analysis:  A 

survey,‚Äñ IEEE Transactions on Systems Man and Cybernetics: Part C, vol. 41, no. 6, pp. 765-781, 2011. 

[23] B.  Yang  and  S.  Chen,  ‚ÄïA  comparative  study  on  local  binary  pattern  (LBP)  based  face  recognition:  LBP  histogram  versus  LBP 

image,‚Äñ Neurocomputing, vol. 120, pp. 365-379, 2013. 

[24] W. Zhang, S. Shan, W  Gao, X. Chen, and H. Zhang, ‚ÄïLocal  Gabor binary pattern histogram sequence (LGBPHS): a novel non-

statistical model for face representation and recognition,‚Äñ IEEE International Conference on Computer Vision, pp. 786-791, 2005. 

[25] X.  Tan  and  B.  Triggs,  ‚ÄïEnhanced  local  texture  feature  sets  for  face  recognition  under  difficult  lighting  conditions,‚Äñ  IEEE 

Transactions on Image Processing, vol. 19, no. 6, pp. 1635-1650, 2010. 

[26] B. Zhang, Y. Gao, S. Zhao, and J. Liu, ‚ÄïLocal derivative pattern versus local binary pattern: face recognition with high-order local 

pattern descriptor,‚Äñ IEEE Transactions on Image Processing, vol. 19, no. 2, pp. 533-544, 2010. 

[27] J.  Chen,  S.  Shan,  C.  He,  G.  Zhao,  M.  Pietikainen,  X.  Chen,  and  W.  Gao,  ‚ÄïWLD:  A  robust  local  image  descriptor,‚Äñ IEEE 

Transactions on Pattern Analysis and Machine Intelligence, vol. 32, no. 9, pp. 1705-1720, 2010.  

[28] S.  Xie,  S.  Shan,  X.  Chen,  and  J.  Chen,  ‚ÄïFusing  local  patterns  of  gabor  magnitude  and  phase  for  face  recognition,‚Äñ  IEEE 

Transactions on Image Processing, vol. 19, no. 5, pp. 1349‚Äì1361, 2010.  

[29] N.S.  Vu  and  A.  Caplier,  ‚ÄïEnhanced  patterns  of  oriented  edge  magnitudes  for  face  recognition  and  image  matching,‚Äñ  IEEE 

Transactions Image Processing, vol. 21, no. 3, pp. 1352‚Äì1365, 2012. 

[30] C. Chan, M. Tahir, J. Kittler, and M. Pietikainen, ‚ÄïMultiscale local phase quantisation for robust component-based face recognition 
using kernel fusion of multiple descriptors,‚Äñ IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 35, no. 5, pp. 
1164‚Äì1177, 2013. 

[31] A.R.  Rivera,  J.R.  Castillo,  and  O.  Chae,  ‚ÄïLocal  directional  number  pattern  for  face  analysis:  Face  and  expression  recognition,‚Äñ 

IEEE Transactions on Image Processing, vol. 22, no. 5, pp. 1740-1752, 2013. 

[32] K.C.  Fan  and  T.Y.  Hung,  ‚ÄïA  Novel  Local  Pattern  Descriptor‚ÄîLocal  Vector  Pattern  in  High-Order  Derivative  Space  for  Face 

Recognition,‚Äñ IEEE Transactions on Image Processing, vol. 23, no. 7, pp. 2877-2891, 2014. 

[33] K. Jeong, J. Choi, and G.J. Jang, ‚ÄïSemi-local structure patterns for robust face detection,‚Äñ IEEE Signal Processing Letters, vol. 22, 

no. 9, pp. 1400-1403, 2015. 

[34] S.  Chakraborty,  S.K.  Singh,  and  P.  Chakraborty,  ‚ÄïLocal  directional  gradient  pattern:  a 

local  descriptor  for  face 

recognition,‚Äñ Multimedia Tools and Applications, vol. 76, no. 1, pp. 1201-1216, 2017. 

[35] O. Arandjelovi, ‚ÄïGradient Edge Map Features for Frontal Face Recognition under Extreme Illumination Changes,‚Äñ British Machine 

Vision Conference, pp. 12.1-12.11, 2012.  

[36] S. Liao, X. Zhu, Z. Lei, L. Zhang, and S.Z. Li, ‚ÄïLearning multi-scale block local binary patterns for face recognition,‚Äñ International 

Conference on Biometrics, pp. 828-837, 2007. 

[37] S. ul Hussain and B. Triggs, ‚ÄïVisual recognition using local quantized patterns,‚Äñ in Proc. Eur. Conf. Comput. Vis., 2012, pp. 716‚Äì

729. 

This paper is published in Multimedia Tools and Applications, Springer. Cite this article as: S.R. Dubey and S. Mukherjee, 
‚ÄïLDOP:  Local  Directional  Order  Pattern  for  Robust  Face  Retrieval‚Äñ,  Multimedia  Tools  and  Applications,  2019. 
https://doi.org/10.1007/s11042-019-08370-x 

14 

Pre-print: Published in Multimedia Tools and Applications, Springer 

[38] Z. Lei, M. Pietik√§inen, and S.Z. Li, ‚ÄïLearning discriminant face descriptor,‚Äñ IEEE Transactions on Pattern Analysis and Machine 

Intelligence, vol. 36, no. 2, pp. 289-302, 2014. 

[39] J.  Lu, V.E.  Liong, X.  Zhou,  and  J.  Zhou,  ‚ÄïLearning  compact  binary  face  descriptor  for  face  recognition,‚Äñ IEEE  Transactions on 

Pattern Analysis and Machine Intelligence, vol. 37, no. 10, pp. 2041-2056, 2015. 

[40] R. Gupta, H. Patil, and A. Mittal, ‚ÄïRobust order-based methods for feature description,‚Äñ IEEE Conference on Computer Vision and 

Pattern Recognition, pp. 334-341, 2010. 

[41] Z. Wang, B. Fan, and F. Wu, ‚ÄïLocal intensity order pattern for feature description,‚Äñ IEEE International Conference on Computer 

Vision, pp. 603-610, 2011. 

[42] B.  Fan,  F.  Wu,  and  Z.  Hu,  ‚ÄïRotationally  invariant  descriptors  using  intensity  order  pooling,‚Äñ IEEE  Transactions  on  Pattern 

Analysis and Machine Intelligence, vol. 34, no. 10, pp. 2031-2045, 2012. 

[43] S.R. Dubey, S.K. Singh, and R.K. Singh, ‚ÄïRotation and Illumination Invariant Interleaved Intensity Order Based Local Descriptor,‚Äñ 

IEEE Transactions on Image Processing, vol. 23, no. 12, pp. 5323-5333, 2014. 

[44] pdist2: https://pdollar.github.io/toolbox/classify/pdist2.html. 
[45] K. Lu, N. He, J. Xue, J. Dong, and L. Shao, ‚ÄïLearning View-Model Joint Relevance for 3D Object Retrieval,‚Äñ IEEE Transactions 

on Image Processing, vol. 24, no. 5, pp. 1449-1459, 2015. 

[46] J.R. Beveridge, P.J. Phillips, D.S. Bolme, B.A. Draper, G.H. Givens, Y.M. Lui, M.N. Teli, H. Zhang, W.T. Scruggs, K.W. Bowyer, 
and P.J. Flynn, P.J., ‚ÄïThe challenge of face recognition from digital point-and-shoot cameras,‚Äñ IEEE Sixth International Conference 
on Biometrics: Theory, Applications and Systems, 2013. 

[47] C.  Sanderson  and  B.C.  Lovell,  ‚ÄïMulti-region  probabilistic  histograms  for  robust  and  scalable  identity  inference,‚Äñ  International 

Conference on Biometrics, pp. 199-208, 2009. 

[48] P.J.  Phillips,  H.  Wechsler,  J.  Huang,  and  P.  Rauss,  ‚ÄïThe  FERET  database  and  evaluation  procedure  for  face  recognition 

algorithms,‚Äñ Image and Vision Computing, vol. 16, no. 5, pp. 295-306, 1998. 

[49] P.J. Phillips, H. Moon, S.A. Rizvi, and P.J. Rauss, ‚ÄïThe FERET Evaluation Methodology for Face Recognition Algorithms,‚Äñ IEEE 

Transactions on Pattern Analysis and Machine Intelligence, vol. 22, no. 10, pp.1090-1104, 2000. 

[50] A.M. Martinez and R. Benavente, ‚ÄïThe AR Face Database,‚Äñ CVC Technical Report, no. 24, 1998.  
[51] A.M. Mart√≠nez and A.C. Kak, ‚ÄïPca versus lda,‚Äñ IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 23, no. 2, 

pp. 228-233, 2001. 

[52] F.S. Samaria and A.C. Harter, ‚ÄïParameterisation of a stochastic model for human face identification,‚Äñ  Second IEEE Workshop on 

Applications of Computer Vision, pp. 138-142, 1994. 

[53] A.S. Georghiades, P.N. Belhumeur, and D.J. Kriegman, ‚ÄïFrom few to many: illumination cone models for face recognition under 
variable lighting and pose,‚Äñ IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 23, no. 6, pp. 643‚Äì660, 2001. 
[54] K.C. Lee, J. Ho, and D.J. Kriegman, ‚ÄïAcquiring linear subspaces for face recognition under variable lighting,‚Äñ  IEEE Transactions 

on Pattern Analysis and Machine Intelligence, vol. 27, no. 5, pp.  684‚Äì698, 2005. 

[55] P. Viola and M.J. Jones, ‚ÄïRobust real-time face detection,‚Äñ International Journal of Computer Vision, vol. 57, no. 2, pp. 137-154, 

2004.  

[56] L. Nie, S. Yan, M. Wang, R. Hong, and T.S. Chua. ‚ÄïHarvesting visual concepts for image search with complex queries,‚Äñ 20th ACM 

International Conference on Multimedia, pp. 59-68, 2012. 

[57] M.  Kokare,  P.K.  Biswas,  and  B.N.  Chatterji,  ‚ÄïTexture  image  retrieval  using  new  rotated  complex  wavelet  filters,‚Äñ  IEEE 

Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), vol. 35, no. 6, pp. 1168-1178, 2005. 

[58] X. You, L. Du, Y. Cheung, and Q. Chen, ‚ÄïA Blind Watermarking Scheme Using New Nontensor Product Wavelet Filter Banks,‚Äñ 

IEEE Transactions on Image Processing, vol. 19, no. 12, pp. 3271-3284, 2010. 

[59] G. Quellec, M. Lamard, G. Cazuguel, B. Cochener, and Christian Roux, ‚ÄïFast Wavelet-Based Image Characterization for Highly 

Adaptive Image Retrieval,‚Äñ IEEE Transactions on Image Processing, vol. no. 4, pp. 1613-1623, 2012. 

This paper is published in Multimedia Tools and Applications, Springer. Cite this article as: S.R. Dubey and S. Mukherjee, 
‚ÄïLDOP:  Local  Directional  Order  Pattern  for  Robust  Face  Retrieval‚Äñ,  Multimedia  Tools  and  Applications,  2019. 
https://doi.org/10.1007/s11042-019-08370-x 

15 

