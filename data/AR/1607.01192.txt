Bounded Inﬂuence Propagation τ -Estimation:
A New Robust Method for ARMA Model
Estimation

Michael Muma, Member, IEEE, and Abdelhak M. Zoubir, Fellow, IEEE

1

6
1
0
2

t
c
O
0
2

]
E
M

.
t
a
t
s
[

3
v
2
9
1
1
0
.
7
0
6
1
:
v
i
X
r
a

Abstract—A new robust and statistically efﬁcient estimator
for ARMA models called the bounded inﬂuence propagation
(BIP) τ -estimator is proposed. The estimator incorporates an
auxiliary model, which prevents the propagation of outliers.
Strong consistency and asymptotic normality of the estimator for
ARMA models that are driven by independently and identically
distributed (iid) innovations with symmetric distributions are
established. To analyze the inﬁnitesimal effect of outliers on
the estimator, the inﬂuence function is derived and computed
explicitly for an AR(1) model with additive outliers. To obtain
estimates for the AR(p) model, a robust Durbin-Levinson type
and a forward-backward algorithm are proposed. An iterative
algorithm to robustly obtain ARMA(p,q) parameter estimates is
also presented. The problem of ﬁnding a robust initialization is
addressed, which for orders p + q > 2 is a non-trivial matter.
Numerical experiments are conducted to compare the ﬁnite
sample performance of the proposed estimator to existing robust
methodologies for different types of outliers both in terms of
average and of worst-case performance, as measured by the
maximum bias curve. To illustrate the practical applicability of
the proposed estimator, a real-data example of outlier cleaning for
R-R interval plots derived from electrocardiographic (ECG) data
is considered. The proposed estimator is not limited to biomedical
applications, but is also useful in any real-world problem whose
observations can be modeled as an ARMA process disturbed by
outliers or impulsive noise.

Index Terms—Robust Estimation, ARMA, Bounded Inﬂuence
Propagation, Robustness, Dependent Data, Outliers, τ -estimator,
Artifacts, Inﬂuence Function, ECG, HRV

I. INTRODUCTION

(ARMA) models

Autoregressive moving-average

are
amongst the most popular models for characterizing dependent
data and they have a long tradition in numerous real-world ap-
plications, e.g. in speech processing [1], biomedicine [2], [3],
radar [4], electricity consumption forecasting [5]–[7], system
identiﬁcation [8] and econometry [9]. Numerous extensions
of the ARMA model, such as Seasonal Integrated ARMA
(SARIMA) [7], Periodic ARMA (PARMA) [10], Controlled
ARMA [11], and Time-Varying ARMA (TV-ARMA) models
[12] have been proposed.

This paper focusses on robust parameter estimation for
ARMA models associated with random processes for which
the majority of samples are appropriately modeled by a sta-
tionary and invertible ARMA model and a minority consists of

M. Muma and A.M. Zoubir are with the Signal Processing Group, Tech-
nische Universit¨at Darmstadt, Darmstadt, Germany. This work was supported
by the project HANDiCAMS which acknowledges the ﬁnancial support of
the Future and Emerging Technologies (FET) programme within the Seventh
Framework Programme for Research of the European Commission, under
FET-Open grant number: 323944.

outliers with respect to the ARMA model. For such cases and,
in general, classical estimators are unreliable and may break
down completely [5]–[7], [13]–[23]. The nature of the outliers
depends on the application. For example, motion artifacts
are often evident in biomedical signals such as intracranial
pressure (ICP), electrocardiographic (ECG) and photoplethys-
mographic (PPG) signals [24]–[28] while in electricity con-
sumption forecasting outliers are associated with holidays,
major sporting events and strikes [5], [21]. For a discussion
on how outliers affect ARMA parameter estimation, the reader
is referred, e.g. to [14], [16], [19], [29], [30] and there is a
clear need for robust methods that can, to some extent, resist
outliers. First contributions to robust estimation for dependent
data were made in the 1980’s [31]–[34], and in recent years,
research in this area has increased signiﬁcantly (e.g. [5]–[7],
[18]–[20], [22]–[24], [26], [27], [35]–[47]).

Research on robust ARMA parameter estimation may be
loosely grouped into two categories which are associated with
the diagnostic approach (e.g. [13]–[17], [23], [38], [39], [47])
and the statistically robust approach (e.g. [5]–[7], [18]–[22],
[27], [48], [49]). Diagnostic approaches enhance robustness
via detection and hard rejection of outliers, followed by a
classical parameter estimation method that handles missing
values. Statistically robust methods utilize the entire data set
and accommodate the outliers by bounding their inﬂuence on
the parameter estimates. Robust statistical theory also provides
measures, such as the inﬂuence function (IF), the breakdown
point and the maximum bias curve [19], [21], [50], which
characterize quantitative and qualitative robustness and allow
for an analytical comparison of different estimators.

The main contributions of this paper is to propose and
analyze a new estimator for ARMA model parameters called
the bounded inﬂuence propagation (BIP) τ -estimator which is
simultaneously robust and possesses a controllable statistical
efﬁciency. Robustness and high efﬁciency are jointly achieved
by incorporating an auxiliary model which prevents the prop-
agation of outliers into the τ -estimator. The term ’propagation
of outliers’ means that one outlier in the observations creates
multiple outliers in the reconstructed innovation series. The
BIP τ -estimate minimizes a robust and efﬁcient scale of
the reconstructed innovation series. In Theorem 1, strong
consistency of the τ -estimator of the ARMA parameters is
established. In Lemma 1, Fisher consistency of the τ -estimator
of the ARMA parameters is shown, given all past observations.
In Lemma 2, almost sure convergence of the τ -estimator
of the innovations scale to the population value based on

 
 
 
 
 
 
the expectation operator is proven. In Theorem 2, under an
ARMA model, it is established that the BIP τ -estimator is
asymptotically equivalent to a τ -estimator. Theorems 1 and 2
together prove the strong consistency of the proposed estimator
under general conditions, which include the Gaussian ARMA
model as a special case. In Theorem 3, asymptotic normality
of the estimator for the ARMA model is proven by deriving
the asymptotic equivalence to an M-estimator. To analyze
the inﬁnitesimal robustness of the BIP τ -estimator in the
asymptotic case, its IF is derived. The IF is explicitly computed
for an autoregressive process of order one, AR(1), in the case
of additive outliers. To compute the estimates for the AR(p)
model, a computationally efﬁcient robust Durbin-Levinson
type algorithm is proposed that incorporates the BIP model.
Here the parameters are recursively found for increasing
orders. In this way, searching for a robust starting point
to minimize a non-convex cost function is avoided, which
is a key-difﬁculty in robust estimation. A forward-backward
algorithm to recursively compute the AR(p) parameters is
also proposed. In the search for ARMA parameter estimates,
a Marquard algorithm is used to ﬁnd the parameters that
minimize the τ -scale of the innovations. For this case, an
algorithm to ﬁnd a robust starting point is presented. The
starting point algorithm uses a BIP-AR model based outlier
cleaning operation. Numerical experiments to evaluate the
estimator in terms of the maximum bias curve in order to
assess its quantitative robustness and also to compare it to
existing benchmark estimators are conducted. In particular,
Monte Carlo experiments for ARMA models of orders 4 ≥
(p + q) ≥ 8 are performed. This is unusual in robust ARMA
parameter estimation, which usually is limited to ARMA
models of lower orders. Patchy and independent replacement
and additive outliers of different types are considered in the
simulations. Finally, the proposed estimator is applied to a
real-data example of artifact cleaning for R-R interval plots
derived from electrocardiographic (ECG) data. R-R intervals
denote the time intervals between consecutive heart beats and
are used in heart rate and heart rate variability analysis.

Relation to existing work: In the analysis of our estimator,
we build upon theoretical results that were established for
the BIP MM-estimator [20]. As for the classical regression
setting, the τ [51] and MM [52] are alternative estimators with
similar statistical and robustness properties. In the context of
AR parameter estimation, a key advantage of the τ -estimator
is its deﬁnition via the τ -scale. Based on this deﬁnition, a
robust Durbin-Levinson type procedure is proposed. Further,
the starting point for the BIP MM, especially for p + q > 2 is
difﬁcult to ﬁnd and expressions for the IF are not available
for the BIP MM-estimator. Our estimator is also conceptually
related to the ﬁltered τ -estimator [19], which uses a robust
ﬁlter to prevent outlier propagation. A disadvantage of the
ﬁltered estimators is that
they are intractable in terms of
robustness and asymptotic statistical analysis.

The paper is organized as follows. Section II introduces
the signal and outlier models and discusses the propagation
of outliers. Section III introduces the BIP τ -estimator and de-
tails associated statistical and robustness analysis. Section IV
presents an algorithm for computing the stationary and invert-

2

ible BIP τ -estimates. Section V compares the performance of
the proposed BIP τ -estimator with existing ARMA parameter
estimators via Monte Carlo simulations. Section VI provides
a real-data example of artifact cleaning for R-R interval plots
derived from ECG data. Conclusions, and possible extensions
of this research are presented in Section VII.

Notation. Vectors (matrices) are denoted by bold-faced
lowercase (uppercase letters), e.g. a (A). The jth column
vector of a matrix A is denoted by aj. (⋅)⊺ is the transpose
operator. Sets are denoted by calligraphic letters, e.g. B. ˆβ
refers to the estimator (or estimate) of the parameter vector
β, log+(x) = max(log(∣x∣), 1), f (x) and F (x) are, respec-
tively, the probability density function (pdf) and cumulative
distribution function (cdf) of x, f (x1, x2) and F (x1, x2) are,
respectively, the joint pdf and joint cdf of the random variables
x1 and x2, f (x1∣x0; φ1) is the pdf of x1 conditioned on x0
and given φ = φ1. P (x = c) is the probability that x = c.
E
denotes
convergence to the normal distribution with mean vector 0
)
∶ Rk → R,
and covariance matrix Σ. Given a function g
x
is the k-dimensional column vector whose ith element
∇g
x
∂xi. Finally, xmin ∶ ∆x ∶ xmax denotes the grid of
is ∂g
)
(
equidistant points in R, ranging from xmin to xmax with a step
(
)/
size of ∆x.

is the expectation operator, while

0, Σ
(

x
)
(

→
D
Ð

⋅
]
[

N

II. SIGNAL AND OUTLIER MODELS

The ARMA and Bounded Innovation Propagation (BIP)-
ARMA signal models, as well as some important outlier
models, are brieﬂy revisited. Attention is drawn to the fact
that estimators, which are computed based on the innovations,
require a mechanism that prevents the propagation of outliers.

A. Signal model

Let

yt =

. . . , yt−k, . . . , yt−1, yt
(

)

(1)

denote a sequence of observations that was generated by a
stationary and invertible ARMA(p, q) process up to time t
according to

p

q

)

)

)

)

−

(2)

∑i=1

∑i=1

φ0,i

+ at

θ0,iat−i

β0
(

yt = µ0 +

β0
(
φ0, θ0, µ0
(

yt−i − µ0
(
where the true parameter vector β0 =
and θ0 =
θ0,1, . . . , θ0,q
φ0,1, . . . , φ0,p
(A1) Assume that at are independent and identically dis-
(
(
tributed (iid) random variables with a symmetric distribution
log+
and further assume that E
To restrict the parameter space in a manner which is consistent
[
let β =
with a stationary and invertible ARMA model,
φ, θ, µ
(

be a parameter vector deﬁned by the polynomials

, φ0 =
)

< ∞.

.
)

∣)]

at

(∣

)

p

and

= 1 −

B
φ
(

)

= 1 −

θ

B
(

)

∑i=1

q

∑i=1

φiBi

θiBi

(3)

(4)

which have all their roots outside the unit circle. Then, by
deﬁning

B
φ
(
)
the following recursion follows

B
(

β
(

)

= θ−1

ae
t

yt − µ

)(

,
)

p

∑i=1

φi

yt−i − µ
(

)

+

q

∑i=1

θiae

t−i

β
(

)

= yt − µ −

ae
t

β
(
β0
(

)
= at.

and ae
t
(A2) Assume that φ0
)
roots.

B
(

)

and θ0

B
(

)

do not have common

where b is deﬁned as

3

x
)
(

by setting η
= x. Thus, by choosing η
to be one of
the well-known monotone or redescending nonlinearities (e.g.,
Huber’s or Tukey’s) [50], all innovations that lie within some
region around µ are left untouched and, on the other hand, the
effect of a single AO or RO is bounded to a single corrupted
innovation. In (10), σ is a robust M-scale of at [21], [50], i.e.,
it solves

x
)
(

(5)

(6)

at
σ

E

ρ
[

(

= b,

)]

(11)

.

)]

(12)

⋅
]
[

x
(

b = E

ρ
[
To make the M-estimator consistent in scale with the standard
deviation when the data is Gaussian, E
in (12), is the
to the standard normal
expectation operator with respect
distribution.
x
(A3) Assume that ρ
0
, and ρ
following properties: ρ
−x
)
(
. ψ
x
tinuous, non-constant and non-decreasing in
)
(
(
is bounded and continuous.
∣
∣
(A4) Assume that η
function.
From (10), the innovations sequence can be recursively ob-
tained for t ≥ p + 1 according to

is a real-valued function with the
= 0, ρ
is con-
dρ(x)
dx

is an odd, bounded and continuous

x
x
)
(
=
)
(

x
)
(

x
)
(

= ρ

)

(8)

ab
t

β, σ
(

)

= yt − µ −

φi

p

∑i=1

r

+

∑i=1 (
.

yt−i − µ
(

ab
t−i

)
β, σ
(
σ

φiab

t−i

β, σ
(

)

)

(

(13)

ση
)

θi − φi
+
) )
(
Fig. 1 illustrates the inﬂuence of η
for an ARMA(2,1)
⋅
model with parameters φ0 =
, θ0 = 0.9. The
−0.39, −0.3
)
(
red crosses mark the AO positions in the observations. When
)
(
reconstructing the innovations with an ARMA model (6) that
uses β0, multiple innovation samples are contaminated. This
effect is suppressed when applying the BIP-ARMA (13).

10

e
d
u
t
i
l

0

p
m
A
−10

0

AO position
an(β0)
ab
n(β0, σ(β0))BIP−ARMA
ae
n(β0)ARMA
20

40

60
Samples

80

100

Fig. 1.
(blue) True innovations sequence; (red) innovations derived from
a Gaussian ARMA(2,1) observation with AOs whose positions are marked
with red crosses; (black) innovations obtained when using a BIP-ARMA(2,1)
model. In both cases, the true parameter vector β0, is used.

III. PROPOSED ESTIMATOR

We next deﬁne an estimator that is based on the idea of
minimizing a robust and efﬁcient scale of the reconstructed
innovations, the τ -scale. The estimator is deﬁned for the
case when the sample size exceeds the number of model
parameters, i.e., n > p + q. It computes the τ -scale both for

B. Outlier models

In real-world applications,

the observations yt may not
exactly follow (2). There exist several statistical models for
outliers in dependent data (see e.g. [13]–[17], [19], [21], [23]).
The following provides a brief review of important models.
The additive outlier (AO) model deﬁnes contaminated obser-
vations yε

t according to

t = xt + ξε
yε
where xt follows an ARMA model, as given in (2), wt deﬁnes
the contaminating process that is independent of xt and ξε
t is
a stationary random process for which

t wt,

(7)

1
0

ξε
t = ⎧⎪⎪
⎨
⎪⎪⎩

with probability ε
with probability

1 − ε
(

.
)

For the replacement outlier (RO) model

yε
t =

xt + ξε
)
where wt is independent of xt and ξt is deﬁned by (8). As
discussed, e.g. in [19], [21], innovation outliers, i.e., outliers
in at, can be dealt with by classical robust estimators.

1 − ξε
t
(

t wt,

(9)

takes the value 1, such that at

Outliers may also differ in their temporal structure. For
isolated outliers, ξε
least
t
one non-outlying observation is between two outliers (e.g.
ξε
t follows an independent Bernoulli distribution). For patchy
outliers, on the other hand, ξε
t ,
takes the value
1 for npatch ≤ n

2 subsequent samples.

t ∈ 1, . . . , n

}

{

/

C. Bounded innovation propagation (BIP)-ARMA model

ARMA parameter estimation, i.e., determining ˆβ, is often
based on minimizing some function of the reconstructed inno-
vation sequence. However, as can be seen from (5), one AO
or RO in yt can propagate onto multiple innovations ae
.
t
In the extreme case, all entries of the innovations sequence
)
are disturbed by a single outlier. Thus, robust estimators are
only applicable if they are combined with a mechanism to
prevent outlier propagation. An auxiliary model to do this, is
the BIP-ARMA model [20]:
p

β
(

r

yt =at + µ+

φi

yt−i − µ
(

)

−

∑i=1

φiat−i +

∑i=1(

θi − φi
(

ση
)

(

at−i
σ
))
(10)

, where if r > p, ap+1 = . . . = ar = 0, while
p, q
Here, r = max
if r > q, bq+1 = . . . = br = 0. ARMA models are included
)
(

 
 
innovations reconstructed from the ARMA in (6) and from the
BIP-ARMA in (13), and chooses as a ﬁnal estimate ˆβ∗
τ , which
provides the smaller τ -scale. We show, for iid innovations
with a symmetric pdf, that the proposed estimator is strongly
consistent with the ARMA model (Theorem 1 and Theorem
2). Further, the estimator is asymptotically normal for the
ARMA model case with a controllable efﬁciency with respect
to the maximum-likelihood estimator (Theorem 3). Finally,
an expression for the IF which measures robustness against
inﬁnitesimal contamination is provided.

A. Deﬁnition of the τ -estimator under the ARMA model

4

2

.

(21)

where σy is the standard deviation of yt and

κ2

= Var

at
σ

η
[

= E

η
[(

at
σ

− E

η
[

(

(
The estimate of σ in Eq. (20) can then be computed according
to

)])

)]

(

)

]

ˆσ2

β
(

=

ˆστ
n

2

yn
qlong
(
)
i=1 λ2
i

with yn =
large to approximate the MA-inﬁnity representation.

β
(
, and where qlong is chosen sufﬁciently
)

)
y1, . . . , yn
(

1 + κ2

∑

)

at
σ

,

(22)

be an M-estimate of the scale of an

=
which satisﬁes A3, i.e.,

)

β
(

= b.

)

))

(14)

)
β
(

under the ARMA model is

Let ˆσM
n
β
ap+1
(
(

β
an
, . . . , an
(
(
)

∑t=p+1
(A5) Assume that sup ρ1
The τ -estimate of β =
deﬁned according to

1
n − p

β
))
(

(

ρ1

))
n

ˆσM
n

based on ρ1

x
)
(
β
at
(
an
(
> b.
x
φ, θ, µ
(
)
(
ˆβτ = arg min

ˆστ
n

)

where ˆστ
β
n
and is deﬁned as
(

an
(

))

β
(
is the τ -estimate [51] of the scale of an

an
(

,
))

β∈B

(15)

β
(

)

n

ρ2

1
n − p

¿
Á
ÁÀ

ˆστ
n

an
(

β
(

= ˆσM

n

an
(

β
(

))

ˆσM
n

∑t=p+1
))
∈ Rp+q ∶
Here B = B0 ×R where B0 =
φ, θ
z
for some small ζ > 0.
B
B
for all roots z of φ
and θ
{(
∣
∣
x
(A6) Assume that ρ2
satisﬁes A3, and additionally,
(
)
(
x ≥ 0, where ψ2
2ρ2
x
(
)
)
(

)
)}
x
)
(

)
β
)
(16)
))
(
≥ 1 + ζ holds

dρ2(x)
dx .

x
)
(

− ψ2

(

=

at

β
(
an
(

B. Deﬁnition of the τ -estimator under the BIP ARMA model

φ, θ, µ
The τ -estimate of β =
model is deﬁned according to
(
ˆβb

τ = arg min
β∈B

under the BIP-ARMA

)

ˆστ
n

ab
n
(

β, ˆσ
(

β
(

,
)))

(17)

where

ˆστ
n

ab
n
(

β, ˆσ
(

β
(

)))

n

= ˆσM
¿
Á
ÁÀ

ab
n
(
1
n − p

⋅

)))

β, ˆσ
(

n

β
(
ρ2

∑t=p+1

(

ˆσM
n

ab
β, ˆσ
t
(
ab
n
(

β
(
β, ˆσ
(

))
β
(

)
)))
(18)

β, ˆσ
(

ab
and ab
p+1
n
cursively obtained from (13). To compute ˆσ
)))
(
inﬁnity representation of the BIP-ARMA model is used

β
β, ˆσ
is re-
β
, the MA-
(
(
)
(

β, ˆσ
(

, . . . , ab
n

β
(

β
(

))

))

=

β
where λi
follows that
(

)

yt = µ − at +

∞

∑i=1

λiση

at−i
σ

(

are the coefﬁcients of φ−1

,

)
B
(

σ2

=

β
(

)

1 + κ2

σ2
y
∞
i=1 λ2
i

∑

,

β
(

)

(19)

θ
)

B
(

. It then
)

(20)

C. Deﬁnition of the proposed τ -estimator

The ﬁnal τ -estimate of the innovations scale is
ˆβτ
(

an
(
and the ﬁnal parameter estimate becomes

ˆσ∗
τ = min

ab
n
(

ˆβb
(

ˆβb
τ
(

, ˆστ
n

τ , ˆσ

ˆστ
n

))

{

)))}

(23)

{

τ =

if
if

ˆβ∗

ˆστ
n
ˆστ
n

ˆβτ
ˆβb
τ

ˆβb
< ˆστ
(

an
ab
(
n
(

ab
n
(
)))

ˆβb
ˆβτ
< ˆστ
τ , ˆσ
n
τ
ˆβb
ˆβb
ˆβτ
(
))
(
an
τ , ˆσ
τ
(
(
(
(
is shown in Sec. III-D that when the data follows an
It
ˆβτ
ARMA model without outliers, the result that ˆστ
an
<
n
is asymptotically obtained for n → ∞.
ˆστ
(
(
n
This implies that the asymptotic efﬁciency of ˆβ∗
τ is indepen-
dent of η. However, this does not hold in the ﬁnite sample
size case.

ab
n
(

ˆβb
τ
(

ˆβb
(

)))
.
))

τ , ˆσ

(24)

)))

))

n

D. Statistical analysis

Theorem 1. establishes strong consistency of

the τ -

estimator of the ARMA parameters.
Assume that yt follows from Eq. (2) with at satisfying A1.
Further, assume that ρ1 satisﬁes A3 and A5 and that ρ2
satisﬁes A6. Then, the τ -estimator ˆβτ deﬁned in Eq. (15) is
strongly consistent for β0.
Proving this theorem requires Lemmas 1-3.
Lemma 1. provides the Fisher consistency of the τ -estimator
of the ARMA parameters given all past observations1.
Let yt be an observation from an ARMA(p,q), as in Eq. (2).
Assume that ρ1
is bounded and satisﬁes A3 and A5. It
then holds, with σ0 denoting the true innovations scale, that
if β ∈ B and β ≠ β0. This implies that
σ0 = ˆστ
the estimate ˆβτ , as deﬁned in Eq. (15), is Fisher consistent
for β0.

x
)
(
β
< ˆστ
(

β0
(

)

)

Proof: Consider the assumptions made in Theorem 1
which are the same assumptions made in Lemma 2 in [53].
This lemma states: if β ∈ B and β ≠ β0 it holds, for an M-
estimate of scale ˆσM

= b,

> 0 deﬁned by
ae
β
t
)
(
ˆσM
β
)
(
. Since for β ≠ β0
)
= ω

β
(
E

)
ρ1
[
β
(
β
(

at + c
)

B
(

)]

(

)

µ0 − µ
(

that ˆσM

β0
(

)

< ˆσM
ae
t

1For visual clarity, let ˆστ (ae
t (β)) =∶ ˆσM (β)

ˆσM (ae

)
t (β0)) =∶ ˆστ (β0), ˆστ (ae
t (β)) =∶ ˆστ (β) and

(25)

(26)

where

ω

B
(

)

= θ−1

B
(

θ0
)

B
(

φ−1
0
)

B
(

B
φ
(
)

)

= 1 +

ωiBi

(27)

∞

∑i=1

A6 on ρj, j = 1, 2, that

lim
n→∞

sup
β∈B0×[−d,d],c∈[h1/2,2h2]

(28)

(29)

(30)

(32)

and

c =

1 −
1 −

it follows by deﬁning

p
i=1 φi
q
i=1 θi

∑
∑

≠ 0

∆t

=

β
(

)

∞

∑i=1

ωiat−i + c

µ0 − µ
(

,
)

that

ˆσ2
τ

β
(

)

= ˆσ2

M

β
(

E
)

ρ2
[

(

β
(
)]
Using Lemma 3.1 (i) from [54] it then follows that

ρ2
[

E
)

(

M

)

= ˆσ2

ae
β
t
)
(
β
ˆσM
)]
)
(
β
at + ∆t
(
β
ˆσM
)
(

at

ˆσ2
τ

> ˆσ2

)

M

β
(

E
)

ρ2
[

β
(
≠ 0. Then, using Lemma 3.1 (ii) from [54],
is continuously differentiable, it is

β
(

(31)

ˆσM

)]

(

)

β
for all ∆t
and assuming that ρ2
(
sufﬁcient to show, for ˆσM > 0, that

x
)
(

)

= ˆσ2

M E

h

ˆσM
(

)

ρ2
[

(

at
ˆσM )]

is nondecreasing with respect to ˆσM , since A6 implies that

dh

ˆσM
(
dˆσM

)

= ˆσM E

2ρ2
[

(

at
ˆσM )

− ψ2

at
ˆσM )

at
ˆσM ]

(

≥ 0.

(33)

Lemma 2. states the almost sure convergence of the τ -
estimator of the innovations scale to the population value based
on the expectation operator.
Under the assumptions of Theorem 1, for any d > 0, it follows
that

lim
n→∞

sup
β∈B0×[−d,d]∣

ˆστ
n

an
(

β
(

))

− ˆστ

β
(

)∣

= 0 a.s..

(34)

Proof: The continuity and positivity of the M-scale func-
> 0 deﬁned in Eq. (25) was shown in Lemma 5
follows from

tional ˆσM
of [53]. The continuity and positivity of ˆστ
(30), as long as ρ2 satisﬁes A3. Let

β
(

β
(

)

)

(35)

(36)

and

h1 =

inf
β∈B0×[−d,d]

ˆστ

β
(

)

h2 =

sup
β∈B0×[−d,d]

ˆστ

β
(

.
)

Then h1 > 0 and h2 < ∞. According to Lemma 5 of [53], it
holds, for any d > 0, that
ˆσM
sup
n
β∈B0×[−d,d]∣

))
From Lemma 2 of [55], it holds, under the assumptions A3,

= 0 a.s..

an
(

lim
n→∞

β
(

β
(

− ˆσM

(37)

)∣

5

ae
t

β
)c
(

)

ρj

(

= 0 a.s..

(38)

)]∣

1
n − p

RRRRRRRRRRR

n

∑t=p+1
ae
t

−E

ρj
[

(

β
)c
(

Eq. (34) then follows from (37), (38) and (30).

Lemma 3
Under the assumptions of Theorem 1, there exists d > 0, such
that

lim
n→∞

inf
∣µ∣>d,(φ,θ)∈B0

inf

ˆστ
n

an
(

β
(

))

> σ0 + 1

a.s..

(39)

Proof: The proof is based on the one given in Lemma 6

of [53] which states that

ˆσM
n

inf

lim
n→∞

> σ0 + 1 a.s.,

inf
∣µ∣>d,(φ,θ)∈B0

an
(
where ρ1 has been replaced by ρj, j = 1, 2, and ρj is assumed
to be consistent with A3 and A6. Then, using the continuity
and positivity of ˆστ
and the deﬁnition of the τ -scale of
(30), (39) follows from (40).

β
(

(40)

))

β
(

)

β
(

Proof of Theorem 1: Take ξ > 0 arbitrarily small and
let d be as in Lemma 3. The continuity of the M-scale
> 0 deﬁned in (25) follows from Lebesgue’s
functional ˆσM
β
dominated convergence theorem. The continuity of ˆστ
follows from (30) as long as ρ2 satisﬁes A3. By Lemma 1
)
(
of this paper, there exists 0 < γ < 1 such that
min
β∈B0×[−d,d],∣∣β−β0∣∣≥ξ

≥ σ0 + γ.

(41)

ˆστ

)

β
(

)

By Lemma 2 of this paper, there exists n1, such that for n ≥ n1
ˆστ
(42)
n

≥ σ0 + γ

min
β∈B0×[−d,d],∣∣β−β0∣∣≥ξ

2

an
(

β
(

))

/

and

ˆστ
n

β0
(
By Lemma 3, there exists n2, such that for n ≥ n2
ˆστ
a.s..
n

≤ σ0 + γ

an
(

> σ0 + γ

))

4.

/

inf
∣µ∣>d,(φ,θ)∈B0

β
(

an
(
n1, n2

}

))
it holds that

ˆβτ − β0
∣∣

∣∣

Therefore, for n ≥ max
which proves the theorem.
{

(43)

(44)

< ξ,

Theorem 2. establishes, under an ARMA model, that the

BIP τ - is asymptotically equivalent to a τ -estimator.
Assume that yt follows (2) with at satisfying A1. Further,
assume that ρ1 and ρ2 are bounded, that ρ1 satisﬁes A3 and
< 1 for any compact
A5, that ρ2 satisﬁes A6, that P
at ∈
, and, ﬁnally, that η satisﬁes A4. Then, if yt is not white
set
(
noise, with probability 1, there exists n0, such that ˆβb
ˆβτ
for all n ≥ n0 and then ˆβ∗
τ

→ β0 a.s..

τ =

C)

C

Proof: Theorem 2 of [53] shows that

lim
n→∞

inf
β∈B

ˆσM
n

ab
n
(

β, ˆσ
(

φ, θ
(

)))

> σ0 + δ

a.s..

(45)

Starting from (45),

Differentiating (15) yields the following system of equations:

6

ˆστ
n

ab
n
(

inf
β∈B

lim
n→∞

β, ˆσ
(

φ, θ
(
follows from Lemmas 9 and 10 of [53] together with Eq. (30),
as long as ρ2 satisﬁes A3. Furthermore, in Theorem 1, it is
established that

> σ0 + δ

(46)

a.s.

)))

ˆβτ
(
and this proves the theorem.

an
(

lim
n→∞

ˆστ
n

= σ0

a.s..

))

(47)

Theorem 3. establishes the asymptotic normality of the

estimator for the ARMA model.
Let yt be as in (2),
let A1, A2, A3 be fulﬁlled and let
E
are
continuous and bounded functions. Then, the τ -estimator is
asymptotically normally distributed with

< ∞. Further, assume that dψτ (x)

and d2ψτ (x)

a2
t
[

dx2

dx

]

n − p
(

1/2

)

ˆβτ − β0
(

)

Ð→
D

0, Σ

N (

,
)

Σ =

σ2
0E
E2

[
dψτ (x)
dx

,

=

σ0
/
σ0

ψ2
τ
[
ψ′
τ

at
(
at
(

/

)]
)]

σ2C−1 0
0

c−2
0 )

(

where

with ψ′
τ

x
)
(

p
i=1 φ0i
q
i=1 θ0i
and C being the matrix of dimensions
with elements

1 −
1 −

c0 = −

∑
∑

(48)

(49)

(50)

ci,j =

cp+i,p+j

=

νkνk+j−i

if

i ≤ j ≤ p,

∞

∑k=0
∞

̟k̟k+j−i

if

∑k=0
∞

i ≤ j ≤ q,

(51)

(52)

ci,p+j = −

ci,p+j = −

Here φ−1
0

= 1 +

B
(

)

∑k=0
∞

̟kνk+j−i

vk̟k+i−j

if

if

∑k=0
∞
i=1 νiBi and θ−1
0

∑

i ≤ p, j ≤ p, i ≤ j, (53)

i ≤ p, j ≤ q, j ≤ i. (54)

B
(

)

= 1 +

∞
i=1 ̟iBi.

∑

Proof: According to Theorem 5 of [53], an M-estimator,
under the same assumptions that are made in this theorem, is
asymptotically normally distributed with

n − p
(

1/2

)

ˆβM − β0
(

)

Ð→
D

0, Σ

N (

,
)

(55)

where

Σ =

σ2
0E
E2

ψ2
[
ψ′
[

at
(
at
(

σ0
/
σ0

)]
)]
To prove Theorem 3, it must be shown that the τ -estimator
of the ARMA parameters satisﬁes an M -estimating equation.

c−2
0 .

(

)

/

σ2C−1 0
0

(56)

∇ˆστ
n

an
(

β
(

2

))

= 2ˆσM
an
n
(
1
n − p

β
n
(

∇ˆσM
n

an
(
at
ˆσM
n

))
ρ2

∑t=p+1
n

(

ψ2

+

1
n − p

∑t=p+1
ˆσM
an
n
(
)

ˆσM
n

(

β
(

))

⋅

))

β
(
β
(
an
(

))
)
β
(
β
(
an
(
−at

at

)
β
(
β
(

β
(

∇at
(
= 0.

)

⋅

)
))
∇ˆσM
an
n
(
)

β
(
(57)

)))

Here,

∇ˆσM
n

an
(

β
(

))

=−ˆσM

n

an
(

β
(

))

with ∇at

∂ae

t (β)
∂φi

, ∂ae
t (β)
∂θj

n
t=p+1 ψ1
(
n
t=p+1 ψ1

∑

ˆσM

at(β)
n (an(β))
)
at(β)
n (an(β))

ˆσM

∑
, ∂ae

t (β)
∂µ

T

(
, where

∇at

at

)

)

β
(
β
)(58)
(

=

β
(
)
(
∂ae
β
t
(
∂φi

)

= −θ−1

B
(

yt−i − µ

)(

)
,
)

1 ≤ i ≤ p,

(59)

∂ae
β
t
(
∂θj

)

= −θ−2

B
(

B
φ
(
)

yt−j − µ

)(

,
)

1 ≤ j ≤ q,

(60)

and

p
i=1 φi
q
∑
j=1 θj
∑
Replacing (58) in (57) and deﬁning

∂ae
β
t
(
∂µ

1 −
1 −

= −

)

.

(61)

n
t=p+1 2ρ2

=∑

at(β)
n (an(β))

ˆσM

−ψ2

(
n
t=p+1 ψ1

(

)
at(β)
ˆσM
n (an(β))

ˆσM

at(β)
n (an(β))
)
at(β)
n (an(β))

ˆσM

at(β)
n (an(β))

ˆσM

,

(62)
satisﬁes A6, the τ -estimate satisﬁes an M-estimating

∑

)

(

(63)

.

at

β
(
an
(

at

β
(
an
(
= 1

n

ψτ

)
β
∑t=p+1
(
with data adaptive ψτ given by

ˆσM
n

(

= 0

∇at

β
(

)

)

))

+ ψ2

ψτ

x
)
(

= Wn

β
(

ψ1
)

)

(

ˆσM
n

ˆσM
n

)
β
(
(
))
2x2 which results in Wn

)
(64)
β
Special cases are (i) ρ2
=
0 and the τ -estimator being equivalent to an LS estimator,
(
/
(ii) ρ1
which results in the τ -estimator being
equivalent to an S-estimator. The asymptotic value of the
estimator is deﬁned by

x
)
(

x
)
(

x
)
(

)
β
(

= ρ2

))

)

at

β
(
an
(

lim
n→∞

n

ψτ

∑t=p+1

ˆσM
n

(

at

β
(
an
(

)
β
(

))

∇at

β
(

)

)

= 0

(65)

and under suitable regularity conditions, i.e., ergodicity, the in-
terchange of limits is justiﬁed (e.g. by dominated convergence)
to yield

n

lim
n→∞

ψτ
∑t=p+1

at

β
(
an
(

)
β
(

ˆσM
n

(

∇an

)

))

β
(

)

=E

ψτ
[

β
at
)
(
β
ˆσM
(
)
)
(

∇at

.

β
(

)]
(66)

p + q + 1
(

×

p + q + 1
(

)

)

Wn

β
(

)

if ρ2
x
equation
)
(

IF

F

({

x, ξε, w
(

it

follows,

From (49),

free ARMA
for
model, where the innovations follow the standard Gaussian
distribution F , that the statistical efﬁciency of our proposed
estimator is given by:

the outlier

EFF
ψτ , F
(

)

=

σ2
0EF
σ2E2
F

[

ψ2
τ
ψ′
τ
[

at
(
at
(

/

/

σ0
σ0

.

)]
)]

E. Inﬂuence function (IF) analysis

To analyze the inﬁnitesimal effect of outliers on the asymp-
totic estimate, the IF is computed. Assume that the observa-
tions follow an ARMA model that is contaminated by additive
or replacement outliers as in (7) or (9). The temporal structure
of the outliers may be patchy or iid, depending on the choice
of the process ξε
t . The dependent data IF is deﬁned [33] as
the directional derivative at F

)}

; ˆβ∞

x
, i.e.,
(
)
ˆβ∞
= lim
↓ε
(
∂
ˆβ∞
∂ε

yε
(
yε
(
the limit exists. Here, F

F
(
F
(

=

)

− ˆβ∞

))

ε=0,

F
(

x
(

)))
(67)

))∣
ξε
, F
, F
x
provided that
yε
are the cdfs of xt, wt, ξε and yε
and F
t , respectively.
)
(
)
)
(
is the joint distribution of xt, wt, ξε.
x, ξε, w
Further, F
)
(
x, ξε, w
IF
F
is deﬁned for functionals which may
(
be computed as a solution of the estimating equation
(

w
(

; ˆβ∞
)

({

)}

)

)

∫

yt, ˆβ
˜ψ
(

(68)

= 0.

yt
(

dF
)
This class is quite large and contains both classical and robust
parameter estimators, e.g. the M-estimators, the generalized
M-estimators and estimators based on residual autocovariances
(RA-estimators) [33]. It will be shown that the τ -estimators
of the ARMA parameters are of the ˜ψ-type.
Proof: From (66) it follows, by deﬁning

yt, ˆβτ
˜ψ
(

= ψτ

β
at
)
(
β
ˆσM
)
(

)
and by noting the results stated in (68), that

)

(

∇at

β
(

)

(69)

β
at
)
(
β
ˆσM
)
(

∫ ψτ

dF
dF
)
)
This proves that the τ -estimator is a ˜ψ-estimator.

yt, ˆβτ
˜ψ
(

yt
(

β
(

= ∫

∇at

(

)

)

yt
(

)

= 0.
(70)

IF of the τ -estimator for an AR(1) with AO contamination

In general, the IF deﬁned by Eq. (67) is a curve on measure
space. It is useful to compute the IF of the τ -estimator for the
particular case of AR(1) models with additive outliers2.

Let yε

t follow (7) with xt satisfying (2) with p = 1, q = 0
and µ = 0. Further, let the ξε
t be an independently distributed
0-1 sequence that is independent of xt and wt. Then, as long
as the following assumptions are fulﬁlled:
(A7) ψτ
⋅
(A8) dψτ (x)
)
(
dx
φ1
a2
(A9)
(
∣

is continuous, odd, bounded, and ψτ
is bounded,
a1
ψτ
(
)

a2
∣
2To the best of our knowledge, all IFs that have been explicitly computed

∞
)
(
, with K < ∞,

φ1
(

φ1
(

≤ K

= 0,

))∣

)∣

in the literature concern AR(1) and MA(1) models only.

, ∂a2(φ1)ψτ (a1(φ1)))
∂a2(φ1)
K

∂a1(φ1)

(A10) ∂a2(φ1)ψτ (a1(φ1)))
(A11)
∣
∂(a1(φ1)ψτ (a1(φ1))))
∂a2(φ1)
w1

∂(a2(φ1)ψτ (a1(φ1))))
∂a1(φ1)

∣

,

∣
(A12) E
< ∞
the IF of the τ -estimator is given by
]

[∣

∣

∣
≤ K, with K < ∞,

≤

7

are continuous,

a2
∣

and

φ1
(

)∣

IF
F
(

w
(

, ˆβτ , φ
)
)

1 − φ2
1

1/2

= (
E

)
0
E
x0 + w0

⋅

1 − φ2
1

[(

)(

1/2ψτ
)

a1−φ1w0
(

)]
(71)

Here
∂x
independent standard normal random variables.

0 = E
E

ν2 ∂(ψτ (x))
[

x=u

]

∣

≠ 0, where ν and u are

Proof: With Theorem 1 and (70), as long as A7-A12,
hold, the proof follows the steps of Theorem 5.2 in [33], with
ψ

replaced by ψτ

x
(
)
If we now let P

x
.
)
(
wt = cw
(

= 1 for a constant cw, the IF has
the appealing heuristic interpretation of displaying the inﬂu-
ence of a contamination value cw on the estimator, similarly
to Hampel’s deﬁnition [56] for iid data. The computation of
the IF then requires the evaluation of the following integrals:

)

∞

0 = ∫
E

−∞

ν2 ∂

x
ψτ
(
(
∂x

))

∣x=u

1
2π

e− u2 +ν2

2 dudν

(72)

∞

∞
1 = ∫
−∞ ∫
E
f

∞
−∞ ∫
x1, x0; φ1
(

−∞ (
f
)

x0 + w0

1 − φ2
1

1/2ψτ
)
dx1dx0dw0
)

)(

w0
(

Here the following equality holds

a1 − φ1w0
(

⋅

)
(73)

x0; φ1
(

f
)
(x1 −φ1x0)2
σ2

f

x1, x0; φ1
(

)

= f

x1
(

x0; φ1
∣

(74)

)

where

2

)

f

=

(75)

e− 1

x1
(

x0; φ1
∣

1
√2πσ
√1 − φ2
√2πσ
Fig. 2 displays the IF of the proposed estimator and that
of the LS estimator for the above example of an AR(1) with
φ = −0.5 for independent AOs of magnitude cw for

x0; φ1
(

0(1−φ2
x2
1)
σ2

e− 1

(76)

=

f

)

1

.

2

ρ2

x
)
(

=

⎧⎪⎪⎪⎪⎪
⎪⎪⎪⎪⎪⎩

⎨

0.5x2
x
0.002x8 − 0.052x6
∣
∣
+0.432x4 − 0.972x2 + 1.792 if 2 <
x
> 3,
3.25
∣
∣

≤ 2

if

≤ 3

x
∣
∣
x
)
(

c1

= ρ2

x
(

= dρ2

x
/
(

x
)
(

(77)
, with c1 = 0.4050 and η
ρ1
dx.
By comparing this ﬁgure to Fig. 1 in [33], we conclude
)
that the gross-error sensitivity (GES), which is deﬁned as the
of our estimator is smaller than
supremum of
that of the generalized M-estimator (GM) and the residual
)∣
autocovariance (RA) estimator. The comparison with Fig. 4.2
of [6], leads to the deduction that the GES of our estimator is
also smaller than that of the median-of-ratios-estimator (MRE)
and ratio-of-medians-estimator (RME), which were published
in [6], [57].

, ˆβ, φ
)

IF
∣

w
(

F
(

)/

0

)
φ

,

ˆβ

,
w
F
(
F
I

−0.5

−1

−1.5

GES

IF(Fw, ˆβτ, φ)
IF(Fw, ˆβLS, φ)

−2
−10

−5

0
cw

5

10

Fig. 2. The IF of the proposed estimator and that of the LS estimator for
the AR(1) model with φ = −0.5 and for the case of independent AOs of
magnitude cw. The supremum of the IF is the gross-error sensitivity (GES).

IV. ALGORITHM

A. Estimating the AR parameters with a Robust Durbin-
Levinson Algorithm
To compute ˆβ∗

τ for the AR(p) model, a robust Durbin-
Levinson type algorithm is proposed, where the parameters
are recursively found for m = 1, . . . , p. Table I details the
algorithm for the AR(1) model, while Fig. 3 illustrates the
procedure by giving an example3. The top graph depicts the

Algorithm 1: Robust Durbin-Levinson Algorithm for the AR(1)
for p = 1, q = 0, ζ 0

= −0.99 ∶ ∆ζ0 ∶ 0.99

→ an(ζ 0

compute AR(1) innovations from (6) and (13)
n(ζ 0, ˆσ(ζ 0
compute τ -scale from (16), (18) with ˆσM
n

), ab

))

computed as in [19] pages 40-41
→ ˆστ (an(ζ 0

)), and ˆστ (ab

n(ζ 0, ˆσ(ζ 0

)))

end for

ﬁt polynomial to
(ζ 0,ˆστ (an(ζ 0
at ζ 0

Estimate AR(1) by
ˆφ1 = argmin

ζ

))), and (ζ 0,ˆστ (ab

n(ζ 0, ˆσ(ζ 0

))))

= −0.99 ∶ ∆ζ0 ∶ 0.99

{ˆστ (an(ζ)), ˆστ (ab

n(ζ, ˆσ(ζ)))} .

TABLE I
SUMMARY OF THE ROBUST DURBIN-LEVINSON FOR THE AR(1) MODEL.

results for yt = xt with φ1 = −0.5 for σ = 1, n = 1000. The
bottom graph displays an illustrative AO example, where ξε
t wt
in (7) produces 10 % equally spaced AOs of amplitude 10.

For a general AR(p) process, the parameters are found

recursively for m = 2, . . . , p by minimizing

ˆστ

ˆφm,m = argmin

ζ
(
at each order m in the same manner described in Table I, with
the help of the Durbin-Levinson recursion:

ζ, ˆσ
(

an
(

ab
n
(

ζ
(

)))}

(78)

, ˆστ

))

{

ζ

8

n(ζ , ˆσ(ζ )))

n(ab
ˆστ
n(an(ζ ))
ˆστ

ˆφ1 =-0.487

−0.5

0
ζ

0.5

1

3

2

)
ζ
(
τn
ˆσ

1

0
−1

3

2

)
ζ
(
τn
ˆσ

1

ˆφ1 =
-0.485

0
−1

−0.5

0
ζ

n(ζ , ˆσ(ζ )))

n(ab
ˆστ
n(an(ζ ))
ˆστ

0.5

1

Fig. 3. Example of ﬁnding −1 < ζ < 1 which minimizes ˆστ
n(an(ζ))and
ˆστ
n(ab
n(ζ, ˆσ(ζ))) for an AR(1) process with φ1 = −0.5 and σ = 1. (top)
yt = xt clean data example; (bottom) 10 % equally spaced AOs of amplitude
10.

B. Estimating the AR parameters with a Robust Forward-
Backward Algorithm

it

In classical AR estimation,

is well known [58] that
algorithms, which are based on forward and backward inno-
vations estimates, outperform the Durbin-Levinson method.
The following algorithm adapts the concept of minimizing
the arithmetic mean of the forward and backward innovations
estimates of scale.

The backward innovations estimates under the AR model

are recursively obtained for t = p + 1, . . . , n by:

ae,bw
t

β
(

)

= yt−p − µ −

p
∑
i=1

φi

yt−p+i − µ
(

)

(80)

Similarly, for the BIP-AR model the backward innovations
estimates are deﬁned recursively for n − p − 1, . . . , p + 1 by:
p
∑
i=1

= yt−p − µ −

ab,bw
t

yt−p+i − µ
(

β, σ
(

φi

)

)

+

p
∑
i=1 (

φiab,bw
t+i

β, σ
(

− φiση

ab,bw
β, σ
t+i
(
σ

)

(81)

(
)
, . . . , abk
The τ -scale estimtes of abk
abk
β
β
p+1
n
n
, . . . , ab,bk
ab,bk
)
(
(
)
(
β, ˆσ
β
β, ˆσ
n
n−p−1
β
computed analogously to (16) and (18) with ˆσ
(
))
(
(
(22).
(

ab,bk
p+1
(

β, ˆσ
(

β
(

))

=

=

)

))
β
and
(
))
β
are
as given in
(
)))

ζ
ˆφm,m = ⎧⎪⎪
ˆφm−1,i − ζ ˆφm−1,m−i
⎨
⎪⎪⎩

if
if

i = m
1 ≤ i ≤ m − 1

(79)

Table II details the forward-backward algorithm for the
AR(1) model. For a general AR(p) models, the parameters
are found recursively for m = 2, . . . , p by means of (79) and
evaluation of

3First evaluating (16), (18) on a coarse grid (e.g. using a step size of ∆ζ0 =
0.05) and then modeling the true curves by a polynomial is an optional step
to speed up the algorithm compared to evaluating (16), (18) on a very ﬁne
grid. Details are given in Sec. V-E.

ˆφm,m = argmin

ζ

ˆστ

{(

ˆστ
(

an
(

ab
n
(

ζ
(

))
ζ
(

))

+ ˆστ

+ ˆστ

abk
n
(

ζ
(
ab,bk
n
(

2,

)))/
ζ
(

)))/

2,

(82)

}

 
 
 
 
 
 
for each m analogously to the AR(1) model case.

Algorithm 2: Robust Forward-Backward Algorithm for the AR(1)
for p = 1, q = 0, ζ 0

= −0.99 ∶ ∆ζ0 ∶ 0.99

compute AR(1) innovations from (6),(13),(80) and (81)
(ζ 0, ˆσ(ζ 0

n(ζ 0, ˆσ(ζ 0
n
compute τ -scale from (16), (18) with ˆσM
n

→ an(ζ 0

), ab,bk

)), abk

n (ζ 0

), ab

))

computed as in [19] pages 40-41
→ ˆστ (an(ζ 0
n(ζ 0, ˆσ(ζ 0
)), ˆστ (ab
)), ˆστ (ab,bk
n (ζ 0
→ ˆστ (abk

)))
(ζ 0, ˆσ(ζ 0

n

)))

end for

ﬁt polynomial to
(ζ 0,ˆστ (an(ζ 0
(ζ 0,ˆστ (abk
n (ζ 0
at ζ 0

Estimate AR(1) by
ˆφ1 = argmin

ζ

))), (ζ 0,ˆστ (ab
))), (ζ 0,ˆστ (ab,bk

n

n(ζ 0, ˆσ(ζ 0

)))),
(ζ 0, ˆσ(ζ 0

))))

= −0.99 ∶ ∆ζ0 ∶ 0.99

{(ˆστ (an(ζ)) + ˆστ (abk

n (ζ)))/2,
n(ζ)) + ˆστ (ab,bk

n

(ˆστ (ab

(ζ)))/2, }

TABLE II
SUMMARY OF THE ROBUST FORWARD-BACKWARD ALGORITHM FOR THE
AR(1) MODEL.

C. Estimating the ARMA parameters

Determining an estimate for β with q > 0 requires ﬁnding
the β that minimizes (16) and (18). Since this is a non-convex
problem, the crucial point is to ﬁnd a starting point that is
sufﬁciently close to the true β. Due to the computational
complexity, except for some very simple cases (e.g. p + q ≤ 2),
it is not possible to perform an exhaustive grid search. The
following procedure to ﬁnd a robust starting point is therefore
proposed.

1) Robust starting point algorithm: From (10) it follows,
for the AR model, that the one step prediction of yt can be
computed recursively for t ≥ p + 1 via:

p
∑
i=1

φi

ˆyt = µ +

yt−i − µ − ab
(

ˆβ, ˆσ
(
From (83), outlier-cleaned observations are obtained for t ≥
p + 1 by computing

+ ˆση

(83)

) )

t−i

(

)

)

ab
t−i

ˆβ, ˆσ
(
ˆσ

.

(84)

t = yt − ab
y∗

t

ˆβ, ˆσ
(

ab
t

+ ˆση

ˆβ, ˆσ
(
ˆσ

)

(

)

)
To ﬁnd a starting point for the ARMA parameter estimation,
the data is ﬁrst cleaned from outliers using an AR(p) approx-
imation, which can be computed with the methods described
in Sec. IV-A and IV-B. The choice of p to be used in the
approximation is discussed in Sec. V-D. The starting point ˆβ0
for the BIP-τ ARMA parameter estimation algorithm can then
be computed, based on y∗
t , and by using any classical ARMA
parameter estimator, e.g. [59].

2) ARMA parameter estimation algorithm: From (16) and
2
(18), it is evident that the minimization of
ˆβb
2 can be solved by any nonlinear
and
)))
τ
LS algorithm, e.g. the Marquard algorithm. The initialization
(
ˆβ0, which is critical for the success of the Marquard algorithm

ab
n
(

ˆβb
(

ˆβτ
(

ˆστ
n
(

ˆστ
n
(

an
(

))))

τ , ˆσ

9

is found via the robust starting point algorithm that is described
above4.

V. NUMERICAL EXPERIMENTS

A. Quantile bias curve analysis

The maximum bias curve (MBC) provides information on
the maximum asymptotic bias of an estimator w.r.t. a given
fraction of contamination ε. For dependent data, the MBC is
deﬁned as for the iid case, but also depends on the outlier
model. In practice, in the dependent data setting, the MBC is
usually approximated by using Monte Carlo simulations [5],
[7], [19] according to

MBC

ε
(

)

ˆβn

= sup
cw ∣

ε, cw
(

)

− β

∣

(85)

The approximation is done by choosing, for MBC
, the
worst-case estimate of β over all Monte Carlo runs for a given
)
contamination probability ε. cw is a deterministic value that is
varied on a grid such that for each value of cw, the distribution
= 0.5.
of wt (see (9)) is given by Pr
wt = −cw
(

= Pr
wt = cw
(

More generally, let

ε
(

)

)

− β

.

(86)

ε
QBCα
(

= Qα

ˆβn

ε, cw
(

ε
(

ε
(

ε
(

.
)

)

{∣
denote the quantile bias curve, which states that α percent of
the sorted data is to the left of Qα. For example, QBC75
ε
represents the MBC obtained in 75 % of the Monte Carlo
)
(
runs for varying cw and ﬁxed ε. QBC50
corresponds to
the Median BC

ε
is the MBC
(

and QBC100

∣}

)

)

)

)

cw, ε
(

The quantile bias curves of the BIP τ -estimator for the
AR(1) model with independent AOs are provided in the bottom
graph of Fig. 4. The top graph shows the maximum bias for a
. As in [20], φ = 0.5 and the asymptotic
given pair of
value was approximated using n = 10000. It can be seen from
)
Fig. 4 (bottom) that the MBC saturates at 0.5 for ε ≥ 0.38.
This breakdown, however, only occurs for a minority of the
with α < 100. Similar
ε
data, as can be seen from the QBCα
to the BIP-MM-estimator of [20], it is observed that the bias
(
curves re-descend. This is easily explained by the fact that
for large values of ε the probability of obtaining patches of
outliers increases. The effect of the patches is to increase the
correlation, and therewith, to prevent a further shrinkage of
the estimates towards zero.

)

B. Comparison to existing robust methods

Our proposed estimator is compared numerically to the

following methods.

3σ cleaned ML-estimator (ML 3σ): This estimator is a
simple diagnostic robust method that is frequently used among
engineering practitioners [21]. It applies an ML-estimator
after a 3σ rejection, i.e., observations beyond three standard
deviations are ﬂagged as outliers. In this implementation,
the median and the normalized median absolute deviations
estimators of location and scale and the ML ARMA-estimator
by Jones [59] are used.

4We would like to highlight

the ARMA parameter estimation is
performed on the original data yt and AR approximation based outlier
cleaning is only used within the starting point algorithm to ﬁnd ˆβ0.

that

w

c

10

8

6

4

2

0
0

0.5

0.4

0.3

0.2

0.1

s
e
v
r
u
C
s
a
i
B

e
l
i
t
n
a
u
Q

0
0

10

0.5

0.4

0.3

0.2

0.1

C. Monte Carlo study on bias and standard deviation

Next, numerical experiments to assess the average perfor-
mance in terms of the bias and standard deviation for some
ARMA models with 4 ≤ p + q ≤ 8 are conducted. In all
cases, results represent averages over 1000 Monte Carlo runs.
Presenting results for such ranges of p, q is unusual in robust
ARMA parameter estimation, which usually considers ARMA
models of lower orders [5], [6], [19], [20], [33]. For our
proposed estimator, ρ1 and ρ2 are chosen as in (77) with two
choices of c1, as listed in Tables IV-VI and ∆ζ0 = 0.05. The
forward-backward algorithm and the initial starting point for
the ARMA are abbreviated by fb and init, respectively. To
be able to compute the Filt τ and BIP MM for such models,
both methods are initialized with a starting point that was
determined by our proposed robust starting point algorithm.

0.1

0.2

ε

0.3

0.4

MBC(ε)
QBC90(ε)
QBC80(ε)
QBC70(ε)
QBC50(ε)

0.1

0.2

ε

0.3

0.4

0.5

(left) The maximum bias and quantile bias curves of the BIP τ -
Fig. 4.
estimator for the AR(1) with AOs. The top graph shows the maximum bias
for a given pair of (cw, ε). The bottom plot represents the QBC obtained
assuming the worst possible cw for a ﬁxed ε.

BIP MM-estimator: The BIP MM-estimator is a sophis-
ticated robust estimator that has been proposed by Muler et al.
[20] who introduced the BIP model. MM-estimation consists
of computing in the ﬁrst step a highly robust estimate of the
error scale, and in the second step, using this scale estimate
to compute an efﬁcient M-estimate. Its performance strongly
depends on the starting point.

Filtered τ -estimator (Filt τ ): An alternative approach
to prevent the propagation of outliers is to combine robust
estimators with approximate conditional mean (ACM) type
ﬁlters (see [19], [27], [31], [60]). As a benchmark comparison,
the ﬁltered τ -estimator is considered. This estimator ﬁnds
the estimates ˆβ such that the τ -scale-estimate of the ﬁltered
innovations sequence is minimized. See [19] for a detailed
discussion of this estimator.

Implementation The implementation for the benchmark
comparison in the case of the ML and the 3σ cleaned ML
is straightforward. For the BIP MM [20] and the Filt τ [19],
no code is publicly available and the performance strongly
depends on the starting point, which cannot be found by a
grid search for the model orders considered. To provide a
fair comparison, these methods are initialized with the same
starting point as the BIP τ . To verify the correctness of
our implementations of these methods, we reproduced the
experiments conducted in [20] and obtained similar results
for the BIP MM. For the Filt τ , performance in the case of
ARMA models could not be obtained as reported in [19], [20].
For this case, only the Filt τ results for the AR models are
displayed, where the correctness of the implementation could
be veriﬁed by comparing results to those published in [19],
[20].

)∣

N (

∣N (

0, σw

, σ =
)

In our experiments, both patchy and independent replace-
ment and AOs of different types are considered. Best average
performance, i.e., best µ ˆβ is highlighted in bold font. Small
standard deviations are only a useful measure of performance
if the estimator does not break down, since breakdown can
mean that all estimates take a similar (false) value. For this
reason, µ ˆβ and σ ˆβ are displayed, instead of mean-squared
errors, in Tables IV-VI.
Example AR(4): φ =
1, µ = 0, n = 75
This model was investigated for the clean data case in [61].
0, σ2
AO1 refers to a single AO (ε = 0.0133), where wt ∼
w
with σw = 5σa. RO1 refers to a single replacement outlier
)
(ε = 0.0133), where wt ∼
with σw = 5σa. PAO20
refers to large positive patchy AOs (patch length = 20, i.e.,
)
N (
0, σ2
ε = 0.2667), where wt ∼
with σw = 5σx. PRO20 on
w
the other hand considers positive patchy replacement outliers
(patch length = 20, i.e., ε = 0.2667) whose standard deviation
is identical to the uncorrupted process, where wt ∼
with σw = σx. This is aparticularly challenging case.

−2.7607, 3.8106, −2.6535, 0.9238
(

)∣
Table IV summarizes the results. As could be expected, the
ML and ML 3σ only perform well in the clean data case,
i.e., yt = xt. The Filt τ -estimator performs reasonably well,
but is outperformed by all BIP estimators. The performance
difference between the BIP τ - and the BIP MM-estimators
is not signiﬁcant, which is reasonable, since they use the
same starting point. Best performance depends on the type
of outliers.
Example AR(7): φ =
−3.5258, 6.9530, −9.3074, 8.9473,
−6.1572, 2.8428, −0.7059
, σ = 1, µ = 0, n = 50
(
The frequency response obtained with these parameters cor-
)
responds to that of a Hamming-window based linear-phase
ﬁlter with normalized cutoff frequency at 0.5. AO1, AO2 and
AO3 refer to 1, 2, and 3 isolated AOs whose distribution is
wt ∼

with σw = σx.

0, σ2
w

0, σ2
w

Table V summarizes the results. As for the previous exper-
iment, the MLE performs best for the clean data case and the
BIP model based estimators provide best performance in the
presence of outliers. In this experiment, the BIP τ consistently
outperforms its robust competitors for all considered scenarios.
ARMA(4,4): φ =
, θ =
, σ = 1, µ = 0, n = 1000
0.0226, 0.8175, 0.0595, 0.0764
)
This model was investigated for the clean data case in [62].
(
)

0.100, 1.6600, 0.0930, 0.8649
(

∣N (

N (

)

 
 
 
 
)

The data is contaminated by independent AOs, with wt ∼

where σw = 10.

0, σ2
w
Table VI summarizes the results. As in the previous ex-
N (
periments, the BIP model based estimators exhibit a good
resistance against outliers (in this case up to 40 percent) and
also perform well for the clean data case. Table VI also
displays the robust starting point ˆβ0, for which an AR(8)
approximation was used. In this example, because the outliers
are easily detected by the 3σ rule, the performance of the 3σ
ML is surprisingly good up to ε = 0.25.
D. Choice of AR order in the robust starting point algorithm

Fig. 5 plots the Monte Carlo averaged mean absolute error
of the ARMA(4,4) parameter estimates for the above example
as a function of the order of the AR approximation that is used
to ﬁnd the starting point. For the clean data-case, the choice
of the order is not critical, since y∗
t ≈ yt, i.e., not much outlier
cleaning is performed for any of the AR models. In the case
of additive outliers the order should be chosen large enough
so that the cleaned values, i.e., the values for which y∗
t ≠
yt, approximately ﬁt into an ARMA(4,4) model. In practice,
numerical experiments suggest a value in the range of p + q ≤
p ≤ 2
is sufﬁcient to ﬁnd a starting point.

p + q
(

)
β
−
ˆβ
(

E
S
M
R

0.1

0.08

0.06

0.04

0.02

)

yt = xt
10 % AO

5

10
p

15

20

Fig. 5. Evaluation of the effect of the AR order on the ﬁnal estimates.

E. Computational complexity of the algorithm

Allthough a theoretical complexity analysis of the pro-
posed algorithm cannot be derived, information deduced from
Monte-Carlo averaged runtimes, is useful. Firstly, the main
computation time (on average 82.925 % for the ARMA(4,4)
example), is required to ﬁnd a robust starting point, since
Marquard algorithms can solve nonlinear LS problems very ef-
ﬁciently. Therefore, the focus of complexity analysis is on the
AR parameter estimation. Results are displayed for Algorithm
1; runtimes for Algorithm 2 are approximately twice as long.
Secondly, the computational complexity of robust methods far
exceeds that of non-robust methods. Thirdly, the runtimes of
the algorithms strongly depend on the available processing
power5, and, accordingly, the relative differences are of more
important interest than the absolute values.

Fig. 6 displays the reduction of computation time that is
achieved by ﬁrst evaluating (16) and (18) on a coarse grid

5The presented average runtimes are based on an Intel Core i5 CPU 760,

2.80 GHz x 4, where no parallel multicore processing has been performed.

11

and then interpolating the curves onto a grid of ∆ζ = 0.001
by using a least-squares polynomial ﬁt of order four compared
to evaluating (16) and (18) directly on ∆ζ = 0.001.

)
s
d
n
o
c
e
S
(

e
m
T

i

25

20

15

10

5

0
0

∆ζ 0 = 0.05
∆ζ 0 = 0.01
∆ζ 0 = 0.001

200

400

n

600

800

1000

Fig. 6. Computation times for p = 1 for different step sizes ∆ζ0 of the grid
on which the τ -scale is evaluated.

Fig. 7 plots the computation times for different AR model
orders p as a function of the sample size n. The increase is
a linear function of n. Further numerical experiments, which
are not reported here due to space limitations, show that the
complexity for a ﬁxed sample size is also linearly related to
p.

)
s
d
n
o
c
e
S
(

e
m
T

i

10
9
8
7
6
5
4
3
2
1
0
0

p = 1
p = 2
p = 3
p = 4
p = 5

200

400

n

600

800

1000

Fig. 7. Computation times for different AR model orders p as a function of
the sample size n. ∆ζ0 = 0.05

VI. REAL-DATA EXAMPLE

Finally, the real-data applicability of our proposed estima-
tor is illustrated by considering the practical application of
cleaning the R-R interval plots from errors that are introduced
by imperfections of an R-peak detection algorithm. The ECG
data that is shown, is part of a larger dataset that was recorded
at Technische Universit¨at Darmstadt in cooperation with the
Department of Psychology using the Biopac MP 150 System
and the AcqKnowledge 4.2 Software (Biopac Systems, 2011).
The data was sampled with a sampling frequency of 250 Hz.
To extract the R-R intervals, the QRS detector by Pan and
Tompkins [63] that was implemented by Clifford [64] was
applied. As can be seen from Fig. 8 (top), most of the R-
peaks of the ECG were correctly detected, however, because
of some occasional misdetections and false alarms, the R-R
interval series contains outliers.

The proposed estimator was used to outlier clean the R-R
interval series by applying (84) and using an AR(5) model. The

 
 
 
 
 
 
 
 
ˆR- ˆR

ˆR- ˆR(BIPτ )

8

6

4

2

)
s
(
.
t
n

i

R

-

R

0
1.5

1.25

1

0.75

)
s
(
.
t
n

i

R

-

R

500

1000 1500 2000 2500 3000 3500 4000

ECG
ˆR-Peaks
R-Peaks

ˆR- ˆR
ˆR- ˆR(BIPτ )
R-R

0.5
0
8
6
4
2
0
−2
4

)
V
m

(

G
C
E

)
s
(
.
t
n

i

R

-

R

3

2

1

0
300

310

320

330

340

350

360

Fig. 8. An application of the proposed estimator for cleaning of R-R interval
plots. From these plots HRV metrics are derived. The bottom two plots show
a 60 second except containing ground truth R-peaks and cleaned R-R plots.

result of the outlier cleaning is depicted in Fig. 8 (2nd from
top). To determine the correct model order, i.e., to estimate p,
robust model order selection criteria [25] were applied based
on the ﬁnal τ -estimate of the innovations scale, i.e.,

2

ˆσ∗
τ
(

/

/

)

)

)

p

)/

))

IC

(87)

p
(

p
)

n
(

n
(

= log

+ cpenp.

log
(

p + 1
(

n, cpen = log

p
(
The results of the robust model order selection are provided
in Table III. By choosing cpen = 2
n
and cpen = 2 log
n the criteria by Akaike, Schwarz
and Hannan and Quinn, stated respectively in [25], [61] are
obtained. The third plot of Fig. 8 details a particular outlier
contaminated region of the R-R series, for which we have
manually corrected the R-peak detection to obtain a ground
truth reference (black circles). The bottom plot displays the
outlier cleaned R-R interval series (green), the original one
derived from the faulty R-detection (red) and the one obtained
from the ground truth R-peak detection (black). By comparing
the plots, it becomes clear that, ﬁrstly, only the outlying R-
intervals are cleaned, and secondly, the correction is close to
the ground truth value. The chosen example is typical of the
results obtained for the entire data set. The full dataset and the
Matlab code to reproduce Fig. 8, are available upon request.

VII. CONCLUSION

A new robust and statistically efﬁcient estimator for ARMA
models called the bounded inﬂuence propagation (BIP) τ -
estimator was proposed and analyzed. Strong consistency and
asymptotic normality of the estimator for ARMA models that
are driven by independently and identically distributed (iid)
innovations with symmetric distributions were established. To
analyze the inﬁnitesimal effect of outliers on the estimator,
the inﬂuence function was derived. The gross error sensitivity
of the BIP τ -estimator was found to be lower than that

12

of existing robust estimators for an AR(1) with additive
outliers. Algorithms were provided to compute the estimates.
Numerical experiments were conducted to compare the ﬁnite
sample performance of the proposed estimator to existing
robust methodologies for different types of outliers both in
terms of average and of worst-case performance, as measured
by the maximum bias curve. A real-data example of outlier
cleaning for R-R interval plots derived from electrocardio-
graphic (ECG) data showed the practical applicability of the
proposed estimator. The proposed estimator is also useful in
many other real-world problems, e.g. speech processing, state
estimation or econometry, which can be modeled as an ARMA
that is disturbed by outliers or impulsive noise. Extensions
to the Seasonal Integrated ARMA (SARIMA) or Periodic
ARMA (PARMA) [10] as well as vectorial AR (VAR) will
be investigated in future.

ACKNOWLEDGMENTS

We thank the anonymous reviewers and Dr. Roy Howard
for their careful reading of our manuscript and their many
insightful comments and suggestions. This work was sup-
ported by the project HANDiCAMS which acknowledges the
ﬁnancial support of the Future and Emerging Technologies
(FET) programme within the Seventh Framework Programme
for Research of the European Commission, under FET-Open
grant number: 323944.

APPENDIX
RESULTS OF THE NUMERICAL EXPERIMENTS

REFERENCES

[1] Saeed V Vaseghi,

Advanced digital signal processing and noise

reduction, John Wiley & Sons, 2008.

[2] M.P. Tarvainen, J.K. Hiltunen, P.O. Ranta-aho, and Pasi A. Karjalainen,
“Estimation of nonstationary EEG with Kalman smoother approach:
an application to event-related synchronization (ERS),” IEEE Trans.
Biomed. Eng., vol. 51, no. 3, pp. 516–524, March 2004.

[3] T. Cassar, K.P. Camilleri, and S.G. Fabri,

“Order estimation of
multivariate ARMA models,” IEEE J. Select. Topics Signal Process.,
vol. 4, no. 3, pp. 494–503, June 2010.

[4] Simon Haykin, Adaptive radar signal processing, John Wiley & Sons,

2007.

[5] Y. Chakhchoukh, P. Panciatici, and P. Bondon, “Robust estimation of
SARIMA models: Application to short-term load forecasting,” in In
Proc. IEEE Workshop Statist. Signal Proces. (SSP 2009), Cardiff, UK,
Aug 2009.

[6] Y. Chakhchoukh, Contribution to the estimation of SARIMA (application
to short-term forecasting of electricity consumption),
Ph.D. thesis,
Universit´e de Paris-Sud, Facult´e des Sciences d’Orsay, Essonne, 2010.
[7] Y. Chakhchoukh, P. Panciatici, and L. Mili, “Electric load forecasting
based on statistical robust methods,” IEEE Trans. Power Syst., vol. 26,
no. 3, pp. 982–991, Mar. 2010.

[8] Y. Wang and F. Ding,

“Filtering-based iterative identiﬁcation for
multivariable systems,” IET Control Theory & Applications, vol. 10,
no. 8, pp. 894–902, 2016.

[9] R. S. Tsay, Analysis of ﬁnancial time series, John Wiley & Sons, 3

edition, 2010.

[10] A. J. Q. Sarnaglia, V. A. Reisen, and P. Bondon, “Periodic ARMA
models: Application to particulate matter concentrations,” in In Proc.
European Signal Processing Conference (EUSIPCO), Aug 2015, pp.
2181–2185.

[11] F. Ding, X. Liu, H. Chen, and G. Yao, “Hierarchical gradient based
and hierarchical least squares based iterative parameter identiﬁcation
for CARARMA systems,” Signal Process., vol. 97, pp. 31–39, 2014.

[12] F. Ding, Y. Shi, and T. Chen,

algorithms of nonstationary ARMA processes,”
Process., vol. 54, no. 3, pp. 1041–1053, 2006.

“Performance analysis of estimation
IEEE Trans. Signal

 
 
 
 
 
 
 
 
TABLE III
ROBUST BIP-τ BASED MODEL ORDER SELECTION [25] FOR THE R-R INTERVAL SERIES. THE CHOSEN ORDER IS HIGHLIGHTED WITH BOLD FONT.

13

0

1

2

3

4

5

6

7

8

9

10

AIC

SIC

-4.902

-6.587

-6.613

-6.604

-6.622

-6.648

-6.631

-6.658

-6.575

-6.612

-6.621

-4.902

-6.586

-6.611

-6.601

-6.617

-6.641

-6.623

-6.579

-6.564

-6.600

-6.608

HQC

-4.902

-6.587

-6.612

-6.603

-6.621

-6.646

-6.628

-6.658

-6.571

-6.608

-6.616

TABLE IV
MONTE CARLO EXPERIMENT FOR THE PARAMETER ESTIMATION OF AN AR(4) WITH φ = (−2.7607, 3.8106, −2.6535, 0.9238), σ = 1, µ = 0, n = 75.
c1,rob = 0.8100 AND c1,eﬀ = 0.4050 (CORRESPONDING TO 95 % EFFICIENCY AT THE GAUSSIAN ARMA MODEL). BEST PERFORMANCE IN TERMS OF
BIAS FOR EACH PARAMETER IS HIGHLIGHTED WITH BOLD FONT.

Parameter

Methods

yt = xt

σ ˆβ

µ ˆβ

φ1 = −2.7607

φ2 = 3.8106

φ3 = −2.6535

φ4 = 0.9238

ML
ML 3σ
MRE
BIP MM
Filt τ
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ c1,eﬀ,fb

ML
ML 3σ
MRE
BIP MM
Filt τ
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ c1,eﬀ,fb

ML
ML 3σ
MRE
BIP MM
Filt τ
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ c1,eﬀ,fb

ML
ML 3σ
MRE
BIP MM
Filt τ
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ c1,eﬀ,fb

-2.7272
-2.5130
-0.5599
-2.7708
-2.4317
-2.8001
-2.7622
-2.1619

3.7188
3.3230
-0.0155
3.6821
3.0866
3.7008
3.6940
2.5227

-2.5587
-2.2157
0.3785
-2.4526
-1.9435
-2.4317
-2.4726
-1.4176

0.8804
0.7843
0.3152
0.7683
0.6457
0.7445
0.7967
0.4166

0.0688
0.5603
7.7694
0.3543
0.5991
0.3791
0.2625
0.7679

0.1628
1.0152
10.2315
0.5565
1.1622
0.5765
0.3737
1.5461

0.1659
0.8773
10.2031
0.4686
1.1244
0.4590
0.2982
1.5031

0.0759
0.2596
7.7540
0.1970
0.4695
0.1892
0.1516
0.6525

AO1

RO1

PAO20

PRO20

µ ˆβ

-2.2174
-2.0327
-1.8573
-2.7554
-2.2119
-2.7729
-2.7225
-2.0896

2.5446
2.0327
0.6752
3.6407
2.6242
3.6508
3.6187
2.4165

-1.4027
-1.1477
1.0557
-2.4021
-1.5171
-2.3896
-2.4060
-1.3325

0.4233
0.3675
-0.9727
0.7465
0.4970
0.7337
0.7773
0.4050

σ ˆβ

0.4292
0.5837
39.5711
0.3693
0.6504
0.3868
0.2758
0.7534

0.9661
1.1239
23.0591
0.5737
1.2627
0.5857
0.3974
1.4910

0.9405
1.0241
23.1040
0.4761
1.2057
0.4689
0.3228
1.4436

0.3648
0.3648
39.5902
0.2000
0.4964
0.1951
0.1630
0.6285

µ ˆβ

-1.2482
-1.2186
-1.1769
-2.7376
-2.3171
-2.7519
-2.7104
-1.9569

0.8504
0.8198
1.9330
3.6323
2.8394
3.6408
3.6186
2.1916

0.0085
0.0179
-1.7660
-2.4108
-1.7128
-2.3965
-2.4196
-1.3322

0.0999
0.1084
1.5158
0.7644
0.5592
0.7506
0.7932
0.3469

σ ˆβ

0.5832
0.5705
23.5192
0.3787
0.6310
0.4146
0.3016
0.7430

0.9615
0.9068
51.8618
0.6037
1.2594
0.6232
0.4516
1.5078

0.7971
0.7421
51.8481
0.5139
1.2171
0.5056
0.3752
1.4763

0.2575
0.2689
23.4962
0.2091
0.5115
0.1999
0.1687
0.6480

µ ˆβ

-0.5266
-0.8544
-0.7473
-2.5936
-1.6414
-2.6086
-2.4561
-1.8346

-0.1449
0.4006
0.0027
3.3832
1.3569
3.3934
3.1170
1.7183

-0.0251
-0.0512
0.1724
-2.2155
-0.3875
-2.2099
-1.9697
-0.6067

-0.0244
0.1775
0.3240
0.7169
-0.0175
0.6981
0.6255
0.0618

σ ˆβ

0.1746
0.7296
4.2561
0.5879
0.4637
0.6220
0.7296
0.7139

0.2139
0.7454
8.8627
1.0585
0.9199
1.0608
1.2694
1.5822

0.2198
0.6078
8.9325
0.9490
0.9184
0.9373
1.1368
1.6190

0.1625
0.3107
4.3423
0.3658
0.4697
0.3606
0.4343
0.7886

µ ˆβ

-0.6473
-0.8150
-0.9731
-2.5145
-1.3558
-2.5230
-2.4326
-1.8537

-0.0556
0.1723
-0.8450
3.2687
1.0812
3.2737
3.0599
1.8517

0.0920
0.1490
2.0991
-2.1259
-0.2552
-2.1216
-1.9062
-0.7734

-0.0159
0.0232
-1.1864
0.7099
-0.004
0.6906
0.6001
0.1608

σ ˆβ

0.1665
0.2322
25.7938
0.6385
0.4685
0.6720
0.7028
0.6692

0.2135
0.3748
38.5007
1.1083
0.7998
1.1122
1.1247
1.5030

0.2243
0.3408
38.4327
0.9800
0.7627
0.9725
1.1457
1.5309

0.1560
0.2102
25.7253
0.3743
0.4027
0.3594
0.4464
0.7461

[13] R.S. Tsay, “Outliers, level shifts, and variance changes in time series,”

J. Forecasting, vol. 7, no. 1, pp. 1–20, Jan 1988.

[14] S.J. Deutsch, J. E. Richards, and J.J. Swain, “Effects of a single outlier
on ARMA identiﬁcation,” Commun. Stat. Theory, vol. 19, no. 6, pp.
2207–2227, 1990.

[15] G.M. Ljung, “On outlier detection in time series,” J. Roy. Stat. Soc. B,

pp. 559–567, 1993.

[16] C. Chen and L.-M. Liu, “Joint estimation of model parameters and
outlier effects in time series,” J. Am. Stat. Assoc., vol. 88, no. 421, pp.
284–297, 1993.

[17] D.W. Shin, S. Sarkar, and J.H. Lee, “Unit root tests for time series with
outliers,” Stat. Probabil. Lett., vol. 30, no. 3, pp. 189–197, 1996.
[18] X. de Luna and M. G. Genton, “Robust simulation-based estimation of
ARMA models,” J. Comput. Graph. Stat., vol. 10, no. 2, pp. 370–387,
2001.

[19] R. A. Maronna, R. D. Martin, and V. J. Yohai, Robust Statistics, Theory

and Methods, John Wiley & Sons, Ltd, 2006.

[20] N. Muler, D. Pe˜na, and V. J. Yohai, “Robust estimation for ARMA

models,” Ann. Statist., vol. 37, no. 2, pp. 816–840, 2009.

[21] A. M. Zoubir, V. Koivunen, Y. Chakhchoukh, and M. Muma, “Robust
estimation in signal processing: a tutorial-style treatment of fundamental

concepts,” IEEE Signal Process. Mag., vol. 29, no. 4, pp. 61–80, Jul
2012.

[22] B. Andrews, “Rank-based estimation for autoregressive moving average
time series models,” J. Time Ser. Anal., vol. 29, no. 1, pp. 51–73, 2008.
[23] H. Louni, “Outlier detection in ARMA models,” J. Time Series Anal.,

vol. 29, no. 6, pp. 1057–1065, 2008.

[24] B. Han, M. Muma, M. Feng, and A. M. Zoubir, “An online approach
for intracranial pressure forecasting based on signal decomposition and
robust statistics,” in Proc. IEEE Int. Conf. Acoustics, Speech and Signal
Processing (ICASSP), May 2013, pp. 6239–6243.

[25] M. Muma, “Robust model order selection for ARMA models based
in Proc. IEEE

on the bounded innovation propagation τ -estimator,”
Workshop Stat. Signal Process. (SSP), 2014, pp. 428–431.

[26] F. Strasser, M. Muma, and A. M. Zoubir, “Motion artifact removal in
ECG signals using multi-resolution thresholding,” in In Proc. European
Signal Processing Conference (EUSIPCO), Aug 2012, pp. 899–903.

[27] B. Spangl and R. Dutter,

“Estimating spectral density functions ro-

bustly,” REVSTAT-Statst. J., vol. 5, no. 1, pp. 41–61, 2007.

[28] T. Sch¨ack, C. Sledz, M. Muma, and A. M. Zoubir, “A new method
for heart rate monitoring during physical exercise using photoplethys-
mographic signals,” in 23rd European Signal Processing Conference
(EUSIPCO), Aug 2015, pp. 2666–2670.

14

TABLE V
MONTE CARLO EXPERIMENT FOR THE PARAMETER ESTIMATION OF AN AR(7) WITH
φ = (−3.5258, 6.9530, −9.3074, 8.9473, −6.1572, 2.8428, −0.7059), σ = 1, µ = 0, n = 50. c1,rob = 0.8100 AND c1,eﬀ = 0.4050 (CORRESPONDING TO
95 % EFFICIENCY FOR THE GAUSSIAN ARMA MODEL). BEST PERFORMANCE IN TERMS OF BIAS FOR EACH PARAMETER IS HIGHLIGHTED WITH BOLD
FONT.

Parameter

Methods

yt = xt (ε = 0)
σ ˆβ
µ ˆβ

AO1 (ε = 0.02)
σ ˆβ
µ ˆβ

AO2 (ε = 0.04)
σ ˆβ
µ ˆβ

AO3 (ε = 0.06)
σ ˆβ
µ ˆβ

φ1 = −3.5258

φ2 = 6.9530

φ3 = −9.3074

φ4 = 8.9473

φ5 = −6.1572

φ6 = 2.8428

φ7 = −0.7059

ML
ML 3σ
BIP MM
Filt τ
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ c1,eﬀ,fb

ML
ML 3σ
BIP MM
Filt τ
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ c1,eﬀ,fb

ML
ML 3σ
BIP MM
Filt τ
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ c1,eﬀ,fb

ML
ML 3σ
BIP MM
Filt τ
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ c1,eﬀ,fb

ML
ML 3σ
BIP MM
Filt τ
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ c1,eﬀ,fb

ML
ML 3σ
BIP MM
Filt τ
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ c1,eﬀ,fb

ML
ML 3σ
BIP MM
Filt τ
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ c1,eﬀ,fb

-3.4353
-2.7113
-2.6524
-2.2798
-2.6628
-3.0679
-3.1519

6.6280
4.9232
4.4563
3.3475
4.4540
5.5738
5.7895

-8.6849
-6.2725
-5.2197
-3.3303
-5.2245
-6.9467
-7.2974

8.1793
5.8583
4.5298
2.3825
4.5028
6.2768
6.6373

-5.5059
-3.9388
-2.8382
-1.1707
-2.8726
-4.1037
-4.3782

2.4878
1.7817
1.2617
0.3319
1.2568
1.8026
1.9573

-0.6006
-0.4276
-0.3060
-0.0315
-0.3026
-0.4275
-0.4836

0.1407
1.1828
0.9123
0.7397
0.8950
0.6986
0.5412

0.4396
2.7819
2.3185
1.9313
2.3239
1.9095
1.6229

0.7835
3.9425
3.4983
3.0250
3.4830
2.9714
2.7028

0.9335
3.8171
3.4874
3.2252
3.5052
3.0783
2.9851

0.7741
2.6327
2.4965
2.4465
2.4500
2.1997
2.2606

0.4318
1.2299
1.1567
1.2821
1.1616
1.0441
1.1562

0.1391
0.3322
0.3286
0.3800
0.3220
0.2847
0.3390

-1.3891
-1.0050
-2.7141
-1.8765
-2.7067
-2.9080
-2.7187

0.9911
0.6496
4.5704
2.4808
4.5626
5.1319
-4.4105

-0.0784
-0.0908
-5.3514
-2.1003
-5.3466
-6.2273
-4.9234

-0.3699
-0.0873
4.5605
1.2127
4.5408
5.4845
4.0069

0.1616
-0.0157
-2.7902
-0.3738
-2.8057
-3.4956
-2.4171

0.2015
0.0822
1.1540
-0.0237
1.1709
1.5027
0.9797

-0.1786
-0.0267
-0.2717
0.0746
-0.2623
-0.3498
-0.2208

0.0816
0.4860
0.8652
0.6726
0.8750
0.7939
0.7235

0.1631
0.7536
2.2581
1.5172
2.2650
2.1251
2.0701

0.1940
0.6495
3.3969
2.2103
3.4015
3.3143
3.3977

0.0907
0.4168
3.4649
2.2370
3.4663
3.4396
3.6532

0.2997
0.4344
2.4891
1.6336
2.4849
2.4699
2.6873

0.3534
0.4210
1.1919
0.8322
1.1992
1.1751
1.3511

0.2011
0.2700
0.3494
0.8322
0.3372
0.3150
0.3966

-1.3292
-1.1694
-2.5088
-1.3962
-2.4900
-2.6412
-1.9790

1.1240
0.9012
4.1243
1.3745
4.1149
4.4827
-2.7402

-0.6310
-0.4192
-4.8231
-0.7735
-4.8279
-5.3770
-2.7670

0.5177
0.3654
4.1789
0.2622
4.1722
4.7711
-2.1874

-0.6736
-0.5616
-2.6423
-0.0792
-2.6534
-3.1207
-1.3718

0.6885
0.5424
1.1253
0.0661
1.1353
1.4048
0.6580

-0.3281
-0.2460
-0.2709
-0.0290
-0.2693
-0.3563
-0.2053

0.0938
0.2662
1.0249
0.5125
1.0308
0.9534
0.7817

0.0961
0.3927
2.6441
0.9546
2.6449
2.5357
1.9888

0.1284
0.4520
3.9715
1.0865
3.9731
3.8943
2.9288

0.0930
0.3518
4.0830
0.8173
4.0740
4.0299
2.8919

0.1662
0.2634
2.9502
0.6021
2.9478
2.9066
2.0258

0.2012
0.2838
1.4610
0.4033
1.4474
1.3931
0.9747

0.1671
0.2013
0.4580
0.2101
0.4156
0.3952
0.2939

-1.0565
-0.9473
-2.3467
-1.2712
-2.3384
-2.5042
1.7116

0.5221
0.4482
3.8317
1.1059
3.8091
4.0770
2.0826

0.1217
0.1149
-4.4369
-0.4324
-4.4499
-4.6962
-1.7982

-0.0746
-0.0467
3.8235
0.0128
3.8067
3.9903
1.2030

-0.3720
-0.3264
-2.4079
0.0131
-2.4187
-2.5316
-0.6731

0.5798
0.4171
1.0264
0.0819
1.0199
1.1032
0.3310

-0.2811
0.1770
-0.2297
-0.0712
-0.2315
-0.2732
-0.1203

0.0902
0.2023
1.0882
0.4129
1.1021
0.9971
0.7821

0.1021
0.1939
2.6445
0.7301
2.6659
2.5960
1.9334

0.1206
0.2234
3.8166
0.8485
3.8060
3.9031
2.7958

0.0646
0.1656
3.7295
0.7325
3.7296
3.9442
2.7626

0.1138
0.2059
2.5409
0.6060
2.5386
2.7367
1.9763

0.1165
0.2795
1.1792
0.4401
1.1698
1.2651
0.9772

0.1514
0.2146
0.3147
0.2222
0.3227
0.3408
0.3004

TABLE VI
MONTE CARLO EXPERIMENT FOR THE PARAMETER ESTIMATION OF AN ARMA(4,4) WITH φ = (0.100, 1.6600, 0.0930, 0.8649),
θ = (0.0226, 0.8175, 0.0595, 0.0764), σ = 1, µ = 0, n = 1000. c1,rob = 0.8100 AND c1,eﬀ = 0.4050 (CORRESPONDING TO 95 % EFFICIENCY FOR THE
GAUSSIAN ARMA MODEL). BEST PERFORMANCE IN TERMS OF BIAS FOR EACH PARAMETER IS HIGHLIGHTED WITH BOLD FONT.

15

Parameter

Methods

φ1 = 0.100

φ2 = 1.6600

φ3 = 0.0930

φ4 = 0.8649

θ1 = 0.0226

θ2 = 0.8175

θ3 = 0.0595

θ4 = 0.0764

ML
ML 3σ
BIP MM
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ init

ML
ML 3σ
BIP MM
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ init

ML
ML 3σ
BIP MM
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ init

ML
ML 3σ
BIP MM
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ init

ML
ML 3σ
BIP MM
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ init

ML
ML 3σ
BIP MM
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ init

ML
ML 3σ
BIP MM
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ init

ML
ML 3σ
BIP MM
BIP τ c1,rob
BIP τ c1,eﬀ
BIP τ init

yt = xt

µ ˆβ
0.0959
0.0958
0.0980
0.0956
0.0958
0.0959

σ ˆβ
0.0187
0.0188
0.0244
0.0206
0.0188
0.0187

AO ε = 0.05
σ ˆβ
µ ˆβ
0.1426
0.0890
0.0201
0.0965
0.0244
0.0977
0.0215
0.0967
0.0215
0.0972
0.0212
0.0978

AO ε = 0.10
σ ˆβ
µ ˆβ
0.4413
0.0386
0.0236
0.0977
0.0272
0.1036
0.0263
0.1045
0.0271
0.1062
0.0282
0.1038

ε = 0.25

µ ˆβ
0.0635
0.0949
0.1135
0.1135
0.1280
0.1196

σ ˆβ
0.8285
0.0330
0.0485
0.0485
0.0644
0.0630

AO ε = 0.40
σ ˆβ
µ ˆβ
0.8561
-0.0527
0.6403
-0.0045
0.2488
0.0797
0.2475
0.0803
0.6239
0.0370
0.6374
0.0260

1.6539
1.6541
1.6517
1.6526
1.6537
1.6540

0.0879
0.0879
0.0885
0.0892
0.0877
0.0879

0.8578
0.8580
0.8572
0.8580
0.8579
0.8578

0.0189
0.0199
0.0188
0.0191
0.0187
0.0187

0.8156
0.8260
0.8171
0.8151
0.8148
0.8151

0.0530
0.0534
0.0540
0.0538
0.0529
0.0528

0.0733
0.0819
0.0720
0.0733
0.0729
0.0726

0.0207
0.0210
0.0284
0.0250
0.0209
0.0208

0.0178
0.0178
0.0251
0.0199
0.0178
0.0177

0.0197
0.0199
0.0320
0.0245
0.0203
0.0199

0.0427
0.0445
0.0471
0.0439
0.0427
0.0428

0.0428
0.0453
0.0463
0.0459
0.0425
0.0427

0.0461
0.0467
0.0479
0.0473
0.0460
0.0461

0.0371
0.0388
0.0373
0.0364
0.0372
0.0372

1.6339
1.6555
1.6303
1.6323
1.6377
1.6346

0.0729
0.0885
0.0870
0.0882
0.0876
0.0862

0.8456
0.8590
0.8415
0.8344
0.8409
0.8355

0.0677
0.0391
0.0382
0.0387
0.0371
0.0382

1.4043
1.0068
0.8504
0.8520
0.8513
0.8562

0.0674
0.0639
0.0625
0.0387
0.0606
0.0613

0.6128
0.2349
0.0965
0.0978
0.1005
0.0997

0.1136
0.0224
0.0250
0.0244
0.0257
0.0242

0.1166
0.0191
0.0214
0.0199
0.0192
0.0192

0.1124
0.0224
0.0299
0.0266
0.0267
0.0243

0.1519
0.0425
0.0468
0.0451
0.0433
0.0429

0.1167
0.0751
0.0578
0.0568
0.0521
0.0552

0.1067
0.0424
0.0499
0.0485
0.0458
0.0479

0.1146
0.0642
0.0503
0.0494
0.0514
0.0541

1.3544
1.6549
1.6169
1.6168
1.6242
1.6066

-0.0571
0.0904
0.0936
0.0918
0.0879
0.0885

0.6229
0.8591
0.8215
0.8171
0.8271
0.8036

0.0231
0.0540
0.0581
0.0581
0.0591
0.0620

1.2001
1.1269
0.8780
0.8816
0.8683
0.8831

-0.0498
0.0738
0.0701
0.0713
0.0698
0.0716

0.5031
0.3424
0.1211
0.1221
0.1163
0.1146

0.5024
0.0252
0.0349
0.0345
0.0404
0.0382

0.3544
0.0238
0.0250
0.0250
0.0257
0.0238

0.4511
0.0254
0.0381
0.0360
0.0428
0.0396

0.4417
0.0454
0.0505
0.0499
0.0474
0.0475

0.5005
0.0741
0.0786
0.0786
0.0837
0.0852

0.3111
0.0466
0.0552
0.0549
0.0527
0.0553

0.4012
0.0705
0.0668
0.0654
0.0723
0.0758

0.8911
1.6434
1.6049
1.6048
1.6036
1.5645

-0.2001
0.0884
0.0808
0.0808
0.0722
0.0874

0.2757
0.8580
0.8082
0.8082
0.8033
0.7516

0.0585
0.0768
0.0874
0.0874
0.1001
0.0966

0.8150
1.3654
0.9739
0.9739
1.0315
1.0706

-0.1909
0.0906
0.0745
0.0745
0.0662
0.0770

0.2551
0.5661
0.2192
0.2192
0.2694
0.2783

0.6289
0.0338
0.0638
0.0638
0.0724
0.0684

0.6868
0.0332
0.0316
0.0316
0.0387
0.0347

0.5881
0.0359
0.0792
0.0792
0.0962
0.0868

0.8319
0.0620
0.0673
0.0673
0.0800
0.0813

0.6334
0.0719
0.1058
0.1058
0.1281
0.1250

0.6486
0.0591
0.0646
0.0646
0.0700
0.0770

0.5656
0.0761
0.1012
0.1012
0.1254
0.1321

0.7407
1.1933
1.5321
1.5314
1.0778
1.0858

-0.2942
-0.1453
0.0272
0.0271
-0.1186
0.1071

0.2800
0.5339
0.7606
0.7606
0.4203
0.4319

-0.0594
-0.0202
0.0534
0.0528
0.0169
0.0111

0.6882
1.0539
1.1099
1.1105
0.9044
0.8974

-0.2856
-0.1388
0.0395
0.0397
0.1098
0.0948

0.2676
0.4389
0.3856
0.3857
0.3194
0.3159

0.6524
0.5861
0.1979
0.1978
0.5320
0.5371

0.6054
0.4816
0.1962
0.1967
0.4468
0.4402

0.5458
0.5154
0.1478
0.1476
0.4032
0.4094

0.8610
0.6457
0.2451
0.2461
0.6307
0.6448

0.6599
0.5808
0.2089
0.2093
0.5238
0.5340

0.5824
0.4203
0.1199
0.1191
0.3731
0.3656

0.5391
0.4663
0.1269
0.1268
0.3555
0.3798

[29] F. F. Molinares, V. A.Reisen, and F. Cribari-Neto, “Robust estimation
in long-memory processes under additive outliers,” J. Stat. Plan. Infer.,
vol. 139, no. 8, pp. 2511–2525, 2009.

[35] J. G. Gonzalez and G. R. Arce, “Optimality of the myriad ﬁlter in
practical impulsive-noise environments,” IEEE Trans. Signal Process.,
vol. 49, no. 2, pp. 438–441, Feb 2001.

[30] Y. S. Kharin and V. A. Voloshko, “Robust estimation of AR coefﬁcients
under simultaneously inﬂuencing outliers and missing values,” J. Stat.
Plan. Infer., vol. 141, no. 9, pp. 3276 – 3288, 2011.

[31] R. D. Martin and D. J. Thomson, “Robust-resistant spectrum estimation,”

Proc. IEEE, vol. 70, no. 9, pp. 1097–1115, Sept 1982.

[36] Y. Yang, H. He, and G. Xu, “Adaptively robust ﬁltering for kinematic

geodetic positioning,” J. Geodesy, vol. 75, no. 2, pp. 109–116, 2001.

[37] L. Mili, M. G. Cheniae, and P. J. Rousseeuw, “Robust state estimation
of electric power systems,” IEEE Trans. Circuits Syst. I, Reg. Papers,
vol. 41, no. 5, pp. 349–358, May 2002.

[32] S. A. Kassam and V. Poor, “Robust techniques for signal processing: a

[38] A. D. McQuarrie and C.-L. Tsai, “Outlier detections in autoregressive

survey,” Proc. IEEE, vol. 73, no. 3, pp. 433–481, Mar 1985.

models,” J. Comput. Graph. Stat., vol. 12, no. 2, pp. 450–471, 2003.

[33] R. D. Martin and V. J. Yohai, “Inﬂuence functionals for time series,”

Ann. Statist., vol. 14, no. 3, pp. 781–818, 1986.

[34] O. H. Bustos and V. J. Yohai, “Robust estimates for ARMA models,”

J. Am. Statist. Assoc., vol. 81, no. 393, pp. 155–168, 1986.

[39] P. Chareka, F. Matarise, and R. Turner, “A test for additive outliers
applicable to long-memory time series,” J. Econ. Dyn. Control, vol. 30,
no. 4, pp. 595 – 621, 2006.
[40] T. C. Aysal and K. E. Barner,

“Meridian ﬁltering for robust signal

16

processing,” IEEE Trans. Signal Process., vol. 55, no. 8, pp. 3349–
3962, Aug 2007.

[41] K. Liang, X. Wang, and T. H. Li, “Robust discovery of periodically
expressed genes using the Laplace periodogram,” BMC Bioinform., vol.
10, no. 1, pp. 1–15, 2009.

[42] R. Nunkesser, R. Fried, K. Schettlinger, and U. Gather, “Online analysis
of time series by the Qn estimator,” Comput. Stat. Data An., vol. 53,
no. 6, pp. 2354–2362, 2009.

[43] H. Dong, Z. Wang, and H. Gao, “Robust H∞ ﬁltering for a class of
nonlinear networked systems with multiple stochastic communication
delays and packet dropouts,” IEEE Trans. Signal Process., vol. 58, no.
4, pp. 1957–1966, Apr 2010.

[44] T. H. Li, “A nonlinear method for robust spectral analysis,” IEEE Trans.

Signal Process., vol. 58, no. 5, pp. 2466–2474, May 2010.

[45] M. A. Gandhi and L. Mili, “Robust Kalman ﬁlter based on a generalized
maximum-likelihood-type estimator,” IEEE Trans. Signal Process., vol.
58, no. 5, pp. 2509–2520, May 2010.

[46] C. Becker, R. Fried, and S. Kuhnt, Robustness and Complex Data
Structures: Festschrift in Honour of Ursula Gather, Springer Science
& Business Media, 2014.

[47] H. Dehling, R. Fried, and M. Wendler,

“A robust method for shift

detection in time series,” arXiv preprint arXiv:1506.03345, 2015.
[48] A. D¨urre, R. Fried, and T. Liboschik, “Robust estimation of (partial)
autocorrelation,” Wiley Interdisciplinary Reviews: Computational Statis-
tics, vol. 7, no. 3, pp. 205–222, 2015.

[49] R. C. Molinari, S. Guerrier, and M.-P. Victoria-Feser, “Robust inference
for time series models: a wavelet-based framework,” Archive ouverte
UNIGE (Preprint), 2015.

[50] P. J. Huber and E. M. Ronchetti, Robust Statistics, vol. 2, John Wiley

& Sons, Inc., Publication, 2009.

[51] V.J. Yohai and R.H. Zamar,

“High breakdown-point estimates of
regression by means of the minimization of an efﬁcient scale,” J. Amer.
Statist. Assoc., vol. 83, no. 402, pp. 406–413, 1988.

[52] V. J. Yohai, “High breakdown-point and high efﬁciency estimates for

regression,” Ann. Statist., vol. 15, pp. 642–656, 1987.

[53] N. Muler, D. Pe˜na, and V. J. Yohai, “Robust estimation for ARMA
models,” Tech. Rep., Universidad Torcuato di Tella, Universidad Carlos
III de Madrid and Universidad de Buenos Aires and CONICET, 2007.
[54] V. Yohai and R. Zamar, “High breakdown-point estimates of regression
by means of the minimization of an efﬁcient scale,” Tech. Rep. 84,
University of Washington,, Aug 1986.

[55] N. Muler and Yohai V. J., “Robust estimates for ARCH processes,” J.

Time Ser. Anal., vol. 23, no. 3, pp. 341–375, 2002.

[56] F. R. Hampel, “The inﬂuence curve and its role in robust estimation,”

J. Amer. Statist. Assoc., vol. 40, no. 1, pp. 375–382, 1974.

[57] Y. Chakhchoukh, “A new robust estimation method for ARMA models,”
IEEE Trans. Signal Process., vol. 58, no. 7, pp. 3512–3522, Jul 2010.
[58] R. L. Stoica, P.and Moses, Spectral analysis of signals, vol. 452, Pearson

Prentice Hall Upper Saddle River, NJ, 2005.

[59] R. H. Jones, “Maximum likelihood ﬁtting of ARMA models to time
series with missing observations,” Technometrics, vol. 22, no. 3, pp.
389–395, 1980.

[60] C. Masreliez, “Approximate non-Gaussian ﬁltering with linear state and
observation relations,” IEEE Trans. Autom. Control, vol. 20, no. 1, pp.
107–110, Feb 1975.

[61] A. D. R. McQuarrie and C.-L. Tsai, Regression and Time Series Model

Selection, World Scientiﬁc Publishing Co. Pte. Ltd., 1998.

[62] R. Moses, P. Stoica, B. Friedlander, and T. S¨oderstr¨om, “An efﬁcient
linear method of ARMA spectral estimation,” in Proc. IEEE Int. Conf.
Acoustics, Speech and Signal Processing (ICASSP), 1987, pp. 2077–
2080.

[63] J. Pan and W. J. Tompkins, “A real-time QRS detection algorithm,”
IEEE Trans. Biomed. Eng., vol. 1, no. 3, pp. 230–236, Mar 1985.
[64] G. D. Clifford, Signal processing methods for heart rate variability,
Ph.D. thesis, Department of Engineering Science, University of Oxford,
2002.

