7
1
0
2

r
a

M
7

]

R
P
.
h
t
a
m

[

1
v
7
6
4
2
0
.
3
0
7
1
:
v
i
X
r
a

Invariance Principles for Tempered Fractionally

Integrated Processes

Farzad Sabzikar1 and Donatas Surgailis2

September 24, 2018

1Iowa State University and 2Vilnius University

We discuss invariance principles for autoregressive tempered fractionally integrated moving

Abstract

averages in α-stable (1 < α

2) i.i.d.

innovations and related tempered linear processes

with vanishing tempering parameter λ

λ∗/N . We show that the limit of the partial sums

process takes a diﬀerent form in the weakly tempered (λ∗ = 0), strongly tempered (λ∗ =

),

∞

and moderately tempered (0 < λ∗ <

) cases. These results are used to derive the limit

distribution of the OLS estimate of AR(1) unit root with weakly, strongly, and moderately

≤

∼

∞

tempered moving average errors.

Keywords:

invariance principle; tempered linear process; autoregressive fractionally integrated moving

average; tempered fractional stable/Brownian motion; tempered fractional unit root distribution;

1

Introduction

The present paper discusses partial sums limits and invariance principles for tempered moving

averages

in i.i.d. innovation process

bd(k)

Xd,λ(t) =

∞

Xk=0

e−λkbd(k)ζ(t

k),

−

Z

t

∈

(1.1)

with coeﬃcients bd(k) regularly varying at inﬁnity as kd−1, viz.
ζ(t)
}
{
cd
Γ(d)

kd−1,

(1.2)

= 0,

→ ∞

cd 6

= 0

∼

d

k

,

where d

∈

R is a real number, d

=

1,

−

−

(1.2) we assume that

2, . . . and λ > 0 is tempering parameter. In addition to

∞

Xk=0
∞

Xk=0

kjbd(k) = 0,

0

j

d],

[
−

≤

≤

−∞

< d < 0,

bd(k)
|
|

<

,

∞

∞

Xk=0

bd(k)

= 0,

d = 0

1

(1.3)

(1.4)

 
 
 
 
 
 
6
6
6
An important example of such processes is the two-parametric class ARTFIMA(0, d, λ, 0) of tem-

pered fractionally integrated processes, generalizing the well-known ARFIMA(0, d, 0) class, writ-

ten as

Xd,λ(t) = (1

−

e−λB)−dζ(t) =

∞

Xk=0

e−λkω−d(k)ζ(t

k),

−

Z

t

∈

(1.5)

with coeﬃcients given by power expansion (1

e−λz)−d =

−

∞
k=0 e−λkω−d(k)zk,

< 1, where

z
|

|

Bx(t) = x(t
1) is the backward shift. Due to the presence of the exponential tempering
factor e−λk the series in (1.1) and (1.5) absolutely converges a.s. under general assumptions on

−

P

the innovations, and deﬁnes a strictly stationary process. On the other hand, for λ = 0 the

corresponding stationary processes in (1.1) and (1.5) exist under additional conditions on the

parameter d. See Granger and Joyeux [12], Hosking [13], Brockwell and Davis [5], Kokoszka and

Taqqu [15]. We also note (see e.g.

[10], Ch. 3.2) that the (untempered) linear process Xd,0 of

(1.1) with coeﬃcients satisfying (1.2) for 0 < d < 1/2 is said long memory, while (1.2) and (1.3)

for

−

1/2 < d < 0 is termed negative memory and (1.4) short memory, respectively, parameter d

usually referred to as memory parameter.

The model in (1.5) appeared in Giraitis et al. [8], which noted that for small λ > 0, Xd,λ has a

covariance function which resembles the covariance function of a long memory model for arbitrary

large number of lags but eventually decays exponentially fast.

[8] termed such behavior ‘semi

long-memory’ and noted that it may have empirical relevance for modelling of ﬁnancial returns.

Giraitis et al. [9] propose the semi-long memory ARCH(

∞

) model as a contiguous alternative to

(pure) hyperbolic and exponential decay which are often very hard to distinguish between in a

ﬁnite sample. On the other side, Meerschaert et al. [20] eﬀectively apply ARTFIMA(0, d, λ, 0) in

(1.5) for modeling of turbulence in the Great Lakes region.

The present paper obtains limiting behavior of tempered linear processes in (1.1) with small

tempering parameter λ = λN →
statistic is the partial sums process

0 tending to zero together with the sample size. The important

Sd,λ
N (t) :=

[N t]

Xk=1

Xd,λ(k),

[0, 1]

t

∈

of Xd,λ in (1.1) with i.i.d. innovations

ζ(t)
}
{

in the domain of attraction of α-stable law, 1 < α

(1.6)

2.

≤

Functional limit theorems for the partial sums process play a crucial role in the R/S analysis, unit

root testing, change-point analysis and many other time series inferences. See Lo [17], Phillips [21],

Giraitis et al. [9], Lavancier et al. [16] and the references therein.

We prove that the limit behavior of (1.6) essentially depends on how fast λ = λN tends to 0.

Assume that there exists the limit

lim
N→∞

N λN = λ∗ ∈

[0,

].

∞

(1.7)

2

Depending on the value of λ∗, the process Xd,λN will be called strongly tempered if λ∗ =
weakly tempered if λ∗ = 0, and moderately tempered if 0 < λ∗ <

,
∞
. While the behavior of Sd,λN

N

∞

in the strongly and weakly tempered cases is typical for short memory and long memory processes,
respectively, the moderately tempered decay λN ∼
stable motion of second kind (TFSM II) Z II

H,α,λ∗, H = d + 1/α > 0 deﬁned as a stochastic integral

) leads to tempered fractional

λ∗/N, λ∗ ∈

(0,

∞

Z II

H,α,λ(t)

:=

hH,α,λ(t; y)Mα(y. ),

ZR

R

t

∈

with respect to α-stable L´evy process Mα with integrand

hH,α,λ(t; y)

:= (t

+ λ

−

Z

0

y)
t

(s

−

H− 1
α
+

e−λ(t−y)+

y)

(
−

−
e−λ(s−y)+ s.,

H− 1
α
+

y)

H− 1
α
+

e−λ(−y)+

R.

y

∈

(1.8)

(1.9)

TFSM II and its Gaussian counterpart tempered fractional Brownian motion of second kind

(TFBM II) were recently introduced in Sabzikar and Surgailis [22], the above processes being

closely related to the tempered fractional stable motion (TFSM) and the tempered fractional Brow-

nian motion (TFBM) deﬁned in Meerschaert and Sabzikar [19] and Meerschaert and Sabzikar [18],

respectively. As shown in [22], TFSM and TFSM II are diﬀerent processes, especially striking are

their diﬀerences as t

.

→ ∞

As an application of our invariance principles we obtain the limit distribution of the OLS

βN of the slope parameter in AR(1) model with tempered ARTFIMA(0, d, λN , 0) errors

0 satisfying (1.7), under the null (unit root) hypothesis

estimator
and small tempering parameter λN →
β = 1.

b

In the case of (untempered) ARFIMA(0, d, 0) error process with ﬁnite variance and

standardized i.i.d. innovations, Sowell [24] proved that the distribution of the normalized statistic
N 1∧(1+2d)(
fractional Brownian motion with parameter H = d + 1

2 . Sowell’s [24] result extends the classical
unit root distribution for weakly dependent errors in Phillips [21] to fractionally integrated error

1) tends to the so-called fractional unit root distribution written in terms of

βN −
b

process, yielding drastically diﬀerent limits for 0 < d < 1/2, d = 0 and

1/2 < d < 0.

−

It turns out that in the case of ARTFIMA(0, d, λN , 0) error process with λN ∼
∞

distribution of

[0,

] and d. Roughly speaking (see Theorem 5.2 for precise

λ∗/N , the limit

βN depends on λ∗ ∈
b

formulation), in the moderately tempered case 0 < λ∗ <
similarly to Sowell [24] with FBM BH replaced by TFBM II BII

∞

the limit distribution of

βN writes

H,λ∗ and the convergence holds
< 1/2. Under strong tempering

b

for all

−

1/2 < d <

∞

in contrast to [24] which is limited to

d
|
|

→

λ∗ =

λN /N

, the limit distribution of

but takes a diﬀerent form in the cases d > 0, d = 0 and d < 0, d

βN is written in terms of standard Brownian motion
= N−; moreover, except for
the i.i.d. case d = 0, this limit is diﬀerent from Sowell’s limit in [24] and also from the unit root

∞

b

distribution in Dickey and Fuller [6] and Phillips [21].

3

6
The paper is organized as follows. Section 2 introduces ARTFIMA(p, d, λ, q) class and provides

basic properties of these processes. In Section 3 we deﬁne TFSM II/TFBM II. Section 4 contains

the main results of the paper (invariance principles). Section 5 discusses the application to unit

root testing. The proofs of the main results are relegated to Section 6.

In what follows, C denotes generic constants which may be diﬀerent at diﬀerent locations. We

fdd
= for the weak convergence and equality of distributions and ﬁnite-

,

,

fdd
−→

d
−→

d
write
= ,
dimensional distributions. N± :=
R. Lp(R) (p
R
kp =
f
k

, R+ := (0,
}
1) denotes the Banach space of measurable functions f : R
≥
px.
f (x)
|

2, . . .

{±

∞

±

1,

), (x)± := max(

→

(cid:0) R |

1/p.
(cid:1)

R,

x, 0), x
:=
±
∈
R with ﬁnite norm

R

2 Tempered fractionally integrated process

In this section, we deﬁne ARTFIMA(p, d, λ, q) process and discuss its basic properties. Let Φ(z) =

1

p
i=1 φizi and Θ(z) = 1 +
such that Φ(z) does not vanish on

P

P

−

C,
z
|
N+. Consider Taylor’s expansion

z
{

∈

q
i=1 θizi be polynomials with real coeﬃcients of degree p, q

0,

≥

1
}

| ≤

and Φ(z) and Θ(z) have no common zeros.

Let d

R

\

∈

Note that

where ωd(k) = Γ(k−d)
Θ(z)/Φ(z),
z
|
N−

| ≤

R

d

∈

\

Θ(z)
Φ(z)

(1

−

z)d =

∞

Xk=0

ad(k)zk,

< 1.

z
|

|

ad(k) =

k

Xs=0

ωd(k)ψ(k

s),

−

0,

k

≥

(2.1)

(2.2)

∞
j=0 ψ(j)zj =
Γ(k+1)Γ(d) , and ψ(j) are the coeﬃcients of the power series
1. We use the fact (see Kokoszka and Taqqu ([15], Lemma 3.1) that for any

P

ω−d(k) =

Γ(k + d)
Γ(k + 1)Γ(d)

= Γ(d)−1kd−1

Proposition 2.1 Let Θ(1)

= 0. For any d

∈

conditions (1.2)-(1.4). In particular, for any d

R

R

\

,

.

(cid:0)

k

1 + O(1/k)
(cid:1)
N−, the coeﬃcients a−d(k), k
0,

→ ∞

2, . . .

1,

(2.3)

0 satisfy

≥

a−d(k)

}

∈

∼

−

\ {

kd−1

Θ(1)
Φ(1)Γ(d)

−
1
k (cid:1)(cid:17)
(cid:0)
k
j=0 ψ(j)ω−d(k
0, see (2.2). It is
Ce−cj for some constants C, c > 0, see ([15], proof of Lemma 3.2). Note

1 + O

→ ∞

(2.4)

j), k

P

−

≥

(cid:16)

k

.

,

Proof. Let us prove (2.4). By deﬁnition, a−d(k) =

well-known that

Θ(1)/Φ(1) =

P

ψ(j)
|
| ≤
∞
j=0 ψ(j)

= 0. We have

a−d(k)
k

(cid:12)
(cid:12)
=

Xj=0

(cid:12)
(cid:12)

−

(Θ(1)/Φ(1))ω−d(k)
(cid:12)
(cid:12)
ω−d(k)

ω−d(k

j)

−

−

ψ(j)
(cid:0)

(cid:1) −

3

ω−d(k)

Xj>k

ψ(j)
(cid:12)
(cid:12)

ℓk,i,

≤

Xi=1

4

6
6
where

ℓk,1

:=

ℓk,2

:=

X0≤j≤k1/4

ψ(j)
|(cid:12)
|
(cid:12)

ω−d(k

j)

−

−

,

ω−d(k)
(cid:12)
(cid:12)

Xk1/4<j≤k

ψ(j)
|

|(cid:0)|

ω−d(k

j)
|

−

+

ω−d(k)
|

|(cid:1)

,

and ℓk,3 :=
Similarly, ℓk,2 ≤
ℓ′′
k,2), where ℓ′′

ω−d(k)
|
|
P
Ce−ck1/4
k,2 := kd−2

j>k |

ψ(j)
| ≤
k max1≤j≤k |
ψ(j)
j≥0 |
|

Ckd−1

P
ω−d(j)
|
= O(kd−2) and

P

j>k e−cj = o(kd−2) since ψ(j) decay exponentially.
= o(kd−2). Using (2.3) we obtain
k,1 +

C(ℓ′

ℓk,1| ≤
|

ψ(j)
|

|(cid:0)

kd−1

(k

−

−

j)d−1

= kd−1

(cid:1)

X0≤j≤k1/2

ψ(j)
|

|(cid:16)

1

1

−

− (cid:0)

j
k

)d−1

(cid:17)

ℓ′
k,1

:=

≤

proving

a−d(k)

X0≤j≤k1/4
Ckd−2

j

ψ(j)
|
|

= O(kd−2)

Xj≥0

= O(kd−2) and hence (2.4) in view of (2.3). Thus, a−d(k),

(cid:12)
(cid:12)

−

(Θ(1)/Φ(1))ω−d(k)
(cid:12)
(cid:12)

d

= 0 satisfy (1.2). Condition (1.4) is obvious from a0(k) = ψ(k) and properties of ψ(k) stated

above.

It remains to prove (1.3). Let j <

z
Θ(z)/Φ(z) is analytic on
{
∞
k=0 a−d(k)zk = Ψ(z)(1
i
r=0
(cid:1)
(cid:0)
∞
k=0 k(k

∂rΨ(z)
∂zr
1)

z=1
(k

P

P

i
r

(cid:12)
(cid:12)
· · ·

−

−

a−d(k)
(
∈
|
}
∃
z)−d is j times diﬀerentiable on

d < j + 1 for some j = 0, 1, . . . . Then since Ψ(z) :=
Ckd−1, see (2.4), the function
and ∂i

δ > 0) and

−
1+δ

z)−d

| ≤

z
|

C,

| ≤
1
| ≤
}
∞
k=i k(k

z
{|
j. Hence, 0 =

z=1 =
∂zi Ψ(z)(1
−
(cid:12)
(cid:12)
i+1)a−d(k) =
(k
1)
j, proving (1.3) and the proposition, too. (cid:3)

· · ·

P

−

−

i

−
∂i−r(1−z)−d
∂zi−r
i + 1)a−d(k) for any 0

z=1 = 0, 0

≤

(cid:12)
(cid:12)

i

≤

P
Deﬁnition 2.2 Let the autoregressive polynomials Θ(z), Φ(z) of degree p, q satisfy the above con-

≤

≤

ditions, and d

E

ζ(0)
|
|

<

∞

R

N−, λ

ζ(t), t
{
. By ARTFIMA(p, d, λ, q) process with innovation process ζ we mean a stationary

be a stationary process with

0. Moreover, let ζ =

≥

∈

∈

\

}

Z

moving-average process Xp,d,λ,q =

Xp,d,λ,q(t), t
{

∈

Z

}

deﬁned by

Xp,d,λ,q(t) =

∞

Xk=0

e−λka−d(k)ζ(t

k),

−

Z

t

∈

(2.5)

where the series converges in L1.

Remark 2.3 (i) For λ = 0 and

d
|
|

< 1/2 and i.i.d. innovations with zero mean and unit variance,

ARTFIMA(p, d, 0, q) process Xp,d,0,q coincides with ARFIMA(p, d, q) process, see e.g. Brockwell

and Davis [5]. Particularly, Xd,0 = X0,d,0,0 in (2.5) is a stationary solution of the AR(

∞

B)dXd,0(t) =

(1

−

∞

Xj=0

ωd(j)Xd,0(t

j) = ζ(t)

−

) equation

(2.6)

and the series in (2.5) and (2.6) converge in L2, meaning that Xd,0 is invertible.

5

6
(ii) For λ = 0 and zero mean i.i.d. α-stable innovations, 1 < α < 2, the deﬁnition of Xp,d,0,q in

Deﬁnition 2.2 agrees with the deﬁnition of ARFIMA(p, d, q) process in [15], who showed that the

series in (2.5) converges a.s. and in L1 for d < 1

1
α .

−

Proposition 2.4 Let Θ(z), Φ(z) satisfy the above conditions and λ > 0. Then the series in (2.5)
N− hence ARTFIMA(p, d, λ, q) process Xp,d,λ,q in Deﬁnition
2.2 is well-deﬁned for arbitrary (stationary) innovation process ζ with ﬁnite mean. Moreover, if

converges in L1 for any d

R

∈

\

Θ(z)
|
|

> 0,

z
|

| ≤

1 then Xp,d,λ,q is invertible:

ζ(t) =

∞

Xk=0

e−λk

ad(k)Xp,d,λ,q(t

k),

−

e

ad(k) zk =

Φ(z)
Θ(z)

(1

−

z)d,

< 1

z
|

|

∞

Xk=0

e

where

and the series in (2.7) converges in L1.

(2.7)

(2.8)

Proof. The convergence in L1 of the series in (2.5) follows from (2.4). To show invertibility of

these series, note that by Proposition 2.1 the coeﬃcients in (2.8) satisfy the bound
Ck−d−1, k
≥
Hence, e−λk

| ≤
N+.
R implying the convergence in L1 of the series in
< 1. (cid:3)

(2.7). Finally, equality in (2.7) follows from identity 1 =

N+, and an exponential bound

Ce−λkk−d−1, for any d

1, c > 0 for d
e

ad(k)
|

ad(k)
|

ad(k)
|

Ce−ck, k

1 for d

z)−d

z)d

| ≤

| ≤

≥

R

∈

∈

∈

\

,

e

Θ(z)
Φ(z) (1

−

−

(cid:1)(cid:0)

z
|

|

(cid:1)

e
Φ(z)
Θ(z) (1

(cid:0)

Proposition 2.5 describes some second order properties of ARTFIMA(p, d, λ, q) with standard-

ized innovations.

Proposition 2.5 Let Xp,d,λ,q be ARTFIMA(p, d, λ, q) process in (2.5), d

N−, λ > 0,
, Eζ(0) = 0, Eζ 2(0) = 1. Then EXp,d,λ,q(t) =
}

R

∈

\

with standardized i.i.d.
0, EX 2

p,d,λ,q(t) =

∞
k=0 e−2λka2

−d(k) <

innovations

ζ(t), t
{

∈

Z

and

∞

(i) The spectral density of Xp,d,λ,q is given by

P

h(x) =

2

1
2π (cid:12)
(cid:12)
(cid:12)
(cid:12)

Θ(e−ıx)
Φ(e−ıx) (cid:12)
(cid:12)
(cid:12)
(cid:12)

(ii) The covariance function of X0,d,λ,0 is given by

2e−λ cos x + e−2λ)−d,

(1

−

π

−

≤

x

≤

π.

γd,λ(k) = EX0,d,λ,0(0)X0,d,λ,0(k) =

e−λkΓ(d + k)
Γ(d)Γ(k + 1) 2F1(d, k + d; k + 1; e−2λ),
where 2F1(a, b; c; z) is the Gauss hypergeometric function (see e.g. [11]). Moreover,

γd,λ(k)
(cid:12)
(cid:12)

Xk∈Z (cid:12)
(cid:12)

<

,

∞

γd,λ(k) = (1

e−λ)−2d

−

Xk∈Z

and

(2.9)

(2.10)

γd,λ(k)

∼

Akd−1e−λk,

k

→ ∞

, where A = (1

−

e−2λ)−dΓ(d)−1.

(2.11)

6

Proof. (i) From the transfer function (Θ(e−ıx)/Φ(e−ıx))(1
that h(x) = 1
−2d, where
|

2
Θ(e−ıx)/Φ(e−ıx)
|

e−ıx−λ

2π |

1
|

−

−
1
|

−

e−ıx−λ)−d of the ﬁlter in (2.5) we have
2e−λ cos(x) + e−2λ,

e−ıx−λ

2 = 1
|

−

proving part (i). (ii) (2.9) follows from γd,λ(k) =

<
e−λ)−2d. Finally, (2.11) is proved in ([8], (4.15)).

π
−π cos (kx)h(x) x. and ([11], Eq. 9.112). The
, see (2.3), and the second one from
(cid:3)

R
e−λj ωd(j)
|
|

j∈Z

P

∞

ﬁrst relation in (2.10) follows from

k∈Z γd,λ(k) = 2πh(0) = (1

−

P

3 Tempered fractional Brownian and stable motions of second

kind

This section contains the deﬁnition of TFBM II/TFSM II and some of its properties from Sabzikar

and Surgailis [22]. The reader is referred to the aforementioned paper for further properties

of these processes including relation to tempered fractional calculus, relation between TFBM

II/TFSM II and TFBM/TFSM, dependence properties of the increment process (tempered frac-

tional Brownian/stable noise), local and global asymptotic self-similarity.

For 1 < α

2, let Mα =

}
dent increments and characteristic function

≤

∈

Mα(t), t
{

R

be an α-stable L´evy process with stationary indepen-

EeıθMα(t) = e−σα|θ|α|t|

1−ıβ tan(πα/2)sign(θ)
(cid:1)

,

(cid:0)

R,

θ

∈

(3.1)

where σ > 0 and β
1, 1] are the scale and skewness parameters, respectively. For α = 2,
M2(t) = √2σB(t), where B is a standard Brownian motion with variance EB2(t) = t. Stochastic
Lα(R) as α-stable random variable with
integral Iα(f )

f (x)Mα(x. ) is deﬁned for any f

[
−

∈

∈

characteristic function

≡ R

EeıθIα(f ) = exp

σα

θ
|

α
|

{−

α
f (x)
|

Z |

1

(cid:0)

−

ıβ tan(πα/2)sign(θf (x))
(cid:1)

,
x. }

R.

θ

∈

(3.2)

see e.g. [23, Chapter 3].

For t

∈

R, H > 0, 1 < α

in (1.9). Note hH,α,λ(t;

)
·

≤

∈

2, λ
Lα(R) for any t

≥

0 consider the function y

7→
R, λ > 0, 1 < α

∈

hH,α,λ(t; y) : R

R given

→

2, H > 0 and also for

≤

(0, 1). We will use the following integral representation of (1.9) (see [22]).

λ = 0, 1 < α
For H > 1
α :

2, H

≤

∈

For 0 < H < 1
α :

hH,α,λ(t; y) = (H

1
α )

−

t
0 (s

−

R

α −1

H− 1
+

y)

e−λ(s−y)+ s..

hH,α,λ(t; y) = (H

1

α ) 


−



t
0 (s
−
∞
t (s

R
− R

α −1

H− 1
+

y)

H− 1
+

y)

−

e−λ(s−y)+ s.,
α −1

e−λ(s−y)+ s. + λ

y < 0,

1

α −HΓ(H

1
α ),

−

0.

y

≥

7

(3.3)

(3.4)

b > 0.

∀
(iii) Z II

Deﬁnition 3.1 Let Mα be α-stable L´evy process in (3.1), 1 < α

for t

∈

R, the stochastic integral

2 and H > 0, λ > 0. Deﬁne,

≤

Z II

H,α,λ(t)

:=

hH,α,λ(t; y)Mα(y. ).

Z

(3.5)

The process Z II

H,α,λ =

Z II
{

H,α,λ(t), t

R

}

∈

will be called tempered fractional stable motion of second

kind (TFSM II). A particular case of (3.5) corresponding to α = 2

BII

H,λ(t)

:=

1
Γ(H + 1

2 ) Z

hH,2,λ(t; y)B(y. )

(3.6)

will be called tempered fractional Brownian motion of second kind (TFBM II).

The next proposition states some basic properties of TFSM II Z II

H,α,λ.

Proposition 3.2 ([22])

(i) Z II

H,α,λ in (3.5) is well-deﬁned for any t

R and 1 < α

∈

≤

2, H > 0, λ > 0, as a stochastic

integral in (3.2).

(ii) Z II

over, it satisﬁes the following scaling property:

H,α,λ in (3.5) has stationary increments and α-stable ﬁnite-dimensional distributions. More-
Z II
,
(cid:9)

H,α,λ(bt), t

H,α,bλ(t), t

bH Z II

fdd
=

R

R

∈

∈

(cid:8)

(cid:9)

(cid:8)

H,α,λ in (3.5) has a.s. continuous paths if either α = 2, H > 0, or 1 < α < 2, H > 1/α

hold.

4

Invariance principles

In this section, we discuss invariance principles and the convergence of (normalized) partial sums

process

Sd,λ
N (t) :=

[N t]

Xk=1

Xd,λ(k),

[0, 1]

t

∈

(4.1)

of tempered linear process Xd,λ in (1.1) with i.i.d.

innovations belonging to the domain of at-

traction of α-stable law, 1 < α

≤

2 (see below). We shall assume that the tempering parameter

λ

λN →

≡

0 as N

→ ∞

and following limit exists:

lim
N→∞

N λN = λ∗ ∈

[0,

].

∞

(4.2)

Recall that Xd,λN is said strongly tempered if λ∗ =
tempered if 0 < λ∗ <

∞

. We show that the limits of the partial sums process in (4.1) exist under

, weakly tempered if λ∗ = 0, and moderately

∞

condition (4.2) and depend on λ∗, d, α; moreover, in all cases these limits belong to the class of

TFSM II processes deﬁned in Section 3.

8

Deﬁnition 4.1 Write ζ

D(α), 1 < α

2 if

≤

∈

(i) α = 2 and Eζ = 0, σ2 := Eζ 2 <

, or

∞

(ii) 1 < α < 2 and there exist some constants c1, c2 ≥
x
x) = c1 and limx→−∞ |

αP(ζ
|

≤

x) = c2; moreover, Eζ = 0.

0, c1 + c2 > 0 such that limx→∞ xαP(ζ >

Condition ζ

∈

D(α) implies that r.v. ζ belongs to the domain of normal attraction of an

α-stable law. In other words, if ζ(i), i

Z are i.i.d. copies of ζ then

∈

N −1/α

[N t]

Xi=1

ζ(i)

fdd
−→

Mα(t),

N

,

→ ∞

(4.3)

where Mα is an α-stable L´evy process in (3.1) with σ, β determined by c1, c2, see ([7], pp. 574-581).

We shall use the following criterion for convergence of weighted sums in i.i.d. r.v.s. See ([10],

Prop. 14.3.2), [2], [14].

Proposition 4.2 Let 1 < α

≤

ζ(t)

∈

D(α) with real coeﬃcients gN (t), t

if α = 2 and a function g

∈

∈
Lp(R) such that the functions

2 and Q(gN ) =

t∈Z gN (t)ζ(t) be a linear form in i.i.d. r.v.s
[1, α) if α < 2, p = 2

Z. Assume that there exists p

P

∈

(4.4)

(4.5)

gN (x) := N 1/αgN ([xN ]),

R

x

∈

e

satisfy

Then Q(gN )

Write

D[0,1]
−→

0

(N

).

g

gN −
k
e

kp →
g(x)Mα(x. ), where Mα is as in (4.3) and (3.1).

d
−→ R
for weak convergence of random processes in the Skorohod space D[0, 1] equipped

→ ∞

with J1-topology, see [4].

In Theorem 4.3 below, Xd,λN is a tempered linear process of (1.1) with i.i.d.

innovations
N− satisfying (1.2)-(1.4), and tempering
) satisfying (4.2). W.l.g., we shall assume that the asymptotic

0, d

≥

R

∈

\

∈

2, coeﬃcients bd(k), k

ζ(t)
D(α), 1 < α
≤
parameter 0 < λN →
constant cd in (1.2)-(1.4) equals 1: cd = 1

→ ∞

0 (N

d

∀

∈

R

\

N−.

Theorem 4.3 (i) (Strongly tempered process.) Let λ∗ =

and d

R

\

∈

∞

N−. Then

N − 1

α λd

N Sd,λN

N (t)

fdd
−→

Mα(t),

(4.6)

where Mα is α-stable L´evy process in (4.3). Moreover, if α = 2 and E
then

p <
ζ(0)
|
|

∞

for some p > 2

N − 1

2 λd

N Sd,λN

N (t)

D[0,1]
−→

σB(t),

(4.7)

9

where B is a standard Brownian motion and σ > 0 some constant.

(ii) (Weakly tempered process.) Let λ∗ = 0 and H = d + 1

α ∈

(0, 1). Then

N −HSd,λN

N (t)

fdd
−→

Γ(d + 1)

−1ZH,α,0(t),

(4.8)

where ZH,α,0 is a linear fractional α-stable motion, see Deﬁnition 3.1. Particularly, for α = 2,

ZH,2,0 is a multiple of FBM.

Moreover, if either 1 < α

2, 1/α < H < 1, or α = 2, 0 < H < 1/2 and E

p <
ζ(0)
|
|

(
∃

∞

p > 1/H)

hold, then

fdd
−→

≤

in (4.8) can be replaced by

(iii) (Moderately tempered process.) Let λ∗ ∈

) and H = d + 1

α > 0. Then

∞

.

D[0,1]
−→
(0,

N −HSd,λN

N (t)

fdd
−→

Γ(d + 1)

−1Z II

H,α,λ∗(t),

where Z II

H,α,λ∗ is a TFSM II as deﬁned in Deﬁnition 3.1.

Moreover, if either 1 < α
hold, then fdd
−→

≤

in (4.9) can be replaced by

D[0,1]
−→

.

2, 1/α < H, or α = 2, 0 < H < 1/2 and E

(4.9)

p <
ζ(0)
|
|

(
∃

∞

p > 1/H)

Remark 4.4 Note that for λN = λ∗/N the normalization in (4.6) becomes N −( 1
the exponent 1

α + d = H is the same as in (4.8) and (4.9).

α +d)λd

∗ where

Remark 4.5 The functional convergence in (4.6), case 1 < α < 2 (the case of discontinuous limit

process) is open and apparently does not hold in the usual J1-topology, see [3]. In the case of
(4.8) and (4.9) and 1 < α < 2, 0 < H < 1

α , functional convergence cannot hold in principle since

the limit processes do not belong to D[0, 1].

5 Tempered fractional unit root distribution

A fundamental problem of time series is testing for the unit root β = 1 in the AR(1) model

Y (t) = βY (t

−

1) + X(t),

t = 1, 2, . . . , N, Y (0) = 0

(5.1)

with stationary error process X =

X(t), t
{

∈

Z

. The classical approach to the unit root testing
}

is based on the limit distribution of the OLS estimator

βN

βN =

P

b

N
t=1 Y (t)Y (t
N
t=1 Y 2(t

1)

b
−
1)

−

P

.

(5.2)

The limit theory for

βN in the case of weakly dependent errors X was developed in Phillips [21].

We note that [21] makes an extensive use of invariance principle for the error process. Sowell [24]

b

obtained the limit distribution of

βN in the case of strongly dependent ARFIMA(0, d, 0) error

b

10

process with ﬁnite variance and standardized i.i.d. innovations. [24] proved that the distribution
of the normalized statistic N 1∧(1+2d)(

1) tends to that of the ratio

βN −
b
H (1),



B2

B2(1)


−

1,

−
HΓ(H + 1

1
1
0 B2
H(s)s.

2

R

2 )/Γ( 3

2 −

H),

0 < d < 1/2,

d = 0,

(5.3)

1/2 < d < 0,

−
(0, 1), B = B1/2 being a standard

where H = d + 1

2 and BH is a FBM with parameter H

∈

Brownian motion.

In this section we extend Sowell’s [24] result to ARTFIMA(0, d, λN , 0) error process with small

tempering parameter λN ∼
ized to more general tempered processes with ﬁnite variance as in Theorem 4.3, our choice of

0 as in (4.2). Although Theorem 5.2 can be general-

λ∗/N

→

ARTFIMA(0, d, λN , 0) as the error process is motivated by better comparison to [24]. As noted

in Section 1, the degree of tempering has a strong eﬀect on the limit distribution of

βN and leads

to a new two-parameter family of tempered fractional unit root distributions. Following [24], we

b

decompose

where

AN :=

[N x]
t=1 X(t), x

P
rewritten as

∈

1 =

βN −
b

AN −
b

BN ,

b

(5.4)

(5.5)

.

1)

Y 2(N )
N
t=1 Y 2(t

,

1)

−

2

BN :=

2

b

N
t=1 X 2(t)
P
N
t=1 Y 2(t

−

b

Under the unit root hypothesis β = 1 we have Y (t) =

P

P
t
i=1 X(i) = SN (t/N ), where SN (x) :=
P
[0, 1] is the partial sums process. Particularly, the statistics in (5.5) can be

AN =

b

2N

S2
N (1)
1
0 S2

N (s)s.

,

BN =

P
2N

b

.

N
t=1 X 2(t)
1
0 S2
N (s)s.
1
0 S2

For ARTFIMA error process Xd,λN , the behavior of S2
Theorem 4.3. The behavior of

R
N (1) and
N
t=1 X 2(t) is established in the following proposition.

R

R

N (s)s. can be derived from

(5.6)

P

Proposition 5.1 Let Xd,λN be an ARTFIMA(0, d, λN , 0) process in (2.5) with i.i.d. innovations
, Eζ(0) = 0, Eζ 2(0) = 1, fractional parameter d
0.
ζ(t)
{
}
Moreover, let E

N− and tempering parameter λN →

p > 2). Then

R

∈

\

p <
ζ(0)
|
|

∞

(
∃
1
N

λ2d−1
N
N

1
log λN |

N

|

N

Xt=1
N

Xt=1
N

Xt=1

X 2

d,λN (t)

X 2

d,λN (t)

X 2

d,λN (t)

p
−→

p
−→

p
−→

11

Γ(1
−
Γ2(1
−

2d)
d)

,

1/2)
Γ(d
−
2√π Γ(d)

,

1
π

,

d < 1/2,

d > 1/2,

d = 1/2.

(5.7)

(5.8)

(5.9)

The main result of this section is the following theorem.

Theorem 5.2 Consider the AR(1) model in (5.1) with β = 1 and ARTFIMA(0, d, λN , 0) error
, Eζ(0) = 0, Eζ 2(0) =
∈
}
N− and tempering parameter

ζ(t), t
{
1/(d + 1/2)), fractional parameter d

in (2.5) with i.i.d.

innovations

R

Z

process X =
1, E
p <
ζ(0)
|
|

Xd,λN (t)
}
{
p > 2
(
∃

∨

∞

∈

\

λN > 0 satisfying (4.2).

(i) (Strongly tempered errors.) Let λ∗ =

, d

∞

∈

R

\

N−. Then

min(1, λ−2d

N )N (

βN −
b

1)

d
−→

1
1
0 B2(s) s.

2

R

where B is a standard Brownian motion.

B2(1),

B2(1)

1,

−

d > 0,

d = 0,

Γ(1

−

−

2d)/Γ(1

−

d)2, d < 0,






(ii) (Weakly tempered errors.) Let λ∗ = 0 and H = d + 1

2 ∈

(0, 1). Then

N 1∧(1+2d)( ˆβN −

1)

d
−→

2

where BH is a FBM with variance EB2

B2

H(1),



R

1,

B2(1)

1
1
0 B2
H (s)s.



H(t) = t2H, B = B1/2.

−
HΓ(H + 1

−

2 )/Γ( 3

2 −

1
2 < H < 1,
H = 1
2

(5.10)

H),

0 < H < 1
2 ,

(iii) (Moderately tempered errors.) Let 0 < λ∗ <

N 1∧(1+2d)( ˆβN −

1)

d
−→

1
BII
H,λ∗(s)
(cid:1)

2s.

2

1
0

R

(cid:0)

where BII

H,λ is a TFBM II given by (3.6).

∞






and H = d + 1

2 > 0. Then

(BII

(BII

H,λ∗ (1))2,
(1))2

1
2 ,λ∗

−

1,

H > 1
2 ,
H = 1
2

(5.11)

Γ(2(1

−

−

H))/Γ( 3

2 −

H)2,

0 < H < 1
2 ,

Remark 5.3 The limit (5.10) in the weakly tempered case coincides with Sowell’s limit (5.3).
22H HΓ(H + 1/2)√π, see [22], the r.v. on the r.h.s.
Since BII

fdd= C1BH , where C 2

H)

1 = Γ(1

H,0

of (5.11) for λ∗ = 0, 0 < H < 1 also coincides with (5.3), however the convergence (5.11) holds

−

(cid:14)

for any H > 0 in contrast to H

(0, 1) in (5.10).

∈

Proof of Theorem 5.2. From Theorem 4.3 and Proposition 5.1 we obtain the joint convergence of

aN (Sd,λN
(cid:16)
0, bN →

N (1))2, aN

1

0 (Sd,λN

N (s))2s., bN

R

N
t=1 X 2

d,λN

(t)

(cid:17)

P

(5.12)

where aN →
λ∗, in each case (i)-(iii) of Theorem 5.2. Then the statement of Theorem 5.2 follows from (5.12),

0 are normalizations deﬁned in these theorems and depending on d and

the continuous mapping theorem and the representation of

corresponding quantities in (5.12).

βN −
b

1 in (5.4)-(5.6) through the
(cid:3)

12

(6.1)

(6.2)

(6.3)

6 Proofs of Theorem 4.3 and Proposition 5.1

Proof of Theorem 4.3. (i) We restrict the proof of ﬁnite-dimensional convergence in (4.6) to one-

dimensional convergence at t > 0 since the general case follows similarly. We use Proposition 4.2.
Accordingly, write N − 1
N Sd,λN
i∈Z gN (t; i)ζ(i), where gN (t; i) := N −1/αλd
N
[N t]
k=1∨i e−λN (k−i) bd(k
i). It suﬃces to prove (4.5) for suitable p and g(t; x) := 1[0,t](x). We

N (t) = Q(gN (t,

)) =
·

α λd

P

P
have

−

e

gN (t; x) = λd
N

[N t]

Xk=1∨[N x]

e−λN (k−[N x]) bd(k

[N x]).

−

Let us prove the point-wise convergence:

gN (t; x)

→

g(t; x) = 1[0,t](x),

x

= 0, t.

∀

Let us prove that conditions (1.2)-(1.4) imply that

e

GN := λd
N

∞

Xk=0

e−λN k bd(k)

1

→

(N

).

→ ∞

First, let d > 0. Then since

n
k=0 bd(k)

∼

(1/dΓ(d))nd, n

→ ∞

according to (1.2), then by

applying the Tauberian theorem for power series (Feller [7], Ch. 13,

P

5, Thm. 5) we have

§

∞
k=0 bd(k) e−λN k

(1

∼

−

e−λN )−d, N

→ ∞

P
of (1.4) the dominated convergence theorem applies yielding

, proving (6.3) for d > 0. Next, let d = 0. Then in view
∞
k=0 e−λN k b0(k)

∞
k=0 b0(k) = 1

P

→

P

and (6.3) follows again.

Next, let

1 < d < 0. Then ˜bd(k) :=

−

(0, 1), ˜bd(0) = 0 and
Then the aforementioned Tauberian theorem implies

∞
k=0 e−λkbd(k) =

P

−

−

∞
i=k bd(i)
e−λ)

P
eλ(1

e−λN )−d proving (6.3) for

−

1 < d < 0. In the general case

(6.3) follows similarly using summation by parts j times.

Let 0 < x < t ﬁrst. Then

g∗
N (t; x), where

→ ∞

, ˜d := d + 1

1/dΓ(d))k ˜d−1, k

(
∼
−
∈
k=1 e−λk˜bd(k) using summation by parts.
∞
∞
k=0 e−λN kbd(k)
(1
j < d <

−
j + 1, j = 1, 2, . . . relation

e−λN )1− ˜d = (1

P

−

∼

P

−

−

gN (t; x) = GN −
e
N (t; x) := λd
g∗
N

e

bd(k)e−λN k.

Xk>[N t]−[N x]

Using (1.2) for d

= 0 we obtain

e

g∗
N (t; x)
|

| ≤

C(N λN )dN −1

e−(N λN )(k/N )(k/N )d−1

Xk>[N t]−[N x]

e

C(N λN )d

≤

∞

∞

Z

t−x

e−N λN yyd−1y.

= C

Z

(t−x)(N λN )

e−zzd−1z. →

0

13

(6.4)

6
6
since N λN → ∞
proves (6.2) for 0 < x < t. Next, let x < 0. Then similarly as above

. A similar result for d = 0 follows directly from (1.4). In view of (6.3), this

gN (t; x)

e

≤

≤

C(N λN )dN −1

Xk>|[N x]|

e−(N λN )(k/N )(k/N )d−1

C(N λN )d

∞

Z

|x|

e−N λN yyd−1y.

∞

= C

Z

|x|(N λN )

e−zzd−1z.

0,

→

(6.5)

gN (t; x)
| ≤
|
is bounded
e

2 decays

−

Cλd
gN (t; x)
proving (6.2). Note also that
N
| ≤
|
∞
0 e−zzd−1z.
0 e−N λN y yd−1y. ≤
C(N λN )d
e
R
R, N

uniformly in x

C

∞

R

P
≤

1; moreover, according to (6.5)

bd(k)

∞
k=0 |
C for d > 0, implying that

N ≤

Cλd

| ≤

C for d < 0 and

gN (t; x)
|
|
Ce−c′|x|, x <
e

gN (t; x)
|

| ≤

with some c′ > 0 uniformly in N
e

1. This proves (4.5) and hence

≥

∈

≥

exponentially with x

→ −∞

(4.6).

Consider the functional convergence in (4.7). This follows from the tightness criterion

N −p/2λpd
N

E

Sd,λN
N (t)
|

−

Sd,λN
p
N (s)
|

C

LN (t)
|

−

≤

p/2,
LN (s)
|

0

∀

≤

s < t

1,

≤

(6.6)

where LN (t) := [N t]/N , see [4], also ([10], Lemma 4.4.1). By Rosenthal’s inequality (see e.g.
[10], Proposition 4.4.3), E
Sd,λN
2 = N λ−2d
N (s)
|
proving (6.6) and part (i), too.

Sd,λN
p
N (s)
|
−
2x. ≤
gN (s; x)
|

−
follows similarly as above,

Sd,λN
2 where E
N (s)
|

Sd,λN
N (t)
|
gN (t; x)

CEp/2
≤
CN λ−2d
N |

Sd,λN
N (t)
|
LN (t)

−
LN (s)
|

Sd,λN
N (t)
|

R |

−

−

N

e

e

(ii) Relation (4.8) is well-known with Sd,λN

N (t) replaced by Sd,0

N (t), see e.g. [2], also ([10], Cor. 4.4.1),

so that it suﬃces to prove

RN (t) := Sd,λN

N (t)

Sd,0
N (t) = op(N H).

−

(6.7)

With Proposition 4.2 in mind, (6.7) follows from

g0
N (t;
k

)
kp →
·

0, where

:= N −d

g0
N (t; x)
|
|

e

[N t]

Xk=1∨[N x]

(cid:12)
(cid:12)
(cid:12)

e
[N x])

−

bd(k

1
(cid:0)

−

e−λN (k−[N x])

(cid:1)(cid:12)
(cid:12)
(cid:12)

C(N λN )

≤

1
N d+1

[N t]

(k

Xk=1∨[N x]

[N x])d

−

C(N λN )

0

→

≤

uniformly in x

∈
(0, 1), 1 < α

H

∈

R, where we used (1.2), inequality 1

2 imply

−

1 < d < 1

1
α . For x <

−

−

≤

e−x

−

≤

x (x

≥

0) and the fact that

1 a similar argument leads to

[N t]

CN −d

(k

g0
N (t; x)
|

| ≤

e

C((t

≤

Xk=1
x)d

−

x)d)

(
−

−

C(

−

≤

x)d−1

14

[N x])d−1

−

≤

CN −d

([N t]

(cid:0)

[N x])d

[N x])d

(
−

−

−

(cid:1)

(6.8)

implying the dominating bound

g0
N (t; x)
|

| ≤

C/(1+

x
|

)1−d =: ¯g(x) where
|

suﬃciently close to α due to condition d < 1

e

−

(4.8), too.

1
α . This proves

g0
N (t;
k

e

kp <
¯g
k
)
kp →
·

for 1

≤

∞

p < α

0, hence (6.7) and

To prove the tightness part of (ii), we use a similar criterion as in (6.6), viz.,

N −pHE

Sd,λN
N (t)
|

Sd,λN
p
N (s)
|

−

C

LN (t)
|

−

≤

q,
LN (s)
|

0

∀

≤

s < t

1,

≤

with LN (t) = [N t]/N and suitable p, q > 1. Let ﬁrst 1
gN (t; x) = N −d

[N t]
k=1∨[N x] bd(k

[N x]) e−λN (k−[N x]). Then for 0 < s < t

α < H < 1, or 0 < d < 1

−

(6.9)

1
α . Let

−

e

P

gN (t; x)
|

−

gN (s; x)

| ≤

N −d

e

e

Xk=[N s]+1
[N t]

[N t]

[N t]

bd(k
|

−

[N x])

| ≤

CN −d

(k

Xk=[N s]+1

[N x])d−1

+

−

CN −d

Z

[N s]

C((LN (t)

−

(y

−
LN (x))d

≤

≤

[N x])d−1
+ y.

(LN (s)

−

LN (x))d
+)

(6.10)

+ −

p < α suﬃciently close to α

and therefore for 1

N −pHE

Sd,λN
N (t)
|

−

≤
Sd,λN
p
N (s)
|

gN (s;

p
)
p
k
·

C

C

≤

≤

gN (t;
k
∞

)
−
·
e
(LN (t)
|

e
Z
0

LN (s) + LN (x))d

LN (x)d

px.
|

−

−

LN (s))pdN −1 +

−

∞

(LN (t)
|

−

Z

0

LN (s) + x)d

−

xd

px.
|

(cid:17)
(6.11)

C

(LN (t)

≤

(cid:16)
LN (t)
(cid:0)
= 0 implies LN (t)

≤

C

1+pd

−

LN (s)
(cid:1)

LN (s)

N −1. This proves (6.9) with q = 1 + pd > 1.

since LN (t)

LN (s)
Next, let α = 2 and 0 < H < 1

−

−
1/2 < d < 0. Then (6.9) holds for Sd,0

≥

2 , or

N with
q = pH > 1, see ([10], proof of Prop. 4.4.4). Hence, it suﬃces to prove a similar bound for RN (t) in
(6.7). By Rosenthal’s inequality (see the proof (6.6)) E
2
RN (s)
RN (t)
−
|
|
p
and hence N −pHE
g0
2, where
)
N (s;
k
·

p
RN (s)
|

p
RN (s)
|

g0
N (t;
k

RN (t)
|

RN (t)
|

CEp/2

)
·

−

≤

−

−

−

C

N instead of Sd,λN

g0
N (t; x)
|

−

g0
N (s; x)

| ≤

CN −d

e

e

≤
[N t]

e
(k

e
[N x])d−1

+

−

1

(cid:0)

−

e−λN (k−[N x])+

(cid:1)

Xk=[N s]+1

C 


(
−
C

≤

LN (x))d−1(LN (t)

LN (s)),

−
LN (x))d+1

+ −
similarly as in (6.10). Hence N −pHE
p
RN (s)
|
LN (s))1+p(1+d) follows, proving (6.7) and part (ii), too.

RN (t)
|



−

−

≤

(LN (t)
(cid:0)

(LN (s)

−

LN (x))d+1

+

C

g0
N (t;
k

)
·

−

g0
N (s;

e

e

−

,
(cid:1)
p
)
2 ≤
k
·

x <

1,

−

(6.12)

1 < x < 1,

C(LN (t)

−

(iii) Similarly as in the proof of (ii), let us prove

gN (t;
k

)
·

−

gN (t; x) := 1
N d

e

[N t]
k=1∨[N x] bd(k

−

P

[N x]) e−λN (k−[N x]),

e

15

0, where

g(t;

)
kp →
·
g(t; x) := 1

Γ(1+d) hH,α,λ∗(t; x),

(6.13)

6
see the deﬁnition of hH,α,λ in (1.9). First, let d > 0 or H > 1
point-wise convergence

α . Then using (1.2) we obtain the

gN (t; x) =

e

1

N Γ(d) X1
N ≤ k

N ∨ [Nx]
t

N ≤ [Nt]

N

1
Γ(d) Z
0

→

see (3.3), where

k
N −

[N x]
N (cid:1)

(cid:0)

d−1

1 + ǫN 1(k, x)
(cid:1)

(cid:0)

e−λ∗( k

N − [Nx]

N )(1+ǫN2)

x)d−1

+ e−λ∗(y−x)+ dy =

(y

−

1
Γ(1 + d)

hH,α,λ∗(t; x),

x

= 0, t, (6.14)

∀

ǫN 1(k, x) := Γ(d)(k

[N x])1−dbd(k

−

[N x])

1

−

→

0,

−

ǫN 2 := (N λN /λ∗)

1

−

→

0

as N

→ ∞

, k

−

[N x]

→ ∞

and

ǫN 1(k, x)
|
|

+

ǫN 2|
|

< C is bounded uniformly in N, k, x.

Therefore (6.14) holds by the dominated convergence theorem. We also have from (6.13) that
+ e−(λ∗/2)(s−x)+ s. =
[N x])d−1e−(λ∗/2)(k−[N x])
.
kp <
¯g
k

gN (t; x)
|
Chd+1/α,α,λ∗/2(t; x) =: ¯g(x) is dominated by an integrable function, see (3.3), with
e

[N t]
k=1∨[N x](k

t
0 (s
R

CN −d

x)d−1

| ≤

P

∞

≤

−

−

C

This proves (4.9) for d > 0.

Next, let

−

1
α < d < 0. Decompose

gN (t; x) in (6.13) as

gN (t; x) =

gN 1(x)

gN 1(x)

e

e
:= N −d

∞

Xk=1∨[N x]
∞

bd(k

−

e

e

[N x]) e−λN (k−[N x]),

gN 2(x)

:= N −d

e

bd(k

−

X[N t]+1

[N x]) e−λN (k−[N x]).

Let 0 < x < t. First we have

gN 2(t; x), where

−

e

∞
j=0 bd(j) e−λN j
λ−d
N

(N λN )−d

λ−d
∗

→

gN 1(x) = P
e

since the last ratio tends to 1 as N

, see (6.3). We also have

→ ∞
k
N −

(cid:0)

gN 2(t; x) =

e

→

1

N Γ(d) Xk
N > [Nt]
∞

N

1
Γ(d) Z
t

d−1

[N x]
N (cid:1)

1 + ǫN 1(k, x)
(cid:1)
(cid:0)

e−λ∗( k

N − [Nx]

N )(1+ǫN2)

(s

−

x)d−1

+ e−λ∗(s−x)+s. = λ−d

∗ −

1
Γ(1 + d)

hH,α,λ∗ (t; x),

see (3.4), similarly to (6.14). This proves the point-wise convergence
d)−1hH,α,λ(t; x) for 0 < x < t and the proof for x < 0 is similar. Then

(4.9) for

−

1
α < d < 0 follows similarly as in the case d > 0 above.

g(t; x) = Γ(1 +

g(t;

)
kp →
·

0 or

→
)
·

−

gN (t; x)

gN (t;
e
k

e

Consider the proof of tightness in (iii). We use the same criterion (6.9) as in part (ii). Let

ﬁrst d > 0. Then for

1
−1 |
LN (s))1+pd follows as in (6.11). On the other hand, for x <

1 the bound in (6.10) and hence

| ≤

x
|

R

C(LN (t)

−

gN (t; x)

px.
gN (s; x)
|

−

≤

1 we have
e

e
−

gN (t; x)
|

−

gN (s; x)

| ≤

Ce−(λ∗/2)|x|

e

e

[N t]/N

Z

[N s/N ]

16

y. = Ce−(λ∗/2)|x|(LN (t)

LN (s))

−

6
implying

−1
−∞ |

R

gN (t; x)

px.
gN (s; x)
|
p > 1. Finally, (6.9) for α = 2,

LN (t)
|

≤

−

C

−

e

with q = (1 + pd)
e

∧

p. Consequently, (6.9) for d > 0 holds
LN (s)
|

1/2 < d < 0 follows as in case (ii) since (6.12)
(cid:3)

−

holds in the case λN = O(1/N ) as well. This ends the proof of Theorem 4.3.

Proof of Proposition 5.1. (i) By stationarity, N −1E

the convergence of expectations:

N
t=1 X 2

d,λN

(t) = EX 2

d,λN

(0). Let us ﬁrst prove

P

EX 2

d,λN (0)

λ2d−1
N

EX 2

d,λN (0)

log λN |

|

−1EX 2

d,λN (0)

,

2d)
Γ(1
−
Γ2(1
d)
−
Γ(d
1/2)
−
2√π Γ(d)
1
π

,

→

→

→

d < 1/2,

,

d > 1/2,

d = 1/2,

(6.15)

(6.16)

(6.17)

as N

→ ∞

. Since EX 2

d,λN

(0) =

∞
k=0 e−2λN kω2

−d(k), with ω−d(k)

≡

P

ω−d(k) deﬁned in (2.3), and

n

Xk=0

ω2

−d(k)

∼

(1/(2d

−

1)Γ2(d))n2d−1,

(1/Γ2(1/2)) log(n),

d > 1/2,

d = 1/2,

∞
k=0 ω2

−d(k) = Γ(1

2d)/Γ2(1

−

−

d), d < 1/2

P






, the convergences in (6.15)-(6.17) follows from the Tauberian theorem in [7] used in

as n

→ ∞

the proof of Theorem 4.3 (i) above.

With (6.15)-(6.17) in mind, (5.7)-(5.9) follow from

QN ≡

N −1

N

Xt=1 h

X 2

d,λN (t)

EX 2

d,λN (t)
(cid:3)

−

=

op(1),

op(λ1−2d

N ),
log λN |

op(
|






d < 1/2,

d > 1/2,

(6.18)

), d = 1/2.

Let ω−d,λ(k) := ω−d(k)e−λk. We have QN = QN 1 + QN 2, where

QN 1 = N −1

(ζ 2(s)

−

Eζ 2(s))

Xs≤N

N

Xt=1∨s

ω2
−d,λN (t

s),

−

QN 2 = N −1

ζ(s1)

N

Xt=1∨s1

Xs2<s1≤N

ω−d,λN (t

−

s1)ω−d,λN (t

−

s2)ζ(s2).

Note QN i, i = 1, 2 are sums of martingale diﬀerences. We shall use the well-known moment

inequality for sums of martingale diﬀerences:

E

| Xi≥1

α

ξi|

≤

2

Xi≥1

E

α

ξi|
|

(6.19)

see e.g. ([10], Prop. 2.5.2), which is valid for any 1

E

α <

ξi|
|

∞

, E[ξi|

ξj, 1

≤

j < i] = 0, i

1.

≥

α

≤

≤

2 and any sequence

ξi, i
{

≥

1
}

with

17

First, let d > 1/2. Using E

p <
ζ(0)
|
|

∞

N

E

p/2

QN 1|
|

CN −p/2

CN −p/2

CN −p/2

CN −p/2

≤

≤

≤

≡

Xs≤N (cid:12)
(cid:12)
(cid:12)

Xt=1∨s
N

Xt=1∨s

Xs≤N (cid:16)
∞

(t

N

−

s.

N

n Z
(cid:16) Z
0
IN 1 + IN 2

.

(cid:8)

N
Here, IN 2 ≤
CN p/2λ(1−d)p−1
N

∞
0

t2(d−1)e−2λN tt.
(cid:17)

(cid:16) R
. Therefore,

, 2 < p < 4 and (6.19) with α = p/2 we obtain

ω2
−d,λN (t

−

s)2(d−1)
+

p/2

s)
(cid:12)
(cid:12)
(cid:12)
e−2λN (t−s)

p/2

(cid:17)

(t + s)2(d−1)e−2λN (t+s)t.
(cid:17)

p/2

+ N

N

(cid:16) Z

0

t2(d−1)e−2λN tt.

p/2

(cid:17)

o

(cid:9)
p/2

= CN λ(p/2)(1−2d)
N

and IN 1 ≤

CN p/2

∞
N s(d−1)pe−λN pss.

≤

R

E

p/2

QN 1|
|

C

λ(1−d)p−1
N
(cid:0)

≤

+ N 1−p/2λ(p/2)(1−2d)
N

.

(cid:1)

(6.20)

Next,

E

2

QN 2|
|

CN −2

CN −2

CN −2

CN −2

≤

≤

≤

≤

= CN −1

Xs2<s1≤N

N

E

Xt=1∨s1
(cid:0)
N

ω−d,λN (t

−

s1)ω−d,λN (t

2

−

s2)ζ(s2)
(cid:1)

ω2
−d,λN (t

−

s1)ω2

−d,λN (t

s2)

−

Xs2<s1≤N
N

Xt=1∨s1

ω2
−d,λN (t

2

s)
(cid:1)

−

Xt=1 (cid:0) Xs≤t
N

t

t.

Z

0

∞

0

(cid:16) Z
2d) and 1

(t

s)2(d−1)e−2λN (t−s)s.

2

−

−∞

(cid:16) Z
s2(d−1)e−2λN ss.

2

(cid:17)

≤

(cid:17)
CN −1λ2(1−2d)
N

Since (1

d)p

−

−

1 > (p/2)(1

−

(p/2) < 0, (6.20) and (6.21) prove (6.18) for d > 1/2.

−

Next, let d < 1/2. Then similarly as above we obtain

.

(6.21)

E

p/2

QN 1|
|

≤

CN −p/2

∞

Xs≤N (cid:16)
Xt=1∨s
N

s)2(d−1)
+

(t

−

p/2

(cid:17)

= CN −p/2

t2(d−1)

N

n

(cid:0)

Xt=1

CN 1−p/2 + CN −p/2

≤

and

Xs≥N

N

p/2 +
(cid:1)
(N s2(d−1))p/2

Xs≥N (cid:0)

Xt=1

(s + t)2(d−1)

p/2

o

(cid:1)

CN 1−p/2

≤

(6.22)

E

2

QN 2|
|

≤

≤

CN −2

Xs2<s1≤N
N

CN −2

(t

Xt=1 (cid:16) Xs<t

18

N

Xt=1∨s1

ω2
−d,λN (t

−

s1)ω2

−d,λN (t

s2)

−

s)2(d−1)

−

2

(cid:17)

≤

CN −1.

(6.23)

(6.22) and (6.23) prove (6.18) for d < 1/2.

Finally, let d = 1/2. Then since p > 2

E

p/2

QN 1|
|

≤

CN −p/2

= CN −p/2

∞

Xs≤N (cid:16)
Xt=1∨s
N

s)−1
+

(t

−

p/2

(cid:17)

N

n

t−1

p/2 +
(cid:1)

Xt=1
CN 1−p/2(log N )p/2 + CN −p/2

(cid:0)

Xs≥N (cid:0)

N

(s + t)−1

Xt=1

p/2

o

(cid:1)

(N s−1)p/2

Xs≥N

CN 1−p/2(log N )p/2 = o(1)

(6.24)

≤

≤

while

E

2

QN 2|
|

≤

CN −2

N

(t

Xt=1 (cid:16) Xs<t

−

s)−1e−λN (t−s)

2

(cid:17)

≤

CN −1(log λN )2.

(6.25)

(6.24) and (6.25) prove (6.18) for d = 1/2. Proposition 5.1 is proved.

(cid:3)

References

[1] Abramowitz, M., Stegun, I.: Handbook of mathematical functions, ninth edition, Dover, New York (1965).

[2] Astrauskas, A. (1983). Limit theorems for sums of linearly generated random variables. Lithuanian J. Math.

23 127–134.

[3] Balan, R., Jakubowski, A. and Louhichi, S. (2016). Functional convergence of linear processes with heavy-tailed

innovations. J. Theoret. Probab. 29 491–526.

[4] Billingsley, P. (1968). Convergence of Probability Measures. New York: Wiley.

[5] Brockwell, P.J. and Davis, R.A. (1991). Time Series: Theory and Methods, 2nd ed.. New York: Springer.

[6] Dickey, D. and Fuller, W. (1979). Distribution of the estimators for autoregressive time series with a unit root.

JASA 74 427–431.

[7] Feller, W. (1966). An Introduction to Probability Theory and Its Applications, vol. 2. New York: Wiley.

[8] Giraitis, L., Kokoszka, P. and Leipus, R. (2000). Stationary ARCH models: dependence structure and central

limit theorem. Econometric Theory 16 3–22.

[9] Giraitis, L., Kokoszka, P., Leipus, R. and Teyssi`ere, G. (2003). Rescaled variance and related tests for long

memory in volatility and levels. J. Econometrics 112 265–294.

[10] Giraitis, L., Koul. H.L. and Surgailis, D. (2012). Large Sample Inference for Long Memory Processes. London:

Imperial College Press.

[11] Gradshteyn, I.S. and Ryzhik, I.M. (2000). Tables of Integrals and Products. 6th edition. New York: Academic

Press.

[12] Granger, C.W.J. and Joyeux, R. (1980). An introduction to long-memory time series models and fractional

diﬀerencing. J. Time Series Anal. 1 15–29.

19

[13] Hosking, J.R.M. (1981). Fractional diﬀerencing. Biometrika 68 165–176.

[14] Kasahara, Y. and Maejima, M. (1988). Weighted sums of i.i.d. random variables attracted to integrals of stable

processes. Probab. Theory Relat. Fields 78 75–96.

[15] Kokoszka, P.S. and Taqqu, M.S. (1995). Fractional ARIMA with stable innovations. Stochastic Process. Appl.

60 19–47.

[16] Lavancier, F., Leipus, R., Philippe, A. and Surgailis, D. (2013). Detection of non-constant long memory

parameter. Econometric Theory 29 1009–1056.

[17] Lo, A. (1991). Long-term memory in stock market prices. Econometrica 59 1279–1313.

[18] Meerschaert, M.M. and Sabzikar, F. (2013). Tempered fractional Brownian motion. Statist. Probab. Lett. 83

2269–2275.

[19] Meerschaert, M.M. and Sabzikar, F. (2016). Tempered fractional stable motion. J. Theoret. Probab. 29 681–

706.

[20] Meerschaert, M.M., Sabzikar, F., Phanikumar, M.S. and Zeleke, A. (2014). Tempered fractional time series

model for turbulence in geophysical ﬂows. J. Stat. Mech. Theory Exp. 2014 P09023.

[21] Phillips, P.C.B. (1987). Time series regression with a unit root. Econometrica 55 277–301.

[22] Sabzikar, F. and Surgailis, D. (2017). Tempered fractional Brownian and stable motions of second kind.

Preprint. Available on http://arxiv.org/abs/1702.07258

[23] Samorodnitsky, G. and Taqqu, M.S. (1996). Stable Non-Gaussian Random Processes: Stochastic Models with

Inﬁnite Variance. Boca Raton etc: Chapman and Hall.

[24] Sowell, F. (1990). The fractional unit root distribution. Econometrica 58 495–505.

20

