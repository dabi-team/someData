9
1
0
2

r
p
A
9
2

]
E
M

.
t
a
t
s
[

1
v
3
1
5
2
1
.
4
0
9
1
:
v
i
X
r
a

The Hyv¨arinen scoring rule in Gaussian linear
time series models

Silvia Columbua, Valentina Mamelib, Monica Musioa and A.Philip Dawidc
a Dep. of Mathematics and Computer Science, Univ. of Cagliari, IT
b Dep. of Environmental Sciences, Informatics and Statistics Ca’ Foscari Univ. of Venice, Italy
c Dep. of Pure Mathematics and Mathematical Statistics, Univ. of Cambridge, UK

Abstract

Likelihood-based estimation methods involve the normalising con-
stant of the model distributions, expressed as a function of the param-
eter. However in many problems this function is not easily available,
and then less eﬃcient but more easily computed estimators may be
attractive. In this work we study stationary time-series models, and
construct and analyse “score-matching” estimators, that do not in-
volve the normalising constant. We consider two scenarios: a single
series of increasing length, and an increasing number of independent
series of ﬁxed length. In the latter case there are two variants, one
based on the full data, and another based on a suﬃcient statistic.

We study the empirical performance of these estimators in three
special cases, autoregressive (AR), moving average (MA) and frac-
tionally diﬀerenced white noise (ARFIMA) models, and make com-
parisons with full and pairwise likelihood estimators. The results are
somewhat model-dependent, with the new estimators doing well for
MA and ARFIMA models, but less so for AR models.

Keywords: Scoring rule estimators, Hyv¨arinen scoring rule, Gaussian Linear
time series.

1

Introduction

The evaluation of the exact full likelihood may be diﬃcult or even impossible
in situations where complex problems deal with large correlated datasets.
These problems are likely to occur for instance in spatial statistics and time
series frameworks in which direct computation of the normalising constant

1

 
 
 
 
 
 
can be a very challenging task, entailing multidimensional integration of the
full joint density for each value of the parameter. Many approaches have
been proposed to tackle this issue. in this paper, we investigate an appealing
approach based on the score matching estimator proposed by Hyv¨arinen in
2005 [23].

The score matching estimator can be regarded as a speciﬁc case of esti-
mators derived from proper scoring rules (see Dawid and Musio (2014) [13]),
which are loss functions for measuring the quality of probabilistic forecasts.
In particular, this estimator derives from the Hyv¨arinen scoring rule, which
is a homogeneous proper scoring rule (see Ehm and Gneiting (2012) [17] and
Parry et al. (2012) [33]), namely a proper scoring rule which does not require
knowledge of the normalising constant. Homogeneous scoring rules have been
characterised for continuous real variables (Parry et al. (2012) [33]) and for
discrete variables (Dawid et al. (2012) [12]). In a Bayesian framework, Dawid
and Musio (2015) [15] have shown, for the case of continuous variables, how
to handle Bayesian model selection with improper within-model prior dis-
tributions, by exploiting the use of homogeneous proper scoring rules. The
(2017)
discrete counterpart has been empirically studied by Dawid et al.
[16].
In a recent contribution, Shao et al. (2018) [35] consider the use of
the Hyv¨arinen score for model comparison. Although the majority of con-
tributions involving the use of Hyv¨arinen scoring rules focus on Euclidean
spaces, scholars have also investigated extensions to non-Euclidean spaces:
for an early study see Dawid (2007) [11]. Recently, Mardia et al. (2016) [29]
proposed an extension of the Hyv¨arinen scoring rule to compact oriented
Riemannian manifolds, and Takasu et al. (2018) [36] constructed a novel
class of homogeneous strictly proper scoring rules for statistical models on
spheres.

Given the growing interest in the use of this scoring rule for very com-
plex statistical models, in this paper we aim to derive an estimation method
based on the Hyv¨arinen scoring rule for estimating linear Gaussian time series
models.

We distinguish two separate cases: a ﬁrst in which the length of a single
time series increases to inﬁnity, and a second in which the length of the time
series is ﬁxed and the number of series increases to inﬁnity.

The consistency and asymptotic distribution of the Hyv¨arinen estimator
are derived for the case of a single time series of increasing length. In par-
ticular, under some mild regularity conditions we derive consistency of the
proposed estimator for linear Gaussian time series models, while the asymp-
totic distribution is proved in the speciﬁc case of autoregressive moving av-
erage (ARMA) causal invertible models. For time series with ﬁxed length
and the number of time series increasing to inﬁnity the performances of two

2

estimators based on the Hyv¨arinen scoring rule, namely the total Hyv¨arinen
estimator and the matrix Hyv¨arinen estimator are compared through simu-
lation studies with the full maximum likelihood and the pairwise maximum
likelihood estimators. Three simple time series models have been considered
in the design of simulations: autoregressive (AR), moving average (MA) and
fractionally diﬀerenced white noise (ARFIMA).

Diﬀerent behaviours can be detected for the total Hyv¨arinen estimator
among the settings examined.
In particular, it outperforms the pairwise
likelihood estimator in terms of eﬃciency with respect to the full maximum
likelihood estimator for the MA and ARFIMA processes.

The paper unfolds as follows. Section 2 introduces basic notions on scor-
ing rules. In Section 3 we introduce the Hyv¨arinen scoring rule for Gaus-
sian linear time series. Some asymptotic results for the Hyv¨arinen estimator
are given. In the speciﬁc case of n independent series we describe the to-
tal Hyv¨arinen estimator and the matrix Hyv¨arinen estimator. Section 4
summarises the results of the simulation studies. Section 5 presents some
concluding remarks. Technical details are postponed to the Appendices.

2 Scoring rules

A scoring rule is a loss function designed to measure the quality of a proposed
probability distribution Q, for a random variable X, in light of the outcome
x of X. Speciﬁcally, if a forecaster quotes a predictive distribution Q for X
and the event X = x realises, then the forecaster’s loss will be S(x, Q). The
expected value of S(X, Q) when X has distribution P is denoted by S(P, Q).

The scoring rule S is proper (relative to the class of distributions

S(P, Q)

S(P, P ), for all P, Q

.

≥
It is strictly proper if equality obtains only when Q = P .

∈ P

) if

P

(1)

Any proper scoring rule gives rise to a general method for parameter

estimation, based on an unbiased estimating equation: see

2.2 below.

§

2.1 Examples of proper scoring rules

log q(x)
Some important proper scoring rules are the log-score, S(x, Q) =
(Good (1952) [20]), where q(
) is the density function of Q, which recovers
the full (negative log) likelihood; and the Brier score (Brier (1950) [3]). A
particularly interesting case, which avoids the need to compute the normal-
ising constant, produces the score matching estimation method of Hyv¨arinen

−

·

3

(2005) [23], based on the following proper scoring rule:

S(x, Q) = ∆x ln q(x) +

1
2 k∇

x ln q(x)

2 ,
k

(2)

,
k · k
) is assumed twice continuously diﬀerentiable, and x is the realised value of
x denotes the gradient operator, and ∆x the Laplacian operator,

where X ranges over the whole of IRp supplied with the Euclidean norm
q(
X. In (2),
with respect to x. For p = 1 we can express

∇

·

S(x, Q) =

q′′(x)
q(x) −

1
2

q′(x)
q(x)

2

.

(cid:19)

(cid:18)

(3)

The scoring rule (2) is a 2-local homogeneous proper scoring rule (see
Parry et al. (2012) [33]). It is homogeneous in the density function q(
), i.e.
its value is unaﬀected by applying a positive scale factor to the density q,
and so can be computed even if we only know the density function up to a
scale factor. Inference performed using any homogeneous scoring rule does
not require knowledge of the normalising constant of the distribution.

·

2.2 Estimation based on proper scoring rules

Let (x1, . . . , xn) be independent realisations of a random variable X, having
distribution Pθ depending on an unknown parameter θ
Θ, where Θ is an
open subset of IRm. Given a proper scoring rule S, let S(x, θ) denote S(x, Pθ).
Inference for the parameter θ may be performed by minimising the total

∈

empirical score,

n

S(θ) =

S(xp, θ),

p=1
X

(4)

resulting in the minimum score estimator ,

θS = arg minθ S(θ).

Under broad regularity conditions on the model (see e.g. Barndorﬀ-

Nielsen & Cox (1994) [2]),

θS satistﬁes the score equation:

b

b
s(θ) :=

n

p=1
X

s(xp, θ) = 0,

(5)

where s(x, θ) :=
θS(x, θ), the gradient vector of S(x, θ) with respect to θ.
The score equation is an unbiased estimating equation (Dawid & Lauritzen
(2005) [10]). When S is the log-score, the minimum score estimator becomes
the maximum likelihood estimator.

∇

4

θS

From the general theory of unbiased estimating functions, under broad
θS is asymp-
regularity conditions on the model the minimum score estimate
), where
totically consistent and normally distributed:
G(θ) denotes the Godambe information matrix G(θ) := K(θ)J(θ)−1K(θ),
where J(θ) = E
is the variability matrix , and K(θ) =
s(X, θ)T
E
is the sensitivity matrix . In contrast to the case for the full
likelihood, J and K are diﬀerent in general: see Dawid & Musio (2014) [13],
Dawid et al (2016)[14]. We point out that estimation of the matrix J(θ), and
(to a somewhat lesser extent) of the matrix K(θ), is not an easy task: see
Varin (2008) [37], Varin et al. (2011) [38] and Cattelan and Sartori (2016)
[5].

s(X, θ)s(X, θ)T

nG(θ)
}
b

N(θ,

∇

∼

−1

(cid:8)

(cid:9)

(cid:9)

(cid:8)

b

{

3 Gaussian linear time series models

In this section we introduce some results based on the use of the Hyv¨arinen
scoring rule in the setting of Gaussian linear time series models.

Consider the Gaussian linear time series model

∞

yt = µ +

ψjzt−j,

t = 1, 2, . . . ,

(6)

j=0
X

∈

t <

t=0 ψ2

IRm−2, where for j

parametrised by µ, σ2 and λ
0, ψj = ψj(λ) satisﬁes
∞
ψ0 = 1 and
. The (zt) are iid Gaussian variables with mean 0
and variance σ2. Let θ = (µ, σ2, λ) be the vector of model parameters. The
P
t=0 ψtψt+j = σ2γλ(j),
µ)(yt
autocovariance function is E
{
say. Using basic diﬀerentiation rules, it is easy to ﬁnd the Hyv¨arinen score
based on the single time series YT = (y1, y2, . . . , yT ):

= σ2

(yt+j

P

∞

µ)

−

≥

−

}

∞

H(θ, YT ) =

1
σ2

−

T

Γii +

1
2

T

T

1
σ2 Γit(yt

−

2

µ)

,

(7)

i=1 (
X
) and Γij is the (i, j) entry
where the matrix Γ has (i, j) entry Γij = γλ(
of Γ−1. We will denote denote the Hyv¨arinen estimator based on a single
series by

t=1
X
j

i=1
X

θH.

)

−

i

|

|

3.1 Asymptotic results for a single time series

b

In this section we analyse the asymptotic statistical properties of the
Hyv¨arinen scoring rule estimator, based on (7), for a single time series.
The following theorem shows the consistency of the estimator

θH in the
Gaussian linear time series setting. The proof of the Theorem is deferred

5

b

to Appendix and follows arguments similar to those used by Davis and Yau
(2011) [8] to prove the consistency of the pairwise likelihood estimator.

Theorem 1. Suppose (yt) is the linear process in (6) with µ = 0 and param-
eter θ0 = (σ2

0, λ0). Let

θH = argmin

H(θ, YT )

θ

be the minimum score estimator, where θ = (σ2, λ) and λ
b
compact set. If the identiﬁability condition

∈

Λ, where Λ is a

1γλ1(j) = σ2
σ2

2γλ2(j) for j = 0, 1, . . . , k iﬀ (σ2

1, λ1) = (σ2

2, λ2)

(8)

is satisﬁed, then

θH

a.s.
−−→

θ0 as T

.

→ ∞

b

Once consistency has been proved, we focus on the asymptotic distribu-
θH. Its analytic form involves the elements Γij of the inverse of the
tion of
autocovariance matrix. In order to guarantee its absolute summability, we
restrict our attention to the case of ARMA causal invertible processes.

b

Deﬁning bij = Γij/σ2, the gradient and the Hessian with respect to

are given, respectively, by the following two expressions:

J(θ) =

∂
∂θ

H(θ, YT ) =

K(θ) =

∂2
∂θ2 H(θ, YT ) =

T

−

−

i=1
X
T

i=1
X
T

+

T

i,j,t=1
X
T

∂bii
∂θ

+

2
2

∂2bii
∂θ2 +

i,j,t=1
X
∂2bij
∂θ2 bityjyt

i,j,t=1
X

∂bij
∂θ

bityjyt

∂bij
∂θ

∂bit
∂θ

yjyt

(10)

where ∂/∂θ denotes diﬀerentiation with respect to the components of the
vector θ.

Theorem 2. Suppose that (yt) is an ARMA(p, q) causal and invertible pro-
cess. Furthermore, assume that the Hessian matrix K(θ) is invertible in a
neighbourhood of θ0. If the identiﬁability condition (8) holds, then

√T (

θT

∞
r=−∞

b

where V =

Nm−1

0, K(θ0)−1V K T (θ0)−1

θ0) D
−→

−
∞
k=−∞ V (r, k, θ0) with

(cid:0)

,

(cid:1)

P
V (r, k, θ0) =

P
∂
∂θ0

(cid:18)

2

γ−1(0)
σ2
0 (cid:19)

+

∂
∂θ0

γ−1(k)
σ2
0

γ−1(0)

∂γ−1(k + r)
∂θ0

γ(r).

6

θH

b

(9)

Theorem 2 shows that the Hyv¨arinen scoring rule estimator

θH, in the case
that (yt) is an ARMA causal invertible process, is asymptotically normally
distributed with rate of decay √T . As is well known, the autocovariance
function of an ARMA process decays exponentially, which means that an
ARMA process is a short memory process, and its autocovariance function is
absolutely summable Brockwell & Davis (1991) [4]. This property, together
with the duality of ARMA models under causality and invertibility, allows us
to prove asymptotic normality. For the complete proof refer to the appendix.

b

3.2 Estimation approaches for n independent time se-

ries

In the remainder of this section we discuss the case of n independent series
of length T . We assume that T is ﬁxed while n increases to inﬁnity. We
also specialise to the case that the common mean µ and innovation variance
σ2 = σ2

0 are known; without loss of generality we take µ = 0.

Consider now n independent and identically distributed processes
Y1, . . . , Yn, where Yp = (yp1, . . . , ypT ), each having the T -variate normal dis-
tribution with mean-vector 0 and variance covariance matrix σ2Γ, with un-
known parameter λ. Let the (n
T ) random matrix Y have the vector Yp as
its pth row. We deﬁne the total Hyv¨arinen score (HT) as the sum of n single
Hyv¨arinen scores in (7):

×

n

HT(λ) =

Hp(λ, Yp),

p=1
X

where

Hp(λ, Yp) =

1
σ2

−

T

i=1
X

Γii +

1
2

T

T

i=1 (
X

t=1
X

2

.

1
σ2 Γitypt

)

(11)

(12)

The estimate of λ minimising the total Hyv¨arinen score will be denoted by
λHT.

An alternative approach is to consider as basic observable the sum-of-
squares-and-products matrix SSP = Y T Y , which is a suﬃcient statistic for
b
the multivariate normal model, having the Wishart distribution with n de-
grees of freedom and scale matrix σ2Γ. Then inference for the parameter λ
can be performed by resorting to the Hyv¨arinen score based directly on the
Wishart model. We will call this scoring rule the matrix Hyv¨arinen score.

Assuming n
i

j

(sij : 1

T , so that the joint distribution of the upper triangle
≥
T ) of the sum-of-squares-and-products random matrix SSP

≤

≤

≤

7

(which has a Wishart distribution with parameters n and σ2Γ) has a density,
and taking into consideration all of the properties of the derivatives of traces
and determinants, it can be shown that the Hyv¨arinen score based on this
joint density is

HW(SSP, Γ) =

(n

−

T
2

−

T

1)

−

(sii)2+

T

(n

−

1
2

T
2

1)

sij

−

1
2σ2 Γij

−

2

,

(cid:27)
(13)
where sij and Γij are the elements of the inverse matrices SSP−1 and of Γ−1,
respectively. The matrix Hyv¨arinen estimator for λ, minimising HW(SSP, Γ)
with respect to λ, will be denoted by

i,j=1 (cid:26)
X

λHW.

i=1
X

The derivative of HW(SSP, Γ) with respect to λ is

HWλ(SSP, Γ) =

1
2σ2

−

T

(n

i,j=1 (cid:26)
X

b

−

T
2

1)

sij

−

1
2σ2 Γij

−

∂Γij
∂λ

,

(cid:27)

(14)

{

HWλ(SSP, Γ)

and E
Kollo & von Rosen, p. 257). Moreover, K(λ) = E

1)) (see
=
/4σ4. The derivation of the function J(λ), which after

= 0 since E (sij) = Γij/(σ2(n

HWλλ(SSP, Γ)

T
i,j=1 (∂Γij/∂λ)

−

−

T

}

}

{

2

taking account of the square of (14) reduces to
P

(n

J(λ) =

T
−
−
16σ4

1)2

T

∂Γij
∂λ

2

cov

sij, skl

,

(15)

i,j,k,l=1 (cid:18)
X
involves calculations requiring the covariance matrix of the random matrix
SSP−1, which has an Inverse Wishart distribution with scale matrix 1
σ2 Γ−1:
see Von Rosen (1998) [39] for details on the components of the covariance
matrix.

(cid:19)

(cid:0)

(cid:1)

In general, the Godambe information needed to estimate the standard
λHW is not easy to derive analytically due to the form of the matrix
error of
Γ. It should be pointed out that this approach can not be used if we have a
single time series of length T with T increasing to
, since for non-singularity
T .
of the Wishart distribution we need to assume n

b

∞
≥

4 Numerical assessment

In this section we report simulation studies designed to assess and compare
the behaviours of the estimators obtained by using the total and the matrix
Hyv¨arinen estimators. We refer to the case described in paragraph 3.2 in

8

∞

which T is ﬁxed and n increases to
. For comparison, we will consider also
the full and pairwise maximum likelihood estimators (Davis & Yau (2011)
[8] ). We discuss three examples: the ﬁrst order autoregressive AR(1), the
ﬁrst order moving average MA(1) and the fractionally diﬀerenced white noise
ARFIMA(0, d, 0). Various parameter settings are considered in all simula-
tion studies. All calculations have been done in the statistical computing
environment R ([34]). The summary statistics shown are: average estimates
of the parameters, asymptotic standard deviations (sd) and the asymptotic
relative eﬃciency (ARE) with respect to the maximum likelihood estimator.

4.1 First order autoregressive models

The stationary univariate autoregressive process of order 1, denoted by
AR(1), is deﬁned by

1

1

y1 = µ +

−
yt = µ + φ(yt−1

p

z1

µ) + zt,

(t = 2, . . . , T ),

φ2

−

−

φ

where (zt) is a Gaussian white noise process with mean 0 and variance σ2.
is the autoregressive parameter . Then y1, . . . , yT
Here φ, with
are jointly normal with mean vector µ1T (where 1T is the T -dimensional
unit vector), and covariance matrix σ2Γ, with Γ having components Γlm =
φ|l−m|/(1

φ2) (l, m = 1, . . . , T ).

< 1,

|

|

For comparison purposes we consider also the numerical performance of
a class of pairwise likelihood estimators. Since, in the time series considered,
dependence decreases in time, as in Davis & Yau (2011) [8] we shall restrict
to the ﬁrst order consecutive pairwise likelihood , rather than the complete
pairwise likelihood, so that adjacent observations are more closely related
than the others. This choice is motivated also by the loss in eﬃciency incurred
in using the k-th order consecutive pairwise likelihood as k increases (see
Davis and Yau (2011) [8]; Joe and Lee (2009) [27]). Note that, when it is
known that µ = 0 but σ2 is unknown, the pairwise likelihood estimator of
t + y2
t=2(y2
φ is
t−1), which is also the Yule-Walker
estimator (Davis & Yau (2011) [8]).

T
t=2 ytyt−1/

φPL = 2

T

b

P

P

Simulation 1 The values of the model parameters are µ = 0 and σ = 1,
with the autoregressive parameter φ
In the
simulation study, 1000 replicates are generated of n = 200 processes of length
T = 50. Results are summarised in Table 1. The numerical results in Table 1
φHW do not have
and in the left-hand panel of Figure 1 suggest that

0.8, . . . , 0.8, 0.9

φHT and

∈ {−

0.9,

−

}

.

9

b

b

high eﬃciency as φ approaches 1: in particular, the asymptotic eﬃciency of
φ
φHW tends to 0 for large values of
. In contrast, under the same model
|
setting, there is only a modest loss of eﬃciency for the pairwise likelihood-
based estimator
b

φPL.

|

4.2 First order moving average models

b

The univariate moving average process of order 1, denoted by MA(1), is
deﬁned by

yt = µ + αzt−1 + zt,

(t = 1, . . . , T ),

(16)

|

|

α

< 1 and z0, . . . , zT are independent Gaussian random variables
where
with 0 mean and variance σ2. Then the random variables y1, . . . , yT are
jointly normal, each having mean µ and variance σ2(1 + α2). The variables
> 1, while yt and yt+1 have covariance σ2α
yt and yt+k are independent for
1). Hence, the covariance matrix σ2Γ of Y = (y1, y2, . . . , yT )
(t = 1, . . . , T
has components σ2Γss = σ2(1 + α2), σ2Γst = σ2α if
= 1, σ2Γst = 0
otherwise.

t
|

−

−

k

s

|

|

|

As before we consider the ﬁrst order consecutive pairwise likelihood since
the use of a higher order consecutive pairwise likelihood is unrealistic due
to the independence of yt and yt+k for k
1, the pair
(yt, yt+1) has a bivariate Gaussian distribution, in which the two components
both have mean µ and variance σ2(1 + α2), and have covariance σ2α.

2. For t = 1, . . . , T

≥

−

.

−

0.9,

∈ {−

0.8, . . . , 0.8, 0.9

Simulation 2 The values of the model parameters are µ = 0 and σ = 1,
with the moving average parameter α
In the
simulation study, 1000 replicates are generated of n = 200 processes of length
T = 50. Results are summarised in Table 2. The simulation shows that the
αHT achieves the same eﬃciency as the MLE in the
total Hyv¨arinen estimator
MA(1) model for values of the moving average parameter near 0; see Table 2
and the right-hand panel of Figure 1. However, the loss in eﬃciency of the
b
αHT is modest even when the absolute value of
total Hyv¨arinen estimator
the moving average parameter reaches 1. In contrast, the pairwise likelihood
αPL shows very poor performances in terms of asymptotic relative
estimator
eﬃciency: the ARE ranges from 1 to 0.1 as

increases.

α

b

}

|

|

b

4.3 Fractionally diﬀerenced white noise

The fractionally diﬀerenced white noise, ARFIMA(0, d, 0), model is deﬁned
by

Π)dyt = zt, with t = 1, . . . , T,

(1

−

10

where Π is the lag operator and d
(0, 0.5), and z1, . . . , zT are independent
Gaussian random variables with 0 mean and variance σ2. Then the random
variables y1, . . . , yT are jointly normal, with covariance matrix σ2Γ whose
components (see Hosking (1981) [22]) are

∈

σ2Γij =

Γ(

(

−
| −

k

|

1)|k|σ2Γ(1
d + 1)Γ(

−
k

2d)

−|

| −

d + 1)

(k = i

j)

−

(17)

(where in the right-hand side of (17), Γ denotes the gamma function.)

As before we consider the ﬁrst order consecutive pairwise likelihood
since no great improvement can be detected by using a higher order con-
secutive pairwise likelihood: see the results of Davis and Yau (2011) [8].
For t = 1, . . . , T
1, the pair (yt, yt+1) has a bivariate Gaussian distri-
in which the two components both have mean µ and variance
bution,
σ2Γ(1
2d)/Γ(1

d)2, and have covariance

2d)/Γ(2

σ2Γ(1

d)Γ(

d).

−

−

−

−

−

−

−

}

∈ {

0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3

Simulation 3 The values of the model parameters are µ = 0 and σ = 1,
with the fractional parameter d
. In the
simulation study, 1000 replicates are generated of n = 100 processes of length
T = 50. Results are sumarised in Table 3. Simulation 3 shows that the total
dHT achieves the same eﬃciency as the MLE in the
Hyv¨arinen estimator
ARFIMA(0, d, 0) model near 0 and near 0.3; see Table 3 and the right-hand
panel of Figure 1. The loss in eﬃciency of the total Hyv¨arinen estimator
dHW is poor with ARE
dHT is very slight when d
values ranging from 0 to 0.45. For all the estimators considered the ARE is
dHW,
0 when d
b
however the values of ARE range from 0.6 to 0.96, reaching a maximum when
d = 0.1, with a major loss of eﬃciency with respect to the total Hyv¨arinen
estimator.

(0.3, 0.5). The pairwise estimator

dPL performs better than

(0, 0.3). The eﬃciency of

∈

∈

b

b

b

b

4.4 Discussion

φHT,

αHT and

It should be noted that for the MA(1) and the ARFIMA(0, d, 0) models no
analytic expressions for the derivatives of (7) are available. The standard
dHT are empirical estimates of the square root of
deviations of
the Godambe information function, which is obtained by compounding the
empirical estimates of J and K. The standard deviations of the pairwise
maximum likelihood estimator and the maximum likelihood estimator are
obtained using the analytic expressions (see Pace et al. (2011) [31]) for the
AR(1) model and the empirical counterparts for the MA(1) model. Numer-
ical evaluation of scoring rule derivatives has been carried out using the R
package numDeriv; see Gilbert & Varadhan (2012) [19].

b

b

b

11

Results from simulations reveal that the estimators considered produce
estimates very close to the true values of the parameters. However, results
not shown here suggest that when the length T of the series is small the
pairwise likelihood estimator performs worse in terms of bias than the other
estimators in all the models considered.

The left, the middle and right-hand panels of Figure 1 depict the asymp-
totic relative eﬃciency as a function of φ for the AR(1) model, as a function
of α for the MA(1) model, and as a function of d for the ARFIMA(0, d, 0)
model, respectively.

All the results of the simulation studies are in agreement with the ﬁndings
of Davis & Yau (2011) [8] who focus on pairwise likelihood-based methods
for linear time series.

5 Conclusions

In this paper we have considered the use of Hyv¨arinen scoring rules in linear
time series estimation under diﬀerent conditions. We have established the
consistency of the Hyv¨arinen scoring rule estimator for a single times series
under some general conditions and its asymptotic normality in an ARMA
time series context.

We have investigated, for n independent time series, the performances of
two estimators based on the Hyv¨arinen scoring rule, which can be regarded
as a surrogate for a complex full likelihood. The properties of the estimators
found using this scoring rule are compared with the full and pairwise max-
imum likelihood estimators. Three simple models are discussed: the ﬁrst a
stationary ﬁrst order autoregressive model, the second a ﬁrst order moving
average model and the third a fractionally diﬀerenced white noise. In the
ﬁrst case the total Hyv¨arinen method leads to poor estimators; in contrast,
in the second and third this method produces good estimators. The opposite
behaviour is observed for the pairwise estimators. For the moving average
process and the fractionally diﬀerenced white noise, there can be a large gain
in eﬃciency, as compared to the pairwise likelihood method, by using the
total or the matrix Hyv¨arinen scoring rule estimators. For the autoregres-
sive model, in contrast, the total Hyv¨arinen score methods suﬀer a loss of
eﬃciency as

approaches 1.

φ

In all examples, results not reported here show that there is a great im-
provement in the performances of the matrix Hyv¨arinen estimator based on
the Wishart model as the ratio T /n becomes negligible. It is clear that the
loss of eﬃciency incurred in using the Hyv¨arinen scoring rules or pairwise
likelihood can be substantial, but this depends on the underlying model, and

|

|

12

no overall general principle has emerged that might oﬀer guidance for cases
not yet considered. The matrix Hyv¨arinen estimator has the apparent ad-
vantage over the other estimators (apart from full maximum likelihood) of
being based on the suﬃcient statistic of the model; nevertheless the total
Hyv¨arinen estimator shows good performance in terms of eﬃciency.

We conclude that minimising the total Hyv¨arinen score may oﬀer a vi-
able and useful approach to estimation in models where computation of the
normalising constant in the likelihood function is not feasible, and pairwise
likelihood methods lead to poor estimators.

Acknowledgements

Monica Musio was supported by the project GESTA of the Fondazione di
Sardegna and Regione Autonoma di Sardegna.

Appendix: Proof of Theorem 1

Let θ = (σ2, λ) and let Eθ denote the expectation with respect to the proba-
bility distribution for (yt) deﬁned in Equation (6). Let θ0 = (σ2
0, λ0) denote
the true parameter value. From the ergodicity of (yt), it follows that H(θ, YT )
is ergodic and stationary and therefore

1
T

H(θ, YT )

a.s.
−−→

H(θ0, θ) := Eθ0H(θ, y1).

(18)

Since the Hyv¨arinen score is strictly proper we have

H(θ0, θ)

H(θ0, θ0)

(19)

≥
with equality if and only if θ = θ0, by the identiﬁability condition (8). The
approach used to derive the consistency of the total Hyv¨arinen estimator
now follows the same general argument used to derive the consistency of the
pairwise likelihood estimator in Davis & Yau (2011) [8].

In particular, the compactness of Λ and the inequality (19) are used as

devices for proving the claim.

Appendix: Proof of Theorem 2

Deﬁne the sample gradient and Hessian as

JT (θ) :=

1
T

−

T

i=1
X

∂bii
∂θ

+

2
2T

T

i,j,t=1
X

∂bij
∂θ

bityjyt

13

and

KT (θ) :=

1
T

−

T

i=1
X

∂2bii
∂θ2 +

1
T

T

i,j,t=1
X

∂bij
∂θ

∂bit
∂θ

yjyt +

1
T

∂2bij
∂θ2 bityjyt.

T

i,j,t=1
X

Using a Taylor expansion of JT (θ) around θ0 and the consistency of
T be-

Hyv¨arinen scoring rule estimator, it can be proved that, for some θ+
tween θ0 and

θT ,

JT (θ0) = KT (θ+

T )√T (θ0

θT ).

−

(20)

The asymptotic distribution of

θT can be derived by exploiting the asymp-
b
T ) and JT (θ0), together with the ergodic theorem and

b

totic properties of KT (θ+
the fact that θ+
θ0.
T
Writing

a.s.
−−→

b

∂
∂θ0

=

∂
∂θ

Γ = Γ(λ0)

θ=θ0
(cid:12)
(cid:12)
(cid:12)
(cid:12)

it can be shown that

KT (θ+
T )

a.s.
−−→

T

i,j,t=1
X

∂bij
∂θ0

∂bit
∂θ0

σ2
0Γtj = K(θ0).

θT we need to calculate
In order to calculate the asymptotic distribution of
the expectation and the variance of JT (θ0). The calculation of the expecta-
tion of JT (θ0) follows easily from the unbiasdness of the scoring rule estimat-
ing equation (Dawid & Lauritzen (2005) [10]). However, calculation of the
variance of JT (θ0) is challenging due to the presence of the non deterministic
term

b

Bi =

j,t=1
X
It relies on the following calculation:

T

∂bij
∂θ0

bityjyt.

var(JT (θ0)) =

=

1
T

1
T

T

var(Bi) =

i=1
X
T

i,j,t,ℓ,h=1
X

∂bij
∂θ0

bit

∂biℓ
∂θ0

bihcov(yjyt, yℓyh)

14

=

=

where

T

∂bij
∂θ0

Γit
σ2
0

∂biℓ
∂θ0

Γih
σ2
0 {

cov(yj, yℓ)cov(yt, yh)

i,j,t,ℓ,h=1
X
+ cov(yj, yh)cov(yt, yℓ) + cum4(yj, yt, yℓ, yh)

T

i,j,t,ℓ,h=1
X

Ajℓth + Cjhtℓ + Ditℓh,

Ajℓth =

Cjhtℓ =

Ditℓh =

∂bij
∂θ0
∂bij
∂θ0
∂bij
∂θ0

Γit
σ2
0
Γit
σ2
0
Γit
σ2
0

∂biℓ
∂θ0
∂biℓ
∂θ0
∂biℓ
∂θ0

Γih
σ2
0
Γih
σ2
0
Γih
σ2
0

cov(yj, yℓ)cov(yt, yh)

cov(yj, yh)cov(yt, yℓ)

cum4(yj, yt, yℓ, yh).

The ﬁrst term in (21) simpliﬁes as

T

T

Ajℓth =

i,j,t,ℓ,h=1
X

i,j,t,ℓ,h=1
X

∂bij
∂θ0

Γii ∂biℓ
∂θ0

Γjℓ.

The second term simpliﬁes as

T

i,j,t,ℓ,h=1
X

Cjhtℓ = T

∂
∂θ0

2

.

γ−1(0)
σ2
0 (cid:19)

(cid:18)

}

(21)

(22)

(23)

The third term in (21), which involves the fourth cumulant, vanishes as for
Gaussian linear processes all the cumulant functions cumk for k > 3 are iden-
tically null Brockwell & Davis (1991) [4]. Hence convergence of var(JT (θ0))
is evaluated by considering only the ﬁrst non-constant term (22).

Equation (22) can be rewritten as

T

T

Ajℓth =

∂
∂θ0

γ−1(i
−
σ2
0

j)

γ−1(0)

∂
∂θ0

γ−1(i
−
σ2
0

ℓ)

γ(j

ℓ),

−

i,j,t,ℓ,h=1
X

i,j,ℓ=1
X
ℓ) = Γjℓ and γ−1(i

j) = Γij. Let k = i
where γ(j
Without lose of generality, we assume that γ(h) = 0 if
previous expression and consequently the ﬁrst term in (21) simpliﬁes to

ℓ.
> T . Then the

j and r = j

−
h
|
|

−

−

−

T

k,r=−T
X

(T

max

k

,

|

|

{|

−

k + r

r

,

|

|

|}

)

∂
∂θ0

γ−1(k)
σ2
0

γ−1(0)

∂
∂θ0

γ−1(k + r)
σ2
0

γ(r).

15

The absolute summability of the autocovariance and the duality proper-
ties of autocorrelation and of its inverse for causal invertible autoregressive-
moving average processes (see Cleveland (1972) [7], Chatﬁeld (1979) [6] and
Hosking (1980) [21]) guarantee the following holds:

T

(T

−

max

{|

k
,
|
T

|

k + r

r

,

|

|

|}

)

γ−1(0)

∂
∂θ0

γ−1(k)
σ2
0
γ−1(k)
∂
σ2
∂θ0
0

γ−1(0)

γ(r)

γ−1(k + r)
σ2
0
γ−1(k + r)
σ2
0

∂
∂θ0

γ(r)

V (r, k, θ0),

(24)

lim
T →∞

=

=

r,k=−T
X
∂
∂θ0
∞

×

r,k=−∞
X
∞

r,k=−∞
X

where

V (r, k, θ0) =

∂
∂θ0

2

γ−1(0)
σ2
0 (cid:19)

(cid:18)

+

∂
∂θ0

γ−1(k)
σ2
0

γ−1(0)

∂γ−1(k + r)
∂θ0

γ(r).

Combining equations (24) and (23) we obtain

var(JT (θ0))

V,

−→

(25)

where V =

∞
r,k=−∞ V (r, k, θ0).

P

Since J(θ0) depends on the Bi’s, which involve the sample autocovariance,
it follows from the asymptotic normality of the sample autocovariance of
ARMA processes that JT (θ0) is also asymptotically normal with zero mean
and variance V . From (20) and (25) we obtain the asymptotic normality of
θT :

√T (

θT

θ0) D
−→

−

Nm−1

0, K(θ0)−1V K T (θ0)−1

.

(cid:0)

(cid:1)

b

References

b

[1] Almeida, M. P. and B. Gidas (1993). A variational method for estimating
the parameters of MRF from complete or incomplete data. Annals of
Applied Probability, 3, 103–136.

[2] Barndorﬀ-Nielsen, O. E. & Cox, D. R. (1994). Inference and Asymp-

totics. Chapman & Hall, London.

16

[3] Brier, G. W. (1950). Veriﬁcation of forecasts expressed in terms of prob-

ability, Monthly Weather Review, 78, 1–3.

[4] Brockwell, P. J. and Davis, R. A. (1991). Time Series: Theory and

Methods. Springer, New York.

[5] Cattelan, M. & Sartori, N. (2016). Empirical and simulated adjustments
of composite likelihood ratio statistics, Journal of Statistical Computa-
tion and Simulation, 86, 1056-1067.

[6] Chatﬁeld, C. Inverse Autocorrelations. Journal of the Royal Statistical

Society. Series A, 142(3), 363-377.

[7] Cleveland, W. S. (1972) The Inverse Autocorrelations of a Time Series

and Their Applications. Technometrics, 14(2), 277-293.

[8] Davis, R. A. & Yau, C. Y. (2011). Comments on pairwise likelihood in

time series models. Statistica Sinica, 21, 255–277.

[9] Davison, A. C. (2003). Statistical Models. Cambridge University Press,

Cambridge.

[10] Dawid, A. P. & Lauritzen, S. L. (2005). The geometry of decision theory.
In Proceedings of the Second International Symposium on Information
Geometry and its Applications, 22–28. University of Tokyo.

[11] Dawid, A.P. (2007). The geometry of proper scoring rules. Ann. Inst.

Statist. Math, 59, 77–93.

[12] Dawid, A. P., Lauritzen, S. L. and Parry, M. (2012). Proper local scoring

rules on discrete sample spaces. Ann. Statist.—, 40, 593–608.

[13] Dawid, A. P. & Musio, M. (2014). Theory and applications of proper

scoring rules. Metron, 72, 169–183.

[14] Dawid, A. P., Musio, M. , & Ventura, L. (2016). Minimum scoring rule

inference. Scandinavian Journal of Statistics, 43, 1, 123–134.

[15] Dawid, A. P. & Musio, M. (2015). Bayesian model selection based on
proper scoring rules (with Discussion). Bayesian Analysis, 10(2), 479–
521.

[16] Dawid, A. P. & Musio, M., Columbu, S. (2017). A note on Bayesian
model selection for discrete data using proper scoring rules, Statistics &
Probability Letters, 129, 101–106.

17

[17] Ehm, W., Gneiting, T. Local proper scoring rules of order two Ann.

Statist., 40, 609–637.

[18] Forbes, P. G. M. & Lauritzen, S. (2015) Linear estimating equations for
exponential families with application to Gaussian linear concentration
models, Linear Algebra and its Applications, 473, 261–283.

[19] Gilbert, P. & Varadhan, R. (2012). numDeriv: Accurate Numerical

Derivatives. http://CRAN.R-project.org/package=numDeriv.

[20] Good, I. J. (1952). Rational decisions. Journal of the Royal Statistical

Society, Series B, 14, 107–114.

[21] Hosking, J. R. M. (1980). The Asymptotic Distribution of the Sample
Inverse Autocorrelations of an Autoregressive-Moving Average Process.
Biometrika, 67(1), 223–226.

[22] Hosking, J. R. M. (1981). Fractional diﬀerencing. Biometrika, 68(1),

165–176.

[23] Hyv¨arinen, A. (2005). Estimation of non-normalized statistical models
by score matching. Journal of Machine Learning Research, 6, 695–709.

[24] Hyv¨arinen, A. (2007). Some extensions of score matching. Computa-

tional Statistics and Data Analysis, 51, 2499–2512.

[25] Kollo, T. & von Rosen, D. (2005). Advanced Multivariate Statistics with

Matrices. Dordrecht: Springer.

[26] Kroese, D. P., Taimre, T. & Botev, Z. I. (2011). Handbook of Monte

Carlo Methods. John Wiley & Sons, Inc., Hoboken, New Jersey.

[27] Joe, H. & Lee, Y. (2009). On weighting of bivariate margins in pairwise

likelihood. Journal of Multivariate Analysis, 100, 670–685.

[28] Le Cessie, S. & Van Houwelingen, J. C. (1994). Logistic regression for
correlated binary data. Journal of the Royal Statistical Society, Series
C, 43, 95–108.

[29] Mardia, K. Kent, J., Laha, A. (2016). Score matching estimators for

directional distributions. arXiv:1604.08470.

[30] Musio, M. & Dawid, A. P. (2013). Local scoring rules: A versatile tool
for inference. In Proceedings of the 59th ISI World Statistics Congress,
Hong Kong.

http://2013.isiproceedings.org/Files/STS019-P3-S.pdf.

18

[31] Pace, L., Salvan, A., & Sartori, N. (2011). Adjusting composite likeli-

hood ratio statistics. Statistica Sinica, 21, 129–148.

[32] Park, J. and Haran, M. (2017). Bayesian Inference in the Presence of
Intractable Normalizing Functions. Journal of the American Statistical
Association, 113 (523), 1372–1390.

[33] Parry, M. F., Dawid, A. P., & Lauritzen, S. L. (2012). Proper local

scoring rules. The Annals of Statistics, 40, 561–592.

[34] R Core Team (2013). R: A language and environment for statistical
computing. R Foundation for Statistical Computing, Vienna, Austria.
ISBN 3-900051-07-0.

[35] Shao, S., Jacob, P. E., Ding, J. & Tarokh, V. (2018). Bayesian model
comparison with the Hyv¨arinen score: computation and consistency.
Journal of the American Statistical Association, online ﬁrst, DOI:
10.1080/01621459.2018.1518237

[36] Takasu, Y., Yano, K., Komaki, F. (2018). Scoring rules for statistical
models on spheres, Statistics & Probability Letters, 138, 111–115.

[37] Varin, C. (2008). On composite marginal likelihoods. AStA Advances in

Statistical Analysis, 92, 1–28.

[38] Varin, C., Reid, N., & Firth, D. (2011). An overview of composite like-

lihood methods. Statistica Sinica, 21, 5–42.

[39] von Rosen, D. (1988). Moments for the inverted Wishart distribution.

Scandinavian Journal of Statistics, 15, 97–109.

19

E
R
A

E
R
A

0
.
1

8
.
0

6
.
0

4
.
0

2
.
0

0
.
0

0
.
1

8
.
0

6
.
0

4
.
0

2
.
0

0
.
0

E
R
A

0
.
1

8
.
0

6
.
0

4
.
0

2
.
0

0
.
0

f^
f^
f^

p

H

HW

a^
a^
a^

p

H

HW

−0.5

0.0

0.5

−0.5

0.0

0.5

^
d
^
d
^
d

p

H

HW

0.00

0.05

0.10

0.15

0.20

0.25

0.30

d

Figure 1: Asymptotic relative eﬃciency of estimators for the AR(1) model
(left top panel),
for the MA(1) model (right top panel) and for the
ARFIMA(0, d, 0) model (left bottom panel).

20

f
a
Table 1: Simulation 1. Estimated mean (Est.), asymptotic standard de-
viation (sd), and asymptotic relative eﬃciency (ARE) of estimators of the
parameter φ in the AR(1) model, for n = 200, T = 50, and varying values
of φ. We denote by
φPL the pairwise
φHW the total and the matrix Hyv¨arinen
likelihood estimate, and by
estimates, respectively.

φ the maximum likelihood estimate, by

φHT and

b

b

φ

Est.

φ

b

sd

Est.

b
φPL

sd
b

b

ARE

Est.

φHT

sd

b

ARE

Est.

φHW

sd

b

ARE

0.9

−

0.8

−

0.7

−

0.6

−

0.5

−

0.4

−

0.3

−

0.2

−

0.1

−
0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

0.8997 0.0041

−

0.8000 0.0059

−

0.7002 0.0071

−

0.6002 0.0080

−

0.5001 0.0087

−

0.4002 0.0092

−

0.2997 0.0096

−

0.2003 0.0099

−

0.8997 0.0045 0.8625

−

0.7999 0.0064 0.8340

−

0.7001 0.0079 0.8087

−

0.6002 0.0089 0.7986

−

0.4999 0.0097 0.8069

−

0.4000 0.0101 0.8351

−

0.2997 0.0102 0.8808

−

0.2002 0.0102 0.9347

−

0.9008 0.0150 0.0738

−

0.8007 0.0146 0.1602

−

0.7007 0.0139 0.2599

−

0.6008 0.0130 0.3794

−

0.5009 0.0122 0.5060

−

0.4006 0.0115 0.6466

−

0.2998 0.0109 0.7773

−

0.2005 0.0104 0.8991

−

0.9004 0.0244 0.0278

−

0.8007 0.0236 0.0613

−

0.7005 0.0226 0.0979

−

0.6008 0.0216 0.1367

−

0.5011 0.0202 0.1853

−

0.4001 0.0184 0.2505

−

0.2995 0.0164 0.3438

−

0.2007 0.0143 0.4780

−

0.0997 0.0100

0.0997 0.0101 0.9813

0.0997 0.0102 0.9776

0.0999 0.0125 0.6493

−
0.0002

−
0.0002

0.0101

0.0101 0.9998

0.0101 1.0077

0.0117 0.7401

−
0.0002

−
0.0003

0.1005

0.0100

0.1005

0.0101 0.9810

0.1005

0.0101 0.9810

0.1007

0.0125 0.6506

0.1997

0.0099

0.1997

0.0102 0.9350

0.1998

0.0104 0.8980

0.1995

0.0143 0.4802

0.2997

0.0096

0.2997

0.0102 0.8808

0.2998

0.0109 0.7774

0.2995

0.0164 0.3433

0.3993

0.0092

0.3993

0.0101 0.8355

0.3997

0.0115 0.6451

0.3995

0.0184 0.2506

0.5002

0.0087

0.5003

0.0097 0.8071

0.5006

0.0122 0.5077

0.5004

0.0201 0.1867

0.5997

0.0080

0.5997

0.0089 0.7985

0.5998

0.0130 0.3757

0.5990

0.0215 0.1376

0.6992

0.0071

0.6992

0.0079 0.8087

0.6997

0.0138 0.2630

0.6993

0.0227 0.0977

0.8001

0.0058

0.8001

0.0064 0.8343

0.8006

0.0146 0.1605

0.8002

0.0235 0.0618

0.8998

0.0041

0.8998

0.0044 0.8622

0.8999

0.0150 0.0734

0.8987

0.0244 0.0278

21

Table 2: Simulation 2. Estimated mean (Est.), asymptotic standard de-
viation (sd), and asymptotic relative eﬃciency (ARE) of estimators of the
parameter α in the MA(1) model, for n = 200, T = 50, and varying values
αPL the pairwise
of α. We denote by
αHW the total and the matrix Hyv¨arinen
likelihood estimate, and by
estimates, respectively.

α the maximum likelihood estimate, by

αHT and

b

b

α

0.9

−

0.8

−

0.7

−

0.6

−

0.5

−

0.4

−

0.3

−

0.2

−

0.1

−
0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

b
αPL

sd

b

Est.

b

ARE

Est.

αHT

sd

b

αHW

ARE

Est.

sd

ARE

b

0.8996 0.0167 0.1064

−

0.7996 0.0176 0.1390

−

0.6996 0.0183 0.1692

−

0.6005 0.0182 0.2080

−

0.4999 0.0169 0.2757

−

0.3997 0.0148 0.3984

−

0.3000 0.0126 0.5905

−

0.2002 0.0111 0.7926

−

0.8999 0.0064 0.7208

−

0.7998 0.0075 0.7566

−

0.6997 0.0086 0.7583

−

0.6007 0.0095 0.7553

−

0.5007 0.0101 0.7646

−

0.4003 0.0104 0.8038

−

0.3006 0.0105 0.8527

−

0.2001 0.0104 0.9119

−

0.8993 0.0074 0.5471

−

0.7992 0.0091 0.5177

−

0.6993 0.0106 0.5020

−

0.6003 0.0119 0.4878

−

0.5002 0.0129 0.4743

−

0.4001 0.0136 0.4713

−

0.3006 0.0139 0.4838

−

0.1999 0.0135 0.5408

−

0.1004 0.0103 0.9456

0.1004 0.0101 0.9882

0.1006 0.0124 0.6557

α

Est.

sd

b
0.8998 0.0055

−

0.7997 0.0066

−

0.6997 0.0075

−

0.6004 0.0083

−

0.5004 0.0089

−

0.4000 0.0093

−

0.3003 0.0097

−

0.2000 0.0099

−

0.1003 0.0101

−
0.0001

0.0101

0.0101 1.0082

0.0101 1.0101

0.0117 0.7429

−
0.0001

−
0.0005

−
0.0001

0.1000

0.0101

0.1000

0.0103 0.9526

0.1001

0.0101 0.9933

0.0997

0.0124 0.6554

0.2000

0.0099

0.2000

0.0111 0.7932

0.2000

0.0104 0.9171

0.1994

0.0135 0.5402

0.2994

0.0097

0.2996

0.0126 0.5853

0.2994

0.0105 0.8475

0.2992

0.0139 0.4835

0.4000

0.0093

0.4006

0.0148 0.3979

0.4000

0.0105 0.7938

0.3994

0.0137 0.4639

0.5002

0.0089

0.5000

0.0169 0.2760

0.5004

0.0101 0.7672

0.5000

0.0129 0.4721

0.6001

0.0083

0.6000

0.0182 0.2075

0.6001

0.0095 0.7643

0.5993

0.0119 0.4850

0.6999

0.0075

0.6997

0.0182 0.1707

0.6999

0.0086 0.7682

0.6996

0.0106 0.5047

0.7999

0.0066

0.7997

0.0175 0.1402

0.8000

0.0075 0.7639

0.7995

0.0091 0.5209

0.8999

0.0055

0.8997

0.0167 0.1072

0.9000

0.0064 0.7300

0.8995

0.0074 0.5504

22

Table 3: Simulation 3. Estimated mean (Est.), asymptotic standard de-
viation (sd), and asymptotic relative eﬃciency (ARE) of estimators of the
parameter d in the ARFIMA model, for n = 200, T = 50, and varying values
of d. We denote by
dPL the pairwise
dHW the total and the matrix Hyv¨arinen
likelihood estimate, and by
estimates, respectively.

d the maximum likelihood estimate, by

dHT and

b

b

d

Est.

d

b

sd

Est.

b
dPL

sd
b

b

ARE

Est.

dHT

sd
b

ARE

Est.

dHW

sd
b

ARE

0.01

0.0121 0.0059

0.0101 0.007

0.7015

0.0101 0.0059 0.9866

0.0105 0.0087 0.4537

0.05

0.0526 0.0062

0.0499 0.0067 0.8585

0.0499 0.0065 0.9257

0.0504 0.0117 0.2827

0.1

0.1034 0.006

0.0997 0.0062 0.9593

0.1

0.0067 0.8241

0.1001 0.0128 0.223

0.15

0.1545 0.0052

0.15

0.0054 0.9258

0.1503 0.0058 0.8226

0.1497 0.0108 0.2349

0.20

0.2041 0.0038

0.1999 0.0043 0.8061

0.2

0.0041 0.8809

0.1997 0.0077 0.2475

0.25

0.2587 0.0021

0.2499 0.0026 0.6173

0.2499 0.0021 0.9339

0.2495 0.0038 0.3005

0.3

0.3032 0

0.3

0.0009 0

0.3

0.0001 0

0.3

0.0043 0

23

