Connecting Sharpe ratio and Student t-statistic, and
beyond

,
Eric Benhamou ∗

,

†

‡

Abstract

Sharpe ratio is widely used in asset management to compare and benchmark funds and
asset managers. It computes the ratio of the excess return over the strategy standard
deviation. However, the elements to compute the Sharpe ratio, namely, the expected
returns and the volatilities are unknown numbers and need to be estimated statistically.
This means that the Sharpe ratio used by funds is subject to be error prone because
of statistical estimation error. Lo (2002), Mertens (2002) derive explicit expressions
for the statistical distribution of the Sharpe ratio using standard asymptotic theory
under several sets of assumptions (independent normally distributed - and identically
distributed returns). In this paper, we provide the exact distribution of the Sharpe ratio
for independent normally distributed return. In this case, the Sharpe ratio statistic
is up to a rescaling factor a non centered Student distribution whose characteristics
have been widely studied by statisticians. The asymptotic behavior of our distribution
provides the result of Lo (2002). We also illustrate the fact that the empirical Sharpe
ratio is asymptotically optimal in the sense that it achieves the Cramer Rao bound.
We then study the empirical SR under AR(1) assumptions and investigate the eﬀect of
compounding period on the Sharpe (computing the annual Sharpe with monthly data
for instance). We ﬁnally provide general formula in this case of heteroscedasticity and
autocorrelation.

JEL classiﬁcation: C12, G11.

Keywords: Sharpe ratio, Student distribution, compounding eﬀect on Sharpe, AR(1), Cramer
Rao bound

9
1
0
2

y
a
M
4
1

]
T
S
.
n
i
f
-
q
[

4
v
3
3
2
4
0
.
8
0
8
1
:
v
i
X
r
a

∗A.I. SQUARE CONNECT, 35 Boulevard d’Inkermann 92200 Neuilly sur Seine, France
†LAMSADE, Universit Paris Dauphine, Place du Marchal de Lattre de Tassigny,75016 Paris, France
‡E-mail: eric.benhamou@aisquareconnect.com, eric.benhamou@dauphine.eu

1

 
 
 
 
 
 
1.

Introduction

When facing choices to invest in various funds (whether mutual or hedge funds), it is
quite common to compare their Sharpe ratio in order to rank funds. This indicator aims at
measuring performance for a given risk. This eponymous ratio established by Sharpe (1966)

is a simple number easy to understand. It computes the ratio of the excess return over the
strategy standard deviation. However, the elements to compute the Sharpe ratio, namely,

the expected returns and the volatilities are unknown numbers and need to be estimated
statistically. This means that the Sharpe ratio used by funds is subject to be error prone be-
cause of statistical estimation error. In a seminal paper, Lo (2002) derive explicit expressions

for the statistical distribution of the Sharpe ratio using standard asymptotic theory under
several sets of assumptions (independent normally distributed - and identically distributed

returns). This is interesting as it provides intuition of potential bias and correction to apply
to get an unbiased estimator. However, the results are provided as asymptotic results. It
could be interested to derive or extend result to the non asymptotic distribution. This is

precisely the contribution of this paper. First, we extend provide the exact distribution of
the Sharpe ratio for independent normally distributed return. We show that under these

conditions, the Sharpe ratio statistic is a non centered Student distribution whose character-
istics have been widely studied by statisticians, up to a rescaling factor. Results of Lo (2002)
are easily derived as the limit of our results when the sample size tends to be large. We also

study the asymptotic eﬃciency of the Sharpe ratio statistics and provide exact distribution
under AR(1) normal process conditions. We examine ﬁnally the impact of compounding

eﬀect for computing the Sharpe ratio. The standard square root rule is questionable as soon
as there is autocorrelation or homoscedasticity.

2. Primer on Student distribution

2.1. Historical anecdote: why Student?

The Student t-distribution has been widely studied in statistics. Originally derived as

a posterior distribution in 1876 by Helmert (1876) and Luroth (1876) as well as in a more
general form as Pearson Type IV distribution in Pearson (1895), the Student distribution
was really popularized by William Sealy Gosset in Student alias W. S. Gosset (1908). There

is various interpretations why this distribution has been published under the pseudonym
’Student’.

Gosset, an Oxford graduate, worked at the Guinness Brewery in Dublin, Ireland. He was
interested in testing small samples for instance, he wanted to test the chemical properties

1

of barley where sample sizes might be as few as 3. The main version of the origin of the
pseudonym is that Gosset’s employer, Guiness, preferred staﬀ to use pen names to keep secret
their inventions. So when publishing scientiﬁc papers, instead of their real name, scientist

used diﬀerent names to hide their identity. Gosset chose the name ”Student”. Posterity kept
this name for the distribution. Another version is that Guinness was reluctant to make public

to their competitors their usage of the t-test to determine the quality of raw materials. All
in all, Gosset’s most noteworthy achievement is now called Student’s, rather than Gosset’s,
t-distribution.

2.2. Assumptions

If X, ..., Xn are independent and identically distributed as a normal distribution with

mean µ and variance σ2, then the empirical average

¯X =

1
n

n

Xi

i=1
X

follows also a normal distribution. The empirical (Bessel-corrected) variance

ˆσ2 =

1

−

1

n

n

i=1
X

¯X)2

(Xi −

follows (up to the renormalizing term n
freedom. The t- statistic deﬁned as

−

1) a Chi Square distribution with n

1 degree of

−

¯X
µ0
−
ˆσ/√n

= √n

¯X

ˆµ0

−
ˆσ

(1)

has a Student’s t-distribution with n

1 degrees of freedom. If the variables (Xi)i=1..n
have a mean µ diﬀerent from µ0, the distribution is referred to as a non-central t-distribution
with non centrality parameter given by

−

η = √n

µ0

µ

−
σ

(2)

It is simply the expectation of the estimator. The centered and non centered Student dis-

tribution are very well known. Extension to weaker condition for the t-statistics has been
widely studied. Mauldon (1956) raised the question for which pdfs the t-statistic as deﬁned
by 1 is t-distributed with n
1 degrees of freedom. This characterization problem can be gen-

eralized to the one of ﬁnding all the pdfs for which a certain statistic possesses the property

−

2

which is a characteristic for these pdfs. Kagan, Linnik, and Rao (1973), Bondesson (1974)
and Bondesson (1983) to cite a few tackled Mauldons problem. Bondesson (1983) proved
the necessary and suﬃcient condition for a t-statistic to have Students t-distribution with

−

n
1 degrees of freedom for all sample sizes is the normality of the underlying distribution.
It is not necessary that X1, ..., Xn is an independent sample. Indeed consider X1, ..., Xn as
a random vector Xn = (X1, ..., Xn)T each component of which having the same marginal
distribution function, F (). Efron (1969) has pointed out that the weaker condition of sym-
metry can replace the normality assumption. Later, Fang, Yang, and Kotz (2001) showed
that if the vector Xn has a spherical distribution, then the t-statistic has a t-distribution. A
possible extension of Mauldons problem is to ﬁnd all F () for which the Students t-statistic

has the t-distribution with n
distribution of the t-statistic under weaker conditions.

−

1 degrees of freedom. Another extension is to determine the

2.3. A few properties

Its cumulative distribution function can be expressed in closed form (see for instance

Lenth (1989)) as follows:

Fn

−

1,η(x) =

1,η(x),
˜Fn

1,

0;

if x

≥
if x < 0,

η(x),

(3)

˜Fn

−


1


−

−
−
j + 1

1

+ qjIy

j + 1, n

1

−
2

,

(cid:1)

(cid:0)

(cid:1)(cid:3)

−

−

∞j=0

pjIy


2, n

1,η(x) = Φ(

where ˜Fn
η) + 1
−
2
2
Iy(a, b) is the regularized incomplete beta function,
y = x2
1,
x2+n
−
j! exp
η
√2Γ(j+3/2)

pj = 1

exp

o (cid:16)

(cid:17)
η2
2

η2
2

η2
2

η2
2

P

−

n

(cid:0)

(cid:2)

,

,

j

j

qj =
and Φ is the cumulative distribution function of the standard normal distribution.

−

o (cid:16)

(cid:17)

n

Its probability density function can be expressed in several forms. The most common form
(as implemented in R) is the following:

f (x) =

n

1

−
x

√πn






x

Fn+1,η
Γ( n
2 )
n
1Γ( n−1
−

(cid:16)
q
2 ) exp

1

1 + 2
n
−
η2
,
2

−

(cid:16)

(cid:17)

3

Fn

−

−

(cid:17)

1,η(x)

,

if x

= 0;

o

if x = 0.

(4)

6
In general, the kth raw moment of the non-central t-distribution is

n

1

−
2

k

2 Γ( n−1−k
Γ( n−1
2 )

2

)

exp


(cid:0)
Does not exist,


(cid:1)

η2
2

dk
dηk exp

η2
2

,

if n

(cid:17)

(cid:16)

(cid:17)

if n

−

(cid:16)

1 > k;

k.

1

≤

−

−

(5)

E

T k

=

(cid:2)

(cid:3)

2.4. Lower moments



In particular, for n > 3, the mean and variance of the non-central t-distribution are

deﬁned and given by

= η kn

(6)

E [T ] = η

r
(n

V ar [T ] =

−

n

1

2
Γ( n
2 )
−
−
1
Γ( n
2
2 )
−
1)(1 + η2)
n
3
Γ( n−2
2 )
−
Γ( n−1
2
2 )
32n2 + O(n−

−
1

n

E [T ]2

−

Γ(n+1/2)

where we have deﬁned the constant kn =
Γ(n+1) ) is 1 + 3
to the Wallis ratio 1
3) (see Gallagher (2011)). More on
√π
the Wallis ratio and multiple approximations can be for instance found in Mortici (2010),
Guo, Xu, and Qi (2013), Qi and Mortici (2015), Lin, Ma, and Chen (2017)). Another good
approximation is

. A good approximation for kn (related

q
4n + 25

.

1

Instead of the constant kn, it is quite common in statistical control litterature (see Duncan
(1986) for instance) to use another constant called c4(n) (since there exists table for it) deﬁned
as follows

3
4n−5

1

−

c4(n) =

Γ( n
2 )
1
Γ( n
2 )
−

1

2

−

n

r

(7)

Using the traditional property of the Gamma function Γ(n + 1) = nΓ(n), it is immediate

to see that kn = n
n

1
2c4(n).

−
−

2.5. Asymptotic distribution

When n tends to inﬁnity, the t-distribution denoted by t tends to a normal distribution
denoted by N(η, σ) whose parameters are the ﬁrst two moment of the non centered Student

distribution. A better approximation is provided by Walck (2007) which states that

t(1

1
1) )
4(n
−
−
1 + t2
2(n
−

q

N(0, 1)

→

(8)

η

−

1)

4

3. Application to the Sharpe ratio

3.1. Non central distribution

Let us apply these result to the eponymous Sharpe ratio denoted in the sequel (SR).
Rf ) over the risk free

Recall that it is deﬁned as the ratio of expected excess return ( ¯R
rate Rf to its standard deviation, σ:

−

SR =

¯R

Rf

−
σ

(9)

The Sharpe ratio is simply the t-statistic divided by √n. In other terms, √nSR follows a
(centered or not) Student distribution under the explicit assumption that the returns
are normally distributed according to a normal distribution with mean µR = ¯R,
variance σ2 and are i.i.d.. Because ¯R and σ are unobservable, they are estimated using
historical data as the population moments of the returns’ distribution. Hence, given historical
returns (R1, R2, ..., Rn), the standard estimator for the Sharpe ratio (SR) is given by

where

SR =

ˆ¯R

Rf

−
ˆσ

c
ˆ¯R =

n
i=1 Ri
n

P

or equivalently

n
i=1

P

2

ˆ¯R

(cid:17)

Ri −
1
−

(cid:16)
n

(10)

(11)

(12)

ˆ¯R2

(cid:17)

n
i=1

P

(cid:16)
n

R2

i −
1

−

ˆσ = v
u
u
t

ˆσ = v
u
u
t

Precomputing ˆ¯R avoids a double summation in the deﬁnition of the volatility estimator. The
n
1 divisor is for the estimator to be unbiased. Hence, the formula for SR in terms of the
individual returns (Ri)i=1..n is given by:

−

SR =

√n

1

−

c

n

r

n

i=1 (Ri −
ˆ¯R
Ri −

n
P
i=1

P

(cid:16)

Rf )
2

(cid:17)

(13)

An immediate application of the results of section 2 shows that √nSR follows a non-
1. The non-centrality parameter µ is given

central t-distribution with degree of freedom n

−

by

η = √n

Rf

µR −
σ

= √n SR

∞

(14)

5

where the theoretical Sharpe ratio SR

. Section 2 provides
the exact distribution of the SR. This result that is quite basic is surprisingly almost absents
in the ﬁnancial literature although it was alluded in Miller and Gehr (1978). It is not for

is deﬁned as SR

−
σ

∞

∞

= µR

Rf

instance mentioned or noted in Lo (2002). This result although simple is powerful yet as it
provides various results for the Sharpe ratio.

•

•

•

First, it provides the real distribution (and leads obviously to the asymptotic distribu-
tion as the asymptotic distribution of the non-central t-distribution).
Second, all results for the t-statistic are directly transposable to SR, meaning we get for

free any results about test, moments, cumulative distribution and cumulative density
functions.

Third, as we are able to compute moments, we can immediately see that SR is biased
estimator

3.2. Moments

We have in particular that the moments of the Sharpe ratio estimator are immediately

provided by

and

E [SR] = SR

= SR

∞ r
kn

∞

n

1

Γ((n
Γ(n

−
2

2)/2)
1/2)

−
−

V ar [SR] =

(n

−

1)(1 + SR2
∞
n
3

)

−

E [SR]2

−
Equation 15 implies in particular that the empirical SR is biased with a bias term given
by kn, which is a result already noted in Miller and Gehr (1978) and Jobson and Korkie
(1981). As the constant kn is larger than one and multiplicative, the empirical Sharpe ratio
will overestimate SR
when positive, and underestimate when negative. For one year of
data and monthly data point, the bias k12 is about 1.08, indicating an overestimation of 8
percents. We provide below in table 1 the computation of bias for various value of n. The

∞

bias decreases rapidly as n increases and is below 2 percents after roughly 3 years.

6

(15)

(16)

(17)

Table 1: Sharpe ratio biais

n

3

6

12

24

36

48

60

120

bias

1.772

1.189

1.075

1.034

1.022

1.016

1.013

1.006

3.3. A few results

Using previous results 3.2, we have the following result that extends the result of Lo

(2002)

Proposition 1. SR under normal i.i.d. returns assumption is asymptotically normal in n

with standard deviation σIID,1 given by

σIID,1 =

1 +

r

SR2
∞
2

(18)

Another asymptotic approximation for the standard deviation (that is better for small n) is
given by

Last but not least, a more precise estimation of the standard deviation is given by

σIID,2 =

s

∞

1 + SR2
2
1/n
1

−

1 + SR2

∞
1/n)

σIID,3 =

q
1

−

2(1
−
1
4(n

−

1)

The proposition means from a distribution point of view the following

√n( ˆSR

SR

∞

)

−

→

N(0, σIID,i)

(19)

(20)

(21)

for i = 1 to 3 depending on which version of the asymptotic standard deviation is used,

where in the equation (21) the normal distribution is parametrized in terms of the standard
deviation.

Proof. Immediate using previous results and given in A.0.1

Proposition 1 provides tighter bound for the asymptotic distribution than the one pro-

vided in Lo (2002). In particular, it states that the 1
Sharpe ratio ˆSR is given by

−

α conﬁdence interval for the empirical

ˆSR

±

qα/2σIID,i

7

(22)

for i = 1 to 3 where qα/2 is the α/2 quantile of the normal distribution in the asymptotic case.
In the non asymptotic case, one needs to use the quantile of the non centered distribution. It
is enlightening to compare the various estimator of the variance of SR. We provide in table

2 the computation of these volatilities for various values of SR and n according to formula
σIID,3 For reference, we have also provided in appendix computation according to formula
σIID,1 respectivly σIID,2 in table 3 and 4 as well as the diﬀerence with our best estimator of
the variance of the Sharpe ratio.

Table 2: Asymptotic variance for SR according to formula σIID,3

SR

0.5
0.75
1

1.25
1.5
1.75

2
2.25

2.5
2.75
3

12

24

36

48

60

125

250

500

0.308
0.330
0.359

0.393
0.431
0.472

0.515
0.560

0.606
0.654
0.702

0.217
0.232
0.252

0.275
0.301
0.329

0.359
0.390

0.421
0.454
0.487

0.177
0.189
0.205

0.224
0.245
0.267

0.291
0.316

0.342
0.369
0.395

0.153
0.164
0.177

0.194
0.212
0.231

0.252
0.273

0.296
0.318
0.341

0.137
0.146
0.159

0.173
0.189
0.206

0.225
0.244

0.264
0.284
0.305

0.095
0.101
0.110

0.120
0.131
0.143

0.155
0.169

0.182
0.196
0.210

0.067
0.072
0.078

0.084
0.092
0.101

0.110
0.119

0.129
0.139
0.149

0.047
0.051
0.055

0.060
0.065
0.071

0.078
0.084

0.091
0.098
0.105

An interesting feature of SR variance is that it decreases asymptotically as 1

n or equiva-
lently as 1
n . SR variance is quite large as for instance for an empirical Sharpe ratio of 1 and
12 month of data, the variance represents almost .36 or 36% of it. If we take a quantile of
97.5% whose student quantile is 2.201 (for 11 degree of freedom) as opposed to the normal

0.359
well known quantile of 1.96, this implies that our Sharpe ratio lies between 1
which provides as boundaries that the empirical Sharpe lies between [0.210, 1.790]. This is
very wide range and shows the imprecision of the Sharpe. Even for longer maturities like 5

2.201

×

±

years, the range is still wide: 1

2.00

×

±

0.159 = [0.682, 1.318].

3.4. Eﬃciency of the empirical Sharpe ratio

Using the Frechet Darmois Cramer Rao inequality, we can prove the following result

that shows that the empirical SR is asymptotically eﬃcient in the sense that it achieves the
Cramer Rao bound

8

Proposition 2. under normal i.i.d. returns assumption, the estimator resulting from the
empirical SR and the empirical variance is asymptotically eﬃcient, meaning that it achieves
the lower bound in terms of Cramer Rao bound given by

CRB =

1
n 

Proof. Given in A.0.2

3.5. Weaker conditions

1 + SR2
/2
∞
σ2
SR

−

∞

σ2

−

SR
∞
2σ4

!

(23)

Lo (2002), Mertens (2002) and later Christie (2005) derived the asymptotic distribu-

tion of the Sharpe ratio under the more relaxed assumption of stationarity and ergodicity.
Opdyke (2007) interestingly showed that the derivation provided by Christie (2005) under

the non-IID returns condition was in fact identical to the one provided by Mertens (2002).
Liu, Rekkas, and Wong (2012) and Qi, Rekkas, and Wong (2018) improved approximation
accuracy to order O(n−

3/2) .

3.6. Sample SR under AR(1) assumptions

3.6.1. Exact distribution for normal AR(1)

The i.i.d. normal assumption for the return is far from being veriﬁed in practice. A more

realistic set-up is to assume that the returns follow an AR(1) process deﬁned as follows:

Rt = µ + ǫt
ǫt = ρǫt

1 + σvt

−

(

1;

2;

t

t

≥

≥

(24)

where vt is an independent white noise processes (i.i.d. variables with zero mean and

unit constant variance). To assume a stationary process, we impose

It is easy to check that equation 24 is equivalent to

ρ

| ≤

|

1

Rt = µ + ρ(Rt

−

µ) + σvt

1 −

2;

t

≥

(25)

(26)

9

We can also easily check that the variance and covariance of the returns are given by

V (Rt)
Cov(Rt, Ru) = σ2ρ|t−u|
ρ2

= σ2
ρ2

−

1

1

−

for t

1

≥
for t, u

1

≥

(27)

Both expressions in 27 are independent of time t and the covariance only depends on
implying that Rt is a stationary process. If we now look at the empirical SR under
u
|

t

−

|
these assumptions, it should converge to

E[Rt]

Rf
−
var(Rt)

µ

−

=

Rf
σ2
ρ2

1

−

3.6.2.

Impact of sub-sampling

p

q

(28)

Another interesting feature that was ﬁrst mentioned in Lo (2002), is the impact of com-
puting annual Sharpe using monthly data. This can be formalized as follows: Let us deﬁne

the q period return as

Rt(q)

Rt + Rt

−

≡

1 + . . . + Rt

−

q+1

(29)

where in our deﬁnition, we have ignored the eﬀects of compounding for computational eﬃ-
ciency1. We are interested in measuring eﬀect of auto correlation and heteroscedasticity of
returns on the Sharpe ratio and the impact of using for instance monthly return for com-

puting annual Sharpe. Let us denote by SR(q) the SR computed with q period returns. Its
limit is deﬁned as follows:

SR(q) =

E[Rt(q)]

Rf
V ar[Rt(q)]

−

(30)

p
Let us denote the returns mean by µ, the auto correlation by ρu,v = Corr(Ru, Rv) and
V ar[Rt]. It is interesting to see the linkage between
. This is the

the returns variance by σ2
→∞
∞
the q period SR denoted by SR(q) and the regular SR denoted by SR = µ
−
σ∞
subject of the following proposition

= limt

Rf

Proposition 3. The ratio between the q period returns SR(q) and the regular SR is the
following:

qσ

SR(q)
SR

=

q
1
i=0 σ2
−
t
−

i + 2

q
1
−
k=1

∞
q
1
−
i=0

k

−

ρt

i,t

−

i

−

kσt

−

iσt

−

k

i

−

(31)

−
1Of course, the exact expression for compounding returns is Rt(q)

qP

P

P

1. But the sake
of clarity, we can ignore the compounding eﬀect in our section as this will be second order eﬀect. Equally,
we could use log or continuously compounded returns deﬁned as log(Pt/Pt−1) in which case, our deﬁnition
would be exact

Q

≡

−

q−1
i=0 (1 + Rt−j)

10

If the return process is stationary with a constant variance σ2 = V ar[Rt] = σ2
∞
correlation denoted by ρv

u = Corr(Ru, Rv), this relationship simpliﬁes to

−

and stationary

SR(q)
SR

=

1 + 2

r

q
q
1
k=1(q
−

k)ρk

−

If in addition, the returns follow an AR(1) process ρk = ρk, equation 32 becomes

P

SR(q)
SR

=

s

1 + 2ρ
ρ
1
−

q

1

(cid:16)

−

1
−
q(1

ρq
ρ)

−

(cid:17)

If the returns are non correlated (ρk = 0), equation 33 becomes

SR(q)
SR

= √q

(32)

(33)

(34)

The last equation is the so called square root rule that states that the annual Sharpe is equal
to √12 the monthly Sharpe.

Proof. Given in A.0.3

A numerical result is provided in table 7. Proposition 3 is important as it shows that the

compounding eﬀect (computing annual Sharpe with monthly return) can have some large
impact when using the square root rule to convert the monthly Sharpe to the annual Sharpe
in presence of autocorrelation and heteroscedasticity.

4. Conclusion

Even if Sharpe ratio is the norm of funds ﬁnancial analysis, we have shown that its em-

pirical estimate has various bias that makes its usage for ranking questionable. Generally,
there is well reported literature that Sharpe ratios are skewed to the left, fat tailed and
very sensitive to small samples (see Goetzmann, Ingersoll, Spiegel, and Welch (2002)). Not

surprisingly, the bias are highly inﬂuenced by the statistical properties of the returns time
series (and in particular auto-correlation and heteroscedasticy). Our work extends previous

results in terms of the real distribution of the empirical Sharpe ratio and give as a by-product
standards results obtained in the Sharpe ratio ﬁnancial literature. This work advocates for
more substantial analysis when ever comparing funds and in particular a good understanding

of investment style to identify potential skew and autocorrelation in fund presented perfor-
mance monthly returns. This also encourages to use various other performance ratios to

analyze deeply funds performance.

11

Appendix A. Various Proofs

A.0.1. Proof of Proposition 1

Section 2.5 states that √n SR tends asymptotically to a normal distribution whose ﬁrst

two moments are given by the asymptotic limit of 15 and 17. 17 provided the exact formula
for the standard deviation of √nSR. Denoting by σ2
IID the variance of the random variable
√nSR, and using the expression for the variance of SR thanks to equation (17), we get
using a Taylor expansion in power of 1
n :

σ2
IID
n

=

=

=

(n

1
n
1
n

−

−

1)(1 + SR2
∞
n
3
+ SR2
∞
SR2
∞
2n

+ O(

((1

−

+

1
n
1
n2 )

)

(SR

∞

−

kn)2

)(1 +

3
n

)

−

(1 +

6
4n

)) + O(

1
n2 )

(35)

(36)

(37)

This is the result obtained by Lo (2002). It is obviously equivalent asymptotically to
σIID,2. If we use the result provided by 8, we have another approximation for the standard
deviation given by

σIID,3 =

A.0.2. Proof of Proposition 2

1

n + SR2

∞
1)

2(n
1
4(n

−

−

1)

q
1

−

(38)

The log-likelihood of i.i.d. returns with normal distribution with unknown Sharpe ratio

s and variance v is given by

(s, v) =

L

n
2

−

log (2πv)

n

−

i=1
X

(Ri −

Rf −
2v

sv1/2)2

(39)

The Fisher information for the estimator resulting from the empirical SR and the empir-

ical variance is computed as the expected opposite of the second order derivative of the log
likelihood with respect to the parameters denoted by θ = (s, v)T

(s, v) =

I

E

−

(cid:18)

∂2

(s, v)
L
∂2θ

θ

|

(cid:19)

(40)

This log-likelihood is computed for the parameters that maximizes the log likelihood and

12

given by

¯s =

¯v =

n

i=1(Ri −
n v1/2
i=1(Ri −

P
n

Straight computation using 41 leads to

P

Rf )

Rf −
n

¯sv1/2)2

∂2

∂2

(s, v)
L
∂2s
(s, v)

L
∂v∂s

∂2

(s, v)
L
∂2v

=

=

=

n

−

s
2v
2 + s2
4v2

−

−

This implies that the Fisher information is given by

(s, v) = n

I

1
s
2v

s
2v
2+s2
4v2 !

Inverting is trivial and leads to the Cramer Rao bound as follows:

CRB =

I

1(s, v) =

−

1
n 

1 + s2/2
sσ2

−

sσ2
−
2σ4 !

(41)

(42)

(43)

(44)

(45)

(46)

(47)

Now if we consider the estimator given by the empirical Sharpe ratio and the variance
. It is an unbiased estimator of [s, v]T . Equations 17 and 15 state that the variance

T

ˆSR, ˆv
of ˆSR is given by
h
i

V ar [SR] =

(n

−

)

1)(1 + SR2
∞
n
3

−

(SR

∞

−

kn)2

(48)

n

n

whose asymptotic limit is (see 18) 1+s2/2

. The variance of the empirical variance is well
1 that is asymptotically equivalent to 2σ4
known and given by 2σ4
n . The covariance term
between the empirical SR and the variance is more involved and can be found in Mertens
sσ2
n which concludes the
(2002) or Pav (2016) and is asymptomatically equivalent to by −
proof as the estimator given by the empirical Sharpe ratio and the variance achieves the
Cramer-Rao lower bound asymptotically.

−

13

 
A.0.3. Proof of Proposition 3

The numerator of the empirical SR converges to q(µ

Rf ) where µ denotes the returns
mean. The denominator can be expanded to measure the impact of (auto)correlation between
returns as follows:

−

V ar[Rt(q)] =

1

q

q

−

1

−

Cov(Rt

−

i, Rt

−

j)

j=0
X

=

i=0
X
1
q
−

i=0
X

V ar(Rt

−

i) + 2

q

1

−

q

1

−

i=0
X

j=i+1
X

Cov(Rt

−

i, Rt

−

j)

(49)

(50)

Using the change of variable, k = j

i, denoting by ρu,v = Corr(Ru, Rv) and by σ2

u =

V ar(V ar(Ru), we get the following expression:

−

V ar[Rt(q)] =

q

1

−

i=0
X

σ2
t
−

i + 2

1

q

q

−

k

1

−

−

Xk=1

i=0
X

ρt

−

i,t

−

i

−

kσt

−

iσt

−

k

i

−

(51)

Computed the fraction SR(q)

SR leads to the result of equation 31. This is the most general

formula that extends the one of Lo (2002).

If the return process is stationary with a constant variance, then

•
•

σu does not depend on u and can be denoted by σ,
ρu,v only depends on the absolute diﬀerence between u and v and is written for v
as ρv

u

−

Then equation 51 becomes

V ar[Rt(q)] = σ2

q + 2

q

1

−

(q

Xk=1

k)ρk

−

!

Again, computing the fraction SR(q)
For AR(1) process, we have ρk = ρk and equation 52 becomes

SR leads to the result of equation 32.

V ar[Rt(q)] = σ2

q +

(cid:20)

2ρ

ρ

1

−

1
(cid:18)

−

ρq
ρ)

1
q(1

−
−

(cid:19)(cid:21)

u

≥

(52)

(53)

where we have used

immediate.

P

q

2

k=0 ρk = 1

−

ρq−1
−
ρ
1

−

and

q
1
k=0 kρk
−

1 =

−

1−ρq
1−ρ −
(1
−

qρq−1
ρ)

. Equation 34 is

P

14

 
Appendix B. Numerical applications

B.1. Variance computation

We provide here values of the variance of the Sharpe ratio according to formula σIID,1
respectivly σIID,2 in table 4 and 2 as well as the diﬀerence with our best estimator of the
variance of the Sharpe ratio.

Table 3: Asymptotic variance for SR according to formula σIID,1

SR

0.5
0.75
1

1.25
1.5

1.75
2
2.25

2.5
2.75

12

24

36

48

60

125

250

500

0.306
0.327
0.354

0.385
0.421

0.459
0.500
0.542

0.586
0.631

0.217
0.231
0.250

0.272
0.298

0.325
0.354
0.384

0.415
0.446

0.177
0.189
0.204

0.222
0.243

0.265
0.289
0.313

0.339
0.364

0.153
0.163
0.177

0.193
0.210

0.230
0.250
0.271

0.293
0.316

0.137
0.146
0.158

0.172
0.188

0.205
0.224
0.243

0.262
0.282

0.095
0.101
0.110

0.119
0.130

0.142
0.155
0.168

0.182
0.196

0.067
0.072
0.077

0.084
0.092

0.101
0.110
0.119

0.128
0.138

0.047
0.051
0.055

0.060
0.065

0.071
0.077
0.084

0.091
0.098

3

0.677

0.479

0.391

0.339

0.303

0.210

0.148

0.105

15

Table 4: Asymptotic variance for SR according to formula σIID,2

SR

12

24

36

48

60

125

250

500

0.5

0.320

0.221

0.179

0.155

0.138

0.095

0.067

0.047

0.75
1

1.25
1.5
1.75

2
2.25

2.5
2.75
3

0.341
0.369

0.402
0.440
0.480

0.522
0.567

0.612
0.659
0.707

0.236
0.255

0.278
0.304
0.332

0.361
0.392

0.423
0.456
0.489

0.191
0.207

0.226
0.246
0.269

0.293
0.318

0.343
0.370
0.396

0.165
0.179

0.195
0.213
0.232

0.253
0.274

0.296
0.319
0.342

0.147
0.159

0.174
0.190
0.207

0.225
0.245

0.264
0.285
0.305

0.102
0.110

0.120
0.131
0.143

0.156
0.169

0.182
0.196
0.211

0.072
0.078

0.085
0.092
0.101

0.110
0.119

0.129
0.139
0.149

0.051
0.055

0.060
0.065
0.071

0.078
0.084

0.091
0.098
0.105

Table 5: Diﬀerence between asymptotic variance for SR according to formula σIID,1 and
σIID,3

SR

0.5
0.75
1

1.25
1.5

1.75
2
2.25

2.5
2.75

12

24

36

48

60

125

250

500

1.21% 0.41% 0.22% 0.14% 0.10% 0.03% 0.01% 0.00%
1.13% 0.39% 0.21% 0.13% 0.10% 0.03% 0.01% 0.00%
1.04% 0.36% 0.19% 0.12% 0.09% 0.03% 0.01% 0.00%

0.95% 0.33% 0.18% 0.11% 0.08% 0.03% 0.01% 0.00%
0.87% 0.30% 0.16% 0.10% 0.07% 0.02% 0.01% 0.00%

0.80% 0.27% 0.15% 0.10% 0.07% 0.02% 0.01% 0.00%
0.73% 0.25% 0.14% 0.09% 0.06% 0.02% 0.01% 0.00%
0.67% 0.23% 0.13% 0.08% 0.06% 0.02% 0.01% 0.00%

0.62% 0.21% 0.12% 0.07% 0.05% 0.02% 0.01% 0.00%
0.58% 0.20% 0.11% 0.07% 0.05% 0.02% 0.01% 0.00%

3

0.54% 0.19% 0.10% 0.06% 0.05% 0.02% 0.01% 0.00%

16

Table 6: Diﬀerence between asymptotic variance for SR according to formula σIID,2 and
σIID,3

SR

0.5
0.75

1
1.25
1.5

1.75
2

2.25
2.5
2.75

12

24

36

48

60

125

250

500

1.21% 0.41% 0.22% 0.14% 0.10% 0.03% 0.01% 0.00%
1.13% 0.39% 0.21% 0.13% 0.10% 0.03% 0.01% 0.00%

1.04% 0.36% 0.19% 0.12% 0.09% 0.03% 0.01% 0.00%
0.95% 0.33% 0.18% 0.11% 0.08% 0.03% 0.01% 0.00%
0.87% 0.30% 0.16% 0.10% 0.07% 0.02% 0.01% 0.00%

0.80% 0.27% 0.15% 0.10% 0.07% 0.02% 0.01% 0.00%
0.73% 0.25% 0.14% 0.09% 0.06% 0.02% 0.01% 0.00%

0.67% 0.23% 0.13% 0.08% 0.06% 0.02% 0.01% 0.00%
0.62% 0.21% 0.12% 0.07% 0.05% 0.02% 0.01% 0.00%
0.58% 0.20% 0.11% 0.07% 0.05% 0.02% 0.01% 0.00%

3

0.54% 0.19% 0.10% 0.06% 0.05% 0.02% 0.01% 0.00%

17

B.2. Compounding eﬀect

Table 7: Compounding eﬀect for AR(1) process for the Sharpe

q

ρ

\

2

3

4

6

12

24

36

48

125

250

90% 1.026
80% 1.054

70% 1.085
60% 1.118
50% 1.155

40% 1.195
30% 1.240

20% 1.291
10% 1.348
0% 1.414

-10% 1.491
-20% 1.581
-30% 1.690

-40% 1.826
-50% 2.000

-60% 2.236
-70% 2.582
-80% 3.162

1.046
1.097

1.152
1.213
1.279

1.353
1.433

1.523
1.622
1.732

1.853
1.987
2.132

2.287
2.449

2.611
2.762
2.887

1.065
1.137

1.215
1.300
1.393

1.494
1.605

1.725
1.857
2.000

2.157
2.331
2.527

2.752
3.024

3.371
3.860
4.663

1.102
1.213

1.333
1.462
1.600

1.748
1.905

2.073
2.254
2.449

2.664
2.901
3.169

3.477
3.843

4.300
4.922
5.909

1.207
1.427

1.654
1.885
2.121

2.364
2.615

2.879
3.160
3.464

3.798
4.171
4.596

5.093
5.692

6.444
7.449
8.961

1.408
1.808

2.187
2.551
2.910

3.273
3.645

4.035
4.450
4.899

5.393
5.949
6.586

7.339
8.259

9.436
11.047
13.505

1.597
2.136

2.622
3.081
3.530

3.981
4.444

4.928
5.442
6.000

6.615
7.306
8.103

1.773
2.424

2.997
3.534
4.057

4.581
5.119

5.682
6.280
6.928

7.643
8.449
9.377

9.046
10.205

11.699
13.768
16.983

10.480
11.837

13.593
16.040
19.884

2.668
3.795

4.749
5.633
6.490

7.347
8.226

9.144
10.121
11.180

12.350
13.670
15.196

17.014
19.262

22.195
26.327
32.960

3.698
5.318

6.679
7.936
9.153

10.371
11.618

12.921
14.308
15.811

17.473
19.349
21.519

24.106
27.313

31.505
37.434
47.018

-90% 4.472

2.970

6.472

8.095

12.064

18.289

23.325

27.613

46.986

67.650

Compared to the standard square root rule, we can compute the ratio of the real factor

and √d given below

18

Table 8: This table provides the ratio of the correct compounding eﬀect and the usual square
root constant. More precisely, we compute 1 + 2ρ
ρ
−

1
−
q(1

ρq
ρ)

1

−

1

(cid:16)

−
24

(cid:17)
36

48

125

250

q

ρ

\

2

3

4

6

12

90% 1.378
80% 1.342

70% 1.304
60% 1.265
50% 1.225

40% 1.183
30% 1.140
20% 1.095

10% 1.049
0% 1.000

-10% 0.949
-20% 0.894
-30% 0.837

-40% 0.775
-50% 0.707

-60% 0.632
-70% 0.548
-80% 0.447

1.655
1.579

1.503
1.428
1.354

1.281
1.208
1.137

1.068
1.000

0.935
0.872
0.812

0.757
0.707

0.663
0.627
0.600

1.877
1.760

1.647
1.539
1.436

1.339
1.246
1.159

1.077
1.000

0.927
0.858
0.792

0.727
0.661

0.593
0.518
0.429

2.223
2.020

1.838
1.676
1.531

1.402
1.286
1.181

1.087
1.000

0.920
0.844
0.773

0.704
0.637

0.570
0.498
0.415

2.870
2.428

2.095
1.837
1.633

1.466
1.325
1.203

1.096
1.000

0.912
0.831
0.754

0.680
0.609

0.538
0.465
0.387

3.478
2.709

2.240
1.920
1.683

1.497
1.344
1.214

1.101
1.000

0.908
0.824
0.744

0.668
0.593

0.519
0.443
0.363

3.757
2.809

2.288
1.947
1.700

1.507
1.350
1.218

1.102
1.000

0.907
0.821
0.740

0.663
0.588

0.513
0.436
0.353

3.908
2.858

2.311
1.961
1.708

1.512
1.353
1.219

1.103
1.000

0.906
0.820
0.739

0.661
0.585

0.510
0.432
0.348

4.190
2.946

2.354
1.985
1.723

1.522
1.359
1.223

1.105
1.000

0.905
0.818
0.736

0.657
0.580

0.504
0.425
0.339

4.276
2.973

2.367
1.992
1.727

1.525
1.361
1.224

1.105
1.000

0.905
0.817
0.735

0.656
0.579

0.502
0.422
0.336

-90% 0.316

0.583

0.309

0.303

0.287

0.268

0.257

0.251

0.238

0.234

19

References

Bondesson, L., 1974. Characterizations of probability laws through constant regression.

Z.Wahrscheinlichkeitstheorie verw. Gebiete pp. 93–115.

Bondesson, L., 1983. When is the t-statistic t-distributed. Sankhya, Ser. A pp. 338–345.

Christie, S., 2005. Is the sharpe ratio useful in asset allocation? MAFC Research Papers .

Duncan, A. J., 1986. Quality control and industrial statistics.

Efron, B., 1969. Student’s t-test under symmetry conditions. J. Amer. Statist. Assoc. pp.

1278–1302.

Fang, K., Yang, Z., Kotz, S., 2001. Generation of multivariate distributions by vertical

density representation. Statistics pp. 281–293.

Gallagher, P. D., 2011. Digital library of mathematical functions.

Goetzmann, W., Ingersoll, J., Spiegel, M. I., Welch, I., 2002. Sharpening sharpe ratios.

NBER Working Paper No. 9116 .

Guo, S., Xu, J.-G., Qi, F., 2013. Some exact constants for the approximation of the quantity

in the wallis’ formula. Journal of Inequalities and Applications 2013, 67.

Helmert, F. R., 1876. Uber die wahrscheinlichkeit der potenzsummen der beobachtungsfehler

und uber einige damit in zusammenhang stehende fragen. Math. Phys pp. 192–218.

Jobson, J. D., Korkie, B. M., 1981. Performance hypothesis testing with the sharpe and

treynor measures. The Journal of Finance 36, 889–908.

Kagan, A., Linnik, Y., Rao, C., 1973. Characterization problems in mathematical statistics.

Lenth, R. V., 1989. Algorithm as 243: Cumulative distribution function of the non-central t

distribution. Journal of the Royal Statistical Society, Series C pp. 185–189.

Lin, L., Ma, W.-C., Chen, C.-P., 2017. Pade approximant related to the wallis formula.

Journal of Inequalities and Applications .

Liu, Y., Rekkas, M., Wong, A., 2012. Inference for the sharpe ratio using a likelihood-based

approach. Journal of Probability and Statistics .

Lo, A. W., 2002. The statistics of sharpe ratios. Financial Analysts Journal 58, No. 4, 36–52.

20

Luroth, J., 1876. Vergleichung von zwei werten des wahrscheinlichen fehlers. Astron Nachr

14, 209–220.

Mauldon, J., 1956. Characterizing properties of statistical distributions. Quart. J. Math. pp.

155–160.

Mertens, E., 2002. Comments on variance of the iid estimator in lo. Technical report, Working

Paper University of Basel .

Miller, R. E., Gehr, A. K., 1978. Sample size bias and sharpes performance measure: A note.

Journal of Financial and Quantitative Analysis pp. 943–946.

Mortici, C., 2010. New approximation formulas for evaluating the ratio of gamma functions.

Mathematical and Computer Modelling 52, 425 – 433.

Opdyke, J. D., 2007. Comparing sharpe ratios: so where are the p-values? Journal of Asset

Management 8, 308336.

Pav, S. E., 2016. Notes on the sharpe ratio. /cran.r-project.org .

Pearson, K., 1895. Contributions to the mathematical theory of evolution, ii: Skew variation
in homogeneous material. Philosophical Transactions of the Royal Society pp. 343–414.

Qi, F., Mortici, C., 2015. Some best approximation formulas and inequalities for the wallis

ratio. Applied Mathematics and Computation 253, 363 – 368.

Qi, J., Rekkas, M., Wong, A., 2018. Highly accurate inference on the sharpe ratio for auto-

correlated return data. Journal of Statistical and Econometric Methods .

Sharpe, W. F., 1966. Mutual fund performance. Journal of Business pp. 119–138.

Student alias W. S. Gosset, 1908. The probable error of a mean. Biometrika pp. 1–25.

Walck, C., 2007. Hand-book on Statistical distribution for experimentalists. Stockholm Uni-

versity.

21

