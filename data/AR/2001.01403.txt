0
2
0
2

b
e
F
0
2

]

M
M

.
s
c
[

2
v
3
0
4
1
0
.
1
0
0
2
:
v
i
X
r
a

Joint Communication and Computational Resource
Allocation for QoE-driven Point Cloud Video
Streaming

Jie Li†, Cong Zhang†, Zhi Liu‡, Wei Sun∓, Qiyue Li∓
†School of Computer and Information, Hefei University of Technology, China
‡Department of Mathematical and Systems Engineering, Shizuoka University, Japan
∓ School of Electrical Engineering and Automation, Hefei University of Technology Hefei, China
Email: {lijie@hfut.edu.cn, zhangcong@mail.hfut.edu.cn, liu@shizuoka.ac.jp
wsun@hfut.edu.cn, liqiyue@mail.ustc.edu.cn}

Abstract—Point cloud video is the most popular representa-
tion of hologram, which is the medium to precedent natural
content in VR/AR/MR and is expected to be the next genera-
tion video. Point cloud video system provides users immersive
viewing experience with six degrees of freedom (6DoF) and
has wide applications in many ﬁelds such as online education
and entertainment. To further enhance these applications, point
cloud video streaming is in critical demand. The inherent
challenges lie in the large size by the necessity of recording the
three-dimensional coordinates besides color information, and the
associated high computation complexity of encoding/decoding.
To this end, this paper proposes a communication and compu-
tational resource allocation scheme for QoE-driven point cloud
video streaming. In particular, with the goal to maximize the
deﬁned QoE by selecting proper quality levels (uncompressed
tiles at different quality levels are also considered) for each
partitioned point cloud video tile, we formulate this into an
optimization problem under the limited communication and
computational resources constraints and propose a scheme to
solve it. Extensive simulations are conducted and the simulation
results show the superior performance of the proposed scheme
over the existing schemes.

Index Terms—point cloud video, hologram video, QoE, video

streaming, immersive video, 6DoF, resource allocation

I. INTRODUCTION

With the rise of the immersive video, technologies such
as Virtual Reality (VR) and Augmented Reality (AR) are
increasingly favored by users. Currently 360 degree videos
[1], [2], [3] are widely used because 360 degree video can
directly use the standard video compression technology such
as HEVC for encoding. However, 360 degree video can only
achieve two degrees of freedom (2DoF), and this limits the
immersive viewing experience. Thus, hologram video, which
can support six degrees of freedom (6DoF) and can give users
a real immersive experience, becomes a research hotspot and
draws more and more attentions [4].

However, higher degree of freedom also means a much
larger amount of data to be transmitted with stringent play-
back deadline, thus the wireless streaming of hologram videos
brings more challenges. Nowadays,
light ﬁeld and point
cloud are two commonly used technologies to represent the

hologram video. Due to the difﬁculty of obtaining the full
plenoptic function for scene, light ﬁeld technology is less
popular in practice [5], and point cloud is more proper for
hologram video applications. Note that the point cloud is
composed of quantities of points in three-dimensional space,
and each point contains RGB attributes. Due to that the point
cloud needs to store three dimensions of information, the
amount of data is very large compared to ordinary video [6],
[7]. For example, when the number of 3D points is around
2,800,000, the amount of trafﬁc without any compression is
approximately 78 Mbits for a single frame, which means that
the bandwidth requirement of hologram video streaming is
about 2300Mbps when frame rate is 30 frames per second.
This number will be even lager when streaming high quality
point cloud video. Therefore, larger bandwidth requirement
is one challenging research issue for the transmission of
hologram video.
Currently,

there are limited researches about hologram
video streaming, and state-of-the-art point cloud researches
mainly focus on the point cloud compression. In particular,
Hu, et al. propose a novel point cloud compression method for
attributes, based on geometric clustering and normal weighted
graph Fourier transform [8]. Mohammad, et al. propose
spatially sub-sample point clouds in the 3D space method
to reduce data amount and combine DASH protocol to make
the point cloud video transmission adaptive [9]. There are
also public point cloud compression tools available, such as
Google’s Draco [10] and point cloud compression (PCC) by
MPEG-I [11]. However, in our experiment tests, the running
time of encoding and decoding is very large, although they
support multi-core, multi-thread operation. For example, the
time for a typical computer with i7 processor to decode 30
frames of a popular point cloud video sequence loot may be
at the minute level.

To reduce the bandwidth consumption, we can use the idea
of 360 video processing method [1], [2], [12] by partitioning
the point cloud video into 3D tiles and only transmitting
the tiles within user’s FoV. This reduces the number of
tiles transmitted and hence saves the precious bandwidth.

 
 
 
 
 
 
In particular, Jounsup, et al propose a volumetric media
transmission scheme that cuts the point cloud video into
tiles spatially, while different tiles have various quality levels,
culling them or reducing their level of quality depending on
their relation to the users view frustum and distance to the user
[13]. However, the large encoding and decoding time before
playback is not considered in their research. Arunkumar, et
al. study the relationship between the decoding time and
transmission time in VR video and propose to balance the
relationship between the two by partially transferring raw tiles
of VR video [14]. However, this research does not optimize
this process and can not be directly used in point cloud video
streaming due to the unique features of point cloud video.

To this end, we study the point cloud video streaming
considering both the communication and computational re-
source. Speciﬁcally, the point cloud video is ﬁrst divided
into 3D tiles evenly and each tile is encoded into different
quality levels for selection. Then we optimize the quality level
selection (the uncompressed tiles at different quality levels are
also considered which do not require any decoding time) to
maximize the deﬁned user QoE under the communication and
computational resource constraints. This problem is a non-
linear integer programming problem and we obtain a sub-
optimal solution of this problem. Extensive simulations are
conducted and the simulation results show that the proposed
scheme results in higher QoE over baseline schemes.

To the best of our knowledge, this is the ﬁrst research that
jointly considers communication and computational resource
allocation for hologram video streaming optimization. Our
contributions are summarized as follows:
(1) We propose a joint communication and computational
resources allocation framework for point cloud video
streaming, in which computational resources are used
to decode the compressed 3D tiles on user’s playback
device.

(2) We propose a QoE evaluation metric for dynamic point
cloud video based on user’s perspective and point cloud
characteristics, including distance between user and the
scene and quality level of each tile.

(3) We formulate the point cloud video transmission into an
optimization problem to maximize the QoE and propose
a scheme to solve it.

(4) Extensive simulations are conducted and the simulation
results show that the proposed scheme results in higher
QoE over the baseline schemes.

The remainder of this paper is organized as follows: Section
II introduces the proposed transmission system, and Section
III introduces the joint communication and computational
resource allocation problem to maximize user’s QoE and how
we solve this optimization problem. Section IV shows the
simulation results, and we conclude this paper in Section V.

II. OVERVIEW OF POINT CLOUD VIDEO STREAMING
SYSTEM

In this section, we introduce our point cloud video stream-

ing system and its tile selection module.

Fig. 1.

Illustration of the adaptive point cloud video transmission system.

A. System Architecture

As mentioned above, point cloud video cannot be directly
transmitted via the wireless network due to its large size.
Similar to 360 video streaming, point cloud video is ﬁrst
partitioned into multiple 3D tiles and only the tiles inside
user’s FoV are transmitted to reduce the bandwidth require-
ment [13]. Besides,
these tiles are compressed to further
reduce the bandwidth requirement, where decoding requires
computational resources of the user’s playback device. With
different available computational resources and time-varying
network bandwidths, how to optimize the transmission to
achieve a better user’s QoE still remains a non-trivial issue.
In this paper, we propose a dynamic point cloud adaptive
streaming system to select the proper quality level (the raw
tiles at different quality levels are also considered which
do not require computation power to decode) for each tile
inside the FoV and thus conduct the tradeoff between the
computational resources and communication resources.

As shown in Fig.1, the whole system is composed of two
parts: the server side and the client side. The server pre-
processes the point cloud video (i.e. partitioning it into 3D
tiles) and encodes each tile into different representations at
different quality levels with Group of Frame (GOF) as the
minimum unit. The information of all the point cloud video
tiles is stored in a Media Presentation Description (MPD)
ﬁle, similar to MPEG-DASH [15], and the server will send
corresponding tiles after receiving streaming requests from
the client. After all the tiles are received and decoded, the
point cloud video will be reconstructed. Then the recon-
structed point cloud video will be sent to the buffer, waiting
for playback. To maintain a continuous playback, the buffer
cannot be drained.

ClientServersequenceGOFr1compressedTilesTile SelectionHTTP interfaceGOFUserreconstructionTile selection strategyMPD FileBufferHTTP interfaceDecoderUncompressed TilesPoint cloud video3D TilesEncoderuncompressedTilesView portRequest tilesTiles infoCPUBinary FilesTilesReorderingDecoderPly FilesrncompressedTilesuncompressedTilesTiles infoBinary filesPly filesThe core of the client side is the tile selection module. It
calculates user’s FoV, selects the tiles residing inside the FoV
with appropriate quality levels to maximize user’s QoE, ac-
cording to the bandwidth status, buffer status and the available
computational resources. Note that the uncompressed tiles at
different quality levels are considered in the tile selection,
which do not consume computation power for decoding with
relatively large source rate. Please also note that considering
the decoding complexity is not necessary in traditional video
streaming, which also distinguishes the point cloud video
streaming from the traditional video streaming.

B. Tile Selection Module

To accommodate the transmission of high quality point
cloud video, of which the size of compressed video is still
large for the existing wireless networks, we borrow the idea
of 360 transmission method, i.e. partitioning the point cloud
video into 3D tiles evenly and only transmitting the tiles
within the users FoV. To partition the point cloud video, we
ﬁrst calculate the length, width, and height of the smallest
enclosing cuboid that surrounds the point cloud, and deter-
mine which side of the cuboid is ’height’ according to the
situation of the object. For example, when the point cloud
is a character, the direction in which the character stands is
’height’ of the cuboid. Then we perform n × m partitioning
on the plane perpendicular to the height, and dividing them
into h layers in the ”height” direction, and ﬁnally n × m × h
tiles are obtained. Fig.2 shows the point cloud partitioning
with three sequences basketball, loot and longdress.

Fig. 2.
basketball, loot and longdress, respectively.

Illustration of the point cloud partitioning. The three sequences are

With the help of tile partitioning, we can reduce the
transmission of non-necessary tiles and further select proper
quality level for each tile under the bandwidth and com-
putational resources constraint to optimize the QoE. Note
that the decoding from the compressed tiles requires extra
computational power (which is much larger than the com-
putational power of decoding a common compressed video)
and time, which may limit the usage of the point cloud video
compression, while uncompressed tiles do not require the
computational resource for decoding with high source rate.

How to best utilize the communication and computational
resources to provide higher QoE is the focus of this paper.

III. PROBLEM FORMULATION

A. Computational Resources and Decoding Time

The decoding time and the required computational resource
of point cloud video is related to its total number of points
and quality levels [16]. Assume the required computational
resource to decode one tile with the lowest quality is C, we
can ﬁnd a parameter ∂g,k, which is related to the number of
points and the degree of the compression so that the required
computational resource of tile k with quality level r in GOF
g can be described as Cg,k,r = ∂g,k,r × C, and it can be
normalized into CPU frequency to describe the required time
to decode the tile. All the consumed computational resource
Cg,k,r can be regarded as known parameters stored in the
MPD ﬁle. We assume CU1 is the computational resources
that one single processor core of user’s playback device can
provide within one GOF time, and N C is the number of
cores, then CUN C = N C × τN C × CU1, where CUN C is
the total computational resource available, and τN C is the
conversion efﬁciency when the decoding process is running in
multi-core and multi-thread mode. Obviously, the consumed
computational resource cannot exceed user device’s capacity.
Then we can obtain the decoding time T dg for GOF g, which
can be expressed as follows:

T dg =

f
f ps

×

(cid:80)M

k=1 eg,k × (cid:80)R

r=1 Cg,k,r × vg,k × xg,k,r

N C × τN C × CU1

(1)
Where f is the number of frames in one GOF and f ps is
frame rate of the point cloud video. eg,k is a binary variable,
eg,k = 1 if the compressed version is selected, and eg,k = 0
means that the uncompressed tile is selected. M is the number
of tiles, and R is the number of quality levels available. vg,k
is a binary variable calculated through FoV, vg,k=1 means
the tile is in user’s FoV and should be transmitted and 0
otherwise. xg,k,r is a binary variable, xg,k,r = 1 means
compressed version of tile k with quality level r in GOF g
is transmitted, and 0 otherwise. This equation shows that the
decoding time can be determined by the relationship between
the computational resources required to decode the point
cloud in molecule and the computational resources provided
by the device in denominator.

In our system, all the retrieved tiles are stored in a buffer
before playback. Let T bg denote the current buffer status,
which records the frames (measured in time) of point cloud
video stored in buffer. To maintain a continuous playback,
we have T bg > 0, ∀g ∈ [1, G], where G presents the total
number of GOFs in the video. Then the dynamics of the
playback buffer can be expressed by the following equations:

T bg = T bg−1 − T ug + T ig,

(2)

where T ig is the increased playback time when GOF g enters
f
f ps .
the buffer, which is a constant value and equals to

T ug indicates the time consumed by transmitting all the tiles
residing in FOV and decoding the compressed tiles in GOF
g. Thus T ug can be expressed as:

T ug = T sg + T dg

(3)

where

T sg =

raw tiles.size + compressed tiles.size
Bwg
r=1 binSg,k,r × vg,k × xg,k,r

k=1 eg,k × (cid:80)R

(cid:80)M

=

+

Bwg
k=1 (1 − eg,k) × (cid:80)R

(cid:80)M

r=1 plySg,k,r × vg,k × xg,k,r
Bwg

(4)

binSg,k,r indicates the data size of the compressed tile k with
quality level r in GOF g, plySg,k,r represents the data size
of raw tile k with quality level r ,which is decoded from the
compressed ﬁle of the corresponding quality level in GOF g,
and the parameters are all stored in the MPD ﬁle. Bwg is the
predicated wireless bandwidth during the time of GOF g.

B. The Quality of Experience Model

The point cloud video system can support 6DoF (one
FoV is shown in Fig.3). During the playback, different tiles
have different distances from the viewer’s position, and they
have different contributions to the total QoE. We assume
the closer the tile is to the user’s viewpoint position, the
greater its contribution. Besides, for each tile, there are up
to R compressed quality levels available, and when different
quality level is requested, different QoE will be yielded.

1

and its degree of inﬂuence of the user into consideration. In
this paper, we deﬁne pg,k as pg,k =
distg,k(vg,posg,k) , where
vg is the user viewpoint position when watching GOF g, and
posg,k is the position of tile k in GOF g. distg,k is a function
of the tangential distance from the viewpoint. As to the quality
weight QTg,k, due to irregularity of the point cloud video, the
number of points contained in each tile is different. Thus we
can deﬁne the quality weight for a 3D tile k as the ratio of
number of points in that tile to the total number of points in
whole FoV, which can be expressed as QTg,k = Ng,k,R
.
k=1 Ng,k,R
The quality of the point cloud frame is generally evaluated
by the level of density, which represents the number of points
in the unit volume, and the user views each point in the FoV.
Then for the whole point cloud video, we can deﬁne the QoE
as [17]:

(cid:80)M

QoE = log

(cid:32)

(cid:80)G

g=1

(cid:80)G

(cid:80)M

g=1

k=1 Qg,k
k=1 pg,k × R × QTg,k × vg,k

(cid:80)M

(cid:33)

(6)

C. Objective Function and Solution

Thus, we formulate the QoE driven communication and
resource allocation for point cloud video

computational
streaming as follows:

= log

s.t.

max
xg,k,r,eg,k

QoE = log

(cid:32)

(cid:80)G

g=1

(cid:80)G

(cid:80)M

g=1

k=1 Qg,k
k=1 pg,k × R × QTg,k × vg,k

(cid:80)M

(cid:33)

(cid:32) (cid:80)G

g=1

(cid:80)M

k=1

(cid:80)R

r=1 (pg,k × r × QTg,k × vg,k × xg,k,r)
k=1 (pg,k × R × QTg,k × vg,k)

(cid:80)M

(cid:80)G

g=1

(cid:33)

R
(cid:88)

r=1

xg,k,r = 1, ∀g ∈ [1, G], k ∈ [1, M ]

T bg > 0, ∀g ∈ [1, G]

(7)

(8)

(9)

This is a constrained nonlinear 0-1 programming problem.

Among them, Eq. (9) can be calculated as follows:

T bg = T bg−1 − T ug + T ig
(cid:104)



(cid:80)M

= T bg−1 −



eg,k × (cid:80)R

k=1

r=1 (binSg,k,r × vg,k × xg,k,r)

(cid:105)

Bwg

(cid:80)M

k=1

(cid:104)
(1 − eg,k) × (cid:80)R

(cid:105)
r=1 (plySg,k,r × vg,k × xg,k,r)

(cid:80)M

k=1

+

f
f ps

×

Bwg

(cid:104)
eg,k × (cid:80)R

(cid:105)
r=1 (Cg,k,r × vg,k × xg,k,r)

CUN C



 +

f
f ps

It can be simpliﬁed to

(10)

T b (g) − T b (g − 1) = F (xg,k,r)

(11)

Fig. 3. An example of one FoV.

+

Then for a single tile k in GOF g, we can deﬁne its QoE

contribution as:

Qg,k =

R
(cid:88)

r=1

pg,k × r × QTg,k × vg,k × xg,k,r

(5)

where pg,k and QTg,k are distance weight and quality weight
for 3D tile k in GOF g, respectively. This QoE model takes
the quality of the point cloud video, the proportion of each tile

TileDist(v,k)FOVRADT b(0) = b > 0

(12)

This constraint

is a ﬁrst-order non-homogeneous linear
difference equation, x, e is a binary vector, and b is the initial
buffer size. Then we have
g
(cid:88)

T b(g) =

[F (xi,k,r)] + b > 0

(13)

i=1

The goal of the transmission optimization model we estab-
lished is to maximize the QoE value. The variables are the
quality level x limited by Eq. (8) and the transmission form e
of each tiles, which presents the compressed or uncompressed
tile is transmitted and limited by Eq.(9). The problem is a
nonlinear integer programming problem. If the variables of
the problem is relaxed to a continuous variable, its objective
function and constraint are convex functions and convex sets
that are easy to solve. Therefore, the paper ﬁrstly relaxes
the problem, converts the nonlinear integer programming
problem problem into nonlinear programming problem, and
uses the KKT-condition to ﬁnd the solution of the nonlinear
programming problem. Then the branch-and-bound method
is used to solve the integer variable solution of the original
problem.

IV. PERFORMANCE EVALUATION

We build a simulation platform to verify the feasibility
of our proposed transmission scheme, calculate the different
results under different computational resources CU i
N C and
different communication resources Bwi, and then compare
with the traditional transmission scheme, that is, the scheme
of only transmitting the compressed tiles, in terms of system
resource utilization and QoE values.

Limited to the effectiveness of bandwidth prediction, we set
the length of the dynamic point cloud to 2s, with each GOF
lasts for 1/3 second. We set M = 2 × 2 × 6, total quality
levels r = 5 and initial buffer length b = 2s. The required
computational resource with the smallest size among all the
tiles is set to C = 1, and the computational resources required
for each tile are obtained according to their densities. Other
simulation parameters are listed in Table I.

TABLE I
SIMULATION PARAMETERS SETTING

Group ID N C(N umberof Cores) Bw(M bps)

1
2
3
4
5
6
7
8
9

2
2
2
4
4
4
6
6
6

54
72.2
104
54
72.2
104
54
72.2
104

Firstly, we study the performance of our proposed system.
Fig.4(a) shows the number of transmitted uncompressed tiles
and compressed tiles under various conditions. We can see

(a)

(b)

Fig. 4.
(a) Number of tile transmission forms under different schemes (b)
Comparison of the number of tile in different quality under different condition

that when the computational resources are relatively large
(with larger N C), the scheme preferentially transmits the
compressed tile to improve the resource utilization. When
the bandwidth is relatively large, the scheme preferentially
transmits the uncompressed tile to make full use of the
communication resources, in order to achieve the best system
resource utilization.

Fig.4(b) illustrates the difference in terms of tile numbers at
different quality levels (where R1 is the lowest quality and R5
is the highest quality level) transmitted under different condi-
tions. When the computational and communication resources
are low, the system will choose to transmit tiles at a lower
bit rate and quality level to reduce resource requirements,
and when the system resources are sufﬁcient, high different
quality tile will be transmitted to achieve the best quality
experience. For example, when comparing group 1, 2, 3, we
can ﬁnd that the number of high quality level tiles becomes
larger.

system.C + tiles.B

Then we compare with traditional hologram transmis-
sion system, which delivers only compressed tiles. Three
i.e. B1 = 54M bps, B2 =
bandwidths are considered,
72.2M bps, B3 = 104M bps as shown in TABLE I. Fig.5
illustrates system resource utilization expressed by p =
1
2 × ( tiles.C
system.B ), where tiles.c represents the
total computational resources required to decode the tiles.
system.c represents the available computational resources,
tiles.B represents the total amount of data required for
transmission, and system.B represents the communication
resources that system can be provided. The x-axis represents
the computational resources provided by the device, i.e. the
CU mentioned above. From the simulation results, we can
ﬁnd that our system has a better system resource utilization in
comparison to the traditional hologram transmission scheme.

Fig.6 is a comparison of QoE values between our scheme
and the traditional scheme. We can see that since our trans-
mission scheme makes full use of communication resources
and computational resources, it can maximize the quality
levels of the tiles, and can obtain a greater QoE value. We
can also observe that when the computing resources are scare,
which is typical for mobile user playback equipment, the QoE
value is signiﬁcantly higher than the traditional solution.

(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:1)(cid:6)(cid:2)(cid:1)(cid:2)(cid:6)(cid:3)(cid:1)(cid:3)(cid:6)(cid:4)(cid:1)(cid:4)(cid:6)(cid:5)(cid:1)(cid:5)(cid:6)(cid:6)(cid:1)(cid:6)(cid:6) (cid:11)(cid:6)(cid:2)(cid:7)(cid:5)(cid:8)(cid:9)(cid:4)(cid:10)(cid:10)(cid:4)(cid:3)    (cid:2)(cid:7)(cid:5)(cid:8)(cid:9)(cid:4)(cid:10)(cid:10)(cid:4)(cid:3)(cid:3)(cid:6)(cid:7)(cid:5)(cid:1)(cid:2)(cid:10)(cid:8)(cid:4)(cid:5)(cid:9)(cid:1)(cid:9)(cid:7)(cid:11)(cid:8)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:1)(cid:6)(cid:2)(cid:1)(cid:2)(cid:6)(cid:3)(cid:1)(cid:3)(cid:6)(cid:4)(cid:1)(cid:4)(cid:6)(cid:5)(cid:1)(cid:5)(cid:6)(cid:6)(cid:1)(cid:6)(cid:6) (cid:8)(cid:2)   (cid:8)(cid:3)   (cid:8)(cid:4)  (cid:1)(cid:8)(cid:5)   (cid:8)(cid:6)(cid:3)(cid:6)(cid:7)(cid:5)(cid:1)(cid:2)(cid:10)(cid:8)(cid:4)(cid:5)(cid:9)(cid:7)(cid:11)(cid:9)(cid:12)(cid:10)[4] M. J. Richardson and J. D. Wiltshire, What is a Hologram?

IEEE,

2018.

[5] G. Wu, B. Masia, A. Jarabo, Y. Zhang, L. Wang, Q. Dai, T. Chai, and
Y. Liu, “Light ﬁeld image processing: An overview,” IEEE Journal of
Selected Topics in Signal Processing, vol. 11, no. 7, pp. 926–954, Oct
2017.

[6] L. Cui, H. Xu, and E. S. Jang, “Hybrid color attribute compression
for point cloud data,” in 2017 IEEE International Conference on
Multimedia and Expo (ICME), July 2017, pp. 1273–1278.

[7] H. Hu, Y. Jin, Y. Wen, and C. Westphal, “Orchestrating caching,
transcoding and request routing for adaptive video streaming over icn,”
ACM Transactions on Multimedia Computing, Communications, and
Applications (TOMM), vol. 15, no. 1, pp. 1–23, 2019.

[8] Y. Xu, W. Hu, S. Wang, X. Zhang, S. Wang, S. Ma, and W. Gao,
“Cluster-based point cloud coding with normal weighted graph fourier
transform,” in 2018 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP), April 2018, pp. 1753–1757.
[9] M. Hosseini and C. Timmerer, “Dynamic adaptive point cloud stream-
ing,” in Proceedings of the 23rd Packet Video Workshop, ser. PV ’18.
New York, NY, USA: ACM, 2018, pp. 25–30.

[10] “Google.2018.draco: 3d data compression.retrieved march 3,2018

from,” http://github.com/google/draco.

[11] S. Schwarz, M. Preda, V. Baroncini, M. Budagavi, P. Cesar, P. A. Chou,
R. A. Cohen, M. Krivokua, S. Lasserre, Z. Li, J. Llach, K. Mammou,
R. Mekuria, O. Nakagami, E. Siahaan, A. Tabatabai, A. M. Tourapis,
and V. Zakharchenko, “Emerging mpeg standards for point cloud
compression,” IEEE Journal on Emerging and Selected Topics in
Circuits and Systems, vol. 9, no. 1, pp. 133–148, March 2019.
[12] J. Li, R. Feng, Z. Liu, W. Sun, and Q. Li, “Modeling qoe of virtual
reality video transmission over wireless networks,” in 2018 IEEE
Global Communications Conference (GLOBECOM), Dec 2018.
[13] J. Park, P. A. Chou, and J. Hwang, “Rate-utility optimized streaming of
volumetric media for augmented reality,” IEEE Journal on Emerging
and Selected Topics in Circuits and Systems, vol. 9, no. 1, pp. 149–162,
March 2019.

[14] A. Ravichandran, I. K. Jain, R. Hegazy, T. Wei, and D. Bharadia,
“Facilitating low latency and reliable vr over heterogeneous wireless
networks,” in Proceedings of the 24th Annual International Conference
on Mobile Computing and Networking, ser. MobiCom ’18. New York,
NY, USA: ACM, 2018, pp. 723–725.

[15] “Information

(dash)-part

http
segment

technology-dynamic

over
and
02-20,”
media-presentation-description-and-segment-formats.

streaming
description
3.2015-
formats.iso/iec
https://mpeg.chiariglione.org/standards/mpeg-dash/

adaptive
presentation

23009-1:2014/pdam

1: Media

[16] “mpeg point cloud compression common test condition reporting
https://www.interdigital.com/download/

n18175,”

template
5d2072018934bf9bb4000968.

[17] W. Huang, L. Ding, H. Wei, J. Hwang, Y. Xu, and W. Zhang,
“Qoe-oriented resource allocation for 360-degree video transmission
over heterogeneous networks,” CoRR, vol. abs/1803.07789, 2018.
[Online]. Available: http://arxiv.org/abs/1803.07789

Fig. 5. System utilization comparison

Fig. 6. Maximum QoE comparison

V. CONCLUSION

In this paper, we proposed a communication and computa-
tional resource allocation scheme for QoE-driven point cloud
video streaming. In particular, with the goal to maximize the
deﬁned QoE by selecting proper quality levels (uncompressed
tiles at different quality levels are also considered) for each
partitioned point cloud video tile, we formulated this into an
optimization problem under the limited communication and
computational resources constraints and proposed a scheme
to solve it. Extensive simulations were conducted and the
simulation results showed the superior performance of the
proposed scheme over the existing schemes.

REFERENCES

[1] Z. Liu, S. Ishihara, Y. Cui, Y. Ji, and Y. Tanaka, “Jet: Joint source
and channel coding for error resilient virtual reality video wireless
transmission,” Signal Processing, vol. 147, pp. 154–162, 2018.

[2] C. Guo, Y. Cui, and Z. Liu, “Optimal multicast of tiled 360 vr video,”
IEEE Wireless Communications Letters, vol. 8, no. 1, pp. 145–148,
2018.

[3] J. Li, R. Feng, Z. Liu, W. Sun, and Q. Li, “Qoe-driven coupled uplink
and downlink rate adaptation for 360-degree video live streaming,”
IEEE Communications Letters, pp. 1–1, 2020.

(cid:4)(cid:2)(cid:5)(cid:2)(cid:6)(cid:2)(cid:7)(cid:2)(cid:3)(cid:2)(cid:2)(cid:3)(cid:4)(cid:2)(cid:3)(cid:5)(cid:2)(cid:2)(cid:1)(cid:5)(cid:2)(cid:1)(cid:6)(cid:2)(cid:1)(cid:7)(cid:3)(cid:1)(cid:2)  (cid:2)(cid:15)(cid:12)(cid:13)(cid:5)(cid:8)(cid:1)(cid:11)(cid:5)(cid:12)(cid:10)(cid:14)(cid:11)(cid:4)(cid:5)(cid:1)(cid:14)(cid:13)(cid:6)(cid:7)(cid:6)(cid:16)(cid:3)(cid:13)(cid:6)(cid:10)(cid:9)(cid:7)(cid:20)(cid:18)(cid:21)(cid:25)(cid:24)(cid:11)(cid:24)(cid:16)(cid:20)(cid:19)(cid:11)(cid:17)(cid:1)(cid:22)(cid:14)(cid:23)(cid:20)(cid:25)(cid:22)(cid:12)(cid:14) (cid:8)(cid:22)(cid:20)(cid:21)(cid:20)(cid:23)(cid:14)(cid:13)(cid:1)(cid:9)(cid:12)(cid:15)(cid:14)(cid:18)(cid:14)(cid:1)(cid:6)(cid:26)(cid:5)(cid:6)(cid:2)(cid:1)(cid:8)(cid:22)(cid:20)(cid:21)(cid:20)(cid:23)(cid:14)(cid:13)(cid:1)(cid:9)(cid:12)(cid:15)(cid:14)(cid:18)(cid:14)(cid:1)(cid:6)(cid:26)(cid:5)(cid:6)(cid:3)(cid:1)(cid:8)(cid:22)(cid:20)(cid:21)(cid:20)(cid:23)(cid:14)(cid:13)(cid:1)(cid:9)(cid:12)(cid:15)(cid:14)(cid:18)(cid:14)(cid:1)(cid:6)(cid:26)(cid:5)(cid:6)(cid:4)(cid:1)(cid:10)(cid:22)(cid:11)(cid:13)(cid:16)(cid:24)(cid:16)(cid:20)(cid:19)(cid:11)(cid:17)(cid:1)(cid:9)(cid:12)(cid:15)(cid:14)(cid:18)(cid:14)(cid:1)(cid:6)(cid:26)(cid:5)(cid:6)(cid:2)(cid:1)(cid:10)(cid:22)(cid:11)(cid:13)(cid:16)(cid:24)(cid:16)(cid:20)(cid:19)(cid:11)(cid:17)(cid:1)(cid:9)(cid:12)(cid:15)(cid:14)(cid:18)(cid:14)(cid:1)(cid:6)(cid:26)(cid:5)(cid:6)(cid:3)(cid:1)(cid:10)(cid:22)(cid:11)(cid:13)(cid:16)(cid:24)(cid:16)(cid:20)(cid:19)(cid:11)(cid:17)(cid:1)(cid:9)(cid:12)(cid:15)(cid:14)(cid:18)(cid:14)(cid:1)(cid:6)(cid:26)(cid:5)(cid:6)(cid:4)(cid:3)(cid:1)(cid:5)(cid:1)(cid:7)(cid:1)(cid:8)(cid:1)(cid:2)(cid:1)(cid:1)(cid:2)(cid:3)(cid:1)(cid:2)(cid:5)(cid:1)(cid:4)(cid:3)(cid:4)(cid:5)(cid:4)(cid:7)(cid:4)(cid:8)(cid:5)(cid:1)(cid:5)(cid:3)(cid:5)(cid:5)(cid:5)(cid:7)(cid:5)(cid:8)(cid:6)(cid:1)(cid:6)(cid:3)(cid:6)(cid:5)(cid:6)(cid:7)(cid:6)(cid:8)  (cid:1)(cid:8)(cid:22)(cid:20)(cid:21)(cid:20)(cid:23)(cid:14)(cid:13)(cid:1)(cid:9)(cid:12)(cid:15)(cid:14)(cid:18)(cid:14)(cid:1)(cid:6)(cid:26)(cid:5)(cid:6)(cid:2)(cid:1)(cid:8)(cid:22)(cid:20)(cid:21)(cid:20)(cid:23)(cid:14)(cid:13)(cid:1)(cid:9)(cid:12)(cid:15)(cid:14)(cid:18)(cid:14)(cid:1)(cid:6)(cid:26)(cid:5)(cid:6)(cid:3)(cid:1)(cid:8)(cid:22)(cid:20)(cid:21)(cid:20)(cid:23)(cid:14)(cid:13)(cid:1)(cid:9)(cid:12)(cid:15)(cid:14)(cid:18)(cid:14)(cid:1)(cid:6)(cid:26)(cid:5)(cid:6)(cid:4)(cid:1)(cid:10)(cid:22)(cid:11)(cid:13)(cid:16)(cid:24)(cid:16)(cid:20)(cid:19)(cid:11)(cid:17)(cid:1)(cid:9)(cid:12)(cid:15)(cid:14)(cid:18)(cid:14)(cid:1)(cid:6)(cid:26)(cid:5)(cid:6)(cid:2)(cid:1)(cid:10)(cid:22)(cid:11)(cid:13)(cid:16)(cid:24)(cid:16)(cid:20)(cid:19)(cid:11)(cid:17)(cid:1)(cid:9)(cid:12)(cid:15)(cid:14)(cid:18)(cid:14)(cid:1)(cid:6)(cid:26)(cid:5)(cid:6)(cid:3)(cid:1)(cid:10)(cid:22)(cid:11)(cid:13)(cid:16)(cid:24)(cid:16)(cid:20)(cid:19)(cid:11)(cid:17)(cid:1)(cid:9)(cid:12)(cid:15)(cid:14)(cid:18)(cid:14)(cid:1)(cid:6)(cid:26)(cid:5)(cid:6)(cid:4)(cid:3)(cid:8)(cid:2)(cid:1)(cid:4)(cid:5)(cid:7)(cid:9)(cid:6)(cid:7)(cid:20)(cid:18)(cid:21)(cid:25)(cid:24)(cid:11)(cid:24)(cid:16)(cid:20)(cid:19)(cid:11)(cid:17)(cid:1)(cid:22)(cid:14)(cid:23)(cid:20)(cid:25)(cid:22)(cid:12)(cid:14)