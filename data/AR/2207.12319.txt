2
2
0
2

p
e
S
7
2

]

V
C
.
s
c
[

3
v
9
1
3
2
1
.
7
0
2
2
:
v
i
X
r
a

OpenFilter: A Framework to Democratize Research Access
to Social Media AR Filters

Piera Riccio
ELLIS Alicante

Bill Psomas
National Technical University of Athens

Francesco Galati
EURECOM Sophia Antipolis

Francisco Escolano
Universidad de Alicante

Thomas Hofmann
ETH Zurich

Nuria Oliver
ELLIS Alicante

piera@ellisalicante.org

psomasbill@mail.ntua.gr

galati@eurecom.fr

sco@ua.es

thomas.hofmann@inf.ethz.ch

nuria@ellisalicante.org

Abstract

Augmented Reality or AR ﬁlters on selﬁes have become very popular on social media
platforms for a variety of applications, including marketing, entertainment and aesthetics.
Given the wide adoption of AR face ﬁlters and the importance of faces in our social structures
and relations, there is increased interest by the scientiﬁc community to analyze the impact
of such ﬁlters from a psychological, artistic and sociological perspective. However, there are
few quantitative analyses in this area mainly due to a lack of publicly available datasets of
facial images with applied AR ﬁlters. The proprietary, close nature of most social media
platforms does not allow users, scientists and practitioners to access the code and the
details of the available AR face ﬁlters. Scraping faces from these platforms to collect data
is ethically unacceptable and should, therefore, be avoided in research. In this paper, we
present OpenFilter, a ﬂexible framework to apply AR ﬁlters available in social media
platforms on existing large collections of human faces. Moreover, we share FairBeauty and
B-LFW, two beautiﬁed versions of the publicly available FairFace and LFW datasets and
we outline insights derived from the analysis of these beautiﬁed datasets.

1 Introduction

Selﬁes (photos of one self, typically captured with smartphone or webcams) have become very popular on
social media platforms, particularly on Instagram2, Snapchat3 and TikTok.4 Google reported that its Android
devices took 93 million selﬁes per day in 2019 and in 2021 Instagram users uploaded an average of 95 million
photos and 250 millions stories each day (9). In a recent poll, 18-to-24-year-old participants reported that
every third photo they take is a selﬁe (56). In fact, selﬁes constitute a new visual genre (10) that centralizes

1https://www.flaticon.com/
2https://www.instagram.com/
3https://www.snapchat.com/
4https://www.tiktok.com/

1

 
 
 
 
 
 
Figure 1: OpenFilter pipeline. A machine runs the targeted social media application (e.g. Instagram) on
an Android emulator. An image from the dataset is projected on the camera opened through the social media
application. A ﬁlter is directly applied to the image. This Figure has been designed using resources from
Flaticon1and (30).

self-expression in its most traditional interpretation: presenting a positive view of the self, conforming to
social norms and meeting the expectations of others to receive positive feedback (20). AI-enhanced face
ﬁlters are becoming increasingly pervasive on social media platforms (17). These ﬁlters leverage algorithmic
advances in Computer Vision to automatically detect the face and facial features of the user, and Computer
Graphics (namely Augmented Reality or AR) to superimpose digital content in real-time, enhancing or
distorting the original facial image (44). Hence, we shall refer to them as AR ﬁlters. In their original form,
selﬁes were conceived as a digital manifestation of an underlying reality (i.e. the face of a person), and its
relation to the place and space (26). However, considering the wide adoption of these ﬁlters, the original
equation relating selﬁes to real human faces adopts new dynamics and the online identity becomes an artifact.

Diﬀerent types of AR face ﬁlters are currently available on social media for a variety of applications and use
cases, including marketing and commercials (3), entertainment, and aesthetics (18). Users of social media
platforms are able to create and share their own AR ﬁlters using oﬀ-the-shelf tools, establishing a new creative
form of expression and a new artistic role: the ﬁlter creator. Other users can use the ﬁlters to experience
diﬀerent versions of themselves, with e.g. futuristic or sci-ﬁ scenarios, funny deformations, horrifying or
surreal textures, 3D makeup or beauty enhancement. The possibility of experiencing these transformations
transcends the physical location of the users as all is needed is a smartphone with an Internet connection,
making AR face ﬁlters a form of post-Internet art (4). The COVID-19 pandemic has represented a turning
point for the general acceptance of AR ﬁlters as an eﬀective form of art (25), giving ﬁlter creators an essential
responsibility in shaping the cultural and societal impact of this technology.

Given the importance of faces in our social structures and relations, and the wide adoption of AR face
ﬁlters, the scientiﬁc community has shown increased interest to analyze the impact of such ﬁlters from a
psychological, artistic and sociological perspective (37). However, there are few quantitative analyses in
this area mainly due to a lack of publicly available datasets of facial images with applied AR ﬁlters. The
proprietary, close nature of most social media platforms does not allow users, scientists and practitioners to
access the code and the details of the available AR face ﬁlters (24). Scraping faces from these platforms to
collect data is ethically unacceptable and should, therefore, be avoided in research. A possible solution to
this challenge consists of recruiting volunteers to participate in user studies to create a dataset with their
content after obtaining their informed consent. However, this approach is time-consuming, expensive and
non-scalable. In this paper, we provide a methodology to overcome these limitations and democratize access
to AR ﬁlters used in social media for research purposes.

Speciﬁcally, we make the following contributions:

1. We present OpenFilter (section 3), a ﬂexible open framework to apply AR ﬁlters available in social

media platforms on existing, publicly available large collections of human faces.

2

2. In our case study (section 4), we focus on ﬁlters intended to enhance facial aesthetics. In this regard,
we share FairBeauty and B-LFW, the beautiﬁed versions of the publicly available FairFace (30)
and LFW (27) datasets.

3. We conduct face similarity and recognition experiments on these beautiﬁed datasets and outline

several insights from a technical and sociological perspective (section 5).

2 Related Work

The popularity of AR ﬁlters on social media has led to an increased interest in the research community
towards understanding their impact from a variety of perspectives. However, there is a lack of publicly
available datasets to enable a quantitative, systematic analysis of ﬁltered face images (24). Hence, user studies
and surveys are the most commonly explored techniques to quantify the impact of these ﬁlters, overcoming
the legal and ethical implications related to direct scraping of the data from social media. Early work by
(17) studied the impact of face ﬁlters on self-perception and self-esteem through a user study including 33
participants (23 females and 10 males). In this work, the authors highlight that the self-perception of the
body image is highly inﬂuenced by social factors and that we tend to assume that attractive features on
others are also desirable in ourselves, especially in individuals with low self-esteem.

More recently, (18) studied the short-term perception of users on their appeal, personality, intelligence and
emotion when diﬀerent distortions are applied through AR face ﬁlters. The study included 18 diﬀerent
SnapChat ﬁlters on 20 male and 20 female users, with ages ranging from 20 to 50 years old, and mostly white
people. The authors report that people self-perceive the targeted characteristics in their facial traits in the
same way as they perceive them in others. They conclude that even small changes in the facial traits impact
self-recognition capabilities and that the eyes are particularly relevant for conveying emotions.

Surveys and user studies are undoubtedly a valuable methodology to address certain research questions.
However, they are hardly scalable and hence do not enable carrying out quantitative studies of the impact
of these ﬁlters. To mitigate this limitation, scholars have approximated the AR ﬁlters available on social
media through alternative techniques or software. In particular, (6) introduce a database of beautiﬁed faces
with three diﬀerent ethnic variations. The dataset is generated using Fotor5, BeautyPlus6 and PortraitPro
Studio Max7 and it is composed of 600 diﬀerent individuals of three diﬀerent ethnicities (Indian, Chinese
and Caucasian) with balanced genders. Note that the word beautiﬁed refers to a set of digital retouching
techniques, including skin smoothing, skin tone enhancement, acne removal, face slimming, eye and lip color
change, and distortion of jaw and forehead. More recently, (24) create a beautiﬁed version of LFW (27)
benchmark dataset. In their case, the word beautiﬁed refers to the superimposition of simple AR elements
(e.g. dog nose, transparent glasses, sunglasses) on the original faces. While not focused on beautiﬁcation, (35)
study the eﬀect of surgical masks on face recognition techniques, creating mask overlays using SparkAR.8

These methods are able to apply simple ﬁlters (such as the superimposition of glasses, or masks) on pre-
existing images. However, they are unable to reproduce the intrinsic cultural and sociological value of the
user-generated ﬁlters available on social media, including the beauty ﬁlters. In this work, we address the
limitations of the aforementioned methods by providing a framework called OpenFilter to apply any AR
ﬁlter directly obtained from social media applications to pre-existing face datasets. OpenFilter enables the
creation of large-scale datasets that represent the current cultural ecosystems on social media platforms. Note
that an approximation of these ﬁlters through other methodologies risks biasing the study and jeopardizing
the ecological validity of the results.

3 OpenFilter: A Framework for AR-based Filtered Dataset Creation

Most of the AR ﬁlters available on social media platforms –such as Instagram, TikTok, SnapChat– can only
be applied in real-time on selﬁe images captured from the camera of the smartphone. Hence, it is challenging

5https://www.fotor.com/es/
6https://play.google.com/store/apps/details?id=com.commsource.beautyplus
7https://www.anthropics.com/
8https://sparkar.facebook.com/ar-studio/

3

to carry out quantitative and systematic research on such ﬁlters. OpenFilter fulﬁlls such a need by enabling
the application of AR ﬁlters on publicly available datasets of faces. The pipeline architecture of OpenFilter
is depicted in Figure 1 and the code is available in our repository9.

OpenFilter allows the application of AR ﬁlters directly from social media through (1) an Android Emulator,
(2) a machine and (3) a virtual webcam. The Android emulator runs on the machine, where the social media
application targeted in the research is installed10. In the emulator, the researcher may access any available
AR ﬁlter of the social media platform. As previously stated, most of these ﬁlters can only be applied on live
images from the camera. To overcome this limitation, the virtual webcam projects the existing image dataset
on the camera enabling the application of the AR ﬁlters on it. Through an auto-clicker system, each image is
ﬁrst projected on the camera; next, the ﬁlter is applied to the image and ﬁnally the ﬁltered image is saved
on disk. The instructions for use and a walk-through video are available in our repository; an exemplary
screenshot and code snippets can be found in the Appendix. OpenFilter processes an image every 4 seconds
on a Intel(R) Core(TM) i7-8565U machine with NVIDIA GeForce MX150, i.e. around 900 images per hour
and 22,000 per day.

Next, we describe two novel datasets created using OpenFilter by applying eight popular AR beautiﬁcation
ﬁlters to the FairFace (30) and LFW (27) benchmark face datasets. We also provide insights derived from
the analysis of the impact of the beauty ﬁlters on the original face images.

4 FairBeauty and B-LFW: Two Novel Datasets of Beautiﬁed Faces

In recent years, AR face ﬁlters are increasingly used to beautify the original faces and make them conform
to certain canons of beauty by digitally modifying facial features, especially among female users (45). We
shall refer to these ﬁlters as beauty ﬁlters. While selﬁes have been used to challenge beauty norms and to
propose diﬀerent and ironic perspectives (15; 2; 55), the popularity of beauty ﬁlters seems to be pushing in
the opposite direction. According to (14), beauty ﬁlters contribute to the sexualization of women, while (16)
claim that the aesthetic concept behind beauty ﬁlters projects the female faces closer to normative ideals of
femininity.

Nowadays, thousands of AR beauty ﬁlters are available on Instagram and other social media platforms. These
ﬁlters apply similar transformations to the input image: they provide a smooth and uniformly colored skin,
almond shaped eyes and brows, full lips, a small nose and a prominent cheek structure (46; 38; 33; 29; 50; 22; 41)
(see the examples in Figure 2). Given the scale of this phenomenon, beauty ﬁlters are an interesting research
topic to strengthen our understanding of the development of contemporary culture and aesthetics (49). On
the one hand, the extensive use and exposure to beautiﬁed selﬁes seems to be a homogenizing force of beauty
standards, contributing to a signiﬁcant increase in teenage plastic surgery (31) and mental health issues (1).
On the other, today’s fashion brands, companies, magazine editors and movie producers are encouraging a
more diverse and inclusive view on beauty, which is partly attributed to the emergence and persistence of the
selﬁes culture (19). In this paper, we do not take a stand on the virtues and dangers of beauty ﬁlters for
society: as with every technology, its use creates a spectrum of possibilities whose value should be properly
investigated and understood through interdisciplinary research. For this reason, we share a technical tool
(OpenFilter) that facilitates quantitative and qualitative research in this ﬁeld and present an exemplary
case study on two novel datasets: FairBeauty and B-LFW.

FairBeauty is a beautiﬁed version of the FairFace dataset (30). FairFace (license CC BY 4.0) contains
108,501 face images, promoting algorithmic fairness in Computer Vision systems. The choice of this dataset
is motivated by its focus on diversity and our will to identify a dataset that would be representative of the
population of Instagram –which is a globalized social environment with over 800 million users in the world11–
without biasing the results towards speciﬁc facial traits, gender or age ranges. In FairBeauty, eight popular,
AR beauty ﬁlters are applied on equal portions of the original dataset. An example of the applied ﬁlters is
shown in Figure 2. The choice of the beauty ﬁlters is based on their popularity, which we assessed through

9https://github.com/ellisalicante/OpenFilter
10In our implementation, we refer to Instagram, but OpenFilter may be used with any other social media application available

on the Android emulator.

11https://www.statista.com/statistics/578364/countries-with-most-instagram-users/

4

articles in women’s magazines12 and relevant trends on Instagram. All selected beauty ﬁlters have been
created by Instagram users that describe themselves as ﬁlter/digital artists.

B-LFW is a beautiﬁed version of the LFW (Labeled Faces in the Wild) (27) dataset, a public benchmark
dataset for face veriﬁcation, designed for studying and evaluating unconstrained face recognition systems.
This dataset contains more than 13,000 facial images of 1,680 diﬀerent individuals who appeared in the news
and hence are public ﬁgures. In this work, we have beautiﬁed LFW with the same eight popular Instagram
beauty ﬁlters described above and depicted in Figure 2, using diﬀerent ﬁlters on diﬀerent images from the
same individuals.

Figure 2: Example of the eight diﬀerent beauty ﬁlters applied to the left-most image (30). From left to
right and top to bottom: ﬁlter 0 -pretty by herusugiarta; ﬁlter 1 -hari beauty by hariani; ﬁlter 2 -Just
Baby by blondinochkavika; ﬁlter 3 -Shiny Foxy, ﬁlter 4 -Caramel Macchiato and ﬁlter 5 -Cute baby face by
sasha_soul_art; ﬁlter 6 -Baby_cute_face_ by anya__ilicheva; ﬁlter 7 -big city life by triutra.

4.1 Intended Use

In this paper, we address two research questions through the analysis of the shared datasets. In RQ1, we
investigate whether beauty ﬁlters homogenize faces, hence reducing the distance between pairs of faces. In
RQ2, we explore the impact of beautiﬁed faces on face veriﬁcation techniques. In addition, we outline other
research directions that would be enabled by the beautiﬁed face datasets.

The ﬁrst direction concerns studying the inﬂuence of beauty ﬁlters on social constructs, such as trustworthiness,
homophily and intelligence, both computationally and through user studies. Recent work has reported that
humans trust deep fakes more than faces of real humans (39) and scholars have found an attractiveness halo
(13; 53), which is the tendency to assign positive qualities and traits –such as higher morality, better mental
health, and greater intelligence– to physically attractive people. The two datasets shared in this paper would
enable empirical research to assess the existence, prevalence and intensity of the attractiveness halo.

A second direction concerns societal implications of beauty ﬁlters on social media platforms. These ﬁlters
have raised concerns regarding existing biases in the automatic beautiﬁcation practices and have been widely
criticized for perpetuating racism (38) and, in particular, colorism (46). Note that the ﬁlters we apply
to obtain the beautiﬁed datasets are selected due to their popularity on social media platforms, without
considering the cultural background of the ﬁlter creators. FairBeauty opens the possibility of studying
such issues computationally, and to understand their nature and scope.

We strongly discourage controversial and unethical uses of our framework and datasets, including the
In 2017, a Make-Up Remover App13 was released,
development of beautiﬁcation removal applications.
unleashing a wave of criticism (32; 5; 34) as it was perceived as sexist and misogynistic. We acknowledge that

12https://creatorkit.com/blog/most-popular-instagram-filters-effects and
https://inflact.com/blog/instagram-filters-for-stories/, accessed in April 2022

13The application is no longer available.

5

the removal of beauty ﬁlters may be considered an insightful research topic from a technical perspective, and
some of the application ﬁelds (e.g. psychotherapy for teenagers dealing with low self-esteem and dysmorphia)
could be highly beneﬁcial. However, the wide distribution of such a tool to the general public could have
negative unintended eﬀects. In addition, regarding the development of face recognition techniques, we stress
that this technology raises several legal and ethical challenges (11), which need to be taken into account to
avoid perpetuating injustice (43) and to preserve the privacy of individuals (11). Considering these potential
implications, we share all our assets with exclusively non-commercial licenses (CC BY-NC-SA 4.0 for the
datasets, dual licensing of GNU General Public License version 2 for OpenFilter), encouraging our readers to
be always cognizant of the implications of their uses.

In the next section, we describe two preliminary experiments on the generated datasets to address RQ1 and
RQ2. We study RQ1 –the homogenization of faces– on the FairBeauty dataset. We explore RQ2 –the
impact of beauty ﬁlters on face recognition systems– by analyzing the B-LFW dataset.

5 Experiments

5.1 Preliminaries

Problem formulation We are given an evaluation set X ⊂ X , where X is the input space, and a
transformation set T . We are also given a model fθ : X → Rd that maps input samples to a d-dimensional
embedding vector. Parameters θ are obtained, as f is typically pre-trained on a larger set. Given two sample
images x, x0 ∈ X , we denote by d(x, x0) the distance between x, x0 in the embedding space, typically an
increasing function of Euclidean distance. We call x, x0 a pair. The set T contains transformations shown in
Figure 3, such as beautiﬁcation, Gaussian ﬁltering or down-sampling. We denote these transformations by
tb, tg, ts ∈ T respectively. We denote by xb the beautiﬁed version of x, that is xb = tb(x), etc; tσ=n
represents
the application of a Gaussian ﬁlter with radius n on image x, which will result in an image xg, while tw,h=N
represents the down-sampling from RH×W ×3 → RN ×N ×3, which will result in an image xs. It is common to
‘2-normalize the embeddings. To simplify the notation, we drop the dependencies of f , d.

g

s

Setup We conduct experiments leveraging diﬀerent face veriﬁcation models to determine the similarity
between pairs of faces. Three of them –namely DeepFace (52), VGG-Face (40), and Facenet (47)– are
well-known models available in the Python library deepface (48); the other three – CurricularFace (28),
MagFace (36), and ElasticFace (8)– are recent state-of-the-art models for face recognition. DeepFace and
VGG-Face use a custom CNN architecture with an embedding size d = 4096, Facenet uses Inception-ResNet
(51) with an embedding size d = 128. CurricularFace, MagFace and ElasticFace use ResNet100 (12) with
an embedding size d = 512. DeepFace, VGG-Face and Facenet are pre-trained on the VGGFace2 dataset
(40), while CurricularFace, MagFace and ElasticFace are pre-trained on the MS1MV2 dataset (12), a reﬁned
version of the MS-Celeb-1M (21), containing 5.8M images of 85k identities. We evaluate on both original and
transformed datasets following the evaluation protocols and metrics of each dataset.

5.2 Experiments on FairBeauty: RQ1 - Do beauty ﬁlters homogenize faces?

The AR beauty ﬁlters detect the position of the faces in an original image and super-impose digital content
to modify (i.e. to beautify) the original facial features. As these ﬁlters apply the same transformation to
the facial features of all faces, we hypothesize that they homogenize facial aesthetics making the beautiﬁed
faces more similar to each other. As previously stated, the images in FairFace are diverse by design. In
it
this experiment, we aim to assess whether the application of beauty ﬁlters reduces the diversity, i.e.
homogenizes the FairFace dataset.

To determine the homogenization of the ﬁltered faces, we consider both the FairFace and the FairBeauty
datasets. We conduct this experiment using the six diﬀerent models previously described, i.e. DeepFace,
VGG-Face, Facenet, CurricularFace, MagFace and ElasticFace. First, we sample pairs of faces. Next, we
forward them through a pre-trained model f and obtain the corresponding embedding vectors to compute the
distance d between them. For every experiment, we compute the distances between a diﬀerent subset of 500
pairs of images, so that the overall measurements consider 3,000 distinct pairs of images, to minimize potential

6

Algorithm 1 Computation of pair-wise face distances
Require: Datasets FairFace, FairBeauty, Model f
Ensure: Collection C

1: C ← {}
2: repeat
3:
4:
5:

6:

7:

Sample (x, x0) from FairFace
Select (xb, x0
b
g ← tσ=2
xg, x0
g
g ← tσ=3
ˆxg, ˆx0
g
s ← tw,h=64
xs, x0
s

) from FairBeauty
(x0)
(x), tσ=2
g
(x0)
(x), tσ=3
g

(x), tw,h=64
s

(x0)

8: m ← ||f (x) − f (x0)||2
)||2
9: mb ← ||f (xb) − f (x0
b
)||2
g ← ||f (xg) − f (x0
10: m0
g
)||2
g ← ||f (ˆxg) − f (ˆx0
11: m00
g
12: ms ← ||f (xs) − f (x0
)||2
s
g, m00
C ← C ∪ {m, mb, m0
g , ms}
13:
14: until 500 repetitions are reached

biases in the results. We evaluate the homogenization using the average distance of all sampled pairs from
FairFace and FairBeauty datasets, i.e. the lower the average distance, the greater the homogenization. In
FairBeauty, the eight selected beauty ﬁlters are applied on equal portions of the original FairFace dataset,
to better simulate a social media scenario. Note that the images are selected without considering the applied
ﬁlter, and the loss of diversity is therefore analyzed even when applying diﬀerent beauty ﬁlters to diﬀerent
images that are compared. As a reference, we perform the same computation when applying Gaussian ﬁltering
(blurring) and down-sampling (pixelation) to the original faces of the FairFace dataset. This comparison
allows a better understanding of the potential diversity loss due to the beauty ﬁlters. Examples of the original,
beautiﬁed, Gaussian ﬁltered and down-sampled images are shown in Figure 3, while the algorithm can be
found in Algorithm 1.

Figure 3: An exemplary pair of images from (30) illustrating the ﬁve diﬀerent versions that are analyzed to
address RQ1: the face homogenization experiment. From left to right: beautiﬁed version using OpenFilter,
original version, blurred version with Gaussian ﬁlter at radius 2, blurred version with Gaussian ﬁlter at radius
3, down-sampled (pixeled) version to 64x64 pixels.

The results of this experiment are shown in Figure 4. For each pair, distances between transformed images
are plotted in terms of diﬀerences w.r.t. the distance between the original images. A value of 0 (plotted as a
dashed red line in the Figure) means that there is no diﬀerence between the original distance and the distance
after applying one transformation, i.e. the transformation does not aﬀect the distance between the faces. In
Figure 4, we observe a signiﬁcant diﬀerence in the distances between the original and the transformed faces.
Depending on the experiment, the reduction in distances that comes with beautiﬁcation is comparable to the
eﬀect of applying either Gaussian ﬁlters or down-sampling on the images. In all cases, the measurements
obtained on the beautiﬁed version have lower average distance than those of the original dataset. In other

7

Figure 4: Boxplots of the diﬀerences in the distance metric obtained for ﬁltered image pairs versus the metric
obtained for the corresponding original pairs of images. A negative value indicates that an image pair was
more similar (lower distance metric) when ﬁltered as compared to the original pair. Speciﬁcally, each subplot
shows these values for the beautiﬁed ﬁltered (blue), blurred with a Gaussian ﬁlter of radius 2 (yellow) and 3
(green), and down-sampled or pixelated (red) images. The obtained distances and the distances between
the original pairs (with no transformation) are ﬁrst scaled to range [0, 1], then subtracted, to allow a better
visualization of the results.

Table 1: Paired t-test results comparing similarity distributions of the original faces and the beautiﬁed faces.
Each column corresponds to a diﬀerent sample of 500 couple of images, processed with a diﬀerent model.

DeepFace VGG-Face

Facenet

CurricularFace MagFace

ElasticFace

t-statistic
p-value

-15.09
1.200e-42

-8.428
3.776e-16

-10.32
9.561e-23

-9.775
9.110e-21

-30.63
1.070e-116

-11.94
4.400e-29

words, according to these experiments, the beautiﬁed faces in FairBeauty are statistically more similar to
each other than the original faces. Thus, the answer to RQ1 is positive.

We further analyze the statistical diﬀerence between the measurements obtained on the original images and
the beautiﬁed ones through paired t-tests on each experiment. The results are shown in Table 1. This test
conﬁrms that the distributions are statistically diﬀerent with p-values below 3.776e − 16 in all cases.

5.3 Experiments on B-LFW: RQ2 - Do beauty ﬁlters hinder face recognition?

In this section, we describe experiments to address RQ2, i.e. to shed light on the impact of AR beauty
ﬁlters on face recognition techniques. Previous works (23; 7) focus on the impact of simple ﬁlters on face
recognition, particularly ﬁlters that apply occlusions of some parts of the faces. However, to the best of our
knowledge, there is no previous work analyzing the impact of this type of beauty ﬁlters on face recognition.
Hence, the analysis of the B-LFW dataset may lead to new insights on understanding the impact of such
ﬁlters, particularly when no explicit occlusion is applied. This analysis is of societal relevance given the wide
adoption of these ﬁlters on today’s social media platforms.

We evaluate the performance of three state-of-the-art face recognition models (CurricularFace, ElasticFace
and MagFace) on the original LFW dataset, on each single beauty ﬁlter applied to LFW and on the B-LFW
dataset (in which diﬀerent beauty ﬁlters are applied on diﬀerent images of the same individual). To perform
these experiments, we ﬁlter the entire LFW dataset (27) with each of the ﬁlters, creating eight diﬀerent

8

Table 2: Veriﬁcation accuracy (%) of three state-of-the-art models on LFW, eight ﬁltered variants of LFW
and B-LFW. Red, Green: respectively, the greatest and lowest performance drop compared to LFW. w/:
with. f0 - f7: Filter 0 - Filter 7.

CurricularFace MagFace ElasticFace

LFW

LFW w/ f0
w/ f1
w/ f2
w/ f3
w/ f4
w/ f5
w/ f6
w/ f7

B-LFW

99.80

98.93
99.33
98.90
99.13
99.13
99.18
98.08
96.06

99.38

99.82

99.47
99.42
99.37
99.45
99.45
99.49
98.42
96.23

99.63

99.80

99.17
99.50
99.35
99.33
99.43
99.67
98.38
96.18

99.57

variants of it, one for each beauty ﬁlter. The obtained results are shown in Table 2, where the ﬁlters are
shown in the same order as in Figure 2.

Evaluating the impact of each ﬁlter on face recognition opens interesting research lines related to studying
which properties of AR ﬁlters have a stronger impact on face recognition methods. Note how Filter 7 (big
city life by triuta) is the ﬁlter that impacts the recognition accuracy the most when compared to the rest of
ﬁlters. This eﬀect is consistent across the three state-of-the-art models, as CurricularFace drops performance
by 3.74% (99.80 → 96.06), MagFace by 3.59% (99.82 → 96.23) and ElasticFace by 3.62% (99.80 → 96.18).
As shown in Figure 2, this ﬁlter applies strong modiﬁcations not only to the facial features but also to the
contrast, hue and exposition of the images.

As previously mentioned, the B-LFW dataset has the purpose of simulating the social media environment,
in which diﬀerent ﬁlters co-exist. In Table 2, we observe that the results on B-LFW do not show signiﬁcant
decrease in the performance of state-of-the-art face recognition models.

6 Discussion

In the experiment on the FairBeauty dataset, we empirically show that, regardless of the selected sample
of images and utilized model, there is a general homogenization of the beautiﬁed faces when compared to
the original ones. However, the experiment on B-LFW shows that the application of beauty ﬁlters does not
generally impact the performance of the state-of-the-art face recognition models. This result is intuitively
consistent with the role of beauty ﬁlters in social media: their goal is to improve the appearance of the user
while preserving their identity. As a future research direction, we plan to investigate how the homogenization
eﬀect of beauty ﬁlters varies depending on the similarity between the original pair of images. It is expected
that images that are originally diﬀerent (based on diﬀerent attributes, such as diﬀerent ages, genders and/or
races) would be homogenized more than images that are originally similar. Investigating this characteristic
could highlight intrinsic and subtle biases in the beautiﬁcation canons of these ﬁlters. Note that, in this
paper, face recognition techniques are utilized as a research tool to improve our understanding of the impact
and behavior of beauty ﬁlters, rather than the opposite. We do not conceive our research on beauty ﬁlters as
a way to improve the quality of current face recognition techniques; in case our readers wish to develop this
line of research, we emphasize that they should deeply consider the expected beneﬁts and potential negative
consequences of their research. Another directions of future research entails studying the behavior of the
beauty ﬁlters depending on the facial expressions of the individuals and performing a deeper investigation of

9

the impact of beauty ﬁlters on face veriﬁcation algorithms including diﬀerent performance metrics beyond
accuracy.

The framework proposed in this paper, OpenFilter, allows researchers from diﬀerent disciplines to have
access to the AR ﬁlters available on social media. Despite being ﬂexible and adaptable, we highlight two
limitations. First, the framework requires some software skills to precisely follow the given instructions. In
addition, due to the resolution limitations of social media, the ﬁlters can be applied only to images of up to
512x512 pixels. Unfortunately, this limitation does not allow to fully appreciate the power of some AR ﬁlters:
beauty ﬁlters, for example, apply strong skin smoothing that is less visible on low-resolution images.

We emphasize that any researcher utilizing our datasets should consider their ecological validity before
drawing conclusions on the impact of beauty ﬁlters on society. As explained in section 2, we have made a
signiﬁcant eﬀort in simulating the real social media environment (further details in the Appendix). However,
the users of these platforms tend to use speciﬁc communication paradigms –for example, in their poses
(54) and facial expressions (42) – which would be represented in a dataset created by scraping the images
from social media. However, such practice should be avoided in due to privacy and ethical concerns. As a
consequence, FairBeauty and B-LFW contain faces that may be demographically more diverse (e.g. in terms
of gender) than the faces of the typical users of beauty ﬁlters on social media.

7 Conclusion

In this paper, we share a framework (OpenFilter) to automatically apply AR ﬁlters on benchmark face
datasets. We have also applied popular beautiﬁcation ﬁlters to two publicly available face datasets and have
drawn key insights on the characteristics of AR ﬁlter-based beautiﬁcation. We believe that the dynamics
related to the eﬀects of beautiﬁcation ﬁlters deserves more interest from diﬀerent disciplines. We hope that
the two datasets shared in this paper (FairBeauty and B-LFW) and our framework (OpenFilter) will
inspire and support novel research in this ﬁeld, which is, otherwise, hardly accessible.

Acknowledgements

Piera Riccio and Nuria Oliver are supported by a nominal grant received at the ELLIS Unit Alicante
Foundation from the Regional Government of Valencia in Spain (Convenio Singular signed with Generalitat
Valenciana, Conselleria d’Innovació, Universitats, Ciència i Societat Digital, Dirección General para el Avance
de la Sociedad Digital). Piera Riccio is also supported by a grant by the Banc Sabadell Foundation.

References
[1] E. Abi-Jaoude, K. T. Naylor, and A. Pignatiello. Smartphones, social media use and youth mental health.

Canadian Medical Association Journal, 192(6):E136–E141, Feb. 2020.

[2] C. Abidin. “aren’t these just young, rich women doing vain things online?”: Inﬂuencer selﬁes as subversive

frivolity. Social Media + Society, 2(2):2056305116641342, 2016.

[3] G. Appel, L. Grewal, R. Hadi, and A. T. Stephen. The future of social media in marketing. Journal of the

Academy of Marketing Science, 48(1):79–95, Oct. 2019.

[4] S. Ashby, B. Abbas, R. A. Rahme, B. Troemel, and O. Kholeif. You are here: Art after the internet, 2018.

[5] K. Bell. Makeup removing app is a great way to ruin your selﬁes, 2017.

[6] A. Bharati, M. Vatsa, R. Singh, K. W. Bowyer, and X. Tong. Demography-based facial retouching detection using
subclass supervised sparse autoencoder. In 2017 IEEE International Joint Conference on Biometrics (IJCB),
pages 474–482, 2017.

[7] C. Botezatu, M. Ibsen, C. Rathgeb, and C. Busch. Fun selﬁe ﬁlters in face recognition: Impact assessment and

removal. arXiv preprint arXiv:2202.06022, 2022.

[8] F. Boutros, N. Damer, F. Kirchbuchner, and A. Kuijper. Elasticface: Elastic margin loss for deep face recognition.

arXiv preprint arXiv:2109.09416, 2021.

10

[9] Broadband. Average time spent daily on social media, 2022.

[10] N. Bruno, K. Pisanski, and S. et al. Editorial: Understanding selﬁes. Frontiers in psychology, 9:44, 2018.

[11] Q. Bu. The global governance on automated facial recognition (afr): ethical and legal opportunities and privacy

challenges. International Cybersecurity Law Review, 2(1):113–145, 2021.

[12] J. Deng, J. Guo, N. Xue, and S. Zafeiriou. Arcface: Additive angular margin loss for deep face recognition. In
2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 4685–4694, 2019.

[13] K. K. Dion. Physical attractiveness and evaluation of children's transgressions. Journal of Personality and Social

Psychology, 24(2):207–213, 1972.

[14] A. Dobson. Postfeminist Digital Cultures: Femininity, Social Media, and Self-Representation. Palgrave Macmillan,

Australia, 2015.

[15] A. S. Dobson. “sexy” and “laddish” girls. Feminist Media Studies, 14(2):253–269, 2014.

[16] A. S. Elias and R. Gill. Beauty surveillance: The digital self-monitoring cultures of neoliberalism. European

Journal of Cultural Studies, 21(1):59–77, 2018.

[17] F. M. Felisberti and K. Musholt. Self-face perception: Individual diﬀerences and discrepancies associated with
mental self-face representation, attractiveness and self-esteem. Psychology & Neuroscience, 7(2):65–72, 2014.

[18] R. Fribourg, E. Peillard, and R. McDonnell. Mirror, mirror on my phone: Investigating dimensions of self-face
perception induced by augmented reality ﬁlters. In 2021 IEEE International Symposium on Mixed and Augmented
Reality (ISMAR), pages 470–478, 2021.

[19] R. Givhan and A. Morales. The idea of beauty is always shifting. today, it’s more inclusive than ever., Jan 2020.

[20] E. e. a. Goﬀman. The presentation of self in everyday life, volume 21. Harmondsworth London, 1978.

[21] Y. Guo, L. Zhang, Y. Hu, X. He, and J. Gao. Ms-celeb-1m: A dataset and benchmark for large-scale face

recognition. In European conference on computer vision, pages 87–102. Springer, 2016.

[22] A. Haines. From ‘instagram face’ to ‘snapchat dysmorphia’: How beauty ﬁlters are changing the way we see

ourselves, Apr 2021.

[23] P. Hedman, V. Skepetzis, K. Hernandez-Diaz, J. Bigun, and F. Alonso-Fernandez. On the eﬀect of selﬁe

beautiﬁcation ﬁlters on face detection and recognition. arXiv preprint arXiv:2110.08934, 2021.

[24] P. Hedman, V. Skepetzis, K. Hernandez-Diaz, J. Bigun, and F. Alonso-Fernandez. Lfw-beautiﬁed: A dataset of

face images with beautiﬁcation and augmented reality ﬁlters. arXiv preprint arXiv:2203.06082, 2022.

[25] J. Herrington. Face ﬁlters as augmented reality art on social media. In Springer Series on Cultural Computing,

pages 297–310. Springer International Publishing, 2022.

[26] A. Hess. The selﬁe assemblage. International Journal of Communication, 9(1):1629–1646, 2015.

[27] G. B. Huang, M. Mattar, T. Berg, and E. Learned-Miller. Labeled Faces in the Wild: A Database forStudying
Face Recognition in Unconstrained Environments. In Workshop on Faces in ’Real-Life’ Images: Detection,
Alignment, and Recognition, Marseille, France, Oct. 2008. Erik Learned-Miller and Andras Ferencz and Frédéric
Jurie.

[28] Y. Huang, Y. Wang, Y. Tai, X. Liu, P. Shen, S. Li, J. Li, and F. Huang. Curricularface: Adaptive curriculum
learning loss for deep face recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR), June 2020.

[29] V. Jagota. Why do all the snapchat ﬁlters try to make you look white?, Jun 2016.

[30] K. Karkkainen and J. Joo. Fairface: Face attribute dataset for balanced race, gender, and age for bias measurement
and mitigation. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV),
pages 1548–1558, January 2021.

[31] N. Khunger and H. Pant. Cosmetic Procedures in Adolescents: What’s Safe and What Can Wait. Indian Journal

of Paediatric Dermatology, 22(1):12–20, 2021.

11

[32] C. Ledbetter. Controversial photo-editing app under ﬁre for makeup removal feature, 2017.

[33] S. Li. The problems with instagram’s most popular beauty ﬁlters, from augmentation to eurocentrism, Jul 2020.

[34] S. Liao. I used a makeup removal app repeatedly to turn into an acne-covered zombie, 2017.

[35] T. Mare, G. Duta, M.-I. Georgescu, A. Sandru, B. Alexe, M. Popescu, and R. T. Ionescu. A realistic approach to

generate masked faces applied on two novel masked face recognition data sets, 2021.

[36] Q. Meng, S. Zhao, Z. Huang, and F. Zhou. Magface: A universal representation for face recognition and quality
assessment. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),
pages 14225–14234, June 2021.

[37] R. Mihăilă and L. Branişte. Digital semantics of beauty apps and ﬁlters: Big data-driven facial retouching,
aesthetic self-monitoring devices, and augmented reality-based body-enhancing technologies. Journal of Research
in Gender Studies, 11(2):100–112, 2021.

[38] S. Mulaudzi. Let’s be honest: Snapchat ﬁlters are a little racist, Jan 2017.

[39] S. J. Nightingale and H. Farid. Ai-synthesized faces are indistinguishable from real faces and more trustworthy.

Proceedings of the National Academy of Sciences, 119(8):e2120481119, 2022.

[40] O. Parkhi, A. Vedaldi, and A. Zisserman. Deep face recognition. BMVC 2015 - Proceedings of the British Machine

Vision Conference 2015, pages 1–12, 2019.

[41] K. Pillai. Social media ﬁlters harm young girls by reinforcing beauty standards, Oct 2020.

[42] L. Qiu, J. Lu, S. Yang, W. Qu, and T. Zhu. What does your selﬁe say about you? Computers in Human Behavior,

52:443–449, 2015.

[43] I. D. Raji, T. Gebru, M. Mitchell, J. Buolamwini, J. Lee, and E. Denton. Saving face: Investigating the ethical
concerns of facial recognition auditing. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society,
AIES ’20, page 145–151, New York, NY, USA, 2020. Association for Computing Machinery.

[44] J. S. Rios, D. J. Ketterer, and D. Y. Wohn. How users choose a face lens on snapchat. In Companion of the 2018
ACM Conference on Computer Supported Cooperative Work and Social Computing, CSCW ’18, page 321–324,
New York, NY, USA, 2018. Association for Computing Machinery.

[45] T. Ryan-Mosley. Beauty ﬁlters are changing the way young girls see themselves, Apr 2021.

[46] T. Ryan-Mosley. How digital beauty ﬁlters perpetuate colorism, Aug 2021.

[47] F. Schroﬀ, D. Kalenichenko, and J. Philbin. Facenet: A uniﬁed embedding for face recognition and clustering. In

Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2015.

[48] S. I. Serengil and A. Ozpinar. Lightface: A hybrid deep face recognition framework. In 2020 Innovations in

Intelligent Systems and Applications Conference (ASYU), pages 1–5, 2020.

[49] E. Shein. Filtering for beauty. Communications of the ACM, 64(11):17–19, 2021.

[50] J. Singer. Let’s talk about our love-hate relationship with beauty ﬁlters, Apr 2022.

[51] C. Szegedy, S. Ioﬀe, V. Vanhoucke, and A. A. Alemi. Inception-v4, inception-resnet and the impact of residual

connections on learning. In Thirty-ﬁrst AAAI conference on artiﬁcial intelligence, 2017.

[52] Y. Taigman, M. Yang, M. Ranzato, and L. Wolf. Deepface: Closing the gap to human-level performance in face
veriﬁcation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June
2014.

[53] S. N. Talamas, K. I. Mavor, and D. I. Perrett. Blinded by beauty: Attractiveness bias and accurate perceptions

of academic performance. PLOS ONE, 11(2):e0148284, Feb. 2016.

[54] A. Tifentale and L. Manovich. Selﬁecity: Exploring Photography and Self-Fashioning in Social Media, pages

109–122. Palgrave Macmillan UK, London, 2015.

12

[55] K. Tiidenberg. Boundaries and conﬂict in a nsfw community on tumblr: The meanings and uses of selﬁes. New

Media & Society, 18(8):1563–1578, 2016.

[56] M. Zetlin. Taking selﬁes destroys your conﬁdence and raises anxiety, a study shows. why are you still doing it?,

May 2019.

A Appendix

OpenFilter: implementation details

Most of the AR ﬁlters available on social media platforms can only be applied in real-time on selﬁe images
captured from the camera. Hence, it is challenging to carry out quantitative and systematic research on such
ﬁlters. OpenFilter fulﬁlls such a need through (1) an Android Emulator, (2) a computer and (3) a virtual
webcam. Through an auto-clicker system, each image is ﬁrst projected on the camera; next, the ﬁlter is
applied to the image and ﬁnally the ﬁltered image is saved on disk.

For the auto-clicker to work, it is necessary to place the required elements in a precise position on the desktop.
More details are available in our repository, and an exemplary screenshot can be found in Figure 5. Note that
OpenFilter saves the ﬁltered images by taking a screenshot, rather than downloading the image directly
from the social media app. This is motivated by the will of accelerating the process: very often, images
treated with AR ﬁlters are downloaded as videos, causing remarkable delays. OpenFilter is designed to ﬁlter
large collections of images and, as a consequence, the ﬂuidity of the system is one of the main speciﬁcation
requirements.

Figure 5: Screen set-up for OpenFilter. Android simulator on the left, virtual camera on the right. The
image is projected on the camera opened on Instagram and the selected ﬁlter is directly applied on the image.

Next, we highlight several code snippets of OpenFilter. In Listing 1, we include the requirements. Note
that since we are dealing with an auto-clicker, we identify the positions of the diﬀerent elements on the
desktop. The values reported correspond to a full-HD desktop (1920 x 1080 pixels), and will need to be
re-calibrated in case of diﬀerent screen resolutions. In particular, new_file refers to the position of the next
image that will be processed by the system; many_cam and many_cam_confirm respectively refer to the area

13

on the virtual camera where the new image is dragged and the conﬁrmation button on its interface; screen
refers to the four corners of the area where the screenshot is taken to save the ﬁltered image; right_filter
and left_filter respectively refer to the position of the next ﬁlter on the right and on the left of the current
one.

Listing 1: Requirements

import random
import time
import numpy a s np
import o s
import a r g p a r s e
from PIL import Image

import p y a u t o g u i a s auto

p o s i t i o n s = {

( 1 2 2 0 , 7 5 0 ) ,
( 1 1 5 0 , 2 5 0 ) ,

" n e w _ f i l e " :
"many_cam" :
" many_cam_confirm " :
" s c r e e n " :
" r i g h t _ f i l t e r " :
" l e f t _ f i l t e r " :

( 4 3 0 , 9 8 0 ) ,

( 1 5 0 , 9 8 0 )

( 4 2 , 3 0 5 , 5 1 0 , 5 1 0 ) ,

( 1 1 8 0 , 2 8 0 ) ,

}

In Listing 2, we include the relevant functions that are implemented in the auto-clicker. The function
drag_and_drop is used to move the images on the desktop, processing them sequentially. The calls to the
function sleep are calibrated to the response times of software on a Intel(R) Core(TM) i7-8565U machine
with NVIDIA GeForce MX150. The functions h_padding and v_padding create a padding around the target
image, so that the buttons of the interface of the social media app (Instagram in our case, see Figure 5)
do not overlap with the image. The full code including the order of the diﬀerent actions performed by the
auto-clicker is available in our repository.

Listing 2: Functions

def drag_and_drop ( s t a r t , end ) :
auto . mouseDown ( s t a r t )
auto . moveTo ( end )
auto . mouseUp ( )

def

s l e e p (ms ) :
s e c o n d s = ms / 1000
s e c o n d s += random . random ( ) ∗ s e c o n d s /10
time . s l e e p ( s e c o n d s )

def h_padding ( img ) :

new_size = ( img . s i z e [ 0 ] + 5∗ img . s i z e [ 0 ] / / 2 8 5 ,
background = Image . new ( ’RGB ’ , new_size )
background . p a s t e ( img ,
return background

( background . s i z e [ 0 ] − img . s i z e [ 0 ] , 0 ) )

img . s i z e [ 1 ] )

def v_padding ( img ) :

new_size = ( img . s i z e [ 0 ] ,
background = Image . new ( ’RGB ’ , new_size )
background . p a s t e ( img ,

( 0 ,

img . s i z e [ 1 ] + 150∗ img . s i z e [ 1 ] / / 2 8 5 )

( background . s i z e [ 1 ] − img . s i z e [ 1 ] ) / / 2 ) )

14

return background

Dataset Documentation

We have beautiﬁed two face datasets using OpenFilter which we also share in this contribution.

FairBeauty is a beautiﬁed version of the FairFace dataset, following the same nomenclature for the ﬁles
and the same dataset documentation.14 FairFace is publicly available with a CC BY 4.0 license. This
license enables sharing, copying and redistributing the material in any medium and format and adapt, remix,
transform and build upon the material for any purpose, even commercially. Hence, we had permission to
create the FairBeauty dataset as derivative work. We share FairBeauty with a CC-BY-NC-SA 4.0 license
which does not allow the use of the datasets for commercial purposes.

In the case of FairBeauty, the original folders (train and validation) are divided into subfolders according to
the name of the images (e.g. images from 0_01.png to 999_01.png are in subfolder 000000, from 1000_01.png
to 1999_01.png in subfolder 001000, and so on). Additionally, we provide metadata regarding the ﬁlter that
is applied on the images. This information is enclosed in the ﬁles filters.txt that can be found in the two
main folders (train and validation). These ﬁles associate the ﬁlter name to the name of a subfolder. All the
images in a subfolder are beautiﬁed using the same ﬁlter. An extract of filters.txt is shown in Listing
3: on the left-hand side we provide the name of the subfolder, and on the right-hand side the name of the
utilized ﬁlter.

Listing 3: Filters.txt

0 2 1 0 0 0 : b i g c i t y l i f e
0 2 2 0 0 0 : hary beauty
0 2 3 0 0 0 : P r e t t y
0 2 4 0 0 0 : Shiny f o x y
0 2 5 0 0 0 : J u s t Baby
0 2 6 0 0 0 : hary beauty
0 2 7 0 0 0 : P r e t t y

To facilitate the access to the ﬁles, we provide a synthetic representation of the ﬁlenames in FairBeauty
through the regular expressions available in Listing 4, distinguished for the two diﬀerent folders (train and
validation).

Listing 4: Regular expressions for FairBeauty ﬁles.

t r a i n _ f a i r _ b e a u t y

^0[0 −86]{2}000 $

^ [ 0 − 9 ] { 1 , 5 }_0[ 0 − 9 ] { 1 } \ . png$

f i l t e r s . t x t

v a l _ f a i r _ b e a u t y

^0[0 −10]{2}000 $

^ [ 0 − 9 ] { 1 , 5 }_0[ 0 − 9 ] { 1 } \ . png$

f i l t e r s . t x t

B-LFW is a beautiﬁed version of the LFW (Labeled Faces in the Wild) dataset, a public benchmark dataset
for unconstrained face recognition. In particular, we beautify the aligned version with the images rescaled at
112x112 pixels15, where the images are shared as a carray of the bcolz Python library. For the beautiﬁcation
purposes, we extract the images from the array and convert them to png ﬁles. The nomenclature of the ﬁles
in our dataset follows the index of the images in the original array (i.e. the entry 0 of the array is coverted

14More information available on the oﬃcial Github repository of FairFace: https://github.com/joojs/fairface.
15Version available at: https://github.com/ZhaoJ9014/face.evoLVe.

15

to 0.png). In the case of B-LFW, the ﬁlters correspondence for every image is synthesized into the numpy
array filters.npy. The entries of this array are integer number from 0 to 7, referring to the eight beauty
ﬁlters. The position of the ﬁlter ID in the array corresponds to the name of the beautiﬁed image (i.e. if entry
0 of filters.npy is equal to 2, then ﬁlter 2 is applied on image 0.png). Please refer to Listing 5 for the
correspondence between ﬁlter IDs and names.

Listing 5: Correspondence between ﬁlter IDs and names.

f i l t e r 0 :
f i l t e r 1 :
f i l t e r 2 :
f i l t e r 3 :
f i l t e r 4 :
f i l t e r 5 :
f i l t e r 6 :
f i l t e r 7 :

" p r e t t y " by h e r u s u g i a r t a
" h a r i ␣ beauty " by h a r i a n i
" J u s t ␣Baby " by b l o n d i n o c h k a v i k a
" Shiny ␣Foxy " by s a s h a _ s o u l _ a r t
" Caramel ␣ Macchiato " by s a s h a _ s o u l _ a r t
" Cute ␣ baby ␣ f a c e " by s a s h a _ s o u l _ a r t
" Baby_cute_face_ " by an y a _ _i l i ch e v
" b i g ␣ c i t y ␣ l i f e " by t r i u t r a

The regular expressions for the nomenclature of the ﬁles in B-LFW is available in Listing 6. Note that, aside
from B-LFW, we also share eight diﬀerent versions of the LFW dataset: in each version, all the images
are beautiﬁed with one of our selected ﬁlters. This allows reproducing our experiments, and investigating
in-depth each ﬁlter separately.

Listing 6: Regular expressions for B-LFW ﬁles.

lfw_align_112_png_beauty

^[0 −7]{2}_[0 −7]{2} $
^ [ 0 − 9 ] { 6 } \ . png$

f i l t e r s . npy

Choice of the ﬁlters

Hundreds of “beautiﬁcation” ﬁlters created by Instagram users are available on social media platforms.
Unfortunately, there is no structured repository of all the available ﬁlters and there is no visibility regarding
their popularity. Thus, to select a representative sample of ﬁlters, we had to rely on information provided by
external sources –such as magazine reports or online articles featuring the ﬁlters– and/or on ﬁlters created
by inﬂuential, digital ﬁlter creators on Instagram with thousands of followers. Our goal was to capture
a representative sample of current beautiﬁcation ﬁlters, trying to mitigate the unavoidable sampling bias
related to this choice.

Below, we provide a summary of each ﬁlter and Instagram user who created it (the information was last
updated on the 2nd of August 2022).

• Filter 0 is called pretty and was created by heru sugiarta,16 a digital creator of ﬁlters with 300,000

followers on Instagram.

• Filter 1 is called hari beauty and was created by hariani,17 a digital creator with 10.2 million

followers on Instagram.

• Filter 2 is called Just Baby by blondinochkavika,18 a creator of beauty ﬁlters with 179,000 followers

on Instagram.

• Filter 3 is called Shiny Foxy, Filter 4 is called Caramel Macchiato, Filter 5 is called Cute Baby
Face, all created by sasha_soul_art,19 an Instagram ﬁlter designer of extremely popular ﬁlters on
Instagram, with 1 million followers.

16https://www.instagram.com/herusugiarta/
17https://www.instagram.com/hariany/
18https://www.instagram.com/blondinochkavika/
19https://coveteur.com/sasha-soul-interview

16

• Filter 6 is called Baby cute face, a popular beauty ﬁlter created by anya__ilicheva20 with 13,500

followers on Instagram.

• Filter 7 is called Big city life by triutra,21 a digital ﬁlter creator on Instagram with 138,000

followers.

All the users describe themselves as digital creators or digital ﬁlter creators and have created several Instagram
ﬁlters, including the very popular beauty ﬁlters used in our study.

Note that the eight beauty ﬁlters selected through this approach reﬂect feminine beauty ideals. While it
is impossible to quantitatively assess such a gender bias in the use of the ﬁlters, it is possible to grasp an
intuition about it. To shed light on this topic, we performed search queries with relevant hashtags, such
as beautyfilter and related keywords on Instagram (both among posts and ﬁlters). In a qualitative and
approximated manner, our searches revealed that the majority of users posting beautiﬁed content are women.
We believe that gender biases related to beauty are, to some extent, intrinsic in our society as a whole, and
the popularity of beauty ﬁlters for women is one of its many manifestations.

Intended Use

OpenFilter (section 3) is a ﬂexible open framework to apply AR ﬁlters available in social media platforms
on existing, publicly available large collections of images. We share this framework to provide the research
community and practitioners with easier access to any AR ﬁlter available on social media, and to perform novel
research in this emerging and culturally relevant ﬁeld. We strongly discourage controversial and unethical
uses of our framework and datasets. We acknowledge that, while the development of some applications could
be appealing from a technical and scientiﬁc perspective, the subject matter of this work has a profound
sociological and cultural component, which should not be ignored. As a consequence, we opt for protecting
the general public from any consequence of this research, and thus share our datasets with exclusively a
non-commercial license.

The intended uses of our datasets (FairBeauty and B-LFW) are very wide. Among the possibilities, we
mention investigating the inﬂuence of beauty ﬁlters on social constructs, both computationally and through
user studies. A second direction concerns societal implications of beauty ﬁlters. For example, these ﬁlters
have raised concerns regarding existing biases in the automatic beautiﬁcation practices and have been widely
criticized for perpetuating racism and colorism. FairBeauty, in particular, opens the possibility of studying
such issues computationally. As an insight, in Figure 6, we report exemplary images from FairBeauty,
divided according to the label race in the original FairFace dataset.

Hosting and Maintenance plan

The project is version-trackable on our Github repository22, where it will be permanently available. The
datasets FairBeauty and B-LFW are hosted on Microsoft Azure23, from where they can be downloaded.24
The dataset was created at the ELLIS Unit Alicante, and the authors are committed to maintain the repository
and the dataset storage at least until 2025, providing proper maintenance and development. Piera Riccio is
in charge of supporting, hosting and maintaining the dataset. She can be contacted at her email address
piera@ellisalicante.org.
For the time being, the authors do not foresee periodic updates of the dataset, but it will be corrected in case
any error is detected in the current version. The availability of older versions will be subject to the type of
update that is performed. The authors will make sure that any update is clearly communicated and justiﬁed
to the rest of the community through the oﬃcial GitHub page and the project page25.

20https://www.instagram.com/anya__ilicheva/
21https://www.instagram.com/triutra/
22https://github.com/ellisalicante/OpenFilter
23We have requested oﬃcial identiﬁers on http://identifiers.org/, respectively fairbeauty and blfw. The requests are

currently being processed.

24Download links provided in the README ﬁles of the Github repository.
25https://ellisalicante.org/datasets/OpenFilter

17

Figure 6: Examples of 70 diﬀerent individuals in the FairBeauty dataset, divided by row according to the
value of the label race.

If other researchers are interested in collaborating on this work by extending or augmenting the datasets,
they are warmly encouraged to get in touch with the authors. The authors will evaluate each proposal
for extension before including it in the dataset. Even in this case, the authors will make sure to properly
communicate the updates on both the GitHub and the project’s page.

Licensing and Distribution

The datasets FairBeauty and B-LFW are distributed under the CC BY-NC-SA 4.026 license agreement,
which allows sharing and re-adaptation for non-commercial purposes and redistribution under the same
license.

The code for OpenFilter is shared under a dual license. For non-commercial purposes, the GNU General
Public License, version 2 applies.27 Users interested in using the code for commercial purposes are asked to
contact the authors for an explicit authorization. The authors will evaluate the ethical implications for each
case.

Author Statement

We, the authors, will bear all responsibility in case of violation of rights.

26https://creativecommons.org/licenses/by-nc-sa/4.0/
27https://www.gnu.org/licenses/old-licenses/gpl-2.0.html

18

