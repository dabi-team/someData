Chunyuan Shi, Dapeng Yang, Senior Member, IEEE, Jingdong Zhao, Member, IEEE, Li Jiang 

i-MYO: A Hybrid Prosthetic Hand Control System based on Eye-tracking, 
Augmented Reality and Myoelectric signal* 

Chunyuan Shi, Dapeng Yang, Jingdong Zhao, Li Jiang 

these hands due to the absence of a suitable control system [8]. 
A  reliable  and  intuitive  control  system  to  support  dexterous 
manipulation is needed for advanced prostheses [9]. 

The myoelectric control system (MEC) has always been the 
mainstream  for  prosthetic  hand  control  [8].  In  a  MEC,  weak 
EMG  signals  are  obtained  from  the  patient’s  stump  through 
EMG electrodes and processed to control the prosthesis[9]. The 
classic  proportional  control  method  [9],  [10]  and  the  on/off 
control method were proposed in the 1960s, still being adopted 
for most commercial prosthetics [11]. These two methods are 
simple  and  intuitive  but  have  insufficient  functions,  which 
cannot  support  the  multi-grasp  type  control  of  dexterous 
prosthetics  [12].  Although  the  three-amplitude  state  method 
[13], [14] and the finite state machine method (FSM) [2], [15] 
can increase the controllable degrees of freedom (DOF), they 
are not real-time and have poor intuitiveness and large burden. 
Researchers  have  focused  on  the  EMG  pattern  recognition 
algorithm (PR)[11] to improve the MEC system in the past few 
decades.  PR  assumes  the  existence  of  distinguishable  and 
repeatable patterns among EMG activities[16]. Thus a method 
based on multi-channel signals (> four channels) and classifiers 
(such  as  Support  Vector  Machine  (SVM)[17],  [18],  Linear 
Discriminate Analysis (LDA [19]]), Artificial Neural Networks 
(ANN [20], [21]), etc.) can establish the mapping relationship 
between muscle activity and grasp type. However, this method 
is  slow  in  response,  non-proportional  control  [11],  and  is  not 
robust [9] due to electrode crosstalk [22], forearm motion[23], 
forearm  loading  [24],  and  other  confounding  factors  [25]. 

Abstract—  Dexterous  prosthetic  hands  have  better  grasp 
performance  than  traditional  ones.  However,  patients  still  find  it 
difficult to use these hands without a suitable control system. A new 
hybrid  myoelectric  control  system,  termed  i-MYO,  is  presented  and 
evaluated to solve this problem. The core component of the i-MYO is 
a  novel  grasp-type  switching  interface  based  on  eye-tracking  and 
augmented  reality  (AR),  termed  i-GSI.  With  the i-GSI,  the user  can 
easily switch a grasp type (six total) for a prosthetic hand by gazing at 
a  GazeButton.  The  i-GSI  is  implemented  in  an  AR  helmet  and  is 
integrated, as an individual module, into the i-MYO system. In the i-
MYO system, the myoelectric signal was used to control hand opening 
/closing proportionally. The operation of the i-MYO was tested on nine 
healthy  subjects  who  wore  HIT-V  hand  on  the  forearm  and 
manipulated objects  in  a  reach-and-grasp  task.  It  was  also  tested  on 
one patient who had an inferior myoelectric signal and was required to 
control the HIT-V hand to grasp objects. Results showed that in 91.6% 
of  the  trials,  inexperienced  healthy  subjects  accomplished  the  task 
within 5.9 s, and most failed trials were caused by a lack of experience 
in fine grasping. In addition, in about 1.5% of trials, the subjects also 
successfully transferred the objects but with a non-optimal grasp type. 
In 97.0% of the trials, the subjects spent ~1.3 s switching the optimal 
grasp  types.  A  higher  success  rate  in  grasp  type  (99.1%)  for  the 
untrained patient has been observed thanks to more trials conducted. 
In 98.7 % of trials, the patient only needed another 2 s to control the 
hand to grasp the object after switching to the optimal grasp type. The 
tests  demonstrate  the  control  capability  of  the  new  system  in  multi-
DOF  prosthetics, and all  inexperienced  subjects were able to master 
the operation of the i-MYO quickly within a few pieces of training and 
apply it easily. 

Index  Terms—  Prosthetic  hand,  Hybrid  control  system,  Eye-

tracking, AR 

I.    INTRODUCTION 
Prosthesis refers to a device that can help amputees restore 
hand  function  and  improve  their  quality  of  life[1].  However, 
most  commercial  prosthetic  hands  are  simple  and  unable  to 
meet the  daily  needs of patients  [2]. Many patients  hope that 
these hands can have better grasp performance and that fingers 
can move independently [3]. In research, many multi-fingered 
dexterous  prosthetic  hands  [4]–[6]  meet 
the  functional 
requirements and can reproduce a variety of grasp types [7] to 
deal  with  different  grasp  tasks.  But  most  users  do  not  accept 

*  This  work 

is  partially  supported  by  NSF  Grant  #52075114, 
Interdisciplinary Research Foundation of HIT (IR2021218), and Postdoctoral 
Scientific  Research  Development  Fun 
to  D.Yang. 
Corresponding author: Dapeng Yang (yangdapeng@hit.edu.cn). 

(LBH-W18058) 

The  authors  are  from  the  State  Key  Laboratory  of  Robotics  and  System, 
Harbin Institute of Technology (HIT), Harbin 150080, China. D. Yang and J. 
Zhao  are  also  from  the  Artificial  Intelligence  Laboratory  (HIT),  Harbin 
150001,  China 
jiangli01@hit.edu.cn).   

(e-mail:  Chunyuan_Shi,  yangdapeng,  zhaojingdong,     

Fig.  1.  Schematic  diagram  of  new  system  principle.  i-GSI,  a  grasp-type 
switching  interface  based  on  augmented  reality  and  eye-tracking.  The  new 
system uses i-GSI for switching a grasp type and EMG for controlling hand 
closing\opening. 

©2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including 
reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse 
of any copyrighted component of this work in other works. 

OPEN/CLOSE&AMPLITUDEGRASP TYPEi-GSIEMGProsthesisUser+ 
 
 
 
 
 
 
   
Fig. 2. The i-MYO control system. The first image shows that the subject was pinching a bead using the prosthetic hand attached to his forearm, and the second 
image is the scene the subject saw through the AR helmet, HoloLens 2. 

Moreover, the available channels are limited due to muscle loss 
resulting  from  amputation,  further  reducing  availability  [26]. 
Although targeted muscle reinnervation technology (TMR) can 
alleviate the problem of muscle loss and improve classification 
accuracy [27]–[29], most patients reject it due to the many risks 
associated [26]. On the other hand, algorithms based on Linear 
Regression (LR) [30], Non-Negative Matrix (NMF)  [31], and 
Deep Learning (DL) [32] can regress multi-DOF synchronous 
proportional  control  signals  from  multi-channel  EMGs.  It  is 
also  difficult  to  operate  the  hand  dexterously  because  of  less 
DOF (two to three). 

It is necessary to introduce other sensors to make up for the 
deficiency  of  the  EMG-only  control  system  [8].  The  EMG 
hybrid  control  system  (EMG-HCS)  [26]  has  been  further 
developed in recent years. A hybrid control system refers to a 
system with more than two control signal sources [26], [33]. In 
an EMG-HCS, EMG is still used to control hand opening and 
closing (proportionally control), other signals, such as plantar 
pressure  [34],  [35],  tongue  movement  signal  [36],  and 
radiofrequency  tags  [37],  etc.,  are  used  to  switch  the  hand’s 
grasp type. However, current EMG-HCS implementations still 
have an insufficient performance to switch the grasp type [26]. 
It  is  still  complicated  to  use  and  non-real-time.  Besides, 
combining the features of different signals as the input of the 
PR  algorithm  is  also  a  hybrid  control  method,  but  most  are 
offline analyses[9], [38]. Artificial vision is a newly developed 
method in recent years, and many challenges await being solved 
[26],  [39],  [40],  such  as  clutter  background  and  target  object 
detection.   

The  authors  have  recently  proposed  a  new  grasp-type 
switching interface (i-GSI) based on augmented reality and eye-
tracking to solve the grasp-type problem [41]. With the i-GSI, 
users can easily switch between six grasp types by gazing at a 
holographic grasp-type icon, and even a novice can master the 
i-GSI very quickly. 

This paper proposes a novel hybrid prosthetic hand control 

system based on i-GSI and myoelectric signal (i-MYO) (shown 
in  Figure  1),  demonstrating  how  the  i-GSI  as  a  standalone 
module  can  be  integrated  into  a  myoelectric  dexterous 
prosthetic  hand  [6].  The  i-MYO  can  be  implemented  on 
commercial mobile devices. The goal of the current study was 
to  test  the  operation  performance  of  i-MYO.  A  total  of  nine 
the  reach-grasp 
healthy  novice  subjects  participated 
experiment, of which the results refer to the efficacy of grasping 
the objects. Further, the i-MYO was tested in one patient with 
a  congenital  upper  limb  deficiency.  The  result  of  the  patient 
proves that even a subject with an extremely poor EMG signal 
can operate the i-MYO well.   

in 

II.    MATERIALS AND METHODS   

A. i-MYO Contol System 

The i-MYO control system includes a grasp-type switching 
interface (i-GSI), a two-site myoelectric interface (MYO), and 
a multi-DOF prosthetic hand, as shown in Figure 2. For a target 
object, the user can use the i-GSI to select an optimal grasp type 
and then use the MYO to control the prosthetic hand to grasp or 
release the object in a proportional way.   

1） i-GSI: the i-GSI is responsible for switching grasp types 
and mainly includes a hologram panel with nine GazeButtons. 
The  GazeButton  refers  to  a  button  with  advanced  gaze-based 
interactions [42]. The hologram panel is directly superimposed 
in the user’s vision, and the GazeButton can be triggered when 
the user gazes at it. This gaze behavior means that the human 
observes  a  position  for  more  than  120  ms,  and  the  threshold 
parameter of gaze time in this study is set at 200 ms for stable 
control.  Of  the  nine  buttons,  six  are  grasp  types:  Cylindrical, 
Spherical, Tripod, Pinch, Lateral, and Hook; these are the basic 
grasp  types  for  manipulating  daily  life  objects  [43]  and  are 
usually  used  as  indicators  for  designing  dexterous  prosthetic 
hands.  A  grasp-type index  will be sent to the  prosthetic  hand 
through Bluetooth  when the relative  GazeButton is  triggered. 

6-DOF ProsthesisProsthetic handMotion ParamTableEMG InterfaceThresholdingGRASP TYPE  INDEX (Bluetooth)Motion Planning PARAMPOSITONFINGERS SPEEDPATTERN & AMPLITUDE HoloLens 2i-GSI  
 
 
the maximum speed scale factor, was set and mapped linearly 
proportional to the EMG amplitude. 

A personal host was used to adjust system parameters (i.e., 
EMG threshold, gaze time threshold) for different users during 
the experiment, which is unnecessary for clinical applications.   

B. Operation Flow of the i-MYO System   

The operation of the i-MYO system is effortless (shown in 
Figure  3).  Firstly,  the  user  gazes  at  the  target  GazeButton  to 
switch the grasp type when the fingers are spread out. Secondly, 
the user approaches the prosthetic hand to the object and elicits 
an EMG signal (flexing the wrist) to control the prosthetic hand 
from a full-open position to a pre-shape position. Then, the user 
controls the hand to continue to close and grasp the object by 
observing the scene. After transporting the object successfully 
to  another  position,  the  user  elicits  another  EMG  signal 
(stretching the wrist) to open the prosthetic hand to release the 
object. 

III.    EXPERIMENTS 

A. Subjects & Sensor Calibration 

One patient and nine healthy subjects were recruited to test 
the operation of the i-MYO system. Two healthy subjects had a 
few experiences with EMG control, and others had none (see 
more  in  TABLE  I).  Evaluating  the  i-MYO  system  from  the 
patient with an extremely poor EMG signal can better show the 
system's applicability to patients. The patient has a congenital 
upper limb deficiency,  and the stump is less than one-fifth of 
the forearm. Due to the lack of exercise, the arm was as thin as 
that of a child,  with little strength. He did not have the right-
hand muscle  memory  such as flexing/extending the wrist and 
did not have phantom limb sensation[44]. Therefore, his EMG 
signal was far inferior to those acquired from the patients with 
radial amputation. The EMG electrodes were placed over two 
muscles  he  could  independently  activate  repeatedly,  and  the 
muscles were near the end of the elbow. 

Subject 

Gender  Age 

For different users, the magnifications and thresholds of the 
EMG  electrodes  were  adjusted  respectively  to  obtain  a  good 
signal-to-noise ratio. Subjects calibrated the eye tracker using 
an  APP  of  the  HoloLens  2  system.  The  position  of  the 
holographic panel was fine-tuned to make the user comfortable, 
TABLE I 
SUBJECT INFORMATION 
Height 
(CM) 
170 
173 
162 
170 
178 
170 
170 
170 
175 
178 

Prosthetic control 
experience 
59  20.42  ☆☆☆☆☆ 
63  21.05  ☆☆☆☆☆ 
49  18.67  ☆☆☆☆☆ 
76  26.30  ☆☆☆☆☆ 
78  24.62  ☆☆☆☆☆ 
61  21.11  ★★☆☆☆ 
75  25.95  ★☆☆☆☆ 
66  22.84  ☆☆☆☆☆ 
73  23.84  ☆☆☆☆☆ 
62  19.57  ☆☆☆☆☆ 

Handed- 
ness 
R 
R 
R 
R 
R 
R 
R 
R 
R 
L 

Male 
Male 
Female 
Male 
Male 
Male 
Male 
Male 
Male 
Male 

1 
2 
3 
4 
5 
6 
8 
7 
9 
10* 

24 
24 
28 
26 
24 
29 
28 
31 
27 
26 

Weight 
(KG) 

BMI 

* Amputee   
All experiments were approved by the university's Ethical Committee 
(NO.HIT-2021009) and conformed to the Declaration of Helsinki.   

(a) Flow diagram. 

(b) Actual scene. 

Fig. 3. The operation flow of the i-MYO system. The user was switching the 
garget grasp type in the first two images. The hand in image  ③  was at the 
pre-shape position, the one in image  ⑥  was at the target-grasp position, and 
the image  ⑧  shows that the hand released the object. 

The other three buttons are reserved for other functions, such as 
wrist control, and will not be discussed in this paper. The i-GSI 
is  implemented  in  an  untethered  self-contained  holographic 
device  (Holoens2,  Microsoft,  USA)  with  an  eye  tracker.  Our 
previous  work  provides  more  detailed  information  about  the 
hologram panel and the gaze algorithm[41].   

2） Myoelectric Interface  (MYO): MYO  is  used to  get the 
user’s  intention  to  proportionally  control  the  prosthetic  hand 
opening\closing from a  two-site  myoelectric  signal. The  two-
site  signal  was  recorded  using  two  OttoBock  dry  electrodes 
(Otto Bock, Germany, 13E200 = 50) over a pair of antagonist 
muscles (flexor and extensor). The two-site EMG inputs have a 
sufficient  signal  ratio  thanks  to  the  electrode’s  preprocessing 
and  were  directly  thresholded  with  individually  adjustable 
levels  to  generate  opening/closing  control  commands.  The 
amplitude  of  the  signal  is  mapped  to  the  scale  factor  of  the 
maximum  finger  speed  (90°/s).  The  MYO’s  algorithm  was 
implemented  on  a  controller  connected  with  the  two-site 
electrodes,  and  the  controller  was  housed  inside  a  prosthetic 
palm.   

3） Prosthetic  hand:  The  prosthetic  hand  is  used  to 
manipulate  daily  life  objects  and  emulated  by  a  robot  hand, 
HIT-V  [6],  attached  to  the  subject’s  forearm  by  a  3D-printed 
bypass. The HIT-V has five anthropomorphic fingers actuated 
by six DC motors: five motors for finger flexion/extension and 
one  for  thumb  adduction/abduction.  All  degrees  of  freedom 
contain  position  sensors,  thus  realizing  position  control.  A 
mapping table with motion parameters of six grasp types was 
saved  offline  in  the  controller  housed  inside  the  palm.  These 
parameters,  such  as  the  pre-shape  position  of  fingers,  were 
obtained  by  trial  and  test.  Another  parameter,  the  grasp-type 
index, is obtained from the i-GSI via Bluetooth. The index was 
used to configure the hand by the look-up table and could only 
change when the hand was between the full-open and pre-shape 
positions (as detailed in Section II.B). Yet another parameter, 

StartPre-shapepositionCloseFull-openpositionTarget-grasp positionFClose FINDEXEOpen Open EGAZESwitching grasp type EFExtensionFlexion1 s0 s2.2 s132465786.4 s6.8 s7.6 s10121192.4 s3.0 s3.8 s5.0 s6.2 s5.6 s 
 
 
 
 
 
IMG 

No. 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
20 
21 

Grasp Type 

Cylindrical 

Spherical 

Tripod 

Pinch 

Lateral 

Hook* 

Size（cm） 

15 × Φ6.3 
18 × Φ5.2 
17.8 × Φ5.8 
13.5 × Φ6 
SΦ6.3 
SΦ6.3 
SΦ6.3 
SΦ6.3 
5.9 × 2.8 × 1.4 
3.7 × 3.2 × 2 

TABLE II 
TARGET OBJECTS   
Object 
Powder bottle   
Plastic bottle 1 
Plastic bottle 2 
Sauce bottle 
Toy ball 1 
Toy ball 2 
Toy ball 3 
Toy ball 4 
Toy brick   
Plug 
Medicine pack box  5.5 × 3.3 × 3.3 
Small Yarn Ball   
Small wooden cube  1.8 × 1.8 ×1.8 
2.8 × 1.7 × 0.9 
Mini eraser 
5 × 3 × 1.9 
Mini padlock 
SΦ1.5 
Bead 
13 × 11 × 0.05 
Transdermal patch 
8.5 × 5.3 × 0.1 
Plastic card 
10 × 4.7 × 0.1 
Tea bag 
16 × 4 × 0.2 
Ruler 
9.5 × 12.5 Φ3 
Plastic handle 

SΦ4.4 

* Printed 3D model, shaped like a doorknob, will appear four times in each 
block test.   

Metrics 

TABLE III 
METRICS WITH DEFINITION 
Definition 

Schematic diagram   

SR-G 

Grasp-type success rate 

T-G 

The time spent switching correct grasp type. 

SR-HT  The task success rate for the healthy subjects. 

The time a healthy subject spends on one trial. 

T-HT 
SR-PT  The task success rate for the patient. 

T-PT 

The time patient spends on one trial. 

manipulate. Once finished a block of twenty-four trials, the user 
rested for five minutes to prevent forearm muscle fatigue. 

3) Metrics: Six metrics listed in TABLE III were defined and 
used  to  evaluate  the  performance  of  the  i-MYO  system.  1) 
Grasp-type success rate (SR-G, for all subjects): the grasp type 
was  deemed  correct  if  the  final  grasp  type  used  to  grasp  the 
object was optimal according to classification in TABLE III. 2) 
Time  spent  switching  the  correct  grasp  type  (T-G,  for  all 
subjects).  3)  Task  success  rate  for  the  healthy  subjects  (SR-
HT):  a  trial  was  considered  successful  if  the  healthy  subject 
used the correct grasp type to accomplish the task in which the 
subject  was  required  to  pick  the  object  up  and  place  it  at  the 
target area. Otherwise, the trial would be considered a failure 
once  an  incorrect  grasp  type  was  used,  even  if  the  subject 
accomplished the task (e.g.,  using  Pinch to  transfer  an object 
that  Tripod  should  have  transferred).  4)  The  time  a  healthy 
subject spends on one trial (T-HT). 5) The task success rate for 
the  patient  (SR-PT):  a  trial  was  considered  successful  if  the 
patient elicits an EMG signal to control the robot hand grasping 
the objects with the correct grasp type. 6) The time the patient 
spends on one trial (T-PT). The time criteria for T-G, T-HT, and 
T-PT are illustrated in TABLE III. 

Fig. 4. Experimental setup for healthy subjects. With the robot hand attached to 
his  right  forearm  by  a  bypass,  the  subject  sits  on  the  chair  comfortably  and 
wears the AR helmet on his head. The two EMG electrodes are also put over 
the right forearm. He needs to manipulate the robot hand to transfer the object 
in front of him to the target area at his right. 

and the threshold parameter of the gaze (as described in Section 
II.A) was fine-tuned to adapt to user habits. The prosthetic hand 
was attached to healthy subjects’ right forearms by a 3D-printed 
bypass. 

B. Experimental Protocols & Data Analysis 

1) Test Task: The healthy subjects were required to complete 
a reach-and-grasp task to test the operation of the i-MYO. This 
task aims to test if the i-MYO can help the user restore typical 
daily activities. As shown in Figure 4, the subject in this task 
needed to manipulate the robot hand attached to his forearm to 
reach, pick up, transport, and place the target object in the target 
area on the table. As for the patient, his right arm is too thin and 
powerless to wear the robot hand (> 600 g); thus, the robot hand 
was  fixed  on  the  fixture.  He  was  required  to  switch  a  target 
grasp type and trigger the EMG signal to control the hand to 
hold the object. This task for the patient aimed to test if a subject 
with  extremely  poor  EMG  could  also  activate  a  myoelectric 
signal  to  control  the  prosthetic  hand  to  grasp  and  release 
different objects. 

Twenty-one  household  objects  listed  in  Table  II  were 
selected  as  the  target  objects,  including  one  sample  for  Hook 
and  four  samples  for  every  other  grasp  type.  Each  healthy 
subject  needed  to  carry  out  eight  blocks  of  24  trials,  and  the 
patient  needed  twenty  blocks  to  gather  sufficient  data  for 
statistical  analysis.  The  object  for  Hook  would  appear  four 
times  in  a  block.  The  objects  for  Pinch  were  small  (i.e.,  the 
bead, SΦ1.5 cm) and would be a challenge for the subjects. 

2)  Experiment  Procedures:  Before  experimenting  on  each 
subject, the assistant calibrated the sensors and introduced the 
task to the subject. The subject would take less than ten minutes 
to practice this system. During practice, the user would try to 
manipulate  the  hand  to  grasp  the  bead  or  mini  padlock  five 
times to learn how to use Pinch. After practice, the user had a 
ten-minute break before the test. During the test, the assistant 
randomly  placed  an  object  of  which  the  grasp  type  was  non-
the  object 
repeating 
simultaneously 
trigger  a  GazeButton 
subconsciously.  After  being  instructed,  the  user  started  to 

trial.  The  user  observed 

so  as  not 

in  each 

to 

HoloLens 22-Ch EMGBypassRobot handTarget objectTarget areaT-GT-PTT-HT 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
       
 
 
)

%

(
E
T
A
R
S
S
E
C
C
U
S

100

80

60

40

20

0

97.5±1.2 

91.6±3.1 

SR-G 

SR-HT 

11
10
9
8
7
6
5
4
3
2
1
0

)
s
(
E
M
I
T

5.8

1.3

T-G

T-HT

(a) Task results of healthy subjects. 

(b) Time results of healthy subjects 

99.2% ± 2.2

98.7 ± 3.1 

100

)

%

(
E
T
A
R
S
S
E
C
C
U
S

80

60

40

20

0

SR-G 

SR-PT 
(c) Task result of patient 

)
s
(
E
M
I
T

6

5

4

3

2

1

0

3.2

1.3

T-G

T-PT

(d) Time result of patient 

Fig. 5. The overall results of the healthy subjects and the patient. 

4) Data Analysis Methods: this study used the box plots with 
median,  inter-quartile  range,  and  extremum  to  represent  the 
time data collected in this paper since it did not fit a normal   
distribution 
test).  A 
the 
Wilcoxon  signed-rank 
significance  of  the  paired  data  between  two  groups,  and  a 
Friedman test and the Bonferroni adjustment  were used when 
the paired data was from more than two groups. 

(Kolmogorov–Smirnov  normality 

test  was  used 

to  determine 

IV.    RESULTS & ANALYSIS 

Nine  healthy  subjects  finished  a  total  of  1728  trials  (nine 
subjects,  eight  24-trial  blocks),  and  the  patient  finished  480 
trials  (one  subject,  20  24-trial  blocks).  Overall,  the  healthy 
subjects with no prior training successfully transferred objects 
in 91.6% of the cases and switched the optimal grasp types in 
97.5%, as shown in Figure 5(a). It means that only one-third of 
failures were attributed to i-GSI. Furthermore, in about 1.5% of 
cases, the subjects successfully transferred the objects but with 
a  non-optimal  grasp  type  one  that  the  subject  considered 
optimal (e.g., using Tripod to grasp objects that Pinch should 
have  grasped),  mainly  in  early  trials.  These  subjects  spent 
about 5.8 s transferring an object and about 1.3 s switching the 
grasp type, as shown in Figure 5(b). Figure 5(c) showed that the 
patient could successfully trigger the EMG to control the hand 
holding the objects in 98.7% of trials in around 3.2 s and spend 
around 1.3 s to switch the optimal grasp types in 99.2% of trials.   
The  analysis  of  different  blocks  showed  that  the  healthy 
subjects  with  no  prior  training  could  quickly  master  the 
operation of the i-MYO system, and the operation of i-GSI was   
natural and stable. Most unsuccessful tasks happened in the first 
three blocks, especially the first block, with only 85% of cases 
successful, as shown in Figure 6(a). But the figure also clearly 
showed a significant improvement from the first to the fifth   

* 
*** 

T-G  T-HT 
*** 
* 
*** 
*** 
* 

100

)

%

(
E
T
A
R

S
S
E
C
C
U
S

95

90

85

80

75

70

65

60

SR-G  SR-HT 

14

12

10

)
s
(
E
M
I
T

8

6

4

2

0

1 2 3 4 5 6 7 8
BLOCKS 

(a) Success rate results 

1 2 3 4 5 6 7 8
BLOCKS 
(b) Time results 

Fig. 6. The result from different blocks of the healthy subjects. p* < 0.5, p** < 
0.01, p*** < 0.001. 

SR-G SR-HT

SR-G SR-HT

)

%

(
E
T
A
R
S
E
E
C
U
S

100

80

60

40

20

0

(a) Task result of grasp types

Toy brick

Small Yarn Ball

Plug

Medicine pack box

Toy ball 4

Toy ball 3

Toy ball 2

Toy ball 1

Small wooden cube

Mini padlock

Mini eraser

bead

12

10

)
s
(
E
M
I
T

8

6

4

2

0

T-G

T-HT

Transdermal patch

Tea bag

Ruler

Plastic card

Plastic handle

Sauce bottle

Powder bottle

Plastic bottle 2

Plastic bottle 1

(b) Time results of grasp types

(c) Success rate results of objects

Fig. 7. Results of different grasp types or objects 

0%

50%

100%

SUCCESS RATE

block  (85%  to  95%),  and  Figure  6(b)  showed  the  time  spent 
reduced from 7.6 s to 5.0 s. In addition, no significant difference 
was observed in the fifth to eighth block. The switch success 
rate is 95% in the first block and is increased to 99% in the third 
block.The time spent switching the grasp type decreased from 
1.7  s  in  the  first  block  to  1.2  s  in  the  eighth  block,  and  no 
significant difference was observed from the fourth block to the 
eighth block.   

The grasping success rate according to different grasp types 
is shown in Figure 7. Figure 7(a) shows that objects grasped by 
Pinch  (80%  success  rate)  were  the  most  difficult  to  transfer 
since these objects are too small to be precisely  grasped (i.e., 
the  bead:  SΦ1.5  cm3,  mini  padlock:  5.0  ×  0.3× 1.9  cm).  The 
robot  hand  fingers  often  closed  on  empty  air  in  the  first  few 
blocks since the subjects failed to predict thecontact position of   

 
 
   
   
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
100

)

%

(
E
T
A
R
S
S
E
C
C
U
S

80

60

40

20

0

1

2

T-G
T-HT

14

12

10

)
s
(
E
M
I
T

8

6

4

2

0

)

%

(
E
T
A
R
S
S
E
C
C
U
S

100
95
90
85
80
75
70
65
60

1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20

BLOCKS
(a) Success rate results from different blocks 

SR-G

SR-PT

5

4

6
3
SUBJECTS

7

8

9

1

(a) Success rate results 

Fig. 8 Results of different healthy subjects 

2

7

3

4

5
6
SUBJECTS
(b) Time results   

8

9

)
s
(
E
M
I
T

the  index  and  thumb  fingers.  The  objects  grasped  by  the 
Cylindrical, Spherical, and Tripod were easier to transfer, with 
a  95%-plus  success  rate.  All  healthy  subjects  thought  it  was 
challenging  to  grasp  and  transfer  the  bead,  and  only  66%  of 
cases were successful, as shown in Figure 7(c). To grasp a bead 
stably  requires  good  balance  in  the  control  of  position  and 
strength  to  prevent  the  bead  from  being  squeezed  out  or 
dropped. The transdermal patch was the easiest to transfer, with 
a  98%-plus  success  rate.  The  analysis  of  the  time  showed 
(shown in Figure 7(b)) that the objects grasped by the Lateral 
needed the most time (around 6.2 s) to transfer as the Lateral 
needed  more  time  to  pre-shape  and  grasp,  and  there  were  no 
statistical differences on other grasp types, about 5.5 to 5.8 s. 
The test for T-G on different grasp types found no significant 
differences (p = 0.7). 

Significant  differences  in  the  healthy  subjects  remained  in 
the time spent transferring since everyone's ability to operate a 
new system is different. As shown in Figure 8, the sixth subject 
had  the  highest  success  rate  in  transferring  an  object,  around 
95%, and also spent the least time, about 4.7 s. The first subject 
had the lowest success rate, around 88%. The seventh subject 
spent the most time completing the transfer task, around 8.8 s, 
and also spent the most time switching the grasp type. 

The result of the patient with the longer test (twenty blocks) 
showed a significant improvement in performance throughout 
the test. Figure 9(a) shows that he accomplished the task in only 
87% of trials in the first block and 96% in the second block, but 
this  number  remained  at  100%  after  the  eleventh  block.  The 
time spent to accomplish tasks, shown in Figure 9(b), decreased 
significantly as the number of trials increased, and it just needed 
about 1.1 s to switch the target and around  2.8 s to grasp the 
object in the last five blocks. 

V.    DISCUSSIONS 

A new hybrid prosthetic control system (i-MYO) is proposed 
in  the  paper.  With  the  help  of  the  i-MYO  system,  users  can 
quickly, easily, stably, and robustly control the prosthetic hand 
to manipulate daily life objects using a variety of grasp types. 
The new grasp-type switcher can switch quicker among a larger 
quantity  of  grasp  types  than  traditional  methods,  such  as  Co-
Contraction  and  coded  switching  methods  [2].  The  users  are 

BLOCKS 

T-G  T-PT 

Fig. 9. Results from different blocks of the patient.   

(b) Time results of different blocks 

also  more  relaxed  and  less  fatigued  since  they  only  need  to 
glance  at  a  GazeButton  on  the  grasp-type  panel  to  switch  a 
grasp  type.  In  the  past,  the  user  was  usually  required  to 
repeatedly contract the forearm muscles, which was tedious and 
tiring. The result of the i-MYO system was very stable because 
the i-MYO system provides intuitive real-time feedback of the 
grasp-type results to allow the users to make corrections in time. 
The method is not affected by various confounding factors like 
EMG (e.g., electrode deviation, sweating, tension, temperature 
changes, muscle fatigue). 

According  to  the  modular  design  idea,  the  grasp-type 
interface  (i-GSI)  of  the  i-MYO  system  is  designed  as  a 
completely 
independent  module.  The  module  can  run 
independently  on  a  mobile  headset  device  (e.g.,  HoloLens  2) 
since its computational burden is small. The module does not 
need  to  receive  signals  from  other  devices.  The  grasp-type 
result  in  this  module  can  be  transmitted  to  the  existing 
prosthetic system through wireless communication (e.g., WIFI 
and  Bluetooth).  Most  commercial  dexterous  prosthetic  hands 
are  manufactured  with  built-in  wireless  communication  to 
receive  a  grasp  type  from  a  mobile  phone  APP.  The  new 
switching interface can be easily added to its program frame to 
replace  the  mobile  APP  (e.g.,  an  i-Limb  prosthetic  hand  and 
communicate with Bluetooth [45]).   

It is found that  during the operation of the i-MYO system, 
switching a grasp type and manipulating the hand is not strictly 
controlled in sequence, and it may be a parallel mechanism. For 
example, the subject will observe the scene first after switching 
the  grasp type in most cases  and then manipulate the hand to 
reach an object and trigger the EMG at the same time to pre-
shape the hand when ensuring the safety of the prosthetic hand 
operation.  However,  after  many  trials  and  proficiency,  some 
subjects  boldly  raised  and  pre-shaped  the  robot  hand  first 
instead of observing the scene when the sight was still on the 
grasp-type panel (the target GazeButton had been triggered).   

0123456781234567891011121314151617181920 
 
 
 
 
 
 
 
 
 
 
 
Although  the  i-GSI  has  achieved  good  results  in  the 
experiment, failed trials still exist. For example, when the robot 
hand  reaches  the  object's  vicinity,  the  grasp  type  will 
occasionally be mistakenly switched to another grasp type. The 
main reason is that the HoloLens 2 has a limited holographic 
field of view (in the vertical direction), and the grasp-type panel 
cannot be completely out from the common sight area. In this 
way, an error may happen when the grasp-type panel overlaps 
with the supervision area  where  the  user supervises the robot 
hand. However, devices with a wider field of view and even an 
infinite  field  of  view  are  rapidly  developing  (e.g.,  HoloLens 
3[46]), which may solve this problem. 

Furthermore,  with 

the  development  of  mechatronics 
technology,  there  have  been  dexterous  prosthetic  hands 
equipped  with  active  wrists  (e.g.,  i-Limb®  Quantum[45]), 
which poses a higher challenge to the traditional man-machine 
interface. Although this study only evaluated the performance 
of the i-MYO  system in controlling the  fingers, the  proposed 
system is also applicable to control an active wrist with multiple 
degrees  of  freedom,  such  as  pronation/supination  and 
flexion/extension.  A  two-DOF  wrist  has  been  integrated  into 
our  prosthetic  hand,  and  some  simple  tests  have  been 
conducted.  In  the  future,  we  will  carry  out  wrist-hand 
combination paradigm experiments to evaluate the performance 
of  the  new  method  in  higher-level  prosthetics  and  more 
complex tasks.   

VI.    CONCLUSIONS 

A new  hybrid prosthetic control system (i-MYO) based on 
eye-tracking,  augmented  reality  feedback,  and  EMG 
is 
proposed  in  this  study.  Nine  healthy  subjects  and  one  patient 
tested  the  operation  of  the  i-MYO.  Our  results  show  that  a 
novice  can  quickly  master  the  operation  of  the  new  control 
system after a few trials. With the new control system, the user 
can  easily  switch  between  six  grasp  types  by  glancing  at  a 
GazeButton  and  intuitively  control  the  prosthetic  hand  to 
transfer  the  daily  life  objects  together  with  a  simple  EMG 
interface. Our endeavor on  a primary clinical trial also shows 
that  the  new  method  can  also  be  adapted  to  a  patient  with 
extremely  poor  EMG.  The  new  method  largely  lessens  the 
difficulty  for  users  to  control  a  dexterous  prosthetic  hand 
comfortably. 

VII.    ACKNOWLEDGMENTS 

Special recognition to all volunteers who participated in the 

experiment of this article. 

REFERENCES 

[1]  “Powered  Upper  Limb  Prostheses,  Control,  Implementation  and  Clinical 

Application,” 2004, doi: 10.1007/978-3-642-18812-1. 

[2] S. A. Dalley, H. A. Varol, and M. Goldfarb, “A Method for the Control of 
Multigrasp Myoelectric Prosthetic Hands,” Ieee T Neur Sys Reh, vol. 20, 
no. 1, pp. 58–67, 2012, doi: 10.1109/tnsre.2011.2175488. 

[3] C. H. Jang et al., “A Survey on Activities of Daily Living and Occupations 
of Upper Extremity Amputees,” Ann Rehabilitation Medicine, vol. 35, no. 
6, pp. 907–921, 2011, doi: 10.5535/arm.2011.35.6.907. 

[4]  M.  Cheng,  S.  Fan,  and  L.  Jiang,  “Design  of  a  Highly  Compliant 
Underactuated Prosthetic Hand,” 2019 Ieee Int Conf Robotics Biomimetics 

Robio, 
pp. 
10.1109/robio49542.2019.8961650. 

vol. 

00, 

2833–2838, 

2019, 

doi: 

[5]  L.  Jiang,  B.  Zeng,  S.  Fan,  K.  Sun,  T.  Zhang,  and  H.  Liu,  “A  modular 
multisensory prosthetic hand,” 2014 Ieee Int Conf Information Automation 
Icia, no. July, pp. 648–653, 2014, doi: 10.1109/icinfa.2014.6932734. 
[6] W. Ryu, Y. Choi, Y. J. Choi, Y. G. Lee, and S. Lee, “Development of an 
Anthropomorphic Prosthetic Hand with Underactuated Mechanism,” Appl 
Sci, vol. 10, no. 12, p. 4384, 2020, doi: 10.3390/app10124384. 

[7]  T.  Feix,  R.  Pawlik,  H.-B.  Schmiedmayer,  J.  Romero,  and ́  D.  K.,  “A 

comprehensive grasp taxonomy”, 2009. 

[8] N. Jiang, S. Dosen, K. R. Muller, and D. Farina, “Myoelectric control of 
artificial limbsis there a need to change focus?,” Ieee Signal Proc Mag, vol. 
29, no. 5, pp. 148–152, 2012, doi: 10.1109/msp.2012.2203480. 

[9]  Y.  Fang,  N.  Hettiarachchi,  D.  Zhou,  and  H.  Liu,  “Multi-Modal  Sensing 
Techniques for Interfacing Hand Prostheses: A Review,” Ieee Sens J, vol. 
15, no. 11, pp. 6065–6076, 2015, doi: 10.1109/jsen.2015.2450211. 

[10]  A.  Fougner,  O.  Stavdahl,  P.  J. Kyberd,  Y.  G.  Losier,  and  P.  A.  Parker, 
“Control  of  upper  limb  prostheses:  Terminology  and  proportional 
myoelectric controla review,” Ieee T Neur Sys Reh, vol. 20, no. 5, pp. 663–
677, 2012, doi: 10.1109/tnsre.2012.2196711. 

[11] N. V. Iqbal, K. Subramaniam, and S.  A. P., “A Review on Upper-Limb 
Myoelectric Prosthetic Control,” Iete J Res, vol. 64, no. 6, pp. 1–13, 2017, 
doi: 10.1080/03772063.2017.1381047. 

[12] M. A. Oskoei and H. Hu, “Myoelectric control systems-A survey,” Biomed 
Signal  Proces,  vol.  2,  no.  4,  pp.  275–294,  2007,  doi: 
10.1016/j.bspc.2007.07.009. 

[13] D. S. Dorcas and R. N. Scott, “A three-state myo-electric control,” Medical 
Biological Eng, vol. 4, no. 4, pp. 367–370, 1966, doi: 10.1007/bf02476154. 
[14]  Childress  and  D.  A.,  “A  myoelectric  three-state  controller  using  rate 

sensitivity,” Proc. 8th ICMBE, 1969. 

[15]  J.  C.  Baits,  R.  W.  Todd,  and  J.  M.  Nightingale,  “The  Feasibility  of  an 
Adaptive  Control  Scheme  for  Artificial  Prehension,”  Archive  Proc 
Institution  Mech  Eng  Conf  Proc  1964-1970  Vols  178-184  Titles  Label 
Volumes 
doi: 
10.1243/pime_conf_1968_183_178_02. 

54–59, 

1968, 

310, 

183, 

vol. 

pp. 

no. 

S, 

[16] T. W. Wright, A. D. Hagen, and M. B. Wood, “Prosthetic usage in major 
upper extremity amputations,” J Hand Surg, vol. 20, no. 4, pp. 619–622, 
1995, doi: 10.1016/s0363-5023(05)80278-3. 

[17] C. Castellini, E. Gruppioni, A. Davalli, and G. Sandini, “Fine detection of 
grasp  force  and  posture  by  amputees  via  surface  electromyography,”  J 
Physiology-paris,  vol.  103,  no.  3–5,  pp.  255–262,  2009,  doi: 
10.1016/j.jphysparis.2009.08.008. 

[18] N. M. Kakoty and S. M. Hazarika, “Recognition of Grasp Types through 
Principal Components of DWT based EMG Features,” 2011 Ieee Int Conf 
Rehabilitation 
doi: 
10.1109/icorr.2011.5975398. 

Robotics, 

2011, 

1–6, 

vol. 

pp. 

1, 

[19]  G.  Huang,  Z.  Zhang,  D.  Zhang,  and  X.  Zhu,  “Spatio-spectral  filters  for 
low-density  surface  electromyographic  signal  classification,”  Med  Biol 
Eng Comput, vol. 51, no. 5, pp. 547–555, 2013, doi: 10.1007/s11517-012-
1024-3. 

[20] F. C. P. Sebelius, B. N. Rosén, and G. N. Lundborg, “Refined Myoelectric 
Control in Below-Elbow Amputees Using Artificial Neural Networks and 
a  Data  Glove,”  J  Hand  Surg,  vol.  30,  no.  4,  pp.  780–789,  2005,  doi: 
10.1016/j.jhsa.2005.01.002. 

[21] U. Baspinar, H. S. Varol, and V. Y. Senyurek, “Performance Comparison 
of Artificial Neural Network and Gaussian Mixture Model in Classifying 
Hand Motions by Using sEMG Signals,” Biocybern Biomed Eng, vol. 33, 
no. 1, pp. 33–45, 2013, doi: 10.1016/s0208-5216(13)70054-8. 

[22]  A.  Fougner,  E.  Scheme,  A.  D.  C.  Chan,  K.  Englehart,  and  Stavdahl, 
“Resolving the Limb Position Effect in Myoelectric Pattern Recognition,” 
Ieee  T  Neur  Sys  Reh,  vol.  19,  no.  6,  pp.  644–651,  2011,  doi: 
10.1109/tnsre.2011.2163529. 

[23]  C.  Cipriani  et  al.,  “Online  Myoelectric  Control  of  a  Dexterous  Hand 
Prosthesis by Transradial Amputees,” Ieee T Neur Sys Reh, vol. 19, no. 3, 
pp. 260–270, 2011, doi: 10.1109/tnsre.2011.2108667. 

[24]  E.  Scheme,  A.  Fougner,  Stavdahl,  A.  D.  C.  Chan,  and  K.  Englehart, 
“Examining  the  adverse  effects  of  limb  position  on  pattern  recognition 
based myoelectric control,” 2010 Annu Int Conf Ieee Eng Medicine Biology, 
vol. 2010, pp. 6337–6340, 2010, doi: 10.1109/iembs.2010.5627638. 
[25] C. Cipriani, R. Sassu, M. Controzzi, and M. C. Carrozza, “Influence of the 
weight  actions  of  the  hand  prosthesis  on  the  performance  of  pattern 
recognition based myoelectric control: Preliminary study,” 2011 Annu Int 

 
Conf 
10.1109/iembs.2011.6090468. 

Eng  Medicine 

Ieee 

Biology 

Soc, 

2011, 

doi: 

[26] D. G. K. Madusanka, L. N. S. Wijayasingha, R. A. R. C. Gopura, Y. W. R. 
Amarasinghe, and G. K. I. Mann, “A review on hybrid myoelectric control 
systems for upper limb prosthesis,” 2015 Moratuwa Eng Res Conf Mercon, 
pp. 136–141, 2015, doi: 10.1109/mercon.2015.7112334. 

[27]  T.  A.  Kuiken  et  al.,  “Targeted  Muscle  Reinnervation  for  Real-time 
Myoelectric Control of Multifunction Artificial Arms,” Jama, vol. 301, no. 
6, pp. 619–628, 2009, doi: 10.1001/jama.2009.116. 

[28] T. A. Kuiken et al., “Targeted reinnervation for enhanced prosthetic arm 
function in a woman with a proximal amputation: a case study,”  Lancet, 
vol.  369,  no.  9559,  pp.  371–380,  2007,  doi:  10.1016/s0140-
6736(07)60193-7. 

[29] L. A. Miller et al., “Control of a Six Degree of Freedom Prosthetic Arm 
After Targeted Muscle Reinnervation Surgery,” Arch Phys Med Rehab, vol. 
89, no. 11, pp. 2057–2065, 2008, doi: 10.1016/j.apmr.2008.05.016. 
[30] J. M. Hahne, M. A. Schweisfurth, M. Koppe, and D. Farina, “Simultaneous 
control of multiple functions of bionic hand prostheses: Performance and 
robustness  in  end  users,”  Sci  Robotics,  vol.  3,  no.  19,  pp.  eaat3630–
eaat3630, 2018, doi: 10.1126/scirobotics.aat3630. 

[31] N. Jiang, K. B. Englehart, and P. A. Parker, “Extracting Simultaneous and 
Proportional  Neural  Control  Information  for  Multiple-DOF  Prostheses 
From the Surface Electromyographic Signal,” Ieee T Bio-med Eng, vol. 56, 
no. 4, pp. 1070–1080, 2009, doi: 10.1109/tbme.2008.2007967. 

[32] W. Yang, D. Yang, Y. Liu, and H. Liu, “Decoding Simultaneous Multi-
DOF  Wrist Movements From Raw EMG Signals Using a Convolutional 
Neural Network,” Ieee T Hum-mach Syst, vol. 49, no. 5, pp. 411–420, 2018, 
doi: 10.1109/thms.2019.2925191. 

[33] G. Pfurtscheller et al., “The Hybrid BCI,” Front Neurosci, vol. 4, p. 30, 

2010, doi: 10.3389/fnpro.2010.00003. 

[34]  M.  C.  Carrozza  et  al.,  “A  Novel  Wearable  Interface  for  Robotic  Hand 
Prostheses,”  9th  Int  Conf  Rehabilitation  Robotics  2005  Icorr  2005,  pp. 
109–112, 2005, doi: 10.1109/icorr.2005.1501063. 

[35]  M.  C.  Carrozza  et  al.,  “A  Wearable  Biomechatronic  Interface  for 
Controlling  Robots  with  Voluntary  Foot  Movements,”  Ieee  Asme 
Transactions  Mechatronics,  vol.  12,  no.  1,  pp.  1–11,  2007,  doi: 
10.1109/tmech.2006.886250. 

[36] D. Johansen, D. B. Popović, L. N. S. A. Struijk, F. Sebelius, and S. Jensen, 
“A  Novel  Hand  Prosthesis  Control  Scheme  Implementing  a  Tongue 
Control  System,”  Int  J  Eng  Manuf,  vol.  2,  no.  5,  pp.  14–21,  2012,  doi: 
10.5815/ijem.2012.05.03. 

[37]  M.  Vilarino  et  al.,  “Outcomes  and  Perception  of  a  Conventional  and 
Alternative Myoelectric Control Strategy,” J Prosthet Orthot, vol. 27, no. 
2, pp. 53–62, 2015, doi: 10.1097/jpo.0000000000000055. 

[38] A. Fougner, E. Scheme, A. D. C. Chan, K. Englehart, and Ø. Stavdahl, “A 
Multi-Modal  Approach  for  Hand  Motion  Classification  Using  Surface 
EMG  and  Accelerometers,”  2011  Annu  Int  Conf  Ieee  Eng  Medicine 
Biology 
doi: 
10.1109/iembs.2011.6091054. 

4247–4250, 

2011, 

2011, 

Soc, 

vol. 

pp. 

[39] S. Došen, C. Cipriani, M. Kostić, M. Controzzi, M. C. Carrozza, and D. B. 
Popović,  “Cognitive  vision  system  for  control  of  dexterous  prosthetic 
hands:  Experimental  evaluation,”  J Neuroeng Rehabil,  vol.  7, no. 1, pp. 
42–42, 2010, doi: 10.1186/1743-0003-7-42. 

[40]  M.  N.  Castro  and  S.  Dosen,  “Continuous  Semi-autonomous  Prosthesis 
Control Using a Depth Sensor on the Hand,” Front Neurorobotics, vol. 16, 
p. 814973, 2022, doi: 10.3389/fnbot.2022.814973. 

[41] C. Shi, D. Yang, S. Qiu, and J. Zhao, “i-GSI: A Fast and Reliable Grasp-
type Switching Interface based on Augmented Reality and Eye-tracking,” 
ArXiv, abs/2204.10664, 2022. 

[42]  K.  Krejtz  et  al.,  “GazeButton:  enhancing  buttons  with  eye  gaze 
interactions,”  Proc  11th  Acm  Symposium  Eye  Track  Res  Appl,  pp.  1–7, 
2019, doi: 10.1145/3317956.3318154. 

[43] C. L. TAYLOR and R. J. SCHWARZ, “The anatomy and mechanics of 

the human hand,” Artif Limbs, vol. 2, no. 2, pp. 22–35, 1955. 

[44]  M.  J.  Giummarra,  S.  J.  Gibson,  N.  Georgiou-Karistianis,  and  J.  L. 
Bradshaw,  “Central  mechanisms  in phantom  limb  perception:  The  past, 
present and future,” Brain Res Rev, vol. 54, no. 1, pp. 219–232, 2007, doi: 
10.1016/j.brainresrev.2007.01.009. 

[45] “The i-LIMB hand”, [Online]. Available: http://www.touchbionics.com/i-

LIMB 

[46] “The New about HoloLens 3.” https://www.onmsft.com/news/hololens-3-
could-launch-in-4-years-with-infinite-field-of-view-says-alex-kipman. 

 
 
 
 
