Draft version June 20, 2018
Typeset using LATEX twocolumn style in AASTeX61

USING MACHINE LEARNING METHODS TO FORECAST IF SOLAR FLARES WILL BE ASSOCIATED
WITH CMES AND SEPS

Fadil Inceoglu,1, 2, 3 Jacob H. Jeppesen,1 Peter Kongstad,2 N´estor J. Hern´andez Marcano,1 Rune H. Jacobsen,1
and Christoffer Karoff2, 3

1Department of Engineering, Aarhus University, Finlandsgade 22, DK-8200 Aarhus N, Denmark
2Department of Geoscience, Aarhus University, Høegh-Guldbergs Gade 2, DK-8000 Aarhus C, Denmark
3Stellar Astrophysics Centre, Department of Physics and Astronomy, Aarhus University, Ny Munkegade 120, DK-8000 Aarhus C, Denmark

(Received; Revised; Accepted 23-05-2018)

Submitted to ApJ

ABSTRACT

Among the eruptive activity phenomena observed on the Sun, the most technology threatening ones are ﬂares with
associated coronal mass ejections (CMEs) and solar energetic particles (SEPs). Flares with associated CMEs and
SEPs are produced by magnetohydrodynamical processes in magnetically active regions (ARs) on the Sun. However,
these ARs do not only produce ﬂares with associated CMEs and SEPs, they also lead to ﬂares and CMEs, which are
not associated with any other event. In an attempt to distinguish ﬂares with associated CMEs and SEPs from ﬂares
and CMEs, which are unassociated with any other event, we investigate the performances of two machine learning
algorithms. To achieve this objective, we employ support vector machines (SVMs) and multilayer perceptrons (MLPs)
using data from the Space Weather Database of Notiﬁcation, Knowledge, Information (DONKI) of NASA Space
Weather Center, the Geostationary Operational Environmental Satellite (GOES), and the Space-Weather Heliospheric
and Magnetic Imager Active Region Patches (SHARPs). We show that True Skill Statistics (TSS) and Heidke Skill
Scores (HSS) calculated for SVMs are slightly better than those from the MLPs. We also show that the forecasting
time frame of 96 hours provides the best results in predicting if a ﬂare will be associated with CMEs and SEPs
(TSS=0.92±0.09 and HSS=0.92±0.08). Additionally, we obtain the maximum TSS and HSS values of 0.91±0.06 for
predicting that a ﬂare will not be associated with CMEs and SEPs for the 36 hour forecast window, while the 108 hour
forecast window give the maximum TSS and HSS values for predicting CMEs will not be accompanying any events
(TSS=HSS=0.98±0.02).

Keywords: Sun: magnetic activity, surface magnetic ﬁeld, solar ﬂare, coronal mass ejection, machine

learning, SVM, MLP

Corresponding author: Fadil Inceoglu
fadil@eng.au.dk

2

Inceoglu et al.

1. INTRODUCTION

The Sun potentially endangers modern civilisation
through large solar eruptions. Predicting and monitor-
ing the large solar ﬂares, coronal mass ejections (CMEs)
and solar energetic particles (SEPs), which introduce
enormous amounts of particles and energy to Earth’s
vicinity and into its atmosphere, is therefore of crucial
importance.

The strongest observed ﬂare and accompanying CME
was the Carrington event that occurred in 1859, which
was about twice as big as the strongest events observed
during the space era (Carrington 1859; Cliver & Di-
etrich 2013). Since the 1950s, a series of the most
powerful ﬂares and their accompanying CMEs have oc-
curred between mid-October to early November 2003
peaking around 28 and 29 October (the so-called Hal-
loween solar storms), which caused radio blackouts on
Earth, and problems in diﬀerent instruments of the
satellites, such as star trackers. These ﬂares even killed
the power supply of the Japanese Earth-resource satel-
lite, the MIDORI-II (ADEOS-2), and left it inoperative.
The eﬀects of the Halloween solar storms extended be-
yond the Earth to Mars and caused the Mars Odyssey
spacecraft to go into deep safe-mode (Lopez et al. 2004).
The CMEs originate from large coronal loop struc-
tures, which contain plasma and magnetic ﬁelds, ex-
panding from the Sun into the interplanetary medium.
They occur on a quasi-regular basis and are the largest-
scale eruptive phenomena in our solar system (Chen
2011; Webb & Howard 2012; Kilpua et al. 2017). Flares,
on the other hand, are eruptive events that occur in
the solar atmosphere with energies ranging from 1028
to 1032 erg (Shibata & Magara 2011). Based on their
peak ﬂuxes in the 1 to 8 Angstrom range X-rays near
Earth, as measured by XRS instrument on the Geo-
stationary Operational Environmental Satellite (GOES),
ﬂares are classiﬁed as A, B, C, M, and X. Each ﬂare
class is also divided into subclasses linearly scaled from
1 to 9, such as M4 or X9 (Schrijver & Siscoe 2010).
Strong ﬂares and CMEs occasionally cause SEP events,
where protons, electrons, and heavier nuclei are acceler-
ated to the energies ranging between a few tens of keVs
to GeVs (Reames 2013). Strong SEPs cause nuclear
cascades in the upper atmosphere of the Earth (Reames
et al. 2013). Flares are often associated with CMEs as
they are thought to have a common magnetically-driven
mechanism and not one causing the other (Webb &
Howard 2012). However, there are CMEs and ﬂares that
are not associated with one another (Chen 2011; Webb
& Howard 2012). Observations show that the speeds
and energies of the CMEs are higher when they are ac-
companied by bright ﬂares in comparison to those not

accompanying with ﬂares (Chen 2011; Webb & Howard
2012).

Magnetically strong regions on the photosphere, the
so-called active regions (ARs), are often the source
regions to ﬂares and CMEs (Chen 2011; van Driel-
Gesztelyi & Green 2015). Strong ARs are generally large
and evolve rapidly with lifetimes varying from days to
months (van Driel-Gesztelyi & Green 2015), and they
exhibit complex magnetic geometry (Benz 2008). Vector
magnetograms, which measure the line-of-sight (LoS)
magnetic ﬁeld separately from the image-plane, allow
us to calculate the physical indices of the ARs, such as
magnetic helicity, magnetic shear angles, proxies for free
energy and magnetic ﬂuxes of the ARs, and polarity-
separation lines (Leka & Barnes 2003; Schrijver 2007;
Moore et al. 2012).

Previous studies on predicting solar eruptive phenom-
ena used photospheric magnetic ﬁeld data to calculate
the physical indices of ARs and they link these physi-
cal indices to the occurrences of ﬂares and CMEs (Leka
& Barnes 2003; Schrijver 2007; Moore et al. 2012). Re-
cently, machine learning (ML) methods, such as support
vector machines (SVMs) and neural networks (NNs),
have been used in predicting ﬂares, CMEs, and SEPs
(Yu et al. 2009; Yuan et al. 2010; Ahmed et al. 2013;
Boucheron et al. 2015; Bobra & Couvidat 2015; Bobra
& Ilonidis 2016; Florios et al. 2018).

Yu et al. (2009) used LoS magnetogram data from
the Michelson Doppler Imager (MDI) on the Solar and
Heliospheric Observatory (SOHO) to predict ﬂare occur-
rences within a forecast window of 48 hours. To achieve
this objective, the authors used data from ARs, which
generated at least one ≥C1 class ﬂare. They divided
this data into two subclasses as ﬂaring and non-ﬂaring
regions based on their total importance threshold value
(Equation 1 in Yu et al. 2009), and used it in a learning
vector quantisation neural networks algorithm. Yuan et
al. (2010), on the other hand, used the same data to
predict ﬂare classes A, B, C, M, and X via SVMs.

To predict >C1 class ﬂares 24 and 48 hours prior to
their occurrences, Ahmed et al. (2013) used magnetic
feature data of ﬂaring and non-ﬂaring regions from the
Helioseismic and Magnetic Imager (HMI) on the Solar
Dynamics Observatory (SDO) in a cascade correlation
neural network algorithm. The authors deﬁned an AR
as non-ﬂaring if it does not produce a ﬂare within 24
hours for their 24 hour prediction window, while for the
48 hour forecast window they deﬁned an AR as non-
ﬂaring if it does not produce a ﬂare within ±48 hours
after the sampling time. Boucheron et al. (2015), on the
other hand, used the SOHO/MDI data of ﬂaring and
non-ﬂaring ARs in a SVM regressor.

AASTEX Forecasting Solar Eruptions via Machine Learning Methods

3

To predict occurrences of ﬂares larger than M1 class,
Bobra & Couvidat (2015) used SDO/HMI’s deﬁnitive
ﬂaring and non-ﬂaring AR data, which are deﬁned sim-
ilar to Ahmed et al. (2013), in SVMs at time delays 48
and 24 hours, respectively. In addition, Bobra & Iloni-
dis (2016) used the SDO/HMI’s deﬁnitive AR data that
produce ﬂares and ﬂares with associated CMEs in SVMs
to predict whether a ﬂare will be associated with CMEs
within a 24 hour forecast window.

Florios et al. (2018), on the other hand, calculated
physical features of ﬂaring and non-ﬂaring ARs, which
they identiﬁed on the SDO/HMI’s near-real-time vec-
tor magnetogram data. The ﬂaring and non-ﬂaring
ARs are deﬁned based on whether they produce a ﬂare
within a 24 hour forecasting window or not. The authors
used this data in SVMs, multilayer perceptrons (MLPs),
which is based on NNs, and also decision tree algo-
rithms to predict occurrences of >M1-class and >C1-
class ﬂares.

In this study, we aim to distinguish ﬂares with asso-
ciated CMEs and SEPs from ﬂares and CMEs without
any accompanying events. To predict which event will
be produced from an AR, all of which lead to solar erup-
tions, we investigate the performances of two ML algo-
rithms, SVMs and MLPs, based on the vector magnetic
ﬁeld data observed with the HMI on the SDO (Schou
et al. 2012). The results will also highlight the discrimi-
native potential of the Space-Weather Heliospheric and
Magnetic Imager Active Region Patches (SHARPs) data
among the three classes. Section 2 describes the data
used in this study, while the performed analyses, includ-
ing brief explanations of the ML methods, are presented
in Section 3. Results from the analyses are shown in
Section 4 and discussion and conclusions are given in
Section 5.

2. THE SDO/HMI DATA

To predict which solar eruptive phenomena will be
generated from an AR, which is known to have gener-
ated only ﬂares, ﬂares with associated CMEs and SEPs,
or only CMEs, via SVMs and MLPs, we use data from
the Space Weather Database Of Notiﬁcation, Knowl-
edge, Information (DONKI)1 of NASA Space Weather
Research Center, for a period spanning from 01 Jan-
uary 2010 to 31 January 2018. DONKI contains ﬂare
data with their classes, source AR numbers, and their
start, peak, and end times. This database also provides
whether a ﬂare is accompanied with CMEs and/or SEPs.
Similar to the ﬂare data, DONKI also provides CME
data with their speeds, types, and start times as well

as whether they are associated with any ﬂares and/or
SEPs. For some events however, DONKI does not pro-
vide an AR number although an M or X class ﬂare with
an accompanying CME is listed. For example, the M3.0
class ﬂare with an accompanying CME and SEP that
occurred on 06 March 2015. To ﬁll the unregistered AR
numbers in DONKI for these events and also to double
check the peak times and the AR numbers of ﬂares, we
use ﬂare data from GOES via SunPy Python package
v0.8.2 (SunPy Community et al. 2015).

Based on the DONKI and the GOES databases we
have 347 ﬂares that are not associated with CMEs and
SEPs, and 179 ﬂares associated with CMEs and SEPs
(Figure 1a). Further, there are 376 CMEs in total, 174
of which are not associated with any other event (Fig-
ure 1b).

Following the veriﬁcation of the ﬂare data from the
DONKI and the GOES databases, we use publicly avail-
able SHARPs data from the Joint Science Operations
Center (JSOC)2, spanning from 01 January 2010 to 31
January 2018. We select the SHARPs data based on
four criteria following Bobra & Ilonidis (2016), so the
SHARPs data has to be; (i) disambiguated, (ii) taken
while the SDO’s orbital velocity < 3500m s−1, (iii) of
a high-quality, meaning the data with reliable Stokes
vectors (observables during good conditions), and (iv)
within ±70◦ longitudinal band during GOES peak time,
since beyond this band the signal-to-noise ratio in the
vector magnetic ﬁeld data decreases signiﬁcantly. The
SHARPs data contain vector magnetic ﬁeld measure-
ments of the ARs and 18 keywords, which are listed in
Table 1 together with their deﬁnitions. These keywords
parametrise the measured physical quantities as well as
proxies of physical quantities (for details, see Bobra et
al. 2014).

The 18 physical features of the ARs (Table 1) for the
three subsets are then compiled at a time before the
starting times of the events. This time gap is deﬁned
as the time-delay (∆t), which ranges from 12 to 120
hours with 12 hour intervals. This means that we use
conditions ∆t hours before the event occurs to predict
whether this event will be a ﬂare without associated
events, ﬂare with associated CMEs and SEPs or CMEs
without associated events. For each time delay itera-
tion, the data from the DONKI and GOES databases
goes through the same data selection criteria and this
causes the sample size of each three class to change (Ta-
ble 2). This situation is directly related to the temporal
evolution and motion of the ARs on the solar disk as

1 http://kauai.ccmc.gsfc.nasa.gov/DONKI/

2 http://jsoc.stanford.edu

4

Inceoglu et al.

Table 1. Keywords, deﬁnitions, and formulations of the 18
physical features of ARs. The Keyword column indicates the
name of the FITS header keyword in the SHARP data series.

Keyword

Deﬁnition

ABSNJZH

Absolute value of the net current helicity

R VALUE

Sum of ﬂux near polarity inversion line

AREA ACR Area of strong ﬁeld pixels

in the active region

MEANSHR Mean shear angle

TOTPOT

Total photospheric magnetic

free energy density

SAVNCPP

Sum of the modulus of the net current

per polarity

TOTUSJZ

Total unsigned vertical current

MEANJZD Mean vertical current density

MEANGBZ Mean gradient of vertical ﬁeld

MEANGAM Mean angle of ﬁeld from radial

MEANALP Mean characteristic twist parameter, α

MEANGBH Mean gradient of horizontal ﬁeld

TOTUSJH

SHRGT45

Total unsigned current helicity
Fraction of Area with Shear > 45◦

MEANPOT Mean photospheric magnetic free energy

MEANJZH Mean current helicity (Bz contribution)

MEANGBT Mean gradient of total ﬁeld

USFLUX

Total unsigned ﬂux

well as availability of the SHARPs data for a given time
time delay.

Table 2. Number of ﬂares, ﬂares with CMEs and SEPs, and
CMEs for each time delay ranging from 12 to 120 hours.

time delay ﬂares ﬂares w/ CMEs & SEPs CMEs

12 h

24 h

36 h

48 h

60 h

72 h

84 h

96 h

108 h

120 h

228

237

239

236

226

215

205

196

182

177

103

100

105

100

101

95

91

90

80

76

97

94

102

99

93

88

87

87

79

76

Figure 1. The top panel shows the distributions of the
ﬂare classes of ﬂares (orange) and ﬂares with CMEs and
SEPs (red), while bottom panel shows the distributions of
the CME speeds for CME only events (green) and ﬂares with
CMEs and SEPs (red). Note that the y-axes in all panels are
in logarithmic scale.

The ﬂares that occurred during the study period clus-
ter in M-class ﬂares (Figure 1a). The ﬂares unassociated
with any other events centre around M1.0 class, whereas
ﬂares associated with CMEs and SEPs cluster around
M5.0-class and extend up to X9.9 (Figure 1a).

The distribution of the CME speeds ranges between
90 to 2650 km s−1. The speeds of the CMEs that are
unassociated with an event centre around 500 km s−1,
while the speeds of the CMEs associated with ﬂares and
SEPs centre around 1000 km s−1 and reach up to 2650
km s−1 (Figure 1b).

The distribution of the ﬂare classes and the CME
speeds indicate that we can separate our data into three
subsets as (i) ﬂares only, (ii) ﬂares with associated CMEs
and SEPs, and (iii) CMEs only. These three subsets rep-
resent the classes for our multi-class classiﬁcation prob-
lem, which we aim to sort out using the SVM and MLP
algorithms. It must be noted that the size of the un-
derlying data from the SDO/HMI is smaller than those
used in previous studies based on the SOHO/MDI, mis-
sion duration of which has reached ∼22 years. Addi-
tionally, the current solar cycle 24 is quiet in nature and
does not generate many eruptions compared to previous
stronger cycles.

3. ANALYSES

Before using the 18 physical parameters of the ARs in
further analyses for each ∆t hours delay, we standardise
all the data according to their median and standard de-

B1.0C1.0M1.0X1.0X9.9Flare Class100101102# events(a)FLRs OnlyFLRs w/ CME & SEP05001000150020002500speed (km/s)100101102# events(b)CMEs OnlyFLRs w/ CME & SEPAASTEX Forecasting Solar Eruptions via Machine Learning Methods

5

viation values. The reason for this approach is to make
sure that the data with small sample size is well rep-
resented, the distribution of which might sometimes be
left or right skewed. For larger sample sizes, the median
and the mean values overlap.

3.1. Machine Learning Algorithms

To investigate which ML method provides better pre-
dictions of our three classes, we use two of the most
popular machine learning algorithms; (i) SVMs (Cortes
& Vapnik 1995), and (ii) MLPs (Hornik & White 1989)
provided by the scikit-learn software package v0.19.1
(Pedregosa et al. 2011).

3.1.1. Support Vector Machines

SVMs are initially designed to solve binary (l = 2)
classiﬁcation problems and employing them to multi-
class (l > 2) classiﬁcation problems requires diﬀerent
approaches, where they are generally fragmented into
series of diﬀerent binary classiﬁcation problems (Hsu &
Lin 2002). In this study, we use the one-versus-rest ap-
proach (Vapnik 1998), which creates k separate binary
classiﬁers for l number of classes. The m-th binary SVM
classiﬁer is then trained using the data from the m-th
class as positive (+1), whereas the remaining l − 1 num-
ber of classes are regarded as negative (−1) examples
(Hsu & Lin 2002). The SVM then classiﬁes the data
by placing a separating hyperplane with the maximum
distance between the classes of the data.

Let us consider a multi-class classiﬁcation reduced to
a binary class problem via one-versus-rest approach for
an m-th class. For a vector of P predictor consist-
ing of training data at observation i is given as a pair
(xi, yi), where i = 1, .., n, and xi ∈ RP and its class
yi ∈ {+1, −1}, then the SVM solves the optimisation
problem as follows (Hsu & Lin 2002),

min w,b,ζ

1
2

ωT ω + C

n
(cid:88)

i=1

ζi,

(1)

subject to yi (ωT φ(xi) + b) ≥ 1 − ζi,

ζi > 0, i = 1, ..., n,

where ω is the weight vector, while φ(xi) is an unknown
function included in a known kernel function that maps
the training vectors xi into a higher dimensional space.
C > 0 is the regularisation parameter, which compro-
mises misclassiﬁcation of training examples to make the
decision surface simpler. Lower C values make the deci-
sion surface smooth, while higher values enable the al-
gorithm to minimise the errors on the training examples

and maximise the separation margins (Cortes & Vap-
nik 1995). The kernel function is deﬁned as the inner
product of the data with itself for diﬀerent pairs of ob-
servations i and j, K(xi, xj) = φ(xi)T φ(xj) (Florios et
al. 2018). In our study, we use a Radial Basis Function
(RBF) kernel that is deﬁned as,

K(xi, xj) = exp(−γ||xi − xj||2),

(2)

where γ > 0 deﬁnes how much inﬂuence a single train-
ing example have on the classiﬁcation.
If γ is a large
value, then the other examples need to be closer to be
inﬂuenced, whereas smaller values can make the model
too constrained, which causes the model to not capture
the complexity of the underlying data. A more detailed
information on how the solve Equations 1 and 2 can be
found elsewhere (Cortes & Vapnik 1995; Vapnik 1998).

3.1.2. Multilayer Perceptrons

The MLP is a feed-forward NN that classiﬁes multi-
dimensional data into l diﬀerent classes. The multi-
class classiﬁcation problem in MLPs can be regarded
as a multinomial logistic regression, where the output
of the NN is the posterior probability that the input
data belongs to a particular class. The estimated pos-
terior probability distribution of a categorical random
variable depends not only on a data point from a ran-
dom feature, but also on the weights of the neurons,
which are the basic processing units (MacKay 2005).
As a feed-forward network, the MLP performs nonlin-
ear parametrised mapping from an input I to an out-
put that is a continuous function of the input and the
weights O = (I; ω, A), where ω is the weight and bias
parameter vector, and A is the architecture of the net-
work deﬁning the number of nodes in every layer (Florios
et al. 2018).

In this study, our MLPs have an input layer with m =
18 inputs Im and bias θ(1), a single hidden layer with j
hidden nodes Hj and a bias θ(2), and an output layer Oi
that only post-processes a data point to give an estimate
of the posterior probability. The architecture is given
below following MacKay (2005) and Florios et al. (2018);

α(1)

j =

α(2)

i =

(cid:88)

m
(cid:88)

j

jmIm + θ(1)
ω(1)

j

; Hj = f (α(1)

j ),

(3)

ij Hj + θ(2)
ω(2)

i

; Oi = g(α(2)

i

),

1

where f (α) =
(1+exp(−α)) is the logistic activation func-
tion, which deﬁnes the response of a neuron in the hid-
den layer to a stimulus obtained from its input (Hinton
1989). The index m used for the inputs, j and i run over
the hidden units and outputs, respectively. The weights

6

Inceoglu et al.

ω and biases θ deﬁne the parameter vector ω (MacKay
2005).

The function g(αi) coupled to the output layer Oi is
called the softmax activation function because our MLP
is designed to solve a multi-class classiﬁcation problem,
which is given as (MacKay 2005);

g(αi) =

exp(αi)
l=1 exp(αl)

(cid:80)k

,

(4)

where αi represents the i-th element of the input to soft-
max corresponding to class l, and k is the number of
classes.

The MLPs are trained using a data D = {I (n); t(n)}
by adjusting ω to minimise the negative log-likelihood
function given as (MacKay 2005);

G(ω) = −

(cid:88)

(cid:88)

t(n)
i

ln Oi(I (n); ω),

(5)

n
where I (n) is the predictor matrix, t(n)
vector, and n = 1, . . . , N is the observations.

i

i

is the target

Minimising the log-loss function is equivalent to ob-
taining the maximum likelihood estimator of the weights
and biases. To ﬁnd the output and hidden layer weights
and biases, we use a L-BFGS unconstrained optimisa-
tion algorithm.

3.2. Training and tuning of the algorithms

The size of the underlying dataset is limited because of
the quiet solar cycle 24 and the mission duration of the
SDO/HMI. This situation leads to diﬃculties in reach-
ing a suﬃcient number of events to separate the data
into training and testing subsets. To overcome this dif-
ﬁculty, we employ the stratiﬁed k-fold cross-validation
(CV) method, following Bobra & Ilonidis (2016), where
we change k-fold values from 3 to 15. This method di-
vides the dataset into k subsets, where one subset is used
for test and the remaining are used for training. This
process is then repeated k times, such that each subset
is used for testing exactly once, before the results are
averaged.

Limitations of using this method do exist, however,
as it assumes that the dataset to follow the same dis-
tribution over time. In our case, the number of events
varies in-phase with the 11-year sunspot cycle, which is
expected considering the formation of the ARs on the
solar photosphere by emergence of deep-seated toroidal
magnetic ﬂux ropes, which are generated by the shearing
of the poloidal magnetic ﬁelds by solar diﬀerential rota-
tion, through the photosphere to the corona (Charbon-
neau 2010; van Driel-Gesztelyi & Green 2015). However,
signiﬁcant ﬂares can occur at all phases of the sunspot
cycle, as three of the last four solar cycles showed X-class

ﬂares around their minima (Hathaway 2015). The date
of the event is not included in the classiﬁer, thus this
bias should be accounted for. This is done by shuﬄing
the data before the k-fold cross-validation is carried out.
In addition to employing the k-fold cross-validation,
we tune the hyper-parameters of the SVMs and MLPs
in each k-fold. To achieve this, we use the grid search
algorithm provided by the scikit-learn software package
(Pedregosa et al. 2011). This algorithm performs an ex-
haustive search over a predeﬁned set of hyper-parameter
values and the best combination of them is then re-
tained. For example, two hyper-parameters with lists
of predeﬁned values would result in a 2D grid, where
each element is tested and the pair of values that gives
the best result is saved. While training the SVM, the
regularisation parameter, C, vary between 10−3 and 107,
while the radial basis function coeﬃcient, γ, vary from
10−6 to 104 in 11 equidistant values in log-space. For
the MLP, we have an input, a hidden, and an out-
put layer, where the size of the hidden layer is tested
with [18, 36, 54, 72, 90, 108] neurons. Additionally, we
vary both the regularisation and tolerance parameters
between 10−7 and 10−3 in 5 equidistant values in log-
space.

3.3. Comparison of the Algorithms

Most of the metrics that are used to characterise and
quantify the predictive power of classiﬁers are calculated
directly from the confusion matrices, which are built
based on the results from the raw classiﬁer outputs. A
confusion matrix for l number of classes shows how n
number of instances are distributed over predicted Pi
and observed Oi classes, where 1 ≤ i ≤ l.

Table 3. A confusion matrix. The term nij denote the
number of instances predicted in class i by the classiﬁer (Pi),
where it is observed in class j (Oj), and 1 ≤ i, j ≤ l.

O1

· · · Ol

P1 n11
...
...
nl1
Pl

· · ·
. . .

· · ·

n1l
...
nll

The diagonal terms in a confusion matrix (i = j) show
correctly predicted instances, while the oﬀ-diagonal
terms (i (cid:54)= j) represents incorrectly predicted classes
(Table 3).

Let us now consider only one class i. The confu-
sion matrix obtained from a classiﬁer gives four types
of instances, which are true positives (TP), false pos-
itives (FP), false negatives (FN), and true negatives
(TN). TP and FP refer to the events that are predicted

AASTEX Forecasting Solar Eruptions via Machine Learning Methods

7

and observed, and that are predicted but not observed,
respectively. FN and TN, on the other hand, repre-
sent the events that are not predicted but observed,
and that are not predicted and not observed, respec-
tively. For the class i, these metrics are calculated as
T P = ni,i, F P = ni,+ − nii, F N = n+,i − ni,i and
T N = n − T P − F P − F N , where ni,+, and n+,i denote
the sums of the confusion matrix elements over row i
and column i, respectively (Labatut & Cheriﬁ 2011).

To evaluate the predictive power of the algorithms,
(i) SVMs for diﬀerent k-folds, (ii) MLPs for diﬀerent
k-folds, and (iii) SVMs versus MLPs for the same k-
fold, we use the True Skill Statistics (TSS) (Hanssen &
Kuipers 1965) and the Heidke Skill Score (HSS) (Heidke
1926).

The TSS compares the probability of detection
(POD), to the probability of false detection (POFD)
and is calculated based on the confusion matrices ob-
tained from ML-algorithms. The TSS is deﬁned as,

T SS = P OD − P OF D,
T P
T P + F N

=

−

F P
F P + T N

(6)

,

The TSS varies between −1 and +1, and the value of 0
means that the algorithm is incompetent. High positive
values indicate that the algorithm performs well, while
negative values show a contradictory behaviour, sug-
gesting that the positive and negative classes are mixed
around and therefore giving a reversed score (Florios et
al. 2018).

The HSS, on the other hand, is a method of measur-
ing the fractional improvement of the forecast over the
random forecast and it is deﬁned as,

HSS =

2(T P × T N − F P × F N )
(T P + F N )(F N + T N ) + (T P + F P )(F P + T N )

,

(7)

The HSS ranges from −∞ to 1. A negative value
in the HSS method, means that the random forecast is
better. A value of 0 means that the model has no skill
over the random forecast, while positive values indicate
the optimum forecasting method (Florios et al. 2018).

Both the TSS and HSS values are calculated based
on the confusion matrices obtained from the SVMs and
MLPs for each k-fold CV iteration, ranging from 3 to 15.
This method, in turn, will provide n TSS and n HSS val-
ues for n-folds cross-validation, from which averages and
standard deviations of TSS and HSS can be calculated;

for example, for a 10-fold cross-validation, we will cal-
culate 10 TSS and 10 HSS values. The results presented
in the next section are based on the averaged TSS and
HSS values.

4. RESULTS

4.1. Machine Learning Algorithms

To predict which solar eruptive phenomena will be
generated from an AR, which is known to have gen-
erated ﬂares alone, ﬂares with associated CMEs and
SEPs, or CMEs alone, at ∆t hour before they occur,
we train SVMs and MLPs separately. Previously, it was
suggested that using 12 to 18 features will not result in
overﬁtting and using a single best feature will only cause
marginally better results (Bobra & Ilonidis 2016), there-
fore we did not include any feature selection criterion for
our algorithms.

4.1.1. Support Vector Machines

The TSS and HSS values are calculated based on the
confusion matrices obtained from the SVMs for diﬀerent
k-fold CV. A sample for the confusion matrix for the 36
hour delay and k = 3-fold CV show that 74 instances
of the ﬂares, 32 of the ﬂares with CMEs and SEPs, and
again 32 of the CMEs are correctly classiﬁed (Table 4).
The results from TSS values suggest that we can predict
if a ﬂare will be unassociated with any other events 96
and 36 hours prior to their occurrences, where the max-
imum TSS level of 0.91±0.06 is found for the 36 hour
delay. This value decreases down to ∼0.76 on average
for the time delays between 48 and 72 hours and in-
creases to around 0.85 at the 84 hour delay and reaches
∼0.88±0.08 level for the 108 and 120 hour delays. The
maximum TSS values for the 24 and 12 hour delays are
0.85±0.10 and 0.73±0.10, respectively (Figure 2 and Ta-
ble 5). A similar variation pattern can also be observed
in the HSS values (Figure 3 and Table 5).

Table 4. A sample confusion matrix for one of the SVMs for
the 36 hour delay, where C = 104, γ = 10−3, and k = 3-fold
CV. Indices 1, 2, and 3 denote ﬂare, ﬂare with CMEs and
SEPs, and CMEs classes, respectively.

O1 O2 O3

74

3

3

3

32

0

1

1

32

P1

P2

P3

The maximum TSS and HSS values of 0.92±0.09 and
0.92±0.08, respectively, show that the SVMs can suc-
cessfully predict if a ﬂare will be accompanied with
CMEs and SEPs 96 hours prior to their occurrences.

8

Inceoglu et al.

Table 5. Maximum TSS and HSS values from the SVMs for three classes at diﬀerent time delays. Note that the TSS and HSS
values ≥ 0.90 with standard deviation ≤ 10% are marked in bold face.

time delay

ﬂares

ﬂares w/ CMEs & SEPs

CMEs

∆t (hrs)

TSSM ax

HSSM ax

TSSM ax

HSSM ax

TSSM ax

HSSM ax

12

24

36

48

60

72

84

96

108

120

0.73±0.10

0.73±0.10

0.58±0.11

0.58±0.12

0.82±0.11

0.83±0.10

0.85±0.10

0.85±0.10

0.85±0.14

0.84±0.12

0.91±0.10 0.91±0.10

0.91±0.06 0.91±0.06 0.91±0.05 0.90±0.08 0.96±0.06 0.97±0.04

0.77±0.08

0.77±0.08

0.80±0.10

0.80±0.09

0.79±0.19

0.80±0.09

0.79±0.05

0.79±0.05

0.71±0.18

0.70±0.17

0.84±0.16

0.85±0.14

0.72±0.08

0.73±0.08

0.66±0.09

0.67±0.11

0.76±0.12

0.78±0.14

0.85±0.11

0.85±0.12

0.83±0.18

0.84±0.18

0.91±0.08 0.93±0.05

0.90±0.08 0.90±0.08 0.92±0.09 0.92±0.08 0.91±0.05 0.92±0.05

0.89±0.09

0.89±0.09

0.88±0.08

0.86±0.08

0.98±0.02 0.98±0.02

0.87±0.08

0.87±0.08

0.82±0.11

0.82±0.09

0.96±0.06 0.97±0.03

delays longer than 96 hours, the maximum TSS and HSS
values are around 0.85. For the 24 hour forecast window,
the TSS and HSS values are 0.85±0.14 and 0.84±0.12,
respectively. The performance of the SVMs on predict-
ing if a ﬂare will be accompanied with CMEs and SEPs
is minimum for the time delay of 12 hours (Table 5 and
Figures 2 and 3).

The results also show that the SVMs can predict if a
CME will not accompany ﬂares and SEPs for the time
delays between 120 and 84 hours as well as 36 and 24
hours prior to their occurrences as suggested by the max-
imum TSS and HSS levels of above 0.90±0.10 (Table 5).
For the 12 hour time delay, the maximum TSS and HSS
values are 0.82±0.11 and 0.83±0.10, respectively. The
TSS and HSS values decrease down to around ∼0.80 for
the time delays between 48 and 72 hours (Table 5, and
Figures 2 and 3).

4.1.2. Multilayer Perceptrons

The TSS and HSS values are calculated based on the
confusion matrices obtained from the MLPs for diﬀer-
ent k-fold CV. A sample for the confusion matrix for
the 36 hour delay and k = 3-fold CV show that 74 in-
stances of the ﬂares, 31 of the ﬂares with CMEs and
SEPs, and again 33 of the CMEs are correctly classiﬁed
(Table 6). The TSS and HSS values for diﬀerent k-fold
CV suggest that the MLPs can predict that a ﬂare will
not be associated with any other event 96 hours prior
to its occurrence with maximum TSS and HSS values of
0.91±0.07 (Table 7). The TSS and HSS levels are above
0.70 for the 108 and 120 hour time delays, while they
vary between 0.60 and 0.85 for the time delays between
24 and 84 hours. The TSS and HSS decrease below 0.70
for the 12 hour time delay (Figures 4a and 5a).

Figure 2. The TSS values calculated based on confusion
matrices obtained from the SVMs as a function of k-folds
CV and ∆t time delays for ﬂares only (orange), ﬂares with
CMEs and SEPs (red), and CMEs only (green).

For the 36 hours forecasting window, the TSS and HSS
values are 0.91±0.05 and 0.90±0.08, respectively (Ta-
ble 5 and Figures 2 and 3). The maximum TSS and
HSS values for this class are around ∼0.72 on average
at time delays between 48 and 72 hours, where they in-
crease up to 0.83 for the 84 hour time delay. For time

0.00.20.40.60.81.0TSS(a) t=12h(b) t=24h0.00.20.40.60.81.0TSS(c) t=36h(d) t=48h0.00.20.40.60.81.0TSS(e) t=60h(f) t=72h0.00.20.40.60.81.0TSS(g) t=84h(h) t=96h246810121416k-fold0.00.20.40.60.81.0TSS(i) t=108h246810121416k-fold(j) t=120hFLRs OnlyFLRs w/ CMEs & SEPsCMEs OnlyAASTEX Forecasting Solar Eruptions via Machine Learning Methods

9

Figure 3. The HSS values calculated based on confusion
matrices obtained from the SVMs as a function of k-folds
CV and ∆t time delays for ﬂares only (orange), ﬂares with
CMEs and SEPs (red), and CMEs only (green).

Figure 4. The TSS values calculated based on confusion
matrices obtained from the MLPs as a function of k-folds
CV and ∆t time delays for ﬂares only (orange), ﬂares with
CMEs and SEPs (red), and CMEs only (green).

Table 6. A sample confusion matrix for one of the MLPs
for the 36 hour delay, where the number of neurons is 36,
the tolerance is 10−9, and k = 3-fold CV. Indices 1, 2, and 3
denote ﬂare, ﬂare with CMEs and SEPs, and CMEs classes,
respectively.

O1 O2 O3

74

6

0

3

31

1

1

0

33

P1

P2

P3

The results show that the MLPs can predict whether
a ﬂare will be accompanied with CMEs and SEPs with
maximum TSS and HSS values of 0.93±0.04 for the 96
hour time delay. Further, these values are above 0.80
levels for the 108 and 120 hour time delays, while they
are generally below 0.85 levels for the rest (Table 7 and
Figures 4 and 5).

The maximum TSS and HSS values above 0.90±0.10
show that the MLPs can successfully predict that a CME
will not be associated with ﬂares and SEPs 120 hours,
108 hours, 36 hours, and 24 hours prior to their occur-
rences (Figures 4 and 5). For the 108 hour delay, we

obtained maximum TSS and HSS values of 0.99±0.02
and 0.99±0.01, respectively. These values gradually de-
crease down below 0.80 until the 48 hour delay. For
the 12 hour time delay, the maximum TSS and HSS are
0.78±0.07 and 0.79±0.11, respectively (Table 7).

4.2. Comparison of the SVMs and MLPs

The resulting TSS and HSS values show that the
SVMs generally perform better than MLPs, having the
TSS and HSS values mostly above 0.50, while the MLPs
reach down to around 0.40.

The TSS and HSS values, which are calculated to pre-
dict that ﬂares will not be associated with CMEs and
SEPs, are generally higher in SVM for all k-fold values,
while the MLP values reach down to ∼0.55. The two
methods show overlapping high TSS and HSS values for
the 96 hour delay (Figures 2, 3, 4, and 5).

The TSS and HSS values show that SVMs can predict
that a ﬂare will be accompanied with CMEs and SEPs
in the forecast window of 96 hours (TSS=0.92±0.08,
HSS=0.92±0.09), which also coincides with the highest
TSS and HSS values from the MLPs (TSS=0.93±0.04,
HSS=0.93±0.04).
In addition to the 96 hour fore-
cast window, the SVMs also show high TSS and HSS

0.00.20.40.60.81.0HSS(a) t=12h(b) t=24h0.00.20.40.60.81.0HSS(c) t=36h(d) t=48h0.00.20.40.60.81.0HSS(e) t=60h(f) t=72h0.00.20.40.60.81.0HSS(g) t=84h(h) t=96h246810121416k-fold0.00.20.40.60.81.0HSS(i) t=108h246810121416k-fold(j) t=120hFLRs OnlyFLRs w/ CMEs & SEPsCMEs Only0.00.20.40.60.81.0TSS(a) t=12h(b) t=24h0.00.20.40.60.81.0TSS(c) t=36h(d) t=48h0.00.20.40.60.81.0TSS(e) t=60h(f) t=72h0.00.20.40.60.81.0TSS(g) t=84h(h) t=96h246810121416k-fold0.00.20.40.60.81.0TSS(i) t=108h246810121416k-fold(j) t=120hFLRs OnlyFLRs w/ CMEs & SEPsCMEs Only10

Inceoglu et al.

Table 7. Maximum TSS and HSS values from the MLPs for three classes at diﬀerent time delays. Note that the TSS and HSS
values ≥ 0.90 with standard deviation ≤ 10% are marked in bold face.

time delay

ﬂares

ﬂares w/ CMEs & SEPs

CMEs

∆t (hrs)

TSSM ax

HSSM ax

TSSM ax

HSSM ax

TSSM ax

HSSM ax

12

24

36

48

60

72

84

96

108

120

0.70±0.07

0.70±0.07

0.54±0.06

0.56±0.08

0.78±0.07

0.79±0.11

0.79±0.11

0.79±0.11

0.74±0.13

0.77±0.05

0.93±0.07 0.91±0.08

0.85±0.07

0.85±0.06

0.84±0.04

0.84±0.03

0.94±0.06 0.94±0.05

0.80±0.09

0.81±0.09

0.71±0.07

0.72±0.05

0.79±0.12

0.80±0.07

0.82±0.08

0.83±0.08

0.74±0.08

0.73±0.09

0.84±0.13

0.84±0.12

0.71±0.10

0.72±0.09

0.62±0.17

0.63±0.15

0.73±0.15

0.77±0.12

0.81±0.11

0.81±0.11

0.80±0.11

0.81±0.08

0.87±0.09

0.88±0.09

0.91±0.07 0.91±0.07 0.93±0.04 0.93±0.04

0.89±0.11

0.90±0.11

0.89±0.07

0.89±0.07

0.85±0.16

0.85±0.11

0.99±0.02 0.99±0.01

0.80±0.07

0.81±0.07

0.74±0.08

0.76±0.07

0.97±0.07 0.97±0.05

tween 120 and 84 hours, as well as 36 and 24 hours
(Table 5). On the other hand, the MLPs give TSS and
HSS values above 0.90±0.10 for the forecast windows of
120, 108, 36, and 24 hours (Table 7).

5. DISCUSSION AND CONCLUSIONS

Florios et al. (2018) used data from ﬂaring and non-
ﬂaring ARs in an SVM algorithm to predict occurrences
of >M1-class and >C1-class ﬂares within a 24 hour fore-
casting window. For prediction of >M1 class ﬂares,
the authors reported TSS and HSS values of ∼0.72 and
∼0.55, respectively, while for >C1 class ﬂares their TSS
and HSS values decreased down to ∼0.57 and ∼0.50, re-
spectively. To predict occurrences of ﬂares >M1 class,
Bobra & Couvidat (2015) used SDO/HMI’s deﬁnitive
ﬂaring and non-ﬂaring AR data in SVMs at time de-
lays 48 and 24 hours, and reported TSS values of 0.82
and 0.76, respectively. In addition, again based on the
SDO/HMI’s deﬁnitive AR data that produce ﬂares and
ﬂares with associated CMEs in SVMs, Bobra & Ilonidis
(2016) calculated TSS=∼ 0.80 ± 0.20 to predict whether
a ﬂare will be associated with CMEs in a 24 hour forecast
window. On the other hand, Boucheron et al. (2015)
used the SOHO/MDI data of ﬂaring and non-ﬂaring
ARs in an SVM regressor and calculated TSS=0.55 and
HSS=0.46 in their size regressions for >C1 class ﬂares,
which is used to predict the size of a ﬂare. To predict
ﬂare classes A, B, C, M, and X, Yuan et al. (2010) used
SVMs and achieved maximum TSS and HSS values of
0.63 and 0.64 for predictions of A and B class ﬂares, 0.09
and 0.11 for only C class ﬂares, 0.05 and 0.06 for only M
class ﬂares, and 0.14 and 0.18 for only X class ﬂares, re-
spectively. We recovered the TSS and HSS values based

Figure 5. The HSS values calculated based on confusion
matrices obtained from the MLPs as a function of k-folds
CV and ∆t time delays for ﬂares only (orange), ﬂares with
CMEs and SEPs (red), and CMEs only (green).

values for the 36 hour time delay (TSS=0.91±0.05,
HSS=0.90±0.08), while the MLPs cannot reach these
levels (Tables 5, and 7).

The SVMs can predict that a CME will not be asso-
ciated with any other event with TSS and HSS values
above 0.90±0.10 for the time delays continuously be-

0.00.20.40.60.81.0HSS(a) t=12h(b) t=24h0.00.20.40.60.81.0HSS(c) t=36h(d) t=48h0.00.20.40.60.81.0HSS(e) t=60h(f) t=72h0.00.20.40.60.81.0HSS(g) t=84h(h) t=96h246810121416k-fold0.00.20.40.60.81.0HSS(i) t=108h246810121416k-fold(j) t=120hFLRs OnlyFLRs w/ CMEs & SEPsCMEs OnlyAASTEX Forecasting Solar Eruptions via Machine Learning Methods

11

on the confusion matrices given in their work (Figures
3b, 4b, 5b, and 6b in Yuan et al. 2010).

Using SVMs for the 24 hour forecast window, we
reached maximum TSS and HSS values of 0.85±0.10 to
predict whether a ﬂare will be unassociated with any
other event. The maximum TSS and HSS values to
predict whether a ﬂare will be accompanied by CMEs
and SEPs are 0.85±0.14 and 0.84±0.12, respectively. As
for predicting whether an AR will produce only CMEs,
our maximum TSS and HSS values are 0.91±0.10 (Ta-
ble 5). Additionally, our maximum TSS and HSS values
from the SVMs for the 48 hour prediction window that
a ﬂare will not be associated with any other event is
0.77±0.08. For predicting whether a ﬂare will be asso-
ciated with CMEs and SEPs, our TSS=0.80±0.10 and
HSS=0.80±0.09, while for forecasting that a CME will
not be associated with any other event, the maximum
TSS and HSS values are 0.79±0.19 and 0.80±0.09, re-
spectively. Among the time delays we used in our study,
which range from 120 to 12 hours, the forecast windows
of 96 and 36 hours consistently provided maximum TSS
and HSS values above 0.90 with standard deviations
smaller than 10% (Table 5). These results are better
than those found by the previous studies. However, it
must be noted that the scope of this study is to distin-
guish the three classes of solar eruptions observed on the
Sun, therefore non-ﬂaring ARs are not included. Also,
the choice of the parameters used in this study diﬀers
from most of the previous studies.

Using MLPs to predict the occurrences of >M1 and
>C1 class ﬂares within a 24 hour forecast window, sepa-
rately, Florios et al. (2018) obtained maximum TSS and
HSS values of ∼0.73 and ∼0.55 for >M1 class ﬂares,
and ∼0.57 and ∼0.55 for >C1 class ﬂares, respectively
(Figures 3 and 5 in Florios et al. 2018). Using a cas-
cade correlation neural network algorithm to predict the
occurrences of >C1 class ﬂares within 24 and 48 hour
forecast windows, Ahmed et al. (2013) calculated max-
imum TSS and HSS as 0.45 and 0.54, respectively. Yu
et al. (2009), on the other hand, used a learning vector
quantisation neural networks algorithm to predict ﬂare
occurrences within a forecast window of 48 hours and
reached maximum TSS=0.67, which we recovered using
T SS = T Prate − (1 − T Nrate) relationship.

Our maximum TSS and HSS values obtained from the
MLPs for the 24 hour forecast window are 0.79±0.11 for
forecasting that a ﬂare will not be associated with any
other event. To predict whether a ﬂare will be associated
with CMEs and SEPs, we obtained TSS=0.74±0.13 and
HSS=0.77±0.05, while these values are 0.93±0.07 and
0.91±0.08 for forecasting that a CME will not be associ-
ated with any other event (Table 7). As for the forecast

window of 48 hours, we obtained TSS=0.80±0.09 and
HSS=0.81±0.09 for predictions of ﬂare only events. The
MLPs gave maximum TSS and HSS values of 0.71±0.07
and 0.72±0.05 for predictions whether a ﬂare will be ac-
companied with CMEs and SEPs, while these numbers
are 0.79±0.12 and 0.80±0.07 for predictions of CME
only events. Although our maximum TSS and HSS val-
ues are higher than those found in the previous studies,
we must again note that we do not include data from
non-ﬂaring ARs, since our main focus here is to distin-
guish the three classes of solar eruptions observed on the
Sun.

In our study, we used SVMs and MLPs to predict
whether an AR, which is known to originate solar erup-
tions, will produce only ﬂares, ﬂares with associated
CMEs and SEPs, or only CMEs for time delays extend-
ing from 12 hours to 120 hours. To achieve this ob-
jective, we used data provided by the SHARPs, GOES
and DONKI databases. The size of the data used in
this study is limited due to the mission duration of
SDO/HMI and also because of the quietness of the cur-
rent solar cycle 24, which leads to fewer ﬂares, CMEs
and SEPs. To overcome this diﬃculty, we employed the
stratiﬁed k-fold CV method, which ensures that each
subset of data is used to train and test the ML algo-
rithms. However, this method assumes that the under-
lying data follows the same distribution throughout the
study period. It is shown that the number of occurrences
of ﬂares, CMEs and SEPs, although sporadic, follow a
trend in-phase with the 11-year solar cycle (Aschwan-
den & McTiernan 2010; Chen 2011; Hathaway 2015).
To decrease this bias in our calculations, we shuﬄed the
data before performing k-fold CV method. However, to
remove this bias substantially, to avoid overﬁtting, and
to train and validate the ML algorithms further, longer
data sets are needed.

To optimise the hyper-parameters used in our SVM
and MLP algorithms, we employed an embedded grid
search for each iteration of k-fold CV values ranging
from 3 to 15. Our results show that we can achieve
TSS and HSS values greater than 0.90 with standard
deviations smaller than 10%, which shows both our
SVM and MLP are good classiﬁers, though the for-
mer is slightly better than the latter. Our results also
show that we can predict that ﬂares will not be ac-
companied with any associated event earliest 96 hours
before they happen with maximum TSS and HSS val-
ues of 0.90±0.08 for the SVMs and 0.91±0.07 for the
MLPs. The earliest forecast that a ﬂare will be associ-
ated with CMEs and SEPs can be made at 96 hour time
delay with TSS=0.92±0.09 and HSS=0.92±0.08 for the
SVMs and TSS=HSS=0.93±0.04 for the MLPs. We also

12

Inceoglu et al.

showed that we can predict if an AR will produce only
CMEs unassociated with any other events 108 hours be-
fore they occur with maximum TSS and HSS values of
0.98±0.02 for the SVMs and 0.99±0.02 for the MLPs.
Our results indicate that the discriminative potential of
the physical features of ARs in SHARPs data is very
high.

We also calculated the Fisher-scores of the 18 physical
parameters for each time delay, which are not shown in
this study, as we do not include them as feature selec-
tion criteria. However, we need to note that the results
show that the variation in the Fisher-scores of the phys-
ical parameters of the ARs provide insights into why the
predictive powers of the SVMs and MLPs change with
diﬀerent time delays. Additionally, the calculated Fisher
scores indicate that the physical features are highly com-
plementary across the diﬀerent time delays, meaning
that all features are relevant, but not necessarily at the
same time delay.

In conclusion, our results show that the SVMs are
slightly better than the MLPs. However, a more exten-
sive future work is necessary for SVM classiﬁers, where

ARs that do not produce any eruptive phenomena are
planned to be included in the analyses. This will, how-
ever, introduce imbalance problems because the number
of ARs that do not produce an eruptive event is over-
whelmingly high compared to those produce eruptions
(Bobra & Couvidat 2015). It is therefore important to
ﬁnd the optimum values for the class weight ratios to
sort out this problem. Additionally, we plan to investi-
gate the optimum number of features by combining the
predictions from the individual time delays, to search
a larger grid for the C and γ values, and to employ
diﬀerent kernel functions and grid search their related
parameters (such as polynomial functions with diﬀer-
ent degrees). Furthermore, another direction we plan
to exploit is using deep neural networks with temporal
evolutionary algorithms on the time-series aspect of the
available SHARPs data.

Funding for the Stellar Astrophysics Centre is pro-
vided by the Danish National Research Foundation
(Grant agreement No.: DNRF106). The project has
been supported by the Villum Foundation.

Ahmed, O. W., Qahwaji, R., Colak, T., et al. 2013, SoPh,

Hanssen, A., Kuipers, W. 1965, On the Relationship

REFERENCES

283, 157.

Aschwanden, M. J., & McTiernan, J. M. 2010, ApJ, 717,

683.

Benz, A. O. 2008, Living Reviews in Solar Physics, 5, 1.

Bobra, M. G., Sun, X., Hoeksema, J. T., et al. 2014, SoPh,

289, 3549

Bobra, M. G., & Couvidat, S. 2015, ApJ, 798, 135.

Bobra, M. G., & Ilonidis, S. 2016, ApJ, 821, 127.

Boucheron, L. E., Al-Ghraibah, A., & McAteer, R. T. J.

2015, ApJ, 812, 51.

Carrington, R. C. 1859, MNRAS, 20, 13.

Charbonneau, P. 2010, Living Reviews in Solar Physics, 7,

3.

Chen, P. F. 2011, Living Reviews in Solar Physics, 8, 1.

Cliver, E. W., & Dietrich, W. F. 2013, Journal of Space

Weather and Space Climate, 3, A31.

Cortes, C., & Vapnik, V. 1995, Support vector networks.

Mach. Learn. 20(3), 273297.

van Driel-Gesztelyi, L., & Green, L. M. 2015, Living

Reviews in Solar Physics, 12, 1.

Between the Frequency of Rain and Various
Meteorological Parameters: (with Reference to the
Problem of Objective Forecasting).

Hathaway, D. H. 2015, Living Reviews in Solar Physics, 12,

4

Heidke, P. 1926, Geogr. Ann. 8, 301.

Hinton, G. E. 1989, Artif. Intell., 40, 185.

Hornik, K., Stinchcombe, M.,White, H. 1989, Multilayer
feedforward networks are universal approximators,
Neural Netw. 2(5), 359.

Hsu, C., Lin, C. 2002, A comparison of methods for

multi-class support vector machines. IEEE Trans. Neural
Netw. 13, 415425.

Kilpua, E., Koskinen, H. E. J., & Pulkkinen, T. I. 2017,

Living Reviews in Solar Physics, 14, 5.

Labatut, V., Cheriﬁ, H. 2011, The 5th International

Conference on Information Technology, 1.

Leka, K. D., & Barnes, G. 2003, ApJ, 595, 1277.

Lopez, R. E., Baker, D. N., & Allen, J. 2004, EOS

Transactions, 85, 105.

MacKay, D. J. C. 2005, Information Theory , Inference

And Learning Algorithms, Cambridge University Press.

Florios, K., Kontogiannis, I., Park, S.-H., et al. 2018, SoPh,

Moore, R. L., Falconer, D. A., & Sterling, A. C. 2012, ApJ,

293, #28.

750, 24.

AASTEX Forecasting Solar Eruptions via Machine Learning Methods

13

Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V.,
Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P.,
Weiss, R., Dubourg, V., Vanderplas, J., Passos, A.,
Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E.,
2011, Journal of Machine Learning Research, 12, 2825.

Reames, D. V. 2013, SSRv, 175, 53.
Reames, D. V., Ng, C. K., & Tylka, A. J. 2013, SoPh, 285,

233.

Shibata, K., & Magara, T. 2011, Living Reviews in Solar

Physics, 8, 6.

SunPy Community, Mumford, S. J., Christe, S., et al. 2015,

Computational Science and Discovery, 8, 014009

Vapnik, V. 1998, Statistical Learning Theory. Wiley, New

York.

Webb, D. F., & Howard, T. A. 2012, Living Reviews in

Schou, J., Scherrer, P. H., Bush, R. I., et al. 2012, SoPh,

Solar Physics, 9, 3.

275, 229.

Schrijver, C. J. 2007, ApJL, 655, L117.
Schrijver, C. J., & Siscoe, G. L. 2010, Heliophysics: Space
Storms and Radiation: Causes and Eﬀects, pp. 375.

Yu, D., Huang, X., Wang, H., & Cui, Y. 2009, SoPh, 255, 91

Yuan, Y., Shih, F. Y., Jing, J., & Wang, H.-M. 2010,

Research in Astronomy and Astrophysics, 10, 785

