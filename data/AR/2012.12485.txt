1
2
0
2

r
a

M
2
2

]

G
L
.
s
c
[

3
v
5
8
4
2
1
.
2
1
0
2
:
v
i
X
r
a

Global Models for Time Series Forecasting: A Simulation Study

Hansika Hewamalagea,∗, Christoph Bergmeira, Kasun Bandarab

Hansika.Hewamalage@monash.edu, Christoph.Bergmeir@monash.edu, kasun.bandara@unimelb.edu.au

aDept of Data Science and AI, Faculty of IT, Monash University, Melbourne, Australia.
bSchool of Computing and Information Systems, Melbourne Centre for Data Science, University of Melbourne,
Melbourne, Australia.

Abstract

In the current context of Big Data, the nature of many forecasting problems has changed from predict-

ing isolated time series to predicting many time series from similar sources. This has opened up the

opportunity to develop competitive global forecasting models that simultaneously learn from many

time series, which have shown recently promising results in forecasting competitions. Nevertheless,

it still remains unclear under which circumstances global forecasting models can outperform the uni-

variate benchmarks, especially along the dimensions of the homogeneity/heterogeneity of series, the

complexity of patterns in the series, the complexity of forecasting models, and the lengths/number of

series. Our study attempts to address this problem through investigating the eﬀect from these factors,

by simulating a number of datasets that have controllable time series characteristics. We simulate

time series from simple data generating processes (DGP), such as Auto Regressive (AR) and Seasonal

AR, to complex DGPs, such as Chaotic Logistic Map, Self-Exciting Threshold Auto-Regressive, and

Mackey-Glass Equations. The data heterogeneity is introduced by mixing time series generated from

several DGPs into a single dataset. The lengths and the number of series in the dataset are varied

in diﬀerent scenarios. We perform experiments on these datasets using global forecasting models in-

cluding Recurrent Neural Networks (RNN), Feed-Forward Neural Networks, Pooled Regression (PR)

models and Light Gradient Boosting Models (LGBM), and compare their performance against stan-

dard statistical univariate forecasting techniques. Our experiments demonstrate that when trained

as global forecasting models, techniques such as RNNs and LGBMs, which have complex non-linear

modelling capabilities, are competitive methods in general under challenging forecasting scenarios such

as series having short lengths, datasets with heterogeneous series and having minimal prior knowledge

of the patterns of the series. This makes these techniques promising candidates for forecasting under

∗Corresponding Author Name: Hansika Hewamalage, Aﬃliation: Dept of Data Science and AI, Faculty of IT, Monash
University, Melbourne, Australia, Postal Address: Faculty of Information Technology, P.O. Box 63 Monash University,
Victoria 3800, Australia, E-mail address: Hansika.Hewamalage@monash.edu

Preprint submitted to Elsevier

March 23, 2021

 
 
 
 
 
 
uncertain situations as opposed to techniques such as PR and AR models, which assume linearity of

the underlying data.

Keywords: Time Series Forecasting, Global Forecasting Models, Time Series Simulation, Data

Generating Processes

1. Introduction

In many industries, such as retail, energy, ride-share, and tourism, generating accurate forecasts

plays a crucial role in business decision-making scenarios. For example, for retailers such as Amazon

and Walmart, sales demand forecasting is important as it provides better grounds for optimising

their product inventories (Wen et al., 2017a; Bandara et al., 2019).

In the energy sector, demand

forecasts are used to determine the fuel allocation, economic dispatch, and others (Mandal et al., 2006),

whereas accurate service demand forecasts across diﬀerent geographies are essential for industries such

as tourism and healthcare (Claveria and Torra, 2014; Bandara et al., 2020a). In ride-share services

such as Uber, accurate prediction of passenger demand during extreme events can help with better

resource allocation and with budget planning in advance (Zhu and Laptev, 2017).

The paradigm in time series forecasting throughout decades has been to treat every time series as an

independent dataset. As a result, traditional forecasting techniques are univariate, consider each time

series separately and forecast it in isolation. The Exponential Smoothing State Space Model (ETS,

Hyndman et al., 2008) and Auto-Regressive Integrated Moving Average Model (ARIMA, Box et al.,

1994) are the most prominent examples of such methods. However, nowadays many companies are

collecting large quantities of time series from similar sources routinely, such as sales in retail of thou-

sands of diﬀerent products, measurements for predictive maintenance across many machines, smart

meter data across many households, etc. Though traditional univariate techniques can still deal with

forecasting under these circumstances, they leave the huge potential of learning patterns across time

series untapped.

Due to this reason, there has been a paradigm shift in forecasting recently, where now a set of series,

as opposed to just one series, is seen as a dataset. Then, a global forecasting model (Januschowski

et al., 2020) is trained across all the series in the dataset. The global model has the same set of

parameters (e.g., the weights if the global model is a neural network) for all the series in contrast

to a local model which has a diﬀerent set of parameters for every individual series (Januschowski

et al., 2020). Nowadays, such global models for forecasting are being introduced at fast pace, e.g.,

2

in the works of Wen et al. (2017b); Salinas et al. (2019); Bandara et al. (2020b). They are quickly

making their way into practice, and have won all recent prestigious forecasting competitions, such as

the M4 (Makridakis et al., 2020a) and M5 competition (Makridakis et al., 2020b), and all competitions

held in recent years on the Kaggle platform with a forecasting task (Bojer and Meldgaard, 2020).

The premise under which these works operate, and how they explain the almost unreasonable

eﬀectiveness of global models, is that the series have to be “related” in some way (Salinas et al., 2019;

Wang et al., 2019; Rangapuram et al., 2018; Wen et al., 2017a; Bandara et al., 2020b), so that the

global model can extract patterns across the series. However, none of the works attempts to deﬁne or

analyse the characteristics of such “relatedness.” Furthermore, global models seem to work well even

in situations where series are clearly unrelated, such as the M4 forecasting competition, whose dataset

is a broad mix of un-aligned time series across many diﬀerent domains. The competition was won by

ES-RNN, a global recurrent neural network (Smyl, 2020).

Thus, the problem of understanding when and why global forecasting models work, is arguably

the most important open problem currently in time series forecasting. The ﬁrst work to oﬀer expla-

nations in this space is the recent work by Montero-Manso and Hyndman (2020), which demonstrates

theoretically that, no matter how heterogeneous the data are, there always exists a global forecasting

model for any dataset that can perform equally well or even better than a collection of local models.

Thus, global forecasting models are in theory not in any way more restricted than local ones, and series

don’t have to be “related” for global forecasting models to perform well. However, mere existence of

such a global model does not mean it is straightforward to ﬁnd or construct such a model. Instead of

considering relatedness, that study focuses on model complexity. Due to exploiting more data, global

models can aﬀord to be more complex than local ones while still generalising better. Montero-Manso

and Hyndman (2020) then argue that the complexity of global models can be controlled mainly by

using 1) more lags as inputs, 2) using non-linear, non-parametetric models, and 3) using data partition-

ing. Those authors then proceed to conﬁrm and illustrate their ﬁndings empirically using real-world

datasets.

Despite the insights of the work of Montero-Manso and Hyndman (2020), many questions in this

space are still unanswered, around under which circumstances global forecasting models work, and

how model complexity is best introduced for datasets with diﬀerent amounts of data complexity, data

availability, and relatedness. In order to deﬁne and fully control relatedness of the time series in a

dataset, we base our work on simulated time series with known Data Generating Processes (DGP).

3

Then, we deﬁne relatedness in terms of the parameters of the known DGPs. This also gives us full

control over the complexity of the patterns in the data and the availability of data, rather than relying

on real-world datasets which may contain a mixture of many diﬀerent characteristics or none at all.

We perform a comprehensive experimental study under controlled conditions, to carefully analyse and

quantify the interplay between complexity of the DGP, complexity of the model, amount of data

available, and the “relatedness” of the series.

Our study has the following key contributions. We simulate diﬀerent datasets using a number

of carefully chosen DGPs which cover a variety of time series characteristics, most of them closely

simulating real-world scenarios. The DGPs that we have chosen vary from simple linear AR(3),

to Seasonal Auto-Regressive (SAR) DGPs, to more complex and non-linear DGPs such as Chaotic

Logistic Map, Mackey-Glass Equation and Self-Exciting Threshold Auto-Regressive (SETAR) models.

The simulation settings that we use in our study along with the respective DGP implementations are

available publicly as a code repository1. We have designed several experimental scenarios with each

one of these DGPs. To explore the eﬀect of data availability on the model performance, we vary

the amount of data in the datasets in terms of both the number of series as well as the lengths of

the individual series. For diﬀerent degrees of data relatedness, we investigate both homogeneous and

heterogeneous settings by changing the number of DGPs mixed within the same dataset. Thirdly, we

perform experiments with a number of selected global forecasting models including Recurrent Neural

Networks (RNN), Pooled Regression (PR) models, Feed-Forward Neural Networks (FFNN) and Light

Gradient Boosting Machines (LGBM, Ke et al., 2017) on the simulated datasets under the diﬀerent

experimental scenarios. The complexity of the diﬀerent global forecasting models is further changed by

introducing two model setups, namely the GFM.All setup where all the series are ﬁtted using the same

global model and the GFM.GroupFeature setup, which on top of the GFM.All setup involves extra

features to indicate the invidual DGPs the series are generated from within a heterogeneous context.

Finally, the performance of the models is compared against each other as well as against the univariate

techniques of AR and SETAR models. Based on the empirical evidence, an analysis is provided around

the diﬀerent factors which aﬀect the performance of diﬀerent global forecasting models.

The rest of the paper is structured as follows. Section 2 ﬁrst details the overall methodology

employed in the study including the diﬀerent experimental scenarios designed. Next, Section 3 provides

a brief review of the diﬀerent studies which involve time series simulation, followed by the details of

1Currently available at:

https://drive.google.com/file/d/1Qllh4rDEZ26_-fdKTOzi3qAMo3m9tZI_/view?usp=

sharing. A github link will be provided in the ﬁnal version of the manuscript.

4

the DGPs involved in this study.

In Section 4, we provide the details of the diﬀerent forecasting

techniques that are compared against each other in the study along with their data preprocessing,

model training and testing information. Section 5 presents the details of the dataset characteristics

along with the evaluation metrics as well as the tests for statistical signiﬁcance of the performance

diﬀerences between the methods. In Section 6, we present an analysis of the results of the experiments

as well as a comparison of the computational times of the employed forecasting techniques. Section

7 concludes the paper with the ﬁnal remarks of the overall study, the conclusions derived and the

way forward. We also have an Online Appendix2 where we include further details of the used DGPs,

forecasting techniques, experimental setup and results analysis.

2. Overview of the Methodology

The methodology of our study involves ﬁrst simulating a number of datasets having many diﬀerent

characteristics. Once the datasets are simulated as required, diﬀerent forecasting techniques are tested

on them. We introduce a host of experimental scenarios to quantitatively explore the interplay between

the complexity of diﬀerent forecasting models and characteristics of the data in this manner. In our

experiments, characteristics of the data are controlled along four dimensions: 1) complexity, 2) single

or multiple series, 3) heterogeneity, and 4) amount of data points, whereas forecasting models are

controlled using diﬀerent levels of complexity. The speciﬁc details of these controlled experimental

settings are explained in this section, and Figure 1 gives an overview.

2.1. Complexity of the Patterns in the Data

The complexity of the simulated time series is determined by the complexity of the underlying

DGP. The diﬀerent DGPs that we use for the experiments are as follows.

• AR(3)

• SAR(1)

• Chaotic Logistic Map

• SETAR

• Mackey-Glass Equation

2https://drive.google.com/file/d/1LDCEJzOmbmTN3wZXfKUyK8cgInbWaONM/view?usp=sharing

5

Figure 1: Visualisation of Experimental Settings Employed in the Study

Out of these DGPs, as discussed in more detail under Section 3, AR(3) and SAR(1) are linear

DGPs whereas the rest generate time series with more complex and non-linear characteristics.

2.2. Single or Multiple Series

With every DGP used, series are both used for single series settings and split into multiple equal

length series to constitute a scenario with multiple series. The purpose of this experimental scenario

is to quantitatively evaluate whether it makes any diﬀerence for the models under consideration to

learn from the same data either on one long series or across multiple series. For both the scenarios, we

evaluate on the same forecast horizon. This means that for the multiple series scenarios, the evaluation

is performed on the test forecast horizon of the series that corresponds to the last segment of the relevant

long single series. In terms of the forecasting techniques, this indicates that the techniques that can

be built as global models can leverage that facility when in the multiple series mode. However, for

local forecasting models such as AR and SETAR models, learning is always restricted to use only one

series at a time. Consequently, in single time series scenarios, such local models have more training

data than in the multiple series scenarios.

6

2.3. Scale of Heterogeneity

We control the scale of heterogeneity of time series by simulating the following scenarios using

above DGPs.

1. Homogeneous (Single) Pattern

2. Heterogeneous Patterns (Only for Multiple Series)

For multiple series, homogeneity means that all time series are simulated from the same DGP with

diﬀerent seeds. The multiple series scenarios can be made heterogeneous by combining time series

generated from diﬀerent DGPs into a single dataset. Diﬀerent patterns can also be created using the

same DGP by adding Gaussian noise over the coeﬃcients. Thus, the heterogeneity experiments are

performed using all DGPs, by generating each simulated time series from a new set of coeﬃcients.

2.4. Amount of Data Available

We also control the availability of data by changing the lengths of the individual series or varying

the number of series in the dataset. For single series and multiple series scenarios, this is performed

using two diﬀerent setups.

1. Single Series Scenarios - Varying the length of the series

2. Multiple Series Scenarios

(a) Homogeneous Patterns - Varying the lengths of the series, Varying the number of series

(b) Heterogeneous Patterns - Varying the lengths of the series

For the single series scenario, we can only change the length of the single series. However, for the

multiple series scenarios with a single pattern (homogeneous), we simulate both with varying number of

series and varying lengths of the series. For the multiple series scenarios with heterogeneous patterns,

we only vary the amount of data by changing the lengths of the series.

Based on the diﬀerent experimental considerations relevant to each DGP, such as data heterogeneity

or single and multiple series inclusion, we introduce the terminology summarised in Table 1 that is

used throughout the rest of this paper.

2.5. Complexity of Forecasting Techniques

The modelling capability of models is varied by conducting experiments using a number of tech-

niques with diﬀerent attributes as explained more under Section 4. The complexity of these base

7

Abbreviation
SS
MS-Hom-Short Many Series Homogeneous with Short Lengths
MS-Hom-Long Many Series Homogeneous with Long Lengths
MS-Het

Meaning
Single Series

Many Series Heterogeneous

Table 1: Explanations of Abbreviations

models can be further increased by using two techniques. The ﬁrst is by increasing the number of pa-

rameters in the model. For NNs, the hyperparameters are tuned by using automated hyperparameter

tuning techniques. However, the size of the input window can be increased as required to improve

the complexity. For pooled regression models this can be done by increasing the lag size. The second

approach is to introduce diﬀerent training paradigms for global models as mentioned below.

1. GFM.All: Where the global models are trained using all the series available in the dataset irre-

spective of their potential heterogeneity. This setup is used in all the multiple series experimental

scenarios.

2. GFM.GroupFeature: Where the global models are trained using all the series available in the

dataset similar to the GFM.All setup, but in addition to the time series data, every input has

an additional feature to indicate which subgroup the particular series belongs to. This approach

is used to attend to existing heterogeneity in the data. It can act as an implicit clustering of the

data by giving information to the models of the existence of diﬀerent subgroups. However, this

training paradigm is irrelevant for the heterogeneous setting that we described before, since none

of the series in the dataset share coeﬃcients. Therefore, we introduce a separate experimental

scenario named Group Feature setup where we mix few patterns from each DGP within a dataset.

The GFM.All setup is the base setup. The GFM.GroupFeature setup is expected to increase the

complexity of the GFM.All setup.

3. Data Generating Processes

Generating synthetic datasets is a heavily used approach in many domains to evaluate the perfor-

mance of diﬀerent algorithms, against other benchmarks. Our interest in this study lies speciﬁcally

around those methods that can generate time series with controllable features, rather than random

generation processes. In this section we ﬁrst mention several related work of time series simulation

and then move on to explain the diﬀerent DGPs used in our study.

8

Domain

Time Series Classiﬁcation

Time Series Forecasting

Machine Learning

Literature
Sun et al. (2019)
Zhao and Itti (2018)
Bergmeir and Ben´ıtez (2012)
Bergmeir et al. (2018)
Hyndman et al. (2002)
Petropoulos et al. (2014)
Lau and Wu (2008)
Ye and Dai (2021)
Vanli et al. (2019)
Fischer et al. (2018)
Zhang and Qi (2005)
Zhang (2007)
Zhang et al. (2001)
Suhartono et al. (2018)

Table 2: Related Work of Time Series Simulation in Diﬀerent Domains

3.1. Background

Table 2 summarises the literature related to time series simulation in diﬀerent domains. For more

detailed explanations refer to Appendix A.1 of our Online Appendix. However, most of the work

present in the literature builds univariate models for forecasting as opposed to global forecasting

models. Most importantly, none of these studies clearly investigates how the simplicity/complexity of

the series, complexity of the models, the heterogeneity/homogeneity of the data or the amount of data

overall/per series aﬀects the forecasting performance of global models. On the other hand, many of

the recent studies involving global forecasting models such as RNNs, claim that global models only

work with sets of related time series (Salinas et al., 2019; Wen et al., 2017b; Bandara et al., 2019;

Januschowski et al., 2020). The study by Bandara et al. (2020b) uses special clustering mechanisms

to group the related time series together to build global models on every cluster. Yet, the notion

of relatedness is not well-understood in many of these contexts. No proper eﬀorts have been made

to analyse these terms within controlled experimental settings. Therefore, in this study, we strive to

explore the eﬀect of these diﬀerent factors for building global forecasting models in comparison to

other state-of-the-art univariate forecasting benchmarks.

3.2. Data Generating Processes Used for the Study

The experimental settings of our study involve scenarios with simple/complex patterns, homoge-

neous/heterogeneous series, varying number of series, and varying series lengths, as described under

Section 2. The DGPs that we use for the study are selected such that they can simulate practical fore-

casting scenarios as closely as possible. We start from the simplest forms of DGPs, which are linear

9

DGPs with short memory. Then, we gradually make them more complex by increasing the num-

ber of lags to have linear DGPs with longer memory. Next, we introduce more complex, non-linear

DGPs namely, a threshold linear model that switches between diﬀerent linear models based on certain

conditions, a chaotic model and another delay diﬀerential equation based model, the Mackey-Glass

Equations. This section gives details of these DGPs that we use for our experiments in order to control

the complexity of the patterns in the data. Further details corresponding to every DGP can be found

under Appendix A.2 of our Online Appendix.

3.2.1. Linear Auto-Regressive Models

We ﬁrst simulate series using AR models. ARIMA models attempt to model the autocorrelation

in the data (Hyndman and Athanasopoulos, 2018). AR models use a linear combination of the past

values of the target series itself as regressors to predict the future values. MA models, on the other

hand, model the future in terms of a linear combination of the past forecast errors. AR and MA

models, once combined together with suﬃcient diﬀerencing of the time series to achieve stationarity,

are called ARIMA models. The number of lags used for the AR model (p) and the MA model (q)

and the amount of diﬀerencing (d) deﬁnes the complexity of the underlying ARIMA model. ARMA

models can be approximated by pure AR models using many lags (Kang et al., 2020). In this study,

we generate series from AR models to enforce linear relationships in the simulated data. For the

convenience of explanation, we ﬁrst introduce the backshift operator as in Equation 1.

Byt = yt−1

B(Byt) = B2yt = yt−2

(1)

The backshift operator on the variable yt is used to denote its lags.

3.2.1.1 Non-Seasonal Auto-Regressive Models

Equation 2 deﬁnes a non-seasonal AR model of order p using the backshift operator.

yt = c + φ1Byt + φ2B2yt + φ3B3yt + ... + φpBpyt + (cid:15)t

(2)

Here, (cid:15)t indicates a white noise error term, which is the error in the AR modelling, and c is a

constant term which is also known as the intercept. As Equation 2 shows, an AR model is a simple

10

linear regression model where the past lags are the predictors of the value of the series at the tth time

step. Therefore, AR DGPs can simulate those time series common in the real world where the value

at a certain time is a (linear) function of its own past values. Given a particular time series, the

coeﬃcients φ1, φ2, ..., φp are estimated to ﬁt an AR model by minimising a loss criterion such as the

Maximum Likelihood Estimation (MLE). Similarly, given the values for the coeﬃcients φ1, φ2, ..., φp of

the diﬀerent lags, the AR model can simulate series. In this study, we use an AR(3) DGP to simulate

simple linear patterns in the time series data. We use the arima.sim function from the stats package

of the R core libraries (R Core Team, 2020) to simulate series using AR(3) DGP.

3.2.1.2 Seasonal Auto-Regressive Models

To make the patterns more complex, we also simulate series using an SAR model. Equation 3 shows

such an SAR model of order P , where the period is denoted by S.

yt = c + Φ1BSyt + Φ2B2Syt + Φ3B3Syt + ... + ΦP BP Syt + (cid:15)t

(3)

Comparing Equation 2 with Equation 3, in the Seasonal AR model, the predictor variables are now

seasonal lags as opposed to normal lags as in the non-seasonal AR model. Therefore, the Seasonal AR

model is a regression model where the predictor variables are seasonal lags of the time series. Thus,

an SAR DGP can simulate time series having a seasonality of a particular periodicity which are also

very commonly seen in real-world scenarios. Similar to the non-seasonal AR model, given the values

of the coeﬃcients Φ1, Φ2, ..., Φp, the model can simulate new time series. However, unlike in simple

AR models, since it is the seasonal lags that are signiﬁcant in the SAR models, they account for much

longer-term dependencies, thus generating series with longer memory. In our study, to generate series

with SAR models, we ﬁrst ﬁt an SAR model of order 1 to the USAccDeaths monthly series of the

datasets package (R Core Team, 2020) available in the R core libraries. Then, we use this model to

simulate series using the simulate function of the forecast package (Hyndman et al., 2020).

3.2.2. Chaotic Logistic Map

The Chaotic Logistic Map DGP is another technique used in this study to generate more complex

patterns in the time series data. This type of logistic models were ﬁrst introduced in biological research

to describe the population growth of certain species over time (May, 1976). Chaos theory is used in

mathematics to deal with heavily non-linear dynamical systems. Thus, Chaotic Logistic Maps are well-

11

suited techniques for simulating non-linear characteristics in time series which can also be found in

the real world. The DGP used in this study generates data as per Equation 4. This is a zero-bounded

chaotic process where (cid:15)t indicates a white noise error term. r is the coeﬃcient of the model.

(cid:16)

yt = max

ryt−1 (1 − yt−1) +

(cid:17)

, 0

(cid:15)t
10

(4)

3.2.3. Self-Exciting Threshold AutoRegressive Models

The SETAR model is also a technique used for simulating complex patterns. This model belongs

to the family of TAR models, ﬁrst introduced by Tong (1978). A TAR model is deﬁned as in Equation

5.

yt =






c1 + φ1

1Byt + φ1

2B2yt + φ1

3B3yt + ... + φ1

pBpyt + (cid:15)t,

c2 + φ2

1Byt + φ2

2B2yt + φ2

3B3yt + ... + φ2

pBpyt + (cid:15)t,

...

ck + φk

1Byt + φk

2B2yt + φk

3B3yt + ... + φk

pBpyt + (cid:15)t,

if zt ≤ r1

if r1 ≤ zt ≤ r2

if rk−1 ≤ zt

(5)

According to Equation 5, the TAR model involves k −1 number of threshold values (r1, r2, ..., rk−1),

which separate the space into k regimes, where each one is modelled by a diﬀerent AR process of order p.

The threshold variable is denoted by zt which is an exogenous variable. Therefore, in contrast to linear

AR models, TAR models capture non-linear dynamics in time series by means of a regime-switching

technique that changes the underlying AR coeﬃcients, when a particular threshold value is met. When

the threshold variable zt is a lagged value of the series itself (denoted by yt−d, where d is the delay

parameter), the model is known as a SETAR model. The SETAR models were ﬁrst introduced by

Tong and Lim (1980). Due to their regime-switching nature, SETAR models can capture, for example,

real-world scenarios where patterns of a certain time series change due to policy interventions upon

reaching a certain threshold value in the time series. For this study, we use the simulation capability

of SETAR models implemented in the setar.sim function of the tsDyn R package (Fabio Di Narzo

et al., 2019).

3.2.4. Mackey-Glass Equation

The Mackey-Glass Equation forms another DGP that can be used to simulate complex patterns

in time series data. This equation was ﬁrst introduced in a research studying ﬁrst-order non-linear

12

Simulation Technique
AR(3)

SAR(1)

Chaotic Logistic Map
SETAR
Mackey-Glass Equation

Function
arima.sim
simulate
sim.ssarima
-
setar.sim
data.mackey glass

Package
stats (R Core Team, 2020)
forecast (Hyndman et al., 2020)
smooth (Svetunkov, 2019)
-
tsDyn (Fabio Di Narzo et al., 2019)
nolitsa (Mannattil, 2017)

Linearity
(cid:88)

(cid:88)

(cid:55)
(cid:55)
(cid:55)

Table 3: Summary of Techniques Used for Time Series Simulation

Diﬀerential-Delay Equations (DDE) which describe physiological control systems (Mackey and Glass,

1977). The Mackey-Glass Equation was speciﬁcally used to explain the ﬂuctuations of white blood

cells in the human body under certain cases of chronic leukemia. The solutions of these DDEs can be

chaotic and thus cause complexity in the underlying time series. The Mackey-Glass equation is deﬁned

as in Equation 6.

dyt
dt

=

βyt−τ
1 + yn

t−τ

− γyt

(6)

In Equation 6, τ is called the delay whereas β, γ, n > 0 are parameters that determine the periodicity

and the chaos induced into the resulting series. Following from Equation 6, the solution to the Mackey-

Glass equation is as shown in Equation 7. Therefore, Equation 7 can be directly used to simulate

complex time series. For this study we use the Mackey-Glass based time series generation implemented

in the nolitsa Python package (Mannattil, 2017).

yt+1 = yt +

βyt−τ
1 + yn

t−τ

− γyt

(7)

Table 3 provides an overall summary of the aforementioned techniques used for time series sim-

ulation. Here, the Function and Package columns provide the references to the respective software

implementations of the simulation techniques used in our experiments. The Chaotic Logistic Map

DGP is implemented by ourselves and does not involve any already existing software packages. The

table furthermore indicates a characterisation of the generated time series in terms of their linearity.

4. Forecasting Framework

Depending on the speciﬁc experimental scenario, we train models either as univariate models or

global forecasting models. In this section, the details of the diﬀerent forecasting techniques employed

are explained along with their associated data preprocessing methodologies, model training and testing.

13

4.1. Forecasting Techniques

For the forecasting techniques of the study, we use RNNs, FFNNs, PR models, LGBMs, AR,

SETAR and SAR models as appropriate. The details of these techniques are as follows. Further

details can be found under Appendix B of our Online Appendix.

4.1.1. Recurrent Neural Networks

Figure 2: Recurrent Neural Network with Residual Connections

RNNs are a type of NNs that are specialised for sequence modelling problems due to their states

which are propagated up to the end of the sequence and thus help them distinguish between every

individual series among a set of series. Like other NNs, RNNs too are univeral approximators meaning

that they are inherently non-linear models (Sch¨afer and Zimmermann, 2006). RNNs can be imple-

mented with many diﬀerent architectures. In the study by Hewamalage et al. (2020), those authors

have identiﬁed the Stacked architecture as the generally best RNN architecture across a number of

real-world datasets. Therefore, in this study we choose that same architecture along with residual con-

nections. Residual connections were introduced by He et al. (2016) on CNNs mainly for the purpose of

image recognition. Such networks were named as Residual Nets (ResNets). However, later many other

14

domains were inspired by this architecture and implemented diﬀerent modiﬁed versions of it for their

own work. For the time series forecasting domain, Smyl and Kuber (2016) used residual connections

on RNN layers. Moreover, the winning solution by Smyl (2020) at the M4 forecasting competition

also involved RNNs with residual connections. Inspired by this work, we use an architecture similar to

the work of Smyl and Kuber (2016) in our study. In particular, our RNN architecture is illustrated in

Figure 2. The recurrent unit used for the RNN layers in this study is the Long Short-Term Memory

(LSTM) cell with peephole connections introduced by Gers et al. (2003). The residual connections

are especially helpful to avoid vanishing gradient issues of the layers of NNs. The RNNs used for this

study are implemented with version 2.0 of the Tensorﬂow open-source deep learning framework (Abadi

et al., 2015).

4.1.2. Feed-Forward Neural Networks

An FFNN can be described as the most basic type of an NN. The neurons within a single layer

of an FFNN have no feedback connections as in an RNN and the neurons of each layer feed their

outputs directly into the next immediate layer of the stack. Thus, FFNNs, when used for forecasting

problems as described here, do not diﬀerentiate between individual time series as an RNN, since they

do not have per-series states that propagate towards the end of the series. FFNNs can only distinguish

between windows when used in a moving window scheme. The basic architecture of an FFNN is

as illustrated in Figure 3. The FFNNs used for this study are implemented with version 2.0 of the

Tensorﬂow open-source deep learning framework (Abadi et al., 2015).

Figure 3: Feed-Forward Neural Network

15

4.1.3. Light Gradient Boosting Models

We also use LGBMs in our study as another forecasting technique. Extreme Gradient Boosting

(XGBoost) models (Chen and Guestrin, 2016) recently have become popular by winning many ML

related challenges. Gradient Boosting Models (GBM) are a type of ML algorithms based on decision

trees and can be used to solve a wide range of ML problems including regression, classiﬁcation, and

others. Due to the non-linear nature of decision trees, which is the fundamental building block of

LGBMs, they too are non-linear models.

The competitive performance of LGBMs when used for forecasting has been most recently demon-

strated at the M5 Forecasting Competition, where an LGBM-based solution won the ﬁrst place followed

by many other LGBM-based solutions securing top ranks (Makridakis et al., 2020b). However, similar

to FFNNs, LGBMs by default have no notion of the individual series of a dataset, when used for fore-

casting. They are only aware of the windows and they do not remember anything beyond what they

see immediately within this input window. In our study we use the LGBM implementation available

in the Python package lightgbm (Ke et al., 2017).

4.1.4. Linear Auto-Regressive Models

We also use univariate AR models, both non-seasonal and seasonal as other forecasting techniques

in the study. The modelling process of these AR models is the same as described by Equations 2

and 3 in the format of DGPs. AR models are linear in the lags of the target series. To implement

the AR and SAR models for forecasting, we use the Arima function of the forecast package in the

R programming language by providing the required seasonal or non-seasonal orders (Hyndman et al.,

2020).

4.1.5. Self-Exciting Threshold Auto-Regressive Models

For the scenarios involving the datasets generated from the SETAR DGP, we also experiment with

SETAR as a forecasting technique. The underlying modelling process of the SETAR forecast model

is as described in Equation 5 under Section 3.2.3 for the DGPs. Due to the inherent regime-switching

nature, SETAR is a non-linear forecast model. In this study, to implement the SETAR models we use

the setar function from the tsDyn package in the R programming language (Fabio Di Narzo et al.,

2019).

16

Forecasting Technique

RNN

FFNN
LGBM

SETAR

PR

AR

Software Details

Tensorflow Framework (Abadi et al., 2015)

Attributes
Non-linear Modelling
Per Series State
Non-linear Modelling
Non-linear Modelling
tsDyn R Package (Fabio Di Narzo et al., 2019) Non-linear Modelling

Tensorflow Framework (Abadi et al., 2015)
lightgbm Python Package (Ke et al., 2017)

(setar function)
stats R Package (R Core Team, 2020)
(glm function)
forecast R Package (Hyndman et al., 2020)
(Arima function)

Linear Modelling

Linear Modelling

Table 4: Summary of Forecasting Techniques

4.1.6. Pooled Regression Models

We implement PR models similar to the work of Trapero et al. (2015) as another forecasting

technique for the study. The PR model is eﬀectively a global version of an AR model. The term

pooling indicates that the coeﬃcients of such regression models are calculated by pooling across many

series. However, compared with, e.g., RNNs, the pooled regression models can only capture linear

relationships in the data. Also, similar to FFNNs, PR models also do not maintain a state per every

time series in the dataset. A PR model of order p can be deﬁned as in Equation 8. This equation is

the same as in Equation 2 for the non-seasonal AR model, except now the coeﬃcients Θ are calculated

by pooling across all the series in the dataset.

yt = c + Θ1Byt + Θ2B2yt + Θ3B3yt + ... + ΘpBpyt + (cid:15)t

(8)

PR models in this context are used to distinguish potential gains of using RNNs as opposed to linear

models as global models. The PR models may also assist in identifying accuracy gains from purely

using cross-series information without any complex architectural additions from RNNs (Hewamalage

et al., 2020). To implement the PR models, we use the glm function in the stats package of the R

core libraries (R Core Team, 2020).

The summary of all the forecasting techniques used for the study along with their respective

attributes as well as the corresponding software details are available in Table 4.

4.2. Data Preprocessing for Forecasting

We apply a number of data preprocessing steps to the data corresponding to the diﬀerent forecasting

techniques. 1) We ﬁrst perform a normalization of each series to avoid the varying scales of the series,

especially when developing a global model. 2) Then, we perform a logarithmic transformation of the

17

series in order to avoid non-stationarities in time series data such as exponential trends that machine

learning models cannot handle properly. 3) Next, to produce a forecast horizon, we perform a moving

window transformation of the data speciﬁcally for those models that can output windows; other models

use either a recursive startegy or train one model per each step in the horizon. 4) Finally, to further

reduce risks from remaining linear trends, a per-window normalization is applied to the data which is

ﬁrst moving window transformed. A detailed description of all the preprocessing steps can be found

in Appendix C of the Online Appendix.

4.3. Model Training & Testing

RNNs in this study use the COntinuous COin Betting (COCOB) optimiser introduced by Orabona

and Tommasi (2017) as the underlying learning algorithm where as FFNNs use the well-known Adam

optimiser (Kingma and Ba, 2015). For more details related to model training such as the hyperpa-

rameter tuning, loss functions used as well as the validation setups, refer to Appendix B of the Online

Appendix. For the NNs, once the optimal hyperparameters are found, they are applied for training the

NNs once again and testing on the test data. During testing, the NNs are trained using 10 Tensorﬂow

graph seeds and then the ﬁnal NN forecasts are ensembled by taking the median, as discussed by

Hewamalage et al. (2020). This approach eﬀectively addresses the parameter uncertainty associated

with the NNs by initialising the networks 10 times independently.

For all the other models, once the model training is completed, the trained models are then used

to perform the forecasting on the intended forecast horizon. As mentioned before, even though AR,

SETAR and PR models train using one-step-ahead forecasts, during testing an output window is

formed by performing a recursive strategy. LGBMs achieve the same objective by having one model

per each step in the horizon.

4.4. Data Postprocessing

Once the forecasts are obtained from each individual model, a sequence of postprocessing is done

on the forecasts, to reverse the preprocessing steps that were carried out on the data beforehand. This

is done in the following order: 1) Add the last input point trend value back into the corresponding

output windows. 2) Transform the data by taking the exponential. 3) Deduct 1, in case the original

data contains zero values. 4) Re-scale the forecasts by multiplying by the series means. However, the

exact postprocessing steps performed on the forecasts of each model, depend on which preprocessing

was done in the beginning.

18

5. Experimental Setup

This section details the experimental framework used in this study. To achieve signiﬁcant results,

for every scenario we generate 1000 datasets having the described characteristics and average the

results over 1000 runs. In the rest of this section, we present the details of the datasets generation,

error metrics used for the evaluation and the statistical tests conducted for the signiﬁcance of the

diﬀerences.

5.1. Generation of Datasets

The characteristics of diﬀerent datasets generated from all DGPs according to the experimental

scenarios explained in Section 2, are shown in Table 5. Here, the Min. Length and Max. Length columns

refer to the range of the time series lengths we select when training our models. Similarly, Min. No.

of Series and Max. No. of Series is the range of number of time series we use in our experiments.

Scenario

SS
MS-Hom-Short
MS-Hom-Long
MS-Het

SS
MS-Hom-Short
MS-Hom-Long
MS-Het

SS
MS-Hom-Short
MS-Hom-Long
MS-Het

SS
MS-Hom-Short
MS-Hom-Long
MS-Het

SS
MS-Hom-Short
MS-Hom-Long
MS-Het

No. of DGPs Min. Length Max. Length Min. No. of Series Max. No. of Series
AR(3) DGP

Forecast Horizon

1
1
1
100

1
1
1
100

1
1
1
100

1
1
1
100

1
1
1
100

18
18
18
18

24
24
24
24

60
60
60
60

6000
60
240
240

6000
60
240
240

1800
18
180
180

SAR(1) DGP

1
1
100
100

2400
24
240
240

1
1
100
100
Chaotic Logistic Map DGP
1
1
100
100

6000
60
600
600

SETAR DGP

6000
60
240
240

1
100
100
100
Mackey-Glass Equation DGP

6000
60
240
240

1
100
100
100

1
100
100
100

1
100
100
100

1
100
100
100

1
100
100
100

1
100
100
100

3
3
3
3

3
3
3
3

12
12
12
12

12
12
12
12

12
12
12
12

Table 5: Characteristics of Generated Datasets from All DGPs

Due to computational constraints arising from the variety of experiments designed, out of the

ﬁve DGPs used in the study, we perform the data availability experiments only using three DGPs,

namely AR(3), SAR(1) and Chaotic Logistic Map. For SETAR and Mackey-Glass Equation DGPs,

we experiment using only one selected length and number of series as shown in Table 5. Here, the idea

is that once the important conclusions are drawn about data availability in initial experiments, those

conclusions can be used to ﬁx a suﬃcient length and the number of series for the remaining experiments.

19

Characteristic
No. of DGPs
Min. Length
Max. Length
Min. No. of Series
Max. No. of Series
Forecast Horizon

Value
4
600
600
100
100
12

Table 6: Characteristics of Generated Datasets for the Group Feature Setup of the Chaotic Logistic Map DGP

Also, due to the computational constraints, we perform the Group Feature setup experiments only using

the Chaotic Logistic Map DGP. In Table 6, are the characteristics of the datasets generated for this

Group Feature setup of the Chaotic Logistic Map DGP.

We also drop the number of datatsets associated with each scenario to 100, to avoid heavy compu-

tational complexities of this study. This applies to the experiments on the two DGPs, Mackey-Glass

Equation and SETAR and the Group Feature setup of the Chaotic Logistic Map DGP.

5.2. Performance Measures

The relative performance of the models is evaluated with respect to two performance measures

commonly found in the literature related to forecasting, namely SMAPE and Mean Absolute Scaled

Error (MASE). Further details of the error measures can be found under Appendix D of the Online

Appendix. However, According to, e.g., Hyndman and Koehler (2006), the SMAPE metric is highly

skewed with values close to zero. Therefore, as per the guidelines by Hewamalage et al. (2020), on the

Chaotic Logistic Map DGP datasets which have zero values, we use a variant of SMAPE to address

this problem. Since our forecasting scenarios involve multiple series from many datasets, we consider

the mean SMAPE and mean MASE measures to summarise the overall error distribution across all

the series available.

5.3. Statistical Tests for Signiﬁcance of the Diﬀerences

The objective behind performing every experiment on 100/1000 datasets is that the individual

diﬀerences between the models are signiﬁcant for every scenario that way. However, to show sys-

tematically that this is the case, we perform non-parametric Friedman rank-sum tests on few of the

most important scenarios as explained in Section 6, to estimate the signiﬁcance of diﬀerences. This

is followed by Hochberg’s post hoc procedure to further analyse the diﬀerences relative to a control

method, in particular the best method in every scenario (Garc´ıa et al., 2010). A signiﬁcance level of

α = 0.05 is used for all the tests.

20

6. Results and Analysis

This section provides a detailed analysis of the results obtained for diﬀerent experimental setups.

Furthermore, we provide a comparison of the computational complexities of various forecasting variants

employed in this study.

6.1. Comparison of Model Performance

The results of all the DGPs as well as the percentage diﬀerence of every model from the best model

in each scenario computed according to Equation 9 are presented in Table 7 under the Error and Diﬀ

columns. In Equation 9, Dm is the percentage diﬀerence of the performance of model m, Em is the

error of model m and Eb is the error of the best model in the respective scenario.

Dm = 100 ∗

Em − Eb
Eb

(9)

In every column of Table 7, the best-performing model under every DGP is indicated in boldface.

Not all the models are relevant to all the experimental setups; hence the ‘-’ in some of the table cells.

Since PR models are the global versions of AR models, we run only the AR models in the SS scenarios.

For the relevant models, we also indicate the number of lags used to train the model. For example,

LGBM(3) refers to an LGBM model with an order of 3 lags. Although we conduct experiments

for data availability for some of the DGPs, the numbers shown in Table 7 correspond only to the

highest length/number of series in each scenario as per Table 5. For more results analysis details,

data availability experiment results as well as further details on the Hochberg’s post-hoc procedures

of diﬀerent scenarios, refer to Appendix F of the Online Appendix.

6.1.1. AR(3) Data Generating Process

Figure 4 illustrates how the performance of the forecasting models under the AR(3) DGP setting

evolve with increasing lengths and number of series.

In Table 7, under the SS scenario of the AR(3) DGP, the AR(3) model performs the best, with

the AR(2) being the second and the AR(10) the third, with respect to mean SMAPE. This is not

surprising as AR(3) is the model of the true underlying DGP. Since AR(3) DGP is a subclass of the

AR(10) forecast model, the training process of the AR(10) model resolves to training the coeﬃcients

beyond the third lag close to 0. However, when looking at the SS scenario in Figure 4, we can see that

at the beginning lengths, the AR(2) model is better than the AR(3). For the SS scenario of the AR(3)

21

E
S
A
M

E
P
A
M
S

E
S
A
M

E
P
A
M
S

E
S
A
M

E
P
A
M
S

E
S
A
M

E
P
A
M
S

i

ﬀ
D

r
o
r
r
E

i

ﬀ
D

r
o
r
r
E

i

ﬀ
D

r
o
r
r
E

i

ﬀ
D

r
o
r
r
E

i

ﬀ
D

r
o
r
r
E

i

ﬀ
D

r
o
r
r
E

i

ﬀ
D

r
o
r
r
E

i

ﬀ
D

r
o
r
r
E

t
e
H
-
S
M

g
n
o
L
-
m
o
H
-
S
M

t
r
o
h
S
-
m
o
H
-
S
M

S
S

l
e
d
o
M

P
G
D
)
3
(
R
A

6
1
.
3
1

8
5
.
6

4
7
.
9
1

7
4
.
4
1

2
4
.
8
1

4
8
.
1
1

6
1
.
3
1

6
1
.
3
1

0
0
.
0

0
0
.
0

3
6
.
2

1
7
.
5

0
0
.
0
1

7
5
.
8

1
7
.
5

6
8
.
2

1
7
.
5

0
0
.
0

0
0
.
0

7
2
.
2

0
0
.
0

0
0
.
0

0
0
.
0

0
0
.
0

2
2
.
2

0
0
.
0

4
4
.
4

7
6
.
6

3
3
.
3
1

0
0
.
0

1
7
.
1
1
1

4
2
.
3
4

8
4
.
7
7

6
9
.
3
6

6
8
.
0

1
8
.
0

1
9
.
0

7
8
.
0

0
9
.
0

5
8
.
0

6
8
.
0

6
8
.
0

6
7
.
0

6
7
.
0

8
7
.
0

4
7
.
0

7
7
.
0

6
7
.
0

4
7
.
0

2
7
.
0

4
7
.
0

8
2
.
9

7
7
.
4

6
1
.
7
1

4
4
.
1
1

6
8
.
6
1

3
6
.
9

8
9
.
8

8
9
.
8

0
0
.
0

0
1
.
0

6
0
.
2

8
4
.
4

0
4
.
8

4
7
.
7

7
8
.
3

2
1
.
2

9
2
.
4

8
7
.
1
2

8
8
.
0
2

5
3
.
3
2

1
2
.
2
2

9
2
.
3
2

5
8
.
1
2

2
7
.
1
2

2
7
.
1
2

3
9
.
9
1

5
9
.
9
1

4
3
.
0
2

5
1
.
2
2

8
9
.
2
2

4
8
.
2
2

2
0
.
2
2

5
6
.
1
2

1
1
.
2
2

0
7
.
0

0
0
.
0

0
2
.
1
2

8
8
.
0

0
9
.
0

8
8
.
0

8
8
.
0

8
8
.
0

5
4
.
0

6
4
.
0

5
4
.
0

7
4
.
0

8
4
.
0

1
5
.
0

1
1
.
1

5
3
.
2

9
5
.
1

7
9
.
1

2
8
.
1

3
3
.
0

6
6
.
2

0
0
.
0

6
6
.
0

0
4
.
0

3
4
.
0

0
7
.
0

0
0
.
0

9
2
.
3

9
1
.
5

0
7
.
2
1

0
0
.
0

4
8
.
7
0
1

6
8
.
1
4

8
7
.
6
7

0
8
.
0
6

4
5
.
7
2

8
1
.
8
2

5
4
.
7
2

3
6
.
7
2

6
5
.
7
2

3
9
.
5
2

0
0
.
6
2

2
8
.
5
2

7
6
.
6
2

6
1
.
7
2

0
1
.
9
2

6
7
.
6

5
0
.
4
1

9
5
.
9

5
9
.
1
1

7
8
.
0
1

9
8
.
1

0
0
.
0

3
4
.
9

7
7
.
3

3
4
.
9

7
7
.
3

0
0
.
0

0
0
.
0

0
0
.
0

0
0
.
0

9
8
.
1

2
2
.
7

0
0
.
0

3
0
.
1

0
0
.
0

6
0
.
2

4
5
.
4
8

0
0
.
0

2
8
.
2

1
4
.
1

0
0
.
0

6
8
.
9

7
2
.
1
1

0
0
.
0

4
4
.
2

4
4
.
2

8
8
.
4

2
3
.
7

2
3
.
7

4
1
.
7
5
1

4
1
.
7
5
4

0
0
.
0

4
1
.
7
5
5
1

0
0
.
0
0
6
1

4
5
.
0

3
5
.
0

8
5
.
0

5
5
.
0

8
5
.
0

5
5
.
0

3
5
.
0

3
5
.
0

3
5
.
0

3
5
.
0

4
5
.
0

4
0
.
1

7
9
.
0

8
9
.
0

7
9
.
0

9
9
.
0

9
7
.
1

7
9
.
0

3
7
.
0

2
7
.
0

1
7
.
0

8
7
.
0

9
7
.
0

1
4
.
0

2
4
.
0

2
4
.
0

3
4
.
0

4
4
.
0

4
4
.
0

8
1
.
0

9
3
.
0

7
0
.
0

6
1
.
1

9
1
.
1

2
4
.
1

1
7
.
0

4
4
.
9

5
6
.
3

9
4
.
9

8
0
.
3

0
0
.
0

5
0
.
0

7
4
.
0

1
7
.
0

6
6
.
2

5
4
.
6

0
3
.
0

3
8
.
0

8
0
.
0

5
3
.
2

4
5
.
7
7

0
0
.
0

2
8
.
2

0
5
.
1

0
0
.
0

9
0
.
2
1

0
5
.
2
1

0
0
.
0

8
6
.
0

1
5
.
0

6
4
.
3

0
0
.
6

5
1
.
8

8
0
.
1
2

7
1
.
1
2

2
2
.
1
2

3
6
.
1
2

3
0
.
4
1

2
2
.
3
1

9
2
.
3
1

9
1
.
3
1

9
4
.
3
1

0
4
.
3
2

8
1
.
3
1

7
3
.
1
2

2
2
.
1
2

6
0
.
3
2

4
8
.
1
2

7
0
.
3
2

2
7
.
1
2

7
6
.
1

-

7
6
.
6

-

3
3
.
8

-

7
0
.
1
2

0
0
.
0

-

0
0
.
5

0
0
.
0
1

7
6
.
1
7

1
6
.
0

-

4
6
.
0

-

5
6
.
0

-

0
6
.
0

-

3
6
.
0

6
6
.
0

3
0
.
1

P
G
D
)
1
(
R
A
S

7
9
.
0

0
0
.
0

0
8
.
6

4
9
.
1

7
3
.
4
5

7
4
.
4
8

7
9
.
0

4
0
.
1

3
0
.
1

0
1
.
1

5
0
.
1

9
5
.
1

0
9
.
1

4
0
.
1

2
3
.
2

-

8
7
.
6

-

0
7
.
8

-

-

0
1
.
6

8
2
.
0
1

8
8
.
5
8

2
8
.
0

0
0
.
0

9
7
.
6

4
4
.
1

3
2
.
8
5

2
7
.
2
8

2
8
.
0

P
G
D
p
a
M

c
i
t
s
i
g
o
L

c
i
t
o
a
h
C

2
1
.
8
4

0
5
.
7
4

0
8
.
6
4

6
4
.
2
5

5
6
.
2
5

8
6
.
3
2

4
8
.
3
2

0
8
.
3
2

0
5
.
4
2

0
1
.
5
2

1
6
.
5
2

0
0
.
0

7
6
.
2

7
6
.
2

0
0
.
8

7
6
.
8
1

5
7
.
0

7
7
.
0

7
7
.
0

1
8
.
0

9
8
.
0

P
G
D
R
A
T
E
S

0
0
.
0

4
4
.
2

8
8
.
4

8
8
.
4

7
0
.
7
1

2
3
.
7

1
4
.
0

2
4
.
0

3
4
.
0

3
4
.
0

8
4
.
0

4
4
.
0

0
0
.
0

1
9
.
1

8
4
.
2

5
4
.
8

9
1
.
7
1

0
0
.
0

8
5
.
0

3
5
.
2

1
1
.
3

4
1
.
6
1

2
2
.
8

7
6
.
6
6
1

6
5
.
5
7
4

0
0
.
0

7
6
.
6
2
6
1

6
5
.
5
7
6
1

0
2
.
1

9
5
.
2

5
4
.
0

7
7
.
7

9
9
.
7

3
2
.
9
6

2
6
.
4
8

0
0
.
0

8
3
.
5
1
7

5
1
.
6
4
9

2
2
.
0

4
2
.
0

3
1
.
0

6
0
.
1

6
3
.
1

7
1
.
5
6

0
9
.
0
8

0
0
.
0

2
1
.
1
0
7

6
9
.
5
3
9

P
G
D
n
o
i
t
a
u
q
E
s
s
a
l
G
-
y
e
k
c
a
M

-

-

9
7
.
8
1

3
5
.
9
1

2
9
.
2
3

0
9
.
4

6
8
.
4

9
1
.
5

3
9
.
4

9
6
.
7

8
8
.
8

0
9
.
4

1
2
.
9
4

5
1
.
0
5

3
4
.
0
5

7
3
.
3
5

7
6
.
7
5

7
5
.
0
2

9
6
.
0
2

9
0
.
1
2

1
2
.
1
2

9
8
.
3
2

6
2
.
2
2

7
4
.
1

1
6
.
1

9
8
.
0

3
1
.
7

2
2
.
9

-

-

-

0
0
.
0

0
0
.
0

9
8
.
1

9
1
.
3

6
2
.
4

2
3
.
5

-

0
0
.
0

3
2
.
7
8

0
0
.
0

1
4
.
5

6
4
.
9

0
0
.
0

-

6
7
.
6

3
6
.
4
1

4
4
.
2

0
0
.
0

-

8
8
.
4

0
0
.
0

3
3
.
3
3
4

1
1
.
1
1
8

0
0
.
0

-

5
5
.
0

-

8
5
.
0

-

9
5
.
0

-

-

-

3
5
.
0

3
5
.
0

4
5
.
0

7
9
.
0

8
9
.
0

9
9
.
0

-

4
9
.
0

6
7
.
1

4
9
.
0

8
7
.
0

1
8
.
0

4
7
.
0

-

9
7
.
0

7
4
.
0

2
4
.
0

1
4
.
0

-

3
4
.
0

1
4
.
0

8
4
.
0

2
8
.
0

9
0
.
0

-

-

-

-

6
0
.
0

0
0
.
0

6
4
.
0

7
3
.
3

0
0
.
4

6
2
.
5

-

2
4
.
0

3
5
.
6
8

0
0
.
0

2
5
.
5

7
8
.
8

0
0
.
0

-

3
1
.
8

3
2
.
4
1

7
2
.
1

4
5
.
0

-

7
2
.
3

0
0
.
0

7
0
.
4
4
4

3
7
.
3
2
8

0
0
.
0

-

-

-

-

8
4
.
7
1

7
4
.
7
1

5
5
.
7
1

1
9
.
4

4
9
.
4

0
0
.
5

-

7
7
.
4

6
8
.
8

5
7
.
4

3
6
.
1
5

7
2
.
3
5

3
9
.
8
4

-

1
9
.
2
5

4
4
.
3
2

8
7
.
0
2

3
6
.
0
2

-

9
1
.
1
2

2
5
.
0
2

1
2
.
3

5
4
.
5

9
5
.
0

-

1
8
.
6

)
0
1
(
N
N
R

)
3
(
N
N
F
F

)
3
(
N
N
R

)
0
1
(
N
N
F
F

)
3
(
M
B
G
L

)
0
1
(
M
B
G
L

)
0
1
(
R
P

)
3
(
R
P

)
2
(
R
A

)
3
(
R
A

)
0
1
(
R
A

)
2
1
(
N
N
F
F

)
2
1
(
M
B
G
L

)
2
1
(
N
N
R

)
2
1
(
R
P

)
2
1
(
R
A

)
3
(
R
A

)
1
(
R
A
S

)
5
1
(
N
N
F
F

)
5
1
(
M
B
G
L

)
5
1
(
N
N
R

)
5
1
(
R
P

)
5
1
(
R
A

)
5
1
(
N
N
F
F

)
5
1
(
M
B
G
L

)
5
1
(
N
N
R

)
5
1
(
R
P

)
5
1
(
R
A

R
A
T
E
S

)
5
1
(
N
N
F
F

)
5
1
(
M
B
G
L

)
5
1
(
N
N
R

)
5
1
(
R
P

)
5
1
(
R
A

22

0
0
.
0

1
7
.
7
1

2
1
.
8
1

-

1
9
.
8
1

-

7
7
.
3

-

3
4
.
9

-

5
2
.
9
1

2
3
.
1
1

6
2
.
3

-

9
3
.
9

-

4
0
.
8
1

-

1
1
.
9
1

-

9
1
.
0
1

5
2
.
9
1

3
3
.
3
3
0
1

2
0
.
1

4
2
.
4
5
0
1

o
i
r
a
n
e
c
S

l
a
t
n
e
m

i
r
e
p
x
E
h
c
a
e

r
e
d
n
u

l
e
d
o
M

t
s
e
B
e
h
t

m
o
r
f

i

s
e
c
n
e
r
e
ﬀ
D
e
g
a
t
n
e
c
r
e
P
d
n
a

s
t
l
u
s
e
R

:
7

e
l
b
a
T

Figure 4: Visualisation of the Change of Errors of the Models Across Diﬀerent Amounts of Data in the AR(3) DGP
Scenarios

DGP, the Friedman test gives an overall p-value of 1.21 × 10−10 in terms of the mean SMAPE values

indicating the signiﬁcance of the diﬀerences of the models. Refer to Appendix F.3 for details of the

Hochberg’s post-hoc procedure results.

In the MS-Hom-Short case, the local AR model which learns only from the current series, becomes

worse as the lengths of the individual series are much shorter (18 data points). Among the AR models

as well, we can see how the performance gets worse with the increased number of coeﬃcients; AR(10)

is the worst and AR(3), the second worst. The PR(3) model performs best since the underlying DGP

is an AR(3), so that a linear model of the corresponding order performs competitively. The RNN(3)

model is the next best to the PR(3) in this setting. Furthermore, in a very short length scenario like

this, it is evident how the global models such as PR(3) and RNN(3) which learn from all the series

can be better than the local models, even AR(3) which is the one closest to the true DGP. When the

length of all the series is 18, AR(2) is better than AR(3) across all the dataset sizes, complying with

the ﬁndings in the SS setting. In fact, at the beginning lengths, the AR(2) is the best model and

gradually the PR(3) starts to outperform as the number of series in the dataset increases. AR(10)

remains the worst performing model across all dataset sizes.

23

Since we have suﬃcient lengths in the MS-Hom-Long scenario, we run the PR, RNN, LGBM and

FFNN models with both 3 and 10 lags. As seen in Table 7, the diﬀerence of the performance between

the two models PR(3) and PR(10) is quite small in the MS-Hom-Long case. Similar to the MS-Hom-

Short scenario, the PR models still remain the best out of all the models, in terms of Mean SMAPE.

However, AR(2) and AR(3) models in the MS-Hom-Long scenario are much closer in performance to

the PR models due to the increased lengths of the series (180 points). Yet, the PR model outperforms

in terms of Mean SMAPE since the series are all homogeneous and the global, linear PR model learns

better across the series. The lag 10 models all outperform their lag 3 variants for the complex models.

In fact, with respect to mean MASE, RNN(10) demonstrates an equivalent performance to that of

the best models PR(3), PR(10). In terms of Mean SMAPE, the RNN(10) model demonstrates the

same result as the AR(3) model which is the true DGP. According to the MS-Hom-Long setting in

Figure 4, we can see that AR(10) is the worst performing model in the beginning lengths similar to

the observations from the MS-Hom-Short scenario.

In the MS-Het scenario, the local AR(2) and AR(3) models again emerge as the best models with

the AR(10) being the third. This can be explained by the induced heterogeneity among the series so

that the local AR models built per every series outperform all the global models. Among the global

models, the RNN(10) model performs better than the linear PR models since the inherent complex,

non-linear modelling capacity of the RNN model can account for the heterogeneity among the series

to a certain extent. According to the Diﬀ column in Table 7, the percentage diﬀerence between

the best performing local models and the RNN(10) is very small (4.77% in terms of Mean SMAPE)

compared to the diﬀerences of other models. In Figure 4, although AR(10) outperforms all the global

models at the maximum length, it performs the worst in the beginning lengths. Moreover, the PR(10)

performs better than its corresponding local model AR(10) at the beginning lengths. Similarly, both

RNN models perform better than AR(10) at shorter lengths. This demonstrates that although local

models can be competitive in a heterogeneous series setting, for that they require suﬃcient lengths in

the series. Otherwise, having global models, especially complex non-linear ones such as RNNs in a

heterogeneous setting like this, which learn across all the short series together can be quite competitive.

Friedman test for the MS-Het scenario gives an overall p-value of 2.59 × 10−10 in terms of the mean

SMAPE values which means that the diﬀerences are statistically highly signiﬁcant. For the details of

Hochberg’s post-hoc procedure, refer to Appendix F.3.

According to Figure 4, it is evident that the accuracies of all the models in general improve by

24

increasing the length of the time series or the number of time series, except for the local models in the

MS-Hom-Short scenario where we only increase the number of series in the dataset.

6.1.2. SAR(1) Data Generating Process

As seen in Table 7 for the SAR(1) DGP, the SAR(1) model is the best on the SS scenario, which

is obvious given that SAR(1) is the true DGP. The AR(3) model which is a misspeciﬁed model with

respect to the SAR(1), is the worst. The AR(12) in the SS setting is equivalent in performance to

SAR(1) in terms of Mean MASE. AR(12) is a superclass of the true DGP SAR(1), where only the

12th coeﬃcient needs to be signiﬁcant, which can be learned with suﬃcient length in the series. In the

MS-Hom-Short scenario with the same data, the AR(3) model remains the worst performing model.

However, the AR(12) has also become the second worst performing model in the MS-Hom-Short

setting, due to the heavy complexity of the AR(12) model compared to the SAR(1) model and the

short lengths of the series (24 points). The model closest to the true DGP which is SAR(1) shows the

same performance as the RNN(12) and is the second best model. The FFNN outperforms the SAR(1)

model which is the true DGP, although the short lengths of the series in the MS-Hom-Short setting are

adequate to learn the one coeﬃcient in the SAR(1) model. This shows the competence of the models

that learn across series in such homogeneous contexts. The PR(12) model in the MS-Hom-Short

scenario closely follows the SAR(1) and RNN(12) models.

When the lengths of the series are increased as per the results of the MS-Hom-Long scenario,

once again the SAR(1) model surpasses all the other models. However, the PR(12) model is almost

the same as the SAR(1) model with the FFNN being the next following the PR(12). All three of

them are equivalent in performance with respect to the Mean MASE values. In the MS-Het scenario,

the SAR(1) model again becomes the best, complying with the observation in the AR(3) DGP. The

second best model in this case is the AR(12) model, although it shows poor performance on the

previously described homogeneous series scenarios. Among the global models, the PR(12) is the best.

The RNN(12) is quite close and is exactly equal in performance to PR(12) with respect to Mean

MASE. This indicates that, although the RNN is a competitive model due to its complexity in the

heterogeneous setting, under the SAR(1) DGP with just one coeﬃcient for every series, the RNN’s

high complexity may be unnecessary. Surprisingly, the misspeciﬁed AR(3) model outperforms all the

non-linear global models in the MS-Het scenario. Theoretically this is unlikely for AR(3) even with

the heterogeneous series. However, this result is due to generating series in the MS-Het scenario by

randomly picking a coeﬃcient from U(-0.5, 0.5) to induce heterogeneity. Some of these series may end

25

up getting non-signiﬁcant 12th lags depending on how big the coeﬃcient is. On the other hand in

the MS-Hom-Long setting, the underlying SAR(1) model used has a coeﬃcient of 0.85 as mentioned

in Appendix A.2.2 of our Online Appendix, which is chosen intentionally to create series with longer

memory, and thus the inferior performance of AR(3) in that scenario. In the SAR(1) DGP too, the

observations related to data availability are the same as for the AR(3) DGP, i.e., the performance of

all the models improves in general as the size of the dataset increases, although not quite consistent

across the individual lengths and number of series in some scenarios.

6.1.3. Chaotic Logistic Map Data Generating Process

As shown in Table 7, the non-linearity of the patterns generated by the Chaotic Logistic Map DGP

are perceived by the non-linear forecasting models outperforming the linear ones in all the diﬀerent

experimental scenarios. For the SS scenario, even though there is only one DGP with the same

coeﬃcients, the complex patterns produced by the DGP are not captured well by the linear model

AR(15). The LGBM(15) is the best model on the SS scenario. On the MS-Hom-Short scenario, the

RNN(15) is the best model with the FFNN(15) and the LGBM(15) being quite close. Once again, the

lengths of the short series in the MS-Hom-Short scenario are not suﬃcient for the AR(15) model to

properly learn all its 15 coeﬃcients. However, the PR(15) model, although linear in nature, performs

better than the AR(15) model in the MS-Hom-Short scenario, due to the underlying homegeneity of

the series. Yet, since the individual series hold complex patterns, the linear PR is still not suﬃcient

to surpass the complex global models in this scenario. For the MS-Hom-Short scenario, the Friedman

test of statistical signiﬁcance gives an overall p-value of 3.12 × 10−10 indicating the signiﬁcance of the

diﬀerences between the models. Results of Hochberg’s post-hoc procedure for this scenario indicate

that all the models are signiﬁcantly worse than the best model RNN(15) in this case.

In the MS-Hom-Long case, still the non-linear complex models win over the linear models, while the

LGBM(15) is the best. The drop of the errors in the AR model due to the length increase is notable.

Despite their complexity, the lengths of the individual series in this case seem suﬃcient for the AR(15)

to learn competitively. Yet, due to the homogeneity of the multiple series, the PR(15) which learns

across series is ahead of the AR(15). For this scenario, the Friedman test of statistical signiﬁcance

gives an overall p-value of < 10−30. Hochberg’s post-hoc procedure for this scenario, by using the

LGBM(15) model as the control method indicate that all the other models are signiﬁcantly worse than

that. In the MS-Het scenario, even though the patterns become relatively easy to be modelled by all

the forecasting models with respect to the mean SMAPE values (further explained in Appendix F.1.3),

26

still the non-linear global models outperform the two linear AR and PR models. Furthermore, similar

to the previous DGPs, the local AR(15) built per each series outperforms the PR(15).

We can observe that the models improve with increased amounts of data in general, in the Chaotic

Logistic Map DGP too. Based on the conclusions obtained regarding data availability for forecasting

from all the experimental scenarios explained thus far, we eliminate the data availability experiments

from the rest of the experimental setups explained next.

6.1.4. SETAR Data Generating Process

For the SS scenario of the SETAR DGP, the length of the series used is 6000. The best model under

the SS scenario is the true model which is SETAR. Once again, the complexity of the DGP is visible by

the non-linear models FFNN(15) and LGBM(15) outperforming the linear AR(15) model. However,

the RNN(15) becomes the worst model in this scenario (further explained in Appendix F.1.4). Apart

from the SS scenario, the SETAR DGP results are quite similar to the Chaotic Logistic Map DGP.

For the MS-Hom-Short experiment, the length of every individual series is 60 with 100 series in the

dataset (corresponding to the 6000 data points in the SS scenario). In this case, the RNN(15) is the

best model followed by the FFNN(15) and the LGBM(15). The errors of the local AR and SETAR

models increase due to short lengths of the series in the MS-Hom-Short scenario. Although the global

PR is better than the local models due to the homogeneity of the series, it is not adequate to capture

the complex patterns produced by the SETAR DGP for the individual series.

As seen in Table 7, the non-linear global models surpass the linear AR and PR models in both

the MS-Hom-Long and MS-Het scenarios. For the SETAR model the increased lengths in the MS-

Hom-Long scenario still do not seem to be suﬃcient to capture the non-linear patterns of the series

properly. The AR(15) model seems to learn some patterns better than at least the SETAR model

with the increased lengths in the MS-Hom-Long scenario. Yet, they are both inferior in performance

to the PR model which learns across series in this homogeneous case. However, in the heterogeneous

scenario, diﬀerent from the previous DGPs, the PR model performs better than both the AR and

SETAR models. For the AR models, this can be explained by the regime-switching nature of the series

generated by the SETAR DGP, which makes one AR model trained for the whole series not the ideal

model for this scenario. Although the true model is the best under the heterogeneous settings of the

previous DGPs, it is not the case with the SETAR DGP. The SETAR model in the heterogeneous case

is still the worst performing model due to the insuﬃcient lengths of the series. Also, it seems that the

MS-Het scenario has made it diﬃcult for all forecasting techniques to model the series in general.

27

6.1.5. Mackey-Glass Data Generating Process

The number and the lengths of the series in all the scenarios of the Mackey-Glass DGP are the

same as in the SETAR DGP. The observations from this DGP too are very similar to SETAR and

Chaotic Logistic Map DGPs. The non-linear models RNN(15), FFNN(15), and LGBM(15) outperform

the linear models in most of the scenarios. The LGBM(15) model is remarkably better than all the

other models under the SS, MS-Hom-Short and MS-Hom-Long scenarios. This is also conﬁrmed

by the Friedman test of statistical signiﬁcance for the SS scenario, which gives an overall p-value

of 1.08 × 10−10, suggesting that the results are statistically highly signiﬁcant. Further tests with

Hochberg’s post-hoc procedure by using LGBM(15) as the control method indicate that all the other

models are signiﬁcantly worse than the LGBM(15) model in this case.

The PR model is better than the AR model in both the MS-Hom-Short and MS-Hom-Long scenar-

ios, due to the homogeneity among the series. The complexity of the datasets in the MS-Het scenario

is evident by the substantial increase of the SMAPE values in all the models. In the heterogeneous

scenario of the Mackey-Glass DGP too, the local AR model appears to be better than the global PR

model, due to the inherent heterogeneity of the datasets. For the heterogeneous case, the Friedman

test gives an overall p-value of 1.74 × 10−10, once again indicating the high signiﬁcance of the per-

formance diﬀerences. Hochberg’s post-hoc process for the heterogeneous scenario reveals that all the

other models are signiﬁcantly worse than the RNN(15) model in this case.

6.1.6. Results of the Group Feature Experiments

The results from the Group Feature setup experiments performed on the Chaotic Logistic Map

DGP are presented in Table 8. For this we use 100 datasets, each having series of length 240. The

horizontal line in Table 8 separates the GFM.GroupFeature setup results with their corresponding

GFM.All results along with the local AR model results. The “GroupFeature” suﬃx indicates that

the GFM.GroupFeature training paradigm explained in Section 2.5 is used on the respective models.

As seen in Table 8, the GFM.GroupFeature setup improves the accuracy of the GFM.All setup in all

techniques except the PR model where the SMAPE value remains constant. Especially in the case of

the FFNN, the group feature inclusion results in the base model improving beyond the PR models.

All the non-linear GroupFeature models hold a better standing over the linear models in this scenario,

while the RNN(15)-Group performs the best. The Friedman test of statistical signiﬁcance for the

Group Feature scenario gives an overall p-value of 2.08 × 10−10, expressing that the diﬀerences are

28

Model
RNN(15)
FFNN(15)
LGBM(15)
PR(15)
AR(15)
RNN(15)-Group
FFNN(15)-Group
LGBM(15)-Group
PR(15)-Group

SMAPE MASE

38.27
39.13
37.39
38.89
39.31
36.68
38.40
37.05
38.89

0.87
0.90
0.86
0.87
0.88
0.84
0.88
0.85
0.87

Table 8: Mean SMAPE and Mean MASE values for the GFM.GroupFeature Setup

Model
RNN(15)
FFNN(15)
LGBM(15)
AR(15)
SETAR
PR(15)

Data Preprocessing Model Training & Testing
10788.62
649.73
4.58
111.08
3.03
0.40

5.36
5.36
5.36
-
-
0.05

Total
10793.98
655.09
9.94
111.08
3.03
0.45

Table 9: Computational Times Comparison of the Forecasting Models (in seconds)

statistically highly signiﬁcant. Refer to Appendix F.3 for further results with Hochberg’s post-hoc

procedure.

6.2. Comparison of Computational Complexities

Under the computational resources provided under Appendix E, we provide a comparison of the

computational times of the diﬀerent forecasting models. For this, we select the MS-Hom-Long scenario

of the SETAR DGP. In Table 9, we record the time taken for one of the 100 datasets. Data prepro-

cessing is not relevant for the AR(15) and SETAR models. Since RNN, FFNN, and LGBM all use

the data preprocessed in the same manner, their data preprocessing times are the same. As observed

from Table 9, the NN-based techniques spend comparatively higher computational times, with the

RNN taking the highest and the FFNN the second highest time. The PR models in general are the

most eﬃcient, while the SETAR and the LGBM models are the second and third most eﬃcient models

respectively. Compared to LGBM and PR, which are global models, the local AR model in this case

with its 15 coeﬃcients also takes a considerable amount of time due to building one model per each

series.

6.3. Overall Summary of Results

In this section, we provide a summary for the overall results obtained. With respect to the data

availability experiments, we can conﬁrm the expected behaviour that the performance of all models,

29

both local and global variants, improve as the individual series get longer. Also as expected, this is

not the case with local models when we increase the number of series in the dataset, while keeping the

lengths constant. Considering the experiments related to single and multiple series, although the error

values are not exactly the same, all global model accuracies are roughly equivalent in the SS and MS-

Hom-Short scenario. This indicates that for global models it does not make much diﬀerence whether

the data remains on one long series or spread across multiple diﬀerent series. Several exceptions to

this conclusion are also mentioned under Appendix F.2 of the Online Appendix. The local AR models

clearly become worse when moving to the MS-Hom-Short context, since less data is used for the model

training then. Again, there are exceptions to this, such as the SAR(1) forecast model in the SAR(1)

DGP. With its single coeﬃcient, the SAR(1) model can be trained well with minimal training data.

The lengths in the MS-Hom-Long settings can still be inadequate for certain local models depending

on the underlying DGPs. An example of this is the MS-Hom-Long setting of the SETAR DGP where

the SETAR model performs the worst.

From Table 7, we can see that with just a single series having adequate length, with either complex

or simple patterns, the local forecast model closest to the true DGP if known, can win over all the

other models. However, when moving into the MS-Hom-Short scenarios, this can happen only if the

individual series are long enough. This depends on the lengths of the series as well as the complexity of

the local model in terms of the number of coeﬃcients. On the other hand, in multiple series scenarios,

the power of global models which learn across series come into play. With these global models as

well, the ones closest to the true underlying DGP can win. The more complex the patterns in the

individual series, the more complex global models can win, as seen with the MS-Hom-Short and MS-

Hom-Long scenarios of the Chaotic Logistic Map DGP, SETAR DGP and Mackey-Glass Equation

DGP. Even if the individual series lengths are suﬃcient for local models, if the series in the dataset

are all homogeneous, the global models which learn across series are competitive over local ones which

learn only from a single series. This holds for simple global models on series with complex patterns

as well, as seen under the MS-Hom-Long scenarios of the Chaotic Logistic Map, SETAR and Mackey-

Glass-Equation DGPs. When moving into the heterogeneous series settings, again the local models

become competitive especially over the simple, linear global models. Once again, the potential of

the global models come into play in the heterogeneous series settings, when the series lengths are

short. However, unlike in the homogeneous settings, with the heterogeneous scenarios, the complex,

non-linear global models are very competitive over simple, linear global models, with both simple

30

and complex patterns in the individual series, as seen in the AR(3), Chaotic Logistic Map, SETAR

and Mackey-Glass Equation DGPs. Apart from that, as seen in the AR(3) DGP case, for complex,

non-linear global models, adding more memory/lags can help the models learn the patterns better.

Adding external information to the GFM.All models regarding the existence of pre-known clusters

within the data can further improve the model performance. This is conﬁrmed by almost all the

GFM.GroupFeature models outperforming their corresponding GFM.All setup models. Therefore,

this attests our understanding that the GroupFeature setup can add more complexity to the base

global model.

Thus, the linear models such as PR, AR work best with known linear patterns in the data while

non-linear models such as LGBM, RNN are more general in that they can perform reasonably well

irrespective of the exact DGP. They can be competitive models under practical situations such as short

series or heterogeneity across series. This is evident in Table 7 where LGBMs and RNNs perform

best under many scenarios. However, with RNNs, this superior performance comes at the cost of

more computational time. LGBMs, on the other hand, are catching up with RNNs in terms of their

performance, while being extremely fast in model training & testing.

7. Conclusions

The recent work by Montero-Manso and Hyndman (2020) has shown that any local method ap-

plied on a dataset of many series can be approximated by a global model with suﬃcient complexity,

irrespective of the relatedness of the underlying series. Therefore, for global models it is about ﬁnding

the right amount of complexity to outperform local methods. However, in practice there are complex

trade-oﬀs to be made between model complexity and capabilities on the one hand, and factors such

as the availability of data, complexity of DGPs, and the heterogeneity of the underlying data on the

other hand. In this work, we have explored in an extensive experimental study some of the poorly

understood factors that contribute to global forecasting model performance under these trade-oﬀs. We

have focused on characteristics common in real-world forecasting problems and their related challenges

such as series with short history and heterogeneity of the series. Through extensive empirical evalua-

tions carried out within a controlled setting of simulated datasets, we have demonstrated the interplay

between these diﬀerent aspects.

In terms of the methodology, we start by simulating data using the arguably simplest DGPs avail-

able and then making them more complex. We start with simple, linear AR(3) and SAR(1) DGPs

31

and then move onto more complex, non-linear DGPs with the Chaotic Logistic Map, SETAR, and

Mackey-Glass Equations. We simulate both homogeneous and heterogeneous scenarios. In the ho-

mogeneous setup, all time series in the dataset are simulated using the same DGP, whereas in the

heterogeneous case, time series from diﬀerent DGPs are mixed together within the same dataset. The

availability of data for the experiments is controlled by changing the lengths and the number of series.

For each scenario, 100 or 1000 datasets are simulated using diﬀerent random seeds, to achieve reliable

and signiﬁcant experimental results. Similar to the complexity of the DGPs, the complexity of the

forecasting techniques is regulated by experimenting using a number of forecasting techniques with

diﬀerent modelling capabilities. We have used linear AR, PR models as well as more complex SETAR,

RNNs, FFNNs, and LGBMs as forecasting techniques. The complexity of global models is further

varied by introducing two model setups, GFM.All and GFM.GroupFeature.

The results of our study have ﬁrst conﬁrmed that local linear models such as AR work best with

known linear patterns in the data, with suﬃcient lengths in the series. The linear global models such

as PR can cope well under multiple short series. When the patterns are made more complex, the

complex non-linear global models such as RNNs, LGBMs are superior to simple linear global models.

With heterogeneity existing across series, complex non-linear global models are competitive over linear

global models irrespective of the simplicity or complexity of the patterns. Thus, non-linear, non-

parametric models such as RNNs and LGBMs are in general quite competitive models across a variety

of uncertain situations, where we have little prior knowledge about the data. The LGBM models

hold another advantage of being computationally eﬃcient compared to RNNs. Simple models such

as AR and PR make assumptions about the linearity of the underlying data which are not always

valid. The results of the experiments that involve diﬀerent scales of heterogeneity prove that the

complexity of global forecasting models can be further improved by incorporating prior knowledge

about the heterogeneity of data in the form of external features. With respect to data availability,

unsurprisingly all global models gradually improve as the lengths and the number of series in the

dataset increase. For local models, this improvement is understandably only seen with the length of

the individual series. The model complexity of local models grows proportional to the number of series

in the dataset, potentially even higher than the constant complexity of a global model built on the

same dataset. This is why, even though ﬁtting a single local model on just one series may take very

little time, ﬁtting many of them on a whole dataset of series takes a considerable amount of time. In

terms of future work, further experiments can be conducted across all DGPs by changing the order of

32

the same forecasting models within the same scenarios. For the heterogeneous setups, a third model

setup GFM.Cluster can be introduced which trains multiple global models on the diﬀerent clusters of

the same dataset.

Acknowledgement

This research was supported by the Australian Research Council under grant DE190100045, Face-

book Statistics for Improving Insights and Decisions research award, Monash University Graduate

Research funding and MASSIVE - High performance computing facility, Australia.

References

Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Davis, A., Dean,
J., Devin, M., Ghemawat, S., Goodfellow, I., Harp, A., Irving, G., Isard, M., Jia, Y., Jozefowicz,
R., Kaiser, L., Kudlur, M., Levenberg, J., Man´e, D., Monga, R., Moore, S., Murray, D., Olah,
C., Schuster, M., Shlens, J., Steiner, B., Sutskever, I., Talwar, K., Tucker, P., Vanhoucke, V.,
Vasudevan, V., Vi´egas, F., Vinyals, O., Warden, P., Wattenberg, M., Wicke, M., Yu, Y., Zheng,
X., 2015. TensorFlow: Large-scale machine learning on heterogeneous systems. URL: https:
//www.tensorflow.org/. software available from tensorﬂow.org.

Bandara, K., Bergmeir, C., Campbell, S., Scott, D., Lubman, D., 2020a. Towards accurate predictions
and causal ’what-if’ analyses for planning and policy-making: A case study in emergency medical
services demand.

Bandara, K., Bergmeir, C., Smyl, S., 2020b. Forecasting across time series databases using recurrent
neural networks on groups of similar series: A clustering approach. Expert Systems with Applications
140, 112896.

Bandara, K., Shi, P., Bergmeir, C., Hewamalage, H., Tran, Q., Seaman, B., 2019. Sales demand
forecast in e-commerce using a long short-term memory neural network methodology, in: Gedeon,
T., Wong, K.W., Lee, M. (Eds.), Neural Information Processing, Springer International Publishing,
Cham. pp. 462–474.

Bergmeir, C., Ben´ıtez, J.M., 2012. On the use of cross-validation for time series predictor evaluation.

Information Sciences 191, 192 – 213. Data Mining for Software Trustworthiness.

Bergmeir, C., Hyndman, R.J., Koo, B., 2018. A note on the validity of cross-validation for evaluating

autoregressive time series prediction. Computational Statistics & Data Analysis 120, 70 – 83.

Bojer, C.S., Meldgaard, J.P., 2020. Kaggle forecasting competitions: An overlooked learning opportu-

nity. International Journal of Forecasting .

Box, G., Jenkins, G., Reinsel, G., 1994. Time Series Analysis: Forecasting and Control. Forecasting

and Control Series, Prentice Hall.

Chen, T., Guestrin, C., 2016. Xgboost: A scalable tree boosting system, in: Proceedings of the 22nd
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Association for
Computing Machinery, New York, NY, USA. p. 785–794. doi:10.1145/2939672.2939785.

Claveria, O., Torra, S., 2014. Forecasting tourism demand to catalonia: Neural networks vs. time

series models. Economic Modelling 36, 220 – 228.

Fabio Di Narzo, A., Luis Aznarte, J., Stigler, M., 2019. tsDyn: Nonlinear Time Series Models with
Regime Switching. URL: https://CRAN.R-project.org/package=tsDyn. r package version 0.9-
48.1.

Fischer, T., Krauss, C., Treichel, A., 2018. Machine learning for time series forecasting - a simulation
study. FAU Discussion Papers in Economics 02/2018. Friedrich-Alexander University Erlangen-
Nuremberg, Institute for Economics.

33

Garc´ıa, S., Fern´andez, A., Luengo, J., Herrera, F., 2010. Advanced nonparametric tests for multiple
comparisons in the design of experiments in computational intelligence and data mining: Experimen-
tal analysis of power. Information Sciences 180, 2044 – 2064. Special Issue on Intelligent Distributed
Information Systems.

Gers, F.A., Schraudolph, N.N., Schmidhuber, J., 2003. Learning precise timing with lstm recurrent

networks. J. Mach. Learn. Res. 3, 115–143.

He, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual learning for image recognition, in: 2016 IEEE
Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770–778. doi:10.1109/CVPR.
2016.90.

Hewamalage, H., Bergmeir, C., Bandara, K., 2020. Recurrent neural networks for time series forecast-

ing: Current status and future directions. International Journal of Forecasting .

Hyndman, R., Athanasopoulos, G., Bergmeir, C., Caceres, G., Chhay, L., O’Hara-Wild, M., Petropou-
los, F., Razbash, S., Wang, E., Yasmeen, F., 2020. forecast: Forecasting functions for time series
and linear models. URL: http://pkg.robjhyndman.com/forecast. r package version 8.11.

Hyndman, R., Koehler, A., Ord, K., D Snyder, R., 2008. Forecasting with exponential smoothing. The

state space approach. Springer Berlin Heidelberg. doi:10.1007/978-3-540-71918-2.

Hyndman, R.J., Athanasopoulos, G., 2018. Forecasting: Principles and Practice. second ed., OTexts.

URL: https://otexts.com/fpp2/.

Hyndman, R.J., Koehler, A.B., 2006. Another look at measures of forecast accuracy. International

Journal of Forecasting 22, 679 – 688.

Hyndman, R.J., Koehler, A.B., Snyder, R.D., Grose, S., 2002. A state space framework for automatic
forecasting using exponential smoothing methods. International Journal of Forecasting 18, 439 –
454.

Januschowski, T., Gasthaus, J., Wang, Y., Salinas, D., Flunkert, V., Bohlke-Schneider, M., Callot, L.,
2020. Criteria for classifying forecasting methods. International Journal of Forecasting 36, 167 –
177. M4 Competition.

Kang, Y., Li, F., Hyndman, R.J., 2020. GRATIS: Generating time series with diverse and controllable

characteristics. Statistical Analysis and Data Mining 13, 354–376. doi:10.1002/sam.11461.

Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., Ye, Q., Liu, T.Y., 2017. Lightgbm: A
highly eﬃcient gradient boosting decision tree, in: Guyon, I., Luxburg, U.V., Bengio, S., Wallach,
H., Fergus, R., Vishwanathan, S., Garnett, R. (Eds.), Advances in Neural Information Processing
Systems 30. Curran Associates, Inc., pp. 3146–3154.

Kingma, D.P., Ba, J., 2015. Adam: A method for stochastic optimization, in: 3rd International

Conference for Learning Representations.

Lau, K., Wu, Q., 2008. Local prediction of non-linear time series using support vector regression.

Pattern Recognition 41, 1539 – 1547.

Mackey, M.C., Glass, L., 1977. Oscillation and chaos in physiological control systems. Science 197,

287–289.

Makridakis, S., Spiliotis, E., Assimakopoulos, V., 2020a. The m4 competition: 100,000 time series and

61 forecasting methods. International Journal of Forecasting 36, 54 – 74. M4 Competition.

Makridakis, S., Spiliotis, E., Assimakopoulos, V., 2020b. The m5 accuracy competition: Results,
ﬁndings and conclusions. URL: https://www.researchgate.net/publication/344487258_The_
M5_Accuracy_competition_Results_findings_and_conclusions.

Mandal, P., Senjyu, T., Urasaki, N., Funabashi, T., 2006. A neural network based several-hour-ahead
electric load forecasting using similar days approach. International Journal of Electrical Power &
Energy Systems 28, 367 – 373.

Mannattil, M., 2017. nolitsa. https://github.com/manu-mannattil/nolitsa.
May, R.M., 1976. Simple mathematical models with very complicated dynamics. Nature 261, 459–467.
Montero-Manso, P., Hyndman, R.J., 2020. Principles and algorithms for forecasting groups of time
series: Locality and globality. URL: https://arxiv.org/abs/2008.00444, arXiv:2008.00444.
Orabona, F., Tommasi, T., 2017. Training deep networks without learning rates through coin betting,
in: Proceedings of the 31st International Conference on Neural Information Processing Systems,

34

Curran Associates Inc., USA. pp. 2157–2167.

Petropoulos, F., Makridakis, S., Assimakopoulos, V., Nikolopoulos, K., 2014.

‘horses for courses’ in

demand forecasting. European Journal of Operational Research 237, 152 – 163.

R Core Team, 2020. R: A Language and Environment for Statistical Computing. R Foundation for

Statistical Computing. Vienna, Austria. URL: https://www.R-project.org/.

Rangapuram, S.S., Seeger, M., Gasthaus, J., Stella, L., Wang, Y., Januschowski, T., 2018. Deep state
space models for time series forecasting, in: Proceedings of the 32nd International Conference on
Neural Information Processing Systems, Curran Associates Inc., Red Hook, NY, USA. p. 7796–7805.
Salinas, D., Flunkert, V., Gasthaus, J., Januschowski, T., 2019. Deepar: Probabilistic forecasting with

autoregressive recurrent networks. International Journal of Forecasting .

Sch¨afer, A.M., Zimmermann, H.G., 2006. Recurrent neural networks are universal approximators, in:
Proceedings of the 16th International Conference on Artiﬁcial Neural Networks - Volume Part I,
Springer-Verlag, Berlin, Heidelberg. pp. 632–640. doi:10.1007/11840817_66.

Smyl, S., 2020. A hybrid method of exponential smoothing and recurrent neural networks for time

series forecasting. International Journal of Forecasting 36, 75 – 85. M4 Competition.

Smyl, S., Kuber, K., 2016. Data preprocessing and augmentation for multiple short time series fore-

casting with recurrent neural networks, in: 36th International Symposium on Forecasting.

Suhartono, Amalia, F.F., Saputri, P.D., Rahayu, S.P., Ulama, B.S.S., 2018. Simulation study for
determining the best architecture of multilayer perceptron for forecasting nonlinear seasonal time
series. Journal of Physics: Conference Series 1028, 012214.

Sun, J., Yang, Y., Liu, Y., Chen, C., Rao, W., Bai, Y., 2019. Univariate time series classiﬁcation using

information geometry. Pattern Recognition 95, 24 – 35.

Svetunkov, I., 2019. smooth: Forecasting Using State Space Models. URL: https://CRAN.R-project.

org/package=smooth. r package version 2.5.3.

Tong, H., 1978. On a threshold model, in: Pattern Recognition and Signal Processing. Springer

Netherlands, pp. 575–586.

Tong, H., Lim, K.S., 1980. Threshold autoregression, limit cycles and cyclical data. Journal of the

Royal Statistical Society: Series B (Methodological) 42, 245–268.

Trapero, J.R., Kourentzes, N., Fildes, R., 2015. On the identiﬁcation of sales forecasting models in
the presence of promotions. Journal of the Operational Research Society 66, 299–307. doi:10.1057/
jors.2013.174.

Vanli, N.D., Sayin, M.O., Mohaghegh N., M., Ozkan, H., Kozat, S.S., 2019. Nonlinear regression via

incremental decision trees. Pattern Recognition 86, 1 – 13.

Wang, Y., Smola, A., Maddix, D., Gasthaus, J., Foster, D., Januschowski, T., 2019. Deep factors for

forecasting, PMLR, Long Beach, California, USA. pp. 6607–6617.

Wen, R., Torkkola, K., Narayanaswamy, B., Madeka, D., 2017a. A multi-horizon quantile recurrent

forecaster. URL: https://arxiv.org/abs/1711.11053, arXiv:1711.11053.

Wen, R., Torkkola, K., Narayanaswamy, B., Madeka, D., 2017b. A Multi-Horizon quantile recurrent

forecaster, in: Neural Information Processing Systems.

Ye, R., Dai, Q., 2021. Implementing transfer learning across diﬀerent datasets for time series forecast-

ing. Pattern Recognition 109, 107617.

Zhang, G., Patuwo, B., Hu, M.Y., 2001. A simulation study of artiﬁcial neural networks for nonlinear

time-series forecasting. Computers & Operations Research 28, 381 – 396.

Zhang, G.P., 2007. A neural network ensemble method with jittered training data for time series

forecasting. Inf. Sci. 177, 5329–5346. doi:10.1016/j.ins.2007.06.015.

Zhang, G.P., Qi, M., 2005. Neural network forecasting for seasonal and trend time series. Eur. J.

Oper. Res. 160, 501–514.

Zhao, J., Itti, L., 2018. shapedtw: Shape dynamic time warping. Pattern Recognition 74, 171 – 184.
Zhu, L., Laptev, N., 2017. Deep and conﬁdent prediction for time series at uber. 2017 IEEE Interna-

tional Conference on Data Mining Workshops (ICDMW) .

35

