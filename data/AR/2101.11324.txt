1
2
0
2

n
a
J

7
2

]

C
O
.
h
t
a
m

[

1
v
4
2
3
1
1
.
1
0
1
2
:
v
i
X
r
a

Minimum energy with inﬁnite horizon:
from stationary to non-stationary states

P. Acquistapace∗, F.Gozzi†

Abstract

We study a non standard inﬁnite horizon, inﬁnite dimensional linear-quadratic control problem
arising in the physics of non-stationary states (see e.g. [7, 9]): ﬁnding the minimum energy to drive
a given stationary state ¯x = 0 (at time t = −∞) into an arbitrary non-stationary state x (at time
t = 0). This is the opposite to what is commonly studied in the literature on null controllability
(where one drives a generic state x into the equilibrium state ¯x = 0). Consequently, the Algebraic
Riccati Equation (ARE) associated to this problem is non-standard since the sign of the linear part is
opposite to the usual one and since it is intrinsically unbounded. Hence the standard theory of AREs
does not apply. The analogous ﬁnite horizon problem has been studied in the companion paper [1].
Here, similarly to such paper, we prove that the linear selfadjoint operator associated to the value
function is a solution of the above mentioned ARE. Moreover, diﬀerently to [1], we prove that such
solution is the maximal one. The ﬁrst main result (Theorem 4.7) is proved by approximating the
problem with suitable auxiliary ﬁnite horizon problems (which are diﬀerent from the one studied in
[1]). Finally in the special case where the involved operators commute we characterize all solutions
of the ARE (Theorem 5.5) and we apply this to the Landau-Ginzburg model.

Keywords: Minimum energy; Null controllability; Landau-Ginzburg model; Optimal control with inﬁnite hori-
zon; Algebraic Riccati Equation in inﬁnite dimension; Value function as maximal solution.

Contents

1 Introduction

1.1 Plan of the paper . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2 The problem and the main results

2.1 The state equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 Minimum energy problems with inﬁnite horizon and associated Riccati equation . . . . .
2.3 The method and the main results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3 The auxiliary problem

3.1 A key comparison result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4 Minimum energy with (negative) inﬁnite horizon

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.1 Optimal strategies
4.2 Connection with the ﬁnite horizon case . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3 Algebraic Riccati Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5 The selfadjoint commuting case

6 A motivating example: from equilibrium to non-equilibrium states

A Minimum Energy with ﬁnite horizon

A.1 General formulation of the problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
A.2 The space H and its properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

∗Dipartimento di Matematica, Università di Pisa, e-mail: paolo.acquistapace@unipi.it
†Dipartimento di Economia e Finanza, Università LUISS - Guido Carli Roma; e-mail: fgozzi@luiss.it

2
2

3
3
4
5

7
9

14
14
15
16

18

23

24
25
25

1

 
 
 
 
 
 
1 Introduction

We study a non standard inﬁnite dimensional, inﬁnite horizon, linear-quadratic control problem: ﬁnding
the minimum energy to drive a given stationary state ¯x = 0 (at time t = −∞) into an arbitrary non-
stationary state x (at time t = 0).
This kind of problems arises in the control representation of the rate function for a class of large deviation
problems (see e.g. [13] and the references quoted therein; see also [18, Chapter 8] for an introduction to
the subject). It is motivated by applications in the physics of non-equilibrium states and in this context
it has been studied in various papers, see e.g. [4, 5, 6, 7, 8, 9] (see Section 6 for a description of a model
case).
The main goal here, as a departure point of the theory, is to apply the dynamic programming approach to
characterize the value function as the unique (or maximal/minimal) solution of the associated Hamilton-
Jacobi-Bellman (HJB) equation, a problem left open e.g. in [7, 9]. This problem is quite diﬃcult since
it deals with the opposite to what is commonly studied in the literature on null controllability (where
one drives a generic state x into the equilibrium state ¯x = 0). For this reason we start studying here the
simplest case, i.e. when the state equation is linear and the energy functional is purely quadratic: so the
problem falls into the class of linear-quadratic optimal control problems, the value function is quadratic,
and the associated HJB equation reduces to an Algebraic Riccati Equation (ARE).
The above feature (i.e. the fact we bring 0 to x instead of the opposite) implies that the ARE associated
to this problem is non-standard for two main reasons: ﬁrst, the sign of the linear part is opposite to
the usual one; second, since the set of reachable x is strictly smaller than the whole state space X, the
solution is intrinsically unbounded in X. The combination of these two diﬃculties does not allow to
apply the standard theory of AREs.
In the companion paper [1] we studied, as a ﬁrst step, the associated ﬁnite horizon case. Here we partially
exploit the results of such paper to deal with the more interesting inﬁnite horizon case, which is the one
that arises in the above mentioned papers in physics.
Our main results (Theorems 4.7 and 5.5) show that, under a null controllability assumption (after a
given time T0 ≥ 0) and a coercivity assumption on the control operator, the linear selfadjoint operator
P associated to the value function is the maximal solution of the above mentioned ARE. The ﬁrst result
concerns the general case with some restrictions on the class of solutions, while the second one looks
at the case where the state and the control operators commute, without any restriction on the class of
solutions.
This is only partially similar to what has been done in [1]. Indeed, the proof that P is a solution of ARE
is substantially similar to what is done in [1, Section 4.3]. On the other hand, while in [1, Section 4.4] we
prove a partial uniqueness result (i.e. uniqueness in a suitable family of invertible operators), here we are
able to prove, through a delicate comparison argument (based on a nontrivial approximation procedure),
that P is the maximal solution of the associated ARE.
To prove the comparison argument (which is the content of the key Lemma 3.10) we need to introduce
a family of auxiliary ﬁnite horizon problems, which are diﬀerent from the one studied in [1].
Finally, in the special case where the involved operators commute, we are able, again diﬀerently from the
ﬁnite horizon case, to characterize all solutions of the ARE. This allows to apply our result to the case
of Landau-Ginzburg model.

1.1 Plan of the paper

In Section 2 we illustrate the problem and the strategy to show the main results. It is divided in three
subsections: in the ﬁrst we present the state equation and the main Hypothesis; in the second one we
describe our minimum energy problem; the third subsection brieﬂy explains the method used to prove
our main results. Section 3 concerns the study of the auxiliary problem. After devoting the ﬁrst part of
the section to some basic results on it, we show, in Subsection 3.1, the comparison Lemma 3.10 which
will be used to prove the maximality result in the inﬁnite horizon case. Section 4 is devoted to the main
problem and the main maximality result. In Section 5 we analyze the case when the operators A and
BB∗ commute. In Section 6 we present, as an example, a special case of the motivating problem given
in [7] (the case of the so-called Landau-Ginzburg model): we show that it falls into the class of problems
treated in this paper.

2

2 The problem and the main results

2.1 The state equation

Notation 2.1. Given any two Banach spaces Y and Z, we denote by L(Y, Z) the set of all linear bounded
operators from Y to Z, writing L(Y ) when Z = Y . When Y is a Hilbert space we denote by L+(Y ) the
set of all elements of L(Y ) which are selfadjoint and nonnegative.

Let −∞ < s < t < +∞. Consider the abstract linear equation

y′(r) = Ay(r) + Bu(r),

r ∈ ]s, t],

(

y(s) = x ∈ X,

under the following assumption.

Hypothesis 2.2.

(i) X, the state space, and U , the control space, are real separable Hilbert spaces;

(ii) A : D(A) ⊆ X → X is the generator of a C0-semigroup on X such that

ketAkL(X) ≤ M e−ωt,

t ≥ 0,

for given constants M > 0 and ω > 0;

(iii) B : U → X is a bounded linear operator;

(iv) u, the control strategy, belongs to L2(s, t; U ).

We recall the following well known result, pointed out e.g. in [1, Proposition 2.2].

(1)

(2)

Proposition 2.3. For −∞ < s < t < +∞, x ∈ X and u ∈ L2(s, t; U ), the mild solution of (1), deﬁned
by

y(r; s, x, u) = e(r−s)Ax +

s
Z

is in C([s, t], X).

r

e(r−σ)ABu(σ) dσ,

r ∈ [s, t],

We now consider the state equation in the half-line ] − ∞, t]:

y′(r) = Ay(r) + Bu(r),

r ∈ ] − ∞, t],




lim
s→−∞

y(s) = 0.

Since (4) is not completely standard we introduce the following deﬁnition of solution.



Deﬁnition 2.4. Given u ∈ L2(−∞, t; U ), we say that y ∈ C( ] − ∞, t]; X) is a solution of (4) if for every
−∞ < r1 ≤ r2 ≤ t we have

and

y(r2) = e(r2−r1)Ay(r1) +

r2

r1

Z

e(r2−τ )ABu(τ )dτ.

lim
s→−∞

y(s) = 0.

(5)

(6)

Lemma 2.5. Given any u ∈ L2(−∞, t; U ), there exists a unique solution of the Cauchy problem (4) and
it is given by

r

y(r; −∞, 0, u) :=

−∞

Z

e(r−τ )ABu(τ ) dτ,

r ≤ t.

(7)

3

(3)

(4)

Proof. We prove ﬁrst that the function y(·; −∞, 0, u) given by (7) is continuous. Fixed r1 < r2 ≤ t, we
have

y(r2; −∞, 0, u) − y(r1, −∞, 0, u) =

e(r2−τ )ABu(τ ) dτ −

r1

−∞

Z

r2

Z

−∞
r1

=

=

e(r2−r1)A − I

e(r1−τ )ABu(τ ) dτ +

e(r1−τ )ABu(τ ) dτ =

−∞

Z

(cid:16)

(cid:17)

r2

r1

Z

e(r2−τ )ABu(τ ) dτ,

and then continuity follows by standard arguments. We now prove that (5) holds. For −∞ < r1 ≤ r2 ≤ t,
we have

y(r2; −∞, 0, u) =

r2

−∞

Z

e(r2−τ )ABu(τ ) dτ =

= e(r2−r1)A

r1

e(r1−τ )ABu(τ ) dτ +

−∞

Z
= e(r2−r1)Ay(r1; −∞, 0, u) +

r2

r1

Z

r2

r1

Z

e(r2−τ )ABu(τ ) dτ =

e(r2−τ )ABu(τ ) dτ,

so (5) is satisﬁed. Moreover letting r → −∞, since u ∈ L2(−∞, t; U ) and thanks to equation (2), we
have y(r; −∞, x, u) → 0 as r → −∞.
In order to prove uniqueness, consider two solutions y1(·) and y2(·) and a point r ∈ (−∞, t). Since y1(·)
and y2(·) satisfy (5), for their diﬀerence we have, for r0 < r < t,

ky1(r) − y2(r)kX = ke(r−r0)A(y1(r0) − y2(r0))kX ≤ M e−(r−r0)ωk(y1(r0) − y2(r0))kX .

As y1(·) and y2(·) satisfy (6), letting r0 → −∞ above we get y1(r) = y2(r) for every r < t.

Remark 2.6. Notice that, if the initial condition (6) is not zero, then the above equation cannot have
any solution. Indeed any solution y(·; −∞, x, u) of the state equation (4), with 0 replaced by x ∈ X \ {0}
in (6), must satisfy (5) and lims→−∞ y(s) = x. But, as r1 → −∞, (5) implies, as in (7), that

y(r2; −∞, x, u) :=

r2

−∞

Z

e(r2−τ )ABu(τ )dτ,

r2 ≤ t.

(8)

Taking the limit as r2 → −∞ we get x = 0, a contradiction.

2.2 Minimum energy problems with inﬁnite horizon and associated Riccati

equation

To better clarify our results we state, roughly and informally, the mathematical problem (see Section 4
for a precise description). The state space X and the control space U are both real separable Hilbert
spaces. We take the linear controlled system in X

y′(s) = Ay(s) + Bu(s),

s ∈ ] − ∞, 0],

(

y(−∞) = 0,

(9)

where A : D(A) ⊂ X → X generates a strongly continuous semigroup and B : U → X is a linear,
possibly unbounded operator. Given a point x ∈ X we consider the set U[−∞,0](0, x) of all square
integrable control strategies that drive the system from the equilibrium state 0 (at time t = −∞) into
the generic non-equilibrium state x (at time t = 0). It is well known (see Proposition 4.2) that the set
U[−∞,0](0, x) is nonempty if and only if x ∈ H, where H is a suitable subspace of X that can be endowed
with its own Hilbert structure (see next subsection for the precise deﬁnition of H and Subsection A.2 for
its properties).
We want to minimize the “energy-like” functional

J[−∞,0](u) =

1
2

0

−∞

Z

4

ku(s)k2

U ds.

(10)

As usual the value function V∞ is deﬁned as

V∞(x) =

inf
u∈U[−∞,0](0,x)

J[−∞,0](u),

(11)

and it is ﬁnite only when x ∈ H.
The peculiarity of the problem with respect to the most studied minimum energy problems in Hilbert
spaces (see e.g. [10] [13], [14, 15], [20], [28], and the general surveys [3], [11], [22, 23], [32]) is that it gives
rise to an Algebraic Riccati Equation with a ‘wrong’ sign in the linear term to which, to our knowledge,
the standard theory developed in the current literature does not apply.
Indeed, the associated ARE in X (with unknown R), which can be found applying the dynamic program-
ming principle, is, formally,

0 = −hAx, RyiX − hRx, AyiX − hB∗Rx, B∗RyiU ,

x, y ∈ D(A) ∩ D(R).

(12)

Since R is unbounded (this comes from the fact that V∞ is deﬁned only in H), it is convenient to rewrite
(12) in H (with unknown P , which is now a bounded operator on H). This way we get the equation

0 = −hAx, P yiH − hP x, AyiH − hB∗Q−1

∞ P x, B∗Q−1

∞ P yiU ,

or, transforming the inner products in H into inner products in X,

0 = −hAx, Q−1

∞ P yiX − hQ−1

∞ P x, AyiX − hB∗Q−1

∞ P x, B∗Q−1

∞ P yiU ,

(13)

(14)

In the last two equations Q∞ is the so-called controllability operator (see (19)) and Q−1
∞ denotes its
pseudoinverse, which is, in general, unbounded. Moreover the last two equations make sense for x, y
belonging to suitable sets to be speciﬁed later on. For more details on how these equations arise, the
deﬁnitions of solution, and the relations among them, see the discussion at the beginning of Subsection
4.3. Here we just observe that the form of equation (14) turns out to be more suitable to prove our main
results.
The ‘wrong’ sign in the linear term1 of (14) (or (12), or (13)) does not allow us to approach it using the
standard method (described e.g.
in [3, pp. 390-394 and 479-486], see also [28, p.1018]), which consists
in taking the associated evolutionary Riccati equation, proving that it has a solution P (t) (using an a
priori estimate, due to the fact that of both the linear and the quadratic terms have the same sign), and
taking the limit of P (t) as t → ∞.
On the other hand the ‘wrong’ sign comes from the nature of the motivating problem: to look at minimum
energy paths from equilibrium to non-equilibrium states (see Section 6), which is the opposite direction
of the standard one considered in the above quoted papers. This means that the value function depends
on the ﬁnal point, while in the above quoted problems it depends on the initial one (see Remark 3.3 to
see what happens to our auxiliary problem using a time inversion). Therefore we are driven to use a
diﬀerent approach, that exploits the structure of the problem; we partly borrow some ideas from [28] and
from the literature about model reduction2 (see e.g.
[25] and [30]: indeed our results partly generalize
Theorem 2.2 of [30], see Remark 4.4).

2.3 The method and the main results

We now brieﬂy explain our approach. First of all we consider the associated ﬁnite horizon problem
(which has been studied in the companion paper [1] whose results, for the part needed here, are recalled
in Appendix A), where the state equation is

y′(r) = Ay(r) + Bu(r),

r ∈ ] − t, 0],

(

y(−t) = 0,

and the energy to be minimized is

J[−t,0](u) =

1
2

0

−t

ku(r)k2

U dr.

Z
1Evidently the two terms in equation (14) (or (12), or (13)) have the same sign, while in the standard case they do not.

We infer that the ‘wrong’ sign is in the linear term looking at the corresponding ﬁnite horizon problem in [1].

2We thank prof. R. Vinter for providing us these references.

5

(15)

(16)

The value function is

where

V (t, x) =

inf
u∈U[−t,0](0,x)

J[−t,0](u),

We now recall the well known expression of the controllability operator

U[−t,0](0, x) = {u ∈ L2(−t, 0; U ) : y(0) = x}.

Qtx =

t

0
Z

erABB∗erA

∗

x dr,

x ∈ X,

t ∈ [0, +∞].

(17)

(18)

(19)

It is well known (see e.g [32, Part IV, Theorem 2.3]) that, for t ≥ 0, the reachable set of the control
systems (15) (ﬁnite horizon case) and (4) (inﬁnite horizon case), is R(Q1/2
the range of Q1/2
(t ∈ [0, +∞]). This is clearly the set where the value functions V of (17) (ﬁnite horizon case) and V∞
of (11) (inﬁnite horizon case) are well deﬁned. Moreover, as pointed out, e.g., in [1, Proposition C.2-(i)],
for 0 ≤ t1 ≤ t2 we have R(Q1/2
t2 ). It will be often useful to assume, beyond Hypothesis 2.2,
also the following null controllability assumption.

t1 ) ⊆ R(Q1/2

), i.e.

t

t

Hypothesis 2.7. There exists T0 ≥ 0 such that

R(eT0A) ⊆ R(Q1/2
T0

).

Under such assumption we get, for t ≥ T0,

Consequently

R(Q1/2

t1 ) = R(Q1/2
t2 ),

T0 ≤ t1 ≤ t2 ≤ +∞.

ker Qt1 = ker Q1/2

t1 = ker Q1/2

t2 = ker Qt1 ,

T0 ≤ t1 ≤ t2 ≤ +∞.

We can now introduce the already announced space H. We deﬁne

H = R(Q1/2

∞ ).

Of course it holds

H ⊆ R(Q1/2

∞ ) = [ker Q1/2

∞ ]⊥ = [ker Q∞]⊥.

The inclusion is in general proper. Deﬁne in H the inner product

hx, yiH = hQ−1/2

∞ x, Q−1/2

∞ yiX ,

x, y ∈ H.

(20)

(21)

(22)

(23)

Some useful results on the space H which form the ground for our main results and are partly proved in
[1], are recalled (and proved, when needed) in Appendix A.2.
Using H as the ground space we know (see [1, Proposition 4.8-(ii)]) that V (t, x) = 1
2 hP (t)x, xiH , where
P (t) is a suitable extension of Q∞Q−1
is the pseudoinverse of Qt, see [1, Appendix A] or [32,
Part IV, end of Section 2.1]). Moreover, using this explicit expression it is proved in [1, Theorem 4.12]
that P (t) solves the following Riccati equation in H:

(here Q−1

t

t

d
dt

hP (t)x, yiH =−hAx, P (t)yiH−hP (t)x, AyiH−hB∗Q−1

∞ P (t)x, B∗Q−1

∞ P (t)yiU ,

t > 0,

(24)

whose natural condition at t = 0 is, heuristically,

It is not diﬃcult to prove (see Proposition 4.3) that

lim
t→0+

P (t) = +∞.

V∞(x) = lim

t→+∞

V (t, x).

(25)

2 hx, xiH . This allows to prove that P = IH (the identity on H) solves the ARE (14)

and that V∞(x) = 1
in H (Theorem 4.7-(ii)).
However, due to the inﬁnite initial condition at 0 of P (t) (similarly to what happens in [28]), the above
limit does not help to prove any comparison theorem for (14). Here comes the main diﬃculty since, even
in very simple cases, it is not known in the literature whether the ARE characterizes V∞ or not (see e.g.
[7]). To get a comparison result we proceed as follows.

6

• We ﬁrst introduce a suitable auxiliary problem (beginning of Section 3).

• Next, we prove a comparison result for the auxiliary problem (Subsection 3.1, Lemma 3.10).

• Finally we use the relation among the auxiliary problem and the original problem to prove our main

maximality result (Theorem 4.7).

The idea of introducing an auxiliary problem is exploited in [28], too. However the method used there
cannot work here, due to the diﬀerent sign of the linear part of our equation.

3 The auxiliary problem

In this section we introduce an auxiliary problem which can be considered a “time reversed” version of
the auxiliary problem considered in [28] (see also Remark 3.3 about this). This problem will be a key
tool to prove the main result, Theorem 4.7. Indeed, as we will see, any solution of our Algebraic Riccati
Equation (14) is also, under appropriate assumptions, a solution of this auxiliary problem with itself as
initial datum; a comparison argument will then allow to get the main result.
Throughout this section Hypothesis 2.2 will be always assumed, while Hypothesis 2.7 will be used when
necessary.
Let us consider, for x ∈ X, the following set of controls:

U [−t,0](x) = {(z, u) ∈ H × L2(−t, 0; U ) : y(0) = x},

(26)

where y(·) := y(·; −t, z, u) is the solution of the Cauchy problem (similar to (15) but with generic initial
datum z)

y′(r) = Ay(r) + Bu(r),
y(−t) = z.

r ∈ ] − t, 0],

(cid:26)

(27)

Note that a control in U [−t,0](x) is a couple: an initial point z ∈ H and a control u ∈ U[−t,0](z, x), where

U[−t,0](z, x) = {u ∈ L2(−t, 0; U ) : y(0; −t, z, u) = x}.

(this is similar to the set (18) but with a generic initial datum z). The following is true:

Proposition 3.1. Deﬁne the reachable set from the point z as

and set

Rz

[−t,0] :=

x ∈ X : U[−t,0](z, x) 6= ∅

.

(cid:8)

(cid:9)

¯R[−t,0] :=

Rz

[−t,0].

Then the set U [−t,0](x) introduced in (26) is nonempty if and only if x ∈ ¯R[−t,0]. Moreover we have

[z∈H

with equality for t ≥ T0, if Hypothesis 2.7 holds.

¯R[−t,0] ⊆ H,

(28)

(29)

(30)

(31)

Proof. The ﬁrst statement is an immediate consequence of the deﬁnition of reachable set in (29). The
second one follows from (99), Lemma A.4-(i), the fact that R(Q1/2
∞ ) (with equality, for t ≥ T0,
when Hypothesis 2.7 holds), and the equality

) ⊆ R(Q1/2

t

R (L−t,0) = R0

[−t,0] = R(Q1/2

t

),

t ∈ [0, +∞]

(32)

(here L−t,0 is the operator deﬁned in (98)), which is proved in [32, Theorem 2.3] for t < +∞. Such
equality holds also when t = +∞ with exactly the same proof.

7

Given a bounded selfadjoint positive operator N on H we want to minimize, in the class U [−t,0](x), the
following functional with an initial cost:

J N
[−t,0](z, u) =

1
2

hN z, ziH +

1
2

0

−t

Z

ku(s)k2

U ds.

(33)

The presence of the operator N ∈ L+(H) forces us to ﬁx the starting point z at time −t in H, rather
than in X. Deﬁne

V N (t, x) =

inf
(z,u)∈U [−t,0](x)

J N
[−t,0](z, u) = inf
z∈H

inf
u∈U[−t,0](z,x)

(cid:20)

J N
[−t,0](z, u)
(cid:21)

, t > 0, x ∈ X,

(34)

with the agreement that the inﬁmum over the emptyset is +∞, so that V N (t, x) is ﬁnite only when
x ∈ H. Now we provide a relation between V N and the value function V deﬁned in (17).

Proposition 3.2. We have

V N (t, x) = inf
z∈H

V (t, x − etAz) +
(cid:20)

1
2

hN z, ziH

,

t > 0, x ∈ X

(cid:21)

and, in particular,

V N (t, x) ≤ V (t, x)

∀x ∈ X,

∀t > 0.

Proof. We use (96), (100) and (101) getting

(35)

(36)

inf
u∈U[−t,0](z,x)

J N
[−t,0](z, u) = V1(−t, 0; z, x) +

1
2

hN z, ziH = V (t, x − etAz) +

1
2

hN z, ziH .

This equality immediately implies (35). Taking z = 0 we get (36).

The following remark is crucial to understand what is the “natural” Riccati equation associated to this
auxiliary problem.

Remark 3.3. If A generates not just a C0-semigroup but a C0-group, the auxiliary problem can be shown,
under appropriate assumptions, to be equivalent, reversing the time, to a standard optimization problem
with ﬁnal cost. Indeed, given x ∈ H, consider the problem of minimizing, over all v(·) ∈ L2(0, t; U ), the
functional

J N
[0,t](x, v) =

hN w(t), w(t)iH +

kv(s)k2

U ds,

1
2

1
2

t

0
Z

where w(·) := w(·; 0, x, v) is the mild solution of the Cauchy problem

b

w′(s) = −Aw(s) + Bv(s),

s ∈ ] − t, 0],

w(0) = x.

(37)

(38)

Assume now that, for every x ∈ H, the mild solution w(·; 0, x, v) belongs to H for every t > 0. Setting

it can be seen that

V N (t, x) =

inf
v∈L2(0,t;U)

J N
[0,t](x, v),

b

b

V N (t, x) = V N (t, x).

To see this, ﬁx (t, x) ∈ [0, +∞[ ×H and recall that, for every (z, u) ∈ U [−t,0](x), we have

b

etAz +

0

−t

Z

e−sABu(s)ds = x ⇐⇒ z +

e(−t−s)ABu(s)ds = e−tAx;

0

−t

Z

hence, changing variable in the integral,

z = et(−A)x +

t

0

Z

e(t−s)(−A)B(−u(−s))ds.

8





This means that ¯R[−t,0] = H (see (30)). Moreover, to any (z, u) ∈ U [−t,0](x) we can associate a function
v ∈ L2(0, t; U ) such that w(t) = z, namely, v(s) = −u(−s); consequently

J N
[−t,0](z, u) =

J N
[0,t](x, v).

(39)

Conversely, given any v ∈ L2(0, t; U ), set z = w(t; 0, x, v) and u(s) = −v(−s): then, clearly, (z, u) ∈
U [−t,0](x) and, again, (39) holds. In conclusion, there is a one-to-one correspondence between the control
set of the two problems and, in particular,

V N (t, x) = V N (t, x).

b

The equation for the “time-reversed” problem (37)-(38) turns out to be the following:

b

d
ds

hP N (s)x, yiH = −hAx, P N (s)yiH − hP N (s)x, AyiH −
∞ P N (s)yiU ,

∞ P N (s)x, B∗Q−1

−hB∗Q−1

s ∈ ]0, t],

(40)

P N (0) = N.

To give sense to (40) we must take x, y ∈ D(A) ∩ H with Ax, Ay ∈ H and P N (t)x, P N (t)y ∈ R(Q∞).
When B∗Q−1
∞ can be extended to a bounded operator H → U and A generates a group, then it is known
P N : [0, +∞[→ L+(H) is
V N (t, x) = h
that the value function
the unique solution of (40). In our case this is not obvious, but it suggests anyway the right form of the
Riccati equation for our auxiliary problem. Note, ﬁnally, that the right hand side of (40) is exactly one
of the forms of the ARE we aim to study (see (13)).

P N (t)x, xiH , where

V N is quadratic and

b

b

b

b

Remark 3.4. As in the case N = 0 treated in [1], in the above Riccati equations the sign of the linear
part is opposite to the usual one. In fact the control problem (27)-(33) involves an “initial cost”, instead
of a ﬁnal cost like in the standard problems (see e.g. [28]).

Our aim now is to prove that for every stationary solution Q of the Riccati equation (40) (in a suitable
class to be deﬁned later) there exists an operator N , namely Q itself, such that

1
2

hQx, xiH ≤ V N (t, x),

for suﬃciently large t.

Remark 3.5. It is possible to prove much more about the auxiliary problem, namely:

(i) that, for every N ∈ L+(H) the value function V N is continuous and is a quadratic form in H;

(ii) that, when N is coercive (i.e., for some ν > 0, hN x, xiH ≥ ν|x|2

P N associated to the value function solves the Riccati equation (40);

H for all x ∈ H), the linear operator

(iii) that the comparison result mentioned above translates in the inquality P N ≥ QN , in the preorder
of positive operators, for every constant solution QN of the Riccati equation (40) in a suitable class.

This is the subject of a paper in progress.

3.1 A key comparison result

Given any initial datum N ∈ L+(H), we want to compare the “stationary” solutions of the Riccati
equation (40) with the value function V N of the auxiliary problem. This fact will be used, in the next
section, as a key tool to prove our main results. In order to do this we need ﬁrst to give a precise meaning
to the concept of stationary solution of (40).
Roughly speaking, a stationary solution P ∈ L+(H) of the Riccati Equation (40) should also be a solution
of the following Algebraic Riccati Equation (ARE), which comes from the right hand side of (40):

0 = −hAx, P yiH − hP x, AyiH − hB∗Q−1

∞ P x, B∗Q−1

∞ P yiU .

(41)

This equation is meaningful for every x, y ∈ D(A) ∩ H with P x, P y ∈ R(Q∞) and Ax, Ay ∈ H. Since
the last requirement appears too restrictive, we rewrite (41) by taking the ﬁrst two inner products in X,
getting:

0 = −hAx, Q−1

∞ P yiX − hQ−1

∞ Ox, AyiX − hB∗Q−1

∞ P x, B∗Q−1

∞ P yiU .

(42)

9

This makes sense in a larger set of vectors x, y, namely for every x, y ∈ D(A) ∩ H with P x, P y ∈ R(Q∞).3
We can now provide the precise deﬁnition of solution of (42).

Deﬁnition 3.6. Let P ∈ L+(H) and deﬁne the operator ΛP as follows:

D(ΛP ) = {x ∈ H : P x ∈ R(Q∞)}
ΛP x = Q−1

∀x ∈ D(ΛP ).

∞ P x

(

(43)

We say that P is a solution of (42) (or, alternatively, a stationary solution of (40)) if D(A) ∩ D(ΛP ) is
dense in [ker Q∞]⊥ and

0 = −hAx, ΛP yiX − hΛP x, AyiX − hB∗ΛP x, B∗ΛP yiU

∀x, y ∈ D(A) ∩ D(ΛP ).

(44)

We now deﬁne a subclass Q of the class of all stationary solutions of (40). First of all we recall that, by
Lemma A.4-(i), etA|H is a strongly continuous semigroup in H. We then use the following notation.

Notation 3.7. We denote by A0 : D(A0) ⊆ H → H the generator of etA|H , and we write etA0 in place
of etA|H .

Deﬁnition 3.8. Let P ∈ L+(H). We say that P ∈ Q if there exists D ⊆ D(ΛP ) such that D is dense in
D(A) ∩ H with respect to the norm k · kH + kA · kX ;

Lemma 3.9. The set R(Q∞) ∩ D(A) is dense in D(A) ∩ H, equipped with the norm k · kH + kA · kX .
Hence, choosing D = R(Q∞) ∩ D(A), we have P = IH ∈ Q.

Proof. Let x ∈ H ∩ D(A) such that

hx, ziH + hAx, AziX = 0,

∀z ∈ R(Q∞) ∩ D(A).

It is enough to prove that x = 0. Observe that, writing z = Q∞y,

hx, Q∞yiH + hAx, AQ∞yiX = 0,

∀y ∈ D(AQ∞).

Then

hAx, AQ∞yiX = −hx, Q∞yiH = −hx, yiX

∀y ∈ D(AQ∞).

This means that Ax ∈ D((AQ∞)∗) and (AQ∞)∗Ax = −x. Hence

h(AQ∞)∗Ax, AxiX = −hx, AxiX = |(−A)1/2x|2

X ≥ 0.

On the other hand we know, from [1, Lemma 3.1-(ii)], that, for every y ∈ D((AQ∞)∗) ⊆ D(AQ∞)

so that

2h(AQ∞)∗y, yiX = −kB∗yk2

U ,

2h(AQ∞)∗Ax, AxiX = −kB∗Axk2

U ≤ 0.

This implies that k(−A)1/2xk2

X = 0; hence Ax = 0 and, since A is invertible, x = 0.

Lemma 3.10. Assume Hypothesis 2.7. Let P ∈ L+(H) be a solution of (42) according to Deﬁnition 3.6.
Assume also that P ∈ Q and that BB∗ is coercive, which is equivalent to require that, for some µ > 0,
kB∗xkU ≥ µkxkX for all x ∈ X. Then, the following estimate holds:

1
2

hP x, xiH ≤ V P (t − T0, x)

∀x ∈ H, ∀t > T0,

where V P is the value function deﬁned in (34) with N = P .
3Note that (41) is the same as (13) while (42) is the same as (14).

10

Proof.
Step 1 We prove the estimate

hP x, xiH ≤ hP y(T0 − t), y(T0 − t)iH +

0

T0−t

Z

ku(s)k2

U ds,

t > T0,

for every (z, u) ∈ U [−t,0](x) with x ∈ H, where y is the state corresponding to (z, u), i.e.

y(s) = e(s+t)Az +

e(s−σ)A Bu(σ) dσ,

s ∈ [−t, 0].

s

−t

Z

(45)

(46)

Such inequality would be easy to prove if we were able to compute d

ds hP y(s), y(s)iH and prove that

d
ds

hP y(s), y(s)iH ≤ ku(s)k2
U ,

s ∈ [−t, 0].

Unfortunately we even do not know if such a derivative exists. Hence we need to build a delicate
approximation procedure as follows.
Fix t > T0 and x ∈ H; consider any (z, u) ∈ U [−t,0](x).
u(σ) ∈ R(B∗) for every σ ∈ [−t, 0]: indeed, writing, for every such σ,

It is not restrictive to assume in (46) that

u(σ) = u1(σ) + u2(σ),

u1(σ) ∈ R(B∗),

u2(σ) ∈ R(B∗)

⊥

= ker B,

it is clear that e(s−σ)ABu2(σ) = 0. Hence

y(s) = e(s+t)Az +

s

−t

Z

e(s−σ)A Bu1(σ) dσ,

s ∈ [−t, 0].

[−t,0](z, u) ≥ J P
D(A0)

Since, evidently, J P
× C1
sequence {(zn, un)} ⊆
in H × L2(−t, 0; U ). Thus we can set un = B∗vn, where vn ∈ C1
corresponding state, we have yn ∈ C1([−t, 0]; H) ∩ C([−t, 0]; D(A)) (see e.g.
2.5]) and

[−t,0](z, u1), we can always choose u1 in place of u. Next, select a
0 ([−t, 0]; U )4, such that un is R(B∗)-valued and (zn, un) → (z, u)
0 ([−t, 0], X) and, denoting by yn the
[27, Chapter 4, Corollary

(cid:3)

(cid:2)

yn(s) = e(s+t)Azn +

e(s−σ)A BB∗vn(σ) dσ,

s ∈ [−t, 0].

s

Thanks to the properties of the set D of Hypothesis 3.8, we can now choose, for every n ∈ N, another
approximating sequence {ynk}h∈N ⊂ C1([−t, 0], H) ∩ C0
0 ([−t, 0], D(A)), such that ynk(s) ∈ D for every
s ∈ [−t, 0] and satisfying, as k → +∞,

−t

Z

ynk → yn in C1([−t, 0]; H),

Aynk → Ayn in C([−t, 0]; X)

(47)

(see e.g. [27, Chapter 4, Theorem 2.7]). Set now wnk = y′

nk − Aynk. By (47) we get, for every n ∈ N,

wnk → yn − Ayn = BB∗vn in C0([−t, 0]; X)

as k → +∞.

(48)

We now can diﬀerentiate the quantity hP ynk(s), ynk(s)iH for s ∈ [−t, 0]. Indeed, taking into account the
above deﬁnition of wnk, we obtain, for s ∈ [−t, 0] and n, k ∈ N:

d
ds

hP ynk(s), ynk(s)iH = hy′

nk(s), P ynk(s)iH + hP ynk(s), y′

nk(s)iH =

= hy′

nk(s), ΛP ynk(s)iX + hΛP ynk(s), y′

nk(s)iX =

= hAynk(s) + wnk(s), ΛP ynk(s)iX + hΛP ynk(s), Aynk(s) + wnk(s)iX .

4C1

0 ([−t, 0]; U ) is the set of C1 U -valued functions which take the value 0 at the boundary.

11

Since P solves the ARE (44) we get, for every s ∈ [−t, 0],

d
ds

hP ynk(s), ynk(s)iH =

= −kB∗ΛP ynk(s)k2

U + hwnk(s), ΛP ynk(s)iX + hΛP ynk(s), wnk(s)iX =

= −kB∗ΛP ynk(s)k2

U + hB∗vn(s), B∗ΛP ynk(s)iU + hB∗ΛP ynk(s), B∗vn(s)iU =

+hwnk(s) − BB∗vn(s), ΛP ynk(s)iX + hΛP ynk(s), wnk(s) − BB∗vn(s)iX =

= −kB∗ΛP ynk(s) − B∗vn(s)k2

U + kB∗vn(s)k2

U +

+hwnk(s) − BB∗vn(s), ΛP ynk(s)iX + hΛP ynk(s), wnk(s) − BB∗vn(s)iX .

Hence, recalling that un = B∗vn, we may write for every ε > 0,

d
ds

hP ynk(s), ynk(s)iH ≤ −kB∗ΛP ynk(s) − B∗vn(s)k2

U + kun(s)k2

U +

+2kwnk(s) − Bun(s)kX kΛQP ynk(s)kX ≤
U + kun(s)k2

≤ −kB∗ΛP ynk(s) − B∗vn(s)k2

U +

+

1
ε

kwnk(s) − Bun(s)k2

X + εkΛP ynk(s)k2
X .

Now observe that

εkΛP ynk(s)k2

X ≤

ε
µ

kB∗ΛP ynk(s)k2

U ≤ 2

ε
µ

kB∗ΛP ynk(s) − B∗vn(s)k2

U + 2

ε
µ

kB∗vn(s)k2
U .

Inserting this inequality into (49) we get

d
ds

hP ynk(s), ynk(s)iH ≤ −

1 − 2

(cid:18)

+

1 + 2

Hence, for all positive ε such that 2 ε

(cid:18)
2 we get

µ ≤ 1

ε
µ

ε
µ

(cid:19)

(cid:19)

kB∗ΛP ynk(s) − B∗vn(s)k2

U +

kun(s)k2

U +

1
ε

kwnk(s) − Bun(s)k2

X .

(49)

(50)

d
ds

hP ynk(s), ynk(s)iH ≤

1 + 2

(cid:18)

kun(s)k2

U +

1
ε

ε
µ

(cid:19)

kwnk(s) − Bun(s)k2

X .

(51)

Now we have for every s ∈ [−t, 0], as k → ∞,

kynk(s) − yn(s)kH → 0,

ky′

nk(s) − y′

n(s)kH → 0,

kwnk(s) − Bun(s)kX → 0;

thus we get, for every n ∈ N+, s ∈ [−t, 0] and 0 < ε ≤ µ/4,

d
ds

hP yn(s), yn(s)iH ≤

1 + 2

(cid:18)

kun(s)k2

U .

ε
µ

(cid:19)

Finally, letting ε → 0,

d
ds

hP yn(s), yn(s)iH ≤ kun(s)k2
U

∀n ∈ N+,

∀s ∈ [−t, 0].

We now integrate in the smaller interval [T0 − t, 0]:

hP yn(0), yn(0)iH ≤ hP yn(T0 − t), yn(T0 − t)iH +

0

T0−t

Z

kun(s)k2

U ds.

12

Letting n → ∞, since yn(s) → y(s) for every s ∈ [−t, 0], y(0) = x, and un → u in L2(−t, 0; U ), we deduce
for every (z, u) ∈ U [−t,0](x)

hP x, xiH ≤ hP y(T0 − t), y(T0 − t)iH +

0

T0−t

Z

ku(s)k2

U ds,

t > T0;

this is equation (45).

Step 2 We complete the proof of the Lemma. Consider a sequence (ˆzn, ˆun) ∈ U [T0−t,0](x), such that, as
n → ∞,

J P
[T0−t,0](ˆzn, ˆun) →

inf
(z,u)∈U [T0

−t,0](x)

[T0−t,0](z, u) = V P (t − T0, x).
J P

(52)

Thus ˆzn ∈ H, ˆun ∈ L2(T0 − t, 0; U ) and the corresponding state is

ˆyn(s) = e(s+t−T0)A ˆzn +

e(s−σ)AB ˆun(σ) dσ,

s ∈ [T0 − t, 0];

s

T0−t

Z

in particular ˆyn(0) = x. Now choose ˆvn ∈ L2(−t, T0 − t; U ) such that

T0−t

−t

Z

e(T0−t−σ)ABˆvn(σ) dσ = ˆzn;

(53)

this is possible since, due to Hypothesis 2.7, the range of the operator (deﬁned in (98))

is all of H (see [32, Theorem 2.3]). Then, setting

v 7→ L−t,T0−t(v) = L−T0,0(v(· + t − T0))

un =

ˆvn

in [−t, T0 − t]

(

ˆun

in [T0 − t, 0],

the state corresponding to (0, un) in [−t, 0] is

yn(s) =

s

−t

Z

e(s−σ)ABun(σ) dσ.

yn(T0 − t) =

T0−t

−t

Z

e(T0−t−σ)ABun(σ) dσ = ˆzn;

By (53) we have

hence, by uniqueness,

yn(s) = e(s+t−T0)A ˆzn +

s

T0−t

Z

e(s−σ)AB ˆun(σ) dσ = ˆyn(s)

∀s ∈ [T0 − t, 0],

so that yn(0) = ˆyn(0) = x. This shows that (0, un) ∈ U [−t,0](x), and consequently, by (45),

hP x, xiH ≤ hP ˆzn, ˆzniH +

0

T0−t

Z

Finally, by (52), as n → ∞ we get

kˆun(s)k2

U ds = 2J P

[T0−t,0](ˆzn, ˆun).

1
2

hP x, xiH ≤ V P (t − T0, x)

∀t > T0,

∀x ∈ H.

13

4 Minimum energy with (negative) inﬁnite horizon

We now give a precise formulation of our inﬁnite horizon problem (see Subsection 2.2 and also [1, Remark
2.8]). We assume that Hypothesis 2.2 holds throughout this section without repeating it. For any given
control u ∈ L2(−∞, s; U ) we take the state equation

y′(r) = Ay(r) + Bu(r),
y(−∞) = 0.

(cid:26)

r ∈ ] − ∞, s],

(54)

By Lemma 2.5 we know that the unique solution of (54) belongs to C( ] − ∞, s]; X), is given by

y(r) := y(r; −∞, 0, u) =

r

−∞

Z

e(r−τ )ABu(τ ) dτ, −∞ < r ≤ s,

and satisﬁes, for every −∞ < r1 ≤ r2 ≤ s,

y(r2) = e(r2−r1)Ay(r1) +

r2

r1

Z

As for the ﬁnite horizon case, we deﬁne:

e(r2−τ )ABu(τ ) dτ,

and

lim
r→−∞

y(r) = 0

in X.

U[−∞,s](0, x)

def
=

u ∈ L2(−∞, s; U ) : y(s; −∞, 0, u) = x

,

(55)

(cid:8)

J[−∞,s](u) =

V1(−∞, s; 0, x)

def
=

1
2

s

−∞

Z

ku(r)k2

U dr,

inf
u∈U[−∞,s](0,x)

J[−∞,s](u),

(cid:9)

with the agreement that the inﬁmum over the empty set is +∞. From (55) it is easy to see that

u(·) ∈ U[−∞,s](0, x) ⇐⇒ u(· − s) ∈ U[−∞,0](0, x);

(56)

this implies that

From now on we set, as in (101)

V1(−∞, s; 0, x) = V1(−∞, 0; 0, x).

V∞(x) = V1(−∞, 0; 0, x) =

inf
u∈U[−∞,0](0,x)

J[−∞,0](u),

x ∈ X.

(57)

We collect now some results about the above problem and the function V∞.

4.1 Optimal strategies

We start proving the existence of optimal strategies.

Proposition 4.1. The set U[−∞,0](0, x) is nonempty if and only if x ∈ H. Moreover, for every x ∈ H
there exists a unique ˆux ∈ U[−∞,0](0, x) such that

V∞(x) = J[−∞,0](ˆux).

Proof. The ﬁrst statement follows from (32) as in Proposition 3.1. Now take x ∈ H and observe that any
minimizing sequence {un}n∈N must be bounded in L2(−∞, 0; U ); so, passing to a subsequence, we have
un ⇀ ˆux in L2(−∞, 0; U ). As the functional J[−∞,0] is weakly lower semicontinuous, we get

V∞(x) ≤ J[−∞,0](ˆux) ≤ lim inf
n→∞

J[−∞,0](un) = V∞(x),

i.e. ˆux is optimal. Uniqueness is an easy consequence of the strict convexity of the functional J[−∞,0].

Moreover we have the following result about the optimal couples when x ∈ R(Q∞) (see [1, Proposition
C.3 and Remark C.4]).

14

Proposition 4.2. Let x ∈ R(Q∞). Let (ˆyx, ˆux) be the optimal couple for our problem with target x.
Then we have

ˆux(r) = B∗e−rA

Q−1

∞ x,

r ∈ ] − ∞, 0].

∗

Moreover the corresponding optimal state ˆyx satisﬁes

ˆyx(r) = Q∞e−rA

∗

Q−1

∞ x,

r ∈ ] − ∞, 0];

hence the optimal couple satisﬁes the feedback formula

ˆux(r) = B∗Q−1

∞ ˆyx(r),

r ∈ ] − ∞, 0],

and, formally, ˆyx is a solution of the backward closed loop equation (BCLE)

y′(r) = (A + BB∗Q−1

∞ )y(r),

r ∈ ] − ∞, 0[ ,

y(0) = x,

which, since Q∞ solves the Lyapunov equation (see [1, Proposition 3.3] rewrites as

y′(r) = −Q∞A∗Q−1

∞ y(r),

r ∈ ] − ∞, 0[ .

(58)

(59)

(60)

(61)

(62)

If A∗ commutes with Q∞ (e.g. when A is selfadjoint and invertible, and A and BB∗ commute), then
(62) becomes

y′(r) = −A∗y(r),

r ∈ ] − ∞, 0[ .

(63)

This means that, in such case, the optimal trajectory arriving at x is given by

y(r) = e−rA

∗

x,

r ∈ ] − ∞, 0].

4.2 Connection with the ﬁnite horizon case

We now prove the connection between V∞ and the value function V of the corresponding ﬁnite horizon
problem which is studied in [1] (see also Appendix A).

Proposition 4.3. Under Hypothesis 2.7, for every x ∈ H we have

V∞(x) = lim

t→+∞

V (t, x) = inf
t>0

V (t, x).

Moreover V∞(x) = 1

2 kxk2
H .

Proof. First of all, by [1, Proposition 4.8-(i)], the function V (·, x) is decreasing for every x ∈ H; hence,
for every such x

∃ lim

t→+∞

V (t, x) = inf
t>0

V (t, x).

We now prove that V∞(x) ≤ inf t>0 V (t, x). With an abuse of notation we can write

U[−t,0](0, x) ⊆ U[−∞,0](0, x)

∀t > 0 :

indeed, given a control bringing 0 to x in the interval [−t, 0], we can extend it to a control bringing 0
to x in the interval [−∞, 0] just taking the null control on ] − ∞, −t]. So, if the set U[−t,0](0, x) is not
empty, a fortiori the set U[−∞,0](0, x) will be not empty. This fact, together with the monotonicity of
V (·, x) implies that V∞(x) ≤ inf t>0 V (t, x).
We prove now that V∞(x) = inf t>0 V (t, x). Assume by contradiction that V∞(x) < inf t>0 V (t, x), and let
ε > 0 be such that V∞(x)+2ε < inf t>0 V (t, x). Take uε ∈ U[−∞,0](0, x) such that J[−∞,0](uε) < V∞(x)+ε.
By (5) we get

x =

0

−∞

Z

e−τ ABuε(τ ) dτ = etAy(−t) +

e−τ ABuε(τ ) dτ

∀t > 0;

0

−t

Z

hence we have uε|[−t,0] ∈ U[−t,0](y(−t), x), which in turn implies that

V (t, x − etAy(−t)) ≤

1
2

0

−t

Z

kuε(s)k2

U ds.

15

(64)

Now we observe that for every δ ∈ ]0, 1[ we may choose tδ > T0 + 1 such that ketAy(−t)kH ≤ δ for every
t > tδ: indeed, by Hypothesis 2.7 and Lemma A.1-(v) we have

ketAy(−t)kH = kQ−1/2

∞ etAy(−t)kX ≤ kQ−1/2
∞ eAkL(X)M e−ω(t−1)ky(−t)kX .

≤ kQ−1/2

∞ eAkL(X)ke(t−1)Ay(−t)kX ≤

Since y(−t) is uniformly bounded in X for t > 0, we have the claim.
Going ahead with the proof, we recall that, by [1, Proposition 4.8-(iii)-(b)], we have uniform continuity
of V on [T0, +∞] × BH (0, R) for every R > 0, where BH (0, R) is the ball of center 0 and radius R in H.
So, setting R = kxkH + 1, and denoting by ρR the continuity modulus of V on [T0, +∞] × BH (0, R), we
have for t > tδ

V

t, x − etAy(−t)

> V (t, x) − ρR(δ).

The above, together with (64), implies that

(cid:0)

(cid:1)

V (t, x) − ρR(δ) ≤ V∞(x) + ε

∀t > tδ .

Now it is enough to choose δ such that ρR(δ) < ε to get a contradiction.
Finally the last statement follows from [1, Proposition 4.8-(iii)-(d)].

4.3 Algebraic Riccati Equation

We deal with the Algebraic Riccati Equation (ARE from now on) associated to our inﬁnite horizon
problem. As well known, when the value function is a quadratic form in the state space X, the ARE is
an equation whose unknown is an operator R. A typical goal in studying such ARE is to prove that the
operator representing the quadratic form in X given by the value function is a solution (possibly unique)
of the associated ARE. Formally our ARE is given as follows:

0 = −hAx, RyiX − hRx, AyiX − hB∗Rx, B∗RyiU ,

x, y ∈ D(A).

(65)

In our case (see Proposition 4.1) the value function V∞ is ﬁnite only in H so that the operator R above
must be unbounded and the above equation makes sense only for x, y ∈ D(A) ∩ D(R). Moreover, by
Proposition 4.3, V∞ is a quadratic form on the space H, represented by the identity operator IH ∈ L(H),
H . Consequently, transforming such norm in X, it must be V∞(x) = 1
i.e. V∞(x) = 1
2 kxk2
X, and,
when x ∈ R(Q∞), V∞(x) = 1
∞ x, xiX . Hence it is natural to deduce that the operator representing
V∞ in the space X is Q−1
∞ .
Due to the unboundedness of the candidate solution R of the ARE (65), it seems better to study the
corresponding ARE in the space H, with unknown P ∈ L(H) whose form (taking R = Q−1
∞ P ) must be
(compare with (14)):

2 kQ−1/2

2 hQ−1

∞ k2

0 = −hAx, Q−1

∞ P yiX − hQ−1

∞ P x, AyiX − hB∗Q−1

∞ P x, B∗Q−1

∞ P yiU .

(66)

Note that such expression makes sense only when P x, P y ∈ R(Q∞) and x, y ∈ D(A) ∩ H.
By Proposition 4.3, we expect that the positive selfadjoint operator P = IH associated with the value
function V∞ is a solution of the above ARE (66). Similarly we expect that R = Q−1
∞ is a solution of the
above ARE (65). As they cannot be unique (the zero operator is always a solution of both), we somehow
expect such solutions to be maximal in some suitable sense.

Remark 4.4. In the ﬁnite-dimensional case, when the operator Q∞ is invertible, it is proved that the
operator R = Q−1
∞ solves (65), using the fact that its inverse W = Q∞ is the unique solution of the
Lyapunov equation

AW + W A∗ = −BB∗

(67)

among all deﬁnite positive bounded operators X → X. This is reported by Scherpen [30, Theorem 2.2],
who quotes Moore [25] for the proof (see also [21, Chapters 5 and 7] for related results). In fact, as we
will see, this procedure works in our inﬁnite dimensional case, too, but with more diﬃculties.

16

Deﬁnition 4.5.

(i) An operator P ∈ L+(H) is a solution of the ARE (66) if the set D(A) ∩ D(ΛP )

(see (43)) is dense in H and the equation (66) is satisﬁed for all x, y ∈ D(A) ∩ D(ΛP ).

(ii) A positive, selfadjoint, possibly unbounded operator R : D(R) ⊂ X → X is a solution of the ARE
(65) if the set D(A) ∩ D(R) is dense in [ker Q∞]⊥ (in the topology inherited by X) and the equation
(65) is satisﬁed for all x, y ∈ D(A) ∩ D(R).

Proposition 4.6. The following facts are equivalent.

(i) P ∈ L+(H) is a solution to (66);

(ii) R = Q−1

∞ P is a solution to (65) and it satisﬁes, in addition, Q1/2

∞ RQ1/2

∞ ∈ L(X).

Proof. (i) Assume that P ∈ L+(H) solves (66). Then, in particular the set D(A) ∩ D(ΛP ) is dense in
H. Setting R = Q−1
∞ P we see that its domain is exactly D(ΛP ), which is dense in [ker Q∞]⊥. The fact
that such R satisﬁes (65) for every x, y ∈ D(A) ∩ D(ΛP ) follows by simple substitution. Finally, for every
x ∈ X we have

kQ1/2

∞ RQ1/2

∞ xkX = kQ−1/2

∞ P Q1/2

∞ xkX = kP Q1/2

∞ xkH ≤ kP kL(H)kQ1/2

∞ xkH = kP kL(H)kxkX .

(ii) Let R : D(R) → X be a solution of (65), having the property Q1/2
∞ ∈ L(X): note that, in this
case, D(R) must coincide with H. Thus D(A) ∩ D(R) is dense in H, since it contains D(A0). We set
P = Q∞R: then P ∈ L+(H) since, for every x ∈ H,

∞ RQ1/2

kP xkH = kQ∞RxkH = kQ1/2

≤ kQ1/2

∞ RQ1/2

∞ [Q1/2
∞ kL(X)kQ−1/2

∞ ]Q−1/2
∞ RQ1/2
∞ xkX = kQ1/2

∞ xkH = k[Q1/2
∞ RQ1/2

∞ kL(X)kxkH .

∞ RQ1/2

∞ ]Q−1/2

∞ xkX ≤

Moreover, we see immediately that D(ΛP ) = H. In addition, (65) transforms into (66), and it holds
for every x, y ∈ D(A) ∩ D(R), i.e.
it holds for every x, y ∈ D(A) ∩ H = D(A) ∩ D(ΛP ), as required by
Deﬁnition 4.5.

Concerning the two AREs (66) and (65) we have the following result.

Theorem 4.7. Let Hypothesis 2.7 hold true.

(i) The operator R = Q−1

∞ is a solution of the Riccati equation (65) in the sense of Deﬁnition 4.5(ii).

(ii) The operator P = IH is a solution of the Riccati equation (66) in the sense of Deﬁnition 4.5(i).

(iii) Assume that BB∗ is coercive. Then the operator IH is the maximal solution of (66) in the following
sense: if ˆP is another solution of (66) in the sense of Deﬁnition 4.5-(i), belonging to the class Q
introduced in Deﬁnition 3.8, then

1
2

h ˆP x, xiH ≤

1
2

hx, xiH = V∞(x)

∀x ∈ H.

Proof. (i) By [1, Proposition 3.3], Q∞ solves the Lyapunov equation, i.e. we have for every ξ ∈ D(A∗)

This implies that, for every ξ ∈ D(A∗) and η ∈ X,

AQ∞ξ + Q∞A∗ξ + BB∗ξ = 0.

hAQ∞ξ, ηiX + hQ∞A∗ξ, ηiX + hB∗ξ, B∗ηiU = 0.

When η ∈ D(AQ∞) the second term above rewrites as hξ, AQ∞ηiX . Consequently, when η ∈ D(AQ∞),
the functional ξ → hAQ∞ξ, ηiX , well deﬁned since ξ ∈ D(A∗), can be extended to a bounded linear
operator on X, since it is equal to −hξ, AQ∞ηiX − hB∗ξ, B∗ηiU . Hence, choosing ξ ∈ D(AQ∞), we get,
for ξ, η ∈ D(AQ∞), that

hAQ∞ξ, ηiX + hξ, AQ∞ηiX + hB∗ξ, B∗ηiU = 0.

(68)

17

Now set x = Q∞ξ and y = Q∞η. Then x, y ∈ D(A) and the above rewrites as

hAx, ηiX + hξ, AyiX + hB∗ξ, B∗ηiU = 0.

(69)

Observe that ξ = Q−1
fact that Q∞ solves the Lyapunov equation in the form (68), we have, for ξ ∈ D(AQ∞),

∞ y + η0 for suitable ξ0, η0 ∈ ker Q∞ ⊆ ker B∗. Hence, using the

∞ x + ξ0 and η = Q−1

hAx, η0iX = hAQ∞ξ, η0iX = −hξ, AQ∞η0iX − hB∗ξ, B∗η0iU = 0

and, similarly, for η ∈ D(AQ∞), hξ0, AyiX = 0. We then get, substituting into (69) and observing that
B∗ξ0 = B∗η0 = 0,

hAx, Q−1

∞ yiX + hQ−1

∞ x, AyiX + hB∗Q−1

∞ x, B∗Q−1

∞ yiU = 0, +x, y ∈ Q∞(D(AQ∞)).

(70)

The above is exactly equation (65) for R = Q−1
∞ . To end the proof of (i), it is enough to observe that
Q∞(D(AQ∞)) is dense in [ker Q∞]⊥ (using Remark A.3 and the fact that it contains Q∞(D(A∗))), and
moreover that

Q∞(D(AQ∞)) = D(A) ∩ R(Q∞) = D(A) ∩ D(Q−1
Indeed if x ∈ Q∞(D(AQ∞)) then it must be x = Q∞ξ with ξ ∈ (D(AQ∞)), so that AQ∞ξ is well deﬁned
and, clearly, it coincides with Ax, proving that x ∈ D(A). Obviously it must also be x ∈ R(Q∞). The
converse is similar.
(ii) It is enough to observe that (70) coincides with (66) with P = IH , and that D(ΛIH ) = R(Q∞).
(iii) Let ˆP be a solution of (66) belonging to the class Q introduced in Deﬁnition 3.8. It is immediate to
see that ˆP is a stationary solution of (40) in the sense of Deﬁnition 3.6. Now we apply Lemma 3.10 and
(36), getting

∞ ).

Taking the limit as t → +∞, the result follows by Proposition 4.3.

h ˆP x, xiH ≤ V

ˆP (t, x) ≤ V (t, x) x ∈ H,

t > T0.

1
2

Remark 4.8. The statement of Theorem 4.7 still holds if we consider the slightly more general problem
where the energy functional has the integrand hCu, uiU instead of hu, uiU , where C ∈ L+(U ) is coercive
and hence invertible. Indeed it is enough to deﬁne the new control variable v = C1/2u and, consequently,
to replace the control operator B in the state equation by BC−1/2.

Remark 4.9. Theorem 4.7 can be applied to a variety of cases (e.g. delay equations treated in [1,
Subsection 5.1] or wave equations). Here, according to our motivating example arising in physics, we
develop more deeply the analysis when the operator A is selfadjoint and commutes with BB∗ and, in
particular, when both are diagonal. This will be done in the next section.

5 The selfadjoint commuting case

We consider the case where A is selfadjoint and invertible and commutes with BB∗. To apply Theorem
4.7 we need that BB∗ is coercive; hence we assume the following:

Hypothesis 5.1. A is selfadjoint and invertible and commutes with BB∗ i.e.
for every x ∈ D(A) we
have BB∗x ∈ D(A) and ABB∗x = BB∗Ax. Moreover, BB∗ is coercive, i.e., for a suitable µ > 0,
kB∗xkU ≥ µkxkX for all x ∈ X.

From [1, Proposition C.1-(v)] we know that, for every x ∈ X,

Q∞x = −

1
2

A−1BB∗x.

This implies that R(Q∞) = D(A), and, as BB∗ is invertible in X, we have Q−1
∞ x = −2(BB∗)−1Ax
for every x ∈ R(Q∞) (see again [1, Proposition C.1-(v)]). Hence the Riccati equation (66) in H (with
unknown P ∈ L(H)), becomes

0 = −hAx, Q−1

∞ P yiX − hQ−1

∞ P x, AyiX + 2hAP x, Q−1

∞ P yiX .

(71)

18

This makes sense, as for (66), when x, y ∈ D(A) ∩ D(ΛP ) (see Deﬁnition 3.6). We now want to rewrite
∞ Q−1/2
this equation using the inner products in H. Observe ﬁrst that in R(Q∞) we have Q−1
∞ .
Then, if Ax, Ay and AP x belong to H, we rewrite (71) as

∞ = Q−1/2

0 = −hAx, P yiH − hP x, AyiH + 2hAP x, P yiH .

(72)

Now, recalling the deﬁnition of A0 (see Notation 3.7 and Lemma A.4)-(ii)), equation (72) can be equiva-
lently rewritten as

0 = −hA0x, P yiH − hP x, A0yiH + 2hA0P x, P yiH ,

provided that x, y, P x, P y belong to D(A0).
We now clarify the relationship between (71) and (73). First we set

DP := {x ∈ D(A0) : P x ∈ D(A0)} .

(73)

(74)

Next, we provide the following deﬁnition of solution for (73) (compare with Deﬁnition 4.5):

Deﬁnition 5.2. An operator P ∈ L+(H) is a solution of the ARE (73) if the set DP is dense in H and
the equation (73) is satisﬁed for every x, y ∈ DP .

Finally, we observe that every solution of (71) is also a solution of (73): indeed, if P ∈ L+(H), then, by
deﬁnition, we have DP ⊆ D(A) ∩ D(ΛP ). Hence, if P ∈ L+(H) solves equation (71), then, choosing in
particular x, y ∈ DP we can turn (71) into (73).
The reverse procedure is also possible: we postpone the proof at the end of the Section, since some more
informations on solutions P of (73) are needed.

We now give a preparatory result about the properties of such solutions.

Proposition 5.3. Assune Hypothesis 5.1. Then any solution P of (73) satisﬁes

hA0x, A0P ziH = hA0P x, A0ziH

∀x, z ∈ DP .

(75)

Proof. Let P be a solution of (73). We observe that for all x, y ∈ DP we have, since A0 is selfadjoint in
H (see Lemma (A.5)-(iii)),

By density, this equation holds for every x ∈ DP and y ∈ H. Symmetrically we have also

hA0P x, yiH + hP A0x, yiH = 2hP A0P x, yiH .

for every x ∈ H and y ∈ DP . We choose in (76) y = P A0z − A0P z, with z ∈ DP , and we obtain:

hx, P A0yiH + hx, A0P yiH = 2hx, P A0P yiH

(76)

(77)

hA0P x, P A0ziH − hA0P x, A0P ziH + hP A0x, P A0ziH − hP A0x, A0P ziH

= 2hP A0P x, P A0ziH − 2hP A0P x, A0P ziH .

We isolate on the left the symmetric terms:

2hP A0P x, A0P ziH − hA0P x, A0P ziH + hP A0x, P A0ziH

= −hA0P x, P A0ziH + hP A0x, A0P ziH + 2hP A0P x, P A0ziH .

Next, we apply (76) to the last term on the right:

2hP A0P x, A0P ziH − hA0P x, A0P ziH + hP A0x, P A0ziH

= −hA0P x, P A0ziH + hP A0x, A0P ziH + hA0P x, P A0ziH + hP A0x, P A0ziH ,

which simpliﬁes to

2hP A0P x, A0P ziH − hA0P x, A0P ziH = hP A0x, A0P ziH .

19

Applying (77) to the term on the right, rewritten as hA0x, P A0P xiH , we obtain for every x, z ∈ DP

2hP A0P x, A0P ziH − hA0P x, A0P ziH −

1
2

hP A0x, A0ziH =

1
2

hA0x, A0P ziH .

(78)

We now restart from (77), and choose x = P A0z − A0P z, with z ∈ DP : acting on the left variable of the
inner product, and proceeding exactly in the same way as before, we get for every z, y ∈ DP

2hA0P z, P A0P yiH − hA0P z, A0P yiH −

1
2

hP A0z, A0yiH =

1
2

hA0P z, A0yiH .

(79)

Comparing equations (78) and (79), both written with variables x, y, we immediately obtain

1
2

hA0x, A0P yiH =

1
2

hA0P x, A0yiH ,

x, y ∈ DP ,

which is (75).

We can now prove:

Theorem 5.4. Assume Hypothesis 5.1. Then any solution P of (73) commutes with A0, i.e. P x ∈ D(A0)
for every x ∈ D(A0) and

A0P x = P A0x

∀x ∈ D(A0).

In particular DP = D(A0).

Proof. We start from (75) with w = A0x and y = A0z, i.e.

hw, A0P A−1

0 yiH = hA0P A−1

0 w, yiH

∀w, y ∈ A0(DP ).

(80)

Notice that A0(DP ) is the natural domain of the operator A0P A−1
in H. Let us denote by Z the closure of D(A0P A−1

0 )in H; so we have

0 ; which might be (a priori) not dense

Z := A0(DP ) = D(A0P A−1

0 ).

Obvoiusly Z is a Hilbert space with the inner product of H. Equation (80) then tells us that A0(DP ) ⊆
D((A0P A−1

0 )∗) and

(A0P A−1

0 )∗w = A0P A−1

0 w

∀w ∈ A0(DP ) = D(A0P A−1

0 ).

(81)

On the other hand, if x ∈ D(A0) and y ∈ D(A0P A−1

0 ) we may write

hx, A0P A−1

0 yiH = hA−1

0 P A0x, yiH ;

consequently

and

We now claim that A0P A−1
0

D(A0) ⊆ D((A0P A−1

0 )∗)

(A0P A−1

0 )∗x = A−1
is selfadjoint in the space H, i.e.

0 P A0x

∀x ∈ D(A0).

D((A0P A−1

0 )∗) = D(A0P A−1

0 ) = A0(DP )

is dense in H and (81) holds.
Indeed, assume that z ∈ D((A0P A−1

0 )∗): then there is c > 0 such that

|hA0P A−1

0 x, ziH | ≤ ckxkH

∀x ∈ D(A0P A−1

0 ).

In particular, by (81),

(82)

(83)

(84)

hx, (A0P A−1

0 )∗ziH = hA0P A−1

0 x, ziH = h(A0P A−1

0 )∗x, ziH ∀x ∈ D(A0P A−1

0 ).

20

This shows that z ∈ D(A0P A−1

0 ) and A0P A−1

0 z = (A0P A−1

0 )∗z. Hence
0 = (A0P A−1

D((A0P A−1

0 )∗) ⊆ D(A0P A−1

0 ) and A0P A−1

0 )∗ on D((A0P A−1

0 )∗).

Conversely, we know from (81) that

D(A0P A−1

0 ) = A0(DP ) ⊆ D((A0P A−1

0 )∗) and (A0P A−1

0 )∗ = A0P A−1
0

on D(A0P A−1

0 ).

In particular, by (82), Z coincides with H, i.e. both domains in (84) are dense in H. This proves our
claim.
Take now x ∈ D(A0). As, by (82), D(A0) ⊆ D(A0P A−1

0 ), we have

P A−1

0 ∈ D(A0) ∀x ∈ D(A0),

i.e. DP = D(A0).

(85)

(see (74)). Moreover, by (83) and by the above claim we deduce

A−1

0 P A0x = A0P A−1
0 x

∀x ∈ D(A0).

0 x for every x ∈ D(A0), or, equivalently,

Applying A−1

0 we have A−2
0 P A2

A−2

0 P A0x = P A−1
∀z ∈ D(A2

This means that the bounded operators A−2
such that (A−1
bounded operator B which commutes with A−2

0 )2 = A−2

0z = z

0 w
0 and P commute. Now, since A−1
is a non-negative operator
0
0 , by a well known result (see [29, Theorem VI.9]), A−1
0 must commute with every

∀w ∈ H.

0 P w = P A−2

A−2

0),

i.e.

0 , for instance B = P . So

A−1

0 P w = P A−1

0 w

∀w ∈ H,

i.e.

P z = A−1

0 P A0z

∀z ∈ D(A0);

this implies that P (D(A0)) ⊆ D(A0) and A0P z = P A0z for every z ∈ D(A0). Thus P commutes with
A0, as required. Moreover P (D(A0)) ⊆ D(A0) implies D(A0) ⊆ DP . The reverse inclusion immediately
follows from the deﬁnition of DP .

We are now able to characterize all solutions of the ARE (73).

Theorem 5.5. Assume Hypothesis 5.1 and let P ∈ L+(H). Then P is a solution of (73) if and only if P
is an orthogonal projection in H and it commutes with A0. In particular the identity IH is the maximal
solution among all solutions of (73).

Proof. Let P be a solution of (73): by Theorem 5.4 we have P x ∈ D(A0) for every x ∈ D(A0) and
A0P x = P A0x. Hence the ARE (76), equivalent to (73), becomes

0 = −2hP A0x, yiH + 2hP A0P x, yiH ,

x ∈ DP , y ∈ H.

Since y is arbitrary, using (85) we get 2P A0x = 2P A0P x for every x ∈ D(A0), and successively, for all
x ∈ D(A0), P A0x − P A0P x = 0 , P A0(IH − P )x = 0, A0P (IH − P )x = 0, P (IH − P )x = 0, P x = P 2x;
ﬁnally, by density, P = P 2.
Assume, conversely, that P is an orthogonal projection in H and it commutes with A0. Then

P A0P z = P 2A0z = P A0z = A0P z ∀z ∈ D(A0),

and consequently P solves (76). Finally, since IH solves (73), the last statement is immediate.

We conclude this Section proving the equivalence of the two forms (71) and (73) of the ARE.

Proposition 5.6. Every solution of (71) is also a solution of (73) and vice versa.

Proof. We have already seen that every solution of (71) is also a solution of (73).
Consider now a solution P of (73). First of all, if x, y ∈ DP = D(A0), equation (73) transforms into (71),
so that (71) holds true for x, y ∈ DP .
We claim that DP is dense in D(A)∩D(ΛP ) (see (74)) with respect to the norm k·kH +kA·kX +kAP ·kX.
Indeed, for z ∈ D(A) ∩ D(ΛP ), recalling Lemma A.4, we set

zn = nR(n, A)z = nR(n, A)|H z = nR(n, A0)z.

21

Then zn ∈ D(A0) = DP and, as n → ∞,

zn → z

in H,

A0zn = nA0R(n, A0)z = nAR(n, A)z → Az

in X,

A0P zn = nA0P R(n, A0)z = nAR(n, A)P z → AP z

in X;

this proves our claim.
Let now x, y ∈ D(A) ∩ D(ΛP ); select {xn}, {yn} ⊆ D(A0) such that, as n → ∞,

xn → x in H, Axn → Ax in X, AP xn → AP x in X,

yn → y in H, Ayn → Ay in X, AP yn → AP y in X.

As a consequence,

Q−1

∞ P xn = −2BB∗AP xn → −2BB∗AP x = Q−1

∞ P x in X as n → ∞,

and similarly Q−1

∞ P xn → Q−1

∞ P y in X as n → ∞. For xn and yn, (71) holds:

0 = −hAxn, Q−1

∞ P yniX − hQ−1

∞ P xn, AyniX + 2hAP xn, Q−1

∞ P yniX .

In all terms, by what established above, we can pass to the limit as n → ∞, obtaining

0 = −hAx, Q−1

∞ P yiX − hQ−1

∞ P x, AyiX + 2hAP x, Q−1

∞ P yiX

∀x, y ∈ D(A) ∩ D(ΛP ),

i.e. P solves (71).

Remark 5.7. It is easy to verify that for every solution P of (73) the space DP = D(A0) is dense in
D(A) ∩ H with respect to the norm k · kH + kA · kX: it suﬃces to repeat the argument above, i.e. to
consider, for ﬁxed x ∈ D(A) ∩ H, the approximation xn = nR(n, A0)x, observing that xn → x in H and
A0xn = Axn → Ax in X. Thus, P belongs to the class Q introduced in Deﬁnition 3.8, and consequently,
by Theorem 4.7, we have P ≤ IH . Of course, this follows as well by Theorem 5.5.

Corollary 5.8. Assume that A0 is a diagonal operator with respect to an orthonormal complete system
{en} in H with sequence of eigenvalues {λn} ⊂ ] − ∞, 0[ . Let P be a solution of the ARE (73). Then

(i) every eigenspace of A0 is invariant for P ;

(ii) if all eigenvalues are simple, then P is diagonal with respect to the system {en}, too;

(iii) if at least one eigenspace M has dimension m ≥ 2, then the restriction of P to M needs not be
diagonal: for instance, if m = 2 a non-diagonal P on M must have the following explicit form:

a

±

a(1 − a)

(cid:18)

±

a(1 − a)
1 − a

p

(cid:19)

for some a ∈ ]0, 1[ .

(86)

p

Proof. To prove (i) it is enough to show that, for every eigenvalue λ of A0 and x eigenvector of A0
associated to λ, we have λP x = A0P x. This is immediate since A0 and P commute.
Concerning (ii) we observe that, for every n ∈ N we have A0en = λnen, so that λnP en = A0P en. Since
λn is simple, it is P en = ken for some k ∈ R. Since P is a projection, it must be k = 0 or k = 1.
Finally (iii) can be proved with straightforward algebraic calculations, using the fact that M is invariant
under P and that P is a projection.

Remark 5.9. Let A be a diagonal operator with respect to an orthonormal complete system {en} in H
with sequence of eigenvalues {λn} ⊂ ] − ∞, 0[ , where all λn are distinct and simple. Then BB∗ must be
diagonal, too. Indeed we have, for every n ∈ N,

hBB∗en, ekiH ek = BB∗en =

1
λn

BB∗Aen =

1
λn

ABB∗en =

+∞

Xk=0

1
λn

+∞

Xk=0

λkhBB∗en, ekiH ek ,

22

which implies

hBB∗en, ekiH

λk
λn (cid:19)
Since all eigenvalues are distinct, it must be BB∗en = bnen for all n ∈ N for a suitable sequence {bn} ∈ ℓ∞.
This implies that Q∞ and Q1/2
∞ are diagonal with respect to {en}, too. Following [1, Subsection 5.2] we
may also consider the case when BB∗ is unbounded and characterize the space H, for speciﬁc choices of
BB∗, in terms of the domain of suitable powers of (−A). In Section 6 we will consider a speciﬁc diagonal
case arising in mathematical physics.

= 0 ∀k, n ∈ N.

1 −

(cid:18)

6 A motivating example:

from equilibrium to non-equilibrium

states

In this section we describe, in a simple one-dimensional case, the optimal control problem outlined in the
papers [4, 5, 6, 7, 8, 9]. Such special case ﬁts into the application studied e.g. in [7, 9], in the case of the
Landau-Ginzburg model.
We consider a controlled dynamical system whose state variable is described by a function ρ : ]−∞, 0]
(the choice of the letter ρ comes from the fact that in many physical models ρ is a density). The control
variable is a function F : ]−∞, 0] × [0, 1] → R which we assume to belong to L2
. The
state equation is formally given by

−∞, 0; L2(0, 1)

(cid:0)

(cid:1)

∂2ρ
∂x2 (t, x) + ∇F (t, x) ,

ρ (t, 1) = ρ+,

∂ρ

2

∂t (t, x) = 1
ρ (−∞, x) = ¯ρ(x),
ρ (t, 0) = ρ−,
ρ (0, x) = ρ0 (x) ,






t ∈ ] − ∞, 0[ , x ∈ ]0, 1[ ,

x ∈ [0, 1],
t ∈ ] − ∞, 0[ ,
x ∈ [0, 1],

(87)

where ρ+, ρ− ∈ (0, 1), and ¯ρ is an equilibrium state for the uncontrolled problem. Hence ¯ρ is the unique
solution of the following system

v′′ (x) = 0,
v (0) = ρ−,
v (1) = ρ+;




so we have ¯ρ(x) = (ρ+ − ρ−)x + ρ−.
For any datum ρ0 ∈ L2(0, 1) we consider any control driving (in equation (87)) the equilibrium state ¯ρ
(at time t = −∞) to ρ0 at time t = 0. Then we consider the problem of minimizing, over the set of such
controls, the energy functional



J 0
∞ (F ) =

1
2

0

−∞

Z

kF (s)k2

L2(0,1) ds.

Given the above structure it is natural to consider the new control

ν = ∇F ∈ L2

−∞, 0; H −1(0, 1)

and take both the state space X and the control space U equal to H −1 (0, 1). We now rewrite (87) in
our abstract setting as follows. First we denote by A the Laplace operator in the space H −1(0, 1) with
Dirichlet boundary conditions, i.e.

(cid:1)

(cid:0)

D (A) = H 1

0 (0, 1) ,

Aη = η′′ ∀η ∈ H 1

0 (0, 1) .

Hence, formally, the state equation (87) becomes

ρ′(t) = A[ρ(t) − ¯ρ] + ν(t),
ρ(−∞) = ¯ρ.

(

t < 0,

(88)

23

Using a standard argument (see e.g. [17, Appendix C]), the state equation (87) can be rewritten in the
space X and in the new variable y(t) := ρ(t) − ¯ρ as

y′(t) = Ay(t) + ν(t),
y(−∞) = 0.

(

t < 0,

(89)

(90)

(91)

The function

y(t; −∞, 0, ν) =

t

−∞

Z

e(t−s)Aν(s) ds,

t ≤ 0,

−∞ e(t−s)Aν(s) ds, is the unique solution of (89), adopting Deﬁnition 2.4
corresponding to ρ(t; ν) = ¯ρ +
and applying Lemma 2.5.
R
The energy functional, in the new control variable ν, becomes

t

¯J 0
∞ (ν) =

1
2

0

−∞

Z

kA−1/2ν(s)k2

L2(0,1) ds =

1
2

0

−∞

Z

kν(s)k2

H−1(0,1) ds.

The set of admissible controls here is exactly U[−∞,0](0, y0) (see Subsection 2.2), which is nonempty if
and only if y0 ∈ H := R(Q1/2
∞ ) = D(A1/2) = L2(0, 1) (see e.g. [1, Section 5.2]). The value function V∞
is deﬁned as

V∞ (y0) :=

inf
ν∈U[−∞,0](0,y0)

¯J 0
∞ (ν) .

Now, recalling that X = U = H −1(0, 1) and setting B = IH−1(0,1) ∈ L(U, X), this problem belongs to
the class of the minimum energy problems studied in this paper. We know, from Proposition 4.3, that
the value function is given by

We can now apply Theorem 4.7, obtaining that:

V∞(y0) =

1
2

ky0k2

L2(0,1).

• the identity in L2, IL2(0,1), solves the ARE (66) where we replace B and B∗ by IH−1(0,1);

• the operator Q−1

∞ = 2A solves the ARE (65) where we replace B∗ by IH−1(0,1);

• IL2(0,1) is the maximal solution of the ARE (66) among those in the class Q introduced in Deﬁnition

3.8.

Moreover, here Hypothesis 5.1 holds; hence we can apply Theorem 5.5. Then, noting that A0 is the
Laplace operator with Dirichlet boundary conditions in the space H = L2(0, 1), whose domain is H 2(0, 1)∩
H 1

0 (0, 1), we obtaing that:

• the identity in L2, IL2(0,1), is a solution of the two (equivalent) AREs (71) and (73);

• the set of all solutions of (71) and (73) consists of all orthogonal projections P which commute with

A0, i.e. all projections whose image is generated by a subset of the eigenvectors of A0;

• IL2(0,1) is the maximal solution among all solutions of (71) and (73).

Appendix

A Minimum Energy with ﬁnite horizon

This part of the Appendix is devoted to recall the formulation of the ﬁnite horizon minimum energy
problem studied in [1] (brieﬂy described at the beginning of Subsection 2.3) and to provide some related
results which are useful in treating the inﬁnite horizon problem (9)–(10). Throughout this section we will
assume that Hypothesis 2.2 holds without repeating it.

24

(94)

(95)

A.1 General formulation of the problem

We take the Hilbert spaces X (state space) and U (control space), as well as the operators A and B, as
in Hypothesis 2.2. Given a time interval [s, t] ⊂ R, an initial state z ∈ X and a control u ∈ L2(s, t; U )
we consider the state equation (1), which we rewrite here:

y′(r) = Ay(r) + Bu(r),
y(s) = z.

(

r ∈ ]s, t],

Denote by y(·; s, z, u) the mild solution of (92) (see Proposition 2.3):

y(r; s, z, u) := e(r−s)Az +

r

s
Z

e(r−τ )ABu(τ ) dτ,

r ∈ [s, t].

(92)

(93)

We deﬁne the class of controls u(·) bringing the state y(·) from a ﬁxed z ∈ X at time s to a given target
x ∈ X at time t:

U[s,t](z, x)

def
=

u ∈ L2(s, t; U ) : y(t; s, z, u) = x

.

Consider the quadratic functional (the energy)

(cid:8)

(cid:9)

J[s,t](u) =

ku(r)k2

U dr.

t

1
2

s
Z
The minimum energy problem at (s, t; z, x) is the problem of minimizing the functional J[s,t](u) over all
u ∈ U[s,t](z, x). The value function of this control problem (the minimum energy) is

V1(s, t; z, x)

def
=

inf
u∈U[s,t](z,x)

J[s,t](u).

(96)

with the agreement that the inﬁmum over the emptyset is +∞. Similarly to what we did in Proposition
3.1, given any z ∈ X we deﬁne the reachable set in the interval [s, t], starting from z, as

Deﬁning the operator

(cid:8)

(cid:9)

Rz

[s,t] :=

x ∈ X : U[s,t](z, x) 6= ∅

.

it is clear that

Ls,t : L2(s, t; U ) → X,

Ls,tu =

e(t−τ )ABu(τ ) dτ,

t

s
Z

Rz

[s,t] := e(t−s)Az + Ls,t

L2(s, t; U )

.

(97)

(98)

(99)

The use of [1, Proposition 2.6] allows to reduce the number of variables from 4 to 2. In particular

(cid:0)

(cid:1)

V1(s, t; z, x) = V1(s − t, 0; 0, x − e(t−s)Az) = V1(0, t − s; 0, x − e(t−s)Az);

(100)

Hence from now on we set, for simplicity of notation,

V (t, x) := V1(−t, 0; 0, x) =

inf
u∈U[−t,0](0,x)

J[−t,0](u)

t ∈ ]0, +∞[,

x ∈ X.

(101)

A.2 The space H and its properties

In this subsection we provide some useful properties of the space H introduced in Subsection 2.3 (see
(22)-(23)). First recall that

H = R(Q1/2
∞ )

and

hx, yiH = hQ−1/2

∞ x, Q−1/2

∞ yiX ,

x, y ∈ H,

(102)

and that (with, in general, proper inclusion)

H ⊆ R(Q1/2

∞ ) = [ker Q1/2

∞ ]⊥ = [ker Q∞]⊥.

Next Lemmas A.1 and A.2 are exactly Lemmas 4.2 and 4.3 of [1].

25

Lemma A.1.

(i) The space H is a Hilbert space continuously embedded into X.

(ii) The space R(Q∞) is dense in H.

(iii) The operator Q−1/2

∞ is an isometric isomorphism from H to [ker Q1/2

∞ ]⊥, and in particular

kQ−1/2

∞ xkX = kxkH

∀x ∈ H.

(103)

(iv) We have Q1/2

∞ ∈ L(H) and

kQ1/2

∞ kL(X) = kQ1/2

∞ kL(H).

(v) For every F ∈ L(X) such that R(F ) ⊆ H we have Q−1/2

∞ F ∈ L(X), so that F ∈ L(X, H).

Lemma A.2. For 0 < t ≤ +∞ let Qt be the operator deﬁned by (19). Then, for every t ∈ [T0, +∞], the
space Qt(D(A∗)) is dense in H and contained in D(A). In particular D(A) ∩ H is dense in H.

Remark A.3. The above Lemma immediately implies that, for every t ∈ [T0, +∞], Qt(D(A∗)) is dense
in [ker Q∞]⊥ with the topology inherited by X, since the inclusion of H into [ker Q∞]⊥ is continuous.

Now we state and prove three very useful lemmas.

Lemma A.4. Assume Hypothesis 2.7. Then we have the following:

(i) For every z ∈ H and r ≥ 0 we have erAz ∈ H; moreover the semigroup etA|H is strongly continuous

in H. In particular, for each T > 0 there exists cT > 0 such that

kerAzkH ≤ cT kzkH

∀z ∈ H,

∀r ∈ [0, T ].

(ii) For every λ ∈ ρ(A) we have λ ∈ ρ(A0) and R(λ, A0) = R(λ, A)|H .

(iii) The generator A0 of the semigroup etA|H is given by

D(A0) = {x ∈ D(A) ∩ H : Ax ∈ H}

(

A0x = Ax ∀x ∈ D(A0).

(104)

We denote the semigroup etA|H by etA0 (see Notation 3.7): thus etA0 is a strongly continuous semigroup
in H.

Proof. (i) Fix any z ∈ H and t > T0: then, by Hypothesis 2.7, z ∈ R(Q1/2
(32)), i.e. there exists u ∈ L2(0, r; U ) such that

∞ ) = R(Q1/2

t

) = R(L−t,0) (see

Hence, for every r > 0,

where

z = L−t,0(u) =

e−σA Bu(σ) dσ.

0

−t

Z

erAz =

0

−t

Z

e(r−σ)A Bu(σ) dσ =

e(r−σ)A Bu(σ) dσ,

r

−t

Z

u(s) =

u(s)

if s ∈ [−t, 0]

(

0

if s ∈ [0, r].

Setting r − σ = −s and v(s) = u(s + r), it follows that

erAz =

0

−t−r

Z

e−sA Bu(r + s) ds = L−t−r,0(v) ∈ R(L−t−r,0) = R(Q1/2

t+r) = R(Q1/2

∞ ) = H.

26

Let us now prove that the restriction of erA to H has closed graph in H: if z, {zn} ⊂ H and zn → z in
H, erAzn → w ∈ H in H, then, since H is continuously embedded into X,

zn → z in X,

erAzn → w in X;

but erA ∈ L(X), so that w = erAz. Thus erAzn → erAz in H, and it follows that erA ∈ L(H).
Now ﬁx x ∈ H and consider for t > 0 the quantity etAx − x. We have

ketAx − xkH = sup

hetAx − x, yiH ;

kykH =1

thus, for every ε ∈ ]0, 1[ there exists yε ∈ H with kyεkH = 1 such that

ketAx − xkH < ε + hetAx − x, yεiH ;

then, using Lemma A.2 and choosing zε ∈ R(Q∞) such that kzε − yεkH < ε, we obtain

ketAx − xkH < ε + hetAx − x, yε − zεiH + hetAx − x, zεiH ≤
≤ ε + ketAx − xkH kyε − zεkH + hetAx − x, Q−1
≤ ε + ketAx − xkH ε + ketAx − xkX kQ−1
∞ zεkX .

∞ zεiX ≤

Hence

and letting t → 0+ we get

(1 − ε)ketAx − xkH < ε + ketAx − xkX kQ−1

∞ zεkX ,

lim sup
t→0+

ketAx − xkH ≤

ε
1 − ε

+ 0.

The arbitrariness of ε leads to the conclusion.
(ii) This is an immediate consequence of point (i) and of the well known resolvent formula R(λ, A) =

e−λtetA dt.

+∞
0
(iii) If z ∈ D(A0) then it must be, by deﬁnition, z ∈ D(A), z ∈ H, Az ∈ H; hence D(A0) ⊆
R
{x ∈ D(A) ∩ H : Ax ∈ H}. To prove the converse we ﬁrst observe that, using (ii), we get, for n ∈ N−{0}
and h ∈ H,

nAR(n, A)x = nx − n2R(n, A)x = nx − n2R(n, A0)x = nA0R(n, A0)x

Now assume that z ∈ D(A) ∩ H with Az ∈ H. To prove that z ∈ D(A0) it is enough to show that
nA0R(n, A0)z converges to some element y of H when n → +∞. In this case such element is A0z. To
do this we observe that, by the above remarks for the resolvents and by the assumptions on z, we get

nA0R(n, A0)z = nAR(n, A)z = nR(n, A)Az = nR(n, A0)Az

The latter, by the properties of resolvents, converges in H to Az as n → +∞, since Az ∈ H. This shows
that z ∈ D(A0) and A0z = Az.

Lemma A.5. Assume Hypothesis 2.7. Then we have the following.

(i) Q∞(H) is dense in H.

(ii) Q∞(D(A∗

0)) is dense in H.

(iii) Let A be selfadjoint and commuting with BB∗. Then Q∞(D(A∗

0)) ⊆ D(A0). Moreover A∗

0 is

selfadjoint in H.

∞ = ker Q∞, we have R(Q1/2

∞ ) = R(Q∞). Fix x ∈ H and set z := Q−1/2

∞ x ∈

∞ ). Then there exists {wn} ⊂ X such that, deﬁning zn := Q∞wn ∈ R(Q∞), we have zn → z in X.

Proof. (i) Since ker Q1/2
R(Q1/2
Set

xn := Q1/2

∞ zn = Q1/2

∞ Q∞wn = Q∞Q1/2

∞ wn.

Clearly xn ∈ Q∞(H). Moreover

kxn − xkH = kQ1/2

∞ zn − xkH = kzn − zkX → 0 as n → +∞,

27

which proves the claim.

[(ii) Fix x ∈ H. By part (i) there exists {xn} ⊂ Q∞(H) such that xn → x in H. We must have
0) is dense in H, then, for every n ∈ N+ there exists wn ∈ D(A∗
xn := Q∞zn, with zn ∈ H. Since D(A∗
0)
such that kzn − wnkH < 1/n. Consequently, setting yn := Q∞wn, we have, using Lemma A.1-(iv),

kyn − xkH ≤ kQ∞(wn − zn)kH + kxn − xkH ≤ kQ∞kL(H)

1
n

+ kxn − xkH .

This proves the claim.

(iii) Let A be selfadjoint and commuting with BB∗. Observe ﬁrst that D(A∗
when x ∈ D(A∗
that A and Q∞ commute (see [1, Proposition C.1-(v)])), we get, for every y ∈ D(A),

0) ⊆ D(A∗) = D(A). Indeed,
0), the linear map y → hx, A0yiH is bounded in H. Using such boundedness and the fact

hx, AyiX = hx, Q∞AyiH = hx, AQ∞yiH = hx, A0Q∞yiH ≤ CkQ∞ykH ≤ C′kykX

0) ⊆ D(A∗)) and let
0) be such that x = Q∞z. Using again the fact that A and Q∞ commute, we get Ax = AQ∞z =

0)) (which is contained in D(A) by Lemma A.2, since D(A∗

which implies x ∈ D(A∗) = D(A).
Now, let x ∈ Q∞(D(A∗
z ∈ D(A∗
Q∞Az ∈ H. Hence, by deﬁnition of A0, we deduce that x ∈ D(A0) and A0x = Ax.
Now we prove that A0 is selfadjoint in H. Let x ∈ D(A0) and y ∈ Q∞(D(A∗
we have y = Q∞z and Q−1
Ax = A0x ∈ H ⊆ [ker Q∞]⊥. Using this fact, we get

0)). Then for some z ∈ D(A∗
0)
∞ y = z + z0, where z0 ∈ ker Q∞. Hence it must be hAx, z0iX = 0, since

hA0x, yiH = hAx, yiH = hAx, Q−1

∞ yiX = hAx, ziX = hx, AziX =

= hx, Q∞AziH = hx, AQ∞ziH = hx, AyiH = hx, A0yiH ,

where in the last step we used the inclusion D(A∗
inclusion Q∞(D(A∗
is deﬁned on Q∞(D(A∗
A∗
0x = A0x. Hence A∗
such that λ ∈ ρ(A0) ∩ ρ(A∗
implies that D(A0) = D(A∗

0) ⊆ D(A), the fact that Q∞ and A commute, and the
0)) ⊆ D(A0). This implies that, for every x ∈ D(A0), the linear map y → hx, A0yiH
0)) (which is dense in H) and is bounded in H. This implies that x ∈ D(A∗
0) and
0 extends A0. Since both A0 and A∗
0 generate a semigroup, we can choose λ > 0
0) = R(λ, A0), which immediately

0). For such λ we now prove that R(λ, A∗
0). Indeed for z ∈ H we have

z = (λ − A0)R(λ, A0)z = (λ − A∗

0)R(λ, A0)z,

where in the last equality we used that D(A0) ⊆ D(A∗
R(λ, A∗

0) to both sides we get the claim.

0) and that A∗

0x = A0x for all x ∈ D(A0). Applying

Lemma A.6. Assume Hypothesis 2.7.

(i) For 0 ≤ s ≤ T0 we have Q−1/2

∞ esA ∈ L(H, X), and there exists C1(T0) > 0 such that

kQ−1/2

∞ esAxkX ≤ C1(T0)kxkH

∀x ∈ H,

∀s ∈ [0, T0],

and (Q−1/2

∞ esA)∗ = esA

0 Q−1/2

∞ ∈ L(X, H), with

∗

k(Q−1/2

∞ esA)∗kL(X,H) ≤ C1(T0)

∀s ∈ [0, T0].

(ii) For s > T0 we have Q−1/2

∞ esA ∈ L(X), with

kQ−1/2

∞ esAxkX ≤ C1(T0)M e−ω(s−T0)kxkX

∀x ∈ X,

∀s > T0,

and

k(Q−1/2

∞ esA)∗kL(X) ≤ C1(T0)M e−ω(s−T0)

∀s > T0.

(iii) For s ≥ 0, x ∈ X we have

esA

∗

0 Q∞x = Q∞esA

∗

x.

28

(iv) For x ∈ D(A∗) we have Q∞x ∈ D(A∗

0). Moreover, for every s ≥ 0 we have

A∗

0esA

∗

0 Q∞x = Q∞A∗etA

∗

x.

Proof. (i) We have by Lemma A.4-(i)

kQ−1/2

∞ esAxkX = kesAxkH ≤ cT0 kxkH

∀x ∈ H,

∀s ∈ [0, T0];

moreover (identifying here X and H with their duals), (Q−1/2
x ∈ X, we have

∞ esA)∗ ∈ L(X, H) and, for all z ∈ H and

h(Q−1/2

∞ esA)∗x, ziH = hx, Q−1/2

∞ esAziX = hQ1/2

∞ x, esA0ziH = hesA

∗

0 Q1/2

∞ x, ziH .

This shows that

with

(Q−1/2

∞ esA)∗ = esA

∗

0 Q1/2

∞ ∈ L(X, H),

k(Q−1/2

∞ esA)∗kL(X,H) = kesA0Q1/2

∞ kL(X,H) = kQ−1/2

∞ esAkL(H,X) ≤ cT0 ∀s ∈ [0, T0].

(ii) By Hypothesis 2.7 we have Q−1/2

∞ esA ∈ L(X), and by (i) we get

kQ−1/2

∞ esAkL(X) = kQ−1/2
≤ kQ−1/2

∞ eT0Ae(s−T0)AkL(X)
∞ eT0AkL(X)M e−ω(s−T0) ≤ C1(T0)M e−ω(s−T0) ∀s > T0.

The claim easily follows.

(iii) For s ≥ 0, x ∈ X, z ∈ H, we have

hesA

∗

0 Q∞x, ziH = hQ∞x, esA0 ziH = hx, esAziX = hesA

∗

x, ziX = hQ∞esA

∗

x, ziH ,

which proves the claim.

(iv) Let x ∈ D(A∗) and s ≥ 0. For h > 0 we have, using the point (iii) above,

∗

0 − esA
e(s+h)A
h

∗
0

Q∞x = Q∞

∗

e(s+h)A
h

∗

− esA

x

Letting h → 0, the claim follows.

References

[1] P. Acquistapace, and F. Gozzi. Minimum energy for linear systems with ﬁnite horizon: a non-

standard Riccati equation. Math. Control Signals Syst. 29, 19 (2017).

[2] E. Barucci, and F. Gozzi. Technology Adoption and Accumulation in a Vintage Capital Model. J.

of Economics, 74, N.1, 1–38 (2001).

[3] A. Bensoussan, G. Da Prato, M.C. Delfour, and S.K. Mitter. Representation and control of Inﬁnite

dimensional system. Second edition, Birkhäuser, Boston 2007.

[4] L. Bertini, A. De Sole, D. Gabrielli, G. Jona–Lasinio, and C. Landim. Fluctuations in stationary

nonequilibrium states of irreversible processes. Phys. Rev. Lett. 87, 040601 (2001).

[5] L. Bertini, A. De Sole, D. Gabrielli, G. Jona–Lasinio, and C. Landim. Macroscopic ﬂuctuation theory

for stationary non equilibrium state. J. Statist. Phys. 107, 635–675 (2002).

[6] L. Bertini, A. De Sole, D. Gabrielli, G. Jona–Lasinio, and C. Landim. Large deviations for the

boundary driven simple exclusion process. Math. Phys. Anal. Geom. 6, 231–267 (2003).

29

[7] L. Bertini, A. De Sole, D. Gabrielli, G. Jona–Lasinio, and C. Landim. Minimum Dissipation Principle

in Stationary Non-Equilibrium States. J. Statist. Phys. 116, 831–841 (2004).

[8] L. Bertini, A. De Sole, D. Gabrielli, G. Jona–Lasinio, and C. Landim. Action Functional and Quasi-
Potential for the Burgers Equation in a Bounded Interval. Comm. Pure. Appl. Math. 64, 649–696
(2011).

[9] L. Bertini, D. Gabrielli, and J.L. Lebowitz. Large deviations for a stochastic model of heat ﬂow. J.

Statist. Phys. 121, 843–885 (2005).

[10] 0. Carja. The minimal time function in inﬁnite dimensions. SIAM J. Contr. Optimiz. 31 (5), 1103-

1114 (1993).

[11] R. Curtain, and A. J. Pritchard. Inﬁnite Dimensional Linear Systems Theory. Springer 1978.

[12] G. Da Prato, and J. Zabczyk. Stochastic Equations in Inﬁnite Dimension. Springer 1992.

[13] G. Da Prato, A. J. Pritchard, and J. Zabczyk. Null controllability with vanishing energy. SIAM J.

Control Optim. 29 (1), 209–221 (1991).

[14] Z. Emirsajlow. A feedback for an inﬁnite-dimensional linear-quadratic control problem with a ﬁxed

terminal state. IMA J. Math. Control Inf. 6 (1), 97-117 (1989).

[15] Z. Emirsajlow, and SD. Townley. Uncertain systems and minimum energy control. J. Appl. Math.

Comput. Sci. 5 (3), 533–545 (1995).

[16] K-J. Engel, and R. Nagel. One Parameter Semigroups for Linear Evolution Equations. Springer

1999.

[17] G. Fabbri, F. Gozzi, and A. Swiech. Stochastic optimal control in inﬁnite dimension. Springer 2017.

[18] J. Feng, and T. Kurtz. Large Deviations for Stochastic Processes. Mathematical Surveys and Mono-

graphs, AMS 2006.

[19] J.A. Goldstein. Semigroups of linear operators and applications. Oxford Mathematical Monographs,

1985.

[20] F. Gozzi, and P. Loreti. Regularity of the minimum time function and minimum energy problems:

The linear case. SIAM J. Control Optim. 37 (4), 1195–1221 (1999).

[21] P. Lancaster, and L. Rodman. Algebraic Riccati Equations. Oxford Science Publications, Clarendon

Press, Oxford, 1995.

[22] I. Lasiecka, and R. Triggiani. Control Theory for Partial Diﬀerential Equations: Continuous and

Approximation Theories. Part 1. Cambridge University Press 2000.

[23] I. Lasiecka, and R. Triggiani. Control Theory for Partial Diﬀerential Equations: Continuous and

Approximation Theories. Part 2. Cambridge University Press 2000.

[24] A. Lunardi. Analytic semigroups and optimal regularity in parabolic problems. Birkhäuser Verlag,

Basel, 1995.

[25] B. C. Moore. Principal component analysis in linear systems: controllability, observability, and model

reduction. IEEE Trans. Automat. Control 26 (1), 17–32 (1981).

[26] A. W. Olbrot, and L. Pandolﬁ. Null controllability of a class of functional-diﬀerential systems.

Internat. J. Control 47 (1), 193–208 (1988).

[27] A. Pazy. Semigroups of linear operators and applications to partial diﬀerential equations. Springer

Verlag, New-York 1983.

[28] E. Priola, and J. Zabczyk. Null controllability with vanishing energy. SIAM J. Control and Optim.

42 (6), 1013-1032, 2003.

30

[29] M. Reed, B. Simon. Functional Analysis. Academic Press, London 1980.

[30] J.M.A. Scherpen. Balancing for Nonlinear Systems. Syst. Contr. Lett. 21 (2), 143-153 (1993).

[31] H. Triebel. Interpolation theory, function spaces, diﬀerential operators. North-Holland Publishing

Co., Amsterdam 1978.

[32] J. Zabczyk. Mathematical control theory: an introduction. Birkhäuser Verlag, Boston 1995.

31

