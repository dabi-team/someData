2
2
0
2

n
u
J

3
1

]

M
E
.
n
o
c
e
[

3
v
1
7
3
1
1
.
3
0
1
2
:
v
i
X
r
a

A Powerful Subvector Anderson Rubin Test in Linear

Instrumental Variables Regression with Conditional
Heteroskedasticity∗

Patrik Guggenberger
Department of Economics
Pennsylvania State University

Frank Kleibergen
Department of Quantitative Economics
University of Amsterdam

Sophocles Mavroeidis
Department of Economics
University of Oxford

June 14, 2022

Abstract

We introduce a new test for a two-sided hypothesis involving a subset of the structural pa-
rameter vector in the linear instrumental variables (IVs) model. Guggenberger et al. (2019),
GKM19 from now on, introduce a subvector Anderson-Rubin (AR) test with data-dependent
critical values that has asymptotic size equal to nominal size for a parameter space that al-
lows for arbitrary strength or weakness of the IVs and has uniformly nonsmaller power than
the projected AR test studied in Guggenberger et al. (2012). However, GKM19 imposes the
restrictive assumption of conditional homoskedasticity. The main contribution here is to ro-
bustify the procedure in GKM19 to arbitrary forms of conditional heteroskedasticity. We ﬁrst
adapt the method in GKM19 to a setup where a certain covariance matrix has an approximate
Kronecker product (AKP) structure which nests conditional homoskedasticity. The new test
equals this adaption when the data is consistent with AKP structure as decided by a model
selection procedure. Otherwise the test equals the AR/AR test in Andrews (2017) that is fully
robust to conditional heteroskedasticity but less powerful than the adapted method. We show

∗We would like to thank the Co-Editor and two referees for very helpful comments. Guggenberger thanks the
European University Institute for its hospitality while parts of this paper were drafted. Mavroeidis gratefully ac-
knowledges the research support of the European Research Council via Consolidator grant number 647152. We
would like to thank Donald Andrews for detailed comments and for providing his Gauss code of, and explanations
about, Andrews (2017) and Lixiong Li for outstanding research assistance for the Monte Carlo study. We thank
seminar participants in Amsterdam, Bologna, Bristol, Florence (EUI), Indiana, Konstanz, Manchester, Mannheim,
Paris (PSE), Pompeu Fabra, Regensburg, Rotterdam, Singapore (NUS and SMU), Tilburg, Toulouse, T¨ubingen, and
Zurich, and conference participants at the Institute for Fiscal Studies (London) for helpful comments.

1

 
 
 
 
 
 
theoretically that the new test has asymptotic size bounded by the nominal size and document
improved power relative to the AR/AR test in a wide array of Monte Carlo simulations when
the covariance matrix is not too far from AKP.

Keywords: Asymptotic size, conditional heteroskedasticity, Kronecker product, linear IV

regression, subvector inference, weak instruments

JEL codes: C12, C26

1

Introduction

Robust and powerful subvector inference constitutes an important problem in Econometrics. For

instance, it is standard practice to report conﬁdence intervals on each of the coeﬃcients in a linear

regression model. By robust we mean a testing procedure for a hypothesis of (or a conﬁdence

region for) a subset of the structural parameter vector such that the asymptotic size is bounded

by the nominal size for a parameter space that allows for weak or partial identiﬁcation. Recent

contributions to robust subvector inference have been made in the context of the linear instrumental

variables (IVs from now on) model (see, for example, Dufour and Taamouti (2005), Guggenberger

et al. (2012) (GKMC from now on), Guggenberger et al. (2019) (GKM19 from now on), and

Kleibergen (2021)), GMM models (see, for example, Chaudhuri and Zivot (2011), Andrews and

Cheng (2014), Andrews and Mikusheva (2016), Andrews (2017), and Han and McCloskey (2019)),

and also models deﬁned by moment (in)equalities (see, for example, Bugni et al. (2017), Gafarov

(2017), and Kaido et al. (2019)). GKM19 introduce a new subvector test that compares the

AR subvector statistic to conditional critical values that adapt to the strength or weakness of

identiﬁcation and verify that the resulting test has correct asymptotic size for a parameter space

that imposes conditional homoskedasticity (CHOM from now on) and uniformly improves on the

power of the projected AR test studied in Dufour and Taamouti (2005).

The contribution of the current paper is to provide a robust subvector test that improves the

power of another robust subvector test by combining it with a more powerful test that is robust

for only a smaller parameter space. More speciﬁcally, in the context of the linear IV model, we
ﬁrst provide a modiﬁcation of the subvector AR test of GKM19, called the ARAKP,α test, where α
denotes the nominal size. We verify that it has correct asymptotic size for a parameter space that

nests the setup with CHOM and also allows for particular cases of conditional heteroskedasticity

(CHET from now on), namely setups where a particular covariance matrix has a Kronecker product

(KP from now on) structure. For example, the data generating process (DGP from now on) has a

KP structure if the vector of structural and reduced-form errors equals a random vector independent

of the IVs times a scalar function of the IVs. In particular then, the variances of all the errors

depend on the IVs by the same multiplicative constant given as a scalar function of the IVs. In the

companion paper Guggenberger et al. (2022) (GKM22 from now on) we ﬁnd that KP structure is

not rejected at the 5% nominal size in more than 63% of empirical data sets we studied of several

recently published empirical papers (namely, 38 of 60 speciﬁcations are not rejected; and, including

cases with clustering, 56 out of 118 are not rejected). For comparison, CHOM is rejected for 57

2

of the 60 speciﬁcations considered at the 5% nominal size, using the test in Kelejian (1982). Of

course, these ﬁndings do not prove that empirical data sets do have KP structure as the low number

of rejections of KP structure may be due to type II errors of the test. However, coupled with the

quite favorable ﬁnite sample power results of the test of KP structure reported in GKM22 (for

sample sizes of n = 200) we believe that KP structure might be compatible with a sizable subset

of empirical data sets.

Second, depending on a model selection mechanism that determines whether the data are com-
patible with KP, the recommended test then equals the ARAKP,α test or the AR/AR test in Andrews
(2017) that is robust to arbitrary forms of CHET. We show that the recommended test has correct
asymptotic size. An important ingredient in establishing that is showing that the ARAKP,α test
does not reject less often under the null hypothesis than the AR/AR test when the data are close

to KP structure.

We propose two diﬀerent model selection methods. One is based on the KPST test statistic

introduced in GKM22 for testing the null hypothesis that a covariance matrix has KP structure.

The other one is based on the standardized norm of the distance between the covariance matrix

estimator and its closest KP approximation. As in the model selection method proposed in Andrews

and Soares (2010), we compare the test statistic to a user chosen threshold that, in the asymptotics,

is let go to inﬁnity. The thresholds can be chosen diﬀerently depending on the number of IVs k and

parameters not under test. Based on comprehensive ﬁnite sample simulations we provide choices

for the thresholds for several values of k that lead to good control of the ﬁnite sample size.

As the main contribution of the paper, we verify that the resulting test, called ϕM S−AKP,α
test, has asymptotic size bounded by the nominal size α under certain conditions on the selection

mechanism and implementation of the AR/AR test at nominal size α − δ for some arbitrarily small

δ > 0.

In a Monte Carlo study, we compare the suggested new test ϕM S−AKP,α with several alter-
natives given in Andrews (2017), in particular, the AR/AR and the AR/QLR1 tests. Andrews

(2017) ﬁlls a very important gap in the literature on subvector inference by providing two-step
Bonferroni-like methods1 for a rich class of models that nests GMM, that i) control the asymp-
totic size under relatively mild high-level conditions that allow for CHET, ii) are asymptotically

non-conservative (in contrast to standard Bonferroni methods) and iii) for the case of AR/QLR1

is asymptotically eﬃcient under strong identiﬁcation (while the AR/AR test is not asymptotically

eﬃcient under strong identiﬁcation in overidentiﬁed situations). In contrast, the test considered
here, ϕM S−AKP,α, can only be used in the linear IV model and is not asymptotically eﬃcient under
strong identiﬁcation. The Monte Carlo study ﬁnds that ϕM S−AKP,α has uniformly higher rejection
probabilities than the AR/AR test for all the DGPs considered. That includes the null rejection
probabilities (NRPs from now on) with the ϕM S−AKP,α test having ﬁnite sample size of 6% versus
the 5.4% of the AR/AR test at nominal size 5%. Based on the Monte Carlo study we conclude
that relative to the AR/QLR1 test, ϕM S−AKP,α can be a useful alternative in terms of power in

1See McCloskey (2017) for a general reference on Bonferroni methods in nonstandard testing setups.

3

situations of weak or mixed identiﬁcation strengths when the degree of overidentiﬁcation is small

and the covariance matrix of the data is not too far from KP structure. Whenever the data are

compatible with KP structure, it also oﬀers an important computational advantage because the
ARAKP,α test is given in closed form. In contrast, implementation of the two-step Bonferroni-like
methods require minimization of a statistic over a set that has dimension equal to the number of

parameters not under test. The computation time should grow exponentially in the dimension of

that set which constitutes a computational challenge especially when an applied researcher uses the

proposed methods for the construction of a conﬁdence region by test inversion. This being said, an
applied researcher who uses the ϕM S−AKP,α test has to be ready to implement the AR/AR test in
case it is determined that KP structure is not compatible with the data. Given the construction
of the ARAKP,α test it is not surprising to ﬁnd the relative best performance of the ϕM S−AKP,α
test to occur under weak identiﬁcation. Namely, the critical values of the former test adapt to the

strength of identiﬁcation and can be substantially lower than the corresponding chi-square critical

values when identiﬁcation is deemed to be weak.

The rest of the paper is organized as follows. In Section 2 we introduce a version of a subvector

Anderson and Rubin (1949) test that has correct asymptotic size for a parameter space that imposes

an approximate Kronecker product (AKP) structure for the covariance matrix. In Section 3 we

introduce the new test that has correct asymptotic size for a parameter space that does not impose

any structure on the covariance matrix and therefore, in particular, allows for arbitrary forms of

conditional heteroskedasticity. Finally, in Section 4 we study the ﬁnite sample properties of the

test. Proofs are given in the Appendix at the end.

Notation: Throughout the paper, we denote by “⊗” the KP of two matrices, by vec(·) the
column vectorization of a matrix, and by || · || the Frobenius norm.2 We use the notation MA :=
In − PA and PA := A(A(cid:48)A)−1A(cid:48) for any full rank matrix A ∈ (cid:60)n×k.

2 Subvector AR Test under Approximate Kronecker Product Struc-

ture

Assume the linear IV model is given by the equations

y =Y β + W γ + ε

Y =ZΠY + VY

W =ZΠW + VW ,

(2.1)

where y ∈ (cid:60)n, Y ∈ (cid:60)n×mY , W ∈ (cid:60)n×mW , and Z ∈ (cid:60)n×k. Here, W contains endogenous regressors,
while the regressors Y may be endogenous or exogenous. We assume that k −mW ≥ 1 and mW ≥ 1.

2Recall the Frobenius norm for a matrix A = (aij) ∈ (cid:60)m×n is deﬁned as ||A||2 := (cid:80)m

(cid:80)n

j=1a2

ij. When A is a

i=1

vector the Frobenius and the Euclidean norm are numerically equivalent.

4

The reduced form can be written as

(cid:16)

y Y W

(cid:17)

(cid:16)

= Z

ΠY ΠW

(cid:32)

(cid:17)

ImY

β
γ 0mW ×mY

0mY ×mW
ImW

(cid:33)

+

(cid:16)

(cid:124)

vy VY VW
(cid:123)(cid:122)
V

(cid:17)

,
(cid:125)

(2.2)

where vy := VY β+ VW γ + ε (which depends on the true β and γ), V (cid:48)
(VY,1, . . . , VY,n), Z
column vector and similarly for other matrices.

Y =
= (Z1, . . . , Zn). By Vi, for i = 1, ..., n, we denote the i-th row of V written as a

W = (VW,1, . . . , VW,n), V (cid:48)

(cid:48)

The objective is to test the subvector hypothesis

H0 : β = β0 against H1 : β (cid:54)= β0,

(2.3)

using tests whose size, i.e. the highest NRP over a large class of distributions for (εi, Z
W,i)
and the unrestricted nuisance parameters ΠY , ΠW , and γ, equals the nominal size α, at least
asymptotically. In particular, weak identiﬁcation and non-identiﬁcation of β and γ are allowed for.

(cid:48)
i, V (cid:48)

Y,i, V (cid:48)

The setup allows testing the coeﬃcients of exogenous or endogenous regressors Y in the presence

of endogenous regressors W . We impose the following assumption as in GKM19 (from where the

name of the assumption is inherited).

Assumption B: The random vectors (εi, Z
distribution F.

(cid:48)
i, V (cid:48)

Y,i, V (cid:48)

W,i) for i = 1, ..., n in (2.1) are i.i.d. with

For a given sequence an = o(1) in (cid:60)≥0, we deﬁne a sequence of parameter spaces FAKP,an for
(γ, ΠW , ΠY , F ) under the null hypothesis H0 : β = β0 that is larger than the corresponding ones in
GKMC and GKM19 in that general forms of AKP structures for the variance matrix

RF := EF (vec(ZiU (cid:48)

i )(vec(ZiU (cid:48)

i ))(cid:48)) ∈ (cid:60)kp×kp

(2.4)

are allowed for.3 Namely, for Ui := (εi+V (cid:48)
and m := mY + mW let

W,iγ, V (cid:48)

W,i)(cid:48) (which equals (vyi−V (cid:48)

Y,iβ, V (cid:48)

W,i)(cid:48)), p := 1+mW ,

FAKP,an = {(γ, ΠW , ΠY , F ) : γ ∈ (cid:60)mW , ΠW ∈ (cid:60)k×mW , ΠY ∈ (cid:60)k×mY ,

EF (||Ti||2+δ1) ≤ B, for Ti ∈ {vec(ZiU (cid:48)
EF (ZiV (cid:48)

i ) = 0k×(m+1), RF = GF ⊗ H F + Υn,

i ), ||Zi||2},

κmin(A) ≥ δ2 for A ∈ {EF (Z

(cid:48)
iZi), GF , H F }}

for symmetric matrices Υn ∈ (cid:60)kp×kp such that

||Υn|| ≤ an,

(2.5)

(2.6)

3Regarding the notation (γ, ΠW , ΠY , F ) and elsewhere, note that we allow as components of a vector column

vectors, matrices (of diﬀerent dimensions), and distributions.

5

positive deﬁnite (pd from now on) symmetric matrices GF ∈ (cid:60)p×p (whose upper left element is
normalized to 1) and H F ∈ (cid:60)k×k, δ1, δ2 > 0, B < ∞. Note that the factors in the KP GF ⊗ H F are
not uniquely deﬁned due to the summand Υn. Note that no restriction is imposed on the variance
matrix of vec(ZiV (cid:48)
Y,i))(cid:48)) does not need to factor into
a KP.

Y,i) and, in particular, EF (vec(ZiV (cid:48)

Y,i)(vec(ZiV (cid:48)

The factorization of the covariance matrix into an AKP in line three of (2.5) is a weaker
(cid:48)
assumption than CHOM. Under CHOM, we have GF = EF (UiU (cid:48)
iZi) (prior to
the normalization of the upper left element of GF ) and Υn = 0kp×kp. The AKP structure allowed
for here (but not in GKMC and GKM19) also covers some important cases of CHET involving
vec(ZiU (cid:48)

i ) and H F = EF (Z

i) Consider the case in (2.1) where ((cid:101)εi, (cid:101)V (cid:48)

pd variance matrix, independent of Zi, and (εi, V (cid:48)
W,i)(cid:48) := f (Zi)((cid:101)εi, (cid:101)V (cid:48)
function f of Zi.4 In that case, the covariance matrix RF can be written

W,i)(cid:48) ∈ (cid:60)p are i.i.d. zero mean with a
W,i)(cid:48) for some scalar valued

i ).
Examples.

EF (vec(ZiU (cid:48)
(cid:16)

=EF

UiU (cid:48)

i )(vec(ZiU (cid:48)
(cid:48)
i

i ⊗ ZiZ

(cid:17)

i ))(cid:48))

(cid:16)

(cid:16)

=EF

=EF

(εi + V (cid:48)

W,iγ, V (cid:48)

((cid:101)εi + (cid:101)V (cid:48)

W,iγ, (cid:101)V (cid:48)

W,i)(cid:48)(εi + V (cid:48)
W,i)(cid:48)((cid:101)εi + (cid:101)V (cid:48)

W,iγ, V (cid:48)

W,iγ, (cid:101)V (cid:48)

W,i) ⊗ ZiZ
(cid:17)
W,i)

⊗ EF

(cid:17)

(cid:48)
i

(cid:16)

f (Zi)2ZiZ

(cid:17)

(cid:48)
i

and thus has KP structure even though, obviously, CHOM is not satisﬁed because

EF (UiU (cid:48)

i |Zi) = f (Zi)2EF ((cid:101)εi + (cid:101)V (cid:48)

W,iγ, (cid:101)V (cid:48)

W,i)(cid:48)((cid:101)εi + (cid:101)V (cid:48)

W,iγ, (cid:101)V (cid:48)

W,i)

(2.7)

(2.8)

depends on Zi.

ii) In a wage regression to assess the eﬀect of ”years of education”, the assumption of CHOM

would require that e.g. the variance of ”wage” does not depend on the included regressor ”race”.

This assumption is incompatible with recent US data where the wage dispersion is largest for
W,i)(cid:48) in i) allows for dependence of the
W,i)(cid:48) := f (Zi)((cid:101)εi, (cid:101)V (cid:48)
Asians. Instead, the construction (εi, V (cid:48)
variances of the regressand and all endogenous regressors on a scalar function of Zi. The maintained
restriction is that all these variances are aﬀected approximately by the same scalar function of Zi.
In the related paper, GKM22, we test the null hypothesis of KP structure for 118 speciﬁcations in

about a dozen highly cited papers and ﬁnd that at the 5% nominal size in 47.5% of the cases the

null is not rejected.

In this section we will introduce a new conditional subvector ARAKP test and show it has
asymptotic size with respect to the parameter space FAKP,an equal to the nominal size. We next
deﬁne the new test statistic and the critical value for the case considered here of AKP structure.

4For example, Andrews (2017) considers f (Zi) = ||Zi||/k1/2.

6

Estimation of the two factors in the AKP structure: Deﬁne

Zi := (n−1Z

(cid:48)

Z)−1/2Zi ∈ (cid:60)k

(2.9)

and Z ∈ (cid:60)n×k with rows given by Z(cid:48)

i for i = 1, ..., n.5 Deﬁne an estimator of the matrix

RF = (Ip ⊗ (EF ZiZ

(cid:48)
i)−1/2)RF (Ip ⊗ (EF ZiZ

(cid:48)
i)−1/2) ∈ (cid:60)kp×kp

(2.10)

by

(cid:98)Rn := n−1(cid:80)n
fi := ((MZY 0)i, (MZW )(cid:48)

i=1fif (cid:48)

i ∈ (cid:60)kp×kp, where

i)(cid:48) ⊗ Zi ∈ (cid:60)kp, and Y 0 := y − Y β0.

(2.11)

Note that (cid:98)Rn is automatically a centered estimator because, as straightforward calculations show,
n−1(cid:80)

ifi = 0. From RF = GF ⊗ H F + Υn, it follows that RF = GF ⊗ HF + o(1) for

Let

HF := (EF ZiZ

(cid:48)
i)−1/2H F (EF ZiZ

(cid:48)
i)−1/2.

( (cid:98)Gn, (cid:98)Hn) = arg min ||G ⊗ H − (cid:98)Rn||,

(2.12)

(2.13)

where the minimum is taken over (G, H) for G ∈ (cid:60)p × p, H ∈ (cid:60)k × k being pd, symmetric matrices,
and normalized such that the upper left element of G equals 1.

It can be shown that ( (cid:98)Gn, (cid:98)Hn) are given in closed form by the following construction.6 First,

for a pd matrix A ∈ (cid:60)kp×kp deﬁne the rearrangement of A as











R(A) :=

Aj :=


 ∈ (cid:60)pp×kk, where


A1
...
Ap

(vec(A1j))(cid:48)
...
(vec(Apj))(cid:48)


 ∈ (cid:60)p×kk for j = 1, ..., p,


(2.14)

where Alj ∈ (cid:60)k×k denotes the (l, j) submatrix of dimensions k × k, where l, j = 1, ..., p. Second,
denote by

(cid:98)L(cid:48)R(A) (cid:98)N = diag((cid:98)σl) ∈ (cid:60)pp×kk
5For simplicity, we do not use the more precise notation Zin for Zi. It is explained in detail in Comment 3 below
Theorem 1 why we introduce Zi, namely to obtain invariance of the testing procedure with respect to nonsingular
transformations of the IVs.

(2.15)

6This follows from a combination of Lemma 2 below and Theorem 5.8 in van Loan and Pitsianis (1993, Corollary

2.2).

7

a singular value decomposition of R(A),7 where the singular values (cid:98)σl for l = 1, ..., p2 are ordered
non-increasingly. Finally, denote by (cid:98)L(:, 1) and (cid:98)N (:, 1) singular vectors corresponding to the largest
singular value (cid:98)σ1 and let (cid:98)L(1, 1) denote the ﬁrst component of (cid:98)L(:, 1). Then, letting the role of A
be played by (cid:98)Rn in (2.15), minimizers ( (cid:98)Gn, (cid:98)Hn) to (2.13) are deﬁned by

vec( (cid:98)Gn) = (cid:98)L(:, 1)/(cid:98)L(1, 1) and vec( (cid:98)Hn) = (cid:98)σ1 (cid:98)L(1, 1) (cid:98)N (:, 1),

(2.16)

where (cid:98)L(1, 1) > 0 whenever (cid:98)Rn is pd. By Lemma 4 below, the deﬁnition given in (2.16) is unique
for all large enough n wp18 and

(cid:98)Gn − GFn → 0p×p and (cid:98)Hn − HFn → 0k×k a.s.

(2.17)

under certain sequences Fn as deﬁned in FAKP,an for which RFn = GFn ⊗ HFn + o(1) (where RFn
(cid:48)
i)−1/2 (as deﬁned
is deﬁned in (2.10) with F replaced by Fn), HFn := (EFnZiZ
in (2.12)), and the upper left element of GFn is normalized to 1.

(cid:48)
i)−1/2H Fn(EFnZiZ

Deﬁnition of the conditional subvector test: We denote the subvector AR statistic when
the variance matrix has AKP structure by ARAKP,n(β0) and deﬁne it as the smallest root ˆκpn of
the roots ˆκin, i = 1, ..., p (ordered nonincreasingly) of the characteristic polynomial

(cid:12)
(cid:12)ˆκIp − n−1 (cid:98)G−1/2
(cid:12)

n

(cid:0)Y 0, W (cid:1)(cid:48)

Z (cid:98)H −1

n Z(cid:48) (cid:0)Y 0, W (cid:1)

(cid:98)G−1/2
n

(cid:12)
(cid:12)
(cid:12) = 0.

The conditional subvector test ARAKP,α rejects H0 at nominal size α if

ARAKP,n(β0) > c1−α(ˆκ1n, k − mW ),

(2.18)

(2.19)

where c1−α (·, ·) is deﬁned as follows. Muirhead (1978), in the case where mW = 1 and assuming
normality, provides an approximate, nuisance parameter free, conditional density of the smaller
eigenvalue ˆκ2n given the larger one ˆκ1n for any degree of overidentiﬁcation k − mW , see (2.12) in
GKM19 for the conditional pdf. For given ˆκ1n and arbitrary mW , c1−α(ˆκ1n, k−mW ) denotes the 1−
α-quantile of that approximation. GKM19 (Table 1 and Supplement C) provide c1−α(ˆκ1n, k − mW )
for α = 1, 5, 10%, k−mW = 1, ..., 20 and a ﬁne grid of values for ˆκ1n, say ˆκ1,1 ≤ ... ≤ ˆκ1,j ≤ ... ≤ ˆκ1,J
for some large J. We reproduce Table 1 (that covers the case α = 5% and k − mW = 4) from
GKM19 below. Conditional critical values for values of ˆκ1n not reported in the tables are obtained
by linear interpolation. Speciﬁcally, let q1−α,j(k − 1) denote the 1 − α quantile of the distribution
whose density is given by (2.12) in GKM19 with ˆκ1n replaced by ˆκ1,j. The end point of the grid
ˆκ1,J should be chosen high enough so that q1−α,J (k − mW ) ≈ χ2
k−mW ,1−α. For any realization of

7In van Loan and Pitsianis (1993, Corollary 2), the orthogonal matrices (cid:98)L ∈ (cid:60)pp×pp and (cid:98)N ∈ (cid:60)kk×kk are called

U and V, respectively, notation that we have already used for other objects.

8Note that it would not be unique if the eigenspace associated with the largest singular value had dimension larger

than 1.

8

ˆκ1n ≤ ˆκ1,J , ﬁnd j such that ˆκ1n ∈ [ˆκ1,j−1, ˆκ1,j] with ˆκ1,0 = 0 and q1−α,0 (k − mW ) = 0, and let

c1−α (ˆκ1n, k − mW ) :=

ˆκ1,j − ˆκ1n
ˆκ1,j − ˆκ1,j−1

q1−α,j−1 (k − mW ) +

ˆκ1n − ˆκ1,j−1
ˆκ1,j − ˆκ1,j−1

q1−α,j (k − mW ) .

(2.20)

Table 1: cv = c1−α(ˆκ1, k − mW ) for α = 5%, k − mW = 4 for various values of ˆκ1

ˆκ1
1.2
1.3
1.4
1.6
1.8

cv

1.1
1.2
1.3
1.5
1.7

ˆκ1
2.1
2.3
2.5
2.7
3.0

cv

1.9
2.1
2.3
2.5
2.7

ˆκ1
3.2
3.5
3.7
4.0
4.2

cv

2.9
3.1
3.3
3.5
3.7

ˆκ1
4.5
4.7
5.0
5.3
5.6

cv

3.9
4.1
4.3
4.5
4.7

ˆκ1
5.9
6.2
6.5
6.8
7.1

cv

4.9
5.1
5.3
5.5
5.7

ˆκ1
7.4
7.8
8.2
8.6
9.0

cv

5.9
6.1
6.3
6.5
6.7

ˆκ1
9.4
9.9
10.5
11.1
11.7

cv

6.9
7.1
7.3
7.5
7.7

ˆκ1
12.5
13.4
14.5
15.9
17.9

cv

7.9
8.1
8.3
8.5
8.7

ˆκ1
20.9
26.5
39.9
57.4
1000

cv

8.9
9.1
9.3
9.4
9.48

Denote by P(γ,ΠW ,ΠY ,F )(·) the probability of an event under the null hypothesis when the true
values of the structural and reduced form parameters and the distribution of the random variables
are given by (γ, ΠW , ΠY , F ). Recall the deﬁnition of the parameter space FAKP,an in (2.5). We can
now formulate the main result of this section.

Theorem 1 Under Assumption B, the conditional subvector test ARAKP,α deﬁned in (2.19) im-
plemented at nominal size α has asymptotic size, i.e.

lim sup
n→∞

sup
(γ,ΠW ,ΠY ,F )∈FAKP,an

P(γ,ΠW ,ΠY ,F )(ARAKP,n(β0) > c1−α(ˆκ1n, k − mW ))

equal to α for α ∈ {1%, 5%, 10%} and k − mW ∈ {1, ..., 20} .

Comment. 1. The conditional subvector test ARAKP,α adapts the test in GKM19 from a setup
under CHOM to AKP structure. The modiﬁcation involves replacing the matrices (cid:0)Y 0, W (cid:1)(cid:48)
MZ
(cid:0)Y 0, W (cid:1) /(n − k) and n−1Z
Z in GKM19 by the matrices (cid:98)Gn and (cid:98)Hn, respectively, in (2.18) to
account for the more general structure of the covariance matrix. Some portions of the proof follow

(cid:48)

similar steps as the proof of Theorem 5 in GKM19. In particular, one portion of the proof relies on

an one-dimensional simulation exercise to prove that the NRPs are bounded by the nominal size.
This exercise could be extended to choices of α and k − mW beyond those in the theorem and likely
the theorem would extend to many more choices.

2. Trivially, under the same assumptions as in Theorem 1, we obtain that

lim sup
n→∞

sup
(γ,ΠW ,ΠY ,F )∈FAKP,an

P(γ,ΠW ,ΠY ,F )(ARAKP,n(β0) > χ2

k−mW ,1−α) = α.

That is, the generalization of the subvector test in GKMC to AKP structure has correct asymptotic

size. This result is obtained fully analytically; its proof does not require any simulations.

3. Invariance with respect to nonsingular transformations of the IV matrix. The
i γ)Zi =

identifying power of the model comes from the moment condition EF εiZi = EF (yi−Y (cid:48)

i β−W (cid:48)

9

0. This moment condition obviously still holds when the instrument vector is premultiplied by a
nonrandom nonsingular matrix A ∈ (cid:60)k×k, i.e. EF εiAZi = 0. It then seems reasonable to look for
testing procedures whose outcome is invariant to such nonsingular transformations. In the weak IV

literature, e.g. Andrews et al. (2006) and Andrews et al. (2019) and references therein, the class of

(similar) invariant tests to orthogonal transformations A, that is, changes of the coordinate system,

has been studied. The transformation of the IVs in (2.9) is performed in order for the test to be

invariant to nonsingular transformations of the IVs.

If the conditional subvector ARAKP test deﬁned in (2.19) (and (cid:98)Rn in (2.11)) was deﬁned with Zi
in place of Zi it would be invariant to orthogonal transformations but not necessarily to nonsingular
ones. To see the former, denote by (cid:98)RnA the matrix (cid:98)Rn when the instrument vector has been
transformed to AZi (and consequently Z is changed to ZA(cid:48)). Then the claim follows from R( (cid:98)RnA) =
R( (cid:98)Rn)(A(cid:48) ⊗ A(cid:48)) (which holds for any nonsingular matrix A by straightforward calculations using
vec(ABC) = (C(cid:48) ⊗ A)vec(B) for any conformable matrices A, B, and C and MZ = MZA(cid:48)) which
implies (cid:98)GnA = (cid:98)Gn and (cid:98)HnA = A (cid:98)HnA(cid:48) when A is orthogonal, where again (cid:98)GnA and (cid:98)HnA denote the
matrices (cid:98)Gn and (cid:98)Hn when the instrument vector Zi has been transformed to AZi. It then follows
(cid:48) (cid:0)Y 0, W (cid:1)
that the matrix n−1 (cid:98)G−1/2
in (2.18) (and thus its eigenvalues)
remain invariant under orthogonal transformations Zi → AZi of the instrument matrix. This test
however is not invariant in general to arbitrary nonsingular transformations.

(cid:0)Y 0, W (cid:1)(cid:48)

(cid:98)G−1/2

Z (cid:98)H −1

n Z

n

n

But with the replacement of Zi by Zi as done in (2.11) and, correspondingly, Z by Z(n−1Z

Z)−1/2
in (2.18), the test is invariant against nonsingular transformations A. The invariance of this test
to arbitrary nonsingular transformations Zi → AZi of the instrument matrix (which leads to a
ZA(cid:48))−1/2AZi) follows from straightforward calculations and the fact
transformation of Zi to (AZ
that the matrix

(cid:48)

(cid:48)

TA := (Z

(cid:48)

Z)1/2A(cid:48)(AZ

(cid:48)

ZA(cid:48))−1/2 ∈ (cid:60)k×k

(2.21)

In particular, one can easily show that the matrices R( (cid:98)Rn), (cid:98)Gn, and (cid:98)Hn that
is orthogonal.
appear as ingredients in the conditional subvector test ARAKP,α with A = Ik are related to the
corresponding matrices R( (cid:98)RnA), (cid:98)GnA, and (cid:98)HnA, when A is an arbitrary nonsingular matrix, via

R( (cid:98)RnA) = R( (cid:98)Rn) (TA ⊗ TA) , (cid:98)GnA = (cid:98)Gn, and (cid:98)HnA = T (cid:48)

A (cid:98)HnTA

(2.22)

which immediately implies the desired invariance result.

4. The conditional subvector test can be generalized to a stationary time series setting, see

the Appendix, Section A.5, for details.
In the context of a time series setting we oﬀer another
example of AKP structure. Namely, consider a structural vector autoregression AXt = BXt−1 + ηt,
where dim Xt = dim ηt = n, E (ηt|Xt−1) = 0 and suppose that var (ηt|Xt−1) = var (ηt) = Σt =
diag (cid:0)σ2
i for some scalar function of time at, i.e., the volatilities of all the
shocks change over time in a proportional manner, then the variance of Xt−1ηt has KP structure.
In this model, identiﬁcation can be achieved by exclusion restrictions (Sims, 1980) that render some
of Xt−1 valid instruments. It can also be achieved with external instruments if available (Stock and

it = atσ2

1t, ..., σ2
nt

(cid:1). If σ2

10

Watson, 2018). Time-variation in volatilities has been reported in many contexts. For instance, the

‘great moderation’ is a well-documented phenomenon of a fall in macroeconomic volatility in the

US in the early 1980s (cf. Bernanke (2004), ch. 4). AKP would result if the fall in the volatilities

were similar across variables.

5. Note that under the null hypothesis the test does not depend on the value of the reduced
form matrix ΠY because the test statistic and the critical value are aﬀected by Y only through
Y 0 = y − Y β0.

6. GKM19 establish that the conditional subvector AR test introduced there enjoys near op-

timality properties in the linear IV model with conditional homoskedasticity in a certain class of
tests that depend on the data only through the roots ˆκin, i = 1, ..., p when k − mW = 1. On the
other hand, when k − mW gets bigger the test may be quite conservative. The power gains over the
projected AR subvector test discussed in Dufour and Taamouti (2005) arise in weakly identiﬁed

scenarios while under strong identiﬁcation these two tests become identical. Similarly, we expect
the power properties of the new conditional subvector test ARAKP,α to be most competitive for
small k − mW , particular, when k − mW = 1, in weakly identiﬁed situations.

Intuition behind the result derived in GKM19 that conditioning on the largest eigenvalue when
mW > 1 leads to a test with correct size is based on i) the corresponding result for mW = 1 and
ii) the so called ”inclusion principle” that provides a ranking of the corresponding eigenvalues of

a Hermitian matrix and its principal submatrices (see GKM19 bottom p.499-500, in particular eq

(2.23)).

3 Subvector Testing under Arbitrary Forms of Conditional Het-

eroskedasticity

We now allow for arbitrary forms of CHET, that is, the parameter space does not impose an AKP
structure for RF . We describe a testing procedure under high level assumptions that we then verify
in the next subsections for particular implementations of the test. In particular, Lemma 1 below

veriﬁes Assumptions RT and RP below for a particular implementation of the AR/AR test.

In what follows, FHet is a generic parameter space for (γ, ΠW , ΠY , F ) that does not impose an
AKP structure, but if the restriction RF = GF ⊗ H F + Υn as in FAKP,an in (2.5) was added to
the conditions in FHet then FHet ⊂ FAKP,an. For example, the null parameter space FHet may
impose stronger moment conditions than FAKP,an so that certain Lyapunov CLTs apply. See the
deﬁnitions of FHet in the next subsections. We summarize the restrictions on the parameter space
(PS) in the following assumption.

Assumption PS: FHet ⊂ (cid:101)FAKP,an, where (cid:101)FAKP,an is equal to FAKP,an without the condition
RF = GF ⊗ H F + Υn (AKP structure ) and without the assumptions κmin(A) ≥ δ2 for A ∈
{GF , H F }.

We assume there exists a robust test (RT) ϕRob,α that has asymptotic size for the parameter
space FHet bounded by the nominal size α. For example, in the next subsection we consider a

11

particular implementation of the AR/AR test in Andrews (2017). In general, we think of ϕRob,α
as a test whose power can be substantially improved on by the test ϕAKP,α when RF has AKP
structure.

Assumption RT: The test ϕRob,α of (2.3) has asymptotic size bounded by the nominal size α for
the parameter space FHet.

We now deﬁne a new test that, roughly speaking, coincides with ϕAKP,α or ϕRob,α depending

on whether the data seems consistent or not with AKP structures. We now provide the details.

Consider a given sequence of constants cn such that

cn → ∞ and cn/n1/2 → 0

e.g. cn = cn1/2/ ln(n) or cn = cn1/2/ ln ln(n) for some constant c > 0 and deﬁne

λ9n := min ||R−1/2

Fn

(G ⊗ H − RFn)R−1/2

Fn

||/cn,

(3.1)

(3.2)

where the minimum (here and in analogous expressions below) is taken over (G, H) for G ∈ (cid:60)p×p,
H ∈ (cid:60)k×k being pd, symmetric matrices, normalized such that the upper left element of G equals
1.9 The quantity λ9n measures how far from KP structure the covariance matrix RFn in (2.10)
when F = Fn is. To show that the new test ϕM S−AKP,α deﬁned below has asymptotic signiﬁcance
level α, it is suﬃcient (as proven in the Appendix) to consider two types of drifting sequences of
DGPs in FHet and to establish that the test has limiting NRP bounded by the nominal size α in
each case. The ﬁrst type of sequences are those for which

n1/2λ9n → h9 = ∞,

(3.3)

that is sequences where the covariance matrix RFn is ”far away” from KP structure. We assume
that there is a model selection (MS) method ϕM S,cn ∈ {0, 1} such that when RFn is ”far from”
KP structure it will chose the robust test wpa1. The next assumption makes that statement more

precise. To properly formulate the assumption we require terminology that is provided in the

Appendix because it requires a lot of space. In particular, we need to consider particular sequences
of drifting parameters λwn,h (deﬁned in (A.21) in the Appendix) where wn denotes a subsequence
of n.

Assumption MS: The model selection method ϕM S,cn ∈ {0, 1} satisﬁes ϕM S,cn = 1 wpa1 under
parameter sequences λwn,h (with underlying parameter space FHet) with h9 = ∞.

By deﬁnition, along λwn,h, w1/2

n λ9wn → h9 and thus when h9 = ∞ the sequence is not local to

KP structure.

Deﬁnition of the fully robust test: Let δ ≥ 0. The new suggested test ϕM S−AKP,δ,cn,α of

9The expression G ⊗ H − RFn is pre- and postmultiplied by R−1/2

Fn

for invariance reasons.

12

nominal size α of the null hypothesis (2.3) is deﬁned as

ϕM S,cnϕRob,α−δ + (1 − ϕM S,cn)ϕAKP,α.

(3.4)

We typically write ϕM S−AKP,α rather than ϕM S−AKP,δ,cn,α to simplify notation. Ideally, δ = 0 can
be chosen in this construction. To verify Assumption RP below using the AR/AR test as ϕRob,α−δ
we need to have δ > 0. (Potentially, Assumption RP may hold with δ = 0 but our current proof

technique does not allow verifying it).

By Assumption MS, ϕM S−AKP,α = ϕRob,α−δ wpa1 in case (3.3). Thus, by Assumption RT, the

new test ϕM S−AKP,α has limiting NRP bounded by α − δ of the test in that case.

For the model selection methods introduced below, the sequence of constants cn reﬂects a trade-
oﬀ between size and power. Large values of cn will imply frequent use of ϕAKP,α which should
translate into good power properties. On the other hand, use of ϕAKP,α could distort the NRPs
in ﬁnite samples if the test is used in a scenario where the covariance matrix does not have AKP
structure. Below we make a recommendation regarding the choice of cn based on comprehensive
Monte Carlo studies. Note that cn can also depend on observed nonrandom quantities such as e.g.
k and mW but for the sake of notational simplicity we don’t make that explicit.

To guarantee correct asymptotic signiﬁcance level α of the test ϕM S−AKP,α and to rule out any
potential pretesting issue, we have to implement the test ϕRob,α at a nominal size inﬁnitesimally
smaller than α. For example, we can pick δ = 10−6, which should not make any practical diﬀerence
in terms of power relative to using the test with δ = 0.

In addition, we have to impose one additional assumption regarding the relative NRPs (As-
sumption RP below) of the robust test ϕRob,α−δ and ϕAKP,α under sequences with AKP structure
in order to make sure that ϕM S−AKP,α has limiting NRP bounded by α. More precisely, consider
a sequence of DGPs in FHet such that

n1/2λ9n → h9 ∈ [0, ∞).

(3.5)

Using n1/2/cn → ∞, one can then show that min ||G ⊗ H − RFn|| → 0 and the sequences are of
AKP structure. Therefore, under such sequences the test ϕAKP,α has limiting NRP bounded by α.
The notation Pλwn,h(A) denotes probability of an event A when the true DGP is characterized by
λwn,h. By deﬁnition, along λwn,h, w1/2
n λ9wn → h9 and thus when h9 < ∞ the sequence is local to
KP structure.

Assumption RP: Under sequences of DGPs (γwn, ΠW wn, ΠY wn, Fwn) in FHet for subsequences
wn for which λwn,h satisﬁes h9 ∈ [0, ∞), Pλwn,h(ϕRob,α−δ ≤ ϕAKP,α) → 1.

Assumption RP says that under null sequences local to KP structure the robust test ϕRob,α−δ
has critical region that is contained in the critical region of ϕAKP,α with probability going to one.
Even when δ = 0 this does not need to imply that the two tests are asymptotically identical because

the robust test may have limiting NRP strictly smaller than α and may be more conservative than
ϕAKP,α. Under Assumption RP one can show that in case (3.5) (i.e. under drifting sequences of

13

DGPs λwn,h with ﬁnite h9) ϕM S−AKP,α has limiting NRP bounded by the nominal size of the test
(because from the proof of Theorem 1 the test ϕAKP,α has limiting NRP bounded by α; and the
limiting NRP of the new test ϕM S−AKP,α is then bounded by α by the assumption that ϕRob,α−δ
has asymptotic size bounded by α − δ.)

From the above, it then follows quite straightforwardly, that the asymptotic size of ϕM S−AKP,α
is bounded by the nominal size for the parameter space FHet. Also, the new test is at most as
nonsimilar asymptotically as ϕRob,α−δ which translates into favorable power properties of the new
test.

Theorem 2 Suppose Assumptions PS, RT, MS, and RP hold. Then the test ϕM S−AKP,δ,cn,α
deﬁned in (3.4) with δ > 0 and cn satisfying the conditions in (3.1) has asymptotic size bounded by
the nominal size α for the parameter space FHet for α ∈ {1%, 5%, 10%} and k − mW ∈ {1, ..., 20} .

Comments. 1. If lim inf n→∞ inf (γ,ΠW ,ΠY ,F )∈FHet E(γ,ΠW ,ΠY ,F )ϕM S−AKP,δ,cn,α is continuous in
δ at δ = 0 then as δ → 0 the new test ϕM S−AKP,δ,cn,α is asymptotically not more nonsimilar (i.e.
less conservative) than ϕRob,α, i.e.

lim
δ→0

lim inf
n→∞

inf
(γ,ΠW ,ΠY ,F )∈FHet

E(γ,ΠW ,ΠY ,F )ϕM S−AKP,δ,cn,α

≥ lim inf
n→∞

inf
(γ,ΠW ,ΠY ,F )∈FHet

E(γ,ΠW ,ΠY ,F )ϕRob,α.

(3.6)

See the proof of Theorem 2 for a proof. Property (3.6) should translate into improved power of
ϕM S−AKP,δ,cn,α relative to ϕRob,α.

2. The restriction to α ∈ {1%, 5%, 10%} and k−mW ∈ {1, ..., 20} in the formulation of Theorem
2 is an artifact of Theorem 1 where the conditional subvector test ϕAKP,α was shown to have correct
asymptotic size for these cases only. The same is true for other theorems formulated below.

In the next subsection we speciﬁcally use the AR/AR subvector procedure due to Andrews

(2017) as ϕRob,α−δ.

3.1 Model selection methods ϕM S,cn

In this subsection we discuss two methods that can be used for ϕM S,cn as model selection procedures.
The ﬁrst one is akin to the moment selection method in Andrews and Soares (2010) to check which

moment inequalities are binding in a model deﬁned by moment inequalities. The second one is

based on the test for KP structure introduced in GKM22.

Method 1: Deﬁne

(cid:98)Kn := n1/2|| (cid:98)R−1/2

n

( (cid:98)Gn ⊗ (cid:98)Hn − (cid:98)Rn) (cid:98)R−1/2

n

||,

(3.7)

with (cid:98)Gn and (cid:98)Hn deﬁned in (2.13), to evaluate how far the true model is away from KP structure.
Deﬁne the ﬁrst choice for model selection as

ϕM S,cn := I( (cid:98)Kn > cn).

(3.8)

14

Recall the deﬁnition of (cid:101)FAKP,an given in Assumption PS. Here we take

FHet = {(γ, ΠW , ΠY , F ) ∈ (cid:101)FAKP,an,

EF ((||Zi||2||Ui||2)2+δ1) ≤ B, κmin(Rn) ≥ δ2}.

(3.9)

It is easy to show using the formulae in (2.22) and the analogous one (cid:98)RnA = (Ip ⊗ T (cid:48)
A) (cid:98)Rn(Ip ⊗ TA)
for (cid:98)Rn, orthogonality of TA, and using the fact that the Frobenius norm is invariant to orthogonal
transformations, that (cid:98)Kn is invariant to nonsingular transformations of the instrument vector.
Crucial for this result is again that fi in (2.11) in the deﬁnition of (cid:98)Rn (and as a result in the
deﬁnition of (cid:98)Gn and (cid:98)Hn in (2.13)) is implemented with the transformed instrument vector Zi
(rather than with Zi).
Method 2: Deﬁne

ϕM S,cn := I(KP ST > cn),

(3.10)

where KP ST is the test statistic introduced in GKM22 to test the null of a KP structure of RF .10 To
employ this method, we need to strengthen the moment restrictions in FHet to EF (||Ti||2 +δ1) ≤ B,
for Ti ∈ {||Zi||4||Ui||4, ||Zi||4}, see Theorem 3 in GKM22.

We verify Assumption MS in the Appendix, Section A.3, for these two choices of ϕM S,cn and

for the parameter space deﬁned in (3.9).

3.2 Choice for ϕRob,α : The AR/AR test in Andrews (2017)

In this subsection we deﬁne one particular version of the various weak IVs and heteroskedasticity

robust subvector tests suggested in Andrews (2017), namely the so called AR/AR test and verify

that it satisﬁes Assumptions RT and RP from the previous subsection. We deﬁne it for nominal

size α.

To do so, we use the following quantities. For θ = (β, γ) let11

gi (θ) := Zi(yi − Y (cid:48)

i β − W (cid:48)

i γ) and (cid:98)gn (θ) := n−1(cid:80)n

i=1gi (θ) .

Deﬁne

ˆΣn (θ) := n−1(cid:80)n

i=1 (gi (θ) − (cid:98)gn (θ)) (gi (θ) − (cid:98)gn (θ))(cid:48) .

(3.11)

(3.12)

The heteroskedasticity-robust AR statistic for testing hypotheses involving the full parameter vector
θ, evaluated at (β0, γ) , is deﬁned as

HARn (β0, γ) := n(cid:98)gn (β0, γ)(cid:48) ˆΣn (β0, γ)−1

(cid:98)gn (β0, γ) .

(3.13)

For s = 1, ..., mW denote by W s ∈ (cid:60)n the s-th column of W. Next, as in Andrews (2017, (7.9)-(7.10))

10The test statistic is deﬁned in (19) and (22) in GKM20 and not reproduced here for brevity. In their notation

our fi is (cid:98)fi, compare the formula below (7) in GKM20 to our (2.11).

11To simplify notation we write (β, γ) here and in other situations, rather than the more correct (β(cid:48), γ(cid:48))(cid:48).

15

let

˜Dn (θ) := ˆΣn (θ)−1/2 ( (cid:98)D1n (θ) , ..., (cid:98)DmW n (θ)) ∈ (cid:60)k×mW ,
W s − ˆΓsn (θ) ˆΣn (θ)−1
(cid:98)Dsn (θ) := −n−1Z
ˆΓsn (θ) := −n−1(cid:80)n

(cid:98)gn (θ) ∈ (cid:60)k,

W s(cid:17)

i − n−1Z

ZiW s

(cid:16)

(cid:48)

(cid:48)

i=1

gi (θ)(cid:48) ∈ (cid:60)k×k, and

HARβ,n (β0, γ) := n(cid:98)gn (β0, γ)(cid:48) ˆΣn (β0, γ)−1/2 M ˜Dn(β0,γ)+an−1/2ζ1

ˆΣn (β0, γ)−1/2

(cid:98)gn (β0, γ) ,

(3.14)

where HARβ,n (β0, γ) is a C (α)-AR statistic, obtained as a quadratic form in the moment condi-
tions projected onto the space orthogonal to the orthogonalized Jacobian with respect to γ. The
random perturbation an−1/2ζ1 (with ζ1 ∈ (cid:60)k×mW a random matrix of independent standard normal
random variables that are independent of all other statistics considered) in the last line of (3.14)
is introduced in Andrews (2017, p.23), to guarantee that the space projected on has rank mW a.s.
Here a ∈ (cid:60) is a tiny positive constant.

Let α ∈ (0, 1). The AR/AR test at nominal size α is deﬁned as follows.

1. Fix an α1 ∈ (0, α) . As in Andrews (2017, (7.1)) deﬁne

CS+

1n := {(cid:101)γ ∈ (cid:60)mW : HARn (β0, (cid:101)γ) < χ2

k,1−α1} ∪ (cid:101)Γ1n,

where for (cid:98)Qn (θ) := (cid:98)gn (θ)(cid:48) (n−1(cid:80)n

i=1ZiZ

(cid:48)
i)−1

(cid:98)gn (θ) ,

(cid:101)Γ1n :=

(cid:110)
γ ∈ (cid:60)mW : W (cid:48)Z((cid:80)n

i=1ZiZ

(cid:98)Qn (β0, γ) ≤ min
(cid:101)γ∈(cid:60)mW

(cid:98)Qn (β0, (cid:101)γ) +

(cid:48)
i)−1

(cid:98)gn (β0, γ) = 0mW &
ln n
n

(cid:27)

(3.15)

(3.16)

is the so-called “estimator set”, see Andrews (2017, p.1 and (7.3)). If W (cid:48)PZW is invertible
(which would happen wpa1 under the assumption (not imposed here) that EF ZiW (cid:48)
i is full col-
umn rank) then the ﬁrst condition in (cid:101)Γ1n has the unique solution γn := (W (cid:48)PZW )−1W (cid:48)PZ(y−
Y β0) and therefore (cid:101)Γ1n = {γn}. (Note that along certain sequences for which ||γ|| → ∞ it
follows that ||(cid:98)gn (β0, γ) || → ∞ and therefore if the function (cid:98)Qn (β0, γ) ≥ 0 only has one local
extremum it must be a global minimum.)

2. For α2,n(θ) deﬁned below (and depending on α and α1), H0 in (2.3) is rejected if

(cid:16)

inf
(cid:101)γ∈CS+

1n

HARβ,n (β0, (cid:101)γ) − χ2

k−mW ,1−α2,n(β0,(cid:101)γ)

(cid:17)

> 0.

That is

ϕAR/AR,α,α1 = 1(cid:26)

inf

(cid:101)γ∈CS+
1n

(cid:18)

HARβ,n(β0,(cid:101)γ)−χ2

k−mW ,1−α2,n(β0,(cid:101)γ)

(cid:27),

(cid:19)

>0

(3.17)

see Andrews (2017, (4.2)). We typically write ϕAR/AR,α instead of ϕAR/AR,α,α1.

16

The second step size α2,n(θ) is chosen as

(cid:40)

α2,n(θ) :=

α − α1,
α,

if ICSn(θ) ≤ KL
if ICSn(θ) > KL,

(3.18)

for some positive number KL, e.g., KL = 0.05 and α1 = .005, see Andrews (2017, (7.8) and p.34)12,
where

(cid:98)Φn(θ) := Diag{ˆσ−1
(cid:16)
sn(θ) := n−1(cid:80)n
ˆσ2

i=1

1n (θ), ..., ˆσ−1

mW n(θ)} ∈ (cid:60)mW ×mW ,
(cid:17)2

Hsi(θ) − (cid:98)Hsn(θ)

, for s = 1, ..., mW ,

(cid:113)

Hsi(θ) :=

(W s
ICSn(θ) := n−1κ1/2

i )2Z
min((cid:98)Φn(θ)W (cid:48)Z ˆΣn (θ)−1 Z

ˆΣn (θ)−1 Zi, (cid:98)Hsn(θ) := n−1(cid:80)n
W (cid:98)Φn(θ)),

(cid:48)

(cid:48)
i

i=1Hsi(θ),

(3.19)

see Andrews (2017, (7.4)-(7.5)), where W s

i ∈ (cid:60) denotes the s-th component of Wi.

Coming back to the statistic ARAKP,n(β0) given in (2.18) note that

ARAKP,n(β0) = inf

(cid:103)ARAKP,n(β0, (cid:101)γ) :=

(cid:101)γ∈RmW
n−1(cid:0) 1
−(cid:101)γ

(cid:103)ARAKP,n(β0, (cid:101)γ), where
(cid:1)(cid:48) (cid:0)Y 0, W (cid:1)(cid:48)
n Z(cid:48) (cid:0)Y 0, W (cid:1) (cid:0) 1
Z (cid:98)H −1
−(cid:101)γ
(cid:1)(cid:48)
(cid:0) 1
(cid:0) 1
(cid:98)Gn
−(cid:101)γ
−(cid:101)γ

(cid:1)

(cid:1)

(3.20)

using the fact that the minimal eigenvalue of any symmetric square matrix A ∈ Rp×p is obtained
as minx∈Rp,||x||=1 x(cid:48)Ax. Furthermore,

(cid:101)Σn (β0, (cid:101)γ)−1
(cid:103)ARAKP,n(β0, (cid:101)γ) =n(cid:98)gn (β0, (cid:101)γ)(cid:48)
(cid:0)1, −(cid:101)γ(cid:48)(cid:1)(cid:48)) ⊗ (n−1Z
(cid:101)Σn (β0, (cid:101)γ) :=((cid:0)1, −(cid:101)γ(cid:48)(cid:1)
(cid:98)Gn
(cid:19)
(cid:19)(cid:48)
( (cid:98)Gn ⊗ (n−1Z

⊗ Ik

=

(cid:48)

(cid:98)gn (β0, (cid:101)γ) , where
(cid:48)

Z)1/2 (cid:98)Hn(n−1Z

Z)1/2 (cid:98)Hn(n−1Z

(cid:48)

Z)1/2

(cid:18)(cid:18) 1
−(cid:101)γ

(cid:48)

Z)1/2)

(cid:19)

(cid:18)(cid:18) 1
−(cid:101)γ

(cid:19)

⊗ Ik

(3.21)

and ( (cid:98)Gn, (cid:98)Hn) deﬁned in (2.16).

Let γ+

n be an element in arg min

(cid:101)γ∈RmW (cid:103)ARAKP,n(β0, (cid:101)γ). We impose a mild technical condition

below, namely that

ΠW nn1/2(γ+

n − γn) = Op(1)

(3.22)

n = Op(1) under sequences in FHet (deﬁned in (3.24) below) that are of AKP structure, i.e.

and γ+
under sequences λn,h for which h9 ∈ [0, ∞).

12Andrews (2017, (7.8)) allows for more involved deﬁnitions of α2,n(θ). We choose the version that takes KU = KL
in the notation of Andrews (2017) that is also used in the Monte Carlos in Andrews (2017). Regarding the deﬁnition
of (cid:98)Φn(θ), note that it constitutes a slight modiﬁcation compared with the deﬁnitions in Andrews (2017, (7.5)). In
particular, the modiﬁcation in the deﬁnition of ˆσ2
sn is necessary to make the procedure invariant to nonsingular
transformations of the instrument vector. We thank Donald Andrews for suggesting this updated version of his test
statistic.

17

Condition (3.22) has been established for several closely related estimators. E.g. γ+

n − γn =
Op(1) holds under weak IV sequences ΠW n = C/n1/2 (for some ﬁxed matrix C) and homoskedas-
ticity when γ+
n is the LIML estimator, see Staiger and Stock (1997, Theorem 1). Results in Hahn
and Kuersteiner (2002, Theorem 1) imply (3.22) for the 2SLS estimator under a setup where
ΠW n = C/nδ for δ > 0. Stock and Wright (2000, Theorem 1(ii)) and Guggenberger and Smith
(2005, Theorem 2) implies (3.22) for the CU estimator under mixed weak/strong IV asymptotics
ΠW n = (C/n1/2, D) for a ﬁxed full rank matrix D ∈ (cid:60)k×m(cid:48)
W ≤ mW (using high level
assumptions, such as Assumptions B and D in Stock and Wright (2000)) and possible CHET.

W with m(cid:48)

n = Op(1), then for all ε > 0, γ+

Stock and Wright (2000, Theorem 1(ii)) can also be applied in the current situation to show
(3.22) under sequences λn,h for which h9 ∈ [0, ∞). Given ε > 0 we need to show that for some
compact set Kε, ΠW nn1/2(γ+
n − γn) ∈ Kε with probability at least 1 − ε for all large enough sample
sizes. Assuming γ+
n is contained in a compact set Kε with probability
at least 1 − ε for all large enough sample sizes. Consider the estimator γKε
that is deﬁned as a
n
minimizer of (cid:103)ARAKP,n(β0, (cid:101)γ) in (cid:101)γ over Kε. Thus γKε
n are numerically identical for all sample
sizes large enough with probability at least 1 − ε. Note that (cid:103)ARAKP,n(β0, (cid:101)γ) has the same structure
as the criterion function ST (θ, θ) in (2.2) in Stock and Wright (2000) with (cid:101)Σn (β0, (cid:101)γ)−1 playing
the role of the weighting matrix WT (θ) and n1/2
s=1φs (θ).
Therefore, under drifting sequences of mixed weak/strong IVs, namely ΠW n = (C/n1/2, D), the
limiting distribution of γKε
n is given in Stock and Wright (2000, Theorem 1(ii)) if Assumptions B and
D in Stock and Wright (2000) hold for parameter space Kε for (cid:101)γ and (cid:103)ARAKP,n(β0, (cid:101)γ) has a unique
minimum. Stock and Wright (2000, Theorem 1(ii)) states that those components of γKε
n − γn that
correspond to the columns of C/n1/2 in ΠW n are Op(1) and those that correspond to the columns
of D in ΠW n are Op(n−1/2) which establishes ΠW nn1/2(γKε

(cid:98)gn (β0, (cid:101)γ) playing the role of n−1/2(cid:80)T

n and γ+

n − γn) = Op(1).

Assumption B in Stock and Wright (2000) holds for γKε
n

(in fact, Assumption B’ in Stock
and Wright (2000), which is suﬃcient for Assumption B, holds by linearity of gi (θ) , the moment
conditions in FHet, and compactness of Kε). To establish Assumption D note that under sequences
(cid:48)
λn,h, n−1Z
i, (cid:98)Gn →p lim GFn, and (cid:98)Hn →p lim HFn (note that the right hand side
limits exist by deﬁnition of λn,h). Therefore, under sequences λn,h

Z →p lim EFnZiZ

(cid:48)

(cid:101)Σn (β0, (cid:101)γ)−1 →p (lim EFnZiZ

(cid:48)
i)−1/2 lim H −1
Fn

(lim EFnZiZ

(cid:48)

i)−1/2/((cid:0)1, −(cid:101)γ(cid:48)(cid:1) lim GFn

(cid:0)1, −(cid:101)γ(cid:48)(cid:1)(cid:48)) (3.23)

uniformly over (cid:101)γ (noting that || (1, −(cid:101)γ(cid:48)) || ≥ 1, lim GFn > 0, and lim HFn > 0) with the limit matrix
being nonrandom, continuous, symmetric, and pd for all (cid:101)γ. Thus, by Stock and Wright (2000,
Theorem 1(ii)), if (cid:103)ARAKP,n(β0, (cid:101)γ) has a unique minimum in Kε and γ+
n = Op(1), it follows that
ΠW nn1/2(γKε
n − γn) ∈ K
at least with probability 1 − ε for all n large enough. Because γ+
coincide at least with
probability 1 − ε for all large enough sample sizes, it then follows that ΠW nn1/2(γ+
n − γn) ∈ K at
least with probability 1 − 2ε for all n large enough.

n − γn) = Op(1). Thus there exists a compact set K such that ΠW nn1/2(γKε

n and γKε
n

Deriving (3.22) under all possible drifting sequences ΠW n is technically tedious and involves
e.g. also consideration of so-called sequences of non-standard weak identiﬁcation, see Andrews and

18

Guggenberger (2019, AG from now on) for more discussion. If (3.22) is not already implied by the
restrictions in the parameter space FHet below then the asymptotic size results should simply be
interpreted for sequences of parameter spaces FHet,n that impose additional restrictions on FHet
such that (3.22) holds.

The null parameter space is restricted by the conditions in FAR/AR of Andrews (2017, (8.8))

and some weak additional ones, namely,

FHet = {(γ, ΠW , ΠY , F ) ∈ (cid:101)FAKP,an : γ ∈ Θγ∗ ⊂ (cid:60)mW ,
EF ||UijZil1Zil2Zil3||1+δ1 ≤ B for j = 1, ..., p, l1, l2, l3 = 1, ..., k,
EF ||εiZi||2+δ1 ≤ B, EF ||vec(W (cid:48)
s = 1..., mW , and κmin(A) ≥ δ2 for A ∈ {RF , EF ε2

i Zi)||2+δ1 ≤ B, varF ||W s
(cid:48)
i}},

i ZiZ

i Zi)|| ≥ δ2 for

(3.24)

for constants B < ∞, and δ1, δ2 > 0 and a bounded set Θγ∗ such that for some (cid:15) > 0 we have
B(Θγ∗, (cid:15)) ⊂ Θγ, where Θγ denotes the null nuisance parameter space for γ and B(Θγ∗, (cid:15)) denotes
the union of closed balls in (cid:60)mW with radius (cid:15) centered at points in Θγ∗.

Lemma 1 Assume that under any sequence of DGPs (γwn, ΠW wn, ΠY wn, Fwn) in FHet deﬁned
in (3.24) for subsequences wn for which λwn,h satisﬁes h9 ∈ [0, ∞) we have γ+
wn = Op(1) and
Π1/2
wn − γwn) = Op(1). Then, for any δ > 0, the AR/AR test ϕAR/AR,α−δ,α1 in (3.17)
W wn
satisﬁes Assumptions RT and RP for the parameter space FHet.

wn(γ+

3.3 Main result

We obtain the following corollary of Lemma 1, Theorem 2, and the veriﬁcation of Assumption MS
in subsection 3.1 for the two model selection methods ϕM S,cn suggested there.

Deﬁne the parameter space FHet as the intersection of the parameter spaces deﬁned in (3.9)
and (3.24) when the method in (3.8) is used as ϕM S,cn (and a slightly more restricted parameter
space when (3.10) is used, as explained below (3.10).)

Corollary 3 Assume the same condition as in Lemma 1. Then the test ϕM S−AKP,α deﬁned in (3.4)
with δ > 0 and cn satisfying the conditions in (3.1) implemented with the AR/AR test ϕAR/AR,α−δ,α1
of Andrews (2017) playing the role of ϕRob,α−δ and either of the two model selection methods
described above used for ϕM S,cn, has asymptotic size bounded by the nominal size α for the parameter
space FHet deﬁned in the paragraph above for α ∈ {1%, 5%, 10%} and k − mW ∈ {1, ..., 20} .

Comment. Note that under the null hypothesis the test does not depend on the value of the

reduced form matrix ΠY .

19

4 Monte Carlo study

In this section we investigate the ﬁnite sample performance in model (2.1) of the suggested new test
ϕM S−AKP,α deﬁned in (3.4) and juxtapose it to the performance of alternative methods suggested
in the extant literature, namely the two-step tests AR/AR, AR/LM, and AR/QLR1 in Andrews
(2017). For the implementation of ϕM S−AKP,α we use both methods considered in Section 3.1 and
call the resulting tests MS-AKP1 and MS-AKP2 for the remainder of this section. We also simulate
the performance of the test ARAKP,α (which is of course size distorted in the setups with CHET
that are outside of KP structure).

All results below are for nominal size α = 5%. Unless otherwise stated, we take mW = 1. We
consider the case β ∈ (cid:60) and γ ∈ (cid:60) and pick γ = 0 and test the null hypothesis in (2.3) with β0 = 0.

Choice of tuning parameters

The implementation of the various tests depends on a large number of user chosen constants.
In particular, to implement the AR/AR, AR/LM, and the AR/QLR1 tests we pick α1 = .005,
KL = KU = 0.05 as already mentioned above after (3.18). To calculate the estimator set (cid:101)Γ1n we
employ the closed form solution provided below (3.16). We choose a = .001 and pick the elements
of the random matrix ζ1 ∈ (cid:60)k×mW as i.i.d. N (0, 1) independent of all other variables considered,
see the last line of (3.14).13 The conﬁdence interval (or region) for γ that appears in (3.15) is
obtained by grid search over an interval (or rectangle) of length 20 centered at the true value of
γ with 100 equally spaced gridpoints.14 To implement the AR/QLR1 test, as in Andrews (2017)
we pick K∗
U = 0.005 and Krk = 1. We refer to Table II in Andrews (2017) that provides
the results of a comprehensive sensitivity analysis on most of the user chosen constants above. To

L = K∗

calculate the data-dependent critical values for the AR/QLR1 test we use 10,000 i.i.d chi-square
random variables. There was no noticeable diﬀerence between δ = 0 and δ = 10−6 for δ given in
(3.4); therefore, for the sake of computational simplicity, we pick the former in the simulations.
Finally, cn has to be chosen, which we do in the next subsection.

Recommended choices for cn

First, we perform a large number of simulations in order to determine recommendations for the
sequence of constants cn satisfying (3.1). We make recommendations for cn,k,mW = cn as a function
of the number k of IVs and consider choices from k ∈ {2, 3, 4}.

For each k, sample size n ∈ {250, 500}, and (ΠY , ΠW ) ∈ (cid:60)k×2 with

ΠW = 1kπW /(nk)1/2

(4.1)

13Note that by choosing a (cid:54)= 0 the tests are no longer invariant to nonsingular transformations of the IV vector.

However, for small a the diﬀerences after a transformations are usually very small.

14When the dimension of γ grows then the implementation of that step by grid search will cause an exponential

increase in computation time for each of the two-step methods.

20

with πW ∈ {2, 4, 40}, corresponding to “very weak”, “weak”, and “strong” identiﬁcation of γ (and,
relevant for the power results below, ΠY = (cid:101)1kπY /(nk)1/2 with πY ∈ {2, 4, 40} and (cid:101)1k equal to
(1k/2(cid:48), −1k/2(cid:48))(cid:48) when k is even and equal to (1, −12(cid:48))(cid:48) when k = 3) we randomly generate 1, 000
diﬀerent DGPs (that is a choice for the covariance matrix) as described below and simulate the

NRPs (using 5, 000 i.i.d samples of each given DGPs) of MS-AKP1 and MS-AKP2 for choices of
cn given as

cn = cn,k,1 = c(k, 1)n1/2/ ln ln n

(4.2)

with c(k, 1) taken from the set C := {.05, .1, ..., 3}.

In ﬁnite sample simulations for the DGPs considered here, the AR/AR test sometimes slightly

overrejects. For example, under CHOM, n = 250, k = 3, strong IVs, and covariance matrix Σ being
chosen as below (4.8), where (ui, vY,i, vW,i)(cid:48) ∼ i.i.d. N (03, Σ), the AR/AR test has NRP equal to
5.4%. From our theory we also know that the test ARAKP,α (at least under AKP structures) has
nonsmaller NRP than the AR/AR test. Deﬁne as the ”simulated size of a test when there are k

IVs” the highest empirical NRP of the test over all choices of n, Π, and (1, 000) random DGPs

considered. For each of the two methods MS-AKP1 and MS-AKP2 and for each k ∈ {2, 3, 4}, our
recommendation for cn,k,1 then is to take the largest c(k, 1) in C such that the simulated size does
not exceed 6% (that is, we allow for a distortion of 1% in the ”simulated size”). It turns out that in
our simulations this criterion for cn,k,1 always leads to well deﬁned choice of c(k, 1) (when a priori
it could be that even for the smallest/largest choice of c(k, 1) in C the simulated size exceeds/is

still below 6%).

To generate random DGPs we consider the following mechanism. Given all tests considered
above, including ARAKP,α, have correct asymptotic size under AKP structure we focus attention
on designs with conditional heteroskedasticity that are not of AKP structure. In particular, we

choose

εi = (αε + ||QεZi||)ui,

VY,i = (αV + ||QV Zi||)vY,i,

VW,i = (αV + ||QV Zi||)vW,i,

(4.3)

with (ui, vY,i, vW,i)(cid:48) ∼ i.i.d. N (03, Σ) and independent of Zi ∼ i.i.d. N (0k, Ik) for i = 1, ..., n. Each
of the 1,000 random DGPs is determined by choosing αε, αV ∈ (cid:60), Qε, QV ∈ (cid:60)k×k, and Σ ∈ (cid:60)3×3,
where Σ has diagonal elements equal to 1. The scalars αε, αV and the components of Qε, QV ∈ (cid:60)k×k
are obtained by i.i.d. draws from a U [0, 10], and the oﬀ-diagonal ones of Σ ∈ (cid:60)3×3 are obtained by
i.i.d. draws from a U [0, 1] (subject to the restriction that the resulting matrix Σ is pd). Note that
the setup in (4.3) nests KP structure when e.g. αε = αV = 0, Qε = QV = Ik and CHOM when e.g.
αε = αV = 1, Qε = QV = 0k×k.

For each k = 2, 3, 4 the binding constraint on c(k, 1) always came from the combination n = 250

and “strong” identiﬁcation, while for the “very weakly” identiﬁed scenario even the largest choice

of c(k, 1) ∈ C typically did not yield overrejection for any of the sample sizes considered. Based

21

on the above setup we recommend the following choices for cn,k,1. For Method 1 in Section 3.1,
MS-AKP1, that is for ϕM S−AKP,α based on the distance in Frobenius norm statistic, we suggest

c(2, 1) = .85,

c(3, 1) = 1.25,

c(4, 1) = 1.4,

(4.4)

while for Method 2, MS-AKP2, that is for ϕM S−AKP,α based on the KPST statistic in GKM22, we
suggest

c(2, 1) = .75,

c(3, 1) = 1.45,

c(4, 1) = 1.9.

(4.5)

Recall that with these choices of c(k, 1) and cn chosen as in (4.2) the tests and MS-AKP1 and
MS-AKP2 have correct asymptotic size for a parameter space with arbitrary forms of conditional

heteroskedasticity.

Next we consider mW = 2. We take γ = (0, 0)(cid:48). As pointed out above already, the computational
eﬀort in the above exercise increases exponentially in the dimension of mW if we use the same
number of gridpoints in each dimension in the calculation of the conﬁdence interval for γ that

appears in (3.15). Therefore, we use a grid of a product of two intervals of length 20 centered at

the true value of γ with only 50 equally spaced gridpoints in each dimension (rather than 100 in
the case mW = 1.) Everything else is the same, mutatis mutandis (e.g. Σ is now a 4x4 matrix),
as described in the case mW = 1 except that ΠW ∈ (cid:60)k×2 is taken as (πW 1e1, πW 2e2)/(nk)1/2 with
πW 1, πW 2 ∈ {2, 40} and that the search set for c(k, 2) is increased to C := {.05, .1, ..., 7.5}.

For Method 1 in Section 3.1, MS-AKP1 we suggest

c(3, 2) = 1.75,

c(4, 2) = 3.2,

c(5, 2) = 3.05,

(4.6)

while for Method 2, MS-AKP2 we suggest

c(3, 2) = 2.9,

c(4, 2) = 7.2,

c(5, 2) = 7.5.

(4.7)

Just like in the case mW = 1 the highest null rejection probabilities occur in the strongly identiﬁed
case.

Size results

All results below are for the case where mW = 1. Under a setup with CHET outside of KP, the
tests MS-AKP1 and MS-AKP2 equal the AR/AR test wpa1. We therefore ﬁrst consider the KP
setup in Andrews (2017) in Section 9.1 which is obtained from (4.3) with αε = αV = 0 and
Qε = QV = Ik. We also consider the setup with CHOM obtained from (4.3) with αε = αV = 1
and Qε = QV = 0k×k. Then, ﬁnally, below we also examine how power is aﬀected as the DGP
transitions from CHOM to CHET outside of KP.

In both cases of CHET and CHOM, we take the matrix

kΣ ∈ (cid:60)3×3

22

(4.8)

to have diagonal elements equal to one, and the (1,2) and (1,3) elements equal to .8 and the (2,3)
element equal to .3, as in Andrews (2017). We consider πW = πY ∈ {2, 4, 40} in (4.1), again,
representing ”very weak”, ”weak”, and ”strong” IVs, also see Andrews (2017). Finally, we take

k ∈ {2, 3, 4} and sample sizes n ∈ {250, 500}. Altogether, that makes for 36 diﬀerent speciﬁcations.

In addition, we also obtain results for certain cases of mixed identiﬁcation strength, e.g. when
πW (cid:54)= πY ∈ {2, 40} and also some results for larger sample sizes.

As reported in Andrews (2017), we also ﬁnd that in an overall sense the AR/AR and AR/LM

tests are dominated by the AR/QLR1 test. For instance, regarding the AR/LM test, its power

function (even in the strong IV context under CHOM) is not always U-shaped and suﬀers from

power dips against certain alternatives. For example, for the KP setup for n = 250, k = 4, with

weak IVs, the power of the AR/LM and AR/QLR1 tests when β = −2 are 8.6% and 75.6%,

respectively, while in the setup with CHOM when β = −1.43 the power of the AR/LM test is

34.9% while all the other tests have power equal to 100%. On the other hand, the AR/AR test

fares worse than the AR/QLR1 test in strongly identiﬁed overidentiﬁed situations. In what follows,

we don’t therefore discuss the AR/LM test in much detail.

We consider rejection probabilities under the null β0 = 0 and (for power) under a grid of seven
β values on each side of 0 with distances from the hypothesized value 0 chosen depending on the

strength of identiﬁcation. For example, in the very weakly, weakly, and strongly identiﬁed cases we

take β in the interval [−2, 2], [−2, 2], and [−.2, .2], respectively, around the true value of 0. Results

are obtained from 10, 000 i.i.d samples from each DGP.

First, we discuss the NRPs. Over the 18 DGPs of the KP setups, the NRPs of MS-AKP1,

MS-AKP2, AR/AR, AR/LM, and AR/QLR1 lie in the intervals (all numbers in %):

[3.5,5.9],

[3.3,6.0], [1.9,5.1], [.6,5.2], and [1.5,4.9]. As set up above, the tests MS-AKP1 and MS-AKP2

slightly overreject the null for small sample sizes (especially in the strongly identiﬁed case), but the

size distortion disappears as n grows. For example, the NRPs of MS-AKP2 in the KP setup with

k = 3 and strong identiﬁcation is 6.0, 5.5, 5.2, and 5.1%, respectively, when n = 250, 500, 1, 000,

and 1, 500. On the other hand, the tests AR/AR, AR/LM, and AR/QLR1, while controlling the

NRP very well, underreject the null in weakly identiﬁed scenarios. This leads to relatively poor

power properties relative to the tests MS-AKP1 and MS-AKP2 in weakly identiﬁed situations.

Regarding the 18 DGPs with CHOM, the one important diﬀerence relative to the KP setup is

that the three tests AR/AR, AR/LM, and AR/QLR1 are less conservative with NRPs over the 18

DGPs in the intervals [4.1,5.4], [3.5,5.4], and [3.7,5.1], respectively. As a consequence, these tests

have relatively better power properties than in the KP setup.

Power results

Next we discuss the power results. We focus again on the case where mW = 1. Power for MS-AKP1,
MS-AKP2, AR/AR, and AR/QLR1 increases as the IVs become stronger. On the other hand, by

the local-to-zero design considered here (see (4.1) and below), as n increases, power for these three

tests changes only slightly. We therefore only provide details for the case where n = 250. Power of

23

Figure 1: Power of various subvector tests in diﬀerent cases. Covariance structure: Kronecker
product (KP); CHOM. Identiﬁcation strength (πW , πY ): Very Weak (2, 2); Weak (4, 4); Strong
(40, 40); Mixed strength: (2, 40).

all the tests is much higher in the setting with CHOM compared to the KP setting and especially

so for the AR/QLR1 test (because it underrejects the null hypothesis less under CHOM than under

KP). As one example, consider the case n = 250, k = 2, with weak identiﬁcation. In that case,

when β = −.571 the tests MS-AKP2, AR/AR, and AR/QLR1 have power 48.7, 46.3, and 45.4%

under KP, but power equal to 95.9, 95.6, and 95.4% under CHOM!

A representative selection of power curves in four diﬀerent cases is plotted in Figure 1. Note

that in the ﬁgures corresponding to the diﬀerent cases, both the scale of the horizontal and the

vertical axes vary by a lot depending on the strength of identiﬁcation.

The key takeaways from the power study are as follows:

i) Based on the DGPs considered here we cannot make a clear recommendation as to which one

of the two tests MS-AKP1 and MS-AKP2 is preferable. In most cases, they have virtually identical

power. In few cases, one dominates the other, but only by a small diﬀerence. In the Figures below

we only report results for MS-AKP2.

ii) Regarding the comparison between the tests MS-AKP1, MS-AKP2 and AR/AR we ﬁnd

that the former two virtually uniformly dominate the latter in all the designs considered. This

is not surprising given the construction of the new tests and given they satisfy Assumption RP

above. The relative power advantage of the tests MS-AKP1, MS-AKP2 over AR/AR partly stems

from the underrejection of the latter test under the null. See e.g. Figure 1a that contains power

curves for n = 250, k = 2, very weak identiﬁcation, and KP structure for MS-AKP2, AR/AR, and

AR/QLR1. (The NRPs of the three tests reported here are 4.2, 2.0, and 1.6%, respectively. Note

24

a) n=250,k=2,Very Weak, KP-2-101200.050.10.150.20.25MS-AKP2AR/ARAR/QLR1b) n=250,k=4,Strong, KP-0.2-0.100.10.200.20.40.60.81c) n=250,k=3,Weak, CHOM-2-101200.20.40.60.81d) n=250,k=4,Mixed Strength, KP-1-0.500.5100.050.10.150.20.250.3that the x-axis in Figures I-IV plots the true value β.)

iii) Regarding the comparison between the tests MS-AKP1, MS-AKP2 and AR/QLR1 in the
case of equal identiﬁcation strength πW = πY we ﬁnd that the former two are generally more
powerful under weak identiﬁcation and small k while the reverse is true under strong identiﬁcation

and larger k, see Figures 1a and b for the cases “k = 2 and very weak identiﬁcation” and “k = 4

and strong identiﬁcation,” respectively, both for n = 250 and KP. (In Figure 1b, the NRPs of

the tests MS-AKP2, AR/AR, and AR/QLR1 are 5.9, 5.1, and 4.6%, respectively.) These two

ﬁgures show the best relative performances for the MS-AKP1, MS-AKP2 and AR/QLR1 tests in
the “equal identiﬁcation” settings where πW = πY . In Figure 1a the power advantage of MS-AKP2
over AR/QLR1 is as high as 5.2%, while in Figure 1b the power of AR/QLR1 can be up to 13.1%

more powerful than MS-AKP2.

In the “intermediate” case between these extremes, namely “k = 3 and weak identiﬁcation”

(again with n = 250 and KP; not reported in Figure 1), the MS-AKP1 and MS-AKP2 tests have

slightly higher power than AR/QLR1 when β is positive while the reverse is true for negative values

of β. In all cases, the relative performance of the AR/QLR1 test improves under CHOM; under

CHOM, for the “intermediate” case “k = 3 and weak identiﬁcation” (again with n = 250) the

AR/QLR1 test has uniformly higher power than the MS-AKP1 and MS-AKP2 tests, see Figure 1c.

(In Figure 1c, the NRPs of the tests MS-AKP2, AR/AR, and AR/QLR1 are 5.5, 4.7, and 5.1%,

respectively.)

In cases of mixed identiﬁcation strength, πW (cid:54)= πY ∈ {2, 40}, we ﬁnd that when πW = 2 and
πY = 40 the tests MS-AKP1 and MS-AKP2 have uniformly higher power than AR/QLR1 for all k
considered whereas in the case πW = 40 and πY = 2 all tests have comparable power. See Figure
1d that contains the case πW = 2 and πY = 40, n = 250, k = 4, with KP structure where the
power gap between the new tests and AR/QLR1 is as high as 13.4%. (In Figure 1d, the NRPs of

the tests MS-AKP2, AR/AR, and AR/QLR1 are 3.3, 1.9, and 0.9%, respectively.) It seems that

in these cases of mixed identiﬁcation strength the new tests enjoy their most competitive relative

performance.

Results for non-KP DGPs

Finally, we examine how rejection probabilities are aﬀected as the DGP transitions from KP to

CHET outside of KP. To do so, we report rejection probabilities under the null and certain al-

ternatives and probabilities with which MS-AKP1 and MS-AKP2 equals the AR/AR test in the

second stage for a class of DGPs that under KP coincide with the ones considered in Figures 1b
(πW = πY = 40) and d ((πW , πY ) = (2, 40)). In particular, we choose k = 4, n = 250, γ = 0, and

25

the matrix Σ equals the one in (4.8). In (4.3) we take

Qε = I4 + (cid:37)









10 8 6 4

3

8

4

5 9 3

6 9 2

3 2 1









(4.9)

for (cid:37) ∈ {0, .01, ..., .1}, αε = αV = 0, and QV = I4. Note that for (cid:37) = 0, the design leads to KP
while for (cid:37) > 0, it leads to CHET outside of KP. In particular, arg minG,H>0 ||G ⊗ H − RF || (with
RF deﬁned in (2.4) with Ui = (εi, V (cid:48)
W,i)(cid:48)) equals 0, .14, .29, .45, .60, .74, .88, 1.01, 1.13, 1.24, and
1.34 when (cid:37) ∈ {0, .01, .02, ...., .1}, respectively. The latter numbers are found by simulations based
on 107 simulation repetitions using Theorem 1 in GKM22.

As before, we report results for 10, 000 simulation repetitions at nominal size 5%.

Null rejection probabilities. Here we report results when β = 0, that is, we report NRPs.

First, in the setup of Figure 1b the probability with which MS-AKP1 and MS-AKP2 coincide

with AR/AR is strictly increasing in (cid:37) and e.g.

equals 66.2% and 64.9%, 82.9% and 85.1%,

and 98.8% and 99.5%, respectively for (cid:37) = 0, .03, and .1, respectively. (We also simulated these

probabilities when (cid:37) = 0 for n = 500 and they equal 20.8% and 20.2%, respectively). The highest

NRP of both the MS-AKP1 and MS-AKP2 tests is 5.9% which occurs when (cid:37) = 0 and is caused
by a 7.4% NRP of the conditional subvector test ARAKP,α (even though by Theorem 1 this test
has correct asymptotic NRP for this DGP; interestingly, this test has NRP equal to 5.8% when

(cid:37) = .1, a case that is not covered by Theorem 1). Given the MS-AKP1 and MS-AKP2 tests

equal the AR/AR test with increasing probability as (cid:37) increases, their NRPs get closer (but not

monotonically so) to 5% as (cid:37) increases. As (cid:37) = .1 both tests have NRP equal to 5.2%.

Second, in the setup of Figure 1d the probability with which MS-AKP1 and MS-AKP2 coincide

with AR/AR are identical as just reported for the setup in Figure 1b. The highest NRPs of the

MS-AKP1 and MS-AKP2 tests are 3.5% and 3.2% respectively, which occur when (cid:37) = 0. The

AR/AR and AR/QLR1 tests have NRPs in the intervals [1.2%,1.9%] and [.3%,.8%], respectively,

and therefore, quite substantially underreject the null hypothesis. As the MS-AKP1 and MS-AKP2

tests equal the AR/AR test with increasing probability as (cid:37) increases, their NRPs approach 1.2%

as (cid:37) gets closer to .1.

Power results. Here we examine how power is aﬀected as the DGP transitions from KP to

CHET outside of KP.

First, in the setup of Figure 1b) we consider the alternative β = .1. The probabilities with

which MS-AKP1 and MS-AKP2 coincide with AR/AR are increasing in (cid:37) and are very similar to

the corresponding values when β = 0; e.g. the probabilities equal 68.6% and 68.9% when (cid:37) = .01,

respectively, and equal 98.2% and 99.1% when (cid:37) = .1. Power for all tests monotonically decreases

as (cid:37) increases, e.g. for AR/QLR1, AR/AR, and MS-AKP1 from 83.5% to 44.4%, from 71.5% to

32.4% and from 72.5% to 32.4%, respectively, when (cid:37) goes from 0 to .1.

Second, in the setup of Figure 1d) we consider the alternative β = −1. When (cid:37) = .01, MS-

26

AKP1 and MS-AKP2 coincide with AR/AR with probability 78.3% and 75.5%, respectively and

for (cid:37) ≥ .04 both MS-AKP1 and MS-AKP2 coincide with AR/AR at least 99.6% of the cases.

The power of the AR/AR and the AR/QLR1 for all values of (cid:37) ∈ {0, .01, .02, ...., .1} are in the

intervals [27.9%,29.4%] and [21.2%,23.5%], respectively, with neither test’s power being monotonic

in (cid:37). While the power of MS-AKP1 and MS-AKP2 slightly exceeds the power of the AR/AR test

for (cid:37) < .04 their power is identical to the one of the AR/AR test for larger values of (cid:37).

In sum, as one would expect given the construction of MS-AKP1 and MS-AKP2 tests, when

moving from KP to CHET outside of KP, their rejection probabilities get closer and closer to those

of the AR/AR test.

5 Conclusion

We propose the construction of a robust test that improves the power of another robust test

by combining it with a powerful test that is only robust for a subset of the parameter space.
We implement this construction in the context of the linear IV model applied to the ARAKP,α
test that has correct asymptotic size for a parameter space that imposes AKP structure and the

AR/AR test that is robust even when allowing for arbitrary forms of CHET. We believe that

the particular construction and implementation suggested here, namely combining a powerful but

non fully robust test with a less powerful fully robust test in order to obtain a fully robust more

powerful test, might be successfully applied in other scenarios and also in the current scenario based

on diﬀerent choices of testing procedures. For instance, it might be feasible to combine the LR

type subvector test of Kleibergen (2021) with the AR/QLR1 of Andrews (2017) but it would be

technically substantially more challenging to verify the assumptions given above that are suﬃcient

for control of the asymptotic size of the resulting test. Other extensions include improving the
power of the ARAKP,α test by making the conditional critical value depend on more than just the
largest eigenvalue.

A Appendix

The Appendix is structured as follows. In Section A.1 the proof of Theorem 1 is given, prepared for

ﬁrst with several technical lemmas in Subsection A.1.1. Next in Section A.2 the proof of Theorem

2 is given. We provide veriﬁcations of the high level assumptions for particular implementations of
the test including for both ϕM S,cn and AR/AR in Sections A.3 and A.4, respectively. Finally, in
Section A.5, we generalize the conditional subvector test to a time series framework.

27

A.1 Proof of Theorem 1

A.1.1 Technical lemmas

In what follows below we will require results about solutions to certain minimization problems

involving the Frobenius norm. The next lemma provides a special case of Corollary 2.2 in van Loan

and Pitsianis (1993). Note that van Loan and Pitsianis (1993) point to Golub and van Loan (1989,

p.73) for a proof of Corollary 2.2. However, the result in Golub and van Loan (1989, p.73) is for a

minimization problem using the p-norm for p = 2 and not the Frobenius norm which is used here.

Lemma 2 Consider the minimization problem

min
B∈(cid:60)m×n, rk(B)=1

||A − B||2

for a given nonzero matrix A ∈ (cid:60)m×n with singular value decomposition A = U diag(σ1, ..., σp)V (cid:48) for
singular values σ1 ≥ σ2 ≥ ... ≥ σp ≥ 0 with p = min{m, n} and rectangular diag(σ1, ..., σp) ∈ (cid:60)m×n,
orthogonal matrices U = [u1, ..., um] ∈ (cid:60)m×m, and V = [v1, ..., vn] ∈ (cid:60)n×n. Then a minimizing
argument is given by B = σ1u1v(cid:48)
1 is
the unique minimizer.

1 and the minimum equals (cid:80)p

i . If σ1 > σ2 then B = σ1u1v(cid:48)

i=2σ2

Proof of Lemma 2. Note that

min
B∈(cid:60)m×n, rk(B)=1

||A − B||2 =

min
C∈(cid:60)m×n, rk(C)=1

||diag(σ1, ..., σp) − C||2

(A.1)

by viewing C = U (cid:48)BV and because ||D|| = ||U (cid:48)D|| = ||DV || for any matrix D ∈ (cid:60)m×n and
conformable orthogonal matrices U and V. We can write any matrix C ∈ (cid:60)m×n with rk(C) = 1 as

C = ||c||−1(α1c, ..., αnc)

(A.2)

for c ∈ (cid:60)m\{0m} and αk ∈ (cid:60) for k = 1, ..., n. Because ||A+B||2 = ||A||2+||B||2+2 < A, B >F where
< A, B >F := trace(A(cid:48)B) denotes the Frobenius inner product, and ||diag(σ1, ..., σp)||2 = (cid:80)p
i=1σ2
i ,
||C||2 = (cid:80)n

i=1σiαici||c||−1 for c = (c1, ..., cm)(cid:48) we have

i , < diag(σ1, ..., σp), C >F = (cid:80)p

i=1α2

||diag(σ1, ..., σp) − C||2 = (cid:80)p

i=1σ2

i + (cid:80)n

i=1α2

i − 2(cid:80)p

i=1σiαici||c||−1.

(A.3)

Viewing (A.3) as a function in αk, k = 1, ..., n, and c, taking ﬁrst order conditions (FOCs) with
respect to αk, we obtain 2αk − 2σkck||c||−1 = 0 or

αk = σkck||c||−1 for k = 1, ..., p and αk = 0 for k = p + 1, ..., n.

(A.4)

Taking FOCs with respect to cj, j = 1, ..., p, we obtain (||c||σjαj − ((cid:80)p
and thus

i=1σiαici)cj||c||−1)||c||−2 = 0

||c||2σjαj − ((cid:80)p

i=1σiαici)cj = 0

(A.5)

28

and for j = p + 1, ..., m we have ((cid:80)p

i=1σiαici)cj||c||−3 = 0 and therefore

cj

(cid:80)p

i=1σiαici = 0.

(A.6)

The objective is to ﬁnd (c1, ..., cp) such that the two summands in (A.3) that depend on C are
being minimized. Using (A.4) we thus need to ﬁnd (c1, ..., cm) such that

(cid:80)p

i=1σ2

i c2

i ||c||−2 − 2(cid:80)p

i=1σ2

i c2

i ||c||−2 = −(cid:80)p

i=1σ2
i (

ci
||c||

)2

(A.7)

is minimized. Let a be the largest index for which σ1 = ... = σa. Given that σa > σb for b > a it
(cid:54)= 0m−p
follows that a vector c = (c1, ..., cm)(cid:48) is a minimizing argument if and only if (c1, ..., ca)(cid:48)
and (ca+1, ..., cm)(cid:48) = 0m−a and the minimum in (A.3) equals

(cid:80)p

i=1σ2

i − (cid:80)p

i=1σ2
i (

ci
||c||

)2 = (cid:80)p

i=1σ2

i − σ2
1

(cid:80)a

i=1(

ci
||c||

)2 = (cid:80)p

i=2σ2
i .

(A.8)

For example, one solution is c = e1 := (1, 0, ...0)(cid:48) ∈ (cid:60)m for which the minimizing matrix in (A.1)
becomes C = (σ1e1, 0m, ...0m). Correspondingly, a minimizing matrix B becomes U CV (cid:48) = σ1u1v(cid:48)
1.
If σ1 > σ2 then a = 1. Therefore, any minimizing c equals (c1, 0, ..., 0)(cid:48) for some c1 (cid:54)= 0
and therefore, by (A.2) and (A.4), the only minimizing matrix C equals ||c||−1(α1c, ..., αnc) =
1. (cid:3)
(σ1e1, 0m, ...0m). And consequently, there can only be a unique minimizer B = U CV (cid:48) = σ1u1v(cid:48)

Let R ∈ (cid:60)m×l and R = U ΣV (cid:48) be a singular value decomposition of R, where Σ ∈ (cid:60)m×l has
min{m, l} singular values of R on the diagonal and zeros elsewhere, U ∈ (cid:60)m×m is an orthogonal
matrix of eigenvectors of RR(cid:48), and V ∈ (cid:60)l×l is an orthogonal matrix of eigenvectors of R(cid:48)R.
In general, U, Σ, and V are not uniquely deﬁned. The matrix Σ is uniquely determined by the

restriction that the singular values are ordered nonincreasingly. We assume that this is the case from
now on. Let a be the geometric multiplicity of the largest eigenvalue of RR(cid:48). Write U = [(cid:102)W : (cid:102)W C]
for (cid:102)W ∈ (cid:60)m×a. Thus (cid:102)W = ( (cid:101)w1, ..., (cid:101)wa) denotes an orthogonal basis for the eigenspace associated
with the largest eigenvalue of RR(cid:48).

Lemma 3 Let R and Rn for n ≥ 1 be (cid:60)m×l matrices such that Rn → R as n → ∞. Let U ΣV (cid:48)
and UnΣnV (cid:48)
n be any singular value decompositions of R and Rn, respectively, where the singular
values are ordered nonincreasingly. For j ≤ m, denote by (cid:101)wj and (cid:101)wnj the j-th column of U and
Un, respectively. Decompose U = [(cid:102)W : (cid:102)W C] ∈ (cid:60)m×m, where (cid:102)W = ( (cid:101)w1, ..., (cid:101)wa) ∈ (cid:60)m×a is an
orthogonal basis for the eigenspace associated with the largest eigenvalue of RR(cid:48). Conformingly, let
Un = [(cid:102)Wn : (cid:102)W C
nj (cid:101)wl = o(1) for j > a and
l ≤ a.

n ].15 Assume Σ does not equal the zero matrix. Then (cid:101)w(cid:48)

15But note that (cid:102)Wn does not necessarily correspond to a basis for the eigenspace of the largest eigenvalue of RnR(cid:48)
n
but may represent eigenvectors corresponding to several diﬀerent eigenvalues because the multiplicities of eigenvalues
of RnR(cid:48)
n equal to a diagonal
matrix with ﬁrst and second diagonal elements equal to 1 and 1 − n−1, respectively.

n and RR(cid:48) may not be the same. As a trivial example, consider RR(cid:48) = I2 and RnR(cid:48)

29

Proof of Lemma 3. Wlog we can assume m ≥ l. (If m < l add l − m rows of zeros to the

bottom of R and Rn. Then the result for

(cid:32)

R
0l−m×l

(cid:33)

(cid:32)

=

U
0l−m×m

0m×l−m
(cid:101)U

(cid:33) (cid:32)

(cid:33)

V (cid:48)

Σ
0l−m×l

for any orthogonal matrix (cid:101)U implies the desired result for R = U ΣV (cid:48).) Denote by σj the j-th
singular value of R (i.e. σj equals the (j, j)-th element of Σ) for j = 1, ..., l, and likewise σnj
denotes the j-th singular value of Rn. By deﬁnition (and given that the algebraic and geometric
multiplicities coincide for any diagonalizable matrix), a is the largest index for which σ1 = ... = σa.
Deﬁne

δn := min{ min

1≤j≤l−a

|σa − σn(a+j)|, σa}.

(A.9)

Then by Wedin’s (1972) theorem (see, e.g. Li (1998) equations (4.4) and (4.8)16), it follows that

|| sin Θ((cid:102)W , (cid:102)Wn)|| = o(1/δn),

(A.10)

where Θ((cid:102)W , (cid:102)Wn) denotes the angle matrix between (cid:102)W and (cid:102)Wn (see Li (1998), equation (2.3) for a
deﬁnition). Furthermore, by Lemma 2.1 and equation (2.4) in Li (1998), we have

|| sin Θ((cid:102)W , (cid:102)Wn)|| = ||(cid:102)W C(cid:48)

n (cid:102)W ||.

(A.11)

Note that δn is bounded away from zero for all large n because (1) σa > 0 by the assumption that
Σ (cid:54)= 0, (2) if a < l, by construction σa > σa+1 and therefore min1≤j≤l−a |σa − σn(a+j)| is uniformly
bounded away from zero (because singular values are continuous as functions of the matrix elements
and Rn → R), and (3) if a = l then min1≤j≤l−a |σa − σn(a+j)| = ∞, because we take a minimum of
the empty set. Therefore, by (A.10) and (A.11) we have

||(cid:102)W C(cid:48)

n (cid:102)W || = o(1)

(A.12)

which implies that (cid:101)w(cid:48)

nj (cid:101)wl = o(1) for j > a and l ≤ a. (cid:3)

A.1.2 Uniformity Reparametrization

To prove that the new conditional subvector ARAKP test has asymptotic size bounded by the
nominal size α we use a general result in Andrews, Cheng, and Guggenberger (2020, ACG from
now on). To describe it, consider a sequence of arbitrary tests {ϕn : n ≥ 1} of a certain null
hypothesis and denote by RPn(λ) the NRP of ϕn when the DGP is pinned down by the parameter
vector λ ∈ Λ, where Λ denotes the parameter space of λ. By deﬁnition, the asymptotic size of ϕn

16A comprehensive reference for background reading on Wedin’s (1972) theorem is Stewart and Sun (1990, p.260,

Theorem 4.1).

30

is deﬁned as

AsySz = lim sup
n→∞

sup
λ∈Λ

RPn(λ).

(A.13)

Let {hn(λ) : n ≥ 1} be a sequence of functions on Λ, where hn(λ) = (hn,1(λ), ..., hn,J (λ))(cid:48) with
hn,j(λ) ∈ (cid:60) ∀j = 1, ..., J. Deﬁne

H = {h ∈ ((cid:60) ∪ {±∞})J : hwn(λwn) → h for some subsequence {wn}
of {n} and some sequence {λwn ∈ Λ : n ≥ 1}}

(A.14)

Assumption B in ACG: For any subsequence {wn} of {n} and any sequence {λwn ∈ Λ : n ≥ 1} for
which hwn(λwn) → h ∈ H, RPwn(λwn) → [RP −(h), RP +(h)] for some RP −(h), RP +(h) ∈ (0, 1).17
The assumption states, in particular, that along certain drifting sequences of parameters λwn
indexed by a localization parameter h the NRP of the test cannot asymptotically exceed a certain
threshold RP +(h) indexed by h.

Proposition 4 (ACG, Theorem 2.1(a) and Theorem 2.2) Suppose Assumption B in ACG holds.
Then, inf h∈H RP −(h) ≤ AsySz ≤ suph∈H RP +(h).

We next verify Assumption B in ACG for the conditional subvector ARAKP test and establish
that suph∈H RP +(h) = α when the test is implemented at nominal size α. In the setup considered
here, the parameter space Λ actually depends on n which does not aﬀect the conclusion of Theorem

2.1(a) and Theorem 2.2 in ACG.

We use Proposition 16.5 in AG, to derive the joint limiting distribution of the eigenvalues (cid:98)κin,
i = 1, ..., p in (2.18). We reparameterize the null distribution F to a vector λ. The vector λ is chosen

such that for a subvector of λ convergence of a drifting subsequence of the subvector (after suitable
renormalization) yields convergence of the NRP of the test. For given F and any GF ∈ (cid:60)p×p and
H F ∈ (cid:60)k×k such that RF = GF ⊗ H F + Υn as in (2.5) deﬁne

UF := G−1/2

F

∈ (cid:60)p×p and QF := H −1/2

F

(EF ZiZ

(cid:48)
i)1/2 ∈ (cid:60)k×k,

(A.15)

where again HF = (EF ZiZ

(cid:48)
i)−1/2H F (EF ZiZ

(cid:48)
i)−1/2 from (2.12). Denote by

BF ∈ (cid:60)p×p an orthogonal matrix of eigenvectors of U (cid:48)

F (ΠW γ, ΠW )(cid:48)Q(cid:48)

F QF (ΠW γ, ΠW )UF (A.16)

ordered so that the p corresponding eigenvalues (η1F , ..., ηpF ) are nonincreasing. Denote by

CF ∈ (cid:60)k×k an orthogonal matrix of eigenvectors of QF (ΠW γ, ΠW )UF U (cid:48)

F (ΠW γ, ΠW )(cid:48)Q(cid:48)

F .18
(A.17)

17By deﬁnition, the notation xn → [x1,∞, x2,∞] means that x1,∞ ≤ lim inf n→∞ xn ≤ lim supn→∞ xn ≤ x2,∞.
18The matrices BF and CF are not uniquely deﬁned. We let BF denote one choice of the matrix of eigenvectors of
F (ΠW γ, ΠW )(cid:48)Q(cid:48)

F QF (ΠW γ, ΠW )UF and analogously for CF .

U (cid:48)

31

The corresponding k eigenvalues are (η1F , ..., ηpF , 0, ..., 0). Denote by

(τ1F , ..., τpF ) the singular values of QF (ΠW γ, ΠW )UF ∈ (cid:60)k×p,

(A.18)

which are nonnegative, ordered so that τjF is nonincreasing. (Some of these singular values may
be zero.) As is well-known, the squares of the p singular values of a k × p matrix A equal the p
largest eigenvalues of A(cid:48)A and AA(cid:48). In consequence, ηjF = τ 2
jF for j = 1, ..., p. In addition, ηjF = 0
for j = p + 1, ..., k.

Deﬁne the elements of λ to be19

λ1,F := (τ1F , ..., τpF )(cid:48) ∈ (cid:60)p,
λ2,F := BF ∈ (cid:60)p×p,
λ3,F := CF ∈ (cid:60)k×k,

λ4,F := EF ZiZ

(cid:48)
i ∈ (cid:60)k×k,

λ5,F := (λ5,1F , ..., λ5,p−1F )(cid:48) :=

(cid:18) τ2F
τ1F

, ...,

τpF
τp−1F

(cid:19)(cid:48)

∈ [0, 1]p−1, where 0/0 := 0,

λ6,F := QF ∈ (cid:60)k×k,
λ7,F := UF ∈ (cid:60)p×p,

λ8,F := F, and

λ := λF := (λ1,F , ..., λ8,F ).

(A.19)

4,F λ−1

(cid:48)
Note that by (A.15) we have GF = U −2
i)1/2
= λ1/2
4,F . In Section 3 the additional element λ9,F deﬁned in (3.2) is appended to λ with
corresponding changes to several objects below, e.g. Λn and hn(λ) in (A.20) and λwn,h in (A.19)
and (A.21); e.g. hn(λ) becomes (n1/2λ1,F , λ2,F , λ3,F , ..., λ7,F , λ9,F ).

7,F and HF = (EF ZiZ

F = λ−2

F (EF ZiZ

(cid:48)
i)1/2Q−1

(cid:48)−1
6,F λ1/2

F Q(cid:48)−1

6,F λ

The parameter space Λn for λ and the function hn(λ) (that appears in Assumption B in ACG)

are deﬁned by

Λn := {λ : λ = (λ1,F , ..., λ8,F ) for some F st (γ, ΠW , ΠY , F ) ∈ FAKP,an for some (γ, ΠW , ΠY )},

hn(λ) := (n1/2λ1,F , λ2,F , λ3,F , ..., λ7,F ).

(A.20)

We deﬁne λ and hn(λ) as in (A.19) and (A.20) because, as shown below, the asymptotic
distributions of the test statistic and conditional critical values under a sequence {Fn : n ≥ 1}
for which hn(λFn) → h depend on lim n1/2λ1,Fn and lim λm,Fn for m = 2, ..., 7. Note that we can

Note that the role of EF Gi in AG, Section 16, is played by (ΠW γ, ΠW ) ∈ Rk×p and the role of WF is played by

QF .

19For simplicity, as above, when writing λ = (λ1,F , ..., λ8,F ) (and likewise in similar expressions) we allow the
elements to be scalars, vectors, matrices, and distributions. Note that λ5,F is included so that Proposition 16.5 in
AG can be applied.

32

view h ∈ ((cid:60) ∪ {±∞})J (for an appropriately chosen ﬁnite J ∈ N ).
For notational convenience, for any subsequence {wn : n ≥ 1},

{λwn,h : n ≥ 1} denotes a sequence {λwn ∈ Λn : n ≥ 1} for which hwn(λwn) → h.

(A.21)

It follows that the set H deﬁned in (A.14) is given as the set of all h ∈ ((cid:60) ∪ {±∞})J such that
there exists {λwn,h : n ≥ 1} for some subsequence {wn : n ≥ 1}.

We decompose h analogously to the decomposition of the ﬁrst seven components of λ: h =
(h1, ..., h7), where λm,F and hm have the same dimensions for m = 1, ..., 7. We further decompose
the vector h1 as h1 = (h1,1, ..., h1,p)(cid:48), where the elements of h1 could equal ∞. Again, by deﬁnition,
under a sequence {λn,h : n ≥ 1}, we have

n1/2τjFn → h1,j ≥ 0 ∀j = 1, ..., p, λm,Fn → hm ∀m = 2, ..., 7.

(A.22)

Note that h1,p = τpFn = 0 because ρ(ΠW γ, ΠW ) < p, where ρ(A) denotes the rank of a matrix A.
By Lyapunov-type WLLNs and CLTs, using the moment restrictions imposed in (2.5), we have

under λn,h

(cid:48)

(cid:32) n−1/2Z
(cid:16)
vec

(ε + VW γn)
(cid:17)
(cid:48)

n−1/2Z

VW

(cid:33)

(cid:32)

→
d

ξ1,h
ξ2,h

(cid:33)

(cid:16)

∼ N

0kp, (cid:0)h−2

7 ⊗ (h4h−1

6 h(cid:48)−1

6 h4)(cid:1)(cid:17)

λ−1
4,Fn

(n−1Z

(cid:48)

Z) →
p

Ik, n−1Z

(cid:48)

[ε : VW ] →
p

0k×p,

,

(A.23)

where the random vector (ξ1,h, ξ(cid:48)
under λn,h, and, by deﬁnition above, h−2
λn,h.

2,h)(cid:48) is deﬁned here, Fn denotes the distribution of (εi, Z

W,i)
6 h4 denote the limits of GFn and H Fn under

7 and h4h−1

6 h(cid:48)−1

Y,iV (cid:48)

(cid:48)
i, V (cid:48)

Let q = qh ∈ {0, ..., p − 1} be such that

h1,j = ∞ for 1 ≤ j ≤ qh and h1,j < ∞ for qh + 1 ≤ j ≤ p,

(A.24)

where h1,j := lim n1/2τjFn ≥ 0 for j = 1, ..., p by (A.22) and the distributions {Fn : n ≥ 1}
correspond to {λn,h : n ≥ 1} deﬁned in (A.21). This value q exists because {h1,j : j ≤ p} are
nonincreasing in j (since {τjF : j ≤ p} are nonincreasing in j, as deﬁned in (A.18)). Note that
q is the number of singular values of QFn(ΠW nγn, ΠW n)UFn ∈ (cid:60)k×p that diverge to inﬁnity when
multiplied by n1/2. Note again that q < p because ρ(ΠW nγn, ΠW n) < p.

A.1.3 Asymptotic Distributions

One might wonder whether the deﬁnition of (cid:98)Gn in (2.16) as vec( (cid:98)Gn) = (cid:98)L(:, 1)/(cid:98)L(1, 1) where
( (cid:98)Gn, (cid:98)Hn) are minimizers in (2.13) is unique. If for instance the eigenspace corresponding to the
largest eigenvalue was of dimension bigger than one, then clearly (cid:98)L(:, 1) would not be uniquely
deﬁned. The following lemma shows that the deﬁnition of (cid:98)Gn is unique and derives its limit.

33

To simplify notation a bit, we write shorthand Rn for RFn and likewise for other expressions.

Lemma 4 Under sequences λn,h from Λn in (A.20) based on the parameter space FAKP,an, wp1
the deﬁnition of (cid:98)Gn ∈ (cid:60)p×p and (cid:98)Hn ∈ (cid:60)k×k in (2.16) is unique and

(cid:98)Gn → lim
n→∞

Gn and (cid:98)Hn → lim
n→∞

Hn a.s.,

where Hn = (EFnZiZ

(cid:48)
i)−1/2H n(EFnZiZ

(cid:48)
i)−1/2 is deﬁned in (2.12).

Comment. Note that under sequences λn,h, limn→∞ Gn and limn→∞ Hn do exist. On the
other hand, the matrices Gn and Hn may not be uniquely pinned down by the restrictions in (2.5)
in FAKP,an. The results (cid:98)Gn → limn→∞ Gn and (cid:98)Hn → limn→∞ Hn a.s. hold for any possible choice
of Gn and Hn.

Proof of Lemma 4. Recall the deﬁnition

Rn = (Ip ⊗ (EFnZiZ

(cid:48)
i)−1/2)EFn(vec(ZiU (cid:48)

i )(vec(ZiU (cid:48)

i ))(cid:48))(Ip ⊗ (EFnZiZ

(cid:48)
i)−1/2)

(A.25)

in (2.10). By Theorem 1 in van Loan and Pitsianis (1993),

||A − B ⊗ C|| = ||R(A) − vec(B)vec(C)(cid:48)||

(A.26)

for any conformable matrices A, B, and C. Thus, for

Υn := (Ip ⊗ (EFnZiZ

(cid:48)
i)−1/2)Υn(Ip ⊗ (EFnZiZ

(cid:48)
i)−1/2),

(A.27)

(cid:48)
i)−1/2), κmin(Gn), and
it follows that R(Rn − Υn) = vec(Gn)vec(Hn)(cid:48) and because κmin(EFnZiZ
κmin(H n) ≥ δ2 in FAKP,an, it follows that R(Rn−Υn) has rank 1. It follows also that limn→∞ R(Rn−
Υn) = limn→∞ R(Rn) (which exists under sequences λn,h) has rank 1 (even though the rank of
R(Rn) could be larger than 1 for every n). By continuity of the singular values and because
the geometric and algebraic multiplicity coincide for diagonalizable matrices, the dimension of the
eigenspace of R(Rn)R(Rn)(cid:48) corresponding to the largest singular value of R(Rn) is one for all n
large enough.

By the uniform moment restrictions in (2.5) in FAKP,an, namely EF (||Ti||2+δ1) ≤ B < ∞, for
(cid:48)
i)) ≥ δ2 > 0, a strong law of large numbers implies

(cid:48)
i)} and κmin(EF (ZiZ

i ), vec(ZiZ

Ti ∈ {vec(ZiU (cid:48)
that

(cid:98)Rn − Rn → 0kp×kp and R( (cid:98)Rn) − R(Rn) → 0pp×kk a.s.

(A.28)

Therefore, the dimension of the eigenspace of R( (cid:98)Rn)R( (cid:98)Rn)(cid:48) corresponding to the largest singular
value of R( (cid:98)Rn) is one for all n large enough wp1.

By the uniqueness statement of Lemma 2 for the rank 1 case, it follows that the formula for

minimizers of the KP approximation problem in (2.13) given in van Loan and Pitsianis (1993,

34

Corollary 2 and Theorem 11), namely

vec( (cid:98)Gn) = (cid:98)σ1 (cid:98)L(:, 1) and vec( (cid:98)Hn) = (cid:98)N (:, 1),

(A.29)

yields symmetric pd matrices (cid:98)Gn and (cid:98)Hn. When applying Theorem 11, note that (cid:98)Rn > 0 for all
large enough n wp1, which holds by (A.28), limn→∞ Gn ⊗ Hn = limn→∞ Rn − Υn = limn→∞ Rn,
(cid:48)
i)−1/2), κmin(Gn), and κmin(H n) ≥ δ2 in FAKP,an. Given that (cid:98)Gn > 0,
and because κmin(EFnZiZ
Sylvester’s criterion for positive deﬁniteness implies that (cid:98)L(1, 1) > 0 for all large enough n wp1, and
we can therefore deﬁne (cid:98)Gn and (cid:98)Hn as in (2.16) with normalization to 1 of the upper left element
of (cid:98)Gn for all large enough n wp1.

Next we apply Lemma 3 with a = 1 and the roles of Rn and R in Lemma 3 played by R( (cid:98)Rn)

and limn→∞ R(Rn), respectively. By (A.28), the lemma implies

(cid:98)L(:, j)(cid:48)L1 = o(1)

(A.30)

wp1.
for j > 1, where (cid:98)L(:, j) denotes the j-th column of (cid:98)L in the singular value decomposition
(cid:98)L(cid:48)R( (cid:98)Rn) (cid:98)N = diag((cid:98)σl) of R( (cid:98)Rn) and L1 denotes the ﬁrst column of L in the singular value decom-
(cid:48)
R(limn→∞ R(Rn))N = diag(σl) of limn→∞ R(Rn). For any orthogonal basis (x1, ..., xp2)
position L
of (cid:60)p2 and y ∈ (cid:60)p2 we have y = (cid:80)p2
1 (cid:98)L(:, j))(cid:98)L(:
, j) = (L(cid:48)
1 (cid:98)L(:, 1))(cid:98)L(:, 1) + o(1) wp1., where the second equality holds by (A.30). Together with the
normalization of the upper left elements of (cid:98)Gn and Gn to 1, this implies (cid:98)Gn − Gn → 0p×p a.s. and
(cid:98)Hn − Hn → 0k×k a.s. follows analogously. (cid:3)

j=1(y(cid:48)xj)xj. In particular, we have L1 = (cid:80)p2

j=1(L(cid:48)

An analogue to Lemma 16.4 in AG and Lemma 1 in GKM19 is given by the following statement.

Deﬁne

Denote by vec−1
matrix.

k,mW

(cid:98)Dn := (Z

(cid:48)

Z)−1Z

(cid:48) (cid:0)Y 0, W (cid:1) and (cid:98)Qn := (cid:98)H −1/2

n

(n−1Z

(cid:48)

Z)1/2.20

(A.31)

(·) the inverse vec operation that transforms a kmW vector into a k × mW

Lemma 5 Under sequences {λn,h : n ≥ 1} with λn,h ∈ Λn in (A.20) based on the parameter space
FAKP,an, n1/2( (cid:98)Dn − (ΠW nγn, ΠW n)) →d Dh, where

Dh ∼ h−1

4 (ξ1,h, vec−1

k,mW

(ξ2,h)),

ξ1,h and ξ2,h are deﬁned in (A.23), and again h4 is the limit of λ4,n = EFnZiZ
have (cid:98)Qn − Qn →p 0k×k.

(cid:48)
i. Furthermore, we

35

Proof of Lemma 5. We have

(cid:48)

(cid:48)

n1/2( (cid:98)Dn − (ΠW nγn, ΠW n))
=n1/2((Z
Z)−1Z
Z)−1Z
=n1/2((Z
(cid:48)
Z)−1[n−1/2Z
=(n−1Z

(cid:48)

(cid:48)

(cid:48)

(y − Y β0, W ) − (ΠW nγn, ΠW n))

(ZΠW nγn + VW γn + ε, ZΠW n + VW ) − (ΠW nγn, ΠW n))

(VW γn + ε, VW )] →d Dh,

(A.32)

where the ﬁrst equality uses the deﬁnition of (cid:98)Dn in (A.31), the second equality uses the formulas
in (2.1), and the convergence results holds by the (triangular array) CLT and WLLN in (A.23).
The remaining statement holds by the WLLN in (A.23) and the consistency of (cid:98)Hn for Hn proven
above. (cid:3)

For notational convenience, write

(cid:98)Un := (cid:98)G−1/2

n

.

(A.33)

n (cid:98)Q(cid:48)

n (cid:98)Qn (cid:98)Dn (cid:98)Un equals n−1 (cid:98)G−1/2

(cid:98)G−1/2
Note that the matrix n (cid:98)Un (cid:98)D(cid:48)
Z (cid:98)H −1
which
n
appears in (2.18). Thus, (cid:98)κin for i = 1, ..., p equals the ith eigenvalue of n (cid:98)U (cid:48)
n (cid:98)Qn (cid:98)Dn (cid:98)Un, ordered
nonincreasingly, and (cid:98)κpn is the subvector ARAKP test statistic. To describe the limiting distribution
of ((cid:98)κ1n, ..., (cid:98)κpn) we need additional notation, namely:

n Z(cid:48) (cid:0)Y 0, W (cid:1)
n (cid:98)Q(cid:48)
n (cid:98)D(cid:48)

(cid:0)Y 0, W (cid:1)(cid:48)

n

h2 = (h2,q, h2,p−q), h3 = (h3,q, h3,k−q),

h(cid:5)
1,p−q : =






0q×(p−q)
Diag{h1,q+1, ..., h1,p−1, 0}
0(k−p)×(p−q)


∈ (cid:60)k×(p−q),


∆h : = (∆h,q, ∆h,p−q) ∈ (cid:60)k×p, ∆h,q := h3,q ∈ (cid:60)k×q,

∆h,p−q := h3h(cid:5)

1,p−q + h6Dhh7h2,p−q ∈ (cid:60)k×(p−q),

(A.34)

where h2,q ∈ (cid:60)p×q, h2,p−q ∈ (cid:60)p×(p−q), h3,q ∈ (cid:60)k×q, h3,k−q ∈ (cid:60)k×(k−q), ∆h,q ∈ (cid:60)k×q, and ∆h,p−q ∈
(cid:60)k×(p−q).21 Let Tn := BFnSn and Sn := Diag{(n1/2τ1Fn)−1, ..., (n1/2τqFn)−1, 1, ..., 1} ∈ (cid:60)p×p.
The same proof as the one of Lemma 16.4 in AG shows that n1/2QFn (cid:98)DnUFnTn →d ∆h under all
sequences {λn,h : n ≥ 1} with λn,h ∈ Λ. The following proposition is an analogue to Proposition
16.5 in AG and to Proposition 2 in GKM19.

Proposition 5 Under all sequences {λn,h : n ≥ 1} with λn,h ∈ Λn,

(a) (cid:98)κjn →p ∞ for all j ≤ q,
(b) the (ordered) vector of the smallest p − q eigenvalues of n (cid:98)U (cid:48)

(cid:98)κpn)(cid:48), converges in distribution to the (ordered) p−q vector of the eigenvalues of ∆
(cid:60)(p−q)×(p−q),

n (cid:98)D(cid:48)

n (cid:98)Qn (cid:98)Qn (cid:98)Dn (cid:98)Un, i.e., ((cid:98)κ(q+1)n, ...,

(cid:48)
h,p−qh3,k−qh(cid:48)

3,k−q∆h,p−q ∈

(c) the convergence in parts (a) and (b) holds jointly with the convergence in Lemma 5, and

21There is some abuse of notation here. For example, h2,q and h2,p−q denote diﬀerent matrices even if p − q equals

q.

36

(d) under all subsequences {wn} and all sequences {λwn,h : n ≥ 1} with λwn,h ∈ Λn, the results

in parts (a)-(c) hold with n replaced with wn.

Comments. 1. The proof of the proposition follows from the proof of Proposition 16.5 in AG.

Note that Assumption WU in AG (assumed in their Proposition 16.5) is fulﬁlled with the roles
of W2F , WF , U2F , and UF in AG played here by QF , QF , UF , and UF , respectively, while the
roles of W1 and U1 in AG are played by the identity function. The roles of (cid:99)W2n and (cid:99)Wn in AG
are both played by (cid:98)Qn and those of both (cid:98)U2n and (cid:98)Un by (cid:98)Un. Lemma 5 then shows consistency
(cid:99)W2n − W2Fn →p 0k×k and (cid:98)U2n − U2Fn →p 0p×p under sequences {λn,h : n ≥ 1} with λn,h ∈ Λn
and trivially the functions W1 and U1 are continuous in our case. Note that by the restrictions
in FAKP,an in (2.5) the requirements in the parameter space FW U in AG, namely “κmin(QF ) and
κmin(UF ) are uniformly bounded away from zero and ||QF || and ||UF || are uniformly bounded away
from inﬁnity”, are fulﬁlled. For example, the former follows because κmin(QF ) = 1/κmax(Q−1
F ) =
(cid:48)
1/κmax((EF ZiZ

i)−1/2H 1/2
2. Proposition 5 yields the desired joint limiting distribution of the p eigenvalues in (2.18).
Using repeatedly the general formula (C(cid:48) ⊗ A)vec(B) = vec(ABC) for three conformable matrices
A, B, C, we have for the expression h6Dhh7 that appears in ∆h,p−q

F ) is uniformly bounded.

F ) and κmax((EF ZiZ

i)−1/2H 1/2

(cid:48)

vec(h6Dhh7) = vec(h6h−1

4 (ξ1,h, vec−1

k,mW

(ξ2,h))h7) = (h7 ⊗ (h4h−1

6 )−1)

(cid:33)

(cid:32)

ξ1,h
ξ2,h

∼vec(v1, ..., vp),

(A.35)

where, by deﬁnition, vj, j = 1, ..., p are i.i.d. normal k-vectors with zero mean and covariance
matrix Ik, and the distributional statement follows by straightforward calculations using (A.23).
Therefore, by Lemma 5, the deﬁnition of ∆h,p−q in (A.34), and by noting that

3,k−qh3h(cid:5)
h(cid:48)

1,p−q =

(cid:32)

Diag{h1,q+1, ..., h1,p−1, 0}
0(k−p)×(p−q)

(cid:33)

(A.36)

we obtain

h(cid:48)
3,k−q∆h,p−q =

∼

(cid:32)

(cid:32)

Diag{h1,q+1, ..., h1,p−1, 0}
0(k−p)×(p−q)

Diag{h1,q+1, ..., h1,p−1, 0}
0(k−p)×(p−q)

(cid:33)

(cid:33)

+ h(cid:48)

3,k−q(v1, ..., vp)h2,p−q

+ (w1, ..., wp−q),

(A.37)

where, by deﬁnition, wj, j = 1, ..., p−q are i.i.d. normal (k−q)-vectors with zero mean and covariance
matrix Ik−q. The distributional equivalence in the second line holds because (v1, ..., vp)h2,p−q ∼
((cid:101)v1, ..., (cid:101)vp−q), where (cid:101)vj, j = 1, ..., p − q are i.i.d. N (0k, Ik) as h2,p−q has orthogonal columns of
length 1. Analogously, h(cid:48)
3,k−q((cid:101)v1, ..., (cid:101)vp−q) ∼ (w1, ..., wp−q) because h3,k−q has orthogonal columns
of length 1.

37

3,k−q∆h,p−q = w1 ∈ (cid:60)k−mW . Therefore ∆

For example, when q = p−1 = mW (which could be called the ”strong IV” case), we obtain from
(cid:48)
h,p−qh3,k−qh(cid:48)
and thus by

(A.37) h(cid:48)
part (b) of Proposition 5 the limiting distribution of the subvector ARAKP test statistic is χ2
in that case, while all the larger roots in (2.18) converge in probability to inﬁnity by part (a).

3,k−q∆h,p−q ∼ χ2

k−mW

k−mW

Proof of Theorem 1. Given the discussion in Comment 2 to Proposition 5, the same proof

as for Theorem 5 in GKM19 applies. (cid:3)

A.2 Proof of Theorem 2

Proof of Theorem 2. It is enough to verify Proposition 4 above for the parameter space FHet
and the test ϕM S−AKP,α. To verify Assumption B in ACG consider a sequence λwn,h deﬁned as in
(A.19) and (A.21) above except that the component

λ9wn := min ||R−1/2
Fwn

(G ⊗ H − RFwn )R−1/2
Fwn

||/cwn

(A.38)

is added to λwn, where the minimum (here and in similar expressions below) is taken over (G, H) for
G ∈ (cid:60)p×p, H ∈ (cid:60)k×k being pd, symmetric matrices, normalized such that the upper left element of
G equals 1. In (A.20), we replace FAKP,awn by FHet and deﬁne hwn(λF ) := (w1/2
n λ1,F , λ2,F , λ3,F , . . . ,
λ7,F , w1/2

n λ9,F ). To simplify notation, we write n instead of wn from now on.

Consider ﬁrst a sequence λn,h with h9 = ∞. By Assumption MS, ϕM S,cn = 1 wpa1 and therefore,
ϕM S−AKP,α = ϕRob,α−δ wpa1. Thus, the new test ϕM S−AKP,α has limiting NRP bounded by α − δ
in that case because ϕRob,α−δ has asymptotic size bounded by its nominal size by Assumption RT
.

Fn

(G ⊗ H − RFn)R−1/2

Second, consider a sequence λn,h with h9 ∈ [0, ∞). In that case, n1/2/cn → ∞ implies that
min ||R−1/2
|| → 0. By submultiplicativity of the Frobenius norm and ||R1/2
||
Fn
being uniformly bounded in FHet it then follows that min ||G ⊗ H − RFn|| → 0. That is, the
covariance matrix RFn has AKP structure. Therefore, also the covariance matrix RFn has AKP
structure. By the proof of Theorem 1 the test ϕAKP,α then has limiting NRP bounded by α under
sequences λn,h with h9 ∈ [0, ∞). It therefore follows that

Fn

lim sup
n→∞

Pλn,h(ϕM S−AKP,α = 1)

≤ lim sup
n→∞

= lim sup
n→∞

Pλn,h(max{ϕRob,α−δ, ϕAKP,α} = 1)

Pλn,h(ϕAKP,α = 1) ≤ α,

(A.39)

where the equality uses Assumption RP, Pλn,h(ϕRob,α−δ ≤ ϕAKP,α) → 1, which implies that
Pλn,h((max{ϕRob,α−δ, ϕAKP,α} = 1) ∩ (ϕRob,α−δ > ϕAKP,α)) → 0 and the last inequality follows
from the fact that the limiting NRP of the test ϕAKP,α is bounded by α.

This establishes Proposition 4 with suph∈H RP +(h) ≤ α and thus Theorem 2.

38

To prove Comment 1 below Theorem 2, note that by the assumed continuity,

lim
δ→0

lim inf
n→∞

inf
(γ,ΠW ,ΠY ,F )∈FHet

E(γ,ΠW ,ΠY ,F )ϕM S−AKP,δ,cn,α

= lim inf
n→∞

inf
(γ,ΠW ,ΠY ,F )∈FHet

E(γ,ΠW ,ΠY ,F )ϕM S−AKP,0,cn,α.

(A.40)

But note that

lim inf
n→∞

inf
(γ,ΠW ,ΠY ,F )∈FHet

E(γ,ΠW ,ΠY ,F )ϕM S−AKP,0,cn,α

E(γn,ΠW n,ΠY n,Fn)ϕM S−AKP,0,cn,α

=lim inf
n→∞
E(γwn ,ΠW wn ,ΠY wn ,Fwn )ϕM S−AKP,0,cwn ,α

= lim
n→∞

= lim
n→∞

Eλwn,hϕM S−AKP,0,cwn ,α,

(A.41)

where in the ﬁrst equality (γn, ΠW n, ΠY n, Fn) ∈ FHet is chosen such that inf (γ,ΠW ,ΠY ,F )∈FHet
E(γ,ΠW ,ΠY ,F )ϕM S−AKP,0,cn,α ≥ E(γn,ΠW n,ΠY n,Fn)ϕM S−AKP,0,cn,α − n−1, in the second equality a
subsequence {wn} of {n} can be found, and in the third equality {wn} may denote a further sub-
sequence along which (γwn, ΠW wn, ΠY wn, Fwn) is of type λwn,h for some h. (We are allowing here
for the possibility that Eλwn,hϕM S−AKP,δ,cwn ,α may depend on the particular sequence λwn,h rather
than just h.) If h9 = ∞ then ϕM S−AKP,0,cwn ,α = ϕRob,α wpa1 by Assumption MS and

lim
n→∞

Eλwn,hϕRob,α ≥ lim inf
n→∞

inf
(γ,ΠW ,ΠY ,F )∈FHet

E(γ,ΠW ,ΠY ,F )ϕRob,α.

(A.42)

On the other hand, if h9 < ∞ then by Assumption RP, ϕRob,α ≤ ϕAKP,α wpa1 and

lim
n→∞

Eλwn,hϕM S−AKP,0,cwn ,α ≥ lim
n→∞

Eλwn,hϕRob,α

(A.43)

and the desired conclusion then follows as in (A.42). (cid:3)

A.3 Assumption MS for the model selection method ϕM S,cn

Here we verify Assumption MS for the two suggested methods for ϕM S,cn.

Method 1, deﬁned as I( (cid:98)Kn > cn) : To simplify notation we write again n instead of wn and

subscripts Fn as n. Consider a sequence λn,h with h9 = ∞. Rewrite

(cid:98)Kn/cn = n1/2|| (cid:98)R−1/2

n

( (cid:98)Gn ⊗ (cid:98)Hn − Rn + (Rn − (cid:98)Rn)) (cid:98)R−1/2

n

||/cn.

(A.44)

In the proof of Lemma 4 we use the uniform moment restrictions in (2.5) in FAKP,an to obtain (cid:98)Rn −
Rn = op(1); here the stronger uniform moment condition EF ((||Zi||2||Ui||2)2+δ1) ≤ B allows the
application of a Lyapunov CLT and to establish that n1/2( (cid:98)Rn−Rn) = Op(1). Because by assumption

39

κmin(RFn) ≥ δ2 in FHet, we thus have n1/2 (cid:98)R−1/2

n

(Rn − (cid:98)Rn) (cid:98)R−1/2

n

/cn = op(1). Furthermore,

n1/2||R−1/2

n

( (cid:98)Gn ⊗ (cid:98)Hn − Rn)R−1/2

n

||/cn ≥ n1/2λ9n → h9 = ∞,

(A.45)

where the inequality holds by the deﬁnition of λ9n in (3.2). Because (cid:98)R1/2
are continuous, it thus follows that (cid:98)Kn/cn > 1 wpa1.

n R−1/2

n →p Ikp and norms

Method 2: The desired result is obtained using Theorem 3 in GKM22.

A.4 Proofs of Results Involving the AR/AR test

Proof of Lemma 1. Assumption RT is satisﬁed by the AR/AR test by Theorem 8.1 in Andrews
(2017) noting that the parameter space FAR/AR in Andrews (2017, (8.8)) contains the parameter
In particular, note that ξ1i deﬁned in (8.2) in Andrews (2017),
space FHet deﬁned in (3.24).
equals 0 in the linear IV model considered here and therefore the condition in (8.8) EF ξ2
1i being
bounded holds trivially. Also, Assumption W in Andrews (2017) holds with the choice (cid:99)W1n =
(n−1(cid:80)n

(cid:48)
i)−1 considered here.

i=1ZiZ

Assumption RP is veriﬁed by the following argument that uses Lemma 6 below. To simplify

notation we write n instead of wn. Let (cid:98)γn be an element in arg min

(cid:101)γ∈RmW HARn (β0, (cid:101)γ) .

1n, deﬁned in (3.15). Then, in particular, it must be that

Consider ﬁrst the case where (cid:98)γn /∈ CS+

HARn (β0, (cid:98)γn) > χ2

k,1−α1

. We obtain

ARAKP (β0) − c1−α (ˆκ1n, k − mW )
k,1−α1 + (χ2
= HARn (β0, (cid:98)γn) − χ2

k,1−α1 − c1−α (ˆκ1n, k − mW )) + (cid:101)Bn + op (1) ,

(A.46)

where the equality follows from Lemma 6. But χ2
ter what value ˆκ1n takes on. Given mW ≥ 1 and α1 < α we have that χ2
k,1−α1
(cid:15) wp1 for some (cid:15) > 0. Because (cid:101)Bn ≥ 0 it follows from HARn (β0, (cid:98)γn) > χ2
c1−α (ˆκ1n, k − mW ) wpa1. In other words, the conditional subvector ARAKP test rejects wpa1.

k−mw,1−α ≥ c1−α (ˆκ1n, k − mW ) no mat-
−c1−α (ˆκ1n, k − mW ) >
that ARAKP (β0) >

> χ2

k,1−α1

k,1−α1

Consider second the case where (cid:98)γn ∈ CS+
(cid:101)γ∈CS+

inf
by (3.18). Therefore, in particular for (cid:98)γn ∈ CS+

(HARβ,n (β0, (cid:101)γ) − χ2

1n

1n

1n. Recall the rejection condition of the test ϕAR/AR,α−δ,α1,

k−mW ,1−α2,n(β0,(cid:101)γ)) > 0. For any (cid:101)γ ∈ CS+

1n, we have α2,n(β0, (cid:101)γ) ≤ α − δ

χ2
k−mW ,1−α2,n(β0,(cid:98)γn) > χ2

k−mw,1−α + (cid:15) ≥ c1−α (ˆκ1n, k − mW ) + (cid:15)

(A.47)

for some (cid:15) > 0. We thus obtain that

ARAKP,n(β0) − c1−α (ˆκ1n, k − mW )
> HARn (β0, (cid:98)γn) − χ2
≥ HARβ,n (β0, (cid:98)γn) − χ2
≥ min
(cid:101)γ∈CS+

(HARβ,n (β0, (cid:101)γ) − χ2

1n

k−mW ,1−α2,n(β0,(cid:98)γn) + (cid:15) + (cid:101)Bn + op (1)
k−mW ,1−α2,n(β0,(cid:98)γn) + (cid:15) + (cid:101)Bn + op (1)

k−mW ,1−α2,n(β0,(cid:101)γ)) + (cid:15) + (cid:101)Bn + op (1) ,

(A.48)

40

where the ﬁrst inequality follows from Lemma 6 and (A.47), the second inequality follows from
HARn (β0, (cid:101)γ) ≥ HARβ,n (β0, (cid:101)γ) for any (β0, (cid:101)γ) because M ˜Dn(β0,(cid:101)γ)+an−1/2ζ1
trix, and the last inequality follows because (cid:98)γn ∈ CS+
(HARβ,n (β0, (cid:101)γ)−χ2
> 0 wpa1.22

k−mW ,1−α2,n(β0,(cid:101)γ)) > 0, it must also be true that ARAKP,n(β0)−c1−α (ˆκ1n, k − mW )

1n. Thus, if ϕAR/AR,α−δ,α1 = 1 and min

is a projection ma-

(cid:101)γ∈CS+

1n

The inequalities in (A.47) and (A.48) immediately imply the desired result

Pλwn,h(ϕRob,α−δ ≤ ϕAKP,α)
= Pλwn,h((ϕRob,α−δ ≤ ϕAKP,α) ∩ ((cid:98)γn ∈ CS+
→ 1.

1n)) + Pλwn,h((ϕRob,α−δ ≤ ϕAKP,α) ∩ ((cid:98)γn /∈ CS+

1n))
(A.49)

(cid:3)

Recall that (cid:98)γwn is an element in arg min

(cid:101)γ∈RmW HARwn (β0, (cid:101)γ) and γ+

wn is an element in

arg min

(cid:101)γ∈RmW (cid:103)ARAKP,wn(β0, (cid:101)γ).

Lemma 6 Consider a sequence λwn,h (of reparameterized elements in FHet) with h9 < ∞ (that is,
wn = Op(1) and ΠW wnw1/2
a sequence of AKP structure). If γ+
wn − γwn) = Op(1) then along λwn,h

n (γ+

ARAKP,wn(β0) = HARwn (β0, (cid:98)γwn) + (cid:101)Bwn + op (1)

for some random sequence (cid:101)Bwn that is nonnegative wp1.

Proof. To simplify notation we write n instead of wn. Recall from (3.13)

HARn (β0, (cid:101)γ) =n(cid:98)gn (β0, (cid:101)γ)(cid:48) ˆΣn (β0, (cid:101)γ)−1
(cid:18) 1
−(cid:101)γ

(cid:0)Y 0, W (cid:1)(cid:48)

(cid:98)gn (β0, (cid:101)γ)
Z ˆΣn (β0, (cid:101)γ)−1 Z

=n

(cid:19)(cid:48)

(cid:48) (cid:0)Y 0, W (cid:1)

(cid:19)
.

(cid:18) 1
−(cid:101)γ

(A.50)

Deﬁning b+

n := (1, −β(cid:48)

0, −γ+(cid:48)

n )(cid:48) it follows that under the null

Y 0i −W (cid:48)

i γ+

n = yi −Y (cid:48)

i β0 −W (cid:48)

i γ+

n = vy,i −V (cid:48)

Y,iβ0 −V (cid:48)

W,iγ+

n +Z

(cid:48)
iΠW n(γ −γ+

n ) = V (cid:48)

i b+

n +Z

Deﬁne

ξin := ZiZ

(cid:48)
iΠW n(γ − γ+

n ) ∈ (cid:60)k and ξn := n−1(cid:80)n

i=1ξin.

(cid:48)
iΠW n(γ −γ+

n ).
(A.51)

(A.52)

22Note that it is this derivation that necessitates using ϕRob,α−δ rather than the more powerful ϕRob,α in the
deﬁnition of ϕM S−AKP,δ,cn,α. The term (cid:101)Bn might go to zero and the op (1) term could be negative and dominate and
therefore, without the (cid:15) > 0 term we would not be able to obtain a strict inequality between the ﬁrst and second line
of (A.48) and thus not be able to show that ϕRob,α ≤ ϕAKP,α holds wpa1 under all drifting sequences. Under weak
identiﬁcation we would still be able to do so; namely, if q = qh = 0, see (A.24) above then Proposition 5(b) implies
that (cid:98)κ1n = Op(1) and given that the critical values c1−α (ˆκ1n, k − mW ) obtained by linear interpolation from the
tables in the Appendix of GKM19 are strictly increasing in (cid:98)κ1n with c1−α (ˆκ1n, k − mW ) → χ2
k−mw ,1−α as ˆκ1n → ∞
it follows that there is a γ > 0 such that χ2
k−mw ,1−α ≥ c1−α (ˆκ1n, k − mW ) + γ wpa1. Then, (A.48) implies that
ϕRob,α ≤ ϕAKP,α holds wpa1. But that argument does not go through when q = qh ≥ 1.

41

We then have

(cid:1)

n ˆΣn
=(cid:80)n

(cid:0)β0, γ+
(cid:104)
Zi(Y 0i − W (cid:48)

n

i=1
i=1(Y 0i − W (cid:48)
(cid:20)
(cid:0)V (cid:48)

i b+
n

i=1

i γ+
(cid:1)2 + 2(V (cid:48)

=(cid:80)n

=(cid:80)n

i γ+
n )2ZiZ

n ) − Z
(cid:48)
i − Z

(cid:48) (cid:0)Y 0 − W γ+

n

(cid:1) /n

(cid:105) (cid:104)

Zi(Y 0i − W (cid:48)

i γ+

n ) − Z

(cid:48) (cid:0)Y 0 − W γ+

n

(cid:1) /n

(cid:105)(cid:48)

(cid:48) (cid:0)Y 0 − W γ+

n

(cid:1) (cid:0)Y 0 − W γ+

n

(cid:1)(cid:48)

Z/n

(cid:48)
iΠW n(γ − γ+

n )) +

(cid:16)

Z

(cid:48)
iΠW n(γ − γ+
n )

(cid:17)2(cid:21)

ZiZ

(cid:48)
i

i b+

n Z

(cid:48)

(cid:48)

n V (cid:48)Z + 2Z
n b+(cid:48)
V b+
− (Z
(cid:1)2 ZiZ
(cid:0)V (cid:48)
(cid:48)
=(cid:80)n
i b+
n
i=1
+ 2(cid:80)n
i b+
i=1(V (cid:48)
n Z
(cid:1)2 ZiZ
(cid:0)V (cid:48)
=(cid:80)n
i b+
n

V b+
i + (cid:80)n
i=1
(cid:48)
iΠW n(γ − γ+

n (γ − γ+

n )(cid:48)Π(cid:48)
(cid:0)ξin − ξn
n ))ZiZ

(cid:48)
i + Op(n1/2),

i=1

(cid:48)

Z + Z
W nZ
(cid:1)(cid:48)
(cid:1) (cid:0)ξin − ξn
V b+

(cid:48)

(cid:48)
i − 2Z

(cid:48)

ZΠW n(γ − γ+

n )(γ − γ+

n )(cid:48)Π(cid:48)

W nZ

(cid:48)

Z)/n

n (γ − γ+

n )(cid:48)Π(cid:48)

W nZ

(cid:48)

Z/n − Z

(cid:48)

V b+

n b+(cid:48)

n V (cid:48)Z/n

(A.53)

where for the third equality we use (A.51) and Z

n ), in the
ﬁfth equality we apply a WLLN or a Lyapunov CLT theorem for each of the last three summands in

n + Z

ZΠW n(γ − γ+

V b+

n

(cid:48) (cid:0)Y 0 − W γ+

(cid:1) = Z

(cid:48)

(cid:48)

the second to last line and the second summand in the third to last line which hold by the moment
conditions imposed in the parameter space FHet in (3.24). In particular, using γ+
n = Op(1) and
ΠW nn1/2(γ+
n − γn) = Op(1), the ﬁrst summand in the second to last line is Op(n1/2) while the other
summands are Op(1).

The ﬁrst summand in the last line of (A.53) can be expanded as follows after normalization by

n−1.

(cid:0)V (cid:48)

n−1(cid:80)n
= (cid:0)b+

i=1
n ⊗ Ik

(cid:48)
i

(cid:1)2 ZiZ
i b+
n
(cid:1)(cid:48) n−1(cid:80)n
(cid:19)(cid:48)
(cid:19)

i=1

=

(cid:18)(cid:18) 1

−γ+
n

⊗ Ik

n−1(cid:80)n

i=1

(cid:0)Vi ⊗ Zi

(cid:124)

(cid:1) (cid:0)Vi ⊗ Zi
(cid:18)(cid:18)vyi − V (cid:48)
VW i

(cid:1)(cid:48) (cid:0)b+
n ⊗ Ik
(cid:19)

Y iβ0

(cid:1)

(cid:19) (cid:18)(cid:18)vyi − V (cid:48)
VW i

Y iβ0

(cid:19)

⊗ Zi

(cid:19)(cid:48)

(cid:18)(cid:18) 1

(cid:19)

−γ+
n

(cid:125)

(cid:19)

⊗ Ik

.

⊗ Zi

(cid:123)(cid:122)
=: (cid:98)RFn

When β0 = β (which is assumed here) we have

(cid:98)RFn = EFn(vec(ZiU (cid:48)

i )(vec(ZiU (cid:48)

i ))(cid:48)) + op(1) = GFn ⊗ H Fn + Υn + op(1),

(A.54)

for some Υn = o(1), where the ﬁrst equality holds by a WLLN and the second one holds by the
assumption that n1/2λ9n → h9 < ∞ and the argument given in the Proof of Theorem 2 that
establishes that RFn has AKP structure.

42

Therefore, by (3.21)

(cid:0)β0, γ+
ˆΣn
n
= n−1(cid:80)n

(cid:1)

(cid:1) − (cid:101)Σ (cid:0)β0, γ+
(cid:1)2 ZiZ
i b+
n

(cid:0)V (cid:48)

n

i=1

(cid:48)

i − ((cid:0)1, −γ+(cid:48)

n

(cid:1)

(cid:98)Gn

(cid:0)1, −γ+(cid:48)
n

(cid:1)(cid:48)) ⊗ (n−1Z

(cid:48)

Z)1/2 (cid:98)Hn(n−1Z

(cid:48)

Z)1/2 + op(1)

= op (1) ,

(A.55)

where the last line follows from γ+

n = Op(1), A.54, a WLLN, and Lemma 4. Therefore,

HARn

(cid:0)β0, γ+

n

(cid:1) = n(cid:98)g (cid:0)β0, γ+

n

(cid:1)(cid:48) (cid:104)

(cid:101)Σ (cid:0)β0, γ+

n

(cid:1) + op (1)

(cid:105)−1

(cid:98)g (cid:0)β0, γ+

n

(cid:1) = (cid:103)ARAKP,n(β0, γ+

n ) + op(1),

where we use positive deﬁniteness of (cid:101)Σ (β0, γ+
(cid:48)
on EF (Z
iZi), GF , and H F in (2.5).
By deﬁnition of (cid:98)γn, HARn (β0, γ+

(cid:103)ARAKP,n(β0, γ+

n ). Thus, by (A.56)

(A.56)
n ) in the last equality which holds by the restrictions

n ) ≥ HARn (β0, (cid:98)γn). By deﬁnition of γ+

n , ARAKP,n(β0) =

ARAKP,n(β0) =HARn

(cid:0)β0, γ+

n

(cid:1) + op(1) ≥ HARn (β0, (cid:98)γn) + op(1),

(A.57)

which is the desired result. (cid:3)

A.5 Time series case

In this section we drop Assumption B and allow for a stationary time series setup. In the time
i )(cid:48) : i = ..., 0, 1, ...}.

series case, F denotes the distribution of the stationary inﬁnite sequence {(Z
W,iγ, V (cid:48)
Recall the deﬁnition Ui := (εi + V (cid:48)

W,i)(cid:48) and deﬁne

(cid:48)
i, V (cid:48)

RF,n := V arF

(cid:16)

n−1/2(cid:80)n

i=1vec(ZiU (cid:48)
i )

(cid:17)

.

(A.58)

Consider again a sequence an = o(1) in (cid:60)≥0. The parameter space is given by

FT S,AKP,an : = {(γ, ΠW , ΠY , F ) : γ ∈ (cid:60)mW , ΠW ∈ (cid:60)k×mW , ΠY ∈ (cid:60)k×mY , {(Zi, Vi) : i = ..., 0, 1, ...}
are stationary and strong mixing under F with strong mixing numbers
{αF (m) : m ≥ 1} that satisfy αF (m) ≤ Cm−d,
i ) = 0k×(m+1), RF,n = GF ⊗ H F + Υn,
EF (ZiV (cid:48)
i ), ||Zi||2}
EF (||Ti||2+δ) ≤ B, for Ti ∈ {vec(ZiU (cid:48)

κmin(A) ≥ δ for A ∈ {EF ZiZ

(cid:48)
i, GF , H F }}

(A.59)

for some δ > 0, d > (2+δ)/δ, B, C < ∞, for symmetric matrices Υn ∈ (cid:60)kp×kp such that ||Υn|| ≤ an,
pd symmetric matrices GF ∈ (cid:60)p×p (whose upper left element is normalized to 1) and H F ∈ (cid:60)k×k.
In the time series context, the deﬁnition of (cid:98)Rn in (2.11) is replaced by a heteroskedasticity
and autocorrelation consistent (HAC) variance matrix estimator based on {fi : i ≤ n} for RF,n :=

43

(cid:48)
i)−1/2)RF,n(Ip ⊗(EF ZiZ

(cid:48)
i)−1/2), e.g. see Newey and West (1987) and Andrews (1991).
(Ip ⊗(EF ZiZ
With this modiﬁcation, the conditional subvector ARAKP test for the time series case is then deﬁned
exactly as in (2.19). Theorem 1 then holds without Assumption B and with FAKP,an replaced by
FT S,AKP,an.

Comment. 1. The proof of the theorem in the time series case follows the exact same steps as

the proof of Theorem 1 in the i.i.d. case in the Appendix with simple modiﬁcations. In particular,
deﬁne sequences {λwn,h : n ≥ 1} as in (A.21) but with FAKP,an replaced by FT S,AKP,an in (A.20).
Then, under sequences λn,h (writing n instead of wn to simplify notation), the HAC estimator
(cid:98)Rn satisﬁes (cid:98)Rn − RF,n →p 0kp×kp and thus (cid:98)Rn →p h−2
see earlier sections for
notation. Also, the CLT in (A.23) continues to hold under the mixing conditions in FT S,AKP,an.
Then, the exact same proof as for the i.i.d. case applies.

7 ⊗ h1/2

4 h−1
6 h

(cid:48)−1
6 h1/2

4

2. Again, we obtain the corresponding result for the generalization of the subvector test in

GKMC to the time series KP structure case. This test has correct asymptotic size for the param-
eter space FT S,AKP,an and the result is obtained fully analytically; its proof does not require any
simulations.

References

Anderson, T. W. and H. Rubin (1949). Estimation of the parameters of a single equation in a

complete system of stochastic equations. Ann. Math. Statistics 20, 46–63.

Andrews, D. W. (2017). Identiﬁcation-robust subvector inference. Cowles Foundation Discussion

Papers 3005, Cowles Foundation for Research in Economics, Yale University.

Andrews, D. W. and X. Cheng (2014). Gmm estimation and uniform subvector inference with

possible identiﬁcation failure. Econometric Theory 30 (2), 287–333.

Andrews, D. W., X. Cheng, and P. Guggenberger (2020). Generic results for establishing the

asymptotic size of conﬁdence sets and tests. Journal of Econometrics 218 (2), 496–531.

Andrews, D. W. and P. Guggenberger (2019). Identiﬁcation-and singularity-robust inference for

moment condition models. Quantitative Economics 10 (4), 1703–1746.

Andrews, D. W., V. Marmer, and Z. Yu (2019). On optimal inference in the linear iv model.

Quantitative Economics 10 (2), 457–485.

Andrews, D. W. and G. Soares (2010). Inference for parameters deﬁned by moment inequalities

using generalized moment selection. Econometrica 78 (1), 119–157.

Andrews, D. W. K. (1991). Heteroskedasticity and autocorrelation consistent covariance matrix

estimation. Econometrica 59 (3), 817–858.

44

Andrews, D. W. K., M. J. Moreira, and J. H. Stock (2006). Optimal two-sided invariant similar

tests for instrumental variables regression. Econometrica 74 (3), 715–752.

Andrews, I. and A. Mikusheva (2016). A geometric approach to nonlinear econometric models.

Econometrica 84 (3), 1249–1264.

Bernanke, B. (2004). Essays on the Great Depression. Princeton University Press.

Bugni, F. A., I. A. Canay, and X. Shi (2017). Inference for subvectors and other functions of partially

identiﬁed parameters in moment inequality models. Quantitative Economics 8 (1), 1–38.

Chaudhuri, S. and E. Zivot (2011). A new method of projection-based inference in GMM with

weakly identiﬁed nuisance parameters. Journal of Econometrics 164 (2), 239–251.

Dufour, J.-M. and M. Taamouti (2005). Projection-based statistical inference in linear structural

models with possibly weak instruments. Econometrica 73 (4), 1351–1365.

Gafarov, B. (2017). Inference in high-dimensional set-identiﬁed aﬃne models.

Golub, G. H. and C. F. van Loan (1989). Matrix Computations, Volume 3. ohns Hopkins Studies

in Mathematical Sciences.

Guggenberger, P., F. Kleibergen, and S. Mavroeidis (2019). A more powerful subvector Anderson

Rubin test in linear instrumental variables regression. Quantitative Economics 10, 487–526.

Guggenberger, P., F. Kleibergen, and S. Mavroeidis (2022). A Test for Kronecker Product Structure

Covariance Matrix. Journal of Econometrics. Forthcoming.

Guggenberger, P., F. Kleibergen, S. Mavroeidis, and L. Chen (2012). On the Asymptotic Sizes of

Subset Anderson-Rubin and Lagrange Multiplier Tests in Linear Instrumental Variables Regres-

sion. Econometrica 80 (6), 2649–2666.

Guggenberger, P. and R. J. Smith (2005). Generalized empirical likelihood estimators and tests

under partial, weak, and strong identiﬁcation. Econometric Theory 21 (4), 667–709.

Hahn, J. and G. Kuersteiner (2002). Discontinuities of weak instrument limiting distributions.

Economics Letters 75 (3), 325–331.

Han, S. and A. McCloskey (2019). Estimation and inference with a (nearly) singular Jacobian.

Quantitative Economics 10 (3), 1019–1068.

Kaido, H., F. Molinari, and J. Stoye (2019). Conﬁdence intervals for projections of partially

identiﬁed parameters. Econometrica 87 (4), 1397–1432.

Kleibergen, F. (2021). Eﬃcient size correct subset inference in homoskedastic linear instrumental

variables regression. Journal of Econometrics 221 (1), 78–96.

45

Li, R.-C. (1998). Relative perturbation theory: Ii. eigenspace and singular subspace variations.

SIAM Journal on Matrix Analysis and Applications 20 (2), 471–492.

McCloskey, A. (2017). Bonferroni-based size-correction for nonstandard testing problems. Journal

of Econometrics 200 (1), 17–35.

Muirhead, R. J. (1978). Latent roots and matrix variates: a review of some asymptotic results.

The Annals of Statistics, 5–33.

Newey, W. K. and K. D. West (1987). A simple, positive semideﬁnite, heteroskedasticity and

autocorrelation consistent covariance matrix. Econometrica 55 (3), 703–708.

Sims, C. A. (1980). Macroeconomics and Reality. Econometrica 48 (1), 1–48.

Staiger, D. and J. H. Stock (1997).

Instrumental variables regression with weak instruments.

Econometrica 65, 557–586.

Stewart, G. and J.-G. Sun (1990). Matrix perturbation theory. San Diego: Academic Press, Inc..

Stock, J. H. and M. W. Watson (2018). Identiﬁcation and estimation of dynamic causal eﬀects in

macroeconomics using external instruments. The Economic Journal 128 (610), 917–948.

Stock, J. H. and J. H. Wright (2000). Gmm with weak identiﬁcation. Econometrica 68 (5), 1055–

1096.

van Loan, C. F. and N. Pitsianis (1993). Approximation with kronecker products. In Linear algebra

for large scale and real-time applications, pp. 293–314. Springer.

Wedin, P.-˚A. (1972). Perturbation bounds in connection with singular value decomposition. BIT

Numerical Mathematics 12 (1), 99–111.

46

