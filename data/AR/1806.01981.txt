8
1
0
2

n
u
J

6

]

O
C

.
t
a
t
s
[

1
v
1
8
9
1
0
.
6
0
8
1
:
v
i
X
r
a

Regenerative Simulation for the Bayesian Lasso

Y.-L. Chen & Z. I. Botev
UNSW Sydney, Australia

June 7, 2018

Abstract

The Gibbs sampler of Park and Casella is one of the most popular MCMC
methods for sampling from the posterior density of the Bayesian Lasso regression.
As with many Markov chain samplers, their Gibbs sampler lacks a theoretically
sound method of output analysis — a method for estimating the variance of a
given ergodic average and estimating how closely the chain is sampling from the
stationary distribution, that is, the burn-in.

In this paper, we address this shortcoming by identifying regenerative structure
in the sampler of Park and Casella, thus providing a theoretically sound method
of assessing its performance. The regenerative structure provides both a strongly
consistent variance estimator, and an estimator of (an upper bound on) the total
variation distance from the target posterior density. The result is a simple and
theoretically sound way to assess the stationarity of the Park and Casella and, more
generally, other MCMC samplers, for which regenerative simulation is possible.

We perform a numerical study in which we validate the standard errors calcu-
lated by our regenerative method by comparing it with the standard errors calcu-
lated by an AR(1) heuristic approximation. Thus, we show that for the Bayesian
Lasso model, the regenerative method is a viable and theoretically justiﬁed alter-
native to the existing ad-hoc MCMC convergence diagnostics.

1

Introduction

The linear Lasso regression and its Bayesian analogue are studied extensively and have
appealed to many practitioners [20]. Inference for the Bayesian Lasso requires one
to take expectations with respect to π, the posterior density. These expectations are
intractable and call for Monte Carlo statistical methods such as Markov chain Monte
Carlo (MCMC).

The idea is to construct a Markov chain {X0, . . . , Xt} starting from some (possibly
random) initial state X0, with invariant density π, so that the average of the sample path
converges to the expectation one wishes to compute. Denoting Eπh the expectation of
h with respect to π, we have under suitable conditions:

¯ht := 1
t + 1

t(cid:88)

k=0

h(Xk)

a.s.
−→ Eπh,

t → ∞.

(1)

1

 
 
 
 
 
 
One of the most popular MCMC samplers for the Bayesian Lasso is the Gibbs sampler
of Park and Casella [20]. Despite its wide use, the sampler still lacks a systematic way
to: (i) estimate the variability of the estimator ¯ht; (ii) assess how closely (in total varia-
tion distance) a state of the Markov chain follows the target posterior (this is related to
the problem of estimating the size of the burn-in of the Markov chain).

Currently one resorts to heuristic approximations to address both (i) and (ii). For
example, a popular approach to address (i) is the batch means variance estimator to
estimate the standard error of ¯ht. The batch means variance estimator requires co-
variance stationarity [15], which is diﬃcult to verify in practice. Furthermore, for the
batch means estimator to be consistent, each batch size has to diverge to inﬁnity and in
practice it is not clear how large each batch has to be.

There are many existing works that address (ii), but, roughly speaking, these ap-
proaches can be categorized into two groups. The ﬁrst approach is to analyze the
transition kernel of the Markov chain and construct a total variation distance bound
between the transition density and the invariant density (see [17, 22], for example).
Despite its theoretical soundness, this approach often requires diﬃcult or intractable
analysis.

The simpler and more popular alternative is to examine the output of the Markov
chain sampler. These approaches are known as “convergence diagnostics” in the liter-
ature, and include examining the decay of the sample autocorrelation plots [21] or run-
ning multiple chains until the chains roughly stay in the same region of the state space
(for example in the popular Bayesian inference software WinBugs). These heuristics or
rules-of-thumb mostly provide a pictorial convergence assessment and rarely a quan-
titative one.
[6] mention that “...statisticians rely heavily on
such diagnostics, if for no other reason than that a weak diagnostic is better than no
diagnostic at all.”

Indeed, Cowles et al.

In this paper, we address both problems (i) and (ii) by identifying the regenerative
structure in the output of the Park & Casella Gibbs sampler. Regenerative simulation
is a compromise between the two extremes above (analytical bounds and diagnostic
plots) — it relies both on some preliminary analytical work and on the output of the
MCMC sampler. Roughly speaking, given the Markov chain {X0, . . . , Xt}, with invari-
ant density π, the aim is to identify the times where the process stochastically ‘restarts’
itself, thereby breaking the chain into iid segments. Our novel approach uses results
from [10] to construct a total variation distance bound between the distribution of Xt
and the invariant density, and then uses the (regenerative) iid output from the sampler
to estimate the unknown constants in this bound. In short, we demonstrate that a re-
generative structure is all that is needed to address both (i) and (ii). We note that while
the idea of using regeneration to address (i) goes back to [18, 12], these works do not
address the important burn-in issue of (ii) via regeneration.

In summary, our contribution is twofold: 1) to apply the regenerative method
[18, 12] to the Park and Casella Gibbs sampler and address (i); and 2) to show how
regenerative simulation can address the burn-in issue (ii) for any MCMC sampler, not
just for the speciﬁc sampler of Park & Casella.

The rest of the paper is structured as follows. In Section 2, we provide background
on regenerative simulation and then discuss how regeneration can address the problem
of MCMC burn-in, that is, issue (ii). Then, in Section 3 we show how regenerative

2

simulation can be applied to the Park & Casella Gibbs sampler. This is followed by a
numeric section that uses two popular test cases, where we compare the regenerative
estimators with the estimators based on the AR(1) heuristic approximation. Finally, we
draw conclusions on the beneﬁts of regenerative simulation for addressing both issues
(i) and (ii).

2 Convergence Assessment for Regenerative Processes

Before presenting our novel contribution, we brieﬂy summarize known facts about
regenerative processes. Recall that {Xk, k = 0, 1, 2, . . .} is said to be a zero-delayed
discrete-time regenerative process if there exist times

0 = T0 ≤ T1 ≤ T2 ≤ T3 ≤ . . .

such that {XTr+k, 0 ≤ k ≤ Tr+1 − 1} and {XT s+k, 0 ≤ k ≥ T s+1 − 1} are iid for all r (cid:44) s.
As a consequence, the lengths of the tours or cycles

Mr = Tr+1 − Tr,

r = 1, 2, . . .

are iid. Suppose h is a measurable function with E|h(Xk)| < ∞ and

Hr :=

Tr−1(cid:88)

k=Tr−1

h(Xk)

Then, we know [5] that Xk converges in distribution to a random variable X ∼ π such
that

E (cid:80)T1−1
k=0 h(Xk)
EM1
We denote the distribution of this X as π. It is the stationary distribution of the regen-
erative process. We also have [25]:

Eπh(X) =

EH1
EM1

=

ˆqt := 1
t

t−1(cid:88)

k=0

h(Xk)

a.s.
−→ Eπh =: q

and

√

t( ˆqt − q)

d
−→ N(0, γ2),

where γ2 is the so-called time-average variance constant (TAVC). In fact, the TAVC is
t ˆqt. Note that, the regenerative
asymptotically the same as the mean squared error of
process may or may not be Markovian. If it is Markovian, then we have a Markov
chain with stationary and limiting distribution π.

√

2.1 Regenerative Mean Square Error Estimator

With a regenerative process, such as the above, it is well-known [10, 25] how to esti-
mate the TAVC using the ratio estimator:

=

ˆγ2
t

(cid:80)N(t)

r=1 (Hr − ˆqt Mr)2
t

,

3

(2)

where N(t) = max{n : Tn ≤ t} is the number of regenerations that have occurred after
running the process for t steps.

Arguably the simplest and most frequently used alternative to (2) is the batch means
estimator. It is applied when the process under consideration is a Markov process and
identifying the regeneration events is not possible.

The batch means estimator divides a single run of a Markov chain, {X1, . . . , Xt} into
n ‘batches’ of m adjacent observations (so that t = m × n). Denoting the sample mean
of the m observations from the k-th ‘batch’ by ˜Xk, the batch means variance estimator
is given by [14]

(cid:16) ˜Xk − 1
The batch means variance estimator is motivated by the fact that the dependence be-
tween adjacent batch means goes down to zero as m → ∞ (see [14] for more details).
For this reason, [12] views the batch means estimator as an ad-hoc variant of the re-
generative estimator (2).

= 1
n−1

k=1 Xk

ˆγ2
batch

(cid:80)m×n

(cid:80)n

m×n

k=1

(cid:17)2

.

Unfortunately, ensuring the consistency of ˆγ2

batch is nontrivial. On the one hand [7]
shows that if n → ∞ and m → ∞, then the batch variance estimator is consistent. On
the other hand, [11] shows that for any ﬁxed n and m → ∞, any batch means estimator
of a stationary quantity of interest is not consistent. Thus, consistency requires that both
n and m grow without bound. In practice, however, the lack of independence between
batches makes it very diﬃcult to determine how large n needs to be and how m needs
to grow as a function of n. In contrast, if regeneration events can be identiﬁed within
the Markov chain, then the iid regenerative structure ensures that such diﬃculties do
not exist.

2.2 Novel regenerative burn-in estimator

In this section, we explain how to estimate the total variation discrepancy of a Markov
chain for which we can identify its regenerative events.

Recall that the total variation distance between κt(·|x0), the t-th step transition ker-

nel of a Markov chain starting at x0, and the invariant density π is deﬁned by

(cid:107)κt(·|x0) − π(cid:107)TV = sup
A∈B

|κt(A|x0) − π(A)|,

where B is the Borel σ-algebra (and henceforth omitted from the notation). Also, if
(cid:107)κt(·|x0) − π(cid:107)TV ≤ c1 exp(−εt) for some ε > 0 and constant c1 (possibly depending on
x0), then the underlying Markov chain is said to be geometrically ergodic.

Now, suppose that we initialize the chain from a random initial X0 drawn from
some density π0. Then, the t-step transition kernel is obtained by taking the expectation
with respect to X0, namely, E[κt(A | X0)]. We deﬁne the (cid:15)-burn-in of a Markov chain
with transition kernel κ as the smallest t for which (cid:107)E[κt(· | X0)] − π(cid:107)TV < (cid:15), that is:

tb := min{t : (cid:107)E[κt(· | X0)] − π(cid:107)TV < (cid:15)}

Hence, a theoretically sound assessment of convergence, is to construct an estimate
of (or a bound for) (cid:107)E[κt(· | X0)] − π(cid:107)TV, and examine how fast it decays with respect

4

to t. Since a simple analytical formula is too diﬃcult to derive, practitioners turn to
heuristics such as examining the autocorrelation plots (mentioned in the introduction)
or experimenting with the Markov chain using diﬀerent starting values, X0.

Instead, we adopt a more theoretically sound approach that is a compromise be-
tween the extremes of an exact theoretical bound and an heuristic diagnostic plot. Our
key insight is that the bias properties of regenerative estimators [10] allow us to bound
the total variation distance, as follows.

Theorem 2.1 (Total Variation Bound for MCMC) Let κt(·|X0) with X0 ∼ π0 be the
t-step transition kernel of a geometrically ergodic Markov chain with invariant density
π. Suppose we can identify regenerative times of the Markov chain and assume that
X0 ∼ π0 initialized a new regenerative cycle for simplicity. Then, we have (for some
constant ε > 0)

(cid:107)E[κt(·|X0)] − π(cid:107)TV ≤

+ O(exp(−εt)),

η
t + 1

where η = EM2

1 −EM1
2EM1

with M1, M2, . . . denoting the iid regenerative cycles.

The proof is given in the Appendix.

A key insight from the theorem above is that an asymptotic upper bound for the
(cid:15)-burn-in, tb, is (cid:100)η/(cid:15)(cid:101) , and that the constant η can be estimated from simulation using
the iid realizations of M1, M2, . . ..

for the (cid:15)-burn-in is:

In summary, (Tn = M1 + · · · + Mn and N(t) = max{n : Tn ≤ t}) our novel estimator
k − (cid:80)N(t)
k=1 Mk

2(cid:15) (cid:80)N(t)

k=1 M2

k=1 Mk

(cid:80)N(t)

(3)









.

This estimator can admittedly be quite conservative as it relies on an upper bound of
the total variation distance, not on the actual distance.

The following table summarizes the current popular practice and our suggested

alternative.

Issue
Theoretical approach
Popular approach
Regenerative approach

(i) Estimate MSE
Compute/Bound TAVC
Batch-means estimator
TAVC Estimator (2)

(ii) Assessing the convergence
Compute/bound the TV distance
Diagnostic plots
Bias Estimator (3)

In the next section, we apply the variance estimator (2) and the (cid:15)-burn-in estimator
(3) to the Gibbs sampler of Park & Casella. Note that their sampler is known to be
geometrically ergodic [13], so that the results in Theorem 2.1 apply.

3 Regenerative Simulation for Park & Casella Sampler

In order to assess the convergence of the Park & Casella sampler via the regenerative
estimators (2) and (3), we ﬁrst need to identify the regeneration events in the output
of the sampler. The most common method for identifying regenerative structure in
Markov chains is the state-space augmentation method of Nummelin & Mykland [19,
18, 12].

5

3.1 Nummelin state-space augmentation

To identify regenerative structure in a Markov chain with transition kernel κ(xk+1|xk)
and invariant density π, we ﬁrst need to establish the so-called minorization condition.
Namely, we seek a probability measure ν and a function s such that

κ(xk+1|xk) ≥ ν(dxk+1)s(xk), ∀xk.

(4)

Once (4) is established, one can then simulate the Markov chain X1, X2, . . . via the
mixture representation of κ:

κ(xk+1|xk) = s(xk)ν(dxk+1) + (1 − s(xk)) κ(xk+1|xk)−ν(dxk+1)s(xk)

1−s(xk)

.

(5)

Thus, a regenerative structure arises in this process, because {X1, . . . , Xk} is indepen-
dent of {Xk+1, Xk+2, . . .} whenever Xk+1 is simulated from the ﬁrst component, ν(dxk+1),
of the mixture.

Simulation from the mixture components of (5) may be diﬃcult, if not impossible.
Indeed, an important insight of [18] is that one does not need to simulate from the
mixture densities of (5) directly. Instead, one can simulate from κ(xk+1|xk) in the usual
manner, and identify regeneration times retrospectively. To be precise, given xk, the
k-th realization, we can simulate Xk+1 from κ(xk+1|xk) and decide that regeneration has
occurred with retrospective probability:

ψk := P[ regeneration at k | Xk, Xk+1] = s(Xk)ν(Xk+1)
κ(Xk+1|Xk)

.

That is to say, if one wishes to incorporate regeneration in a geometrically ergodic
MCMC sampler, one proceeds as follows.

1. Establish (4) for the transition density of the MCMC sampler.

2. Simulate the Markov chain {X1, X2, . . . , Xt} as usual (e.g., running the Gibbs

sampler of Park & Casella), starting from X0.

3. For k ∈ {1, . . . , t − 1}, simulate a Bernoulli random variable with success proba-

bility ψk to decide whether regeneration has occurred.

In the next section we establish the minorization condition for the Gibbs sampler of
Park & Casella and provide a formula for ψk. In this way, we will have all the ingredi-
ents to run the above algorithm.

3.2 Application to Park & Casella sampler

Given the response variable Y and model matrix X, the hierarchical formulation of
Bayesian Lasso linear regression model is as follows (here β, σ are model parameters
and λ is the Lasso regularization parameter):

β j|λ i.i.d∼ Laplace(0, 1/λ),

for j ∈ {1, . . . , p}

Y|(β, λ, σ2) ∼ N(Xβ, σ2I).

6

It follows that inference for the Bayesian Lasso linear regression requires one to take
expectations with respect to the posterior density (for simplicity of notation we drop y)
(cid:16)
− 1

(λ/2)p exp

(cid:17)

2σ2 (cid:107)y − Xβ(cid:107)2
(cid:96)(λ, σ2)

2 − λ(cid:107)β(cid:107)1

,

(6)

π(β|λ, σ2) =

where (cid:96)(λ, σ2) := (cid:82)
of the pair (λ, σ2).

(λ/2)p exp

(cid:16)

− 1

2σ2 (cid:107)y − Xβ(cid:107)2

2 − λ(cid:107)β(cid:107)1

(cid:17)

dβ is the marginal likelihood

Recall (see Appendix B for details or [20]) that the transition density for the Gibbs

sampler of Park & Casella is

κ((βk+1, τk+1)
(cid:124)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:123)(cid:122)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:125)
xk+1

) = π(τk+1|βk)π(βk+1|τk+1),

| (βk, τk)
(cid:124)(cid:32)(cid:32)(cid:123)(cid:122)(cid:32)(cid:32)(cid:125)
xk

where π(τk+1|βk) is the joint density of independent Wald(λ(cid:48), µ(cid:48)
j) random variables with
λ(cid:48) = λ2 and µ(cid:48)
= λ/|β j| (see, for example, [4]) and π(βk+1|τk+1) is the density of the
j
multivariate N(AX(cid:62) y, σ2A) distribution, where A := X(cid:62)X + diag(τ). We have the
following lemma whose proof is in the Appendix.

Lemma 3.1 (Regenerative conditions for Park & Casella sampler)
Let ˆβ be the solution to the frequentist Lasso penalized regression model:

ˆβ = argmin

β

{(cid:107)y − Xβ(cid:107)2
2

+ λ(cid:107)β(cid:107)1}

and let D = Rp ×[c, d] be a subset of Rp ×Rp
Deﬁne the probability measure ν(βk+1, τk+1):

+, the state space on which (β, τ) is deﬁned.

ν(βk+1, τk+1) = ε−1κ((βk+1, τk+1)|( ˆβ, 1)) × I{(βk+1, τk+1) ∈ D} ,
where 1 ∈ Rp is the vector of ones and ε is the normalizing constant for ν. Let the
notation a+ mean setting all negative entries of the vector a to zero, and similarly a−
sets all positive entries of a zero (a2 means squaring each entry). Then, the measure ν
and the function:

(7)

s(βk, τk) = ε exp

(cid:18)
− 1

2 d(cid:62)(β2

k − ˆβ

2

)+ − 1

2 c(cid:62)(β2

k − ˆβ

(cid:19)

2

)−

satisfy the minorization condition:

κ((βk+1, τk+1)|(βk, τk)) ≥ ν(βk+1, τk+1)s(βk, τk),

∀(βk, τk).

Conditional on the simulated states (βk, τk) and (βk+1, τk+1), the probability that a re-
generation at the k-th step has occurred is:

ψk = exp

(cid:18)
− (d−τk+1)(cid:62)(β2

2

k − ˆβ

)+

2

× I {τk+1 ∈ [c, d]}

− (c−τk+1)(cid:62)(β2

k − ˆβ

2

2

(cid:19)

)−

×

(8)

To start the Markov chain with a fresh regenerative cycle, we need only simulate an
initial state from ν(β, τ) in (7) above. Now, we have all the ingredients for identifying
regeneration events during the course of running the Gibbs sampling of Park & Casella.

7

3.3 Practical tuning of algorithm

Our simulation experience suggests that it does pay oﬀ to put some eﬀort in optimizing
the probability of regeneration with respect to c, d ∈ Rp
+. Clearly, as the volume of the
hyper rectangle [c, d] in (8) decreases, the probability of observing τ ∈ [c, d] shrinks
to zero. However, if one makes [c, d] too large, then the exponential term approaches
zero, that is, the probability of observing a regeneration again shrinks to zero. This
suggests that we can search for the [c∗, d∗] that yield the optimal tradeoﬀ between
these two antagonistic conditions.

Ideally one should solve the optimization program

(c∗, d∗) = argmax

E[P[ regeneration at k | Xk, Xk+1]],

c,d

where the expectation is with respect to a pair Xk, Xk+1 that is in stationarity (that is,
Xk ∼ π and Xk+1 ∼ κ(Xk+1|Xk)).

Figure 1: Grid search to maximize the number of regenerations for the diabetes dataset.
Here the empirical Bayes estimator for the pair (λ, σ) is (0.00431, 53.5). We can see a
clearly pronounced maximum at α ≈ 0.01.

There are two diﬃculties here. First, solving the program analytically is impossible.

Second, the integration is 2p-dimensional.

Our solution to the ﬁrst diﬃculty is to ﬁrst simplify the optimization to a univariate
optimization in terms of a single variable α. More precisely, to simplify the grid search
optimization, we let α ∈ [0, 1] and for each j, we denote the lower and the upper
α-quantile for τ j by c j,(α) and d j,(α) respectively. Approximately, we have

P[τ j < c j,(α)] = P[τ j > d j,(α)] = α

Thus, instead of solving the optimization program for a general (c∗, d∗), we solve the

8

00.020.040.060.080.100.10.20.30.40.50.60.7αEstimated probability of regenerationunivariate program

α∗ = argmax

α

E[P[ regeneration at k | Xk, Xk+1]]

and use [c(α∗), d(α∗)].

For the second diﬃculty, note that we already have access to a Gibbs sampler which
can generate the sample paths quickly. Thus, to perform the optimization for α, we run
a pilot of the Gibbs sampler to obtain an approximate empirical distribution for many
pairs (Xk, Xk+1). We then use a grid search to maximize the estimated probability of
regeneration with respect to α. The procedure is summarized in the following pseudo-
code.

Algorithm 1 : Grid search optimization for ˆα∗
Require: solution to the frequentist Lasso ˆβ, grid α = (α(1), α(2), . . . , α(q)), number of

samples in the pilot run t
Obtain empirical distribution (β1, τ1), . . . , (βt, τt) from the Gibbs sampler.
Approximate the empirical marginal distribution for τ j by the ordered statistics
(τ j,(1), . . . , τ j,(t)) for each j ∈ {1, . . . , p}
for i ∈ {1, . . . , q} do

Approximate c j,(α(i)), and d j,(α(i)) from the empirical marginal distribution for
each j
Compute ψ(i)
ˆψ(i) ← 1
t−1

k using c j,(α(k)) and d j,(α(k)) for k ∈ {1, . . . , t − 1} using (8)
(cid:80)t−1
k=1 ψ(i)
Choose i∗ such that ψ(i) is maximum
return Return ˆα∗ ← α(i∗)

k

Figure 1 shows the result of the univariate grid search for the diabetes example

considered in Section 4.

It is important to note that the above optimization does not improve the convergence
of the sampler, but simply helps identify more regenerative events (which occur even
when they go unidentiﬁed). Identifying more regenerations only allows us to quantify
the error in the MCMC estimate more accurately, but does nothing to speed up the
convergence.

4 Numeric Examples

To validate the regenerative results, we will use an AR(1) process as a heuristic approx-
imation to the Markov chain output. Recall that an AR(1) process is given by:

Yt+1 = c + ρYt + εt,

t = 0, 1, 2, . . .

where ε ∼ N(0, σ2
Then, the formula for the mean and variance is

ε). Suppose the process starts at some initial state Y0 = y0 and |ρ| < 1.

µt = c

1 − ρt
1 − ρ

+ ρty0, Var(Yt) = σ2
ε

1 − ρ2t
1 − ρ2

9

Thus, the stationary distribution of the AR(1) process is a Gaussian with mean and
variance, µ = limt↑∞ µt = c/(1 − ρ) and σ2 = limt↑∞ Var(Yt) = σ2
1−ρ2 , respectively. In
other words, once we have estimates for the AR(1) model parameters, we can upper
bound the total variation distance as follows.

ε

Lemma 4.1 (AR(1) Bounds on Total Variation) Assuming that the output of the Markov
chain follows the AR(1) model above, we have the two bounds:

(cid:118)(cid:116)

≤

2 − 2

(cid:114)

√

2

1−ρ2t

2−ρ2t

|P[Yt ∈ A] − P[Y∞ ∈ A]| ≤

sup
A

(cid:19)2


−

(cid:18)
c 1−ρt
1−ρ
(cid:18)



exp


|P[Yt ∈ A] − P[Y∞ ∈ A]| ≤

+ρty0− c
1−ρ
1−ρ2t
1−ρ2

4σ2
ε

+ 1

1−ρ2

(cid:19)


,

− ρ2t − ln(1 − ρ2t),

sup
A
ρ2t (y0−c/(1−ρ))2
σ2
(cid:15) /(1−ρ2)

(cid:113)

≤ 1
2

where the ﬁrst one is derived using the Hellinger distance and the second one is derived
using the Kullback-Leibler (KL) distance.

In the following examples, we use estimates of c, ρ for each β j, j = 1, . . . , p and plug
them into the AR(1)-based upper bounds. We then use the largest of these p-estimates
as a heuristic approximation of the true total variation distance of the Gibbs sampler.
In a sense, this is equivalent to picking the autocorrelation plot that appears to decay at
the slowest rate.

4.1 Diabetes dataset

We present the result of our numerical study on the diabetes dataset of [8]. The dataset
consists of 10 predictor variables (age, sex, BMI, etc.) and a response variable which
is a medical measurement for the level of diabetes for n = 442 patients. We model the
variables using the Bayesian Lasso linear regression, and apply the regenerative Gibbs
sampler to sample from the posterior distribution.

Regenerative variance estimator (2). The result is given in Table 1, in which we
run the sampler to generate 5000 samples and observed 3369 regenerations. We also
compare our regenerative estimator (2) with the AR(1)-based estimates for the standard
errors[15, 9].

Both methods give estimates in the same ballpark. It is also worthwhile noting that
the AR(1) approximation approach consistently gives larger standard error estimates
than the regenerative approach.

Regenerative (cid:15)-burn-in estimator (3). For the diabetes data set, our estimate for
η is 1.0178 ( 1.0178 ± 0.0008 is a 95% numerical conﬁdence interval), therefore an
approximate 0.01-burn-in period is tb ≈ 101.

10

Table 1: A comparison of the standard error estimators for the diabetes dataset.

Mean
−2.9
−2.1 × 102
5.2 × 102
3.1 × 102
−1.9 × 102
8.5
−1.5 × 102
1.0 × 102
5.3 × 102
6.4 × 101

Standard error
7.5 × 10−1
9.0 × 10−1
9.6 × 10−1
9.4 × 10−1
3.0
2.4
1.8
1.9
1.6
8.8 × 10−1

AR(1) st. err.
7.5 × 10−1
9.1 × 10−1
9.9 × 10−1
9.8 × 10−1
3.4
2.7
2.1
2.1
1.7
9.3 × 10−1

Relative error
2.6 × 10−1
4.2 × 10−3
1.8 × 10−3
3.1 × 10−3
1.6 × 10−2
2.9 × 10−1
1.2 × 10−2
1.9 × 10−2
3.0 × 10−3
1.4 × 10−2

AR(1) rel. err.
2.6 × 10−1
4.3 × 10−3
1.9 × 10−3
3.2 × 10−3
1.8 × 10−2
3.2 × 10−1
1.4 × 10−2
2.1 × 10−2
3.3 × 10−3
1.4 × 10−2

age
sex
bmi
map
tc
ldl
hdl
tch
ltg
glu

For the AR(1) approximation, substituting in the estimated parameters, we ﬁnd that
t > 5 is suﬃcient for the t-th state to be within 0.01 total variation distance to the
stationary distribution. Thus, the AR(1) approximation is very optimistic. We note that
we did not detect a practical diﬀerence between the two inequalities in Lemma 4.1. A
comparison of all bounds is given in Figure 2.

Figure 2: A comparison of diﬀerent approximations to the total variation distance
bound.

4.2 Boston house price dataset

The Boston house price dataset consists of 13 predictor variables (crime rate per capita,
proportion of residential land etc.) and a response variable which is the median value
of owner-occupied homes for n = 506 cases. We again model the variables using the
Bayesian Lasso linear regression, and apply the regenerative Gibbs sampler to sample
from the posterior distribution.

11

1234567891000.20.40.60.811.21.4Markov chain stepsTotal variation distance bound  Regenerative simulationAR(1) approximation, Hellinger distanceAR(1) approximation, KL distanceRegenerative variance estimator (2). From Table 2 we see that the regenerative
variance estimator agrees with the AR(1) approximation. It is worthwhile noting that
the optimal average probability of regeneration is highly sensitive to the data. On
the one hand, after optimizing with respect to α, the diabetes dataset can achieve a
probability of regeneration of more than 0.6. On the other hand, the Boston house
price dataset can barely achieve a probability of 0.04.

Table 2: A comparison of the standard error estimators for the Boston house price
dataset

crim
zn
indus
chas
nox
rm
age
dis
rad
tax
ptratio
b
lstat

Mean
−8.5 × 10−1
9.8 × 10−1
−1.1 × 10−3
6.8 × 10−1
−1.9
2.7
−1.4 × 10−2
−3.0
2.2
−1.7
−2.0
8.3 × 10−1
−3.7

Standard error
4.3 × 10−3
4.6 × 10−3
5.8 × 10−3
3.3 × 10−3
6.3 × 10−3
3.8 × 10−3
5.4 × 10−3
5.5 × 10−3
8.4 × 10−3
9.3 × 10−3
3.9 × 10−3
3.3 × 10−3
5.3 × 10−3

AR(1) st. err.
4.2 × 10−3
4.8 × 10−3
5.4 × 10−3
3.1 × 10−3
6.4 × 10−3
4.2 × 10−3
5.0 × 10−3
6.0 × 10−3
9.2 × 10−3
9.9 × 10−3
4.0 × 10−3
3.6 × 10−3
5.1 × 10−3

Relative error
5.0 × 10−3
4.7 × 10−3
4.1
4.9 × 10−3
3.3 × 10−3
1.4 × 10−3
3.6 × 10−1
1.8 × 10−3
3.8 × 10−3
5.5 × 10−3
1.9 × 10−3
4.0 × 10−3
1.4 × 10−3

AR(1) rel. err.
4.9 × 10−3
4.9 × 10−3
3.9
4.6 × 10−3
3.4 × 10−3
1.5 × 10−3
3.3 × 10−1
2.0 × 10−3
4.1 × 10−3
5.9 × 10−3
2.0 × 10−3
4.3 × 10−3
1.4 × 10−3

Figure 3: Grid search to maximize the number of regenerations. Here the empirical
Bayes estimator for the pair (λ, σ) is (0.613, 4.68). We can see a clearly pronounced
maximum at α ≈ 0.04.

Further experiments suggest that the dataset aﬀects the probability of regeneration
mainly through the estimated value for the Lasso parameter λ.
In other words, the
number of detected regenerative events depends on the value of the Lasso parameter
λ. Although, fewer observed regenerations do not necessarily signify a high mean

12

00.020.040.060.080.100.0050.010.0150.020.0250.030.0350.04αEstimated probability of regenerationsquared error, we need to observe at least two regenerations to be able to compute
a valid estimate of the asymptotic variance. Thus, a limitation of our regenerative
sampling is that when λ is very large, one may need to run the Markov chain for many
steps.

Regenerative (cid:15)-burn-in estimator (3). For the housing data set, our estimate for η
is 51 ( 51 ± 6.1 for a 95% numerical conﬁdence interval). Therefore, an approximate
0.01-burn-in period is tb ≈ 5100.

In contrast, the AR(1) approximation is remarkably optimistic, as seen from this

table of estimated bounds:

distance bnd.
step t

9.5 × 10−3
1

7.8 × 10−4
2

1.1 × 10−4
3

1.7 × 10−5
4

We can see that t ≥ 1 is suﬃcient for the t-th state to be within 0.01 total variation
distance to the stationary distribution. Thus, in this example there is a signiﬁcant dis-
agreement between the regenerative and the heuristic convergence assessment. We
believe that while the regenerative estimate is too conservative, the heuristic one is too
optimistic, and that the true (cid:15)-burn-in is somewhere in-between.

5 Concluding Remarks

In this paper, we identify the regenerative times in the output of the popular Park
& Casella Gibbs sampler, which (approximately) simulates from the posterior of the
Bayesian Lasso. The resulting regenerative simulation algorithm allows practitioners
to answer the two key questions that need to be answered for any convergence assess-
ment [12] of a Markov chain:

(i) What is the statistical error of any empirical average that aims to estimate a
stationary quantity of interest? The answer is provided by the consistent mean
squared error estimator (2).

(ii) How long does it take for the Markov chain to get suﬃciently close to the limiting
distribution? One good answer is the consistent estimator (3) of (an upper bound
on) the (cid:15)-burn-in of the Markov chain.

Whenever applicable, one should use the regenerative estimators to tackle issue (i) and
(ii), because the popular alternatives, such as batch-means estimators and diagnostic
plots, do not have the same sound theoretical foundation for their use.

While the estimator (3) of the mean square error is not novel [18, 12], the regen-
erative estimator (3) of the burn-in period appears to have been overlooked as a more
rigorous approach to estimating the burn-in. This article ﬁlls this gap.

13

A Proof of theorem 2.1

We use the notation from Section 2. Let Qt[A] be the distribution of a state X picked at
random from the Markov chain states: X0, . . . , Xt. In other words,

Qt[A] := 1
t + 1

t(cid:88)

k=0

E[κk(A | X0)],

where E[κk(A | X0)] = P[Xk ∈ A] for all k ≥ 0. By assumption, the Markov chain is
geometrically ergodic, that is, the distribution of the length M of a regenerative cycle
of the chain is light-tailed. In other words, E exp((cid:15)1M) < ∞ for some (cid:15)1 > 0. The
process X0, X1, . . . is also a zero-delayed regenerative process, because by assumption
the initial X0 commences a new cycle. Therefore, the conditions of Lemma A.1 (see
below) are satisﬁed and we have:

(cid:107)Qt − π(cid:107)TV ≤

EM2 − EM
2(t + 1)EM

+ O(exp(−εt))

(9)

for some (cid:15) ∈ (0, (cid:15)1]. In addition, Lemma A.2 below states that the distribution of the
ﬁnal state of the Markov chain, Xt, is closer to π than a state picked at random from
the history of the chain up until time t: X0, . . . , Xt. In other words,

(cid:107)E[κt(· | X0)] − π(cid:107)TV ≤ (cid:107)Qt − π(cid:107)TV

(10)

The result of the theorem then follows by combining (9)+(10).

Lemma A.1 (Uniform bias estimate) Suppose X0, X1, . . . is a zero-delayed discrete
regenerative process with regeneration times 0 = T0 < T1 < T2 < · · · , where Tn =
M1 + · · · + Mn, and stationary distribution Q. Let E exp(ε1M) < ∞ for some ε1 > 0
and let Qt be the distribution of a state drawn at random from the whole history of the
chain up until time t, that is, drawn at random from X0, . . . , Xt. Then, we have for some
ε ∈ (0, ε1]

|Qt[A] − Q[A]| ≤

sup
A

EM2 − EM
2(t + 1)EM

+ O(exp(−εt))

Proof. The proof follows closely the ideas in [10]. Using the notation from Section 2,
let u(k) = (cid:80)k
P(T j = k) = P(∃ j : T j = k) denote the renewal measure, and deﬁne
the convolution operator (a ∗ b)(t) = (cid:80)t
k=0 a(t − k)b(k) between two functions a and b.
Further, deﬁne

j=0

eA(t) := (t + 1)(Q[A] − Qt[A]) = E

t(cid:88)

k=0

Zk(A),

where Zk(A) = Q[A] − I{Xk ∈ A}. Wald’s identity implies that

M1−1(cid:88)

E

k=0

Zk(A) = Q[A]EM1 − EH1(A) = 0.

14

Thus, we can then verify that eA satisﬁes the renewal equation

eA(t) = (vA ∗ u)(t),

where

vA(t) := E (cid:104)(cid:80)M1−1
= E (cid:104)(cid:80)M1−1

k=0 Zk(A) − (cid:80)t
k=t+1 Zk(A); M1 ≥ t + 2

k=0 Zk(A); M1 > t
(cid:105)

(cid:105)

with

|vA(t)| ≤ E [M1 − t − 1; M1 ≥ t + 2]
Since E exp(ε1M) < ∞, then there exists some ε2 ∈ (0, ε1] such that EM exp(ε2 M) ≤
∞, and therefore

|vA(t)| ≤ E [M; M ≥ t] ≤

≤

E[M exp(ε2M); M ≥ t]
exp(ε2t)
E[M exp(ε2M)]
exp(ε2t)

= O(exp(−ε2t))

An application of [2, Theorem 2.10 on Page 196] yields for some ε ∈ (0, ε2]:

eA(t) =

(cid:80)

k≥0 vA(k)
EM

+ O(exp(−εt)),

t ↑ ∞

uniformly in A. In other words,
(cid:80)

|eA(t)| ≤

sup
A

Simplifying the upper bound (cid:80)
the desired result.

k≥0 supA |vA(k)|
EM

+ O(exp(−εt)),

t ↑ ∞

k≥0 supA |vA(k)| ≤ (cid:80)

k≥0

E[(M −k −1)+] = EM2−EM

2

yields

(cid:3)

Lemma A.2 (Time-average bound on total variation distance) Let X1, X2, . . . , Xt be
a Markov chain with a t-step transition kernel κt(· | X0), X0 ∼ π0 and a stationary/limiting
distribution π. Then, the distribution of a random variable drawn uniformly from
X1, . . . , Xt is further away from π than the distribution of the last state Xt. In other
words, we have that

sup
A

|E[κt(A | X0)] − π(A)| ≤ sup
A

(cid:12)(cid:12)(cid:12)(cid:12)

1
t

(cid:12)(cid:12)(cid:12)(cid:12)
(E[κ j(A | X0)] − π(A))

t(cid:88)

j=1

Proof. For simplicity, assume that there exist densities E[κt(x | X0)] and π(x), corre-
sponding to E[κt(A | X0)] = P[Xt ∈ A] and π(A) (which is the case with the Gibbs
sampler of Park & Casella anyway). We then use the following four facts.

First, for any nonnegative functions g1 and g2, we have min{g1(x) + g2(x), 1} ≤
min{g1(x), 1} + min{g2(x), 1}. More generally, for any nonnegative functions g1, g2, . . .
(cid:111)
g j(x), 1

min{g j(x), 1}

(cid:110) (cid:88)

(11)

min

(cid:88)

≤

j

j

15

Second, Sheﬀe’s lemma states that for any densities p and q:

(cid:90)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

A

sup
A

p(x)dx −

(cid:90)

A

q(x)dx

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(cid:90)

= 1
2

= 1 −

|p(x) − q(x)|dx

(cid:90)

min{p(x), q(x)}dx

Third, for any s(cid:48) ≤ s, we have

(cid:107)E[κs(cid:48) (· | X0)] − π(cid:107)TV ≥ (cid:107)E[κs(· | X0)] − π(cid:107)TV,

(12)

(13)

which is nothing more than a statement of the obvious fact that the more we run the
Markov chain, the closer we get to its stationary distribution. Fourth, two random
variables X1 and X2 on the same probability space and with marginal distributions
π1(A) = P[X1 ∈ A] and π2(A) = P[X2 ∈ A] are maximally coupled [24] when their
joint distribution is such that

(cid:107)π1 − π2(cid:107)TV = P[X1 (cid:44) X2]

We now apply these four results as follows. Let X and Y be maximally coupled with
E[κ j(x | X0)] and π(y), respectively. Then, P[X (cid:44) Y] =
marginal densities 1
t
supA

(cid:12)(cid:12)(cid:12) and

(cid:12)(cid:12)(cid:12) 1

(cid:80)t

j=1

t

(cid:80)t
j=1(E[κ j(A | X0)] − π(A))
(cid:90)

P[X = Y]

(12)=

π(x) min

(cid:110) 1
t

t(cid:88)

j=1

E[κ j(x | X0)]
π(x)

(cid:111)
dx

, 1

(11)
≤

1
t

(12)= 1
t

= 1 −

t(cid:88)

(cid:90)

(cid:111)
(cid:110)E[κ j(x | X0)], π(x)

dx

min

j=1
t(cid:88)

j=1

(cid:32)
1 − sup
A

|E[κ j(A | X0)] − π(A)|

(cid:33)

1
t

t(cid:88)

j=1

(cid:107)E[κ j(· | X0)] − π(cid:107)TV.

Then, using P[X (cid:44) Y] = 1 − P[X = Y], the last inequality implies that

P[X (cid:44) Y] ≥

1
t

t(cid:88)

j=1

(cid:107)E[κ j(· | X0)] − π(cid:107)TV

(13)
≥ (cid:107)E[κt(· | X0)] − π(cid:107)TV,

whence the desired result follows.

(cid:3)

B Background: Gibbs sampler for the Bayesian Lasso

The ﬁrst key insight in [20] is that a Laplace(0, 1/λ) density is in fact a Gaussian-scale
mixture [1]. In particular, for each β j, j ∈ {1, . . . , p}, we have the identity,

(cid:16)

exp

(cid:17) =

−λ|β j|

λ
2

(cid:90) ∞

0

1
2πs j

(cid:112)


−







β2
j
2s j

×

λ2
2

(cid:32)

exp

−

λ2
2

(cid:33)

s j

ds j.

exp

16

It follows form the change of variable τ j = 1/s j,

(cid:16)
−λ|β j|

(cid:17) =

exp

λ
2

(cid:90) ∞

0

2

λ2
√

2π

exp


−



β2
j τ j
2



 exp

(cid:32)
−

λ2
2τ j

(cid:33)

τ−3/2
j

dτ j.

(14)

Hence if one considers sampling the pair (β, τ) ∈ Rp × Rp
π(β, τ|λ, σ2) =

+ from the joint density

(cid:16)

exp

=

− 1

2σ2 (cid:107)y − Xβ(cid:107)2

2

(cid:17) (cid:81)p

λ2
√

exp

j=1

2

2π
(cid:96)(λ, σ2)

(cid:19)

(cid:18)
−

β2
j τ j
2

exp

(cid:19)

(cid:18)
− λ2
2τ j

τ−3/2
j

,

(15)

the marginal samples β, from samples of the pair (β, τ), have the same distribution as
(6). This is because (14) implies

π(β, τ|λ, σ2) dτ = π(β|λ, σ2).

(cid:82)

Rp
+

The form of (15) suggests a natural (block) Gibbs sampler that cycles between the
full conditional distributions π(β|τ, λ, σ2) and π(τ|β, λ, σ2). The second key insight in
[20] is that π(τ|β, λ, σ2) takes the product form

π(τ|β, λ, σ2) ∝


−



β2
j τ j
2



 exp

(cid:32)

−

λ2
2τ j

(cid:33)

exp

τ−3/2
j

.

p(cid:89)

j=1

This means each τ j are conditionally independent. Moreover, the conditional distribu-
= λ/|β j| (see, for example, [4]). Finally,
tion of τ j is Wald(λ(cid:48), µ(cid:48)
it is not hard to show that

j) where λ(cid:48) = λ2 and µ(cid:48)

j

π(β|τ, λ, σ2) ∝ exp

(cid:32)

−

1
2σ2

(cid:16)
β − AX(cid:62) y

(cid:17)(cid:62)

A−1 (cid:16)

β − AX(cid:62) y

(cid:17)(cid:62)

(cid:33)

,

where A−1 = X(cid:62)X+diag(τ) is a symmetric invertible matrix. This means, β conditional
on τ, is a p-dimensional Gaussian random variable with the mean vector AX(cid:62) y and the
covariance matrix σ2A.

At this stage one may wonder how we determine the pair (λ, σ2). In fact, one may
choose to adapt a fully Bayesian approach and assign the pair some prior distributions,
see [16]. However, in this paper we take the empirical Bayes approach and use the
estimator (ˆλ, ˆσ2) = argmax (cid:96)(λ, σ2). This is because the parameters (λ, σ2) are rarely
of interest, that is, they are nuisance parameters. In this paper, we use the approximate
EM algorithm of [3] to solve the program (ˆλ, ˆσ2) = argmax (cid:96)(λ, σ2).

17

C Proof of Lemma 3.1

Our strategy follows from the approach described in [18] and used in [23]. Denote
X = Rp × Rp

+ and ﬁx ( ˜β, ˜τ) ∈ X and D ⊆ X . Observe that κ(βk+1, τk+1|βk, τk) =

= π(τk+1|βk)π(βk+1|τk+1)
= π(τk+1|βk)
π(τk+1| ˜β)

(cid:41)

π(τk+1| ˜β)π(βk+1|τk+1)
(cid:40) π(τk+1|βk)
π(τk+1| ˜β)
(cid:40) π(τk+1|βk)
π(τk+1| ˜β)

(cid:41)

inf
(βk+1,τk+1)∈D

inf
(βk+1,τk+1)∈D

≥ ε

= ε

where

ε−1π(τk+1| ˜β)π(βk+1|τk+1)I (cid:8)(βk+1, τk+1) ∈ D(cid:9)

ε−1κ(βk+1, τk+1| ˜β, ˜τ)I (cid:8)(βk+1, τk+1) ∈ D(cid:9)

ε =

(cid:90)

D

κ(βk+1, τk+1| ˜β, ˜τ) d(βk+1, τk+1).

In particular, let us take D = Rp × (cid:81)p
j=1[c j, d j] := Rp × [c, d] and ( ˜β, ˜τ) = ( ˆβ, 1) where
ˆβ is the solution to the frequentist Lasso penalized regression model. It follows that we
can take

ε−1s(βk, τk) =

inf
(βk+1,τk+1)∈D

(cid:41)

(cid:40) π(τk+1|βk)
π(τk+1| ˆβ)

p(cid:88)

−

1
2

j=1
j )I(cid:110)
k, j− ˆβ2
2

τk+1, j(β2

k, j − ˆβ2
j )





= inf

exp

τk+1∈[c,d]
(cid:32)

ε−1s(βk, τk) = exp

−

(cid:80)p

j=1 d j(β2

k, j− ˆβ2
β2

j ≥0

(cid:111)

−

(cid:80)p

j=1 c j(β2

j )I(cid:110)
k, j− ˆβ2
2

(cid:33)

(cid:111)

k, j− ˆβ2
β2

j <0

= exp

(cid:18)
− d(cid:62)(β2

2

k − ˆβ
2

)+

k − ˆβ
− c(cid:62)(β2
2

(cid:19)

2

)−

Here j is the index for entries within the vectors and k is the index for the steps in the
Markov chain. The above calculation recalls the fact that the normalizing constant for
the density function of a Wald(λ(cid:48), µ(cid:48)) random variable is (λ/2π)1/2.

Denote

ν(βk+1, τk+1) = ε−1κ(βk+1, τk+1| ˜β, ˜τ)I (cid:8)(βk+1, τk+1) ∈ D(cid:9) .

Therefore, by construction we have

κ((βk+1, τk+1)|(βk, τk)) ≥ ν(βk+1, τk+1)s(βk, τk),

∀(βk, τk)

18

as required. For the probability of regeneration, we then obtain:

ψk = s(βk, τk)ν(βk+1, τk+1)
κ(βk+1, τk+1|βk, τk)

= ε−1s(βk, τk)π(τk+1| ˜β)π(βk+1|τk+1)I (cid:8)(βk+1, τk+1) ∈ D(cid:9)
π(τk+1|βt)π(βk+1|τk+1)
= ε−1s(βk, τk)π(τk+1| ˜β)I {τk+1 ∈ [c, d]}
π(τk+1|βk)

p(cid:88)

1
2

= ε−1s(βk, τk) exp

k, j − ˆβ2
β2

τk+1



(cid:16)

(cid:17)

j

j=1

× I {τk+1 ∈ [c, d]}

(cid:32)

−

= exp

1
2

p(cid:88)

j=1

(u j − τk+1, j)

(cid:16)
k, j − ˆβ2
β2

j

k, j − ˆβ2
β2

(cid:111)
j ≥ 0


(cid:17) I (cid:110)

−

1
2

p(cid:88)

j=1

(l j − τk+1, j)

(cid:16)

k, j − ˆβ2
β2

j

(cid:17) I (cid:110)

k, j − ˆβ2
β2

j < 0

(cid:111) (cid:33)

× I {τk+1 ∈ [c, d]}

Therefore,

ψk = exp

(cid:32)
−

1
2

(u − τk+1)(cid:62)(β2

k − ˆβ

2

)+ −

1
2

D Proof of Lemma 4.1

(l − τk+1)(cid:62)(β2

k − ˆβ

2

(cid:33)

)−

× I {τk+1 ∈ [c, d]} .

The ﬁrst bound is derived from the facts: i) 1
φ2(cid:107)2, where
φ1 and φ2 are any probability densities; and ii) for two Gaussian densities φ1, φ2 with
means (µ1, µ2) and variances (σ2
2) the L2 norm (cid:107)
2 is explicitly given by
2 − 2
exp

(cid:19)
. Then, we obtain

2 (cid:107)φ1 − φ2(cid:107)1 ≤ (cid:107)

1, σ2

φ1 −

φ2(cid:107)2

φ1 −

√

√

(cid:18)

(cid:113) 2σ1σ2
+σ2
σ2
2
1

− (µ1−µ2)2
+σ2
4(σ2
2)
1

√

√

supA |P[Yt ∈ A] − P[Y∞ ∈ A]| ≤

2 − 2

(cid:114)

(cid:113) 2σtσ
σ2
t

+σ2 exp

(cid:18)
− (µt−µ)2
+σ2)
4(σ2
t

(cid:19)
,

where Yt is a Gaussian with mean c 1−ρt
1−ρ
looser bound, is obtained via Pinsker inequality.

+ρty0 and variance σ2
ε

1−ρ2t
1−ρ2 . The second, slightly

References

[1] D. F. Andrews and C. L. Mallows. Scale mixtures of normal distributions. Journal
of the Royal Statistical Society. Series B (Methodological), pages 99–102, 1974.

[2] Søren Asmussen. Applied probability and queues, volume 51. Springer Science

& Business Media, 2008.

[3] George Casella. Empirical Bayes Gibbs sampling. Biostatistics, 2(4):485–500,

2001.

19

[4] R. S. Chhikara and J. L. Folks. The Inverse Gaussian Distribution: Theory:

Methodology, and Applications, volume 95. Marcel Dekker, Inc., 1988.

[5] Erhan Cinlar. Introduction to stochastic processes. Courier Corporation, 2013.

[6] Mary Kathryn Cowles and Bradley P Carlin. Markov chain Monte Carlo con-
vergence diagnostics: a comparative review. Journal of the American Statistical
Association, 91(434):883–904, 1996.

[7] Halim Damerdji. Strong consistency of the variance estimator in steady-state
simulation output analysis. Mathematics of Operations Research, 19(2):494–512,
1994.

[8] B. Efron, T. Hastie, I. Johnstone, and R Tibshirani. Least angle regression. The

Annals of statistics, 32(2):407–499, 2004.

[9] Walter R Gilks, Gareth O Roberts, and Sujit K Sahu. Adaptive Markov chain
Monte Carlo through regeneration. Journal of the American statistical associa-
tion, 93(443):1045–1054, 1998.

[10] Peter W. Glynn. Some topics in regenerative steady-state simulation. Acta Appli-

candae Mathematica, 34(1-2):225–236, 1994.

[11] Peter W Glynn and Ward Whitt. Estimating the asymptotic variance with batch

means. Operations Research Letters, 10(8):431–435, 1991.

[12] Galin L Jones and James P Hobert. Honest exploration of intractable probability
distributions via Markov chain Monte Carlo. Statistical Science, pages 312–334,
2001.

[13] Kshitij Khare and James P. Hobert. Geometric ergodicity of the Bayesian lasso.

Electronic Journal of Statistics, 7:2150–2163, 2013.

[14] Averill M Law and John S Carson. A sequential procedure for determining
the length of a steady-state simulation. Operations Research, 27(5):1011–1025,
1979.

[15] Averill M Law and W David Kelton. Conﬁdence intervals for steady-state sim-
ulations: I. a survey of ﬁxed sample size procedures. Operations Research,
32(6):1221–1239, 1984.

[16] Chenlei Leng, Minh-Ngoc Tran, and David Nott. Bayesian adaptive lasso. Annals

of the Institute of Statistical Mathematics, 66(2):221–244, April 2014.

[17] Sean P Meyn and Robert L Tweedie. Computable bounds for geometric conver-
gence rates of Markov chains. The Annals of Applied Probability, pages 981–
1011, 1994.

[18] Per Mykland, Luke Tierney, and Bin Yu. Regeneration in Markov chain samplers.

Journal of the American Statistical Association, 90(429):233–241, 1995.

20

[19] Esa Nummelin. General Irreducible Markov Chains and Non-Negative Opera-
tors. Cambridge Tracts in Mathematics. Cambridge University Press, 1984.

[20] T. Park and G. Casella. The Bayesian lasso. Journal of the American Statistical

Association, 103(482):681–686, 2008.

[21] N. G. Polson, J. G. Scott, and J. Windle. The Bayesian bridge. Journal of
the Royal Statistical Society: Series B (Statistical Methodology), 76(4):713–733,
2014.

[22] Jeﬀrey S Rosenthal. Minorization conditions and convergence rates for
Markov chain Monte Carlo. Journal of the American Statistical Association,
90(430):558–566, 1995.

[23] Vivekananda Roy and James P Hobert. Convergence rates and asymptotic stan-
dard errors for Markov chain Monte Carlo algorithms for Bayesian probit regres-
sion. Journal of the Royal Statistical Society: Series B (Statistical Methodology),
69(4):607–623, 2007.

[24] Hermann Thorisson. On maximal and distributional coupling. The Annals of

Probability, pages 873–876, 1986.

[25] Zeyu Zheng and Peter W Glynn. Extensions of the regenerative method to new
In Winter Simulation Conference (WSC), 2016, pages 289–301.

functionals.
IEEE, 2016.

21

