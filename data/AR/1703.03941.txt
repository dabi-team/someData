A Vision-based Scheme for Kinematic Model Construction of
Re-conﬁgurable Modular Robots

Kewei Lin, Juan Rojas, and Yisheng Guan1.

7
1
0
2

r
a

M
1
1

]

O
R
.
s
c
[

1
v
1
4
9
3
0
.
3
0
7
1
:
v
i
X
r
a

Abstract— Re-conﬁgurable modular robotic (RMR) systems
are advantageous for their reconﬁgurability and versatility.
A new modular robot can be built for a speciﬁc task by
using modules as building blocks. However, constructing a
kinematic model for a newly conceived robot requires signiﬁcant
work. Due to the ﬁnite size of module-types, models of all
module-types can be built individually and stored in a database
beforehand. With this priori knowledge, the model construction
process can be automated by detecting the modules and their
corresponding interconnections. Previous literature proposed
theoretical frameworks for constructing kinematic models of
modular robots, assuming that such information was known
a priori. While well-devised mechanisms and built-in sensors
can be employed to detect these parameters automatically,
they signiﬁcantly complicate the module design and thus are
expensive. In this paper, we propose a vision-based method
to identify kinematic chains and automatically construct robot
models for modular robots. Each module is afﬁxed with
augmented reality (AR) tags that are encoded with unique
IDs. An image of a modular robot is taken and the detected
modules are recognized by querying a database that maintains
all module information. The poses of detected modules are
used to compute: (i) the connection between modules and
(ii) joint angles of joint-modules. Finally, the robot serial-link
chain is identiﬁed and the kinematic model constructed and
visualized. Our experimental results validate the effectiveness
of our approach. While implementation with only our RMR
is shown, our method can be applied to other RMRs where
self-identiﬁcation is not possible.

I. INTRODUCTION

Modular robotic systems (MRSs) use robotic modules as
building blocks to create a variety of kinematic conﬁgura-
tions, see Fig. 1. Each module is an independent mechatronic
subsystem with a single function. Modules can be of different
types. A new kinematic conﬁguration can be speciﬁcally
selected for a given task and built with modules of different
types. This system design principle brings great versatility
and ﬂexibility. Throughout this paper, the phrase ”kinematic
conﬁguration” refers to the robot morphology, whereas the
word ”conﬁguration” indicates the robot state.

MRSs can be self-reconﬁgurable robots (SRRs) or not.
Unlike SRRs, e.g. Roombot [1] and M-TRAN [2], re-
conﬁgurable modular robots (RMRs) tend to be industry-
oriented and are set-up manually by users for speciﬁc
tasks [3]–[5]. RMRs reconﬁguration is conducted by users,
whereas SRRs use complex self-docking mechanisms to
ensure reliable mechatronic connections between modules

1Kewei Lin,

Juan Rojas

author, Email:
(the
juan.rojasn@gdut.edu.cn), and Yisheng Guan are with the Biomimetic
and Intelligent Robotics Lab (BIRL), School of Electro-Mechanical
Engineering, Guangdong University of Technology, Guangzhou, China,
510006.

corresponding

Fig. 1: Different kinematic conﬁgurations are possible by
combining different robot modules in different ways. Also
we classify module types in two categories: joint-modules
and tool-modules. Joint-modules build the main body of the
robot, while tool-modules act as end-effectors.

and enable self-reconﬁguration [6]. RMRs are simpler and
of lower-cost compared to SRRs. Nevertheless, they share
similar challenges in design and control [7].

To use a RMR for a speciﬁc task, one must (i) set up the
physical modular robot and (ii) construct the robot model
in the software. Physical connection of modules has been
well addressed through the use of quick-lock mechanisms
in each module. Modular robots are now set up conveniently
with little effort. The bottle neck of RMRs application lies in
constructing kinematic models for newly conceived modular
robots, which takes effort and expertise [4].

When considering kinematic conﬁgurations of a RMR sys-
tem, there is a large number of possible combinations given
a ﬁnite-set of modules and module-types. It’s cumbersome
for RMR designers to derive all possible kinematic models.
Consequently, the user needs to derive a kinematic model
every time a new modular robot is conceived. The automation
of the kinematic model construction is crucial to further
lower the barriers for non-experts.

With regard to automatic model generation, Chen et al.
[4] introduced a theoretical framework for automatic RMR
model generation. This work assumed that the robot struc-
ture was known a priori or speciﬁed manually. Rebots, a
physics-based simulator for MRS, provides an intuitive way
to specify modular robot structures [8]. Given a physical
modular robot, a user can observe the module-types and their
ordering, and reproduce it in the simulation using drag-and-
drop interaction. Despite the intuitive interface, untrained

 
 
 
 
 
 
users may mistake the module-types or their ordering.

The goal then is to automate both the identiﬁcation of the
robot structure as well as the kinematic model generation.
In doing so, model errors will be minimized and barriers-to-
use will be lowered. For developing plug-and-play RMRs,
modules should be able to self-identify: (i) the order in
which they are connected and (ii) how adjacent modules
are connected. There are in fact, self-reconﬁgurable modular
robots that are able to perform self-identiﬁcation of their
kinematic structures. They do so, through built-in sensors
that detect the adjacent modules and the connection between
modules. M-TRAN [2], uses IR communication between
neighboring modules to learn connection information. The
hardware solution (i.e. the use of additional built-in sensors)
increases the design complexity of the docking interface,
increases costs, and yet the information query is done infre-
quently. For industrial-oriented RMRs, reconﬁguration hap-
pens only occasionally (only when new tasks are given), so
the inclusion of additional built-in sensors is less preferred.
In this paper we study whether less costly alternatives exist
to autonomously identify the robot kinematic conﬁguration
and subsequently generate the kinematic model of the sys-
tem. To this end, we contribute a vision-based kinematic-
conﬁguration identiﬁcation system and an accompanying
kinematic model generation scheme for RMRs. Our work
places one or more markers (QR codes, laser engravings,
etc) in each module. Each marker has a unique ID. A camera
takes a picture of the modular robot. Markers are detected
by the marker tracking method and their poses are used to
estimate the poses of the modules. By querying the module
database, other information of the corresponding modules is
also available. Then with this set of detected modules and
their pose estimates, the kinematic structure grows by itera-
tively (i) ﬁnding the connected module for each module and
(ii) computing their connection parameters. After identifying
the modules and their connections, the robot kinematic chain
is constructed. Moreover, joint-modules’ joint angles are also
computed to better visualize the generated robot model. The
effectiveness of our approach is demonstrated by the correct
model generation of multiple robots with different kinematic
conﬁgurations or a robot at different conﬁgurations.

This paper is organized as follows: In Sec. II, the general
identiﬁcation framework for tree-type RMRs (chain type as
a special case) is introduced. Sec. III and Sec. IV detail
the implementation of our method speciﬁcally for our RMR
system. In Sec. III, terminology and representation of RMR
are introduced. In Sec. IV kinematic chain identiﬁcation and
model construction are described. In Sec. V experiments are
shown. In Sec. VI discussion of the topic is presented.

II. GENERAL FRAMEWORK OF KINEMATIC
CHAIN IDENTIFCATION

In our method, a camera is used to take images of a newly
built modular robot (see Fig. 2). AR-tag-tracking methods
(e.g. ar track alvar [9]) can be employed to detect marker
tags on a modular robot and estimate their poses.

Fig. 2: Each module is afﬁxed with AR tags. The camera
takes an image of the newly built modular robot, a manipu-
lator in this case, for identiﬁcation of the kinematic structure.
Then the robot model is constructed and visualized.

A module database maintains data of all module-types
and information of all fabricated modules. Querying the
module database with marker IDs retrieves information of
the corresponding modules, including the module-types and
communication IDs on the ﬁeld-bus.

Then the procedure of kinematic structure identiﬁcation
begins to ﬁnd all parent-child relations among detected
modules. In a pair of connected modules, the parent module
is the module that is closer to the base of the chain, and the
child is the remaining one. A tree-like kinematic structure has
one or more modules as its end-effectors, which are called
tool-modules, in order to perform useful operations.

An iterative algorithm will identify parent-child relations
to build the kinematic chain (see Fig. 3). The algorithm starts
by selecting a tool-module as a child and ﬁnding its parent.
For each succeeding cycle, parent modules become child
modules. The chain grows until no further parents are found.
This is considered a kinematic branch-chain. In cases, where
other branch-chains exist, those would be processed as well
resulting in an overall tree-structure for the modular robot.
For chain-like RMR systems, since there is only one branch
chain, the algorithm computes the chain in one pass.

As our approach deals with tree-type structures, the parent-
searching method avoids multiple results that appears in a
child-searching method, because in a tree-structure a module
might have multiple children.

One way to search for a parent module of a child is to
exploit the geometric constraints of all module-types, as we
will detail in Sec. IV.

Another alternative is to formulate the problem as an
optimization problem. In doing so, a more generalized frame-
work for different RMRs can be established. What’s more,
with a well-devised cost function, all variables needed to
extend the kinematic structure can be found simultaneously,
including the parent module, the connection and the state of
the parent. The dimension of optimization space does not
grow as the degrees of freedom of a modular robot increase,
because each time only variables of one module is optimized.
For two modules m1 and m2, relevant deﬁnitions are listed

Marker13Marker1Marker2Module RecognitionModel  ConstructionCamerachildparentKinematic Chain IdentificationMarker11Marker21Marker5gtTT’IiFig. 3: Kinematic sub-structures extend themselves by itera-
tively ﬁnding a parent module among detected modules for a
child. In the end, all sub-structures form an overall kinematic
structure of a modular robot.

in Table I.

TABLE I: NOMENCLATURE

M
tm1
Hm1
Om1xyz
θm1
cm1 ,m2
Nm1

a set that contains all modules types
module-type of m1, query from module database
detected pose of m1 as a homogeneous matrix
coordinate frame of Hm1
module state, e.g. a joint angle for a joint-module
connection variable between parent m1 and child m2
neighboring modules around m1

For most RMR systems, only ﬁnite possible connection
approaches between two modules are supported: cm1,m2 ∈
{c1, c2, · · · , cn}.

Given a child module, denoted as c, the algorithm tries to
ﬁnd out its parent p. To do so, ﬁrst, neighbors around c, Nc,
are found. The distance between a neighbor n and c must
not exceed the maximum distance between two connected
modules of any module-types and therefore satisﬁes Eqtn. 1:

Fig. 4: From left-to-right, we have two different types of
tool-modules that serve as grippers, followed by 4 joint-
module types. The ﬁrst two are simple cylinders that allow
for revolute rotations, the last two are composed of two
revolute joints and serve as T-connectors. They are denoted
as G, g, I, i, T and t.

where ◦ is element-wise product and a weighting matrix
W that adjusts weights for translational and orientation
differences.

The parent-searching procedure now can be expressed in

the form of an optimization problem:

min : F (T, T n
c )
variables : n, cn,c, θn

s.t. n ∈ Nc;

(4)

cn,c ∈ {c1, c2, · · · , cn};
θn ∈ [min(θtc), max(θtc)] .

n∈Nc

If min(F (T, T n
p = arg min

c )) is within a certain threshold, the parent
F (T, T n
c ) is found, as well as the connection
variable with its child and the parent state. This parent-
searching procedure extends the kinematic chain to next
module. And one module by another, the kinematic chain
can be completed.

(cid:13)
(cid:126)OnOc
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13) ≤ max(

(cid:13)
(cid:126)OpOc
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)) + (cid:15)1, ∀n ∈ Nc .

(1)

III. TERMINOLOGY AND REPRESENTATION OF
RE-CONFIGURABLE MODULAR ROBOTS

where (cid:15)1 is an error threshold.

For each neighbor n ∈ Nc, the transformation from n to
c is deﬁned as a homogeneous matrix T n
n Hc. If
n is the parent of c, i.e. p = n, a module state θn and a
connection variable cn,c that transforms the pose of c to that
of n can be found. This transformation is deﬁned as

c = H −1

T (cn,c, θc, tc, θn, tn) = T1(θc, tc)T2(cn,c)T3(θn, tn)

(2)

where T1, T2 and T3 denote respectively the transformations
relevant to child’s state, connection between parent and child,
and parent’s state.

In other words, if p = n, there is a θn and a cn,c that
c . A metrics F

allows T in Eqtn. 2 to theoretically equal T n
is devised for measuring the distance between T and T n
c :

F (T, T n

c ) = (cid:107)W ◦ (T − T n
c )(cid:107)2 ,

wo wo wo wt
wo wo wo wt
wo wo wo wt
0
0





0

0

.







W =

(3)

The following two sections will detail the implementation
of our method speciﬁcally for our RMR system in [3]. This
section introduces the representation of modules and modular
robots in [3].

A. Re-conﬁgurable Modular Robotic System

Our system and its design methodology are well presented
in [3]. Fig. 1 shows ﬁve robotic systems built with these
modules for different applications [3], [10], [11].

For joint-modules, upper-case letters T and I indicate I-
typed and T-typed joint-modules whose rotation axes are
collinear with and perpendicular to the link axes, respec-
tively. As for tool-modules, we use G, W and S to represent
respectively the gripper, wheel and suction modules. Fig. 4
shows some of these modules.

Smaller-sized modules are also developed. Using them
instead of larger ones near the end of a serial modular robot
help ease the torque requirement of its base module. These
modules are denoted with lower-case letters such as t, i and
g, which indicate the smaller version of T, I and G.

childparentneighborSub-chain1XSub-chain2Besides joint-modules and tool-modules, there are acces-
sory modules. Link modules are used to extend the distance
between two adjacent joint axes and are denoted as L or l.
Adapter linkage modules, denoted as A, are use to connect
larger modules with smaller modules.

Most of these modules can be installed in an inverted way
in a kinematic chain, i.e. the output link is closer to the base.
A single quote after the module-type letter indicates this type
of installation, e.g. T’.

B. Representation of Basic Modules

Each module-type is stored in the module database as
a Xacro format ﬁle that contains kinematic and dynamic
parameters, as well as transmission and motor speciﬁcations.
These Xacro ﬁles are named with the corresponding module-
type names.

Since the joint-modules can be installed into a kinematic
chain in an upside-down way, the terms input and output
are adopted only in the sense of where the driving motors
are placed. To address the problem of inverted installation of
modules, Xacro ﬁles of inverted modules are also created.

The usage of Xacro ﬁles incorporates other useful tools
from Robot Operating System (ROS) such as the general
inverse kinematics solver TRACK-IK [12].

C. Representation of Modular robots

With a database that stores Xacro ﬁles of all module-types,
we can develop a high-level abstraction of kinematic chains
of modular robots by specifying the following information:

1) constituent modules and their types,
2) the order of each module in the kinematic chain,
3) connectivity between a pair of adjacent modules (con-

nection angle c).

Besides, in order to better visualize the robot, we will also
estimate the robot state: 4) joint angles of joint-modules.

it

A text-based method is employed to implement this ab-
straction for our serial modular robotic system. The modular
manipulator in Fig. 1 is described with a string ”I-T0-T0-
A-i0-t180-g90”. And for the biped tree/truss climbing robot
Pole-Climbot in Fig. 1, it is ”G’-I0-T’0-L0-T’90-T180-I’0-
G0”. However,
is also appropriate to describe it with
”G’-I0-T’0-T’180-L’(-90)-T0-I’0-G0” because of its bipedal
locomotion behavior. These strings are organized in the order
from the bases of kinematic chains to the ends. The hyphens
are delimiters between adjacent substrings. Each substring
contains the module-type and the connection angle c in
degrees. The connection angle describes how a module is
connected to its parent module. Due to four pin holes on
the connection interface of each module, there are only four
possible connection angles: c ∈ {−90◦, 0◦, 90◦, 180◦}.

Once the above high-level parameters are speciﬁed, a
modular robot can be represented with an overall Xacro
ﬁle, which incorporates macros of the constituent modules
according to these parameters.

While straightforward enough for MRS designers, the text-
based method still requires users to manually specify the
robots structure, which is error-prone for users.

Fig. 5: A green rectangle represents the master marker of
the child module c while the red one represents that of the
parent p. The frame Ocxyz represents the input link’s pose
of c while Opxyz represents that of p. (cid:126)u is the unit vector
of

(cid:126)OpOc.

IV. KINEMATIC CHAIN IDENTIFICATION

To identify the aforementioned high-level parameters, we
propose a vision-based method. An open-source project
called ar track alvar [9] is employed to track AR tags on
modules.

A. Placement of Tags

Every module is afﬁxed with marker tags encoded with
unique IDs. The markers are placed on the surface of each
module such that at least one of them can be captured by
the camera while we seek to keep the number of markers
to minimum. Markers on the same rigid body are called a
”bundle”. The usage of multi-tags bundle allows to estimate
the pose of a multi-sided object, even when some of the tags
cannot be seen. One marker in each bundle is designated as
the master marker. The poses of the detected markers are
transformed into the pose of the master to represent that of
the object.

link and the other for the input

Each I-type module has two bundles, one for the out-
put
link. This allows
computing the joint angle θ using the difference be-
tween the poses of two linkages T in
in Hout =
Rot(yin, θ)T rans(yin, dis), where dis represents the trans-
lational distance between two poses.

out = H −1

For other module-types, only input links are attached with
tags in order to reduce the number of tags. For a T-type
module, the joint angle can be computed by comparing the
pose of its input link with that of the adjacent modules.

A virtual marker, locating at the center of each module
with its Y-axis collinear with the axis of input link, is desig-
nated as the master marker of the module. For each T-type
module, the Z-axis of the virtual master marker is collinear
with the joint axis. Using these virtual master markers to
represent poses of modules are convenient for calculating
high-level parameters. Now the Y-axis or its reverse of a
module is pointing to the parent module, with the only
exceptions of inverted T-type modules T (cid:48), t(cid:48). This allows
the use of a geometric method instead of the optimization
method for our system.

childparentB. Module Identiﬁcation Using Markers

follows:

The ID of each master marker on a module represents the
serial number of this module, which is unique and logged
in a database that maintains all product information of the
fabricated modules. The product information database also
manages all the module Xacro ﬁles.

Once the markers are detected, they are transformed to the
corresponding virtual master markers. By querying the mod-
ule database, the module-type, ID number on communication
bus and other information of each marker are available for
further computation.

C. Geometry Constraints

Our RMR system shows an obvious geometric characteris-
tic: the y-axis of a module’s pose usually points to or opposes
to its adjacent module, with exceptions when T-type modules
get involved. Therefore, a geometry-based method will be
more convenient for our implementation.

The markers tracking and database querying procedures
return the poses of constituent modules of a modular robot,
which must satisfy a series of geometry constraints. Some
useful constraints are deduced as below.

in

Here

some

deﬁne

symbols

for
installed

discussion. Modules
kinematic

convenience
of
upright
an
set
way
to
m = {T, t, I, i, G, g, W, S, L, , l, A}, while the inverted ones
belong to m(cid:48) = {T (cid:48), t(cid:48), I (cid:48), i(cid:48), G(cid:48), g(cid:48), W (cid:48), S(cid:48), L(cid:48), l(cid:48), A(cid:48)}. A
complete set of all module-types is deﬁned as M = m + m(cid:48).

the
in
belong

chain

the

the

Consider a pair of connected modules, parent module
p ∈ M and its child module c ∈ M , geometric constraints
between them can be organized as a constraint matrix CST
in Eqtn. 5 according to their module-types. Each element in
CST , cstp,c indicates the constraint set that corresponds to
the parent and child module-types.

CST =



cstT,T







cstt,T
...
csti(cid:48),T

cstT,t

cstt,t
...
· · ·

· · ·

· · ·
. . .
· · ·









.

cstT,i(cid:48)
...
...
csti(cid:48),i(cid:48)

(5)

As illustrated in Fig. 5, the frame Opxyz represents the input
link’s pose of the parent module while Ocxyz represents that
of the child. (cid:126)u is the unit vector of

(cid:126)OpOc.
implementation, only some handy con-
straints, denoted as cst, are used and they are listed as

For practical

(cid:13)
(cid:13)
(cid:13)p,c∈M

) + (cid:15)1 .

(6)

cst1 :

(cid:13)
(cid:126)OpOc
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:126)OpOc
(cid:13)
(cid:13)
(cid:13) ≤ max(
(cid:13)
cst2 : | (cid:126)yp · (cid:126)u| ≥ 1 − (cid:15)2 .
cst3 : | (cid:126)yc · (cid:126)u| ≥ 1 − (cid:15)2 .
cst4 : (cid:126)yp · (cid:126)u ≥ 0 .
cst5 : (cid:126)yp · (cid:126)u < 0 .
cst6 : (cid:126)yc · (cid:126)u ≥ 0 .
cst7 : (cid:126)yc · (cid:126)u > 0 .
cst8 : p ∈ m .
cst9 : p ∈ m(cid:48) .
cst10 : c ∈ m .
cst11 : c ∈ m(cid:48) .

thresholds

error
where
(cid:13)
(cid:13)
(cid:126)OpOc
(cid:13)
(cid:13)
max(
(cid:13)p,c∈M
(cid:13)
summed up in Table II for short.

are

(cid:15)1 (cid:28)
deﬁned
), (cid:15)2 (cid:28) 1. These constraints are

as:

TABLE II: Geometric constraints of a pair of connected
modules.

child \ parent

p (cid:54)∈ {T, t}

c (cid:54)∈ {T (cid:48), t(cid:48)}

c ∈ {T (cid:48), t(cid:48)}

if cst4
if cst5
if c4
if cst5

cst1, 2, 3, 8
cst1, 2, 3, 9
cst1, 2, 8
cst1, 2, 9

p ∈ {T, t}

if cst6

if cst7

cst1, 10

cst1, 11

cst1

By looking up the above table, the parent module can be
selected among the neighbors. Note that though Table II is
an incomplete table for CST , e.g. {cst1, cst2, cst3, cst8} ∈
cstt,g(cid:48)|c4 , it’s useful for ﬁnding parent-child relations in a
kinematic chain.

Once the parent module is found, the relative pose T p
c
is exploited for calculating the connection angle cp,c and
joint angle of parent θp. For connection angle cp,c ∈
{−90◦, 0◦, 90◦, 180◦}:

cp,c = discretize(ˆcp,c) ;

(cid:40)

ˆcp,c =

arccos( (cid:126)zp · (cid:126)zc)
− arccos( (cid:126)zp · (cid:126)zc)

, if (cid:126)zp × (cid:126)zc · (cid:126)u ≥ 0
, if others

(7)

D. Kinematic Chain Construction

After setting up the physical modular robot, the users
launch the robot identiﬁcation program to start procedures
illustrated in Fig. 6.

By querying the module database, the algorithm examines
all detected markers for their validity and, if valid, retrieves
their module information. False positives are eliminated
while valid markers remain and are exploited to build the
kinematic chain.

Tool-modules are used as the end-effectors. The procedure
of kinematic chain identiﬁcation starts from the ﬁrst detected
tool-modules and grows along the chain to the base module.
In the biped climbing robot, two tool-modules are used,
either of which can be regarded as the end of the kinematic
chain.

marker detection

database

markers

query database on a marker

next
marker in
markers

no

marker
on end-
effector?

yes

kinematic chain construction

chainList

robot description generation

calculate joint angles

joint angles

model visualization

Fig. 6: Flowchart of the modular robot identiﬁcation.

Once the end module is found, its pose is used for ﬁnding
its parent module and calculating the connection parameter
according to the geometric constraints in Table II. This
process continues iteratively until all identiﬁed modules ﬁnd
their place in the kinematic chain. A recursive algorithm,
see Line 14 in Alg. 1, is designed for the process. Note that
chainList in Alg. 1 returns the kinematic chain in the order
from base to end.

After identifying the kinematic chain, the joint angles are
computed for robot model visualization, which allows the
users to intuitively conﬁrm the result. Robot speciﬁcation
ﬁles, as well as ﬁles for control, are also generated. The
generated ﬁles are essential for our ROS-based control
software, which aims to provide a programming framework
for modular robots. Our work on robot model identiﬁcation
paves the path towards the goal of kinematic-conﬁguration-
agnostic programming for modular robots.

V. EXPERIMENTS

In our method, only a camera is needed. To be speciﬁc,
a Kinect is used in Fig. 7, but any common camera can
be used. Currently AR tags are used, however we envision
our modules being marked through laser engravings during
fabrication.

Four tests were carried out, as illustrated in Fig. 8. Our
algorithm successfully identiﬁed the kinematic chains and
computed the joint angles. In each sub-ﬁgure, the left part
shows an image of a modular robot, taken by the camera,

Fig. 7: Experimental set-up for modular robot identiﬁcation.
Only a camera is needed in our method.

(a) Modular manipulator.

(b) Modular manipulator at a different conﬁgurations.

(c) Modular manipulator of different kinematic conﬁguration.

(d) Biped climbing modular robot.

Fig. 8: Three modular robots were tested. The ﬁrst two ex-
periments used the same robot but at different conﬁgurations.
Despite the existence of false marker detection, the algorithm
could identify the kinematic chains and compute the joint
angles for visualization.

CameraModular robotMarkersFalse detectionAlgorithm 1 Kinematic chain construction

1: Initialize chainList
2: childM arker ← markerOnEndEf f ector
3: function BUILDCHAIN(childM arker, markers)
4:
5:

if markers is empty then

return

6:
7:
8:
9:
10:
11:

end if
for all marker ∈ markers do

if marker is parent of childM arker then

Find connect angle cp,c, install direction d.
Remove marker from markers.
break for loop

end if

12:
13:
14:
15:
16: end function

end for
BuildChain(marker, markers)
Append [marker, cp,c, d] to chainList.

(cid:46) recursion

while the middle and the right columns illustrate the resulting
model, which are constructed on-the-ﬂy.

The ﬁrst two experiments, shown in Fig. 8a and Fig. 8b,
used the same modular manipulator, but at two different
conﬁgurations. They both shared a same kinematic chain: I-
T’0-T’0-A0-t0-i0-g0. The third experiment identiﬁed another
modular manipulator with a kinematic chain I-T’0-T0-A0-i0-
t0-g0. The robot in Fig. 8d is not a manipulator, but a bipedal
climbing robot: G’-I0-T’0-L0-T’0-0T-0I’0-G0, showing that
the proposed method can be applied to bi-directional kine-
matic chains such biped robots.

Though kinematic chains were correctly identiﬁed, joint
angle estimations were not precise due to the errors of tag
placement on the module and the detection errors. Some
false detections appeared in Fig. 8b and Fig. 8d. They were
eliminated as they failed to match the information stored in
the module database, or couldn’t ﬁnd any parent or child.

VI. DISCUSSION AND CONCLUSION

In this paper we showed that kinematic-conﬁguration
identiﬁcation and automatic kinematic model generation can
be done on the ﬂy by using a vision-based scheme and a
geometric mathematical model of serial-chain systems.

Reconﬁgurability brings great advantages and also chal-
lenges, comparing to robots with ﬁx-morphology. The soft-
ware of RMR systems is supposed to support features corre-
sponding to the reconﬁgurability. The rapid development of
robot middlewares provides useful tools for implementation
of software for RMRs. Xacro ﬁles, widely used in ROS,
can be used to represent different types of modules as XML
macros. Generic kinematic solvers such as TRACK-IK and
IKFast, with properly speciﬁed kinematic structures, provide
kinematic solutions for robots. These can greatly simplify
the painstaking construction process of kinematic models,
assuming that the kinematic chain is known or manually
speciﬁed.

To identify the kinematic structures of modular robots
allows full automation of the model construction process. We

proposed a vision-based scheme for kinematic conﬁguration
identiﬁcation and model construction of RMR in this paper.
Each module is afﬁxed with AR tags, which can be laser-
engraved on the module shell during fabrication. A camera
is used for tracking these markers, whose poses and IDs are
used for computing the kinematic chain and joint angles.
Finally, the constructed models are visualized for validation.
All the above procedures are done on-the-ﬂy. Comparing
to solutions that use built-in sensors or other mechatronic
device in each module, our method is of lower-cost and can
be applied to other modular robotic systems in which self-
identiﬁcation is not possible.

In the further, in order to thoroughly address the occlusion
problem, a hand-held camera can be employed to scan a
robot while a multi-view geometry algorithm keeps tracking
all marker poses. What’s more, our ultimate goal is a system
that allows kinematic-conﬁguration-agnostic programming
for RMR systems, i.e. programming is not speciﬁcally for
a particular modular robot but for all possible ones.

VII. ACKNOWLEDGMENTS
This work is supported by the grants: ”Major Project
of the Guangdong Province Department for Science and
Technology (2014B090919002), (2016B0911006).”

REFERENCES

[1] A. Sprowitz, R. Moeckel, M. Vespignani, S. Bonardi, and A. J. Ijspeert,
“Roombots: A hardware perspective on 3d self-reconﬁguration and
locomotion with a homogeneous modular robot,” Robotics and Au-
tonomous Systems, vol. 62, no. 7, pp. 1016–1033, 2014.

[2] H. Kurokawa, K. Tomita, A. Kamimura, S. Kokaji, T. Hasuo, and
S. Murata, “Distributed self-reconﬁguration of m-tran iii modular
robotic system,” The International Journal of Robotics Research,
vol. 27, pp. 373–386, 2008.

[3] Y. Guan, L. Jiang, and X. Zhang, “Development of novel robots
with modular methodology,” in Ieee/rsj International Conference on
Intelligent Robots and Systems, 2009, pp. 2385–2390.

[4] I. M. Chen, H. Y. Song, G. Chen, and G. Yang, “Kernel for modular
robot applications: Automatic modeling techniques,” International
Journal of Robotics Research, vol. 18, no. 2, pp. 225–242, 1999.
[5] R. Bischoff, J. Kurth, G. Schreiber, R. Koeppe, A. Albu-Schaeffer,
A. Beyer, O. Eiberger, S. Haddadin, A. Stemmer, and G. Grunwald,
“The kuka-dlr lightweight robot arm - a new reference platform for
robotics research and manufacturing,” in Isr/robotik 2010, Proceedings
for the Joint Conference of Isr, 2010, pp. 1–8.

[6] J. Baca, S. G. M. Hossain, P. Dasgupta, C. A. Nelson, and A. Dutta,
“Modred: Hardware design and reconﬁguration planning for a high
dexterity modular self-reconﬁgurable robot for extra-terrestrial explo-
ration,” Robotics & Autonomous Systems, vol. 62, no. 7, pp. 1002–
1015, 2014.

[7] M. Yim, W. M. Shen, B. Salemi, and D. Rus, “Modular self-
reconﬁgurable robot systems [grand challenges of robotics],” IEEE
Robotics & Automation Magazine, vol. 14, no. 1, pp. 43–52, 2007.
[8] T. Collins and W. M. Shen, “Rebots: A drag-and-drop high-
performance simulator for modular and self-reconﬁgurable robots.”
[Online]. Available: http://www.isi.edu/publications/trpublic/pdfs/isi-
tr-714.pdf
[9] S. Niekum,
[Online;
https://github.com/sniekum/ar track alvar

2012,
Available:

9-February-2017].

“ar track alvar

repository,”

[Online].

accessed

github

–

[10] Y. Guan, X. Shi, X. Zhou, X. Zhang, and H. Zhang, “A novel mobile
robot capable of changing its wheel distance and body conﬁguration,”
in International Conference on Robotics and Biomimetics, 2009, pp.
806–811.

[11] Y. Guan, H. Zhu, W. Wu, X. Zhou, L. Jiang, C. Cai, L. Zhang,
and H. Zhang, “A modular biped wall-climbing robot with high
mobility and manipulating function,” IEEE/ASME Transactions on
Mechatronics, vol. 18, no. 6, pp. 1787–1798, 2013.

[12] P. Beeson and B. Ames, “Trac-ik: An open-source library for improved
solving of generic inverse kinematics,” in IEEE RAS Humanoids
Conference, 2015, pp. 928–935.

