0
2
0
2

r
a

M
1
3

]
T
S
.
h
t
a
m

[

1
v
8
3
9
3
1
.
3
0
0
2
:
v
i
X
r
a

On the the linear processes of a stationary time series AR(2)

Mouloud Goubi

Abstract. Our aim in this work is to give explicit formula of the linear pro-
cesses solution of autoregressive time series AR(2) with hint of generating
functions theory by using the Horadam numbers and polynomials.

1. Introduction

The time series (see [1]) we observe are the realizations of Random vari-
ables Y1, · · · , Yt which are a part of a larger stochastic process {Yt; t ∈ Z}. Let
{Yt; t ∈ Z} a zero-mean time series. Consider H the Hilbert space spanned by the
Random variables Yt with inner product

and the norm

hX, Y i = E(X, Y )

kXk =

E(X 2).

p
The mean function of a time series is deﬁned by µ(t) = E(Yt) and the auto-
covariance function is given by γ(s, t) = cov (Ys, Yt). The mean and the auto-
covariance functions are fundamental parameters and it would be useful to obtain
sample estimates of them. For general time series there are 2t + t(t−1)
parameters
associated with Y1, · · · , Yt and it is not possible to estimate all these parameters
from t data values. To make any progress we consider the times series is stationary.

2

On general a times series Yt is strictly stationary if for k > 0 and any t1, · · · , tk
of Z, the distribution of (Yt1 , · · · , Ytk ) is the same as that for (Yt1+u, · · · , Ytk+u)
for every u. If Yt is stationary then µ(t) = µ and γ(s, t) = γ(s − t, 0). We say Yt
is weakly stationary if E(Y 2
t ) < ∞, µ(t) = 0 and γ(t + u, t) = γ(u, 0). When time
series are stationary it is possible to simplify the parameterizations of the mean
and auto-covariance functions. In this case we can deﬁne the mean of the series to
be µ = E(Yt) and the autocovariance function to be γ(u) = cov (Yt+u, Yt).
If the random variables which make up Yt are uncorrelated, have means 0 and

2010 Mathematics Subject Classiﬁcation. Primary 62M10 Secondary 05A15.
Key words and phrases. Linear processes; time series; generating functions; Horadam num-

bers; Horadam polynomials.

1

 
 
 
 
 
 
2

MOULOUD GOUBI

variance σ2 (are so called white-noise series). Then Yt is stationary with auto-
covariance function

(1.1)

γ(u) =

σ2
0

(cid:26)

if u = 0,
otherwise.

2. Autoregressive series

If the time series Yt satisﬁes the identity

(2.1)

Yt = φ1Yt−1 + · · · + φpYt−p + ǫt

where ǫt is white noise and φu are constants, then Yt is called an autoregressive
series of order p and denoted by AR(p). These series are important, it explain how
the next value observed is a slight perturbation of a simple function of the most
recent observations. The solution; if exist in the form

∞

Yt =

φuǫt−u

Xu=0

∞
u=0 |φn|2 < ∞ to assure the con-
is called a linear processes with the condition
vergence of the last series in H. The lag operator L for a time series Yt is deﬁned
by

P

and is linear. The last relation (2.2) can be written in the form

(2.2)

Yt = φ1L(Yt) + · · · + φpLp(Yt) + ǫt.

L(Yt) = Yt−1

To found Yt, we write

If the operator 1 + φ1L + · · · + φpLp is bijective we then write

1 + φ1L + · · · + φpLp
(cid:0)

(Yt) = ǫt.
(cid:1)

Yt = (1 − φ1L − · · · − φpLp)

−1 ǫt.

−1 ǫt
The linear processes of AR(1) is completely known. We have Yt = (1 − L)
u>0 |φ1|2n < ∞, which means that
then Yt =
|φ1| < 1. An equivalent condition is that the root of the equation 1 − φ1z = 0 lies
P
outside the unit circle in the complex plane C.

1 ǫt−u with the condition

u>0 φu

P

The AR(2) model is deﬁned by Yt = φ1L(Yt) + φ2L2(Yt) + ǫt. Then we write

Yt =

1 − φ1L − φ2L2
(cid:0)

−1

ǫt. The decomposition gives

(cid:1)
1 − φ1L − φ2L2 = (1 − c1L) (1 − c2L) .

We can invert the operator if we can invert each factor separately. This is possible
if and only if |c1| < 1 and |c2| < 1, or equivalently, if the roots of the polynomial
1 − φ1z − φ2z2 lie outside the unit circle. But from the symmetric relations of the
roots we have c1 + c2 = φ1 and c1c2 = φ2. The strong conditions of convergence
are |φ1| < 2 and |φ2| < 1.

LINEAR PROCESSES/ M. GOUBI

3

In this work we are interested by times series belong to AR(2) respecting the
conditions |φ1| < 2 and |φ2| < 1. The linear processes Yt can be computed by
two diﬀerent methods. The ﬁrst expression; well-known by the statisticians which
consist to compute each AR(1) separately and take the product. We reproduce it
directly by the following theorem.

Theorem 2.1.

(2.3)

Yt =

∞

u

Xu=0

Xk=0

1 (φ2/φ1)k ǫt+k−uǫt−k.
φu

The identity (2.3) is interesting, but the second member of the equality contains
the product of two white noise ǫt. Then it is not as the standard form of linear
processes. To escape this problem the second way is given by the following theorem.

Theorem 2.2.

∞

⌊ u

2 ⌋

(2.4)

Yt =



u − k

(cid:18)

k (cid:19)

Xk=0

φ2/φ2
1
(cid:0)

k
(cid:1)




Xu=0




φu
1 ǫt−u.

The condition |φ1| < 2 and |φ2| < 1 for the convergence of the linear processes

Yt on H can be replaced by the condition

⌊ u

2 ⌋



Xu>0

Xk=0

u − k

(cid:18)

k (cid:19)

φ2/φ2
1
(cid:0)

k
(cid:1)

2

φ2u
1 < ∞.



1 in the expression (2.4) Theorem 2.2; the following corollary is




Letting φ2 = φ2
immediate.

Corollary 2.1.

∞

⌊ u

2 ⌋

(2.5)

Yt =

Xu=0






u − k

(cid:18)

Xk=0

k (cid:19)



φu
1 ǫt−u.




(see [2]) occurs an important place in combinatorics. It is a
The symbol
(cid:0)
particular case of
which is the number of k-blocks P ⊂ [u] = {1, 2, · · · , n}
with the following property; between two arbitrary points of P are at least l points
(cid:0)
of [n] which do not belong to P .

(cid:1)

u−k
k
u−(k−1)l
(cid:1)
k

2.1. Proof of main results. From the decomposition 1 − φ1L − φ2L2 =

(1 − c1L) (1 − c2L) . we conclude that

Yt = 

φu
1 ǫt−u



φu
2 ǫt−u

Xu>0



Xu>0







Use Cauchy product of series to get the desired result (2.3) Theorem 2.1. For more
details about this technique we refer to [4].

4

MOULOUD GOUBI

The proof of second theorem needs use techniques from generating functions

theory ( see [3]). We consider

1
1 − φ1xz − φ2z2 =

Au(x)tu.

Xu>0

where Au(x) is a polynomial of degree u to compute. Write f (x, z) =
then

1
1−φ1xz−φ2z2

f (x, z) = 1

1 − φ1xz − φ2z2
(cid:0)

(cid:1)
An(x)zn+1 − φ2

Au(x)zn − φ1x

Au(x)zn+2 = 1

Xu>0

Xu>0

Au(x)zn − φ1x

Au−1(x)zu − φ2

Au−2(x)zu = 1

Xu>1

Xu>2

and

Thus

and

Xu>0

Xu>0

A0(x) + (A1(x) − φ1xA0(x)) z +

(Au(x) − φ1xAu−1(x) − φ2Au−2(x)) zu = 1

Xu>2

Since this entire series is constant we deduce that A0(x) = 1, A1(x) = φ1x and
others are given by the recursion relation

(2.6)

Au(x) = φ1xAu−1(x) + φ2Au−2(x).

These polynomials are well-known and so called Horadam polynomials. G. B.
Djordjevi´c and G. V. Milovanovi´c (see [3]) provide the following explicit represen-
tation

Au(x) =

⌊ u

2 ⌋

Xk=0

φk
2

(u − k)!
k!(u − 2k)!

(φ1x)u−2k .

Letting x = 1 we obtain Horadam numbers An these are written by the form

Au = φu
1

⌊ u

2 ⌋

Xk=0

(u − k)!
k!(u − 2k)!

φ2/φ2
1
(cid:0)

k

.

(cid:1)

and admit for generating function

(2.7)

1
1 − φ1t − φ2t2 =

Autu.

Xu>0

Numbers An can be deﬁned from the following recursion relation

Au = φ1Au−1 + φ2Au−2, n > 2

with A0 = 1 and A1 = φ1. Instead of z we take the operator L and it is obvious to
obtain the identity (2.4) Theorem 2.2.

LINEAR PROCESSES/ M. GOUBI

5

References

[1] P. J. Brockwell and R.A. Davis, Introduction to Time Series and Forecasting, Springer 2002.
[2] L. Comtet, Advanced combinatorics D. Riedel Publishing Company Boston USA 1974.
[3] G. B. Djordjevic and G. V. Milovanovic, Special Classes of Polynomials, University of Ni,

Faculty of Technology, Leskovac, 2014.

[4] M. Goubi, Successive derivatives of Fibonacci type polynomials of higher order in two vari-

ables, Filomat 32(4) (2018), pp. 5149–5159.

Mouloud Goubi, Department of Mathematics, University of UMMTO RP. 15000,

Tizi-ouzou, Algeria, Laboratoire d’Alg`ebre et Th´eorie des Nombres, USTHB Alger

E-mail address: mouloud.goubi@ummto.dz

