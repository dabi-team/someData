1
2
0
2

r
a

M
6
1

]

A
F
.
h
t
a
m

[

5
v
8
4
7
8
0
.
2
1
7
1
:
v
i
X
r
a

Cointegration and Representation of

Cointegrated Autoregressive Processes in Banach Spaces

Won-Ki Seo

School of Economics, University of Sydney

March 17, 2021

Abstract

0, 1
[

We extend the notion of cointegration for time series taking values in a potentially inﬁnite dimen-
sional Banach space. Examples of such time series include stochastic processes in C
equipped with
the supremum distance and those in a ﬁnite dimensional vector space equipped with a non-Euclidean
distance. We then develop versions of the Granger-Johansen representation theorems for I(1) and I(2)
autoregressive (AR) processes taking values in such a space. To achieve our goal, we ﬁrst note that an
AR(p) law of motion can be characterized by a linear operator pencil via the companion form repre-
sentation, and then study the spectral properties of a linear operator pencil to obtain a necessary and
sufﬁcient condition for a given AR(p) law of motion to admit I(1) or I(2) solutions. These operator-
theoretic results form a fundamental basis for our representation theorems. Furthermore, it is shown that
our operator-theoretic approach is in fact a closely related extension of the conventional approach taken
in a Euclidean space setting. Our theoretical results may be especially relevant in a recently growing
literature on functional time series analysis in Banach spaces.

]

1 Introduction

Conventionally, the subject of time series analysis is time series taking values in ﬁnite dimensional Euclidean

space. On the other hand, a recent literature on functional time series analysis deals with time series taking

values in a possibly inﬁnite dimensional Banach or Hilbert space, for instance, those in C

equipped

with the supremum norm. Examples of such time series are not restricted to function-valued stochastic

0, 1
]

[

processes: those in a ﬁnite dimensional vector space equipped with a non-Euclidean metric, such as e.g.

Chebyshev distance or taxicab distance, are also included.

The property of cointegration, which was introduced by Granger (1981) and has been studied in Eu-

clidean space, was recently extended to a more general setting. A recent paper by Chang et al. (2016b)

appears to be the ﬁrst to consider the possibility of cointegration in an inﬁnite dimensional Hilbert space.

More recently, Beare et al. (2017) adopted the notion of cointegration from Chang et al. (2016b) and pro-

vided a rigorous treatment of cointegrated linear processes taking values in Hilbert spaces.

The Granger-Johansen representation theorem is the result on the existence and representation of I(1)

(and I(2)) solutions to a given autoregressive (AR) law of motion. Due to crucial contributions by e.g.

1

 
 
 
 
 
 
Engle and Granger (1987), Johansen (1991, 1992, 1995, 2008), Schumacher (1991), Hansen (2005), Faliva and Zoia

(2002, 2010, 2011, 2021), and Franchi and Paruolo (2016, 2019), much on this subject is already well

known in a Euclidean space setting. For a brief historical overview of this topic, see the introduction of

Beare and Seo (2020). More recently, Chang et al. (2016a), Hu and Park (2016) and Beare et al. (2017) ex-

tended the Granger-Johansen representation theorem for the I(1) case to a more general Hilbert space setting.

Furthermore, Beare and Seo (2020) provided representation theorems for I(1) and I(2) AR processes in such

a setting based on analytic operator-valued function theory, and Franchi and Paruolo (2020) developed a
more general result for I(d) AR processes for d ≥ 1.

This paper provides a suitable notion of cointegration and extends the Granger-Johansen representation

theorem for Banach-valued, not necessarily Hilbert-valued, AR processes that are I(1) or I(2); that is, our
0, 1
theory can be applied to more general AR processes, for instance, those taking values in C
]
for 1 ≤ q < ∞, or any ﬁnite dimensional vector space equipped with an arbitrary norm. Viewed in the
light of our purpose, our representation theorems need to be developed without relying on the following two

0, 1
]

, Lq

[

[

preconditions commonly required in the literature: (i) a Hilbert space structure and (ii) a special restriction

on the AR polynomial. To see this in detail, we brieﬂy review the relevant literature. For a given AR(p) law
= I − zΦ1 − . . . − zpΦp,
of motion in a Hilbert space, which is characterized by the AR polynomial Φ
Beare et al. (2017) assume that Φ1, . . . , Φp are compact operators when p > 1 (this compactness assumption
is not required if p = 1), and provide a sufﬁcient condition for the existence of I(1) solutions and a charac-
terization of such solutions. In their representation theory, compactness of Φ1, . . . , Φp makes Φ
belong
to a special subclass of linear operators, called Fredholm operators, and the mathematical properties of such

z

z

)

(

)

(

operators play an important role. More representation theorems in a Hilbert space setting are provided by
Hu and Park (2016), Beare and Seo (2020) and Franchi and Paruolo (2020), among which the latter paper
more generally deals with I(d) AR(p) processes for d ≥ 1 and p ≥ 1. The representation theorems in
those papers are closely related to that provided by Beare et al. (2017) in the sense that Fredholmness of
Φ

has a crucial role in their developments. The Fredholm assumption explicitly or implicitly employed

z

(

)

in the foregoing papers turns out to place nontrivial restrictions on solutions to the AR(p) law of motion:

nonstationarity of such a solution is driven by a necessarily ﬁnite dimensional unit root process even in an

is a compact operator and provide an I(1) representation result. As opposed to the results under

inﬁnite dimensional setting. From another standpoint, Chang et al. (2016a) employ a different assumption
that Φ
1
)
Fredholmness of Φ
ated with an inﬁnite dimensional unit root process unless the considered Hilbert space is ﬁnite dimensional.

, it turns out that their compactness assumption always leads to I(1) solutions associ-

z

)

(

(

To brieﬂy sum up, all of these existing versions are developed in a Hilbert space setting, and each of those
relies on a special requirement about Φ
way. We thus need a novel approach to overcome these limitations in our more general setting.

which restricts solutions to the AR(p) law of motion in a speciﬁc

z

(

)

To accomplish our goal, we ﬁrst introduce a suitable notion of cointegration in Banach spaces by deﬁning

a cointegrating functional that properly generalizes the conventional notion of a cointegrating vector. We

then characterize the cointegrating space (to be deﬁned as the collection of cointegrating functionals) based

on the Phillips-Solo device (Phillips and Solo, 1992) applied to operator-valued functions. After doing that,

representation theorems for I(1) and I(2) AR processes taking values in a Banach space are provided. Our

2

representation theory is derived under more primitive and weaker mathematical conditions in a general

Banach space setting where we do not even have the notion of an angle (inner product) between two vectors.

From Johansen (1991, 1992) to the foregoing recent papers, it seems that some geometrical properties

induced by an inner product, such as orthogonality, have been thought to be essential for the representation

theory. However, it will be clariﬁed in this paper that such a richer geometry is not necessarily required: in

our representation theory, geometrical properties induced by an inner product have no essential role.

To obtain our representation theorems, we ﬁrst note that an AR(p) law of motion in a Banach space

)

(

z

. By studying
−1

allows the companion form AR(1) representation in a properly deﬁned product Banach space, and it is thus
characterized by a linear operator pencil (to be introduced in detail later) denoted by ̃Φ
the spectral properties of a linear operator pencil, we ﬁnd necessary and sufﬁcient conditions for ̃Φ
−1 near z = 1. These
to have a pole of order 1 and 2, and also obtain a local characterization of ̃Φ
(
operator-theoretic results not only determine the integration order of solutions to the AR(p) law of motion,
around z = 1; that is,
but also lead us to a representation of such solutions in terms of the behavior of ̃Φ
our versions of the Granger-Johansen representation theorems for I(1) and I(2) AR processes are obtained.
The fact that solutions to the AR(p) law of motion are characterized in terms of a local behavior of ̃Φ
(
rather than the original AR polynomial Φ
in a Hilbert/Euclidean space setting. We thus provide further representation results so that important char-
acteristics of I(1) or I(2) solutions are expressed in terms of linear operators associated with Φ
. To this
−1 to have a pole of order 1 (resp. 2)
end, we ﬁrst show that our necessary and sufﬁcient condition for ̃Φ
is equivalent to a natural generalization of the well known Johansen I(1) (resp. I(2)) condition, and then we

)
, makes it difﬁcult to compare our results to those developed

z

z

z

z

z

z

z

(

(

)

(

(

)

)

)

(

)

)

,

recharacterize solutions to the AR(p) law of motion in a desired way using those equivalent conditions. By
this further effort, not just we can obtain a more detailed characterization of such solutions but also we can

better clarify the connection between our representation results and those in the existing literature.

We structure the remainder of the paper as follows.

In Section 2, we develop a suitable notion of

cointegration in Banach spaces and provide some related results. Our representation theory for I(1) and I(2)

AR processes are contained in Section 3, and concluding remarks follow in Section 4. Appendix A reviews

background material for our study, and Appendix B collects the proofs of our main results.

2 Cointegration in Banach spaces

{

{

}

Xt

Xt

β⊺Xt

Let
exists a nonzero vector β ∈ Rn such that
that

t≥0 be an I(1) time series taking values in Euclidean space of dimension n, denoted by Rn. If there
t≥0 is stationary under a suitable choice of X0, we then say
t≥0 is cointegrated with respect to β, and call β a cointegrating vector; see e.g. Johansen (1995,
Deﬁnition 3.4). In this conventional deﬁnition of cointegration, β itself acts as a scalar-valued map deﬁned
on Rn, and what makes β a cointegrating vector is stationarity of scalar-valued time series
t≥0. We
thus may understand cointegration as a property of scalar-valued maps deﬁned on Rn, which leads to the
following alternative deﬁnition.

β⊺Xt

{

}

}

}

{

Deﬁnition 2.1. For an I(1) time series
functional on Rn), if
is cointegrated with respect to f , and call f a cointegrating functional.

Xt

Xt

)}

f

{

{

}

(

t≥0 can be stationary under a suitable choice of X0, then we say that

t≥0 and any scalar-valued linear map f deﬁned on Rn (i.e.,

Xt

{

t≥0

}

3

In fact, the above deﬁnition is equivalent to the conventional one due to the Riesz representation theorem
(see e.g., Conway, 1994, p. 13), implying that any functional f on Rn is uniquely identiﬁed as a vector β
= β⊺x for all x ∈ Rn. Nevertheless, deﬁning cointegration as in Deﬁnition
in the following sense: f
2.1 is advantageous especially when we consider a more general vector space; as will be shown, we may
replace Rn with a separable complex Banach space B without a serious theoretical complication, and then
may obtain a suitable notion of cointegration in B.

x

)

(

Throughout this section, we formally introduce cointegrated I(1) and I(2) processes taking values in a
Banach space and characterize the collection of cointegrating functionals. Prior to a detailed mathematical

treatment of those, it may be helpful to see an example of functional time series of economic or statistical

interest that can motivate our more general setting.

2.1 Example : Banach-valued time series and cointegration

Our more general setting is of central relevance for applications involving functional time series. As men-

tioned and analyzed in Horv´ath et al. (2010) and H¨ormann et al. (2013), possibly one of the most natu-
ral functional time series is a sequence of intraday price curves of a ﬁnancial asset. Let Xt
price of a ﬁnancial asset at time s ∈
smin, smax
, u ∈
, Xt ≔
u =
u
smax − smin
)
0, 1
the Banach space of continuous functions on
]

on day t ∈
]
0, 1
0, 1
[
]
equipped with the usual sup norm. Linear functionals

may be viewed as a random element in C

. By reparametrizing s into

reveal various characteristics of Xt. For example, consider f1, f2, and f3 deﬁned by

deﬁned on C

s − smin

1, 2, . . .

be the

[
Xt

)/(

]}

{

{

}

s

)

(

)

(

(

[

[

,

[

0, 1
]
f1

,

x

= x

1
)
)
(
0, 1
. Then, f1
]
gives their difference.

(

[

(

where x ∈ C
f3

Xt

)

f2

x

=

(
)
(resp. f2

∫
0
Xt

(

)

1

1

x

du,

u
)

f3

x

= x

−

1
)

∫

x

du,

u
)

(
) computes the closing (resp. average) price on day t, and

)

(

(

(

0

(2.1)

(

)

Xt
We may assume that price curves observed on two adjacent days, Xt−1 and Xt, are tightly connected
≔

in the sense that Xt
Xt
− Xt−1
on day t. For illustrative purposes, we may model such a sequence returns as follows: for some stationary

or loosely connected in the sense that an overnight jump νt

= Xt−1
is allowed. In either case,

denotes cumulative intraday returns

− Xt−1

1
)}

0,1
]
[

u
)

0
)

1
)

1
)

0
)

0
)

Xt

u∈

{

(

(

(

(

(

(

(

process

t≥0,1

νt

{

}

Xt

u
)

(

− Xt−1

1
)

(

= νt

u
)

(

,

u ∈

,

0, 1
]

[

{

νt

1
)}

where
linear operator Φ1 deﬁned by Φ1
u
)
convenience, (2.2) can be written as a curve-valued AR(1) process as follows,

t≥0 is assumed to have a positive variance for reasons to become apparent. By introducing a
0, 1
and then suppressing dependence on u for
]

for u ∈

1
)

= x

)(

x

(

(

(

[

If we take the functional f1 to both sides of (2.2), we obtain

Xt = Φ1Xt−1 + νt.

(2.2)

(
1An empirical evidence about stationarity of cumulative stock return curves of a ﬁnancial asset was provided in Horv´ath et al.
(2010); however, we need to be careful in interpreting such evidence in our context since their results are obtained by viewing
2
intraday price curves as random elements of the usual Hilbert space L

rather than C

(

(

.

0, 1
]

[

0, 1
]

[

Xt

1
)

= Xt−1

+ νt

1
)

.

1
)

4

That is, the time series of closing prices

f1
{
fore,
t≥0 is a nonstationary curve-valued process; if it were stationary,
{
since f1 is a continuous linear transformation. On the other hand, note that

t≥0 is a random walk with stationary increments. There-
t≥0 would be stationary

Xt

Xt

Xt

f1

)}

)}

{

}

(

(

Xt

f3

(

)

= f3

νt

,

)

(

f3

Xt

from which we ﬁnd that
t≥0
is stationary. That is, f3 transforms the curve-valued nonstationary process
t≥0 into a scalar-valued
stationary process. In view of Deﬁnition 2.1, f3 may be called a cointegrating functional, which is, of course,
informal at this point since we have not yet provided our formal deﬁnition of a cointegrating functional.

t≥0 is stationary since f3 is a continuous linear transformation and

Xt

)}

νt

{

{

}

}

{

(

One may be interested in describing the above characteristics of the model (2.2) using the existing

, the space of square integrable functions on

theory of cointegration, assuming that the intraday price curves are random elements of the usual Hilbert
space L2
=
0, 1
]
[
1
du. In this case, however, the AR(1) operator Φ1 given in (2.2) and the functionals f1 and f3
u
g
0 f
∫
)
given in (2.1) lack an essential continuity property required in the existing theory, and dealing with those
linear maps in this context is far beyond what has been covered in the literature.2 This example, therefore,
shows that our general Banach space setting is useful to accommodate more various functional time series

equipped with inner product

0, 1
]

u
)

f, g

(

(

[

⟨

⟩

as subjects of the theory of cointegration.

Moreover, Banach space methodology is sometimes naturally in demand when researchers want to adopt

a different notion of distance for functional time series analysis. For example, Dette et al. (2020) noted that
two curves with rather different visual shapes may still have a small L2-distance and thus be identiﬁed
as similar in the usual L2
setting. They therefore employed the sup-distance, which is expected to
better reﬂect the visualization of curve-valued observations in statistical analysis, by assuming that such

0, 1
]

[

observations are random elements of C

.

0, 1
]

[

2.2 Notation

We here review our notation for the subsequent discussions. The setting for our analysis is a separable
B
complex Banach space B equipped with norm
B. To conveniently introduce our notation, we let ̃
∥
B, which can be set to, for example, B or the complex
denote another such space, equipped with norm
∥ ̃
∥
plane C, or the topological dual B′ to be deﬁned.

∥

⋅

⋅

x

∥

Ax

B ≤ M
∥ ̃

A linear operator A ∶ B ↦

B is said to be bounded if
̃

B for some M < ∞. Such
an operator is obviously continuous on B. Unless otherwise noted, every linear operator considered in this
B equipped with
paper is bounded. Let L
B, so let L
B
the operator norm
̃
(
)
denote L
B
B, ̃
, we let
)
). Commonly, ran A (resp. ker A)
ran A (resp. ker A) denote the set
{
< ∞, then A is said to be a ﬁnite rank operator.
is called the range (resp. the kernel) of A. If dim
ran A
)
(
For any subspace V ⊂ B, let V ′ denote the space of bounded linear functionals from V to C equipped with

denote the space of bounded linear operators from B to ̃
B. We are mostly concerned with the case B =
≤1
∥ ̃
∥
denote the identity operator acting on B. For any A ∈ L
x ∈ B ∶ Ax = 0
Ax ∶ x ∈ B
}

B
B, ̃
)
op = sup
x
∥
B

∥
, and let I ∈ L

(resp.

B, B

Ax

A

∥

∥

∥

∥

}

{

(

)

(

(

)

(

2
2Φ1, f1 and f3 are not continuous with respect to the topology of L

. Such a linear map is equivalently said to be
unbounded. As far as this author knows, unbounded linear operators or functionals have not been considered in the existing theory
of cointegration and the Granger-Johansen representation due to serious technical difﬁculties in dealing with those.

0, 1
]

[

5

)

(

{

V, C
)
V

B and V1 ∩ V2 =
̃

, which is commonly called the topological dual of V .

B, let cl
(
B, we let V1 + V2 denote the set

the operator norm, i.e., V ′ = L
denote the closure of V , i.e., union of V and its limit points. For
For any subset V of ̃
v1 + v2 ∶ v1 ∈ V1, v2 ∈ V2
subspaces V1 and V2 of ̃
, which is called the
}
B is the direct sum of
algebraic sum of V1 and V2. If V1 + V2 =
0
, we then say that ̃
}
{
B = V1 ⊕ V2. In this case, V1 (resp. V2) is said to be complemented by V2 (resp. V1),
V1 and V2, and write ̃
and V2 (resp. V1) is called a complementary subspace of V1 (resp. V2). These deﬁnitions can be extended
for a ﬁnite collection of subspaces V1, V2, . . . , Vk in an obvious way. For any set V ⊂
denote the annihilator of V , deﬁned by the set
subspace of ̃
space equipped with the quotient norm

= 0, ∀x ∈ V
B ′ (Fabian et al., 2010, p. 56). For any closed subspace V of ̃
⋅
B
∥ ̃

V , which are brieﬂy reviewed in Appendix A.1.
/

The deﬁnitions of a B-random variable X, its expectation EX, covariance CX, and cross-covariance
CX,Y with another B-random variable Y are given in Appendix A.2. We are mostly concerned with the
2
collection of B-valued random variables X satisfying EX = 0 and E
B < ∞, which is denoted by
L2
= 0 implies that f = 0.

, we say that X has a positive deﬁnite covariance if f CX

)
which turns out to be a closed

B, we let Ann
̃
(

B
B, we let ̃
/

V denote the quotient

. For X ∈ L2

B ′ ∶ f
̃

f ∈

X

B

B

∥

∥

∥

V

x

f

}

{

)

(

(

)

(

)

(

)

2.3 Cointegrated I(d) processes in Banach spaces
Throughout this paper, we will need to consider I(d) processes in B and in C for d ∈
, with innovations
B as in Sec-
in B, so it is convenient to deﬁne the I(d) property with another separable complex Banach space ̃
tion 2.2. Our deﬁnition of the I(d) property is adapted from Beare and Seo (2020) and Franchi and Paruolo

1, 2
}

{

(2020) for our more general setting. As a key building block for the I(d) property, we ﬁrst deﬁne the I(0)

property.

Deﬁnition 2.2. A sequence X =

Xt

{

}

t≥t0 in L2

(

is said to be I(0) if we may write

B
̃
)
∞

Xt − E

=

Xt

(

)

∑
j=0

Θjεt−j,

t ≥ t0,

where
in L

εt
{
}
B
B, ̃
)

(

t∈Z is an iid sequence in L2
∞
satisfying
j=0

B
(
op < ∞ and

Θj

)

∑

∥

∥

∞
j=0 Θj ≠ 0.

∑

with positive deﬁnite covariance Cε0 and

(2.3)

j≥0 is a sequence

Θj

{

}

}

{

εt

Remark 2.1.

t∈Z in Deﬁnition 2.2 is an iid sequence in L2

, which is called a strong B-white noise
(Bosq, 2000, p. 148). The iid condition is imposed for simplicity, and the results to be developed remain
valid even if it is replaced by stationarity in the covariance structure, i.e., Cεt does not depend on t and
t∈Z is called a weak B-white noise (Bosq, 2000, p. 161).
Cεt,εs

= 0 for all t and s ≠ t. Such a sequence

εt

B

)

(

{

}

As in a Euclidean space setting, (2.3) may be conveniently expressed as

Xt − E
j=0 Θjzj and L denotes the lag operator. Note that Θ

Xt

εt,

L

∞

(

)

)

(

= Θ

=

)

(

z

∑

where Θ
C, which is called an operator pencil (see Appendix A.4); if Θ
is matrix-valued, it is specially called a
matrix pencil. Based on the I(0) property given by Deﬁnition 2.2, we deﬁne the I(1) and the I(2) properties
as follows.

is an operator-valued function on

⋅
)

⋅
)

(

(

6

Deﬁnition 2.3. For d ∈
admitting a representation (2.3) with

1, 2
}

, a sequence in L2
Θj

{

(
j≥0 satisfying

B
̃
)

{

}

∞

j=1 j d

∑

Θj

∥

op < ∞.

∥

is said to be I(d) if its d-th difference is an I(0) process

Note that we require some summability conditions for I(1) and I(2) sequences, which are introduced for

mathematical convenience in order to facilitate the use of the Phillips-Solo device in Section 2.4.

Cointegration of an I(d) process in B may be deﬁned by extending Deﬁnition 2.1 in an obvious way.
Let X be an I(d) process in B, f be an element of B′, and ∆ ≔ I − L be the difference operator. If the
t≥0 is stationary (∆0 is understood as the identity operator) in C for
scalar-valued time series
a suitable choice of X0, we then say that X is cointegrated and call f a cointegrating functional. Obviously,
the collection of cointegrating functionals constitutes a subspace of B′, so we call it the cointegrating space.

∆d−1Xt

)}

f

{

(

2.4 Characterization of the cointegrating space

In this section, we characterize the cointegrating space associated with I(1) or I(2) processes in B. A key
input to our results is the Phillips-Solo device (Phillips and Solo, 1992, Lemma 2.1 and Section 4) for

obtaining an algebraic decomposition of a linear ﬁlter into long-run and transitory components. Even if

the Phillips-Solo device was presented in Phillips and Solo (1992) as a way to decompose matrix pencils

when the usual matrix norm is considered, it can be directly extended to our Banach space setting by just

replacing matrix pencils (resp. the usual matrix norm) with operator pencils (resp. the operator norm); no

further changes are required from their proofs.
, let X =

For d ∈

1, 2
}

{

{

}

Xt

t≥−d+1 be an I(d) sequence in B, admitting the following representation,

(
Under the summability conditions given in Deﬁnition 2.3, we may apply the Phillips-Solo device to obtain

)

(

)

∞

L

∑

j=0 Θ⭒

where Θ⭒
= −
(resp. transitory) component of Θ
allows the following representation, called the Beveridge-Nelson decomposition: for d ∈
some τ0,

j =
; see Phillips and Solo (1992). We may deduce from (2.5) that (2.4)

j Lj and Θ⭒
L

) is called the long-run

(resp. ∆Θ⭒

∑

L

(

)

(

)

(

∆d−1Xt = τ0 + Θ

t

1
)

(

∑
s=1

εs + νt,

t ≥ 0,

t≥0 is stationary and νt = Θ⭒
where
associated with X is formally deﬁned as follows: for d ∈

νt

L

}

{

)

(

εt for each t. Given (2.6), the cointegrating space C

,

1, 2
}

{

X

C

(

=

)

{

f ∈ B′ ∶

∆d−1Xt

f

{

(

)}

We also deﬁne

t≥0 is stationary for some τ0 ∈ L2

.

B

(

)}

X

A
(

)

= ran Θ

,

1
)

(

which is called the attractor space of X. We then provide useful results to characterize C
is no restriction on A
(

is complemented in B, i.e., for some V ⊂ B,

X

X

X

)

)

(

when (i) there

⊕ V.

))

(2.7)

and (ii) the closure of A
(
A
(

B = cl
(

)
X

7

(2.4)

(2.5)

and for

1, 2
}

{

(2.6)

X

(

)

∆dXt = Θ

L

εt,

t ≥ 1.

Θ

(

L

+ ∆Θ⭒

= Θ

1
)
)
(
∞
k=j+1 Θk. In (2.5), Θ

L

(

,

)
1
)

⊥

)

X

If B is a Hilbert/Euclidean space, then V = A
always satisﬁes (2.7); however, there may not exist a
(
subspace V satisfying (2.7) if B is an inﬁnite dimensional Banach space (Remark 2.3). Note also that, even
in a very simple case, a subspace V satisfying (2.7) is not unique; for example, in the case where B = R2
and cl
can be V .
(
However, the subsequent results do not depend on any speciﬁc choice of V , and hence V can be arbitrarily
chosen among possible candidates. For such V , we can deﬁne a unique projection PV ∈ L
cl

, the span of any arbitrary vector that is not included in span

, which is deﬁned by the following three properties:

onto V along

= span

A
(

1, 0

1, 0

{(

{(

)}

)}

))

X

X

B

)

(

PV = P2
V ,

ran PV = V,

ker PV = cl

;

(2.8)

X

A
(

(

))

see Megginson (2012, Theorem 3.2.11). Our ﬁrst result given below characterizes C
and PV .

X

in terms of A
(

X

)

)

(

A
(

(

))

Proposition 2.1. If X =

(i) C

X

(

)

= Ann
(

A
(

{
X

Xt

}
.
))

t≥−d+1 isI(d)for d ∈

1, 2
,thefollowing hold.
}

{

Proposition 2.1-(i) shows that C

X

(ii) If (2.7) issatisﬁed forsome V ⊂ B,then C

X

=

f ◦ PV ∶ f ∈ B′

(

)

{
is given by the annihilator of A
(

)

(

)

,where PV satisﬁes (2.8).
}
X

, and thus a closed subspace

of B′ regardless of whether A
X
(
, as a subspace of B′, is fully characterized by the projection PV ∈ L
sition 2.1-(ii) says that C
X
which in turn leads to a natural decomposition of

,
)
t≥0 into two components with different kinds of

is closed or not. Moreover, under the direct sum condition (2.7), Propo-

∆d−1Xt

B

)

(

)

(

cointegrating behavior; see Remark 2.2 below.

{

}

(

X

X

Remark 2.2. In our Banach space setting, the cointegrating space C
is, by deﬁnition, a subspace of
B′ which is in general different from B. However, the result given in Proposition 2.1-(ii) makes it possible
to understand C
as a subspace of B. Consider the Beveridge-Nelson decomposition (2.6). Using PV
deﬁned under the direct sum (2.7), we may decompose ∆d−1Xt into
∆d−1Xt and PV ∆d−1Xt. The
t≥0 cannot be stationary for all f ∈
former is the unit root component in the sense that
B′ as long as f
t≥0
can be made stationary under a suitable choice of τ0 for all f ∈ B′. This projection-based decomposition of
a cointegrated time series is what has been done in a Euclidean space setting (see e.g. Johansen, 1995, pp.

I −PV
≠ 0 while the latter is the stationary component in the sense that

f PV ∆d−1Xt

(
∆d−1Xt

I −PV

I −PV

f

}

{

}

{

)

(

)

)

)

(

(

)

40–41), and as discussed, it is also possible in our setting without a richer geometry of a Hilbert space.

Remark 2.3. If B is an inﬁnite dimensional Banach space, a closed subspace may not be complemented
(Megginson, 2012, pp. 301–302), hence (2.7) is not generally true. It, however, turns out that either of the

following is a sufﬁcient (but not necessary) condition for the existence of V satisfying (2.7),

(i) dim
(

A
(

X

))

< ∞,

(ii) dim

B

A
(

/

(

X

))

< ∞;

see Theorem 3.2.18 in Megginson (2012). The two conditions lead to different dimensionalities of the
cointegrating space of B′. In case (i), V is necessarily inﬁnite dimensional, and we deduce from Proposition
In case (ii), on the other hand, V is ﬁnite
2.1 that the cointegrating space is also inﬁnite dimensional.

dimensional, hence the cointegrating space is ﬁnite dimensional as well.

8

One may be interested in how the general results given by Proposition 2.1 reduce to what we have known
about cointegration in a Hilbert/Euclidean space. Let H be a separable complex Hilbert space with inner
. If B = H, the Riesz representation theorem (see e.g. Conway, 1994, p. 13) implies that every
⋅, ⋅
product
⟩
f ∈ H′ is given by the map
∶ H ↦ C for a unique element y ∈ H. Therefore, we may alternatively
deﬁne the cointegrating space as follows: for d ∈
∆d−1Xt, y

1, 2
}
t≥0 is stationary for some τ0 ∈ L2

y ∈ H ∶

(2.9)

CH

⋅, y

H

X

=

{

⟩

⟨

⟨

.

,

(

)

{

{⟨

⟩}

(

)}

Moreover, in this case, the closure of any subspace is complemented by its orthogonal complement, i.e.,
the direct sum (2.7) holds for V = A
(Conway, 1994, pp. 35–36). For this choice of V , PV be-
(
comes an orthogonal projection. Under all these simpliﬁcations, Proposition 2.1 reduces to the following
characterization, which is identical to the description of CH

given by Beare et al. (2017).

X

X

⊥

)

Corollary 2.1. If X =

Xt

t≥−d+1 isI(d)for d ∈

and B = H,then CH

X

)
We close this section with some remarks on Proposition 2.1 and Corollary 2.1.

{

}

{

(

1, 2
}

⊥

.

X

= A
(

)

(

)

X

, given in (2.9). If there exists a nonzero cointegrating vector, the long-run component Θ

Remark 2.4. Suppose that B = Rn or Cn equipped with the usual inner product
= x⊺y. This is of
course a special case of a Hilbert space, so we may consider the alternative deﬁnition of the cointegrating
space, CH
1
)
= s < n. If so,
from the Phillips-Solo decomposition in this setting is a reduced rank matrix, i.e., rank Θ
⊺
there are two full column rank n × s matrices θ1 and θ2 satisfying Θ
2 (see e.g. Faliva and Zoia,
2010, Theorem 3 in Chapter 1). As a result, CH
is given by the collection of vectors that are orthogonal
to the columns of θ1, which is an

-dimensional subspace of Rn or Cn.

= θ1θ

n − s

1
)

1
)

x, y

X

)

(

(

(

)

(

(

⟩

⟨

(

)

Remark 2.5 (Second-order cointegrating functionals). Under the summability requirement for the I(2) prop-
erty in Deﬁnition 2.3, we may apply the Phillips-Solo device to Θ⭒

in (2.5), and obtain

L

Θ

L

= Θ

(
j Lj and Θ⭒⭒

(
j =

)

+ ∆Θ⭒
1
)
(
∞
k=j+1 Θ⭒
k. We then may deduce from (2.10) that (2.4) with

(2.10)

1
)

(

)

,

(
+ ∆2Θ⭒⭒

)
L

where Θ⭒⭒
d = 2 allows the following representation: for some τ0 and τ1,

j=0 Θ⭒⭒

= −

∑

∑

L

∞

)

(

t

r

t

Xt = τ0 + τ1t + Θ

1
)

εs + Θ⭒

εs + ν⭒
t ,

(

∑
s=1

1
∑
∑
)
r=1
s=1
εt for each t. Note that for any f ∈ C
τ0
by assuming f

t ≥ 0,

(
t = Θ⭒⭒
+ f

(

)

{

= f

where

L
)
(
ν⭒
t

ν⭒
t
we have f

t≥0 is stationary and ν⭒
}
t
Θ⭒
s=1 εs
Xt
)
a nearly identical argument used to prove Proposition 2.1-(i) that
ran Θ⭒
f ∈ Ann
Xt
)}
(
(
τ0 and τ1 for any f ∈ Ann
ran Θ
(
functional, which will be of interest to us in Section 3 as an important aspect of I(2) AR processes in B.

= Ann
1
,
))
(
= 0. Then it may deduced from
t≥0 is stationary if and only if
t≥0 can be made stationary under a suitable choice of
1
. We call such f as a second-order cointegrating
))

f
{
∩ Ann
(

also holds. To sum up,

τ1
(
)
Xt

1
) ∑

= f
f

ran Θ⭒

1
))

1
))

ran Θ

)}

X

{

(

(

(

)

)

(

(

)

(

(

(

(

(

9

3 Representation of I(1) and I(2) autoregressive processes

For ﬁxed p ∈ N, suppose that a sequence

t≥−p+1 ⊂ L2

B

satisﬁes the following AR(p) law of motion:

Xt

{
Φ

}
L

(

Xt = εt,

)

(
)
t ≥ 1,

(3.1)

where

εt

{

}

t∈Z ⊂ L2

B

(

)

is an iid sequence with positive deﬁnite covariance Cε0 and

= I −

Φ

z

(

)

p

∑
j=1

Φjzj, Φ1, . . . , Φp ∈ L

.

B

(

)

}

{

B

εt

We let the operator pencil Φ ∶ C ↦ L
be called the AR polynomial. The iid condition imposed
t∈Z can be replaced by stationarity in the covariance structure without affecting the results to be
on
developed in this section; see Remark 2.1. We hereafter say that Φ has a unit root if it satisﬁes Assumption
denotes the spectrum of Φ given by the set
3.1 below, where the following notation is employed: σ
z ∈ C ∶ Φ

and DR denotes the open disk with radius R centered at 0 ∈ C.

is not invertible

Φ

z

)

)

(

(

)
{
Assumption 3.1 (Unit root).

(

}

(a) σ

Φ

)
(
(b) ran Φ

∩ D1+η =

1
}
and ker Φ

{

1
)

(

for some η > 0 and Φ

≠ 0.

1
)

(

(

1
)
B = ran Φ

can be complemented, i.e., for some

ran Φ

∁ ⊂ B and

ran Φ

(

⊕

1
[
)
(resp. ker Φ

1
)]

∁ = ker Φ

[
1
)
) to allow a complementary subspace

1
)]

∁.

⊕

(

(

(

[

1
(
)]
ker Φ

ker Φ

1
)]

(

[

∁ ⊂ B,

(3.2)

[

[

[

(

(

(

(

(

⊥

∁ =

1
)

ker Φ

ran Φ

ran Φ

ran Φ

ran Φ

∁ and

1
)]

1
)]

1
)]

1
)]

Note that we require ran Φ

1
)
In general,

∁) in Assumption 3.1-(b).

1
1
)]
(
)]
1
is necessarily closed since Φ
)

∁ (resp.
(
ker Φ
∁ satisfying (3.2) do not
[
[
uniquely exist, but the results to be developed in this section only require their existence. If B is a Hilbert
space as a special case, any closed subspace can be complemented by its orthogonal complement, hence
ker Φ
[
B

(3.2) holds for
1
(ker Φ
)
a Hilbert space setting, closedness of ran Φ
quentially holds (see Remark 3.1 to appear in Section 3.1). In a general Banach space setting, on the other
hand, (3.2) does not necessarily hold when ran Φ
Theorem 3.2.20). Nevertheless, Assumption 3.1-(b) may not be restrictive in general and, moreover, is a
fairly weaker requirement which is strictly implied by the regularity conditions on Φ
existing literature; a more detailed discussion will be given in Remark 3.1.

(
is implied by the employed assumptions, so (3.2) conse-

). In the existing representation theorems developed in

is closed; see the example given by Megginson (2012,

as long as ran Φ

employed in the

and
∈ L

is closed

1
)]

1
)]

ker Φ

1
)

1
)

1
)

∁ =

z

⊥

(

(

(

(

)

(

(

)

(

(

(

[

[

In this setting, what we seek are (i) a necessary and sufﬁcient condition under which the AR(p) law of
motion (3.1) allows I(1) or I(2) solutions, and (ii) a characterization of such solutions; in the case B = Rn
or Cn, these issues are dealt with in Johansen’s representation theory. Hereafter, we conveniently say that a
t≥−p+1 from (3.1) allows the Johansen I(1) representation if it satisﬁes the following: for τ0
sequence
νt

depending on initial values of (3.1), a stationary sequence

, and Υ−1 ∈ L

t≥0 ⊂ L2

Xt

B

B

}

{

,

Xt = τ0 + Υ−1

t

∑
s=1

{

}

(

)

(

)

εs + νt,

t ≥ 0.

(3.3)

We also say that

Xt

{

}

t≥−p+1 allows the Johansen I(2) representation if it can be represented as follows: for τ0

10

and τ1 depending on initial values of (3.1), a stationary sequence
t

r

t

νt

{

}

t≥0 ⊂ L2

B

(

)

, and Υ−2, Υ−1 ∈ L

B

,

)

(

Xt = τ0 + τ1t + Υ−2

∑
r=1

∑
s=1

εs + Υ−1

∑
s=1

εs + νt,

t ≥ 0.

(3.4)

In the case B = Rn or Cn, Johansen (1991, 1995) shows that a necessary and sufﬁcient condition for the

AR(p) law of motion (3.1) to allow I(1) solutions is given by that

⊺
1
⊥⊥Φ(
α
)

1
)

(

β⊥⊥ is invertible,

(3.5)

(

⊺
⊥⊥α⊥⊥ = β
that α

= αβ⊺ for some r < n, then
where, if we let α and β are full-rank n × r matrices satisfying ran Φ
1
)
n − r
α⊥⊥ (resp. β⊥⊥) is a full-rank n ×
matrix whose columns are orthogonal to α (resp. β) and satisﬁes
⊺
⊥⊥β⊥⊥ = In−r (the identity matrix of dimension n − r). The condition given by (3.5) is
Xt
called the Johansen I(1) condition, under which a sequence
t≥−p+1 from (3.1) allows the Johansen I(1)
representation with a certain operator Υ−1; see e.g. Johansen (1995, Theorem 4.2). A similar representation
result for the I(2) case is also given by Johansen (1995, Theorem 4.6). Extending these results to a general
Banach space setting may not be done by a simple extension: in general, B is not equipped with an inner
product and, moreover, it can be inﬁnite dimensional; hence we cannot rely on some important geometrical

{

}

(

)

properties and matrix algebraic results that are allowed in Euclidean space. We thus need a novel approach
that relies on neither of geometrical properties induced by an inner product nor ﬁnite dimensionality of B.

)

(

(

)

z

z

law of motion, characterized by a matrix pencil Φ
Φ

As observed in an early contribution by Schumacher (1991), the I(d) property of solutions to the AR(p)
, in Rn is determined by the behavior of the inverse
−1 around z = 1. This is also true in our Banach space setting, so our approach for developing
representation theory for I(1) and I(2) AR processes essentially boils down to examining the inverse of
the AR polynomial around z = 1. As a way to achieve this goal, we ﬁrst consider the companion form
−1
of (3.1) characterized by a linear operator pencil ̃Φ to be deﬁned later, and study the behavior of ̃Φ
around z = 1 based on the spectral theory of linear operator pencils given in e.g. Kato (1995), Gohberg et al.
(2013), Albrecht et al. (2011), Albrecht et al. (2019) and references therein. We then recover the behavior
of Φ

−1 around z = 1 from that of ̃Φ

(
It will be convenient to ﬁx standard notation and terminology, based on Appendix A.4 providing a brief

−1.

z

z

z

)

(

(

)

)

introduction to operator pencils, for the subsequent discussions. For any operator pencil A and its spectrum

(

=

A
)

z ∈ C ∶ A
(

σ
, we let ρ
(
set of A. Now suppose that A allows the Laurent series at z = z0 as follows: for some d ≥ 0,
∞

is not invertible

denote the set C

A
)

A
)

σ

\

{

}

z

(

)

, which is called the resolvent

=

z

A
(

)

Aj

(

∑
j=−d

z − z0

)

j, A−d ≠ 0.

(3.6)

)

(

)

z

z0

denote the j-th complex derivative of A
(

If d = 0, we say that A
is holomorphic (or equivalently, complex-differentiable) at z = z0 and let
(
j
evaluated at z = z0. In this case, (3.6) becomes the
A(
)
if z0 = 0. If
Taylor series of A
(
d ≠ 0, A
is said to have an isolated singularity at z = z0. An isolated singularity with d < ∞ is called
(
a pole of order d. A pole of order one is said to be simple. If d = ∞, A
is said to have an essential
(
singularity at z = z0. The sum of the leading terms indexed by j = −d, . . . , −1 is the called the principal

at z = z0, which is specially called the the Maclaurin series of A
(

z

z

z

z

z

)

)

)

)

)

11

part and the sum of the remaining terms is called the holomorphic part.

3.1 Relations with the literature

A few different versions of the Granger-Johansen representation theorem have been proposed in the recent

literature on cointegrated functional time series taking values in a Hilbert space, such as Chang et al. (2016a),
Hu and Park (2016), Beare et al. (2017), Beare and Seo (2020) and Franchi and Paruolo (2020). Compared

to those, our versions are to be developed under a general Banach space setting without relying on a richer

geometry of a Hilbert space, which can help us consider more various functional time series as subjects

of the theory of cointegration, as illustrated in Section 2.1. Apart from such mathematical gains, we here

brieﬂy describe how our setting is related to the assumptions employed in the aforementioned papers by
assuming B = H (recall that H denotes a separable complex Hilbert space).

We ﬁrst focus on the I(1) case. Except for the paper by Chang et al. (2016a) providing a quite different

representation result, the AR polynomial Φ
z ∈ C,

(

z

)

in the foregoing papers satisﬁes the following condition: for

dim
(

ker Φ

z

< ∞ and dim

ran Φ

z

< ∞.

(3.7)

⊥

(

(

)

)

(

z

([

))

)]
is called a Fredholm operator. Fredholmness of Φ
z

If (3.7) holds, Φ
can be more generally deﬁned in
< ∞. The Fred-
our Banach space setting by replacing the latter condition in (3.7) with dim
(
holm property, combined with the unit root assumption (Assumption 3.1), produces some special behavior
−1 near z = 1, which becomes a crucial input to the existing theorems; see Beare and Seo (2020,
of Φ
Appendix A.1) and Franchi and Paruolo (2020, Appendix B). An important consequence of assuming (3.7)
t
is that Υ−1 in (3.3) always becomes a ﬁnite rank operator, hence the random walk component Υ−1 ∑
s=1 εs
in (3.3) essentially boils down to a ﬁnite dimensional unit root process. As a result, the attractor space

ran Φ

)/

B

z

z

(

)

(

)

(

)

(resp. the cointegrating space) associated with the AR(p) law of motion is necessarily ﬁnite dimensional

(

1
)

(resp. inﬁnite dimensional). On the other hand, the version of Chang et al. (2016a) relies on the assumption
that Φ
is compact, which turns out to result in the opposite case, where the cointegrating space is ﬁnite
dimensional and the random walk component takes values in an inﬁnite dimensional space unless H is ﬁnite
dimensional. Their compactness assumption is not compatible with Fredholmness of Φ
in an inﬁnite
dimensional setting. We thus have two qualitatively different I(1) representation results depending on two
generally incompatible regularity conditions on Φ

z

z

(

)

.

To the best of the author’s knowledge, the existing representation theorems for I(2) AR processes in

(

)

a general Hilbert space setting were recently provided by Beare and Seo (2020) and Franchi and Paruolo
(2020), where Fredholmless of Φ
is an essential assumption for their representation theory. Similar to
the I(1) case, the Fredholm assumption makes Υ−2 and Υ−1 in (3.4) become ﬁnite rank operators, hence the
t
random walk component Υ−2 ∑
s=1 εs is intrinsically a ﬁnite dimensional unit root pro-
cess. This requirement entailed by the Fredholm assumption not only compels the attractor space associated

s=1 εs +Υ−1 ∑

t
r=1 ∑

z

(

)

r

with I(2) solutions to be ﬁnite dimensional, but also places some more restrictions on their cointegrating

behavior; a more detailed discussion will be given in Section 3.4.
As discussed above, any regularity conditions imposed on Φ

law of motion to have some speciﬁc characteristics. It is thus desirable to develop representation theory for

z

may compel solutions to the AR(p)

(

)

12

I(1) and I(2) AR processes under minimal regularity conditions on Φ
conditions on Φ
theory place weaker restrictions on solutions to the AR(p) law of motion. As an example, the random walk

than either of Fredholmness or compactness, which naturally makes our representation

. We in this paper require weaker

z

z

(

(

)

)

component of I(1) or I(2) solutions can be either ﬁnite dimensional or inﬁnite dimensional in our results; this

z

is in contrast to that the component is required to be exclusively ﬁnite dimensional or inﬁnite dimensional
depending on the employed regularity condition on Φ

in the recent literature.

)
z

1
)

1
)

(resp. ker Φ

is either Fredholm or compact. Fredholm prop-

(
Remark 3.1. As discussed, in the existing literature, Φ
erty (3.7) implies that ran Φ
) allows a ﬁnite (resp. an inﬁnite) dimensional complemen-
tary subspace. This is also true in a more general situation where B is not necessarily a Hilbert space and
is a Fredholm operator acting on B; this can be shown from Remark 2.3 and the fact that both ker Φ
1
Φ
z
(
)
)
and B
is compact and satisﬁes Assumption 3.1-(a),
/
then Φ
(
ker Φ
1
)
or compactness of Φ
while no such restrictions are required by Assumption 3.1-(b).

1
)
) allows an inﬁnite (resp. a ﬁnite) dimensional complementary subspace. Note that Fredholmness
∁,

is necessarily a ﬁnite rank operator (Chang et al., 2016a, Lemma 1). Thus, ran Φ

places some speciﬁc dimensionality restrictions on

are ﬁnite dimensional in this case. If Φ

1
)]

1
)]

∁ and

ran Φ

ran Φ

(resp.

ker Φ

1
)

1
)

z

z

(

(

(

)

(

(

(

(

(

)

(

(

)

(

[

[

Remark 3.2. As will be shown in Proposition 3.4, the random walk component in the I(1) case always
takes values in ker Φ
under Assumption 3.1-(a). This shows where the difference between the existing I(1) representation results

, whose dimension is ﬁnite (resp. inﬁnite) if Φ

is Fredholm (resp. compact)

1
)

z

)

(

(

about the dimensionality of the random walk component originates from.

3.2 Linearization of the AR polynomial
Consider the product Banach space Bp equipped with the norm
x1, . . . , xp
(
may be understood as the following AR(1) law of motion in Bp:

)

B for any
∈ Bp. We let Ip denote the identity map acting on Bp. In fact, the AR(p) law of motion (3.1)

x1, . . . , xp

)∥

∥(

xj

∑

∥

∥

Bp =

p
j=1

where ̃Φ ∶ C ↦ L

Bp

(

)

εt,
̃
is a linear operator pencil given by ̃Φ
(

̃Xt =

̃Φ

L

(

)

z

)

= Ip − z ̃Φ1 and

̃Xt =

,

̃Φ1 =

Xt
Xt−1
⋮
Xt−p+1

⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣

⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦

Φ1 Φ2 ⋯ Φp−1 Φp
I
0
0 ⋯ 0
⋮
⋮ ⋱
⋮
0 ⋯ I
0

⋮
0

⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣

⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦

,

εt =
̃

εt
0
⋮
0

⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣

⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦

(3.8)

.

(3.9)

Commonly, (3.8) is called the companion form of (3.1); see e.g. Johansen (1995, p. 15) or Bosq (2000,
−1 that we want to know may be
p. 128, 161). From a mathematical point of view, the behavior of Φ
−1, which is as described in Proposition 3.1 below, where the following notation
obtained from that of ̃Φ
(
is employed: Πp ∶ Bp ↦ B and Π∗

p ∶ B ↦ Bp denote the maps deﬁned by

z

z

(

)

)

x1, x2, . . . , xp

Πp

(

= x1,

)

Π∗
p

=

x1

(

)

x1, 0, . . . , 0
)

.

(

(3.10)

Proposition 3.1. UnderAssumption 3.1,theoperator pencils ̃Φ and Φ satisfy thefollowing.
z

−1Π∗

(i) σ

−1.

= σ

Φ

z

p = Φ

̃Φ

(

)

and Πp ̃Φ

(

)

(

)

(

)

13

(ii) UnderAssumption3.1,ifeitherof ̃Φ
(

z

)
at z = 1,then theother hasapoleoforder d (resp.essential singularity) at z = 1.

)

(

−1 orΦ

z

−1 hasapoleoforderd (resp.essentialsingularity)

(

z

Proposition 3.1-(i) shows that ̃Φ
z
(
−1 can be recovered from ̃Φ
(

and Φ
implies that we can obtain a necessary and sufﬁcient condition for Φ
z = 1 by ﬁnding such a condition for ̃Φ
(
representation theorems for I(1) and I(2) AR processes.

inherits the unit root property of Φ
given by Assumption 3.1,
−1 using the maps given in (3.10). Moreover, Proposition 3.1-(ii)
−1 to have a pole of order 1 or 2 at
−1. These results will become useful in the development of our

)
z

z

z

z

)

)

)

(

)

(

)

3.3 Representation of I(1) autoregressive processes

In Section 3.3.1 we develop our representation theory for I(1) AR processes resorting to the companion form
AR(1) representation (3.8); this is done by studying the spectral properties of ̃Φ
We then discuss on how the results obtained via the companion form can be reformulated in terms of the
behavior of the AR polynomial Φ

under Assumption 3.1.

in Section 3.3.2.

z

z

(

)

(

)

3.3.1 Representation via the companion form

Resorting to the companion form (3.8), we in this section provide a necessary and sufﬁcient condition for

the AR(p) law of motion (3.1) to admit I(1) solutions and a characterization of such solutions.

Under Assumption 3.1-(a), we know from the results given in Appendix A.4 (especially, see (A.1)) that
−1 can be written as the following Laurent series: for d ∈ N ∪

∞

,

z

̃Φ

(

)

−1 = −

z

̃Φ
(

)

−1

̃Nj

z − 1
)

(

∑
j=−d

j −

∞

∑
j=0

}

{
̃Nj

(

j.

z − 1
)

(3.11)

(3.12)

For notational convenience, we let

̃P ≔

̃N−1 ̃Φ1.

The operator given above turns out to be a projection under Assumption 3.1 (Lemma B.1-(ii)) and has a cru-

cial role in the subsequent discussion. What we ﬁrst pursue for the development of our representation theory

)

(

z

is a necessary and sufﬁcient condition under which the AR(p) law of motion (3.1) admits I(1) solutions (or
−1 has a simple pole at z = 1). When B = Rn or Cn, a well known such condition is
equivalently, ̃Φ
the Johansen I(1) condition given by (3.5), and it plays an essential role in Johansen’s representation theory
for I(1) AR processes. Beare et al. (2017), who studied the same issue for the case B = H, revisited the
Johansen I(1) condition and provided its geometric reformulation given by a certain nonorthogonal direct
sum of Hp; see Remark 3.4. Inspired by their direct sum condition that can be applied for H of an arbitrary
dimension, we propose the following condition.

.

(

1
)

1
)

⊕ ker ̃Φ

I(1) condition: Bp = ran ̃Φ
(
Some remarks on the I(1) condition are given in order.
Remark 3.3. The I(1) condition is given as the direct sum of Bp by two ﬁxed subspaces ran ̃Φ
ker ̃Φ
(
of I(1) solutions. In the case where our I(1) condition holds, it is worth noting that a unique projection whose
range is ker ̃Φ
(

, and this speciﬁc direct sum condition will be shown to be necessary and sufﬁcient for the existence

is well deﬁned (Megginson, 2012, Theorem 3.2.11).

and kernel is ran ̃Φ

1
)

1
)

1
)

1
)

and

(

(

14

Remark 3.4. In the case where B = H of an arbitrary dimension and Φ1, . . . , Φp are compact operators,
Beare et al. (2017) showed that the nonorthogonal direct sum Hp = ran ̃Φ
is a sufﬁcient
condition for the AR(p) law of motion (3.1) to admit I(1) solutions; however, its necessity was not discussed
in their paper. They showed that their condition becomes equivalent to the Johansen I(1) condition if H = Rn
or Cn. The reader is referred to the results given in Section 4 (and the proofs of those) of their paper.

⊕ ker ̃Φ

1
)

1
)

(

(

Our ﬁrst result in this section not only shows that the I(1) condition is a necessary and sufﬁcient condition
−1 to have a simple pole at z = 1 but also characterizes the principal part of its Laurent series.

for ̃Φ
(
Proposition 3.2. Suppose thatAssumption 3.1holds. Thefollowing conditions areequivalent.

z

)

)

(

z

−1 hasasimplepoleat z = 1.

(i) ̃Φ
(ii) ̃P istheprojection onto ker ̃Φ
(iii) TheI(1)condition holds.

1
)

(

along ran ̃Φ

1
.
)

(

Underanyofthese conditions, thefollowing holds: forsome η > 0,

1 − z

z

̃Φ

−1 =

̃P +

1 − z

H

z

,

z ∈ D1+η,

(3.13)

where H

z

(
Maclaurin series of

)

(

)
denotes the holomorphic part of the Laurent series of ̃Φ
(
isconvergent on D1+η.

−1 and H

1 − z

z

z

(

(

)

)

)

(

̃Φ

)

(

)

(

(

)

−1 around z = 1. Moreover, each

z

)

Examples of the use of Proposition 3.2 for verifying that ̃Φ

−1 has a simple pole at z = 1 will be
given later in this section. Proposition 3.2 extends the results given by Beare et al. (2017), which are brieﬂy

z

)

(

reviewed in Remark 3.4, in the sense that it provides a necessary and sufﬁcient condition for the existence
of I(1) solutions without requiring either of a Hilbert space structure or compactness of Φ1, . . . , Φp. In
−1 around z = 1 given by (3.13)
addition, combined with Propositions 3.1, the local behavior of ̃Φ
provides a characterization of solutions to the AR(p) law of motion (3.1), which leads to our ﬁrst version of

z

)

(

the Granger-Johansen representation theorem for I(1) AR processes given below.

Proposition 3.3. Suppose that Assumption 3.1 holds. Under the I(1) condition, a sequence

satisfying (3.1) allowstheJohansen I(1)representation (3.3) with

Υ−1 = Πp ̃PΠ∗
p ,

νt = ΠpH

L

Π∗

p εt =

Πp ̃Φj

1

Ip − ̃P

Π∗

p εt−j,

∑
j=0
are given in Proposition 3.2, and Πp and Π∗
where ̃P and H
lawofmotion (3.1) does notallowI(1)solutions iftheI(1)condition isnotsatisﬁed.

z

(

(

)

)

(

)

∞

p are given in (3.10). Moreover, the AR(p)

Xt

{

}

t≥−p+1

(3.14)

Proposition 3.3 shows that, under our I(1) condition, solutions to the AR(p) law of motion (3.1) can

be represented as (3.3) similar to the Beveridge-Nelson decomposition (2.6) of an I(1) cointegrated linear

process. For such a solution
can be made stationary under a suitable initial condition if and only if f ∈ Ann
(
remarks on the results given by Proposition 3.3 are in order.

t≥0, we may deduce from our discussion in Section 2.4 that

Πp ̃PΠ∗

p

)

Xt

}

{

f

Xt
t≥0
. Some more

)}

{

(

Remark 3.5. Proposition 3.3 may be viewed as an extension of Theorem 4.1 of Beare et al. (2017), which

provides a version of the Granger-Johansen representation theorem in a Hilbert space setting resorting to the

15

companion form representation of a given AR(p) law of motion.

= ∞, neither of the attractor nor the cointegrating space associated with
Remark 3.6. In the case dim
(
(3.1) is compelled to be ﬁnite dimensional in our representation theorem; this is in contrast to that one

)

B

)

In this

ran Φ1

ran Φ1

(resp. dim

of those subspaces is necessarily ﬁnite dimensional in the existing theorems developed in a Hilbert space
setting; see Section 3.1. As a simple illustration, let p = 1 and Φ1 be an arbitrary projection.
case, we may deduce from Propositions 2.1, 3.2, and 3.3 that the dimension of the attractor space (resp.
). Since Φ1 is an
the cointegrating space) associated with (3.1) is equal to dim
)
= ∞, (ii)
ker Φ1
arbitrary projection, all the following cases are possible: (i) dim
(
= ∞.
ran Φ1
ker Φ1
dim

ker Φ1
(
< ∞ and dim
ker Φ1

< ∞, and (iii) dim

= ∞ and dim

(
In this section, the I(1) condition and solutions to the AR(p) law of motion (3.1) are characterized
around z = 1. For this reason, our results do not clearly reveal how
in terms of the behavior of ̃Φ
(
the proposed I(1) condition and the cointegrating behavior of I(1) solutions are related to the structure
of the original AR polynomial Φ
companion form representation of (3.1) to obtain our main results given in this section. In the next section,
we will discuss on how these results can be recast in terms of the behavior of the AR polynomial Φ
doing so, we obtain a more detailed characterization of I(1) solutions and ﬁnd the connection between our

. This is a natural consequence resulting from that we resort to the

)
ran Φ1
)
= ∞ and dim
(

. By

z

z

z

(

)

)

(

)

(

(

)

(

)

(

)

)

representation results and those developed in a Hilbert/Euclidean space setting. We close this section with a
few examples illustrating the use of Proposition 3.2 for verifying that ̃Φ
Example 3.1. In the example given in Section 2.1, B = C
z
Φ1
0, 1
1
]
(
)
This implies that every y ∈ ran ̃Φ
(
Moreover, it can be veriﬁed that ̃Φ
(
−1x

1
)
must satisfy y
−1 is well deﬁned for any z ≠ 1 and given by

, ̃Φ
(
1
x
)
= 0, from which we ﬁnd that ̃Φ

)
= I − zΦ1, and Φ1 is deﬁned by
.

. Note that ̃Φ
1
)
z

)
= 0 for any arbitrary x ∈ C

[
≠ 0 and ̃Φ
1
)

0, 1
]
is not invertible.

−1 has a simple pole at z = 1.

0, 1
]
1
)

for u ∈

1 − z

+ zx

u
)

1
)

= x

u ∈

= x

)(

x

z

z

(

(

(

(

(

(

(

[

[

,

.

u
)

(

1
)/(

(

)

0, 1
]

[

̃Φ

(

)

)
u
)

(

= C0 and ker ̃Φ
(

Thus, Assumption 3.1-(a) is satisﬁed. Let C0 be the set of continuous functions x ∈ B satisfying x
= 0,
and let C1 be the set of constant functions. Then, B = C0 ⊕ C1 may be easily deduced. We will show that
= C1; this implies that both Assumption 3.1-(b) and the I(1) condition are
ran ̃Φ
1
(
)
satisﬁed, and thus ̃Φ
satisﬁes
1
x
)
(
that ran ̃Φ
(

−1 has a simple pole at z = 1. It was already shown that any x ∈ ran ̃Φ
z
(
)
(
= 0, hence ran ̃Φ
1
(
)
⊃ C0. Thus, ran ̃Φ

x ∈ ran ̃Φ
= C1, we ﬁrst observe that

⊂ C0. Moreover, for any x ∈ C0 we have x =
= C0 holds. To show ker ̃Φ
(
1
,
)

(
x ∈ ker ̃Φ

1
)
u ∈

, which implies

0, 1
]

⇒ x

u
)

1
)

1
)

1
)

1
)

1
)

1
)

1
)

1
)

= x

̃Φ

(

(

(

(

(

(

,

⊂ C1 holds. The reverse inclusion (C1 ⊂ ker ̃Φ

1
)

and hence ker ̃Φ
that ̃Φ
1
)
Example 3.2. Suppose that B = C

(

(

x = 0 for any constant function x ∈ C

1
(
)
. We thus also ﬁnd that ker ̃Φ
(
= I −zΦ1, and Φ1 is deﬁned by

0, 1
]

[

1
)

[
) immediately follows from the fact
= C1.

)/
[
, and Φ1 (resp. I −Φ1) is the projection onto the space of even
One can easily show that σ
(resp. odd) functions along the space of odd (resp. even) functions. Moreover, in this case we have B =

1
}

)/

=

{

(

(

(

)

−u

2,

x ∈ B,

u ∈

.

−1, 1
]

Φ1x

u
(
)
̃Φ

z

, ̃Φ
−1, 1
]
)
(
2 + x

u

[
= x

16

1
)

1
⊕ker ̃Φ
ran ̃Φ
and ker ̃Φ
)
(
(
(
from which it is concluded that ̃Φ
cases where any arbitrary projection replaces Φ1 in the above.

1
)

)

(

= ran Φ1. Therefore, Assumption 3.1 and the I(1) condition are satisﬁed,
−1 has a simple pole at z = 1. In fact, we reach the same conclusion in
z

for a =

Example 3.3. Let c0 be the space of complex sequences converging to zero equipped with the norm
=
∈ c0. The space c0 may be viewed as a natural generalization of a ﬁnite
supi
dimensional vector space equipped with the supremum norm, and also turns out to be a separable Banach
space (Megginson, 2012, Examples 1.2.13 and 1.12.6). Let Φ1 be deﬁned by

a1, a2, . . .

ai
∣

∥

∥

a

)

(

∣

Φ1

(

a1, a2, a3, a4 . . .

=

a1, a1 + a2, λa3, λ2a4, . . .

,

)

(

(3.15)

)

(

)
a1 = b1

/(
This shows that ̃Φ
invertible on D1+η

where λ ∈

0, 1
)

(

z

. Then, ̃Φ
(
)
I −zΦ1
a =

= I −zΦ1 maps a =

a1, a2, . . .

to

)

(

1 − z

a1,

1 − z

a2 − za1,

1 − zλ

(

)
It may be deduced that ̃Φ
b =

b1, b2, b3 . . .

(

)

((
)
is injective on c0 for any z ∈ D1+η
a1, a2, a3 . . .

(

∈ c0, we can ﬁnd a sequence a =

z

)

(

a3,

)

(

1
}

1 − z

,

)

a2 = b2

1 − z

)

/(

+ zb1

/(

1 − z

2,

)

(

1 − zλ2

a4, . . .

.

)

)
. Furthermore, for any sequence

\ {
∈ c0 satisfying ̃Φ
1 − zλj−2

)
aj = bj

/(

a = b by setting

j ≥ 3.

)

z

(

,

)

(

z

=

\ {

ran ̃Φ
(

is also a surjection for z ∈ D1+η
)
. Note also that ran ̃Φ
1
}
∶ bj ∈ C, lim
j→∞

1
(
)
bj = 0
}
The above subspaces can be complemented (see Example 3.4), hence Assumption 3.1 is satisﬁed. However,
−1 does not have a simple
(3.16) clearly shows that B ≠ ran ̃Φ
1
)
pole at z = 1; it will be shown in Section 3.4 that ̃Φ

. We thus conclude that ̃Φ
(
z

−1 has a pole of order 2 at z = 1 .

. Therefore, we have shown that ̃Φ
1
}
are given as follows,

\ {
1
and ker ̃Φ
(
)
ker ̃Φ

⊕ ker ̃Φ
(

0, b1, 0, 0, . . .

0, b1, b2, . . .

∶ b1 ∈ C

(3.16)

1
)

1
)

1
)

{(

{(

is

=

}

z

z

(

)

)

)

(

)

(

,

.

(

)

3.3.2 Further characterization of I(1) solutions
If B = Rn or Cn, the Johansen I(1) condition given by (3.5) is necessary and sufﬁcient for Φ
have a simple pole at z = 1. If we let P
1
ran Φ
onto
(resp.
)]
invertibility of P
1
(
eralization of this condition to a general Banach space setting may be the following: for some

−1 to
⊥ ) denote the orthogonal projection

), then the Johansen I(1) condition can be alternatively understood as

. A natural gen-
ran Φ

as a map from ker Φ

ker Φ
[
1
⊥ Φ(
)

⊥ (resp. P

(
1
)(

ran Φ
[

ran Φ
[

ker Φ
[

ker Φ
[

1
)]

1
)]

ran Φ

I −P

1
)

1
(

1
(

1
(

to

z

)]

)]

)]

)]

⊥

⊥

⊥

(

(

)

(

(

)

(

[

[

⊥

1
)]

(

∁

[

∁ satisfying (3.2),

and

[

ker Φ

1
)]

(
Λ1,∁ ≔ P

ran Φ
1
[
(
)]
∁ and P

1
∁ Φ(
)

(

)]

where P

ran Φ
[
ran PV∁

ker Φ
[
= V∁, ker PV∁

1
(
= V,

1
(

)]

I − P

1
1
1
)
)(
(
∁ are the projections satisfying

ker Φ
[

∶ ker Φ

∁
)]

(

)

↦

ran Φ

[

1
)]

(

∁ is invertible,

(3.17)

V, V∁

=

ran Φ

ran Φ

or

ker Φ

ker Φ

. (3.18)

(

(

(

)

(
These projections are uniquely deﬁned linear operators for each choice of
see Megginson (2012, Theorem 3.2.11). In the case where B = Rn or Cn,
ker Φ
, the condition (3.17) becomes equivalent to the Johansen I(1) condition, under
[
−1 has a simple pole at z = 1. Proposition
which we know from Johansen (1995, Theorem 4.2) that Φ
3.4 given below shows that this result can be extended to a more general Banach space setting, and also

1
∁;
)]
(
⊥
, and

(
∁ and

(
ran Φ

[
ran Φ

[
ran Φ

1
)]

1
)]

1
)]

1
)]

ker Φ

∁ =

z

⊥

(

(

(

(

(

)

(

)

(

[

[

[

[

,

1
)

1
)]

∁

,

[

1
)
1
)]
∁ =

∁

1
)]
)
ker Φ

17

provides a characterization of Υ−1 in terms of the operators deﬁned above.

Proposition 3.4. Suppose thatAssumption 3.1holds. Thenthefollowing conditions areequivalent.

(i) TheI(1)condition holds.

(ii) Λ1,∁ ∶ ker Φ

(iii) Λ1,∁ ∶ ker Φ

1
)
1
)

(

(

↦

↦

[

ran Φ

ran Φ

(

1
)]
1
)]

(

[

∁ isinvertible forsomechoice of

(
∁ isinvertibleforeverypossiblechoiceof

[

ran Φ

∁ and

1
)]
ran Φ

[

ker Φ

(
∁ and

∁.

1
)]
ker Φ

[
∁ and

1
(
)]
ker Φ

∁.

1
)]
∁, a sequence

(

[

Let any of the above conditions hold. Then for any choice of
Xt

1
)]
t≥−p+1 satisfying (3.1) allowstheJohansen I(1)representation (3.3) with Υ−1 satisfying
= Λ−1
1,∁.

= 0, Υ−1 ∶

∁ ↦ ker Φ

1
)]

I − P

ran Φ

ran Φ

P

{

}

(

(

[

[

ker Φ
[

1
(

∁ Υ−1 = Υ−1
)]

(

ran Φ
[

1
(

∁
)]

)

1
)]

(

[

1
)

(

(3.19)

It is interesting that a natural generalization of the Johansen I(1) condition is equivalent to our previ-

ous necessary and sufﬁcient condition for the existence of I(1) solutions developed in a general Banach

space setting. This shows that our operator-theoretic approach is in fact closely related to the conventional

∁ and
1
)]

(

[

3.4 that

Johansen’s approach. We know from the equivalence between the three conditions given in Proposition
∁ can be arbitrarily chosen among possible candidates; this, of course,
) in

∁) can always be ﬁxed to

ker Φ
∁ (resp.

1
)]
ker Φ

1
(
)]
ran Φ

implies that

ran Φ

ran Φ

(resp.

ker Φ

⊥

⊥

(

[

[

1
)]

(

[

1
)]

(

[

a Hilbert/Euclidean space setting without loss of generality. Moreover, (3.19) describes how the operator
Υ−1 acts as a map from ran Φ
1
ker Φ
∁ to ker Φ
∁; this in fact provides a full
⊕
)]
(
[
characterization of Υ−1, given that B allows the direct sums given in (3.2).

1
)]

ran Φ

1
)

1
)

⊕

(

(

(

[

1
)]

(

[

In Section 3.3.1, the I(1) condition and the cointegrating behavior of I(1) solutions are characterized
given in the companion form (3.8); however, one may

in terms of some operators associated with ̃Φ
be interested in characterizing those using operators associated with the original AR polynomial Φ
)
The conditions given by (ii) and (iii) in Proposition 3.4 are already given in such a manner, and those are
equivalent reformulations of our I(1) condition. Moreover, our characterization of Υ−1, given by (3.19),
helps us characterize the cointegrating behavior in a desired way; see Remarks 3.7 and 3.8 below. Some

z

z

(

(

)

.

more remarks are given for comparison between our I(1) representation result given by Proposition 3.4 and

the existing ones developed in a Hilbert/Euclidean space setting.

(

1
)

, which is complemented by another subspace

Remark 3.7. From (3.19), we know that the attractor space of I(1) solutions is given by ran Υ−1 =
ker Φ
∁ under Assumption 3.1-(b). We then
∁ , where g ∈ B′.
deduce from Proposition 2.1 that a cointegrating functional f satisﬁes f = g P
1
ker Φ
∁ only
This result, of course, holds for any arbitrary choice of
)]
affects the deﬁnition of P

1
(
)]
∁ without any further changes.

1
(
)]
∁; a different choice of

ker Φ
[

1
)]

ker Φ

ker Φ

(

(

[

[

[

ker Φ
[

1
(

)]

Remark 3.8. Using the results given in Proposition 3.4, we may obtain a stronger characterization of the
cointegrating behavior of I(1) solutions than that given in Section 3.3.1. From the expression of Υ−1 given
in (3.19), we ﬁnd that a nonzero element f ∈ B′ satisﬁes

Xt

f

{

(

t≥0 is I(0) if and only if f ∈ Ann
(

)}

ker Φ

;

1
))

(

(3.20)

see Appendix B.2.3 for our proof of (3.20). The above characterization not only shows that the cointegrat-
ing space is given by Ann
t≥0 for any cointegrating
(

, but also establishes I(0)-ness of

1
))

ker Φ

Xt

)}

f

{

(

(

18

functional f . In the case B = H, any f ∈ H′ is identiﬁed as the map
so f ∈ Ann
is given by the map
(
x, v
⟨
⟩
any v ∈ H

ker Φ
= 0 for all x ∈ ker Φ
,

⟨
if and only if v ∈

for some v ∈

⟩
ker Φ

1
))

1
)]

1
)

⋅, v

⊥

(

(

(

[

[

⋅, v
⟨
ker Φ

⊥

for a unique element v ∈ H,
⟩
1
(To see why, note that
)]

.

(

.) Thus, (3.20) reduces to the following: for

Xt, v

t≥0 is I(0) if and only if v ∈

ker Φ

(3.21)

z

[
is a Fredholm operator satisfying (3.7) and, as a result, ker Φ

If Φ
to the characterization of the cointegrating behavior of I(1) solutions provided by Beare and Seo (2020) and

(
is ﬁnite dimensional, (3.21) reduces

1
)

⟩}

{⟨

(

)

(

⊥

.

1
)]

0
}

\ {

Franchi and Paruolo (2020). However, our results given by (3.20) and (3.21) do not require the Fredholm
=
assumption and, as a consequence, ker Φ
ker Φ

1
)
(
in the case p = 1, we see this from Remark 3.6 and/or Example 3.2.

is not necessarily ﬁnite dimensional; noting that ker ̃Φ
(

1
)

1
)

(

Remark 3.9. If B = H, we know from Proposition 3.4 that the following is a necessary and sufﬁcient
condition for the AR(p) law of motion (3.1) to admit I(1) solutions:

Λ1 = P

ran Φ
[

1
(

)]

1
⊥ Φ(
)

I − P

1
)(

(

ker Φ
[

1
(

⊥

)]

)

∶ ker Φ

If the Fredholm assumption (3.7) holds and thus ker Φ
condition reduces to one of the necessary and sufﬁcient conditions for the AR(p) law of motion (3.1) to

(

⊥

↦

ran Φ

1
)
is ﬁnite dimensional, the above invertibility

is invertible.

1
)]

(3.22)

(

[

(
1
)

admit I(1) solutions given by Beare and Seo (2020, Theorem 3.2). Their invertibility condition, a spe-

(

(

(

1
)

1
)

1
)

ker Φ

1
⊕ Φ(
)

cial case of (3.22), was given together with an equivalent nonorthogonal direct sum condition given by
H = ran Φ
. In the same setting, Franchi and Paruolo (2020) provided a necessary
and sufﬁcient condition for the existence of I(d) solutions for any d ≥ 1, which is characterized as an orthog-
onal direct sum of H and turns out to be useful to identify the cointegrating behavior of I(d) solutions; for
d = 1, their condition is equivalent to the nonorthogonal direct sum condition given by Beare and Seo (2020)
(Franchi and Paruolo, 2020, Proposition 4.6). Under any of these equivalent conditions, solutions to (3.1)
allows the Johansen I(1) representation (3.3) with Υ−1 of ﬁnite rank. (To see why, note that (3.19) implies
ran Υ−1 = ker Φ
is necessarily ﬁnite dimensional under the Fredholm assumption.) This
implies that the random walk component given in (3.3) reduces to a ﬁnite dimensional unit root process. On
the other hand, if Φ
a ﬁnite rank operator (Chang et al., 2016a, Lemma 1). In this case, (3.22) reduces to the condition given by

satisﬁes Assumption 3.1 and Φ

is a compact operator, then Φ

turns out to be

and ker Φ

1
)

1
)

1
)

1
)

z

(

(

)

(

(

(

Chang et al. (2016a, Theorem 2) as a sufﬁcient condition for the existence of I(1) solutions, and the random
walk component of such a solution takes values in ran Υ−1 = ker Φ
H is ﬁnite dimensional. In our results for the case B = H, ran Υ−1 = ker Φ
ﬁnite or inﬁnite dimensional; we see this from Remark 3.6. Thus, our I(1) representation result given by

, which is inﬁnite dimensional unless

is not required to be either

1
)

1
)

(

(

Proposition 3.4 complements the earlier results developed in a Hilbert space setting.

Remark 3.10. Suppose that B = Rn or Cn,
1
.
)]
In this case, Υ−1 may be understood as an n × n matrix. Using the notation introduced for (3.5), the
⊺
⊥⊥Υ−1α⊥⊥ =
results given by (3.19) can be written as β

−1α⊺ = 0 and β

1
(
[
)]
−1β⊺Υ−1 = Υ−1α
(

α⊺α
)

1
)]

1
)]

ran Φ

ran Φ

ker Φ

ker Φ

β⊺β

, and

∁ =

∁ =

−1. We then may deduce that Υ−1 can be written as

⊺
1
⊥⊥Φ(
α
)

(

)

(

(

(

[

[

[

⊥

⊥

(

β⊥⊥

1
)

(

)

Υ−1 = β⊥⊥

⊺
1
⊥⊥Φ(
α
)
(

1
)

(

β⊥⊥

−1

)

⊺
⊥⊥,
α

19

which is equivalent to the expression of Υ−1 given by Johansen (1995, Theorem 4.2).

3.4 Representation of I(2) autoregressive processes

In this section, we suppose that the I(1) condition fails and develop our representation theory for I(2) AR
processes. The failure of the I(1) condition means either of (i) Bp ≠ ran ̃Φ
1
)
(
1
ker Φ
vertibility of the map Λ1,∁ given in (3.17) for some
)]
(
we know that

⊕ ker ̃Φ
or (ii) nonin-
∁. Due to Proposition 3.4,
∁ may be arbitrarily chosen among possible candidates without
[
∁ =
1
loss of generality. Especially,
can be assumed
)]
(
whenever B is a Hilbert space; this helps us compare the results to be developed with the existing I(2) results
given in a Hilbert space setting. We deﬁne P

1
)]
∁ =

[
ran Φ

(
1
)]

1
)]

1
)]

1
)]

1
)]

∁ and

∁ and

ran Φ

ran Φ

ran Φ

ker Φ

ker Φ

ker Φ

1
)

and

⊥

⊥

∁ as in (3.18) and let

∁ and P

(

(

(

(

(

(

[

[

[

[

[

[

R ≔ P

ran Φ
[

1
(

)]

1
∁ Φ(
)

1
)

(

ker Φ

,

1
)

(

ran Φ
[

1
(
)]
K ≔

1
ker Φ
(
[
x ∈ ker Φ

{

)]
1
)

(

1
∶ Φ(
)

1
)

(

x ∈ ran Φ

.

1
)}

(

The conditions that we require for our I(2) representation results are summarized below in Assumption 3.2.

Assumption 3.2.

(a) Assumption 3.1 holds and the I(1) condition fails for some
∁ =

Hilbert space,

ran Φ

ran Φ

ker Φ

and

⊥

[
∁ =

ran Φ

(
ker Φ

[
(b) R (resp. K) can be complemented in

(

[

1
)]

1
)]

[
(
∁ (resp. ker Φ

1
(
)]
ran Φ

1
)]

[
(
∁ = R ⊕ R∁,

ker Φ

1
∁ and
)]
⊥
1
.
)]

(

[
1
)
= K ⊕ K∁.

(
1
)

(

ran Φ

[

(

1
)]

), i.e., for some R∁ ⊂ B and K∁ ⊂ B,

(3.23)

ker Φ

1
)]

(

[

∁; if B is a

The complementary subspaces R∁ and K∁ appearing in Assumption 3.2 do not uniquely exist in gen-
eral; however, our subsequent results only require their existence. The direct sum conditions required by

Assumption 3.2, i.e., (3.2) and (3.23), may not be restrictive in general and do not invalidate that our I(2)

results to be developed can complement the earlier results developed in a general Hilbert space setting;
the regularity condition imposed on Φ
sums and, moreover, places some certain restrictions on the dimensions of the complementary subspaces

for the existing I(2) results strictly implies the required direct

z

(

)

appearing in Assumption 3.2, see Remark 3.11.

[

(

(

)

z

ker Φ

1
)]

∁ (Remark 3.1), and both

is an essential assumption in the existing I(2) representation theorems

Remark 3.11. Fredholmness of Φ
developed in the case B = H. In such a setting, the direct sums given by (3.2) hold for some
ran Φ
and

1
)]
ﬁnite dimensional space can be complemented (Remark 2.3), the direct sums given by (3.23) hold for some
R∁ and K∁. This is also true in a more general situation where B is not necessarily a Hilbert space and
is a Fredholm operator acting on B; this can be seen from Remark 2.3. Note that the Fredholm
Φ
, R∁ and K∁ are all ﬁnite dimensional in (3.2) and (3.23),
naturally leads us to stronger conditions than the direct sums

1
∁
)]
are ﬁnite dimensional. Since every

∁, ker Φ
z

∁ and ker Φ

1
)]

ran Φ

ran Φ

1
)

1
)

z

(

(

(

(

)

(

[

[

assumption requires that
which means that Fredholmness of Φ
required by Assumption 3.2.

(

[

(

)

As in Section 3.3, we ﬁrst develop our representation theory for I(2) AR processes resorting to the

companion form representation (3.8). We then discuss on how the results obtained via the companion form
can be recast in terms of the behavior of the AR polynomial Φ

. In the subsequent discussions, we will

z

(

)

20

need a notion of a generalized inverse operator in our Banach space setting. Appendix A.3 introduces a

suitable one extending the notion of the Moore-Penrose inverse, employed in Beare and Seo (2020) and

Franchi and Paruolo (2020) for their I(2) representation results developed in a Hilbert space setting.

3.4.1 Representation via the companion form
As in Section 3.3.1, we ﬁrst resort to linearization of Φ ∶ C ↦ B, hence consider ̃Φ ∶ C ↦ Bp given in (3.8)
−1 near z = 1 as in (3.11), and also
and (3.9). Under Assumption 3.2, we have the Laurent series of ̃Φ
deﬁne ̃P as in (3.12). Before stating our main results, we collect some preliminary results and ﬁx notation.
can be complemented (Lemma B.2-(i)), i.e., for some

z

(

)

1
Under Assumption 3.2, ran ̃Φ
(
)
∁ ⊂ Bp,

∁ ⊂ Bp and

and ker ̃Φ

1
)

(

ran ̃Φ

1
)]

(

[

⊕

The complementary subspaces

1
)]
ker ̃Φ
∁ given in (3.24) are not uniquely determined
(
in general, but the subsequent results only require their existence and do not depend on a speciﬁc choice of
∁, we may

∁ = ker ̃Φ
(
1
)]

ran ̃Φ
[
∁ and

them. Under the direct sums given by (3.24) and for any choice of
deﬁne the projections P

ran ̃Φ
(

satisfying

ker ̃Φ

ker ̃Φ

1
)]

1
)]

1
)]

1
)]

∁ and

and P

(3.24)

1
)

∁.

⊕

(

(

(

[

[

[

[

[

ker ̃Φ
1
[
(
)]
Bp = ran ̃Φ
1
(
)
ran ̃Φ
(

ran ̃Φ
[
= V∁, ker PV∁

1
∁
(
)]
= V,

ran PV∁

∁
)]

ran ̃Φ
(
satisfying

(

ker ̃Φ
1
[
(
=
V, V∁
)
(
g of ̃Φ
1
)
(
g = Ip −P

,

1
)

ran ̃Φ
(

1
)]

[

∁

)

or

ker ̃Φ

,

1
)

ker ̃Φ
(

1
)]

[

(

∁

)

(

, (3.25)

and the generalized inverse ̃Φ
(
̃Φ
1
)
, P

̃Φ
(

1
)
1
(
)
1
ker ̃Φ
(
[

1
ran ̃Φ
[
(
∁; see Megginson (2012, Theorem 3.2.11) and Appendix A.3. If B = H,

ran ̃Φ
1
∁
[
)]
(
g are uniquely deﬁned for each choice of
1
, and ̃Φ
)
(

ker ̃Φ
[

∁
)]

∁
)]

∁
)]

1
(

(

(

,

̃Φ

g

̃Φ

1
)

1
)

= P

.

The operators P
ker ̃Φ
and
[
1
ran ̃Φ
[
)]
(
projection onto

1
(
)]
⊥
, and

1
)]
⊥

ker ̃Φ
(
1
)]

[
ran ̃Φ
(

∁ =
[
(resp.

⊥

ker ̃Φ

1
)]
(
1
ker ̃Φ
)]

) and ̃Φ
(see Appendix A.3). For notational convenience, we let

(

[

[

, then P
⊥

ran ̃Φ
[
1
)

(

ran ̃Φ
(
1
)]
g becomes the Moore-Penrose inverse of ̃Φ

1
∁
)]
[
∁ =
ran ̃Φ
) becomes the orthogonal
1
)

1
ker ̃Φ
(
[

(resp. P

∁
)]

∁
)]

(

(

[

1
(

(3.26)

(
A crucial preliminary result is that K ≠
is required for ̃Φ
(
B.2-(iv)); based on this result and the notation deﬁned above, we propose our I(2) condition as follows.

∩ ker ̃Φ
(
−1 to have a pole of order 2 at z = 1 (Lemma
z

K = ran ̃Φ
0
}

(3.27)

1
)

1
)

{

)

.

I(2) condition: K ≠

+ker ̃Φ
(
Some remarks on the I(2) condition are given in order.

ran ̃Φ

0
}

1
)

{

(

(

and Bp =

1
))

gK for some

⊕ ̃Φ

1
)

(

ran ̃Φ
(

1
)]

[

∁ and

ker ̃Φ
(

1
)]

[

∁.

1
)

gK, where the latter depends on the choice of

(
g does so. However, it turns out that if the direct sum holds for a speciﬁc choice of

Remark 3.12. The I(2) condition is given as the direct sum of Bp by two subspaces ran ̃Φ
1
1
)
)
and ̃Φ
∁ since the deﬁnition of
ran ̃Φ
̃Φ
1
∁ and
(
)
(
ker ̃Φ
∁, then it also holds for any arbitrary possible choice of those; see Lemma B.2-(iii). Therefore,
[
(
∁ does not affect the subsequent results, and also may be arbitrarily
the choice of
chosen among possible candidates without loss of generality; for example, in a Hilbert space setting, we may
1
)]

ran ̃Φ
(

ran ̃Φ
(

ker ̃Φ
(

+ ker ̃Φ

assume that

ran ̃Φ

ran ̃Φ

ker ̃Φ

ker ̃Φ

ker ̃Φ

1
)]

1
)]

1
)]

1
)]

1
)]

1
)]

1
)]

1
)]

1
)]

∁ and

∁ and

∁ =

∁ =

and

⊥

⊥

(

(

(

(

(

(

(

[

[

[

[

[

[

[

[

[

.

21

[

(

z
(
⊥

)
and

ran ̃Φ
(

satisﬁes the Fredholm assumption (3.7). In this case, we
⊥

Remark 3.13. Suppose that B = H and Φ
∁ =
ker ̃Φ
ran ̃Φ
1
may assume that
(
)]
above without loss of generality (see Remark 3.12), then ̃Φ
of ̃Φ
1
)
(
that ̃Φ
z
(
K ≠
0
}

1
)
(see Appendix A.3). In this setting, Beare and Seo (2020, Theorem 4.2 and Remark 4.7) showed
−1 has a pole of order 2 at z = 1 if and only if Hp =
†K for
1
⊕ ̃Φ
1
(
)
)
(
))
.3 However, it is worth noting that Fredholmness of ̃Φ
(and thus K) to be
z
ﬁnite dimensional while no such restriction required in our I(2) condition; see Example 3.5 to appear later.

∁ =
1
)]
g becomes the Moore-Penrose inverse ̃Φ
1
(
)

in the I(2) condition given
†

ran ̃Φ
1
)
(
requires ker ̃Φ

+ ker ̃Φ
1
)

ker ̃Φ
(

1
)]

1
)]

{

(

)

(

(

(

[

[

[

Our next result shows that the proposed I(2) condition is indeed necessary and sufﬁcient for ̃Φ
to have a pole of order 2 at z = 1, and provides a partial characterization of the principal part of the
Laurent series; a more detailed characterization of the principal part can be obtained in terms of some
operators associated with ̃Φ
(
and concepts, which are to be developed in Appendix B, are required.

, but which is postponed to Appendix B.3.3 since more preliminary results

z

z

(

)

)

−1

Proposition 3.5. Suppose that Assumption 3.2 holds. Then ̃Φ
(
I(2)condition holds. UndertheI(2)condition, thefollowing holdsforsome η > 0,

z

)

−1 has a pole of order 2 if and only if the

1 − z

(

2

̃Φ

z

(

)

)

−1 = − ̃N−2 +

1 − z

̃N−2 + ̃P

+

1 − z

2H

z

,

z ∈ D1+η,

(3.28)

)(

(
(
isthe holomorphic part ofthe Laurent series of ̃Φ

(

)

)

)

z

converges on D1+η.

−1,and each

z

(

)

where ̃N−2 satisﬁes ran ̃N−2 = K, H
Maclaurin series of

z
(
−1 andH

1 − z

z

)

2

̃Φ

(

)
Examples of the use of Proposition 3.5 for verifying that ̃Φ
(

)

)

(

(

z

)

−1 has a pole of order 2 will be given
−1

at the end of this section. Proposition 3.5 provides a characterization of the local behavior of ̃Φ
around z = 1 under the I(2) condition, which, together with Proposition 3.1, leads to our ﬁrst version of the
Granger-Johansen representation theorem for I(2) AR processes as follows.

z

(

)

Proposition 3.6. Suppose that Assumption 3.2 holds. Under the I(2) condition, a sequence

satisfying (3.1) allowstheJohansen I(2)representation (3.4) with

Xt

{

}

t≥−p+1

Υ−2 =−Πp ̃N−2Π∗

p , Υ−1 =Πp

̃N−2 + ̃P

)

(

Π∗
p ,

νt =ΠpH

Π∗

p εt =

L

(

)

∞

∑
j=0

Πp ̃Φj

1

Ip − ̃P

(

)

Π∗

p εt−j ,

(3.29)

where ̃N−2, ̃P and H
AR(p)lawofmotion (3.1) doesnotallowI(2)solutions iftheI(2)condition isnotsatisﬁed.

are given in Proposition 3.5, and Πp and Π∗

z

(

)

p are given in (3.10). Moreover, the

Πp ̃N−2Π∗

Note that the representation (3.4) with (3.29) is similar to the Beveridge-Nelson decomposition (2.6)
of an I(2) cointegrated linear process. From our discussion in Section 2.4, we may deduce that f ∈
∩Ann
Ann
) is a cointegrating functional (resp. a second-
(
(
order cointegrating functional). Appendix B.3.3 provides characterizations of ̃N−2 and ̃P in terms of certain
operators associated with ̃Φ
(

, which complements the results given by Proposition 3.6.

In this section, we have shown that the AR(p) law of motion (3.1) admits I(2) solutions if and only if

(resp. f ∈ Ann
(

Πp ̃N−2Π∗

Πp ̃PΠ∗

z

)

)

)

)

p

p

p

3In fact, the direct sum condition given by Beare and Seo (2020, Theorem 4.2 and Remark 4.7) is slightly different. However,
⊕

with a simple algebra, it can be shown that the direct sum given in the I(2) condition is equivalent to B =
Φ
Ip − ̃
(

K, which is exactly comparable with their direct sum condition.

+ ker

Φ
̃
(

1
)

1
)

ran

Φ
̃

))

1

(

(

)

(

g

22

the I(2) condition holds, and provided a partial characterization of such solutions. All these results are ob-

tained resorting to the companion form representation of (3.1), hence it is not clearly revealed how the I(2)

z

. This issue will be addressed in the next section by providing a more detailed characterization

condition and the cointegrating behavior of I(2) solutions are related to the structure of the original AR poly-
nomial Φ
of I(2) solution in terms of operators associated with Φ
of the use of Proposition 3.5 for verifying that ̃Φ

. Before closing this section, we give examples

−1 has a pole of second order.

z

z

)

(

)

(

(

)

Example 3.4. Consider Example 3.3, where we showed that ̃Φ
(
1
hence know that Assumption 3.2-(a) holds. Note that ran ̃Φ
1
)
(
)
(
ker ̃Φ
1
ran ̃Φ
subspace
(
)]
, ∶ bj ∈ C, lim
∁ =
b1, 0, b2, b3, . . .
j→∞
⊕ R = ran Φ

−1 does not have a simple pole at z = 1,
z
)
(resp. ker ̃Φ
) allows a complementary
1
∁ and
)]

1
[
)]
b1, 0, 0, . . .

1
ker ̃Φ
)]
(
, b1 ∈ C

ran ̃Φ
∁ =

∁); speciﬁcally,

∁ may be set to

bj = 0
}

[
1
)]

ran ̃Φ

∁ (resp.

ker ̃Φ

1
)]

.

+

{(

{(

}

)

(

(

(

)

(

[

[

[

[

,

ker Φ

Then it can be shown that Assumption 3.2-(b) is also satisﬁed; observe that ran Φ
1
1
Φ(
)
(
)
for R∁ =
[
0, b1, 0, . . .

and K = ker ̃Φ
(
∈
ran ̃Φ
1
(
)]
g, we obtain
1
)

. Pre-composing both sides of this equation with ̃Φ

= ran ̃Φ
1
(
)
∁ and K∁ =
1
)]

+ker ̃Φ
0
}

1
)
b1, 0, . . .

1
(
)
ran ̃Φ

(
. For any

= ran ̃Φ

1
)

1
)

{

(

(

)

(

)

(

[

1
)

(

, hence the required direct sums hold
=
∁, we ﬁnd that − ̃Φ

b1, 0, . . .

1
)(

(

)

1
)

(

where the equality holds since
(
and the fact that K = ran ̃Φ
1
1
)
)
which is a complementary subspace of ran ̃Φ
(

(

∈

(
b1, 0, . . .
)
∩ ker ̃Φ
(

=

(

̃Φ
)
ker ̃Φ
1
)]
[
(
= ker ̃Φ
1
)
(
+ ker ̃Φ
1
)

g

,

1
)
(
∁ and ̃Φ
1
. From (3.16), (3.30)
)
, b1 ∈ C
, we deduce that ̃Φ
b1, 0, . . .
(
}
−1 has a pole of order 2 at z = 1.
. Thus, ̃Φ

= P
1
)

ker ̃Φ
1
[
(
gK =

)
1
)

(3.30)

∁
)]

̃Φ

{(

z

(

)

(

,

1
)

(

(

)

−b1, 0, . . .

g

(
0, b1, 0, . . .

and K are ﬁnite dimensional
Example 3.5. In the setting of Examples 3.3 and 3.4, we observed that ker ̃Φ
(
under the I(2) condition. However, these subspaces may not be ﬁnite dimensional in general. To see this, we
will consider slight modiﬁcations of Φ1; under any of the changes in Φ1 to be given below, it can be easily
shown that Assumption 3.2 is still satisﬁed. We ﬁrst replace (3.15) with the following,

1
)

Φ1

a1, a2, a3, a4 . . .

(

)
It can be easily shown that ̃Φ
1
)

ran ̃Φ

=

(
z

)

(
=

ker ̃Φ

=

(
1
(
)
∩ ker ̃Φ
(

{(

{(
1
)

a1, a2 + a1, a3 + a1, a4, a5 + a4, a6 + a4, a7, a8 + a7, a9 + a7, . . .

.

is invertible for z ≠ 1. We note that ran ̃Φ
0, b1, b1, 0, b2, b2, 0, b3, b3, . . .

1
)

(

(

1
)
∶ bj ∈ C, lim
j→∞
∶ bj ∈ C, lim
j→∞

and ker ̃Φ
bj = 0
,
}
.

bj = 0
}

)

0, b1, b2, 0, b3, b4, 0, b5, b6, . . .

)

)
are given by

1
)

1
)

Since K = ran ̃Φ
= ran ̃Φ
(
are inﬁnite dimensional. With some algebra, it may be deduced that ran ̃Φ
1
(resp. ker ̃Φ
(
)
(
ker ̃Φ
1
∁ may be set to
complementary subspace
)]
(
[
∶ bj ∈ C, lim
bj = 0
j→∞
}

, we know from (3.31) and (3.32) that both ker ̃Φ
1
)

ker ̃Φ
1
)]
b1, 0, b2, b3, 0, b4, b5, 0, b6, . . .

∁), and especially

ran ̃Φ
∁ =

∁ (resp.

1
)]

[
ker ̃Φ
1
(
)]
b1, 0, b2, b3, 0, b4, b5, 0, b6, . . .

Moreover, note that for

1
)

{(

(

(

(

[

[

.

and K
(
) allows a

(
− ̃Φ
(
b1, 0, b2, b3, 0, b4, b5 . . .

1
)(

Since

(

)
b1, 0, b2, b3, 0, b4, b5 . . .

∈

ker ̃Φ

1
)]

∁ and ̃Φ
(

(

[

)

= P

1
ker ̃Φ
(
[

∁
)]

, we ﬁnd the following equal-

)
ker ̃Φ
0, b1, b1, 0, b3, b3, . . .

1
)]

∁,

(

∈

[
=

.

)

g

)
1
)

(
1
)

̃Φ
(

23

(3.31)

(3.32)

(3.33)

(3.34)

g,

ity by pre-composing both sides of (3.34) with ̃Φ
(
b1, 0, b2, b3, 0, b4, b5 . . .
−

1
)
=

)
(
From (3.31), (3.32) and (3.35), we deduce that ran ̃Φ
(
hence ̃Φ
(

−1 has a pole of order 2 at z = 1.

Now we replace (3.15) with the following,

z

)

g

̃Φ
1
(
)
(
+ker ̃Φ
(

1
)

0, b1, b1, 0, b3, b3, . . .

.

(3.35)

gK =

1
)

ker ̃Φ
(

1
)]

[

∁,

)
and ̃Φ
(

1
)

= ker ̃Φ
(

1
)

Then, we ﬁnd that

a1, a2, a3, a4 . . .

Φ1

(

=

)

(

a1, a2 + a1, a3, a4, a5, . . .

.

)

,

)

)

(

}

=

=

{(

{(

1
)

1
)

1
)

, (3.36)

ker ̃Φ

ran ̃Φ

∶ b1 ∈ C

∶ bj ∈ C, lim
j→∞

bj = 0
}

0, b1, 0, 0, . . .

0, b1, b2, b3, . . .

is inﬁnite dimensional but K is ﬁnite dimensional.

. From similar arguments, it can be shown that our I(2) condition holds. In this case,

1
(
)
and thus K = ran ̃Φ
(
as may be deduced from (3.36), ker ̃Φ
3.4.2 Further characterization of I(2) solutions
Suppose that B = Rn or Cn and the Johansen I(1) condition fails. With the notation introduced for (3.5), we
β⊥⊥ = ̟̺⊺, where s < n − r. Let ̟⊥⊥
let ̟ and ̺ be full-rank
(resp.
(
⊺
⊥⊥̺⊥⊥ = In−r−s (the identity matrix
−1 to

β, β⊥⊥̺
(
)
of dimension n − r − s). Johansen (1992, 1995) provides a necessary and sufﬁcient condition for Φ
have a pole of order 2 at z = 1, which is given by that

⊺
1
⊥⊥Φ(
× s matrices satisfying α
)
(
matrix whose columns are orthogonal to those of

). Without loss of generality, we may assume that ̟

(resp. ̺⊥⊥) be a full-rank n ×

⊺
⊥⊥̟⊥⊥ = ̺

n − r − s

α, α⊥⊥̟

n − r

1
)

z

)

)

(

(

(

(

)

)

⊺
⊥⊥

̟

1
2

2
Φ(
)

1
)

(
(
† is the Moore-Penrose inverse of Φ

(

1
− Φ(
)

Φ

1
)

1
)

(

1
†Φ(
)

1
))

(

̺⊥⊥ is invertible,

(3.37)

where Φ
condition that can be applied to our Banach space setting, as we did in Section 3.3.2 for the I(1) case, we

. To provide a natural generalization of the Johansen I(2)

1
)

1
)

(

(

ﬁrst review some preliminary results that hold under Assumption 3.2 and ﬁx notation.

Under Assumption 3.2, we let P

ran Φ
[

1
(

)]

∁ and P

ker Φ
[

1
(

)]

∁ be deﬁned as in (3.18), and also let Φ

denote the generalized inverse satisfying the following properties:

g

1
)

(

g = Ip −P

Φ

Φ

1
(
)
∁ , P
ran Φ
)]
[
∁. If B = H and thus

1
)
(
ker Φ
[

The operators P
∁ =
ker Φ
and
[
g is equivalent to the Moore-Penrose inverse Φ
1
Φ
)

1
)]

1
(

1
(

)]

(

(

[

(

)]

1
ran Φ
(
[
g are all uniquely deﬁned for any ﬁxed choice of
1
∁ and Φ
[
)
(
ker Φ
1
ran Φ
and
(
)]

∁ =
; see Appendix A.3. Moreover, we note

ran Φ
⊥
1
)]

1
∁
(
)]
, then

ker Φ
[

1
)]

ker Φ

1
(

)]

⊥

(

(

[

[

(

(
that the direct sum conditions given in Assumption 3.2 can be combined and equivalently formulated as

(

1
ran Φ
)]
(
† of Φ
1
)

[
1
)

(3.38)

∁ .

∁ ,

= P

Φ

gΦ

1
)

1
)

follows,

B = ran Φ
1
)
(
∁ = R ⊕ R∁ and ker Φ
1
where
)
deﬁne the projections PR∁ and PK satisfying

1
)]

ran Φ

(

(

[

⊕ R ⊕ R∁ =

ker Φ

(3.39)
= K ⊕ K∁. Then for any possible choice of R∁ and K∁, we may

1
)]

∁ ⊕ K ⊕ K∁,

(

[

= R∁,

ran PR∁

1
ker Φ
(
)
see Megginson (2012, Theorem 3.2.11). Suppose that B = Rn or Cn, R∁ = R⊥

ker PR∁

ker PK =

= ran Φ

ran PK = K,

⊕ R,

[

∁ ⊕ K∁;

1
)]

(
(the orthogonal comple-

(3.40)

24

(

1
)

⊕ R), and K∁ = K⊥

(the orthogonal complement to

ment to ran Φ
Johansen I(2) condition given by (3.37) can be alternatively understood as invertibility of PR⊥
1
Φ(
)
condition is a special case of the following more general condition stated without the notion of an orthogonal
complement in a general Banach space setting: for some choice of R∁ and K∁,

⊕ K) hold. Then the
2
Φ(
) −
. Given this observation, we know that the Johansen I(2)

PK as a map from K to R⊥

1
†Φ(
)

1
))

1
)]

ker Φ

1
)

1
)

Φ

1
2

⊥

(

(

(

(

(

[

1
2

2
Φ(
)

1
− Φ(
)

(

1
)

Λ2,∁ ≔ PR∁

1
)
We will show in Proposition 3.7 below that the above condition is equivalent to our I(2) condition developed
in a general Banach space setting, and also characterize Υ−2 and Υ−1 in terms of some operators associated
with the AR polynomial Φ
using this equivalence. To simplify mathematical expressions, we employ the
following notation:

PK ∶ K ↦ R∁ is invertible.

1
))

(3.41)

1
)

Φ

z

)

(

(

(

(

(

1
gΦ(
)

1
∁ Φ(
)

,

)]

I − P

M2 =

ran Φ
[
2
Φ(
)

(
1
− Φ(
)

M1 = P
1
2
1
6

1
)(
1
)
1
)
As the last piece of our preliminary results for Proposition 3.7, we note that the generalized inverse Mg
M1 is uniquely deﬁned for any choice of R∁ and K∁ under Assumption 3.2, and it satisﬁes ran Mg
and ker Mg

∁
)]
1
)
1
)

1
(
1
)
1
)

ker Φ
[
1
gΦ(
)

⊕ R∁ (Lemma B.3).

1
)
1
)

1
− Φ(
)

1
gΦ(
)

1
gΦ(
)

M3 =

1 = ran Φ

3
Φ(
)

1
)

1
)

1
(

Φ

Φ

Φ

(

(

(

(

(

(

(

(

(

(

)

.

,

1 of
1 = K∁

1
)

(

Proposition 3.7. Suppose thatAssumption 3.2holds. Thenthefollowing conditions areequivalent.

(i) TheI(2)condition holds.

(ii) Λ2,∁ ∶ K ↦ R∁ isinvertible forsomechoice of R∁ and K∁.

(iii) Λ2,∁ ∶ K ↦ R∁ isinvertible foreverypossible choice of R∁ and K∁.
Letanyoftheaboveconditions hold. Thenforanychoice of R∁ and K∁,asequence
(3.1) allowstheJohansen I(2)representation (3.4) with Υ−2 satisfying

t≥−p+1 satisfying

Xt

{

}

I − PK

(

)

Υ−2 = Υ−2

I − PR∁

= 0,

)

(

Υ−2 ∶ R∁ ↦ K = Λ−1
2,∁,

(3.42)

and Υ−1 satisfying

I − PK

Υ−1

I − PR∁

(

I − PK

(
PKΥ−1

)

(
Υ−1PR∁

)
I − PR∁

=

)
Φ
(
(
= Υ−2

= −Mg
1,
1
gΦ(
1
)
)
1
Φ(
)

+ Mg

Υ−2,

1M2
)
g + M2Mg

1

,

1
)
Φ

(
1
)
1
)

1
)
(
1
gΦ(
)

)
1
− Φ(
)

(

)
= Υ−2

(
(
M3 − M2Φ
(

(

PKΥ−1PR∁

1
)
Proposition 3.7 not only shows that the condition given by (3.41) is equivalent to our I(2) condition
developed in a general Banach space setting, but also implies that R∁ and K∁ can be arbitrarily chosen among
possible candidates; this, of course, means that R∁ and K∁ can always be ﬁxed to the relevant orthogonal
complements in a Hilbert/Euclidean space setting without loss of generality. Moreover, Proposition 3.7
characterizes in detail how Υ−2 and Υ−1 act on B satisfying the tripartite decompositions given by (3.39).

Υ−2.

1M2

1
)

1
)

Φ

)

(

(

(

gM2 − M2Mg

25

Based on such characterizations, we can further characterize I(2) solutions; see Remarks 3.14-3.16 below.

Some more remarks are given for comparison between our I(2) representation result given by Proposition

3.7 and the existing I(2) results developed in a Hilbert/Euclidean space setting.

Remark 3.14. From (3.42), we know that the attractor space associated with I(2) solutions is given by
ran Υ−2 = K. Then Proposition 2.1 implies that a cointegrating functional f satisﬁes f = g
, where
g ∈ B′. This result holds for any arbitrary choice of K∁; a different choice of K∁ only affects the deﬁnition
of PK without any further changes.

I − PK

)

(

Remark 3.15. Using the results given in Proposition 3.7, we can obtain a stronger characterization of the
cointegrating behavior of I(2) solutions as follows: for any nonzero element f ∈ B′ and for some r ∈

,

Xt

Xt

f

f

{

{

(

(

)}

)}

t≥0 is I(r) if and only if f ∈ Ann
(
t≥0 is I(0) if and only if f ∈ Ann
(

,

K
)
ker Φ

1
))

(

∩ Ann
(

Φ

1
)

(

1
gΦ(
)

.

1
)

K
)

(

(3.44)

Obviously, (3.43) (resp. (3.44)) identiﬁes the cointegrating space (the collection of the second-order cointe-

grating funcitonals). A detailed discussion including our proofs of these results is given in Appendix B.3.4.
If B = H and thus the complementary subspaces are all set to the relevant orthogonal complements, then
1
Φ
is given by
)

† (see Appendix A.3) and f ∈ Ann
(

g is equivalent to the Moore-Penrose inverse Φ

(see Remark 3.8). In this case, (3.43) and (3.44) can be reformulated as

for some v ∈ V

V

⊥

(

)

(

1
)
⋅, v
the map
follows: for any v ∈ H

⟩

⟨

0, 1
{
}
(3.43)

\ {

⟩}

,

0, 1
}

and for some r ∈

0
}
t≥0 is I(r) if and only if v ∈ K⊥
t≥0 is I(0) if and only if v ∈

{

,

{⟨

Xt, v

Xt, v

{⟨

(
satisﬁes the Fredholm assumption (3.7) and, as a result, both ker Φ

and K is ﬁnite dimensional,
If Φ
our characterization given by (3.45) and (3.46) reduces to that provided by Beare and Seo (2020, Remarks

⟩}

z

(

(

(

(

)

[

[

ker Φ

∩

Φ

⊥

1
)]

1
)

K
]

1
†Φ(
)

1
)
1
)

4.5 and 4.6). It, however, should be noted that (3.45) and (3.46) hold without the Fredholm assumption and,
and K = K
thus, ker Φ
hold in the case p = 1, we see from Example 3.5 that those can be inﬁnite dimensional.

and K are not required to be ﬁnite dimensional; noting that ker ̃Φ

= ker Φ

1
)

1
)

1
)

(

(

(

⊥

.

(3.45)

(3.46)

K
)

, f may or may not satisfy f ∈ Ann
(

Remark 3.16 (Polynomial cointegration for an I(2) AR process). For any cointegrating functional f ∈
Ann
(

since K ⊂ ker Φ
1
1
and one combines levels and ﬁrst differences as in f
− f
(
)
)
(
is always I(0); this phenomenon does not occur if f ∉ Ann
ker Φ
(
our proof of this result is given in Appendix B.3.5. The case where the sequence of f

1
gΦ(
)
1
. A detailed discussion including
))

1
))
(
, then such a sequence

. If f ∈ Ann

1
(
)
∆Xt

1
(
))
Xt

and that of

ker Φ

ker Φ

Φ

)

(

(

(

)

(

1
gΦ(
)

f

Φ

(

1
)

(

∆Xt

1
)

(

)

are both I(1) may be understood as polynomial cointegration or multicointegration

(Yoo, 1987; Granger and Lee, 1989; Engsted and Johansen, 1997; Kheifets and Phillips, 2019) in our set-
ting; a detailed treatment of this topic for the case B = H is given by Franchi and Paruolo (2020, Section
g may be set to the Moore-Penrose inverse Φ
4.2). In the case B = H, Φ
(resp.
f ∈ Ann
1
ker Φ
)]
⟨
(
above characterization given in a Banach space setting can be rewritten as follows: for f ∈ K⊥
of

† and f ∈ Ann
(
⊥

K
)
). Then the

. If the Fredholm assumption

is I(0) if and only if f ∈

for some v ∈ K⊥

1
)
(resp. v ∈

) is identiﬁed as the map

1
))
1
†Φ(
)

, the sequence

∆Xt, v

Xt, v

ker Φ

ker Φ

1
)

⋅, v

Φ

−

⊥

(

(

(

(

[

⟩

⟨

⟩

⟨

1
)

(

1
)

(

⟩

1
)]

(

[

Xt

(

)

26

(3.7) holds, this result becomes consistent with the characterization of polynomial cointegration given by
and K are necessarily ﬁnite dimensional un-
Franchi and Paruolo (2020, Remark 4.10). However, ker Φ
der the Fredholm assumption, while such restrictions are not required for our results given in this remark;

1
)

(

see Remark 3.15 and Example 3.5.

Remark 3.17. Suppose that B = H and all the complementary subspaces are set to the relevant orthogonal
complements. In this case, (3.41) reduces to that

1
2

2
Φ(
)

1
− Φ(
)

1
†Φ(
)

PK ∶ K ↦ R⊥

(

(

(

Φ

PR⊥

1
)

1
)

1
)

1
))
(
where PR⊥ (resp. PK) is the orthogonal projection onto R⊥
satisﬁes the Fredholm as-
and K are ﬁnite dimensional, then (3.47) reduces to the invertibility
sumption (3.7) and thus both ker Φ
condition for the existence of I(2) solutions given by Beare and Seo (2020, Theorem 4.2). Their condi-
tion is given together with an equivalent nonorthogonal direct sum condition in H; on the other hand,
Franchi and Paruolo (2020) provided an orthogonal direct sum condition for the existence of I(2) solutions

(resp. K). If Φ

is invertible,

(3.47)

1
)

z

(

)

(

(

under the same setting, see Section 4 of their paper. Under any of these equivalent conditions, solutions to
the AR(p) law of motion satisﬁes the Johansen I(2) representation (3.4) for Υ−2 and Υ−1 of ﬁnite rank; it
can be deduced from our characterizations of Υ−2 and Υ−1 given in Proposition 3.7 that the ranges of these
and K are ﬁnite dimensional. Hence the random walk com-
operators are ﬁnite dimensional if both ker Φ
ponent of I(2) solutions is intrinsically a ﬁnite dimensional unit root process. However, in our results for the
or K is not required to be ﬁnite dimensional and the random walk component
case B = H, either ker Φ
can take values in an inﬁnite dimensional subspace; we see this by noting that ran Υ−2 = K and K can be
inﬁnite dimensional as in Example 3.5. Thus, Proposition 3.7 complements the earlier I(2) representation

1
)

1
)

(

(

results developed in a Hilbert space setting.

(

(

(

(

1
2

Φ

̟

⊺
⊥⊥

̺⊥⊥

1
)

1
)

2
Φ(
)

̟⊺̟

1
))

1
†Φ(
)

1
− Φ(
)

(
2
Φ(
)

Υ−2 = ̺⊥⊥

−1̺⊺Υ−2 = Υ−2̟

⊺
⊥⊥Υ−2̟⊥⊥ =
and ̺

Remark 3.18. Suppose that B = Rn or Cn and all the complementary subspaces are set to the relevant
orthogonal complements. In this case, Υ−2 and Υ−1 may be understood as n×n matrices. Using the notation
−1̟⊺ = 0
̺⊺̺
introduced for (3.37), the results given in (3.42) can be recast as ̺
(
)
−1. From these results, we ﬁnd that
1
)
⊺
⊥⊥

1
)
⊺
⊺
−1. Then the operator M1 can be written
Let α1 = α⊥⊥̟, β1 = β⊥⊥̺, α1 = α1
1 β1
β
α
1α1
(
⊺
1. By replacing Υ−2 and Mg
⊥⊥ and its Moore-Penrose inverse M†
1 is given by M†
as M1 = α⊥⊥̟̺⊺β
1
with (3.48) and M†
1 respectively in our characterization of Υ−1 given in Proposition 3.7, we can obtain Υ−1
characterized as an n × n matrix. These expressions for Υ−2 and Υ−1 are equivalent to those in Johansen’s
representation of I(2) AR processes (see e.g., Johansen, 2008, Theorem 5). The case where B = Rn or Cn
was discussed in detail as a special case of a Hilbert space in the recent literature, so the results given in this
remark were already noted in the earlier works; see e.g., Beare and Seo (2020, Remark 4.4).

1
(
)
−1 and β1 = β1

)
1
†Φ(
)

1 = β1α

1
− Φ(
)

1
))

(3.48)

1
)

⊺
⊥⊥.

̺⊥⊥

1
2

̟

̟

Φ

−1

(

[

]

(

)

(

(

(

(

(

)

)

⊺

27

4 Concluding remarks

In this paper, we provide a suitable notion of cointegration in Banach spaces and study theoretical properties

of the cointegrating space. We also extend the Granger-Johansen representation theorem to a potentially

inﬁnite dimensional Banach space setting. Compared to the existing results, our representation theorems are

derived under a weaker geometry of a Banach space and weaker regularity conditions on the AR polynomial.

As a consequence, not only more general AR(p) law of motions can be accommodated in our representation

theory, but also our results do not place any dimensionality restrictions on the random walk component of

I(1) or I(2) solutions to a given AR(p) law of motion.

To develop our representation theorems under weaker assumptions, this paper only focuses on the I(1)

and I(2) cases; on the other hand, Franchi and Paruolo (2020) recently studied the general I(d) case for
d ≥ 1 and provided a complete characterization of the cointegrating behavior in a convenient form based on
the geometry of a Hilbert space and the spectral properties of Fredholm operator pencils. Extending their

results directly to our Banach space setting, where non-Fredholm AR polynomials are allowed, seems to be

nontrivial. This can certainly be further explored in the future study.

Beyond representation theory, research on the development of statistical procedures for analyzing Banach-

valued cointegrated time series also needs to be pursued to complement the existing papers on estimation,

testing, and forecasting with stationary Banach-valued time series such as e.g., Pumo (1998), Bosq (2002),
Labbas and Mourid (2002), Dehling and Sharipov (2005), Ruiz-Medina and ´Alvarez-Li´ebana (2019), and
Dette et al. (2020). There may be a lot of possibilities for further studies in this direction.

References

Albrecht, A., Howlett, P., and Verma, G. (2019). The fundamental equations for the generalized resolvent
of an elementary pencil in a unital Banach algebra. Linear Algebra and its Applications, 574:216–251.

Albrecht, A. R., Howlett, P. G., and Pearce, C. E. (2011). Necessary and sufﬁcient conditions for the
inversion of linearly-perturbed bounded linear operators on Banach space using Laurent series. Journal
of mathematical analysis and applications, 383(1):95–110.

Amouch, M., Abdellah, G., and Messirdi, B. (2015). A spectral analysis of linear operator pencils on
Banach spaces with application to quotient of bounded operators. International Journal of Analysis and
Application, 7:104–128.

Bart, H., Gohberg, I., Kaashoek, M., and Ran, A. C. M. (2007). Factorization of Matrix and Operator

Functions: The State Space Method. Birkh¨auser Basel.

Beare, B. K., Seo, J., and Seo, W.-K. (2017). Cointegrated linear processes in Hilbert space. Journal of

Time Series Analysis, 38(6):1010–1027.

Beare, B. K. and Seo, W.-K. (2020). Representation of I(1) and I(2) autoregressive Hilbertian processes.

Econometric Theory, 36(5):773–802.

Bosq, D. (2000). Linear Processes in Function Spaces. Springer-Verlag New York.

Bosq, D. (2002). Estimation of mean and covariance operator of autoregressive processes in Banach spaces.

Statistical inference for stochastic processes, 5(3):287–306.

28

Chang, Y., Hu, B., and Park, J. Y. (2016a). On the error correction model for functional time series with unit

roots. Mimeo, Indiana University.

Chang, Y., Kim, C. S., and Park, J. Y. (2016b). Nonstationarity in time series of state densities. Journal of

Econometrics, 192(1):152 – 167.

Conway, J. B. (1994). A Course in Functional Analysis. Springer.

Dehling, H. and Sharipov, O. S. (2005). Estimation of mean and covariance operator for Banach space
valued autoregressive processes with dependent innovations. Statistical inference for stochastic processes,

8(2):137–149.

Dette, H., Kokot, K., Aue, A., et al. (2020). Functional data analysis in the Banach space of continuous

functions. Annals of Statistics, 48(2):1168–1192.

Engl, H. W. and Nashed, M. (1981). Generalized inverses of random linear operators in Banach spaces.

Journal of Mathematical Analysis and Applications, 83(2):582 – 610.

Engle, R. F. and Granger, C. W. J. (1987). Co-integration and error correction: Representation, estimation,

and testing. Econometrica, 55(2):251–276.

Engsted, T. and Johansen, S. (1997). Granger’s representation theorem and multicointegration.
Fabian, M., Habala, P., H´ajek, P., Montesinos, V., and Zizler, V. (2010). Banach Space Theory. Springer-

Verlag GmbH.

Faliva, M. and Zoia, M. G. (2002). On a partitioned inversion formula having useful applications in econo-

metrics. Econometric theory, pages 525–530.

Faliva, M. and Zoia, M. G. (2010). Dynamic Model Analysis. Springer Berlin Heidelberg.
Faliva, M. and Zoia, M. G. (2011). An inversion formula for a matrix polynomial about a (unit) root. Linear

and Multilinear Algebra, 59:541–556.

Faliva, M. and Zoia, M. G. (2021). Cointegrated solutions of unit-root VARs: An extended representation

theorem. arXiv preprint arXiv:2102.10626.

Franchi, M. and Paruolo, P. (2016). Inverting a matrix function around a singularity via local rank factoriza-

tion. SIAM Journal on Matrix Analysis and Applications, 37(2):774–797.

Franchi, M. and Paruolo, P. (2019). A general inversion theorem for cointegration. Econometric Reviews,

pages 1–26.

Franchi, M. and Paruolo, P. (2020). Cointegration in funcational autoregressive processes. Econometric

Theory, 36(5):803–839.

Gohberg, I., Goldberg, S., and Kaashoek, M. (2013). Classes of Linear Operators Vol. I. Birkh¨auser.

Granger, C. W. and Lee, T.-H. (1989).

Investigation of production, sales and inventory relationships us-
ing multicointegration and non-symmetric error correction models. Journal of applied econometrics,

4(S1):S145–S159.

Granger, C. W. J. (1981). Some properties of time series data and their use in econometric model speciﬁca-

tion. Journal of Econometrics, 16(1):121 – 130.

Hansen, P. R. (2005). Granger’s representation theorem: A closed-form expression for I(1) processes.

Econometrics Journal, 8(1):23–38.

H¨ormann, S., Horv´ath, L., and Reeder, R. (2013). A functional version of the ARCH model. Econometric

29

Theory, 29(2):267–288.

Horv´ath, L., Huˇskov´a, M., and Kokoszka, P. (2010). Testing the stability of the functional autoregressive

process. Journal of Multivariate Analysis, 101(2):352–367.

Hu, B. and Park, J. Y. (2016). Econometric analysis of functional dynamics in the presence of persistence.

Mimeo, Indiana University.

Johansen, S. (1991). Estimation and hypothesis testing of cointegration vectors in Gaussian vector autore-

gressive models. Econometrica, 59(6):1551–1580.

Johansen, S. (1992). A representation of vector autoregressive processes integrated of order 2. Econometric

theory, 8(2):188–202.

Johansen, S. (1995). Likelihood-Based Inference in Cointegrated Vector Autoregressive Models. Oxford

University Press.

Johansen, S. (2008). Representation of cointegrated autoregressive processes with application to fractional

processes. Econometric Reviews, 28(1-3):121–145.

Kato, T. (1995). Perturbation Theory for Linear Operators. Springer.

Kheifets, I. and Phillips, P. C. (2019). Fully modiﬁed least squares for multicointegrated systems.
Labbas, A. and Mourid, T. (2002). Estimation et pr´evision d’un processus autor´egressif Banach. Comptes

Rendus Mathematique, 335(9):767–772.

Laursen, K. B. and Mbekhta, M. (1995). Operators with ﬁnite chain length and the ergodic theorem. Pro-

ceedings of the American Mathematical Society, 123(11):3443–3448.

Markus, A. S. (2012). Introduction to the Spectral Theory of Polynomial Operator Pencils (Translations of

Mathematical Monographs). American Mathematical Society.

Megginson, R. E. (2012). Introduction to Banach Space Theory. Springer New York.
Phillips, P. C. B. and Solo, V. (1992). Asymptotics for linear processes. The Annals of Statistics, 20(2):971–

1001.

Pumo, B. (1998). Prediction of continuous time processes by C[0, 1]-valued autoregressive process. Statis-

tical Inference for Stochastic Processes, 1(3):297–309.

Ruiz-Medina, M. D. and ´Alvarez-Li´ebana, J. (2019). Strongly consistent autoregressive predictors in ab-

stract Banach spaces. Journal of Multivariate Analysis, 170:186–201.

Schumacher, J. M. (1991). System-Theoretic Trends in Econometrics, pages 559–577. Springer Berlin

Heidelberg, Berlin, Heidelberg.

Yoo, B. S. (1987). Co-integrated time series: Structure, forecasting and testing (Doctoral dissertation).

A Preliminaries

A.1 Quotient spaces

Let V be a subspace of an arbitrary separable complex Banach space B equipped with norm
B. The
∥
, x ∈ B. The
cosets of V are deﬁned as the collection of the following sets: x + V =
quotient space of V , denoted by B
V , is the vector space whose elements are equivalence classes of the
cosets of V : two cosets x + V and y + V are in the same equivalence class if and only if x − y ∈ V . In

x + v ∶ v ∈ V

∥

/

}

{

⋅

30

the present paper, any quotient space B
quotient map πB
is deﬁned as

V is deﬁned by the map πB
/
V = inf y∈V
x − y
x + V
/

V
/
B for x + V ∈ B
V is a Banach space (Megginson, 2012, Theorem 1.7.7).
/

∥

∥

∥

∥

/

(

)

B

B

⋅

∥

∥
A.2 Random elements in B

V is mostly associated with a closed subspace V . For such V , the
= x + V for x ∈ B and the quotient norm

x

⋅

V
V equipped with the quotient norm

∥

∥

/

B

V . B

/

/

We brieﬂy introduce Banach-valued random elements, called B-random variables. The reader is referred to
Bosq (2000, Chapter 1) for a more detailed discussion on this subject.

(

)

Let

Ω, F, P

be an underlying probability triple. A B-random variable is a measurable map X ∶ Ω ↦ B,
where B is understood to be equipped with the Borel σ−ﬁeld. We say that X is integrable if E
B <
∞. If X is integrable, it turns out that there exists a unique element EX ∈ B such that for all f ∈ B′,
2 < ∞.
E
)
∥
The covariance operator CX of X ∈ L2
X
X
for
f ∈ B′. For X, Y ∈ L2

be the space of B-random variables X with EX = 0 and E
is a map from B′ to B, deﬁned by CX
= E
= E
, the cross-covariance operator CX,Y is deﬁned by CX,Y

. Let L2

EX

= f

(
X

(
f

)
Y

∥
f

[
f

)]

X

X

X

]
.

B

B

B

∥

∥

f

f

)

(

)

)

(

(

(

[

(

)

[

(

)

]

(

)

A.3 Generalized inverse operators
Let B and ̃
and ̃
A−1
(resp. codomain) of A−1

R to B (resp. ̃

B be separable complex Banach spaces and let A ∈ L

. Suppose that B = ker A ⊕ V
B. Since AR = A ∶ V ↦ ran A is invertible,
̃
R ∶ ran A → V is well deﬁned. The generalized inverse Ag of A is obtained by extending the domain

B = ran A ⊕ W hold for some V ⊂ B and W ⊂

B
B, ̃
)

(

B); speciﬁcally, Ag is deﬁned as the map

B ∋ x ↦ A−1
R
(
where PW denotes the projection onto W along ran A. It can be shown that the generalized inverse Ag
satisﬁes the following properties: AAgA = A, AgAAg = Ag, AAg =
, and AgA = PV , where
PV denotes the projection on V along ker A.

I − PW

I − PW

x ∈

B,
̃

)

(

)

Note that V and W satisfying B = ker A ⊕ V and ̃

B = ran A ⊕ W are not uniquely determined in
general, so the above deﬁnition of Ag depends on the choice of V and W ; however, for any ﬁxed choice of
V and W , Ag is uniquely deﬁned. In the case where B and ̃
B are Hilbert spaces, V (resp. W ) can be set to
), which makes Ag become equivalent to the Moore-Penrose inverse of A. For a
ker A
[
]
more detailed discussion on generalized inverses, see Engl and Nashed (1981).

ran A
]

(resp.

⊥

⊥

[

)

A.4 Operator pencils
Let U be some open and connected subset of the complex plane C. An operator pencil is an operator-valued
map A ∶ U → L
B
. An operator pencil A is said to be holomorphic on an open and connected set U0 ⊂ U
(
1
if, for each z0 ∈ U0, the limit A(
.
)
)
It turns out that if an operator pencil A is holomorphic, for every z0 ∈ U0, we may represent A on U0 in
terms of a power series A
. If
(
there exists k such that Aj = 0 for all j ≥ k, then A is called a polynomial operator pencil. If Aj = 0 for
all j ≥ 2, then A is called a linear operator pencil. The collection of z ∈ U at which the operator A
is
(
not invertible is called the spectrum of A, and denoted by σ

j for z ∈ U0, where A0, A1, . . . is a sequence in L

. It turns out that the spectrum is always a

≔ limz→z0 A
(

exists in the norm of L

− A
(

∞
j=0 Aj

z − z0

z − z0

)/(

z0

z0

∑

=

B

B

z

z

z

)

(

(

)

)

)

(

)

)

(

)

A
)

(

31

closed set, and if A is holomorphic on U , then A
(

z

)

is called the resolvent set of A, and denoted ρ
(

A
)
−1 allows the following Laurent series in a punctured neighborhood of z = z0:

z

−1 is holomorphic on U

A
(Markus, 2012, p. 56).
)
. If A is holomorphic and z0 is an isolated point

σ

\

(

σ

U

\
of σ

A
)
, then A
(

(
A
)

(

)

−1 =

z

A
(

)

∞

Aj

(

∑
j=−d

z − z0

j,

)

d ∈ N ∪

∞

}

{

, Aj ∈ L

.

B

(

)

(A.1)

By Cauchy’s residue theorem, we have Aj = − 1
contour around z0 such that the only element of σ

2πi ∫Γ
A
)

(

B Mathematical Appendix

−1
A
z
j+1 dz, where Γ ⊂ ρ
)
(
z−1
(
(
)
included inside the contour is z0.

̃Φ
)

is a clockwise-oriented

We provide mathematical proofs of the results given in Sections 2-3. It is sometimes convenient to consider
A ∈ L

V = A ∶ V ↦ B.
whose domain is restricted to V ⊂ B, which is denoted by A
V ; that is, A
∣
∣

B

(

)

τ0

+ f Θ

B.1 Proofs of the results given in Sections 2 and 3.2
Proof of Proposition 2.1. To show (i), we take 0 ≠ f ∈ B′ to both sides of (2.6) and obtain f
f
(
νt
}
{
is given by tf Θ
∆d−1Xt
f

t≥0 is stationary since f is Borel measurable and
t
1
s=1 εs
)(∑
)
= 0. Therefore, for
= 0 is required. In this case, a suitable initial condition on τ0 can
= 0 if and only if

t
1
s=1 εs
+ f
)(∑
)
(
t≥0 is stationary. Because E
1
)

= 0. Moreover, one can show without difﬁculty that f Θ

, which increases without bound as t grows unless f Θ

, t ≥ 0. Then
)
f Θ
εt

, the second moment of f Θ

f
(
{
= f Θ

)}
Cε0f Θ

∆d−1Xt

νt
1
)

Cε0f Θ

1
)

1
)

1
)

1
)

1
)

νt

[(

=

(

(

(

(

)

(

)

(

(

)

(

]

2

)

(

= Ann
1
(
))
To show (ii), suppose that g ∈ C
X
)
(
∈ cl
(
A
(

A
X
(
. Note that x ∈ B allows the following unique decomposition,
A
and xV ∈ V . From (i) and continuity of bounded linear
+ xV , where xcl
(
. Therefore, g ∈ C
= Ann
X
X
implies that
(
(
, t ≥ 0.
. Now suppose that g = f ◦ PV . Then clearly g
τ0
Xt

x = xcl
))
functionals, we ﬁnd that C
(
x
g

A
X
(
(
))
= Ann
(

A
(

)
+ g

= g

X
(

A
(

)))

xV

))

))

))

νt

X

X

X

cl

x

)

(

.

(

(
t≥0 to be stationary, f Θ
τ0
(
, so C

)
X

(

)}

{
be obtained by letting f
f ∈ Ann
(

ran Θ

(

1
)

(

= g

= g ◦ PV
This can be made stationary by letting g

)

)

(

)

(

(

(

)

(

)

(

)

= 0.

τ0

(

)

Proof of Corollary 2.1. Under the simpliﬁcations discussed in Section 2.4 for the case B = H, Proposition
2.1-(ii) implies that f ∈ C

for y ∈ H. Then the stated result follows.

is given by the map

X

⋅, PV y

(

)

⟨

⟩

Proof of Proposition 3.1. Note that ̃Φ
(

z

)

may be viewed as the following block operator matrix,

=

z

̃Φ
(

)

⎛

⎜⎜⎜⎜⎜⎜⎜

⎝

I −zΦ1 −zΦ2 −zΦ3 ⋯ −zΦp

−z I
0
⋮
0

I
−z I
⋮
0

0
I
⋱
0

⋯
⋯
⋱
−z I

0
0
⋮
I

⎞

⎟⎟⎟⎟⎟⎟⎟

⎠

≕

̃Φ
̃Φ

[

[

(

11

21

z
](
z
](

̃Φ
̃Φ

[

[

)
)

12

22

z
](
z
](

,

)
)
)

(B.1)

where ̃Φ
̃Φ+
z
)
](
When ̃Φ

11
[

22
[
≔

22
]
[

)
11
[

z
](
̃Φ
− ̃Φ
z
)
is invertible, ̃Φ
(

12
[

](

](
z

)

∶ Bp−1 ↦ Bp−1 is invertible for all z ∈ C. Deﬁne the Schur complement of ̃Φ
z

. From a little algebra, we ﬁnd that ̃Φ+

−1

z

z

z
22
](
[
= Φ

as

)
z

.

)
is invertible (Bart et al., 2007, Section

](

(

)

11
[

z

22
[

̃Φ
̃Φ
)
is invertible if and only if ̃Φ+

21
[

](

](

)

)

11
[

](

z

)

32

2.2), so σ

. Furthermore from the Schur’s formula in Bart et al. (2007, p. 29), we have

Φ

(

)

= σ

̃Φ
)
−1 =

(
z

̃Φ
(

)

22
[

z
](

−̃Φ
(
−1 = Πp ̃Φ

)

−1

Φ
z
)
(
−1
̃Φ
21
[

z

(

)

Φ
z
z
](
)
(
−1Π∗

−1

)

̃Φ

22
[

z
](

−1

)

+ ̃Φ

22
[

−1

−Φ

z
(
z
](

)
−1
)

̃Φ
̃Φ

12
[
21
[

z
](
z
](

̃Φ
)
Φ
)

22
[
z
(

z
](
)
−1
̃Φ
)

−1

12
[

z
](

̃Φ
)

22
[

z
](

,

)

−1

)

(B.2)

which shows Φ

(

z

)

p . (iii) is deduced from (B.2) and invertibility of ̃Φ

22
[

](

z

.

)

B.2 Mathematical appendix to the I(1) representation (Section 3.3)

B.2.1 Preliminary results

̃P =

We provide important preliminary results for the subsequent discussions. Hereafter it should be noted that
̃P and ̃Nj may be alternatively expressed as the following contour integrals,
−1

−1
2πi ∫Γ (
where Γ ⊂ ρ
̃Φ
)
(
inside the contour is one. From ̃Φ
)
(
the power series deﬁned in a punctured neighborhood of one as follows,

is a clockwise-oriented contour around one such that the only element of σ
̃Φ

−1
2πi ∫Γ (

included
−1, the identity map may be understood as

j ∈ Z, (B.3)

Ip −z ̃Φ1

Ip −z ̃Φ1

z − 1
)

z − 1
)

−j−1dz,

−j−1dz,

= Ip =

̃Nj =

̃Φ
(

)

(

̃Φ1

̃Φ

̃Φ

−1

−1

z

z

z

z

(

)

(

)

)

(

)

(

)

∞

∑
j=−∞ (

̃Nj−1 ̃Φ1 − ̃Nj

Ip − ̃Φ1

(

z − 1
)

)) (

j = Ip =

∞

∑
j=−∞ (

̃Φ1 ̃Nj−1 −

Ip − ̃Φ1

(

̃Nj

)

z − 1
)

) (

j.

The above identity expansions give us the following relationships,

̃N−1 ̃Φ1 − ̃N0
̃Nj−1 ̃Φ1 − ̃Nj

(

Ip − ̃Φ1
Ip − ̃Φ1

)

= Ip =
= 0 =

̃Φ1 ̃N−1 −
̃Φ1 ̃Nj−1 −

̃N0,
)
̃Nj,

Ip − ̃Φ1
(
Ip − ̃Φ1
)
z
.

j ≠ 0.

(
The following lemma collects some essential spectral properties of ̃Φ
Lemma B.1. Suppose thatAssumption 3.1holds. Thenthefollowing hold.

)

(

)

(

(B.4)

(B.5)

(B.6)

̃Φ1 hasapole at z = 1 oforder ℓ,then ̃N−m ̃Φ
(
j ≥ 0
. Moreover, ̃N−1 ̃Φ1 and ̃N−1 areprojections.
}

̃Nj+k+1,where ηj = 1
{

= 0 forall m ≥ ℓ.

1
)

−1

)

z

(i) If ̃Φ
(
(ii) ̃Nj ̃Φ1 ̃Nk =
(iii) ̃Nj ̃Φ1 =
(iv) ̃Φ

z

1 − ηj − ηk
̃Φ1 ̃Nj forall j ∈ Z.

)

(

(

)

ℓ ∈ N and(b) ran
(

Gm

)

−1 hasapoleoforderatmost ℓ at z = 1 ifandonlyif(a) n−1

Ip −G
)
isclosed forsome m ∈ N satisfying m ≥ ℓ,where G =
̃Φ
−1

Gℓ−1
∥

−1

(

n

op → 0 forsome
∥
̃P.
1
)

Proof. To show (i), we note that Ip =
neighborhood of z = 1.
−1
Ip −z ̃Φ1

−
)
(
Ip − ̃Φ1
̃Φ1 has a pole of order ℓ ≥ 1. We therefore have ̃N−m ̃Φ
(

It is then clear that

)
(
Ip −z ̃Φ1

Ip −z ̃Φ1

Ip − ̃Φ1

−1

(

(

(

)

(

)

)
1
)

z − 1

Our proof of (ii) is similar to those in Kato (1995, p. 38) and Amouch et al. (2015, p. 119). Let Γ, Γ′ ⊂
be contours enclosing z = 1, and assume that Γ′ is outside Γ. Using the generalized resolvent equation
Φ

ρ
(

)

(Gohberg et al., 2013, p.50), it can be shown that

Ip −z ̃Φ1

(
̃Φ1 in a punctured
must have a pole of order ℓ − 1 if
= 0 for all m ≥ ℓ.

)(

)

̃Nj ̃Φ1 ̃Nk =

2

1
2πi )

(

∫Γ′ ∫Γ

Ip −λ ̃Φ1
(
λ − z

(

)(

−1 −
)
z − 1
)

(
j+1

Ip −z ̃Φ1
λ − 1
)

(

−1
k+1 dzdλ.
)

(B.7)

33

From Kato (1995, p.38), we may deduce that

1
2πi ∫Γ

z − 1
)
Since we may evaluate the integral in any order, the right hand side of (B.7) can be written as

λ − 1
)

1 − ηk

)(

(

(

1
2πi ∫Γ′ (
(

−1
λ − z
k+1 dλ =
)
λ − 1
)

−1
λ − z
j+1 dz = ηj
)
(
z − 1
)
(

−j−1,

−k−1.

(B.8)

2

1
2πi )

(

∫Γ′ ∫Γ

λ − z
(

Ip −λ ̃Φ1
)
(
j+1
z − 1
)

λ − 1
(

−

k+1 dzdλ
)

2

1
2πi )

(

∫Γ ∫Γ′

λ − z
(

Ip −z ̃Φ1
(
)
j+1
z − 1
)

−1

−1

λ − 1
(

.

k+1 dλdz
)

)(

2

)(

1

From (B.8) and Cauchy’s residue theorem, we deduce that 1 = −ηj ̃Nj+k+1 and 2 =
from which we ﬁnd that ̃Nj ̃Φ1 ̃Nk =
1 − ηj − ηk
̃N−1 ̃Φ1 ̃N−1 =
̃N−1, which implies that ̃N−1 ̃Φ1 is a projection. We now let U
PU = 1
2πi ∫Γ U
PU =
̃N−1 holds (Beare and Seo, 2020, Remark 3.11).

̃Nj+k+1,
̃Nj+k+1. By putting j = −1 and k = −1, we obtain
= zI − ̃Φ1, and deﬁne
z
−1dz. Then PU is a projection (Gohberg et al., 2013, Lemma 2.1 in Chapter I) and

ηk − 1
)

z

(

)

(

(

(

)

)

To show (iii), note that ̃Φ1 and Ip −z ̃Φ1 commute, and this implies that

Ip −z ̃Φ1

commute (Kato, 1995, Theorem 6.5). We thus have ̃Nj ̃Φ1 =

To show (iv), we will ﬁrst verify that the following holds for some η > 0,

̃Φ1 ̃Nj for all j ∈ Z.

(

−1

̃Φ1 =

)

Ip −z ̃Φ1

̃Φ1

(

−1

)

Ip −z ̃Φ1

−

(

)

−1

̃Φ1 =

∞

∑
j=1

Gj

z − 1
)

(

−1−j + ̃N−1 ̃Φ1

z − 1
)

(

−1 + ̃NH

z

,

)

(

z ∈ D1+η

,

1
}

\ {

(B.9)

(

(

̃Φ

̃Φ

̃Φ

1
)

1
)

̃N−1 ̃Φ1 ̃N−1 =

is the holomorphic part of the above Laurent series. We deduce that ̃Φ1 ̃N−2 =
̃N−1 =
1
)

1
̃N−1 from
where ̃NH
z
)
(
)
(
̃N−2 ̃Φ1 =
̃P = G from (ii)-(iii). We thus ﬁnd that G =
(B.6), and ̃Φ
(
̃Φ1 ̃N−2. It is also deduced from (ii) and (iii) that ̃N−k ̃Φ1 = Gk−1 and Gk−1 =
̃P holds for k ≥ 2,
1
Gk
k
from which we ﬁnd that (B.9) holds. In order for (B.9) to converge for z ∈ D1+η
op = 0
/
∥
must hold (Kato, 1995, pp. 180–181). In this case, (a) and (b) are necessary and sufﬁcient for Gℓ to be zero
(Laursen and Mbekhta, 1995, Lemma 3 and Corollary 7). If Gℓ = 0, we know, from (B.9) and (i), that
= 0 for all k ≥ ℓ. Combining these
−
(
(
= 0 for all k ≥ ℓ. Since ̃N−k−1 =
results with (B.6), we have ̃N−k−1 ̃Φ1 =
+ ̃N−k−1 ̃Φ1,
−1 has a pole of order at most ℓ at z = 1. Conversely, if
we ﬁnd that ̃N−k−1 = 0 for all k ≥ ℓ, so
−1 has a pole of order at most ℓ at z = 1, we have ̃N−k−1 ̃Φ1 = Gk = 0 for k ≥ ℓ. For Gℓ+1 to be
Ip −z ̃Φ1
(
nilpotent, (a) and (b) must hold; see Laursen and Mbekhta (1995, Lemma 3 and Corollary 7).

̃Φ1 has a pole of order at most ℓ at z = 1 and ̃N−k ̃Φ
̃N−k ̃Φ

1
)
, limk→∞

1
(
)
Ip −z ̃Φ1

̃Φ
(
1
}

Ip −z ̃Φ1

̃N−k−1 ̃Φ

1
)

1
)

k−1

\{

−1

∥

(

(

)

)

)

B.2.2 Proofs of the main results
Proof of Proposition 3.2. Since (ii) ⇒ (iii) is trivial, we will show that (i) ⇒ (ii) and (iii) ⇒ (i). This
completes our proof of the equivalence of (i)-(iii). Then we will verify (3.13).

z

We will show (i) ⇒ (ii). Since ̃Φ
̃N−1 = 0. This implies that ran ̃N−1 ⊂ ker ̃Φ
1
)
1
)
1
2πi ∫Γ(

̃Φ
(
̃N−1 ̃Φ1. Furthermore, ker ̃Φ
̃Pxk = −

Ip −z ̃Φ1

−1

(

)

)

(

̃Φ1xkdz =

−1 has a simple pole at z = 1, we may deduce from (B.6) that
since ̃P =
. We then ﬁnd that ran ̃P ⊂ ker ̃Φ

1
)
⊂ ran ̃P holds. To see this, note that if xk ∈ ker ̃Φ

1
)

(

(

,

1
)

(
−1xkdz = xk.

(B.10)

We thus conclude that ran ̃P = ker ̃Φ

1
)

(

. Moreover, ̃N−1 ̃Φ

= 0 is deduced from (B.6) and Ip − ̃P =

z − 1
)

1
2πi ∫Γ(
1
)

(

34

.

2

2

2

2

2

2

2

2

2

2

)

(

(

(

(

(

(

(

(

(

)

(

)

(

)

(

(

)

)

)

)

(

(

)

(

(

(

(

(

)

(

(

(

)

(

)

{

(
n

∥

=

=

̃Φ

G2

1
)

1
)

1
)

1
)

1
)

1
)

1
)

1
)

1
)

n−1

̃Φ
(

G
(

̃P =

Bp =

, we have

Ip − ̃P

Ip − ̃P

1
)]
G
(

)
Ip − ̃P

= ran ̃Φ

, which means

ran ̃Φ
(
Ip − ̃P

(
and ran
(

(
Ip −G
)

1
(
)
)
ran ̃Φ
(

1
(
)
= ran ̃Φ

along ran ̃Φ
z

(
op ≤ n−1
∥

1
̃Φ
)
(
)
=
1
̃Φ
)
(
n
Ip −G
)

⊂ ran
(
x since Ip − ̃P is a projection and ̃P =

Ip − ̃Φ1 ̃N−1 is deduced from Lemma B.1-(iii). Since N−1 ran ̃Φ
ran ̃Φ
1
, which implies that ran ̃Φ
(
)
Ip − ̃Φ1 ̃N−1
have x =
̃N0 + Ip. Therefore, x =
1
̃Φ
)
(
Ip − ̃P
⊂ ran ̃Φ
we have ran
1
(
)
Ip − ̃P
was already shown. To sum up, ran ̃P = ker ̃Φ
ran
1
that ̃P is the projection onto ker ̃Φ
)

1
)
Ip − ̃Φ1 ̃N−1
x = − ̃Φ
, from which we conclude that ran

Ip − ̃P
0
)
}
. On the other hand, for any x ∈ ran
(

1
)
, we
̃Φ1 ̃N−1. We know from (B.5) that ̃Φ1 ̃N−1 =
. Hence,
⊂
1
)

̃N0x, which implies that x ∈ ran ̃Φ
1
(
)
since ran ̃Φ
(
1
)

1
)
1
(
)
= ran ̃Φ
(
Ip −G
)
n

̃Φ
= ran ̃P ∩ ran ̃Φ
2y =
1
̃Φ
)

1
(
)
)
̃P ̃Φ
1
(
)
2. This shows that x ∈ ran ̃P ∩ ran ̃Φ

(iv), it sufﬁces to show that n−1
G
∥
(
̃P commute, G2 =
1
̃P ̃Φ
(
)
To see this, note that for x ∈ ran
̃P ̃Φ
(
the second equality results from commutativity of ̃P and ̃Φ
⊂ ran ̃P ∩ ran ̃Φ
hence ran
̃P ̃Φ
1
(
)
(
= ran ̃P ∩ ran
ran
̃Φ
1
̃P ̃Φ
(
)
Under the direct sum Bp = ran ̃Φ
holds. That is, ran
(
It can be easily deduced that

(
−1 has a pole of order at most 2 at z = 1. Due to Lemma B.1-
To prove (iii) ⇒ (i), we ﬁrst show that ̃Φ
)
Ip −G
op → 0 and ran
is closed for G =
̃P. Since ̃Φ1 and
∥
)
2.
2. Moreover, it can be shown that ran
̃P ̃Φ
1
(
)
, there exists y ∈ Bp such that x =
̃P, where
2,
1
1
)
)
2. The reverse inclusion is trivial, so we omit its proof. Since
is closed.
ran ̃Φ
1
1
)
(
(
)
op → 0.
∥
+ ̃Φn
1 ̃P. From the fact that ̃Φ1 and ̃P commute, we have
op ≤ n−1
̃Φn
(B.11)
∥
Under Assumption 3.1, we may deduce, from nearly identical arguments used in Beare et al. (2017) to prove
a similar statement, that there exists k ∈ N such that for all n ≥ k,
1
ran ̃Φ
)∥
∣
(
Hence, the upper bound in (B.11) vanishes to zero, and we conclude that ̃Φ
z
)
(
at z = 1 under the direct sum Bp = ran ̃Φ
. From (B.5) and (B.6), we have ̃N−2 ̃Φ
(
and ̃N−2 ̃Φ1 =
1
ker ̃Φ
∣
)
Since Bp = ran ̃Φ
⊕ ker ̃Φ

(
is closed if ran
and ran ̃P is closed, ran
̃P ̃Φ
(
)
⊕ ker ̃Φ
⊕ ker ̃Φ
1
1
̃Φ
, ̃Φ
1
(
)
)[
(
)
, which is closed. It remains to show that n−1
1
)
n =
Ip − ̃P
)
1
̃Φ
)
∥

1
)
(
It remains only for us to show that (3.13) holds. Let H
series given in (3.11). Note that if Assumption 3.1 holds and ̃Φ
series of

denote the holomorphic part of the Laurent
−1 has a simple pole, the Maclaurin
is convergent on D1+η. Then from Lemma 4.1 of Johansen
(1995) (or its obvious extension allowing power series with operator coefﬁcients), it may be deduced that
is convergent on D1+η. Now we will show ̃P =
̃N−1 to complete our proof.
the Maclaurin series of H
One can deduce from our proof of (i) ⇒ (iii) that ran ̃P = ran ̃N−1. Moreover, Lemma B.1-(ii) implies that
Ip − ̃Φ1
̃N−1 is a projection. Therefore, ̃N−1 is clearly a projection whose range is equal to ran ̃P = ker
.
)
Then we ﬁnd that ̃P =
̃N−1, where the second equality is from the fact that ̃Φ1 and ̃N−1
commute, and the last equality is from that ̃Φ1

< an for some a ∈
0, 1
.
)
−1 has a pole of at most 2
= 0
1
)
= 0).

1
)
. The former (resp. the latter) shows that ̃N−2

ran ̃Φ
∣
, we conclude that ̃N−2 = 0. Hence, ̃Φ
z

1
−1 has a simple pole at z = 1.
(
)

Proof of Proposition 3.3. From Propositions 3.1 and 3.2, we have
z
)
)
∆νt, where νt = ΠpH
the process given by Πp ̃N−1Π∗
component τ0 given as the solution to the homogeneous equation ∆Xt = 0.

)
1 −
p +
(
)
−1 to (3.1), we obtain ∆Xt = Πp ̃N−1Π∗
p εt+
j! is convergent on D1+η. Clearly,
)
t
s=1 εs + νt is a solution, which is completed by adding a time invariant

p . Applying the linear ﬁlter induced by
p εt and H

(
Φ
)
j=0 Hjzj with Hj = H (

(
Ip − ̃Φ1
−1 = Πp ̃N−1Π∗

and ran ̃N−1 = ker

̃N−1 ̃Φ
1
)

= 0 (resp. ̃N−2

1
ran ̃Φ
)∥
∣
(

̃N−1 ̃Φ1 =

̃Φ1 ̃N−1 =

)
1 − z

⊕ ker ̃Φ

̃Φn
∥

̃Φn
∥

Ip −̃Φ1
(

Ip −̃Φ1
(

1
)∥

̃Φ
∥

(
1
)
(

−1 =

̃P +

ΠpH

= Ip

1 − z

1 − z

ker
∣

ker
∣

p ∑

1
)

1−z

Π∗

Π∗

op.

̃Φ

∑

H

Φ

L

=

∥

op

∞

/

z

z

z

z

z

z

z

z

z

(

(

(

(

(

)

(

)

(

(

(

)

)

(

)

(

)

(

)

)

(

)

(

(

(

)

)

(

(

(

)

(

(

1

1

1

.

)

j

35

We then verify the claimed expression of νt in (3.14). Once we show that

H0 = Ip − ̃P, Hj =

̃Φ1Hj−1,

j ≥ 1,

(B.12)

then the claimed expression given in (3.14) may be easily veriﬁed. First, it can be shown that H
= −

∞

Ip − ̃P
)
=

z
H
)(
(
Ip − ̃P
̃Nj
(
)
j=0 ̃Nj
−
∑

∞

holds. To see this, note that H
̃Nj − ̃Nj ̃Φ1 ̃N−1 =

j=0 ̃Nj
z
(
)
̃Nj for j ≥ 0, we ﬁnd that H
(
= H

∑

−1

z − 1
)
(
Ip − ̃P
z
, and

)(
z

z

)

j. This also shows that ̃Φ
(
̃Φ
z

Ip − ̃P =

Ip − ̃P

(
z

−1

)
̃Φ

)
Ip − ̃P

z − 1
)

(

(
=

)
̃Φ
(

(B.13)
(
We then easily deduce that H0 = Ip − ̃P from (B.13) evaluated at z = 0. Furthermore, (B.13) can be
rewritten as

H

H

−

z

z

z

z

)

(

)

)

)

(

)

(

.

=
j. Since Lemma B.1-(ii) implies that
j =

= −

∞

z

(

)

Ip − ̃P

(

z − 1
)

)(

j=0 ̃Nj

∑

= Ip − ̃P, from which we have
z

= 0,

z

j

j ≥ 1.

)
j
H (

(
)

z

(

)

z − 1
)

̃Φ1H
)
(
j−1
− j ̃Φ1H (
)
0
)

(

)

)

(
)
= j ̃Φ1H (

− z ̃Φ1H (
j−1
0
)
)

(

(
)
= j! ̃Φ1Hj−1, which veriﬁes (B.12).

(B.14)

j
Evaluating (B.14) at z = 0, we obtain H (

It remains to show that if the I(1) condition is not satisﬁed then the AR(p) law of motion (3.1) does not

Ip − ̃Φ1

(

)

(

allow I(1) solutions. This immediately follows from Propositions 3.1 and 3.2.

Proof of Proposition 3.4. Throughout this proof, we write the Laurent series of Φ
∞
lows: for d ∈ N ∪
j=−d Nj
∑
show that (i) ⇒ (iii) and (ii) ⇒ (i). The whole proof is divided into several parts.

−1 near z = 1 as fol-
j. Since it is obvious that (iii) ⇒ (ii), we will only

z − 1
)

−1 = −

, Φ

∞

{

}

z

z

(

(

)

(

)

[

[

(

(

(

)

(

z

1
)

1
)

1
)

ker Φ

ran Φ

ker Φ
[

= ker Φ

, it may be

0 in the identity expansion Φ

. Moreover, from the coefﬁcients of
= 0

∁ be arbitrarily chosen among possible candidates. We
under the I(1) condition; see Propo-

∈ ker ̃Φ
implies that x1 = ⋯ = xp ∈ ker Φ
1
)
(
p ⊂ Πp ker ̃Φ
1
)
(
−1Φ
z

1. (i) ⇒ (iii) : Let
1
1
∁ and
)]
)]
know that d = 1, N−1 = Πp ̃PΠ∗
p , and ̃P is a projection onto ker ̃Φ
(
x1, . . . , xp
sitions 3.1 and 3.2. Since
deduced that ran N−1 = ran Πp ̃PΠ∗
−1 and
z − 1
z − 1
(
(
)
)
1
+ N0Φ
1
and N−1Φ(
)
(
)
(
= I − P
P
ker Φ
1
[
(
↦
so Λ1,∁ ∶ ker Φ
1
)
in the expansion Φ
(
1
implies that −P
ran Φ
)
[
it is concluded that Λ1,∁ ∶ ker Φ
[
arguments do not depend on the choice of

I −
1
,
)
(
0
−1 and
z − 1
z − 1
)
)
(
N0 = −I, which
1
1
(
)
)
(
∁ holds. Since ran N−1 = ker Φ
was already shown,
1
(
)]
1
∁ is also a surjection, i.e., it is a bijection. The above
)]
∁. Thus (i) ⇒ (iii).
1
)]
2. (ii) ⇒ (i) : Suppose that the direct sums given in (3.2) hold and Λ1,∁ is invertible for some choice of
ran Φ

(
= −I. From these equations, we observe that −N−1P
∁ holds, hence ker Φ
1
)]

(
1
)(
⊂ ran N−1. We thus ﬁnd that ran N−1 = ker Φ

−1 = I, we ﬁnd that Φ
z
)
(
1
N−1 = P
∁ Φ(
)
↦
1
)

∁ is an injection. Also, from the coefﬁcients of

= I, we know that N−1 satisﬁes N−1Φ

∁. We deﬁne Q∁ ∶ Bp → Bp as follows,

N−1 + Φ
1
)

1
N−1 = 0 and Φ(
)

1
)
1
(
)]
ran Φ

ran Φ
[
ran Φ

(
ran Φ

1
∁ Φ(
)

ran Φ
[

1
)]

∁ and

∁ and

ker Φ

ker Φ

1
)

1
)

1
)

)
1
(

∁
)]

[
Φ

1
(

z

)]

)]

(

)

(

(

(

(

)

(

(

(

(

(

(

(

(

)

[

[

[

(

1
)]

[

1
)]
ran Φ
(
[

(
P

0
⋮
0

Q∁ = ⎛
⎜⎜⎜⎜
⎝

∁ P

1

)]

ran Φ
(
[

1

p
j=2 Φj P
∁ ∑
)]
0
⋮
0

ran Φ
(
[

1

∁ ∑
)]
0
⋮
0

p
j=3 Φj ⋯ P

⋯
⋱
⋯

ran Φ
(
[
0
⋮
0

36

∁ Φp

1

)]

(B.15)

.

⎞
⎟⎟⎟⎟
⎠

= 0. The latter may be veriﬁed by noting that

Then Q∁ is a projection on Bp and Q∁ ̃Φ
=

Φ

1
)

(

(

I
−1

̃Φ
̃Φ

1
(
)
0

12
[
22
[

̃Φ
1
](
(
)
](
where ̃Φ
, ̃Φ
⋅
)
also be shown that ker Q∁ ⊂ ran ̃Φ
p
j=3 Φjx3 + ⋯ + Φpxp
∑
−

1
)
̃Φ
1
22
)) (
[
are deﬁned in (B.1). We thus ﬁnd that ker Q∁ ⊃ ran ̃Φ
1
It can
(
)
p
j=2 Φjx2 +
1
x1 +
ran Φ
1
∑
∁
)
(
)]
[
(
p
=
= 0 holds for any x =
0, x2, . . . ,
1
j=2 xj
∑
)(
p
p
j=3 Φjx3 − ⋯ − Φpxp.
j=3 Φjx3 − ⋯ − Φpxp, x2, . . . , xp
∑

∈ ker Q∁, and ̃Φ
(
p
j=2 Φjx2 −

. To see why, we ﬁrst note that P

)
. Let y1 = −

p
j=2 Φjx2 −

0
Ip−1)

x1, . . . , xp

1
)
1
))

(B.16)

, ̃Φ

12
[
22
[

̃Φ
21
[

1
(
)
0

= 0,

22
[

21
[

12
[

Q∁

⋅
)

⋅
)

̃Φ
̃Φ

](
](

1
)

1
)

∑

∑

∑

](

](

](

(

](

](

(

(

)

)

Φ

,

.

(
With some algebra, we obtain the following results.

)

(B.17)

x, 0, . . . , 0
)
ran Φ
[

(
y1 = P

1
(

∈ ran ̃Φ
∁ y1 +

1
)
I − P

(

for x ∈ ran Φ

,

1
)
(
y1, P

(

. Let xk =
1
(
)
Q∁xk =

)]

(
Using (B.17) and (B.18), we ﬁnd that
(B.17), we conclude that x =

P
ran Φ
[
x1, . . . , xp
)
We have shown that ker Q∁ = ran ̃Φ

(

(

(

x1,k, . . . , xp,k

subspace of ran ̃Φ
1
)
xp,k and x1,k ∈ ker Φ

(

ran Φ
[

)

1
∁
(
)]
∁ x1, x2, . . . , xp

ran Φ
[

1
(

∁ y1 = P
)]

∁ x1.

1
(

ran Φ
[
. Combining this result with

)]

(B.18)

)]

1
(

1
)

1
)
.

∈ ran ̃Φ
(
1
)

∈ ran ̃Φ
(
)
, so ker Q∁ ⊂ ran ̃Φ
1
)
(
, so we know that Q∁ is a projection onto a complementary
, then it may be easily shown that x1,k = ⋯ =
x1,k, we obtain

∈ ker ̃Φ

I −P

1
)

)

(

−P

1
∁ Φ(
)

. With a little algebra and from the fact that x1,k =

)]

(

ran Φ
[

1
(
Moreover, we may deduce that ran Q∁ ⊂
{(
with (B.19) and invertibility of Λ1,∁ ∶ ker Φ
ran ̃Φ
[
be deduced from Fact 4.3 of Fabian et al. (2010) and the fact that the map D ∶ ran ̃Φ
0
Ip
ran ̃Φ
0 Q−1
(

(
x1, 0, . . . , 0
)
↦
ran Φ
[
is a complementary subspace of ran ̃Φ
1
(
)
ran ̃Φ
⊕

1
)
∁ is invertible. This implies that ker ̃Φ
(

1
)]
}
∁, we ﬁnd that Q∁,R = Q∁ ∶ ker ̃Φ

ker Φ
1
∁
)
[
(
)]
∈ Bp ∶ x1 ∈

⊕ ker ̃Φ
(

given by D =

is invertible.

1
)]

1
)]

ran Φ

1
)

1
)

1
)

1
)

∁,R )

(

(

(

(

(

[

1
)

(
, which may
∁ ↦
1
)]

(

)

1
(

∁
)]

ker Φ
(
[
x1,k, 0, . . . , 0
)
. Combining this result
↦

(B.19)

(

[

∁

.

I − P

1
)(

3. Formula for Υ−1 : For any arbitrary choice of
[
= I − P
1
−N−1P
ker Φ
)(
[
is invertible, from which (3.19) follows immediately.

1
∁ Φ(
)

ran Φ
[

ker Φ
[

I − P

∁
)]

1
(

1
(

)]

(

)

ran Φ

1
(

)]

∁ and

1
ker Φ
(
)]
∁ and the map Λ1,∁ ∶ ker Φ

1
)]

(

[

∁, we found earlier that

1
)

(

↦

ran Φ

[

1
)]

(

∁

B.2.3 A detailed discussion on Remark 3.8

1
)
= f

From (3.19), we ﬁnd that ran Υ−1 = ker Φ

(

. Therefore, for a nonzero f ∈ Ann

ker Φ

,

1
))

(

(

f

Xt

τ0

+ f

νt

,

t ≥ 0.

(B.20)

(

)

)

(

(

(

)

)

(

z

τ0

)
= 0. We know from Proposition 3.2 that Φ

is convergent on D1+η for η > 0 (and thus the coefﬁcients of the Maclaurin series of H

Let τ0 be satisfy f
H
exponentially in norm) and N0 = −
establish I(0)-ness of
which implies that ran N−1 + ran N0 = B. In this case, for any f ∈ ker Φ
which contradicts our assumption that f ≠ 0. Therefore f N0 ≠ 0 is impossible.

j,
z−1
)
decay
p . We therefore only need to show that f N0 ≠ 0 to
= −I,
+ N0Φ
, f N0 = 0 implies that f = 0,

1
t≥0. Under the I(1) condition, we know that N−1Φ(
)

∞
j=0 Nj
(
z

j=0 ΠpHjΠ∗

−1 = −N−1

z−1
)

−1−

1
)

1
)

1
)

)}

∑

∑

νt

∞

f

{

z

)

(

(

(

(

(

)

(

(

37

(B.21)

ran ̃Φ

+

1
)

(

(

B.3 Mathematical appendix to the I(2) representation (Section 3.4)

B.3.1 Preliminary results

We ﬁrst collect some preliminary results that are useful for the subsequent discussions.

Lemma B.2. Leteverything beasinSection 3.4. Thefollowing holds.

canbecomplemented in Bp.
(i) UnderAssumption 3.1, ran ̃Φ
(ii) UnderAssumption 3.2,thefollowing hold forsome R∁ ⊂ Bp and K∁ ⊂ Bp,

and ker ̃Φ

1
)

1
)

(

(

where R = P

ran ̃Φ
[

1
(

∁
)]

Bp = ran ̃Φ
1
ker ̃Φ
.
)

(

⊕ R ⊕ R∁ =

1
)

(

ker ̃Φ

1
)]

(

[

∁ ⊕ K ⊕ K∁,

(iii) UnderAssumption3.2,theI(2)conditionisequivalenttothefollowing: K ≠
gK holds foranyarbitrary choice of

ker ̃Φ

⊕ ̃Φ
(iv) UnderAssumption 3.2, K ≠

1
))

1
)

(

(

andBp =
1
ran ̃Φ
∁.
∁ and
)]
[
−1 tohave apoleoforder 2.

0
{
}
ker ̃Φ

1
)]

(

(

[

0
}

{

isnecessary for ̃Φ

z

(v) UnderAssumption3.2,theoperator Q = P

ran ̃Φ
[
Qg satisfying ran Qg = K∁ and ker Qg = ran ̃Φ

(

)
Ip −P
∁ (
⊕ R∁.

1
(
)]
1
)

(

1
ker ̃Φ
(
[

∁ )

)]

allowsthegeneralizedinverse

)

)

(

(

(

(

(

)]

1
(

1
)

1
)

p × p

ker Φ
[

∈ ker ̃Φ

. Let T∁ be the

To show (ii), note that ran ̃Φ

(
implies that x1 = x2 = . . . = xp and x1 ∈ ker Φ

Proof. Under Assumption 3.1, we may deﬁne the projection Q∁ given (B.15). Since ker Q∁ = ran ̃Φ
it is complemented by ran Q∁. Moreover, ker ̃Φ
1
)
1
x1, . . . , xp
(
)
matrix whose entries of the ﬁrst column are all equal to I − P
zero. Then it can be easily shown that this is a projection deﬁned on Bp and its range is equal to ker ̃Φ
(
hence ker ̃Φ

1
,
)
is also complemented. To see this, we note that x =
operator
∁ and all the other entries are equal to
;

is complemented by the kernel of this projection. This completes our proof of (i).
= ran ̃Φ

1
. For such x, we have S∁x = −PR∁ Φ(
)
. Then we ﬁnd that ker S∁ ⊃ ran ̃Φ

⊕ R. We deﬁne S∁ ∶ Bp → Bp as the
∁ with PR∁ in (B.15). Then it can be easily shown
for some xk ∈
= ran Φ
+

+ ker ̃Φ
1
(
)
block operator matrix obtained by replacing P
that S∁ is a projection on Bp and S∁ ̃Φ
ker Φ
1
(
)
1
Φ(
) ker Φ
1
)
ker S∁ ⊂ ran ̃Φ
1
1
+ ker ̃Φ
must
)
)
(
p
= 0. As in our proof of Proposition 3.4, if we let
j=2 Φjx2 +
satisfy PR∁
x1 +
∑
(
p
p
j=3 Φjx3 − ⋯ − Φpxp, then we have PR∁y1 = PR∁x1. It can also be shown that
y1 = −
j=2 Φjx2 −
1
̃Φ
)(

, then x =
xk, . . . , xk
)
xk = 0, which is because ker PR∁
+ ker ̃Φ
1
)
(
x1, . . . , xp

. Moreover, it can be also shown that
∈ ker S∁. Then x =

(
1
)
. To see why, we let x =

= 0. If x ∈ ker ̃Φ
1
)

(
p
j=3 Φjx3 + ⋯ + Φpxp

1
)
ran Φ
[

y1, x2, . . . , xp

. We note that

∑
p
j=2 xj

x1, . . . , xp

0, x2, . . . ,

1
)

1
)

1
)

1
)

1
)

1
(

∑

∑

∑

=

)]

(

(

(

(

(

(

(

)

(

)

(

(

(

)

for x ∈ ran Φ

ker Φ

,

(B.22)

)
x, 0, . . . , 0
)

(

(
∈ ran ̃Φ

1
)

(

)
+ ker ̃Φ

1
)

(

=

w, w, . . . , w

+
(
I − PR∁

which is because for any arbitrary u ∈ B and w ∈ ker Φ
1
v + Φ(
1
Φ
pw
)
)
(
(
)
(
1
ker Φ
1
+ Φ(
ran
)
)
We have shown that S∁ is a projection whose kernel is ran ̃Φ
is complemented by ran S∁. The latter direct sum of (B.21) clearly holds for K∁ = ker ̃Φ
(

w, 0, . . . , 0
1
)
)
1
, we may deduce that
)

x1, . . . , xp
̃Φ

(
+ ker ̃Φ

)
= ran Φ

1
)

1
)

1
)

1
)

=

(

(

(

(

)

(

(

(

∈ ran ̃Φ
1
)
(
)
⊕ R, hence ̃Φ
1
)
1
∩
)

1
+ ker ̃Φ
.
(
)
⊕ R
1
(
)
1
ran ̃Φ
∁.
)]
(

[

v − w, v − 2w, . . . , v −
. Combining all these results with the fact that

(

(

1
+ Φ(
)

1
(
)
we have ̃Φ

1
)

(
1
)(

1
)

(

38

g

[

[

(

1
)]

choices of

1 and ̃Φ
1
)
(
1
ker ̃Φ
)]

1
)
∁. Let V = ran ̃Φ
(

To show (iii), we let ̃Φ
(
ran ̃Φ
∁ and
(

g
2 be the generalized inverse operators depending on two different
g
2K.
, V1 =
1
)
We know from Megginson (2012, Theorem 1.7.14 and Corollary 3.2.16) that two complementary subspaces
must be isomorphic, which implies that AV1 = V2 and V1 = A−1V2 for some invertible map
of ker ̃Φ
. Deﬁne the map D ∶ V ⊕ V1 ↦ V ⊕ V2 given by D =
A ∈ L
Ip 0
.
0 A )
)
(
= V1. We then deduce from Fact 4.3 of
Note that D
Fabian et al. (2010) that Bp = V ⊕ V1 holds if and only if Bp = V ⊕ V2 holds. This completes the proof.

1
(
)
V1, V2
(
, which is obviously invertible and its inverse D−1 ∶ V ⊕ V2 ↦ V ⊕ V1 is given by D−1 =

and its inverse A−1 ∈ L

g
1K, and V2 =

= V , and D−1

= V2, D−1

+ ker ̃Φ

Ip
0
0 A−1

= V , D

V2, V1

̃Φ
(

1
)

1
)

1
)

̃Φ

V2

V1

V

V

(

(

(

)

(

)

)

)

(

(

(

)

)

(

0
}

−1 has a pole of order 2 at z = 1 and K =

z

. It can be shown that

To show (iv), suppose that ̃Φ
⊂ ran ̃P ⊂ ker

2

2

)

)

(

(

{

̃Φ

̃Φ

1
)

1
)

0
}

{
To show (v), we note that Bp = ran ̃Φ

ker ̃Φ
̃Φ
1
(
(
)
To see why the second inclusion holds, we note that ̃N−2 =
̃N−2 = 0. From these results, we ﬁnd that ̃Φ
(B.6) that ̃Φ
(
inclusion. Since K =
= ker
implies that ker ̃Φ
(
̃P = 0. This contradicts our assumption that ̃Φ
̃N−2 =
1
)

(
holds under Assumption 3.1, where the ﬁrst inclusion follows from (B.10).
̃P (Lemma B.1-(iv)), and then deduce from
̃P = 0, which proves the second
and so
0
.
}
⊕ ran Q ⊕ R∁ under the former direct sum (B.21). Moreover,
∁. Therefore,

̃Φ
1
(
)
̃N−2 =
1
)
(
, we ﬁnd that ran ̃P = ker ̃Φ
1
̃Φ
)
(
−1 has a pole of order 2 at z = 1, so K ≠
z

(
from the latter direct sum of (B.21), we have Bp = ker Q ⊕ K∁, where ker Q = K ⊕
the generalized inverse Qg exists and ran Qg = K∁ and ker Qg = ran ̃Φ
Lemma B.3. Suppose that Assumption 3.2holds. Thenfor anyarbitrary choice of R∁ and K∁,the operator
M1 = P
M1Mg

ker ̃Φ
⊕ R∁, see Appendix A.3.

allowsthegeneralized inverse Mg

∁
)]
1M1 = PK∁,

1
(
)]
I − PR∁

ran Φ
[
1 =

1 satisfying

1 = ran Φ

1 = K∁,

ran Mg

ker Mg

1
∁ Φ(
)

⊕ R∁,

ker Φ
[

1
)]

(B.23)

I − P

1
)

1
)

1
)

1
)

1
)

(
P

1
(

{

(

(

(

)

(

(

)

)

(

[

2

1
)(
ran Φ
[

∁ , Mg
)
where PK∁ istheprojection onto K∁ along

1
(

)]

(

1
)

(

ker Φ

1
)]

(

[

∁ ⊕ K.

Proof. Under the direct sums given in (3.39), B = ran Φ
∁ ⊕ K, hence we have B = ker M1 ⊕ K∁. (To see why, recall that B = ker Φ
1
ker Φ
)]
[
and ker Φ
1
)
whose range is K∁ and kernel is ran Φ

1
)
1
)]
= K ⊕ K∁.) We then know from Appendix A.3 that M1 allows the generalized inverse Mg

⊕ R∁, from which (B.23) immediately follows.

⊕ ran M1 ⊕ R∁ holds. Note also that ker M1 =

ker Φ

1
)

⊕

(

(

(

(

(

[

∁

1

1
)

(

B.3.2 Proofs of the main results

Proof of Proposition 3.5. Under the direct sums (B.21) given in Lemma B.2-(ii), we let PR∁ denotes the
⊕R, which is well deﬁned. The whole proof is divided into several parts.
projection onto R∁ along ran ̃Φ
1. Necessity of the I(2) condition : If the I(2) condition is not satisﬁed, then it must be the case either

1
)

(

gK ≠

(

(

1
)

1
))

∩ ̃Φ
(

+ ker ̃Φ

ran ̃Φ
(

1
)
It will be shown that (B.24) is false if ̃Φ
(
)
̃N−2 ̃Φ
̃N−2 ̃Φ1 − ̃N−1 ̃Φ
̃N−1 ̃Φ1 − ̃N0 ̃Φ

z

0
}

or Bp ≠ ran ̃Φ
(

1
)

+ ker ̃Φ

1
)

+ ̃Φ
(

1
)

{
−1 has a pole of order 2 at z = 1. From (B.5)-(B.6), we have

(

gK.

(B.24)

1
)
1
)
1
)

(

(

(

=0 =

=0 =
= Ip =

̃Φ
̃N−2,
1
)
(
̃Φ1 ̃N−2 − ̃Φ
(
̃Φ1 ̃N−1 − ̃Φ

̃N−1,
1
)
̃N0.
1
)

(

(B.25)

(B.26)

(B.27)

From (B.25), we observe that

39

̃N−2 ̃Φ1,
.

ran ̃Φ
[

1
(

∁
)]

̃Φ1 ̃N−2 =
̃N−2P
, we ﬁnd that

̃N−2 =
̃N−2 =
1
)
= 0 ⇔

Restricting both sides of (B.26) to ker ̃Φ
(

̃N−2

1
ker ̃Φ
∣
)
(

̃N−2 ker ̃Φ

=

1
)

(

.

0
}

{

g exists, and then deduce from (B.26) and (B.28) that

We note that ̃Φ

1
)

(

Ip −P

̃N−1

̃N−2.
(B.29) implies that post-composing both sides of the latter equation in (B.31) with P
nothing, hence

̃N−2 ̃Φ
(

1
ker ̃Φ
(
[

ran ̃Φ
[

∁ ̃N−1 =

1
)

1
)

̃Φ

∁ )

1
(

=

)]

)]

(

(

g, P

g

Ip −P
ran ̃Φ
[
From the former equation in (B.31) and (B.32), we ﬁnd that

̃N−2 +

̃N−1P

1
)

∁
)]

̃Φ

1
(

=

(

(

g

ker ̃Φ
[

1
(

∁ )

)]

̃N−1P

.

1
ran ̃Φ
(
[

∁
)]

(B.28)

(B.29)

(B.30)

(B.31)

changes

(B.32)

1
ran ̃Φ
(
[

∁
)]

g

g + ̃Φ
(

(

1
)

1
)

̃N−1 =

̃N−2 ̃Φ

̃N−1P
K, which is due to (B.30). Further,
∣
K = Ip
K =
K =
1
∣
∣
)
∣
1
K. Given PR∁, the former direct sum given in (B.21), equations (B.29)-(B.30), and the fact that ran ̃Φ
⊕
)
(
∣

̃N−2 +
(
Restricting both sides of (B.33) to K, we obtain ̃N−1
̃N−1
Ip
R = ran ̃Φ

K is deduced by restricting both sides of (B.27) to K, so we ﬁnd that ̃N−1
∣

ker ̃Φ
[
̃N−2 ̃Φ
(

K =
∣

̃N−2 ̃Φ

ran ̃Φ
[

)]
1
)

(B.33)

∁ )
g

∁
)]

1
(

1
(

(

.

g

Ip −P

1
)

(

+ ker ̃Φ
(

1
)

, we conclude that ̃N−2 =
̃N−2PR∁ ̃Φ
(

̃N−2PR∁. Therefore,
1
)

K = Ip
∣

K.
∣

g

(B.34)

g ∶ K ↦ R∁, hence the former condition in (B.24) is impossible.

This proves injectivity of PR∁ ̃Φ
(

1
)

Pre-composing both sides of the latter equation in (B.26) with PR∁ ̃Φ

g and using (B.28), we have

1
)

(

PR∁ ̃Φ

g

1
)

(

̃N−2 = PR∁P

1
ker ̃Φ
(
[

)]

∁ ̃N−1 = PR∁ ̃N−1,

(B.35)

where the last equality is established from the fact that the kernel of PR∁ is ran ̃Φ
PR∁

and thus
= 0 . Similarly, pre-composing both sides of the latter equation of (B.27) with PR∁,

+ ker ̃Φ

Ip −P

1
)

1
)

(

(

(

ker ̃Φ
[

1
(

∁ )

)]

Note that PR∁ ̃N−1 = PR∁ ̃Φ
(B.36) that PR∁ ̃N−1 = PR∁. Combining this with (B.35), we obtain PR∁ ̃Φ
sujectivity of PR∁ ̃Φ

g ∶ K ↦ R∁. Hence, the latter condition in (B.24) cannot hold.

̃N0 = PR∁.
PR∁ ̃Φ1 ̃N−1 = PR∁ + PR∁ ̃Φ
(
̃N−1 + PR∁ ̃Φ1 ̃N−1, where the ﬁrst term is 0. We therefore deduce from
̃N−2 = PR∁ , which implies

(B.36)

1
)

1
)

1
)

(

(

g

1
)

(

(

)

z

1
)

̃N−m ̃Φ1 =

2. Sufﬁciency of the I(2) condition : Suppose that ̃Φ
that ̃N−m =
̃Φ
1
)
(
the I(2) condition holds, any x ∈ Bp can be written as x = xran + xker + ̃Φ
1
)
xker ∈ ker ̃Φ
y1 ∈ Bp and y2 ∈ Bp satisfying xran =

̃Φ1 ̃N−m from (B.6), and also ̃N−m = Gm−1 =

and xK ∈ K. From the deﬁnitions of ran ̃Φ
1
(
)
y2, and ̃Φ
1
̃Φ
)
(
xran + xker + ̃Φ

̃Φ
1
)
(
where the ﬁrst equality comes from commutativity of ̃P and ̃Φ
(
̃Φ

1
(
)
my1 + ̃P ̃Φ
(
1
)

y1, xK =
gxK

1
)
̃P ̃Φ
(

̃PB =

, so ̃Φ

̃Φ
(
=

̃Px =

̃P ̃Φ

1
)

1
)

1
)

m−1

m−1

m−1

m−1

(

(

(

)

(

0
}

{

1
)

(

1
)

(

−1 has a pole of order m ≥ 3 at z = 1. We deduce
̃P from Lemma B.1-(iv). If
gxK, where xran ∈ ran ̃Φ
1
,
)
and K, we also know that there exist

m−1

(

(
2y2 = 0. We thus ﬁnd that

. It is then deduced from (B.37) that
̃P = 0. That is, ̃N−m = 0 is concluded, which, however, contradicts our as-

m−1

1
)

(

xker + y2

)

= 0,

(B.37)

40

sumption that ̃Φ
{
which excludes the existence of a simple pole (see Proposition 3.2).

−1 has a pole of order m ≥ 3. In addition, K ≠

z

)

(

0
}

implies that B ≠ ran ̃Φ
(

1
)

⊕ker ̃Φ

,

1
)

(

2

z

)

z

̃Φ
(

)

̃N−1 + ̃Φ1 ̃N−1. We also know from (B.28) that ̃N−2 ̃Φ2

1 =

̃N−2. Combining this with (B.26), it is deduced that ̃N−1 =

3. Formula for ̃N−1 : Note that ̃N−1 =
̃N−2 ̃Φ1 =
4. ran ̃N−2 = K : The result immediately follows from (B.34) and invertibility of PR∁ ̃Φ
−1 and H
5. Holomorphicity of

̃N−1 + ̃Φ1 ̃N−1 =
1
)

1
)

1
)

̃Φ

̃Φ

z

z

(

(

(

2

1 −
−1 is convergent on D1+η. Then from an obvious extension of Lemma 4.1 of Johansen (1995), it

on D1+η : We know that the Maclaurin series of

1 − z

̃Φ

(

(

)

)

)

(

(

̃N−2 + ̃P.
g ∶ K → R∁.

may be deduced that the Maulaurin series of H

is convergent on D1+η.

z

(

)

(

Π∗
p

̃N−2 + ̃P

−1 = −Πp ̃N−2Π∗
Proof of Proposition 3.6. From Propositions 3.1 and 3.5, we have
p +
2. Applying the linear ﬁlter induced by
−1
2Φ
1 − z
Πp
1 − z
Πp
z
z
(
to (3.1), we obtain ∆2Xt = −Πp ̃N−2Π∗
̃N−2 + ̃P
εt − εt−1
. We then may
deduce that solutions to (3.1) satisﬁes (3.4) for some τ0 and τ1. The claimed expression of νt can be veri-
ﬁed from nearly identical arguments used in our proof of Proposition 3.3. Moreover, we may deduce from

1 − z
(
)
p εt + Πp

(
∆νt − ∆νt−1

+ ΠpH

1 − z

Π∗
p

2Φ

+

z

)

(

(

)

(

)

(

)

(

(

)

)

)

)

)

(

)

Propositions 3.1 and 3.5 that (3.1) does not allow I(2) solutions if the I(2) condition is not satisﬁed.

Proof of Proposition 3.7. We write the Laurent series of Φ
Φ
z − 1
)
(ii) ⇒ (i). The whole proof is divided into several parts.

∞
j=−d Nj

−1 = −

∑

z

(

)

(

,
}
j. Since it is obvious that (iii) ⇒ (ii), we will only show that (i) ⇒ (iii) and

−1 around z = 1 as follows: for d ∈ N∪

∞

{

z

(

)

1. (i) ⇒ (iii) : Let R∁ and K∁ be arbitrarily chosen among possible candidates. If
)
know from (4.40) of Beare et al. (2017) that x1 = ⋯ = xp, and there exists y1 ∈ B such that Φ
1
x1. This implies that x1 ∈ K. Since ran ̃N−2 = K, ran N−2 = ran Πp ̃N−2Π∗
−Φ(
)
the I(2) condition, we know that Φ
the coefﬁcients in the identity expansion Φ

∈ K, we
y1 =
p ⊂ K holds. Under
−1 has a pole of order 2 at z = 1 and may deduce the following from
−1,

x1, . . . , xp

1
)

1
)

Φ

z

z

(

)

(

(

(

1
N−2Φ(
)
1
2 + N−1Φ(
)

(

2
N−2Φ(
)

1
)/

(

(
1
)

+ N−1Φ

1
)
+ N0Φ

1
)

(

z
(
N−2Φ

)

(

)

z
(
N−2,

(

z
)
=0 = Φ

= I = Φ
1
)
(
1
=0 = Φ(
)

−1Φ
)
1
)
(
1
)
2
= −I = Φ(
)

(

(

1
)
1
)

(

N−2

/

N−2 + Φ

N−1,
1
(
)
1
2 + Φ(
)

1
)

(

(B.38)

(B.39)

(B.40)

N−1 + Φ

N0.

1
)

(

I −
= 0 and −N−2PR∁M2PK = PK. This implies that K ⊂ ran N−2 (hence ran N−2 = K has been

From some algebra similar to that in proof of Theorem 4.2 of Beare and Seo (2020), we ﬁnd that N−2
PR∁
established) and thus Λ2,∁ = PR∁M2PK ∶ K ↦ R∁ is an injection.
Now from the latter equation in (B.39) and the properties of Φ

g, we may deduce that

(

)

1
gΦ(
)

1
N−2 + Φ(
)

1
Φ(
)

1
N−1 = −Φ(
)

(

(

(

Φ

1
)

1
)

1
)

1
1
ker Φ
)
(
[
1
N−1 =
From the latter equation in (B.40) and (B.41), we obtain PR∁M2N−2 + PR∁Φ(
1
1
)
)
)(
(
(
1
N−1 = 0. We
=
I − P
−PR∁. Note that PR∁Φ(
)
thus ﬁnd that PR∁M2N−2 = −PR∁. Since ran N−2 = K as shown above, this implies that Λ2,∁ = PR∁M2PK ∶
K ↦ R∁ is also a surjection, i.e., it is a bijection. The above arguments do not depend on a speciﬁc choice
of R∁ and K∁, and thus (i) ⇒ (iii).

1
, which implies that PR∁Φ(
)

ker Φ
[
1
(

∁
)
)]
I − P

ker Φ
[

1
)(

(B.41)

I − P

N−1.

ker Φ

0
}

1
)

1
)

∁
)]

∁
)]

{

)

(

(

(

(

(

1
)

(
1
)(

41

2.(ii) ⇒ (i) : Suppose that Assumption 3.2 hold and Λ2,∁ is invertible for some choice of R∁ and K∁. It
g (Lemma (i)-(iii)). Let
sufﬁces to show that the I(2) condition holds for some choice of ̃Φ
1
)
(
̃Φ−1
̃Φ
12
22
g
]
[
]
[
̃Φ
1
Φ
21
)
(
]
[

1
−Φ
+ ̃Φ−1
)
(
̃Φ
22
]
[

1
Φ
)
(
̃Φ
21
]
[

(B.42)

−̃Φ−1

̃Φ
(

1
)

̃Φ−1

̃Φ−1

g =

1
)
(

22
]
[

12
]
[

22
]
[

22
[

])

(

Φ

.

g

g

g

g

(

(

̃Φ

1
)

1
)

g = Ip −Q∁
=
̃Φ
1
(
)

given in our proof of Lemma B.2-(i).

1
)
, given in (B.15). Moreover, ̃Φ
(

From the factorization formula (2.3) of Bart et al. (2007), it may be easily shown that ̃Φ
for Q∁, the bounded projection whose kernel is equal to ran ̃Φ
1
(
)
Ip −T∁ for T∁, the bounded projection whose range is equal to ker ̃Φ
(
g given in (B.42) is the generalized inverse of ̃Φ
Therefore, ̃Φ
1
1
ran ̃Φ
for some
∁
(
)
(
)]
1
depending on the choice of
∁. As in our proof of Lemma B.2-(ii), we let
)]
(
S∁ ∶ Bp → Bp denote the block operator matrix obtained by replacing P
∁ with PR∁ in the deﬁnition
ran Φ
[
∶ Bp−1 ↦ B denote the upper-right block of S∁. We already showed
of Q∁ given by (B.15), and let S∁,
that S∁ is a projection onto a complementary subspace of ran ̃Φ
1
+ ker ̃Φ
in our proof of Lemma
(
)
g =
B.2-(ii). Then using the formula (2.3) of Bart et al. (2007), we ﬁnd that S∁ ̃Φ
1
)
(
C1 =PR∁Φ
1
Φ
)
(
−1+S∁,
C2 =PR∁Φ

, where
)

ker ̃Φ
(

C1 C2
0
0

1
)]

1
)]

∁ and

∁ and

1,2
]
[

ran Φ

ker Φ

21
]
[

1
)

1
)

1
)

1
(

g,

Φ

−1

−1

)]

(

(

(

(

(

[

[

[

[

g

̃Φ
1
1
)
)
](
are deﬁned in (B.1). Consider xk =

−1+ ̃Φ

1
)

22
[

22
[

12
[

̃Φ

](

](

21
[

1
)

1
̃Φ
](
)
x1,k, . . . , xp,k

(

12
[

1
)

̃Φ
̃Φ
22
)
[
∈ K, then we ﬁnd that

1
)

](

](

,

and ̃Φ
x1,k = ⋯ = xp,k and x1,k ∈ K. For such xk, we obtain the following after a tedious algebra,

21
[

22
[

12
[

](

](

](

(

)

g − S∁,
1
)
g
̃Φ
1
)
, ̃Φ

12
[

22
]
[
22
[

̃Φ−1
12
]
[
̃Φ
1
)
, ̃Φ

](
⋅
)

](
⋅
)

(
⋅
)

gxk =

S∁ ̃Φ

1
)

(

−PR∁M2PKx1,k, 0, . . . , 0
)
(

.

(B.43)

From the deﬁnition of S∁, it may be deduced that ran S∁ ⊂
. Com-
{(
bining this result with (B.43) and invertibility of the map Λ2,∁ = PR∁M2PK ∶ K ↦ R∁, we may con-
gK is a complementary subspace of
K ↦ R∁ is invertible. This implies that ̃Φ
clude that S∁ ∶ ̃Φ
(
+ ker ̃Φ
1
ran ̃Φ
by a similar argument that we used in our proof of Proposition 3.4. From the above
)
(
proof, we know that K =

is impossible since it implies K = 0.

x1, 0, . . . , 0
)

1
)
(
1
)
(

1
)

∈ Bp ∶ x1 ∈ R∁

}

0
}

{

3. Formula for Υ−2 : We know −N−2PR∁M2PK = PK holds under the I(2) condition. Since the map
Λ2,∁ ∶ K ↦ R∁ is invertible and Υ−2 = −N−2, the desired results given by (3.42) are easily obtained.

4. Formula for Υ−1 : We ﬁrst establish some preliminary results. According to the direct sums given in
Assumption 3.2 and for any arbitrary choice of the complementary subspaces therein, we have

I =

(

I − P

ran Φ
[

+

I − PR∁

P

)

∁
)]

1
(
x1,k, . . . , xp,k

(

ran Φ
[

1
(

)]

)
∈ Bp, xk ∈ ker ̃Φ
(

∁ + PR∁.

As shown in our previous proof, for xk =
x1,k = ⋯ = xp,k and x1,k ∈ ker Φ
(
expressions of N−1
∁
)
)]
need (B.39), (B.40) and the following obtained from the coefﬁcient of
Φ

(resp. xk ∈ K) implies that
(resp. x1,k ∈ K). Based on the identity (B.44), we will obtain explicit
1
)
∁ and N−1PR∁. In the subsequent proof, we
, N−1
1 in the identity expansion

z − 1
)

I − PR∁

ran Φ
[

ran Φ
[

= I = Φ

I − P

−1Φ

1
)

−1,

1
(

1
(

Φ

P

z

z

z

z

)]

)

)

(

(

(

(

(B.44)

(
(
)
3
N−2Φ(
)

)
1
)/

(

(

)
(
2
6+N−1Φ(
)

)
1
)/

(

1
2+N0Φ(
)

1
)

(

3
=0 = Φ(
)

N−2

1
)

(

/

2
6+Φ(
)

N−1

1
)

(

/

1
2+Φ(
)

N0.

1
)

(

(B.45)

42

From (B.39), we have

N−1

I − P
(
1
From (B.40) and the identity N−1Φ(
)
have
P

)
I − P
1
(
(
1
ker Φ
)
(
[
. Substituting (B.46) into this equation and using the deﬁnition of M1, we have

1
Φ
1
(
)
)
1
1
Φ(
)
)
(
1
∁ Φ(
)

ran Φ
1
∁
[
(
)]
= N−1
1
Φ(
)

+ N−1P
1
)](

(
1
∁
)
)]
(
1
ran Φ
(
[

ran Φ
[
+ N−1P

ran Φ
[
I − P

(
ran Φ
[

2
N−2Φ(
)

2 + N−1

1
)
1
(

1
)/

I − P

∁
)]

)]

(

(

)

(

1
= −N−2Φ(
)

g.

(B.46)

1
1
∁ Φ(
)
)
(
= −
(

∁
)]

)

)]
1
(

, we

I −

[
ker Φ
[

1
(

∁
)]

)

N−1M1 = −
I + N−2M2
(
)(
1 and using the fact that M1Mg
Post-composing both sides of (B.47) with Mg
B.3), we obtain that

ker Φ
[

I − P

∁
)]

1
(

,

)
1 =

(B.47)

I −PR∁

P

)

ran Φ
[

(

1
(

)]

∁ (Lemma

P

N−1

I − PR∁
(
3
N−2Φ(
1
Now from (B.45), we have
)
[
)/
(
1
deﬁnition of K that N0Φ(
PK = N0
I − P
1
)
(
)
(
2
g
g − N−2Φ(
1
Φ
P
)
(
/
)
N−2M3 − N−2M2Φ

1
)/
(
1
Φ(
ran Φ
1
)
)
[
(
1
1
2 − N−1Φ(
)
)
(
1
gΦ(
)

= −
∁
(
)
)]
2
6 + N−1Φ(
)

ran Φ
[

ran Φ
[

= −Φ

1
)

1
)

∁
)]

∁
)]

1
(

1
(

(

)

(
N−1M2PK = −
[

I + N−2M2
)
1
2 + N0Φ(
)

Mg
1.

(B.48)

(

1
)]

PK = 0. We note from the
I −
g. Combining these results, we obtain

PK, and deduce from (B.40) that N0
1
)
1
)
− Φ

(B.49)

PK.

1
gΦ(
)

(

(
Φ

(
1
)
(
I −PR∁

1
(

∁
)]

1
)

ran Φ
[

1
)
P

(
(
M2−N−1

1
)]
1
(
)]
∁ are given in (B.46) and (B.48), we have
1
1
gΦ(
gΦ(
1
)
)
(
)
Mg
gM2PK +

1
(
)
I + N−2M2

(
ran Φ
[

1
)

− Φ

Φ

)

(

)

(

PK

1
(
)]
1M2PK.

N−2M3 − N−2M2Φ

[

1
+ N−2Φ(
)

∁M2

PK, and N−1

I −

(

]

Since N−1PR∁M2PK =
P

and N−1

ran Φ
[

1
(

∁
)]

)

N−1M2−N−1
P

[
I − PR∁

(
1
ran Φ
[
(
N−1PR∁M2PK = −

)

(

)]

I −P

(

(

1
)

1
)
By post-composing both sides of (B.50) with N−2, a formula for N−1PR∁ is obtained. Combining this with
(B.46), (B.48), and the fact that Υ−2 = −N−2 and Υ−1 = N−1, we obtain
1
1
gΦ(
1
1
Φ(
)
)
)
(
)
(
gM2 − M2Mg
1M2

1
)
1 = K∁ and Υ−2 = PKΥ−2PR∁, the desired results are obtained from (B.51).

+ Υ−2
Using the fact that ran Mg

1
Φ
(
)
M3 − M2Φ
(

1
)
1
gΦ(
)

Υ−1 = − Mg

g + M2Mg

)
1
− Φ(
)

Υ−2 + Υ−2

(
1
)

+ Mg

(B.50)

(B.51)

Υ−2.

1M2

1
)

1
)

1 +

Φ

Φ

)

)

(

)

(

(

(

(

(

(

1

(

(

)

z

1
(

∁
)]

∁
)]

1
)

and ̃Φ

1
ker ̃Φ
(
[

[
Ip −P

1
ran ̃Φ
(
[

⊕ R (resp.

1
)]
∁ )

−1 in more detail. Let P

B.3.3 Supplementary results to Proposition 3.5
We here characterize the principal part of the Laurent series ̃Φ
,
g be deﬁned as in Section 3.4.1. Given the direct sum conditions given in (B.21),
P
which holds under Assumption 3.2, we let PR∁ (resp. PK) be the projection onto R∁ (resp. K) along
g ∶ K ↦ R∁ and let
∁ ⊕ K∁). Let ̃Λ be the map given by PR∁ ̃Φ
ran ̃Φ
1
ker ̃Φ
(
)
(
(
. Given the direct sums (3.24), the generalized inverse Qg is well de-
Q = P
ran ̃Φ
1
ker ̃Φ
[
(
[
ﬁned and satisﬁes that ran Qg = K∁ and ker Qg = ran ̃Φ
⊕ R∁ (Lemma B.2-(v)). We will show that
̃Λ ∶ K ↦ R∁ is invertible and ̃N−2 satisﬁes
̃N−2
(
Ip −Γr

and ̃P =
1. Formula for ̃N−2 : Under the I(2) condition, we know from our proof of Proposition 3.5 that (B.34) holds,
̃N−2 =

g ∶ K → R∁ is bijective, from which (B.52) immediately follows.

̃N−2 ∶ R∁ ↦ K =
̃Φ

̃N−2PR∁ and ̃Λ = PR∁ ̃Φ

̃N−2 and Γr =

̃N−2 =
+ Γℓ

+ Γr, where Γℓ =

Ip −PR∁

Ip −PK

Ip −Γr

̃N−2 ̃Φ

Ip −Γℓ

̃Λ−1,

(
Qg

(B.52)

1
)

1
)

1
)

1
)

= 0,

∁ (

g.

)]

)]

(

)

(

)

(

)

(

)

(

)

(

g

1
)

(

43

2. Formula for ̃P : We will verify the claimed formula for ̃P. From the former direct sum in (B.21), we have
(B.53)

P

+

Ip =

Ip −P

Ip −PR∁

+ PR∁.

(
+ ̃P

(

ran ̃Φ
1
[
(
)]
Ip −PR∁

∁ )
P

(
1
ran ̃Φ
(
[

∁
)]

)

1
ran ̃Φ
(
[

∁
)]

)

+ ̃PPR∁ , we will obtain an expression for each

Thus ̃P =
summand.

̃P

(

Ip −P

ran ̃Φ
[

1
(

∁ )

)]

Pre-composing both sides of the former equation in (B.26) with ̃Φ1, we obtain ̃Φ1 ̃N−2 ̃Φ1 =

We then deduce the following from (B.28) and the fact that ̃Φ1 ̃N−1 =
̃P,
g.
1
)

̃N−2 ̃Φ
(

Ip −P

1
(

̃P

=

̃Φ1 ̃N−1 ̃Φ

.

1
)

(

(B.54)

(

)]

1
(

∁ )

ran ̃Φ
[
1
(

ran ̃Φ
[
+ P
, we ﬁnd that ̃PQ =
Ip −P
1
)

∁ )
Ip − ̃N−2 ̃Φ

and post-composing both sides of the former equa-
Ip − ̃P
(
(
1
ker ̃Φ
∁ )
(
)]
[
. Thus, post-composing both sides with Qg, we ﬁnd that

Ip −P
Ip −P
. It may be deduced from Lemma B.2-(v)

ran ̃Φ
[

ran ̃Φ
[

ker ̃Φ
[

. Then

∁ ))(

∁
)]

∁
)]

∁ )

1
(

1
(

1
(

)(

)]

)]

)]

(

g

Ip −P

Using the identity Ip =
(
tion in (B.27) with Ip −P
ker ̃Φ
[
from (B.54), we obtain ̃PQ =
that QQg =
ran ̃Φ
[
̃P

Ip −PR∁

P

)

(

(
1
∁
(
)]
Ip −PR∁

g

Qg.

(

(

(

)

)]

)]

(

=

P

1
(

1
(

∁ )

∁
)]

Ip − ̃N−2 ̃Φ
(

1
)

1
)

1
)

̃Φ
(

(B.55)

ran ̃Φ
[

ran ̃Φ
[

Ip −P

gPK. Note that

∁ )
1
̃N1 ̃Φ
)
(

gPK −
gPK, we obtain ̃P ̃Φ
PK = PK. We also deduce from (B.6)
gPK =

PK =
1
ran ̃Φ
(
[
, which implies that ̃N0PK = 0. Combining these results, we ﬁnd that ̃P ̃Φ

gPK. Then from the identity decomposition (B.53), we have
gPK − ̃P
(

1
)
)
Post-composing both sides of the former equation in (B.27) with ̃Φ
(
Ip −P
̃N0
that ̃N0 ̃Φ1 =
1
̃Φ
(
)
̃PPR∁ ̃Φ
̃Φ
(
We then substitute (B.54) and (B.55) into (B.56), and then post-compose both sides with ̃N−2, noting that
PK ̃N−2 =
̃N−2 due to (B.52). This gives us an explicit formula for ̃PPR∁. Combining this with (B.54) and
(B.55), the claimed formula for ̃P can be obtained.
B.3.4 A detailed discussion on Remark 3.15
Since ran Υ−2 = K, f ∈ Ann
deduce from the formula of Υ−1 given in Proposition 3.7 that f Υ−1 is equal to

is a cointegrating functional. For any nonzero f ∈ Ann

gPK − ̃P
(

gPK =
̃Φ
(

Ip −PR∁

, we may

Ip −P

∁ ̃Φ
(

ran ̃Φ
[

ran ̃Φ
[

gPK.

(B.56)

K
)

Υ−2

1
)

1
)

1
)

1
)

1
)

∁ )

1
(

1
(

P

)]

)]

)

(

)

(

(

(

(

Using the expression of f Υ−1 given by (B.57), we will show that the following holds,

− f Mg
1

(

I − M2Υ−2

+ f Φ

1
)

(

)

1
gΦ(
)

Υ−2.

1
)

(

(B.57)

1
gΦ(
)

(

(

Φ

1
)

1
)

ker Φ

K
)

f Υ−1 = 0 ⇔ f ∈ Ann
(

∩ Ann
(
Since ran Υ−2 = K, the second term in (B.57) is zero if and only if f ∈ Ann
(
remains to show that f ∈ Ann
1
because ker Φ
. To see this, we ﬁrst
(
)
)
= K∁. Since ran Mg
Mg
⊂ K∁. Note that for
1 = K∁, ran
I − M2Υ−2
show that ran
1
(
))
(
(
any V ⊂ B, Mg
V ⊂ Mg
B ⊂ K∁ holds. Thus, if there is a subset V such that
I − M2Υ−2
I − M2Υ−2
1
1
(
(
Mg
Mg
V = K∁, then ran
= K∁ holds. Let V =
I −M2Υ−2
I −PR∁
I −M2Υ−2
∁. We then
1
1
(
)
(
))
. Moreover, ran Mg
⊕ R∁.
know from (3.42) that M2Υ−2V =
1
0
(
)
{
}
V = Mg
From these results, we ﬁnd that Mg
= K∁. We
I − M2Υ−2
1

1
)
(
= K ⊕ K∁ and f ∈ Ann
(
Mg
1

1 = Mg
1V = K∁, so ran

)[
(
1V holds since ker Mg

1
(
))
1
gΦ(
)
K
)

ran Φ
1
)]
(
1 = ran Φ

I − M2Υ−2

I − M2Υ−2

. It thus only

(B.58)

K
)

Mg
1

1
)

K∁

))

Φ

)

(

)

(

(

(

.

(

)

(

(

))

44

K∁

)

)

(

Xt

+ f

K
)

if and only if the ﬁrst term in (B.57) is zero.

thus conclude that f ∈ Ann
(
We have shown that (B.58) holds for f ∈ Ann
(

= f Υ−1
(∑
Xt
(
)
−1 = −N−2

. We know from Proposition 3.7 that (ignoring τ0
K
satisﬁes either of the following: (i)
)
t
= f
s=1 εs
t≥0 is
is I(0) under our I(2) condition. To see this, note that we know from
∞
j=0 Nj
z

and τ1 without loss of generality) a nonzero element f ∈ Ann
(
f Υ−1 ≠ 0 and f
Xt
I(1) obviously. In case (ii), f
Proposition 3.5 that Φ
z − 1
(
)
)
on D1+η for η > 0 (and thus the coefﬁcients of the Maclaurin series of H
decay exponentially in norm)
p . As in Appendix B.2.3, it sufﬁces to show that f N0 ≠ 0 to establish the desired
and N0 = −
I(0)-ness. Under the I(2) condition, we know from (B.40) that ran N−2 + ran N−1 + ran N0 = I. Since
f N−2 = f N−1 = 0 in case (ii), f N0 = 0 implies f = 0, which contradicts our assumption that f ≠ 0. We
thus ﬁnd that f N0 ≠ 0, so the cointegrating behavior of I(2) solutions is characterized as stated.

(
)
j=0 ΠpHjΠ∗

(
)
−2 − N−1

z − 1
)

z − 1
)

is convergent

In case (i),

or (ii) f

−1 −

j, H

Xt

)}

∑

∑

νt

νt

∞

f

{

)

z

z

(

(

(

)

(

)

)

(

(

(

.

B.3.5 A detailed discussion on Remark 3.16

For a nonzero f ∈ Ann
(

K
)

, we deduce from (B.57) that f

1
)

1
gΦ(
)

∆Xt

1
)

(

)

is given by

Xt

)

(
t

− f

(

Φ

(
ν⭒
t

− f

Mg
1
(

(

I − M2Υ−2

∑
s=1

)

εs

)

+ f

(

,

)

(B.59)

Mg
1

(

(

(

)

(

(

(

(

(

(

{

{

f

))

∑

)}

ν⭒
t

1
)

1
)

ker Φ

ker Φ

K
)

1
))

1
))

, f ∉ Ann

t = νt − Φ
1
)

then the ﬁrst term in (B.59) is zero. Hence, it only remains to prove I(0)-ness of

= K∁.
I − M2Υ−2
K∁
. Therefore,
. On the other hand, if f ∈

1
gΦ(
)
(
= K ⊕ K∁ and f ∈ Ann
(

where ν⭒
Since ker Φ
1
))
the sequence given in (B.59) cannot be stationary for f ∉ Ann
(
Ann
(

εt + ∆νt. As shown in Appendix B.3.4, ran
(
implies that f ∉ Ann
(
ker Φ

t≥0
for the desired result. The summability condition for the I(0) property is satisﬁed, which can be easily
1
gΦ(
∞
t as ν⭒
shown. We rewrite ν⭒
t =
1
N−1. If this
j=0 Ψjεt−j, and ﬁnd that
)
∑
)
(
1
gΦ(
ν⭒
t≥0 is I(0). Suppose by contradiction that f N0 = −f Φ
N−1.
1
1
f
operator is nonzero, then
t
)
)
(
)
g and using the fact that Φ
Pre-composing (B.40) with f Φ
1
∁ , we ﬁnd that
)
1
g.
gΦ(
)

2
gΦ(
1
)
)
1
gΦ(
In the above, f Φ
)
= 0 for any f ∈ Ann
1
P
)
(
our expression of N−2 = −Υ−2 given in (3.42), we know that N−2 ran Φ
2
gΦ(
)

ker Φ
1
[
(
∁ N0 = −f Φ
1
)
(
)]
∁ N0 = f N0 since f
N−1 = −f N0 under our supposition, and f P
1
ker Φ
[
(
)]
2
gΦ(
2 = −f Φ
N−2
1
)
)
(
=
0
1
(
}
)
for all x ∈ ran Φ

∞
j=0 Ψj = −N0 − Φ

. We thus ﬁnd that f Φ

(
N−1 + f P

I −
(
g. From

1
)
(
ker Φ
[

)}
1
)
(
N−2

N−2x = −f Φ

/
and so

0 = f Φ

2 + f Φ

ker Φ
[

(
1
)

(
1
)

1
))

1
)
(
From the properties of a generalized inverse, we have Φ
(B.60) holds if and only if f ∈ Ann
ker Φ

1
∁
)]
∁, we conclude that f = 0, which contradicts our assumption that f is nonzero.

1
))

1
)
. Since f ∈ Ann

1
)
1
)]
and B = ker Φ

∁ and thus ﬁnd that
⊕

(
ker Φ

g ran Φ

[
ker Φ

(B.60)

ker Φ

ker Φ

1
)

1
)

1
)

1
)

1
)

1
)

1
)

1
)

1
)

gx,

= P

gΦ

f Φ

∁
)]

1
(

1
(

([

=

/

{

)]

(

(

(

(

(

(

(

(

(

(

(

(

(

)

(

(

(

(

)

(

.

[

(

1
)]

45

