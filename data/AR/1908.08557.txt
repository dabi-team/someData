9
1
0
2

g
u
A
2
2

]

R
S
.
h
p
-
o
r
t
s
a
[

1
v
7
5
5
8
0
.
8
0
9
1
:
v
i
X
r
a

GEOPHYSICAL & ASTROPHYSICAL FLUID DYNAMICS

DOI: 10.1080/03091929.2019.1643849

Driving solar coronal MHD simulations on high-performance
computers

Philippe-A. Bourdin

Space Research Institute, Austrian Academy of Sciences, Graz, Austria

ARTICLE HISTORY
Received 30 August 2018
Accepted 11 July 2019

KEYWORDS
Magneto-hydrodynamics;
astrophysics; Sun; corona;
high-performance computing

ABSTRACT
The quality of today’s research is often tightly limited to the available
computing power and scalability of codes to many processors. For
example, tackling the problem of heating the solar corona requires a
most realistic description of the plasma dynamics and the magnetic
ﬁeld. Numerically solving such a magneto-hydrodynamical (MHD)
description of a small active region (AR) on the Sun requires mil-
lions of computation hours on current high-performance comput-
ing (HPC) hardware. The aim of this work is to describe methods
for an efﬁcient parallelization of boundary conditions and data in-
put/output (IO) strategies that allow for a better scaling towards
thousands of processors (CPUs). The Pencil Code is tested before
and after optimization to compare the performance and scalability
of a coronal MHD model above an AR. We present a novel bound-
ary condition for non-vertical magnetic ﬁelds in the photosphere,
where we approach the realistic pressure increase below the pho-
tosphere. With that, magnetic ﬂux bundles become narrower with
depth and the ﬂux density increases accordingly. The scalability is
improved by more than one order of magnitude through the HPC-
friendly boundary conditions and IO strategies. This work describes
also the necessary nudging methods to drive the MHD model with
observed magnetic ﬁelds from the Sun’s photosphere. In addition,
we present the upper and lower atmospheric boundary conditions
(photospheric and towards the outer corona), including swamp lay-
ers to diminish perturbations before they reach the boundaries. Al-
together, these methods enable more realistic 3D MHD simulations
than previous models regarding the coronal heating problem above
an AR – simply because of the ability to use a large amount of
CPUs efﬁciently in parallel.

1.

Introduction

Cutting-edge science is often limited only by computational resources. More realistic
models come into reach with the continuously increasing computer power. One such
fundamental step towards better understanding the famous coronal heating problem and
plasma heating mechanisms was achieved with the work of Bourdin et al. (2013) and their
following publications. This step only became feasible, because the Pencil Code got ex-

CONTACT Philippe-A. Bourdin Philippe.Bourdin@oeaw.ac.at

TeX template ‘emulate/gGAF2e.cls’ c(cid:13) 2019 Philippe-A. Bourdin

 
 
 
 
 
 
2

PH.-A. BOURDIN

tended with some massive-parallel methods that enabled large-scale models to be run
within the time of a typical PhD contract. Otherwise, scaling to less processors, the main
simulation run described in Bourdin et al. (2013) would have taken about four years using
256 processors instead of about one year it took with 1024 processors.

The coronal heating mechanisms are unclear since many decades (Klimchuk 2006).
For a better understanding of the coronal heating, novel models need to be as realistic
as possible, so that the most relevant physical processes may be captured and analyzed
in a data post-processing step. It is currently not possible to use only observations for
that task, because some key quantities like the coronal 3D structure and amplitude of the
magnetic ﬁeld still remain inaccessible. Still, long-standing theories need to be veriﬁed,
like the entangling of magnetic ﬁeld lines in the corona through shufﬂing of footpoints
in the photosphere (Parker 1972). This could lead to so-called nanoﬂares that heat the
corona through small and short-lived magnetic reconnection events after the ﬁeld be-
came entangled in the corona (Parker 1988). Magneto-hydrodynamic (MHD) turbulence
and Alfv´en wave turbulence compete to explain the coronal heat input; see the results of
Rappazzo et al. (2007, 2008) versus results from van Ballegooijen et al. (2011, 2014). More
recent models may test these scenarios against a realistic coronal magnetic ﬁeld conﬁgu-
ration (Bourdin et al. 2016).

We complement the approach of Rempel (2012) that includes parts of the convection
zone below the photosphere to drive the magnetic ﬁeld. While Rempel (2017) uses more
advanced physics, our models are driven by actual photospheric observations and hence
are able to match observed structures in the corona directly. This work is a continuation
of Pencil Code models, like ﬁrst presented in Bingert et al. (2010) that led to a better un-
derstanding on why the cross-section of coronal loops appears as roughly constant (Peter
and Bingert 2012). Still, we do not know if such loops have a single- or multi-stranded
structure in their magnetic ﬁelds (Peter et al. 2013). Chen et al. (2014) use a convection
simulation with two emerging sunspots to drive a separate corona model. Peter et al.
(2015) review what MHD models can tell us on coronal heating mechanisms. For dif-
ferent phenomena, like type-II spicules or a more realistic chromosphere, other groups
include radiative transfer or ambipolar diffusion in their equation sets (Hansteen et al.
2010, Mart´ınez-Sykora et al. 2011, Wedemeyer-B¨ohm et al. 2012).

We note that the Alfv´en velocity is at least about one order of magnitude larger in the
corona than in the chromosphere, which suggests that any changes in the chromospheric
magnetic ﬁeld would almost instantly and quasi-statically change the coronal ﬁeld con-
ﬁguration (Bourdin et al. 2014, 2015). The ﬁeld may either reconnect and release magnetic
twist into the solar wind, the twisting magnetic perturbation may leave the corona before
a substantial twist is build up on “open” ﬁeld lines that connect to the heliosphere, or the
perturbation may cross the whole corona on closed loops and eventually twist the chro-
mospheric ﬁeld on the other end of the loop, where the Alfv´en velocity becomes lower
again. To address this topic, we need to know the coronal ﬁeld more precisely and we
may indeed track coronal ﬁeld lines from 3D MHD model data (Bourdin et al. 2018).

In order to obtain realistic coronal magnetic ﬁelds, we need to drive the MHD simula-
tion with observations of real solar magnetograms, e.g. of a full active region (AR) that fea-
tures some coronal EUV-bright loops that are known to be at least 1 MK hot. We cover an
AR with some surrounding quiet Sun (about 240×240 Mm2) with 1024×1024 grid points.
The vertical grid resolution varies form about 100 km for the photosphere and chromo-

GEOPHYSICAL & ASTROPHYSICAL FLUID DYNAMICS

3

sphere to about 800 km in the upper corona. Furthermore, the photospheric horizon-
tal shifting motions from granulation are required to ultimately test the ﬁeld-line braid-
ing mechanism. To this end, we implemented a photospheric granulation driver in the
solar corona module of the Pencil Code together with schemes for photospheric and
chromospheric nudging that always gently push the model towards the observed state in
the photosphere and that provide a lower solar atmosphere that adapts to pressure and
temperature stratiﬁcation changes in the corona. Our chromosphere acts here as a ﬂex-
ible lower boundary condition and as a reservoir for mass and internal energy, which is
also the case in reality, because the lower atmosphere hosts signiﬁcantly more mass than
the corona.

With a novel boundary condition for the photospheric magnetic ﬁeld we allow the
granulation driver to push the foot points of ﬁeld lines. This changes the horizontal com-
ponent of the magnetic ﬁeld already in the photosphere and in the grid cells above, which
is required to test the braiding mechanism proposed by Parker (1972). Therefore, we need
to extrapolate the magnetic ﬁeld to the interior of the Sun, in order to provide the required
ghost zones for the computation of numerical dervatives. Because the pressure increases
below the photosphere, magnetic ﬂux tubes shrink in their diameter with depth; see sec-
tion 2.4 for details.

In the following we describe the photospheric and chromospheric nudging, the granu-
lation driver, a new magnetic-ﬁeld extrapolation, as well as coronal boundary conditions.
Finally, we analyze the parallelization of the Fourier transform and the data access (IO)
routines.

2. Photospheric nudging

The photosphere is the lower boundary condition for our simulation domain. This re-
quires us to set the temperature T , the density ρ, and the vertical components of the
vector quantities that are perpendicular to this boundary, the vertical velocity uz and the
magnetic ﬁeld Bz. In the photosphere, the convective cells from below practically reach
the layer, where radiation efﬁciently cools the plasma. Hence, the advective heat transport
by convection ends and the vertical transport of hot plasma breaks into granules, where
the plasma motion has a horizontal component of some km/s at about 0.5 − 0.8 Mm
around the granule center (Ruiz Cobo et al. 1996). Once cooled, the now denser plasma
gets submerged below the surface due to gravity and will eventually be heated again to
complete the convection cycle.

In the same time, we know that plasma beta, the ratio between thermal and magnetic
pressure, is near or above unity at the photosphere, in average (Bourdin 2017). As a result,
the horizontal motions of breaking granules will advect the magnetic ﬁeld with them.
Many subsequently rising and decaying granules may push the ﬁeld lines even on spa-
tial scales larger than one single granule and in a random-walk fashion. Finally, magnetic
ﬂux bundles are rooted below the photosphere and constantly undergo a smooth global
reconﬁguration due to dynamo processes, which leads to horizontal motions of these
patches on spatial scales much larger than one granule, but typically with a signiﬁcantly
lower speed. To complete the spectrum of photospheric driving motions, we will need
to consistently combine both, small-scale granular motions and the large-scale magnetic
reconﬁguration in the photosphere.

4

PH.-A. BOURDIN

2.1. Magnetic ﬁeld

For the photospheric magnetic ﬁeld nudging we use actual observations of the Hinode
satellite, where the data from SOT/NFI (Solar Optical Telescope/Narrowband Filter Im-
ager) give us the line-of-sight (LOS) component of the magnetic ﬁeld in the photosphere
(Kosugi et al. 2007, Tsuneta et al. 2008); see gray-scale background in ﬁgure 1. The resolu-
tion of our LOS magnetograms is about 120 km per pixel. Magnetograms do not resemble
visible-light intensity observations (cf. Bourdin 2011) and hence we do neither directly
see the granules in such magnetograms nor could we derive the horizontal plasma mo-
tions. Even intensity maps of the photosphere from the same telescope would not resolve
a granule with more than a few pixels. Therefore, we can not recover the horizontal gran-
ular advection from Hinode data and have to ﬁnd another way to mimic realistic granula-
tion; see section 2.3.

The LOS magnetograms are uncalibrated and we use the smaller ﬁeld-of-view (FOV)
of the SOT/SP (Spectro-Polarimetric) instrument (Lites et al. 2013) that provides calibrated
vector magnetograms and co-align both, the LOS and SP data, while we reduce the reso-
lution of the LOS to the SP data. A pixel by pixel comparison allows us to ﬁnd the calibra-
tion factor for the full-FOV LOS magnetograms. For consitency, we also interpolate two
LOS magnetograms in time to match the exact SP observation time. Because both instru-
ment’s detectors have a slight rotation against each other, we split the common FOV in
about 8 × 8 subﬁelds and coaling them separately. These steps help to reduce the broad-
ness of the scatter in the distribution of the correlated data that we show in ﬁgure 2.

Figure 1. Hinode line-of-sight magnetogram (grayscale, saturated at ±300 G) with overlaid velocity
vectors (blue) obtained with a local correlation tracking. The observation was made near disc center
and is from 2007 November 14.

051015202530Solar-X [Mm]05101520Solar-Y [Mm]GEOPHYSICAL & ASTROPHYSICAL FLUID DYNAMICS

5

Figure 2. Distribution of co-aligned uncalibrated SOT/NFI and calibrated SOT/SP data. The red line rep-
resents a least-absolute-deviation (LAD) ﬁt with its uncertainty interval marked by dotted lines. Figure
taken from Bourdin (2014a); see Figure 2.4 on page 31.

The horizontal extent of our NFI FOV is about one seventh of the solar radius. We cor-
rect the LOS magnetograms for the surface curvature within the FOV of SOT/NFI by as-
suming that all strong ﬂux concentrations are mainly vertical, so that we may scale the
magnetic ﬁeld amplitude of both polarities with 1/ cos θ , where θ is the angle between
the LOS and the vertical direction. We now co-align the time series of magnetograms to
the one in middle of the time series so that we correct for spacecraft jitter and the rotating
Sun. Finally, we crop all images to their common FOV.

For each of the magnetograms we rescale both polarities separately and with a con-
stant factor to obtain ﬂux-balanced observations. This is required here to avoid an average
magnetic monopole that would force all of its ﬂux to leave through the upper boundary,
because the simulation domain is periodic in the horizontal directions. Also this avoids
unwanted effects from a time-varying total ﬂux that would have to propagate immedi-
ately through the whole domain because of our boundary conditions and hence disturb
the actual coronal magnetic ﬁeld in an unnatural way. In any case, the total magnetic ﬂux
of the whole Sun is always zero. Natural localized ﬂux imbalances on the real Sun cause
magnetic connectivity to remote regions, which we can not include in our model due to
the limited simulation domain size. The connectivity that we miss through our ﬂux bal-
ancing is minor and does not signiﬁcantly change the ﬁeld geometry in our model.

When we use a non-periodic magnetogram for a periodic simulation domain, we need
to overlap the boundaries of the magnetogram with a smooth transition at the borders of
the observable FOV. This makes the magnetograms periodic and we do not see artefacts
in our model if the overlap region is about 24 pixels or about 6 Mm wide.

-0.04-0.020.000.020.04Stokes V / Stokes I [-]-600-400-2000200400600Magnetic flux density [G]f=145946

PH.-A. BOURDIN

If we would now simply impose the obtained ﬂux-balanced time series of LOS magne-
tograms on our lower boundary for all times, the magnetic ﬁeld description would on one
hand be perfectly consistent with the observation. On the other hand, we would effec-
tively stop the granular driving to operate, because of two reasons: First, the granular mo-
tions are not directly recovered with LOS magnetograms. Second, our granulation driver
can practically never advect a magnetic ﬁeld line, because its original state would get re-
stored in the next iteration of the simulation. Therefore, we have to allow the granulation
to advect the ﬁeld lines and in the same time we have to carefully restore the observed
magnetic state. Luckily, small-scale granules live much shorter than the large-scale mag-
netic ﬁeld needs to change substantially. This allows us to apply two nudging processes on
different time scales, where we push the model into the targeted states by an exponential
decay with distinct characteristic half times for each process.

2.2. Local correlation tracking

Once we want to allow for time-varying magnetograms at the lower boundary, we need
to apply also horizontal plasma motions that are consistent with the displacement of the
observed magnetic patches. When plasma beta is around unity, the magnetic ﬁeld can be
shifted from plasma motions or the plasma can be dragged together with moving ﬁeld
lines. Both ways, the magnetic ﬁeld displacement and the plasma motion should be con-
sistent. Therefore, we deduce the horizontal motions of magnetic patches with a local-
correlation-tracking (LCT) method and obtain another lower-amplitude velocity ﬁeld on
spatial scales larger than granules. This LCT velocity ﬁeld we also need to apply in the
photosphere.

Even though we omit here electric ﬁelds that are in principle necessary to fulﬁll the
induction equation, the good match of the simulated AR corona with the observed one
(Bourdin et al. 2013) supports this simpliﬁcation. Still, the question remains how much
the coronal heat input may change if we include those omitted photospheric electric
ﬁelds.

In the ﬁrst step to obtain a velocity ﬁeld out of a magnetogram time series, we rebin
the data to the optical resolution, which means we bin a square of 2 × 2 pixels into one
simulation pixel of about 235 km side length. Then we compute the local cross-correlation
coefﬁcients of two consecutive frames of the time series, where we shift the frames to each
other by one pixel in each direction. Together with the original zero-shift correlation co-
efﬁcient this gives us ﬁve coefﬁcients, where we ﬁnd the sub-pixel shift vector as the local
maximum of a ﬁve-point Gaussian ﬁt along two spatial dimensions. We apply a Gaussian-
convolution ﬁlter to the obtained map of shift vectors to remove small-scale ﬂuctuations
that we are not interested in. Finally, we need to interpolate this vector ﬁeld at the actual
pixel positions of our simulation grid.

The resulting velocity ﬁeld from our LCT method is displayed as blue arrows in ﬁgure 1.
As we see, some magnetic patches are surrounded by a local velocity ﬁeld pointing in one
direction, where the strongest velocity is near the center of that patch; see black patch at
x = 25 Mm and y = 8 Mm in ﬁgure 1. The correlation decays with distance from the ﬂux
concentrations, which is expected because one can not deduce a horizontal velocity from
two consecutive insigniﬁcant ﬂux regions (gray background).

GEOPHYSICAL & ASTROPHYSICAL FLUID DYNAMICS

7

2.3. Granulation driver

To mimic the horizontal advecting motions of breaking granules in the photosphere we
use a constructed velocity ﬁeld that resembles granules with a diameter of 1.6 Mm. We
modify here a method described by Gudiksen and Nordlund (2005) that is based on a
weighted Voronoi tessellation driver (Schrijver et al. 1997). In contrast to Gudiksen and
Nordlund (2002) who use a random pattern for driving their simulation, we generate a
velocity ﬁeld that resembles solar granulation not only in a statistical sense. Around each
granule we deﬁne an additional radius of 0.24 Mm as a zone where inter-granular lanes
may form due to overlapping of the velocity ﬁelds from neighboring granules. The typical
lifetime of a granule is Tgran = 5 min. The amplitude of the typical velocity in the interior
of a granule we deﬁne as v0 = 1.028 km/s. The radial velocity within each granule must
of course be zero at the center, increases with distance from the center, until it decays
outside of the granule’s radius and within the inter-granular lane, which ranges from 0.8
to 1.04 Mm distance from the center. An example of a mainly radial velocity ﬁeld can be
seen near x = 6 and y = 8 Mm in ﬁgure 3.

We randomly ﬁll the simulation domain with granules, until there is no more available
space for new granules. No new granule is allowed to emerge within the inner radius of
0.64 Mm around any other granule’s center. A granule ceases to exist, when its velocity

Figure 3. Granulation driver velocity ﬁeld (grayscale, saturated black is 8 km/s) with overplotted velocity
vectors (red). One grayscale square represents one simulation pixel with a side length of 230 km.

0246810Solar-X [Mm]012345678Solar-Y [Mm]8

PH.-A. BOURDIN

amplitude v(t) drops below the threshold of vmin = 0.78 v0; see equation (2). The former
granule’s area then becomes immediately available for new granules.

To avoid that all granules emerge and decay always at the same time, we vary the aver-
age granular lifetime with normally distributed random values within ±10 % and deﬁne
this individual lifetime as T = Tgran ± 10 %. We also alter the typical granular velocity
amplitude in the same way for each granule as vmax = v0 ± 15 %. Accordingly, we change
the time when the maximum velocity amplitude shall be reached (tmax) to be earlier for
shorter lifetimes and later for longer lifetimes T as

tmax = T (cid:112)| log(vmin/vmax)|.

(1)

For a smooth emergence and decay of a granule, we multiply its velocity amplitude
with a life-cycle function that depends on the simulation time t and the time when the
granule was created t0:

(cid:34)

v(t) = vmax · exp

−

(cid:18)t − t0 − tmax
T

(cid:19)2(cid:35)

(2)

Now that we have ﬁlled our FOV with granules, in particular with overlapping areas
that have non-radial velocities, we may amplify the purely stochastic vorticity in our
two-dimensional horizontal-velocity ﬁeld vvvgran(rrr, t) at the position vector rrr. For that,
we Fourier-transform the velocity ﬁeld, extract its rotational part ˆvvvrot, and ﬁlter out large
wavenumbers with an exponential weighting factor

ˆvvv(cid:48)
rot(kkk, t) = ˆvvvrot(kkk, t) · exp

− (2|kkk|/kN)4(cid:105)
(cid:104)

,

(3)

where kkk is the in-plane wave vector and kN is the Nyquist frequency. We transform
ˆvvv(cid:48)
rot(kkk, t) back to real space vvv(cid:48)
rot(rrr, t), amplify it with a factor of frot, and add it back to
the initial granular ﬁeld. We choose frot = 5 so that the resulting velocity ﬁeld will have
ﬂows along the inter-granular lanes that reach realistic horizontal speeds of about 8 km/s,
which is similar to the observed inter-granular velocities; see saturated black color in ﬁg-
ure 3.

Finally, we correct the new velocity ﬁeld with enhanced vorticity vvvvor so that its root-

mean-squared velocity becomes identical to one of the initial granulation ﬁeld:

vvvvor = vvvgran + frot vvv(cid:48)
rot

vvv∗
gran = vvvvor ·

(cid:113)

(cid:104)vvvgran

2(cid:105)/(cid:104)vvvvor

2(cid:105)

(4)

We obtain a velocity ﬁeld with radial outﬂows that turn into tangential velocities. The
tangential ﬂows of neighboring granules may interfere and form inter-granular lanes with
larger velocities than the average speeds inside the granules; see around x = 3 and y =
4 Mm in ﬁgure 3 for an example.

For consistency with external velocity ﬁelds, like the LCT velocities derived from a mag-
netogram time series, all granule centers will be propagated in accordance with the pre-
existing velocity vector at each granule’s center. If no other velocity ﬁeld has been acti-
vated during the generation of the granular driving motions, the granule centers remain
where they emerge.

GEOPHYSICAL & ASTROPHYSICAL FLUID DYNAMICS

9

A common problem in massive-parallel simulations are boundary conditions that in-
volve only few processors (see section 5.1 for another example) because the boundary
processors then cause inactive delays on the non-boundary processors. The granulation
driver code in the Pencil Code is not scalable. Therefore, we improve the scalability of our
coronal model with a two-step scheme: First, we create the granulation in a 2D simu-
lation of the photosphere and write the generated velocity ﬁeld to an external ﬁle. This
step requires only few processors and may run with a substantially larger timestep than
the full coronal model because we need only one granulation snapshot about every 10
seconds and some timestep-critical methods (like the Spitzer heat conduction) are not
relevant here. Second, in the 3D coronal model we read the previously generated veloc-
ity ﬁeld, distribute this data to each of the photospheric boundary processors, and then
interpolate between the granulation snapshots in time. Because the timestep in the 3D
model is substantially lower than 10 seconds, we save many iterations of the granulation
driver code, because the changes therein are minimal. In addition, the time-interpolation
between two granulation snapshots can be scaled to all involved boundary processors,
because each processor already has all necessary data. Finally, a time-interpolation con-
sists of much less computations than one granulation driver iteration. This scheme re-
duces the waiting time of non-boundary processors to a minimum and hence makes the
coronal model better scalable.1

The photospheric velocity driver is of course not switched on immediately. If we would
do that, we would cause an instantaneous force acting on an equilibirum state. This
is equivalent to a very strong impulse that creates a shock front; see Figure 3 of Bour-
din (2014b). To avoid this switch-on effect, we smoothly ramp up the targeted veloc-
ity ﬁeld linearly within the ﬁrst minute of the simulation. In addition, the horizontal
bulk velocity uuuhor| j at the photospheric boundary and in the three ghost layers below (
j ∈ {0, −1, −2, −3}) is never directly imposed. We smoothly push the velocity to its target
value by an exponential decay that we implement by an additional term in the equation
of motion (shortened by ‘...’):

∂ uuuhor/∂t| j = ... − τu

(cid:16)

uuuhor| j − vvv∗

gran

(cid:17)

(5)

with the inverse decay half-time τu = 0.5 s−1.

ﬁgure 4 shows a direct comparison of LCT and granulation driver velocity histograms,
where we see that the LCT velocities have a peak below 0.1 km/s and hence smaller ampli-
tudes than the granulation driver that peaks around 2 km/s. We checked that most of the
driving power (Poynting ﬂux) stems from the granulation driver. The granular velocities
vary on much smaller spatial scales than the LCT velocities from the horizontal move-
ment of magnetic patches, as also becomes clear from a direct comparison of the axes in
ﬁgures 1 and 3.

1 The related parameters in the solar corona module are the logical ﬂag lgranulation to activate the gran-
ulation driver, lwrite driver to write the generated velocity ﬁeld to an external ﬁle, tau inv as the inverse
time scale for velodity-ﬁeld nudging, vorticity factor as the factor to increase the vorticity, and dt gran as
the update interval for the granules. The logical ﬂags luse vel field and luse mag vel field activate the
reading of external velocity ﬁelds.

10

PH.-A. BOURDIN

Figure 4. Histograms of LCT (blue) and granulation driver (red) velocities.

2.4. Magnetic-ﬁeld extrapolation

We use the vector potential AAA for our computation and the magnetic ﬁeld BBB is then only
a derived quantity that is always divergence free and is unique for any given gauge Φ0:

BBB = ∇ × (AAA + Φ0)

(6)

To prescribe the vertical magnetic ﬁeld Bz in the photosphere, while using the vector po-
tential AAA within our simulation, we need to set the two components Ax and Ay because

Bz =

∂ Ay
∂ x

−

∂ Ax
∂ y

.

(7)

Az may then be set according to a self-chosen gauge, here the Weyl gauge with Φ0 = 0.

In order to mimic the increase in atmospheric and magnetic pressure in the solar in-
terior below the photosphere, we use an inverted potential-ﬁeld extrapolation that con-
centrates any magnetic ﬂux bundles with depth, which leads to a reduction of the diam-
eter and an increase of the amplitude of those ﬂux bundles. Typically, the pressure scale
height below the photosphere is about 300 km. As we use three ghost layers below the
lower boundary with a grid distance of about ∆z = 100 km, we would have to double the
contrasts from the surface magnetograms observed at z(0) = 0 Mm. This is not possible
without introducing artifacts like wiggles and checker-board patterns in the ghost cells.
Therefore, we reduce the contrast increase in the lower ghost cells by a constant factor,
here to one ﬁfth, as if the pressure scale height would be about 1.5 Mm; see also Bourdin
et al. (2018) for a more mathematical description. Of course, this reduction introduces a

0246810velocity [km/s]10-610-510-410-310-210-1100probability densityLCT velocitiesgranulation driversum of bothGEOPHYSICAL & ASTROPHYSICAL FLUID DYNAMICS

11

Figure 5. In-plane magnetic ﬁeld lines (red) in a vertical cut through a strong ﬂux concentration in the
lower part of the model. The gray scale indicates the logarithmic density. The blue dashed line is the
actual physical boundary of the simulation domain at z = 0 Mm.

slight error in the horizontal ﬁeld components below the surface. But this error seems
acceptable, because signiﬁcant magnetic structures in the photosphere typically have a
horizontal diameter of well above 1 Mm and the ﬁeld therein is anyway mainly vertical for
strong ﬂux concentrations that ﬁnally may reach our model corona; see ﬁgure 5.

In principle, one could say that this description of the lower magnetic ﬁeld boundary
is similar to a strictly vertical ﬁeld boundary condition. We like to note this is not the case,
because we still allow for any amount of horizontal ﬁeld at the boundary and hence very
small near-surface closed ﬁeld lines may form; see red lines near x = 10 and 120 Mm
in ﬁgure 5, where at the latter position a ﬁeld line even gets horizontal below the actual
boundary. Such cases are rare, which supports our argument that the error is small when
enlarging the pressure scale height as described above, but this shows we do not enforce
a vertical ﬁeld in the photosphere and below.

Different and less complex boundary conditions for the magnetic ﬁeld may of course
exist. For example, we could enforce a vertical ﬁeld at the lower boundary. But when we
do that, many ﬁeld lines in the physical domain that are not strictly vertical, would have a
stronger kink near the boundary as with a more ﬂexible boundary condition. An enforced
vertical ﬁeld at the bottom will generate larger derivatives and hence artiﬁcial currents
near the photosphere for a multi-polar AR case. In comparison, the vertical-ﬁeld bound-
ary condition has about twice the current density, twice the maximum magnetic Reynolds
number, and about 40 % larger Lorenz forces than we ﬁnd with the more ﬂexible scheme
we use here at the bottom of the domain. This would then require us to double our mag-
netic diffusivity η in order to keep the magnetic Reynolds number under control. As a
consequence, the larger diffusivity leads to more slippage of the ﬁeld lines when we ad-
vect them with our observational driving — which means the driving looses much of its
effect. Therefore, currents at the bottom boundary are unwanted and we like to keep the
magnetic diffusivity minimal to get the model more realistic.

020406080100120140160Solar-X [Mm]0246Solar-Z [Mm]-15-14-13-12-11-10-9-8-7log() [g/cm3]12

PH.-A. BOURDIN

Previously, the Pencil Code had also a regular potential-ﬁeld extrapolation that relaxes
the ﬁelds to a force-free state outside the physical domain. This would mean to smear
out constrasts in the magnetic ﬁeld below the photosphere. For the top boundary this is
acceptable, because the ﬁeld is already quite force free, there. But below the photosphere,
the pressure increases and magnetic structures are not force free. If we would apply the
original potential-ﬁeld extrapolation, we again generate strong currents because the ﬁeld
will relax to a force-free state. This is a permanent process, because we constantly keep
on driving the ﬁeld away from that state. Therefore, our method with increasing magnetic
contrasts in the ghost cells below the bottom boundary is closer to reality than using the
regular potential-ﬁeld extrapolation.

At the top boundary, we may use the regular potential-ﬁeld extrapolation with con-
trasts that get smeared out exponentially with height, which is fairly realistic in the outer
corona.2

2.5. Atmospheric boundary condition

At the lower boundary and below (in the ghost layers) we prescribe the density accord-
ing to a smoothly combined proﬁle of the stellar interior and the solar atmosphere, as
given in Bourdin (2014b). We use a globally constant diffusivity of Dρ = 8 · 106 m2/s in
the mass density ρ, which is needed for the numerical stability in all independent MHD
variables. This results in a very small mass transport into the simulation box through the
lower boundary because the diffusion acts along the gradient that points upwards. Im-
plicitly, the thermal pressure increases in the upper layers. This pressure increase gets ex-
actly compensated by a hydrodynamic ﬂow equilibrium that requires a downwards bulk
plasma motion. Consequently, the photospheric density at the physical boundary layer
may vary slightly from the preset value. The closed z-boundary condition sets the vertical
bulk velocity uz = 0 at the lower physical boundary z(0). Hence, a mass inﬂow would
then accumulate. To compensate for continuous density changes due to the diffusion,
we have to constantly overwrite the density to its initial proﬁle at and below the photo-
sphere. The layers above the photosphere undergo the regular hydrodynamic settlement
of the atmospheric stratiﬁcation due to the gas pressure, mass ﬂows, and gravity.

We set the temperature boundary condition so that a consistent hydrostatic equilib-
rium is reached at the lower boundary. To achieve this, we recursively set the temperature
T | j in the three lower ghost layers j ∈ {−1, −2, −3} at the grid positions z( j) as:3

T | j = T | j+1

ρ| j+1
ρ| j

(cid:34)
− ∆z| j

exp

(cid:35)

,

cv
cp

g| j+1
T | j+1

(8)

where we use the identity cv = γ/(γ − 1) for an ideal gas and ∆z| j = z( j + 1) − z( j) > 0
for the bottom boundary. ρ| j is the density and g| j is the gravity constant at the grid
positions z( j).

An alternative, without prescribing the density to its initial value, is to maintain a zero
ﬁrst derivative of the temperature by a symmetric boundary condition and then adapt the

2 In the start.in conﬁguration ﬁle we set bcz to 'pfe' for the ﬁrst magnetic ﬁeld component. At the same
component’s position we also set fbcz bot only for the bottom boundary to 0.2 in order to limit the extrapolation
below the photosphere to one ﬁfth of the pressure scale height.

3 In the start.in conﬁguration ﬁle we set bcz to 'fg' for the density and to 'hse' for the temperature.

GEOPHYSICAL & ASTROPHYSICAL FLUID DYNAMICS

13

density according to a hydrostatic equilibrium. This has the advantages that, ﬁrst, there
is no heat ﬂow into or out of the simulation domain, and second, that the density may
deviate from its initial value and maintain a hydrostatic equilibrium at the boundary; see
section 4.1 for details.

3. Chromospheric nudging

Radiative losses act as an energy sink in the solar atmosphere (Cook et al. 1989). The
Spitzer heat conduction transports energy along the temperature gradient (Spitzer and
H¨arm 1953) and therefore provides an energy source in the chromosphere. Both together
may destabilize the chromosphere because once the heat conduction provides less en-
ergy, the radiative losses cool the plasma that hence becomes denser. Denser plasma is
a stronger source of radiation that cools the plasma further. This may form a run-away
effect, because there is no radiative source term in our model that would heat optically
thicker plasma through absorption.

Another run-away effect exists for an excess heat input that leads to an adiabatic ex-
pansion of some plasma which then looses its ability to radiate an excess of internal en-
ergy, because the radiative losses decrease for lower densities. Therefore, we need to sta-
bilize our model chromosphere with a so-called Newtonian cooling method, which re-
sembles the stabilizing effects of chromospheric radiative transfer at low computational
costs.

3.1. Newtonian cooling

Temperature ﬂuctuations in the lower solar atmosphere get smoothened out through the
radiative transfer that efﬁciently heats denser and optical thicker plasma, while it also
cools less dense plasma through reduced absorption and the continuous emission of pho-
tons (Spiegel 1957). Both stabilizing effects of a proper radiative transfer treatment in the
chromosphere can be achieved through a novel combined Newtonian cooling and chro-
mospheric nudging approach.

First, we gently push back the chromospheric temperature to its initial stratiﬁcation
T0(z) through an exponential decay. Second, we implement a cooling term that slowly
pushes the temperature to a target value T (cid:48)(ρ(rrr, t)) at the position rrr = (x, y, z) that we
take from the initial temperature stratiﬁcation T0(z(cid:48)) at the height z(cid:48) where the actual
density ρ(rrr, t) is equal to the initial density stratiﬁcation ρ0(z(cid:48)) = ρ(rrr, t). We ﬁnally obtain
the target temperature T ∗ for the nudging as:

T ∗(rrr, t) = (cid:112)T0(z)T (cid:48)(ρ(rrr, t))

(9)

Of course, we like to apply the Newtonian cooling only in the chromosphere, where
our model needs it, and not beyond. This we achieve by a cutoff mechanism with four
components: 1) we use a density-dependent cutoff that sets in when the density becomes
eight orders of natural-logarithmic magnitude smaller than the photospheric value, 2) we
smooth out this sharp cutoff boundary with a sine function over the last two orders in this
natural-logarithmic magnitude, 3) we enforce another cutoff that sets in above a height
of 3 Mm, and 4) we apply another smooth sine transition over the upper 0.3 Mm on this
height-dependant cutoff.

14

PH.-A. BOURDIN

Figure 6. Logarithmic temperature (color code) in the lower atmosphere for a vertical cut through a
strong ﬂux concentration together with the in-plane magnetic ﬁeld lines (white) at the same location as
in ﬁgure 5. The red-dashed line indicates the location of the photosphere.

We now add the nudging term to the energy balance (shortened by ‘...’):4

∂ T /∂t = ... + T exp

(cid:20)
−τt

(cid:18)

1 −

(cid:19)

T ∗
T

(cid:21)

cρ cz

(10)

with the inverse decay half-time τt = 0.5 s−1, cρ as the smooth density-dependent cutoff
function, and cz as the smooth height-dependent cutoff.

3.2. Compressible atmospheric column

The effect of the Newtonian cooling becomes visible in ﬁgure 6, where we see a relatively
constant chromospheric temperature is maintained during the simulation run and re-
mains similar to the initial condition below 3 Mm (black dotted). We indicate locations
with down arrows, where we ﬁnd that the atmospheric column gets compressed and
hence the temperature follows a similarly compressed stratiﬁcation. With time, this atmo-
spheric column compression will relax towards the initial state due to our combined New-
tonian nudging method; see section 3.1. This allows our model chromosphere to adapt to,
e.g., downﬂows from the corona and eventually relax back to the initial stratiﬁcation after
these downﬂows end.

At some locations we ﬁnd the atmospheric column rises quickly to coronal tempera-
tures above 3 Mm; see leftmost and rightmost down arrows in ﬁgure 6. In other regions,
the lower-coronal plasma remains relatively cool, typically above regions with more hor-
izontal ﬁeld; see at Solar-X from 60 to 95 Mm.

4 The related parameters in the solar corona module are the logical ﬂag lnc density depend to acti-
vate the density-dependent Newtonian cooling, nc tau as the inverse time scale necessary for the nudging
by an exponential decay, nc lnrho num magn as the number of natural-logarithmic magnitudes in density,
nc lnrho trans width deﬁning the smooth transition of the density-dependent cutoff, nc z max as the max-
imum height to apply the Newtonian cooling, and nc z trans width to deﬁne the smooth transition for the
height-dependent cutoff.

020406080100120140160Solar-X [Mm]0246Solar-Z [Mm]3.73.83.94.04.14.24.34.4log(T) [K]GEOPHYSICAL & ASTROPHYSICAL FLUID DYNAMICS

15

In the photosphere, we see that temperatures may be higher and lower, where the den-
sity is lower and higher, respectively. This anti-correlating behavior of temperature and
density could be due to some compressional heating from the granular horizontal advect-
ing motions; see the lower boundaries in ﬁgure 5 and ﬁgure 6 at z = 0 Mm (dashed lines).
Also these local changes in temperature will eventually relax to the initial photospheric
temperature due to the limited lifetime of granules and the Newtonian cooling.

We ﬁnd also that the height of the photospheric temperature minimum varies between
about 250 to 350 km due to our compressible atmospheric column at the lower boundary
of our simulation domain; see wavy black layer in the lower part of ﬁgure 6.

4. Upper coronal boundaries

On the upper end of the simulation domain, we prefer not to allow heat or plasma inﬂows
or outﬂows. The reason is that any inﬂow would be of undeﬁned velocity, temperature
and density. We would anyway not expect heat outﬂows, because the temperature gradi-
ent usually leads only to inﬂows of heat. At the same time, such inﬂows are unwanted,
because we like to learn about the intrinsic heating of the corona, independent of any
boundary condition.

If we allow for plasma outﬂows, this may lead to an unrealistic mass loss, because in
reality this outﬂowing plasma may well fall back to the Sun, later, due to gravity. Therefore,
we prefer to make the simulation domain large enough to capture all relevant plasma
ﬂows and to simply close the upper simulation boundary for any plasma and heat ﬂows.
For the magnetic ﬁeld, though, we like to allow for “open” ﬁeld lines instead of formu-
lating a boundary condition that either enforces vertical or horizontal ﬁelds at the top
boundary; as we describe in section 4.2 below.

4.1. Closed atmospheric boundary

Above the upper boundary at 156 Mm the coronal temperature in standard 1D atmo-
spheric stratiﬁcations would still rise (Bourdin 2014b). If we simply prescribe the temper-
ature in the upper ghost layers from such a stratiﬁcation, we would impose an unwanted
thermal energy inﬂow downwards into the physical box due to heat conduction along the
temperature gradient. Therefore, and in contrast to the lower atmospheric boundary in
the photosphere, we need to employ a different boundary condition at the upper coronal
boundary (in grid cell nz) that assures there is no heat inﬂow. We achieve this by forcing
the temperature gradient to be zero at the upper physical boundary ( z|nz = 156 Mm) with
a symmetric boundary condition for the three upper ghost cells j ∈ {1, 2, 3} at the grid
positions z|nz+ j as:

T |nz+ j = T |nz− j

(11)

Since the temperature near the boundary is almost uniform, also inclined ﬁeld lines see a
symmetric temperature stratiﬁcation.

We then need to set the density ρ|nz+ j again consistent with a hydrostatic equilibrium:

∂ p
∂ z

(cid:12)
(cid:12)
(cid:12)
(cid:12)nz+ j

= ρ|nz+ j g|nz+ j

(12)

16

PH.-A. BOURDIN

This leads us to an upper boundary condition for the density that would require a con-
stant temperature, constant gravity, and symmetric grid distances at the top:5

⇒ ρ|nz+ j = ρ|nz− j exp

−

(cid:20)

(cid:16)

1
γ

z|nz+ j − z|nz− j

(cid:21)

(cid:17) g|nz
T |nz

(13)

For a non-constant temperature, non-constant gravity, and arbitrary grid distances at

the boundary, the density in the ghost layers can be formulated in a recursive way as:

⇒ ρ|nz+ j = ρ|nz+ j−1 exp

−

(cid:34)

(cid:32)

1
2γ

∆(cid:48)z(cid:12)

(cid:12)nz+ j−1

g|nz+ j−1
T |nz+ j−1

+ ∆(cid:48)z(cid:12)

(cid:12)nz+ j

(cid:33)(cid:35)

g|nz+ j
T |nz+ j

,

(14)

where ∆(cid:48)z(cid:12)
to being equidistant near the boundary, we may simplify equation (14) to:6

(cid:12) j denotes the vertical extent of the grid cell at z( j). If the grid spacing is close

⇒ ρ|nz+ j = ρ|nz+ j−1 exp

−

(cid:34)

(cid:16)

1
γ

z|nz+ j − z|nz+ j−1

(cid:17) g|nz+ j + g|nz+ j−1
T |nz+ j + T |nz+ j−1

(cid:35)

.

(15)

4.2. Potential-ﬁeld extrapolation

When the simulation domain is large enough, the magnetic ﬁeld near the top boundary
should have reached a nearly potential state. We may then use a purely potential ﬁeld in
the three ghost layers above the domain as boundary condition for the magnetic ﬁeld.
Because the ﬁeld vectors above and below the upper boundary are not perfectly rota-
tion free, we still obtain some currents at the physical boundary, which represent the re-
laxation from a nearly to a fully potential state. If these currents are strong, they might
artiﬁcially heat the corona. To counter this effect, we employ an additional magnetic dif-
fusivity below the boundary to smoothen the transition to the potential state and reduce
these artiﬁcial currents, as we describe in section 4.3.1 below.

For the potential-ﬁeld extrapolation into the ghost layers, we Fourier-transform the
magnetic vector potential AAA, extrapolate it by smoothing out contrasts, and then trans-
form it back:

(cid:12)
(cid:12)
(cid:98)AAA(kx, ky, t)
(cid:12)nz

(cid:90)

=

AAA(x, y, t)|nz eikkk·rrr d2rrr ,

(16)

where the vector rrr = (x, y) lies in the horizontal plane and kkk = (kx, ky) denotes the hor-
izontal wave vector. We extrapolate from the location of the physical boundary z(nz) to
the coordinates z(nz + j) of the three ghost layers j ∈ {1, 2, 3} with:7

(cid:12)
(cid:12)
(cid:98)AAA(kx, ky, t)
(cid:12)nz+ j

(cid:12)
(cid:12)
= (cid:98)AAA(kx, ky, t)
(cid:12)nz

exp

(cid:104)
−|kkk| ∆(cid:48)(cid:48)z(cid:12)

(cid:12)nz+ j

(cid:105)

(17)

We denote here the distance between the physical boundary and the extrapolated layer as
∆(cid:48)(cid:48)z(cid:12)
(cid:12)nz+ j = z(nz+ j)−z(nz) > 0. The normalized Fourier back transform of (cid:98)AAA ﬁnally gives

5 In the run.in conﬁguration ﬁle we set bcz to 'hs' for the density and to 's' for the temperature.
6 For non-constant gravity in the ﬁle run.in we set bcz to 'hse' for the density and to 's' for the temperature.
7 In the run.in conﬁguration ﬁle we set bcz to 'pfe' for the ﬁrst magnetic ﬁeld component, which also sets the

other two components accordingly.

us the vector potential AAA in the upper three ghost layers. Because ∆(cid:48)(cid:48)z(cid:12)
the upper boundary, we smear out any contrasts in AAA with increasing height.

(cid:12)nz+ j is positive on

GEOPHYSICAL & ASTROPHYSICAL FLUID DYNAMICS

17

4.3. Diffusive swamp region

The potential-ﬁeld extrapolation relaxes the magnetic ﬁeld very quickly into a force-free
state and hence strong currents may emerge at the upper physical boundary. Also a strong
heat transport towards the upper simulation domain may become problematic, because
the upper boundary is closed for heat ﬂows and we may accumulate very high tempera-
tures that become numerically demanding in the low-density plasma of the outer corona,
where this plasma can not radiate an excess of internal energy. To circumvent both prob-
lems, we use an additional diffusivity for the magnetic ﬁeld and for the heat conduction
below the physical boundary by implementing a so-called swamp region.

The swamp diffusivities act only in the upper part of the simulation domain to re-
duce the artiﬁcial effects on the upper boundary. We achieve a smooth transition by a
height-dependent weighting function w(z) that smoothly goes from 0 below to 1 within
the swamp region. For this transition we use a cubic step function that starts at height
zs and ends at zt . The swamp region is fully active above zt so that w(z ≤ zs) = 0 and
w(z ≥ zt) = 1 with zero ﬁrst derivatives at the edges of the transition function w(z).8

4.3.1. Magnetic diffusivity
To diffuse out currents near the upper end of the simulation domain, we implement an
additional isotropic magnetic diffusivity within the swamp region. This swamp diffusivity
is of course omitted in the energy balance in order not to heat the corona artiﬁcially. We
multiply the weighting function w(z) to the constant swamp diffusivity ηs and obtain the
height-dependent magnetic swamp diffusivity ηs(z) = ηs w(z). Now we add the magnetic
swamp diffusion term to the induction equation (shortened by ‘...’):9

∂ AAA
∂t

= ... + ηs(z) ∆AAA + eeez

∂ ηs(z)
∂ z

∇·AAA

(18)

In the case of Bourdin et al. (2013) the simulation domain was large enough, so that
currents at the top boundary were not problematic and hence no magnetic swamp diffu-
sivity was used there.

4.3.2. Heat conduction
Similar to the magnetic swamp diffusivity (see above), we implement also a diffusivity that
acts on the temperature as a constant, uniform, and isotropic heat conduction. For that,
we add another term to the energy balance (shortened by ‘...’) and use χs as the swamp
heat diffusivity constant:10

∂ T
∂t

= ... + χs w(z) ∆T

(19)

8 In the run.in conﬁguration ﬁle the parameters swamp fade start and swamp fade end deﬁne the height of

the smooth transition to the swamp region.

9 In the run.in conﬁguration ﬁle one may activate the magnetic swamp diffusivity by setting swamp eta to a value

larger than zero and similar to the parameter eta.

10 In the run.in conﬁguration ﬁle we set the parameter swamp chi larger than zero to activate the heat swamp

diffusion.

18

PH.-A. BOURDIN

Again, the height-dependent function w(z) provides a smooth transition between the
physical regime and the swamp region.

We like note that χs acts either on the temperature T , the natural-logarithmic tem-
perature ln T , or the entropy ε, depending on which quantity is active in the simulation
setup. Therefore, the physical unit of χs is not identical across these cases and may be
different from the units of χ used for the regular global isotropic heat conduction χ ∆T .

4.3.3. Mass diffusion
Similar as for the heat conduction, we implement another swamp region that acts on the
density with a diffusive term added to the continuity equation (shortened by ‘...’):11

Dρ
Dt

= ... + χρ w(z) ∆ρ

(20)

Like for equation (19) we use the same diffusivity parameter χρ with different physical
units for either the density or the natural-logarithmic density, depending on what quan-
tity is used for the simulation.

5. Massive-parallel methods

For high-performance computing applications it is crucial to reduce all computations
that are serialized or restricted to few processors. The parallelization of such computa-
tions therefore helps to scale an application efﬁciently to substantially more processors.
In the following sections we describe some massive-parallel methods introduced to the
Pencil Code in the years from 2009 to 2013.

One bottleneck in massive parallelization for simulation runs like described in Bourdin
et al. (2013) is the potential-ﬁeld boundary condition that uses a Fast Fourier Transform
(FFT), as well as the massive-parallel ﬁle input and output described in section 5.2.

5.1. Fast Fourier Transform

Some boundary conditions, like a potential-ﬁeld extrapolation, need to compute the FFT
along both horizontal directions. This requires to collect once all data along x and then
once along y. Less parallelized FFT routines collect all data on one processor, perform the
FFT, and then distribute the transformed data back to all processors. During the compu-
tationally expensive communication and computation, a large number of processors are
idle and their potential resources remain unused.

A more efﬁcient method is to collect all data along the one direction which the FFT ac-
tually needs and to split the domain along the other direction; see the remapping scheme
presented in ﬁgure 7. As a result, all processors in one (x, y)-layer may contribute in paral-
lel to the computation of the FFT along one direction. Furthermore, the remapping of the
data can be done in a parallel way, so that all communication ﬁnishes after only two com-
munication cycles: one send and one receive operation. The trick is to let one half of the
processors send ﬁrst and then receive, while the other half ﬁrst receive and then send their
local data portion. This is actually faster than to collect all data on one processor, because

11 We activate the density swamp region via the swamp diffrho parameter in the run.in conﬁguration ﬁle.

GEOPHYSICAL & ASTROPHYSICAL FLUID DYNAMICS

19

Figure 7. Data remapping strategy for the parallel FFTs in the module ‘fourier fftpack’.

this can only be done in a sequential way and requires signiﬁcantly more communication
cycles for a large number of processors. The same holds true for the remapping back to
the original subdomains.

The required transpose operation of the remapped data during a two-dimensional
FFT needs more communication cycles, namely as many as the number of subdomains
along the x-direction. Still, this number is typically less than the number of processors
in one (x, y)-layer and the transpose can be parallelized between the processors in the
y-direction.

Due to the participation of many processors in the FFT, the whole computation, in-
cluding the multiple data remappings, is faster than the original scheme of the FFT for
only one processor. When the domain is not split into subdomains along x, both schemes
are of course similar, but this is usually not the case for large simulation runs with many
processors.

5.2.

Input/Output

One challenge for large-scale simulation runs is the input and output (IO) of data snap-
shots, as well as their storage requirements. With clever IO strategies one can not only
perform IO operations faster, but also save signiﬁcant amounts of storage space.

Traditionally, the Pencil Code stores data snapshots in a ‘distributed’ manner, where
each processor writes one ﬁle with its local subdomain portion of the data, like imple-
mented in the ‘io dist’ module. This strategy has the advantage that the writing can
be done fully in parallel, but at the cost of writing all inner ghost layers between any neigh-
boring processors, which contains overlapping and identical data. The smaller the sub-
domains get and the more processors we like to use in order to boost the computation
speed, the larger is the amount of unneeded data that this distributed method requires to
store. Also a fully distributed IO method will cause problems on any ﬁle system, because
these are not made for thousands or more simultaneous IO requests.

In a ﬁrst step, one might try to collect all data on one processor and write it out into
one monolithic snapshot ﬁle. This strategy we call ‘collective’ and it is implemented in
the ‘io collect’ module. It turns out this method is not optimal regarding the IO
speed, because one processor alone can only access a data snapshot in a sequential way.
Nonetheless, we may omit to store all inner ghost cells; see the scheme displayed in ﬁg-
ure 8.

The next step of improving the IO lies in combining the distributed with the collective
strategy. This we implement as the ‘io collect xy’ module, where all data is ﬁrstly
collected in along (x, y)-layers by the leading processor in this layer and secondly writ-

20

PH.-A. BOURDIN

Figure 8. Reduction of required data space for monolithic ﬁles in an extreme case, where the needed
outer ghosts are colored in green and the physical domain is blue. The redundant inner ghost cells (see
numbers) being saved with the distributed ‘io dist’ IO module in the Pencil Code are highlighted
in red. Black lines depict the data boundaries for each ﬁle. There number of ghost layers is 2 for this
example.

Figure 9. Collective IO strategy of the module ‘collect xy’, where data is collected in subdomain
layers along (x, y) and is written to multiple ﬁles by the collecting (here rightmost) processors in each
(x, y)-plane. The vertical separation of the layers depicts the z-direction in the simulation domain.

ten by all (x, y)-leading processors in parallel; see ﬁgure 9. The reading access works in
the same way: the (x, y)-leading processors read in parallel and then distribute the data
within their layer. For this improvement one has to take the disadvantage of storing the
inner ghost cells between all (x, y)-layers, which is still signiﬁcantly less than storing all
inner ghost cells. Hence, this advanced method has substantial potential to accelerate the
IO by some parallelization.

Most modern IO methods usually use an intermediate software layers to optimize the
number of parallel IO requests and to write out monolithic ﬁles that do not need to store
any inner ghost cells at all. Such ﬁle formats therefore have the potential to save a sub-
stantial amount of storage space. In the Pencil Code we now provide two IO modules:
‘io mpi2’ that relies on the MPI-2 standard and ‘io hdf5’ that uses the parallel HDF5
software library for IO operations. Both use monolithic ﬁle formats and hence are opti-
mal regarding the data storage requirements. In the same time, their IO routines are also
optimized for scalability and speed; see comparison in table 1.

143213241324GEOPHYSICAL & ASTROPHYSICAL FLUID DYNAMICS

21

Table 1. Properties of the different IO strategies in Pencil Code for writing a
full data snapshot.

module

distributed
collect
collect xy
mpi2
hdf5

time

2 s
70 s
10 s
8 s
9 s

storage

notes

+31 %
min.
+16 %
min.
min.

not scalable above 256 CPUs
one IO node collects globally
one IO node per (x, y)-layer
binary IO hidden in MPI2
portable, extendable structure

5.3. HDF5 ﬁle format

The Pencil Code is now capable of storing monolithic data snapshots with minimal stor-
age requirements in the HDF5 format. Snapshot ﬁles (that were previously in a raw bi-
nary format) are now stored in the self-explanatory HDF5 format with an extendable data
structure. All HDF5 ﬁles carry the ﬁlename sufﬁx ‘.h5’ instead of the binary ‘.dat’ ﬁle
extension.

Once a user switches to the HDF5 ﬁle format, the build process (pc build or make)
tries to automatically ﬁnd the HDF5 libaray and uses the location where the Fortran com-
piler wrapper is present.12 For that, the ‘$PATH’ environment variable must point to one
of those compiler wrappers (h5pfc or h5fc). Otherwise, no conﬁguration by the user is
required. In a computing center, this usually requires to load an environment module
with the command ‘module load ...hdf5...’, where all available modules can be
listed with ‘module avail’.

The classical snapshot ﬁles like var.h5 do now contain the grid positions, dimensions
of the setup, as well as some basic simulation settings in a separate data structure. This
additional information can be suppressed to save storage space when a large number of
small data snapshots is generated; set lomit add data=T within the section run pars
inside the run.in conﬁguration ﬁle. The main simulation data is written out in compo-
nents, like ux, uy, uz, lnrho or rho, etc. Unused components are of course not written.
Inner ghost layers are cut for all quantities that are deﬁned on grid cells. The HDF5 snap-
shots are hence always monolithic and are stored in the directory data/allprocs.

A typical example of the content of a var.h5 snapshot can be visualized with
the tool ‘hdfview’; see ﬁgure 10. The datasets (like ux) are listed in groups (like
data or settings) that can be opened and closed by a double mouseclick. Some
fundamental parameters of the simulation can be contained in snapshot ﬁles, e.g.
settings/precison holds either an ‘S’ for single or a ‘D’ for double precision. The
time of the snapshot is stored as a separate scalar double-precision dataset named time.
Datasets can also be multi-dimensional arrays and the order of these arrays is in the
canonical Fortran way, which means the ﬁrst dimension of the array is along the z-
direction. This implies that one has to transpose multi-dimensional data arrays for post-
processing with languages like C or Julia/Python, while the datasets are naturally
aligned for languages like Fortran or IDL.

12 We switch to the HDF5 format by setting IO = io hdf5 and HDF5 IO = hdf5 io parallel in
src/Makefile.local. On a standard ubuntu 18.04 LTS system, one needs to install
the package
‘libhdf5-openmpi-dev’. The packages ‘hdf5-tools’ and ‘hdfview’ contain optional tools for inspect-
ing and modifying HDF5 ﬁles.

22

PH.-A. BOURDIN

Figure 10. Example content of a ‘var.h5’ ﬁle, here from the corona sample. The conversion factor
from code units to physical units is 10−8 for the density. This sample stores the logarithmic density
lnrho as three-dimensional data array, together with the logarithmic temperature lnTT, and all com-
ponents of the vector potential and velocity ﬁeld. The time of the snapshot is given as a scalar. The
settings and grid are optional and are stored in each snapshot by default.

The so-called persistent data (that is usually associated per processor) is written to
global arrays of the size (nprocx,nprocy,nprocz), where nprocx means the number of
processors along the x-direction. Particle data gets collected from all processors and is
stored in global arrays together with the information of the mapping of particles to the
processors.

In addition to the snapshots, the module ‘io hdf5’ generates also a grid ﬁle
data/grid.h5 that contains the global grid data, as well as some fundamental parame-
ters, like the size of the simulation domain, the number of grid points, grid distances, etc.;
see ﬁgure 11.

For inspecting HDF5 ﬁles from a text-based command line, one can use the ‘h5dump’
command. The optional parameter ‘-H’ allows to see the ﬁle structure (groups and
datasets) without printing the actual data.

In table 1 we compare the advantages and disadvantages of each IO method available
in the Pencil Code for a setup with 1024 × 1024 × 256 grid cells distributed on 8 × 16 ×
8 = 1024 processors. One monolithic snapshot has a size of 17 GB and the timings were
obtained on the JuRoPA supercomputer with the Lustre ﬁlesystem in a version from 2012.
Red entries in table 1 highlight the disadvantages. Please note these timings are hardly
comparable with nowadays supercomputers, because the JuRoPA hardware and storage
system are outdated and had beed decomissioned several years ago.

GEOPHYSICAL & ASTROPHYSICAL FLUID DYNAMICS

23

Figure 11. Content of the ﬁle ‘grid.h5’ from the corona sample, where we use a non-equidistant
grid in the z-direction. The unit length is 107 in SI units and we use double precision for ﬂoating-point
numbers. The array dz 1 contains the inverse grid spacing along the z-direction and the scalar dz gives
the average grid spacing.

6. Conclusions

We use small-scale granulation and large-scale magnetic patches to drive a corona model
by magnetic observations of an active region. The combination of both horizontal-
velocity ﬁelds extends the spectrum of driving velocities to cover a large range in am-
plitues and in spatial length scales; see ﬁgure 4. An adaptice atmospheric boundary con-
dition together with an adaptive chromospheric Newton cooling allows to formulate a
ﬂexible lower-boundary condition for the coronal part of the model. The varying mag-
netic pressure around strong polarities or the granulation driver may increase the plasma
density in the intergranular lanes. This changes the density in the lower atmosphere and
requires a matching response in from Newton cooling term. The new Newton cooling
scheme implemented in the Pencil Code allows for expanding and shrinking atmospheric
columns at the lower boundary, so that the temperature stratiﬁcation is now adaptive.

For the upper boundary we have developed several mechanisms to diffuse away per-
turbations in the density and temperature. A new swamp-diffusion region can be used to
relax non-force-free magnetic ﬁelds in order to reduce strong currents at the upper phys-
ical boundary, where “open” magnetic ﬁelds are desired but are in a force-free state.

24

PH.-A. BOURDIN

Figure 12. Comparison of the hard scaling before (triangles) and after (circles) the implementation of a
massive-parallel FFT in the Pencil Code versus the theoretical scaling limit (dashed red line).

The IO strategy is crucial for large-scale models in nowadays science where large
amounts of data are generated. We ﬁnd that only the modules ‘io mpi2’ and ‘io hdf5’
are optimal regarding storage requirements and scalability. Of these two, only ‘io hdf5’
offers a transparent, portable, and extendable data structure that allows to change the
ﬁle formats without loosing backwards compatibility for the main code and for any data
analysis scripts. Furthermore, almost all modern data analysis languages provide at least
reading routines for the HDF5 ﬁle format.

Boundary conditions that make use of a FFT, like a potential-ﬁeld extrapolation, bene-
ﬁt from massive-parallel FFT implementation, like the routine ‘fft xy parallel’ pro-
vided in the ‘fourier fftpack’ module. The scalability of such boundary conditions
is signiﬁcantly improved as compared to the original ‘fourier transform’ set of rou-
tines.

Altogether, the scalability of the Pencil Code could be improved substantially with
massive-parallel methods that we implemented for the IO modules and for the FFT used
by the potential-ﬁeld boundary condition 'pfe'. We show a comparison plot for the total
runtime in ﬁgure 12 that we obtained with a constant global number of grid cells but for
an increasing number of processors, which is usually called a ‘hard scaling’ test.

The advantages of the HDF5 ﬁle format become clear from the comparison in table 1.
We recommend to concentrate future developments of IO routines on the ‘io hdf5’
module and to fade out support for older IO modules during the next years.

6412825651210241632Number of cores0,0010,010,1CPU time / timestep / meshpoint [µs]Ideal scalingOriginal versionAfter optimizationREFERENCES

25

Acknowledgements

The results of this research have been achieved using the PRACE Research Infrastructure resource
Curie based in France at TGCC, as well as JuRoPA hosted by the J ¨ulich Supercomputing Centre in
Germany. Hinode is a Japanese mission developed, launched, and operated by ISAS/JAXA, in part-
nership with NAOJ, NASA, and STFC (UK). Additional operational support is provided by ESA and
NSC (Norway).

Disclosure statement

No potential conﬂict of interest was reported by the authors.

ORCID

Philippe-A. Bourdin

https://orcid.org/0000-0002-6793-601X

References

Bingert, S., Zacharias, P., Peter, H. and Gudiksen, B., On the nature of coronal loops above the quiet

sun network. Adv. in Space Res., 2010, 45, 310–313, DOI: 10.1016/j.asr.2009.08.020.

Bourdin, P.A., Denoising observational data. Contr. Astron. Obs. Skalnate Pleso, 2011, 41, 149–155.
Bourdin, P.A., Observationally driven 3D MHD model of the solar corona above a magnetically active
region, 2014a (uni-edition GmbH., Berlin), ISBN: 978-3-944072-03-6, DOI: 11858/00-1735-0000-
0022-5F1B-D.

Bourdin, P.A., Standard 1D solar atmosphere as initial condition for MHD simulations and switch-on

effects. Cent. Eur. Astrophys. Bull., 2014b, 38, 1–10.

Bourdin, P.A., Plasma Beta Stratiﬁcation in the Solar Atmosphere: A Possible Explanation for the

Penumbra Formation. ApJL, 2017, 850, L29 (5pp), DOI: 10.3847/2041-8213/aa9988.

Bourdin, P.A., Bingert, S. and Peter, H., Observationally driven 3D MHD model of the solar corona

above an active region. A&A, 2013, 555, A123, DOI: 10.1051/0004-6361/201321185.

Bourdin, P.A., Bingert, S. and Peter, H., Coronal loops above an Active Region: Observation versus

model. PASJ, 2014, 66, 1–8, DOI: 10.1093/pasj/psu123.

Bourdin, P.A., Bingert, S. and Peter, H., Coronal energy input and dissipation in a solar Active Region

3D MHD model. A&A, 2015, 580, A72, DOI: 10.1051/0004-6361/201525839.

Bourdin, P.A., Bingert, S. and Peter, H., Scaling laws of coronal loops compared to a 3D MHD model

of an active region. A&A, 2016, 589, A86, DOI: 10.1051/0004-6361/201525840.

Bourdin, P.A., Singh, N. and Brandenburg, A., Magnetic Helicity Reversal in the Corona at Small

Plasma Beta. ApJ, 2018, 869, 2, DOI: 10.3847/1538-4357/aae97a.

Chen, F., Peter, H., Bingert, S. and Cheung, M.C.M., A model for the formation of the active
region corona driven by magnetic ﬂux emergence. A&A, 2014, 564, A12, DOI: 10.1051/0004-
6361/201322859.

Cook, J.W., Cheng, C.C., Jacobs, V.L. and Antiochos, S.K., Effect of coronal elemental abundances on

the radiative loss function. ApJ, 1989, 338, 1176–1183, DOI: 10.1086/167268.

Gudiksen, B. and Nordlund, ˚A., Bulk heating and slender magnetic loops in the solar corona. ApJL,

2002, 572, L113–116, DOI: 10.1086/341600.

Gudiksen, B. and Nordlund, ˚A., An ab initio approach to the solar coronal heating problem. ApJ, 2005,

618, 1020–1030, DOI: 10.1086/426063.

Hansteen, V.H., Hara, H., Pontieu, B.D. and Carlsson, M., On Redshifts and Blueshifts in the Transition

Region and Corona. ApJ, 2010, 718, 1070–1078, DOI: 10.1088/0004-637X/718/2/1070.

Klimchuk,

J.A., On Solving the Coronal Heating Problem. Sol. Phys., 2006, 234, 41–77,

DOI: 10.1007/s11207-006-0055-z.

Kosugi, T., Matsuzaki, K., Sakao, T., Shimizu, T., Sone, Y., Tachikawa, S., Hashimoto, T., Minesugi, K.,
Ohnishi, A., Yamada, T., Tsuneta, S., Hara, H., Ichimoto, K., Suematsu, Y., Shimojo, M., Watan-
abe, T., Shimada, S., Davis, J.M., Hill, L.D., Owens, J.K., Title, A.M., Culhane, J.L., Harra, L.K.,

26

REFERENCES

Doschek, G.A. and Golub, L., The Hinode (Solar-B) Mission: An Overview. Sol. Phys., 2007, 243,
3–17, DOI: 10.1007/s11207-007-9014-6.

Lites, B.W., Akin, D.L., Card, G., Cruz, T., Duncan, D.W., Edwards, C.G., Elmore, D.F., Hoffmann, C.,
Katsukawa, Y., Katz, N., Kubo, M., Ichimoto, K., Shimizu, T., Shine, R.A., Streander, K.V., Suematsu,
A., Tarbell, T.D., Title, A.M. and Tsuneta, S., The Hinode Spectro-Polarimeter. Sol. Phys., 2013, 283,
579–599, DOI: 10.1007/s11207-012-0206-3.

Mart´ınez-Sykora, J., Hansteen, V. and Moreno-Insertis, F., On the Origin of the Type II Spicules: Dy-
namic Three-dimensional MHD Simulations. ApJ, 2011, 736, 9, DOI: 10.1088/0004-637X/736/1/9.
Parker, E.N., Topological Dissipation and the Small-Scale Fields in Turbulent Gases. ApJ, 1972, 174,

499–510, DOI: 10.1086/151512.

Parker, E.N., Nanoﬂares and the solar X-ray corona. ApJ, 1988, 330, 474–479, DOI: 10.1086/166485.
Peter, H. and Bingert, S., Constant cross section of loops in the solar corona. A&A, 2012, 548, A1,

DOI: 10.1051/0004-6361/201219473.

Peter, H., Bingert, S., Klimchuk, J.A., de Forest, C., Cirtain, J.W., Golub, L., Winebarger, A.R., Kobayashi,
K. and Korreck, K.E., Structure of solar coronal loops: from miniature to large-scale. A&A, 2013, 556,
A104, DOI: 10.1051/0004-6361/201321826.

Peter, H., Warnecke, J., Chitta, L.P. and Cameron, R.H., Limitations of force-free magnetic ﬁeld extrap-
olations: Revisiting basic assumptions. A&A, 2015, 584, A68, DOI: 10.1051/0004-6361/201527057.
Rappazzo, A.F., Velli, M., Einaudi, G. and Dahlburg, R.B., Coronal Heating, Weak MHD Turbulence,

and Scaling Laws. ApJL, 2007, 657, L47–L51, DOI: 10.1086/512975.

Rappazzo, A.F., Velli, M., Einaudi, G. and Dahlburg, R.B., Nonlinear Dynamics of the Parker Scenario

for Coronal Heating. ApJ, 2008, 677, 1348–1366, DOI: 10.1086/528786.

Rempel, M., Numerical Sunspot Models: Robustness of Photospheric Velocity and Magnetic Field

Structure. ApJ, 2012, 750, 62, DOI: 10.1088/0004-637X/750/1/62.

Rempel, M., Extension of the MURaM Radiative MHD Code for Coronal Simulations. ApJ, 2017, 834,

10, DOI: 10.3847/1538-4357/834/1/10.

Ruiz Cobo, B., del Toro Iniesta, J.C., Rodriguez Hidalgo, I., Collados, M. and Sanchez Almeida, J., Em-
pirical model of an average solar granule; in Cool Stars, Stellar Systems, and the Sun, edited by
R. Pallavicini and A.K. Dupree, Vol. 109 of Astronomical Society of the Paciﬁc Conference Series, Jan.,
1996, p. 155.

Schrijver, C.J., Hagenaar, H.J. and Title, A.M., On the patterns of the solar granulation and supergran-

ulation. ApJ, 1997, 475, 328–337, DOI: 10.1086/303528.

Spiegel, E.A., The Smoothing of Temperature Fluctuations by Radiative Transfer. ApJ, 1957, 126, 202,

DOI: 10.1086/146386.

Spitzer, L. and H¨arm, R., Transport phenomena in a completely ionized gas. Phys. Rev., 1953, 89, 977–

981, DOI: 10.1103/PhysRev.89.977.

Tsuneta, S., Ichimoto, K., Katsukawa, Y., Nagata, S., Otsubo, M., Shimizu, T., Suematsu, Y., Nakagiri,
M., Noguchi, M., Tarbell, T., Title, A., Shine, R., Rosenberg, W., Hoffmann, C., Jurcevich, B., Kushner,
G., Levay, M., Lites, B., Elmore, D., Matsushita, T., Kawaguchi, N., Saito, H., Mikami, I., Hill, L.D. and
Owens, J.K., The Solar Optical Telescope for the Hinode Mission: An Overview. Sol. Phys., 2008, 249,
167–196, DOI: 10.1007/s11207-008-9174-z.

van Ballegooijen, A.A., Asgari-Targhi, M. and Berger, M.A., On the Relationship Between Photo-
spheric Footpoint Motions and Coronal Heating in Solar Active Regions. ApJ, 2014, 787, 87,
DOI: 10.1088/0004-637X/787/1/87.

van Ballegooijen, A.A., Asgari-Targhi, M., Cranmer, S.R. and DeLuca, E.E., Heating of the Solar
Chromosphere and Corona by Alfv´en Wave Turbulence. ApJ, 2011, 736, 3, DOI: 10.1088/0004-
637X/736/1/3.

Wedemeyer-B¨ohm, S., Scullion, E., Steiner, O., Rouppe van der Voort, L., de La Cruz Rodriguez, J.,
Fedun, V. and Erd´elyi, R., Magnetic tornadoes as energy channels into the solar corona. Nature,
2012, 486, 505–508, DOI: 10.1038/nature11202.

