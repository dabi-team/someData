Augmented Reality-Based Advanced Driver-Assistance System for
Connected Vehicles

Ziran Wang∗, Kyungtae Han, and Prashant Tiwari
Toyota Motor North America R&D, InfoTech Labs, Mountain View, CA, USA
{ziran.wang, kyungtae.han, prashant.tiwari}@toyota.com

0
2
0
2

g
u
A
1
3

]

C
H
.
s
c
[

1
v
1
8
3
3
1
.
8
0
0
2
:
v
i
X
r
a

Abstract—With the development of advanced communication
technology, connected vehicles become increasingly popular in our
transportation systems, which can conduct cooperative maneuvers
with each other as well as road entities through vehicle-to-
everything communication. A lot of research interests have been
drawn to other building blocks of a connected vehicle system, such
as communication, planning, and control. However, less research
studies were focused on the human-machine cooperation and
interface, namely how to visualize the guidance information to the
driver as an advanced driver-assistance system (ADAS). In this
study, we propose an augmented reality (AR)-based ADAS, which
visualizes the guidance information calculated cooperatively by
multiple connected vehicles. An unsignalized intersection scenario
is adopted as the use case of this system, where the driver
can drive the connected vehicle crossing the intersection under
the AR guidance, without any full stop at the intersection. A
simulation environment is built in Unity game engine based
on the road network of San Francisco, and human-in-the-loop
(HITL) simulation is conducted to validate the effectiveness of our
proposed system regarding travel time and energy consumption.

I. INTRODUCTION

The emergence of connected vehicle technology during the
past decades brings many new possibilities to our existing trans-
portation systems. Speciﬁcally, the level of connectivity within
our vehicles has greatly increased, allowing these “equipped”
vehicles to behave in a cooperative manner not only among
themselves through vehicle-to-vehicle (V2V) communication,
but also with other transportation entities through vehicle-
to-infrastructure (V2I) communication, vehicle-to-cloud (V2C)
communication, vehicle-to-pedestrian (V2P) communication,
etc., namely vehicle-to-everything (V2X) communication.

Many research works have widely studied various aspects
of the connected vehicle systems, such as communication,
perception, localization, planning, and control, where each of
them handles one or several tasks in the system [1]. The latter
four aspects are often studied in the autonomous driving domain
as well, and the concept of connected and automated vehi-
cles (CAV) emerges where vehicles can conduct cooperative
automation maneuvers together. However, it is expected that
full automation of our transportation systems will not happen
anytime soon, due to the hurdles in both the technical side
and the liability side. Therefore, during the transition from no
automation to full automation in the mixed trafﬁc environment,
human-driven connected vehicles will play a crucial role given
the rich information they can share through V2X communica-
tion, as well as the ability to cooperate with other human-driven
connected vehicles or CAVs.

needs to know how to correctly interact with the vehicle to
maximize its full advantages [2]. One critical aspect of this
topic is to design the human-machine interface (HMI) of the
advanced driver-assistance system (ADAS), so that the infor-
mation received through V2X communication can be visualized
to the driver, and guides him/her to driver the vehicle in a safer,
more efﬁcient, and more comfortable way.

Connected vehicles have been well researched regarding
the planning and control aspects, even with numerous ﬁeld
implementations conducted by real mass-produced vehicles.
However, most of them designed the HMI of their ADAS as
a simple visualization tool of the connected vehicles’ plan-
ning and control modules, such as the driver guidance on
the connected eco-driving system [3], or the driver vehicle
interface design by U.S. Department of Transportation [4]. Only
a relatively small portion of them addressed the issue from
the HMI perspective, which designed the connected vehicle’s
planning and control modules according to the pattern of the
HMI, making the integrated ADAS more informative while also
intuitive for the driver to operate.

In this study, we propose an ADAS for connected vehicles
using augmented reality (AR) as the HMI, which overlays
the guidance information on driver’s ﬁeld-of-view through the
windshield. A speciﬁc use case of unsignalized intersection
is studied, where connected vehicles (including CAVs) can
cooperate with each other to cross intersections without any
full stop, largely increasing the time efﬁciency and energy
efﬁciency of vehicles. A slot reservation planning algorithm
and a feedforward/feedback control algorithm are developed to
serve the AR HMI of the ADAS. Unity game engine is used
to model the proposed system, and human-in-the-loop (HITL)
simulation is conducted to validate the effectiveness of this
system in the unsignaliezd intersection use case.

The remainder of this paper is organized as follows: Sec-
tion II introduces the problem statement of this study in a
greater details. Section III develops different modules of this
ADAS on connected vehicles, including the AR HMI design
for drivers, the slot reservation planning algorithm, and the
feedforward/feedback control algorithm. Section IV conducts
the modeling and evaluation works of this ADAS in Unity
game engine, with results in HITL simulation showing the
effectiveness of the system. Finally, the paper is concluded with
some future directions in section V.

II. PROBLEM STATEMENT

Therefore, the importance of studying the topic of human-
machine cooperation arises, as the driver of a connected vehicle

In this study, an ADAS is designed for connected vehicles,
which includes various modules such as communication, local-

 
 
 
 
 
 
Fig. 1: System architecture of the proposed AR-based ADAS for connected vehicles

ization, perception, planning, control, and AR HMI. Although
every module is essential to the overall system architecture, we
focus on the latter three in this study. Connected vehicles in this
study can either be driven by human drivers with AR HMI, or
driven by automated controllers as CAVs. A Digital Twin (i.e.,
cyber-physical) architecture is adopted for connected vehicles
in this study, where all connected vehicles in the physical world
are connected through the cyber world. The proposed coopera-
tive maneuvers among connected vehicles does not specify or
require any speciﬁc communication technology, which means
vehicles can potentially be connected with the cyber world
through Dedicated Short-Range Communications [5], Cellular
Vehicle-to-Everything (C-V2X) [6], or a combination of both.
The general architecture of the proposed ADAS can be
illustrated as Fig. 1. In the physical world, connected vehicles
are equipped with different hardware modules that can provide
information of themselves and the surrounding trafﬁc. For ex-
ample, CAN BUS provides speed, acceleration, and many other
detailed information of the ego vehicle, while the localization
module provides its coordinate information. The perception
module, on the other hand, provides surrounding information
to the ego vehicle, such as road geometry, detected objects, and
trafﬁc condition. All these information is fed into the processor
of the ego vehicle, which processes the data locally and sends
to the cyber world through V2X communication. The processor
also receives information from the cyber world and propagates
to the AR HMI for the driver-assistance purpose. It should be
noted that, this study does not focus on the hardware setup of
the ADAS, as long as the necessary information can be gathered
and provided to the planning, control, and HMI modules.

In the cyber world, the planning and the control modules
play important roles in the overall system. The planning
module schedules different connected vehicles before they
conduct cooperative maneuvers (e.g., crossing the unsignalized
intersections in this use case), allowing connected vehicles to
identify their desired motions. The control module calculates
the particular control commands to allow vehicles to achieve
their desired motions, and executed either by human drivers or
automated controllers.

Compared to previous studies on AR or ADAS of connected
vehicles, the major contributions of this study are listed below:
• Design the planning and control modules of the ADAS to
better serve the HMI, making the system human-centered.
The HMIs in most existing ADAS simply visualize the
information derived from other modules of their systems,
such as visualizing the trafﬁc light information received
through V2X communication [3], [7], [8], providing colli-
sion warning messages [2], [9], or displaying downstream
trafﬁc-related messages [10], [11]. In this study, however,
we design the HMI using AR in a slot reservation for-
mat, and then develop the planning and control modules
according to that. The HMI is not a natural output of
this ADAS, but the basis of this ADAS that facilitates
the human-centered human-machine cooperation.

• Adopt AR to overlay the guidance information on top
of the trafﬁc environment from the driver’s ﬁeld-of-view,
providing more intuitive guidances. Instead of adopting
the AR concept to show trafﬁc information on a separate
display [12], [13], or to show some simple information on
the head-up display [14], we adopt AR to overlay the guid-

ance information on top of the trafﬁc environment. This
HMI provides a more intuitively meaningful indication of
reference connected vehicles’ presence and current status,
and better assists the driving maneuver of the driver.
• Enable the cooperative maneuvers among connected ve-
hicles through AR HMI, and validate the system through
game engine modeling and HITL simulation. Most of the
existing automotive AR HMI designs are only for ego ve-
hicle’s maneuvers, such as navigation, speed visualization,
and driving mode visualization [15], [16]. In this study, we
leverage V2X communication to allow connected vehicles
to conduct cooperative maneuvers with the assistance of
AR HMI. Not only do we design the AR HMI together
with its associated planning and control modules in the
system, but also conduct modeling and simulation with
Unity game engine, which validates its effectiveness in an
unsignalized intersection use case.

III. AUGMENTED REALITY FOR ADVANCED
DRIVER-ASSISTANCE SYSTEM

A. Use Case of Unsignalized Intersections

By design, an intersection is a planned location where vehi-
cles traveling from different directions may come into conﬂict,
and its functional area extends upstream and downstream from
the physical area of the crossing streets. Trafﬁc signals have
been playing a crucial role in achieving safer performance
at intersections, which can reduce the severity of crashes if
operated properly [17]. However, the addition of unnecessary or
inappropriately-designed signals have adverse effects on trafﬁc
safety and mobility. In addition, the dual objectives of safety
and mobility introduce trade-offs in many cases.

Therefore, the designs of unsignalized intersections emerge
during recent years, which take advantage of the connected ve-
hicle technology. Speciﬁcally, approaching vehicles can be as-
signed speciﬁc sequences by the proposed planning/scheduling
algorithms through V2X communication, and their motions
will be controlled by automated controllers or drivers with
guidance information. Most existing works in this use case
assume automation of connected vehicles [18]–[21], namely all
vehicles in the system are CAVs. However, in this study, we
aim to develop an AR-based ADAS that allows human-driven
connected vehicles to perform the cooperative maneuvers at
unsignalized intersections. This enables a more realistic appli-
cation in this use case, because not all vehicles will become
automated vehicles in the very near future, and there will
deﬁnitely be a transition period of mixed trafﬁc environment
(that has both human-driven and automated vehicles).

In this case study, since we focus on the effectiveness of
our proposed AR-based ADAS, some reasonable speciﬁcations
are made regarding the settings of the use case: 1) The ego
connected vehicle can receive information regarding vehicles
coming from other directions of this intersection, either di-
rectly through V2V communication, or indirectly through V2I
communication or V2C communication; 2) Except for the ego
vehicle, not all other vehicles are required to be connected ve-
hicles. In the case that certain vehicles do not have connectivity,
the perception sensors equipped on their surrounding connected

vehicles or on the intersection infrastructures can measure the
information of those unconnected vehicles, and share it with
the ego vehicle; 3) No vulnerable road users (e.g., pedestrians,
bicycles, etc.) are considered in this use case.

B. Design of the Augmented Reality Human-Machine Interface

In this study, we propose an AR HMI that guides the
driver to drive the connected vehicle and cross the unsignalized
intersections with other connected vehicles. The information
that needs to be visualized to the driver through the AR
HMI is regarding vehicles coming from other directions of
the intersections. We propose a slot reservation methodology
to strategically allocate different vehicles with slots upon their
approaches to the intersection. While the details regarding the
slot reservation will be covered in the next subsection under
the planning module, the design of the reserved slots on the
AR HMI is introduced here.

A simple example of the unsignalized intersection is illus-
trated in Fig. 2, where three connected vehicles are approaching
the intersection from three directions. Once an ego vehicle
gets assigned a slot, its information will be shared with its
conﬂicting vehicles, whose paths have conﬂicting points with
the ego vehicle’s path. The slot reserved by the ego vehicle
will then be shown to the drivers of conﬂicting vehicles as a
red “unavailable slot” through AR HMI, so those drivers can
control their vehicles to stay in the green “available slots”. It
needs to be noted that all slots are not stagnant, which are
dynamically updated according to the status changes of their
associated vehicles.

Fig. 2: Illustration of the slot reservation concept for connected
vehicles crossing an unsignalized intersection

The high-level concept of the AR HMI is illustrated in Fig.
2, while an example from the driver’s ﬁeld-of-view is shown
in Fig. 3. The ego vehicle is approaching an unsignalized
intersection, where two unavailable red slots are visualized on
the HMI, denoting there are two conﬂicting vehicles coming
from other directions of the intersection. The driver of this

ego vehicle needs to control the vehicle to keep in the green
available slots, so it can avoid collision while crossing the
intersection.

pa = (cid:2)R t(cid:3)

3×4







xw
yw
zw
1







4×1

(1)

Then, the intrinsic parameter matrix is applied, which con-
tains the parameters of the AR HMI’s projection device, such
as the focal length and lens distortion. Let (u0, v0) be the
coordinates of the principle point of the image plane (i.e., image
center), dx and dy be the physical size of pixels, and f be the
focal length, the projected point pi(u, v) on the AR HMI image
plane can be calculated as

pi =





zadx/f
0
0

0

−zadxu0/f
zady/f −zadyv0/f

0

za





3×3

(cid:1)

(cid:0)pa

3×1

(2)

Therefore, given the position and size of any slot in the world
referenced frame, we are able to transform the slot to the AR
HMI image plane, so it can be properly shown to the driver of
the vehicle. The calculation of slot’s position and size will be
discussed in the control module of the next subsection.

C. Planning and Control of Connected Vehicles

The planning module and the control module of this AR-
based ADAS are developed to provide the inputs for the
aforementioned AR HMI. As we design the AR HMI in an
intuitive manner that visualizes vehicles as slots projected along
the roadway, we ﬁrst need our planning module to reserve those
slots for different crossing vehicles, and then use our control
module to adjust the appropriate sizes and speeds of the slots
based on the vehicles’ real-time information.

1) Planning Module: As illustrated in Fig. 1, the planning
module takes as input the current status of the ego vehicle
while approaching the intersection, and schedules its sequence
of crossing the intersection by querying the slot pool. Once its
slot is reserved, the ego vehicle can connect and cooperate with
its reference vehicles that have conﬂicting paths with itself. The
slot reservation algorithm (Algorithm 1) is developed below for
the planning module of the ADAS.

Instead of adopting a ﬁrst-come-ﬁrst-served policy [18],
which simply assigns a vehicle with a slot when it enters
a pre-deﬁned geo-fence, we develop a new slot reservation
algorithm that accounts for various statuses of a vehicle. The
estimated time of arrival (ETA) of a vehicle is considered,
which quantiﬁes a speciﬁc point in time when a vehicle is
supposed to cross the intersection. Due to the limitation of
space, the calculation of ETA is not covered in this subsection,
which can be referred to our previous work [22]. However, an
additional step in our slot reservation algorithm is that, this ETA
value of a vehicle is further updated by the ETA value of any
immediate preceding vehicle of this vehicle. This means the
trafﬁc condition is also considered in the correct calculation of
ETA, since a following vehicle’s ETA cannot be earlier than its
preceding vehicle’s ETA, where a constant car-following time
headway th must be guaranteed as the delay in between.

Therefore, the condition that triggers a vehicle’s slot reser-
vation request is two-fold: Either its ETA is lower than a
predeﬁned time constant tθ, or it enters a pre-deﬁned geo-fence

Fig. 3: Driver’s ﬁeld-of-view of the AR HMI

Fig. 4: Coordinate transformation of the slot from the world
referenced frame to AR HMI referenced frame

The AR HMI is displayed on an image plane (e.g., wind-
shield) through the projector unit, where a front-view camera is
needed to identify the road geometry, so a slot can be correctly
overlaid on the road surface from the driver’s ﬁeld-of-view. In
order to transform the slot from its global position and size
(calculated in our control module) to the AR HMI, we develop
a coordinate transformation algorithm based on the pinhole
camera projection model, which is illustrated in Fig. 4.

The extrinsic parameter matrix in this algorithm identiﬁes the
transformation between the world referenced frame and the AR
HMI reference frame. It consists of a 3 × 3 rotation matrix R
and a 3 × 1 translation vector t. Given a 3D point of the slot in
the world referenced frame pw(xw, yw, zw), its corresponding
point pa in the AR referenced frame can be calculated as

Algorithm 1: Slot reservation for crossing vehicles at an
unsignalized intersection

Data: Ego vehicle i’s path pi from the current link to the next

link, i’s longitudinal position ri, i’s longitudinal speed vi,
i’s longitudinal acceleration ai, car-following time
headway th, reservation-trigger time constant tθ,
reservation-trigger geo-fence distance constant dθ
Result: Ego vehicle i’s reserved slot si, i’s reference vehicles js

1 Ego vehicle i enters the current link;
2 while i is not assigned si at the current intersection do
3

Calculate estimated time of arrival (ETA) ti = f (ri, vi, ai);
if There is/will be an immediate preceding vehicle j on the

same lane then

Update ETA ti = min(ti, tj + th);

end
Calculate distance to arrival di based on ri;
if ti <= tθ || di <= dθ then

Query conﬂicting vehicle j whose path

pj ∩ pi ! = ∅ ;

Query the slot pool regarding the maximum slot number
of all conﬂicting vehicles smax
Assign slot number to the ego vehicle si = smax
Connect conﬂicting vehicle j as a reference vehicle of i;

j + 1;

;

j

4

5

6

7

8

9

10

11

12

end

13
14 end
15 while i leaves the current link do
Reset the slot number si = 0;
16
Disconnect all reference vehicles;

17
18 end

of this intersection. This prevents some corner cases such as an
ego vehicle enters the geo-fence earlier, but has a much lower
speed (i.e., expected to arrive at the intersection later) than
its conﬂicting vehicle coming from another direction. In that
case, the conﬂicting vehicle needs to signiﬁcantly decelerate to
follow the ego vehicle to cross the intersection. Once Algorithm
1 is implemented, such unnecessary speed adjustments will not
exsit anymore, and the overall trafﬁc throughput and energy
efﬁciency will be improved at this intersection.

2) Control Module: Once a connected vehicle is assigned a
slot and connected with its reference vehicles, vehicle informa-
tion is constantly transmitted among them. The control module
of the ego vehicle aims to adjust the positions and sizes of
its reference vehicles’ reserved slots, so the slots can be better
visualized for the AR HMI.

First, a target speed of the ego vehicle is calculated, based
on the information received from its leading reference vehicle
j, whose reserved slot is right in front of the ego vehicle’s slot
(i.e., sj = si − 1). This target speed allows the ego vehicle
to follow the movement of its reference vehicle’s slot with the
car-following time headway. A feedforward/feedback control
algorithm is developed to calculate this target speed (that needs
to be executed at the next time step) vi(t + δt). The feedback
consensus control part is written as follow

(cid:34)

vi(t+δt) = vi(t)+

−αijkij ·

(cid:20)(cid:16)

ri(t)−rj

(cid:0)t−τij(t)(cid:1)+vi(t)

· (cid:0)th + τij(t)(cid:1)(cid:17)

+ γi ·

(cid:16)

vi(t) − vj

(cid:0)t − τij(t)(cid:1)(cid:17)(cid:21)(cid:35)

· δt

(3)

where δt is the length of each time step, vi(t) is the cur-
longitudinal speed of the vehicle, ri(t) is the current
rent
longitudinal position of the vehicle, αij denotes the value
of adjacency matrix. The time-variant communication delay
between two vehicles is denoted as τij(t), which is assumed
as a normal distribution in this study, with a mean value of 40
ms and a standard deviation of 0.0259 based on our test results
[23]. The control gains kij and γi in this feedback control
algorithm can be either deﬁned as constants, or further tuned
by a feedforward control algorithm to guarantee the safety,
efﬁciency, and comfort of this slot-following process. A lookup-
table approach is adopted to dynamically calculate these control
gains, based on the initial speeds of two vehicles, as well as
their initial headway. In short, it can be summarized as

{kij, γi} = f (cid:0)vi(0), vj(0), ri(0) − rj(0)(cid:1)

(4)

where the details can be referred to our previous work [24].

This target speed value vi(t + δt) is directly fed into the
their longitudinal
automated controller of CAVs to control
speed. As for the AR HMI on human-driven connected vehicles,
this target speed is the input to calculate the positions and sizes
of the slots reserved by reference vehicles, where Algorithm 2
is developed below for the control module of the ADAS.

Algorithm 2: Slot adjustment for AR HMI visualization
Data: Ego vehicle i’s target speed at the next time step
vi(t + δt), i’s reference vehicle j, i’s longitudinal
position ri, i’s lateral position xi, j’s longitudinal
position rj, car-following time headway th, i’s path pi
from the current link to the next link, j’s path pj from the
current link to the next link, j’s longitudinal position rj,
j’s length lj, j’s width wj

Result: j’s reserved slot’s longitudinal position rsj , lateral

position xsj , length lsj , width wsj

1 for Ego vehicle i’s all reference vehicles js, j = 1, 2, ..., n do
Calculate the conﬂicting point Oij of i’s path and j’s path;
2
Calculate the distance difference δij from i’s lane and j’s

3

lane to the conﬂicting point;

Calculate distances to arrival di and dj based on ri and rj;
while i does not cross the conﬂicting point Oij do

4

5

6

7

8

9

10

11

12

13
14 end

Calculate j’s reserved slot’s longitudinal position
rsj = ri − (di − dj) + δij;
Set j’s reserved slot’s lateral position xsj = xi;
Calculate j’s reserved slot’s width wsj = wj;
Calculate j’s reserved slot’s length
lsj = max(lj, vi(t + δt) ∗ th);

end
while i crosses the conﬂicting point Oij do
Reset the slot information rsj , wsj , lsj ;

end

IV. GAME ENGINE MODELING AND EVALUATION

A. Game Engine for Modeling Connected Vehicles

Game engines enable the design of video games for software
developers, which typically consist of a rendering engine for 2-
D or 3-D graphics, a physics engine for collision detection and
response, and a scene graph for the management of multiple
elements (e.g., models, sound, scripting, threading, etc.). Along

with the rapid development of game engines in recent years,
their functions have been broadened to a wider scope: data
visualization, training, medical, and military use. Game engines
also become popular options in the development of advanced
vehicular technology [25], which have been used to study driver
behaviors [14], prototype connected vehicle systems [26], [27],
and simulate autonomous driving [28], [29].

In this study, we adopt Unity game engine to conduct
modeling and evaluation of our AR-based ADAS, given its
advantages of graphics design and visualization, as well as its
easiness to connect with external driving simulators [30]. As
shown in Fig. 5, the map built by LGSVL is adopted in our
study, which is based on the South of Market (SoMa) district in
San Francisco [29]. Shown as yellow lines on the road surface,
centimeter-level routes along the 2nd Street, Harrison Street,
Folsom Street, Howard Street, and Mission Street are further
modeled in this study, so map matching and path planning
features can be enabled in our ADAS. The planning and control
modules we develop in this study are modeled on vehicles in
this environment through Unity’s C# API. The AR HMI is
also designed on the ego vehicle through Unity’s visualization
feature.

Fig. 5: A four-intersection corridor HD map built in Unity game
engine based on the SoMa district in San Francisco

B. Human-in-the-Loop Simulation

To evaluate our proposed AR-based ADAS, we conduct
HITL simulation with drivers controlling the external driving
simulator. As shown in Fig. 6 The driving simulator platform is
built with a desktop (processor Intel Core i7-9750 @2.60GHz,
memory 32.0 GB), a Logitech G29 Driving Force racing wheel,
and Unity 2019.2.11f1.

Fig. 6: Driving simulator platform to conduct human-in-the-
loop simulation

The invited participants in this simulation are advised to drive
the ego vehicle in the Unity environment, which travels along
the 2nd Street. The ego vehicle starts from the Bryant Street
with zero speed, and then crosses four consecutive unsignalized
intersections from south to north. All other vehicles in the
simulation are non-player characters (NPCs), which run the
proposed planning and control modules as CAVs.

Additionally, all participants drive the ego vehicle in the
baseline scenario, where all four intersections have traditional
ﬁxed-timing trafﬁc signals. NPC vehicles are randomly gener-
ated from all directions at each intersection, and they are not
enabled with any CAV feature in this scenario. This enables us
to investigate the beneﬁts brought by the proposed AR-based
ADAS to the existing transportation systems.

C. Simulation Results and Evaluation

Among all

the trips conducted by the participants, one
is shown in Fig. 7. This sample
sample simulation result
result was generated when the participant drove the ego vehicle
through unsignalized intersections, under the guidance of our
proposed AR-based ADAS. Speciﬁcally, the ﬁrst segment of
the whole trip is picked out, where the ego vehicle crossed the
ﬁrst intersection (i.e., 2nd Street & Harrison Street intersection)
in collaboration with all other six NPC vehicles.

The distance-time plot in Fig. 7(a) shows the ego vehicle was
able to keep a relatively safe distance regarding its reference
vehicles, including its immediate preceding NPC vehicle 3.
Meanwhile, the ego vehicle also acts as a reference vehicle for
NPC vehicle 4, 5 and 6, where NPC vehicle 4 considers the ego
vehicle as its immediate preceding vehicle. Since the proposed
feedforward/feedback control algorithm was applied to these
three NPC vehicles, they consecutively decelerated during 5-
12 s to maintain a relatively safe distance with their immediate
preceding vehicles.

The process of all seven vehicles reserving slots is shown in
Fig. 7(b), which corresponds to the vehicle trajectories in Fig.
7(a). Once a vehicle was assigned a slot by our proposed Al-
gorithm 1, they immediately identiﬁed their reference vehicles
and apply the control algorithm. Once they crossed the current

intersection, the reserved slots were reset to zero, waiting for
new assignments while approaching the next intersection. It can
be noticed from this plot that, the ego vehicle (i.e., dark-red
dashed line) was assigned a new slot of three after it entered
the next link, even before NPC vehicle 5 and 6 crossed the ﬁrst
intersection. This means the proposed slot reservation process is
independent at each intersection, which continues running when
different vehicles approaching and leaving the intersection.

Fig. 8: A sample comparison when the ego vehicle travels
through the whole corridor 1) with traditional intersections and
2) with unsignalized intersections using the proposed ADAS

time, and an average of 23.7% reduction in fuel consumption
(calculated by the open-source MOVESTAR model [31] and
assuming all gasoline vehicles) can be achieved by applying
the proposed AR-based ADAS.

V. CONCLUSION AND FUTURE WORK

In this study, an AR-based ADAS was designed for con-
nected vehicles, which visualizes the guidance information to
vehicle drivers in a more intuitive manner. Instead of making
the HMI a simpliﬁed output of whatever is provided by other
modules of the ADAS, we designed the planning and control
modules of our ADAS to better serve the HMI, making this
system human-centered. A slot reservation methodology was
proposed in the unsignalized intersection use case, where a
driver can cooperate with other crossing vehicles at intersec-
tions by simply following the guidance on the AR HMI. Mod-
eling and evaluation of this AR-based ADAS were conducted
in Unity game engine, where HITL simulation results proved
the its beneﬁts in travel time and energy consumption.

To take this study one step further, vulnerable road users
such as pedestrians and bicycles need to be considered in the
modeling and visualization process. The term “mixed trafﬁc
environment” does not only refer to an environment mixed with
different kinds of vehicles, but also includes vulnerable road
users that have the highest priority in the environment. How
to build the ADAS of connected vehicles that could cooperate
with vehicles, bicycles and pedestrians at the same time remains
an interesting question to be solved.

ACKNOWLEDGMENT

The contents of this paper only reﬂect the views of the
authors, who are responsible for the facts and the accuracy
of the data presented herein. The contents do not necessarily
reﬂect the ofﬁcial views of Toyota Motor North America.

REFERENCES

[1] Z. Wang, Y. Bian, S. E. Shladover, G. Wu, S. E. Li, and M. J. Barth,
“A survey on cooperative longitudinal motion control of multiple con-
nected and automated vehicles,” IEEE Intelligent Transportation Systems
Magazine, vol. 12, no. 1, pp. 4–24, 2020.

(a)

(b)

Fig. 7: A sample simulation result of applying AR-based ADAS
at the 2nd St & Harrison St intersection, where the ego vehicle
is driven by a human driver on the driving simulation platform

A sample comparison between the unsignalized intersection
scenario and the baseline traditional intersection scenario is
shown in Fig. 8. This speed-distance plot was created when
the same participant drove the ego vehicle through all four
intersections in Fig. 5. In the baseline scenario, the ego vehicle
ran into red lights at the ﬁrst and the fourth intersections,
while directly passed the second and the third intersections
during green lights. In the unsignalized intersection scenario,
however, the ego vehicle maintained a relatively stable speed
while travelling through all four intersections, without any full
stop at any intersection. Although a higher maximum speed
was reached in the baseline scenario,
the excessive speed
changes signiﬁcantly increased the travel time and the energy
consumption. Based on all trips conducted by the participants
in HITL simulation, an average of 20% reduction in travel

[22] Z. Wang, G. Wu, and M. Barth, “Distributed consensus-based
cooperative highway on-ramp merging using V2X communications,”
in SAE Technical Paper, Apr. 2018.
[Online]. Available: https:
//doi.org/10.4271/2018-01-1177

[23] Z. Wang, X. Liao, X. Zhao, K. Han, P. Tiwari, M. J. Barth, and G. Wu, “A
digital twin paradigm: Vehicle-to-Cloud based advanced driver assistance
systems,” in 2020 IEEE 91st Vehicular Technology Conference, May
2020, pp. 1–6.

[24] Z. Wang, K. Han, B. Kim, G. Wu, and M. J. Barth, “Lookup table-
based consensus algorithm for real-time longitudinal motion control of
connected and automated vehicles,” arXiv:1902.07747v2, 2019.

[25] J. Ma, C. Schwarz, Z. Wang, M. Elli, G. Ros, and Y. Feng, “New
simulation tools for training and testing automated vehicles,” in Road
Vehicle Automation 7, G. Meyer and S. Beiker, Eds. Cham: Springer
International Publishing, 2020, pp. 111–119.

[26] Z. Wang, G. Wu, K. Boriboonsomsin, M. Barth et al., “Cooperative
ramp merging system: Agent-based modeling and simulation using game
engine,” SAE International Journal of Connected and Automated Vehicles,
vol. 2, no. 2, 2019.

[27] Y. Liu, Z. Wang, K. Han, Z. Shou, P. Tiwari, and J. H. L. Hansen,
“Sensor fusion of camera and cloud digital twin information for intelligent
vehicles,” in IEEE Intelligent Vehicles Symposium (IV), Jun. 2020.
[28] A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, and V. Koltun, “CARLA:
An open urban driving simulator,” arXiv preprint arXiv:1711.03938,
2017.

[29] G. Rong, B. H. Shin, H. Tabatabaee, Q. Lu, S. Lemke, M. Moˇzeiko,
E. Boise, G. Uhm, M. Gerow, S. Mehta et al., “Lgsvl simulator:
for autonomous driving,” arXiv preprint
A high ﬁdelity simulator
arXiv:2005.03778, 2020.

[30] Unity, “Unity for all.” [Online]. Available: https://unity.com/
[31] Z. Wang, G. Wu, and G. Scora, “MOVESTAR: An open-source vehicle

fuel and emission model based on usepa moves,” 2020.

[2] C. Olaverri-Monreal and T. Jizba, “Human factors in the design of
human–machine interaction: An overview emphasizing v2x communica-
tion,” IEEE Transactions on Intelligent Vehicles, vol. 1, no. 4, pp. 302–
313, 2016.

[3] Z. Wang, Y. Hsu, A. Vu, F. Caballero, P. Hao, G. Wu, K. Boriboonsomsin,
M. J. Barth, A. Kailas, P. Amar, E. Garmon, and S. Tanugula, “Early
ﬁndings from ﬁeld trials of heavy-duty truck connected eco-driving
system,” in 2019 IEEE Intelligent Transportation Systems Conference
(ITSC), 2019, pp. 3037–3042.

[4] J. Campbell, J. Brown, J. Graving, C. Richard, M. Lichty, T. Sanquist, and
J. Morgan, “Human factors design guidance for driver-vehicle interfaces,”
U.S. Department of Transportation National Highway Trafﬁc Safety
Administration, Tech. Rep., 2016.

[5] J. B. Kenney, “Dedicated short-range communications (dsrc) standards in
the united states,” Proceedings of the IEEE, vol. 99, no. 7, pp. 1162–1182,
July 2011.

[6] S. Chen, J. Hu, Y. Shi, Y. Peng, J. Fang, R. Zhao, and L. Zhao, “Vehicle-
to-everything (V2X) services supported by LTE-based systems and 5G,”
IEEE Communications Standards Magazine, vol. 1, no. 2, pp. 70–76,
2017.

[7] O. D. Altan, G. Wu, M. J. Barth, K. Boriboonsomsin, and J. A. Stark,
“Glidepath: Eco-friendly automated approach and departure at signalized
intersections,” IEEE Transactions on Intelligent Vehicles, vol. 2, no. 4,
pp. 266–277, Dec 2017.

[8] H. Conceic¸ ˜ao, M. Ferreira, and P. Steenkiste, “Virtual trafﬁc lights in par-
tial deployment scenarios,” in 2013 IEEE Intelligent Vehicles Symposium
(IV), 2013, pp. 988–993.

[9] C. Olaverri-Monreal, P. Gomes, R. Fernandes, F. Vieira, and M. Ferreira,
“The see-through system: A vanet-enabled assistant for overtaking ma-
neuvers,” in 2010 IEEE Intelligent Vehicles Symposium, 2010, pp. 123–
128.

[10] R. L. Bertini, S. Boice, and K. Bogenberger, “Dynamics of variable
speed limit
system surrounding bottleneck on german autobahn,”
Transportation Research Record, vol. 1978, no. 1, pp. 149–159, 2006.
[Online]. Available: https://doi.org/10.1177/0361198106197800119
[11] S. Nyg˚ardhs and G. Helmers, “VMS - Variable Message Signs: A

literature review,” Infrastructure maintenance, Tech. Rep. 570A, 2007.

[12] M. Quinlan, T.-C. Au, J. Zhu, N. Stiurca, and P. Stone, “Bringing simu-
lation to life: A mixed reality autonomous intersection,” in Proceedings
of IEEE/RSJ International Conference on Intelligent Robots and Systems
(IROS), October 2010.

[13] Y. Feng, C. Yu, S. Xu, H. X. Liu, and H. Peng, “An augmented
reality environment for connected and automated vehicle testing and
evaluation*,” in 2018 IEEE Intelligent Vehicles Symposium (IV), 2018,
pp. 1549–1554.

[14] Z. Wang, X. Liao, C. Wang, D. Oswald, G. Wu, K. Boriboonsomsin,
M. Barth, K. Han, B. Kim, and P. Tiwari, “Driver behavior modeling
using game engine and real vehicle: A learning-based approach,” IEEE
Transactions on Intelligent Vehicles, pp. 1–1, 2020.
“Augmented-reality

[15] Continental,

Accessed:

HUD,”

2020-07-
https://www.continental-automotive.com/

[Online]. Available:

06.
en-gl/Passenger-Cars/Information-Management/Head-Up-Displays/
Augmented-Reality-HUD

[16] Volkswagen, “AR Head-Up display,” Accessed: 2020-07-06. [Online].
Available: https://www.volkswagen.co.uk/electric/id/id-family/id3.html#
comfort

[17] U.S. Department of Transportation Federal Highway Administration,
2020-06-02.
“Signalized
[Online]. Available: https://safety.fhwa.dot.gov/intersection/conventional/
signalized/fhwasa13027/ch1.cfm

intersections: An

informational

guide,”

[18] K. Dresner and P. Stone, “A multiagent approach to autonomous inter-
section management,” Journal of artiﬁcial intelligence research, vol. 31,
pp. 591–656, 2008.

[19] N. Neuendorf and T. Bruns, “The vehicle platoon controller in the
decentralised, autonomous intersection management of vehicles,” in Pro-
ceedings of the IEEE International Conference on Mechatronics, 2004.
ICM ’04., Jun. 2004, pp. 375–380.

[20] Q. Jin, G. Wu, K. Boriboonsomsin, and M. Barth, “Platoon-based multi-
intersection management for connected vehicle,” in 2013 16th
agent
International IEEE Conference on Intelligent Transportation Systems
(ITSC)), Oct. 2013, pp. 1462–1467.

[21] B. Xu, S. E. Li, Y. Bian, S. Li, X. J. Ban, J. Wang, and K. Li, “Distributed
conﬂict-free cooperation for multiple connected vehicles at unsignalized
intersections,” Transportation Research Part C: Emerging Technologies,
vol. 93, pp. 322–334, 2018.

