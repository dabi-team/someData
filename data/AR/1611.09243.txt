7
1
0
2

r
a

M
5
2

]
I

N
.
s
c
[

2
v
3
4
2
9
0
.
1
1
6
1
:
v
i
X
r
a

Energy-Efﬁcient Resource Allocation for Mobile

Edge Computing-Based Augmented Reality

Applications

Ali Al-Shuwaili and Osvaldo Simeone

Abstract

Mobile edge computing is a provisioning solution to enable Augmented Reality (AR) applications on mobile

devices. AR mobile applications have inherent collaborative properties in terms of data collection in the uplink,

computing at the edge, and data delivery in the downlink. In this letter, these features are leveraged to propose a novel

resource allocation approach over both communication and computation resources. The approach, implemented via

Successive Convex Approximation (SCA), is seen to yield considerable gains in mobile energy consumption as

compared to conventional independent ofﬂoading across users.

Index Terms

Mobile edge computing, Augmented reality, Resource allocation, Shared ofﬂoading, Multicasting.

I. INTRODUCTION

Augmented Reality (AR) mobile applications are gaining increasing attention due to the their ability to

combine computer-generated data with the physical reality. AR applications are computational-intensive

and delay-sensitive, and their execution on mobile devices is generally prohibitive when satisfying users’

A. Al-Shuwaili and O. Simeone are with the Center for Wireless Information Processing (CWiP), Department of Electrical and Computer

Engineering, New Jersey Institute of Technology, Newark, NJ 07102 USA (e-mail: ana24@njit.edu, and osvaldo.simeone@njit.edu).

 
 
 
 
 
 
expectations in terms of battery lifetime [1–3]. To address this problem, it has been proposed to leverage

mobile edge computing [3–6]. Accordingly, users can ofﬂoad the execution of the most time- and energy-

consuming computations of AR applications to cloudlet servers via wireless access points.

The stringent delay requirements pose signiﬁcant challenges to the ofﬂoading of AR application via

mobile edge computing [3, 6]. A recent line of work has demonstrated that it is possible to signiﬁcantly

reduce mobile energy consumption under latency constraints by performing a joint optimization of the

allocation of communication and computational resources [7, 8]. These investigations apply to generic

applications run independently by different users. However, AR applications have the unique property

that the applications of different users share part of the computational tasks and of the input and output

data [3? ]. In this paper, we propose to leverage this property to reduce communication and computation

overhead via the joint optimization of communication and computational resources.

To illustrate the problem at hand, consider the class of AR applications that superimpose artiﬁcial images

into the real world through the screen of a mobile device. The block diagram of such applications shown

in Fig. 1 identiﬁes the following components[3, 4]: (i) Video source, which obtain raw video frames from

the mobile camera; (ii) Tracker, which tracks the position of the user with respect to the environment; (iii)

Mapper, which builds a model of the environment; (iv) Object recognizer, which identiﬁes known objects

in the environment; and (v) Renderer, which prepares the processed frames for display. The Video source

and Renderer components must be executed locally at the mobile devices, while the most computationally

intensive Tracker, Mapper and Object recognizer components can be ofﬂoaded. Moreover, if ofﬂoaded,

Mapper and Object recognizer can collect inputs from all the users located in the same area, limiting the

transmission of redundant information in the uplink across users. Also, the outcome of the Mapper and

Object recognizer components can be multicast from the cloud to all co-located users in the downlink.

In this work, unlike prior papers [7, 8], we tackle the problem of minimizing the total mobile energy

expenditure for ofﬂoading under latency constraints over communication and computation parameters by

2

Fig. 1. Example of a component-based model of an AR application [3]. The application includes the Video source and Renderer

components, which need to be executed locally on the mobile device, and the three main components of Mapper, Tracker and

Object recognizer, which may be ofﬂoaded.

explicitly accounting for the discussed collaborative nature of AR applications. Section II introduces

the system model. The resource allocation problem is formulated and tackled by means of a proposed

Successive Convex Approximation (SCA) [9] solution in Section III. Numerical results are ﬁnally provided

in Section IV.

II. SYSTEM MODEL

We consider the mobile edge computing system illustrated in Fig. 2, in which K users in a set K =

{1, . . . , K} run a computation-intensive AR application on their single-antenna mobile devices with the

aid of a cloudlet server. The server is attached to a single-antenna Base Station (BS), which serves all the

users in the cell using Time Division Duplex (TDD) over a frequency-ﬂat fading channel. Following the

discussion in Sec. I, we assume that the ofﬂoaded application has shared inputs, outputs and computational

tasks, which pertain to the Tracker, Mapper and Object recognizer components.

To elaborate, let us ﬁrst review the more conventional set-up, studied in, e.g., [7, 8], in which users

perform the ofﬂoading of separate and independent applications. In this case, ofﬂoading for each user k

would require: (i) Uplink: transmitting a number BI

k input bits from each user k to the cloudlet in the

uplink; (ii) Cloudlet processing: processing the input by executing Vk CPU cycles at the cloudlet; (iii)

3

Fig. 2. Ofﬂoading of an AR application to a cloudlet attached to the BS. Shared data and computations are shaded.

Downlink: transmitting BO

k bits from the cloudlet to each user k in the downlink. In contrast, as discussed

in Sec. I, the collaborative nature of the Tracker, Mapper and Object recognizer components (recall Fig. 1)

can be leveraged to reduce mobile energy consumption and ofﬂoading latency, as detailed next. We note

that the non-collaborative components can potentially also be carried out locally if this reduces energy

consumption (see, e.g., [7][8]). We leave the study of the optimization of this aspect to future work.

1) Shared uplink transmission: A given subset of BI

S ≤ mink{BI

k} input bits is shared among the users

in the sense that it can be sent by any of the users to the cloudlet. For example, the input bits to the

ofﬂoaded Object recognizer component in Fig. 1 can be sent by any of the users in the same area. As a

result, each user k transmits a fraction of BI

S,k bits of the BI

S shared bits, which can be optimized under

the constraint

k BI

S,k = BI

S, as well as ∆BI

k = BI

k − BI

S,k bits that need to be uploaded exclusively by

user k.

P

2) Shared cloudlet processing: Part of the computational effort of the cloudlet is spent producing output

bits of interest to all users. An example is the computational task of updating the model of the environment

carried out by the mobiles. Therefore, we assume that VS ≤ mink{Vk} CPU cycles are shared, whereas

∆Vk = Vk − VS CPU cycles are to be executed for each user k.

4

Fig. 3. Data frame structure for a system with K = 3 users. The preamble containing training sequences is not shown.

3) Multicast downlink transmission: Some of the output bits need to be delivered to all users. For

example, a co-located group of users may need the output bits from the Mapper component for a map

update. To model this, we assume that a subset of BO

S ≤ mink{BO

k } output bits can be transmitted in

multicast mode to all users in the cell, while ∆BO

k = BO

k − BO

S bits need to be transmitted to each user

in a unicast manner.

The frame structure is detailed in Fig. 3. Not shown are the training sequences sent by the users

prior to the start of the data transmission frame, which enable the BS to estimate the uplink Channel

State Information (CSI), and hence also the downlink CSI due to reciprocity. The CSI is assumed to

remain constant for the frame duration. As seen in Fig. 3, in the data frame, the shared communication

and computation tasks are carried out ﬁrst, followed by the conventional separate ofﬂoading tasks, as

discussed next.

1) Uplink transmission: The achievable rate, in bits/s, for transmitting the input bits of user k in the

uplink is given by

Rul

k (P ul

k ) =

W ul
K

log2

1 +

(cid:18)

γkP ul
k
N0W ul/K

,

(cid:19)

(1)

5

where P ul
k

is the transmit power of the mobile device of user k; the uplink bandwidth W ul is equally

divided among the K users, e.g., using OFDMA; γk is the uplink and downlink channel power gains of user

k; and N0 is the noise power spectral density at the receiver. Referring to Fig. 3 for an illustration, the time,

in seconds, necessary to complete the shared uplink transmissions is deﬁned as T ul

S = maxkBI

S,k/Rul

k (P ul

k ),

whereas the time needed for user k to transmit the separate ∆BI

k bits is ∆BI

k/Rul

k (P ul

k ). The corresponding

mobile energy consumption due to uplink transmission is

Eul

k (P ul

k , BI

S,k) =

P ul
k
k (P ul
k )

Rul

(cid:18)

+ lul
k

BI

S,k + ∆BI
k

,

(cid:19)

(cid:0)

(cid:1)

(2)

where lul

k is a parameter that indicates the amount of energy spent by the mobile device to extract each

bit of ofﬂoaded data from the video source. In (2) and in subsequent equations, we make explicit the

dependence on variables to be optimized.

2) Cloudlet processing: Let FC be the capacity of the cloudlet server in terms of number of CPU cycles

per second. Also, let fk ≥ 0 and fS ≥ 0 be the fractions, to be optimized, of the processing power FC

assigned to run the ∆Vk CPU cycles exclusively for user k and the VS shared CPU cycles, respectively,

so that

k∈K fk ≤ 1 and fS ≤ 1. As shown in Fig. 3, the execution time for the shared CPU cycles

is T C

P

S = VS/(fSFC) and the time needed to execute ∆Vk CPU cycles of interest to user k remotely is

∆Vk/(fkFC).

3) Downlink transmission: The common output bits BO

S are multicast to all users. Let P dl

M be the

transmit power for multicasting, which is subject to the optimization. The resulting achievable downlink

rate for user k is given by

Rdl

M,k(P dl

M ) = W dl log2

1 +

(cid:18)

γkP dl
M
N0W dl

,

(cid:19)

(3)

with Rdl

M (P dl

M ) = minkRdl

M,k(P dl

M ), with W dl being the downlink bandwidth. The downlink transmission

time to multicast BO

S bits can hence be computed as T dl

S = BO

S /Rdl

M (P dl

M ) (see Fig. 3). The ∆BO

k output

6

bits intended exclusively for each user k are sent in a unicast manner in downlink using an equal bandwidth

allocation, with rate

Rdl

k (P dl

k ) =

W dl
K

log2

1 +

(cid:18)

γkP dl
k
N0W dl/K

,

(cid:19)

(4)

where P dl
k

is the BS transmit power allocated to serve user k. The overall downlink mobile energy

consumption for user k is

Edl

k (P dl

k , P dl

M ) =

∆BO
k
k (P dl
k )

Rdl

+

BO
S
M,k(P dl

Rdl

M ) !

ldl
k ,

(5)

where ldl

k is a parameter that captures the mobile receiving energy expenditure per second in the downlink.

We note that we leave the optimization of the bandwidth allocation across users for uplink and downlink

to future work.

III. ENERGY-EFFICIENT RESOURCE ALLOCATION

In this section, we tackle the minimization of the mobile sum-energy required for ofﬂoading across

all users under latency and power constraints. Stated in mathematical terms, we consider the following

problem:

+ VS
fSFC

+ ∆BO
k
k (P dl
Rdl

k ) ≤ Tmax − T ul

S − T dl

S , ∀k ∈ K,

min
z

k∈K
P
s.t. C.1

C.2

C.3

C.4

C.5

C.6

Eul

k (P ul

k , BI

S,k) + Edl

k (P dl

k , P dl
M )

Rul

Rul

fkFC

∆BI
k ) + ∆Vk
k
k (P ul
BI
k ) ≤ T ul
S,k
k (P ul
BO
M ) ≤ T dl
S
M,k(P dl

Rdl

S , ∀k ∈ K,

S , ∀k ∈ K,

fk ≤ 1; 0 ≤ fS ≤ 1; fk ≥ 0, ∀k ∈ K,

BI

S,k = BI
S,

k∈K
P

k∈K
P

(P.1)

, where Pul ,

k∈K
P
The optimization variables are collected in vector z ,

Pul, BI

S, f, Pdl, P dl

M , T ul

S , T dl
S

k ≤ P dl
P dl

max; P dl

M ≤ P dl

max; P ul

k ≤ P ul

max, ∀k ∈ K.

(P ul

k )k∈K, BI

S

, (BI

(cid:0)
S,k)k∈K, f , ((fk)k∈K, fS), Pdl , (P dl
k )k∈K, and we deﬁned Z as the feasible set

(cid:1)

7

 
of problem (P.1). As illustrated in Fig. 3, constraints C.1-C.3 enforce that the execution time of the

ofﬂoaded application to be less than or equal to the maximum latency of Tmax seconds. Constraints C.4-

C.5 impose the conservation of computational resources and shared input bits, and C.6 enforces transmit

power constraints at BS and users.

Problem (P.1) is not convex because of the non-convexity of the energy function Eul

k (P ul

k , BI

S,k) and of

the latency constraints C.2, which we can rewrite as gk(P ul

k , BI

S,k) ≤ T ul

S , ∀k ∈ K. We address this issue

by developing an SCA solution following [9]. Theorem 2 in [9] shows that the SCA algorithm converges

to a stationary point of the non-convex problem (P.1). Furthermore, such convergence requires a number

of iterations proportional to 1/ǫ, where ǫ measures the desired accuracy in terms of the stationarity metric

kF (z) k2

2 deﬁned in [10, Eq. (6)].

In order to apply the SCA method, we need to derive convex approximants for the functions Eul

k (P ul

k , BI

S,k)

and gk(P ul

k , BI

S,k) that satisfy the conditions speciﬁed in [9, Sec. II]. Using such approximants, we obtain

the SCA scheme detailed in Algorithm 1. In the algorithm, at each iteration v, the unique solution

ˆz (z (v)) ,

(cid:0)

ˆPul, ˆBI

S, ˆf , ˆPdl, ˆP dl

M , ˆT ul

S , ˆT dl

S

of the following strongly convex problem

ˆz (z (v)) , argmin

(cid:1)

z

˜E (zk; zk (v))

Xk∈K

s.t.

C.2

˜gk

k , BI
P ul

S,k; P ul

k (v), BI

S,k(v)

≤ T ul

S , ∀k ∈ K,

C.1, C.3 − C.6 of (P.1),

(cid:0)

(cid:1)

(P.2)

is obtained, where we have deﬁned zk ,

k , BI
P ul

S,k, fk, fS, P dl

k , P dl

M , T ul

S , T dl
S

as well as ˜Ek (zk; zk (v)) ,

˜Eul

k (zk; zk (v)) + Edl

k (P dl

k , P dl

M ). The approximants functions ˜Eul

k (.; .) and ˜gk (.; .) are discussed next. The

(cid:1)

(cid:0)

approximant ˜Eul

k (zk; zk (v)) around the current feasible iterate zk(v) can be obtained following [9, Sec.

8

III, Example #8] as

˜Eul

k (zk; zk (v)) =

P ul

k (v)

S,k(v) + ∆BI
k

BI
Rul
(cid:0)
k
P ul
k

(cid:1)

P ul
k
S,k(v) + ∆BI
BI
(cid:1)
(cid:0)
k
P ul
Rul
k (v)
(cid:0)
k

+

P ul

k (v)
Rul
(cid:0)
k

BI
S,k + ∆BI
k
P ul
k (v)

+

(cid:1)

(cid:1)

(6)

+ ¯Eul

(cid:0)
k (zk; zk(v)) + lul

(cid:1)

k

BI

S,k + ∆BI
k

(cid:0)

,

(cid:1)

where ¯Eul

k (zk; zk(v)) , (zk − zk(v))T Ψ (zk − zk(v)), with Ψ being a diagonal matrix with non-negative

(cid:0)

(cid:1)

elements τP ul, τBI

S

, τf , τfS , τP dl, τP dl

M

, τT ul

S

and τT dl

S

. For the second approximant, in light of the relation

g(x1, x2) = x1x2 = 1/2(x1 + x2)2 − 1/2(x2

1 + x2

2), a convex upper bound is obtained as requested by SCA

by linearizing the concave part of gk(P ul

k , BI

S,k)[9, Sec. III, Example #4], which results in

(cid:1)

1
k (P ul
k (v))2

Rul

(cid:19) !

k , BI
P ul

S,k; P ul

k (v), BI

S,k(v)

˜gk

(cid:0)

−

BI

S,k(v)

2

−

−

(cid:0)

(cid:1)
Rul
k
1 + γkP ul
k (v)
(cid:0)
N0W ul/K
(cid:16)

(cid:18)
P ul

k (v)
Rul
k

(cid:17)

(cid:0)

=

1
2   (cid:18)

BI

S,k +

1
k (P ul
k )

Rul

2

(cid:19)

−

(BI

S,k(v)

BI

S,k − BI

S,k(v)

(7)

P ul
(cid:1)

k (v)

4

(cid:18)

Rul
k

1
P ul
k

(cid:0)

−

Rul
k

1
P ul
k (v)

(cid:1)

.

(cid:19)!

The convexity of (7) is established by noting that the second term in the right-hand side is the reciprocal

(cid:1)

(cid:0)

(cid:1)

(cid:0)

(cid:1)

of the rate function (concave and positive) and the fourth power (convex and non-decreasing) of a convex

function is convex [11].

Algorithm 1 SCA Algorithm
1: Initialization: z (0) ∈ Z; α = 10−5; ǫ = 10−5; v = 0; τP ul, τBI

S

, τf , τfS , τP dl, τP dl

M

, τT ul

S

, τT dl

S

> 0.

2: Compute ˆz (z (v)) from (P.2).

3: Set z (v + 1) = z (v) + δ (v) (ˆz (z (v)) − z (v)), with δ (v) = δ (v − 1) (1 − αδ (v − 1)).

4: If kF (z (v)) k2

2 ≤ ǫ, stop.

5: Otherwise, set v ← v + 1, and return to step 2.

9

 
IV. NUMERICAL RESULTS

In this section, we provide numerical examples with the aim of illustrating the advantages that can be

accrued by leveraging the collaborative nature of AR applications for mobile edge computing. We consider

a scenario where eight users are randomly deployed in a small cell. The radio channels are Rayleigh fading

and the path loss coefﬁcient is obtained based on the small-cell model in [12] for a carrier frequency of 2

GHz. The users’ distances to the BS are randomly uniformly selected between 100 and 1000 meters and

the results are averaged over multiple independent drops of users’ location and of the fading channels.

The noise power spectral density is set to N0 = −147 dBm/Hz. The uplink and downlink bandwidth is

W ul = W dl = 10 MHz. The uplink and downlink power budgets are constrained to the values P ul

max = 50

and P dl

max = 60 dBm, respectively. The cloudlet server processing capacity is FC = 1010 CPU cycles/s [3].

We also set lul

k = 1.78 × 10−6 J/bit [13], ldl

k = 0.625 J/s [14] and ǫ = 10−5.

The size of the input data generally depends on the number and size of the features of the video sources

obtained by the mobiles that are to be processed at the cloudlet. Here we select BI

k = 1 Mbits, which

may correspond to the transmission of 1024 × 768 images [5]. A fraction of the input bits BI

S = ηBI
k

bits can be transmitted cooperatively by all users for some parameter 0 ≤ η ≤ 1. The required CPU

cycles of the ofﬂoaded components is set to Vk = 2640 × BI

k CPU cycles, representing a computational

intensive task [15]. The shared CPU cycles are assumed to be VS = ηVk for the same sharing factor η.

The output bits are assumed to equal the amount of input bits BO

k = BI

k = 1 Mbits with shared fraction

BO

S = ηBO

k . Practical latency constraints for AR applications are of the order of 0.01 s [4, 5]. Throughout

our experiments, we found that the accuracy ǫ = 10−5 was obtained within no more than 25 iterations.

————————————————————————————————

For reference, we compare the performance of the proposed scheme, in which uplink and downlink

transmissions and cloudlet computations are shared as described, with the following ofﬂoading solutions:

(i) Shared Cloudlet Processing and Downlink Transmission: CPU cycles and output data are shared as

10

]
J
[

y
g
r
e
n
E
m
u
S

-

e
l
i

b
o
M

4500

4000

3500

3000

2500

2000

1500

1000

500

0

0

Separate oﬄoading
Shared Processing & Downlink
Shared Uplink
Shared Uplink, Processing & Downlink
Global optimization of (P.1) [16]

Tmax = 0.05 s

Tmax = 0.15 s

0.1

0.2

0.3

0.4

0.5
η

0.6

0.7

0.8

0.9

1

Fig. 4. Average mobile sum-energy consumption versus the fraction η of shared data in uplink and downlink and of shared

CPU cycles executed at the cloudlet.

described in Sec. II, while the input bits BI

k are transmitted by each user individually, i.e., we set BI

S,k = 0

and ∆BI

k = BI

k for all k ∈ K; and (ii) Shared Uplink Transmission: Only the input bits are shared

as discussed, while no sharing of computation and downlink transmission takes place, i.e., ∆Vk = Vk

and ∆BO

k = BO

k for all k ∈ K. We also include for reference the result obtained by solving problem

(P.1) using the global optimization BARON software running on NEOS server with a global optimality

tolerance of 10−6 [16]. As shown in Fig. 4, for Tmax = 0.05 s and η = 0.3, the Shared Cloudlet Processing

and Downlink Transmission scheme achieves energy saving about 37% compared to separate ofﬂoading

(which sets ∆BI

k = BI

k, ∆Vk = Vk and ∆BO

k = BO

k for all k ∈ K). This gain can be attributed to the

increased time available for uplink transmission due to the shorter execution and downlink transmission

periods, which reduces the associated ofﬂoading energy. Under the same conditions, the energy saving

of around 50% with respect to separate ofﬂoading brought by Shared Uplink Transmission is due to

the ability of the system to adjust the fractions of shared data transmitted by each user in the uplink

based on the current channel conditions. These two gains combine to yield the energy saving of the

11

proposed shared data ofﬂoading scheme with respect to the conventional separate ofﬂoading of around

63%. Both separate and shared ofﬂoading schemes have similar energy performance for the relaxed delay

requirement of Tmax = 0.15 s, which can be met with minimal mobile energy expenditure even without

sharing communication and computation resources. The ﬁgure also shows that SCA yields a solution that

is close to the global optimum, for this example.

REFERENCES

[1] D. Van Krevelen and R. Poelman, “A survey of augmented reality technologies, applications and

limitations,” International J. of Virtual Reality, vol. 9, no. 2, pp. 1–20, Jan. 2010.

[2] F. Liu et al., “Gearing resource-poor mobile devices with powerful clouds: architectures, challenges,

and applications,” IEEE Wireless Commun., vol. 20, no. 3, pp. 14–22, Jun. 2013.

[3] T. Verbelen et al., “Leveraging cloudlets for immersive collaborative applications,” IEEE Perv.

Comput., vol. 12, no. 4, pp. 30–38, Dec. 2013.

[4] S. Bohez et al., “Mobile, collaborative augmented reality using cloudlets,” in Proc. Mobilware,

Bologna, Italy, Nov. 2013.

[5] J. M. Chung et al., “Adaptive cloud ofﬂoading of augmented reality applications on smart devices

for minimum energy consumption,” KSII Trans. Internet Inf. Syst., vol. 9, no. 8, pp. 3090–3102,

Aug. 2015.

[6] M. Satyanarayanan et al., “The case for VM-based cloudlets in mobile computing,” IEEE Perv.

Comput., vol. 8, no. 4, pp. 14–23, Dec. 2009.

[7] A. Al-Shuwaili et al., “Joint uplink/downlink optimization for backhaul-limited mobile cloud

computing with user scheduling,” ArXiv preprints:1607.06521, Jul. 2016.

[8] S. Sardellitti et al., “Joint optimization of radio and computational resources for multicell mobile-

edge computing,” IEEE Trans. Signal Inf. Process. Net., vol. 1, no. 2, pp. 89–103, Jun. 2015.

12

[9] G. Scutari et al., “Parallel and distributed methods for constrained nonconvex optimization-part I:

Theory,” IEEE Trans. Signal Process., to appear, 2016. On-line: arXiv:1410.4754.

[10] L. Cannelli et al., “Asynchronous parallel algorithms for nonconvex big-data optimization. part II:

Complexity and numerical results,” arXiv preprint:1701.04900, Jan. 2017.

[11] S. Boyd and L. Vandenberghe, Convex optimization. Cambridge university press, 2004.

[12] 3GPP TR 36.814, “Technical speciﬁcation group radio access network; Further advancements for

E-UTRA, physical layer aspects,” Mar. 2010.

[13] F. Renna et al., “Query processing for the internet-of-things: Coupling of device energy consumption

and cloud infrastructure billing,” in Proc. IEEE IoTDI, Berlin, Germany, pp. 83-94, Apr. 2016.

[14] N. Balasubramanian et al., “Energy consumption in mobile phones: A measurement study and

implications for network applications,” in Proc. ACM SIGCOMM, Chicago, IL, pp. 280–293, Nov.

2009.

[15] A. Miettinen et al., “Energy efﬁciency of mobile clients in cloud computing,” in Proc. USENIX,

Boston, MA, USA, pp. 4-11, Jun. 2010.

[16] N. Sahinidis, “Baron for solving nonconvex optimization problems to global optimality,” Mar. 2017.

On-line: https://neos-server.org/neos/solvers/go:BARON/AMPL.html.

13

