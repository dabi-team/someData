Interacting with Acoustic Simulation and Fabrication

Dingzeyu Li
Columbia University
dli@cs.columbia.edu

7
1
0
2
c
e
D
4

]

C
H
.
s
c
[

2
v
5
9
8
2
0
.
8
0
7
1
:
v
i
X
r
a

Figure 1. (a) Interactively physics-based sound simulator helps artists try out different materials and auralize the results immediately. (b) An example
of Acoustic Voxels. By optimizing how the internal cavity ﬁlters sound waves, we can embed unique acoustic signatures in different models. (c) AirCode
invisible tags are designed with our physics-based light scattering tool. Here the tags not only identify the mug but also help estimate its pose, leading to
a successful robotic grasp.

ABSTRACT
Incorporating accurate physics-based simulation into interac-
tive design tools is challenging. However, adding the physics
accurately becomes crucial to several emerging technologies.
For example, in virtual/augmented reality (VR/AR) videos,
the faithful reproduction of surrounding audios is required
to bring the immersion to the next level. Similarly, as per-
sonal fabrication is made possible with accessible 3D printers,
more intuitive tools that respect the physical constraints can
help artists to prototype designs. One main hurdle is the sheer
amount of computation complexity to accurately reproduce the
real-world phenomena through physics-based simulation. In
my thesis research, I develop interactive tools that implement
efﬁcient physics-based simulation algorithms for automatic
optimization and intuitive user interaction.

ACM Classiﬁcation Keywords
H.5.m. Information Interfaces and Presentation (e.g. HCI):
Miscellaneous

Author Keywords
3D printing; computational fabrication; virtual reality;
interaction; design tools; physics-based simulation; audio;

INTRODUCTION
With the increasing accessibility of mixed reality devices and
consumer-level 3D printers, recent technology enables us to
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
UIST ’17 Adjunct, October 22–25, 2017, Quebec City, QC, Canada
© 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ISBN 978-1-4503-5419-6/17/10. . . $15.00
DOI: https://doi.org/10.1145/3131785.3131842

experience a more immersive virtual world as well as fabricate
personalized digital models. The immersion in virtual reality
(VR) and the interactions with personalized 3D models require
new design tools that respect the underlying physics to keep the
seamless immersion. For example, it is important to provide
accurate audio propagation in VR scenes in order to achieve
full immersion. My thesis research focuses on physics-based
design tools that help users achieve desired functionalities.

During the design process, interactive feedback is crucial,
since it not only gives a quick updated view for the edits but
also guides the trial-and-error improvement process. For non-
intuitive and sometimes complex physical phenomena, for
example, sound propagation or resonant chamber design, one
would usually resort to accurate and predictive simulations.
However, it is challenging to achieve interactive performance
while obtaining accurate simulation results. In my research, I
develop tools based on physical principles, augmenting design
tools with simulations.

My ﬁrst project is an interactive tool that allows the user to
explore different materials for animations and outputs synchro-
nized sounds accurately (Figure 1-a). I designed algorithms to
accelerate the computation for sound propagation and imple-
mented an efﬁcient runtime approximation scheme, achieving
realistic audio in virtual scenes. With previous methods, if
users want to listen to an updated sound with slightly different
material parameters (e.g. Young’s modulus), the computation
would take minutes or even longer. We validated our interac-
tive tool through numerical experiments and user studies [5].

Another area where physics-based tools are helpful is computa-
tional design for fabrication. Manipulating 3D geometry with
desired properties is difﬁcult since the relationship between
geometry and physical properties is very non-intuitive. Acous-
tic Voxels is a system that predicts and optimizes the internal

abc 
 
 
 
 
 
Figure 2. The key idea is to simplify mesh differently at different fre-
quencies. By carefully choosing the decimating parameters, my method
provides 10× speedup over naive computation while preserving the ac-
curacy of the wave propagation.

structure to meet the resonant frequency requirements [6].
This tool enables users to explore acoustic ﬁlters with different
shapes, creating musical instruments in unconventional shapes
and motivating new applications in data encoding (Figure 4,5).
Take the encoding idea one step further, I propose AirCode,
an unobtrusive tagging tool to design and embed small air
pockets beneath the surface [7]. These AirCode tags can be
3D printed easily without extra processing and detected using
our consumer-level camera system.

By exploring various tools for different design tasks, my thesis
aims to bring physics-based simulation into design tools. In
the following, I review related literature, present my research
projects on physics-based tools, and discuss future research
directions.

RELATED WORK
Two themes of existing research are mostly related to my pro-
posed area: (i) interactive design tools; and (ii) computational
design methods for personalized fabrication. Here I only dis-
cuss several representative projects among abundant literature
under these two themes.

Interactive Design Tools
To ease the design process, various interactive tools have been
proposed. For example, in order to add sensors into 3D printed
objects, Capricate designs custom-shaped sensors that ﬁt on
complex surfaces and automatically wire the underlying sen-
sors [9]. Another design tool, aeroMorph, focuses on simulat-
ing bending mechanism that creates shape-changing behaviors
with common materials, such as paper and plastics [8]. With
the interactive visualization, users receive feedbacks interac-
tively as they work on the design. This tool provides great
ﬂexibility for them, bypassing time-consuming traditional vali-
dation approaches which require repeated fabrication. Platener,
a low-ﬁdelity fabrication tool, shows users an interactive inter-
face with a global slider to deﬁne the ﬁdelity-speed trade-off,
making it easier to decide on fabrication ﬁdelity [1]. My goal
is to develop interactive tools and augment them with efﬁcient
physics-based simulations and optimization, providing more
accurate interactive feedback on complex problems.

Computational Design for Fabrication
To design custom-shaped geometries with more complex phys-
ical phenomena, ofﬂine computational optimization is usually
used in the design process. Digital Mechanical Metamaterials
proposes to embody mechanical movements into 3D printed
objects using a modular method [3]. Each of the modular cells

I designed and implemented an interactive sound editing
Figure 3.
interface. At runtime, an straightforward spline curve editor can be
used to edit the time-varying artistic effects. The sound propagation
is precomputed using efﬁcient physics-based simulation and evaluated
interactively at runtime.

is specially designed such that they can pass digital informa-
tion when connected together. Acoustruments introduced a
passive acoustic-based mechanisms for interactive controls on
smartphones [4]. Through carefully designed tube geometries
and materials, an expansive dataset of design primitives is
generated for easy construction. To reproduce physical hap-
tic interaction during fabrication, HapticPrint explores and
builds a library of various patterns to different types of compli-
ance [10]. While this type of research is a promising direction,
I would like to investigate how to better combine computa-
tional design with intuitive tools for the users.

MY THESIS RESEARCH
My research lies mainly at the intersection of physics-based
simulation and interactive tools for computational designs. I
have focused on developing efﬁcient algorithms that lead to
interactive tools for non-intuitive functional requirements.

Interactive Material-based Sound Editing
Accurate audio in virtual reality is crucial for a fully immer-
sive experience. To edit virtual sounds from physics-based
simulation, current sound models compute the modal vibra-
tions and solve for the wave propagation at these vibration
frequencies. Figure 1-(a) shows some representative materials.
During the interaction, whenever the user tweaks material pa-
rameters, the modal vibration frequencies changes completely.
At these new modal frequencies, expensive recomputation of
sound propagation is required. In my research, I developed a
new system to speed up the computation, enabling interactive
and continuous editing as well as the exploration of material
parameters [5].

One of our key contributions is an efﬁcient precomputation
method for sound pressure ﬁelds. Since precomputation is
needed over a frequency range, the main bottleneck becomes
the numerical solves of the wave equation. It is known that
the complexity of these depend on the number of surface
elements N. The smaller N is, the faster computation can be.
The element size is bounded by the wavelengths at different
frequencies. Intuitively, the idea is to use coarser mesh while
preserving the accuracy of the solves (Figure 2).

The uniqueness of our work lies in the interactive material
editing interface where the users can freely explore at runtime,
as shown in Figure 3. Our tool allows for interactive preview

lower frequencycoarser meshfrequency-aware mesh simplificationhigher frequencyfiner meshAnimation ViewerCurve EditorSpectrogram ViewerFigure 4. Acoustic Voxels help prototype wind instruments in unconven-
tional shapes by efﬁciently optimizing internal shapes, as shown in the
top row. Provided with the desired pitches, our tool can generate a 3D
mesh ready for printing. The recorded spectrogram at the bottom right
shows the efﬁcacy of our design tool.

of the synchronized simulated sound that reﬂects the user
editing. The fast iteration enables users to explore artistic
sound effects interactively which would take minutes using
naive implementation.

Acoustic Voxels: Efﬁcient Computational Fabrication
Acoustic ﬁlters have numerous important applications,
whether to produce a desired sound pitch or to attenuate unde-
sired noise. The applications range from wind instruments to
mufﬂers and hearing aids. When sound waves pass through
a cavity, the ﬁltered frequencies are largely affected by the
shape of the cavity. However, for all but the simplest cavity
shapes, the inﬂuence of the shape on the ﬁltered frequency
bands is complicated and unintuitive.

I developed Acoustic Voxels, a computational tool that builds
complex cavity shapes from basic shape primitives. The assem-
bled cavity will produce the desired acoustic ﬁltering effects.
I proposed a modular scheme which not only simpliﬁes the
precomputation process on the primitive shapes but also dras-
tically speeds up the design process. Since typical numerical
simulations scale nonlinearly with the number of elements, to
predict the ﬁltering behavior of a complex shape, it might take
hours to simulate. I demonstrated that the solving time in the
proposed reduced design space can be reduced to seconds.

I also presented a number of applications including wind in-
strument prototyping, acoustic tagging, and acoustic encod-
ing [6]. Figure 4 illustrates a prototype wind instrument in a
hippo shape, enabled by our efﬁcient and accurate simulation
tool. Figure 1-b shows an example where we tagged piggy
with desired acoustic signature which can be detected via tap-
ping on the nose. Taking tagging one step further, Figure 5
demonstrates the potential to encode data in the acoustic ﬁlter-
ing process. Acoustic Voxels makes all these designs possible
by utilizing efﬁcient physics-based simulation, freeing users
from dealing with non-intuitive physical requirements.

AirCode: Unobtrusive Tagging for 3D Printing
Motivated by the acoustic tagging application, I am interested
in unobtrusive ways to embed tags since acoustic ﬁlters require
one inlet and one outlet (see the bottom of the octopus). Taking

Figure 5.
Example of acoustic encoding. Acoustic Voxels optimizes
and embeds voxels in the octopus. When interacting with an iPhone, the
iPhone app detects the encoded 4-bit binary data.

advantages of subsurface scattering, I propose AirCode, an
unobtrusive tagging tool for 3D printed objects. As illustrated
in Figure 6, the key idea is simply placing thin air pockets
under the surface of 3D printed objects. Air changes how light
is scattered after penetrating the material surface. Most plastic
3D printing materials, even those considered opaque, scatter
light. The amount of light penetrating and scattered is often
weak and most of the light is directly reﬂected at the surface.
Consequently, the effects of air pockets on appearance can be
made imperceptible to our eyes. The scattered light can be
separated out with a computational imaging method.

AirCode helps determine the shapes and positions of sub-
surface air pockets to encode useful information at a user-
speciﬁed smooth region. Intuitively, if the air pockets are very
close to the surface, they are no longer imperceptible to hu-
man vision. On the other hand, if the air pockets are put too
deep to be discernible with an imaging system, it is impossi-
ble to extract and decode the embedded tags. Combining the
rendering algorithms and statistics from perception studies, I
designed a method to estimate a range of depths that satisﬁes
our requirements.

One straightforward application is to embed tags and metadata.
In Figure 7, an invisible tag is embedded in the statue and
revealed under computational imaging system, leading to a
webpage with more details. The embedded tag can not only
provide additional metadata and digital identiﬁcation but also
help estimate the pose of the object [7], which becomes very
helpful for robotic grasping. If an object embeds AirCode tags,
the camera system of a robotic manipulator can recognize the
object and retrieve its complete 3D model by reading the tags.
More remarkably, the located tags further allow the system to
estimate the object pose with respect to the camera. With all
the information, the robot gathers sufﬁcient knowledge for a
successful grasp.

FUTURE WORK:

INTERACTIVE PHYSICS-BASED DESIGN TOOLS
To further integrate accurate simulation with interactive tools,
there are a few directions that I want to explore. First, I
would like to work on high-ﬁdelity sound simulations that
run at interactive rate. Some of my past research has focused

400 Hz200 Hz   105   106   107   108600 Hz800HzimpedanceG4: 390Hz467Hz556Hz652HzBb4:E5: C#5:G4pedal noteBb4C#5E5Transmiision Loss (dB)1000 Hz2000 Hz3000 Hz304020100111for most FDM printers, the layer height is also an important
parameter that has been largely overlooked. I wish to build
interactive tools that shows how this parameter affects printing
time and the strength of printed models. Furthermore, it is
interesting to investigate how to embed information in varying
layer heights. I look forward to more interactive physics-based
tools that can enable more creative and functional designs.

ACKNOWLEDGMENTS
I would like to thank my advisor Changxi Zheng for his sup-
port and mentorship. This research was funded in part by the
NSF CAREER-1453101 and donations from Adobe and Intel.
Dingzeyu Li was partially supported by a Shapeways EDU
Grant and an Adobe Research Fellowship.

REFERENCES

1. Dustin Beyer, Seraﬁma Gurevich, Stefanie Müller,

Hsiang-Ting Chen, and Patrick Baudisch. 2015. Platener:
Low-Fidelity Fabrication of 3D Objects by Substituting
3D Print with Laser-Cut Plates. In CHI 2015.

2. Gabriel Cirio, Dingzeyu Li, Eitan Grinspun, Miguel A.
Otaduy, and Changxi Zheng. 2016. Crumpling Sound
Synthesis. ACM Trans. Graph. (SIGGRAPH Asia) (2016).

3. Alexandra Ion, Ludwig Wall, Robert Kovacs, and Patrick
Baudisch. 2017. Digital Mechanical Metamaterials. In
CHI 2017.

4. Gierad Laput, Eric Brockmeyer, Scott E Hudson, and

Chris Harrison. 2015. Acoustruments: Passive,
Acoustically-Driven, Interactive Controls for Handheld
Devices. In CHI 2015.

5. Dingzeyu Li, Yun Fei, and Changxi Zheng. 2015.

Interactive Acoustic Transfer Approximation for Modal
Sound. ACM Trans. Graph. (SIGGRAPH) (2015).

6. Dingzeyu Li, David I.W. Levin, Wojciech Matusik, and
Changxi Zheng. 2016. Acoustic Voxels: Computational
Optimization of Modular Acoustic Filters. ACM Trans.
Graph. (SIGGRAPH) (2016).

7. Dingzeyu Li, Avinash S. Nair, Shree K. Nayar, and

Changxi Zheng. 2017. AirCode: Unobtrusive Physical
Tags for Digital Fabrication. In UIST 2017 (to appear).

8. Jifei Ou, Mélina Skouras, Nikolaos Vlavianos, Felix

Heibeck, Chin-Yi Cheng, Jannik Peters, and Hiroshi Ishii.
2016. aeroMorph - Heat-sealing Inﬂatable Shape-change
Materials for Interaction Design. In UIST 2016.

9. Martin Schmitz, Mohammadreza Khalilbeigi, Matthias
Balwierz, Roman Lissermann, Max Mühlhäuser, and
Jürgen Steimle. 2015. Capricate: A Fabrication Pipeline
to Design and 3D Print Capacitive Touch Sensors for
Interactive Objects. In UIST 2015.

10. César Torres, Tim Campbell, Neil Kumar, and Eric

Paulos. 2015. HapticPrint: Designing Feel Aesthetics for
Digital Fabrication. In UIST 2015.

11. Yin Yang, Dingzeyu Li, Weiwei Xu, Yuan Tian, and

Changxi Zheng. 2015. Expediting Precomputation for
Reduced Deformable Simulation. ACM Trans. Graph.
(SIGGRAPH Asia) (2015).

Figure 6. Key idea: Most plastic 3D printing materials exhibit strong
subsurface scattering. Light rays (green) that are reﬂected by the sur-
face represent the direct component; rays (orange) that enter the surface
and are scattered within before leaving the surface result in the global
component. A structured change in the material that lies beneath the
surface only affects the global component of a captured image.

on the high-quality sounds. For example, we can simulate
crumpling sounds when crushing a soda can or unwrapping
a candy wrap on powerful machines in the order of minutes
or hours [2]. Our work on efﬁcient precomputation is a step
towards more efﬁcient simulations [11]. I believe a general
interactive pipeline that supports physics-based simulation can
bring the audio editing and design to the next level.

I am also interested in bringing rich statistics from recorded
audios into simulations. More speciﬁcally, I think a hybrid
method between physics-based algorithms and data-driven
statistics is a promising research area. For a fully immersive
virtual environment, while simulations can supply most of the
surrounding audios, there are certain subtle effects that are
hard to simulate well. For example, realistic room acoustic
effects for indoor and natural ambient sounds for outdoor
scenes. To this end, data-driven methods can ﬁll in the gap by
augmenting simulated results with rich and real statistics from
recordings. I think combining these two themes of methods
can further improve the quality of VR audio.

In my past research fabrication projects, I mainly focused
on how to embed metadata or tags in a given 3D geometry
through computational optimization. The use of physics-based
simulation greatly eases the design process for the users. In the
future, I would like to explore more on the computational side
of fabrication, bringing more intuitive tools for ordinary users.
One idea is to use properties that are speciﬁc to certain printing
processes. In AirCode project, I exploited the optical trans-
parency in PolyJet printing material to embed tags. However,

Figure 7. AirCode designs and embeds optimized air pockets beneath
the surface. The fabricated model has the tag invisible under normal en-
vironmental lighting. The tag can be retrieved using our imaging system
that separates out the scattering effects. In this example, we embedded
a web link of the statue.

ProjectorCameraAir pocketgoo.gl/1ph6g2