ISSN 1172-496X (Print)
ISSN 1172-4234

(Online)

TECHNICAL REPORTS from the ELECTRONICS GROUP
at the UNIVERSITY of OTAGO

Metropolis-Hastings algorithms with autoregressive proposals,
and a few examples

by

Richard A. Norton, Colin Fox

ELECTRONICS TECHNICAL
REPORT No. 2016-1

UNIVERSITY of OTAGO
DUNEDIN, NEW ZEALAND

6
1
0
2

y
a
M
9
1

]

O
C

.
t
a
t
s
[

2
v
1
4
4
5
0
.
5
0
6
1
:
v
i
X
r
a

Online version has URL: http://www.physics.otago.ac.nz/reports/electronics/ETR2016-1.pdf
E-mail: richard.norton@otago.ac.nz
Address: Physics Department, University of Otago, P.O. Box 56, Dunedin, New Zealand

 
 
 
 
 
 
Electronics Group at Otago

In 1987 Millman and Grabel discarded the historical deﬁnition of ‘electronics’ as the
science and technology of the motion of charges, preferring instead the operational
deﬁnition that the primary concern of people doing electronics is information process-
ing. This makes a distinction from energy processing practiced in the rest of electrical
engineering. The act of information processing is what gets electronics practicioners
invloved in the fours ‘C’s: communication, computation, control, and components. This
practical deﬁnition seems to describe well the activities within the Electronics Group
in the Physics Department at the University of Otago, and the range of topics covered
in this technical report series.

In May 2016, research within the Electronics Group include projects applying infer-
ence algorithms to embedded sensors, on lightweight GPS tags for birds, modelling
and control of a robotic elbow, design and deployment of an under-sea glider, analysis
of networks of random resistors, electrical impedance imaging, calibration of numeri-
cal models for geothermal ﬁelds using Bayesian inference, modelling and sampling of
Gaussian processes, and efﬁcient algorithms for Markov chain Monte Carlo applied to
inverse problems.

Citing this Report

This report should be cited as:

Richard A. Norton and Colin Fox, “Metropolis-Hastings algorithms with
autoregressive proposals, and a few examples”, Electronics Technical Re-
ports No. 2016-1, ISSN 1172-496X, May 2016.

Alternatively, using BibTeX, as:

Metropolis-Hastings algorithms with autoregressive
,

Richard A. Norton and Colin Fox
Technical Reports from the Electronics Group at the

,

}

}}

University of Otago
1172-496X (Print) 1172-4234 (Online)

}}

,

,

{
http://www.physics.otago.ac.nz/reports/electronics/ETR2016-1.pdf
}

}

,

{

{{

{
{

etr2016-1,

@techreport
title
proposals, and a few examples
author=
series=
University of Otago
institution=
issn=
url=
number=
date

May 2016

2016-1

{{

,

}

{

{

,
}
} }

{

Metropolis-Hastings algorithms with autoregressive proposals,
and a few examples

Richard A. Norton & Colin Fox

Abstract

We analyse computational eﬃciency of Metropolis-Hastings algorithms with stochastic AR(1)
process proposals. These proposals include, as a subclass, discretized Langevin diﬀusion (e.g.
MALA) and discretized Hamiltonian dynamics (e.g. HMC).

We derive expressions for the expected acceptance rate and expected jump size for MCMC
methods with general stochastic AR(1) process proposals for the case where the target distri-
bution is absolutely continuous with respect to a Gaussian and the covariance of the Gaussian
is allowed to have oﬀ-diagonal terms. This allows us to extend what is known about several
MCMC methods as well as determining the eﬃciency of new MCMC methods of this type. In
the special case of Hybrid Monte Carlo, we can determine the optimal integration time and the
eﬀect of the choice of mass matrix.

By including the eﬀect of Metropolis-Hastings we also extend results by Fox and Parker, who
used matrix splitting techniques to analyse the performance and improve eﬃciency of stochastic
AR(1) processes for sampling from Gaussian distributions.

1

2

Contents

1 Introduction

2 Preliminary results and notation

5

11

2.1 Stochastic AR(1) processes correspond to matrix splittings . . . . . . . . . . . . . . . . . . . 11

2.2 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12

3 Gaussian targets

13

3.1 Expected acceptance rate for a Gaussian target . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

3.2 Expected squared jump size for a Gaussian target . . . . . . . . . . . . . . . . . . . . . . . . . . 16

4 Non-Gaussian targets

19

4.1 Expected acceptance rate for a non-Gaussian target . . . . . . . . . . . . . . . . . . . . . . . . 19

4.2 Expected jumpsize for non-Gaussian target . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25

5 Examples

27

5.1 Discretized Langevin diﬀusion - MALA and SLA . . . . . . . . . . . . . . . . . . . . . . . . . . . 27

5.2 Discretized Langevin diﬀusion - more general algorithms . . . . . . . . . . . . . . . . . . . . . 29

5.3 L-step methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31

5.4 Hybrid Monte Carlo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34

6 Concluding remarks

Appendix

A Proofs

39

41

A.1 Proof of Lemma 3.1.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

A.1.1 Proof of Lemma 3.2.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

A.2 Proof of Theorem 5.2.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

3

A.3 Proof of Lemma 5.3.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43

A.4 Proof of Theorem 5.3.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44

A.5 Proof of Theorem 5.4.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45

A.6 Proof of Corollary 5.4.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45

A.7 Proof of Theorem 5.4.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46

A.8 Proof of Theorem 5.4.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47

4

Chapter 1

Introduction

We consider Metropolis-Hastings (MH) algorithms for sampling from a target distribution πd
Rd is
using a stochastic AR(1) process proposal; given current state x
given by

Rd the proposal y

∈

∈

y = Gx + g + ν

(1.1)

×

∈

Rd

d is the iteration matrix, g

Rd is a ﬁxed vector and ν is an independent and
where G
identically distributed (i.i.d.) draw from N(0, Σ). In general, G, g and Σ may depend on x. We
will refer to (1.1) as an AR(1) proposal or stochastic AR(1) proposal. The proposal is accepted
with probability

∈

α(x, y) = 1

πd(y)q(y, x)
πd(x)q(x, y)

∧

where πd(x) denotes the target probability density function, q(x, dy) = q(x, y)dy is the transition
kernel for the proposal y given current state x, and p

q = min

∧

p, q
{

.
}

Algorithms using AR(1) proposals include: the random-walk Metropolis algorithm (RWM)
[29], the simpliﬁed Langevin algorithm (SLA) [9], the so-called θ-SLA method [9], preconditioned
versions of RWM and SLA [9], and the Crank-Nicolson (CN) and preconditioned Crank-Nicolson
(pCN) proposals [15]. When the target distribution is Gaussian, then the Metropolis-adjusted
Langevin algorithm (MALA) [30] and the Hybrid Monte Carlo algorithm (HMC) [16, 6, 26] can
also be written in the form of (1.1), and MALA is the same as SLA. For any target distribution,
one step of HMC is the same as MALA [6].

Analysis of these Markov chain Monte Carlo (MCMC) methods is almost exclusively limited
to the case when the target distribution πd is a change of measure from a reference product
distribution so that

dπd
d˜πd

(x) = exp(

−

φd(x))

for some φd : Rd

7→

R where ˜πd is a product distribution of the form

d

˜πd(x) =

λif (λixi)

for some f : R
approximations of inﬁnite-dimensional measures π and ˜π satisfying dπ
state space.

R and sequence

d
i=1 ⊂

λi}
{

7→

Yi=1
R. We can view πd and ˜πd as ﬁnite-dimensional
φ(x)) on some

d˜π (x) = exp(

−

Examples of inverse problems that yield posterior distributions of this form can be found in

[34, 9, 8].

5

(1.2)

(1.3)

→ ∞

. Of which the d

Analysis of MH algorithms with AR(1) proposals is also typically limited to the cases when
d = 1 or d
case is more important because it is used as an
approximation for the practical computational problem when d is large but ﬁnite. Precisely
what is meant by ‘large’ is problem dependent. For example, [30,
3] demonstrates that for
§
x2/2) and λi = 1, then d = 5 is large, but if f is non-
exp(
MALA with φd = 0, f (x)
symmetric then large d is greater than 10.

→ ∞

−

∝

→ ∞

Analyses of RWM and MALA began with the case when φ = 0 and λi = 1 for all i (so that
πd has product form with i.i.d. components) based on discretizations of a Langevin diﬀusion
process. Roberts, Gelman and Gilks [29] for RWM and then Roberts and Rosenthal [30] for
MALA showed that as d
, the ﬁrst component of the Markov chain converges to a Langevin
diﬀusion process and the ‘speed’ of the diﬀusion process is maximised when the acceptance rate
is 0.234 for RWM and 0.574 for MALA. This is equivalent to maximising the expected squared
= 1 for RWM and
jump size of the Markov chain. The non i.i.d. cases when φ = 0 and λi 6
MALA are subsequently treated in [31, 3, 4, 5].
In these articles it is noted that while the
optimal acceptance rate for RWM and MALA remains the same, the expected jump size of
RWM decreases as the l2-norm of the sequence
increases, while MALA depends on the
l6-norm. An ‘inhomogeneous’ RWM proposal is also considered in [3], which is what we will call
‘preconditioning’. In [5], it is also noted that their results also hold when the target distribution
is a multivariate normal whatever the covariance matrix since orthogonal transformations can
transform the target to one with independent components. We will exploit this fact throughout
this article. A non-product form of target for RWM is considered in [14].

λi}
{

The case of RWM and SLA (a simpliﬁed version of MALA) for non-product target distribu-
= 0, is considered in [9]. The optimal acceptance rates remain 0.234 for RWM
λi}∞i=1. Again, the
{
. It is also

tions, when φ
and 0.574 for SLA (same as MALA), under certain conditions on φd and
expected jump sizes for these algorithms decrease with the l2- and l6-norms of
suggested how to precondition the RWM and SLA proposals in [9].

λi}
{

HMC was analysed in [6] for the case when the target distribution has product form with
i.i.d. components. Similarly to the analyses of RWM, MALA and SLA, the authors of [6] showed
that the expected squared jump size for HMC is maximised when the acceptance rate is 0.651,
(d1/4) steps to traverse state space. This compares favourably with
and this corresponds to
(d1/3) steps respectively for the same problem, but
RWM and MALA which require
still blows up as d

(d) and

O

O

O

.

→ ∞

More recent analyses has shown that some methods can be modiﬁed so they are well-deﬁned
, the methods achieve
in the inﬁnite-dimensional function space setting, so in the limit as d
(1) steps are required to traverse
a positive acceptance rate without zero step size and only
state space. This requires modifying the proposals by ‘preconditioning’ and/or a coordinate
transformation. For example, in the case when the target is a change of measure from a Gaussian
reference measure, when

→ ∞

O

˜πd(x)

∝

exp

−

(cid:18)
Rd

1
2

xT Ax + bT x

,

(cid:19)

(1.4)

Rd, the CN and pCN proposals
for symmetric positive deﬁnite matrix A
are analysed in [15], and a variant of HMC is analysed in [7]. Other examples of this approach
include [8, 10, 28]. Another way to view preconditioning of MALA and HMC is given by [20].

d and vector b

∈

∈

×

In pCN and the variant of HMC in [7] it is necessary to draw independent samples from
1) or compute a spectral decomposition of A which eﬀectively transforms the reference

N(0, A−

6

6
measure to a product distribution; both of which could be computationally infeasible when d is
1 for some t > 0 is required per iteration of the Markov
large. In CN, the action of (I + tA)−
chain, see [15], which may be expensive to compute.

The results in [9], where ˜πd has product form, easily extend to the case where ˜πd is Gaussian
(1.4) where A may have non-zero oﬀ-diagonal terms. This is obvious once we recognise that the
Markov chains for RWM and SLA are invariant to orthogonal coordinate transformations. That
is, there exists an orthogonal coordinate transformation that diagonalizes the covariance matrix
of πd and G and Σ in (1.1), see e.g. Lemma 3.1.2. It is important to note that it is not necessary
to compute the orthogonal transformation, as it is enough to simply know that it exists, and
the eﬃciency of the untransformed Markov chain is identical to the transformed chain.

We will extend this idea to MH algorithms with general AR(1) proposals where G and Σ
are functions of A, targeting distributions that are either Gaussian, or a change of measure
from a reference Gaussian distribution (1.4). In particular, the Gaussian reference distribution
is allowed to have oﬀ-diagonal terms so it is not restricted to product form.

Therefore, we extend the study of MH algorithms with particular AR(1) proposals to general
AR(1) proposals where G and Σ are functions of the reference precision matrix A. We also extend
the study of MH algorithms with AR(1) proposals targeting distributions deﬁned by (1.2) and
(1.3) to target distributions deﬁned by (1.2) and (1.4) where A may have oﬀ-diagonal terms.

Another important feature of this analysis is that the proposals do not necessarily require
1) or N(0, A), multiplying by A1/2 or A−
1/2, or computing a
independent samples from N(0, A−
1; even though we use the existence of a spectral decomposition
spectral decomposition of A or A−
of A for theoretical purposes. This fact separates this new theory from previous theory for CN,
pCN and HMC in [15, 7], where these proposals include operations that may be computationally
infeasible in high dimensions.

By generalising the results in [9, 6] under some assumptions, we calculate limits for the ex-
pected acceptance rate and expected squared jump size for MH algorithms with AR(1) proposals
. We can then decide on the eﬃciency of a method based on expected jump size and
as d
the computing cost for each proposal.

→ ∞

Our new theory encompasses existing MCMC methods with AR(1) proposals, which are now
special cases for our theory, and we can extend the results that are currently available for SLA,
HMC, θ-SLA, and preconditioned versions of these MCMC methods, see Section 5. In the case
of HMC for a Gaussian target, we are no longer restricted, as in [6], to an i.i.d. product target,
and we now have criteria for how to choose the mass matrix (preconditioner) and the total time
to integrate the Hamiltonian system. Previous analyses of HMC only provided guidance on
tuning the time step until the acceptance rate is 0.651.

We can also apply our new theory to new MCMC methods. For example we can analyse an
MCMC method where the proposal is L steps of the SLA proposal before accepting or rejecting.
We show that for any L, the step size should be tuned until the acceptance rate is 0.574, the
same as MALA and SLA, and when the computing cost is dominated by matrix-vector products
with A, then it is optimal to use L > 1. Moreover, as the cost of evaluating φd increases, so
does the optimal choice of L.

Our analysis relies on the theory of matrix splitting which originated in numerical linear
algebra for iteratively solving linear systems of equations [2], but has since been applied to

7

sampling from Gaussian distributions [17, 19, 18]. As we will see in Section 2.1, if the spectral
radius of G is less than 1, then it is possible to rewrite (1.1) in terms of a matrix splitting of a
, which is not equal to A in general. By deﬁning splitting matrices M and N such that
matrix
N then y from (1.1) satisﬁes
= M

A
−

A

M y = N x + β + ν

(1.5)

1(M T + N )M −

1β and Σ =
where β is a vector, ν is an i.i.d. draw from N(0, M T + N ), G = M −
T . The converse statement, y satisﬁes (1.1) if y satisﬁes (1.5), only requires
M −
1 exists. Moreover, if the spectral radius of G is less than 1, then the Markov chain
that M −
1),
generated by (1.1) or (1.5) without the MH accept/reject step, will converge to N(
which we call the proposal limit distribution, see [19]. We call this Markov chain the proposal
chain.

1N , g = M −

A−

A−

1β,

Fox and Parker [19] realised that Gibbs sampling from a Gaussian N(

1) is very
A−
closely related to the Gauss-Seidel iterative solution to a linear system of equations
x = β,
A
N ; M = L+D
and that Gauss-Seidel and Gibbs sampling use the same matrix splitting
and N = U where L, D and U are the strictly lower triangular, diagonal, and upper triangular
parts of
respectively. A generalisation of this observation is that all proposal chains generated
by (1.5) are generalised ﬁxed-scan Gibbs samplers for a Gaussian.

= M

A−

1β,

A

A

−

If (1.1) or (1.5) is a proposal for the MH algorithm then the transition kernel changes from
that of the proposal chain and we cannot use the theory in [19] to determine its convergence
properties. Moreover, acceleration techniques suggested in [18, 19] for the proposal chain may
not accelerate the MH algorithm. For example, Goodman and Sokal [21] accelerated Gibbs
sampling of normal distributions using ideas from multigrid linear solvers, but only observed
modest eﬃciency gains in their non-normal examples (exponential distributions with fourth
moments). Also, Green and Han [22] applied successive-over-relaxation to a local Gaussian
approximation of a non-Gaussian target distribution as a proposal for the MH algorithm. Again,
they did not observe signiﬁcant acceleration in the non-normal target case.

This article is useful for designing eﬃcient MCMC methods because it shows how the ex-
pected squared jump size depends on the eigenvalues of G and the diﬀerence between the pro-
1). Generally, an eﬃcient MH
posal limit N(
algorithm with an AR(1) proposal should satisfy:

1) and the target reference N(A−

1b, A−

A−

A−

1β,

1.

A

= A and β = b or have small diﬀerences.

2. The spectral radius of G should be bounded well below 1.

3. The proposal should be cheap to compute, i.e. multiplying by G or M −
sampling from N(0, Σ) or N(0, M T + N ) should be cheap to compute.

1 and independent

In addition to providing these ‘rules of thumb’, we have quantiﬁed the eﬀect of the eigenvalues
1b and
of G, the diﬀerence between the eigenvalues of A and
A−

, and the diﬀerence between A−

1β.

A

Our long-term goal is to construct an AR(1) proposal for the MH algorithm based on local
Gaussian approximations to the target πd, using ideas in this article. For example, we might
x + βT x is a local quadratic approximation to log πd, and then
choose A and b such that
= A and β = b and the proposal is cheap to
choose M and N to deﬁne a proposal such that

1
2 xT

A

−

A

8

compute. To a certain extent, choosing A and b to obtain a local quadratic approximation to
log πd mimics the design of some optimization algorithms, see e.g. [27], so optimization theory
could be a source of inspiration for designing sampling algorithms.

Our analysis is limited to cases where M and N are functions of A. This allows us to
simultaneously diagonalise both the AR(1) proposal and the target reference distribution with
a coordinate transformation and deﬁne a parallel Markov chain (that we never compute with)
such that it has the same convergence properties as the original. This is not an overly restrictive
condition if the dimension is high enough to make a spectral decomposition of A impractical
to compute. We will see below that it includes several important examples of MH algorithms
already in use.

The remaining sections are as follows.

In Section 2.1 we show that (1.1) and (1.5) are
equivalent, then Section 3 presents new analyses for the expected acceptance rate and jump
size of MH algorithms with AR(1) proposals when the target distribution is Gaussian (φd = 0).
We then extend these results to the non-Gaussian case in Section 4. Section 5 then applies
this new analysis to proposals from Langevin diﬀusion and Hamiltonian dynamics. We see that
these proposals are AR(1) proposals and we identify the corresponding matrix splitting and
proposal limit distribution. Using our earlier analysis we assess the convergence properties of
. We provide concluding remarks in Section 6. Several proofs have
these methods as d
been moved to the Appendix to improve readability.

→ ∞

9

10

Chapter 2

Preliminary results and notation

2.1 Stochastic AR(1) processes correspond to matrix splittings

We can express a stochastic AR(1) process using either (1.1) or (1.5), provided it converges.

Theorem 2.1.1 If we are given G, g and Σ, and the spectral radius of G is less than 1, then
the stochastic AR(1) process (1.1) can be written as (1.5) using

=

A

∞

Xl=0

GlΣ(GT )l

1

−

!

and

M =

N =

(I

(I

A

A

−

−

G)−

G)−

1,
1G,

β =

(I

A

−

G)−

1g.

Note that

= M

A

−

N is symmetric and positive deﬁnite (spd).

(2.1)

(2.2)

Proof. Since the spectral radius of G is less than 1 and Σ is spd, it follows that

∞l=0 GlΣ(GT )l is well-deﬁned and spd. Then (2.1) and (2.2) satisfy
1(M T + N )M −

1β. We must also check that Σ = M −
T we get
1(M T + N )M −

and g = M −
P
(2.2) into M −

1 :=
1N
T is satisﬁed. Substituting

N , G = M −

= M

A−

A

−

M −

1(M T + N )M −

T = (I

G)

−

A
G

1 + G
1GT

−

A

−
1
−

1GT

−

=

=

A
∞

−
A
GlΣ(GT )l

GlΣ(GT )l

−

∞

Xl=1

Xl=0
= Σ.

If we are given M , N and β, and M −

1 exists, then it is obvious that if y satisﬁes (1.5), then

y satisﬁes (1.1) with G = M −

1N , g = M −

1β and Σ = M −

1(M T + N )M −

T .

We also remark that Theorem 2.1.1 does not apply to RWM since G = I for RWM.

In the following special case we obtain a symmetric matrix splitting.

11

 
Corollary 2.1.1 If the spectral radius of G is less than 1 and GΣ is symmetric, then the
stochastic AR(1) process (1.1) has a corresponding matrix splitting deﬁned by

M = Σ−

1(I + G),

N = M G = Σ−

1(I + G)G,

= M (I

A
β = M g = Σ−

−

G) = Σ−

1(I
1(I + G)g,

−

G2),

and M and N are symmetric (we say the matrix splitting is symmetric).

Proof. These matrix splitting formulae follow from the identity

GlΣ(GT )l =

∞

Xl=0

∞

Xl=0

G2lΣ = (I

G2)−

1Σ.

−

To see that M is symmetric (and hence also N since
that

A

is symmetric and

= M

A

−

N ) we note

M =

(I

G)

−

∞

G2lΣ

Xl=0

2.2 Notation

1

−

.

!

Throughout the remainder of this article we will use the following notation. Let Gi, λ2
respectively. Also deﬁne
be eigenvalues of G, A and

i and ˜λ2

i

A

gi := 1

,

˜ri :=

˜gi := 1

Gi,
˜λ2
i

−
λ2
i −
λ2
i

ri :=

and

G2
i ,

mi := (A−

1b)i,

˜mi := (

A

1β)i,

−

ˆri := mi −

˜mi

−
λ2
i
˜λ2
i

,

T0i := ˆr2
T3i := 1

i λ2
i ( 1
2 rigi,

2 rigi −

˜gi),

T1i := ˆriλi(rigi −
1
2 ri˜rigi,
T4i :=
−

˜gi),

T2i := ˆriλi(˜rigi)1/2(1
−
riGi(˜rigi)1/2.
T5i :=

−

riGi),

In general, all of these quantities may depend on d. The standard normal cumulative distribution
function will always be Φ.

We will say that fd,i =

if for all i and all suﬃciently large
d, fd,i/gd,i is bounded by a constant that is independent of d and i. Likewise, fd,i = o(gd,i)
(uniformly in i) as d
. For brevity we will sometimes
omit “uniformly in i”.

(gd,i) (uniformly in i) as d

d fd,i/gd,i →

if max1

0 as d

→ ∞

→ ∞

→ ∞

O

≤

≤

i

Other articles use λ2

i to denote the eigenvalues of the covariance matrix corresponding to
˜πd [9, 11, 10, 7]. We do not follow this convention and instead use λ2
i to denote eigenvalues of
1) is equivalent to solving
1b, A−
the precision matrix. Since sampling from the Gaussian N (A−
the linear system Ax = b (see [17, 18, 19]), our notation aligns with literature on solving linear
systems.

12

 
Chapter 3

Gaussian targets

3.1 Expected acceptance rate for a Gaussian target

The expected acceptance rate is a quantity that is related to eﬃciency and for optimal perfor-
mance the proposal is usually tuned so that the observed average acceptance rate is between
0 and 1. For example, it has been shown, for particular target distributions, in the case when
d
, that 0.234 is optimal for RWM [29], 0.574 is optimal for MALA [30] and SLA [9], and
0.651 is optimal for HMC [6]. All of these results required expressions for the expected acceptance
. Here we derive an expression for the expected acceptance rate
rate of the algorithm as d
1), provided
for a MH algorithm with an AR(1) proposal (1.5) and Gaussian target N(A−
the splitting matrices are functions of A. Thus, our MH algorithm is deﬁned by

1b, A−

→ ∞

→ ∞

Target:

N(A−

1b, A−

1),

Proposal:

y = Gx + M −

1β + (

A

1

−

G

1GT )1/2ξ,

−

A

−
1(M T + N )M −

(3.1)

1GT
where ξ
[18, Lem. 2.3]. The following lemma is a result of simple algebra. The proof is in the Appendix.

N(0, I), and we have used G = M −

1N and M −

T =

A−

A−

G

−

∼

1

Lemma 3.1.1 Suppose
for (3.1) satisﬁes

A

= M

−

N is a symmetric splitting. Then the acceptance probability

α(x, y) = 1

exp

∧

1
2

−

(cid:18)

yT (A

)y +

− A

xT (A

1
2

− A

)x + (b

β)T (y

−

−

x)

.

(cid:19)

Since A is real and symmetric, we can deﬁne a spectral decomposition

A = QΛQT

Rd

d is orthogonal and Λ = diag(λ2

d) is a diagonal matrix of eigenvalues of
where Q
A. Although we may not be able to compute Q and Λ this does not stop us from using the
existence of a spectral decomposition for theory. Simple algebra gives us the following result.

1, . . . , λ2

∈

×

Lemma 3.1.2 Suppose M = M (A) and N = N (A) are functions of A. Then G and
functions of A and under the coordinate transformation

A

are also

QT x

x

↔

the MH algorithm (3.1) is transformed to a MH algorithm deﬁned by

Target:

N(Λ−

1QT b, Λ−

1),

Proposal:

y = Gx + M (Λ)−

1QT β + (˜Λ−

1

G˜Λ−

1GT )1/2ξ,

−

where ξ

∼

N(0, I), and G = M (Λ)−

1N (Λ) and ˜Λ =

(Λ) are diagonal matrices.

A

(3.2)

13

Using Lemma 3.1.1 we see that the acceptance probability of MH algorithms (3.1) and (3.2)
are identical and hence it is suﬃcient to analyse the convergence properties of (3.2) to determine
the convergence properties of (3.1).

We will use the following Lyapunov central limit theorem, see e.g. [12, Thm. 27.3].

Theorem 3.1.1 For each d
∈
ables each with ﬁnite expected value µd,i and variance σ2
exists a δ > 0 such that

N let Xd,1, . . . , Xd,d be a sequence of independent random vari-
d,i. If there

d,i. Deﬁne s2

d
i=1 σ2

d :=

P

then

lim
d
→∞

1
s2+δ
d

d

Xi=1

Xd,i −
E[
|

2+δ] = 0,

µd,i|

1
sd

d

Xi=1

(Xd,i −

µd,i) D
−→

N(0, 1)

as d

.

→ ∞

An equivalent conclusion to this theorem is

d

→ ∞

. Another useful fact is

N(µ, σ2)

X

∼

⇒

d

i=1 Xd,i →

N(

d
i=1 µd,i, s2

d) in distribution as

P
eX ] = Φ( µ

P
σ ) + eµ+σ2/2Φ(
−

µ
σ )

σ

−

E[1

∧

(3.3)

where Φ is the standard normal cumulative distribution function. See e.g. [29, Prop. 2.4] or [9,
Lem. B.2].

Theorem 3.1.2 Suppose that M and N in (3.1) are functions of A, and the Markov chain is
in equilibrium, i.e. x

1). If there exists a δ > 0 such that

1b, A−

N(A−

∼

= 0

for j = 1, 2, 3, 4, 5

1+δ/2

(3.4)

2+δ

d
i=1 |

Tji|
Tji|

2

lim
d
d
→∞ P
i=1 |
(cid:16)P

(cid:17)

(j = 0 is not required) and the limits µ = limd
where

→∞

d
i=1 µd,i and σ2 = limd

→∞

d
i=1 σ2

d,i exist

µd,i = T0i + T3i + T4i

and

P
d,i = T 2
σ2

1i + T 2

2i + 2T 2

3i + 2T 2

P
4i + T 2
5i,

then

Z := log

π(y)q(y, x)
π(x)q(x, y)

(cid:18)

D
−→

(cid:19)

N(µ, σ2)

as d

→ ∞

and the expected acceptance probability satisﬁes

E[α(x, y)] = E[1

eZ ]

Φ( µ

σ ) + eµ+σ2/2Φ(
−

σ

−

µ
σ )

→

∧

as d

.

→ ∞

In the above theorem, M and N may depend on d, so Tji may depend on d.

Proof. By Lemma 3.1.2 it is suﬃcient to only consider (3.1) in the case where all matrices are
diagonal matrices, e.g. A = diag(λ2
d), M = diag(M1, . . . , Md),
G = diag(G1, . . . , Gd), mi = λ−

1, . . . , ˜λ2
d),
A
i bi, and ˜mi = ˜λ−
2
i βi. Then, in equilibrium we have

= diag(˜λ2

1, . . . , λ2

2

xi = mi +

1
λi

ξi

14

where ξi ∼

N(0, 1) and using ˜mi = Gi ˜mi + M −

1

i βi we have

yi = Gixi +

(1

−

+

βi
Mi

i )1/2

G2
˜λi

νi

= Gi

mi +

(cid:18)

1
λi

ξi

(cid:19)

+ (1

= ˜mi + Giˆr +

Gi
λi

ξi +

−
g1/2
i
˜λi

Gi) ˜mi +

g1/2
i
˜λi

νi

νi

where νi ∼

N(0, 1). From Lemma 3.1.1 we also have Z =

d
i=1 Zd,i where

Zd,i =

−

1

2 (λ2

i −

˜λ2
i )(y2

i −

P
x2
i ) + (bi −

βi)(yi −

xi).

Substituting xi and yi as above, using the identity (bi −
algebra we eventually ﬁnd

βi)λ−

2
i = ˆri + ri ˜mi, then after some

Zd,i = T0i + T1iξi + T2iνi + T3iξ2

i + T4iν2

i + T5iξiνi.

µd,i := E[Zd,i] = T0i + T3i + T4i

=

d,i := Var[Zd,i] = E[Z 2
σ2
0i + T 2
T 2

E[Zd,i]2
d,i]
−
1i + T 2
3i + 3T 2
2i + 3T 2
(T0i + T3i + T4i)2
3i + 2T 2

2i + 2T 2

4i + T 2
5i

(cid:0)
−
1i + T 2
= T 2

4i + T 2

5i + 2T0iT3i + 2T0iT4i + 2T3iT4i

(cid:1)

Hence

and

and

Zd,i −

µd,i = T1iξi + T2iνi + T3i(ξ2

i −

1) + T4i(ν2

i −

1) + T5iξiνi.

Therefore, for any d
follows

∈

N and δ > 0 we can bound the Lyapunov condition in Theorem 3.1.1 as

1
s2+δ
d

d

Xi=1

Zd,i −
E[
|

2+δ]

µd,i|

≤

52+δ
s2+δ
d

5

d

Cj(δ)

Xj=1
5

Xi=1

2+δ

Tji|
|

52+δ

≤

Xj=1

Cj(δ)

ξ2
2+δ] , C3(δ) = C4(δ) = E[
|
|

−

where C1(δ) = C2(δ) = E[
ξ
|
ξ

N(0, 1).

∼

2+δ

1+δ/2

d
Tji|
i=1 |
d
i=1 T 2
P
ji
(cid:17)
(cid:16)P
2+δ] and C5(δ) = E[
ξ
1
|
|

2+δ]2, and
|

Therefore, if (3.4) holds then the result follows from Theorem 3.1.1 and (3.3).

15

3.2 Expected squared jump size for a Gaussian target

The eﬃciency of a MCMC method is usually given in terms of the integrated autocorrelation time
which is equivalent to “the number of dependent sample points from the Markov chain needed to
give the variance reducing power of one independent point”, see e.g. [26,
6.3]. Unfortunately,
§
we are unable to directly estimate this quantity for our matrix splitting methods, and it depends
on the statistic of concern. As a proxy we instead consider the expected squared jump size of
the Markov chain in a direction q

Rd,

∈

E[(qT (x′

x))2]

−

N(A−

1b, A−

1) are successive elements of the Markov chain in equilibrium. We will
where x, x′ ∼
only consider the cases where q is an eigenvector of the precision or covariance matrix. It is
related to the integrated autocorrelation time for the linear functional qT (
) by
·

Corr[qT x, qT x′] = 1

−

E[(qT (x′ −

2Var[qT x]

x))2]

so that large squared jump size implies small ﬁrst-order autocorrelation, see e.g. [30,
2.3].
§

3] or [9,
§

This is similar to the approach used for analysing the eﬃciency of RWM, MALA and HMC,
where the expected squared jump size of an arbitrary component of the Markov chain is consid-
ered, see e.g. [9] and [6].

We will need the following technical lemma whose proof is in the Appendix.

Lemma 3.2.1 Suppose

ti}∞i=1 ⊂
{

R and r > 0. Then, for any k

N,

r

r/2

d
ti|
i=1 |
lim
d
d
i=1 t2
→∞ P
i
(cid:16)P

(cid:17)

= 0

⇒

d
i=1,i

lim
d
d
→∞ P
i=1,i

r

∈
ti|
=k |
=k t2
i

r/2

(cid:16)P

(cid:17)

= 0.

(3.5)

The following theorem is a generalization of [6, Prop. 3.8].

Theorem 3.2.1 Suppose that M and N in (3.1) are functions of A, and the Markov chain is
1). With µd,i and σ2
d,i deﬁned as in Theorem 3.1.2, let qi
in equilibrium, i.e. x
N(A−
be a normalized eigenvector of A corresponding to λ2
i . If there exists a δ > 0 such that (3.4) is
=i σ2
satisﬁed, and µ− := limd

=i µd,j and (σ−)2 := limd

d,j exist, then

1b, A−

d
j=1,j

d
j=1,j

∼

→∞

→∞

P
E[(qT

i (x′

−

P
x))2] = U1U2 + E3 + o(U1)

(3.6)

as d

→ ∞

where

U1 = ˜g2

i ˆr2

i +

U2 = E[1

,

+

gi
˜λ2
i

˜g2
i
λ2
i
eX ] = Φ( µ−

∧
U3 = (σ2

d,i + µ2

E3| ≤
|

σ− ) + eµ−+(σ−)2/2Φ(
−
−
3
i + ˜rigi)2 +
(˜g2
λ4
i

µ−
σ− ), X
6
λ2
i

i ˆr4
˜g4

i +

d,i)1/2

σ−

×

∼
i ˜g2
ˆr2

(cid:18)

N (µ−, (σ−)2),

i (˜g2

i + ˜rigi)

1/2

.

(cid:19)

16

6
6
6
6
↔

QT x, (3.1) becomes (3.2) and E[(qT

i (x′ −
Proof. Under the coordinate transformation x
xi)2]. Therefore it is suﬃcient to only consider the squared jump size
x))2] becomes E[(x′i −
of an arbitrary coordinate of the Markov chain for the case when all matrices are diagonal
1, . . . , ˜λ2
matrices. As in the proof of Theorem 3.1.2, let A = diag(λ2
d),
A
2
i βi. Since the chain is
M = diag(M1, . . . , Md), G = diag(G1, . . . , Gd), mi = λ−
i ξi + g1/2
˜λ−
1
i νi
in equilibrium we have xi = mi + λ−
=i Zd,j) where Zd,j is deﬁned as in the
where νi ∼
proof of Theorem 3.1.2.

d),
i bi, and ˜mi = ˜λ−
N(0, 1) and yi = ˜mi + Giˆr + Giλ−

N(0, 1). Deﬁne α−(x, y) := 1

i ξi for ξi ∼

= diag(˜λ2

1, . . . , λ2

d
j=1,j

exp(

∧

1

1

2

i

P

The proof strategy is now to approximate E[(x′i −

xi)2α−(x, y)];

xi)2] = E[(yi −

xi)2α(x, y)] with E[(yi −

E[(x′i −
By independence,

xi)2] = E[(yi −

xi)2α−(x, y)] + E[(α(x, y)

α−(x, y))(yi −

−

xi)2].

E[(yi −

xi)2α−(x, y)] = E[(yi −

xi)2]E[α−(x, y)]

= E

˜giˆri −



 −



= U1E[α−(x, y)].

˜gi
λi

ξi +

2

g1/2
˜λi

νi

!

E[α−(x, y)]





Also, by Theorem 3.1.2 (using Lemma 3.2.1 to ensure the appropriate condition for Theorem
xi)2α(x, y)] = U1U2 + o(U1) as
3.1.2 is met) we obtain E[α−(x, y)]
d

, so E[(yi −

U2 as d

→ ∞

→

.

→ ∞

The error is bounded using the Cauchy-Schwarz inequality;

E[(α(x, y)
|

α−(x, y))(yi −

−

xi)2]

| ≤

E[(α(x, y)

α−(x, y))2]1/2E[(yi −

−

xi)4]1/2.

eX is Lipschitz with constant 1, and using results from the proof of Theorem 3.1.2, we

Since 1
obtain

∧

E[(α(x, y)

−

α−(x, y))2]1/2

and some algebra yields

E[(yi −

xi)4]1/2 = E

˜giˆri −



 −

≤

˜gi
λi

E[Z 2

d,i]1/2 = (σ2

d,i + µ2

d,i)1/2,

ξi +

g1/2
˜λi

νi

1/2

4



!


i ˆr4
˜g4

i +

3
λ4
i

=

(cid:18)

(˜g2

i + ˜rigi)2 +

6
λ2
i


i ˜g2
ˆr2

i (˜g2

i + ˜rigi)

1/2

.

(cid:19)

The terms in the theorem above are quite lengthy, but in many situations they simplify. For
, so U2 becomes the
example, we may have the situation where µ− →
expected acceptance rate for the algorithm. Also, it may be possible to derive a bound such as

µ and σ− →

σ as d

→ ∞

so that U3 is small if both the relative error of the ith eigenvalue and error of the means are
small.

U3| ≤
|

C(ri + ˆri)

17

6
18

Chapter 4

Non-Gaussian targets

Our results can be extended to non-Gaussian target distributions in some cases. We follow the
methodology in [9]. Suppose that target πd is a change of measure from a reference Gaussian,
so that πd is deﬁned by (1.2) and (1.4).

With an AR(1) proposal associated with a matrix splitting

algorithm deﬁned by

= M

−

A

N , we consider an MH

Target:

Proposal:

πd,
y = Gx + g + ν,

where ν

N(0, Σ),

∼

(4.1)

1N , g = M −
where G = M −
probability of this MH algorithm satisﬁes

1β and Σ = M −

1(M T +N )M −

T =

1

A−

G

A−

−

1GT . The acceptance

α(x, y) = 1

exp (φd(x)

∧

−

φd(y) + Z)

where Z = log( ˜πd(y)q(y,x)
algorithm (3.1).

˜πd(x)q(x,y) ). Deﬁne ˜α(x, y) = 1

∧

exp(Z) to be the acceptance probability for MH

In the theory below, Eπd[α(x, y)] is the expectation of α(x, y) over x

πd and y from (4.1).

∼

4.1 Expected acceptance rate for a non-Gaussian target

The following theorem applies to inverse problems with a Gaussian prior and bounded likelihood.

Theorem 4.1.1 Suppose there exists a constant M > 0 such that for suﬃciently large d

Then MH algorithm (4.1) in equilibrium satisﬁes

φd(x)
|

| ≤

M

for all x

Rd.

∈

Eπd[α(x, y)]
Eπd[α(x, y)] > 0

≤

CE˜πd[˜α(x, y)]
Z
if E˜πd[
|

] <
|

,

∞

(4.2)

(4.3)

where E˜πd[˜α(x, y)] is the expected acceptance rate of (3.1) in equilibrium.

Proof. We follow the same reasoning as in the proof of [9, Thm. 2]. Note that 1
φd(y) + Z)
≤
C = exp(3M ).

exp(Z)), and πd(x)

−
exp(M )˜πd(x). Hence, we obtain (4.2) with

exp(2M )(1

exp(φd(x)

≤

∧

∧

19

To prove (4.3) ﬁrst note for a random variable X and any γ > 0 we have E[1

exp(
γ)(1
−
−
C + CE˜πd[
Z
|

γ−
] <
|

φd(x)
]), see [9, Lem. B1]. Also note that C0 := Eπd[
|
|

1E[
X
|
. Hence, we obtain (4.3) by taking γ = 2C0.
∞

−

∧

exp(X)]
]
|

φd(y) + Z

≥
≤

Thus, in a certain weak sense, the acceptance rate of (4.1) with non-Gaussian target mimics
the acceptance rate of (3.1) with a Gaussian target; if the acceptance rate of (3.1) is small,
then so is the acceptance rate of (4.1); and if the expected value of
is ﬁnite (which loosely
corresponds to when the acceptance rate of (3.1) is positive) then the acceptance rate of (4.1)
in equilibrium is positive.

Z
|

|

A similar result is given in [9, Thm. 2] for RWM and SLA.

Our next theorem more precisely describes the acceptance rate for a non-Gaussian target,

but ﬁrst, some deﬁnitions and a lemma.

We associate a norm with the spd precision matrix A of our reference Gaussian measure ˜π.

For any s

∈

R deﬁne a norm

| · |s on Rd by
x
|

|s =

Asx
|

|

for all x

∈

Rd. If λ2

1 is the smallest eigenvalue of A, then
λ2(s
1

r)

−

|r

x
|

x
for all s < r.
|s ≤
|
Assumption 4.1.2 Suppose there exist constants m, s, s′, s′′ ∈
bounded function δ : R+
7→
φd(x)
φd(y)
φd(x)
|

x
δ(
|
−
C(1 +

y
|s,
|
1b
A−

φd(x)
|

−
p
s′′)
|

x
|

A−

A−

| ≤

| ≤

R+

m,

1b

1b

−

−

≥

×

R+ such that for all suﬃciently large d

x
|s)
|

y

|s′,

−

for all x, y

Rd.

∈

Assumption 4.1.3 Suppose that r is such that

(4.4)
R, C, p > 0, and a locally

lim
d
→∞

d

Xi=1

1

λ4r
i

−

<

.

∞

The following lemma is similar to part of the proof of [9, Thm. 3].

Lemma 4.1.1 Suppose φd satisﬁes Assumption 4.1.2 and r = max
satisﬁes Assump-
tion 4.1.3. Also suppose that there exists td,i and a t > 0 such that MH algorithm (4.1) satisﬁes

s, s′, s′′}
{

G and Σ are functions of A,
, gi˜λ−
1
˜g2
i ˆr2
(td,i) =
i
˜ri is bounded uniformly in d and i.

i λi, ˜g2

i λ−
i

are

O

1

(d−

t) (uniformly in i) as d

O

, and

→ ∞

N there exists a constant C > 0 (that may depend on q) such that

Then for any q

∈

E˜πd[
x
|
y
E˜πd[
|

−

−

and for proposal y from x,

2q
1b
r ] < C for all d
A−
|
2q
(d−
d,i) =
r ] =
|

(tq

O

O

x

qt) as d

,

→ ∞

φd(x)

φd(y)

0

→

−

in Lq(πd) as d

.

→ ∞

20

Proof. For x

∼

N(A−

1b, A−

1), ξ

N(0, I), ν

∼

N(0, I) and Λ = diag(λ2

1, . . . , λ2

d),

x
E˜πd[
|

−

A−

1b

Ar
2q
r ] = E˜πd[
|
|

−

Λr
2q] = E˜πd[
|
|

q

−

2q]
1/2ν
|
d

= E˜πd

" 

λ4r
i

1

ν2
i

−

C

!

# ≤

q

,

!

1

λ4r
i

−

Xi=1

∼
1/2ξ
d

Xi=1

which is bounded uniformly in d by Assumption 4.1.3.

As above, and using the transformation x

↔
from the proof of Theorem 3.2.1 where ξi and νi

xi) =
N(0, 1), we have

QT x, and (yi −
iid
∼

˜giˆri −

−

˜giλ−

1

i ξi +g1/2

i

˜λ−
1
i νi

y
E˜πd[
|

−

x

d

Xi=1
d

Xi=1







2q
r ] = E˜πd 
|

= E˜πd 

O

1
i =

λ4r
i

˜giˆri −

 −

˜gi
λi

ξi +

g1/2
i
˜λi

νi

q

2





!

1

λ4r
i

−

˜giˆriλ1/2

i −

 −

˜gi
λ1/2
i

ξi +



g1/2
˜r1/4
i
i
˜λ1/2
i

νi

q

2

.





!

Since ˜g2
follows that for all suﬃciently large d,

i λi, ˜g2

1, gi˜λ−

i λ−

i ˆr2


(td,i) uniformly in i, and ˜ri is bounded uniformly in d and i, it





y
E˜πd[
|

−

x

2q
r ]
|

≤

Ctq
d,i

y
so by Assumption 4.1.3, E˜πd[
|

−

x

2q
r ] =
|

O

(tq

d,i) as d

q

,

!

d

λ2r

−

1

Xi=1

.

→ ∞

2q
1b
x
y
r ] < C and E˜πd[
−
|
|
that there is a (new) constant C > 0 such that

x
From E˜πd[
|

A−

−

2q
r ]
|

→

0, it follows from the triangle inequality

y
E˜πd[
|

−

A−

1b

2q
r ] < C
|

for all d.

(4.5)

φd(y). For any R > 0 deﬁne

Let ∆d = φd(x)

−

δ(a, b)q : a
γ(R) = sup
{
Rd :
Rd :

∈

≤
A−

R, b
1b
1b

≤
|s ≤
|s ≤

R

}
,
}
,
}

S1 =

x
|
y
|
and let IS be the indicator function for set S. Using Assumption 4.1.2, a generic constant C
that may vary between lines, the Cauchy-Schwarz inequality, and then Markov’s inequality, we
have for each q

x
{
x
{

S2 =

A−

−

−

R

R

N

∈

∈

∆d|
E˜πd[
|

y

−

≤

≤

qIS1
q] = E˜πd[
S2] + E˜πd[
∆d|
∆d|
|
|
∩
q
s′] + CE[(1 +
y
x
γ(R)E[
|
|
q
s′]
x
γ(R)E[
|
|
−
2pq
1b
x
+ CE[1 +
A−
s′′ +
|
−
|
q
s′] + C(P(Rd
y
|
C
q
s′] +
R1/2
|
C
q
s′] +
R1/2
|

x
γ(R)E[
|
x
γ(R)E[
|

x
γ(R)E[
|

(cid:0)
.

≤

−

−

≤

≤

−

y

y

qIRd

x
|

−

S2)]
(S1
∩
\
pq
1b
s′′ +
A−
|

y
|

−

A−

1b

pq
s′′)IRd
|

(S1

\

S2)]
∩

S1) + P(Rd
\

S2))1/2
\

−

2pq
s′′ ]1/2(P(Rd
1b
y
A−
|
|
S1) + P(Rd
S2))1/2
\
\
y
|s] + E[
x
E[
|
|

A−

1b

−

−

A−

1/2

1b

|s]
(cid:1)

21

 
 
Note that we used Jensen’s inquality (which implies
x
and (4.4) to obtain bounds on E[
|

)
≤ ∞
1b
|s].
Hence, for any ǫ > 0 we can choose R = R(ǫ) such that C/R1/2 < ǫ/2 and since E˜πd[
y
|

kLq(˜πd) for 1
1b
A−
−

f
kLp(˜πd) ≤ k
2pq
1b
x
s′′ ], E[
|
|

p
≤
y
|s] and E[
|

2pq
y
s′′ ], E[
|
|

(by Jensen’s inequality), for all suﬃciently large d we have

f
k
A−

q
A−

0 as d

≤
−

A−

1b

−

−

−

x

q
r]
|

→

→ ∞

Thus,

φd(x)
E˜πd[
|

−

∆d|
] = E˜πd[
φd(y)
|
|

q] < ǫ.

φd(x)

φd(y)

0

→

−

in Lq(˜πd) as d

.

→ ∞

The result then follows from φd(x)

m.

≥

Theorem 4.1.4 Suppose that φd satisﬁes Assumption 4.1.2 and r = max
satisﬁes
Assumption 4.1.3. Also suppose there exists td,i and t > 0 such that MH algorithm (4.1)
satisﬁes

s, s′, s′′}
{

G and Σ are functions of A,
, gi˜λ−
1
˜g2
i ˆr2
(td,i) =
i
˜ri is bounded uniformly in d and i,

i λi, ˜g2

i λ−
i

are

O

1

(d−

t) (uniformly in i) as d

O

,

→ ∞

T1i, T2i, T3i, T4i, T5i are

(d−

1/2) as d

O
3i + 2T 2
2i + 2T 2

1i + T 2
T 2

4i + T 2

5i <

.

∞

(uniformly in i), and

→ ∞

lim
d
→∞

d

Xi=1

If

µng = µ + lim
→∞

d

d

Xi=1
d

κd,iT1i + T3i(γi −

1),

ng = σ2 + lim
σ2
→∞

d

Xi=1

(κd,iT1i + T3i(γd,i −

1))2 ,

exist, where κd,i = Eπd[qT
eigenvector of A corresponding to the eigenvalue λ2
3.1.2, then

i A1/2(x

A−

1b)], γd,i = Eπd[(qT

−

i A1/2(x

1b))2], qi is a normalised
i , and µ and σ2 are the same as in Theorem

A−

−

eZng ] = Φ( µng
σng

) + eµng +σ2

ng /2Φ(

σng −

µng
σng

)

−

Eπd[α(x, y)]

E[1

→
N(µng, σ2

∧
ng).

as d

→ ∞

, where Zng ∼

Proof. As in the proofs of Theorems 3.1.2 and 3.2.1 it is suﬃcient to prove the result in the
case when all matrices are diagonal. This follows from the coordinate transformation z = QT x
where A = QΛQT , since

Λsz
|

Λs(z
|s =
|
R, and since ψd(z) := φd(Qz) satisﬁes Assumption 4.1.2. Henceforth and

1QT b)
|

|s =

and

x
|

A−

Λ−

1b

−

−

|

for all x
without loss of generality, let us assume that A, G and Σ are diagonal matrices.

∈

∈

x
|
Rd and s

Using Lemma 4.1.1 with q = 1, and the fact that z

continuous, it follows that

1

∧

7→

exp(z) is globally Lipschitz

Eπd[α(x, y)]

Eπd[˜α(x, y)]

0

→

−

as d

.

→ ∞

(4.6)

22

To complete the proof we must ﬁnd the limit of Eπd[˜α(x, y)] as d

.

→ ∞

As in the proof of Theorem 3.1.2 we have Z =

d
i=1 Zd,i where

Zd,i = T0i + T1iξi + T2iνi + T3iξ2

i + T4iν2

i + T5iξiνi,

P

noting that ξi = λi(xi −

mi) with x

∼

πd, mi = (A−

1b)i, and νi ∼

N(0, 1).

Note that κd,i = Eπd[λi(xi −
mE˜πd[ξ2
γd,i ≤

both uniformly bounded in d and i since φd(x)
i ] = e−
0

mE[u2] where u

mi)] = Eπd[ξi] and γd,i = Eπd[λ2
mi)2] = Eπd[ξ2
i (xi −
i ] are
mE[
mE˜πd[
] and
u
ξi|
e−
|
|
|

κd,i| ≤
|
N(0, 1). If we deﬁne

] = e−

m and

e−

≥

∼

≤

Sd,j :=

j

Xi=1

then

T1i(ξi −

κd,i) + T2iνi + T3i(ξ2

i −

γd,i) + T4i(ν2

i −

1) + T5iξiνi,

d

Z =

(T0i + T1iκd,i + T3iγd,i + T4i) + Sd,d.

Xi=1

We will now show that Sd,d converges in distribution towards a normal distribution as d

using a Martingale central limit theorem, see [24, Thm. 3.2, p. 58].

,

→ ∞

The set

Sd,j : 1
{
N and 1

≤
j

j

≤

≤

each d

∈

d, d

N
}
≤
d, Sd,j is measurable,

∈

is a zero mean, square-integrable Martingale array, i.e. for

Eπd[Sd,j] = 0,

Sd,j|
Eπd[
|

] <

,

∞

and

Eπd[(Sj,d)2] <

.

∞

For deﬁnitions, see [24, p. 1 and 53]. Deﬁne Xd,j := Sd,j −
1. To ensure we satisfy the
conditions for [24, Thm. 3.2] we must show that there exists an a.s. ﬁnite random variable η2
such that

Sd,j

−

Xd,i|
d |

p
−→

0

as d

,

→ ∞

max
i
1
≤
≤
d

X 2
d,i

η2

p
−→

as d

, and

→ ∞

X 2
d,i

max
d
i
1
≤
≤

(cid:18)

(cid:19)

is bounded in d.

Xi=1
Eπd

First consider (4.7). We have

Xd,i| ≤ |
|

T5i||
νi|
|
which goes to zero in probability since κd,i and γd,i are bounded uniformly and

ξi|
(
T1i|
|

i + γd,i) +

i + 1) +

T2i||
|

κd,i|
|

T4i|
|

T3i|
|

) +

+

+

(ν2

(ξ2

ξi||

νi|
Tji|
|

(d−

1/2) as d

O

→ ∞
Now consider (4.8). Deﬁne

uniformly in i.

η2 := σ2

ng = lim
d
→∞

d

Xi=1

1i + T 2
T 2

2i + 2T 2

3i + 2T 2

4i + T 2

5i + (κd,iT1i + T3i(γd,i −

1))2 <

∞

23

(4.7)

(4.8)

(4.9)

are all

and Yd,i := dX 2

d,i so that Y d = 1
d
2i + 2T 2
1i + T 2
T 2
P

E˜πd[Yd,i] = d

d
i=1 Yd,i =

d
i=1 X 2

d,i. Then

3i + 2T 2
P

4i + T 2

5i + (κd,iT1i + T3i(γd,i −

and

(cid:0)

Var˜πd[Yd,i] = d2

CωT ω1

1i T ω2

2i T ω3

3i T ω4

4i T ω5

5i

1))2

,

(cid:1)

where ω is a multi-index with ωi ≥
constants. Since Tji are all

(d−

0 and

=

i ωi = 4, and Cω are uniformly bounded

1/2), E˜πd[Yd,i] and Var˜πd[Yi] are uniformly bounded.

O

P

=4
ω
X|
|
ω
|

|

Then by the Markov inequality, and independence of Yd,i, for any ǫ > 0,

Pr

Y d −
(cid:0)(cid:12)
(cid:12)

E˜πd

Y d

ǫ

≥

(cid:2)

(cid:3)(cid:12)
(cid:12)

(cid:1)

≤

=

≤

1
ǫ2 Var˜πd
1
ǫ2d2

d

Xi=1

C
ǫ2d →

Y d

(cid:3)
(cid:2)
Var˜πd[Yd,i]

0 as d

.

→ ∞

Hence Y d
rather than πd.

p
−→

η2 as d

. This is not (4.8) yet, because it is convergence with respect to ˜πd

→ ∞

Since limd

E˜πd[Y d] = η2 <

→∞

bounded in d. Therefore, Y d is uniformly integrable and so Y d →
Thm. 6.5.5 on p. 169]. Hence

and

Y d|
|

∞

= Y d, it follows that E˜πd[
Y d|
|
η2 in L1(˜πd) as d

] is uniformly
[33,

→ ∞

X 2
d,i

L1(˜πd)
−−−−→

η2

as d

.

→ ∞

d

Xi=1

From φd(x)
≥
hence we have shown (4.8).

m, the same limit holds in L1(πd), which also implies convergence in probability,

Condition (4.9) follows from X 2

d,i ≤

Y d for 1

i

≤

≤

Y d|
d, E˜πd[
|

] uniformly bounded in d, and

φd(x)

m.

≥

Therefore, by the Martingale central limit theorem [24, Thm. 3.2],

Hence,

Sd,d D
−→

N(0, η2)

as d

.

→ ∞

The result then follows from (4.6), (4.10) and (3.3).

Z D
−→

N(µng, σ2

ng)

as d

.
→ ∞

(4.10)

Corollary 4.1.1 In addition to the conditions for Theorem 4.1.4, if

then

lim
d
→∞

d

Xi=1

1i + T 2
T 2

3i = 0

µng = µ

and

ng = σ2,
σ2

and the expected acceptance rate for the non-Gaussian target case has the same limit as d
as the Gaussian target case.

→ ∞

24

Proof. With ξi deﬁned as in the proof of Theorem 4.1.4 (we only need to consider the case when
matrices are diagonal), since E˜πd[ξ2
i ] = 3 for all i and d, and since ξi and ξj are
independent for i

i ] = 1 and E˜πd[ξ4

= j under ˜πd,

d

2

d

lim
d
→∞

E˜πd 


T1iξi + T3i(ξ2

1)

i −



!

= lim
d
→∞

1i + 2T 2
T 2

3i = 0

Xi=1

d
i=1(T1iξi + T3i(ξ2
. Therefore, since κd,i = Eπd[ξi] and γd,i = Eπd[ξ2
i ],

From Jensen’s inequality and φd(x)
d

m we have

Xi=1

≥

→ ∞

P

1))

→

0 in L1(πd) as

i −

d

Xi=1

T1iκd,i + T3i(γd,i −

1) = Eπd

d

"

Xi=1

T1iξi + T3i(ξ2

i −

1)

# →

0

as d

,

→ ∞

and µng = µ. Also, since κd,i and γd,i are uniformly bounded in d and i,

d

(T1iκd,i + T3i(γd,i −

Xi=1

1))2

C

≤

d

Xi=1

1i + T 2
T 2

3i →

0

as d

,

→ ∞

and σ2

ng = σ2.

4.2 Expected jumpsize for non-Gaussian target

Theorem 4.2.1 Under the same conditions as Theorem 4.1.4,

Eπd[(qT

i (x′

x))2] =

−



i ˆr2
˜g2

i +

gi
˜λ2
i !

Eπd[α(x, y)] + 2

i γ1/2
ˆri˜g2
λi

d,i

ud,i +

˜g2
i γd,i
λ2
i

(uniformly in i) as d


→ ∞

, for some

1

−

≤

ud,i ≤

1 and 0

vd,i ≤

1.

≤

+ o(td,iλ−

1
i )

vd,i


Proof. As in earlier proofs, it is suﬃcient to prove the result in the case when all matrices are
diagonal, so let A, G and Σ be diagonal matrices.

Let Sd denote the expected squared jump size in coordinate direction i, so that

Sd = Eπd[(x′i −

xi)2] = Eπd[(yi −

xi)2α(x, y)].

Also deﬁne

˜Sd := Eπd[(yi −

xi)2 ˜α(x, y)]

and

˜S−d := Eπd[(yi −

xi)2 ˜α−(x, y)]

where ˜α−(x, y) = 1
mi).
λi(xi −

∧

exp(

d
j=1,j

=i Zd,i), and Zd,i is the same as earlier. Recall that ξi =

P

We ﬁrst show that Eπd[(yi −

xi)4] =

(t2

d,iλ−
i

2

O

of Theorem 3.2.1, from y = Gx + g + Σ1/2ν where ν

) (uniformly in i) as d

. As in the proof
→ ∞
N(0, I), and ˜m = G ˜m + g it follows that

∼

yi −

xi =

˜giˆri −

−

˜gi
λi

ξi +

g1/2
i
˜λi

νi

25

6
 
 
6
where νi

iid
∼

N(0, 1), ξi = λi(xi −

mi) and x

∼

πd. Therefore,

(yi −

xi)4 = λ−
i

2

˜giˆriλ1/2

i −

 −

˜gi
λ1/2
i

ξi +

4

˜r1/4
i

.

νi

g1/2
i
˜λ1/2
!
i
and γd,i = Eπd[ξ2

In the proof of Theorem 4.1.4 we showed that
bounded. Similarly,
1, gi˜λ−
1
i λi, ˜g2
i ˆr2
˜g2
i λ−
i
(t2
xi)4] =
Eπd[(yi −

i ] are uniformly
Eπd[ξ3
i ] are also uniformly bounded. Using these facts and
i ]
|
|
(td,i) (uniformly in i) and ˜ri bounded uniformly in d and i, it follows that
d,iλ−
i

) (uniformly in i) as d

and Eπd[ξ4

Eπd[ξi]
|
|

κd,i|
|

→ ∞

=

2

.

˜Sd = o(td,iλ−

1
i ) as d

O
Now let us show that Sd −
1
7→

∧

z

exp(z) and the Cauchy-Schwarz inequality,
Sd −

˜α(x, y)]

˜Sd = Eπd[(yi −
Eπd[(yi −

≤

xi)2(α(x, y)
−
xi)4]1/2Eπd[
φd(x)
|
xi)4] =

(t2

−
2
d,iλ−
i

).

˜S−d = o(td,iλ−

O
1
i ) as d

by Lemma 4.1.1, since Eπd[(yi −
Now show that ˜Sd −
1
7→

∧

z

→ ∞

˜Sd −

exp(z) and the Cauchy-Schwarz inequality,
˜S−d = Eπd[(yi −
Eπd[(yi −
≤
d,iλ2
(t2

i ) and Tji are all

xi)4] =

xi)2(˜α(x, y)
˜α−(x, y))]
−
d,i]1/2 = o(td,iλ−
xi)4]1/2Eπd[Z 2
i

(d−

1/2).

O

since Eπd[(yi −

O

. From the Lipschitz continuity of

→ ∞

2]1/2 = o(td,iλ−
φd(y)
|

1
i )

as d

,

→ ∞

. Again, by the Lipschitz continuity of

1

) as d

,

→ ∞

Now consider ˜S−d . Since νi is independent of ξi and ˜α−(x, y), E[νi] = 0 and E[ν2

i ] = 1,

˜S−d = Eπd[(yi −
i ˆr2
˜g2
= Eπd

xi)2 ˜α−(x, y)]
ˆri˜g2
i
λi

i + 2

ξi +

" 

˜g2
i
λ2
i

ξ2
i +

gi
˜λ2
i !

˜α−(x, y)

#

=

i ˆr2
˜g2

i +

gi
˜λ2
i !

Eπd[˜α−(x, y)] + 2

ˆri˜g2
i
λi

Eπd[ξi ˜α−(x, y)] +

˜g2
i
λ2
i

Eπd[ξ2

i ˜α−(x, y)].

Since ˜α−(x, y)

(0, 1], it follows from Jensen’s inequality that

∈
Eπd[ξi ˜α−(x, y)]
|
Eπd[ξ2

i ˜α−(x, y)]

| ≤
Eπd[ξ2

ξi|
Eπd[
|
i ] = γd,i.

Also, 0

≤

Finally, using z

1

≤
exp(z) Lipschitz, and since Tji are
Zd,i| →

Eπd[˜α(x, y)]

| ≤
1
i ) it follows that as d

−

Eπd|
→ ∞

7→

∧
Eπd[˜α−(x, y)]
|
=

(td,iλ−

O
0

(d−

1/2),

as d

.

→ ∞

˜α−(x, y)]

]
ξi|
Eπd[
|

≤

≤

Eπd[ξ2

i ]1/2 = γ1/2
d,i .

Since ˜g2

i ˆr2

i + gi
˜λ2
i

O
Sd = S−d + o(td,iλ−
i

1

)

=



i ˆr2
˜g2

i +

gi
˜λ2
i !

Eπd[˜α(x, y)] + 2

i γ1/2
ˆri˜g2
λi

d,i

ud,i +

˜g2
i γd,i
λ2
i

+ o(td,iλ−

1
i )

vd,i


[0, 1]. The result then follows from (4.6) and ˜g2

i ˆr2

i + gi
˜λ2
i

=


for some ud,i ∈
[
−
1
(td,iλ−
i ).
O

1, 1] and vd,i ∈

26

 
 
Chapter 5

Examples

5.1 Discretized Langevin diﬀusion - MALA and SLA

The proposal for MALA is obtained from the Euler-Maruyama discretization of a Langevin
which satisﬁes the stochastic diﬀerential equation
diﬀusion process

zt}
{

dzt
dt

=

1
2 ∇

log π(zt) +

dWt
dt

,

where Wt is standard Brownian motion in Rd. This diﬀusion process has the desired target
distribution π as equilibrium, so one might expect a discretization of the diﬀusion process to
1), then
almost preserve the desired target distribution. If the target is Gaussian, N(A−
for current state x

Rd and time step h > 0, the MALA proposal y

1b, A−
Rd is deﬁned as

∈

∈

y = (I

−

h

2 A)x + h

2 b + √hξ

(5.1)

where ξ
N(0, I). One can also use this proposal for situations where the target distribution is
a change of measure from a Gaussian; in which case it is called the SLA proposal [9]. The SLA
algorithm is

∼

Target:

πd,

Proposal:

y = (I

−

h

2 A)x + h

2 b + √hξ,

where ξ

N(0, I),

∼

(5.2)

Identifying (5.1) with (1.1) and applying Corollary 2.1.1 we have the following theorem.

Theorem 5.1.1 The SLA proposal corresponds to the matrix splitting

M = 2
N = 2

h (I
h (I

h
4 A),
h
4 A)(I

−

−

h
2 A),

−

= (I

A
β = (I

h
4 A)A,
h
4 A)b.

−

−

Thus, the SLA proposal corresponds to a matrix splitting where M and N are functions of
A and our theory applies. An important feature of this proposal is that ˆri = 0 for all i. This
greatly simpliﬁes the results in Theorems 3.1.2, 3.2.1, 4.1.4 and 4.2.1 and we extend existing
theory ([9, Cor. 1] and the simpler results in [31, Thm. 7]) to the case where the reference
Gaussian measure is allowed to have oﬀ-diagonal covariance terms. The theorem below is a
special case of Theorem 5.2.2 so we omit the proof.

Theorem 5.1.2 Suppose there exist constants c, C > 0 and κ
of A satisfy

≥

0 such that the eigenvalues λ2
i

ciκ

λi ≤

≤

Ciκ

for i = 1, . . . , d.

27

Also suppose that φd satisﬁes Assumption 4.1.2 and r = max
4.1.3.

s, s′, s′′}
{

satisﬁes Assumption

If h = l2d−

1/3

−

2κ for some l > 0 then SLA, in equilibrium, satisﬁes

E[α(x, y)]

2Φ

→

l3√τ
8

(cid:17)

−

(cid:16)

and

E[(xi −

xi)2] = 2hΦ

as d

→ ∞

where τ = limd

→∞

1
d1+6κ

d
i=1 λ6
i .

l3√τ
8

+ o(h)

(cid:17)

−

(cid:16)

(5.3)

Thus, the performance of SLA depends on the choice of h which is usually tuned (by tuning

P

l) to maximise the expected jump distance. From (5.3), using s = lτ 1/6/2, we have

2l2d−

1/3

−

2κΦ

max
l>0

l3√τ
8

= max
s>0

−

2κ

8d−

1/3

−
τ 1/3

−

s2Φ(

s3),

(5.4)

(cid:16)

(cid:17)
which is maximised at s0 = 0.8252, independent of τ . Therefore, the acceptance rate that
s3
0) = 0.574. This result was ﬁrst stated in [30] for
maximises expected jump distance is 2Φ(
product target distributions, then more generally in [31, 9]. Our result is even more general
because we allow the reference measure, which must be Gaussian in our case, to have oﬀ-
diagonal covariance terms. In practice, h (equivalently l) is adjusted so that the acceptance rate
is approximately 0.574 to maximise the expected jump size. This acceptance rate is independent
of τ , so it is independent of the eigenvalues of A. However, the eﬃciency of SLA still depends
on τ , and as τ increases the expected square jump distance will decrease by a factor τ 1/3.

−

The rationale for studying the case when d

when d is ‘large’ and ﬁnite (see eg.
that we should take h
tends towards 0 as d
asymptotic performance over RWM (see [9, Thms. 1-4 and Cor. 1] and [30, Fig. 1]).

is that it is a good approximation for cases
[30, Fig. 1] or [31]). However, the results above suggest
, to achieve at best an expected jump size that also
0 as d
. The only good point about these results is that SLA has superior

→
→ ∞

→ ∞

→ ∞

To understand the convergence of SLA to equilibrium (burn in) we would like to know the
‘spectral gap’ or second largest eigenvalue of the transition kernel, as this determines the rate
of convergence. As far as we are aware this is an open problem.

We can also use Theorem 5.1.1 to analyse the unadjusted Langevin algorithm (ULA) in
[32] in the case when the target is Gaussian, in which case ULA is simply the proposal chain
from (5.1) without the accept/reject step in the MH algorithm. From Theorem 5.1.1 we see
that it does not converge to the correct target distribution since
= A. Instead of converging
1). Indeed, the authors of [32] note that ULA
to N(A−
A−
has poor convergence properties. We see here the reason why it converges to the wrong target
distribution, and from [17, 19] we know its convergence rate to the incorrect target distribution
depends on the spectral radius of G = I

1), ULA converges to N(A−

h
2 A, which is close to 1 when h is small.

1b, A−

1b,

A 6

−

Despite possibly having slow convergence per iteration, the SLA proposal is cheap to com-
h
pute. Since G = I
2 A, we only require a single matrix-vector multiplication with A for each
proposal and since Σ = hI, an i.i.d. sample from N(0, Σ) at each iteration is also cheap to
compute.

−

28

θ
0

0

V
I

Method
SLA, MALA and ULA [32, 9]. SLA=MALA for Gaussian target distri-
butions.

A−

1 Used in [28]. With a change of variables x

QT V −

1/2x, it is the

∈

[0, 1]
1
2
1
2

I
I
A−

1

Preconditioned Simpliﬁed Langevin Algorithm (P-SLA) [9].
θ-SLA [9].
CN [15].
pCN [15].

↔

Table 5.1. Diﬀerent choices of θ and V in (5.6) lead to diﬀerent
proposals for the MH algorithm (5.7). Other choices are possible.

5.2 Discretized Langevin diﬀusion - more general algorithms

It is possible to generalise MALA and SLA by ‘preconditioning’ the Langevin diﬀusion process
and using a discretization scheme that is not Euler-Maruyama. For symmetric positive deﬁnite
matrix V
satisfying the stochastic
∈
diﬀerential equation

d (the ‘preconditioner’) consider a Langevin process

zt}
{

Rd

×

dzt
dt

=

1
2

V

∇

log π(zt) +

dWt
dt

(5.5)

where Wt is Brownian motion in Rd with covariance V . This diﬀusion process also preserves π.
Rd by discretizing
For θ
∈
(5.5) as

[0, 1], time step h > 0 and current state x

Rd deﬁne a proposal y

∈

∈

y

x = h

2 V

log π(θy + (1

θ)x) + √hν

−
N(0, V ). When the target is Gaussian, N(A−

∇

−

1b, A−

1), this can be rewritten as

y = (I + θh

2 V A)−

1

(I

(1

θ)h

2 V A)x + h

2 V b + (hV )1/2ξ

−

−

h

i

N(0, I), which is an AR(1) proposal. Thus, we deﬁne a MH algorithm by

where ν

∼

where ξ

∼

Target: πd,

Proposal: y = (I + θh

2 V A)−

1

(I

h

−

(1

θ)h

2 V A)x + h

2 V b + (hV )1/2ξ

−

, for ξ

i

N(0, I).

∼

(5.6)

(5.7)

Diﬀerent choices of θ and V give diﬀerent proposals. For example, SLA has θ = 0 and V = I,

and pCN corresponds to θ = 1

2 and V = A−

1. Table 5.1 describes several more examples.

Applying Corollary 2.1.1 we can prove the following theorem.

Theorem 5.2.1 The general Langevin proposal (5.6) corresponds to the matrix splitting

M = 2
N = 2

h V −
h V −

1/2W (I + θh
2 B)V −
θ)h
(1
1/2W (I
2 B)V −
−

1/2,

−

1/2,

= V −

A
β = V −

1/2 = ˜W A,

1/2W BV −
1/2W V 1/2b = ˜W b,

where B = V 1/2AV 1/2, W = I + (θ

−

1

2 ) h

2 B and ˜W = I + (θ

−

29

1

2 ) h

2 AV .

Proof. With iteration matrix G = (I + θh
and matrix Σ = (I + θh
Corollary 2.1.1 we ﬁrst check that GΣ is symmetric. We have

1(I
2 AV )−

1(hV )(I + θh

2 V A)−

2 V A)−

−

(1

θ)h

2 V A), vector g = h

1V b
−
1, then (5.6) is the same as (1.1). To apply

2 (I + θh

2 V A)−

G = V 1/2(I + θh

2 B)−

1(I

−

(1

θ)h
2 B)V −
−

1/2

and Σ = hV 1/2(I + θh

2 B)−

2V 1/2

so that

GΣ = hV 1/2(I + θh

2 B)−

1(I

(1

θ)h

2 B)(I + θh

2 B)−

−

2V 1/2

−
which is symmetric since V and B are symmetric. Applying Corollary 2.1.1 then yields the
result.

Because of Theorem 5.2.1, the proposal chain for (5.6) converges to N(A−
= 1

1), and
= A, and the target reference and proposal limit distributions disagree.

1b, ( ˜W A)−

= I,

if θ

2 , then ˜W

A 6

If θ = 1

2 , then the proposal limit and target reference distributions are the same.

If, in
addition, the target is Gaussian, then the MH accept/reject step is redundant and we can use
[17, 19, 18] to analyse and accelerate the proposal chain generated by (5.6).

To evaluate the performance of the MH algorithm (5.7) when

= A we would like to be able
to apply Theorems 4.1.4 and 4.2.1, but we see in Theorem 5.2.1 that the splitting matrices are
functions of B and V (not A) so we cannot directly apply our new theory. However, a change of
coordinates will ﬁx this! The following lemma is a result of simple algebra and Theorem 5.2.1.

A 6

Lemma 5.2.1 Under the change of coordinates

V −

1/2x

x

↔

the MH algorithm (5.7) is transformed to the MH algorithm deﬁned by

Target: πd where dπd
d˜πd
(I + θh

Proposal:

2 B)y = (I

(1

−
2 B)x + h

θ)h

−

−

2 V 1/2b + h1/2ξ, where ξ

N(0, I),

∼

(5.8)

(x) = exp(

φd(V 1/2x)) and ˜πd is N(B−

1V 1/2b, B−

1),

and B = V 1/2AV 1/2. Moreover, the proposal in (5.8) corresponds to the matrix splitting
B = M

N where

−

M = 2
N = 2

h W (I + θh
h W (I

2 B),
θ)h
(1
2 B),
−

−

= W B,
A
β = W V 1/2b,

and W = I + (θ

−

1

2 ) h

2 B.

Thus, we have transformed the MH algorithm (5.7) to a MH algorithm where the splitting
matrices are functions of the target reference precision matrix, and we can apply Theorems 4.1.4
and 4.2.1 to (5.8) to ﬁnd the expected acceptance rate and expected jump size of (5.7). Note
that we never compute the Markov chain for (5.8), we only use it to determine the convergence
properties of (5.7) since they are identical.

Theorem 5.2.2 Suppose there are constants c, C > 0 and κ
of B = V 1/2AV 1/2 (equivalently, λ2

i are eigenvalues of V A) satisfy

≥

0 such that the eigenvalues λ2
i

ciκ

λi ≤

≤

Ciκ

for i = 1, . . . , d.

30

6
6
Also suppose that ψd(x) := φd(V 1/2x) satisﬁes Assumption 4.1.2 (with
satisﬁes Assumption 4.1.3.
and r = max

s, s′, s′′}
{

| · |s =

Bs
|

· |

for s

R)

∈

If h = l2d−
−
equilibrium, satisﬁes

1/3

2κ for l > 0 and τ = limd

1
d6κ+1

d
i=1 λ6

i then MH algorithm (5.7), in

→∞

E[α(x, y)]

2Φ

→

 −

l3

θ
|

√τ

P
1
2 |

−
4

!

and for normalised eigenvector qi of B corresponding to λ2
i ,

qT
i V −
E[
|

1/2(x′

2] = 2hΦ
x)
|

−

l3

θ
|

−
4

√τ

1
2 |

!

 −

+ o(h)

as d

.

→ ∞

The proof of Theorem 5.2.2 is in the Appendix.

(5.9)

(5.10)

For eﬃciency, as well as considering the expected squared jump size, we must also consider
1 and an

the computing cost of the proposal (5.6), which requires the action of (I + θh
independent sample from N(0, V ), as well as the actions of V and A multiplying a vector.

2 V A)−

We see that V plays a similar role to a preconditioner in solving a linear system. For a
linear system we choose V to be cheap to compute matrix multiplication and to minimise the
condition number of V A. For the MH algorithm (5.7) we choose it so that multiplying with V
and sampling from N(0, V ) are cheap to compute and to minimise τ . In both cases V is chosen
to ‘control’ the eigenvalues of V A.

Although SLA and more general discretizations of Langevin diﬀusion have been successfully
analyzed in [9], all of these results are stated for target distributions that are a change of measure
from product measures. Theorem 5.2.2 extends their theory (in particular [9, Cor. 1]) to the
case where the reference measure ˜πd may be Gaussian with oﬀ-diagonal covariance terms and
θ

[0, 1]. See also [31, Thm. 7].

∈

With θ = 0 and V = I, SLA is very cheap to compute because we only have to invert
the identity matrix and sample from N(0, I) at each iteration (as well as multiply by A). Al-
ternatively, pCN, with θ = 1
1) which may be
computationally expensive, particularly in high dimensions.

1, requires a sample from N(0, A−

2 and V = A−

5.3 L-step methods

Given an AR(1) proposal of the form (1.1), we can form a new AR(1) proposal by taking L steps
of the original proposal before performing the MH accept/reject step. This may be advantageous
when the cost of evaluating φd is signiﬁcant. The L-step proposal is computed by iterating

y(l) = Gy(l

−

1) + g + ν(l)

for l = 1, . . . , L,

where ν(l) is an i.i.d. draw from N(0, Σ) and y(0) = x. This yields a new proposal in the form
of (1.1),

y = GLx + gL + νL,

with νL ∼

N(0, ΣL)

(5.11)

31

where GL = GL, gL = (I
of GL are GL
the 1-step proposal chain (i.e.

−

L
l=0 GlΣ(GT )l. Hence, the eigenvalues
−
i , and if Gi < 1 then the L-step proposal chain will converge to the same limit as

GL)g and ΣL =

G)−

1(I

1

and βL = β).

P

−
AL =

A

We can reduce the computational cost of evaluating the acceptance ratio for the L-step
proposal using the surrogate transition method [25, p.194]. The proof of the following lemma is
in the Appendix.

Lemma 5.3.1 The L-step acceptance probability satisﬁes

α(x, y) = 1

πd(y)qL(y, x)
πd(x)qL(x, y)

∧

= 1

πd(y)π∗(x)
πd(x)π∗(y)

∧

where qL(x, dy) = qL(x, y)dy is the transition kernel for the L-step proposal y given x from
(5.11) and π∗(x)

x + βT x).

exp(

∝

1
2 xT

−

A

The computational cost of the L-step proposal is L times the cost of the original proposal,
but the expected squared jump size for the L-step method is, in general, not L times the original.
For example, let us consider L-step SLA, where G = (I
2 b and Σ = hI, and the
proposal is given by (5.11). The proof of the following theorem is in the Appendix.

2 A), β = h

−

h

Theorem 5.3.1 Suppose there exist constants c, C > 0 and κ
of A satisfy

≥

0 such that the eigenvalues λ2
i

ciκ

λi ≤

≤

Ciκ

for i = 1, . . . , d.

Also suppose that φd satisﬁes Assumption 4.1.2 and r = max
4.1.3.

s, s′, s′′}
{

satisﬁes Assumption

If h = l2d−

1/3

−

2κ for some l > 0 then L-step SLA, in equilibrium, satisﬁes

E[α(x, y)]

2Φ

→

l3√Lτ
8

(cid:17)

−

(cid:16)

and

E[(x′i −

xi)2] = 2LhΦ

as d

→ ∞

where τ = limd

→∞

1
d1+6κ

d
i=1 λ6
i .

l3√Lτ
8

+ o(h)

(cid:17)

−

(cid:16)

(5.12)

(5.13)

To maximise the performance of L-step SLA we then tune l to maxmise the expected jump

P

size. From (5.13), using s = l(Lτ )1/6/2, we have

2Ll2d−

1/3

−

2κΦ

max
l>0

l3√Lτ
8

= max
s>0

8L2/3d−

1/3

−

2κτ −

1/3s2Φ(

−

s3),

(5.14)

−

(cid:16)

(cid:17)

which is maxmised at s0 = 0.8252. Therefore, the expected jump size of L-step SLA is
s3
maxmimised when the acceptance rate is 2Φ(
0) = 0.574, which is the same as SLA, but
−
this corresponds to an expected jump size that is only L2/3 times larger than the jump size for
SLA (compare (5.14) and (5.4)) in the limit when d

.

→ ∞

To compare the eﬃciency L-step SLA for varying L we must also consider the computational
cost of the method. For example, suppose that matrix-vector products with A cost 1 unit of
CPU time, inner products and drawing independent samples from N(0, I) are essentially free,
and evaluating φd costs t units of CPU time. From Lemma 5.3.1, we can simplify the acceptance
ratio for L-step SLA to

α(x, y) = 1

exp

∧

h
Ax
4 (
|

2
|

Ay

− |

2)
|

−

h

2 bT (Ax

−

Ay) + φd(x)

φd(y)

−

(cid:0)

32

(cid:1)

0.5

0.45

0.4

0.35

0.3

0.25

y
c
n
e
i
c
ﬃ
e

0.2

0

2

4

6

L

8

t = 0
t = 1
t = 2
t = 5

10

Figure 5.1. Eﬃciency of the L-step SLA method for varying
number of steps L and varying computing cost for evaluating φd.
Filled markers correspond to maximum eﬃciency.

so L-step SLA uses L matrix vector products with A per proposal and an additional matrix-
vector product and two evaluations of φd in the acceptance ratio. If the proposal is accepted
then we can reuse some of the calculations in the acceptance ratio, but if it is rejected then a
matrix-vector product and an evaluation of φd are wasted. The average cost of an L-step SLA
iteration is then

L + t + (1

−

α)(1 + t) = 1.426 + 0.426t + L

units of CPU time, assuming that we have tuned L-step SLA so that the acceptance rate is
0.574. Also let 1 unit of jump size be the expected jump size of 1-step SLA, then L-step SLA
has an expected jump size of L2/3 units, and the ‘eﬃciency’ of L-step SLA is calculated as jump
size divided by computing cost,

L2/3
1.426 + 0.426t + L

,

which is maxmised at L = 2(1.426 + 0.426t). Our conclusion is that SLA can be improved by
using L-step SLA with L > 1, and the optimal value of L depends on the cost of evaluating φd.
If t = 0, then L = 3 is optimal. Figure 5.1 shows the eﬃciency of L-step SLA for other values
of t.

This analysis can be repeated for other L-step algorithms.

33

5.4 Hybrid Monte Carlo

Another type of AR(1) proposal, that ﬁts our theory when πd is Gaussian, are proposals from
the Hybrid (or Hamiltonian) Monte Carlo algorithm (HMC), see e.g. [16, 6, 26]. For this section,
suppose that the target πd is the Gaussian N(A−

1b, A−

1).

∈

∈

Rd as the initial position of a particle, the initial momentum
HMC treats the current state x
Rd of the particle is chosen independently at random, and then the motion of the particle
p
is evolved according to a Hamiltonian system for a ﬁxed amount of time. The ﬁnal position of
the particle is the proposal. Instead of solving the Hamiltonian system exactly, the evolution of
the particle is approximated using a reversible, symplectic numerical integrator. For example,
the leap-frog method (also called the Stormer-Verlet method) is an integrator that preserves a
1), is computed
modiﬁed Hamiltonian, see e.g. [23]. Hence, the proposal y, for target N(A−
d be a symmetric positive deﬁnite matrix and deﬁne a Hamiltonian
as follows; let V
×
R by
function H : Rd

1b, A−

∈
Rd

Rd

×

→

H(q, p) :=

pT V p +

1
2

1
2

qT Aq

bT q.

−

Given a time step h > 0, a number of steps L
and sample p0 ∼

∈
1). Then for l = 0, . . . , L

N(0, V −

N, and current state x

1 compute

h

−
pl+1/2 = pl −
2 (Aql −
ql+1 = ql + hV pl+1/2,
pl+1 = pl+1/2 −

h

b),

2 (Aql+1 −

b).

(5.15)

Rd, deﬁne q0 := x,

∈

The proposal is then deﬁned as y := qL. In matrix form we have

ql+1
pl+1 (cid:21)

(cid:20)

= K

ql
pl (cid:21)

(cid:20)

+ J

0
h
2 b

(cid:21)

(cid:20)

where K, J

∈

R2d

×

2d are deﬁned as

K =

I
0
h
2 A I

(cid:20)

−

(cid:21) (cid:20)

I hV
I
0

I
0
h
2 A I

=

(cid:21)

"

−

(cid:21) (cid:20)

−

h2
2 V A
I
−
hA + h3
4 AV A I

hV
h2
2 AV #

−

and

J =

(cid:20)
Hence, y is given by

I
0
0 I

+

(cid:21)

(cid:20)

−

I
0
h
2 A I

(cid:21) (cid:20)

I hV
I
0

=

(cid:21)

(cid:20)

2I
h
2 A 2I

−

hV
h2
2 AV

−

.

(cid:21)

y
pL (cid:21)

(cid:20)

= K L

x
ξ

+

(cid:21)

(cid:20)

L

1

−

Xl=0

K lJ

0
h
2 b

(cid:21)

(cid:20)

where ξ

∼

N(0, V ),

(5.16)

or equivalently,

y = (K L)11x +

SJ

(cid:20)
and (K L)ij is the ij block (of size d
).
entries of the vector (
·

(cid:18)

0
h
2 b

(cid:21)(cid:19)1

+ (K L)12ξ,

where ξ

∼

N(0, V −

1),

(5.17)

d) of K L, S = (I

K)−

1(I

K L) and (
)1 are the ﬁrst d
·

−

−

×

34

In the case of only one time step of the leap-frog integrator (L = 1) then HMC is MALA [6].
Hence, we immediately know that the HMC proposal with L = 1 is an AR(1) proposal where
the proposal limit and target distributions are not the same, and the expected acceptance rate
and jump size are given by Theorem 5.1.2. The case for L > 1 is more complicated, but (5.17)
is still an AR(1) proposal that can be expressed as a matrix splitting using (1.5). The proofs of
the following two results are in the Appendix.

Theorem 5.4.1 The HMC proposal (5.17) corresponds to the matrix splitting

M = Σ−

1(I + (K L)11),

= Σ−

1(I

(K L)2

11),

−

A

N = Σ−

1(I + (K L)11)(K L)11,

β = Σ−

1(I + (K L)11)

(SJ

where Σ = (K L)12V −
12.
Corollary 5.4.1 The matrix splitting from HMC satisﬁes

1(K L)T

(cid:18)

(cid:20)

1β = A−

1b.

A−

0
h
2 b

,

(cid:21)(cid:19)1

These results imply that the proposal chain for HMC converges to N(A−
= A, rather than the desired target N(A−

1) where
1), so the MH accept/reject step is necessary

1b, A−

A−

1b,

A 6
even when the target is Gaussian.

For the analysis of HMC we require the eigenvalues of the iteration matrix. A proof of the

following result is in the Appendix.
Theorem 5.4.2 Let λ2
eigenvalues). Then the iteration matrix G = (K L)11 for the HMC proposal has eigenvalues

i be eigenvalues of B = V 1/2AV 1/2 or V A (these matrices have the same

where θi =

cos−

1(1

−

h2
2 λ2
i ).

−

Gi = cos(Lθi)

From this theorem we see how the eigenvalues of the iteration matrix depend on V , the
number of time steps L, and the time step h. Again we refer to V as a preconditioner (as in
[7]) because it plays a similar role to a preconditioner for solving linear systems of equations.
Alternatively, V may be referred to as a mass matrix since p in the Hamiltonian (5.15) is
momentum and H is energy.

To complete our analysis of HMC we restrict our attention to the case when d

and
try to apply Theorems 3.1.2 and 3.2.1. These theorems require that the splitting matrices are
functions of the target precision matrix. A simple change of coordinates achieves this.

→ ∞

Theorem 5.4.3 Under the change of coordinates

x
p

(cid:20)

1

−

x
p

,

(cid:21)

(cid:20)

↔ V

(cid:21)

where

V

=

0
1/2
V −

∈

(cid:21)

R2d

×

2d,

V 1/2
0

(cid:20)
1b, A−

the Hamiltonian (5.15) and HMC with target N(A−
to a Hamiltonian, and MH algorithm deﬁned by

1) and proposal (5.17) are transformed

Hamiltonian:

H

(x, p) := 1

2 pT p + 1
1),

1V 1/2b, B−

2 xT Bx

Target: N(B−

(V 1/2b)T x,

−

(5.18)

Proposal:

y = (

K

L)11x +

0
h
2 V 1/2b

(cid:21)(cid:19)1

SJ

(cid:18)

(cid:20)

L)12ξ, for ξ

+ (

K

N(0, I),

∼

35

where B = V 1/2AV 1/2,

= (I

S
h2
I
2 B
−
hB + h3
4 B2

)−

1(I

L),

− K

− K

hI
h2
2 B #

−

I

and

=

J

(cid:20)

2I
h
2 B 2I

−

hI

h2
2 B

−

.

(cid:21)

=

K

"

−

Moreover, the proposal in (5.18) corresponds to the matrix splitting

= M

A

−

N with

M = (

K

N = (

K

L)−

2
12 (I +(

K

L)−

2
12 (I +(

K

L)11),

L)11)(

K

L)11,

= (

K

A

β = (

K

(
K

L)−

2
12 (I

−
2
12 (I +(

L)−

K

L)2

11),

L)11)

0
h
2 V 1/2b

.

(cid:21)(cid:19)1

SJ

(cid:18)

(cid:20)

Proof. Use K =

VKV −

1 and J =

1.

VJ V −

Similar coordinate transformations are used in classical mechanics [1, p. 103], see also [13].

MH algorithm (5.18) has splitting matrices that are functions of the target precision matrix,
so we can apply Theorems 3.1.2 and 3.2.1 to (5.18) to reveal information about the performance
of the original HMC algorithm. A proof of the following result is in the Appendix.

Theorem 5.4.4 Suppose there are constants c, C > 0 and κ
B = V 1/2AV 1/2 (equivalently, V A or AV ) satisfy

≥

0 such that the eigenvalues of

If h = ld−
(5.17) and target N(A−

−

≤
κ for l > 0, and L =
1b, A−

1/4

T
h ⌋

⌊

1)), in equilibrium, satisﬁes

ciκ

Ciκ

λi ≤

for i = 1, . . . , d.

for ﬁxed T , then the HMC algorithm (with proposal

E[α(x, y)]

→

a(l) := 2Φ

l2√τ
8

(cid:19)

−

(cid:18)

(5.19)

where τ = limd

→∞

1
d1+4κ

d
i=1 λ4

i sin2(λiT ′) and for eigenvector qi of B corresponding to λ2
i ,

qT
i V −
E[
|

P
1/2(x′

2] = 2
x)
|

−

1

−

cos(λiT ′)

λ2
i

a(l) + o

1

−

(cid:18)

cos(λiT ′)

λ2
i

(cid:19)

(5.20)

as d

→ ∞

, where T ′ = Lh.

The above result is an extension to the results in [7, 6] since their results only cover the

situation when the target distribution has diagonal covariance, and κ > 1/2 or κ = 0.

Note that in the above theory if we take h = ld−

4 + κ then we would ﬁnd
that the expected acceptance rate would either tend to 0 or 1. As is well known for Metropolis-
Hastings algorithms, the optimal acceptance rate usually lies somewhere between 0 and 1 and
κ is the correct scaling of h to the dimension to achieve this. However, even
taking h = ld−
with this scaling we are still free to tune h by varying l and from the above result we can derive
the optimal acceptance rate for HMC for a wider class of problems than previously studied in
[6, 7].

1/4

−

r for some r

= 1

For the eﬃciency of HMC, as well as considering the expected squared jump size of the chain,
and
we must also consider the compute time per proposal which is proportional to L =
depends on d. Therefore, to maximise eﬃciency of HMC we must maximise the expected jump

T
h ⌋

⌊

36

6
size divided by the compute time for a proposal. With all other quantities held constant, this
corresponds to varying l to maximise

la(l) = C√sΦ(s)

where s = l2√τ
and C is a constant, which is maximised at s0 = 0.4250, which corresponds to
8
an expected acceptance rate of 2Φ(s0) = 0.651. This is the same acceptance rate found in [6]
where they considered target distributions that are product distributions with λi constant for
all i.

Our theory goes further than earlier results in [6] and [7] for HMC because we also provide
guidance on how to choose the other parameters in HMC: V and T . From Theorem 5.4.4 we see
that we should choose V in a similar way to how we would choose a preconditioner for solving
a linear system of equations. We should choose V to control the spread of eigenvalues of V A so
that κ is as small as possible and τ is minimised, and we should choose V so that the action of
1) are cheap to compute. This result
matrix multiplication with V and sampling from N(0, V −
1, the perfect preconditioner, but if it
is touched on in [7] where they suggest taking V = A−
is possible to sample from N(0, A) then other sampling algorithms may be more eﬃcient than
HMC, particularly when the target distribution is N(A−

1b, A−

1).

Our theory also shows how to choose T to maximise eﬃciency. After tuning h to achieve an

acceptance rate of 0.651 the expected squared jump size satisﬁes

qT
i V −
E[
|

1/2(x′

2]
x)
|

−

→

1.302

1

−

cos(λiT ′)

λ2
i

as d

.

→ ∞

By ﬁrst deciding which i correspond to directions we need to consider for our statistic of interest
cos(λiT ′)
(this will depend on the eigenvectors qi of AV ) we can then choose T to maximise 1
for those i. Thus, how we choose T depends on the problem, V and our statistic of interest. In
the special case when λi are equal then we should choose T = π
λi

−

.

The theory presented here is for the leap-frog numerical integrator applied to the Hamiltonian
system. Higher order integrators are also suggested in [6] and alternative numerical integrators
based on splitting methods (in the ODEs context) are suggested in [13] that minimize the
Hamiltonian error after L steps of the integrator. It may be possible to evaluate these other
methods by ﬁrst expressing them as a an AR(1) proposal and writing down the corresponding
matrix splitting, then applying Theorems 3.1.2 and 3.2.1 after a change of variables; as we have
done for the leap-frog integrator.

For non-Gaussian target distributions, we cannot apply Theorems 4.1.4 and 4.2.1 to this
9 0 as
x

, since ˜g2

1

1

i λ−
i

, gi˜λ−
i

T
h ⌋

⌊

), since Eπd[
y
|

−

2q
r ] 9 0 as d
|

→ ∞

, see the proof of Theorem 5.4.4 in the Appendix.

HMC algorithm (with L =
d

→ ∞

37

38

Chapter 6

Concluding remarks

Until now, each MH algorithm with an AR(1) proprosal has required its own analysis, e.g.
RWM, MALA, SLA, pCN and HMC. In this article we have designed a unifying theory that
encompasses all of these AR(1) proposals (except RWM) and other general AR(1) proposals
where G and Σ are functions of A, for the case where the target distribution is a change of
measure from a Gaussian reference measure.

The main analysis tool we used is matrix splitting. By writing an AR(1) proposal in terms of
a matrix splitting, and requiring that the splitting matrices are functions of the target reference
precision matrix A, then a simple change of variables diagonalises both the target reference A
and the matrices in the proposal; G and Σ. A consequence of this fact is that it is suﬃcient to
analyse MH algorithms where the proposal and target reference are deﬁned by diagonal matrices.
Essentially, we reduce the general case back to MH algorithms where the target reference measure
is a product distribution, for which existing analysis of MALA, SLA and HMC can be extended
to general AR(1) proposals.

[0, 1]. For HMC, we extended results in [6] to the case when κ

In particular, we wrote down the obvious extension of results for Langevin proposals in [9]
to the case where the target reference measure is Gaussian with non-diagonal covariance and
θ
0 from κ = 0, we derived a
new formula for the eigenvalues of the iteration matrix of the HMC proposal, and we provided
criteria on how to choose T and V for HMC (previous analysis only said to adjust h until the
acceptance rate is 0.651).

≥

∈

We also analysed a variation of the SLA algorithm where L steps of the proposal are taken
before the accept/reject step. We simpliﬁed the evaluation of the acceptance probability using
the surrogate transition method, and we found that, in the circumstances considered, it is
optimal to take L > 1 steps of SLA.

The analysis presented here requires that the splitting matrices are functions of the target
reference precision matrix. In high dimensions this is a natural assumption to make because
factorizing A may be computationally infeasible.

Designing proposals for the MH algorithm to achieve eﬃcient MCMC methods is a challenge,
particularly for non-Gaussian target distributions, and the job is made harder by the diﬃcultly
we have in analysing the convergence properties of MH algorithms. By focusing on AR(1)
proposals in high dimension we have proven new theoretical results that provide us with criteria
for evaluating and constructing new AR(1) proposals for eﬃcient MH algorithms.

Designing an eﬃcient MH algorithm with an AR(1) proposal is often a balancing act between
minimising the integrated autocorrelation time (we use maximising expected jump size as a proxy
for this) and minimising compute time for each iteration of the chain. If the proposal limit and

39

target distributions are Gaussian and identical then it follows from the theory in [17, 19, 18]
that to construct an eﬃcient AR(1) process we should try to satisfy the following conditions:

1. The spectral radius of G should be as small as possible.

2. Computing an iteration of the stochastic AR(1) process should be as cheap. This means
that the action of G and independent sampling from N(0, Σ) should be cheap to compute.

If the target distribution is Gaussian and diﬀerent from the proposal distribution then Theorems
3.1.2 and 3.2.1 suggest that, in addition, we should try to satisfy:

3. The diﬀerence between the target and proposal limit distributions should be as small
as possible in the sense that the diﬀerence in means should be small, and the relative
diﬀerence in precision matrix eigenvalues should be small.

If the target distribution is non-Gaussian, then Theorems 4.1.4 and 4.2.1 suggest how we should
try to satisfy:

3. The diﬀerence between the target reference and proposal limit distributions should be as
small as possible in the sense that the diﬀerence in means should be small, and the relative
diﬀerence in precision matrix eigenvalues should be small.

In particular examples we can quantify these conditions using our theory. For example, for
proposals based on discretized generalised Langevin diﬀusion, Theorem 5.2.2 shows us how the
choice of symmetric positive deﬁnite matrix V eﬀects eﬃciency as it eﬀects squared jump size
in four ways. Whilst choosing V to maximise the limit in (5.10) (by minimising κ and τ ) we
should balance this against the scaling and direction that V induces on E[qT
x)2]
through qi and V −

1/2 on the left-hand side of (5.10).

1/2(x′ −

i V −

Another example, pCN, satisﬁes conditions 1 and 3 above, but not necessarily condition 2.
In particular, G is the diagonal matrix with entries all 1
1+h/4 on the diagonal, and
= A and
−
A
1), which
β = b. However, each proposal for pCN requires an independent sample from N(0, A−
In the special case when A is diagonal, or a spectral
may be infeasible in high dimensions.
decomposition of A is available, then pCN satisﬁes all of our conditions for an eﬃcient method.

h/4

Proposals for MALA and HMC are examples of proposals that are constructed by discretizing
a stochastic diﬀerential equation that preserves the target distribution. Our theory allows us
to consider a wider selection of possible AR(1) proposals for the MH algorithm, that are not
necessarily based on discretizing a stochastic diﬀerential equation.

40

Appendix A

Proofs

A.1 Proof of Lemma 3.1.1

First note that

∝
Simple algebra then yields

q(x, y)

exp( 1

2 (M y

N x

−

−

β)T (M + N )−

1(M y

N x

−

−

β)).

2 log

(cid:18)

πd(y)q(y, x)
πd(x)q(x, y)

=

(cid:19)

−

=

−

=

−

yT Ay + xT Ax + 2bT (y

x)

−
β)T (M + N )−
β)T (M + N )−

(M x

N y

−

−

−
N x
+ (M y
yT Ay + xT Ax + 2bT (y

−

−

x)

−

1(M x
1(M y

N y

N x

β)

β)

−

−

−

−

((M

N )(x + y))T (M + N )−

1((M + N )(x

−
−
+ 2βT (M + N )−
yT (A

)y + xT (A

− A

1((M + N )(x

y))

−
)x + 2(b

− A

β)T (y

x).

−

−

y))

−

A.1.1 Proof of Lemma 3.2.1

Suppose limd
that for any d > D,
P
exists a D

→∞

(

r)/(
ti|

d
ti|
i=1 |
d
i=1 |
k such that for any d > D,
P
d

d
i=1 t2
r < ǫ(
P

P

≥

r

tk|
|

Therefore, for any d > D, t2

k < 1
2

≤

Xi=1
d
i=1 t2

r <

ti|
|

1
2r/2  

r/2

.

d

Xi=1

t2
i

!

i and so

i )r/2 = 0. Then for any ǫ > 0 there exists a D
N, taking ǫ = 2−

i )r/2. Then for any k

d
i=1 t2

N such
∈
r/2, there

∈

d
i=1,i

P
r

r/2

ti|
=k |
=k t2
i

<

r

d
ti|
i=1 |
d
i=1 t2
i

1
2

P

= 2r/2

r/2

(cid:17)

(cid:16)

P

(cid:17)

d
P
i=1,i

(cid:16)P

r

.

r/2

d
ti|
i=1 |
d
i=1 t2
P
i
(cid:16)P

(cid:17)

A.2 Proof of Theorem 5.2.2

We use the following technical lemma in the proof of Theorem 5.2.2.

41

6
6
Lemma A.2.1 Suppose
0. If s > 3, then limd
κ

ti} ⊂
{

R is a sequence such that 0 < ti ≤
d
i=1 ts

i = 0.

≥

→∞

Cd−

1/3( i

d )2κ for C > 0 and

P

Proof.

lim
d
→∞

d

Xi=1

ts
i ≤

C s lim
d
→∞

s/3

d1
−

d

2κs

1
d

i
d

Xi=1

(cid:0)

(cid:1)

= C s lim
d
→∞

s/3

d1
−

1

0

Z

z2κsdz = 0.

Proof of Theorem 5.2.2. First note that V A and V 1/2AV 1/2 are similar, so they have the same
eigenvalues. Lemma 5.2.1 implies that it is equivalent to study the MH algorithm with target
and proposal given by (5.8). We now attempt to apply Theorems 4.1.4 and 4.2.1 to (5.8). Note
that the splitting matrices for (5.8) are functions of B = V 1/2AV 1/2. Let td,i = hλi =
t)
d )2κ =
for t = 1/3 + κ, let si = hλ2

1/3) and let ρ = (θ

1
2 )/2. Then

i = ld−

1/3( λi

(d−

(d−

O

O

−

˜λ2
i = (1 + ρsi)λ2
i ,

Gi = 1

ri =

ρsi,

−

˜ri =

1
2 si
1 + θ
−
1
1 + ρsi

,

2 si

,

˜gi =

1
2 si
1 + θ

2 si

,

gi =

si(1 + ρsi)
1 + θ

2 si

,

ˆri = 0,

so that

Hence

T0i = T1i = T2i = 0,
1
2 ρs2
(1 + θ

i (1 + ρsi)
2 si)2

T3i = −

,

T4i =

1
2 ρs2
i
(1 + θ
2 si)2

,

T5i =

1

2 ρs3/2

1

θ
(1
2 si)
−
i
−
(1 + θ
2 si)2

.

i ˆr2
˜g2

i λi = 0,

˜g2
i λ−

1
i =

O

(td,isi) = o(td,i),

gi˜λ−

1
i =

(td,i),

O

˜ri =

(1)

O

as d

, and T3i =

→ ∞
We also have

(d−

2/3), T4i =

O

O

(d−

2/3) and T5i =

(d−

1/2) as d

O

.

→ ∞

d

d

T3i + T4i

µ = lim
d
→∞

= lim
d
→∞

Xi=1
ρ2
2

−

µi = lim
d
→∞
Xi=1
s3
i
(1 + θ
2 si)2

d

Xi=1

= lim
d
→∞

−

ρ2
2

d

Xi=1

s3
i =

−

l6(θ

1
2 )2τ

,

−
8

42

and using Lemma A.2.1,

d

Xi=1
d

Xi=1
d

Xi=1
d

σ2
i = lim
d
→∞

1
(1 + θ
2 si)4

d

2T 2

3i + 2T 2

4i + T 2
5i

Xi=1
1

2 ρ2s4

i (1 + ρsi)2 + 1

2 ρ2s4

i + 1

4 ρ2s3

i (1

1

θ

2 si)2

−

−

(cid:0)

(cid:1)

1

2 ρ2s4

i (1 + ρsi)2 + 1

2 ρ2s4

i + 1

4 ρ2s3

i (1

1

θ

2 si)2

−

−

(cid:0)
4 ρ2s3
1

i

(cid:1)

σ2 = lim
d
→∞

= lim
d
→∞

= lim
d
→∞

= lim
d
→∞

Xi=1
l6(θ

1
2 )2τ

.

−
4

= lim
d
→∞
d
i=1 T 2

P

d

Xi=1
µ
σ =

Hence limd

→∞

1i + T 2

2i + 2T 2

3i + 2T 2

4i + T 2

5i <

. Also note that, by Lemma A.2.1,

∞

lim
d
→∞

1i + T 2
T 2

3i = lim
d
→∞

d

Xi=1

T 2
3i = lim
d
→∞

d

Xi=1

1

4 ρ2s4

i = 0.

It follows that µ
θ
σ =
|
Theorem 4.1.4, using Corollary 4.1.1.

l3

−

−

−

σ

1
2 |

−

√τ /4 and µ + σ2

2 = 0. Hence we obtain (5.9) from

For the expected jump size, ﬁrst note that ˆri = 0. Also,

gi
˜λ2
i

=

h
1 + θ
2 si

= h +

O

(hsi) = h + o(h),

as d

,

→ ∞

and using the fact that γ2

d,i is uniformly bounded (see proof of Theorem 4.1.4),

i γ1/2
˜g2
d,i
λ2
i

=

O

(cid:18)

s2
i
λ2

i (cid:19)

=

O

(hsi) = o(h)

as d

.

→ ∞

Therefore, applying Theorem 4.2.1 to the MH algorithm (5.8) we ﬁnd

Eπd[(qT

i (x′i −

xi))2] = 2hΦ

l3

θ
|

−
4

√τ

1
2 |

!

 −

+ o(h)

as d
→ ∞
obtain (5.10).

, where πd is given in (5.8). Reversing the coordinate transformation x

V −

1/2x we

↔

A.3 Proof of Lemma 5.3.1

By replacing πd with π∗ in the proof of Lemma 3.1.1 it follows that

π∗(x)q(x, y) = π∗(y)q(y, x)

43

,
where q corresponds the transition kernel for the SLA proposal. That is, q(
·
). It then follows from
balance with respect to π∗(
·

) satisﬁes detailed
·

qL(x, y) =

· · ·

Z

Z

q(x, y(1))q(y(1), y(2))

q(y(L

−

1), y) dy(1)dy(2)

dy(L

−

1)

· · ·

· · ·

,
that qL(
·

), so that
) satisﬁes detailed balance with respect to π∗(
·
·

π∗(x)qL(x, y) = π∗(y)qL(y, x)

Using this fact, we ﬁnd

πd(y)qL(y, x)
πd(x)qL(x, y)

=

πd(y)
π∗(y) π∗(y)qL(y, x)
πd(x)
π∗(x) π∗(x)qL(x, y)

=

πd(y)
π∗(y) π∗(y)qL(y, x)
πd(x)
π∗(x) π∗(y)qL(y, x)

=

πd(y)π∗(x)
πd(x)π∗(y)

.

Hence, result.

A.4 Proof of Theorem 5.3.1

We prove this theorem by applying Theorems 4.1.4 and 4.2.1 to L-step SLA. First, let us check
h
2 A, Σ = hI be the proposal matrices for the
the conditions for these theorems. Let G = I
−
SLA proposal. These matrices are functions of A. It follows that GL and ΣL for the L-step SLA
proposal are also functions of A and GLΣL is symmetric. It then follows from Corollary 2.1.1
that the splitting matrices for L-step SLA are also functions of A.

Let td,i = hλi =

κ) and si = hλ2
SLA are the same as for SLA, from the proof of Theorem 5.2.2 we have ˜λ2
ri = 1
(1).

1/3) as d

→ ∞

i =

1 =

(d−

(d−

1/3

O

O

−

. Since

A
i = (1

and β for L-step
i , ˆri = 0,

1
4 si)λ2

−

1
4 si)−

4 si and ˜ri = (1
−
1
2 si so the eigenvalues of GL are GL
i = Lsi +

Also, Gi = 1
−
i = L
2 si +

i ) and gLi = 1

G2L

GL

(s2

O

O

˜gLi = 1

−

i = (1

−
(s2
i ).

O

1
2 si)L = 1

L
2 si +

O

−

(s2

i ). Hence,

−
1
i =
Liλ−

(s2

i λ−
i

1

) =

O

O

(sitd,i) = o(td,i), and gLi˜λ−

1
i =

It then follows that ˜g2

i ˆr2

i λi = 0, ˜g2

(td,i).

O

We also have for L-step SLA,

T3i = 1

8 Ls2

i +

(s3

i ), T4i =

O
2/3), T4i =

1

8 Ls2

i +

−

O
2/3) and T5i =

(d−

O

O
O
We can also calculate, using Lemma A.2.1,

so T3i =

(d−

(d−

1/2).

(s3

i ),

T5i =

−

1
4 si(Lsi +

O

(s2

i ))1/2(1 +

(si)),

O

lim
d
→∞

d

Xi=1

T 2
3i = 1

64 L2 lim

d

→∞

s4
i = 0,

d

Xi=1

and similarly, limd

→∞

d
i=1 T 2

4i = 0, and as in the proof of Theorem 5.2.2 (calculating σ2),

P

d

lim
d
→∞

Xi=1

T 2
5i = lim
d
→∞

d

Xi=1

44

1

16 Ls3

i = L

l6τ
16

=: σ2
L,

Using Lemma A.2.1, and as for calculating µ in the proof of Theorem 5.2.2,

T3i + T4i = lim
→∞

d

d

Xi=1

1

2 rigi(˜ri −

−

1)

1

32 Ls3

i +

(s4
i )

O

1

32 Ls3

i

−

−

µL = lim
→∞

d

= lim
d
→∞

d

Xi=1
d

Xi=1
d

= lim
d
→∞

=

L

−

Xi=1
l6τ
.
32

Hence, we obtain (5.12) from Theorem 4.1.4 and Corollary 4.1.1.

For the expected jump size, (5.13) follows from ˆri = 0, gLi˜λ−

2
i = Lh + o(h), ˜g2

Liλ−

2
i = o(h),

and γd,i bounded uniformly (see proof of Theorem 4.1.4).

A.5 Proof of Theorem 5.4.1

The result will follow from Corollary 2.1.1 with G = (K L)11 and Σ = (K L)12V −
we must ﬁrst check that GΣ is symmetric. Deﬁne
K =

12 but
and B as in Theorem 5.4.3. Then

1, so that K L =

1(K L)T

K

V

L

,

VKV −

VK
(K L)11 = V 1/2(

1 and
V −
L)11V −

1/2

K

and (K L)12 = V 1/2(

K

L)12V 1/2.

Then

GΣ = V 1/2(

K

L)11(

K

L)2

12V 1/2

which is symmetric because V and B are symmetric and (
B.

K

L)11 and (

K

L)12 are polynomials of

A.6 Proof of Corollary 5.4.1

First note that

so we are required to show that

(I

−

(K L)11)

A

1β =

−

SJ

(cid:18)

(cid:20)

which holds if

(I

Using S = (I

K)−

1(I

−

−

which is easy to check.

(K L)11)A−

1b =

SJ

(I

−

(cid:18)

(cid:20)

= SJ

K L)

−

1b
A−
0

(cid:20)
(cid:20)
K L), we can equivalently show

(cid:21)

(I

−

K)

(cid:20)

1b
A−
0

= J

(cid:21)

(cid:20)

0
h
2 b

,

(cid:21)

45

0
h
2 b

0
h
2 b

,

,

(cid:21)(cid:19)1

(cid:21)(cid:19)1

0
h
2 b

.

(cid:21)

A.7 Proof of Theorem 5.4.2

Deﬁne a spectral decomposition

V 1/2AV 1/2 = QΛQT

(A.1)

where Q is an orthogonal matrix and Λ = diag(λ2
of V 1/2AV 1/2 (V A is similar to V 1/2AV 1/2 so they have the same eigenvalues). Also deﬁne
as in Theorem 5.4.3 and

d) is a diagonal matrix of eigenvalues

1, . . . , λ2

V

A similarity transform of K is deﬁned by

Q 0
0 Q

˜Q =

(cid:20)

∈

(cid:21)

R2d

×

2d.

K =

V

˜Q ˜K ˜QT

V

1 with

−

˜K =

h2
I
2 Λ
−
hΛ + h3
4 Λ2

"

−

hI
h2
2 Λ #

−

.

I

Hence K and ˜K have the same eigenvalues. Moreover, K L =

˜Q ˜K L ˜QT

V

V −

1 and it follows that

(K L)11 = V 1/2Q( ˜K L)11QT V −

1/2.

Thus (K L)11 and ( ˜K L)11 are similar.

Notice that ˜K is a 2

d block is diagonal. Therefore, ˜K L is
2 block matrix with diagonal blocks. In particular, ( ˜K L)11 is a diagonal matrix, so

2 block matrix where each d

also a 2
the eigenvalues of ( ˜K L)11 are on the diagonal of ( ˜K L)11. Moreover,

×

×

×

[( ˜K L)11]ii = (kL

i )11

where [( ˜K L)11]ii is the ith diagonal entry of ( ˜K L)11, (kL
kL
i ∈

2, and ki ∈

2 is deﬁned by

R2

R2

×

×

i )11 is the (1, 1) entry of the matrix

ki =

(cid:20)

( ˜K11)ii
( ˜K21)ii

( ˜K12)ii
( ˜K22)ii (cid:21)

=

h2
2 λ2
1
i
−
i + h3
4 λ4
hλ2
i

"

−

h
h2
2 λ2

i #

.

1

−

The matrix ki can be factorized

1 0
0 a

ki =

(cid:20)

(cid:21) (cid:20)

cos(θi)
sin(θi)

sin(θi)
−
cos(θi)

1
0
0 a−

1

(cid:21)

(cid:21) (cid:20)

where a = λ

1

q

h2
4 λ2

i and θi =

−

cos(1

−

−

h2
2 λ2

i ). Therefore,

kL
i =

1 0
0 a

(cid:20)

(cid:21) (cid:20)

cos(Lθi)
sin(Lθi)

sin(Lθi)
−
cos(Lθi)

1
0
0 a−

1

(cid:21)

(cid:21) (cid:20)

and hence

[( ˜K L)11]ii = (kL

i )11 = cos(Lθi).

46

A.8 Proof of Theorem 5.4.4

Theorem 5.4.3 implies that it is equivalent to study the MH algorithm with target and proposal
L)12 are functions of B we can apply Theorems 3.1.2
given by (5.18), and since (
and 3.2.1. Using the spectral decomposition (A.1) note that

L)11 and (

K

K

L)ij = Q( ˜K L)ijQT

for i, j = 1, 2.

(
K

where ˜K is deﬁned in the proof of Theorem 5.4.2, and where it is shown that ( ˜K L)ij is diagonal
and

[( ˜K L)11]ii = cos(Lθi)

where θi =

cos−

1(1

−

−

h2
2 λ2

i ). Similarly,

[( ˜K L)12]ii =

1

a−
i

−

sin(Lθi)

where ai = λi
let si = h2λ2

1
−
i = l2d−
q

h2
4 λ2
1/2( λi

i . Moreover,
dκ )2 =
(d−

O

= Q( ˜K L)2

12(I

A
1/2), then

( ˜K L)2

11)QT so that ˜λ2

i =

−

a2
i and if we

−

˜λ2
i = λ2
i (1
ri = 1
4 si,

1
4 si),

−

Gi = cos(Lθi),
˜ri = 1
1
1
4 si
−

,

˜gi = 1
ˆri = 0.

−

cos(Lθi),

gi = sin2(Lθi),

Note that we used Corollary 5.4.1 to show ˆri = 0. Then

T0i = T1i = T2i = 0,

T3i = 1

8 si sin2(Lθi),

T4i =

−

1
8 si sin2(Lθi)
1
4 si

1

−

,

T5i =

−

1
8 si sin(2Lθi)

1
4 si

1

−

q

.

Using the trigonmetric expansion cos−
L = T ′

h we ﬁnd

1(1

−

z) = √2z +

O

(z3/2), and deﬁning T ′ such that

Lθi = L(

−

√si +

O

(s3/2
i

)) =

Ls1/2
i

(1 +

−

(si)) =

O

−

T ′λi(1 +

O

(d−

1/2))

hence, there exists a function T ′′(d) such that Lθi =

T ′′λi and T ′′(d) = T ′ +

−

(d−

1/2).

O

To apply Theorems 3.1.2 and 3.2.1 we need to check (3.4). For some h > 0, cl2( i

d )2κ

≤

d1/2si = l2( λi

dκ )2

≤

Cl2( i

d )2κ and so we ﬁnd

2+δ

1+δ/2

d
i=1 |

T3i|
T3i|

2

lim
d
d
→∞ P
i=1 |
(cid:16)P

(cid:17)

d
i=1 |

si sin2(Lθi)
2+δ
|
si sin2(Lθi)
2
|

1+δ/2

(cid:17)

= lim
d
d
→∞ P
i=1 |
(cid:16)P
δ/2

d−

= lim
d
→∞

= 0




47



(cid:16)P

(cid:16)P

d
i=1 |
d
i=1 |

d1/2si sin2(T ′′λi)
2+δ
|

(cid:17)
d1/2si sin2(T ′′λi)
2
|

1/(2+δ)

2+δ

1/2 




(cid:17)

since
T5i. Now we can apply Theorem 3.1.2 with

v
kq ≤ k

kp for q

v
k

≥

p > 0 for lp-norms on Rd. Similar arguments verify (3.4) for T4i and

d

T3i + T4i

Xi=1

lim
d
→∞

lim
d
→∞

lim
d
→∞

lim
d
→∞

d

Xi=1
d

i sin2(Lθi)
s2
1
1
4 si

−

s2
i sin2(Lθi)

Xi=1
1
d1+4κ

1
d1+4κ

d

Xi=1
d

Xi=1

i sin2(λiT ′′(d))
λ4

i sin2(λiT ′)
λ4

µ = lim
d
→∞

1
32

1
32

l4
32

l4
32

=

−

=

−

=

−

=

−

=

l4τ
32

−

and similarly,

σ2 = lim
d
→∞

= lim
d
→∞

= lim
d
→∞

d

Xi=1
d

Xi=1
d

Xi=1

2T 2

3i + 2T 2

4i + T 2
5i

i sin4(Lθi) +
s2

i sin4(Lθi) +
s2

i sin4(Lθi)
s2
1
4 si)2
(1

−

+

1
64

i sin2(2Lθi)
s2

1
32

1
64

1
32

1
16

d

i sin2(2Lθi)
s2
1
4 si

1

−

i sin2(Lθi)
s2

Xi=1

=

=

1
16

lim
d
→∞

l4τ
16

.

Hence µ

σ =

σ

−

−

µ
σ =

l2√τ
8

−

and µ + σ2/2 = 0, so from Theorem 3.1.2 we obtain (5.19).

For the expected jump size, we apply Theorem 3.2.1 with

U1 =

=

+

˜g2
i
λ2
i
2(1

−

=

−

(1

gi
˜λ2
i
cos(λiT ′))
λ2
i

cos(Lθi))2

λ2
i

+

sin2(Lθi)
1
λ2
i (1
4 si)

−

2(1

=

−

cos(λiT ′))
λ2
i

+

si
λ2

i (cid:19)

O

(cid:18)

(h)

+

O

→ ∞

as d
σ− exist. Recall that Z
and using the fact that z

∼

. Also, it is straightforward to show that µi =
N(µ, σ2) and X

N(µ−, (σ−)2), then X
ez is monotone and globally Lipschitz continuous

−

∼

−

∼

1) and σ2
Z

i =

O
N(

(d−

1), so µ− and
µi, σ2 + (σ−)2),

(d−

O

1

∧

7→

U2 −
|

E[α(x, y)]
|

=

E[1
|

∧

eX ]

E[1

∧

−

48

eZ ]

E[X

Z]
|

−

=

=

µi|
|

O

(d−

1).

| ≤ |

1

1
4 si

1

−

sin2(Lθi)

!

Then U2 = E[α(x, y)] +

(d−

1) as d

O

, and

→ ∞

= (σ2

i + µ2

U3|
|

= (σ2

i + µ2

˜g2
i + ˜rigi

(cid:0)

(cid:1)

i )1/2 √3
λ2
i
i )1/2 √3
λ2

i  

(d−

1/2).

=

O

Therefore, we obtain (5.20).

cos(Lθi))2 +

(1

−

49

50

References

[1] V. I. Arnol′d. Mathematical methods of classical mechanics, volume 60 of Graduate Texts
in Mathematics. Springer-Verlag, New York, second edition, 1989. Translated from the
Russian by K. Vogtmann and A. Weinstein.

[2] Owe Axelsson. Iterative solution methods. Cambridge University Press, Cambridge, 1994.

[3] Myl`ene B´edard. Weak convergence of metropolis algorithms for non-i.i.d. target distribu-

tions. The Annals of Applied Probability, 17(4):1222–1244, 2007.

[4] Myl`ene B´edard. Optimal acceptance rates for metropolis algorithms: Moving beyond 0.234.

Stochastic Processes and their Applications, 118(12):2198 – 2222, 2008.

[5] Myl`ene B´edard and Jeﬀrey S. Rosenthal. Optimal scaling of Metropolis algorithms: heading

toward general target distributions. Canad. J. Statist., 36(4):483–503, 2008.

[6] A. Beskos, N. Pillai, G. Roberts, J.M. Sanz-Serna, and A. Stuart. Optimal tuning of the

hybrid Monte Carlo algorithm. Bernoulli, 19(5A):1501–1534, 2013.

[7] A. Beskos, F. J. Pinski, J. M. Sanz-Serna, and A. M. Stuart. Hybrid Monte Carlo on Hilbert

spaces. Stochastic Process. Appl., 121(10):2201–2230, 2011.

[8] A. Beskos, G. Roberts, A. Stuart, and J. Voss. MCMC methods for diﬀusion bridges. Stoch.

Dyn., 8(3):319–350, 2008.

[9] Alexandros Beskos, Gareth Roberts, and Andrew Stuart. Optimal scalings for local
Metropolis-Hastings chains on nonproduct targets in high dimensions. Ann. Appl. Probab.,
19(3):863–898, 2009.

[10] Alexandros Beskos and Andrew Stuart. Computational complexity of metropolis-hastings
methods in high dimensions. In Pierre L’ Ecuyer and Art B. Owen, editors, Monte Carlo
and Quasi-Monte Carlo Methods 2008, pages 61–71. Springer Berlin Heidelberg, 2009.

[11] Alexandros Beskos and Andrew Stuart. MCMC methods for sampling function space. In
ICIAM 07—6th International Congress on Industrial and Applied Mathematics, pages 337–
364. Eur. Math. Soc., Z¨urich, 2009.

[12] Patrick Billingsley. Probability and measure. Wiley Series in Probability and Mathematical
Statistics. John Wiley & Sons, Inc., New York, third edition, 1995. A Wiley-Interscience
Publication.

[13] Sergio Blanes, Fernando Casas, and J. M. Sanz-Serna. Numerical integrators for the hybrid

Monte Carlo method. SIAM J. Sci. Comput., 36(4):A1556–A1580, 2014.

[14] L.A. Breyer and G.O. Roberts. From metropolis to diﬀusions: Gibbs states and optimal

scaling. Stochastic Processes and their Applications, 90(2):181 – 206, 2000.

[15] S. L. Cotter, G. O. Roberts, A. M. Stuart, and D. White. MCMC methods for functions:

modifying old algorithms to make them faster. Statist. Sci., 28(3):424–446, 2013.

51

[16] Simon Duane, Anthony D Kennedy, Brian J Pendleton, and Duncan Roweth. Hybrid monte

carlo. Physics letters B, 195(2):216–222, 1987.

[17] Colin Fox. Polynomial accelerated mcmc and other sampling algorithms inspired by com-
In Josef Dick, Frances Y. Kuo, Gareth W. Peters, and Ian H.
putational optimization.
Sloan, editors, Monte Carlo and Quasi-Monte Carlo Methods 2012, volume 65 of Springer
Proceedings in Mathematics & Statistics, pages 349–366. Springer Berlin Heidelberg, 2013.

[18] Colin Fox and Albert Parker. Convergence in variance of Chebyshev accelerated Gibbs

samplers. SIAM J. Sci. Comput., 36(1):A124–A147, 2014.

[19] Colin Fox and Albert Parker. Accelerated Gibbs sampling of normal distributions using

matrix splittings and polynomials. Bernoulli; in the press, 2016.

[20] Mark Girolami and Ben Calderhead. Riemann manifold langevin and hamiltonian monte
carlo methods. Journal of the Royal Statistical Society: Series B (Statistical Methodology),
73(2):123–214, 2011.

[21] Jonathan Goodman and Alan D. Sokal. Multigrid monte carlo method. conceptual foun-

dations. Phys. Rev. D, 40:2035–2071, Sep 1989.

[22] Peter J. Green and Xiao-liang Han. Metropolis methods, Gaussian proposals and anti-
thetic variables. In Stochastic models, statistical methods, and algorithms in image analysis
(Rome, 1990), volume 74 of Lecture Notes in Statist., pages 142–164. Springer, Berlin, 1992.

[23] E. Hairer, C. Lubich, and G. Wanner. Geometric numerical integration, volume 31 of
Springer Series in Computational Mathematics. Springer-Verlag, Berlin, second edition,
2006. Structure-preserving algorithms for ordinary diﬀerential equations.

[24] P. Hall and C. C. Heyde. Martingale limit theory and its application. Academic Press,
Inc. [Harcourt Brace Jovanovich, Publishers], New York-London, 1980. Probability and
Mathematical Statistics.

[25] Jun S. Liu. Monte Carlo strategies in scientiﬁc computing. Springer Series in Statistics.

Springer-Verlag, New York, 2001.

[26] Radford M Neal. Probabilistic inference using markov chain monte carlo methods. Technical
Report CRG-TR-93-1, Department of Computer Science, University of Toronto Toronto,
Ontario, Canada, 1993.

[27] Jorge Nocedal and Stephen J. Wright. Numerical optimization. Springer Series in Opera-

tions Research. Springer-Verlag, New York, 1999.

[28] Natesh S. Pillai, Andrew M. Stuart, and Alexandre H. Thi´ery. Optimal scaling and diﬀusion
limits for the Langevin algorithm in high dimensions. Ann. Appl. Probab., 22(6):2320–2356,
2012.

[29] G. O. Roberts, A. Gelman, and W. R. Gilks. Weak convergence and optimal scaling of

random walk Metropolis algorithms. Ann. Appl. Probab., 7(1):110–120, 1997.

[30] Gareth O. Roberts and Jeﬀrey S. Rosenthal. Optimal scaling of discrete approximations to

Langevin diﬀusions. J. R. Stat. Soc. Ser. B Stat. Methodol., 60(1):255–268, 1998.

[31] Gareth O. Roberts and Jeﬀrey S. Rosenthal. Optimal scaling for various Metropolis-

Hastings algorithms. Statist. Sci., 16(4):351–367, 2001.

52

[32] Gareth O. Roberts and Richard L. Tweedie. Exponential convergence of Langevin distri-

butions and their discrete approximations. Bernoulli, 2(4):341–363, 1996.

[33] Pranab K. Sen and Julio M. Singer. Large sample methods in statistics: an introduction

with applications. Chapman & Hall, New York, 1993.

[34] A. M. Stuart. Inverse problems: a Bayesian perspective. Acta Numer., 19:451–559, 2010.

53

54

ETreport.cls v0.0

Electronics Group
Department of Physics
University of Otago
elec.otago.ac.nz

