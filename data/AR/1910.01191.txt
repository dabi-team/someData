Adaptive Generation of Phantom Limbs Using Visible Hierarchical
Autoencoders

Dakila Ledesmaa, Yu Liang*a, Dalei Wua

aDeparment of Computer Science and Engineering, University of Tennessee at Chattanooga, United States

9
1
0
2

t
c
O
2

]

C
H
.
s
c
[

1
v
1
9
1
1
0
.
0
1
9
1
:
v
i
X
r
a

Abstract

This paper proposed a hierarchical visible autoencoder in the adaptive phantom limbs generation according to the
kinetic behavior of functional body-parts, which are measured by heterogeneous kinetic sensors. The proposed visible
hierarchical autoencoder consists of interpretable and multi-correlated autoencoder pipelines, which is directly derived
from hierarchical network described in forest data-structure. According to speciﬁed kinetic script (e.g., dancing,
running, etc.) and users’ physical conditions, hierarchical network is extracted from human musculoskeletal network,
which is fabricated by multiple body components (e.g., muscle, bone, and joints, etc.) that are bio-mechanically,
functionally, or nervously correlated with each other and exhibit mostly non-divergent kinetic behaviors. Multi-
layer perceptron (MLP) regressor models as well as several variations of autoencoder models are investigated for the
sequential generation of missing or dysfunctional limbs. The resulting kinematic behavior of phantom limbs will be
constructed using virtual reality and augmented reality (VR/AR), actuators, and potentially controller for prosthesis
(an artiﬁcial device that replaces a missing body part). The addressed work aims to develop practical innovative
exercise methods that (1) engage individuals at all ages, including those with chronic health condition(s) and/or
disability, in regular physical activities, (2) accelerate the rehabilitation of patients, and (3) release users’ phantom
limb pain. The physiological and psychological impact of the addressed work will critically assessed in future work.

Keywords: Visible autoencoder, human musculoskeletal network, phantom limb, virtual reality, kinetics.

1. Introduction

This paper proposed a hierarchical auto-encoder neural network [1] in the adaptive phantom limbs generation
(denoted as PLG-HAE for simplicity) according to the kinetic behavior of functional body-parts, which are measured
by variance of kinetic sensors. Clinically, a phantom limb [2] is deﬁned by the sensation that an amputated or missing
limb is still attached [3]. To counteract phantom limbs, this work employs sensors and actuators, virtual reality and
augment reality, and deep learning to generate missing or dysfunctional limbs. As a an intelligent, four-dimensional
(namely X-Y-Z plus somatosensory), partial control (e.g., phantom limb generation), and virtual-reality-enabled re-
habilitation modality, this project directly inﬂuences the user’s motivation for movement [4].

It is known that various components of human body are correlated functionally, bio-mechanically, or nervously.
As a machine learning strategy, the proposed work generates phantom limbs from other functional and measurable
body parts by employing above correlations among human body [2]. As illustrated in Figure 1(a), x1, x2, x3, and x4
constitute the four input channels while the lower-limb-related input x4 is not valid for a seated user. Fortunately, we
can formulate x4 according to the correlation between x4 and other enabled inputs – x1, x2, and x3. The correlation
can be discovered using a supervised deep neural network (DNN) regression [6, 7], based on which the input x4 can
be reconstructed as a function of other known inputs: x(cid:48)
4 = DN N (x1, x2, x3). Tai-Chi movement is selected as the
script, there the training data comes from the recorded virtual Tai-Chi master’s kinetic data [8, 4]. As our preliminary
contribution, MLP and autoencoder methods are employed to construct phantom legs according to arm kinetics.

∗Corresponding author
Email address: yu-liang@utc.edu (Yu Liang*)

Preprint submitted to Neural Network

October 7, 2019

 
 
 
 
 
 
Figure 1: Compensation of disabled input channels via Deep Neural Network: (a) framework; (b) snapshot about the compensated kinetic status
of a wheel-chaired user, who receives “functional phantom legs” (in yellow color) through disable-channel compensation; (c) walking by moving
arms (online video [5])

Figure 1(b) shows a snapshot about the compensated kinetic status of a wheelchair-bound user, who received
“functional legs,” in compensation for the phantom limbs through compensation of missing data.
In this ﬁgure,
the compensation of missing data is generated by a neural network, and the visualization of this generated data
is done through a virtual environment, namely VR. Besides bringing to the forefront improvements to body gesture
recognition and motion generation, missing data compensation has potential clinical beneﬁt to users, i.e. as a treatment
to phantom limb pain [2].

Figure 2: Derivation of visible autoencoder Neural Network: (a) muscoloskeletal network; (b) sample hierarchical network in forest data structure;
(c) visible autoencoder neural network derived from hierarchical network.

As illustrated in Figure 2, the proposed visible hierchical autoencoder consists of interpretable and multi-correlated
autoencoder pipelines, which is directly derived from hierarchical network described in forest data-structure. Accord-
ing to speciﬁed kinetic script (e.g., dancing, running, etc.) and users’ physical conditions, hierarchical network is
extracted from human musculoskeletal network, which is fabricated by multiple body components (e.g., muscle,
bone, and joints, etc.) that are bio-mechanically, functionally, or nervously correlated with each other and exhibit
mostly non-divergent kinetic behaviors.

For the purposes of the neural network, the motion similarity between these correlations are assessed to improve
performance. Multi-layer perceptron (MLP) regressor models, as well as several variations of autoencoder models
are investigated for the sequential compensation of missing or dysfunctional limbs. The resulting kinematic behavior
of phantom limbs will be constructed using virtual reality and augmented reality (VR/AR), actuator, and potentially
controller for prosthesis (an artiﬁcial device that replaces a missing body part).

The addressed work aims to develop practical innovative exercise methods that (1) engage individuals at all ages,
including those with chronic health condition(s) and/or disability, in regular physical activities, (2) accelerate the
rehabilitation of patients, and (3) release the phantom limb pain. The physiological and psychological impact of the
addressed work will critically assessed in future work.

The remainder of this paper is organized as follows. Section 2 overviews the implementation of the generation
system. Section 3 explains the data acquisition, transmission, and visualization of data. Section 4 investigates the
human musculoskeletal network and some of its correlations to the intuitions used for the proposed neural network.
Section 5 explains the data preprocessing methods for the autoencoder. Section 6 explains and reports the neural

2

network architecture. Section 7 reports the the results of using our proposed network. Lastly, Sections 8 and 9
concludes the paper and deﬁnes future work.

2. Implementation of System

The proposed work employs deep learning techniques such as autoencoder to generate phantom limbs according to
the observed kinetic behaviors of other body parts based on the following hypothesis: (1) The human body consists of
multiple components such as muscle, bones, and joints, which are correlated with each other mechanically, nervously,
or functionally. (2) Because deep learning techniques such as autoencoder can be used to formulate the pattern of
speciﬁc kinetic behavior script such as dancing and sports.

Figure 3: The ﬂowchart of the proposed adaptive phantom limb generation based on multi-correlation hierarchical autoencoder

Figure 3 shows the implementation of the proposed work, which consists of the following critical tasks:

• Formulating human musculoskeletal network (illustrated in Figure 2(a)) [9] according the functional, mechani-

cal and nervous correlation between each body components (muscle, joint, or bone).

• Deriving hierarchical network (illustrated in Figure 2(b), in the conﬁguration of forest data structure) from the
human musculoskeletal network according to the physical status of users, where the phantom limbs will form
the leaves of hierarchical tree.

• Building visible autoencoder neural network (illustrated in Figure 2(c)) according to the hierarchical network
so that the kinetic behavior can be constructed according to the kinetic behavior of user’s functional body parts
measured by heterogeneous sensors.

• Preprocess the kinetic sensory data using noise removing, data normalization, incomplete data compensation
such as Kalman ﬁlter and Spherical linear interpolation (SLERP)[4], and kinetic signal decomposition such as
singular value decomposition (SVD), and wavelet analysis, etc.

• Training the addressed visible autoencoder neural network according to speciﬁc human motions script such as

walking, jogging, dancing, or any other physical activities.

• Representing kinematic behavior about phantom limbs using VR/AR, and actuators, which can directly stimu-

late users.

3. Developing Data Acquisition and Transmission Schemes

Proper data acquisition schemes will be developed to collect 4D kinetic data with suitable format from various
hardware instruments such as a Microsoft Kinect V2, foot-pressure sensors, actuators, and VR goggles. Realtime ap-
plication of two-way communications and edge computing are considered to facilitate the human computer interaction
in the PLG-HAE sytem.

3.1. Acquisition of 4D Sensory Data

3

Figure 4 show the basic input and output equipment of
phantom-limb generation. A Microsoft Kinect V@ sensor,
foot pressure sensor, and electronic glove (studded with
force-sensitive resistors and vibration motors that can es-
sentially re-create the experience of kinetic movement) can
be used to acquire kinetic data (or 4D sensory data) of
a user. A virtual reality goggle, such as the Oculus Rift,
HTC Vive, or Google Cardboard, motor to drive prosthetic
limb, and a tactile actuator are used as output equipment
that work together to depict 4D feedback to the user.

Figure 4: Input&output instruments

Acquisition and Polishment of Kinematic Data. The Mi-
crosoft Kinect collects the kinematic data of the coach
(or physical therapist, for training purposes) and the user.
Through Kinect, we can obtain joints’ transient position
k
(cid:104)x, y, z(cid:105)k
t , where θ is an angle around unit axis (cid:126)v, t
is the time, and k is joint’s identiﬁer. Quaternions [10] are considered to represent the rotation of a rigid body in 3D
space using four degree-of-freedoms (DOFs).

t and corresponding Quaternion rotation [10] (cid:104)cos( θ

2 ), sin( θ

2 )(cid:126)v(cid:105)

Quaternions are superior to many other traditional rotation formulation methods because they completely avoid
gimbal-lock [11]. In the addressed phantom-limb generation system, Quaternions will be used in 4D reconstruction
over Unity3D platform and acquisition of kinetic signal. On the other hand, as a Quaternion is speciﬁed with reference
to an arbitrary axis vector it is not a good choice in rotation recognition. In this work, Euler angles (cid:104)α, β, γ(cid:105), which
represent the angles rotating around axis Z, X, Y respectively (in some literature it is denoted as (cid:104)yaw, pitch, roll(cid:105))
will be adopted in gesture recognition.

The addressed phantom-limb generation system stores the captured kinetic data in JavaScript Object Notation
k
(JSON) format, which includes joint position ((cid:104)x, y, z(cid:105)k
t ), tracking status (0:
invisible; 1: referred; 2: observable). Potentially, force load (f k
t ) and momentum, etc. may be included. Tracking
status indicates whether or not the speciﬁc joint is observable by the depth sensor. The force load and momentum are
derived by inverse dynamics analysis. Besides JSON, a kinetic dataset in Comma-Separated Values (CSV) format is
also provided in PLG-HAE as many data analytics systems do not accept JSON format.

t ), quaternion rotation ((cid:104)cos( θ

2 ), sin( θ

2 )(cid:126)v(cid:105)

Due to measurement error or unavoidable occlusion, a joint is not always observable or tractable by the kinetic
sensor. Spherical linear interpolation (commonly abbreviated as SLERP) [12] and Kalman ﬁltering techniques (be
discussed in Section 5) will be employed to compensate the missing data. As illustrated in our preliminary online
video [13], SLERP can effectively address those short-term missed-tracking joints (namely tracking status=0 or 1).

Acquisition of Tactile Data. Besides the Kinect, other acquisition instruments such as an accelerometer, orientation
sensors, and strain gauges [14] will also be considered for the addressed system. As indicated above, a foot pressure
sensor will be used to obtain the ground reaction force Ft for inverse dynamic analysis. Furthermore, electromyo-
graphy (EMG) [14] will be selectively employed to evaluate and record the electrical activity produced by skeletal
muscles. The EMG signal is characterized by a frequency range of several hertz to over 1 kHz and by amplitudes
ranging from fractions of a microvolt to a few thousand microvolts. Electromyogram can be analyzed to detect activa-
tion level or to analyze the biomechanics of users’ movement. For the acquisition of high-quality EMG signals from
localized muscle region, the PIs will focus on identiﬁcation of localized muscle region of users, noise reduction and
grounding practices (to eliminate extraneous electrical noise), electrode site preparation and placement (to minimize
the detection of irrelevant bioelectrical signals) and appropriate differential signal preampliﬁcation and preliminary
signal conditioning (to further enhance signal-to-noise ratio).

Reconstruction of 4D data. 4D kinetic feedback/instruction is reconstructed through virtual reality and tactile actu-
ators. For example, HTC Vive can be used as the VR device, as it is readily supported and available to consumers
and does not exhibit poor VR qualities, such as low refresh rate, that may induce nausea to the user. Unity3D may
be used as the SDK for generating a virtual environment using AR and VR. To visualize the human body through
a virtual reality facility, the output kinematic data is translated into Quaternion format [10, 11], which is recognized

4

by Unity3D. The conversion of joint input data to Quaternions allows for the manipulation of a 3D human model,
through the manipulation of a model’s child objects or joints. The manipulation of a model allows for a better visual
representation of a body in both recorded and real-time Kinect data.

Equipped with somatosensory stimuli, the phantom limb generator also directly guides users with somatosensory
feedback. Tactile actuators potentially used in this work include Eccentric Rotating Mass (ERM), Linear Resonant
Actuator (LRA), Piezo, and Electro-Active polymers (EAP). EAP will be investigated in the development of phantom-
limb generation because of its high ﬁdelity of sensations, and excellent durability.

We will apply deep learning techniques to electric pros-
thesis with the goal of developing an agent that could learn
and adapt to the needs of the user and changes in the en-
vironment [16]. Deep learning provides a nice set of tools
that allow us to incorporate numerous sensory streams (the
kinetic behavior of other body parts, vision, tactile sensation,
inertial measurements, servo position, etc.) in ways that are
computationally tractable and suitable for online learning. In
this work, autoencoder neural network enables the phantom
limbs coordinate with other body parts according to their cor-
relation, some latency is observed. In the future work, more
”intelligent” deep learning techniques such as reinforcement
learning will be investigated to improve the performance of
prosthetic limb (with much less latency).

3.2. Task: Developing Communication and Edge-Computing
Protocols

Figure 5: Edge-computing-enabled phantom-limb generation
deployed on commodity hardware (demo in online video [15])

Real-time, Two-Way Communication.. Two-way communications are of key importance in the proposed system, since
the information needs to be exchanged in a real-time manner. The challenges of the communication protocol for the
proposed system include: (1) Real-time communication: Information in the addressed system needs to be conveyed
in real time. If there is a signiﬁcant delay in the communications, synchronization between the virtual coach and
user will be lost and the user will experience a disjointed rhythm. (2) High throughput: When there are many users,
all corresponding video and audio need to be conveyed in the network, thus incurring a substantial requirements
for communication bandwidth. (3) Two-way communications: The communications are between the virtual coach
and users with mutual interactions. Therefore, it could be sub-optimal if one-way communications are considered
separately. (4) Dynamics awareness: The communications may be optimized together with the physical dynamics of
the virtual coach and users (namely the motions).

To address the above challenges, we will ﬁrst model phantom-limb generation as a cyber physical system (CPS)
[17, 18] and then analyze the bandwidth needed for controlling the physical dynamics. Then, the detailed communi-
cation protocol will be designed and evaluated with the whole system.

Deployment of Phantom-limb Generation Using Affordable Hardware Based on Edge Computing.. Edge computing
enables real-time knowledge generation and application to occur at the source of the data close to user device [19, 20],
which makes it particularly suitable for the proposed latency-sensitive system. An edge server can be adapted to serve
multiple users through interaction with their devices. There are communication and computing trade-offs between
the edge server and each user device. Data could either be locally processed at the user device or else be transmitted
to and processed at the edge server. Different strategies introduce different communication costs, resulting in a
difference in delay performance. To provide the best quality of experience for users, the PIs will conduct the following
studies for the proposed PLG-HAE system: (1) Identiﬁcation and modularization of computing tasks: the computing
tasks of data preprocessing, kinetic movement recognition, the analysis of individualized movement choreography
(2) Design, prototyping
and the corresponding computing overheads (CPU cycles, memory) will be determined.
and enhancement of ofﬂoading schemes: Based on the results of bandwidth and delay analysis as well as delay
performance requirement, computation ofﬂoading schemes will be developed to determine which computing tasks
should be performed locally at the user device and which computation tasks should be ofﬂoaded to the edge server.

5

As illustrated in Figure 5 (b), enabled by edge-computing technology, the proposed phantom limb generation
system can be deployed over commodity hardware so that it can beneﬁt a broader population. An illustrative concept
demonstration about edge-computing-enabled phantom limb generator is given in our online video [15].

4. Deriving Hierarchical Neural Network from Human Musculoskeletal Network

4.1. Structure, function, and control of the human musculoskeletal network

As illustrated in Figure 6, the human body is a complex organism, the
gross mechanical properties of which are enabled by an interconnected mus-
culoskeletal network [9] controlled by the nervous system. The nature of
musculoskeletal interconnection facilitates stability, voluntary movement,
and robustness to injury. However, a fundamental understanding of this
network and its control by neural systems has remained elusive. Here we
address this gap in knowledge by utilizing medical databases and mathemat-
ical modeling to reveal the organizational structure, predicted function, and
neural control of the musculoskeletal system. We constructed a highly sim-
pliﬁed whole-body musculoskeletal network in which single muscles con-
nect to multiple bones via both origin and insertion points. We demonstrated
that, using this simpliﬁed model, a muscle’s role in this network could of-
fer a theoretical prediction of the susceptibility of surrounding components
to secondary injury. Finally, we illustrated that sets of muscles cluster into
network communities that mimic the organization of control modules in pri-
mary motor cortex. This novel formalism for describing interactions be-
tween the muscular and skeletal systems serves as a foundation to develop

Figure 6: Human musculoskeletal network.

and test therapeutic responses to injury, inspiring future advances in clinical treatments.

4.2. Derivation of hierarchy out of musculoskeletal network

Human-body consists of multiple body-components, which are correlated functionally, bio-mechanically, or ner-
vously. From the correlation graph, we can derive a hierarchical sub-graph that can be formulate by neural network
in a relatively straightforward way. In this work, hierarchical clustering algorithm [21] is employed to formulate the
hierarchical network for phantom limbs out of human muscoloskeletal network.

4.3. Visible and hierarchical neural network architecture for real-time phantom limb generation.

It is known that any system can be
regarded as a hierarchical structure (i.e.,
system → subsystem → subsubsystem,
. . . ). As illustrated in Figure 7(a), the hu-
man body system can be always divided
into sub-components that are mechani-
cally correlated and whose motions are
non-divergent. Inspired by the Bayesian
network, we propose a visible and hierar-
chical neural network to accurately for-
mulate a system. As illustrated in Fig-
ure 7(b), a sample visible and hierarchi-
cal neural network, which is directly de-
rived from the human body system, is
employed to specify the musculoskeletal
kinematic. The visible and hierarchical
neural network can be employed in phantom limb generation, 4D kinetic behavior recognition, and individualized
Tai-Chi choreography (to be discussed in the remaining sections). Preliminary experimental results demonstrate that
is superior to a classical neural network from the point of view of training speed and stability.

Figure 7: Visible and hierarchical neural network

6

4.4. Related Work

Much of work done in human motion generation focuses on choosing a model expressing the inter-dependence
between joints. Recently, human motion was generated through the use of auto-regressive functions, such as models
relying on Gated Recurrent Networks (GRU) or Long-Short Term Memory (LSTM) [1]. However, these models are
not feasible for use in our applications. Unlike long-term or short-term prediction, models focusing on real-time
generation must be small and computationally simple to achieve a 24 predictions-per-second minimum. Other work
has focused on minimizing loss by using techniques such as highway units, custom loss functions, or deﬁning loss
parameters. Generative-Adversarial Networks (GAN) [1] have also been experimented. However, these models tend
to be complex and convergence of the neural network is not intuitive. Thus, determining ground truth error for these
models is nuanced during training. Due to the inability to use these neural networks, methods including real-time
autoencoders are examined in this paper.

Figure 8: Flowchart of the Preprocessing for the generation of phantom limb generation

5. Developing Data Preprocessing Methods of Autoencoder-enabled Phantom Limb Generation

Data preprocessing operations play an indispensable role in phantom limb generation because: (1) Input data
is of a heterogeneous nature. For example, different users have variable sizes; sensors may have various viewing
angles; users will not always be located in a deterministic position; and the two time-series data sets may not be
synchronized. As a result, scaling, rotating, translating, and dynamic time warping (DTW) are needed to normalize the
original input data. (2) The input data set may be incomplete. For example, occlusion inevitably leads to missing data;
Musculoskeletal force and momentum exerted over the joints or muscle cannot be directly obtained from the sensors;
some input channels are not enabled (e.g., partial control) for users with mobility-based chronic conditions (i.e., partial
control). In the implementation of autoencoder-enabled phantom limb generation, Kalman ﬁltering, inverse dynamics,
and time-series prediction are employed to handle the incomplete data [22, 23]. (3) The measurement-induced noise
is signiﬁcant.

Figure 8 shows the ﬂowchart of data preprocessing of autoencoder-enabled phantom limb generation [24, 25,
26, 27]. (cid:104)θ, (cid:126)v(cid:105) (denoted as (cid:104)cos θ
2(cid:126)v(cid:105) in Section 3, where θ is the rotation angle about axis (cid:126)v ) indicates a
joint’s Quaternion rotation; (cid:104)x, y, z(cid:105) denotes a joint’s position; ft indicates a joint’s applied force, which is derived
from inverse dynamics; (cid:104)α, β, γ(cid:105) indicates a joint’s rotation under normalized Joint Coordinate System (JCS) – Euler
angle.
Its main implementation techniques include data fusion, inverse dynamics analysis, spatial normalization,
Kalman ﬁltering, and reconstruction of disable input channels. The kinetic data is stored in JSON format.

2 , sin θ

5.1. Formulating Musculoskeletal Kinetic Features

Inverse dynamics analysis (IDA), which is derived from Newton-Euler equations [28, 29, 30]), aims to calcu-
late unknown kinetic information (the force and moments of joints and muscles) from measured kinematic informa-
tion (e.g., position, velocities and accelerations of joints) and measured kinetic information (e.g., ground reaction

7

force measured by foot pressure sensor). As illustrated in Figure 8, given joints’ location (cid:104)xi, yi, zi(cid:105), Euler rota-
tion (cid:104)αi, βi, γi(cid:105) where i denotes the identity of a joint, and ground-reaction force F , the joints’ force fi and other
musculoskeletal kinetic features can be computed via IDA.

As illustrated in Figure 8, autoencoder-enabled phantom limb generation employs inverse dynamics to compute
internal joint forces and moments with given ground reaction forces. In this work, the human body is divided into
multiple connected rigid bodies [31, 32] which correspond to relevant anatomical segments such as the thigh, calf,
foot, arm, etc. The model’s anthropometric dimension (e.g., the mass and momentum inertia) is derived from statistical
analysis. In addition, it is assumed that each joint is rotationally frictionless.

The proposed methods in Figure 8 can be customized to investigate the bio-mechanical response of human motion
by considering appropriate pathology for different health issues such as cerebral palsy, poliomyelitis, spinal cord
injury, and muscular dystrophy [30]. This will make the addressed work a more constructive rehabilitation system.

5.2. Spatial Normalization

As addressed in Section 3, we can acquire the joints’ position and rotation, which are denoted as (cid:104)x, y, z(cid:105) and

(cid:104)θ, (cid:126)v(cid:105) respectively. Both need to be normalized to ease and boost the gesture recognition:

Normalization of Joints’ Rotation. Spatial rotations in three dimensions can be parametrized using either Euler angles
and unit quaternions. Instead of being denoted as a rotation around an arbitrary vector such as a unit Quaternion, an
Euler angle describes the orientation of a rigid body with respect to a ﬁxed coordinate system. Therefore, in kinetic
gesture recognition, Euler angle is more constructive than Quaternion in data analytics. In the proposed research,
joints’ rotations can be normalized by converting the quaternion (cid:104)θ, (cid:126)v(cid:105) into Euler angle (cid:104)α, β, γ(cid:105).

Normalization of Joint’s Position. Joints’ position (cid:104)x, y, z(cid:105) involves many factors irrelevant to gesture recognition.
These include: a user’s orientation to the camera, location in the room, and body shape and size. To eliminate such
irrelevant factors, This work employs a series of spatial normalization techniques: (1) bone scaling, which makes
uniform the bone length of users [22]; (2) axis-oriented rotating of view angle; (3) translation of the origin, which
makes a user positioned at the center of a sensor; (4) re-constructing (cid:104)x, y, z(cid:105) according to joint rotation [11] ; and
(5) polishing the kinetic curve using a Savitzky-Golay ﬁlter. Our preliminary experimental results demonstrate that
the normalization techniques addressed above can greatly improve the quality of data (less noise and smoother kinetic
performance) so as to achieve higher recognition [22, 25, 24].

5.3. Recovering Occlusion-induced Missing Data

During sensory data acquisition, unavoidable occlusion may introduce missing data or lost-tracking. As addressed
in Section 3, SLERP can basically ﬁx the issues caused by short-term occlusion. Kalman ﬁlter [33, 34, 35] can be
employed to ﬁx the missing information (including both position and rotation) caused by long-term occlusion. A
preliminary comparison between the raw and preprocessed physical rehabilitation kinematic data is available on our
online video [26, 27].

5.4. Application of Singular Value Decomposition on Kinetic Data

Singular value decomposition (SVD) is employed to decompose the human kinetics into multiple of modes, which
will be fed into the autoendoer in different channels. SVD can reduce the nonlinearity degree of kinetic signal so that
it can be formulated by neural network more precisely.

6. Neural Network Architecture and Generation of Phantom Limbs

6.1. Previous Work

Deep neural networks (DNN) have proven to be signiﬁcant in feature learning through their ability to learn rep-
resentations in a hierarchical manner [36]. Speciﬁc to the applications focusing on the generation of human motion
data, DNN models based on recurrent neural networks (RNN), such as ones that employ Long-Short Term Mem-
ory (LSTM) and Gated Recurrent Units (GRU) currently represent the majority of the techniques proposed. These

8

proposed models, such as ones that focus on temporal encoding, were more focused on learning general, generic rep-
resentations from a large pool of general, non-speciﬁc human motion data. Thus, previous models were more focused
on the generation of new, novel motions.

In contrast, our work is focused on assessing current body language that results in the representation of missing
joints given a deterministic motion. In addition, unlike previous models that rely on large datasets, we must be able
to train on very small datasets (such as ones with less that 25 samples per motion). Many architectural modiﬁcations
are proposed to attain proper performance given these constraints.

For the recreation of missing data through phantom limbs, two traditional methods for machine learning were
assessed – multilayer perceptron (MLP) and denoising autoencoders (DAE). In addition, this we proposed a new
autoencoder architecture for the recreation of phantom joints, a multi-correlated hierchical autoencoder.

6.2. Generating phantom legs based on arm movement using visible and hierarchical autoencoder network.

As our preliminary contribution, a neural network is trained to generate the kinetic status of hip, knees, and feet
according to the kinetic status of shoulders, elbows, and arms captured by 4D sensors [5]. As illustrated in ﬁgures
9, 10, 11, and 12, four network architectures are investigated in this research: (a) multiple layer perceptron (MLP);
(b) denoising autoencoder (a classical autoencoder architecture); (c) visible and hierarchical neural network with two
subsystems (VHNN2); and (c) VHNN with four subsystems (VHNN4).

It can be observed that VHNN splits the input tensor and then feeds the split tensor into multiple smaller, paral-
lelized autoencoders. Thus, data for each joint can be calculated in parallel with their own respective autoencoder.
The aforementioned parallelized autoencoder pipelines are simpliﬁed stacked autoencoders, allowing for optimization
of speciﬁc, key tasks rather than one large task.

A video playlist of the generation of phantom legs based on VHNN may be found at [37].

6.3. Multilayer perceptron models

Multilayer perceptrons (MLP) were assessed as a preliminary, prototype network for the inference and generation
of phantom joints. Despite their simplicity, MLP models are able to learn non-linearly separable data, and can learn
features through stochastic approximation. Thus, they are the simplest deep model available, and was used as a
minimum benchmark to the other models we have thus developed. Rather than feeding input into a logistic regression,
MLP networks work by adding layers that process the input using activation functions.

Figure 9: Generation of phantom legs from moving arms using a multilayer perceptron architecture [37])

As seen in Figure 9, our implementation of a MLP Regressor model was built with 7 hidden layers, with each
layer possessing 18 nodes. The MLP model is also ﬁtted with a regularizer term to prevent over-ﬁtting of our motion
data. However, the complexity of our data proved too difﬁcult for the model to learn, and thus our implementation of
an MLP regression model achieved poor accuracy [38] as the model struggles to generate proper regression values.
The increase and/or change of hyperparameter values, such as layer number or nodes per layer, do not signiﬁcantly
beneﬁt accuracy of the results, but do increase the training time.

6.4. Denoising Autoencoder

In generative data applications, autoencoders have had an important inﬂuence for their low computation cost–
relative to RNNs–and their high accuracy. For the generation of phantom limbs, autoencoders (AE) were critically
assessed in their performance for generating human-like motion data whilst being quick in their predictions/generation
of data. Quickness and speed of prediction is important to the generation of phantom limbs as the predictions must
be done in realtime, i.e. generated over 24 times per second. Whilst the generation of temporal/sequence data are
most normally done through recurrent neural networks, convolutional neural networks such as autoencoders have
found success in generative tasks [39]. During initial testing, autoencoders exhibited data bias within the generated
movement, causing difﬁculties in the neural network converging [37].

9

For phantom limb generation, autoencoders are quite applicable as the generation of data does not necessarily
have to be over a large time window. Instead, accuracy during short-time windows and quick reaction speed relative
to the realtime input were more important. In addition, convolutional neural networks are less susceptible to noisy or
substandard data and can better generalize data compared to the more complex recurrent units.

Figure 10: Generation of phantom legs from moving arms using a classical denoising autoencoder architecture [37])

As seen in 11, we moved our attention away from MLP and employed a standard denoising autoencoder to learn
the correlations of one’s body language to a speciﬁc set of phantom limbs. Due to the noisy nature of data captured
by our Microsoft Kinect V2, the performance of autoencoders for denoising as well as generative representation was
assessed. Through the use of a stacked denoising autoencoder, accuracy when viewed in comparison to multi-layer
perceptron models were signiﬁcantly higher in terms of the motion data generated and exhibited less noise within
the movement [38][37]. In contrast to data generated by MLP models, autoencoders achieved motion data that was
believably human-like.

6.4.1. Autoencoder Data Bias

Despite the improvement of generation of human-like data using autoencoders, the generated motions were not
perfect for all phantom limbs. Using our implementation of a denoising autoencoder, the minimization of loss pre-
sented bias towards data points that were closer to the starting joints. Our autoencoder’s input and output tensors
exhibit a dimensionality of (n, 18, 3), representing sample number, joint index, and x, y, z-coordinates respectively.
The generation of motion data found within the ﬁrst few joints, such as the ﬁrst six indices out of 18, exhibited much
better human motion data in comparison to data found in the last twelve data points. Thus, motion generation data
generated for a speciﬁc leg (such as the left leg) was signiﬁcantly more believable than data generated for the com-
plement leg (such as the right leg). The exhibition of the bias in optimization is most apparent during the realtime
generation/prediction of data [37].

The exhibition of data bias may due to the hierchical nature of the human body, e.g. the musculoskeletal network.
Due to the divergent motion relation of different body segments, optimization of the may be compromised when other
joints exhibit opposite or very divergent motion. Thus, the correlations between one’s body language may be intuitive
for joint segment (i.e. one’s left leg), but entirely opposite or non-intuitive for another joint segment (i.e. one’s right
leg).

6.5. Application of Hierarchical Autoencoder

The prior applications of hierchical autoencoders can be found in classiﬁcation tasks and natural language process-
ing (NLP) [40]. In retrospect, these neural networks have been employed to decrease complexity within ambiguous
classiﬁcations [41] or used as a means to assess long sequences of data using CNNs [39]. The beneﬁts of using hierar-
chical CNNs for sequential data are two-fold: (1) They are much quicker to train and predict and (2) They can attain
higher accuracy than RNNs in certain applications.

We turned to the parallelization of convolution pipelines for the generation of phantom limbs in response to the
optimization problems by our stacked denoising autoencoder showed. Thus, the attainment of certain goals was
needed for the new, parallelized autoencoder models: (1) the autoencoder must not too complex that the generation of
data would not be realtime, (2) the autoencoder must not exhibit signs of optimization bias, and (3) the autoencoder
must be able to allow for multi-correlation of outputs.

Figure 11 shows the autoencoder architecture used to resolve this inherent data bias. As seen, the proposed
network has its splits each input tensor according to the joint joint segments that the data is correspondent to for
both input and output, in comparison to ﬁgure 10. This resolves biased optimization by allowing each autoencoder to
optimize for a smaller input data dimensionality, and for motion that is mostly non-divergent. Because of the reduced
dimensionality of input data, the MaxPooling as well as Upsampling of data does not need to encode and decode as
large of data in comparison to a deeper, larger stacked autoencoder. Thus, despite the seemingly double amount of
layers, the amount of layers per smaller autoencoder is reduced, and parameters per parallelized autoencoders are also

10

Figure 11: Generation of phantom legs from moving arms using a two thread (subsystem) visible and hierarchical autoencoder neural network
(VHNN-AE-2) architecture [37])

reduced. This results in training and prediction performance comparable to a standard denoising autoencoder, but
with much higher ground-truth accuracy.

Figure 12: Generation of phantom legs from moving arms using a four thread (subsystem) visible and hierarchical autoencoder neural network
(VHNN-AE-2) architecture [37])

Whilst the splitting of inputs into two parallel autoencoders performed much better than a standard stacked autoen-
coder, the parallelization of autoencoders has caused a separate problem, in which correlations can only be found in
two distinct joint pairs, i.e. one’s left arm motion can inﬂuence the left leg but not the right leg. Thus, multi-correlation
was needed in order to help give better representation of each input to the generated output. As seen in Figure 12,
this resulted in further splitting of the autoencoders, essentially doubling the amount of pipelines within this phantom
limb application. This was done to give correlations to both input joints segments to both output joint segements.

Partial control is an important feature of the generation of phantom limbs as it enables those users with disability
to operate freely. Partial control is implemented by compensating the missing data inferred by disabled input channels:
in the event that several input channels are disabled, the addressed model is able to construct the void input channels by
taking the advantage of correlation among all inputs. Compensation can normalize the input data so that VIGOR can
achieve higher recognition rate, its psychological and physiological beneﬁts to users are also under our investigation.

7. Results

As illustrated in Table 2, the proposed VHNN architecture has proven to have overall superior results compared
to previous work. Decreased training time compared to previous autoencoders architectures can be observed due to
the parallelization of simpler autoencoders, increasing efﬁciency by easing optimization. This is done by allowing
autoencoders to train on speciﬁc gestures in a whole movement. In addition, it does not exhibit data-hungry tendencies
that state-of-the-art models exhibit, allowing it to be trained on small amounts of data.

Lower ground truth error can be seen in the VPNN-AE-2 versus VPNN-AE-4. This is due to training data having
no anomalies of data that real-time can exhibit. While VHNN-AE-2 with single-correlation works better when testing
against ground truth data, VPNN-AE-4 with double-correlation works better in real-time as the patient may not follow
the Tai-Chi movements correctly. This causes worse ground truth error as the added complexity of the architecture
increases noise during output, but enables better patient-error tolerance. Because of this additional noise produced of
VHNN-AE-4, improvements such as larger training datasets, more sophisticated pre- and post-processing of data, as
well as improvements in NN architecture will be investigated.

11

Table 1: Architectures of Autoencoders Assessed and Proposed

Classical

VHNN-2

VHNN-4

Type
conv1D

MaxPooling
conv1D

MaxPooling
conv1D

Upsampling
conv1D

Upsampling
conv1D

Hyperparameters
Filter: 32
Kernel Size: 3
Activation: Linear
Padding: same

Pool size: 3
Filter: 32
Kernel Size: 3
Activation: Linear
Padding: same
Pool size: 2
Filter: 32
Kernel Size: 3
Activation: Linear
Padding: same

Size: 2
Filter: 32
Kernel Size: 3
Activation: Linear
Padding: same
Size: 3
Filter: 1
Kernel Size: 3
Activation: Linear
Padding: same

Type
conv1D

Dropout
MaxPooling

Hyperparameters
Filter: 32
Kernel Size: 3
Activation: Linear
Padding: same
Rate: 0.5
Pool size: 3

Type
conv1D

Dropout
MaxPooling

Hyperparameters
Filter: 32
Kernel Size: 3
Activation: Linear
Padding: same
Rate: 0.5
Pool size: 3

conv1D

conv1D

Filter: 32
Kernel Size: 3
Activation: Linear
Padding: same

Upsampling

Size: 3

Dropout
Upsampling

Filter: 32
Kernel Size: 3
Activation: Linear
Padding: same
Rate: 0.2
Size: 3

conv1D

conv1D

Filter: 1
Kernel Size: 3
Activation: Linear
Padding: same

Filter: 1
Kernel Size: 3
Activation: Linear
Padding: same

Concatenate Axis: 1

Concatenate Axis: 1
Concatenate Axis: 1

Table 2: Time-performance of phantom-legs generation using visible and hierarchical autoencoder neural network (VHNN) (Intel Core i9-7900X,
1x NVIDIA GTX1080 Ti, 64GB RAM; MLP does not employ GPU)

NN architecture

MLP
Denoising Autoencoder
VHNN-Autoencoder-2
VHNN-Autoencoder-4

Training time Training time
for 1K epochs
per step
NA
NA
108 − 110µs
9m 15s
30 − 31µs
2m 44s
52 − 57µs
4m 37s

convergence
in epoch
250
1000
500
800

ground
truth error
9515.51
2107.46
276.68
366.15

online
video
[38]
[42]
[43]
[44]

12

The neural network addressed in our preliminary work is single-modality, which generates a single type of kine-
matic output, either joints’ location (cid:104)x, y, z(cid:105) or joints’ rotation in Euler angle (cid:104)α, β, γ(cid:105). There might be potential
issues for single-modality network. As illustrated in our preliminary work [4, 8], divergence is commonly observed
in an XYZ-oriented network; Euler-angle-oriented network suffer from 0 − 360degree issue [4]. A multi-modality
neural network will be studied for intelligent choreography generation.

Figure 13: Choreography using multi-modality network

As illustrated in Figure 13, multiple heterogeneous kinetic data will be generated simultaneously as the output of

neural network so that a cross-validation can be made.

8. Conclusion and Future Work

As seen from the reported results, the proposed multi-correlation visible hierarchical autoendoder such as VHNN-
4 exhibits much better realtime generated data in comparison to MLP or classical autoencoders. Thus, the segmen-
tation of joint data through human musculoskeletal network as well as non-divergent motion are used as effective
methods to improve neural network optimization and prediction quality. In addition, the proposed work is able to
generate phantom limbs with very scarce amounts of data, in contrast to previous models. Given the ﬂexible nature of
parallelized autoencoders, adding pipelines as well as the modiﬁcation of individual pipelines for other applications
may be easily executed.

In the future, Generative Adversarial Networks (GAN) may be assessed for the prediction of longer time-horizons
in comparison to the short time-horizons predicted by our proposed autoencoder. In addition, more pre-processing
and post-processing methods may be assessed, such as singular value decomposition (SVD), in order to further aid
accuracy and performance. For improvements in data acquisition, better depth sensors relative to the Microsoft Kinect
V2 may be assessed for less noisy, precise data.

Future work also includes evaluating performance and user experience. A variety of user experience data and
clinical beneﬁt data will be generated during system assessment. Analytical results about the extent to which the
addressed work demonstrates superior physical and psychological beneﬁts and user experience over those of existing
systems will also be derived

Acknowledgments

This work is jointly sponsored by the National Science Foundation (award No: 1240734), UTC THEC/CEACSE
2016 Grant Program, and 2015 UTC CRISP program. Special thanks also go to Mr. Mr. Samuel Clark for his
contributions in the paper.

13

References

References

[1] I. Goodfellow, Y. Bengio, A. Courville, Deep Learning, MIT Press, 2016.
[2] M. Ortiz-Catalan, R. A. Guomundsdottir, M. B. Kristoffersen, A. Zepeda-Echavarria, K. Caine-Winterberger, K. Kulbacka-Ortiz, C. Wide-
hammar, K. Eriksson, A. Stockselius, C. Ragn, Z. Pihlar, H. Burger, L. Hermansson, Phantom motor execution facilitated by machine learning
and augmented reality as treatment for phantom limb pain: a single group, clinical trial in patients with chronic intractable phantom limb
pain, The Lancet 388 (10062) (2016) 2885–2894. doi:10.1016/S0140-6736(16)31598-7.

[3] V. S. Ramachandran, W. Hirstein, The perception of phantom limbs. The D. O. Hebb lecture., Brain 121 (9) (1998) 1603–
arXiv:http://oup.prod.sis.lan/brain/article-pdf/121/9/1603/17864034/1211603.pdf, doi:10.

1630.
1093/brain/121.9.1603.
URL https://dx.doi.org/10.1093/brain/121.9.1603

[4] Y. Liang, D. Wu, D. Dakila, C. Davis, R. Slaughter, Z. B. Guo, Virtual tai-chi system, a smart connected modality for rehabilitation, Elsevier:

Smart Health 9–10 (2018) 232–249.

[5] D. Ledesma, Y. Liang, [online] vtcs: Construct phantom legs according to arms’ movement using varius autoencoder strategies, https:

//youtu.be/ZmTobUjRX64, cite November 08, 2018.

[6] Y. Bengio, Learning deep architectures for ai, fundamental Trends Machine Learning 2 (1) (2009) 1–127.
[7] A. Sperduti, A. Starita, Supervised neural networks for the classiﬁcation of structures, IEEE Transactions on Neural Networks 8 (3) (1995)

714–735. doi:10.1109/72.572108.

[8] Y. Liang, D. Wu, D. Dakila, C. Davis, R. Slaughter, Z. B. Guo, Virtual taiji system, a smart-connected modality for rehabilitation, in: The

Third IEEE/ACM Conference on Connected Health: Applications, Systems, and System Technologies, Washington, D.C., 2018.

[9] A. C. Murphy, S. F. Muldoon, D. Baker, A. Lastowka, B. Bennett, M. Yang, D. S. Bassett, Structure, function, and control of the human

musculoskeletal network. plos biology 16 (1). doi:10.1371/journal.pbio.2002811.

[10] R. W. Farebrother, J. Grob, S.-O. Troschke, Matrix representation of quaternions, Linear Algebra and its Applications 362 (2003) 251–255.

doi:doi:10.1016/s0024-3795(02)00535-9.

[11] G. ES, S. WJ, A joint coordinate system for the clinical description of three-dimensional motions: application to the knee, J Biomech Eng.

105 (2) (1983) 136–44.

[12] K. Shoemake, Animating rotation with quaternion curve, SIGGRAPH ’85 proceedings, Computer Graphics 19 (3) (1985) 245–255.
[13] Y. Liang, D. Ledesma, D. Wu, [online] vtcs: virtuality coaching based on unity 3d, https://www.youtube.com/watch?v=

OQySt2i8dzo&feature=youtu.be, cited May 8, 2018.

[14] M. Tiwana, S. Redmond, N. Lovell, A review of tactile sensing technologies with applications in biomedical engineering, Sensors and

Actuators A: Physical 179 (2012) 17–31. doi:10.1016/j.sna.2012.02.051.

[15] D. Ledesma, W. Baker, Y. Liang, [online] vtcs: Deployment of vtcs over commodity hardware, https://youtu.be/_bB8K627JZk,

cite July 04, 2018.

[16] G. Vasan, P. M. Pilarski, Learning from demonstration: Teaching a myoelectric prosthesis with an intact limb via reinforcement learning, in:

2017 International Conference on Rehabilitation Robotics (ICORR), 2017, pp. 1457–1464. doi:10.1109/ICORR.2017.8009453.

[17] E. Lee, Cyber physical systems: Design challenges, in: Proc. of IEEE International Symposium on Object Oriented Real-time Distributed

Computing (ISORC), 2008.

[18] L. Sha, S. Gopalakrishnan, X. Liu, Q. Wang, Cyber-physical systems: A new frontier, in: Proc. of IEEE International Conference on Sensor

Networks, Ubiquitous and Trustworthy Computing, 2008.

[19] Y. Hu, M. Patel, D. Sabella, N. Sprecher, V. Young, Mobile edge computing a key technology towards 5g, European Telecommunications

Standards Institute (ETSI) White Paper.

[20] O. Mkinen, Streaming at the edge: Local service concepts utilizing mobile edge computing, in: The 9th International Conference on Next

Generation Mobile Applications, Services and Technologies, 2015.

[21] P. Langfelder, S. Horvath, Wgcna: an r package for weighted correlation network analysis, BMC Bioinformatics 9 (2008) 1471–2105.

doi:10.1186/1471-2105-9-559.

[22] N. Alharbi, Y. Liang, D. Wu, Extended-kalman-ﬁlter preprocessing technique for gesture recognition, in: 2nd IEEE/ACM CHASE, Philadel-

phia, USA, 2017.

[23] D. Ledesma, D. Ledesma, R. Slaughter, D. Wu, Z. Guo, Y. Liang, Kinetic gesture recognition and choreography, in: IEEE BigDataService

2018, Bamberg, Germany, 2018.

[24] Y. Liang, Z. B. Guo, D. L. Wu, N. Fell, A. Clark, Virtual taiji system - an innovative modality for rehabilitation, in: Annual BSEC Conference

at Oak Ridge National Laboratory Collaborative Biomedical Innovations, 2015.

[25] C. Davis, D. Ledesma, R. Slaughter, D. Wu, Z. Guo, Y. Liang, Kinetic data processing for gesture recognition, in: IEEE BigDataService

2018, Bamberg, Germany, 2018.

[26] Y. Liang, D. Ledesma, C. Davis, R. Slaughter, D. Wu, [online] vtcs: preprocessed and raw kinematic data (front view), https://www.

youtube.com/watch?v=KFBV_EBTEQw, cited March 2, 2018.

[27] Y. Liang, D. Ledesma, C. Davis, R. Slaughter, D. Wu, [online] vtcs: preprocessed and raw kinematic data (front and back view), https:

//youtu.be/Ee31SdhXxXc, cited March 2, 2018.

[28] J. Ambrosio, A. Kecskemethy, Multibody dynamics of biomechanical models for human motion via optimization, Multibody Dynamics:
Computational Method and Application, J.C. Garcia Orden et al. (Eds) 6 (2007) 245–272. doi:10.1007/978-1-4020-5684-0-12.

[29] E. Eich-Soellner, C. Fhrer, Numerical Methods in Multibody Dynamics, Teubner, Stuttgart, 2008.
[30] P. Moreira, U. Lugrs, J. Cuadrado, P. Flores, Biomechanical models for human gait analyses using inverse dynamics formulation, Sociedade

Portuguesa de Biomecnica, 2013.
URL http://hdl.handle.net/1822/23057

14

[31] Y. Liang, M. Szularz, L. T. Yang, Finite-element-wise domain decomposition iterative solvers based on polynomial preconditioning, Mathe-

matical and Computer Modeling 58 (1-2) (2013) 421–437. doi:10.1016/j.mcm.2012.11.017.

[32] J. Wittenburg, Dynamics of Multibody Systems, Berlin, Springer, 2008.
[33] R. Kalman, A new approach to linear ﬁltering and prediction problems, Journal of Basic Engineering 80 (1960) 35. doi:doi:10.1115/

1.3662552.

[34] G. Einicke, Smoothing, Filtering and Prediction: Estimating the Past, Present and Future, Rijeka, Croatia: Intech, 2012.
[35] P. Zarchan, H. Musoff, Fundamentals of Kalman Filtering: A Practical Approach, American Institute of Aeronautics and Astronautics,

Incorporated, 2000.

[36] J. Butepage, M. J. Black, D. Kragic, H. Kjellstrom, Deep representation learning for human motion prediction and classiﬁcation, in: Proceed-

ings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 6158–6166.

[37] D. Ledesma, Y. Liang, [online] playlist of phantom legs induced by moving arms, https://www.youtube.com/playlist?list=

PL8VO3nxhbh0IngDo5ij0PkKxK5uFbtXE0, cite December 08, 2018.

[38] D. Ledesma, Y. Liang, [online] vtcs: Construct phantom legs according to arms’ movement using 7-layer mlp, https://youtu.be/

BFW3JVI0dKM, cite December 08, 2018.

[39] X. Qiao, C. Peng, Z. Liu, Y. Hu, Word-character attention model for chinese text classiﬁcation, International Journal of Machine Learning

and Cybernetics (2019) 1–17.

[40] J. Li, M.-T. Luong, D. Jurafsky, A hierarchical neural autoencoder for paragraphs and documents, arXiv preprint arXiv:1506.01057.
[41] Y. Seo, K. Shin, Hierarchical convolutional neural networks for fashion image classiﬁcation, Expert Systems with Applications 116 (2019)

328–339.

[42] D. Ledesma, Y. Liang, [online] vtcs: Construct phantom legs according to arms’ movement using autoencoder, https://youtu.be/

1aHJQyST9k0, cite December 08, 2018.

[43] D. Ledesma, Y. Liang, [online] vtcs: Construct phantom legs according to arms’ movement using two-thead vhnn autoencoder, https:

//youtu.be/pVtzw0dJduA, cite December 08, 2018.

[44] D. Ledesma, Y. Liang, [online] vtcs: Construct phantom legs according to arms’ movement using four-thead vhnn autoencoder, https:

//youtu.be/dGPm4z7vibI, cite December 08, 2018.

15

