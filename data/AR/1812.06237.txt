Walking Through an Exploded Star: 
Rendering Supernova Remnant Cassiopeia A into Virtual Reality 

Arcand, K.K.1, Jiang, E.2, Price, S.1, Watzke, M.1, Sgouros, T.2, Edmonds, P.1 
(1Smithsonian Astrophysical Observatory/Chandra X-ray Observatory, 2 Brown University)    

ABSTRACT: 

NASA and other astrophysical data of the Cassiopeia A supernova remnant have been rendered into a 

three-dimensional virtual reality (VR) and augmented reality (AR) program, the first of its kind. This 

data-driven experience of a supernova remnant allows viewers to “walk” inside the leftovers from the 

explosion of a massive star, select the parts of the supernova remnant to engage with, and access 

descriptive texts on what the materials are. The basis of this program is a unique 3D model of the 340-

year old remains of a stellar explosion, made by combining data from NASA’s Chandra X-ray 

Observatory, Spitzer Space Telescope, and ground-based facilities. A collaboration between the 

Smithsonian Astrophysical Observatory and Brown University allowed the 3D astronomical data 

collected on Cassiopeia A to be featured in the VR/AR program - an innovation in digital technologies 

with public, education, and research-based impacts. 

Key Words:  data, virtual reality, science communication, visualization, augmented reality, narrative 

1. INTRODUCTION 

1.1. Overview of Virtual Reality (VR) 

Virtual Reality (VR) is computer technology that simulates a user's physical presence in a virtual 

environment. (VR’s close relative, Augmented Reality (AR), adds elements, such as text, overlays and 

audio, to enhance that experience with sensory input and is briefly discussed in section 1.3). VR has been 

around as an idea since the 1960’s, and a reality in some form since the 1980’s (Faisal, 2017). Though it 

has faced many starts and stops (Stein, 2015), e.g., the promise of VRML (Virtual Reality Markup 

Language) in the late 1990’s1, VR has become more commonplace in the consumer market since about 

2010 (Faisal, 2017). With the promise of improving the gaming industry, media, and even adult 

1 

 
 
 
 
entertainment, there are major commercial driving forces behind the technology’s development (Virtual 

Reality Payments 2016; Virtual Reality 101 2016).   

The increased commercial prominence of these technologies, including the availability of less 

expensive but still good quality and more user-friendly technologies, provides opportunity for science as 

well (Ferrand et al., 2016). In science, there is a potential for VR to revolutionize how experts visualize 

and analyze their data, and also how that data is then communicated to non-experts, from molecular 

modeling to environmental conservation (Isenberg, 2013).  

In medicine alone, VR offers a unique tool for data visualization and comprehension as well as 

continuing education and user experiences. Programs in progress range from improving health workers’ 

understanding of brain damage (Hung et al., 2014), to implementing virtual surgery training for medical 

students (Murphy, 2018), to applying VR and AR techniques in an accessible way to the treatment of 

Alzheimer’s disease (Garcia-Betances et al., 2015). Virtual reality has been shown to improve upon the 

traditional tangible model of using dummies to enhance medical students’ preparation for assisting 

patients in higher risk, real life scenarios. It might allow physicians and other health professionals to work 

with individually developed cases to practice applicable caregiving skills, such as looking at and speaking 

to new patients (Murphy, 2018).  

Beyond the universe of the body, and out to the Universe at large, astronomical data sets often 

offer high-resolution, multi-wavelength, multi-dimensional (lately, even multi-messenger) information.  

The process of converting photons, or packets of energy, into 2D images has been documented and 

studied (Rector et al., 2017; Arcand et al., 2013; DePasquale et al., 2015; Rector et al., 2007) but the 

translation of that information into 3D forms that takes advantage of human perspective, cognition and 

stereoscopic vision, less so (Ferrand et al., 2016). Since the Universe is multidimensional itself, as Fluke 

and Barnes (2016) ask: ‘Are we making the best use of the astronomer’s [and non-expert’s] personal 

visual processing system to discover knowledge?’ 

2 

 
A selection of astronomical VR experiences the authors have come into contact with range from 

exploring exoplanets (planets outside our solar system) through science-informed 3D artists’ impressions 

converted into VR2, to experiencing NASA mission spacecraft in VR such as the James Webb Space 

Telescope3, to walking across the surface of Mars4. The authors’ experience also includes exploring 

dozens of massive stars from the perspective of the supermassive black hole at the center of our Galaxy5 

(Russell, 2018) and viewing radio data cubes of a spiral galaxy (Ferrand et al., 2016). 

1.2. Data Path for Cassiopeia A: From 2D to VR  

Supernova explosions are among the most violent events in the universe. When the nuclear power 

source at the center of a massive star is exhausted, the core collapses and in less than a second, a neutron 

star typically forms. This process releases an enormous amount of energy, which reverses the implosion, 

blows material outwards and produces a brilliant visual outburst. The resulting debris field is referred to 

as a “supernova remnant.”   

Cassiopeia A (Cas A) is a supernova remnant from an explosion that occurred approximately 340 

years ago in Earth’s timeframe (see Figure 1). A multi-wavelength three-dimensional (3D) reconstruction 

of this remnant was created using X-ray data from Chandra, infrared data from Spitzer and optical data 

from ground-based telescopes. In Figure 1, the green regions are mostly iron, the yellow regions include a 

combination of argon and silicon, the red regions are cooler explosion debris, and the blue regions show 

the outer blast wave.  

When elements created inside a supernova are heated they emit light at specific wavelengths. 

Because of the Doppler effect, elements moving towards the observer will have shorter wavelengths and 

elements moving away will produce longer wavelengths. Since the amount of the wavelength shift is  

3 

 
  
Figure 1. Cassiopeia A (Cas A) is a supernova remnant located about 10,000 light years from Earth. This 
2D visual representation of Cas A has been processed to show with clarity the appearance of Cas A in 
different bands of X-rays. This will aid astronomers in their efforts to reconstruct details of the 
supernova process such as the size of the star, its chemical makeup, and the explosion mechanism. The 
color scheme used in this image is the following: low-energy X-rays are red, medium-energy ones are 
green, and the highest-energy X-rays detected by Chandra are colored blue. The image is 8.91 arcmin 
across (or about 29 light years).  Credit: NASA/CXC/SAO 

related to the speed of motion, the velocity of the debris can be determined. By combining this Doppler 

information with the expectation that the stellar debris are expanding radially outwards from the 

explosion center, Delaney et al. (2010) applied simple geometry to construct a 3D model of Cas A (Figure 

2). A program called 3D Slicer - modified for astronomical use by the Astronomical Medicine Project at 

Harvard6 - was used to display and manipulate the 3D model. 

4 

 
                    
 
This visualization7 shows that there are two main components to Cas A: a spherical component in 

the outer parts of the remnant containing light elements like helium and carbon from the outer layer of the 

exploded star, and a flattened (disk-like) component in the inner region containing heavier elements like 

argon and iron from the inner layers of the star. The blue filaments defining the blast wave show a 

different type of radiation that does not emit light at discrete wavelengths, and, therefore, were not 

included in the 3D model.  

Figure 2. By combining data from Chandra, the Spitzer Space Telescope, and ground-based optical observations, astronomers 
were able to construct the first three-dimensional fly-through of a supernova remnant. This 3D visualization (shown here as 
a still image) was made possible by importing the data into a medical imaging program that has been adapted for 
astronomical use. Commercial software was then used to create the version of the 3-D data. The green region shown in the 
image is mostly iron observed in X-rays; the yellow region is mostly argon and silicon seen in X-rays, optical and infrared and 
the red region is cooler debris seen in the infrared. The positions of these points in three-dimensional space were found by 
using the Doppler effect and simple assumptions about the supernova explosion.  Credit: NASA/CXC/MIT/T.Delaney et al. 

5 

 
 
                   
High-velocity jets of this material are shooting out from the explosion in the plane of the disk-like 

component mentioned above. Jets of silicon appear in the upper left and lower right regions, while plumes 

of iron are seen in the lower left and northern regions. These had been studied before the 3D model was 

made, but their orientation and position with respect to the rest of the debris field had not been mapped 

before this model. 

The insight into the structure of Cas A gained from this 3D visualization is important for 

astronomers who build models of supernova explosions. They have learned that the outer layers of the 

star come off spherically, but the inner layers come out more disk-like with high-velocity jets in multiple 

directions (Delaney et al., 2010). Since the Delaney et al. (2010) study, two other groups have constructed 

3D models of Cas A (Milisavljevic and Fesen, 2015; Orlando et al., 2016), demonstrating the rich 

scientific value of such visualizations for astronomers. 

This 3D visualization was initially created as an interactive for desktop viewing and interaction8. 

To move beyond the small screen, it was next translated into a 3D printable format9 (Arcand et al., 2017), 

a format which is particularly conducive for exploration by blind and visually impaired populations 

(Grice et al., 2015; Christian et al., 2015).   

The authors considered Virtual Reality (Figure 3) as the next step in the translation process, an 

additional experience beyond the 2D visual and 3D tactile ones (Eriksson, 2014).   

1.3. Augmented Reality in Astronomy 

As mentioned above, Augmented Reality (AR) adds text, image, sound-based elements or other 

effects to deliver an enhanced view for the user experience with additional sensory input, typically in a 

merging of real or “live” and virtual information. AR has been rising in popularity, with the number of 

smartphone, wearable computing devices, and other similar smart devices being pushed in the consumer  

6 

 
 
Figure 3. A three-dimensional virtual reality (VR) with augmented reality (AR) version of the 3D data of Cas A 
allows the user to walk inside the debris from a massive stellar explosion, select the parts of the supernova 
remnant to engage with, and access short captions on what the materials are.  This photo was taken of the first 
author inside the Brown University YURT, or VR CAVE, during testing of the Oculus Rift hardware and 
application.  Credit: NASA/CXC/SAO/E.Jiang 

market (Vogt & Shingles, 201310). From the "computational interfaces" popularized by Pokemon Go11 

(Sicart, 2017), to AR leopards that visitors can interact with to help promote conservation themes12, AR is 

expected to continue rising in popularity in the next few years13.   

7 

 
 
 
      
 
 
 
 
 
 
 
 
 
 
 
 
                                                                                                                                                                                  
 
AR is, therefore, neither a completely new nor a completely unexpected area for topics in 

astronomy. Vogt and Shingles (2013) for example14, make note of AR-based designs in astronomy for 

education purposes including 3D displays of our Solar system, 3D demonstrations of the Sun-Earth 

interaction, and a NASA application that allows users to get ‘up close and personal15’ with NASA 

spacecraft merged with AR overlays. Vogt and Shingles also include the use of AR for astronomy 

research, citing their own interactive AR figure of the supernova remnant N132d.  

2. VR TRANSLATION/TECHNICAL SPECIFICATIONS 

Currently, virtual reality software has not been standardized to the point where we can use data as 

direct input into a VR program. While software exists that allows visualizations to be displayed across 

different platforms (caves16, PowerWalls17, 3DTVs18, head-mounted displays19) using a variety of input 

devices (6 degree-of-freedom trackers20, multi-touch input devices21, haptic devices22), we have yet to 

design a system that can support raw data without any external software. Therefore, with each new type 

of dataset, effort must be made to build the bridge between raw data and VR software in order to produce 

the visualization. 

Given volumetric data (where volume, or the data inside an object, is rendered - as in an MRI or 

CT scan in medicine) and polygonal data (where only the surface, or the outside data, is rendered)  on the 

supernova remnant Cassiopeia A collected by Chandra, Spitzer, and ground-based optical observatories, 

this formatting of Cas A employs volume and surface rendering techniques using the Visualization 

Toolkit (VTK23) to create a MinVR24-enabled program. 

2.1. METHODS 

2.1.1. Volume and Surface Rendering 

To render the supernova both volumetrically and polygonally, we used VTK, an open-source, 

freely available software system for 3D computer graphics, image processing, and visualization. VTK 

supports a wide variety of visualization algorithms including scalar, vector, tensor, texture, and 

8 

 
volumetric methods, as well as advanced modeling techniques such as implicit modeling, polygon 

reduction, mesh smoothing, and contouring (https://www.vtk.org; Avila, Kitware, 2010). VTK has a suite 

of 3D interaction widgets.  

With VTK, we were able to read in the supernova datasets and use its built-in filters and mappers 

to render the remnant’s volume and surface. The remnant is composed of seven different parts, and each 

part is represented by a different color in the surface model. 

2.1.2. Integrating with MinVR 

MinVR is an open-source project developed and maintained collectively by the University of 

Minnesota, Brown University, and Malcalester College. It aims to support data visualization and virtual 

reality research projects by providing a cross-platform VR toolkit that can be used in many different VR 

displays, including Brown University’s YURT (Yurt Ultimate Reality Theatre, or CAVE).  

One technical challenge of this project was integrating the VTK program with MinVR. Since 

both programs had their own render function, we had to use VTK’s external module to allow the VTK 

program to accept an external render window and render loop. As has been the case when working with 

our 3D/VR projects thus far, multiple bridges need to be built between technologies in order to create 

something new.  We worked with the VTK to improve their external camera capacity. In the end, we were 

able to complete the integration and display the supernova models in the YURT.   

2.2. PROGRESS & RESULTS - VOLUME AND SURFACE RENDERING                                          

Figure 4. Volume Rendering 

9 

 
Figure 4(a) shows a sample volume rendering            
demo that uses iron density data to simulate 
what a supernova would look like given its 
volumetric data.  

Figure 4(b) illustrates that when the opacity 
level is low enough, one can observe an outer 
cube that encompasses the iron density data, 
illustrating the importance of adjusting opacity 
levels when volume rendering.  

On the other hand, when the opacity level is too 
high, we cannot see enough of the data to 
observe the differing measurements of density. 
Figure 4(c) shows that we must work to find an 
optimal opacity level and an intuitive color 
scale. 

Figure 5. Surface Rendering 

10 

 
 
 
 
 
      
 
 
 
 
 
 
 
The model in Figure 5(a) is a surface rendering 
of Cas A, which is made up of 7 different parts, 
as shown in different colors. Each part is a 
separate ASCII data file consisting of polygon 
data and triangular strips.  

The 7 parts shown in Figure 5(b) include a 
spherical component (purple), a tilted thick disk 
(gray), and multiple ejecta jets/pistons (green) 
and optical fast-moving knots (red, yellow, 
blue, pink) all populating the thick disk plane. 

Figure 5(c) shows the view from inside the 
spherical structure of the supernova. Here, it is 
possible to see that the rendering is a mesh of 
triangles that shape the surface. 

2.3. Augmented Reality: Narrative Additions 

For the Cas A VR experience, adding interactive text over the VR object was an important 

narrative component of the overall experience due to the complexity of the science model. Providing 

contextual information has been shown to improve the user experience in understanding and enjoyment of 

2D and 3D astronomy images for both experts and non-experts, and across technological platforms 

11 

 
 
 
 
 
 
 
 
 
 
 
 
 
(Smith et al., 2017, 2017, 2014 & 2010). Therefore expanding the addition of contextual information to 

VR data sets seemed ideal for users of all kinds.  

Our enhanced user experience of the VR Cas A model includes annotations for each of the parts 

of the supernova remnant (noting, for example, the neutron star, the iron and silicon debris, etc.) to 

describe both its components and its overall structure. Users can select a specific part of the supernova 

remnant by using their input device or wand (such as the Oculus Touch) to access the annotations and 

bring them up in their VR environment.  They can cycle through each notation to discover more 

information about Cas A.  These additional interactive narrative features may also help educators to more 

effectively tell the life story of a star, and provide resources for researchers who are observing the 

changes in size, density, and shape of stars. 

Figure 6. Augmented Reality 

Figure 6(a) shows the addition of narrative text, where the user can select a part of Cas A to focus on and 
access captions. In this case, the user has chosen to focus on the Neutron Star at the center of the remnant. 

12 

 
 
 
Figure 6(b) captures the screen of a user highlighting the Reverse Shock Sphere that demonstrates wave 
expansion.  Note how the caption superimposed over the image uses analogy to help potentially increase 
understanding (Smith, et al 2017). 

3. DISCUSSION 

The VR Cas A experience was created for 3D immersive environments such as CAVES and the 

Oculus Rift (Clark, 2014). Adaptations for cell phone usage with pop up personal VR viewers such as 

Google Cardboard, and that can also be used in a browser without any VR viewers, have been created to 

allow additional entry points for viewers who do not have access to more expensive equipment (for an 

online demonstration see http://chandra.si.edu/vr/casa).  

The Cas A 3D VR model has the potential to be a useful tool in engaging experts and non-experts 

in the data of astronomy and applications of computer science. For non-experts, specifically, astronomy 

data in general are popular as a science topic, as evidenced by the ubiquitous placement of astronomical 

images throughout popular culture everywhere from bed linens to computer wallpaper (and wallpaper 

murals).25 

13 

 
 
 
By linking the data and images of Cas A with unique computer tools in a project such as this, new 

connections can be made. Astronomy models in virtual reality can provide an unexpected visual and 

perceptual palette for the modern viewer.  Such applications may be able to assist participants in 

establishing a sense of presence with data that is, due to the nature of the distance from Earth, sheer scale, 

and other factors, otherwise difficult to relate to. This data can be shown at a monumental scale with VR. 

There are difficulties with VR technologies to consider, however, such as visual disconnect causing 

motion sickness, the need to incorporate an illusion of boundless movement, accessibility (both for 

underserved socioeconomic areas and also for physical accessibility by people who are visually 

impaired)26, as well as struggles in establishing touch-responsive features (Steinicke, 2016; Amer & 

Peralez, 2014).  

Just as in video games and educational software, VR-enabled science requires narrative 

integration whether for expert or non-expert users.27 The key to making such a project more than just a 

toy or gee-whiz moment is to provide meaningful information and content that is clearly embedded in the 

virtual experience. Projects such as this Cas A 3D VR/AR model could be used as a “jumping off” point 

for opportunities in a host of topics in astrophysics, chemistry, computer science and more. 

With current market trends for equipment and more adaptations of content and technologies for 

VR experiences (including multimodal access points for those with physical disabilities), it is a critical 

time to create quality astronomy-based materials for experienced VR users, as well as those new to VR. 

In education specifically, helping students maximize the potential of VR could be done partially through 

output adaptations to platforms such as YouTube which can host 360 degree versions of many VR videos 

where they can act as a canvas for individualized VR experiences tailored to the needs of different 

learners (Cotabish, 2017). This aspect of the viewer-driven experience in VR broadly (Chen et al., 2014) 

could potentially positively impact users with different learning styles, viewers with autism (Lahiri et al., 

2015), participants with different physical abilities or other special needs (Tyler-Wood et al., 2015), and 

more.  

14 

 
3.1. NEXT STEPS 

3.1.1. Expansion of Astrophysics VR Library  

While our current results have provided an immersive and interactive rendering of the supernova 

remnant Cassiopeia A, we plan to expand our astrophysics VR data sets to build additional 3D 

visualizations to help illustrate more fully the life-cycle of stars, from birth to death, with further 

interactivity included for the user. We are investigating the application of additional 3D data-driven 

models to import into the VR pipeline described in previous sections. Future models include volumetric 

data files of supernovas and younger star systems that might also lead to more comprehensive models.  

We are also working to make the existing VR application ADA/Section 508 compliant for accessibility.28  

3.1.2. Beyond Supernovas & Supernova Remnants 

Through rendering 3D models of Cas A, this project has in addition implemented a generic 

program with examples of how to create similar programs to read in and display such data. In the future, 

the authors hope to demonstrate new models of another famous supernova, SN 1987A, an explosion on 

the surface of a white dwarf, V745 Sco, and other astrophysical density data. The goal is to generate these 

models with less effort than for Cas A. Our intent is that this generic program could act as a skeleton and 

tutorial for future data sets in biomedical, physical or other fields.29   

4. CONCLUSION 

We are excited about both the current abilities and the future potential of opportunities for using 

VR/AR in astronomy. There is a potential for unique educational experiences by wedding the popularity 

of a visual science like astronomy with the technological advances that continue to evolve in VR/AR. 

Making “real world” examples like Cas A part of the cadre of VR/AR could spur creative ideas of how to 

infuse science into a realm that might typically include more content from science fiction. We look 

forward to making deeper connections with the subject matter we are most familiar with, to see how we 

can expand its content into the virtual third dimension and beyond. 

15 

 
ACKNOWLEDGMENTS 

Many special thanks to the Virtual Reality Lab at the Center for Computation and Visualization at Brown 

University without which this project could not have been done. The Cassiopeia A digital 3D model was 

originally developed with Dr. Tracey Delaney of West Virginia Wesleyan College (formerly of MIT), 

with the Chandra X-ray Center at the Smithsonian Astrophysical Observatory, in Cambridge, MA, with 

funding by NASA under contract NAS8-03060.  

REFERENCES 

ADA National Network, What is the Americans with Disabilities Act?, viewed 8 March 2018. 
<https://adata.org/learn-about-ada>. 

Amer, A. & Peralez, P. 2014 ‘Affordable altered perspectives: Making augmented and virtual reality 
technologies accessible’, Global Humanitarian Technology Conference (GHTC) [online], 2014 IEEE, 
San Jose, CA, USA. Available at: http://ieeexplore.ieee.org/document/6970345/?reload=true [Accessed 
11 Jan. 2018]. 

Arcand, K. & Watzke, M. "How to Hold a Dead Star in Your Hand." Chandra X-ray Observatory. 
Harvard-Smithsonian Center for Astrophysics, n.d. Web. Retrieved from 
http://chandra.si.edu/deadstar/deadstar.html 

Arcand K., Watzke, M., DePasquale, J., Jubett, A., Edmonds, P., DiVona, K. 2017, Communicating 
Astronomy with the Public. Bringing Cosmic Objects Down to Earth: An overview of 3D modeling and 
printing in astronomy 

Arcand, K.K., Watzke, M., Rector, T. Levay, Z.G., DePasquale, J., Smarr, O. “Processing Color in 
Astronomical Imagery”, Studies in Media and Communication, December 2013. 

Avila, Kitware, Lisa S. "The VTK User's Guide." The Visualization ToolKit 11th (n.d.): n. pag. Kitware, 
Inc., 2010. Web. Retrieved from https://www.kitware.com/products/books/VTKUsersGuide.pdf  

Christian, C.A, Nota, A., Greenfield, P., Grice, N., Shaheen, N. 2015, Journal and Review of Astronomy 
Education and Outreach, 3. 

Chen, J.A., Metcalf, S.J., & Tutwiler, M.S. (2014).  Motivation and beliefs about the nature of scientific 
knowledge within an immersive virtual ecosystems environment.  Contemporary Educational Psychology 
[online], 39: 2, 112-123.  https://doi.org/10.1016/j.cedpsych.2014.02.004 [Accessed 8 Dec. 2017]. 

Clark, Taylor. (2014). 2014 American Ingenuity Awards: How Palmer Luckey Created Oculus Rift.  
Available at: https://www.smithsonianmag.com/innovation/how-palmer-luckey-created-oculus-rift- 
180953049/?preview=&page=2 [Accessed 10 Jan. 2018]. 

Clements, D. L.; Sato, S.; Portela Fonseca, A., EJPh, 38, 1, 
http://adsabs.harvard.edu/abs/2017EJPh...38a5601C 

16 

 
 
 
 
 
 
 
 
 
 
Cotabish, A. (2017). Utilizing YouTube for immersive VR science learning. [online] Available at: 
https://edexcellence.net/articles/utilizing-youtube-for-immersive-vr-science-learning [Accessed 4 Jan. 
2018]. 

DeLaney, T.,  Rudnick, L., Stage, M. D., Smith, J. D., Isensee, K., Rho, J., Allen, G. E., Gomez, H., 
Kozasa, T., Reach, W. T., Davis, J. E., Houck, J. C.2010, ApJ, 725, 2, https://arxiv.org/abs/1011.3858 

DePasquale, J., Arcand K.K, Edmonds, P., "High Energy Vision: Processing X-rays" Studies in Media 
and Communication,  Vol 3, No 2, 2015 https://doi.org/10.11114/smc.v3i2.913 

Eriksson, U., Linder, C., Airey, J., & Redfors, A. (2014). Who Needs 3D When the Universe is Flat?  
Science Education [online], Volume 98: 3, 412-442.  Available at: 
http://onlinelibrary.wiley.com/doi/10.1002/sce.21109/abstract [Accessed 12 Mar. 2018]. 

Faisal, A. (2017). Computer Science: Visionary of Virtual Reality. Nature [online], Volume 551, 298-
299. Available at https://www.nature.com/articles/551298a [Accesed 5 Jan. 2018]. 

Ferrand, G., English, J., & Irani, P. (2016).  ‘3D Visualization of Astronomy Data Cubes Using 
Immersive Displays,’ presentation given at CASCA Conference, Winnipeg, Manitoba, 31 May - 2 June 
2016.  Available at: http://hci.cs.umanitoba.ca/assets/publication_files/Gilles.pdf [Accessed 9 Feb. 2018]. 

Fluke, C.J. & Barnes, D.G. (2016). ‘The Ultimate Display,’ to appear in Proceedings of ADASS XXV, 
Sydney, Australia, 25-29 October 2015. Available at: https://arxiv.org/abs/1601.03459v1 [Accessed 9 
Feb. 2018]. 

Garcia-Betances, R., Arredondo Waldmeyer, M.T., Fico, G., & Cabrera-Umpierrez, M.F. (2015). A 
succinct overview of virtual reality technology use in Alzheimer’s disease.  Frontiers in Aging 
Neuroscience [online], Volume 7, 80. Available at: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC 
4428215/ [Accessed 10 Jan. 2018]. 

Goodman, A., Rosolowsky, E.W., Borkin, M.A. Foster, J.B., Halle, M. Kauffmann, J. Pineda, J.E. A role 
for self-gravity at multiple length scales in the process of star formation. Nature on January, 2009, Vol 
457. doi:10.1038/nature07609 

Gottschalk, M.  Virtual Reality is the Most Powerful Medium of Our Time, viewed 9 Jan. 2018, 
Artsy.  Available at: https://www.artsy.net/article/artsy-editorial-virtual-reality-is-the-most-powerful-
artistic-Medium-of-our-time 

Grice, N., Christian, C., Nota, A., Greenfield, P., 2015, JBIR, 5, 1, 
https://nfb.org/images/nfb/publications/jbir/jbir15/jbir050101.html 

Hung, Y., Vetivelu, A., Hird, M.A., Yan, M., Tam, F., Graham, S.J., Cusimano, M., & Schweizer, 
T.A.  (2014).   Using fMRI virtual-reality technology to predict driving ability after brain damage: A 
preliminary report. Neuroscience Letters [online], Volume 558, 41-46.  Available at: https://www. 
academia.edu/22458106/Using_fMRI_virtualreality_technology_to_predict_driving_ability_after_brain_
damage_A_preliminary_report [Accessed 11 Jan. 2018]. 

17 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Isenberg, T. 2013. ‘Position Paper: Touch Interaction in Scientific Visualization,’ [online] in Isenberg, P., 
Carpendale, S., Hesselman, T., Isenberg, T., & Lee, B. (eds.), Proceedings of the workshop on Data 
Exploration on Interactive Surfaces, DEXIS 2011, Kobe, Japan, pp. 24 -27.  Available at: 
https://hal.inria.fr/file/index/docid/781512/filename/Isenberg_2011_TIS.pdf [Accessed 11 Jan. 2018]. 

Kiniry, L. (2017).  How Augmented Reality Is Helping Raise Awareness About One of Armenia’s Most 
Endangered Species. [online] Available at: https://www.smithsonianmag.com/travel/how-augmented- 
reality-helping-raise-awareness-about-one-armenias-most-endangered-species-1-180967670/ [Accessed 4 
Jan 2018]. 

Lahiri, U., Bekele, E., Dohrmann, E., Warren, Z., & Sarkar, N.  (2015). A Physiologically Informed 
Virtual Reality Based Social Communication System for Individuals with Autism. Journal of Autism and 
Developmental Disorders [online], Volume 45, 919-931. Available at: https://www.ncbi.nlm.nih.gov/ 
pmc/articles/PMC4369156/ [Accessed 12 Jan. 2018]. 

McLeod, A. F., Dale, J. E., Ginsburg, A., Ercolano, B., Gritschneder, M., Ramsay, S., Testi, L. 2015, 
MNRAS, 450, 1057 https://arxiv.org/abs/1504.03323 

Milisavljevic, D. and Fesen, R.A. 2015, Science, 6221, 526 
https://arxiv.org/abs/1501.07283  

Murphy, B. (2018). Virtual reality taking the dummies out of medical simulation. [online] Available at: 
https://wire.ama-assn.org/education/virtual-reality-taking-dummies-out-medical-simulation [Accessed 9 
Jan. 2018]. 

Orlando, S., 2016, Miceli, M., Pumo, M. L., Bocchino, F. 2016, 822, 22 
https://arxiv.org/abs/1603.03690 

Rector, T., Levay, Z., Frattare, L., Arcand, K.K., Watzke, M.,"The Aesthetics of Astrophysics:  How to 
Make Appealing Color-Composite Images that Convey the Science" Publications of the Astronomical 
Society of the Pacific, 2017. 

Rector, T., Levay, Z., Frattare, L., English, J., Pu'uohau-Pummill, K., Image-Processing Techniques for 
the Creation of Presentation-Quality Astronomical Images, The Astronomical Journal, Volume 133, 
Number 2, 2007. http://iopscience.iop.org/article/10.1086/510117/meta 

Russell, C.M.P. (2018). ‘360-degree videos: a new visualization technique for astrophysical simulations’,  
presentation given at American Astronomical Society, AAS Meeting #231, National Harbor, MD, 8 -12 
January 2018. Available at http://adsabs.harvard.edu/abs/2018AAS...23131101R [Accessed 9 Feb. 2018]. 

Sicart, M. (2017). Reality has always been augmented: Play and the promises of Pokemon GO. Mobile 
Media & Communication [online], Volume 5(1), 30-33. Available at: 
http://journals.sagepub.com/doi/pdf/10.1177/2050157916680015 [Accessed 11 Dec. 2017]. 

Smith, L.S., Arcand, K.K., Smith, B.K., Smith, R.K., Smith, J.K., Bookbinder, J., "Capturing the Many 
Faces of an Exploded Star: Communicating Complex and Evolving Astronomical Data," JCOM Science 
Communication Journal. Dec 2017. 

Smith, L.S., Arcand, K.K., Smith, B.K., Smith, R.K., Bookbinder, J., Smith, J.K., "Black Holes and 
Vacuum Cleaners: Using Metaphor, Relevance, and Inquiry in Labels for Space Images" Psychology of 

18 

 
 
 
 
 
 
 
 
 
 
 
 
 
Aesthetics, Creativity, and the Arts special issue on “Aesthetics, Creativity, and the Arts in Everyday 
Environments," 2017. 

Smith, L.S., Smith, J.K, Arcand K.K, Smith, R.K, Bookbinder, J., "Aesthetics and Astronomy: How 
Labels Affect Understanding and Appreciating Deep Space Images," Curator, 2014.  

Smith, L.S., Smith, J.K, Arcand K.K, Smith, R.K, Bookbinder, J., Keach, K. Aesthetics and Astronomy: 
Studying the public’s perception and understanding of imagery from space. Science Communication 
Journal. August 2010.  

Steffen, W.; Teodoro, M.; Madura, T. I.; Groh, J. H.; Gull, T. R.; Mehner, A.; Corcoran, M. F.; Damineli, 
A.; Hamaguchi, K., 2014, MNRAS, 442, https://arxiv.org/abs/1407.4096 

Stein, J. (2015). Why Virtual Reality Is About to Change the World. [online] Available at: http://time. 
com/3987022/why-virtual-reality-is-about-to-change-the-world/ [Accessed 10 Jan. 2018]. 

Steinicke, F. (2016).  ‘Chapter 4: Scientific, Technological, and Social Challenges,’ in Steinicke, F. Being 
Really Virtual: Immersive Natives and the Future of Virtual Reality [online]. Cham, Switzerland: 
Springer International Publishing, pp. 47 – 57. Available at: https://link.springer.com/chapter 
/10.1007/978-3-319-43078-2_4 [Accessed 5 Jan. 2018]. 

Tyler-Wood, T., Estes, M., Christensen, R., Knezek, G., & Gibson, D.  (2015). SimSchool:  An 
Opportunity for Using Serious Gaming for Training Teachers in Rural Areas. Rural Special Education 
Quarterly [online], Volume 34(3), 17-20. Available at: https://www.questia.com/library/journal/1P3- 
3855958731/simschool-an-opportunity-for-using-serious-gaming [Accessed 12 Jan. 2018]. 

United States Access Board 2000, Section 508 Standards for Electronic and Information Technology, 
viewed 3 March 2018, <https://www.access-board.gov/guidelines-and-standards/communications-and-it/ 
about-the-section-508-standards/section-508-standards>. 

Virtual Reality 101, 2016, viewed 5 Jan. 2018, CNET. Available at: https://www.cnet.com/special-
reports/vr101/   

Virtual Reality Payments, 2016, viewed 6 Apr. 2018, Oracle. Available at: https://www.oracle.com/ 
about/tomorrow/payscout.html?pcode=WWMK171128P00101&sc=ADV_FY18_US_YTT_N121_E_YT
T-TW-Pay-2B 

Vogt, F.P.A. & Shingles, L.J.  (2013). Augmented reality in astrophysics. Astrophysics and Space Science 
[online], Volume 347(1), 47 - 60.   Available at: https://pdfs.semanticscholar.org/e064/14f637bad6170 
ee644d9059339b053177fbb.pdf [Accessed 12 Jan. 2018]. 

1 E.g., http://www.cnn.com/TECH/9710/14/3.d.reality.lat/index.html 
2 https://www.space.com/38749-visit-six-real-exoplanets-with-virtual-reality.html 
3 https://connect.unity.com/p/vr-experience-james-webb-space-telescope 
4 https://www.jpl.nasa.gov/news/news.php?feature=6978 
5 http://chandra.si.edu/photo/2018/gcenter360/ 
6 Note: since archived, Initiative in Innovative Computing: http://am.iic.harvard.edu 
7 Cas A 3D Model video at: http://chandra.si.edu/photo/2009/casa2/ 

19 

 
 
 
 
 
 
 
 
 
 
 
 
                                                           
8 Smithsonian 3D model: http://3d.si.edu/explorer?mid=45 
9 Printable Cas A 3D Model: http://chandra.si.edu/3dprint 
10 http://ieeexplore.ieee.org/document/6970345/?reload=true 
11 Sicart (2017) notes the potential drawbacks for AR, including the ability for it to be used by private companies 
and other for-profit actors that are not accountable to the physical spaces that they create virtual revenue within, 
which can reduce equity rather than provide a new platform for it. 
12 See for example https://www.smithsonianmag.com/travel/how-augmented-reality-helping-raise-awareness-about-
one-armenias-most-endangered-species-1-180967670/ 
13 See for example https://www.thenational.ae/business/peter-nowak-why-augmented-reality-will-be-a-big-trend-in-
2017-1.32774; https://venturebeat.com/2018/02/08/the-nyt-is-boarding-the-ar-train-heres-what-that- 
means-for-storytelling/ 
14 The Vogt and Shingles (2013) paper can be downloaded as an augmented article, illustrating the utility of the 
technology promoted in the paper. The authors argue for collaboration between science researchers and publishing 
platforms to create more stable, as well as backwards compatible, content for AR. 
15 Examples at https://www.nasa.gov/mission_pages/msl/news/app20120711.html 
16 Brown Center for Computation and Visualization CAVE: https://web1.ccv.brown.edu/viz-cave ;Juarez, A., 
Schonenberg, B., & Bartneck, C. (2010). Implementing a Low-Cost CAVE System Using the 
CryEngine2. Entertainment Computing, 1(3-4), 157-164. http://www.bartneck.de/publications/2010/caveCryEngine/ 
[Accessed 17 Mar. 2018] 
17 See for example the Viscon Virtual Reality VR PowerWall: http://viscon.de/en/vr-2/vr-powerwall/ 
18 LG provides a striking example of a 3DTV: https://www.lg.com/us/tvs/lg-OLED55E6P-oled-4k-tv; Reasonably 
priced glasses for the 3DTV are available at Kmart: https://www.kmart.com/edimensional-ed-4-pack-cinema-3d-
glasses-for/p-SPM8624650802?plpSellerId=Ami%20Ventures%20Inc&prdNo=2&blockNo=2&blockType=G2 
19 A very affordable version of the head mounted display is available at: Amazon.com. (2018). [online] Available at: 
https://www.amazon.com/AUPALLA-Cardboard-Christmas-Version-Virtual/dp/B01LZA1EKZ/ref=sr_1_15/143-
5425711-5657840?ie=UTF8&qid=1521395844&sr=8-15&keywords=google%27s+cardboard [Accessed 5 Jul. 
2018]; See for a more costly option: Amazon.com. (2018). [online] Available at: https://www.amazon.com/Oculus-
Rift-Virtual-Reality-Headset-pc/dp/B00VF0IXEY/ref=sr_1_4?s=electronics&ie =UTF8&qid=1521395894&sr=1-
4&keywords=oculus+rift [Accessed 5 Jul. 2018]. 
20 https://www.roadtovr.com/introduction-positional-tracking-degrees-freedom-dof/ 
21 Marzo, A., Bossavit, B., & Hachet, M. (2014). Combining Multi-Touch Input and Design Movement for 3D 
Manipulations in Mobile Augmented Reality Environments, ACM Symposium on Spatial User Interaction [short 
paper], Oct 2014, Honolulu, HI, United States. Available at: https://hal.inria.fr/hal-01056226/document [Accessed 
13 Jul. 2018]. 
22 See this video for an explanation of haptic devices: https://www.youtube.com/watch?v=ABeAAHF6k1k 
23 "Enabled Applications." VTK. Kitware, n.d. Web. http://www.vtk.org/ 
24 "MinVR/MinVR." GitHub. Brown University, 20 Apr. 2017. Web. Retrieved from 
https://github.com/MinVR/MinVR 
25 See, for example, the Space and Astronomy section of Geek Wrapped for an assortment of products decorated 
with astronomical images: Best Space and Astronomy Gifts (2018), viewed 8 March 2018 
<https://www.geekwrapped.com/astronomy>. 
26 The ADA National Network explains What is the Americans with Disabilities Act?, viewed 8 March 2018. 
<https://adata.org/learn-about-ada>. 
27 The necessity of narrative is discussed in Gottschalk, M. (2016) Virtual Reality is the Most Powerful Medium of 
Our Time. 
28 United States Access Board (2000) sets out the Section 508 Standards for Electronic and Information Technology. 
29 The CXC does not endorse any specific commercial product, including the virtual reality technologies referenced 
throughout this paper.  

20 

 
                                                                                                                                                                                           
