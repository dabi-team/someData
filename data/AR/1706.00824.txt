7
1
0
2

n
u
J

2

]

O
C

.
t
a
t
s
[

1
v
4
2
8
0
0
.
6
0
7
1
:
v
i
X
r
a

COMPARATIVE PERFORMANCE ANALYSIS OF THE CUMULATIVE
SUM CHART AND THE SHIRYAEV–ROBERTS PROCEDURE FOR
DETECTING CHANGES IN AUTOCORRELATED DATA

Aleksey S. Polunchenkoa,

∗, Vasanthan Raghavanb

aDepartment of Mathematical Sciences, State University of New York (SUNY) at Binghamton
Binghamtom, NY 13902–6000, USA
bQualcomm, Inc.,
Bridgewater, NJ 08807, USA

Abstract

|

|

λ

We consider the problem of quickest change-point detection where the observations form a ﬁrst-
order autoregressive (AR) process driven by temporally independent standard Gaussian noise.
Subject to possible change are both the drift of the AR(1) process (µ) as well as its correlation
coeﬃcient (λ), both known. The change is abrupt and persistent, and is of known magnitude,
< 1 throughout. For this scenario, we carry out a comparative performance analysis of
with
the popular Cumulative Sum (CUSUM) chart and its less well-known but worthy competitor—
the Shiryaev–Roberts (SR) procedure. Speciﬁcally, the performance is measured through Pollak’s
Supremum (conditional) Average Delay to Detection (SADD) constrained to a pre-speciﬁed level
of the Average Run Length (ARL) to false alarm. Particular attention is drawn to the sensitivity of
each procedure’s SADD and ARL with respect to the value of λ before and after the change. The
performance is studied through the solution of the respective integral renewal equations obtained
via Monte Carlo simulations. The simulations are designed to estimate the sought performance
metrics in an unbiased and asymptotically strongly consistent manner, and to within a prescribed
proportional closeness (also asymptotically). Our extensive numerical studies suggest that both
the CUSUM chart and the SR procedure are asymptotically second-order optimal, even though

∗Address correspondence to A. S. Polunchenko, Department of Mathematical Sciences, State University of New
York (SUNY) at Binghamton, Binghamton, NY 13902–6000, USA; Tel: +1 (607) 777-6906; Fax: +1 (607) 777-
2450; Email: aleksey@binghamton.edu

Email addresses: aleksey@binghamton.edu (Aleksey S. Polunchenko), vasanthan_raghavan@ieee.org

(Vasanthan Raghavan)

URL: http://people.math.binghamton.edu/aleksey (Aleksey S. Polunchenko)

Preprint submitted to Applied Stochastic Models in Business and Industry

June 6, 2017

 
 
 
 
 
 
the CUSUM chart is found to be slightly better than the SR procedure, irrespective of the model
parameters. Moreover, the existence of a worst-case post-change correlation parameter corre-
sponding to the poorest detectability of the change for a given ARL to false alarm is established
as well. To the best of our knowledge, this is the ﬁrst time the performance of the SR procedure
is studied for autocorrelated data.
Keywords:
CUSUM chart, Shiryaev–Roberts procedure, Sequential analysis, Sequential change-point
detection, Auto-regressive process

1. Introduction

Sequential (quickest) change-point detection is concerned with the design and analysis of
reliable statistical machinery for quick detection of potential changes in the attributes of a ran-
dom process. Speciﬁcally, the process is assumed to be continuously monitored through observa-
tions made sequentially, and should their behavior suggest that the process may have statistically
changed, the aim is to conclude so within the fewest observations possible, subject to a tolerance
level on the risk of false alarm. A sequential change-point detection procedure is a stopping-time
adapted to the observations, and provides a rule to stop and declare that a change may be in eﬀect.
This problem ﬁnds applications in many branches of science and engineering: quality control,
biostatistics, economics, seismology, and communication systems; see, e.g., [1–3].

In the simplest change-point detection problem, the observations are independent and iden-
In this setting, the
tically distributed (i.i.d.) with known pre- and post-change distributions.
problem is well-understood and has been solved to optimize diﬀerent objectives. For a recent
survey, see [4, 5] and references therein. In general, two solutions stand out: Page’s Cumulative
Sum (CUSUM) chart [6] and the Shiryaev–Roberts (SR) procedure due to the independent work
of Shiryaev [7, 8] and Roberts [9]. While the two procedures are statistically diﬀerent, both are
optimal under diﬀerent sets of criteria. In particular, Moustakides [10] and Ritov [11] have shown
that the CUSUM chart is exactly minimax-optimal in the sense of minimizing the detection delay
under the most unfavorable set of observations and change-point. This type of minimax optimality
was proposed by Lorden [12]. On the other hand, Pollak and Tartakovsky [13] showed that the SR
procedure is optimal in the stationary setting, a scenario more suitable for detecting changes that
occur at a distant time-horizon. Given that the Lorden criterion is often conservative, Pollak and
Siegmund [14] introduced a more reasonable metric of detection delay under the most unfavorable
change-point, but averaged over the observations; see also [15]. While the structure of the exactly

2

optimal solution is unknown for the Pollak criterion, both the CUSUM chart and SR procedure
are asymptotically optimal as the false alarm risk vanishes; see, e.g., [16]. Thus, there has been a
good justiﬁcation for comparing the two procedures with each other.

This comparative analysis has been done extensively in the i.i.d. case and we now present a
brief sampling of this literature. The study in [17] oﬀered a comprehensive asymptotic analysis (in
the low false alarm regime) for the problem of detecting a change in the drift of Brownian motion.
The conclusion in [17] was that the CUSUM chart is better for changes that occur in the beginning,
whereas the SR procedure out-performs the CUSUM chart for change at inﬁnity. Dragalin [18]
developed an accurate numerical technique to capture the performance of the CUSUM chart in
detecting a change in the mean of a Gaussian sequence. More recently, Moustakides et. al [19, 20]
have developed an exact analytical characterization of the two procedures under either criteria
through a set of integral-equations. These equations are in turn solved numerically using simple
computational techniques. Conﬁrming the ﬁndings of Pollak and Siegmund [17] and Pollak and
Tartakovsky [13], these computations show that the CUSUM chart is superior to the SR procedure
under the Pollak criterion, whereas the SR procedure is better in the stationary sense.

Despite the strong theoretical focus on the i.i.d. problem, observations are often serially cor-
related in industrial practice with a ﬁrst-order autoregressive (AR(1)) process model being a good
ﬁt in many scenarios. A change could occur either due to a shift in the mean level or in the cor-
relation coeﬃcient (of the AR process) or both attributes simultaneously; see diﬀerent examples
in [1, 2, 21–24], etc. Many works in the literature have shown that when the traditional Shewhart,
Exponentially Weighted Moving Average (EWMA) and CUSUM charts designed for i.i.d. ob-
servations are used with AR processes, they result in seriously misleading conclusions; e.g., see
typical case-studies in [25–27].

Motivated by these observations, modiﬁed versions of the traditional control charts accommo-
dating serial correlations have been proposed; see [28, 25, 23, 29–32] for some extensions along
these lines. Most of these procedures decompose the correlated data into common cause eﬀects
and residuals (innovations) that are mutually independent. Under certain assumptions, the sta-
tistical properties of the residuals can be characterized. Speciﬁcally, the limiting distribution of
the likelihood ratio function under either a mean shift or a correlation change in the AR process
has been studied and various approximations to the average run length (ARL) to false alarm are
obtained in [33–35, 29, 36–41]. In particular, Davis, Huang, and Yao [42] has shown that the like-
lihood ratio statistic converges weakly to the extreme value distribution and use this property to
characterize the performance of the CUSUM chart, whereas Timmer et. al [43] estimate the ARL
of the CUSUM chart using a Markov chain representation. The studies in [44] and [45] use the

3

eﬃcient score vector representation of the likelihood ratio statistic of weighted CUSUM charts to
characterize their performance.

In spite of this vast literature, optimality properties of the CUSUM chart have been explored
only under certain special settings and only up to ﬁrst-order. For example, Moustakides [46]
has shown that the CUSUM test statistic reduces to the i.i.d. statistic in the special case where
only the mean of the AR process changes and the CUSUM chart is thus optimal in the Lorden
sense. First-order optimality of the CUSUM chart and the SR procedure under more general
observation models has also been established; see e.g., [47, 48] and [16]. First-order optimality
of the CUSUM chart under certain general change-point models relevant in practice is explored
in [49]. Nevertheless, a comparative performance of the CUSUM chart with the SR procedure in
the model parameter space has not been explored in the AR setting in full generality. The focus
of this paper is on this task and we provide a comparative study of the two procedures in the
non-asymptotic setting with correlated observations. We are not aware of any similar prior work
in this area.

This paper is organized as follows. In Section 2, we set the backdrop for this paper by elabo-
rating on the problem set-up, developing the notation, and connecting it with prior results in this
area. In Section 3, the KL number between autoregressive processes is studied as a function of
the pre- and post-change model parameters. In Section 4, we derive the integral equations for the
performance metrics of interest and provide a simple numerical solution that allows for eﬃcient
computation of the operating characteristics. In Section 5, we present the results of our numerical
studies and discuss the ﬁndings. Section 6 summarizes and concludes the paper.

2. Problem Formulation and Preliminary Background

The aim of this section is to formally state the problem, present the CUSUM chart and the
Shiryaev–Roberts (SR) procedure, both set up appropriately, and review their (asymptotic) opti-
mality properties.
Xn}n

0 be an observation sequence formed sequentially from the output of an AR(1) pro-
≥
1,
0,
≥

cess driven by temporally-independent standard Gaussian noise
and εi is independent of ε j if i , j. Let the statistical nature of the observation sequence,
be temporally piece-wise:

1, i.e., εn ∼ N

≥
Xn}n

(0, 1), n

εn}n

Let

{

{

{

≥

1 + εn, for 1
+ λ
µ
Xn
−
∞
∞
1 + εn, for n
µ0 + λ0Xn
−

≥

n

ν;

≤
≤
ν + 1,

Xn =





4

(1)

|

{

0,

λd|

Xn}n

R and λd is such that

< 1. µd and λd are known for both d =

R is
where µd ∈
a given deterministic value, and ν is a parameter discussed next. The data model in (1) says that the
observation sequence,
0, as it is formed in a one-observation-at-a-time manner, undergoes
≥
a spontaneous change in its statistical nature. The quickest change-point detection problem is to
as quickly and reliably as possible establish that the statistical nature has changed. The challenge
is that the time instance ν, which is referred to as the change-point, is not known in advance. A
0-adapted stopping time,
solution to the problem is a detection procedure identiﬁed with a
≥
T , and a “good” procedure is one whose detection delay cost is the smallest possible within a
given tolerable range of the false alarm risk.

, X0 = x0 ∈

Xn}n

∞}

{

{

, Xν (the pre-change
Remark. A noteworthy feature of the AR(1) model in (1) is that X0, X1,
observations) and Xν+1, Xν+2,
(the post-change observations) are not independent as Xν+1 (the
ﬁrst data point aﬀected by change) is correlated with Xν (the ﬁnal data point not yet aﬀected by
change). This is diﬀerent from the general AR(m) model considered, e.g., in [35], where the pre-
and post-change pieces of the observations sequence are assumed independent.

· · ·

· · ·

≥

∞

are µ

be the hypothesis that ν =

More speciﬁcally, in this work, we will take the minimax approach, i.e., regard the change-
point, ν, as unknown (but not random); for an overview of other approaches, see, e.g., [16, 4, 5,
50]. From now on, the notation ν = 0 is to be understood as the case where the parameters of
Xn}
1, are aﬀected by change ab initio. Similarly, the
are µ0 and λ0 for all n
Xn}n
1, i.e., the data,
{
≥
notation ν =
for all n
Xn}
is to mean that the parameters of
1.
≥
Hk : ν = k be the hypothesis that the change-point, ν, is at epoch k, 0
Let
: ν =
∞

. Let
, i.e., that the process’ parameters never change. Further,
H∞
let Pk (and Ek) be the probability measure (and the corresponding expectation) given a known
. In particular, P
change-point ν = k, where 0
) is the probability measure (corre-
≤ ∞
∞
sponding expectation) assuming that the AR(1) process’ parameters are µ
and λ
1,
). Likewise, P0 (E0) is the probability measure (corresponding
and never change (i.e., ν =
1 (i.e., ν = 0).
expectation) assuming that the AR(1) process’ parameters are µ0 and λ0 for all n
Under the minimax approach, the standard method to gauge the false alarm risk is through
[T ], and

Lorden’s [12] Average Run Length (ARL) to false alarm; it is deﬁned as ARL(T ) , E
∞
captures the average number of observations sampled before a false alarm is sounded. Let

for all n

and λ

k <

(E

∞

∞

∞

≥

≤

≤

≥

k

∞

∞

∞

∞

∞

{

{

∆(γ) ,

T : ARL(T )

γ

, γ > 1,

≥

denote the class of procedures with the ARL to false alarm of at least γ > 1, a pre-selected
tolerance level. For the detection delay cost, we will use the criterion proposed by Pollak [15];

n

o

5

see also [14, Section 5]. It is known as the Supremum (conditional) Average Detection Delay
(SADD), and is deﬁned as,

SADD(T ) , sup
k<
∞

0
≤

ADDk(T ) with ADDk(T ) , Ek[T

T > k].

k

|

−

(2)

The overarching problem of interest in this framework is to ﬁnd Topt ∈

∆(γ) for all γ > 1, or more succinctly, to

SADD(T ) over all T

∈

∆(γ) that minimizes

ﬁnd Topt = arg inf
∆(γ)

T

∈

SADD(T ),

(3)

for every γ > 1. This problem is still open. Even in the basic i.i.d. case, only a partial solution has
been oﬀered so far [51, 52, 20, 53]. Speciﬁcally, as shown in [51, 52], the so-called generalized
Shiryaev–Roberts (GSR) procedure (due to [20]) is exactly SADD-optimal under two speciﬁc
i.i.d. scenarios. This result was then extended in [53] where, under a general i.i.d. scenario, the
GSR procedure was demonstrated to minimize the SADD asymptotically, as γ
, to within an
o(1) term; here o(1)
. However, beyond the basic i.i.d. case, not much progress
has been made so far, and only the asymptotic theory has been outlined. In the general case, it
was demonstrated in [47] that under certain regularity conditions the CUSUM chart and the SR
procedure are asymptotically ﬁrst-order optimal.

0, as γ

→ ∞

→ ∞

→

In the AR(1) case, the joint cumulative distribution functions (c.d.f.’s) of the sample X1:n ,
Hk hypotheses are given by

1, under the

(X1, . . . , Xn), n

and

H∞

≥

n

Yj=k+1

j
i ≡

P0(X j|

1),
X j
−

1 whenever i > j.

P(X1:n|H∞

) =

n

j=1
Y

P

∞

(X j|

X j
−

1) and P(X1:n|Hk) =

k

j=1
Y

P

∞

(X j|

X j
1)
−

Q

where here (and throughout the sequel), it is to be understood that
Consequently, for the respective likelihood ratio (LR), we obtain

Λ1:n,ν=k , dP(X1:n|Hk)
dP(X1:n|H∞
)

=

n

Yj=k+1

Λ j(X j, X j
1),
−

6

where

1) , exp
Λn(Xn, Xn
−

( 

Xn −

1
2

(cid:2)

1(λ0 + λ
Xn
−

∞

) + (µ0 + µ
∞

)

Xn
−

1(λ0 −

λ

) + (µ0 −

∞

h

!
(cid:3)
µ

∞

, n

1,

≥

)
i)

(4)

is the “instantaneous” LR for the n-th data point, Xn, conditioned on the (n
1)-th data point,
−
1) as simply Λn, unless it is necessary
1; for notational brevity, we will also refer to Λn(Xn, Xn
Xn
−
−
to stress that it is a function of Xn and Xn
1.
−

Remark. As a special case of the AR(1) model in (1), suppose, for the moment, that the change is
, µ0;
only in the drift and the correlation coeﬃcient is not aﬀected, i.e., let λ
then the LR formula given above reduces to

= λ0 (, λ), but µ
∞

∞

Λn = exp

(µ0 −

)

µ

∞

˜εn −
(cid:20)

(cid:26)

µ0 + µ
∞
2

, n

1,

≥

(cid:21)(cid:27)

≥

λXn
1, n
−

where ˜εn , Xn −
1. This is easily recognized as the LR formula for the well-studied
i.i.d. data model, i.e., when a sequence of independent unit-variance Gaussian random variables
undergoes an abrupt and persistent shift in the mean from µ
to µ0; see, e.g., [54, 2, 55, 56, 19, 20,
= λ0, the AR(1) model in (1) is equivalent
57, 58] among many other references. Hence, when λ
to the basic i.i.d. model, and the presence of correlation in the observations is completely irrele-
vant; cf. [46, Section IIIB, p. 1967]. We shall therefore always require that at least the correlation
, λ0.
coeﬃcient is aﬀected by the change, i.e., λ

∞

∞

∞

We now switch attention to the objective of this work, which is to study the SR procedure for
detecting change in the AR process parameters and benchmarking its performance with that of the
CUSUM chart. The SR procedure corresponding to a threshold A is deﬁned as

where the SR decision statistic,

{

τsr(A) , inf

n

A

1 : Rn ≥
0, is deﬁned as
≥

(cid:9)

≥
(cid:8)
Rn}n

, such that

inf

∅
}

{

=

,

∞

Rn ,

n

Xk=1

Λ1:n,ν=k =

n
1
−

n

Xk=0

Yi=k

Λi, n

≥

1, with R0 = 0,

7

(5)

(6)

where

{

Λn}n

1 is as in (4), and we note the recursion
≥

1) Λn, n
Rn = (1 + Rn
−

≥

1, with R0 = 0.

(7)

We remark that, as can be seen from (7), the SR detection statistic,

0, starts oﬀ at zero,
≥
i.e., R0 = 0. This is the original deﬁnition of Shiryaev [7, 8] and Roberts [9]. However, if
the detection statistic is given a speciﬁcally designed headstart, i.e., if R0 = r
0, then the
performance of the procedure may improve substantially. The headstarted version of the SR
procedure (the generalized SR procedure) is proposed in [20] and studied in [53]. The basic
proposal of giving headstart to a procedure was ﬁrst proposed in [59] in the context of the CUSUM
chart.

Rn}n

≥

{

Contrary to the quasi-Bayesian background of the SR procedure, the CUSUM chart is based

on the maximum likelihood argument, and its stopping time is deﬁned as

where the decision statistic,

τcs(A) , inf

n

≥

1 : Vn ≥
(cid:8)
0, is given by
≥

A

, such that

inf

∅
}

{

=

,

∞

(cid:9)

Vn}n
{
Vn , max
n
k
1
0
−
≤
≤

Λ1:n,ν=k, n

≥

1, with V0 = 0,

and we note the recursion

Vn = max

1, Vn
1}
−

{

Λn, n

≥

1, with V0 = 0.

(8)

(9)

(10)

As mentioned in the Introduction, a majority of the change-point detection theory developed
to date is restricted to the i.i.d. model, and is largely of asymptotic character. The cornerstone of
the asymptotic theory for the i.i.d. model is the condition

1

−

k

n

log(Λ1:n,ν=k) =

1

−

k

n

n

j=k+1
X

log(Λ j)

p

−−−→n
→∞

k <

≤

∞

D(P0 k

P

∞

) , I,

(11)

; cf. [60, 47, 61]. The quantity

to be valid under the probability measure Pk for all 0
I , D(P0 k

P

∞

) is the Kullback–Leibler divergence or information number (see [62]) deﬁned as

I , D(P0 k

P

∞

) , lim
n
→∞

log

1
n

Z

dP0(X0:n)
(X0:n)
dP
∞

!

dP0(X0:n),

(12)

8

 
.

and it can be interpreted as the directional distance from the probability measure P0 to the prob-
If the i.i.d. scenario is such that I is ﬁnite, then the condition in (11) is
ability measure P
∞
automatically (over-)fulﬁlled by the Strong Law of Large Numbers. Thus, from [15, 63] and an
argument given in [64], it can be deduced that under the i.i.d. assumption both the CUSUM chart
and the SR procedure minimize the SADD to within an additive term of order O(1) asymptoti-
cally, as γ
, and
→ ∞
SADD(τsr)
. This is known as asymptotic
−
second-order optimality.

−
∆(γ) SADD(T ) = O(1), as ARL(τsr) = γ

∆(γ) SADD(T ) = O(1), as ARL(τcs) = γ

. That is, SADD(τcs)

→ ∞

→ ∞

infT

infT

∈

∈

However, except in the i.i.d. case, condition (11) is too weak to even guarantee that the moment
sequence of the stopping time of interest is bounded from above, let alone to ensure any asymptotic
optimality thereof. Hence, unless condition (11) is strengthened, it is not feasible to extend the
asymptotic theory for the i.i.d. model to the general non-i.i.d. case. This strengthened condition
has been obtained in [60, 47, 61, 65] and the condition we need is

1

−

k

n

log(Λ1:n,ν=k) =

1

−

k

n

n

j=k+1
X

log(Λ j)

I

a.s.
−−−→n
→∞

under Pk for every k, 0

k <

≤

∞

, with the constraint on the rate of convergence:

∞

Pk

n=k+1
X

|
(cid:0)

log(Λ1:n,ν=k)

(n

−

−

k) I

|

> (n

−

k)ǫ

<

∞

, for every ǫ > 0,

(13)

(cid:1)

and every 0

k <

. Together, these two conditions are known as complete convergence [66].

The complete convergence condition is not restrictive, and is generally met in practice; in
particular, the condition is true for correlated Markov processes, such as the AR(1) model in (1).
In fact, for the AR(1) model in (1), the complete convergence condition has already been veriﬁed
in [67, Example 1, p. 2455], although in a slightly diﬀerent context. Hence, it is safe to deduce
from [60, 47, 61, 65], that both the CUSUM chart and the SR procedure are asymptotically ﬁrst-
order optimal as ARL(T ) = γ

. That is,

≤

∞

→ ∞

SADD(τcs)

SADD(τsr)

∼

∼

T

inf
∆(γ)
∈

SADD(T )

log γ

I [1 + o(1)],

≥

where o(1)

0, as γ

→

.

→ ∞

To conclude this section, we point out that the KL number, I, is the key in understanding what
one can expect (performance-wise) from a detection procedure, be it the CUSUM chart or the SR

9

procedure. In particular, the higher the KL number, I, the lower the SADD, i.e., the better the
performance. It is therefore worthwhile to analyze the eﬀect that each of the four parameters of
the AR(1) model in (1) has on the KL number. This analysis is undertaken in the next section,
and, in particular, it is shown that the nature of the dependence of the KL number on each of the
four parameters may be counterintuitive.

3. Analysis of the Kullback–Leibler Information Number

The KL number captures the discrimination between the post- and pre-change hypotheses, and
is thus a measure of the detectability of the change. This section’s aim is take a careful look at the
KL number of the AR(1) model in (1).

Proposition 1. The KL number, I, for the AR(1) model in (1) is given by the formula

I , I(µ
∞

=

1
2 ·

, λ0)
)2

+

, µ0, λ
(λ0 −
1
−

∞
λ
∞
λ2
0

(1

)2

λ
−
2

∞

µ0

·

1

"

−

λ0 −

1

µ

−

∞
λ

2

.

∞ #

(14)

Proof. The desired formula can be derived directly from the KL number’s deﬁnition, which is

I , lim
n
→∞

1
n

log

dP0(X0:n)
(X0:n)
dP
∞

!
Now, since the Radon–Nikodym derivative (dP0/dP
∞

Z

dP0(X0:n).

) under the log in the integral (in the

10

 
right-hand side above) has already been computed in (4), we obtain

I = lim
n
→∞

1
n

n

Z

i=1 (
X

Xi(µ0 −

)

µ

∞

−

Xi
−

1(λ0µ0 −

λ

∞

µ

∞

)

+ XiXi
−

1(λ0 −

λ

)

∞

−

X2
i
1
−

λ2
0 −
2

= (µ0 −

µ

∞

) lim
n
→∞

1
n

n

E0[Xi]

i=1
X
+ (λ0 −

−

(λ0µ0 −
1
n

) lim
n
→∞

λ

∞

1
n

µ

∞

∞

) lim
n
→∞

λ

n

E0[XiXi
1]
−

E0[Xi
1]
−

i=1
X

λ2
∞

!
n

µ2
∞

µ2
0 −
2

−

!)

dP0(X0:n)

= [µ0(1

λ0)

(1

µ

∞

−

−

λ

∞

)] lim
n
→∞

−

1
n

i=1
X
λ2
0 −
2

λ2
∞

1
n

lim
n
→∞

−
n

i=1
X

−

!
E0[Xi] + (λ0 −
λ2
λ2
1
0 −
∞
n
2

lim
n
→∞

n

i=1
X
λ

∞

n

E0[X2
1]
i
−

−

n

1
n

) lim
n
→∞

i=1
X
E0[X2
i ]

−

µ2
∞

µ2
0 −
2

!

E0[XiXi
1]
−

µ2
∞

µ2
0 −
2

.

!

Now, recall the basic result that if

an , a,
then its so-called Ce`saro mean sequence (see, e.g., [68, Chapter V, Section 5.4, p. 96]), i.e., the
sequence

an}n

→∞

{

!

i=1
X
1 is a convergent sequence such that limn
≥

bn}n

{

1 formed as
≥

bn , 1
n

n

i=1
X

ai, n

1,

≥

bn = a; see, e.g., [68, Chapter V, Sec-
is also convergent with the same limit, i.e., limn
tion 5.7, p. 100–102]. Hence, with the aid of the Pd-stationarity of the AR(1) model in (1) under

→∞

11

 
 
 
 
 
 
d =

0,

{

∞}

, i.e., the assumption that

< 1, d =

λd|

|

0,

{

∞}

, it is easily established that

1
n

lim
n
→∞

1
n

n

lim
n
→∞
1
n

i=1
X

lim
n
→∞

n

i=1
X
n

E0[Xi] = lim
n
→∞

E0[Xn] =

1

µ0

−

E0[X2

i ] = lim
n
→∞

i=1
X
E0[XiXi
1] = lim
n
−
→∞

E0[X2

n] =

(1

E0[XnXn
1] =
−

,

+

λ0
µ2
0
λ0)2
µ2
0
λ0)2

(1

1

−

−

1

−

+

,

λ2
0

λ0

λ2
0

1

−

.

The desired formula for the KL number follows once these computations are plugged into the
(cid:3)
right-hand side of the expression above and simplifying it.

{

λ

As a “sanity check”, it is easily veriﬁed from (14) that I
, λ0, µ
the four model parameters
∞
there is no change at all, i.e., when µ
I

] for all possible values of
∞
. The smallest value I = 0 is achieved for the case when
1, 1). On the other hand,
(
−

+
We now review several special cases of the AR(1) model that will be considered in the sequel.
= λ0 (, λ), the

To start with, observe that in the case when only the drift changes, i.e., when λ
obtained formula for I reduces to

, as λ0 → ±
1.

= λ0 (, λ), λ

= µ0 and λ

, µ0}

[0, +

→

∞

∈

∈

∞

∞

∞

∞

I =

µ
(µ0 −
2

∞

)2

,

(15)

{

µ0 −
which is independent of λ and is a (symmetric) function only of
, i.e., of the discernibility
|
Xn}n
in the drift of the process,
0, between the pre- and post-change regimes. This is expected,
≥
and (15) is also the same as the KL number between observations that are both i.i.d. pre- and
(µ0, 1), respectively. This suggests that the various change-point
post-change;
detection procedures in this case should be similar in performance to detecting a change in i.i.d.
processes. This result has been established in [46] where the CUSUM chart is shown to be optimal
in the Lorden sense.

, 1) and

(µ

∞|

N

N

µ

∞

The KL number in the i.i.d. pre-change case (λ

= 0 is plotted as a function of
= 0
λ0 for diﬀerent values of µ0 in Fig. 1(a). Similarly, the KL number corresponding to the µ
∞
= 0 settings are plotted as a function of λ0 for diﬀerent combinations of parameters in
and λ
Figs. 1(b) and (c), respectively. These plots clearly illustrate the existence of a certain worst-
case (in the sense of detectability) post-change correlation that leads to the smallest value of I

= 0) with µ

∞

∞

∞

12

conditioned on the other model parameters. To understand this behavior of I, we now study these
special cases more carefully.
In the case where µ

= µ0(, µ), I reduces to

∞

I , (λ0 −
2(1
−

)2
λ
∞
λ2
0) ·

1 + µ2
"

It can be checked that

1 + λ0
1

λ0 !#

−

.

∂ I
∂λ0

, λ0 −
(1
−

λ
∞
λ0)2 ·

"

µ2

1
1

·

λ
∞
λ0

−
−

+

λ0λ
1
∞
(1 + λ0)2

−

.

#

(16)

(17)

and µ, I in (16) decreases in λ0 for all λ0 < λ

Thus, for a ﬁxed λ
I then starts increasing from 0 as λ0 increases past λ
post-change process increases I provided that both the processes are positively correlated.

.
∞
. Speciﬁcally, a higher correlation in the

with I = 0 obtained at λ0 = λ

∞

∞

∞

When the observations are i.i.d. pre-change (λ

= 0) with µ

∞

∞

= 0, I reduces to

I =

2(1

1

−

λ0) ·

"

λ2
0
1 + λ0

+

1

µ2
0
λ0 #

−

.

(18)

For a ﬁxed µ0, it can be checked that

∂ I
∂λ0

=

(1

1
λ0)3 ·

−

"

λ0(1
λ0)
−
(1 + λ0)2

+ µ2
0

.

#

From the above equation, a trivial calculation shows that I is globally minimized at λ0, crit, deﬁned
as,

λ0, crit ,

8µ2

0 + 1
2(µ2

−

q

(2µ2

0 + 1)

.

1)

0 −

Further, the KL number of the correlated process is smaller than µ2
corresponding i.i.d. problem) if and only if λ0 belongs to the interval

0/2 (the KL number of the
λ0, lower, λ0, upper

, where

h

i

and λ0, upper = 0.

λ0, lower , max

1,

−





1
1
2 · 



− s

9µ2
0 + 1
µ2
0 + 1 





13

 
It can be checked that
decreasing in µ2

λ0, lower ≤
≤
0. Further, we also have

1
−

λ0, crit ≤

λ0, upper = 0 for all µ0 with both λ0, lower and λ0, crit

λ0, lower →
λ0, lower → −

0 and λ0, crit →
1 and λ0, crit → −
See Fig. 1(d) for a plot of the three quantities as a function of µ0. In Figs. 1(e)-(f), these three
= 5, respectively. Note that, in
quantities are plotted as a function of µ0 when µ
general, the behavior of all the three quantities is asymmetric in µ0.

0 as µ0 →
0
1 as µ0 → ∞

3 and µ

=

−

∞

∞

.

∞

More generally, if λ

, 0, the behavior of λ0, upper, λ0, lower and λ0, crit as a function of λ

for
and µ0 values is presented in Figs. 2(a)-(b). From Figs. 1(d)-(f) and Figs. 2(a)-(b), we
for every case in the model parameter space. The
, µ0 and 0 and can be summarized

diﬀerent µ
observe that either λ0, lower or λ0, upper equals λ
observed trends depend on the precise relationship between µ
as follows:

∞

∞

∞

∞

µ0 < 0 < µ

∞

or 0 < µ

∞

0 < µ0 < µ

or µ
< µ0 or µ0 < µ

∞

∞

< µ0 < 0

< 0 or µ

∞

∞

=
⇒
< 0 < µ0 =
⇒

λ0, lower = λ
∞
λ0, upper = λ

∞

.

To summarize the above analysis, the KL number, I , I(µ
∞

, λ0), associated with the
AR(1) model in (1) and given by (14), is always larger than the KL number for the basic i.i.d.
problem for post-change correlation above and below certain cut-oﬀ values. In the intervening
regime, the KL number is smaller than the i.i.d. problem with a worst-case λ0 given by λ0, crit.
These trends are illustrated pictorially in Figs. 1(a)-(c).

, µ0, λ

∞

4. Performance Evaluation

This section is devoted to developing a numerical framework to evaluate the performance
of the CUSUM chart (8)–(10) and the SR procedure (5)–(7) when applied to the AR(1) model
in (1). Speciﬁcally, for each of the stopping times—either T = τcs if it is the CUSUM chart, or
T = τsr if it is the SR procedure—the framework is “tailored” to two antagonistic performance
characteristics:a) the usual “in-control” ARL to false alarm, i.e., ARL(T ), and b) Pollak’s [15]
Supremum (conditional) Average Detection Delay, i.e., SADD(T ).

The framework here is a build-up to the one previously oﬀered and applied in [56, 19, 20]
for the i.i.d. model (with no cross-dependence in the observed data); see also, e.g., [69, 57, 58].
Accordingly, just as the prototype framework of [56, 19, 20, 69, 57, 58], our framework is also
developed in two stages: we ﬁrst derive a renewal integral equation for each performance metric

14

involved, and then, as neither one of the obtained equations can be solved analytically, we supply
a numerical method to do so, and carry out an analysis of the method’s accuracy. What is new
in the setting considered here is that the integral equations are not one- but two-dimensional, and
(therefore) the numerical method is not deterministic but rather a Monte-Carlo-type estimation
technique of prescribed proportional closeness, a criterion considered, e.g., in [70, p. 339], [71–
75].

4.1. The renewal equations

To compute the performance of the CUSUM chart (8)–(10) and that of the SR procedure (5)–
(7) when applied to the AR(1) model in (1), we now derive analytically exact renewal equations
on the performance characteristics of interest. To begin with, it is direct to see from (4) that
Λn(Xn, Xn
1 for all n
1) is (absolutely) continuous with respect to both Xn and Xn
1. Next,
−
−
0, consider the generic detection procedure associated with the
given the observation series,
≥
generic stopping time

Xn}n

≥

{

0, x0 ∈
whose decision-making is based oﬀ the generic detection statistic

1 : Yn ≥

, y0 ≥

T (x0, y0, A) , inf

≥

A

n

(cid:8)

(cid:9)

1) Λn(Xn
Yn = Ψ(Yn
−
−

{
1, Xn) for n = 1, 2, . . . with Y0 = y0 ≥

0 deﬁned as
≥

Yn}n
0 and X0 = x0 ∈

R,

R, A > 0,

(19)

∞

×

0 and x0 ∈

where Ψ(z) is a (suﬃciently) smooth non-negative-valued function deﬁned (at least) for z
and y0 ≥
y0 ≥
measure, so that the two-dimensional (homogeneous) Markov process,
to the half-plane [0,

0,
0 and that
0 is almost surely non-negative under any probability
≥
0, is restricted
}n
≥

R are given constants; the assumptions that Ψ(z)

0 are necessary to ensure that

(Yn, Xn)

0 for z

Yn}n

R.

≥

≥

≥

)

{

{

{

Yn}n

0 and the SR detection statistic,
≥

Now note that since the choice of Ψ(z) is ﬂexible, the generic stopping time T (x, y, A) can be
seen to describe a rather large class of LR-based detection procedures; in particular, if Ψ(z) =
1 + z, then
0, are identical, and therefore, for this
≥
choice of Ψ(z) the generic stopping time T (x, y, A) and that associated with the SR procedure
coincide. Hence, the SR procedure is a special case of T (x, y, A), as is the CUSUM chart; indeed,
if Ψ(z) = max
0, and therefore, in this
0 is the CUSUM detection statistic,
{
≥
≥
case the generic stopping time T (x, y, A) is no diﬀerent from that associated with the CUSUM
chart. This ﬂexibility of the generic stopping time T (x, y, A) can be used to study simultaneously
the performance of not only the CUSUM chart or the SR procedure, but also of a far larger number

Rn}n

Vn}n

Yn}n

, then

1, z

}

{

{

{

15

of other procedures (e.g., EWMA procedure).
Let Pd(Yn ≤
1 = x1), d =
1 = y1, Xn
y2, Xn ≤
, denote the transition probability
Yn
−
−
function to describe the evolution (in time, n) of the two-dimensional (homogeneous) Markov pro-
0 under probability measure Pd, d =
1 =
(Yn, Xn)
Yn
cess
}n
{
−
≥
1 = x1), d =
y1, Xn
−

∞}
; note that Pd(Yn ≤

, is independent of n. Let

y2, Xn ≤

x2|

x2|

∞}

0,

0,

0,

{

{

{

∞}

Kd(y2, x2|

y1, x1) ,

∂2
∂y2∂x2

Pd(Yn ≤

y2, Xn ≤

x2|

1 = x1),
1 = y1, Xn
Yn
−
−

d =
d =

, be the respective transition probability density kernel; it is clear that Kd(y2, x2|
, is independent of n as well. A straightforward calculation shows that

(20)

y1, x1),

1 = x1)
1 = y1, Xn
y2, Xn ≤
Yn
x2|
−
−
Φ(min
µd −
x2, ξ(x1, y1, y2)
{
Φ(ξ(x1, y1, y2)
λd x1)
µd −
−

} −

−

Φ(x2 −

λd x1),
µd −

λd x1),

if µ0 −
if µ0 −

µ
µ

∞

∞

+ x1(λ0 −
+ x1(λ0 −

λ
λ

0
)
≥
∞
) < 0,

∞

ξ(x1, y1, y2) ,

1
+ x1(λ0 −

λ

)

∞

log

y2
Ψ(y1)

!

µ0 −

µ

∞

µ0 + µ
∞

+

+ x1(λ0 + λ

2

)

,

∞

0,
{
0,
{

∞}
∞}
Pd(Yn ≤
=

(

where

and

Φ(x) , 1
√2π

x

t2
2 dt,

e−

Z

−∞

i.e., the standard Gaussian cdf.

We are now in a position to derive the ﬁrst renewal equation of interest, viz., that on the
ﬁrst moment of T (x0, y0, A) under measure P
, i.e., for the ARL to false alarm of the generic
∞
stopping time T (x0, y0, A). Speciﬁcally, for notational brevity, denote ℓ(x, y, A) , E
[T (x, y, A)].
By conditioning on the ﬁrst observation, X1, and using a routine renewal argument akin to that
made in [20] we obtain

∞

ℓ(x1, y1, A) = 1 +

A

∞

0
−∞ Z

Z

K

∞

(y2, x2|

y1, x1) ℓ(x2, y2, A) dy2 dx2.

(21)

The double integral in the right-hand side of this equation cannot be separated, since Yn and
1, the

1. However, it is because Yn and Xn are correlated for all n

Xn are correlated for all n

≥

≥

16

 
double integral is eﬀectively a single integral, and is taken along the curve given by the points
y1, x1) , 0. These points satisfy the equation u(x1, y1, y2) = x2, or
(y2, x2) for which K
written explicitly

(y2, x2|

∞

1
+ x1(λ0 −

log

λ

)

y2
Ψ(y1)

µ

µ0 −

µ0 + µ
∞

+

+ x1(λ0 + λ

)

∞

= x2,

2

!
and for all other values of (x1, y1) and (x2, y2) the integral is zero, and ℓ(x1, y1, A) = 1 irrespective
of A > 0.

∞

∞

Thus, the double integral in the right-hand side of (21) is to be understood in the Riemann–
Stieltjes sense with the measure of integration being P
1 = x1).
1 = y1, Xn
Yn
−
−
∞
Since the latter is a two-dimensional cdf, it is clearly a function of bounded variation, and therefore
the existence of the integral is justiﬁed.

y2, Xn ≤

(Yn ≤

x2|

Next, introduce δ0(x, y, A) , E0[T (x, y, A)], and observe that

δ0(x1, y1, A) = 1 +

A

∞

Z

−∞ Z

0

K0(y2, x2|

y1, x1) δ0(x2, y2, A) dy2 dx2,

(22)

which is an exact “copy” of equation (21) except that K
For k

1, since

0 is Markovian, one can establish the recursion
}n
≥

Rr=x
n

{

≥

(y2, x2|

y1, x1) is replaced with K0(y2, x2|

∞

y1, x1).

δk+1(x1, y1, A) =

A

∞

Z

−∞ Z

0

K

∞

(y2, x2|

y1, x1) δk(x2, y2, A) dy2 dx2, k

0,

≥

(23)

with δ0(x, y, A) ﬁrst found from equation (22); cf. [20]. Using this recursion one can generate the
entire functional sequence

0 by repetitive application of the linear integral operator
≥

δk(x, y, A)
}k

{

u , [

K∞ ◦

K∞ ◦

u](x1, y1) ,

A

0

Z

K

∞

(y2, x2|

y1, x1) u(x2, y2) dy2 dx2,

where u(x, y) is assumed to be suﬃciently smooth inside the strip R
[0, A]. Temporarily defer-
ring formal discussion of this operator’s properties, note that using this operator notation, recur-
sion (23) can be rewritten as δk+1 =
0,
where

0, or equivalently, as δk =

k
∞ ◦

K∞ ◦

δ0, k

δk, k

K

×

≥

≥

u for k

1,

≥

u ,

k
∞ ◦

K

K∞ ◦ · · · ◦ K∞
k times

◦

|

{z

}

17

 
            
            
0

∞

K

is the identity operator from now on denoted as I, i.e.,
and
in the operator form, equation (21) can be rewritten as ℓ = 1 +
rewritten as δ0 = 1 +

δ0.

K
K∞ ◦

0
∞ ◦

u , u. Similarly,
u = I
ℓ, and equation (22) can be

◦

K0 ◦

Lemma 1. For the generic detection procedure T (x0, 0, A) given by (19) it is true that

SADD(T (x0, 0, A)) , sup
k<
∞

0
≤

ADDk(T (x0, 0, A))

= ADD0(T (x0, 0, A)) , E0[T (x0, 0, A)].

Equations (21) and (22) provide a “complete package” to compute any of the desired perfor-
mance characteristics of the CUSUM chart and those of the SR procedure. The question to be
considered next is to compute these characteristics in practice.

4.2. The numerical solution and its accuracy

The renewal equations established in the preceding subsection on the performance metrics
of interest are (two-dimensional) Fredholm (linear) integral equations of the second kind. Such
equations rarely permit an analytical, closed-form solution, even in a single dimension. Hence, a
numerical method is in order, and it is the aim of this subsection to propose one.

The branch of numerical analysis concerned with the design and analysis of numerical schemes
to solve Fredholm integral equations of the second kind has plenty of powerful methods for
eﬃcient solution of these equations in one dimension. However, even then the dimension is
two, things get much more complicated. We propose to consider a Markov Chain Monte-Carlo
(MCMC) technique.

We start with an observation that although the integral involved in the equation of interest is
a double integral, it can actually be reduced to a single equation, as Xn and Rn are dependent on
one another. Speciﬁcally, this single integral is along the curve described in the (Xn, Rn) space by
the relation Rn = (1 + Rn
1) Λn, where both Xn
1 and Rn
1 are assumed ﬁxed. Let us therefore deal
−
−
−
with a single-dimensional equivalent of the equation of interest:

u(x) = 1 +

K(x, y) u(y) dy,

(24)

Z

R2, is the respective transition probability density for the appropriate

(x, y)
where
K
Markov chain.

≥

0,

(x, y)

∀

∈

18

It is known (and can be easily shown) that the solution to this equation admits the following

Neumann series:

u(z0) = 1 +

K(z0, z1) dz1 +

Z[0,A]

∞

= 1 +

+

Z⊗

3
i=1[0,A]
k

K(z0, z1) K(z1, z2) dz1 dz2

2
i=1[0,A]

Z⊗
K(z0, z1) K(z1, z2) K(z2, z3) dz1 dz2 dz3 + . . .

1, z j)
K(z j
−


dz1 dz1 . . . dzk,

k

i=1[0,A] 

k=1 Z⊗
X

j=1
Y





where

denotes the usual direct product (as applied to sets).

⊗

We ﬁrst note that equation (24) can be solved either at a particular (single) point, or over
a particular interval. We are interested in the former, with the point being zero, i.e., when the
detection statistic has no headstart. For the actual solution method to obtain u(0) , E[T ], one
option would be to use a deterministic numerical scheme to “linearize” the integral in the right-
hand side of (24), and then, to ensure the linearization is “optimal”, reduce the integral equation to
a system of linear equations for a vector approximating the unknown function [76]. The problem
with this approach is that the integral is actually two-dimensional, and is over an unbounded
region. As a result, it is diﬃcult to “chop up” the region of integration to form a partition of
reasonable size. To overcome this problem, we suggest to consider a Monte Carlo technique.

The idea of the basic Monte Carlo approach to evaluate u(0) , E[T ] is to compute it sta-
tistically, i.e., to—in one way or another—estimate it based on a (somehow) generated sample,
1 independent instantiations of the (same) stopping time T . Speciﬁcally, let
T j}1
{
E[T ] denote an estimator of E[T ]. The standard choice for

E[T ] is to use the sample mean

N, of N

j
≤

≥

≤

d

¯TN , 1
N

T j,

N

j=1
X

d

which is well-justiﬁed since the sample mean is unbiased (for any N
Law of Large Numbers, is also asymptotically (as N

≥
) consistent.

1), and, due to the (strong)

While it is not a problem to simulate as many independent instantiations of T as necessary
E[T ] , ¯TN to the
(even if N is 106 or higher), the question of proximity of the respective estimate
actual true (but unknown) value of E[T ] is to be addressed with care. To that end, the standard
(0, 1), of a prescribed width, w > 0.
solution is to construct a (1

ǫ) %-conﬁdence interval, ǫ

d

→ ∞

−

∈

19

Speciﬁcally, let σT denote the standard deviation of T , i.e., σT , √Var[T ]. If σT is known, then
from the Central Limit Theorem (CLT) we immediately have

and therefore, to ensure that

√N

E[T ]

¯TN −
σT

d
→∞ N
−→N

(0, 1),

P

¯TN −
σT

E[T ]
|

|

≤

w
!

ǫ,

1

−

≥

it suﬃces to take the sample size N as

N

2zǫ/2

+ 1,

σT
w

≥

(cid:16)

(cid:22)

⌊

ǫ

≤

≤

−

w

x
⌋

E[T ]

¯TN −

(cid:23)
is the ﬂoor function, and zǫ/2 is the ǫ/2-th percentile of the standard Gaussian distribu-
(0, 1), the unknown
w, ¯TN + w), i.e., it

where
tion. Rephrasing this, for this choice of N, with probability of at least 1
∈
true mean E[T ] of the stopping time T will be contained in the interval ( ¯TN −
¯TN + w
will be true that P

−
As may be seen, the problem with this approach is that the standard deviation, σT , is not
known. One could, of course, estimate it, and then build a conﬁdence interval oﬀ the estimated
value, ˆσT . The issue with this idea, however, is that the distribution of ( ¯TN −
E[T ])/ ˆσT may fail
to be normal, even asymptotically, as N
. A more elegant way out of this is to note that if
→ ∞
E[T ]. With
the detection statistic’s headstart is zero, which is the case in this work, then σT ≤
formal proof of this inequality temporarily deferred, let us illustrate what it can lead to. Since
σT ≤
is contained in the
1), the event
event

E[T ] and E[T ] > 0 (in fact E[T ]
¯TN −
wσT

≥
, and therefore

¯TN −

w E[T ]

E[T ]

E[T ]

| ≤

| ≤

ǫ.

≥

1

(cid:17)

(cid:9)

|

|
(cid:8)

(cid:9)
P

|

¯TN −

E[T ]
|

E[T ]

P

|

< w
!

≥

(cid:8)
¯TN −
σT

E[T ]
|

,

< w
!

/ E[T ], are readily available; in this case
¯TN−
so that conﬁdence bounds for the relative error,
|
w is measured in percentages. This criterion is known as prescribed proportional closeness [70,
p. 339], [71–75].

E[T ]
|

We now prove the claim made earlier that σT ≤

headstart. Let Mk(x, A) , E[T k(x, A)] with k

E[T ] when the detection statistic has no
N, i.e., Mk(x, A) is the k-th moment of the stopping

∈

20

 
 
 
time T (x, A); in particular, M1(x, A) , E[T (x, A)]. We will need the following two lemmas.

Lemma 2. M1(x, A)

M1(0, A) for any given A > 0 and x

0.

≤
M1(0, A) is merely the statement that, on average,
Proof. The sought-after inequality M1(x, A)
the higher the headstart of the detection statistic behind the stopping time T (x, A), the sooner
(on average) the respective detection procedure is to terminate. That is, the closer the detection
statistic is initially to the detection threshold, A > 0, the sooner (on average) it is to reach the
(cid:3)
threshold, and therefore, the sooner (on average) the detection procedure is to stop.

≥

≤

Lemma 3.

(I

1
)−

◦

− K

M1

(x, A)

≤

M1(0, A) M1(x, A) for any given A > 0 and x

0.

≥

(cid:3)

Proof. The desired result is a direct consequence of Lemma 2, i.e., the inequality M1(x, A)
M1(0, A),
∀
(I
1
)−
◦

≤
0, applied to upperbound each summand in the respective Neumann expansion for
(cid:3)
(x, A).

(cid:2)
x
≥
M1

− K
With Lemma 2 and Lemma 3 in mind, it is easy to see that

1(0, A). As
(cid:2)
shown in [57], the second moment, M2(x, A) , E[T 2(x, A)], of the generic stopping time, T (x, A),
(cid:2)
M2, where M1(x, A) , E[T (x, A)].
is governed by the integral equation M2 = 2M1 −
K ◦
M1. Finally, since
The operator solution to this equation is of the form M2 = 2(I
Var[T ] = M2 −

(cid:3)
M1 −

M1, we obtain

1, and

(x, A)

− K

M1

1 +

−K

1
)−

1
)−

M2

M2

(I

≤

≤

◦

◦

(cid:3)

1

M1 = M1 −
K ◦
M2(x, A) = 2
(I
1
)−
− K
2M2
1(0, A)
(cid:2)
2M2
1(0, A).

≤

−

≤

(x, A)

M1
◦
M1(x, A)
(cid:3)

M1(x, A)

−

M2

1(0, A)

Therefore, M2(0, A)

2M2

1(0, A), and we have

≤

σ2
T

, Var[T (0, A)] , M2(0, A)
1(0, A),

M2

−

≤

E[T ], provided the detection statistic starts oﬀ zero (no headstart). We
which is to say that σT ≤
stress that the assumption of no headstart is a critical one, and when the detection statistic does
have a (non-zero) headstart, the inequality σT ≤
We conclude this subsection with a remark on how to reduce the variance of the sample mean
¯TN. The idea is that since the ﬁrst two terms in the Neumann series are always computable exactly,
as such there is no need to estimate either one of them. Hence, instead of sampling the trajectories

E[T ] may fail to hold.

21

(x, y) assuming the starting point is 0, one may start each trajectory oﬀ a random point,

from
K
sampled from

(x, y), but restricted to the interval [0, A].

K

5. Numerical Studies

We now apply the numerical techniques illustrated in the preceding section to compute ARL
and SADD and perform a comparative analysis of the CUSUM chart and SR procedure. But
before this, we need to design the procedures carefully.

5.1. Designing the CUSUM chart and SR procedure

The design of the CUSUM chart and the SR procedure requires an understanding of how the
threshold A should be set (as a function of γ) to ensure that the ARL with either procedure is at
least γ. For this, we study the ARL behavior of both procedures numerically as a function of the
= 0 and µ0 = 1, Figs. 3(a) and (b) plot ARL
threshold A. In the i.i.d. pre-change setting with µ
for the CUSUM chart and the SR procedure, respectively, for diﬀerent values of A and λ0. In
= 0.50 and
Figs. 3(c)-(d), ARL vs. A is plotted for the CUSUM chart and SR procedure with λ
several λ0 values. Similarly, in Figs. 3(e)-(f), ARL vs. A is plotted for the two procedures with
0.50 and several λ0 values. The robust linear dependence in our studies (across diﬀerent
λ
parameter values) suggests the following empirical relationship (as A

=

−

):

∞

∞

∞

→ ∞

ARL(τcs) = αcs ·
β
α

A + βcs,

ARL(τsr) = αsr ·

A + βsr,

(25)

{

{

∞

∞

−

•}

•}

and

0.50, each with: i) µ

depending only on the model parameters. To further understand
for some constants
the behavior of αcs and αsr as a function of the model parameters, in Figs. 4(a)-(c), we plot
= 0.50 and
estimates of these quantities as a function of λ0 in three settings where λ
= 1 and µ0 = 0.
=
= 0 and µ0 = 1, ii) µ
λ
∞
Noting that SADD is the supremum of the conditional average detection delay (ADDk), we are
= 0 = λ0 case, it is well-understood
interested in the choice of k that maximizes ADDk. In the λ
that this maximum occurs at k = 0. However, generalizing this result to the AR setting seems
diﬃcult. Thus, we pursue a numerical approach in understanding this problem. In Figs. 5(a)
and (b), we plot the behavior of ADDk as a function of k for the CUSUM chart and the SR
procedure, respectively, for diﬀerent A and λ0 values. The same trend is plotted in Figs. 5(c)-(d)
0.50 settings,
and (e)-(f) for the CUSUM chart and SR procedure in the λ
respectively. In all the cases considered, the maximum of ADDk occurs at k = 0 thus suggesting

= 1 and µ0 =

= 0.50 and λ

1, and iii) µ

= 0, λ

−

−

=

∞

∞

∞

∞

∞

∞

22

that SADD = ADD0 in the AR setting also. This fact is critical since Sec. 4 allows us to compute
ADD0(T ) = E0(T ).

Further, from these studies, we also observe that an increase in A leads to an increased ADDk
for all k, and the same threshold results in a higher ADDk for the CUSUM chart relative to the SR
procedure — both of which are not surprising conclusions. Also, note that for both procedures,
ADDk converges to a steady-state value (ADD
can be treated as the average
∞
delay in detecting a change upon repeated trials of the monitoring process. It can also be seen
from Table 1 that the SR procedure is more sensitive to the change-point than the CUSUM chart
as captured by a larger value for the metric ADD0 −
∞
decreases as A increases conﬁrming the intuition that in the large A regime (and thus large ARL
regime from (25)), ADDk is essentially independent of k.

. Further, note that ADD0 −

) quickly. ADD

ADD

ADD

∞

∞

5.2. Comparison between the CUSUM chart and SR procedure

We start with a relative performance comparison between the CUSUM chart and the SR pro-
= 0 and µ0 = 1 as a function of λ0. For this
cedure in the i.i.d. pre-change setting (λ
case, SADD corresponding to the CUSUM chart and the SR procedure are plotted as a function
of log(ARL) in Figs. 6(a)-(b), respectively. In these plots, we consider six post-change settings
with correlation parameter given as λ0 =
0.90 in addition to the i.i.d. post-change
setting (λ0 = 0).

= 0) with µ

0.01,

0.50,

±

±

±

∞

∞

−

As expected from similar studies on the i.i.d. problem (see, e.g., [5, 4, 16]), SADD for either
procedure is linear in log(ARL) in the AR framework as ARL
. Further, with either proce-
dure, the change is more easily detectable (marked by a smaller SADD value for the same ARL
value) relative to the λ0 = 0 case as λ0 increases from 0.01 to 0.50 and 0.90. On the other hand,
0.50, the change gets relatively more diﬃcult to detect. However,
as λ0 decreases to
−
with a further decrease in λ0 to

0.90, the change becomes easier to detect.

0.01 and

→ ∞

−

Reinforcing the above observation, we plot SADD as a function of λ0 for four diﬀerent ARL
values (ARL = 100, 200, 300 and 400) for the CUSUM chart and the SR procedure in Figs. 6(c)
and (d), respectively. For the CUSUM chart, we observe that SADD in the correlated case is
0.91, 0] in the ARL = 100
as large as the SADD corresponding to the λ0 = 0 case if λ0 ∈
scenario. The corresponding intervals in the ARL = 200, 300 and 400 scenarios are [
0.84, 0],
0.79, 0], respectively. The maximum value of SADD is observed in the four
0.81, 0] and [
[
−
−
scenarios at λ0 =
0.39, respectively. In the case of the SR procedure,
−
the corresponding intervals in ARL = 100, 200, 300 and 400 scenarios are λ0 ∈
0.83, 0],
0.76, 0], respectively. The maximum value of SADD
λ0 ∈
[
−

0.77, 0] and λ0 ∈
[
−

0.78, 0], λ0 ∈
[
−

0.39 and

0.39,

0.41,

[
−

[
−

−

−

−

−

23

Table 1: ADD0 and ADD

∞

for diﬀerent choices of A, λ

∞

and λ0 with the CUSUM chart and the SR procedure.

A

ADD0

CUSUM

ADD

∞

ADD0 −

SR

ADD0

= 0

ADD

∞

ADD0 −

ADD

∞

ADD
∞
λ

∞

0
λ

1 100
0
200
.
0
=
300
400
0 100
5
200
.
0
=
300
400
0 100
200
300
400

9
.
0
=

0
λ

0
λ

0
λ

0
.
0
=

5
.
0
=

1 100
200
300
400
0 100
200
300
400
0 100
200
300
400

9
.
0
=

0
λ

0
λ

0
λ

0
.
0
=

1 100
200
300
400
0 100
5
200
.
0
=
300
400
0 100
9
200
.
0
=
300
400

0
λ

0
λ

9.4794
10.8089
11.6191
12.1713
5.0596
5.4508
5.6700
5.8421
3.7302
3.8730
3.9778
4.0328

5.6261
6.1553
6.4911
6.7129
3.8513
4.0576
4.1810
4.2681
3.2341
3.3550
3.4152
3.4542

17.2517
20.1402
21.8208
22.9024
9.5787
10.9615
11.8190
12.3540
4.8245
5.1108
5.2656
5.3880

8.7804
10.1006
10.8822
11.4335
4.8889
5.2807
5.5059
5.6598
3.6574
3.8218
3.9136
3.9745

5.3293
5.8750
6.1949
6.4242
3.6362
3.8497
3.9722
4.0559
3.0222
3.1547
3.2281
3.2747

14.5254
17.2179
18.8028
19.9526
8.8826
10.2309
11.0263
11.5900
4.7586
5.0501
5.2123
5.3240

0.6990
0.7083
0.7369
0.7378
0.1707
0.1701
0.1641
0.1823
0.0728
0.0512
0.0642
0.0583

0.2968
0.2803
0.2962
0.2887
0.2151
0.2079
0.2088
0.2122
0.2119
0.2003
0.1871
0.1795

2.7263
2.9223
3.0180
2.9498
0.6961
0.7306
0.7927
0.7640
0.0659
0.0607
0.0533
0.0640

=

λ

∞

7.7031
9.0141
9.8014
10.3568
4.6441
5.0438
5.2674
5.4434
3.5688
3.7294
3.8311
3.9018
0.50
5.0340
5.5918
5.9061
6.1317
3.6449
3.8682
3.9885
4.0818
3.1334
3.2529
3.3089
3.3666

−

6.3756
7.6100
8.3579
8.8858
4.1965
4.6122
4.8460
5.0101
3.3758
3.5667
3.6697
3.7407

4.4005
4.9433
5.2635
5.4905
3.3084
3.5411
3.6696
3.7593
2.8556
3.0027
3.0838
3.1348

λ

∞

= 0.50

12.5621
15.2273
16.8002
17.9379
7.7808
9.1228
9.9153
10.5127
4.4862
4.8206
4.9900
5.1271

9.3600
11.8155
13.3295
14.4156
6.4275
7.6872
8.4447
8.9938
4.2058
4.5406
4.7238
4.8481

1.3275
1.4041
1.4435
1.4710
0.4476
0.4316
0.4214
0.4333
0.1930
0.1627
0.1614
0.1611

0.6335
0.6485
0.6426
0.6412
0.3365
0.3271
0.3189
0.3225
0.2778
0.2502
0.2251
0.2318

3.2021
3.4118
3.4707
3.5223
1.3533
1.4356
1.4706
1.5189
0.2804
0.2800
0.2662
0.2790

24

−

−

0.39,

0.36,

is observed at λ0 =
0.39 and
−
for the AR framework considered here (λ
0.6180 and λ0, crit =
λ0, upper = 0, λ0, lower ≈ −
than the λ0 = 0 case over the interval
Fig. 1(c) for I as a function of λ0). As ARL
and the worst-case correlation value converge to the theoretically expected values.

0.36, respectively. From a theoretical perspective,
−
= 0 = µ
and µ0 = 1), it can be checked that
1
3 and the KL number in the correlated case is smaller
with the minimum attained at λ0 = λ0, crit (see
, the observed interval where SADD is larger

∞
−
λ0, lower, 0

(cid:3)
→ ∞

∞

(cid:2)

∞

Further, the operating characteristics of the CUSUM chart and the SR procedure correspond-
ing to ARL values of 50, 100, 500, 1000, 5000 and 10000 (namely, the corresponding thresholds
= 0 and µ0 = 1
and SADD values) are presented in Table 2 for the pre-change i.i.d. setting with µ
for four λ0 values: 0, 0.01, 0.50 and 0.90. Also, presented in this table are the standard errors of
ARL and SADD computed according to the formula s
√n, where s is the sample standard deviation
106
and n is the number of samples. For the ARL calculations presented in Table 2, n = 2
independent runs of the procedures were used, whereas for the SADD calculations, n = 106 runs
were used.
In the λ

= 0.50 case, Figs. 7(a)-(b) plot the SADD performance of the CUSUM chart and the
SR procedure as a function of log(ARL), respectively. The KL number in the seven scenarios stud-
ied (λ0 =
0.01, 0, 0.01, 0.50 and 0.90) are 5.1925, 0.7222, 0.2526, 0.25, 0.2476, 0.50
and 12.9211, respectively. The SADD vs. log(ARL) slopes in Figs. 7(a)-(b) are in agreement
with the KL number values. Speciﬁcally, while the SADD is larger in the λ0 =
0.50 sce-
nario relative to the λ0 = 0.50 scenario for small ARL values, the larger KL number value
leads to a smaller SADD at larger ARL values. Similarly, Figs. 7(c)-(d) plot the performance
of the two procedures in the λ
0.50 case. The KL number in the seven scenarios are
0.7327, 0.50, 1.2229, 1.25, 1.2779, 5.1667 and 117.6579, respectively and the SADD vs. log(ARL)
slopes are again in agreement. Speciﬁcally, the slopes in the λ0 =
0.50 scenarios be-
have similar to the description above.

0.90 and

0.90,

0.50,

=

−

−

−

−

−

−

−

×

∞

∞

Recall that a change-point detection procedure τ from the class ∆(γ) is said to be second-order

optimal if

SADD(τ)

inf
∆(γ)
τ
∈

−

SADD(τ) =

(1), as γ

O

.

→ ∞

As noted in Sec. 2, a ﬁrst-order approximation of the performance of either procedure is given by

SADD =

log(ARL)
I

, as ARL

.

→ ∞

(26)

25

Table 2: Operating characteristics of the CUSUM and SR procedures: λ
are presented in parentheses.

∞

= 0, µ

∞

= 0, and µ0 = 1. Standard errors

Procedure

0 CUSUM
9
.
0
=

0
λ

SR

0 CUSUM

5
.
0
=
0
λ

SR

1 CUSUM

0
.
0
=

0
λ

SR

CUSUM

0
=

0
λ

SR

γ
A
ARL

SADD

A
ARL

SADD

A
ARL

SADD

A
ARL

SADD

A
ARL

SADD

A
ARL

SADD

A
ARL

SADD

A
ARL

SADD

50
5.6500
49.81
(0.04)
2.7995
(0.0015)
14.1500
49.99
(0.03)
2.9775
(0.0014)
6.5750
50.02
(0.04)
3.2926
(0.0020)
18.5000
50.12
(0.03)
3.5868
(0.0019)
9.1850
49.94
(0.05)
4.8373
(0.0031)
27.4112
49.97
(0.03)
5.3853
(0.0027)
9.2412
49.97
(0.03)
4.8471
(0.0031)
27.5500
50.00
(0.03)
5.4281
(0.0028)

1000
73.9000
999.64
(0.71)
3.6493
(0.0017)
202.2350
1000.71
(0.71)
3.7438
(0.0017)
103.2500
999.65
(0.71)
5.0794
(0.0028)
320.4500
1000.04
(0.70)
5.3144
(0.0028)
158.5061
1000.40
(0.70)
10.3655
(0.0054)
555.2155
999.95
(0.70)
10.9817
(0.0051)
159.1250
1000.07
(0.70)
10.3719
(0.0055)
559.0000
999.58
(0.70)
11.1363
(0.0051)

5000
324.4000
4999.95
(3.54)
3.9920
(0.0018)
885.9000
5000.99
(3.53)
4.0737
(0.0018)
492.7500
5000.60
(3.54)
5.9552
(0.0032)
1532.9250
4998.86
(3.53)
6.1772
(0.0032)
783.2500
4999.07
(3.53)
13.4867
(0.0065)
2776.7500
4999.74
(3.53)
14.1190
(0.0062)
788.5000
5000.90
(3.53)
13.7190
(0.0066)
2801.0000
5000.46
(3.53)
14.3394
(0.0062)

10000
618.8975
10000.31
(7.07)
4.1264
(0.0019)
1685.9350
9999.93
(7.07)
4.2039
(0.0018)
971.2000
10000.97
(7.07)
6.3127
(0.0033)
3024.18
10002.44
(7.07)
6.5323
(0.0033)
1563.1025
9999.14
(7.07)
14.8425
(0.0069)
5553.0500
9999.47
(7.06)
15.4596
(0.0066)
1573.1500
10000.96
(7.06)
15.0838
(0.0070)
5607.0050
10000.88
(7.05)
15.7182
(0.0066)

100
9.8750
100.31
(0.07)
3.0575
(0.0016)
25.8000
99.93
(0.07)
3.1811
(0.0015)
11.9000
99.65
(0.07)
3.7446
(0.0022)
35.3500
99.71
(0.07)
4.0039
(0.0021)
17.1640
99.99
(0.07)
6.0403
(0.0026)
55.0144
99.70
(0.07)
6.6115
(0.0033)
17.2500
99.92
(0.07)
6.0554
(0.0037)
55.7500
100.25
(0.07)
6.6911
(0.0033)

500
39.5000
499.58
(0.35)
3.4895
(0.0017)
107.8750
499.79
(0.35)
3.5841
(0.0017)
53.2500
500.35
(0.35)
4.6894
(0.0026)
164.1000
499.96
(0.35)
4.9385
(0.0026)
80.1035
500.19
(0.35)
9.0262
(0.0050)
278.0016
500.75
(0.35)
9.6433
(0.0046)
80.5000
499.99
(0.35)
9.1504
(0.0050)
279.0000
499.01
(0.35)
9.7689
(0.0046)

26

In Fig. 8(a), the SADD vs. log(ARL) performance of the CUSUM chart and SR procedure are
compared in three cases: λ0 = 0.01, 0.50 and 0.90. Also plotted is the ﬁrst-order approximation
from (26). Fig. 8(b) plots the performance of the CUSUM chart, SR procedure and ﬁrst-order
approximation in three cases: λ0 =
0.90. On the other hand, Figs. 8(c)-(d) and
0.50 and
−
−
= 0.50 and λ
(e)-(f) illustrate the same trends in the λ
0.50 cases, respectively. From our
studies, we observe that the CUSUM chart out-performs the SR procedure for any set of parameter
increases. Nevertheless, both
values with the gap in performance (generally) decreasing as
procedures have the same slope, which is the same as the ﬁrst-order approximation. Thus, the
constant gap between the true performance of the CUSUM chart and SR procedure in Fig. 8 and
the ﬁrst-order approximation suggests that both procedures are second-order optimal.

0.01,

λ0|

=

−

−

∞

∞

|

6. Conclusion

While change-point detection for AR processes has been extensively studied in the statisti-
cal process control literature, a systematic characterization of the performance of the CUSUM
chart as a function of the model parameters has not received signiﬁcant attention. Further still, a
comparative analysis of the CUSUM chart and a worthy competitor to it (the SR procedure) has
received even lesser attention. The focus of this work is on ﬁlling in some of these gaps in the
context of data generated by an AR(1) process that undergoes a change in the mean level and the
correlation coeﬃcient at an unknown change-point.

Extending prior results on the i.i.d. problem, we developed recipes for setting the threshold
with either procedure to achieve a certain ARL performance. We also established that the worst-
case detection delay (in the Pollak sense) is realized when the change-point is at the start of
observation. Toward understanding the SADD vs. log(ARL) performance of either procedure,
we studied the KL number between AR processes as a function of the model parameters. We
established the existence of a worst-case post-change parameter value that leads to the smallest KL
number (and hence, poorest detectability of change) and characterized its structure as a function
of other AR process model parameters.

Our numerical studies further reinforced the importance of the role played by the KL number
between the post- and pre-change processes. While our results showed that the CUSUM chart
slightly out-performs the SR procedure, both procedures are also second-order optimal with cor-
related data. Future work will consider the problem of establishing the second-order optimality of
either procedure for detecting a change in AR processes.

27

Acknowledgment

The authors greatly appreciate the help received from Distinguished Prof. Shelemyahu Zacks
of the Department of Mathematical Sciences at the State University of New York at Binghamton
who not only encouraged this work, but also diligently read the ﬁrst draft and provided valuable
feedback that helped improve the quality of the manuscript.

The eﬀort of A. S. Polunchenko was supported, in part, by the Simons Foundation via a Col-

laboration Grant in Mathematics under Award # 304574.

References

[1] Basseville M, Nikiforov IV. Detection of Abrupt Changes: Theory and Application. Prentice

Hall: Englewood Cliﬀs, 1993.

[2] Kenett RS, Zacks S. Modern Industrial Statistics: Design and Control of Quality and Relia-

bility (1st edn). Duxbury Press, 1998.

[3] Montgomery DC. Introduction to Statistical Quality Control (7th edn). Wiley, 2009.

[4] Tartakovsky AG, Moustakides GV. State-of-the-art in Bayesian changepoint detection. Se-

quential Analysis 2010; 29 :125–145.

[5] Polunchenko AS, Tartakovsky AG. State-of-the-art in sequential change-point detection.

Methodology and Computing in Applied Probability 2012; 14 :649–684.

[6] Page ES. Continuous inspection schemes. Biometrika 1954; 41 :100–115.

[7] Shiryaev AN. The problem of the most rapid detection of a disturbance in a stationary process.

Soviet Mathematics—Doklady 1961; 2 :795–799.

[8] Shiryaev AN. On optimum methods in quickest detection problems. Theory of Probability

and Its Applications 1963; 8 :22–46.

[9] Roberts S. A comparison of some control chart procedures. Technometrics 1966; 8 :411–430.

[10] Moustakides GV. Optimal stopping times for detecting changes in distributions. Annals of

Statistics 1986; 14 :1379–1387.

28

[11] Ritov Y. Decision theoretic optimality of the CUSUM procedure. Annals of Statistics 1990;

18 :1464–1469.

[12] Lorden G. Procedures for reacting to a change in distribution. Annals of Mathematical Statis-

tics 1971; 42 :1897–1908.

[13] Pollak M, Tartakovsky AG. Optimality properties of the Shiryaev-Roberts procedure. Statis-

tica Sinica 2009; 19 :1729–1739.

[14] Pollak M, Siegmund D. Approximations to the expected sample size of certain sequential

tests. Annals of Statistics 1975; 3 :1267–1282.

[15] Pollak M. Optimal detection of a change in distribution. Annals of Statistics 1985; 13 :206–

227.

[16] Tartakovsky AG, Veeravalli VV. General asymptotic Bayesian theory of quickest change

detection. Theory of Probability and Its Applications 2005; 49 :458–497.

[17] Pollak M, Siegmund D. A diﬀusion process and its applications to detecting a change in the

drift of Brownian motion. Biometrika 1985; 72 :267–280.

[18] Dragalin VP. Optimality of a generalized CUSUM procedure in quickest detection prob-
lem. In Statistics and Control of Random Processes: Proceedings of the Steklov Institute of
Mathematics, Providence, RI, 1994; 202 :107–120.

[19] Moustakides GV, Polunchenko AS, Tartakovsky AG. Numerical comparison of CUSUM
and Shiryaev–Roberts procedures for detecting changes in distributions. Communications in
Statistics – Theory and Methods 2009; 38 :3225–3239.

[20] Moustakides GV, Polunchenko AS, Tartakovsky AG. A numerical approach to performance
analysis of quickest change-point detection procedures. Statistica Sinica 2011; 21 :571–596.

[21] Goldsmith PL, Whitﬁeld H. Average run lengths in cumulative chart quality control schemes.

Technometrics 1961; 3 :11–20.

[22] Johnson RA, Bagshaw M. The eﬀect of serial correlation on the performance of CUSUM

tests. Technometrics 1974; 16 :103–112.

29

[23] Ermer DS, Chow MC, Wu SM. Time series control chart for a nuclear reactor. In Annual

Reliability and Maintainability Symposium, New York, NY, 1979 pp92–98.

[24] Steiner SH, Cook RJ, Farewell VT, Treasure T. Monitoring surgical performance using risk-

adjusted cumulative sum charts. Biostatistics 2000; 1 :441–452.

[25] Berthouex PM, Hunter WG, Pallesen L. Monitoring sewage treatment plants: Some quality

control aspects. Journal of Quality Technology 1978; 10 :139–149.

[26] Wardell DG, Moskowitz H, Plante RD. Control charts in presence of data correlation. Man-

agement Science 1992; 38 :1084–1105.

[27] Alwan LC, Roberts HV. The problem of misplaced control limits. Applied Statistics 1995;

44 :269–278.

[28] Vasilopoulos AV, Stamboulis AP. Modiﬁcation of control chart limits in the presence of data

correlation. Journal of Quality Technology 1978; 10 :20–30.

[29] Alwan LC, Roberts HV. Time-series modeling for statistical process control. Journal of Busi-

ness and Economic Statistics 1988; 6 :87–95.

[30] Montgomery DC, Mastrangelo CM. Some statistical process control methods for autocorre-

lated data. Journal of Quality Technology 1991; 23 :179–204.

[31] Lu CW, Reynolds MR. CUSUM charts for monitoring an autocorrelated process. Journal of

Quality Technology 2001; 33 :316–334.

[32] Apley DW, Tsung F. The autoregressive T 2 chart for monitoring univariate autocorrelated

processes. Journal of Quality Technology 2002; 34 :80–96.

[33] Bagshaw M, Johnson RA. The eﬀect of serial correlation on the performance of CUSUM

tests II. Technometrics 1975; 17 :73–80.

[34] Picard D. Testing and estimating change-points in time series. Advances in Applied Proba-

bility 1985; 17 :841–867.

[35] Nikiforov I. Sequential detection of changes in stochastic systems. In Detection of Abrupt
Changes in Signals and Dynamical Systems, Lecture Notes in Control and Information Sci-
ences, Berlin Heidelberg, 1986; 77 :216–258.

30

[36] Harris TJ, Ross WH. Statistical process control procedures for correlated observations. The

Canadian Journal of Chemical Engineering 1991; 69 :48–57.

[37] Maragah HD, Woodall WH. The eﬀect of autocorrelation on the retrospective X-chart. Jour-

nal of Statistical Computation and Simulation 1992; 40 :29–42.

[38] Yashchin E. Performance of CUSUM control schemes for serially correlated observations.

Technometrics 1993; 35 :37–52.

[39] Wardell DG, Moskowitz H, Plante RD. Run-length distribution of special-cause control

charts for correlated processes. Technometrics 1994; 36 :3–17.

[40] Runger GC, Wlllemain TR, Prabhu S. Average run lengths for CUSUM control charts ap-
plied to residuals. Communications in Statistics - Theory and Methods 1995; 24 :273–282.

[41] Apley DW, Shi J. The GLRT for statistical process control of autocorrelated processes. IIE

Transactions in Quality and Reliability 1999; 31 :1123–1134.

[42] Davis RA, Huang D, Yao YC. Testing for a change in the parameter values and order of an

autoregressive model. Annals of Statistics 1995; 23 :282–304.

[43] Timmer DH, Pignatiello JJ, Longnecker M. The development and evaluation of CUSUM-
based control charts for an AR(1) process. IIE Transactions in Quality and Reliability 1998;
30 :525–534.

[44] Berkes I, Gombay E, Horváth L. Testing for changes in the covariance structure of linear

processes. Journal of Statistical Planning and Inference 2009; 139 :2044–2063.

[45] Gombay E, Serban D. Monitoring parameter change in AR(p) time series models. Journal

of Multivariate Analysis 2009; 100 :715–725.

[46] Moustakides GV. Quickest detection of abrupt changes for a class of random processes.

IEEE Transactions on Information Theory 1998; 44 :1965–1968.

[47] Lai TL. Information bounds and quick detection of parameter changes in stochastic systems.

IEEE Transactions on Information Theory 1998; 44 :2917–2929.

[48] Yakir B, Krieger AM, Pollak M. Detecting a change in regression: First-order optimality.

Annals of Statistics 1999; 27 :1896–1913.

31

[49] Knoth S, Frisén M. Minimax optimality of CUSUM for an autoregressive model. Statistica

Neerlandica 2012; 66 :357–379.

[50] Polunchenko AS, Sokolov G, Du W. Quickest change-point detection: A bird’s eye view.
In Proceeding of the 2013 Joint Statistical Meetings (JSM-2013), Montrèal, Quèbec, Canada,
2013

[51] Polunchenko AS, Tartakovsky AG. On optimality of the Shiryaev–Roberts procedure for

detecting a change in distribution. Annals of Statistics 2010; 38 :3445–3457.

[52] Tartakovsky AG, Polunchenko AS. Minimax optimality of the Shiryaev–Roberts procedure.
In Proceedings of the 5th International Workshop on Applied Probability, Universidad Carlos
III of Madrid, Spain, 2010

[53] Tartakovsky AG, Pollak M, Polunchenko AS. Third-order asymptotic optimality of the gen-
eralized Shiryaev–Roberts changepoint detection procedures. Theory of Probability and Its
Applications 2012; 56 :457–484.

[54] Tartakovsky A, Ivanova I. Comparison of some sequential rules for detecting changes in

distributions. Problems of Information Tranmission 1992; 28 :117–124.

[55] Mahmoud MA, Woodall WH, Davis RE. Performance comparison of some likelihood ratio-
based statistical surveillance methods. Journal of Applied Statistics 2008; 35 :783–798.

[56] Tartakovsky AG, Polunchenko AS, Moustakides GV. Design and comparison of Shiryaev–
Roberts- and CUSUM-type change-point detection procedures. In Proceedings of the 2nd
International Workshop in Sequential Methodologies, University of Technology of Troyes,
Troyes, France, 2009

[57] Polunchenko AS, Sokolov G, Du W. An accurate method for determining the pre-change
run length distribution of the generalized Shiryaev–Roberts detection procedure. Sequential
Analysis 2014; 33 :112–134.

[58] Polunchenko AS, Sokolov G, Du W. Eﬃcient performance evaluation of the generalized
Shiryaev–Roberts detection procedure in a multi-cyclic setup. Applied Stochastic Models in
Business and Industry 2014; 30 :723–739. DOI: 10.1002/asmb.2026

[59] Lucas JM, Saccucci MS. Exponentially weighted moving average control schemes: Proper-

ties and enhancements. Technometrics 1990; 32 :1–12.

32

[60] Lai TL. Sequential changepoint detection in quality control and dynamical systems. Journal

of the Royal Statistical Society Series B Methodological 1995; 57 :613–658.

[61] Tartakovsky AG1998 Extended asymptotic optimality of certain change-point detection pro-
cedures: non-i.i.d. case. Tech. rep., University of Southern California, Department of Mathe-
matics, Center for Applied Mathematical Sciences

[62] Kullback S, Leibler RA. On information and suﬃciency. Annals of Mathematical Statistics

1951; 22 :79–86.

[63] Pollak M. Average run lengths of an optimal method of detecting a change in distribution.

Annals of Statistics 1987; 15 :749–779.

[64] Tartakovsky AG. Sequential Methods in the Theory of Information Systems. Radio & Com-

munications: Moscow, Russia, 1991.

[65] Tartakovsky AG. Asymptotic optimality of certain changepoint detection procedures: non-
iid case. In Proceedings of the 5th World Congress of the Bernoulli Society for Mathematical
Statistics and Probability and the 63rd Annual Institute of Mathematical Statistics Meeting,
Guanajuato, Mexico, 2000

[66] Hsu PL, Robbins H. Complete convergence and the law of large numbers. In Proceedings of

the National Academy of Sciences of the United States of America, 1947; 33 :25–31.

[67] Dragalin VP, Tartakovsky AG, Veeravalli VV. Multihypothesis sequential probability ratio
tests— Part I: Asymptotic optimality. IEEE Transactions on Information Theory 1999; 45
:2448–2461.

[68] Hardy GH. Divergent Series (2nd edn), vol. 334. American Mathematical Society: Provi-

dence, Rhode Island, 1991.

[69] Polunchenko AS, Sokolov G, Du W. On eﬃcient and reliable performance evaluation of the
Generalized Shiryaev–Roberts change-point detection procedure. In Proceedings of the 56-th
Moscow Institute of Physics and Technology Annual Scientiﬁc Conference, Moscow, Russia,
2013

[70] Ehrenfeld S, Littauer SB. Introduction to Statistical Method. McGraw-Hill, Inc.: New York,

NY, 1964.

33

[71] Simons G, Zacks S1967 A sequential estimation of tail probabilities in exponential distribu-

tions with a prescribed proportional closenessTech. Rep.21, Stanford University

[72] Nàdas A. An extension of a theorem of Chow and Robbins on sequential conﬁdence intervals

for the mean. Annals of Mathematical Statistics 1969; 40 :667–671.

[73] Willson LJ, Folks LJ. Sequential estimation of the mean of the negative binomial distribu-

tion. Communications in Statistics Part C: Sequential Analysis 1983; 2 :55–70.

[74] Zacks S. Sequential estimation of the mean of a log-normal distribution having a prescribed

proportional closeness. Annals of Mathematical Statistics 1966; 37 :1688–1696.

[75] Zacks S. 32. In The operating characteristics of sequential procedures in reliability, Balakr-

ishnan N, Rao CR (eds). Elsevier Science, 2001; 789–811.

[76] Atkinson K, Han W. Theoretical Numerical Analysis: A Functional Analysis Framework

(3rd edn), vol. 39. Springer, 2009.

34

10

8

6

4

2

0

-2

-4

-6

-8

)
L
K
(
g
o

l

∞ = 0 = µ
λ

∞

12

10

8

6

4

2

0

)
L
K
(
g
o

l

2 = 0.001
µ
0
2 = 0.01
µ
0
2 = 0.1
µ
0
2 = 1
µ
0
2 = 2
µ
0
2 = 3
µ
0

µ

∞ = 0

µ

µ

µ

µ

µ

µ

 = 1, λ
0
 = 2, λ
0
 = 3, λ
0
 = 1, λ
0
 = 2, λ
0
 = 3, λ
0

∞ = -0.5
∞ = -0.5
∞ = -0.5
∞ = 0.5
∞ = 0.5
∞ = 0.5

-10

-1

-0.8 -0.6 -0.4 -0.2

0
λ
0

0.2

0.4

0.6

0.8

1

-2

-1

-0.8 -0.6 -0.4 -0.2

0.2

0.4

0.6

0.8

1

0
λ
0

(a)
λ
∞ = 0

∞ = -1,  µ
µ
 = -0.5
0
∞ = -1,  µ
µ
 = 0.5
0
∞ = -0.5,  µ
µ
 = 1
0
∞ = 0.5, µ
µ
 = 1
0

0

-0.1

-0.2

-0.3

-0.4

0

λ

-0.5

-0.6

-0.7

-0.8

-0.9

-0.8 -0.6 -0.4 -0.2

0
λ
0

0.2

0.4

0.6

0.8

1

-1
-10

-8

-6

-4

-2

(b)
∞ = 0 = µ
λ

∞

λ

0,upper

λ

0,lower

λ

0,crit

2

4

6

8

10

0
µ
0

(d)

∞ = 0, µ
λ

∞ = 5

λ

0,upper

λ

0,lower

λ

0,crit

(c)
∞ = -3

∞ = 0, µ
λ

λ

0,upper

λ

0,lower

λ

0,crit

1

0.8

0.6

0.4

0.2

0

λ

0

-0.2

-0.4

-0.6

-0.8

)
L
K
(
g
o

l

10

8

6

4

2

0

-2

-4

-1

1

0.8

0.6

0.4

0.2

0

λ

0

-0.2

-0.4

-0.6

-0.8

-1
-10

-8

-6

-4

-2

0

µ
0

(e)

2

4

6

8

10

-1
-10

-8

-6

-4

-2

2

4

6

8

10

0
µ
0

(f)

Figure 1: KL number for diﬀerent sets of AR process parameters: (a) i.i.d. pre-change (λ
= 0, and (c) λ
µ
for diﬀerent values of µ

= 0. (d)-(f) λ0, upper, λ0, lower and λ0, crit as a function of µ0 in the i.i.d. pre-change setting (λ

= 0) with µ

∞

∞

∞

∞

.

= 0, (b)
= 0)

∞

∞

35

 
 
 
 
 
 
 
 
 
 
 
 
1

0.8

0.6

0.4

0.2

0

λ

0

-0.2

-0.4

-0.6

-0.8

-1
-1

 = 0.5
0

∞ = 5, µ
µ
 = 0.5
0

µ
∞ = 2.5, µ

µ
∞ = 1, µ
 = 0.5
0

λ

0,upper

λ

0,lower

λ

0,crit

-0.8 -0.6 -0.4 -0.2

0
λ
∞

(a)

0.2

0.4

0.6

0.8

1

1

0.8

0.6

0.4

0.2

0

λ

0

-0.2

-0.4

-0.6

-0.8

-1
-1

λ

0,upper

λ

0,lower

λ

0,crit

∞ = 0.5, µ
µ
 = 1
0

∞ = 0.5, µ
µ

 = 5
0

0.2

0.4

0.6

0.8

1

-0.8 -0.6 -0.4 -0.2

0
λ

∞

(b)

Figure 2: λ0, upper, λ0, lower and λ0, crit as a function of λ

∞

with diﬀerent µ

∞

and µ0 values.

36

 
 
 
 
10000

9000

8000

7000

6000

L
R
A

5000

4000

3000

2000

1000

0
0

10000

9000

8000

7000

6000

L
R
A

5000

4000

3000

2000

1000

0

0

10000

9000

8000

7000

6000

5000

4000

3000

2000

1000

L
R
A

∞ = 0 = µ
λ

∞, µ

 = 1
0

λ
 = 0.01
0
λ
 = 0.50
0
λ
 = 0.90
0
λ
 = -0.01
0
λ
 = -0.50
0
λ
 = -0.90
0

200

400

600

800
A

(a)

1000

1200

1400

1600

∞ = 0.50, µ
λ

∞ = 0, µ

 = 1
0

λ
 = 0.01
0
λ
 = 0.50
0
λ
 = 0.90
0
λ
 = -0.01
0
λ
 = -0.50
0
λ
 = -0.90
0

200

400

600

800 1000 1200 1400 1600 1800

A

(c)
∞ = -0.50,  µ
λ

∞ = 0, µ
 = 1
0

λ
 = 0.01
0
λ
 = 0.50
0
λ
 = 0.90
0
λ
 = -0.01
0
λ
 = -0.50
0
λ
 = -0.90
0

10000

L
R
A

9000

8000

7000

6000

5000

4000

3000

2000

1000

0
0

L
R
A

10000

9000

8000

7000

6000

5000

4000

3000

2000

1000

0
0

10000

9000

8000

7000

6000

5000

4000

3000

2000

1000

L
R
A

∞ = 0 = µ
λ

∞, µ
 = 1
0

λ
 = 0.01
0
λ
 = 0.50
0
λ
 = 0.90
0
λ
 = -0.01
0
λ
 = -0.50
0
λ
 = -0.90
0

1000

2000

3000

4000

5000

6000

A

(b)
∞ = 0.50, µ
λ

∞ = 0, µ

 = 1
0

i

λ
 = 0.01
0
λ
 = 0.50
0
λ
 = 0.90
0
λ
 = -0.01
0
λ
 = -0.50
0
λ
 = -0.90
0

1000

2000

3000

4000

5000

6000

7000

A

(d)
∞ = -0.50,  µ
λ

∞ = 0, µ
 = 1
0

λ
 = 0.01
0
λ
 = 0.50
0
λ
 = 0.90
0
λ
 = -0.01
0
λ
 = -0.50
0
λ
 = -0.90
0

0
0

200

400

600

800
A

(e)

1000

1200

1400

1600

0
0

1000

2000

4000

5000

6000

3000
A

(f)

Figure 3: ARL as a function of threshold A for the (a) CUSUM chart and (b) SR procedure in the i.i.d. pre-change
= 0.50 and
= 0. ARL vs. A for the CUSUM chart and SR procedure in the case where (c)-(d) λ
setting with µ
(e)-(f) λ

=

∞

∞
0.50 for diﬀerent λ0 values.
−

∞

37

 
 
 
 
 
 
 
 
 
 
 
 
•

α

25

20

15

10

5

0
-1

CUSUM, µ
CUSUM, µ
CUSUM, µ
SR, µ
SR, µ
SR, µ

∞ = 0, µ
 = 1
0
∞ = 1, µ
 = -1
0
∞ = 1, µ
 = -1
0
∞ = 0, µ
 = 1
0
∞ = 1, µ
 = -1
0
∞ = 1, µ
 = 0
0

λ
∞ = 0.50

CUSUM

SR

-0.8 -0.6 -0.4 -0.2

0
λ
0

0.2

0.4

0.6

0.8

1

(b)

CUSUM, µ
CUSUM, µ
CUSUM, µ
SR, µ
SR, µ
SR, µ

∞ = 0, µ
 = 1
0
∞ = 1, µ
 = -1
0
∞ = 1, µ
 = 0
0
∞ = 0, µ
 = 1
0
∞ = 1, µ
 = -1
0
∞ = 1, µ
 = 0
0

15

•

α

10

λ
∞ = 0

CUSUM

SR

5

0
-1

15

10

•

α

5

0
-1

-0.8 -0.6 -0.4 -0.2

0
λ
0

0.2

0.4

0.6

0.8

1

(a)
λ
∞ = -0.50

CUSUM, µ
CUSUM, µ
CUSUM, µ
SR, µ
SR, µ
SR, µ

∞ = 0, µ
 = 1
0
∞ = 1, µ
 = -1
0
∞ = 1, µ
 = 0
0
∞ = 0, µ
 = 1
0
∞ = 1, µ
 = -1
0
∞ = 1, µ
 = 0
0

SR

CUSUM

-0.8 -0.6 -0.4 -0.2

0
λ
0

0.2

0.4

0.6

0.8

1

(c)

Figure 4: Estimates of αcs and αsr as a function of λ0 under three diﬀerent settings for pre-change and post-change
means.

38

 
 
 
 
 
 
∞ = 0 = µ
λ

∞, µ
 = 1
0

λ
 = 0.01
0

A = 100
A = 200
A = 300
A = 400

λ
 = 0.50
0

k

D
D
A

12

10

8

6

4

λ
 = 0.90
0
10

20

0

30

40

50

60

70

80

90

100

k

24

22

20

18

16

14

12

10

8

6

4
0

7

6

5

4

3

k

D
D
A

k

D
D
A

(a)
∞ = 0.50, µ
λ

∞ = 0, µ
 = 1
0

λ
 = 0.01
0

A = 100
A = 200
A = 300
A = 400

λ
 = 0.50
0

λ
 = 0.90
0

20

40

k

60

80

100

(c)
∞ = -0.50,  µ
λ

∞ = 0, µ

 = 1
0

λ
 = 0.01
0

λ
 = 0.50
0

λ
 = 0.90
0

A = 100
A = 200
A = 300
A = 400

2
0

10

20

30

40

50
k

60

70

80

90

100

k

D
D
A

k

D
D
A

11

10

9

8

7

6

5

4

3
0

18

16

14

12

10

8

6

4

2
0

6.5

5.5

k

D
D
A

4.5

3.5

2.5
0

A = 100
A = 200
A = 300
A = 400

∞ = 0 = µ
λ

∞, µ
 = 1
0

λ
 = 0.01
0

λ
 = 0.50
0

λ
 = 0.90
0

40

20

k

60

80

100

(b)
∞ = 0.50, µ
λ

∞ = 0, µ
 = 1
0

λ
 = 0.01
0

A = 100
A = 200
A = 300
A = 400

λ
 = 0.50
0

λ
 = 0.90
0

10

20

30

40

50
k

60

70

80

90

100

(d)
∞ = -0.50,  µ
λ

∞ = 0, µ
 = 1
0

A = 100
A = 200
A = 300
A = 400

λ
 = 0.01
0

λ
 = 0.50
0

λ
 = 0.90
0

10

20

30

40

50
k

60

70

80

90

100

(e)

(f)

Figure 5: ADDk as a function of k in the i.i.d. pre-change setting with µ
SR procedure. ADDk vs. k for the CUSUM chart and SR procedure in the case where (c)-(d) λ
λ

= 0 for the (a) CUSUM chart and (b)
= 0.50 and (e)-(f)

0.50.

=

∞

∞

∞

−

39

 
 
 
 
 
 
 
 
 
 
 
 
25

20

15

10

5

0
2

∞ = 0 = µ
λ

∞, µ
 = 1
0

λ
 = 0
0

λ
 = -0.50
0

λ
 = -0.01
0

λ
 = 0.01
0

λ
 = -0.90
0

λ
 = 0.50
0

λ
 = 0.90
0

3

4

5

6
log(ARL)

7

8

9

10

(b)
∞ = 0 = µ
λ

∞, µ
 = 1
0

ARL = 300, CUSUM
ARL = 300, SR
ARL = 400, CUSUM
ARL = 400, SR

D
D
A
S

20

15

10

5

∞ = 0 = µ
λ

∞, µ
 = 1
0

λ
 = -0.01
0

λ
 = 0
0

λ
 = -0.50
0

λ
 = 0.01
0

D
D
A
S

λ
 = -0.90
0

λ
 = 0.50
0

λ
 = 0.90
0

2

3

4

5

6
log(ARL)

7

8

9

10

(a)
∞ = 0 = µ
λ

∞, µ
 = 1
0

ARL = 100, CUSUM
ARL = 100, SR
ARL = 200, CUSUM
ARL = 200, SR

D
D
A
S

12

10

8

6

4

D
D
A
S

10

8

6

4

2
-1

-0.8 -0.6 -0.4 -0.2

0
λ
0

(c)

0.2

0.4

0.6

0.8

1

-1

-0.8 -0.6 -0.4 -0.2

0.2

0.4

0.6

0.8

1

0
λ
0

(d)

Figure 6: Performance of (a) CUSUM chart and (b) SR procedure for the i.i.d. pre-change setting for diﬀerent values
of λ0 with µ0 = 1. (c)-(d) SADD as a function of λ0 for the CUSUM chart and SR procedure for diﬀerent ARL
values.

40

 
 
 
 
30

25

20

D
D
A
S

15

10

5

0
2

15

10

5

0
2

D
D
A
S

∞ = 0.50, µ
λ

∞ = 0, µ
 = 1
0

λ
 = 0.01
0

λ
 = 0
0

λ
 = -0.01
0

λ
 = 0.50
0

λ
 = -0.50
0

λ
 = -0.90
0

7

8

9

3

4

λ
 = 0.90
0

5
6
log(ARL)

(a)

∞ = -0.50,  µ
λ

∞ = 0, µ
 = 1
0

λ
 = -0.50
0

λ
 = -0.90
0

λ
 = 0
0

λ
 = 0.01
0

λ
 = 0.50
0

λ
 = 0.90
0

λ
 = -0.01
0

3

4

5

6

7

8

9

log(ARL)

(c)

D
D
A
S

D
D
A
S

30

25

20

15

10

5

0
2

16

14

12

10

8

6

4

2

0
2

∞ = 0.50, µ
λ

∞ = 0, µ

 = 1
0

λ
 = 0.01
0

λ
 = 0
0

λ
 = -0.01
0

λ
 = -0.90
0

3

4

5
6
log(ARL)

(b)

λ
 = 0.50
0

λ
 = -0.50
0

λ
 = 0.90
0

7

8

9

∞ = -0.50,  µ
λ

∞ = 0, µ

 = 1
0

λ
 = 0
0

λ
 = -0.90
0

λ
 = 0.01
0

λ
 = -0.50
0

λ
 = 0.50
0

λ
 = 0.90
0

λ
 = -0.01
0

3

4

5
6
log(ARL)

7

8

9

(d)

Figure 7: Performance of CUSUM chart and SR procedure (a)-(b) with λ
diﬀerent values of λ0 and µ0 = 1.

∞

= 0.50 and (c)-(d) with λ

=

−

∞

0.50 for

41

15

D
D
A
S

10

5

0
2

40

35

30

25

20

15

10

5

0
2

8

7

6

5

4

3

2

1

0
2

D
D
A
S

D
D
A
S

∞ = 0 = µ
λ

∞, µ
 = 1
0

CUSUM Chart
SR Procedure
First-Order Approximation

λ
 = 0.01
0

λ
 = 0.50
0

D
D
A
S

λ
 = 0.90
0

3

4

5
6
log(ARL)

7

8

9

(a)
∞ = 0.50, µ
λ

∞ = 0, µ
 = 1
0

CUSUM Chart
SR Procedure
First-Order Approximation

λ
 = 0.01
0

λ
 = 0.50
0

λ
 = 0.90
0

3

4

6
5
log(ARL)

7

8

9

(c)
∞ = -0.50,  µ
λ

∞ = 0, µ

 = 1
0

CUSUM Chart
SR Procedure
First-Order Approximation

λ
 = 0.01
0

λ
 = 0.50
0

λ
 = 0.90
0

3

4

5
6
log(ARL)

7

8

9

D
D
A
S

D
D
A
S

25

20

15

10

5

0

2

40

35

30

25

20

15

10

5

0
2

18

16

14

12

10

8

6

4

2

0
2

∞ = 0 = µ
λ

∞, µ

 = 1
0

CUSUM Chart
SR Procedure
First-Order Approximation

λ
 = -0.01
0

λ
 = -0.50
0

λ
 = -0.90
0

3

4

5

6

7

8

9

log(ARL)

(b)
∞ = 0.50, µ
λ

∞ = 0, µ
 = 1
0

CUSUM Chart
SR Procedure
First-Order Approximation

λ
 = -0.01
0

λ
 = -0.50
0

λ
 = -0.90
0

3

4

6
5
log(ARL)

7

8

9

(d)
∞ = -0.50,  µ
λ

∞ = 0, µ

0 = 1

CUSUM Chart
SR Procedure
First-Order Approximation

λ
 = -0.50
0

λ
 = -0.90
0

λ
 = -0.01
0

3

4

5
6
log(ARL)

7

8

9

(e)

(f)

Figure 8: CUSUM chart and SR procedure performance along with the ﬁrst-order approximation from (26) for the
= 0 for (a) select positive λ0 values and (b) select negative λ0 values. Similar plots
i.i.d. pre-change setting with µ
are provided for the case where (c)-(d) λ

= 0.50 and (e)-(f) λ

0.50.

=

∞

∞

∞

−

42

 
 
 
 
 
 
 
 
 
 
 
 
 
