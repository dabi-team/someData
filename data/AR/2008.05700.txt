Whatleadstogeneralizationofobjectproposals?RuiWang,DhruvMahajan,andVigneshRamanathanFacebookAI{ruiw,dhruvm,vigneshr}@fb.comAbstract.Objectproposalgenerationisoftentheﬁrststepinmanydetectionmodels.Itislucrativetotrainagoodproposalmodel,thatgeneralizestounseenclasses.Thiscouldhelpscalingdetectionmodelstolargernumberofclasseswithfewerannotations.Motivatedbythis,westudyhowadetectionmodeltrainedonasmallsetofsourceclassescanprovideproposalsthatgeneralizetounseenclasses.Wesystematicallystudythepropertiesofthedataset–visualdiversityandlabelspacegranularity–requiredforgoodgeneralization.Weshowthetrade-oﬀbetweenusingﬁne-grainedlabelsandcoarselabels.Weintroducetheideaofprototypicalclasses:asetofsuﬃcientandnecessaryclassesrequiredtotrainadetectionmodeltoobtaingeneralizedproposalsinamoredata-eﬃcientway.OntheOpenImagesV4dataset,weshowthatonly25%oftheclassescanbeselectedtoformsuchaprototypicalset.Theresultingproposalsfromamodeltrainedwiththeseclassesisonly4.3%worsethanusingalltheclasses,intermsofaveragerecall(AR).WealsodemonstratethatFasterR-CNNmodelleadstobettergeneralizationofproposalscomparedtoasingle-stagenetworklikeRetinaNet.Keywords:objectproposals,objectdetection,generalization1IntroductionObjectdetectionsystemshaveshownconsiderableimprovementsforfullysuper-visedsettings[27,18,20,26,3],aswellasweaklysupervisedsettings[7,1,32]thatonlyuseimage-levellabels.Bothapproachestypicallyconsiderdetectionasacombinationoftwotasks:(a)spatiallocalizationoftheobjectsusingproposalsand(b)classiﬁcationoftheproposalsintocorrectclasses.Ageneralizedpro-posalmodelthatlocalizesallclassescanhelpinscalingobjectdetection.Thiscouldleadtotheuseoffewerornoboundingboxannotationstoonlysolvetheclassiﬁcationtaskanddevelopmentofmoresophisticatedclassiﬁers,asexploredinworkslike[35,30].Manydetectionmodels[27,18]havebeendevelopedinrecentyears,whichcanbeusedtoobtainhighqualityobjectproposals.However,anequallyimportantaspectthatdeterminesthegeneralizationabilityofproposalsisthedatasetusedtotrainthesemodels.AsillustratedinFig.1,theobjectsandclasslabelsinadatasetsigniﬁcantlyimpacttheabilitytogeneralizetonewclasses.Intuitively,arXiv:2008.05700v1  [cs.CV]  13 Aug 20202R.Wangetal.bustaxitargetbargegondolatruckvansports carsource (vehicle)targetxFig.1:Proposalmodelslearnedonseenvehicleclassescanlocalizeunseenclasseswhichsharesimilarlocalizationstructurelike“bus”and“taxi”.However,“barge”and“gondola”,whicharealsovehicleswillnotbepreciselylocalizedbythismodel,duetolackofvisualdiversityinthetrainingdatasetforvehiclestolocalizeaﬁne-grainedvehicleliketaxiinatargetdataset,itmightbesuﬃcienttotrainalocalizationmodelwithothervehicleslikecarsorvansinthesourcedataset.Forlocalization(unlikeclassiﬁcation),wemaynotneedanytrainingdataforthisclass.Ontheotherhand,trainingwiththeseclasseswillnothelpinlocalizingothervehicleslikeboat.Whilefewworksleveragethisintuitionforweaklysupervisedlearning[35],theextenttowhichobjectlocalizationdependsonthecategoriesusedtotrainthemodelhasnotbeenwellquantiﬁedandstudiedindetail.Towardsthisend,wedeﬁne“generalization”astheabilityofamodeltolocalize(notclassify)objectsnotannotatedinthetrainingdataset.Inourwork,weanswerthequestion:Whatkindofdatasetisbestsuitedtotrainamodelthatgeneralizeseventounseenobjectclasses?WefurtherstudytheabilityofpopulardetectionmodelslikeFasterR-CNN[27]andRetinaNet[18]togenerateproposalsthatgeneralizetounseenclasses.Thesenetworksaredesignedtoimprovethedetectionqualityforthesmallsetofseenclassesinthetrainingdataset.Wecarefullystudythesedesignchoicesandprovideawaytoobtainproposalsthatgeneralizetoalargersetofunseenclasses.Weanswerseveralquestionsaboutdatasetpropertiesandmodelingchoicesrequiredforgeneralizedproposals:–Whatarethepropertiesofobjectclassestoensuregeneralizationofproposalsfromamodel?First,weshowthatitiscrucialtohavevi-sualdiversitytoobtaingeneralizedproposals.Weneedexamplesofdiﬀerentvehicleslike“car”and“boats”,eveniftheexamplesareonlylabelledas“vehicle”.Further,wehypothesizetheexistenceofprototypicalclassesasasubsetofleafclassesinasemantichierarchythataresuﬃcientandneces-sarytoconstructadatasettotrainamodelforproposalgeneralization.Wedeﬁnenewquantitativemetricstomeasurethesepropertiesforanysetofclassesandshowthatitispossibletoconstructasmallprototypicalsetofobjectclasses.Thishaspositiveimplicationsforlargetaxonomies,sinceitissuﬃcienttoannotateexamplesonlyfortheprototypicalclasses.–Doesthelabel-granularityofthedatasetaﬀectgeneralization?Ifso,whatisthecoarsestgranularitythatcanbeused?Coarse-grainedlabels(“vehicles”insteadof“taxis”)aresigniﬁcantlylesstedioustoanno-tateandmoreaccuratethanﬁne-grainedlabels.PastworkslikeRFCNN-3000[30]arguedthatasinglesuperclassmightbesuﬃcienttoobtaingoodWhatleadstogeneralizationofobjectproposals?3proposals.However,weshowthatthereisatrade-oﬀbetweenusingveryfewcoarseclassesandlarge-numberofﬁne-grainedclasses,andamiddle-groundapproachleadstobestgeneralization.–Whatarethemodelingchoicesthatarecriticalforleveragingstate-of-the-artdetectorstoobtaingeneralizedproposals?Weshowthat:(a)detectionsfromtwo-stagenetworkslikeFasterR-CNNarebetterforobtaininggeneralizedproposalsthanasingle-stagenetworklikeRetinaNet,(b)whileclass-speciﬁcboundingboxregressionistypicallyusedinFasterR-CNN,itisbeneﬁcialonlywhenconsideringlargernumberofproposals(aver-agerecallAR@1000)andclass-agnosticregressionisbetterwhenconsideringfewerproposals(AR@100)and(c)choiceofNMSthresholdisdependentonthenumberofproposalsbeingconsidered(AR@100orAR@1000).OnOIV4[16],weshowthatcomparedtotrainingwithalltheobjectclasses,usingaprototypicalsubsetof25%oftheobjectclassesonlyleadstoadropof4.3%inaveragerecall(AR@100),whiletrainingwith50%ofsuchclassesleadstoanegligibledropof0.9%.WealsoshowhowthedetectionsfromFasterR-CNNcanbefusedtoobtainhighqualityproposalsthathave10%absolutegaininAR@100comparedtotheclass-agnosticproposalsoftheRPNfromthesamenetworkand3.5%betterthanRetinaNet.Tostressthepracticalimpor-tanceofgeneralizedproposals,wealsoshowthatgeneralizationabilityisdirectlycorrelatedwiththeperformanceofweaklysuperviseddetectionmodels.2RelatedWorkGeneralizinglocalizationacrossmultipleclasses:Theideaofdiﬀerentobjectclassessharingthesamestructurehasbeenexploitedinbuildingdetectionmodelsforalongtime[5,22,23,29,34].Morerecently,[3,27]alsohaveadedicatedproposalnetworkforobjectlocalization.Howevertheseworksdonotmeasurethetransferabilityofproposalstrainedononesetofclassestoanother.Uijlingsetal.[35]triedtotransferinformationfromcoarsesourceclassestoﬁne-grainedtargetclassesthatsharesimilarlocalizationproperties.Theyshowedthatthiscanhelpweaklysuperviseddetectionforthetargetclasses.LSDA[11]transformedclassiﬁersintodetectorsbysharingknowledgebetweenclasses.Multipleworks[33,12,28,9]showedthebeneﬁtofsharinglocalizationinformationbetweensimilarclassestoimprovesemisupervisedandweaklysu-perviseddetection.Yangetal.[37]trainedalarge-scaledetectionmodelfollowingsimilarprinciples.Singhetal.[30]showedthatevenadetectortrainedwithoneclasscanlocalizeobjectsofdiﬀerentclassessuﬃcientlywellduetocommonal-itybetweenclasses.Wegeneralizethisideafurther.Therehasalsobeenworkonlearningmodels[37,26,6]withacombinationofboundingboxesforcertainclassesandonlyclasslabelsforothers.Theyinherentlyleveragetheideathatlocalizationcangeneralizeacrossmultipleclasses.Weprovidesystematicwaystoquantifyandmeasurethispropertyforproposalmodels.Objectproposalgenerationmodels:Therehavebeenmanyseminalworksongeneratingclass-agnosticobjectproposals[36,38,25,14].Acomprehensive4R.Wangetal.LandVehicleCarBicycleVanLimousineBicycleWheelAerialVehicleAirplaneRocketEntityVehicleAnimalMammalMarineMammalCarnivoreDolphinSealCatBirdTurkeySparrowL0L1L2L3L4(a)Labelsemantichierarchyvehiclecarsairplanevehiclelow label granularity +  high visual diversityhigh label granularity +  high visual diversitylow label granularity + low visual diversity(b)Granularityvs.DiversityFig.2:Westudytwoimportantdatasetpropertiesneededtotrainaproposalmodel:labelgranularityandvisualdiversity.(a)Labelgranularitycanberep-resentedbydiﬀerentlevelsinasemantichierarchyasshown.(b)Thediﬀerencebetweenlabelgranularityandvisualdiversityisillustrated.Atthesamegranu-larity,wecaneitherhavehighorlowvisualdiversityasshownstudyofdiﬀerentmethodscanbefoundin[13]andastudyofproposalevalu-ationmetricscanbefoundin[2].Proposalmodelshavealsobeentrainedwithdedicatedarchitecturesandobjectivesin[24,15,31].Inourwork,weleveragestandardmodelslikeFasterR-CNNandfocusonthedatasetpropertiesrequiredtoachievegeneralizationwiththismodel.3ApproachWestudytwoimportantaspectsinvolvedinobtaininggeneralizedproposalsfromadetectionmodel:(1)DataPropertiessuchasthegranularityofthelabelspace(showninFig.2a),andthevisualdiversityofobjectclassesundereachlabel,requiredforgeneralizationofproposals.TheideaoflabelgranularityandvisualdiversityisshowninFig.2b.Weinvestigatehowasmallersubsetof“prototypical”objectclassesinadatasetwhichisrepresentativeofallotherclassescanbeidentiﬁed.(2)ModelingChoiceforleveragingadetectortrainedonadatasetwithseenclassestoobtainproposalsthatgeneralizetounseenclasses.3.1DatasetPropertiesThechoiceoflabelsanddatausedtotrainthemodeliscrucialforgeneralization.Tostudytheseproperties,weassume:(a)classesareorganizedinasemantictreeand(b)internalnodesdonothaveanydataoftheirown,thatarenotcategorizedintooneofitschildnodes.Inpractice,suchahierarchyiseitheralreadyavailable(OIV4)orcanbeobtainedfromWordnet[21].Theseassumptionshelpusstudythedatasetsundercontrolledsettings.However,laterweexploreawaytoidentify“prototypical”subsetsevenwhenasemantichierarchyisunavailable.LabelSpaceGranularityAswenotedthroughsomeexamplesearlier,itisintuitivethatwemightnotneedﬁne-grainedlabelstotrainagoodlocalizationWhatleadstogeneralizationofobjectproposals?5model.Toquantitativelystudytheeﬀectofgranularity,weconstructdiﬀerentdatasetswiththesamesetofimagesandobjectboundingboxes,butconsiderclassesatdiﬀerentlevelsofsemantichierarchy(Fig.2a).Wethentrainamodelwiththesedatasetsandevaluatethegeneralizationabilityasafunctionoflabelgranularity.Forinstance,forthecoarsestrootlevel,weassignalltheboundingboxesthesame“object”labelandtrainadetectortodistinguishobjectsfromallnon-objects.Thispertainstotheideaofobjectnessusedinweaklysupervisedalgorithms[36]andsuper-classin[30].Foranintermediatelevel,wecollapseallleaf-labelstotheircorrespondingparentlabelsatthatleveltotrainthemodel.Whileaﬁne-grainedlabelspaceprovidesmoreinformation,amodeltrainedatthislevelalsoattemptstodistinguishobjectclasseswithsimilarstructureandthiscouldaﬀectgeneralization.Wequantifythistrade-oﬀinSec.4.3.PrototypicalclassestocapturevisualdiversityOneofthemainaimsofourworkistoseeifwecanidentifyasigniﬁcantlysmallernumberofclassesthanthefullobject-labelspace,sothatboundingboxesfromthissetofclassesaresuﬃcienttotrainageneralizedproposalmodel.NotethatinSec.3.1,wewantedtostudyifasmallsetofcoarselabelsaresuﬃcienttotrainageneral-izedproposalmodel.However,thisdoesnotansweranythingaboutthevisualdiversityofobjectswithineachsub-categorythatisrequiredforgeneralization.Asanexample(showninFig.2),inordertolocalizediﬀerenttypesofvehicleslike“car”or“airplane”itmightbesuﬃcienttocollapsethelabelforalltheseobjectsintoasinglelabelnamed“vehicle”,howeverdroppingallinstancesofairplaneduringtrainingwillleadtoadropinperformanceforthisclass.Toquantitativelystudythiseﬀect,weintroducethenotionof“prototypical”classes.Givenalargesetofleafclasses,thesearethesmallestsubsetsuchthatamodeltrainedonlywithinstancesfromthemissuﬃcienttolocalizeobjectsfromtheremainingclasses.Notethatduetothelong-taildistributionofreal-worlddata,obtainingimagesforlargenumberofsemanticclassesisatedioustask.Ifasmallsetofprototypicalclassesdoesexist,thismakesthedatacollectionprocessmucheasierwhenscalingdetectiontolargenumberofclasses.Properties:Weidentifythetwopropertiesthatarerequiredtoquantifytheprototypicalityofasetofclasses:Suﬃcientset:isasetofclassessuchthattrainingamodelonlywithexamplesfromthemshouldbesuﬃcienttolocalizeobjectsfromallotherclasses.Themostsuperﬂuoussuﬃcientsetwouldbetheentiresetofleafclassesthemselves.Necessaryset:isasetofclassessuchthatdroppinganyclassfromthissetwillleadtoasigniﬁcantdropingeneralization.Asimpleexamplewouldbeaverycoarseverticallike“vehicle”.Intuitivelydroppingallvehicleswouldaﬀecttheirlocalizationastheydonotsharelocalizationpropertieswithotherclasses.WeprovideconcretewaystomeasureboththesepropertiesinSec.4.3.Identifyingprototypicalclasses:GivenasetofNleafclassesC,wewishtoidentifyasetofPprototypicalclassesP⊂C.Intuitively,thisissimilartoclusteringtheclassesthathavethesamelocalizationstructureandthenchoosingarepresentativeclassfromeachcluster.Below,wediscussthreeapproaches:6R.Wangetal.(a)Oraclevisualclustering:TogetanupperboundforchoosingthebestPprototypicalclasses,weassumethatboundingboxannotationsforalltheNleafclassesareavailable.Wethenusetheseboundingboxestocomputevisualsimilaritybetweenclasses.Wenotethatthisisnotapracticalapproach,butiscrucialtoevaluatetheeﬀectivenessofproxiesweintroducelater.Weﬁrsttrainadetectionmodelusingtheannotationsofalltheleafclasses.Wethenmeasurethevisualsimilaritybetweentwoclassesi,jasSij=max(cid:18)APi(j)APj(j),APj(i)APi(i)(cid:19),(1)whereAPi(j)isthedetectionaverageprecision(AP)forthejthclasswhenweusethedetectionscorrespondingtotheithclassasdetectionsofclassj.Sijisameasureofhowwelloneclasscanreplaceanotherclassinlocalizingit.WethenusetheresultingsimilaritymeasuretohierarchicallyclustertheclassesintoPclustersusingagglomerativeclustering.Wethenpicktheclasswiththehighestnumberofexamplesineachclustertoconstructthesetofprototypicalclasses.Forpracticalreasons,weusefrequencytochoosetherepresentativeclass,sincethisresultsintheconstructionofthelargestdataset.(b)Semanticclusteringbasedonfrequency:SemanticsimilarityisoftenviewedasagoodproxyforvisualsimilarityasshownthroughdatasetslikeImagenet[4]andOIV4.Hence,weusethesemantictreetoclustertheclassesinanhierarchicalfashionstartingfromtheleaves.Atanygivenstep,weclustertogethertwoleafclassesthatshareacommonparentiftheyjointlyhavethelowestnumberofexamples.ThealgorithmstopswhenPclustersareleft.Wethenselectthemostfrequentclassfromeachclusterasaprototypicalclass.Hereweassumethataprioriweknowthefrequencyofeachclassinadataset.Thisisaveryweakassumption,sincearoughestimateofclassdistributioninadatasetcanoftenbeobtainedevenfromweaklabelslikehashtags.Thisdoesn’trequireanyimage-levellabelorboundingboxesandiseasytoimplementinpractice.(c)Mostfrequentprototypicalsubset:Forthisbaseline,wechoosethetopPmostfrequentlyoccurringclassesinthedatasetastheprototypicalclasses.Notethatunlikethepreviousapproaches,thisdoesnotrequireanyknowledgeofthesemantichierarchy.3.2ModelingChoiceOncethedatasetisﬁxed,thenextstepistotrainadetectionmodel.Inourwork,weexploretheuseoftwomodels:FasterR-CNNandRetinaNet.Theobservationsmadeinourworkshouldneverthelessgeneralizetoothertwo-stageandsingle-stagedetectionmodelsaswell.Inthecaseofasingle-stagenetwork,thedetectionsfromamodeltrainedonasourcedatasetwithseenclassescandirectlybetreatedasproposals.Theirabilitytolocalizenovelclassesinatargetdatasetcanbeevaluatedtotestgeneralization.However,foratwo-stagenetwork,anothernaturalchoicewouldbetousetheRegionProposalNetwork(RPN)ofthemodel,sinceitistrainedinaclass-agnosticfashionandaimstolocalizeallobjectsintheimage.However,asWhatleadstogeneralizationofobjectproposals?7notedbyHeetal.[10],thedetectionpartofthemodelisbetteratlocalizingtheobjectduetomoreﬁne-tunedboundingboxregressionandbetterbackgroundclassiﬁcation.Westudythismorerigorously,bycomparingthegeneralizationofproposalsobtainedfromthedetectionheadaswellasRPN.Wevarydiﬀerentmodelparameterstoobtaintheoptimalsettingforproposalgeneralization.4ExperimentsWeevaluatetheabilityoftheobjectproposalobtainedfromdetectionmodelslearnedwithdiﬀerentsettingsinSection3.2togeneralizetonewunseenclasses.Wealsoexploretheeﬀectsoflabel-spacegranularityandtheneedforsemanticandvisualdiversity.Finally,weshowthatasmallsetofprototypicalclassescouldbeusedtotrainaneﬀectiveproposalmodelforallclassesinthedataset.4.1ExperimentalSetupSourceandtargetsplits:Wespliteachdatasetintotwoparts:(a)Sourcedatasetconsistingofasetofseenclassescalledsourceclassesand(b)Targetdatasetconsistingofasetofunseenclassescalledtargetclasses.TargetdatasetisusedtoevaluatethegeneralizationofproposalmodelstrainedwiththeSourcedataset.Sinceanimagecancontainbothsourceandtargetclasses,weensurethatsuchimagesarenotpresentinthesourceclassdataset.However,theremaybeasmallnumberofimagesinthetargetdatasetthatcontainsourceclasses.Weusethefollowingtwodatasetsforourexperiments:(1)OpenImagesV4(OIV4)[16]consistsof600classes.Weretainonlyobjectclasseswhichhavemorethan100trainingimages.Thisresultsinatotalof482leafclasses.Werandomlysplitalltheleafclassesinto432source(OIV4-sourcedataset)and50target(OIV4-targetdataset)classes.Therearealsoannota-tionsassociatedonlywithinternalnodes(forexample,”animal”)andwithoutaspeciﬁcleaflabel(likethetypeofanimal).Weremovesuchannotationsandallassociatedimages,sincesuchimagescannotbeunambiguouslyassignedtoasourceortargetsplit.Thisleavesuswith1.2Mimageswith7.96Mboxesinthetrainsplitand73kimageswith361Kboxesinthetestsplit.Fortrainingproposalmodels,wealwaysusethetrainsplitandforevaluationweusethetestsplit.Whereverneeded,weexplicitlysuﬃxthedatasetwith”train”and”test”(forexample,OIV4-source-trainandOIV4-source-test).(2)COCO[19]:Weusethe2017versionoftheCOCOdatasetandrandomlysplittheclassesinto70source(COCO-sourcedataset)and10target(COCO-targetdataset)classes.Fortraining,weusethetrainsplitandforevaluation,weusethe5000imagesfromthevalidationset.Whereverneeded,weexplicitlysuﬃxthedatasetwith“train”and“test”.Targetclasseslistisprovidedinthesupplementary.Evaluationmetrics:Wereportthestandardaveragerecall(AR@k)[13]met-rictoevaluatethequalityofproposals.Oneofthemainmotivationsforbuildingageneralizedproposalmodelistousetheresultingproposalstotraindetection8R.Wangetal.modelsforunseenclasseswithlimitedornoboundingboxannotation.Atypicalproposal-basedsuperviseddetectionmodelRCNNcouldalsobeusedtoevaluatethequalityofproposals.However,theapplicationtoweaklysuperviseddetec-tionismorecompellingsincetheirperformanceiscloselytiedtoproposalsthansupervisedmodelswhichcancorrecttheinaccuraciesinproposalsduetoavail-abilityoflabelledboundingboxes.Hence,weimplementaweaklysuperviseddetectorwiththeapproachusedinYOLO9000[26]1.WereportthedetectionAP(averagedoverIoUthresholdsrangingfrom0.5to0.95)onthetestsetofthetargetdataset.Pleaseseethesupplementarymaterialformoredetails.Implementationdetails:WeﬁxImagenetpre-trainedResNet-50withFeaturePyramidNetworks[17]asthebackboneforallmodels.WeusetheDetectroncodebase[8].ForCOCO,wetrainthemodelsfor90kiterationswithaninitiallearningrateandthedecaysuggestedin[27].ForOIV4,wetrainthemodelsfor800kiterationswithaninitiallearningrateof0.01andcosinelearningratedecay.Whentrainingtheweaklysupervisedmodel([26]),weusethetop100proposalsineachimagetochoosepseudogroundtruthateverytrainingiteration.4.2ModelingChoicesWeﬁrstidentifythebestdetectionmodelandsettingtoextractproposalsthatgeneralizetonewunseenclasses.Wethenanalyzegeneralizationabilityunderdiﬀerentsettingsfromthismodel.Wereiteratethatinordertotestgeneral-ization,evaluationisdoneontargetclassesthathavenointersectionwiththesourceclassesusedduringtraining.Choiceofdetectionmodel:Wecomparethegeneralizationabilityofatwo-stagenetwork(FasterR-CNN)andasingle-stagenetwork(RetinaNet)inFig.3a.Since,inatwo-stagemodellikeFasterR-CNN,theoutputfromtheRPNisclass-agnosticandcanbeusedasproposalstoo,wecomparetheperformanceoftheRPNaswell.ThemodelsaretrainedonCOCO-source-traindataset.WereportAR@100onseenclassesintheCOCO-source-testdataset,aswellasunseenclassesintheCOCO-target-test.Thediﬀerenceinperformancebetweenseenandunseenclassesreﬂectsthegeneralizationgap.Wealsoshowanupper-boundperformanceonCOCO-target-testobtainedbymodelstrainedonthefulltrainingdatasetcontainingbothCOCO-source-trainandCOCO-target-train.Wenoticethatonseenclasses,RetinaNetachievesalowerperformancecom-paredtoFasterR-CNN(dropof2.4%).However,thedropislargerforunseentargetclasses(3.5%),indicatingalargergeneralizationgapforRetinaNet.OnereasonforthisisthatRetinaNetismoresensitivetomissingboundingboxescorrespondingtounlabelledunseenclassesinthesourcedataset.Proposalscor-respondingtounseenobjectclassesthatarenotannotatedinthetrainingdataaretreatedashard-negatives,duetotheuseoffocal-loss.Hence,themodelheavilypenalizesproposalscorrespondingtounannotatedboundingboxes,lead-ingtooveralldropinAR.Sincesomeseenclassessharevisualsimilaritywith1Wechose[26]duetoitssimplicity.Inpractice,wecanuseotherweaklysupervisedapproachestoo.Whatleadstogeneralizationofobjectproposals?9COCO-source-testCOCO-target-test203040506070AR@10046.731.555.741.558.144.0RPN vs. RetinaNet vs. Faster R-CNNFaster R-CNN upper boundRetinaNet upper boundFaster R-CNNRetinaNetRPN(a)Comparisonofdetectionmodels0.50.60.70.80.9IoU Thresholds0102030405060708090Average RecallCOCO AR at Different IoU ThresholdsDetection-AR@1000RPN-AR@1000Detection-AR@100RPN-AR@100(b)RPNvs.detectionheadFig.3:(a)AR@100correspondingtodiﬀerentmodelstrainedonCOCO-source-trainandevaluatedondiﬀerenttestsplits.Upper-boundcorrespondstomodeltrainedonfullCOCOdatasetandevaluatedonCOCO-target-test.(b)AveragerecallofRPNanddetectionheadatdiﬀerentIoUthresholds,formodeltrainedonCOCO-source-trainandevaluatedonCOCO-target-testunseenclasses,thissensitivitytomissingannotationsaﬀectsARforseenclassestoo.However,thiseﬀectismoremagniﬁedforunseentargetclasses.Ontheotherhand,inFasterR-CNN,onlyasmallnumberofproposals(lessthan512)whichdonotintersectwithannotatedboundingboxesaresampledatrandomasnegatives.Theprobabilitythataproposalcorrespondingtoanunseenobjectclassischosenasanegativeislower,leadingtobettergeneralization.Hence,fortherestofthepaper,weuseFasterR-CNNasthedetectionmodel.WealsonoticethatthedetectionheadofFasterR-CNNprovidesbetteroverallperformancewithoutsacriﬁcinggeneralization.Thiscanbeattributedtobetterboundingboxregressionfromthedetectionheadwhichhasadditionallayers,followingtheRPNinthemodel.Toinvestigatethiseﬀect,wemeasureARatdiﬀerentIoUthresholdsforbothsetsofproposalsforthemodeltrainedonCOCO-sourceandevaluatedonCOCO-targetinFig.3b.WeseethatthediﬀerenceinAR@1000increasesdrasticallyathighervaluesofIoUthreshold,andisnegligibleatathresholdof0.5.Thisimpliesthattheboxesfromthedetectionheadaremoreﬁne-tunedtoexactlylocalizeobjects,unliketheRPN.ChoiceofFasterR-CNNsettings:Theresultssofarwereobtainedusingclass-speciﬁcboundingboxregression(whichisthestandardsettinginFasterR-CNN)forthedetectionhead.Sincewewanttheboundingboxestogeneralizetounseenclasses,classagnosticregressioncouldbeavalidchoicetoo.WestudythisinFig.4forOIV4andCOCO.WeseethatclassagnosticregressionisbetterforsmallnumberofproposalsasseenbyAR@10,20,50.However,whenweconsidermoreproposals(AR@1000),classspeciﬁcregressionprovidesasigniﬁcantgain(4.5%forOIV4and7.5%forCOCO).Itresultsinmultipleregressedversions(onecorrespondingtoeachclass)ofthesameproposalgeneratedfromtheRPN.Thishelpsinimprovingrecallathighernumberofproposals.10R.Wangetal.1020501001000Number of Proposals0.00.10.20.30.40.50.60.70.8Average RecallClass-specific VS. Class-agnosticOIV4-class-specificOIV4-class-agnosticCOCO-class-specificCOCO-class-agnosticFig.4:Eﬀectofclassagnosticregres-sionvs.classspeciﬁcregression0.10.20.30.40.50.60.70.80.91.0NMS Threshold0.20.30.40.50.60.70.8Average RecallEffect of NMS threshold on proposalsOIV4-AR@1000OIV4-AR@100COCO-AR@1000COCO-AR@100Fig.5:EﬀectofNMSthresholdonperformanceofproposalsPreviously,weﬁxedtheNMSthresholdto0.5.WestudytheeﬀectofthisthresholdinFig.5.WetrainonOIV4-source,COCO-sourceandtestonOIV4-target,COCO-targetrespectively.Intuitively,alowthresholdcanimprovespa-tialcoverageofobjectsbyensuringproposalsarespatiallywellspreadout.Whenconsideringalargernumberofproposals,therearesuﬃcientboxestoensurespa-tialcoverage,andhavingsomeredundancyishelpful.ThisiswitnessedbythesteeperdropinAR@1000atlowNMSthresholds,unlikeAR@100.Basedontheseobservations,weuseclass-speciﬁcboundingboxregressionwithanNMSthresholdof0.5forrestoftheexperiments.Table1:ComparingperformanceofproposalsgeneratedbyRPNheadanddetec-tionheadforweaklysuperviseddetection.WealsoshowtheAR@100numberswhichareseentobecorrelatedwithdetectionAPTargetDataset-OIV4-targetSource:OIV4-sourceSource:OIV4-allDet.APAR@100Det.APAR@100FasterR-CNNRPN8.755.09.660.4FasterR-CNNDetection24.069.430.876.9Weaklysuperviseddetection:Astrongpracticalutilityforgeneralizedpro-posalsthatlocalizeallobjectsisthat,noboundingboxannotationsshouldbeneededtotrainadetectionmodelfornewobjectclasses.Hence,wemeasuretheeﬀectofbettergeneralizedproposalsontheperformanceofaweaklysuperviseddetectionmodel,trainedwithoutboundingboxannotations.WeshowresultscorrespondingtotheRPNheadanddetectionheadofFasterR-CNNinTab.1.TheweaklysupervisedmodelistrainedonOIV4-target-trainandevaluatedonOIV4-target-test.WealsoshowresultsforproposalsobtainedfromtrainingwithOIV4-sourceaswellasOIV4-all(upper-bound).Weseethattheperformanceoftheweaklysuperviseddetectionmodelisdirectlycorrelatedwiththequalityoftheproposalsbeingused,showingtheneedforgoodgeneralizedproposals.Whatleadstogeneralizationofobjectproposals?114.3DatasetPropertiesEﬀectoflabelspacegranularity:OIV4organizesobjectclassesinasemantichierarchywith5levels.Wedirectlyleveragethishierarchytomeasuretheeﬀectoflabelgranularity(Fig.2a).WeconstructadatasetateachlevelLi(OIV4-source-Li)byretainingalltheimagesinOIV4-source,butrelabelingboundingboxescorrespondingtoleaflabelswiththeirancestoratLi.Weconstruct5datasets,oneforeachlevelwiththesamesetofimagesandboundingboxes.WereporttheperformanceofthesemodelsonOIV4-targetinTab.2.AlongwithAR@100/1000,wealsoreportthedetectionAPoftheweaklysuperviseddetectionmodelstrainedwiththeproposalsobtainedfromthecorrespondinglevels.TheweaklysupervisedmodelsaretrainedonOIV4-target-trainandeval-uatedonOIV4-target-test.Table2:EﬀectofdiﬀerentlabelspacegranularitiesonthequalityofproposalforOIV4dataset.Thenumberofclassesateachlevelisshowninbrackets.EvaluationisdoneonOIV4-target-evaldataset.BothARandweaklysuperviseddetectionAParereportedSourceDatasetAR@100AR@1000AP(weak)OIV4-source-L0(1)61.772.019.5OIV4-source-L1(86)63.473.022.6OIV4-source-L2(270)63.775.223.1OIV4-source-L3(398)65.277.224.3OIV4-source-L4(432)64.276.124.0Somepastworkslike[30]postulatedthatonesuper-class(similartoL0)couldbesuﬃcient.However,weobservethatbothAR@100andAR@1000increaseaswemovefromL0toL1alongwithasigniﬁcantgain(3.1%)inAP.ThisindicatesthattrainingwithjustabinarylabelyieldslowerqualityproposalscomparedtotrainingwithatleastacoarsesetoflabelsatL1.WhilebothAPandAR@100increaseasthegranularityincreasesfromL1toL3,thediﬀerenceisfairlysmallforbothmetrics(<2%change).However,annotatingboundingboxeswithlabelsatL1(86labels)issigniﬁcantlycheaperthanL3(398labels).Hence,L1canbeseenasagoodtrade-oﬀintermsoflabellingcost,andtrainingagoodmodel.Needforvisualandsemanticdiversity:Wenoticedthattrainingwithcoarselabelscanyieldgoodproposals.Itwouldbeinterestingtoobserveifalloronlysomeofthesecoarseclassesarecrucialtobuildagoodproposalmodel.Tostudythis,weconductablationexperimentswherewetrainamodelwithOIV4-source-trainafterdroppingallimageshavingaspeciﬁcL1labelandevaluatetheproposalsontheOIV4-source-testimagesbelongingtothislabelinFig.6a.Werepeatthisexperimentforafewﬁne-grainedclassesatL4inFig.6b.Wenoticethatcertaincoarseclasses(like“clothing”and“vehicle”)expe-rienceahugedropinperformance.Ontheotherhand,“animal”and“food”arelessaﬀected.Thiscanbeexplainedfromthefactthat,therearemanytoy-animalimageswithinthecoarselabel“toy”,similarly“containers”isacoarseclassinOIV4whichisoftendepictedwithfoodinit.Theseclassescanactas12R.Wangetal.Animal(L1)Food(L1)Clothing(L1)Vehicle(L1)0.40.50.60.70.80.9AR@10000.8080.8110.5950.7510.7820.7870.5060.646(a) Effect of Dropping L1 Classesbefore droppingafter droppingAmbulance(L4)Taxi(L4)Airplane(L4)Helicopter(L4)0.8000.8250.8500.8750.9000.9250.9500.9751.000AR@10000.9520.9260.9110.9250.9460.9050.8360.888(b) Effect of Dropping L4 Classesbefore droppingafter droppingFig.6:EﬀectofSemanticDiversity,measuredbydroppinganobjectclassduringtrainingandmeasuringtheresultingchangeinARforthatclass:(a)droppingL1classesand(b)droppingL4classesproxiesfor“animal”and“food”respectively.However,“clothing”and“vehicle”donothavegoodproxies.Moreinterestingly,wemakeasimilarobservationforﬁnerclassesatL4likeairplanesandhelicopters.ThissuggeststhatthereisasmallersetofobjectsthathaveuniquelocalizationpropertiesinOIV4.Prototypicalclasses:Someobjectclassesaresimilartoothersintermsoflocalization,whilethereareclassesthatareuniqueandneedtobeincludedintraining.Motivatedbythisobservation,wetrytoidentifyasmallsetofclassescalled“prototypical”classeswhicharebothnecessaryandsuﬃcienttotrainageneralizableproposalmodel.WeusetheOIV4-sourcedatasetasbeforewith432leafclasses.WeusethediﬀerentapproachesoutlinedinSec.3.1toidentifyasubsetof“prototypical”classes.Notethatamongthesemethods,oraclevisualclusteringassumesavail-abilityofboundingboxesforallclassesandservesasanupperboundonhowtoidentifyareallygoodprototypicalset.SomesampleclustersofclassesobtainedbythismethodareshowninTab.3.Theremainingmethodsmakeweakeras-sumptionsandaremoreusefulinpractice.Inadditiontothesemethods,wealsotrainmodelswithasetofrandomlychosenprototypicalclasses.Table3:SampleclustersobtainedbyoraclevisualclusteringforP=50.ThemostfrequentclassineachclusterchosenasaprototypicalclassishighlightedWoman,Girl,DollWheel,Tire,BicyclewheelLobster,Scorpion,CentipedeGlasses,GogglesJeans,Shorts,MiniskirtGoose,Ostrich,TurkeyBook,Shelf,BookcaseMusicalkeyboard,PianoSwimmingpool,Bathtub,JacuzziMan,Boy,ShirtApple,Pomegranate,PeachRaven,Woodpecker,BluejayWeintroducetwowaystomeasuresuﬃciencyandnecessity.Fromthe432classes,oncewepickasubsetofPprototypicalclasses,wetrainaproposalmodelandevaluatetheresultingmodelonthe50targetclassesinOIV4-target,tomeasuresuﬃciencyandnecessity.DatasetconstructionforfaircomparisonWeensurethatthetotalnumberofimagesaswellasboundingboxannotationsarekeptﬁxedwhenweconstructdatasetsfordiﬀerentprototypicalsubsets.Thisisimportanttoensurethatpro-Whatleadstogeneralizationofobjectproposals?13posalstrainedwithdiﬀerentsubsetsarecomparable.OncewechoseasetofPprototypicalclasses,weuniformlysub-sampleOIV4-sourceimageshavinganyoftheseprototypicalclassestogetasubsetof920Kimages.Andwithineachsubset,weuniformlysub-sampletheboundingboxescorrespondingtothepro-totypicalclassestoretain5.2Mboundingboxes.Wedonotretainanyboundingboxesoutsidethechosenprototypicalclasses.TrainingwithprototypicalsubsetsForasetofprototypicalclassesandthecorrespondingdataset,wetrainaFasterR-CNNwiththoseclassesaslabels.WecombinethedetectionsasdescribedinSec.3.2toobtainproposals.MeasuringsuﬃciencyofprototypicalclassesAsubsetofclassesaresuﬃ-cient,ifaproposalmodeltrainedwiththemgeneralizesaswellasamodeltrainedwithallclasses.WefollowthisnotionandevaluatetheproposalsobtainedfromthemodelstrainedwithdiﬀerentprototypicalsubsetsonOIV4-targetandre-porttheaveragerecall(AR@100)inFig.7a.SimilartrendsareobservedwithAR@1000aswell(showninsupplementary).Lookingattheproposalsobtainedfromoraclevisualclustering,trainingwithlessthan25%oftheclasses(100)leadstoonlyadropof4.8%inAR@100,com-paredtotrainingwithimagesbelongingtoallobjectclasses.Thisgapreducesto0.4%ifwetrainwith50%(200)ofalltheclasses.Thisprovidesanempiricalprooffortheexistenceofasigniﬁcantlysmallernumberofobjectclassesthataresuﬃcienttotrainageneralizableproposalmodel.Next,welookattheprototypicalclassesobtainedfromamorepracticalapproach:semanticclustering.Wenoticethattheproposalmodeltrainedwiththeseprototypicalclassesalwaysoutperformotherapproachessuchaschoosingarandomsetofclassesorthemostfrequentsetofclasses.Further,theperfor-manceofthismethodisonlylowerbyamarginof3%comparedtooraclevisualclusteringfordiﬀerentvalueofP.Selectingmostfrequentsetofclassesastheprototypicalsubsetperformsslightlyworsethansemanticclustering.Thisshowsthatsemanticclusteringcanserveasagoodwaytoidentifyprototypicalclassesforlargetaxonomieswhenthesemantichierarchyisavailableforthedataset,elsethemostfrequentsubsetisaweakeralternative.MeasuringnecessityofprototypicalclassesAsetofclassesareconsiderednecessary,ifthereisnoredundancyamongtheclassesintermsoflocalizationproperties.Foragivenclassintheset,thereshouldbenoequivalentclasswhichcanprovidesimilarboundingboxes.WemeasurethispropertyforaprototypicalsubsetbyevaluatingthecorrespondingproposalmodelonOIV4-targetdatasetusingthefollowingmethod.ForeverytargetclassinOIV4-target,wemeasuretherelativechangeinAR@100andAR@1000byremovingproposalscorrespond-ingtothemostsimilarclassintheprototypicalsubset(similaritymeasuredbyEq.1).ThechangeinARwouldbeminimalifthereisanotherclassinthepro-totypicalsubsetwhichcanlocalizethetargetclass.Thismeasure,averagedoveralltargetclassesprovidesagoodestimateofnecessity.Ahighvaluesymbolizesahighdegreeofnecessity,whilealowvaluecorrespondstoredundancyamongtheprototypicalclasses.WeplotthisfordiﬀerentnumberofprototypicalclassesfororaclevisualclusteringandsemanticclusteringinFig.7b.14R.Wangetal.50100200300432P0.500.550.600.650.700.750.800.85AR@100(a) Sufficiency of the Prototypical ClassesRandomMost frequentSemantic clusteringVisual clusteringOIV4-43250100200300P0246810Relative % drop in AR7.97%6.71%6.05%5.27%2.23%1.39%1.14%0.97%6.96%5.50%4.05%3.98%2.19%1.02%0.98%0.81%(b) Necessity of the Prototypical ClassesVisual-AR@100Semantic-AR@100Visual-AR@1000Semantic-AR@1000Fig.7:(a)AveragerecallAR@100forproposalsobtainedfrommodelstrainedwithvaryingnumberofprototypicalclasseschosenbydiﬀerentmethods.WeshowtheaveragerecallontheOIV4-targetdatasetwith50unseenclasses.Pdenotesthenumberofprototypicalclasses.Highervalueindicateshighersuﬃ-ciency.(b)TherelativechangeinARfortargetclassesbydroppingproposalscorrespondingtothemostsimilarclassintheprototypicalsubset.HighervalueindicateslowerredundancyinprototypicalsubsetandhighernecessityWenoticethatatanygivennumberofprototypicalclasses,thechangeinav-eragerecallishigherfororaclevisualclusteringcomparedtosemanticclustering.Thisdemonstratesthatvisualclusteringleadstoprototypicalclasseswhicharelessredundant(andmorenecessary).Asexpected,weseethenecessitydrops,asweincreasethenumberofprototypicalclassesforbothmethods.Again,thisisexpectedsinceredundancybetweenclassesincreaseswithmorenumberofclasses.TherelativechangeinAR@1000isalsoseentobelowerthanAR@100,sincewhenconsideringalargernumberofproposals,weexpectmoreredundancyamongtheproposals.Finally,fororaclevisualclusteringaswemovefrom200to300classes,suﬃciencychangesbyasmallamountfrom73.2to75.9(Fig.7a),whilethenecessitydropssteeplyinFig.7b.ThissuggeststhattheidealnumberofprototypicalclassesforOIV4couldbearound200.5ConclusionWestudiedtheabilityofdetectionmodelstrainedonasetofseenclassestolocalizeunseenclasses.WeshowedthatFasterR-CNNcanbeusedtoobtainbetterproposalsforunseenclassesthanRetinaNet,andstudiedtheeﬀectofmodelchoicesongeneralizationofproposals,likeclass-agnosticboundingboxregressionandNMSthreshold.Wequantitativelymeasuredtheimportanceofvisualdiversityandshowedthatusingaveryﬁne-grainedorverycoarselabel-spacecanbothaﬀectgeneralization,whileamiddle-groundapproachisbestsuited.Weintroducedtheideaofprototypicalclassesthataresuﬃcientandnecessarytoobtaingeneralizedproposals.Wedemonstrateddiﬀerentapproachestodeterminesmallprototypicalsubsetsforagivendataset.Webelievethatourworkisastepforwardtowardslearningproposalsthatgeneralizetoalargenumberofclassesandscalingupdetectioninamoredata-eﬃcientway.Whatleadstogeneralizationofobjectproposals?15References1.Arun,A.,Jawahar,C.,Kumar,M.P.:DissimilarityCoeﬃcientbasedWeaklySu-pervisedObjectDetection.In:CVPR(2019)2.Chavali,N.,Agrawal,H.,Mahendru,A.,Batra,D.:Object-proposalevaluationprotocolis’gameable’.In:CVPR(2016)3.Dai,J.,Li,Y.,He,K.,Sun,J.:R-FCN:ObjectDetectionviaRegion-basedFullyConvolutionalNetworks.In:NeurIPS(2016)4.Deng,J.,Dong,W.,Socher,R.,Li,L.J.,Li,K.,Fei-Fei,L.:Imagenet:Alarge-scalehierarchicalimagedatabase.In:CVPR(2009)5.Felzenszwalb,P.F.,Girshick,R.B.,McAllester,D.,Ramanan,D.:Objectdetectionwithdiscriminativelytrainedpart-basedmodels.IEEETransactionsonPatternAnalysisandMachineIntelligence(2009)6.Gao,J.,Wang,J.,Dai,S.,Li,L.J.,Nevatia,R.:NOTE-RCNN:noisetolerantensembleRCNNforsemi-supervisedobjectdetection.In:ICCV(2019)7.Gao,Y.,Liu,B.,Guo,N.,Ye,X.,Wan,F.,You,H.,Fan,D.:C-MIDN:CoupledMultipleInstanceDetectionNetworkWithSegmentationGuidanceforWeaklySupervisedObjectDetection.In:ICCV(2019)8.Girshick,R.,Radosavovic,I.,Gkioxari,G.,Doll´ar,P.,He,K.:Detectron(2018)9.Guillaumin,M.,Ferrari,V.:Large-scaleknowledgetransferforobjectlocalizationinimagenet.In:CVPR(2012)10.He,K.,Gkioxari,G.,Doll´ar,P.,Girshick,R.:MaskR-CNN.In:ICCV(2017)11.Hoﬀman,J.,Guadarrama,S.,Tzeng,E.S.,Hu,R.,Donahue,J.,Girshick,R.,Dar-rell,T.,Saenko,K.:LSDA:Largescaledetectionthroughadaptation.In:NeurIPS(2014)12.Hoﬀman,J.,Pathak,D.,Tzeng,E.,Long,J.,Guadarrama,S.,Darrell,T.,Saenko,K.:Largescalevisualrecognitionthroughadaptationusingjointrepresentationandmultipleinstancelearning.TheJournalofMachineLearningResearch(2016)13.Hosang,J.,Benenson,R.,Doll´ar,P.,Schiele,B.:Whatmakesforeﬀectivedetectionproposals?IEEETransactionsonPatternAnalysisandMachineIntelligence(2015)14.Kr¨ahenb¨uhl,P.,Koltun,V.:Geodesicobjectproposals.In:ECCV(2014)15.Kuo,W.,Hariharan,B.,Malik,J.:Deepbox:Learningobjectnesswithconvolu-tionalnetworks.In:ICCV(2015)16.Kuznetsova,A.,Rom,H.,Alldrin,N.,Uijlings,J.,Krasin,I.,Pont-Tuset,J.,Ka-mali,S.,Popov,S.,Malloci,M.,Duerig,T.,etal.:Theopenimagesdatasetv4:Uniﬁedimageclassiﬁcation,objectdetection,andvisualrelationshipdetectionatscale.arXivpreprintarXiv:1811.00982(2018)17.Lin,T.Y.,Doll´ar,P.,Girshick,R.,He,K.,Hariharan,B.,Belongie,S.:FeaturePyramidNetworksforObjectDetection.In:CVPR(2017)18.Lin,T.Y.,Goyal,P.,Girshick,R.,He,K.,Doll´ar,P.:FocalLossforDenseObjectDetection.In:ICCV(2017)19.Lin,T.Y.,Maire,M.,Belongie,S.,Hays,J.,Perona,P.,Ramanan,D.,Doll´ar,P.,Zitnick,C.L.:Microsoftcoco:Commonobjectsincontext.In:ECCV(2014)20.Liu,W.,Anguelov,D.,Erhan,D.,Szegedy,C.,Reed,S.,Fu,C.Y.,Berg,A.C.:SSD:Singleshotmultiboxdetector.In:ECCV(2016)21.Miller,G.A.:WordNet:ALexicalDatabaseforEnglish.Commun.ACM(1995)22.Novotny,D.,Larlus,D.,Vedaldi,A.:Ihaveseenenough:Transferringpartsacrosscategories.In:BMVC(2016)23.Ott,P.,Everingham,M.:Sharedpartsfordeformablepart-basedmodels.In:CVPR(2011)16R.Wangetal.24.Pinheiro,P.O.,Collobert,R.,Doll´ar,P.:Learningtosegmentobjectcandidates.In:NeurIPS(2015)25.Pont-Tuset,J.,Arbelaez,P.,Barron,J.T.,Marques,F.,Malik,J.:Multiscalecom-binatorialgroupingforimagesegmentationandobjectproposalgeneration.IEEETransactionsonPatternAnalysisandMachineIntelligence(2016)26.Redmon,J.,Farhadi,A.:YOLO9000:better,faster,stronger.In:CVPR(2017)27.Ren,S.,He,K.,Girshick,R.,Sun,J.:FasterR-CNN:TowardsReal-TimeObjectDetectionwithRegionProposalNetworks.In:NeurIPS(2015)28.Rochan,M.,Wang,Y.:Weaklysupervisedlocalizationofnovelobjectsusingap-pearancetransfer.In:CVPR(2015)29.Salakhutdinov,R.,Torralba,A.,Tenenbaum,J.:Learningtosharevisualappear-anceformulticlassobjectdetection.In:CVPR(2011)30.Singh,B.,Li,H.,Sharma,A.,Davis,L.S.:R-FCN-3000at30fps:DecouplingDe-tectionandClassiﬁcation.In:CVPR(2018)31.Szegedy,C.,Reed,S.,Erhan,D.,Anguelov,D.,Ioﬀe,S.:Scalable,high-qualityobjectdetection.arXivpreprintarXiv:1412.1441(2014)32.Tang,P.,Wang,X.,Bai,S.,Shen,W.,Bai,X.,Liu,W.,Yuille,A.L.:PCL:ProposalClusterLearningforWeaklySupervisedObjectDetection.IEEETransactionsonPatternAnalysisandMachineIntelligence(2018)33.Tang,Y.,Wang,J.,Gao,B.,Dellandr´ea,E.,Gaizauskas,R.,Chen,L.:Largescalesemi-supervisedobjectdetectionusingvisualandsemanticknowledgetransfer.In:CVPR(2016)34.Torralba,A.,Murphy,K.P.,Freeman,W.T.,etal.:Sharingfeatures:eﬃcientboost-ingproceduresformulticlassobjectdetection.In:CVPR(2004)35.Uijlings,J.,Popov,S.,Ferrari,V.:Revisitingknowledgetransferfortrainingobjectclassdetectors.In:CVPR(2018)36.Uijlings,J.R.,VanDeSande,K.E.,Gevers,T.,Smeulders,A.W.:Selectivesearchforobjectrecognition.InternationalJournalofComputerVision(2013)37.Yang,H.,Wu,H.,Chen,H.:Detecting11KClasses:LargeScaleObjectDetectionwithoutFine-GrainedBoundingBoxes.arXivpreprintarXiv:1908.05217(2019)38.Zitnick,C.L.,Doll´ar,P.:Edgeboxes:Locatingobjectproposalsfromedges.In:ECCV(2014)(Supplementary)Whatleadstogeneralizationofobjectproposals?RuiWang,DhruvMahajan,andVigneshRamanathanFacebookAI{ruiw,dhruvm,vigneshr}@fb.com1ListofOIV4classesOIV4-Target50:Book,Bookcase,Bull,Cabbage,Camera,Centipede,Coat,Coﬀeecup,Computerkeyboard,Desk,Dog,Doughnut,Egg,Falcon,Flower-pot,Fork,Goldﬁsh,Hippopotamus,Hotdog,House,Juice,Kitchenknife,Knife,Lavender,Missile,Mobilephone,Motorcycle,Mug,Orange,Palmtree,Penguin,Piano,Pictureframe,Porch,Rabbit,Refrigerator,Remotecontrol,Riﬂe,Sea-horse,Skateboard,Strawberry,Sunglasses,Swimmingpool,Sword,Tap,Tripod,Truck,Washingmachine,Wineglass,ZebraOIV4-Source432:Accordion,Adhesivetape,Airplane,Alarmclock,Alpaca,Ambulance,Ant,Antelope,Apple,Artichoke,Asparagus,Axe,Backpack,Bagel,Balancebeam,Balloon,Banana,Banjo,Barge,Barrel,Baseballbat,Baseballglove,Bat,Bathroomcabinet,Bathtub,Beaker,Bee,Beehive,Beer,Bellpepper,Belt,Bench,Bicycle,Bicyclehelmet,Bicyclewheel,Bidet,Billboard,Billiardta-ble,Binoculars,Blender,Bluejay,Boot,Bottle,Bowandarrow,Bowl,Bowlingequipment,Box,Boy,Brassiere,Bread,Briefcase,Broccoli,Bronzesculpture,Brownbear,Burrito,Bus,Bust,Butterﬂy,Cabinetry,Cake,Cakestand,Cal-culator,Camel,Canary,Candle,Candy,Cannon,Canoe,Cantaloupe,Carrot,Cart,Castle,Cat,Catfurniture,Caterpillar,Cattle,Ceilingfan,Cello,Chain-saw,Chair,Cheese,Cheetah,Chestofdrawers,Chicken,Chopsticks,Christ-mastree,Closet,Cocktail,Coconut,Coﬀee,Coﬀeetable,Coﬀeemaker,Coin,Commonﬁg,Computermonitor,Computermouse,Conveniencestore,Cookie,Cordedphone,Countertop,Cowboyhat,Crab,Cream,Cricketball,Crocodile,Croissant,Crown,Crutch,Cucumber,Cupboard,Curtain,Cuttingboard,Dag-ger,Deer,Diaper,Dice,Digitalclock,Dinosaur,Dogbed,Doll,Dolphin,Door,Doorhandle,Dragonﬂy,Drawer,Dress,Drill,Drinkingstraw,Drum,Duck,Dumbbell,Eagle,Earrings,Elephant,Envelope,Fedora,Filingcabinet,Firehy-drant,Fireplace,Flag,Flute,Flyingdisc,Foodprocessor,Football,Footballhel-met,Fountain,Fox,Frenchfries,Frog,Fryingpan,Gasstove,Giraﬀe,Girl,Glasses,Glove,Goat,Goggles,Golfball,Golfcart,Gondola,Goose,Grape,Grapefruit,Guacamole,Guitar,Hamburger,Hammer,Hamster,Handbag,Hand-gun,Harborseal,Harp,Harpsichord,Headphones,Hedgehog,Helicopter,Highheels,Hikingequipment,Honeycomb,Horn,Horse,Houseplant,Humanarm,Humanbeard,Humanbody,Humanear,Humaneye,Humanface,Humanfoot,Humanhair,Humanhand,Humanhead,Humanleg,Humanmouth,HumanarXiv:2008.05700v1  [cs.CV]  13 Aug 20202R.Wangetal.nose,Icecream,Infantbed,Ipod,Isopod,Jacket,Jacuzzi,Jaguar,Jeans,Jelly-ﬁsh,Jetski,Jug,Kangaroo,Kettle,Kitchenanddiningroomtable,Kite,Koala,Ladder,Ladybug,Lamp,Lantern,Laptop,Lemon,Leopard,Lifejacket,Lightbulb,Lighthouse,Lily,Limousine,Lion,Lipstick,Lizard,Lobster,Loveseat,Lynx,Magpie,Man,Mango,Maple,Mechanicalfan,Microphone,Microwaveoven,Milk,Miniskirt,Mirror,Mixer,Mixingbowl,Monkey,Mouse,Muﬃn,Mule,Mushroom,Musicalkeyboard,Nail,Necklace,Nightstand,Oboe,Oﬃcebuilding,Organ,Ostrich,Otter,Oven,Owl,Oyster,Paddle,Pancake,Panda,Papertowel,Parachute,Parkingmeter,Parrot,Pasta,Peach,Pear,Pen,Pen-cilcase,Perfume,Picnicbasket,Pig,Pillow,Pineapple,Pitcher,Pizza,Plas-ticbag,Plate,Platter,Polarbear,Pomegranate,Popcorn,Porcupine,Poster,Potato,Powerplugsandsockets,Pretzel,Printer,Pumpkin,Punchingbag,Rac-coon,Radish,Ratchet,Raven,Raysandskates,Redpanda,Rhinoceros,Rocket,Rollerskates,Rose,Rugbyball,Ruler,Salad,Saltandpeppershakers,Sandal,Saucer,Saxophone,Scale,Scarf,Scissors,Scoreboard,Scorpion,Sealion,Seaturtle,Seafood,Seatbelt,Segway,Servingtray,Sewingmachine,Shark,Sheep,Shelf,Shirt,Shorts,Shotgun,Shower,Shrimp,Sink,Ski,Skull,Skyscraper,Slowcooker,Snail,Snake,Snowboard,Snowman,Snowmobile,Snowplow,Sock,Sofabed,Sombrero,Sparrow,Spicerack,Spider,Spoon,Sportsuniform,Squid,Squir-rel,Stairs,Starﬁsh,Stationarybicycle,Stool,Stopsign,Streetlight,Stretcher,Studiocouch,Submarinesandwich,Suit,Suitcase,Sunhat,Sunﬂower,Surf-board,Sushi,Swan,Swimcap,Swimwear,Syringe,Tabletennisracket,Tabletcomputer,Taco,Tank,Tart,Taxi,Tea,Teapot,Teddybear,Television,Tennisball,Tennisracket,Tent,Tiara,Tick,Tie,Tiger,Tincan,Tire,Toilet,Toiletpaper,Tomato,Toothbrush,Tortoise,Towel,Tower,Traﬃclight,Train,Train-ingbench,Treadmill,Treehouse,Trombone,Trumpet,Turkey,Umbrella,Unicy-cle,Van,Vase,Vehicleregistrationplate,Violin,Volleyball,Waﬄe,Wallclock,Wardrobe,Wastecontainer,Watch,Watermelon,Whale,Wheel,Wheelchair,Whisk,Whiteboard,Willow,Window,Windowblind,Wine,Winerack,Wok,Woman,Wood-burningstove,Woodpecker,Worm,Wrench,Zucchini2ListofCOCOclassesCOCO-Target10:apple,car,cat,clock,diningtable,ﬁrehydrant,giraﬀe,hairdrier,handbag,truckCOCO-Source70:airplane,backpack,banana,baseballbat,baseballglove,bear,bed,bench,bicycle,bird,boat,book,bottle,bowl,broccoli,bus,cake,carrot,cellphone,chair,couch,cow,cup,dog,donut,elephant,fork,frisbee,horse,hotdog,keyboard,kite,knife,laptop,microwave,motorcycle,mouse,orange,oven,park-ingmeter,person,pizza,pottedplant,refrigerator,remote,sandwich,scissors,sheep,sink,skateboard,skis,snowboard,spoon,sportsball,stopsign,suitcase,surfboard,teddybear,tennisracket,tie,toaster,toilet,toothbrush,traﬃclight,train,tv,umbrella,vase,wineglass,zebra(Supplementary)Whatleadstogeneralizationofobjectproposals?33TrainingweaklysupervisedmodelWetrainaweaklysuperviseddetectionmodelbasedonFastR-CNN[?],withthesamemethodasusedinYOLO9000[?].Duringtraining,theFastR-CNNmodelassignsscorestoalltheproposalsintheimage.Wethenchoosethehighestscoringproposal(fromthetop100proposalsintheimage)foreachweaklylabelledclassintheimageanduseitasthepsuedoground-truthboundingboxtoperformbackpropagation.Additionallyallproposalswhichhaveanoverlapgreaterthan0.7withthisboundingboxarealsotreatedaspsuedoground-truth,whileallboundingboxeswithanoverlapgreaterthan0.5andlessthan0.7arenotusedinbackpropagation.Wetrainthemodelfor90000iterations.Weuse500proposalsineachimageforbothtrainingandevaluation.How-ever,weonlyusethetop100proposalswhenchoosingpsuedoground-truthduringtraining.Thisallowsthemodeltochoosepositiveboundingboxesfromthemostconﬁdentproposalsintheimage,whileuseotherproposalsasback-groundproposalsfortrainingthedetectionmodel.4Suﬃciencyofprototypicalclasses50100200300432P0.500.550.600.650.700.750.800.85AR@1000RandomMost frequentSemantic clusteringVisual clusteringOIV4-432Fig.1:AveragerecallAR@1000forproposalsobtainedfrommodelstrainedwithvaryingnumberofprototypicalclasseschosenbydiﬀerentmethods.WeshowtheaveragerecallontheOIV4-targetdatasetwith50unseenclasses.Pdenotesthenumberofprototypicalclasses.Highervalueindicateshighersuﬃciency.