Conservative Plane Releasing for Spatial Privacy Protection in
Mixed Reality

Jaybie Agullo de Guzman
Data 61|CSIRO &
University of New South Wales
Sydney, Australia
jaybie.deguzman@data61.csiro.au

Kanchana Thilakarathna
University of Sydney
Sydney, Australia
kanchana.thilakarathna@sydney.
edu.au

Aruna Seneviratne
University of New South Wales
Sydney, Australia
a.seneviratne@unsw.edu.au

0
2
0
2

r
p
A
7
1

]

V
C
.
s
c
[

1
v
9
2
0
8
0
.
4
0
0
2
:
v
i
X
r
a

ABSTRACT
Augmented reality (AR) or mixed reality (MR) platforms
require spatial understanding to detect objects or surfaces,
often including their structural (i.e. spatial geometry) and
photometric (e.g. color, and texture) attributes, to allow ap-
plications to place virtual or synthetic objects seemingly
“anchored” on to real world objects; in some cases, even al-
lowing interactions between the physical and virtual objects.
These functionalities require AR/MR platforms to capture the
3D spatial information with high resolution and frequency;
however, these pose unprecedented risks to user privacy.
Aside from objects being detected, spatial information also
reveals the location of the user with high specificity, e.g. in
which part of the house the user is. In this work, we propose
to leverage spatial generalizations coupled with conservative
releasing to provide spatial privacy while maintaining data
utility. We designed an adversary that builds up on existing
place and shape recognition methods over 3D data as attack-
ers to which the proposed spatial privacy approach can be
evaluated against. Then, we simulate user movement within
spaces which reveals more of their space as they move around
utilizing 3D point clouds collected from Microsoft HoloLens.
Results show that revealing no more than 11 generalized
planes–accumulated from successively revealed spaces with
large enough radius, i.e. r ≤ 1.0m–can make an adversary
fail in identifying the spatial location of the user for at least
half of the time. Furthermore, if the accumulated spaces are
of smaller radius, i.e. each successively revealed space is
r ≤ 0.5m, we can release up to 29 generalized planes while
enjoying both better data utility and privacy.

Permission to make digital or hard copies of part or all of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. Copyrights for third-
party components of this work must be honored. For all other uses, contact
the owner/author(s).
MobiXXX 2020, September 2020, London, UK
© 2020 Copyright held by the owner/author(s).
ACM ISBN 978-x-xxxx-xxxx-x/YY/MM.
https://doi.org/10.1145/nnnnnnn.nnnnnnn

CCS CONCEPTS
• Human-centered computing → Mixed / augmented
reality; • Security and privacy → Information account-
ability and usage control; Privacy protections; • Computing
methodologies → 3D imaging.

ACM Reference Format:
Jaybie Agullo de Guzman, Kanchana Thilakarathna, and Aruna
Seneviratne. 2020. Conservative Plane Releasing for Spatial Privacy
Protection in Mixed Reality. In Proceedings of MobiXXX 2020. ACM,
New York, NY, USA, 15 pages. https://doi.org/10.1145/nnnnnnn.
nnnnnnn

1 INTRODUCTION
AR/MR platforms such as Google ARCore, Apple ARKit, and
Windows Mixed Reality API requires spatial understanding
of the user environment in order to deliver virtual augmen-
tations that seemingly inhabit the real world, and, in some
immersive examples, even interact with physical objects.1
Fig. 1 shows a generic information flow diagram for MR. The
captured spatial information is stored digitally as a spatial
map or graph of 3D points, called a point cloud (labelled Si in
Fig. 1), which is accompanied by mesh information to indi-
cate how the points, when connected, represent surfaces and
other structures in the user environment. However, these 3D
spatial maps that may contain sensitive information, which
the user did not intend to expose, can be further utilized for
functionalities beyond the application’s intended function
(see potential attacker J in Fig. 1) for benign attacks such
as aggressive localized advertisements to malevolent ones
such as burglaries. Nonetheless, there are no mechanisms in
place that ensure user spatial data privacy in existing MR
platforms.

Moreover, despite 3D data being a structural representa-
tion of the real world, 3D data is perceptually latent from
the users. With traditional media, such as images and video,
what the “machine sees” is what the “user sees”. On the other
hand, with MR, what the machine sees is different–often even
more–than what the user sees. With MR, the experience is
exported as visual data (e.g. objects augmented on the user’s

1ARKit, https://developer.apple.com/documentation/arkit; ARCore, https:
//developers.google.com/ar/; Windows MR, https://www.microsoft.com/
en-au/windows/windows-mixed-reality. For the rest of the paper, we will
be collectively referring to AR and MR as MR.

 
 
 
 
 
 
modify them to operate in the scale on which 3D data is
captured by MR platforms. We demonstrate how easy it is
to extend these methods to be used as an attacker in the
MR scenario whilst quantifying the privacy leakage. Then,
we propose spatial plane generalizations with conservative
plane releasing as a privacy-enhancing approach which can
potentially be easily integrated with existing MR platforms–
i.e. inserted as an intermediary privacy mechanism as shown
in Fig. 1. Finally, we evaluate not only the privacy leakage,
but also the reduction of utility in terms of quality of service
utilizing real-world 3D point cloud data captured through
the Microsoft HoloLens from a variety of spaces. To this end,
we summarize the major contributions as follows:

(1) We present a 3D adversarial inference model that reveals
the general space of a user, i.e. inter-space inference, and
their specific location within the space, i.e. intra-space
inference.

(2) We compare the performance of the two spatial inference
attack approaches and show that a ‘classical’ descriptor-
based matcher can outperform a deep neural network-
based recognizer.

(3) We demonstrate that the insufficient protection provided
by spatial generalizations can be improved by conser-
vatively releasing the plane generalizations; specifically,
controlling the maximum number of released generalized
planes instead of naively providing the generalizations
entirely.

(4) We present an in depth analysis over a realistic scenario
when user spaces are successively released and experi-
mentally determine the maximum number of releases,
and generalized planes that prevents spatial inference,
both inter-space and intra-space. For example, revealing
no more than 11 generalized planes can make an adver-
sary fail in identifying the spatial location of the user for
at least half of the time.

(5) Lastly, we show that better data utility can be achieved
with a smaller size, i.e. r = 0.5m, of revealed generalized
spaces while providing adequate–or even better–privacy;
specifically, we can release up to 29 generalized planes
while enjoying both better data utility and privacy.

The rest of the paper is organized as follows. First, we
discuss the related work in §2, and present the theoretical
framework of the spatial privacy problem, and associated
definitions in §3. Then, in §4, we describe two attack methods
an adversary may utilize for spatial inference. In §5, we de-
scribe the various information reduction techniques we can
employ to prevent spatial inference. We present the evalua-
tion methodology in §6 to investigate the viability of privacy
methods we employ over varying experimental setups. The
results are presented in §7 followed by the discussion in §8.
Lastly, we conclude the paper in §9.

2

Figure 1: Information flow diagram (following the green
solid arrows) for an intended MR function G, with an at-
tacker J which can perform adversarial spatial inference: (1)
adversarial inference modeling or learning from, say, histor-
ical 3D data, and (2) adversarial inference or matching over
currently released 3D data. Then, inserting an intermediate
privacy-preserving mechanism M which aims to prevent ad-
versarial spatial inference.

view) while the user is oblivious about the captured spatial
mapping, its resolution, and exactness. This inherent percep-
tual difference creates a latency from user perception and,
perhaps, affects–or the lack thereof–how users perceive the
sensitivity of 3D information. Aside from the spatial struc-
tural information, the mapping can also include 3D maps of
objects within the space. Furthermore, the spatial map can
also reveal the location of the user: both the general loca-
tion, and their specific location within the space. Moreover,
most users are oblivious about the various information that
are included in the spatial maps captured and stored by MR
platforms.

As majority of the work on MR have been focused on
delivering the technology, only recently have there been
efforts in addressing the security, safety, and privacy risks
associated with MR technology [7, 9]. There have been a
few older works that have pointed out the issues on ethical
considerations [14] in MR as well as highlighting considera-
tions on data ownership, privacy, secrecy, and integrity [13].
Moreover, potential perceptual and sensory threats that can
arise from MR outputs such as photosensitive epilepsy and
motion-induced blindness have also been looked into [4].
In conjunction to these expositions, the EU have recently
legislated the General Data Protection Regulation (GDPR)
which aims to empower users and protect their data pri-
vacy through a policy approach. This further highlights the
importance of designing and developing privacy-enhancing
technologies (PETs) especially those that can be applied to
the MR use case.

In light of this, first, we present two adversary approaches
that recognizes the general space, i.e. inter-space, and also
infers the user’s location within the space, i.e. intra-space. To
construct these attackers, we build up on existing 3D place
recognizers that have been applied over 3D lidar data: an
intrinsic descriptor matching-based 3D object recognizer,
and a deep neural network-based 3D shape classifier. We

Privacy MechanismMXiInput Point Cloudof the True spaceFunctionGAttackerJY OutputH: I|SHypothesisZiTransformed Point Cloudof the True space2Adversarial applicationTrue space iMixed Reality Devicee.g. Microsoft HololensHistorical or previously collected 3D dataExample Outpute.g. Pokémon walking aroundFunctionGY OutputTrue space iExample Outpute.g. Pokémon walking aroundSiInput Point Cloudof the True spaceMixed Reality Devicee.g. Microsoft HololensAdversarial pipelineMain MR processing pipeline1Privacy MechanismMSiTransformed Point Cloudof the True space~Inserting Privacy Preservation2 RELATED WORK
In the general privacy and security space, various work have
already been done: from revealing privacy leakage in online
social networks [19] and mobile devices [27], to developing
privacy-preserving mechanisms for conventional user data
types [10, 21, 35] as well as against deep-learning inference
[1, 30].

Information Sanitization. Consequently, several AR/MR
and related PETs have been proposed in the literature, and
are listed in [9]. Early approaches primarily involved ap-
plying sanitization techniques on visual media (i.e. image
and video): e.g. removing RGB and only showing contours
[17], detecting markers that signify sensitive content to be
sanitized [25, 26], sanitizing sensitive objects from a shared
database or communicated through PAN [2, 20, 28], through
user gestures [32], or based on context [34, 40]. However,
these sanitization approaches are focused on post-captured
images which can still pose security and privacy risks, and
they have only been applied on the wide use case of visual
capture devices and not on actual MR devices or platforms.
Visual information abstraction. Abstraction addresses
the earlier issues by reducing or eliminating the necessity of
accessing the raw visual feed directly. In the specific 3D use
case, significant work have been done on protections involv-
ing abstracted physiological information [11, 16] using the
idea of least privilege [38]. The same approach has also been
used for providing spatial information while maintaining
visual privacy [37]. A recent work also utilized the idea of
least privilege to apply visual abstractions for mobile MR [8].
However, they are functionality or data specific, and have
neither presented or exposed actual risks with 3D MR data
nor provided evaluation against attacks.

3D data: attacks, risks, and protection. Very few re-
cent works have started to look into the actual risks brought
about by indefinite access to 3D data. One provided prelimi-
nary evidence of how an adversary can easily infer spaces
from captured 3D point cloud data from Microsoft Hololens
[7]; and how, even with spatial generalization (i.e. the 3D
space is generalized in to a set of planes), spatial inference
is still possible at a significant success rate; however, they
did not use a machine learning approach which may further
demonstrate the ineffectiveness of spatial generalizations
as privacy protection. In contrast, another recent work em-
ployed machine learning to reveal original scenes from 3D
point cloud data with additional visual information [22].
While a concurrent work focused on a privacy-preserving
method of pose estimation to counter the scene revelation
[33]: 3D “line” clouds are used during pose estimation to ob-
fuscate 3D structural, i.e. geometrical, information; however,
this approach only addresses the pose estimation function-
ality and does not present the viability for surface or object
detection which is necessary for a virtual object to be ren-
dered or “anchored” onto. Thus, it is still necessary for 3D
point cloud data to be exposed but with privacy-preserving

Table 1: Notation Map

Notation Description

Si

point cloud representation of space labelled i;

can be composed of subspaces s, s ⊂ S; and
composed of oriented points p, ∀p ∈ s (cid:55)→ ∀p ∈ S

privacy-preserving mechanism
transformed point cloud released by M
intended functionality (i.e. MR app or service)
output of the intended functionality G
difference of the transformed (cid:101)S from S
adversarial inferrer
hypothesis of J about an unknown query space i∗;
producing an inter-space hypothesis i∗ = i, and
an intra-space hypothesis centroid cS

inter-space privacy measure in terms of classification error
intra-space privacy measure in terms of distance error

M
(cid:101)S(i),v
G
Yi,v
Q

(cid:101)S ;S
J
h

Π1((cid:101)S; S)
Π2((cid:101)S; S)

transformations to hide sensitive content and prevent spatial
recognition.

In this work, we improve upon the attacker used in [7] by
extending the attack with intra-space inference, and adding
a deep neural network-based approach in our investigation
as a potentially stronger attacker. Moreover, we augment the
currently inadequate spatial generalizations with conserva-
tive releasing as a stronger countermeasure against these
attacks.

3 SPATIAL PRIVACY PROBLEM IN

MIXED REALITY

As shown in Fig. 1 and following the notation map in Tab. 1,
we define a space represented by a point cloud S identified
by a label i which can be segmented into a set of overlapping
point cloud subspaces S = {s1, s2, ...sn }. An MR functionality
G produces an output Y , and from which we derive the utility
or QoS function Q. An adversarial inferrer J produces a
hypothesis H to reveal the spatial location of an unknown
space. Lastly, a privacy preserving mechanism M transforms
S, or its subspaces s ⊂ S, to a privacy-preserving version
(cid:101)S or ˜s, i.e. M : S or s (cid:55)→ (cid:101)S or ˜s.

In the succeeding sections, we formalize the adversary
model in §3.2, the privacy metrics in §3.3, and the function-
ality and utility metrics in §3.4. Before we proceed, we first
introduce 3D data representation.

3.1 3D spatial data
There are various ways that MR-capable devices capture and
compute 3D spatial data. Depending on the platform, the
underlying environmental mapping approach would be any
or combinations of the following: simultaneous localization
and mapping (SLAM), visual odometry, and/or structure from
motion (SfM). We direct the readers to [29] for a survey on
these visual mapping algorithms.

Regardless of the underlying mapping algorithm, the aim
is to construct a 3D spatial map represented by a set of ori-
ented points: 3D points described by their {x, y, z}-position in

3

space and usually accompanied by a normal vector {nx , ny, nz }
which informs of the orientation of the surface to which the
point belongs to. (When normal vectors are not readily avail-
able, it is estimated from the points themselves.) A collection
of these oriented points together with an accompanying
mesh information, which informs of how the points are con-
nected to form surfaces, constitute a point cloud.

3.2 Adversary model
Currently, there are no mechanisms in place that ensures
user data privacy on MR platforms. As shown in Fig. 1, any
potentially adversarial application can access and store all
captured 3D spatial maps. These adversaries may desire to
infer the location of the users, or they may further infer user
poses, movement in space, or even detect changes in user
environment. Furthermore, in contrast to video and image
capture, 3D data can provide a much more lightweight and
near-truth representation of user spaces.

In this work, we will focus on the spatial inference attack
where the adversary aims to recognize the location of the
user on two levels given historical 3D data of user spaces: (1)
the general location of the user (among the known ensemble
of spaces) we call inter-space inference, and (2) the specific
location of the user within the space we call intra-space
inference. Also, we assume that the adversary’s aim is to
individually infer user spaces; thus, an attacker will develop
a different reference model for every user. And that it can
only infer spaces that the user has historically been in.

Defining adversarial inference. As shown in Fig. 1, infer-
ence is a two-step process: (1) the training of a reference
model or creation of a dictionary using 3D description algo-
rithms over the previously known spaces as reference, (2)
and the inference of unknown spaces by testing the model,
i.e. matching their 3D descriptors to that of the reference de-
scriptors from step 1. We assume that the adversary has prior
knowledge about the spaces which they can use as reference.
Prior knowledge can be made available through historical or
publicly available 3D spatial data of the user spaces, previ-
ously provided data by the user themselves or other users,
or from a colluding application or service that has access to
raw or higher resolution 3D data. Furthermore, we assume
that the adversary is aware of the generalizations that can
be applied on released point cloud data and be able to adjust
its attack accordingly.

Then, an attacker J produces a two-element hypothesis
h for our two-level attack: inter-space location, i.e. location
i∗ = i, to determine in which of the reference spaces the
query space is; and intra-space location defined by a centroid
cS ∗ = {x ∗, y∗, z∗} of an unknown point cloud S ∗
.Hypothesis
i

4

h is defined as follows:

J : S ∗

i −→ h : i∗ = i, and cs ∗ = {x, y, z}, where
i∗ = i = argmax

LS ∗(i∗ = i), and

∀i
cS ∗ = {x ∗, y∗, z∗} (cid:55)→ cSr

= {xr , yr , zr },

(1)

(a)

(b)

where LS ∗(i∗ = i) is a likelihood function about the un-
known space S ∗ having a label i∗ = i, and {xr , yr , zr } =
|{kSr ,b }|cent r oid is the centroid of the best reference key
point matches.

Intra-space inference is the primary step in tracking or
localization. Aside from knowing the general location of a
user, which can have a huge width such as r ≈ 100m, an
attacker would also require the exact location of the user. For
example, if an adversarial advertising service with various
points of presence (PoP) can tell if one of their PoP is within
user view, then, the service can ship an advertisement to the
PoP nearest to the user. Conversely, if the attacker wrongly
infers the intra-space location of the user, then the attack
has failed. The methods employed for inference are further
discussed in §4.

3.3 Privacy Metrics

Defining the privacy metrics. We define the inter-space pri-
vacy function Π1 in terms of the inter-space misclassification
error rate of the inferrer J . A few works in the literature
uses a similar classification error-based metric for privacy
[31, 39]. We treat the correct classification event as a dis-
crete random variable defined by a discrete delta function
δ (i∗, i) = {1 if i∗ = i; 0 if i∗ (cid:44) i} so that we can pose Π1 as
the expectation of misclassification given an unknown point
cloud S ∗ as follows

Π1(S ∗; S ) = (cid:213)
∀i

(cid:213)

∀i ∗

(1 − δ (i ∗, i))LS ∗ (i ∗ = i)

(2)

where i∗ is the hypothesis label of J about the true label i
of an unknown space S ∗, and Ls ∗(i∗ = i) is the likelihood
function.

Likewise, we can also pose a secondary metric Π2 for intra-
space privacy which captures how accurate an adversary can
estimate a user’s position within a space; that is, the user,
at any given time is at a specific subspace within the larger
known space. We define the mean intra-space distance error
as follows:

Π2((cid:101)S ; S ) =

1
|∀{S ∗, S : i ∗ = i } |

(cid:213)

∀{S ∗, S :i ∗=i }

d (cS ∗, cS )

(3)

where the d(cS ∗, cS ) represent the total distance error be-
tween the correct intra-space location cS = {x, y, z} and
the hypothesis intra-space location cS ∗ = {x ∗, y∗, z∗} =
{xr , yr , zr } for a given unknown space S ∗. The distance for-
mula is as follows:

d(cS ∗, cS ) = ||cS ∗ − cS ||

= (cid:112)(xr − x)2 + (yr − y)2 + (zr − z)2.

(4)

3.4 Mixed reality functionality
Perhaps, the most common functionality in MR is the an-
choring of virtual 3D objects on to real world surfaces (e.g.
the floor, walls, or tables). At the minimum level, a static
anchor only requires an {x, y, z} point with an orientation
{nx , ny, nz }. A set of these oriented points which forms a
plane or surface can allow for dynamic virtual augmenta-
tions that move about the surface. Furthermore, a set of these
planes or surfaces can constitute a space which, then, allows
for augmentations that move about the space.

(cid:101)S

;YS

Defining the function utility. For a given functionality G,
an effective privacy mechanism M aims to make the result-
ing outputs Y from the raw point cloud S and its privacy-
preserving version (cid:101)S similar, i.e. YS ≃ Y
. Thus, we define util-
(cid:101)S
ity as the Quality-of-Service (QoS) in terms of the output trans-
formation error, QY
, or the difference of the transformed
output Y
(cid:101)S |,
(cid:101)S
which we aim to minimize.
For consistently anchored augmentations, some function-
alities require near-truth point cloud representations. This
as the dif-
implies that we can directly compute the QY
ference Q
of the point clouds themselves instead of the
outputs like so Q

from the original output YS : QY

= |S − (cid:101)S |.
Defining the utility metric. We can define Q

as a utility
metric by specifying it as a mean transformation error (QoS)
with the following components

= |YS − Y

(cid:101)S ;S

(cid:101)S ;S

(cid:101)S ;S

;YS

;YS

(cid:101)S

(cid:101)S

Q

(cid:101)S ;S

= mean

∀ ˜p ∈ (cid:101)S, ∀p ∈S

[α · (| |p − ˜p | |) + β · (1 − (cid:174)np · (cid:174)n ˜p )]

(5)

where the first component, i.e. ||p − ˜p||, is the point-wise
Euclidean difference of the true/raw point p from the trans-
formed point ˜p, while the second component are their normal
vector difference using the difference from 1 of their normal
vector cosine similarity (i.e. (cid:174)np · (cid:174)n ˜p ). The coefficients α and
β are contribution weights where α, β ∈ [0, 1] and α + β = 1.
We set α, β = 0.5. To compute this point-wise differences, we
have to first find the nearest neighbor pairs of each point in
the transformed point cloud (cid:101)S from the raw point cloud S, i.e.
1nn
˜p ∈ (cid:101)S
(cid:55)−→ p ∈ S; thus, the differences are computed between
the 1nn { ˜p, p}-pair of points and is computed ∀ ˜p ∈ (cid:101)S to get
the mean difference over the entire transformed point cloud
(cid:101)S.

Moreover, we also specify an inequality constraint γ that
defines the maximum permissible transformation error as
follows:

mean
∀ ˜p ∈ (cid:101)S, ∀p ∈S

[α · (1 − | | ˜p − p | |) + β · ( (cid:174)n ˜p · (cid:174)np )] ≤ γ

(6)

The γ can be used as a tunable parameter depending on
the exactness required by the MR function: higher gamma
implies that the MR function does not require released spaces
to be very exact to the true space, while a small gamma
implies exactness.

5

Figure 2: Reference construction, model training, and infer-
ence using two approaches: NN-matcher, and pointnetvlad

A desired mechanism M produces (cid:101)S that maximizes the
privacy functions Π1 and Π2 while minimizing Q. Moreover,
we will freely use the following notation Π1(Θ) or Π2(Θ)
where we indicate a set of parameters Θ that specifies the
transformation M.

4 ADVERSARIAL SPATIAL INFERENCE
We utilize two methods for our spatial inference attack:
a descriptor nearest-neighbor matching approach we call
NN-matcher (improved from [7]), and a deep neural net-
work (DNN) based approach called pointnetvlad [36]. Fig.
2 shows a diagram of the overall process involved in the two
inference methods. It has been previously demonstrated that
spatial generalizations, i.e. 3D surfaces generalized as a set
of planes, is an inadequate measure for spatial privacy [7].
Furthermore, generalizations can easily be replicated by an
adversary allowing it to adjust its attack accordingly. Thus,
as shown in Fig. 2, for both methods, we augment the raw
captured point cloud data with multiple generalized versions
as a combined reference ensemble.

4.1 Inference using 3d descriptors:

NN-matcher

Step 1 for NN-matcher involves the construction of a ref-
erence set of descriptors from the historical data available
augmented with generalized versions. A subset of oriented
points for each space are selected and are called key points.
Then, for each key point, an intrinsic feature descriptor is
computed. The key point selection and feature computation
depends on the chosen algorithm. The result of this process
results to the accumulation of a set of key point-feature pairs
for each reference space like so: {{ki,0, fi,0}, {ki,1, fi,1}, ...}

Privacy MechanismMXiInput Point Cloudof the True spaceFunctionGAttackerJY OutputZiTransformed Point Cloudof the True space2Adversarial applicationTrue space i1Mixed Reality Devicee.g. Microsoft HololensReference 3d point cloudsExample Outpute.g. Pokémon walking aroundFunctionGY OutputQuery point cloud, i.e. space S*Example Outpute.g. Pokémon walking aroundSiInput Point Cloudof the True space?{kN,1, fN,1}{k2,n, f2,n}{kN,0, fI,0}{k1,1, f1,1}{k1,n, f1,n}{k1,0, f1,0}{k0,1, f0,1}{k0,n, f0,n}{k0,0, f0,0}{k?,1, f?,1}{k?,n, f?,n}{k?,0, f?,0}Reference set of descriptors...Descriptor MatchingQuery descriptors{{k0,0, f0,0},{k0,1, f0,1}, … , {k0,m, f0,m}}{{k1,0, f1,0},{k1,1, f0,1}, … , {k1,m, f1,m}}{{kN,0, fN,0},{kN,1, fN,1}, .., {kN,m, fN,m}}...H: i* = 0 | SiH: i* = 1 | SiH: i* = N | Si......Matching Score✔Step 1: Building Reference or TrainingStep 2: QueryingExtraction of 3D descriptorsTrain DNNGeneralized 3d point cloudsGeneralizeDatabase of reference 3D descriptorsNN-matcherDatabase of reference 3D pointcloudsDNN Model,i.e. pointnetvladExtraction of 3D descriptorsDatabase of reference 3D descriptorsNN-matcherDatabase of reference 3D pointcloudsDNN Model,i.e. pointnetvladH: I|SH: I|S(a) Sample partial spaces of a bigger space

(b) Generalizing the partial spaces

(c) Conservative release of planes

Figure 3: Sample (a) partial releases with (b) generalization, and (c) conservative plane releasing.

for any space i. Then, for the inference step, we match the ref-
erence set with the key point-descriptor set of the unknown
query space.

For inter-space inference, we utilize a deterministic matching-

based approach using nearest-neighbor matching in the de-
scriptor space, i.e. { fS ∗ } (cid:55)→ { fSc ∈ {Sr }}. Then, a voting mech-
anism determines the best candidate match among the ref-
erence spaces (Sc ∈ {Sr }) which has the most matched de-
scriptors with the query space (S ∗). A similar voting-based
mechanism was utilised in place recognition over 3D lidar
data [5, 6].

We improve upon the mechanism used in [7] by extend-
ing the inference to intra-space location. We collect the key
points of the corresponding features matched from inter-
space inference, and trim the collection by only getting the
pair of reference and query descriptors whose nearest neigh-
bor distance ratio (or NNDR) < 0.9. Then, using their cor-
responding key points, as in {kS ∗ } (cid:55)→ {kSr },we perform a
geometric structure consistency check which produces the best
pairs of key points with consistent structural relationships;
that is, the graph (or sub-graph) of the reference key points
is similar to the graph (or sub-graph) of the corresponding
set of query key points. This can be generalized to the NP-
complete sub-graph isomorphism problem but we instead
use a heuristic-based approach using the product of the an-
gular (using cosine similarity) and distance similarities of the
two key point graphs. Then, we pick the resulting sub-graph
with the most number of structurally consistent matched key
points as the best intra-space match. We then compute the
resulting intra-space distance d(cS ∗, cS ) of the true centroid
cS of the query space to that of the centroid of the matched
reference space cS ∗ = cS r within the query space as described
by Eq. 4.

4.2 Inference using DNN: pointnetvlad
To produce a large-scale place recognizer with 3D point
cloud as input, pointnetvlad combines the deep network
3D point cloud shape classifier PointNet [23] with NetVLAD
[3], which is a deep network image-based place recognizer.
To train pointnetvlad, we split the reference point clouds
to disjoint training and validation sets. The point cloud

sets are further subdivided to similarly-sized overlapping
submaps with a radius of 2m and are re-sampled to contain
1024 points. The submap intervals are 0.5m and covers all 3
axes (while the original pointnetvlad only covers the two
ground axes). The PointNet layer produces local feature de-
scriptors for each point in a submap, and, then, feed those to
the NetVLAD layer to learn a global descriptor vector for the
given submap. We direct the reader to [36] for more details
on pointnetvlad.2

For inference, pointnetvlad creates a reference database
of the global descriptors of the combined raw and general-
ized spaces available. The point cloud of the query space
will also be divided into submaps and be directly fed to the
pointnetvlad model which likewise produces the two-level
spatial inference hypothesis.

5 PRIVACY MEASURES OVER 3D DATA
Directly releasing raw point clouds exposes all spatial infor-
mation as well as structural information of sensitive objects
within the space. A mechanism can be inserted, as shown in
Fig. 1, along the MR processing pipeline to provide privacy
protection. We present two baseline protection measures:
partial releasing, and planar spatial generalizations. How-
ever, it has been shown that planar spatial generalizations
are inadequate forms of protection [7]; thus, we augment the
protection further with conservative releasing of the plane
generalizations.

5.1 Partial spaces
To limit the amount of information released with the point
clouds, partial releasing can be utilised to provide MR appli-
cations the least information necessary to deliver the desired
functionality. With partial spaces, we only release segments
of the space with varying radius. Fig. 3a shows an example
space with 2 partial releases. Partial releasing can either be
performed once or up to a predefined number of releases if
more of the space is necessary for the MR application to pro-
vide its service. Then, succeeding revelations of the space are

2Original pointnetvlad code can be accessed at github.com/mikacuy/
pointnetvlad.

6

no longer provided to the MR application. Moreover, partial
releasing can be applied over raw or generalized spaces.

5.2 Plane fitting generalization
As discussed in §3.1, to deliver augmentations, MR platforms
digitally maps the physical space to gain understanding of it.
And, as discussed in §3.4, depending on the desired function-
ality, an MR application may require just a single oriented
point as a static anchor, a single plane or surface, or a set of
surfaces for dynamic augmentations. Thus, arguably, with-
out a significant impact on the delivery of the desired MR
functionality, any surface within a space can be generalized
into a set of planes. Furthermore, surface-to-plane general-
izations inadvertently sanitizes information that is below
the desired generalization resolution. For example, a key-
board on a desk surface may be generalized as part of the
desk. However, spatial information, i.e. location, may still be
inferred as we will reveal later.

To perform surface-to-plane generalization, we employed
the popular Random Sample Consensus (or RANSAC) plane
fitting method [12]. For our implementation, we directly
utilize the accompanying normal vector of each point to
estimate the planes in the plane fitting process instead of
computing or estimating them from the neighbouring points.

5.3 Conservative plane releasing
Plainly using plane generalizations do not adequately pro-
vide protection from spatial inference especially when we
continuously reveal the space. Thus, we present conservative
releasing, where we limit the number of planes a generaliza-
tion produces. Fig. 3b shows an example set of planes that
are released after RANSAC generalization of the revealed
partial raw spaces (in Fig. 3a); then, as shown in Fig. 3c, we
can limit the maximum allowable planes that can be released
to, say, a maximum of 3 planes in total.

As will be presented later in §7.3, conservative releasing
is a viable privacy countermeasure which provides QoS that
are arguably adequate for most MR functionalities.

6 EVALUATION SETUP
We present the various experimental setups we designed to
investigate the viability of the different privacy-preserving
methods described in §5. We use the ensemble of raw point
cloud data augmented with generalized versions as the refer-
ence set available to the adversary (Step 1 in Fig. 2). We, then,
implement the various privacy-preserving methods to inves-
tigate how well can the adversary perform their attacks over
such defenses. Specifically, for all succeeding experiments,
we will be utilizing RANSAC generalization but with varying
release mechanisms: in terms of the size of the partial space,
the number of successive releases, and the maximum total
number of released planes. We first present our data and
specify our metrics before describing the evaluation setups.

Figure 4: 3D point clouds of the 7 collected environments
(left); a 3D surface of a sample space (bottom-right), and its
2D-RGB view (top-right).

6.1 Dataset
For our dataset, we gathered real 3D point cloud data using
the Microsoft HoloLens in various environments to demon-
strate the leakage from actual human-scale spaces in which
an MR device is usually used. As shown in Fig. 4, our collected
environments include the following spaces: a work space, a
reception area, an office kitchen or pantry, an apartment, a
drive way, a hall way, and a stair well.

The combined approximate floor area of the spaces is
899.9m2 while the combined approximate surface area (i.e.
including the vertical surfaces and other objects whose 3d
point cloud are captured) is 1434.7m2. The combined size of
the raw point clouds are 39.7MB. The resulting reference
descriptor set used by NN-matcher is 5.5MB while the refer-
ence database used by pointnetvlad is 5.41MB.

6.2 Metrics
To quantify the privacy leakage in our various evaluation
setups, as defined in §3.2, we use adversarial inference error
as our privacy metrics. We posed a two-level attack: (1) inter-
space inference, and (2) intra-space inference. For the first
level, privacy can be directly linked, as in Eq. 2, to the inter-
space inference error rate. While, for the second level, as
in Eq. 3, intra-space privacy can be related to the distance
error which is in distance units u (where 1 u is approximately
1 meter ).

Moreover, we set the following desired subjective lower-
bounds for the privacy metrics. For inter-space privacy, we
can set a desirable lower-bound at Π1 ≥ 0.5. This means
that an adversary can only make a correct guess at most half
the time. Furthermore, we define 1.0 ≥ Π1 ≥ 0.75 as high
privacy, 0.75 > Π1 ≥ 0.5 as medium privacy, and Π1 < 0.5

7

2D-view of sample region3D surface plot of sample regionas low privacy. For intra-space privacy, we set a desirable
lower-bound at Π2 ≥ 4m. However, we emphasize the great
subjectivity of these lower-bounds especially that of the intra-
space distance error where a desirable lower-bound highly
depends on the scenario or location. For example, for indoor
scenarios, a distance error of at least 4m can perhaps mean
that the actual user is in a different room, while, for outdoor
scenarios, a distance error of at least 4m is still relatively
small.

6.3 Setup
We validate the viability of generalization as we vary the size
of the one-time partially released generalized spaces, and as
we successively release more partial spaces. Then, we pro-
ceed with the investigation of the viability of conservative
releasing as an augmented countermeasure to generaliza-
tions.

One time release of partial spaces. For initial investigation
and validation, we use the case when an MR application is
provided only once with 3D spatial information but we vary
the size, i.e. radius r , of the revealed space. We apply this
to the raw point clouds as well as for RANSAC-generalized
point clouds. For every radius r , we get 1000 random sam-
ple spaces, i.e. random submap of radius r from a randomly
picked space, as a user can initiate an MR application from
any point within a space; to ensure rotation-invariance, we
also randomly rotate and translate the space. We, then, mea-
sure the inference performance. We feed the same set of
partial spaces to the two chosen attack approaches: the
descriptor-based NN-matcher, and the deep neural network-
based pointnetvlad.

Successive release of partial spaces. To demonstrate the
case when users are moving around and their physical space
is gradually revealed, we included a validation setup that
successively releases partial spaces. Following the described
generalization strategy in §5.2, we perform successive re-
leasing of partial spaces for collected raw point cloud, and
for RANSAC generalized versions. We do 100 random sam-
ple partial iterations, and produce 100 releases per random
sample. We do this for radii = {0.5, 1.0, 2.0}.

As the released points are accumulated, we perform gener-
alization over the accumulated points. To achieve consistency
on the generalizations, we implemented a plane subsumption
handler for generalizing successively released points. Specif-
ically, new points will be checked against existing planes
(produced by previous releases) if they can be subsumed by
the existing ones instead of performing RANSAC generaliza-
tion for the entire accumulated points; RANSAC will only
be performed over the remaining [ungeneralized] points.

We feed the same set of successive spaces to both the
NN-matcher, and pointnetvlad. The resulting stronger at-
tacker will be used for the subsequent cases.

Figure 5: One-time partially released RANSAC-generalized
spaces vs varying radii: (left) inter-space and (right) intra-
space privacy

Conservative plane releasing. In addition to the previous
setups, we employ conservative releasing which limits the
number of planes a surface-to-plane generalization produces
as a form of spatial privacy countermeasure. For our inves-
tigation, we apply conservative releasing over the same set
of successively released partial spaces with subsumption ap-
plied during RANSAC generalization. But, for every sample
release, we investigate the impact of limiting the maximum
number of planes, we label max_planes, that are generated
by the RANSAC plane generalization process. We performed
controlled plane releasing with max_planes in steps of 2
from 1 to 30.

7 RESULTS
Now, we present the results of the systematic evaluation. We
first present the results of the validation experiments over
partially released and successively released spaces followed
by the results of our investigation on conservative releasing
as a complementary approach to generalization for privacy
preservation.

7.1 One time partial releasing
Fig. 5 shows the average privacy provided by surface pla-
nar generalization as we vary the size of released spaces for
the one-time release case, and for our two attackers. We use
the subscript NN for NN-matcher while PV for pointnetvlad.
We also show the privacy values of Raw spaces for compar-
ison. As shown in Fig. 5-left, generalization provides im-
proved inter-space privacy for the one-time partial release
case. This can be observed in the sharp drop of Π1,NN,Raw
while Π1,NN,Gen slowly drop as we increase the radius. At
r = 1.0m, there is more than a two-fold difference between
Π1,NN,Raw and Π1,NN,Gen; at r = 1.5m, Π1,NN,Raw is already
< 0.1 while Π1,NN,Gen is still > 0.3.

On the other hand, pointnetvlad learns to generalize
during training, thus raw and surface-generalized query
spaces will result to the similar global descriptors and, hence,
same Π1 values. As shown in Fig. 5-left, pointnetvlad per-
forms worse than the NN-matcher at r < 1.75m. This is
due to the submaps used to train pointnetvlad having 2m
radius.3 To further demonstrate the impact of submap gen-
eration, we show the performance in Fig. 5-left when we

3In the interest of space, we no longer show the results of the preliminary
analysis over pointnetvlad but smaller submaps have worse performance

8

0.00.51.01.52.02.53.0Partial Radius (m)0.00.20.40.60.81.0INTER-space Privacy, 11,NN,Raw1,NN,Gen1,PV,assisted1,PV,unassisted0.00.51.01.52.02.53.0Partial Radius (m)0246810INTRA-space Privacy, 2 (m)2,NN,Gen2,PV,unassistedeither increase the size of a partial space, or reveal more
portions and/or planes of the space, unsurprisingly, the inter-
space privacy (Fig. 6-left) decreases. For r = 0.5m, both Π1,NN
and Π1,PV slowly drops but with Π1,NN dropping faster. If we
double the size of the releases to r = 1.0m, both Π1 drops
quickly with Π1,NN still dropping faster. Thus, in terms of
inter-space privacy, NN-matcher still performs better than
the deep neural network-based pointnetvlad even in the
successive case.

Despite the accumulated spaces in the successive case be-
ing larger than 2.0m after a few releases, pointnetvlad’s
performance still suffers from non-optimal submap gener-
ation. We did observe that Π1 drops to 0 in Fig. 5-left, but
that is due to how the partial spaces are generally enclosed
in spheres. Whereas in the successive case, the accumulated
spaces will now be irregularly shaped. Fig. 3 shows how it
looks with two releases. Thus, for accumulated spaces larger
than 2.0m, the submap generator will produce more than 1
submap to cover the entire query space and, then, perform
the inference on the submaps. Some of these submaps, say
the edge submaps, will lead to erroneous inter-space labels.
On the other hand, similar to the one-time partial case, intra-
space performance of pointnetvlad is fairly sustained and
better than the NN-matcher–owing to the discriminative
power of the NetVLAD layer as long as the inter-space label
is correct.

Differently, the NN-matcher’s intra-space distance error
initially drops but slowly increases as we reveal more of
the space. As shown in Fig. 6-right, at the first release, at
r = 0.5m, Π2,NN is slightly high with an error of ≥ 4m, but,
after 20 or more releases, the Π2 drops < 3m. But, inter-
estingly, as we reveal more of the space, the Π2 seems to
improve: for r = 1.0m, Π2 approximately increases to almost
4m again as we reach 60 or more releases. And, regardless of
the size, after 20 releases, Π2,NN follows a similar increasing
trend. This can be attributed to how artificial, i.e. man-made,
spaces have repeating similar structures which also produces
very similar descriptors. As a result, successive releases can
contain structures on a different intra-space location but is
similar to structures that were previously released. A good
example of this are the workstations in the same company
or institution which are all designed similarly.

However, this seemingly improving intra-space privacy
is not necessarily an improvement as the revealed space
grows in size which leads to a possible overlap of the hy-
pothesis intra-space to the true space. For example, after a
number of releases the width of the accumulated space is
4.0m, a Π2,NN < 4.0m means that the adversary was still able
to produce a hypothesis space that overlaps with or, even,
within the true space. Nevertheless, we will use NN-matcher
in the succeeding setups as it outperforms pointnetvlad in
inter-space inference.

Figure 6: Successively released partial spaces: (left) inter-
space and (right) intra-space privacy

assist the submap generation with true centroids of the par-
tial spaces, and when it is unassisted–i.e. the attacker has
to infer the centroids of the partial spaces. When assisted,
a slight improvement on pointnetvlad’s performance can
be observed: i.e. at r = 2.0m, P1,PV,assisted < 0.1 while
P1,PV,unassisted > 0.1; however, this only further exposes the
weakness of pointnetvlad for r < 2.0m. In the subsequent
cases, we only show the results of unassisted pointnetvlad.
Subsequently, Fig. 5-right shows the average intra-space
privacy for the partial query spaces that are correctly labelled
during inter-space inference. We only focus on the results for
the surface-generalized query spaces, and only for the unas-
sisted pointnetvlad. At partial releases with r ≤ 0.75m,
Π2,NN > 4m which directly translates to the intra-space hy-
pothesis being off by at least 4m in average from the true
intra-space location. On the other hand, Π2,PV ≤ 2m regard-
less of the radius: the NetVLAD layer ensures that nearby
submaps will have similar global descriptors (and distant
submaps to be dissimilar) which leads to good intra-space
performance. On the other hand, NN-matcher descriptors
are directly computed from the point cloud which means that
nearby descriptors can be dissimilar while distant descriptors
can be similar.

Evidently, there is no intra-space privacy benefit from
generalizations for r > 1.0m, but, as shown in Fig. 5, a signif-
icant inter-space privacy benefit can be observed. However,
one-time partial releasing provides very limited data to ap-
plications. In reality, other MR applications may desire to
receive new, expanded, and/or updated information about
the user’s physical space to deliver their MR functionality
with immersiveness. Thus, we also need to investigate the
viability of using generalizations but with successively re-
leased spatial information.

Takeaway. Surface-to-plane generalizations provide INTER-
space privacy benefit for the one-time partial release case, but
does not provide any significant benefit in terms of INTRA-
space privacy.

7.2 Successive releasing
Fig. 6 shows the inference performance as we successively
release generalized partial spaces. Regardless of the size of
the released partial spaces and of the attacker used, as we

for two primary reasons: smaller submaps (1) contain less information, and
(2) results to more similar-looking submaps.

9

020406080100Number of Releases0.00.20.40.60.81.0INTER-space Privacy, 1r =0.5, 1,NNr =1.0, 1,NNr =2.0, 1,NNr = 0.5, 1,PVr = 1.0, 1,PVr = 2.0, 1,PV020406080100Number of Releases0246810INTRA-space Privacy, 2 (m)r = 0.5, 2,NNr = 1.0, 2,NNr = 2.0, 2,NNr = 0.5, 2,PVr = 1.0, 2,PVr = 2.0, 2,PV(a) 3D plot (r = 0.5)

(b) Heatmap (r = 0.5)

(a) 3D plot (r = 0.5)

(b) Heatmap (r = 0.5)

(c) Heatmap (r = 1.0)

(d) Heatmap (r = 1.0)

(c) 3D plot (r = 1.0)

(d) Heatmap (r = 1.0)]

(e) Average Π1 over all releases
Figure 7: Average INTER-space privacy of conservatively
released planes over successive releasing (using NN-matcher
attacker)

Takeaway. The evaluation over successive releases high-
lights the inference power, especially in INTER-space inference,
of a descriptor matching-based attacker in recognizing spatial
locations from 3D MR data.

7.3 Conservative releasing
Now, we explore the privacy approach of combining conser-
vative releasing with surface planar generalizations to pro-
vide spatial privacy in MR as more of the space is revealed.
Specifically, we control the maximum number of released
planes after the surface-to-plane generalization process. Fig.
7 shows the inter-space privacy values as we increase the
maximum number of planes, i.e. max_planes, and the num-
ber of releases. We can see from the 3D plot for r = 0.5m
in Fig. 7a that the inter-space privacy gradually decreases
as we reveal more of the space (more releases) and increase
max_planes. For Π1(r = 0.5m) to go below 0.5, both the
number of releases and max_planes needs to be high. This
is more evident through the unevenly quantized heatmap
shown in Fig. 7b which shows that we will get Π1 ≤ 0.5
for only a few occasions in the provided range of values
for number of releases and max_planes.4 We also show the
heatmap version for the successive case with no conserva-
tive releasing, i.e. max_planes = ∞, at the top of Fig. 7b for
comparison. And as shown, for successively released partial

4The uneven quantized levels follows our set ranges in §6.2

(e) Average Π2 over all releases

(f) Average Π2 over varying number of planes
Figure 8: Average INTRA-space privacy of conservatively
released planes over successive releasing (using NN-matcher
attacker)

spaces with radius r = 0.5m, the average inter-space privacy
Π1 drops below 0.5 after 31 or more releases. But, with con-
servative releasing, we can release up to 51 successive partial
releases with max_planes ≤ 23 for Π1 ≥ 0.5. Furthermore,
if we average Π1(r = 0.5m) over all releases and observe it
relative to max_planes, average Π1(r = 0.5m) does not go
below 0.5 if max_planes ≤ 29 as shown in Fig. 7e.

On the other hand, for r = 1.0m, Figs. 7c and 7d shows that
the decrease in Π1 is primarily due to max_planes. Aside
from the few occasions shown in Fig. 7d that Π1 ≥ 0.5 with
lower number of releases, we can observe that generally
Π1 < 0.5 for max_planes ≥ 13. We also show the successive
case with max_planes = ∞ for r = 1.0m which shows that
right after the first release we have Π1 < 0.5. Furthermore, as
shown in Fig. 7e, the average Π1(r = 1.0m) over all releases
goes below 0.5 if the max_planes ≥ 13. Thus, for r ≤ 1.0,
there can be at most 11 planes released regardless of the
number of successive partial releases so that Π1(r = 1.0m) ≥

10

1357911131517192123252729Max number of planes0.00.250.50.751.0INTER-space Privacyr = 0.5r = 1.01357911131517192123252729Max number of planes02468INTRA-space Privacyr = 0.5r = 1.011121314151617181Number of releases02468INTRA-space Privacyr = 0.5r = 1.0Figure 9: QoS Q vs varying radius r . The average Q over all
test radii, i.e. 0.25 ≤ r ≤ 4.0m, is 0.120 ± 0.007, while there is a
medium positive correlation, i.e. ρ = 0.71, between Q and r .
0.5. Arguably, having a maximum limit of 11 planes is already
adequate for most MR functionalities.

We also present the intra-space privacy with conserva-
tive releasing in Fig. 8 with quantized heatmaps. Figs. 8a-8b
and 8c-8d shows differences in Π2 for r = 0.5 and 1.0m,
but, if we are to average it over all releases as shown in
Fig. 8e, the plots of Π2(r = 0.5m) and Π2(r = 1.0m) over-
lap and plateaus at roughly ∼ 3.085m. The difference being
only at max_planes ≤ 3 where Π2(r = 1.0m) drops faster
Π2(r = 0.5m) from max_planes = 1 to 3 before eventually
plateauing at similar levels.

On the other hand, if we are to average Π2 over max_planes,
we see that Fig. 8f reflects the behavior of Π2,NN shown in
Fig. 6-right. Both figures show increasing Π2 as we increase
the number of releases. In Fig. 8f, it is more evident for
Π2(r = 1.0) which starts to increase immediately after 1
release, while Π2(r = 0.5) increases only after 31 releases.

Takeaway. Conservative releasing of generalized planes
provide INTER-space privacy: for r = 0.5, if we are to release up
to 17 planes, an adversary will misidentify a space at least half
of the time regardless of the number of releases, and will be off
by at least 3.0m in INTRA-space inference for these infrequent
occasions of INTER-space success. We can get similar privacy
for r = 1.0 with up to 11 plane releases.

7.4 Utility in terms of QoS
Plane-fitting generalizations contribute variations to the
released point clouds from true spaces. Fig. 9 shows the
computed average QoS Q based on Eq. 5 (with coefficients
α, β = 0.5) for RANSAC generalized spaces with varying
radii r . We also show the plots of two components used to
compute the overall Q: the normal QoS, and the point-wise
QoS.5 As shown, the overall Q very slowly increases (but
not consistently) as we increase the radius. The increase can
be attributed more to the normal QoS component which
has medium positive correlation, i.e. ρ = 0.74, with radius r .
While the overall Q has a medium positive correlation, i.e.
ρ = 0.71, with r , and, if we average Q over all radii, we get
¯Q = 0.120±0.007 which has less than 10% standard deviation.
This slight increase is attributed to how more information, i.e.
larger radius, introduces additional errors, albeit minimally,
especially on the normals during generalization.

5A normal QoS of 0.2 means that the resulting normals after generalization
are on average about 18◦ off from the original normals.

11

(a) 3D plot (r = 0.5)

(b) Heatmap (r = 0.5)

(c) 3D plot (r = 1.0)

(d) Heatmap (r = 1.0)

Figure 10: Average QoS Q of conservatively released planes
over successive releasing

Fig. 10 shows the Q values for conservatively released
planes over successively released partial spaces. Here, re-
gardless of r , we can see that Q decreases as we increase
max_planes. Consequently, if we fix max_planes, more suc-
cessive partial releases increases Q. Intuitively, more infor-
mation should, i.e. more releases, should decrease Q but
becasue we are also limiting the maximum allowable num-
ber of planes to be released, this introduces errors and thus
increasing Q.

Let’s look at the sample shown earlier in Fig. 3. As shown
in Fig. 3c, if we set max_planes = 3, this means that the
succeeding releases will be forced on to these previously
released 3 planes. Other structures present on these succeed-
ing releases that cannot be subsumed by these planes will
effectively not be released, and, thus, contribute to the QoS
calculation. Example of these other structures are the planes
shown in Fig. 3b but not present in Fig. 3c. Furthermore, the
increasing Q with increasing radius is also corroborated by
Fig. 10 which shows that the values for r = 0.5 are less than
or equal to that of r = 1.0 for the same number of releases
or max_planes.

Takeaway. To achieve better QoS with generalized spaces,
smaller size or radius is preferred. And, if conservative releas-
ing is applied, good Q, i.e. < 0.2, can be achieved with lower
number of releases.

8 DISCUSSION

Challenge with point cloud data. Point clouds are un-
ordered and variable-sized data structures which makes com-
putation of, say, mutual information challenging. This poses
a further challenge in directly applying well-studied privacy
frameworks such as differentially private mechanisms. Thus,

0.00.51.01.52.02.53.03.54.0Partial Radius0.000.050.100.150.200.250.300.35Average QoSoverall QoSnormal QoSpoint-wise QoS11121314151617181Releases1591317212529Max number of planes0.00.20.40.60.81.0Average QoS11121314151617181Releases1591317212529Max number of planes0.00.20.40.60.81.0Average QoS3D lidar data. Now, conversely, the protection methods we
have designed and developed can be applied on these other
platforms. Of course, the figuring out a balance between
functional utility, say, for a self-driving car, and privacy will
still be a significant a challenge.

Improving the attackers. It is not the focus of this work
to develop the best attacker. However, countermeasures are
only as good as the best attack it can defend against. Thus, it
is a worthwhile effort to explore improvements on the attack
methods as future work such as an optimal submap generator
for pointnetvlad. Likewise, the intrinsic descriptors used
by NN-matcher can be transformed to a more discriminative
global descriptor using NetVLAD to improve NN-matcher’s
intra-space performance. Moreover, pointnetvlad can po-
tentially be improved by replacing the PointNet layer with
the updated PointNet++ [24].

9 CONCLUSION AND FUTURE WORK
Currently, MR services are provided with full and indefinite
access to the 3D spatial information, i.e. 3D point cloud data,
captured by MR-capable devices. In this work, we highlight
the risks associated to the indefinite access of applications
to these 3D point cloud data. We have demonstrated how a
descriptor-based and a deep neural network-based inferrers
can be used for 3D spatial inference. Using these inferrers, we
can recognize the current space of a user using the 3D point
cloud information captured by their MR device. Furthermore,
we have extended the capability of the inferrers to also reveal
the exact location within the space of the user. Our validation
results reveal that, unsurprisingly, raw 3D point cloud data
readily reveals the specific location of spaces with average
intra-space error of as low as 1m. And we reiterate that naive
spatial generalizations, i.e. using the RANSAC plane-fitting
algorithm, is still inadequate. Therefore, it is necessary to
provide users with further protection.

In this work, we have demonstrated that we can enhance
privacy protection with plane generalizations by conserva-
tively releasing the generalized planes provided to applica-
tions. Our experimental investigation over accumulated data
from successive releases (emulating user movement) shows
that we can reveal up to 11 planes and avoid inter-space in-
ference at least for half of the time for large enough revealed
spaces, i.e. r ≤ 1.0. Specifically, with such very conserva-
tive releases, the success rate of any (inter-space) inferrer
is no better than a random guess. And, for the occasions
that the adversary correctly recognizes the space, the intra-
space location can be off by at least 3 meters. Moreover, we
quantified the privacy improvement in terms of both Π1 and
Π2 by reducing the size of the partial spaces to be revealed.
Consequently, in terms of data utility Q, a smaller size is
preferred to provide good (i.e. low) Q.

Overall, conservative releasing is a viable solution for pro-
tecting spatial privacy of users as they use MR services

(a) r = 0.5

(b) r = 1.0

Figure 11: Intersection map of Q ≤ 0.2 and Π1 ≥ 0.5

in this work, we measured privacy in terms of the errors of
the two-level spatial inference attack described earlier.

Utility vs Privacy. Fig. 11 shows an intersection map
for acceptable Q and Π1, i.e. Q ≤ 0.2 and Π1 ≥ 0.5. For
r = 0.5m, as shown in Fig.11a, the good intersection regions
are primarily dictated by good Q, i.e. up to 51 releases and
up to 23 max_planes. Contrariwise, for r = 1.0m, as shown
in Fig.11b, the good intersection regions are very scarce
and are primarily dictated by good Π1; specifically, up to
13 max_planes and up to 26 releases but lower max_planes
worsen Q. Thus, for r = 1.0, if we prioritize privacy over
utility/QoS, then we can stick to max_planes ≤ 11 but no
limit in the number of successive releases. But, if we want
better Q, we can reduce the size of the space, say, r = 0.5m,
and enjoy more freedom in the number of releases.

Functional Utility. So far, we have only been focused
on data utility. Specifically, we assume that as long as the
revealed generalized space has a low Q, we hypothesize that
the same original functionality can still be provided with
the user perceiving minimal to no difference. For a great
deal of MR applications requiring “anchoring” to surfaces, as
long as the plane generalizations are kept aligned with their
corresponding true surfaces, the user may indeed perceive
minimal to no difference. For the case when a specific target,
e.g. a 2D image marker or 3D object, is the desired anchor,
the position (and orientation) of this target can be provided
as either a small plane generalization or as a point anchor
which can be used together with the other plane generaliza-
tions. However, it would also be worthwhile as future work
to implement the proposed mechanism for protection over
various MR applications and use cases, and measure actual
user satisfaction or Quality-of-Experience (QoE).

Extensions to other 3D data sources. Furthermore, we
have only focused on 3D point cloud data captured by MR
platforms. However, there are other platforms and use cases
in which 3D data is used. For example, 3D lidar data captured
and used in geo-spatial work, by self-driving cars, and now by
many other applications on recent smartphones. As we have
mentioned, the methods we have used for spatial attacks are
adapted from place recognition methods originally used for

12

11121314151617181Releases1591317212529Max number of planesQ>0.2 or 1<0.5     Q0.2 and 10.5   11121314151617181Releases1591317212529Max number of planesQ>0.2 or 1<0.5     Q0.2 and 10.5   while providing measurable privacy guarantees or thresholds.
Plane generalization are already–or can easily be–implemented
in most MR platforms. Thus, what remains is the implemen-
tation of conservative plane releasing to provide protection
in these MR platforms. In our future work, we aim to de-
velop a software library for mobile devices that includes the
mechanisms proposed in this work which facilitates MR app
designers to develop privacy-aware MR applications.

AVAILABILITY
The source codes of our experiments is available at https:
//github.com/spatial-privacy/3d-spatial-privacy.

APPENDIX: THE NN-MATCHER
Intrinsic 3D descriptors. Features that describe and discrimi-
nate among 3D spaces are usually used for inference mod-
elling, and there are considerable features in 3D point clouds
for it to be directly used as a 3D descriptor. However, point
cloud extractions of the same space may produce translated
and/or rotated versions of each other; thus, for a machine
to recognize that these point clouds are of the same space,
machine understanding has to be translation- and rotation-
invariant. To provide invariance, we utilize an existing 3D
description algorithm called spin image (SI) descriptors [18].
The SI description algorithm only uses the normal vectors

Algorithm 1: Inter-space matching algorithm
Data: ;
{ {f1, k1 }, {f2, k2 }, ..., {fI , kI } } the ensemble set of information from
reference spaces where {fi, ki } is the set of key point-descriptor pairs for
reference space i;
{fq, kq } is the set of key point-descriptor pairs for a query space;
Result: i∗ candidate reference space, and {kq (cid:55)→ k1∗ } the matched query and

reference key points
1 J a 3D feature matcher, i.e. 2nn matcher
2 T is NNDR threshold = 0.9
3 Ei,q a 2d-array of 2nn indices
4 Di,q a 2d-array of 2nn distances // both E and D have shape Q×2, where

Q is the length of fq

5 S = {s1, s2, ... }, the global matching scores of reference spaces i
6 K = { {kq (cid:55)→ k1 }, {kq (cid:55)→ k2 }, ... } are the set-pairs of matched query key

points kq with the key points ki of every reference space i

7 for {fi, ki } ← {f1, k1 } to {fI , kI } do
8

Ei,q, Di,q = J(fi, fq )
Di,q ← max_normalize(Di,q )
D ← Di,q [:, 0]/Di,q [:, 1] // the array of the same length as fq
containing the NNDR for every query feature with its
top-2 matches among the reference features

(optional strict step; applied in [7])Ei,T ⊂ Ei,q , where D1 < T // the

subset of indices with NNDR<T

{kq ⊂ kq, ki ⊂ ki }, where kq (cid:55)→ ki // the unique key point

matches

Ei ⊂ Ei,T of {kq, ki } // the subset indices corresponding to

the unique key point matches

9

10

11

12

13

14

15

K ← K + {kq, ki }
si = (1 − mean(D[Ei ])) · |Ei |
|fq |
S ← S + si
16
17 i∗ = argmax(S)

associated with the points. Moreover, it is not reliant on cur-
vature or any other second-order or higher-order structural
information.

The original spin image descriptor algorithm does not
have a key point selection process. For our implementation,
we implement a pseudo key point selection process by using
a sub-sampled point cloud space (sampling factor of 5) as our
chosen key points instead of the complete point cloud. This
reduces the likelihood of having neighbouring points having
exactly the same descriptors. Then, we compute the spin im-
age descriptors made up of cylindrical bins relative to a local
cylindrical coordinate system around each key point. The
spin comes from the fact that spinning the key point about
its normal will have no effect on the computed descriptor;
thus, it is rotation-invariant about its normal. Consequently,
the spinning effect reduces the impact of variations within
that spin which makes SI descriptors more robust compared
to other descriptors which are reliant on second-order infor-
mation such as curvatures. Furthermore, as described in §5.2,
plane generalization removes curvatures as well as other
second- and higher-order information which makes its use
as a geometric description information impractical. It has
been shown that, indeed, SI descriptors are more robust when
spaces are plane generalized than a similar algorithm, i.e. self
similarity [15], which requires curvature information [7].
Inter-space inference. A matching function maps two sets of
features { fa,0, fa,1, ...} and { fb,0, fb,1, ...} of spaces Sa and Sb ,
respectively. To accept a match, we get the nearest neighbor
distance ratio (NNDR) of the features like so: d (fa, 1, fb, 1)
d (fa, 1, fb, 2) <
threshold, where d(·) is some distance measure in the fea-
ture space, and descriptor fb,1 is the nearest neighbor of
descriptor fa,1 while fb,2 is the second nearest neighbor. If
the NNDR falls below a set threshold, then {ka,1, fa,1} and
{kb,1, fb,1} is an acceptable key point-feature pairs.

For our implementation, we use the Euclidean nearest
neighbors, i.e. 2-nn, for the feature distance function d(·).
Afterwards, the NNDR of the two best matching reference
descriptors for every query descriptor from the reference
spaces are computed. Then, to determine the best matching
space for inter-space inference, a weighted score is computed
based on the product on the product of the percentage of
uniquely indexed lowest ratio matches per candidate space,
and that of the difference from 1 of the mean of the NNDRs
of the unique (key point-wise) matches. The reference space,
with the highest score–akin to the argmax operation of Eq.
1a–is the best candidate space for the query space. In this
work, we utilized a relaxed version of the inference method
utilized in [7] which originally only accepts the uniquely
matched key point pairs with NNDR < 0.9 before computing
the weighted score. Alg. 1 presents the pseudo-code for inter-
space inference.

To determine the best matching space for inter-space in-
ference, we, first, get the 2 nearest neighbors of a query

13

feature among the reference features. Line 8 in both Alg. 1
shows this 2nn distance computation in the feature space
which produces two arrays: Ei,q contains indices of the 2nn
descriptors from reference space i, while Di,q contains the
distance values. Afterwards, Di,q is maximum-normalized
(line 9) before we compute the NNDR (line 10). Originally,
in [7], an optional step (line 11) trims the 2nn matches and
only keeps those below the set threshold T. Then, the set
of matches are further trimmed (line 12, and 13) by only ac-
cepting the matches with unique key point matches; that is,
query key points are matched to unique reference key points.
If there are query key points matched to the same reference
key points, we keep the pair with the lowest NNDR. The
resulting matches are kept (line 14), while the global match-
ing score is computed as shown in line 15. The reference
space with the highest score is picked as the inter-space can-
didate (line 17). The key point pairs of the resulting matched
space is provided to the intra-space matcher to determine
the intra-space location of the user.

Intra-space inference. The resulting keypoint matches are
fed to the intra-space matcher as shown in Alg. 2 to deter-
mine the intra-space location of the user. We trim the key
point pairs by only accepting those whose feature NNDR
are below the set threshold T1 (line 4). Then, we find the
fully-connected graphs of both query (line 5) and matched
reference (line 6) key points; the key points are the vertices

Algorithm 2: Intra-space matching
Data: {kq (cid:55)→ k∗ } the matched query and reference key points
D∗ the NNDR ratios of the matched key points
Result: c∗ centroid of the matched reference key points ki ∗

1 G(·) a graph
2 T1 is NNDR threshold = 0.9
3 T2 is geometric similarity threshold = 0.95
4 {kq, 1 ⊂ kq, ki∗, 1 ⊂ ki ∗ }, where D∗ < T1 // For the Strict-NN, this

step has already been performed

5 Gq, 1 = G(kq, 1) // complete graph with elements of key point

positions pk ∈ kq, 1(∈ R3) as vertices, and edges defined by the
point-to-point distance vector ˆv ∈ R3.

6 G∗, 1 = G(k∗, 1) // we get the same for the reference key points; in
matrix form, the dimensions of Gq, 1 and G∗, 1 are the same and
their elements should be consistently ordered following their
matched key points
7 Vq ← | |Edges(Gq, 1)| |L2,

V∗ ← | |Edges(G∗, 1)| |L2 // we get the L2-norms of the distance
vectors which are the edges of the complete graphs

8 Aq ← internal_angles(Edges(Gq, 1)),

A∗ ← internal_angles(Edges(G∗, 1)) // we get the internal
angles formed by the distance vectors with each other
9 Sd = exp(−0.5 ∗ |Vq − V∗ |) // we compute the distance similarity
using an exponential function with rate = −0.5; Sd ∈ [0, 1]
with 1 being the highest similarity

10 Sϕ = cosine_similarity(Aq, A∗) // we compute the cosine

similarity of the two sets of internal angles; Sϕ ∈ [0, 1] with
1 being the highest similarity

11 S = Sd · Sϕ // combined product similarity measure
12 {kq, 2 ⊂ kq, 1, k∗, 2 ⊂ k∗, 1 }, where S ≥ T2 // only keep the key point

pairs with S ≥ T2

13 c∗ = centroid(k∗, 2)

while the edges are defined by the point-to-point vector
connecting the key points. We compute the distances using
L2-norm of the point-to-point distance vectors (line 7). We
also compute the internal angles (using cosine similarity)
formed by the vectors (line 8). We compute a distance simi-
larity measure (line 9) Sd , and an angular similarity measure
(line 10) Sϕ . The product of the two measures forms the com-
bined similarity metric S (line 11). The vertices, i.e. key point
pairs, with an acceptable S, i.e. ≥ 0.95, are the accepted key
point pairs.The intra-space location is the centroid of the
accepted matched reference key points.

REFERENCES
[1] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya
Mironov, Kunal Talwar, and Li Zhang. 2016. Deep learning with
differential privacy. In Proceedings of the 2016 ACM SIGSAC Conference
on Computer and Communications Security. ACM, 308–318.

[2] Paarijaat Aditya, Rijurekha Sen, Peter Druschel, Seong Joon Oh, Ro-
drigo Benenson, Mario Fritz, Bernt Schiele, Bobby Bhattacharjee, and
Tong Tong Wu. 2016. I-pic: A platform for privacy-compliant image
capture. In Proceedings of the 14th Annual International Conference on
Mobile Systems, Applications, and Services. ACM, 235–248.

[3] Relja Arandjelovic, Petr Gronat, Akihiko Torii, Tomas Pajdla, and Josef
Sivic. 2016. NetVLAD: CNN architecture for weakly supervised place
recognition. In Proceedings of the IEEE conference on computer vision
and pattern recognition. 5297–5307.

[4] Stefano Baldassi, Tadayoshi Kohno, Franziska Roesner, and Moqian
Tian. 2018. Challenges and New Directions in Augmented Reality,
Computer Security, and Neuroscience–Part 1: Risks to Sensation and
Perception. arXiv preprint arXiv:1806.10557 (2018).

[5] Michael Bosse and Robert Zlot. 2009. Keypoint design and evaluation
for place recognition in 2D lidar maps. Robotics and Autonomous
Systems 57, 12 (2009), 1211–1224.

[6] Michael Bosse and Robert Zlot. 2013. Place recognition using keypoint
voting in large 3D lidar datasets. In 2013 IEEE International Conference
on Robotics and Automation. IEEE, 2677–2684.

[7] Jaybie A de Guzman, Kanchana Thilakarathna, and Aruna Seneviratne.
2019. A First Look into Privacy Leakage in 3D Mixed Reality Data.
In European Symposium on Research in Computer Security. Springer,
149–169.

[8] Jaybie A de Guzman, Kanchana Thilakarathna, and Aruna Seneviratne.
2019. SafeMR: Privacy-aware Visual Information Protection for Mobile
Mixed Reality. In 2019 IEEE 41st Conference on Local Computer Networks
(LCN). IEEE.

[9] Jaybie A. De Guzman, Kanchana Thilakarathna, and Aruna Senevi-
ratne. 2019. Security and Privacy Approaches in Mixed Reality: A
Literature Survey. ACM Comput. Surv. 52, 6, Article 110 (Oct. 2019),
37 pages. https://doi.org/10.1145/3359626

[10] Cynthia Dwork, Aaron Roth, et al. 2014. The algorithmic foundations of
differential privacy. Foundations and Trends® in Theoretical Computer
Science 9, 3–4 (2014), 211–407.

[11] Lucas Silva Figueiredo, Benjamin Livshits, David Molnar, and Margus
Veanes. 2016. Prepose: Privacy, Security, and Reliability for Gesture-
Based Programming. In Security and Privacy (SP), 2016 IEEE Symposium
on. IEEE, 122–137.

[12] Martin A Fischler and Robert C Bolles. 1981. Random sample consen-
sus: a paradigm for model fitting with applications to image analysis
and automated cartography. Commun. ACM 24, 6 (1981), 381–395.
[13] Batya Friedman and Peter H Kahn Jr. 2000. New directions: A Value-
Sensitive Design approach to augmented reality. In Proceedings of
DARE 2000 on designing augmented reality environments. ACM, 163–
164.

14

symposium on security and privacy. IEEE, 247–262.

[32] Jiayu Shu, Rui Zheng, and Pan Hui. 2016. Cardea: Context-Aware
Visual Privacy Protection from Pervasive Cameras. arXiv preprint
arXiv:1610.00889 (2016).

[33] Pablo Speciale, Johannes L Schonberger, Sing Bing Kang, Sudipta N
Sinha, and Marc Pollefeys. 2019. Privacy preserving image-based
localization. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition. 5493–5503.

[34] Julian Steil, Marion Koelle, Wilko Heuten, Susanne Boll, and Andreas
Bulling. 2018. PrivacEye: Privacy-Preserving First-Person Vision Using
Image Features and Eye Movement Analysis. CoRR abs/1801.04457
(2018). arXiv:1801.04457 http://arxiv.org/abs/1801.04457

[35] Latanya Sweeney. 2002. k-anonymity: A model for protecting privacy.
International Journal of Uncertainty, Fuzziness and Knowledge-Based
Systems 10, 05 (2002), 557–570.

[36] Mikaela Angelina Uy and Gim Hee Lee. 2018. PointNetVLAD: Deep
Point Cloud Based Retrieval for Large-Scale Place Recognition. In The
IEEE Conference on Computer Vision and Pattern Recognition (CVPR).
[37] John Vilk, David Molnar, Benjamin Livshits, Eyal Ofek, Chris Rossbach,
Alexander Moshchuk, Helen J Wang, and Ran Gal. 2015. Surroundweb:
Mitigating privacy concerns in a 3d web browser. In Security and
Privacy (SP), 2015 IEEE Symposium on. IEEE, 431–446.

[38] John Vilk, David Molnar, Eyal Ofek, Chris Rossbach, Ben
Livshits, Alexander Moshchuk, Helen J. Wang, and Ran Gal.
2014. Least Privilege Rendering in a 3D Web Browser.
(February
https://www.microsoft.com/en-us/research/publication/
2014).
least-privilege-rendering-3d-web-browser/ Microsoft Research
Technical Report MSR-TR-2014-25.

[39] Isabel Wagner and David Eckhoff. 2018. Technical Privacy Metrics: A
Systematic Survey. ACM Comput. Surv. 51, 3, Article 57 (June 2018),
38 pages. https://doi.org/10.1145/3168389

[40] Eisa Zarepour, Mohammadreza Hosseini, Salil S Kanhere, and Arcot
Sowmya. 2016. A context-based privacy preserving framework for
wearable visual lifeloggers. In Pervasive Computing and Communica-
tion Workshops (PerCom Workshops), 2016 IEEE International Conference
on. IEEE, 1–4.

[14] Olli I Heimo, Kai K Kimppa, Seppo Helle, Timo Korkalainen, and Teijo
Lehtonen. 2014. Augmented reality-Towards an ethical fantasy?. In
Ethics in Science, Technology and Engineering, 2014 IEEE International
Symposium on. IEEE, 1–7.

[15] Jing Huang and Suya You. 2012. Point cloud matching based on 3D
self-similarity. In Computer Vision and Pattern Recognition Workshops
(CVPRW), 2012 IEEE Computer Society Conference on. IEEE, 41–48.
[16] Suman Jana, David Molnar, Alexander Moshchuk, Alan M Dunn, Ben-
jamin Livshits, Helen J Wang, and Eyal Ofek. 2013. Enabling Fine-
Grained Permissions for Augmented Reality Applications with Recog-
nizers.. In USENIX Security.

[17] Suman Jana, Arvind Narayanan, and Vitaly Shmatikov. 2013. A Scan-
ner Darkly: Protecting user privacy from perceptual applications. In
Security and Privacy (SP), 2013 IEEE Symposium on. IEEE, 349–363.

[18] Andrew E Johnson and Martial Hebert. 1999. Using spin images for
efficient object recognition in cluttered 3D scenes. IEEE Transactions
on Pattern Analysis & Machine Intelligence 5 (1999), 433–449.

[19] Balachander Krishnamurthy and Craig E Wills. 2010. Privacy leakage
in mobile online social networks. In Proceedings of the 3rd Wonference
on Online social networks. USENIX Association, 4–4.

[20] Ang Li, Qinghua Li, and Wei Gao. 2016. PrivacyCamera: Coopera-
tive Privacy-Aware Photographing with Mobile Phones. In Sensing,
Communication, and Networking (SECON), 2016 13th Annual IEEE In-
ternational Conference on. IEEE, 1–9.

[21] Frank McSherry and Kunal Talwar. 2007. Mechanism design via dif-
ferential privacy. In Foundations of Computer Science, 2007. FOCS’07.
48th Annual IEEE Symposium on. IEEE, 94–103.

[22] Francesco Pittaluga, Sanjeev J Koppal, Sing Bing Kang, and Sudipta N
Sinha. 2019. Revealing scenes by inverting structure from motion
reconstructions. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition. 145–154.

[23] Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. 2017. Point-
net: Deep learning on point sets for 3d classification and segmentation.
In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition. 652–660.

[24] Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J Guibas. 2017.
Pointnet++: Deep hierarchical feature learning on point sets in a metric
space. In Advances in neural information processing systems. 5099–5108.
[25] Nisarg Raval, Animesh Srivastava, Kiron Lebeck, Landon Cox, and
Ashwin Machanavajjhala. 2014. Markit: Privacy markers for protect-
ing visual secrets. In Proceedings of the 2014 ACM International Joint
Conference on Pervasive and Ubiquitous Computing: Adjunct Publication.
ACM, 1289–1295.

[26] Nisarg Raval, Animesh Srivastava, Ali Razeen, Kiron Lebeck, Ashwin
Machanavajjhala, and Lanodn P Cox. 2016. What you mark is what
apps see. In Proceedings of the 14th Annual International Conference on
Mobile Systems, Applications, and Services. ACM, 249–261.

[27] Jingjing Ren, Ashwin Rao, Martina Lindorfer, Arnaud Legout, and
David Choffnes. 2016. Recon: Revealing and controlling pii leaks in
mobile network traffic. In Proceedings of the 14th Annual International
Conference on Mobile Systems, Applications, and Services. ACM, 361–
374.

[28] Franziska Roesner, David Molnar, Alexander Moshchuk, Tadayoshi
Kohno, and Helen J Wang. 2014. World-driven access control for
continuous sensing. In Proceedings of the 2014 ACM SIGSAC Conference
on Computer and Communications Security. ACM, 1169–1181.

[29] Muhamad Risqi U Saputra, Andrew Markham, and Niki Trigoni. 2018.
Visual SLAM and structure from motion in dynamic environments: A
survey. ACM Computing Surveys (CSUR) 51, 2 (2018), 37.

[30] Reza Shokri and Vitaly Shmatikov. 2015. Privacy-preserving deep
learning. In Proceedings of the 22nd ACM SIGSAC conference on com-
puter and communications security. ACM, 1310–1321.

[31] Reza Shokri, George Theodorakopoulos, Jean-Yves Le Boudec, and
Jean-Pierre Hubaux. 2011. Quantifying location privacy. In 2011 IEEE

15

