8
1
0
2

r
a

M
9

]

R
P
.
h
t
a
m

[

2
v
1
9
0
4
0
.
1
0
8
1
:
v
i
X
r
a

Multivariate stochastic delay diﬀerential
equations and CAR representations of
CARMA processes

Andreas Basse-O’Connor, Mikkel Slot Nielsen, Jan Pedersen,
and Victor Rohde
Department of Mathematics
Aarhus University
{basse, mikkel, jan, victor}@math.au.dk

Abstract

In this study we show how to represent a continuous time autoregres-
sive moving average (CARMA) as a higher order stochastic delay diﬀer-
ential equation, which may be thought of as a continuous-time equivalent
of the AR(∞) representation. Furthermore, we show how this representa-
tion gives rise to a prediction formula for CARMA processes. To be used
in the above mentioned results we develop a general theory for multivari-
ate stochastic delay diﬀerential equations, which will be of independent
interest, and which will have particular focus on existence, uniqueness and
representations.

AMS 2010 subject classiﬁcations: 60G05; 60G22; 60G51; 60H05; 60H10

Keywords: multivariate stochastic delay diﬀerential equations; multivariate Ornstein-
Uhlenbeck processes; CARMA processes; FICARMA processes; MCARMA pro-
cesses; noise recovery; prediction; long memory

1 Introduction and main ideas

The class of autoregressive moving averages (ARMA) is one of the most popular
classes of stochastic processes for modeling time series in discrete time. This
class goes back to the thesis of Whittle in 1951 and was popularized in Box
and Jenkins [5]. The continuous time analogue of an ARMA process is called a
CARMA process, and it is the formal solution (Xt)t∈R to the equation

P (D)Xt = Q(D)DZt,

t ∈ R,

(1.1)

where P and Q are polynomials of degree p and q, respectively. Furthermore,
D denotes diﬀerentiation with respect to t, and (Zt)t∈R is a Lévy process, the
continuous time analogue of a random walk. In the following we will assume
that p > q and P (z), Q(z) 6= 0 whenever Re(z) ≥ 0.
In this case one can
give precise meaning to (Xt)t∈R as a causal stochastic process through a state-
space representation as long as (Zt)t∈R has log moments. Lévy-driven CARMA
processes have found many applications, for example, in modeling temperature,
electricity and stochastic volatility, cf. [4, 14, 26]. Moreover, there exists a vast

1

 
 
 
 
 
 
amount of literature on theoretical results for CARMA processes (and variations
of these), and a few references are [6, 7, 8, 9, 18, 19, 25].

It is well-known that any causal CARMA process has a continuous time

moving average representation of CMA(∞) type

Xt =

t

Z

−∞

g(t − u) dZu,

t ∈ R,

see the references above or Section 4.3. This representation may be very conve-
nient for studying many of their properties. A main contribution of our work is
that we obtain a CAR(∞) representation of CARMA processes of the form

R(D)Xt =

∞

Z

0

Xt−uf (u) du + DZt,

t ∈ R,

(1.2)

where R is a polynomial of order p−q and f : R → R is a deterministic function,
both deﬁned through P and Q. Since (Xt)t∈R is p − q − 1 times diﬀerentiable,
see [19, Proposition 3.32], the relation (1.2) is well-deﬁned if we integrate both
sides once. A heuristic argument for obtaining (1.2) from (1.1) is as follows. If
q = 0, Q is constant and (1.2) holds with R = P and f = 0. If q ≥ 1, it is
convenient to rephrase (1.1) in the frequency domain:

P (−iy)
Q(−iy)

F [X](y) = F [DL](y),

y ∈ R.

(1.3)

Using polynomial long division we may choose a polynomial R of order p − q
such that

S(z) := Q(z)R(z) − P (z),

z ∈ C,

is a polynomial of at most order q − 1. Now observe that

P (−iy)
Q(−iy)

F [X](y) =

R(−iy) −

S(−iy)
Q(−iy) (cid:19)
= F [R(D)X](y) − F [f ](y)F [X](y),

F [X](y)

(cid:18)

where f : R → R is the L2 function characterized by F [f ](y) = S(−iy)/Q(−iy)
for y ∈ R. (In fact, we even know that f is vanishing on (−∞, 0) and decays
exponentially fast at ∞, cf. Remark 4.10.) Combining this identity with (1.3)
results in the representation (1.2).

We show in Theorem 4.8 that (1.2) does indeed hold true for any invertible
(Lévy-driven) CARMA process. Similar relations are shown to hold for invert-
ible fractionally integrated CARMA (FICARMA) processes, where (Zt)t∈R is
a fractional Lévy process, and also for their multi-dimensional counterparts,
which we will refer to as MCARMA and MFICARMA processes, respectively.
We use these representations to obtain a prediction formula for general CARMA
type processes (see Corollary 4.11). A prediction formula for invertible one-
dimensional Lévy-driven CARMA processes is given in [10, Theorem 2.7], but
prediction of MCARMA processes has, to the best of our knowledge, not been
studied in the literature.

Autoregressive representations such as (1.2) are useful for several reasons.
To give a few examples, they separate the noise (Zt)t∈R from (Xt)t∈R and hence

2

provide a recipe for recovering increments of the noise from the observed process,
they ease the task of prediction (and thus estimation), and they clarify the
dynamic behavior of the process. These facts motivate the idea of deﬁning a
broad class of processes, including the CARMA type processes above, which all
admit an autoregressive representation, and it turns out that a well-suited class
to study is the one formed by solutions to multi-dimensional stochastic delay
diﬀerential equations (MSDDEs). To be precise, for an integrable n-dimensional
t )T , t ∈ R, with stationary increments
(measurable) process Zt = (Z 1
and a ﬁnite signed n × n matrix-valued measure η, concentrated on [0, ∞), a
t )T , t ∈ R, is a solution to the associated
stationary process Xt = (X 1
MSDDE if it satisﬁes

t , . . . , X n

t , . . . , Z n

dXt = η ∗ X(t) dt + dZt.

(1.4)

By equation (1.4) we mean that

X j

t − X j

s =

n

t

Z

s Z[0,∞)

Xk=1

X k

u−v ηjk(dv) du + Z j

t − Z j
s ,

j = 1, . . . , n,

(1.5)

almost surely for each s < t. This system of equations is an extension of the
stochastic delay diﬀerential equation (SDDE) in [3, Section 3.3] to the multi-
variate case. The overall structure of (1.4) is also in line with earlier literature
such as [16, 20] on univariate SDDEs, but here we allow for inﬁnite delay (η is
allowed to have unbounded support) which is a key property in order to include
the CARMA type processes in the framework.

The structure of the paper is as follows: In Section 2 we introduce the no-
tation used throughout this paper. Next, in Section 3, we develop the general
theory for MSDDEs with particular focus on existence, uniqueness and predic-
tion. The general results of Section 3 are then specialized in Section 4 to various
settings. Speciﬁcally, in Section 4.1 we consider the case where the noise process
gives rise to a reasonable integral, and in Section 4.2 we demonstrate how to
derive results for higher order SDDEs by nesting them into MSDDEs. Finally,
in Section 4.3 we use the above mentioned ﬁndings to represent CARMA pro-
cesses and generalizations thereof as solutions to higher order SDDEs and to
obtain the corresponding prediction formulas.

2 Notation

Let f : R → Cm×k be a measurable function and µ a k × n (non-negative)
matrix measure, that is,

µ = 


where each µjl is a measure on R. Then, we will write f ∈ Lp(µ) if






µ11
...
µk1

· · · µ1n
...
. . .
· · · µkn

|fil(u)|pµlj(du) < ∞

ZR

3

for l = 1, . . . , k, i = 1, . . . , m and j = 1, . . . , n. Provided that f ∈ L1(µ), we set

f (u) µ(du) =

ZR

k

Xl=1






R f1l(u) µl1(du)
...
R
R fml(u) µl1(du)
R

· · ·
. . .
· · ·

R

R f1l(u) µln(du)
...
R fml(u) µln(du)






R

.

(2.1)

If µ is the Lebesgue measure, we will suppress the dependence on the measure
and write f ∈ Lp, and in case f is measurable and bounded Lebesgue almost
everywhere, f ∈ L∞. For two (matrix) measures µ+ and µ− on R, where at least
one of them are ﬁnite, we call the set function µ(B) := µ+(B) − µ−(B), deﬁned
for any Borel set B, a signed measure (and, from this point, simply referred to
as a measure). We may and do assume that the two measures µ+ and µ− are
singular. To the measure µ we will associate its variation measure |µ| := µ++µ−,
and when |µ|(R) < ∞, we will say that µ is ﬁnite. Integrals with respect to µ
are deﬁned in a natural way from (2.1) whenever f ∈ L1(µ) := L1(|µ|). If f is
one-dimensional, respectively if µ is one-dimensional, we will write f ∈ L1(µ) if
f ∈ L1(|µij|) for all i = 1, . . . , k and j = 1, . . . , n, respectively if fij ∈ L1(|µ|)
for all i = 1, . . . , m and j = 1, . . . , k. The associated integral is deﬁned in an
obvious manner.

We deﬁne the convolution at a given point t ∈ R by

f ∗ µ(t) =

ZR

f (t − u)µ(du)

provided that f (t − ·) ∈ L1(µ). In case that µ is the Lebesgue-Stieltjes measure
of a function g : R → Rk×n we will also write f ∗ g(t) instead of f ∗ µ(t) (not
to be confused with the standard convolution between functions). For a given
measure µ we set

D(µ) =

z ∈ C :

(cid:26)

ZR

eRe(z)u |µij |(du) < ∞ for i = 1, . . . , k and j = 1, . . . , n

(cid:27)

and deﬁne its Laplace transform L[µ] as

L[µ]ij (z) =

ZR

ezu µij (du),

for

i = 1, . . . , k, j = 1, . . . , n,

for every z ∈ D(µ). If µ is a ﬁnite measure, we will also refer to the Fourier
transform F [µ] of µ, which is given as F [µ](y) = L[µ](iy) for y ∈ R. If µ(du) =
f (u) du for some measurable function f , we write L[f ] and F [f ] instead. We
will also use that the Fourier transform F extends from L1 to L1 ∪ L2, and it
maps L2 onto L2. We will say that µ has a moment of order p ∈ N0 if

|u|p |µjk|(du) < ∞

ZR

for all j, k = 1, . . . , n. Finally, for two functions f, g : R → R and a ∈ [−∞, ∞],
we write f (t) = o(g(t)), f (t) ∼ g(t) and f (t) = O(g(t)) as t → a if

lim
t→a

f (t)
g(t)

→ 0,

lim
t→a

f (t)
g(t)

= 1

and

respectively.

lim sup
t→a (cid:12)
(cid:12)
(cid:12)
(cid:12)

f (t)
g(t) (cid:12)
(cid:12)
(cid:12)
(cid:12)

< ∞,

4

3 Stochastic delay diﬀerential equations

Consider the general MSDDE in (1.4), where the noise (Zt)t∈R is a measurable
process, which is integrable and has stationary increments. The ﬁrst main result
provides suﬃcient conditions to ensure existence and uniqueness of a solution.
To obtain such results we need to put assumptions on the delay measure η. In
order to do so, we associate to η the function h : D(η) → Cn×n given by

h(z) = −zIn − L[η](z).

(3.1)

where In is the n × n identity matrix.

Theorem 3.1. Let h be given in (3.1) and suppose that det(h(iy)) 6= 0 for all
y ∈ R. Suppose further that η has second moment. Then there exists a function
g : R → Rn×n in L2 characterized by

F [g](y) = h(iy)−1,

the convolution

g ∗ Z(t) := Zt +

ZR

g ∗ η(t − u) Zu du

(3.2)

(3.3)

is well-deﬁned for each t ∈ R almost surely, and Xt = g ∗ Z(t), t ∈ R, is
the unique (up to modiﬁcation) stationary and integrable solution to (1.4). If,
in addition to the above stated assumptions, det(h(z)) 6= 0 for all z ∈ C with
Re(z) ≤ 0 then the solution in (3.3) is casual in the sense that (Xt)t∈R is adapted
to the ﬁltration

{σ(Zt − Zs : s < t)}t∈R.

The solution (Xt)t∈R to (1.4) will very often take form as a (Zt)t∈R-driven

moving average, that is,

Xt =

ZR

g(t − u) dZu

(3.4)

for each t ∈ R (cf. Section 4.1). This fact justiﬁes the notation g ∗ Z introduced
in (3.3). In case n = 1, equation (1.4) reduces to the usual ﬁrst order SDDE, and
then the existence condition becomes h(iy) = −iy − F [η](y) 6= 0 for all y ∈ R,
and the kernel driving the solution is characterized by F [g](y) = 1/h(iy). This
is consistent with earlier literature (cf. [3, 16, 20]).

The second main result concerns prediction of MSDDEs. In particular, the
content of the result is that we can compute a prediction of future values of the
observed process if we are able to compute the same type of prediction of the
noise.

Theorem 3.2. Suppose that det(h(z)) 6= 0 for all z ∈ C with Re(z) ≤ 0 and that
η has second moment. Furthermore, let (Xt)t∈R be the stationary and integrable
solution to (1.4) and let g be given by (3.2). Fix s < t. Then, if we set

ˆZu = E[Zu − Zs | Zs − Zr, r < s],

u > s,

(3.5)

5

it holds that

E[Xt | Xu, u ≤ s]

= g(t − s)Xs +

t

Z
s

g(t − u)η ∗

1

(−∞,s]X

(u) du + g ∗

1

(s,∞)

ˆZ

(t),

(cid:8)

(cid:9)

(cid:8)

(cid:9)

using the notation

η ∗ {1
(cid:0)

j :=
(−∞,s]X}(u)
(cid:1)

n

Xk=1
n

X k

u−v ηjk(dv)

and

Z[u−s,∞)

g ∗ {1
(cid:0)

(s,∞)

ˆZ}(u)
j :=
(cid:1)

Z[0,u−s)

Xk=1

ˆZ k

u−v gjk(dv)

for u > s and j = 1, . . . , n.

Remark 3.3. In case (Zt)t∈R is a Lévy process, the prediction formula in Theo-
rem 3.2 simpliﬁes, since ˆZu = (u − s)E[Z1] and thus

E[Xt | Xu, u ≤ s]

= g(t − s)Xs +

t

Z
s

g(t − u)η ∗

1

(−∞,s]X

(u) du +

(cid:8)

(cid:9)

t

Z
s

g(t − u) du E[Z1],

using integration by parts. Obviously, the formula takes an even simpler form if
E[Z1] = 0. If instead we are in a long memory setting and (Zt)t∈R is a fractional
Brownian motion, we can rely on [15] to obtain ( ˆZu)s<u≤t and then use the
formula given in Theorem 3.2 to compute the prediction E[Xt | Xu, u ≤ s].

In Section 4.3 we use this prediction formula combined with the relation
between MSDDEs and MCARMA processes to obtain a prediction formula for
any invertible MCARMA process.

4 Examples and further results

In this section we will consider several examples of MSDDEs and give some
additional results. We begin by deﬁning what we mean by a regular integrator,
since this makes it possible to have the compact form (3.4) of the solution to
(1.4) in most cases. Next, we show how one can nest higher order MSDDEs in
the (ﬁrst order) MSDDE framework. Finally, we show that invertible MCARMA
processes (and some generalizations) form a particular subclass of solutions to
higher order MSDDEs.

4.1 Regular integrators and moving average representa-

tions

When considering the form of the solution in Theorem 3.1 it is natural to ask
if this can be seen as a moving average of the kernel g with respect to the noise
(Zt)t∈R, that is, if

X j

t =

(cid:18) ZR

g(t − u) dZu

n

=

(cid:19)j

ZR

Xk=1

gjk(t − u) dZ k
u,

t ∈ R,

(4.1)

6

for j = 1, . . . , n. The next result shows that the answer is positive if (Z k
t )t∈R
is a "reasonable" integrator for a suitable class of deterministic integrands for
each k = 1, . . . , n.

Proposition 4.1. Let h be the function given in (3.1) and suppose that, for
all y ∈ R, det(h(iy)) 6= 0. Suppose further that η has second moment and let
(Xt)t∈R be the solution to (1.4) given by (3.3). Finally assume that, for each
k = 1, . . . , n, there exists a linear map Ik : L1 ∩ L2 → L1(P) which has the
following properties:

(i) For all s < t, Ik(1

(s,t]) = Z k

t − Z k
s .

(ii) If µ is a ﬁnite Borel measure on R having ﬁrst moment then

Ik

(cid:18) ZR

fr(t − ·) µ(dr)

(cid:19)

=

ZR

Ik(fr(t − ·)) µ(dr)

(4.2)

almost surely for all t ∈ R, where fr = 1

[0,∞)(· − r) − 1

[0,∞) for r ∈ R.

Then it holds that

X j

t =

n

Xk=1

Ik(gjk(t − ·)),

j = 1, . . . , n,

(4.3)

almost surely for each t ∈ R.
integrator and we will write

· dZ k = Ik.

In this case, (Zt)t∈R will be called a regular

The typical example of a regular integrator is a multi-dimensional Lévy

R

process:

Example 4.2. Suppose that (Zt)t∈R is an n-dimensional integrable Lévy pro-
cess. Then, in particular, each (Z j
t )t∈R is an integrable (one-dimensional) Lévy
u is well-
process, and in [3, Lemma 5.3] it is shown that the integral
deﬁned in the sense of [21] and belongs to L1(P) if f ∈ L1 ∩ L2. Moreover, the
stochastic Fubini result given in [1, Theorem 3.1] implies in particular that con-
dition (ii) of Proposition 4.1 is satisﬁed, which shows that (Zt)t∈R is a regular
integrator and that (4.1) holds.

R f (u) dZ j
R

We will now show that a class of multi-dimensional fractional Lévy processes
can serve as regular integrators as well (cf. Example 4.4 below). Fractional noise
processes are often used as a tool to incorporate (some variant of) long memory
in the corresponding solution process. As will appear, the integration theory
for fractional Lévy processes we will use below relies on the ideas of [17], but
is extended to allow for symmetric stable Lévy processes as well. For more on
fractional stable Lévy processes, the so-called linear fractional stable motions,
we refer to [22, p. 343]. First, however, we will need the following observation:

Proposition 4.3. Let f : R → R be a function in L1 ∩ Lα for some α ∈ (1, 2].
Then the right-sided Riemann-Liouville fractional integral

I β
−f : t 7→

∞

1
Γ(β) Z
t

f (u)(u − t)β−1 du

(4.4)

is well-deﬁned and belongs to Lα for any β ∈ (0, 1 − 1/α).

7

Example 4.4. Let α = (α1, . . . , αn) with αj ∈ (1, 2] and f = (fjk) : R → Rn×n
be a function such that fjk ∈ L1 ∩ Lαk for j, k = 1, . . . , n. Consider an n-
dimensional Lévy process (Lt)t∈R where its j-th coordinate is symmetric αj-
stable if αj ∈ (1, 2) and mean zero and square integrable if αj = 2. Then, for
a given vector β = (β1, . . . , βn) with βj ∈ (0, 1 − 1/αj) for j = 1, . . . , n the
corresponding fractional Lévy process (Zt)t∈R with parameter β is deﬁned as

Z j

t =

I βj
− [1

(−∞,t] − 1

(−∞,0]]

(u) dLj
u

ZR (cid:0)

1

=

(t − u)βj

(cid:1)
+ − (−u)βj

+

dLj
u

Γ(1 + βj) ZR (cid:2)
for t ∈ R and j = 1, . . . , n, and where x+ = max{x, 0}.
In light of Propo-
sition 4.3, this deﬁnition makes it natural to deﬁne the integral of a function
f : R → R in L1 ∩ Lαj (particularly in L1 ∩ L2) with respect to (Z j

(cid:3)

t )t∈R as

f (u) dZ j

u =

I βj
− f

(u) dLj
u
(cid:1)

ZR

ZR (cid:0)
for j = 1, . . . , n. Note that the integral belongs to L2(P) for αj = 2 and to
Lγ(P) for any γ < αj if αj ∈ (1, 2). Using Proposition 4.3 and the stochastic
Fubini result given in [1, Theorem 3.1] for (Lj
t )t∈R it is straightforward to verify
that assumption (ii) of Proposition 4.1 is satisﬁed as well, and thus (Zt)t∈R is
a regular integrator and the solution (Xt)t∈R to (1.4) takes the moving average
form (4.1).

At this point it should be clear that the conditions for being a regular inte-
grator are mild, hence they will, besides the examples mentioned above, also be
satisﬁed for a wide class of semimartingales with stationary increments.

4.2 Higher order (multivariate) SDDEs

An advantage of introducing the multivariate setting (1.4) is that we can nest
higher order MSDDEs in this framework. Eﬀectively, as usual and as will be
demonstrated below, it is done by increasing the dimension accordingly.

Let ̟0, ̟1, . . . , ̟m−1 be (entrywise) ﬁnite n × n measures concentrated on
[0, ∞) which all admit second moment, and let (Zt)t∈R be an n-dimensional
integrable stochastic process with stationary increments. For convenience we
will assume that (Zt)t∈R is a regular integrator in the sense of Proposition 4.1.
We will say that an n-dimensional stationary, integrable and measurable process
(Xt)t∈R satisﬁes the corresponding m-th order MSDDE if it is m − 1 times
diﬀerentiable and

dX (m−1)
t

=

m−1

Xj=0

̟j ∗ X (j)(t) dt + dZt

(4.5)

where (X (j)
to t. By (4.5) we mean that

t

)t∈R denotes the entrywise j-th derivative of (Xt)t∈R with respect

X (m−1)
t
(cid:0)

m−1

n

t

k

−

X (m−1)

s

k

=

(cid:1)

(cid:0)

(cid:1)

Xj=0

Xl=1

Z
s Z[0,∞) (cid:0)

X (j)
u−v

(̟j)kl(dv) du + Z k

t − Z k
s

l

(cid:1)

8

for k = 1, . . . , n and each s < t almost surely. Equation (4.5) corresponds to
the mn-dimensional MSDDE in (1.4) with noise (0, . . . , 0, Z T

t )T ∈ Rmn and

η =

0
Inδ0
0
Inδ0
0
0
...
...
...
0
0
0
̟0 ̟1 ̟2










0
· · ·
0
· · ·
...
. . .
· · ·
Inδ0
· · · ̟m−1

.










(4.6)

(If n = 1 then η = ̟0.) With η given by (4.6) it follows that

m−1

D(η) =

D(̟j)

\j=0

and



h(z) = −

Inz
0
...
0

In
Inz
...
0

L[̟0](z) L[̟1](z)








0
In
. . .
· · ·
· · · L[̟m−2](z)

· · ·
· · ·
. . .
Inz

0
0
...
In
Inz + L[̟m−1](z)










for z ∈ D(η). In general, we know from Theorem 3.1 that a solution to (4.5)
exists if det(h(iy)) 6= 0 for all y ∈ R, and in this case the unique solution is
given by

Xt =

ZR

g1m(t − u) dZu,

t ∈ R,

(4.7)

where F [g1m] is characterized as entrance (1, m) in the n×n block representation
of h(i·)−1. In other words, if ej denotes the j-th canonical basisvector of Rm
and ⊗ the Kronecker product,

F [g1m](y) = (e1 ⊗ In)T h(iy)−1(em ⊗ In)

for y ∈ R. However, due to the particular structure of η in (4.6) we can simplify
these expressions:

Theorem 4.5. Let the setup be as above. Then it holds that

det(h(z)) = det

(cid:18)

m−1

In(−z)m −

L[̟j](z)(−z)j

Xj=0

(cid:19)

(4.8)

for all z ∈ D(η), and if det(h(iy)) 6= 0 for all y ∈ R, there exists a unique
solution to (4.5) and it is given as (4.7) where g : R → Rn×n is characterized
by

F [g1m](y) =

In(−iy)m −

(cid:18)

m−1

Xj=0

F [̟j](y)(−iy)j

−1

(cid:19)

(4.9)

for y ∈ R. The solution is causal if det(h(z)) 6= 0 whenever Re(z) ≤ 0.

9

Observe that, as should be the case, we are back to the ﬁrst order MSDDE
when m = 1 and (4.8)-(4.9) agree with Theorem 3.1. As we will see in Sec-
tion 4.3 below, one motivation for introducing higher order MSDDEs of the
form (4.5) and to study the structure of the associated solutions, is their rela-
tion to MCARMA processes. However, we start with the multivariate CAR(p)
process, where no delay term will be present, as an example:

Example 4.6. Let P (z) = Inzp + A1zp−1 + · · · + Ap, z ∈ C, for suitable
A1, . . . , Ap ∈ Rn×n. The associated CAR(p) process (Xt)t∈R with noise (Zt)t∈R
can be thought of as formally satisfying P (D)Xt = DZt, t ∈ R, where D denotes
diﬀerentiation with respect to t. Integrating both sides and rearranging terms
gives

dX (p−1)
t

= −

p−1

Xj=0

Ap−jX (j)

t dt + dZt,

t ∈ R,

(4.10)

which is of the form (4.5) with m = p and ̟j = −Ap−jδ0 for j = 0, 1, . . . , p − 1.
Proposition 4.5 shows that a unique solution exists if

det

In(iy)p +

(cid:18)

p−1

Xj=0

Ap−j(iy)j

(cid:19)

= det(P (iy)) 6= 0

for all y ∈ R, and in this case F [g1m](y) = P (−iy)−1 for y ∈ R. This agrees
with the rigorous deﬁnition of the CAR(p) process, see e.g. [19]. In case p = 1,
(4.10) collapses to the multivariate Ornstein-Uhlenbeck equation

dXt = −A1Xt dt + dZt,

t ∈ R,

and if the eigenvalues of A1 are all positive, it is easy to check that g1m(t) =
e−A1t1
[0,∞)(t) so that the unique solution (Xt)t∈R is causal and takes the well-
known form

Xt =

t

Z

−∞

e−A1(t−u) dZu

(4.11)

for t ∈ R. Lévy-driven multivariate Ornstein-Uhlenbeck processes have been
studied extensively in the literature, and the moving average structure (4.11) of
the solution is well-known when (Zt)t∈R is a Lévy process. We refer to [2, 23, 24]
for further details. The one-dimensional case where (Zt)t∈R is allowed to be a
general stationary increment process has been studied in [1].

4.3 Relations to MCARMA processes
Let p ∈ N and deﬁne the polynomials P, Q : C → Cn×n by

P (z) = Inzp + A1zp−1 + · · · + Ap
Q(z) = B0 + B1z + · · · + Bp−1zp−1

and

(4.12)

for z ∈ C and suitable A1, . . . , Ap, B0, . . . , Bp−1 ∈ Rn×n. We will also ﬁx q ∈ N0,
q < p, and set Bq = In and Bj = 0 for all q < j < p. It will always be assumed

10

that det(P (iy)) 6= 0 for all y ∈ R. Under this assumption there exists a function
˜g : R → Rn×n which is in L1 ∩ L2 and

F [˜g](y) = P (−iy)−1Q(−iy)

(4.13)

for every y ∈ R. Consequently, for any regular integrator (Zt)t∈R in the sense
of Proposition 4.1, the n-dimensional stationary and integrable process (Xt)t∈R
given by

Xt =

ZR

˜g(t − u) dZu,

t ∈ R,

(4.14)

is well-deﬁned. If it is additionally assumed that det(P (z)) 6= 0 for z ∈ C with
Re(z) ≥ 0 then it is argued in [19] that

˜g(t) = 1

[0,∞)(t)(ep

1 ⊗ In)T eAtE

(4.15)

where



0
0
...
0



0
· · ·
0
In
· · ·
0
...
. . .
. . .
In
0
· · ·
· · · −A2 −A1

A =







with E(z) = E1zp−1 + · · · + Ep chosen such that

−Ap −Ap−1








In
0
...
0

E1
...
Ep

and E = 





,




z 7→ P (z)E(z) − Q(z)zp

is at most of degree p − 1. (Above, and henceforth, we use the notation ek
j for
the j-th canonical basis vector of Rk.) We will refer to the process (Xt)t∈R as
a (Zt)t∈R-driven MCARMA(p, q) process. For instance, when (Zt)t∈R is an n-
dimensional Lévy process, (Xt)t∈R is a (Lévy-driven) MCARMA(p, q) process
as introduced in [19].
If (Lt)t∈R is an n-dimensional square integrable Lévy
process with mean zero, and

Z j

t =

1

Γ(1 + βj) ZR (cid:2)

(t − u)βj

+ − (−u)βj

+

dLj
u,

t ∈ R,

(cid:3)

for βj ∈ (0, 1/2) and j = 1, . . . , n, then (Xt)t∈R is an MFICARMA(p, β, q) pro-
cess, β = (β1, . . . , βn), as studied in [18]. For the univariate case (n = 1), the
processes above correspond to the CARMA(p, q) and FICARMA(p, β1, q) pro-
cess, respectively. The class of CARMA processes has been studied extensively,
and we refer to the references in the introduction for details.

Remark 4.7. Observe that, generally, Lévy-driven MCARMA (hence CARMA)
processes are deﬁned even when (Zt)t∈R has no more than log moments. How-
ever, it relies heavily on the fact that ˜g and (Zt)t∈R are well-behaved enough to
ensure that the process in (4.14) remains well-deﬁned. At this point, a setup
where the noise does not admit a ﬁrst moment has not been integrated in a
framework as general as that of (1.4).

11

In the following our aim is to show that, under a suitable invertibility as-
sumption, the (Zt)t∈R-driven MCARMA(p, q) process given in (4.14) is the
unique solution to a certain (possibly higher order) MSDDE of the form (4.5).
Before formulating the main result of this section we introduce some nota-
tion. To P and Q deﬁned in (4.12) we will associate the unique polynomial
R(z) = Inzp−q+Cp−q−1zp−q−1+· · ·+C0, z ∈ C and C0, C1, . . . , Cp−q−1 ∈ Rn×n,
having the property that

z 7→ Q(z)R(z) − P (z)

(4.16)

is a polynomial of at most order q − 1 (see the introduction for an intuition
about why this property is desirable).

Theorem 4.8. Let P and Q be given as in (4.12), and let (Xt)t∈R be the
associated (Zt)t∈R-driven MCARMA(p, q) process. Suppose that det(Q(z)) 6= 0
for all z ∈ C with Re(z) ≥ 0. Then (Xt)t∈R is the unique solution to (4.5) with

m = p − q, ̟0(du) = −C0δ0(du) + f (u) du,

and ̟j = −Cjδ0,

for 1 ≤ j ≤ m − 1 or, written out,

dX (m−1)
t

= −

m−1

Xj=0

CjX (j)

t dt+

∞

(cid:18) Z
0

X T

t−uf (u)T du

T

(cid:19)

dt + dZt,

(4.17)

where C0, . . . , Cm−1 ∈ Rn×n are deﬁned as in (4.16) above, (X (j)
derivative of (Xt)t∈R, and where f : R → Rn×n is characterized by

t

)t∈R is the j-th

F [f ](y) = R(−iy) − Q(−iy)−1P (−iy).

(4.18)

It follows from Theorem 4.8 that p − q is the order of the (possibly multi-
variate) SDDE we can associate with a (possibly multivariate) CARMA process.
Thus, this seems as a natural extension of [3], where the univariate ﬁrst order
SDDE is studied and related to the univariate CARMA(p, p − 1) process.

Remark 4.9. An immediate consequence of Theorem 4.8 is that we obtain an
inversion formula for (Zt)t∈R-driven MCARMA processes. In other words, it
shows how to recover the increments of (Zt)t∈R from observing (Xt)t∈R. For this
reason it seems natural to impose the invertibility assumption det(Q(z)) 6= 0 for
all z ∈ C with Re(z) ≥ 0, which is the direct analogue of the one for discrete time
ARMA processes (or, more generally, moving averages). It is usually referred
to as the minimum phase property in signal processing. The inversion problem
for (Lévy-driven) CARMA processes has been studied in [3, 6, 9, 10] and for
(Lévy-driven) MCARMA processes in [11]. In both cases a diﬀerent approach,
which does not rely on MSDDEs, is used.

Remark 4.10. Since the Fourier transform F [f ] of the function f deﬁned in
Theorem 4.8 is rational, one can determine f explicitly (e.g., by using the partial
fraction expansion of F [f ]). Indeed, since the Fourier transform of f is of the
same form as the Fourier transform of the solution kernel ˜g of the MCARMA
process we can deduce that

f (t) = (eq

1 ⊗ In)T eBtF,

t ≥ 0,

(4.19)

12

with



B =

0
0
...
0

In
0
...
0

· · ·
· · ·
. . .
0

0
In
. . .
· · ·
· · · −Bq−2 −Bq−1

0
0
...
In









where F (z) = F1zq−1 + · · · + Fq is chosen such that

−B0 −B1








and F = 



F1
...
Fq



,




z 7→ Q(z)F (z) − [Q(z)R(z) − P (z)]zq

is at most of degree q − 1 (see (4.13) and (4.15)).

In Corollary 4.11 we formulate the prediction formula in Theorem 3.2 in
the special case where (Xt)t∈R is a (Zt)t∈R-driven MCARMA process. In the
formulation we use the deﬁnition

ˆZu = E[Zu − Zs | Zs − Zr, r < s],

u > s,

in line with (3.5).

Corollary 4.11. Let (Xt)t∈R be a (Zt)t∈R-driven MCARMA process and set

˜gj(t) = (ep

1 ⊗ In)T eAt

p−q

Xk=j

Ak−j ECk,

t ≥ 0,

for j = 1, . . . , p − q, where C0, . . . , Cp−q−1 are given in (4.16) and Cp−q = In.
Suppose that det(P (z)) 6= 0 and det(Q(z)) 6= 0 for all z ∈ C with Re(z) ≥ 0.
Fix s < t. Then the following prediction formula holds

E[Xt | Xu, u ≤ s] =

p−q

Xj=1

˜gj(t − s)X (j−1)

s

s

t

+

Z

−∞ Z
s

˜g(t − u)f (u − v) du Xv dv + ˜g ∗ { ˆZ1

(s,∞)}(t),

where ˜g and f are given in (4.15) and (4.19), respectively, and

˜g ∗ { ˆZ1

(s,∞)}(t) = 1

{p=q+1}

ˆZu + (ep

1 ⊗ In)T AeAt

t

Z
s

e−AvE ˆZv dv.

Example 4.12. To illustrate the results above we will consider an n-dimensional
(Zt)t∈R-driven MCARMA(3,1) process (Xt)t∈R with P and Q polynomials given
by

P (z) = Inz3 + A1z2 + A2z + A3,
Q(z) = B0 + Inz

for matrices B0, A1, A2, A3 ∈ Rn×n such that det(P (z)) 6= 0 and det(Q(z)) 6= 0
for all z ∈ C with Re(z) ≥ 0. According to (4.15), (Xt)t∈R may be written as

Xt =

t

Z

−∞

(e3

1 ⊗ In)T eA(t−u)E dZu

13

where E1 = 0, E2 = In, and E3 = B0 − A1. With

C1 = A1 − B0, C0 = A2 + B0(B0 − A1)

and

F = B0(A2 − B0(A1 − B0)) − A3,

Theorem 4.8 and Remark 4.10 imply that

dX (1)

t = − C1X (1)

t dt − C0Xt dt+

∞

(cid:18) Z
0

(F Xt−u)T e−BT

0 u du

T

(cid:19)

dt + dZt.

Moreover, by Corollary 4.11, we have the prediction formula

E[Xt | Xu, u ≤ s] =(e3

1 ⊗ In)T eAt

(EC1 + AE)Xs + EX (1)

s

(cid:20)

t

+

Z
s

e−AuE

eB0u

(cid:18)

s

Z

−∞

e−B0vF Xv dv + ˆZu(cid:19)

du

.

(cid:21)

5 Proofs and auxiliary results

We will start this section by discussing some technical results. These results
will then be used in the proofs of all the results stated above.

Recall the function h : D(η) → Cn×n deﬁned in (3.1). Note that we always
have {z ∈ C : Re(z) ≤ 0} ⊆ D(η) and h(iy) = −iyIn − F [η](y) for y ∈ R.
Provided that η is suﬃciently nice, Proposition 5.1 below ensures the existence
of a kernel g : R → Rn×n which will drive the solution to (1.4).

Proposition 5.1. Let h be given as in (3.1) and suppose that det(h(iy)) 6= 0
for all y ∈ R. Then there exists a function g = (gjk) : R → Rn×n in L2
characterized by

F [g](y) = h(iy)−1

(5.1)

for y ∈ R. Moreover, the following statements hold:

(i) The function g satisﬁes

g(t − r) − g(s − r) = 1

(s,t](r)In +

t

Z
s

g ∗ η(u − r) du

for almost all r ∈ R and each ﬁxed s < t.

(ii) If η has moment of order p ∈ N, then g ∈ Lq for all q ∈ [1/p, ∞], and

g(t) = 1

[0,∞)(t)In +

t

Z

−∞

g ∗ η(u) du

(5.2)

for almost all t ∈ R. In particular,

g ∗ η(u) du = −In.

ZR

(5.3)

14

(iii) If

[0,∞) eδu |ηjk|(du) < ∞ for all j, k = 1, . . . , n and some δ > 0, then
R

there exists ε > 0 such that

sup
t∈R

max
j,k=1,...,n

|gjk(t)|eε|t| ≤ C

for a suitable constant C > 0.

(iv) If det(h(z)) 6= 0 for all z ∈ C with Re(z) ≤ 0 then g is vanishing on

(−∞, 0) almost everywhere.

Proof. In order to show the existence of g it suﬃces to argue that

y 7→

h(iy)−1
(cid:0)

jk is in L2 for j, k = 1, . . . , n,
(cid:1)

(5.4)

since the Fourier transform F maps L2 onto L2. (Here (h(iy)−1)jk refers to
the (j, k)-th entry in the matrix h(iy)−1.)
Indeed, in this case we just set
gjk = F −1[(h(i·)−1)jk].
[
h(iy) denote the n × n matrix which has the same rows as h(iy), but
where the j-th column is replaced by the k-th canonical basis vector (that is,
the vector with all entries equal to zero except of the k-th entry which equals
one). Then it follows by Cramer’s rule that

Let

h(iy)−1
(cid:0)

jk =
(cid:1)

[
det(
h(iy))
det(h(iy))

.

Recalling that h(iy) = −iyI − F [η](y) and that F [η](y) is bounded in y we get
[
by the Leibniz formula that | det(h(iy))| ∼ |y|n and | det(
h(iy))| = O(|y|n−1) as
|y| → ∞. This shows in particular that

(5.5)

h(iy)−1
(cid:0)

jk
(cid:1)

= O

|y|−1
(cid:0)

(cid:12)
(cid:12)
as |y| → ∞. Since j and k were arbitrarily chosen we get by continuity of (all
the entries of) y 7→ h(iy)−1 that (5.4) holds, which ensures the existence part.
The fact that F [g](−y) = F [g](y), y ∈ R, implies that g takes values in Rn×n.

(cid:12)
(cid:12)

(cid:1)

To show (i), we ﬁx s < t and apply the Fourier transform to obtain

g(t − ·) − g(s − ·) −

F

(cid:20)

t

Z
s

g ∗ η(u − ·) du

(y)

(cid:21)

= (eity − eisy)F [g](−y) − F [1
= F [1
= F [1

(s,t]](y)h(−iy)−1(iyI − F [η](−y))
(s,t]](y)In,

(s,t]](y)F [g](−y)F [η](−y)

which veriﬁes the result.

We will now show (ii) and for this we suppose that η has a moment of order
p ∈ N. Then it follows that ˜h : y 7→ h(iy) is (entry-wise) p times diﬀerentiable
with the m-th derivative given by

−

iδ0({m − 1}) + im

(cid:18)

Z[0,∞)

eiuyumηjk(du)

, m = 1, . . . , p,

(cid:19)

15

and in particular all the the entries of (Dm˜h)(y) are bounded in y. Observe
that, clearly, if a function A : R → Cn×n takes the form

A(t) = B(t)C(t)D(t),

t ∈ R,

(5.6)

where all the entries of B, D : R → Cn×n decay at least as |y|−1 as |y| → ∞ and
all the entries of C : R → Cn×n are bounded, then all the entries of A decay
at least as |y|−1 as |y| → ∞. Using the product rule for diﬀerentiation and the
fact that

D˜h−1
(cid:0)

(y) = −˜h(y)−1(D˜h)(y)˜h(y)−1,
(cid:1)

y ∈ R,

it follows recursively that Dm˜h−1 is a sum of functions of the form (5.6), thus
all its entries decay at least as |y|−1 as |y| → ∞, for m = 1, . . . , p. Since the
entries of Dm˜h−1 are continuous as well, they belong to L2, and we can use the
inverse Fourier transform F −1 to conclude that

F −1[Dp˜h](t) = (it)pF −1[˜h](t) = (it)pg(t),

t ∈ R,

is an L2 function. This implies in turn that t 7→ gjk(t)(1 + |t|)p ∈ L2 and, thus,

|gjk(t)|q dt ≤

gjk(t)(1 + |t|)p

2

dt

ZR

(cid:18) ZR (cid:0)

(cid:1)
for any q ∈ [1/p, 2) and j, k = 1, . . . , n. By using the particular observation that
g ∈ L1 and (i) we obtain that

q
2

(cid:19)

(cid:18) ZR

(1 + |t|)

−

2pq
2−q dt

1−

q
2

(cid:19)

< ∞

g(t) = 1

[0,∞)(t)I +

t

Z

−∞

g ∗ η(u) du

(5.7)

for (almost) all t ∈ R. This shows that

|gjk(t)| ≤ 1 +

ZR

|(g ∗ η(u))jk| du ≤ 1 +

n

ZR

Xl=1

|gjl(u)| du |ηlk|([0, ∞))

for all t ∈ R and for every j, k = 1, . . . , n which implies g ∈ L∞ and, thus,
g ∈ Lq for all q ∈ [1/p, ∞]. Since g(t) → 0 entrywise as t → ∞, we get by (5.7)
that

g ∗ η(u) du = −In,

ZR

which concludes the proof of (ii).

Now suppose that

δ > 0. In this case, Sδ := {z ∈ C : Re(z) ∈ [−δ, δ]} ⊆ D(η) and

[0,∞) eδu |ηjk|(du) < ∞ for all j, k = 1, . . . , n and some
R

z 7→ det(h(z)) = det

(cid:18)

− zI −

ezu η(du)

(cid:19)

Z[0,∞)

is strictly separated from 0 when |z|, z ∈ Sδ, is suﬃciently large. Indeed, the
dominating term in det(h(z)) is (−1)nzn when |z| is large, since

(cid:18) Z[0,∞)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

ezu η(du)

(cid:19)jk(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ max

l,m=1,...,n Z[0,∞)

eδu |ηlm|(du)

16

for j, k = 1, . . . , n. Using this together with the continuity of z 7→ det(h(z))
implies that there exists ˜δ ∈ (0, δ] so that z 7→ det(h(z)) is strictly separated
from 0 on S˜δ := {z ∈ C : Re(z) ∈ [−˜δ, ˜δ]}. In particular, z 7→ (h(z)−1)jk is
bounded on any compact set of S˜δ, and by using Cramer’s rule and the Leibniz
formula as in (5.5) we get that |(h(z)−1)jk| = O(|z|−1) as |z| → ∞ provided
that z ∈ S˜δ. Consequently,

sup

x∈[−˜δ,˜δ] ZR (cid:12)
(cid:12)

h(x + iy)−1
(cid:0)

jk
(cid:1)

2

(cid:12)
(cid:12)

dy < ∞,

and this implies by [3, Lemma 5.1] that t 7→ gjk(t)eεt ∈ L1 for all ε ∈ (−˜δ, ˜δ). Fix
any ε ∈ (0, ˜δ) and j, k ∈ {1, . . . , n}, and observe from (5.7) that gjk is absolutely
continuous on both [0, ∞) and (−∞, 0) with density (g ∗ η)jk. Consequently,
for ﬁxed t > 0, integration by parts yields

|gjk(t)|eεt ≤ |gjk(0)| +

|(g ∗ η(u))jk|eεu du + ε

ZR

ZR

|gjk(u)|eεu du.

(5.8)

Since

|(g ∗ η(u))jk|eεu du ≤

ZR

n

ZR

Xl=1

|gjl(u)|eεu du

eεu |ηlk|(du)

Z[0,∞)

it follows from (5.8) that

max
j,k=1,...,n

|gjk(t)| ≤ Ce−εt

for all t > 0 with

C := 1

+ max

j,k=1,...,n(cid:18)

n

ZR

Xl=1

|gjl(u)|eε|u| du

eεu |ηlk|(du) + ε

|gjk(u)|eε|u| du

.
(cid:19)

ZR

Z[0,∞)

By considering −ε rather than ε in the above calculations one reaches the con-
clusion that

max
j,k=1,...,n

|gjk(t)| ≤ Ceεt,

t < 0,

and this veriﬁes (iii).

Finally, suppose that det(h(z)) 6= 0 for all z ∈ C with Re(z) ≤ 0. Then it
holds that h, and thus z 7→ h(z)−1, is continuous on {z ∈ C : Re(z) ≤ 0} and
analytic on {z ∈ C : Re(z) < 0}. Moreover, arguments similar to those in (5.5)
show that |(h(z)−1)jk| = O(|z|−1) as |z| → ∞, and thus we may deduce that

sup
x<0 ZR

|(h(x + iy)−1)jk| dy < ∞.

From the theory on Hardy spaces, see [3, Lemma 5.1], [12, Section 2.3] or [13],
this implies that g is vanishing on (−∞, 0) almost everywhere, which veriﬁes
(iv) and ends the proof.

17

From Proposition 5.1 it becomes evident that we may and, thus, do choose
the kernel g to satisfy (5.2) pointwise, so that the function induces a ﬁnite
Lebesgue-Stieltjes measure g(du). We summarize a few properties of this mea-
sure in the corollary below.

Corollary 5.2. Let h be the function introduced in (3.1) and suppose that
det(h(iy)) 6= 0 for all y ∈ R. Suppose further that η has ﬁrst moment. Then the
kernel g : R → Rn×n characterized in (5.1) induces an n × n ﬁnite Lebesgue-
Stieltjes measure, which is given by

g(du) = Inδ0(du) + g ∗ η(u) du.

(5.9)

A function f = (fjk) : R → Cm×n is in L1(g(du)) if

|fjl(u)(g ∗ η)lk(u)| du < ∞,

l = 1, . . . , n,

ZR

for j = 1, . . . , m and k = 1, . . . , n. Moreover, the measure g(du) has (p − 1)-th
moment whenever η has p-th moment for any p ∈ N.

Proof. The fact that g induces a Lebesgue-Stieltjes measure of the form (5.9)
is an immediate consequence of (5.2). For a measurable function f = (fjk) :
R → Cm×n to be integrable with respect to g(du) = (gjk(du)) we require that
fjl ∈ L1(|glk(du)|), l = 1, . . . , n, for each choice of j = 1, . . . , m and k = 1, . . . , n.
Since the variation measure |glk|(du) of glk(du) is given by

|glk|(du) = δ0({l − k})δ0(du) + |(g ∗ η(u))lk| du,

we see that this condition is equivalent to the statement in the result. Finally,
suppose that η has p-th moment for some p ∈ N. Then, for any j, k ∈ {1, . . . , n},
we get that

|u|p−1 |gjk|(du) ≤

ZR

n

Xl=1

|ηlk|([0, ∞))

(cid:18)

ZR

|up−1gjl(u)| du

+

Z[0,∞)

|v|p−1 |ηlk|(dv)

|gjl(u)| du

.
(cid:19)

ZR

From the assumptions on η and Proposition 5.1(ii) we get immediately that
R |gjl(u)| du are ﬁnite for all l = 1, . . . , n.
|ηlk|([0, ∞)),
R
Moreover, for any such l we compute that

[0,∞) |v|p−1 |ηlk|(dv) and
R

|up−1gjl(u)| du

ZR

≤

Z{|u|≤1}

|up−1gjl(u)| du+

u−2 du

(cid:18) Z{|u|>1}

1
2

(cid:19)

(cid:18) Z{|u|>1}

(upgjl(u))2 du

1
2

(cid:19)

which is ﬁnite since u 7→ upgjl(u) ∈ L2, according to the proof of Proposi-
tion 5.1(ii), and hence we have shown the last part of the result.

We now give a result that both will be used to prove the uniqueness part of

Theorem 3.1 and Theorem 3.2.

18

Lemma 5.3. Suppose that det(h(iy)) 6= 0 for all y ∈ R and that η is a ﬁnite
measure with second moment, and let g be given by (3.2). Furthermore, let
(Xt)t∈R be a measurable process, which is bounded in L1(P) and satisﬁes (1.5)
almost surely for all s < t. Then, for each s ∈ R and almost surely,

∞

Xt = g(t − s)Xs +

g(t − u) η ∗

+ g ∗

1

Z
s
(s,∞)(Z − Zs)

(t)

1

(cid:8)

(−∞,s]X

(u) du

(cid:9)

(5.10)

(cid:8)
for Lebesgue almost all t > s, using the notation

(cid:9)

(η ∗ {1AX})j(t) :=

n

Xk=1
n

Z[0,∞)

1A(t − u)X k

t−u ηjk(du) and

(g ∗ {1

(s,∞)(Z − Zs)})j(t) :=

ZR

Xk=1

1

Z k
t−u − Z k
(s,∞)(t − u)
s
(cid:0)

(cid:1)

gjk(du)

for j = 1, . . . , n and t ∈ R.

Proof. By arguments similar to those in the proof of Proposition 5.1(iii) we get
that the assumption det(h(iy)) 6= 0 for all y ∈ R implies that we can choose
δ ∈ (0, ε), such that det(h(z)) 6= 0 for all z ∈ C with −δ < Re(z) ≤ 0 and

sup

h(x + iy)−1
x∈(−δ,0) ZR (cid:12)
(cid:0)
(cid:12)

jk
(cid:1)

(cid:12)
(cid:12)

2

dy < ∞.

for all j, k = 1, . . . , n. Thus, [3, Lemma 5.1] ensures that L[g](z) = h(z)−1 when
Re(z) ∈ (−δ, 0). From this point we will ﬁx such z and let s ∈ R be given. Since
(Xt)t∈R satisﬁes (1.4),

1

(s,∞)(t)Xt = 1

(s,∞)(t)Xs +

t

Z

−∞

1

(s,∞)(u) η ∗ X(u) du + 1

(s,∞)(t)(Zt − Zs)

for Lebesgue almost all t ∈ R outside a P-null set (which is a consequence of
Tonelli’s theorem). In particular, this shows that

− zL[1

(s,∞)X](z)

= − z

XsL[1

(cid:26)

(s,∞)](z) + L

·

1

(cid:20) Z

−∞

(s,∞)(u) η ∗ X(u) du

(z)

(cid:21)

+ L[1

(s,∞)(Z − Zs)](z)

=L[Xsδ0(· − s)](z) + L[1

By noticing that

(cid:27)
(s,∞) η ∗ X](z) − zL[1

(s,∞)(Z − Zs)](z).

L[1

(s,∞) η ∗ X](z) = L
(cid:2)
= L
(cid:2)

1

1

(s,∞) η ∗
(s,∞) η ∗

1

(cid:8)

1

(−∞,s]X
(−∞,s]X

(cid:8)

(cid:9)(cid:3)

(cid:9)(cid:3)

it thus follows that

1

η ∗

(z) + L
(cid:2)
(z) + L[η](z)L[

(cid:8)

(s,∞)X
1

(cid:9)(cid:3)
(s,∞)X

(z)

(cid:8)

(z)

(cid:9)(cid:3)

h(z)L[1
=L
(cid:2)

(s,∞)X](z)
Xsδ0(· − s) + 1

(s,∞) η ∗

1

(−∞,s]X

(z) − zL[1

(s,∞)(Z − Zs)](z).

(cid:8)

(cid:9)(cid:3)

19

(The reader should observe that since both (Xt)t∈R and (Zt)t∈R are bounded
in L1(P), the Laplace transforms above are all well-deﬁned almost surely. We
refer to the beginning of the proof of Theorem 3.1 where details for a similar
argument are given.) Now, using that L[g](z) = h(z)−1, we notice

−zh(z)−1L[1

(s,∞)(Z − Zs)](z) = L[g(du)](z)L[1

(s,∞)(Z − Zs)](z)

and thus

Xt = g(t − s)Xs +

∞

Z
s

= L
(cid:2)

g ∗

1

(s,∞)(Z − Zs)

(z),

(cid:8)

(cid:9)(cid:3)

g(t − u) η ∗

1

(−∞,s]X

(u) du + g ∗

1

(s,∞)(Z − Zs)

(cid:8)

(cid:9)

(cid:8)

(cid:9)

for Lebesgue almost all t > s with probability one.

With Lemma 5.3 in hand we are now ready to prove the general result,

Theorem 3.1, for existence and uniqueness of solutions to the MSDDE (1.4).

t−u is gT -integrable (by Corollary 5.2) which means that u 7→ Z k

Proof of Theorem 3.1. Fix t ∈ R. The convolution in (3.3) is well-deﬁned if
u 7→ Z T
t−u
belongs to L1(|gjk|(du)) for all j, k = 1, . . . , n. Observe that, since (Z k
u)u∈R is
integrable and has stationary increments, [1, Corollary A.3] implies that there
exists α, β > 0 such that E[|Z k

u|] ≤ α + β|u| for all u ∈ R. Consequently,

E

(cid:20) ZR

|Z k

t−u| µ(du)
(cid:21)

≤ (α + β|t|)µ(R) + β

|u| µ(du) < ∞

ZR

for any (non-negative) measure µ which has ﬁrst moment. This shows that
u 7→ Z k
t−u will be integrable with respect to such measure almost surely, in
particular with respect to |gjk|(du), j = 1, . . . , n, according to Corollary 5.2 as
η has second moment.

We will now argue that (Xt)t∈R deﬁned by (3.3) does indeed satisfy (1.4),

and thus we ﬁx s < t. Due to the fact that

t

Z

s

X T ∗ ηT (u) du =

t

Z

s

Z T ∗ ηT (u) du +

t

Z

s (cid:18) ZR

g ∗ η(r)Z·−r du

T

(cid:19)

∗ ηT (u) du

it is clear by the deﬁnition of (Xt)t∈R that it suﬃces to argue that

t

s (cid:18) ZR
Z

g ∗ η(r)Z·−r du

T

(cid:19)

∗ ηT (u) du

Z T

r [g ∗ η(t − r) − g ∗ η(s − r)]T dr −

=

ZR

t

Z
s

Z T ∗ ηT (r) dr.

20

We do this componentwise, so we ﬁx i ∈ {1, . . . , n} and compute that

t

(cid:18) Z

s (cid:18) ZR
n

g ∗ η(r)Z·−r dr

T

(cid:19)

∗ ηT (u) du

(cid:19)i

n

n

t

gjl ∗ ηlk(v)Z k

·−r dr

∗ ηij (u) du

(cid:19)

=

=

=

=

=

=

t

Z k
r Z[0,∞) Z

s Z[0,∞)

Z

s (cid:18) ZR

Xj=1
n

Xk=1
n

Xl=1
n

ZR

Xl=1

Xj=1
n

Xk=1
n

Z k
r Z[0,∞) Z
s

ZR

Xk=1
n

Xl=1
n

gjl(u − v − r − w) ηij (dv) du ηlk(dw) dr

t

(g ∗ η)il(u − r − w) du ηlk(dw) dr

Xk=1

Xl=1

(cid:18) ZR

Z k
r Z[0,∞)

[gil(t − r − w) − gil(s − r − w)] ηlk(dw) dr

Z k
r Z[0,∞)

ZR

−

n

δ0({i − l})1

(s,t](r + w) ηlk(dw) dr

(cid:19)

Z k

r [(g ∗ η)ik(t − r) − (g ∗ η)ik(s − r)] dr −

(cid:18) ZR

Xk=1

t

Z

s

Z k ∗ ηik(r) dr

(cid:19)

Z T

r [g ∗ η(t − r) − g ∗ η(s − r)]T dr −

(cid:18) ZR

t

Z
s

Z T ∗ ηT (r) dr

(cid:19)i

where we have used (i) in Proposition 5.1 and the fact that g and η commute
in a convolution sense, g ∗ η = (gT ∗ ηT )T (compare the associated Fourier
transforms).

Next, we need to argue that (Xt)t∈R is stationary. Here we will use (5.3) to

write the solution as

Xt =

ZR

g ∗ η(u) [Zt−u − Zt] du

for each t ∈ R. Fix m ∈ R. Let −m = tk
[−m, m] with maxj=1,...,k(tk

k = m be a partition of
j−1) → 0, k → ∞, and deﬁne the Riemann sum

1 < · · · < tk

0 < tk

j − tk

X m,k

t =

k

Xj=1

g ∗ η(tk

j−1) [Zt−tk

j−1 − Zt] (tk

j − tk

j−1).

Observe that (X m,k
t
converges to the i-th component of

)t∈R is stationary. Moreover, the i-th component of X m,k

t

X m

t =

m

Z

−m

g ∗ η(u) [Zt−u − Zt] du

in L1(P) as k → ∞. To see this, we start by noting that

X m
t
(cid:0)

i −
(cid:1)

X m,k
t
(cid:0)

i
(cid:1)

E

(cid:2)(cid:12)
(cid:12)

≤

(cid:12)
(cid:3)
(cid:12)

n

k

ZR

Xj=1

Xl=1

− (g ∗ η)ij

1

(tk

l−1,tk

l ](u)E

t−u − Z j
Z j
(g ∗ η)ij (u)
(cid:2)

t

(cid:3)

h(cid:12)
(cid:12)
− Z j
t

Z j

t−tk

l−1

du.

i

(cid:3)(cid:12)
(cid:12)

tk
l−1
(cid:0)

(cid:1)(cid:2)

21

Then, for each j ∈ {1, . . . , n},

1

max
l=1,...,k

(tk

l−1,tk

l ](u)E

Z j
t−u − Z j

t

(g ∗ η)ij (u)
(cid:2)
l−1,tk
(tk

h(cid:12)
(cid:12)
≤ max

1

l=1,...,k

− (g ∗ η)ij

tk
l−1
(cid:0)
(cid:3)
|(g ∗ η)ij (u)| E

Z j

t−tk

l−1

(cid:1)(cid:2)
Z j
t−u − Z j

− Z j
t

i

(cid:3)(cid:12)
(cid:12)

t−tk

l−1

l ](u)
(cid:16)

− Z j
t

+ E

Z j

t−tk

l−1

(g ∗ η)ij (u) − (g ∗ η)ij

(cid:2)(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:3)
→ 0

(cid:17)

tk
l−1
(cid:0)

(cid:12)
(cid:12)

(cid:2)(cid:12)
(cid:12)

(cid:3) (cid:12)
(cid:12)
as k → ∞ for almost all u ∈ R using that (Z j
t )t∈R is continuous in L1(P) (cf. [1,
Corollary A.3]) and that (g∗η)ij is càdlàg. Consequently, Lebesgue’s theorem on
dominated convergence implies that X m,k
t entrywise in L1(P) as k → ∞,
thus (X m
)t∈R. Finally, since
X m
t → Xt (entrywise) almost surely as m → ∞, we obtain that (Xt)t∈R is
stationary as well.

t )t∈R inherits the stationarity property from (X m,k

t → X m

(cid:1)(cid:12)
(cid:12)

t

To show the uniqueness part, we let (Ut)t∈R and (Vt)t∈R be two stationary,
integrable and measurable solutions to (1.4). Then Xt := Ut − Vt, t ∈ R,
is bounded in L1(P) and satisﬁes an MSDDE without noise. Consequently,
Lemma 5.3 implies that

Xt = g(t − s)Xs +

∞

Z
s

g(t − u)η ∗ {1

(−∞,s]X}(u) du

holds for each s ∈ R and Lebesgue almost all t > s. For a given j we thus ﬁnd
that

E

X j
t

≤ C

(cid:2)(cid:12)
(cid:12)

(cid:3)

(cid:12)
(cid:12)

n

Xk=1

|gjk(t − s)| +

(cid:18)

n

∞

Z
s

Xl=1

|gjk(t − u)| |ηkl|([u − s, ∞)) du

(cid:19)

0 |].

0 | + |V k

where C := maxk E[|U k
It follows by Proposition 5.1(ii) that g(t)
converges as t → ∞, and since g ∈ L1 it must be towards zero. Using this fact
together with Lebesgue’s theorem on dominated convergence it follows that the
right-hand side of the expression above converges to zero as s tends to −∞,
from which we conclude that Ut = Vt almost surely for Lebesgue almost all t.
By continuity of both processes in L1(P) (cf.
[1, Corollary A.3]), we get the
same conclusion for all t.

Finally, under the assumption that det(h(z)) 6= 0 for z ∈ C with Re(z) ≤ 0
it follows from Proposition 5.1(iv) that g ∗ η is vanishing on (−∞, 0), and hence
we get that the solution (Xt)t∈R deﬁned by (3.3) is causal since

Xt = Zt +

∞

Z
0

g ∗ η(u) Zt−u du = −

∞

Z
0

g ∗ η(u)[Zt − Zt−u] du

for t ∈ R by (5.3).

Proof of Theorem 3.2. Since (Xt)t∈R is a solution to an MSDDE,

σ(Xu : u ≤ s) = σ(Zs − Zu : u ≤ s)

and the theorem therefore follows by Lemma 5.3.

22

Proof of Proposition 4.1. We start by arguing why (4.2) is well-deﬁned. To see
that this is the case, note initially that Ik(fr(t − ·)) = Z k
t−r and thus, since
(Z k
t )t∈R is integrable and has stationary increments, there exists α, β > 0 such
that E[|Ik(fr(t − ·))|] ≤ α + β|r| for all r ∈ R (see, e.g., [1, Corollary A.3]). In
particular

t − Z k

E

(cid:20) ZR

|Ik(fr(t − ·))| |µ|(dr)

(cid:21)

≤ α|µ|(R) + β

ZR

|r| |µ|(dr) < ∞,

which shows that Ik(fr(t − ·)) is integrable with respect to µ, thus the right-
hand side of (4.2) is well-deﬁned, almost surely for each t ∈ R. To show that the
R fr(u) µ(dr) belongs
left-hand side is well-deﬁned, it suﬃces to note that u 7→
to L1 ∩ L2 by an application of Jensen’s inequality and Tonelli’s theorem.

To show (4.3) we start by ﬁxing t ∈ R and j, k ∈ {1, . . . , n}, and by noting
that µ(dr) = (g ∗ η)jk(r) dr is a ﬁnite measure with having ﬁrst moment ac-
cording to Corollary 5.2. Consequently, we can use assumptions (i)-(ii) on Ik to
get

R

ZR

(g ∗ η)jk(r)
(cid:2)

t−r − Z k
Z k
t

dr =

(cid:3)

ZR

Ik(1

(t,t−r])(g ∗ η)jk(r) dr

= Ik

(cid:18) ZR

1

(t,t−r](g ∗ η)jk(r) dr

(cid:19)

= Ik

(cid:18)

δ0({j − k})1

[0,∞)(t − ·) +

t−·

Z

−∞

(g ∗ η)jk(u) du

(cid:19)

= Ik(gjk(t − ·))

using (5.2) and the convention that 1
this relation with (5.3) and (3.3) we obtain

(a,b] = −1

(b,a] when a > b. By combining

X j

t =

n

ZR

Xk=1

(g ∗ η)jk(r)[Z k

t−r − Z k

t ] dr =

n

Xk=1

Ik(gjk(t − ·)).

Proof of Proposition 4.3. Let α ∈ (1, 2] and β ∈ (0, 1 − 1/α), and consider a
function f : R → R in L1 ∩ Lα. We start by noticing that

∞

Z
t

|f (u)|(u − t)β−1 du =

1

Z
0

|f (t + u)|uβ−1 du +

∞

Z
1

|f (t + u)|uβ−1 du.

For the left term we ﬁnd that

1

ZR(cid:18) Z

0

|f (t + u)|uβ−1 du

α

(cid:19)

dt

1

1

≤

=

(cid:18) Z
0

(cid:18) Z
0

uβ−1 du

α−1

1

(cid:19)

α

ZR Z
0

|f (t + u)|αuβ−1 du dt

uβ−1 du

(cid:19)

ZR

|f (t)|α dt < ∞.

23

For the right term we ﬁnd

∞

|f (t + u)|uβ−1 du

ZR(cid:18) Z
1

α

(cid:19)

dt

∞

ZR Z
1
∞

|f (t + u)|uα(β−1) du dt

uα(β−1) du < ∞.

≤

=

(cid:18) ZR

(cid:18) ZR

f (u)du

α−1

(cid:19)

α

f (u)du

(cid:19)

Z
1

I β
−f
(cid:0)

(u) ∈ Lα.
(cid:1)

We conclude that

Proof of Theorem 4.5. The identity (4.8) is just a matter of applying standard
computation rules for determinants. For instance, one may prove the result
when z 6= 0 by induction using the block representation

−h(z) =

A B
C D(cid:21)
(cid:20)

(5.11)

with A = Inz, B = (e1 ⊗In)T ∈ Rn×(m−1)n, C = em−1 ⊗L[̟0](z) ∈ R(m−1)n×n,
and

Inz
0
...
0

In
Inz
...
0

L[̟1](z) L[̟2](z)

D =










0
In
. . .
· · ·
· · · L[̟m−2](z)

· · ·
· · ·
. . .
Inz

0
0
...
In
Inz + L[̟m−1](z)










.

Here e1 and em−1 refer to the ﬁrs and last canonical basis vector of Rm−1,
respectively. The case where z = 0 follows directly from the Leibniz formula.
In case det(h(iy)) 6= 0 for all y ∈ R, we may write h(iy)−1 as an m × m
matrix, where each element (h−1(iy))jk is an n × n matrix. We then know from
Theorem 3.1 that the unique solution to (4.5) is a (Zt)t∈R-driven moving average
of the form (4.7) with F [g1m](y) = (h−1(iy))1m. Similar to the computation
of det(h(z)), when h(z) is invertible, block (1, m) of h(z)−1 can inductively be
shown to coincide with

In(−z)m −

(cid:18)

m−1

Xj=0

L[̟j](z)(−z)j

−1

(cid:19)

using the representation (5.11) and standard rules for inverting block matrices.
This means in particular that (4.9) is true.

Proof of Theorem 4.8. We start by arguing that that there exists a function
f with the Fourier transform in (4.18). Note that, since z 7→ det(Q(z)) is
just a polynomial (of order nq), the assumption that det(Q(z)) 6= 0 whenever
Re(z) ≥ 0 implies in fact that

H(z) := R(−z) − Q(−z)−1P (−z) = Q(−z)−1[Q(−z)R(−z) − P (−z)]

24

is well-deﬁned for all z ∈ Sδ := {x + iy : x ≤ δ, y ∈ R} and a suitably chosen
δ > 0. According to [3, Lemma 5.1] it suﬃces to argue that there exists ε ∈ (0, δ]
such that

sup
x<ε ZR

|H(x + iy)jk|2 dy < ∞

(5.12)

for all j, k = 1, . . . , n. Let k·k denote any sub-multiplicative norm on Cn×n
and note that |H(z)jk| ≤ kQ(−z)−1kkQ(−z)R(−z) − P (−z)k. Thus, since
kQ(z)R(z) − P (z)k ∼ c1|z|q−1 and kQ(z)−1k ∼ c2|z|−q as |z| → ∞ for some
c1, c2 ≥ 1 (the former by the choice of R and the latter by Cramer’s rule),
|H(z)jk| = O(|z|−1). Consequently, the continuity of H ensures that (5.12) is
satisﬁed for a suitable ε ∈ (0, δ], and we have established the existence of f with
the desired Fourier transform. This also establishes that the n × n measures
̟0, ̟1, . . . , ̟p−q−1 deﬁned as in the statement of the theorem are ﬁnite and
have moments of any order. Associate to these measures the n(p − q) × n(p − q)
measure η given in (4.6). Then it follows from (4.8) that

det(h(iy)) = det

In(−iy)p−q +

(cid:18)

p−q−1

Xj=0

Rj(−iy)j − F [f ](y)

(cid:19)

=

det(P (−iy))
det(Q(−iy))

,

and hence is non-zero for all y ∈ R. In light of Proposition 4.5, in particular
(4.9), we may therefore conclude that the unique solution to (4.5) is a (Zt)t∈R-
driven moving average, where the driving kernel has Fourier transform

In(−iy) +

(cid:18)

p−q−1

Xj=0

Rj(−iy)j − F [f ](y)

(cid:19)

= P (−iy)−1Q(−iy)

−1

for y ∈ R. In other words, the unique solution is the (Zt)t∈R-driven MCARMA(p, q)
process associated to the polynomials P and Q.

Before giving the proof of Corollary 4.11 we will need the following lemma:

Lemma 5.4. Let C0, . . . , Cp−q−1 be given in (4.16) and Cp−q = In. Deﬁne

Rj(z) =

p−q

Xk=j

Ckzk−j,

j = 1, . . . , p − q − 1.

Then ˜g is p − q − 2 times diﬀerentiable and Dp−q−2˜g has a density with respect
to the Lebesgue measure which we denote Dp−q−1˜g. Furthermore, we have that

(ep−q

1 ⊗ In)T g = (˜gR1(D), . . . , ˜gRp−q−1(D), ˜g)

(5.13)

where

˜gRj(D)(t) =

p−q

Xk=j

Dk−j ˜g(t)Ck

= 1

[0,∞)(t)(ep

1 ⊗ In)T eAt

p−q

Xk=j

Ak−jECk

25

(5.14)

for j = 1, . . . , p − q − 1 and g : R → Rn×n is characterized by F [g](y) = h(iy)−1
with h : C → Cn(p−q)×n(p−q) given by

h(−z) =

0

−In
Inz −In
...
. . .
· · ·
0
Q−1(z)P (z) − zR1(z) C1
· · · Cp−q−2

· · ·
· · ·
. . .
Inz

Inz
0
...
0










0
0
...
−In
Inz + Cp−q−1

.










Proof. That ˜g is p − q − 2 times diﬀerentiable and Dp−q−2˜g has a density with
respect to the Lebesgue measure follows form the relation in (5.2). Furthermore,
by Theorem 4.8 we know that F [˜g](y) = P −1(−iy)Q(−iy). Consequently, (5.13)
follows since

(P −1(−iy)Q(−iy)R1(−iy),

. . . , P −1(−iy)Q(−iy)Rp−q−1(−iy), P −1(−iy)Q(−iy))h(z) = (ep−q

1 ⊗ In)T .

The relation in (5.14) follows by the representation of ˜g given in (4.15).

Proof of Corollary 4.11. The prediction formula is a consequence of Lemma 5.4
combined with Theorem 3.2 and Theorem 4.8. Furthermore, to get the expres-
sion for ˜g ∗ { ˆZ1

(s,∞)}, note that

˜g(dv) = 1

{p=q+1}δ0(dv) + (ep

1 ⊗ In)T eAvAE dv,

which follows from the representation of ˜g in (4.15)

Acknowledgments

This work was supported by the Danish Council for Independent Research
(Grant DFF - 4002 - 00003).

References

[1] Barndorﬀ-Nielsen, O. E. and A. Basse-O’Connor (2011). Quasi Ornstein-

Uhlenbeck processes. Bernoulli 17 (3), 916–941.

[2] Barndorﬀ-Nielsen, O. E., J. L. Jensen, and M. Sørensen (1998). Some
in Appl.

stationary processes in discrete and continuous time.
Probab. 30 (4), 989–1007.

Adv.

[3] Basse-O’Connor, A., M. S. Nielsen, J. Pedersen, and V. Rohde (2017).
arXiv preprint

A continuous-time framework for ARMA processes.
arXiv:1704.08574.

[4] Benth, F. E., J. v. S. Benth, and S. Koekebakker (2007). Putting a price on

temperature. Scand. J. Statist. 34 (4), 746–767.

[5] Box, G. E. P. and G. M. Jenkins (1970). Times series analysis. Forecasting

and control. Holden-Day, San Francisco, Calif.-London-Amsterdam.

26

[6] Brockwell, P. (2014). Recent results in the theory and applications of
CARMA processes. Annals of the Institute of Statistical Mathematics 66 (4),
647–685.

[7] Brockwell, P. and T. Marquardt (2005). Lévy-driven and fractionally
Statist.

integrated ARMA processes with continuous time parameter.
Sinica 15 (2), 477–494.

[8] Brockwell, P. J. (2001). Lévy-driven CARMA processes. Ann. Inst. Statist.
Math. 53 (1), 113–124. Nonlinear non-Gaussian models and related ﬁltering
methods (Tokyo, 2000).

[9] Brockwell, P. J., R. A. Davis, and Y. Yang (2011). Estimation for non-
negative Lévy-driven CARMA processes. Journal of Business & Economic
Statistics 29 (2), 250–259.

[10] Brockwell, P. J. and A. Lindner (2015). Prediction of Lévy-driven CARMA

processes. Journal of Econometrics 189 (2), 263–271.

[11] Brockwell, P. J. and E. Schlemm (2013). Parametric estimation of the
driving Lévy process of multivariate CARMA processes from discrete obser-
vations. J. Multivariate Anal. 115, 217–251.

[12] Doetsch, G. (1937). Bedingungen für die Darstellbarkeit einer Funktion
als Laplace-integral und eine Umkehrformel für die Laplace-Transformation.
Math. Z. 42 (1), 263–286.

[13] Dym, H. and H. P. McKean (1976). Gaussian Processes, Function Theory,
and the Inverse Spectral Problem. New York: Academic Press [Harcourt Brace
Jovanovich Publishers]. Probability and Mathematical Statistics, Vol. 31.

[14] García, I., C. Klüppelberg, and G. Müller (2011). Estimation of sta-
ble CARMA models with an application to electricity spot prices. Stat.
Model. 11 (5), 447–470.

[15] Gripenberg, G. and I. Norros (1996). On the prediction of fractional Brow-

nian motion. J. Appl. Probab. 33 (2), 400–410.

[16] Gushchin, A. A. and U. Küchler (2000). On stationary solutions of delay dif-
ferential equations driven by a Lévy process. Stochastic Process. Appl. 88 (2),
195–211.

[17] Marquardt, T. (2006). Fractional Lévy processes with an application to

long memory moving average processes. Bernoulli 12 (6), 1099–1126.

[18] Marquardt, T. (2007). Multivariate fractionally integrated carma processes.

Journal of Multivariate Analysis 98 (9), 1705–1725.

[19] Marquardt, T. and R. Stelzer (2007). Multivariate CARMA processes.

Stochastic Process. Appl. 117 (1), 96–120.

[20] Mohammed, S. E. A. and M. K. R. Scheutzow (1990). Lyapunov exponents
and stationary solutions for aﬃne stochastic delay equations. Stochastics
Stochastics Rep. 29 (2), 259–283.

27

[21] Rajput, B. S. and J. Rosiński (1989). Spectral representations of inﬁnitely

divisible processes. Probab. Theory Related Fields 82 (3), 451–487.

[22] Samorodnitsky, G. and M. S. Taqqu (1994). Stable Non-Gaussian Random
Processes. Stochastic Modeling. New York: Chapman & Hall. Stochastic
models with inﬁnite variance.

[23] Sato, K., T. Watanabe, and M. Yamazato (1994). Recurrence conditions
for multidimensional processes of Ornstein-Uhlenbeck type. J. Math. Soc.
Japan 46 (2), 245–265.

[24] Sato, K. and M. Yamazato (1983). Stationary processes of Ornstein-
Uhlenbeck type.
In Probability theory and mathematical statistics (Tbilisi,
1982), Volume 1021 of Lecture Notes in Math., pp. 541–551. Springer, Berlin.

[25] Stelzer, R. (2011). CARMA Processes driven by Non-Gaussian Noise. arXiv

preprint arXiv:1201.0155.

[26] Todorov, V. (2009). Estimation of continuous-time stochastic volatility
models with jumps using high-frequency data. J. Econometrics 148 (2), 131–
148.

28

