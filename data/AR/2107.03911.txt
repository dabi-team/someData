Draft version July 14, 2021
Typeset using LATEX default style in AASTeX63

1
2
0
2

l
u
J

3
1

]

R
S
.
h
p
-
o
r
t
s
a
[

2
v
1
1
9
3
0
.
7
0
1
2
:
v
i
X
r
a

Prediction of Solar Proton Events with Machine Learning: Comparison with Operational Forecasts
and “All-Clear” Perspectives

Viacheslav M. Sadykov,1 Alexander G. Kosovichev,2, 3 Irina N. Kitiashvili,3 Vincent Oria,4 Gelu M. Nita,2
Egor Illarionov,5, 6 Patrick M. O’Keefe,4 Yucheng Jiang,4 Sheldon H. Fereira,2 and Aatiya Ali1

1Physics & Astronomy Department, Georgia State University, Atlanta, GA 30303, USA
2Physics Department, New Jersey Institute of Technology, Newark, NJ 07102, USA
3NASA Ames Research Center, Moﬀett Field, CA 94035, USA
4Computer Science Department, New Jersey Institute of Technology, Newark, NJ 07102, USA
5Department of Mechanics and Mathematics, Moscow State University, Moscow, 119991, Russia
6Moscow Center of Fundamental and Applied Mathematics, Moscow, 119234, Russia

ABSTRACT

Solar Energetic Particle events (SEPs) are among the most dangerous transient phenomena of solar
activity. As hazardous radiation, SEPs may aﬀect the health of astronauts in outer space and adversely
impact current and future space exploration. In this paper, we consider the problem of daily prediction
of Solar Proton Events (SPEs) based on the characteristics of the magnetic ﬁelds in solar Active Regions
(ARs), preceding soft X-ray and proton ﬂuxes, and statistics of solar radio bursts. The machine learning
(ML) algorithm uses an artiﬁcial neural network of custom architecture designed for whole-Sun input.
The predictions of the ML model are compared with the SWPC NOAA operational forecasts of SPEs.
Our preliminary results indicate that 1) for the AR-based predictions, it is necessary to take into
account ARs at the western limb and on the far side of the Sun; 2) characteristics of the preceding
proton ﬂux represent the most valuable input for prediction; 3) daily median characteristics of ARs and
the counts of type II, III, and IV radio bursts may be excluded from the forecast without performance
loss; and 4) ML-based forecasts outperform SWPC NOAA forecasts in situations in which missing
SPE events is very undesirable. The introduced approach indicates the possibility of developing robust
“all-clear” SPE forecasts by employing machine learning methods.

Keywords: Solar energetic particles (1491); Space weather(2037); Solar radiation(1521); Neural net-

works(1933); Solar ﬂares (1496)

1. INTRODUCTION

Solar Energetic Particle events (SEPs) are sharp increases in the particle ﬂux from the Sun as observed in the
near-earth environment. SEPs represent one of the clearest manifestations of transient solar activity and are one of
the drivers of Space Weather disturbances. Accelerated directly at the sites of solar ﬂares or at the shock wave fronts
formed by Coronal Mass Ejections (CMEs), SEPs propagate through the Heliosphere and interact with the space
environment of the Earth (Reames 2021). There are various consequences of such interactions, including impacts on
astronauts’ health (Martens 2018), increase in the radiation levels at aviation altitudes during the strongest events
(Kataoka et al. 2018) and corresponding economic impacts (Saito et al. 2021), damage to satellites, and potential
danger for space exploration. Consequently, monitoring and prediction of SEPs are high priorities for the operational
and research communities.

Solar Proton Events (SPEs) represent a major subclass of SEP events. A classical deﬁnition of the least-strength S1
events (on the scale of the Space Weather Prediction Center at the National Oceanic and Atmospheric Administration
(SWPC NOAA Space Weather Scales 2011)) is an enhancement of the ﬂux of > 10 MeV protons above the 10 pfu
(particle ﬂux unit) threshold. Prediction of such SPEs is a challenging problem from many perspectives. During solar

vsadykov@gsu.edu

 
 
 
 
 
 
2

Sadykov et al.

cycle 24, one or more such enhancements were observed less often than 1 day in 30. This ratio (deﬁned here as a
class-imbalance) becomes even stronger for higher ﬂuxes or energy thresholds. Diﬃculties and strategies for forecasting
space weather events for highly-imbalanced data sets were pointed out by Ahmadzadeh et al. (2021), and a need for
balanced data sets for space weather prediction was emphasized by (Martens & Angryk 2018). In addition, SPEs may
be signiﬁcantly delayed (up to tens of hours) with respect to the onset time of the preceding solar ﬂare. Therefore, the
forecasting time window and data handling are challenging because of the diﬀerent timescales for processes associated
with SPEs. Also, it is important to note that the origin of SPEs at the solar surface (or the exact location of the host
Active Region, AR) sometimes cannot be determined, especially if the host AR is very close to or behind the western
limb of the Sun. In this situation, the characteristics of the magnetic ﬁeld structure and complexity in the host AR
cannot be deﬁned. The last two points make it challenging to connect a particular SPE to its host AR.

With the increasing amount and quality of available data and the development and accessibility of machine learning
(ML) algorithms, there has been a growing number of attempts to apply ML to predict solar transient events. For
example, Huang et al. (2012) utilized the ensemble forecasting approach for SPEs based on preceding ﬂares and CMEs
and found better performance if these data are combined to make forecasts. Kim et al. (2018) developed an algorithm
to predict SPEs using the solar radio ﬂux by employing statistical analysis, neural networks, and genetic algorithms.
Jeong et al. (2014) developed an algorithm of SPE forecasting with NOAA scales based on Multi-Layer Perceptrons
(MLPs) and using GOES solar soft X-ray (SXR) characteristics of ﬂares from 1976 to 2011. Bain et al. (2019) pointed
that ML models built on the data available in real-time could outperform operational forecasts. In addition, there is
growing interest in the development of forecasting frameworks (Engell et al. 2017) and ML-ready data-set preparation
(Martens & Angryk 2018).

The current operational daily forecasting of > 10 MeV > 10 pfu SPEs relies on a statistics-based approach, plus a
human forecaster to correct the predictions (Balch 1999, 2008; Bain et al. 2021). This approach has been validated
over several solar cycles. Despite advances in ML-based predictions, comparisons with these operational SWPC NOAA
forecasts or application to the same temporal and spatial scales (Zhong et al. 2019; Jeong et al. 2014; Bain et al. 2019)
are rarely made.

In addition to the daily forecasting of > 10 MeV > 10 pfu proton events, there are approaches targeted on shorter
timescales for the prediction (Laurenza et al. 2018; Papaioannou et al. 2018), higher proton energy thresholds (N´u˜nez
2015; Malandraki et al. 2018), and various quantities related to the SPEs (ﬂuence, peak ﬂux, etc., Aminalragia-Giamini
et al. 2020; Lovelace et al. 2018). One of the recent focuses of SPE predictions is the “all-clear” approach, where a
missed event is considered a signiﬁcant failure of the algorithm as compared to a false alarm event. This approach is
of special importance for mitigating risks from radiation exposure.

In this work, we present a novel approach for developing daily prediction capabilities of Solar Proton Events (SPEs)
based on entire Sun observations, applying an artiﬁcial neural network of custom architecture, and comparing the
prediction results with the SPE forecasts by SWPC NOAA. We also extend this approach to the “all-clear” prediction
problem for SPEs. Section 2 describes the data preparation, derivation of characteristics, and data set construction
for the prediction. Section 3 presents the architecture of the artiﬁcial neural network for SPE prediction and the
training strategy. Section 4 summarizes the main results of this work and is followed by a discussion in Section 5. The
conclusion is presented in Section 6.

2. DATA PREPARATION

The data processing and machine learning setups described in Sections 2 and 3 are publicly available at the SPE

Prediction Project URL (2021).

2.1. Daily SWPC NOAA Proton Event Probabilities

Operational space weather forecasts of solar transient events are currently prepared jointly by the Space Weather
Prediction Center (SWPC) of the National Oceanic and Atmospheric Administration (NOAA) and the 557th Weather
Wing of the United States Air Force (USAF). The forecasts are released daily, at 22:00 UT, for the three following days
(starting from 00:00 UT). The forecasts are available via ftp (ftp://ftp.swpc.noaa.gov/pub/warehouse/) in the RSGA
folder for each year. The forecast of solar proton events is presented in section “III” of that document in terms of
probabilities (ranging from 1 to 99) of the > 10 MeV proton ﬂux to exceed 10 pfu. The forecasts rely on statistical models
(Balch 1999, 2008) augmented by the “forecaster-in-the-loop” technique (the calculated probabilities are corrected by
forecasters based on the forecasters’ experience). This technique was proven to have a higher performance than non-
corrected probabilities for the SXR solar ﬂares and in terms of Brier Skill Score (BSS, Crown 2012). For the current

Prediction of Solar Proton Events

3

study, we utilize only the next-day probabilities of the proton events. The data used were collected for each day
from June 2010 — December 2019. The probabilities for the days when the reports were not issued were obtained
by interpolation from the neighboring days. An extensive study of the SWPC NOAA SPE probabilities was recently
performed by Bain et al. (2021); we direct the readers to this study for more details about the operational forecasts.
One of the goals of this study is to compare the performance of ML-based prediction of SPEs with the probabilistic
operational forecasts. Because the next-day SWPC NOAA probabilities are issued at 22:00 UT and are valid starting
from 00:00 UT, we will adopt the following convention in this study: all characteristics described below will be computed
for each considered day from the data acquired between 22:00 UT of the previous day and 22:00 UT of the considered
day, i.e., they can be fully deﬁned at 22:00 UT of the considered day. However, the prediction will be made for the
presence of >10 MeV >10 pfu events during the next day starting from 00:00 UT, i.e., the forecast will have a 2-hour
latency time window. This setting will allow us to match the timing of SWPC NOAA operational forecasts.

2.2. Records of Radio Bursts

Radio bursts of types II and IV are prominent indicators of the formation of shocks in the Heliosphere (Zimovets
& Sadykov 2015), and, together with type III radio bursts, are valuable characteristics for SEP forecasts (Winter &
Ledbetter 2015; Miteva et al. 2017; Ameri et al. 2019; Bain et al. 2019; Kalaivani et al. 2020). Therefore, information
about such radio bursts is essential to consider for forecast development. In this work, we utilize a simplistic approach
by counting the number of type II, III, and IV radio bursts that occurred during each day. The daily counts of the
radio bursts will be utilized as characteristics to predict SPEs for the following day. The records of the radio bursts
are publicly available at SWPC NOAA via FTP (ftp://ftp.swpc.noaa.gov/pub/warehouse/).

2.3. Daily Median SHARP Characteristics of Active Regions

The characteristics of the vector magnetic ﬁelds in ARs (such as the total unsigned magnetic helicity, total unsigned
vertical electric currents, etc.) are often used to predict solar ﬂares and CMEs (e.g., Bobra & Couvidat 2015; Bobra
& Ilonidis 2016; Campi et al. 2019). Space Weather HMI Active Region Patches (SHARPs, Bobra et al. 2014) are,
probably, the most widely-used set of vector magnetic ﬁeld characteristics calculated for each recognized magnetic ﬁeld
patch with a 12 min cadence. In this study, the “Active Regions” (ARs) term will correspond to any magnetic ﬁeld
patches recorded in the SHARP database. We compute the daily median values of the Cylindrical Equal Area (CEA)
projected SHARP characteristics for each patch and use these for the prediction of SPEs. There are 30 characteristics
for each magnetic patch used in this study, including the patch center coordinates and data quality parameters.

The SHARP characteristics are reliable only if the AR is located within ≈68 deg from the solar disc center (Bobra
& Couvidat 2015), due to projection eﬀects and the loss of the spatial resolution closer to the limb. This represents a
problem for SPE prediction. In Parker’s solar wind model (Parker 1958), the solar longitudes magnetically connected
to the Earth are located close to the western solar limb. Statistical studies of the distribution of SPE origins (Cliver
et al. 2020) also demonstrate an asymmetry towards the western limb, with the average SPE origin range of east 20
– west 100 longitudes. As a result, one has to consider patches in close proximity to the western limb and beyond to
issue a whole-Sun prediction of SPEs.

To address this issue, we mimic the existence of the magnetic ﬁeld characteristics close to and behind the western
solar limb by assuming that the AR has the same magnetic ﬁeld characteristics as for the previous day. We also assume
that the AR obeys the Carrington rotation rate (∼25.4 days) and exists on the far side of the Sun for 11 more days
while preserving magnetic ﬁeld characteristics. We apply this strategy for every magnetic ﬁeld patch recognized in
SHARP.

The paper aims to utilize the characteristics of the magnetic ﬁeld of patches (ARs) over the whole Sun to predict
the SPEs. The number of individual ARs (or magnetic patches) on the Sun varies from day to day. It is known that
large and more complex ARs tend to produce more ﬂares and SPEs (e.g., Falconer et al. 2012; Sadykov & Kosovichev
2017). Therefore, for each day, we select 10 SHARPs with the largest unsigned magnetic ﬁeld ﬂuxes (including those
extrapolated to and behind the western limb) and use their characteristics for the whole-Sun prediction. In case there
are less than 10 patches recorded for the current day, we introduce zero entries for the absent patches.

2.4. Daily Characteristics of GOES Proton and Soft X-ray Flux Measurements

The recent history of transient solar activity (e.g., the number of prior transient events within one or several days)
may serve as a useful characteristic for predicting future solar transient events (Falconer et al. 2012; Nishizuka et al.

4

Sadykov et al.

2017). In our forecast of SPEs, we include information about prior activity in the form of the daily characteristics of
soft X-ray (SXR) 0.5-4 ˚A and 1-8 ˚A ﬂuxes and > 10 MeV proton ﬂuxes, both observed by the GOES series. We have
utilized the 1-minute averaged SXR ﬂuxes and 5-minute averaged proton ﬂuxes, available at the NOAA National Center
for Environmental Information (NOAA NCEI, https://satdat.ngdc.noaa.gov/sem/goes/data/avg/). The proton ﬂux
observations are done by GOES in eastward and westward directions. In this study, we utilize the average ﬂux from
the two detectors. We also discuss in Section 5 how using the ﬂux from only one of two detectors aﬀects the results.
For each day from June 2010 — December 2019, we compute the mean, median, minimum, and maximum ﬂuxes of
0.5-4 ˚A and 1-8 ˚A SXR radiation and > 10 MeV protons, as well as their daily standard deviations. We also record the
lowest available proton ﬂux for the day (i.e., at 22:00 UT).

2.5. Normalization of Characteristics, Labeling, Oversampling, and Train-Test Separation

Extraction of characteristics yields, for each day, 300 characteristics corresponding to the magnetic ﬁelds of ARs (each
of 10 included ARs/patches has 30 characteristics), 10 SXR characteristics (5 for each SXR channel), 6 characteristics
of the >10 MeV proton ﬂux, and counts of type II, III, and IV radio bursts. Each characteristic is normalized to the
zero-one range, the similar AR characteristics (for example, the unsigned current helicities for each of 10 ARs) are
normalized following the same scale. These characteristics are organized into 319-component vectors, one for each day.
Each vector of characteristics is assigned with the label, 1 or 0, depending on whether the ﬂux of > 10 MeV protons
(averaged from two GOES detectors) hits the 10 pfu threshold sometime during the next day or not. As a result of
the labeling, there were 101 days during the June 2010 — December 2019 time period labeled as days with SPEs and
3400 days labeled as having no SPEs. That leaves us with a class-imbalance ratio of about 1 to 34.

Next, we separate the labeled vectors of characteristics into the train and test data subsets. The separation strategy
shown in Table 1. As one can see, there are approximately twice as many samples in the train data set than in the
test data set, and the class-imbalance ratios in both data sets are also kept approximately equal to 1 to 34. Because
the separation is done by keeping long chunks in the same data sets, we avoid the temporal coherence problem
(Ahmadzadeh et al. 2021).

Because the data set suﬀers from class-imbalance, we adopt a strategy to mitigate this (Ahmadzadeh et al. 2021). In
this work, we oversample the positive cases (days with SPEs) in the dataset to balance the number of negative cases.
In essence, this means that we introduce 34 times more positive samples into the data set. In this case, both the train
and the test data sets become balanced, which eases the ML training by allowing us to use any common loss function
for training.

3. MACHINE LEARNING SETUP

There are several challenges in SPE prediction, including the unknown origin on the solar surface for some events, and
diﬃculties in separating the proton ﬂux enhancement from variations of the proton ﬂux background. These problems
could be solved if we consider the whole Sun for building a prediction. There is also the third issue. The number of
days with SPEs (66 days in the train data set, see Table 1) is small in comparison to the number of characteristics
(319 for each day). In such situations, overﬁtting (i.e., memorization of the train data set instead of its generalization)
is a common problem. To avoid overﬁtting at the level of the neural network architecture, one can bring some physical
guidance into the prediction algorithm and reduce the number of free parameters to tune during the training. Here, we
present some guidance on how the neural network architecture should look. We note, ﬁrst, that the data set contains
the characteristics of 10 ARs with the largest unsigned magnetic ﬂuxes and the pre-processing should be the same
for each of the 10 ARs used for prediction. Second, the prediction of SPEs and other transient events is typically
performed for individual ARs using highly correlated characteristics of the magnetic ﬁeld. Both of these points help
us determine the neural network architecture to be used for the whole-Sun problem.

Figure 1 illustrates the architecture of the neural network used in this work. As one can see, the characteristics
for each AR are initially pre-processed in the form of “AR blocks” — sets of fully connected layers that reduce the
initially entered 30 characteristics of each AR to 2 characteristics summarizing the AR capability to produce an SPE.
The numbers of neurons in the subsequent layers of the AR blocks are set at 30 - 15 - 8 - 4 - 2. All AR blocks share
the same weights and biases (free parameters tuned during the neural network training). The outputs of the blocks
are then summed up and entered in the main part of the network together with other daily characteristics (SXR and
> 10 MeV proton ﬂux characteristics, and the counts of type II, III, and IV radio bursts). The numbers of neurons in
subsequent layers of the main part are set at 21 - 15 - 10 - 5 - 2. The output of the network consists of two numbers.

Prediction of Solar Proton Events

5

Depending on which of these numbers is larger, the algorithm issues a prediction of the occurrence/non-occurrence
of an SPE event during the next day. Rectiﬁed Linear Unit (ReLU) activation functions are used everywhere in the
network, and the two outputs of the network are normalized to the probabilities using the Soft-Max function. The
loss function for network training is the cross-entropy loss deﬁned as:

L = −

1
N

N
(cid:88)

i=1

yi · log(pi) + (1 − yi)log(1 − pi).

(1)

Here N is the total number of samples in the data set, yi is the label of the i-th feature vector (1 or 0), and pi is the
predicted probability of the i-th feature vector to have a label 1. The “adam” optimizer (Kingma & Ba 2015) with a
learning rate of 0.00025 was used to progress the training. The batch size was equal to the entire training data set (i.e.,
the data set was not subdivided into the “mini-batches”). To avoid overﬁtting while training the network, we employ
the early stopping criterion. After each iteration (epoch) of the training process, we evaluate the performance of the
network on the test data set in terms of the loss function Ltest. We stop the learning process when the mean value
of Ltest for ten consecutive epochs is larger than or equal to the mean value of Ltest for the previous ﬁve consecutive
epochs. The same training procedure is repeated ﬁve times to check if weight initialization and data set shuﬄing aﬀect
the training and the resulting prediction. An example of the training process for the neural network trained on all
characteristics is presented in Figure 2.

To test how the inclusion or exclusion of various characteristics aﬀects the forecast, we substitute the excluded
characteristics with a certain constant number (equal to 0.5) without modifying the network architecture. We also
examine the network performance using various metrics for binary predictions. For binary predictions, we utilize the
True Skill Statistics (TSS) and Heidke Skill Score (HSS) metrics of the 1st and 2nd kind (Bobra & Couvidat 2015).
The optimal threshold for the network output is selected for each particular binary metric separately. In addition,
we look at the Receiver Operating Characteristic (ROC) curve and calculate the area under this curve. The ROC
curve illustrates how the false-positive rate (the fraction of incorrectly-predicted days without SPEs) and true-positive
rate (the fraction of correctly-predicted days with SPEs) change with the variation of the threshold for the network
output. Because we are also interested in all-clear forecasts, we introduce a new metric, Weighted True Skill Statistics
(WTSS), deﬁned as:

W T SS(α) = 1 −

(cid:18)

α

2
α + 1

W T SS(1) = T SS = 1 −

F N
P
F N
P

+

−

F P
N
F P
N

(cid:19)

,

.

(2)

(3)

Here FN is the number of SPEs predicted as no-SPEs, FP is the number of no-SPEs predicted as SPEs, P is the
total number of SPEs, N is the total number of no-SPEs, α is the parameter that indicates how strongly the missed
event rate (FN/P) is penalized with respect to the false alarm rate (FP/N). The WTSS metric preserves some of the
properties of the TSS metrics. First, for each particular α, it is not sensitive to the class-imbalance ratio and ranges
from -1 (totally wrong forecast) to 1 (entirely correct forecast). WTSS = 0 corresponds to the random choice forecast.
We analyze how this score behaves for diﬀerent α values. The large values of α are of special interest for the “all-clear”
forecasts as they indicate a signiﬁcantly lower tolerance to the missed event rate than the false alarm rate.

4.1. Comparison of Neural Network Results with SWPC NOAA

4. RESULTS

A comparison of the prediction results obtained with the ML algorithm (an artiﬁcial neural network) with the daily
operational forecasts by SWPC NOAA and persistence forecast (the prediction for the next day being the same as
the observation for the current day) in terms of various metrics is summarized in Table 2. Based on these results,
the “winner” (the forecast receiving the highest score) depends on the selected metrics. For example, the SWPC
NOAA forecast outperforms the ML-based forecast in terms of the HSS1 and HSS2 metrics (i.e. has higher scores for
these metrics). However, the situation is the opposite for almost all other metrics (including the TSS score), where
the ML-based forecast performs better than the SWPC forecast. The persistence model performs worse for both the
operational forecast and ML-based model prediction.

Figure 3 illustrates the ROC curves for the ML-based prediction and SWPC NOAA operational forecast. These
ROC curves look very similar to the ones presented by Huang et al. (2012) in Fig. 4. One can see that the primary

6

Sadykov et al.

diﬀerence between the two ROC curves is in the region of high true-positive rates (and, correspondingly, low false-
negative rates). There, the ML-based forecast outperforms the SWPC NOAA forecast. Because the top of the ROC
curve corresponds to the region when the number of false-negative predictions is very low (i.e., when very few SPEs
are missed), this region can be considered as a region of the “all-clear” forecasts. Correspondingly, the ML-based
predictions outperform the SWPC NOAA forecasts in terms of the potential to issue “all-clear” predictions. This is
also clearly visible from the analysis of WTSS scores in Table 2 and is discussed later in the text.

Another way of comparing the forecasts is to unroll the probabilities over time and compare them for particular
events (Benvenuto et al. 2020). Figure 4 illustrates how the SWPC NOAA forecast and ML-based prediction performed
during the September 2017 events. The soft-max function was used to normalize the output of the neural network
(two channels) into “probabilities”. Although these numbers may not necessarily have a meaning of probability in
the statistical sense, they are still enough to analyze how the network reacts to the upcoming event. One can see two
major SPEs during that month, marked by green rectangles in the plot. It is clear that the SWPC NOAA forecast
reacts to both events with one day delay, while the ML-issued forecast captures the beginning of the ﬁrst event well,
and the corresponding probability does not drop strongly at the beginning of the second event.

In the previous chapter, we have introduced the Weighted True Skill Statistics (WTSS) metrics. The parameter α
determines the ratio of penalties for the missed event rate and the false alarm rate. Figure 5 illustrates the WTSS
score as a function of α for the ML-based prediction and the SWPC NOAA forecasts. Any value of α > 1 indicates
the preference to have a higher false alarm rate with respect to the missed event rate. One can see in this ﬁgure that,
while the ML prediction based on all characteristics and the SWPC NOAA forecast are mostly similar to each other
for α < 1, the ML-based prediction starts to outperform the SWPC NOAA forecast for α ≥ 1. This indicates that
the ML-based forecasts behave better in the regime when the missed events are not desirable (i.e., in the “all-clear”
regime).

4.2. Prediction Based on SHARP AR Characteristics

In addition to building an ML-based model on all available characteristics, we also investigate the model performance
based on AR characteristics only (i.e., SHARP characteristics for this research). We consider four cases here: 1) learning
based on the SHARP characteristics where the extension of ARs behind the limb is taken into account; 2) learning
without such extension; 3) learning when the AR coordinates are not provided to the neural network; and 4) learning
then the ARs are distinguished based on their unsigned magnetic ﬂux (i.e., not summed up before entering the main
network, see Section 3 and Figure 1). The results are summaries in rows 2-5 in Table 3.

The AR-based predictions score is smaller compared to SWPC NOAA forecasts for any of the scores considered
in Table 3 except WTSS for α ≥ 2. For example, the HSS1 score (indicates the performance of the prediction with
respect to the fully negative no-SPE prediction) is zero for the AR-based predictions. Other scores also experience a
decrease when only SHARP characteristics are considered. Such a decrease in performance is also evident from the
ROC curves presented in Figure 6. Another observation is that the extension of ARs to the western limb and beyond
helps obtain a signiﬁcantly better prediction compared to the case when ARs are not extended. This is evident from
the scores in Table 3 and the ROC curves in Figure 6. The diﬀerence between the AR-based forecasts with and without
the introduction of AR coordinates is negligible and, most probably, is related to the poor sampling of the positive
events in the data and its small size. The last interesting point is, if the AR Block outputs are not summed before
propagating to the main network, the performance of the forecast decreases in terms of all considered scores.

Nevertheless, an interesting detail is that, although the AR-based forecasts do not perform well compared to SWPC
NOAA for most of the considered metrics, they start to outperform the operational forecasts when approaching the
“all-clear” regime. This is also evident in Figure 5, where one can see that the AR-based forecast demonstrates higher
W T SS scores for α (cid:38) 1.5. The possible interpretation of such behavior is discussed in more detail in Section 5.

4.3. Inﬂuence of Feature Inclusion/Exclusion on the Forecast

In addition to considering AR-based predictions, we investigate how the exclusion of characteristics of various types
aﬀects the forecast. If the exclusion of the characters from the data set does not aﬀect the predictor performance after
its retraining, the information carried by this characteristic with respect to the predicted quantity can be inferred from
other characteristics. On the other hand, if the predictor performance drops signiﬁcantly, the characteristic cannot be
replaced by other inputs and is especially valuable for the forecasts. First, we exclude the AR (SHARP) characteristics,
the solar proton ﬂux-related characteristics, the soft X-ray characteristics, and the counts of the radio bursts, each

Prediction of Solar Proton Events

7

separately. The results of this experiment are summarized in Table 3. The exclusion of the proton ﬂux characteristics
seriously reduces the forecasting scores, and excluding other characteristics does not aﬀect the score. On the other
hand, predictions based solely on the proton ﬂux characteristics have slightly reduced performance. While there is no
doubt that the prehistory of the proton ﬂux is the most valuable characteristic, identifying the second most valuable
one remains open.

To answer this question, we considered each of the remaining groups of characteristics combined with the proton ﬂux
characteristics. The results are summarized in Table 3 and visualized in Figure 7. The proton and SXR ﬂux charac-
teristics, grouped together, already reach and even outperform the prediction based on all characteristics. Predictions
based on the proton ﬂux and AR characteristics demonstrate a slightly weaker performance, and the results are even
weaker for the inclusion of the counts of the radio bursts.

5. DISCUSSION

One of the current goals is to highlight several new approaches to predict Solar Proton Events (SPE) and solar
transient events in general. One such approach is a custom-built neural network used to construct whole-Sun-based
predictions instead of considering each AR separately. In our opinion, there are several advantages to this approach.
First, it naturally considers characteristics of the data integrated over the whole Sun and in-situ measurements, such
as the SXR and proton ﬂuxes. There is no need to link the events detected in such measurements to the host ARs.
Therefore, there is no problem with the background for the events: any increase of the measured ﬂux above a certain
threshold may be considered as an event. This may be especially important for binary prediction of solar ﬂares, where
the estimate of the pre-ﬂare background depends on the background subtraction method (Ryan et al. 2012; Sadykov
et al. 2019).

The second important advantage of the built architecture is the use of shared weights for “AR Blocks” and similar
processing for ARs. This allows us to signiﬁcantly reduce the number of free parameters in the network (weights
and biases) and simplify the training. In fact, we have also considered a fully connected architecture with no weight
sharing. We found that a fully connected architecture is hard to train because of fast overﬁtting. Correspondingly, the
shared-weight architecture introduced here was necessary to train the network successfully. The distinction between
ARs within the network (which introduces more free parameters) makes the AR-based forecast worse (Table 3).

Our results showed that it is necessary to account for the ARs close to the western limb and on the far side for the
AR-based predictions. Figure 6b and Table 3 support this point. If no AR extension to and behind the western limb
is applied, the forecast is worse in terms of the majority of the metrics, and the cross-entropy value is very close to the
totally-random forecast value (∼0.69). Because the solar longitude magnetically connected to the Earth is very close
to the western limb (∼ 78 deg), these results are understandable. It was also pointed out by Cliver et al. (2020) that
the SPE-producing ARs are located between 20 east - 100 west longitudes and tend to appear more in the western
hemisphere. Therefore, a signiﬁcant number of SPEs should come from the ARs whose characteristics are formally
not “trustable” or even not known (i.e., the ARs are located farther than 68 deg from the solar disc center). As one
sees, even a simple model of the AR extension to and behind the western limb helps to improve the forecast. A more
advanced model for the evolution of the AR characteristics can help build more robust forecasts.

Figure 6a and Table 3 also indicate that the exclusion of the AR coordinates does not make the forecast worse,
which is a bit of surprise. Moreover, as evident in Table 3 and Figure 7a, the ML-based prediction does not worsen
if the AR characteristics are completely excluded from the forecast. There are several possible explanations for such
unexpected results. First, this may point to a low complexity of the implemented approach. In this study, we have
worked only with the daily median values of SHARP characteristics but did not include their variations with time. A
consideration of the evolution of SHARP characteristics and analysis of the corresponding multivariate time series is
necessary to increase the forecasting quality. Second, such results may be caused by the fact that the training data
set was very small (only 2222 negative cases and 66 positive cases used for training ( Table 1). On the other hand,
our conclusions indicate a possibility to validate the forecast on longer time series using the proton ﬂux and SXR data
only, or to use the simpliﬁed characteristics of the ARs (such as the Hale and Mackintosh classes, McIntosh 1990)
instead of the vector magnetic ﬁeld characteristics.

Table 3 highlights how valuable various groups of characteristics are for prediction. The most critical set of char-
acteristics comes from the characteristics of the preceding > 10 MeV proton ﬂux. In fact, the forecast is not far, in
terms of performance, from one involving all characteristics even if only SPE characteristics are used. The prediction
becomes signiﬁcantly worse if these characteristics are excluded from the forecast, while predictions based solely on

8

Sadykov et al.

these characteristics are relatively good. This is understandable as the prediction captures the persistence in SPE
occurrence. Essentially, it may capture the fact that if the SPE is happening today and does not end by the end of
today, it continues tomorrow. This is also evident from the experiment when we removed the last >10 MeV proton
ﬂux value for the day (at 22:00 UT). As Table 3 indicates, the performance of proton ﬂux-based forecast drops in this
case.

It was also evident that excluding any of the other groups of characteristics (AR, SXR, or radio burst) does not
aﬀect the prediction. We tested how the inclusion of any one among these three groups, in addition to the proton
ﬂux characteristics, aﬀects the forecast. The results are shown in Figures 7c-e and Table 3. The inclusion of either
the SXR or AR group of characteristics in addition to the proton ﬂux characteristics produces predictions with scores
comparable with the forecast based on all characteristics. The inclusion of both these groups simultaneously does
not improve the prediction. Also, the inclusion of the radio bursts together with the proton ﬂux characteristics does
not improve the prediction but even makes it worse. In some sense, the counts of the radio bursts seem to be the
least valuable feature for the forecast within the settings of this work. Inclusion of the SXR and AR characteristics
It is well known that the
increases the prediction performance, with a higher preference for SXR characteristics.
average SXR levels (and corresponding ﬂare productiveness) are related to the complexity of ARs (Falconer et al.
2012; Sadykov & Kosovichev 2017). Therefore, such results are not surprising. The only signiﬁcant diﬀerence between
these characteristics is when a complex SPE-productive AR is behind the western limb, which was encountered rarely
during the Solar Cycle 24 (https://umbra.nascom.nasa.gov/SEP/).

Another interesting observation following from Table 3 is that the inclusion of additional characteristics or increasing
the complexity of the neural network does not necessarily lead to an increase of the forecast performance and may even
result in a notable decrease. One can notice this by comparing 1) the network trained on the AR characteristics only
and the network where SXR and radio bursts were introduced in addition (lines 3 and 8 in Table 3); 2) the network
trained on a full set of characteristics and on SXR and proton ﬂux characteristics only (lines 1 and 13 in Table 3);
or 3) the AR-trained network where the AR Block outputs are summed and not summed before propagating into the
main network (lines 3 and 6 in Table 3). This behavior may have two reasons behind it. First, the introduction of
new characteristics should not necessarily improve the forecast if the characteristics are not so relevant to the forecast.
The eﬀects of the metrics decreasing with the increase of the number of characteristics are evident, for example, in
Figure 4 by Bobra & Couvidat (2015). Second, the train data set have a very small number of positive samples. In
this situation, the introduction of additional degrees of freedom into the forecasting model in terms of characteristics
or network structure may result in a strengthening of memorization eﬀects.

While constructing SPE predictions in this work, we have used the ﬂux of the > 10 MeV protons averaged over the
east-oriented and west-oriented measurements of protons by the GOES satellite (Rodriguez et al. 2010). Because the
distribution of particles is anisotropic, the measurements of the two directions are not exactly equal to each other.
How does using the data from only one of the directions aﬀect the forecasts? Figure 8 and Table 4 show that using
the particle ﬂux data from one of the two detectors instead of averaging them changes the number of days with SPEs,
and the overall performance of the machine learning approach slightly decreases. On the one hand, this demonstrates
that the usage of the detector-averaged ﬂux leads to a more robust prediction. On the other hand, it shows that using
data from the GOES satellites that did not have measurements in two directions does not result in a signiﬁcant loss
of performance, especially in the regime of all-clear forecasts.

Although we have formulated the prediction of SPEs as a simplistic feature-based binary classiﬁcation problem in
this study, it leads to several important outcomes and analysis insights. The Weighted True Skill Statistics (WTSS)
score can tell the end-user more about the applicability of the constructed prediction for various purposes. Our results
show that the machine learning forecast performs better than the SWPC NOAA forecast when the missed events are
much less desirable than the false alarms (i.e., when parameter α > 1 for WTSS(α), Figure 5). The same conclusion
follows from the upper part of the ROC curves in Figure 3. The forecasting regime when missing events is not desirable
is critical from the operational perspective to approach “all-clear” forecasts. Sometimes, missing a single SPE may
lead to a hazardous situation and signiﬁcantly harm operational planning. We see that the ML-based predictions deal
with such a situation better than the current daily operational forecasts.

Unfortunately, the current SWPC NOAA forecasts do not capture some SPEs at all. In 14 out of 101 SPE days in
our data set, only 1% probability of the event for that day was issued. In addition, there was a zero chance to catch
these events by adjusting the probability threshold. On the other hand, the ML-based predictions demonstrated a
capability to capture all SPEs with about a 40% false-positive rate (correspondingly, about 500 days in the test data

Prediction of Solar Proton Events

9

set were predicted as having SPEs while they did not). The false-positive rate for all-clear forecast becomes lower than
30% if constructed based on the proton and SXR ﬂux properties only. Although these numbers are still large, we note
that a good portion of the test data set contained the peak of Solar Cycle 24 (years 2014-2015), when the solar activity
was high almost every day, and complex ARs existed at the solar surface. It also contained the year 2017, when major
SPEs happened on the Sun (and were captured by the algorithm, as Figure 4 demonstrates). Correspondingly, all-clear
forecasts based on machine learning are possible, although with about a 30-40% false-positive rate. Nevertheless, this
seems to be a reasonable price for the all-clear approach.

In this study we have implemented a novel approach to predict SPEs using a neural network of custom architecture
that eﬃciently tackles the problems of whole-Sun prediction and unknown host active regions. The predictions were
made based on the daily characteristics of the vector magnetic ﬁelds in ARs, emitted soft X-ray and proton ﬂuxes, as
well as the counts of type II, III, and IV radio bursts. The primary results of the investigation are the following:

6. CONCLUSION

• For a feature-based binary prediction, it is very important to investigate how the prediction behaves with respect

to the diﬀerent metrics and check for the forecast ROC curves or similar types of characteristics;

• If the prediction is constructed based on the AR characteristics only, then the prediction signiﬁcantly beneﬁts

from the inclusion of proxies characterizing ARs on the western limb and the far side;

• Characteristics of the preceding 10 MeV proton ﬂux are the most valuable characteristics for the prediction.
The inclusion of the soft X-ray ﬂux characteristics and the AR characteristics is valuable, with a preference
of SXR characteristics, while the counts of type II, type III, and type IV radio bursts are the least-valuable
characteristics;

• Exclusion of the information about the AR characteristics and the radio bursts does not aﬀect the forecast
and even makes it better. This provides a possibility to construct an operational forecast based on the GOES
observations only. The possible reasons for such behavior are discussed in Section 5;

• The constructed machine-learning-based forecast is very promising in situations when missing events is very
undesirable. For any α >1 for W T SS(α) metrics, the ML-based forecast outperforms the SWPC NOAA forecast.

The presented study has certain limitations. One of the most important limitations is the signiﬁcant data shortage.
We have analyzed the SPEs and assessed the prediction algorithm performance only for Solar Cycle 24, which contained
just 101 SPE days (positive samples) in total. Such a short data set represents a challenge for the learning algorithm.
Testing of the algorithm on a more extensive data set should lead to more generalized and robust conclusions. The data
shortage is also the reason why we have utilized the deﬁnitive SHARP CEA data series instead of their near-real-time
analogs (Hoeksema et al. 2014; Nishizuka et al. 2021; Georgoulis et al. 2021), since the routine computations of NRT
data started only in September 2012. Another limitation is the way the machine learning procedure was set up in this
work. Typically, the data sets are divided into three parts (train, validation, and test). The ML algorithm is tuned
on the validation data set ﬁrst and evaluated on the test data set then. Here, because of the data shortage, we have
separated the data set into train and test parts only. One can assume that we have emulated the situation when the
validation data set is entirely identical to the test data set. Because the same assumption was eﬀectively made for the
SWPC NOAA forecasts (i.e., the probability thresholds were optimized on the test part but not on the train part),
we can still compare the performances of both approaches and generalize the conclusions.

We also would like to indicate numerous possibilities to improve the analysis performed in this work. First, the
prediction algorithm constructed here is based on daily characteristics. However, the actual data (from which the
characteristics were derived) constitute a multivariate time series (MVTS). The potential of MVTS analysis for the
prediction of SPEs still has to be understood. Another way to improve the prediction algorithm is to include more
valuable data sources. In particular, it was found in several studies that the characteristics of Coronal Mass Ejections
(CMEs) are connected to the characteristics of SPEs (Richardson et al. 2014; Wang et al. 2019; Kalaivani et al. 2020;
Bruno & Richardson 2021). Therefore, although the CME observations are not available in real-time, the inclusion of
CME characteristics available for the previous day may improve SPE forecasts. Other data sources of interest are the
characteristics of proton ﬂuxes of energies other than >10 MeV, soft X-ray characteristics of individual solar ﬂares (such

10

Sadykov et al.

as temperatures and emission measures, Sadykov et al. 2019; Kahler & Ling 2020), the timing of the recorded radio
bursts, etc. To make the prediction algorithm more robust and generalize it for the other solar-cycle conditions, we plan
to extend the prediction to the Solar Cycle 23 data and work with other characteristics of ARs (Hale and Mackintosh
classes, McIntosh 1990). Finally, we plan to extend the proposed forecast implementation to other deﬁnitions of SPEs
(other particle ﬂux and energy thresholds) and other prediction time windows. To summarize, the prediction of SPEs
targeted to a particular goal (e.g., an “all-clear” SPE prediction as in this work) is still a challenging problem from
many perspectives, and we plan to continue and broaden this eﬀort in future work.

The research was supported by NASA Early Stage Innovation program grant 80NSSC20K0302, NASA LWS grant
80NSSC19K0068, NSF EarthCube grant 1639683, and NSF grant 1835958. VMS acknowledges the NSF FDSS grant
1936361 and NSF grant 1835958. EI acknowledges the RSF grant 20-72-00106.

ACKNOWLEDGMENTS

REFERENCES

Ahmadzadeh, A., Aydin, B., Georgoulis, M. K., et al. 2021,

Engell, A. J., Falconer, D. A., Schuh, M., Loomis, J., &

ApJS, 254, 23, doi: 10.3847/1538-4365/abec88

Bissett, D. 2017, Space Weather, 15, 1321,

Ameri, D., Valtonen, E., & Pohjolainen, S. 2019, SoPh, 294,

doi: 10.1002/2017SW001660

122, doi: 10.1007/s11207-019-1512-9

Falconer, D. A., Moore, R. L., Barghouty, A. F., &

Aminalragia-Giamini, S., Jiggens, P., Anastasiadis, A.,

Khazanov, I. 2012, ApJ, 757, 32,

et al. 2020, Journal of Space Weather and Space Climate,

doi: 10.1088/0004-637X/757/1/32

10, 1, doi: 10.1051/swsc/2019043

Georgoulis, M. K., Bloomﬁeld, D. S., Piana, M., et al. 2021,

Bain, H. M., Brea, P., & Adamson, E. T. 2019, in AGU Fall

arXiv e-prints, arXiv:2105.05993.

Meeting Abstracts, Vol. 2019, NG21A–03

https://arxiv.org/abs/2105.05993

Bain, H. M., Steenburgh, R. A., Onsager, T. G., & Stitely,

Hoeksema, J. T., Liu, Y., Hayashi, K., et al. 2014, Solar

E. M. 2021, Space Weather, n/a, e2020SW002670,

Physics, 289, 3483, doi: 10.1007/s11207-014-0516-8

doi: https://doi.org/10.1029/2020SW002670

Huang, X., Wang, H.-N., & Li, L.-P. 2012, Research in

Balch, C. C. 1999, Radiation Measurements, 30, 231,

Astronomy and Astrophysics, 12, 313,

doi: 10.1016/S1350-4487(99)00052-9

—. 2008, Space Weather, 6, S01001,

doi: 10.1029/2007SW000337

doi: 10.1088/1674-4527/12/3/007

Jeong, E.-J., Lee, J.-Y., Moon, Y.-J., & Park, J. 2014,

Journal of Korean Astronomical Society, 47, 209,

Benvenuto, F., Campi, C., Massone, A. M., & Piana, M.

doi: 10.5303/JKAS.2014.47.6.209

2020, ApJL, 904, L7, doi: 10.3847/2041-8213/abc5b7

Kahler, S. W., & Ling, A. G. 2020, ApJ, 901, 63,

Bobra, M. G., & Couvidat, S. 2015, ApJ, 798, 135,

doi: 10.3847/1538-4357/abae5e

doi: 10.1088/0004-637X/798/2/135

Kalaivani, P. P., Shanmugaraju, A., Prakash, O., & Kim,

Bobra, M. G., & Ilonidis, S. 2016, ApJ, 821, 127,

R. S. 2020, Earth Moon and Planets, 123, 61,

doi: 10.3847/0004-637X/821/2/127

doi: 10.1007/s11038-020-09533-9

Bobra, M. G., Sun, X., Hoeksema, J. T., et al. 2014, SoPh,

Kataoka, R., Sato, T., Miyake, S., Shiota, D., & Kubo, Y.

289, 3549, doi: 10.1007/s11207-014-0529-3

Bruno, A., & Richardson, I. G. 2021, SoPh, 296, 36,

2018, Space Weather, 16, 917,

doi: 10.1029/2018SW001874

doi: 10.1007/s11207-021-01779-4

Kim, K. N., Sin, S. A., Song, K. A., & Kong, J. H. 2018,

Campi, C., Benvenuto, F., Massone, A. M., et al. 2019,

Ap&SS, 363, 170, doi: 10.1007/s10509-018-3263-8

ApJ, 883, 150, doi: 10.3847/1538-4357/ab3c26

Kingma, D. P., & Ba, J. 2015, CoRR, abs/1412.6980

Cliver, E. W., Mekhaldi, F., & Muscheler, R. 2020, ApJL,

Laurenza, M., Alberti, T., & Cliver, E. W. 2018, ApJ, 857,

900, L11, doi: 10.3847/2041-8213/abad44

107, doi: 10.3847/1538-4357/aab712

Crown, M. D. 2012, Space Weather, 10, S06006,

Lovelace, A. M., Rashid, A. M., de Wet, W. C., et al. 2018,

doi: 10.1029/2011SW000760

Space Weather, 16, 1073, doi: 10.1029/2017SW001773

Prediction of Solar Proton Events

11

Malandraki, O. E., Heber, B., Labrenz, J., et al. 2018, in

EGU General Assembly Conference Abstracts, EGU

General Assembly Conference Abstracts, 8180

Martens, P. C. 2018, in Deep Space Gateway Concept

Science Workshop, Vol. 2063, 3188

Martens, P. C., & Angryk, R. A. 2018, in Space Weather of

the Heliosphere: Processes and Forecasts, ed. C. Foullon

& O. E. Malandraki, Vol. 335, 344–347,

doi: 10.1017/S1743921318000510

McIntosh, P. S. 1990, SoPh, 125, 251,

doi: 10.1007/BF00158405

Richardson, I. G., von Rosenvinge, T. T., Cane, H. V., et al.
2014, SoPh, 289, 3059, doi: 10.1007/s11207-014-0524-8

Rodriguez, J. V., Onsager, T. G., & Mazur, J. E. 2010,

Geophys. Res. Lett., 37, L07109,
doi: 10.1029/2010GL042531

Ryan, D. F., Milligan, R. O., Gallagher, P. T., et al. 2012,

ApJS, 202, 11, doi: 10.1088/0067-0049/202/2/11

Sadykov, V. M., & Kosovichev, A. G. 2017, ApJ, 849, 148,

doi: 10.3847/1538-4357/aa9119

Sadykov, V. M., Kosovichev, A. G., Kitiashvili, I. N., &

Frolov, A. 2019, ApJ, 874, 19,
doi: 10.3847/1538-4357/ab06c3

Miteva, R., Samwel, S. W., & Krupar, V. 2017, Journal of

Saito, S., Wickramasinghe, N. K., Sato, T., & Shiota, D.

Space Weather and Space Climate, 7, A37,

doi: 10.1051/swsc/2017035

Nishizuka, N., Kubo, Y., Sugiura, K., Den, M., & Ishii, M.

2021, Earth, Planets, and Space, 73, 64,

doi: 10.1186/s40623-021-01381-9

Nishizuka, N., Sugiura, K., Kubo, Y., et al. 2017, ApJ, 835,

156, doi: 10.3847/1538-4357/835/2/156

N´u˜nez, M. 2015, Space Weather, 13, 807,

doi: 10.1002/2015SW001256

2021, Earth, Planets, and Space, 73, 57,
doi: 10.1186/s40623-021-01377-5

SPE Prediction Project URL. 2021, SPE prediction archive

download link, https:
//sun.njit.edu/SEP/ESISPE-prediction-archvie-2021.rar
SWPC NOAA Space Weather Scales. 2011, SWPC NOAA
Solar Radiation Storms, https://www.swpc.noaa.gov/
sites/default/ﬁles/images/NOAAscales.pdf

Wang, C., Cui, Y.-m., Ao, X.-z., et al. 2019, ChA&A, 43,

34, doi: 10.1016/j.chinastron.2019.02.006

Papaioannou, A., Anastasiadis, A., Kouloumvakos, A., et al.

Winter, L. M., & Ledbetter, K. 2015, ApJ, 809, 105,

2018, SoPh, 293, 100, doi: 10.1007/s11207-018-1320-7

doi: 10.1088/0004-637X/809/1/105

Parker, E. N. 1958, ApJ, 128, 664, doi: 10.1086/146579

Reames, D. V. 2021, Solar Energetic Particles. A Modern

Primer on Understanding Sources, Acceleration and

Propagation, Vol. 978, doi: 10.1007/978-3-030-66402-2

Zhong, Q., Wang, J., Meng, X., Liu, S., & Gong, J. 2019,
Space Weather, 17, 709, doi: 10.1029/2018SW001915

Zimovets, I. V., & Sadykov, V. M. 2015, Advances in Space

Research, 56, 2811, doi: 10.1016/j.asr.2015.01.041

12

Sadykov et al.

Figure 1. A schematic representation of a neural network architecture for daily whole-Sun prediction of SPEs. The number of
AR Blocks is equal to 10 for this work. The neuron connections in AR Blocks share the weights and the biases.

Prediction of Solar Proton Events

13

Figure 2. An example of the cross-entropy loss function decay obtained for the train and test subsets during the neural network
training procedure.

14

Sadykov et al.

Figure 3. (a) Receiver Operating Characteristic (ROC) curves for the machine learning-based forecast using all characteristics
(black solid line) and for the SWPC NOAA forecast (blue dotted line). Panel (b) presents the zoomed version of the same ROC
curves.

Prediction of Solar Proton Events

15

Figure 4. Probability of the SPEs rolled over time for August 26 - October 1, 2017 time period. The red line corresponds
to the SPE probability issued by SWPC NOAA for the current day, the blue line corresponds to the machine learning-issued
probability for the current day, the green rectangles mark actual times of SPE occurrence.

16

Sadykov et al.

Figure 5. The Weighted True Skill Statistics (WTSS) as a function of a weighting parameter (α) for ML-based predictions
using all characteristics (black solid line), using SHARP characteristics of ARs only (red dashed line), and calculated for the
SWPC NOAA probabilities (blue dotted line). The vertical black dotted line corresponds to α = 1 case, when W T SS(1) = T SS.

Prediction of Solar Proton Events

17

Figure 6. Comparison of the ROC curves for the ML predictions based on AR characteristics only (black solid line) and
SWPC NOAA forecasts (blue dotted line). Additional red dashed lines correspond to the cases when no AR coordinates were
introduced to the neural network (panel a), and when no AR extension to an behind the western limb is made (panel b).

18

Sadykov et al.

Table 1. Properties of the train and test data sets.

Property
Time covered

SPE days
Non-SPE days
Class ratio

Train data set
Jun 2010 - Dec 2013,
Jan 2016 - Dec 2016,
Oct 2018 - Dec 2019
66
2222
about 1/34

Test data set
Jan 2014 - Dec 2015,
Jan 2017 - Oct 2018

35
1178
about 1/34

Table 2. ML-based prediction model performance, and its comparison with SWPC NOAA forecasts and a persistence model.

Score
HSS1
HSS2
Area below ROC
Cross-entropy loss
TSS
WTSS(2)
WTSS(5)
WTSS(10)

ML-based model
0.377±0.028
0.635±0.008
0.959±0.001
0.273±0.006
0.820±0.006
0.803±0.005
0.857±0.004
0.920±0.004

SWPC NOAA forecast Persistence model

0.571
0.748
0.919
0.461
0.786
0.758
0.765
0.817

0.314
0.647
-
-
0.647
0.536
0.425
0.375

Prediction of Solar Proton Events

19

Figure 7. Comparison of the ROC curves for the ML predictions using all characteristics (black solid line) and SWPC NOAA
forecasts (blue dotted line). Additional red dashed lines correspond to the cases where the network was trained with no AR
characteristics (a), no proton ﬂux characteristics (b), only on proton and soft X-ray ﬂux characteristics (c), proton ﬂux and AR
characteristics (d), only on proton ﬂux and radio burst characteristics (e), and solely on proton ﬂux characteristics (f).

20

Sadykov et al.

Figure 8. (a) Comparison of the ROC curves for the ML predictions using the averaged particle ﬂux from the east and west
GOES detectors (black solid line), using only the east detector particle ﬂux (blue dotted lines), and using only the east detector
particle ﬂux (red dotted lines). Panel (b) presents the zoomed version of the same ROC curves.

Prediction of Solar Proton Events

21

.
l
e
d
o
m
n
o
i
t
c
i
d
e
r
p

d
e
s
a
b
-
L
M

r
o
f

s
c
i
t
s
i
r
e
t
c
a
r
a
h
c

s
u
o
i
r
a
v

f
o

n
o
i
s
u
l
c
x
e
/
n
o
i
s
u
l
c
n
i

f
o

s
t
s
e
t

e
h
t

f
o

s
t
l
u
s
e
R

.
3

e
l
b
a
T

)
0
1
(
S
S
T
W

)
5
(
S
S
T
W

)
2
(
S
S
T
W

S
S
T

s
s
o
l

y
p
o
r
t
n
e
-
s
s
o
r
C

C
O
R
w
o
l
e
b

a
e
r
A

2
S
S
H

1
S
S
H

l
e
d
o
M

4
0
0
.
0
±
0
2
9
.
0

4
0
0
.
0
±
7
5
8
.
0

5
0
0
.
0
±
3
0
8
.
0

6
0
0
.
0
±
0
2
8
.
0

6
0
0
.
0
±
3
7
2
.
0

1
0
0
.
0
±
9
5
9
.
0

8
0
0
.
0
±
5
3
6
.
0

8
2
0
.
0
±
7
7
3
.
0

)
e
n

i
l
e
s
a
b
(

l
e
d
o
m
L
M

7
1
8
.
0

5
6
7
.
0

8
5
7
.
0

6
8
7
.
0

3
0
0
.
0
±
2
1
9
.
0

3
0
0
.
0
±
3
7
8
.
0

6
0
0
.
0
±
3
0
8
.
0

4
0
0
.
0
±
6
3
7
.
0

7
0
0
.
0
±
7
2
9
.
0

4
0
0
.
0
±
4
7
8
.
0

8
0
0
.
0
±
5
9
7
.
0

0
1
0
.
0
±
3
2
7
.
0

4
0
0
.
0
±
6
6
8
.
0

8
0
0
.
0
±
5
5
7
.
0

6
0
0
.
0
±
6
3
5
.
0

8
0
0
.
0
±
3
3
3
.
0

6
0
0
.
0
±
0
1
9
.
0

1
1
0
.
0
±
4
3
8
.
0

6
1
0
.
0
±
6
7
6
.
0

6
3
0
.
0
±
9
5
5
.
0

3
0
0
.
0
±
6
3
9
.
0

4
0
0
.
0
±
3
8
8
.
0

4
0
0
.
0
±
8
0
8
.
0

3
0
0
.
0
±
0
0
8
.
0

1
0
0
.
0
±
8
8
8
.
0

5
0
0
.
0
±
0
0
8
.
0

5
1
0
.
0
±
5
5
6
.
0

4
1
0
.
0
±
5
9
5
.
0

4
1
0
.
0
±
9
0
9
.
0

1
1
0
.
0
±
9
4
8
.
0

3
1
0
.
0
±
0
1
8
.
0

3
1
0
.
0
±
4
1
8
.
0

0
1
0
.
0
±
8
2
9
.
0

9
0
0
.
0
±
7
7
8
.
0

6
1
0
.
0
±
8
0
8
.
0

6
1
0
.
0
±
5
2
8
.
0

3
0
0
.
0
±
3
8
8
.
0

6
0
0
.
0
±
4
3
8
.
0

5
0
0
.
0
±
7
7
7
.
0

7
0
0
.
0
±
8
0
8
.
0

2
3
0
.
0
±
5
4
8
.
0

6
4
0
.
0
±
9
7
7
.
0

4
0
0
.
0
±
1
7
7
.
0

6
0
0
.
0
±
0
0
8
.
0

1
0
0
.
0
±
4
5
9
.
0

2
0
0
.
0
±
5
1
9
.
0

3
0
0
.
0
±
0
3
8
.
0

3
0
0
.
0
±
1
2
8
.
0

5
1
0
.
0
±
5
1
9
.
0

6
1
0
.
0
±
0
5
8
.
0

6
0
0
.
0
±
3
8
7
.
0

0
1
0
.
0
±
3
1
8
.
0

1
0
0
.
0
±
8
5
8
.
0

2
0
0
.
0
±
5
3
8
.
0

7
0
0
.
0
±
4
9
7
.
0

1
1
0
.
0
±
6
0
8
.
0

1
6
4
.
0

4
0
0
.
0
±
9
7
3
.
0

8
0
0
.
0
±
5
9
3
.
0

4
0
0
.
0
±
2
4
6
.
0

6
1
0
.
0
±
0
2
5
.
0

2
0
0
.
0
±
7
6
2
.
0

2
1
0
.
0
±
4
9
4
.
0

7
0
0
.
0
±
7
7
2
.
0

8
0
0
.
0
±
3
6
2
.
0

3
0
0
.
0
±
3
8
2
.
0

0
1
0
.
0
±
3
1
3
.
0

2
0
0
.
0
±
6
5
2
.
0

1
1
0
.
0
±
6
8
2
.
0

3
0
0
.
0
±
3
0
3
.
0

9
1
9
.
0

8
4
7
.
0

1
7
5
.
0

t
s
a
c
e
r
o
f

A
A
O
N
C
P
W
S

2
0
0
.
0
±
7
0
9
.
0

0
1
0
.
0
±
4
9
2
.
0

2
0
0
.
0
±
5
1
9
.
0

4
1
0
.
0
±
1
3
3
.
0

6
2
0
.
0
±
5
5
6
.
0

3
3
0
.
0
±
7
6
0
.
0

8
1
0
.
0
±
8
9
7
.
0

4
1
0
.
0
±
0
1
1
.
0

0
.
0

0
.
0

0
.
0

0
.
0

d
e
s
a
b
-
R
A
L
M

)
s
e
t
a
n
d
r
o
o
c

i

o
n
(

d
e
s
a
b
-
R
A
L
M

)
n
o
i
s
n
e
t
x
e

o
n
(

d
e
s
a
b
-
R
A
L
M

)
d
e
h
s
i
u
g
n
i
t
s
i

d

s
R
A
(

d
e
s
a
b
-
R
A
L
M

1
0
0
.
0
±
1
6
9
.
0

8
0
0
.
0
±
3
5
6
.
0

3
0
0
.
0
±
3
8
3
.
0

)
a
t
a
d
R
A
o
n
(

L
M

4
0
0
.
0
±
4
5
8
.
0

4
2
0
.
0
±
4
4
2
.
0

3
1
0
.
0
±
1
1
0
.
0

)
a
t
a
d

x
u
ﬂ

n
o
t
o
r
p

o
n
(

L
M

1
0
0
.
0
±
4
5
9
.
0

1
2
0
.
0
±
4
3
6
.
0

3
3
0
.
0
±
6
0
4
.
0

)
a
t
a
d

x
u
ﬂ
R
X
S

o
n
(

L
M

3
0
0
.
0
±
1
6
9
.
0

2
1
0
.
0
±
2
4
6
.
0

1
2
0
.
0
±
3
2
4
.
0

)
a
t
a
d

t
s
r
u
b

o
i
d
a
r

o
n
(

L
M

1
0
0
.
0
±
6
4
9
.
0

8
0
0
.
0
±
8
4
7
.
0

8
1
0
.
0
±
1
7
5
.
0

d
e
s
a
b
-
x
u
ﬂ

n
o
t
o
r
p

L
M

1
0
0
.
0
±
5
6
9
.
0

5
1
0
.
0
±
3
7
6
.
0

6
4
0
.
0
±
4
3
4
.
0

d
e
s
a
b
-
R
X
S
+
n
o
t
o
r
p

L
M

3
0
0
.
0
±
9
4
9
.
0

2
1
0
.
0
±
0
5
6
.
0

9
3
0
.
0
±
0
4
4
.
0

d
e
s
a
b
-
R
A
+
n
o
t
o
r
p

L
M

1
0
0
.
0
±
0
4
9
.
0

9
1
0
.
0
±
4
6
6
.
0

8
2
0
.
0
±
3
2
4
.
0

d
e
s
a
b
-
t
s
r
u
b

o
i
d
a
r
+
n
o
t
o
r
p

L
M

9
1
0
.
0
±
3
1
9
.
0

7
1
0
.
0
±
6
5
6
.
0

8
4
0
.
0
±
0
4
5
.
0

)
e
u
l
a
v

t
s
a
l

o
n
(

d
e
s
a
b
-
x
u
ﬂ

n
o
t
o
r
p

L
M

22

Sadykov et al.

Table 4. Comparison of ML-based predictions trained on the particle ﬂux data from east/west GOES detectors.

Property/Score
SPE days
Non-SPE days
HSS1
HSS2
Area below ROC
Cross-entropy loss
TSS
WTSS(2)
WTSS(5)
WTSS(10)

east/west averaged ﬂux
101
3400
0.377±0.028
0.635±0.008
0.959±0.001
0.273±0.006
0.820±0.006
0.803±0.005
0.857±0.004
0.920±0.004

east detector ﬂux west detector ﬂux

109
3392
0.498±0.024
0.709±0.014
0.958±0.001
0.299±0.005
0.793±0.003
0.795±0.005
0.852±0.005
0.913±0.005

100
3401
0.096±0.122
0.354±0.047
0.941±0.003
0.319±0.007
0.799±0.004
0.803±0.001
0.888±0.006
0.938±0.003

