7
1
0
2

v
o
N
0
3

]

C
H
.
s
c
[

1
v
8
8
0
0
0
.
2
1
7
1
:
v
i
X
r
a

IEEE ELECTRONIC PREPRINT (UNDER REVIEW)

1

The Effect of Focal Distance, Age, and
Brightness on Near-Field Augmented Reality
Depth Matching

Gujot Singh, Member, IEEE, Stephen R. Ellis, and J. Edward Swan II, Senior Member, IEEE

Abstract—Many augmented reality (AR) applications operate within near-ﬁeld reaching distances, and require matching the depth of a
virtual object with a real object. The accuracy of this matching was measured in three experiments, which examined the effect of focal
distance, age, and brightness, within distances of 33.3 to 50 cm, using a custom-built AR haploscope. Experiment I examined the
effect of focal demand, at the levels of collimated (inﬁnite focal distance), consistent with other depth cues, and at the midpoint of
reaching distance. Observers were too young to exhibit age-related reductions in accommodative ability. The depth matches of
collimated targets were increasingly overestimated with increasing distance, consistent targets were slightly underestimated, and
midpoint targets were accurately estimated. Experiment II replicated Experiment I, with older observers. Results were similar to
Experiment I. Experiment III replicated Experiment I with dimmer targets, using young observers. Results were again consistent with
Experiment I, except that both consistent and midpoint targets were accurately estimated. In all cases, collimated results were
explained by a model, where the collimation biases the eyes’ vergence angle outwards by a constant amount. Focal demand and
brightness affect near-ﬁeld AR depth matching, while age-related reductions in accommodative ability have no effect.

Index Terms—Perception and psychophysics, virtual and augmented reality, human performance, depth perception.

(cid:70)

1 INTRODUCTION

M ANY compelling applications of augmented reality

(AR) require interacting with real and virtual ob-
jects at reaching distances. Some examples include image-
guided medical procedures (e.g., Kersten-Oertel et al. [1]),
manufacturing (e.g., Curtis et al. [2]), and maintenance
(e.g., Henderson and Feiner [3]). Among the factors that
determine success is the accuracy with which observers
can match the distance of a real object to an AR-presented
virtual object. For example, a surgeon may need to cut to
the depth indicated by an AR-presented tumor, or place a
needle within the tumor. In order for AR to be useful for
image-guided surgery of the brain, Edwards et al. [4] found
that surgeons must be able to place a scalpel with a tolerance
of 1 mm; and, in order for AR to be useful for a type of
radiation therapy, Krempien et al. [5] found that a needle
must be placed with a tolerance of 1 mm.

In previous work motivated by this topic, Swan et al. [6]
reported initial efforts to measure the accuracy of AR depth
matching. An optical see-through AR display was used,
and reaching distances of 24 to 56 cm were examined. The
depth judgment was perceptual matching, where observers
adjusted a pointing object in depth, until they judged it
to be the same distance from themselves as a target object.
Fig. 1 summarizes these results, which were collected across
three experiments. The pointer was always a real object, and
therefore its distance from the observer could be objectively

• Gurjot Singh is with Fairleigh Dickinson University.

•

•

E-mail: gurjot@acm.org.
Stephen R. Ellis a Consultant, and was formally with NASA Ames
Research Center. E-mail: ellisstephenr3@gmail.com.
J. Edward Swan II is with Mississippi State University.
E-mail: swan@acm.org.

Manuscript received XXXX; revised XXXX.
c(cid:13)2017 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses,
in any current or future media, including reprinting/republishing this material for advertising or promotional
purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted
component of this work in other works.

measured in the real world. In Fig. 1, the x-axis is the
actual depth of the target object, and the y-axis is the
depth error of the pointer. Here, error = 0 indicates that
observers placed the pointer at the same depth as the target
object; error > 0 indicates overestimated depth matches,
where observers placed the pointer farther in depth than
the target object; and error < 0 indicates underestimated
depth matches, where observers placed the pointer closer
than the target object. As a control condition, Swan et al. [6]
examined the accuracy of matching a real target object, and
found accuracies of 1.4 to 2.7 mm (Fig. 1a, the real consistent
condition). However, when they examined matching a vir-
tual target object, they found that observers systematically
overestimated the matching distance, ranging from 0.5 cm
at near distances to 4.0 cm at far distances (Fig. 1b, the
AR collimated condition). Therefore, as illustrated in Fig. 1,
there was a signiﬁcant difference in depth matching real and
virtual targets.

Swan et al. [6] determined that the likely reason for these
results was that their AR display used collimating optics,
which present virtual objects focused at optical inﬁnity. They
found the results to be very well described by a model
where this collimation causes the eyes’ vergence angle to
rotate outwards by a constant amount. Fig. 2 illustrates this
model. Let the black points labelled α and α(cid:48) be two real
objects, with the ﬁrst located close to the observer, and the
second located farther away. And, let the red points labelled
β and β(cid:48) be two virtual objects, which are rendered to be the
same distance as the real targets. α, α(cid:48), β, and β(cid:48) also repre-
sent the angle of binocular parallax that the eyes make when
the observer ﬁxates on each object. Therefore, when ﬁxating
on the close real object, the angle of binocular parallax is α,
and if the ﬁxation changes to the close virtual object, then

 
 
 
 
 
 
IEEE ELECTRONIC PREPRINT (UNDER REVIEW)

2

and unadjustable by the end user.1 Therefore, an augmented
reality haploscope—an AR display mounted on an optical
workbench that allows accommodative demand and ver-
gence angle to be independently and precisely adjusted—
was developed and used for the experiments reported here.2

2 BACKGROUND AND RELATED WORK
2.1 Depth Perception and Depth Cues

The human visual system achieves a percept of perceived
depth from depth cues—sources of perceptual information re-
lated to depth. At least nine depth cues have been identiﬁed
(Cutting and Vishton [9]): occlusion (a closer object occludes
farther objects), binocular disparity (an object projects to dif-
ferent locations on each retina), motion perspective (objects at
different distances from a moving observer have different
apparent velocities), height in the visual ﬁeld (starting from
the horizon, closer objects are lower in the visual ﬁeld),
relative size (among objects of the same size, the farther
object projects to a smaller retinal angle), accommodation (the
lens of the human eye changes shape to bring objects into
focus), vergence (the two eyes rotate to ﬁxate on an object
(Fig. 2)), relative density (for a textured surface, at farther
distances more objects are seen within a constant retinal
angle), and aerial perspective (objects at great distances lose
color saturation and contrast).

Depth cues differ in effectiveness based on various visual
characteristics, such as scene content and distance from the
observer. Nagata [10], and later Cutting and Vishton [9],
organized the relative effectiveness of different depth cues
according to distance. Within near-ﬁeld reaching distances,
they ﬁnd that the operative depth cues, in approximate
order of decreasing salience, are occlusion, binocular disparity,
motion perspective, relative size, accommodation and vergence,
and relative density.

Most of these depth cues can be categorized as retinal,
because the information from the cue comes from the visual
scene sensed on the retina. However, the cues of accom-
modation and vergence are extra-retinal, because the cue
information comes from sensors that detect the state of the
muscles that control the lenses’ shape and the eyes’ ver-
gence angle. In principal, the extra-retinal cues cues could
provide absolute egocentric depth information (Gillam [11]).
In contrast, retinal cues can only provide relative depth
information between objects in the scene; these cues re-
quire an external reference to establish the scene’s overall
scale. However, when combined with extra-retinal cues, and
an observer’s constant interpupillary distance, retinal cues
can also provide absolute depth information (Bingham and
Pagano [12], Mon-Williams and Tresilian [13]). In general,
the way the human visual system combines information
from different depth cues to produce a stable percept of
distance is subtle and not fully understood, although many
theories have been advanced and the collected evidence fa-
vors some theories over others (Landy et al. [14], Singh [8]).

1. The authors of the current paper, who have been studying virtual
and augmented reality for 8, 30, and 18 years, respectively, can only
recall a single commercially-available AR display—the Microvision
Nomad from the early 2000’s— which came with a focus adjustment
knob (Gabbard et al. [7]).

2. Portions of these experiments are reported in a PhD dissertation

(Singh [8]).

Fig. 1. The perceptual matching depth judgments from Swan et al. [6].
For Experiment I, the actual distances were 34, 38, 42, 46, and 50 cm,
while for Experiments II and III the actual distances were 55, 63, 71, 79,
and 87% of each observer’s maximum reach.

Fig. 2. The model that explains how a constant change in vergence
angle, ∆v, leads to matched distances of virtual objects (red: β, β(cid:48)),
relative to real objects (black: α, α(cid:48)), that are increasingly overestimated
with increasing distance.

the collimation causes the eyes to rotate outwards, reducing
the angle to β. When placing the real pointer α at the same
depth as the virtual target β, observers’ eyes rotate inwards
and outwards as they ﬁxate between the two objects, and
therefore observers perceive them to be located at the same
depth. The model predicts that this change in vergence
angle, ∆v = α − β, is constant for reaching distances.
Therefore, when ﬁxating on the far target, α(cid:48) < α, and this
same change in vergence angle, ∆v = α(cid:48) − β(cid:48), causes a
larger depth distance between α(cid:48) and β(cid:48) (Fig. 2). This model
explains three properties of Swan et al.’s [6] results (Fig. 1):
(1) because the collimating optics cause the eyes to rotate
outwards, the depth judgments of the virtual targets are
overestimated relative to the real targets, (2) the amount of
overestimation increases with increasing distance, and (3)
the results are very well ﬁt with a linear model.

This analysis suggests that, for accurate depth place-
ment, virtual objects need to be presented with a focal
depth—also termed accommodative demand—that is consistent
with their intended depth. Then, the eyes’ vergence angle
will not be biased, and depth matches will be more accurate.
This paper reports three experiments that systematically
examine this hypothesis.

However, it was not possible to conduct these experi-
ments with the same AR display as Swan et al. [6]. That
display, an NVIS Inc. nVisor ST60 model, contains unad-
justable collimating optics, which always present virtual
objects focused at optical inﬁnity. This is consistent with the
vast majority of commercially available AR displays, almost
all of which have a focal distance that is set at the factory,

Real ConsistentAR Collimatedlllllllllllllll(a)lllllllllllllll(b)−10123451234512345Actual DistanceError (cm), –1 SEMExperimentlllExp IExp IIExp IIIclose objects α β Δv = α – β Δv = α’ – β’ α’ β’ far objects IEEE ELECTRONIC PREPRINT (UNDER REVIEW)

3

Of course, the vergence-accommodation reﬂex is cali-
brated for viewing real world objects, which present consis-
tent binocular disparity and focal blur cues (Fig. 3a). When
viewing virtual objects, the binocular disparity and focal
blur cues are often inconsistent, because the focal blur cue
is ﬁxed at the screen depth, while the depth of the binocular
disparity cue varies, sometimes beyond the screen depth
(Fig. 3b), and sometimes in front (Fig. 3c). This is called
the vergence-accommodation conﬂict, and it is a ubiquitous
aspect of all stereo displays with a single focal plane (Kruijff
et al. [20]). The conﬂict causes visual fatigue (Gabbard et
al. [7], Lambooij et al. [21]), hinders visual performance
(Hoffman et al. [22]), and biases depth perception towards
the screen depth (Fig. 3, Swenson [23], Mon-Williams and
Tresilian [19]).

The contribution of vergence to perceived depth de-
the scene. At near-
pends upon various properties of
ﬁeld distances, vergence has been conclusively found to
provide egocentric depth information (Brenner and Van
Damme [24], Owens and Liebowitz [25], Tresilian et al. [26],
Viguier et al. [27]; Foley [28] provides a comprehensive
review). Although vergence in isolation is not a very ac-
curate depth cue, observers are very sensitive to changes
in vergence, which generally allows accurately matching
the depth of one object with another (Brenner and Van
Damme [24]). Each individual has a different vergence rest-
ing point—their dark vergence—which is the vergence angle
that their eyes assume when the controlling muscles are
completely relaxed. In low light conditions, the egocentric
depth speciﬁed by vergence is biased towards each individ-
ual’s dark vergence distance (Owens and Liebowitz [25]).
As a depth cue, vergence is most effective within near-
ﬁeld distances of 2 meters (Viguier et al. [27]), a distance
range that encompasses ∼90% of vergence eye movements
(Tresilian et al. [26]). As other retinal depth cues become
available, the contribution of vergence to perceived depth is
reduced, but still present (Foley [28]).

As discussed above, accommodation inﬂuences per-
ceived depth through the vergence-accommodation reﬂex.
Although some studies have found evidence that accommo-
dation alone can serve as a depth cue for some observers,
these experiments require careful experimental setups to
eliminate other depth cues, and the consensus remains
that accommodation inﬂuences perceived depth through
its effect on vergence (Mon-Williams and Tresilian [19]).
Similar to dark vergence, each individual has a dark focus—
the distance their eyes focus when the controlling mus-
cles are in a relaxed state (Iavecchia et al. [29]). The dark
focus biases the eye’s focal response, resulting in a num-
ber of perceptual consequences, including perceived depth
(Roscoe [30]). Generally, the dark focus and dark vergence
distances vary independently, and for most individuals are
not equal (Owens and Leibowitz [25]).

2.3 Accommodation and Age

Accommodative ability, the distance range within which a
viewed object can be brought into clear focus, decreases
with increasing age (Duane [31]), a condition known as
presbyopia. It is primarily caused by hardening of the crys-
talline lens, although other physiological changes in the

Fig. 3. The vergence-accommodation conﬂict, and its effect on per-
ceived depth. (a) In normal viewing of real world objects, the vergence
distance, required for zero binocular disparity, is the same as the focal
distance, required for minimal focal blur. (b) When the vergence distance
is farther than the focal distance, e.g. when viewing a virtual object
beyond the surface of a stereo monitor, the vergence angle is biased
inwards (grey lines), and the object is seen as closer than encoded
by disparity. (c) When the vergence distance is closer than the focal
distance, e.g. when viewing a virtual object in front of the surface of a
stereo monitor, the vergence angle is biased outwards (grey lines), and
the object is seen as farther than encoded by disparity.

2.2 Vergence and Accommodation

Visual perception requires a rapid series of precise eye
movements (Leigh and Zee [15]), including ﬁxation (hold an
image steady on the fovea by minimizing eye movement),
saccadic (quick movement that projects an object of interest
to the fovea), smooth pursuit (retain ﬁxation on an object dur-
ing smooth movement of either the object or head), vestibular
(hold vision steady during head movements), and vergence
(the two eyes rotate to ﬁxate on an object of interest (Fig. 2)).
When changing ﬁxation from a far to a near object, the eyes
converge, the lenses become thicker, and the pupils con-
strict. These three actions—vergence, accommodation, and
changing pupil size—are interlinked physiologically, and
the mechanism of these three simultaneous reﬂexes is called
the near triad. Because of the interlinkage, changes in either
accommodation or vergence drive corresponding changes
in the other two components of the triad (Semmlow and
Hung [16]). Apart from the inﬂuence of accommodation and
vergence, pupil diameter also changes according to scene
illumination, becoming larger in dim settings and smaller in
bright settings. Although these illumination-driven changes
in pupil diameter affect the eye’s optical depth of ﬁeld,
and therefore could potentially affect accommodation, little
effect of changing pupil diameter on accommodation has
been observed (Ripps et al. [17]). Therefore, in near ﬁeld
viewing, vergence and accommodation are the main depth
reﬂexes, and the link between them is known as the vergence-
accommodation reﬂex. Because of this reﬂex, accommodation
and vergence operate in unison: changes in accommodation
drive changes in vergence (accommodative vergence), and
changes in vergence drive changes in accommodation (ver-
gence accommodation) (Kersten and Legge [18]). Therefore,
the vergence reﬂex is driven both by binocular disparity
(the eyes rotate to bring a ﬁxated object to a level of zero
binocular disparity), as well as accommodative vergence.
Likewise, the accommodation reﬂex is driven both by focal
blur (the lenses adjust to minimize blur), as well as vergence
accommodation (Mon-Williams and Tresilian [19]).

(a) normal viewing (b) vergence farther than accommodation  vergence distance focal distance vergence distance focal distance vergence distance focal distance (c) accommodation farther than vergence IEEE ELECTRONIC PREPRINT (UNDER REVIEW)

4

lens, connective tissue, and controlling muscles also play
a role (Kasthurirangan and Glasser [32]). As measured by
Duane [31], presbyopia begins by the age of 12, but through
the early 30’s the loss is minuscule—the closest distance
of clear focus declines from ∼8 to ∼13 cm. However, the
decline then accelerates, and by the age of 50 often surpasses
50 cm. At some point in the 40’s, the closest distance of
clear focus often surpasses standard reading distance, and
reading glasses are required. By their mid-50’s, most people
have lost the ability to adjust the distance of clear focus.

It seems reasonable that this loss of accommodative abil-
ity would have perceptual consequences, and indeed, older
people are worse than younger people at many perceptual
tasks (Bian and Andersen [33]). However, accommodative
vergence does not diminish with age; even as the visual
system looses the ability to adjust accommodation, the eyes
still verge properly in response to accommodative stimuli
(Heron et al. [34]). Because vergence is the primary source of
depth information from the vergence-accommodation reﬂex
(Mon-Williams and Tresilian [19]), this suggests that depth
perception could be unaffected by presbyopia. Indeed, Bian
and Andersen [33] found that, when making judgments of
medium-ﬁeld egocentric distances, older people (average
73.4 years) were more accurate than younger people (average
22.5 years). This is one of a series of recent studies that have
found that older observers preserve their abilities in tasks
related to distance perception (Bian and Andersen [33]).

2.4 Accommodation and Scene Flatness

Another effect of the vergence-accommodation conﬂict in
stereo displays is that the accommodative distance changes
the perceived ﬂatness of the scene (Andersen et al. [35], Na-
gata [10], Singh [8]). Speciﬁcally, when medium- to far-ﬁeld
scenery is shown on a display, but accommodative distance
is in the near ﬁeld, depth distances between scene objects
are compressed, and the scene is perceived as being a ﬂat
window, positioned some depth distance from the observer.
However, when the same scene is shown with collimation,
these depth distances are no longer compressed, and the
scene objects appear to extend in depth, with some closer to
the observer and others farther. This is a reason why many
augmented and virtual reality displays, especially those
used for ﬂight simulation and other far-ﬁeld applications,
present collimated light (Watt et al. [36]). Likewise, the NVIS
nVisor ST60 used by Swan et al. [6], which also presents
collimated light, was originally marketed for military train-
ing and forward observer tasks, which primarily involve
medium- to far-ﬁeld distances.

2.5 Depth Perception and Brightness

Among objects of the same size and distance, the brighter
appear closer than the dimmer. This principal has long
been known in art, and is discussed by Leonardo Da
Vinci in his Notebooks (McCurdy [37]). The principal has
been thoroughly studied, at both near ﬁeld (Ashley [38],
Farn`e [39]) and medium ﬁeld (Coules [40]) distances, and
in both monocular and binocular conditions (Coules [40]).
In addition to brightness, the contrast between an object
and the background also effects perceived depth, so a dark
object against a light background can appear closer than an

Fig. 4. The Augmented Reality (AR) Haploscope. The physical design
allows independent adjustment of vergence angle and focal distance.

object with less contrast (Farn`e [39]). Among the theories
that explain this effect are that brighter objects stimulate
a larger area on the retina, and that brighter objects effect
pupil size, which then biases other near triad reﬂexes.

2.6 Related Work in Augmented Reality

To date, including Swan et al. [6], only a small number of
papers have examined near-ﬁeld AR depth matching. Ellis
and Menges [41] measured the effects of convergence, ac-
commodation, observer age, viewing condition (monocular,
biocular stereo, binocular stereo), and the presence of an
occluding surface. They found that accuracy is degraded
by monocular viewing and an occluding surface. Using the
same experimental setup, McCandless et al. [42] addition-
ally studied motion parallax and latency in monocular view-
ing; they found reduced accuracy with increasing distance
and latency. Singh et al. [43] found that an occluding surface
has complex accuracy effects, and Rosa et al. [44] found
increased accuracy with redundant tactile feedback.

3 THE AUGMENTED REALITY HAPLOSCOPE
As motivated in Section 1, an augmented reality haploscope
was designed and engineered.3 The design was loosely
based on the AR haploscopes described by Rolland et al. [45]
and Ellis and Menges [41], but similar designs have a long
history in the study of depth perception (e.g., Swenson [23]).
Fig. 4 shows the AR haploscope. The physical design has
the following requirements: (1) provide a range of vergence
angles and accommodative demands, (2) adjust to match
a wide range of inter-pupillary distances, and (3) be rigid
enough to resist inevitable bumps. To achieve these, the
device is mounted on an optical breadboard. The primary
structure is built on three optical rails: two 12-inch rails
serve as mounting bases for left-eye and right-eye optical
systems, and both 12-inch rails are mounted on a 24-inch rail
using 3-inch rail carriers, which can be adjusted to match the
required inter-pupillary distance.

3. Additional technical details, and a history of preliminary versions

and design tradeoffs, can be found in Singh [8].

monitorcollimation*lensminificationlensaccommodationlensoptical*combinersheight*adjustablechin*and*forehead*restpivot*pointsrotatable*assemblyrail*carriers*(adjust*inter8pupillary*distance)tracking*fiducialsrotatable*assemblyIEEE ELECTRONIC PREPRINT (UNDER REVIEW)

5

distance between the pivot points matches the observer’s
inter-pupillary distance (Fig. 4). The chin and forehead rest
is adjusted so that these pivot points are directly below the
rotational centers of the observer’s eyes. As illustrated in
Fig. 6, when the left and right optical systems then rotate
about the pivot points, for all convergence distances the
view rays from the center of the two eyes stay in line
with the principal axes of the optical systems. This allows
presenting a virtual object at any distance, near (n), medium
(m), or far (f ), while the observer’s view rays continue to
pass through the middle of the optical system, where optical
distortion is minimized. To display a target object at a spe-
ciﬁc distance, the optical systems are rotated to the matching
convergence angle 1/2α (Figs. 2, 6); 1/2α = arctan(i/2d),
where i is the observer’s interpupillary distance, and d is
the target distance. The angle of each optical system is
measured by a constellation of tracking ﬁducials attached
to each monitor (Fig. 4), which allows an ART TrackPack to
measure the vergence angle to an accuracy of 0.01◦.

4 EXPERIMENT I: ACCOMMODATION

As discussed in Section 1, Swan et al. [6] hypothesized that
the linearly increasing overestimation they found with col-
limated AR graphics (Fig. 1), was caused by the collimation
biasing the eyes’ vergence angle to rotate outwards by a
constant amount (Fig. 2). The purposes of Experiment I were
to test aspects of this hypothesis, using the same matching
task and within a similar range of near-ﬁeld distances.
Because Experiment I used a different display—the AR
haploscope—the ﬁrst purpose (1) was to replicate the real
consistent and AR collimated conditions of Swan et al. [6]. If
Experiment I found similar results, that would suggest that
these results generalize to AR more broadly, and are not
speciﬁc to the NVIS display used by Swan et al. [6]. The next
purpose (2), the AR consistent condition, was to test whether
presenting AR objects at a focal distance that was consistent
with the distance speciﬁed by other depth cues, especially
binocular disparity, would result in more accurate depth
matches than what was seen in the AR collimated condition.
If the depth matches are more accurate, that would further
support the hypothesis that collimated graphics bias the
eyes’ vergence angle outwards. However, for many AR
applications, always presenting virtual objects at consistent
focal distances is unlikely to be practical. Therefore, the
ﬁnal purpose (3), the AR midpoint condition, was to test
whether presenting AR objects at a focal distance equal to
the midpoint of the tested range would result in performance
similar to the consistent condition. If the performance is
similar, this would suggest that, for accurate depth matching
within reaching distances, the expense of making the focal
demand consistent for every virtual object is not necessary.

4.1 Method

4.1.1 Apparatus and Task

Fig. 7 shows the experimental setup. The haploscope was
mounted on the end of an optical breadboard, 244 cm long
by 92 cm wide. The breadboard was supported by a custom-
built aluminum table, with six legs. Mounted to the legs of
the table were six hydraulic jacks, which could lift the entire

Fig. 5. The optical system of the AR haploscope. Changing the accom-
modation lens changes the focal distance.

Fig. 6. Rotating the optical systems to match the correct vergence angle.

The goal of each optical system is to collimate the gen-
erated image, so the image is located at optical inﬁnity, or
0 diopters (D). Then, the collimated image can either be left
at optical inﬁnity, or a negative power lens can reduce the
focal distance. Fig. 5 shows the optical system. The image
is ﬁrst generated by a monitor. Then, the image is miniﬁed
by a −10 D concave lens; without miniﬁcation, only a small
part of the monitor can be seen through the optical system.
As shown in Fig. 5, when this −10 D lens is placed 10 cm
from the monitor, it creates a miniﬁed image at −5 cm. This
miniﬁed image is then collimated by a +10 D convex lens,
positioned 10 cm from the image. The collimated image is
then passed through an accommodation lens. This comes from
a standard optometric trial set; either a 0 D plain glass lens,
which retains the collimation, or a negative power concave
lens, which reduces the focal distance. In the experiments
reported here, the strongest accommodation lens used was
−3 D, which resulted in a 33.3 cm focal distance. After
generation, the images are reﬂected into the observers’
eyes by 15% reﬂective optical combiners, mounted at 45◦
directly in front of each eye. Fig. 4 shows the monitors; the
miniﬁcation, collimation, and accommodation lenses; and
the optical combiners.

Fig. 6 illustrates how the haploscope matches different
vergence angles. The rail carriers are adjusted so that the

monitor 10 cm minification lens (50 mm concave) collimation lens (50 mm convex) accommodation lens (38 mm concave) virtual object image generated  by minimization  lens 10 cm 5 cm image formed at 0 to 3 D  (infinity to 33.3 cm), based on  power of accommodation lens –10 D +10 D 0%to%–3%D fmnmonitoropticalsystemeye.rotational.centers.over.pivot.pointsopticalcombinerid1/2αIEEE ELECTRONIC PREPRINT (UNDER REVIEW)

6

table, so the surface could be adjusted to be between 104
and 134 cm above the ground. This adjustability allowed
the table to be comfortably positioned for observers of many
different heights. Aluminum arms extending above the table
supported tracking cameras, as well as an overhead light
(Fig. 7). Because the tracking cameras and light were at-
tached to the table, when the table height was adjusted, their
distance above the table top remained constant. Tracking
was provided by a 2-camera TRACKPACK system, from
A.R.T. GmbH.

On both sides of the table, depth adjusters—plastic pipes
running through collars—could easily be slid back and forth
in depth (Fig. 7). When the real target was presented, it
hung from an arm attached to the left-hand depth adjuster.
The real target was a wireframe octahedron, 5 cm wide by
6 cm high, constructed of balsa wood and painted green.
An electric motor rotated the target at 4 rpm. Although
slow, the rotation gave a deﬁnite sense of three-dimensional
structure from motion, even when viewed monocularly. The
depth position of the real target was precisely measured
by a tracking ﬁducial mounted to the arm (Fig. 7). When
an AR target was presented, the arm supporting the real
target was removed. The AR target was identical to the real
target: a green octahedron that rotated at 4 rpm, rendered
and viewed through the haploscope optics. Only the green
channel was used, which eliminated chromatic distortion.
Careful calibration ensured that the AR target matched the
real target in size and position at all tested distances. In
addition, because accommodation lenses of different pow-
ers change the overall magniﬁcation of the optical system
(Fig. 5), the calibration was repeated for every lens power.
The targets were located 29 cm above the tabletop, and seen
against a black curtain hung 1.2 meters from the observer
(Fig. 7). The appearance of the real and AR targets was
as similar as possible: the lighting and color of the real
target made it appear to glow against an otherwise dark
background, and it did not cast any visible shadows or
reﬂections. The table was covered with black cloth, which
created a smooth and featureless surface under the target.

The matching task from Swan et al. [6] was replicated.
The pointer was made of green, translucent plastic, ∼4
mm in diameter, with a rounded top, mounted on an arm
attached to the right-hand depth adjuster (Fig. 7). Observers
matched the target depth by sliding the depth adjuster
until the pointer was directly below the bottom point of
the rotating target. The distance between the bottom of the
target and the top of the pointer was ∼1 cm. The depth
position of the pointer was precisely measured by a tracking
ﬁducial mounted on the arm (not visible in Fig. 7).

4.1.2 Experimental Design

Observers: 40 observers were recruited from a population of
university students and staff. The observers ranged in age
from 18 to 38; the mean age was 20.9, and 18 were male and
22 female. 10 observers were paid $12 an hour, and the rest
received course credit.

Independent Variables: Observers saw 4 different conditions:
real consistent, AR collimated, AR consistent, and AR mid-
point. The target object appeared at 5 different distances
from the observer: 33.3, 36.4, 40, 44.4, and 50 cm, which

Fig. 7. The experimental setup. The AR haploscope was mounted on
the end of an optical breadboard. Real and AR targets were positioned
at different depths from the observer. The depth of the targets was
matched by changing the position of the pointer.

correspond to 3, 2.75, 2.5, 2.25, and 2 D. Observers saw 6
repetitions of each distance.

In the real consistent condition, observers saw the real
target object (Fig. 7), which, by deﬁnition, was always
presented at a focal distance that was consistent with its
actual distance. In the remaining conditions, the AR target
was seen. In the AR collimated condition, a 0 D plain glass
accommodation lens was used, presenting the target at
optical inﬁnity. In the AR consistent condition, the accom-
modation lens power—3, 2.75, 2.5, 2.25, or 2 D—was always
consistent with the target’s presented distance. Finally, in
the AR midpoint condition, the 2.5 D accommodation lens
was used, presenting the target at a focal distance of 40 cm.

Dependent Variables: The primary dependent variable
was judged distance—the measured position of the pointer
(Fig. 7). In addition, error = judged distance − actual distance
was also calculated (Fig. 1).

Design: A mixed design was used, with condition varying
between observers, and distance and repetition varying
within each observer. There were 10 observers in each
condition, and the presentation order of condition varied
in a round-robin fashion, so each group of 4 observers
covered all conditions. For each observer, distance × rep-
etition was randomly permuted, with the restriction that
the distance changed every trial. Therefore, each observer
completed 5 (distance) × 6 (repetition) = 30 trials, and the
experiment collected a total of 40 (observers) × 30 (trials) =
1200 data points.

4.1.3 Procedure

After receiving an explanation of the experimental proce-
dures, an observer gave informed consent. Then, they took
a stereo vision test, which measured their sensitivity to
depth changes encoded by binocular disparity. Next, the
observer’s inter-pupillary distance was measured, using a

tracking cameras background curtain  real target pointer tracking  fiducial light real target depth adjuster pointer depth adjuster IEEE ELECTRONIC PREPRINT (UNDER REVIEW)

7

pupilometer set to optical inﬁnity, and the haploscope was
adjusted to match this distance. The task was then ex-
plained, using the real target and the pointer. If the observer
indicated that, when working at the demonstrated dis-
tances, they would normally wear corrective optics (glasses
or contacts), they were instructed to wear the optics. Ob-
servers then donned safety goggles, which easily ﬁt over
glasses. The googles had 3.5 cm circular openings for each
eye, and were otherwise covered with black gaffer tape. The
size of these openings was calibrated so that, when looking
through the haploscope optics, observers could see the
complete ﬁeld of view provided by the optical combiners,
but their peripheral view of the rest of the haploscope was
blocked. The chinrest and forehead rest were adjusted so
that the observer’s eyes were approximately centered within
the optical combiners, and the haploscope pivot points were
approximately centered under the eyes’ rotational centers
(Figs. 4, 6). The table and chair heights were adjusted so the
observer was sitting comfortably.

The observer then completed one of the four conditions.
The pointer was placed at a random position within the
trackable distance of 23 to 67 cm from the observer, and the
experimenter then displayed the ﬁrst target distance. Using
their right hand to manipulate the pointer depth adjuster
(Fig. 7), the observer moved the pointer from this starting
position to match the target’s depth. The observer then
closed their eyes, and the experimenter displayed the next
target distance. The observer then opened their eyes, and
moved the pointer from the previously matched distance
to the new distance. This pattern continued until all trials
were completed. To display distances with the real target,
the experimenter used the real target depth adjuster to slide
the real target to the correct position. For the AR target, the
experimenter adjusted the angle of each haploscope arm,
and swapped out the accommodation lenses as needed.
Regardless of condition, the procedures were as similar as
possible, and the time required for each trial was approxi-
mately equal. During real consistent trials, observers looked
through the haploscope optics, even through the monitors
were switched off.

After the trials, the observer was debriefed. The overall

experiment took approximately one hour.

4.2 Analysis

Similar to Swan et al. [6], the data was analyzed by examin-
ing the slopes and intercepts of linear equations that predict
judged distance from actual distance. Multiple regression
methods determine if the slopes and intercepts signiﬁcantly
differ (Pedhazur [46], Cohen et al. [47]). For data with
this structure, multiple regression methods are preferable
to ANOVA analysis, because multiple regression allows the
prediction of a continuous dependent variable (judged dis-
tance) from a continuous independent variable (actual target
distance), as well as a categorical
independent variable
(condition). In contrast, ANOVA analysis only examines cat-
egorical independent variables, which results in a signiﬁcant
loss of power when an independent variable is inherently
continuous (Pedhazur [46]). In addition, multiple regression
yields slopes and intercepts, which as descriptive statistics
are more useful than means, because they directly describe

functions that predict judged distances from actual target
distances. Finally, multiple regression methods focus on
effect size, as opposed to signiﬁcance; an analytic approach
advocated by many in the applied statistics community
(Cohen et al. [47]).4

Figs. 8a–d and 9 show the results from Experiment I,
plotted as a scatterplot of judged against actual distance
(Fig. 8), as well as mean error against distance (Fig. 9). Both
ﬁgures indicate that the data is very well ﬁt by linear regres-
sions; note the r2 values in Fig. 8. Fig. 10 shows multiple
regression analysis, which compares pairs of panels from
Fig. 8 against each other; each panel in Fig. 10 examines
two independent variables: a continuous variable (actual
distance), and a categorical variable (a pair of panels from
Fig. 8). To properly account for repeated measurements, for
each observer at each distance, the responses were averaged
over the 6 repetitions, reducing the size of the analyzed
dataset from 1200 to 200 points—note the reduced density
of points in Fig. 10 relative to Fig. 8a–d.

Each panel in Fig. 10 compares two regression equations
from Fig. 8. The multiple regression analysis operates in the
following manner: First, the slopes of the equations are tested
to see if they signiﬁcantly differ. If they do, as in Fig. 10a,
both equations from Fig. 8 are reported as the best overall
description of the data in the panel. If the slopes of the
equations do not signiﬁcantly differ, then the intercepts of
the equations are tested to see if they signiﬁcantly differ.
This test ﬁrst sets the slopes of the equations—which do
not differ—to a common value. If the intercepts signiﬁcantly
differ, as in Fig. 10b, two regression equations, with slopes
adjusted to a common value, are reported as the best overall
description of the data in the panel. If neither the slopes
nor the intercepts signiﬁcantly differ, as in Fig. 10c, then the
data from both panels is combined, and a regression over
the combined data is reported as the best overall description
of the data in the panel. Therefore, this multiple regression
analysis yields three possible outcomes, which by chance are
illustrated in the ﬁrst three panels of Fig. 10: (1) the slopes
signiﬁcantly differ (Fig. 10a), (2) the slopes do not differ but
the intercepts signiﬁcantly differ (Fig. 10b), or (3) neither the
slopes nor the intercepts signiﬁcantly differ (Fig. 10c).

In each case, the panel also indicates two measures of
effect size: (1) the overall R2 value, the percentage of vari-
ation in the panel explained by the linear regressions, and
(2) dR2, the percentage of variation explained by the change
in the categorical variable. If dR2 is too small, hypothesis
testing is not performed, because any statistical differences
would be too small to be meaningful (Pedhazur [46]). Based
on the results reported in this paper, hypothesis testing is
only conducted when dR2 ≥ 0.08%. Finally, for each panel,
if there is a statistical difference in either slope or intercept,
then the distance, d, in cm, between the ﬁtted regression
lines is also reported. When there is a difference in slope,
as in Fig. 10a, d is reported at the minimum and maximum
x values (33.3 and 50 cm). When there is a difference in
intercept, as in Fig. 10b, then the regression lines are the
same distance apart for every x, and only one d value is

4. Custom analysis software, developed by the third author, was
used, which implements methods described by Pedhazur [46]. A more
detailed discussion of the application of multiple regression methods
to depth perception data is available in Swan et al. [6].

IEEE ELECTRONIC PREPRINT (UNDER REVIEW)

8

Fig. 8. The results for all three experiments, plotted as judged against actual distance. Each panel shows the individual data points, color coded
according to observer, and ﬁt with a color-coded regression line per observer. For each panel, the dotted line represents veridical performance, and
the solid black line is the overall regression line. The corresponding regression equation is at the top of each panel. The r2 values indicate that the
data in each panel is very well described by the regression equation. A separate group of 10 observers provided the data for each panel. The graph
summarizes N = 1200 (Experiments I and II) and N = 900 (Experiment III) data points.

Fig. 9. Experiment I, plotted as mean error against distance (N = 1200).

reported. d is a signed value; d > 0 indicates a distance
farther from the observer, and d < 0 closer to the observer.

4.3 Results

Real consistent very accurate: Fig. 9a indicates that observers
were extremely accurate in the real consistent condition. The
mean error is −0.2 mm, and the slope of the regression for
Fig. 9a, y = −0.003x + 0.11, does not signiﬁcantly differ
from 0 (F1,48 = 1.63, p = 0.21). Note that this is statistically
equivalent to testing whether the slope in Fig. 8a differs
from 1.

AR collimated increasingly overestimated: When AR collimated
is compared to real consistent (Fig. 10a), the slopes sig-

Fig. 10. Experiment I, multiple regression analysis, plotted as a scat-
terplot of judged against actual distance, with N = 200 ghosted data
points. The thin dashed lines represent veridical performance. Blue lines
represent ﬁtted regression equations from Fig. 8. Black and red lines
represent the linear regressions shown in each panel. Blue lines are
not visible when overlaid by black or red lines; the degree of blue line
visibility is a graphical indication of how closely the regressions in each
panel agree with the regressions from Fig. 8.

niﬁcantly differ (F1,96 = 10.7, p = 0.001), indicating that
the AR collimated targets were overestimated, from +0.7 to
+1.8 cm (Fig. 9b).

AR consistent underestimated: When AR consistent is com-
pared to real consistent (Fig. 10b), the slopes do not signif-
icantly differ (F1,96 = 0.68, p = 0.41), but the intercepts do
(F1,97 = 41.3, p < 0.001), indicating that the AR consistent

Real ConsistentAR CollimatedAR ConsistentAR Midpointllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll(a)y = 0.997x + 0.11  r2 = 99.9%llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll(e)y = 0.988x + 0.60  r2 = 99.0%(i)llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll(b)y = 1.062x − 1.33  r2 = 96.5%llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll(f)y = 1.081x − 3.21  r2 = 96.6%llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll(j)y = 1.062x − 1.30  r2 = 95.9%llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll(c)y = 0.988x + 0.06  r2 = 99.3%llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll(g)y = 0.978x + 0.69  r2 = 99.0%llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll(k)y = 1.029x − 1.10  r2 = 99.3%llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll(d)y = 1.009x − 0.60  r2 = 99.0%llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll(h)y = 0.982x + 0.74  r2 = 98.6%llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll(l)y = 1.010x − 0.25  r2 = 99.3%303540455055303540455055303540455055Exp IExp II: Older ObserversExp III: Dim Targets33.336.440.044.450.033.336.440.044.450.033.336.440.044.450.033.336.440.044.450.0Actual Distance (cm)Judged Distance (cm)lllll(a)lllll(b)lllll(c)lllll(d)Real ConsistentAR CollimatedAR ConsistentAR Midpoint−1.0−0.50.00.51.01.52.02.5−1.0−0.50.00.51.01.52.02.533.336.440.044.450.033.336.440.044.450.0Actual Distance (cm)Error (cm), –1 SEMExperimentlExp Illllllllllllllllllllllllllllllllllllllllllllllllll(a)  AR Collim: y = 1.062x − 1.33Real Consis: y = 0.997x + 0.11R2 = 99.1%dR2 = 1.1%, d = +0.7, +1.8 cmllllllllllllllllllllllllllllllllllllllllllllllllll(b)Real Consis: y = 0.993x + 0.28  AR Consis: y = 0.993x − 0.11R2 = 99.7%dR2 = 0.12%, d = −0.4 cmllllllllllllllllllllllllllllllllllllllllllllllllll(c)y = 1.003x − 0.25R2 = 99.6%dR2 = 0.036%(d)y = 0.999x − 0.27R2 = 99.4%dR2 = 0.035%AR Collim vs Real ConsisAR Consis vs Real ConsisAR Midpt vs Real ConsisAR Consis vs AR Midpt30354045505530354045505533.336.440.044.450.033.336.440.044.450.0Actual Distance (cm)Judged Distance (cm)ConditionlReal ConsisAR CollimAR ConsisAR MidptIEEE ELECTRONIC PREPRINT (UNDER REVIEW)

9

targets were underestimated by a constant −0.4 cm (Fig. 9c).

AR midpoint equivalent to real consistent: When AR midpoint
is compared to real consistent (Fig. 10c), the effect size of the
difference is 0.036% of the variation, which is too small for
any statistical differences to be meaningful. Therefore, the
joint data is best ﬁt by a single equation, indicating that AR
midpoint targets were accurately matched (Fig. 9d).

AR consistent and AR midpoint equivalent: When AR consis-
tent is compared to AR midpoint (Fig. 10d), the effect size
is 0.035%, also too small for any statistical differences to be
meaningful. Therefore, matches of AR consistent and AR
midpoint targets were equivalent (Fig. 9c, d).

4.4 Discussion

The ﬁrst purpose (1) of Experiment I was to replicate the real
consistent and AR collimated conditions of Swan et al. [6]
(Fig. 1). The pattern in Figs. 9a, b indeed matches Fig. 1.
Given the many differences between the AR haploscope and
the NVIS display used by Swan et al. [6], this replication is
consistent with the idea that this pattern of results gener-
alizes to any collimated AR or stereo display. In addition,
Swan et al. [6] hypothesized that collimation biases the eyes’
vergence angle to rotate outwards by a constant amount
(Fig. 2). For each distance, Fig. 11a shows ∆v, the change
in vergence angle,5 for the 10 AR collimated observers. For
all observers ∆v changes less than 0.5◦, and the median
observer, seen in the boxplot, changes less than 0.072◦. These
small angular changes are consistent with the hypothesis
that, within these reaching distances, the vergence angle bias
is constant.

The next purpose (2) was to test whether presenting
AR objects at a focal distance that was consistent with the
distance speciﬁed by other depth cues, especially binocular
disparity, would result in more accurate depth matches than
what was seen in the AR collimated condition. Figs. 9a, b,
and c, as well as the analysis in Figs. 10a and b, conﬁrm this
hypothesis: AR consistent is much more accurate than AR
collimated, and for a consistent focal distance, real and AR
targets do not differ in slope (Fig. 10b).

The ﬁnal purpose (3) was to test whether presenting AR
objects at a focal distance equal to the midpoint of the tested
range would result in similar performance as the consistent
condition. Figs. 9c and d, as well as the analysis in Figs. 10c
and d, indicate that, when the focus was set to the midpoint,
matching was indeed just as accurate.

5 EXPERIMENT II: AGE
As discussed in Section 2.3, increasing age leads to presby-
opia, a decline in the ability of the eyes to accommodate
to different focal distances. Experiment I found signiﬁcant
negative effects of collimation, but all of the observers were
young, with a mean age of 20.9, and therefore likely not
presbyopic. In addition, as discussed in Section 2.3, although

5. ∆v = α − β, α = 2 arctan(i/2x), and β = 2 arctan(i/2y), where i
is the observer’s inter-pupillary distance, x is the actual target distance,
and y is the judged distance (Fig. 8). Note that using x assumes that
observers would match a real object with perfect accuracy, but the very
accurate and precise results for the real consistent condition suggest
this assumption is reasonable.

Fig. 11. For the AR collimated condition, the change in vergence angle
∆v = α − β (Fig. 2), when an observer has matched the depth of the
virtual target β with the real pointer α (Fig. 7). Each line in each panel
is a different observer. For all N = 30 observers, ∆v is approximately
constant across all tested distances. The boxplot gives the value for the
median observer.

older people are worse than younger people at many per-
ceptual tasks, recent studies have found that older people
preserve their abilities in many tasks related to distance per-
ception. Therefore, it was unclear if older observers would
replicate the effects observed in Experiment I (Fig. 9). Fur-
thermore, this work was primarily inspired by medical AR
applications, and the majority of medical professionals are
old enough to suffer some degree of presbyopia. Therefore,
the purpose of Experiment II was to replicate Experiment I,
using presbyopic observers, aged 40 and older.

5.1 Method

Other than the age of the observers, the methods of Exper-
iment II were identical to Experiment I. 40 observers were
recruited from a population of university and community
members. The observers ranged in age from 41 to 80; the
mean age was 55.6, and 19 were male and 21 female. 6
observers were paid $10 an hour, 33 were paid $12 hour, and
one was not paid. Each observer completed 5 (distance) ×
6 (repetition) = 30 trials, and the experiment collected a
total of 40 (observers) × 30 (trials) = 1200 data points.

5.2 Results

Fig. 8e–h shows the results from Experiment II as scatter-
plots; the r2 values indicate that the data continues to be
very well ﬁt by regression equations. Fig. 12 shows the
results as error, with Experiment I’s results also shown for
comparison. Figs. 13 and 14 show the results of multiple
regression analysis.

Older and younger only differ in AR collimated: Fig. 13 com-
pares Experiment I to Experiment II condition by condition.
For the AR collimated condition (Fig. 13b), the slopes do
not signiﬁcantly differ (F1,96 = 0.38, p = 0.54), but the
intercepts do (F1,97 = 35.7, p < 0.001); the older observers
matched collimated AR targets a constant −1.1 cm closer
to themselves than the younger observers (Fig. 12b). For
the remaining conditions, the effect size of the difference
between Experiments I and II, 0.013% (Fig. 13a), 0.031%
(Fig. 13c), and 0.056% (Fig. 13d), is too small for any sta-
tistical differences to be meaningful. Therefore, for the real
consistent, AR consistent, and AR midpoint conditions, the
results for the older observers and the younger observers
are equivalent.

Exp IExp II: Older ObserversExp III: Dim Targetsllllllllllllllllllllllllllllllllllllllllllllllllll(a)llllllllllllllllllllllllllllllllllllllllllllllllll(b)llllllllllllllllllllllllllllllllllllllllllllllllll(c)−1.2−0.9−0.6−0.30.00.30.633.336.44044.45033.336.44044.45033.336.44044.450Actual Distance (cm)Dv(cid:176)IEEE ELECTRONIC PREPRINT (UNDER REVIEW)

10

Fig. 12. Experiment II: older observers, plotted as mean error against
actual distance (N = 1200). For comparison, Experiment I’s results are
also shown in light grey, offset along the x-axis for clarity.

Fig. 13. Experiment I versus II, the effect of age, multiple regression
analysis, with N = 400 ghosted data points. See the caption for Fig 10.

Real consistent very accurate: Fig. 12a indicates that older
observers were very accurate when matching the distance
of real targets. The mean error is +0.4 mm, and the slope of
the linear model for Fig. 12a, y = −0.012x + 0.60, does not
signiﬁcantly differ from 0 (F1,48 = 2.5, p = 0.12). Note that
this is statistically equivalent to testing whether the slope in
Fig. 8e differs from 1.

AR collimated increasingly overestimated: For the older ob-
servers, when AR collimated is compared to real con-
sistent (Fig. 14a), the slopes signiﬁcantly differ (F1,96 =
13.8, p < 0.001); the AR collimated errors ranged from −0.7
to +0.9 cm (Fig. 12b).

AR consistent underestimated: For the older observers, when
AR consistent is compared to real consistent (Fig. 14b), the
slopes do not signiﬁcantly differ (F1,96 = 0.56, p = 0.46),
but the intercepts do (F1,97 = 16.6, p < 0.001); the AR con-
sistent targets were underestimated by a constant −0.3 cm
(Fig. 12c).

AR midpoint equivalent to real consistent: For the older ob-
servers, when AR midpoint is compared to real consistent
(Fig. 14c), the effect size is 0.0093%, which is too small for
any statistical differences to be meaningful. Therefore, the
AR midpoint targets were accurately matched (Fig. 12d).

AR consistent and AR midpoint equivalent: For the older ob-
servers, when AR consistent is compared to AR midpoint
(Fig. 14d), the effect size is 0.036%, also too small for
any statistical differences to be meaningful. Therefore, the
matches of the AR consistent and AR midpoint targets were
equivalent (Fig. 12c, d).

5.3 Discussion

The purpose of Experiment II was to replicate Experiment I,
using older, presbyopic observers. According to Duane [31],
the younger observers in Experiment I had an expected near
focus of ∼8.3 cm (∼11.5 D), while for these older observers
the expected near focus was ∼68 cm (∼1.5 D).

Fig. 14. Experiment II, multiple regression analysis, older observers, with
N = 200 ghosted data points. See the caption for Fig 10.

Experiment II’s results only differ for the AR colli-
mated condition. For collimated targets, older observers
showed less overestimation than younger observers, with
matches shifted towards the observer by a constant −1.1 cm
(Fig. 13b). Older observers had a mean error of +0.12 cm,
while younger observers had a mean error of +1.2 cm
(Fig. 12b), and therefore older observers were on average
more accurate than younger observers. However, the slope,
b = 1.072, is the same for both sets of observers (Fig. 13b),
and differs signiﬁcantly from the slope for the real consistent
condition (Figs. 10a and 14a). Therefore, for both younger
and older observers, matches of collimated targets were
inaccurate, and increasingly overestimated with increasing
distance. In addition, for each distance, Fig. 11b shows
∆v, the change in vergence angle for the 10 older AR
collimated observers. For 9 of the 10 observers ∆v changes
less than 0.6◦, for the outlying observer it changes 1.4◦, and
the median observer changes less than 0.25◦. These small
angular changes are consistent with the hypothesis that, for

llllllllll(a)llllllllll(b)llllllllll(c)llllllllll(d)Real ConsistentAR CollimatedAR ConsistentAR Midpoint−1.0−0.50.00.51.01.52.02.5−1.0−0.50.00.51.01.52.02.533.336.440.044.450.033.336.440.044.450.0Actual Distance (cm)Error (cm), –1 SEMExperimentllExp IIExp Illllllllllllllllllllllllllllllllllllllllllllllllll(a)y = 0.992x + 0.35R2 = 99.8%dR2 = 0.013%llllllllllllllllllllllllllllllllllllllllllllllllll(b) Exp I: y = 1.072x − 1.72Exp II: y = 1.072x − 2.82R2 = 98.0%dR2 = 0.74%, d = −1.1 cmllllllllllllllllllllllllllllllllllllllllllllllllll(c)y = 0.983x + 0.38R2 = 99.4%dR2 = 0.031%llllllllllllllllllllllllllllllllllllllllllllllllll(d)y = 0.995x + 0.07R2 = 99.2%dR2 = 0.056%Real Consis: Exp I vs Exp IIAR Collim: Exp I vs Exp IIAR Consis: Exp I vs Exp IIAR Midpt: Exp I vs Exp II30354045505530354045505533.336.440.044.450.033.336.440.044.450.0Actual Distance (cm)Judged Distance (cm)ExperimentlExp IExp IIllllllllllllllllllllllllllllllllllllllllllllllllll(a)  AR Collim: y = 1.081x − 3.21Real Consis: y = 0.988x + 0.60R2 = 98.6%dR2 = 0.20%, d = −0.7, +0.9 cmllllllllllllllllllllllllllllllllllllllllllllllllll(b)Real Consis: y = 0.983x + 0.81  AR Consis: y = 0.983x + 0.49R2 = 99.5%dR2 = 0.081%, d = −0.3 cmllllllllllllllllllllllllllllllllllllllllllllllllll(c)y = 0.985x + 0.67R2 = 99.4%dR2 = 0.0093%(d)y = 0.980x + 0.71R2 = 99.2%dR2 = 0.036%AR Collim vs Real ConsisAR Consis vs Real ConsisAR Midpt vs Real ConsisAR Consis vs AR Midpt30354045505530354045505533.336.440.044.450.033.336.440.044.450.0Actual Distance (cm)Judged Distance (cm)ConditionlReal ConsisAR CollimAR ConsisAR MidptIEEE ELECTRONIC PREPRINT (UNDER REVIEW)

11

experiment collected a total of 30 (observers) × 30 (trials) =
900 data points.

6.2 Results

Fig. 8j–l shows the results from Experiment III as scatter-
plots; the r2 values indicate that the data continues to be
very well ﬁt by regression equations. Fig. 16 shows the same
results as error, with Experiment I’s results also shown for
comparison. Figs. 17 and 18 show the results of multiple
regression analysis.

Dim targets differ in AR consistent and AR midpoint: Fig. 17
compares Experiment I to Experiment III condition by con-
dition. For the AR collimated condition (Fig. 17a), the effect
size of the difference is 0.00027%, much too small for any
statistical differences to be meaningful. Therefore, the results
for the dim targets and the bright targets are equivalent
(Fig. 16b). For the AR consistent condition (Fig. 17b), the
slopes signiﬁcantly differ (F1,96 = 7.7, p = 0.007), and
therefore the dim targets were matched +0.2 to +0.9 cm
farther than the bright targets (Fig. 16c). And ﬁnally, for the
AR midpoint condition (Fig. 17c), the slopes do not signiﬁ-
cantly differ (F1,96 < 0.01, p = 0.96), but the intercepts do
(F1,97 = 17.7, p < 0.001), and therefore the dim targets were
matched +0.4 cm farther than the bright targets (Fig. 16d).

AR collimated increasingly overestimated: When dim AR col-
limated is compared to real consistent from Experiment I
(Fig. 18a), the slopes signiﬁcantly differ (F1,96 = 5.5, p =
0.021), indicating that the dim AR collimated targets were
overestimated from +0.8 to +1.9 cm (Fig. 16b).

AR consistent equivalent to real consistent: When dim AR
consistent is compared to real consistent from Experiment I
(Fig. 18b), the effect size of the difference is 0.031%, which
is too small for any statistical differences to be meaningful.
Therefore, the dim AR consistent targets were accurately
matched (Fig. 16c).

AR midpoint equivalent to real consistent: When dim AR
midpoint is compared to real consistent from Experiment I
(Fig. 18c), the effect size of the difference is 0.025%, which is
too small for any statistical differences to be meaningful.
Therefore, the dim AR midpoint targets were accurately
matched (Fig. 16d).

AR consistent and AR midpoint equivalent: When dim AR
consistent is compared to dim AR midpoint (Fig. 18d),
the effect size is 0.012%, also too small for any statistical
differences to be meaningful. Therefore, the matches of dim
AR consistent and dim AR midpoint targets were equivalent
(Fig. 16c, d).

6.3 Discussion

The purpose of Experiment III was to determine if a dim
AR target, which has the same apparent brightness as the
real target (Fig. 15), would increase the accuracy of the
AR consistent condition. When comparing Experiment III
to Experiment I, there was no difference in matching AR
collimated targets, but increased accuracy for both AR con-
sistent and AR midpoint targets (Fig. 17). In addition, when
combined with the real consistent data from Experiment I,

Fig. 15. Experiment III examined target brightness. (a) The real target.
(b) The bright AR target used in Experiments I and II. (c) The dim AR
target used in Experiment III.

both younger and older observers, the vergence angle bias
is constant.

For the other conditions, the observer’ age—and there-
fore the observers’ ability to accommodate to different focal
demands—made no difference. Older observers were just as
accurate as younger observers in matching the distance to
real targets, as well as to AR targets with both consistent
and midpoint focal cues. These results are consistent with
previous work that has found that older observers preserve
their abilities in many tasks related to distance perception
(Bian and Andersen [33]).

6 EXPERIMENT III: BRIGHTNESS

However, a conﬂicting ﬁnding from both experiments is that
AR consistent was underestimated, while AR midpoint was
accurate and AR consistent was equivalent to AR midpoint.
This is true for both Experiment I (Fig. 10) and Experiment II
(Fig. 14). These conﬂicting statistical results are likely due
to the small effect size of AR consistent’s underestimation
(d = −0.4 and d = −0.3 cm, respectively). Nevertheless, the
underestimation is statistically signiﬁcant, and was repli-
cated among 20 observers with widely varying ages.

As discussed in Section 2.5, brighter objects appear closer
than similar-sized dimmer objects. Figs. 15a and b show
photographs, taken through the haploscope optics, of the
real and AR targets used in Experiments I and II. The AR
target appeared brighter than the real target.6 For Exper-
iment III, the brightness was reduced, until the AR and
real targets appeared to have the same brightness (Fig. 15c).
The purpose of Experiment III was to determine if the dim
AR target would increase the accuracy of the AR consistent
condition.

6.1 Method

Other than the brightness of the AR target, the methods
of Experiment III were identical to Experiment I. Because
the real target object did not change, that condition was
not replicated. To facilitate comparison with Experiment I,
younger observers were recruited, from a population of
university students and staff. The 30 observers ranged in
age from 17 to 24; the mean age was 19.8, and 21 were
male and 9 female. 6 observers were paid $12 an hour,
and the rest received course credit. Each observer com-
pleted 5 (distance) × 6 (repetition) = 30 trials, and the

6. Note that brightness is the perceptual experience of luminance, and
cannot be directly measured or captured with a camera. The luminance
of the targets was measured (Singh [8]).

(a)real'target(b)bright'AR'target(c)'dim'AR'targetIEEE ELECTRONIC PREPRINT (UNDER REVIEW)

12

Fig. 16. Experiment III: dim targets, plotted as mean error against actual
distance (N = 900). For comparison, Experiment I’s results are also
shown in light grey, offset along the x-axis for clarity.

Fig. 18. Experiment III, multiple regression analysis, dim targets, with
N = 200 ghosted data points. See the caption for Fig 10. The real
consistent data is repeated from Experiment I.

than 0.12◦. These small angular changes are consistent with
the hypothesis that, for the dim AR targets, the vergence
angle bias is still constant.

7 GENERAL DISCUSSION
Constant Vergence Angle Bias: As discussed in Section 1,
Swan et al. [6] found that the AR collimated condition
caused overestimation that increased linearly with distance,
and proposed that this was caused by the collimation bias-
ing the eyes’ vergence angle to rotate outwards by a constant
amount. All of the experiments reported here replicated this
result, and strongly support this hypothesis. These ﬁndings
are also consistent with the prediction, by Mon-Williams
and Tresilian [19], that an inconsistent accommodative cue
would bias perceived depth in the same direction as the
accommodative cue (Fig. 3). However, Swan et al. [6] did
not measure this vergence angle change, and it was not
measured here. In a future experiment, it should be directly
measured.

Dim Targets: The experiments found the most accurate
matches for dim AR targets, which more closely matched
the brightness of the real targets. These results are consistent
with previous work that ﬁnds brighter objects appear closer
than dimmer objects (Ashley [38], Farn`e [39], Coules [40]).
However, it is interesting that the error for matching the
dim AR targets disappeared, even though the error was
calculated between-subjects: in all of the experiments, differ-
ent groups of 10 observers saw the real targets, the bright
AR targets, and the dim AR targets. It would have been
less surprising to have found these errors in a within-
subjects design, where observers made a judgment about
two targets with different brightnesses, viewed simultane-
ously (e.g., Ashley [38], Farn`e [39], Coules [40]). The errors
may be related to the fact that AR targets are drawn with
impoverished depth cues, and therefore brightness could
be directly biasing the vergence angle. If this hypothesis
is true, it would be another component of accurate depth
presentation that must be considered by AR practitioners. A

Fig. 17. Experiment I versus III, the effect of brightness, multiple regres-
sion analysis, with N = 300 ghosted data points. See the caption for
Fig 10.

matches for the dim AR target were overestimated in the AR
collimated condition, but accurate in both the AR consistent
and AR midpoint conditions (Figs. 18). Therefore, for the AR
consistent and AR midpoint conditions, the dim AR targets
were as accurately matched as the real targets (Fig. 16).

In addition, the pattern of AR consistent being underes-
timated, while AR midpoint was accurate and AR consistent
was equivalent to AR midpoint, occurred for both the
younger observers of Experiment I (Fig. 10) and the older
observers of Experiment II (Fig. 14). While Experiment III
only tested younger observers, the results are consistent
with the hypothesis that older observers would also accu-
rately match the depth of dim AR consistent and dim AR
midpoint targets.

Finally, for the dim AR collimated targets, for each
distance Fig. 11c shows ∆v, the change in vergence angle,
for the 10 AR collimated observers. For all observers ∆v
changes less than 0.4◦, and the median observer changes less

lllll(a)llllllllll(b)llllllllll(c)llllllllll(d)Real ConsistentAR CollimatedAR ConsistentAR Midpoint−1.0−0.50.00.51.01.52.02.5−1.0−0.50.00.51.01.52.02.533.336.440.044.450.033.336.440.044.450.0Actual Distance (cm)Error (cm), –1 SEMExperimentllExp IIIExp Illllllllllllllllllllllllllllllllllllllllllllllllll(a)y = 1.062x − 1.32R2 = 97.6%dR2 = 0.00027%llllllllllllllllllllllllllllllllllllllllllllllllll(b)Exp III: y = 1.029x − 1.10  Exp I: y = 0.988x + 0.06R2 = 99.5%dR2 = 0.21%, d = +0.2, +0.9 cmllllllllllllllllllllllllllllllllllllllllllllllllll(c)Exp III: y = 1.009x − 0.23  Exp I: y = 1.009x − 0.62R2 = 99.4%dR2 = 0.10%, d = +0.4 cmAR Collim: Exp I vs Exp IIIAR Consis: Exp I vs Exp IIIAR Midpt: Exp I vs Exp III30354045505530354045505533.336.440.044.450.0Actual Distance (cm)Judged Distance (cm)ExperimentlExp IExp IIIllllllllllllllllllllllllllllllllllllllllllllllllll(a)  AR Collim: y = 1.062x − 1.30Real Consis: y = 0.997x + 0.11R2 = 98.3%dR2 = 1.1%, d = +0.8, +1.9 cmllllllllllllllllllllllllllllllllllllllllllllllllll(b)y = 1.013x − 0.50R2 = 99.7%dR2 = 0.031%llllllllllllllllllllllllllllllllllllllllllllllllll(c)y = 1.003x − 0.07R2 = 99.7%dR2 = 0.025%(d)y = 1.019x − 0.67R2 = 99.5%dR2 = 0.012%AR Collim vs Real ConsisAR Consis vs Real ConsisAR Midpt vs Real ConsisAR Consis vs AR Midpt30354045505530354045505533.336.440.044.450.033.336.440.044.450.0Actual Distance (cm)Judged Distance (cm)ConditionlReal ConsisAR CollimAR ConsisAR MidptIEEE ELECTRONIC PREPRINT (UNDER REVIEW)

13

future experiment should examine whether the brightness
of an AR object directly inﬂuences vergence angle.

Midpoint Accommodative Stimulus: While the AR consis-
tent condition was accurate for the dim AR targets, the
AR midpoint condition was accurate across all of the ex-
periments. It is not clear why AR midpoint was accurate
at both brightness levels, while AR consistent was not.
Nevertheless, the practical implication is that, because the
AR midpoint condition was at least as accurate as the AR
consistent condition, for AR applications requiring accurate
near-ﬁeld depth matching, it is sufﬁcient for the focal de-
mand to be set to the middle of the working volume.

However, the positive results for the AR midpoint con-
dition suggest comparison with light-ﬁeld displays, which
can simultaneously present multiple virtual objects at dif-
ferent focal distances. In addition to solving the vergence-
accommodation conﬂict, light-ﬁeld displays are predicted to
eventually become the dominant technology for all kinds of
3D experiences (Balram [48]). However, although the tech-
nology is rapidly developing, AR light-ﬁeld displays face
many fundamental challenges and design tradeoffs, in areas
such as depth range, color resolution, spatial resolution,
computational demands, and data throughput requirements
(Wu et al. [49]). Therefore, the AR midpoint results suggest
that the level of engineering complexity required for these
kinds of displays may not be necessary, especially for AR
applications where the most important perceptual task is
accurate matching at near-ﬁeld distances (e.g., Edwards [4],
Krempien et al. [5]).

Future Work: As discussed in this section, errors detected in
these experiments are likely due to vergence angle biases.
Therefore, useful future work would replicate these exper-
iments while measuring vergence angle. Possible methods
for making this measurement include binocular eye track-
ing (Wang et al. [50]), or nonius line methods (Ellis and
Menges [41]).

In addition, because the AR haploscope was mounted to
a tabletop, these experiments could not examine the depth
cue of motion perspective. Although some AR applications,
such as the operating microscope described by Edwards et
al. [4], are also mounted and therefore lack motion perspec-
tive, it is a very salient depth cue (Nagata [10], Cutting and
Vishton [9]), and should be examined in future experiments.
A head-mounted AR haploscope, such as the one used by
McCandless et al. [42], would allow a replication of these
experiments that included motion perspective.

8 PRACTICAL IMPLICATIONS
For accurate near-ﬁeld depth matching, the experiments
reported here have the following implications:

• Collimated graphics should not be used. A focal distance
set to the middle of the depth range is a good as a focal
distance optimized for every virtual object.

• The brightness of virtual objects needs to match the
brightness of real objects.

• Observers old enough to suffer age-related reductions
in accommodative ability are just as accurate as younger
observers.

ACKNOWLEDGMENTS

This material is based upon work supported by the National
Science Foundation, under awards IIS-0713609, IIS-1018413,
and IIS-1320909, to J. E. Swan II.

REFERENCES

[1] M. Kersten-Oertel, P. Jannin, and D. L. Collins, “The State of the
Art of Visualization in Mixed Reality Image Guided Surgery,”
Comput. Medical Imaging and Graphics, vol. 37, no. 2, pp. 98–112,
2013.

[2] D. Curtis, D. Mizell, P. Gruenbaum, and A. Janin, “Several devils
in the details: Making an AR application work in the airplane
factory,” in Proc. of Intern. Workshop on Augmented Reality (IWAR),
1998, pp. 47–60.
S. J. Henderson and S. Feiner, “Evaluating the beneﬁts of aug-
mented reality for task localization in maintenance of an armored
personnel carrier turret,” in Intern. Symp. on Mixed and Augmented
Reality (ISMAR), 2009, pp. 135–144.

[3]

[4] P. J. Edwards, A. P. King, C. R. Maurer Jr., D. A. de Cunha, D. J.
Hawkes, D. L. G. Hill, R. P. Gaston, M. R. Fenlon, A. Jusczyzck,
A. J. Strong, C. L. Chandler, and M. J. Gleeson, “Design and eval-
uation of a system for microscope-assisted guided interventions
(MAGI),” IEEE Trans. on Medical Imaging, vol. 19, no. 11, pp. 1082–
1093, 2000.

[5] R. Krempien, H. Hoppe, L. Kahrs, S. Daeuber, O. Schorr, G. Eggers,
M. Bischof, M. W. Munter, J. Debus, and W. Harms, “Projector-
Based Augmented Reality for Intuitive Intraoperative Guidance in
Image-Guided 3D Interstitial Brachytherapy,” International Journal
of Radiation Oncology • Biology • Physics, vol. 70, no. 3, pp. 944–952,
Mar. 2008.
J. E. Swan II, G. Singh, and S. R. Ellis, “Matching and reaching
depth judgments with real and augmented reality targets,” IEEE
Trans. on Visualization and Computer Graphics, vol. 21, no. 11, pp.
1289–1298, 2015.
J. L. Gabbard, D. G. Mehra, and J. E. Swan II, “Effects of AR
display context switching and focal distance switching on human
performance,” article in submission, 2017.

[6]

[7]

[9]

[8] G. Singh, “Near-Field Depth Perception in Optical See-Through
Augmented Reality,” Ph.D. dissertation, Mississippi State Univer-
sity, Aug. 2013.
J. E. Cutting and P. M. Vishton, “Perceiving layout and knowing
distances: The integration, relative potency, and contextual use of
different information about depth,” in Handbook of Perception and
Cognition: Perception of Space and Motion, W. Epstein and S. Rogers,
Eds. Academic Press, 1995, vol. 5, pp. 69–117.

[10] S. Nagata, “How to Reinforce Perception of Depth in Single Two-
Dimensional Pictures,” in Pictorial Communication in Virtual and
Real Environments, S. R. Ellis, M. K. Kaiser, and A. J. Grunwald,
Eds. London: Taylor & Francis, 1989, pp. 527–545.

[11] B. Gillam, “The perception of space layout,” in Perception of Space
and Motion, 2nd ed., W. Epstein and S. Rogers, Eds. Academic
Press, 1995, pp. 23–67.

[12] G. P. Bingham and C. C. Pagano, “The necessity of a perception-
action approach to deﬁnite distance perception: Monocular dis-
tance perception to guide reaching,” Journal of Experimental Psy-
chology: Human Perception and Performance, vol. 24, no. 1, pp. 145–
168, 1998.

[13] M. Mon-Williams and J. R. Tresilian, “Some recent studies on the
extraretinal contribution to distance perception,” Perception, pp.
167–181, 1999.

[14] M. S. Landy, L. T. Maloney, E. B. Johnston, and M. Young, “Mea-
surement and modeling of depth cue combination: In defense of
weak fusion,” Vision Research, vol. 35, no. 3, pp. 389–412, Feb 1995.
[15] R. J. Leigh and D. S. Zee, The Neurology of Eye Movements, 5th ed.

Oxford University Press, USA, 2015.

[16] J. L. Semmlow and G. K. Hung, “The near response: Theories of
control,” in Vergence Eye Movements: Basic & Clinical Aspects, C. M.
Schor and K. J. Ciuffreda, Eds. Butterworth, 1983, pp. 175–195.

[17] H. Ripps, N. B. Chin, I. M. Siegel, and G. M. Breinin, “The effect of
pupil size on accommodation, convergence, and the ac/a ratio.”
Investigative Ophthalmology, vol. 1, pp. 127–135, Feb 1962.

[18] D. Kersten and G. E. Legge, “Convergence accommodation,”
Journal of the Optical Society of America, vol. 73, no. 3, pp. 332–338,
Mar 1983.

IEEE ELECTRONIC PREPRINT (UNDER REVIEW)

14

[19] M. Mon-Williams and J. R. Tresilian, “Ordinal depth information
from accommodation?” Ergonomics, vol. 43, no. 3, pp. 391–404,
2000.

[20] E. Kruijff, J. E. Swan II, and S. Feiner, “Perceptual Issues in
Augmented Reality Revisited,” in Intern. Symp. on Mixed and
Augmented Reality (ISMAR), J. Park, V. Lepetit, and T. H ¨ollerer,
Eds. Piscataway, NJ, USA: IEEE, 2010, pp. 3–12.

[21] M. Lambooij, M. Fortuin, I. Heynderickx, and W. IJsselsteijn,
“Visual discomfort and visual fatigue of stereoscopic displays: A
review,” Journal of Imaging Science and Technology, vol. 53, no. 3, pp.
030 201–030 201–14, 2009.

[22] D. M. Hoffman, A. R. Girshick, K. Akeley, and M. S. Banks,
“Vergence–accommodation conﬂicts hinder visual performance
and cause visual fatigue,” Journal of Vision, vol. 8(3), no. 33, pp.
1–30, 2008.

[23] H. A. Swenson, “the Relative Inﬂuence of Accommodation and
Convergence in the Judgment of Distance,” Journal of General
Psychology, vol. 7, no. 2, pp. 360–380, 1932.

[24] E. Brenner and J. M. Van Damme, “Judging distance from ocular
convergence,” Vision Research, vol. 38, no. 4, pp. 493–498, 1998.
[25] D. A. Owens and H. W. Liebowitz, “Accommodation, conver-
gence, and distance perception in low illumination,” Optometry
& Vision Science, vol. 57, no. 9, pp. 540–550, 1980.

[26] J. R. Tresilian, M. Mon-Williams, and B. M. Kelly, “Increasing
conﬁdence in vergence as a cue to distance,” Proc. of the Royal
Society of London B, vol. 266, pp. 39–44, 1999.

[27] A. Viguier, G. Clment, and Y. Trotter, “Distance perception within

near visual space,” Perception, vol. 30, pp. 115–124, 2001.

[28] J. M. Foley, “Binocular distance perception,” Psychological Review,

vol. 87, no. 5, pp. 411–434, 1980.

[29] J. H. Iavecchia, H. P. Iavecchia, and S. N. Roscoe, “Eye accommo-
dation to head-up virtual images,” Human Factors, vol. 30, no. 6,
pp. 703–712, 1988.

[30] S. N. Roscoe, “Bigness Is in the Eye of the Beholder,” Human

Factors, vol. 27, no. 6, pp. 615–636, 1985.

[31] A. Duane, “Normal values of the accommodation at all ages,”
Journal of the American Medical Association, vol. LIX, pp. 1010–1013,
1912.

[32] S. Kasthurirangan and A. Glasser, “Age related changes in accom-
modative dynamics in humans,” Vision Research, vol. 46, pp. 1507–
1519, Apr 2006.

[33] Z. Bian and G. J. Andersen, “Aging and the perception of ego-
centric distance,” Psychology and Aging, vol. 28, no. 3, pp. 813–825,
2013.

[34] G. Heron, W. N. Charman, and C. M. Schor, “Age changes in the
interactions between the accommodation and vergence systems,”
Optometry and Vision Science, vol. 78, no. 10, pp. 754–762, 2001.
[35] G. J. Andersen, A. Saidpour, and M. L. Braunstein, “Effects of Col-
limation on Perceived Layout in 3-D Scenes,” Perception, vol. 27,
no. 11, pp. 1305–1315, 1998.

[36] S. J. Watt, K. Akeley, M. O. Ernst, and M. S. Banks, “Focus Cues
Affect Perceived Depth,” Journal of Vision, vol. 5, no. 10, pp. 834–
862, 2005.

[37] E. McCurdy, The Notebooks of Leonardo da Vinci, Volume II. Reynal

& Hitchcock, 1938.

[38] M. L. Ashley, “Concerning the signiﬁcance of intensity of light in
visual estimates of depth,” Psychological Review, vol. 5, no. 6, pp.
595–615, 1898.

[39] M. Farn`e, “Brightness as an indicator to distance: Relative bright-
ness per se or contrast with the background?” Perception, vol. 6,
pp. 287–293, 1977.

[40] J. Coules, “Effect of photometric brightness on judgments of

distance,” Experimental Psychology, vol. 50, no. 1, pp. 19–25, 1955.

[41] S. R. Ellis and B. M. Menges, “Localization of virtual objects in the
near visual ﬁeld,” Human Factors, vol. 40, no. 3, pp. 415–431, 1998.
[42] J. W. McCandless, S. R. Ellis, and B. D. Adelstein, “Localization
of a time-delayed, monocular virtual object superimposed on a
real environment,” Presence: Teleoperators and Virtual Environments,
vol. 9, no. 1, pp. 15–24, 2000.

[43] G. Singh, J. E. Swan II, J. A. Jones, and S. R. Ellis, “Depth judgment
measures and occluding surfaces in near-ﬁeld augmented reality,”
in ACM Symp. on Applied Perception in Graphics and Visualization
(APGV). New York, NY, USA: ACM, 2010, pp. 149–156.

[44] N. Rosa, W. H ¨urst, P. J. Werkhoven, and R. C. Veltkamp, “Visuo-
tactile Integration for Depth Perception in Augmented Reality,” in
Proc. of ACM Intern. Conf. on Multimodal Interaction (ICMI). ACM,
2016, pp. 45–52.

[45] J. P. Rolland, W. Gibson, and D. Ariely, “Towards quantifying
depth and size perception in virtual environments,” Presence:
Teleoperators and Virtual Environments, vol. 4, no. 3, pp. 24–49, 1995.
[46] E. J. Pedhazur, Multiple Regression in Behavioral Research, 2nd ed.

Holt, Rinehart and Winston, 1982.

[47] J. Cohen, P. Cohen, S. G. West, and L. S. Aiken, Applied Multiple
Regression/Correlation Analysis for the Behavioral Sciences, 3rd ed.
Lawrence Erlbaum Associates, 2003.

[48] N. Balram, “The next wave of 3-D—light-ﬁeld displays,” Informa-

tion Display, vol. 30, no. 6, pp. 4,49, November/December 2014.

[49] W. Wu, K. Berkner, I. Toˇsi´c, and N. Balram, “Personal near-to-eye
light-ﬁeld displays,” Information Display, vol. 30, no. 6, pp. 16–22,
November/December 2014.

[50] R. I. Wang, B. Pelfrey, A. T. Duchowski, and D. H. House, “Online
3D Gaze Localization on Stereoscopic Displays.” ACM Trans. on
Applied Perception, vol. 11, no. 1, pp. 1–21, 2014.

Gurjot Singh Biography text here.

PLACE
PHOTO
HERE

PLACE
PHOTO
HERE

PLACE
PHOTO
HERE

Stephen R. Ellis Biography text here.

J. Edward Swan II Biography text here.

