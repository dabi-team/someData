2
2
0
2

n
a
J

7

]

V

I
.
s
s
e
e
[

1
v
9
1
6
2
0
.
1
0
2
2
:
v
i
X
r
a

High-contrast, speckle-free, true 3D holography via
binary CGH optimization

Byounghyo Lee , Dongyeon Kim , Seungjae Lee , Chun Chen , and Byoungho Lee*

School of Electrical and Computer Engineering, Seoul National University, Gwanak-Gu Gwanakro 1, Seoul 08826,
South Korea
*byoungho@snu.ac.kr

ABSTRACT

Holography is a promising approach to implement the three-dimensional (3D) projection beyond the present two-dimensional
technology. True 3D holography requires abilities of arbitrary 3D volume projection with high-axial resolution and independent
control of all 3D voxels. However, it has been challenging to implement the true 3D holography with high-reconstruction quality
due to the speckle. Here, we propose the practical solution to realize speckle-free, high-contrast, true 3D holography by
combining random-phase, temporal multiplexing, binary holography, and binary optimization. We adopt the random phase for
the true 3D implementation to achieve the maximum axial resolution with fully independent control of the 3D voxels. We develop
the high-performance binary hologram optimization framework to minimize the binary quantization noise, which provides
accurate and high-contrast reconstructions for 2D as well as 3D cases. Utilizing the fast operation of binary modulation, the
full-color high-framerate holographic video projection is realized while the speckle noise of random phase is overcome by
temporal multiplexing. Our high-quality true 3D holography is experimentally veriﬁed by projecting multiple arbitrary dense
images simultaneously. The proposed method can be adopted in various applications of holography, where we show additional
demonstration that realistic true 3D hologram in VR and AR near-eye displays. The realization will open a new path towards
the next generation of holography.

Introduction

Holography has been investigated with lots of attention based on the possibility of three-dimensional (3D) projection in the
past decades1–4. True 3D holography requires ability to project any 3D volume with high-axial resolution and can control all
3D points independently. Recent emerging studies of computer-generated holograms (CGHs) concentrate on visualization of
photorealistic scene, including high-contrast and speckle-free reconstruction5, 6. Yet, the works strict the 3D points following
the speciﬁc smooth phase distribution to avoid speckle, which leads to dependency among the complex-valued 3D points. As
disadvantages of the dependency, the 3D reconstruction of smooth phase encoding suffers low axial resolution with a small
eyebox and difﬁculty in supporting parallax.

Although holography can reproduce the arbitrary 3D volume from the linear superposition of Fresnel zone plate patterns,
if the phase of 3D points is deﬁned to some speciﬁc distribution, it is limited to control the complex-valued holographic 3D
points independently. A possible approach for breaking the dependency is to make the phase proﬁle of 3D points following
the random distribution so that the mutual interference is removed by using the orthogonality of random vectors7. However,
the speckle noise from the random phase severely hampers reconstructed images quality, so that the previous works on true
3D projection are limited to sparse images such as dots or letters, or noisy images7, 8. Until today, it remains as an unsolved
challenge for holography to achieve high-contrast, speckle-free, and true 3D projection simultaneously9.

The speckle noise in holography appears inevitably due to the technical issue of the spatial light modulator (SLM), imaging
principle of holography, and statistics of random phasors. The ﬁnite window size and limited diffraction angle of the SLM cause
a single voxel to be imaged with area rather than an ideal point. There have to exist interference between the adjacent voxels,
resulting in signiﬁcant speckle contrast even if a small number of random phasors are summated10. Due to the fundamental
limitation, it is challenging to remove the speckle for random phase holography. Decreasing coherency of the light source (e.g.,
LED) is one available approach to mitigate the speckle, but it sacriﬁces overall depth range and spatial resolution11, 12. Another
method is sampling reconstructed image considering the size of voxel’s area to avoid interference between adjacent voxels,
which suffers the loss of spatial resolution and the light efﬁciency13, 14. Smooth phase methods reduce speckle by enforcing the
interference between the adjacent voxels to constructive only5, 6, 15–19, but the dependency of phase results in the loss of the true
3D reconstruction capability.

The reconstruction quality and the ability of true 3D reconstruction are on the trade-off due to the speckle, which is hard to
be resolved by a single CGH no matter how optimize it. To overcome the fundamental limitation, we extend the problem to

 
 
 
 
 
 
ﬁnding a set of CGHs to give additional physical degree-of-freedom in the time-domain. From the statistical optics, one of the
powerful strategy is to sum the mutually independent speckle patterns, known as temporal multiplexing (TM) in holography10, 20.
However, implementation of speckle-free, full-color, and dynamic video projections through this method requires an SLM with
a signiﬁcantly fast refresh rate. The potential candidates are to utilize binary SLMs such as Ferro-electronic liquid crystal on
silicon (FLCOS) and digital micromirror devices. However, the results from the binary SLMs inherently suffer from binary
quantization noise21, appearing as background noise which reduces reconstructed image contrast22, 23. The previous works for
mitigating the binary noise are implemented through direct binary search24, 25, error diffusion26, 27, and Gerchberg–Saxton (GS)
algorithm28. But the direct binary search is computationally heavy and the improvements by other methods are not obvious.
In this paper, we report an unprecedented realization of speckle-free, high-contrast, true 3D holography supporting dynamic
video through the development of the binary optimization framework. The trade-off that cannot be physically solved in one
hologram is overcome with multiple holograms, and the remaining reduce-able binary noise is mitigated through a developed
hologram optimization framework. We experimentally demonstrate the true 3D holography by multidepth projection of
mutually independent images. The results show high-resolution, high-contrast, speckle-free, dense color images that go beyond
state-of-the-art works that often represent a sparse and monochromatic imagery. We also apply high-quality true 3D holography
to the near-eye displays as a demonstration that our approach can be adopted in various holographic applications. With
the powerful performance of our true 3D holography, we verify the ability to provide realistic 3D hologram, showing high
correspondence with rendered 3D scenes in virtual reality (VR) and real objects in augmented reality (AR).

Results

Prototypes of true 3D holography
To demonstrate the realization of true 3D holography, we build two types of full-color holographic prototypes, such as multiplane
projection system and near-eye displays. The schemes of these setups are shown in Figs. 1a and 3a (see Supplementary
Information for real photographs). We use an 8.2 µm pitch of FLCOS (Fourth Dimension Displays; QXGA-R10) as a binary
SLM, synchronized with a ﬁber-coupled full-color laser diode (Wikioptics; Red: 638 nm, Green: 520 nm, Blue: 450 nm). The
laser source is expanded and collimated by combining an objective lens (Nikon; M-40x, 0.65NA) and a collimating lens (Nikon;
50mm f/1.4). The FLCOS is originally designed to operate for 8 bits × 3 colors × 150 Hz when the resolution is 1920 × 1200
(WUXGA). We relocate the time sequence for the binary operation, which corresponds to the 1 bit × 3 colors × 50 Hz × 24
TM. The time sequence is synchronized with the ﬁber-coupled laser diode using the transistor-transistor logic (TTL) signal.
Although our FLCOS is originally designed for the phase only modulation, we use it for the amplitude type by sandwiching two
orthogonal linear polarizers to adopt single-side band encoding. The amplitude type CGH encoding makes our optimization
focusing on minimizing the binary quantization noise only without considering the complex-valued representation, and enables
successful optimization results. A custom-made single-sideband spatial ﬁlter is placed at the Fourier plane of the Fourier lens
(Canon EF 200mm f/2.8). The ﬁlter size is determined to match the blue channel’s Fourier domain size of 11 mm x 5.5 mm.
Since red and green channels have larger Fourier domain sizes than blue, input RGD data is resized and zero-padded to match
the size of the blue channel. The size of the entire projection area of multiplane system is equal to the blue channel’s Fourier
domain size. For the near-eye setup, an additional eyepiece lens (Nikon; 50mm f/1.4) is placed by consisting 4f system with the
Fourier lens. The prototype’s ﬁeld of view (FOV) is 12.6° × 6.3°, and the eyebox is 3.9 mm × 2.5 mm.

Realization of speckle-free true 3D projection with arbitrary 3D volume
To demonstrate the ability of speckle-free true 3D holographic projection, we design multiplane projection systems whose
target 3D volume is consisted of multiple dense images that are uncorrelated to each other. The ﬁve target intensities are
spaced 15 mm apart centered on the Fourier plane as shown in Fig. 1a. Here, we select the distance by considering the depth
of ﬁeld of the holographic projection system, which is limited by the space-bandwidth product of the SLM. We compared
our binary optimization method, termed binary-stochastic gradient descent (B-SGD), with the state-of-art works IFTA7 and
NOVO8(see Methods for the procedure of B-SGD). We also compare with the superposition hologram generated by summation
of propagated ﬁelds from all depths (termed Superposition) and its binary form combined with TM (termed Random). Since the
size of Fourier plane differs by the hologram encoding methods such as phase-only or amplitude-only, we apply the anamorphic
transform to the phase-only hologram to match the size29. To compare the CGH methods quantitatively, we simulate the
average structural similarity index measure (SSIM) according to the number of layers as shown in Fig. 1b. The simulated
results for the case of the ﬁve independent layers are included in Fig. 1c. Since all methods use the random phase, it is available
to project the independent images at each target depth with high-axial resolution. The IFTA and NOVO offer better results than
Superposition and provide acceptable image quality when the target proﬁles are simple (see Supplementary Information), but
the inevitable speckle noise from the random phase makes it challenge to be applied for the dense and complicated proﬁles as
shown in Fig. 1c.

2/15

The binary CGHs such as Random and our B-SGD can overcome the speckle issue and provide higher SSIM than the
above phase-only CGH results. The B-SGD optimization signiﬁcantly improves image contrast compared to the Random case,
and show the best performance of all the comparing methods. Figure 1d is experimental photographs of B-SGD hologram,
conﬁrming that the complicated color images can be reproduced with high-quality. Figure 1e is the intermediate planes
between the third and fourth planes from the SLM, showing a high agreement between the experiments and simulations. An
experimentally recorded axial sweep video within the full depth range is available in Supplementary Video 1.

We design the tomographic 3D visualization as an application of the true 3D multiplane projection. Figure 2a is the 3D
blended model (Synapse), where we obtain the eleven target tomographic images by capturing the cross-section of the model
using the 3D rendering program. The target images are designed to be spaced apart by 15 mm for consistency with the above
demonstration. Figure 2b is experimentally captured images at each designed depth, showing the feasibility of tomographic
visualization with high-quality and speckle-free projection. These results also support the possibility of controlling a large
number of arbitrary depth planes in the wide depth range.

Evaluating the performance of true 3D holography
We simulate the holographic reconstructions to assess the performance of the B-SGD. Here, we use the near-eye display setup
(see Fig. 3a) to reconstruct and evaluate the binary hologram. Figure 3b shows the simulated results corresponding to the
iteration number using image evaluation metrics such as the peak signal-to-noise ratio (PSNR) and the SSIM. The GS method
and non-optimized random phase results are compared by applying an equal number of TM (24 binary holograms). The
Random results are illustrated by dot line because they are not achieved from iterative methods. The ﬁgures show mean values
and standard error of 50 data sets from Sintel30, where the data sets are obtained by sampling ﬁve frames for each of the ten
scenes (’market’, ’cave’, ’bamboo’, etc.). The results conﬁrm that the GS algorithm quickly falls into the local minima and the
performance improvement is subtle compared to the initial and Random results. On the other hand, the B-SGD optimization
shows a clear performance improvement in both PSNR and SSIM.

Next, we experimentally evaluate our system using a 2D image (from bigbuck bunny31) as shown in Fig. 3c. Although
all the binary holographic methods are free from the speckle noise with the advantage of TM, the Random and GS suffer
from background noise and low-image contrast. The proposed B-SGD only reconstructs the speckle-less and high-contrast
holographic image in both experiment and simulation. The PSNR and SSIM are measured for quantitative evaluation, where
these two metrics are denoted in bottom insets in Fig. 3c. The experimental results as increasing the number of multiplexing are
summarized in Fig. 3d. Our prototype experimentally shows high performances that the PSNR of 22.1 dB and SSIM of 0.84.
To our knowledge, the experimental values are highly comparable to the state-of-art results from smooth phase holography
although we adopt random phase6, 16. Figure 3e shows the experimentally measured speckle contrast according to the number
of multiplexing and its reduction ratio, where the target intensity has a ﬂat constant. Interestingly, the speckle contrast shows the
identical trend in both optimization or not, and the reduction ratios match well with the statistical theory. It is implied that our
optimization preserves the uncorrelation among the speckle patterns, and the advantages of TM is achieved without sacriﬁce.
We also measure the image contrast by displaying sinusoidal pattern hologram as shown in Fig. 3f. The Michelson contrast
(Imax − Imin)(cid:14)(Imax + Imin) is improved from [0.83, 0.75, 0.73] to [0.91, 0.84, 0.82] for [R, G, B] color channels, where Imax
and Imin are the maximum and the minimum intensities. See Supplementary Information for additional 2D experimental results.

Realization of realistic 3D holographic near-eye displays
Since our realization overcomes the fundamental challenge for high-quality true 3D holography, it can be applied in various
holographic applications. Here, we show an application to the holographic near-eye displays, and demonstrate the proposed
method can provide not only speckle-free, high-contrast but also realistic focus cues and natural parallax. We use RGBD data
as input and set the number of depth layers N = 32, where the distances for nearest and farthest are 4.0 diopter (D) and 0.0D.
The depth distortion from chromatic aberration is experimentally corrected by arranging depth range and each color’s FOV.
Figure 4a shows some examples of the experimentally captured focal images where the top insets denote the focal depth of
the camera. In the same manner of the 2D case, the random binary holography supports speckle-free imagery but its image
contrast is low due to the binarization noise. On the other hand, the proposed B-SGD achieves high-contrast results without
sacriﬁcing focus cues, occlusion, spatial resolution. Since the random phase fulﬁlls the entire eyebox and provides the highest
axial resolution, signiﬁcant 3D focus and defocus effects are observed. Fig. 4b shows comparisons of the shape of focus and
blur among the target, our experimental results, and simulated smooth phase holography. Note that the target is calculated from
the incoherent transfer function to reﬂect the 3D focus cues of real world (see Methods). The experimental photographs show
that the proposed B-SGD successfully projects 3D space, including focus and defocus scenes, matching the incoherent real
world at all depths. To emphasize the signiﬁcance of our work, we simulate smooth phase holography that encodes phase of
target planes follows smooth distribution instead of random. Here, we simulate the ideal case where the complex amplitude
is perfectly represented by amplitude encoding and the hologram is reconstructed through perfect propagation model (see
Discussion). Although the ideal simulation shows speckle-free results at the focused plane, it fails to provide natural and

3/15

realistic focus cues compared to the incoherent 3D target. More results of continuous focal-sweep video is available from
Supplementary Video 2. The full-color synchronized 50 Hz video is available from Supplementary Video 3, which supports the
capability of dynamic projection of our system.

Finally, beyond the comparison with the computed virtual 3D scene, we compare with the real objects to show the
implementation of the most realistic 3D holographic projection. We convert our VR prototype to the AR type by placing an
additional beam splitter between the eyepiece lens and camera lens (see Supplementary Information). Two real objects are
placed on the 3.3D (bird) and 1.0D (cat), and the target images are achieved using the built AR prototype. Here, we capture two
target images focusing on each object and digitally synthesize the target RGBD data. The aperture stop of the C-mount lens is
set at about 3.3 mm, considering that the eyebox of our holographic system is 3.9 mm × 2.5 mm. Figure 5a is the AR result as
changing the camera focal state to each object. The result conﬁrms that our true 3D holography provides natural and realistic
focus cues that correspond to real objects. In addition, since our system truly reconstructs the 3D objects, realistic parallax is
also provided, as shown in Fig. 5b. Here, the parallax results are captured by a mobile phone whose aperture diameter is 3 mm,
where the white dot lines represent identical FOV. More results for the focal-sweep video and the parallax video of the AR
experiments are available in Supplementary Videos 4 and 5.

Discussion

Here, we brieﬂy discuss the importance of the random phase distribution in 3D holography through comparison with the smooth
phase (SP) holography. Recently, variety of works such as double-phase5, 18, Wirtinger holography15, and SGD optimization6
encode the CGH following the smooth distribution to reduce speckle. The methods have a common goal to represent the
complex amplitude using phase-only CGH. Rather than comparing with all the cases, we select amplitude hologram with SP
as a representative method since it can completely express the complex amplitude. To avoid any difference from Fourier or
Fresnel hologram type, we simulate the SP holography in the Fourier type. While our random phase-based method shows a
natural focal blur suitable for each depth, SP holography provides a large depth-of-ﬁeld and almost all-in-focused 3D scenes(see
Supplementary Information). In addition, the shape of the blur for SP is a diffraction pattern determined by the spatial frequency
of the amplitude. It is inconsistent with the real world, where the point spread function is not correlated with spatial frequency
of the texture. Also, almost energy is concentrated at the DC for SP holography, so the effective Fourier spectrum is much
smaller than the SLM supporting diffraction region. If the observer’s eye pupil deviates from the DC, the entire image cannot
be observed, and only the high-frequency component of amplitude (edge) is perceived. Thus, parallax cannot be provided by
SP holography.

The reproducibility of the speckle-free holographic displays is an important issue due to the sensitiveness of the coherent
imaging. Peng et al. and Chakravarthula et al. deal with the speckle noise generated in the mismatch between the ideal and
the actual wave propagation and summarizing the difﬁculty in reproduction for several SP holographic displays6, 32. The
reproducibility depends on the strategy chosen to alleviate the speckle noise. SP holography reduces the speckle by equalizing
the phase between adjacent reconstructed points so that only constructive interference occurs. However, it is susceptible to
experimentally generated phase disturbing noise, which leads to unwanted destructive interference. Thus, accurate phase
compensation (sub-wavelength level) is required like the camera-in-the-loop technique, which also has a limitation to be
repeated when the optical system, camera, or target image suffers any changes. On the other side, we adopt statistical reduction
by averaging the uncorrelated speckle patterns through the time domain. Even if the phase disturbing random noise is added,
each reconstructed point still follows the random distribution, and the speckle is removed. Hence we do not need any additional
object phase compensation, and we achieve the successful speckle reduction in every experimental reconstruction. We believe
our speckle reduction strategy is a more suitable approach considering the commercialization of holography in the next
generation.

Recently, dynamic computer-generated holography (DCGH) which seems similar to our works is proposed33. The main
difference is that our B-SGD optimizes a binary hologram at once and repeats the whole process m times for TM, but DCGH
optimizes all the m holograms at once considering dependency among the binary holograms. From the statistical speckle
m is achieved when the reconstructed intensity follows
theory, the successful speckle reduction that reaches to the ratio of 1/
identical distribution. If each intensity is designed to follow some different distribution, then the speckle reduction ratio would
be reduced. Thus, we believe that our approach that repeats frame-wise optimization to make every individual intensity proﬁle
following identical distribution is more appropriate to apply the TM for speckle reduction.

√

There are some issues for true 3D holography, which will be valuable topics for future research. First, since we take TM to
reduce the speckle noise, a proportionally increased computational burden is an remaining issue for real-time implementation.
We believe it will be resolved in the near future with the rapidly developing computational holographic works such as complex
amplitude optimization34, and the deep-learning hologram generation5, 6, 35–37. Note that the computing cost for optimizing
a single B-SGD hologram has almost similar cost for a conventional single 8-bit phase-only SGD hologram. Second, the
limited space-bandwidth product is a remaining challenge. Several space-bandwidth product extending approaches such as

4/15

beam steering with eye-tracking38, structured illumination with TM20, and placing photon sieve39, 40 would be solutions to
mitigate the issue. Third, an RGBD image shows a 3D scene from a viewpoint, so it does not have information about the object
occluded at the current viewpoint. Although we start from a single RGBD image considering versatility and data bandwidth for
near-eye displays, it is not necessary as we demonstrate in independent multi-plane projections. Creating the accurate target
focal stack from the set of RGBD images or light-ﬁeld data set taken from multiple viewpoints can solve the issue. Finally, the
ability to implement the high-contrast, speckle-free, true 3D holography beneﬁts not only for holographic displays in VR and
AR but also for hologram-based 3D printing, lithography, and metasurfaces. We believe that our research will be a turning
point in holography for practical utilization in various applications beyond the current academic research.

Methods

Space conversion from sRGB to linear
Since holography reconstructs light without any gamma correction, preprocessing for target intensity is required for the input
sRGB images to be perceived correctly by humans. The sRGB to linear conversion relationship is given by

Ilin = 1

12.92 IsRGB

Ilin =

(cid:16) IsRGB+0.055
1.055

(cid:17)2.4

.

0 ≤ IsRGB ≤ 0.04045

0.04045 < IsRGB ≤ 1

(1)

In our CGH calculation procedure, we ﬁrst convert the input sRGB intensity image to the linear space intensity and sequentially
Ilin ≈ (IsRGB)1.1. The similarity between amplitude in linear space and intensity in
achieve the linear space amplitude Alin =
sRGB space guarantees optimal perceived image for human observers by optimizing the amplitude in linear space6.

√

Generating target focal scenes for true 3D holography
Our optimization is designed to ﬁnd optimal binary hologram with minimal amplitude loss compared to the target 3D amplitudes.
Thus, it is crucial to generate an optically accurate 3D target for realistic and crosstalk-free implementations. In this paper, we
demonstrate two types of holographic systems that project an RGBD data and multiple independent images. From the RGBD
data, we generate a target focal stack from spatially incoherent wave propagation to reﬂect the focus cues in nature and achieve
a realistic 3D scene. The incoherently propagated intensity is given by

(cid:90)(cid:90)

˜Tz [I] =

F [I(x, y)] Hi( fx, fy)ei2π( fxx+ fyy)zd fxd fy,

(2)

where F is Fourier transform, fx, fy are spatial frequencies, z is propagation distance, and Hi is the incoherent free-space
propagation transfer function. Using the relationship between incoherent and coherent transfer functions, Hi can be described
by

Hi = Hc (cid:63) Hc

Hc( fx, fy) =

(cid:40)

(cid:113)

ei 2π

λ

1−(λ fx)2−(λ fy)2

z,

(cid:113)

0

2 < 1
λ ,

2 + fy
fx
otherwise

(3)

where (cid:63) denotes auto-correlation, λ is wavelength, and Hc is the coherent transfer function that widely used for angular-spectrum
method41. Then, the target focal 3D scene is calculated by sum of the incoherently transferred intensities at all depths with
consideration of occlusion:

IT
n = ∑
k∈N

˜T∆zk,n

(cid:2)Ix∈xk

(cid:3) Mk,n.

( f or RGBD)

(4)

Here, n is index of depth layer (n = 1, 2, . . . , N), I is a given RGB image, xk is the set of object points at the k-th depth layer,
∆zk,n = |zn − zk|, and Mk,z is the occlusion mask.

For the second type of input data (multiple independent images In), the target set directly corresponds to the input images.
One additional step is to match the energies of all depth images according to each color channel to satisfy the energy conversation

5/15

principle. To match the energies of all depth layers, we divide the intensity at each depth by its energy (the sum of the intensities
for all x) and multiply with the average of all the layer energies. The target intensities are given by

IT
n =





1
N

∑
∀x
In

∑
n∈N
∑
∀x



In

 In.

( f or Multiplane)

(5)

Binary CGHs optimization
The summarized binary CGH optimization procedure is visualized in Supplementary Information. We ﬁrst initialize binary
hologram with a designed holographic reconstruction system. The Fourier type holography is adopted where a single object
point is reconstructed by the interference of most pixels of the SLM, which guarantees more possibility to ﬁnd optimal
hologram. The initial object phase is set by 2π range of random phase for maximum axial resolution. From the input data and
the initial random phase, the initial complex amplitude at the SLM plane is achieved through coherent transfer function Hc and
Fourier transform F. Next, an amplitude type of Fourier hologram Hamp is generated from the complex amplitude using the
single-sideband encoding method, which represents the complex amplitude using an amplitude-only SLM42. It is converted to
the initial binary hologram Hbi by the forward binary operator, where we use the hard-clipping method B f orward(x) = sign(x).
Then, the focal amplitude stack for all depth layers An(n ∈ N) are numerically reconstructed from the initial binary hologram.
After the initialization step, we calculate amplitude loss for all depth layers and summate those losses for the total 3D
loss. The total volumetric loss enforces our optimization to minimize amplitude difference not only for focused but also
for the blurred scenes in all depths. To achieve the optimized binary hologram, we set the problem as ﬁnding the optimum
continuous amplitude hologram (Hamp) resulting in minimum loss after binarization. This indirect problem setting allows for an
incremental hologram update during gradient-based optimization. Our amplitude optimization can be summarized by solving
the following optimization problem.

minimize
Hamp

L

∑
n∈N

∑
∀x

(cid:20)
enAn,

(cid:113)

(cid:21)

,

IT
n

(6)

where L is the loss function and en is an energy scale factor given by en =

IT
n
|An|2 . We set the L as the l2 mean square error
(MSE) considering that the MSE is sensitive with the difference of mean value rather than variance, which is appropriate to
reduce the background noise of binary hologram. To solve the equation (6), We utilize the iterative optimization based on SGD
designed for binary system, termed by B-SGD. Our update rules in iteration k (k = 1, 2, . . . , K) with learning rate α are

∑
∀x

∑
∀x

(cid:118)
(cid:117)
(cid:117)
(cid:116)

amp = Hk−1
Hk

amp − α

(cid:18) ∂ L

∂ Hamp

(cid:19)
,

(7)

where K is set as 200 in this paper. Unlike the previous phase-only SGD works, the backward gradient of the loss cannot be
obtained directly because the binary operation during the forward propagation is non-diffentiable. Inspired by the binarized
neural networks research43, we adopt the straight-through estimator, which assumes the backward binary operator using
a similar shape of differentiable function. We choose the hard hyperbolic tangent function for Bbackward(x) = Htanh(x) =
max(−1, min(1, x)) as the estimated backward binary operator. After ﬁnishing the optimization process, the output optimized
binary hologram is acquired through a forward binarization to the optimized amplitude hologram with the conversion of the -1
value to zero. The B-SGD approach has advantage for fast hologram computing with a graphic processing unit (GPU). Also,
the gradient of the loss function in equation (7) can be robustly achieved via autograd of Pytorch without the need to develop
gradient manually.

Speckle analysis for random phase holography
We show the theoretical speckle analysis to ensure the fundamental challenge for random phase holography to be speckle-free.
Here, we consider the Fourier holography system consisted of an SLM and a Fourier lens. The SLM has nx × ny pixels whose
pitch correspond to dx × dy and the focal length of Fourier lens is f . At the Fourier plane, the intensity distribution of a
reconstructed point followed sinc2 function due to the ﬁnite size of the SLM (or ﬁnite numerical aperture):

I = I0 sinc 2

(cid:18) nxdx
λ f

(cid:19)

x

sinc 2

(cid:18) nydy
λ f

(cid:19)

y

.

(8)

6/15

By assuming that the main lobe only affects the interference with the adjacent points, the 2D size of the main lobe is given by

Alobe =

4λ 2 f 2
nxnydxdy

.

(9)

From the sampling theorem, the physical interval between adjacent points is (cid:0) f λ (cid:14)nxdx, f λ (cid:14)nydy
for each sampled point is calculated by

(cid:1), and the 2D area allocated

Ainterval =

λ 2 f 2
nxnydxdy

.

(10)

Then, the overlapped ratio by the sinc2 mainlobe corresponds to r = Alobe
= 4, which is constant rather than function of the
Ainterval
parameters. It implies that no matter how CGH is optimized and reproduced, there will be interference between adjacent pixels.
When the object phase is uniformly distributed on (-π,π), the speckle phenomena can be statistically analyzed through the
number of overlapped phasors. We assume the length of phasors from adjacent points are identical to a to simplify statistical
formulas, where it is supported by the fact that neighboring pixels in general images have similar intensity. From the ﬁrst-order
statistical properties of the speckle10, the probability density function of intensity with the sum of ﬁnite number r phasors is
given by

p(I) = 2π 2

2π
(cid:90)

0

ρJr

0 (2πaρ)J0

(cid:16)

2π

√

Iρ

(cid:17)

dρ,

(11)

where J0 is the Bessel function of the ﬁrst kind. Then, we obtain speckle contrast C by sequentially calculating expectation
value and variance:

E [I] = a2, σ 2 = (cid:0)1 − 1
r

(cid:1) a4,

C = σ

E[I] =

(cid:113)

1 − 1
r .

(12)

Note that the shape of speckle contrast increases rapidly from zero to one in the small number of r, and in our case with r = 4, it
becomes a high value of 0.87. Although many parameters affect the speckle contrast, including ﬁll factor of SLM, intensity
proﬁle, and high-order lobes, the results sufﬁciently show the inevitable speckle noise from the random phase and justify the
need of TM. Note that the analysis is derived in the linear space.

Speckle reduction through TM
When the object phase follows the random phase distribution, the random constructive and destructive interference among
adjacent points results in inevitable speckle. One available approach for speckle reduction is to adopt the TM technique
following the statistical speckle theory10, where the speckle variance is decreased by averaging the independent speckle patterns
during the observing framerate. The independent speckle patterns are achieved by changing the initial object phase when
calculating CGHs to follow other random phase sets. The accumulated intensity has reduced speckle contrast as Cm = C1√
m ,
where m (m = 1, 2, . . . , M) is the number of TM. We choose the M = 24 to avoid ﬂickering observation by considering the
human visual system. Using the off-the-shelf binary SLM which supports 3600 Hz in WUXGA resolution, we build the 50 Hz
video projection prototypes in full-color. Here, the 50 Hz is given by dividing 3600 Hz into 3 colors and 24 TM. The speckle
contrast is reduced by 4.9 times (

24) compared with the reconstructed scene of a single-frame random phase hologram.

√

Camera acquisition method
To capture the experimental results in this paper, we mainly use a machine vision CCD sensor (FLIR; GS3-U3-91S6C) adapted
with a C-mount lens (Nikon; 60 mm f/2.8) for the multiplane projection and with another C-mount lens (Navitar; 35 mm f/1.4)
for near-eye VR system. The CCD sensor is controlled by the manufacturer providing GUI software (Spinview). Speciﬁcally,
the gain and the sensor’s black level are set to zero, and shutter speed is set to 20 ms. Sensor gamma is set to (1/2.2) to capture
the sRGB intensities from the linear space intensities. Focal sweep videos (Supplementary Videos 1, 2, and 4) are recorded using
the CCD camera. A mobile phone (Apple; iPhone pro 11) is used to achieve the high-framerate movie (Supplementary Video 3)

7/15

and AR parallax results (Fig. 5b and Supplementary Video 5). Here, the telephoto lens (52 mm equivalent, f/2) is used whose
actual focal length is 6 mm and the diameter of the aperture is 3 mm. The sRGB results are obtained automatically through
the image processor built in the mobile phone. The white balance for all color results is manually matched by controlling the
currency of the ﬁber-coupled laser diodes before capturing the experimental results.

Data availability

The data to support the results within this paper is available from the corresponding author on reasonable request.

References

1. Poon, T.-C. Digital Holography and Three-dimensional Display: Principles and Applications (Springer Science & Business

Media, 2006).

2. Matsushima, K. Computer-generated holograms for three-dimensional surface objects with shade and texture. Appl. Opt.

44, 4607–4614 (2005).

3. Yu, H., Lee, K., Park, J. & Park, Y. Ultrahigh-deﬁnition dynamic 3d holographic display by active control of volume

speckle ﬁelds. Nat. Photonics 11, 186 (2017).

4. Chlipala, M. & Kozacki, T. Color led dmd holographic display with high resolution across large depth. Opt. Lett. 44,

4255–4258 (2019).

5. Shi, L., Li, B., Kim, C., Kellnhofer, P. & Matusik, W. Towards real-time photorealistic 3d holography with deep neural

networks. Nature 591, 234–239 (2021).

6. Peng, Y., Choi, S., Padmanaban, N. & Wetzstein, G. Neural holography with camera-in-the-loop training. ACM Trans.

Graph. 39, 185 (2020).

7. Makey, G. et al. Breaking crosstalk limits to dynamic holography using orthogonality of high-dimensional random vectors.

Nat. Photonics 13, 251–256 (2019).

8. Zhang, J., Pégard, N., Zhong, J., Adesnik, H. & Waller, L. 3d computer-generated holography by non-convex optimization.

Optica 4, 1306–1313 (2017).

9. Chang, C., Bang, K., Wetzstein, G., Lee, B. & Gao, L. Toward the next-generation vr/ar optics: a review of holographic

near-eye displays from a human-centric perspective. Optica 7, 1563–1578 (2020).

10. Goodman, J. W. Speckle phenomena in optics: theory and applications (Roberts and Company Publishers, 2007).

11. Kozacki, T. & Chlipala, M. Color holographic display with white light led source and single phase only slm. Opt. Express

24, 2189–2199 (2016).

12. Lee, S. et al. Light source optimization for partially coherent holographic displays with consideration of speckle contrast,

resolution, and depth of ﬁeld. Sci. Rep. 10, 18832 (2020).

13. Mori, Y., Fukuoka, T. & Nomura, T. Speckle reduction in holographic projection by random pixel separation with time

multiplexing. Appl. Opt. 53, 8182–8188 (2014).

14. Takaki, Y. & Yokouchi, M. Speckle-free and grayscale hologram reconstruction using time-multiplexing technique. Opt.

Express 19, 7567–7579 (2011).

15. Chakravarthula, P., Peng, Y., Kollin, J., Fuchs, H. & Heide, F. Wirtinger holography for near-eye displays. ACM Trans.

Graph. 38, 213 (2019).

16. Choi, S., Kim, J., Peng, Y. & Wetzstein, G. Optimizing image quality for holographic near-eye displays with michelson

holography. Optica 8, 143–146 (2021).

17. An, J. et al. Slim-panel holographic video display. Nat. Commun. 11, 5568 (2020).

18. Maimone, A., Georgiou, A. & Kollin, J. S. Holographic near-eye displays for virtual and augmented reality. ACM Trans.

Graph. 36, 85 (2017).

19. Chang, C., Cui, W., Park, J. & Gao, L. Computational holographic maxwellian near-eye display with an expanded eyebox.

Sci. Rep. 9, 18749 (2019).

20. Lee, B. et al. Wide-angle speckleless dmd holographic display using structured illumination with temporal multiplexing.

Opt. Lett. 45, 2148–2151 (2020).

8/15

21. Pandey, N. & Hennelly, B. Quantization noise and its reduction in lensless fourier digital holography. Appl. Opt. 50,

B58–B70 (2011).

22. Buckley, E. Computer-generated phase-only holograms for real-time image display. Advanced Holography-Metrology and

Imaging 277–304 (2011).

23. Buckley, E. Holographic laser projection. J. Disp. Technol. 7, 135–140 (2011).

24. Liu, J.-P., Yu, C.-Q. & Tsang, P. W. Enhanced direct binary search algorithm for binary computer-generated fresnel

holograms. Appl. Opt. 58, 3735–3741 (2019).

25. Seldowitz, M. A., Allebach, J. P. & Sweeney, D. W. Synthesis of digital holograms by direct binary search. Appl. Opt. 26,

2788–2798 (1987).

26. Yang, G., Jiao, S., Liu, J.-P., Lei, T. & Yuan, X. Error diffusion method with optimized weighting coefﬁcients for binary

hologram generation. Appl. Opt. 58, 5547–5555 (2019).

27. Buckley, E. Real-time error diffusion for signal-to-noise ratio improvement in a holographic projection system. J. Disp.

Technol. 7, 70–76 (2011).

28. Masuda, K. et al. Improvement of image quality of 3d display by using optimized binary phase modulation and intensity

accumulation. J. Disp. Technol. 12, 472–477 (2016).

29. Kim, H. et al. Anamorphic optical transformation of an amplitude spatial light modulator to a complex spatial light

modulator with square pixels. Appl. Opt. 53, G139–G146 (2014).

30. Sintel. https://sintel-depth.csail.mit.edu/.

31. Bigbuckbunny. http://peach.blender.org/.

32. Chakravarthula, P., Tseng, E., Srivastava, T., Fuchs, H. & Heide, F. Learned hardware-in-the-loop phase retrieval for

holographic near-eye displays. ACM Trans. on Graph. (TOG) 39, 1–18 (2020).

33. Curtis, V. R., Caira, N. W., Xu, J., Sata, A. G. & Pégard, N. C. Dcgh: Dynamic computer generated holography for
speckle-free, high ﬁdelity 3d displays. In 2021 IEEE Virtual Reality and 3D User Interfaces (VR), 1–9 (IEEE, 2021).

34. Chen, C. et al. Multi-depth hologram generation using stochastic gradient descent algorithm with complex loss function.

Opt. Express 29, 15089–15103 (2021).

35. Horisaki, R., Takagi, R. & Tanida, J. Deep-learning-generated holography. Appl. Opt. 57, 3859–3863 (2018).

36. Lee, J. et al. Deep neural network for multi-depth hologram generation and its training strategy. Opt. Express 28,

27137–27154 (2020).

37. Eybposh, M. H., Caira, N. W., Atisa, M., Chakravarthula, P. & Pégard, N. C. Deepcgh: 3d computer-generated holography

using deep learning. Opt. Express 28, 26636–26650 (2020).

38. Jang, C., Bang, K., Li, G. & Lee, B. Holographic near-eye display with expanded eye-box. ACM Trans. Graph. 37, 195

(2018).

39. Park, J., Lee, K. & Park, Y. Ultrathin wide-angle large-area digital 3d holographic display using a non-periodic photon

sieve. Nat. Commun. 10, 1304 (2019).

40. Kuo, G., Waller, L., Ng, R. & Maimone, A. High resolution étendue expansion for holographic displays. ACM Trans.

Graph. 39, 66 (2020).

41. Goodman, J. W. Introduction to Fourier Optics (Roberts and Company Publishers, 2017).

42. Wyrowski, F. Diffraction efﬁciency of analog and quantized digital amplitude holograms: analysis and manipulation. JOSA

A 7, 383–393 (1990).

43. Courbariaux, M., Hubara, I., Soudry, D., El-Yaniv, R. & Bengio, Y. Binarized neural networks: Training deep neural

networks with weights and activations constrained to+ 1 or-1. arXiv preprint arXiv:1602.02830 (2016).

44. Kim, C., Zimmer, H., Pritch, Y., Sorkine-Hornung, A. & Gross, M. H. Scene reconstruction from high spatio-angular

resolution light ﬁelds. ACM Trans. Graph. 32, 73–1 (2013).

45. Sheikh, H. R., Sabir, M. F. & Bovik, A. C. A statistical evaluation of recent full reference image quality assessment

algorithms. IEEE Trans. on image processing 15, 3440–3451 (2006).

9/15

Acknowledgements

This work was supported by Institute for Information & Communications Technology Promotion (IITP) grant funded by the
Korea government (MSIT) (No. 2017-0-00787, Development of vision assistant HMD and contents for the legally blind and
low visions).

Author contributions statement

B.L. conceived the idea, realized the proposed method, built optical systems, conducted the experiment, and wrote the
manuscript. D.K. executed the experiment for evaluation, analyzed the results, and wrote the manuscript with B.L. S.L.
analyzed the results, and veriﬁed the optimization algorithm. C.C. performed and veriﬁed the optimization algorithm with the
optical simulation. B.L. supervised the project. All of the authors discussed the results and reviewed the manuscript.

Additional information

Competing interests The authors declare no competing interests.

Supplementary information

10/15

Figure 1. Demonstration and performance evaluation for crosstalk-free 3D projection. a. Scheme of Fourier
holographic projection, where ﬁve independent images are apart from 15 mm interval. b. Simulated comparison results of ﬁve
CGH methods, including superposition within phase hologram (superposition), iterative Fourier transform algorithm (IFTA),
non-convex optimization (NOVO), superposition within binary hologram (random), and binary-SGD (B-SGD). The binary
holographic methods only adopt 24 TM considering dynamic projection. c. Numerical propagation results as focusing on each
target depth layers. Only B-SGD shows crosstalk-free projection with high-contrast and low-speckle. d. Experiemental results
of proposed B-SGD. e. Intermediate planes of B-SGD method. Source images by Kim, C. et al.44, Sheikh, H.R. et al.45, and ©
copyright 2008, Blender Foundation | www.bigbuckbunny.org.

11/15

Figure 2. Tomographic 3D projection a. Target 3D model (Synapse), purchased from Free 3D, All Rights Reserved.
Eleven cross-section images are taken by using the 3D rendering software (’Autodesk Maya’). b. Experimental results of the
tomographic projection. The results are captured by shifting the camera from 0 mm to 150 mm in the z-axis. White lines denote
length of 1 mm.

12/15

Figure 3. Demonstration and performance evaluation of true 3D holography in 2D near-eye displays. a. Scheme of
Fourier amplitude holographic display prototype. The ﬁgure visualizes SLM illuminating light and diffracted light from the
center pixel of SLM (dot line). Only red wavelength is depicted for simplicity. b. Simulation results to assess three binary CGH
methods, including superposition as updating random phase (random), Gearchberg-Saxton (GS), binary-SGD (B-SGD). c.
(left) Simulation and (right) experimental results. All results are obtained with 24 TM. The bottom insets are PSNR and SSIM.
d. Experimentally measured PSNR and SSIM according to number of multiplexing e. Experimentally measured speckle
contrast and its reduction ratio. f. Experimental image contrast comparisons using the sinusoidal hologram and zoom-in region
of (c). Source image by © copyright 2008, Blender Foundation | www.bigbuckbunny.org.

13/15

Figure 4. Experimental results for 3D scenes whose depth range extends between 0.0D to 4.0D. a. Three example focal
sweep scenes when the camera is focusing on 0.5D, 2.3D, 4.0D without/with optimization. b. Comparisons with incoherent 3D
target and simulated smooth phase holography. Focal sweep results are summarized in right ﬁgures where focused images are
noted as dot boxes. Our prototype shows realistic focus cues well match the 3D target. On the other hands, smooth phase fails
to provide accurate focus cues. The source data by © copyright Blender Foundation | durian.blender.org.

14/15

Figure 5. AR demonstration of true 3D holography featuring realistic focus cues and parallax The real objects are
placed on the 3.3D (bird) and 1.0D (cat). a. Focal sweep results of our AR prototype, where the hologram shows realistic focus
cues that of the real object. b. Parallax results by laterally shifting the camera. Bottom insets are the shifted distance of the
camera, and dot lines indicate the identical FOV in both results. The hologram and real objects are captured simultaneously.

15/15

