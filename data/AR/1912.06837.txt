9
1
0
2
c
e
D
4
1

]

O
R
.
s
c
[

1
v
7
3
8
6
0
.
2
1
9
1
:
v
i
X
r
a

FOLLOW PEDRO! AN INFRARED-BASED PERSON-FOLLOWER
USING NONLINEAR OPTIMIZATION

A PREPRINT

Pedro A. Peña∗
Robotics
Toyota Research Institute
Cambridge, MA. 02139
pedro.pena.ctr@tri.global

Toffee Albina
Robotics
Toyota Research Institute
Cambridge, MA. 02139
toffee.albina@tri.global

December 17, 2019

ABSTRACT

We used ROS2 as a platform to conduct AI research for developing a Follow-Me capability as a proof-
of-concept on a wheeled robot, demonstrating that AI research is possible in the ROS2 framework.
We developed a complete system that uses perception and navigation components based on a sensor
suite of ﬁsheye cameras, lidar, and IMU running on an ARM64 Embedded Linux platform that runs
ROS2 natively. The perception package detects AR markers and/or IR beacons to track a person.
The tracker uses AI algorithms such as particle ﬁlters and nonlinear optimization to extract the SE(3)
information of the 2D feature.

Keywords Human-robot interaction · ROS2 · Robotics

1

Introduction

We propose a real-time integrated system that utilizes minimal amount of computational power that can enable robots to
follow a person through an AR marker or IR beacon. Although a plethora of research has been done on this topic, they
either rely on machine learning [1, 2] or human behavior models [3, 4, 5, 6] and computationally expensive, i.e., high
spatial and temporal complexity, algorithms [7, 8, 9, 10] in which data and high-end hardware for computational power
is required. This paper is meant for current ROS1 research teams, researchers looking for a platform for AI/Robotics
research, and researchers working on embedded systems that can beneﬁt from inexpensive hardware to create an
integrated system that is able to follow a person. Our system utilizes an inexpensive ARM64 processor that can run
Linux and ROS2 natively and is able to detect and follow a person reliably. In section 2, we will discuss the algorithm
used to follow a person given a detection. Then in section 3, we will explain how a marker is detected using an AR
marker, and in section 4 we explain the IR beacon detection algorithm that utilizes a nonlinear optimization to infer
the 3D pose from a 2D triangle on an image. We will then show how our method was used on a Turtlebot platform to
follow a person and a robot in section 5.

2 Follower

The Follow-Me algorithm consists of detectors and a follower component. For this research, we developed two detection
algorithms:

• AR Marker

• IR Beacon with active 3 infrared transmitters in a triangle conﬁguration on black

∗https://www.pedroapena.com

 
 
 
 
 
 
Follow Pedro! An Infrared-based Person-Follower using Nonlinear Optimization

A PREPRINT

Figure 1: The graphs show the comparison of ﬁsheye space vs Euclidean space. The top left graph shows bearing
data ﬁtting for the rear camera and the top right graph shows bearing data ﬁtting for the front camera. The bottom
graph shows the range data ﬁtting for the front camera. Note: the range data ﬁtting was only done for the front camera
because the robot does not move towards the robot from the rear (i.e. the robot will rotate towards the person). The
range of the data is ~(−π, π)

Both of these detectors output a range and bearing in the robot’s base frame enabling the Follow-Me implementation
to be modular. In this way we can develop detectors and followers separately from each other. The follower uses a
PID-controller to get within a speciﬁed radius of a person. Consequently, the velocity of the robot is proportional to the
distance from the person to the robot. Therefore as the robot gets close to the person, it will slow down until it has
reached its equilibrium. In order to reach its target, it uses relative odometry where it does not depend on a global frame
of reference. When we receive a range and bearing from a detector, i.e., a detection of the human the robot is following,
we verify that the range and bearing (i.e. deﬁned as vector ξrb) of the person the robot is following is greater than some
value (cid:15)rb. If this is the case, the robot will move towards the position of the human. As stated before, we use a PID
controller where the error is the range and bearing of the person. Since we want to avoid the robot bumping into the
human it is following, we subtract a predetermined distance vector, d, from the range so that the robot is always at a
distance d from the person. When the range and bearing are below some threshold (cid:15)rb, the robot will stop moving. The
algorithm is as follows:

F ollow =

(cid:40)

GoT oHuman(ξrb − d),
Stop(),

if (cid:107)ξrb − d(cid:107) ≥ (cid:15)rb
otherwise

(1)

3 AR-Marker Detector

The marker detector uses the ArUco library 2 to ﬁnd the 3D pose of an AR marker tag. To utilize ﬁsheye cameras, for
the advantage of the ﬁeld of view, the 3D pose given by ArUco may not be correct because of distortions of the camera
in the border of the lens. Based on empirical observations, there is a mapping between ﬁsheye space and Euclidean
space. The camera is sampled with the marker in different conﬁgurations and a transformation from ﬁsheye position to
a Euclidean position is ﬁtted with a quadratic equation; the graphs in ﬁgure 1 show the relationship between these two
spaces for two different cameras.The sampling of conﬁgurations can be done by recording the pose of the marker and
the output of ArUco; this needs to be done for every camera. After we learn this map, the range and bearing is given in
the robot’s base frame.

2https://docs.opencv.org/trunk/d5/dae/tutorial_aruco_detection.html

2

Follow Pedro! An Infrared-based Person-Follower using Nonlinear Optimization

A PREPRINT

Figure 2: The right image shows the perception of a 3D printed black puck containing three IR transmitters in a triangle
formation from a ﬁsheye camera ﬁtted with an IR ﬁlter. The left image shows a particle ﬁlter tracking the IR beacon.

4

IR-Beacon Detector

For this detector, an IR ﬁlter is ﬁtted to the lenses of the ﬁsheye cameras to solely perceive the IR light. A 3D printed
black puck containing three IR transmitters in a triangle formation is attached to the leader; ﬁgure 2 shows a perception
of the IR beacon by a ﬁsheye camera. The input of the algorithm is the camera image, and we need to perceive three
bright blobs that form a triangle on a black background. The algorithm proceeds as follows:

• Threshold and get only the pixel values above the threshold. This threshold function will give us the brightest

pixels.

• Get the contours in the image and approximate the contours with polynomials.
• Find circles that bound these polynomials - these are the potential IR beacons.
• We then do a permutation of tuples of three circles to form a triangle. The triangles that satisfy the following

constraints become the candidate triangles for the multivariate Newton’s method:

– The difference of the side between the ﬁrst and second beacon and the side between the ﬁrst and third

beacon need to be less than a side threshold

– The radius of the ﬁrst, second, and third beacon needs to be below a threshold
– The lengths of the sides needs to be below a threshold
– The pixel value midway between the triangle sides needs to be above a pixel threshold
– The pixel value in the center of the triangle needs to be above a threshold

The triangles that pass these constraints can be used for the multivariate Newton’s method. The multivariate Newton’s
method is used to solve the roots of nonlinear equations, and in our case, we are using it to ﬁnd the P3P correspondence
of the triangle in image space to Euclidean space with the equation:

f (xn) = u = F · T · x,
(2)
where u is the image coordinates in pixel space, F is the camera matrix, T is the transformation with respect to the
optical frame (this is what we are looking for), and x is the beacon pose in 3D space relative to a coordinate frame in
Euclidean space (we chose the center point of the triangle formed by the IR transmitters). The equation is formulated as
a difference equation where the steps are discrete:

f (xn)
f (cid:48)(xn)
where c is the initial condition. This equation iterates until the following constraint is satisﬁed: F (xn) − F (xn−1) ≤ (cid:15),
i.e., this means we have hit a ﬁxed point which directly translates to the roots of equation 2. It is important to note that
the state of T is SE(3) which makes the difference equation multivariate. Hence, the equation is:

F (x) = xn −

x(0) = c,

(3)

,

xn+1 = xn − J+ · f (xn),
(4)
where J+ represents the pseudoinverse of the Jacobian matrix. In order to smooth the output of the system and
compensate for any perception or numerical errors, the detector injects uncertainty into the system with a particle ﬁlter
to keep track of the IR beacon in Euclidean space. The motion model used for the prediction step is:

xn+1 = xn + u(t) + v(t),
(5)
where u(t) represents the control input of the robot, xn is particle n’s pose in 3D space and v(t) represents the velocity
of the IR beacon in world space. The mean particle pose is used as the output for the range and bearing. Figure 2 shows
the IR beacon tracked by the particle ﬁlter.

A video of an IR beacon in a triangle conﬁguration running the multivariate Newton’s method can be found here:

https://www.youtube.com/watch?v=qOWwjKRiL9o

3

Follow Pedro! An Infrared-based Person-Follower using Nonlinear Optimization

A PREPRINT

Figure 3: TurtlebotRex used for Follow-Me and built with a Kobuki base and two sets of Turtlebot 2 hardware stacked
vertically to better situate the cameras for detection. The top of the robot’s Orbbec Astra camera has two ﬁsheye
cameras, e.g., one facing front and another camera facing rear. The Bosch BNO055 IMU is on the bottom of the robot.
There is also a Garmin Lidar Lite V3HP by the bottom of the Orbbec Astra camera. All the sensors and algorithms are
powered by the ROCK64, an ARM64 processor.

5 Application

To evaluate the algorithm proposed in this paper, the follower and detectors were implemented on ROS2 using the
Turtlebot 2 hardware and software stack 3 so that we can communicate with the Kobuki base for motor control. Because
the height of Turtlebot 2 is short and the application requires detections of humans, we built a robot that is composed of
two Turtlebot 2 platforms stacked on top of each other to situate the cameras at a more proper height: TurtlebotRex. For
the camera system setup, the original Turtlebot 2 came with an Orbbec Astra Camera for depth and RGB data. The
Orbbec Astra Camera contained the following drawbacks:

• Low FPS depth stream, and
• Limited FOV(60 degrees horizontal).

To eliminate these drawbacks, two ﬁsheye cameras are used, one for the front view and back view, creating an almost
full view, omnidirectional, around the robot. The limitations of a ﬁsheye camera such as distortion are considered in the
detectors as discussed in sections 3 and 4. The depth sensor used for TurtlebotRex is a Garmin Lidar Lite V3HP, and an
IMU, Bosch BNO055, is also used to ﬁlter odometry. The processing unit is an ARM64 processor, ROCK64, which has
4 GB of memory and runs ROS2 Bouncy Bolson natively. Figure 3 shows how all the components are arranged on
TurtlebotRex and a system diagram is shown in ﬁgure 4.

A video of TurtlebotRex following a person with an AR marker can be found here:

https://www.youtube.com/watch?v=COBOlq15_DU

A video of TurtlebotRex following a robot with an AR marker can be found here:

A video of TurtlebotRex following a person with an IR beacon can be found here:

https://www.youtube.com/watch?v=KU3pCqkwUrE

https://www.youtube.com/watch?v=1ti0Bj0yDfI

6 Conclusion

In this paper, we show a Follow-Me application using ROS2 where a physical robot, TurtlebotRex, was used. The
Follow-Me application consists of modular components such as detectors, for perceptions of the follower, and a follower
algorithm that enables a robot to follow its target. One of the detectors, IR beacon detector, uses a nonlinear optimization
to correspond 2D features on an image of three IR beacons in a triangle conﬁguration to their 3D position in the world.
This application of robotics on ROS2 demonstrates that lightweight algorithms on inexpensive processors is possible
with the correct technologies enabling interesting interactions with robots and humans.

3https://github.com/ros2/turtlebot2_demo

4

Follow Pedro! An Infrared-based Person-Follower using Nonlinear Optimization

A PREPRINT

Figure 4: A system diagram of the Follow-Me application.

References

[1] Yu Fan Chen, Michael Everett, Miao Liu, and Jonathan P How. Socially aware motion planning with deep
reinforcement learning. In 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),
pages 1343–1350. IEEE, 2017.

[2] Linzhuo Pang, Yunzhou Zhang, Sonya Coleman, and He Cao. Efﬁcient hybrid-supervised deep reinforcement

learning for person following robot. Journal of Intelligent & Robotic Systems, pages 1–14, 2019.

[3] Gonzalo Ferrer, Anais Garrell, and Alberto Sanfeliu. Robot companion: A social-force based approach with
human awareness-navigation in crowded environments. In 2013 IEEE/RSJ International Conference on Intelligent
Robots and Systems, pages 1688–1694. IEEE, 2013.

[4] Aniket Bera, Tanmay Randhavane, Rohan Prinja, and Dinesh Manocha. Sociosense: Robot navigation amongst
pedestrians with social and psychological constraints. In 2017 IEEE/RSJ International Conference on Intelligent
Robots and Systems (IROS), pages 7018–7025. IEEE, 2017.

[5] Tanmay Randhavane, Aniket Bera, Emily Kubin, Austin Wang, Kurt Gray, and Dinesh Manocha. Pedestrian
dominance modeling for socially-aware robot navigation. In 2019 International Conference on Robotics and
Automation (ICRA), pages 5621–5628. IEEE, 2019.

[6] Anais Garrell and Alberto Sanfeliu. Cooperative social robots to accompany groups of people. The International

Journal of Robotics Research, 31(13):1675–1701, 2012.

[7] Minkyu Kim, Miguel Arduengo, Nick Walker, Yuqian Jiang, Justin W Hart, Peter Stone, and Luis Sentis. An

architecture for person-following using active target search. arXiv preprint arXiv:1809.08793, 2018.

[8] Gigih Priyandoko, Choi Kah Wei, and Muhammad Sobirin Hendriyawan Achmad. Human following on ros

framework a mobile robot. Sinergi: Jurnal Teknik Mercu Buana, 22(2):77–82, 2018.

[9] Tsung-Han Tsai and Chia-Hsiang Yao. A real-time tracking algorithm for human following mobile robot. In 2018

International SoC Design Conference (ISOCC), pages 78–79. IEEE, 2018.

[10] Mark Tee Kit Tsun, Bee Lau, and Hudyjaya Siswoyo Jo. An improved indoor robot human-following navigation

model using depth camera, active ir marker and proximity sensors fusion. Robotics, 7(1):4, 2018.

5

