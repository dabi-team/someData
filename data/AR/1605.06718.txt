8
1
0
2

p
e
S
2
1

]
E
M

.
t
a
t
s
[

3
v
8
1
7
6
0
.
5
0
6
1
:
v
i
X
r
a

The De-Biased Whittle Likelihood

Adam M. Sykulski1, Soﬁa C. Olhede2, Jonathan M. Lilly3,
Arthur P. Guillaumin2 and Jeffrey J. Early3

Abstract

The Whittle likelihood is a widely used and computationally efﬁcient pseudo-likelihood. However, it
is known to produce biased parameter estimates for large classes of models. We propose a method for
de-biasing Whittle estimates for second-order stationary stochastic processes. The de-biased Whittle like-
lihood can be computed in the same O(n log n) operations as the standard approach. We demonstrate the
superior performance of the method in simulation studies and in application to a large-scale oceanographic
dataset, where in both cases the de-biased approach reduces bias by up to two orders of magnitude, achiev-
ing estimates that are close to exact maximum likelihood, at a fraction of the computational cost. We prove
−1/2, under weaker
that the method yields estimates that are consistent at an optimal convergence rate of n
assumptions than standard theory, where we do not require that the power spectral density is continuous in
frequency. We describe how the method can be easily combined with standard methods of bias reduction,
such as tapering and differencing, to further reduce bias in parameter estimates.

Keywords: Parameter estimation; Pseudo-likelihood; Periodogram; Aliasing; Blurring; Tapering; Dif-
ferencing.

1 Introduction

This paper introduces an improved computationally-efﬁcient method of estimating time series model pa-
rameters of second-order stationary processes. The standard approach is to maximize the exact time-domain
likelihood, which in general has computational efﬁciency of order n2 for regularly-spaced observations
(where n is the length of the observed time series) and produces estimates that are asymptotically efﬁcient,
converging at a rate of n−1/2. A second approach is the method of moments, which in general has a com-
putational efﬁciency of smaller order but with poorer statistical performance (Brockwell & Davis, 1991,
p.253), exhibiting both bias and often a higher variance. A third approach of approximating the exact likeli-
hood, often referred to as quasi-, pseudo-, or composite-likelihoods, is receiving much recent attention across
statistics, see e.g. Fan et al. (2014) and Guinness & Fuentes (2017). In time series analysis, such likelihood
approximations offer the possibility of considerable improvements in computational performance (usually
scaling as order n log n), with only small changes in statistical behaviour, see e.g. Dutta & Mondal (2015)
and Anitescu et al. (2016). Here we introduce a pseudo-likelihood that is based on the Whittle likelihood
(Whittle, 1953) which we will show offers dramatic decreases in bias and mean-squared error in applications,
yet with no signiﬁcant increase in computational cost, and no loss in consistency or rate of convergence. We
will refer to our pseudo-likelihood as the de-biased Whittle likelihood.

1 Data Science Institute / Department of Mathematics and Statistics, Lancaster University, UK (email: a.sykuslki@lancaster.ac.uk)
2 Department of Statistical Science, University College London, UK
3 NorthWest Research Associates, Redmond WA, USA

1

 
 
 
 
 
 
The Whittle likelihood of Whittle (1953) is a frequency-domain approximation to the exact likeli-
hood. This method is considered a standard method in parametric spectral analysis on account of its
order n log n computational efﬁciency (Choudhuri et al., 2004; Fuentes, 2007; Matsuda & Yajima, 2009;
Krafty & Collinge, 2013; Jesus & Chandler, 2017). However, it has been observed that the Whittle likeli-
hood, despite its desirable asymptotic properties, may exhibit poor properties when applied to real-world,
ﬁnite-length time series, particularly in terms of estimation bias (Dahlhaus, 1988; Velasco & Robinson,
2000; Contreras-Cristan et al., 2006). Bias is caused by spectral blurring, sometimes referred to as spec-
tral leakage (Percival & Walden, 1993). Furthermore, when the time series model is speciﬁed in continuous
time, but observed discretely, then there is the added problem of aliasing, which if unaccounted for will
further increase bias in Whittle estimates. The challenge is to account for such sampling effects and de-bias
Whittle estimates, while retaining the computational efﬁciency of the method. We here deﬁne such a pro-
cedure, which can be combined with tapering and appropriate differencing, as recommended by Dahlhaus
(1988) and Velasco & Robinson (2000). This creates an automated procedure that incorporates all modiﬁ-
cations simultaneously, without any hand-tuning or reliance on process-speciﬁc analytic derivations such as
in Taniguchi (1983).

We compare pseudo-likelihood approaches with simulated and real-world time series observations. In
our example from oceanography, the de-biased Whittle likelihood results in parameter estimates that are
signiﬁcantly closer to maximum likelihood than standard Whittle estimates, while reducing the computa-
tional runtime of maximum likelihood by over a factor of 100, thus demonstrating the practical utility of
our method. Additionally, the theoretical properties of our new estimator are studied under relatively weak
assumptions, in contrast to Taniguchi (1983), Dahlhaus (1988), and Velasco & Robinson (2000). Taniguchi
studies autoregressive processes that depend on a scalar unknown parameter. Dahlhaus studies processes
whose spectral densities are the product of a known function with peaks that increase with sample size, and
a latent spectral density that is twice continuously differentiable in frequency. Velasco and Robinson study
processes that exhibit power-law behaviour at low frequencies and require continuous differentiability of the
spectrum (at all frequencies except zero). Our assumptions on the spectral density of the time series will be
milder. In particular, we will not require that the spectral density is continuous in frequency. Despite this, we
are still able to prove consistency of de-biased Whittle estimates, together with a convergence rate matching
the optimal n−1/2.

2 Deﬁnitions and Notation

We shall assume that the stochastic process of interest is modelled in continuous time, however, the de-
biased Whittle likelihood can be readily applied to discrete-time models, as we shall discuss later. We deﬁne
{Xt} as the inﬁnite sequence obtained from sampling a zero-mean continuous-time real-valued process
X(t; θ), where θ is a length-p vector that speciﬁes the process. That is, we let Xt ≡ X(t∆; θ), where t
is a positive or negative integer, t = . . . , −2, −1, 0, 1, 2, . . ., and ∆ > 0 is the sampling interval. If the
process is second-order stationary, we deﬁne the autocovariance sequence by s(τ ; θ) ≡ E{XtXt−τ } for
τ = . . . , −2, −1, 0, 1, 2, . . ., where E{·} is the expectation operator. The power spectral density of {Xt}
forms a Fourier pair with the autocovariance sequence, and is almost everywhere given by

∞

f (ω; θ) = ∆

s(τ ; θ) exp(−iωτ ∆),

s(τ ; θ) =

τ =−∞
X

1
2π

π/∆

−π/∆

Z

f (ω; θ) exp(iωτ ∆)dω.

(1)

As {Xt} is a discrete sequence, its Fourier representation is only deﬁned up to the Nyquist frequency ±π/∆.
Thus there may be departures between f (ω; θ) and the continuous-time process spectral density, denoted as

2

˜f (ω; θ), which for almost all ω ∈ R is given by

˜f (ω; θ) =

∞

−∞

Z

˜s(λ; θ) exp(−iωλ)dλ,

˜s(λ; θ) =

1
2π

∞

−∞

Z

˜f (ω; θ) exp(iωλ)dω.

(2)

Here ˜s(λ; θ) ≡ E{X(t)X(t − λ)} (for λ ∈ R) is the continuous-time process autocovariance, which is
related to s(τ ; θ) via ˜s(τ ∆; θ) = s(τ ; θ), when τ is an integer. It follows that

∞

f (ω; θ) =

˜f

ω + k

Xk=−∞

(cid:18)

2π
∆

; θ

, ω ∈ [−π/∆, π/∆].

(3)

(cid:19)

Thus contributions to ˜f (ω; θ) outside of the range of frequencies ±π/∆ are said to be folded or wrapped into
f (ω; θ). We have deﬁned both f (ω; θ) and ˜f (ω; θ), as both quantities are important in separating aliasing
from other artefacts in spectral estimation.

In addition to these theoretical quantities, we will also require certain quantities that are computed di-
rectly from a single length-n sample {Xt}n
t=1. A widely used, but statistically inconsistent, estimate of
f (ω; θ) is the periodogram, denoted I(ω), which is the squared absolute value of the Discrete Fourier Trans-
form (DFT) deﬁned as

I(ω) ≡ |J(ω)|2 ,

J(ω) ≡

∆
n

1/2 n

Xt exp(−iωt∆), ω ∈ [−π/∆, π/∆].

(4)

t=1
X
Note that I(ω) and J(ω) are taken to be properties of the observed realisation and are not regarded as
functions of θ.

(cid:18)

(cid:19)

3 Maximum Likelihood and the Whittle Likelihood

Consider the discrete sample X = {X}N
t=1, which is organized as a length n column vector. Under the
assumption that X is drawn from X(t; θ), the expected n × n autocovariance matrix is C(θ) ≡ E
,
where the superscript “T ” denotes the transpose, and the components of C(θ) are given by Cij (θ) =
(cid:9)
s (i − j; θ). Exact maximum likelihood inference can be performed for Gaussian data by evaluating the
log-likelihood (Brockwell & Davis, 1991, p.254) given by

XX T

(cid:8)

ℓ(θ) ≡ − log |C(θ)| − X T C−1(θ) X,

(5)

where the superscript “−1” denotes the matrix inverse, and |C(θ)| is the determinant of C(θ). We have
removed additive and multiplicative constants not affected by θ in (5). The optimal choice of θ for our
chosen model to characterize the sampled time series X is then found by maximizing the likelihood function
in (5) leading to

ˆθ = arg max
θ∈Θ

ℓ(θ),

where Θ deﬁnes the parameter space of θ. Because the time-domain maximum likelihood is known to have
optimal properties, any other estimator will be compared with the properties of this quantity.

A standard technique for avoiding expensive matrix inversions is to approximate (5) in the frequency
domain, following the seminal work of Whittle (1953). This approach approximates C(θ) using a Fourier

3

representation, and utilizes the special properties of Toeplitz matrices. Given the observed sampled time
series X, the Whittle likelihood, denoted ℓW (θ) is

ℓW (θ) ≡ −

log ˜f (ω; θ) +

Xω∈Ω (cid:26)

I(ω)
˜f (ω; θ) (cid:27)

,

where Ω is the set of discrete Fourier frequencies given by

Ω ≡ (ω1, ω2, . . . , ωn) =

2π
n∆

(−⌈n/2⌉ + 1, . . . , −1, 0, 1, . . . , ⌊n/2⌋) .

(6)

(7)

The subscript “W ” in ℓW (θ) is used to denote “Whittle.” We have presented the Whittle likelihood in a
discretized form here, as its usual integral representation must be approximated for ﬁnite-length time series.
In general, if the summation in (6) is performed over subsets of Ω then the resulting procedure is semi-
parametric.

The Whittle likelihood approximates the time-domain likelihood when all Fourier frequencies are used
Its
in (7), i.e. ℓ(θ) ≈ ℓW (θ), and this statement can be made precise (Dzhaparidze & Yaglom, 1983).
computational efﬁciency is a signiﬁcantly faster O(n log n), versus O(n2) for maximum likelihood, as the
periodogram can be computed using the Fast Fourier Transform, thus explaining its popularity in practice.

4 Modiﬁed pseudo-likelihoods

The standard version of the Whittle likelihood (6) is calculated using the periodogram, I(ω). This spectral
estimate, however, is known to be a biased measure of the continuous-time process’s spectral density for ﬁ-
nite samples, due to blurring and aliasing effects (Percival & Walden, 1993), as discussed in the introduction.
Aliasing results from the discrete sampling of the continuous-time process to generate an inﬁnite sequence,
whereas blurring is associated with the truncation of this inﬁnite sequence over a ﬁnite-time interval. The
desirable properties of the Whittle likelihood rely on the asymptotic behaviour of the periodogram for large
sample sizes. The bias of the periodogram for ﬁnite samples however, will translate into biased parameter
estimates from the Whittle likelihood, as has been widely reported (see e.g. Dahlhaus (1988)).

In this section we propose a modiﬁed version of the Whittle likelihood in Section 4.1 which de-biases
Whittle estimates. Furthermore, tapering and differencing are two well-established methods for improving
Whittle estimates (Dahlhaus, 1988; Velasco & Robinson, 2000). In Sections 4.2 and 4.3 we respectively
outline how the de-biased Whittle likelihood can be easily combined with either of these procedures.

4.1 The de-biased Whittle likelihood

We introduce the following pseudo-likelihood function given by

ℓD(θ) ≡ −

log f n(ω; θ) +

Xω∈Ω (cid:26)

π/∆

I(ω)
f n(ω; θ)

,

(cid:27)

f n(ω; θ) ≡

−π/∆

Z

f (ν; θ)Fn,∆ (ω − ν) dν, Fn,∆(ω) ≡

∆
2πn

sin2(nω∆/2)
sin2(ω∆/2)

,

(8)

(9)

where the subscript “D” stands for “de-biased.” Here ˜f (ω; θ) in (6) has been replaced by f n(ω; θ), which is
the expected periodogram, and may be shown to be given by the convolution of the true modelled spectrum

4

with the Fej´er kernel Fn,∆(ω), such that f n(ω; θ) ≡ E{I(ω)} (Bloomﬁeld, 1976). We call (8) the de-biased
Whittle likelihood, where the set Ω is deﬁned as in (7).

Replacing the true spectrum ˜f (ω; θ) with the expected periodogram f n(ω; θ) in (8) is a straightforward
concept, however, our key innovation lies in formulating its efﬁcient computation without losing O(n log n)
efﬁciency. If we directly use (9), then this convolution would usually need to be approximated numeri-
cally, and could be computationally expensive. Instead we utilize the convolution theorem to express the
frequency-domain convolution as a time-domain multiplication (Percival & Walden, 1993, p.198), such that

f n(ω; θ) = 2∆ · ℜ

n−1

(

τ =0 (cid:16)
X

1 −

τ
n

(cid:17)

s(τ ; θ) exp(−iωτ ∆)

)

− ∆ · s(0; θ),

(10)

where ℜ{·} denotes the real part. Therefore f n(ω; θ) can be exactly computed at each Fourier frequency
directly from s(τ ; θ), for τ = 0, . . . , n − 1, by using a Fast Fourier Transform in O(n log n) operations.
Care must be taken to subtract the variance term, ∆ · s(0; θ), to avoid double counting contributions from
τ = 0. Both aliasing and blurring effects are automatically accounted for in (10) in one operation; aliasing
is accounted for by sampling the theoretical autocovariance function at discrete times, while the effect of
blurring is accounted for by the truncation of the sequence to ﬁnite length, and the inclusion of the triangle
function (1 − τ /n) in the expression.

The de-biased Whittle likelihood can also be used for discrete-time process models, as (10) can be
computed from the theoretical autocovariance sequence of the discrete process in exactly the same way.
Furthermore, the summation in (8) can be performed over a reduced range of frequencies to perform semi-
parametric inference. If the analytic form of s(τ ; θ) is unknown or expensive to evaluate, then it can be
approximated from the spectral density using Fast Fourier Transforms, thus maintaining O(n log n) compu-
tational efﬁciency.

As an aside, we point out that computing the standard Whittle likelihood of (6) with the aliased spectrum
f (ω; θ) deﬁned in (1), without accounting for spectral blurring, would in general be more complicated than
using the expected periodogram f n(ω; θ). This is because the aliased spectrum f (ω; θ) seldom has an
analytic form for continuous processes, and must be instead approximated by either explicitly wrapping in
contributions from ˜f (ω; θ) from frequencies higher than the Nyquist as in (3), or via an approximation to the
Fourier transform in (1). This is in contrast to the de-biased Whittle likelihood, where the effects of aliasing
and blurring have been computed exactly in one single operation using (10). Thus addressing aliasing and
blurring together using the de-biased Whittle likelihood is simpler and computationally faster to implement
than accounting for aliasing alone.

4.2 The de-biased tapered Whittle likelihood

To ameliorate spectral blurring of the periodogram, a standard approach is to pre-multiply the data sequence
with a weighting function known as a data taper (Thomson, 1982). The taper is chosen to have spectral
properties such that broadband blurring will be minimized, and the variance of the spectral estimate at each
frequency is reduced, although the trade-off is that tapering increases narrowband blurring as the correlation
between neighbouring frequencies increases.

The tapered Whittle likelihood (Dahlhaus, 1988) corresponds to replacing the direct spectral estimator

formed from I(ω) in (4) with one using the taper h = {ht}

J(ω; h) ≡ ∆1/2

n

t=1
X

htXt exp(−iωt∆),

I(ω; h) ≡ |J(ω; h)|2 ,

h2
t = 1,

(11)

n

t=1
X

5

where ht is real-valued. Setting ht = 1/n1/2 for t = 1, . . . n recovers the periodogram estimate of (6). To
estimate parameters we then maximize

ℓT (θ) ≡ −

log ˜f (ω; θ) +

Xω∈Ω (cid:26)

I(ω; h)
˜f (ω; θ) (cid:27)

,

(12)

where the subscript “T ” denotes that a taper has been used. Velasco & Robinson (2000) demonstrated that
for certain discrete processes it is beneﬁcial to use this estimator, rather than the standard Whittle likelihood,
for parameter estimation, particularly when the spectrum exhibits a high dynamic range. Nevertheless,
tapering in itself will not remove all broadband blurring effects in the likelihood, because we are still com-
paring the tapered spectral estimate against the theoretical spectrum, and not against the expected tapered
spectrum. Furthermore, there remain the issues of narrowband blurring, as well as aliasing effects with
continuous sampled processes.

A useful feature of our de-biasing procedure is that it can be naturally combined with tapering. To do

this we deﬁne the likelihood given by

ℓT D(θ) ≡ −

log f n(ω; h, θ) +

Xω∈Ω (cid:26)

π/∆

I(ω; h)
f n(ω; h, θ)

,

(cid:27)

f n(ω; h, θ) ≡

−π/∆

Z

f (ν; θ)H∆ (ω − ν) dν, H∆(ω) ≡ ∆

(13)

2

,

n

t=1
X

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

ht exp(−iωt∆)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

with I(ω; h) as deﬁned in (11) such that f n(ω; h, θ) ≡ E{I(ω; h)}. We call ℓT D(θ) the de-biased ta-
pered Whittle likelihood and f n(ω; h, θ) the expected tapered spectrum which can be computed exactly and
efﬁciently using a similar O(n log n) calculation to (10) to ﬁnd f n(ω; h, θ) such that

f n(ω; h, θ) = 2∆ · ℜ

(

n−1

n−τ

s(τ ; θ)

htht+τ

exp(−iωτ ∆)

− ∆ · s(0; θ).

!

)

τ =0
X

t=1
X
Accounting for the particular taper used in f n(ω; h, θ) accomplishes de-biasing of the tapered Whittle like-
lihood, just as using the expected periodogram does for the standard Whittle likelihood. The time-domain
n−τ
kernel
t=1 htht+τ can be pre-computed using FFTs or using a known analytical form. Then during op-
timization, an FFT of this ﬁxed kernel multiplied by the autocovariance sequence is taken at each iteration.
Thus the de-biased tapered Whittle likelihood is also an O(n log n) pseudo-likelihood estimator.

P

Both the de-biased tapered and de-biased periodogram likelihoods have their merits, but the trade-offs
are different with nonparametric spectral density estimation than they are with parametric model estima-
tion. Speciﬁcally, although tapering decreases the variance of nonparametric estimates at each frequency,
it conversely may increase the variance of estimated parameters. This is because the taper is reducing de-
grees of freedom in the data, which increases correlations between local frequencies. On the other hand,
the periodogram creates broadband correlations between frequencies, especially for processes with a high
dynamic range, which also contributes to variance in parameter estimates. We explore these trade-offs in
greater detail in Section 5.

4.3 The de-biased Whittle likelihood with differenced data

Another method of reducing the effects of blurring on Whittle estimates is to ﬁt parameters to the differ-
enced process. This was illustrated in Velasco & Robinson (2000), where the Whittle likelihood was found

6

 
Xω∈ΩY (

n−2

(

τ
n

to perform poorly with fractionally integrated processes that exhibited higher degrees of smoothness, but
improved when working with the differenced process as this reduced the dynamic range of the spectrum and
hence decreased broadband blurring.

Whittle likelihood using the differenced process proceeds as follows. Deﬁne Y (t; θ) ≡ X(t + ∆; θ) −
X(t; θ) for the continuous-time differenced process, and Yt = Xt+1 − Xt for the sampled process. The
spectral density of Y (t; θ), denoted ˜fY (ω; θ), can be found from ˜f (ω; θ) via the relationship

Then the Whittle likelihood for differenced processes is performed by maximizing

˜fY (ω; θ) = 4 sin2

˜f (ω; θ).

ω∆
2

(cid:18)

(cid:19)

ℓW (θ) ≡ −

log ˜fY (ω; θ) +

Xω∈ΩY (cid:26)

IY (ω)
˜fY (ω; θ) (cid:27)

,

(14)

where IY (ω) is the periodogram of the sample {Yt}n−1
t=1 . The set of Fourier frequencies ΩY are now
2π(−⌈(n − 1)/2⌉ + 1, . . . , −1, 1, . . . , ⌊(n − 1)/2⌋)/(n − 1)∆, where one degree of freedom has been lost
by differencing, and a second has been lost as the zero frequency should be excluded because the spectral
density is now equal to zero here. The de-biased Whittle likelihood is also straightforward to compute from
{Yt}n−1

t=1 over the same set of Fourier frequencies ΩY

ℓD(θ) ≡ −

log f n,Y (ω; θ) +

IY (ω)
f n,Y (ω; θ) )

,

(15)

f n,Y (ω; θ) = 2∆ · ℜ

1 −

sY (τ ; θ) exp(−iωτ ∆)

− ∆ · sY (0; θ),

τ =0 (cid:16)
X
where f n,Y (ω; θ) ≡ E{IY (ω)} and sY (τ ; θ) is the autocovariance of Yt where

(cid:17)

)

sY (τ ; θ) = 2s(τ ; θ) − s(τ + 1; θ) − s(τ − 1; θ),

from direct calculation. This likelihood remains an O(n log n) operation to evaluate, as computing all
required sY (τ ; θ) from s(τ ; θ) is O(n), and the rest of the calculation is as in (10). Differencing and
tapering can be easily combined in O(n log n), with both the standard and de-biased Whittle likelihoods.
Furthermore, differencing can be applied multiple times if required.

To see how differencing can reduce the variance of the estimators, we investigate the variance of the
score of the de-biased Whittle likelihood, which (as derived in equation (33) of the Appendix material) can
be bounded for each scalar θi by

var

1
n

∂
∂θi

(cid:26)

ℓD(θ)

≤

(cid:27)

maxk ∂f n
f 2
∂θi
nf 4

min

k2
∞

,

(16)

where k∂f n/∂θik2
∞ is the upper bound on the partial derivative of the expected periodogram with respect to
θi, and fmin and fmax are upper and lower bounds on the spectral density respectively (assumed ﬁnite and
non-zero). The signiﬁcance of (16) is that the bound on the variance of the score is controlled by the dynamic
range of the spectrum, as a high dynamic range will lead to large values of f 2
min. This suggests that
one should difference a process with steep spectral slopes, as this will typically reduce the dynamic range of
the spectrum thus reducing f 2
min, in turn decreasing the bound on the variance. Differencing multiple
times however may eventually send fmin to zero, such that at some point the ratio will increase, in turn
increasing the bound on the variance.

max/f 4

max/f 4

7

5 Monte-Carlo Simulations

All simulation results in Sections 5 and 6 can be exactly reproduced in MATLAB, and all data can be down-
loaded, using the software available at www.ucl.ac.uk/statistics/research/spg/software.
As part of the software we provide a simple package for estimating the parameters of any time series obser-
vation modelled as a second-order stationary stochastic process speciﬁed by its autocovariance.

5.1 Comparing the standard and de-biased Whittle likelihood

In this section we investigate the performance of the standard and de-biased Whittle likelihoods in a Monte
Carlo study using observations from a Mat´ern process (Mat´ern, 1960), as motivated by the simulation studies
of Anitescu et al. (2012) who study the same process. The Mat´ern process is a three-parameter continuous
Gaussian process deﬁned by its continuous-time unaliased spectrum

˜f (ω) =

A2
(ω2 + c2)α .

(17)

The parameter A sets the magnitude of the variability, 1/c > 0 is the damping timescale, and α > 1/2
controls the rate of spectral decay, or equivalently the smoothness or differentiability of the process. For large
α the power spectrum exhibits a high dynamic range, and the periodogram will be a poor estimator of the
spectral density due to blurring. Conversely, for small α there will be departures between the periodogram
and the continuous-time spectral density because of aliasing. We will therefore investigate the performance
of estimators over a range of α values.

In Fig. 1 we display the bias and standard deviation of the different Whittle estimators for the three
parameters {A, α, c} where α varies from [0.6, 2.5] in intervals of 0.1. We ﬁx A = 1 and c = 0.2, but
estimate all three parameters assuming they are unknown. For each value of α, we simulate 10,000 time
series each of length n = 1000, and use these replicated series to calculate biases and standard deviations for
each estimator. We implement several different Whittle estimators: standard Whittle likelihood (6), tapered
Whittle likelihood (12), and differenced Whittle likelihood (14). In addition, for each of these we implement
the de-biased version (equations (8), (13), and (15), respectively). The choice of data taper is the Discrete
Prolate Spheroidal Sequence (DPSS) taper (Slepian & Pollak, 1961), with bandwidth parameter equal to
4, where performance was found to be broadly similar across different choices of bandwidth (not shown).
We also performed ﬁts using combined differenced and tapered versions of both the standard and de-biased
Whittle likelihoods, as discussed in Section 4.3, and found that results were virtually identical to tapering
without differencing (also not shown). The optimization is performed in MATLAB using fminsearch,
and uses identical settings for all likelihoods. Initialized guesses for the slope and amplitude are found using
a least squares ﬁt in the range [π/4∆, 3π/4∆], and the initial guess for the damping parameter c is set at a
mid-range value of 100 times the Rayleigh frequency (i.e. c = 100π/n = π/10.)

The ﬁrst column in Fig. 1 displays the absolute bias of each estimator for the three Mat´ern parameters.
The absolute biases are displayed on a log10 scale, and in many instances we can see bias reductions of
over a factor of 10 in each of the parameters, representing over a 90% bias reduction. The “U” shape over
the range of α values, with the standard Whittle likelihood using the periodogram, corresponds to aliasing
effects for small α and blurring effects for large α. Differencing and tapering ameliorate the blurring effects
for high α, but not the aliasing effects for low α. De-biased methods, particularly when combined with
differencing, remove bias most consistently across the full range of α values.

The second column displays the standard deviations of the estimates. These are broadly comparable
between the methods, although methods that use the periodogram suffer from reduced performance for high

8

100

10-1

10-2

s
a
b

i

l

e
t
u
o
s
b
a

10-3

0.5

100

10-1

10-2

s
a
b

i

l

e
t
u
o
s
b
a

10-3

0.5

100

10-1

10-2

s
a
b

i

l

e
t
u
o
s
b
a

10-3

0.5

estimates of A

1

1.5
true slope parameter (α)
estimates of α

2

1

1.5
true slope parameter (α)
estimates of c

2

1

1.5
true slope parameter (α)

2

100

10-1

10-2

n
o
i
t
a
v
e
d

i

d
r
a
d
n
a
t
s

2.5

10-3

0.5

100

10-1

10-2

n
o
i
t
a
v
e
d

i

d
r
a
d
n
a
t
s

2.5

10-3

0.5

100

10-1

10-2

n
o
i
t
a
v
e
d

i

d
r
a
d
n
a
t
s

2.5

10-3

0.5

estimates of A

Periodogram
Tapered
Differenced

1

1.5
true slope parameter (α)
estimates of α

2

1

1.5
true slope parameter (α)
estimates of c

2

1

1.5
true slope parameter (α)

2

r
o
r
r
e

e
r
a
u
q
s

n
a
e
m

t
o
o
r

r
o
r
r
e

e
r
a
u
q
s

n
a
e
m

t
o
o
r

r
o
r
r
e

e
r
a
u
q
s

n
a
e
m

t
o
o
r

100

10-1

10-2

10-3

0.5

100

10-1

10-2

10-3

0.5

100

10-1

10-2

10-3

0.5

2.5

2.5

2.5

estimates of A

1

1.5
true slope parameter (α)
estimates of α

2

1

1.5
true slope parameter (α)
estimates of c

2

1

1.5
true slope parameter (α)

2

2.5

2.5

2.5

Figure 1: Absolute bias (left column), standard deviation (centre column) and root-mean-square-error
(right column) of Mat´ern parameter estimates using different forms of the standard and de-biased Whittle
likelihoods. The colours correspond to different approaches: periodogram, tapered, or differenced (as in-
dicated by the legend in the top centre panel). For each approach, the dashed lines are for standard Whittle
approaches, and the solid lines are the corresponding de-biased approaches. The top row corresponds to
estimates for the amplitude parameter A, the second row for the slope parameter α, and the bottom row
for the damping parameter c, as given in (17). In all panels the results are over a range of α values in
increments of 0.1 from 0.6 to 2.5, translating to a spectral slope between ω

−1.2 and ω

−5.

9

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Table 1: Aggregated results from Fig. 1, averaging the percentage bias (relative to the true parameter
values), standard deviation (SD), and root-mean-square-error (RMSE) across all estimates of {A, α, c},
over the full range of α considered

Inference Method
Standard Whittle (periodogram)
De-Biased Whittle (periodogram)
Standard Whittle (tapered)
De-Biased Whittle (tapered)
Standard Whittle (differenced)
De-Biased Whittle (differenced)

Eqn
(6)
(8)
(12)
(13)
(14)
(15)

Bias

RMSE
SD
23.69% 10.34% 26.66%
3.96% 12.97% 13.75%
18.11% 12.23% 23.12%
2.60% 14.15% 14.41%
9.33% 22.09%
8.99%
8.90%

18.99%
1.19%

α due to broadband spectral blurring. The dip when estimating α for low values with standard methods
is due to boundary effects in the optimization. Here the estimate of α cannot go below 0.5, and due to
severe aliasing, the optimization typically converges to this lower bound when the true α is less than 0.7,
such that the estimate is badly biased, but not variable. As we have used 10,000 replicates, the standard
error of the reported biases can be observed by eye, by dividing the corresponding standard deviations by
100001/2 = 100, meaning that the observed bias reductions using our approach appear highly signiﬁcant.

The ﬁnal column displays the root-mean-square-error (RMSE), thus combining information from the
ﬁrst two columns. With standard methods, the observed biases are in general larger than the standard de-
viations, so the shapes of the RMSE curves generally follow those of the biases. The de-biased methods
are signiﬁcantly less biased such that standard deviation is now the main contribution to RMSE. Overall,
because bias tends to dominate variance with the standard Whittle estimates, the de-biased methods improve
upon the standard methods with only a few exceptions, and can reduce error by an order of magnitude.

Finally, in Table 1 we aggregate all information in Fig. 1 to provide the average percentage bias (rel-
ative to the true parameter values), standard deviation, and RMSE for each likelihood estimator and each
parameter combination. Of all the estimators, the de-biased Whittle likelihood using the differenced process
performs best. Overall, of the three modiﬁcations to the standard Whittle likelihood—de-biasing, taper-
ing and differencing—the de-biasing method proposed here is the single procedure that yields the greatest
overall improvement in parameter estimation.

5.2 Comparison with time-domain estimators

Time-domain O(n log n) pseudo-likelihood procedures have been proposed in Anitescu et al. (2012) (see
also Dutta & Mondal (2015) and Anitescu et al. (2016)) who use Hutchinson trace estimators and circu-
lant embedding techniques, removing the need to calculate a matrix inverse or determinant. We con-
trast the approach proposed here with that of Anitescu et al. (2012) using the MATLAB package “Scala-
Gauss” supplied by those authors at http://press3.mcs.anl.gov/scala-gauss/software/.
We use the same parameters of their example code for a Mat´ern process, which estimates the damping
parameter, and assumes the slope parameter is known, and the amplitude parameter is known up to a
proportion of the damping parameter. The parameters used, when transformed into the form of (17), are
A = 1.7725c, α = 1.5, c = 0.0197 and n = 1, 024. As the slope parameter is high, we ﬁt the de-biased
Whittle to the differenced process. We perform 10,000 repeats and report the results in Table 2. We include
results for maximum likelihood, standard Whittle likelihood, and standard and de-biased tapered likelihoods.
Standard Whittle likelihood performs extremely poorly due to the blurring effects of using the peri-
odogram. The de-biased Whittle likelihood and the method of Anitescu et al. (2012) return estimation errors

10

Table 2: Percentage bias, standard deviation (SD), and root mean squared error (RMSE) of different
methods when estimating the damping parameter, α of a Mat´ern process. The experiment is repeated over
10,000 independently generated Mat´ern series of length n = 1, 024 with parameters, A = 1.7725c, α =
1.5, c = 0.0197. CPU times are as performed on a 2.8 GHz Intel Core i7 processor

Inference Method
Maximum likelihood
Standard Whittle (periodogram)
De-Biased Whittle (differenced)
Standard Whittle (tapered)
De-Biased Whittle (tapered)
Anitescu et al. (normal version)
Anitescu et al. (faster version)

Eqn
(5)
(6)
(15)
(12)
(13)

Bias
0.029%

RMSE
SD
2.204%
2.204%
107.735% 101.357% 147.916%
2.212%
2.212%
0.030%
25.550% 20.459% 32.731%
2.558%
2.558%
0.023%
2.205%
2.205%
0.029%
2.223%
2.223%
0.035%

CPU (sec.)
4.257
0.139
0.157
0.168
0.198
1.998
0.438

that are very close to maximum likelihood. The method of Anitescu et al. (2012) however, requires an order
of magnitude more processing time than the de-biased and standard Whittle likelihood. This is because
the method involves many more steps in the procedure, such as generating random numbers to form the
Hutchinson trace estimators. To speed up the Anitescu et al. (2012) method, we have included results with a
modiﬁed version which uses only one Hutchinson trace estimator (as opposed to the 50 used in the example
code). The method still remains slower than the de-biased Whittle likelihood, and now yields slightly worse
estimation accuracy. The de-biased method appears to be the best method at combining the ﬁt quality of
time-domain maximum likelihood, with the speed of the standard Whittle method.

6 Application to Large-Scale Oceanographic Data

In this section we examine the performance of our method when applied to a real-world large-scale dataset,
by analysing data obtained from the Global Drifter Program, which maintains a publicly-downloadable
database of position measurements obtained from freely-drifting satellite-tracked instruments known as
drifters (http://www.aoml.noaa.gov/phod/dac/index.php). In total over 23,000 drifters have
been deployed, with interpolated six-hourly data available since 1979 and one-hourly data since 2005 (see
Elipot et al. (2016)), with over 100 million data points available in total. The collection of such data is piv-
otal to the understanding of ocean circulation and its impact on the global climate system (see Griffa et al.
(2007)); it is therefore essential to have computationally efﬁcient methods for their analysis.

In Fig. 2, we display 50-day position trajectories and corresponding velocity time series for three drifters
from the one-hourly data set, each from a different major ocean. These trajectories can be considered as
complex-valued time series, with the real part corresponding to the east/west velocity component and the
imaginary part corresponding to the north/south velocity component. We then plot the periodogram of
the complex-valued series, which has different power at positive and negative frequencies, distinguishing
directions of rotation on the complex plane (Schreier & Scharf, 2010). The de-biased Whittle likelihood for
complex-valued proper processes is exactly the same as (8)–(10) (see also Sykulski et al. (2016)), where the
autocovariance sequence of a complex-valued process Zt is s(τ ; θ) = E{ZtZ ∗
t−τ }. For proper processes
the complementary covariance is r(τ ; θ) = E{ZtZt−τ } = 0 at all lags (Schreier & Scharf, 2010), and can
thus be ignored in the likelihood, as s(τ ; θ) captures all second-order structure in the zero-mean process.

We model the velocity time series as a complex-valued Mat´ern process, with power spectral density
given in (17), as motivated by Sykulski et al. (2016) and Lilly et al. (2017). To account for a type of cir-

11

Atlantic

Pacific

Indian

18

17

8

7

6

5

4

358.5

lon

359

246

247

248

lon

88 89 90 91 92 93 94
lon

10

20

30

40

50

day

1

0.5

0

-0.5

-1

0

104

102

100

10

20

30

40

50

day

1

0.5

0

-0.5

-1

0

104

102

100

10

20

30

40

50

day

-27

t
a

l

-27.5

1

0.5

s
/
m

0

-0.5

-1

0

104

s
/

2
m

102

100

0.1

0.5 1

3

12

0.1

0.5 1

3

12

0.1

0.5 1

3

12

cycles per day

cycles per day

cycles per day

Figure 2: The top row displays 50-day trajectories of Drifter IDs: #2339255 (Atlantic Ocean), #49566
(Paciﬁc Ocean), and #43577 (Indian Ocean). The second row displays the east/west (red-solid) and
north/south (blue-dashed) velocity time series for each trajectory. The third row displays the periodograms
of the complex-valued velocity series, with the non-inertial side of the spectrum in red-solid, and the in-
ertial side in blue-dashed. The expected periodogram, f n(ω; ˆθ), from the de-biased Whittle likelihood is
overlaid in black.

cular oscillations in each time series known as inertial oscillations, which create an off-zero spike on one
side of the spectrum, we ﬁt the Mat´ern process semi-parametrically to the opposite “non-inertial” side of
the spectrum (as displayed by the red-solid line in the ﬁgure). We overlay the ﬁt of the de-biased Whit-
tle likelihood to the periodograms in Fig. 2. For a full parametric model of surface velocity time series,
see Sykulski et al. (2016). We have selected drifters without noticeable tidal effects; for de-tiding proce-
dures see Pawlowicz et al. (2002).

We estimate the Mat´ern parameters for each time series using the de-biased and regular Whittle likeli-
hood, as well as exact maximum likelihood. The latter of these methods can be performed over only positive
or negative frequencies by ﬁrst decomposing the time series into analytic and anti-analytic components using
the discrete Hilbert transform, see Marple (1999), and then ﬁtting the corresponding signal to an adjusted
Mat´ern autocovariance that accounts for the effects of the Hilbert transform. The details for this procedure
are provided in the online code.

12

Table 3: Estimated Mat´ern parameters using the maximum, de-biased Whittle, and standard Whittle,
likelihoods for the velocity time series of Fig. 2. The parameters are given in terms of the damping
timescale (1/c), the slope (2α) and the diffusivity (κ). CPU times are as performed on a 2.8 GHz Intel
Core i7 processor

Drifter
location method

Inference

Damping Slope
(days)

Diffusivity
(m2/s×103)

CPU (s)

Maximum likelihood

Atlantic De-biased Whittle
Standard Whittle

Maximum likelihood

Paciﬁc De-biased Whittle
Standard Whittle

Indian

Maximum likelihood
De-biased Whittle
Standard Whittle

10.65
9.84
30.19

10.63
11.82
19.59

21.76
19.91
39.99

1.460
1.462
1.097

1.829
1.886
1.566

1.825
1.802
1.545

0.49
0.44
0.65

5.09
6.00
7.18

30.47
22.71
31.19

20.89
0.06
0.02

31.65
0.09
0.02

30.37
0.11
0.01

The parameter estimates from the three likelihoods are displayed in Table 3, along with the corresponding
CPU times. We reparametrize the Mat´ern to output three important oceanographic quantities: the damping
timescale, the decay rate of the spectral slope, and the diffusivity (which is the rate of particle dispersion)
given by κ ≡ A2/4c2α (Lilly et al., 2017, eq.(43)). From Table 3 it can be seen that the de-biased Whittle
and maximum likelihoods yield similar values for the slope and damping timescale, however, regular Whit-
tle likelihood yields parameters that differ by around 15% for the slope, and over 100% for the damping
timescale. These are consistent with the signiﬁcant biases reported in our simulation studies in Section 5.
The diffusivity estimates vary across all estimation procedures, and this variability is likely due to the fact
that diffusivity is a measure of the spectrum at frequency zero, hence estimation is performed over rela-
tively few frequencies. The time-domain maximum likelihood is over two orders of magnitude slower to
execute than the de-biased Whittle likelihood. When this difference is scaled up to ﬁtting all time series in
the Global Drifter Program database, then time-domain maximum likelihood becomes impractical for such
large datasets (taking years rather than days on the machine used in this example). The de-biased Whittle
likelihood, on the other hand, retains the speed of Whittle likelihood, whilst returning estimates that are close
to maximum likelihood. This section therefore serves as a proof of concept of how the de-biased Whittle
likelihood is a useful tool for efﬁciently estimating parameters from large datasets.

7 Properties of the De-Biased Whittle Likelihood

In this section, we establish consistency and optimal convergence rates for de-biased Whittle estimates with
Gaussian processes. We will assume that the process is Gaussian in our proofs, however, formally we only
require that the Fourier transform of the process is Gaussian. This is in general a weaker requirement. Pro-
cesses that are non-Gaussian in the time domain may in fact have Fourier transforms with approximately
Gaussian distributions for sufﬁciently large sample size. This is a consequence of a central limit theorem
(Brillinger, 2001, p.94), which also provides formal conditions when the Gaussian assumption is asymptot-
ically valid. Serroukh & Walden (2000) provide practical examples which satisfy such conditions.

To show that de-biased Whittle estimates converge at on optimal rate, the main challenge is that although

13

our pseudo-likelihood accounts for the bias of the periodogram, there is still present the broadband corre-
lation between different frequencies caused by the leakage associated with the Fej´er kernel. This is what
prevents the de-biased Whittle likelihood from being exactly equal to the time-domain maximum likelihood
for Gaussian data. To establish optimal convergence rates, we bound the asymptotic behaviour of this cor-
relation. The statement is provided in Theorem 1, with the proof provided in the Appendix. The proof is
composed of several lemmas which, for example, place useful bounds on the expected periodogram, the
variance of linear combinations of the periodogram at different frequencies, and also the ﬁrst and second
derivatives of the de-biased Whittle likelihood. Together these establish that the de-biased Whittle likeli-
hood is a consistent estimator with estimates that converge in probability at an optimal rate of n−1/2, under
relatively weak assumptions.

Theorem 1. Assume that {Xt} is an inﬁnite sequence obtained from sampling a zero-mean continuous-time
real-valued process X(t; θ), which satisﬁes the following assumptions:

1. The parameter set Θ ⊂ Rp is compact with a non-null interior, and the true length-p parameter vector

θ lies in the interior of Θ.

2. Assume that for all θ ∈ Θ and ω ∈ [−π, π], the spectral density of the sequence {Xt} is bounded

below by f (ω; θ) ≥ fmin > 0, and bounded above by f (ω; θ) ≤ fmax.

3. If θ 6= ˜θ, then there is a space of non-zero measure such that for all ω in this space f (ω; θ) 6= f (ω; ˜θ).

4. Assume that f (ω; θ) is continuous in θ and Riemann integrable in ω.

5. Assume that the expected periodogram f n(ω; θ), as deﬁned in (9), has two continuous derivatives in
θ which are bounded above in magnitude uniformly for all n, where the ﬁrst derivative in θ also has
Θ(n) frequencies in Ω that are non-zero.

Then the estimator

ˆθ = arg max
θ∈Θ

ℓD(θ),

for a sample {Xt}n

t=1, where ℓD(θ) is the de-biased Whittle likelihood of (8), satisﬁes

ˆθ = θ + OP

n−1/2

.

(cid:17)

(cid:16)
Standard theory shows that standard Whittle estimates are consistent with optimal convergence rates for
Gaussian processes if the spectrum (and its ﬁrst and second partial derivatives in θ) are continuous in ω and
bounded from above and below (see Dzhaparidze & Yaglom (1983)), as well as being twice continuously
differentiable in θ. In contrast, we have not required that the spectrum nor its derivatives are continuous in
ω; such that Theorem 1 will hold for discontinuous spectra, as long as the other assumptions are satisﬁed
such as Riemann integrability. As detailed in the Appendix, this is possible because the expectation of the
score is now zero after de-biasing (equation (32) in the Appendix material, which would not be the case for
the standard Whittle likelihood), such that we only need to consider the variance of the score and Hessian.
To control these variances we make repeated use of a bound on the variance of linear combinations of the
periodogram (Lemma 8)—a result previously established in (Giraitis & Koul, 2013, Theorem 3.1) under a
different set of assumptions.

It can be easily shown that the assumptions in Theorem 1 are weaker than standard Whittle assumptions,
despite requiring statements on the behaviour of the expected periodogram f n(ω; θ) in Assumption 5. This
is because if the spectral density f (ω; θ) (and its ﬁrst and second partial derivatives in θ) are continuous in

14

both ω and θ, then it can be shown by applying the Leibniz’ integration rule to the ﬁrst and second derivatives
of (9) in θ, that f (ω; θ) twice continuously differentiable in θ implies that f n(ω; θ) is twice continuously
differentiable in θ. To show this we make use of (Stein & Shakarchi, 2003, Prop 3.1) which states that the
convolution of two integrable and periodic functions is itself continuous. This result can also be used to
show that f n(ω; θ) is always continuous in ω, even if f (ω; θ) is not, as from (9) we see that f n(ω; θ) is
the convolution of f (ω; θ) and the Fej´er kernel—two functions which are integrable and 2π-periodic in ω.
Therefore, not only does f n(ω; θ) remove bias from blurring and aliasing, and is computationally efﬁcient
to compute, but it also has desirable theoretical properties leading to consistency and optimal convergence
rates of de-biased Whittle estimates under weaker assumptions.

Appendix

In the Appendix we prove that de-biased Whittle estimates converge at an optimal rate (Theorem 1). To prove
Theorem 1 we will ﬁrst show that the debiased Whittle estimator is consistent (Proposition 1) in a series of
steps using eight Lemmas. Consistency will be established by showing that properties of the debiased
Whittle estimator converge to that of the standard Whittle estimator. Then having established consistency,
we establish the convergence rates via Lemma 9, where the differences between the debiased and standard
Whittle estimators will become especially clear. This allows us to establish optimal convergence rates under
weaker assumptions in Theorem 1, where we shall not require that the spectral density is continuous in
frequency.

Without loss of generality, we shall assume that the sampling interval is set to ∆ = 1 in this section.
We need to make the following assumptions on the stochastic process X(t; θ) to achieve consistency and
optimal convergence rates:

1. The parameter set Θ ⊂ Rp is compact with a non-null interior, and the true length-p parameter vector

θ lies in the interior of Θ.

2. Assume that for all θ ∈ Θ and ω ∈ [−π, π], the spectral density of the sequence {Xt} is bounded

below by f (ω; θ) ≥ fmin > 0, and bounded above by f (ω; θ) ≤ fmax.

3. If θ 6= ˜θ, then there is a space of non-zero measure such that for all ω in this space f (ω; θ) 6= f (ω; ˜θ).

4. Assume that f (ω; θ) is continuous in θ and Riemann integrable in ω.

5. Assume that the expected periodogram f n(ω; θ), as deﬁned in (9), has two continuous derivatives in
θ which are bounded above in magnitude uniformly for all n, where the ﬁrst derivative in θ also has
Θ(n) frequencies in Ω that are non-zero.

We start with the following lemma which bounds the behaviour of the expected periodogram.

Lemma 1. For all θ ∈ Θ and n ∈ N, the expected periodogram f n(ω; θ) is bounded below (by a positive
real number), and above, independently of n and θ.

Proof. We start by noting that

f n(ω; θ) =

π

−π

Z

f (ν; θ)Fn (ω − ν) dν, Fn (ω) =

1
2πn

sin2 (nω/2)
sin2 (ω/2)

,

15

as given in (9) when ∆ = 1. From Assumption 2 we have that f (ν; θ) ≥ fmin > 0 and also that f (ν; θ) ≤
fmax ∈ R. It therefore follows that

f n(ω; θ) ≤

π

−π

Z

fmaxFn (ω − ν) dν = fmax

Fn (ω − ν) dν = fmax,

π

−π

Z

such that the expected periodogram is upper bounded by fmax. We also have that

f n(ω; θ) ≥

π

−π

Z

fminFn (ω − ν) dν = fmin

Fn (ω − ν) dν = fmin,

π

−π

Z

such that the expected periodogram is lower bounded by fmin > 0.

Following the work of Taniguchi (1979) and Guillaumin et al. (2017), we now introduce the following

quantity

D(n) (γ, g) =

for all θ ∈ Θ and n ∈ N. We also deﬁne

1
n

Xω∈Ω (cid:26)

log f n(ω; γ) +

g(ω)
f n(ω; γ)

,

(cid:27)

T (n)(g) = arg min
γ∈Θ

D(n) (γ, g) .

(18)

(19)

The minimum of T (n)(g) for ﬁxed g is well deﬁned since the set Θ is compact, and the function D(n) (γ, g)
is continuous in γ (from Assumptions 1 and 5). However in cases where the minimum is not unique but
exists at multiple parameter values, T (n)(g) will denote any of these values, chosen arbitrarily. We proceed
with seven further lemmas that are required in proving Proposition 1 which establishes consistency, starting
with Lemma 2 which we repeatedly use in the lemmas that follow.

Lemma 2. The function κ(x) = x − log x, deﬁned on the set of positive real numbers, admits a global
unique minimum for x = 1 where it takes the value 1.

Proof. This can be easily shown by taking the derivative of κ(x).

Lemma 3. For all integer n the quantity T (n)(g) as deﬁned in (18) and (19), satisﬁes T (n)(f n(ω; θ)) = θ.

Proof. We have that for all γ ∈ Θ

D

γ, f n(ω; θ)

=

(cid:8)

(cid:9)

=

≥

1
n

1
n

1
n

f n(ω; θ)
f n(ω; γ)

(cid:27)

f n(ω; θ)
f n(ω; γ)
z

log f n(ω; γ) +

Xω∈Ω (cid:26)



log f n(ω; θ) +

Xω∈Ω





log f n(ω; θ) + 1

Xω∈Ω

(cid:8)

,

(cid:9)

≥1

− log
}|

(cid:26)

f n(ω; θ)
f n(ω; γ)


{
(cid:27)





where from Lemma 2 we have an equality if and only if f n(ω; θ) = f n(ω; γ) for all ω ∈ Ω, which is clearly
satisﬁed for γ = θ.

16

This shows that for all n, the function γ → D

reaches a global minimum at the true
parameter vector θ, although we have not proven any uniqueness properties at this stage. Now because
(cid:8)
(cid:9)
f n(·; θ) is changing with n, we require the following ﬁve lemmas.

γ, f n(·; θ)

Lemma 4. Deﬁne ω′ ∈ [−π, π] such that f (ω; γ) is continuous at ω′. For all ǫ > 0, there exists δ > 0 and
an integer m such that for all n ≥ m, if ω′′ is such that |ω′′ − ω′| ≤ δ

f n(ω′′; γ) − f (ω′; γ)

≤ ǫ.

Proof. By Assumption 4, f (ω; γ) is Riemann integrable in ω, and therefore is continuous almost every-
where. It follows that there then exists an ω′ ∈ [−π, π] such that f (ω; γ) is continuous at ω′. Now let ǫ > 0.
By continuity of f (ω; γ) at ω′, there exists δ > 0 such that |f (ω′′; γ) − f (ω′; γ)| ≤ ǫ/2 for all ω′′ such that
|ω′′ − ω′| ≤ δ. According to (Brockwell & Davis, 1991, p.71) there exists an integer m such that, for all
n ≥ m

(cid:12)
(cid:12)

(cid:12)
(cid:12)

δ
2 ≤|λ|≤π
We then have for ω′′ such that |ω′′ − ω′| ≤ δ/2

Z

|Fn(λ)|dλ ≤

ǫ
2kf k∞

.

f n(ω′′; γ) − f (ω′; γ)

=

(cid:12)
(cid:12)

(cid:12)
(cid:12)

≤

+

π

Z

−π
δ
2

− δ
2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
Z

{f (ω′′ − λ; γ) − f (ω′; γ)} Fn(λ)dλ
(cid:12)
(cid:12)
(cid:12)
(cid:12)

|f (ω′′ − λ; γ) − f (ω′; γ)||Fn(λ)|dλ

|f (ω′′ − λ; γ) − f (ω′; γ)||Fn(λ)|dλ.

δ
2 ≤|λ|≤π

Z

Observing that for |λ| ≤ δ/2 (in the ﬁrst integral of the above equation) and given our choice of ω′′, we have
by the triangle inequality |(ω′′ − λ) − ω′| ≤ |ω′′ − ω′| + |λ| ≤ δ, such that |f (ω′′ − λ; γ) − f (ω′; γ)| ≤ ǫ/2
and thus we obtain

f n(ω′′; γ) − f (ω′; γ)

≤

(cid:12)
(cid:12)

This concludes the proof.

(cid:12)
(cid:12)

ǫ
2

δ
2

− δ
2

Z

|Fn(λ)|dλ + kf k∞

|Fn(λ)|dλ ≤

ǫ
2

+

ǫ
2

= ǫ.

δ
2 ≤|λ|≤π

Z

Lemma 5. Recalling the deﬁnition of D(n)

γ, f n(·; θ)

in (18), we have that

Proof. We have

Deﬁne

D(n)

γ, f n(·; θ)

(cid:8)

(cid:9)

(cid:8)
→

1
2π

π

(cid:9)
log f (ω; γ) +

−π (cid:26)
Z

f (ω; θ)
f (ω; γ)

dω.

(cid:27)

D(n)

γ, f n(·; θ)

=

(cid:8)

(cid:9)

1
n

log f n(ω; γ) +

Xω∈Ωn (cid:26)

f n(ω; θ)
f n(ω; γ)

.

(cid:27)

gn(ω) = log f n {kn(ω); γ} +

f n {kn(ω); θ}
f n {kn(ω); γ}

,

(20)

17

where kn(ω) = ⌊nω⌋

n , i.e. kn(ω) corresponds to the closest smaller Fourier frequency to ω. Then,

D(n)

γ, f n(ω; θ)

=

π

gn(ω)dω.

−π

Z

(cid:8)

(cid:9)
We shall now use the bounded convergence theorem, for which we need to show that gn(ω) converges almost
everywhere. We recall f (ω; θ) is continuous almost everywhere. Now take ω′ ∈ [−π, π] such that f (ω; θ) is
continuous at ω′. Let ǫ > 0. Using Lemma 4, there exists δ and an integer m such that, for all ω′′ satisfying
|ω′′ − ω′| ≤ δ, and for all n ≥ m, |f n(ω′′) − f (ω′)| ≤ ǫ.

Additionally, kn(ω′) converges to ω′ when n goes to inﬁnity, such that there exists an integer p such
that |kn(ω′) − ω′| ≤ δ for n ≥ p. Therefore, eventually in n, we have |f n {kn(ω′); θ} − f (ω′; θ)| ≤ ǫ.
Thus, f n {kn(ω′); θ} converges to f (ω′; θ). As we have shown this for almost every ω′ ∈ [−π, π], we
have proved the point-wise convergence of f n {kn(ω); θ} to f (ω; θ) almost everywhere with respect to ω
on [−π, π]. The same reasoning shows the point-wise convergence of f n {kn(ω); γ} to f (ω; γ) and that of
log f n {kn(ω); γ} to log f (ω; γ) almost everywhere with respect to ω on [−π, π], as f (ω; γ) and f n(ω; γ)
are bounded below. As the ﬁnite intersection of Lebesgue sets each having measure 2π is a Lebesgue set
with measure 2π, gn(ω) converges point-wise almost everywhere to the integrand of the right-hand-side
of (20). Moreover, gn(ω) is clearly upper bounded in absolute value by an integrable function according
to Lemma 1, such that we can apply the dominated convergence theorem and conclude that the sum on the
left-hand-side of (20) converges to the integral on the right-hand-side of (20) as n goes to inﬁnity.

Lemma 6. If γ ∈ Θ and if {γn}n∈N ∈ ΘN is a sequence of parameter vectors converging to γ, then it
follows that

D(n)

γn, f n(ω; θ)

→

1
2π

π

log f (ω; γ) +

−π (cid:26)
Z

f (ω; θ)
f (ω; γ)

dω.

(cid:27)

(cid:8)

(cid:9)

Proof. By the triangle inequality and having proved Lemma 5 we only need to prove that

converges to zero. This quantity can be written as

(cid:8)

(cid:9)

(cid:8)

(cid:9)

D(n)

γn, f n(·; θ)

− D(n)

γ, f n(·; θ)

,

1
n

Xω∈Ωn (cid:20)

log f n(ω; γn) − log f n(ω; γ) + f n(ω; θ)

1
f n(ω; γn)

−

1
f n(ω; γ)

,

(cid:27)(cid:21)

(cid:26)

which converges to zero because of the upper bound on the absolute derivative of ∂f n(ω; γ)/∂γ and lower
bound for f n(ω; γ).
Lemma 7. If {γn}n∈N ∈ ΘN is a sequence of parameter vectors such that D
converges to zero when n goes to inﬁnity, then γn converges to θ.

γn, f n(·; θ)

θ, f n(·; θ)

−D

(cid:0)

(cid:1)

(cid:0)

(cid:1)

Proof. Let (γn)n∈N be a sequence of parameter vectors such that

D(n)

γn, f n(·; θ)

− D(n)

θ, f n(·; θ)

→ 0.

(21)

We assume, with the intent to reach a contradiction, that the sequence (γn) does not converge to θ. By
compactness of Θ, there exists an increasing function from the set of positive integers to the set of positive
integers, denoted φ, and γ ∈ Θ distinct from θ, such that the sequence γφ(n) converges to γ as n goes to
inﬁnity.

(cid:9)

(cid:8)

(cid:9)

(cid:8)

18

Using Lemma 6, we have that

Dφ(n)

γφ(n), f φ(n)(·; θ)

→

n

o

1
2π

π

log f (ω; γ) +

−π (cid:26)
Z

f (ω; θ)
f (ω; γ)

dω.

(cid:27)

Similarly,

Dφ(n)

θ, f φ(n)(·; θ)

→

π

{log f (ω; θ) + 1} dω.

1
2π

−π

n

Z
As f (ω; γ) and f (ω; θ) are, by Assumption 3, distinct on a non-zero Lebesgue subset of [−π, π],
and using the properties of the function x → x − log x from Lemma 2, we have that the expression
π
−π {log f (ω; θ) + 1} dω, and
(1/2π)
this is a contradiction with (21). Therefore the sequence γn must converge to θ, and this concludes the
R
proof.

π
−π {log f (ω; γ) + f (ω; θ)/f (ω; γ)} dω is strictly larger than (1/2π)
R

o

We now show that the functions D

and D {γ, I(ω)}, deﬁned on Θ, are asymptotically
equivalent. For this, we ﬁrst need the following lemma where we bound the asymptotic variance of linear
(cid:9)
combinations of the periodogram, a result previously established in (Giraitis & Koul, 2013, Theorem 3.1)
and Guillaumin et al. (2017) under different sets of assumptions.

γ, f n(ω; θ)

(cid:8)

Lemma 8. Assume that {Xt} is an inﬁnite sequence obtained from sampling a zero-mean continuous-time
real-valued process X(t; θ) with a spectral density f (ω; θ) that is bounded above by the ﬁnite value fmax.
Additionally, assume that the deterministic function an(ω) has a magnitude that is bounded above by an,max
for all ω ∈ Ω. Then linear combinations of values of the periodogram, I(ω), at different frequencies, have
a variance that is upper bounded by

var

1
n

(

Xω∈Ω

an(ω)I(ω)

)

≤

n,maxf 2
a2
n

max

.

Proof. By deﬁnition, for ω, ω′ ∈ Ω

cov {I(ω), I(ω′)} = E {I(ω)I(ω′)} − E {I(ω)} E {I(ω′)} .

Then, using the fact that the Fourier transform of a Gaussian process is also Gaussian, we may use Isserlis’
theorem (Isserlis, 1918) and so obtain that

E {I(ω)I(ω′)} = E {J(ω)J ∗(ω)J(ω′)J ∗(ω′)}

= E {J(ω)J ∗(ω)} E {J(ω′)J ∗(ω′)} + E {J(ω)J ∗(ω′)} E {J(ω′)J ∗(ω)} ,

where J(ω) is the Discrete Fourier Transform. Thus it follows that

cov {I(ω), I(ω′)} = E {J(ω)J ∗(ω′)} E {J(ω′)J ∗(ω)} = |cov {J(ω), J(ω′)}|2 ≥ 0.

(22)

Recalling that C(θ) = E {XX T}, and after deﬁning the vector G(ω) = [exp(iωt)]T for t = 1, . . . , n, such
that J(ω) = (1/n1/2)GH(ω)X, then we can represent the covariance of the Fourier transform as given by

cov {J(ω), J(ω′)} = E {J(ω)J ∗(ω′)} =

1
n

E {GH(ω)XX TG(ω′)} =

1
n

GH(ω)C(θ)G(ω′).

(23)

19

Substituting (23) into (22), it follows that

cov {I(ω), I(ω′)} =

=

1
n2 GH(ω)C(θ)G(ω′) {GH(ω)C(θ)G(ω′)}
1
n2 GH(ω)C(θ)G(ω′)GH(ω′)C H(θ)G(ω),

H

(24)

and so (24) is a positive quadratic form. We note that an(ω)an(ω′) ≤ |an(ω)an(ω′)| ≤ a2
these relationships, given (22), imply that

n,max. Therefore

var

1
n

(

Xω∈Ω

an(ω)I(ω)

)

=

≤

≤

=

1
n2

a2
n,max
n2

a2
n,max
n4

a2
n,max
n4

Xω∈Ω Xω′∈Ω

an(ω)an(ω′) cov {I(ω), I(ω′)}

cov {I(ω), I(ω′)}

Xω∈Ω Xω′∈Ω

Xω∈Ω Xω′∈Ω

GH(ω)C(θ)G(ω′)GH(ω′)C H(θ)G(ω)

GH(ω)C(θ)

G(ω′)GH(ω′)

)

(

Xω′∈Ω

Xω∈Ω

C H(θ)G(ω).

(25)

It can then easily be veriﬁed that

G(ω′)GH(ω′) = nIn,

where In is the n × n identity matrix and Ω is given in (7). This follows as any off-diagonal term

Xω′∈Ω

ω∈Ω exp {iω(t − s)} = 0 for t 6= s. Therefore (25) simpliﬁes to

P

var

1
n

(

Xω∈Ω

an(ω)I(ω)

)

≤

a2
n,max
n3

Xω∈Ω

GH(ω)C(θ)C H(θ)G(ω).

(26)

The matrix C(θ) is Hermitian, so it can be written U DU H where U is unitary and D is the diagonal matrix
consisting of the set of n eigenvalues {ηk}, such that

GH(ω)C(θ)C H(θ)G(ω) = GH(ω)U DU HU DHU HG(ω) = GH(ω)U DDHU HG(ω)
maxGH(ω)U U HG(ω) = η2

maxkG(ω)k2

2 = η2

maxn,

≤ η2

(27)

where ηmax denotes the maximal eigenvalue of {ηk}, and the last equality uses that kG(ω)k2
2 = n. It is well
known that for a Toeplitz covariance matrix C(θ) with eigenvalues {ηk} and associated with the spectral
density f (ω), then ηmax < fmax, see for example (Lee & Messerschmitt, 1988, p. 384). Therefore, by
combining (26) and (27) it follows that

var

1
n

(

Xω∈Ω

an(ω)I(ω)

)

≤

a2
n,max
n3

Xω∈Ω

ηmaxn ≤

n,maxf 2
a2
n

max

,

as |Ω| = n, thus yielding the desired result.

20

Remembering that f n(ω; θ) = E {I(ω)}, we thus have

an(ω)I(ω) =

1
n

Xω∈Ω

1
n

Xω∈Ω

an(ω)f n(ω; θ) + OP

.

n−1/2
(cid:16)

(cid:17)

We are now able to state a consistency theorem for our estimator ˆθ.

Proposition 1. Assume that {Xt} is an inﬁnite sequence obtained from sampling a zero-mean continuous-
time real-valued process X(t; θ) which satisﬁes Assumptions (1–5). Then the estimator

ˆθ = arg max
θ∈Θ

ℓD(θ),

for a sample {Xt}n

t=1, where ℓD(θ) is the de-biased Whittle likelihood of (8), satisﬁes

ˆθ P−→ θ.

Proof. Denote h

(n)

(γ; θ) = D

γ, f n(ω; θ)

and ˆh(n)(γ) = D {γ, I(ω)} deﬁned for any γ ∈ Θ. We have

(cid:8)
(γ; θ) − ˆh(n)(γ) =

(n)

h

=

1
n

1
n

(cid:9)
log f n(ω; γ) +

Xω∈Ω (cid:26)

Xω∈Ω

f n(ω; θ) − I(ω)
f n(ω; γ)

− log f n(ω; γ) −

I(ω)
f n(ω; γ)

(cid:27)

f n(ω; θ)
f n(ω; γ)

.

We have shown in Lemma 1 that f n(ω; γ) is bounded below in both variables ω and γ by a positive real
number, independently of n. Therefore, making use of Lemmas 1 and 8 we have

(n)

h

sup
γ∈Θ

(cid:12)
(cid:12)
(cid:12)

(γ; θ) − ˆh(n)(γ)
(cid:12)
(cid:12)
(cid:12)

P−→ 0, (n → ∞),

where P−→ indicates that the convergence is in probability, as the difference is of stochastic order n−
particular (28) implies that

i.e.

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(n)

min
γ

h

(γ; θ) − min

γ

(n)

h

T (n)

f n(ω; θ)

ˆh(n)(γ)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
; θ

≤ sup
γ∈Θ

(cid:12)
(cid:12)
(cid:12)
− ˆh(n)

P−→ 0,

(n)

h

(γ; θ) − ˆh(n)(γ)
(cid:12)
(cid:12)
(cid:12)
−→ 0.

P

T (n) {I(ω)}
h

h
Relation (28) also implies that

(cid:12)
(cid:12)
(cid:12)

(cid:8)

i

(cid:9)

(n)

h

T (n) {I(ω)} ; θ

− ˆh(n)

T (n) {I(ω)}

h
such that using the triangle inequality, (29) and (30), we get

i

h

(cid:12)
(cid:12)
(cid:12)

i(cid:12)
(cid:12)
(cid:12)

i(cid:12)
(cid:12)
(cid:12)
P−→ 0,

(n)

h

T (n) {I(ω)} ; θ

(n)

− h

T (n)

f n(ω; θ)

; θ

P−→ 0.

We then obtain the stated proposition making use of Lemmas 3 and 7.

i

h

(cid:8)

h

(cid:12)
(cid:12)
(cid:12)

(cid:9)

i(cid:12)
(cid:12)
(cid:12)

21

(28)

1

2 . In

(29)

(30)

Before proceeding to prove optimal convergence rates of de-biased Whittle estimates (Theorem 1), we

require one further lemma.

Lemma 9. Assume that {Xt} is an inﬁnite sequence obtained from sampling a zero-mean continuous-time
real-valued process X(t; θ) which satisﬁes Assumptions (1–5). Then the pseudo-likelihood ℓD(θ), deﬁned
in (8), has ﬁrst and second derivatives in each component of θ, denoted θi, for i = 1, . . . , p, that satisfy

and

respectively, where

1
n

∂ℓD(θ)
∂θi

= OP

n−1/2

,

(cid:16)

(cid:17)

1
n

∂2ℓD(θ)
∂θ2
i

+

1
n

2

∂f n(ω;θ)
∂θi

n

o
2
n (ω; θ)

f

Xω∈Ω

= OP

n−1/2

,

(cid:16)

(cid:17)

2

∂f n(ω;θ)
∂θi

n

o
2
n (ω; θ)

f

1
n

Xω∈Ω

= Θ(1).

Proof. We start by evaluating the score directly from (8)

1
n

∂ℓD(θ)
∂θi

= −

1
n

∂
∂θi

Xω∈Ω (

log f n (ω; θ) −

∂f n (ω; θ)
∂θi

I (ω)
2
n (ω; θ) )

.

f

If we take the expectation of (31) then, recalling that f n(ω; θ) = E {I(ω)},

E

1
n

(cid:26)

∂ℓD(θ)

∂θi (cid:27)

= −

1
n

∂
∂θi

Xω∈Ω (

log f n (ω; θ) −

∂
f n (ω; θ)
∂θi
f n (ω; θ) )

= 0.

(31)

(32)

Note that for ﬁnite sample sizes in general E {I(ω)} 6= f (ω; θ), so the expectation of the score would not
exactly be zero for the standard Whittle likelihood.
Furthermore, using Lemma 8 with an(ω) =

2
n(ω; θ), the variance of the score

∂f n (ω; θ) /∂θi

/f

takes the form of

var

1
n

(cid:26)

∂ℓD(θ)

∂θi (cid:27)

= var

1
n

(

Xω∈Ω

(cid:8)

(cid:9)

∂f n (ω; θ)
∂θi

I(ω)
2
n(ω; θ) )

f

≤

maxk ∂f n
f 2
∂θi
nf 4

min

k2
∞

,

(33)

where k∂f n/∂θik∞ = supω
conclude using Chebyshev’s inequality (Papoulis, 1991, pp.113–114) that we can ﬁx C > 0 such that

and fmin ≤ f n(ω; θ) from Lemma 1. We can therefore

∂f n(ω; θ)/∂θi

where Pr{·} denotes the probability of the argument. We may therefore deduce that





Pr

1
n




∂ℓD(θ)
∂θi

≥ C

fmaxk ∂f n
k∞
∂θi
n1/2f 2
min 


≤

1
C2 ,

(cid:8)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:9)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
n

∂ℓD(θ)
∂θi

= OP

n−1/2

.

(cid:16)

(cid:17)

22

Next we examine the Hessian. Again from (8) we have

∂2ℓD(θ)
∂θ2
i

= −

Xω∈Ω (cid:26)

= −



Xω∈Ω




∂2
∂θ2
i

log f n (ω; θ) +

∂2
∂θ2
i

−1
n (ω; θ) I (ω)

f

(cid:27)

2

∂

f n(ω;θ)
∂θ2
i
f n (ω; θ)

2

∂f n(ω;θ)
∂θi

n

o
2
n (ω; θ)

f

−

2

∂f n(ω;θ)
∂θi

n

o
3
n (ω; θ)

f

−

2

∂

f n(ω;θ)
∂θ2
i

2
n (ω; θ)

f

I (ω) ,






−






Xω∈Ω

2






thus as E {I(ω)} = f n(ω; θ) it follows that

E

1
n

(cid:26)

∂2ℓD(θ)
∂θ2

i (cid:27)

= −

1
n

Xω∈Ω

2

∂f n(ω;θ)
∂θi

(cid:16)

(cid:17)
2
n (ω; θ)

f

.

As f n(ω; θ) is bounded above and below (from Lemma 1), and
also bounded below at Θ(n) frequencies (using Assumption 2) we have

∂f n (ω; θ) /∂θi

(cid:8)

(34)

is bounded above and

2

(cid:9)

2

∂f n(ω;θ)
∂θi

n

o
2
n (ω; θ)

f

−

1
n

Xω∈Ω

= Θ(1).

(35)

Furthermore, we have that,

var

1
n

(cid:26)

∂2ℓD(θ)
∂θ2

i (cid:27)

1
n

= var 


We deﬁne



∂f n(ω;θ)
∂θi

n

3
o
n (ω; θ)

f

2

−

2

∂

f n(ω;θ)
∂θ2
i

2
n (ω; θ)

f

Xω∈Ω

2










.

I (ω)




Sn (θ) = sup
ω

2

∂f n(ω;θ)
∂θi

o
3
n (ω; θ)

−

2

∂

f n(ω;θ)
∂θ2
i

2
n (ω; θ)

f

.

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2

f

n

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
∂2ℓD(θ)
∂θ2

In this instance we can bound the variance, using Lemma 8, by

(cid:26)
We can therefore conclude from (34)–(36), and using Chebyshev’s inequality, that

i (cid:27)

var

1
n

Sn

≤

2 (θ) f 2
n

max

.

(36)

Pr 


1
n (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

This yields the second result.



∂2ℓD(θ)
∂θ2
i

+

1
n

Xω∈Ω

2

∂f n(ω;θ)
∂θi

n

o
2
n (ω; θ)

f

≥ C ·

Sn (θ) fmax

n1/2 


≤

1
C2 .



(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Lemma 9 shows the order of the ﬁrst and second derivative of ℓD(θ). Mutatis mutandis we can show
the corresponding results hold for ∇ℓD(θ) and H(θ), the Hessian matrix. We have now proved the ancillary
results required to prove Theorem 1.

23

Proof. We let the p-vector θ′ lie in a ball centred at the p-vector θ with radius kˆθ − θk (this is a shrinking
radius as Proposition 1 has shown consistency). We additionally deﬁne the p × p Hessian matrix H(θ),
having entries given by

Hij (θ) =

∂2ℓD(θ)
∂θi∂θj

.

Then as Proposition 1 has shown ˆθ P→ θ we can write for some kθ − θ′k ≤ kθ − ˆθk, applying the Taylor
expansion of (Brockwell & Davis, 1991, p.201),

ˆθ
(cid:16)
(cid:17)
We shall now understand the terms of this expression better. We note directly that

∇ℓD (θ) +

H (θ′)

ˆθ − θ

∇ℓD

=

(cid:16)

(cid:17)

.

1
n

1
n

1
n

(37)

Hij(θ) = −

∂

f

2

f n(ω;θ)
∂θi∂θj
2
n (ω; θ)

Xω∈Ω

f n (ω; θ) − I (ω)

−

(cid:8)

Xω∈Ω

(cid:9)

∂f n(ω;θ)
∂θj

∂f n(ω;θ)
∂θi
3
n (ω; θ)

f

2I (ω) − f n (ω; θ)

.

(38)

(cid:8)

(cid:9)

We see from this expression, coupled with Lemma 8 and Chebyshev’s inequality, that

∂

f

2

f n(ω;θ)
∂θi∂θj
2
n (ω; θ)

1
n

Xω∈Ω

I (ω) −

1
n

∂

f

2

f n(ω;θ)
∂θi∂θj
2
n (ω; θ)

Xω∈Ω

f n (ω) P→ 0,

such that the limiting behaviour of the second partial derivatives need not be determined, as they are by
assumption ﬁnite (Assumption 5). Then if we deﬁne

and by taking expectations of (38) we see that

Hn(θ) ≡

1
n

E {H(θ)} ,

Hn,ij(θ) = −

1
n

Xω∈Ω

∂f n(ω;θ)
∂θj

∂f n(ω;θ)
∂θi
2
n (ω; θ)

f

= O(1),

as we have already noted that both f
per Lemma 9. Furthermore,

−2
n (ω; θ) and ∂f n(ω; θ)/∂θi are bounded and Riemann integrable as

Hn,ii(θ) = −

2

∂f n(ω;θ)
∂θi

(cid:16)

2
(cid:17)
n (ω; θ)

f

1
n

Xω∈Ω

= Θ(1),

2
n (ω; θ) is bounded above and below independently of n, and

as f
bounded below for Θ(n) frequencies (from Assumption 5).

∂f n (ω; θ) /∂θi

2

is bounded above, and

We also note that the elements of the matrix H(θ) take the form of linear combinations of I(ω) and so

the element-wise extension of Lemma 8 applies. This means

1
n

H(θ) = Hn(θ) + OP (n−1/2).

24

(39)

(cid:0)

(cid:1)

From Proposition 1 we then observe that

kθ − θ′k ≤ kθ − ˆθk = oP (1).

By applying the Taylor expansion of (Brockwell & Davis, 1991, p.201), we observe that

f n (ω; θ′) = f n (ω; θ) + oP (1),

∂f n (ω; θ′)
∂θi

=

∂f n (ω; θ)
∂θi

+ oP (1),

where neither of the oP (1) terms depend on ω or n because of the upper bound on the magnitude of the ﬁrst
and second derivatives of f n (ω; θ) with respect to θ in Assumption 5. Therefore, and because f n (ω; θ) is
bounded below from Assumption 2,

1
n

∂f n(ω;θ
∂θi

′)

∂f n(ω;θ
∂θj
2
n (ω; θ′)

′)

=

1
n







Xω∈Ω

f

since θ′ converges to θ. Writing the Hessian at θ′ as




Xω∈Ω






∂f n(ω;θ)
∂θi
2

∂f n(ω;θ)
∂θj

f

n (ω; θ) 


+ oP (1),

where

1
n

Hij(θ′) =

1
n

Xω∈Ω





Mn(ω; θ′)

f n (ω; θ′) − I(ω)

+

(cid:8)

(cid:9)

∂

2

f n(ω;θ
∂θi∂θj

′)

Mn(ω; θ′) =

∂f n(ω;θ
∂θi

f n (ω; θ′) − 2
3
n (ω; θ′)

f



′)

′)

∂f n(ω;θ
∂f n(ω;θ
∂θi
∂θj
f n (ω; θ′)

,





′)

∂f n(ω;θ
∂θj

′)

,

is bounded according to our set of assumptions, we then observe using the triangle inequality that

Xω∈Ω
1
n

Xω∈Ω

1
n

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
=

≤

1
n

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Mn(ω; θ′)

f n (ω; θ′) − I(ω)

(cid:8)
Mn(ω; θ′)

f n (ω; θ′) − f n (ω; θ) + f n (ω; θ) − I(ω)

(cid:9)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Mn(ω; θ′)

(cid:8)
f n (ω; θ′) − f n (ω; θ)

+

1
n

(cid:9)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Mn(ω; θ′)

f n (ω; θ′) − I(ω)

.

Xω∈Ω

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:9)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
The ﬁrst sum converges to zero in probability given the bound of the derivative of f n (ω; θ) with respect to
(cid:12)
(cid:12)
θ from Assumption 5, and the second sum converges to zero according to Lemma 8. It follows that

Xω∈Ω

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:8)

(cid:8)

(cid:9)

1
n

H (θ′) −

1
n

H (θ) = oP (1).

(40)

25

Starting from (37), using Lemma 9, and substituting in (39) and (40) we obtain

ˆθ − θ = −

1
n

(cid:26)

H (θ) + oP (1)

∇ℓD (θ)

−1 1
n

(cid:27)
n−1/2

= −

Hn(θ) + OP

−1

+ oP (1)

OP

n−1/2

n
= Hn(θ)−1

(cid:17)
(cid:16)
I + oP (1) + OP

o
n−1/2

n
OP

(cid:16)
n−1/2

(cid:17)o

= OP

n
n−1/2

,

(cid:16)

(cid:17)o n

(cid:16)

(cid:17)o

(cid:16)
which yields the result we require.

(cid:17)

References

ANITESCU, M., CHEN, J. & STEIN, M. L. (2016). An inversion-free estimating equations approach for

Gaussian process models. J. Comput. Graph. Stat. 26, 98–107.

ANITESCU, M., CHEN, J. & WANG, L. (2012). A matrix-free approach for solving the parametric Gaussian

process maximum likelihood problem. SIAM J. Sci. Comput. 34, A240–A262.

BLOOMFIELD, P. (1976). Fourier analysis of time series: an introduction. John Wiley.

BRILLINGER, D. R. (2001). Time series: data analysis and theory. SIAM.

BROCKWELL, P. J. & DAVIS, R. A. (1991). Time series: theory and methods. Springer.

CHOUDHURI, N., GHOSAL, S. & ROY, A. (2004). Contiguity of the Whittle measure for a Gaussian time

series. Biometrika 91, 211–218.

CONTRERAS-CRISTAN, A., GUTI ´ERREZ-PE ˜NA, E. & WALKER, S. G. (2006). A note on Whittle’s likeli-

hood. Commun. Stat.-Simul. C. 35, 857–875.

DAHLHAUS, R. (1988). Small sample effects in time series analysis: A new asymptotic theory and a new

estimate. Ann. Stat. 16, 808–841.

DUTTA, S. & MONDAL, D. (2015). An h-likelihood method for spatial mixed linear models based on

intrinsic auto-regressions. J. R. Statist. Soc. B 77, 699–726.

DZHAPARIDZE, K. O. & YAGLOM, A. M. (1983). Spectrum parameter estimation in time series analysis.

In Developments in Statistics, P. R. Krishnaiah, ed. Academic Press, Inc., pp. 1–96.

ELIPOT, S., LUMPKIN, R., PEREZ, R. C., LILLY, J. M., EARLY, J. J. & SYKULSKI, A. M. (2016). A

global surface drifter data set at hourly resolution. J. Geophys. Res. Oceans 121, 2937–2966.

FAN, J., QI, L. & XIU, D. (2014). Quasi-maximum likelihood estimation of GARCH models with heavy-

tailed likelihoods. J. Bus. Econ. Stat. 32, 178–191.

FUENTES, M. (2007). Approximate likelihood for large irregularly spaced spatial data. J. Am. Stat. Soc.

102, 321–331.

26

GIRAITIS, L. & KOUL, H. L. (2013). On asymptotic distributions of weighted sums of periodograms.

Bernoulli 19, 2389–2413.

GRIFFA, A., KIRWAN, A. D., MARIANO, A. J., ¨OZG ¨OKMEN, T. & ROSSBY, T. (2007). Lagrangian

analysis and prediction of coastal and ocean dynamics. Cambridge University Press.

GUILLAUMIN, A. P., SYKULSKI, A. M., OLHEDE, S. C., EARLY, J. J. & LILLY, J. M. (2017). Analysis
of non-stationary modulated time series with applications to oceanographic surface ﬂow measurements.
Journal of Time Series Analysis 38, 668–710.

GUINNESS, J. & FUENTES, M. (2017). Circulant embedding of approximate covariances for inference

from Gaussian data on large lattices. J. Comput. Graph. Stat. 26, 88–97.

ISSERLIS, L. (1918). On a formula for the product-moment coefﬁcient of any order of a normal frequency

distribution in any number of variables. Biometrika 12, 134–139.

JESUS, J. & CHANDLER, R. E. (2017). Inference with the Whittle likelihood: A tractable approach using

estimating functions. J. Time Ser. Anal. 38, 204–224.

KRAFTY, R. T. & COLLINGE, W. O. (2013). Penalized multivariate Whittle likelihood for power spectrum

estimation. Biometrika 100, 447–458.

LEE, E. A. & MESSERSCHMITT, D. G. (1988). Digital communication. Kluwer Academic Publishers,

Boston.

LILLY, J. M., SYKULSKI, A. M., EARLY, J. J. & OLHEDE, S. C. (2017). Fractional Brownian motion, the
Mat´ern process, and stochastic modeling of turbulent dispersion. Nonlinear Proc. Geoph. 24, 481–514.

MARPLE, S. L. (1999). Computing the discrete-time “analytic” signal via FFT. IEEE T. Signal Proces. 47,

2600–2603.

MAT ´ERN, B. (1960). Spatial Variation: Stochastic Models and Their Application to Some Problems in

Forest Surveys and Other Sampling Investigations. Statens Skogsforskningsinstitut.

MATSUDA, Y. & YAJIMA, Y. (2009). Fourier analysis of irregularly spaced data on Rd. J. R. Statist. Soc. B

71, 191–217.

PAPOULIS, A. (1991). Probability, random variables, and stochastic processes. McGraw-Hill, Inc.

PAWLOWICZ, R., BEARDSLEY, B. & LENTZ, S. (2002). Classical tidal harmonic analysis including error

estimates in MATLAB using T TIDE. Computers & Geosciences 28, 929–937.

PERCIVAL, D. B. & WALDEN, A. T. (1993). Spectral Analysis for Physical Applications: Multitaper and

conventional univariate techniques. Cambridge University Press.

SCHREIER, P. J. & SCHARF, L. L. (2010). Statistical signal processing of complex-valued data: the theory

of improper and noncircular signals. Cambridge University Press.

SERROUKH, A. & WALDEN, A. T. (2000). Wavelet scale analysis of bivariate time series ii: statistical

properties for linear processes. J. Nonparametr. Stat. 13, 37–56.

SLEPIAN, D. & POLLAK, H. O. (1961).
uncertainty–I. Bell Syst. Tech. J. 40, 43–63.

Prolate spheroidal wave functions, Fourier analysis and

27

STEIN, E. M. & SHAKARCHI, R. (2003). Fourier analysis: an introduction. Princeton University Press.

SYKULSKI, A. M., OLHEDE, S. C., LILLY, J. M. & DANIOUX, E. (2016). Lagrangian time series models

for ocean surface drifter trajectories. J. R. Statist. Soc. C 65, 29–50.

TANIGUCHI, M. (1979). On estimation of parameters of gaussian stationary processes. J. Appl. Probab. 16,

575–591.

TANIGUCHI, M. (1983). On the second order asymptotic efﬁciency of estimators of Gaussian ARMA

processes. Ann. Stat. 11, 157–169.

THOMSON, D. J. (1982). Spectrum estimation and harmonic analysis. Proc. IEEE 70, 1055–1096.

VELASCO, C. & ROBINSON, P. M. (2000). Whittle pseudo-maximum likelihood estimation for nonstation-

ary time series. J. Am. Stat. Soc. 95, 1229–1243.

WHITTLE, P. (1953). Estimation and information in stationary time series. Ark. Mat. 2, 423–434.

28

