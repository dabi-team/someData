8
1
0
2

n
a
J

4

]

V
C
.
s
c
[

1
v
7
5
5
1
0
.
1
0
8
1
:
v
i
X
r
a

Plan in 2D, execute in 3D: An augmented reality solution for cup
placement in total hip arthroplasty

Javad Fotouhia,*, Clayton P. Alexander, M.D.b, Mathias Unberatha, Giacomo Taylora, Sing Chun Leea,
Bernhard Fuerst 1a, Alex Johnson, M.D.b, Greg Osgood, M.D.b, Russell H. Taylorc, Harpal Khanuja, M.D.b,
Mehran Armandc,d, †, Nassir Navaba,e, †
aJohns Hopkins University, Computer Aided Medical Procedures, 3400 N Charles Street, Baltimore, USA, 21218
bJohns Hopkins Hospital, Department of Orthopaedic Surgery, 1800 Orleans Street, Baltimore, USA, 21287
cJohns Hopkins University, Laboratory for Computational Sensing and Robotics, 3400 N Charles Street, Baltimore, USA, 21218
dJohns Hopkins University Applied Physics Laboratory, 11100 Johns Hopkins Road, Laurel, Maryland, USA, 20723
eTechnische Universit¨at M¨unchen, Computer Aided Medical Procedures, 3 Boltzmannstr, Munich, Germany

Abstract. Reproducibly achieving proper implant alignment is a critical step in total hip arthroplasty (THA) procedures that has been shown to
substantially affect patient outcome. In current practice, correct alignment of the acetabular cup is veriﬁed in C-arm X-ray images that are acquired
in an anterior-posterior (AP) view. Favorable surgical outcome is, therefore, heavily dependent on the surgeon’s experience in understanding the 3D
orientation of a hemispheric implant from 2D AP projection images. This work proposes an easy to use intra-operative component planning system
based on two C-arm X-ray images that is combined with 3D augmented reality (AR) visualization that simpliﬁes impactor and cup placement
according to the planning by providing a real-time RGBD data overlay. We evaluate the feasibility of our system in a user study comprising four
orthopedic surgeons at the Johns Hopkins Hospital, and also report errors in translation, anteversion, and abduction as low as 1.98 mm, 1.10◦,
and 0.53◦, respectively. The promising performance of this AR solution shows that deploying this system could eliminate the need for excessive
radiation, simplify the intervention, and enable reproducibly accurate placement of acetabular implants.

Keywords: intra-operative planning, X-ray, augmented reality, RGBD camera, total hip arthroplasty.

* javad.fotouhi@jhu.edu
† Mehran Armand and Nassir Navab are joint senior authors listed in alphabetical order

1 Introduction

1.1 Clinical Background

In total hip arthroplasty (THA), also referred to as total hip replacement, the damaged bone and cartilage are replaced

with prosthetic components. The procedure relives pain and disability with a high success rate. In 2010, there were
approximately 330,000 THAs performed in the US. This is projected to increase to 570,000 THAs by 20301 as younger
patients and patients in developing countries are considered for THA. Together with a prolonged life expectancy, the

consideration of younger, more active patients for THA suggests that implant longevity is of increasing importance
as it is associated with the time to revision arthroplasty.1 The time to repeat surgery is affected by the wear of the
implants that is correlated with their physical properties as well as acetabular component positioning. Poor placement

leads to increased impingement and dislocation that promotes accelerated wear. Conversely, proper implant placement

that restores the hip anatomy and biomechanics decreases the risk for dislocation, impingement, loosening, and limb
length discrepancy, and thus implant wear and revision rate.2–6 Steps to ensure accuracy and repeatability of acetabular
component positioning are therefore essential. Due to the large volume of THA procedures, small but favorable

changes to the risk-beneﬁt proﬁle of this procedure enabled by improved implant positioning will have a signiﬁcant

impact on a large scale.

Unfortunately, optimal placement of the acetabular component is challenging due to two main reasons. First, the
ideal position of the implant with respect to the anatomy is unknown; yet, a general guideline exists7 and is widely
accepted in clinical practice. This guideline suggests abduction and anteversion angles of the hip joint measured with

respect to bony landmarks deﬁning the so-called safe zone, that is indicative for an acceptable outcome. Recent studies
suggest that an even narrower safe zone may be necessary to minimize the risk of hip dislocation.8, 9 Deﬁning the ideal

1Bernhard Fuerst is now with Verb Surgical Inc.

1

 
 
 
 
 
 
implant position is not as straight-forward as the deﬁnition of a range of abduction and anteversion angles when
considering a large population.10 A static deﬁnition of the safe zone seems even more prone to error when considering
that the position of the pelvis varies dramatically from supine to sitting to standing posture among individuals.11, 12

Second, even if a clinically acceptable safe zone is known it is questionable whether surgeons are, in fact, able
to accomplish acetabular component placement within the suggested margin.9 In light of previous studies that report
mal-positioning of up to 30% to 75%13–15 when free-hand techniques are used, addressing this challenge seems to be
imperative.

Most computer-assisted methods consider the direct anterior approach (DAA) to the hip for THA, as it allows
for convenient integration of intra-operative ﬂuoroscopy to guide the placement of the acetabular component16. The
guidance methods reviewed below proved effective in reducing outliers and variability in component placement, which
equates to more accurate implant positioning.17–20

1.2 Related work:

External navigation systems commonly use certain points on the anatomy of interest, as decided by the surgeon, and

conform to a ”map” of the known morphology of the anatomy of interest. Despite the fact that THA commonly uses X-

ray images for navigation and pre-operative patient CT may not be available, several computer assisted THA solutions
suggest planning the desired pose of the acetabular component pre-operatively on a CT scan of the patient.21, 22 Pre-
operative CT imaging allows planning of the implants in 3D, automatically estimating the orientation of the natural
acetabular opening, and predicting the appropriate size of the cup implant.23

Navigation-based THA with external trackers are performed based on pre-operative patient CT, or image-less

computer assisted approaches. The planning outcome in a CT-based navigation approach is used intra-operatively

with external optical navigation systems to estimate the relative pose of the implant with respect to the patient anatomy

during the procedure. Tracking of the patient is commonly performed using ﬁducials that are drilled into the patient’s

bones. Registration of the pre-operative CT data to the patient on the surgical bed is performed by manually touching
anatomical landmarks on the surface of the patient using a tracked tool.21 In addition to the paired-point transformation
estimated by matching the few anatomical landmarks, several points are sampled on the surface of the pelvis and
matched to the segmentation of the pelvis in the CT data.24 CT-based navigation showed statistically signiﬁcant
improvement in orienting the acetabular component and eliminating malpositioning, while resulting in increased blood
loss, cost, and time for surgery.25, 26 Combined simultaneous navigation of the acetabulum and the femur was used in
10 clinical tests where the surgical outcome based on post-operative imaging showed 2.98 mm and 4.25◦ error in cup
position and orientation, respectively.27

Image-less navigation systems do not require any pre-operatively acquired radiology data. In this method, the

pelvic plane is located in 3D by only identifying anatomical landmarks on the surface of the patient using a tracked
pointer reference tool and optically visible markers attached to the patient.28 This approach showed improvement in
terms of cup positioning.29 However, few number of samples points for registration as well as pelvis tilts resulted in
unreliable registration.30

Robotic systems are developed to provide additional conﬁdence to the surgical team in placing implants during
THA.31, 32 In a robotic system, pins are implanted into the patient’s femur prior to acquiring a pre-operative CT scan.
After the surgeon has performed the planning on the CT data, the robot is introduced into the operating room. To close

the registration loop between patient, robot, and CT volume, each pre-operatively implanted pin is touched by the robot

with manual support. To eliminate the need for ﬁducial implantation, registration is either achieved by selecting several

points on the surface of the bone using a digitizer and using an iterative closest point algorithm to perform registration

2

to patient CT data,33 or by using intra-operative C-arm ﬂuoroscopy and performing 2D/3D registration between the
X-ray image and CT volume.34 After registering the pre-operative CT data to patient, the robot assists the surgeon in
placing the femoral stem and the acetabular component according to the planning. The outcome of 97 robot-assisted
THA procedures indicates performance similar to the conventional technique;35 However, in some cases additional
complications such as nerve damage, post-operative knee effusion, incorrect orientation of the acetabular component,

and deep reaming resulting in leg length discrepancy were reported when the robotic system was used. To assist the

surgeon in placing implants for joint replacement procedures, haptic technology was integrated into robotic solutions
to maintain the orientation of the cup according to pre-operative planning and control the operator’s movement.36

If pre-operative CT is available, intensity-based 2D/3D registration can be used to evaluate and verify the po-
sitioning of the acetabular component post-operatively.22 This is done by recovering the spatial relation between a
post-operative radiograph (2D) and the pre-operative patient CT data (3D), followed by a registration of the 3D CAD

model of the component to the 2D representation of the cup in the post-operative radiograph. To overcome the large

variability in individual patient pelvic orientations, and to eliminate the need for pre-operative 3D imaging, the use of
deformable 2D/3D registration with statistical shape models was suggested.37

Aforementioned solutions perform well but require pre-operative CT which increases the time and cost for surgery
and requires intra-operative registration to the patient.25, 32 Zheng et al. proposed a CT-free approach for navigation
in THA.38 The method relies on tracking of the C-arm, surgical instruments used for placing femoral and acetabular
components, as well as the patient’s femur and pelvis using an external navigation system. Multiple stereo C-arm

ﬂuoroscopy images are acquired intra-operatively. Anatomical landmarks are then identiﬁed both in these X-ray

images as well as percutaneously using a point-based digitizer. Thanks to the tracking of the C-arm, the relative

pose between the X-ray images are known, therefore the anatomical landmarks are triangulated from the images and

reconstructed in 3D. These points are used later to deﬁne the anterior pelvic plane and the center of rotation for the

acetabulum. After estimating the pelvis coordinate frame, the impactor is moved by the surgeon until the cup is at

the correct alignment with respect to a desired orientation in the anterior pelvic plane coordinate frame. This work

reported sub-degree and sub-millimeter accuracy in antetorsion, varus/valgus, and leg length discrepancy. Later, this
system was tested in 236 hip replacement procedures, where a maximum of 5◦ inclination error, and 6◦ anteversion
error were observed.39

The state of the art approaches that provide guidance using image-less or image-based methods have certain draw-
backs. Image-less methods require complex navigation and may provide unreliable registration.30 Image-based so-
lutions rely on pre-operative CT scans or intra-operative ﬂuoroscopy and often use external navigations systems for
tracking.40, 41 Systems based on external navigation are expensive and increase the operative time due to the added
complexity. Use of pre-operative CT scans increases the radiation exposure and cost to the patient. Moreover, many of

the methods used for registering CT to patient seek to solve ill-posed problems that require manual interaction either

for initialization or landmark identiﬁcation and, thus, disrupt the surgical workﬂow. Manual annotations can take be-
tween 3 to 5 minutes during the intervention for each image registration.21 Although proven beneﬁcial for the surgical
outcome, neither of these costly and labor-intensive navigation techniques were widely adopted in clinical practice.

Partly due to above drawbacks, surgeons who use the DAA often rely solely on ﬂuoroscopic image guidance16, 42.
These images, however, are a 2D representation of 3D reality and have inherent ﬂaws that complicate the assessment.

The challenges include ﬁnding the true anterior pelvic plane as well as eyeballing acetabular component position by

eye on the image. Therefore, a technique that provides a quantitative and reliable representation of the pelvis and

acetabular component intra-operatively without increasing neither radiation dose or cost while largely preserving the

procedural workﬂow is highly desirable.

3

Fig 1 After the femoral head is dislocated, the size of the acetabular implant is identiﬁed based on the size of the reamer. Next, two C-arm X-ray
images are acquired from two different perspectives. While the C-arm is repositioned to acquire a new image, the relative poses of the C-arm are
estimated using the RGBD camera on the C-arm and a visual marker on the surgical bed. The surgeon then plans the cup position intra-operatively
based on these two stereo X-ray images simultaneously. Next, the pose of the planned cup and impactor are estimated relative to the RGBD camera.

This pose is used to place the cup in a correct geometric relation with respect to the RGBD camera and visualize it in an AR environment. Lastly,
the surgeon observes real-time optical information from the impactor, and aligns it with the planned impactor using the AR visualization. The green
boxes in this ﬁgure highlight the contributions of this work.

1.3 Proposed solution:

This work proposes an augmented reality (AR) solution for intra-operative guidance of THA using DAA where the
C-arm is kept in place until the correct alignment of the acetabular cup is conﬁrmed43, 44. With the proposed solution,
the surgeon ﬁrst plans the position of the acetabular cup intra-operatively based on two ﬂuoroscopy images that are

acquired after the dislocation of the femoral head and the reaming of the acetabulum are completed. The orientation

of the cup in the X-ray images could be either automatically preset based on desired angles relative to the APP plane

(or other known pelvic coordinate frames), or be adjusted by the surgeon. Once the desired pose of the acetabular cup

is estimated relative to the C-arm, we use optical information from the co-calibrated RGBD camera that is mounted
on the C-arm to provide an AR overlay45–47 that enables placement of the cup according to the planning. As the cup
is not visible in RGBD, we exploit the fact that the acetabular cup is placed using an impactor that is rigidly attached

to the cup and is well perceived by the RGBD camera. For accurate cup placement, the surgeon aligns the optical

information of the impactor (a cloud of points provided by the RGBD camera) with the planned virtual impactor-cup,

that are visualized simultaneously in our AR environment. A schematic of the proposed clinical workﬂow is shown in

Fig. 1.

2 Methodology

The AR environment for THA requires a co-calibrated RGBD-C-arm (Sec. 2.1). Whenever the C-arm is re-positioned,

the RGBD camera on the C-arm tracks and estimates C-arm relative extrinsic parameters (Sec. 2.2). During the

intervention, two X-ray images are recorded at different poses together with the respective extrinsic parameters, and

are used for intra-operative planning of the component (Sec. 2.3). Lastly, an AR environment is provided for the

placement of the cup that comprises of surface meshes of a virtual cup and impactor displayed in the pose obtained

by intra-operative planning, overlaid with the real-time cloud of points from the surgical site acquired by the RGBD

camera (Sec. 2.4).

4

Prosthetic hip replacementImpactor alignmentAligning the cloud of points from the impactor with the planned 3D impactorReaming the acetabulum and removing the articular cartilageIdentifying the size of the acetabular cupDislocation of the femoral headPlacing the acetabular componentImage acquisitionAcquiring two X-ray images from different perspectives (e.g. anterior-posterior and 15°oblique)Intra-operative planningPlacing the acetabular cup simultaneously on two stereo X-ray imagesAR visualizationOverlay of the planned cup and impactor and real-time cloud of points observed by the cameraFig 2 In the transformation chain of the RGBD-C-arm system for THA (a), the RGBD, X-ray, visual marker, and acetabular cup coordinate frames
are denoted as RGBD, X, M, and C, respectively. In an ofﬂine calibration step, the extrinsic relation between the RGBD and X-ray (XTRGBD) is
estimated. Once this constant relation is known, the pose of the X-ray source can be estimated for every C-arm re-positioning (b) by identifying
displacements in the RGBD camera coordinate frame.

2.1 Co-calibration of the RGBD-C-arm imaging devices

The co-calibration of the RGBD camera and the X-ray imaging devices is performed using a multi-modal checkerboard

pattern. In this hybrid checkerboard pattern, each black square is backed with a radiopaque thin metal square of the
same size.48 Calibration data is acquired by simultaneously recording RGB and X-ray image pairs of the checkerboard
at various poses. Next, we estimate the intrinsic parameters for both the RGB channel of the RGBD sensor as well

as for the X-ray imaging device. Using these intrinsic parameters, we estimate the 3D locations of each checkerboard
corner, OCHRGB and OCHX in the RGB and X-ray coordinate frames, respectively. The stereo relation between the
X-ray and RGB imaging devices XTRGB is then estimated via least squares minimization:

min
XTRGB

(cid:107)XTRGBOCHRGB − OCHX(cid:107)2
2 .

(1)

The stereo relation between the RGB and IR (or depth) channel of the RGBD sensor is provided by the manufacturer.
To simplify the notation, we use XTRGBD which embeds the relation between the RGB, depth, and the X-ray imaging
devices. We assume that both extrinsic parameters between X-ray and RGBD and the intrinsic parameters of the X-ray

remain constant, however, both quantities are subject to minor change while the C-arm rotates to different angles, an

observation that is further discussed in Sec. 4. Fig. 2-a illustrates the spatial relation between the RGBD camera and

the X-ray source.

5

XTRGBDX’TXRGBD’TRGBDX-RAY SOURCERGBD CAMERA ON THE DETECTORMTRGBD’MTRGBDXX’RGBDRGBD’CTX’CTXCTRGBDCTRGBD’CX-RAY SOURCERGBD CAMERAa)b)2.2 Vision-based estimation of C-arm extrinsic parameters

The stereo relation between C-arm X-ray images acquired at different poses are estimated by ﬁrst tracking visual

markers in the RGBD camera coordinate frame, and then transforming the tracking outcome to the X-ray coordinate

frame:

X(cid:48)

TX =RGBD(cid:48)

T−1
X(cid:48)

MT−1

RGBD(cid:48)

MTRGBD

RGBDTX ,

(2)

where RGBD(cid:48)
rigid movement of X-ray source with the RGBD camera origin are shown for an arbitrary C-arm orbit.

TX(cid:48) =RGBD TX due to the rigid construction of the RGBD camera on the C-arm gantry. In Fig. 2-b the

2.3 Intra-operative planning of the acetabular cup on two X-ray images

Planning of the acetabular component is performed in a user interface where the cup could be rotated and translated by
the surgeon in 3D with six degrees of freedom (DOF) rigid parameters, and is forward projected (pcv and p(cid:48)
cv ) onto
the planes of the two X-ray images acquired from different perspectives:

pcv = K P CT−1
X
cv = K(cid:48) P CT−1
p(cid:48)
X(cid:48)

Cv TW ,
Cv TW ,

(3)

where K and K(cid:48) are the intrinsic perspective projection parameters for each C-arm image, P is a projection operator,
and Cv TW is the position of vertex v of the cup in the world coordinate frame. Relying on two X-ray views not only
provides the ability to plan the orientation of the acetabular component such that it is aligned in two images but, more

importantly, also allows adjusting the depth of the cup correctly, which is not possible when a single X-ray image is

used. It is worth mentioning, that the size of the acetabular cup does not require adjustment but is known at this stage

of the procedure as it is selected to match the size of the reamer.

In addition, if the desired orientation of the cup is known relative to an anatomical coordinate frame (e.g. APP

plane), and an X-ray image is acquired from a known perspective in relation to that anatomical frame (e.g. AP view),

then the orientation of the cup could be automatically adjusted for the user (equivalent to presetting the orientation
in CTX). It is worth emphasizing that in several image-guided orthopedic procedures, X-ray images are frequently
acquired from the AP view.

The transparency of the cup is adjusted by the surgeon in the user interface such that the ambiguity between the

front and the back of the cup is optimally resolved. Lastly, the contours around the edge of the cup are estimated and
visualized by thresholding the dot product of the unit surface normal nv and the intersecting ray rv:

| rv . nv | < τ .

(4)

The planning of an acetabular cup based on two X-ray images is shown in Fig. 3.

2.4 Augmented-reality visualization

Once the desired cup position is known, guidance of the cup placement using an impactor with an AR visualization is

needed to ensure a positioning in agreement with the planning. To construct the AR environment, we ﬁrst estimate the

pose of the RGBD sensor relative to the planned cup as

CTRGBD =C TX

XTRGBD .

(5)

6

Fig 3 The acetabular component is forward projected from an initial 3D pose onto the respective X-ray image plane (a-b). The surgeon moves the
cup until satisﬁed with the alignment in both views (c-d). The X-ray images shown here are acquired from a dry pelvis phantom encased in gelatin.
A cubic visual marker is placed near the phantom but outside the X-ray ﬁeld of view to track the C-arm (e).

Fig 4 Multiple virtual perspectives of the surgical site are shown to the surgeon (a-b) before the cup is aligned (c). The impactor is then moved by
the user until it completely overlaps with the virtual planned impactor (d-f).

Within the AR environment, we then render a 3D mesh of the cup and impactor superimposed with the real-time cloud

of points observed by the camera, all in the RGBD coordinate frame. In the interventional scenario, the acetabular cup

is hidden under the skin, and only the impactor is visible. Therefore, the surgeon will only align the cloud of points

from the impactor, a cylindrical object, with the 3D virtual representation of the planned impactor.

Ambiguities in the AR environment, among others occlusions or the rendering of a 3D scene in a 2D display,

are eliminated by showing different perspectives of the scene simultaneously. Thus, it is ensured that the surgeon’s

execution fully matches the planning once alignment of the current cloud of points of the impactor and the planned

model is achieved in all perspectives. We provide an intuitive illustration of these relations in Fig. 4.

In order to solely visualize the moving objects (e.g.

the surgeon’s hands and tools), background subtraction of

point clouds is performed with respect to the ﬁrst static frame observed by the RGBD camera. It is important to note

that in an image-guided DAA procedure, most tools other than the impactor, such as retractors, are removed prior to

placing the acetabular component, therefore important details on the ﬂuoroscopy image are not occluded.

7

a)b)c)d)e)August 23, 2017Computer Aided Medical ProceduresSlide 18a)b)c)d)e)f)3D representation of the cup and impactor estimated from planningCloud of points from the impactor and cup heldbythesurgeonImpactorCup3 Evaluation and Results

3.1 System Setup

In DAA for THA the detector is commonly positioned above the surgical bed. This orientation of the C-arm machine

is considered to reduce the scattering to the surgical crew. Therefore, we modiﬁed the C-arm machine by mounting

the RGBD camera near the detector plane of the C-arm which then allows the detector to remain above the bed. The

mount for the RGBD camera extends out from the C-arm detector for nearly 5.00 cm in XY direction (Z being the

principal axis of the X-ray camera) and is screwed to a straight metal plate which is rigidly tied to the image intensiﬁer.

Considering that the RGB camera is used for pose estimation of the C-arm scanner while the depth camera is used

for point cloud observation, the RGBD camera needs to be angled such that a maximum of the surgical site is visible

in both RGB and depth camera views. The RGBD sensor is, therefore, angled such that it has a direct view onto the

surgical site such that the principal axis of the camera is close to the iso-center of the C-arm.

The impactor used for testing is a straight cylindric acetabular trialing from Smith and Nephew. For intra-operative

X-ray imaging, we use an Arcadis Orbic 3D C-arm (Siemens Healthcare GmbH, Forchheim, Germany) with an iso-

centeric design and an image intensiﬁer. The RGBD camera is a short range Intel RealSense SR300 (Intel Corporation,

Santa Clara, CA) which combines depth sensing with HD color imaging. Data transfers from C-arm and the RGBD

camera to the development PC are done via Ethernet and powered USB 3.0 connections, respectively.

The AR visualization is implemented as a plug-in application in ImFusion Suite using the ImFusion software

development kit 2. We use ARToolkit 3 for visual marker tracking.49

3.2 Experimental Results

Stereo co-calibration of the RGBD and X-ray cameras: Ofﬂine stereo co-calibration between the X-ray source

and the RGBD camera using 22 image pairs yields a mean reprojection error of 1.10 pixels. Individual mean repro-

jection errors for X-ray and RGBD cameras are 1.46 and 0.74 pixels, respectively.

Accuracy in tracking X-ray poses: Tracking accuracy is computed by acquiring X-ray images from a phantom with

several radiopaque landmarks and measuring the stereo error between the corresponding landmark points in different

images.

The phantom is constructed by attaching 9 radiopaque mammography skin markers (bbs) with diameters of

1.5 mm, inside and near the acetabulum on a pelvis model as shown in Fig. 5. Next, we acquired 11 X-ray im-
ages from −50◦ to +50◦ along C-arm oblique rotation, and 9 X-ray images from −40◦ to +40◦ on the cranial/caudal
direction, with intervals of 10◦. In the planning software, we placed a virtual sphere with the same diameter as the bbs
on each of the bb landmarks, and measured the distance of the bb in the second image to the epipolar line from the
center of the corresponding virtual sphere in the ﬁrst image. The error distance is measured as 7.58 ± 3.02 pixels4 in
an X-ray image with pixel size of 1024 × 1024 and pixel spacing of 0.22 mm
pixel . In addition, we acquired a cone beam
CT (CBCT) scan of the phantom and measured a root mean square error of 1.37 mm between the bbs in the CT and

those reconstructed using two X-ray images.

2http://imfusion.de/products/imfusion-suite
3https://artoolkit.org/
4values reported as mean ± standard deviation

8

Fig 5 The geometric error is measured using radiopaque bbs viewed in the stereo X-ray images (a-b). The blue line highlights a pair of corresponding
bbs in the two images. The phantom is shown in (c).

Fig 6 An implant cup is placed inside the acetabulum and two X-ray images and a CBCT scan are acquired using the C-arm. (a-b) and (c) are the
X-ray and CBCT images before planning. (d-f) show the overlay of the real and virtual cup after proper alignment.

Planning accuracy in placing the acetabular component using two views:

In order to measure 3D errors and

ensure precise placement of the cup in two X-ray images during planning, we construct a dry phantom where an

implant cup is screwed into the acetabulum. Therefore, the desired implant cup placement is well visible in the X-ray

images and serves as a reference. We perform experiments where a virtual cup with the same size of the implant,

shown in Fig. 6, must be aligned precisely with the cup implanted a priori that is visible in the X-ray images. To

evaluate the 3D error, we acquire a CBCT scan of the phantom and measure the error between the planning outcome

and the ground-truth pose. This yields a mean translation error of 1.71 mm, and anteversion and abduction errors of
0.21◦ and 0.88◦, respectively.

Pre-clinical feasibility study of acetabular component planning using stereo X-ray imaging:

In image-guided

DAA hip arthroplasty, the proper alignment of the acetabular component is frequently inferred from AP X-ray im-
ages50. Thus, the accuracy in estimating the 3D pose based on a single 2D image heavily depends on the surgeon’s
experience. In this experiment, we seek to demonstrate the clinical feasibility of our solution that is based on stereo X-

ray imaging, and compare the outcome to image-guided DAA solutions that only use AP X-ray images for guidance.

9

August 17, 2017Computer Aided Medical ProceduresSlide 34a)b)c)Radiopaque landmarksPLACING A CUP ON A CUPAugust 9, 2017Computer Aided Medical ProceduresSlide 27a)b)c)d)e)f)Fig 7 DRRs were generated from −45◦ to +45◦ around the AP view (a). Participants were each time given two images, where one was always AP,
and the other one generated from a different view. The translational errors are shown for all four participants in (b). Note that 0◦ in the horizontal
axis refers to where the user performed planning on only the AP X-ray image.

We refer to the latter as ”classic DAA”. Although the use of a single AP radiograph and the anterior pelvic plane co-

ordinate system have certain drawbacks, it is the frame of reference that is most commonly used in computer-assisted
THA solutions.51 While there may be alternatives (e.g. coronal plane), the use of anterior pelvic plane as the frame of
reference will enable direct comparison with the current literature.

We conduct a pre-clinical user study where medical experts use the planning software to place acetabular cups

on simulated stereo X-ray images. These results are then compared to conventional AP-based method considering

orientational error in abduction and anteversion.

For the purpose of the user study, simulated X-ray images or so-called digitally reconstructed radiographs (DRR)
are produced from a cadaver CT data. We generate 21 DRRs from the hip area, starting at −45◦ and ending at +45◦
with increments of +4.5◦ on the orbital oblique axis of the C-arm, where 0◦ refers to an AP image. Each time the
users are given a randomly selected DRR together with the DRR corresponding to the AP plane, and are expected to

place the acetabular cup such that it is properly aligned in both views.

As the spatial conﬁguration of the DRRs are known relative to the APP plane, we are able to compute the correct

rotation of the acetabular component, and preset this orientation for the cup in the planning software. This can occur

when an AP image is acquired during the intervention and the desired orientation of the component is known relative

to the anterior pelvic plane which allows locking the DOF for rotational parameters. When the orientation is preset,

the user only has to adjust a translational component, substantially reducing the task load. Presetting the orientation

of the cup is evidently only possible if the X-ray pose is known relative to the APP or the AP image.

Four orthopedic surgery residents from the Johns Hopkins Hospital participate in the user study. The translation

error in placing the cup are shown in Fig. 7. The abduction and anteversion errors are measured as zero as a result of

presetting the desired angles. The abduction and anteversion adjusted by the user solely using AP image (classic DAA)
are 6.52◦ ± 5.97◦ and 1.82◦ ± 1.89◦, respectively. Ground-truth for these statistics includes the 5 DOF pose of the
cup in CT data (as the cup is a symmetric hemisphere, 1 DOF, i. e. rotation around the symmetry axis, is redundant),
where abduction and anteversion angles are 40◦ and 25◦, respectively.

Error evaluation in the AR environment: To evaluate the agreement between surgeons’ actions in the AR envi-

ronment with their intra-operative planning, we measure the orientational error of the impactor after placement with

10

August 31, 2017Computer Aided Medical ProceduresSlide 20a)b)Fig 8 The angle between the principal axis of the virtual impactor and the cloud of points represent the orientation error in the AR environment.

respect to its planning.

The axis-angle error between the principal axis of the true and planned impactor in the AR environment are mea-

sured as shown in Fig. 8. We repeat this experiment for 10 different poses, and each time use four virtual perspectives
of the surgical site. The orientational error is 0.74◦ ± 0.41◦.

After the cup is placed in the acetabulum using AR guidance, we acquire a CBCT scan of the cup and measure
the translation, abduction, and anteversion errors compared to a ground-truth CBCT as 1.98 mm, 1.10◦, and 0.53◦,
respectively.

4 Discussion and Conclusion

We propose an AR solution based on intra-operative planning for easy and accurate placement of acetabular compo-

nents during THA. Planning does not require pre-operative data, and is performed only on two stereo X-ray images.

If either of the two X-ray projections is acquired from an AP perspective, the correct orientation of the cup can be

adjusted automatically, thus, reducing the task load of the surgeon and promoting more accurate implant placement.

Our AR environment is built upon an RGBD enhanced C-arm, that enables visualization of 3D optical information

from the surgical site superimposed with the planning target. Ultimately, accurate cup placement is achieved by

moving the impactor until it is fully aligned with the desired planning.

Experimental results indicate that the anteversion and abduction errors are minimized substantially compared to

the classic DAA approach. The translational error is below 3 mm provided that the lateral opening between two images
is larger than 18◦. All surgeons participating in the user study believed that presetting the cup orientation is useful and
valid, as having access to AP images in the OR is a well-founded assumption. Nonetheless, the authors believe that a
pose-aware RGBD augmented C-arm52 can, in future, assist the surgeon in acquiring and conﬁrming true AP images
considering pelvis supine tilts in different planes.

The translational and orientational error of the proposed AR solution is 1.98 mm and 1.22◦ respectively which
shows reduced error compared to navigation-based system proposed by Sato et.al. with translation error of 2.98 mm
and orientation error of 4.25◦.27 These results show the clear necessity to continue research and perform user studies

11

SURFACE RECONSTRUCTIONAugust 9, 2017Computer Aided Medical ProceduresSlide 30Principle axis of the planned impactor vs. the principle axis of the clouds of pointsView of the surgical sitePlanned impactor  in the mixed reality environmentReal-time cloud of points from the impactor in the mixed reality environmentCloud of points from the patient surfaceαon cadaveric specimens and quantify the changes in operating time, number of required X-ray images, dose, accuracy,

and surgical task load compared to classic image-guided approaches.

In classic DAA hip arthroplasty, correct translation of the cup is achieved by naturally placing the acetabular

component inside the acetabulum, and then moving the impactor around the pivot point of the acetabulum until the

cup is at proper orientation. However, in order for our proposed solution to provide reliable guidance, both the

translational and orientational alignments need to be planned.

In addition to presetting the orientations for the cup during planning, the surgeon can also adjust all 6 DOF rigid

parameters of the component. Though, in the suggested AR paradigm, there are two redundant degrees of freedom; i)

rotation along the symmetry axis of the cup, and ii) translation along the acetabular axis.

The RGBD camera on the C-arm is a short range camera to allow detection even in near distances. The RGB

channel of the sensor is used for tracking visual markers, and the depth channel is utilized to enable AR. The ﬁeld of

view of the RGBD camera is greater than the X-ray camera. Therefore, it allows placing visual marker outside the

X-ray view to not obscure the anatomy in the X-ray image.

The visual marker is only introduced into the surgical scene for a short interval between acquiring two X-ray

images. These external visual markers could be avoided if incorporating RGBD-based simultaneous localization
and mapping to track the surgical site.52 Alternatively, the impactor which is a cylindric object could be used as a
ﬁducial for vision-based inside-out tracking. It is important to note that surgical tools with shiny surfaces reﬂect IR

beam. Tracking the surgical impactor is only done reliably if the surface has a matte ﬁnish, or it is covered with a

non-reﬂective adhesive material.

Projection of the 3D hemispheric virtual cup onto the plane of X-ray images are done by utilizing the intrinsics

parameters of the X-ray camera. These parameters are estimated while performing the checkerboard calibration.

However, at different C-arm arrangements the focal length and principal point could slightly change due to gravity
and ﬂex in the C-arm machine. We quantiﬁed the drift in the principal point for ±10◦, ±20◦, and ±30◦ of C-arm
lateral opening and the average shift was 5.17, 7.3, and 17 pixels on a 1024 × 1024 X-ray image. Considering the

pixel spacing of the detector, these values are equivalent to 1.16 mm, 1.64 mm, and 3.82 mm drift on the detector plane

coordinate frame. To overcome the limitations of change of intrinsics in future, a look-up table could be constructed

from pre-calibration of the C-arm at different angulations. The correct intrinsic parameters could then be retrieved

from the table by matching the corresponding extrinsics from the inside-out tracking of the C-arm. To avoid small

inaccuracies due to image distortion of the image intensiﬁer, we placed the acetabulum near the image center where

image distortion is minimal.

During the clinical intervention, sterilization of the imaging device needs to be ensured by either covering the

RGBD camera with transparent self-adhesive sterile covers, or extending the mount of the camera such that the camera

is located outside the sterile zone. While both options are conceivable, the latter will reduce the range of free motion

while rearranging the C-arm.

The RGBD sensor is not embedded in the gantry of the C-arm; therefore, it is possible that the surgical crew

inadvertently hit the camera and affect the calibration. Since repeating the co-calibration for the imaging devices is

not feasible when the patient is present in the OR, we plan to place an additional co-calibrated camera on the opposite

side of the detector. Hence, when the calibration of one camera becomes invalid, the opposite camera could be used

as a substitute.

In the proposed solution the patient is assumed to be static while placing the cup. However, if the patient moves,

either the planning needs to be repeated, or the surgeon ought to continue with classic ﬂuoroscopy-based guidance.

12

This AR solution for THA uses a self-contained C-arm which only needs a one-time ofﬂine calibration, requires

no external trackers, and does not depend on out-dated pre-operative patient data. We believe that this system, by

enabling quick planning and visualization, can contribute to reduction of radiation, time, and frustration and increase

the efﬁciency and accuracy for placing acetabular components. Ultimately, this approach may aid in reducing the risk

of revision surgery in patients with diseased hip joints.

References

1 S. Kurtz, K. Ong, E. Lau, et al., “Projections of primary and revision hip and knee arthroplasty in the united

states from 2005 to 2030,” JBJS 89(4), 780–785 (2007).

2 R. L. Barrack, C. Lavernia, M. Ries, et al., “Virtual reality computer animation of the effect of component

position and design on stability after total hip arthroplasty,” Orthopedic Clinics 32(4), 569–577 (2001).

3 J. Charnley and Z. Cupic, “The nine and ten year results of the low-friction arthroplasty of the hip.,” Clinical

orthopaedics and related research 95, 9–25 (1973).

4 D. D. D’lima, A. G. Urquhart, K. O. Buehler, et al., “The effect of the orientation of the acetabular and femoral

components on the range of motion of the hip at different head-neck ratios,” JBJS 82(3), 315–21 (2000).

5 C. F. Scifert, T. D. Brown, D. R. Pedersen, et al., “A ﬁnite element analysis of factors inﬂuencing total hip

dislocation.,” Clinical orthopaedics and related research 355, 152–162 (1998).

6 M. Yamaguchi, T. Akisue, T. W. Bauer, et al., “The spatial location of impingement in total hip arthroplasty,”

The journal of Arthroplasty 15(3), 305–313 (2000).

7 G. E. Lewinnek, J. Lewis, R. Tarr, et al., “Dislocations after total hip-replacement arthroplasties.,” JBJS 60(2),

217–220 (1978).

8 J. M. Elkins, J. J. Callaghan, and T. D. Brown, “The 2014 frank stinchﬁeld award: The landing zonefor wear and

stability in total hip arthroplasty is smaller than we thought: a computational analysis,” Clinical Orthopaedics

and Related Research R(cid:13) 473(2), 441–452 (2015).

9 J. R. Danoff, J. T. Bobman, G. Cunn, et al., “Redeﬁning the acetabular component safe zone for posterior

approach total hip arthroplasty,” The Journal of arthroplasty 31(2), 506–511 (2016).

10 C. I. Esposito, B. P. Gladnick, Y.-y. Lee, et al., “Cup position alone does not predict risk of dislocation after hip

arthroplasty,” The Journal of arthroplasty 30(1), 109–113 (2015).

11 A. M. DiGioia III, M. A. Hafez, B. Jaramaz, et al., “Functional pelvic orientation measured from lateral standing

and sitting radiographs.,” Clinical orthopaedics and related research 453, 272–276 (2006).

12 J. Zhu, Z. Wan, and L. D. Dorr, “Quantiﬁcation of pelvic tilt in total hip arthroplasty,” Clinical Orthopaedics and

Related Research R(cid:13) 468(2), 571–575 (2010).

13 M. C. Callanan, B. Jarrett, C. R. Bragdon, et al., “The john charnley award: risk factors for cup malposition-

ing: quality improvement through a joint registry at a tertiary hospital,” Clinical Orthopaedics and Related

Research R(cid:13) 469(2), 319–329 (2011).

14 B. Bosker, C. Verheyen, W. Horstmann, et al., “Poor accuracy of freehand cup positioning during total hip

arthroplasty,” Archives of orthopaedic and trauma surgery 127(5), 375–379 (2007).

15 G. Saxler, A. Marx, D. Vandevelde, et al., “The accuracy of free-hand cup positioning-a ct based measurement

of cup placement in 105 total hip arthroplasties,” International orthopaedics 28(4), 198–201 (2004).

16 A. T. H. A. C. A. Investigators et al., “Outcomes following the single-incision anterior approach to total hip

arthroplasty: a multicenter observational study,” Orthopedic Clinics of North America 40(3), 329–342 (2009).

13

17 B. G. Domb, Y. F. El Bitar, A. Y. Sadik, et al., “Comparison of robotic-assisted and conventional acetabular

cup placement in tha: a matched-pair controlled study,” Clinical Orthopaedics and Related Research R(cid:13) 472(1),

329–336 (2014).

18 L. D. Dorr, A. Malik, Z. Wan, et al., “Precision and bias of imageless computer navigation and surgeon estimates

for acetabular component position.,” Clinical orthopaedics and related research 465, 92–99 (2007).

19 J. T. Moskal and S. G. Capps, “Acetabular component positioning in total hip arthroplasty: an evidence-based

analysis,” The Journal of arthroplasty 26(8), 1432–1437 (2011).

20 S. B. Murphy, T. M. Ecker, and M. Tannast, “Tha performed using conventional and navigated tissue-preserving

techniques.,” Clinical orthopaedics and related research 453, 160–167 (2006).

21 A. M. Digioia, B. Jaramaz, C. Nikou, et al., “Surgical navigation for total hip replacement with the use of hipnav,”

Operative Techniques in Orthopaedics 10(1), 3–8 (2000).

22 B. Jaramaz and K. Eckman, “2d/3d registration for measurement of implant alignment after total hip replace-

ment,” Medical Image Computing and Computer-Assisted Intervention–MICCAI 2006 , 653–661 (2006).

23 C. Nikou, B. Jaramaz, A. M. DiGioia, et al., “Pop: Preoperative planning and simulation software for total

hip replacement surgery,” in International Conference on Medical Image Computing and Computer-Assisted

Intervention, 868–875, Springer (1999).

24 T. Leenders, D. Vandevelde, G. Mahieu, et al., “Reduction in variability of acetabular cup abduction using

computer assisted surgery: a prospective and randomized study,” Computer Aided Surgery 7(2), 99–106 (2002).

25 K.-H. Widmer and P. A. Gr¨utzner, “Joint replacementtotal hip replacement with ct-based navigation,” Injury

35(1), 84–89 (2004).

26 R. G. Haaker, K. Tiedjen, A. Ottersbach, et al., “Comparison of conventional versus computer-navigated acetab-

ular component insertion,” The Journal of arthroplasty 22(2), 151–159 (2007).

27 Y. Sato, T. Sasama, N. Sugano, et al., “Intraoperative simulation and planning using a combined acetabular and

femoral (caf) navigation system for total hip replacement,” in MICCAI, 1114–1125, Springer (2000).

28 V. K. Sarin, C. R. Pratt, M. E. Apgar, et al., “Non-imaging, computer assisted navigation system for hip replace-

ment surgery,” (2004). US Patent 6,711,431.

29 T. Kalteis, M. Handel, H. B¨athis, et al., “Imageless navigation for insertion of the acetabular component in total

hip arthroplasty,” Bone & Joint Journal 88(2), 163–167 (2006).

30 F. Lin, D. Lim, R. L. Wixson, et al., “Limitations of imageless computer-assisted navigation for total hip arthro-

plasty,” The Journal of arthroplasty 26(4), 596–605 (2011).

31 R. H. Taylor, B. D. Mittelstadt, H. A. Paul, et al., “An image-directed robotic system for precise orthopaedic

surgery,” IEEE Transactions on Robotics and Automation 10(3), 261–275 (1994).

32 N. Sugano, “Computer-assisted orthopaedic surgery and robotic surgery in total hip arthroplasty,” Clinics in

orthopedic surgery 5(1), 1–9 (2013).

33 N. Nakamura, N. Sugano, T. Nishii, et al., “Robot-assisted primary cementless total hip arthroplasty using surface

registration techniques: a short-term clinical report,” International journal of computer assisted radiology and

surgery 4(2), 157–162 (2009).

34 J. Yao, R. H. Taylor, R. P. Goldberg, et al., “Ac-arm ﬂuoroscopy-guided progressive cut reﬁnement strategy using

a surgical robot,” Computer Aided Surgery 5(6), 373–390 (2000).

14

35 A. P. Schulz, K. Seide, C. Queitsch, et al., “Results of total hip replacement using the robodoc surgical assis-

tant system: clinical outcome and evaluation of complications for 97 procedures,” The International Journal of

Medical Robotics and Computer Assisted Surgery 3(4), 301–306 (2007).

36 D. H. Nawabi, M. A. Conditt, A. S. Ranawat, et al., “Haptically guided robotic technology in total hip arthro-

plasty: a cadaveric investigation,” Proceedings of the Institution of Mechanical Engineers, Part H: Journal of

Engineering in Medicine 227(3), 302–309 (2013).

37 G. Zheng, “Statistically deformable 2d/3d registration for accurate determination of post-operative cup orien-

tation from single standard x-ray radiograph,” Medical Image Computing and Computer-Assisted Intervention–

MICCAI 2009 , 820–827 (2009).

38 G. Zheng, A. Marx, U. Langlotz, et al., “A hybrid ct-free navigation system for total hip arthroplasty,” Computer

Aided Surgery 7(3), 129–145 (2002).

39 P. A. Gr¨utzner, G. Zheng, U. Langlotz, et al., “C-arm based navigation in total hip arthroplastybackground and

clinical experience,” Injury 35(1), 90–95 (2004).

40 K. Xu, Y.-m. Li, H.-f. Zhang, et al., “Computer navigation in total hip arthroplasty: a meta-analysis of random-

ized controlled trials,” International Journal of Surgery 12(5), 528–533 (2014).

41 I. H. Reininga, W. Zijlstra, R. Wagenmakers, et al., “Minimally invasive and computer-navigated total hip arthro-

plasty: a qualitative and systematic review of the literature,” BMC musculoskeletal disorders 11(1), 92 (2010).

42 W. P. Barrett, S. E. Turner, and J. P. Leopold, “Prospective randomized study of direct anterior vs postero-lateral

approach for total hip arthroplasty,” The Journal of arthroplasty 28(9), 1634–1638 (2013).

43 E. M. Slotkin, P. D. Patel, and J. C. Suarez, “Accuracy of ﬂuoroscopic guided acetabular component positioning

during direct anterior total hip arthroplasty,” The Journal of arthroplasty 30(9), 102–106 (2015).

44 J. Masonis, C. Thompson, and S. Odum, “Safe and accurate: learning the direct anterior total hip arthroplasty.,”

Orthopedics 31(12 Suppl 2), 1417–1426 (2008).

45 S. C. Lee, B. Fuerst, J. Fotouhi, et al., “Calibration of rgbd camera and cone-beam ct for 3d intra-operative mixed

reality visualization,” International journal of computer assisted radiology and surgery 11(6), 967–975 (2016).

46 J. Fotouhi, B. Fuerst, S. C. Lee, et al., “Interventional 3d augmented reality for orthopedic and trauma surgery,”

in 16th Annual Meeting of the International Society for Computer Assisted Orthopedic Surgery (CAOS), (2016).

47 M. Fischer, B. Fuerst, S. C. Lee, et al., “Preclinical usability study of multiple augmented reality concepts for

k-wire placement,” International journal of computer assisted radiology and surgery 11(6), 1007–1014 (2016).

48 J. Fotouhi, B. Fuerst, W. Wein, et al., “Can real-time rgbd enhance intraoperative cone-beam ct?,” International

Journal of Computer Assisted Radiology and Surgery , 1–9 (2017).

49 H. Kato and M. Billinghurst, “Marker tracking and hmd calibration for a video-based augmented reality confer-

encing system,” 85–94 (1999).

50 W. Ji and N. Stewart, “Fluoroscopy assessment during anterior minimally invasive hip replacement is more

accurate than with the posterior approach,” International orthopaedics 40(1), 21–27 (2016).

51 M.-A. Rousseau, J. Y. Lazennec, P. Boyer, et al., “Optimization of total hip arthroplasty implantation: is the

anterior pelvic plane concept valid?,” The Journal of arthroplasty 24(1), 22–26 (2009).

52 J. Fotouhi, B. Fuerst, A. Johnson, et al., “Pose-aware c-arm for automatic re-initialization of interventional 2d/3d

image registration,” International Journal of Computer Assisted Radiology and Surgery , 1–10 (2017).

15

