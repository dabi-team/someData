9
1
0
2

g
u
A
2
1

]

O
H
.
h
t
a
m

[

1
v
9
7
1
4
0
.
8
0
9
1
:
v
i
X
r
a

Moments of Maximum: Segment of AR(1)

Steven Finch

August 12, 2019

Abstract.

Let Xt denote a stationary ﬁrst-order autoregressive process.
Consider ﬁve contiguous observations (in time t) of the series (e.g., X1, . . . ,
X5).
Let ρ be the lag-one serial
< 1. For what value of ρ is E(M ) maximized?
correlation, which satisﬁes
How does V(M ) behave for increasing ρ? Answers to these questions lie in
Afonja (1972), suitably decoded.

Let M denote the maximum of these.
ρ
|
|

Assume that (X1, . . . , Xℓ) is ℓ-multivariate normally distributed with vector mean

zero and covariance matrix

ρ12 ρ13
1
ρ23
ρ21
1
ρ31 ρ32
1
...
...
...
ρℓ1 ρℓ2 ρℓ3

. . . ρ1ℓ
. . . ρ2ℓ
. . . ρ3ℓ
...
. . .
. . .
1

.










R =










In particular, all variances are one and the correlation between Xi and Xj is ρij = ρji.
Deﬁne

Φℓ(R) = P

Xi ≥
{

0 for all i = 1, . . . , ℓ

}

and M = max

X1, . . . , Xℓ}

{

. Afonja [1] proved that

ℓ

E (M) =

i=1
X

=i r

j
X

1

ρij

−
4π

Φℓ

−

·

2(Ri,j),

ℓ

E

M 2

= 1+

(cid:0)

(cid:1)

i=1
X

=i
j
X

k
=i
X
=j
k

0Copyright c
(cid:13)

1

ρij
−
4π ·

ρik −
1 + ρij −
ρik)
(1
−
−
−

ρij)(1

ρjk
ρij −

4(1

−

ρik + ρjk)2 ·

Φℓ

−

3(Ri,,jk)

p

2019 by Steven R. Finch. All rights reserved.

1

 
 
 
 
 
 
6
6
6
6
Moments of Maximum: Segment of AR(1)

2

where the matrices Ri,j and Ri,jk require speciﬁcation. As a preliminary step, let

ri,jk = 




=

=

and








Xj and Xi −
Xj and Xi
Xk

correlation between Xi −
correlation between Xi −
correlation between Xi and Xi −
1
ρik + ρjk
2(1

if j

ρik)

−

Xk

= i and k
= i,
if j
= i and k = i,
if j
= i,
if j = i and k
if j = i and k = i

1
−
2(1
1
−
2(1
1

−
2(1

ρij −
ρij)
−
ρij

p

ρij)

−
ρik

ρik)

p

p

1
p
1
−
4(1
1

−
ρij −
−
ρij

−
2

ρik

1

−
2

p
r

r
1

ρik + ρjk

ρij)(1

ρik)

−

Ri = 




= i and k

= i,

if j

= i and k = i,

if j = i and k

= i

if j = i and k = i

if j

= i and k

= i,

if j

= i and k = i,

if j = i and k

= i,

if j = i and k = i

ri,11
...
ri,ℓ1

. . . ri,1ℓ
...
. . . ri,ℓℓ

.






Clearly ri,jk = ri,kj always. The matrix Ri will not be needed in ensuing sections –
we have included it for completeness’ sake only – it would, however, come into play
if means were nonconstant.

1. Partial Correlations

Set ℓ = 4 for simplicity. Fix 1
m < n such that (i, j, m, n
}

=

{

≤

1, 2, 3, 4

. Deﬁne a 3

≤

}

i < j

4. There exists a unique ordered pair

P =



1
ri,mn
ri,jm ri,jn

ri,mn ri,jm
ri,jn
1

1



3 matrix

×




Xn, Xi −

Xj. Let Pab be the
which captures all correlations among Xi −
cofactor of the element pab in the expansion of the determinant of P . The partial

Xm, Xi −

6
6
6
6
6
6
6
6
6
6
6
6
Moments of Maximum: Segment of AR(1)

3

=

−

ri,mn.j =

correlation ri,mn.j between Xi −

Xm and Xi −
P12
√P11P22

Xn, given Xi −
ri,jmri,jn
ri,mn −
r2
1
i,jm
−
q(cid:0)
(cid:1) (cid:0)
(cid:1)
The notation here [1] diﬀers from that used elsewhere [2, 3, 4].
measures the linear dependence of Xi −
Xm and Xi −
Xj is removed. Deﬁne ﬁnally a 2
Xi −
2 matrix
×
1
ri,mn.j

ri,mn.j
1

Ri,j =

r2
i,jn

−

1

.

(cid:18)

(cid:19)

Xj, is prescribed by

In words, ri,mn.j
Xn in which the inﬂuence of

as was to be done.

Set now ℓ = 5. Fix 1
=

5. There exists a unique ordered triple m < n < o
such that (i, j, m, n, o
. The preceding discussion extends naturally,
supplementing the case (m, n) by additional possible cases (m, o) and (n, o). Deﬁne
ﬁnally a 3

i < j
1, 2, 3, 4, 5

3 matrix

≤
{

≤

}

}

×

We could go on for larger ℓ, but this is all that is needed for our purposes.
i < j < k

Again, set ℓ = 5. Fix 1
≤
m < n such that (i, j, k, m, n
}

=

≤
1, 2, 3, 4, 5
}

{

5. There exists a unique ordered pair
4 matrix
. Deﬁne a 4

Ri,j =



1
ri,mn.j
ri,mo.j

ri,mn.j
1
ri,no.j



ri,mo.j
ri,no.j

.

1 


1

1
ri,mn
ri,jm ri,jn
ri,km ri,kn

ri,mn ri,jm ri,km
ri,kn
ri,jn
ri,jk
1
ri,jk
1

×



Q = 





Xk. Let
which captures all correlations among Xi −
Qab be the cofactor of the element qab in the expansion of the determinant of Q. The
Xk,
partial correlation ri,mn.jk between Xi −
is prescribed by

Xm, Xi −
Xm and Xi −

Xj and Xi −

Xj, Xi −




Xn, Xi −
Xn, given Xi −

ri,mn.jk =

Q12
√Q11Q22

−

ri,mn −
r2
i,jm −

=

1
q(cid:0)

−

ri,jmri,jn −
r2
i,km + 2ri,jmri,kmri,jk −

ri,kmri,kn + ri,kmri,jnri,jk + ri,jmri,knri,jk −
1

r2
i,jn −

r2
i,jk

−

r2
i,kn + 2ri,jnri,knri,jk −

ri,mnr2

i,jk

(cid:1) (cid:0)

r2
i,jk

.

(cid:1)

Moments of Maximum: Segment of AR(1)

4

In words, ri,mn.jk measures the linear dependence of Xi −
Xj and Xi −
the inﬂuence of Xi −

Xk is removed. Deﬁne ﬁnally a 2

Xm and Xi −
×

Xn in which
2 matrix

Ri,jk =

(cid:18)

1
ri,mn.jk

ri,mn.jk
1

(cid:19)

as was to be done.

Set now ℓ = 6. Fix 1

6. There exists a unique ordered triple
≤
1, 2, 3, 4, 5, 6
m < n < o such that (i, j, k, m, n, o
. The preceding discussion
{
extends naturally, supplementing the case (m, n) by additional possible cases (m, o)
and (n, o). Deﬁne ﬁnally a 3

i < j < k
=

3 matrix

≤

}

}

×

Ri,jk =



1
ri,mn.jk
ri,mo.jk

ri,mn.jk ri,mo.jk
ri,no.jk
1

1
ri,no.jk

.



We could go on for larger ℓ, but this is all that is needed for our purposes.





For convenience, deﬁne

2. Small Segments

h(x, y, z) =

=

=

1

1

1

x
−
4π ·
x
−
4π ·
x
−
4π ·

1 + x

y

z

y)
−
1 + x
z)

−

−

−
(1
−
y
−
−
(1
−

−
z

x)(1

x)(1

4(1

p

4(1

−

−

p

(1

−

x)(3 + x)

−

y + z)2

x

−

x
−
1 + x

z + y)2
y

z

−

−
−

−

y(2 + y)

z(2 + z) + 2(xy + xz + yz)

.

The latter expression, while more cumbersome, exhibits symmetry in y, z.

p

If ℓ = 2, then Φℓ

−

2(Ri,j) = 1 and Φℓ

−

3(Ri,,jk) = 0. We have

ρ12

−
4π

=

1

ρ12
−
π

,

r

E (M 2) = 1.

E (M) = 2

1

r
2(Ri,j) = 1

E (M) =

1
√4π

If ℓ = 3, then Φℓ

−

2 and Φℓ

3(Ri,,jk) = 1. We have

−

ρ12 +

1

−

ρ13 +

1

−

1

−

ρ23

,

E

M 2

p
= 1 + 2h(ρ12, ρ13, ρ23) + 2h(ρ13, ρ12, ρ23) + 2h(ρ23, ρ12, ρ13).

p

(cid:16)p

(cid:17)

In formula (3.6) for E (M) in [1],
(cid:1)

(cid:0)

(π) should be replaced by

(2π).

p

p

5

(cid:1)

Moments of Maximum: Segment of AR(1)

If ℓ = 4, then

Φℓ

1

+

In general, ri,mn.j 6
E (M) = 1
1
√4π
−
hp
ρ13 ·
−
ρ14 ·
ρ23 ·
ρ24 ·
ρ34 ·

p
1

p

p

p

−

−

−

−

+

+

+

+

1

1

1

2(Ri,j) = 1

4 + 1

2π arcsin(ri,mn.j),

Φℓ

3(Ri,,jk) = 1
2.

−
= rj,mn.i and thus symmetry fails for E (M). We have

−

2π arcsin(r2,34.1)

2π arcsin(r1,34.2)

+

1

1

1

(cid:0)

4 + 1
ρ12 ·
4 + 1
(cid:0)
2π arcsin(r1,24.3)
4 + 1
2π arcsin(r1,23.4)
4 + 1
2π arcsin(r2,14.3)
4 + 1
2π arcsin(r2,13.4)
(cid:0)
4 + 1
1
2π arcsin(r3,12.4)
(cid:0)

(cid:0)

1

1

+

(cid:1)
1

+

1

p

+

1

p

+

1

p

(cid:1)

(cid:1)

(cid:1)

(cid:1)

+

p
1

1

−
p
ρ13 ·
ρ14 ·
ρ23 ·
ρ24 ·
ρ34 ·

−

−

−

−

−

1

1

1

(cid:0)

4 + 1
ρ12 ·
4 + 1
(cid:0)
2π arcsin(r3,24.1)
4 + 1
2π arcsin(r4,23.1)
4 + 1
2π arcsin(r3,14.2)
4 + 1
2π arcsin(r4,13.2)
(cid:0)
4 + 1
1
2π arcsin(r4,12.3)
(cid:0)

(cid:0)

1

1

(cid:1)

(cid:1)

(cid:1)

,

(cid:1)
(cid:1)i

p

(cid:0)

(cid:1)

p

(cid:0)

E

M 2

(cid:0)

(cid:1)

= 1 + h(ρ12, ρ13, ρ23) + h(ρ12, ρ14, ρ24) + h(ρ13, ρ12, ρ23) + h(ρ13, ρ14, ρ34)
+ h(ρ14, ρ12, ρ24) + h(ρ14, ρ13, ρ34) + h(ρ23, ρ12, ρ13) + h(ρ23, ρ24, ρ34)
+ h(ρ24, ρ12, ρ14) + h(ρ24, ρ23, ρ34) + h(ρ34, ρ13, ρ14) + h(ρ34, ρ23, ρ24).

In formula (3.7) for E (M) in [1], a factor 1/√2π should be inserted in front of the
summation.

If ℓ = 5, then

Φℓ

2(Ri,j) = 1

1
4π arccos(ri,mn.j)

1
4π arccos(ri,mo.j)

2 −

−

−
2π arcsin(ri,mn.jk).
Symmetry now fails for both E (M) and E (M 2). We have

−
4 + 1

3(Ri,,jk) = 1

Φℓ

−

1
4π arccos(ri,no.j),

E (M) = 1
√4π

1

−
hp
ρ12 ·
−
ρ13 ·
ρ13 ·

−

−

ρ12 ·
1
2 −
1
(cid:0)
2 −
1
(cid:0)
2 −

−

1
2 −
1
(cid:0)
4π arccos(r2,34.1)
1
4π arccos(r1,24.3)
1
4π arccos(r3,24.1)

1
4π arccos(r1,34.2)
1
4π arccos(r2,35.1)
1
4π arccos(r1,25.3)
1
4π arccos(r3,25.1)

1
4π arccos(r1,35.2)
1
4π arccos(r2,45.1)
1
4π arccos(r1,45.3)
1
4π arccos(r3,45.1)

−

−

−

−

−

(cid:1)

(cid:1)

+

1
4π arccos(r1,45.2)

−

−

(cid:0)

(cid:1)

(cid:1)

· · ·

,

i

+

1

+

1

p

+

p
1

p

E

M 2

(cid:0)

(cid:1)

= 1 + h(ρ12, ρ13, ρ23)
1
+ h(ρ12, ρ14, ρ24)
+ h(ρ12, ρ15, ρ25)

·

1

1

2π arcsin(r1,45.23)

4 + 1
2π arcsin(r1,35.24)
2π arcsin(r1,34.25)

·
4 + 1
(cid:0)
4 + 1

+ h(ρ12, ρ23, ρ13)
1

(cid:1)

+ h(ρ12, ρ24, ρ14)
+ h(ρ12, ρ25, ρ15)

1

2π arcsin(r2,45.13)

4 + 1
2π arcsin(r2,35.14)
2π arcsin(r2,34.15)

·
4 + 1
(cid:0)
4 + 1

1

·

·

(cid:0)

(cid:0)

(cid:1)

+

,

· · ·

(cid:1)

(cid:1)

·

(cid:0)

(cid:0)

(cid:1)

(cid:1)

Moments of Maximum: Segment of AR(1)

6

a total of 20 terms and 61 terms, respectively.

If ℓ = 6, then E (M) contains non-elementary functions which require numerical

integration (beyond our present scope).

In contrast,

1
4π arccos(r1,56.23)

E

M 2

(cid:0)

(cid:1)

·

·

(cid:0)

= 1 + h(ρ12, ρ13, ρ23)
·
1
+ h(ρ12, ρ23, ρ13)
(cid:0)
2 −
1
+ h(ρ12, ρ14, ρ24)
2 −
1
+ h(ρ12, ρ24, ρ14)
2 −
1
+ h(ρ12, ρ15, ρ25)
2 −
1
+ h(ρ12, ρ25, ρ15)
2 −
1
+ h(ρ12, ρ16, ρ26)
2 −
1
+ h(ρ12, ρ26, ρ16)
2 −

(cid:0)

(cid:0)

(cid:0)

(cid:0)

(cid:0)

·

·

·

·

·

−

−

−

−

−

1
2 −
1
4π arccos(r2,45.13)
1
4π arccos(r1,35.24)
1
4π arccos(r2,35.14)
1
4π arccos(r1,34.25)
1
4π arccos(r2,34.15)
1
4π arccos(r1,34.26)
1
4π arccos(r2,34.16)

1
4π arccos(r1,45.23)
1
4π arccos(r2,46.13)
1
4π arccos(r1,36.24)
1
4π arccos(r2,36.14)
1
4π arccos(r1,36.25)
1
4π arccos(r2,36.15)
1
4π arccos(r1,35.26)
1
4π arccos(r2,35.16)

1
4π arccos(r1,46.23)
1
4π arccos(r2,56.13)
1
4π arccos(r1,56.24)
1
4π arccos(r2,56.14)
1
4π arccos(r1,46.25)
1
4π arccos(r2,46.15)
1
4π arccos(r1,45.26)
1
4π arccos(r2,45.16)

−

−

−

−

−

−

−

−

−

−

−

(cid:1)

+

,

· · ·

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

In formula (3.9) for E (M 2) in [1], a constant term 1 should be
a total of 121 terms.
inserted in front of the ﬁrst summation; further, the last summation should be taken
over both k

= j (not merely k

= i and k

= i).

(cid:0)

Consider a discrete-time stationary ﬁrst-order autoregressive process

3. Time Series

Xt = ρ Xt

−

1 +

ρ2

1

−

·

εt,

< t <

,

∞

−∞

< 1

ρ
|

|

where εt is N(0, 1) white noise. The ℓ

p

×

ℓ covariance matrix R has ijth element

ρij = ρ|

j

i

|

−

which leads to certain simpliﬁcations. Let us make the reliance of M on ℓ explicit.
We have

E (M2) =

E (M3) =

1

r
ρ

−
π

r

1

ρ

,

−
π

1

ρ2

−
4π

,

+

r

E (M4) = 1
4π

ρ

1

−
π

π + 2 arcsin

1

+ 1
2π

ρ

1

−
π

π + 2 arcsin

+ 1
2π

1

ρ2
−
π

q
h
π + 2 arcsin

q

(cid:20)

2

−

ρ

3

−

(cid:16)

ρ)2
(1
−
ρ)(3+ρ+ρ2

(cid:17)i

√(3

−

(cid:18)

ρ3)

−

(cid:19)(cid:21)

q
+ 1
4π

(cid:20)
1

ρ3
−
π

π + 2 arcsin

1

q

h

(cid:16)

2
3+ρ+ρ2

ρ3

−

−

(cid:17)i

ρ2

1+2ρ
−
ρ)(3+ρ+ρ2

√(3

−

(cid:18)

ρ3)

−

(cid:19)(cid:21)

6
6
6
Moments of Maximum: Segment of AR(1)

7

but E (M5) is too lengthy to record here.

In the limit as ρ

1
√π

,

3
2√π

,

3
√π

1
π

1
(cid:20)

−

arcsec(3)

,

(cid:21)

5
√π

1

−

(cid:20)

→
3
2π

0, we obtain

arcsec(3)

(cid:21)

for ℓ = 2, 3, 4, 5 and these are consistent with well-known values [5] corresponding to
independent Xt. Figure 1 displays E (Mℓ) as functions of ρ. The left-hand endpoint
2/π is unsurprisingly the mean of a standard half-normal
is at (
distribution. The right-hand endpoint is at (1, 0). Associated with ℓ = 3, 4, 5 are
maximum points with ρ equal to

2/π) and

p

p

−

1,

1

√5
−
2

=

0.6180339887498948482045868...,

−

0.4973597615161907364022217...,

−

0.4336476843162656141275672...

−

respectively. Closed-form expressions for the latter two quantities remain open.

We also have

E

M 2
3

= 1 +

ρ)

(1

−

E

M 2
4

= 1 +

(cid:0)
3+√(3

−

(cid:1)
ρ)(3+ρ+ρ2

−

ρ)(1 + ρ)

,

(3
−
2π
2ρ2

ρ3)+ρh1
−

p
2ρ
−
2π√(1+ρ)(3+ρ+ρ2

−

ρ3+ρ4

−
ρ3)

ρ√(3

ρ)(3+ρ+ρ2

ρ3)i

−

−

(cid:0)
(cid:1)
5 ) and E (M 2
but E (M 2
obtain

−
6 ) are too lengthy to record here.

In the limit as ρ

0, we

→

1 +

√3
2π

, 1 +

√3
π

, 1 +

5√3
2π

1
π

1

−

(cid:20)

arcsec(4)

, 1 +

(cid:21)

5√3
π

3
2π

1

−

(cid:20)

arcsec(4)

(cid:21)

for ℓ = 3, 4, 5, 6 and these again are consistent with well-known values [5]. Associated
with ℓ = 3, 4, 5, 6 are maximum points with ρ equal to

1

√2 =

0.4142135623730950488016887,

−
0.3879232988398265768779440...,

−

−

0.3599267104829689555367968...

−

0.3406053067160525788737944...

−

respectively. Closed-form expressions for the latter three quantities remain open.
E (Mℓ)2 as functions of ρ. The left-hand
Figure 2 displays V (Mℓ) = E (M 2
ℓ )
2/π); the right-hand endpoint is at (1, 1). Unlike E (Mℓ)
endpoint is at (
or E (M 2
ℓ ), the variance is strictly increasing throughout the interval. An intuitive
reason for such behavior would be good to establish someday.

1, 1

−

−

−

Moments of Maximum: Segment of AR(1)

8

4. Proof of Revision
Our general formula for E (M 2) looks somewhat diﬀerent from that presented by
Afonja [1]. To demonstrate the equivalence of the two formulas, it suﬃces to prove
that if j

= i, k

= i and k
1
2π

= j, then
ri,ki −
1
−

ri,ji ·

ri,jkri,ji

r2
i,jk

= h (ρij, ρik, ρjk) .

The left-hand side is equal to

q

ρij

1

1
2π r

−
2

r

·

=

1
4π

1

ρij ·

−

p

=

1
4π

1

ρij ·

−

p

ρij

1

−
2

1

ρik
−
2 −

1
−
4(1

1

s

(1

p
−

−
4(1
1

−

√1

ρik −

−

ρik + ρjk

ρij −
ρij)(1
−
ρij −
−
ρij −
4(1

ρij)(1

−

−

ρik) r
ρik + ρjk)2
ρik)

−
ρik + ρjk
ρik)

(1

−
4(1

ρik)

1

s
2(1

−

−

4(1

s

ρik)

−

−

ρik + ρjk)2
ρik)

ρij −
p
ρij)(1
−

−

(1

(1

−
ρij −
ρik + ρjk)
ρik + ρjk)2
ρij −
−
ρij
1
−
−
ρik −
1 + ρij −
ρik)
(1
−
−
−

ρjk
ρij −

ρik + ρjk)2

=

1
4π

(1

ρij)

·

−

4(1

ρij)(1

−

which is the right-hand side, as was to be shown.

p

5. Proof from First Principles
An exercise in [6] suggests that formulas for E (M2) and V (M2) should be derived
from

max

=
It is instructive to similarly prove our formula for E (M3), using instead
X1, X2}

X1, X2, X2}
{

X1, X2}

(X1 + X2) +

X1 −

X2|

, max

max

max

{

.

1
2

1
2 |

=

= max
1
2
1
4
1
4 |

=

+

{
(max

{
X1, X2}

{

+ max

{

((X1 + X2) + (X2 + X3) +

(X1 + X2)

(X2 + X3) +

−

X2, X3}}
{
X2, X3}
) +
X1 −
|
X1 −

|

max

1
2 |
{
X2 −
X2|
|
X2 −
X2| − |

X1, X2} −
X3|
)
X3||

+

.

max

X2, X3}|

{

6
6
6
Moments of Maximum: Segment of AR(1)

9

Deﬁne Y = X1−
with vector mean zero and covariance matrix

X2 and Z = X3−

X2. Clearly (Y, Z) is bivariate normally distributed

2ρ12

2
−
ρ12 −
ρ13 −

ρ23 + 1

(cid:18)

Also

ρ23 + 1

ρ12 −
ρ13 −
2
−

2ρ23

=

(cid:19)

(cid:18)

σ2
y
ξ σyσz

ξ σyσz
σ2
z (cid:19)

.

E

1
4

=

Y
|

|

E

1
4

2
π

=

r

1

ρ12

−
4π

,

1

ρ23

σy
4 r
σz
4 r

2
π

Z
|
The four integrals (depending on signs of Y and Z) underlying

−
4π

r

=

=

|

.

E

1
4

|

(Y +

Y

|

)

|

−

(Z +

Z

)

|

|

|

=

1

ρ13

−
4π

r

can all be evaluated (however tediously). Because

X3 = (X1 −
we suspect that a more elegant proof ought to be available.
gap would be welcome.

(X3 −

X1 −

X2) = Y

X2)

−

Z

−

Ideas on bridging this

In more detail, letting

f (y, z) =

2π

1

1

−

exp

ξ2 σyσz

2 (1

−

(cid:20)

1

−

y2
σ2
y −

2ξyz
σyσz

+

z2
σ2
z (cid:19)(cid:21)

ξ2)

(cid:18)

p
denote the bivariate normal density, we obtain

∞

∞

Z0

Z0

2

y
|

z

|

−

f (y, z)dy dz =

1
√2π

(1

−
h

−

ξ)(σy + σz) + 2

σ2
y −

2ξσyσz + σ2
z

i

q

when Y > 0 and Z > 0;

when Y < 0 and Z > 0;

0

∞

Z0

Z
−∞

0

∞

Z
−∞

Z0

2 z f (y, z)dy dz =

(1

ξ)σz

−
√2π

2 y f (y, z)dy dz =

(1

ξ)σy

−
√2π

Moments of Maximum: Segment of AR(1)

10

when Y > 0 and Z < 0; and 0 when Y < 0 and Z < 0. Adding these contributions
and dividing by 4, we verify

1
2√2π

σ2
y −

q

as was desired.

2ξσyσz + σ2

z =

1
2√π

(1

ρ12)

(ρ13 −

ρ12 −

−

−

ρ23 + 1) + (1

ρ23)

−

1

ρ13

p
−
4π

=

r

Calculating the variance of M3 from ﬁrst principles has not been attempted. The
variance of the median (50%-tile) is also of interest, appearing explicitly in [7] for
ℓ = 3 but under the assumption of independence.

An alternative probability density-based derivation of E (M2) and V (M2) can be
found in [8, 9]. See also [10] for the expected range of a normal sample, [11] for the
expected absolute maximum, and [12] for other aspects of AR(1).

Assuming ρij depends only on

j
|

i
|

−

= d, Berman [13, 14, 15] proved that if either

6. Large Segments

ln(d) = 0

or

∞

ρ(d)2 <

lim
d
→∞

ρ(d)

·

then

where

P

lim
ℓ
→∞

np

2 ln(ℓ)(Mℓ −

aℓ)

≤

aℓ =

2 ln(ℓ)

1
2

−

p

d=1
X

x

= exp

o
(cid:0)
ln(ln(ℓ)) + ln(4π)

2 ln(ℓ)

,

∞

e−

−

x

(cid:1)

.

Further, the two hypotheses on ρ(d) cannot be signiﬁcantly weakened. This theorem
clearly applies for a ﬁrst-order autoregressive process, although we note that aℓ does
not incorporate lag-one correlation ρ at all. A more precise asymptotic result might
do so.

p

Other relevant works in the literature include [16, 17, 18, 19, 20, 21, 22, 23, 24].
In particular, Figure 2 of [19] depicts the density of AR(1) maximum for ℓ = 5 and
ρ =

8/10, . . . , 8/10, 9/10.

9/10,

−

−

7. Acknowledgements
Raymond Kan [25] symbolically evaluated the integrals in Section 5, at my request,
for the special case σy = σz = 1 using Mathematica. Enrique del Castillo [23]
identiﬁed several typographical errors in [18] and provided R code for numerically
approximating the ﬁrst two moments of Mℓ.
I am grateful to both individuals for
their kindness!

Moments of Maximum: Segment of AR(1)

11

References
[1] B. Afonja, The moments of the maximum of correlated normal and t-variates,

J. Royal Statist. Soc. Ser. B 34 (1972) 251–262; MR0331637.

[2] A.V.

Prokhorov,
of

coeﬃcient,
Partial
Encyclopaedia
1988;
Mathematics,
https://www.encyclopediaofmath.org/index.php/Partial correlation coeﬃcient;
MR1263687.

correlation

Kluwer,

[3] K. Baba, R. Shibata and M. Sibuya, Partial correlation and conditional correla-
tion as measures of conditional independence, Austral. New Zealand J. Statist.
46 (2004) 657–664; MR2115961.

[4] S. Finch, Expected n-step product for Gaussian tours, arXiv:1512.05592.

[5] S. R. Finch, Extreme value constants, Mathematical Constants, Cambridge Univ.

Press, 2003, pp. 363–367; MR2003519.

[6] H. A. David and H. N. Nagaraja, Order Statistics, 3th ed., Wiley, 2003, pp. 7 &

54; MR1994955.

[7] S. Finch, Capturing, ordering and Gaussianity in 2D, arXiv:1601.04937.

[8] J. J. Hunter, Renewal theory in two dimensions: asymptotic results, Adv. Appl.

Probab. 6 (1974) 546–562; MR0346929.

[9] S. Nadarajah and S. Kotz, Exact distribution of the max/min of two Gaussian
random variables, IEEE Transactions on Very Large Scale Integration (VLSI)
Systems, v. 16 (2008) n. 2, 210–212.

[10] S. Finch, Mean width of a regular simplex, arXiv:1111.4976.

[11] S. Finch, Mean width of a regular cross-polytope, arXiv:1112.0499.

[12] S. Finch, Another look at AR(1), arXiv:0710.5419.

[13] S. M. Berman, Limit theorems for the maximum term in stationary sequences,

Annals Math. Statist. 35 (1964) 502–516; MR0161365.

[14] J. Pickands, Maxima of stationary Gaussian processes, Z. Wahrscheinlichkeits-

theorie und Verw. Gebiete 7 (1967) 190–223; MR0217866.

[15] B. James, K. James and Y. Qi, Limit distribution of the sum and maximum
from multivariate Gaussian sequences, J. Multivariate Anal. 98 (2007) 517–532;
MR2293012.

Moments of Maximum: Segment of AR(1)

12

[16] A. M. Ross, Useful Bounds
Normal

related
trial
http://people.emich.edu/aross15/q/papers/bounds Emax.pdf.

Engineering

Variables,

Technical

Systems

Report

Lehigh

Dept.,

and

on the Expected Maximum of Cor-
Indus-
2003;

03W-004,
Univ.,

[17] A. M. Ross, Computing bounds on the expected maximum of correlated normal
variables, Methodol. Comput. Appl. Probab. 12 (2010) 111–138; MR2580098.

[18] B. Wang and P. Mazumder, Multivariate normal distribution based statistical
timing analysis using global projection and local expansion, Proceedings of
the 18th International Conference on VLSI Design held jointly with 4th Inter-
national Conference on Embedded Systems Design, IEEE, 2005, pp. 380–385;
http://www1.ece.uic.edu/MURI-RF/Publications/Journals/Mazumder VLSI Jan 2005.pdf.

[19] R. B. Arellano-Valle and M. G. Genton, On the exact distribution of the maxi-
mum of absolutely continuous dependent random variables, Statist. Probab. Lett.
78 (2008) 27–35; MR2381270.

[20] C. S. Withers and S. Nadarajah, The distribution of the maximum of a ﬁrst
order autoregressive process: the continuous case, Metrika 74 (2011) 247–266;
MR2822160.

[21] C. S. Withers and S. Nadarajah, The distribution of the maximum of a second

order autoregressive process: the continuous case, arXiv:1001.5265.

[22] C. S. Withers and S. Nadarajah, The joint distribution of the maximum and min-
imum of an AR(1) process, Statist. Probab. Lett. 99 (2015) 77–84; MR3321499.

[23] E. del Castillo, A. Beretta and Q. Semeraro, Optimal setup of a multihead
weighing machine, European J. Oper. Res. 259 (2017) 384–393; MR3595868.

[24] S. Nadarajah, E. Afuecheta and S. Chan, On the distribution of maximum of
multivariate normal random vectors, Comm. Statist. Theory Methods 48 (2019)
2425–2445; MR3963113.

[25] R. Kan and C. Robotti, On moments of folded and truncated multivariate normal

distributions, J. Comput. Graph. Statist. 26 (2017) 930–93; MR3765356.

Steven Finch
MIT Sloan School of Management
Cambridge, MA, USA
steven ﬁnch@harvard.edu

Moments of Maximum: Segment of AR(1)

13

Figure 1:

Interior maximum points exist for ℓ

3, but not for ℓ = 2.

≥

Moments of Maximum: Segment of AR(1)

14

Figure 2: Linear (with slope 1/π and vertical intercept 1
increasing for ℓ

3.

≥

1/π) for ℓ = 2; strictly

−

