AR-LSAT: Investigating Analytical Reasoning of Text
Wanjun Zhong1âˆ—, Siyuan Wang3âˆ—, Duyu Tang2, Zenan Xu1âˆ—, Daya Guo1âˆ—
Yining Chen2, Jiahai Wang1, Jian Yin1, Ming Zhou4 and Nan Duan2
1 The School of Data and Computer Science, Sun Yat-sen University.
2 Microsoft Research 3 Fudan University, China 4SINOVATION VENTURES
{zhongwj25, xuzn, guody5}@mail2.sysu.edu.cn
{wangjiah@mail,issjyin@mail}.sysu.edu.cn
{dutang,nanduan,yining.chen}@microsoft.com
wangsy18@fudan.edu.cn; zhouming@chuangxin.com

Abstract

Analytical reasoning is an essential and chal-
lenging task that requires a system to ana-
lyze a scenario involving a set of particu-
lar circumstances and perform reasoning over
it to make conclusions.
In this paper, we
study the challenge of analytical reasoning
of text and introduce a new dataset consist-
ing of questions from the Law School Ad-
mission Test from 1991 to 2016. We ana-
lyze what knowledge understanding and rea-
soning abilities are required to do well on this
task. Furthermore, to address this reasoning
challenge, we design two different baselines:
(1) a Transformer-based method which lever-
ages the state-of-the-art pre-trained language
models and (2) Analytical Reasoning Machine
(ARM), a logical-level reasoning framework
extracting symbolic knowledge (e.g, partici-
pants, facts, logical functions) to deduce legit-
imate solutions. In our experiments, we ï¬nd
that the Transformer-based models struggle to
solve this task as their performance is close to
random guess and ARM achieves better perfor-
mance by leveraging symbolic knowledge and
interpretable reasoning steps. Results show
that both methods still lag far behind human
performance, which leave further space for fu-
ture research. 1

Figure 1: An example of the required reasoning pro-
cess to do well on the AR task. The input is a passage,
a question and multiple options, and the output is the
most plausible answer.

1

Introduction

Analytical reasoning assesses the problem-solving
ability to understand knowledge (e.g., partici-
pants, facts, rules), and reasoning over that knowl-
edge to determine a solution. Analytical reason-
ing is known to involved when doing everyday
tasks, and engages high-level cognitive mecha-
nisms of humans (Williams et al., 2019). Although

âˆ— Work done while this author was an intern at Microsoft

Research.

1The data and code are provided in https://github.

com/zhongwanjun/AR-LSAT.

Transformer-based pre-trained language models in-
cluding BERT (Devlin et al., 2018), GPT-2 (Rad-
ford et al., 2019) and RoBERTa (Liu et al., 2019)
have achieved state-of-the-art performance on a va-
riety of NLP tasks, they still struggle to perform
deep reasoning beyond shallow-level semantic un-
derstanding of literal clues. For example, Talmor
et al. (2020) show that pre-trained models fail on
half of eight reasoning tasks that require symbolic
operations. We hope to challenge current systems
and take a step towards analytical reasoning.

In this paper, we study the challenge of analyt-

1
2
0
2

r
p
A
5
1

]
L
C
.
s
c
[

2
v
8
9
5
6
0
.
4
0
1
2
:
v
i
X
r
a

PassageThe Mom & Pop liquor store employs five cashiers-Adams, Bates, Cox, Drake, and Edwards-each of whom works alone on exactly one day, Monday through FridayAdams will work only on Tuesday or Thursday. Bates will not work on Monday or Wednesday. Cox works on Friday. Drake and Edwards do not work on consecutive days. QuestionWhich one of the following is a possible work schedule?Optionsğ´Edwards, Bates, Adams, Drake, Cox(cid:4666)ğµ(cid:4667) Drake, Adams, Bates, Edwards, Cox(cid:4666)ğ¶(cid:4667)Edwards, Adams, Cox, Bates, Drake (cid:4666)ğ·(cid:4667)Edwards, Adams, Drake, Bates, Cox(cid:4666)ğ¸(cid:4667)Drake, Edwards, Bates, Adams, CoxAnswer: ğ·Reasoning Process of Humans:From the passage, we first understand conditions(i.e., participants and positions) and comprehend rulesand facts. Then, we check each option to see whether it satisfy all the rules and select the most plausible one. [Grouping Game] Passageï¼šSeven directors -A,B,C,D,E,F,andG-serveson theXcommittee ortheYcommittee.Questionï¼šIfDandFbothserveontheXcommittee,Factthen whichoneofthefollowingcouldbetrue?Optionsï¼šA.AandCbothserveontheX committee. B.AandE bothserveontheY committee.C.BandGbothserveontheX committee.D.CandEbothserveontheY committee. âˆšE.GandEbothserveontheX committee.Rules to Logical ExpressionsR-1: ğ´ ğ‘œğ‘› ğ‘‹ â†’ğµ ğ‘œğ‘› ğ‘ŒR-2: ğ¶ ğ‘œğ‘› ğ‘‹ â†’ğ· ğ‘œğ‘› ğ‘Œ&(cid:4666)ğ¸ ğ‘œğ‘› ğ‘Œ(cid:4667)R-3: ğ‘ƒğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘œğ‘› ğ‘œğ‘“ ğ¹(cid:3405)ğ‘ƒğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘œğ‘› ğ‘œğ‘“ ğºR-4:ğ‘ƒğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘œğ‘› ğ‘œğ‘“ ğ¸(cid:3405)ğ‘ƒğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘œğ‘› ğ‘œğ‘“ ğ´R-5: ğº ğ‘œğ‘› ğ‘‹ â†’ğµ ğ‘œğ‘› ğ‘‹Factğ· ğ‘œğ‘› ğ‘‹&(cid:4666)ğ¹ ğ‘œğ‘› ğ‘‹(cid:4667)IfAservesonX,thenBservesonY. R-1IfCservesonX,thenDand E serveonY. R-2FservesonadifferentcommitteewithG. R-3EservesonadifferentcommitteewithA. R-4IfGservesonX,sodoesB. R-5RulesParticipantsğ´,ğµ,ğ¶,ğ·,ğ¸,ğ¹,ğºPositionsğ‘‹,ğ‘Œ(cid:4666)ğ¶ ğ‘œğ‘› ğ‘‹(cid:4667)&(cid:4666)ğ· ğ‘œğ‘› ğ‘‹(cid:4667) confict with R-2 (cid:4666)ğ´ ğ‘œğ‘› ğ‘Œ(cid:4667)&(cid:4666)ğ¸ ğ‘œğ‘› ğ‘Œ(cid:4667) confict with R-4 ğº ğ‘œğ‘› ğ‘‹&(cid:4666)ğ¹ ğ‘œğ‘› ğ‘‹(cid:4667) confict with R-3 ğº ğ‘œğ‘› ğ‘‹&(cid:4666)ğ¹ ğ‘œğ‘› ğ‘‹(cid:4667) confict with R-3 
 
 
 
 
 
ical reasoning (AR). We introduce a new dataset
AR-LSAT from the Law School Admission Test2
(LSAT) from 1991 to 2016. to facilitate research
on this area. An example of analytical reasoning in
LSAT is given in Figure 1, whose task is to separate
participants (i.e., A,B, etc.) into two positions (i.e.,
X committee and Y committee) under certain con-
straints. Solving the problem requires a system to
understand the knowledge in the context including
participants, positions, rules expressed in natural
language (e.g., â€œIf G serves on X, so does B") and
facts (e.g., â€œD and F both serve on the X commit-
tee"). Then, it needs to deduct logical expressions
(e.g., â€œG on X â†’ B on X") from the rules, and
draw inference before making conclusions.

In this paper, we analyze the knowledge under-
standing and reasoning ability required for solv-
ing this task and present two base approaches for
this challenge: (1) Transformer-based approach
that applies pretrained language models to encode
the input context into distributed representation for
classiï¬cation. (2) Analytical Reasoning Machine
(ARM), a logical-level framework that ï¬rst extracts
symbolic knowledge (i.e., participants, rules, facts)
from the context, and further maps them into exe-
cutable logical functions (e.g., â€œIfThen", â€œBefore")
to assess whether a solution can satisfy mentioned
rules and then deduce legitimate solutions for mak-
ing prediction. This framework sheds a light on
the logical-level reasoning procedure required for
this task, and each step can be further developed in
future for better performance or expandability.

Experiments show that the Transformer-based
approach struggles to learn this task, which indi-
cates that this task is very challenging for current
models as it requires the complex reasoning abil-
ity far beyond implicit reasoning over the literal
clues. ARM performs relatively better than the
Transformer-based approach with higher accuracy
and better interpretability. The performance of
both approaches lag far behind human performance,
which leaves a huge space for further research.
The contributions of our paper are two-fold.

â€¢ We introduce a new dataset AR-LSAT to fa-

cilitate research on analytical reasoning.

â€¢ We present two approaches for this task: a
Transformer-based approach and a logical-
level reasoning framework that utilizes sym-
bolic knowledge to perform reasoning.
2https://en.wikipedia.org/wiki/Law_

School_Admission_Test

2 Related Works

There is an increasing trend on machine reason-
ing research in recent years. The reasoning ability
investigated are partitioned into several major as-
pects, including (1) logical reasoning; (2) common-
sense reasoning; (3) mathematical reasoning and
(4) multi-hop reasoning.

Logical Reasoning The task of Natural Lan-
guage Inference (NLI) (Dagan et al., 2005; Bow-
man et al., 2015; Wang et al., 2018; Williams et al.,
2018; Welleck et al., 2018; Khot et al., 2018; Nie
et al., 2019; Bhagavatula et al., 2019; Liu et al.,
2020a) requires the models to detect the logical en-
tailment relationship of two sentences. There have
been Machine Reading Comprehension (MRC)
datasets (Rajpurkar et al., 2016; Welbl et al., 2017;
Yang et al., 2018a; Huang et al., 2019b) that ex-
amine the ability of logical reasoning. LogiQA
(Liu et al., 2020b) and ReClor (Yu et al., 2020) are
sourced from examination in realistic scenario and
examine a range of logical reasoning skills.

Commonsense Reasoning There are many re-
cent benchmarks that assess the commonsense rea-
soning capabilities from different aspects, like so-
cial (Rashkin et al., 2018), physics (Talmor et al.,
2018; Zellers et al., 2019), or temporal (Zhou et al.,
2019). There exist several MRC datasets that re-
quire commonsense knowledge (Ostermann et al.,
2018; Zhang et al., 2018; Huang et al., 2019a).

Mathematical Reasoning There are many exist-
ing datasets (Kushman et al., 2014; Hosseini et al.,
2014; Koncel-Kedziorski et al., 2015; Clark et al.,
2016; Ling et al., 2017) focus on mathematical
word problems. Ling et al. (2017) builds a dataset
that encourages generating answer rationales be-
yond simply selecting the correct answer. DROP
(Dua et al., 2019) is a benchmark MRC dataset
requiring mathematical reasoning. Saxton et al.
(2019) focuses on algebraic generalization.

Multi-hop Reasoning Multi-hop reasoning over
textual data (Talmor and Berant, 2018; Welbl et al.,
2018; Yang et al., 2018b; Inoue et al., 2020) require
a model to reason over multiple paragraphs before
making prediction.

To the best of our knowledge, there has not an
existing benchmark dataset that completely focuses
on the analytical reasoning over textual data. We
introduce a new dataset to ï¬ll this gap and to foster
research on this area.

Figure 2: Examples of ordering game and assignment game in AR task. Facts and Rules are highlighted in orange
and blue, respectively. Example of grouping game is shown in Figure 1. Ã— indicates conï¬‚ict.

3 Task and Dataset

In this section, we describe the task of analytical
reasoning, introduce the dataset AR-LSAT we col-
lected from the Law School Admission Test and
make analysis about the required reasoning skills.

3.1 Task: Analytical Reasoning of Text

Taking a passage, a question, and multiple options
as the input, a system is required to select the
most plausible answer as the output. Each passage
describes a reasoning game belonging to various
types. According to Kolby (2016), there are three
dominant game types in LSAT: ordering games,
grouping games, and assignment games, which
are described as follows and examples are given in
Figures 1 and 2:

â€¢ Ordering games are to order participants

based on given facts and rules.

â€¢ Grouping games are to separate participants

into groups with given facts and rules.

â€¢ Assignment games are to assign characteris-
tics to the participants with given rules, like
assigning schedules for people.

3.2 Dataset Collection: AR-LSAT

We collect data from nearly 90 LSAT exams from
1991 to 2016 and select questions from the ana-
lytical reasoning part to construct the dataset, and
name it AR-LSAT. Each exam in LSAT consists
of 101 multiple choice questions, 24 of which are
AR questions. We ï¬nally leave up the questions
with 5 answer options.

Number of questions
Average length of passages
Average length of questions
Average length of answers
Number of options
Ratio of ordering game
Ratio of grouping game
Ratio of assignment game

2,046
99.3
19.1
6
5
42.5%
38.75%
18.75%

Table 1: Data statistics of AR-LSAT dataset.

3.3 Data Analysis

As mentioned above, the questions of AR-LSAT
come from exams in realistic scenario. Each pas-
sage describes a reasoning game belongs to three
dominant type: (1) ordering game, (2) grouping
game and (3) assignment game. We manually an-
alyze and summarize the ratio of each type of rea-
soning game in AR-LSAT. The corresponding data
statistics and ratios are shown in Table 1. Moreover,
the questions in AR-LSAT are further challenging
as them require the system to have different kinds
of reasoning skills. We manually categorize and an-
alyze question types that are common in AR-LSAT
dataset. The detailed description of question types
is shown in Table 2. We also notice that the three
most common question types: â€œacceptable solu-
tion", â€œcould be true/false" and â€œmust be true/false"
associate with most of the passages. There also
exist challenging questions, like â€œcalculation" and
â€œsubstitution" problems. The examples of question
types are given in Appendix C.

3.4 Challenges

In this part, we point out the reasoning ability re-
quired for solving AR questions, and put forward

[Ordering Game] PassageA professor must determine the order in which five of her students-Fernando, Ginny, Hakim, Juanita, and Kevin-will perform in a recital. Ginny perform earlier than Fernando. R-1Kevin perform earlier than Hakim and Juanita. R-2Hakimperform either immediately before orimmediately after Fernando.R-3Rules to Logical ExpressionsR-1: ğ‘ƒğ‘œğ‘ .ğ‘œğ‘“ ğºğ‘–ğ‘›ğ‘›ğ‘¦(cid:3407)ğ‘ƒğ‘œğ‘ .ğ‘œğ‘“ ğ¹ğ‘’ğ‘Ÿğ‘›ğ‘ğ‘›ğ‘‘ğ‘œR-2: (cid:4666)ğ‘ƒğ‘œğ‘ .ğ‘œğ‘“ ğ¾ğ‘’ğ‘£ğ‘–ğ‘›(cid:3407)ğ‘ƒğ‘œğ‘ .ğ‘œğ‘“ ğ»ğ‘ğ‘˜ğ‘–ğ‘š(cid:4667) &(cid:4666)ğ‘ƒğ‘œğ‘ .ğ‘œğ‘“ ğ¾ğ‘’ğ‘£ğ‘–ğ‘›(cid:3407)ğ‘ƒğ‘œğ‘ .ğ‘œğ‘“ ğ½ğ‘¢ğ‘ğ‘›ğ‘–ğ‘¡ğ‘(cid:4667)R-3: ğ‘ƒğ‘œğ‘ .ğ‘œğ‘“ ğ»ğ‘ğ‘˜ğ‘–ğ‘š(cid:3404)ğ‘ƒğ‘œğ‘ .ğ‘œğ‘“ ğ¹ğ‘’ğ‘Ÿğ‘›ğ‘ğ‘›ğ‘‘ğ‘œ(cid:3397)1|   ğ‘ƒğ‘œğ‘ .ğ‘œğ‘“ ğ»ğ‘ğ‘˜ğ‘–ğ‘š(cid:3404)ğ‘ƒğ‘œğ‘ .ğ‘œğ‘“ ğ¹ğ‘’ğ‘Ÿğ‘›ğ‘ğ‘›ğ‘‘ğ‘œ(cid:3398)1FactUncertainPositions1(cid:3046)(cid:3047),2(cid:3041)(cid:3031),3(cid:3045)(cid:3031),4(cid:3047)(cid:3035),5(cid:3047)(cid:3035)Participants(cid:4666)ğ¹ğ‘’ğ‘Ÿğ‘›ğ‘ğ‘›ğ‘‘ğ‘œ,ğºğ‘–ğ‘›ğ‘›ğ‘¦,ğ»ğ‘ğ‘˜ğ‘–ğ‘š,ğ½ğ‘¢ğ‘ğ‘›ğ‘–ğ‘¡ğ‘,ğ¾ğ‘’ğ‘£ğ‘–ğ‘›(cid:4667)OptionsA.Ginny, Fernando, Hakim, Kevin, JuanitaÃ—R-2B.Ginny, Juanita, Kevin, Hakim, FernandoÃ—R-2C.Ginny, Kevin, Hakim, Juanita, FernandoÃ—R-3D.Kevin, Ginny, Juanita, Fernando, HakimâˆšE.Kevin, Juanita, Fernando, Hakim, GinnyÃ—R-1QuestionWhich one of the following could be the order the students perform?[Assignment Game] PassageFive cashiers-Adams, Bates, Cox, Drake, and Edwards-eachof whom works alone on exactly one day, Monday through FridayAdams will work only on Tuesday or Thursday.  R-1Bates will not work on Monday or Wednesday.   R-2Cox works on Friday.   F-1Edwards donâ€™t work next to Drake R-3.Rules to Logical ExpressionsR-1: ğ´ğ‘‘ğ‘ğ‘šğ‘  ğ‘œğ‘› ğ‘‡ğ‘¢ğ‘’ğ‘ .| ğ´ğ‘‘ğ‘ğ‘šğ‘  ğ‘œğ‘› ğ‘‡â„ğ‘¢ğ‘Ÿ.R-2: (cid:3411)ğµğ‘ğ‘¡ğ‘’ğ‘  ğ‘œğ‘› ğ‘€ğ‘œğ‘›. ğµğ‘ğ‘¡ğ‘’ğ‘  ğ‘œğ‘› ğ‘Šğ‘’ğ‘‘.(cid:4667) R-3: ğ‘ƒğ‘œğ‘ .ğ‘œğ‘“ ğ¸ğ‘‘ğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘ (cid:3405)ğ‘ƒğ‘œğ‘ .ğ‘œğ‘“ ğ·ğ‘Ÿğ‘ğ‘˜ğ‘’(cid:3397)1Positionsğ‘€ğ‘œğ‘›.,ğ‘‡ğ‘¢ğ‘’ğ‘ .,ğ‘Šğ‘’ğ‘‘.,ğ‘‡â„ğ‘¢ğ‘Ÿ.,ğ¹ğ‘Ÿğ‘–. Participants(cid:4666)ğ´ğ‘‘ğ‘ğ‘šğ‘ ,ğµğ‘ğ‘¡ğ‘’ğ‘ ,ğ¶ğ‘œğ‘¥,ğ·ğ‘Ÿğ‘ğ‘˜ğ‘’,ğ¸ğ‘‘ğ‘¤ğ‘ğ‘Ÿğ‘‘ğ‘ (cid:4667)OptionsA.Edwards, Bates, Adams, Drake, Cox Ã—R-1B.Drake, Adams, Bates, Edwards, Cox Ã—R-2C.Edwards, Adams, Cox, Bates, Drake Ã—F-1D.Edwards, Adams, Drake, Bates, CoxâˆšE.Drake, Edwards, Bates, Adams, Cox Ã—R-3QuestionWhich one of the following is a possible work schedule?Factğ¶ğ‘œğ‘¥ ğ‘œğ‘› ğ¹ğ‘Ÿğ‘–.Question Type
Acceptable solution (15.6%)
Complete list (3.5%)
Could be true/false (26.8%)
Must be true/false (26.4%)
Negation (14.7%)
Substitution (4.3%)
Condition for determined solution (3.5%)
Calculation (3%)
Earliest/latest position (1.3%)
Maximum/minimum members (1.3%)

Description
identify a feasible solution that can satisfy all the rules
identify a complete and accurate list of participants under given condition
select answer that could be true/false under given condition
select answer that must be true/false under given condition
questions that contain negation
identify a new rule that can substitute one of the old rules for the desiring result
identify a new rule so that the feasible solution is determined
calculate possible participants in a group
identify the earliest/latest position that a speciï¬c participant can be assigned to
identify the possible maximum/minimum number of participants in a speciï¬c group

Table 2: The ratio and description of each question type in the test set of the AR-LSAT dataset.

the challenges that systems should face. As we can
observe from the examples in Figure 1 and Figure
2, solving AR questions needs systems to under-
stand the complex scenario and perform reasoning
over it, and has no special needs for external knowl-
edge. In conclusion, AR questions test a range of
reasoning skills:

1) Comprehending the knowledge including par-
ticipants of events, facts, and rules described
in the context.

2) Extracting machine-understandable logical
functions (expressions) from the rules. For
example, the rule â€œIf A serves on X, then B
serves on Y." needs to be transferred as logi-
cal expression â€œA on X â†’ B on Y",

3) Making deductions to derive legitimate solu-
tions that satisfy extracted logical functions.

4) Selecting the answer that satisï¬es all the rules
with the deducted legitimate solutions. In the
examples, a system should eliminate options
that conï¬‚ict with rules and select the option
that accords with legitimate solutions.

Therefore, this task requires the machine to per-
form explicit complex reasoning, far beyond just
understanding the literal clues presented in the text.

4 Approaches

In this section, we describe our two base ap-
proaches: (1) Transformer-based approach and (2)
Analytical Reasoning Machine (ARM).

4.1 Transformer-based Approach

In this approach, we view the analytical rea-
soning challenge as a multiple-choice question
answering problem. We employ state-of-the-
art pre-trained Transformer-based language mod-
els (i.e., BERT (Devlin et al., 2018), XL-
Net (Yang et al., 2019), RoBERTa (Liu et al.,

2019), and ALBERT (Lan et al., 2019)) for
classiï¬cation as they achieve impressive perfor-
mance on a wide variety of tasks.
Speciï¬-
cally, we take the concatenated sequence X =
{[CLS], passage, [SEP ], question, option} as
the input, where [CLS] is the ending special to-
ken and [SEP ] is used to split two types of in-
put. The representation of the sequence H =
fT ransf ormer(X) is further fed into a two-layer
perceptron fM LP for classiï¬cation pÎ¸(X) =
Ïƒ(fM LP (H)), where Ïƒ is an activation function.
The model parameters Î¸ of the Transformer and
MLP layer are ï¬ne-tuned with cross-entropy loss
on the training set.

4.2 Analytical Reasoning Machine (ARM)

In this part, we describe the logical-level frame-
work, Analytical Reasoning Machine (ARM),
which extracts symbolic knowledge from the con-
text and perform reasoning over the knowledge to
draw conclusions. Figure 3 gives an overview of
the ARM framework. We propose to break down
the reasoning process into four stages: (1) extract-
ing arguments (i.e., the participants, positions, facts
and rules) from the context (Â§ 4.2.1); (2) interpret-
ing rules into a set of logical constraint functions,
whose arguments are selected from participants and
positions (Â§ 4.2.2); (3) reasoning with the logical
functions and ï¬nally generating a group of legit-
imate assignments (solutions) that satisfy all the
rules (Â§ 4.2.3); (4) selecting the most plausible op-
tion by matching the legitimate assignments and
options (Â§ 4.2.4).

ARM sheds a light on the logical-level reasoning
procedure for analytical reasoning and each proce-
dure can be further developed for both performance
and expandability.

4.2.1 Arguments Extraction
In order to understand the context and formalize
the problem, the ï¬rst step is to extract the par-

Figure 3: An overview of our approach. The original example is given in Figure 1. It extracts arguments from the
context (Â§ 4.2.1). Then it extracts logical functions from rules (Â§ 4.2.2). Afterwards, it conducts deduction to ï¬nd
legitimate assignments (Â§ 4.2.3). Lastly, it matches the options and legitimate assignments for prediction (Â§ 4.2.4).

ticipants, positions, facts and rules expressed in
natural language from the passage and hypoth-
esis of the question. An assignment represents
a solution that assigns participants to positions,
and has a group of values of three possible states:
(True, False, Unknown) representing whether a par-
ticipant is assigned to a position. The rules de-
scribe the constraints of assignments while the
facts describe determined initial assignments ex-
plicitly mentioned in the context. We take the ex-
ample in Figure 3 as a running example to show the
extracted participants, positions, facts and rules.

Speciï¬cally, we extract the entities with a neural
Named Entity Recognition (NER) model (Peters
et al., 2017) and group the extracted entities into
participants or positions. Rules and facts are iden-
tiï¬ed by whether a sentence mentions determined
assignment. We parse groups of entities that appear
together in the leading sentence of the passage as
groups of participants or positions, where partici-
pants always appear before positions.

4.2.2 Logical Function Extraction
We introduce a set of predeï¬ned logical functions
to express the constraints in the rules, which is the
foundation of the reasoning process. A function
consists of arguments and a executor, whose input
is an assignment and the output is a Bool value
indicates whether the assignment satisï¬es the con-
straint. The detailed deï¬nition of each function
is listed in Appendix B. As the fragment shown
in Table 3, the logical functions include following
basic types:

Relational Function The relational functions,
whose arguments involve participants or posi-
tions, represent the constraints of the relation-
ship between them. For example, the function
Before(Ginny, F ernando) indicates that Ginny
should be in the position before Fernando in the

ordering game. To(A, X) indicates that participant
A should be assigned to position X.

Compositional Function A compositional func-
tion expresses the relationship between two sets of
functions, like the conditional rule (if-then rule)
and the if-and-only-if rule. The arguments of
compositional functions involve two sets of sub-
functions. For example, the rule â€œIf A serves on the
X, then B serves on the Y." should be expressed as
IfThen({T o(A, X)}, {T o(B, Y )}).

Counting Function The counting functions fo-
cus on the calculation problem of participants un-
der speciï¬c constraints. The arguments of counting
functions involve a participant and a number. For
example, LastPos(A, 3) checks whether the partic-
ipant A is assigned to the last 3 positions.

Based on the extracted arguments, we formalize
the rules into logical functions. One straightfor-
ward way is to design a symbolic parsing method.
For each function, we follow NSM (Liang et al.,
2016) that uses trigger words to match a potential
function. For example, the function Before can be
triggered by words â€œbefore" and â€œearlier". Then
we select arguments (i.e., participants, positions,
and numbers) based on their relative positions to
the trigger word. The relational and counting func-
tions can be constituted into compositional func-
tions based on predeï¬ned grammar patterns. For
example, for the grammar pattern â€œIf P, then Q",
Each function is grouped into the function set F1
if it occurs in P, or the function set F2 if it occurs
in Q. F1 and F2 are taken as the arguments of the
function IfThen.

Furthermore, to handle the uncertain cases and
improve the coverage of extracted functions, we
build a neural semantic parsing model based on a
pre-trained language model RoBERTa (Liu et al.,
It takes the sentence and two parsed ar-
2019).

ğŸ’.ğ€ğ§ğ¬ğ°ğğ« ğ’ğğ¥ğğœğ­ğ¢ğ¨ğ§PassageSeven directors -A,B,C,D,E,F,andG-serveson theXcommittee ortheYcommittee.IfAservesontheX,thenBservesontheY.IfCservesontheX,thenDand E serveonthe Y.FservesonadifferentcommitteewithG.EservesonadifferentcommitteewithA.IfGservesontheX,sodoesB.questionIfDandFbothserveontheXcommittee,then whichoneofthefollowingcouldbetrue?ParticipantA, B, C, D, E, F, GPositionX, YFactsD and F both serve on X RulesIf A serves on the X, then B serves on Y IfCservesontheX,thenDand E serveonthe Y.FservesonadifferentcommitteewithG.EservesonadifferentcommitteewithA.IfGservesontheX,sodoesB.ğ‘“(cid:2868)(cid:3404)ğ¼ğ‘“ğ‘‡â„ğ‘’ğ‘›ğ‘‡ğ‘œğ´,ğ‘‹,ğ‘‡ğ‘œğµ,ğ‘Œğ‘“(cid:2869)(cid:3404)ğ¼ğ‘“ğ‘‡â„ğ‘’ğ‘›ğ‘‡ğ‘œğ¶,ğ‘‹,ğ‘‡ğ‘œğ·,ğ‘Œ;ğ‘‡ğ‘œ(cid:4666)ğ¸,ğ‘Œ(cid:4667)ğ‘“(cid:2870)(cid:3404)ğ·ğ‘–ğ‘“ğ‘“ğ‘’ğ‘Ÿğ‘’ğ‘›ğ‘¡(cid:4666)ğ¹,ğº(cid:4667)ğ‘“(cid:2871)(cid:3404)ğ·ğ‘–ğ‘“ğ‘“ğ‘’ğ‘Ÿğ‘’ğ‘›ğ‘¡(cid:4666)ğ¸,ğ´(cid:4667)ğ‘“(cid:2872)(cid:3404)ğ¼ğ‘“ğ‘‡â„ğ‘’ğ‘›(cid:4666)ğ‘‡ğ‘œğº,ğ‘‹,(cid:4668)ğ‘‡ğ‘œ(cid:4666)ğµ,ğ‘‹(cid:4667)(cid:4669)(cid:4667)ğ‘(cid:2868)ğ‘(cid:2869)ğ‘(cid:2870)ğ‘(cid:2871)ğ‘“(cid:2868)ğ‘“(cid:2868)ğ‘“(cid:2868)ğ‘“(cid:2869)ğ‘“(cid:2869)ğ‘“(cid:2869)â€¦ğ‘“(cid:3041)ğ‘“(cid:3041)ğ‘(cid:3040)(cid:2879)(cid:3039)ğ‘(cid:3040)â€¦ğ¥ğğ ğ¢ğ­ğ¢ğ¦ğšğ­ğ ğšğ¬ğ¬ğ¢ğ ğ§ğ¦ğğ§ğ­ğ¬ğŸ‘.ğ‹ğğ ğ¢ğ­ğ¢ğ¦ğšğ­ğ ğ€ğ¬ğ¬ğ¢ğ ğ§ğ¦ğğ§ğ­ğ¬ ğƒğğğ®ğœğ­ğ¢ğ¨ğ§ABCDEFGX---T-T-Y---F-F-ğˆğ§ğ¢ğ­ğ¢ğšğ¥ ğšğ¬ğ¬ğ¢ğ ğ§ğ¦ğğ§ğ­ ğšğŸğŸ.ğ€ğ«ğ ğ®ğ¦ğğ§ğ­ğ¬ ğ„ğ±ğ­ğ«ğšğœğ­ğ¢ğ¨ğ§ğğ©ğ­ğ¢ğ¨ğ§ğ¬ğŸ.ğ…ğ®ğ§ğœğ­ğ¢ğ¨ğ§ ğ„ğ±ğ­ğ«ğšğœğ­ğ¢ğ¨ğ§ğ´ğ‘›ğ‘ ğ‘¤ğ‘’ğ‘Ÿğğšğ¬ğ¬ğšğ ğ ğšğ§ğ ğğ®ğğ¬ğ­ğ¢ğ¨ğ§Type

Function

Args

Relational
Functions

Before/After

Same/Different

Compositional
Functions
Counting
Functions

To

IfThen

FirstPos/LastPos

participant1
participant2

participant1
position1
function set F1
function set F2
participant1,
number m

Description
Whether participant1 is in the
position before/after participant2.
Whether participant1 is in the
same/different position with participant2.
Whether participant1 is assigned
to position1.
If functions in F1 satisï¬ed,
then functions in F2 satisï¬ed.
Whether participant1 is assigned
to the ï¬rst/last m positions.

Table 3: A fragment of the logical constraint function deï¬nition.

guments in the sentence as the input and predicts
their potential function type. Speciï¬cally, given
a rule as the input X, we follow Xu et al. (2020)
and modify the input by adding special tokens â€œ@â€
and â€œ#â€ before and after the ï¬rst and second parsed
arguments respectively. Then we encode sentence
X with RoBERTa model as follows:

H = RoBERTa(X).

(1)

Afterwards, we take the representation of the ï¬rst
â€œ@â€ and â€œ#â€ for classiï¬cation.

f unction = argmax(classiï¬er([H @; H #])),

(2)
where [;] denotes concatenation, and the classi-
ï¬er is a linear layer followed by a softmax func-
tion. , and p is the possibilities distribution over
class number. Since there is no annotated data of
corresponding logical functions, we need to con-
struct the training data automatically. The training
data consist of (1) positive instances: all the {in-
put: (rule, arguments); label: function} pairs that
extracted by the symbolic parsing method from
the training set; (2) negative instances: the same
number of instances that have arguments with no
function related.

4.2.3 Legitimate Assignments Deduction
Given the extracted logical constraint functions
and the initial assignment, we conduct reasoning
to ï¬nd the legitimate assignments that satisfy all
the constraints. The process is formulated into
a tree-based reasoning algorithm. As shown in
Figure 4, each node in a tree corresponds to an
assignment and each edge indicates a logical func-
tion. A node v with path {e0, e1, ..., ei} from the
root indicates that its assignment satisï¬es functions
{f0, f1, ..., fi}. Suppose we have n constraint func-
tions, we need to ï¬nd all the leaf nodes with depth
n. These leaf nodes satisfy all the functions and
thus become legitimate assignments.

Figure 4: An example of the reasoning process. Newly
added participants in f0 are highlighted.
(1) and (2)
conducted recursively until depth = n. (T /F/âˆ’) =
(T rue/F alse/U nknown)

Therefore, we introduce how to construct the

complete reasoning tree by the following steps:

1) Firstly, we start with the root, which is the cer-
tain initial assignment decided by facts. For
the function f0, we generate all possible as-
signments related to newly added arguments
in f0. As shown in the example in Figure 4,
for the function IfThen(To(A, X), To(B, Y )),
we generate all possible assignments related
to the new participants A and B.

2) We execute f0 to ï¬nd all the legitimate
assignments that satisfy f0 as a group of
children of the root.
In the same exam-
ple, we keep the assignments that meets

(2) ğ‘­ğ’–ğ’ğ’„ğ’•ğ’Šğ’ğ’ ğ‘¬ğ’™ğ’†ğ’„ğ’–ğ’•ğ’Šğ’ğ’ ğ’•ğ’ ğ’‡ğ’Šğ’ğ’… ğ’„ğ’ğ’ğ’‡ğ’ğ’Šğ’„ğ’•ABCDEFGX---T-T-Y---F-F-ğ¼ğ‘›ğ‘–ğ‘¡ğ‘–ğ‘ğ‘™ ğ‘ğ‘ ğ‘ ğ‘–ğ‘”ğ‘›ğ‘šğ‘’ğ‘›ğ‘¡ ğ‘(cid:2868)ğ‘“(cid:2868)(cid:3404)ğ¼ğ‘“ğ‘‡â„ğ‘’ğ‘›ğ‘‡ğ‘œğ´,ğ‘‹,ğ‘‡ğ‘œğµ,ğ‘Œ(1) ğ‘®ğ’†ğ’ğ’†ğ’“ğ’‚ğ’•ğ’† ğ’‘ğ’ğ’”ğ’”ğ’Šğ’ƒğ’ğ’† ğ’‚ğ’”ğ’”ğ’Šğ’ˆğ’ğ’ğ’†ğ’ğ’•ğ’”ABCDEFGXTF-T-T-YFT-F-F-ABCDEFGXFT-T-T-YTF-F-F-ABCDEFGXFF-T-T-YTT-F-F-ABCDEFGXTT-T-T-YFF-F-F-ğ‘(cid:2869)ğ‘(cid:2870)ğ‘(cid:2871)ğ‘(cid:2872)ğ‘(cid:2868)ğ‘“(cid:2868)ğ‘“(cid:2868)ğ‘“(cid:2868)ğ‘(cid:2869)ğ‘(cid:2870)ğ‘(cid:2871)Conflict with ğ‘“(cid:2868)ğ‘(cid:2868)ğ‘¹ğ’†ğ’‚ğ’”ğ’ğ’ğ’Šğ’ğ’ˆ ğ‘»ğ’“ğ’†ğ’† ğ‘¬ğ’™ğ’•ğ’†ğ’ğ’”ğ’Šğ’ğ’ğ‘¨ğ’”ğ’”ğ’Šğ’ˆğ’ğ’ğ’†ğ’ğ’• ğ‘®ğ’†ğ’ğ’†ğ’“ğ’‚ğ’•ğ’Šğ’ğ’ğ‘­ğ’–ğ’ğ’„ğ’•ğ’Šğ’ğ’ğ’‡ğŸğ·ğ‘’ğ‘ğ‘¡â„(cid:3404)1IfThen(To(A, X), To(B, Y )).

5.1 Model Comparison

3) Then we select each child as a new root and
select function f1 for further extension of the
reasoning tree.

These processes are recursively conducted until
depth n, which means that all the functions are
used to construct the reasoning tree. The tree-based
manner reduces the computational complexity and
can be further accelerated by ranking the functions.
The procedure is summarized into pseudo-code in
Appendix A. Therefore, this algorithm has advan-
tages of performing explicit interpretable reasoning
over the extracted functions.

4.2.4 Answer Selection
Previous steps understand the passage and the ques-
tion. In this part, we introduce how to analyze the
options, and match the options with the deducted
legitimate assignments beyond word-level for mak-
ing a ï¬nal prediction. Speciï¬cally, we can derive
two types of information from an option:

1) Assignment-based option indicates an as-
signment. For example, â€œA and C both serve
on the X committee" can be interpreted as:
{(A, X) = True; (C, X) = True}. For this
type, we match the parsed option assignment
with all the legitimate assignments and calcu-
late an assignment-based matching score.

2) Function-based option indicates an option
representing a logical function, like â€œThe
sedan is serviced earlier in the week than the
roadster", which can be parsed into the func-
tion â€œBefore(sedan, roadster)". We execute
the option-based function on the legitimate
assignments to ï¬nd the satisï¬able option and
calculate a function-based matching score.

These two types of scores are combined for making
a conclusion. The question types and score calcu-
lating methods are summarized in the Appendix C.

5 Experiments

In this section, we focus on evaluating the pre-
sented methods on AR-LSAT. We split the data
into (train/dev./test) = (1, 585/231/230). We also
hold out a small test set for human evaluation.
Moreover, case study illustrates the reasoning pro-
cess of the ARM method by an explicit example.
Lastly, we make error analysis to point out chal-
lenges in this task.

Human Performance Since the dataset is based
on a test designed for undergraduate students, we
select nearly 100 instances in the AR-LSAT dataset
and ask 10 undergraduate college students major-
ing in literature, commerce and law to answer these
questions. In order to prevent the training bias, we
select students who have not received LSAT pro-
fessional training before. We take their averaged
performance as human performance and report it
in Table 5.

Transformer-based Methods We take various
powerful Transformer-based pre-trained language
models, including BERT (Devlin et al., 2018), XL-
Net (Yang et al., 2019), RoBERTa (Liu et al., 2019),
and the recent ALBERT (Lan et al., 2019)), as
the backbones of the Transformer-based methods
and investigate their performance on the AR-LSAT
dataset. The implementation details of these mod-
els are given in Appendix D.

ARM To evaluate the performance of arguments
extraction, we manually annotate the correct par-
ticipants and positions in the development set as
labels and report the accuracy and recall of in Table
4. For function extraction, we deï¬ne a API set to
include roughly 20 types of logical functions like
Before, After, To, IfThen and realize their executors.
The detailed deï¬nition of functions can be found
in Appendix B.

Participants
Positions

Acc. (%) Recall (%)
96.17
84.42

92.88
85.79

Table 4: Performance of extraction of participants and
positions on the development set.

Methods

Human Performance
Random Guess
BERT
XLNet
RoBERTa
ALBERT
ARM

Dev.
Acc (%)
-
20.0%
23.4%
23.8%
24.2%
24.4%
34.2%

Test
Acc (%)
59.7%
20.0%
21.4%
22.5%
23.1%
23.0%
30.9%

Table 5: The performance on the AR-LSAT dataset.

Figure 5: A case study on the AR-LSAT dataset. Our system correctly extracts participants, positions, and rules
from the context. Afterwards, it interprets rules into logical functions. After deduction, our system ï¬nds legitimate
assignments and makes the correct prediction. Rules are highlighted in blue.

Results
In Table 5, we report the performance
of different methods and human performance on
the development and test set. Firstly, we observe
that the Transformer-based models struggle to do
well on this task, and achieve close performance
with random guess. This observation indicates that
analytical reasoning is extremely challenging for
current neural pre-trained language models as it
requires the ability of complex reasoning. In addi-
tion, ARM with context understanding and explicit
reasoning process outperforms Transformer-based
method with 34.2% accuracy on the development
set and 30.9% accuracy on the test set. It is also
noticed that the performance of both our system
and baselines are still far from human performance,
leaving signiï¬cant opportunities for further explo-
ration.

5.2 Case Study

We present a case study in Figure 5 to illustrate
the reasoning process of the ARM framework with
interpretable results. ARM extracts correct argu-
ments from the context, and interprets the rules
into logical constraint functions. Afterwards, it per-
forms deduction to ï¬nd legitimate solutions. Lastly,
it matches the options with the legitimate solutions
and calculates a score for each option. Option A
achieves the highest score because it accords with
legitimate assignments. This analysis demonstrates
that ARM has better explicit interpretable reason-
ing ability.

5.3 Error Analysis

We randomly select 50 instances that are wrongly
predicted by ARM from the development set and
manually summarize the major error types.

The dominant error type is that some rules with
complex semantics are not covered by current con-
straint logical function set. For example, given a
rule â€œEach crew member does at least one task dur-
ing the installation." , we should map â€œAt least" to
function AtLeastNum.

The second type of errors is caused by failing to
extract correct participants or positions by the NER
model and predeï¬ned matching pattern.

The third error type is caused by the lack of ba-
sic commonsense knowledge, which is required for
understanding the concept in the rules. For exam-
ple, when a passage mentioned â€œSix entertainers
should be scheduled at 9:00 A.M., 2:00 P.M., etc"
and the rule is â€œSome participants should be sched-
uled in the morning.", the system fails to match the
morning with a speciï¬c time zone.

5.4 Discussion

We would like to further highlight important direc-
tions to facilitate research on analytical reasoning.
One of the major challenges lies in deep un-
derstanding of the knowledge in the context, like
parsing the rules into logically equivalent symbolic
functions. Deriving machine-understandable func-
tions from natural language is an essential step
towards deeper understanding and reasoning. Al-
though supervised semantic parsing has achieved

Passage: A professor must determine the order in which five of her students â€”Fernando, Ginny, Hakim, Juanita, and Kevin â€”will perform in an upcoming piano recital. Each student performs one piece, and no two performances overlap. The following constraints apply:Ginny must perform earlier than Fernando. Kevin must perform earlier than Hakim and Juanita. Hakim must perform either immediately before or immediately after Fernando.Question:  If Juanita performs earlier than Ginny, then which one of the following could be true?Options:(cid:4666)ğ´(cid:4667) Fernando performs fourth. âˆš(cid:4666)ğµ(cid:4667) Ginny performs second.  (cid:4666)ğ¶(cid:4667) Hakim performs third.(cid:4666)ğ·(cid:4667) Juanita performs third.  (cid:4666)ğ¸(cid:4667) Kevin performs secondParticipants & PositionsFernando, Ginny, Hakim, Juanita, Kevinfirst, second, third, fourth, fifthRules &Functions(1)Ginny must perform earlier than Fernando. (2)Kevin must perform earlier than Hakim and Juanita. (3)Hakim must perform either immediately before or immediately after Fernando.(4)Juanita performs earlier than Ginny(cid:4666)1(cid:4667)ğµğ‘’ğ‘“ğ‘œğ‘Ÿğ‘’ (cid:4666)ğºğ‘–ğ‘›ğ‘›ğ‘¦,ğ¹ğ‘’ğ‘Ÿğ‘›ğ‘ğ‘›ğ‘‘ğ‘œ(cid:4667)(cid:4666)2(cid:4667)ğ´ğ‘›ğ‘‘ (cid:4666)(cid:4668)ğµğ‘’ğ‘“ğ‘œğ‘Ÿğ‘’ (cid:4666)ğ¾ğ‘’ğ‘£ğ‘–ğ‘›,ğ»ğ‘ğ‘˜ğ‘–ğ‘š(cid:4667)(cid:4669),(cid:4668)ğµğ‘’ğ‘“ğ‘œğ‘Ÿğ‘’(cid:4666)ğ¾ğ‘’ğ‘£ğ‘–ğ‘›,ğ½ğ‘¢ğ‘ğ‘›ğ‘–ğ‘¡ğ‘(cid:4667)(cid:4669)(cid:4667)(cid:4666)3(cid:4667)ğ‘‚ğ‘Ÿ (cid:4666)(cid:4668)ğ‘ğ‘’ğ‘¥ğ‘¡ (cid:4666)ğ»ğ‘ğ‘˜ğ‘–ğ‘š,ğ¹ğ‘’ğ‘Ÿğ‘›ğ‘ğ‘›ğ‘‘ğ‘œ(cid:4667)(cid:4669),(cid:4668)ğ¿ğ‘ğ‘ ğ‘¡ (cid:4666)ğ»ğ‘ğ‘˜ğ‘–ğ‘š,ğ¹ğ‘’ğ‘Ÿğ‘›ğ‘ğ‘›ğ‘‘ğ‘œ(cid:4667)(cid:4669)(cid:4667)(cid:4666)4(cid:4667)ğµğ‘’ğ‘“ğ‘œğ‘Ÿğ‘’ (cid:4666)ğ½ğ‘¢ğ‘ğ‘›ğ‘–ğ‘¡ğ‘,ğºğ‘–ğ‘›ğ‘›ğ‘¦(cid:4667)Legal AssignmentsOption Scoresğ‘¨ ğŸğµ (cid:3398)1ğ¶ (cid:3398)1ğ· (cid:3398)1ğ¸ (cid:3398)1ğŸğ’”ğ’•ğŸğ’ğ’…ğŸ‘ğ’“ğ’…ğŸ’ğ’•ğ’‰ğŸ“ğ’•ğ’‰FernandoFFFTFGinnyFFTFFHakimFFFFTJuanitaFTFFFKevinTFFFFğŸğ’”ğ’•ğŸğ’ğ’…ğŸ‘ğ’“ğ’…ğŸ’ğ’•ğ’‰ğŸ“ğ’•ğ’‰FernandoFFFFTGinnyFFTFFHakimFFFTFJuanitaFTFFFKevinTFFFFpromising progress in recent years, obtaining com-
plete human-annotated logical functions is imprac-
tical for this task. Therefore, further study can fo-
cus on function extraction with no annotated func-
tions or small amount of annotated functions.

Furthermore, a better inference engine built upon
logical functions is also essential because AR ques-
tions require deeper reasoning abilities far beyond
just understanding the literal clues. Standard sym-
bolic systems like expert systems can provide ex-
plicit reasoning, but they are difï¬cult to deal with
uncertainty in data. Although neural-based meth-
ods are more ï¬‚exible at dealing with uncertainty,
they still struggle to perform interpretable and ex-
plicit reasoning. It is promising to better integrate
neural and symbolic systems to improve this task
with deeper reasoning ability.

6 Conclusion

In this paper, we study the challenging task of ana-
lytical reasoning and introduce a dataset AR-LSAT
to facilitate research on analytical reasoning. We
analyze the knowledge understanding and reason-
ing ability required for this task and present two
basic approaches: a Transformer-based approach
and a logical-level reasoning framework, named
Analytical Reasoning Machine (ARM). ARM ex-
tracts symbolic knowledge, including participants,
facts and rules mentioned in the context and ex-
tract logical functions from the rules. Afterwards,
it performs deep reasoning to ï¬nd all the legiti-
mate solutions to the problem posed and ï¬nally
makes a prediction. ARM sheds a light on the
reasoning procedure for analytical reasoning, and
each component can be further developed. Ex-
periments show that this task is very challenging
for current Transformer-based pre-trained language
models and ARM outperforms them with better per-
formance and interpretability. Further discussions
are made to shed light on important future direc-
tions.

References

Chandra Bhagavatula, Ronan Le Bras, Chaitanya
Malaviya, Keisuke Sakaguchi, Ari Holtzman, Han-
nah Rashkin, Doug Downey, Scott Wen tau Yih, and
Yejin Choi. 2019. Abductive commonsense reason-
ing.

In Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing (EMNLP).
Association for Computational Linguistics.

Peter Clark, Oren Etzioni, Tushar Khot, Ashish Sab-
harwal, Oyvind Tafjord, Peter Turney, and Daniel
Khashabi. 2016. Combining retrieval, statistics, and
inference to answer elementary science questions.
In Proceedings of the AAAI Conference on Artiï¬cial
Intelligence, volume 30.

Ido Dagan, Oren Glickman, and Bernardo Magnini.
2005. The pascal recognising textual entailment
challenge. pages 177â€“190.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. Bert: Pre-training of deep
bidirectional transformers for language understand-
ing. arXiv preprint arXiv:1810.04805.

Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel
Stanovsky, Sameer Singh, and Matt Gardner. 2019.
Drop: A reading comprehension benchmark re-
quiring discrete reasoning over paragraphs. arXiv
preprint arXiv:1903.00161.

Felix A Gers, JÃ¼rgen Schmidhuber, and Fred Cummins.
1999. Learning to forget: Continual prediction with
lstm.

Mohammad Javad Hosseini, Hannaneh Hajishirzi,
Oren Etzioni, and Nate Kushman. 2014. Learning
to solve arithmetic word problems with verb catego-
rization. In Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 523â€“533.

Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, and
Yejin Choi. 2019a. Cosmos qa: Machine reading
comprehension with contextual commonsense rea-
soning. arXiv preprint arXiv:1909.00277.

Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, and
Yejin Choi. 2019b. Cosmos QA: Machine reading
comprehension with contextual commonsense rea-
soning. In Proceedings of the 2019 Conference on
Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natu-
ral Language Processing (EMNLP-IJCNLP), pages
2391â€“2401, Hong Kong, China. Association for
Computational Linguistics.

Naoya Inoue, Pontus Stenetorp, and Kentaro Inui. 2020.
R4C: A benchmark for evaluating RC systems to get
the right answer for the right reason. In Proceedings
of the 58th Annual Meeting of the Association for
Computational Linguistics, pages 6740â€“6750, On-
line. Association for Computational Linguistics.

Tushar Khot, Ashish Sabharwal, and Peter Clark. 2018.
SciTail: A textual entailment dataset from science
question answering. In AAAI.

Samuel R. Bowman, Gabor Angeli, Christopher Potts,
and Christopher D. Manning. 2015. A large anno-
tated corpus for learning natural language inference.

Jeff Kolby. 2016. Master The LSAT: Includes 4 Ofï¬-
cial LSATs! (Novaâ€™s Master the LSAT). Nova Press
(August 17, 2016).

Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish
Sabharwal, Oren Etzioni, and Siena Dumas Ang.
2015. Parsing algebraic word problems into equa-
tions. Transactions of the Association for Computa-
tional Linguistics, 3:585â€“597.

Nate Kushman, Yoav Artzi, Luke Zettlemoyer, and
Regina Barzilay. 2014. Learning to automatically
solve algebra word problems. In Proceedings of the
52nd Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
271â€“281.

Zhenzhong Lan, Mingda Chen, Sebastian Goodman,
Kevin Gimpel, Piyush Sharma, and Radu Soricut.
2019. Albert: A lite bert for self-supervised learn-
arXiv preprint
ing of language representations.
arXiv:1909.11942.

Chen Liang, Jonathan Berant, Quoc Le, Kenneth D For-
bus, and Ni Lao. 2016. Neural symbolic machines:
Learning semantic parsers on freebase with weak su-
pervision. arXiv preprint arXiv:1611.00020.

Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blun-
som. 2017. Program induction by rationale genera-
tion: Learning to solve and explain algebraic word
problems. arXiv preprint arXiv:1705.04146.

Hanmeng Liu, Leyang Cui, Jian Liu, and Yue Zhang.
2020a. Natural
language inference in contextâ€“
investigating contextual reasoning over long texts.
arXiv preprint arXiv:2011.04864.

Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang,
Yile Wang, and Yue Zhang. 2020b. Logiqa: A chal-
lenge dataset for machine reading comprehension
with logical reasoning. Proceedings of the Twenty-
Ninth International Joint Conference on Artiï¬cial In-
telligence.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Roberta: A robustly optimized bert pretraining ap-
proach. arXiv preprint arXiv:1907.11692.

Yixin Nie, Adina Williams, Emily Dinan, Mohit
Bansal, Jason Weston, and Douwe Kiela. 2019. Ad-
versarial nli: A new benchmark for natural language
understanding. ArXiv, abs/1910.14599.

Simon Ostermann, Michael Roth, Ashutosh Modi, Ste-
fan Thater, and Manfred Pinkal. 2018. Semeval-
2018 task 11: Machine comprehension using com-
monsense knowledge. In Proceedings of the 12th In-
ternational Workshop on semantic evaluation, pages
747â€“757.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. GloVe: Global vectors for word
representation. In Proceedings of the 2014 Confer-
ence on Empirical Methods in Natural Language
Processing (EMNLP), pages 1532â€“1543, Doha,
Qatar. Association for Computational Linguistics.

Matthew E Peters, Waleed Ammar, Chandra Bhagavat-
ula, and Russell Power. 2017. Semi-supervised se-
quence tagging with bidirectional language models.
arXiv preprint arXiv:1705.00108.

Alec Radford, Jeffrey Wu, Rewon Child, David Luan,
Dario Amodei, and Ilya Sutskever. 2019. Language
models are unsupervised multitask learners. OpenAI
blog, 1(8):9.

Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and
Percy Liang. 2016.
Squad: 100,000+ questions
for machine comprehension of text. arXiv preprint
arXiv:1606.05250.

Hannah Rashkin, Maarten Sap, Emily Allaway,
Noah A Smith, and Yejin Choi. 2018. Event2mind:
Commonsense inference on events, intents, and re-
actions. arXiv preprint arXiv:1805.06939.

David Saxton, Edward Grefenstette, Felix Hill, and
Pushmeet Kohli. 2019. Analysing mathematical rea-
soning abilities of neural models. arXiv preprint
arXiv:1904.01557.

Alon Talmor and Jonathan Berant. 2018. The web as
a knowledge-base for answering complex questions.
In NAACL-HLT.

Alon Talmor, Yanai Elazar, Yoav Goldberg, and
Jonathan Berant. 2020. olmpics-on what language
model pre-training captures. Transactions of the As-
sociation for Computational Linguistics, 8:743â€“758.

Alon Talmor, Jonathan Herzig, Nicholas Lourie, and
Jonathan Berant. 2018. Commonsenseqa: A ques-
tion answering challenge targeting commonsense
knowledge. arXiv preprint arXiv:1811.00937.

Alex Wang, Amanpreet Singh, Julian Michael, Felix
Hill, Omer Levy, and Samuel R. Bowman. 2018.
GLUE: A multi-task benchmark and analysis plat-
form for natural language understanding. CoRR,
abs/1804.07461.

Johannes Welbl, Pontus Stenetorp, and Sebastian
Riedel. 2017. Constructing datasets for multi-hop
reading comprehension across documents.

Johannes Welbl, Pontus Stenetorp, and Sebastian
Riedel. 2018. Constructing datasets for multi-hop
reading comprehension across documents. Transac-
tions of the Association for Computational Linguis-
tics, 6:287â€“302.

Sean Welleck, Jason Weston, Arthur Szlam, and
Kyunghyun Cho. 2018. Dialogue natural language
inference.

Adina Williams, Nikita Nangia, and Samuel Bowman.
2018. A broad-coverage challenge corpus for sen-
tence understanding through inference. In Proceed-
ings of the 2018 Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies, Volume
1 (Long Papers), pages 1112â€“1122, New Orleans,

Louisiana. Association for Computational Linguis-
tics.

A Pseudo-code of Legitimate
Assignments Deduction

Chad C Williams, Mitchel Kappen, Cameron D Has-
sall, Bruce Wright, and Olave E Krigolson. 2019.
Thinking theta and alpha: Mechanisms of intuitive
and analytical reasoning. NeuroImage, 189:574â€“
580.

Zenan Xu, Daya Guo, Duyu Tang, Qinliang Su,
Linjun Shou, Ming Gong, Wanjun Zhong, Xi-
aojun Quan, Nan Duan, and Daxin Jiang. 2020.
Syntax-enhanced pre-trained model. arXiv preprint
arXiv:2012.14116.

Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-
bonell, Russ R Salakhutdinov, and Quoc V Le. 2019.
Xlnet: Generalized autoregressive pretraining for
language understanding. In Advances in neural in-
formation processing systems, pages 5753â€“5763.

Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,
William Cohen, Ruslan Salakhutdinov, and Christo-
pher D. Manning. 2018a. Hotpotqa: A dataset for
diverse, explainable multi-hop question answering.
Proceedings of the 2018 Conference on Empirical
Methods in Natural Language Processing.

Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben-
gio, William W Cohen, Ruslan Salakhutdinov, and
Christopher D Manning. 2018b. Hotpotqa: A
dataset for diverse, explainable multi-hop question
answering. arXiv preprint arXiv:1809.09600.

Weihao Yu, Zihang Jiang, Yanfei Dong, and Jiashi
Feng. 2020. Reclor: A reading comprehension
dataset requiring logical reasoning. arXiv preprint
arXiv:2002.04326.

Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali
Farhadi, and Yejin Choi. 2019. Hellaswag: Can a
machine really ï¬nish your sentence? arXiv preprint
arXiv:1905.07830.

Sheng Zhang, Xiaodong Liu, Jingjing Liu, Jianfeng
Gao, Kevin Duh, and Benjamin Van Durme. 2018.
Record: Bridging the gap between human and ma-
chine commonsense reading comprehension. arXiv
preprint arXiv:1810.12885.

Ben Zhou, Daniel Khashabi, Qiang Ning, and Dan
Roth. 2019.
" going on a vacation" takes longer
than" going for a walk": A study of tempo-
arXiv preprint
ral commonsense understanding.
arXiv:1909.03065.

Require: A set of constraint functions F = {f0, f1, ..., fn}

and an initial assignment a0

return

if depth == n then:

end if
function = functions[depth]
old_pars = node.participants
old_assign = node.assignment
new_pars = ï¬nd_new_participant(function, old_pars)
all_assign = gen_all_assign(old_assign, new_pars)
satisï¬ed = ï¬nd_satisï¬ed(all_assign, function)
depth = depth+1
children = update_notes(node, satisï¬ed, new_pars)
for child in children do

1: function CONSTRUCTTREE(node,functions,depth,n)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16: end function
17: root = Node(a0)
18: depth = 0
19: n = length of F
20: complete_tree = CONSTRUCTTREE(root, F , depth, n)
21: legitimate = nodes in complete_tree with depth n
22: return legitimate

CONSTRUCTTREE(child, functions, depth, n)

end for

B Function Deï¬nition

In this part, we present the detailed description and
trigger words for each logical constraint functions
in Table 7.

C Question Type

In this part, we list common question types in the
AR-LSAT datasets and give examples in Table 6.
We further introduce how we calculate a score for
dominant question type with a group of legitimate
assignments.

1) Must be true/false: this question type needs
to select answer that must be true in all the as-
signments. We match all the assignments with
the option.
If one option accords/conï¬‚icts
with one assignment, the single matching
score will be 1/-1, otherwise the score will
be 0. We then calculate the sum of all the
matching scores as the ï¬nal score.

2) Could be true/false: this question type needs
to select answer that could be true in one of
the legitimate assignments. We match all the
assignments with the option. If one option
accords/conï¬‚icts with one assignment, the sin-
gle matching score will be 1/-1, otherwise the
score will be 0. We then calculate the maxi-
mum matching scores as the ï¬nal score. The

Question Type
Acceptable solution

Complete list

Could be true/false with condition
Must be true/false with condition
Negation

Substitution

Condition for unique solution

Calculation

Earliest/latest position

Maximum/minimum members

Example
Which one of the following could be the schedule of the studentsâ€™ reports?
Which one of the following could be a complete and accurate list of
the books placed on the bottom shelf?
If Himalayans are not featured on day 7. which one of the following could be true?
If Theresa tests G on the second day. then which one of the following must be true?
P CANNOT be performed at?
Which one of the following. if substituted for the condition that Waiteâ€™s audition
must take place earlier than the two recorded auditions.
would have the same effect in determining the order of the auditions?
The assignment of parking spaces to each of the new employees is fully and uniquely
determined if which one of the following is true?
How many of the students are there who could be the one assigned to 1921?
If Zircon performs in an earlier slot than Yardsign. which one of the following
is the earliest slot in which Wellspring could perform?
What is the minimum number of solos in which Wayne performs a traditional piece?

Table 6: Question types of AR-LSAT dataset.

Acceptable solution question type also use this
method to calculate score.

task: Masked LM and Nest Sentence Predic-
tion.

â€¢ XLNet

(Yang et al., 2019)

is also a
transformer-based model, pre-trained on
BooksCorpus, Wikipedia, Giga5, ClueWeb
2012-B and Common Crawl with Permuta-
tion Language Modeling.

â€¢ RoBERTa (Liu et al., 2019) is a transformer-
based model with the same model structure as
BERT but trained on a larger corpus and on a
different training setting.

â€¢ ALBERT (Lan et al., 2019) is a most recent
transformer-based pre-trained model. AL-
BERT uses parameter-reduction techniques
that support large-scale conï¬gurations.

D.2

Implementation Details

For all the baselines, we employ cross-entropy loss
as the loss function and select AdamW as the opti-
mizer for model training/ ï¬ne-tuning. These base-
lines add a simple classiï¬cation layer on the top of
them and take the the last hidden state as the input.
For all the Transformer-based models, we employ
base model as the backbone.

3) Maximum number of participants in a po-
sition: this question type needs to calculate
the maximum possible number of participants
in a speciï¬ed position (group). We calculate
the maximum number of participants in all the
legetimate assignments and calculate the abso-
lute difference with the number in the option
as the ï¬nal score.

4) Find the earliest position of a participant:
this question type needs to calculate the earli-
est possible position of a speciï¬c participant.
We calculate the index of the earliest position
of the participant in all the legitimate assign-
ments and calculate the absolute difference
with the number in the option as the ï¬nal
score.

5) Count the number of possible positions
that a participant can be assigned in: for
this question type, we count all the non-
repetitive assignments of the speciï¬c partici-
pant and calculate the absolute difference with
the number in the option as the ï¬nal score.

D Baseline Models

D.1 Descriptions

â€¢ LSTM (Gers et al., 1999) is a classical RNN-
based model. We apply Bi-LSTM with
GloVE (Pennington et al., 2014) embedding.

â€¢ BERT (Devlin et al., 2018) is a transformer-
based model pre-trained on BooksCorpus and
Wikipedia with two unsupervised learning

Type

Function

Arguments

Before

After

Last

Next

Adjacent

Different

Same

BeforeEqual

AfterEqual

To

IfThen

IFF

And

Or

Unless

Neither

FirstPos

LastPos

participant 1
participant 2

participant
position

function set 1
function set 2

participant
number

Relational
Functions

Compos.
Functions

Counting
Functions

Description
whether participant 1 is in the
position before participant 2
whether participant 1 is in the
position after participant 2
whether participant 1 is in the
last position of participant 2
whether participant 1 is next
to participant 2
whether participant 1 is
neighboring to participant 2
whether participant 1 in the different
position with participant 2
whether the ï¬rst participant in the same
position with the second participant
whether participant 1 before
or equals to the position of participant 2
whether participant 1 after or equals
to the position of participant 2
Whether the participant is
assigned to the position
If rules in rule set 1 satisï¬ed,
then rules in rule set 2 satisï¬ed
Rules in rule set 1 satisï¬ed if and
only if rules in rule set 2 satisï¬ed
Rules in rule set 1 satisï¬ed and
rules in the rule set 2 satisï¬ed
Rules in rule set 1 satisï¬ed or
rules in rule set 2 satisï¬ed
Rules in rule set 1 satisï¬ed unless
rules in rule set 2 satisï¬ed
Neither rules in rule set 1 satisï¬ed
nor rules in rule set 2 satisï¬ed
Whether the participant is in the
last (number) positions
Whether the participant is in the
ï¬rst (number) positions

Trigger Words
before, above,
precede, earlier
after, larger, higher
bigger, older
immediately before,
last
immediately after,
next
neighboring,
adjacent

different

same, also

no later

no earlier

to, on, give, in

If... then, If ... , ...

if and only if

and

or

unless

Neither ... nor ...

one of the
last (number)
one of the
ï¬rst (number)

Table 7: Detailed function descriptions and corresponding trigger words

