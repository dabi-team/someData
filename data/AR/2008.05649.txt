Sensitivity Analysis of Error-Contaminated
Time Series Data under Autoregressive
Models with Application of COVID-19 Data

Qihuang Zhang and Grace Y. Yi1

Abstract

Autoregressive (AR) models are useful tools in time series analysis. Inferences under such
models are distorted in the presence of measurement error, which is very common in prac-
tice. In this article, we establish analytical results for quantifying the biases of the parameter
estimation in AR models if the measurement error eﬀects are neglected. We propose two
measurement error models to describe diﬀerent processes of data contamination. An es-
timating equation approach is proposed for the estimation of the model parameters with
measurement error eﬀects accounted for. We further discuss forecasting using the proposed
method. Our work is inspired by COVID-19 data, which are error-contaminated due to
multiple reasons including the asymptomatic cases and varying incubation periods. We
implement our proposed method by conducting sensitivity analyses and forecasting of the
mortality rate of COVID-19 over time for the four most populated provinces in Canada.
The results suggest that incorporating or not incorporating measurement error eﬀects yields
rather diﬀerent results for parameter estimation and forecasting.

0
2
0
2

g
u
A
3
1

]
E
M

.
t
a
t
s
[

1
v
9
4
6
5
0
.
8
0
0
2
:
v
i
X
r
a

Keywords: Autoregressive Model, COVID-19, Forecasting, Measurement Error, Sensitivity
Analysis, Time Series.

Short title: Time Series with Measurement Error COVID-19

1Corresponding Author: Department of Statistical and Actuarial Sciences, Department of Computer
Science, University of Western Ontario, London, Ontario, Canada, N6A 5B7. Department of Statistics and
Actuarial Science, University of Waterloo. Email: gyi5@uwo.ca

 
 
 
 
 
 
1

Introduction

Time series data are common in the ﬁelds of epidemiology, economics, and engineering.

Various models and methods have been developed for analyzing such data. The validity of

these methods, however, hinges on the condition that time series data are precisely collected.

This condition is restrictive in applications. Measurement error is often inevitable. In the

study of air pollution, for example, it is diﬃcult or even impossible to precisely obtain the

true measurement of the daily air population level.

Some work on time series subject to measurement error is available in the literature.

Tanaka (2002) proposed a Lagrange multiplier test to assess the presence of measurement

error in time series data. Staudenmayer and Buonaccorsi (2005) explored the classical mea-

surement error model for the autoregressive process. Tripodis and Buonaccorsi (2009) studied

measurement error in forecasting using the Kalman ﬁlter. Dedecker et al. (2014) considered

a non-linear AR(1) model with measurement error. Despite available discussions of measure-

ment error in time series, several limitations restrict the application scope of the existing

work. Most available methods consider only autoregressive models without the drift and

assume the simplest additive measurement error model. Furthermore, most work involves a

complex formulation to adjust for the measurement error eﬀects, which is not straightfor-

ward to implement for practitioners. In addition, to our knowledge, there is no available

work addresses measurement error eﬀects on prediction under autoregressive models.

In this article, we systematically explore analysis of error-prone time series data under

autoregressive models. We propose two types of models to delineate measurement error

processes: additive regression models and multiplicative models. These modeling schemes

oﬀer us great ﬂexibility in facilitating diﬀerent applications. We investigate the impact of the

naive analysis which ignores the feature of measurement error in the inferential procedures,

and we obtain analytical results for characterizing the biases incurred in the naive analysis.

We develop an estimating equation approach to adjust for the measurement error eﬀects on

time series analysis. We establish asymptotic results for the proposed estimators, and develop

the theoretical results for the forecasting of times series in the presence of measurement

error. Finally, we describe a block bootstrap algorithm for computing standard errors of the

1

proposed estimators.

Our work is partially motivated by the data of COVID-19, a wide-spread disease that has

become a global health challenge and has caused over ten million infections and half million

deaths as of August, 2020. Because of the special features of the disease, the COVID-19 data

introduce a number of new challenges: 1) due to the asymptomatic infected cases and the

patients with light symptoms who do not go to hospitals, the number of reported cases with

COVID-19 is typically smaller than the true number of infected cases; 2) due to the limited

test resources, many infected cases are not able to be identiﬁed instantly; and 3) the varying

incubation periods lead to the delay of the identiﬁcation of the infections. Consequently, the

discrepancy between the reported case number and the true case number can be substantial,

and ignoring these features and applying the traditional time series analysis method would

no longer produce valid results.

In this paper, we apply the developed methods to analyze the COVID-19 data. We are

interested in studying how the mortality rate in a region may change over time and describing

the trajectory of the death rate. While the mortality rate of a disease is deﬁned as the death

number divided by the case number, the determination of the mortality rate of COVID-19

is challenging. In contrast to the standard deﬁnition, Baud et al. (2020) estimated mortality

rates by dividing the number of deaths on a given day by the number of patients with

conﬁrmed COVID-19 infections 14 days earlier, driven by the consideration of the maximum

incubation time to be 14 days. Due to the unique features of COVID-19, there does not seem

to be a precise way to deﬁne the mortality rate of COVID-19. In this paper, we conduct

sensitivity analyses to assess the severity of the pandemic by using diﬀerent deﬁnitions of the

mortality rate and considering diﬀerent ways of modeling measurement error in the data.

The remainder of the article is organized as follows. The notation and the setup for

autoregressive time series models and the proposed measurement error models are introduced

in Section 2. In Section 3, we present the theoretical results for characterizing the impact of

measurement error on the analysis of time series data. In Section 4, we develop an estimating

equation approach to adjust for the biases due to measurement error.

In Section 5, we

implement the proposed method to analyze the COVID-19 data in four Canadian provinces.

The article is concluded with a discussion presented in Section 6.

2

2 Model Setup and Framework

2.1 Time Series Model

Consider a T × 1 vector of time series, X (T ) = (X1, X2, . . . , XT )T. We are interested in

modeling the dependence of Xt on it previous observations X (t−1) and we consider it to be

postulated by an autoregressive model with lag p

Xt = φ0 +

p
(cid:88)

j=1

φjXt−j + (cid:15)t,

(1)

where p is an integer smaller than T , (cid:15)(t) = ((cid:15)1, . . . , (cid:15)t)T is independent of X (t) = (X1, . . . , Xt)T

with each (cid:15)t having zero mean and variance σ2

(cid:15) , φ0 is a constant drift, and φ = (φ1, . . . , φp)T

is the regression coeﬃcient.

The additive form in (1) and the zero mean assumption of (cid:15)t show that φ0 and φ are

constrained by

φ0 = E(Xt) − {E( (cid:101)Xt−1)}Tφ,

(2)

where (cid:101)Xt−1 = (Xt−1, . . . , Xt−p)T. To make the process of Xt stationary, φ1, . . . , φp are further

constrained such that all the roots of the equation in z

zp − φ1zp−1 − · · · − φp = 0

have absolute values smaller than 1 (Brockwell and Davis 2002, Sec.3.1.). For example,

a stationary AR(1) process requires that |φ1| < 1, and a stationary AR(2) process needs

that (φ1 + φ2) < 1, (φ2 − φ1) < 1 and |φ2| < 1. Here we are interested in the estimation

of parameters, φ and φ0. Let µ denote the mean E(Xt) of the time series, which equals

if Xt is (weakly) stationary. When p = 1, the stationarity of a time series implies

φ0
1−φ1−...−φp
Var(Xt) = σ2
(cid:15)
1−φ2
1

for t = 1, . . . , T .

2.2 Estimation of Model Parameters

The estimation of the parameters in the AR(p) time series model (1) can be carried out by

the least squares method. To see this, we ﬁrst focus on estimation of φ = (φ1, . . . , φp)T. Let
S(φ) = (cid:80)T
j=1 φjXt−j)}2 be the sum of the squared diﬀerence between

t=p+1{Xt − (φ0 + (cid:80)p

3

Xt and its linearly combined history with lag p. Then applying the constraint (2) gives
S(φ) = (cid:80)T

(cid:105)2

(cid:104)

.

{Xt − E(Xt)} − { (cid:101)Xt−1 − E( (cid:101)Xt−1)}Tφ
To minimize S(φ) with respect to φ, we solve ∂S(φ)

t=p+1

∂φ = 0 for φ and obtain the solution

(cid:98)φ(LS) =

(cid:32) T

(cid:88)

t=p+1

(cid:110)

(cid:101)Xt−1 − E( (cid:101)Xt−1)

(cid:111) (cid:110)

(cid:101)Xt−1 − E( (cid:101)Xt−1)

(cid:111)T

(cid:33)−1

T
(cid:88)

t=p+1

(cid:110)

(cid:101)Xt−1 − E( (cid:101)Xt−1)

(cid:111)

{Xt − E(Xt)} ,

where for t = 1, . . . , T , E(Xt) can be estimated by 1
T

(cid:80)T

t=1 Xt, which is denoted as (cid:98)µ.

Next, by the constraint (2), replacing E(Xt) by (cid:98)µ gives an estimator of φ0:

(cid:98)φ(LS)
0 = (cid:98)µ − (cid:98)µ

p
(cid:88)

j=1

(cid:98)φj.

(3)

(4)

Re-expressing (1) as (cid:15)t = Xt − (φ0 + (cid:80)p

j=1 φjXt−j) and by the deﬁnition of S(φ), we may

estimate Var((cid:15)t) = σ2

(cid:15) by

(cid:98)σ2(LS)
(cid:15) =

=

1
T − p

1
T − p

S((cid:98)φ)

T
(cid:88)

{Xt − E(Xt)}2 −

t=p+1

2
T − p

T
(cid:88)

{Xt − E(Xt)}{ (cid:101)Xt−1 − E( (cid:101)Xt−1)}T (cid:98)φ

t=p+1

+

1
T − p

T
(cid:88)

t=p+1

with E(Xt) estimated by (cid:98)µ.

(cid:98)φT{ (cid:101)Xt−1 − E( (cid:101)Xt−1)}{ (cid:101)Xt−1 − E( (cid:101)Xt−1)}T (cid:98)φ

(5)

Estimators (3)–(5) can be derived in an alternative way. First, by the stationarity of the

Xt, for k = 0, . . . , p and p ≤ t, Cov(Xt, Xt−k) is time-independent and let γk denote it; it is

clear that γ0 represents Var(Xt) for any t. Let Γ be the autocovariance matrix




Γ =






γ0
...
γp−1

· · · γp−1
...
. . .
γ0

· · ·

.






Let (cid:98)γ = ( (cid:98)γ1, · · · , (cid:98)γp)T with (cid:98)γk = 1
k = 0, . . . , p, and let (cid:98)Γ be the estimator of Γ with γk replaced by (cid:98)γk for k = 0, . . . , p − 1.

t=k+1(Xt − (cid:98)µ)(Xt−k − (cid:98)µ) being an estimator of γk for

T −k

(cid:80)T

Next, we examine the summation terms in (3) and (5) by using the fact that as T → ∞,
(cid:80)T

t=p+1{Xt − E(Xt)}{ (cid:101)Xt−1 − E( (cid:101)Xt−1)}T p

t=p+1{Xt − E(Xt)}2

−→ γ, and

p
−→ γ0,

(cid:80)T

1
T −p

1
T −p

4

(cid:80)T

t=p+1{ (cid:101)Xt−1−E( (cid:101)Xt−1)}{ (cid:101)Xt−1−E( (cid:101)Xt−1)}T p

1
T −p
method of ﬁnding estimators for φ, φ0, and σ2

−→ Γ. Then, (3)–(5) motivate an alternative

(cid:15) , by solving the estimating equations:

φ = (cid:98)Γ−1
(cid:32)

(cid:98)γ;

φ0 =

1 −

(cid:33)

φi

(cid:98)µ;

p
(cid:88)

i=1

σ2
(cid:15) = (cid:98)γ0 − 2φT

(cid:98)γ + φT(cid:98)Γφ,

(6)

for φ, φ0, and σ2

(cid:15) . Let (cid:98)φ, (cid:98)φ0 and (cid:98)σ2

(cid:15) denote the resultant estimators of φ, φ0, and σ2
(cid:15) ,

respectively. These estimators are asymptotically equivalent to the least squares estimators
p
−→ 0, (cid:98)φ0 − (cid:98)φ(LS)

in a sense that (cid:98)φ − (cid:98)φ(LS)

p
−→ 0, as

(cid:98)φ(LS), (cid:98)φ(LS)

−→ 0 and (cid:98)σ2

(cid:15) − (cid:98)σ2(LS)

0 , and (cid:98)σ2(LS)

p

0

(cid:15)

(cid:15)

T → ∞, and hence, they are consistent (Box et al. 2015, Ch.7, A.7.4).

Estimating equations (6) oﬀer a uniﬁed estimation framework in its connections with

not only the least squares estimation but also the maximum likelihood method under the

assumption of Gaussian error as well as the Yule-Walker method. Similar to the least squares

method, ﬁnding estimators using one of those approaches is asymptotically equivalent to

solving (6) for φ, φ0 and σ2

(cid:15) (Box et al. 2015, Ch.7, A.7.4).

3 Measurement Error and Impact

3.1 Measurement Error Models

Suppose that for t = 1, . . . , T , the observation of Xt is subject to measurement error and

the precise measurement of Xt may not be observed, but its surrogate measurement X ∗
t

is

available. We consider two measurement error models.

The ﬁrst measurement error model takes an additive form

X ∗

t = α0 + α1Xt + et

(7)

for t = 1, . . . , T , where the error term et is independent of Xt with mean 0 and time-

independent variance σ2

e and is assumed to be independent for t = 1, . . . , T , and α = (α0, α1)T

is the parameter vector. Here, α0 represents the systematic error and α1 represents the

5

constant inﬂation (or shrinkage) due to the measurement error. For instance, if α0 = 0, then

setting α1 < 1 (or α1 > 1) features the scenario where X ∗

t tends to be smaller (or larger)

than Xt if the noise term is ignored. This model generalizes the classical additive model

considered by Staudenmayer and Buonaccorsi (2005) who considered the case with α0 = 0

and α1 = 1.

By the stationarity of the Xt, we note that model (7) yields E(X ∗

t ) = α0 + α1µ and

Var(X ∗

t ) = α2

1γ0 + σ2
e ;

(8)

the variability of the X ∗

t can be greater or smaller than that of the Xt, depending on the

value of α1.

The second measurement error model assumes a multiplicative form:

X ∗

t = β0utXt,

(9)

for t = 1, . . . , T , where β0 is a positive scaling parameter, and the ut are the error terms

which are independent of each other as well as of the Xt, and have mean one and time-

independent variance σ2

u. Depending on the distribution of the error term ut, (9) can feature

diﬀerent types of discrepancy between Xt and X ∗
t .

The stationarity of the Xt together with model (9) implies E(X ∗

t ) = β0µ, and

Var(X ∗

t ) = β2
0

(cid:8)(σ2

u + 1)γ0 + σ2

uµ2(cid:9) ,

(10)

where we use the independence of Xt and ut.

Since E(X ∗

t ) is time-independent for both (7) and (9), in the following discussion, we

let µ∗ denote E(X ∗

(7) or (9) introduces extra parameters {α0, α1, σ2

t ) for t = 1, . . . , T . The modeling of the measurement error process by
e } or {β0, σ2

u}, where the variance of the

error term is bounded by the variability of X ∗
u < Var(X ∗
t )
β2
0 µ2

t ) and (10) implies that σ2

σ2
e < Var(X ∗

.

t together with others. Clearly, (8) shows that

3.2 Naive Estimation and Bias for AR(1) Model

Estimating equations (6) are useful when measruements of Xt are available. However, due

to the measurement error, Xt is not observed so (6) cannot be directly used for estimation of

6

the parameters for model (1). As the surrogate X ∗

t for Xt is available, one may attempt to

employ the naive analysis to model (1) with Xt replaced by X ∗

t . Here we study the impact
of measurement error on the naive analysis disregarding the diﬀerence between Xt and X ∗
t .

We start with the AR(1) model, i.e., model (1) with p = 1.

If we naively replace Xt in (1) by X ∗

t , then the time series model (1) becomes

X ∗

t = φ∗

0 + φ∗

1X ∗

t−1 + (cid:15)∗
t ,

(11)

where (φ∗

0, φ∗

1)T and (cid:15)∗

t show possible diﬀerences from the corresponding quantity in the

model (1). To estimate φ∗

Speciﬁcally, we minimize S(φ∗

0 and φ∗
0, φ∗

1, we may employ the ordinary least squares (OLS) method.
1) = (cid:80)T

t−1)2 with respective to φ∗

t − φ∗

0 − φ∗

0 and

1X ∗

1, yielding the OLS estimators of φ∗
φ∗

t=2(X ∗
1 and φ∗
0:

(cid:80)T

t=2(X ∗
(cid:80)T

(cid:98)φ∗
1 =

0 = ¯X ∗
(cid:98)φ∗

t − (cid:98)φ∗
1

(−1))(X ∗

t − ¯X ∗)

t−1 − ¯X ∗

(−1))2

t−1 − ¯X ∗
t=2(X ∗
¯X ∗,

,

(12)

(cid:80)T

t=2 X ∗

t−1 and ¯X ∗ = 1

T −1

(cid:80)T

t=2 X ∗
t .

and

where ¯X ∗

(−1) = 1

T −1

Theorem 1 Let ω1 =

1σ2
α2
(cid:15)
e (1−φ2
(cid:15) +σ2

1) , φ∗

α2

1σ2

1 = φ1ω1, and φ∗

0 =

(cid:16)

α0 + α1φ0
1−φ1

(cid:17)

(1 − φ1ω1). Assume

the stationarity of the times series. If the measurement error process satisﬁes (7), then

(1) (cid:98)φ∗
1

p

−−→ φ∗

1 and (cid:98)φ∗
0

p

−−→ φ∗

0 as T → ∞,

(2) (cid:15)∗

t = α0(1 − φ∗
and hence Var((cid:15)∗

1) + α1φ0 − φ∗
t ) = φ2

0 + α1(φ1 − φ∗
1)Xt−1 + (1 − φ∗
1(1 − ω1)2 (cid:16) σ2
(cid:17)

+ (1 − ω1φ1)2σ2

1α2

(cid:15)
1−φ2
1

e + α2

1σ2
(cid:15) .

1)et + α1(cid:15)t for t = 1, . . . , T ,

The proof of the theorem is included in Supplementary Appendix A.2. This theorem

essentially implies that the naive estimator under the additive form in (7) is inconsistent

because φ∗

1 (cid:54)= φ1 and φ∗

0 (cid:54)= φ0. The naive estimator (cid:98)φ∗

1 attenuates and the attenuation factor

ω1 depends on the parameters α1 and σ2

e of the measurement error model (7) as well as φ1

and σ2

(cid:15) in the time series model (1). The coeﬃcient α1 in the measurement error model

(7) aﬀects the estimation of the both naive estimators (cid:98)φ∗
1 or Var((cid:15)∗).
inﬂuences the estimation of φ∗

0 only, but not φ∗

1 and (cid:98)φ∗

0, while the intercept α0

7

Theorem 2 Let ω2 = {1 + σ2

uφ2
u + (1+φ1)σ2
0
(1−φ1)σ2
(cid:15)

}−1, φ∗

1 = φ1ω2, and φ∗

0 = β0φ0
1−φ1

(1 − ω2φ1). If the

times series is stationary and the measurement error process satisﬁes (9), then

(1) (cid:98)φ∗
1

p

−−→ φ∗

1 and (cid:98)φ∗
0

p

−−→ φ∗

0 as T → ∞,

(2) (cid:15)∗

t = β0φ0ut − φ∗
and hence Var((cid:15)∗

0 + β0Xt−1(φ1ut − ω2φ1ut−1) + β0ut(cid:15)t for t = 1, . . . , T ,
t ) = β2

0 + (1 + σ2

(cid:15) } + β2

0{σ2

u)σ2

uφ2

0φ2
1

(1+ω2
2)
ω2

σ2
1) .
(cid:15)
(1−φ2

The proof of the theorem is included in Supplementary Appendix A.3. This theorem

says the attenuation eﬀect resulting from the measurement error on estimation of φ1. The

constant scaling parameter β0 in the measurement error model (9) does not inﬂuence the

estimation of φ1 but aﬀects the estimation of φ0 and σ2

(cid:15) . The attenuation factor ω2 is

determined by the magnitude σ2

u of measurement error as well as the values of φ0, φ1, and

σ2
(cid:15) of the time series model (1).

3.3 Naive Estimation and Bias for AR(p) Model with p ≥ 2

We now extend the discussion in Section 3.2 to the AR(p) model with p ≥ 2. Replacing Xt

with X ∗
t

in (1) gives the working model

X ∗

t = φ∗

0 +

p
(cid:88)

j=1

φ∗
j X ∗

t−j + (cid:15)∗
t ,

(13)

where φ∗ = (φ∗

p)T and (cid:15)∗
icking the procedure of using (6) with Xt replaced by X ∗

1, . . . , φ∗

t may diﬀer from the corresponding symbol in (1). If mim-

then we let (cid:98)φ∗ = ((cid:98)φ∗
(cid:98)µ, we deﬁne (cid:98)µ∗ = 1
(cid:98)γ∗ = ((cid:98)γ∗

1, . . . , (cid:98)γ∗

1, . . . , (cid:98)φ∗
(cid:80)T
t=1 X ∗
0 = 1
T

p)T, (cid:98)φ∗
t and (cid:98)γ∗
(cid:80)T

p)T and (cid:98)γ∗

T

0 and (cid:98)σ∗2
k = 1
T −k

t=1(X ∗

t − (cid:98)µ∗)(X ∗

t − (cid:98)µ∗).

t to estimate φ∗, φ∗
(cid:15) denote the resultant estimators. Similar to (cid:98)γk and
t+k − (cid:98)µ∗) for k = 1, . . . , p. Let

t − (cid:98)µ∗)(X ∗

0 and σ2∗
(cid:15)

t=1 (X ∗

in (13),

(cid:80)T −k

We now discuss the asymptotic results of the naive estimators under diﬀerent measure-

ment error models.

Theorem 3 Let 1p be the p×1 unit and let Ip be the p×p identity matrix. Deﬁne γ∗ = α2

1γ,

0 = α2
γ∗
e − α4
σ2

1γ0 + σ2
1γ T (α2

e , φ∗ = α2

1(α2

1Γ + σ2

1γ0 +
e Ip)−1 γ. Under regularity conditions, if the time series is stationary and

0 = (1 − φ∗ · 1p) (α0 + α1µ) and σ2∗

e Ip)−1γ, φ∗

(cid:15) = α2

1Γ + σ2

the measurement error process satisﬁes (7), then

8

(1) (cid:98)γ∗

p

−−→ γ∗ and (cid:98)γ∗

0

p

−−→ γ∗
0

as T → ∞.

(2) (cid:98)φ∗

p
−−→ φ∗, (cid:98)φ∗
0

p

−−→ φ∗

0, and (cid:98)σ2∗

(cid:15)

p

−−→ σ2∗
(cid:15)

as T → ∞.

(3) Let Q1 denote the (p+1)×(p+1) asymptotic covariance matrix of

as T → ∞. Then the elements of Q1 are given by

100 = α4
q∗

1q00 + 4α2

1γ0σ2

e + E(e4

t ) − σ4
e ;

10p = α4
q∗

1q0p + 4α2

1γpσ2
e ;

√
T (cid:8)((cid:98)γ∗

0, (cid:98)γ∗T)T − (γ∗

0, γ∗T)T(cid:9)

1pr = α4
q∗

1qpr + 2α2

1σ2

e (γ|p−r| + γp+r) for r (cid:54)= 0, r (cid:54)= p;

1pp = α4
q∗

1qpp + 2α2

1σ2

e (γ0 + γ2p) + σ4
e ;

for p ≥ 1, where qjk is the (j, k) element of the asymptotic covariance matrix of
((cid:98)γ0, (cid:98)γT)T, given by (Brockwell et al. 1991, Sec. 7.3)

qjk = (η − 3)γjγk +

∞
(cid:88)

(γiγi−j+k + γi+kγi−j)

(14)

i=−∞

for (j, k) = (0, 0), (0, p), (p, p) and (p, r) with r (cid:54)= 0 and r (cid:54)= p, with η = E((cid:15)4

t )/σ4
(cid:15) .

The proof of Theorem 3 is presented in Supplementary Appendix A.4. Similar to the

results in Theorem 1, the intercept α0 only inﬂuence φ0 and does not inﬂuence φ.

u(γ0 + µ2)Ip}−1 γ,
0γ, γ∗
Theorem 4 Let γ∗ = β2
u(γ0 + µ2)Ip}−1 γ.
0 = β0 (1 − φ∗T · 1p) µ, and σ2∗
φ∗
Under regularity conditions, if the time series are stationary and the measurement error

uµ2}, φ∗ = {Γ + σ2
u + 1)γ0 + σ2
uµ2 − β2
0σ2
u + 1)γ0 + β2
0γ T {Γ + σ2

0 = β2
(cid:15) = β2

0 {(σ2
0(σ2

process satisfy (9), then

(1) (cid:98)γ∗

p

−−→ γ∗ and (cid:98)γ∗

0

p

−−→ γ∗
0

as T → ∞.

(2) (cid:98)φ∗

p
−−→ φ∗, (cid:98)φ∗
0

p

−−→ φ∗

0, and (cid:98)σ2∗

(cid:15)

p

−−→ σ2∗
(cid:15)

as T → ∞.

(3) Let Q2 denote the (p+1)×(p+1) asymptotic covariance matrix of

9

√
T (cid:8)((cid:98)γ∗

0, (cid:98)γ∗T)T − (γ∗

0, γ∗T)T(cid:9)

as T → ∞. Then the elements of Q2 are given by

200 = β4
q∗

0 (σ2

u + 1)2q00 + β4

0 {E(u4

t ) − (σ2

u + 1)2}E(Xt − µ)4

+ 4µβ4

0 σ2

u + 1)v0 + 4µβ4

0 {E(u4

t ) − σ2

u(σ2

u + 1)}E(Xt − µ)3

u(σ2
(cid:8)E(u4
(cid:34)
σ4
u

+ 2µ2β4
0

+ 4µ2β4
0

t ) − 2E(u3
∞
(cid:88)

t ) − E(u3
(cid:9) γ0

t ) + 1 − σ4
u

γh + (cid:8)E(u4

t ) − 2E(u3

t ) + σ2

u + 1 − σ4
u

(cid:35)

(cid:9) γ0

+ µ4β4
0

(cid:2)E{(ut − 1)4} − σ4

u

(cid:3) ;

h=−∞

20p = β4
q∗

0 qp(σ2

u + 1) + β4
0

(cid:8)E(u3

t ) − (σ2

u + 1)(cid:9) (cid:2)E{(Xt − µ)3(Xt+p − µ)} + E{(Xt − µ)3(Xt−p − µ)}(cid:3)

+ 2µβ4

0 σ2

uv0p + µβ4

0 E{3u3

t − 3u2

t − 2σ2

u} (cid:2)E{(Xt − µ)2(Xt−p − µ)} + E{(Xt − µ)2(Xt+p − µ)}(cid:3)

+ 6µ2β4

0 E(ut − 1)3γp + 4µ2β4

0 σ2

uγp;

2pr = β4
q∗

0 σ2
u

(cid:2)E{(Xt − µ)2(Xt+p − µ)(Xt+r − µ)} + E{(Xt − µ)(Xt+p − µ)2(Xt+p+r − µ)}

0 qpr + β4
+E{(Xt−r − µ)(Xt − µ)2(Xt+p − µ)} + E{(Xt − µ)(Xt+p−r − µ)(Xt+p − µ)2}(cid:3)

+ µβ4

0 σ2

u [E{(Xt − µ)(Xt+p − µ)(Xt+r − µ)} + E{(Xt − µ)(Xt+p − µ)(Xt+p+r − µ)}

+E{(Xt−r − µ)(Xt − µ)(Xt+p − µ)} + E{(Xt − µ)(Xt+p−r − µ)(Xt+p − µ)}]

+ 2µ2β4

0 σ2

u(γ|p−r| + γp+r) for r (cid:54)= p, r (cid:54)= 0;

2pp = β4
q∗

0 qpp + β4

u + 2σ2

u)Var{(Xt − µ)(Xt+p − µ)} + 2β4

0 (σ4
(cid:2)E{(Xt − µ)(Xt+p − µ)2} + 2E{(Xt − µ)(Xt+p − µ)(Xt+2p − µ)}

0 E{(Xt − µ)(Xt+p − µ)2(Xt+2p − µ)}

0 σ2
u

+ µβ4
+ E{(Xt − µ)2(Xt+p − µ)}(cid:3) + 2µ2β4

0 σ4

uγp + 2µ2β4

0 σ2

u(γ0 + γ2p) + µ4β4

0 σ4
u;

where the qjk are given by (14), for (j, k) = (0, 0), (0, p), (p, p) and (p, r) with r (cid:54)= 0

and r (cid:54)= p, and vp = limT →∞

(cid:80)T

t=1

1
T

(cid:80)T

s=1 E{(Xt − µ)(Xt+p − µ)(Xs − µ)}.

The proof of the theorem is presented in Supplementary Appendix A.5. The multiplica-

tive measurement error ut contributes to the biasedness of the parameter estimation for φ,

while the scaling parameter β0 has no eﬀects on the naive estimator (cid:98)φ∗.

4 Methodology of Correcting Measurement Error Ef-

fects

4.1 Estimation of Model Parameters

In the presence of measurement error, measurements of the Xt are not always available but

surrogate measurements X ∗

t are available. It may be tempting to conduct a naive analysis

10

by implementing (6) with the Xt replaced by the X ∗
by (cid:98)µ∗ and the (cid:98)γ∗
4, such a procedure typically yields biased estimators.

k, respectively, to ﬁnd estimators of φ, φ0 and σ2

t , or equivalently with (cid:98)µ and (cid:98)γk replaced
(cid:15) . However, by Theorems 3–

In this section, we develop new

estimators accounting for the measurement error eﬀects described by either the additive

model (7) or the multiplicative model (9).

Our idea is still to employ (6) to ﬁnd consistent estimators of φ, φ0 and σ2

(cid:15) , but instead
of replacing (cid:98)µ and the (cid:98)γk with (cid:98)µ∗ and the (cid:98)γ∗
k as in the naive analysis, we replace (cid:98)µ and
the (cid:98)γk in (6) with new functions of the X ∗
t , denoted as (cid:101)µ and the (cid:101)γk, which adjust for the
measurement error eﬀects. Speciﬁcally, if we can ﬁnd (cid:101)µ and the (cid:101)γk such that they resemble
(cid:98)µ and the (cid:98)γk in the sense that as T → ∞,

and

(cid:101)µ and (cid:98)µ have the same limit in probability,
(cid:101)γk and (cid:98)γk have the same limit in probability for k = 0, . . . , p,

(15)

then substituting (cid:98)µ and the (cid:98)γk with (cid:101)µ and the (cid:101)γk in (6) yields consistent estimators of φ, φ0
and σ2
(cid:15) .

With the availability of the (cid:101)γk satisfying (15), let (cid:101)Γ denote Γ with the γk replaced by
(cid:15) can be

the (cid:101)γk. Then provided regularity conditions, consistent estimators of φ, φ0 and σ2
obtained by solving the estimating equations for φ, φ0, and σ2
(cid:15) :

φ = (cid:101)Γ−1
(cid:32)

(cid:101)γ,

φ0 =

1 −

(cid:33)

φi

(cid:101)µ,

p
(cid:88)

i=1

σ2
(cid:15) = (cid:101)γ0 − 2φT

(cid:101)γ + φT(cid:101)Γφ.

(16)

It is immediate to obtain the following result.

Theorem 5 Assume regularity conditions hold and the time series are stationary. If (cid:101)µ and
the (cid:101)γk are functions of the X ∗
t with t = 1, . . . , T and they satisfy (15), and let (cid:101)φ, (cid:101)φ0, and
(cid:101)σ(cid:15)
T → ∞

(cid:15) , respectively, obtained by solving (16). Then, as

2 denote the estimators for φ, φ0 and σ2

(1) (cid:101)φ

p
−→ φ, (cid:101)φ0

p

−→ φ0, and (cid:101)σ(cid:15)

2

p
−→ σ2
(cid:15) ;

11

√

(2)

n((cid:101)φ − φ)

d−−→ N (0, GQGT),

0, (cid:98)γ∗T)T.
where G is the matrix of derivatives of (cid:101)φ with respect to the components of ((cid:98)γ∗
Here Q = Q1, the matrix in Theorem 3, if measurement error follows the model (7);

and Q = Q2, the matrix in Theorem 4, if measurement error follows the model (9).

Now we discuss explicitly how to determine (cid:101)µ and the (cid:101)γk under the measurement error
− α0, (cid:101)γ0 = 1
for k = 1, . . . , p.
α1
u+1, and (cid:101)γk = (cid:98)γ∗
uµ2
− σ2
σ2

model (7) or (9). With (7), take (cid:101)µ = (cid:98)µ∗
With (9), take (cid:101)µ = (cid:98)µ∗
in Theorem 3(1) and Theorem 4(1), it can be easily veriﬁed that these (cid:101)µ and the (cid:101)γk satisfy
(15).

e ), and (cid:101)γk = (cid:98)γ∗
for k = 1, . . . , p. By the results

γ∗
0
u)β2
(1+σ2
0

, (cid:101)γ0 =

0 − σ2

((cid:98)γ∗

k
α2
1

k
β2
0

α2
1

β0

We conclude this section with a procedure of estimating the asymptotic covariance ma-

trix for the estimator (cid:101)φ. While Theorem 5 presents the sandwich form of the asymptotic

covariance matrix of (cid:101)φ, its evaluation involves lengthy calculations. We may alternatively

employ the block bootstrap algorithm (Lahiri 1999) to obtain variance estimates for (cid:101)φ using

the following steps. Firstly, we set a positive integer, say N , as the number for the boot-

strap sampling; N can be set as a large number such as 1000. Next, we repeat through the

following ﬁve steps:

Step 1: At iteration n ∈ {1, . . . , N }, we initialize a null time series X (n,0) of dimension 0

and specify a block length, say b, which is an integer between 0 and T . Initialize

m=1.

Step 2: Sample an index, say i, from {0, . . . , T − b}, and then deﬁne X (m−1)

add

=

{Xi+1, . . . , Xi+b}.

Step 3: Update the previous time series X (n,m−1) by appending X (m−1)

add

to it, and let

X (n,m) denote the new time series.

Step 4: If the dimension X (n,m) is smaller than T then return to Steps 2 and 3; oth-

erwise drop the elements in the time series with the index greater than T to

ensure the dimension of X (n,m) is identical to T and then go to Step 5.

12

Step 5: Obtain an estimate (cid:101)φ(n) of parameter φ by applying the times series X (n,m)

to (16). If n < N , then set n to be n + 1 and go back to Step 1 to repeat;

otherwise stop.

Let

¯
(cid:101)φ(n) = 1
N

(cid:80)N

n=1

¯
(cid:101)φ(n) be the sample mean. The bootstrap variance of (cid:101)φ is then given

by,

Varboot((cid:101)φ) =

1
N

N
(cid:88)

n=1

((cid:101)φ(n) −

¯
(cid:101)φ(n))2.

4.2 Forecasting and Prediction Error

Forecasting is an important application of the autoregressive models. Speciﬁcally, in forecast-

ing based on the observed time series X(T ) = {x1, . . . , xT }, we are interested in the predictions

of {XT +1, . . . , XT +H} for a positive integer H, which is done one by one starting from the

nearest time point T + 1 to the farthest time point T + H. To this end, let h = 1, . . . , H,

the h-step forecasting of XT +h is based on its history of lag-p, {XT +h−1, . . . , XT +h−p}, by

using the conditional expectation E(XT +h|xT +h−1, . . . , xT +h−p), denoted (cid:98)XT +h, where for

j = T + h − 1, . . . , T + h − p, xj is the observe value of Xj if j ≤ T ; and xj is the pre-

dicted value of Xj, (cid:98)Xj, if j > T . This prediction minimizes the squared prediction error
E( (cid:98)XT +h − XT +h)2 (e.g., Box et al. 2015, p.131).

If no measurement error is involved, due to the zero mean of the random error term (cid:15)t in

the AR(p) model (1), for h = 1, . . . , H, the conditional expectation can be calculated by

(cid:98)XT +h = φ0 + φ1xT +h−1 + . . . + φpxT +h−p.

(17)

When measurement error appears, the observe values xj for j = T, . . . , T − p + 1 in (17)

are no longer available but their surrogates X ∗

j are available. We now provide a sensible

estimate of Xj by using the measurement error model for characterizing the relationship of

Xj and X ∗

j . If measurement error follows (7), we “estimate” Xj by

(cid:98)Xj =

1
α1

(X ∗

j − α0)

for j = t, . . . , t − p + 1;

if the measurement error follows (9), then (cid:98)Xj is “estimated” by

(cid:98)Xj =

X ∗
j
β0

for j = t, . . . , t − p + 1.

13

(18)

(19)

These “estimates” are unbiased in the sense that E( (cid:98)Xj) = Xj for j = t, . . . , t − p + 1.

Consequently, for h = 1, . . . , H, XT +h is predicted as

(cid:98)XT +h = φ0 + φ1 (cid:98)XT +h−1 + · · · + φp (cid:98)XT +h−p.

(20)

In contrast to the observed values {xT , . . . , xT −p+1}, also referred to as the initial values

of the forecasting of XT +1, . . . , XT +H, the estimates determined by (18) or (19) introduce

additional prediction error which should be characterized. Without the loss of generality, we

consider p = 1 to illustrate the recursive calculation of the prediction error; the prediction

error with higher orders of the autoregressive process can be derived recursively in a similar

way but with more complex expressions.

If the measurement error follows (7), the mean squared prediction error of the 1-step

prediction is given by

P(1)

e = E( (cid:98)XT +1 − XT +1)2

= E{(φ0 + φ1 (cid:98)XT ) − (φ0 + φ1XT + (cid:15)T +1)}2
(cid:19)

(cid:27)2

(cid:26)

(cid:18)

− φ1XT − (cid:15)T +1

eT
α1

= E

φ1

Xt +

=

1σ2
φ2
e
α2
1

+ σ2
(cid:15) ,

where the last step is due to the independence between et and (cid:15)t+1, as well as E(e2

t ) = σ2
e

and E((cid:15)2

t ) = σ2
(cid:15) .

Then, the h-step prediction error is given by

P(h)

e = E( (cid:98)XT +h − XT +h)2
(cid:16)

(cid:110)

= E

φ1

(cid:98)XT +h−1 − XT +h−1

(cid:17)

− (cid:15)T +1

(cid:111)2

= φ2

1P(h−1)
e

+ σ2
(cid:15)

=

φ2h
1 σ2
e
α2
1

+

h−1
(cid:88)

i=0

1 σ2
φ2i
(cid:15) ,

(21)

where the last step comes from the recursive evaluation of P (h−1)

e

.

Similarly, if the measurement error follows (9), the mean squared prediction error is given

14

by

P(1)

e = E( (cid:98)XT +1 − XT +1)2
(cid:27)
(cid:26) σ2
(cid:15)
1 − φ2
1

= φ2
1

+ µ2

u + σ2
σ2
(cid:15) ,

where we use the independence of (cid:15)t+1, ut and Xt, E(ut) = 1, and Var(Xt) = σ2
(cid:15)
1−φ2
1

due to

the stationary AR(1) process. Hence,

P(h)

e = E( (cid:98)XT +h − XT +h)2
(cid:16)

(cid:110)

= E

φ1

(cid:98)XT +h−1 − XT +h−1

(cid:17)

− (cid:15)T +1

(cid:111)2

= φ2

1P(h−1)
e

+ σ2
(cid:15)

= φ2h−2
1

P(1)

e +

h−2
(cid:88)

i=0

1 σ2
φ2i
(cid:15)

= φ2h
1

(cid:26) σ2
(cid:15)
1 − φ2
1

(cid:27)

+ µ2

σ2
u +

h−1
(cid:88)

i=0

1 σ2
φ2i
(cid:15) .

(22)

The evaluation of the mean squared prediction error P(h)

e

is carried out by replacing the

parameters with their estimators. We comment that the common second term in (21) and
(22), (cid:80)h−1
settings (e.g. Box et al. 2015, p.152), which equals 1−φ2h
1
1−φ2
1

(cid:15) , is the mean squared prediction error for the AR(1) model for error-free

i=0 φ2i

1 σ2

σ2
(cid:15) .

For an α with 0 < α < 1, then h-step (1 − α)-prediction interval is constructed as

(cid:104)
(cid:98)XT +h − q α

2

P(h)
e

, (cid:98)XT +h + q α

2

P(h)
e

(cid:105)

,

where q α
2

the α-level quantile of the distribution of (cid:98)XT +h − XT +h. In practice, under normal

assumption of (cid:15)t and et, one can take q α

2

to be the α-level quantile of the standard normal

distribution (Brockwell and Davis 2002, p.108).

5 Analysis of COVID-19 Death Rates

5.1 Study Objective

Using Canadian provincial COVID-19 data containing the daily conﬁrmed cases and deaths

from April 3, 2020 to May 4, 2020, we compare the times series of death rates for British

15

Columbia, Ontario, Quebec, and Alberta, the four provinces in Canada which experience se-

vere situations. The daily conﬁrmed cases and fatalities are taken from “1Point3Acres.com”

(https://coronavirus.1point3acres.com/).

In epidemiology, the mortality rate, deﬁned as the proportion of cumulative deaths of

the disease in the total number of people diagnosed with the disease (Kanchan et al. 2015),

is often used to measure the severeness of an infectious disease. For COVID-19, determining

the mortality rate is not trivial due to the diﬃculty in precisely determining the number of

infected cases. Due to the limited test capacity, individuals with light symptoms are not

being tested. Asymptomatic infections and the incubation period make it diﬃcult to acquire

an accurate number of infections. To circumvent this, we explore diﬀerent deﬁnitions of

death rates. Deﬁnition 1 is from Baud et al. (2020) who estimated mortality rates by

dividing the number of deaths on a given day by the number of patients with conﬁrmed

COVID-19 infection 14 days before, with the consideration of the maximum incubation time

to be 14 days. On the other hand, the median time from symptom onset to intensive care

unit admission is about 10 days ([3] in Baud et al. 2020), so we consider Deﬁnition 2 which

is the number of deaths of COVID-19 on day t divided by the number of conﬁrmed cases at

day (t − 10). In comparison, we also consider Deﬁnition 3 by calculating the death rate on

day t as the ratio of the number of deaths on day t to the number of conﬁrmed cases on day

t.

While the ﬁrst two ways may help more reasonably estimate mortality rates than the third

deﬁnition, these calculated rates still diﬀer from the true mortality rates because of under-

reported cases which are primarily due to limited test capacity and undetected asymptomatic

infections. To reﬂect the discrepancy between the reported and the true mortality rates for

each province, for each deﬁnition of the mortality rate, we let X1,t, X2,t, X3,t, and X4,t,

represent the true mortality rate on day t for British Columbia, Ontario, Quebec and Alberta,

respectively; and let X ∗

1,t, X ∗

2,t, X ∗

3,t and X ∗

4,t denote the reported mortality rate on day t in

British Columbia, Ontario, Quebec and Alberta, respectively. The objective is to use the

reported mortality rates {X ∗

it : t = 1, . . . , 31} to infer the true mortality rates Xi,t which

are modeled by (1) separately for i = 1, . . . , 4. In addition, we want to forecast the true

mortality rate of COVID-19 for a future time period. Due to the undetected asymptomatic

16

cases and untested cases for light symptoms, the reported mortality rates X ∗

i,t are typically

overestimated (i.e., X ∗

i,t ≥ Xi,t) for i = 1, . . . , 4. As there is no exact information to guide

us how to characterize the relationship between X ∗

it and Xit, here we conduct sensitivity
studies by considering measurement error model (7) or (9). We use the observed data X ∗
i,t

from April 3, 2020 to May 4, 2020, i.e., {X ∗

i,t : t = 1, ..., Ti} with T1 = T2 = 31, to estimate

the model parameters in (1) with measurement error eﬀects accounted for, and then forecast

the mortality rate of COVID-19, from May 5, 2020 to May 9, 2020, in British Columbia,

Ontario, Quebec and Alberta, Canada.

5.2 Models Building

Figure 1 displays the trajectory of the mortality rates of COVID-19 in the four provinces

that are obtained from the three deﬁnitions. To assess the stationarity of the X ∗

it, we conduct

the augmented DickeyFuller (ADF) tests (Cheung and Lai 1995) to times series {X ∗

i,t : t =

1, . . . , T }, or its diﬀerencing transformation {X ∗

i,(t+1) − X ∗

i,t : t = 1, . . . , T } for i = 1, . . . , 4 in

each deﬁnition. Supplementary Table 4 presents the test statistics and p-value of the ADF

test for each time series, where “TSV” represents a test statistics value.

[ Place Figure 1 About Here ]

To determine the lag value p for the autoregression model (1) used for the time series

{Xi,t : t = 1, ..., Ti} with T1 = T2 = 31 for i = 1, . . . , 4, we ﬁt the naive model (13) with (cid:15)∗
t

assumed to follow a normal distribution N (0, σ∗2

(cid:15) ), and use the AIC criterion by minimizing

− 2

T
(cid:88)

t=p

logf (x∗

t |x∗

t−1, . . . , x∗

t−p) + 2p,

(23)

where f (x∗

t |x∗

t−1, . . . , x∗

t−p) is the conditional probability of X ∗

t given X ∗

t−1, . . . , X ∗

t−p. The

results are summarized in Supplementary Table 5, where no-diﬀerencing or 1-diﬀerencing is

applied, the entries with “-” indicate that the corresponding model is not applicable due to

the ADF test results.

We take those lag values for an AR(p) model to feature the true mortality rate Xi,t for each

deﬁnition and i = 1, . . . , 4. To be speciﬁc, for the British Columbia data, with Deﬁnition 1

17

we consider two models: AR(1) model for the time series with 1-order diﬀerencing and

AR(2) model for the time series with no-diﬀerencing; with Deﬁnitions 2 and 3, we consider

AR(2) and AR(1) models, respectively, for the time series with 1-order diﬀerencing. For the

Ontario data, we consider AR(1) and AR(4) for the time series with 1-order diﬀerencing in

Deﬁnitions 1 and 3, respectively, and AR(2) for Deﬁnition 2 with no transformation. For

the Quebec data, we consider AR(1) and AR(2) models for the times series with 1-order

diﬀerencing in Deﬁnitions 1 and 2, respectively. For Alberta data, we consider an AR(1)

model for the times series with 1-order diﬀerencing for both Deﬁnitions 1 and 2.

5.3 Sensitivity Analyses

As there are no additional data available for estimating the parameters for the model (7)

or (9), we conduct sensitivity analyses using the ﬁndings in the literature. Diﬀerent studies

showed diﬀerent estimates of the asymptomatic infection rates, changing from 17.9% to

78.3% (Kimball 2020; Day 2020). To accommodate the heterogeneity of diﬀerent studies,

He et al. (2020) carried out a meta-analysis and obtained an estimate of the asymptomatic

infection rate to be 46%. If under-reported conﬁrmed cases are only caused from undetected

asymptomatic cases, then Xt = (1 − τA)X ∗

t , or equivalently,

X ∗

t =

1
1 − τA

Xt,

(24)

where τA represents the rate of asymptomatic infections.

Now we use (24) as a starting point to conduct sensitivity analyses. In the multiplicative

model (9), we take β0ut = 1

1−τA

. With E(ut) = 1, we set β0 = 1

1−τA

by setting τA = 46%,

the value from the meta-analysis of He et al. (2020). To see diﬀerent degrees of error, we

consider σ2

u to take a small value, say σ2

u1, and a large value, say, σ2

reﬂected by the change of the coeﬃcient of variation, CV = σu

u2, which is alternatively
E(ut) , of the error term ut from

σu1 × 100% to σu2 × 100%.

When using the additive model (7) to characterize the measurement error process, mo-

tivated by (24), we set α0 = 0 and α1 = 1

1−46%, and let σ2

e take a small value, say σ2

e1, and

a large value, say σ2

e2, to feature an increasing degree of measurement error. Due to the

18

constraints for the parameters discussed for (8) and (10), we set the values for σu1, σu2, σe1,

and σe2 case by case for each deﬁnition and for each province, which are recorded in Table 6.

The model ﬁtting results are reported in Tables 1–2 and Supplementary Table 7 for the

three deﬁnitions of mortality rates, where the point estimates (EST), the associated standard

errors (SE), and the p-values for the model parameters are included. Table 1 shows that with

Deﬁnition 1, the estimates of φ0 in the absolute value from the proposed method are smaller

than those of naive method, while the estimates of φ1 produced from the proposed and naive

methods exhibit an opposite direction. As expected, the standard errors for the proposed

method are generally larger than those of the naive method. However, both methods ﬁnd no

evidence to support that φ0 and φ1 are diﬀerent from zero for the data of British Columbia

and Ontario, suggesting that the mortality rates of these two provinces remain statistically

unchanged. At the signiﬁcance level 0.1, the naive method and the proposed method show

diﬀerent evidence for the data of Quebec and Alberta. The naive method suggests a likely

downward trend with p-value 0.071 and 0.061 for testing of φ0 for Quebec and Alberta,

respectively. The proposed method, on the other hand, show that φ0 is insigniﬁcant for

these two provinces.

Table 2 displays the results for Deﬁnition 2. For the British Columbia data, the estimates

of the three parameters φ1, φ2 and φ3 produced from the proposed method are smaller than

those yielded from the naive method, whereas the standard errors output from the proposed

method are larger than those from the naive method. However, at the signiﬁcance level 0.05,

both methods ﬁnd no evidence to show the signiﬁcance of φ0, φ1 and φ2, suggesting that

the mortality rate of British Columbia remain unchanged with time. Similar ﬁndings are

revealed for the Alberta data except that the parameter estimates output from the proposed

method are larger than those produced from the naive method. For the Ontario and Quebec

data, the revealings from the two methods are quite diﬀerent. For Ontario, both methods

show that φ0 is insigniﬁcant and φ1 is signiﬁcant. The evidence of φ2, however, depends on

the nature of measurement error. On the contrary, the ﬁndings for Quebec do not tend to

show a deﬁnite direction, and they vary with the model form or degree of the measurement

error process.

Table 7 shows the results for Deﬁnition 3. For the British Columbia data, the estimates

19

produced by the proposed method are smaller than those yielded from the naive method. The

standard errors output from the proposed methods inﬂate as the degree of measurement error

increases. The naive and proposed methods reveal diﬀerent evidence for the signiﬁcance of φ0

and φ1, and the degree of measurement error aﬀects the ﬁndings too. For the Ontario data,

both methods uncover the same type of evidence for all the parameters at the signiﬁcance

level 0.05, except for the case with the large error under the multiplicative model.

[ Place Tables 1–2 About Here ]

5.4 Forecasting

With the ﬁtted model for each time series in Section 5.3, we forecast the true mortality rate

for the subsequent ﬁve days (May 5 – May 9) using the method described in Section 4.2.

Speciﬁcally, since the true mortality rates are not observable, we “estimate” them using (18)

and (19), respectively, for the measurement error models (7) and (9), and then we forecast

the values of Xi,32, Xi,33, Xi,34, Xi,35, and Xi,36 using (20).

To quantify the forecasting performance, we calculate P(h)

e

for h = 1, . . . , H for each

speciﬁed model of the mortality rates Xi,t, and we report the results, together with the total
(cid:80)H

in Tables 8–10, where H is set as 5. For h = 1, . . . , H, we report the observed

h=1 P(h)

e

prediction error (XT +h − (cid:98)XT +h)2, and the expected prediction error deﬁned in (21) and (22).

Forecasting results based on the three deﬁnitions of mortality rates are reported in Fig-

ures 4–3 for the four provinces, where the prediction results after May 4 are marked in blue

and red for the measurement error models (7) and (9), respectively, together with predic-

tion areas marked in shaded parts, as well as the prediction results obtained from the naive

method by using (20) with naive estimates of φ (marked in dark yellow). In comparison,

we display the reported mortality rate (in black) from Apr 3, 2020 to May 9, 2020 as well

as the adjusted mortality rates obtained from (24) (in green); in addition, we report the

ﬁtted values using (17) in blue points. To compare the forecasting results in the presence

of diﬀerent degrees of measurement error. We report the results derived from a mild de-

gree of measurement error in top subﬁgures and place those obtained from a large degree of

measurement error in bottom subﬁgures.

20

[ Place Figure 2 About Here ]

The results for British Columbia are presented in Figure 2 and Web Figures 4–6. With

Deﬁnition 1, the methods with measurement error eﬀects accommodated suggest that the

mortality rate in the past and its forecasting values are around 4%, whereas the results

obtained from the method without accounting for measurement error eﬀects indicate that

the mortality rates over time are higher than 6%. With Deﬁnition 2, the methods with

or without accounting for measurement error eﬀects reveal that the mortality rates over

time are, respectively, below 3.5% and above 5%. With Deﬁnition 3, the methods with or

without accounting for measurement error eﬀects indicate that the mortality rates over time

are, around 3% and above 4%, respectively.

[ Place Figure 3 About Here ]

The results for Ontario are presented in Figure 3 and Supplementary Figures 7–8. With

Deﬁnition 1, the methods with measurement error eﬀects accommodated suggest that the

mortality rate over time is around 7% over time, while the reported mortality rate over time

is about 12.5%. With Deﬁnition 2, the methods with and without incorporating the feature

of measurement error indicate the mortality rate in the past and its forecasting values are,

respectively, below 6% and around 10%. With Deﬁnition 3, the mortality rate increases over

time substantially. The methods with measurement error eﬀects accommodated suggest that

the mortality rate increases from 2% to above 4% whereas the reported mortality rate shows

that rate increases from below 4% to above 8%.

The results for Quebec are presented in Supplementary Figures 9–10. With Deﬁnition 1

the methods with measurement error eﬀects accommodated show that the mortality rate is

around 6.5% over time, whereas the method without considering measurement error indicates

the mortality rate is over 10%. With Deﬁnition 2, the methods with or without addressing

the measurement error eﬀects show that the mortality rates over time are, respectively, below

6% and above 7.5%.

The results for Alberta are presented in Supplementary Figures 11–12. With Deﬁnition 1

the methods with and without measurement error accommodated suggest that the mortality

21

rates are, respectively, around 2% and 4% over time. With Deﬁnition 2, the methods with

or without addressing the measurement error eﬀects show that the historical mortality rate

and its predictions are, respectively, below 2% and above 2%.

5.5 Model Assessment

The speciﬁcation of lag p for model (1) of the true mortality rates {Xi,t : t = 1, . . . , T } is

based on (23) which is derived from the reported mortality rates {X ∗

i,t : t = 1, . . . , T }, but

not from {Xi,t : t = 1, . . . , T } itself. This discrepancy introduces the possibility of model

misspeciﬁcation when featuring the series Xi,t using (1). To investigate this, we conduct a

sensitivity analysis by considering the AR(p) with a diﬀerent value of p for the Xi,t from

Deﬁnition 1. As Table 5 indicates the feasibility of using AR(1) for all four provinces, here

we further employ the AR(2) model to do forecasting for the period from May 5 to May 9.

In Table 3, we report the observed and expected prediction errors of the forecasting

using AR(2) models in comparison with AR(1) models. Comparing diﬀerent lag orders of

the autoregressive models, we ﬁnd that in terms of the observed prediction error, the selected

AR(1) models have better performance than the AR(2) models for the data of Ontario and

Alberta, and the results for British Columbia and Quebec are fairly similar. It is noticed

that both the observed prediction error and the expected prediction error associated with

the proposed method tend to become small when the degree of measurement error increases

for British Columbia, Ontario, and Quebec.

[ Place Table 3 About Here ]

6 Discussion

In this article, we investigate the impact of measurement error on time series analysis under

autoregressive models and establish analytic results under the additive and multiplicative

measurement error models. We propose an estimating equation method to correct for the

biases induced from the naive analysis which disregards the diﬀerences between the true

measurements and their surrogate measurements. We rigorously establish the theoretical re-

22

sults for the proposed method. As a genuine application, we apply to the proposed method

to analyze the mortality rates of COVID-19 data in four provinces, British Columbia, On-

tario, Quebec, and Alberta, which have the most severe virus outbreaks in Canada. The real

data analysis clearly demonstrates that incorporating measurement error in the analysis can

uncover various diﬀerent results.

Our method has the ﬂexibility or robustness in that distribution assumptions are required

to describe the measurement error process as well as the time series autoregressive process.

While our research is motivated by the faulty nature of COVID-19 data, the proposed method

can be applied to handle other problems related to error-contaminated time series. Our

development here is directed to using autoregressive models to delineate time series data.

The same principles can be applied to other model forms such as moving average models or

autoregressive moving average models which may be used to handle error-prone time series

data, where technical details can be more notationally involved.

When checking the stationarity of time series, we apply the ADF test to the observed

time series X ∗

t , which is mainly driven by the unavailability of the true values of Xt, as well as

the fact that the weakly stationarity of observed time series implies the weakly stationarity

of the true time series if measurement error is featured with (7) or (9). It is interesting to

rigorously develop a formal test similar to the ADF test to handle time series subject to

measurement error.

Acknowledgements

This research is partially supported by the Natural Sciences and Engineering Research Coun-

cil of Canada (NSERC) as well as the Rapid Response Program COVID-19 of the Canadian

Statistical Sciences Institute (CANSSI). Yi is Canada Research Chair in Data Science (Tier

1). Her research was undertaken, in part, thanks to funding from the Canada Research

Chairs Program.

23

References

Baud, D., Qi, X., Nielsen-Saines, K., Musso, D., Pomar, L., and Favre, G. (2020). Real

estimates of mortality following COVID-19 infection. The Lancet Infectious Diseases.

Box, G. E., Jenkins, G. M., Reinsel, G. C., and Ljung, G. M. (2015). Time Series Analysis:

Forecasting and Control. New Jersey, NJ: John Wiley & Sons.

Brockwell, P. J. and Davis, R. A. (2002). Introduction to Time Series and Forecasting. New

York, NY: Springer-Verlag.

Brockwell, P. J., Davis, R. A., and Fienberg, S. E. (1991). Time Series: Theory and Methods.

New York, NY: Springer Science & Business Media.

Cheung, Y.-W. and Lai, K. S. (1995). Lag order and critical values of the augmented dickey-

fuller test. Journal of Business & Economic Statistics, 13(3):277–280.

Day, M. (2020). COVID-19: four ﬁfths of cases are asymptomatic, China ﬁgures indicate.

The BMJ, 369.

Dedecker, J., Samson, A., and Taupin, M.-L. (2014). Estimation in autoregressive model

with measurement error. ESAIM: Probability and Statistics, 18:277–307.

He, W., Yi, G. Y., and Zhu, Y. (2020). Estimation of the basic reproduction number, average

incubation time, asymptomatic infection rate, and case fatality rate for COVID-19: Meta-

analysis and sensitivity analysis. Journal of Medical Virology.

Kanchan, T., Kumar, N., and Unnikrishnan, B. (2015). Mortality: Statistics. In Payne-

James, J. and Byard, R. W., editors, Encyclopedia of Forensic and Legal Medicine: Second

Edition, pages 572–577. Oxford, OX:Elsevier.

Kimball, A. (2020). Asymptomatic and presymptomatic SARS-CoV-2 infections in resi-

dents of a long-term care skilled nursing facilityKing County, Washington, March 2020.

Morbidity and Mortality Weekly Report, 69:377–381.

24

Lahiri, S. N. (1999). Theoretical comparisons of block bootstrap methods. The Annals of

Statistics, 27(1):386–404.

Staudenmayer, J. and Buonaccorsi, J. P. (2005). Measurement error in linear autoregressive

models. Journal of the American Statistical Association, 100(471):841–852.

Tanaka, K. (2002). A uniﬁed approach to the measurement error problem in time series

models. Econometric Theory, 18(2):278–296.

Tripodis, Y. and Buonaccorsi, J. P. (2009). Prediction and forecasting in linear models with

measurement error. Journal of statistical planning and inference, 139(12):4039–4050.

25

s
i

”
g
n
i
c
n
e
r
e
ﬀ
i
d

1
-
r
e
d
r
o
“

h
t
i
w

l
e
d
o
m

)
1
(
R
A
e
h
t

:
s
l
e
d
o
m

r
o
r
r
e

t
n
e
m
e
r
u
s
a
e
m

t
n
e
r
e
ﬀ
i
d

r
e
d
n
u

n
o
i
t
a
m

i
t
s
e

r
e
t
e
m
a
r
a
p

e
h
T

:
1

n
o
i
t
i
n
ﬁ
e
D

:
1

e
l

b
a
T

a
t
r
e
b
l
A
d
n
a

c
e
b
e
u
Q

,
o
i
r
a
t
n
O

,
a
i
b
m
u
l
o
C
h
s
i
t
i
r
B

f
o

a
t
a
d

e
h
t

t
ﬁ

o
t

d
e
s
u

a
t
r
e
b
A

l

c
e
b
e
u
Q

o
i
r
a
t
n
O

a
i
b
m
u
l
o
C
h
s
i
t
i
r
B

e
u
l
a
v
-
p

E
S

T
S
E

e
u
l
a
v
-
p

E
S

T
S
E

e
u
l
a
v
-
p

E
S

T
S
E

e
u
l
a
v
-
p

E
S

T
S
E

r
e
t
e
m
a
r
a
P

e
e
r
g
e
D
r
o
r
r
E

d
o
h
t
e

M

1
6
0
.
0

6
1
0
.
0

1
3
0
.
0
-

1
7
0
.
0

0
8
1
.
0

0
4
3
.
0
-

4
8
3
.
0

3
4
2
.
0

5
1
2
.
0
-

2
7
2
.
0

3
4
0
.
0

0
5
0
.
0
-

1
2
7
.
0

4
4
1
.
0

2
5
0
.
0

3
2
9
.
0

4
2
1
.
0

2
1
0
.
0

3
8
1
.
0

7
5
1
.
0

5
1
2
.
0

3
3
5
.
0

4
1
2
.
0

8
3
1
.
0

8
8
0
.
0

9
0
0
.
0

7
1
0
.
0
-

2
1
1
.
0

1
1
1
.
0

3
8
1
.
0
-

6
0
4
.
0

4
3
1
.
0

3
1
1
.
0
-

3
1
3
.
0

5
2
0
.
0

7
2
0
.
0
-

4
6
7
.
0

5
8
1
.
0

6
5
0
.
0

3
9
9
.
0

6
6
5
.
1

4
1
0
.
0

6
0
4
.
0

0
8
2
.
0

7
3
2
.
0

8
8
7
.
0

2
3
5
.
0

6
4
1
.
0

5
4
8
.
0

3
7
0
.
0

4
1
0
.
0
-

3
8
0
.
0

0
0
1
.
0

1
8
1
.
0
-

5
1
7
.
0

3
6
2
.
0

7
9
0
.
0
-

8
9
2
.
0

5
2
0
.
0

7
2
0
.
0
-

9
0
9
.
0

6
9
5
.
1

3
8
1
.
0

4
3
9
.
0

3
2
3
.
0

7
2
0
.
0

7
1
7
.
0

9
3
9
.
0

5
4
3
.
0

0
6
7
.
0

8
6
4
.
0

6
4
1
.
0

0
8
0
.
0

9
0
0
.
0

7
1
0
.
0
-

8
7
0
.
0

9
9
0
.
0

3
8
1
.
0
-

8
8
4
.
0

2
5
1
.
0

7
0
1
.
0
-

6
8
2
.
0

4
2
0
.
0

7
2
0
.
0
-

0
4
7
.
0

0
8
1
.
0

0
6
0
.
0

3
2
9
.
0

6
6
1
.
0

6
1
0
.
0

0
6
2
.
0

8
3
2
.
0

5
7
2
.
0

5
3
5
.
0

6
3
2
.
0

1
5
1
.
0

9
9
2
.
0

5
1
0
.
0

6
1
0
.
0
-

0
7
1
.
0

7
2
1
.
0

0
8
1
.
0
-

4
6
9
.
0

0
9
6
.
1

8
7
0
.
0
-

8
0
3
.
0

4
2
0
.
0

5
2
0
.
0
-

2
1
8
.
0

0
6
3
.
0

7
8
0
.
0

1
8
9
.
0

7
2
3
.
1

1
3
0
.
0

5
0
9
.
0

5
5
9
.
3

6
7
4
.
0

5
3
5
.
0

0
0
3
.
0

2
9
1
.
0

0
φ

1
φ

0
φ

1
φ

0
φ

1
φ

0
φ

1
φ

0
φ

1
φ

-

l
l
a
m
S

)

1
2e
σ
(

e
g
r
a
L

)

2
2e
σ
(

l
l
a
m
S

)

1
2u
σ
(

e
g
r
a
L

)

2
2u
σ
(

d
o
h
t
e

M
d
e
s
o
p
o
r
P
e
h
T

r
o
r
r
E
e
v
i
t
a
c
i
l

p
i
t
l
u
M
h
t
i
w

d
o
h
t
e

M
d
e
s
o
p
o
r
P
e
h
T

r
o
r
r
E
e
v
i
t
i
d
d
A
h
t
i
w

e
v
i
a
N

26

d
e
s
u

s
i

”
g
n
i
c
n
e
r
e
ﬀ
i
d

o
n
“

h
t
i
w

l
e
d
o
m

)
2
(
R
A
e
h
t

:
s
l
e
d
o
m

r
o
r
r
e

t
n
e
m
e
r
u
s
a
e
m

t
n
e
r
e
ﬀ
i
d

r
e
d
n
u

n
o
i
t
a
m

i
t
s
e

r
e
t
e
m
a
r
a
p

e
h
T

:
2

n
o
i
t
i
n
ﬁ
e
D

:
2

e
l

b
a
T

1
-
r
e
d
r
o
“

h
t
i
w

l
e
d
o
m

)
2
(
R
A
e
h
t

d
n
a

,
a
t
r
e
b
l
A

f
o

a
t
a
d

e
h
t

t
ﬁ

o
t

d
e
s
u

s
i

”
g
n
i
c
n
e
r
e
ﬀ
i
d

1
-
r
e
d
r
o
“

h
t
i
w

l
e
d
o
m

)
1
(
R
A
e
h
t

,
o
i
r
a
t
n
O

f
o

a
t
a
d

e
h
t

t
ﬁ

o
t

.
c
e
b
e
u
Q
d
n
a

a
i
b
m
u
l
o
C
h
s
i
t
i
r
B

f
o

a
t
a
d

e
h
t

t
ﬁ

o
t

d
e
s
u

s
i

”
g
n

i
c
n
e
r
e
ﬀ
d

i

a
t
r
e
b
A

l

c
e
b
e
u
Q

o
i
r
a
t
n
O

a
i
b
m
u
l
o
C
h
s
i
t
i
r
B

e
u
l
a
v
-
p

E
S

T
S
E

e
u
l
a
v
-
p

E
S

T
S
E

e
u
l
a
v
-
p

E
S

T
S
E

e
u
l
a
v
-
p

E
S

T
S
E

r
e
t
e
m
a
r
a
P

e
e
r
g
e
D
r
o
r
r
E

d
o
h
t
e

M

1
6
5
.
0

2
2
0
.
0

3
1
0
.
0
-

1
0
0
.
0

8
5
0
.
0

5
2
2
.
0

8
3
1
.
0

8
8
3
.
1

6
2
1
.
2

7
9
0
.
0

4
3
0
.
0

2
6
0
.
0

7
7
4
.
0

2
7
1
.
0

4
2
1
.
0
-

0
8
3
.
0

6
3
1
.
0

2
2
1
.
0
-

1
0
0
.
0
<

9
0
2
.
0

7
6
1
.
1

6
4
0
.
0

6
8
1
.
0

5
1
4
.
0
-

-

-

-

3
0
0
.
0

2
9
0
.
0

9
0
3
.
0
-

4
1
0
.
0

0
4
1
.
0

0
7
3
.
0
-

5
9
1
.
0

5
8
1
.
0

4
5
2
.
0
-

7
6
5
.
0

2
1
0
.
0

7
0
0
.
0
-

0
0
0
.
0

2
4
0
.
0

4
7
1
.
0

4
4
1
.
0

9
5
7
.
0

6
4
1
.
1

4
1
1
.
0

0
2
0
.
0

4
3
0
.
0

6
8
4
.
0

5
8
1
.
0

1
3
1
.
0
-

1
0
0
.
0

2
3
0
.
0

4
2
1
.
0

1
0
0
.
0
<

6
1
2
.
0

3
7
1
.
1

3
5
0
.
0

1
0
2
.
0

2
3
4
.
0
-

-

-

-

5
3
4
.
0

5
6
1
.
0

0
3
1
.
0
-

4
1
0
.
0

1
4
1
.
0

5
7
3
.
0
-

5
1
2
.
0

5
0
2
.
0

8
6
2
.
0
-

4
5
5
.
0

2
1
0
.
0

7
0
0
.
0
-

2
0
0
.
0

6
9
0
.
0

7
2
3
.
0
-

0
4
1
.
0

7
4
7
.
0

8
3
1
.
1

4
6
1
.
0

4
2
0
.
0

6
3
0
.
0

9
2
5
.
0

7
4
2
.
0

8
5
1
.
0
-

1
0
0
.
0

4
4
0
.
0

2
6
1
.
0

1
0
0
.
0
<

9
3
2
.
0

9
8
1
.
1

5
8
0
.
0

5
6
2
.
0

7
9
4
.
0
-

-

-

-

4
0
0
.
0

1
4
0
.
0

2
3
1
.
0

2
3
0
.
0

2
7
1
.
0

0
9
3
.
0
-

4
8
3
.
0

4
5
3
.
0

0
2
3
.
0
-

4
6
5
.
0

2
1
0
.
0

7
0
0
.
0
-

0
8
4
.
0

9
2
2
.
0

4
6
1
.
0
-

1
4
1
.
0

8
4
7
.
0

9
3
1
.
1

5
1
1
.
0

0
2
0
.
0

4
3
0
.
0

7
8
4
.
0

5
0
2
.
0

4
4
1
.
0
-

9
5
0
.
0

9
9
1
.
0

4
9
3
.
0
-

1
0
0
.
0
<

1
3
2
.
0

8
8
1
.
1

3
5
0
.
0

5
0
2
.
0

9
3
4
.
0
-

6
4
5
.
0

2
1
0
.
0

8
0
0
.
0
-

2
0
0
.
0

6
3
0
.
0

7
2
1
.
0

9
4
1
.
0

7
4
7
.
0

2
1
1
.
1

6
3
2
.
0

2
3
0
.
0

9
3
0
.
0

4
2
5
.
0

7
1
3
.
0

5
0
2
.
0
-

7
6
4
.
0

4
9
1
.
0

3
4
1
.
0
-

0
2
0
.
0

3
0
5
.
0

5
5
2
.
1

1
1
1
.
0

9
3
3
.
0

4
8
5
.
0
-

-

-

-

4
0
0
.
0

1
1
1
.
0

3
5
3
.
0
-

4
8
3
.
0

0
1
5
.
0

1
5
4
.
0
-

5
4
2
.
0

2
2
3
.
0

3
9
3
.
0
-

-

-

-

6
0
0
.
0

2
4
0
.
0

8
2
1
.
0

4
2
0
.
0

2
6
1
.
0

9
8
3
.
0
-

5
0
2
.
0

4
0
2
.
0

3
7
2
.
0
-

0
φ

1
φ

2
φ

0
φ

1
φ

2
φ

0
φ

1
φ

2
φ

0
φ

1
φ

2
φ

0
φ

1
φ

2
φ

-

e
v
i
a
N

)

1
2e
σ
(

l
l
a
m
S

)

2
2e
σ
(

e
g
r
a
L

)

1
2u
σ
(

l
l
a
m
S

)

2
2u
σ
(

e
g
r
a
L

d
o
h
t
e

M
d
e
s
o
p
o
r
P
e
h
T

r
o
r
r
E
e
v
i
t
a
c
i
l

p
i
t
l
u
M
h
t
i
w

d
o
h
t
e

M
d
e
s
o
p
o
r
P
e
h
T

r
o
r
r
E
e
v
i
t
i
d
d
A
h
t
i
w

27

s
l
e
d
o
m
e
v
i
s
s
e
r
g
e
r
o
t
u
a

f
o

r
e
d
r
o

g
a
l

t
n
e
r
e
ﬀ
i
d

r
o
f

r
o
r
r
e

n
o
i
t
c
i
d
e
r
p

d
e
t
c
e
p
x
e

d
n
a

r
o
r
r
e

n
o
i
t
c
i
d
e
r
p

d
e
v
r
e
s
b
o

e
h
T

:
3

e
l
b
a
T

r
o
r
r
E

n
o
i
t
c
i
d
e
r
P

d
e
t
c
e
p
x
E

r
o
r
r
E

n
o
i
t
c
i
d
e
r
P

d
e
v
r
e
s
b
O

)
h
(
E
P
E
1
=
Hh
(cid:80)

5

y
a
D

4

y
a
D

3

y
a
D

2

y
a
D

1

y
a
D

)
h
(
E
P
O
1
=
Hh
(cid:80)

5

y
a
D

4

y
a
D

3

y
a
D

2

y
a
D

1

y
a
D

l
e
d
o
M

)
2u
σ

r
o
(

2e
σ

d
o
h
t
e
M

4
3
8
.
0

3
8
7
.
0

4
8
7
.
0

2
2
2
.
0

4
7
1
.
0

8
2
8
.
0

7
7
7
.
0

8
7
7
.
0

0
2
2
.
0

3
7
1
.
0

7
1
1
.
3
1

3
5
8
.
1
1

3
2
0
.
8

5
6
9
.
2

2
4
6
.
1

1
1
1
.
3
1

1
5
8
.
1
1

2
7
0
.
8

6
8
9
.
2

3
0
1
.
2

7
5
0
.
9

7
0
8
.
7

7
5
0
.
4

5
9
9
.
1

5
2
0
.
1

1
2
9
.
8

6
9
0
.
7

3
4
0
.
2

0
6
7
.
1

9
1
3
.
1

7
2
6
.
0

7
7
5
.
0

7
7
1
.
0

7
5
1
.
0

9
0
1
.
0

1
2
6
.
0

0
7
5
.
0

9
1
4
.
0

5
5
1
.
0

9
0
1
.
0

7
6
1
.
0

7
6
1
.
0

7
6
1
.
0

7
6
1
.
0

4
6
1
.
0

7
5
1
.
0

7
5
1
.
0

7
5
1
.
0

7
5
1
.
0

4
5
1
.
0

7
5
1
.
0

7
5
1
.
0

7
5
1
.
0

7
5
1
.
0

4
5
1
.
0

4
4
0
.
0

4
4
0
.
0

4
4
0
.
0

4
4
0
.
0

4
4
0
.
0

5
3
0
.
0

5
3
0
.
0

5
3
0
.
0

5
3
0
.
0

4
3
0
.
0

7
6
1
.
0

7
6
1
.
0

7
6
1
.
0

5
6
1
.
0

1
6
1
.
0

7
5
1
.
0

7
5
1
.
0

7
5
1
.
0

5
5
1
.
0

1
5
1
.
0

7
5
1
.
0

7
5
1
.
0

7
5
1
.
0

5
5
1
.
0

1
5
1
.
0

4
4
0
.
0

4
4
0
.
0

4
4
0
.
0

4
4
0
.
0

3
4
0
.
0

5
3
0
.
0

5
3
0
.
0

5
3
0
.
0

5
3
0
.
0

4
3
0
.
0

9
4
6
.
2

9
4
6
.
2

9
4
6
.
2

3
4
6
.
2

7
2
5
.
2

9
9
3
.
2

9
9
3
.
2

9
9
3
.
2

1
9
3
.
2

4
6
2
.
2

9
4
6
.
1

9
4
6
.
1

6
4
6
.
1

6
2
6
.
1

3
5
4
.
1

3
0
6
.
0

3
0
6
.
0

3
0
6
.
0

9
9
5
.
0

8
5
5
.
0

8
4
3
.
0

8
4
3
.
0

5
4
3
.
0

1
3
3
.
0

0
7
2
.
0

9
4
6
.
2

9
4
6
.
2

8
4
6
.
2

8
4
6
.
2

7
1
5
.
2

9
9
3
.
2

9
9
3
.
2

8
9
3
.
2

8
9
3
.
2

6
5
2
.
2

9
4
6
.
1

9
4
6
.
1

6
4
6
.
1

8
5
6
.
1

0
7
4
.
1

3
0
6
.
0

3
0
6
.
0

3
0
6
.
0

6
0
6
.
0

1
7
5
.
0

5
7
3
.
0

0
9
3
.
0

5
1
4
.
0

9
6
4
.
0

4
5
4
.
0

1
1
8
.
1

1
1
8
.
1

1
1
8
.
1

1
1
8
.
1

1
1
8
.
1

1
6
5
.
1

1
6
5
.
1

1
6
5
.
1

1
6
5
.
1

1
6
5
.
1

1
1
8
.
0

1
1
8
.
0

1
1
8
.
0

1
1
8
.
0

1
1
8
.
0

9
9
3
.
0

9
9
3
.
0

9
9
3
.
0

9
9
3
.
0

9
9
3
.
0

5
0
2
.
0

5
0
2
.
0

5
0
2
.
0

5
0
2
.
0

5
0
2
.
0

1
1
8
.
1

9
0
8
.
1

9
0
8
.
1

6
4
7
.
1

6
4
7
.
1

1
5
4
.
1

7
4
4
.
1

7
4
4
.
1

5
7
3
.
1

5
7
3
.
1

2
0
4
.
0

7
0
4
.
0

7
0
4
.
0

3
1
4
.
0

3
1
4
.
0

7
5
3
.
0

6
5
3
.
0

6
5
3
.
0

5
4
3
.
0

5
4
3
.
0

7
8
1
.
0

4
3
2
.
0

4
3
2
.
0

2
3
3
.
0

2
3
3
.
0

5
2
1
.
0

5
2
1
.
0

5
2
1
.
0

5
2
1
.
0

5
2
1
.
0

5
1
1
.
0

5
1
1
.
0

5
1
1
.
0

5
1
1
.
0

5
1
1
.
0

5
3
0
.
0

5
3
0
.
0

5
3
0
.
0

5
3
0
.
0

5
3
0
.
0

1
3
0
.
0

1
3
0
.
0

1
3
0
.
0

1
3
0
.
0

1
3
0
.
0

2
2
0
.
0

2
2
0
.
0

2
2
0
.
0

2
2
0
.
0

2
2
0
.
0

5
2
1
.
0

5
2
1
.
0

5
2
1
.
0

2
2
1
.
0

2
2
1
.
0

5
1
1
.
0

5
1
1
.
0

5
1
1
.
0

2
1
1
.
0

2
1
1
.
0

5
8
0
.
0

5
8
0
.
0

5
8
0
.
0

1
8
0
.
0

1
8
0
.
0

1
3
0
.
0

1
3
0
.
0

1
3
0
.
0

1
3
0
.
0

0
3
0
.
0

2
2
0
.
0

2
2
0
.
0

2
2
0
.
0

2
2
0
.
0

2
2
0
.
0

6
2
1
.
0

7
3
0
.
0

7
3
0
.
0

7
3
0
.
0

7
3
0
.
0

2
2
1
.
0

5
3
0
.
0

5
3
0
.
0

5
3
0
.
0

4
3
0
.
0

4
8
8
.
1

3
4
2
.
0

4
3
1
.
0

1
0
2
.
0

3
6
0
.
0

1
8
0
.
2

9
7
3
.
0

8
6
3
.
0

0
7
3
.
0

1
9
4
.
0

9
0
7
.
7

7
8
5
.
2

0
8
5
.
2

6
8
5
.
2

8
7
5
.
2

9
7
0
.
7

9
2
4
.
2

3
0
3
.
1

0
9
3
.
2

7
4
8
.
1

0
6
1
.
0

2
6
2
.
0

2
0
3
.
0

3
6
2
.
0

0
7
2
.
0

1
9
1
.
0

6
9
2
.
0

0
2
3
.
0

1
0
3
.
0

4
3
3
.
0

0
2
0
.
0

3
4
0
.
0

2
3
0
.
0

5
1
0
.
0

5
1
0
.
0

0
0
0
.
0

1
1
0
.
0

1
1
0
.
0

5
0
0
.
0

0
1
0
.
0

d
l
i

M

-

0
0
0
.
0

1
1
0
.
0

1
1
0
.
0

5
0
0
.
0

0
1
0
.
0

a

)
1
(
R
A

e
t
a
r
e
d
o
M

0
0
0
.
0

1
1
0
.
0

1
1
0
.
0

5
0
0
.
0

0
1
0
.
0

0
0
0
.
0

1
1
0
.
0

1
1
0
.
0

5
0
0
.
0

0
1
0
.
0

9
1
0
.
0

2
4
0
.
0

1
3
0
.
0

4
1
0
.
0

6
1
0
.
0

0
0
0
.
0

0
1
0
.
0

0
1
0
.
0

5
0
0
.
0

0
1
0
.
0

e
t
a
r
e
d
o
M

d
l
i

M

d
l
i

M

-

0
0
0
.
0

0
1
0
.
0

0
1
0
.
0

5
0
0
.
0

0
1
0
.
0

)
2
(
R
A

e
t
a
r
e
d
o
M

e
v
i
t
a
c
i
l
p
i
t
l
u
M

e
v
i
t
i
d
d
A

e
v
i
a
N

e
v
i
t
i
d
d
A

e
v
i
a
N

0
0
0
.
0

0
1
0
.
0

0
1
0
.
0

5
0
0
.
0

0
1
0
.
0

0
0
0
.
0

0
1
0
.
0

0
1
0
.
0

5
0
0
.
0

0
1
0
.
0

e
t
a
r
e
d
o
M

d
l
i

M

e
v
i
t
a
c
i
l
p
i
t
l
u
M

a
i
b
m
u
l
o
C
h
s
i
t
i
r
B

9
5
0
.
1

1
2
5
.
0

6
9
1
.
0

7
8
0
.
0

0
2
0
.
0

5
7
1
.
0

6
5
0
.
0

7
0
0
.
0

4
0
0
.
0

1
0
0
.
0

d
l
i

M

-

0
1
1
.
0

3
2
0
.
0

0
0
0
.
0

0
0
0
.
0

0
0
0
.
0

a

)
1
(
R
A

e
t
a
r
e
d
o
M

2
5
1
.
0

4
4
0
.
0

3
0
0
.
0

2
0
0
.
0

0
0
0
.
0

5
3
0
.
0

0
0
0
.
0

4
1
0
.
0

0
1
0
.
0

4
0
0
.
0

1
1
1
.
1

0
5
5
.
0

0
4
2
.
0

7
0
1
.
0

3
7
0
.
0

7
2
2
.
0

3
8
0
.
0

6
2
0
.
0

4
1
0
.
0

9
2
0
.
0

e
t
a
r
e
d
o
M

d
l
i

M

d
l
i

M

-

1
2
2
.
0

3
6
0
.
0

1
3
0
.
0

8
0
0
.
0

5
4
0
.
0

)
2
(
R
A

e
t
a
r
e
d
o
M

e
v
i
t
a
c
i
l
p
i
t
l
u
M

e
v
i
t
i
d
d
A

e
v
i
a
N

e
v
i
t
i
d
d
A

e
v
i
a
N

2
2
2
.
0

6
7
0
.
0

7
2
0
.
0

2
1
0
.
0

4
3
0
.
0

0
1
3
.
0

4
2
0
.
0

1
7
0
.
0

1
0
0
.
0

5
8
0
.
0

e
t
a
r
e
d
o
M

d
l
i

M

e
v
i
t
a
c
i
l
p
i
t
l
u
M

o
i
r
a
t
n
O

4
9
2
.
3

9
8
2
.
2

7
5
3
.
1

7
0
6
.
0

3
6
1
.
0

3
5
0
.
1

8
7
7
.
0

9
7
4
.
0

6
1
2
.
0

1
6
0
.
0

d
l
i

M

-

1
5
0
.
1

6
7
7
.
0

8
7
4
.
0

5
1
2
.
0

0
6
0
.
0

a

)
1
(
R
A

e
t
a
r
e
d
o
M

3
5
0
.
1

8
7
7
.
0

9
7
4
.
0

6
1
2
.
0

1
6
0
.
0

0
5
0
.
1

6
7
7
.
0

7
7
4
.
0

5
1
2
.
0

0
6
0
.
0

5
8
0
.
3

5
1
1
.
2

6
2
2
.
1

4
2
5
.
0

9
2
1
.
0

2
0
0
.
1

4
3
7
.
0

6
4
4
.
0

5
9
1
.
0

2
5
0
.
0

e
t
a
r
e
d
o
M

d
l
i

M

d
l
i

M

-

9
1
5
.
0

6
9
3
.
0

7
4
2
.
0

9
0
1
.
0

2
3
0
.
0

)
2
(
R
A

e
t
a
r
e
d
o
M

e
v
i
t
a
c
i
l
p
i
t
l
u
M

e
v
i
t
i
d
d
A

e
v
i
a
N

e
v
i
t
i
d
d
A

e
v
i
a
N

8
8
9
.
0

3
2
7
.
0

8
3
4
.
0

0
9
1
.
0

1
5
0
.
0

4
7
7
.
0

0
6
5
.
0

3
3
3
.
0

1
4
1
.
0

8
3
0
.
0

e
t
a
r
e
d
o
M

d
l
i

M

e
v
i
t
a
c
i
l
p
i
t
l
u
M

0
7
0
.
0

5
5
0
.
0

7
2
0
.
0

7
0
0
.
0

2
0
0
.
0

5
1
1
.
0

7
8
0
.
0

4
4
0
.
0

2
1
0
.
0

4
0
0
.
0

d
l
i

M

-

9
2
1
.
0

8
9
0
.
0

2
5
0
.
0

7
1
0
.
0

6
0
0
.
0

a

)
1
(
R
A

e
t
a
r
e
d
o
M

5
1
1
.
0

7
8
0
.
0

4
4
0
.
0

2
1
0
.
0

4
0
0
.
0

8
1
1
.
0

9
8
0
.
0

5
4
0
.
0

3
1
0
.
0

5
0
0
.
0

1
8
0
.
0

4
6
0
.
0

3
3
0
.
0

0
1
0
.
0

3
0
0
.
0

7
2
1
.
0

7
9
0
.
0

1
5
0
.
0

6
1
0
.
0

5
0
0
.
0

e
t
a
r
e
d
o
M

d
l
i

M

d
l
i

M

-

6
3
1
.
0

4
0
1
.
0

6
5
0
.
0

8
1
0
.
0

6
0
0
.
0

)
2
(
R
A

e
t
a
r
e
d
o
M

e
v
i
t
a
c
i
l
p
i
t
l
u
M

e
v
i
t
i
d
d
A

e
v
i
a
N

e
v
i
t
i
d
d
A

e
v
i
a
N

a
t
r
e
b
l
A

c
e
b
e
u
Q

9
2
1
.
0

9
9
0
.
0

2
5
0
.
0

6
1
0
.
0

5
0
0
.
0

1
4
1
.
0

9
0
1
.
0

9
5
0
.
0

9
1
0
.
0

6
0
0
.
0

e
t
a
r
e
d
o
M

d
l
i

M

e
v
i
t
a
c
i
l
p
i
t
l
u
M

l
e
d
o
m
d
e
t
c
e
l
e
s

e
h
T

a

28

Figure 1: The time series plots of the death rate with diﬀerent deﬁnitions

29

British ColumbiaOntarioQuebecAlbertaApr 06Apr 13Apr 20Apr 27May 04Apr 06Apr 13Apr 20Apr 27May 04Apr 06Apr 13Apr 20Apr 27May 04Apr 06Apr 13Apr 20Apr 27May 040102030DateFatality Rate (%)Definition ofDeath RateDefinition 1Definition 2Definition 3y
a
M

(

e
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

e
h
t

f
o

g
n
i
t
s
a
c
e
r
o
f

y
a
d
-
5
A

:
)
g
n
i
c
n
e
r
e
ﬀ
i
d

1
-
r
e
d
r
o

,
)
1
(
R
A
(

3

n
o
i
t
i
n
ﬁ
e
D
y
b

a
i
b
m
u
l
o
C
h
s
i
t
i
r
B

:
2

e
r
u
g
i
F

d
e
t
r
o
p
e
r

e
h
t

;
)
w
o
l
l
e
y

k
r
a
d

n
i
(

l
e
d
o
m

e
v
i
a
n

e
h
t

s
u
s
r
e
v

)
d
e
r

n
i
(

e
v
i
t
a
c
i
l
p
i
t
l
u
m

r
o

)
e
u
l
b

n
i
(

e
v
i
t
i
d
d
a

e
h
t

n
o

d
e
s
a
b

)
9

y
a
M

-

5

.
)
n
e
e
r
g

n
i
(

s
e
s
a
c

c
i
t
a
m
o
t
p
m
y
s
a

e
h
t

r
o
f

g
n
i
t
n
u
o
c
c
a

e
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

d
e
t
s
u
j
d
a

e
h
t

d
n
a

)
k
c
a
l
b

n
i
(

s
e
t
a
r

y
t
i
l
a
t
r
o
m

30

AdditiveMultiplicativeMildModerateApr 13Apr 20Apr 27May 04Apr 13Apr 20Apr 27May 0423452345DayFatality Rate (%)Reference Time SeriesAdjusted FatalityFitted FatalityReported FatalityMeasurement Error TypeAdditiveMultiplicativeNaive95% Prediction IntervalAdditiveMultiplicative)
9

y
a
M

-

5

y
a
M

(

e
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

e
h
t

f
o

g
n
i
t
s
a
c
e
r
o
f

y
a
d
-
5
A

:
)
g
n
i
c
n
e
r
e
ﬀ
i
d

1
-
r
e
d
r
o

,
)
4
(
R
A
(

3

n
o
i
t
i
n
ﬁ
e
D
y
b

o
i
r
a
t
n
O

:
3

e
r
u
g
i
F

s
e
t
a
r

y
t
i
l
a
t
r
o
m
d
e
t
r
o
p
e
r

e
h
t

;
)
w
o
l
l
e
y

k
r
a
d

n
i
(

l
e
d
o
m
e
v
i
a
n

e
h
t

s
u
s
r
e
v

)
d
e
r

n
i
(

e
v
i
t
a
c
i
l
p
i
t
l
u
m

r
o

)
e
u
l
b

n
i
(

e
v
i
t
i
d
d
a

e
h
t

n
o

d
e
s
a
b

.
)
n
e
e
r
g

n

i
(

s
e
s
a
c

c
i
t
a
m
o
t
p
m
y
s
a

e
h
t

r
o
f

g
n
i
t
n
u
o
c
c
a

e
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

d
e
t
s
u
j
d
a

e
h
t

d
n
a

)
k
c
a
l
b

n
i
(

31

AdditiveMultiplicativeMildModerateApr 13Apr 20Apr 27May 04Apr 13Apr 20Apr 27May 0424682468DayFatality Rate (%)Reference Time SeriesAdjusted FatalityFitted FatalityReported FatalityMeasurement Error TypeAdditiveMultiplicativeNaive95% Prediction IntervalAdditiveMultiplicativeSupplementary Materials for “Sensitivity
Analysis of Error-Contaminated Time Series
Data under Autoregressive Models with
Application of COVID-19 Data”

A Appendix

A.1 Regularity Conditions

(R1) The time series {Xt : t = 1 . . . , T } is stationary.

(R2) The observed error-prone time series {X ∗

t : t = 1 . . . , T } is stationary.

(R3) For any t ∈ {1, . . . , T }, 1
T

(cid:80)T

s=1 γ|s−t| → 0 as T → ∞.

(R4) For any p, 1
T

(cid:80)T

t=1

(cid:80)T

s=1 E{(Xt − µ)(Xt+p − µ)(Xs − µ)} < ∞.

While the two process {Xt : t = 1, . . . , T } and {X ∗
t

: t = 1, . . . , T } are constrained

by the measurement error model (7) or (9), they can both be assumed to be stationary

without inducing conﬂicting requirements on the associated processes. Obviously, the weak

stationarity of {Xt : t = 1, . . . , T } implies the weak stationarity of {X ∗
t

: t = 1, . . . , T } if

they are linked by (7) or (9). Condition (R3) says that as the time series goes long enough,

the average of the covariances between any paired variables is is negligible. Condition (R4)

requires the summation of the third moment of Xt is O(T ), which is needed in Theorem 4

when φ0 (cid:54)= 0; this condition can be satisﬁed if E((cid:15)3

t ) = 0, for example.

A.2 The proof of Theorem 1

Applying the weak law of large numbers to (cid:98)φ∗
1 converges in probability to Cov(X ∗
(cid:98)φ∗

t−1)

Var(X ∗

t ,X ∗
t−1)

1 given by (12), we obtain that the estimator

, which is denoted as φ∗

1. Now we further examine

φ∗
1 by using the AR(1) model (1) and the measurement error model (7):
t , X ∗
t−1)

Cov(X ∗

Var(X ∗

φ∗
1 =

t−1)

Cov(α0 + α1Xt + et, α0 + α1Xt−1 + et−1)
Var(α0 + α1Xt + et)

=

=

=

α2
α2

α2
1Cov(Xt, Xt−1)
1Var(Xt) + Var(et)
1Cov(φ0 + φ1Xt−1 + (cid:15)t, Xt−1)
1Var(Xt) + Var(et)
1Var(Xt−1)
1Var(Xt) + V ar(et)

α2

α2

α2

,

= φ1 ·

where the second step is due to (7), the third step is because of the independence among the

Xt and the et, and the fourth step is because of (1). Since the time series {Xt} is stationary,
it follows that Var(Xt) = Var(Xt−1) = σ2
(cid:15)
1−φ2
1

, and hence

1σ2
Next, applying the Slutsky’s theorem to (12), we have that as T → ∞,

α2

φ∗
1 = φ1 ·

1σ2
α2
(cid:15)
e (1 − φ2
(cid:15) + σ2
1)

= φ1ω1.

(S.1)

(cid:98)φ∗
0
(cid:17)

(cid:16)

p
−→ E(X ∗

t ) − φ∗

1E(X ∗

t ),

where the limit equals

t ) = α0 + α1φ0
1−φ1
Finally, plugging the AR(1) model (1) into the measurement error model (11), we obtain

(1 − φ1ω1) by (S.1) and the fact that E(X ∗

α0 + α1φ0
1−φ1

.

that

X ∗

t = α0 + α1(φ0 + φ1Xt−1 + (cid:15)t) + et.

(S.2)

On the other hand, plugging the measurement error model (7) into the working model (11),

we obtain that

X ∗

t = φ∗

0 + φ∗

1(α0 + α1Xt−1 + et) + (cid:15)∗
t .

(S.3)

Then equating (S.2) and (S.3) that

(cid:15)∗ = α0(1 − φ∗

1) + α1φ0 − φ∗

0 + α1(φ1 − φ∗

1)Xt−1 + (1 − φ∗

1)et + α1(cid:15)t.

Consequently, by the independence assumption for Xt−1, et and (cid:15)t, we obtain that

V ar((cid:15)∗

t ) = φ2

1α2

1(1 − ω1)2Var(Xt−1) + (1 − ω1φ1)2Var(et) + α2

1Var((cid:15)t)

= φ2

1α2

1(1 − ω1)2

(cid:19)

(cid:18) σ2
(cid:15)
1 − φ2
1

2

+ (1 − ω1φ1)2σ2

e + α2

1σ2
(cid:15) .

A.3 The proof of Theorem 2

As noted in the beginning of A.2, as T → ∞, (cid:98)φ∗
1

p
−→ φ∗

1 where

(cid:98)φ∗
1 =

Cov(X ∗

t−1)

t , X ∗
t−1)

.

Var(X ∗

Now we further examine φ∗

1 by using the AR(1) model (1) and the measurement error

model (9):

φ∗
1 =

=

=

=

Cov(X ∗

t−1)

t , X ∗
t−1)

Var(X ∗

Cov(β0utXt, β0ut−1Xt−1)
Var(β0ut−1Xt−1)
β2
0Cov(utXt, ut−1Xt−1)
β2
0Var(ut−1Xt−1)

Cov{ut(φ0 + φ1Xt−1 + (cid:15)t), ut−1Xt−1}
Var(Xt−1ut−1)
Cov(utXt−1, ut−1Xt−1)
Var(ut−1Xt−1)

E(utut−1X 2
E(u2
E(ut)E(ut−1)E(X 2
E(u2

t−1) − E(utXt−1)E(ut−1Xt−1)
t−1X 2
t−1) − E2(ut−1Xt−1)

t−1) − E(ut)E(ut−1)E2(Xt−1)

t−1)E(X 2

t−1) − E2(ut−1Xt−1)

= φ1

= φ1

= φ1

= φ1

E(ut)E(ut−1)Var(Xt−1)
{Var(ut−1) + E2(ut−1)}{Var(Xt−1) + E2(Xt−1)} − E2(ut−1)E2(Xt−1)

= φ1

= φ1

Var(Xt−1)
{Var(ut−1) + 1}{Var(Xt−1) + E2(Xt−1)} − E2(Xt−1)
Var(Xt−1)
Var(ut−1)Var(Xt−1) + Var(ut−1)E2(Xt−1) + Var(Xt−1)

,

(S.4)

where the second step is due to measurement error model (9), the seventh step is because

ut, ut−1 and Xt−1 are mutually independent, and the second last step is due to E(ut) = 1.
Since the time series {Xt} is stationary, it follows that E(Xt) = E(Xt−1) = φ0
1−φ1

and

3

Var(Xt) = Var(Xt−1) = σ2
(cid:15)
1−φ2
1

. Hence (S.4) becomes

φ∗
1 = φ1

Var(Xt−1)
Var(ut−1)Var(Xt−1) + Var(ut−1)E2(Xt−1) + Var(Xt−1)

σ2
u

σ2
(cid:15)
1−φ2
1

= φ1

= φ1

σ2
(cid:15)
1−φ2
1
(cid:16) φ0
1−φ1

+ σ2
u
σ2
(cid:15)
(cid:15) + σ2

(cid:17)2

+ σ2
(cid:15)
1−φ2
1

(cid:15) σ2
σ2

u + σ2

= φ1ω2.

1+φ1
1−φ1

(S.5)

uφ2
0

Next, applying the Slustky’s Theorem to (12) gives that as T → ∞,

(cid:98)φ∗
0

p
−−→

(cid:19)

(cid:18) β0φ0
1 − φ1

(1 − φ1ω2)

by (S.5) as well as E(X ∗

t ) = β0φ0
1−φ1

.

Finally plugging the AR(1) model (1) into the measurement error model (9), we obtain

that

X ∗

t = β0(φ0 + φ1Xt−1 + (cid:15)t)ut.

(S.6)

On the other hand, plugging the measurement error model (9) into the working model (11),

we obtain that

X ∗

t = φ∗

0 + φ∗

1(β0Xt−1ut−1) + (cid:15)∗
t .

(S.7)

Then equating (S.6) and (S.7) gives that

(cid:15)∗ = β0φ0ut − φ∗

0 + β0Xt−1(φ1ut − ω2φ1ut−1) + β0ut(cid:15)t.

4

yielding that

V ar((cid:15)∗

t ) = φ2

0β2

0Var(ut) + β2

0φ2

1Var(Xt−1ut) + β2

0ω2

2φ2

1Var(Xt−1ut−1) + β2

0V ar(ut(cid:15)t)

= φ2

0β2

0σ2

u + (β2

0φ2

1 + β2

0ω2

2φ2

1){E(X 2

t−1u2

t−1) − E2(Xt)E2(ut−1)} + β2

0{E(u2

t )E((cid:15)2

t ) − E2(ut)E2((cid:15)t)}

= φ2

0β2

0σ2

u + (β2

0φ2

1 + β2

0ω2

2φ2

1){E(X 2

t−1)E(u2

t−1) − E2(Xt)E2(ut−1)} + β2

0(σ2

u + 1)σ2
(cid:15)

= β2

0{σ2

uφ2

0 + (1 + σ2

u)σ2
(cid:15) }

+ β2

0φ2

1(1 + ω2

2) (cid:2){Var(ut−1) + E2(ut−1)}{Var(Xt−1) + E2(Xt−1)} − E2(Xt−1)(cid:3)

= β2

0{σ2

uφ2

0 + (1 + σ2

u)σ2

(cid:15) } + β2

0φ2

1(1 + ω2

= β2

0{σ2

uφ2

0 + (1 + σ2

u)σ2

(cid:15) } + β2

0φ2

1(1 + ω2

2) (cid:2){Var(ut−1) + 1}{Var(Xt−1) + E2(Xt−1)} − E2(Xt−1)(cid:3)
2) (cid:8)Var(ut−1)Var(Xt−1) + Var(ut−1)E2(Xt−1) + Var(Xt−1)(cid:9)

= β2

0{σ2

uφ2

0 + (1 + σ2

u)σ2

(cid:15) } + β2

0φ2

1(1 + ω2
2)

V ar(Xt−1)
ω2

= β2

0{σ2

uφ2

0 + (1 + σ2

u)σ2

(cid:15) } + β2

0φ2
1

1 + ω2
2
ω2

σ2
(cid:15)
1 − φ2
1

,

where the second step is because of the independence assumption as well as E(u2

t−1) = E(u2
t )

and E(ut−1) = E(ut) such that Var(Xt−1ut) = Var(Xt−1ut−1), and the second last step is

due to ω2 =

Var(ut−1)Var(Xt−1)+Var(ut−1)E2(Xt−1)+Var(Xt−1) in (S.5).

Var(Xt−1)

A.4 The proof of Theorem 3

Proof of Theorem 3(1):

For k = 1, . . . , p, applying the weak law of large numbers to (cid:98)γ∗
k converges in probability to Cov(X ∗

t , X ∗

the estimator (cid:98)γ∗

t−k), denoted γ∗
k.

k, we obtain that as T → ∞,

Next, we examine γk. By the form of measurement error model (7), we have that for

0 < k < t,

Cov(X ∗

t , X ∗

t−k) = Cov(α0 + α1Xt + et, α0 + α1Xt−k + et−k)

= α2

1Cov(Xt, Xt−k) = α2

1γk,

and by (8), Var(X ∗

t ) = α2

1γ0 + σ2

e , which is denoted as γ∗
0.

Thus, Theorem 3(1) follows.

5

Proof of Theorem 3(2):

First, by Theorem 3(1), we write

(cid:98)γ∗ = α2

1γ + op(1)

(S.8)

and








where (cid:98)Γ∗ =

(6) with (cid:98)γ∗
k,

0

(cid:98)γ∗
...
(cid:98)γ∗

p−1

(cid:98)Γ∗ = α2

1Γ + σ2

e Ip + op(1),








. Then the naive estimator (cid:98)φ∗ is obtained by replacing (cid:98)γk in

p−1

· · · (cid:98)γ∗
...
. . .
(cid:98)γ∗

· · ·

0

(cid:98)φ∗ = (cid:8)α2

1Γ + σ2

e Ip + op(1)(cid:9)−1 (cid:8)α2

1γ + op(1)(cid:9) = α2

1

(cid:0)α2

1Γ + σ2

e Ip

(cid:1)−1 γ + op(1),

(S.9)

and hence φ∗ = α2

1 (α2
Again, replacing (cid:98)γk in (6) with (cid:98)γ∗

1Γ + σ2

e Ip)−1 γ such that (cid:98)φ∗

p
−→ φ∗ as T → ∞.

k gives the naive estimator (cid:98)φ∗
0
(cid:32) p
(cid:33)

(cid:33) (cid:32)

(cid:98)φ∗
0 =

1
T − p

T
(cid:88)

t=p

X ∗

t −

= E(X ∗

t ) − E(X ∗
t )

(cid:88)

(cid:98)φ∗
k

k=1
p
(cid:88)

(cid:98)φ∗
k + op(1)

1
T − p

T
(cid:88)

t=p

X ∗

t−k

k=1

= α0 + α1E(Xt) − {α0 + α1E(Xt)}

= (1 − φ∗T · 1p) (α0 + α1µ) + op(1),

p
(cid:88)

k=1

{φ∗

k + op(1)} + op(1)

where (cid:98)φk and φk are respectively the kth element of (cid:98)φ and φ, the third step is because

(cid:98)φk = φk + op(1) by (S.9) as well as the model form (7), and the last step is due to the

stationarity of the time series {Xt} such that E(Xt) = µ.

Finally, noting that the native estimator (cid:98)σ2∗
applying a version similar to (6), we obtain that

(cid:15)

is given by (cid:98)σ2∗

(cid:15) = (cid:98)γ∗

0 − 2(cid:98)φ∗T

(cid:98)γ∗ + (cid:98)φ∗T(cid:98)Γ∗ (cid:98)φ∗ by

0 − 2(cid:98)φ∗T

(cid:15) = (cid:98)γ∗
(cid:98)σ2∗
= (α2

1γ2

0 + σ2

(cid:98)γ∗ + (cid:98)φ∗T(cid:98)Γ∗ (cid:98)φ∗
1γ T(α2
e ) − 2α4

1Γ + σ2

e Ip)−1γ + α4

1γ T(α2

1Γ + σ2

e Ip)−1(α2

1Γ + σ2

e Ip)(α2

1Γ + σ2

e Ip)−1γ + op(1)

= α2

1γ0 + σ2

e − α4

1γ T(α2

1Γ + σ2

e Ip)−1γ + op(1),

6

where the second step is due to (8), (S.8) and (S.9).

Proof of Theorem 3(3):

Step 1: We show certain identities before proving Theorem 3(3).

1. By model (7), we have that

X ∗

t − (cid:98)µ∗ = α0 + α1Xt + et −
(cid:32)

T
(cid:88)

t=1

1
T
(cid:33)

(cid:32)

= α1

Xt −

Xt

+

et −

1
T

T
(cid:88)

t=1

(cid:33)

1
T

T
(cid:88)

t=1

et

(α0 + α1Xt + et)

= α1(Xt − (cid:98)µ) + (et − ¯e),

(S.10)

where the ﬁrst step is because (cid:98)µ∗ = 1
2. For any t and s, we have that

T

(cid:80)T

t=1 X ∗

t and in the last step ¯e = 1
T

(cid:80)T

t=1 et.

Cov (cid:8)(Xt − (cid:98)µ)2, (Xs − (cid:98)µ)(es − ¯e)(cid:9)
=E{(Xt − (cid:98)µ)2(Xs − (cid:98)µ)(es − ¯e)} − {E(Xt − (cid:98)µ)2}E{(Xs − (cid:98)µ)(es − ¯e)}
=E{(Xt − (cid:98)µ)2(Xs − (cid:98)µ)}E(es − ¯e) − {E(Xt − (cid:98)µ)2}E(Xs − (cid:98)µ)E(es − ¯e)
=0,

(S.11)

where the second step is due to the independence of et and Xt, and the last step is by

E(es − ¯e) = 0.

3. By the independence of et and es for t (cid:54)= s, we have that

Cov {(Xt − (cid:98)µ)(et − ¯e), (Xs − (cid:98)µ)(es − ¯e)}

=E{(Xt − (cid:98)µ)(et − ¯e)(Xs − (cid:98)µ)(es − ¯e)} − E{(Xt − (cid:98)µ)(et − ¯e)}E{(Xs − (cid:98)µ)(es − ¯e)}
=E{(Xt − (cid:98)µ)(Xs − (cid:98)µ)}E{(et − ¯e)}E{(es − ¯e)} − E{(Xt − (cid:98)µ)}E{(et − ¯e)}E{(Xs − (cid:98)µ)}E{(es − ¯e)}
=0,

(S.12)

where the second step is due to the independence of the et and the Xt, and the last step is

by E(es − ¯e) = 0.

7

4. For any t, we have that

Var {(Xt − (cid:98)µ)(et − ¯e)}
=E{(Xt − (cid:98)µ)2(et − ¯e)2} − E2{(Xt − (cid:98)µ)(et − ¯e)}
=E{(Xt − (cid:98)µ)2}E{(et − ¯e)2} − E2{(Xt − (cid:98)µ)}E2{(et − ¯e)}
=E{(Xt − (cid:98)µ)2}E{(et − ¯e)2}.

(S.13)

5. For any t, we have

lim
T →∞

= lim
T →∞

E{(Xt − (cid:98)µ)2}
E{(Xt − µ)2 + (µ − (cid:98)µ)2 + 2(Xt − µ)(µ − (cid:98)µ)}

=γ0 + lim
T →∞

E{((cid:98)µ − µ)2} + 2 lim

T →∞

E{(Xt − µ)(µ − (cid:98)µ)}

=γ0 + lim
T →∞

E{((cid:98)µ − µ)2} − 2 lim

T →∞

E

(Xt − µ){

(cid:34)

(cid:35)

(Xs − µ)}

1
T

T
(cid:88)

s=1

1
T

T
(cid:88)

s=1

E{(Xt − µ)(Xs − µ)}

=γ0 + lim
T →∞

V ar((cid:98)µ) − 2 lim

T →∞

=γ0 + 0 − 2 lim
T →∞

1
T

T
(cid:88)

s=1

γ|s−t|

=γ0,

(S.14)

where the third step is due to (cid:98)µ − µ = 1
E((cid:98)µ−µ) = 0 by stationarity of the time series, the second last step is due to lim
(Brockwell et al. 1991, Theorem 7.1.1.), and the last step due to Condition (R3).

s=1(Xs − µ), and the fourth step is because
V ar((cid:98)µ) = 0

T →∞

T

(cid:80)

6. Similar to (S.14), we have that

lim
T →∞

E{(Xt − (cid:98)µ)(Xt−p − (cid:98)µ)}

= lim
T →∞

= lim
T →∞

E{(Xt − µ + µ − (cid:98)µ)(Xt−p − µ + µ − (cid:98)µ)}

[E{(Xt − µ)(Xt−p − µ)} + E{(µ − (cid:98)µ)(Xt−p − µ)} + E{(µ − (cid:98)µ)(Xt − µ)} + E{(µ − (cid:98)µ)(µ − (cid:98)µ)}]

=γp + lim
T →∞

1
T

T
(cid:88)

s=1

=γp,

(γ|t−s| + γ|t−s−p|) + lim
T →∞

Var((cid:98)µ)

8

(S.15)

where the last step is due to Condition (R3) and lim
T →∞

V ar((cid:98)µ) = 0 (Brockwell et al. 1991,

Theorem 7.1.1).

7. For any t, we have

E{(et − ¯e)2}

t − 2et¯e + ¯e2}

=E{e2
(cid:40)

=

E(e2

t ) −

(cid:40)

=E(e2

t ) +

−

2
T

T
(cid:88)

s=1

E(etes) +

1
T 2

2
T

E(etet) +

1
T 2

T
(cid:88)

t=1

T
(cid:88)

T
(cid:88)

(cid:41)

E(etes)

t=1

s=1

(cid:41)

E(e2
t )

=

T − 1
T

E(e2

t ) =

T − 1
T

σ2
e ,

E{(et − ¯e)2} = σ2
e .

so lim
T →∞
8. By the independence of et and Xt, for any s and t, we have that

Cov{(Xt − (cid:98)µ)(et − ¯e), (es − ¯e)2}
=E{(Xt − (cid:98)µ)(et − ¯e)(es − ¯e)2} − E{(Xt − (cid:98)µ)(et − ¯e)}E{(es − ¯e)2}
=E(Xt − (cid:98)µ)E{(et − ¯e)(es − ¯e)2} − E(Xt − (cid:98)µ)E(et − ¯e)E(es − ¯e)2
=0,

(S.16)

(S.17)

where the last step is due to E(Xt − (cid:98)µ) = 0 and E(et − ¯e) = 0.

9. For any t (cid:54)= s, Cov {(et − ¯e)2, (es − ¯e)2} = 0; and for t = s,

Var{(et − ¯e)2}

=E{(et − ¯e)4} − E2{(et − ¯e)2}

t ¯e) + 6E(e2

t ¯e2) − 4E(et¯e3) + E(¯e4

=E(e4

=E(e4

t ) − 4E(e3
4
T
(cid:26)

t ) −

E(e4

−

E(e2

t ) −

t ) +

(cid:20) 6(T − 1)
T 2

{E(e2

t )}2 +

2
T

E(e2

t ) +

(cid:27)2

E(e2
t )

,

1
T

t ) − 2E(et¯e) + E(¯e2)}2
t ) − {E(e2
(cid:20) 1
(cid:21)
4
6
T 3 E(e4
T 3 E(e4
T 2 E(e4
t )

t ) +

t ) +

−

3(T − 1)
T 3

(cid:21)

{E(e2

t )}2

(S.18)

so lim
T →∞

Var{(et − ¯e)2} = E(e4

t ) − {E(e2

t )}2 = E(e4

t ) − σ4
e .

9

10. Similar to the derivation in (S.18), we can show Cov{(et − ¯e)2, (es − ¯e)(es+p − ¯e)} = 0

for s (cid:54)= t and s (cid:54)= t − p. For a given t,

Cov{(et − ¯e)2, (et − ¯e)(et+p − ¯e)}

=E{(et − ¯e)3(et+p − ¯e)} − E{(et − ¯e)2}E{(et − ¯e)(et+p − ¯e)},

(S.19)

which can be derived analogously to the (S.18) that limT →∞ E{(et − ¯e)3(et+p − ¯e)} − E{(et −

¯e)2}E{(et − ¯e)(et+p − ¯e)} = E{e3

t et+p} − E{e2

t }E{etet+p} = 0 and similarly lim
T →∞

Cov{(et −

¯e)2, (et−p − ¯e)(et − ¯e)} = 0.

11. For any t,

Cov {(Xt − (cid:98)µ)(et+p − ¯e), (Xt+p−r − (cid:98)µ)(et+p − ¯e)}
= (cid:2)E (cid:8)(Xt − (cid:98)µ)(Xt+p−r − (cid:98)µ)(et+p − ¯e)2(cid:9) − E(Xt − (cid:98)µ)E(Xt+p−r − (cid:98)µ)E2(et+p − ¯e)(cid:3)
= E {(Xt − (cid:98)µ)(Xt+p−r − (cid:98)µ)} E (cid:8)(et+p − ¯e)2(cid:9)

= γ|p−r|

(cid:19)

(cid:18) T − 1
T

σ2
e ,

(S.20)

where the second step is because of E(Xt − (cid:98)µ) = 0 and the independence of Xt and et, the
third step is due to (S.16) and (S.15). Hence,

lim
T →∞

Cov {(Xt − (cid:98)µ)(et+p − ¯e), (Xt+p−r − (cid:98)µ)(et+p − ¯e)} = γ|p−r|σ2
e .

Similarly,

lim
T →∞

Cov {(Xt+p − (cid:98)µ)(et − ¯e), (Xt−r − (cid:98)µ)(et − ¯e)} = γ|p−r|σ2
e .

Then, similarly,

Cov {(Xt − (cid:98)µ)(et+p − ¯e), (Xt+p+r − (cid:98)µ)(et+p − ¯e)}
= (cid:2)E (cid:8)(Xt − (cid:98)µ)(Xt+p+r − (cid:98)µ)(et+p − ¯e)2(cid:9) − E(Xt − (cid:98)µ)E(Xt+p−r − (cid:98)µ)E2(et+p − ¯e)(cid:3)
= E {(Xt − (cid:98)µ)(Xt+p+r − (cid:98)µ)} E (cid:8)(et − ¯e)2(cid:9)

= γp+r

(cid:19)

(cid:18) T − 1
T

σ2
e ,

(S.21)

and hence limT →∞ Cov {(Xt − (cid:98)µ)(et+p − ¯e), (Xt+p+r − (cid:98)µ)(et+p − ¯e)} = γp+rσ2
limT →∞ Cov {(Xt+p − (cid:98)µ)(et − ¯e), (Xt+r − (cid:98)µ)(et − ¯e)} = γp+rσ2
e .

e . Similarly,

10

12. By independence assumption between {et}, if t (cid:54)= s or p (cid:54)= r, we have that

Cov {(et − ¯e)(et+p − ¯e), (es − ¯e)(es+r − ¯e)} = 0.

(S.22)

In addition, by (S.16), we have that

Var {(et − ¯e)(et+p − ¯e)}
= E (cid:8)(et − ¯e)2(et+p − ¯e)2(cid:9)
= E (cid:8)(et − ¯e)2(cid:9) E (cid:8)(et+p − ¯e)2(cid:9) ,

(cid:19)2

=

(cid:18) T − 1
T

σ4
e ,

(S.23)

so limT →∞ Var {(et − ¯e)(et+p − ¯e)} = σ4
e .

Step 2: Now we prove the results in (3).

11

1◦. We ﬁrst show the derivation of q∗

100 as follows:

q∗
100 = lim
T →∞

T Cov

= lim
T →∞

T Cov

(cid:40)

1
T

(cid:34)

1
T

T
(cid:88)

t=1
T
(cid:88)

t=1

(X ∗

t − (cid:98)µ∗)2,

1
T

(cid:41)

T
(cid:88)

(X ∗

s − (cid:98)µ∗)2

s=1

(cid:8)α2

1(Xt − (cid:98)µ)2 + 2α1(Xt − (cid:98)µ)(et − ¯e) + (et − ¯e)2(cid:9) ,

(cid:35)

1
T

T
(cid:88)

s=1

1(Xs − (cid:98)µ)2 + 2α1(Xs − (cid:98)µ)(es − ¯e) + (es − ¯e)2
α2
(cid:40)

(cid:41)

= α4

1 lim
T →∞

T Cov

T
(cid:88)

1
T

(Xt − (cid:98)µ)2,
t=1
(cid:40)

T
(cid:88)

1
T

T
(cid:88)

s=1

(Xs − (cid:98)µ)2

1
T

+ lim
T →∞

T Cov

+ lim
T →∞

T Cov

(cid:40)

1
T

2α1(Xt − (cid:98)µ)(et − ¯e),

t=1
T
(cid:88)

(et − ¯e)2,

t=1

1
T

T
(cid:88)

s=1

(es − ¯e)2

(cid:41)

2α1(Xs − (cid:98)µ)(es − ¯e)

1
T

T
(cid:88)

s=1
(cid:41)

= α4

1q00 + lim
T →∞

4α2
1
T

T
(cid:88)

T
(cid:88)

Cov {(Xt − (cid:98)µ)(et − ¯e), (Xs − (cid:98)µ)(es − ¯e)}

t=1
T
(cid:88)

s=1
T
(cid:88)

+ lim
T →∞

1
T

Cov (cid:8)(et − ¯e)2, (es − ¯e)2(cid:9)

= α4

1q00 + lim
T →∞

4α2
1
T

s=1

t=1
T
(cid:88)

Cov {(Xt − (cid:98)µ)(et − ¯e), (Xt − (cid:98)µ)(et − ¯e)}

+ lim
T →∞

1
T

t=1
T
(cid:88)

t=1

Cov (cid:8)(et − ¯e)2, (et − ¯e)2(cid:9)

= α4

1q00 + 4α2

= α4

1q00 + 4α2

1E (cid:8)(Xt − (cid:98)µ)2(et − ¯e)2(cid:9) + E(e4
t ) − σ4
1γ0σ2
e ,

e + E(e4

t ) − (cid:8)E(e2

t )(cid:9)2

where the second step is due to (S.10), the third step is because of (S.11), (S.17), and the
t=1(Xt − (cid:98)µ)2, 1
to (S.12) and (S.18), and the sixth step is because (S.13) and (S.18), and the last step is

deﬁnition q00 = limT →∞ T Cov

s=1(Xs − (cid:98)µ)2(cid:111)

, the ﬁfth step is due

(cid:110) 1
T

(cid:80)T

(cid:80)T

T

because (S.16) and (S.17).

12

2◦. We derive the value of q∗

10p:

q∗
10p = lim
T →∞

T Cov

= lim
T →∞

T Cov

(cid:40)

1
T

(cid:34)

1
T

T
(cid:88)

t=1
T
(cid:88)

t=1

(X ∗

t − (cid:98)µ∗)2,

1
T − p

T −p
(cid:88)

s=1

(X ∗

s − (cid:98)µ∗)(X ∗

s+p − (cid:98)µ∗)

(cid:41)

(cid:8)α2

1(Xt − (cid:98)µ)2 + 2α1(Xt − (cid:98)µ)(et − ¯e) + (et − ¯e)2(cid:9) ,

T −p
(cid:88)

α2
1(Xs − (cid:98)µ)(Xs+p − (cid:98)µ) + α1(Xs − (cid:98)µ)(es+p − ¯e)

1
T − p

s=1

(cid:35)
+ α1(Xs+p − (cid:98)µ)(es − ¯e) + (es − ¯e)(es+p − ¯e)

= α4

1 lim
T →∞

T Cov

(cid:40)

1
T

T
(cid:88)

(Xt − (cid:98)µ)2,
t=1
(cid:40)

1
T − p

T −p
(cid:88)

s=1

(cid:41)

(Xs − (cid:98)µ)(Xs+p − (cid:98)µ)

T
(cid:88)

t=1

T
(cid:88)

t=1

+ lim
T →∞

T Cov

+ lim
T →∞

T Cov

+ lim
T →∞

T Cov

(cid:40)

(cid:40)

1
T

1
T

1
T

2α1(Xt − (cid:98)µ)(et − ¯e),

2α1(Xt − (cid:98)µ)(et − ¯e),

1
T − p

1
T − p

T −p
(cid:88)

s=1
T −p
(cid:88)

s=1

(cid:41)

α1(Xs − (cid:98)µ)(es+p − ¯e)

(cid:41)

α1(Xs+p − (cid:98)µ)(es − ¯e)

(cid:41)

T
(cid:88)

(et − ¯e)2,

1
T − p

T −p
(cid:88)

s=1

(es − ¯e)(es+p − ¯e)

= α4

1q0p + lim
T →∞

2α2
1
T − p

T
(cid:88)

t=1

+ lim
T →∞

2α2
1
T − p

= α4

1q0p + lim
T →∞

2α2
1
T − p

t=1
T −p
(cid:88)

s=1
T −p
(cid:88)

T
(cid:88)

s=1

t=1
T
(cid:88)

t=p
(s=t−p)

Cov {(Xt − (cid:98)µ)(et − ¯e), (Xs − (cid:98)µ)(es+p − ¯es)}

Cov {(Xt − (cid:98)µ)(et − ¯e), (Xs+p − (cid:98)µ)(es − ¯e)}

Cov {(Xt − (cid:98)µ)(et − ¯e), (Xt−p − (cid:98)µ)(et − ¯e)}

+ lim
T →∞

2α2
1
T − p

T −p
(cid:88)

t=1
(s=t)

Cov {(Xt − (cid:98)µ)(et − ¯e), (Xt+p − (cid:98)µ)(et − ¯e)}

= α4

1q0p + 2α2

= α4

1q0p + 4α2

1E (cid:8)(Xt − (cid:98)µ)(Xt−p − (cid:98)µ)(et − ¯e)2(cid:9) + 2α2
1γpσ2
e ,

1E (cid:8)(Xt − (cid:98)µ)(Xt+p − (cid:98)µ)(et − ¯e)2(cid:9)

where the second step is due to (S.10), the third step is because of (S.11) and (S.17), the

fourth step is by deﬁnition that q0p = limT →∞ T Cov

(cid:110) 1
T

(cid:80)T

t=1(Xt − (cid:98)µ)2,

1
T −p

(cid:80)T −p

(cid:111)
s=1 (Xs − (cid:98)µ)(Xs+p − (cid:98)µ)

and (S.19), the ﬁfth step is due to (S.12), and the last step is result from (S.16) and (S.15).

13

3◦. We derive q∗

1pr for p > 0, r > 0 and p (cid:54)= r:

(cid:40)

q∗
1pr = lim
T →∞

T Cov

1
T − p

T −p
(cid:88)

(X ∗

t − (cid:98)µ∗)(X ∗

t+p − (cid:98)µ∗),

1
T − r

T −r
(cid:88)

s=1

(X ∗

s − (cid:98)µ∗)(X ∗

s+r − (cid:98)µ∗)

(cid:41)

(cid:34)

= lim
T →∞

T Cov

1
T − p

t=1
T −p
(cid:88)

t=1

(cid:8)α2

1(Xt − (cid:98)µ)(Xt+p − (cid:98)µ) + α1(Xt − (cid:98)µ)(et+p − ¯e)

+α1(Xt+p − (cid:98)µ)(et − ¯e) + (et − ¯e)(et+p − ¯e)} ,

1
T − r

T −r
(cid:88)

s=1

α2
1(Xs − (cid:98)µ)(Xs+r − (cid:98)µ) + α1(Xs − (cid:98)µ)(es+r − ¯e)

(cid:35)

+ α1(Xs+r − (cid:98)µ)(es − ¯e) + (es − ¯e)(es+r − ¯e)

= α4

1 lim
T →∞

T Cov

(cid:40)

1
T − p
(cid:40)

+ lim
T →∞

T Cov

+ lim
T →∞

T Cov

+ lim
T →∞

T Cov

+ lim
T →∞

T Cov

(cid:40)

(cid:40)

(cid:40)

T −p
(cid:88)

t=1

(Xt − (cid:98)µ)(Xt+p − (cid:98)µ),

1
T − r

T −r
(cid:88)

s=1

(cid:41)

(Xs − (cid:98)µ)(Xs+r − (cid:98)µ)

1
T − p

1
T − p

1
T − p

1
T − p

T −p
(cid:88)

t=1
T −p
(cid:88)

t=1
T −p
(cid:88)

t=1
T −p
(cid:88)

t=1

α1(Xt − (cid:98)µ)(et+p − ¯e),

α1(Xt − (cid:98)µ)(et+p − ¯e),

α1(Xt+p − (cid:98)µ)(et − ¯e),

α1(Xt+p − (cid:98)µ)(et − ¯e),

1
T − r

1
T − r

1
T − r

1
T − r

T −r
(cid:88)

s=1

T −r
(cid:88)

s=1

T −r
(cid:88)

s=1

T −r
(cid:88)

s=1

(cid:41)

(cid:41)

(cid:41)

(cid:41)

α1(Xs − (cid:98)µ)(es+r − ¯e)

α1(Xs+r − (cid:98)µ)(es − ¯e)

α1(Xs − (cid:98)µ)(es+r − ¯e)

α1(Xs+r − (cid:98)µ)(es − ¯e)

= α4

1qpr + α2

1 lim
T →∞

T
(T − p)(T − r)

T −p
(cid:88)

t=max(1,r−p+1)
(s=t+p−r)

Cov {(Xt − (cid:98)µ)(et+p − ¯e), (Xt+p−r − (cid:98)µ)(et+p − ¯e)}

+ α2

1 lim
T →∞

T
(T − p)(T − r)

+ α2

1 lim
T →∞

T
(T − p)(T − r)

T −p−r
(cid:88)

t=1
(s=t+p)

T −p
(cid:88)

t=r+1
(s=t−r)

Cov {(Xt − (cid:98)µ)(et+p − ¯e), (Xt+p+r − (cid:98)µ)(et+p − ¯e)}

Cov {(Xt+p − (cid:98)µ)(et − ¯e), (Xt−r − (cid:98)µ)(et − ¯e)}

+ α2

1 lim
T →∞

T
(T − p)(T − r)

T −max(p,r)
(cid:88)

t=1
(s=t)

Cov {(Xt+p − (cid:98)µ)(et − ¯e), (Xt+r − (cid:98)µ)(et − ¯e)}

= α4

1qpr + 2α2

1σ2

e (γ|p−r| + γp+r),

(S.24)

14

where the second step is due to (S.10), the third step is because of (S.11) and a similar

version to (S.17), the fourth step is because (S.22) and by the deﬁnition that

qpr = limT →∞ T Cov

(cid:110) 1
T −p

(cid:80)T −p

t=1 (Xt − (cid:98)µ)(Xt+p − (cid:98)µ),

1
T −r

(cid:80)T −r

s=1 (Xs − (cid:98)µ)(Xs+r − (cid:98)µ)

(cid:111)

, and the

last step is from (S.20) and (S.21).

15

4◦. Finally, we present the derivation of q∗

1pp for p (cid:54)= 0,

(cid:40)

q∗
1pp = lim
T →∞

T Cov

1
T − p

(cid:34)

= lim
T →∞

T Cov

1
T − p

T −p
(cid:88)

t=1
T −p
(cid:88)

t=1

(cid:8)α2

(X ∗

t − (cid:98)µ∗)(X ∗

t+p − (cid:98)µ∗),

1
T − p

T −p
(cid:88)

s=1

(X ∗

s − (cid:98)µ∗)(X ∗

s+p − (cid:98)µ∗)

(cid:41)

1(Xt − (cid:98)µ)(Xt+p − (cid:98)µ) + α1(Xt − (cid:98)µ)(et+p − ¯e)

+α1(Xt+p − (cid:98)µ)(et − ¯e) + (et − ¯e)(et+p − ¯e)} ,

T −p
(cid:88)

α2
1(Xs − (cid:98)µ)(Xs+p − (cid:98)µ) + α1(Xs − (cid:98)µ)(es+p − ¯e)

1
T − p

s=1

(cid:35)
+ α1(Xs+p − (cid:98)µ)(es − ¯e) + (es − ¯e)(es+p − ¯e)

= α4

1 lim
T →∞

T Cov

(cid:40)

1
T − p
(cid:40)

+ lim
T →∞

T Cov

+ lim
T →∞

T Cov

+ lim
T →∞

T Cov

+ lim
T →∞

T Cov

+ lim
T →∞

T Cov

(cid:40)

(cid:40)

(cid:40)

(cid:40)

t=1

1
T − p

1
T − p

1
T − p

1
T − p

1
T − p

T −p
(cid:88)

(Xt − (cid:98)µ)(Xt+p − (cid:98)µ),

1
T − p

T −p
(cid:88)

s=1

(cid:41)

(Xs − (cid:98)µ)(Xs+p − (cid:98)µ)

T −p
(cid:88)

t=1
T −p
(cid:88)

t=1
T −p
(cid:88)

t=1
T −p
(cid:88)

α1(Xt − (cid:98)µ)(et+p − ¯e),

α1(Xt − (cid:98)µ)(et+p − ¯e),

α1(Xt+p − (cid:98)µ)(et − ¯e),

α1(Xt+p − (cid:98)µ)(et − ¯e),

t=1
T −p
(cid:88)

(et − ¯e)(et+p − ¯e),

t=1

1
T − p

1
T − p

1
T − p

1
T − p

T −p
(cid:88)

s=1
T −p
(cid:88)

s=1
T −p
(cid:88)

s=1
T −p
(cid:88)

s=1

(cid:41)

α1(Xs − (cid:98)µ)(es+p − ¯e)

(cid:41)

α1(Xs+p − (cid:98)µ)(es − ¯e)

(cid:41)

α1(Xs − (cid:98)µ)(es+p − ¯e)

(cid:41)

α1(Xs+p − (cid:98)µ)(es − ¯e)

1
T − p

T −p
(cid:88)

s=1

(cid:41)

(es − ¯e)(es+p − ¯e)

= α4

1qpp + α2

1 lim
T →∞

T
(T − p)2

T −p
(cid:88)

t=1
s=t

Cov {(Xt − (cid:98)µ)(et+p − ¯e), (Xt − (cid:98)µ)(et+p − ¯e)}

+ α2

1 lim
T →∞

T
(T − p)2

+ α2

1 lim
T →∞

T
(T − p)2

T −2p
(cid:88)

t=1
s=t+p

T −p
(cid:88)

t=1+p
s=t−p

Cov {(Xt − (cid:98)µ)(et+p − ¯e), (Xt+2p − (cid:98)µ)(et+p − ¯e)}

Cov {(Xt+p − (cid:98)µ)(et − ¯e), (Xt−p − (cid:98)µ)(et − ¯e)}

+ α2

1 lim
T →∞

T
(T − p)2

T
(cid:88)

t=1
s=t

Cov {(Xt+p − (cid:98)µ)(et − ¯e), (Xt+p − (cid:98)µ)(et − ¯e)}

T

+ α2

1 lim
T →∞

(T − p)2 Var {(et − ¯e)(et+p − ¯e)} = α4

16

1qpp + 2α2

1σ2

e (γ0 + γ2p) + σ4

e , (S.25)

where the second step is due to (S.10), the third step is because of (S.11) and a similar

version to (S.17), the fourth step is because (S.22) and by the deﬁnition that

qpp = limT →∞ T Cov

(cid:110) 1
T −p

(cid:80)T −p

t=1 (Xt − (cid:98)µ)(Xt+p − (cid:98)µ),

1
T −p

(cid:80)T −p

(cid:111)
s=1 (Xs − (cid:98)µ)(Xs+p − (cid:98)µ)

, the last

step is because of (S.23), and (S.20) and (S.21) with q = p.

A.5 The proof of Theorem 4

Proof of Theorem 4(1):

For k = 1, . . . , p, applying the weak law of large numbers to (cid:98)γ∗
k converges in probability to Cov(X ∗

t , X ∗

the estimator (cid:98)γ∗

t−k), which is denoted as γ∗
k.

k, we obtain that as T → ∞,

Next, we examine γk. By the form of measurement error model (9), we have that for

0 < k < t,

Cov(X ∗

t , X ∗

t−k)

= Cov(β0Xtut, β0Xt−kut−k)

= β2

0{E(XtutXt−kut−k) − E(Xtut)E(Xt−kut−k)}

= β2

0{E(ut)E(ut−k)Cov(Xt, Xt−k)}

= β2

0{Cov(Xt, Xt−k)} = β2

0γk,

and by (10), Var(X ∗

t ) = β2

0 {(σ2

u + 1)γ0 + σ2

uµ2}, which is denoted as γ∗

0. Thus, Theorem 4(1)

follows.

Proof of Theorem 4(2):

First, by Theorem 4(1), we write

and

(cid:98)Γ∗ =








β2
0(σ2

uµ2

u + 1)γ0 + β0σ2
...
β2
0γp−1

= β2
0

(cid:8)Γ + σ2

u(γ0 + µ2)Ip

(cid:98)γ∗ = β2

0γ + op(1)

β2
0γ1

· · ·
. . .

· · · β2

0(σ2

β2
0γp−2
(cid:9) + op(1).

17

β2
0γp−1
...
u + 1)γ0 + β0σ2

uµ2








+ op(1)








where (cid:98)Γ∗ =

(6) with (cid:98)γ∗
k,

0

(cid:98)γ∗
...
(cid:98)γ∗

p−1

p−1

· · · (cid:98)γ∗
...
. . .
(cid:98)γ∗

· · ·

0








. Then the naive estimator (cid:98)φ∗ is obtained by replacing (cid:98)γk in

(cid:98)φ∗ = [β2
0

(cid:8)Γ + σ2

u(γ0 + µ2)Ip

(cid:9) + op(1)]−1{β2

0γ + op(1)} = (cid:8)Γ + σ2

u(γ0 + µ2)Ip

(cid:9)−1 γ + op(1),

(S.26)

and hence φ∗ = {Γ + σ2

u(γ0 + µ2)Ip}−1 γ such that (cid:98)φ∗

p
−→ φ∗ as T → ∞.

Again, by replacing (cid:98)γk in (6) with (cid:98)γ∗

k gives the naive estimator (cid:98)φ∗
0

(cid:98)φ∗
0 =

1
T − p

T
(cid:88)

t=p

(cid:33) (cid:32)

(cid:32) p

(cid:88)

(cid:98)φ∗
k

X ∗

t −

1
T − p

T
(cid:88)

t=p

(cid:33)

X ∗

t−k

= E(X ∗

t ) − E(X ∗
t )

(cid:98)φ∗
k + op(1)

k=1
p
(cid:88)

k=1

= β0E(Xt) − β0E(Xt)

p
(cid:88)

{φ∗

k + op(1)} + op(1)

k=1
= β0(1 − φ∗T1p)µ + op(1),

where (cid:98)φk and φk are respectively the kth element of (cid:98)φ and φ, the third step is because

(cid:98)φk = φk + op(1) by (S.26) as well as the model form (9), and the last step is due to the

stationarity of the time series {Xt} such that E(Xt) = µ.

Finally, noting that the native estimator (cid:98)σ(cid:15)
applying a version similar to (6), we obtain that

∗2 is given by (cid:98)σ∗2

(cid:15) = (cid:98)γ∗

0 − 2(cid:98)φ∗T

(cid:98)γ∗ + (cid:98)φ∗T(cid:98)Γ∗ (cid:98)φ∗ by

(cid:15) =(cid:98)γ∗
(cid:98)σ∗2
=β2
0

0 − 2(cid:98)φ∗T
(cid:8)(σ2

(cid:98)γ∗ + (cid:98)φ∗T(cid:98)Γ∗ (cid:98)φ∗

u + 1)γ0 + σ2

uµ2(cid:9) − 2β2
u(γ0 + µ2)I}−1{Γ + σ2

0γ T{Γ + σ2

+ β2

0γ T{Γ + σ2
(cid:8)(σ2

u + 1)γ0 + σ2

=β2
0

uµ2(cid:9) − β2

0γ T{Γ + σ2

u(γ0 + µ2)I}−1γ + op(1).

u(γ0 + µ2)I}−1γ

u(γ0 + µ2)I}{Γ + σ2

u(γ0 + µ2)I}−1γ + op(1)

Proof of Theorem 4(3):

Step 1: We show that as T → ∞,

√

T

(cid:32)

1
T

T
(cid:88)

(X ∗

t − µ∗)(X ∗

t+p − µ∗) −

t=1

(X ∗

t − (cid:98)µ∗)(X ∗

t+p − (cid:98)µ∗)

= op(1).

(S.27)

(cid:33)

1
T − p

T −p
(cid:88)

t=1

18

With some simple algebra,

(cid:40)

√

T

√

=

T

1
T
(cid:40)

(cid:40)

√

T

=

T
(cid:88)

t=1

(X ∗

t − µ∗)(X ∗

t+p − µ∗) −

1
T − p

T −p
(cid:88)

t=1

(X ∗

t − (cid:98)µ∗)(X ∗

t+p − (cid:98)µ∗)

(cid:41)

1
T

1
T

T
(cid:88)

t=1

T
(cid:88)

t=1

(X ∗

t − µ∗)(X ∗

t+p − µ∗) −

(X ∗

t − µ∗)(X ∗

t+p − µ∗) −

−

1
T − p

T −p
(cid:88)

(X ∗

t − µ∗)(µ∗ − (cid:98)µ∗) −

t=1

1
T − p

1
T − p

1
T − p

T −p
(cid:88)

(X ∗

t − µ∗ + µ∗ − (cid:98)µ∗)(X ∗

t+p − µ∗ + µ∗ − (cid:98)µ∗)

(cid:41)

t=1
T −p
(cid:88)

(X ∗

t − µ∗)(X ∗

t+p − µ∗)

t=1
T −p
(cid:88)

(X ∗

t+p − µ∗)(µ∗ − (cid:98)µ∗) −

t=1

1
T − p

T −p
(cid:88)

t=1

(cid:41)

(µ∗ − (cid:98)µ∗)2

√

T

=

(cid:18) T − p
T

− 1

(cid:19) 1

T −p
(cid:88)

T − p

t=1

(X ∗

t − µ∗)(X ∗

t+p − µ∗) +

√

+

T ((cid:98)µ∗ − µ∗)

(cid:32)

1
T − p

T −p
(cid:88)

t=1

X ∗

t +

1
T − p

T −p
(cid:88)

t=1

(cid:44) I1 + I2 + I3.

1
√
T

T
(cid:88)

(X ∗

t − µ∗)(X ∗

t+p − µ∗)

t=T −p+1

(cid:33)

X ∗

t+p − (cid:98)µ∗ − µ∗

(S.28)

Now we examine each term in (S.28) as T → ∞ separately. First,

I1 = −

= −

p
√
T
p
√
T

1
T − p

T −p
(cid:88)

t=1

(X ∗

t − µ∗)(X ∗

t+p − µ∗)

{γ∗

p + op(1)} = op(1)

as

T → ∞.

(S.29)

Next, we examine the second term I2 in (S.28). Since T − 1
2 pVar(Xt) (Brockwell et al. 1991, p.230) and T − 1

µ∗)] ≤ T − 1

2 E[(cid:80)T

t=T −p+1(X ∗

t − µ∗)(X ∗

t+p −

2 pVar(Xt) → 0 as T → ∞, we

have that

I2 =

1
√
T

T
(cid:88)

(X ∗

t − µ∗)(X ∗

t+p − µ∗) = op(1).

(S.30)

t=T −p+1

19

Finally, we examine I3 in (S.28).

1
T − p

=

1
T − p

=

1
T − p

T −p
(cid:88)

t=1
T −p
(cid:88)

t=1

T −p
(cid:88)

t=1

X ∗

t+p − (cid:98)µ∗

X ∗

t+p −

X ∗

t+p −

1
T

1
T

p
(cid:88)

t=1

p
(cid:88)

t=1

X ∗

t −

X ∗

t −

1
T

1
T

T
(cid:88)

t=p+1

X ∗
t

T −p
(cid:88)

t=1

X ∗

t+p

=(

1
T − p

−

1
T

)

T −p
(cid:88)

t=1

X ∗

t+p −

1
T

p
(cid:88)

t=1

X ∗
t

=op(1)

as

T → ∞,

(S.31)

(cid:80)T

where (cid:98)µ∗ = 1
T → ∞. In addition, by the weak law of large numbers,

t = op(1) because E( 1
T

t , and 1
T

t=1 X ∗

t=1 X ∗

T

(cid:80)p

(cid:80)p

t=1 X ∗

t ) = 1

T pE(Xt) → 0 as

1
T − p

T −p
(cid:88)

t=1

X ∗

t − µ∗

p
−→ 0

as

T → ∞.

(S.32)

By condition (R2) and the central limit theorem for strictly stationary p-dependent sequences

(Brockwell et al. 1991, Theorem 6.4.2), we have

√

T ((cid:98)µ∗ − µ∗) = Op(1).

(S.33)

Therefore, applying (S.29), (S.30), (S.31), (S.32) and (S.33) yields (S.27).

Step 2: We show that as T → ∞, the asymptotic covariance matrix of

√

T (cid:8)((cid:98)γ∗

0, (cid:98)γ∗T)T − (γ∗

0, γ∗T)T(cid:9)

equals

lim
T →∞

Cov

(cid:40)

1
√
T

T
(cid:88)

t=1

(X ∗

t − µ∗)(X ∗

t+r − µ∗),

(X ∗

s − µ∗)(X ∗

s+q − µ∗)

.

(cid:41)

1
√
T

T
(cid:88)

s=1

20

For k ≤ p

√

T ((cid:98)γk − γk)

(cid:40)

(cid:40)

√

=

√

=

T

T

1
T − k

T −k
(cid:88)

t=1

(X ∗

t − (cid:98)µ∗)(X ∗

t+k − (cid:98)µ∗) − γk

(cid:41)

(cid:41)

(X ∗

t − µ∗)(X ∗

t+k − µ∗) − γk

T
(cid:88)

1
T
(cid:40)

t=1

1
T − k

T −k
(cid:88)

t=1

√

T

+

(cid:40)

=

1
√
T

T
(cid:88)

t=1

(X ∗

t − (cid:98)µ∗)(X ∗

t+k − (cid:98)µ∗) −
(cid:41)

(X ∗

t − µ∗)(X ∗

t+k − µ∗)

(cid:41)

1
T

T
(cid:88)

t=1

(X ∗

t − µ∗)(X ∗

t+k − µ∗) − γk

+ op(1),

where the last step is due to (S.27).

Hence, the (r, q) element of matrix lim
T →∞

Var

(cid:16)√

T (cid:8)((cid:98)γ∗

0, (cid:98)γ∗T)T − (γ∗

0, γ∗T)T(cid:9)(cid:17)

lim
T →∞

Cov

(cid:40)

1
√
T

T
(cid:88)

t=1

(X ∗

t − µ∗)(X ∗

t+r − µ∗),

1
√
T

T
(cid:88)

s=1

(X ∗

s − µ∗)(X ∗

s+q − µ∗)

.

is given by

(cid:41)

Step 3: We show certain identities to be used for proving Theorem 4(3):

1. By model (9), we have that

X ∗

t − µ∗ = β0Xtut − β0µ

= β0Xtut − β0utµ + β0utµ − β0µ

= β0{ut(Xt − µ) + µ(ut − 1)}

(S.34)

where the ﬁrst step is because µ∗ = E(β0Xtut) = β0E(Xt)E(ut) = β0µ.

21

2. We have that

lim
T →∞

= lim
T →∞

= lim
T →∞

1
T

1
T

1
T

T
(cid:88)

T
(cid:88)

t=1
T
(cid:88)

s=1
T
(cid:88)

t=1
T
(cid:88)

s=1
T
(cid:88)

t=1

s=1
s(cid:54)=t

Cov (cid:8)u2

t (Xt − µ)2, u2

s(Xs − µ)2(cid:9)

(cid:2)E{u2

t u2

s(Xt − µ)2(Xs − µ)2} − E(u2

t )E(u2

s)E{(Xt − µ)2}E{(Xs − µ)2}(cid:3) ,

(cid:2)E(u2

t u2

s)E{(Xt − µ)2(Xs − µ)2} − E(u2

t )E(u2

s)E{(Xt − µ)2}E{(Xs − µ)2}(cid:3)

+ lim
T →∞

1
T

T
(cid:88)

t=1
s=t

(cid:2)E(u4

t )E{(Xt − µ)4} − E2(u2

t )E2{(Xt − µ)2}(cid:3) ,

= lim
T →∞

1
T

T
(cid:88)

T
(cid:88)

t=1

s=1
s(cid:54)=t

(cid:2)E(u2

t )E(u2

s)Cov{(Xt − µ)2, (Xs − µ)2}(cid:3) + lim

T →∞

+ lim
T →∞

1
T

T
(cid:88)

t=1
s=t

(cid:8)E(u4

t ) − E2(u2

t )(cid:9) E{(Xt − µ)4}

= lim
T →∞

1
T

T
(cid:88)

T
(cid:88)

t=1

s=1

(cid:2)E(u2

t )E(u2

s)Cov{(Xt − µ)2, (Xs − µ)2}(cid:3) + lim

T →∞

1
T

T
(cid:88)

t=1
s=t

1
T

T
(cid:88)

t=1

E2(u2

t )Var{(Xt − µ)2}

(cid:8)E(u4

t ) − E2(u2

t )(cid:9) E{(Xt − µ)4}

=(σ2

u + 1)2q00 + {E(u4

t ) − (σ2

u + 1)2}E{(Xt − µ)4},

(S.35)

step, we use the deﬁnition q00 = limT →∞

where the second and third step is due to the independence between ut and Xt. In the last
T
(cid:80)
s=1

u+1,
t ) and E{(Xt − µ)4} are time-independent which are derived from

Cov {(Xt − µ)2, (Xs − µ)2}, E(u2

and the fact that E(u4

t ) = σ2

T
(cid:80)
t=1

1
T

Conditions (R1) and (R2) together with independence between ut and Xt.

3. Similar to the derivation in (S.35), now we derive the summation of Cov{β2

0u2

t (Xt −

22

µ)2, β2

0usus+p(Xs − µ)(Xs+p − µ)} for p > 0,

lim
T →∞

1
T

= lim
T →∞

T
(cid:88)

T
(cid:88)

Cov{β2

0u2

t (Xt − µ)2, β2

0usus+p(Xs − µ)(Xs+p − µ)}

t=1
β4
0
T

s=1
T
(cid:88)

T
(cid:88)

t=1

s=1

(cid:2)E(u2

t usus+p)E{(Xt − µ)2(Xs − µ)(Xs+p − µ)}

−E(u2

= lim
T →∞

t )E(us)E(us+p)E(Xt − µ)2E{(Xs − µ)(Xs+p − µ)}(cid:3)
β4
0
T

E(u2

T
(cid:88)

T
(cid:88)

t )E(us)E(us+p)Cov{(Xt − µ)2, (Xs − µ)(Xs+p − µ)}

s=1
T
(cid:88)

t=1
β4
0
T

+ lim
T →∞

+ lim
T →∞

β4
0
T

(cid:8)E(u3

t )E(ut+p) − E(u2

t )E(ut)E(ut+p)(cid:9) E{(Xt − µ)3(Xt+p − µ)}

t=1
s=t
T
(cid:88)

t=1
s=t−p

(cid:8)E(u3

t )E(ut−p) − E(u2

t )E(ut)E(ut−p)(cid:9) E{(Xt − µ)3(Xt−p − µ)}

= lim
T →∞

β4
0
T

T
(cid:88)

T
(cid:88)

(σ2

u + 1)Cov{(Xt − µ)2, (Xs − µ)(Xs+p − µ)}

t=1

s=1
t ) − E(u2

t ) − E(u2

+ β4
0

+ β4
0

(cid:8)E(u3
(cid:8)E(u3

t )(cid:9) E{(Xt − µ)3(Xt+p − µ)}
t )(cid:9) E{(Xt − µ)3(Xt−p − µ)},

= β4

0q0p(σ2

u + 1) + β4
0

(cid:8)E(u3

t ) − (σ2

u + 1)(cid:9) (cid:2)E{(Xt − µ)3(Xt+p − µ)} + E{(Xt − µ)3(Xt−p − µ)}(cid:3) ,

where the ﬁrst step is because Xt and ut are independent, and the second last step is due

(S.36)

to E(u2

t ) = V ar(ut) + E(u2

t ) = σ2

u + 1 and is derived similar to the second and third step in

(S.35), and the last step is because of the deﬁnition that q0p = limT →∞

1
T

Cov{(Xt −

µ)2, (Xs − µ)(Xs+p − µ)} and the fact that E{(Xt − µ)3(Xt+p − µ)}, E{(Xt − µ)3(Xt−p − µ)}

T
(cid:80)
t=1

T
(cid:80)
s=1

and E(u3

t ) are time-independent, derived from Conditions (R1) and (R2) together with the

independence between ut and Xt.

4. Analogous to the derivation in (S.35) and (S.36), we derive the summation of

23

Cov{utut+p(Xt − µ)(Xt+p − µ), usus+r(Xs − µ)(Xs+r − µ)} for p > 0, r > 0 and p (cid:54)= r,

β4
0 lim
T →∞

=β4

0 lim
T →∞

1
T

1
T

T
(cid:88)

T
(cid:88)

t=1
T
(cid:88)

s=1
T
(cid:88)

t=1

s=1

+ β4

0 lim
T →∞

+ β4

0 lim
T →∞

+ β4

0 lim
T →∞

+ β4

0 lim
T →∞

1
T

1
T

1
T

1
T

Cov{utut+p(Xt − µ)(Xt+p − µ), usus+r(Xs − µ)(Xs+r − µ)}

E(utut+pusus+r)Cov{(Xt − µ)(Xt+p − µ), (Xs − µ)(Xs+r − µ)}

T
(cid:88)

(cid:8)E(u2

t )E(ut+p)E(ut+r) − 1(cid:9) E{(Xt − µ)2(Xt+p − µ)(Xt+r − µ)}

t=1
s=t
T
(cid:88)

t=1
s=t+p

T
(cid:88)

t=1
s=t−r

T
(cid:88)

(cid:8)E(u2

t+p)E(ut)E(ut+p+r) − 1(cid:9) E{(Xt − µ)(Xt+p − µ)2(Xt+p+r − µ)}

(cid:8)E(u2

t )E(ut+p)E(ut−r) − 1(cid:9) E{(Xt−r − µ)(Xt − µ)2(Xt+p − µ)}

(cid:8)E(u2

t+p)E(ut)E(ut+p−r) − 1(cid:9) E{(Xt − µ)(Xt+p−r − µ)Xt+p − µ)2}

t=1
s=t+p−r

=β4

0qpr + β4

0σ2

uE{(Xt − µ)2(Xt+p − µ)(Xt+r − µ)} + β4

0σ2

uE{(Xt − µ)(Xt+p − µ)2(Xt+p+r − µ)}

+ β4

0σ2

uE{(Xt−r − µ)(Xt − µ)2(Xt+p − µ)} + β4

0σ2

uE{(Xt − µ)(Xt+p−r − µ)(Xt+p − µ)2},

where the third step is derived analogously to the second step of (S.36), and E(utut+pusus+r) =

(S.37)

1, and the last step is due to the deﬁnition qpr = limT →∞

1
T

Cov{(Xt − µ)(Xt+p −

µ), (Xs−µ)(Xs+r−µ)} and the fact that E{(Xt−µ)2(Xt+p−µ)(Xt+r−µ)}, E{(Xt−µ)(Xt+p−

T
(cid:80)
t=1

T
(cid:80)
s=1

µ)2(Xt+p+r − µ)}, E{(Xt−r − µ)(Xt − µ)2(Xt+p − µ)}, and E{(Xt − µ)(Xt+p − µ)2(Xt+2p − µ)}

are time-independent derived from Conditions (R1) and (R2).

5. Similar to the derivation in (S.35), (S.36), and (S.37), we derive the summation of

24

Cov{utut+p(Xt − µ)(Xt+p − µ), usus+p(Xs − µ)(Xs+p − µ)} for p > 0,

β4
0 lim
T →∞

1
T

= β4

0 lim
T →∞

t=1

1
T

t=1

T
(cid:88)

T
(cid:88)

Cov{utut+p(Xt − µ)(Xt+p − µ), usus+p(Xs − µ)(Xs+p − µ)}

s=1
T
(cid:88)

T
(cid:88)

E(ut)E(ut+p)E(us)E(us+p)Cov{(Xt − µ)(Xt+p − µ), (Xs − µ)(Xs+p − µ)

+ β4

0 lim
T →∞

+ β4

0 lim
T →∞

+ β4

0 lim
T →∞

1
T

1
T

1
T

s=1
T
(cid:88)

(cid:8)E(u2

t )E(u2

t+p) − 1(cid:9) Var{(Xt − µ)(Xt+p − µ)}

t=1
s=t
T
(cid:88)

t=1
s=t+p

T
(cid:88)

t=1
s=t−p

(cid:8)E(u2

t+p)E(ut)E(ut+2p) − 1(cid:9) E{(Xt − µ)(Xt+p − µ)2(Xt+2p − µ)}

(cid:8)E(u2

t )E(ut−p)E(ut+p) − 1(cid:9) E{(Xt−p − µ)(Xt − µ)2(Xt+p − µ)}

= β4

0qpp + β4

0(σ4

u + 2σ2

u)Var{(Xt − µ)(Xt+p − µ)} + 2β4

0E{(Xt − µ)(Xt+p − µ)2(Xt+2p − µ)},
(S.38)

where the last step is by the deﬁnition qpp = limT →∞

1
T

Cov{(Xt − µ)(Xt+p − µ), (Xs −

µ)(Xs+p − µ)} and E{(Xt − µ)(Xt+p − µ)2(Xt+2p − µ)} = E{(Xt−p − µ)(Xt − µ)2(Xt+p − µ)}

T
(cid:80)
t=1

T
(cid:80)
s=1

due to the stationarity of the time series and the fact that Var{(Xt − µ)(Xt+p − µ)} and

E{(Xt −µ)(Xt+p −µ)2(Xt+2p −µ)} are time-independent, resulting from the Conditions (R1)

and (R2).

6. For any t, s and p, we have that

Cov{(Xt − µ)(Xt−p − µ), (Xs − µ)}

=E{(Xt − µ)(Xt−p − µ)(Xs − µ)} − E{(Xt − µ)(Xt−p − µ)}E(Xs − µ)

=E{(Xt − µ)(Xt−p − µ)(Xs − µ)},

(S.39)

where the last step is because E(Xs − µ) = 0.

25

7. For any t and s, we have that

Cov{ut(ut − 1)(Xt − µ), us(us − 1)(Xs − µ)}

=E{ut(ut − 1)(Xt − µ)us(us − 1)(Xs − µ)} − E{ut(ut − 1)(Xt − µ)}E{us(us − 1)(Xs − µ)}

=E{ut(ut − 1)(Xt − µ)us(us − 1)(Xs − µ)}

=E{ut(ut − 1)us(us − 1)}E{(Xt − µ)(Xs − µ)},

(S.40)

where the second step is because of the independence between ut and Xt and that E(Xt−µ) =

0. Then, E{ut(ut −1)us(us −1)} = σ4

u for t (cid:54)= s and E{u2

t (ut −1)2} = E(u4

t )−2E(u3

t )+σ2

u +1

for any t.

By (S.40), we have that

lim
T →∞

= lim
T →∞

= lim
T →∞

1
T

1
T

1
T

T
(cid:88)

T
(cid:88)

t=1
T
(cid:88)

s=1
T
(cid:88)

t=1
T
(cid:88)

s=1
T
(cid:88)

t=1

s=1

Cov {ut(ut − 1)(Xt − µ), us(us − 1)(Xs − µ)}

E{ut(ut − 1)us(us − 1)}E{(Xt − µ)(Xs − µ)}

σ4
uE{(Xt − µ)(Xs − µ)} + lim
T →∞

1
T

T
(cid:88)

t=1
s=t

(cid:8)E(u4

t ) − 2E(u3

t ) + σ2

u + 1 − σ4
u

(cid:9) E{(Xt − µ)2}

=σ4
u

∞
(cid:88)

h=−∞

γh + (cid:8)E(u4

t ) − 2E(u3

t ) + σ2

u + 1 − σ4
u

(cid:9) γ0,

(S.41)

where the last is because limT →∞

(cid:80)T

t=1

1
T

et al. 1991, Theorem 7.1.1).

(cid:80)T

s=1 E{(Xt −µ)(Xs −µ)} = (cid:80)∞

h=−∞ γh (Brockwell

8. For any t, s and p > 0, we have that

Cov{ut(ut − 1)(Xt − µ), us+p(us − 1)(Xs+p − µ)}

=E{ut(ut − 1)(Xt − µ)us+p(us − 1)(Xs+p − µ)} − E{ut(ut − 1)(Xt − µ)}E{us+p(us − 1)(Xs+p − µ)}

=E{ut(ut − 1)us+p(us − 1)}E{(Xt − µ)(Xs+p − µ)}

=E{ut(ut − 1)us+p(us − 1)}γ|s+p−t|,

(S.42)

where the second step is because of the independence between ut and Xt and that E(Xt−µ) =

0. Then, E{ut(ut − 1)us+p(us − 1)} = 0 for t (cid:54)= s and E{ut(ut − 1)2ut+p} = E{ut(ut − 1)2} =

E{(ut − 1)3} + σ2

u for any s = t.

26

9. By independence of ut and us, for t (cid:54)= s, we have that

Cov{u2

t (Xt − µ)2, (us − 1)2} = 0,

(S.43)

and for any t,

Cov{u2

t (Xt − µ)2, (ut − 1)2}

=E{u2
= (cid:2)E{u2
= (cid:8)E(u4
= (cid:8)E(u4

t (ut − 1)2(Xt − µ)2} − E{u2

t (Xt − µ)2}E{(ut − 1)2}

t (ut − 1)2} − E(u2

t ) − 2E(u3

t ) + σ2

t ) − 2E(u3

t ) + 1 − σ4
u

t )E(ut − 1)2(cid:3) E{(Xt − µ)2}
(cid:9) γ0
u + 1 − σ4
(cid:9) γ0.

u − σ2
u

(S.44)

10. By independence of ut and us, for s (cid:54)= t, s (cid:54)= t + p and any p, we have that

Cov{utut+p(Xt − µ)(Xt+p − µ), (us − 1)2} = 0.

(S.45)

For any t and p > 0,

Cov{utut+p(Xt − µ)(Xt+p − µ), (ut − 1)2}

=E{utut+p(ut − 1)2(Xt − µ)(Xt+p − µ)} − E{utut+p(Xt − µ)(Xt+p − µ)}E{(ut − 1)2}
= (cid:2)E{utut+p(ut − 1)2} − E(utut+p)E{(ut − 1)2}(cid:3) E{(Xt − µ)(Xt+p − µ)}
=E (cid:8)(ut − 1)3(cid:9) γp,

(S.46)

and

Cov{utut−p(Xt − µ)(Xt−p − µ), (ut − 1)2} = E (cid:8)(ut − 1)3(cid:9) γp.

11. For any t and s, and r (cid:54)= p and r > 0, we have that

Cov{utut+p(Xt − µ)(Xt+p − µ), (us − 1)(us+r − 1)} = 0.

(S.47)

By independence of ut and us, for t (cid:54)= s and any p, we have that

Cov{utut+p(Xt − µ)(Xt+p − µ), (us − 1)(us+p − 1)} = 0,

(S.48)

27

and for any t and p > 0,

Cov{utut+p(Xt − µ)(Xt+p − µ), (ut − 1)(ut+p − 1)}

=E{utut+p(ut − 1)(tt+p − 1)(Xt − µ)(Xt+p − µ)}

− E{utut+p(Xt − µ)(Xt+p − µ)}E{(ut − 1)(ut+p − 1)}

=E{ut(ut − 1)}E{ut+p(ut+p − 1)}E{(Xt − µ)(Xt+p − µ)}

=σ4

uγp.

(S.49)

12. For any t, we have that

Cov{ut(ut − 1)(Xt − µ), (us − 1)2}

= E{ut(ut − 1)(Xt − µ)(us − 1)2} − E{ut(ut − 1)(Xt − µ)}E{(us − 1)2}
= (cid:2)E{ut(ut − 1)(us − 1)2} − E{ut(ut − 1)}E{(us − 1)2}(cid:3) E(Xt − µ) = 0,

(S.50)

where the last step is because E(Xt − µ) = 0.

13. By independence assumption between {ut}, if t (cid:54)= s or p (cid:54)= r, we have that

Cov {(ut − 1)(ut+p − 1), (us − 1)(us+r − 1)} = 0.

(S.51)

In addition, for any t and p we have that

and for any t, we have that

Var {(ut − 1)(ut+p − 1)}
= E (cid:8)(ut − 1)2(ut+p − 1)2(cid:9)
= E (cid:8)(ut − 1)2(cid:9) E (cid:8)(ut+p − 1)2(cid:9)

= σ4
u,

Var(ut − 1)2

=E{(ut − 1)4} − E2{(ut − 1)2}

=E{(ut − 1)4} − σ4
u.

28

(S.52)

(S.53)

Step 4: Now we prove the results in (3).

1◦. We ﬁrst show the derivation of q∗

200 as follows:

q∗
200 = lim
T →∞

T Cov

(cid:40)

1
T

= lim
T →∞

β4
0
T

T
(cid:88)

T
(cid:88)

t=1

s=1

T
(cid:88)

(X ∗

t − µ∗)2,

t=1

(cid:41)

(X ∗

s − µ∗)2

1
T

T
(cid:88)

s=1

Cov (cid:8)u2

t (Xt − µ)2 + 2µut(ut − 1)(Xt − µ) + µ2(ut − 1)2,

s(Xs − µ)2 + 2µus(us − 1)(Xs − µ) + µ2(us − 1)2(cid:9)
u2
β4
0
T

s(Xs − µ)2(cid:9)

t (Xt − µ)2, u2

Cov (cid:8)u2

T
(cid:88)

T
(cid:88)

= lim
T →∞

t=1
s=1
4µβ4
0
T

+ lim
T →∞

+ lim
T →∞

2µ2β4
0
T

+ lim
T →∞

4µ2β4
0
T

+ lim
T →∞

µ4β4
0
T

T
(cid:88)

T
(cid:88)

Cov (cid:8)u2

t (Xt − µ)2, us(us − 1)(Xs − µ)(cid:9)

t=1
T
(cid:88)

s=1
T
(cid:88)

t=1
T
(cid:88)

s=1
T
(cid:88)

Cov (cid:8)u2

t (Xt − µ)2, (us − 1)2(cid:9)

Cov {ut(ut − 1)(Xt − µ), us(us − 1)(Xs − µ)}

t=1
T
(cid:88)

s=1
T
(cid:88)

Cov (cid:8)(ut − 1)2, (us − 1)2(cid:9)

t=1
u + 1)2q0 + β4

s=1
0{E(u4

= β4

0(σ2

t ) − (σ2

u + 1)2}E{(Xt − µ)4}

+ 4µβ4

0σ2

u + 1)v00 + 4µβ4

0{E(u4

t ) − σ2

u(σ2

u + 1)}E{(Xt − µ)3}

+ 2µ2β4
0

u(σ2
(cid:8)E(u4
(cid:34)

t ) + 1 − σ4
u

t ) − 2E(u3
∞
(cid:88)

t ) − E(u3
(cid:9) γ0

+ 4µ2β4
0

σ4
u

γh + (cid:8)E(u4

t ) − 2E(u3

t ) + σ2

u + 1 − σ4
u

(cid:35)

(cid:9) γ0

h=−∞

+ µ4β4
0

(cid:2)E{(ut − 1)4} − σ4

u

(cid:3) ,

where the second step is due to (S.34), the third step is because of (S.50), the last step is by

(S.35), (S.39), (S.41), (S.43), (S.44), and (S.53).

29

2◦. Then we derive the value of q∗

20p:

q∗
20p = lim
T →∞

T Cov

(cid:40)

1
T

T
(cid:88)

t=1

(X ∗

t − µ∗)2,

1
T

T
(cid:88)

s=1

(X ∗

s − µ∗)(X ∗

s+p − µ∗)

(cid:41)

= lim
T →∞

β4
0
T

T
(cid:88)

T
(cid:88)

t=1

s=1

Cov (cid:8)u2

t (Xt − µ)2 + 2µut(ut − 1)(Xt − µ) + µ2(ut − 1)2,

usus+p(Xs − µ)(Xs+p − µ) + µus(us+p − 1)(Xs − µ) + µus+p(us − 1)(Xs+p − µ) + µ2(us − 1)(us+p − 1)(cid:9)

= lim
T →∞

β4
0
T

T
(cid:88)

T
(cid:88)

Cov (cid:8)u2

t (Xt − µ)2, usus+p(Xs − µ)(Xs+p − µ)(cid:9)

T
(cid:88)

T
(cid:88)

Cov (cid:8)u2

t (Xt − µ)2, us(us+p − 1)(Xs − µ) + us+p(us − 1)(Xs+p − µ)(cid:9)

s=1

t=1
µβ4
0
T

+ lim
T →∞

+ lim
T →∞

2µβ4
0
T

+ lim
T →∞

µ2β4
0
T

t=1
T
(cid:88)

s=1
T
(cid:88)

Cov {usus+p(Xs − µ)(Xs+p − µ), ut(ut − 1)(Xt − µ)}

t=1
T
(cid:88)

s=1
T
(cid:88)

t=1

s=1

(cid:2)Cov (cid:8)u2

t (Xt − µ)2, (us − 1)(us+p − 1)(cid:9)

+ Cov (cid:8)(ut − 1)2, usus+p(Xs − µ)(Xs+p − µ)(cid:9)(cid:3)

+ lim
T →∞

2µ2β4
0
T

+ lim
T →∞

2µ2β4
0
T

T
(cid:88)

T
(cid:88)

t=1
T
(cid:88)

s=1
T
(cid:88)

Cov {ut(ut − 1)(Xt − µ), us(us+p − 1)(Xs − µ)}

Cov {ut(ut − 1)(Xt − µ), us+p(us − 1)(Xs+p − µ)}

t=1
T
(cid:88)

s=1
T
(cid:88)

+ lim
T →∞

µ4β4
0
T

= β4

0q0p(σ2

t=1
u + 1) + β4
0

+ µβ4

0E{u3

t − u2

Cov (cid:8)(ut − 1)2, (us − 1)(us+p − 1)(cid:9)

s=1
(cid:8)E(u3
t } (cid:2)E{(Xt − µ)2(Xt−p − µ)} + E{(Xt − µ)2(Xt+p − µ)}(cid:3)

t ) − (σ2

u + 1)(cid:9) (cid:2)E{(Xt − µ)3(Xt+p − µ)} + E{(Xt − µ)3(Xt−p − µ)}(cid:3)

+ 2µβ4

0σ2

uv0p + 2µβ4

0E{u3

t − u2

+ 2µ2β4

0E(ut − 1)3γp + 4µ2β4
0
(cid:8)E(u3

t ) − (σ2

u + 1) + β4
0

= β4

0qp(σ2

+ 2µβ4

0σ2

uvp + µβ4

0E{3u3

t − 3u2

u} (cid:2)E{(Xt − µ)2(Xt−p − µ)} + E{(Xt − µ)2(Xt+p − µ)}(cid:3)

t − σ2
(cid:8)E(ut − 1)3 + σ2
0σ4
u
u + 1)(cid:9) (cid:2)E{(Xt − µ)3(Xt+p − µ)} + E{(Xt − µ)3(Xt−p − µ)}(cid:3)
t − 2σ2

u} (cid:2)E{(Xt − µ)2(Xt−p − µ)} + E{(Xt − µ)2(Xt+p − µ)}(cid:3)

(cid:9) γp + µ4β4

u

+ 6µ2β4

0E(ut − 1)3γp + 4µ2β4

0σ2

uγp,

where the second step is by (S.34), the third step is because (S.39) and (S.50), and the

second last step is because (S.36), (S.47), (S.46), (S.42), and (S.51).

30

3◦. Then we derive the value of q∗

2pr for r (cid:54)= p

q∗
2pr = lim
T →∞

T Cov

(cid:40)

1
T

T
(cid:88)

t=1

(X ∗

t − µ∗)(X ∗

t+p − µ∗),

(X ∗

s − µ∗)(X ∗

s+r − µ∗)

(cid:41)

1
T

T
(cid:88)

s=1

= lim
T →∞

β4
0
T

T
(cid:88)

T
(cid:88)

t=1

s=1

Cov {utut+p(Xt − µ)(Xt+p − µ)

+ µut(ut+p − 1)(Xt − µ) + µut+p(ut − 1)(Xt+p − µ) + µ2(ut − 1)(ut+p − 1),
usus+r(Xs − µ)(Xs+r − µ) + µus(us+r − 1)(Xs − µ) + µus+r(us − 1)(Xs+r − µ) + µ2(us − 1)(us+r − 1)(cid:9)

= lim
T →∞

β4
0
T

T
(cid:88)

T
(cid:88)

t=1

s=1

Cov {utut+p(Xt − µ)(Xt+p − µ), usus+r(Xs − µ)(Xs+r − µ)}

+ lim
T →∞

+ lim
T →∞

+ lim
T →∞

+ lim
T →∞

µβ4
0
T

µβ4
0
T

µβ4
0
T

µβ4
0
T

T
(cid:88)

T
(cid:88)

t=1

s=1

T
(cid:88)

T
(cid:88)

t=1

s=1

T
(cid:88)

T
(cid:88)

t=1

s=1

T
(cid:88)

T
(cid:88)

t=1

s=1

Cov {usus+r(Xs − µ)(Xs+r − µ), ut(ut+p − 1)(Xt − µ)}

Cov {usus+r(Xs − µ)(Xs+r − µ), ut+p(ut − 1)(Xt+p − µ)}

Cov {utut+p(Xt − µ)(Xt+p − µ), us(us+r − 1)(Xs − µ)}

Cov {utut+p(Xt − µ)(Xt+p − µ), us+r(us − 1)(Xs+r − µ)}

+ lim
T →∞

2µ2β4
0
T

T
(cid:88)

T
(cid:88)

t=1

s=1

Cov {utut+p(Xt − µ)(Xt+p − µ), (us − 1)(us+r − 1)}

+ lim
T →∞

+ lim
T →∞

+ lim
T →∞

+ lim
T →∞

+ lim
T →∞

µ2β4
0
T

µ2β4
0
T

µ2β4
0
T

µ2β4
0
T

µ4β4
0
T

T
(cid:88)

T
(cid:88)

t=1

s=1

T
(cid:88)

T
(cid:88)

t=1

s=1

T
(cid:88)

T
(cid:88)

t=1

s=1

T
(cid:88)

T
(cid:88)

t=1

s=1

T
(cid:88)

T
(cid:88)

t=1

s=1

Cov {ut(ut+p − 1)(Xt − µ), us(us+r − 1)(Xs − µ)}

Cov {ut(ut+p − 1)(Xt − µ), us+r(us − 1)(Xs+r − µ)}

Cov {ut+p(ut − 1)(Xt+p − µ), us(us+r − 1)(Xs − µ)}

Cov {ut+p(ut − 1)(Xt+p − µ), us+r(us − 1)(Xs+r − µ)}

Cov {(ut − 1)(ut+p − 1), (us − 1)(us+q − 1)} ,

= β4

0 σ2
u

(cid:2)E{(Xt − µ)2(Xt+p − µ)(Xt+r − µ)} + E{(Xt − µ)(Xt+p − µ)2(Xt+p+r − µ)}

0 qpr + β4
+E{(Xt−r − µ)(Xt − µ)2(Xt+p − µ)} + E{(Xt − µ)(Xt+p−r − µ)(Xt+p − µ)2}(cid:3)

+ µβ4

0 σ2

u [E{(Xt − µ)(Xt+p − µ)(Xt+r − µ)} + E{(Xt − µ)(Xt+p − µ)(Xt+p+r − µ)}

+E{(Xt−r − µ)(Xt − µ)(Xt+p − µ)} + E{(Xt − µ)(Xt+p−r − µ)(Xt+p − µ)}]

+ 2µ2β4

0 σ2

u(γ|p−r| + γp+r),

(S.54)

where the second step is by (S.34), the third step is because (S.39) and (S.50), and the

31

second last step is because (S.36), (S.47), (S.42), and (S.51).
4◦. Finally, similar to the derivation of q∗

2pq, now we derive the value of q∗

2pp

q∗
2pp = lim
T →∞

T Cov

(cid:40)

1
T

T
(cid:88)

t=1

(X ∗

t − µ∗)(X ∗

t+p − µ∗),

1
T

T
(cid:88)

s=1

(X ∗

s − µ∗)(X ∗

s+p − µ∗)

(cid:41)

= lim
T →∞

β4
0
T

T
(cid:88)

T
(cid:88)

t=1

s=1

Cov {utut+p(Xt − µ)(Xt+p − µ) + µut(ut+p − 1)(Xt − µ)

+ µut+p(ut − 1)(Xt+p − µ) + µ2(ut − 1)(ut+p − 1),
usus+r(Xs − µ)(Xs+p − µ) + µus(us+p − 1)(Xs − µ) + µus+p(us − 1)(Xs+p − µ) + µ2(us − 1)(us+p − 1)(cid:9)

= lim
T →∞

β4
0
T

T
(cid:88)

T
(cid:88)

t=1

s=1

Cov {utut+p(Xt − µ)(Xt+p − µ), usus+p(Xs − µ)(Xs+p − µ)}

+ lim
T →∞

2µ2β4
0
T

T
(cid:88)

T
(cid:88)

t=1

s=1

Cov {utut+p(Xt − µ)(Xt+p − µ), (us − 1)(us+p − 1)}

+ lim
T →∞

+ lim
T →∞

+ lim
T →∞

+ lim
T →∞

+ lim
T →∞

+ lim
T →∞

+ lim
T →∞

+ lim
T →∞

+ lim
T →∞

µβ4
0
T

µβ4
0
T

µβ4
0
T

µβ4
0
T

T
(cid:88)

T
(cid:88)

t=1

s=1

T
(cid:88)

T
(cid:88)

t=1

s=1

T
(cid:88)

T
(cid:88)

t=1

s=1

T
(cid:88)

T
(cid:88)

t=1

s=1

Cov {usus+p(Xs − µ)(Xs+p − µ), ut(ut+p − 1)(Xt − µ)}

Cov {usus+p(Xs − µ)(Xs+p − µ), ut+p(ut − 1)(Xt+p − µ)}

Cov {utut+p(Xt − µ)(Xt+p − µ), us(us+p − 1)(Xs − µ)}

Cov {utut+p(Xt − µ)(Xt+p − µ), us+p(us − 1)(Xs+p − µ)}

T
(cid:88)

T
(cid:88)

t=1

s=1

T
(cid:88)

T
(cid:88)

t=1

s=1

T
(cid:88)

T
(cid:88)

t=1

s=1

T
(cid:88)

T
(cid:88)

t=1

s=1

T
(cid:88)

T
(cid:88)

Cov {ut(ut+p − 1)(Xt − µ), us(us+p − 1)(Xs − µ)}

Cov {ut(ut+p − 1)(Xt − µ), us+p(us − 1)(Xs+p − µ)}

Cov {ut+p(ut − 1)(Xt+p − µ), us(us+p − 1)(Xs − µ)}

Cov {ut+p(ut − 1)(Xt+p − µ), us+p(us − 1)(Xs+p − µ)}

Cov {(ut − 1)(ut+p − 1), (us − 1)(us+p − 1)} ,

µ2β4
0
T

µ2β4
0
T

µ2β4
0
T

µ2β4
0
T

µ4β4
0
T

t=1
u + 2σ2

s=1
u)Var{(Xt − µ)(Xt+p − µ)} + 2β4

= β4

0 qpp + β4

+ µβ4

0 σ2
u

0 (σ4
(cid:2)E{(Xt − µ)(Xt+p − µ)2} + 2E{(Xt − µ)(Xt+p − µ)(Xt+2p − µ)} + E{(Xt − µ)2(Xt+p − µ)}(cid:3)

0 E{(Xt − µ)(Xt+p − µ)2(Xt+2p − µ)} (S.55)

+ 2µ2β4

0 σ4

uγp + 2µ2β4

0 σ2

u(γ0 + γ2p) + µ4β4

0 σ4
u,

where the second step is by (S.34), the third step is because (S.39) and (S.50), and the last

step is because (S.38), (S.48), (S.49) and (S.52).

32

B Tables

Supplementary Table 4: The results of the augmented Dickey-Fuller test

British Columbia

Ontario

Quebec

Alberta

Deﬁnition

Transformation

TSV

p-value

TSV

p-value

TSV

p-value

TSV

p-value

Deﬁnition 1

Deﬁnition 2

Deﬁnition 3

Xt

-8.346

<0.01

-1.527

0.755

Xt+1 − Xt

-6.974

<0.01

-5.522

<0.01

Xt

Xt+1 − Xt

Xt

Xt+1 − Xt

-1.208

-3.336

-1.325

-3.590

0.878

0.084

0.833

0.048

-4.294

<0.01

-2.599

-2.264

0.342

0.471

-4.584

<0.01

-1.813

-3.880

-2.018

-3.340

0.098

-2.209

0.645

0.027

0.566

0.084

0.999

0.492

-2.850

-3.516

-1.768

-3.296

-2.688

-2.008

0.245

0.059

0.662

0.090

0.307

0.569

Supplementary Table 5: The results of the augmented Dickey-Fuller test

British Columbia

Ontario

Quebec

Alberta

Deﬁnition

Diﬀerencing

lag p

Diﬀerencing

lag p

Diﬀerencing

lag p

Diﬀerencing

lag p

Deﬁnition 1

1 degree

no diﬀerencing

Deﬁnition 2

1 degree

Deﬁnition 3

1 degree

1

2

2

1

1 degree

-

no diﬀerencing

1 degree

1

-

2

4

1 degree

-

1 degree

-

1

-

2

-

1 degree

-

1 degree

-

1

-

1

-

33

)
9
(

r
o

)
7
(

l
e
d
o
m

r
o
r
r
e

t
n
e
m
e
r
u
s
a
e
m
e
h
t

r
o
f

2u
σ

r
o

2e
σ

f
o

s
e
u
l
a
v

r
e
t
e
m
a
r
a
p

e
h
T

:
6

e
l
b
a
T
y
r
a
t
n
e
m
e
l
p
p
u
S

.
s
e
s
y
l
a
n
a

y
t
i
v
i
t
i
s
n
e
s

r
o
f

d
e
s
u

e
r
a

t
a
h
t

a
t
r
e
b
l
A

c
e
b
e
u
Q

o
i
r
a
t
n
O

a
i
b
m
u
l
o
C
h
s
i
t
i
r
B

l
e
d
o
M

r
o
r
r
E

n
o
i
t
i
n
ﬁ
e
D

)
1
(
R
A

)
1
(
R
A

)
1
(
R
A

)
1
(
R
A

3
.
0

8
.
0

1
.
0

4
.
0

-

-

-

-

-

1

1

-

-

-

5
.
0

5
.
0

-

-

1

1

-

-

-

5
.
0

5
.
0

-

-

2
.
0

2
0
.
0

2
.
0

6
.
0

*
)
2
(
R
A

1
.
0

5
0
.
0

2
.
0

1
.
0

1
.
0

5
0
.
0

8
.
0

4
.
0

6
.
0

3
.
0

1
0
.
0

5
0
0
.
0

1
.
0

5
.
0

)
1
(
R
A

)
2
(
R
A

*
)
2
(
R
A

)
2
(
R
A

-

-

-

-

-

-

-

-

5
0
.
0

2
0
.
0

2
.
0

1
.
0

6
0
.
0

6
.
0

-

-

)
4
(
R
A

)
2
(
R
A

1
.
0

3
.
0

1
.
0

1
0
.
0

5
0
.
0

2
.
0

3
0
.
0

3
.
0

)
2e
σ
(

e
v
i
t
i
d
d
A

)
2u
σ
(

e
v
i
t
a
c
i
l

p
i
t
l
u
M

)
2e
σ
(

e
v
i
t
i
d
d
A

)
2u
σ
(

e
v
i
t
a
c
i
l

p
i
t
l
u
M

1

n
o
i
t
i
n
ﬁ
e
D

)
2u
σ
(

e
v
i
t
a
c
i
l

p
i
t
l
u
M

)
2e
σ
(

e
v
i
t
i
d
d
A

2

n
o
i
t
i
n
ﬁ
e
D

)
2u
σ
(

e
v
i
t
a
c
i
l

p
i
t
l
u
M

)
2e
σ
(

e
v
i
t
i
d
d
A

3

n
o
i
t
i
n
ﬁ
e
D

g
n
i
c
n
e
r
e
ﬀ
d

i

o
n

h
t
i
w
s
e
i
r
e
s

e
m

i
t

e
h
T

*

34

Supplementary Table 7: Deﬁnition 3: The parameter estimation under diﬀerent measure-

ment error models: the AR(1) model with “order-1 diﬀerencing” is used to ﬁt the data of

British Columbia and the AR(4) model with “order-1 diﬀerencing” is used to ﬁt the data of

Ontario.

Method

Error Degree

Parameter

EST

SE

p-value

EST

SE

p-value

British Columbia

Ontario

Naive

-

The Proposed Method

with Additive Error

The Proposed Method

with Multiplicative Error

Small (σ2

e1)

Large (σ2

e2)

Small (σ2

u1)

Large (σ2

u2)

φ0

φ1

φ2

φ3

φ4

φ0

φ1

φ2

φ3

φ4

φ0

φ1

φ2

φ3

φ4

φ0

φ1

φ2

φ3

φ4

φ0

φ1

φ2

φ3

φ4

0.105

0.038

-0.207

0.077

0.018

0.020

-

-

-

-

-

-

-

-

-

0.057

0.021

-0.213

0.086

0.021

0.029

-

-

-

-

-

-

-

-

-

0.058

0.021

-0.234

0.147

0.017

0.137

-

-

-

-

-

-

-

-

-

0.058

0.023

-0.244

0.090

0.027

0.019

-

-

-

-

-

-

-

-

-

0.066

0.035

-0.401

0.219

0.087

0.092

-

-

-

-

-

-

-

-

-

0.379

0.057

<0.001

-0.086

0.099

-0.287

0.106

-0.301

0.094

-0.284

0.078

0.391

0.012

0.004

0.001

0.206

0.031

<0.001

-0.088

0.100

-0.290

0.109

-0.303

0.094

-0.287

0.081

0.383

0.014

0.003

0.002

0.212

0.036

<0.001

-0.102

0.123

-0.306

0.139

-0.318

0.107

-0.308

0.093

0.417

0.037

0.006

0.003

0.210

0.033

<0.001

-0.097

0.107

-0.300

0.117

-0.312

0.098

-0.300

0.087

0.230

0.058

-0.139

0.183

-0.347

0.213

-0.354

0.159

-0.361

0.149

0.375

0.016

0.004

0.002

0.001

0.454

0.116

0.035

0.023

35

y
t
i
l
a
t
r
o
m
e
u
r
t

e
h
t

f
o

g
n
i
t
s
a
c
e
r
o
f

y
a
d
-
5
A

:
)
g
n
i
c
n
e
r
e
ﬀ
i
d

o
n

,
)
2
(
R
A
(

1

n
o
i
t
i
n
ﬁ
e
D
y
b

a
i
b
m
u
l
o
C
h
s
i
t
i
r
B

:
4

e
r
u
g
i
F

y
r
a
t
n
e
m
e
l
p
p
u
S

e
h
t

;
)
w
o
l
l
e
y

k
r
a
d

n
i
(

l
e
d
o
m
e
v
i
a
n

e
h
t

s
u
s
r
e
v

)
d
e
r

n
i
(

e
v
i
t
a
c
i
l
p
i
t
l
u
m

r
o

)
e
u
l
b

n
i
(

e
v
i
t
i
d
d
a

e
h
t

n
o

d
e
s
a
b

)
9

y
a
M

-

5

y
a
M

(

e
t
a
r

.
)
n
e
e
r
g

n
i
(

s
e
s
a
c

c
i
t
a
m
o
t
p
m
y
s
a

e
h
t

r
o
f

g
n
i
t
n
u
o
c
c
a

e
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

d
e
t
s
u
j
d
a

e
h
t

d
n
a

)
k
c
a
l
b

n
i
(

s
e
t
a
r

y
t
i
l
a
t
r
o
m
d
e
t
r
o
p
e
r

36

AdditiveMultiplicativeMildModerateApr 13Apr 20Apr 27May 04Apr 13Apr 20Apr 27May 040246802468DayFatality Rate (%)Reference Time SeriesAdjusted FatalityFitted FatalityReported FatalityMeasurement Error TypeAdditiveMultiplicativeNaive95% Prediction IntervalAdditiveMultiplicativee
u
r
t

e
h
t

f
o

g
n

i
t
s
a
c
e
r
o
f

y
a
d
-
5

A

:
)
g
n
i
c
n
e
r
e
ﬀ
i
d

1
-
r
e
d
r
o

,
)
1
(
R
A
(

1

n
o
i
t
i
n
ﬁ
e
D

y
b

a
i
b
m
u
l
o
C

h
s
i
t
i
r
B

:
5

e
r
u
g
i
F

y
r
a
t
n
e
m
e
l
p
p
u
S

;
)
w
o
l
l
e
y

k
r
a
d
n
i
(

l
e
d
o
m
e
v
i
a
n

e
h
t

s
u
s
r
e
v

)
d
e
r

n
i
(

e
v
i
t
a
c
i
l
p
i
t
l
u
m

r
o

)
e
u
l
b

n
i
(

e
v
i
t
i
d
d
a

e
h
t

n
o

d
e
s
a
b

)
9

y
a
M

-

5

y
a
M

(

e
t
a
r

y
t
i
l
a
t
r
o
m

.
)
n
e
e
r
g

n

i
(

s
e
s
a
c

c
i
t
a
m
o
t
p
m
y
s
a

e
h
t

r
o
f

g
n
i
t
n
u
o
c
c
a

e
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

d
e
t
s
u
j
d
a

e
h
t

d
n
a

)
k
c
a
l
b

n
i
(

s
e
t
a
r

y
t
i
l
a
t
r
o
m
d
e
t
r
o
p
e
r

e
h
t

37

AdditiveMultiplicativeMildModerateApr 13Apr 20Apr 27May 04Apr 13Apr 20Apr 27May 0402460246DayFatality Rate (%)Reference Time SeriesAdjusted FatalityFitted FatalityReported FatalityMeasurement Error TypeAdditiveMultiplicativeNaive95% Prediction IntervalAdditiveMultiplicativee
u
r
t

e
h
t

f
o

g
n

i
t
s
a
c
e
r
o
f

y
a
d
-
5

A

:
)
g
n
i
c
n
e
r
e
ﬀ
i
d

1
-
r
e
d
r
o

,
)
3
(
R
A
(

2

n
o
i
t
i
n
ﬁ
e
D

y
b

a
i
b
m
u
l
o
C

h
s
i
t
i
r
B

:
6

e
r
u
g
i
F

y
r
a
t
n
e
m
e
l
p
p
u
S

;
)
w
o
l
l
e
y

k
r
a
d
n
i
(

l
e
d
o
m
e
v
i
a
n

e
h
t

s
u
s
r
e
v

)
d
e
r

n
i
(

e
v
i
t
a
c
i
l
p
i
t
l
u
m

r
o

)
e
u
l
b

n
i
(

e
v
i
t
i
d
d
a

e
h
t

n
o

d
e
s
a
b

)
9

y
a
M

-

5

y
a
M

(

e
t
a
r

y
t
i
l
a
t
r
o
m

.
)
n
e
e
r
g

n

i
(

s
e
s
a
c

c
i
t
a
m
o
t
p
m
y
s
a

e
h
t

r
o
f

g
n
i
t
n
u
o
c
c
a

e
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

d
e
t
s
u
j
d
a

e
h
t

d
n
a

)
k
c
a
l
b

n
i
(

s
e
t
a
r

y
t
i
l
a
t
r
o
m
d
e
t
r
o
p
e
r

e
h
t

38

AdditiveMultiplicativeMildModerateApr 13Apr 20Apr 27May 04Apr 13Apr 20Apr 27May 04123456123456DayFatality Rate (%)Reference Time SeriesAdjusted FatalityFitted FatalityReported FatalityMeasurement Error TypeAdditiveMultiplicativeNaive95% Prediction IntervalAdditiveMultiplicativee
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

e
h
t

f
o

g
n
i
t
s
a
c
e
r
o
f

y
a
d
-
5
A

:
)
g
n
i
c
n
e
r
e
ﬀ
i
d

1
-
r
e
d
r
o

,
)
1
(
R
A
(

1

n
o
i
t
i
n
ﬁ
e
D
y
b

o
i
r
a
t
n
O

:
7

e
r
u
g
i
F

y
r
a
t
n
e
m
e
l
p
p
u
S

d
e
t
r
o
p
e
r

e
h
t

;
)
w
o
l
l
e
y

k
r
a
d

n
i
(

l
e
d
o
m
e
v
i
a
n

e
h
t

s
u
s
r
e
v

)
d
e
r

n
i
(

e
v
i
t
a
c
i
l
p
i
t
l
u
m

r
o

)
e
u
l
b

n
i
(

e
v
i
t
i
d
d
a

e
h
t

n
o

d
e
s
a
b

)
9

y
a
M

-

5

y
a
M

(

.
)
n
e
e
r
g

n
i
(

s
e
s
a
c

c
i
t
a
m
o
t
p
m
y
s
a

e
h
t

r
o
f

g
n
i
t
n
u
o
c
c
a

e
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

d
e
t
s
u
j
d
a

e
h
t

d
n
a

)
k
c
a
l
b

n
i
(

s
e
t
a
r

y
t
i
l
a
t
r
o
m

39

AdditiveMultiplicativeMildModerateApr 13Apr 20Apr 27May 04Apr 13Apr 20Apr 27May 04−100102001020DayFatality Rate (%)Reference Time SeriesAdjusted FatalityFitted FatalityReported FatalityMeasurement Error TypeAdditiveMultiplicativeNaive95% Prediction IntervalAdditiveMultiplicativey
a
M

(

e
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

e
h
t

f
o

g
n
i
t
s
a
c
e
r
o
f

y
a
d
-
5
A

:
)
g
n
i
c
n
e
r
e
ﬀ
i
d

o
n

,
)
1
(
R
A
(

2

n
o
i
t
i
n
ﬁ
e
D
y
b

o
i
r
a
t
n
O

:
8

e
r
u
g
i
F
y
r
a
t
n
e
m
e
l
p
p
u
S

d
e
t
r
o
p
e
r

e
h
t

;
)
w
o
l
l
e
y

k
r
a
d

n
i
(

l
e
d
o
m

e
v
i
a
n

e
h
t

s
u
s
r
e
v

)
d
e
r

n
i
(

e
v
i
t
a
c
i
l
p
i
t
l
u
m

r
o

)
e
u
l
b

n
i
(

e
v
i
t
i
d
d
a

e
h
t

n
o

d
e
s
a
b

)
9

y
a
M

-

5

.
)
n
e
e
r
g

n
i
(

s
e
s
a
c

c
i
t
a
m
o
t
p
m
y
s
a

e
h
t

r
o
f

g
n
i
t
n
u
o
c
c
a

e
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

d
e
t
s
u
j
d
a

e
h
t

d
n
a

)
k
c
a
l
b

n
i
(

s
e
t
a
r

y
t
i
l
a
t
r
o
m

40

AdditiveMultiplicativeMildModerateApr 13Apr 20Apr 27May 04Apr 13Apr 20Apr 27May 04246810246810DayFatality Rate (%)Reference Time SeriesAdjusted FatalityFitted FatalityReported FatalityMeasurement Error TypeAdditiveMultiplicativeNaive95% Prediction IntervalAdditiveMultiplicativee
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

e
h
t

f
o

g
n
i
t
s
a
c
e
r
o
f

y
a
d
-
5
A

:
)
g
n
i
c
n
e
r
e
ﬀ
i
d

1
-
r
e
d
r
o

,
)
1
(
R
A
(

1

n
o
i
t
i
n
ﬁ
e
D
y
b

c
e
b
e
u
Q

:
9

e
r
u
g
i
F

y
r
a
t
n
e
m
e
l
p
p
u
S

d
e
t
r
o
p
e
r

e
h
t

;
)
w
o
l
l
e
y

k
r
a
d

n
i
(

l
e
d
o
m
e
v
i
a
n

e
h
t

s
u
s
r
e
v

)
d
e
r

n
i
(

e
v
i
t
a
c
i
l
p
i
t
l
u
m

r
o

)
e
u
l
b

n
i
(

e
v
i
t
i
d
d
a

e
h
t

n
o

d
e
s
a
b

)
9

y
a
M

-

5

y
a
M

(

.
)
n
e
e
r
g

n
i
(

s
e
s
a
c

c
i
t
a
m
o
t
p
m
y
s
a

e
h
t

r
o
f

g
n
i
t
n
u
o
c
c
a

e
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

d
e
t
s
u
j
d
a

e
h
t

d
n
a

)
k
c
a
l
b

n
i
(

s
e
t
a
r

y
t
i
l
a
t
r
o
m

41

AdditiveMultiplicativeMildModerateApr 13Apr 20Apr 27May 04Apr 13Apr 20Apr 27May 04010051015DayFatality Rate (%)Reference Time SeriesAdjusted FatalityFitted FatalityReported FatalityMeasurement Error TypeAdditiveMultiplicativeNaive95% Prediction IntervalAdditiveMultiplicativee
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

e
h
t

f
o

g
n
i
t
s
a
c
e
r
o
f

y
a
d
-
5
A

:
)
g
n
i
c
n
e
r
e
ﬀ
i
d

1
-
r
e
d
r
o

,
)
2
(
R
A
(

2

n
o
i
t
i
n
ﬁ
e
D
y
b

c
e
b
e
u
Q

:
0
1

e
r
u
g
i
F
y
r
a
t
n
e
m
e
l
p
p
u
S

d
e
t
r
o
p
e
r

e
h
t

;
)
w
o
l
l
e
y

k
r
a
d

n
i
(

l
e
d
o
m
e
v
i
a
n

e
h
t

s
u
s
r
e
v

)
d
e
r

n
i
(

e
v
i
t
a
c
i
l
p
i
t
l
u
m

r
o

)
e
u
l
b

n
i
(

e
v
i
t
i
d
d
a

e
h
t

n
o

d
e
s
a
b

)
9

y
a
M

-

5

y
a
M

(

.
)
n
e
e
r
g

n
i
(

s
e
s
a
c

c
i
t
a
m
o
t
p
m
y
s
a

e
h
t

r
o
f

g
n
i
t
n
u
o
c
c
a

e
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

d
e
t
s
u
j
d
a

e
h
t

d
n
a

)
k
c
a
l
b

n
i
(

s
e
t
a
r

y
t
i
l
a
t
r
o
m

42

AdditiveMultiplicativeMildModerateApr 13Apr 20Apr 27May 04Apr 13Apr 20Apr 27May 042.55.07.510.0246810DayFatality Rate (%)Reference Time SeriesAdjusted FatalityFitted FatalityReported FatalityMeasurement Error TypeAdditiveMultiplicativeNaive95% Prediction IntervalAdditiveMultiplicativee
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

e
h
t

f
o

g
n

i
t
s
a
c
e
r
o
f

y
a
d
-
5
A

:
)
g
n
i
c
n
e
r
e
ﬀ
i
d

1
-
r
e
d
r
o

,
)
1
(
R
A
(

1

n
o
i
t
i
n
ﬁ
e
D
y
b

a
t
r
e
b
l
A

:
1
1

e
r
u
g
i
F
y
r
a
t
n
e
m
e
l
p
p
u
S

d
e
t
r
o
p
e
r

e
h
t

;
)
w
o
l
l
e
y

k
r
a
d

n
i
(

l
e
d
o
m
e
v
i
a
n

e
h
t

s
u
s
r
e
v

)
d
e
r

n
i
(

e
v
i
t
a
c
i
l
p
i
t
l
u
m

r
o

)
e
u
l
b

n
i
(

e
v
i
t
i
d
d
a

e
h
t

n
o

d
e
s
a
b

)
9

y
a
M

-

5

y
a
M

(

.
)
n
e
e
r
g

n
i
(

s
e
s
a
c

c
i
t
a
m
o
t
p
m
y
s
a

e
h
t

r
o
f

g
n
i
t
n
u
o
c
c
a

e
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

d
e
t
s
u
j
d
a

e
h
t

d
n
a

)
k
c
a
l
b

n
i
(

s
e
t
a
r

y
t
i
l
a
t
r
o
m

43

AdditiveMultiplicativeMildModerateApr 13Apr 20Apr 27May 04Apr 13Apr 20Apr 27May 0402460246DayFatality Rate (%)Reference Time SeriesAdjusted FatalityFitted FatalityReported FatalityMeasurement Error TypeAdditiveMultiplicativeNaive95% Prediction IntervalAdditiveMultiplicativee
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

e
h
t

f
o

g
n

i
t
s
a
c
e
r
o
f

y
a
d
-
5
A

:
)
g
n
i
c
n
e
r
e
ﬀ
i
d

1
-
r
e
d
r
o

,
)
1
(
R
A
(

2

n
o
i
t
i
n
ﬁ
e
D
y
b

a
t
r
e
b
l
A

:
2
1

e
r
u
g
i
F
y
r
a
t
n
e
m
e
l
p
p
u
S

d
e
t
r
o
p
e
r

e
h
t

;
)
w
o
l
l
e
y

k
r
a
d

n
i
(

l
e
d
o
m
e
v
i
a
n

e
h
t

s
u
s
r
e
v

)
d
e
r

n
i
(

e
v
i
t
a
c
i
l
p
i
t
l
u
m

r
o

)
e
u
l
b

n
i
(

e
v
i
t
i
d
d
a

e
h
t

n
o

d
e
s
a
b

)
9

y
a
M

-

5

y
a
M

(

.
)
n
e
e
r
g

n
i
(

s
e
s
a
c

c
i
t
a
m
o
t
p
m
y
s
a

e
h
t

r
o
f

g
n
i
t
n
u
o
c
c
a

e
t
a
r

y
t
i
l
a
t
r
o
m
e
u
r
t

d
e
t
s
u
j
d
a

e
h
t

d
n
a

)
k
c
a
l
b

n
i
(

s
e
t
a
r

y
t
i
l
a
t
r
o
m

44

AdditiveMultiplicativeMildModerateApr 13Apr 20Apr 27May 04Apr 13Apr 20Apr 27May 040123401234DayFatality Rate (%)Reference Time SeriesAdjusted FatalityFitted FatalityReported FatalityMeasurement Error TypeAdditiveMultiplicativeNaive95% Prediction IntervalAdditiveMultiplicativet
n
e
r
e
ﬀ
i
d

r
o
f

r
o
r
r
e

n
o
i
t
c
i
d
e
r
p

d
e
t
c
e
p
x
e

d
n
a

r
o
r
r
e

n
o
i
t
c
i
d
e
r
p

d
e
v
r
e
s
b
o

e
h
T

:
1

n
o
i
t
i
n
ﬁ
e
D

:
8

e
l
b
a
T

y
r
a
t
n
e
m
e
l
p
p
u
S

.
s
e
t
a
r

h
t
a
e
d

f
o

n
o
i
t
i
n
ﬁ
e
d

r
o
r
r
E

n
o
i
t
c
i
d
e
r
P

d
e
t
c
e
p
x
E

r
o
r
r
E

n
o
i
t
c
i
d
e
r
P

d
e
v
r
e
s
b
O

)
h
(
E
P
E
1
=
Hh
(cid:80)

5

y
a
D

4

y
a
D

3

y
a
D

2

y
a
D

1

y
a
D

1

n
o
i
t
i
n
ﬁ
e
D

)
h
(
E
P
O
1
=
Hh
(cid:80)

5

y
a
D

4

y
a
D

3

y
a
D

2

y
a
D

1

y
a
D

)
2u
σ

r
o
(

2e
σ

d
o
h
t
e
M

6
9
3
.
0

2
8
3
.
0

2
4
3
.
0

1
1
1
.
0

0
9
0
.
0

1
9
9
.
8

3
8
9
.
8

3
6
9
.
8

5
5
6
.
2

9
7
8
.
2

7
5
0
.
9

7
0
8
.
7

7
5
0
.
4

5
9
9
.
1

5
2
0
.
1

7
2
6
.
0

7
7
5
.
0

7
7
1
.
0

7
5
1
.
0

9
0
1
.
0

3
8
0
.
0

2
8
0
.
0

1
8
0
.
0

1
8
0
.
0

9
6
0
.
0

0
8
0
.
0

0
8
0
.
0

8
7
0
.
0

8
7
0
.
0

6
6
0
.
0

3
7
0
.
0

2
7
0
.
0

0
7
0
.
0

0
7
0
.
0

7
5
0
.
0

3
2
0
.
0

3
2
0
.
0

3
2
0
.
0

3
2
0
.
0

0
2
0
.
0

9
1
0
.
0

9
1
0
.
0

8
1
0
.
0

9
1
0
.
0

5
1
0
.
0

8
7
1
.
0

8
7
0
.
0

0
8
0
.
0

8
7
0
.
0

3
8
0
.
0

1
8
0
.
0

8
5
0
.
0

7
1
0
.
0

6
0
0
.
0

7
1
0
.
0

-

e
v
i
a
N

5
3
0
.
0

7
2
0
.
0

5
0
0
.
0

1
0
0
.
0

1
1
0
.
0

d
l
i

M

5
3
0
.
0

7
2
0
.
0

5
0
0
.
0

1
0
0
.
0

1
1
0
.
0

d
l
i

M

6
3
0
.
0

7
2
0
.
0

5
0
0
.
0

1
0
0
.
0

2
1
0
.
0

e
t
a
r
e
d
o
M

7
3
0
.
0

9
2
0
.
0

4
0
0
.
0

1
0
0
.
0

3
1
0
.
0

e
t
a
r
e
d
o
M

e
v
i
t
i
d
d
A

e
v
i
t
a
c
i
l
p
i
t
l
u
M

a
i
b
m
u
l
o
C
h
s
i
t
i
r
B

4
1
5
.
2

2
7
3
.
2

8
4
0
.
2

6
4
4
.
1

2
1
6
.
0

0
4
9
.
2
1

4
6
2
.
8

0
6
3
.
0

9
0
4
.
3

7
7
0
.
0

0
3
8
.
0

-

e
v
i
a
N

o
i
r
a
t
n
O

7
1
5
.
2

3
7
3
.
2

6
4
0
.
2

0
4
4
.
1

7
0
6
.
0

1
3
5
.
2

8
7
3
.
2

0
4
0
.
2

2
2
4
.
1

1
9
5
.
0

4
5
7
.
0

4
0
7
.
0

2
0
6
.
0

0
2
4
.
0

6
7
1
.
0

8
8
8
.
0

5
7
7
.
0

0
3
6
.
0

8
1
4
.
0

9
6
1
.
0

1
1
8
.
1

1
1
8
.
1

1
1
8
.
1

1
1
8
.
1

1
1
8
.
1

1
6
5
.
1

1
6
5
.
1

1
6
5
.
1

1
6
5
.
1

1
6
5
.
1

1
1
8
.
0

1
1
8
.
0

1
1
8
.
0

1
1
8
.
0

1
1
8
.
0

9
9
3
.
0

9
9
3
.
0

9
9
3
.
0

9
9
3
.
0

9
9
3
.
0

5
0
2
.
0

5
0
2
.
0

5
0
2
.
0

5
0
2
.
0

5
0
2
.
0

5
2
1
.
0

5
2
1
.
0

5
2
1
.
0

5
2
1
.
0

5
2
1
.
0

5
1
1
.
0

5
1
1
.
0

5
1
1
.
0

5
1
1
.
0

5
1
1
.
0

5
3
0
.
0

5
3
0
.
0

5
3
0
.
0

5
3
0
.
0

5
3
0
.
0

1
3
0
.
0

1
3
0
.
0

1
3
0
.
0

1
3
0
.
0

1
3
0
.
0

2
2
0
.
0

2
2
0
.
0

2
2
0
.
0

2
2
0
.
0

2
2
0
.
0

8
8
2
.
0

4
0
3
.
0

2
0
3
.
0

9
8
3
.
0

9
0
7
.
7

7
8
5
.
2

0
8
5
.
2

6
8
5
.
2

8
7
5
.
2

0
6
1
.
0

2
6
2
.
0

2
0
3
.
0

3
6
2
.
0

0
7
2
.
0

4
0
0
.
0

1
6
1
.
0

2
0
0
.
0

6
1
1
.
0

4
0
0
.
0

d
l
i

M

7
0
0
.
0

1
7
1
.
0

1
0
0
.
0

9
1
1
.
0

4
0
0
.
0

d
l
i

M

7
0
0
.
0

2
7
1
.
0

1
0
0
.
0

9
1
1
.
0

4
0
0
.
0

e
t
a
r
e
d
o
M

9
2
0
.
0

5
2
2
.
0

0
0
0
.
0

2
3
1
.
0

3
0
0
.
0

e
t
a
r
e
d
o
M

e
v
i
t
i
d
d
A

e
v
i
t
a
c
i
l
p
i
t
l
u
M

c
e
b
e
u
Q

4
9
2
.
3

9
8
2
.
2

7
5
3
.
1

7
0
6
.
0

3
6
1
.
0

-

e
v
i
a
N

3
5
0
.
1

8
7
7
.
0

9
7
4
.
0

6
1
2
.
0

1
6
0
.
0

d
l
i

M

1
5
0
.
1

6
7
7
.
0

8
7
4
.
0

5
1
2
.
0

0
6
0
.
0

e
t
a
r
e
d
o
M

3
5
0
.
1

8
7
7
.
0

9
7
4
.
0

6
1
2
.
0

1
6
0
.
0

d
l
i

M

0
5
0
.
1

6
7
7
.
0

7
7
4
.
0

5
1
2
.
0

0
6
0
.
0

e
t
a
r
e
d
o
M

e
v
i
t
i
d
d
A

e
v
i
t
a
c
i
l
p
i
t
l
u
M

a
t
r
e
b
l
A

0
7
0
.
0

5
5
0
.
0

7
2
0
.
0

7
0
0
.
0

2
0
0
.
0

-

e
v
i
a
N

5
1
1
.
0

7
8
0
.
0

4
4
0
.
0

2
1
0
.
0

4
0
0
.
0

d
l
i

M

9
2
1
.
0

8
9
0
.
0

2
5
0
.
0

7
1
0
.
0

6
0
0
.
0

e
t
a
r
e
d
o
M

5
1
1
.
0

7
8
0
.
0

4
4
0
.
0

2
1
0
.
0

4
0
0
.
0

d
l
i

M

8
1
1
.
0

9
8
0
.
0

5
4
0
.
0

3
1
0
.
0

5
0
0
.
0

e
t
a
r
e
d
o
M

e
v
i
t
i
d
d
A

e
v
i
t
a
c
i
l
p
i
t
l
u
M

45

t
n
e
r
e
ﬀ
i
d

r
o
f

r
o
r
r
e

n
o
i
t
c
i
d
e
r
p

d
e
t
c
e
p
x
e

d
n
a

r
o
r
r
e

n
o
i
t
c
i
d
e
r
p

d
e
v
r
e
s
b
o

e
h
T

:
2

n
o
i
t
i
n
ﬁ
e
D

:
9

e
l
b
a
T

y
r
a
t
n
e
m
e
l
p
p
u
S

.
s
e
t
a
r

h
t
a
e
d

f
o

n
o
i
t
i
n
ﬁ
e
d

r
o
r
r
E

n
o
i
t
c
i
d
e
r
P

d
e
t
c
e
p
x
E

r
o
r
r
E

n
o
i
t
c
i
d
e
r
P

d
e
v
r
e
s
b
O

)
h
(
E
P
E
1
=
Hh
(cid:80)

5

y
a
D

4

y
a
D

3

y
a
D

2

y
a
D

1

y
a
D

2

n
o
i
t
i
n
ﬁ
e
D

)
h
(
E
P
O
1
=
Hh
(cid:80)

5

y
a
D

4

y
a
D

3

y
a
D

2

y
a
D

1

y
a
D

)
2u
σ

r
o
(

2e
σ

d
o
h
t
e
M

4
3
8
.
0

3
8
7
.
0

4
8
7
.
0

2
2
2
.
0

4
7
1
.
0

7
1
1
.
3
1

3
5
8
.
1
1

3
2
0
.
8

5
6
9
.
2

2
4
6
.
1

6
2
9
.
0

4
7
8
.
0

6
1
7
.
0

6
3
2
.
0

2
6
1
.
0

6
3
2
.
0

3
2
2
.
0

5
8
1
.
0

9
5
0
.
0

2
4
0
.
0

7
6
1
.
0

7
6
1
.
0

7
6
1
.
0

7
6
1
.
0

4
6
1
.
0

7
5
1
.
0

7
5
1
.
0

7
5
1
.
0

7
5
1
.
0

4
5
1
.
0

7
5
1
.
0

7
5
1
.
0

7
5
1
.
0

7
5
1
.
0

4
5
1
.
0

4
4
0
.
0

4
4
0
.
0

4
4
0
.
0

4
4
0
.
0

4
4
0
.
0

5
3
0
.
0

5
3
0
.
0

5
3
0
.
0

5
3
0
.
0

4
3
0
.
0

9
4
6
.
2

9
4
6
.
2

9
4
6
.
2

3
4
6
.
2

7
2
5
.
2

9
9
3
.
2

9
9
3
.
2

9
9
3
.
2

1
9
3
.
2

4
6
2
.
2

9
4
6
.
1

9
4
6
.
1

6
4
6
.
1

6
2
6
.
1

3
5
4
.
1

3
0
6
.
0

3
0
6
.
0

3
0
6
.
0

9
9
5
.
0

8
5
5
.
0

8
4
3
.
0

8
4
3
.
0

5
4
3
.
0

1
3
3
.
0

0
7
2
.
0

3
9
1
.
0

2
9
1
.
0

1
9
1
.
0

6
7
1
.
0

4
7
1
.
0

3
8
1
.
0

2
8
1
.
0

1
8
1
.
0

5
6
1
.
0

3
6
1
.
0

3
5
1
.
0

1
5
1
.
0

9
4
1
.
0

3
3
1
.
0

0
3
1
.
0

0
5
0
.
0

9
4
0
.
0

9
4
0
.
0

5
4
0
.
0

4
4
0
.
0

4
3
0
.
0

4
3
0
.
0

3
3
0
.
0

0
3
0
.
0

0
3
0
.
0

7
4
0
.
0

7
4
0
.
0

7
4
0
.
0

7
4
0
.
0

7
4
0
.
0

5
4
0
.
0

5
4
0
.
0

5
4
0
.
0

5
4
0
.
0

4
4
0
.
0

7
3
0
.
0

7
3
0
.
0

7
3
0
.
0

7
3
0
.
0

6
3
0
.
0

2
1
0
.
0

2
1
0
.
0

2
1
0
.
0

2
1
0
.
0

2
1
0
.
0

8
0
0
.
0

8
0
0
.
0

8
0
0
.
0

8
0
0
.
0

8
0
0
.
0

6
2
1
.
0

7
3
0
.
0

7
3
0
.
0

7
3
0
.
0

7
3
0
.
0

4
8
8
.
1

3
4
2
.
0

4
3
1
.
0

1
0
2
.
0

3
6
0
.
0

9
3
7
.
0

1
8
0
.
0

7
8
0
.
0

4
8
0
.
0

8
9
0
.
0

9
1
0
.
0

1
3
0
.
0

1
3
0
.
0

1
3
0
.
0

0
3
0
.
0

a
i
b
m
u
l
o
C
h
s
i
t
i
r
B

0
2
0
.
0

3
4
0
.
0

2
3
0
.
0

5
1
0
.
0

5
1
0
.
0

-

e
v
i
a
N

0
0
0
.
0

1
1
0
.
0

1
1
0
.
0

5
0
0
.
0

0
1
0
.
0

d
l
i

M

0
0
0
.
0

1
1
0
.
0

1
1
0
.
0

5
0
0
.
0

0
1
0
.
0

d
l
i

M

0
0
0
.
0

1
1
0
.
0

1
1
0
.
0

5
0
0
.
0

0
1
0
.
0

e
t
a
r
e
d
o
M

0
0
0
.
0

1
1
0
.
0

1
1
0
.
0

5
0
0
.
0

0
1
0
.
0

e
t
a
r
e
d
o
M

e
v
i
t
i
d
d
A

e
v
i
t
a
c
i
l
p
i
t
l
u
M

o
i
r
a
t
n
O

9
5
0
.
1

1
2
5
.
0

6
9
1
.
0

7
8
0
.
0

0
2
0
.
0

-

e
v
i
a
N

5
7
1
.
0

6
5
0
.
0

7
0
0
.
0

4
0
0
.
0

1
0
0
.
0

d
l
i

M

2
5
1
.
0

4
4
0
.
0

3
0
0
.
0

2
0
0
.
0

0
0
0
.
0

d
l
i

M

0
1
1
.
0

3
2
0
.
0

0
0
0
.
0

0
0
0
.
0

0
0
0
.
0

e
t
a
r
e
d
o
M

5
3
0
.
0

0
0
0
.
0

4
1
0
.
0

0
1
0
.
0

4
0
0
.
0

e
t
a
r
e
d
o
M

e
v
i
t
i
d
d
A

e
v
i
t
a
c
i
l
p
i
t
l
u
M

3
1
4
.
0

3
8
1
.
0

6
8
0
.
0

4
4
0
.
0

3
1
0
.
0

-

e
v
i
a
N

5
6
0
.
0

3
1
0
.
0

3
0
0
.
0

1
0
0
.
0

0
0
0
.
0

d
l
i

M

8
6
0
.
0

4
1
0
.
0

3
0
0
.
0

2
0
0
.
0

0
0
0
.
0

e
t
a
r
e
d
o
M

6
6
0
.
0

3
1
0
.
0

3
0
0
.
0

2
0
0
.
0

0
0
0
.
0

d
l
i

M

3
7
0
.
0

7
1
0
.
0

4
0
0
.
0

3
0
0
.
0

2
0
0
.
0

e
t
a
r
e
d
o
M

e
v
i
t
i
d
d
A

e
v
i
t
a
c
i
l
p
i
t
l
u
M

a
t
r
e
b
l
A

2
1
0
.
0

3
0
0
.
0

2
0
0
.
0

0
0
0
.
0

1
0
0
.
0

-

e
v
i
a
N

9
1
0
.
0

7
0
0
.
0

3
0
0
.
0

1
0
0
.
0

1
0
0
.
0

d
l
i

M

9
1
0
.
0

6
0
0
.
0

3
0
0
.
0

1
0
0
.
0

1
0
0
.
0

e
t
a
r
e
d
o
M

9
1
0
.
0

6
0
0
.
0

3
0
0
.
0

1
0
0
.
0

1
0
0
.
0

d
l
i

M

9
1
0
.
0

6
0
0
.
0

3
0
0
.
0

1
0
0
.
0

1
0
0
.
0

e
t
a
r
e
d
o
M

e
v
i
t
i
d
d
A

e
v
i
t
a
c
i
l
p
i
t
l
u
M

c
e
b
e
u
Q

46

t
n
e
r
e
ﬀ
i
d

r
o
f

r
o
r
r
e

n
o
i
t
c
i
d
e
r
p

d
e
t
c
e
p
x
e

d
n
a

r
o
r
r
e

n
o
i
t
c
i
d
e
r
p

d
e
v
r
e
s
b
o

e
h
T

:
3

n
o
i
t
i
n
ﬁ
e
D

:
0
1

e
l
b
a
T

y
r
a
t
n
e
m
e
l
p
p
u
S

.
s
e
t
a
r

h
t
a
e
d

f
o

n
o
i
t
i
n
ﬁ
e
d

r
o
r
r
E

n
o
i
t
c
i
d
e
r
P

d
e
t
c
e
p
x
E

r
o
r
r
E

n
o
i
t
c
i
d
e
r
P

d
e
v
r
e
s
b
O

)
h
(
E
P
E
1
=
Hh
(cid:80)

5

y
a
D

4

y
a
D

3

y
a
D

2

y
a
D

1

y
a
D

3

n
o
i
t
i
n
ﬁ
e
D

)
h
(
E
P
O
1
=
Hh
(cid:80)

5

y
a
D

4

y
a
D

3

y
a
D

2

y
a
D

1

y
a
D

)
2u
σ

r
o
(

2e
σ

d
o
h
t
e
M

5
5
1
.
0

1
5
1
.
0

7
3
1
.
0

8
3
0
.
0

3
2
0
.
0

2
0
2
.
0

0
0
2
.
0

7
8
1
.
0

6
5
0
.
0

8
4
0
.
0

1
3
0
.
0

1
3
0
.
0

1
3
0
.
0

1
3
0
.
0

0
3
0
.
0

0
3
0
.
0

0
3
0
.
0

0
3
0
.
0

0
3
0
.
0

9
2
0
.
0

8
2
0
.
0

8
2
0
.
0

8
2
0
.
0

8
2
0
.
0

6
2
0
.
0

8
0
0
.
0

8
0
0
.
0

8
0
0
.
0

8
0
0
.
0

7
0
0
.
0

5
0
0
.
0

5
0
0
.
0

5
0
0
.
0

5
0
0
.
0

5
0
0
.
0

2
4
0
.
0

2
4
0
.
0

9
3
0
.
0

9
3
0
.
0

9
3
0
.
0

2
4
0
.
0

2
4
0
.
0

9
3
0
.
0

9
3
0
.
0

9
3
0
.
0

9
3
0
.
0

9
3
0
.
0

6
3
0
.
0

6
3
0
.
0

6
3
0
.
0

2
1
0
.
0

2
1
0
.
0

1
1
0
.
0

1
1
0
.
0

1
1
0
.
0

0
1
0
.
0

0
1
0
.
0

9
0
0
.
0

9
0
0
.
0

9
0
0
.
0

0
7
1
.
0

6
1
0
.
0

6
1
0
.
0

6
1
0
.
0

7
1
0
.
0

9
1
2
.
1

8
5
0
.
0

7
5
0
.
0

7
5
0
.
0

5
5
0
.
0

a
i
b
m
u
l
o
C
h
s
i
t
i
r
B

0
9
0
.
0

7
5
0
.
0

0
2
0
.
0

3
0
0
.
0

0
0
0
.
0

-

e
v
i
a
N

9
0
0
.
0

5
0
0
.
0

0
0
0
.
0

1
0
0
.
0

1
0
0
.
0

d
l
i

M

9
0
0
.
0

5
0
0
.
0

0
0
0
.
0

1
0
0
.
0

1
0
0
.
0

e
t
a
r
e
d
o
M

9
0
0
.
0

5
0
0
.
0

0
0
0
.
0

1
0
0
.
0

1
0
0
.
0

d
l
i

M

0
1
0
.
0

6
0
0
.
0

0
0
0
.
0

1
0
0
.
0

1
0
0
.
0

e
t
a
r
e
d
o
M

e
v
i
t
i
d
d
A

e
v
i
t
a
c
i
l
p
i
t
l
u
M

4
6
4
.
0

3
3
3
.
0

3
4
2
.
0

2
3
1
.
0

8
4
0
.
0

-

e
v
i
a
N

4
2
0
.
0

7
1
0
.
0

1
1
0
.
0

4
0
0
.
0

2
0
0
.
0

d
l
i

M

3
2
0
.
0

6
1
0
.
0

1
1
0
.
0

4
0
0
.
0

2
0
0
.
0

e
t
a
r
e
d
o
M

3
2
0
.
0

6
1
0
.
0

1
1
0
.
0

4
0
0
.
0

2
0
0
.
0

d
l
i

M

3
2
0
.
0

5
1
0
.
0

1
1
0
.
0

4
0
0
.
0

2
0
0
.
0

e
t
a
r
e
d
o
M

e
v
i
t
i
d
d
A

e
v
i
t
a
c
i
l
p
i
t
l
u
M

o
i
r
a
t
n
O

47

