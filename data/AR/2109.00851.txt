1
2
0
2

p
e
S
2

]

R
P
.
h
t
a
m

[

1
v
1
5
8
0
0
.
9
0
1
2
:
v
i
X
r
a

Some relation between spectral dimension and
Ahlfors regular conformal dimension on inﬁnite
graphs

Kˆohei Sasaya ∗

September 3, 2021

Abstract

The spectral dimension ds of a weighted graph is an exponent asso-
ciated with the asymptotic behavior of the random walk on the graph.
The Ahlfors regular conformal dimension dimAR of the graph distance is
a quasisymmetric invariant, where quasisymmetry is a well-studied prop-
erty of homeomorphisms between metric spaces. In this paper, we give a
counter example of the inequality dimAR ≤ ds < 2 in a homogeneous but
not scale symmetric class of fractals, and also give a suﬃcient condition
for the inequality in a class of scale symmetric graphs.

1 Introduction

Let (X, d) be a metric space and µ be a Borel measure on it. We ﬁrst deﬁne
quasisymmetry and the Ahlfors regular conformal dimension.

Deﬁnition 1.1 (Quasisymmetry, [12]). Let X be a set, d, ρ be distances on
X, and θ :
) be a homeomorphism. Then we say d is θ-
)
∞
quasisymmetric to ρ if for any x, y, z

X with x

= z,

[0,

[0,

∞

→

∈

(ρ(x, y)/ρ(x, z))

θ(d(x, y)/d(x, z)).

≤
Moreover, if d is θ-quasisymmetric to ρ for some θ, then we say that d is qua-
sisymmetric to ρ and write d

ρ.

∼QS
dα for any α

For example, d

(0, 1) and metric space (X, d). Qua-

∼QS

∈
sisymmetry was introduced by Tukia and V¨ais¨ala in [18] as a generalization of
quasiconformal mappings on the complex plane. Quasisymmetry has been stud-
ied in various ﬁelds, such as Gromov hyperbolic spaces ([13, 15] for example)
and metric measure spaces ([7, 17] for example). From the viewpoint of global

∗Kyoto University, Kyoto 606-8502, Japan.

JSPS Research Fellow (DC1). E-mail:

ksasaya@kurims.kyoto-u.ac.jp

1

 
 
 
 
 
 
6
analysis, quasisymmetry was used as a modiﬁcation which preserves doubling
conditions (See [9, 11] for example).
Ahlfors regularity and the Ahlfors regular conformal dimension are deﬁned as
follows.

Deﬁnition 1.2 (Ahlfors regularity). We say µ is α-Ahlfors regular with respect
to (X, d) if there exists C > 0 such that

C−

1rα

µ(Bd(x, r))

Crα for any x

≤

≤
where rx = rx,d = inf y
d(x, y) < r
measure µ such that µ is α-Ahlfors regular with respect to (X, d).

|
. The space (X, d) is called α-Ahlfors regular if there exists a Borel

d(x, y), and Bd(x, r) is the open ball

X

≤

∈

∈

\{

}

{

y

X

∈

x

}

X and rx ≤

r

diam(X, d)

Deﬁnition 1.3 (Ahlfors regular conformal dimension). The Ahlfors regular
conformal dimension (ARC dimension in short) of (X, d) is deﬁned by

dimAR(X, d) = inf

α

{

|

there exists a metric ρ on X

such that ρ is α-Ahlfors regular and d

ρ

,

}

∼QS

where inf

=

.
∞

∅

Note that if (X, d) is an α-Ahlfors regular space without isolated points,
then α coincides with the Hausdorﬀ dimension of (X, d). ARC dimension was
introduced for continuous metric spaces by Bourdon and Pajot [6] (see also
Bonk and Kleiner [5]). In [5], it is related to the well-known Cannon’s conjecture,
which claims that for any hyperbolic group G whose boundary is homeomorphic
to the 2-dimensional sphere, there exists a discrete, cocompact and isometric
action of G on the hyperbolic space H3.
In [12], Kigami evaluated ARC dimension using partitions. Roughly speaking,
the partition is a successive division of a continuous metric space encoded by
a tree. For a given partition, he deﬁned the upper (resp.
E p
(resp.
E p) of the partition as a certain limit of p-energies on graphs deﬁned by
the division (see [12, Deﬁnition 4.6.8] for details and Deﬁnition 2.7 for graph
cases). Note that the p-energy enjoys a phase transition when p varies, that is,
there exists a p0 > 0 such that
E p = 0 if p > p0. For p > 0,
E p > 0 if p < p0 and
p) of
he also deﬁned the upper (resp.
the partition as the related exponents. Remark that the spectral dimension of
a Hunt process Y is deﬁned by

s
p (resp. ds
lower) p-spectral dimension d

lower) p-energy

ds(Y ) =

2 lim
t
→∞
if the heat kernel ht(x, y) and the limit exist. If X is the Sierpi´nski gasket or the
(generalized) Sierpi´nski carpet, and d is the restriction of the Euclidean metric,
s
then the 2-spectral dimensions ds
2 and d
2 coincide with the spectral dimension
of the Brownian motion on X.

−

ln ht(x, x)
ln t

2

Theorem 1.4 ([12], Theorem 4.6.4, 4.6.9 and 4.7.9). Let (X, d) be a compact
metric space without isolated points. Under some conditions about d and for
partitions in a certain class, the following hold.

(1) dimAR(X, d) = inf

p

{
(2) If dimAR(X, d) < p, then dimAR(G, d)

}

{

| E p = 0

= inf

p

(3) If dimAR(X, d)

≥

p, then dimAR(G, d)

.

| E p = 0
}
s
ds
p < p.
d
p ≤
s
d
p ≥

ds
p ≥

p.

≤

≥

(See [12] for details, and Theorem 2.8 and [16] for graph cases.) By the
above theorem and the cases of Sierpi´nski carpets, it is natural to expect the
following inequalities;

either dimAR(X, d)

≤

ds(Y ) < 2 or dimAR(X, d)

ds(Y )

≥

≥

2 holds,

(1.1)

for a class of processes Y on X.

Our main aim of this paper is twofold. The ﬁrst is to give a counterexample
of (1.1) in a graph case, and the second is to give a suﬃcient condition for a scale
symmetric class of graphs. In order to state them, next we introduce conditions
of inﬁnite graphs.
Let (G, E) be an inﬁnite, connected, locally ﬁnite (simple) graph. We say
µ : E

) is a weight on E if µxy = µyx for any (x, y)

E. We set

(0,

→

∞

µx =

µxy

and µ(A) =

µx

(for any x

G, A

G).

E

A
Xx
Xy:(x,y)
∈
∈
G, there exists a Markov chain X x such that pn(x, y) := P(X x

n = y)

∈

∈

⊂

For any x
satisﬁes

∈

p0(x, y) =

1
0
(

y = x
otherwise

and pn(x, y) =

µzy
µz

pn

−

1(x, z).

Xz:(y,z)
∈

E

In this paper, we also assume the condition (p0) as in [4]. That is,

there exists p0 > 0, for any (x, y)

E,

∈

µxy
µx ≥

p0.

(p0)

Note that X x is symmetric in the following sense: hn(x, y) = hn(y, x) for any
N, where hn(x, y) := pn(x, y)/µy is called the heat kernel. We
x, y
G and n
also note that

∈

∈

sup
G
x

∈

y

#
{

|

(x, y)

E

∈

} ≤

p−
0

1

if the condition (p0) is satisﬁed, where #A denotes the number of vertices of a
set A.
The spectral dimension of the weighted graph (G, µ) is the following limit, if it
exists:

ln h2n(x, x)
ln n

.

(1.2)

ds(G, µ) = lim

→∞ −
n

2

3

∈

G. If µ is the simple weight (i.e. µxy ≡

It is easy that if ds(G, µ) exists, then the value does not rely on the choice of
x
1), we use ds(G, E) instead of
ds(G, µ) for simplicity.
Quasisymmetry, Ahlfors regularity and the ARC dimension of the graph dis-
tance is deﬁned by Deﬁnitions 1.1, 1.2 and 1.3 in the same way, as a (discrete)
metric space. In [16, Theorem4.14], the author extended Theorem 1.4 to inﬁnite
graphs.

We now introduce a counterexample of the following statement;

≤

either dimAR(G, d)

ds(G, µ) < 2 or dimAR(X, d)

ds(G, µ)

2 holds,

(1.3)
where d is the graph distance of (G, E). For the rest of this paper, C (resp.
√
imaginary unit), and intA means the
interior of A

8
j=0 denote the points

C.

−

≥

≥

{

⊂

1) denotes the complex plane (resp.
pj}
1
2 −
√
−
2

√
−
2
1

−
1
2

p1 =

p2 =

p5 =

p6 =

−
√
−
2

1
2

+

1

,

,

,

√
−
2
1

,

p0 = 0,

p4 =

1

,

p3 =

p7 =

1
2 −
1
2

−

,

1

√
−
2
√
−
2

+

1

,

p8 =

,

1
2
(1.4)

−

in C (see Figure 1.1) and ϕj (0
Let f : N
0) by
(n

→ {

0, 1

}

≥

pj)+pj .
be a map. We inductively deﬁne graphs (Gn(f ), En(f ))

8) denotes the maps ϕj(z) = 1

3 (z

≤

≤

−

j

G0(f ) =

{

,

p0, p1, p3, p5, p7}
0,1,3,5,7
∪j
∈{
8
j=1ϕj (Gn
∪

−

}

ϕj (Gn
1(f ))

(

Gn(f ) =

for n

≥

1 and

−

1(f ))

if f (n) = 0
if f (n) = 1

(1.5)

En(f ) =

(x, y)

{

∈

Gn(f )

×

Gn(f )

x

y

|

−

| |

= 3−

n2−

1/2

}

(1.6)

≥

for n
set K which satisﬁes K =
Vicsek set (resp. Sierpi´nski carpet). We also deﬁne (G(f ), E(f )) by

0 (see Figures 1.2 and 1.3). Note that the unique nonempty compact
8
j=1ϕj(K)) is the
∪

ϕj(K) (resp. K =

0,1,3,5,7

∪j

∈{

}

G(f ) =

∞

n=0
[

3n(Gn(f )+

1
2

+

1

√
−
2

), E(f ) =

(x, y)

{

∈

G(f )

×

G(f )

x

−

y

|

| |

= 2−

1/2

.

}

(1.7)

Our ﬁrst main theorem is the following.

Theorem 1.5. Set

(n) =

f

∗

if k(k2
1
−
0 otherwise

(

1) < n

≤

k3 for some k

N,

∈

(1.8)

4

Im

p6

p0

p2

p5

p4

1
2

p3

p7

p8

p1

Gn−1

Gn−1

Gn−1

Gn−1

Gn−1

Re

Gn−1

Gn−1

Gn−1

Gn−1

Gn−1

Gn−1 Gn−1 Gn−1

Figure 1.1: p0, ..., p8

Figure 1.2:
Gn(f ) (f (n) = 0)

Figure 1.3:
Gn(f ) (f (n) = 1)

then

ds(G(f

), E(f

∗

∗

)) = 2

ln 5
ln 3 + ln 5

< dimAR(G(f

), d
∗

∗

) = dimAR(SC, d2) < 2,

where d
is the graph distance of (G(f
∗
∗
carpet and d2 is the Euclidean distance of R2.

), E(f

∗

)), SC is the (standard) Sierpi´nski

Remark. diam(Gn(f
), En(f
(Gn(f

∗

∗

∗

), dn)

3n, where dn denotes the graph distance of

)). We will prove it in Lemma 3.12.

6≍

Note that we can construct a counterexample of (1.1), which is compact and
continuous in a similar way. More precisely, we can construct a diﬀusion process
Y and a Radon measure µ on a compact metric space (X, d) such that ds(Y )
exists and ds(Y ) < dimAR(X, d) < 2.

In the second part of this paper, we give a suﬃcient condition for (1.3),
which includes a type of scale symmetry. In order to state the condition, we
introduce the resistance on weighted graphs as follows;

Rµ(A, B) = (inf

1
2

{

X(x,y)
∈

E

(f (x)

f (y))2µxy |

−

f : G

R, f

|A ≡

1, f

|B ≡

1

)−

0

}

→

for A, B
⊂
minimum and Rµ(
{
second main theorem is to give a suﬃcient condition for (1.3) as follows.

1 attains the
) is the distance on G (see [10] for example). Our

. It is known that (Rµ(A, B))−

G with A
,

B =
∩
y
{

x
}

}

∅

Theorem 1.6. Let (G, E) be an inﬁnite, connected, locally ﬁnite graph, d be
the graph distance of (G, E) and µ be a weight on E satisfying the condition
(p0). If there exist α, β, C > 0 such that α + β > 2 and
1d(x, y)α
1nβ

Cd(x, y)α,
Cnβ

x
}
}
µ(Bd(x, n))

Rµ(
{

C−

C−

≤

≤

{

y

)

,

≤

≤

for any x, y

G and n

∈

≥

0, then the limit of (1.2) exists and

ds(G, µ) < 2.

dimAR(G, d)

≤

5

Im

0

Figure 1.4: (G(f

), E(f

))

∗

∗

Notations

Re

• Let f, g be functions on a set X. We say f . g (resp. f & g) for any x

A
for any x

⊂

X if there exists C > 0 such that f (x)

Cg(x) (resp. f (x)

≥
g (for any x) if f . g and f & g.

≤

A. We also write f

∈

∈
Cg(x))

• a

∨

b (resp. a

∧

• For a set X and A

is obvious.

⊂

b) denotes max

(resp. min

a, b

}
{
X, we write Ac instead of X

{

).

}
A if the whole set X

\

≍
a, b

•

⊔λ
∈
any λ, τ

ΛAλ denotes the disjoint union, that is,
= τ.

Λ with λ

∈

∪λ
∈

ΛAλ with Aλ ∩

Aτ =

for

∅

• Let X be a set and f : X

k

→

X be a map, then we write f k instead of

f . Moreover, f −

k denotes (f −

1)k for k > 0.

f

◦ · · · ◦
}|

{

z
• Let Θ be a variable deﬁned by the minimum or maximum of some func-
tions. We say f is the optimal function for Θ if f attains the minimum or
maximum. For example, we say f is the optimal function for Rµ(A, B) if
(Rµ(A, B))−

f (y))2µxy, f

1 and f

0.

E(f (x)

1 = 1
2

|A ≡

|B ≡

(x,y)

∈

−

• µ(G,E) denotes the simple weight on E, that is, µxy = 1 for any (x, y)

P

For simplicity, we will write R(G,E) instead of Rµ(G,E) .

E.

∈

6

6
We abuse the notation x instead of
,
we write R(x, y) instead of R(
{

x
}

if no confusion may occur. For instance,
x
}
{
).
y
}
{

2 Partition of inﬁnite graphs

In this section, we introduce the notion of partition of inﬁnite graphs and results
of [16] which is necessary to prove our main theorems. Note that these results
are based on compact cases in [12]. See these papers for details.

Deﬁnition 2.1 (Bi-inﬁnite tree). Let T be a countable set and π : T
a map which satisﬁes the following.

→

T be

(T1) For any w, v

T, there exists n, m

0, πn(w) = πm(v).

(T2) For any n

∈
1 and w

T, πn(w)

≥
= w.

≥
Aπ =
πn(v) = w for some n

Then we deﬁne
graph (T,
T

∈
(w, v)

{

v

and consider the simple
Aπ). We call (T, π) a bi-inﬁnite tree. We also deﬁne subtree Tw =

π(w) = v or π(v) = w

, and denote the inverse of π by S.

}

0

|

{

∈

|
(1) Let φ

≥

}

∈

T . We call the triple (T, π, φ) a bi-inﬁnite tree with a reference
T we deﬁne the height of vertices by [w] = [w]φ =

m such that πn(w) = πm(φ). We also deﬁne (T )n by (T )n =

w

{

∈

point φ, and for any w
n
T

for any n

−
[w] = n
|

∈
Z.

∈
(2) Deﬁne (descending) geodesics of T by Σ∗ =

}

ωn ∈
ω = (ωn)n
and geodesics passing through w by

{

∈

Z

|

(T )n, π(ωn+1) = ωn for all n
Σ∗w =

ω[w] = w

Σ∗

Z
}
∈
for any w

ω

T.

∈

|

{

∈
Deﬁnition 2.2 (Partition). Let
erence point. A map K : T
(G, E) parametrized by

}

→ {

(PG1)

v

∈

T
S(w) Kv = Kw for any w

T.

∈

S
(PG2) For any ω

Σ

, there exist n0(ω)

∈
∗
for any n

x, y

{

}

(PG3) For any (x, y)

∈

n0(ω).

≥
E, there exists w

= (T, π, φ) be a bi-inﬁnite tree with a ref-
is called a partition of

#(A) <

G

T
A

if it satisﬁes the following conditions.

⊆

|

∞}

Z and (x, y)

∈

E such that Kωn =

T such that Kw =

x, y

.

}

{

∈

∈

(1) We denote ωn0(ω) by ωe where n0(ω) is in the condition (PG2). We also

deﬁne Λe and Te by

Λe =
Te =

w
w

{
{
Te)

T
T

#(Kw) = 2 and #(Kπ(w)) > 2
=
Tw ∩

w

∈

T

{

|

}

|
|

=

∈
∈
∅}
Λe, we deﬁne we ∈

Λe 6

Λe such that w

Twe.

∈

#(Kπ(w)) > 2

.

}

For w

(T

∈

\
(2) K is called minimal if Kw 6

∪

= Kv for any w, v

Λe with w

= v.

∈

7

6
6
Deﬁnition 2.3 (Discrete weight function). Let K be a partition of (G, E)
) is called a discrete weight
parametrized by (T, π, φ). A function g : Te →
function (with respect to K) if it satisﬁes following conditions.

(0,

∞

(GG1) For some w

Te, limn

∈
Te, g(π(w))

→∞

g(πn(w)) =

.
∞

g(w).

(GG2) For any w

∈
(1) For s > 0, we deﬁne the scale Λg

≥

s associated g by

g(w)

Te |

s < g(π(w))
}

,

≤

Λg

s =

w

{
∈
Λg
s by

and write Eg

s ⊆
Eg
s =

Λg

s ×
(w, v)

{

w, v

|

∈

Λg

s, w

= v and Kw ∩

Kv 6

=

.

∅}

(2) For x

X, s > 0, M

0 and w

≥

∈
s,M (w) =

Λg

v

{

∈

Λg

s |

lEg

s (w, v)

Λg

s, we deﬁne

, Λg

s,M (x) =

M

}

∈

≤

Λg

s,M (w),

Λg
[w
s
∈
Kw
and x
∈

where lEg

s is the graph distance of (Λg

s, Eg

s ), and

U g

M (x, s) =

{

(

,

if Λg

s,M (x) =

s,M (x) Kw, otherwise.
Λg

x
}
w

∈

,

∅

Example 2.4. Deﬁne

S

(G) =

d

{

|

D∞

d is a metric on G such that diam(G, d) =

and let d
(G). We also deﬁne gd : Te →
then gd is a discrete weight function.
We denote gd by d if no confusion may occur.

∈ D∞

(0,

∞

∞}
) by gd(w) = max

d(x, y),

x,w

Kw

∈

Deﬁnition 2.5. Let g be a discrete weight function and d

(1)

• g is called uniformly ﬁnite if

(G).

∈ D∞

|
• g is called thick (with respect to K) if there exists α > 0 such that

∈

#(Λg

s,1(w))

s > 0, w

sup
{

Λg
s}

<

.
∞

for any w

∈

Te, Λg

αg(π(w)),1(x)

Tw for some x

Kw.

∈

⊂

(G) is called uniformly ﬁnite (resp. thick) if gd is uniformly ﬁnite

d
(resp. thick).

∈ D∞

(2) d is called adapted if there exist α1, α2 > 0 and M

N such that

∈

Bd(x, α1r)

U d

M (x, r)

⊆

⊆

Bd(x, α2r)

for any x

X and r

1.

≤

∈

8

6
Deﬁnition 2.6 (Basic framework). Let (G, d) be a metric space and assume
K is minimal partition of (G, E). We say (G, d) satisﬁes the basic framework
(with respect to K) if the following conditions hold.

∈

Te\

• supw
Λe #(S(w)) <
• d is uniformly ﬁnite, thick, adapted.
• There exists r

(0, 1) such that d(w)

.
∞

∈

r[w] for any w

Te.

∈

≍

Moreover, for w

Sw,m =

{{

Λe and n

∈
≥
(x, k), (y, 2n(m)

0, let

G, n(m)

where x, y
∈
∈
Then we deﬁne Tr = Te ⊔

(

w

k)
N such that Kw =

−

−

1

}w,m |
x, y

∈
and 2−

k

[0, 2n(m)

1]Z

−
}
rm < 21

n(m).
n(m)
1 Sw,m) and formally deﬁne K on Tr by

≤

}

{

−

Λe

∈
Te,

m

≥

F

S
if w
∈
if w =
otherwise.

{

(x, 0), (y, 2n(m)

1)

}m,v for some m, v,

−

Kw,
x
,
}
,

Kw = 
{

∅

Tr by

and π′ : Tr →
π′(w) =

π(w),
v,
(x, l), (y, 2n(m



{

We also deﬁne J h
J h
m = J h

m(K) =

1)

−

1

−

−

l)

}v,n
−

1,

Te,
Sv,1,

if w
∈
if w
∈
if w =
and [

(x, k), (y, 2n(m)
k+1
[
2(n(m)) ]

{
k
2n(m) ,

1
−
−
l
2n(m−1) ,

k)
}v,m
l+1
2n(m−1) ].

⊆

m, J h

N,m ⊂

(Tr)m ×
w, u

(Tr)m by

(w, u)

{

i

≥

|

∈
0 such that w =

=

K v 6
∅
(x, i), (y, 2n(m

(Tr)m, Kw ∩
{
(x, i

u =

1), (y, 2n(m

−

[v])

−

1

−
[v])

or there exists v

{

−

Te,

[v],

−
[v]}

,

−
i)

i)

∈
}w,m
}w,m
,
N

−

−

J h
N,m =
v

{

(w, v)
|
(Tr)[w] |

and Γn(w) =
∈
(Tr, π′) as a bi-inﬁnite tree and lJ h

{

m

m

w, v

(Tr)m such that 0 < lJ h
∈
(w, v)
lJ h

for any w

n

m

(w, v)

}
Tr, where we consider

≤

≤

}

∈

is the graph distance of ((Tr)m, J h

m).

We now introduce the spectral dimension in the sense of partition.

Deﬁnition 2.7 (Critical exponent, p-spectral dimension). For any N
N2 ≥

0, p > 0 and w

N1 ≥

Tr, let

1,

≥

Ep,k,w(N1, N2, N ) = inf

(cid:26)

f (x)

|

p

f (y)
|

−

J h
X(x,y)
∈

N,|w|+k

∈
1
2

f : (Tr)[w]+k →

R such that f

|Sk(ΓN1 (w)) ≡

1, f

|(Sk(ΓN2 (w)))c

≡

0

.
(cid:27)

9

(cid:12)
(cid:12)
(cid:12)
(cid:12)

and we also write

w

Ep,k(N1, N2, N ) = sup
E p(N1, N2, N ) = lim sup
k
→∞
p
(N1, N2, N ) = inf
I

∈

T Ep,k,w(N1, N2, N ),
Ep,k(N1, N2, N ),
|E p(N1, N2, N ) = 0
}
#(Sk(w))1/k,

,

{
= lim sup
k

N

∗

E

sup
T
w

∈

→∞
Rp(N1, N2, N ) = lim sup
→∞

k

s
d
p(N1, N2, N ) =

log N

∗ −

Ep,k(N1, N2, N )1/k,

p log N
log Rp(N1, N2, N )

∗

.

s
d
p(N1, N2, N ) is called upper p-spectral dimension.

Theorem 2.8 ([16], Theorem 4.14). Let K be a minimal partition of (G, E).
If the graph distance d satisﬁes the the basic framework, then for any N, N1, N2
such that N2 −
(1) I

N1 is suﬃciently large,

(N1, N2, N ) = dimAR(G, d).

E

(2) If Rp(N1, N2, N ) < 1, then dimAR(G, d)

(3) If Rp(N1, N2, N )

1, then dimAR(G, d)

≥

s
p(N1, N2, N ) < p.

d

s
p(N1, N2, N )

d

p.

≥

≤

≥

This theorem is the discrete version of Theorem 1.4.

3 Example of ds(G, µ) < dimAR(G, d) < 2: Proof of

Theorem 1.5

In this section, we will prove Theorem 1.5. We ﬁrst prove ds(G, µ) = 2 ln 5/ ln 15
using the argument of resistances. In the second part of this section, we will
8
prove dimAR(G, d) = dimAR(SC, d2) using partitions. Recall that
j=0,
is deﬁned by (1.4), (1.5), (1.6), (1.7) and
Gn(f ), G(f ), En(f ), E(f ) and f
(1.8).

pj}

{

∗

3.1 Evaluation of ds(G, µ)

We ﬁrst check properties of the resistance.

Lemma 3.1. For any f : N

(1) R(Gn(f ),En(f ))(p1, p3)

(2) R(Gn(f ),En(f ))(p1, p5)

(3) R(Gn(f ),En(f ))(p1, p5)

≤

0,

0, 1

and n

→ {
≥
}
4R(Gn(f ),En(f ))(
{
4R(Gn(f ),En(f ))(
{

≤

≤

{
R(Gn+1(f ),En+1(f ))(p1, p5).

,

{

p1, p7}
p1, p7}

,

p3, p5}
p3, p5}

).

).

10

Proof. Let hjk be the optimal function for R(Gn(f ),En(f ))(pj, pk) (j, k = 1, 3, 5, 7).

(1) By symmetry, h13(z) = 1

2 for any z

potential minimality assure h13(p7)

≥

Gn with Re(z) = 0. This and
1
2 , so

∈
1
2 and h13(p5)

ˆh(z) = (h13(z) + h75(z)

h13(p5))

−

≤
1

∧

satisﬁes ˆh(p1) = ˆh(p7) = 1 and ˆh(p3) = ˆh(p5) = 0. This shows

R(Gn(f ),En(f ))(
{

,

p1, p7}
2 for any z

{

p3, p5}

1

)−

≤

4R(Gn(f ),En(f ))(p1, p3)−

1.

Gn with Re(z) =

Im(z), this follows

−

∈

(2) Since h15(z) = 1
similarly to (1).

(3) The statement is clear, considering the function `h on Gn+1(f ) such that

`h(z) = 


1
1 (z))
1
5 (z))

h15(ϕ−
h15(ϕ−
1
2

if Re(z) + Im(z)
if Re(z) + Im(z)
otherwise.

2
3 ,

≤ −
2
3 ,
≥



For simplicity of notation, we write G
∗

), R(G∗,E∗), µ(G∗,E∗)). We also set

(resp. E(f

∗

(resp. E∗, R∗, µ∗) instead of G(f

)

∗

I =

z

{

∈

C

| |

Re(z)

| ∨ |

Im(z)

| ≤

1
2 }

,

I

z

{

Il =

Re(z) =

1
2 }
|
R∗n = R(Gn(f∗),En(f∗))(Gn(f
)
∗
R∗n,pt = R(Gn(f∗),En(f∗))(p1, p5).

−

∈

,

Ir =

z

{
∈
Il, Gn(f

∩

1
2 }

,

Re(z) =

Ir),

I

)

|

∩

∗

Theorem 3.2.

(1) R∗n ≍

R∗n,pt for any n

0.

≥

(2) Let m1(n) denotes the number #
k
k
{
|
#
1) = 0
n, f
k
{
∗
ρ > 1 such that

(k) = 1, f

(k

−

≤

k

∗

|

n, f

(k) = 1

and m2(n) denotes
≤
, then there exist C1, C2 > 0 and
}

}

∗

ρm1(n)3n

−

m1(n)Cm2(n)
1

R∗n,pt ≤

≤

2ρm1(n)3n

−

m1(n)Cm2(n)
2

for any n

0.

≥

In order to prove the above theorem, we introduce the resistance estimate for
and we inductively
p1, p3, p5, p7}
0 =
), we set
1). Similar to the cases of Gn(f

the graphical Sierpi´nski carpet. Let GSC
j=1ϕj(GSC
8
deﬁne GSC
n
∪
−
(x, y)

n =

GSC

{

y

∗

En(f ) =
RSC
RSC

{
n = R(GSC
n,pt = R(GSC

GSC
n ×
∈
n )(GSC
n ,ESC
n ∩
n )(p1, p5).

n ,ESC

x
n | |
−
Il, GSC
n ∩

n

,

}

= 3−

|
Ir),

We use the following fact.

11

Remark.

Proposition 3.3. ρn

RSC

RSC

n,pt for some ρ > 1.

≍

(1) ρn

≍
RSC
n

n ≍
for some ρ > 1 follows in the same way as [2]. On the
other hand, we can not apply this method to RSC
n,pt because the method,
especially the part of potential argument in [2, Section 4], uses the fact
that the optimal function h for RSC
Il: we can
not obtain RSC
for any
n, k

1 on GSC
n ∩
n+k,pt & RSC
n,ptRSC
k
n,pt in the appendix.

satisﬁes h
k,pt but only RSC
n & RSC

0 in this way. We will prove RSC

n+k,pt & RSC

n,ptRSC

≡

n

≥

(2) The heat kernel estimates of the simple random walks on graphical Sierpi´nski

carpets have been studied in [3], including transient cases without resis-
tance estimates. We can also obtain ρn
n by [3, Theorem 1.5] and
[4, Theorem 1.3].

RSC

≍

Deﬁnition 3.4 (Unit ﬂow). Let (V, P ) be a connected, locally ﬁnite graph. For
A, B
R is called an unit ﬂow from A to B if it
⊂
satisﬁes

V with A

, f : E

B =

→

∩

∅

• f (x, y) =

•

•

P

y:(x,y)

∈

f (y, x) for any (x, y)

−
E f (x, y) = 0 for any x

P,

B,

A

∪

∈

6∈

A

x

∈

y:(x,y)

∈

E f (x, y)µxy = 1 and

B

x

∈

y:(x,y)

∈

E f (x, y)µxy =

1.

−

P
Let µ be a weight on P, then it is known that

P

P

P

Rµ(A, B) = min

1
2

{

X(x,y)
∈

P

f (x, y)2µxy |

f is a unit ﬂow from A to B

(3.1)

.

}

We say f is the optimal ﬂow for Rµ(A, B), or optimal ﬂow from A to B if f

is the optimal function for the right hand side of (3.1).

Lemma 3.5. Let l = l(n) be the integer such that

l(n) = max
{

m

|

m

≤

n, f

∗

(m) = 0

,

}

(3.2)

then

for any n with f

(n) = 1.

∗

RSC
n
−

l,ptR∗l,pt & R∗n,pt

Proof. For any x, y
from x to y on En(f

Gn(f
∗
) such that

) with (x, y)

∈
∗

• fxy(z, w) = 0 for any (z, w)

• 1
2

(z,w)

∈

P

En(f∗) fxy(z, w)2

≤

En(f

∈
4R∗l,pt

ESC
n
−

l, there exists an unit ﬂow fxy

∈

) with

∗

x

|

z

|

−

> 21/23−

(n

−

l)

12

by Lemma 3.1. Let g be the optimal ﬂow for RSC
−
by

n

l,pt. We deﬁne ˜g : En(f

R

)

∗

→

˜g(z, w) =

1
2

g(x, y)fx,y(z, w),

X(x,y)
∈

ESC
n−l

then we can see that ˜g is a unit ﬂow from p1 to p5. Since

sup
Gn(f∗)

#
{

(x, y)

ESC
n
−

l | |

x

−

z

∈

| ≤

21/23−

(n

−

l)

36,

} ≤

z

∈

this shows

R∗n,pt ≤

≤

1
2

En(f∗)

X(z,w)
∈
72RSC
l,ptR∗l,pt.
n
−

˜g(z, w)2

9
2

≤

g(x, y)2

fxy(z, w)2

X(x,y)
∈

ESC
n−l

X(z,w)
∈

En(f∗)

Proof of Theorem 3.2.

(1) It is suﬃcient to show R∗n & R∗n,pt for n

1.

≥

• The case of f

Here we set h∗n : G∗n →

(n) = 0: let g∗n
R by

∗

1 be the optimal function for R∗n

−

1,pt.

−

h∗n(z) = 


1
g∗n
0

−

1(3z) + g∗n

−

1(3√

−

1z)

1
2

−

ϕ7(I)

∪

ϕ1(I)
ϕ0(I)
ϕ3(I)

if z
if z
if z

∈
∈
∈
1,pt)−

ϕ5(I),

∪
1 = 12(R∗n,pt)−

1,


then 1
(x,y)
2
−
which completes this case.

(h∗n(x)

E∗
n

∈

h∗n(y))2

4(R∗n

−

≤

• The case of f

P

∗

(n) = 1 : let l(n) be the same as (3.2). Using the

former case, Proposition 3.3 and Lemma 3.5, we obtain

RSC
n
−

lR∗l & RSC
n
−

l,ptR∗l,pt & R∗n,pt

for any n with f

(n) = 1.

∗

On the other hand, we can get R∗n & RSC
lR∗l for any n by the same
n
−
potential argument as in [2, Theorem4.3], which completes the proof.

(2) We will inductively prove the upper bound. Let C3, C4 > 0 be the
(1) and
l,ptR∗l,pt ≥
f −
∗
(n) = 0, the claim

0. We write C2 = C3C4. If f

constants which satisfy C3RSC
−
RSC
C4ρk for any k
is obvious. Otherwise,

R∗n,pt for any n

k,pt ≤

≥

∈

n

∗

1

R∗n,pt ≤

C3RSC
n
−
= 2ρm1(n)3n

l,ptR∗l,pt ≤

m1(n)Cm2(n)
2

.

−

2ρm1(l)3l

−

m1(l)Cm2(l)
2

C2ρn
−

l

·

This conclude the proof of upper bound. We can prove the lower bound
in a similar way.

13

Lemma 3.6. There exists M > 0 such that R∗n,pt ≤
Remark. Note that this lemma does not follows from Theorem 3.2 (2). Indeed,
we do not know whether C1 equal to C2 for Theorem 3.2 (2).

1
2 R∗n+M,pt for any n

0.

≥

Proof. By the deﬁnition of f

, the following claim holds.

∗

Claim. For any m
exists k = k(n, m) such that n

1, there exists N (m) such that for any n

N (m), there
n+m and f (k) = f (k+1) = ... = f (k+m).

≥

≥

k

≤

≤
N (m),

For ﬁxed m and n

• if f

∗

≥
(k) = 0, then R∗k+m,pt ≥

R∗k+1,pt = 3R∗k,pt.

• Otherwise, let l = l(k + m) = l(k) be the same as (3.2), then

R∗k,pt ≤
= 4

4RSC
k
−
R∗l,pt
R∗l

l,ptR∗l,pt
R∗k+m
R∗k+m,pt

lR∗l

RSC

k+m
−
R∗k+m

RSC
k
−
ρk
−

l,pt
l

ρk+m
RSC

k+m

l

−

l

−

ρ−

mR∗k+m,pt

by the same argument as Lemma 3.5. Therefore Theorem 3.2, Proposi-
R∗k+m,pt if m is
tion 3.3 and the potential argument shows that 2R∗k,pt ≤
suﬃciently large. Fix such a m

1 and set M = 2m + N (m), then

≥

R∗n,pt ≤

R∗n+N (m),pt ≤

R∗k,pt ≤

1
2

R∗k+m,pt ≤

1
2

R∗n+M,pt

for any n

≥

0 and some k

≤

n + N (m) + m. This concludes the proof.

Proposition 3.7. For x1, x2 ∈
such that there exist aj, bj ∈
xj ∈
for j = 1, 2, where

In(x1,x2),aj ,bj , int(In(x1,x2),aj ,bj )

G∗, we denote by n(x1, x2) the minimal integer

Z (j = 1, 2) with the property that

G∗

=

, In(x1,x2),a1,b1 ∩

∅

∩

In(x1,x2),a2,b2 6

=
∅
(3.3)

In,a,b =

z

∈
Then R∗(x1, x2)

{

3na

G∗

|

≤

Re(z)

≤

3n(a + 1), 3nb

Im(z)

3n(b + 1)
}

.

≤

≤

R∗n(x1,x2) for any x, y

G∗.

∈

≍

Proof. We ﬁrst prove R∗(x1, x2) . R∗n(x1,x2). By (3.3), we can inductively choose
n = n(x1, x2) such that
xj,k for j = 1, 2 and 0

k

≤

≤

G∗

|

xj,k ∈
xj,0| ≤
2−
1, xj,k} ⊂
∈

xj −
xj,k
{
for some a, b

−

In,aj ,bj , Re(xj,k), Im(xj,k)

3kZ and

∈

if k = 0,

∩
1/2

1(Gk

−

1 +

−

3k
Z

1
2

+ a + (

1
2

+ b)√

1)

−

⊂

G∗

othersise.

14






6
x1

1

x2

0

Figure 3.1: x1, x2 and H2

It is easy to check that

R∗(xj,k, xj,k

1)

−

≤

(R∗k

1,pt ∨

−

R(G∗

k−1,E∗

k−1)(p1, p3))

4R∗k

1,pt,

therefore we obtain R∗(x1, x2)
≤
so R∗(x1, x2) . R∗n(x1,x2) follows.
P
We next show R∗(x1, x2) & R∗n(x1,x2). By the deﬁnition of n = n(x1, x2), there
exist a

Z such that ψn,a∗,b∗ (x1)

ϕ0(I) and ψn,a∗,b∗ (x2)

k=0 R∗k,pt ≤

I where

2 + 8

, b

n

≤

−
16M R∗n,pt by Lemma 3.6,

∗

∗ ∈

ψn,a∗,b∗ (z) = (3−

nz + (

∈
1
2

6∈

+

a
∗
3

) + (

1
2

+

b
∗
3

)√

−

1)

(see Figure 3.1). Let H1 be the function on
function on G∗ such that

8
j=0ϕj (G∗n
∪

−

1) and H2 be the

H1(z) =

1
j (z))

h(ϕ−
1
(

5
j=3ϕj (G∗n
if z
∈ ∪
otherwise

−

1)

H2(z) =

min
0
(

{

H1(k√

−

1

·

ψn,a∗,b∗ (z))

|

k = 0, 1, 2, 3

}

if ψn,a∗,b∗ (z)
otherwise

I

∈

where h be the optimal function for R∗n
1
2

E∗(H2(x)

H2(y))2

8(R∗n

(x,y)

−
1)−

1. Then H2(x1) = 1, H2(x2) = 0 and
1, which concludes the proof.

∈

−

≤

−

Deﬁnition 3.8. Let (X, d) be a metric space and ν be a (Borel) measure on it.

P

x

∈

X and r > 0, there exist

(1) (X, d) is called metric doubling if there exists N > 0 such that for any
, r).

yx,r
j }
(2) We say (X, d) satisﬁes the volume doubling condition with respect to µ if
X

N
j=1 with Bd(x, 2r)

Cν(Bd(x, r)) for any x

j=1Bd(yx,r

there exists C > 0 such that ν(Bd(x, 2r))
and r > 0.

⊂ ∪

≤

∈

{

N

j

It is easy that if (X, d) satisﬁes the volume doubling condition with respect
to some measure ν, then (X, d) is metric doubling. On the other hand, If (X, d)
is complete and metric doubling, then there exists a measure µ such that (X, d)
satisﬁes volume doubling condition with respect to µ (see [7]).

15

Lemma 3.9. Let Vn = 8m1(n)5n

−

m1(n) then

n(x,y)

(1) µ∗(
{

y

≍
|
(2) µ∗(BR∗ (x, R∗(x, y))

≤

m}

)

Vm for any x

G∗ and m

0.

≥

∈

Vn(x,y) for any x, y

G∗.

∈

≍

(3) R∗ satisﬁes the volume doubling condition with respect to µ∗.

The proof is straightforward and we omit it.

By Lemma 3.9 and [16, Theorem 4.27], there exists a distance δ on G∗ such that
G∗,
δ

V ∗(x, R∗(x, y))R∗(x, y) for some γ > 1 and any x, y

, δ(x, y)γ

∼QS

R
∗
and h2n(x, x)

≍
Vδ (x,n1/γ ) for any x

1

≍

G∗ and n

0.

≥

∈

Theorem 3.10. ds(G∗, E∗) = 2

∈
ln 5
ln 3+ln 5 .

Proof. It is easy to see that if δ(x, y)γ
C > 0. Moreover, there exists C′ > 0 such that for any n
N = N (n) satisfy C′R∗N,pt < n

N for some
0 and for some
CR∗N,pt, where C is same as above. Therefore

CR∗N,ptVN then n(x, y)

≥

≤

≤

≤

lim sup

2 −

ln p2k(x, x)
ln k

= lim sup
k

2

ln Vδ(x, k1/γ)
ln k
→∞
(CR∗N,ptVN )1/γ

)

}

ln µ∗(
{

y

2

δ(x, y)

≤
|
ln(R∗N,ptVN ) + ln C′

|

y

ln µ∗(
{

n(x, y)
N
ln(R∗N,ptVN ) + ln C′
m1(N )

≤

)

}

m1(N )

N (ln 8 + ln ρ) + (1

−

N ln 8 + (1

m1(N )

−
m1(N )

N ) ln 5
N )(ln 5 + ln 3) + m2(N )

N ln C1

k

→∞

≤

lim sup
N

→∞

≤

2

lim sup
N

→∞

≤

2

lim sup
N

→∞

=2

ln 5
ln 5 + ln 3

because limN
lim inf k

2 −

→∞

→∞

ln P2k(x,x)

ln k

2

≥

m1(N )

N = limN

m2(N )

N = 0. Similarly, we can obtain

→∞

ln 5

ln 5+ln 3 , which proves the theorem.

3.2 Evaluation of ARC dimension

In this subsection, we will check dimAR(G(f
titions. Let

), d
∗

∗

) = dimAR(SC, d2) using par-

(T ∗)n =

{
(

n,a,b |

intI
a + b√

I
−
3
j=0{
⊔

−

n,a,b ∩
−
1 + √
−
2

G∗
1j

=
∅}
I0,0,0 |

and T ∗ =
⊔n
n,a,b ∈
∈
unique elements in (T ∗)n
n,a,b ⊂
−
Then (T ∗, π∗) is a bi-inﬁnite tree and K(I
−

Z(T ∗)n. Moreover, for I
1 such that I

−

−

if n

0,

≤

if n > 0

T ∗0 }

a, b

∈

Z with I0,a,b ∈
(T ∗)n, π∗(I
π∗(I
n,a,b) = I

−

−

n,a,b) denotes the
n,a,b) as the subsets of C.
G∗ is a partition of
n,a,b ∩

−

16

6
G∗. We can also check that this satisﬁes the basic framework for
other hand, for p > 0, and any graph (V, P ) with V

C, let

⊂

C. On the

| · |

Ep(V, P ) = inf

1
2

{

f (x)

|

p

f (y)
|

|

−

f : V

→

R, f

|V

Il ≡

∩

1, f

|V

Ir ≡

∩

0

}

P

X(x,y)
∈
p,k = Ep(GSC

and we write ESC
and Theorem 4.6.10] and symmetry,

k , ESC

K ) for any k

0. Then by [12, Example 4.6.7

≥

dimAR(SC, d2) = inf

p

{

|

lim sup

k

→∞

ESC

p,k = 0

}

Proposition 3.11. dimAR(G∗,

C) = dimAR(SC, d2).

| · |

Proof. Let Ep,k(f ) = Ep(Gk(f ), Ek(f )) for any k
Theorem 2.8 and symmetry of Gk(f ) show that

≥

0 and f : N

0, 1

}

→ {

. Then

dimAR(G∗,

C) = inf

| · |

p

{

|

lim sup

k

→∞

sup
0
a

≥

Ep,k(Fa) = 0

}

∗

≥

|·|

C)

0, 1

where Fa(k) = f

(a+k). It is easy to prove that dimAR(G∗,

1. Fix any p > dimAR(SC, d2) and f : N

dimAR(SC, d2)
. We assume f (l + 1) =
≥
→ {
f (l + 2) = .. = f (k) = 1 for some l, k with l < k. Then there exists C > 0
Ep,k(f ) in the same way as the
Ep,l(f )
independent of l, k and f , CESC
p,k
−
potential argument in [14, Theorem 5.8] (which is based on[2, Theorem 4.3])
for resistance, because only symmetry, convexity and the fact that the optimal
functions are constant on Il and Ir are used in the argument. By [12, Propo-
sition 4.7.5], there exists γp < 1 such that ESC
0, so in the
same way as in Theorem 3.2 (2), there exist C, C′ > 0, which are independent
of f , such that

p for any k

p,k . γk

≥

≥

}

l

Ep,k(f )

≤

C′γmf

p

1 (k)

3(1

−

p)(k

−

mf

1 (k))Cmf

2 (k)

a

a

|

≤

k, f (a) = 1

, mf

2 (k) = #
{

}

a

a

|

≤

k, f (a) = 1, f (a

1) = 0

.

}

−

0, where

for any k

≥
1 (k) = #
{

mf

Therefore

By deﬁnition of f

sup
0
a

≥
, limk

∗

Ep,k(Fa)

C′(31

−

p

γp)k(sup
a

∨

≤

CmFa

2 (k)).

supa mFa

2 (k)/k = 0 and it also means

→∞

lim
k
→∞

sup
a

Ep,k(Fa) = 0.

Since p > dimAR(SC, d2) is arbitrary, this also shows dimAR(G∗,
dimAR(SC, d2) and concludes the proof.

C)

| · |

≤

Lemma 3.12. There exist C > 0 and c

N such that for any x, y, z

∈

G∗,

∈

17

3n(Gl

−

1 + 1

2 + i
2 )

5 6 7

8 9 10

4
3

1 2

Figure 3.2: bn ≥

3n

−

l+1al

1

−

Figure 3.3: bn ≥

10an

−

1

(1) d
∗

(x, y)

≍

dn(x,y)(p1, p5) with the graph distance dn of (Gn(f

), En(f

)).

∗

∗

(2) If n(x, y) = n(x, z) + 1 then d
∗
(x, y)

(3) If n(x, y)

n(x, z) + c then d
∗

(x, y)

≥

≤

≥

(x, z).

Cd
∗
(x, z).

2d
∗

(4) diam(Gn, dn)

6≍

3n for n

0.

≥
Gn(f

Proof. Let an = dn(p1, Ir ∩
dn(p1, p5), and en = dn(p1, p3) for any n
an ≥
bn. Moreover, considering the reﬂection on
, we can obtain 2an ≥
z
{
|
(3.2), then by the reﬂection of edges, we can see that

)), bn = dn(Il ∩
≥
z

)), cn =
), Ir ∩
en ≥
0. It is obvious that cn ∨
and
Re(z) + Im(z) = 0
}
en. Additionally, let l = l(n) be as in

Re(z) = 0

cn ∨

Gn(f

Gn(f

}

{

∗

∗

∗

|

−
cn ≍

3n

−

l+1al

bn ≥

1
2

((3n

−

1 ≥

−

l+1

2)el

1 + 2cl

1)

−

≥

−

1
2

an,

0.

bn ≍

en for any n

3bn, we also obtain an ≍

(see Figure 3.2), which shows an ≍
0 and
diam(Gn, dn) for any n
Since bn+1 ≥
(x, y) . cn(x,y) for any x, y
G∗ in the same way as Proposition 3.7. On
d
∗
the other hand, by deﬁnition and reﬂection on edges similar to the above,
d
(2), (3) imme-
∗
diately follow from (1) and bn+1 ≥
Finally, If f
(n
−
∗
1)+1bl(n
we also get bn ≥

∈
1 holds. This and cn+1 ≤
5cn shows (1).
3bn, cn+1 ≤
5cn.
1) = 1 then bn ≥

10an
1, this and bn+1 ≥

1 (see Figure 3.3), so
3bn show (4).

(n) = 0 and f
9 3n

bn(x,y)

(x, y)

≥

≥

≥

l(n

10

1)

−

−

−

−

−

−

∗

Proof of Theorem 1.5. By Lemma 3.12 and
that d

3n(x,y), it is easy to see
x
C. Therefore what is left to show is dimAR(SC, d2) > 2 ln 5/(ln 3 +

≍

−

y

C

|

|

∗ ∼QS | · |

ln 5). But it is known that dimAR(SC, d2)
1 + (ln 3/ ln 2) (see [19] and [20] for
example). Since 1 + (ln 3/ ln 2) > 1.5 > ln 5/(ln 3 + ln 5), we have the desired
inequality.

≥

Remark. By Theorem 3.2, Lemma 3.6 and Proposition 3.7, we can also see
R∗

C and so dimAR(G∗, R∗) = dimAR(G∗,

).

C) = dimAR(G∗, d
∗

| · |

∼QS | · |

18

4 Scale symmetric case: Proof of Theorem 1.6

In this section, we will prove the existence of a partition such that d satisﬁes
s
basic framework (Deﬁned in Deﬁnition 2.6), and d
2(N1, N2, N ) = ds(G, µ) < 2
under the assumptions of Theorem 1.6. This suﬃces to show Theorem 1.6.

Lemma 4.1. Under the same assumption as Theorem 1.6, there exists a par-
tition such that d satisﬁes basic framework.

Proof. For (x, y), (z, w)
between them, that is,

∈

E, dH ((x, y), (z, w)) denotes the Hausdorﬀ distance

(d(x, z)

d(x, w))

(d(y, z)

∧

∨

∧

d(y, w))

d(y, z))

∨

(d(x, w)

d(y, w)).

.
Then dH is the distance on E/
}
Since d is metric doubling (which follows form Ahlfors regularity) and (G, E) is
bounded degree, dH is also metric doubling. Fix some w
and applying
[8, Theorem 2.2], we obtain C1, C2 > 0, r
such that
and Q :

∗ ∈
(0, 1), (T )k =

∼
wk
n}n
∈

(z, w) if

z, w

x, y

E/

E/

E/

∼

∼

∼

⊂

A

∈

{

{

}

{

N

(d(x, z)

∨

∧
where (x, y)

∧
=

⊔k

∈

Z(T )k → {

⊂
wk

∼}
1 = w
∗

, E/

=

∼

Qwk

n

,

n, C1rk)
BdH (wk
k, then either Qwl

⊂

Qwk

n ⊂

Qwk

n

m ⊂

if l

≥

for any k
denotes the unique vertex in (T )k

Z and any n, m

∈

∈

N. Let T =

⊔k
1 and Kwk

n

−

N
Gn
∈
BdH (wk
or Qwl

n, C2rk),
Qwk

=

n

m ∩

∅
Z(T )k. For any wk
∈
denotes the set

n ∈

T, π(wk
n)

Kwk

n

=

x

{

|

(x, y)

Qwk

n

∈

for some y

,

G
}

∈

then (T, π) is a bi-inﬁnite tree and K is a partition of (G, E). Moreover, by
deﬁnition of dH , there exist C3, C4 and xk

G such that

n ∈

Bd(xk

n, C3rk)

Kwk

n ⊂

⊂

Bd(xk

n, C4rk)

(4.1)

0 and n

for any k
≤
Fix any x, y
some N such that x1 = x, xN = y and (xj , xj+1)
(G, d) is metric doubling and (4.1) holds,

N. Here we check that K satisﬁes the basic framework.
Bd(x, rk) for
xj}
{
E for any j < N. Since

G with d(x, y) < rk, then there exist

N
j=1 ⊂

∈

∈

∈

M := sup
G

x

∈

sup
k

#
{

wk

n ∈

(T )k |

B(x, rk)

Kwk
n 6

=

∩

<

.
∞

∅}

This shows U d
1(x, C1rk)
M
from metric doubling condition and (4.1).

⊃

−

Bd(x, rk), and the other properties also follow

Note that we can choose r > 0 such that Te =

0(T )k.

⊔k

≤

Proposition 4.2. For ﬁxed N
k0 and w = wl
rkα for any k

≥

≥
n ∈ ⊔l

M , There exists k0 such that

E2,k,w(0, N, 1) &

k(T )l.

≤−

19

v

∈

Γn(w) Kv for any w

Te. By [16, Lemma 6.6 of the
Proof. Write
Nn(w) =
arXiv version] and ewtric doubling property of d, it follows that for ﬁxed c > 1,
R(Bd(x, φ), Bd(x, cφ))
G. This and (4.1) show that
N1(w)c)
R(Kw,
≍
(G, µ, A, B) =

φα for any φ
NN (w)c)
m

1 and x
≥
r[w]α for any w

P
≍
R(Kw,

Te. Let

≍
N, there exist x0 ∈

m
j=1 |

xj}

{{

B

∈

∈

∈

C

∈
A, xm ∈
E for any 0

such that (xj, xj+1)

∈

j

m

,

}

≤

≤

(G, µ, A, B) =

f : G

{

F

f (x)µx ≥

1 for any

xj}

m
j=1 ∈ C

{

(G, µ, A, B)
}

,

(G, µ, A, B) = min
{

M

f

(G, µ, A, B)
}

∈ F

(it exists),

m

R

→
|
1
X
f (x)2µx |

G
Xx
∈

for any A, B
that R(A, B)−
(Qw,N,k) instead of the quadruple

G with A

≍ M

⊂
1

∩

. Then by the condition (p0), we know
(G, µ, A, B) for any A, B. For the rest of proof, we write

B =

∅

((T )[w]+k, µ((T )[w]+k,J h

[w]+k), Sk(w), Sk(ΓN (w)c))

∈ ⊔l

for simplicity. Then in the same way we know that
for any w

E2,k,w(0, N, 1)
NN (w)) & r[w] for any w
−
N1(v)
is k0 ≥
Kw or
N1(v)
[w].
(T )[w]+k with ko ≤
any w
∈
Hereafter, we ﬁx such w. Let gv be the optimal function for
with v

(Qw,N,k)
k(T )l, which follows from uniformly ﬁniteness of the partition.
Te, so there
∩ NN (w)c is the empty set for
k
N1(v)c)

≤−
Since K is adapted for M
0 such that either
k0 (T )l and v
∈ ⊔l

(G, µ, Kv,
R by

(Qw,N,k) we deﬁne g : G

Sk(ΓN (w)). For f

1, d(Kw,

≍ M

≤ −

M

≤−

∈

∩

∈

g(x) = max
{

{

m
Fix any
xj}
j=1 ∈
we inductively set j1 = min
xja−
satisfying
{
easy that
va}
{
j < ja |
la = max
ja−

1, xja } ∈
b
a=1 ∈ C

xj 6∈ N1(va)
}

{

1

,

∈ F
f (v)gv(x)

v

→
(T )[w]+k such that x

∈ N1(v)
}

.

∈

|
NN (w)c) and x0, xm+1 in the deﬁnition, then
C(G, µ, Kw,
(T )[w]+k be the vertex
xj
Kw}
, va ∈
j
|
. Here it is
j
xj
Kva, and ja = min
|
{
(Qw,N,k) for some b. If
, then for
N1(va)

Kva−1}
Kw =

6∈
∩

6∈

∅

{

1

ja−

f (va)

g(xj)µxj ≥

gva (xj)µxj ≥

f (va)

and the case of

∩ NN (w)c =

∅

Xj=la+1
N1(v)

Xj=la +1
is similar. Therefore

m

j=1
X

L2
∗

b

L

g(xj)µxj ≥

a=1
X
(T )[w]+k |

f (va)

∗

1

≥

x

∈ N1(v)
}

, and the uniformly

where L

= supk

k0,x

≥

G #
{

v

∈

∈

∗

20

ﬁniteness assures L

<

∗

. Therefor we obtain that

C−

1r−

[w]α

∞
(G, µ, Kw,

NN (w))
L5
∗

g(x)2µx ≤

([w]+k)α

≤ M
L4
∗

≤

L5
∗

≤

Xx
G
∈
Cr−

Xv
∈
for some C > 0. This concludes the proof.

(T )[w]+k

f (v)2

gv(x)2µx

Xv
∈

(T )[w]+k
f (v)2µ((T )[w]+k,J h

G
Xx
∈

[w]+k)(x)

Proposition 4.3. For ﬁxed N
k0 and w = wl
rkα for any k

≥

≥
n ∈ ⊔l

k(T )l.

≤−

M , There exists k0 such that

E2,k,w(0, N, 1) .

Proof. We use the argument of ﬂow. By [4, Lemma 2.5], there exist C, C′ > 1
such that for any k
, there exists a unit
≤
ﬂow fu,v from u = wk
a to v (as points of G) satisfying fu,v(x, y) = 0 whenever
a, Crk), and
Bd(xk
x, y

(T )k with Ku ∩

0 and u, v

Kv 6

=

∈

∅

{

} 6⊂

1
2

X(x,y)
∈

E

fu,v(x, y)2µxy ≤

C′rkα.

Additionally, since (G, d) is metric doubling,

M ′ := sup
{

#
{

(wk

a, wk
b )

J h
k |

x

∈
same as Lemma 4.1. Similar to Lemma 3.5 and Proposition 4.2, this shows

} |

∞

≤

∈

∈

}

Bd(xk

a, Crk)

x

G, k

0

<

C−

1r[w]α

1
2

≤

f (x, y)2µxy ≤

Cr([w]+k)α

E2,k,w(0, N, 1)−

1

X(x,y)
∈
for some C > 0. This concludes the proof.

P

[w])

E2,k,w(0, N, 1) . r((

Proof of Theorem 1.6. Let N be suﬃciently large. By Propositions 4.2 and 4.3,
it is easy that
k(T )l.
∈
1. Therefore
Considering the resistance restricted on a path, we know that α
R2(0, N, 1) = rα. On the other hand, N
µ(Bd(x, n)), (4.1),
≍
s
∗
and d is uniformly ﬁnite. Therefore d
2(0, N, 1) = 2β/(α + β) = ds(G, µ) < 2,
where the third equation follows from [4, Theorem 1.3]. This with Theorem 2.8
suﬃces to prove the statement.

Tr \ ⊔l
≤

β because nβ

0) for w

rk+([w]

= r−

≤−

0)α

−

∨

∧

·

A Proof of RSC

n & RSC
n,pt.

Let ϕ(A) =

j=1ϕj(A), Dn = ϕn(
8
{
∪
Dn ×

Bn =

(x, y)

∈

{

p0, p2, p4, p6, p8}
x

y

Dn | |

−

|

) and

= 3−

n2−

1

.

}

21

We say g : Dn →

R is harmonic on A

Dn if

g(x) = (#
{

y

|

(x, y)

Dn}

∈

)−

g(y)

for any x

A.

∈

⊂
1

Xy:(x,y)
∈

Dn

In this section, we will use the following fact which can be proved in a similar
way to [1, Theorem3.1] (see also [3, Theorem 4.4]).

Proposition A.1 (Harnack’s inequality for the graphical Sierpi´nski carpet).
0 and any nonnegative harmonic function
There exists C > 0 such that any n
f on
Dn ∩
Proof of Proposition 3.3. As we mentioned before, it suﬃces to show RSC
RSC

f (y) for any x, y

n,pt. Let ˜Rn and ˜Rn,

z
{
∈
ϕ1(I).

satisfy cf (x)

Dn |

n &

denote

≥
= 1

Im(z)

Re(z)

2 }

≥

∈

∨

△

Ir),

˜Rn = R(Dn,Bn)(Dn ∩
˜Rn,
p1 +
= R(Dn,Bn)(
{

Il, Dn ∩
√
1
, Dn ∩ {
3n , p1 +
−
2
·
respectively (see Figure A.1). It is easy to see that ˜Rn ≍
Let gn be the optimal function for ˜Rn,

1
3n }

2

△

z

·

, then gn is harmonic on

△

Re(z) + Im(z) = 0

)

}

|

RSC

n and ˜Rn,

RSC

n,pt.

△ ≍

Dn ∩ {

z

|

Re(z) + Im(z) < 0

p1 +

} \ {

√
2

1
3n , p1 +
−
·

1
3n }

·

2

and gn(p1 + √
1
3n ) = 1
)−
3n )
−
−
2
2
−
△
·
·
that ˜Rn+k,
2 ˜Rn
n,ptRSC
n+k,pt & RSC
0 (RSC
△ ≥
existence of k), and deﬁne the function hn on Dn+k+2 by

gn(p1 + 1
2
·
for any n

3n + √

2 ( ˜Rn,

≥

△

k

1

1. Here we ﬁx k
and ρn

≥
RSC
n

0 such
assure

≍

hn(x) =

˜Rn+k+2,
˜Rn+k+2,

(

△ ·
△ ·

gn+k+2(x)
gn+k+2(x)

−

˜Rn+2,

△ ·

gn+2(ϕ−

k
1 (x))

1(I)

ϕk

if x
∈
otherwise.

Then hn is harmonic on Dn+k+2 ∩
Dn+k+2 ∩
any x
∈
exists C > 0 such that

), especially on
0 for
0
Dn+k+2 with Re(x) + Im(x) = 0, hn is nonnegative. Therefore there

(I). Moreover, since hn(x) = ˜Rn+k+2,

Re(z) + Im(z) < 0

gn+k+2(x)

ϕk+1
1

△ ·

≥

−

}

z

|

ϕk
1(
{

Chn(x)

≥

hn(p1 +

1
3n )

·

2

˜Rn+2,

△

≥

for any x

Dn+k+2 ∩

∈

ϕk+2
1

(I)

because of Proposition A.1. This shows

R(Dn+k+2,Bn+k+2)(ϕk+2
C−

1
)2(2(( ˜Rn+k+2,

(Dn), ϕk+2
)2

(Dn))
1 + ( ˜Rn+2,

−

5

)2

−

1))−

1

△

2( ˜Rn+2,
2 1
4

△
( ˜Rn+2,

≥

C−

≥

△

)2( ˜Rn+k+2,

)−

1.

△

△

22

6
On the other hand, by the potential argument as in [2, Theorem4.3], it follows
that

R(Dn+k+2,Bn+k+2)(ϕk+2

(Dn), ϕk+2

1
(D0), ϕk+2

5

(Dn))
5
(D0)) ˜Rn.

.R(Dk+2,Bk+2)(ϕk+2

1

3k
We also obtain that (2
resistance metric (see Figure A.2). Therefore we get

1)RSC

n,pt ≥

RSC

−

·

n+k,pt by the triangle inequality of the

RSC

n & RSC
n
−

2 & ˜Rn

−

2 & ( ˜Rn,

△

)2/ ˜Rn+k,

△

& RSC
n,pt

for any n

2.

≥

0

1

1

Re(z) = Im(z)

Figure A.1: ˜Rn,

△

Acknowledgments.

Figure A.2: RSC

n,pt & RSC

n+k,pt

I would like to thank my supervisor, Professor Takashi Kumagai for helpful
advice about structure of this paper.
This work was supported by JSPS KAKENHI Grant Number JP20J23120.

References

[1] M. T. Barlow and R. F. Bass, The construction of Brownian motion on the
Sierpi´nski carpet. Ann. Inst. H. Poincar´e Probab. Statist. 25 (1989), no.
3, 225-257.

[2] M. T. Barlow and R. F. Bass, On the resistance of the Sierpi´nski carpet.

Proc. Roy. Soc. London Ser. A 431 (1990), no. 1882, 345-360.

[3] M. T. Barlow and R. F. Bass, Random walks on graphical Sierpinski car-
pets. Random walks and discrete potential theory (Cortona, 1997), 26-55,
Sympos. Math., XXXIX, Cambridge Univ. Press, 1999.

23

[4] M. T. Barlow, T. Coulhon and T. Kumagai, Characterization of sub-
Gaussian heat kernel estimates on strongly recurrent graphs. Comm. Pure
Appl. Math. 58 (2005), no. 12, 1642-1677.

[5] M. Bonk and B. Kleiner, Conformal dimension and Gromov hyperbolic

groups with 2-sphere boundary. Geom. Topol. 9 (2005), 219-246.

[6] M. Bourdon and H. Pajot, Cohomologie ℓp et espaces de Besov. J. Reine

Angew. Math. 558 (2003), 85-108.

[7] J. Heinonen, Lectures on analysis on metric spaces. Universitext. Springer-

Verlag, New York, 2001.

[8] T. Hyt¨onen and A. Kairema, Systems of dyadic cubes in a doubling metric

space. Colloq. Math. 126 (2012), no. 1, 1–33.

[9] N. Kajino and M. Murugan, On the conformal walk dimension: Qua-
sisymmetric uniformization for symmetric diﬀusions. Preprint, 2020. arXiv:
2009.03595 [math.PR].

[10] J. Kigami, Analysis on fractals. Cambridge Tracts in Mathematics, 143.

Cambridge University Press, Cambridge, 2001.

[11] J. Kigami, Resistance forms, quasisymmetric maps and heat kernel esti-

mates. Mem. Amer. Math. Soc. 216 (2012), no. 1015.

[12] J. Kigami, Geometry and analysis of metric spaces via weighted partitions.

Lecture Notes in Mathematics, Springer, 2020.

[13] J. M. Mackay and J. T. Tyson, Conformal dimension. Theory and ap-
plication. University Lecture Series, 54. American Mathematical Society,
Providence, RI, 2010.

[14] I. McGillivray, Resistance in higher-dimensional Sierpi´nski carpets. Poten-

tial Anal. 16 (2002), no. 3, 289–303.

[15] F. Paulin, Un groupe hyperbolique est d´etermin´e par son bord. J. London

Math. Soc. (2) 54 (1996), no. 1, 50-74.

[16] K. Sasaya Ahlfors Regular Conformal Dimension of Metrics on Inﬁnite
Graphs and Spectral Dimension of the Associated Random Walks. To ap-
pear in J. Fractal Geom.
The preprint version is available in arXiv: 2009.03595 [math.PR].

[17] S. Semmes, Some novel types of fractal geometry. Oxford Mathematical
Monographs. The Clarendon Press, Oxford University Press, New York,
2001.

[18] P. Tukia and J. V¨ais¨al¨a, Quasisymmetric embeddings of metric spaces.

Ann. Acad. Sci. Fenn. Ser. A I Math. 5 (1980), no. 1, 97-114.

24

[19] J. T. Tyson, Sets of minimal Hausdorﬀ dimension for quasiconformal maps.

Proc. Amer. Math. Soc. 128 (2000), no.11, 3361-3367.

[20] J. T. Tyson and J. M. Wu, Quasiconformal dimensions of self-similar frac-

tals. Rev. Mat. Iberoam. 22 (2006), no.1, 205-258.

25

