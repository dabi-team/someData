COVINS:Visual-InertialSLAMforCentralizedCollaborationPatrikSchmuckThomasZieglerMarcoKarrerJonathanPerraudinMargaritaChli*VisionforRoboticsLab,ETHZurich,SwitzerlandABSTRACTCollaborativeSLAMenablesagroupofagentstosimultaneouslyco-localizeandjointlymapanenvironment,thuspavingthewaytowide-rangingapplicationsofmulti-robotperceptionandmulti-userARexperiencesbyeliminatingtheneedforexternalinfrastructureorpre-builtmaps.ThisarticlepresentsCOVINS,anovelcollab-orativeSLAMsystem,thatenablesmulti-agent,scalableSLAMinlargeenvironmentsandforlargeteamsofmorethan10agents.Theparadigmhereisthateachagentrunsvisual-inertialodometyindependentlyonboardinordertoensureitsautonomy,whileshar-ingmapinformationwiththeCOVINSserverback-endrunningonapowerfullocalPCoraremotecloudserver.Theserverback-endestablishesanaccuratecollaborativeglobalestimatefromthecontributeddata,reﬁningthejointestimatebymeansofplacerecog-nition,globaloptimizationandremovalofredundantdata,inordertoensureanaccurate,butalsoefﬁcientSLAMprocess.AthoroughevaluationofCOVINSrevealsincreasedaccuracyofthecollab-orativeSLAMestimates,aswellasefﬁciencyinbothremovingredundantinformationandreducingthecoordinationoverhead,anddemonstratessuccessfuloperationinalarge-scalemissionwith12agentsjointlyperformingSLAM.Keywords:CollaborativeSLAM,ComputerVision,Multi-AgentSystems,AugmentedandMixedReality,Large-scaleSLAMIndexTerms:Computingmethodologies—Artiﬁcialintelligence—Computervision—TrackingandReconstruction1INTRODUCTIONWithSimultaneousLocalizationAndMapping(SLAM)havingreachedsigniﬁcantmaturityandrobustness,notonlyithasstartedbeingemployedinmorecostumerproducts,butalsomorecomplex,multi-agentapplicationshavebeengainingtractionintheresearchcommunity.Sharinginformationamongstparticipantsanddivid-inguptasksbetweenmultipleagentspromisestoboostrobustness,efﬁciencyandaccuracyofaroboticmissioninvariousscenarios.Be-yondrobotics,recentlyemergingtechnologies,suchasAugmentedandVirtualReality(AR/VR)dependoncollaborativeperceptionsystemsinordertocreatesharedexperiencesformultipleusers.Par-ticularly,thisvisionofmulti-usersharedARcurrentlyexperienceshighattention,withcompaniessuchasMicrosoft,MagicLeaporNrealactivelyresearchinganddevelopingsuchsolutions.Similartosingle-agentscenarios,alargebodyofthecollaborativeperceptionliteraturefocusesoneithermapping[9]orlocalization[10]frommultipleagents.However,itisonlywhenaddressingbothchallengessimultaneously,thatcollaborativeSLAMcanhappen,andeventuallyenablethefullspectrumofpossibilitiesamulti-agentsystemhastooffer.Seamlessmulti-userARexperiencerequirescollaborativeSLAMformaximumﬂexibility,avoidingtediouspre-mappingorputtingupexternaltrackinginfrastructure,aswellastheefﬁcientdeploymentofroboticteamsinsearch-and-rescuesituations,wheregeneratinganinitialmapwouldsigniﬁcantlydecreaseresponsetime.*ThisworkwassupportedbySNSF(Agreementno.PP00P2157585)andNCCRRobotics.Figure1:CollaborativeSLAMestimatefrom12dronesﬂyingoveravillagescenerycoveringapprox.500m2with1750mtotaltrajectorylength.Redlinesindicateinter-trajectoryconstraints.Atthesametime,multi-agentSLAMposessigniﬁcantchallenges,suchasaccurateco-localization,ensuringconsistencywithmultipleagentssimultaneouslycontributinginformation,andmanagingscal-abilitywithregardtothelargeamountofcontributeddata.Severalworkshaveshowngoodprogresstacklingoneoremoreofthesechallengesoverthelastfewyears[3,11,12,18,19].However,col-laborativeSLAMisarelativelyyoungresearchﬁeld,albeitaverypromisingone.Inthisspirit,thisworkpresentsCOVINS,acollabo-rativeVisual-Inertial(VI)SLAMsystem,enablingagroupofagents,eachequippedwithaVIsensorsuite,toestablishcollaborativesceneunderstandingonlineduringamission,throughco-localizationandjointcreationofaglobalmapoftheenvironment.Togetherwiththeabilitytosharedatathroughtheserver,thisprovidesthebasistode-ploycoordinatedmulti-robotmissionsandsharedARexperiences.ThecoreofCOVINSconstitutesacomprehensiverevisionofawell-establishedarchitectureapproachformulti-agentSLAM[11]aswellasoftheindividualsystemmodules,distillingthebestaspectsofthehighestperformingmodulesfromthestateoftheart,revisitingthekeyideasbehindthem,aswellastheirinteraction.Thistranslatesintoincreasedversatilityandefﬁciencyoftheframework,anden-ablesscalabilitytolargergroupsofagents.Thisframeworkisshowntoachieveimprovedaccuracy,andallowstodemonstratecollaborateSLAMinascenariowithupto12agentscontributingsimultane-ouslytothesystem(Fig.1),whichtothebestofourknowledgeisthemostpopulousteamdemonstratingtoperformcollaborativeVISLAMtodate.TheimplementationofCOVINSwillbereleasedforpublicusewiththeﬁnalversionifthisarticle.2RELATEDWORKTheliteratureinmulti-agentperceptionsystemsdistinguishesbe-tweencentralizedanddistributedarchitectures.OneoftheﬁrstworkstotacklecollaborativeSLAMinafullydecentralizedmannerwasDDF-SAM[6],evaluatingroboticcollaborationinasimulatedsetupusingvisual,inertialandGPSdata.Choudharyetal.[4]showadecentralizedSLAMsystemwithpre-trainedobjectsenablingco-arXiv:2108.05756v1  [cs.RO]  12 Aug 2021localizationoftheparticipatingrobots.Cieslewskietal.[5]combinethisoptimizationapproachwithanefﬁcientandscalabledistributedsolutionforplacerecognition.Mostrecently,Lajoieetal.[12]andChangetal.[3]proposedsystemsfordistributedSLAMbothusingadistributedPose-GraphOptimization(PGO)scheme,demonstratingsuperiorperformancecomparedtotheGauss-Seidelapproachof[4].Whileenablingawiderangeofapplications,andgoodscalabilitytolargenumbersofagents,guaranteeingdataconsistencyandavoid-inginformationdouble-countingarethebiggestchallengesforthisarchitecture,whereascentralizedsystemshaveamorestraightfor-wardmanagementofinformation,andusuallyexhibitasigniﬁcantlyhigheraccuracy[2,11,15]thanstate-of-the-artdistributedSLAMapproaches,suchas[3,12].ZouandTanhaveintroducedCoSLAM[23],apowerfulvision-onlycollaborativeSLAMsystem,groupingcameraswithsceneoverlapinordertohandledynamicenvironments.Forsteratal.[7]demonstratedcollaborationofuptothreeUnmannedAerialVehicles(UAVs)byextendingaStructurefromMotion(SfM)pipelinetocollaborativeSLAM.WithC2TAM[16],Riazueloetal.proposedamulti-agentsystemperformingonlypositiontrackingonboardeachagent,whileallmappingtasksareofﬂoadedtotheserver,en-ablingagentstocopewithverylimitedcomputationalresources,however,therebyalsoheavilyrestrictingeachagent’sautonomy.CCM-SLAM[19]proposedtoefﬁcientlymakeuseoftheserverbyofﬂoadingcomputationallyexpensivetasks,whilestillensuringeachagent’sautonomyatlowcomputationalresourcerequirementsbyrunningavisualodometrysystemonboard.CVI-SLAM[11]ex-tendstheapproachof[19]toavisual-inertialsetup,enablinghigheraccuracyaswellasmetricscaleestimationandgravityalignmentofthecollaborativeSLAMestimate,demonstratedwithrealdatafromuptofouragents.However,whileitwastheﬁrstfullVIcollabora-tiveSLAMsystemwithtwo-waycommunication,CVI-SLAMalsohaspracticallimitations,suchaslimitedﬂexibility,e.g.intermsofinterfacingwithcustomVisual-InertialOdometry(VIO)front-ends,andintermsofscalabilitytolargerteams.TheabilitytoleverageVIOtoenableARexperienceswithmo-biledeviceshasbeenshownbymultipleworksoverthelastyears,suchas[13,15].Justrecently,Platinskyetal.[14]havedemon-stratedapipelinesupportingcity-scalesharedaugmentedrealityexperiencesonmobiledevices.However,theirapproachreliesontime-consumingandcostlypreparatorywork,comprisingextensivedatacollectionusingacar-basedplatformandofﬂinemapgenera-tion.Ontheotherhand,theconceptofspatialanchorscanenableadhocmulti-userAR,throughco-localizationwithrespecttothesameanchor.However,thisrequiresatleastcoarsepriorknowledgeofthelocationoftheusers,forexampleknowingalldevicesareinthesameroom,anddoesnotdirectlygiveindividualagentstheabilitytore-usemapscreatedbyotheragents.CollaborativeSLAMcanbridgethegapbetweenthesetwoapproaches,enablingsharedARexperienceinlargerenvironments,suchasentirefactoryhallsordepartmentstoresinanadhocfashion,onlyusingtheARdevices’built-insensorsandwithoutpre-mapping.Multi-agentglobalcollaborativeestimatessimilartothosefromcol-laborativeSLAMcanalsobeachievedbyrecentSLAMsystemswithmulti-sessioncapabilities,suchas[2,15].Theabilitytore-useSLAMmapscreatedinapreviousrunenablesmulti-sessionSLAMsystemstoachieveimpressivelevelsofrobustness[15]andaccuracy[2],outperformingthesingle-sessioncase.However,thecircumstancethatonlyoneagentatatimecanbeactiveinmulti-sessionSLAMheavilyrestrictsthelevelofcollaborationamongstagents,andthesituationthatallpartsofthesemulti-sessionSLAMsystemsrunonboardthesamecomputingunitpreventstoofﬂoadinformationandcomputationloadtoapowerfulserver.COVINSextendsthewell-establishedarchitectureforcollaborativeSLAMdeployedin[11]towardsamoreﬂexibleandefﬁcientsetup.Agentscanconnecttothesystemon-the-ﬂy,thenumberofagentsVIOLocalMapAgent 1CommKFsLMssharedinformationServerVIOLocalMapAgent nCommKFsLMssharedinformation...Comm 1PlaceRec.Server MapsServerMap 1x.. KFDatabaseMapFusionKFPruningMap ManagerAccessControllOptimizationGBAPGOcallExternalInterfaceMap accessMap / DB accessinteractComm nPlaceRec....Map dataMap datacallKFKFFigure2:OverviewoftheCOVINSsystemarchitecture.doesnotneedtobeknownapriori,andagenericcommunicationinterfaceallowstointerfacetheserverback-endwithdifferentVIOsystems.Moreefﬁcientmapmanagementandoptimizationschemesandastate-of-the-artredundancydetectionschemetranslateintoimprovedaccuracyandbetterscalability,allowingtodemonstratecollaborativeSLAMwith12agents,whiletothebestofourknowl-edge,otherrecentcollaborative[7,11,19]andmulti-session[2,15]SLAMsystemswithcomparableaccuracylevelaretestedwithnomorethanﬁveagentssofar.3PRELIMINARIES3.1Notation,IMUModelandSystemStatesInthiswork,weadoptthenotationfrom[11]formathematicalnotation.Small(e.g.a)andlarge(e.g.A)boldlettersdenotevectorsandmatrices,respectively.Coordinateframesaredenotedasplaincapitalletters(e.g.A).ForavectorxexpressedinA,thenotationAxisused.ArigidbodytransformationfromframeBtoAisdenotedasTAB,withtandRdenotingthetranslationalandrotationalpart,respectively.ThroughoutthisworkwedenotetheworldframeasW,theInertialMeasurementUnit(IMU)bodyframeasSandthecameraframeasC.InordertoincorporateIMUinformationintoCOVINS,wemodeltheIMUusingastandardmodel,assumingadditiveGaussiannoiseandunknown,timevaryingsensorbias(cf.[20]).ToaccountforthisIMUmodel,thesystemstateΘΘΘincludesbesidestheKeyframe(KF)posesandLandmark(LM)positionsalsothelinearvelocitiesWvaswellasthebiasvariablesforeachKFk:ΘΘΘ:={RkWS,tkWS,Wvk,bk|{z}KFk,Wli},∀k∈V,∀i∈L,(1)wherethesetsVandLdenotethesetofallKFsandLMs,respec-tively.Inthefollowing,wheneverthecontextallowsforit,weuseθjtodenoteanindividualstatevariable.4METHODOLOGY4.1SystemOverviewThesystemarchitectureofCOVINSisillustratedinFig.2.RunningaVIOfront-endmaintainingalocalmapoflimitedsizeonboardeachagentensuresbasicautonomyoftheindividualagent.Atthesametime,globalmapmaintenanceandcomputation-heavypro-cessesaretransferredtothemorepowerfulserver.Thisunderlyingarchitecturalprinciplewasﬁrstintroducedin[17],whichisex-tendedtoamoreﬂexibleandefﬁcienthandlingandmaintenanceofcollaborativemapdataontheserverinthiswork.Onboththeagents’andserver’ssides,wedeployacommunicationmodulefordataexchange.Thecommunicationmoduleestablishespeer-to-peer(p2p)connection,allowingtheservertorunonalocallydeployedcomputeraswellasonaremotecloudservice,asdemonstratedinSec.5,furthermoreremovingthepreviousROSdependencyofthecommunicationmodulein[11].COVINSimplementsandex-portsagenericcommunicationinterface,providingthefreedomtointerfaceitwithanycustom-builtkeyframe-basedVIOsystem,inordertoenablecollaborationamongstmultipleagents.Thecoreoftheservermodulesformsamapmanager,whichcontrolsaccesstotheglobalmapdatapresentinthesystem.Itmaintainsthismapdatainoneormultiplemaps,aswellasaKFdatabaseforefﬁcientplacerecognition.Moreover,itprovidesalgorithmstomergemapsonceoverlapisdetectedandthefunctionalitytoremoveredundantKFs,altogetherfacilitatingdataroutingcomparedto[11].PlacerecognitionmodulesprocessallincomingKFsfromtheagentstodetectvisualoverlapbetweenre-visitedpartsoftheenvironment.Asopposedto[11],COVINSdoesnotdistinguishbetweendifferentplacerecognitionmodulesforeitherloopclosureormapfusion,soasingleplacerecognitionqueryforaKFtriggersbothevents,reducingworkloadandsystemcomplexity.Theserver,furthermore,providesoptimizationroutines,namelyPose-GraphOptimization(PGO)andGlobalBundleAdjustment(GBA).Incontrastto[11],COVINSimplementsanoptimizationstrategyregularlyperformingPGO,whileexecutingGlobalBundleAdjustment(GBA)tofurtherreﬁnemapslessfrequently,inordertobetterbalancerestrictedmapaccessduetoongoingoptimizationwithdesiredhighmapaccuracy.Inaddition,theserverprovidesanexternalinterface,allowingausertointeractwiththesystem.4.2MapStructureThemapstructureusedbytheserverback-endofCOVINS(termedservermap)maintainsthedataofthecollaborativeestimationpro-cess.AservermapMxisaSLAMgraph,holdingasetVxofKFsandasetLxofLMsasvertices,andedgesinducedeitherbetweentwoKFsthroughIMUconstraintsorbetweenaKFandaLMasalandmarkobservation.Whilemultipleagentscancontributetooneservermap,multipleservermapsexistsimultaneouslyuntilallpar-ticipatingagentsareco-localized.TogetherwiththestatedeﬁnitionfromSec.3.1,thisunderlingSLAMestimationprobleminducesafactorgraph[20],whichformsthebasisoftheGBAschemeexplainedinSec.4.8.ThesharedLMobservationscreatedependen-ciesbetweenKFsfrommultipleagents,whileIMUfactorsareonlyinsertedbetweenconsecutiveKFscreatedbythesameagent.InanARuse-case,themapwouldfurthermorestoreARcontentcreatedbyuserscontributingtothismap.4.3ErrorResidualsFormulationByformulatingasetofresiduals,theoptimizationofstatevariablesoccurringinKF-basedVISLAMcanbeexpressedasaweightednonlinearleast-squaresproblem.Eachsuchresidualeiexpressesthedifferencebetweentheexpectedmeasurementbasedonthecurrentstateofthesystemandtheactualmeasurementzi:ei:=zi−hi(Ai),(2)whereAiisthesetofstatevariablesθjrelevantformeasurementzi,andhi(·)isthemeasurementfunction,predictingthemeasurementaccordingtothesestatevariablesinAi.Bycollectingalloccurringresidualterms,theobjectiveoftheoptimizationcanbeexpressedas:ΘΘΘ∗=argminΘΘΘ(∑ikzi−hi(Ai)k2Wi),(3)wherekxk2W=xTWxdenotesthesquaredMahalanobisdistancewiththeinformationmatrixW.Withinoursystem,weessentiallyusethreedifferenttypesofresiduals:reprojectionresidualser,rela-tiveposeresidualse∆T,andIMUpre-integrationresidualseIMU.Adetaileddescriptionoftheindividualresidualscanbefoundin[20].4.4Visual-InertialOdometryFront-EndCOVINSisabletogenerateaccuratecollaborativeglobalestimatesfrommapdatacontributedbyakeyframe-basedVIOsystem(alsoreferredtoasVIOfront-end).Toenablethesharingofmapinfor-mationbetweenthisVIOfront-endrunningonboardtheagent,andtheserver,thisframeworkprovidesacommunicationinterfacethatenablesthecombinationoftheserverback-endwithanyindirectVIOsystem(i.e.usingfeature-basedlandmarkcorrespondences,requiredforthereprojectionresiduals)asexplainedinSec.4.5.ForhandlingtheinertialdatainGBA,weusetheestimatesofthemetricscaleaswellastheIMUbiasesandthevelocitiesoftheVIOasaninitializationpoint.InordertoevaluatetheperformanceofCOVINS,intheexperimentsconductedforthispaper,weemploytheVIOfront-endofORB-SLAM3[2],asanominalopen-sourceoption.4.5CommunicationThecommunicationmoduleisbasedonsocketprogrammingusingtheTCPprotocol,andtheheader-onlylibrarycereal[22]fortheserializationofmessages.ThisallowstodeploytheserveronalocalcomputationalunitaswellasonremotecloudserversThecom-municationmoduleontheserversidelistenstoapre-deﬁnedportforincomingconnectionrequestsbytheagents,allowingthemtojoindynamicallyduringthemissionwithoutanypriorspeciﬁcationofthenumberofparticipatingagents.AgenericcommunicationinterfaceforusageontheagentsideisexportedbyCOVINSasasharedlibrary,enablinganexistingVIOsystemtosharemapdatawiththeserverback-endusingpre-deﬁnedKFandLMmessages.4.5.1Agent-to-ServerCommunicationForsharingmapdatafromtheagenttotheserver,COVINSadoptstheefﬁcientmessagepassingschemefrom[19],whichaccountsforstaticpartsofKFandLMs,suchasextracted2Dfeaturekeypointsandrelateddescriptors,andensuresthisinformationisnotrepeatedlysent,inordertoreducetherequirednetworkbandwidth.Thecom-municationschemedistinguishesbetweenso-called‘full’messages,comprisingallrelevantinformationforaKFandLM,includingalsostaticmeasurements(e.g.2Dkeypoints),andsigniﬁcantlysmallerupdatemessages,whereonlychangesinthestate(e.g.modiﬁedKFpose)aretransmitted.Allmapdatatobesharedwiththeserverisaccumulatedoverashorttimewindow,andcommunicatedtotheserverbatch-wiseataﬁxedfrequency.Thecommunicationcounter-partontheserversideintegratesthetransmittedmapinformationintothecollaborativeSLAMestimate.4.5.2Server-to-AgentCommunication(MapRe-Use)ThecommunicationinterfaceofCOVINSsupportstwo-waycom-municationbetweentheagentsandtheserver,inthisarticleappliedtoestimatethedriftofanagent’sVIO.Ontheserver,driftcanbeaccountedforonaglobalscopethroughloopclosureandsubsequentoptimization-basedmapreﬁnement.Inordertoenabletheagenttoalsoaccountforthisdrift,weregularlysharetheserver’sestimatedposeofthemostrecentlycreatedKFofanagentwiththisagent.Comparingthisdrift-correctedposeestimatefromtheserverwiththeestimatedposeoftheKFinthelocalmapallowstoestimatealocalodometrytransformationTodomonboardtheagent,quantifyingthedriftinthecurrentposeestimate.Withthisscheme,themapofthelocalVIOisnotmodiﬁed,leavingthesmoothnessoftheVIOunaffected,whichisofsubstantialimportance,forexamplewhenusingtheposeestimateinafeedbacksystemforcontrollingarobot.4.6Multi-MapManagementThemapmanagermaintainsthedatacontributedbyallagentsinoneormoreservermaps,asdescribedinSec.4.2.Anewmapisinitializedforeveryagentthatentersthesystem.Assoonasplacerecognitiondetectsoverlapbetweentwodistinctmaps,themapfusionroutineofthemapmanageristriggered.Furthermore,themapmanagerholdsandmaintainstheKFdatabasenecessaryforefﬁcientplacerecognition.BesidesprovidingroutinesformapfusionandgraphcompressionthroughremovalofredundantKFs(Sec.4.8),themapmanagerisinchargeofcontrollingaccesstotheservermapsandtheKFdatabase,inordertoensureglobalconsistency.Storingallmapsatacentralpointinthesystemwithindividualmodulesrequestingaccesstoeitherreadfromoralsomodifyaspeciﬁcmapfacilitatestocoordinatemapaccessfromdifferentsystemmodulesinordertokeepmapsconsistent,e.g.whenmultipleagentscontributetoasingleservermap,ortorestrictmapaccessinordertoperformmapfusionoroptimization.4.7PlaceRecognition,LoopClosure&MapFusionTodetectrepeatedlyvisitedlocationswithhighprecision,weemployastandardmulti-stageplacerecognitionpipelinewhichwebrieﬂysummarizehere.ForaqueryKFKFq,abag-of-wordsapproach[8]isemployedtoselectasetCofpotentialmatchingcandidatesfromallKFsinthesystem.AfterestablishingfeaturecorrespondencesbetweenKFqandallKFsinC,a3D-2DRANSACschemefollowedbyareﬁnementstepminimizingthereprojectionerrorisappliedtoﬁndarelativetransformationTTTcqbetweenKFqandapotentialmatchKFc∈C.Finally,TTTcqisusedtoﬁndadditionalLMconnectionsbetweenKFqandKFcAplacerecognitionmatchisaccepted,ifforaKFcthroughoutallstages,enoughinliersarefound.InthecasethatKFqandKFcarepartofthesameservermap,weperformloopclosure,carryingoutaPGOinordertooptimizetheposesoftheKFsinthemap,improvingaccuracyandreducingdriftintheestimate.InthecasethatKFqandKFcresideindifferentservermaps,themapfusionroutineofthemapmanageristriggered,aligningthemapMqofthequeryKFandthethemapMcofthecandidateKFusingTTTcq,ﬁnallyreplacingbothmapswithonenewservermapMcqcontainingallKFsfromMqandMc.ThisinvolvesalsothefusionofduplicateLMs.Intheprocess,potentialARcontentinMqwouldbetransformedintothecoordinateframeofMcq,andcombinedtogetherwiththeARcontentcontainedinMc.Thisalsoentailsthataftermapfusion,ARcontentofMcisnowavailabletoalluserspreviouslyassociatedtoMq,andviceversa.4.8MapReﬁnement4.8.1Pose-GraphOptimizationPGO1isappliedtoamapwhenanewloopconstraintbetweentwoKFsisaddedtothismapaftersuccessfulloopclosuredetection.WeusethefollowingobjectivefunctionforPGO,optimizingtheposeofallKFsoftheservermap:JPGO(ΘΘΘ):=∑i∈V∑j∈Vx(i,j)·kei,j∆Tk2W∆T,(4)wherex(i,j)isanindicatorfunctiondeﬁnedbyx(i,j)=(1,ifi<jand{i,j}∈(E∪Q)0otherwise(5)ande∆TdenotestherelativeposeresidualsandW∆Ttheinformationmatrixoftherelativeposeconstraints(Sec.4.3).ThesetsEandQdenotethecovisibilityedgesbetweenKFsandloopclosureedges,respectively.Aftertheoptimization,thepositionsofallLMsintheservermaparepropagatedusingtheoptimizedKF-poses.4.8.2GlobalBundleAdjustmentCOVINSperformson-demandGBA,e.g.attheendofthemissionwhentheagentsarenotactivelysendingfurtherinformationtotheserver.Thiscreatesahighlyaccurateestimate,whichcanbere-usedinamulti-sessionfashionforfurthercollaborativeSLAMsession.Foraspeciﬁcservermap,weperformGBAtakingintoaccountallKFsandLMsinthemap,usingthefollowingobjectivefunction:1AlloptimizationschemesofCOVINSusetheCeressolverJGBA(ΘΘΘ):=keeecpk2WWWcp+∑k∈V∑j∈L(k)δ(cid:16)keeek,jrk2WWWk,jr(cid:17)(6)+∑k−1,k∈V(cid:18)keeek−1,kIMUk2WWWk−1,kIMU+keeek−1,kbk2WWWk−1,kb(cid:19),wheretheﬁrsttermcorrespondstoaprioraddedtotheﬁrstKFinordertoremovetheGaugedegreeoffreedom,andL(k)denotesthesetofLMsobservedbyKFk.Thefunctionδ(·)denotestheuseofarobustcostfunctiontoreducetheinﬂuenceofoutlierobserva-tions,inourcasetheCauchylossisused.ThetermserandeIMUcorrespondtothereprojectionandIMUpre-integrationresiduals(Sec.4.3)Thetermek−1,kbpenalizeschangesinthebiasvariablesbetweensuccessiveKFs.Aftertheoptimization,aoutlierswithlargereprojectionresidualsareremovedfromthemap.NotethattheIMUconstraintsinEq.(6)areonlyinsertedbetweenconsecutiveKFscreatedbythesameagent.4.8.3RedundancyRemoval(KFPruning)CreatingalargenumberofKFsisbeneﬁcialforVIOtoachieveahighlevelofrobustnessandaccuracy.However,fortheglobalSLAMestimate,anincreasingnumberofKFsresultsinincreasingruntimeoftheemployedalgorithms,notablyoftheoptimizationalgorithms,scalingcubicwiththenumberofKFsintheworstcase.Therefore,itisdesirabletoremoveredundantKFsfromtheSLAMgraphtoincreasescalabilityofthesystem.Forthisreason,weem-ploythestructure-basedheuristicintroducedin[18]toidentifyandremoveredundantKFs.TheunderlyingassumptionoftheheuristicisthatwithincreasingnumberofobservationsofaspeciﬁcLM(bydifferentKFs),theinformationgainedbyanindividualobservationdecreases.Therefore,withobs(LMi)denotingthenumberofobser-vationsofLMi,afunctionτ(x):N0→[0,1]assignsavaluetoeachLMdependingonitsnumberofobservations,withincreasingnum-berencodingincreasingredundancyofanindividualobservationofthisLM.Thecompletedeﬁnitionofτcanbefoundin[18,20].UsingL(k),thesetofLMsobservedbyKFk,wecancalculatearedundancyvalueφ(·)foreachKFkinthemapasφ(KFk)=1|L(k)|∑i∈L(k)τ(obs(LMi))(7)Thisway,assigningavaluetoeachKFestimatingitsinformationcontributedtotheSLAMestimate,themostredundantKFscanberemovedfromtheestimate.RedundancyremovalisperformedbeforeGBA,sincethetimingofGBAisaffectedthestrongestbythenumberofKFs.LMpruningisimplicitlyhandled:wheneveraLMbecomesunder-observed(i.e.lessthan2observations),eitherfromremovalofoutlierobservationsorthroughremovingKFs,thisLMisremovedfromthemap.5EXPERIMENTALRESULTSWeevaluateCOVINSinathoroughtestbedofexperiments,in-vestigatingitsaccuracyusingtheEuRoCbenchmarkdataset[1]employingalocalPCaswellasanAmazonWebServices(AWS)cloudserver(Sec.5.1),scalabiltyinlarge-scaleexperimentswith12agents(Sec.5.2),driftcorrection(Sec.5.3),theinﬂuenceofthere-dundancyremoval(Sec.5.4)andcommunicationstatistics(Sec.5.5).Allresultswereobtainedbyre-playingdatainreal-time,andvaluesinthissectionareaveragedover5runsforeachexperimentifnotstatedotherwise.Fortheseexperiments,thefollowingsetupisused:•LocalServer:LenovoT480s(1.80GHz×8(max4.00GHz))•CloudServer:AWSc5a.8xlarge(32vCPUsat3.3GHz)•Agents:IntelNUC7i7BNHwith3.5GHz×4Throughoutallexperiments,thepre-recordeddatasetsareprocessedonboardtheagents,whichareconnectedtotheserverviaawirelessnetwork,sothatrealcommunicationtakesplace.ThismakesourFigure3:CollaborativeSLAMestimatewithﬁveagentsusingEu-RoCMH1-MH5.Top:Agentsceneviews.evaluationacrossdifferentrunsmorecomparableandprovidesuswithgroundtruth,whilestillusingrealnetworkcommunicationasitwouldbethecaseduringareal-worldapplication.5.1CollaborativeSLAMEstimationAccuracyWeevaluatetheaccuracyoftheglobalcollaborativeSLAMestimateofCOVINSusing[1],whereweusetheﬁveMachineHall(MH)sequences,andthethreeViconRoom1(V1)sequencestoestablishacollaborativeestimationscenariowiththreeandﬁveparticipatingagents.AglobalestimatejointlycreatedbyﬁveagentsisshowninFig.3.Table1reportstheaccuracyofthealignedglobalestimateintermsofabsolutetrajectoryerror(ATE)andscaleerror,aswellasacomparisontoORB-SLAM3[2],VINS-mono[15](bothhavingmulti-sessionfunctionalities)andCVI-SLAM[11]usingtheLocalServerforallexperiments.COVINSshowsgenerallyhighaccuracyacrossalldatasets,achievingsimilarorbetterperformancethanthestateoftheart.ThehighqualityofCOVINS’estimateinmulti-agentscenariosisduetothefactthattheframeworkisabletoestablishalargenumberofaccurateconstraintsbetweenthedatacontributedbytheindividualagents,asvisiblefromFig.3,wheretheredlinesencodecovisibilityedgesbetweenseparatetrajectories.Further-more,Table1reportstheresultsforthesameexperimentalsetupforCOVINS,exceptthatanAWScloudserverisnowusedtoruntheserverback-endofCOVINS.Theaccuracyofthiscloud-basedestimationcollaborativeSLAMestimateissimilartotheaccuracyusingalocalserver,attestingtothecapabilityoftheCOVINSback-endtobeexecutedonremotecloudcompute,withpotentiallymuchhighercomputationalresourcesthanalocallydeployedPC.5.2Large-ScaleCollaborativeSLAMwith12AgentsInthisexperiment,weevaluatetheapplicabilityofCOVINStoalarge-scalesceneandalargeteamofparticipatingagents.Forthis,weuseanewlygenerateddatasetwith12UAVsequippedwithadownwardlookingcameraﬂyingoverasmallvillage.Inordertoobtainaccurategroundtruth,thedatasetwascreatedusingtheTable1:Multi-agentmapevaluation(ATEinm,scaleerrorin%),using[1](lowesterrorinbold).Thefront-endof[11]isnotabletotrackthehighlydynamicmotionsoftheV10xsequences,therefore,novaluesarereported.Lastrow:resultsontheAWScloudserver.SystemSequencesMH01-MH03MH01-MH05V101-V103CVI-SLAM[11]0.054(0.47%)0.091(1.02%)—(—)ORB-SLAM3[2]0.041(2.21%)0.082(1.13%)0.048(1.30%)VINS-mono[15]0.062(0.31%)0.100(0.08%)0.076(1.34%)COVINS0.024(0.24%)0.036(0.3%)0.042(1.01%)COVINSAWS0.025(0.36%)0.039(0.42%)0.049(1.81%)(a)FinalVIOestimatedlocation(gold)anddrift-correctedestimate(white)onboardtheagentonEuRoCMH3.(b)Drift-correctionaf-terloopclosure(MH5).Figure4:Driftcorrection,withgroundtruth(red),VIOtrajectoryes-timate(gold),anddrift-correctedestimate(white).Thestarindicatestheagent’scurrentposition.Thegreencirclemarkstheorigin.visual-inertialsimulatorfrom[21],creatingphoto-realisticvisiondatasetsforUAVﬂightsusingahigh-quality3Dmodelofthescene.Itcomprises12circularUAVtrajectoriesof20mradius,coveringanareaofabout500m2with1750mtotaltrajectorylength.Fig.1showstheﬁnalcollaborativeestimategeneratedbyCOVINS,consistingofover3200KFsandabout200kLMs.TheaverageATEoftheestimateis0.050m,theaveragescaleerroris0.44%.Anillustrationofthe3Dsceneisshownin[20]andtheaccompanyingvideo2.5.3DriftCorrectionFig.4visuallydemonstratestheeffectofthedriftestimationandcorrectionscheme.Fig.4ashowstheﬁnaltrajectoryestimatedbytheagent’sonboardVIOsystemusingtheMH3sequence.Notethatalthoughthefulltrajectoryisdisplayed,thistrajectorywasnevergloballyoptimizedbytheagentitself.AsvisiblefromFig.4a,theestimatedtrajectory(gold)isaffectedbysomedrift,sothatthees-timatedﬁnallocationoftheagentdeviatesfromthetruelocation(red).However,basedonthecontinuousestimationofthedriftusingtheinformationreceivedfromtheserver,theagentcanestimateacorrectedtrajectory(white),beingnoticeablyclosertothetruetrajectory.AsimilareffectcanbeseenfromFig.4b,whichreﬂectsasnapshotoftheVIOestimateduringanexperimentusingtheMH5sequence,withthegreenboxhighlightingasigniﬁcantdriftcorrec-tionwithinformationreceivedfromtheserverafterloopclosure.5.4RedundancyDetection&RemovalUsingthemapscreatedduringthe5-agentexperimentsinSec.5.1,weevaluatetheinﬂuenceoftheredundancydetectionschemeim-plementedinCOVINS.Theevaluationisperformedasfollows:theﬁvemulti-agentmapscreatedduringtheﬁve5-agentexperimentsonMH1-MH5ofSec.5.1weresavedtoﬁlestorageaftereachex-periment,sothattheycanbereloadedintoCOVINSforfurtherexperiments.Foreachmap,whichcontainsonaverageapproxi-mately1700KFseach,areductionofthemapto1250,1000and750KFsisperformedinseparateexperiments.Theresults(averageATEoverallﬁvemaps)arereportedinTable2,demonstratingthatCOVINSisabletosigniﬁcantlyreducethenumberofKFsintheestimateatonlyasmalllossinaccuracyandasigniﬁcantreductionoftheGBAtime.Evenwhencompressingthemapbymorethan50%,themeanerrorincreasesbyonly7mm.Table2:Evaluationofredundancydetectiononthemapaccuracy.Num.KFs1681(init.state)12501000750ATE[m]0.0360.0390.040.043GBATime[s]1335334202https://youtu.be/FxJTY5x1fGE5.5CommunicationStatisticsTable3reportsthenetworktrafﬁcgeneratedbythecommunica-tionbetweenseverandagent.Eachagentinformstheserveratafrequencyof5Hzaboutnewandmodiﬁedmapdatasincethepreviouslysentdatabundle.Theserversharesinformationwiththeagentata2Hzfrequency.AsvisiblefromTable3,thegen-eratednetworktrafﬁcfromanindividualagenttotheserverliesapproximatelybetween400and600KB/s,whichcancomfortablybecoveredbytypicalWiFiinfrastructure.Morechallengingse-quencesrequireVIOtocreatemoreKFsforsuccessfuloperation,translatingtomoretransmitteddata(e.g.MH1(easiest):2.9KFs/screated,V103(hardest):6.9KFs/s).Thetrafﬁcfromtheservertotheindividualagentissigniﬁcantlylowerinourimplementation,sinceonlyposeinformationforasingleKFneedstobesharedforthedriftcorrectionscheme.Theaveragesizeoftheindividualmes-sagetypesisasfollows:KFfull:97kB;KFupdate:273byte;LMfull:162byte;LMupdate:65byte.Table3alsoreportsthetimingsTable3:Networktrafﬁcofagent-to-serverandvice-versa,andtotaltimeconsumedforcommunicationonboardtheagent,averagedoverall8EuRoCsequencesused,andforselectedindividualsequences.SequenceAgent→ServerServer→AgentCommTimeAvg.(8seq.)493.36kB/s2.31kB/s792.91msMH1422.83kB/s2.29kB/s939.92msMH5540.37kB/s2.32kB/s776.33msV103609.22kB/s2.31kB/s850.24msofthecommunicationmoduleontheagent.Withapproximately1softotalcommunicationtimeforeachsequence,andthesequencescontainingﬂightsbetween84s(V102)and144s(V101),theover-headofthecommunicationismarginal(<1%)comparedtothetotaltimeoftheestimationprocessanddoesnotcompromisethereal-timecapabilityoftheVIOsystem.6CONCLUSIONInthispaper,wepresentCOVINS,apowerfulandaccurateback-endforcollaborativeSLAM.COVINSallowsmultipleagentstogeneratecollaborativeglobalSLAMestimatesfromtheirsimultaneouslycontributeddataonlineduringthemission,eliminatingtheneedforexternalinfrastructureorpre-builtmapsinordertoenablemulti-agentapplications.TheefﬁcientarchitectureandsystemdesignofCOVINSallowsthisframeworktoprocessdatacontributedbymanyagentssimultaneously.OurexperimentsattesttothehighaccuracyofthecollaborativeSLAMestimatesinlarge-scalemulti-agentmissions,inparticulardemonstratingcollaborativeSLAMwithupto12agentscontributingtothesystem,which,tothebestofourknowledge,isthehighestnumberofparticipantsdemonstratedbyanycomparablesystemintheliterature.Boostingapplicabilityandscalabilityofthesystem,thisframeworkcanrunlocallyonaPCaswellasonaremotecloudserver,furthermore,supportedbyaredundancydetectionschemethatwasdemonstratedtobeaabletosigniﬁcantlyreducethenumberofKFsintheestimate,whilekeepingasimilarlevelofaccuracy.Futureworkwillfocusonfurtherleveragingtheapplicabilityandscalabilityofthesystemtopotentiallyhundredsofagents,andinterfacingCOVINSwithafront-endthatisabletorunonmobiledevices,suchasVINS-Mobile[15],furthermoreenabledtodisplayARcontent,inordertoleverageCOVINS’collaborativesceneunderstandingtocreateanddemonstrateasharedARexperienceformultipleusers.REFERENCES[1]M.Burri,J.Nikolic,P.Gohl,T.Schneider,J.Rehder,S.Omari,M.W.Achtelik,andR.Siegwart.TheEuRoCmicroaerialvehicledatasets.InternationalJournalofRoboticsResearch(IJRR),2016.[2]C.Campos,R.Elvira,J.J.G.Rodr´ıguez,J.M.Montiel,andJ.D.Tard´os.ORB-SLAM3:Anaccurateopen-sourcelibraryforvisual,visual-inertialandmulti-mapSLAM.IEEETransactionsonRobotics(T-RO),2021.[3]Y.Chang,Y.Tian,J.P.How,andL.Carlone.Kimera-Multi:aSystemforDistributedMulti-RobotMetric-SemanticSimultaneousLocaliza-tionandMapping.arXivpreprintarXiv:2011.04087,2020.[4]S.Choudhary,L.Carlone,C.Nieto,J.Rogers,H.I.Christensen,andF.Dellaert.Distributedmappingwithprivacyandcommunicationconstraints:Lightweightalgorithmsandobject-basedmodels.Interna-tionalJournalofRoboticsResearch(IJRR),36(12):1286–1311,2017.[5]T.Cieslewski,S.Choudhary,andD.Scaramuzza.Data-EfﬁcientDe-centralizedVisualSLAM.ProceedingsoftheIEEEInternationalConferenceonRoboticsandAutomation(ICRA),2018.[6]A.Cunningham,V.Indelman,andF.Dellaert.DDF-SAM2.0:Consis-tentdistributedsmoothingandmapping.InProceedingsoftheIEEEInternationalConferenceonRoboticsandAutomation(ICRA),2013.[7]C.Forster,S.Lynen,L.Kneip,andD.Scaramuzza.CollaborativemonocularSLAMwithmultiplemicroaerialvehicles.InProceedingsoftheIEEE/RSJConferenceonIntelligentRobotsandSystems(IROS),2013.[8]D.G´alvez-L´opezandJ.D.Tardos.Bagsofbinarywordsforfastplacerecognitioninimagesequences.IEEETransactionsonRobotics(T-RO),28(5):1188–1197,2012.[9]C.X.Guo,K.Sartipi,R.C.DuToit,G.A.Georgiou,R.Li,J.O’Leary,E.D.Nerurkar,J.A.Hesch,andS.I.Roumeliotis.Resource-AwareLarge-ScaleCooperativeThree-DimensionalMappingUsingMultipleMobileDevices.IEEETransactionsonRobotics(T-RO),2018.[10]R.Jung,C.Brommer,andS.Weiss.DecentralizedCollaborativeStateEstimationforAidedInertialNavigation.InProceedingsoftheIEEEInternationalConferenceonRoboticsandAutomation(ICRA),pp.4673–4679.IEEE,2020.[11]M.Karrer,P.Schmuck,andM.Chli.CVI-SLAM-CollaborativeVisual-InertialSLAM.IEEERoboticsandAutomationLetters(RA-L),3(4):2762–2769,2018.[12]P.-Y.Lajoie,B.Ramtoula,Y.Chang,L.Carlone,andG.Beltrame.DOOR-SLAM:Distributed,Online,andOutlierResilientSLAMforRoboticTeams.IEEERoboticsandAutomationLetters(RA-L),5(2):1656–1663,2020.[13]P.Li,T.Qin,B.Hu,F.Zhu,andS.Shen.Monocularvisual-inertialstateestimationformobileaugmentedreality.InProceedingsoftheInternationalSymposiumonMixedandAugmentedReality(ISMAR),pp.11–21.IEEE,2017.[14]L.Platinsky,M.Szabados,F.Hlasek,R.Hemsley,L.DelPero,A.Pan-cik,B.Baum,H.Grimmett,andP.Ondruska.Collaborativeaugmentedrealityonsmartphonesvialife-longcity-scalemaps.InProceedingsoftheInternationalSymposiumonMixedandAugmentedReality(IS-MAR),pp.533–541.IEEE,2020.[15]T.Qin,P.Li,andS.Shen.VINS-Mono:Arobustandversatilemonoc-ularvisual-inertialstateestimator.IEEETransactionsonRobotics(T-RO),34(4):1004–1020,2018.[16]L.Riazuelo,J.Civera,andJ.Montiel.C2TAM:Acloudframeworkforcooperativetrackingandmapping.RoboticsandAutonomousSystems(RAS),62(4):401–413,2014.[17]P.SchmuckandM.Chli.Multi-UAVCollaborativeMonocularSLAM.InProceedingsoftheIEEEInternationalConferenceonRoboticsandAutomation(ICRA),2017.[18]P.SchmuckandM.Chli.OntheRedundancyDetectioninKeyframe-basedSLAM.InProceedingsoftheInternationalConferenceon3DVision(3DV),2019.[19]P.SchmuckandM.Chli.CCM-SLAM:RobustandefﬁcientcentralizedcollaborativemonocularSimultaneousLocalizationAndMappingforroboticteams.JournalofFieldRobotics(JFR),36(4):763–781,2019.[20]P.Schmuck,T.Ziegler,M.Karrer,J.Perraudin,andM.Chli.COVINS:Visual-inertialSLAMforcentralizedcollaborationSupplementaryMa-terial,2021.[21]L.Teixeira,M.R.Oswald,M.Pollefeys,andM.Chli.AerialSingle-ViewDepthCompletionWithImage-GuidedUncertaintyEstimation.IEEERoboticsandAutomationLetters(RA-L),5(2):1055–1062,2020.[22]USCiLab.cereal.https://github.com/USCiLab/cereal.[23]D.ZouandP.Tan.CoSLAM:CollaborativevisualSLAMindynamicenvironments.IEEETransactionsonPatternAnalysisandMachineIntelligence(PAMI),35(2):354–366,2013.COVINS:Visual-InertialSLAMforCentralizedCollaborationSupplementaryMaterialPatrikSchmuckThomasZieglerMarcoKarrerJonathanPerraudinMargaritaChliVisionforRoboticsLab,ETHZurich,Switzerland1NOTATIONInthiswork,weadoptthenotationfrom[4]formathematicalno-tationandstateanderrorresidualformulations.Smallboldletters(e.g.a)andlargeboldletters(e.g.A)denotevectorsandmatrices,respectively.Coordinateframesaredenotedasplaincapitalletters(e.g.A).InordertodenoteavectorxexpressedinA,thenotationAxisused.ArigidbodytransformationtransformingapointfromcoordinateframeBtoAisdenotedasTAB,wherethetranslationalandrotationalpartofanyTisdenotedbytandR,respectively.Throughoutthisworkwedenotetheworldframe(i.e.theinertialframe)asW,theInertialMeasurementUnit(IMU)bodyframeasSandthecameraframeasC.2IMUMODELANDSYSTEMSTATESInordertoincorporateIMUinformationintoCOVINS,wemodeltheIMUusingastandardmodel.AssumingthatmeasurementsfromboththeaccelerationSa(t)andthegyroscopeSωωωWS(t)arecorruptedbyadditiveGaussiannoiseηandhaveanunknown,timevaryingsensorbias,theIMUreadingsaremodelledasfollows:Sa(t)=RTWS(t)(Wˆa(t)−Wg)+ba(t)+ηηηa(t),(1)SωωωWS(t)=SˆωωωWS(t)+bg(t)+ηηηg(t).(2)Thetruevaluesforthevariablesareindicatedbyaˆ·andWgdenotesthegravityvector.ToaccountforthisIMUmodel,thesystemstateΘΘΘincludesbesidestheKeyframe(KF)posesandLandmark(LM)positionsalsothelinearvelocitiesWvaswellasthebiasvariablesforeachKFk:ΘΘΘ:={RkWS,tkWS,Wvk,bk|{z}KFk,Wli},∀k∈V,∀i∈L,(3)wherethesetsVandLdenotethesetofallKFsandLMs,respec-tively.Wheneverthecontextallowsforit,weuseθjtodenoteanindividualstatevariable.3ERRORRESIDUALSFORMULATIONByformulatingasetofresiduals,theoptimizationofstatevariablesoccurringinKF-basedVISLAMcanbeexpressedasaweightednonlinearleast-squaresproblem.Eachsuchresidualeiexpressesthedifferencebetweentheexpectedmeasurementbasedonthecurrentstateofthesystemandtheactualmeasurementzi:ei:=zi−hi(Ai),(4)whereAiisthesetofstatevariablesθjrelevantformeasurementzi,andhi(·)isthemeasurementfunction,predictingthemeasurementaccordingtothesestatevariablesinAi.Bycollectingalloccurringresidualterms,theobjectiveoftheoptimizationcanbeexpressedas:ΘΘΘ∗=argminΘΘΘ(∑ikzi−hi(Ai)k2Wi),(5)wherekxk2W=xTWxdenotesthesquaredMahalanobisdistancewiththeinformationmatrixW.Withinoursystem,weessentiallyusethreedifferenttypesofresiduals:reprojectionresidualser,rela-tiveposeresidualse∆T,andIMUpre-integrationresidualseIMU.3.1ReprojectionResidualThereprojectionresidualrelatestheprojectionofLMj,withitspositionWlj,totheassociated2Dimageobservationzk,jinKFkandisgivenby:ek,jr:=zk,j−π(cid:16)TkCS(TkWS)−1Wlj(cid:17).(6)3.2RelativePoseResidualTherelativeposeresidualsareusedtoformconstraintsacrosstwoposesTi(=TRI)andTj(=TRJ),withRbeingareferenceframe.Themeasurement∆TijprovidesanestimateofthetransformationbetweentheframesIandJ.Usingthat,theresidualcanbeformu-latedase∆T:=(cid:20)log(cid:16)∆RijRTjRi(cid:17)T(cid:16)∆tij+RTjtj−ti(cid:17)T(cid:21)T,(7)wherethelog(R)deﬁnesthemappingofa3Drotationtoitstangentplane,asdescribedin[1].3.3IMUpre-integrationResidualGivenasequenceofIMUreadings,bothaccelerometerandgyroscope,betweentwoKFs,arelativeconstraintbetweenthetwoKFscanbeobtainedbythemeansofintegrationoftheIMUmeasurements.However,asdescribedinEq.(1),thesemeasurementsareaffectedbyanunknownbias,whichinreturninﬂuencestheresultoftheintegration.Inordertoavoidthecostlyre-integratingallIMUmeasurementsuponeverychangeofthebiasvariables(i.e.aftereveryoptimizationstep),[3]presentedamethodallowingtoperformtheintegrationonlyonceandapplylinearizedcorrectionsconsideringthebiaschangesw.r.t.thebiasestimateusedatthetimeoftheintegration.Utilizingthispre-integrationscheme,theresultingIMUresidualtermscanbewrittenas:eeek−1,k∆RRR=log (cid:18)∆˜RRRk−1,k(¯bbbk−1g)exp(cid:18)∂∆¯RRRk−1,k∂bbbgδbbbg(cid:19)(cid:19)|RRRk−1|WSRRRkWS(cid:17)eeek−1,k∆vvv=∆RRRk−1|WS(cid:16)Wvvvk−Wvvvk−1−Wggg∆tk−1,k(cid:17)−(cid:18)∆˜vvvk−1,k(¯bbb)+∂∆¯vvvk−1,k∂bbbaδbbba+∂∆¯vvvk−1,k∂bbbg(cid:19)(8)eeek−1,k∆ttt=RRRk−1|WS(cid:18)∆tttkWS−tttk−1WS−Wvvvk−1∆tk−1,k−12ggg∆t2k−1,k(cid:19)−(cid:18)∆˜tttk−1,k(¯bbbk−1)+∂∆¯tttk−1,k∂bbbaδbbba+∂∆¯tttk−1,k∂bbbgδbbbg(cid:19),wherethevaluesindicated¯·denotevariablesobtainedwiththearXiv:2108.05756v1  [cs.RO]  12 Aug 2021Landmarks.........TjTj+1v,bj+1Ti+1v,bi+1v,bjT iKF state variableKF pose, from a second agentReprojection residualsIMU pre-integration residualsTi+2v,bi+2v,biTkTk+1v,bk+1v,bk.........Figure1:SchematicdepictionofthefactorgraphformulationoftheSimultaneousLocalizationAndMapping(SLAM)mapwithallrelevantvariables,whichareinvolvedinGBA.KFscapturedbydifferentagentsgetassociatedviamutualobservationsofLMs,whileIMUresidualsareonlyconnectingKFsfromthesameagent.Note:possibleadditionalconstraintsfromloopclosuresarenotillustratedhere.biasestimate¯batthetimeofthepre-integrationandvalueswith˜·indicatevaluesusingthecurrentestimateofthestatevariables.Thescalarvalue∆tk−1,krepresentsthetimeintervalbetweenthetwoKFsattimek−1andk.TheindividualerrortermsinEq.(8)areputtogetherintoaresidualvectorasek−1,kIMU:=heeek−1,k∆RRRTeeek−1,k∆vvvTeeek−1,k∆tttTiT(9)4FACTORGRAPHREPRESENTATIONOFTHEMAPSTRUC-TURETogetherwiththestatedeﬁnition(Sec.2)andtheerrorresiduals(Sec.3),theunderlyingSLAMestimationproblemofCOVINSinducesafactorgraph,illustratedinFig.1,whichformsthebasisoftheGlobalBundleAdjustment(GBA)schemeemployedintheframework.Asshown,sharedLMobservationscreatedependenciesbetweenKFsfrommultipleagents,whileIMUfactorsareonlyinsertedbetweenconsecutiveKFscreatedbythesameagent.5OBSERVATIONREDUNDANCYMEASUREFollowing[5],thefunctionτ(x):N0→[0,1]assignsavaluetoeachLMdependingonitsnumberofobservationsx,withincreasingnumberencodingincreasingredundancyofanindividualobserva-tionofthisLM.Inconformitywith[5],withaminimumobtwoobservationsrequiredtoconstrainaLM,τ(2)=0,andτ(x)=1forx>5,sothatﬁveobservationsareconsideredsufﬁcienttorobustlyestimatethe3DpositionofaLM.Takingintoaccounttheaspectthattheredundancyofoneindividualobservationincreaseswithincreasingnumberofobservations,τ(x)isdeﬁnedasfollows:τ(x)=0,ifx≤20.4,ifx=30.7,ifx=40.9,ifx=51,ifx>5(10)6EXPERIMENTALRESULTS6.1Large-ScaleCollaborativeSLAMwith12AgentsFig.2aillustratesasceneviewforthevillagedatasetusedforthe12-agentexperimentreportedinCOVINS,aswellasthe12circularUAVtrajectoriesof20mradius.Fig.2bshowsasideviewonthesparseLMpointcloudontheintersectionbetweentwotrajectories,attestingtothehighaccuracyofthecollaborativeestimatethroughthewell-alignedLMsofthetwoagents.(a)Final12-agentcollaborativeSLAMestimate(trajectoriesonly),superimposedonthesceneview.(b)SideviewonthetrajectoriesandLMattheintersectionbetweentwotrajectories,illustrat-ingtheaccuratealignmentofindividualmapdata.Figure2:ThecollaborativeSLAMestimatesinthe12-agentvillageexperiment.6.2CommunicationStatisticsTable1reportsthenetworktrafﬁcgeneratedbythecommunicationbetweenseverandagentforallsequencesoftheEuRoCdataset[2],includingthosethatareomittedinthemainpaper.Table1:Networktrafﬁcofagent-to-serverandvice-versa,andtotaltimeconsumedforcommunicationonboardtheagent(5-run-average).Theﬁrstrowshowstheaverageoverall8differentEuRoCsequences.ThegenerationofmoreKFsonboardtheagentforthemorechallengingsequencesleadstoincreasingnetworktrafﬁc.SequenceAgent→ServerServer→AgentCommTimeAvg.493.36kB/s2.31kB/s792.91msMH1422.83kB/s2.29kB/s939.92msMH2450.78kB/s2.31kB/s825.37msMH3463.82kB/s2.31kB/s771.50msMH4554.26kB/s2.33kB/s652.41msMH5540.37kB/s2.32kB/s776.33msV101402.29kB/s2.29kB/s1063.57msV102503.26kB/s2.33kB/s570.66msV103609.22kB/s2.31kB/s850.24msREFERENCES[1]M.Bloesch,H.Sommer,L.Tristan,M.Burri,G.Nuetzi,P.Fankhauser,D.Bellicoso,C.Gehring,S.Leutenegger,M.Hutter,andR.Siegwart.APrimerontheDifferentialCalculusof3DOrientations.arXivpreprintarXiv:1606.05285,2016.[2]M.Burri,J.Nikolic,P.Gohl,T.Schneider,J.Rehder,S.Omari,M.W.Achtelik,andR.Siegwart.TheEuRoCmicroaerialvehicledatasets.InternationalJournalofRoboticsResearch(IJRR),2016.[3]C.Forster,L.Carlone,F.Dellaert,andD.Scaramuzza.On-ManifoldPreintegrationforReal-TimeVisual–InertialOdometry.IEEETransac-tionsonRobotics(T-RO),33(1):1–21,2017.[4]M.Karrer,P.Schmuck,andM.Chli.CVI-SLAM-CollaborativeVisual-InertialSLAM.IEEERoboticsandAutomationLetters(RA-L),3(4):2762–2769,2018.[5]P.SchmuckandM.Chli.OntheRedundancyDetectioninKeyframe-basedSLAM.InProceedingsoftheInternationalConferenceon3DVision(3DV),2019.