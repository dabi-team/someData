1
2
0
2

l
u
J

0
3

]

V
C
.
s
c
[

1
v
9
5
6
4
1
.
7
0
1
2
:
v
i
X
r
a

Instant Visual Odometry Initialization for Mobile AR

Alejo Concha, Michael Burri, Jes ´us Briales, Christian Forster, and Luc Oth

Abstract—Mobile AR applications beneﬁt from fast initialization to display world-locked effects instantly. However, standard visual
odometry or SLAM algorithms require motion parallax to initialize (see Figure 1) and, therefore, suffer from delayed initialization. In this
paper, we present a 6-DoF monocular visual odometry that initializes instantly and without motion parallax. Our main contribution is a
pose estimator that decouples estimating the 5-DoF relative rotation and translation direction from the 1-DoF translation magnitude.
While scale is not observable in a monocular vision-only setting, it is still paramount to estimate a consistent scale over the whole
trajectory (even if not physically accurate) to avoid AR effects moving erroneously along depth. In our approach, we leverage the
fact that depth errors are not perceivable to the user during rotation-only motion. However, as the user starts translating the device,
depth becomes perceivable and so does the capability to estimate consistent scale. Our proposed algorithm naturally transitions
between these two modes. Our second contribution is a novel residual in the relative pose problem to further improve the results. The
residual combines the Jacobians of the functional and the functional itself and is minimized using a Levenberg–Marquardt optimizer on
the 5-DoF manifold. We perform extensive validations of our contributions with both a publicly available dataset and synthetic data.
We show that the proposed pose estimator outperforms the classical approaches for 6-DoF pose estimation used in the literature in
low-parallax conﬁgurations. Likewise, we show our relative pose estimator outperforms state-of-the-art approaches in an odometry
pipeline conﬁguration where we can leverage initial guesses. We release a dataset for the relative pose problem using real data to
facilitate the comparison with future solutions for the relative pose problem. Our solution is either used as a full odometry or as a
pre-SLAM component of any supported SLAM system (ARKit, ARCore) in world-locked AR effects on platforms such as Instagram and
Facebook.

Index Terms—Monocular initialization, relative pose estimator, Visual Odometry, AR instant placement.

1 INTRODUCTION

Knowing the precise 6-DoF motion of a mobile phone allows us to
augment the real-world with virtual effects. A popular use-case of
this capability is the placement of virtual furniture to make purchas-
ing decisions. The pose of the mobile phone can be estimated with
camera-based Simultaneous Localization and Mapping (SLAM) or Vi-
sual Odometry (VO) – Cadena et al. [5]. These methods detect and track
salient features in the environment and thereby localize the camera.
While SLAM builds and optimizes a map of the observed scene, a VO
system just maintains a sliding-window of the most recent estimated
camera poses and landmarks at the cost of lower global accuracy but
higher compute efﬁciency. Since many world-locked AR experiences
are very short in nature, and compute usage is of high importance, a
VO system sufﬁces for most applications.

Widely used mobile SDKs such as ARKit or ARCore leverage the
inertial measurement unit (IMU) in addition to the camera sensors. The
IMU is an ideal complementary sensor to the camera as it (1) renders
gravity and scale observable and (2) provides reliable angular velocity
and linear acceleration even when the cameras are occluded or the
images suffer motion-blur or low-contrast. However, there exists a large
body of devices without accurate and stable spatial-temporal camera-
IMU calibration. Additionally, there exist many low-end smartphones
with accelerometer but no gyroscope or phones with faulty sensor data
due to manufacturing imprecisions. Ubiquitous mobile AR needs to
support low-end devices, which motivated the development of our
vision-only VO system. Due to the major advantage of leveraging the
IMU, the proposed system is able to optionally include and process
inertial measurements in case they are available.

Many world-locked mobile AR experiences are very short in nature
(a few seconds) as users rapidly browse through different AR effects
that rely on different underlying capabilities such as world-locked, face-
locked, and object-locked. One way to increase user satisfaction is to

All authors are with Facebook Zurich, Switzerland. E-mail:
aconchabelenguer@gmail.com alejocb@fb.com

Manuscript received xx xxx. 201x; accepted xx xxx. 201x. Date of Publication
xx xxx. 201x; date of current version xx xxx. 201x. For information on
obtaining reprints of this article, please send e-mail to: reprints@ieee.org.
Digital Object Identiﬁer: xx.xxxx/TVCG.201x.xxxxxxx

Fig. 1. The left part of the Figure shows that depth is neither perceivable
nor recoverable during pure rotational motion. On the other hand, if
the device translates as shown on the right, it is possible to estimate
consistent depth in a monocular setting up to a constant scale factor.
However, an in-consistent scale over multiple frames would be user
noticeable. Our initialization method naturally moves from the left to the
right by starting to estimate translation magnitude corresponding to a
consistent scale as depth errors become perceivable.

initialize the tracker instantaneously to minimize time-to-fun. However,
standard VO and visual-inertial odometry initialization techniques re-
quire translational motion to initialize (approx. 10 cm, depending on
the scene depth). This is because many closed-form solutions that are
used to jointly initialize the initial camera poses and 3D landmarks re-
quire translation to triangulate the 3D points or may even be degenerate
in the rotation-only case. This motivated our work on a VO system that
initializes instantaneously and independently of the user motion. Our
solution is either used as a full odometry or as a pre-SLAM component
of any supported SLAM system (ARKit, ARCore) in world-locked AR

Pure Rota*onDepth error not perceivable in ARCannot es4mate consistent scaleRota*on & Transla*onDepth error no4ceable in ARCan es4mate consistent scaleMotion:Perception:Estimation: 
 
 
 
 
 
effects on platforms such as Instagram and Facebook.

While our contribution has been motivated by the mobile AR use-
case, there are several other applications in the robotics community that
rely on instant initialization of VO or SLAM. An example is the rapid
deployment of vision-based micro aerial vehicles as shown in Faessler
et al. [11].

2 RELATED WORK
Initializing stereo (Mur-Artal et al. [24]) or RGB-D systems (New-
combe et al. [25], Concha and Civera [7]) is straightforward in the vast
majority of cases. These systems can estimate the depth of features
without moving the device. Other works rely on IMU sensors for fast
initialization, like Bloesch et al. [3] or Li et al. [20]. Structural cues
might also be used as in Huang et al. [17], which propose a method for
initializing from ﬁrst frame using vanishing points and some indoor
cues. Moreover, deep-learning-based depth estimation has the potential
to initialize a map from ﬁrst frame (F´acil et al. [10]).

In this paper, and contrary to some of the above-mentioned works,
we do not make any assumptions regarding the structure of the environ-
ment and we do not use additional sensors to solve this problem either.
In this context, VO initialization can be divided in two main research
lines: feature-based (indirect) initialization methods and direct initial-
ization methods. In the next section, we discuss different initialization
techniques that have been explored in both research lines:

2.1 Feature-based (indirect) initialization methods
Feature-based initialization approaches extract features in an image
that are matched in another image of the same scene with a different
viewpoint. Feature matches are used to estimate both an initial relative
pose between the views and a map of 3D features using either closed-
form solvers or optimization-based techniques:

2.1.1 Minimal solvers based on Essential and Homography

matrices

The relative pose can be recovered by estimating an Essential matrix
(eight-point algorithm, Zisserman and Hartley [2]) or a Homography
matrix (Faugeras and Lustman [13], Longuet [21]) between the cameras,
depending on the camera motion and scene structure. Camera poses
are then used to triangulate the feature correspondences and build a
map that is used for tracking in the subsequent frames. Even though
these solvers have been used successfully for decades, they still present
some issues that motivated this paper:

• Non-instantaneous initialization. The Essential matrix might not
be correctly estimated in the case of zero translation. A zero
matrix becomes a valid solution in such situations and therefore
its constraints deteriorate.

• Non-minimal parametrization: The parameters from the Essential
and the Homography matrix are not directly related to the actual
motion-related parameters and the parametrization is not minimal,
which makes it harder to withdraw conclusions from the actual
estimated values during the optimization.

• Structure-dependency. Essential matrix estimation is an ill-
deﬁned problem with planar scenes. A Homography model
(Faugeras et al. [13]) is proposed in the literature for these sit-
uations as backup plan (Mur-Artal et al. [23]). A Homography
model cannot be applied to non-planar scenes, unless points are
far away where translation cannot be recovered. Mur-Artal et
al. [23] deal with this problem by using a model selection strat-
egy: An homography and an Essential matrix are estimated in
parallel and the one that produces the lowest re-projection error
is taken as a candidate for initialization.

• Solution multiplicity. Homography solvers return multiple solu-
tions (Faugeras et al. [13]) that need to be disambiguated. Some
of the solutions can be trivially rejected but for others there is not
a better option than triangulate and track feature correspondences
for a few frames with a SLAM system to verify their re-projection
error in subsequent frames Mur-Artal et al. [23].

2.1.2 Optimization-based initialization methods
Several optimization-based approaches have been explored that address
some of the limitations of minimal solvers that estimate an Essential
or Homography matrix. Kneip and Lynen [18] have addressed this
problem proposing a direct optimization of frame to frame rotation.
Lee and Civera [19] have recently extended this work to multiple views,
proposing a rotation-only bundle adjustment optimizer. On the down-
side, these approaches need to cope with non-trivial and non-convex
optimization problems for which ﬁnding the right optimal solution
vs other minima can turn challenging. Briales et al. [4] proposed for
the ﬁrst time a solver for (an equivalent form of) the problem formu-
lation by Kneip and Lynen [18] which comes with global optimality
guarantees. The approach however relies on solving a convex SDP
relaxation of an equivalent Quadratically Constrained Quadratic Pro-
gram (QCQP) formulation of the problem (Park and Boyd [26]), which
is computationally intensive (with respect to real-time standards) and
makes it non-straightforward to leverage initial guesses for the relative
pose. Garc´ıa-Salguero et al. [16] extends this work and proposes an
optimality certiﬁer for the relative pose problem.

The main advantage of relative pose estimators is their ability to
accurately estimate rotations independently of the scene structure and
motion of the camera. Translations are also independent of the scene
structure and are accurately estimated if there is enough baseline be-
tween the cameras. For these reasons, we have used a relative pose
estimator in our formulation, see Section 3 for more details.

2.2 Direct initialization methods
Direct approaches directly use pixel intensity for tracking and mapping.
For initialization, direct approaches either use the above-mentioned
solvers from indirect approaches to initialize their systems (Engel et
al. [9]) or create an inaccurate ﬁrst map. For example, in Engel et
al. [8], a random map is initialized and in Concha and Civera [6] the
features are placed at a constant distance from the ﬁrst camera. In
these approaches, the initial inaccurate map is continuously reﬁned
as the camera moves hoping for an eventual convergence of the map
parameters to their true values. Generating an initial inaccurate map
can work in some situations but can fail catastrophically if the initial
map is very different from the actual one. This is because the map
is directly used to estimate all 6-DoF parameters, meaning errors in
the map are directly propagated to all estimation parameters and the
estimation can eventually diverge.

3 CONTRIBUTIONS AND OUTLINE
Optimization-based relative pose estimators solve most of the limita-
tions (section 2.1.1) that are present in classical minimal solvers that
estimate the Essential matrix between two views. Even though relative
pose solvers are good at estimating the two-view problem, they fail to
estimate a consistent scale in a VO setting as they return a unit-norm
translation. While the true scale is not observable in a monocular
vision-only setting, it is still paramount to maintain a consistent scale
by estimating the translation magnitude in the two-view problem. This
is required to recover a camera trajectory that is accurate up to a single
scale factor that remains constant throughout the session. To solve this
issue:

• We propose to combine a relative pose estimator with a translation-
magnitude-estimator. The translation-magnitude-estimator min-
imizes keyframe to frame re-projection errors using depth-
estimates of past feature observations as input. With this formula-
tion, we use all feature correspondences to estimate the relative
pose while only using the correspondences with estimated depth
to estimate the magnitude of the translation. In traditional SLAM
systems, only those features with an accurate estimated depth can
be used to estimate the full 6-DoF pose of the camera. This is why
direct approaches that initialize an inaccurate map can fail during
initialization when the map is inaccurate (see Section 2.2), the
error in the map is directly propagated to all motion parameters
which can eventually diverge. We also initialize an initial inaccu-
rate map, however, in our case the errors in the map do not affect

the estimated relative pose but only the estimated translation mag-
nitude. We exploit the fact that while translation is not observable,
the accuracy of the map does not matter. The reverse also holds:
at the point where translation becomes signiﬁcant, feature depth
becomes observable. We show in the experimental Section 7 that
our 5-DoF + 1-DoF optimizer outperforms the classical 6-DoF
pose estimator in low-parallax motions.

• One challenge with solving the optimization problem underly-
ing relative pose estimators is that the underlying formulation is
not a sum of squares, but rather a sum of algebraic errors. As a
result we cannot directly apply classical simple and lightweight
Gauss-Newton-like algorithms, but need to resort to more generic
Newton-like methods like Riemannian Trust Regions – Absil et
al. [1]. These more generic solvers are not as generally available
as classical Least Squares solvers like Gauss-Newton or Leven-
berg–Marquardt (More [22]), and often lack the maturity of the
latter (specially when it comes to availability as efﬁcient C++
implementations within common libraries). Besides, in resource-
constrained platforms like mobile devices, where each new library
dependency matters to minimize binary size, it is desirable that
we rely on a classical Least Squares solver.

As an alternative to the above-mentioned limitations, Kneip and
Lynen [18] propose to minimize a different functional consisting
of the sum of squared Jacobians of the original functional and
therefore a classical Gauss-Newton or Levenverg-Marquardt algo-
rithm can be applied. This approach, by deﬁnition, is equivalent
to ﬁnding a local minimum for the original functional (where
Jacobians become null). The surrogate residual solved in Kneip
and Lynen [18] has multiple equally valid global minimum (as
many as local minimum exist in the original functional), making
it much harder to converge to the globally optimal solution.

As a second contribution, we extend the Jacobian minimization
trick of Kneip and Lynen [18] and include the objective function
itself in the residual. This basically makes the surrogate residual
well-deﬁned as there will be a single global optimum, making
convergence to the right solution much easier. Another character-
istic of this approach is that it allows the usage of initial guesses
for the parameters to estimate, which is a big advantage for visual
odometries.

The rest of the paper is structured as follows: the problem is deﬁned
in Section 4. Sections 5 and 6 explain the proposed approach in detail.
We validate our contributions in Section 7. Finally, conclusions and
future lines of work are given in Section 8. Additionally, we include an
Appendix in Section 9 for the derivations omitted from Section 5.

4 PROBLEM DEFINITION
Our goal is to estimate in real-time and without initialization a consis-
tent 6-DoF trajectory of the motion of a monocular device with cali-
brated camera parameters. We can solve this by estimating TTT ∈ SE(3),
the pose transform between a previous frame (keyframe) and the current
frame given a set of feature correspondences between them ( fff iii in the
past keyframe and fff (cid:48)
iii in the current frame) and – optionally – the depth
of the features in the source view (di). Where i denotes the index of the
feature. Note if pppiii is a 3D point in the reference frame of the ﬁrst view
and ppp(cid:48)
iii is the same point in the reference frame of the second view, they
are related through TTT as ppp(cid:48)
Where TTT is deﬁned as follows:

iii = TTT pppiii.

TTT =

(cid:20) RRR
01×3

(cid:21)

uuus
1

, s.t. RRR ∈ SO(3), uuu ∈ S2, s ∈ R

(1)

Where SO(3) is the rotation group (Stuelpnagel [27]) and Sn rep-
resents points in the n-dimensional unit sphere. uuu is the translation
direction, a 3D unit-norm vector.

Through the paper, we refer to the magnitude of the translation as
s ∈ R. Whenever we refer to 5-DoF in this paper we mean the unscaled
relative pose between two views (RRR, uuu), while if we refer to 6-DoF

we mean we additionally estimate the magnitude of the translation to
produce a full 6-DoF pose (RRR, uuu, s) → (RRR,ttt) with consistent scale along
the trajectory (but not metric scale, as this is a monocular odometry).

5 6-DOF POSE ESTIMATION
Our pipeline is composed of two main components, a frame to frame
tracker and a pose estimator (see Figure 2). In this section, we explain
the proposed 6-DoF estimator, which is the main contribution of this
paper. We will explain the implementation details of the frame-to-frame
tracker in the next section for completeness.

Following the 6-DoF parametrization in eq. 1, we can split the
6-DoF estimation problem into (1) the estimation of the relative pose
(RRR ∈ SO(3) with unit-norm translation uuu ∈ S2) and (2) the estimation of
the magnitude of the translation (s). The relative pose can be estimated
using all feature correspondences between two views using a relative
pose estimator (see Section 5.1 for details). Once the relative pose is
estimated, we estimate the magnitude of the translation. To estimate
the magnitude of the translation, we also need as input the depth of
the optionally triangulated features, which might have been estimated
using past 6-DoF poses via triangulation (see Section 5.2 for details).

5.1 5-DoF Relative Pose Estimator
The relative pose problem is the problem of determining the relative
rotation and direction of the translation between two frames using
2D-2D correspondences.

Given the bearing vectors ( fff iii and fff (cid:48)

iii) from a set of correspondences,
Kneip and Lynen [18] proposed to solve the relative pose problem by
enforcing the co-planarity of the epipolar plane normals mmmiii = RRR fff iii × fff (cid:48)
iii
for all epipolar planes (see Figure 3 for a graphical explanation). This
is achieved by minimizing the minimum eigenvalue of the covariance
(cid:124)
matrix of the epipolar plane normals MMM(RRR) = ∑n
iii , where the
rotation matrix RRR is the variable to optimize:

i=1 mmmiiimmm

ˆRRR = arg min

RRR

λmin (MMM (RRR))

(2)

We refer the reader to the original work Kneip and Lynen [18] for
more details on the derivation of the functional. Once RRR is estimated,
uuu can be retrieved as the eigenvector corresponding to the minimum
eigenvalue of MMM (cid:0) ˆRRR(cid:1):

ˆuuu = arg min

uuu

uuuMMM (cid:0) ˆRRR(cid:1) uuu(cid:124)

(3)

Instead, we follow a similar approach proposed by Briales et al.
[4], solving translation and rotation simultaneously. The equation
3 is minimized directly with respect to both rotation and direction
translation:

ˆRRR, ˆuuu = arg min

uuuMMM (RRR,,, ) uuu(cid:124)

uuu,RRR

(4)

The computation of the Jacobians of this equation is simpliﬁed
following the derivations available in Briales et al. [4] to obtain the
following functional:

ˆRRR, ˆuuu = arg min

xxxCCCxxx(cid:124)

RRR∈SO(3)uuu∈S2

(5)

Where the data matrix CCC ∈ Sym27 gathers all data (derived from the
original bearing vectors). xxx = vec (rrruuu(cid:124)) where vec() is a vectorization
function and rrr is the vectorized form of the rotation matrix RRR.

At this stage, we diverge from the QCQP procedure in Briales et
al. [4] to solve the optimization problem. While Briales et al. [4] in-
vestigated the properties of the optimization (certifying the solution is
globally optimal), we are interested in building a real-time VO system
where the relative pose estimator is its main building block. For this rea-
son, we choose a Levenberg–Marquardt optimizer, which is a classical
optimizer that is better suited for frame-to-frame optimizations since
it is efﬁcient and allows us to leverage predictions from the previous
frame as initial guesses. We show in the experimental section that
our proposed estimator outperforms QCQP (Briales et al. [4]) when a

Fig. 2. Pipeline of our approach. Images (and optionally IMU gyro predictions) feed our visual odometry. The frame-to-frame tracker matches
features and produces feature correspondences (bearing vectors) that are consumed by the 6-DoF pose estimator. The pose estimator contains a
relative pose estimator (5-DoF) that takes the bearing correspondences and estimates a 5-DoF pose. The 5-DoF pose and the estimated depth of
the features (depth is estimated by the tracker) are used to estimate the magnitude of the translation, completing the ﬁnal 6-DoF pose. If depth is not
available (during the ﬁrst frames), we use the constant depth assumption. A new keyframe is inserted in the previous frame if there are not enough
overlapping features between current keyframe and last frame or if any of the estimators fail. If current keyframe is already the previous frame, we do
not insert a new keyframe. Outliers from pose estimators are sent to the tracker for removal.

ˆRRR, ˆuuu = arg min

RRR∈SO(3),uuu∈S2

3
∑
i=1

∂ xxxCCCxxx(cid:124)
∂ θi

+

2
∑
i=1

∂ xxxCCCxxx(cid:124)
∂ βi

(6)

The second contribution of this paper is the inclusion of the func-
tional in the residual to optimize to further improve the results. The
original residual has convergence issues when the initial guesses of
the parameters to estimate are not good because it only minimizes
the Jacobians of the functional. Adding the functional to the residual
improves the convergence properties of the problem, as shown in the
experimental section. The ﬁnal residual f (RRR, uuu) reads as follows:

ˆRRR, ˆuuu = arg min

f (RRR, uuu)

RRR∈SO(3),uuu∈S2

f (RRR, uuu) =

3
∑
i=1

∂ xxxCCCxxx(cid:124)
∂ θi

+

2
∑
i=1

∂ xxxCCCxxx(cid:124)
∂ βi

+W xxxCCCxxx(cid:124)

(7)

(8)

Where the constant W is used to tune the properties of the estimation
by differently weighting the Jacobians and 1-d residual. How this con-
stant inﬂuences the results is evaluated in Section 7.3. The functional
is minimized using a standard Levenberg–Marquardt optimizer where
the initial guess for the rotation can be obtained by gyro propagation
if available or from the previous frame otherwise. The initial guess
for the translation is obtained using equation 3 given the set of feature
correspondences and the initial guess for the rotation.
∂ xxxCCCxxx(cid:124)
∂ βi

The Jacobians of the functional (

∂ xxxCCCxxx(cid:124)
∂ θi

) are derived in

and

the appendix of the paper.

The main advantage of relative pose estimator methods is that they
always estimate an accurate rotation (even in low parallax motions)
and do not need the depth of the feature matches to do so. One issue
is that the translation direction might not be accurate in low-parallax
motion. Fortunately, we can leverage the fact that translations are not
perceivable by the user in low-parallax motions. Another issue is that
we cannot use robust cost functions to down-weight outlier matches

Fig. 3. Graphical deﬁnition of the relative pose problem. Bearing vectors
(in red) from two different views are the known variables. The rotation RRR
and translation direction uuu between the views are estimated by minimizing
the equation 7. Figure borrowed from Kneip and Lynen [18].

.

decent initial guess is available (even if our estimator does not come
with global optimality guarantees). This is because the global minimum
is not always associated with an accurate 5 DoF solution and therefore
an initial guess makes it easier to ﬁnd an accurate solution. The chal-
lenge with the equation 5 is that the residual is scalar and therefore
the number of unknowns (5) does not match the size of the residual
(1). To solve this problem, we applied the trick proposed in Kneip and
Lynen [18] where instead of minimizing the functional, we minimize
the Jacobians of the functional. That way, the dimension of the residual
equals the number of unknowns. For clarity, we split the 5 parameters
to optimize in two different variables. The so(3) rotation parameters
are stored in variable θθθ while the 2 parameters to optimize from the 3D
unit-norm manifold are stored in variable βββ . Using this convention, the
functional reads as follows:

because the re-projection errors are not directly part of the residual.
Because of this, we need to heavily rely on the RANSAC (Fischler et
al. [14]) approach that is explained in the next Section 6.

The limitation of our relative pose estimator is its low accuracy when
the initial guess for the rotation is not good. This is expected as we
do a non-linear optimization where the initial guess is reﬁned. This is
quantitatively demonstrated in experiment 7.2.

5.2 1-DoF translation magnitude estimator
The relative pose estimator estimates unit norm translations where the
magnitude (s) of the translation is unknown. This is addressed by this
component, which estimates the magnitude of the translation (s) and
updates the ﬁnal 3-DoF translation as ttt ∈ R3 := s ∗ uuu ∈ S2.

The

translation magnitude

is optimized using a Leven-
berg–Marquardt solver by minimizing the squared re-projection errors
(rgeo) of the features with estimated depth, which are re-projected from
the keyframe to the current frame.

ˆs = arg min

s

rgeo,

rgeo =

n
∑
i=1

g

(cid:32) (cid:0)π (RRR fff iiidi + uuus) − π (cid:0) fff (cid:48)

iii

(cid:1)(cid:1)2

(cid:33)

σ 2
i

(9)

(10)

Where g() is a robust cost function and π() is the camera projection
function that transforms 3D points in the camera frame into 2D camera
coordinates. di is the estimated depth of the feature in the source frame
and σi is the uncertainty of the pixel, taken from the pyramid level
where the feature was observed.

6 IMPLEMENTATION DETAILS
6.1 Constant depth assumption
Note that for the very ﬁrst frames, we do not know the depth di of
the features and we assume constant depth of 0.75 meters. As soon
as we pass a minimal parallax angle (which was experimentally set
to 1.0 degrees), we start estimating depth by triangulating the feature
correspondences. The reader might wonder what happens during the
ﬁrst frames in low-parallax cases. The pose estimator estimates a
relative 5-DoF pose between keyframe and frame where the rotation
should always be correct and the unit-norm translation might not be
correct in cases of low parallax motion. However, in such cases, the
translation magnitude estimator will estimate a magnitude that will be
close to zero (features are far away) and therefore the relative translation
between keyframe and frame will be close to zero and will not affect
negatively to the global estimation (and the user will not perceive it
either). The accuracy of the translation direction and the translation
magnitude naturally increase as the baseline between keyframe and
frame also increases. The higher the baseline, the more perceivable the
translation becomes and the more features we can triangulate. We keep
using the constant depth assumption until we have a minimum set of
triangulated features. The reader is referred to Figure 4 for a graphical
explanation.

6.2 Frame-to-frame tracker
We match features from frame-to-frame by projecting 3D points (see
previous subsection), corresponding to the features in the keyframe, into
the current frame and correlating a warped 8x8 pixel-size patch along
the epipolar line in the current view, similar to the depth estimation
stage in Forster et al. [15]. To account for pose prediction inaccuracy,
the search width around the epipolar line is variable. The output of
the matching stage are keyframe-to-frame feature matches ( fff (cid:48)
iii) which
are used for relative pose estimation (section 5.1). The frame-to-frame
tracker also contains a module to reﬁne the depth (di) of the tracked
features in the keyframe once the pose TTT is estimated (see Figure
2). The depth of the features is used to estimate the magnitude of
the relative translations (see Section 5.2) and to update the 3D points
corresponding to the features in the keyframe.

If a feature is lost or is not observed by the tracker, we still keep it
alive for 150 frames. We do this to keep features alive for as long as

possible to ”simulate” that a pseudo-map is tracked and our odometry
can therefore re-use old information and increase the accuracy and
robustness of the tracker –specially with pure rotational motions, where
the pseudo-map cannot be augmented.

6.3 Keyframe heuristics

The 6-DoF pose estimator (5-DoF from Section 5.1 + 1-DoF from
Section 5.2) estimates the pose of the current frame with respect to a
previous keyframe. Estimating the pose with respect to a keyframe,
instead of the previous frame, reduces drift.

New keyframes are added based on the following heuristics: not
enough inliers in the relative pose estimator –we classify a point as an
inlier if its Sampson distance (Fathy et al. [12]) is small enough–, not
enough overlapping features with estimated depth between keyframe
and frame and high re-projection error in the translation magnitude
estimator. If a keyframe has to be inserted, it is inserted in the previous
frame and we estimate the 6-DoF pose between the last 2 frames. Note
that at the time we do pose estimation, we don’t know the depth of
the features in the current frame. However, since we do a keyframe
to frame optimization we do know the depth of the features in the
keyframe as those were triangulated when the keyframe was processed.

6.4 Outlier removal

As with all optimization problems, the formulation of the relative pose
estimator (section 5.1) is sensitive to outlier feature tracks. However, we
are not dealing with a per-feature geometric error but an algebraic one,
meaning we cannot use robust cost functions to down-weight outliers.
Hence, we wrap the minimization in a RANSAC loop (Fischler et
al. [14]) where ﬁrst we initialize the relative rotation from the best
estimated rotation so far. If the rotation have not been estimated yet,
we use the rotation prior from gyro prediction if available. If a rotation
prior is not available, we apply a small perturbation to the estimated
rotation from previous frame. The translation direction is initialized
from equation 3 using the subsampled –from the inliers set– feature
correspondences. We repeat this operation during 5 iterations, updating
the inliers of our problem. After the 5 iteration, we additionally reﬁne
the pose (minimizing eq. 7) during 7 more iterations. After every
iteration, outliers are always removed with respect to the entire set of
correspondences. To determine if a point is an outlier we check if its
squared Sampson distance is higher than a predeﬁned threshold. We
stop early if we reach convergence, which is obtained if the error is not
reduced and the number of inliers does not increase. Otherwise, we
update the best relative pose and the inliers.

The translation magnitude estimator uses only the inliers coming
from the relative pose estimator. We use a robust cost function to down-
weight outliers. After the estimation, we detect additional outliers by
checking the re-projection error of the features. A feature is considered
an outlier if the re-projection error is higher than 1.5 pixels. Outliers
from both the relative pose estimator and the translation magnitude
estimator are removed from the tracker in a post-processing step.

6.5 Initial guess for translation magnitude estimator

When we introduce a new keyframe in the previous frame (n − 1), the
translation magnitude is computed with respect to that frame. In this
case, the estimated translation magnitude will be very close to zero,
and therefore we initialize the initial guess to zero (sn = 0). Otherwise,
when we estimate the translation magnitude with respect to a keyframe
that is older than the previous frame, the current magnitude (sn) is
initialized from the last estimated magnitude (sn := ˆsn−1). However,
we need to take into account that the magnitude sign may ﬂip from
frame to frame. This is because the initial guess for the translation
is computed feeding the initial guess of the rotation into the closed
form solution from equation 3, which can ﬂip the sign of the translation
due to its symmetry in the functional of this equation (uuuMMM (cid:0) ˆRRR(cid:1) uuu(cid:124) =
(−uuu) MMM (cid:0) ˆRRR(cid:1) (−uuu(cid:124))). To solve this, we check if the sign of the 2-DoF
direction has ﬂipped from last frame (uuun (cid:39) − ˆuuun−1) and if that is the
case we also ﬂip the sign of the magnitude prediction (sn := − ˆsn−1).

Fig. 4. Left image: For the very ﬁrst frames, we cannot estimate the depth of the features. All features are used for both estimating the relative pose
(RRR, uuu) and the translation magnitude (s). For the translation magnitude estimation, we assume constant depth for all features. Right image: Once the
baseline between cameras increases, we can estimate the depth of some of the features. Again, all features are used to estimate the relative pose
(RRR, uuu). However, only those features with estimated depth are used for estimating the translation magnitude s. Our method moves from left to right
and therefore stops using the constant depth assumption once 10 features with estimated depth are available.

7 EXPERIMENTS
7.1 Pose estimator validation
In this section, we compare our proposed pose estimator (5-DoF (eq.
7) + 1-DoF (eq. 9)) against the gold standard solution for this problem,
which is doing Bundle Adjustment (Triggs et al. [29]) without optimiz-
ing the position of the 3D points and therefore only optimize the 6-DoF
pose of the camera:

ˆRRR, ˆttt = arg min

r,

RRR∈∈∈SO(3),ttt∈∈∈R333
(cid:32) (cid:0)π (RRR fff iiidi + ttt) − π (cid:0) fff (cid:48)

iii

(cid:1)(cid:1)2

(cid:33)

σ 2
i

r =

n
∑
i=1

g

(11)

(12)

We simulate a map of 200 landmarks and a trajectory of ∼1 second
(37 frames) with a sigma equal to 0.75 for the pixel uncertainty. Around
170 landmarks are observed per frame and from a distance to ﬁrst
camera between 1 and 6 meters. The camera moves around 25 degrees
and 1.0 meters on average. We use a spherical camera model (as in
Kneip and Lynen [18]) with an image size of 640 by 480 and a focal
length of 200 pixels. As stated by Briales et al. [4], increasing the Field
Of View (FOV) makes the relative pose problem easier, as this results
in a better constraining of the optimization objective. The reader is
referred to Briales et al. [4] for an evaluation of the FOV in the relative
pose problem.

We run 50 experiments for each algorithm.

In this experiment,
the estimation is always computed with respect to the ﬁrst frame and
keyframes do not need to be inserted since most of the landmarks
are observed by the 37 frames. This ensures a fair comparison since
we focus on evaluating the pure estimation and not the keyframing
heuristics. We are interested in two comparisons:

• Comparing both approaches when the depth is unknown. We
use the constant depth assumption and therefore ﬁx all depths
to the same value. This is to validate our proposal, showing it
is particularly accurate during the ﬁrst frames when depth is not
available and 6-DoF approaches suffer.

• Comparing both approaches when the depth of the features is
known, which is the normal use case for 6-DoF approaches. This
is to conﬁrm that our estimator works well in the normal case,
meaning it is not only good for initialization but also for tracking.

The problem of the 6-DoF estimator is that the error in the esti-
mated depth of the features is going to propagate to all the estimated
parameters (rotation and translation). However, in our (5-DoF + 1-DoF)
estimator, the error in the estimated depth only propagates to the trans-
lation magnitude and it does not have any inﬂuence in the estimated
rotation or in the translation direction. Our results, that can be observed
in Figure 7.1, conﬁrm these hypotheses. Note that the rotational error
in our approach is independent of the accuracy of the depth, which
is really important for our use case as users might rotate their phones
without applying any translational motion. On the other hand, the
6-DoF estimator estimates a signiﬁcantly less accurate rotation if the
estimated depth is unknown, conﬁrming our hypothesis.

In Figure 7.1 we can withdraw a similar conclusion for the transla-
tion error. In this case, if the depth is unknown our estimator is also
more accurate than the 6-DoF estimator. When the depth is known,
both estimators behave similarly. Also, as expected, the ﬁnal trans-
lation error is increased in both estimators when depth is unknown.
However, not having depth has a way smaller inﬂuence in our estimator
(median error increases from 3 % to 6 %) than in the 6-DoF estimator
(median error increases from 3 % to 19 %). This is because depth error
only propagates to the translation magnitude in our approach while it
propagates to all estimated parameters in the 6-DoF estimator.

Using the same data from previous experiment, we also report the
accumulated keyframe-to-frame average errors per number of frames in
Figure 6. This is a very important result as it shows our approach has a
low and bounded error for the entire trajectory (between 1 % and 3 %)
while the classic 6-DoF estimator accuracy linearly deteriorates as the
baseline (number of frames) increases. The ﬁnal error for the classic
estimator is one order of magnitude worse after 37 frames (between 13
% and 15 %).

These experiments conﬁrm the validity of our approach, demonstrat-
ing that it can be a good replacement for the classical 6-DoF estimator
thanks to the fact it has better properties, specially during initialization
where we face low-parallax motions and features cannot be triangulated
accurately.

The interested reader can also conﬁrm the validity of our approach
by looking at our video from the supplementary material (https://
youtu.be/ZGmzXK-dj1Y).

𝑓!𝑑!patch-search areas along epipolar line𝑓!’patch warp𝑹𝒖𝑠keyframecurrent frameconstant depth for unini4alized points𝑹𝒖𝑠keyframecurrent frame𝑓!𝑝!𝑓!’Fig. 6. Orientation and translation error per number of frames. We
compare our approach against the classic 6-DoF estimator when depth is
not available. Out approach has a bounded average error while the error
of the classic 6-DoF estimator linearly increases with the frame number.
Errors are reported as the ratio [%] between the average absolute error in
a frame and the maximum displacement (orientation or rotation) between
any two points in the trajectory.

associated to those correspondences into the keyframe and the frame.
We subsample the dataset to have an affordable number of keyframe-to-
frame pairs per recording, resulting in around 300 pairs per recording
on average. Both the dataset and the results obtained in this paper
for each algorithm (see next Section) can be downloaded from https:
//github.com/facebookresearch/relative_pose_dataset.

7.2.2 Evaluation with TUM dataset [28]
In this section, we compare our proposal for the relative pose es-
timator problem against the OpenGV implementation (https://
laurentkneip.github.io/opengv/) provided by Kneip and Ly-
nen [18] and QCQP solution from Briales et al. [4]. QCQP code is not
available online but it was provided by the authors. We use the dataset
that we explained in the previous subsection 7.2.1 for this evaluation.
Current implementation of the QCQP solution from Briales et al.
[4] does not admit initial guesses while our proposal and Kneip and
Lynen [18] proposal do admit initial guesses. As a ﬁrst experiment, we
evaluate the importance of the initial guesses. We compare the three
approaches in a recording from TUM benchmark (Sturm et al. [28])
and report the results we obtained with different accuracy levels of the
initial guesses.

Fig. 5. Comparison between classical 6-DoF estimators and our proposal
(5-DoF + 1-DoF estimator). We distinguish between two cases: 1)
general case, where depth is available and 2) depth is not available
– i,e. during initialization phase. Errors are reported as the ratio [%]
between the maximum error (orientation or translation) and the maximum
displacement (rotation or translation) between any two points in the
trajectory. Our approach outperforms the classical 6-DoF estimator
when depth is not available (more details in the text). The whisker plots
representation is as follows: P5, P25, median, P75 and P95.

7.2 Comparison against the state-of-the-art

The initial guesses are generated as follows:

We have compared our approach against state-of-the-art approaches for
the relative pose problem. The TUM benchmark has been used for the
evaluation.

7.2.1 Dataset for the relative pose problem

We release a dataset that we have generated from TUM benchmark
(Sturm et al. [28]) to evaluate relative pose estimators and therefore
facilitate the comparison against future solutions for the relative pose
problem. To this purpose, we use six recordings from TUM benchmark
– two from each different Freiburg Kinect sensor. We run ORB-Slam
(Mur-Artal et al. [24]) in every recording and we store the keyframe-to-
frame bearing correspondences –after removing potential outliers with
our RANSAC approach– into text ﬁles. The corresponding ground-
truth pose from keyframe-to-frame is also provided for quantitative
evaluation. We also generate the same feature correspondences but with-
out noise to facilitate the debugging when ﬁrst using this dataset. We
produce the noiseless correspondences by projecting the 3D map points

Rguess = expso(3)

(cid:17)
(cid:16)
logSO(3)(Rgt) ∗ (1.0 − Γ)

(13)

Where Rgt is the ground-truth relative pose between both cameras
and Γ goes from 0.0 (perfect initial guess) to 1.0 (inaccurate initial
guess). In our ﬁgures, an initial guess error of X% means Γ = 0.01X
in this equation.

As it can be observed in Figure 7, our approach and Kneip and
Lynen [18] approach are quite inaccurate when the initial guesses
are not good. This is expected as these approaches are non-linear
optimizations that normally ﬁnd a local minimum close to the initial
guess. QCQP solution from Briales et al. [4] principal advantage is that
is a solution that comes with global optimality guarantees making this
solution the preferred one, specially if initial guesses are inaccurate.
However, the global minimum is not guaranteed to be the one that
achieves the most accurate pose, specially in ill-posed problems. For
this reason, Kneip and Lynen [18] and our approach obtain comparable
or even better results than QCQP approach from Briales et al. [4] if the

5	DoF	+	1	DoFwith	Depth5	DoF	+	1	DoFwithout	Depth6	DoF	withDepth6	DoF	withoutDepth0510152025Orientation	error	[%]5	DoF	+	1	DoFwith	Depth5	DoF	+	1	DoFwithout	Depth6	DoF	withDepth6	DoF	withoutDepth010203040Translation	error	[%]Fig. 7. Comparison between QCQP approach from Briales et al. [4], Kneip and Lynen [18] and our approach. We have used the TUM dataset ”fr3
structure texture near” for this comparison. The percentage number speciﬁes the error of the initial guess (see equation 13 for the deﬁnition of the
initial guess error). Our approach consistently outperforms Kneip and Lynen [18] and it also outperforms QCQP if the initial guess error is 30% or
smaller. The whisker plots representation is as follows: P5, P25, median, P75 and P95. We release this dataset and our results to facilitate the
comparison against other approaches in https://github.com/facebookresearch/relative_pose_dataset.

Fig. 8. Comparison between QCQP approach from Briales et al. [4], Kneip and Lynen [18] and our approach for 6 datasets from TUM benchmark
(Sturm et al. [28]). Our approach outperforms both QCQP approach from Briales et al. [4] and Kneip and Lynen [18] in most of the recordings. We
have used an initial guess error of 30% in this experiment. See equation 13 for the deﬁnition of the initial guess error. The whisker plots representation
is as follows: P5, P25, median, P75 and P95. Legend of the datasets is as follows: rpy1 (fr1 rpy), xyz1 (fr1 xyz), xyz2 (fr2 xyz), desk2 (fr2 desk2),
far3 (fr3 structure texture near) and near3 (fr3 structure texture far). We release this dataset and our results to facilitate the comparison against other
approaches in https://github.com/facebookresearch/relative_pose_dataset.

initial guesses are good enough. According to these experiments, our
approach can handle initial guess errors of up to 30%, which is good
enough as the initial guesses are computed from the previous frame,
meaning the potential Γ we need to handle is equal to 1 − (N − 1)/N
and therefore the initial guess error will to zero as N increases. Where
N is the number of frames between keyframe and frame. Note that our
approach has better convergence properties than Kneip and Lynen [18],
it is able to converge to an accurate solution using worse initial guesses.
This is mostly due to our second contribution of the paper, which is
combining the functional and its Jacobians in the residual which helps
ﬁnding the global minimum easier. We analyze this weight in more
detail in the Section 7.3.

In a second experiment (see Figure 8), we compare the three ap-
proaches in six recordings from the TUM benchmark. In this experi-
ment, we have used the initial guesses with 30% of error. Note that our
approach outperforms both QCQP approach from Briales et al. [4] and
Kneip and Lynen [18] in most of the recordings.

7.3 Validation of the proposed residual

The previous experiment from Section 7.2 validates our proposal for
the residual of the iterative relative pose problem. However, we include
a second experiment to further analyze the inﬂuence of our contribution
in the formulation. The inﬂuence of our proposal can be tuned with the
weight W . For this experiment, we use synthetic data and same camera
model as in the experiments from Section 7.1. We create a random set
of 2D-2D correspondences between two different camera views (with
uncertainty equal to 0.75 pixels). We perturb the poses, and the initial
guesses for the rotation and translation direction contain an error of
around 10 degrees and 50 degrees in average, respectively. We run
the relative pose estimator and compute the error as a function of the

weight W (which ranges from 0 to 1000). We run 50 experiments per
weight.

Observe in Figure 10 that the best results are obtained with weights
bigger than zero. However, note that we get big errors if we use huge
values for the weight. In this case, the problem becomes ill-posed as the
functional (1-D) will have a way higher inﬂuence than the Jacobians
(5-D) and the residual will become effectively 1-D while the number of
parameters to estimate is still 5. Having a weight equal to zero results in
the original residual (with only the Jacobians), resulting in high errors
in average when compared against our approach.

The new residual is particularly helpful when the initial guess of the
relative pose is far from the optimal one. In this case, the convergence
properties are improved as the functional is included in the residual.
As expected, if one repeats this test with good initial guesses for the
relative pose, the results obtained for both residuals will be accurate
and very close to each other.

We do an additional experiment with real data to further validate
the inclusion of the functional in the residual. The reader is referred to
Figure 9 for more details.

7.4 Complexity of our approach

Our pipeline runs in real-time in both low-end and high-end devices.
We have measured the compute of our full visual odometry (tracker
and pose estimator) in a Samsung-S10 and in a Huawei-P20. We have
obtained average compute times of ∼10 and ∼25 ms respectively. The
frame to frame tracker and the pose estimator represent the ∼ 60% and
∼ 40% of the total compute respectively. While Kneip and Lynen [18]
estimator also works in real time and has a similar complexity as our
approach, QCQP approach from Briales et al. [4] is implemented in
Matlab and it takes several seconds of compute per frame.

Fig. 9. Evaluation of the addition of the functional in the residual. Experiment using TUM dataset ”fr3 structure texture near”. The percentage
number indicates the initial guess error (see equation 13). Note our results are worse if the functional is not included in the residual (weight =
0). Our approach can converge for higher errors of the initial guess when compared against Kneip and Lynen [18] approach. The whisker plots
representation is as follows: P5, P25, median, P75 and P95.

tainties and robust cost functions to down-weight outliers in the
functional to minimize in the relative pose estimator.

• merging the translation magnitude and relative pose estimators
into a single probabilistic estimation module that can consume
both features with depth and without depth instead of decoupling
the estimation in two different modules.

9 APPENDIX

Fig. 10. Positional and rotational errors as a function of the weight
W proposed in equation 7. The Figure shows that our proposal does
improve the results signiﬁcantly in optimizations where the initial guess
is far from the actual solution. The improvements are up to a factor of 10.
Also, the estimator is quite robust to this weight, values between 15 and
250 obtain a similar level of accuracy.

7.5 Failure cases.

As demonstrated in the experimental section, the main failure case of
our approach is the low accuracy achieved when the initial guess is
far from the true value. Even though we tried to mitigate this issue by
robustifying our residual, we still have convergence issues and working
on a more robust solution remains for future work.

Similarly to most relative pose estimators in the literature, our rel-
ative pose estimator is very sensitive to outliers. Even though we do
not handle outliers in the estimator itself, we wrap the relative pose
estimator inside of a RANSAC scheme to mitigate this issue.

8 CONCLUSIONS AND FUTURE WORK

In this paper, we have proposed a novel monocular visual odometry
that initializes without motion parallax and estimates a 6-DoF pose
from ﬁrst frame on. This is achieved by combining a relative pose
estimator and a translation magnitude estimator. We have shown this
estimator outperforms the classical 6-DoF estimator in initialization
stages with low parallax motion. We believe the usage of relative pose
estimators has a great potential in monocular SLAM due to their ability
of not failing with pure rotational motions or with poor map estimation.
For the relative pose problem, we have also proposed a new residual
combining the Jacobians of the functional and the functional itself.
The residual is minimized using a Levenberg–Marquardt optimizer.
We demonstrate that minimizing both errors is more accurate than
minimizing only the Jacobians.

There are some opportunities for future work:

• ﬁnding an analytic solution for the introduction of feature uncer-

In this section, we derive the Jacobians of the functional with respect
∂ xxxCCCxxx(cid:124)
∂ θi

to the so(3) rotation parameters

and the translation direction 2-

that are used as part of the residual to minimize

DoF manifold

in equation 7.

∂ xxxCCCxxx(cid:124)
∂ βi

We apply the chain rule to derive them. First, we compute the

derivative with respect to xxx:

∂ xxxCCCxxx(cid:124)
∂ xxx

= 2CCCxxx

(14)

The Kronecker product (Van [30]) is used to get the derivative with
respect to the translation direction uuu and the vectorized form of the
rotation (rrr = vec(RRR)).

∂ xxx
∂ rrr

∂ xxx
∂ uuu

= kroneckerProduct (uuu, III9x9)

= kroneckerProduct (III3x3, rrr)

(15)

(16)

Relative of the rotation matrix with respect to each axis i = x, y, z:

∂ rrr
∂ θi

= vec (RRR[uniti]x)

(17)

[]x is the skew-symmetric matrix and uniti is the unit vector in the
direction of the i axis.

The translation direction is parametrized using the z-axis (third
column) of a rotation matrix (RRRuuu ∈ SO3() ). Therefore, its Jacobian is
computed as follows:

∂ uuu
∂ βββ

= vec

(cid:16)
[RRRuuu[unitz]x]topBlock(3,2)

(cid:17)

The ﬁnal Jacobians are computed applying the chain rule:

∂ xxxCCCxxx(cid:124)
∂ θi
∂ xxxCCCxxx(cid:124)
∂ βββ

=

=

∂ xxxCCCxxx(cid:124)
∂ xxx
∂ xxxCCCxxx(cid:124)
∂ xxx

∂ xxx
∂ rrr

∂ rrr
∂ θi

∂ xxx
∂ uuu

∂ uuu
∂ βββ

(18)

(19)

(20)

and accurate monocular slam system.
31(5):1147–1163, 2015.

IEEE transactions on robotics,

[24] R. Mur-Artal and J. D. Tard´os. Orb-slam2: An open-source slam system
for monocular, stereo, and rgb-d cameras. IEEE Transactions on Robotics,
33(5):1255–1262, 2017.

[25] R. A. Newcombe, S. Izadi, O. Hilliges, D. Molyneaux, D. Kim, A. J.
Davison, P. Kohi, J. Shotton, S. Hodges, and A. Fitzgibbon. Kinectfusion:
Real-time dense surface mapping and tracking. In 2011 10th IEEE inter-
national symposium on mixed and augmented reality, pp. 127–136. IEEE,
2011.

[26] J. Park and S. Boyd. General heuristics for nonconvex quadratically
constrained quadratic programming. arXiv preprint arXiv:1703.07870,
2017.

[27] J. Stuelpnagel. On the parametrization of the three-dimensional rotation

group. SIAM review, 6(4):422–430, 1964.

[28] J. Sturm, N. Engelhard, F. Endres, W. Burgard, and D. Cremers. A
benchmark for the evaluation of rgb-d slam systems. In 2012 IEEE/RSJ
International Conference on Intelligent Robots and Systems, pp. 573–580.
IEEE, 2012.

[29] B. Triggs, P. F. McLauchlan, R. I. Hartley, and A. W. Fitzgibbon. Bundle
adjustment—a modern synthesis. In International workshop on vision
algorithms, pp. 298–372. Springer, 1999.

[30] C. F. Van Loan. The ubiquitous kronecker product. Journal of computa-

tional and applied mathematics, 123(1-2):85–100, 2000.

REFERENCES

[1] P.-A. Absil, R. Mahony, and R. Sepulchre. Optimization algorithms on

matrix manifolds. Princeton University Press, 2009.

[2] A. M. Andrew. Multiple view geometry in computer vision. Kybernetes,

2001.

[3] M. Bloesch, S. Omari, M. Hutter, and R. Siegwart. Robust visual inertial
odometry using a direct ekf-based approach. In 2015 IEEE/RSJ interna-
tional conference on intelligent robots and systems (IROS), pp. 298–304.
IEEE, 2015.

[4] J. Briales, L. Kneip, and J. Gonzalez-Jimenez. A certiﬁably globally
optimal solution to the non-minimal relative pose problem. In Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition, pp.
145–154, 2018.

[5] C. Cadena, L. Carlone, H. Carrillo, Y. Latif, D. Scaramuzza, J. Neira,
I. Reid, and J. J. Leonard. Past, present, and future of simultaneous
localization and mapping: Toward the robust-perception age. IEEE Trans-
actions on robotics, 32(6):1309–1332, 2016.

[6] A. Concha and J. Civera. Dpptam: Dense piecewise planar tracking and
mapping from a monocular sequence. In 2015 IEEE/RSJ International
Conference on Intelligent Robots and Systems (IROS), pp. 5686–5693.
IEEE, 2015.

[7] A. Concha and J. Civera. Rgbdtam: A cost-effective and accurate rgb-d
tracking and mapping system. In 2017 IEEE/RSJ international conference
on intelligent robots and systems (IROS), pp. 6756–6763. IEEE, 2017.

[8] J. Engel, V. Koltun, and D. Cremers. Direct sparse odometry.

IEEE
transactions on pattern analysis and machine intelligence, 40(3):611–625,
2017.

[9] J. Engel, T. Sch¨ops, and D. Cremers. Lsd-slam: Large-scale direct monoc-
In European conference on computer vision, pp. 834–849.

ular slam.
Springer, 2014.

[10] J. M. Facil, B. Ummenhofer, H. Zhou, L. Montesano, T. Brox, and
J. Civera. Cam-convs: Camera-aware multi-scale convolutions for single-
view depth. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pp. 11826–11835, 2019.

[11] M. Faessler, F. Fontana, C. Forster, and D. Scaramuzza. Automatic re-
initialization and failure recovery for aggressive ﬂight with a monocular
vision-based quadrotor. In 2015 IEEE international conference on robotics
and automation (ICRA), pp. 1722–1729. IEEE, 2015.

[12] M. E. Fathy, A. S. Hussein, and M. F. Tolba. Fundamental matrix estima-
tion: A study of error criteria. Pattern Recognition Letters, 32(2):383–391,
2011.

[13] O. D. Faugeras and F. Lustman. Motion and structure from motion in a
piecewise planar environment. International Journal of Pattern Recogni-
tion and Artiﬁcial Intelligence, 2(03):485–508, 1988.

[14] M. A. Fischler and R. C. Bolles. Random sample consensus: a paradigm
for model ﬁtting with applications to image analysis and automated car-
tography. Communications of the ACM, 24(6):381–395, 1981.

[15] C. Forster, Z. Zhang, M. Gassner, M. Werlberger, and D. Scaramuzza.
Svo: Semidirect visual odometry for monocular and multicamera systems.
IEEE Transactions on Robotics, 33(2):249–265, 2016.

[16] M. Garcia-Salguero, J. Briales, and J. Gonzalez-Jimenez. Certiﬁable
relative pose estimation. Image and Vision Computing, 109:104142, 2021.
[17] J. Huang, R. Liu, J. Zhang, and S. Chen. Fast initialization method for
In 2017 IEEE International
monocular slam based on indoor model.
Conference on Robotics and Biomimetics (ROBIO), pp. 2360–2365. IEEE,
2017.

[18] L. Kneip and S. Lynen. Direct optimization of frame-to-frame rotation. In
Proceedings of the IEEE International Conference on Computer Vision,
pp. 2352–2359, 2013.

[19] S. H. Lee and J. Civera. Rotation-only bundle adjustment. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
pp. 424–433, 2021.

[20] J. Li, H. Bao, and G. Zhang. Rapid and robust monocular visual-inertial
initialization with gravity estimation via vertical edges. In 2019 IEEE/RSJ
International Conference on Intelligent Robots and Systems (IROS), pp.
6230–6236. IEEE, 2019.

[21] H. C. Longuet-Higgins. The reconstruction of a plane surface from two
perspective projections. Proceedings of the Royal Society of London.
Series B. Biological Sciences, 227(1249):399–410, 1986.

[22] J. J. Mor´e. The levenberg-marquardt algorithm: implementation and

theory. In Numerical analysis, pp. 105–116. Springer, 1978.

[23] R. Mur-Artal, J. M. M. Montiel, and J. D. Tardos. Orb-slam: a versatile

