1
2
0
2

n
u
J

5
2

]

G
L
.
s
c
[

2
v
3
2
0
5
0
.
2
1
0
2
:
v
i
X
r
a

NSL: HYBRID INTERPRETABLE LEARNING FROM NOISY RAW
DATA∗

A PREPRINT

Daniel Cunnington1,2, Alessandra Russo2, Mark Law2, Jorge Lobo2 and Lance Kaplan3

1IBM Research Europe, Winchester, UK., Contact: dancunnington@uk.ibm.com
2Imperial College London, London, UK
3Army Research Laboratory, Adelphi, MD, USA

June 28, 2021

ABSTRACT

Inductive Logic Programming (ILP) systems learn generalised, interpretable rules in a data-efﬁcient
manner utilising existing background knowledge. However, current ILP systems require training
examples to be speciﬁed in a structured logical format. Neural networks learn from unstructured
data, although their learned models may be difﬁcult to interpret and are vulnerable to data perturba-
tions at run-time. This paper introduces a hybrid neural-symbolic learning framework, called NSL,
that learns interpretable rules from labelled unstructured data. NSL combines pre-trained neural
networks for feature extraction with FastLAS, a state-of-the-art ILP system for rule learning under
the answer set semantics. Features extracted by the neural components deﬁne the structured context
of labelled examples and the conﬁdence of the neural predictions determines the level of noise of the
examples. Using the scoring function of FastLAS, NSL searches for short, interpretable rules that
generalise over such noisy examples. We evaluate our framework on propositional and ﬁrst-order
classiﬁcation tasks using the MNIST dataset as raw data. Speciﬁcally, we demonstrate that NSL
is able to learn robust rules from perturbed MNIST data and achieve comparable or superior accu-
racy when compared to neural network and random forest baselines whilst being more general and
interpretable.

1 Introduction

Inductive Logic Programming (ILP) systems learn (a set of) logical rules, that together with some background knowl-
edge, explain a set of examples. ILP systems are often praised for their data efﬁciency [2, 3] and the interpretable
nature of their learned rules [4]. Recent state-of-the-art ILP systems have also shown to be noise-tolerant and capable
of learning complex knowledge from mislabelled data in an effective manner [5, 6]. A common characteristic of all
state-of-the-art ILP systems is the fact that examples are required to be speciﬁed in a structured, logical format. This
may hinder their applicability to real-world domains, leaving, as one of their main outstanding challenges, the ability
to learn from unstructured data where contextual information may be noisy or perturbed.

Differentiable learning systems, such as deep neural networks [7], have demonstrated powerful function approximation
on a wide variety of tasks, solving classiﬁcation problems directly from unstructured data. However, large amounts
of training examples are required, learned models are difﬁcult to interpret [8] and may be vulnerable to distributional
shift, where simple data perturbations are observed at run-time [9]. In this case, neural network predictions may be
incorrect and the focus of this paper is learning robust rules in the presence of incorrect neural network predictions,
taking into account the conﬁdence score of such predictions.

To achieve this, we introduce a hybrid Neural-Symbolic Learning framework, called NSL, that aims to combine the
advantages of both ILP and differentiable learning systems. NSL aims to learn a set of interpretable rules, that together

∗This article has been updated, please refer to FF-NSL: Feed-Forward Neural-Symbolic Learner [1]

 
 
 
 
 
 
A PREPRINT - JUNE 28, 2021

with a (possibly empty) background knowledge, explain a given set of labelled unstructured data. It does so, by using a
pre-trained neural network for extracting features from the unstructured data, and automatically generating structured
context-dependent examples that are used by a state-of-the-art ILP system, FastLAS [6] to learn rules that explain the
given labelled unstructured data. The neural network predictions form the context of FastLAS’s labelled examples
and the conﬁdence of the neural network predictions are aggregated to deﬁne a notion of penalty for these examples.
FastLAS uses this notion of penalty, together with the length of rules, to deﬁne a cost over possible solutions. Rules that
do not cover a context-dependent example pay the penalty of the example. Optimal solutions are computed as the set
of rules with minimal cost. This enables NSL to cater for neural predictions with low conﬁdence due to perturbations
in the unstructured data and still learn rules that generalise (i.e. shorter rules pay a lower cost) and maximise coverage
of labelled unstructured data with the highest aggregated conﬁdence of neural predictions.

The NSL framework is evaluated on two classiﬁcation tasks, a propositional animal classiﬁcation task and a ﬁrst-order
valid Sudoku board classiﬁcation task, where numerical features are extracted from MNIST digit images [10]. The
neural network component is pre-trained on non-perturbed MNIST digits. In each task, the NSL framework is trained
by perturbing the MNIST digits – rotating each digit image 90◦ clockwise and rules are learned that deﬁne animal class
and the notion of valid Sudoku boards respectively. The learned rules are evaluated on structured ground truth test
data and unstructured perturbed test data to, respectively (i) validate the accuracy of the learned rules with respect to a
clean dataset (even though the rules were learned in the presence of perturbation at training time), and (ii) evaluate the
robustness of the learned rules when applied to unseen perturbed unstructured data. In the ﬁrst case and in both learning
tasks, NSL is able to learn robust rules in the presence of training data perturbations, achieving comparable or superior
accuracy than neural network and random forest baselines. Also, NSL learns rules that are more general and more
interpretable. In the second case, when perturbations occur at run-time, NSL is able to maintain robust classiﬁcation
performance up to ∼40% perturbations, outperforming the neural network and random forest baselines. Finally, in the
Sudoku classiﬁcation task, we also demonstrate NSL’s data efﬁciency compared to the neural network baseline, as the
neural network requires 12.5X the number of examples required by NSL to achieve comparable performance.

The paper is structured as follows. In the next section we review relevant background material. We then introduce our
NSL framework for learning rules from unstructured data, and discuss its algorithms. We then follow with results of
our extensive evaluation. Finally we conclude with a discussion of related work.

2 Background

This section brieﬂy introduces notations and terminologies used throughout the paper. An ILP learning task aims to
ﬁnd a set of rules, called a hypothesis, that explains a set of labelled examples [11]. Different approaches have been
proposed in the literature [12] and in this paper we focus on the Learning from Answer Sets (LAS) approach [13],
as the recently proposed ILASP systems have been shown to be robust to noisy examples [14] and scalable to large
hypothesis spaces [6]. An Answer Set (ASP) program formalises a given problem in a logical form so that solutions to
the program, called answer sets, provide solutions to the original problem. Formally, an ASP program is a set of rules
of the form h : − b1 . . . bn, not c1, . . . not cm where h, bi and cj are atoms; h is the head of the rule, and b1 . . . not cm
is the body of the rule, formed by a conjunction of positive literals (b1 . . . bn) and negative literals (not c1 . . . not cm)
where not is negation as failure. Given an ASP program P , the Herbrand Base of P (HB(P )) is the set of ground
atoms constructed using the predicates and constants that appear in P . An interpretation I is a subset of HB(P ).
Given an interpretation I, the reduct of the grounding of an ASP program P , denoted as P I (see [15] for deﬁnition
and algorithm) is a grounded program with no negation as failure. I is an answer set of P if and only if it is the
minimal model of the reduct program P I . We denote the set of answer sets of a program P with AS(P ).

In the LAS framework, the objective is to learn ASP programs from examples that are partial interpretations. A partial
interpretation epi is a pair of sets of ground atoms (cid:10)einc, eexc
(cid:11), called inclusion and exclusion sets respectively [6, 14].
An interpretation I extends e iff einc ⊆ I and eexc ∩ I = ∅. In ILASP [14], an example can have an associated context
and penalty value. In this case, the example is called a weighted context-dependant partial interpretation (WCDPI).
This is deﬁned as a tuple e = heid, epen, epi, ectxi where eid is a unique identiﬁer for e, epen is either a positive integer
or ∞, called a penalty, epi is a partial interpretation and ectx is an ASP program relative to the example, called context.
A WCDPI e is accepted by a program P if and only if there is an answer set of P ∪ ectx that extends epi. A task
that learns ASP programs from WCDPIs is called a context-dependent LAS task and denoted as ILP context
. Such a
task is deﬁned as a tuple hB, SM , Ei, where B is background knowledge, expressed as an ASP program, SM is the
hypothesis space, deﬁned by a language bias M 2, and E is a set of WCDPIs. The hypothesis space deﬁnes the set of
rules that can be used to construct a solution to the task. A hypothesis H ⊂ SM is a solution to a given ILP context
task if and only if for every e ∈ E, H covers e, that is B ∪ ectx ∪ H accepts e.

LAS

LAS

2For a detailed deﬁnition of a language bias see [5].

2

A PREPRINT - JUNE 28, 2021

Figure 1: NSL framework with an example Sudoku board classiﬁcation task

FastLAS is a system for solving a speciﬁc class of ILP context
learning tasks, where for all e ∈ E, |AS(B ∪ ectx)| = 1
and no predicate in the head of a rule in SM may occur in the body of any rule in SM or in B [6]. Such tasks are referred
to in the literature as Observational Predicate Learning (OPL) tasks. In this paper we will denote them as ILP OP L
LAS ,
and the set of possible solutions of a given ILP OP L
LAS (LT ). Unless otherwise speciﬁed, we will
assume that our ILP OP L

LAS task LT , as ILP OP L

LAS tasks have WCDPIs as examples.

LAS

The FastLAS system uses a scoring function to compute optimal solutions of a given learning task LT = hB, SM , Ei.
This is a function S : P rograms × TOP L → R≥0 where P rograms is the set of all ASP programs and TOP L is the
set of all OPL tasks deﬁned above (see [6] for a formal deﬁnition). A hypothesis H ∈ P rograms is said to be an
optimal solution of a task LT ∈ TOP L with respect to a scoring function S iff H ∈ ILP OP L
LAS (LT ) and there is no
H ′ ∈ ILP OP L
LAS (LT ) such that S(H ′, LT ) < S(H, LT ). Scoring functions can be domain-speciﬁc and can be given
as input to FastLAS prior to solving a learning task. FastLAS is capable of supporting any scoring function that is
decompositional, that is for each P ∈ P rograms and LT ∈ TOP L:

S(P, LT ) = X
r∈P
where Srule : Rules × TOP L → R≥0 is a function that scores individual rules of a solution H. We refer to Srule as
the decomposition of S.

Srule(r, LT )

3 NSL Framework

This section introduces our Neural-Symbolic Learning (NSL) framework for learning rules from unstructured data.
The framework uses two main computational components: a neural network, for extracting features from unstructured
data, and FastLAS for learning rules from WCDPI examples. The bridge between these two components is realised
through the NSL example generator, which converts unstructured labelled data into structured examples by generating
a WCDPI example for FastLAS, from each set of neural predictions and a given label. A high level overview of the
NSL framework, applied to a Sudoku classiﬁcation task, is shown in Figure 1. The aim of the Sudoku task is to learn
the classiﬁcation of Sudoku boards as valid or invalid. The input is a set of images of digits in a Sudoku board with
a valid/invalid label. The NSL framework returns as output an optimal set of rules that deﬁne the notion of an invalid
Sudoku board. These rules can then be used to classify unseen Sudoku boards (given as sequences of digit images)
as valid or invalid (see evaluation section). In what follows we present in detail the NSL example generator and the
scoring function used by FastLAS as optimisation criteria, based on aggregated conﬁdence of the neural network
feature predictions. We then formalise the NSL learning task.

3.1 NSL Example Generator

The neural component of our NSL framework is a set of feature extractors N , each pre-trained to extract a speciﬁc
feature from a given piece of unstructured raw data. Let d ∈ D be a piece of unstructured raw data (e.g. an image)
and t be a string representing a speciﬁc feature of the unstructured raw data (e.g. a digit). A sample input x to the
neural component is a pair hd, ti for which a feature extractor nt exists in N . For each sample input x = hd, ti, the
feature extractor nt ∈ N outputs a k-dimensional probability vector ρd over the k-class feature t of d, i.e. ρd = nt(d).
Within the scope of this paper, we assume that a speciﬁc feature extractor nt can only extract feature t from a piece of
unstructured raw data d of a given sample x = hd, ti. Let X be a set of such samples.

We assume that each nt ∈ N is a pre-trained neural network with ﬁxed weights performing a classiﬁcation task on
input d. Each feature extractor nt generates a prediction yt
conf =
max(ρd). These represent, respectively, the prediction of feature t and associated conﬁdence estimation output by the
neural network nt for a given input d.

pred = argmax(ρd) with a level of conﬁdence yt

3

A PREPRINT - JUNE 28, 2021

For each piece of unstructured raw data di ∈ D, the conﬁdence score yti
conf of the corresponding feature extractor
in N is used by the NSL example generator to deﬁne the penalty of a WCDPI example constructed from D. This is
achieved by means of a general aggregation function that combines a set of yti
conf conﬁdence estimations into a single
conﬁdence score value. So, given a set of unstructured raw data D and an associated set of samples XD = {hdi, tii},
the overall conﬁdence estimation for D is an aggregation of the conﬁdence estimation of each sample. This aggregated
estimation, denoted as yD
conf , constitutes a single conﬁdence estimation value for a set of features extracted from
unstructured raw data D.

The features extracted from unstructured raw data form the atomic building blocks for the context of the generated
WCDPI examples, ectx. In FastLAS, contexts can be any ASP program which imposes additional example-based
constraints that are taken into account during the learning task. In this paper, we consider a context to be a conjunction
of atoms. To deﬁne the overall conﬁdence estimation of a context ectx for an example e, NSL uses an aggregation
function A deﬁned in terms of triangular norms, (or t-norms) [16]. Given that a context of a generated example is
a conjunction of atoms, NSL uses the G¨odel t-norm (Tg(x, y) = min(x, y)) ([17] and [18]) to recursively deﬁne
the aggregation function A. This is formally deﬁned below. The aggregated conﬁdence estimation yD
conf deﬁnes the
penalty value, epen, of a WCDPI example e, whose context ectx has been constructed from the predictions yt
pred of a
set of neural network feature extractors.

[0, 1]2 → [0, 1] be the G¨odel t-norm function deﬁned as
Deﬁnition 1 (General aggregation function). Let Tg :
Tg(x, y) = min(x, y). Let Az : [0, 1]z → [0, 1], where z ≥ 2, be an aggregation function, recursively deﬁned as
follows3:

A2(x1, x2) = Tg(x1, x2)

Az(x1, . . . , xz) = Tg(Aj(x1, . . . , xj), Az−j(xj+1, . . . , xz))

A general aggregation function A : [0, 1]z → R is then given by A = ⌊λAz⌋ for z ≥ 2, where λ is a parameter used
alongside the ﬂoor function to convert the aggregated conﬁdence score Az([0, 1]z) ∈ [0, 1] to an integer value.
Deﬁnition 2 (Context Generator). Let F be the set of all possible sets of tuples hypred, t, αi indicating a prediction
ypred for feature t. α can be used to encode additional information related to a particular feature prediction, such as
the coordinates of a digit in a Sudoku board classiﬁcation task. A context generator is a function G : F → C, where
C is the set of all possible contexts for a WCDPI. Given an fi ∈ F , G(fi) = {t(α, ypred). | hypred, t, αi ∈ fi}.4

Note that G(fi) gives the context ectx of an example for the FastLAS component based on the neural feature predic-
tions.

Example 1. Let us assume a learning task with a set of unstructured raw data D = { ,
} and a set of features
T = {digit, object}. Let us also assume a set of feature predictions f = {h2, digit, ∅i, hcat, object, ∅i} and a label l
that corresponds to the set of unstructured raw data D. The context generator would then construct from the predictions
f the context ectx = {digit(2). object(cat).}.

Deﬁnition 3 (NSL example). Let (ID, X, l) be an input tuple where ID is a unique identiﬁer, X is a set of samples
of unstructured raw data with associated set fX of predicted features and a general aggregated conﬁdence score AX .
Finally, let l be a label from a given set L of possible labels. An NSL example e is a WCDPI given by the tuple
hID, AX , epi, G(fX )i, where the partial interpretation epi is given by h{l}, {l

∈ L \ {l}}i.

| l

′

′

Algorithm 1 generates the NSL examples from a given labelled sample of unstructured raw data.

Referring to Figure 1, the identiﬁer ID for each NSL example is shown following the #pos statement and the NSL
example penalty P EN calculated on line 13 in Algorithm 1 is shown in bold, immediately following the identiﬁer. The
NSL example penalty represents the aggregated conﬁdence from neural network feature extractors. This encourages
FastLAS to bias the learning towards hypotheses that cover NSL examples with high conﬁdence neural network
predictions, by ensuring that a high penalty is paid for leaving such examples uncovered by the learned hypothesis.
The inclusion and exclusion sets (IN C, EXC) respectively, are shown in italics5 in Figure 1, followed by the context
CT X given by the context generator G.

3Due to the associativity property of Tg the recursive case is the same for all 1 ≤ j ≤ z.
4Note that a more complex function G could be engineered, but this would require additional supervision.
5For binary classiﬁcation tasks such as the Sudoku board classiﬁcation task shown in Figure 1, we can simplify the inclusion
and exclusion sets to only contain one label to represent the type of rules being learned. In this case, rules for invalid Sudoku boards
are learned, so valid can be removed from the inclusion or exclusion set, depending on the example label.

4

Algorithm 1 NSL Example Generator

A PREPRINT - JUNE 28, 2021

′

′

| l

∈ L \ {l}};

1: procedure GENERATE(ID, X, l)
2:
3:
4:
5:
6:
7:

IN C = {l} ;
EXC = {l
P RDCT S = []; CON F S = [];
for hdi, tii ∈ X do
ρdi = nti(di);
yti
pred = argmax(ρdi);
yti
conf = max(ρdi );
P RDCT S += (yti
CON F S += yti
conf ;

pred, ti);

8:

9:

10:
11:
12:
13:
14:
15:
16: end procedure

end for
CT X = G(P RDCT S);
P EN = A(CON F S);
W CDP I = (ID, P EN, (IN C, EXC), CT X);
return W CDP I;

3.2 NSL Optimisation Criteria

Our NSL framework uses the FastLAS system [6] for learning a hypothesis. FastLAS supports user-deﬁned scoring
functions that are capable of biasing the search for a hypothesis that is optimal with respect to a given domain-
speciﬁc optimisation criteria. Also, FastLAS supports learning from noisy examples, where the notion of noise can be
domain-speciﬁc. NSL makes use of these two features of FastLAS to maximise example coverage whilst minimising
the hypothesis length, such that learned rules are interpretable and generalise over unseen examples, whilst taking into
account the conﬁdence of the neural network predictions. Speciﬁcally, NSL considers the noise of an example to be
the penalty value given by the general aggregation score of the example’s context predicted by the neural network, and
deﬁnes a scoring function that combines the standard ILP optimisation criteria, for minimising rule length to encourage
generalisation, with an example penalty that caters for the conﬁdence estimation of the neural network predictions.

Deﬁnition 4 (Penalty scoring function). Let H be a hypothesis and E be a set of generated NSL examples. A penalty
epen where epen is obtained from line 13 in algorithm 1, and
scoring function Spenalty(H, E) =

P
e∈UN COV (H,E)

U N COV (H, E) is the set of examples in E that are not covered by H. Note that H is said to cover an example e iff
H accepts e [6].

The standard ILP scoring function [12] is given by the length scoring function Slen(H) = |H| which scores a hypoth-
esis H simply by counting the number of literals in H.

As FastLAS supports user-deﬁned scoring functions, in our NSL framework, we can deﬁne a scoring function that
combines the standard length scoring function Slen with the penalty scoring function given in Deﬁnition 4, to jointly
achieve both optimisation objectives. This is formally deﬁned as follows:

Deﬁnition 5 (NSL scoring function). Let H be a set of rules and E be a set of generated NSL examples. The NSL
scoring function SN SL(H, E) = Spenalty (H, E) + γSlen(H) where γ ∈ [0, ∞] can be used to weight example
coverage or generalisation. In this paper, we assume γ = 1.

We can now deﬁne the notion of an NSL learning task. Informally, this is based on the notion of an Observational
Predicate Learning task (ILP OP L
LAS ) under the Answer Set semantics [6], where examples are labelled unstructured
data.
Deﬁnition 6 (NSL learning task). An NSL learning task is a tuple N SLtask = hB, SM , SN SL, ERAW i where B is
an ASP program called background knowledge, SM is the set of possible rules, whose head predicates are the given
labels and body predicates are predicates in B or in the given set of features T , SN SL is the NSL scoring function and
ERAW is a set of labelled raw unstructured data.

The goal of the NSL learning task is to ﬁnd an optimal solution to the task where the notion of optimality is given
below.

5

A PREPRINT - JUNE 28, 2021

Deﬁnition 7 (NSL Optimal Solution). Let LT = hB, SM , SN SL, ERAW i be an N SLtask learning task. A set of rules
H ∈ SM is an optimal solution of LT if and only if there is no H ′ ∈ SM such that SN SL(H ′, E) < SN SL(H, E)
where E is the set of NSL examples generated from the given ERAW .

4 Evaluation

To evaluate our NSL framework, we ﬁrstly focus on the ability to learn generalised and interpretable rules in the
presence of perturbed training data. Secondly, we evaluate predictive performance at run-time where test data is
perturbed proportionally to the amount of perturbations present at training time.

Our evaluation is constructed over two neural-symbolic learning tasks:

1. Zoo animal multi-class classiﬁcation where the goal is to classify an animal as either a mammal, bird, ﬁsh,
reptile, bug, amphibian, or invertebrate from a variety of features such as the number of legs. For this task,
we use the ‘Zoo’ data set6 which contains 101 examples. We select 10 numeric features and substitute digit
feature values for an image of a corresponding digit from the MNIST test set. This task can be solved using
propositional rules.

2. Sudoku board binary classiﬁcation as illustrated in Figure 1 where the goal is to learn rules that classify
a 4x4 Sudoku board as valid or invalid. Hanssen’s Sudoku puzzle generator7 is used to generate 200 valid
boards. We generate a further 200 invalid boards manually. In this task, digits on the Sudoku board are also
replaced with images of corresponding MNIST test set digits. This task requires ﬁrst-order rules (i.e. rules
with variables) to correctly differentiate between valid and invalid Sudoku boards.

We perform 5-fold cross-validation in both learning tasks with an 80%/20% train/test split. Full details regarding the
data sets are listed in Section 4.3.

For the zoo animal classiﬁcation task we compare our NSL framework to a shallow feed forward neural network and
random forest baselines8, as neural networks and tree-based methods are known to perform well on this task [19, 20].
Also, their learned models can be evaluated for interpretability by either using a surrogate model to approximate the
predictions of a neural network, or inspecting learned trees directly in the case of a random forest.

For the Sudoku board classiﬁcation task we compare NSL to a CNN-LSTM deep neural network architecture due to
the spatial dependency between the sequence of digits on a Sudoku board. This architecture has demonstrated strong
performance on other sequence classiﬁcation tasks [21, 22]. We also compare NSL to a random forest model due to
its inherently explainable properties.

Our evaluation uses two neural network feature extractors pre-trained on the MNIST training set. Their weights remain
ﬁxed throughout our experiments. We use a LeNet 5 architecture [10] with the standard softmax classiﬁcation layer
and also a state-of-the-art uncertainty-aware network called EDL-GEN [23]9. To ensure a fair comparison with our
NSL framework, in both learning tasks, all neural network and random forest baselines are given softmax feature
extractor predictions as input and don’t learn over the raw unstructured data directly. When aggregating softmax or
EDL-GEN conﬁdence information within the construction of an NSL example, we use the G¨odel t-norm aggregation
function due to the conjunctive nature of the learning tasks presented in this paper. The classiﬁcation label in both
tasks depends on the conjunction of animal features, or the conjunction of digits on a Sudoku board.

In both learning tasks, we simulate distributional shift for the neural network feature extractors by perturbing all the
unstructured raw data within an increasing percentage of training examples. Unstructured raw data is perturbed by
rotating each MNIST image within an example 90◦ clockwise [9]10. The ﬁnal labels (i.e. the animal classiﬁcation or
the Sudoku board classiﬁcation) remain unchanged.

4.1 Learning rules from perturbed training data

Figures 2a and 2c show the results for learning rules from perturbed training data on the zoo and Sudoku tasks re-
spectively. In both tasks, the evaluation is performed on ground truth test data where the original feature values are

6https://archive.ics.uci.edu/ml/datasets/Zoo
7https://www.menneske.no/sudoku/2/
8Details of selected hyper-parameters and model architectures are given in Section 4.4
9We use the softmax and EDL-GEN feature extractor implementation from https://muratsensoy.github.io/uncertainty.html

and https://muratsensoy.github.io/gen.html respectively.

10Note. This is one example of a distributional shift.

6

A PREPRINT - JUNE 28, 2021

used and are not substituted for their corresponding MNIST digits. This is to indicate the quality of the learned rules
and to evaluate the ability to ignore data perturbations at training time. The mean classiﬁcation accuracy across all
5 cross-validation splits is reported to highlight classiﬁcation performance. The standard error of the mean across
all cross-validation splits is shown with the displayed error bars to indicate the deviation between the sampled mean
and the true population mean. The NSL Baseline uses a constant example penalty of 10 within FastLAS instead of
aggregating neural network feature extractor conﬁdence information.

y
c
a
r
u
c
c
a

t
e
s

t
s
e
T

1.00

0.95

0.90

0.85

0.80

0.75

0.70

0.65

0.60

s
e
t
a
c
i
d
e
r
p

f
o

r
e
b
m
u
n

l

a
t
o
T

100

80

60

40

20

0

y
c
a
r
u
c
c
a

t
e
s

t
s
e
T

1.00

0.95

0.90

0.85

0.80

0.75

0.70

0.65

0.60

0.55

0.50

0.45

s
e
t
a
c
i
d
e
r
p

f
o

r
e
b
m
u
n

l

a
t
o
T

1200

1000

800

600

400

200

0

0

10

20

30

40

50

60

70

80

90

0

10

20

30

40

50

60

70

80

90

0

10

20

30

40

50

60

70

80

90

0

10

20

30

40

50

60

70

80

90

Percentage of perturbed training examples (%)

Percentage of perturbed training examples (%)

Percentage of perturbed training examples (%)

Percentage of perturbed training examples (%)

(a) Zoo - accuracy

(b) Zoo - Interpretability

(c) Sudoku - accuracy

(d) Sudoku - interpretability

Figure 2: Accuracy of learned rules with structured ground truth test data and interpretability of learned rules for both
the zoo animal classiﬁcation and Sudoku board classiﬁcation tasks

In terms of ground truth test set classiﬁcation performance, NSL out-performs the baseline methods in both the zoo
and Sudoku learning tasks, with the exception of the random forest in Figure 2a. Aggregating conﬁdence information
from neural network feature extractors leads to a beneﬁt in both learning tasks after ∼40% perturbations, with the
EDL-GEN feature extractor outperforming softmax.

The zoo task in Figure 2a is relatively simple for symbolic ILP learners and the neural network baseline even in a
simple task is vulnerable to data perturbations, as NSL clearly demonstrates superior performance. NSL is marginally
beaten by the random forest at 20% and beyond 50% perturbations, although NSL is within the standard error of the
random forest. In order to obtain this increase in performance, the random forest learns a less interpretable model. To
evaluate interpretability, we obtain the total number of predicates across all learned rules and plot the mean across all 5
cross-validation splits. The standard error of the mean across all splits is indicated with error bars. Rules with a lower
number of predicates are assumed to be more interpretable [24]. Figures 2b and 2d show the total number of learned
predicates increases as more perturbations are present in the training examples. In both the zoo and Sudoku learning
tasks, NSL learns a more interpretable set of rules than the baseline methods for all percentages of training example
perturbation and NSL with an EDL-GEN feature extractor outperforms NSL with a softmax feature extractor.

We note that explaining what the random forest has learned may not be trivial, depending on the number of trees in
the forest. In our experiments we have 100 trees in the ensemble. To interpret the neural network models, a surrogate
decision tree is trained to approximate the neural network predictions [25]. For the random forest models, rules learned
from the ﬁrst tree within the ensemble are selected.

In Figure 2c, which is a more complicated task requiring the use of memory, NSL outperforms all baselines for all
percentages of training example perturbations. NSL is able to take advantage of background knowledge regarding
the layout of a Sudoku board to increase its performance. At 50% perturbations the performance of all the neural
network and random forest baselines reduce to ∼50% and start to increase again as more patterns begin to emerge in
the training data. Given the CNN-LSTM is a deep neural network architecture, we conducted a further experiment
with an increased number of training examples. We found that at 4000 training examples the CNN-LSTM was able to
achieve similar performance to NSL with 320 training examples below 50% example perturbations. This is a 12.5X
reduction, indicating the data efﬁciency of the NSL framework as a result of background knowledge integration within
FastLAS.

4.2 Run-time perturbations

This subsection presents results where perturbations are applied to unstructured data at run-time in the same manner
and at the same proportion that was observed during training in Figure 3, for both the zoo and Sudoku learning tasks.

In order to account for unconﬁdent neural network predictions at run-time, we convert the rules learned with NSL to
a ProbLog program [26] and create annotated disjunctions [27] to represent the probability of a given MNIST image
being classiﬁed as a certain digit. ProbLog then outputs a prediction as well as a probability of the prediction being
true with respect to the neural network feature extractions and the learned rules. This is interpreted as a conﬁdence

7

 
 
 
 
 
 
 
 
 
 
value to align with the baseline neural network and random forest methods which already contain built-in conﬁdence
outputs at run-time.

To evaluate both the prediction and the conﬁdence simultaneously, in addition to the standard accuracy metric, we use a

A PREPRINT - JUNE 28, 2021

modiﬁed accuracy metric, denoted probabilistic accuracy, or prob. accuracy for short, calculated as ˆa =
where pi
y true represents the predicated conﬁdence for the ground-truth class for the ith test example and n is the
number of test examples. Instead of simply counting a correct (resp.
incorrect) prediction as 1 (resp. 0) as with
standard accuracy, this ensures that the learner will be penalised for predicting correctly with low conﬁdence and also
predicting incorrectly with high conﬁdence. Error bars indicate the standard error when evaluating learned models
from all 5 cross-validation splits. For these experiments, the NSL Baseline is removed given we are evaluating in the
presence of perturbed test data and unconﬁdent neural network predictions.

y true

Pn

i=1 pi
n

y
c
a
r
u
c
c
a

t
e
s

t
s
e
T

1.00

0.95

0.90

0.85

0.80

0.75

0.70

0.65

0.60

y
c
a
r
u
c
c
a

c
i
t
s
i
l
i

b
a
b
o
r
p

t
e
s

t
s
e
T

1.00

0.95

0.90

0.85

0.80

0.75

0.70

0.65

0.60

0.55

0.50

0.45

0.40

0

10

20

30

40

50

60

70

80

90

0

10

20

30

40

50

60

70

80

90

Percentage of perturbed test examples (%)

Percentage of perturbed test examples (%)

y
c
a
r
u
c
c
a

t
e
s

t
s
e
T

1.00

0.95

0.90

0.85

0.80

0.75

0.70

0.65

0.60

0.55

y
c
a
r
u
c
c
a

c
i
t
s
i
l
i

b
a
b
o
r
p

t
e
s

t
s
e
T

1.00

0.95

0.90

0.85

0.80

0.75

0.70

0.65

0.60

0.55

0

10

20

30

40

50

60

70

80

90

0

10

20

30

40

50

60

70

80

90

Percentage of perturbed test examples (%)

Percentage of perturbed test examples (%)

(a) Zoo - accuracy

(b) Zoo - prob. accuracy

(c) Sudoku - accuracy

(d) Sudoku - prob. accuracy

Figure 3: Run-time perturbation results for both the Zoo and Sudoku learning tasks, evaluated with accuracy and prob.
accuracy

For the zoo experiments in Figure 3a, both NSL approaches outperform a neural network baseline and when evaluating
with probabilistic accuracy in Figure 3b, NSL softmax outperforms the random forest apart from 20%, 60%, 70% and
80% perturbations. In the more complex task of learning rules for invalid Sudoku boards, both NSL approaches
outperform the baselines until 40% perturbations in both Figure 3c and 3d, with the NSL EDL-GEN outperforming all
approaches until 80% perturbations in Figure 3c. Comparing Figures 3c and 3d with Figure 2c, it’s likely that at 50%
perturbations the neural network has over-ﬁtted to the pattern of perturbations in the training data and hasn’t learned
the true rules, given its strong performance when test data is perturbed and low performance when the test data is not
perturbed.

4.3 Data set Preparation

1. Zoo animal classiﬁcation This data set is obtained from the UCI Machine Learning repository and contains
101 examples. In our experiments, we select the hair, feathers, eggs, milk, aquatic, predator, ﬁns, legs and
tail features to enable experiments to be completed in a timely manner. The goal is to classify an example as
either a mammal, bird, ﬁsh, reptile, bug, amphibian, or invertebrate. We perform 5-fold cross validation to
generate 5 training sets each containing 80 examples and 5 test sets each containing 21 examples respectively.
Digit features are then substituted for a random image from the MNIST test set, corresponding to each digit.
This is initially performed for the 5 zoo training sets and for the run-time perturbation experiments this is
performed for the 5 zoo test sets also.

2. Sudoku board classiﬁcation This data set is generated using 4x4 Sudoku puzzles obtained from Hanssen’s
Sudoku puzzle generator. We obtain 200 valid puzzles and generate a further 200 invalid puzzles manually
to create a data set of 400 examples. The goal is to classify whether a Sudoku board is valid or invalid based
on the digits present in the board. Each example contains a varying number of digits and no example details
a completed board. Similarly to the zoo animal classiﬁcation data set, we perform 5-fold cross validation to
generate 5 training sets each containing 320 examples and 5 test sets each containing 80 examples respec-
tively. When evaluating the CNN-LSTM architecture with a larger data set, we obtain 2500 valid Sudoku
puzzles from Hanssen’s Sudoku puzzle generator and generate a further 2500 invalid puzzles manually. 5-
fold cross-validation is then performed to generate 5 training sets of 4000 examples and 5 test sets of 1000
examples respectively. We also perform a similar substitution of digits with random images from the MNIST
test set corresponding to the same digit.

8

 
 
 
 
 
 
 
 
 
 
A PREPRINT - JUNE 28, 2021

4.4 Baseline Architectures and Hyper-Parameter Tuning

1. Zoo animal classiﬁcation The baseline feed forward network consists of 3 fully connected layers where the
ﬁrst two layers contain ReLU activation functions and the ﬁnal layer contains a softmax activation function.
The number of neurons in the ﬁrst two layers as well as the batch size were tuned using a grid search with
the following parameter values. Number of neurons in layer 1: {5, 12, 20}, number of neurons in layer 2:
{8, 10, 15} and batch size: {2, 5, 10}. Tuning was performed over the extended zoo dataset ‘zoo3’11 with
no MNIST digit substitution where the best performing combination of parameters were chosen according to
test set accuracy. We performed an 80%/20% train/test split on the zoo3 data set using the scikit-learn library.
All random seeds were set to 0 and the chosen parameters were 12 neurons in the ﬁrst layer, 8 neurons in
the second layer and a batch size of 10. The model was trained for 150 epochs with the sparse categorical
cross-entropy loss using the Adam optimiser and was implemented in TensorFlow 2.3.0 with Keras 2.4.0.
The baseline random forest model was implemented with scikit-learn 0.23.2 and tuned on the same train/test
split of the zoo3 dataset as the feed forward neural network. The number of estimators were tuned across:
{10, 50, 100, 200}. The best performing parameter value of 100 estimators was chosen.

2. Sudoku board classiﬁcation The baseline CNN-LSTM network consists of an embedding layer, followed by
a 1D convolutional layer with 32 ﬁlters, a kernel size of 3, the ReLU activation function and ‘same’ padding.
Then, a 1D max pooling layer with pool size 2 is used, followed by a dropout layer with dropout probability
0.2, an LSTM layer and a second dropout layer also with dropout probability 0.2. Finally, a dense fully
connected layer with the sigmoid activation function is used to produce a binary classiﬁcation of the input
digit sequence. The input sequence length to the embedding layer is 16, representing each cell on the 4x4
Sudoku board.
Tuning was performed using a separate dataset of 100 valid and 100 invalid Sudoku boards using a grid search
to tune the embedding vector length, the number of neurons in the LSTM layer and the batch size with the
following parameter values. Embedding vector length: {10, 20, 32}, number of neurons in the LSTM layer:
{50, 100} and batch size: {8, 16, 32}. The best performing combination of parameter values was chosen
according to test set accuracy. We performed an 80%/20% train/test split using the scikit-learn library. All
random seeds were set to 0 and the chosen parameters were an embedding vector length of 32, 100 neurons in
the LSTM layer and a batch size of 32. The model was trained for 200 epochs with the binary cross-entropy
loss using the Adam optimiser and was implemented in TensorFlow 2.3.0 with Keras 2.4.0.
The baseline random forest model was implemented with scikit-learn 0.23.2 and tuned on the same train/test
split of the separate Sudoku dataset as the CNN-LSTM neural network. The number of estimators were tuned
across: {10, 50, 100, 200}. The best performing parameter value of 100 estimators was chosen.

4.5 System Details

All experiments in this paper were run on the same machine with the following speciﬁcations:

• Hardware: QEMU KVM virtual machine standard PC (i440FX + PIIX 1996) with 10 nodes of 8-core AMD

EPYC Zen 2 CPUs (80 cores total), 16GB RAM.

• Operating System: Ubuntu 18.04.4 LTS.
• Software: FastLAS 1.0, Python 3.7.3, TensorFlow 2.3.0, Keras 2.4.0, scikit-learn 0.23.2, numpy 1.19.1,

problog 2.1.0.42.

5 Related Work

Existing approached for integrating neural and symbolic techniques can be categorised into two main types. Firstly,
there are a set of approaches that leverage neural networks for learning and symbolic components for reasoning.
Secondly, there are approaches that leverage both neural networks and symbolic components together to perform a
joint learning task.

DeepProbLog [28] is an example of an integrated neural-symbolic learning and reasoning framework that connects
probabilistic logic to neural networks to enable probabilistic reasoning over neural network outputs. Neural network
feature extractors within DeepProbLog can be trained w.r.t resulting policy labels, by constructing a Sentential De-
cision Diagram (SDD) based on hard-coded logical rules. DeepProbLog requires these logical rules to be manually
speciﬁed and they are not learned from data.

11https://www.kaggle.com/agajorte/zoo-animals-extended-dataset

9

A PREPRINT - JUNE 28, 2021

Logic Tensor Networks (LTNs) [29] generalise the semantics of ﬁrst-order logic to introduce real logic, replacing
the standard Boolean values with real values in the interval [0, 1]. LTNs enable integrated learning through tensor
networks and reasoning using real logic. This enables soft and hard logical constraints and relations to be speciﬁed
in ﬁrst-order logic as background knowledge to help guide neural networks during training. With LTNs, logical rules
aren’t learned symbolically, learning occurs in a neural network constrained by real logic.

In both of these approaches, logical rules are not directly learned from unstructured data, which is the key focus of
our NSL framework. A differentiable ILP framework [30] called ∂ILP learns rules from unstructured data by re-
implementing a top-down, generate and test ILP approach. ∂ILP learns, through stochastic gradient descent, which
generated clauses should be “turned on” such that together with the background knowledge, the turned on clauses
entail the positive examples and do not entail the negative examples. Their evaluation includes a pre-trained neural
network that classiﬁes MNIST digits connected to an ILP system for rule learning. Their approach requires, a set
of predeﬁned rule templates to deﬁne the hypothesis space. This is memory intensive and the approach is limited to
predicates up to arity 2. NSL does not have any such constraints as FastLAS is more scalable than the ILP system
used in ∂ILP in terms of the number of examples and the size of the hypothesis space. For example, ∂ILP cannot
be used on the Mutagenesis data set12, which contains 230 examples, whereas the Sudoku task presented in this paper
contains 320 training examples. Finally, the differentiable integration in ∂ILP is tightly coupled with the ILP system,
whereas NSL is modular and preserves separation between the neural and symbolic components.

6 Conclusion

This paper has introduced a hybrid neural-symbolic learning framework called NSL that is capable of learning robust
rules in the presence of perturbed training data and incorrect or unconﬁdent neural network predictions. The framework
aggregates conﬁdence information from neural network feature extractors to create a penalty paid by the FastLAS
ILP system for not covering an NSL example. Our results indicate that NSL is able to learn robust rules in the
presence of perturbed training data, matching or outperforming the neural network and random forest baselines whilst
learning a more general and interpretable model. When perturbations occur at run-time, NSL is able to maintain
robust classiﬁcation performance up to ∼40% perturbations, outperforming the neural network and random forest
baselines. Finally, in the Sudoku task, FastLAS can utilise background knowledge to learn robust rules with fewer
training examples compared to a neural network baseline.

7 Ethics Statement

Interpretable machine learning systems provide a ﬁrst step towards addressing issues such as bias, discrimination and
accountability. In practical terms, it often isn’t possible to acquire training data that perfectly represents the intended
distribution within a population, one can only approximate the distribution through a set of samples. Powerful machine
learning algorithms, such as deep neural networks may unwillingly amplify and reinforce inherent bias present in the
sampled underlying training data that can be difﬁcult to detect until the model is deployed.

In this paper, we explore the combination of an interpretable ILP system with a deep neural network feature extractor
such that learned rules from perturbed data can be inspected for correctness and potential bias or discrimination. An
interesting example of the beneﬁt of this approach can be observed in the Sudoku board classiﬁcation task within our
evaluation. Referring to Figures 3c and 3d when evaluating on perturbed test data, the CNN-LSTM neural network
baseline appears to perform strongly, given 50% perturbed training and test examples. However, comparing the per-
formance of the same model when evaluated on non-perturbed test data in Figure 2c, the performance is signiﬁcantly
reduced. This indicates the CNN-LSTM has ampliﬁed the perturbations present in the training data. This particular
model may be difﬁcult to interpret which highlights a potential issue should the training data contain biased or dis-
criminatory examples. An interpretable approach, such as the NSL framework presented in this paper, could highlight
such ampliﬁcations of biased training data before the model is deployed.

8 Acknowledgments

This research was sponsored by the U.S. Army Research Laboratory and the U.K. Ministry of Defence under Agree-
ment Number W911NF-16-3-0001. The views and conclusions contained in this document are those of the authors and
should not be interpreted as representing the ofﬁcial policies, either expressed or implied, of the U.S. Army Research
Laboratory, the U.S. Government, the U.K. Ministry of Defence or the U.K. Government. The U.S. and U.K. Gov-

12https://relational.ﬁt.cvut.cz/dataset/Mutagenesis

10

A PREPRINT - JUNE 28, 2021

ernments are authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright
notation hereon.

References

[1] Daniel Cunnington, Mark Law, Alessandra Russo, and Jorge Lobo. Ff-nsl: Feed-forward neural-symbolic

learner. https://arxiv.org/abs/2106.13103, 2021.

[2] Andrew Cropper, Sebastijan Dumancic, and Stephen H Muggleton. Turning 30: New ideas in inductive logic

programming. In Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence, 2020.

[3] Dianhuan Lin, Eyal Dechter, Kevin Ellis, Joshua B Tenenbaum, and Stephen H Muggleton. Bias reformulation
for one-shot function induction. Frontiers in Artiﬁcial Intelligence and Applications, pages 525–530, 2014.

[4] Stephen Muggleton, Schmid Ute, Tamaddoni-Nezhad Alireza, and Besold Tarek. Ultra-strong machine learning:
comprehensibility of programs learned with ilp. Machine learning, pages 1119–1140, 2018. Special Issue of the
Inductive Logic Programming (ILP) 2016.

[5] Mark Law. Inductive learning of answer set programs. PhD thesis, Imperial College London, 2018.

[6] Mark Law, Alessandra Russo, Elisa Bertino, Krysia Broda, and Jorge Lobo. Fastlas: Scalable inductive logic

programming incorporating domain-speciﬁc optimisation criteria. In AAAI, 2020.

[7] Ian Goodfellow, Yoshua Bengio,

and Aaron Courville.

Deep Learning.

MIT Press, 2016.

http://www.deeplearningbook.org.

[8] L. H. Gilpin, D. Bau, B. Z. Yuan, A. Bajwa, M. Specter, and L. Kagal. Explaining explanations: An overview of
interpretability of machine learning. In 2018 IEEE 5th International Conference on Data Science and Advanced
Analytics (DSAA), pages 80–89, 2018.

[9] Murat Sensoy, Lance Kaplan, and Melih Kandemir. Evidential deep learning to quantify classiﬁcation uncer-

tainty. In Advances in Neural Information Processing Systems, pages 3179–3189, 2018.

[10] Yann LeCun, L´eon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document

recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.

[11] Stephen Muggleton. Inductive logic programming. New Generation Computing, 8(4):295–318, 1991.

[12] Stephen Muggleton and Luc De Raedt. Inductive logic programming: Theory and methods. The Journal of Logic

Programming, 19:629–679, 1994.

[13] Mark Law, Alessandra Russo, and Krysia Broda. Logic-based learning of answer set programs. In Reasoning
Web. Explainable Artiﬁcial Intelligence - 15th International Summer School 2019, Bolzano, Italy, September
20-24, 2019, Tutorial Lectures, pages 196–231, 2019.

[14] Mark Law, Alessandra Russo, and Krysia Broda. Inductive learning of answer set programs from noisy examples.

Advances in Cognitive Systems, 2018.

[15] M. Gelfond and V. Lifschitz. The stable model semantics for logic programming. In Proceedings of International

Logic Programming Conference and Symposium, volume 88, pages 1070–1080, 1988.

[16] Erich Peter Klement, Radko Mesiar, and Endre Pap. Triangular norms, volume 8. Springer Science & Business

Media, 2013.

[17] George Metcalfe, Nicola Olivetti, and Dov M Gabbay. Proof theory for fuzzy logics, volume 36. Springer Science

& Business Media, 2008.

[18] Qun Ni, Elisa Bertino, and Jorge Lobo. Risk-based access control systems built on fuzzy inferences. In Proceed-
ings of the 5th ACM Symposium on Information, Computer and Communications Security, ASIACCS ’10, page
250–260, New York, NY, USA, 2010. Association for Computing Machinery.

[19] Ibrahim M Nasser and Samy S Abu-Naser. Artiﬁcial neural network for predicting animals category. Interna-

tional Journal of Academic and Applied Research (IJAAR), 2019.

[20] Ratula Ray and Satya Dash. Comparative study of the ensemble learning methods for classiﬁcation of animals

in the zoo. In Smart Computing and Informatics (SCI) Conference, pages 251–260, 12 2018.

[21] A. Yenter and A. Verma. Deep cnn-lstm with combined kernels from multiple branches for imdb review sentiment
analysis. In 2017 IEEE 8th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference
(UEMCON), pages 540–546, 2017.

11

A PREPRINT - JUNE 28, 2021

[22] Chunting Zhou, Chonglin Sun, Zhiyuan Liu, and Francis Lau. A c-lstm neural network for text classiﬁcation.

arXiv preprint arXiv:1511.08630, 2015.

[23] Murat Sensoy, Lance Kaplan, Federico Cerutti, and Maryam Saleki. Uncertainty-aware deep classiﬁers using

generative models. In AAAI, 2020.

[24] Himabindu Lakkaraju, Stephen H Bach, and Jure Leskovec. Interpretable decision sets: A joint framework for
description and prediction. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge
discovery and data mining, pages 1675–1684, 2016.

[25] Christoph Molnar. Interpretable Machine Learning. Lulu.com, 2020.
[26] Luc De Raedt, Angelika Kimmig, and Hannu Toivonen. Problog: A probabilistic prolog and its application in
link discovery. In International Joint Conferences on Artiﬁcial Intelligence (IJCAI), pages 2462–2467, 01 2007.
[27] Dimitar Shterionov, Joris Renkens, Jonas Vlasselaer, Angelika Kimmig, Wannes Meert, and Gerda Janssens.
The most probable explanation for probabilistic logic programs with annotated disjunctions. In Inductive Logic
Programming, pages 139–153. Springer, 2015.

[28] Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, and Luc De Raedt. Deep-
problog: Neural probabilistic logic programming. In Advances in Neural Information Processing Systems, pages
3749–3759, 2018.

[29] Luciano Seraﬁni and Artur d’Avila Garcez. Logic tensor networks: Deep learning and logical reasoning from

data and knowledge. arXiv preprint arXiv:1606.04422, 2016.

[30] Richard Evans and Edward Grefenstette. Learning explanatory rules from noisy data. Journal of Artiﬁcial

Intelligence Research, 61:1–64, 2018.

12

