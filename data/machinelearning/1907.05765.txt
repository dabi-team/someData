9
1
0
2

l
u
J

2
1

]

C
O
.
h
t
a
m

[

1
v
5
6
7
5
0
.
7
0
9
1
:
v
i
X
r
a

Learning to Handle Parameter Perturbations in
Combinatorial Optimization: an Application to
Facility Location

Andrea Lodi1

Luca Mossina2

Emmanuel Rachelson2

1 CERC and ´Ecole Polytechnique de Montr´eal,
andrea.lodi@polymtl.ca
2 ISAE-SUPAERO, Universit´e de Toulouse,
name.surname@isae-supaero.fr

Abstract

We present an approach to couple the resolution of Combinatorial Op-
timization problems with methods from Machine Learning, applied to the
single source, capacitated, facility location problem. Our study is framed
in the context where a reference facility location optimization problem
is given. Assuming there exist data for many variations of the reference
problem (historical or simulated) along with their optimal solution, we
study how one can exploit these to make predictions about an unseen new
instance. We demonstrate how a classiﬁer can be built from these data
to determine whether the solution to the reference problem still applies
to a new instance. In case the reference solution is partially applicable,
we build a regressor indicating the magnitude of the expected change,
and conversely how much of it can be kept for the new instance. This
insight, derived from a priori information, is expressed via an additional
constraint in the original mathematical programming formulation. We
present an empirical evaluation and discuss the beneﬁts, drawbacks and
perspectives of such an approach. Although presented through the ap-
plication to the facility location problem, the approach developed here is
general and explores a new perspective on the exploitation of past expe-
rience in combinatorial optimization.

1

Introduction

Solving combinatorial optimization problems can be highly challenging. Many
problems have been shown to be computationally hard to solve (Garey and John-
son, 1990), that is, no polynomial-time algorithms exist. Despite this intrinsic
complexity, the state-of-the-art modeling and solving solutions can handle real-
world instances via exact methods, heuristics or a mix of the two.

1

 
 
 
 
 
 
Our rationale goes as follows: given a combinatorial problem, we assume
the existence of a reference problem instance Pref , derived from the description
of a system in its nominal state. This reference can be modeled via Mixed
Integer Programming (MIP) and solved to its optimum x∗ref via state-of-the-art
solvers based on branch-and-bound (BB) methods like CPLEX (IBM, 2018).
If a modiﬁcation of the reference parameters occurs, the problem needs to be
solved again. We operate as if we had to respond to this parameter perturbation
(also referred to as disruption) under a tight optimization time budget, aiming
at accelerating the descent towards the optimum. Given the modiﬁcations that
have occurred in the past or that can be simulated a priori, one can build a
dataset of resolutions. Through the example of the Facility Location Problem,
we study how one can extract information from this dataset to facilitate the
resolution of future instances. We cast this problem as a Supervised Learning
problem to predict whether a modiﬁcation will aﬀect and to what extent the
reference optimal solution. According to this prediction, additional constraints
are added to the MIP formulation of the new instance. In order to evaluate the
approach, the two formulations are fed to the solver and the performance are
compared.

Section 2 reviews the related literature on applying Machine Learning to Op-
timization problems. Section 3 provides a description of the Facility Location
Problem and Section 4 introduces how the prediction problem can be formulated
mathematically and linked to existing Machine Learning approaches. Experi-
ments and numerical results are presented and discussed in Section 5. Section
6 discusses the advantages and drawbacks of the proposed method and present
future research directions.

2 Machine Learning for Optimization

The remarkable results achieved in recent years by Machine Learning (ML), for
example in the ﬁeld of image recognition (Krizhevsky et al., 2012) or Reinforce-
ment Learning (Mnih et al., 2015), sparked a lot of interest in the Operations
Research community. Some results have emerged in applications such as guiding
the branching process in branch-and-bound optimization algorithms, in the form
of node exploration ordering (He et al., 2014) and approximating performant
branching rules (Alvarez et al., 2017; Khalil et al., 2016; Lodi and Zarpellon,
2017).
In Di Liberto et al. (2016) one can ﬁnd algorithmic ideas on how to
handle the many existing heuristics already developed for branch-and-bound
methods.

The traveling salesman problem has been addressed via an ad-hoc neural
network architecture in a Reinforcement Learning context (Bello et al., 2017;
Khalil et al., 2017; Deudon et al., 2018), aiming at learning to build incremen-
tally a solution.

Another ﬁeld of application is the interaction between existing optimization
solvers and a priori knowledge on the problem. For instance, Kruber et al.
(2017) ﬁnd an approach to automatically handle MIP problem decompositions,

2

by detecting if and what reformulation to apply within a dedicated software.
On the same topic, Basso et al. (2018) bring evidence to why such an approach
can be carried out, showing empirically that the role of an expert needed when
using decomposition methods can be, at least in part, automated via learning
algorithms. In Bonami et al. (2018), the authors present a method to select the
best resolution method for a Mixed Integer Quadratic Programming problem
from the diﬀerent algorithms oﬀered within the CPLEX framework.

Machine Learning has proven useful in producing a description of the optimal
solution of a yet unseen instance. Fischetti and Fraccaro (2018) describe a real-
world application with the problem of a wind turbine park layout. Minimizing
the complex turbulence induced by the positioning of wind turbines generates a
series of diﬃcult combinatorial problems. Where diﬀerent conﬁgurations would
need to be evaluated at a considerable computational cost, the authors approx-
imate the solution values to these optimizations via ML, thanks to a dataset
built a priori. On a similar line lies the work of Larsen et al. (2018). When the
problem of choosing the optimal load planning for containers on freight trains
cannot be solved online because of time constraints and insuﬃcient information
(tactical level), a set of oﬄine cases can be collected and used to get a descrip-
tion of the solution of a new instance, at an aggregate level. Such description
provides meaningful insights to decision makers in a real-time context.

Strictly connected with our work, Xavier et al. (2019) consider a number of
ML techniques to extract information from previously solved instances of Unit
Commitment problems and leverage such pieces of information to improve the
MIP performance when solving similar instances again and again.

The interested reader is referred to Bengio et al. (2018) for a recent survey

on the subject.

3 Constrained Facility Location Problems

Our application of choice will be that of the Capacitated Facility Location Prob-
lem (CFLP). Given a group of customers and a list of potential facilities that
can serve them, one must open a certain amount of facilities and assign a unique
facility to each of the customers. The goal of the problem is to satisfy the de-
mand of the customers while minimizing the associated operational and start-up
costs. The facilities are constrained in capacity, that is, the quantity of total
service each can provide is limited. When solving this problem one determines
which facilities must be opened and which customers they will serve.

3.1 Mathematical Programming Formulation

The CFLP can be written as a Binary Integer Program, with decision vari-
, indicating respectively whether facility j is activated (also
ables yj, xij
}

∈ {

0, 1

3

referred to as open) and whether customer i is served by j.

minimize
x,y

subject to

(cid:88)

(cid:88)

cijxij +

i
I
∈
(cid:88)

i
I
∈
(cid:88)

j

J

∈
dixij

sjyj

≤

xij = 1

fjyj

(cid:88)

J

j

∈

(1)

(2)

(3)

j
∀

∈

J

I

i
∀

∈

j

J

∈
xij
I =

∈ {

0, 1

, yj
}
1, 2, . . . , NC
{

0, 1
}
, J =
}

∈ {

∈

I are the customers and j
where i
cost of serving customer i from j; fj
di
NC are the number of facilities and of customers, respectively.

∈
≥
0 is the demand of customer i; sj

≥

≥

i

∀

∈

I,

j
∀

∈

J

(4)

1, 2, . . . , NF

,
{
}
0 is the
J the available facilities; cij
0 is the ﬁxed cost for opening facility j;
0 is the capacity of facility j; NF and

(5)

≥

The objective function (1) quantiﬁes the total cost of a given assignment,
composed of the ﬁxed start-up costs (cid:80)
J cijxij, the op-
j
∈
erational costs. Constraints (2) ensure that the total demand of the customers
assigned to j does not exceed its capacity sj. Constraints (3) ensure that each
customer is served by exactly one facility. For convenience, we write an instance
as P = (c, f , d, s).

J fjyj and (cid:80)

(cid:80)
j

∈

∈

I

i

In the various forms of the Facility Location Problem (FLP), the binary
variables associated with facility activation and customer-to-facility assignment
make the problem computationally challenging. Even the uncapacitated version,
for instance, has been proven to be NP-hard (Cornu´ejols et al., 1983). For a
comprehensive treatment on exact formulations of the FLP, we refer the reader
to the work of Klose and Drexl (2005). Beyond mathematical programming and
exact methods, heuristics for the FLP have received a fair amount of attention
(Cornu´ejols et al., 1983; Guastaroba and Speranza, 2012, 2014).

(cid:1)

x∗ref , y∗ref }
{

3.2 Perturbations in a Reference Problem
We assume the existence of a reference instance Pref = (cid:0)cref , f ref , dref , sref
where the parameters are considered to be in their nominal state. This problem
has
as its reference solution. In case a disruption in the system
occurs, for example an anomaly in the capacity, we wish to learn whether the
reference solution, or part of it, is still applicable without running the full op-
timization. To that end, we wish to predict what parts of the solution need
to be changed by providing hints to the solver, via an additional constraint.
(cid:1), which we see as a varia-
We shall write a new instance P (cid:48) = (cid:0)c(cid:48), f (cid:48), d(cid:48), s(cid:48)
tion P (cid:48) = Pref + ∆P , where a disruption ∆P aﬀected one or more of Pref ’s
parameters. In practice, one would proceed as in the following example. The
given (simple) Pref with capacities sref = (5000, 5000, 5000) is aﬀected by a
disruption and the derived P (cid:48) has capacities s(cid:48) = (5000, 5088, 4304). The ML
algorithm will take ∆P =
∗

as input and predict how

0, 88,

∗, y(cid:48)

696

x(cid:48)
{

}

{

−

}

4

x∗ref , y∗ref }

, before running the optimization for P (cid:48) (see Sec-
could diﬀer from
tion 4). In our case, the hint to the solver will specify how many (if any at all)
of the facilities active in Pref will be still active, without specifying which of
the three.

{

The FLP can be adapted to diﬀerent domains. Consider for instance the
airport system of a region.
If a runway at a major airport has problems or
needs maintenance, one could think of this as a disruption. One could then
want to learn and predict how to react to the closure of a runway, how much
of the traﬃc would need to be delayed, rescheduled or rerouted or, in general,
how to be guided to manage the disruption.

4 Learning constraints

In this Section, we formalize the search for a constraint that will be used to
accelerate the resolution of FLP instances facing disruptions. We formulate
this as a statistical learning problem and describe how we couple it with MIP
resolution.

4.1 Learning to Bound the Changes to a Reference Solu-

tion

Given the information gained from past resolutions or simulated data, we inves-
tigate the possibility of predicting the number of facilities we expect to change.
We want to predict that “only a proportion γ = 0.15 of the facilities needs
replanning”, and impose that as a constraint. Indeed, it is well known in the
case of MIPs with binary variables (Fischetti and Lodi, 2003) that it is easy to
express the neighborhood of a feasible solution by a linear constraint and the
resulting MIP is generally way easier to solve than the original problem.
In
addition, for FLP it is also well known that the critical choice is associated with
the facilities to open while the assignment of clients to facilities is easier to deal
with.

Then, the problem boils down to predicting the proportion of facilities
opened in y∗ref to be kept open in y(cid:48)
∗, the optimal solution of the perturbed in-
stance P (cid:48). This estimation is a scalar value (cid:98)γ determined via a function Γ(∆P ),
where Γ : R
K data from the K past res-
(∆Pk, γk)
{
olutions, this is a regression problem, which we can tackle with any Statistical
Learning method (Hastie et al., 2009).

[0, 1]. Given the

}1

→

≤

≤

k

The drawback of such an approach is the potential introduction of bias in
x∗ref , y∗ref }
the solution of P (cid:48) if the true optimum of P (cid:48) is far from
and the
{
ML fails to detect it or if it cuts the optimum from the admissible domain. In
(cid:1) generating P (cid:48) are very diﬀerent from
fact, in case the parameters (cid:0)c(cid:48), f (cid:48), d(cid:48), s(cid:48)
Pref , a good model would impose no additional constraint, thus falling back to
the full problem.

The information on (cid:98)γ = Γ(∆P ) can be modeled through the linear constraint

5

(6), thus yielding the new problem

minimize
x,y

subject to

(cid:88)

(cid:88)

I

i
∈

J

j

∈

cijxij +

fjyj

(cid:88)

J

j

∈

all previous constraints and
≥ (cid:98)γ Nref ,

(cid:88)

yr

r

Rref

∈

(6)

y∗ref,j = 1

is the set of indices of the facilities opened
[0, 1] is the parameter predicted via ML and

}

J

where Rref =
j
{
in the reference solution, (cid:98)γ
Nref =
|

Rref
|

∈

|

∈

is the number of facilities activated in the reference problem.

{

x∗ref , y∗ref }
≈

We do not attempt to identify directly which of the facilities need to change
, but rather to restrict the number of facilities that
or stay as in
can be changed. If (cid:98)γ
0, the disruption data conveys no information as to the
new optimum and all the facility allocations should be left to the solver. In that
case, it is likely that the variation on Pref is so strong that prior information
is of no help and we need to solve the new instance as a full problem in its
original formulation. Conversely, if (cid:98)γ
1, we conclude that all of the reference
≈
facilities are to be left activated, without excluding further facilities from being
activated.

4.2 Structuring the prediction problem

The overall problem of predicting (cid:98)γ = Γ(∆P ) is a regression problem. Previ-
ously solved instances Pk provide values (∆Pk, γk) to assemble a training set.
Then, most ML methods will search for Γ by minimizing a loss function deﬁned
as an expected value of individual losses over the training set, such as the least
squares. Such methods can thus be sensitive to the training samples’ distribu-
tion and might overﬁt to the majority value. In the speciﬁc case of predicting
the proportion of facilities to keep open, the distribution of observed values for
samples (∆Pk, γk) is strongly aﬀected by the fact that in many cases, all the
facilities in the reference solution should remain open (for details, see Section
5.1). To compensate for this imbalance, our predictor’s architecture features
two levels.

First, we ﬁt a binary classiﬁer to indicate whether the open facilities in
x∗ref , y∗ref }
should all be kept open. If this is the case, then (cid:98)γ := 1 without
{
any further computation. Second, if we cannot assert that all the reference active
facilities need to be left active, we call a speciﬁc regression function. This Γ(∆P )
function is trained on all the data points except for those for which γk = 1.
Then, given a new problem P (cid:48), we predict how much of the reference solution
has to be changed, adding that as constraint (6) to the original problem. Figure
1 summarizes the (cid:98)γ estimation process and the resolution of a new instance P (cid:48).

6

Learned bound

1. New instance P (cid:48).

2. if (cid:98)γ = Γ(P (cid:48)) = 1:
add yr = 1,

∈
3. else if (cid:98)γ = Γ(P (cid:48))

r
∀

add(cid:80)
r

yr

Rref

∈

4. Solve

Rref

[0, 1):

∈
≥ (cid:98)γ Nref

Figure 1: Learning to bound the FLP

5 Experimental Evaluation

Given the reference instance Pref and an instance P (cid:48) derived by perturbing
Pref , our aim is to provide a good solution to P (cid:48) within a small time budget.

Our Pref is taken from the CFLP instances of Guastaroba and Speranza
(2014)1. We test our method on three diﬀerent reference cases, respectively
capa1, capb1 and capc1. For conciseness, we refer to these as A, B, C, and their
ref , P C
corresponding MIP models as P A
ref . In each case, we have NF = 100
facilities available that share the same capacity sA = sA

ref , P B

= sA

1 = sA

2 =

100.

· · ·

5.1 Generation of Training Data

For each of the three instances, we produce three datasets of sizes NA = NB =
NC = 10000. Given Pref , we generate our training data by perturbing the
capacities of the facilities. We randomly perturb between 5% and 50% of the
facilities as follows.

1. Pick uniformly at random between 5% and 50% of the NF = 100 facilities.

2. For each facility j, apply a Gaussian noise to its capacity:
sj).

(0, σ = 0.2

sj +

sj

←

N

×

3. All the remaining data is left unchanged. This yields ∆Pk.

4. Solve the new instance Pk = Pref + ∆Pk with a MIP solver and get the

number Yk of facilities that were in x∗ref and are also in x∗k.

5. Add the new point (∆Pk, γk = Yk/NF ) to the dataset.

After generating the data, we can observe the distribution of Y , the number
of original open facilities still open in the optimal solution of the randomized
instances. At their nominal values, the optimal solutions for A, B and C have

1Data available at http://or-brescia.unibs.it/instances/instances_sscflp

7

P0γ=10≤γ<1solveyesno(a) Reference A

(b) Reference B

(c) Reference C

Figure 2: Number of facilities kept after reoptimization

respectively 7, 11 and 11 facilities open. For instance, given the k-th point in our
generated data from case A, if Yk = 4, this means that after the perturbation
of the capacities, of the seven facilities open in the reference optimal solution,
four were included in the optimal solution of the derived problem Pk.

Figure 2 presents three diﬀerent scenarios. With instance A we see that
on average less than half of the 7 original facilities are kept open, that is, the
perturbations aﬀect the new optimal solutions. In the case of B, for most of the
data points the original reference solution is still optimal after the perturbations,
as seen in the right-most bar of Figure 2b. Case C is intermediate, with at least
eight facilities out of eleven still open after the variations of the capacities.

5.2 Learning the Prediction Model

As mentioned in Section 4.2, we need a binary classiﬁer and a regressor to
account for sample distribution imbalance. The number of data for binary
classiﬁcation depends on the shape of the generated data, that is, on how many
extreme cases we observe (rightmost column in histograms of Figure 2).

We split the training data into classiﬁcation and regression data as follows.
In case A, we have 717 data points of value 7, corresponding to the observations
where all the facilities open in the reference solution are to be left open in the
perturbed instances. Thus, we set these 717 points aside and randomly sampled
an equal amount of points among the other points, yielding a learning data set
of NClassif icationA = 1434. The remaining 9283 points form the regression
learning data. This process was repeated for all the three cases, yielding the
distributions reported in Table 1.

8

Reference Classiﬁcation Regression Total

A
B
C

1434
8056
7686

9283
5965
6179

10000
10000
10000

Table 1: Training Data: repartition between binary classiﬁcation and regression

Reference

Model Accuracy False Positive Errors

A Extra Trees
Neural Net
Logistic
Naive Bayes

B Extra Trees
Neural Net
Naive Bayes
Logistic

C Extra Trees
Neural Net
Naive Bayes
Logistic

0.756
0.717
0.648
0.641

0.840
0.857
0.782
0.629

0.864
0.858
0.776
0.616

0.106
0.160
0.189
0.191

0.049
0.083
0.100
0.192

0.033
0.085
0.104
0.199

Table 2: Comparison of binary classiﬁers

In accordance to standard practice in ML (Hastie et al., 2009), at learning
time the data set was randomly split into a training and a test partition. The
predictive models were ﬁt on the training data but evaluated on the test data.

5.2.1 Comparison of ML algorithms: Classiﬁcation

For the binary classiﬁcation task, we tested a set of binary classiﬁers among
which Extremely Randomized Trees (Extra Trees) (Geurts et al., 2006), Neural
Network classiﬁer (Goodfellow et al., 2016), Logistic Regression classiﬁcation
and Naive Bayes classiﬁcation (Hastie et al., 2009).

As can be seen across Table 2, Extra Trees emerged as the best performing
in terms of accuracy and false positives errors, that is, over the total of the
prediction, how many were predicted as false positives. Here, false positives are
cases where the reference solution’s open facilities should not be all kept open
in the new instance but the classiﬁer prescribes otherwise. This could introduce
bias, making this metric important for our task.

5.2.2 Comparison of ML algorithms: Regression

For the regression task we selected Extremely Randomized Trees out of a pool
of models comprising Multiple Linear Regression, Extremely Randomized Trees

9

Reference Linear Regression Extra Trees Neural Net

A
B
C

0.998
2.087
1.114

0.883
1.780
0.750

0.975
2.099
1.097

Table 3: Comparison of regression models by Mean Squared Error

and a Multi-layer Perceptron artiﬁcial Neural Network.

In Table 3 are the values of the Mean Squared Error (MSE) computed on the
test partition. Extra Trees yielded the best performance of the tested methods.
While Neural Networks have recently been the object of intense research and
remarkable results, we think its poorer results can explained by the limited
10000) and the highly nonlinear relations between
amount of training data (N
features and response variable, for which more data could have been needed.

≤

Figures 3a, 3c and 3e, plot the predictions of Y (number of facilities kept
open) versus the true values on the test data. The ideal case of perfect pre-
dictions ˆY = Y , is denoted by the red line. The green line is a simple linear
regression of the form (cid:98)Y = ˆmY + ˆb that graphically renders the actual relation
between Y and (cid:98)Y .

We remark that the data are highly concentrated around some central values.
The tails of the distribution are scarcely represented in our training data, and
the learning function cannot generalize well, as one can see more prominently
with instance A, where most of the data take values 2, 3 or 4.

5.3 Optimization Results

We report the performance of our method on the three references A, B and C,
generating three batches DA, DB and DC of 50 new instances, unseen during
training. We apply the same procedure followed to generate the learning data
(Section 5.1).

To measure the eﬀect of the ML bound with respect to resolution time, each
instance in DA (but also DB and DC) is optimized twice (with and without
bound) with time limits tlim
seconds. At the end of the
time-limited run, we record the objective value and the eﬀective solving time
(some instances are optimized before the limit is reached).

5, 10, 30, 60, 120

∈ {

}

Our ML constraint cannot make the solution infeasible, as the total number
of active facilities is not bounded, but it could cut oﬀ the optimal solution. For
instance, one could predict all of the reference facilities to be open (ˆγ = 1) while
none of them should be. We run the optimization with 3,600 seconds of time
limit, to measure the diﬀerence in objective values after a long run, with and
without the additional constraint.

10

(a)

(c)

(e)

(b)

(d)

(f)

Figure 3: References A (a, b), B (c,d) and C (e,f): Learning, Regression

11

5.3.1 Experimental setup

For each iteration of our experiments, we proceed as follows. A new instance is
generated as detailed in Section 5.1. The instance is then solved once for each
time limit without the additional constraint. The objectives and eﬀective times
are recorded. The ML algorithm is run (see Section 4) and constraint (6) is
introduced in the model’s formulation. The constrained model is then solved
once for each time limit. To verify that the optimal solution was preserved by the
introduced bound constraint, we run both models with and without constraint
(6) for a full hour to check if any remarkable deviation has been caused by the
ML.

When using a highly-optimized MIP solver like CPLEX, it is sometimes hard
to evaluate the impact of model modiﬁcations (imposed by the user) because
the complex algorithmic components within the solver might mitigate the eﬀect
of those modiﬁcations. For this reason, it is common practice to deactivate, for
testing purposes, some of those CPLEX algorithmic ingredients.

In our special case, we are interested in evaluating the eﬀect of the ML-
predicted constraint (6) as a way to fast dive toward good solutions of a mod-
iﬁed FLP instance with respect to the solution of a reference one. To achieve
this goal, we have found useful to run CPLEX without the presolve feature
and we ﬁrst report the results of this conﬁguration. We nonetheless performed
all experiments and report the results with CPLEX default, i.e., with presolve
activated. We show that the overall message provided by the experiments is in
both cases very similar.

Finally, given the interest, especially in the academic community, of using
non-commercial MIP solvers, we report in Appendix A the results obtained by
replacing CPLEX with the most widely adopted of those solvers, namely SCIP
(default version) (Gleixner et al., 2017).

5.3.2 Experimental results

Within 3, 600 seconds, most of the runs attain an optimality gap of the order
of 0.05% or manage to reach optimality. The bias introduced by the learned
bound is on average around 0.03% and at most of the order of 0.5%. That is, at
the 3, 600 seconds time limit, the objective value of the ML-bounded run is on
average 0.03% higher than the objective for the regular run, but never greater
than 0.5%.

Figures 4a, 4c and 4e compare the values of the objective functions of the
constrained and unconstrained resolutions at the time limit. Each point repre-
sents the same new, unseen, instance optimized twice: once with the ML bound
and once without. The color coding helps determining the time limit imposed
on this pair of runs. On the x axis one can see the objective value without ML,
on the y axis the value with the ML bound. Points on the lower left corner
correspond to runs with longer time limits, where the diﬀerence between the
two approaches becomes more negligible. The points below the line are runs for
which our method outperformed the original formulation.

12

(a)

(b)

(c)

(d)

(e)

(f)

Figure 4: References A (a, b), B (c,d) and C (e,f): optimization results

13

In Figures 4b, 4d and 4f, the same information is presented focusing on the
temporal dimension. On the x axis is the eﬀective resolution time, which can be
inferior to the time limit. Along the y axis is the objective value at the time limit.
The points aligned at the bottom of Figures 4d and 4f are those for which the
optimal solution was found before the time limit expired. For short resolution
times, the ML-constrained formulation yields better objective function values
than the original formulation without cutting the optimal solution which is
eventually found given more computational time. On average, the blue points
representing the objective of the ML-bounded model lie below the red ones of the
unbounded model. In case C, our method allows for superior performances than
those obtained simply via the solver. In case A we are still on average improving
the performances or at least keeping in line with the unbounded model. Here,
the amplitude of the perturbations imply completely diﬀerent solutions, making
transfer diﬃcult. We remark however that, on average, our approach avoids
cutting the optimal solution and thus prevents negative transfer.

As noted above, we operated with the presolve feature switched oﬀ. For
completeness, we run all of the experiments a second time with the presolve
feature activated (Figure 5). The results reﬂect what was observed previously,
although the presolve heuristics of CPLEX manage to reduce in part the eﬀect
of our approach in case B (Figure 5 c and d).

6 Conclusions and Perspectives

We have shown that the existing or simulated data of a recurring optimization
problem can be exploited to gain insight into the optimization process. We have
used these data to ﬁt a binary classiﬁer and a regressor. We predict whether
a new instance, derived from a reference instance, will share all or a part of
its optimal solution with the solution of the reference instance. This piece of
information, translated into an additional constraint, is given to a solver and
allows to dive faster, on average, towards a good solution. Moreover, we empir-
ically illustrated that this additional constraint preserves the optimal solution
and thus prevents negative transfer.

Building upon these results, we plan on extending the reach of our approach
by experimenting with other families of problems, where, potentially, diﬀerent
types of constraints should be considered. This will be the way of fully demon-
strating the wide applicability of the approach to both solving repetition (with
diﬀerent data) and re-optimization.

Acknowledgements

The authors wish to acknowledge the support of the Canada Excellence Re-
search Chair in Data Science for Real-Time Decision-Making at Polytechnique
Montr´eal and the ISAE-SUPAERO foundation.

14

(a)

(b)

(c)

(d)

(e)

(f)

Figure 5: References A (a, b), B (c,d) and C (e,f): optimization results with
presolve

15

References

Alvarez, A. M., Louveaux, Q., and Wehenkel, L. (2017). A machine learning-
based approximation of strong branching. INFORMS Journal on Computing,
29(1):185–195.

Basso, S., Ceselli, A., and Tettamanzi, A. (2018). Random sampling and ma-
chine learning to understand good decompositions. Annals of Operations
Research.

Bello, I., Zoph, B., Vasudevan, V., and Le, Q. V. (2017). Neural optimizer
search with reinforcement learning. In International Conference on Machine
Learning, pages 459–468.

Bengio, Y., Lodi, A., and Prouvost, A. (2018). Machine learning for
a methodological tour d’horizon. Preprint

combinatorial optimization:
arXiv:1811.06128.

Bonami, P., Lodi, A., and Zarpellon, G. (2018). Learning a classiﬁcation of
mixed-integer quadratic programming problems. In van Hoeve, W.-J., editor,
Integration of Constraint Programming, Artiﬁcial Intelligence, and Opera-
tions Research, pages 595–604, Cham. Springer International Publishing.

Cornu´ejols, G., Nemhauser, G. L., and Wolsey, L. A. (1983). The uncapacitated
facility location problem. Technical report, Carnegie-mellon univ pittsburgh
pa management sciences research group.

Deudon, M., Cournut, P., Lacoste, A., Adulyasak, Y., and Rousseau, L.-M.
(2018). Learning heuristics for the tsp by policy gradient. In International
Conference on the Integration of Constraint Programming, Artiﬁcial Intelli-
gence, and Operations Research, pages 170–181. Springer.

Di Liberto, G., Kadioglu, S., Leo, K., and Malitsky, Y. (2016). Dash: Dynamic
approach for switching heuristics. European Journal of Operational Research,
248(3):943 – 953.

Fischetti, M. and Fraccaro, M. (2018). Machine learning meets mathemati-
cal optimization to predict the optimal production of oﬀshore wind parks.
Computers and Operations Research.

Fischetti, M. and Lodi, A. (2003). Local branching. Mathematical Programming,

98:23–47.

Garey, M. R. and Johnson, D. S. (1990). Computers and Intractability; A Guide
to the Theory of NP-Completeness. W. H. Freeman & Co., New York, NY,
USA.

Geurts, P., Ernst, D., and Wehenkel, L. (2006). Extremely randomized trees.

Machine learning, 63(1):3–42.

16

Gleixner, A., Eiﬂer, L., Gally, T., Gamrath, G., Gemander, P., Gottwald, R. L.,
Hendel, G., Hojny, C., Koch, T., Miltenberger, M., M¨uller, B., Pfetsch, M. E.,
Puchert, C., Rehfeldt, D., Schl¨osser, F., Serrano, F., Shinano, Y., Viernickel,
J. M., Vigerske, S., Weninger, D., Witt, J. T., and Witzig, J. (2017). The
SCIP Optimization Suite 5.0. Technical report, Optimization Online.

Goodfellow, I., Bengio, Y., and Courville, A. (2016). Deep Learning. MIT Press.

http://www.deeplearningbook.org.

Guastaroba, G. and Speranza, M. (2014). A heuristic for bilp problems: The
single source capacitated facility location problem. European Journal of Op-
erational Research, 238(2):438 – 450.

Guastaroba, G. and Speranza, M. G. (2012). Kernel search for the capacitated

facility location problem. Journal of Heuristics, 18(6):877–917.

Hastie, T., Tibshirani, R., and Friedman, J. (2009). The elements of statistical
learning: data mining, inference, and prediction, springer series in statistics.

He, H., Daume III, H., and Eisner, J. M. (2014). Learning to search in branch
and bound algorithms. In Advances in Neural Information Processing Sys-
tems, pages 3293–3301.

IBM (2018). IBM ILOG CPLEX Optimizers 12.8.0.

Khalil, E. B., Dai, H., Zhang, Y., Dilkina, B., and Song, L. (2017). Learning
In Advances in Neural

combinatorial optimization algorithms over graphs.
Information Processing Systems, pages 6348–6358.

Khalil, E. B., Le Bodic, P., Song, L., Nemhauser, G., and Dilkina, B. (2016).
Learning to branch in mixed integer programming. In Proceedings of the 30th
AAAI Conference on Artiﬁcial Intelligence.

Klose, A. and Drexl, A. (2005). Facility location models for distribution system
design. European Journal of Operational Research, 162(1):4 – 29. Logistics:
From Theory to Application.

Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2012). Imagenet classiﬁcation
with deep convolutional neural networks. In Advances in neural information
processing systems, pages 1097–1105.

Kruber, M., L¨ubbecke, M. E., and Parmentier, A. (2017). Learning when to
use a decomposition. In Salvagnin, D. and Lombardi, M., editors, Integration
of AI and OR Techniques in Constraint Programming, pages 202–210, Cham.
Springer International Publishing.

Larsen, E., Lachapelle, S., Bengio, Y., Frejinger, E., Lacoste-Julien, S., and
Lodi, A. (2018). Predicting solution summaries to integer linear pro-
grams under imperfect information with machine learning. arXiv preprint
arXiv:1807.11876.

17

Lodi, A. and Zarpellon, G. (2017). On learning and branching: a survey. TOP,

pages 1–30.

Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare,
M. G., Graves, A., Riedmiller, M., Fidjeland, A. K., Ostrovski, G., et al.
(2015). Human-level control through deep reinforcement learning. Nature,
518(7540):529.

Xavier, A., Qiu, F., and Ahmed, S. (2019). Learning to solve large-scale security-
constrained unit commitment problems. Technical Report 1902.01697, arXiv.

A Results with SCIP

The MIP solver SCIP, whose source code is accessible for academic purposes, has
a considerable adoption in academic research, which is why it is interesting to
test our approach in conjunction with such a solver. The experiments reported
in Figure 6 are the same as those in Section 5.3, with the exception of the time
limits of 5 seconds; for such a short time limit, most of the runs did not yield
a feasible solution and we did not report it. What observed previously with
CPLEX is true here as well, although the eﬀect of constraint (6) are ampliﬁed.
The additional bound constraint allows the solver to dive much faster towards a
good solution. Even at the 120 seconds mark, the gap between the two objective
values is still considerable.

18

(a)

(b)

(c)

(d)

(e)

(f)

Figure 6: References A (a, b), B (c,d) and C (e,f): optimization results with
the SCIP solver

19

