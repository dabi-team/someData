2
2
0
2

r
a

M
8
1

]

C
O
.
h
t
a
m

[

2
v
4
3
5
6
0
.
7
0
1
2
:
v
i
X
r
a

Zeroth and First Order Stochastic Frank-Wolfe

Algorithms for Constrained Optimization

Zeeshan Akhtar, and Ketan Rajawat

1

Abstract

This paper considers stochastic convex optimization problems with two sets of constraints: (a) deterministic

constraints on the domain of the optimization variable, which are difﬁcult to project onto; and (b) deterministic

or stochastic constraints that admit efﬁcient projection. Problems of this form arise frequently in the context of

semideﬁnite programming as well as when various NP-hard problems are solved approximately via semideﬁnite

relaxation. Since projection onto the ﬁrst set of constraints is difﬁcult, it becomes necessary to explore projection-free

algorithms, such as the stochastic Frank-Wolfe (FW) algorithm. On the other hand, the second set of constraints

cannot be handled in the same way, and must be incorporated as an indicator function within the objective function,

thereby complicating the application of FW methods. Similar problems have been studied before; however, they suffer

from slow convergence rates. This work, equipped with momentum based gradient tracking technique, guarantees fast

convergence rates on par with the best-known rates for problems without the second set of constraints. Zeroth-order

variants of the proposed algorithms are also developed and again improve upon the state-of-the-art rate results. We

further propose the novel trimmed FW variants that enjoy the same convergence rates as their classical counterparts, but

are empirically shown to require signiﬁcantly fewer calls to the linear minimization oracle speeding up the overall

algorithm. The efﬁcacy of the proposed algorithms is tested on relevant applications of sparse matrix estimation,

clustering via semideﬁnite relaxation, and uniform sparsest cut problem.

We consider problems of the form

I. INTRODUCTION

P

P +

minx∈C E[f (x, ξ)]

minx∈C E[f (x, ξ)]

s.t. Gx ∈ X

s.t. G(ξ)x ∈ X (ξ) almost surely,

where C ⊆ Rm is a convex and compact set, ξ is a random variable with unknown distribution, and f (·, ξ) : Rm → R
is a smooth and convex function. The matrices G, G(ξ) ∈ Rn×m are arbitrary, and the sets X , X (ξ) ⊆ Rn are

convex. We write G(ξ) and X (ξ) as explicit functions of ξ in order to emphasize their stochastic nature and

require the constraint G(ξ)x ∈ X (ξ) to be satisﬁed with probability one. While such a requirement is stronger than

Zeeshan Akhtar and K. Rajawat are with the Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur 208016,

India (e-mail: zeeshan@iitk.ac.in, ketan@iitk.ac.in).

March 21, 2022

DRAFT

 
 
 
 
 
 
2

satisfying the constraints in expectation, it is also impossible to check. Therefore, we will instead seek to ﬁnd an

x whose expected distance from the feasible set can be made arbitrarily small.

Afﬁne-constrained stochastic optimization problems of the form in P arise in a number of areas, such as

control theory, multiple kernel learning, blind deconvolution, matrix learning, and communications [1], [2]. Efﬁcient

algorithms for solving these problems make use of the stochastic gradient ∇f (x, ξ) at every iteration, usually

obtained from one or a few data points. In many cases, such a stochastic gradient can be calculated efﬁciently and

exactly, giving rise to the ﬁrst-order stochastic gradient algorithms. On the other hand, in some problems, such as

those arising in simulation-based optimization [3], one must contend with only the function values f (x, ξ), which

are then used to approximate the required stochastic gradients ∇f (x, ξ). Algorithms using such gradient estimators

are referred to as gradient-free or zeroth-order (ZO) algorithms, and ﬁnd applications in parameter estimation and

classiﬁcation of black-box systems [4]. Finally, deterministic constraints such as those in P can be handled in

different ways, such as through the use of projection [5], homotopy [6], or duality theory [7].

The problem P + is less standard, and involves stochastic constraints, which must be satisﬁed with probability

one. Such a formulation is useful in settings where the constraints are not known in advance or are too many to

be processed in one batch. For instance, the constraints in some online learning problems, such as online portfolio

optimization [8] and online compressed sensing [9], are revealed in a sequential fashion. Likewise, the number of

constraints in the semideﬁnite relaxed versions of k-means clustering [10], uniform sparsest cut [11], and maximum

a posterior estimation [12] problems, is very large, ranging from O(m2) to O(m3). In both such cases, efﬁcient

algorithms for solving P + must rely on using only a minibatch of the constraints at every iteration. Again, both

ﬁrst-order and ZO algorithms are well-motivated for solving P +.

In this work, we focus on problems of the form P and P +, where the projection onto the set C is computationally

expensive, but projection onto the set X is simpler. Such templates are prevalent among semideﬁnite programming

(SDP) problems, where C is the positive semideﬁnite (PSD) cone, while X incorporates simple afﬁne or box

constraints. Examples include relaxations of combinatorial optimization problems such as quadratic assignment [13],

maximum cut [14], etc. SDPs are also encountered frequently in machine learning problems such as for certifying the

robustness of neural networks [15], unsupervised clustering and embedding [16], and Lipschitz constant estimation

[17]. However, solving such large-scale SDPs is almost always difﬁcult, even when utilizing ﬁrst- or zeroth-order

stochastic methods due to the presence of the PSD cone constraint. Projection onto the PSD cone requires carrying

out a singular value decomposition, which is a prohibitively expensive operation in large-scale settings.

Let us motivate the issue by illustrating it on the SDP formulation of the k-means clustering problem [10]:

min
X∈C

1
|Ω|

(cid:88)

[M]ij[X]ij

(i,j)∈Ω

s.t. X1 = 1, [X]ij ≥ 0, (i, j) ∈ E,

(1)

(2)

where M ∈ RN ×N is the pairwise distance matrix, 1 denotes the N ×1 vector of all ones, C := {X (cid:23) 0, tr(X) ≤ K},

E := {(i, j) | 1 ≤ i, j ≤ N }, and Ω ⊆ E. A possible solution to problem (1) is to incorporate the additional constraint

(2) into the objective and then use a projection-based algorithm. However, projection onto the set C will require

March 21, 2022

DRAFT

3

the eigenvalue decomposition of an N × N matrix, thus incurring an O(N 3) complexity per iteration.

Stochastic Frank-Wolfe (FW) algorithms, also known as conditional gradient methods (CGM), avoid the compli-

cated projection operation, and have been applied to solve P and P + in [18] and [19], respectively. In the FW class

of algorithms, the projection step is replaced with a linear minimization step, which in many cases, is signiﬁcantly

cheaper. For instance, when C is a PSD cone, the linear minimization step involves ﬁnding only the largest singular

vector, which can be efﬁciently calculated by using the Lanczos method [20].

The afﬁne constraints in P and P + present another challenge, as they cannot generally be incorporated within

C. For instance, in the k-means clustering problem (1), incorporating the constraints (2) into C will no longer allow

us to use the efﬁcient Lanczos method. The works in [18] and [19] proposed incorporating the constraints within

the objective function using indicator functions, and subsequently applying homotopy and Nesterov smoothing

techniques [21] to make them differentiable.

Finally, the stochastic nature of P and P + obviates the use of the classical FW algorithm. The stochastic FW

(SFW) algorithms, unlike the stochastic projected gradient counterparts, require the use of increasingly accurate

gradient estimates, i.e., gradient estimates whose bias and variance decrease with iterations. Typically, such gradient

estimates are constructed using mega-batches whose size increases with iterations, but result in impractical algo-

rithms. More recently, one-sample-per-iteration variants of SFW have become popular, where a gradient tracking

approach is utilized to maintain good quality gradient estimates; the same is employed in [18] and [19]. However,

a key issue with the gradient tracking approach in these works is that it results in suboptimal convergence rates of

the SFW algorithm.

Building on the techniques introduced in [18]- [19], we put forth improved ﬁrst-order algorithms for solving

P and P +. The proposed algorithms utilize a superior momentum-based gradient tracking approach and newer

convergence proofs that allow us to obtain better convergence rates. While the momentum-based gradient tracking

is well-known in the context of non-convex optimization and has been applied to vanilla SFW, its application to

constrained problems such as in P and P + throws up technical challenges that must be addressed. Speciﬁcally, the

presence of the afﬁne constraints, which are incorporated within the objective via smoothed penalty functions, makes

the momentum-based gradient tracking process complicated and requires careful choice of step-size, which now

becomes coupled with the smoothing parameter. The optimality gap of the proposed MOmentum-based STochastic

FW (MOST-FW) algorithm for solving P decays at the rate of O(k−1/2), at par with the rate for the standard

SFW case [22]- [23]. The corresponding algorithm for P +, namely MOST-FW+ , achieves a rate of O(k−1/4),

which is again better than the O(k−1/6) rate achieved in [19]. We also propose the corresponding ZO variants for

MOST-FW and MOST-FW+ , useful for scenarios where the stochastic gradient of the objective function is not

readily available, and must be estimated using ZO information.

Existing deterministic and stochastic FW algorithms, including the proposed ones, generally require one call to the

linear minimization oracle (LMO) per iteration. Consequently, the wall-clock time of large-scale problems is largely

dominated by the time required to solve the linear minimization sub-problems [24]–[26]. In order to alleviate the

issue, we put forth trimmed-FW variants, wherein LMO calls are made only when the observed stochastic gradient

causes sufﬁcient change in the gradient estimate. Otherwise, the LMO call is skipped, and the previously available

March 21, 2022

DRAFT

4

LMO output is re-utilized to carry out the update. The trimming technique is novel in the context of FW algorithms,

and gives rise to the Trimmed-MOST-FW and Trimmed-MOST-FW+ algorithms. Although intuitive as a technique,

we also establish that the trimming process does not hurt the overall rate of convergence of the proposed algorithms.

From the experiments, however, we observe that the trimmed-FW variants need to make only a fraction of calls to

the LMO as compared to their regular (non-trimmed) counterparts.

A. Related Work

We review some of the related work in the context of FW algorithms, smoothing, afﬁne-constrained optimization,

momentum techniques, and ZO methods.

1) FW for smooth functions: Though the FW method was ﬁrst proposed in 1956, it has only been recently used

for solving large-scale optimization problems in a projection-free manner [20]. Subsequently, online and stochastic

variants of the FW method for minimizing smooth convex functions have been widely studied [27], [28]. Many

of the early variants of the stochastic FW algorithms utilized a double loop structure, wherein the inner loop

utilizes a single mini-batch of stochastic gradients per iteration, while the outer loop is used to update some of

the algorithm parameters. Equivalently, these algorithms can be seen as using “checkpoints” for updating various

algorithm parameters, with the interval between checkpoints increasing polynomially [29] or even exponentially

[28]. Such mega-batches result in infrequent update of algorithm parameters, which is not desirable in practice [30].

Modern stochastic FW algorithms require only a single stochastic gradient as well as a single linear minimization

step per iteration [22], [23], [31], [32]. Of these, works in [22], [23] were the ﬁrst to utilize a momentum-based

gradient tracking routine, achieving the state-of-the-art convergence rate of O(k−1/2).

2) FW for non-smooth functions: Complications arise when extending these results to constrained problems, such

as P and P +. Unlike proximal methods, the constraints cannot be handled using an indicator penalty function,

since the resulting objective would be non-smooth. On the other hand, the stochastic FW variants discussed so

far can handle only smooth objective functions. For instance, [33] deals with additional expectation constraints

using penalty reformulation but requires the functional constraints to be smooth. For non-smooth but Lipschitz

continuous objectives, it may still be possible to apply stochastic FW through the use of Nesterov’s smoothing

[34]. The indicator function is, however, not Lipschitz continuous, and hence the constrained formulations in P

and P + are not amenable to the techniques proposed in [34], [35]. Another approach, proposed in [36], entails

incorporating the constraints within the linear minimization step. However, such inclusion may signiﬁcantly increase

the complexity of carrying out the linear minimization, since the special structure present in C may be lost. The

deterministic counterpart of P was ﬁrst considered in [37], and combines the ideas of homotopy and smoothing to

handle the non-smooth component of the objective. The idea there was to replace the non-smooth component with

its smooth approximation. The error due to this approximation is controlled by decreasing the smoothing parameter

(and hence tightening the approximation) at an appropriate rate. The problem in P was ﬁrst considered in [18],

which again used the homotopy and smoothing ideas from [37], but used gradient tracking estimator to handle the

stochastic gradient noise. The stochastic homotopy CGM (SHCGM) of [18] attains a convergence rate of O(k−1/3)

for the optimality gap and O(k−5/12) for the constraint violation. As we shall establish later, the proposed MOST-

March 21, 2022

DRAFT

Reference

Type

Afﬁne Constraint

Constraint Type

Objective

Additional

Afﬁne

Optimality

Constraint

Query

SFW [32]

Stochastic

1-SFW [22]

Stochastic

ORGFW [23]

Stochastic

HFW [37]

Deterministic

SHCGM [18]

Stochastic

H1-SFW [19]

Stochastic

MOST-FW
MOST-FW+

Stochastic

Stochastic

ZO-FW [38]

Deterministic

ZO-SFW [38]

Stochastic

MOST-FW
MOST-FW+

Stochastic

Stochastic

(cid:55)

(cid:55)

(cid:55)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:55)

(cid:55)

(cid:51)

(cid:51)

–

–

–

Deterministic

Gap
O(k−1/3)

O(k−1/2)

O(k−1/2)

O(k−1/2)

Feasibility

–

–

–
O(k−1/2)

Deterministic

O(k−1/3) O(k−5/12)

Stochastic

O(k−1/6)

O(k−1/6)

Deterministic

O(k−1/2)

O(k−1/2)

Stochastic

O(k−1/4)

O(k−1/4)

–

–

Deterministic

O(k−1)

O(k−1/3)

O(k−1/2)

–

–
O(k−1/2)

Stochastic

O(k−1/4)

O(k−1/4)

Size

O(1)

O(1)

O(1)

–

O(1)

O(1)

O(1)

O(1)

O(m)

O(m)

O(m)

O(m)

5

Oracle

SFO

SFO

SFO

FO

SFO

SFO

SFO

SFO

ZO

SZO

SZO

SZO

TABLE I: Summary of related works. For zeroth order oracle, query size indicates the number of function evaluations required

in estimating an m-dimensional gradient. For ﬁrst-order oracle, it denotes the number of stochastic gradient samples required

at each iteration.

FW algorithm also uses homotopy and smoothing, but combines it with momentum-based gradient tracking, thus

achieving a rate of O(k−1/2) for both, optimality gap and constraint violation.

Stochastically constrained stochastic optimization problems of the form in P + have been well-studied in the

context of proximal stochastic algorithms [39] and proximal online algorithms [8]. The works in [40] and [39] can

also accommodate large number of constraints, but cannot handle the additional difﬁcult-to-project set C. Motivated

by these works, the development of a projection-free algorithm for solving P + was pursued in [19], building

upon the techniques from [18]. The H1-SFW algorithm in [19] achieves a convergence rate of O(k−1/6) for the

optimality gap and constraint violation. In comparison, the MOST-FW+ algorithm proposed here achieves the rate

of O(k−1/4) for the same.

3) Variance-reduced FW: Variance-reduced algorithms have been widely used in the context of FW methods;

examples include SCGS [34], SVRF [28], STORC [28], SAGA-FW [41], and SPIDER-FW [42]. However, none

of these approaches can handle afﬁne constraints as in P or P +. A variance-reduced approach called H-SPIDER-

FW is proposed in [19], but requires stochastic gradient batch-sizes that increase exponentially with the iteration

index. The proposed MOST-FW+ algorithm converges at the same rate but works with a standard mini-batch of

stochastic gradients, akin to the state-of-the-art FW algorithms in the standard setting. Recently, a momentum based

deterministic accelerated-FW (AFW) algorithm was proposed in [43] by mimicking the steps of accelerated gradient

methods. Although it covers many important cases, it is not applicable to general constraint set C. Unlike AFW,

propose stochastic algorithms that perform momentum-based tracking over the gradient with the target to reduce

the gradient approximation noise.

March 21, 2022

DRAFT

6

4) FW under zeroth order oracle: Projection-free ZO algorithms have been studied in [38], [44], [45]. Of these,

the work in [44] proposed a stochastic zeroth-order (SZO) FW algorithm using the gradient estimation technique of

[46], but the number of samples of directional derivatives required at each epoch scaled linearly with the iteration

index as well as the problem dimension. An improved variant was proposed in [38], which adopted the gradient

averaging technique from [32], achieving a convergence rate of O(k−1/3) with a query size of O(m). Recently, a

ZO projection-free algorithm was proposed in [45], and resulted in state-of-the-art rates for the non-convex case.

To the best of our knowledge, there are no ZO algorithms for solving P or P +.

B. FW with reduced LMO calls

There have been few attempts at reducing the number of LMO calls of conditional gradient methods, all

in deterministic settings. Among these, the oldest one is the lazy conditional gradient approach designed for

deterministic FW that replaces the linear optimization oracle by a (weak) separation oracle which approximately

solves a separation problem. One recent direction to improve the LMO complexity is to use a randomized linear

oracle [24], [25], [47], wherein linear minimization is performed only over a random sample of the original atomic

domain. However, the effectiveness of such a technique depends on whether a speciﬁed fraction of the constraint

set can be efﬁciently subsampled. Another relevant recent approach is that of using the set-membership oracle

instead of the LMO [26]. The approach does not generally improve upon the FW algorithm, because for many

problems, linear minimization may actually be cheaper than determining the set membership, even approximately.

In summary, no existing works have attempted to improve the LMO complexity by conditionally skipping the LMO

calls. Such a trimming process is novel in the context of FW algorithms, but bears resemblance to the censoring

idea in wireless sensor networks and more recently in distributed optimization [48].

C. Contributions

In this work, we develop stochastic ﬁrst- and zeroth-order FW algorithms for solving P and P +. The proposed

algorithms uses momentum-based gradient tracking and novel proof techniques to provide stronger guarantees than

the existing FW variants [18], [19], while still using one mini-batch per iteration. Our contributions are summarized

as follows:

• We propose MOST-FW to solve P and show that it achieves the state-of-the-art convergence rate of O(k−1/2)

for both optimality gap and constraint feasibility. Remarkably, the state-of-the-art convergence rate of SFW

for solving the standard version (without additional constraint set X ) of P is also O(k−1/2) [22], [23].

• We further propose MOST-FW+ to solve P + that achieves a convergence rate of O(k−1/4) for both op-

timality gap and constraint feasibility. The proposed MOST-FW+ algorithm is a fully stochastic version of

MOST-FW and follows the same idea of momentum-based gradient tracking; however, now it tracks the

gradient of both objective and smoothed afﬁne constraints.

• For the ﬁrst time, we propose ZO methods for solving the above problems. Interestingly, the proposed ZO

versions have the same iteration complexity as their ﬁrst-order counterparts. The obtained rates even improve

over the state-of-the-art ZO algorithms for solving the set-constrained version of P or P + [38].

March 21, 2022

DRAFT

7

• We further propose trimmed variants of both the algorithms called T-MOST-FW and T-MOST-FW+ by em-

ploying a novel trimming technique to improve LMO complexity while maintaining identical convergence rates

up to small constant factors. The key idea is to skip the LMO calls when the observed stochastic gradients

are not sufﬁciently new.

• We provide numerical evidence of the superiority of the proposed approaches on various relevant applications,

namely, sparse matrix estimation, clustering via semideﬁnite relaxation, and uniform sparsest cut problem. We

also demonstrate the computational superiority of the trimmed variants by extensive numerical comparisons

with their non-trimmed version. In all cases, we report a signiﬁcant reduction in the total number of LMO

calls.

A complete comparison of the proposed algorithm with related works is provided in Table I. We only compare

with algorithms that make use of a standard mini-batch of stochastic gradients per iteration, and do not include the

algorithms relying on mega-batches, as those are generally considered impractical [30].

The rest of this paper is organized as follows. We begin with reviewing the notions of smoothing, linear

minimization oracle, and the coordinate-wise gradient estimation techniques before proceeding to discuss the

proposed algorithms of MOST-FW and MOST-FW+ in Sec. II. Various theoretical results are presented in Sec. III,

while the numerical validation is provided in Sec. IV. Finally, Section V concludes the paper.

Notation: A matrix (vector) is denoted by uppercase (lowercase) letters in bold font. The (i, j)-th element of a

matrix X is denoted by [X]ij. The notation (cid:107)·(cid:107) refers to the norm, which when applied to vectors, represents the

Euclidean norm and when applied to matrices, the spectral norm. The (cid:96)1 and Frobenius norms are denoted by (cid:107)·(cid:107)1
and (cid:107)·(cid:107)F , respectively. The inner product is represented by (cid:104)·, ·(cid:105). The distance between the point x and the set X
is denoted by DX (x) := infu∈X (cid:107)u − x(cid:107).

II. ALGORITHM DEVELOPMENT

In this section we develop the MOST-FW and MOST-FW+ algorithms (and their trimmed version T-MOST-FW and

T-MOST-FW+ ) for solving the problems P and P +, respectively. We begin with discussing some preliminaries.

The performance of the proposed algorithms will be characterized in terms of their oracle complexities. Depending

on the problem at hand, we allow two possible choices of the oracle:

• The Stochastic First-Order (SFO) oracle, which provides ∇f (x, ξ) for a given x; and

• The Stochastic Zeroth-Order (SZO) oracle provides f (x, ξ) for a given x.

When using the SZO oracle, the stochastic gradient is estimated using the so-called coordinate-wise gradient

estimator (CGE) [49], [50]:

˜∇f (x, ξ) =

m
(cid:88)

i=1

f (x + ρui, ξ) − f (x − ρui, ξ)
2ρ

ui,

(3)

where ρ is the element-wise smoothing parameter, and ui ∈ Rm is a standard basis vector with [ui]j = 1 if j = i,

otherwise zero.

March 21, 2022

DRAFT

8

Observe here that the calculation of ˜∇f (x, ξ) requires 2m calls to the SZO oracle. For the sake of brevity, we

will henceforth use g(x, ξ) to denote the stochastic gradient, with the understanding that g(x, ξ) may either be
∇f (x, ξ) or ˜∇f (x, ξ), depending on the oracle being used.

As stated earlier, we are interested in settings where the projection over X is easy but the projection over C is

difﬁcult. In particular, we will require access to a linear minimization oracle (LMO), that provides the solution to

the optimization problem minu∈C (cid:104)u, x(cid:105) for a given x. The number of calls to the LMO will also be a performance

metric.

Towards using the SFW framework to solve these problems, let us deﬁne the indicator function

1X (x) =




0

x ∈ X



∞ x /∈ X ,

which allows to write the problems P and P + compactly as

F (x) := E[f (x, ξ)] + 1X (Gx)

min
x∈C

and min
x∈C

ˆF (x) := E[f (x, ξ) + 1Xξ (G(ξ)x)],

(4)

(5)

(6)

respectively. Observe here that only the afﬁne constraints have been incorporated within the indicator function while

the constraint x ∈ C is retained as is.

A projection free algorithm, relying instead on the LMO described earlier, along the lines of [23], [27], [28],

[32] may now be applied to (5)-(6). Note however that the analysis of SFW in these works requires the objective

function to be smooth, which is not the case here due to the presence of indicator functions. To this end, we must

use a smooth approximation of the objective functions. We adopt the Nesterov’s smoothing technique [37], which

entails replacing the indicator function 1X (y) in (5)-(6) with its smooth approximation [51]:

hµ(y, X ) =

1
2µ

D2

X (y) =

1
2µ

(cid:107)y − ΠX (y)(cid:107)2
2

(7)

where µ > 0 is an algorithm parameter, ΠX (y) := argminu∈X (cid:107)u − y(cid:107)2 is the projection operator, and DX (y) :=
(cid:107)y − ΠX (y)(cid:107)2. More generally, the scaled squared set-distance function hµ is the Moreau envelope of 1X , and
therefore convex as well as 1
µ -smooth [51]. It is remarked that the idea of using a smooth approximation of the
objective, so as to allow the use of projection free algorithms (such as SFW) is well known [6], [8]. Typically,

the parameter µ must be carefully tuned so as to ensure that the approximation error, arising from the use of hµ

instead of 1X , remains less than or equal to the optimality gap at a given iteration.

A. Performance Metrics

We will analyze the performance of the proposed algorithms in terms of the following parameters

• Average optimality gap E[f (x, ξ)] − f (x(cid:63)); and

• Average constraint violation give by

D(x) :=




E[DX (Gx)]

for (P)



E[DXξ (G(ξ)x)]

for (P +)

March 21, 2022

(8)

DRAFT

9

Algorithm 1 MOST-FW

Initialization: x0, x1 ∈ C, y0, parameters {γk, ηk, µk, ρk}

for k = 1, 2, . . . do

Compute: yk = (1 − γk)yk−1 + γkg(xk, ξk)

+(1 − γk)(g(xk, ξk) − g(xk−1, ξk))

where,

g(x, ξ) =






˜∇f (x, ξ)

for SZO oracle

∇f (x, ξ)

for SFO oracle

Compute: wk = yk + µ−1

k GT (Gxk − ΠX (Gxk))

Compute: zk = argminz∈C (cid:104)z, wk(cid:105)

Update: xk+1 = xk + ηk(zk − xk)

end for

A point ˜x is said to be ((cid:15), δ)-optimal if it satisﬁes E[f (˜x)] − f (x(cid:63)) ≤ (cid:15) and D(x) ≤ δ. The algorithms will be

designed such that the constraint x ∈ C will always be satisﬁed for all iterates. The goal will be to obtain the

SFO/SZO complexities of ﬁnding an ((cid:15), δ)-optimal solution to (P) and (P +). It is remarked that for the proposed

algorithms, the LMO complexity, which counts the number of calls to the LMO oracle, is the same as the SFO/SZO

complexity as both MOST-FW and MOST-FW+ solves only a single linear minimization problem at each iteration.

Having discussed the preliminaries, we are now ready to detail the proposed algorithms.

B. MOST-FW

We begin with writing the smoothed approximation of P, which takes the form:

Fµ(x) := E [f (x, ξ)] + hµ(Gx, X ).

min
x∈C

(Pµ)

For the sake of brevity, let us denote Fµ(x, ξ) := f (x, ξ) + hµ(Gx, X ), so that Fµ(x) = E [Fµ(x, ξ)].

As mentioned earlier, the problem in P was ﬁrst considered in [18], where the ﬁrst order SFW variant called

SHCGM was proposed for the case when ∇f (x, ξ) was available. The SHCGM approach relies on three key steps:
(a) tracking ∇E [f (xk, ξ)] through the recursive update rule

(b) calling the LMO to solve the problem

yk = (1 − γk)yk−1 + γk∇f (xk, ξk),

and (c) carrying out the update

zk = argmin

z∈C

(cid:104)z, yk + ∇xhµk (Gxk, X )(cid:105),

xk+1 = xk + ηk(zk − xk).

March 21, 2022

(9)

(10)

(11)

DRAFT

10

Algorithm 2 MOST-FW+

Initialization: x0, x1 ∈ C, y0, parameters {γk, ηk, µk, ρk}

for k = 1, 2, . . . do

Compute: yk = (1 − γk)yk−1 + γk ˇgk(xk, ξk)

+(1 − γk)(ˇgk(xk, ξk) − ˇgk−1(xk−1, ξk))

where, ˇgk(x, ξ) = g(x, ξ) + ∇hµk (G(ξ)x, Xξ) and

g(x, ξ) =






˜∇f (x, ξ)

for SZO oracle

∇f (x, ξ)

for SFO oracle

Compute: zk = argminz∈C (cid:104)z, yk(cid:105)

Update: xk+1 = xk + ηk(zk − xk)

end for

It can be seen that the gradient of the smooth approximation hµ is well-deﬁned and given by

∇xhµ(Gx, X ) = GT ∇hµ(Gx, X ) =

1
µ

GT (Gx − ΠX (Gx)).

(12)

We emphasize that one cannot directly use the stochastic gradient ∇Fµk (xk, ξk) in the place of yk+∇xhµk (Gxk, X )

in (10), as the resulting algorithm does not converge. This is because the variance of the stochastic gradient

∇f (xk, ξk) does not go to zero with k. The situation can be remedied by using the average of several iid samples

of ∇f (xk, ξ), though such an approach yields poor SFO complexity [28]. A more sophisticated variance-reduction

approach was proposed in [28], which achieved a better SFO complexity but still required prohibitively large

batches of samples per iteration. Finally, tracking-updates in (9) were proposed in [32], wherein yk serves as a
biased estimator for E [∇f (xk, ξ)] but has a much lower variance, and hence achieves the same SFO complexity

but using a single sample (or a small mini-batch) per iteration. Similar gradient-tracking updates have since been

used in other SFW variants [18], [19], [38].

The proposed MOST-FW algorithm introduces two key innovations over these variants. First, to allow for the
SZO oracle, we replace ∇f (x, ξ) with g(x, ξ), which could either be ∇f (x, ξ) or ˜∇f (x, ξ). Second, we make use

of a momentum-based gradient tracker instead of that in (9), which takes the form:

yk = (1 − γk)yk−1 + γkg(xk, ξk) + (1 − γk)(g(xk, ξk) − g(xk−1, ξk)).

(13)

The momentum term in (13) was ﬁrst introduced in [52] in the context of classical stochastic gradient descent,

and has been shown to improve the gradient tracking performance. In the present case, we will establish that the

momentum-based updates in (13) yield improved oracle complexity bounds. The updates in (10)-(11) remain the

same, and the full algorithm is summarized in Algorithm 1. Recall that ρk is the smoothing parameter associated

with the gradient estimator. The choice of various algorithm parameters {γk, ηk, µk, ρk} will be speciﬁed later.

March 21, 2022

DRAFT

11

C. MOST-FW+

The derivation of the MOST-FW+ algorithm for solving P + follows along similar lines. We begin by ﬁrst writing

down the smoothed approximation of (6) as

ˆFµ(x) := E[f (x, ξ) + hµ(G(ξ)x, Xξ)]

min
x∈C

(P +
µ )

where hµ is the smooth approximation of 1Xξ deﬁned in (7). For the sake of brevity, we denote ∇ ˆFµ(x, ξ) :=
∇f (x, ξ) + ∇xhµ(G(ξ)x, Xξ). Observe here that the gradient of hµ, given by

∇xhµ(G(ξ)x, Xξ) = G(ξ)T ∇hµ(G(ξ)x, Xξ)
1
µ

GT(ξ)(G(ξ)x − ΠXξ (G(ξ)x))

=

is also random and must also be tracked.

To this end, let us deﬁne

ˇgk(x, ξ) = g(x, ξ) + ∇xhµk (G(ξ)x, Xξ)

(14)

(15)

where, as earlier, g(x, ξ) may either be ∇f (x, ξ) or ˜∇f (x, ξ), depending on the oracle available. Then the gradient

tracking update takes the form:

yk = (1 − γk)yk−1 + γk ˇgk(xk, ξk) + (1 − γk)(ˇgk(xk, ξk) − ˇgk−1(xk−1, ξk)).

(16)

Observe that different from (Pµ), the smoothed component of the objective in (P +

µ ) is also random and hence its

gradient must also be tracked via (16). Next, the LMO is called (17) and ﬁnally we carry out the updates (18)

zk = argmin

z∈C

(cid:104)z, yk(cid:105),

xk+1 = xk + ηk(zk − xk).

(17)

(18)

The full algorithm is summarized in Algorithm 2. Before proceeding to introduce a novel trimmed variant of our

proposed algorithms, we provide a remark below to better understand the use of momentum technique in our work.

Remark 1: There have been recent attempts to improve the performance of deterministic Frank-Wolfe algorithms

using Nesterov momentum [43]. However, faster rates for deterministic FW has been achieved under very speciﬁc

circumstances when the constraint set C is either a polytope [53], active strongly convex set [54], or active (cid:96)p-norm

ball [43]. Different from Nesterov momentum, the goal of momentum in stochastic optimization (13) is to reduce

the gradient approximation noise. Our use of this particular momentum technique in the FW context results in key

Lemmas 1 and 3, which yield improved rates. The analysis in these lemmas is new and instrumental as they provide

us the ﬂexibility to set both the γk and ηk decaying at the same rate, unlike the gradient tracking strategy (9). Of

particular note is the usage of momentum to track not only the objective gradient but also the constraint in the

MOST-FW+ algorithm, thanks to its versatility.

March 21, 2022

DRAFT

12

Algorithm 3 T-MOST-FW / T-MOST-FW+

Initialization: parameters {γk, ηk, τk, µk, ρk} and x0, x1 ∈ C, y0, v0

for k = 1, 2, . . . do

Obtain:

sk =




wk



yk

for MOST-FW

for MOST-FW+

Trimming:

if (cid:107)sk − vk−1(cid:107) ≥ τk or k = 1 then

Set vk = sk

Compute: zk = argminz∈C (cid:104)z, vk(cid:105)

else

zk = zk−1 and set vk = vk−1

end if

Update: xk+1 = xk + ηk(zk − xk)

end for

D. Trimmed MOST-FW and MOST-FW+

This section presents a novel trimmed version of both the proposed algorithm. The initial steps of the algorithm

remains the same, i.e., start with obtaining the tracked gradient sk = wk for MOST-FW and sk = yk for

MOST-FW+ . However, before proceeding to solve the linear minimization problem (or call to the LMO), we

ﬁrst compare sk with its old copy vk−1 and solve (10) by calling LMO only when sk provides sufﬁcient new

information. The sufﬁciency is determined by comparing the norm difference (cid:107)sk − vk−1(cid:107) with a threshold τk. In

nutshell, a new call to LMO is only made if (cid:107)sk − vk−1(cid:107) ≥ τk, where (cid:107)·(cid:107) is the norm induced by the inner product

used in the linear minimization step. Finally, we carry out the updates as (11). We will show that for carefully

designed τk, this simple thresholding strategy can scale down the number of LMO calls signiﬁcantly while still

converging at almost the same rate. The full algorithm is summarized in Algorithm 3.

III. CONVERGENCE ANALYSIS

In this section, we study the convergence rate of the proposed MOST-FW and MOST-FW+ algorithms. We begin

with stating the assumptions required for the analysis:

Assumption 1 (Smoothness) The objective function f (·, ξ) is L-smooth on C, i.e., (cid:107)∇f (x, ξ) − ∇f (y, ξ)(cid:107) ≤

L(cid:107)x − y(cid:107) for all x, y ∈ C.

Assumption 2 (Compact domain) The convex set C is compact, so that (cid:107)x − y(cid:107) ≤ D for all x, y ∈ C.

March 21, 2022

DRAFT

Assumption 3 (Bounded variance): The variance of the stochastic gradients ∇f (x, ξ) is bounded by σ2, i.e.,
(cid:107)∇f (x, ξ) − ∇f (x)(cid:107)2(cid:105)

≤ σ2.

E

(cid:104)

13

(19)

where f (x) := E [f (x, ξ)].

Assumption 4 (Bounded spectral norm) The spectral norm of the linear operators G and G(ξ) are bounded, i.e.,

(cid:107)G(ξ)(cid:107)2 ≤ LG < ∞

(cid:107)G(cid:107)2 ≤ LG < ∞

Assumption 5 (Slater’s Condition) Slater’s condition holds for P and P +. In other words, for P,

relint(C × X ) ∩ {(x, b) ∈ Rm × Rn : Gx = b} (cid:54)= ∅.

(20)

(21)

(22)

and for P +, Let C : H → R ∪ {∞}, C(Gx) := E[δXξ (G(ξ)x)], with the linear operator G : Rm → H deﬁned as
G(x)(ξ) := G(ξ)x, for all x, we require that

here, sri stands for strong relative interior [55] and deﬁned as

0 ∈ sri(dom(C) − G(dom(f )))

sriC = {x ∈ C|cone(C − x) = span(C − x)}

(23)

(24)

Assumptions 1, 2, and 3 are standard in the context of SFW algorithms. Observe that Assumption 1 also implies

that f (x) is L-smooth. Further we have from [50, Lemma 3] that

(cid:13)
(cid:13)
˜∇f (x, ξ) − ∇f (x, ξ)
(cid:13)
(cid:13)
(cid:13) ≤
(cid:13)

√

mLρ,

which in turn, implies that

(cid:13)
(cid:13)
˜∇f (x) − ∇f (x)
(cid:13)
(cid:13)
(cid:13) ≤
(cid:13)

√

mLρ.

Assumptions 1 and 3 imply that the variance of ˜∇f (x, ξ) is bounded since

E

(cid:20)(cid:13)
(cid:13)
˜∇f (x) − ˜∇f (x, ξ)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

2(cid:21)

= E

(cid:104)
(cid:107) ˜∇f (x) + ∇f (x)

(25)

(26)

+∇f (x, ξ) − ∇f (x) + ˜∇f (x, ξ) − ∇f (x, ξ)(cid:107)2(cid:105)
(cid:20)(cid:13)
˜∇f (x) − ∇f (x)
(cid:13)
(cid:13)

+ 3E

(cid:13)
(cid:13)
(cid:13)

2(cid:21)

(cid:104)

≤ 3E

(cid:107)∇f (x) − ∇f (x, ξ)(cid:107)2(cid:105)
2(cid:21)

≤ 3σ2 + 6mL2ρ2

+ 3E

(cid:20)(cid:13)
(cid:13)∇f (x, ξ) − ˜∇f (x, ξ)
(cid:13)

(cid:13)
(cid:13)
(cid:13)

Assumption 4 is intuitive and required to ensure that the composite objectives Fµ (cf. (Pµ)) and ˆFµ (cf. (P +

µ )) are

smooth; see also [8], [19]. Finally, Slater’s condition in Assumption 5 implies that for the convex problems P and
P +, strong duality holds and that the dual optimum variable, denoted by λ(cid:63), is bounded and ensures the constraint

set to have a non-empty strong relative interior.

We begin with a brief outline of the proof. We will decrease µ with each iteration so that the decision variable

converges to the original solution as the algorithm proceeds. However, we will observe that the variance of

the stochastic gradient ∇hµ(G(ξ)x, Xξ) is inversely proportional to the smoothing parameter µ (c.f. (72)) and

March 21, 2022

DRAFT

14

hence reducing µ results in a proportional increase in the gradient approximation noise. The same issue was also

encountered in [19] because of which their algorithm (H1-SFW) settled at the convergence rate of O(k−1/6). In this

work, we will show that by careful selection of smoothness parameter µ and using the momentum-based gradient

tracking given in (16), our algorithm can deal with this issue of gradient approximation noise in a much better way

than H1-SFW and helps in achieving better results.

A. Convergence Analysis of MOST-FW

We begin with establishing a key lemma characterizing the evolution of the tracking error E [yk − g(xk)], where
g(xk) := E [g(xk, ξ)]. To allow us to present the results in a uniﬁed manner, we adopt the convention that ρk = 0

when using the SFO oracle, and ρk > 0 when using the SZO oracle. Since a zero value of ρk does not make sense

in (3), the usage should be clear from the context.

Lemma 1 (a) Under Assumptions 1-3, the iterates generated by MOST-FW satisfy:

E

(cid:104)

(cid:107)yk − g(xk)(cid:107)2(cid:105)

≤ (1 − γk)2E

(cid:104)

(cid:107)yk−1 − g(xk−1)(cid:107)2(cid:105)

+ 6γ2

kσ2 + 24mL2ρ2

k−1 + 6η2

k−1L2D2

(b) For the choice γk = 1

k , ηk = 2

k+1 , and ρk ≤

D√
m(k+1) , it holds that

E

(cid:107)yk − ∇f (xk)(cid:107)2(cid:105)
(cid:104)

≤

16(3σ2 + 25L2D2)
k

.

(27)

(28)

Proof: We start by subtracting g(xk) from both sides of (13) and introducing g(xk−1) on the right to obtain

yk − g(xk) = (1 − γk)(yk−1 − g(xk−1))

+ (g(xk, ξk) − g(xk)) + (1 − γk)(cid:0)g(xk−1) − g(xk−1, ξk)(cid:1).

(29)

From the deﬁnition of g, it holds that, E [g(x) − g(x, ξ)] = 0 for all x, implying that the last two terms in (29) are

zero mean. Hence, taking squared-norm on both sides and taking expectation with respect to ξk, we obtain

(cid:104)

(cid:107)yk − g(xk)(cid:107)2(cid:105)

Ek

= (1 − γk)2 (cid:107)yk−1 − g(xk−1)(cid:107)2

(cid:104)

+ Ek

(cid:107)(g(xk, ξk) − g(xk)) +(1 − γk)(cid:0)g(xk−1) − g(xk−1, ξk)(cid:107)2(cid:3)

(30)

where Ek denotes the expectation with respect to the random variable ξk, while keeping everything else ﬁxed. Next,

let us consider the second term and bound it separately. Deﬁning

Xk := γk(g(xk, ξk) − g(xk))

Yk := (1 − γk)(g(xk, ξk) − g(xk−1, ξk)),

(31)

(32)

we see that the second term in (30) is given by Ek(cid:107)Xk + Yk − EkYk(cid:107)2 and can be bounded by using the inequality
Ek(cid:107)Xk + Yk − EkYk(cid:107)2 ≤ 2Ek(cid:107)Xk(cid:107)2 + 2Ek(cid:107)Yk(cid:107)2.

To obtain bounds on Ek(cid:107)Xk(cid:107)2 and Ek(cid:107)Yk(cid:107)2, we consider the SFO and SZO cases separately.

SFO oracle: In this case, g(xk, ξk) = ∇f (xk, ξk), so it follows that

Ek(cid:107)Xk(cid:107)2 = γ2
k

E

(cid:107)∇f (xk)−∇f (xk, ξk)(cid:107)2(cid:105)
(cid:104)

≤ γ2

kσ2

March 21, 2022

(33)

DRAFT

from Assumption 3. Likewise, from Assumption 1 we have

Ek(cid:107)Yk(cid:107)2 = (1 − γk)2Ek

(cid:107)∇f (xk, ξk) − ∇f (xk−1, ξk)(cid:107)2(cid:105)
(cid:104)

≤ L2 (cid:107)xk − xk−1(cid:107)2

≤ L2η2

k−1D2

where we have also used the update (11), dropped the factor (1 − γk)2, and used Assumption 2.
SZO oracle: In this case, g(xk, ξk) = ˜∇f (xk, ξk), so that

Ek(cid:107)Xk(cid:107)2 = γ2
k

E

(cid:20)(cid:13)
(cid:13)
˜∇f (xk) − ˜∇f (xk, ξk)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

2(cid:21)

≤ 3γ2

k(σ2 + 2mL2ρ2
k)

≤ 3γ2

kσ2 + 6mL2ρ2
k

15

(34)

(35)

from (26) and since γk ≤ 1. Next, expanding Yk and using (25)-(26), we obtain

Ek(cid:107)Yk(cid:107)2 = (1 − γk)2Ek

(cid:20)(cid:13)
(cid:13)
˜∇f (xk−1, ξk) − ˜∇f (xk, ξk)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

2(cid:21)

= (1 − γk)2Ek(cid:107) ˜∇f (xk−1, ξk) − ∇f (xk−1, ξk) + ∇f (xk−1, ξk) − ∇f (xk, ξk) + ∇f (xk, ξk) − ˜∇f (xk, ξk)(cid:107)2

≤ 3Ek(cid:107) ˜∇f (xk−1, ξk) − ∇f (xk−1, ξk)(cid:107)2 + 3Ek(cid:107)∇f (xk, ξk) − ˜∇f (xk, ξk)(cid:107)2 + 3Ek(cid:107)∇f (xk−1, ξk) − ∇f (xk, ξk)(cid:107)2

≤ 3mL2ρ2

k + 3mL2ρ2

k−1 + 3L2(cid:107)xk − xk−1(cid:107)2

≤ 3mL2ρ2

k + 3mL2ρ2

k−1 + 3η2

k−1L2D2.

(36)

where we again used (11), Assumption 2, and dropped the factor (1 − γk)2. Finally, if we ensure that ρk ≤ ρk−1,
then the right-hand side of (36) can be written as 6mL2ρ2

k−1 + 3η2

k−1L2D2.

Since the bounds for the SFO and SZO cases differ only in constant factors and in terms depending on ρk, they

can be uniﬁed as

(cid:107)Xk + Yk − Ek [Yk](cid:107)2(cid:105)
(cid:104)

Ek

≤ 6γ2

kσ2 + 24mL2ρ2

k−1 + 6η2

k−1L2D2

(37)

where recall our convention that ρk = 0 for SFO case. Substituting (37) into (30), we obtain the required result.

(b) Substituting in (27), we obtain

E

(cid:107)yk − g(xk)(cid:107)2(cid:105)
(cid:104)

≤ (cid:0)1 − 1

k

(cid:1)2 E

(cid:107)yk−1 − g(xk−1)(cid:107)2(cid:105)
(cid:104)

+ 6(σ2 + 8L2D2)

1
k2

Subsequently, using Lemma 6 with a = 2 and A = 6(σ2 + 8L2D2), we obtain

E

(cid:104)

(cid:107)yk − g(xk)(cid:107)2(cid:105)

≤

24(σ2 + 8L2D2)
k

(38)

(39)

March 21, 2022

DRAFT

16

For SFO case, we get the desired bound simply by setting g(xk) = ∇f (xk) in (39). For SZO case, we start with
E

, introduce ˜∇f (xk), set g(xk) = ˜∇f (xk) in (39), and recall that

(cid:13)
(cid:13)
2
(cid:13)∇f (xk) − ˜∇f (xk)
(cid:13)
(cid:13)
(cid:13)

≤

(cid:104)

(cid:107)yk − ∇f (xk)(cid:107)2(cid:105)
k, so as to yield:

mL2ρ2

E

(cid:104)

(cid:107)yk − ∇f (xk)(cid:107)2(cid:105)

≤ 2E

(cid:20)
(cid:107)yk − g(xk)(cid:107)2 +

(cid:13)
(cid:13)
(cid:13)∇f (xk) − ˜∇f (xk)
(cid:13)
(cid:13)
(cid:13)

2(cid:21)

≤

16(3σ2 + 25L2D2)
k

.

(40)

(41)

Observe that the bound in (39) is less than that in (41), and differs only in constant factors. Therefore, for the sake

of simplicity, we use (41) as the uniﬁed bound.

Bound for Lemma 1 establishes that the auxiliary variable yk tracks the actual gradient ∇f (xk) with average

error bounded as O

(cid:16) σ2+L2D2
k

(cid:17)

.

Remark 2: The gradient tracking approach deﬁned in (13) provides a modiﬁcation of the approach in (9) by adding

a correction term (1 − γk)(g(xk, ξk) − g(xk−1, ξk)). This correction term plays a crucial role in variance reduction
by exploiting the smoothness of f (·, ξ). To see this, let us inspect the tracking error Ek = E (cid:107)yk − g(xk)(cid:107)2 for

both the cases, which yield bounds:

Ek ≤ (1 − γk)Ek−1 + O(γ2

k) + O(η2

k/γ2

k),

Ek ≤ (1 − γk)Ek−1 + O(γ2

k) + O(η2

k),

(42)

(43)

respectively. Observe here that the error dynamics differs only in the last term, where for (9), we have a O(η2

k/γ2
k)
term while for (13), we only have an O(η2
k) term. This means that if we want Ek to decrease with k, we would
have to ensure for (9) that the term η2
= O(γk) → 0, while no such restriction applies to (13). It turns out that
k
γ2
k
this ﬂexibility is the key to achieving a better rate for the proposed algorithms; in fact we set ηk = γk = O(k−1)
for MOST-FW and ηk = γk = O(k−1/2) for MOST-FW+ to obtain the required rates. This particular choice of

step-size parameters would not have been possible had we used the classical gradient tracking estimator (9). Next,

we have the following lemma regarding the evolution of the smoothed objective function.

Lemma 2 (a) Under Assumptions 1, 2, 4, and 5, and for µk ≥ µk−1(1 − ηk), it holds that

Fµk (xk+1) − f (x(cid:63)) ≤ (1 − ηk) (cid:0)Fµk−1(xk) − f (x(cid:63))(cid:1) +

(b) Under Assumptions 1-5, and for ηk = 2

k+1 , γk = 1

k , ρk ≤

(cid:18)

(cid:19)

η2
k
2

L +

LG
µk
m(k+1) , and µk = µc√
D√

k

D2 + ηkD (cid:107)∇f (xk) − yk(cid:107)

(44)

, the smoothed function gap

is bounded by

E[Fµk (xk+1)]−f (x(cid:63)) ≤

√

8

3σD+(41L+LGµ−1
√
k

c )D2

(45)

Proof: The proof of Lemma 2 is provided in Sec.C-A of the supplementary material and is largely similar to proof
(cid:17)

of Theorem 9 in [18]. For a constant µc, Lemma 2 establishes that the smoothed gap evolves as O

(cid:16) σD+LD2
√

,

k

and will allow us to infer the optimality gap and the constraint violation in the subsequent theorem. It is remarked

here that ρk is not a tuning parameter. Ideally, we would like ρk to be as small as possible, so as to minimize the

approximation error. In practice though, a very small value of ρk may not be viable due to computational issues.

March 21, 2022

DRAFT

The results developed here make sense provided that ρk is not too large so as to impact the rate of convergence.

Therefore, the statement of the results require an explicit upper bound on ρk as a function of k.

17

Theorem 1 Under Assumptions 1-5 and for ηk = 2

k+1 , γk = 1

k , ρk ≤

m(k+1) , and µk = µc√
D√

k

, we have:

(a) Optimality gap:

(b) Constraint violation:

E[f (xk)] − f (x(cid:63)) ≤

√

8

3σD+(41L+LGµ−1
√
k

c )D2

where Q := 2µc (cid:107)λ(cid:63)(cid:107) + 6

√

σDµc + 10D

√

Lµc + 2D

√

LG.

E[DX (Gxk)] ≤

Q
√
k

(46)

(47)

Proof: The proof is provided in Sec. C-B of the supplementary material. Theorem 1 establishes an upper bound on

the expected suboptimality and constraint feasibility for the iterates generated by MOST-FW and shows that they

converge to zero at least at the rate of O(k−1/2). These results can be directly translated to oracle complexities

of ﬁnding an ((cid:15), δ)-optimal solution to P. Deﬁning Υ := σD + (L + LG)D2, it can be seen that the SFO oracle

complexity is given by O

(cid:16)

max{ Υ2

(cid:15)2 , (cid:107)λ(cid:63)(cid:107)2+Υ

δ2

(cid:17)
}

while the SZO complexity is O

(cid:16)

m max{ Υ2

(cid:15)2 , (cid:107)λ(cid:63)(cid:107)2+Υ

δ2

(cid:17)
}

, since

gradient calculation requires 2m calls to the SZO oracle. This concludes our analysis of the MOST-FW algorithm.

B. Convergence Analysis of MOST-FW+

We now consider the MOST-FW+ algorithm for solving P +. As in MOST-FW , we begin with bounding the

mean square tracking error E(cid:107)∇ ˆFµk (xk) − yk(cid:107)2.

Lemma 3 (a) Under Assumptions 1-4, the iterates generated by MOST-FW+ satisfy:

(cid:104)

(cid:107)yk − ˇgk(xk)(cid:107)2(cid:105)

Ek

≤ (1 − γk)2 (cid:107)yk−1 − ˇgk−1(xk−1)(cid:107)2

+ 12γ2

4γ2

+

kσ2 + 60mL2ρ2
kL2
GD2
µ2
k

+ 6L2

k−1 + 18η2
(cid:18) 1
µk

GD2

−

k−1L2D2
(cid:19)2

1
µk−1

+

24η2

GD2

k−1L2
µ2

k−1

(b) For the choice γk = 1

k , ρk ≤

m(k+1) , ηk = 2
D√

k+1 , and µk =

E(cid:107)∇ ˆFµk (xk) − yk(cid:107)2 ≤

96(σ2 + 12L2D2 + 9L2

µc

(k+1)1/4 , it holds that
Gµ−2

c D2)

.

√

k

(48)

(49)

Proof: The proof of Lemma 3 is provided in Appendix A. Bound for Lemma 3 establishes that for a constant µc,
(cid:17)
the auxiliary variable yk tracks the actual gradient ∇ ˆFµk (xk) with average error bounded as O
Next, we present the following lemma on the evolution of the smoothed objective function.

(cid:16) σ2+(L2+L2

G)D2

√

k

.

Lemma 4 Under Assumptions 1-5, ρk ≤

D√
m(k+1) , γk = 1

k , and µk =

µc

(k+1)1/4 , the smoothed function gap is

bounded by

March 21, 2022

E[ ˆFµk (xk+1)]−f (x(cid:63)) ≤

√

8(4

6σD + (35L + 31LGµ−1
k 1

4

c )D2)

(50)

DRAFT

Proof: The proof of Lemma (4) is provided in Sec.C-C of the supplementary material. For a constant µc, Lemma
(cid:16) σD+(L+LG)D2
k

4 establishes that the smoothed gap evolves as O

, and will allow us to infer the optimality gap

(cid:17)

1
4

and the constraint violation in the subsequent theorem.

18

Theorem 2 Under Assumptions 1-5 and for ηk = 2

k+1 , γk = 1

k , ρk ≤

D√
m(k+1) , and µk =

µc

(k+1)1/4 , we have:

(a) Optimality gap:

(b) Constraint violation:

E[f (xk)] − f (x(cid:63)) ≤

√

8(4

6σD + (35L + 31LGµ−1
k 1

4

c )D2)

E[DX (ξ)(G(ξ)xk+1)] ≤

Q+
k 1

4

,

where

Q+ := 2

(cid:16)

µc (cid:107)λ(cid:63)(cid:107) + 9(cid:112)σDµc + 17D(cid:112)Lµc + 16D

√

LG

(cid:17)

.

(51)

(52)

Proof: The proof is provided in Sec. C-D of the supplementary material. Theorem 2 establishes an upper bound

on the expected suboptimality and constraint feasibility for the iterates generated by MOST-FW+ and shows that

they converge to zero at least at the rate of O(k1/4). These results can be directly translated to oracle complexities

of ﬁnding an ((cid:15), δ)-optimal solution to P +. Deﬁning Υ := σD + (L + LG)D2, it can be seen that the SFO oracle

complexity is given by O

(cid:16)

max{ Υ4

(cid:15)4 , (cid:107)λ(cid:63)(cid:107)4+Υ2

δ4

(cid:17)

}

while the SZO complexity is O

(cid:16)

m max{ Υ4

(cid:15)4 , (cid:107)λ(cid:63)(cid:107)4+Υ2

δ4

(cid:17)
}

, since

gradient calculation requires 2m calls to the SZO oracle. Note that although the variance reduced algorithm H-

SPIDER-FW [19] achieved the sfo complexity of O((cid:15)−4, δ−4), it requires evaluating a batch of gradients at each

iteration with batch size changing with iteration as O(2k). This restricts the use of H-SPIDER-FW in online setting

where at each iteration we have access only to a single stochastic gradient.

Remark 3: We can explore the dependency of convergence results on the smoothness parameter µk by setting
(k+1)b with b ∈ (1/6, 1/4) in Theorem 2. For this choice of µk, we obtain an optimality gap of O(kb− 1
µk = µc
a constraint feasibility of O(k− min{b, 1

4 }). Varying b in the range (1/6, 1/4) one can observe the trade-off between

2 ) and

optimality gap and constraint feasibility. This trade-off can be better understood from Fig.1, which compares the

convergence rates of all the discussed algorithms. For instance, on setting b = 1/6, for the same order of constraint

feasibility (O(k−1/6)), the proposed algorithm MOST-FW+ shows an improved optimality gap of O(k−1/3) over

O(k−1/6) of H1-SFW. Similarly on setting b = 1/4, MOST-FW+ attains (O(k−1/4)) optimality gap and while the

constraint feasibility gets improved to O(k−1/4) compared to O(k−1/6) of H1-SFW.

Remark 4: Note that CGE in (3) is only a representative of various ZO gradient estimators. One can also use other

estimators as long as it is ensured that the numerical gradient is asymptotically unbiased with ρt → 0. For instance,

we can use I-RDSA [38] where only ˆm < m directions are sampled at each iteration. Although such an approach

reduces the SZO call from 2m to 2 ˆm at each iteration, it makes the ﬁnal rate proportional to m

ˆm . Hence, the total
calls to SZO oracle to achieve (cid:15)-optimal solution remains the same as in our case at O(m(cid:15)−2) for P and O(m(cid:15)−4)

for P +.

March 21, 2022

DRAFT

19

Fig. 1: Comparison of convergence rates for different algorithms. Red color denotes existing state-of-the-art algorithms while blue

color represents the proposed algorithms. Star is used to represent FW-algorithms for problems without additional constraints.

C. Convergence Analysis of T-MOST-FW and T-MOST-FW+

We begin the analysis of trimmed variant with establishing a key lemma characterizing the error introduced due

to trimming operation and then provide the convergence rates.

Lemma 5 For Algorithm 3, the error introduced is upper bounded by the threshold τk, i.e.,

ek := (cid:107)sk − vk(cid:107) < τkfor allk ≥ 0

(53)

Proof: According to the trimming strategy, we have vk = sk if (cid:107)sk − vk−1(cid:107) ≥ τk and vk = vk−1 if (cid:107)sk − vk−1(cid:107) <

τk. Therefore, in both cases, we have ek = (cid:107)sk − vk(cid:107) < τk.

Theorem 3 Under Assumptions 1-5, with ηk = 2

k+1 , γk = 1

k , and ρk ≤

D√
m(k+1) ,

(a) for T-MOST-FW with τk =

τ0

(k+1)1/2 and µk = µc√

k

, we have the following bounds

E[f (xk)] − f (x(cid:63)) ≤ O

(cid:19)

(cid:18) 1
√
k

+

8τ0D
√
k

,

(b) and for T-MOST-FW+ with τk =

τ0

(k+1)1/4 and µk =

E[DX (Gxk)] ≤ O

(cid:19)

+

√
τ0D
4
√
k

,

(cid:18) 1
√
k
µc

(k+1)1/4 , we have the following bounds

E[f (xk)] − f (x(cid:63)) ≤ O

(cid:19)

+

(cid:18) 1
k 1

4

8τ0D
k 1

4

E[DX (Gxk)] ≤ O

(cid:19)

6

+

(cid:18) 1
k 1

4

√

τ0D
k 1

4

.

(54)

(55)

(56)

(57)

Proof: The proof is provided in Sec. C-E of the supplementary material. Theorem 3 establishes an upper bound

on the expected suboptimality and constraint feasibility for the iterates generated by T-MOST-FW (part(a)) and T-

MOST-FW+ (part(b)). Note that, as compared to the non-trimmed version, these convergence rates are reduced by

March 21, 2022

DRAFT

O(k-1/2)O(k-1/3)O(k-1/4)O(k-1/5)O(k-1/6)O(k-1/2)O(k-1/3)O(k-1/4)O(k-1/5)O(k-1/6)SHFW+(O(k-1/6),O(k-1/6))MOST-FW(O(k-1/2),O(k-1/2))ZO-SFWMOST-FW+(O(k-1/4),O(k-1/4))(O(k-1/6),O(k-1/3))SHFW(O(k-5/12),O(k-1/3))ORGFW20

(a) Objective

(b) Constraint Violation

(c) T-MOST-FW

(d) Objective

Fig. 2: Sparse matrix estimation (Sec.IV-A): (a)-(b): Comparison of the proposed algorithm MOST-FW with HFW and SHCGM,

(c): percentage of LMO (compared to MOST-FW) skipped and (d) convergence performance of T-MOST-FW at different threshold

values (τ0).

the factor of τ0. Hence, the SFO oracle complexity for T-MOST-FW and T-MOST-FW+ will be O

(cid:16) (1+τ0)2
(cid:15)2

(cid:17)

and

, respectively. Although it is not possible to directly quantify the LMO complexity for trimmed case,

(cid:16) (1+τ0)4
(cid:15)4

(cid:17)

O

we expect it to be a fraction of SFO complexity. In fact, experimentally (in Section IV) we observe a signiﬁcant

reduction in LMO calls (more than 30%) when compared to the non-trimmed version while maintaining almost

similar accuracy.

In this section, we compare the performance of proposed algorithms MOST-FW and MOST-FW+ with that of

IV. NUMERICAL EXPERIMENTS

HFW [37], SHCGM [18] and H1-SFW [19]. We set γk = 1
τ0
ηk = 2
k1/4 for MOST-FW+ , as dictated by theory.. Further, we set τk as
(k+1)1/4
for T-MOST-FW and T-MOST-FW+ , respectively. The parameter µc and τ0 are tuned to yield the best possible

for MOST-FW and γk = 1
k ,

k+1 , and µk = µc

k+1 , and µk = µc√

(k+1)1/2 and

k , ηk = 2

τ0

k

performance. We plot the objective and constraint violation for different applications to highlight the improved

convergence bounds obtained theoretically. Further, to understand the effect of the trimming scheme, we plot the

total number of times the trimmed variant of the algorithms skipped the LMO calls (in %) for different values of

threshold τ0 as compared to the total LMO calls required by the non-trimmed version (τ0 = 0) of the algorithm. We

also demonstrate the potential advantage of the trimmed version over the original methods by plotting the evolution

of optimality gap at different threshold values.

March 21, 2022

DRAFT

020004000600080001000010-2100020004000600080001000010-51002.533.544.5202530354020004000600080001000010-210021

(a) Objective

(b) T-MOST-FW

(c) Objective

(d) Constraint Violation

(e) T-MOST-FW+

(f) Objective

Fig. 3: K-means clustering (Sec.IV-B): Comparison of (a) Optimality Gap (d) Constraint violation of the proposed algorithms.

Percentage of LMO calls skipped at different threshold values (b) by T-MOST-FW (compared to MOST-FW) and (e) by T-
MOST-FW+ (compared to MOST-FW+). Convergence performance (c) for T-MOST-FW and (f) for T-MOST-FW+ at different

threshold values.

A. Sparse matrix estimation

We consider the problem of estimating a sparse covariance matrix, given independent samples of a Gaussian

random vector, observed in a sequential fashion [56]. The problem arises in a number of disciplines, such as

physics, ﬁnance, machine learning, genome sequencing, and portfolio optimization [57], [58]. The problem can be

formulated as

min
X∈C

f (X) := E (cid:13)

(cid:13)X − wwT(cid:13)
2
(cid:13)

F

s.t. (cid:107)vec (X)(cid:107)1 ≤ α,

(58)

(59)

where C := {X (cid:23) 0, tr(X) ≤ K} and the expectation is over random vector w. For the experiments, we consider
the setup in [18]. The underlying covariance matrix W ∈ R1000×1000 is generated as W = (cid:80)10

i=1 ψiψT

i where the

entries of ψi are drawn uniformly at random from [−1, 1]. At each t, we observe wt ∼ N (0, W) and the goal is

to estimate W by solving (58)-(59), which matches the template in MOST-FW . Observe that the projection over C

is difﬁcult, but projection over the (cid:96)1 norm ball is easy. For this problem, we set α = tr(W) and K = (cid:107)vec (W)(cid:107)1.
We compare the performance of the deterministic HFW, its online version SHCGM, and the proposed MOST-FW

algorithms, the latter two (being stochastic) uses a mini-batch of 200 data points.

We set µc = 1 for MOST-FW while the parameters of HFW and SHCGM are kept the same as in [37], [18],

March 21, 2022

DRAFT

10010510-5100510151520253010010210410-310110010510-210-11001011415162535455522

(a) Objective

(b) T-MOST-FW

(c) Objective

(d) Constraint Violation

(e) T-MOST-FW+

(f) Objective

Fig. 4: Uniform Sparsest Cut (Sec.IV-C): Comparison of (a) Optimality Gap (d) Constraint violation of the proposed algorithms.

Percentage of LMO calls skipped at different threshold values (b) by T-MOST-FW (compared to MOST-FW) and (e) by T-
MOST-FW+ (compared to MOST-FW+). Convergence performance (c) for T-MOST-FW and (f) for T-MOST-FW+ at different

threshold values.

respectively. We run all three algorithms for 104 iterations and analyze their performance in terms of objective
convergence as (cid:107)X − W(cid:107)2

F and constraint violation as max((cid:107)X(cid:107)1 − α, 0)/α.

F / (cid:107)W(cid:107)2

The convergence plots for this experiment are shown in Fig.2. HFW, being a deterministic algorithm, con-

verges fast but gets saturated at some accuracy as it uses the same datapoints at all the iterations. Advantages of

MOST-FW over both the compared algorithms are evident from the plots of optimality gap Fig.2a and constraint

violation Fig.2b, which converges much faster and to a better accuracy level. Next, we analyze the performance

of T-MOST-FW at different threshold values τ0 and plot the variation of LMO(%) in Fig.2c. As expected, the

algorithm frequently skips calls to the LMO with the increase in the threshold value. We proceed to study the effect

of trimming on the convergence in Fig.2d Observe that though trimming affects the convergence, for properly chosen

threshold we can get comparable performance with that of the non-trimmed version. For instance, at τ0 = 3.5,

T-MOST-FW skips around 28% of LMO calls while maintaining almost the same performance as MOST-FW .

B. Clustering via semideﬁnite relaxation

In this experiment, we will consider the K-means clustering problem deﬁned in (1)-(2) which is also considered

in the previous related works [18], [37], [59].

Observe that (1)-(2) is of the form in P when only the entries of M corresponding to a randomly selected subset

Ωt ⊂ Ω are revealed at every iteration. The K-means problem can therefore be solved using the SHCGM algorithm

March 21, 2022

DRAFT

10010510-21000.511.52202530354010010110210310410-210010010510-2100102345672025303510010510-410-210023

from [18] and the proposed MOST-FW algorithm. Further, if a randomly selected subset of the constraints are

imposed at every iteration, we obtain the formulation in P +, allowing us to use the H1-SFW algorithm [19] and

the proposed MOST-FW+ algorithm. It is remarked that the projection over a subset constraints is simpler, and

therefore the formulation in P + is better suited to larger scale problems.

For the experiment, we use N = 1000 samples from MNIST dataset [60] with K = 10 clusters. For MOST-FW ,

MOST-FW+ , SHCGM, and H1-SFW, we estimate objective gradient using only 1% of the data at each iteration

while HFW being deterministic in nature, uses full data. In addition, for MOST-FW+ and H1-SFW, we use only

1% of the randomly sampled constraints at each iteration. We tune µc to achieve the best performance for all
the algorithms and ﬁnally set µc = 10 for MOST-FW and µc = 2.75 for MOST-FW+ while for HFW, SHCGM
and H1-SFW we use the same parameters as in [18], [19], [37], respectively. We run all the algorithms for 105

iterations and analyze their performance in terms of objective convergence as |f (X) − f (cid:63)|/|f (cid:63)| where f (cid:63) = f (X(cid:63))

is derived from the ground truth1 and constraint violation as the sum of violation of both the constraints of (2), i.e.,
(cid:107)X1 − 1(cid:107) / (cid:107)1(cid:107) and (cid:13)

(cid:13)F . The convergence results are shown in Fig. 3a and 3d. It can be observed
that MOST-FW shows the best practical performance, very similar to the deterministic algorithm HFW, although

(cid:13)X − Π[X]i,j ≥0(X)(cid:13)

it uses only 1% of the data at each iteration. Also, MOST-FW+ shows slightly better performance compared to

H1-SFW. These results support our theoretical ﬁndings.

Next, to analyze the performance of trimmed variants, in our experiment, we use N = 2000 samples while

keeping all other settings the same as above. The experimental results are shown in Fig.3 (b-c) and Fig.3 (e-f).

Observe that both the trimmed algorithms skip more LMO calls with the increase in the threshold value. Although

T-MOST-FW skips only around 15% of LMO calls at τ0 = 5, we observed slightly improved performance for T-
MOST-FW+ that skips 25% of LMO calls (at τ0 = 14) while maintaining almost the same convergence performance
as MOST-FW+ .

C. Uniform Sparsest Cut Problem

Consider the problem of graph partitioning where the target is to divide the graph into two or more sub-graphs

by cutting the smallest number of edges. The problem arises in the design of divide-and-conquer algorithms for a

number of other problems including, communications in distributed networks, cluster analysis and, machine learning

[61], [62].

Consider a graph G = (V, E), where V is a set of d vertices, and E is a set of edges. Let A, ˆA ⊂ V denote
two disjoint sets of vertices and let E(A, ˆA) denote the number of edges between these sub-graphs. The uniform
sparsest cut problem considered in [11] aims to ﬁnd the cut (A, ˆA) which minimizes

|E(A, ˆA)|
|A|| ˆA|

,

(60)

where the |·| operator returns the cardinality of the corresponding set. However, ﬁnding such a partition is NP-hard,
and a number of approximation algorithms for solving it exist [63], [64]. Of particular interest is the O((cid:112)log(d))-

1The ground truth is obtained using kmeans-sdp of [59]; see also https://github.com/solevillar/kmeans sdp

March 21, 2022

DRAFT

approximation proposed in [11], that relies on embedding the nodes of the graph onto the d-dimensional space.

The embedding can be obtained by solving the SDP [19]

24

min
X∈C

1
d2

(cid:88)

i,j

[L]ij[X]ij

s.t. d Tr(X) − Tr(1d×dX) =

d2
2

,

Xi

j + Xj

k − Xi

k − Xj

j ≤ 0, for all i, j, k ∈ V,

(61)

(62)

(63)

where L is the Laplacian of G and C := {X (cid:23) 0, tr(X) ≤ d}. The problem can be formulated as P and solved

using MOST-FW by considering only a subset of the summands in the objective function at every iteration. Further,

if only a subset of the constraints are considered at every iteration, the problem is cast as P + and can be solved

using MOST-FW+ .

We will adopt the experimental setup of [19] and use mammalia-primate-association-13 graph from the Network
Repository dataset [65] which has 25 nodes and 181 edges. The SDP dimension for this graph is X ∈ R25×25

while the number of constraints is around 6.9 × 103. We set the batch size to 5% for all algorithms and additionally

use only 5% of the randomly sampled constraints at each iteration for H1-SFW and MOST-FW+ . Finally, we

set µc = 1.5 and 1 for MOST-FW and MOST-FW+ , respectively. For SHCGM and H1-SFW, we use the same

parameters as in [18] and [19], respectively.

not its gradients. We set ρk =

We also test the performance of the ZO methods by assuming that only the loss function values are available but
2√
m(k+1) with m = d2 = 625, and the approximate gradients are obtained using (3).
We run all the algorithms for 105 iterations and plot the convergence results in Fig.4a and Fig.4d. Both the

proposed algorithms outperform SHCGM and H1-SFW. Also, the ZO variants of the proposed algorithms show

almost similar performance. However, these require 2m SZO calls per iteration. Next, we plot the performance

variation with trimming threshold τ for the trimmed variant of both the proposed algorithms. The center plots

(Fig.4b and Fig.4e) show the variation in LMO (%) while the right plots (Fig.4c and Fig.4f) show the effect of

trimming on the objective for few threshold values. Observe that, for both the cases, the trimmed version provides

a signiﬁcant reduction in total LMO calls. In particular, at τ0 = 1, T-MOST-FW skips around 40% of LMO calls
while at τ0 = 5, T-MOST-FW+ skips around 37% of LMO calls while maintaining a similar performance compared

to their non-trimmed version.

V. CONCLUSION

This work puts forth projection-free algorithms MOST-FW and MOST-FW+ to solve constrained stochastic

optimization algorithms. The problems considered here contain two sets of constraints. The ﬁrst set of constraints are

deterministic and difﬁcult to project onto, motivated from the semideﬁnite cone constraints that arise in semideﬁnite

programming. The second set of constraints are easy to project onto, but may be large in number or stochastic,

and can model the very large number of constraints that arise in context of semideﬁnite relaxation. We use the

stochastic Frank-Wolfe (FW) method to develop projection-free algorithms for solving these problems. The second

set of constraints is incorporated using an indicator function within the objective and Nesterov’s smoothing is applied

March 21, 2022

DRAFT

25

to simplify the application of the FW method. Different from existing FW methods to solve similar problems, we

utilize a momentum-based gradient tracker that results in improved convergence rates, at par with the set-constrained

problems. We also develop zeroth-order algorithms for solving the same problems, yielding gradient-free and

projection-free algorithms for solving the same problems while again achieving state-of-the-art convergence rates.

We have also proposed a variant of both the algorithms employing a novel trimming strategy that reduces the number

of times linear minimization problem required to be solved over the domain to reach a certain accuracy. Finally,

the performance of the different algorithms is validated numerically on the problems of sparse matrix estimation,

clustering, and sparsest cut. Also, to highlight the usefulness of the trimming scheme, in experiments, we plot the

reduction in LMO calls at different threshold and studied the effect of trimming (LMO calls) on the optimality

gap. Results showed that the trimmed versions provide signiﬁcant reduction in total LMO calls while maintaining

a similar convergence performance as the original non-trimmed methods.

APPENDIX A

PROOF OF LEMMA 3

To begin with, using the deﬁnition of the projection operation as well as Assumptions 2 and 4, we state the

following result that will be used repeatedly:

(G(ξk)xk))

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

Ek

(cid:20)(cid:13)
(cid:13)G(ξk)T(G(ξk)xk − ΠXξk
(cid:13)
(cid:104)

≤ Ek

≤ L2
G

Ek

Ek

(cid:107)G(ξk)(cid:107)2(cid:105)
(cid:104)

(cid:13)
(cid:13)
(cid:13)G(ξk)xk − ΠXξk
(cid:107)G(ξk)xk − G(ξk)x(cid:63)(cid:107)2(cid:105)

≤ L2

GD2

(G(ξk)xk)

(cid:13)
2
(cid:13)
(cid:13)

(64)

(65)

(a) Starting with deﬁnition of yk from (16), observing that E [ˇgk(x) − ˇgk(x, ξ)] = E [ˇgk−1(x) − ˇgk−1(x, ξ)] = 0,

and proceeding similarly as in (29)-(30), we can write

(cid:104)

(cid:107)yk − ˇgk(xk)(cid:107)2(cid:105)

Ek

= (1 − γk)2 (cid:107)yk−1 − ˇgk−1(xk−1)(cid:107)2

(cid:104)

+ Ek

(cid:107)(ˇgk(xk, ξk) − ˇgk(xk)) +(1 − γk)(cid:0)ˇgk−1(xk−1) − ˇgk−1(xk−1, ξk)(cid:107)2(cid:3)

(66)

Deﬁning

˜Xk := γk(ˇgk(xk, ξk) − ˇgk(xk))

˜Yk := (1 − γk)(ˇgk(xk, ξk) − ˇgk−1(xk−1, ξk)),

and using the inequality Ek(cid:107)˜Xk + ˜Yk − Ek ˜Yk(cid:107)2 ≤ 2Ek(cid:107)˜Xk(cid:107)2 + 2Ek(cid:107)˜Yk(cid:107)2, we obtain

Ek(cid:107)yk − ˇgk(xk)(cid:107)2 ≤ (1 − γk)2 (cid:107)yk−1 − ˇgk−1(xk−1)(cid:107)2 + 2Ek(cid:107)˜Xk(cid:107)2 + 2Ek(cid:107)˜Yk(cid:107)2.

(67)

(68)

(69)

Let Hµ(Gx) := E[hµ(G(ξ)x, Xξ)], so that ∇xHµ(Gx) = E[∇xhµ(G(ξ)x, Xξ)] and Ek(cid:107)˜Xk(cid:107)2 can be bounded as

Ek(cid:107)˜Xk(cid:107)2 = γ2
k

Ek(cid:107)ˇgk(xk, ξk) − ˇgk(xk)(cid:107)2

≤ 2Ek(cid:107)g(xk) − g(xk, ξk)(cid:107)2 + 2Ek

(cid:107)∇xhµk (G(ξk)xk, Xξk ) − ∇xHµk (Gxk)(cid:107)2(cid:105)
(cid:104)

.

(70)

March 21, 2022

DRAFT

We can further bound the last term of (70) using the non-negativity of the variance and from (14) as

Ek

(cid:107)∇xhµk (G(ξk)xk, Xξk ) − ∇xHµk (Gxk)(cid:107)2(cid:105)
(cid:104)
(cid:104)

(cid:107)∇xhµk (G(ξk)xk, Xξk )(cid:107)2(cid:105)
(cid:20)(cid:13)
(cid:13)G(ξk)T(G(ξk)xk − ΠXξk
(cid:13)

(G(ξk)xk))

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

≤ Ek

=

≤

Ek

1
µ2
k
GD2
L2
µ2
k

,

where (72) follows from (65). Substituting, we obtain

Ek(cid:107)˜Xk(cid:107)2 ≤ 2γ2
k

Ek[(cid:107)g(xk)−g(xk, ξk)(cid:107)2]+

2γ2

kL2
GD2
µ2
k

.

Now, taking norm square of ˜Yk deﬁned in (68), dropping the factor (1−γk)2 and introducing ∇xhµk−1(G(ξk)xk, Xξk )
we obtain

Ek(cid:107)˜Yk(cid:107)2 = Ek
(cid:104)

≤ 3Ek

(cid:104)

(cid:107)ˇgk(xk, ξk) − ˇgk−1(xk−1, ξk)(cid:107)2(cid:105)

(cid:107)g(xk, ξk) − g(xk−1, ξk)(cid:107)2(cid:105)

+ 3Bk + 3Ck

where,

Bk := Ek

Ck := Ek

(cid:2)(cid:107)∇xhµk (G(ξk)xk, Xξk ) − ∇xhµk−1(G(ξk)xk, Xξk )(cid:107)2(cid:3)
(cid:2)(cid:107)∇xhµk−1(G(ξk)xk, Xξk ) − ∇xhµk−1 (G(ξk)xk−1, Xξk )(cid:107)2(cid:3)

Here, Bk can be bounded using (65) as

Bk =

≤

(cid:16) 1
µk
(cid:16) 1
µk

− 1

µk−1

− 1

µk−1

(cid:17)2

(cid:17)2

× Ek(cid:107)GT(ξk)(G(ξk)xk − ΠXξk

(G(ξk)xk))(cid:107)2

L2

GD2.

Likewise, Ck can be bounded using (14) as:

Ck =

≤

1
µ2

k−1
2
µ2

k−1

(cid:20)
(cid:107)GT(ξk)G(ξk)(xk − xk−1) + GT(ξk)

(cid:16)

Ek

ΠXξk

(G(ξk)xk−1) − ΠXξk

(cid:17)

(G(ξk)xk)

(cid:21)

(cid:107)2

(cid:20)

Ek

(cid:13)GT(ξk)G(ξk)(xk − xk−1)(cid:13)
(cid:13)
2
(cid:13)

+

(cid:13)
(cid:13)GT(ξk)
(cid:13)

(cid:16)

ΠXξk

(G(ξk)xk−1) − ΠXξk

(G(ξk)xk)

2 (cid:21)

(cid:17)(cid:13)
(cid:13)
(cid:13)

Here, the last term can be bounded using the non-expansiveness property of the projection operator as

(cid:20)(cid:13)
(cid:13)GT(ξk)
(cid:13)

(cid:16)

Ek

ΠXξk

(G(ξk)xk−1) − ΠXξk

(G(ξk)xk)

2(cid:21)

(cid:17)(cid:13)
(cid:13)
(cid:13)

≤ E (cid:107)G(ξk)(cid:107)2 Ek

(cid:13)
(cid:13)
(cid:13)ΠXξk

(G(ξk)xk−1) − ΠXξk

(G(ξk)xk)

(cid:13)
2
(cid:13)
(cid:13)

≤ L2
G

Ek(cid:107)G(ξk)(xk−1 − xk)(cid:107)2

Substituting and simplifying, we obtain

Ck ≤

4L2
G
µ2

k−1

Ek (cid:107)G(ξk)(xk−1 − xk)(cid:107)2 ≤

GD2

4η2

k−1L2
µ2

k−1

26

(71)

(72)

(73)

(74)

(75)

(76)

(77)

(78)

(79)

(80)

(81)

March 21, 2022

DRAFT

where we have used the update equation and Assumption 2. Thus, we have
(cid:18)(cid:16) 1

Ek(cid:107)˜Yk(cid:107)2 ≤ 3Ek(cid:107)g(xk, ξk) − g(xk−1, ξk)(cid:107)2 + 3L2

GD2

µk

− 1

µk−1

(cid:17)2

+

From (33) and (34) for SFO oracle, we have

4η2
µ2

k−1

k−1

(cid:107)g(xk)−g(xk, ξk)(cid:107)2(cid:105)
(cid:104)
≤ γ2
(cid:107)g(xk, ξk) − g(xk−1, ξk)(cid:107)2(cid:105)
(cid:104)

E

γ2
k

Ek

kσ2,

≤ L2η2

k−1D2

Likewise, for SZO oracle, from (35) and (36), we have

(cid:107)g(xk) − g(xk, ξk)(cid:107)2(cid:105)
(cid:104)
(cid:107)g(xk−1, ξk) − g(xk, ξk)(cid:107)2(cid:105)
(cid:104)

E

γ2
k

Ek

≤ 3γ2

kσ2 + 6mL2ρ2
k,

≤ 3mL2ρ2

k + 3mL2ρ2

k−1 + 3η2

k−1L2D2

Using bounds from (83)-(86), the results for both SFO and SZO cases can be uniﬁed as

(cid:20)(cid:13)
˜Xk + ˜Yk − Ek
(cid:13)
(cid:13)

(cid:104)˜Yk

2(cid:21)

(cid:105)(cid:13)
(cid:13)
(cid:13)

Ek

≤ 12γ2

kσ2 + 60mL2ρ2

k−1 + 18η2

k−1L2D2

+ 2L2

GD2

(cid:18)

2γ2
k
µ2
k

+

k−1

12η2
µ2

k−1

+ 3

(cid:16) 1
µk

− 1

µk−1

(cid:17)2(cid:19)

(cid:19)

.

27

(82)

(83)

(84)

(85)

(86)

(87)

(88)

where recall our convention that ρk = 0 for SFO case. Substituting (87) into (69), we obtain the desired expression.
(b) Setting γk = 1

m(k+1) , and ηk = 2
D√

k+1 in (48), we obtain

k , µk =

µc

(k+1)1/4 , ρk ≤
(cid:107)yk − ˇgk(xk)(cid:107)2(cid:105)

(cid:104)

Ek

(cid:18)

≤

1 −

(cid:19)2

1
k

(cid:107)yk−1 − ˇgk−1(xk−1)(cid:107)2

+

12(σ2 + 11L2D2)
k2

+

√

(4

2 + 3
8 + 96)L2
ck3/2
µ2

GD2

(89)

where we have used the fact that (k+1)1/2
that k3/2 ≤ k2 and using Lemma 6 with a = 3/2 and A = 12(σ2 + 11L2D2) + 103L2

= (k+1)1/4−k1/4
µc

k3/2 and 1
µk

− 1

µk−1

≤

k2

2

≤ 1/4

µck(3/4) . Now, using the fact
GD2µ−2
, we obtain
c

√

Ek (cid:107)yk − ˇgk(xk)(cid:107)2 ≤

48(σ2 +11L2D2 +9L2

Gµ−2

c D2)

k1/2

,

(90)

For SFO case, we get the desired bound simply setting ˇgk(xk) = ∇ ˆFµk (xk) in (90). For SZO case, we start
, introduce ∇ ˜Fµk (xk) := E[ ˜∇f (xk, ξ) + ∇xhµk (G(ξ)xk, Xξ)], and obtain the bound

(cid:20)(cid:13)
(cid:13)
(cid:13)yk − ∇ ˆFµk (xk)
(cid:13)
(cid:13)
(cid:13)

2(cid:21)

with E
by setting ˇgk(xk) = ˜∇f (xk) in (90), to yield

E(cid:107)∇ ˆFµk (xk) − yk(cid:107)2 ≤ 2E(cid:107)∇ ˆFµk (xk) − ∇ ˜Fµk (xk)(cid:107)2 + 2E(cid:107)∇ ˜Fµk (xk) − yk(cid:107)2

= 2E(cid:107)∇f (xk) − ˜∇f (xk)(cid:107)2 + 2E(cid:107)∇ ˜Fµk (xk) − yk(cid:107)2
48(σ2 + 11L2D2 + 9L2

Gµ−2

c D2)

(cid:21)

(cid:20)
mρ2

kL2 +

≤ 2

96(σ2 + 12L2D2 + 9L2

≤

k1/2

k1/2
c D2)

Gµ−2

,

(91)

where we have used (25) and the inequality k1/2 ≤ k2. Since, the bounds for the SFO (90) and SZO (91) cases

differ only in constant factors, we will use (91) as a uniﬁed bound for both the cases.

March 21, 2022

DRAFT

28

REFERENCES

[1] A. Shapiro, D. Dentcheva, and A. Ruszczy´nski, Lectures on stochastic programming: modeling and theory. SIAM, 2014.

[2] A. Ahmed, B. Recht, and J. Romberg, “Blind deconvolution using convex programming,” IEEE Transactions on Information Theory,

vol. 60, no. 3, pp. 1711–1732, 2013.

[3] A. R. Conn, K. Scheinberg, and L. N. Vicente, Introduction to derivative-free optimization. SIAM, 2009.

[4] P.-Y. Chen, H. Zhang, Y. Sharma, J. Yi, and C.-J. Hsieh, “Zoo: Zeroth order optimization based black-box attacks to deep neural networks

without training substitute models,” in Proceedings of the 10th ACM Workshop on Artiﬁcial Intelligence and Security, 2017, pp. 15–26.

[5] A. Nemirovski, A. Juditsky, G. Lan, and A. Shapiro, “Robust stochastic approximation approach to stochastic programming,” SIAM Journal

on optimization, vol. 19, no. 4, pp. 1574–1609, 2009.

[6] Q. Tran-Dinh, O. Fercoq, and V. Cevher, “A smooth primal-dual optimization framework for nonsmooth composite convex minimization,”

SIAM Journal on Optimization, vol. 28, no. 1, pp. 96–134, 2018.

[7] A. Yurtsever, O. Fercoq, and V. Cevher, “A conditional-gradient-based augmented lagrangian framework,” in International Conference on

Machine Learning. PMLR, 2019, pp. 7272–7281.

[8] O. Fercoq, A. Alacaoglu, I. Necoara, and V. Cevher, “Almost surely constrained convex optimization,” arXiv preprint arXiv:1902.00126,

2019.

[9] P. Garrigues and L. Ghaoui, “An homotopy algorithm for the lasso with online observations,” Advances in neural information processing

systems, vol. 21, pp. 489–496, 2008.

[10] J. Peng and Y. Wei, “Approximating k-means-type clustering via semideﬁnite programming,” SIAM journal on optimization, vol. 18, no. 1,

pp. 186–205, 2007.

[11] S. Arora, S. Rao, and U. Vazirani, “Expander ﬂows, geometric embeddings and graph partitioning,” Journal of the ACM (JACM), vol. 56,

no. 2, pp. 1–37, 2009.

[12] Q. Huang, Y. Chen, and L. Guibas, “Scalable semideﬁnite relaxation for maximum a posterior estimation,” in International Conference

on Machine Learning, 2014, pp. 64–72.

[13] Q. Zhao, S. E. Karisch, F. Rendl, and H. Wolkowicz, “Semideﬁnite programming relaxations for the quadratic assignment problem,”

Journal of Combinatorial Optimization, vol. 2, no. 1, pp. 71–109, 1998.

[14] M. X. Goemans and D. P. Williamson, “Improved approximation algorithms for maximum cut and satisﬁability problems using semideﬁnite

programming,” Journal of the ACM (JACM), vol. 42, no. 6, pp. 1115–1145, 1995.

[15] A. Raghunathan, J. Steinhardt, and P. S. Liang, “Semideﬁnite relaxations for certifying robustness to adversarial examples,” Advances in

Neural Information Processing Systems, vol. 31, 2018.

[16] B. Kulis, A. C. Surendran, and J. C. Platt, “Fast low-rank semideﬁnite programming for embedding and clustering,” in Artiﬁcial Intelligence

and Statistics. PMLR, 2007, pp. 235–242.

[17] F. Latorre, P. Rolland, and V. Cevher, “Lipschitz constant estimation of neural networks via sparse polynomial optimization,” arXiv preprint

arXiv:2004.08688, 2020.

[18] F. Locatello, A. Yurtsever, O. Fercoq, and V. Cevher, “Stochastic Frank-Wolfe for composite convex minimization,” in Advances in Neural

Information Processing Systems, 2019, pp. 14 269–14 279.

[19] M.-L. Vladarean, A. Alacaoglu, Y.-P. Hsieh, and V. Cevher, “Conditional gradient methods for stochastically constrained convex

minimization,” arXiv preprint arXiv:2007.03795, 2020.

[20] M. Jaggi, “Revisiting Frank-Wolfe: Projection-free sparse convex optimization,” in Proceedings of the 30th international conference on

machine learning, no. CONF, 2013, pp. 427–435.

[21] Y. Nesterov, “Smooth minimization of non-smooth functions,” Mathematical programming, vol. 103, no. 1, pp. 127–152, 2005.

[22] M. Zhang, Z. Shen, A. Mokhtari, H. Hassani, and A. Karbasi, “One sample stochastic frank-wolfe,” in International Conference on Artiﬁcial

Intelligence and Statistics. PMLR, 2020, pp. 4012–4023.

[23] J. Xie, Z. Shen, C. Zhang, B. Wang, and H. Qian, “Efﬁcient projection-free online methods with stochastic recursive gradient.” in AAAI,

2020, pp. 6446–6453.

[24] G. Braun, S. Pokutta, and D. Zink, “Lazifying conditional gradient algorithms,” in International conference on machine learning. PMLR,

2017, pp. 566–575.

[25] T. Kerdreux, F. Pedregosa, and A. d’Aspremont, “Frank-wolfe with subsampling oracle,” in International Conference on Machine Learning.

PMLR, 2018, pp. 2591–2600.

March 21, 2022

DRAFT

29

[26] Z. Mhammedi, “Efﬁcient projection-free online convex optimization with membership oracle,” arXiv preprint arXiv:2111.05818, 2021.

[27] E. Hazan and S. Kale, “Projection-free online learning,” arXiv preprint arXiv:1206.4657, 2012.

[28] E. Hazan and H. Luo, “Variance-reduced and projection-free stochastic optimization,” in International Conference on Machine Learning.

PMLR, 2016, pp. 1263–1271.

[29] Z. Shen, C. Fang, P. Zhao, J. Huang, and H. Qian, “Complexities in projection-free stochastic non-convex minimization,” in The 22nd

International Conference on Artiﬁcial Intelligence and Statistics. PMLR, 2019, pp. 2868–2876.

[30] A. Defazio and L. Bottou, “On the ineffectiveness of variance reduced optimization for deep learning,” arXiv preprint arXiv:1812.04529,

2018.

[31] Z. Akhtar and K. Rajawat, “Momentum based projection free stochastic optimization under afﬁne constraints,” in 2021 American Control

Conference (ACC).

IEEE, 2021, pp. 2619–2624.

[32] A. Mokhtari, H. Hassani, and A. Karbasi, “Stochastic conditional gradient methods: From convex minimization to submodular

maximization,” Journal of Machine Learning Research, vol. 21, no. 105, pp. 1–49, 2020.

[33] Z. Akhtar, A. S. Bedi, and K. Rajawat, “Conservative stochastic optimization with expectation constraints,” IEEE Transactions on Signal

Processing, vol. 69, pp. 3190–3205, 2021.

[34] G. Lan and Y. Zhou, “Conditional gradient sliding for convex optimization,” SIAM Journal on Optimization, vol. 26, no. 2, pp. 1379–1409,

2016.

[35] G. Lan, S. Pokutta, Y. Zhou, and D. Zink, “Conditional accelerated lazy stochastic gradient descent,” arXiv preprint arXiv:1703.05840,

2017.

[36] H. Lu and R. M. Freund, “Generalized stochastic Frank–Wolfe algorithm with stochastic “substitute” gradient for structured convex

optimization,” Mathematical Programming, pp. 1–33, 2020.

[37] A. Yurtsever, O. Fercoq, F. Locatello, and V. Cevher, “A conditional gradient framework for composite convex minimization with

applications to semideﬁnite programming,” arXiv preprint arXiv:1804.08544, 2018.

[38] A. K. Sahu, M. Zaheer, and S. Kar, “Towards gradient free and projection free stochastic optimization,” in The 22nd International

Conference on Artiﬁcial Intelligence and Statistics. PMLR, 2019, pp. 3468–3477.

[39] A. Patrascu and I. Necoara, “Nonasymptotic convergence of stochastic proximal point methods for constrained convex optimization,” The

Journal of Machine Learning Research, vol. 18, no. 1, pp. 7204–7245, 2017.

[40] M. Wang, Y. Chen, J. Liu, and Y. Gu, “Random multi-constraint projection: Stochastic gradient methods for convex optimization with

many constraints,” arXiv preprint arXiv:1511.03760, 2015.

[41] S. J. Reddi, S. Sra, B. P´oczos, and A. Smola, “Stochastic Frank-Wolfe methods for nonconvex optimization,” in 2016 54th Annual Allerton

Conference on Communication, Control, and Computing (Allerton).

IEEE, 2016, pp. 1244–1251.

[42] A. Yurtsever, S. Sra, and V. Cevher, “Conditional gradient methods via stochastic path-integrated differential estimator,” in International

Conference on Machine Learning. PMLR, 2019, pp. 7282–7291.

[43] B. Li, M. Couti˜no, G. B. Giannakis, and G. Leus, “A momentum-guided frank-wolfe algorithm,” IEEE Transactions on Signal Processing,

vol. 69, pp. 3597–3611, 2021.

[44] K. Balasubramanian and S. Ghadimi, “Zeroth-order (non)-convex stochastic optimization via conditional gradient and gradient updates,”

in Advances in Neural Information Processing Systems, 2018, pp. 3455–3464.

[45] F. Huang, L. Tao, and S. Chen, “Accelerated stochastic gradient-free and projection-free methods,” in International Conference on Machine

Learning. PMLR, 2020, pp. 4519–4530.

[46] Y. Nesterov and V. Spokoiny, “Random gradient-free minimization of convex functions,” Foundations of Computational Mathematics,

vol. 17, no. 2, pp. 527–566, 2017.

[47] E. Frandi, R. ˜Nanculef, and J. Suykens, “Complexity issues and randomization strategies in frank-wolfe algorithms for machine learning,”

arXiv preprint arXiv:1410.4062, 2014.

[48] W. Li, Z. Wu, T. Chen, L. Li, and Q. Ling, “Communication-censored distributed stochastic gradient descent,” IEEE Transactions on

Neural Networks and Learning Systems, 2021.

[49] S. Liu, B. Kailkhura, P.-Y. Chen, P. Ting, S. Chang, and L. Amini, “Zeroth-order stochastic variance reduction for nonconvex optimization,”

Advances in Neural Information Processing Systems, vol. 31, pp. 3727–3737, 2018.

[50] K. Ji, Z. Wang, Y. Zhou, and Y. Liang, “Improved zeroth-order variance reduced algorithms and analysis for nonconvex optimization,”

arXiv preprint arXiv:1910.12166, 2019.

[51] A. Beck, First-order methods in optimization. SIAM, 2017.

March 21, 2022

DRAFT

30

[52] A. Cutkosky and F. Orabona, “Momentum-based variance reduction in non-convex sgd,” in Advances in Neural Information Processing

Systems, 2019, pp. 15 236–15 245.

[53] T. Kerdreux, A. d’Aspremont, and S. Pokutta, “Projection-free optimization on uniformly convex sets,” in International Conference on

Artiﬁcial Intelligence and Statistics. PMLR, 2021, pp. 19–27.

[54] D. Garber and E. Hazan, “Faster rates for the frank-wolfe method over strongly-convex sets,” in International Conference on Machine

Learning. PMLR, 2015, pp. 541–549.

[55] H. H. Bauschke, P. L. Combettes et al., Convex analysis and monotone operator theory in Hilbert spaces. Springer, 2011, vol. 408.

[56] E. Richard, P.-A. Savalle, and N. Vayatis, “Estimation of simultaneously sparse and low rank matrices,” arXiv preprint arXiv:1206.6474,

2012.

[57] Q. Zhao, D. Meng, Z. Xu, W. Zuo, and L. Zhang, “Robust principal component analysis with complex noise,” in International conference

on machine learning, 2014, pp. 55–63.

[58] S. Deshmukh and A. Dubey, “Improved covariance matrix estimation with an application in portfolio optimization,” IEEE Signal Processing

Letters, 2020.

[59] D. G. Mixon, S. Villar, and R. Ward, “Clustering subgaussian mixtures by semideﬁnite programming,” arXiv preprint arXiv:1602.06612,

2016.

[60] Y. LeCun, C. Cortes, and C. Burges, “Mnist handwritten digit database. 2010,” URL http://yann. lecun. com/exdb/mnist, vol. 7, p. 23,

2010.

[61] V. Chatziafratis, R. Niazadeh, and M. Charikar, “Hierarchical clustering with structural constraints,” arXiv preprint arXiv:1805.09476,

2018.

[62] P. Bonsma, H. Broersma, V. Patel, and A. Pyatkin, “The complexity of ﬁnding uniform sparsest cuts in various graph classes,” Journal of

discrete algorithms, vol. 14, pp. 136–149, 2012.

[63] T. Leighton and S. Rao, “Multicommodity max-ﬂow min-cut theorems and their use in designing approximation algorithms,” Journal of

the ACM (JACM), vol. 46, no. 6, pp. 787–832, 1999.

[64] D. B. Shmoys, “Cut problems and their application to divide-and-conquer,” Approximation algorithms for NP-hard problems, pp. 192–235,

1997.

[65] R. A. Rossi and N. K. Ahmed, “The network data repository with interactive graph analytics and visualization,” in AAAI, 2015. [Online].

Available: http://networkrepository.com

March 21, 2022

DRAFT

31

APPENDIX B

SUPPLEMENTARY MATERIAL

Before proceeding we replicate some technical results as following corollaries that are borrowed from related

works and will be used in proving our theorems. We also state a preliminary lemma 6 that will apply to most of

the proofs.

Corollary 1 (Lemma 10 in [6]): Suppose hµ(x) be the smooth approximation of a non-smooth convex function h
and λ(cid:63)

µ(·) be the solution of the dual problem, then following inequalities holds true

h(x1) ≥ hµ(x2) + (cid:104)∇hµ(x2), x1 − x2(cid:105) +

µ
2

(cid:107)λ(cid:63)

µ(x2)(cid:107)2,

hµ1(x) ≤ hµ2 (x) +

µ2 − µ1
2

(cid:107)λ(cid:63)
µ1

(x)(cid:107)2.

(92)

(93)

Corollary 2 (Theorem 2(a) in [18]): Let (x(cid:63), λ(cid:63)) be a saddle point of L(x, r, λ(cid:63)) = f (x) + (cid:104)λ(cid:63), Gx − r(cid:105), then

from Lagrange saddle point theory following bound holds for all x ∈ C and r ∈ X

E[f (xk)] − f (x(cid:63)) ≥ −E[min
r∈X

(cid:107)λ(cid:63)(cid:107) (cid:107)Gx − r(cid:107)]

= − (cid:107)λ(cid:63)(cid:107) E[DX (Gxk)].

Corollary 3 (Lemma B.1 in [19]): Consider problem P + and its Lagrangian formulation as
(cid:90)

L(x, λ) := f (x) +

(cid:104)G(ξ)x, λ(ξ)(cid:105) − sup

(cid:104)y, λ(ξ)(cid:105)α(dξ),

here α denotes the probability measure of the random variable ξ. Let (x(cid:63), λ(cid:63)) be a saddle point of L, then

y∈X (ξ)

(cid:90)

D2

X (ξ)(G(ξ)x)α(dξ) ≤ 4µ2(cid:107)λ(cid:63)(cid:107)2 +4µ[Fµ(x)−f (x(cid:63))].

Lemma 6 Let {ψk}t

k=1 be a sequence of numbers satisfying either of the following recursions:

(cid:18)

ψk ≤

1 −

(cid:19)2

1
k

ψk−1 +

A
ka

(cid:18)

ψk ≤

1 −

(cid:19)

2
k + 1

ψk−1 +

A
ka

for some A > 0 and 1 ≤ a ≤ 2. Then it holds that ψk ≤ 4A/ka−1 for all t ≥ 1.

Proof of (96): Multiplying both sides of (96) by k2, we obtain

for all k ≥ 1. Carrying out telescopic sum over k = 1, . . . , K, we obtain

k2ψk ≤ (k − 1)2ψk−1 + Ak2−a

ψK ≤

A
K 2

K
(cid:88)

k=1

k2−a ≤ A

(K + 1)3−a
(3 − a)K 2 ≤

4A
K a−1

where we have used the inequality (cid:80)K

k=1 kn ≤ (K+1)n+1−1

(n+1)

for n ≥ 0.

(94)

(95)

(96)

(97)

(98)

(99)

March 21, 2022

DRAFT

Proof of (97): Multiplying both sides of (97) by k(k + 1), we obtain

k(k + 1)ψk ≤ (k − 1)kψk−1 + Ak1−a(k + 1)

≤ (k − 1)kψk−1 + 2Ak2−a

for all k ≥ 1. Carrying out telescopic sum over k = 1, . . . , K, we obtain

ψK ≤

2A
K(K + 1)

K
(cid:88)

k=1

k2−a ≤ 2A

(K + 1)2−a
(3 − a)K

≤

4A
K a−1

32

(100)

(101)

(102)

where we have used the inequality (cid:80)K

k=1 kn ≤ (K+1)n+1−1

(n+1)

for n ≥ 0.

A. Proof of Lemma 2

APPENDIX C

(a) Since hµ is 1/µ-smooth by construction and f (x) is L-smooth from Assumption 1, it follows from Assumption

4 that Fµ(x) is

(cid:16)

L + LG
µ

(cid:17)

in (11) to obtain

-smooth. We can therefore write the quadratic upper bound on Fµk and use the update

Fµk (xk+1) ≤ Fµk (xk) + ηk(cid:104)∇Fµk (xk), zk − xk(cid:105) +

≤ Fµk (xk) + ηk(cid:104)∇Fµk (xk), zk − xk(cid:105) +

(cid:18)

(cid:18)

L +

L +

η2
k
2
η2
k
2

(cid:19)

(cid:19)

LG
µk
LG
µk

(cid:107)zk − xk(cid:107)2

D2,

(103)

where we have used the compactness assumption on C (Assumption 2). Recall from (12) that ∇Fµk (xk) = ∇f (xk)+
GT∇hµk (Gx, X ), which allows us to write the second term on the right of (103) as

(cid:104)∇Fµk (xk), zk − xk(cid:105) = (cid:104)∇f (xk), zk − xk(cid:105) + (cid:104)GT∇hµk (Gxk, X ), zk − xk(cid:105)

= (cid:104)∇f (xk) − yk, zk − xk(cid:105) + (cid:104)yk + GT∇hµk (Gxk, X ), zk − xk(cid:105).

(104)

From the deﬁnition of zk in (10), we therefore have that

(cid:104)∇Fµk (xk), zk − xk(cid:105) ≤ (cid:104)∇f (xk) − yk, zk − xk(cid:105) + (cid:104)yk + GT∇hµk (Gxk, X ), x(cid:63) − xk(cid:105).

(105)

Adding and subtracting (cid:104)∇f (xk), x(cid:63) − xk(cid:105), and using the convexity of f , we obtain

(cid:104)∇Fµk (xk), zk − xk(cid:105) ≤ (cid:104)∇f (xk) − yk, zk − x(cid:63)(cid:105) + (cid:104)∇f (xk), x(cid:63) − xk(cid:105)

+ (cid:104)GT∇hµk (Gxk, X ), x(cid:63) − xk(cid:105)

≤ (cid:107)∇f (xk) − yk(cid:107)(cid:107)zk − x(cid:63)(cid:107) + f (x(cid:63)) − f (xk)

+ (cid:104)GT∇hµk (Gxk, X ), x(cid:63) − xk(cid:105)

≤ (cid:107)∇f (xk) − yk(cid:107)D + f (x(cid:63)) − f (xk)

+ (cid:104)GT∇hµk (Gxk, X ), x(cid:63) − xk(cid:105),

(106)

(107)

(108)

where we have used the Cauchy-Schwartz inequality on the ﬁrst term in (106) and then the compactness assumption

on C.

March 21, 2022

DRAFT

Next, we rewrite (92) in context of our problem as

1X (Gx(cid:63)) ≥ hµk (Gxk, X ) + (cid:104)∇hµk (Gxk, X ), Gx(cid:63) − Gxk(cid:105) +

µk
2

(cid:107)λ(cid:63)
µk

(Gxk)(cid:107)2

implying that

(cid:104)GT∇hµk (xk, X ), x(cid:63) − xk(cid:105) = (cid:104)∇hµk (xk, X ), Gx(cid:63) − Gxk(cid:105)

≤ 1X (Gx(cid:63)) − hµk (Gxk, X ) −

µk
2

(cid:107)λ(cid:63)
µk

(Gxk)(cid:107)2.

Using (110) in (108) we therefore obtain

(cid:104)∇Fµk (xk), zk − xk(cid:105) ≤ (cid:107)∇f (xk) − yk(cid:107)D + f (x(cid:63)) − f (xk) + 1X (Gx(cid:63))

− hµk (Gxk, X ) −

µk
2

(cid:107)λ(cid:63)
µk

(Gxk)(cid:107)2.

Also, rewriting (93) in context of our problem we get

hµk (Gxk, X ) ≤ hµk−1(Gxk, X ) +

µk−1 − µk
2

(cid:107)λ(cid:63)
µk

(Gxk)(cid:107)2.

Hence, we can write

Fµk (xk) := E[f (xk, ξ)] + hµk (Gxk, X ) = f (xk) + hµk (Gxk, X )

≤ f (xk) + hµk−1 (Gxk, X ) +

µk−1 − µk
2

(cid:107)λ(cid:63)
µk

(Gxk)(cid:107)2

= Fµk−1 (xk) +

µk−1 − µk
2

(cid:107)λ(cid:63)
µk

(Gxk)(cid:107)2.

33

(109)

(110)

(111)

(112)

Substituting the bounds obtained in (111) and (112) into (103) and subtracting f (x(cid:63)) from both sides, we obtain

Fµk (xk+1) − f (x(cid:63)) ≤ (1 − ηk) (cid:0)Fµk−1(xk) − f (x(cid:63))(cid:1)
(cid:18)

(cid:19)

+

η2
k
2

L +

LG
µk

D2 + ηk(cid:107)∇f (xk) − yk(cid:107)D

+

1
2

((1 − ηk)µk−1 − µk) (cid:107)λ(cid:63)
µk

(Gxk)(cid:107)2.

(113)

here we used the fact that 1X (Gx(cid:63)) = 0. Now, since we have assumed that µk ≥ µk−1(1 − ηk), the last term in

(113) is non-positive and can be dropped, yielding the desired result.
(cid:114)
(b) Taking expectation in (44) and using the inequality E [(cid:107)X(cid:107)] ≤

E

(cid:104)

(cid:107)X(cid:107)2(cid:105)

, we obtain

E [Fµk (xk+1) − f (x(cid:63))] ≤ (1 − ηk)E (cid:2)Fµk−1(xk) − f (x(cid:63))(cid:3)
(cid:18)
η2
(cid:107)∇f (xk) − yk(cid:107)2(cid:105)
(cid:104)
k
2

D2 + ηkD

L +

(cid:114)

+

(cid:19)

E

LG
µk

Substituting the result of Lemma 1 and that of the various parameters, we obtain

E [Fµk (xk+1) − f (x(cid:63))] ≤ (1 −

2
k + 1
(cid:32)

)E (cid:2)Fµk−1(xk) − f (x(cid:63))(cid:3)
(cid:33)

√

1
(k + 1)2

L +

k

LG
µc

D2 +

8D
k + 1

(cid:114)

3σ2 + 25L2D2
k

+

March 21, 2022

(114)

(115)

DRAFT

34

Note that for this choice of parameters,

k ≥ k−1
satisﬁed. The bound on the right can therefore be simpliﬁed as

µk
µk−1

=

(cid:113) k−1

E[Fµk (xk+1)− f (x(cid:63))] ≤ (1 −

2
k + 1

)E (cid:2)Fµk−1(xk)− f (x(cid:63))(cid:3)+

Finally, application of Lemma 6 yields the required result.

B. Proof of Theorem 1:

(a) The bound on the optimality gap follows directly from Lemma 2:

k = 1 − ηk, so the condition required for (27) is

√

8

3σD+(41L+LGµ−1
k3/2

c )D2

(116)

E[f (xk+1)] − f (x(cid:63)) ≤ E[f (xk+1)] − f (x(cid:63)) +

X (Gxk+1)]

1
2µk
8

E[D2
√

= E[Fµk (xk+1)] − f (x(cid:63)) ≤

3σD + (41L + LGµ−1
√
k

c )D2

.

(117)

(b) Since xk+1 ∈ C, it follows from corollary 2 that

E[f (xk+1)] − f (x(cid:63)) ≥ − (cid:107)λ(cid:63)(cid:107) E[DX (Gxk+1)].

Substituting (118) into (117) and using the Cauchy-Schwarz inequality, we obtain

− (cid:107)λ(cid:63)(cid:107) E[DX (Gxk+1)] +

1
2µk

(E[DX (Gxk+1)])2 ≤ − (cid:107)λ(cid:63)(cid:107) E[DX (Gxk+1)] +
√

8

≤

3σD + (41L + LGµ−1
√
k

E[D2

X (Gxk+1)]

(118)

(119)

1
2µk
c )D2

which is a quadratic inequality in E [DX (Gxk+1)], and can be solved to yield the required result:

E[DX (Gxk+1)] ≤

≤

1
√
k
1
√
k

(cid:18)

2µc (cid:107)λ(cid:63)(cid:107) +

(cid:113)

√

3σDµc + (41Lµc + LG)D2)

(cid:19)

2(8

(cid:16)

2µc (cid:107)λ(cid:63)(cid:107) + 6(cid:112)σDµc + 10D(cid:112)Lµc + 2D

(cid:112)

LG

(cid:17)

C. Proof of Lemma 4

Since, hµ(G(ξ)x, Xξ) is 1/µ-smooth and f (x) is L-smooth (assumption 1), it follows that ˆFµ(x) is

(cid:16)

L + LG
µ

(cid:17)

-

smooth. Starting with the upper bound

ˆFµk (xk+1) ≤ ˆFµk (xk) + ηk(cid:104)∇ ˆFµk (xk), zk − xk(cid:105) +

(cid:18)

L +

η2
k
2

(cid:19)

D2

LG
µk

and following the steps same as (103)-(113), we can obtain the following bound

ˆFµk (xk+1) − f (x∗) ≤ (1 − ηk) ˆFµk−1(xk) − f (x∗)
η2
(cid:13)
LG
(cid:13)∇ ˆFµk (xk) − yk
(cid:13)
µk
2
(cid:18) (1 − ηk)(µk−1 − µk) − ηkµk
2

+ ηkD

||λ(cid:63)
µk

L +

D2

+

+

(cid:19)

(cid:18)

(cid:19)

(cid:13)
(cid:13)
(cid:13)

(G(ξk)xk)||2.

March 21, 2022

(120)

(121)

(122)

DRAFT

Now, setting ηk and µk such that (1 − ηk)(µk−1 − µk) − ηkµk ≤ 0, we get rid of last term of (121). Taking full

35

expectation:

Substituting µk =

E[ ˆFµk (xk+1)] − f (x∗) ≤ (1 − ηk)E[ ˆFµk−1 (xk)] − f (x∗)
η2
k
2

+ ηkD

L +

D2

LG
µk

(cid:113)

+

(cid:18)

(cid:19)

E||∇ ˆFµk (xk) − yk||2.

µc

(k+1)1/4 , ηk = 2

k+1 , and ρk ≤
(cid:18)

D√

m(k+1) :

E[ ˆFµk (xk+1)] − f (x(cid:63)) ≤

1 −

(cid:19)

2
k + 1

E[ ˆFµk−1(xk)] − f (x(cid:63))

+

2
(k + 1)2

(cid:32)

L +

LG(k + 1) 1
µc

4

(cid:33)

D2

Gµ−2

c D2)

(cid:113)

+

(cid:18)

≤

+

96(σ2 + 12L2D2 + 9L2

4

(cid:19)

k 1

2D
(k + 1)
2
k + 1
6σD + 2(35L + 31LGµ−1
k5/4

1 −
√
8

E[ ˆFµk−1(xk)] − f (x(cid:63))

c )D2

(123)

since k5/4 ≤ (k + 1)2. Note that our selection of µk and ηk satisﬁes the assumption µk ≥ µk−1(1 − ηk). Finally,

application of Lemma 6 yields the required result.

D. Proof of Theorem 2:

(a) The bound on the optimality gap follows from Lemma 4:

E[f (xk+1)] − f (x(cid:63)) ≤ E[f (xk+1)] − f (x(cid:63)) +

1
2µk

E[D2

X (ξ)(G(ξ)xk+1)]

= E[ ˆFµk (xk+1)] − f (x(cid:63))

√

8(4

≤

6σD + 35LD2 + 31LGµ−1
k 1

4

c D2)

(b) We use Jensen’s inequality and Corollary 3 to obtain bound on feasibility as

E[DX (ξ)(G(ξ)xk+1)] ≤

(cid:113)E[D2

X (ξ)(G(ξ)xk+1)]

(124)

(125)

(cid:113)

≤

≤

≤

4µ2

k (cid:107)λ(cid:63)(cid:107)2 + 4µkE[ ˆFµk (xk+1) − f (x(cid:63))]

(cid:107)λ(cid:63)(cid:107) +

2µc
(k + 1) 1
2 (cid:0)µc (cid:107)λ(cid:63)(cid:107) + 9

4

√

√

18

σDµc + 34D

√

Lµc + 32D
8 (k) 1
Lµc + 16D

(k + 1) 1
√

LG

√

8

√

LG

(cid:1)

.

σDµc + 17D
k 1

4

March 21, 2022

DRAFT

36

E. Proof of Theorem 3:

(a) Recall from (12) that ∇Fµk (xk) = ∇f (xk) + GT∇hµk (Gx, X ), which allows us to write the second term on

the right of (103) as

(cid:104)∇Fµk (xk), zk − xk(cid:105) = (cid:104)∇f (xk), zk − xk(cid:105) + (cid:104)GT∇hµk (Gxk, X ), zk − xk(cid:105)

(126)

= (cid:104)∇f (xk) − vk, zk − xk(cid:105) + (cid:104)vk, zk − xk(cid:105) + (cid:104)GT∇hµk (Gxk, X ), zk − xk(cid:105)

≤ (cid:104)∇f (xk) − vk, zk − xk(cid:105) + (cid:104)vk, x(cid:63) − xk(cid:105) + (cid:104)GT∇hµk (Gxk, X ), zk − xk(cid:105),

Note that if trimming is not performed at iteration k, then we call the LMO to solve the problem zk = argminz∈C (cid:104)z, vk(cid:105)

while if trimming is done we set vk = vk−1 and zk = zk−1. Suppose that trimming was not performed at iteration

k −1, then we can say that zk = zk−1 = argminz∈C (cid:104)z, vk−1(cid:105) = argminz∈C (cid:104)z, vk(cid:105). The same argument can again

be applied to conclude that zk = argminz∈C (cid:104)z, vk(cid:105) if trimming was not performance at some iteration k0 ≤ k.

We can assume that trimming is not performed at the ﬁrst iteration. Hence, irrespective of whether trimming is

done or not zk is the minimizer of (cid:104)zk, vk(cid:105). Thus, at each iteration we have (cid:104)zk, vk(cid:105) ≤ (cid:104)x(cid:63), vk(cid:105) using which we
obtain (126). Adding and subtracting (cid:104)∇f (xk), x(cid:63) − xk(cid:105), and using the convexity of f , we get

(cid:104)∇Fµk (xk), zk − xk(cid:105) ≤ (cid:104)∇f (xk) − vk, zk − x(cid:63)(cid:105) + (cid:104)∇f (xk), x(cid:63) − xk(cid:105) + (cid:104)GT∇hµk (Gxk, X ), zk − xk(cid:105)

≤ (cid:104)∇f (xk) − vk, zk − x(cid:63)(cid:105) + f (x(cid:63)) − f (xk) + (cid:104)GT∇hµk (Gxk, X ), zk − xk(cid:105)

(127)

Further, adding and subtracting (cid:104)wk, zk − x(cid:63)(cid:105) we get,

(cid:104)∇Fµk (xk), zk − xk(cid:105) ≤ (cid:104)∇f (xk) − vk + wk − wk, zk − x(cid:63)(cid:105) + f (x(cid:63)) − f (xk) + (cid:104)GT∇hµk (Gxk, X ), zk − xk(cid:105)

≤ (cid:104)∇f (xk) − wk, zk − x(cid:63)(cid:105) + (cid:104)wk − vk, zk − x(cid:63)(cid:105)

+ f (x(cid:63)) − f (xk) + (cid:104)GT∇hµk (Gxk, X ), zk − xk(cid:105)

≤ (cid:104)∇f (xk) − yk, zk − x(cid:63)(cid:105) + (cid:104)GT∇hµk (Gxk, X ), x(cid:63) − zk(cid:105)

+ (cid:104)wk − vk, zk − x(cid:63)(cid:105) + f (x(cid:63)) − f (xk)

+ (cid:104)GT∇hµk (Gxk, X ), zk − xk(cid:105)

= (cid:104)∇f (xk) − yk, zk − x(cid:63)(cid:105) + (cid:104)wk − vk, zk − x(cid:63)(cid:105)

+ f (x(cid:63)) − f (xk) + (cid:104)GT∇hµk (Gxk, X ), x(cid:63) − xk(cid:105)

≤ (cid:107)∇f (xk) − yk(cid:107) D + (cid:107)wk − vk(cid:107) D + f (x(cid:63)) − f (xk)

+ (cid:104)GT∇hµk (Gxk, X ), x(cid:63) − xk(cid:105)

≤ (cid:107)∇f (xk) − yk(cid:107) D + τkD + f (x(cid:63)) − f (xk)

+ (cid:104)GT∇hµk (Gxk, X ), x(cid:63) − xk(cid:105)

(128)

(129)

here (128) is obtained using the Cauchy-Schwartz inequality the compactness assumption on C while the last

inequality comes from the use of Lemma 5.

March 21, 2022

DRAFT

Now using (110) in (129) we obtain

(cid:104)∇Fµk (xk), zk − xk(cid:105) ≤ (cid:107)∇f (xk) − yk(cid:107)D + τkD + f (x(cid:63)) − f (xk) + 1X (Gx(cid:63))

− hµk (Gxk, X ) −

µk
2

(cid:107)λ(cid:63)
µk

(Gxk)(cid:107)2.

37

(130)

Substituting the bounds obtained in (130) and (112) into (103) and subtracting f (x(cid:63)) from both sides, we obtain

Fµk (xk+1) − f (x(cid:63)) ≤ (1 − ηk) (cid:0)Fµk−1(xk) − f (x(cid:63))(cid:1) +

(cid:18)

L +

η2
k
2

(cid:19)

D2

LG
µk

+ ηk(cid:107)∇f (xk) − yk(cid:107)D + ηkτkD +

1
2

((1 − ηk)µk−1 − µk) (cid:107)λ(cid:63)
µk

(Gxk)(cid:107)2,

(131)

here we used the fact that 1X (Gx(cid:63)) = 0. Now, since we have assumed that µk ≥ µk−1(1 − ηk), the last term in

(131) is non-positive and can be dropped, yielding

Fµk (xk+1) − f (x(cid:63)) ≤ (1 − ηk) (cid:0)Fµk−1(xk) − f (x(cid:63))(cid:1) +

(cid:18)

L +

η2
k
2

(cid:19)

D2

LG
µk

+ ηk(cid:107)∇f (xk) − yk(cid:107)D + ηkτkD.

Now, taking expectation on (132), we have

E [Fµk (xk+1) − f (x(cid:63))] ≤ (1 − ηk)E (cid:2)Fµk−1(xk) − f (x(cid:63))(cid:3) +

(cid:18)

η2
k
2

L +

(cid:19)

D2

LG
µk

(cid:114)

+ ηkD

E

(cid:104)

(cid:107)∇f (xk) − yk(cid:107)2(cid:105)

+ ηkτkD

Substituting the result of Lemma 1 and that of the various parameters, we obtain

(132)

(133)

E [Fµk (xk+1) − f (x(cid:63))] ≤ (1 −

2
k + 1
(cid:32)

)E (cid:2)Fµk−1(xk) − f (x(cid:63))(cid:3) +
(cid:33)

√

(cid:114)

2τ0D
(k + 1)3/2

+

1
(k + 1)2

L +

k

LG
µc

D2 +

8D
k + 1

3σ2 + 25L2D2
k

(134)

Note that for this choice of parameters,

k ≥ k−1
satisﬁed. The bound on the right can therefore be simpliﬁed as

µk
µk−1

=

(cid:113) k−1

k = 1 − ηk, so the condition required for (27) is

E [Fµk (xk+1) − f (x(cid:63))]

≤ (1 −

2
k + 1

)E (cid:2)Fµk−1(xk) − f (x(cid:63))(cid:3) +

√
8

3σD + (41L + LGµ−1

c )D2 + 2τ0D

k3/2

(135)

(136)

Finally, application of Lemma 6 yields the required result.

The bound on the optimality gap follows from (135):

E[f (xk+1)] − f (x(cid:63)) ≤

√

4(8

3σD + (41L + LGµ−1

c )D2 + 2τ0D)

√

k

.

(137)

For constraint violation, following (119) and using (137) we have
√

1
2µk

(E[DX (Gxk+1)])2 ≤

4(8

3σD + (41L + LGµ−1

c )D2 + 2τ0D)

√

k

− (cid:107)λ(cid:63)(cid:107) E[DX (Gxk+1)] +

March 21, 2022

(138)

DRAFT

38

which is a quadratic inequality in E [DX (Gxk+1)], and can be solved to yield the required result:
3σDµc + (41Lµc + LG)D2 + 2τ0D)(cid:1)1/2(cid:19)

2µc (cid:107)λ(cid:63)(cid:107) + (cid:0)8(8

E[DX (Gxk+1)] ≤

√

(cid:18)

(cid:18)

2µc (cid:107)λ(cid:63)(cid:107) + 11(cid:112)σDµc + 19D(cid:112)Lµc + 3D

(cid:112)

LG + 4

(cid:112)

τ0D

(cid:19)

(139)

≤

1
√
k
1
√
k

(b) Following the steps same as (126)-(133), we can obtain the following bound for MOST-FW+

ˆFµk (xk+1) − f (x∗) ≤ (1 − ηk) ˆFµk−1(xk) − f (x∗) +

(cid:18)

η2
2

D2

L +

(cid:19)

LG
µk

+ ηkD

(cid:13)
(cid:13)∇ ˆFµk (xk) − yk
(cid:13)
(cid:18) (1 − ηk)(µk−1 − µk) − ηkµk
2

(cid:13)
(cid:13)
(cid:13) + ηkτkD
(cid:19)

+

||λ(cid:63)
µk

(G(ξk)xk)||2.

(140)

Now, setting ηk and µk such that (1 − ηk)(µk−1 − µk) − ηkµk ≤ 0, we get rid of last term of (140). Taking full

expectation:

E[ ˆFµk (xk+1)] − f (x∗) ≤ (1 − ηk)E[ ˆFµk−1(xk)] − f (x∗) +

(cid:18)

η2
k
2

D2

L +

(cid:19)

LG
µk

(cid:113)

+ ηkD

E||∇ ˆFµk (xk) − yk||2 + ηkτkD.

(141)

Substituting µk =

µc

(k+1)1/4 , τk =

τ0

(k+1)1/4 , ηk = 2

D√

m(k+1) , we get

E[ ˆFµk (xk+1)] − f (x(cid:63)) ≤

(cid:18)

1 −

E[ ˆFµk−1 (xk)] − f (x(cid:63))

k+1 , and ρk ≤
(cid:19)

2
k + 1

+

2
(k + 1)2

(cid:32)

L +

(cid:33)

LG(k + 1) 1
µc

4

D2 +

2τ0D
(k + 1)5/4

Gµ−2

c D2)

(cid:113)

96(σ2 + 12L2D2 + 9L2

2D
(k + 1)
2
k + 1
6σD + 2(35L + 31LGµ−1

1 −
√
8

k 1

(cid:19)

E[ ˆFµk−1 (xk)] − f (x(cid:63))

4

≤

+

(cid:18)

+

k5/4

c )D2 + 2τ0D

Finally, application of Lemma 6 yields the required results.

For constraint violation, following proof of Theorem 2(b), we obtain the required bound as

E[DX (ξ)(G(ξ)xk+1)]
√

18

+

2µc (cid:107)λ(cid:63)(cid:107)
(k + 1) 1
2 (cid:0)µc (cid:107)λ(cid:63)(cid:107) + 9

4

√

≤

≤

√

(k + 1) 1
√

Lµc + 32D
8 (k) 1
Lµc + 16D

8

√

LG + 6τ0D

√

LG + 3

√

τ0D(cid:1)

.

σDµc + 34D

σDµc + 17D
k 1

4

(142)

(143)

March 21, 2022

DRAFT

