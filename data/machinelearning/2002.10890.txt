0
2
0
2

b
e
F
4
2

]

C
D
.
s
c
[

1
v
0
9
8
0
1
.
2
0
0
2
:
v
i
X
r
a

Combining Learning and Optimization for Transprecision
Computing

Andrea Borghesi, Giuseppe Tagliavini, Michele Lombardi, Luca Benini, Michela Milano
DISI/DEI University of Bologna

Abstract

The growing demands of the worldwide IT infras-
tructure stress the need for reduced power con-
sumption, which is addressed in so-called transpre-
cision computing by improving energy eﬃciency at
the expense of precision. For example, reducing the
number of bits for some ﬂoating-point operations
leads to higher eﬃciency, but also to a non-linear
decrease of the computation accuracy. Depend-
ing on the application, small errors can be toler-
ated, thus allowing to ﬁne-tune the precision of the
computation. Finding the optimal precision for all
variables in respect of an error bound is a complex
task, which is tackled in the literature via heuris-
tics. In this paper, we report on a ﬁrst attempt to
address the problem by combining a Mathematical
Programming (MP) model and a Machine Learn-
ing (ML) model, following the Empirical Model
Learning methodology. The ML model learns the
relation between variables precision and the out-
put error; this information is then embedded in the
MP focused on minimizing the number of bits. An
additional reﬁnement phase is then added to im-
prove the quality of the solution. The experimen-
tal results demonstrate an average speedup of 6.5%
and a 3% increase in solution quality compared
to the state-of-the-art.
In addition, experiments
on a hardware platform capable of mixed-precision
arithmetic (PULPissimo) show the beneﬁts of the
proposed approach, with energy savings of around
40% compared to ﬁxed-precision.

1

Introduction

The energy consumption of computing systems
keeps growing and, consequently, considerable re-
search eﬀorts aim at ﬁnding energy-eﬃcient so-

lutions. A wide class of techniques belongs to
the approximate computing[XMK16] ﬁeld, which
has the goal of decreasing the energy associated
with computation in exchange for a reduction in
the quality of the computation results.
In this
area, a wide range of techniques have been de-
signed, from specialized HW solutions to SW-based
methods[Mit16]. In recent years, a new paradigm
called transprecision computing emerged[MSea18,
opr], where errors are not merely “tolerated” as
byproducts, but rather SW and HW solutions
are designed to provide the desired computation
quality.
Floating-point (FP) operations are a
common target for transprecision techniques, as
their execution and related data transfers repre-
sent a large share of the total energy consump-
tion for many applications involving a wide nu-
merical range[KMBC14, CBB+17]. For instance,
Tagliavini et al. developed FlexFloat [TMea18], an
open-source SW library that allows to specify the
number of bits used for the mantissa and the expo-
nent of an FP variable: using a smaller number of
bits decreases the precision, thus saving energy.

With the possibility to ﬁne-tune the precision of
application variables comes the challenge of ﬁnding
the best setup. This can be framed as an opti-
mization problem, solvable by paradigms such as
Mathematical Programming (MP). The idea is to
search for the minimal number of bits that can
be assigned to each variable without incurring in
a computation error larger than a target. This
method requires to analytically express the non-
linear relation between precision and the compu-
tation error, not a trivial task [MTDM17]. Static
analysis of the eﬀect of variables precision is bur-
densome, and most current approaches have severe
limitations[DK17, CBB+17]. A possible solution is
to learn, rather than directly express, this relation

1

 
 
 
 
 
 
via ML models. We could then embed this knowl-
edge in the optimization model and solve it. This
notion is the core idea of Empirical Model Learning
(EML)[LMB17], a technique to enable combinato-
rial optimization over complex real-world systems.
In this paper, we propose a novel optimiza-
tion method to ﬁnd optimal variable precision in
a transprecision computing setting, based on the
EML methodology. The main contributions of this
work are:

1. A novel approach, called SmartF P T uner,
that combines ML models (predicting the error
associated with variable precision) and an MP
optimization model (ﬁnding the optimal pre-
cision under a constraint on the error) – this
method provides a 55% reduction in solution
time w.r.t. state-of-the-art (SoA) tools;

2. An extended model, called SmartF P T uner+,
that trades oﬀ quickness for quality and merges
the optimization approach with the SoA algo-
rithm, obtaining a 6.5% speedup over the SoA
and a 3% increase in solution quality.

cases

in some

it produces

in execution time that allows

SmartF P T uner enables a signiﬁcant improve-
integrat-
ment
ing this approach into compilation toolchains,
but
solutions of
lower quality and with marginal energy beneﬁts;
SmartF P T uner+ bridges this gap, always provid-
ing good execution time and high-quality solutions
at the same time. Further experiments on PULPis-
simo, an ultra-low-power platform provided with a
mixed-precision HW FP unit, show additional en-
ergy savings around 40%.

The rest of the paper is organized as follows.
Section 2 discusses the related work in FP preci-
sion tuning. Section 3 introduces the proposed ap-
proach. Sections 5 and 4 show experimental results
on precision tuning and energy eﬃciency, respec-
tively. Finally, Section 6 provides conclusion and
future directions.

2 Related Work

Several works in recent years proposed speciﬁc al-
gorithms for FP variable precision tuning [GJea16,
RGNea16, GRG18]. The current SoA is the par-
allel algorithm called fpPrecisionTuning, proposed

2

it is an automated tool
by Ho et al.[HMWA17];
that ﬁne-tunes the number of bits to be assigned
to FP variables while respecting the constraint on
the desired maximum error (for brevity, we refer
to this algorithm as FPTuning in the rest of the
paper). The algorithm searches for the best solu-
tion by running the application to be tuned with
diﬀerent precision levels; a binary search algorithm
explores the precision ranges.

Many works have tried to analyze the error intro-
duced by tuning FP variables[RGNea16, MTea17,
CBB+17]. While promising, these approaches suf-
they mostly work at
fer from some limitations:
the single-expression level and cannot handle whole
benchmarks; those dealing with entire programs
(e.g., [RGNea16]) are orders of magnitudes slower
than methods such FPTuning; they consider only
very few precision levels (e.g., single or double pre-
cision).

Finding optimal parameter values for a given al-
gorithm is a well-known area of research. For ex-
ample, Hutter et al. propose a Sequential Model-
based optimization for general Algorithm Conﬁg-
uration (SMAC, [HHLB11]), an automated proce-
dure for algorithm conﬁguration that explores the
space of parameter settings. The approach relies on
building regression models that describe the rela-
tionship between the target algorithm performance
and the conﬁguration. Our problem can be cast
in the SMAC scheme if we treat the precision of
the variables as the algorithm conﬁgurations to be
explored and the desired target error as a bound
on the algorithm performance. We applied SMAC
to our problem, but the preliminary attempts were
computationally expensive, and the resulting qual-
ity lower than problem-speciﬁc techniques. Costa
et al. developed RBFOpt [CN18], an open-source
library for optimization with black-box functions.
The method iteratively reﬁnes a kernel-based sur-
rogate model of the target function, which is used
to guide the search. Our task can be seen as a
black-box optimization problem by considering the
precision values as the decision variables and the
error as the black-box function.

Empirical Model Learning is a relatively new
research area, with many potential applications
[BLMB12]. We are particularly interested in
two speciﬁc works, namely:
I) Lombardi et al.
[BLMB11], which shows how to embed a neural-
network-based model in a combinatorial problem,

[BLM15], integrating De-
and II) Bonﬁetti et al.
cision Trees (DT) and Random Forest (RF) mod-
els within an MP problem.
In our approach, we
use their contributions to embed the ML models
for predicting the error associated with the vari-
able precision.

3 Proposed Approach

3.1 Problem Description

We consider numerical benchmarks where multi-
ple FP variables take part in the computation of
the result for a given input set, which includes a
structured set of FP values (typically a vector or
a matrix). The number of variables with control-
lable precision in a benchmark B is nB
var; these
variables are the union of the original variables of
the program and the additional variables inserted
for handling the intermediate results. For exam-
ple, if in the original program we have an instruc-
tion V1 = V2 + V3 involving three FP variables,
the set B contains four FP variables, three cor-
responding to the Vi variables plus the temporary
one added to match the precision of the sum be-
fore the assignment (i.e., the precision at which the
operation is performed). Adopting this approach,
each variable is free to contribute to multiple ex-
pressions with diﬀerent precision; practically, HW
arithmetic units require operands of the same type,
and this requirement can be satisﬁed with the ad-
ditional variable.

Our problem consists of assigning a precision
to each FP variable while respecting a constraint
on the computation error. Assigning a precision
means deciding the number of bits for the man-
tissa; the exponent dictates the extension of dy-
namic range and is set according to the actual types
available on the target HW platform. In the rest
of the paper, we refer to the reduction in output
quality due to the adjusted precision (reduction
w.r.t. the output obtained with maximum preci-
sion) as error. If O indicates the result computed
with the ﬁne-tuned precision and OM the one ob-
tained with maximum precision, we compute the
(oi−oM
i )2
i )2 This error met-
error E as: E = maxi
(oM
ric has been adopted by the current SoA algorithm
for precision tuning [HMWA17], and it is one of
a broad set of metrics proposed for transprecision

computing[MSea18, opr].

In this approach, we focus on the single input set
case: we assume a ﬁxed input set to be fed to the
benchmark, and we look for the best solution given
that precise input set. Consequently, the optimal
solution for an input set may not respect the er-
ror constraint for other ones. This requirement is
not an issue for the comparison with the SoA as it
makes the same assumption; our future work aims
at overcoming this limitation.

We selected a subset of the applications stud-
ied in the context of transprecision computing[opr],
chosen because they represent distinct problems
and capture diﬀerent patterns of computation. At
this stage, we do not consider whole applications
(i.e., training a deep neural net) but we focus on
micro-benchmarks that are part of larger applica-
tions (i.e., convolution operations, matrix multipli-
cations, etc.). In particular, we chose the following
benchmarks:

• FWT, Fast Walsh Transform for real vectors,
from the domain of advanced linear algebra
(nF W T

var = 2);

• saxpy, a generalized vector addition with the
form yi = a × xi + yi, basic linear algebra
(nsaxpy

var = 3);

• convolution, convolution of a matrix with a

11 × 11 kernel, ML (nconv

var = 4);

• dwt, Discrete wavelet transform, from signal

processing (ndwt

var = 7);

• correlation, compute correlation matrix of in-

put, data mining (ncorr

var = 7).

• BScholes, estimates the price for a set of op-
tions applying Black-Scholes equation, from
computational ﬁnance (nBScholes

= 15);

var

• Jacobi, Jacobi method to track the evolution
of a 2D heat grid, from scientiﬁc computing
(nJacobi

var = 25).

We stress out that this is a complex problem,
especially the relationship between variable preci-
sion and error. First, the error measure is very
susceptible to diﬀerences between output at max-
imum precision and output at reduced precision,
due to its maximization component.
Secondly,
the precision-error space is non-smooth, non-linear,

3

non-monotonic, and with many peaks (local op-
tima).
In practice, increasing the precision of all
variables does not guarantee to reduce the error.
This eﬀect is due to multiple factors, such as the
impact of rounding operations and the eﬀects of
numerical stability on the control ﬂow[DK17]. For
instance, suppose to increase only the precision of a
variable involved in the condition of an if statement
with a constant FP value. Since the modiﬁcation
does not consider this dependence, a rounding of
the variable (when its value is near the constant)
can trigger diﬀerent code branches and produce un-
expected results on the output.

3.2 Approach Description

We propose an optimization model based on three
components: 1) an MP model, 2) an ML model to
predict the error associated with a precision conﬁg-
uration, and 3) an ML model to classify conﬁgura-
tions in two macro-classes based on the associated
error (i.e., small or large). The two ML models
are embedded in the MP model and represent the
knowledge about the relationship between variables
precision and output error.

The MP model ﬁnds the optimal bit conﬁgu-
ration according to the prediction of the two ML
models; to assess the quality of the conﬁguration,
we execute the benchmark with the corresponding
precision. For this purpose, we employed FlexFloat
[TMea18], that allows us to run a benchmark spec-
ifying the precision of each FP variable. The task
of the ML models is very hard since their goal is
to learn a complex function. Hence, the solution
found by the MP can be unfeasible; namely, it does
not respect the constraint on the target error, due
to the gap between estimated and actual error. To
ﬁx this problem, we introduce a reﬁnement loop:
we test the MP solution by running the benchmark
with the speciﬁed precision; if the solution is un-
feasible, we search for a new one. The wrong one
(the conﬁguration plus its actual error) is added to
the training set of the ML models, which are then
retrained, and cut from the pool of possible solu-
tions of the MP (via a set of constraints). A new
MP model is then built based on the reﬁned ML
models, and a new search begins; this loop goes on
as long as a feasible solution is found. The overall
approach is depicted in Figure 1.

Figure 1: Scheme of the Approach

3.2.1 ML Models

As a ﬁrst step, we created a collection of data sets
containing examples of our benchmarks run at dif-
ferent precision, with the corresponding error val-
ues. The conﬁgurations used in each data set were
obtained via Latin Hypercube Sampling[Ste87], to
explore the design space eﬃciently.

The majority of conﬁgurations lead to small er-
rors, from 10−1 to 10−30, as the output with ﬁne-
tuned variables does not diﬀer drastically from the
target one. However, in a minority of cases lowering
the precision of critical variables generates errors
higher than 100. Formally, the errors roughly fol-
low a long-tailed distribution: this can be observed
by plotting the histogram of the logarithmic error
log(E), as done in Figure 2 for four of our bench-
marks. Benchmarks with fewer variables (such as
saxpy and conv ) have a regular trend, with loga-
rithmic errors always smaller than 0. When the
number of variables increases, for instance with the
corr benchmark (green bars), the majority of errors
still have a logarithm smaller than 0; however, we
can notice two spikes around 10 and after 20. The
situation gets even more complicated with BScholes
(blue bars); in this case a vast number of conﬁgu-
rations correspond to signiﬁcant errors. This kind
of output distribution makes it very diﬃcult for a
single model trained in a classical fashion (e.g., for
minimum Mean Squared Error) to provide consis-
tently good predictions.

4

variables. Together, the two models oﬀer a more
robust prediction, but still not a perfect one.

3.2.2 MP Model

i , ∀i ∈ {1 . . . nB

The MP model assigns a precision value to each
variable in the benchmark, and it minimizes the
total number of bits while respecting the upper
bound on the error. We have an integer decision
variable xB
var}, namely for each vari-
able of the benchmark. The decision variables rep-
resent the number of bits assigned to the variable
xi ∈ {nbitmin . . . nbitmax}. Then we have a contin-
uous variable e that represents the error predicted
by M LR; as speciﬁed earlier, the predicted error
is the negative log of the actual error. Finally, we
have a variable c ∈ {0, 1} which stands for the out-
put of the classiﬁer M LC. The decision variables
xi and the e and c variables are connected by a
set of constraints that encode the M LC and M LR
models, generated via the EML library EMLlib1.

We then add the constraint that forces the solver
not to choose precision values leading to large er-
rors, namely we require c = 0. We bound the (pre-
dicted) error to be below a given target (Etarget,
again expressed as log) and then we minimize the
total number of bits assigned to the variables:

min z =

nB
var(cid:88)

i=1

xi

s.t. e ≥ Etarget
s.t. c = 0

(1)

(2)

(3)

It is important to notice that the constraints
described by Equations (1-2) depend on EML
methodology, as they encapsulate the empirical
knowledge obtained through the ML models. The
actual formulation of these constraints has been
omitted due to space limitations, as embedding an
ML model can require up to hundreds of even thou-
sands of constraints. Nevertheless, the full imple-
mentation of the MP model is available on a public
code repository 2. Generally speaking, the number
of constraints added due to the embedding of ML
models inside MP optimization problems strongly
depends on the number of variables in a bench-
mark, ranging from 38 in the case of FWT to 4235

1https://github.com/emlopt/emllib
2https://github.com/oprecomp/StaticFPTuner

Figure 2: Prediction errors distribution in logarith-
mic scale

Overly large error values are usually due to nu-
issues arising during computation (e.g.,
merical
overﬂow, underﬂow, division by zero, or not-a-
number exceptions). This intuitively means that
the large-error conﬁgurations are likely to follow a
distinct pattern w.r.t. the conﬁgurations having a
lower error value. Accordingly, it makes sense to
split the prediction task into two specialized mod-
els: a classiﬁer M LC to screen large errors, plus
a regressor M LR to evaluate those conﬁgurations
not ruled-out by the classiﬁer. The M LC needs
to make a distinction between normal error and
large error conﬁgurations. We trained this model
by labeling each error in our data set with a class
ﬁeld c, equal to 1 if the error of the example is
greater than a threshold (0.9 in our experiments),
and equal to 0 otherwise. Conﬁgurations classiﬁed
with class c = 1 can be discarded by the training
set of the regression model.

M LR has the task of predicting the output error
for an assignment of precision values. We quickly
noticed that any ML model we tried struggled with
discerning between small and relatively close er-
rors (i.e., 10−20 and 10−15); therefore, we opted
to predict the negative of the logarithm of the er-
ror, thus magnifying the relative diﬀerences and
dramatically improving the ML model accuracy.
M LC and M LR will be used in the MP model with
the aim to, respectively, avoid large-error conﬁgura-
tions and enforce the bound on the precision of the

5

in the case of Jacobi (for an intermediate bench-
mark such as dwt the number of additional con-
straints is equal to 513). We refer to several works
already published[BLMB12, LG13, LG16, BLM15]
and the publicly available code for details on how
ML models can be embedded in MP models as a
set of additional constraints.

An additional set of constraints derives from the
dependency graph of the benchmark, which speci-
ﬁes how the program variables are related. For in-
stance, consider again the expression V1 = V2 + V3;
this corresponds to four precision levels that need to
be decided xi, i ∈ [1, 4]. The ﬁrst three precision-
variables x1, x2, and x3 correspond to the preci-
sion of the actual variables of the expression, re-
spectively V1, V2, and V3; the last variable x4 is
a temporary precision-variable introduced with the
FlexFloat API to handle the (possibly) mismatch-
ing precision of the operands V2 and V3 (FlexFloat
performs a cast from x2 and x3 to the intermedi-
ate precision x4). Each variable is a node in the
dependency graph, and the relations among vari-
ables are directed edges, as depicted in Fig. 3; an
edge entering a node means that the precision of
the source-variable is linked to the precision of the
destination-variable.

Figure 3: Example of Dependency Graph

From this graph, we can extract additional con-
straints for the MP model; these constraints greatly
prune the search space, thus massively reducing the
time needed to ﬁnd a solution. We focus on two
types of relations: I) assignment (e.g., x4 → x1),
and II) expression-induced cast (e.g., x2, x3 → x4),
meaning that the result of an expression involving
multiple variables has to converge to the precision
associated to the additional variable x4.

In assignment expressions, we impose that the
precision of the value to be assigned needs to be
smaller or equal to the precision of the result, in
our example: x4 ≤ x1. Assigning a larger num-
ber of bits to the value to be assigned x4 would

6

be pointless since the ﬁnal precision of the expres-
sion is ultimately dependent on the precision of
the result variable (x1). For relations of the sec-
ond type, we instead bound the additional vari-
able to have a precision equal to the minimum pre-
cision of the operands involved in the expression
(x4 = min(x2, x3)).

4 Experimental Results: Pre-

cision Tuning

In this section we provide the implementation of the
approach for the selected benchmarks, providing an
evaluation of execution time and solution quality.

4.1 ML Models

The current version of the EML library supports
two types of ML models, Decision Trees (DT) and
Neural Networks (NN): We considered both these
techniques in our exploration. The DT and NN
models are implemented, respectively, with scikit-
learn ML Python module and with Keras and Ten-
sorFlow. The NNs are trained with Adam [KB14]
optimizer with standard parameters; the number of
epochs used in the training phase is 100, and the
batch size is 32.

We opted to implement M LR with a NN. After
an empirical evaluation, we realized that both NN
and DT guaranteed similar prediction errors but
with diﬀerent model complexities: with the NN,
few simple layers were needed to reach small errors
while good DTs had to be very deep (between 40
and 50 levels). Since the size of a DT (and its en-
coding) grows exponentially with depth, having so
many layers caused issues when constructing the
M P model; these issues are solved by the more
straightforward structure needed by NN models.
Our NN is composed of one input layer (number
of neurons equal to nB
var), three dense hidden lay-
ers (with size 2 × nB
var, and nB
var, 2 × nB
var), and a
ﬁnal output layer of size 1; all layers employ stan-
dard Rectiﬁed Linear Units (ReLU), except for the
output layer that is linear.

As noted before, we are not interested in
having perfect error prediction accuracy in this
phase, as SmartF P T uner handles wrong predic-
tions through the reﬁnement phase. Creating a
training set needs considerable time, as it requires

the execution of multiple conﬁgurations. Hence,
we use a relatively small training set (1k examples);
empirical experiments revealed that more extensive
training sets marginally increase the prediction ac-
curacy but not enough to justify the increase in the
creation time. The average, normalized error with
this training set size and NN is around 8%, though
it varies signiﬁcantly from benchmarks with fewer
variables (e.g., 4% for saxpy) to more complex ones
(17% for Jacobi ).

For M LC, after a preliminary evaluation, we set-
tled for using DTs since they provide higher accu-
racy than NNs even with modest depth (15 in our ﬁ-
nal implementation); averaging on all benchmarks,
the M LC accuracy for DT and NN implementa-
tions are, respectively, 97% and 82%.

4.1.2 Error Classiﬁcation

For our classiﬁer, after an empirical evaluation we
settled for using a Decision Tree (DT): this proved
to reach better accuracy w.r.t. NNs, even with
modest depth (20 in our ﬁnal
implementation).
Table 1 compares the prediction accuracy of DT
and NN classiﬁers (same topology as the regressor
one) for diﬀerent data set sizes. The DTs models
neatly outperform NNs, strengthening our conjec-
ture that normal errors and large errors indeed fol-
low diﬀerent patterns. Furthermore, increasing the
training set size does not dramatically improve the
performance of the classiﬁer; smaller training sets
(around 1000 examples) can be used with good re-
sults.

4.2 MP Results

4.1.1 Data set size and prediction error

Since generating the data set used for the ML tasks
has non-negligible costs (each benchmark has to be
run with many conﬁgurations), understanding the
impact of the data set size on the prediction error
is crucial. Figure 4 shows the eﬀect of the training
set size on the prediction error, measured as RMSE
(one line for each benchmark). As expected, the er-
ror decreases when the training sets contain more
examples; however, after a certain size, the gains
become marginal (around 4 or 5 thousand exam-
ples).

Figure 4: Data set size impact on RMSE

the

now

examine

solutions

We
found
bySmartF P T uner. All the experiments were
performed using a quad-core processor (Intel i7-
5500U CPU 2.40 GHz) with 16 GB of RAM. The
MP model was solved using IBM ILOG CPLEX
12.8.0, via the Python API.

4.2.1 Comparison with the State-of-the-

Art

We compare our approach with the SoA technique
for our problem, the FPTuning algorithm. FPTun-
ing proceeds by testing several precision conﬁgura-
tions via binary search; the algorithm is highly par-
allelized and leads to solutions which are very close
to the optimal one, but it has a considerable draw-
back, namely it has to run the benchmark multiple
times to ﬁnd a feasible solution (we can see it as a
variant of a generate-and-test method).

We can highlight

two main advantages of
SmartF P T uner. First, it is more ﬂexible com-
pared to a speciﬁc algorithm and more expressive,
as more sophisticated constraints can be enforced.
For instance, we can constrain the precision of the
variables to assume values available on real HW
implementations (typically, the only allowed val-
ues are 16, 32, and 64 bits). Moreover, the MP
can be easily extended for architecture-speciﬁc op-
timization (vectorial instruction sets) and for han-
dling more complex objectives (e.g., minimize the
number of casting operations). Secondly, once the

7

Benchmark

saxpy
convolution
FWT
correlation
dwt
BScholes
Jacobi

NN

Data set sizes

100

500

1k

2k

8k

100

500

DT
Data set sizes
1k

2k

8k

1.000
1.000
0.850
0.750
0.650
0.700
0.750

1.000
1.000
0.860
0.790
0.860
0.600
0.810

1.000
1.000
0.660
0.795
0.930
0.675
0.800

1.000
1.000
0.677
0.825
0.618
0.677
0.800

1.000
1.000
0.980
0.962
0.965
0.827
0.836

1.000
1.000
0.996
0.996
0.991
0.983
0.906

1.000
1.000
0.997
0.998
0.987
0.984
0.916

1.000
1.000
0.996
0.995
0.989
0.981
0.919

1.000
1.000
0.998
0.991
0.992
0.985
0.912

1.000
1.000
0.998
0.996
0.991
0.988
0.918

Average

0.740

0.784

0.772

0.719

0.914

0.974

0.976

0.976

0.976

0.978

Table 1: M LC Accuracy Results: DT VS NN

ML models have been trained and embedded, the
MP model can be used multiple times, relying only
on the solver without the need to perform addi-
tional benchmark runs. For example, this can be
exploited to characterize the error/precision Pareto
front, whereas FPTuning would need to start ab
initio every time. Considering the current lim-
itations of SmartF P T uner,
it does not always
ﬁnd good solutions compared to FPTuning; on the
contrary, the solutions of SmartF P T uner usually
have a higher number of bits.

Table 2 provides an overview of the compari-
son for all benchmarks. The values reported are
computed over all error targets considered, namely
10−30, 10−25, 10−20, 10−15, 10−10, 10−7, 10−5,
10−3, 10−1. Each column from 2-6 corresponds
to a benchmark; the last one on the right is the
average on all benchmarks. The ﬁrst row reports
the diﬀerence (as a percentage) in solution quality
between SmartF P T uner and FPTuning, in terms
of the number of bits in the solution; a minus
sign indicates that our method outperforms FP-
Tuning. The time required to ﬁnd a solution by
SmartF P T uner includes two components: I) the
time needed to create the data set to train the ML
models and II) the actual solution time, that is
the time required to train and integrate the ML
models, solve the MP model and eventually re-
peat the process in case the solution found does
not respect the bound on the error. The second
row in Table 2 reports the time diﬀerence between
SmartF P T uner and FPTuning, computed exclud-
ing the time needed to create the training sets; in-
cluding it would not be fair, as after the data set is

8

created it can be reused multiple times and diﬀer-
ent error targets (it can be used to train diﬀerent
ML models to be integrated via EML). Deﬁnitely,
the cost for data set creation becomes negligible
over repeated calls of SmartF P T uner.

The time required to found solutions by FP-
Tuning varies considerably depending on the er-
ror given as a target (tighter bounds require longer
times), hence the relative diﬀerences reported in
Tab. 2 are more eﬀective for comparing the ap-
proaches. However, it could be useful to provide
some actual numbers to give the order of magni-
tude. For each benchmark and computed as aver-
age among all error targets, the solution time (in
seconds) required by FPTuning are the following:
FWT 24.3, saxpy 38.5, convolution 81.9, correla-
tion 180.9, dwt 81.8, BlackScholes 1512.3, Jacobi
3409.6.

Concerning the solution quality, FPTuning out-
performs us (except for saxpy), since our solutions
have a higher number of bits (15% on average).
Conversely, SmartF P T uner is markedly quicker,
as attested by the average decrease in solution-time
of around 55%.

4.3 Extended

Approach:

SmartF P T uner+

is

in

noted

previous

the
section,
As
SmartF P T uner
extremely fast but pro-
duces low-quality solutions, as, generally speaking,
higher numbers of bits lead to greater energy
consumption. We decided then to extend our
approach by combining our method with FPTun-

SFPT vs FPT – N. Bits (%)
SFPT vs FPT – Time (%)

SFPT+ vs FPT – N. Bits (%)
SFPT+ vs FPT – Time (%)

FWT
14.1
-62.4

4.7
-8.2

saxpy
-1.0
-14.0

-3.9
9.1

convolution
3.7
-33.5

0.1
9.1

dwt
22.6
53.7

0.7
-5.8

correlation
14.7
-79.5

BlackScholes
22.3
-80.2

-1.0
-8.3

-1.7
-22.6

Jacobi
29.8
-65.1

-4.7
-18.9

Avg.
15.2
-55.4

-3.0
-6.51

Table 2: Comparison between SmartF P T uner(SFPT in the table), SmartF P T uner+(SFPT+) and
FPTuning (FPT)

FPTuning algorithm can be decomposed
ing.
into two phases:
(i) a search for an initial
solution satisfying the error target and (ii) a
reﬁnement that iteratively improves the solution
(by lowering the precision through a heuristic),
until two consecutive solutions have the same
total number of bits. We propose an extended
approach SmartF P T uner+ that exploits FPTun-
ing’s reﬁnement phase 3 to improve the initial
solution found by SmartF P T uner.
In practice,
SmartF P T uner+ starts from the initial solution
quickly found by SmartF P T uner and then im-
proves it by attempting to decrease the precision
of
the variables with the heuristic algorithm
introduced by FPTuning (a variant of binary
search).

The ﬁnal two rows of Table 2 show the results.
The time needed by SmartF P T uner+ to ﬁnd a so-
lution contains an additional component w.r.t. to
SmartF P T uner, namely the time required to im-
prove the initial solution. SmartF P T uner+ re-
mains faster than FPTuning (although the gap
is reduced, average speedup of around 6.5%) for
all but two benchmarks, which are the ones with
low number of variables (saxpy and convolution).
These “easier” benchmarks can be quickly run
multiple times; thus, the FPTuning approach is
less penalizing – with applications with more vari-
ables SmartF P T uner+ is still signiﬁcantly faster,
an encouraging sign for the extension of our ap-
proach to more complex programs. More im-
portantly, SmartF P T uner+ also outperforms the
SoA in terms of solution quality; the improvement
is relatively small (3%), but this is remarkable
nonetheless, as experiments performing an exhaus-
tive search on small benchmarks reveal that FP-
Tuning ﬁnds solutions very close to the optimal
ones.

3https://github.com/minhhn2910/fpPrecisionTuning

4.3.1 Transfer Learning

As mentioned before, at the moment we are mainly
interested in a preliminary evaluation and the com-
parison with the SoA, hence we considered a sin-
gle input set for all previous experiments. But at
the same time, we want to hint at an additional
beneﬁt that can be obtained with the optimization
model w.r.t. FPTuning. Our ML models can learn
some of the latent proprieties that characterize the
benchmarks (their precision-error function); some
of these relationships may hold for diﬀerent input
sets. On the contrary, FPTuning focuses exclu-
sively on the problem at hand. Hence, the solu-
tions found by our approach can be more “robust”
for diﬀerent input sets w.r.t. the FPTuning solu-
In a sense, we want to understand if the
tions.
solution found for a given input set is transferable
to diﬀerent ones.

We tested this hypothesis in this fashion: I) we
generated 30 diﬀerent input sets for each bench-
mark; II) we found the best conﬁgurations for a
ﬁxed input set Si using both SmartF P T uner and
FPTuning and for a given error target; III) ﬁ-
nally, we run the benchmark with the conﬁg-
uration just found but feeding it with the re-
maining input sets (hence 29 separate runs), and
we checked if the conﬁguration satisﬁes the error
target also for other input sets. For these ex-
periments, we considered SmartF P T uner rather
than SmartF P T uner+ since the focus is on
the solution found by the combination of MP
and ML models, without
the added “noise”
introduced by the heuristic reﬁnement phase
of SmartF P T uner+ (the FPUtning-inspired im-
provement over
solution found by
SmartF P T uner). The diﬀerent input sets are vec-
tors of randomly generated numbers. The solutions
for our approach were obtained using data sets of
training size equal to one thousand. Table 3 re-
ports the results. Each row corresponds to an er-

the ﬁrst

9

ror target; the ﬁnal one is the average among all
targets. For each benchmark, we compute the per-
centage of input sets that presented an error lower
than the target with the conﬁguration found with
Si (excluded from this computation); lower values
are preferable since they imply that the conﬁgura-
tion for Si is more robust. Blacksholes and Jacobi
are not reported for space limitations. Columns
FPT and Opt (two for each benchmark) indicate,
respectively, the results with FPTuning and with
SmartF P T uner. The last two columns report the
average values computed among all benchmarks.

From the table we can see that the “transfer-
ability” of the solutions strongly depends on the
particular benchmark; for example, convolution so-
lutions are very robust to diﬀerent input sets, while
the contrary happens for dwt. For all benchmarks
except FWT, SmartF P T uner is more robust com-
pared to FPTuning; this holds true also if we con-
sider all error targets (bold values in the last two
columns highlight the method with the more robust
solution for a given target). These observations
suggest that our approach is capable of learning
part of the underlying patterns that characterize
an application and thus can obtain solutions that
can be reused on diﬀerent input sets.

However, we are aware that the case of diﬀerent
input sets should be explored in more detail – this
is a preliminary approach that we plan to improve
in future works. For example, this issue could be
dealt with by training the ML models on multiple
samples, representative of the target application;
the ML model may optionally output a probability
distribution rather than a single prediction.

cludes a smallFloat unit (SFU)[MRT+18], which
provides a set of non-standard ISA extensions to en-
able operations on smaller-than-32-bit FP formats.
This unit supports two IEEE standard formats,
single-precision (binary32 ) and half-precision (16
bit) ones, and two additional formats, namely bi-
nary8 and binary16alt. The ﬁrst is an 8-bit format
with low precision (3-bit mantissa), and the second
is an alternative 16-bit format featuring a higher
dynamic range (8-bit exponent). The SFU also
supports a vectorial ISA extension which makes use
of SIMD sub-word parallelism by packing multiple
smaller-than-32-bit elements into a single register;
this is a key feature to reduce energy consumption
since it allows to optimize the circuitry of the HW
unit and reduce the memory bandwidth required to
transfer data between memory and registers.

The software ecosystem5 of the PULP project in-
cludes a virtual platform and a compiler (based on
GCC 7.1). The virtual platform is cycle-accurate
and provides detailed execution statistics, includ-
ing instruction and cycle counters, used to evaluate
the energy consumption of the benchmarks. The
power numbers have been obtained through sim-
ulation of the post-layout design set to 350 MHz
using worst-case conditions (1.08 V, 125◦C), as de-
tailed in [MRT+18]. Finally, the compiler pro-
vides an extended C/C++ type system to make
use of the smallFloat types using additional key-
words (ﬂoat8, ﬂoat16 and ﬂoat16alt). The GCC
auto-vectorizer has been extended to enable the
adoption of the vectorial ISA extension; whenever
reduced-precision variables can be used, our bench-
marks take great advantage of this feature.

5 Experimental Results: En-

5.2 Experimental Evaluation

ergy Eﬃciency

5.1 Deployment & Setup

Our target platform is PULPissimo4, an open-
source 32-bit microcontroller based on the RISC-
V instruction set architecture (ISA). This platform
supports the R32IMFC ISA conﬁguration, featur-
ing extensions for integer multiplication and divi-
sion (“M”), single-precision FP arithmetic (“F”)
and compressed encoding (“C”). The core also in-

The energy savings are measured as the energy
obtained by running a benchmark with all single-
precision variables (the baseline) over the energy
obtained with the mixed-precision conﬁguration
found by SmartF P T uner+; values higher than 1
indicate energy gains, as the mixed-precision ap-
proach leads to lower energy consumption than the
baseline. Table 4 reports the results. Each line
corresponds to an error bound, and the last line
summarizes the average on all targets; each column
reports the energy gain compared to the baseline.

4https://github.com/pulp-platform/pulpissimo

5https://github.com/pulp-platform/pulp-sdk

10

Target

0.1
10−2
10−3
10−5
10−7
10−10
10−12
10−15
10−20
10−25

Average

FWT

saxpy

FPT
10.3
17.2
41.4
0
0
0
0
0
0
0

6.9

Opt
44.8
89.6
41.4
3.4
65.5
0
0
0
0
0

24.5

FPT
0
0
0
0
62.1
0
0
0
86.2
6.9

15.5

Opt
0
0
0
0
0
0
0
0
0
0

0

convolution
FPT
17.2
72.4
0
6.8
0
0
0
0
0
0

Opt
0
0
0
24.1
17.2
0
27.6
0
0
0

9.6

6.9

dwt

FPT
62.1
65.5
65.5
75.9
55.2
86.2
62.1
82.7
96.5
7.7

72.4

Opt
79.3
62.1
86.2
51.7
37.9
62.1
3.4
44.8
68.9
0

55.2

correlation
FPT
68.9
68.9
68.9
79.3
10.3
0
3.4
0
0
24.1

Opt
10.3
13.8
10.3
62.1
24.1
20.7
0
17.2
0
0

All Benchmarks
Opt
26.9
33.1
27.6
28.3
28.9
16.6
6.2
12.4
13.8
0

FPT
31.7
44.8
35.2
32.4
25.5
17.2
13.1
16.5
36.5
7.8

32.4

15.9

26.1

19.4

Table 3: Transfer Learning Results

Error Target
10−1
10−2
10−3
10−4
10−5
10−6
10−7

FWT
1.00
1.00
1.00
1.00
1.00
1.00
1.00

saxpy
3.99
2.26
2.00
1.90
2.00
1.13
1.00

convolution
1.35
1.35.
1.27
1.22
1.22
1.30
1.00

Avg.

1.00

2.04

1.25

dwt
1.00
1.00
1.00
1.00
1.00
1.00
1.00

1.00

correlation
1.08
1.00
1.00
1.00
1.00
1.00
1.00

BlackScholes
1.54.
1.52
1.29
1.08
1.06
1.00
1.00

1.00

1.21

Jacobi
2.90
2.90
1.74
1.82
1.77
1.78
1.78

2.09

Avg. over all benchmarks
1.84
1.58
1.33
1.29
1.29
1.17
1.11

1.37

Table 4: Energy gains measured as energy consumed with single-precision over energy with
SmartF P T uner+

Overall,

the results are extremely promis-
ing:
the average energy gain obtained with
SmartF P T uner+ is 1.37 (around 40%), and in the
benchmarks showing energy savings the compiler
was able to apply automatic vectorization to the
code thanks to the precision-reduction enabled by
our tool. However, the gains are not homogeneous,
as for some benchmarks there is no energy sav-
ing w.r.t. the baseline (FWT, dwt, correlation); in
these cases, the discrete precision levels oﬀered no
margin for energy gain – more ﬁne-grained mixed-
precision levels could improve this situation and
will be investigated in future works. The results
clearly show that, as expected, less strict bounds on
the computation accuracy can ensure higher gains
since in these cases the variable precision can be
reduced more markedly.

exploiting the Empirical Model Learning paradigm.
The experimental results reveal that the proposed
model is very fast but, generally speaking, pro-
duces low-quality solutions. Hence we combine our
method with a reﬁnement algorithm from the liter-
ature, thus obtaining an approach that thoroughly
outperforms the SoA.

Moreover, we demonstrate the quality of our
approach by measuring the energy gains obtained
via static precision tuning on a virtual platform
that emulates precision-tunable HW, revealing
energy savings around 40% with the static tuning
of FP variables.

6 Conclusion

Acknowledgements

In this paper we propose a novel approach for solv-
ing the problem of tuning the precision of FP vari-
ables in numerical applications. Our method com-
bines ML models and an MP optimization model,

This work has been partially supported by Eu-
ropean H2020 FET project OPRECOMP (g.a.
732631).

11

References

[BLM15]

Alessio Bonﬁetti, Michele Lombardi,
and Michela Milano. Embedding de-
cision trees and random forests in con-
straint programming.
In Proceedings
of CPAIOR, pages 74–90, 2015.

[BLMB11] Andrea Bartolini, Michele Lombardi,
Michela Milano, and Luca Benini.
Neuron constraints to model complex
real-world problems. In Proceedings of
CP, pages 115–129, 2011.

[BLMB12] Andrea Bartolini, Michele Lombardi,
Michela Milano, and Luca Benini. Op-
timization and controlled systems: A
case study on thermal aware workload
dispatching.
In Proceedings AAAI,
2012.

[CBB+17] Wei-Fan Chiang, Mark Baranowski,
Ian Briggs, Alexey Solovyev, Ganesh
Gopalakrishnan, and Zvonimir Raka-
mari´c. Rigorous ﬂoating-point mixed-
precision tuning. ACM SIGPLAN No-
tices, 52(1):300–315, 2017.

International Symposium on Software
Testing and Analysis, pages 333–343.
ACM, 2018.

[HHLB11] Frank Hutter, Holger H Hoos, and
Kevin Leyton-Brown.
Sequential
model-based optimization for general
algorithm conﬁguration.
In Interna-
tional Conference on Learning and In-
telligent Optimization, pages 507–523.
Springer, 2011.

[HMWA17] Nhut-Minh Ho, Elavarasi Manogaran,
Weng-Fai Wong, and Asha Anoosheh.
Eﬃcient ﬂoating point precision tun-
ing for approximate computing.
In
Design Automation Conference (ASP-
DAC), 2017 22nd Asia and South Pa-
ciﬁc, pages 63–68. IEEE, 2017.

[KB14]

Diederik P Kingma and Jimmy Ba.
stochas-
Adam:
A method for
arXiv preprint
tic optimization.
arXiv:1412.6980, 2014.

[KMBC14] Pavel Klav´ık, A Cristiano I Malossi,
Costas Bekas, and Alessandro Curi-
oni. Changing computing paradigms
towards power eﬃciency. Phil. Trans.
R. Soc. A, 372(2018):20130278, 2014.

[CN18]

[DK17]

[GJea16]

Alberto Costa and Giacomo Nan-
nicini. Rbfopt:
an open-source li-
brary for black-box optimization with
costly function evaluations. Math-
ematical Programming Computation,
10(4):597–629, 2018.

[LG13]

and Viktor Kun-
Eva Darulova
cak. Towards a compiler for reals.
ACM Trans. Program. Lang. Syst.,
39(2):8:1–8:28, March 2017.

[LG16]

Stef Graillat, Fabienne J´ez´equel, and
et al. Promise: ﬂoating-point precision
tuning with stochastic arithmetic. In
Proceedings of the 17th International
Symposium on Scientiﬁc Computing,
Computer Arithmetics and Veriﬁed
Numerics (SCAN), pages 98–99, 2016.

Michele Lombardi and Stefano Gua-
landi. A new propagator for two-layer
neural networks in empirical model
learning. In Proceedings of CP, pages
448–463, 2013.

Michele Lombardi and Stefano Gua-
landi. A lagrangian propagator for ar-
tiﬁcial neural networks in constraint
programming. Constraints, 21(4):435–
462, 2016.

[LMB17] Michele Lombardi, Michela Milano,
and Andrea Bartolini. Empirical de-
cision model learning. Artiﬁcial Intel-
ligence, 244:343–367, 2017.

[GRG18]

Hui Guo and Cindy Rubio-Gonz´alez.
Exploiting community structure for
ﬂoating-point precision tuning. In Pro-
ceedings of the 27th ACM SIGSOFT

[Mit16]

Sparsh Mittal. A survey of techniques
for approximate computing. ACM
Computing Surveys (CSUR), 48(4):62,
2016.

12

platform for ultra-low power com-
puting.
In Design, Automation &
Test in Europe Conference & Exhibi-
tion (DATE), 2018, pages 1051–1056.
IEEE, 2018.

[XMK16] Qiang Xu, Todd Mytkowicz, and
Nam Sung Kim. Approximate comput-
ing: A survey. IEEE Design & Test,
33(1):8–22, 2016.

[MRT+18] S. Mach, D. Rossi, G. Tagliavini,
A. Marongiu, and L. Benini. A Trans-
precision Floating-Point Architecture
for Energy-Eﬃcient Embedded Com-
In 2018 IEEE International
puting.
Symposium on Circuits and Systems
(ISCAS), pages 1–5. IEEE, 2018.

[MSea18] A Cristiano

I Malossi, Michael
Schaﬀner, and et al. The transpreci-
sion computing paradigm: Concept,
design, and applications.
In Design,
Automation & Test in Europe Con-
ference & Exhibition (DATE), 2018,
pages 1105–1110. IEEE, 2018.

[MTDM17] Mariano Moscato,

Laura Titolo,
Aaron Dutle, and C´esar A Munoz.
Automatic
veriﬁed
estimation
of
round-oﬀ errors via
ﬂoating-point
static analysis.
In International
Conference on Computer Safety, Re-
liability, and Security, pages 213–229.
Springer, 2017.

[MTea17] Mariano Moscato, Laura Titolo, and
et al. Automatic estimation of veri-
ﬁed ﬂoating-point round-oﬀ errors via
static analysis. In Stefano Tonetta, Er-
win Schoitsch, and Friedemann Bitsch,
editors, Computer Safety, Reliability,
and Security, pages 213–229, Cham,
2017. Springer International Publish-
ing.

[opr]

Oprecomp - open transprecision com-
puting. http://oprecomp.eu/. Online;
accessed 15 May 2019.

[RGNea16] Cindy

Cuong
Rubio-Gonz´alez,
Nguyen, and et al. Floating-point pre-
cision tuning using blame analysis. In
Proceedings of the 38th International
Conference on Software Engineering,
pages 1074–1085. ACM, 2016.

[Ste87]

Michael Stein. Large sample properties
of simulations using latin hypercube
sampling. Technometrics, 29(2):143–
151, 1987.

[TMea18] Giuseppe Tagliavini, Stefan Mach, and
et al. A transprecision ﬂoating-point

13

