9
1
0
2

y
a
M
7

]
E
S
.
s
c
[

1
v
2
8
7
6
0
.
5
0
9
1
:
v
i
X
r
a

Published as a workshop paper at ML4SE 2019

IDENTIFYING COLLABORATORS IN LARGE CODEBASES

Waren Long, Vadim Markovtsev, Hugo Mougard, Egor Bulychev & Jan Hula
source{d}
Madrid, Spain
{waren,vadim,hugo,egor,jan}@sourced.tech

ABSTRACT

The way developers collaborate inside and particularly across teams often escapes
management’s attention, despite a formal organization with designated teams be-
ing deﬁned. Observability of the actual, organically formed engineering structure
provides decision makers invaluable additional tools to manage their talent pool.
To identify existing inter and intra-team interactions—and suggest relevant op-
portunities for suitable collaborations—this paper studies contributors’ commit
activity, usage of programming languages, and code identiﬁer topics by embed-
ding and clustering them. We evaluate our ﬁndings collaborating with the GitLab
organization, analyzing 117 of their open source projects. We show that we are
able to restore their engineering organization in broad strokes, and also reveal
hidden coding collaborations as well as justify in-house technical decisions.

1

INTRODUCTION

Many organizations undergo rapid digital transformation nowadays. In such a setting, a common
challenge is the understanding of software development dynamics. Horizontal relations between
development teams are typically obscure and unobvious at a glance. Yet understanding them is
important to manage organizational structure, plan hiring, and prioritize work.

This paper introduces complementary methods to analyze contributors to open source projects. We
study several orthogonal contributor features to obtain an overview of existing collaborations and
evaluate our methods on the GitLab organization, a large software company with over 500 employ-
ees and 110 projects with more than 2,000 external contributors as of 2019. The considered features
include the alignment of commit time series, the developer experience reﬂected in contributed lines
of code (LoC), and topic models related to code naturalness (Allamanis et al., 2017). We harness
dimensionality reduction and clustering for visualization.

2 RELATED WORK

Some researchers have already explored developer collaboration and recommendation through anal-
ysis of the coding activities. For example, Montandon et al. (2019) made use of supervised machine
learning classiﬁers to identify experts in three popular JavaScript libraries. However, that approach
depends on manually labeled classes, so it may be difﬁcult to generalize. Along the same line,
Greene & Fischer (2016) have developed a tool to extract and visualize developers’ skills by using
both keywords from the project’s README ﬁle and commit messages combined with their port-
folio metadata, which they collected from third-party Community Question Answering websites.
Hauff & Gousios (2015) had a different objective to directly match developers to relevant jobs by
comparing their embeddings. Those embeddings were generated from the query describing the job
and the README ﬁle of the project, but they do not leverage the source code itself. Regarding
the topic modeling technique, it has been applied on source code identiﬁers by Markovtsev & Kant
(2017), but without analyzing individual contributions or focusing on potential coding collabora-
tions.

Differing from these, we detect collaborators by working with ﬁne-grained information from every
commit: we analyze every ﬁle in the repository’s history.

1

 
 
 
 
 
 
Published as a workshop paper at ML4SE 2019

3 METHODOLOGY

This section presents a combination of three complementary developer analyses, and each clariﬁes
a particular aspect of developers’ characteristics.

3.1 DATA PROCESSING

To gain the quantitative insight into source code required by further analyses, we employ Hercules1
and Gitbase2—tools that allow efﬁcient and rapid mining of Git repositories. We gather the number
of contributed lines per programming language per developer, the ownership information about each
ﬁle (who edited each line the last), and the commit dates. We also extract the identiﬁers from
each ﬁle and store their frequencies. There is the need for matching Git signatures to contributors.
Therefore we aggregate all co-occurring emails and names to a single identity by ﬁnding connected
components in the corresponding undirected co-occurrence graph. We have to exclude signature
stubs such as gitlab@localhost. The help of GitLab API is intentionally avoided for versatility
reasons.

3.2 COMMIT TIME SERIES

The ﬁrst analysis is grounded on aligning developers’ commits time series. People who work in
a team tend to create commits at correlated times, because they often work on related, mutually
dependent features. The relative commit frequency depends on the shared team planning, notably
the deadlines. We found empirically that the absolute values of the time series are less important
than the distribution shape.

Thus we extract how many commits were done by each developer per day, divide the values by the
mean to normalize the resulting time series, and calculate the pairwise distance matrix using Fast
Dynamic Time Warping (Salvador & Chan, 2007). Then we perform DBSCAN (Ester et al., 1996)
clustering and run UMAP (McInnes et al., 2018) dimensionality reduction to visualize the clusters.
Both mentioned algorithms operate on the explicit distance matrix.

3.3 CONTRIBUTIONS BY PROGRAMMING LANGUAGES

The following way of grouping developers is based on the programming language, the amount and
the nature of contributions (line additions, modiﬁcations, and deletions). Intuitively, these coarsely
correlate with developer seniority and activity domains. Hence we exclude text markup ﬁles from the
analysis. We reduce the inﬂuence of outliers by saturating all the values to the 95th percentile. Our
distance metric is L2. We visualize the distribution by applying UMAP, which preserves the local
topological relations that should be highlighted in our case. We calculate clusters in the embedding
space using K-Means, and their number is determined by the elbow rule. Running K-Means in the
original space produces worse results due to its high-dimensionality and sparsity.

3.4 SOURCE CODE IDENTIFIERS

To complement the commit activity and the programming language usage analyses, we leverage the
content of developers’ contributions in order to assign them topics that are representative of their
activity. We compute the representation for each code ﬁle based on its content as a bag of TF-IDF
scores of its identiﬁers. We then represent each developer by aggregating the representations of
the code ﬁles they edited with a sum weighted by the proportion of the owned lines in each ﬁle.
Finally, we apply ARTM (Vorontsov et al., 2015) to ﬁnd decorrelated, sparse topics ﬁtted to those
representations and label them manually having obtained their most likely and speciﬁc terms.

4 RESULTS

We evaluate the three presented analyses on the codebase of the GitLab organization. That com-
prised 117 repositories, totaling 145 programming languages, 44,272 ﬁles and 12,895,956 lines of

1https://github.com/src-d/hercules
2https://github.com/src-d/gitbase

2

Published as a workshop paper at ML4SE 2019

(a)

(b)

(c)

(d)

Figure 1: Clusters of the contributors to gitlab-org open-source projects based on (a) commit time series
and (c) contributed LoC by language. In (b) and (d) the same contributors are labeled not according to their
cluster but according to their ofﬁcial team in the GitLab organization. The gray points stand for contributors
that are either outside the company as of April 2019 or using different identities.

code in April 2019. Among the 2,956 contributors, we detected 210 current GitLab employees split
in 37 teams (this is a lower bound given the algorithmic difﬁculties detailed in Section 3.1). A
mapping from developers to teams is publicly available3.

Fig. 1a and Fig. 1b reveal the temporal commit coupling of the contributors. GitLab employees are
sorted into two clusters among ﬁve; commit activity alignment proves to be a reliable way to tell
GitLab employees from external contributors. However, the ﬁner structure often does not respect
the teams. For example, cluster #2 groups high frequency committers across the company, one of
them being GitLab’s CEO.

On the other hand, clustering developers by their experience in programming languages— Fig. 1c
and 1d—provides different insights. Fig. 1d demonstrates that people in the same team tend to have
similar experience. All the clusters but #4 in Fig. 1c contain Ruby developers. Indeed, GitLab is
driven by Ruby on Rails and being proﬁcient in Ruby is essential for the company. Cluster #2 joins
developers who code in both Go and Ruby, which agrees with the current partial conversion of the
GitLab backend from Ruby on Rails to Go4. Fig. 1d suggests that the Gitaly, Create BE and Verify
teams are particularly working on this, since their members are located together. Then, cluster #4
emphasizes the recent switch to Vue.js in the frontend, and the Dev UX team seems to be one of the

3https://gitlab.com/gitlab-com/www-gitlab-com/blob/master/data/team.yml
4https://about.gitlab.com/2018/10/29/why-we-use-rails-to-build-gitlab/

3

Published as a workshop paper at ML4SE 2019

team in charge of this. Cluster #4 clearly gathers all the frontend engineers who code in JavaScript,
Vue.js framework, and write SCSS. Overall, the clusters match the typical Ruby on Rails relation
between frontend and backend technologies.

Table 1: Teams of topic contributors.

Table 2: Manual labels assigned to topics.

Frontend

Conﬁg Management

Gollum (wiki)

Topic label

Top terms

Verify FE
Core
Manage FE
Create FE
Monitor FE
Serverless FE
Frontend

Monitor BE
Plan BE
Core Alumni
Create BE
Distribution BE

Product Management
Support Department
Core Alumni
Core

Backend frameworks
Language detection
Data mining
Frontend + UI, CSS
Conﬁg management
TODO
Low-level backend

servlet
languag
chartj
modernizr
chef
todo
btree

ﬂask
java
graphql
mstyle
runner
todos
opclass

javax
linguist
averag
elementn
platform
app
using

Finally, to evaluate the quality of a code topic, we retrieve the teams of the contributors for whom the
evaluated topic is the preponderant one. Results shown in Table 1 highlight that the topic modeling
analysis strongly correlates with GitLab teams. Table 2 shows examples of manually created labels.

We also measure the agreement between topics and the clusters from Fig. 1a and 1c. On average, de-
velopers that have a given main topic are in 1.54 and 1.63 clusters for commit activity and experience
clustering respectively (the expectations are 2.11 and 2.27 respectively for random clusters).

5 CONCLUSION

This paper demonstrated how to identify existing collaborations in an organization by exploring
the topological structure of three feature spaces of a codebase: commit activity, usage of program-
ming languages, and topics of source code identiﬁers. Clustering proved insightful: we observed
a good match with existing development teams in the GitLab organization, and additionally found
several product-oriented inter-organizational squads. We traced the partial transition from Ruby to
Go in GitLab’s backends, which was indeed decided at the company level. Commit series alignment
distinguished between external and internal contributors well.

Our future research directions include leveraging the commits to external repositories since devel-
opers usually contribute to several open source projects that do not belong to their company. Fur-
thermore, it would be interesting to study how engineering teams have evolved as the company has
grown. We believe that combining the recent advancements in machine learning with the expressive
features can shed light on relevant coding collaboration opportunities.

REFERENCES
Miltiadis Allamanis, Earl Barr, Premkumar Devanbu, and Charles Sutton. A survey of machine learning for big code and naturalness. ACM

Computing Surveys, 51(4):81, 2017.

Martin Ester, Hans-Peter Kriegel, Jorg Sander, and Xiaowei Xu. A density-based algorithm for discovering clusters a density-based algorithm
for discovering clusters in large spatial databases with noise. In Proceedings of the International Conference on Knowledge Discovery and
Data Mining, pp. 226–231, 1996.

Gillian J. Greene and Bernd Fischer. Cvexplorer: Identifying candidate developers by mining and exploring their open source contributions.

In Proceedings of the International Conference on Automated Software Engineering, pp. 804–809, 2016.

Claudia Hauff and Georgios Gousios. Matching github developer proﬁles to job advertisements. In Proceedings of the International Conference

on Mining Software Repositories, pp. 362–366, 2015.

Vadim Markovtsev and Eiso Kant. Topic modeling of public repositories at scale using names in source code. ArXiv, 1704.00135, 2017.

Leland McInnes, John Healy, and James Melville. Umap: Uniform manifold approximation and projection for dimension reduction. ArXiv,

1802.03426, 2018.

Jo˜ao Eduardo Montandon, Luciana Lourdes Silva, and Marco Tulio Valente. Identifying experts in software libraries and frameworks among

github users. ArXiv, 1903.08113, 2019.

Stan Salvador and Philip Chan. Toward accurate dynamic time warping in linear time and space. Intelligent Data Analysis, 11(5):561–580,

2007.

Konstantin Vorontsov, Oleksandr Frei, Murat Apishev, Peter Romov, and Marina Dudarenko. Bigartm: Open source library for regularized
multimodal topic modeling of large collections. In Proceedings of the International Conference on Analysis of Images, Social Networks
and Texts, pp. 370–381, 2015.

4

