1

2
2
0
2

b
e
F
8
1

]
L
P
.
s
c
[

2
v
7
8
8
1
1
.
0
1
0
2
:
v
i
X
r
a

Conditional independence by typing

MARIA I. GORINOVA, University of Edinburgh
ANDREW D. GORDON, Microsoft Research and University of Edinburgh
CHARLES SUTTON, University of Edinburgh
MATTHIJS VÃKÃR, Utrecht University

A central goal of probabilistic programming languages (PPLs) is to separate modelling from inference. However,
this goal is hard to achieve in practice. Users are often forced to re-write their models in order to improve
efficiency of inference or meet restrictions imposed by the PPL. Conditional independence (CI) relationships
among parameters are a crucial aspect of probabilistic models that capture a qualitative summary of the
specified model and can facilitate more efficient inference.

We present an information flow type system for probabilistic programming that captures conditional
independence (CI) relationships, and show that, for a well-typed program in our system, the distribution it
implements is guaranteed to have certain CI-relationships. Further, by using type inference, we can statically
deduce which CI-properties are present in a specified model.

As a practical application, we consider the problem of how to perform inference on models with mixed
discrete and continuous parameters. Inference on such models is challenging in many existing PPLs, but can
be improved through a workaround, where the discrete parameters are used implicitly, at the expense of
manual model re-writing. We present a source-to-source semantics-preserving transformation, which uses
our CI-type system to automate this workaround by eliminating the discrete parameters from a probabilistic
program. The resulting program can be seen as a hybrid inference algorithm on the original program, where
continuous parameters can be drawn using efficient gradient-based inference methods, while the discrete
parameters are inferred using variable elimination.

We implement our CI-type system and its example application in SlicStan: a compositional variant of Stan.1

CCS Concepts: â€¢ Theory of computation â†’ Random walks and Markov chains; Type structures; Opera-
tional semantics; â€¢ Mathematics of computing â†’ Statistical software; â€¢ Computing methodologies â†’
Learning in probabilistic graphical models.

Additional Key Words and Phrases: probabilistic programming, information flow types, static analysis, condi-
tional independence, compiler correctness

ACM Reference Format:
Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r. 2021. Conditional independence
by typing. ACM Trans. Program. Lang. Syst. 1, 1, Article 1 (January 2021), 54 pages.

1 INTRODUCTION
The number of probabilistic programming languages (PPLs) has grown far and wide, and so has the
range of inference techniques they support. Some focus on problems that can be solved analytically,
and provide a symbolic solution [Gehr et al. 2016], others are very flexible in the models they can
express and use general-purpose inference algorithms [Wood et al. 2014]. Some use gradient-based
methods [Carpenter et al. 2017], or message-passing methods [Minka et al. 2014] to provide an
efficient solution at the cost of restricting the range of expressible programs. Each option presents
its own challenges, whether in terms of speed, accuracy or inference constraints, which is why
PPL users often are required to learn a set of model re-writing techniques: to be able to change the
program until it can be feasibly used within the backend inference algorithm.

1The implementation is available at https://github.com/mgorinova/SlicStan.

2021. 0164-0925/2021/1-ART1 $15.00
https://doi.org/

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

 
 
 
 
 
 
1:2

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

Take for example Stan [Carpenter et al. 2017], which is used by practitioners in a wide range of
sciences and industries to analyse their data using Bayesian inference. While efficient inference
algorithms exist for continuous-only and for some discrete-only models, it is much less clear
what algorithm to use for arbitrary models with large numbers of both discrete and continuous
(latent, i.e., unobserved) parameters. Stan has made a conscious choice not to support probabilistic
models with discrete parameters, so as to perform inference using (dynamic) Hamiltonian Monte
Carlo (HMC) [Betancourt and Girolami 2015; Hoffman and Gelman 2014; Neal et al. 2011]), which
provides efficient, gradient-based inference for differentiable models. As a result, Stan has often
been criticised [Gelman et al. 2015] for its lack of support for discrete parameters. What is usually
overlooked is that many models with discrete parameters can, in fact, be accommodated in Stan, by
manually marginalising (summing) out the discrete parameters and drawing them conditionally
on the continuous parameters [Stan Development Team 2019b, Chapter 7]. One of the core model
rewriting techniques is marginalisation: summing over all possible values that a random variable
can take to obtain a marginal density function that does not involve that variable. Marginalising
efficiently is not always an obvious procedure, as it requires exploiting conditional independence
relationships among the variables in the model. For probabilistic graphical models, there are well-
known algorithms for enumerating all of the conditional independence assumptions implied by a
model. But probabilistic programs are much more general, including control flow and assignment.
For this more general case, it is much less clear how to determine conditional independence
relationships automatically, and doing so requires combining ideas from traditional program
analysis and from probabilistic graphical modelling.

In this paper, we introduce an information flow type system that can deduce conditional inde-
pendence relationships between parameters in a probabilistic program. Finding such relationships
can be useful in many scenarios. As an example application, we implement a semantics-preserving
source-to-source transformation that automatically marginalises discrete parameters. We work in
SlicStan [Gorinova et al. 2019], a form of Stan with a more compositional syntax than the original
language. Our system extends SlicStan to support discrete parameters in the case when the discrete
parameter space is bounded. This transform corresponds to the variable elimination algorithm
[Koller and Friedman 2009; Zhang and Poole 1994]: an exact inference algorithm, efficient in models
with sparse structure. Combining this transformation with an efficient algorithm for continuous
parameters, like HMC, gives us a model-specific, automatically derived inference strategy, which is
a composition of variable elimination and the algorithm of choice. While we only focus on one
application in this paper, our type system for conditional independence is applicable to program
transformations of probabilistic programs more generally, and we believe it can enable other
composed-inference strategies.

In short, we make the following contributions:

(1) Factorised semantics for SlicStan: As a basis for proving correctness of our transformation, we
extend SlicStanâ€™s type system, so that shredding (which slices a SlicStan program into Stan
for execution) correctly separates well-typed programs into data preprocessing, main model,
and purely generative code (Theorem 1).

(2) Main theoretical result: We show how a very simple, relatively standard information flow
type system can be used to capture a conditional independence in probabilistic programs (Â§ 3)
and establish a correspondence between well-typed programs and conditional independence
properties of the probability distribution it implements (Theorem 2, Theorem 3).

(3) Main practical result: We describe and implement (in SlicStan) a source-to-source transfor-
mation that repeatedly uses the result from (2) to efficiently marginalise out the discrete
parameters of the program, and we give a generative procedure for drawing these parameters

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:3

// Stan target program
data{ real x; }
parameters{ real ğœ‡; }
model{ x âˆ¼ normal(ğœ‡, 1); }
generated quantities{
real x_pred = normal_rng(ğœ‡, 1); }

// SlicStan from POPLâ€™19

// Extended SlicStan

real ğœ‡;
data real x âˆ¼ normal(ğœ‡, 1);
real x_pred = normal_rng(ğœ‡, 1);

real ğœ‡;
data real x âˆ¼ normal(ğœ‡, 1);
real x_pred âˆ¼ normal(ğœ‡, 1);

Fig. 1. Example of difference to previous version of SlicStan

(Â§ 4), thus automating inference for mixed discrete-continuous models. We prove that our
transformation is semantics-preserving (Theorem 4).

2 SLICSTAN: EXTENDED SYNTAX AND SEMANTICS
SlicStan [Gorinova et al. 2019] is a Stan-like probabilistic programming language. Compared to
Stan, it provides extra compositionality by dropping the requirement that programs be block-
structured. SlicStan uses type inference in an information-flow type system [Abadi et al. 1999;
Gordon et al. 2015; Volpano et al. 1996] to automatically rearrange the program into parts roughly
corresponding to the block structure of Stan: pre-processing (data), model, and post-processing
(generated quantities). Originally, this shredding was developed to compile SlicStan to Stan. In
this paper, we show that it can be used, more generally, to automatically compile to an efficient
program-specific inference scheme.

Like Stan, SlicStan is imperative and allows for deterministic assignment, for-loops, if-statements,
probabilistic assignment, and factor-statements. One contribution of this work is that we present
an updated version of SlicStan.

A key difference to the original version of SlicStan is the treatment of sampling (âˆ¼) statements. In
the original SlicStan paper [Gorinova et al. 2019], a statement such as ğ‘¥ âˆ¼ N (0, 1) was understood
simply as a syntactic sugar for factor(N (ğ‘¥ | 0, 1)): adding a factor to the underlying density of
the model, rather than performing actual sampling. In our updated version of SlicStan, sampling
statements are part of the core syntax. The semantics of ğ‘¥ âˆ¼ N (0, 1) remains equivalent to that
of factor(N (ğ‘¥ | 0, 1)) in terms of density semantics, however it could be implemented differently
depending on the context. In particular, ğ‘¥ âˆ¼ N (0, 1) could be implemented as a simple call to a
random number generator in Stan, ğ‘¥ = Nğ‘Ÿğ‘›ğ‘” (0, 1), like in the example in Figure 1.

This way of treating âˆ¼ statements differently is useful, as it allows for an increase of the func-
tionality of the SlicStanâ€™s information-flow analysis. Consider, for example the SlicStan program
on the right of Figure 1. Using the original type system, both ğœ‡ and ğ‘¥pred will be of level model,
as they are both involved in a âˆ¼ statement. Thus, when translated to Stan, both ğœ‡ and ğ‘¥pred must
be inferred with HMC (or another similar algorithm), which is expensive. However, the updated
type system of this paper allows for ğ‘¥pred to be of level genqant, which is preferable: in the
context of Stan, this means only ğœ‡ needs to be inferred with HMC, while ğ‘¥pred can be simply drawn
using a random number generator. More generally, the updated SlicStan type system allows for
factorising the density defined by the program: for data D, parameters ğœ½ and generated quantities
ğ‘„, a program defining a density ğ‘ (D, ğœ½, ğ‘„) can be sliced into two programs with densities ğ‘ (D, ğœ½ )
and ğ‘ (ğ‘„ | D, ğœ½ ) respectively (Theorem 1). The parameters ğœ½ are inferred using HMC (or another
general-purpose inference algorithm) according to ğ‘ (D, ğœ½ ), while the quantities ğ‘„ are directly
generated according to ğ‘ (ğ‘„ | D, ğœ½ ).

Treating âˆ¼ statements differently based on context is very similar in spirit to existing effect-
handling based PPLs [Moore and Gorinova 2018] like Edward2 and Pyro, where âˆ¼ can be handled

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:4

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

in different ways. However, in our case, this difference in treatment is determined statically,
automatically, and only in the translation to Stan or another backend.

Another difference between Gorinova et al. [2019]â€™s SlicStan and our updated version is the

target(ğ‘†) expression, which we use to capture locally the density defined by statements.

These changes are a small but useful contribution of the current work: they are key to allowing

us to decompose the program and compose different inference strategies for efficiency.

In the rest of this section, we give the updated formal syntax, typing and semantics of SlicStan

and describe shredding â€” the procedure key to the translation of Stan / inference composition.

2.1 Syntax
SlicStan has the following types, programs, L-values, statements, and expressions. We highlight the
difference with [Gorinova et al. 2019] with boxes.

SlicStan Types:

SlicStan Program:

â„“ ::= data | model | genqant
ğ‘› âˆˆ N
ğœ ::= real | int |
ğ‘‡ ::= (ğœ, â„“)

intâŸ¨ğ‘›âŸ© | ğœ []

level type
size
base type
type

ğ‘ƒ ::= Î“, ğ‘†

program

SlicStan L-Values:

ğ¿ ::= ğ‘¥ [ğ¸1] Â· Â· Â· [ğ¸ğ‘›]

L-value

SlicStan Typing Environments:

Î“ ::= {ğ‘¥1 â†¦â†’ ğ‘‡1, . . . , ğ‘¥ğ‘› â†¦â†’ ğ‘‡ğ‘› }

typing environment

SlicStan Statements:

SlicStan Expressions:

ğ‘† ::=

statement

assignment
ğ¿ = ğ¸
ğ‘†1; ğ‘†2
sequence
for(ğ‘¥ in ğ¸1 : ğ¸2) ğ‘† for loop
if(ğ¸) ğ‘†1 else ğ‘†2
skip
factor(E)

if statement
skip
factor statement

ğ¿ âˆ¼ ğ‘‘ (ğ¸1, ..., ğ¸ğ‘›)

sample statement

expression

ğ¸ ::=
ğ‘¥
ğ‘
[ğ¸1, ..., ğ¸ğ‘›]
ğ¸1 [ğ¸2]
ğ‘“ (ğ¸1, . . . , ğ¸ğ‘›)
[ğ¸ | ğ‘¥ in ğ¸1 : ğ¸2]
target(S)

variable
constant
array
array element
function call
array comprehension

evaluating a density

SlicStan programs consist of a pair Î“, ğ‘† of a typing environment Î“ (a finite map that assigns global
variables ğ‘¥ to their types ğ‘‡ ) and a statement ğ‘†. Following the usual style of declaring variables in C-
like languages, we informally present programs Î“, ğ‘† in examples by sprinkling the type declarations
of Î“ throughout the statement ğ‘†. For example, we write data real ğ‘¥ âˆ¼ normal(0, 1) for the program
{ğ‘¥ â†¦â†’ (real, data)}, ğ‘¥ âˆ¼ normal(0, 1). Sometimes, we will leave out types or write incomplete types
in our examples. In this case, we intend for the missing types to be determined using type inference.
As we discuss in detail in Â§Â§ 2.3, a factor(ğ¸) statement can be read as multiplying the current
weight (contribution to the modelâ€™s joint density) of the program trace by the value of ğ¸. Conversely,
a target(ğ‘†) expression initialises the weight to 1 and returns the weight that is accumulated after
evaluating ğ‘†. For example, if:

ğ‘† = x âˆ¼ normal(0,1); y = 2 * x; z âˆ¼ normal(y,1);

= factor(normal_pdf(x|0,1)); y = 2 * x; factor(normal_pdf(z|y,1));

Then target(ğ‘†) is semantically equivalent to normal_pdf(x|0,1)* normal_pdf(z|2 * x,1).

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:5

We extend the base types of the language of [Gorinova et al. 2019] with intâŸ¨ğ‘›âŸ©, which denotes a
positive integer constrained from above by an integer ğ‘›. For example if ğ‘¥ is of type intâŸ¨2âŸ©, then
ğ‘¥ can only be 1 or 2. These types allow us to specify the support of discrete variables, and they
can easily be extended to include both upper and lower bounds. For the purpose of our typing
rules, we treat intâŸ¨ğ‘›âŸ© identically to int. We only differentiate between these types in Â§ 4, where our
transformation uses the size annotation to eliminate a discrete variable.

2.2 Typing
Types ğ‘‡ in SlicStan range over pairs (ğœ, â„“) of a base type ğœ, and a level type â„“. The level types â„“ form
a lattice ({data, model, genqant}, â‰¤), where data â‰¤ model â‰¤ genqant. We write (cid:195)ğ‘›
ğ‘–=1 â„“ğ‘– for
the least upper bound of the levels â„“1, . . . , â„“ğ‘›. We call variables of level data data (variables), of level
model model parameters, and of level genqant generated quantities. We refer to variables that are
either of level model or genqant simply as parameters. Given a typing environment Î“, we can
consider the well-typedness of expressions and statements, given the types assigned to variables
by Î“. The judgment Î“ âŠ¢ ğ¸ : (ğœ, â„“) means that expression ğ¸ has type ğœ and reads only level â„“ and
below. The judgment Î“ âŠ¢ ğ‘† : â„“ means that statement ğ‘† assigns only to level â„“ and above. We write
Î“ âŠ¢ ğ‘† as a shorthand for Î“ âŠ¢ ğ‘† : data.

The typing rules for expressions are those of [Gorinova et al. 2019] with added rules for the two
constructs of array comprehensions and target(ğ‘†)-expressions. The typing rules for statements are
as in [Gorinova et al. 2019], with three differences (highlighted in boxes). (Factor) and (Sample)
add typing rules for the now new language constructs factor(ğ¸) and ğ¿ âˆ¼ ğ‘‘ (ğ¸1, ..., ğ¸ğ‘›). The lan-
guage supports a finite number of built-in functions ğ‘“ with type ğœ1, . . . , ğœğ‘› â†’ ğœ and (conditional)
distributions ğ‘‘ âˆˆ Dist(ğœ1, . . . , ğœğ‘›; ğœ) over ğœ given values of types ğœ1, . . . , ğœğ‘›.

Typing Rules for Expressions:

(ESub)
Î“ âŠ¢ ğ¸ : (ğœ, â„“)

â„“ â‰¤ â„“ â€²

(Var)

Î“ âŠ¢ ğ¸ : (ğœ, â„“ â€²)

Î“, ğ‘¥ : ğ‘‡ âŠ¢ ğ‘¥ : ğ‘‡

(Const)

ty(ğ‘) = ğœ
Î“ âŠ¢ ğ‘ : (ğœ, data)

(PrimCall)(ğ‘“ : ğœ1, . . . , ğœğ‘› â†’ ğœ)
Î“ âŠ¢ ğ¸ğ‘– : (ğœğ‘–, â„“ğ‘– ) âˆ€ğ‘– âˆˆ 1..ğ‘›

Î“ âŠ¢ ğ‘“ (ğ¸1, . . . , ğ¸ğ‘›) : (ğœ, (cid:195)ğ‘›

ğ‘–=1 â„“ğ‘– )

(ArrEl)
Î“ âŠ¢ ğ¸1 : (ğœ [], â„“)

Î“ âŠ¢ ğ¸2 : (int, â„“)

Î“ âŠ¢ ğ¸1 [ğ¸2] : (ğœ, â„“)

(Target)
Î“ âŠ¢ ğ‘† : â„“ â€²â€² âˆ€â„“ â€² > â„“.ğ‘…Î“âŠ¢â„“â€² (ğ‘†) = âˆ…2
Î“ âŠ¢ target(ğ‘†) : (real, â„“)

(Arr)
Î“ âŠ¢ ğ¸ğ‘– : (ğœ, â„“) âˆ€ğ‘– âˆˆ 1..ğ‘›
Î“ âŠ¢ [ğ¸1, ..., ğ¸ğ‘›] : (ğœ [], â„“)

(ArrComp)
Î“ âŠ¢ ğ¸1 : (int, â„“)

Î“ âŠ¢ ğ¸2 : (int, â„“)

Î“, ğ‘¥ : (int, â„“) âŠ¢ ğ¸ : (ğœ, â„“)

ğ‘¥ âˆ‰ dom(Î“)

Î“ âŠ¢ [ğ¸ | ğ‘¥ in ğ¸1 : ğ¸2] : (ğœ [], â„“)

Typing Rules for Statements:

(SSub)
Î“ âŠ¢ ğ‘† : â„“ â€²

â„“ â‰¤ â„“ â€²

(Assign)3
Î“(ğ¿) = (ğœ, â„“)

Î“ âŠ¢ ğ¸ : (ğœ, â„“)

Î“ âŠ¢ ğ‘† : â„“

Î“ âŠ¢ (ğ¿ = ğ¸) : â„“

(If)
Î“ âŠ¢ ğ¸ : (real, â„“) Î“ âŠ¢ ğ‘†1 : â„“ Î“ âŠ¢ ğ‘†2 : â„“
Î“ âŠ¢ if(ğ¸) ğ‘†1 else ğ‘†2 : â„“

2We use â„“â€² > â„“ as a shorthand for â„“ â‰¤ â„“â€² âˆ§ Â¬â„“â€² â‰¤ â„“

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:6

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

(Seq)
Î“ âŠ¢ ğ‘†1 : â„“

Î“ âŠ¢ ğ‘†2 : â„“ S(ğ‘†1, ğ‘†2) âˆ§ G(ğ‘†1, ğ‘†2)

Î“ âŠ¢ (ğ‘†1; ğ‘†2) : â„“

(Factor)
Î“ âŠ¢ ğ¸ : (real, model)
Î“ âŠ¢ factor(ğ¸) : model

(Skip)

Î“ âŠ¢ skip : â„“

(Sample)3(ğ‘‘ âˆˆ Dist(ğœ1, . . . , ğœğ‘›; ğœ))
Î“(ğ¿) = (ğœ, â„“ â€²) Î“ âŠ¢ ğ¸ğ‘– : (ğœğ‘–, â„“), âˆ€ğ‘– âˆˆ 1..ğ‘› â„“ = â„“ â€² âŠ” model
Î“ âŠ¢ ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›) : â„“

(For)
Î“ âŠ¢ ğ¸1 : (int, â„“)

Î“ âŠ¢ ğ¸2 : (int, â„“)

Î“, ğ‘¥ : (int, â„“) âŠ¢ ğ‘† : â„“
Î“ âŠ¢ for(ğ‘¥ in ğ¸1 : ğ¸2) ğ‘† : â„“

ğ‘¥ âˆ‰ dom(Î“)

ğ‘¥ âˆ‰ ğ‘Š (ğ‘†)

In these rules, we make use of the following notation (see Appendix A for precise definitions).
â€¢ ğ‘Š (ğ‘†): the set of variables ğ‘¥ that have been assigned to in ğ‘†.
â€¢ ğ‘…Î“âŠ¢â„“ (ğ‘†): the set of variables ğ‘¥ that are read at level â„“ in ğ‘†.
â€¢ ğ‘ŠÎ“âŠ¢â„“ (ğ‘†): the set of variables ğ‘¥ of level â„“ that have been assigned to in ğ‘†.
â€¢ (cid:101)ğ‘ŠÎ“âŠ¢â„“ (ğ‘†): the set of variables ğ‘¥ of level â„“ that have been âˆ¼-ed in ğ‘†.
â€¢ ğ‘Š (cid:101)ğ‘ŠÎ“âŠ¢â„“ (ğ‘†) = ğ‘ŠÎ“âŠ¢â„“ (ğ‘†) âˆª (cid:101)ğ‘ŠÎ“âŠ¢â„“ (ğ‘†)
The intention in SlicStan is that statements of level â„“ are executed before those of â„“ â€² if â„“ < â„“ â€². In
order to follow that implementation strategy without reordering possibly non-commutative pairs
of statements, we impose the condition S(ğ‘†1, ğ‘†2) when we sequence ğ‘†1 and ğ‘†2 in (Seq).

Definition 1 (Shreddable seq). S(ğ‘†1, ğ‘†2) â‰œ âˆ€â„“1, â„“2.(â„“2 < â„“1) =â‡’ ğ‘…Î“âŠ¢â„“1 (ğ‘†1) âˆ© ğ‘ŠÎ“âŠ¢â„“2 (ğ‘†2) = âˆ….

For example, this excludes the following problematic program:

data real sigma = 1;
model real mu âˆ¼ normal(0, sigma);
sigma = 2;

Above, sigma and the statements sigma=1 and sigma=2 are of level data, which means they
should be executed before the statement mu âˆ¼ normal(0,sigma), which is of level model. However,
this would change the intended semantics of the program, giving mu a N (0, 2) prior instead of
the intended N (0, 1) prior. This problematic program fails to typecheck in SlicStan, as it is not
shreddable: Â¬S(mu âˆ¼ normal(0,sigma), sigma = 2).

Definition 2 (Generative seq). G(ğ‘†1, ğ‘†2) â‰œ âˆ€â„“ â‰  model. (cid:101)ğ‘ŠÎ“âŠ¢â„“ (ğ‘†1) âˆ© ğ‘Š (cid:101)ğ‘ŠÎ“âŠ¢â„“ (ğ‘†2) = âˆ… âˆ§

ğ‘Š (cid:101)ğ‘ŠÎ“âŠ¢â„“ (ğ‘†1) âˆ© (cid:101)ğ‘ŠÎ“âŠ¢â„“ (ğ‘†2) = âˆ…

To be able to read ğ‘¥ âˆ¼ N (0, 1) at level genqant, depending on the context, either as a prob-
abilistic assignment to ğ‘¥ or as a density contribution, we impose the condition G(ğ‘†1, ğ‘†2) when
we sequence ğ‘†1 and ğ‘†2. This excludes problematic programs like the following, in which the
multiple assignments to y create a discrepancy between the density semantics of the program
ğ‘ (ğ‘¦) = N (ğ‘¦ | 0, 1)N (ğ‘¦ | 0, 1) and the sampling-based semantics of the program y = 5.

genquant real y âˆ¼ normal(0, 1);
y âˆ¼ normal(0, 1);
y = 5;

3 Here we use Î“ (ğ¿) to look up the type of the L-value ğ¿ in Î“. Sometimes we will use an overloaded meaning of this notation
(Definition 14) to look-up the level type of a general expression. Which Î“ (.) we refer to will be clear from context.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:7

This problematic program fails to typecheck in SlicStan owing to the G constraint:
Â¬G(y âˆ¼ normal(0,1), y âˆ¼ normal(0,1)), and also Â¬G(y âˆ¼ normal(0,1), y = 5).

2.3 Operational Semantics of SlicStan Statements
In this paper, we use a modified version of the semantics given in Gorinova et al. [2019]. We extend
the call-by-value operational semantics given in that paper, and derive a more equational form that
also includes the generated quantities.

We define a standard big-step operational semantics for SlicStan expressions and statements:

Big-step Relation

(ğ‘ , ğ¸) â‡“ ğ‘‰
(ğ‘ , ğ‘†) â‡“ (ğ‘  â€², ğ‘¤)

expression evaluation
statement evaluation

Here, ğ‘  and ğ‘  â€² are states, ğ‘‰ is a value and ğ‘¤ âˆˆ R>0 is a weight. Our statements can read and write the
state with arbitrary destructive updates. The weight can be thought of as an element of state that
stores a positive real value which only gets accessed by multiplying it with the value of an expression
ğ¸, through the use of factor(ğ¸)-statements. It can only be read through a target(ğ‘†)-statement which
initialises the weight to 1, evaluates the statement ğ‘† and returns the final weight.

Formally, states and values are defined as follows.

Values and States:

ğ‘‰ ::=
ğ‘
[ğ‘‰1, . . . , ğ‘‰ğ‘›]

value

constant
array

ğ‘  ::= ğ‘¥1 â†¦â†’ ğ‘‰1, . . . , ğ‘¥ğ‘› â†¦â†’ ğ‘‰ğ‘›

ğ‘¥ğ‘– distinct

state (finite map from variables to values)

In the rest of the paper, we use the notation for states ğ‘  = ğ‘¥1 â†¦â†’ ğ‘‰1, . . . , ğ‘¥ğ‘› â†¦â†’ ğ‘‰ğ‘›:
â€¢ ğ‘  [ğ‘¥ â†¦â†’ ğ‘‰ ] is the state ğ‘ , but where the value of ğ‘¥ is updated to ğ‘‰ if ğ‘¥ âˆˆ dom(ğ‘ ), or the element

ğ‘¥ â†¦â†’ ğ‘‰ is added to ğ‘  if ğ‘¥ âˆ‰ dom(ğ‘ ).

â€¢ ğ‘  [âˆ’ğ‘¥] is the state s, but where ğ‘¥ is removed from the domain of ğ‘  (if it were present).
We also define lookup and update operations on values:
â€¢ If ğ‘ˆ is an ğ‘›-dimensional array value for ğ‘› â‰¥ 0 and ğ‘1, . . . , ğ‘ğ‘› are suitable indexes into ğ‘ˆ , then

the lookup ğ‘ˆ [ğ‘1] . . . [ğ‘ğ‘›] is the value in ğ‘ˆ indexed by ğ‘1, . . . , ğ‘ğ‘›.

â€¢ If ğ‘ˆ is an ğ‘›-dimensional array value for ğ‘› â‰¥ 0 and ğ‘1, . . . , ğ‘ğ‘› are suitable indexes into ğ‘ˆ , then
the (functional) update ğ‘ˆ [ğ‘1] . . . [ğ‘ğ‘›] := ğ‘‰ is the array that is the same as ğ‘ˆ except that the
value indexed by ğ‘1, . . . , ğ‘ğ‘› is ğ‘‰ .

The relation â‡“ is deterministic but partial, as we do not explicitly handle error states. The purpose
of the operational semantics is to define a density function in Â§Â§ 2.4, and any errors lead to the
density being undefined. The big-step semantics is defined as follows.

Operational Semantics of Expressions:

(Eval Const)

(Eval Var)
ğ‘‰ = ğ‘  (ğ‘¥)

ğ‘¥ âˆˆ dom(ğ‘ )

(ğ‘ , ğ‘) â‡“ ğ‘

(ğ‘ , ğ‘¥) â‡“ ğ‘‰

(Eval Arr)

(ğ‘ , ğ¸ğ‘– ) â‡“ ğ‘‰ğ‘– âˆ€ğ‘– âˆˆ 1..ğ‘›
(ğ‘ , [ğ¸1, . . . , ğ¸ğ‘›]) â‡“ [ğ‘‰1, . . . , ğ‘‰ğ‘›]

(Eval ArrEl)
(ğ‘ , ğ¸1 â‡“ ğ‘‰ )

(ğ‘ , ğ¸2 â‡“ ğ‘)

(ğ‘ , ğ¸1 [ğ¸2]) â‡“ ğ‘‰ [ğ‘]

(Eval PrimCall)4
(ğ‘ , ğ¸ğ‘– ) â‡“ ğ‘‰ğ‘– âˆ€ğ‘– âˆˆ 1 . . . ğ‘› ğ‘‰ = ğ‘“ (ğ‘‰1, . . . , ğ‘‰ğ‘›)
(ğ‘ , ğ‘“ (ğ¸1, . . . , ğ¸ğ‘›)) â‡“ ğ‘‰

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:8

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

(Eval ArrComp)5
(ğ‘ , ğ¸1) â‡“ ğ‘›

(ğ‘ , ğ¸2) â‡“ ğ‘š (ğ‘ , ğ¸ [ğ‘–/ğ‘¥]) â‡“ ğ‘‰ğ‘–, âˆ€ğ‘› â‰¤ ğ‘– â‰¤ ğ‘š

(ğ‘ , [ğ¸ | ğ‘¥ in ğ¸1 : ğ¸2]) â‡“ [ğ‘‰ğ‘›, . . . , ğ‘‰ğ‘š]

(Eval Target)
(ğ‘ , ğ‘†) â‡“ (ğ‘  â€², ğ‘¤)
(ğ‘ , target(ğ‘†)) â‡“ ğ‘¤

Operational Semantics of Statements:

(Eval Assign) (where ğ¿ = ğ‘¥ [ğ¸1] . . . [ğ¸ğ‘›])
(ğ‘ , ğ¸ğ‘– ) â‡“ ğ‘‰ğ‘– âˆ€ğ‘– âˆˆ 1..ğ‘›

(ğ‘ , ğ¸) â‡“ ğ‘‰ ğ‘ˆ = ğ‘  (ğ‘¥) ğ‘ˆ â€² = (ğ‘ˆ [ğ‘‰1] . . . [ğ‘‰ğ‘›] := ğ‘‰ )
(ğ‘ , ğ¿ = ğ¸) â‡“ (ğ‘  [ğ‘¥ â†¦â†’ ğ‘ˆ â€²], 1)

(Eval Skip)

(ğ‘ , skip) â‡“ (ğ‘ , 1)

(Eval ForTrue)
{(ğ‘ , ğ¸ğ‘– ) â‡“ ğ‘ğ‘– }ğ‘–=1,2

(Eval Seq)
(ğ‘ , ğ‘†1) â‡“ (ğ‘  â€², ğ‘¤)

(ğ‘  â€², ğ‘†2) â‡“ (ğ‘  â€²â€², ğ‘¤ â€²)

(Eval ForFalse)
(ğ‘ , ğ¸1) â‡“ ğ‘1

(ğ‘ , ğ¸2) â‡“ ğ‘2

ğ‘1 > ğ‘2

(ğ‘ , ğ‘†1; ğ‘†2) â‡“ (ğ‘  â€²â€², ğ‘¤ âˆ— ğ‘¤ â€²)

(ğ‘ , for(ğ‘¥ in ğ¸1 : ğ¸2) ğ‘†) â‡“ (ğ‘ , 1)

ğ‘1 â‰¤ ğ‘2

(ğ‘  [ğ‘¥ â†¦â†’ ğ‘1], ğ‘†) â‡“ (ğ‘  â€², ğ‘¤)

(ğ‘  â€²[âˆ’ğ‘¥], for(ğ‘¥ in (ğ‘1 + 1) : ğ‘2) ğ‘†) â‡“ (ğ‘  â€²â€², ğ‘¤ â€²)

(ğ‘ , for(ğ‘¥ in ğ¸1 : ğ¸2) ğ‘†) â‡“ (ğ‘  â€²â€², ğ‘¤ âˆ— ğ‘¤ â€²)

(Eval IfTrue)
(ğ‘ , ğ¸) â‡“ ğ‘ â‰  0.0

(ğ‘ , ğ‘†1) â‡“ (ğ‘  â€², ğ‘¤)

(ğ‘ , if(ğ¸) ğ‘†1 else ğ‘†2) â‡“ (ğ‘  â€², ğ‘¤)

(Eval IfFalse)
(ğ‘ , ğ¸) â‡“ 0.0
(ğ‘ , ğ‘†2) â‡“ (ğ‘  â€², ğ‘¤)
(ğ‘ , if(ğ¸) ğ‘†1 else ğ‘†2) â‡“ (ğ‘  â€², ğ‘¤)

(Eval Factor)
(ğ‘ , ğ¸) â‡“ ğ‘‰
(ğ‘ , factor(ğ¸)) â‡“ (ğ‘ , ğ‘‰ )

(Eval Sample)6
(ğ‘ , ğ¿) â‡“ ğ‘‰

(ğ‘ , ğ¸ğ‘– ) â‡“ ğ‘‰ğ‘–, âˆ€1 â‰¤ ğ‘– â‰¤ ğ‘› ğ‘‰ â€² = ğ‘‘ (ğ‘‰ |ğ‘‰1, . . . , ğ‘‰ğ‘›)

(ğ‘ , ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›)) â‡“ (ğ‘ , ğ‘‰ â€²)

Most rules of the big-step operational semantics are standard, with the exception of (Eval
Factor) and (Eval Sample), which correspond to the PPL-specific language constructs factor and
ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›). While we refer to the latter construct as probabilistic assignment, its formal
semantics is not that of an assignment statement: both the left and the right hand-side of the
â€œassignmentâ€ are evaluated to a value, in order for the density contribution ğ‘‘ (ğ‘‰ | ğ‘‰1, . . . , ğ‘‰ğ‘›) to be
evaluated and factored into the weight of the current execution trace. Contrary to (Eval Assign),
there is no binding of a result to a variable in (Eval Sample). Of course, as is common in probabilistic
programming, it might, at times7, be beneficial to execute these statements as actual probabilistic
assignments. Our treatment of these statements is agnostic of such implementation details, however.
The design of the type system ensures that information can flow from a level â„“ to a higher one
â„“ â€² â‰¥ â„“, but not a lower one â„“ â€² < â„“: a noninterference result. To state this formally, we introduce the
notions of conformance between a state ğ‘  and a typing environment Î“ and â„“-equality of states.

We define a conformance relation on states ğ‘  and typing environments Î“. A state ğ‘  conforms to

an environment Î“, whenever ğ‘  provides values of the correct types for the variables used in Î“:
Conformance Relation:

ğ‘  |= Î“

state ğ‘  conforms to environment Î“

Rule for the Conformance Relation:

4 ğ‘“ (ğ‘‰1, . . . , ğ‘‰ğ‘›) means applying the built-in function ğ‘“ on the values ğ‘‰1, . . . , ğ‘‰ğ‘›.
5Here, we write ğ¸ [ğ¸â€²/ğ‘¥ ] for the usual capture avoiding substitution of ğ¸â€² for ğ‘¥ in ğ¸.
6By ğ‘‘ (ğ‘‰ |ğ‘‰1, . . . , ğ‘‰ğ‘›), we mean the result of evaluating the intended built-in conditional distribution ğ‘‘ on ğ‘‰ , ğ‘‰1, . . . , ğ‘‰ğ‘›.
7For example, in our Stan backend for SlicStan, if such a statement is of level model, it will be executed as density contribution,
while if it is of level genqant, it will be executed as a probabilistic assignment.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:9

(Stan State)

ğ‘‰ğ‘– |= ğœğ‘– âˆ€ğ‘– âˆˆ ğ¼

(ğ‘¥ğ‘– â†¦â†’ ğ‘‰ğ‘– )ğ‘– âˆˆğ¼

|= (ğ‘¥ğ‘– : ğœğ‘– )ğ‘– âˆˆğ¼

Here, ğ‘‰ |= ğœ denotes that the value ğ‘‰ is of type ğœ, and it has the following definition:
â€¢ ğ‘ |= int, if ğ‘ âˆˆ Z, and ğ‘ |= real, if ğ‘ âˆˆ R.
â€¢ [ğ‘‰1, . . . , ğ‘‰ğ‘›] |= ğœ [ğ‘›], if âˆ€ğ‘– âˆˆ 1 . . . ğ‘›.ğ‘‰ğ‘– |= ğœ.
Definition 3 (â„“-eqal states).

Given a typing environment Î“, states ğ‘ 1 |= Î“ and ğ‘ 2 |= Î“ are â„“-equal for level â„“ (written ğ‘ 1 â‰ˆâ„“ ğ‘ 2), if
they differ only for variables of a level strictly higher than â„“:

Lemma 1 (Noninterference of âŠ¢).

ğ‘ 1 â‰ˆâ„“ ğ‘ 2 â‰œ âˆ€ğ‘¥ : (ğœ, â„“ â€²) âˆˆ Î“. (â„“ â€² â‰¤ â„“ =â‡’ ğ‘ 1(ğ‘¥) = ğ‘ 2(ğ‘¥))

Suppose ğ‘ 1 |= Î“, ğ‘ 2 |= Î“, and ğ‘ 1 â‰ˆâ„“ ğ‘ 2 for some â„“. Then for SlicStan statement ğ‘† and expression ğ¸:

(1) If Î“ âŠ¢ ğ¸ : (ğœ, â„“) and (ğ‘ 1, ğ¸) â‡“ ğ‘‰1 and (ğ‘ 2, ğ¸) â‡“ ğ‘‰2 then ğ‘‰1 = ğ‘‰2.
(2) If Î“ âŠ¢ ğ‘† : â„“ and (ğ‘ 1, ğ‘†) â‡“ ğ‘  â€²
2.
1 â‰ˆâ„“ ğ‘  â€²

1, ğ‘¤1 and (ğ‘ 2, ğ‘†) â‡“ ğ‘  â€²

2, ğ‘¤2 then ğ‘  â€²

Proof. (1) follows by rule induction on the derivation Î“ âŠ¢ ğ¸ : (ğœ, â„“), and using that if Î“ âŠ¢ ğ¸ : (ğœ, â„“),
ğ¸ reads ğ‘¥ and Î“(ğ‘¥) = (ğœ â€², â„“ â€²), then â„“ â€² â‰¤ â„“. (2) follows by rule induction on the derivation Î“ âŠ¢ ğ‘† : â„“
â–¡
and using (1). We present more details of the proof in Appendix A.

2.4 Density Semantics
The semantic aspect of a SlicStan program Î“, ğ‘† that we are the most interested in is the final
weight ğ‘¤ obtained after evaluating the program ğ‘†. This is the value the program computes for
the unnormalised joint density ğ‘âˆ— (x) = ğ‘âˆ— (D, ğœ½, ğ‘„) over the data D, the model parameters ğœ½ , and
generated quantities ğ‘„ of the program (see Â§Â§ 2.6). Given a program Î“, ğ‘†, we separate the typing
environment Î“ into disjoint parts: Î“ğœ and Î“x, such that Î“ğœ contains precisely the variables that are
deterministically assigned in ğ‘† and Î“x contains those which never get deterministically assigned;
that is the variables x with respect to which we define the target unnormalised density ğ‘âˆ— (x):

Î“ğœ = {(ğ‘¥ : ğ‘‡ ) âˆˆ Î“ | ğ‘¥ âˆˆ ğ‘Š (ğ‘†)}

Î“x = Î“ \ Î“ğœ .

Similarly, any conforming state ğ‘  |= Î“ separates as ğœ âŠ x with

ğœ = {(ğ‘¥ â†¦â†’ ğ‘‰ ) âˆˆ ğ‘  | ğ‘¥ âˆˆ ğ‘Š (ğ‘†)} x = ğ‘  \ ğœ.

Then, ğœ |= Î“ğœ and x |= Î“x.

The semantics of a SlicStan program Î“ğœ, Î“x, ğ‘† is a function

yields a pair of a state ğœ â€² and a weight ğ‘¤, such that:
ğ‘†
(cid:74)

(cid:75)

(ğœ)(x) = ğœ â€², ğ‘¤, where ğœ âŠ x, ğ‘† â‡“ ğœ â€² âŠ x, ğ‘¤ .

on states ğœ |= Î“ğœ and x |= Î“x that

ğ‘†
(cid:74)

(cid:75)

ğ‘†
(cid:74)

The function

use the notation:
ğ‘†
(cid:74)
density semantics of Î“, ğ‘†. We will be particularly interested in the density semantics.

We will sometimes refer only to one of the two elements of the pair ğœ, ğ‘¤. In those cases we
ğ‘ the
(cid:75)

ğ‘  (ğœ)(x),
(cid:75)
ğ‘ (ğœ) is some positive function ğœ™ (x) of x. If x1, x2 is a partitioning of x and
âˆ« ğœ™ (x)dx1 is finite, we say ğœ™ (x) is an unnormalised density corresponding to the normalised
(cid:75)
density ğ‘ (x1 | x2) = ğœ™ (x)/âˆ« ğœ™ (x)dx1 over x1 and we write
ğ‘ (ğœ)(x) âˆ ğ‘ (x1 | x2). Sometimes,
(cid:75)
when ğœ is clear from context, we will leave it implicit and simply write ğ‘ (x) for ğ‘ (x; ğœ).

ğ‘  the state semantics and
(cid:75)

ğ‘ (ğœ)(x) =
(cid:75)

(ğœ)(x). We call

ğ‘†
(cid:74)
ğ‘†
(cid:74)

ğ‘†
(cid:74)

ğ‘†
(cid:74)

ğ‘†
(cid:74)

(cid:75)

Next, we observe how the state and density semantics compose.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:10

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

Lemma 2 (Semantics composes). The state and density semantics compose as follows:

ğ‘†1; ğ‘†2
(cid:74)

ğ‘  (ğœ)(x) =
(cid:75)

ğ‘†2
(cid:74)

ğ‘  (
(cid:75)

ğ‘†2
(cid:74)

ğ‘  (ğœ)(x))(x)
(cid:75)

ğ‘†1; ğ‘†2
(cid:74)

ğ‘ (ğœ)(x) =
(cid:75)

ğ‘†1
(cid:74)

ğ‘†2
ğ‘ (ğœ)(x)Ã—
(cid:74)
(cid:75)

ğ‘ (
(cid:75)

ğ‘†1
(cid:74)

ğ‘  (ğœ)(x))(x)
(cid:75)

Throughout the paper we use the following notation to separate the store in a concise way.
Definition 4 (Î“â„“ (ğ‘ ) or ğ‘ â„“ ).

For a typing environment Î“ and a store ğ‘  |= Î“, let Î“â„“ (ğ‘ ) = {(ğ‘¥ â†¦â†’ ğ‘‰ ) âˆˆ ğ‘  | Î“(ğ‘¥) = (_, â„“)}. When it is
clear which typing environment the notation refers to, we write simply ğ‘ â„“ instead of Î“â„“ (ğ‘ ).

Using this definition, we re-state the noninterference result in the following convenient form.

Lemma 3 (Noninterference of âŠ¢ reformulated). Let Î“ğœ, Î“x âŠ¢ ğ‘† be a well-typed SlicStan
program. For all levels â„“ âˆˆ {data, model, genquant}, there exist unique functions ğ‘“â„“ , such that for all
ğœ |= Î“ğœ , x |= Î“x and ğœ â€² such that

â„“ = ğ‘“â„“ ({ğœâ„“â€², xâ„“â€²
ğœ â€²

| â„“ â€² â‰¤ â„“ }).

ğ‘†
(cid:74)

ğ‘  (ğœ)(x) = ğœ â€²,
(cid:75)

2.5 Shredding and Translation to Stan
A key aim of SlicStan is to rearrange the input program into three phases of execution, corresponding
to the levels of the type system: data preprocessing, core model code to run MCMC or another
inference algorithm on, and genqant, or generated quantities, which amount to sample post-
processing after inference is performed. The motivation for these phases is that they all naturally
appear in the workflow of probabilistic programming. The blocks of the Stan are built around this
phase distinction, and compilation of SlicStan to Stan and comparable back-ends requires it.

The phases impose different restrictions on the code and make it incur differing computational
costs. The model phase is by far the most expensive to evaluate: code in this phase tends to be
executed repeatedly within the inner loop of an inference algorithm like an MCMC method. Further,
it tends to be automatically differentiated [Griewank and Walther 2008] in case gradient-based
inference algorithms are used, which restricts the available programming features and increases
the space and time complexity of evaluation. Type inference in SlicStan combined with shredding
allows the user to write their code without worrying about the performance of different phases, as
code will be shredded into its optimal phase of execution.

The shredding relation is in the core of this rearrangement. Shredding takes a SlicStan statement
ğ‘† and splits it into three single-level statements (Definition 5). That is, ğ‘† â‡•Î“ ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ means we
split ğ‘† into sub-statements ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ , were ğ‘†ğ· mentions only data variables, ğ‘†ğ‘€ mentions data
and model variables, and ğ‘†ğ‘„ is the rest of the program, and such that the composition ğ‘†ğ· ; ğ‘†ğ‘€ ; ğ‘†ğ‘„
behaves the same as the original program ğ‘†. When combined with type inference, shredding
automatically determines optimal statement placement, such that only necessary work is executed
in the â€˜heavy-weightâ€™ model part of inference.

We adapt the shredding from [Gorinova et al. 2019], so that the following holds for the three

sub-statements of a shredded well-typed SlicStan program Î“ âŠ¢ ğ‘†:

â€¢ ğ‘†ğ· implements deterministic data preprocessing: no contributions to the density are allowed.
â€¢ ğ‘†ğ‘€ is the inference core: it is the least restrictive of the three slices â€” either or both of ğ‘†ğ·
and ğ‘†ğ‘„ can be merged into ğ‘†ğ‘€ . It can involve contributions to the density which require
advanced inference for sampling. Therefore, this is the part of the program which requires
the most computation during inference (in Stan, what is run inside HMC);

â€¢ ğ‘†ğ‘„ represents sample post-processing: any contributions to the density are generative. That is,

they can immediately be implemented using draws from random number generators.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:11

In terms of inference, we can run ğ‘†ğ· once as a pre-processing step. Then use a suitable inference
algorithm for ğ‘†ğ‘€ (in the case of Stan, thatâ€™s HMC, but we can use other MCMC or VI algorithms),
and, finally, we use ancestral sampling for ğ‘†ğ‘„ . 8
Shredding Relation

ğ‘† â‡•Î“ (ğ‘†ğ· , ğ‘†ğ‘€, ğ‘†ğ‘„ )

statement shredding

Shredding Rules for Statements:

(Shred Assign)

Î“(ğ¿) = (_, data) â†’ ğ‘†ğ· = ğ¿ = ğ¸, ğ‘†ğ‘€ = ğ‘†ğ‘„ = skip
Î“(ğ¿) = (_, model) â†’ ğ‘†ğ‘€ = ğ¿ = ğ¸, ğ‘†ğ· = ğ‘†ğ‘„ = skip
Î“(ğ¿) = (_, genqant) â†’ ğ‘†ğ‘„ = ğ¿ = ğ¸, ğ‘†ğ· = ğ‘†ğ‘€ = skip
ğ¿ = ğ¸ â‡•Î“ (ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ )

(Shred Factor)

Î“(ğ¸) = data â†’ ğ‘†ğ· = factor(ğ¸), ğ‘†ğ‘€ = ğ‘†ğ‘„ = skip
Î“(ğ¸) = model â†’ ğ‘†ğ‘€ = factor(ğ¸), ğ‘†ğ· = ğ‘†ğ‘„ = skip
Î“(ğ¸) = genqant â†’ ğ‘†ğ‘„ = factor(ğ¸), ğ‘†ğ· = ğ‘†ğ‘€ = skip
factor(ğ¸) â‡•Î“ (ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ )

(Shred Seq)
ğ‘†1 â‡•Î“ ğ‘†ğ·1, ğ‘†ğ‘€1, ğ‘†ğ‘„1
ğ‘†2 â‡•Î“ ğ‘†ğ·2, ğ‘†ğ‘€2, ğ‘†ğ‘„2
ğ‘†1; ğ‘†2 â‡•Î“ (ğ‘†ğ·1; ğ‘†ğ·2 ), (ğ‘†ğ‘€1; ğ‘†ğ‘€2 ), (ğ‘†ğ‘„1; ğ‘†ğ‘„2)

(Shred Skip)

skip â‡•Î“ (skip, skip, skip)

(Shred Sample)

Î“(ğ¿, ğ¸1, . . . , ğ¸ğ‘›) = data â†’ ğ‘†ğ· = ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›), ğ‘†ğ‘€ = ğ‘†ğ‘„ = skip)
Î“(ğ¿, ğ¸1, . . . , ğ¸ğ‘›) = model â†’ ğ‘†ğ‘€ = ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›), ğ‘†ğ· = ğ‘†ğ‘„ = skip)
Î“(ğ¿, ğ¸1, . . . , ğ¸ğ‘›) = genqant â†’ ğ‘†ğ‘„ = ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›), ğ‘†ğ· = ğ‘†ğ‘€ = skip)
ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›) â‡•Î“ (ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ )

(Shred If)

ğ‘†1 â‡•Î“ (ğ‘†ğ·1, ğ‘†ğ‘€1, ğ‘†ğ‘„1)

ğ‘†2 â‡•Î“ (ğ‘†ğ·2, ğ‘†ğ‘€2, ğ‘†ğ‘„2)

if(ğ‘”) ğ‘†1 else ğ‘†2 â‡•Î“ (if(ğ‘”) ğ‘†ğ·1 else ğ‘†ğ·2 ), (if(ğ‘”) ğ‘†ğ‘€1 else ğ‘†ğ‘€2), (if(ğ‘”) ğ‘†ğ‘„1 else ğ‘†ğ‘„2)
(Shred For)

ğ‘† â‡•Î“ (ğ‘†ğ· , ğ‘†ğ‘€, ğ‘†ğ‘„ )
for(ğ‘¥ in ğ‘”1 : ğ‘”2) ğ‘† â‡•Î“ (for(ğ‘¥ in ğ‘”1 : ğ‘”2) ğ‘†ğ· ), (for(ğ‘¥ in ğ‘”1 : ğ‘”2) ğ‘†ğ‘€ ), (for(ğ‘¥ in ğ‘”1 : ğ‘”2) ğ‘†ğ‘„ )

Here, Î“(ğ¸) (Definition 14) gives the principal type of an expression ğ¸, while Î“(ğ¸1, . . . , ğ¸ğ‘›)

(Definition 15) gives the least upper bound of the principal types of ğ¸1, . . . , ğ¸ğ‘›.

The (Shred If) and (Shred For) rules make sure to shred if and for statements so that they are
separated into parts which can be computed independently at each of the three levels. Note that the
usage of if and for guards is simplified, to avoid stating rules for when the guard(s) are of different
levels. For example, if we have a statement if(ğ¸) ğ‘†1 else ğ‘†2, where ğ¸ is of level model, we cannot
access ğ¸ at level data, thus the actual shredding rule we would use is:

(Shred If Model Level)

ğ‘†1 â‡•Î“ (ğ‘†ğ·1, ğ‘†ğ‘€1, ğ‘†ğ‘„1)

ğ‘†2 â‡•Î“ (ğ‘†ğ·2, ğ‘†ğ‘€2, ğ‘†ğ‘„2)

if(ğ‘”) ğ‘†1 else ğ‘†2 â‡•Î“ skip, (if(ğ‘”) ğ‘†ğ·1 ; ğ‘†ğ‘€1 else ğ‘†ğ·2; ğ‘†ğ‘€2), (if(ğ‘”) ğ‘†ğ‘„1 else ğ‘†ğ‘„2)

8Ancestral (or forward) sampling refers to the method of sampling from a joint distribution by individually sampling
variables from the factors constituting the joint distribution. For example, we can sample from ğ‘ (ğ‘¥, ğ‘¦) = ğ‘ (ğ‘¥)ğ‘ (ğ‘¦ | ğ‘¥) by
randomly generating Ë†ğ‘¥ according to ğ‘ (ğ‘¥), and then randomly generating Ë†ğ‘¦ according to ğ‘ (ğ‘¦ | ğ‘¥ = Ë†ğ‘¥).

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:12

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

These shredding rules follow very closely those given by Gorinova et al. [2019]. The main
difference is that sample statements (ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›)) are allowed to be of genqant level and
can be included in the last, generative slice of the program (see rule (Shred Sample)). In other words,
such genqant sample statements are those statements that can be interpreted as probabilistic
assignment (using random number generator functions) to directly sample from the posterior
distribution according to ancestral sampling.

We provide proofs for the following key results in Appendix A: shredding produces single-level

statements (Definition 5 and Lemma 4) and shredding is semantics preserving (Lemma 6).

Intuitively, a single-level statement of level â„“ is one that updates only variables of level â„“.

Definition 5 (Single-level Statement Î“ âŠ¢ â„“ (ğ‘†)). We define single-level statements ğ‘† of level â„“

with respect to Î“ (written Î“ âŠ¢ â„“ (ğ‘†)), by induction:
Single Level Statements:
(Assign Single)

Î“(ğ‘¥) = (_, â„“)
Î“ âŠ¢ â„“ (ğ‘¥ [ğ¸1] Â· Â· Â· [ğ¸ğ‘›] = ğ¸)

(Seq Single)
Î“ âŠ¢ â„“ (ğ‘†)

Î“ âŠ¢ â„“ (ğ‘† â€²)

Î“ âŠ¢ â„“ (ğ‘†; ğ‘† â€²)

(For Single)

Î“, ğ‘¥ : (int, â„“) âŠ¢ â„“ (ğ‘†)
Î“ âŠ¢ â„“ (for(ğ‘¥ in ğ¸1 : ğ¸2)ğ‘†)

(If Single)
Î“ âŠ¢ â„“ (ğ‘†2)
Î“ âŠ¢ â„“ (ğ‘†1)
Î“ âŠ¢ â„“ (if(ğ¸) ğ‘†1 else ğ‘†2)

(Skip Single)

Î“ âŠ¢ â„“ (skip)

(Factor Single)
Î“ âŠ¢ ğ¸ : â„“ âˆ€â„“ â€² < â„“.Î“ âŠ¬ ğ¸ : â„“ â€²
Î“ âŠ¢ â„“ (factor(ğ¸))

(Sample Single)
Î“ âŠ¢ ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›) : â„“ âˆ€â„“ â€² < â„“.Î“ âŠ¬ ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›) : â„“ â€²
Î“ âŠ¢ â„“ (ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›))

Lemma 4 (Shredding produces single-level statements).

Î“ âŠ¢ ğ‘† âˆ§ ğ‘† â‡•Î“ (ğ‘†ğ· , ğ‘†ğ‘€, ğ‘†ğ‘„ ) =â‡’ Î“ âŠ¢ data(ğ‘†ğ· ) âˆ§ Î“ âŠ¢ model(ğ‘†ğ‘€ ) âˆ§ Î“ âŠ¢ genquant(ğ‘†ğ‘„ )

We prove a result about the effect of single-level statements on the store and weight of well-typed
programs (Lemma 5). Intuitively, this result shows that a single-level statement of level â„“ acts on
the state and weight in a way that is independent of levels greater than â„“.

Lemma 5 (Property of single-level statements).

Let Î“ğœ, Î“x, ğ‘† be a SlicStan program, such that ğ‘† is a single-level statement of level â„“, Î“ âŠ¢ â„“ (ğ‘†). Then
there exist unique functions ğ‘“ and ğœ™, such that for any ğœ, x |= Î“ğœ, Î“x:

(ğœ)(ğ‘¥) = ğ‘“ (ğœ â‰¤â„“, xâ‰¤â„“ ) âˆª ğœ>â„“, ğœ™ (ğœ â‰¤â„“ )(xâ‰¤â„“ ),
where we write ğœ â‰¤â„“ = {(ğ‘¥ â†¦â†’ ğ‘‰ ) âˆˆ ğœ | Î“ğœ (ğ‘¥) = (_, â„“)} and ğœ>â„“ = ğœ \ ğœ â‰¤â„“ .

ğ‘†
(cid:74)

(cid:75)

If Î“ âŠ¢ ğ‘† : data and ğ‘† â‡•Î“ (ğ‘†ğ· , ğ‘†ğ‘€, ğ‘†ğ‘„ ) then

Lemma 6 (Semantic Preservation of â‡•Î“).
ğ‘†
(cid:74)

(cid:75)

=

ğ‘†ğ· ; ğ‘†ğ‘€ ; ğ‘†ğ‘„
(cid:74)

(cid:75)

.

2.6 Density Factorisation
As an extension of [Gorinova et al. 2019], we show that shredding induces a natural factorization of
the density implemented by the program: ğ‘ (D, ğœ½, ğ‘„) = ğ‘ (ğœ½, D)ğ‘ (ğ‘„ | ğœ½, D). 9 This means that we
can separate the program into a deterministic preprocessing part, a part that uses a â€˜heavy-weightâ€™
inference algorithm, such as HMC, and a part that uses simple ancestral sampling.

9Here, ğ‘ (ğ‘„ | ğœ½, D) denotes the conditional probability density of ğ‘„, given the values of ğœ½ and D.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:13

Theorem 1 (Shredding induces a factorisation of the density).

Suppose Î“ âŠ¢ ğ‘† : data and ğ‘† â‡•Î“ ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ and Î“ = Î“ğœ, Î“D, Î“ğœ½ , Î“ğ‘„ . For all ğœ, D, ğœ½ , and ğ‘„: if
ğœ, D, ğœ½, ğ‘„ |= Î“ğœ, Î“D, Î“ğœ½ , Î“ğ‘„ , and

ğ‘ (ğœ)(D, ğœ½, ğ‘„) âˆ ğ‘ (D, ğœ½, ğ‘„) and (cid:101)ğ‘Š (ğ‘†ğ‘„ ) = dom(Î“ğ‘„ ) then:
(cid:75)

ğ‘†
(cid:74)

(1)
(2)

ğ‘ (ğœğ· )(D, ğœ½, ğ‘„) âˆ ğ‘ (ğœ½, D)
ğ‘†ğ‘€
(cid:75)
(cid:74)
ğ‘ (ğœğ‘€ )(D, ğœ½, ğ‘„) = ğ‘ (ğ‘„ | ğœ½, D)
ğ‘†ğ‘„
(cid:75)
(cid:74)
ğ‘  (ğœ)(D, ğœ½, ğ‘„), ğœğ‘€ =
where ğœğ· =
ğ‘†ğ‘€
(cid:74)
(cid:75)

ğ‘†ğ·
(cid:74)

ğ‘  (ğœğ· )(D, ğœ½, ğ‘„), and ğ‘ (D, ğœ½, ğ‘„) = ğ‘ (D, ğœ½ )ğ‘ (ğ‘„ | D, ğœ½ ).
(cid:75)
Proof. This follows by proving a more general result using induction on the structure of ğ‘†,
â–¡

Lemma 6, Lemma 2 and Lemma 4. See Appendix A for full proof.

The given SlicStan program ğ‘† defines a joint density ğ‘ (D, ğœ½, ğ‘„). By shredding we obtain a model
block ğ‘†ğ‘€ that defines ğ‘ (ğœ½, D) and a genqant block ğ‘†ğ‘„ that defines ğ‘ (ğ‘„ | ğœ½, D). Hence, inference
in Stan using these blocks recovers the semantics ğ‘ (D, ğœ½, ğ‘„) of the SlicStan program.

3 THEORY: CONDITIONAL INDEPENDENCE BY TYPING
This section presents the main theoretical contribution of the paper: an information flow type
system for conditional independence. We present a type system and show that a well-typed program
in that system is guaranteed to have certain conditional independencies in its density semantics. As
a reminder, determining the conditional independence relationships between variables is important,
as such relationships capture a qualitative summary of the specified model and can facilitate more
efficient inference. For example, in Â§ 4 we present an application that uses our type system: a
semantic-preserving transformation that allows for discrete parameters to be introduced in SlicStan,
which was previously not possible due to efficiency constraints.

Our aim is to optimise probabilistic programs by transforming abstract syntax trees or interme-
diate representations (as in the Stan compiler) that are close to abstract syntax. Hence, we seek a
way to compute conditional dependencies by a type-based source analysis, rather than by explicitly
constructing a separate graphical representation of the probabilsitic model.

Given three disjoint sets of random variables (RVs) ğ´, ğµ and ğ¶, we say that ğ´ is conditionally
independent of ğµ given ğ¶, written ğ´ âŠ¥âŠ¥ ğµ | ğ¶, if and only if their densities factorise as ğ‘ (ğ´, ğµ | ğ¶) =
ğ‘ (ğ´ | ğ¶)ğ‘ (ğµ | ğ¶). (An alternative formulation states that ğ´ âŠ¥âŠ¥ ğµ | ğ¶ if and only if ğ‘ (ğ´, ğµ, ğ¶) =
ğœ™1(ğ´, ğ¶)ğœ™2(ğµ, ğ¶) for some functions ğœ™1 and ğœ™2.) Deriving conditional independencies in the presence
of a graphical model (such as a factor graph10) is straightforward, which is why some PPLs focus on
building and performing inference on graphs (for example, Infer.NET [Minka et al. 2014]). However,
building and manipulating a factor graph in generative PPLs (e.g. Gen [Cusumano-Towner et al.
2019], Pyro [Uber AI Labs 2017], Edward2 [Tran et al. 2018], PyMC3 [Salvatier et al. 2016]) or
imperative density-based PPLs (SlicStan, Stan) is not straightforward. Dependencies between
modelled variables might be separated by various deterministic transformations, making it harder
to track the information flow, and â€“ more importantly â€“ more difficult to isolate parts of the model
needed for transformations such as variable elimination. In the case of SlicStan, each program can
still be thought of as specifying a factor graph implicitly. In this paper, we focus on the problem
of how to work with conditional independence information implicitly encoded in a probabilistic
program, without having access to an explicit factor graph. For example, consider Program A:

10A factor graph is a bipartite graph that shows the factorisation of a multivariable function. Variables are circular nodes,
and each factor of the function is a square node. An edge exists between a variable node ğ‘¥ and a factor node ğœ™ if and only if
ğœ™ is a function of ğ‘¥. See Program A and its corresponding factor graph as an example, or [Koller and Friedman 2009] for
details.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:14

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

A. Simple Hidden Markov Model (HMM)

ğ‘§1 âˆ¼ ğ‘ (ğœƒ0)

ğ‘§2 âˆ¼ ğ‘ (foo(ğœƒ0, ğ‘§1))

ğ‘§1

int<2> z1 âˆ¼ bern(ğœƒ0);
real ğœƒ1 = foo(ğœƒ0, z1);
int<2> z2 âˆ¼ bern(ğœƒ1);
real ğœ™1 = foo(1, z1);
real ğœ™2 = foo(1, z2);
int<2> y1 âˆ¼ bern(ğœ™1);
int<2> y2 âˆ¼ bern(ğœ™2);

ğ‘¦1 âˆ¼ ğ‘ (foo(1, ğ‘§1))

ğ‘¦2 âˆ¼ ğ‘ (foo(1, ğ‘§2))

ğ‘¦1

ğ‘§2

ğ‘¦2

The factor graph above represents the factorisation of the joint density function over the parame-
ters of the program: ğ‘ (ğ‘§1, ğ‘§2, ğ‘¦1, ğ‘¦2) = ğ‘ (ğ‘§1 | ğœƒ0)ğ‘ (ğ‘¦1 | foo(1, ğ‘§1))ğ‘ (ğ‘§2 | foo(ğœƒ0, ğ‘§1))ğ‘ (ğ‘¦2 | foo(1, ğ‘§2)).
Each of the four factors is represented by a square node in the graph, and it connects to the variables
(circle nodes) that the factor depends on. This representation is useful for thinking about conditional
independencies. For example, it is immediately evident from the graph that variables which connect
to the same square node cannot be conditionally independent as they share a factor. More generally,
if there is an (uninterrupted by observed variables) direct path between two variables, then these
two variables are not conditionally independent [Frey 2002].

When looking at the factor graph, it is straightforward to see that ğ‘§1 and ğ‘§2 are not conditionally
independent, and neither are ğ‘§1 and ğ‘¦1 nor ğ‘§2 and ğ‘¦2, as there is a direct path between each of
these pairs. When looking at the program, however, we need to reason about the information flow
through the deterministic variables ğœƒ1, ğœ™1 and ğœ™2 to reach the same conclusion.

Moreover, manipulation of the program based on conditional dependencies can also be more
difficult without a factor graph. As an example, consider the problem of variable elimination (which
we discuss in more details in Â§Â§ 4.3). If we are to eliminate ğ‘§1 in the factor graph, using variable
elimination, we would simply merge the factors directly connected to ğ‘§1, sum over ğ‘§1, and attach
the new factors to all former neighbours of ğ‘§1 (in this case ğ‘¦1 and ğ‘§2, but not ğ‘¦2). However, in the
case of an imperative program, we need to isolate all the statements that depend on ğ‘§1, and group
them together without changing the meaning of the program beyond the elimination:

B. HMM with ğ‘§1 marginalised out
factor(sum([target(

z1 âˆ¼ bern(ğœƒ0); real ğœƒ1 = foo(ğœƒ0, z1);
z2 âˆ¼ bern(ğœƒ1); real ğœ™1 = foo(1, z1);
y1 âˆ¼ bern(ğœ™1); ) | z1 in 1 : 2 ]));

real ğœ™2 = foo(1, z2);
int<2> y2 âˆ¼ bern(ğœ™2);

.

(cid:205)ğ‘§1 [ğ‘ (ğ‘§1 | ğœƒ0)
Ã—ğ‘ (ğ‘¦1 | foo(1, ğ‘§1))
Ã—ğ‘ (ğ‘§2 | foo(ğœƒ0, ğ‘§1)) ]

ğ‘¦1

ğ‘§2

ğ‘¦2

ğ‘¦2 âˆ¼ ğ‘ (foo(1, ğ‘§2))

We need a way to analyse the information flow to determine conditional independencies between
variables. In the example above, we can leave ğ‘¦2 out of the elimination of ğ‘§1, because ğ‘§1 and ğ‘¦2 are
conditionally independent given ğ‘§2, written ğ‘§1 âŠ¥âŠ¥ ğ‘¦2 | ğ‘§2.

To analyse the information flow, we introduce a novel type system, which we refer to via the
relation âŠ¢2. It works with a lower semi-lattice ({l1, l2, l3}, â‰¤) of levels, where l1 â‰¤ l2 and l1 â‰¤ l3
and l2 and l3 are unrelated. (Recall that a lower semi-lattice is a partial order in which any two
elements â„“1, â„“2 have a greatest lower bound â„“1 âŠ“ â„“2 but do not always have an upper bound.) A
well-typed program induces a conditional independence relationship for the (random) variables
(RVs) in the program: l2-RVs âŠ¥âŠ¥ l3-RVs | l1-RVs.

In the example above, this result allows us to eliminate l2-variables (ğ‘§1), while only considering
l1-variables (ğ‘¦1 and ğ‘§2) and knowing l3-variables (ğ‘¦2) are unaffected by the elimination. We can use

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:15

xl3

xl2

xl3

xl2

ğ‘†3
(cid:74)

ğ‘
(cid:75)

ğ‘†2
(cid:74)

ğ‘
(cid:75)

xl1

ğ‘†1
(cid:74)

ğ‘
(cid:75)

xl1

(a) Factor graph of variables of different levels.

(b) Information flow between levels.

Fig. 2. Intuition for the semi-lattice case l1 < l2 and l1 < l3, where xâ„“ is of level â„“. We get xl2 âŠ¥âŠ¥ xl3 | xl1.

a shredding relation almost identical to that of Â§Â§ 2.5 to slice the program in a semantics-preserving
way, and isolate the sub-statements needed for elimination. Here, ğœƒ1 and ğœ™1 must be of level l2 for
the program to be well-typed. Thus, all statements involving ğ‘§1, ğœƒ1 or ğœ™1 are of level l2, and the
shredding relation groups them together inside of the elimination loop for ğ‘§1.

Figure 2 shows the relationship between the levels l1, l2, l3 and the shredding relation. Informa-
tion flows from l1 to l2 and l3, but there is no flow of information between l2 and l3 (Figure 2b).
A âŠ¢2-well-typed program ğ‘† is shredded by â‡•Î“ into ğ‘†1, ğ‘†2 and ğ‘†3, where ğ‘†1 only mentions l1 vari-
ables, ğ‘†2 only mentions l1 and l2 variables, and ğ‘†3 only mentions l1 and l3 variables. This can
be understood as a new factor graph formulation of the original program ğ‘†, where each of the
substatements ğ‘†1, ğ‘†2, ğ‘†3 defines a factor connected to any involved variables (Figure 2a).

Our approach relies on determining the l1, l2, l3 level types by type inference, as they are not
intrinsic to the variables or program in any way, but are designed solely to determine conditional
independence relationships. These types are not accessible by the probabilistic programming user.
Our type system makes it possible to answer various questions about conditional independence in
a program. Assuming a program defining a joint density ğ‘ (x), we can use the type system to:

(1) Check if x2 âŠ¥âŠ¥ x3 | x1 for some partitioning x = x1, x2, x3.
(2) Find an optimal variable partitioning. Given a variable ğ‘¥ âˆˆ x, find a partitioning x = x1, x2, x3,

such that ğ‘¥ âˆˆ x2, x2 âŠ¥âŠ¥ x3 | x1, and x1 and x2 are as small as possible.

(3) Ask questions about the Markov boundary of a variable. Given two variables ğ‘¥ and ğ‘¥ â€², find
the partitioning x = ğ‘¥, x1, x2, such that ğ‘¥ âŠ¥âŠ¥ x1 | x2 and x2 is as small as possible. Is ğ‘¥ â€² in x2?
In other words, is ğ‘¥ â€² in the Markov boundary of ğ‘¥?

In the rest of Â§ 3, we give the âŠ¢2 type system (Â§Â§ 3.1), state a noninterference result (Lemma 7,
Lemma 8) and show that semantics is preserved when shredding âŠ¢2-well-typed programs (Lemma 10).
We present the type system and transformation rules in a declarative style. The implementation
relies on type inference, which we discuss in Â§Â§ 4.4. We derive a result about the way shredding
factorises the density defined by the program (Theorem 2). We prove a conditional independence
result (Â§Â§ 3.2, Theorem 3) and discuss the scope of our approach with examples (Â§Â§ 3.3).

3.1 The âŠ¢2 Type System
We introduce a modified version of SlicStanâ€™s type system. Once again, types ğ‘‡ range over pairs
(ğœ, â„“) of a base type ğœ, and a level type â„“, but levels â„“ are one of l1, l2, or l3, which form a lower
semi-lattice ({l1, l2, l3}, â‰¤), where l1 â‰¤ l2 and l1 â‰¤ l3. This means, for example, that an l2
variable can depend on an l1 variable, but an l3 variable cannot depend on an l2 variable, as level
types l2 and l3 are incomparable.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:16

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

The type system is a standard information flow type system, very similar to the âŠ¢ system
introduced in Â§Â§ 2.2. We mark the only non-standard rules, (Sample2), (Factor2), and (Seq2), which
also differ from those of âŠ¢. (Sample2) and (Factor2) both have the same effect as an assignment to
an implicit weight variable that can be of any of the three levels. (Seq2) is a less restrictive version
of (Seq) and exactly as in [Gorinova et al. 2019], and it makes sure the program can be sliced later.
Note also that the non-interference between l2 and l3 relies on the (PrimCall2) rule not being
ğ‘–=1 â„“ğ‘– does not exist.

derivable when the least upper bound (cid:195)ğ‘›

Typing Rules for Expressions:

(ESub2)
Î“ âŠ¢2 ğ¸ : (ğœ, â„“)

â„“ â‰¤ â„“ â€²

(Var2)

Î“ âŠ¢2 ğ¸ : (ğœ, â„“ â€²)

Î“, ğ‘¥ : ğ‘‡ âŠ¢2 ğ‘¥ : ğ‘‡

(Const2)

ty(ğ‘) = ğœ
Î“ âŠ¢2 ğ‘ : (ğœ, l1)

(Arr2)
Î“ âŠ¢2 ğ¸ğ‘– : (ğœ, â„“) âˆ€ğ‘– âˆˆ 1..ğ‘›
Î“ âŠ¢2 [ğ¸1, ..., ğ¸ğ‘›] : (ğœ [ğ‘›], â„“)

(ArrEl2)
Î“ âŠ¢2 ğ¸1 : (ğœ [ğ‘›], â„“)

Î“ âŠ¢ ğ¸2 : (int, â„“)

Î“ âŠ¢2 ğ¸1 [ğ¸2] : (ğœ, â„“)

(PrimCall2)(ğ‘“ : ğœ1, . . . , ğœğ‘› â†’ ğœ)
Î“ âŠ¢2 ğ¸ğ‘– : (ğœğ‘–, â„“ğ‘– ) âˆ€ğ‘– âˆˆ 1..ğ‘›

Î“ âŠ¢2 ğ‘“ (ğ¸1, . . . , ğ¸ğ‘›) : (ğœ, (cid:195)ğ‘›

ğ‘–=1 â„“ğ‘– )

(ArrComp2)
âˆ€ğ‘– = 1, 2.Î“ âŠ¢2 ğ¸ğ‘– : (int, â„“)

Î“, ğ‘¥ : (int, â„“) âŠ¢ ğ¸ : (ğœ, â„“) ğ‘¥ âˆ‰ dom(Î“)

Î“ âŠ¢2 [ğ¸ | ğ‘¥ in ğ¸1 : ğ¸2] : (ğœ [ğ‘›], â„“)

(Target2)
Î“ âŠ¢2 ğ‘† : â„“ â€²â€² âˆ€â„“ â€² > â„“.ğ‘…Î“âŠ¢â„“â€² (ğ‘†) = âˆ…
Î“ âŠ¢2 target(ğ‘†) : (real, â„“)

Typing Rules for Statements:

(SSub2)
Î“ âŠ¢2 ğ‘† : â„“ â€²

â„“ â‰¤ â„“ â€²

(Assign2)
Î“(ğ¿) = (ğœ, â„“)

Î“ âŠ¢2 ğ¸ : (ğœ, â„“)

Î“ âŠ¢2 ğ‘† : â„“

Î“ âŠ¢2 (ğ¿ = ğ¸) : â„“

(Sample2)
Î“ âŠ¢2 factor(D(ğ¿ | ğ¸1, . . . , ğ¸ğ‘›)) : â„“
Î“ âŠ¢2 ğ¿ âˆ¼ Ddist (ğ¸1, . . . ğ¸ğ‘›) : â„“

(Factor2)
Î“ âŠ¢2 ğ¸ : (real, â„“)
Î“ âŠ¢2 factor(ğ¸) : â„“

(Seq2)
Î“ âŠ¢2 ğ‘†1 : â„“

Î“ âŠ¢2 ğ‘†2 : â„“ S(ğ‘†1, ğ‘†2)

Î“ âŠ¢2 (ğ‘†1; ğ‘†2) : â„“

(If2)
Î“ âŠ¢2 ğ¸ : (bool, â„“)

Î“ âŠ¢2 ğ‘†1 : â„“

Î“ âŠ¢2 ğ‘†2 : â„“

(Skip2)

Î“ âŠ¢2 if(ğ¸) ğ‘†1 else ğ‘†2 : â„“

Î“ âŠ¢2 skip : â„“

(For2)
Î“ âŠ¢2 ğ¸1 : (int, â„“)

Î“ âŠ¢2 ğ¸2 : (int, â„“)

Î“, ğ‘¥ : (int, â„“) âŠ¢2 ğ‘† : â„“

ğ‘¥ âˆ‰ dom(Î“)

ğ‘¥ âˆ‰ ğ‘Š (ğ‘†)

Î“ âŠ¢2 for(ğ‘¥ in ğ¸1 : ğ¸2) ğ‘† : â„“

We state and prove a noninterference result for âŠ¢2, which follows similarly to the result for âŠ¢.

Lemma 7 (Noninterference of âŠ¢2). Suppose ğ‘ 1 |= Î“, ğ‘ 2 |= Î“, and ğ‘ 1 â‰ˆâ„“ ğ‘ 2 for some â„“. Then for a

SlicStan statement ğ‘† and expression ğ¸:

(1) If Î“ âŠ¢2 ğ¸ : (ğœ, â„“) and (ğ‘ 1, ğ¸) â‡“ ğ‘‰1 and (ğ‘ 2, ğ¸) â‡“ ğ‘‰2 then ğ‘‰1 = ğ‘‰2.
(2) If Î“ âŠ¢2 ğ‘† : â„“ and (ğ‘ 1, ğ‘†) â‡“ ğ‘  â€²
2.
1 â‰ˆâ„“ ğ‘  â€²

1, ğ‘¤1 and (ğ‘ 2, ğ‘†) â‡“ ğ‘  â€²

2, ğ‘¤2 then ğ‘  â€²

Proof. (1) follows by rule induction on the derivation Î“ âŠ¢2 ğ¸ : (ğœ, â„“), and using that if Î“ âŠ¢2 ğ¸ :
(ğœ, â„“), ğ‘¥ âˆˆ ğ‘…(ğ¸) and Î“(ğ‘¥) = (ğœ â€², â„“ â€²), then â„“ â€² â‰¤ â„“. (2) follows by rule induction on the derivation
â–¡
Î“ âŠ¢2 ğ‘† : â„“ and using (1).

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:17

Once again we derive a more convenient form of the noninterference result. Because the level
types l2 and l3 are not comparable in the order â‰¤, changes in the store at l2 do not affect the store
at l3 and vice versa.

Lemma 8 (Noninterference of âŠ¢2-well-typed programs).

Let Î“ğœ, Î“x, ğ‘† be a SlicStan program, and Î“ âŠ¢2 ğ‘† : l1. There exist unique functions ğ‘“ , ğ‘” and â„, such that
for all ğœ |= Î“ğœ , x |= Î“x and ğœ â€² such that
ğ‘  (ğœ)(x) = ğœ â€²:
(cid:75)
l2 = ğ‘”(ğœl1, ğœl2, xl1, xl2), ğœ â€²

l3 = â„(ğœl1, ğœl3, xl1, xl3)

l1 = ğ‘“ (ğœl1, xl1), ğœ â€²
ğœ â€²

ğ‘†
(cid:74)

Proof. Follows from noninterference (Lemma 7).

â–¡

Next, we extend the shredding relation from Â§Â§ 2.5, and the concept of single-level statements,
to SlicStan programs that are well-typed with respect to âŠ¢2. This is done by simply treating l1 as
data, l2 as model, and l3 as genqant for the purpose of shredding. We include the full definition
of shredding with respect to âŠ¢2 for completeness below. We use the same notation â‡•Î“, and we
generally treat the standard shredding relation from 2.5 and the conditional independence shredding
relation presented here, as the same relation, as there is no difference between the two, other than
the naming of levels.
Shredding Rules for Statements:

(Shred2 Assign)
Î“(ğ¿) = l1 â†’ ğ‘†1 = ğ¿ = ğ¸, ğ‘†2 = ğ‘†3 = skip
Î“(ğ¿) = l2 â†’ ğ‘†2 = ğ¿ = ğ¸, ğ‘†1 = ğ‘†3 = skip
Î“(ğ¿) = l3 â†’ ğ‘†3 = ğ¿ = ğ¸, ğ‘†1 = ğ‘†2 = skip
ğ¿ = ğ¸ â‡•Î“ (ğ‘†1, ğ‘†2, ğ‘†3)

(Shred2 Seq)
ğ‘†1 â‡•Î“ ğ‘† (1)
, ğ‘† (1)
2
1
ğ‘†1; ğ‘†2 â‡•Î“ (ğ‘† (1)
1

, ğ‘† (1)
3
; ğ‘† (2)
1

ğ‘†2 â‡•Î“ ğ‘† (2)
, ğ‘† (2)
1
2
), (ğ‘† (1)
; ğ‘† (2)
3
2

, ğ‘† (2)
3
; ğ‘† (2)
3

)

), (ğ‘† (1)
2

(Shred2 Factor)
Î“(ğ¸) = l1 â†’ ğ‘†1 = factor(ğ¸), ğ‘†2 = ğ‘†3 = skip
Î“(ğ¸) = l2 â†’ ğ‘†2 = factor(ğ¸), ğ‘†1 = ğ‘†3 = skip
Î“(ğ¸) = l3 â†’ ğ‘†3 = factor(ğ¸), ğ‘†1 = ğ‘†2 = skip
factor(ğ¸) â‡•Î“ (ğ‘†1, ğ‘†2, ğ‘†3)

(Shred2 Skip)

skip â‡•Î“ (skip, skip, skip)

(Shred2 Sample)
Î“(ğ¿, ğ¸1, . . . , ğ¸ğ‘›) = l1 â†’ ğ‘†1 = ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›), ğ‘†2 = ğ‘†3 = skip
Î“(ğ¿, ğ¸1, . . . , ğ¸ğ‘›) = l2 â†’ ğ‘†2 = ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›), ğ‘†1 = ğ‘†3 = skip
Î“(ğ¿, ğ¸1, . . . , ğ¸ğ‘›) = l3 â†’ ğ‘†3 = ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›), ğ‘†1 = ğ‘†2 = skip
ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›) â‡•Î“ (ğ‘†1, ğ‘†2, ğ‘†3)

(Shred2 If)

ğ‘†1 â‡•Î“ ğ‘† (1)
1
if(ğ‘”) ğ‘†1 else ğ‘†2 â‡•Î“ (if(ğ‘”) ğ‘† (1)
1

, ğ‘† (1)
, ğ‘† (1)
3
2
else ğ‘† (2)

1

ğ‘†2 â‡•Î“ ğ‘† (2)
1
), (if(ğ‘”) ğ‘† (1)
2

, ğ‘† (2)
, ğ‘† (2)
3
2
else ğ‘† (2)

2

), (if(ğ‘”) ğ‘† (1)
3

else ğ‘† (2)

3

)

(Shred2 For)

ğ‘† â‡•Î“ ğ‘†1, ğ‘†2, ğ‘†3
for(ğ‘¥ in ğ‘”1 : ğ‘”2) ğ‘† â‡•Î“ (for(ğ‘¥ in ğ‘”1 : ğ‘”2) ğ‘†1), (for(ğ‘¥ in ğ‘”1 : ğ‘”2) ğ‘†2), (for(ğ‘¥ in ğ‘”1 : ğ‘”2) ğ‘†3)

As before, shredding produces single-level statements, and shredding preserves semantics with

respect to âŠ¢2-well-typed programs.

Lemma 9 (Shredding produces single-level statements, âŠ¢2).

b If ğ‘† â‡•Î“ ğ‘†1, ğ‘†2, ğ‘†3 then Î“ âŠ¢ l1(ğ‘†1), Î“ âŠ¢ l2(ğ‘†2), and Î“ âŠ¢ l3(ğ‘†3).

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:18

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

Lemma 10 (Semantic preservation of â‡•Î“, âŠ¢2).

If Î“ âŠ¢2 ğ‘† : l1 and ğ‘† â‡•Î“ ğ‘†1, ğ‘†2, ğ‘†3 then

=

ğ‘†
(cid:74)

(cid:75)

ğ‘†1; ğ‘†2; ğ‘†3
(cid:74)

(cid:75)

.

In addition, we derive a result about the effect of single-level statements on the store and weight

of âŠ¢2-well-typed programs.

Lemma 11 (Property of âŠ¢2 single-level statements).

Let Î“ğœ, Î“x, ğ‘† be a SlicStan program, and Î“ âŠ¢2 ğ‘† : l1, and ğ‘† be single-level statement of level â„“, Î“ âŠ¢2 â„“ (ğ‘†).
Then there exist unique functions ğ‘“ and ğœ™, such that for any ğœ, x |= Î“ğœ, Î“x:

(1) If â„“ = l1, then
(2) If â„“ = l2, then
(3) If â„“ = l3, then

(ğœ)(ğ‘¥) = (cid:0)ğ‘“ (ğœl1, xl1), ğœl2, ğœl3(cid:1) ,
(ğœ)(ğ‘¥) = (cid:0)ğœl1, ğ‘“ (ğœl1, ğœl2, xl1, xl2), ğœl3(cid:1) , ğœ™ (ğœl1, ğœl2)(xl1, xl2)
(ğœ)(ğ‘¥) = (cid:0)ğœl1, ğœl2, ğ‘“ (ğœl1, ğœl3, xl1, xl3)(cid:1) , ğœ™ (ğœl1, ğœl3)(xl1, xl3)

ğœ™ (ğœl1)(xl1)

We give proofs for Lemma 9, 10, and 11 in Appendix A. These results allows us to derive the
second key theorem of this paper, Theorem 2, which, similarly to Theorem 1, gives us a result on
the way shredding factorises the density defined by the program.

Here, and throughout the paper, we use subscripts to refer to specific subsets of Î“. For example,
Î“l1 stands for the subset of the parameters Î“x, such that ğ‘¥ : (ğœ, â„“) âˆˆ Î“l1 if and only if ğ‘¥ : (ğœ, â„“) âˆˆ Î“x
and â„“ = l1.

Theorem 2 (Shredding induces a factorisation of the density (2)).

Suppose Î“ âŠ¢2 ğ‘† : l1 with Î“ = Î“ğœ, Î“l1, Î“l2, Î“l3, ğ‘† â‡•Î“ ğ‘†1, ğ‘†2, ğ‘†3. Then for ğœ, ğœ½ 1, ğœ½ 2, ğœ½ 3 |= Î“ğœ, Î“1, Î“2, Î“3,
and ğœ â€², ğœ â€²â€² such that

(ğœ â€²)(ğœ½ 1, ğœ½ 2, ğœ½ 3) = ğœ â€²â€² we have:

(ğœ)(ğœ½ 1, ğœ½ 2, ğœ½ 3) = ğœ â€², and

ğ‘†
(cid:74)
ğ‘†
(cid:74)
ğ‘†
(cid:74)

(cid:75)
(cid:75)
(cid:75)

(1)
(2)
(3)

ğ‘†1
(cid:74)
(cid:75)
ğ‘ (ğœ)(ğœ½ 1, ğœ½ 2, ğœ½ 3) = ğœ™1(ğœ½ 1)
(cid:75)
ğ‘ (ğœ â€²)(ğœ½ 1, ğœ½ 2, ğœ½ 3) = ğœ™2(ğœ½ 1, ğœ½ 2)
(cid:75)
ğ‘ (ğœ â€²â€²)(ğœ½ 1, ğœ½ 2, ğœ½ 3) = ğœ™3 (ğœ½ 1, ğœ½ 3)
(cid:75)

ğ‘†1
(cid:74)
ğ‘†2
(cid:74)
ğ‘†3
(cid:74)

ğ‘†2
(cid:74)

(cid:75)

Proof. By applying Lemma 11 to each of ğ‘†1, ğ‘†2, ğ‘†3, which are single-level statements (Lemma 9).
â–¡

3.2 Conditional Independence Result for âŠ¢2-Well-Typed Programs
Theorem 3 states the key theoretical result of this paper: the typing in programs well-typed
with respect to âŠ¢2 corresponds to a conditional independence relationship. In our proofs, we use
the factorisation characterisation of conditional independence stated by Definition 6. This is a
well-known result in the literature (e.g. [Murphy 2012, Theorem 2.2.1.]).

Definition 6 (Characterisation of conditional independence as factorisation).

For variables ğ‘¥, ğ‘¦, ğ‘§ and a density ğ‘ (ğ‘¥, ğ‘¦, ğ‘§), ğ‘¥ is conditionally independent of ğ‘¦ given ğ‘§ with respect to
ğ‘, written ğ‘¥ âŠ¥âŠ¥ğ‘ ğ‘¦ | ğ‘§, if and only if âˆƒğœ™1, ğœ™2 such that ğ‘ (ğ‘¥, ğ‘¦, ğ‘§) = ğœ™1(ğ‘¥, ğ‘§)ğœ™2(ğ‘¦, ğ‘§).

An equivalent formulation is ğ‘ (ğ‘¥, ğ‘¦ | ğ‘§) = ğ‘ (ğ‘¥ | ğ‘§)ğ‘ (ğ‘¦ | ğ‘§).
We extend the notion of conditional independence to apply to a general function ğœ™ (ğ‘¥, ğ‘¦, ğ‘§), using the

notation ğ‘¥ âŠ¥ğœ™ ğ‘¦ | ğ‘§ to mean âˆƒğœ™1, ğœ™2 such that ğœ™ (ğ‘¥, ğ‘¦, ğ‘§) = ğœ™1 (ğ‘¥, ğ‘§)ğœ™2(ğ‘¦, ğ‘§).

Theorem 3 (âŠ¢2-well-typed programs induce a conditional independence relationship).
For a SlicStan program Î“, ğ‘† such that Î“ âŠ¢2 ğ‘† : l1, Î“ = Î“ğœ, Î“l1, Î“l2, Î“l3, and for ğœ, ğœ½ 1, ğœ½ 2, ğœ½ 3 |=
Î“ğœ, Î“l1, Î“l2, Î“l3, we have ğœ½ 2 âŠ¥ğœ™ ğœ½ 3 | ğœ½ 1.

ğ‘†
(cid:74)

When

ğ‘ (ğœ)(ğœ½ 1, ğœ½ 2, ğœ½ 3) âˆ ğ‘ (ğœ½ 1, ğœ½ 2, ğœ½ 3), we have ğœ½ 2 âŠ¥âŠ¥ğ‘ ğœ½ 3 | ğœ½ 1.
(cid:75)
Proof. Let ğœ½ = ğœ½ 1, ğœ½ 2, ğœ½ 3, ğ‘† â‡•Î“ ğ‘†1, ğ‘†2, ğ‘†3, and let ğœ â€² and ğœ â€²â€² be such that ğœ â€² =

ğœ â€²â€² =

ğ‘†2
(cid:74)

ğ‘  (ğœ â€²)(ğœ½ ). Then, by semantic preservation of shredding (Lemma 10), we have
(cid:75)
ğ‘†
(cid:74)

ğ‘ (ğœ)(ğœ½ ) =
(cid:75)

ğ‘†1; ğ‘†2; ğ‘†3
(cid:74)

ğ‘ (ğœ)(ğœ½ )
(cid:75)

by Lemma 10

ğ‘†1
(cid:74)

ğ‘  (ğœ)(ğœ½ ), and
(cid:75)

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:19

real x1 âˆ¼ normal(0,1)
real x2 âˆ¼ normal(0,1)
real x3 âˆ¼ normal(x1+x2,1)
real x4 âˆ¼ normal(x3,1)
real x5 âˆ¼ normal(x3,1)

C. Cross Model

ğ‘¥1

ğ‘¥4

ğ‘¥3

ğ‘¥2

ğ‘¥5

(a) A simple â€˜crossâ€™ model.

(b) Graphical model.

ğ‘¥1 âŠ¥âŠ¥ ğ‘¥2
ğ‘¥1 âŠ¥âŠ¥ ğ‘¥5 | {ğ‘¥3} âˆª ğ´, âˆ€ğ´ âŠ† {ğ‘¥2, ğ‘¥4}
ğ‘¥2 âŠ¥âŠ¥ ğ‘¥5 | {ğ‘¥3} âˆª ğ´, âˆ€ğ´ âŠ† {ğ‘¥1, ğ‘¥4}

ğ‘¥1 âŠ¥âŠ¥ ğ‘¥4 | {ğ‘¥3} âˆª ğ´, âˆ€ğ´ âŠ† {ğ‘¥2, ğ‘¥5}
ğ‘¥2 âŠ¥âŠ¥ ğ‘¥4 | {ğ‘¥3} âˆª ğ´, âˆ€ğ´ âŠ† {ğ‘¥1, ğ‘¥5}
ğ‘¥4 âŠ¥âŠ¥ ğ‘¥5 | {ğ‘¥3} âˆª ğ´, âˆ€ğ´ âŠ† {ğ‘¥1, ğ‘¥2}

(c) CI relationships.

Fig. 3. The cross model, as written in SlicStan (a) with its DAG (b) and CI relationships (c).

ğ‘†1
(cid:74)

ğ‘ (ğœ)(ğœ½ ) Ã—
(cid:75)

ğ‘†3
ğ‘†2
=
(cid:74)
(cid:74)
= ğœ™1(ğœ½ 1) Ã— ğœ™2(ğœ½ 1, ğœ½ 2) Ã— ğœ™3(ğœ½ 1, ğœ½ 3)
= ğœ™ â€²(ğœ½ 1, ğœ½ 2) Ã— ğœ™3(ğœ½ 1, ğœ½ 3)

ğ‘ (ğœ â€²)(ğœ½ ) Ã—
(cid:75)

ğ‘ (ğœ â€²â€²)(ğœ½ )
(cid:75)

by Lemma 2

by Theorem 2

for some ğœ™1, ğœ™2, and ğœ™3, ğœ™ â€²(ğœ½ 1, ğœ½ 2) = ğœ™1(ğœ½ 1) Ã— ğœ™2(ğœ½ 1, ğœ½ 2). Thus ğœ½ 2 âŠ¥ğœ™ ğœ½ 3 | ğœ½ 1 by definition of âŠ¥ğœ™ .
Suppose ğœ™ (ğœ½ 1, ğœ½ 2, ğœ½ 3) âˆ ğ‘ (ğœ½ 1, ğœ½ 2, ğœ½ 3). Then ğ‘ (ğœ½ 1, ğœ½ 2, ğœ½ 3) = ğœ™ (ğœ½ 1, ğœ½ 2, ğœ½ 3) Ã— ğ‘ = ğœ™ â€²(ğœ½ 1, ğœ½ 2) Ã—
ğœ™3(ğœ½ 1, ğœ½ 3) Ã— ğ‘ = ğœ™ â€²(ğœ½ 1, ğœ½ 2) Ã— ğœ™ â€²â€²(ğœ½ 1, ğœ½ 3), where ğ‘ is a constant and ğœ™ â€²â€²(ğœ½ 1, ğœ½ 3) = ğœ™3(ğœ½ 1, ğœ½ 3) Ã— ğ‘ .
â–¡
Therefore, ğœ½ 2 âŠ¥âŠ¥ğ‘ ğœ½ 3 | ğœ½ 1.

3.3 Scope of the Conditional Independence Result
We have shown that âŠ¢2-well-typed programs exhibit a conditional independence relationship in their
density semantics. However, it is not the case that every conditional independence relationship can
be derived from the type system. In particular, we can only derive results of the form ğœ½ 2 âŠ¥âŠ¥ ğœ½ 3 | ğœ½ 1,
where ğœ½ 1, ğœ½ 2, ğœ½ 3 is a partitioning of ğœ½ |= Î“x for a SlicStan program Î“ğœ, Î“x, ğ‘†. That is, the relationship
includes all parameters in the program.

We discuss the scope of our approach using an example and show a situation where trying to

derive a conditional independence result that does not hold results in a failure to type check.
3.3.1 Example of âŠ¢2-well-typed program â†’ conditional independence.
Consider the Cross Model in Figure 3, its SlicStan program (a), its directed graphical model (b) and
the conditional independence (CI) relationships that hold for that model (c).

Out of the many relationships above, we can derive all relationships that involve all the variables.
That is, we can use our type system to derive all conditional independence relationships that hold
and are of the form ğ´ âŠ¥âŠ¥ ğµ | ğ¶, where ğ´, ğµ, ğ¶ is some partitioning of {ğ‘¥1, . . . , ğ‘¥5}. However, note
the following properties of conditional independence:

ğ´ âŠ¥âŠ¥ ğµ | ğ¶ â‡â‡’ ğµ âŠ¥âŠ¥ ğ´ | ğ¶

and ğ´ âŠ¥âŠ¥ ğµ1, ğµ2 | ğ¶ â‡â‡’ ğ´ âŠ¥âŠ¥ ğµ1 | ğ¶ and ğ´ âŠ¥âŠ¥ ğµ2 | ğ¶

Some of the relationships above can be combined and written in other ways, e.g. ğ‘¥1 âŠ¥âŠ¥ ğ‘¥4 | ğ‘¥2, ğ‘¥3
and ğ‘¥1 âŠ¥âŠ¥ ğ‘¥5 | ğ‘¥2, ğ‘¥3 can be written as a single relationship ğ‘¥1 âŠ¥âŠ¥ ğ‘¥4, ğ‘¥5 | ğ‘¥2, ğ‘¥3, thus expressing
them as a single relationship that includes all variables in the program.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:20

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

Exploring different mappings between the parameters ğ‘¥1, . . . , ğ‘¥5 and the type levels l1, l2, l3, for
which the above program typechecks, we can derive all CI relationships that hold for this model,
except for one: ğ‘¥1 âŠ¥âŠ¥ ğ‘¥2, which we cannot derive with our approach.
3.3.2 Conditional independence relationship does not hold â†’ type error.
Suppose that we try to derive the result ğ‘¥1 âŠ¥âŠ¥ ğ‘¥2 | ğ‘¥3, ğ‘¥4, ğ‘¥5. This does not hold for Program C. By
Theorem 3, we have that a program being âŠ¢2-well-typed implies that l2 âŠ¥âŠ¥ l3 | l1. So, we can
derive ğ‘¥1 âŠ¥âŠ¥ ğ‘¥2 | ğ‘¥3, ğ‘¥4, ğ‘¥5 using Theorem 3 if we show that Î“ âŠ¢2 ğ‘† : l1, for Î“ = {ğ‘¥1 : l2, ğ‘¥2 : l3, ğ‘¥3 :
l1, ğ‘¥4 : l1, ğ‘¥5 : l1} and ğ‘† being Program C.

To typecheck Î“ âŠ¢2 ğ‘† : l1, we need to typecheck ğ‘¥3 âˆ¼ normal(ğ‘¥1 + ğ‘¥2, 1) at some level â„“. Thus,
by (Sample2) and (PrimCall2), ğ‘¥1, ğ‘¥2 and ğ‘¥3 need to typecheck at â„“. The types of ğ‘¥1, ğ‘¥2 and ğ‘¥3
are l2, l3 and l1, respectively. So, using (ESub2), it must be the case that l2 â‰¤ â„“, and l3 â‰¤ â„“, and
l1 â‰¤ â„“. However, no such level exists in our lower semi-lattice, as l2 and l3 have no upper bound.
Therefore, typechecking fails and we cannot derive ğ‘¥1 âŠ¥âŠ¥ ğ‘¥2 | ğ‘¥3, ğ‘¥4, ğ‘¥5.

4 APPLICATION: DISCRETE PARAMETERS SUPPORT THROUGH A

SEMANTICS-PRESERVING TRANSFORMATION

This section presents the main practical contribution of our work: a semantics-preserving procedure
for transforming a probabilistic program to enable combined inference of discrete and continuous
model parameters, which we have implemented for SlicStan. The procedure corresponds to variable
elimination (VE) for discrete parameters implemented in the probabilistic program itself, which can
be combined with gradient-based methods, such as HMC, to perform inference on all parameters.
PPLs that have gradient-based methods in the core of their inference strategy do not, in general,
support directly working with discrete parameters. Stan disallows discrete model parameters
altogether, while Pyro [Uber AI Labs 2017] and Edward2 [Tran et al. 2018] throw a runtime
error whenever discrete parameters are used within a gradient-based method. However, working
with discrete parameters in these languages is still possible, albeit in an implicit way. In many
cases, discrete parameters can be marginalised out manually, and then drawn conditionally on the
continuous parameters. Stanâ€™s user guide shows many examples of this approach [Stan Development
Team 2019a, Chapter 7]. Pyro provides an on-request marginalisation functionality, which automates
this implicit treatment for plated factor graphs [Obermeyer et al. 2019].

The key idea of the workaround is to marginalise out the discrete parameters by hand, so that
the resulting program corresponds to a density function that does not depend on any discrete
parameters. That is, the user writes a program that computes (cid:205)
ğ‘ (ğœ½ ğ‘‘, ğœ½ ğ‘ ) = ğ‘ (ğœ½ ğ‘ ), where the
density semantics of the original program was ğ‘ (ğœ½ ğ‘‘, ğœ½ ğ‘ ) for discrete parameters ğœ½ ğ‘‘ and continuous
parameters ğœ½ ğ‘ . This allows for continuous parameters of the program to be sampled with HMC,
or other gradient-based inference algorithms, whereas that would have not been possible for the
program with both discrete and continuous latent variables.

ğœ½ ğ‘‘

Because a SlicStan program computes a density directly, it is easy to modify it to marginalise a
variable. For a SlicStan program Î“, ğ‘†, with parameters x |= Î“x, and a discrete parameter ğ‘§ of type
intâŸ¨ğ¾âŸ©, the program elim(intâŸ¨ğ¾âŸ©ğ‘§) ğ‘† â‰œ factor(sum([target(ğ‘†) | ğ‘§ in 1 : ğ¾])11 marginalises ğ‘§:

factor(sum([target(ğ‘†) | ğ‘§ in 1 : ğ¾]))

(cid:74)

ğ‘ (ğœ)(x) =
(cid:75)

ğ¾
âˆ‘ï¸

ğ‘†
ğ‘§=1(cid:74)

ğ‘ (ğœ)(x) âˆ
(cid:75)

ğ¾
âˆ‘ï¸

ğ‘§=1

ğ‘ (x) = ğ‘ (x \ {ğ‘§})

In other words, we can easily marginalise out all discrete variables in a probabilistic program,
by encapsulating the entire program in nested loops (nested array comprehension expressions in
our examples). However, this approach becomes infeasible for more than a few variables. Variable

11Here, we assume the function sum is available in the language.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:21

D. A Hidden Markov Model (HMM)
...
int<2> z1 âˆ¼ bernoulli(theta[1]);
int<2> z2 âˆ¼ bernoulli(theta[z1]);
int<2> z3 âˆ¼ bernoulli(theta[z2]);
data real y1 âˆ¼ normal(phi[z1], 1);
data real y2 âˆ¼ normal(phi[z2], 1);
data real y3 âˆ¼ normal(phi[z3], 1);

E. Inefficient marginalisation

...
factor(sum [target(

factor(sum [target(

factor(sum [target(

z1 âˆ¼ bernoulli(theta[1]);
z2 âˆ¼ bernoulli(theta[z1]);
z3 âˆ¼ bernoulli(theta[z2]);
y1 âˆ¼ normal(phi[z1], 1);
y2 âˆ¼ normal(phi[z2], 1);
y3 âˆ¼ normal(phi[z3], 1);)

| z1 in 1:2]);

| z2 in 1:2]);

| z3 in 1:2]);

F. Efficient marginalisation

...
real[2] f1 = // new factor on z2

[sum([target(

z1 âˆ¼ bernoulli(theta[1]);
z2 âˆ¼ bernoulli(theta[z1]);
y1 âˆ¼ normal(phi[z1], 1); )

| z1 in 1:2])

| z2 in 1:2]

real[2] f2 = // new factor on z3

[sum([target(

factor(f1[z2]);
y2 âˆ¼ normal(phi[z2], 1);
z3 âˆ¼ bernoulli(theta[z2]); )

| z2 in 1:2])

| z3 in 1:2]

factor(sum [target(
factor(f2[z3]);
y3 âˆ¼ normal(phi[z3], 1); )

| z3 in 1:2]);

elimination [Koller and Friedman 2009; Zhang and Poole 1994] exploits the structure of a model to
do as little work as possible. Consider the HMM snippet (Program D) with three discrete (binary)
hidden variables ğ‘§1, ğ‘§2 and ğ‘§3, and observed outcomes ğ‘¦1, ğ‘¦2 and ğ‘¦3. Naively marginalising out the
hidden variables results in nested loops around the original program (Program E). In the general
case of ğ‘ hidden variables, the resulting program is of complexity ğ‘‚ (2ğ‘ ).

However, this is wasteful: expressions like ğ‘§3 âˆ¼ bernoulli(ğœƒ [ğ‘§2]) do not depend on ğ‘§1, and so do
not need to be inside of the ğ‘§1-elimination loop. Variable elimination (VE) avoids this problem by
pre-computing some of the work. Program F implements VE for this model: when eliminating a
variable, say ğ‘§1, we pre-compute statements that involve ğ‘§1 for each possible value of ğ‘§1 and store
the resulting density contributions in a new factor, ğ‘“1. This new factor depends on the variables
involved in those statements â€” the neighbours of ğ‘§1 â€” in this case that is solely ğ‘§2. We then repeat
the procedure for the other variables, re-using the already computed factors where possible.

In the special case of an HMM, and given a suitable elimination order, variable elimination
recovers the celebrated forward algorithm [Rabiner 1989], which has time complexity ğ‘‚ (ğ‘ ). Our
goal is to automatically translate the source code of Program D to Program F, exploiting statically
detectable independence properties in the model.

4.1 Goal
Our ultimate goal is to transform a program ğ‘† with continuous parameters ğœ½ ğ‘ , discrete parameters
ğ‘ (ğœ)(ğœ½ ğ‘‘, ğœ½ ğ‘, D) âˆ ğ‘ (ğœ½ ğ‘‘, ğœ½ ğ‘ | D), into two subprograms: ğ‘†hmc
ğœ½ ğ‘‘ , data D and density semantics
(cid:75)
and ğ‘†gen, such that:

ğ‘†
(cid:74)

â€¢ The density defined by ğ‘†hmc is the marginal ğ‘ (ğœ½ ğ‘ | D), with the discrete parameters ğœ½ ğ‘‘
marginalised out. This first statement, ğ‘†hmc, represents the marginalisation part of the program

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:22

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

(see Â§Â§ 4.3) and allows for Hamiltonian Monte Carlo (HMC) sampling of ğœ½ ğ‘ , as it does not
involve any discrete parameters.

â€¢ The density defined by ğ‘†gen is the conditional ğ‘ (ğœ½ ğ‘‘ | ğœ½ ğ‘, D). This second statement, ğ‘†gen,
represents the generative part of the program (Â§Â§ 4.5) and it encodes a way to draw ğœ½ ğ‘‘
generatively, without using HMC or another heavy-weight inference algorithm.

Similarly to the extended SlicStan slicing based on information-flow type inference, here we also
want to transform and slice into sub-programs, each focusing on a subset of the parameters, and
preserving the overall meaning:

ğ‘†
(cid:74)

ğ‘ âˆ ğ‘ (ğœ½ ğ‘‘, ğœ½ ğ‘ | D) = ğ‘ (ğœ½ ğ‘ | D) Ã— ğ‘ (ğœ½ ğ‘‘ | ğœ½ ğ‘, D) âˆ
(cid:75)

ğ‘†hmc
(cid:74)

ğ‘ Ã—
(cid:75)

ğ‘†gen
(cid:74)

ğ‘ =
(cid:75)

ğ‘†hmc; ğ‘†gen
(cid:74)

ğ‘
(cid:75)

12

Our approach performs a semantics-preserving transformation, guided by information-flow
and type inference, which creates an efficient program-specific inference algorithm automatically,
combining HMC with variable elimination.

4.2 Key Insight
The key practical insight of this work is to use the adaptation of SlicStanâ€™s level types of Â§ 3 and
its information flow type system to rearrange the program in a semantics-preserving way, so that
discrete parameters can be forward-sampled, instead of sampled using a heavy-weight inference
algorithm. We achieve this by a program transformation for each of the discrete variables. Assuming
that we are applying the transformation with respect to a variable ğ‘§, we use:

â€¢ The top-level information flow type system Î“ âŠ¢ ğ‘† : data from Â§Â§ 2.2, which involves the
level types data â‰¤ model â‰¤ genqant. This partitions the modelled variables x into data
D, model parameters ğœ½ and generated quantities ğ‘„. When we use type inference for âŠ¢ in
conjunction with shredding ğ‘† â‡•Î“ ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ (Â§Â§ 2.5), we slice the statement ğ‘† into a data
part ğ‘†ğ· (involving only variables in D), a non-generative part ğ‘†ğ‘€ (involving D and ğœ½ ) and a
generative part ğ‘†ğ‘„ (involving D, ğœ½ and ğ‘„).

â€¢ The conditional independence information flow type system, Î“ âŠ¢2 ğ‘† : l1 from Â§ 3, which uses
a lower semi-lattice of level types l1 â‰¤ l2, l1 â‰¤ l3. A âŠ¢2-well-typed program induces a
conditional independence relationship: l2-variables are conditionally independent of l3-
variables given l1-variables: xl2 âŠ¥âŠ¥ xl3 | xl1, where x = xl1, xl2, xl3 = ğœ½, D. When we use
type inference for âŠ¢2 in conjunction with shredding ğ‘† â‡•Î“ ğ‘†1, ğ‘†2, ğ‘†3 (Â§Â§ 2.5), we isolate ğ‘†2: a
part of the program that does not interfere with ğ‘†3. We can marginalise out l2-variables in
that sub-statement only, keeping the rest of the program unchanged.

â€¢ The discrete variable transformation relation Î“, ğ‘†

ğ‘§
âˆ’â†’ Î“â€², ğ‘† â€² (defined in Â§Â§Â§ 4.6.2), which takes a
SlicStan program Î“, ğ‘† that has discrete model parameter ğ‘§, and transforms it to a SlicStan pro-
gram Î“â€², ğ‘† â€², where ğ‘§ is no longer a model-level parameter but instead one of level genqant.
We define the relation in terms of âŠ¢ and âŠ¢2 as per the (Elim Gen) rule.

4.3 Variable Elimination
Variable elimination (VE) [Koller and Friedman 2009; Zhang and Poole 1994] is an exact inference
algorithm often phrased in terms of factor graphs. It can be used to compute prior or posterior
marginal distributions by eliminating, one by one, variables that are irrelevant to the distribution
of interest. VE uses dynamic programming combined with a clever use of the distributive law of
multiplication over addition to efficiently compute a nested sum of a product of expressions.

12This expression is simplified for readability.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:23

ğ‘ (ğ‘§1 | ğœƒ1)

ğ‘ (ğ‘¦1 | ğœ™ğ‘§1 )

ğ‘§1

ğ‘¦1

ğ‘ (ğ‘§2 | ğœƒğ‘§1 )

ğ‘ (ğ‘¦2 | ğœ™ğ‘§2 )

ğ‘ (ğ‘§3 | ğœƒğ‘§2 )

ğ‘ (ğ‘¦3 | ğœ™ğ‘§3 )

ğ‘§3

ğ‘¦3

ğ‘§2

ğ‘¦2

ğ‘“1 (ğ‘§2, ğ‘¦1) =
(cid:205)ğ‘§1 [ğ‘ (ğ‘§1 | ğœƒ1)
Ã—ğ‘ (ğ‘¦1 | ğœ™ğ‘§1 )
Ã—ğ‘ (ğ‘§2 | ğœƒğ‘§1 ) (cid:3)

ğ‘§2

ğ‘¦2

ğ‘ (ğ‘¦2 | ğœ™ğ‘§2 )

ğ‘¦1

ğ‘ (ğ‘§3 | ğœƒğ‘§2 )

ğ‘ (ğ‘¦3 | ğœ™ğ‘§3 )

ğ‘§3

ğ‘¦3

(a) To eliminate ğ‘§1, we remove ğ‘§1 and all its neigh-
bouring factors (in red). Create a new factor ğ‘“1, by
summing out ğ‘§1 from the product of these factors.

(b) Connect ğ‘“1 (in green) to the former neighbours
of ğ‘§1. The remaining factor graph defines the mar-
ginal ğ‘ (ğ‘§2, ğ‘§3 | y).

ğ‘“1 (ğ‘§2, ğ‘¦1)

ğ‘§2

ğ‘¦2

ğ‘ (ğ‘¦2 | ğœ™ğ‘§2 )

ğ‘¦1

ğ‘ (ğ‘§3 | ğœƒğ‘§2 )

ğ‘ (ğ‘¦3 | ğœ™ğ‘§3 )

ğ‘§3

ğ‘¦3

ğ‘“2 (ğ‘§3, ğ‘¦2, ğ‘¦1) = (cid:205)ğ‘§2 [ğ‘“1 (ğ‘§2, ğ‘¦1)
Ã—ğ‘ (ğ‘¦2 | ğœ™ğ‘§2 ) Ã— ğ‘ (ğ‘§3 | ğœƒğ‘§2 )(cid:3)

ğ‘ (ğ‘¦3 | ğœ™ğ‘§3 )

ğ‘¦1

ğ‘¦2

ğ‘§3

ğ‘¦3

(c) To eliminate ğ‘§2, we remove ğ‘§2 and all its neigh-
bouring factors (in red). Create a new factor ğ‘“2, by
summing out ğ‘§2 from the product of these factors.

(d) Connect ğ‘“2 (in green) to the former neighbours
of ğ‘§2. The remaining factor graph defines the mar-
ginal ğ‘ (ğ‘§3 | y).

Fig. 4. Step by step example of variable elimination.

We already saw an example of variable elimination in Â§ 3 (Programs A and B). The idea is to
eliminate (marginalise out) variables one by one. To eliminate a variable ğ‘§, we multiply all of
the factors connected to ğ‘§ to form a single expression, then sum over all possible values for ğ‘§ to
create a new factor, remove ğ‘§ from the graph, and finally connect the new factor to all former
neighbours13of ğ‘§. Recall Program D, with latent variables ğ‘§1, ğ‘§2, ğ‘§3 and observed data y = ğ‘¦1, ğ‘¦2, ğ‘¦3.
Figure 4 shows the VE algorithm step-by-step applied to this program. We eliminate ğ‘§1 to get the
marginal on ğ‘§2 and ğ‘§3 (4a and 4b), then eliminate ğ‘§2 to get the marginal on ğ‘§3 (4c and 4d).

4.4 Conditional Independence Relationships and Inferring the Markov Blanket
The key property we are looking for, in order to be able to marginalise out a variable independently
of another, is conditional independence given neighbouring variables. If we shred a âŠ¢2-well-typed
program into ğ‘†1, ğ‘†2 and ğ‘†3, and think of
ğ‘ as factors, it is easy to visualise the
ğ‘ and
ğ‘†2
(cid:75)
(cid:75)
(cid:74)
factor graph corresponding to the program: it is as in Figure 5a. Eliminating all xl2 variables, ends
ğ‘ factor (Figure 5b).
up only modifying the
(cid:75)

When using VE to marginalise out a parameter ğ‘§, we want to find the smallest set of other
parameters ğ´, such that ğ‘§ âŠ¥âŠ¥ ğµ | ğ´, where ğµ is the rest of the parameters. The set ğ´ is also called
ğ‘§â€™s minimal Markov blanket or Markov boundary. Once we know this set, we can ensure that we
involve the smallest possible number of variables in ğ‘§â€™s elimination, which is important to achieve
a performant algorithm.

ğ‘†3
(cid:74)

ğ‘†2
(cid:74)

ğ‘†1
(cid:74)

ğ‘,
(cid:75)

For example, when we eliminate ğ‘§1 in Program D, both ğ‘§2 and ğ‘¦1 need to be involved, as ğ‘§1
shares a factor with them. By contrast, there is no need to include ğ‘¦2, ğ‘§3, ğ‘¦3 and the statements
associated with them, as they are unaffected by ğ‘§1, given ğ‘§2. The variables ğ‘¦1 and ğ‘§2 form ğ‘§1â€™s
Markov blanket: given these variables, ğ‘§1 is conditionally independent of all other variables. That
is, ğ‘§1 âŠ¥âŠ¥ ğ‘§3, ğ‘¦2, ğ‘¦3 | ğ‘§2, ğ‘¦1.

The type system we present in Â§ 3 can tell us if the conditional independence relationship
xl2 âŠ¥âŠ¥ xl3 | xl1 holds for a concrete partitioning of the modelled variables x = xl1, xl2, xl3. But

13â€˜Neighboursâ€™ refers to the variables which are connected to a factor which connects to ğ‘§.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:24

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

ğ‘†1
(cid:74)

ğ‘
(cid:75)

ğ‘†1
(cid:74)

ğ‘
(cid:75)

xl2

xl1

xl3

ğ‘†2
(cid:74)

ğ‘
(cid:75)

ğ‘†3
(cid:74)

ğ‘
(cid:75)

xl1

xl3

(cid:205)

xl2

ğ‘†2
(cid:74)

ğ‘
(cid:75)

ğ‘†3
(cid:74)

ğ‘
(cid:75)

(a) A âŠ¢2-well-typed program with parameters x.

(b) Eliminating xl2 consists of modifying only

ğ‘†2
(cid:74)

ğ‘ .
(cid:75)

Fig. 5. The factor graph and VE induced by the shedding ğ‘† â‡•Î“ ğ‘†1, ğ‘†2, ğ‘†3 according to the semi-lattice
l1 â‰¤ l2, l3.

to find the Markov blanket of a variable ğ‘§ we want to eliminate, we rely on type inference. We
define a performance ordering between the level types l3 â‰º l1 â‰º l2, where our first preference
is for variables to be of level l3, level l1 is our second preference, and l2 is our last resort. In our
implementation, we use bidirectional type-checking [Pierce and Turner 2000] to synthesise hard
constraints imposed by the type system, and resolve them, while optimising for the soft constraints
given by the â‰º ordering. This maximises the number of variables that are conditionally independent
of ğ‘§ given its blanket (l3) and minimises the number of variables forming the blanket (l1). Fixing ğ‘§
to be of l2 level, and l2 being the least preferred option, ensures that only ğ‘§ and variables dependent
on ğ‘§ through deterministic assignment are of that level.

4.5 Sampling the Discrete Parameters
Variable elimination gives a way to efficiently marginalise out a variable ğ‘§ from a model defining
density ğ‘ (x), to obtain a new density ğ‘ (x \ {ğ‘§}). In the context of SlicStan, this means we have the
tools to eliminate all discrete parameters ğœ½ ğ‘‘ , from a density ğ‘ (D, ğœ½ ğ‘, ğœ½ ğ‘‘ ) on data D, continuous
parameters ğœ½ ğ‘ and discrete parameters ğœ½ ğ‘‘ . The resulting marginal (cid:205)
ğ‘ (D, ğœ½ ğ‘, ğœ½ ğ‘‘ ) = ğ‘ (D, ğœ½ ğ‘ )
does not involve discrete parameters, and therefore we can use gradient-based methods to infer ğœ½ ğ‘ .
However, the method so far does not give us a way to infer the discrete parameters ğœ½ ğ‘‘ .

ğœ½ ğ‘‘

To infer these, we observe that ğ‘ (x) = ğ‘ (x \ {ğ‘§})ğ‘ (ğ‘§ | x \ {ğ‘§}), which means that we can
preserve the semantics of the original model (which defines ğ‘ (x)), by finding an expression for
the conditional ğ‘ (ğ‘§ | x \ {ğ‘§}). If x1, x2 is a partitioning of x \ {ğ‘§} such that ğ‘§ âŠ¥âŠ¥ x2 | x1, then
(from Definition 6) ğ‘ (x) = ğœ™1 (ğ‘§, x1)ğœ™2(x1, x2) for some functions ğœ™1 and ğœ™2. Thus, ğ‘ (ğ‘§ | x \ {ğ‘§}) =
ğœ™1(ğ‘§, x1) Â· (ğœ™2(x1, x2)/ğ‘ (x \ {ğ‘§})) âˆ ğœ™1(ğ‘§, x1).

In the case when ğ‘§ is a discrete variable of finite support, we can calculate the conditional
ğœ™1 (ğ‘§,x1)
. We can apply this calculation to the factorisation of
probability exactly: ğ‘ (ğ‘§ | x \ {ğ‘§}) =
(cid:205)ğ‘§ ğœ™1 (ğ‘§,x1)
a program Î“ âŠ¢2 ğ‘† that is induced by shredding (Theorem 2). In that case, xl2, xl1,
ğ‘ play the
(cid:75)
roles of ğ‘§, x1, and ğœ™1, respectively. Consequently, we obtain a formula for drawing xl2 conditional
on the other parameters: xl2 âˆ¼ categorical (cid:16) (cid:104)
ğ‘†2
(cid:74)
xl2

| xl2 âˆˆ supp(xl2)

ğ‘†2
(cid:74)

(cid:105) (cid:17).

(cid:205)

ğ‘ (xl2,xl1)
(cid:75)
ğ‘†2
(cid:74)

ğ‘ (xl2,xl1)
(cid:75)

4.6 A Semantics-Preserving Transformation Rule
In this section we define a source-to-source transformation that implements a single step of variable
elimination. The transformation re-writes a SlicStan program Î“, ğ‘† with a discrete model-level
parameter ğ‘§, to a SlicStan program, where ğ‘§ is a genqant-level parameter. Combining the rule
with the shredding presented in Â§ 2 results in support for efficient inference (see Â§Â§ 4.8 for discussion
of limitations) of both discrete and continuous random variables, where continuous variables can
be inferred using gradient-based methods, such as HMC or variational inference, while discrete
variables are generated using ancestral sampling. The transformation allows for SlicStan programs

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:25

with explicit use of discrete parameters to be translated to Stan. We show a step-by-step example
of our discrete parameter transformation in Â§Â§ 4.7.
4.6.1 The ğœ™, elim and gen derived forms.
We introduce three derived forms that allow us to state the rule concisely.

Variable Elimination Derived Forms

elim(intâŸ¨ğ¾âŸ© ğ‘§) ğ‘† â‰œ factor(sum( [target(ğ‘†) | ğ‘§ in 1 :ğ¾] ))
ğœ™ (intâŸ¨ğ¾1âŸ© ğ‘§1, . . . , intâŸ¨ğ¾ğ‘ âŸ© ğ‘§ğ‘ ) ğ‘†

â‰œ [. . . [target(ğ‘†) | ğ‘§1 in 1 : ğ¾1] | Â· Â· Â· | ğ‘§ğ‘ in 1 : ğ¾ğ‘ ]

gen(intâŸ¨ğ¾âŸ© ğ‘§) ğ‘† â‰œ ğ‘§ âˆ¼ categorical( [target(ğ‘†) | ğ‘§ in 1 : ğ¾] )

elim(intâŸ¨ğ¾âŸ©ğ‘§) ğ‘†

The elimination expression elim(intâŸ¨ğ¾âŸ©ğ‘§) ğ‘† adds a new factor that is equivalent to marginal-
ğ‘ (ğœ)(x) = (cid:205)ğ¾
ising ğ‘§ in ğ‘†. In other words,
ğ‘ (ğœ)(x) (see Lemma 14). A
ğ‘§=1
(cid:75)
(cid:75)
ğœ™-expression ğœ™ (intâŸ¨ğ¾1âŸ© ğ‘§1, . . . , intâŸ¨ğ¾ğ‘ âŸ© ğ‘§ğ‘ ) ğ‘† simply computes the density of the statement ğ‘†
in a multidimensional array for all possible values of the variables ğ‘§1, . . . ğ‘§ğ‘ . In other words,
ğ‘ (ğœ)(x) (Lemma 14).
(ğ‘“ = ğœ™ (intâŸ¨ğ¾1âŸ© ğ‘§1, . . . , intâŸ¨ğ¾ğ‘ âŸ© ğ‘§ğ‘ ) ğ‘†) ; factor(ğ‘“ [ğ‘§1] . . . [ğ‘§ğ‘ ])
(cid:74)
(cid:75)
The ğœ™-expression allows us to pre-compute all the work that we may need to do when marginalis-
ing other discrete variables, which results in efficient nesting. Finally, the generation expression
computes the conditional of a variable ğ‘§ given the rest of the parameters, as in Â§Â§ 4.5 (see Lemma 15).

ğ‘ (ğœ)(x) =
(cid:75)

ğ‘†
(cid:74)

ğ‘†
(cid:74)

(cid:74)

4.6.2 Eliminating a single variable ğ‘§. The (Elim Gen) rule below specifies a semantics-preserving
transformation that takes a SlicStan program with a discrete model-level parameter ğ‘§, and trans-
forms it to one where ğ‘§ is genqant-level parameter. In practice, we apply this rule once per
discrete model-level parameter, which eliminates those parameters one-by-one, similarly to the
variable elimination algorithm. And like in VE, the ordering in which we eliminate those variables
can impact performance.

The (Elim Gen) rule makes use of two auxiliary definitions that we define next. Firstly, the
neighbours of ğ‘§, Î“ne, are defined by the relation ne(Î“, Î“â€², ğ‘§) (Definition 7), which looks for non-data
and non-continuous l1-variables in Î“â€².

Definition 7 (Neighbours of ğ‘§, ne(Î“, Î“â€², ğ‘§)). For a âŠ¢ typing environment Î“, a âŠ¢2 typing environ-

ment Î“â€² = Î“â€²

and a variable ğ‘§ âˆˆ dom(Î“â€²

ğœ, Î“â€²
x
ne(Î“, Î“â€², ğ‘§) â‰œ {ğ‘¥ : (ğœ, â„“) âˆˆ Î“â€²

x), the neighbours of ğ‘§ are defined as:

x | â„“ = l1 and Î“(ğ‘¥) = (intâŸ¨ğ¾âŸ©, model) for some ğ¾ }

Secondly, st(ğ‘†2) (Definition 8) is a statement that has the same store semantics as ğ‘†2, but density
semantics of 1:
ğ‘ = 1. This ensures that the transformation preserves
(cid:75)
both the density semantics and the store semantics of ğ‘† and is needed because gen(ğ‘§)ğ‘†2 discards
any store computed by ğ‘†2, thus only contributing to the weight.

ğ‘  , but
(cid:75)

ğ‘  =
(cid:75)

st(ğ‘†2)

st(ğ‘†2)

ğ‘†2
(cid:74)

(cid:74)

(cid:74)

Definition 8. Given a statement ğ‘†, we define the statement st(ğ‘†) by replacing all factor(ğ¸)- and

ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›)-substatements in ğ‘† by skip (see Appendix A for the precise definition).

The elim-gen rule:

(Elim Gen)

Î“(ğ‘§) = (intâŸ¨ğ¾âŸ©, model)

Î“ne = ne(Î“, Î“ğ‘€, ğ‘§)

ğ‘† â€² = ğ‘†ğ· ; ğ‘† â€²

ğ‘€ ; ğ‘†ğ‘„

Î“ âŠ¢ ğ‘† : data ğ‘† â‡•Î“ ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„

ğ‘€ = ğ‘†1; ğ‘“ = ğœ™ (Î“ne){elim(intâŸ¨ğ¾âŸ©ğ‘§) ğ‘†2}; factor(ğ‘“ [dom(Î“ne)]); ğ‘†3; gen(ğ‘§)ğ‘†2; st(ğ‘†2)
ğ‘† â€²
ğ‘§
âˆ’â†’ Î“ğ‘€ Î“ğ‘€ âŠ¢2 ğ‘†ğ‘€ : l1
ğ‘§
âˆ’â†’ Î“â€², ğ‘† â€²

ğ‘†ğ‘€ â‡•Î“ğ‘€ ğ‘†1, ğ‘†2, ğ‘†3

Î“, ğ‘†

Î“

Î“â€² âŠ¢ ğ‘† â€² : data

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:26

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

We can use the (Elim Gen) rule to transforms a SlicStan program, with respect to a parameter ğ‘§,

as described by Algorithm 1. This involves three main steps:

(1) Separate out ğ‘†ğ‘€ â€” the model-level sub-part of ğ‘† â€” using the top-level type system âŠ¢ (line 1

of Algorithm 1).

(2) Separate out ğ‘†2 â€” the part of ğ‘†ğ‘€ that involves the discrete parameter ğ‘§ â€” using the conditional

independence type system âŠ¢2 (lines 2â€“8).

(3) Perform a single VE step by marginalising out ğ‘§ in ğ‘†2 and sample ğ‘§ from the conditional

probability specified by ğ‘†2 (lines 10â€“11).

Algorithm 1. Single step of applying (Elim Gen)

Arguments: (Î“, ğ‘†), ğ‘§
Requires: Î“ âŠ¢ ğ‘† : data
Returns: (Î“â€², ğ‘† â€²)

// A program (Î“, ğ‘†); the variable ğ‘§ to eliminate
// (Î“, ğ‘†) is well-typed
// The transformed program

1: Slice (Î“, ğ‘†) into ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ according to ğ‘† â‡•Î“ ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ .
2: Derive incomplete Î“ğ‘€ from Î“ based on Î“
3:
4:
5:

6:
7: Infer missing types of Î“ğ‘€ according to Î“ğ‘€ âŠ¢2 ğ‘†ğ‘€ : l1.
8: Slice (Î“ğ‘€, ğ‘†ğ‘€ ) into ğ‘†1, ğ‘†2, ğ‘†3 according to ğ‘†ğ‘€ â‡•Î“ğ‘€ ğ‘†1, ğ‘†2, ğ‘†3.
9:
10: Î“ne = ne(Î“, Î“ğ‘€, ğ‘§)
ğ‘† â€²
ğ‘€ = (ğ‘†1;
11:

ğ‘§
âˆ’â†’ Î“ğ‘€ . // data of Î“ is of level l1 in Î“ğ‘€ .

// Continuous model var. of Î“ are l1 in Î“ğ‘€ .
// ğ‘§ is of level l2 in Î“ğ‘€ .
// All other model variables are given
// a type level placeholder in Î“ğ‘€ .

// Determine the discrete neighbours of ğ‘§.
// Eliminate ğ‘§ and re-generate ğ‘§.

ğ‘“ = ğœ™ (Î“ne){elim(intâŸ¨ğ¾âŸ©ğ‘§) ğ‘†2};
factor(ğ‘“ [dom(Î“ne)]);
ğ‘†3;
gen(ğ‘§) ğ‘†2;
st(ğ‘†2))
ğ‘€ ; ğ‘†ğ‘„

12: ğ‘† â€² = ğ‘†ğ· ; ğ‘† â€²
13: Infer an optimal Î“â€² according to Î“â€² âŠ¢ ğ‘† â€² : data
14: return (Î“â€², ğ‘† â€²)

All other sub-statements of the program, ğ‘†ğ·, ğ‘†1, ğ‘†3 and ğ‘†ğ‘„ , stay the same during the transfor-
mation. By isolating ğ‘†2 and transforming only this part of the program, we make sure we do not
introduce more work than necessary when performing variable elimination.

To efficiently marginalise out ğ‘§, we want to find the Markov boundary of ğ‘§ given all data and
continuous model parameters: the data is given, and marginalisation happens inside the continuous
parameters inference loop, so we can see continuous parameters as given for the purpose of discrete
parameters marginalisation. Thus we are looking for the relationship: ğ‘§ âŠ¥âŠ¥ ğœ½ ğ‘‘2 | D, ğœ½ ğ‘, ğœ½ ğ‘‘1, where
D is the data, ğœ½ ğ‘ are the continuous model-level parameters, ğœ½ ğ‘‘1 is a subset of the discrete model-
level parameters that is as small as possible (the Markov blanket), and ğœ½ ğ‘‘2 is the rest of the discrete
model-level parameters. We can find an optimal partitioning of the discrete parameters ğœ½ ğ‘‘1, ğœ½ ğ‘‘2 that
respects this relationship of interest using the type system from Â§ 3 together with type inference.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:27

The judgement Î“ğ‘€ âŠ¢2 ğ‘†ğ‘€ : l1 induces a conditional independence relationship of the form
ğ‘§
âˆ’â†’ Î“ğ‘€ (Definition 9) constrains the
xl2 âŠ¥âŠ¥ xl3 | xl1, where x |= Î“x (Theorem 3). The relation Î“
form of Î“ğ‘€ based on Î“. This is needed to make sure we are working with a relationship of the form
we are interested in â€” ğ‘§ âŠ¥âŠ¥ ğœ½ ğ‘‘2 | D, ğœ½ ğ‘, ğœ½ ğ‘‘1 â€” and that base types ğœ are the same between Î“ and Î“ğ‘€ .
ğ‘§
In particular, Î“
âˆ’â†’ Î“ğ‘€ constrains ğ‘§ to be the only l2 parameter in Î“ğ‘€ and all data and continuous
model-level parameters of Î“ are l1 in Î“ğ‘€ . Note, dom(Î“ğ‘€ ) âŠ† dom(Î“) and Î“ğ‘€ only contains variables
that are of level model and below in Î“. Variables that are of level genqant in Î“ are not in Î“ğ‘€ .

Definition 9 (Î“

ğ‘§
âˆ’â†’ Î“â€²).

For a âŠ¢ typing environment Î“ and a âŠ¢2 typing environment Î“â€², a variable ğ‘§ and a statement ğ‘†, we have:
x,l2 = {ğ‘§ : ğœ, l2} for some ğœ

Î“(ğ‘§) = (ğœ, model) and Î“â€²
ğ‘¥ : (ğœ, â„“) âˆˆ Î“ such that â„“ â‰¤ model â‡â‡’ ğ‘¥ : (ğœ, â„“ â€²) âˆˆ Î“â€² for some â„“ â€² âˆˆ {l1, l2, l3}
ğ‘¥ : (ğœ, data) âˆˆ Î“ â†’ ğ‘¥ : (ğœ, l1) âˆˆ Î“â€²
ğ‘¥ : (ğœ, model) âˆˆ Î“x and ğœ = real or ğœ = real[]...[] â†’ ğ‘¥ : (ğœ, l1) âˆˆ Î“â€²

Î“

ğ‘§
âˆ’â†’ Î“â€² =

ï£±ï£´ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£´

Following convention from earlier in the paper, we use level subscripts to refer to specific subsets
x,l2 refers to the subset of parameters x in Î“â€², which are of level l2.

of Î“: in the above definition, Î“â€²

ï£³

4.7 Marginalising Multiple Variables: An example
To eliminate more than one discrete parameter, we apply the (Elim Gen) rule repeatedly. Here, we
work through a full example, showing the different steps of this repeated (Elim Gen) transformation.
Consider an extended version of the HMM model from the beginning of this section (Program

D), reformulated to include transformed parameters:

G. An extended HMM

The typing environment

ğ‘† = real[2] phi âˆ¼ beta(1, 1);

Î“ = {ğ‘¦1,2,3 : (real, data),

real[2] theta âˆ¼ beta(1, 1);
real theta0 = theta[0];
int<2> z1 âˆ¼ bernoulli(theta0);
real theta1 = theta[z1];
int<2> z2 âˆ¼ bernoulli(theta1);
real theta2 = theta[z2];
int<2> z3 âˆ¼ bernoulli(theta2);
real phi1 = phi[z1];
real phi2 = phi[z2];
real phi3 = phi[z3];
data real y1 âˆ¼ normal(phi1, 1);
data real y2 âˆ¼ normal(phi2, 1);
data real y3 âˆ¼ normal(phi3, 1);
real theta3 = theta[z3];
int genz âˆ¼ bernoulli(theta4);

ğœ™ : (real[2], model),
ğœƒ : (real[2], model),
ğœƒ0,1,2 : (real, model),
ğœ™1,2,3 : (real, model),
ğ‘§1,2,3 : (int<2>, model),
ğœƒ3 : (real, genqant),
ğ‘”ğ‘’ğ‘›ğ‘§ : (int<2>, genqant)}

The variables we are interested in transforming are ğ‘§1, ğ‘§2 and ğ‘§3: these are the model-level
discrete parameters of Program G. The variable genz is already at genqant level, so we can
sample this with ancestral sampling (no need for automatic marginalisation).

We eliminate ğ‘§1, ğ‘§2 and ğ‘§3 one by one, in that order. The order of elimination generally has a
significant impact on the complexity of the resulting program (see also Â§Â§ 4.8), but we do not focus
on how to choose an ordering here. The problem of finding an optimal ordering is well-studied
[Amir 2010; Arnborg et al. 1987; KjÃ¦rulff 1990] and is orthogonal to the focus of our work.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:28

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

4.7.1 Eliminating ğ‘§1. Eliminating a single variable happens in three steps, as shown in Figure 6:
standard shredding into ğ‘†ğ·, ğ‘†ğ‘€ and ğ‘†ğ‘„ , conditional independence shredding of ğ‘†ğ‘€ into ğ‘†1, ğ‘†2 and
ğ‘†3, and combining everything based on (Elim Gen).

(1) Standard shredding: ğ‘† â‡•Î“ ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ . Firstly, we separate out the parts of the program that
depend on discrete parameters generatively. That is any part of the program that would be
in generated quantities with respect to the original program. In our case, this includes the
last two lines in ğ‘†. This would also include the gen parts of the transform program, that
draw discrete parameters as generated quantities. Thus, ğ‘† â‡•Î“ ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ , where ğ‘†ğ· is empty,

(1) Standard shredding of ğ‘†

(3) Applying (Elim Gen): Program G-1

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

1

2

3

4

5

6

7

8

9

10

11

12

13

14

ğ‘†ğ· = skip;
ğ‘†ğ‘€ = phi âˆ¼ beta(1, 1);

theta âˆ¼ beta(1, 1);
theta0 = theta[0];
z1 âˆ¼ bernoulli(theta0);
theta1 = theta[z1];
z2 âˆ¼ bernoulli(theta1);
theta2 = theta[z2];
z3 âˆ¼ bernoulli(theta2);
phi1 = phi[z1];
phi2 = phi[z2];
phi3 = phi[z3];
y1 âˆ¼ normal(phi1, 1);
y2 âˆ¼ normal(phi2, 1);
y3 âˆ¼ normal(phi3, 1);

ğ‘†ğ‘„ = theta3 = theta[z3];

genz âˆ¼ bernoulli(theta3);

(2) CI shredding of ğ‘†ğ‘€

ğ‘†1 = phi âˆ¼ beta(1, 1);

theta âˆ¼ beta(1, 1);
theta0 = theta[0];
ğ‘†2 = z1 âˆ¼ bernoulli(theta0);

theta1 = theta[z1];
z2 âˆ¼ bernoulli(theta1);
phi1 = phi[z1];
y1 âˆ¼ normal(phi1, 1);

ğ‘†3 = theta2 = theta[z2];

z3 âˆ¼ bernoulli(theta2);
phi2 = phi[z2];
phi3 = phi[z3];
y2 âˆ¼ normal(phi2, 1);
y3 âˆ¼ normal(phi3, 1);

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

phi âˆ¼ beta(1, 1);
theta âˆ¼ beta(1, 1);
theta0 = theta[0];

f1 = ğœ™([int<2> z2]){
elim(int<2> z1){

z1 âˆ¼ bernoulli(theta0);
theta1 = theta[z1];
z2 âˆ¼ bernoulli(theta1);
phi1 = phi[z1];
y1 âˆ¼ normal(phi1, 1);

}}

factor(f1[z2]);

theta2 = theta[z2];
z3 âˆ¼ bernoulli(theta2);
phi2 = phi[z2];
phi3 = phi[z3];
y2 âˆ¼ normal(phi2, 1);
y3 âˆ¼ normal(phi3, 1);

gen(int z1){

z1 âˆ¼ bernoulli(theta0);
theta1 = theta[z1]
z2 âˆ¼ bernoulli(theta1);
phi1 = phi[z1];
y1 âˆ¼ normal(phi1, 1);

}
theta1 = theta[z1];
phi1 = phi[z1];

theta3 = theta[z3];
genz âˆ¼ bernoulli(theta3);

Fig. 6. Step-by-step elimination of ğ‘§1 in Program G.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:29

ğ‘†ğ‘„ = (theta3 = theta[z3];genz âˆ¼ bernoulli(theta3)), and ğ‘†ğ‘€ is the rest of the program (see
Figure 6, (1)).

(2) Conditional independence shredding: ğ‘†ğ‘€ â‡•Î“ğ‘€ ğ‘†1, ğ‘†2, ğ‘†3. In the next step, we want to establish
a conditional independence relationship ğ‘§1 | ğ´ âŠ¥âŠ¥ y, ğœ™0, ğœƒ0, ğµ, where ğ‘§1 is some discrete
parameter and ğ´, ğµ is a partitioning of the rest of the discrete parameters in the model:
{ğ‘§2, ğ‘§3}. We derive a new, âŠ¢2 typing environment Î“ğ‘€ , using Î“

ğ‘§
âˆ’â†’ Î“ğ‘€ :

Î“ğ‘€ = {ğ‘¦1,2,3 : (real, l1), ğœ™ : (real[2], l1), ğœƒ : (real[2], l1),
ğ‘§1 : (int<2>, l2), ğ‘§2 : (int<2>, ?), ğ‘§3 : (int<2>, ?)
ğœƒ0 : (real, l1), ğœƒ1,2 : (real, ?), ğœ™1,2,3 : (real, ?)}

Here, we use the notation ? for a type placeholder, which will be inferred using type inference.
The optimal Î“ğ‘€ under the type inference soft constraint l3 â‰º l1 â‰º l2 such that Î“ğ‘€ âŠ¢2 ğ‘†ğ‘€ : l1
is such that the levels of ğœƒ1 and ğœ™1 are l2, ğ‘§2 is l1 and ğœƒ2, ğœ™2 and ğœ™3 are l3. Shredding then
gives us ğ‘†ğ‘€ â‡•Î“ğ‘€ ğ‘†1, ğ‘†2, ğ‘†3, as in Figure 6, (2).

(3) Combining based on (Elim Gen). Having rearranged the program into suitable sub-statements,

we use (Elim Gen) to get Program G-1 (Figure 6, (3)) and:
Î“â€² = {ğ‘¦1,2,3 : (real, data), ğœ™ : (real, model),

ğœƒ1 : (real, genqant), ğœƒ0,2 : (real, model),
ğœ™1 : (real, genqant), ğœ™2,3 : (real, model),
ğ‘§1 : (int, genqant), ğ‘§2,3 : (int<2>, model),
ğœƒ3 : (real, genqant), ğ‘”ğ‘’ğ‘›ğ‘§ : (int<2>, genqant)}

Eliminating ğ‘§2. We apply the same procedure to eliminate the next variable, ğ‘§2, from the updated
Program G-1. The variable ğ‘§1 is no longer a model-level parameter, thus the only neighbouring
parameter of ğ‘§2 is ğ‘§3. Note also that the computation of the factor ğ‘“1 does not include any free
discrete parameters (both ğ‘§1 and ğ‘§2 are local to the computation due to elim and ğœ™). Thus, we do
not need to include the computation of this factor anywhere else in the program (it does not get
nested into other computations). We obtain a new program, Program G-2:

Program G-2

phi âˆ¼ beta(1, 1);
theta âˆ¼ beta(1, 1);
theta0 = theta[0];

f1 = ğœ™([int<2> z2]){ elim(int<2> z1){

z1 âˆ¼ bernoulli(theta0);
theta1 = theta[z1];
z2 âˆ¼ bernoulli(theta1);
phi1 = phi[z1];
y1 âˆ¼ normal(phi1, 1);

}}

f2 = ğœ™([int<2> z3]){ elim(int<2> z2){

factor(f1[z2]);
theta2 = theta[z2];
z3 âˆ¼ bernoulli(theta2);
phi2 = phi[z2];

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

y2 âˆ¼ normal(phi2, 1);

}}

factor(f2[z3]);
phi3 = phi[z3];
y3 âˆ¼ normal(phi3, 1);

gen(int z2){

factor(f1[z2]);
theta2 = theta[z2];
z3 âˆ¼ bernoulli(theta2);
phi2 = phi[z2];
y2 âˆ¼ normal(phi2, 1);

}
theta2 = theta[z2];
phi2 = phi[z2];

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:30

34

35

36

37

38

39

gen(int z1){

z1 âˆ¼ bernoulli(theta0);
theta1 = theta[z1];
z2 âˆ¼ bernoulli(theta1);
phi1 = phi[z1];
y1 âˆ¼ normal(phi1, 1);

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

40

41

42

43

44

45

}
theta1 = theta[z1];
phi1 = phi[z1];

theta3 = theta0[z3];
.
genz âˆ¼ bernoulli(theta3);

Eliminating ğ‘§3. Finally, we eliminate ğ‘§3, which is the only discrete model-level parameter left in
the program. Thus, ğ‘§3 has no neighbours and ğ‘“3 is of arity 0: it is a real number instead of a vector.

The final program generated by our implementation is Program G-3:

Program G-3

phi0 âˆ¼ beta(1, 1);
theta0 âˆ¼ beta(1, 1);

f1 = ğœ™(int<2> z2){ elim(int<2> z1){

z1 âˆ¼ bernoulli(theta0);
theta1 = theta[z1];
z2 âˆ¼ bernoulli(theta1);
phi1 = phi[z1];
y1 âˆ¼ normal(phi1, 1);

}}

f2 = ğœ™(int<2> z3){elim(int<2> z2){

factor(f1[z2]);
theta2 = theta[z2];
z3 âˆ¼ bernoulli(theta2);
phi2 = phi[z2];
y2 âˆ¼ normal(phi2, 1);

}}

f3 = ğœ™(){elim(int<2> z3){

factor(f2[z3]);
phi3 = phi[z3];
y3 âˆ¼ normal(phi3, 1);

}}

factor(f3);

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

gen(int z3){

factor(f2[z3]);
phi3 = phi[z3];;
y3 âˆ¼ normal(phi3, 1);

}
phi3 = phi[z3];
gen(int z2){

factor(f1[z2]);
theta2 = theta[z2];;
z3 âˆ¼ bernoulli(theta2);
phi2 = phi[z2];;
y2 âˆ¼ normal(phi2, 1);

}
theta2 = theta[z2];
phi2 = phi[z2];
gen(int z1){

z1 âˆ¼ bernoulli(theta0);
theta1 = theta[z1];
z2 âˆ¼ bernoulli(theta1);
phi1 = phi[z1];
y1 âˆ¼ normal(phi1, 1);

}
theta1 = theta[z1];
phi1 = phi[z1];

gen3 = theta[z3];
genz âˆ¼ bernoulli(theta3);

4.8 Relating to Variable Elimination and Complexity Analysis
Assume D, ğœ½ ğ‘‘ , and ğœ½ ğ‘ are the data, discrete model-level parameters, and continuous model-level
parameters, respectively. As ğ‘†2 is a single-level statement of level l2, the density semantics of ğ‘†2 is
of the form ğœ“ (xl1, xl2) = ğœ“ (D, ğœ½ ğ‘, ğœ½ ğ‘‘,l1, ğ‘§) (Lemma 11).

As elim(intâŸ¨ğ¾âŸ©ğ‘§) _ binds the variable ğ‘§ and ğœ™ (Î“ne){_} binds the variables in dom(Î“ne), the ex-
pression ğœ™ (Î“ne){elim(intâŸ¨ğ¾âŸ©ğ‘§) ğ‘†2 depends only on continuous parameters and data, and it contains
no free mentions of any discrete variables. This means that the expression will be of level l1 and

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:31

shredded into ğ‘†1 during the marginalisation of any subsequent discrete variable ğ‘§ â€². The substate-
ment ğ‘†2 will always be some sub-statement of the original program (prior to any transformations),
up to potentially several constant factors of the form factor(ğ‘“ [dom(Î“ne)]).

This observation makes it easy to reason about how repeated application of the (Elim Gen)
transform changes the complexity of the program. If the complexity of a SlicStan program with ğ‘
discrete parameters of support 1, . . . , ğ¾, is O (ğ‘†), then the complexity of a program where we naively
marginalised out the discrete variables (Program E) will be O (ğ‘† Ã— ğ¾ ğ‘ ). In contrast, transforming
with (Elim Gen) gives us a program of complexity at most O (ğ‘ Ã— ğ‘† Ã— ğ¾ ğ‘€+1) where ğ‘€ is the largest
number of direct neighbours in the factor graph induced by the program. Further, the complexity
could be smaller depending on the elimination ordering of choice. This result is not surprising, as
we conjecture that repeated application of (Elim Gen) is equivalent to variable elimination (though
we do not formally prove this equivalence), which is of the same complexity.

It is clear from this complexity observation that VE is not always efficient. When the dependency
graph is dense, ğ‘€ will be close to ğ‘ , thus inference will be infeasible for large ğ‘ . Fortunately,
in many practical cases (such as those discussed in Â§ 5), this graph is sparse (ğ‘€ â‰ª ğ‘ ) and our
approach is suitable and efficient. We note that this is a general limitation of exact inference of
discrete parameters, and it is not a limitation of our approach in particular.

4.9 Semantic Preservation of the Discrete Variable Transformation
The result we are interested in is the semantic preservation of the transformation rule

ğ‘§
âˆ’â†’.

Theorem 4 (Semantic preservation of

ğ‘§
âˆ’â†’).

For SlicStan programs Î“, ğ‘† and Î“â€², ğ‘† â€², and a discrete parameter ğ‘§: Î“, ğ‘†

ğ‘§
âˆ’â†’ Î“â€², ğ‘† â€² implies

=

ğ‘†
(cid:74)

(cid:75)

ğ‘† â€²
(cid:74)

.
(cid:75)

Proof. Note that shredding preserves semantics with respect to both âŠ¢ and âŠ¢2 (Lemma 6 and
10), examine the meaning of derived forms (Lemma 14 and 15), note properties of single-level
statements (Lemma 11), and apply the results on factorisation of shredding (Theorem 1) and
â–¡
conditional independence (Theorem 3). We present the full proof in Appendix A.

In addition, we also show that it is always possible to find a program derivable with (Elim Gen),

such that a model-level variable ğ‘§ is transformed to a genqant-level variable.

Lemma 12 (Existence of model to genqant transformation). For any SlicStan program
Î“, ğ‘† such that Î“ âŠ¢ ğ‘† : l1, and a variable ğ‘§ âˆˆ dom(Î“) such that Î“(ğ‘§) = (intâŸ¨ğ¾âŸ©, model), there exists a
SlicStan program Î“â€², ğ‘† â€², such that:

Î“, ğ‘†

ğ‘§
âˆ’â†’ Î“â€², ğ‘† â€²

and

Î“â€²(ğ‘§) = (intâŸ¨ğ¾âŸ©, genquant)

Proof. By inspecting the level types of variables in each part of a program derivable using (Elim
â–¡

Gen). We include the full proof in Appendix A.

The practical usefulness of Theorem 4 stems from the fact that it allows us to separate inference
for discrete and continuous parameters. After applying (Elim Gen) to each discrete model-level
parameter, we are left with a program that only has genqant-level discrete parameters (Lemma 12).
We can then slice the program into ğ‘†hmc and ğ‘†gen and infer continuous parameters by using HMC
(or other algorithms) on ğ‘†hmc and, next, draw the discrete parameters using ancestral sampling by
running forward ğ‘†gen. Theorem 4 tells us that this is a correct inference strategy.

When used in the context of a model with only discrete parameters, our approach corresponds
to exact inference through VE. In the presence of discrete and continuous parameters, our transfor-
mation gives an analytical sub-solution for the discrete parameters in the model.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:32

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

A limitation of our method is that, due to its density-based nature, it can only be applied to models
of fixed size. It cannot, in its current form, support models where the number of random variables
changes during inference, such as Dirichlet Processes. However, this is a typical constraint adopted
in Bayesian inference for efficiency. Another limitation is that discrete variables need to have finite
(and fixed) support. For example, the method cannot be applied to transform a Poisson-distributed
variable. In some but not all applications, truncating unbounded discrete parameters at a realistic
upper bound would suffice to make the method applicable.

An advantage of our method is that it can be combined with any inference algorithm that
requires a function proportional to the joint density of variables. This includes gradient-based
algorithms, such as HMC and variational inference, but it can also be used with methods that allow
for (e.g. unbounded) discrete variables as an analytical sub-solution that can optimise inference. For
example, consider a Poisson variable ğ‘› âˆ¼ Poisson(ğœ†) and a Binomial variable ğ‘˜ âˆ¼ Binomial(ğ‘›, ğ‘).
While ğ‘› is of infinite support, and we cannot directly sum over all of its possible values, analytically
marginalising out ğ‘› gives us ğ‘˜ âˆ¼ Poisson(ğœ†ğ‘). Future work can utilise such analytical results in
place of explicit summation where possible.

4.10 Scope and limitations of (Elim Gen)

Program H

data int K;
real[K][K] phi;
real[K] mu;
int<K> z1 âˆ¼

categorical(phi[0]);

int<K> z2;
int<K> z3;

if (z1 > K/2) {

z2 âˆ¼ categorical(phi[z1]);
z3 âˆ¼ categorical(phi[z2]);

}
else {

z2 âˆ¼ categorical(phi[z1]);
z3 âˆ¼ categorical(phi[z1]);

}

data real y1 âˆ¼

normal(mu[z1],1);

data real y2 âˆ¼

normal(mu[z2],1);

data real y3 âˆ¼

normal(mu[z3],1);

Program H-A: Optimal
transformation
. . .

factor(elim(int<2> z1) {
z1 âˆ¼ categorical(phi[0]);
y1 âˆ¼ normal(mu[z1], 1));

if (z1 > K/2) {
elim(int<2> z2) {
elim(int<2> z3) {
z2 âˆ¼ categorical(phi[z1]);
z3 âˆ¼ categorical(phi[z2]);
y2 âˆ¼ normal(mu[z2],1);
y3 âˆ¼ normal(mu[z3],1);

}}}

else {
elim(int<2> z2) {
z2 âˆ¼ categorical(phi[z1]));
y2 âˆ¼ normal(mu[z2],1);
}
elim(int<2> z3) {
z3 âˆ¼ categorical(phi[z1]));
y3 âˆ¼ normal(mu[z3],1);

}}});

Program H-B: Our
transformation
. . .

f1 = ğœ™(int<2> z2, int<2> z3){

elim(int<2> z1){
z1 âˆ¼ categorical(phi[0]);
if(z1 > K/2){

z2 âˆ¼ categorical(phi[z1]);
z3 âˆ¼ categorical(phi[z2]);

}
else{

z2 âˆ¼ categorical(phi[z1]);
z3 âˆ¼ categorical(phi[z1]);

}
y1 âˆ¼ normal(mu[z1], 1);
y2 âˆ¼ normal(mu[z2], 1);
y3 âˆ¼ normal(mu[z3], 1);

}}
f2 = ğœ™(int<2> z3){
elim(int<2>z2)

factor(f1[z2,z3]);}

f3 = ğœ™(){

elim(int<2> z3)

factor(f2[z3]);}

factor(f3);

Fig. 7. A program with different conditional dependencies depending on control flow.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:33

Previously, we discussed the scope of the conditional independence result of the paper (Â§Â§ 3.3).
Similarly, here we demonstrate with an example, a situation where our approach of eliminating
variables one-by-one using (Elim Gen) is not optimal.

Consider the simple control-flow Program H below. In this example ğ‘§2 and ğ‘§3 are not conditionally
independent given ğ‘§1 = 1, but they are conditionally independent given ğ‘§1 > ğ¾/2. This indepen-
dence is also referred to as context-specific independence [Boutilier et al. 1996; Minka and Winn
2009]. We can use different elimination strategy depending on which if-branch of the program we
find ourselves. Program H-A demonstrates this: its complexity is O ( ğ¾
2ğ¾ 3+ğ¾ 2).
The typing relation âŠ¢2 can only detect overall (in)dependencies, where sets of variables are
conditionally independent given some ğ‘‹ , regardless of what value ğ‘‹ takes. Thus, our static analysis
is not able to detect that ğ‘§2 âŠ¥âŠ¥ ğ‘§3 | ğ‘§1 = 0. This results in Program H-B, which has complexity
O (ğ¾ 3 + ğ¾ 2 + ğ¾): the same complexity as the optimal Program H-A, but with a bigger constant.

2 Ã—2Ã—ğ¾) = O ( 1

2 Ã—ğ¾ 2+ ğ¾

Even if we extend our approach to detect that ğ‘§2 and ğ‘§3 are independent in one branch, it is
unclear how to incorporate this new information. Our strategy is based on computing intermediate
factors that allow re-using already computed information: eliminating ğ‘§1 requires computing a new
factor ğ‘“1 that no longer depends on ğ‘§1. We represented ğ‘“1 with a multidimensional array indexed
by ğ‘§2 and ğ‘§3, and we need to define each element of that array, thus we cannot decouple them for
particular values of ğ‘§1.

Runtime systems that compute intermediate factors in a similar way, such as Pyro [Uber AI Labs
2017], face that same limitation. Birch [Murray and SchÃ¶n 2018], on the other hand, will be able
to detect the conditional independence in the case ğ‘§1 > ğ¾/2, but it will not marginalise ğ‘§1, as it
cannot (analytically) marginalise over branches. Instead, it uses Sequential Monte Carlo (SMC) to
repeatedly sample ğ‘§1 and proceed according to its value.

5 IMPLEMENTATION AND EMPIRICAL EVALUATION
The transformation we introduce can be useful for variety of models, and it can be adapted to PPLs
to increase efficiency of inference and usability. Most notably, it can be used to extend Stan to allow
for direct treatment of discrete variables, where previously that was not possible.

In this section, we present a brief overview of such a discrete parameter extension for SlicStan
(Â§Â§ 5.1). To evaluate the practicality of (Elim Gen), we build a partial NumPyro [Phan et al. 2019]
backend for SlicStan, and compare our static approach to variable elimination for discrete parameters
to the dynamic approach of NumPyro (Â§Â§ 5.2). We find that our static transformation strategy speeds
up inference compared to the dynamic approach, but that for models with a large number of discrete
parameters performance gains could be diminished by the exponentially growing compilation time
(Â§Â§ 5.3).

In addition to demonstrating the practicality of our contribution through empirical evaluation,

we also discuss the usefulness of our contribution through examples, in Appendix B.

5.1 Implementation
We update the original SlicStan14 according to the modification described in Â§ 2, and extend it to
support automatic variable elimination through the scheme outlined in Â§ 4. As with the first version
of SlicStan, the transformation produces a new SlicStan program that is then translated to Stan.

The variable elimination transformation procedure works by applying (Elim Gen) iteratively,
once for each discrete variable, as we show in Â§Â§ 4.7. The level types l1, l2 and l3 are not exposed to
the user, and are inferred automatically. Using bidirectional type-checking, we are able to synthesise
a set of hard constraints that the levels must satisfy. These hard constraints will typically be satisfied

14Available at https://github.com/mgorinova/SlicStan.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:34

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

by more than one assignment of variables to levels. We search for the optimal types with respect to
the soft constraints l3 â‰º l1 â‰º l2, using the theorem prover Z3 [De Moura and BjÃ¸rner 2008].

5.2 Empirical evaluation
To evaluate the practicality of our approach, we compare to the prior work most closely related
to ours: that of Obermeyer et al. [2019], who implement efficient variable-elimination for plated
factor graphs in Pyro [Uber AI Labs 2017]. Their approach uses effect-handlers and dynamically
marginalises discrete variables, so that gradient-based inference schemes can be used for the
continuous parameters. This VE strategy has also been implemented in NumPyro [Phan et al. 2019].
As both ours and Pyroâ€™s strategies correspond to VE, we do not expect to see differences in
complexity of the resulting programs. However, as in our case the VE algorithm is determined
and set up at compile time, while in the case of Pyro/NumPyro, this is done at run time. The main
question we aim to address is whether setting up the variable elimination logistics at compile time
results in a practical runtime speed-up.

To allow for this comparison, we built a partial NumPyro backend for SlicStan. For each model

we choose, we compare the runtime performance of three NumPyro programs:

(1) The NumPyro program obtained by translating a SlicStan program with discrete parameters to
NumPyro directly (labelled â€˜NumPyroâ€™). This is the baseline: we leave the discrete parameter
elimination to NumPyro.

(2) The NumPyro program obtained by translating a transformed SlicStan program, where all
discrete parameters have been eliminated according to (Elim Gen) (labelled â€˜SlicStanâ€™). The
variable elimination set-up is done at compile time; NumPyro does not do any marginalisation.
(3) A hand-optimised NumPyro program, which uses the plate and markov program constructs
to specify some of the conditional independencies in the program (labelled â€˜NumPyro-Optâ€™).
In each case, we measure the time (in seconds) for sampling a single chain consisting of 2500

warm-up samples, and 10000 samples using NUTS [Hoffman and Gelman 2014].

In addition, we report three compilation times:
(1) The compilation time of the NumPyro program obtained by translating a SlicStan program

with discrete parameters to NumPyro directly (labelled â€˜NumPyroâ€™).

(2) The compilation time of the NumPyro program obtained by translating a transformed SlicStan

program, where all discrete parameters have been eliminated (labelled â€˜SlicStanâ€™).

(3) The time taken for the original SlicStan program to be transformed using (Elim Gen) and

translated to NumPyro code (labelled â€˜SlicStan-to-NumPyroâ€™).

We consider different numbers of discrete parameters for each model, up to 25 discrete parameters.
We do not consider more than 25 parameters due to constraints of the NumPyro baseline, which we
discuss in more detail in Â§Â§ 5.3. We run experiments on two classes of model often seen in practice:
hidden Markov models (Â§Â§Â§ 5.2.1) and mixture models (Â§Â§Â§ 5.2.2). To ensure a fair comparison,
the same elimination ordering was used across experiments. Experiments were run on a dual-core
2.30GHz Intel Xeon CPU and a Tesla T4 GPU (when applicable). All SlicStan models used in the
experiments are available at the SlicStan repo.

5.2.1 Hidden Markov models. We showed several examples of simple HMMs throughout the paper
(Program A, Program D, Program G) and worked through a complete example of VE in an HMM
(4.7). We evaluate our approach on both the simple first-order HMM seen previously, and on two
additional ones: second-order HMM and factorial HMM.

First-order HMM. The first-order HMM is a simple chain of ğ‘ discrete variables, each taking a
value from 1 to ğ¾ according to a categorical distribution. The event probabilities for the distribution

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:35

of ğ‘§ğ‘› are given by ğœ½ ğ‘§ğ‘›âˆ’1, where ğœ½ is some given ğ¾ Ã— ğ¾ matrix. Each data point y is modelled
as coming from a Gaussian distribution with mean ğœ‡ğ‘§ğ‘› and standard deviation 1, where ğ is a
ğ¾âˆ’dimensional continuous parameter of the model.

ğœ‡ğ‘˜ âˆ¼ N (0, 1)

for ğ‘˜ âˆˆ 1, . . . , ğ¾

ğ‘§1 âˆ¼ categorical(ğœ½ 1)

ğ‘§ğ‘› âˆ¼ categorical(ğœ½ ğ‘§ğ‘›âˆ’1)
ğ‘¦ğ‘› âˆ¼ N (ğœ‡ğ‘§ğ‘›, 1)

for ğ‘› âˆˆ 2, . . . , ğ‘

for ğ‘› âˆˆ 1, . . . , ğ‘

We measure the compilation time and the time taken to sample 1 chain with each of the 3
NumPyro programs corresponding to this model. We use ğ¾ = 3 and different values for ğ‘ , ranging
from ğ‘ = 3 to ğ‘ = 25. Figure 8 shows a summary of the results. We see that both on CPU and
GPU, the program transformed using SlicStan outperforms the automatically generated NumPyro
and also the manually optimised NumPyro-Opt. Each of the three programs has compilation
time exponentially increasing with the number of variables, however SlicStanâ€™s compilation time
increases the fastest. We discuss this drawback in more detail in Â§Â§ 5.3, highlighting the importance
of an extended loop-level analysis being considered in future work.

Second-order HMM. The second-order HMM is very similar to the first-order HMM, but the
discrete variables depend on the previous 2 variables, in this case taking the maximum of the two.

ğœ‡ğ‘˜ âˆ¼ N (0, 1)
ğ‘§1 âˆ¼ categorical(ğœƒ1),

for ğ‘˜ âˆˆ 1, . . . , ğ¾
ğ‘§2 âˆ¼ categorical(ğœƒğ‘§1)

ğ‘§ğ‘› âˆ¼ categorical(ğœƒmax(ğ‘§ğ‘›âˆ’2,ğ‘§ğ‘›âˆ’1) )
ğ‘¦ğ‘› âˆ¼ N (ğœ‡ğ‘§ğ‘›, 1)

for ğ‘› âˆˆ 1, . . . , ğ‘

for ğ‘› âˆˆ 3, . . . , ğ‘

Similarly to before, we run the experiment for ğ¾ = 3 and different values for ğ‘ , ranging from
ğ‘ = 3 to ğ‘ = 25. We show the results in Figure 9, which once again shows SlicStan outperforming
NumPyro and NumPyro-Opt in terms of runtime, but having slower compilation time for a larger
number of discrete parameters.

Factorial HMM. In a factorial HMM, each data point ğ‘¦ğ‘› is generated using two independent

hidden states ğ‘§ğ‘› and â„ğ‘›, each depending on the previous hidden states ğ‘§ğ‘›âˆ’1 and â„ğ‘›âˆ’1.

ğœ‡ğ‘˜ âˆ¼ N (0, 1)

for ğ‘˜ âˆˆ 1, . . . , ğ¾ 2

ğ‘§1 âˆ¼ categorical(ğœƒ1),

â„1 âˆ¼ categorical(ğœƒ1)

ğ‘§ğ‘› âˆ¼ categorical(ğœƒğ‘§ğ‘›âˆ’1),

â„ğ‘› âˆ¼ categorical(ğœƒâ„ğ‘›âˆ’1)

for ğ‘› âˆˆ 2, . . . , ğ‘

ğ‘¦ğ‘› âˆ¼ N (ğœ‡ğ‘§ğ‘›âˆ—â„ğ‘›, 1)

for ğ‘› âˆˆ 1, . . . , ğ‘

We run the experiment for ğ¾ = 3 and different length of the chain ğ‘ , ranging from ğ‘ = 1 (2
discrete parameters) to ğ‘ = 12 (24 discrete parameters). We show the results in Figure 10: similarly
to before, SlicStan outperforms both NumPyro and NumPyro-Opt in terms of runtime. We also
observe that, in the case of SlicStan, the time taken to sample a single chain increases more slowly
as we increase the number of discrete variables.

5.2.2 Mixture models. Another useful application of mixed discrete and continuous variable models
is found in mixture models. We run experiments on two models: soft ğ¾-means clustering and linear
regression with outlier detection.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:36

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

Fig. 8. HMM results

Fig. 9. Second-order HMM results

Fig. 10. Factorial HMM results

Fig. 11. Soft K-means results

Fig. 12. Outliers results

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

510152025Number of discrete parameters18.519.019.520.020.521.021.522.022.5Time (sec) per chainFirst-order HMM: Runtime, CPUSlicStanNumPyroNumPyro-Opt510152025Number of discrete parameters14.014.515.015.516.016.5Time (sec) per chainFirst-order HMM: Runtime, GPUSlicStanNumPyroNumPyro-Opt35812151825Number of discrete parameters020406080100Compilation time (sec)First-order HMM: Compilation timesSlicStanNumPyroSlicStan-to-NumPyro510152025Number of discrete parameters181920212223242526Time (sec) per chainSecond-order HMM: Runtime, CPUSlicStanNumPyroNumPyro-Opt510152025Number of discrete parameters1415161718192021Time (sec) per chainSecond-order HMM: Runtime, GPUSlicStanNumPyroNumPyro-Opt35812151825Number of discrete parameters020406080100120Compilation time (sec)Second-order HMM: Compilation timesSlicStanNumPyroSlicStan-to-NumPyro510152025Number of discrete parameters20222426283032Time (sec) per chainFactorial HMM: Runtime, CPUSlicStanNumPyroNumPyro-Opt510152025Number of discrete parameters141618202224Time (sec) per chainFactorial HMM: Runtime, GPUSlicStanNumPyroNumPyro-Opt261014182224Number of discrete parameters0102030405060Compilation time (sec)Factorial HMM: Compilation timesSlicStanNumPyroSlicStan-to-NumPyro510152025Number of discrete parameters304050607080Time (sec) per chainSoft K-means: Runtime, CPUSlicStanNumPyroNumPyro-Opt510152025Number of discrete parameters20253035404550Time (sec) per chainSoft K-means: Runtime, GPUSlicStanNumPyroNumPyro-Opt35812151825Number of discrete parameters050100150200250300350400Compilation timeSoft K-means: Compilation timesSlicStanNumPyroSlicStan-to-NumPyro510152025Number of discrete parameters19202122232425Time (sec) per chainOutlier detection: Runtime, CPUSlicStanNumPyroNumPyro-Opt510152025Number of discrete parameters1415161718Time (sec) per chainOutlier detection: Runtime, GPUSlicStanNumPyroNumPyro-Opt35812151825Number of discrete parameters020406080Compilation time (sec)Outlier detection: Compilation timesSlicStanNumPyroSlicStan-to-NumPyroConditional independence by typing

1:37

Soft K-means. The Gaussian mixture model underlines the celebrated soft ğ¾-means algorithm.
Here, we are interested in modelling some ğ·-dimensional data that belongs to one of ğ¾ (unknown)
Gaussian clusters. Each cluster ğ‘˜ is specified by a ğ·-dimensional mean ğœ‡.,ğ‘˜ . Each data point ğ‘¦.,ğ‘› is
associated with a cluster ğ‘§ğ‘›.

ğœ‡ğ‘‘,ğ‘˜ âˆ¼ N (0, 1)

for ğ‘‘ âˆˆ 1, . . . , ğ· and ğ‘˜ âˆˆ 1, . . . , ğ¾

ğ‘§ğ‘› âˆ¼ categorical(ğœ‹)

for ğ‘› âˆˆ 1, . . . , ğ‘
for ğ‘‘ âˆˆ 1, . . . , ğ· and ğ‘› âˆˆ 1, . . . , ğ‘

ğ‘¦ğ‘‘,ğ‘› âˆ¼ N (ğœ‡ğ‘‘,ğ‘§ğ‘›, 1)

We run the experiments for ğ¾ = 3, ğ· = 10, and ğ‘ = 3, . . . , 25 and show the results in Figure 11.
We observe a clear linear trend of the runtime growing with N, with SlicStan performing better
and its runtime growing more slowly than that of NumPyro. While the SlicStan-translated code
runs faster than NumPyro-Opt for ğ‘ â‰¤ 25, we observe that the SlicStan runtime grows faster than
that of the manually optimised NumPyro-Opt code.

Outlier detection. The final model we consider is a Bayesian linear regression that allows for
outlier detection. The model considers data points (ğ‘¥ğ‘›, ğ‘¦ğ‘›), where ğ‘¦ lies on the line ğ›¼ğ‘¥ + ğ›½ with some
added noise. The noise ğœğ‘§ğ‘› depends on a Bernoulli parameter ğ‘§ğ‘›, which corresponds to whether or
not the point (ğ‘¥ğ‘›, ğ‘¦ğ‘›) is an outlier or not. The noise for outliers (ğœ1) and the noise for non-outliers
(ğœ2) are given as hyperparameters.

ğ›¼ âˆ¼ N (0, 10),

ğ›½ âˆ¼ N (0, 10)

ğœ‹ (ğ‘Ÿğ‘ğ‘¤)
1

âˆ¼ N (0, 1),

ğœ‹ (ğ‘Ÿğ‘ğ‘¤)
2

âˆ¼ N (0, 1),

ğœ‹ =

ğ‘§ğ‘› âˆ¼ bernoulli(ğœ‹)
ğ‘¦ğ‘› âˆ¼ N (ğ›¼ğ‘¥ğ‘› + ğ›½, ğœğ‘§ğ‘› )

exp ğœ‹ (ğ‘Ÿğ‘ğ‘¤)
1
for ğ‘› âˆˆ 1, . . . , ğ‘

for ğ‘› âˆˆ 1, . . . , ğ‘

exp ğœ‹ (ğ‘Ÿğ‘ğ‘¤)
1
+ exp ğœ‹ (ğ‘Ÿğ‘ğ‘¤)
2

Similarly to the earlier HMM models, SlicStan has the smallest runtime per chain, but at the

expense of fast growing compile time (Figure 12).

5.3 Analysis and discussion
Our method can be applied to general models containing a fixed and known number of finite-
support discrete parameters, which significantly reduces the amount of manual effort that was
previously required for such models in languages like Stan [Damiano et al. 2018]. In addition, as
shown in Figures 8â€“12, SlicStan outperforms both the NumPyro baseline and the hand-optimised
NumPyro-Opt, in terms of runtime. This suggests that a static-time discrete variable optimisation,
like the one introduced in this paper, is indeed beneficial and speeds up inference.

One limitation of our experimental analysis is the relatively small number of discrete parameters
we consider. Due to the array dimension limit imposed by PyTorch / NumPy, Pyro cannot have
more than 25 discrete variables (64 for CPU) unless the dependence between them is specified
using markov or plate (as with NumPyro-Opt). For NumPyro this hardcoded limit is 32. Thus, it
would not be possible to compare to the NumPyro baseline for a larger number of variables, though
comparing to the hand-optimised NumPyro-Opt would still be possible.

Perhaps the biggest limitation of the discrete parameters version of SlicStan is the exponentially
growing compilation time. Using a semi-lattice instead of a lattice in the âŠ¢2 level type analysis
breaks the requirement of the bidirectional type system that ensures efficiency of type inference.
The constraints generated by the type system can no longer be resolved by SlicStanâ€™s original
linear-time algorithm. While polynomial-time constraint-solving strategy may still exist, we choose

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:38

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

to employ Z3 to automatically resolve the type inference constraints, and leave the consideration
for more efficient type inference algorithm for future work.

This also highlights the importance of a future SlicStan version that considers arrays of discrete
parameters. Our algorithm currently supports only individual discrete parameters. In the cases
where the size of an array of discrete parameters is statically known, the (Elim Gen) procedure
can be applied to a program where such arrays have been â€˜flattenedâ€™ into a collection of individual
discrete variables, which is the strategy we adopt for the experiments in this section. But to be
applicable more widely, the (Elim Gen) rule needs to be generalised based on array element level
dependence analysis, for example by incorporating ideas from the polyhedral model [Feautrier
1992]. As the array level dependence analysis that would be required in most practical use-cases is
very straightforward, we believe this would be a useful and feasible applied extension of our work.
In addition, this would significantly decrease the number of program variables for which we need
to infer a level type during the (Elim Gen) transformation, thus making compilation practical for
larger or arbitrary numbers of discrete parameters.

6 RELATED WORK
This paper provides a type system that induces conditional independence relationships, and it
discusses one practical application of such type system: an automatic marginalisation procedure
for discrete parameters of finite support.

Conditional independence. The theoretical aim of our paper is similar to that of Barthe et al.
[2019], who discuss a separation logic for reasoning about independence, and the follow-up work
of Bao et al. [2021], who extend the logic to capture conditional independence. One advantage of
our method is that the verification of conditional independence is automated by type inference,
while it would rely on manual reasoning in the works of Barthe et al. [2019] and Bao et al. [2021].
On the other hand, the logic approach can be applied to a wider variety of verification tasks.
Amtoft and Banerjee [2020] show a correspondence between variable independence and slicing
a discrete-variables-only probabilistic program. The biggest difference to our work is that their
work considers only conditional independence of variables given the observed data: that is CI
relationships of the form x1 âŠ¥âŠ¥ x2 | D for some subsets of variables x1 and x2 and data D. The
language of Amtoft and Banerjee [2020] requires observed data to be specified syntactically using
an observe statement. Conditional independencies are determined only given this observed data,
and the method for determining how to slice a program is tied to the observe statements. From
the Amtoft and Banerjee [2020] paper: â€œA basic intuition behind our approach is that an observe
statement can be removed if it does not depend on something on which the returned variable ğ‘¥
also depends.â€ In contrast, we are able to find CI relationships given any variables we are interested
in (x1 âŠ¥âŠ¥ x2 | x3 for some x1, x2, and x3), and type inference constitutes of a straightforward
algorithm for finding such relationships. On the other hand, Amtoft and Banerjee [2020] permit
unbounded number of variables (e.g. while (y > 0) y âˆ¼ bernoulli(0.2)), while it is not clear how
to extend SlicStan/Stan to support this. While not in a probabilist programming setting, Lobo-Vesga
et al. [2020] use taint analysis to find independencies between variables in a program, in order to
facilitate easy trade off between privacy and accuracy in differential privacy context.

Automatic marginalisation. The most closely related previous work, in terms of the automatic
marginalisation procedure, is that of Obermeyer et al. [2019] and that of Murray et al. [2018]. Ober-
meyer et al. [2019] implement efficient variable-elimination for plated factor graphs in Pyro [Uber
AI Labs 2017]. Their approach uses effect-handlers and can be implemented in other effect-handling
based PPLs, such as Edward2 [Tran et al. 2018]. Murray et al. [2018] introduce a â€˜delayed samplingâ€™
procedure in Birch [Murray and SchÃ¶n 2018], which optimises the program via partial analytical

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:39

solutions to sub-programs. Their method corresponds to automatic variable elimination and, more
generally, automatic Raoâ€“Blackwellization. While we focus on discrete variable elimination only,
our conditional independence type system can be directly used for more general analysis. The
method from Â§ 4 can be extended to marginalise out and sample continuous variables whenever
they are part of an analytically-tractable sub-program, similarly to delayed sampling in Birch.
One key difference of our approach is that the program re-writes are guided by the type system
and happen at compile time, before inference is run. In contrast, both Pyro and Birch maintain a
dynamic graph that guides the analysis at runtime.

Symbolic inference. Where a full analytical solution is possible, several probabilistic programming
languages can derive it via symbolic manipulation, including Hakaru [Narayanan et al. 2016] and PSI
[Gehr et al. 2016, 2020], while Dice [Holtzen et al. 2020] performs exact inference for models with
discrete parameters only, by analysing the program structure. In contrast, we focus on re-writing
the program, and decomposing it into parts to be used with fast and more general asymptotically
exact or approximate inference algorithms, like HMC, variational inference or others.

Extending HMC to support discrete parameters. The idea of modifying HMC to handle discrete
variables and discontinuities has been previously explored [Nishimura et al. 2017; Pakman and
Paninski 2013; Zhang et al. 2012; Zhou 2020]. More recently, Zhou et al. [2019] introduced the
probabilistic programming language LF-PPL, which is designed specifically to be used with the
Discontinuous Hamiltonian Monte Carlo (DHMC) algorithm [Nishimura et al. 2017]. The algorithm,
and their framework can also be extended to support discrete parameters. LF-PPL provides support
for an HMC version that itself works with discontinuities. Our approach is to statically rewrite the
program to match the constraints of Stan, vanilla HMC, and its several well-optimised extensions,
such as NUTS [Hoffman and Gelman 2014].

Composable and programmable inference. Recent years have seen a growing number of techniques
that allow for tailored-to-the-program compilation to an inference algorithm. For example, Gen
[Cusumano-Towner et al. 2019] can statically analyse the model structure to compile to a more
efficient inference strategy. In addition, languages like Gen and Turing [Ge et al. 2018] facilitate
composable and programmable inference [Mansinghka et al. 2018], where the user is provided with
inference building blocks to implement their own model-specific algorithm. Our method can be
understood as an automatic composition between two inference algorithms: variable elimination
and HMC or any other inference algorithm that can be used to sample continuous variables.

7 CONCLUSION
This paper introduces an information flow type system that can be used to check and infer condi-
tional independence relationships in a probabilistic programs, through type checking and inference,
respectively. We present a practical application of this type system: a semantics-preserving transfor-
mation that makes it possible to use, and to efficiently and automatically infer discrete parameters
in SlicStan, Stan, and other density-based probabilistic programming languages. The transformed
program can be seen as a hybrid inference algorithm on the original program, where continuous
parameters can be drawn using efficient gradient-based inference methods, like HMC, while the
discrete parameters are drawn using variable elimination.

While the variable elimination transformation uses results on conditional independence of
discrete parameters, our type system is not restricted to this usage. Conditional independence
relationships can be of interest in many context in probabilistic modelling, including more general
use of variable elimination, message-passing algorithms, Rao-Blackwellization, and factorising a

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:40

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

program for a composed-inference approach. We believe conditional independence by typing can
enable interesting future work that automates the implementation of such methods.

ACKNOWLEDGMENTS
We thank Vikash Mansinghka for suggesting the outlier detection example, which we used for
evaluation, as well as Lawrence Murry for clarifying the behaviour of Birch, and anonymous review-
ers whose helpful suggestions improved the paper. Maria Gorinova was supported by the EPSRC
Centre for Doctoral Training in Data Science, funded by the UK Engineering and Physical Sciences
Research Council (grant EP/L016427/1) and the University of Edinburgh. Matthijs VÃ¡kÃ¡r was funded
by the European Unionâ€™s Horizon 2020 research and innovation programme under the Marie
SkÅ‚odowska-Curie grant agreement No. 895827.

REFERENCES
MartÃ­n Abadi, Anindya Banerjee, Nevin Heintze, and Jon G. Riecke. 1999. A Core Calculus of Dependency. In POPL. ACM,

147â€“160.

Eyal Amir. 2010. Approximation algorithms for treewidth. Algorithmica 56, 4 (2010), 448â€“479.
Torben Amtoft and Anindya Banerjee. 2020. A Theory of Slicing for Imperative Probabilistic Programs. ACM Transactions

on Programming Languages and Systems (TOPLAS) 42, 2 (2020), 1â€“71.

Stefan Arnborg, Derek G Corneil, and Andrzej Proskurowski. 1987. Complexity of finding embeddings in a k-tree. SIAM

Journal on Algebraic Discrete Methods 8, 2 (1987), 277â€“284.

Jialu Bao, Simon Docherty, Justin Hsu, and Alexandra Silva. 2021. A Bunched Logic for Conditional Independence. In 2021

36th Annual ACM/IEEE Symposium on Logic in Computer Science (LICS). IEEE, 1â€“14.

Gilles Barthe, Justin Hsu, and Kevin Liao. 2019. A probabilistic separation logic. Proceedings of the ACM on Programming

Languages 4, POPL (2019), 1â€“30.

Michael Betancourt and Mark Girolami. 2015. Hamiltonian Monte Carlo for hierarchical models. Current trends in Bayesian

methodology with applications 79 (2015), 30.

Craig Boutilier, Nir Friedman, Moises Goldszmidt, and Daphne Koller. 1996. Context-Specific Independence in Bayesian
Networks. In Proceedings of the Twelfth International Conference on Uncertainty in Artificial Intelligence (UAIâ€™96). 115â€“123.
Bob Carpenter, Andrew Gelman, Matthew Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker,
Jiqiang Guo, Peter Li, and Allen Riddell. 2017. Stan: A Probabilistic Programming Language. Journal of Statistical Software,
Articles 76, 1 (2017), 1â€“32. https://doi.org/10.18637/jss.v076.i01

Marco F. Cusumano-Towner, Feras A. Saad, Alexander K. Lew, and Vikash K. Mansinghka. 2019. Gen: A General-Purpose
Probabilistic Programming System with Programmable Inference. In Proceedings of the 40th ACM SIGPLAN Conference
on Programming Language Design and Implementation (Phoenix, AZ, USA) (PLDI 2019). Association for Computing
Machinery, New York, NY, USA, 221â€“236. https://doi.org/10.1145/3314221.3314642

Luis Damiano, Brian Peterson, and Michael Weylandt. 2018. A Tutorial on Hidden Markov Models using Stan. StanCon

(2018). https://doi.org/10.5281/zenodo.1284341.

Leonardo De Moura and Nikolaj BjÃ¸rner. 2008. Z3: An efficient SMT solver. In International conference on Tools and

Algorithms for the Construction and Analysis of Systems (TACAS). Springer, 337â€“340.

Paul Feautrier. 1992. Some efficient solutions to the affine scheduling problem. Part II. Multidimensional time. International

journal of parallel programming 21, 6 (1992), 389â€“420.

Brendan J. Frey. 2002. Extending Factor Graphs so as to Unify Directed and Undirected Graphical Models. In Proceedings
of the Nineteenth Conference on Uncertainty in Artificial Intelligence (Acapulco, Mexico) (UAIâ€™03). Morgan Kaufmann
Publishers Inc., San Francisco, CA, USA, 257â€“264.

Hong Ge, Kai Xu, and Zoubin Ghahramani. 2018. Turing: a language for flexible probabilistic inference. In International
Conference on Artificial Intelligence and Statistics (AISTATS). 1682â€“1690. http://proceedings.mlr.press/v84/ge18b.html
Timon Gehr, Sasa Misailovic, and Martin Vechev. 2016. PSI: Exact symbolic inference for probabilistic programs. In

International Conference on Computer Aided Verification. Springer, 62â€“83.

Timon Gehr, Samuel Steffen, and Martin Vechev. 2020. ğœ†PSI: Exact inference for higher-order probabilistic programs. In
Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation. 883â€“897.
Andrew Gelman, Daniel Lee, and Jiqiang Guo. 2015. Stan: A probabilistic programming language for Bayesian inference

and optimization. Journal of Educational and Behavioral Statistics 40, 5 (2015), 530â€“543.

Andrew D. Gordon, Claudio V. Russo, Marcin Szymczak, Johannes BorgstrÃ¶m, Nicolas Rolland, Thore Graepel, and Daniel
Tarlow. 2015. Probabilistic Programs as Spreadsheet Queries. In ESOP (Lecture Notes in Computer Science, Vol. 9032).
Springer, 1â€“25.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:41

Maria I Gorinova, Andrew D Gordon, and Charles Sutton. 2019. Probabilistic programming with densities in SlicStan:

efficient, flexible, and deterministic. Proceedings of the ACM on Programming Languages 3, POPL (2019), 35.

Andreas Griewank and Andrea Walther. 2008. Evaluating derivatives: principles and techniques of algorithmic differentiation.

SIAM.

Matthew D Hoffman and Andrew Gelman. 2014. The No-U-turn sampler: Adaptively setting path lengths in Hamiltonian

Monte Carlo. Journal of Machine Learning Research 15, 1 (2014), 1593â€“1623.

Steven Holtzen, Guy Van den Broeck, and Todd Millstein. 2020. Dice: Compiling Discrete Probabilistic Programs for Scalable

Inference. arXiv preprint arXiv:2005.09089 (2020).

Uffe KjÃ¦rulff. 1990. Triangulation of graphsâ€“algorithms giving small total state space. (1990).
Daphne Koller and Nir Friedman. 2009. Probabilistic graphical models: principles and techniques. MIT press.
Elisabet Lobo-Vesga, Alejandro Russo, and Marco Gaboardi. 2020. A programming framework for differential privacy with

accuracy concentration bounds. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 411â€“428.

Vikash K. Mansinghka, Ulrich Schaechtle, Shivam Handa, Alexey Radul, Yutian Chen, and Martin Rinard. 2018. Probabilistic
Programming with Programmable Inference. In Proceedings of the 39th ACM SIGPLAN Conference on Programming
Language Design and Implementation (Philadelphia, PA, USA) (PLDI 2018). ACM, New York, NY, USA, 603â€“616. https:
//doi.org/10.1145/3192366.3192409

Tom Minka and John Winn. 2009. Gates. In Advances in Neural Information Processing Systems, D. Koller, D. Schuur-
mans, Y. Bengio, and L. Bottou (Eds.), Vol. 21. Curran Associates, Inc. https://proceedings.neurips.cc/paper/2008/file/
4b0a59ddf11c58e7446c9df0da541a84-Paper.pdf

T. Minka, J.M. Winn, J.P. Guiver, S. Webster, Y. Zaykov, B. Yangel, A. Spengler, and J. Bronskill. 2014. Infer.NET 2.6. Microsoft

Research Cambridge. http://research.microsoft.com/infernet.

Dave Moore and Maria I. Gorinova. 2018. Effect Handling for Composable Program Transformations in Edward2. International

Conference on Probabilistic Programming (2018). https://arxiv.org/abs/1811.06150

Kevin P Murphy. 2012. Machine learning: a probabilistic perspective. MIT press.
Lawrence M. Murray, Daniel LundÃ©n, Jan Kudlicka, David Broman, and Thomas B. SchÃ¶n. 2018. Delayed Sampling and
Automatic Rao-Blackwellization of Probabilistic Programs. Proceedings of Machine Learning Research, Twenty-First
International Conference on Artificial Intelligence and Statistics (AISTATS) 84 (2018), 1037â€“1046. http://proceedings.mlr.
press/v84/murray18a.html

Lawrence M Murray and Thomas B SchÃ¶n. 2018. Automated learning with a probabilistic programming language: Birch.

Annual Reviews in Control 46 (2018), 29â€“43.

Praveen Narayanan, Jacques Carette, Wren Romano, Chung-chieh Shan, and Robert Zinkov. 2016. Probabilistic Inference by
Program Transformation in Hakaru (System Description). In Functional and Logic Programming, Oleg Kiselyov and Andy
King (Eds.). Springer International Publishing, Cham, 62â€“79.

Radford M Neal et al. 2011. MCMC using Hamiltonian dynamics. Handbook of Markov Chain Monte Carlo 2, 11 (2011).
Akihiko Nishimura, David Dunson, and Jianfeng Lu. 2017. Discontinuous Hamiltonian Monte Carlo for sampling discrete

parameters. arXiv preprint arXiv:1705.08510 (2017).

Fritz Obermeyer, Eli Bingham, Martin Jankowiak, Justin Chiu, Neeraj Pradhan, Alexander Rush, and Noah Goodman. 2019.

Tensor Variable Elimination for Plated Factor Graphs. International Conference on Machine Learning (2019).

A Pakman and L Paninski. 2013. Auxiliary-variable exact Hamiltonian Monte Carlo samplers for binary distributions.

Advances in Neural Information Processing Systems (2013).

Du Phan, Neeraj Pradhan, and Martin Jankowiak. 2019. Composable Effects for Flexible and Accelerated Probabilistic

Programming in NumPyro. arXiv preprint arXiv:1912.11554 (2019).

Benjamin C Pierce and David N Turner. 2000. Local type inference. ACM Transactions on Programming Languages and

Systems (TOPLAS) 22, 1 (2000), 1â€“44.

Lawrence R Rabiner. 1989. A tutorial on hidden Markov models and selected applications in speech recognition. Proc. IEEE

77, 2 (1989), 257â€“286.

John Salvatier, Thomas V Wiecki, and Christopher Fonnesbeck. 2016. Probabilistic programming in Python using PyMC3.

PeerJ Computer Science 2 (2016), e55.

Stan Development Team. 2019a. Stan language reference manual. Version 2.26.0. http://mc-stan.org.
Stan Development Team. 2019b. Stan userâ€™s guide. Version 2.26.0. http://mc-stan.org.
Dustin Tran, Matthew D. Hoffman, Srinivas Vasudevan, Christopher Suter, Dave Moore, Alexey Radul, Matthew Johnson,
and Rif A. Saurous. 2018. Edward2: Simple, Distributed, Accelerated. (2018). https://github.com/tensorflow/probability/
tree/master/tensorflow_probability/python/edward2 Advances in Neural Information Processing Systems (NeurIPS).

Uber AI Labs. 2017. Pyro: A deep probabilistic programming language. http://pyro.ai/.
Dennis M. Volpano, Cynthia E. Irvine, and Geoffrey Smith. 1996. A Sound Type System for Secure Flow Analysis. J. Comput.

Secur. 4, 2/3 (1996), 167â€“188.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:42

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

John Winn. 2012. Causality with gates. In International Conference on Artificial Intelligence and Statistics (AISTATS). 1314â€“1322.

http://proceedings.mlr.press/v22/winn12.html

Frank Wood, Jan Willem van de Meent, and Vikash Mansinghka. 2014. A New Approach to Probabilistic Programming

Inference. In Proceedings of the 17th International conference on Artificial Intelligence and Statistics. 1024â€“1032.

Nevin Lianwen Zhang and David Poole. 1994. A simple approach to Bayesian network computations. In Proceedings of the
Biennial Conference-Canadian Society for Computational Studies of Intelligence. Canadian Information Processing Society,
171â€“178.

Yichuan Zhang, Zoubin Ghahramani, Amos J Storkey, and Charles A. Sutton. 2012. Continuous relaxations for discrete
Hamiltonian Monte Carlo. In Advances in Neural Information Processing Systems, F. Pereira, C. J. C. Burges, L. Bottou, and
K. Q. Weinberger (Eds.). Curran Associates, Inc., 3194â€“3202. http://papers.nips.cc/paper/4652-continuous-relaxations-
for-discrete-hamiltonian-monte-carlo.pdf

Guangyao Zhou. 2020. Mixed Hamiltonian Monte Carlo for Mixed Discrete and Continuous Variables. In Advances in Neural

Information Processing Systems (NeurIPS).

Yuan Zhou, Bradley J. Gram-Hansen, Tobias Kohn, Tom Rainforth, Hongseok Yang, and Frank Wood. 2019. LF-PPL: A
Low-Level First Order Probabilistic Programming Language for Non-Differentiable Models. In International Conference
on Artificial Intelligence and Statistics (AISTATS). http://proceedings.mlr.press/v89/zhou19b.html

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:43

A DEFINITIONS AND PROOFS

A.1 Definitions

Definition 10 (Assigns-to set ğ‘Š (ğ‘†)). W(S) is the set that contains the names of global variables

that have been assigned to within the statement S. It is defined recursively as follows:
ğ‘Š (ğ‘¥ [ğ¸1] . . . [ğ¸ğ‘›] = ğ¸) = {ğ‘¥ }
ğ‘Š (ğ‘†1; ğ‘†2) = ğ‘Š (ğ‘†1) âˆª ğ‘Š (ğ‘†2)
ğ‘Š (if(ğ¸) ğ‘†1 else ğ‘†2) = ğ‘Š (ğ‘†1) âˆª ğ‘Š (ğ‘†2)
ğ‘Š (for(ğ‘¥ in ğ¸1 : ğ¸2) ğ‘†) = ğ‘Š (ğ‘†) \ {ğ‘¥ }

ğ‘Š (skip) = âˆ…
ğ‘Š (factor(ğ¸)) = âˆ…
ğ‘Š (ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›)) = âˆ…

Definition 11 (Reads set ğ‘…(ğ‘†)). R(S) is the set that contains the names of global variables that

have been read within the statement S. It is defined recursively as follows:
ğ‘…(ğ‘¥) = {ğ‘¥ }
ğ‘…(ğ‘) = âˆ…
ğ‘…( [ğ¸1, . . . , ğ¸ğ‘›]) = (cid:208)ğ‘›
ğ‘–=1 ğ‘…(ğ¸ğ‘– )
ğ‘…(ğ¸1 [ğ¸2]) = ğ‘…(ğ¸1) âˆª ğ‘…(ğ¸2)
ğ‘…(ğ‘“ (ğ¸1, . . . , ğ¸ğ‘›)) = (cid:208)ğ‘›
ğ‘…( [ğ¸|ğ‘¥ in ğ¸1 : ğ¸2]) = ğ‘…(ğ¸) âˆª ğ‘…(ğ¸1) âˆª ğ‘…(ğ¸2)
ğ‘…(target(ğ‘†)) = ğ‘…(ğ‘†)
ğ‘…(ğ‘¥ [ğ¸1] . . . [ğ¸ğ‘›] = ğ¸) = (cid:208)ğ‘›

ğ‘…(ğ‘†1; ğ‘†2) = ğ‘…(ğ‘†1) âˆª ğ‘…(ğ‘†2)
ğ‘…(if(ğ¸) ğ‘†1 else ğ‘†2) = ğ‘…(ğ¸) âˆª ğ‘…(ğ‘†1) âˆª ğ‘…(ğ‘†2)
ğ‘…(for(ğ‘¥ in ğ¸1 : ğ¸2) ğ‘†) = ğ‘…(ğ¸1) âˆª ğ‘…(ğ¸2) âˆª ğ‘…(ğ‘†) \
{ğ‘¥ }
ğ‘…(skip) = âˆ…
ğ‘…(factor(ğ¸)) = ğ‘…(ğ¸)
ğ‘…(ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›)) = ğ‘…(ğ¿) âˆª ğ‘…(ğ¸1) âˆª Â· Â· Â· âˆª
ğ‘…(ğ¸ğ‘›)

ğ‘–=1 ğ‘…(ğ¸ğ‘– )

ğ‘–=1 ğ‘…(ğ¸ğ‘– ) âˆª ğ‘…(ğ¸)

Definition 12 (Samples-to set (cid:101)ğ‘Š (ğ‘†)). (cid:101)ğ‘Š (ğ‘†) is the set that contains the names of global variables

that have been sampled within the statement S. It is defined recursively as follows:
(cid:101)ğ‘Š (ğ¿ = ğ¸) = âˆ…
(cid:101)ğ‘Š (ğ‘†1; ğ‘†2) = (cid:101)ğ‘Š (ğ‘†1) âˆª (cid:101)ğ‘Š (ğ‘†2)
(cid:101)ğ‘Š (if(ğ¸) ğ‘†1 else ğ‘†2) = (cid:101)ğ‘Š (ğ‘†1) âˆª (cid:101)ğ‘Š (ğ‘†2)
(cid:101)ğ‘Š (for(ğ‘¥ in ğ¸1 : ğ¸2) ğ‘†) = (cid:101)ğ‘Š (ğ‘†) \ {ğ‘¥ }

(cid:101)ğ‘Š (skip) = âˆ…
(cid:101)ğ‘Š (factor(ğ¸)) = âˆ…
(cid:101)ğ‘Š (ğ‘¥ [ğ¸1] . . . [ğ¸ğ‘›] âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›)) = {ğ‘¥ }

Definition 13 (Free variables ğ¹ğ‘‰ (ğ‘†)). ğ¹ğ‘‰ (ğ‘†) is the set that contains the free variables that are

used in a statement ğ‘†. It is recursively defined as follows:

ğ¹ğ‘‰ (ğ‘¥) = {ğ‘¥ }
ğ¹ğ‘‰ (ğ‘) = âˆ…
ğ¹ğ‘‰ ( [ğ¸1, . . . , ğ¸ğ‘›]) = (cid:208)ğ‘›
ğ‘–=1 ğ¹ğ‘‰ (ğ¸ğ‘– )
ğ¹ğ‘‰ (ğ¸1 [ğ¸2]) = ğ¹ğ‘‰ (ğ¸1) âˆª ğ¹ğ‘‰ (ğ¸2)
ğ¹ğ‘‰ (ğ‘“ (ğ¸1, . . . , ğ¸ğ‘›)) = (cid:208)ğ‘›
ğ‘–=1 ğ¹ğ‘‰ (ğ¸ğ‘– )
ğ¹ğ‘‰ ( [ğ¸|ğ‘¥ in ğ¸1 : ğ¸2]) = ğ¹ğ‘‰ (ğ¸) âˆª ğ¹ğ‘‰ (ğ¸1) âˆª
ğ¹ğ‘‰ (ğ¸2)
ğ¹ğ‘‰ (target(ğ‘†)) = ğ¹ğ‘‰ (ğ‘†)
ğ¹ğ‘‰ (ğ‘¥ [ğ¸1] . . . [ğ¸ğ‘›] = ğ¸) = (cid:208)ğ‘›

ğ‘–=1 ğ¹ğ‘‰ (ğ¸ğ‘– ) âˆª ğ¹ğ‘‰ (ğ¸)

ğ¹ğ‘‰ (ğ‘†1; ğ‘†2) = ğ¹ğ‘‰ (ğ‘†1) âˆª ğ¹ğ‘‰ (ğ‘†2)
ğ¹ğ‘‰ (if(ğ¸) ğ‘†1 else ğ‘†2) = ğ¹ğ‘‰ (ğ¸)âˆªğ¹ğ‘‰ (ğ‘†1)âˆªğ¹ğ‘‰ (ğ‘†2)
ğ¹ğ‘‰ (for(ğ‘¥ in ğ¸1 : ğ¸2) ğ‘†) = ğ¹ğ‘‰ (ğ¸1) âˆª ğ¹ğ‘‰ (ğ¸2) âˆª
ğ¹ğ‘‰ (ğ‘†) \ {ğ‘¥ }
ğ¹ğ‘‰ (skip) = âˆ…
ğ¹ğ‘‰ (factor(ğ¸)) = ğ¹ğ‘‰ (ğ¸)
ğ¹ğ‘‰ (ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›)) = ğ¹ğ‘‰ (ğ¿) âˆªğ¹ğ‘‰ (ğ¸1) âˆªÂ· Â· Â·âˆª
ğ¹ğ‘‰ (ğ¸ğ‘›)

Definition 14. We overload the notation Î“(ğ¿) that looks up the type of an L-value in Î“. When

applied to a more general expression ğ¸, Î“(ğ¸) looks up the type level of ğ¸ in Î“:

Î“(ğ‘¥) = â„“, where â„“ is the level of ğ‘¥ in Î“
Î“(ğ‘) = data
Î“( [ğ¸1, . . . , ğ¸ğ‘›]) = (cid:195)ğ‘›

ğ‘–=1 Î“(ğ¸ğ‘– )

Î“(ğ¸1 [ğ¸2]) = Î“(ğ¸1) âŠ” Î“(ğ¸2)
Î“(ğ‘“ (ğ¸1, . . . , ğ¸ğ‘›)) = (cid:195)ğ‘›
Î“([ğ¸|ğ‘¥ in ğ¸1 : ğ¸2]) = Î“(ğ¸) âŠ” Î“(ğ¸1) âŠ” Î“(ğ¸2)

ğ‘–=1 Î“(ğ¸ğ‘– )

Definition 15. Î“(ğ¸1, . . . , ğ¸ğ‘›) â‰¡ Î“(ğ¸1) âŠ” Â· Â· Â· âŠ” Î“(ğ¸ğ‘›).

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:44

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

Definition 16 (ğ‘…Î“âŠ¢â„“ (ğ‘†)). ğ‘…Î“âŠ¢â„“ (ğ‘†) is the set that contains the names of global variables that have

been read at level â„“ within the statement ğ‘†. It is defined recursively as follows:
Î“(ğ‘¥) = (_, â„“)
ğ‘–=1 ğ‘…(ğ¸ğ‘– ) âˆª ğ‘…(ğ¸)

(cid:26) (cid:208)ğ‘›
âˆ…

if
otherwise

ğ‘…Î“âŠ¢â„“ (ğ‘¥ [ğ¸1] . . . [ğ¸ğ‘›] = ğ¸) =
ğ‘…Î“âŠ¢â„“ (ğ‘†1; ğ‘†2) = ğ‘…Î“âŠ¢â„“ (ğ‘†1) âˆª ğ‘…Î“âŠ¢â„“ (ğ‘†2)
ğ‘…Î“âŠ¢â„“ (if(ğ¸) ğ‘†1 else ğ‘†2) = ğ‘…Î“âŠ¢â„“ (ğ¸) âˆª ğ‘…Î“âŠ¢â„“ (ğ‘†1) âˆª ğ‘…Î“âŠ¢â„“ (ğ‘†2)
ğ‘…Î“âŠ¢â„“ (for(ğ‘¥ in ğ¸1 : ğ¸2) ğ‘†) = ğ‘…Î“âŠ¢â„“ (ğ¸1) âˆª ğ‘…Î“âŠ¢â„“ (ğ¸2) âˆª ğ‘…Î“âŠ¢â„“ (ğ‘†) \ {ğ‘¥ }
ğ‘…Î“âŠ¢â„“ (skip) = âˆ…
ğ‘…Î“âŠ¢â„“ (factor(ğ¸)) =

â„“ = model

(cid:26) ğ‘…(ğ¸)
âˆ…

if
else
ğ‘…(ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›))

ğ‘…Î“âŠ¢â„“ (ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›)) =

âˆƒğœ .Î“(ğ‘¥) = (ğœ, â„“ â€²)}

âˆ…

otherwise.

ï£±ï£´ï£´ï£²
ï£´ï£´
ï£³

if

â„“ = (cid:195){â„“ â€² | âˆƒğ‘¥ âˆˆ ğ¹ğ‘‰ (ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›)

Definition 17 (ğ‘ŠÎ“âŠ¢â„“ (ğ‘†)). ğ‘ŠÎ“âŠ¢â„“ (ğ‘†) â‰œ {ğ‘¥ âˆˆ ğ‘Š (ğ‘†) | Î“(ğ‘¥) = (ğœ, â„“) for some ğœ }
Definition 18 ( (cid:101)ğ‘ŠÎ“âŠ¢â„“ (ğ‘†)). (cid:101)ğ‘ŠÎ“âŠ¢â„“ (ğ‘†) â‰œ {ğ‘¥ âˆˆ (cid:101)ğ‘Š (ğ‘†) | Î“(ğ‘¥) = (ğœ, â„“) for some ğœ }
Definition 19. Given a statement ğ‘†, we define the statement st(ğ‘†) by structural induction on ğ‘†:
st(ğ‘¥ [ğ¸1] . . . [ğ¸ğ‘›] = ğ¸) = ğ‘¥ [ğ¸1] . . . [ğ¸ğ‘›] = ğ¸
st(ğ‘†1; ğ‘†2) = st(ğ‘†1); st(ğ‘†2)
st(if(ğ¸) ğ‘†1 else ğ‘†2) = if(ğ¸) st(ğ‘†1) else st(ğ‘†2))
st(for(ğ‘¥ in ğ¸1 : ğ¸2) ğ‘†) = for(ğ‘¥ in ğ¸1 : ğ¸2) st(ğ‘†)
st(skip) = skip
st(factor(ğ¸)) = skip
st(ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›)) = skip
Definition 20 (Neighbours of ğ‘§, ne(Î“, Î“â€², ğ‘§)).

For a âŠ¢ typing environment Î“, a âŠ¢2 typing environment Î“â€² = Î“â€²
neighbours of ğ‘§ are defined as:

ğœ, Î“â€²
x

and a variable ğ‘§ âˆˆ dom(Î“â€²

x), the

ne(Î“, Î“â€², ğ‘§) â‰œ {ğ‘¥ : (ğœ, â„“) âˆˆ Î“â€²

x | â„“ = l1 and Î“(ğ‘¥) = (intâŸ¨ğ¾âŸ©, model) for some ğ¾ }

A.2 Proofs
Restatement of Lemma 1 (Noninterference of âŠ¢)
some â„“. Then for SlicStan statement ğ‘† and expression ğ¸:

Suppose ğ‘ 1 |= Î“, ğ‘ 2 |= Î“, and ğ‘ 1 â‰ˆâ„“ ğ‘ 2 for

(1) If Î“ âŠ¢ ğ¸ : (ğœ, â„“) and (ğ‘ 1, ğ¸) â‡“ ğ‘‰1 and (ğ‘ 2, ğ¸) â‡“ ğ‘‰2 then ğ‘‰1 = ğ‘‰2.
(2) If Î“ âŠ¢ ğ‘† : â„“ and (ğ‘ 1, ğ‘†) â‡“ ğ‘  â€²
2.
1 â‰ˆâ„“ ğ‘  â€²

1, ğ‘¤1 and (ğ‘ 2, ğ‘†) â‡“ ğ‘  â€²

2, ğ‘¤2 then ğ‘  â€²

Proof. (1) follows by rule induction on the derivation Î“ âŠ¢ ğ¸ : (ğœ, â„“), and using that if Î“ âŠ¢ ğ¸ : (ğœ, â„“),
ğ‘¥ âˆˆ ğ‘…(ğ¸) and Î“(ğ‘¥) = (ğœ â€², â„“ â€²), then â„“ â€² â‰¤ â„“. (2) follows by rule induction on the derivation Î“ âŠ¢ ğ‘† : â„“
and using (1).

Most cases follow trivially from the inductive hypothesis. An exception is the (Target) case,

which we show below.

(Target)

1, ğ‘¤1, and ğ‘ 2, ğ‘† â‡“ ğ‘  â€²

We use the premise âˆ€â„“ â€² > â„“.ğ‘…Î“âŠ¢â„“â€² (ğ‘†) = âˆ…, together with a lemma that for ğ‘†, ğ‘ 1 and ğ‘ 2
such that ğ‘ 1, ğ‘† â‡“ ğ‘  â€²
2, ğ‘¤2, and âˆ€ğ‘¥ âˆˆ ğ‘…(ğ‘†).ğ‘ 1(ğ‘¥) = ğ‘ 2(ğ‘¥), we have that
ğ‘¤1 = ğ‘¤2. (This lemma follows by structural induction on ğ‘†.) In the case of (Target),
ğ‘ 1, target(ğ‘†) â‡“ ğ‘¤1, and ğ‘ 2, target(ğ‘†) â‡“ ğ‘¤2 and ğ‘…(ğ‘†) = (cid:208)â„“â€² ğ‘…Î“âŠ¢â„“â€² (ğ‘†) = (cid:0)(cid:208)â„“â€² â‰¤â„“ ğ‘…Î“âŠ¢â„“â€² (ğ‘†)(cid:1) âˆª
((cid:208)â„“â€²>â„“ ğ‘…Î“âŠ¢â„“â€² (ğ‘†)) = (cid:208)â„“â€² â‰¤â„“ ğ‘…Î“âŠ¢â„“â€² (ğ‘†). Then, for any ğ‘¥ âˆˆ ğ‘…(ğ‘†), ğ‘¥ âˆˆ ğ‘…Î“âŠ¢â„“â€² (ğ‘†) for some â„“ â€² â‰¤ â„“
, so Î“(ğ‘¥) = (ğœ, â„“ğ‘¥ ) such that â„“ğ‘¥ â‰¤ â„“ â€² â‰¤ â„“. And thus, by definition of â‰ˆâ„“ , ğ‘ 1(ğ‘¥) = ğ‘ 2(ğ‘¥)
for any ğ‘¥ âˆˆ ğ‘…(ğ‘†). By applying the lemma above, we then get ğ‘¤1 = ğ‘¤2, as required.

â–¡

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

Restatement of Lemma 4 (Shredding produces single-level statements)

ğ‘† â‡•Î“ (ğ‘†ğ· , ğ‘†ğ‘€, ğ‘†ğ‘„ ) =â‡’ Î“ âŠ¢ data(ğ‘†ğ· ) âˆ§ Î“ âŠ¢ model(ğ‘†ğ‘€ ) âˆ§ Î“ âŠ¢ genquant(ğ‘†ğ‘„ )

Proof. By rule induction on the derivation of ğ‘† â‡•Î“ ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ .

1:45

â–¡

Restatement of Lemma 5 (Property of single-level statements)
Let Î“ğœ, Î“x âŠ¢ ğ‘† be SlicStan program, such that ğ‘† is single-level statement of level â„“, Î“ âŠ¢ â„“ (ğ‘†). Then there
exist unique functions ğ‘“ and ğœ™, such that for any ğœ, x |= Î“ğœ, Î“x:

(ğœ)(ğ‘¥) = ğ‘“ (ğœ â‰¤â„“, xâ‰¤â„“ ) âˆª ğœ>â„“, ğœ™ (ğœ â‰¤â„“ )(xâ‰¤â„“ ),
where we write ğœ â‰¤â„“ = {(ğ‘¥ â†¦â†’ ğ‘‰ ) âˆˆ ğœ | Î“ğœ (ğ‘¥) = (_, â„“)} and ğœ>â„“ = ğœ \ ğœ â‰¤â„“ .

ğ‘†
(cid:74)

(cid:75)

Proof. This property follows from noninterference (Lemma 1), if we understand factor and
sample statements as assignments to a reserved weight variables of different levels. Let Î“, ğ‘† be a
SlicStan program and suppose we obtain ğ‘† â€² by:

â€¢ Substituting every factor(ğ¸) statement with ğ‘¤â„“ = ğ‘¤â„“ âˆ— ğ¸, where Î“(ğ¸) = real, â„“ and ğ‘¤data,
ğ‘¤model and ğ‘¤qenqant are write-only, distinct and reserved variables in the program.
â€¢ Substituting every ğ¿ âˆ¼ ğ‘‘ (ğ¸1, . . . , ğ¸ğ‘›) statement with ğ‘¤â„“ = ğ‘¤â„“ âˆ— ğ‘‘pdf (ğ¿ | ğ¸1, . . . , ğ¸ğ‘›), where

Î“(ğ‘‘pdf (ğ¿ | ğ¸1, . . . , ğ¸ğ‘›)) = real, â„“.

Then for all ğœ, x |= Î“, we have

ğ‘†
(cid:74)
non-interference (Lemma 1), for any level â„“ and store ğœ2 â‰ˆâ„“ ğœ, if ğœ â€²
2 â‰ˆâ„“ ğœ â€². Thus ğœ â€²
ğœ â€²
â„“,
and ğœ™. Finally, this gives us

ğ‘ (ğœ)(x) = (cid:206)â„“ ğœ â€²(ğ‘¤â„“ ), where ğœ â€² =
ğ‘  (ğœ, âˆ€â„“.ğ‘¤â„“ â†¦â†’ 1)(x). By
ğ‘† â€²
(cid:74)
(cid:75)
(cid:75)
ğ‘  (ğœ2, âˆ€â„“.ğ‘¤â„“ â†¦â†’ 1)(x), then
ğ‘† â€²
(cid:75)
(cid:74)
2(ğ‘¤â„“â€²) = ğœ2(ğ‘¤â„“â€²) for â„“ â€² â‰¤ â„“, and therefore, when ğ‘† is a single-level statement of level
ğ‘  (ğœ, âˆ€â„“.ğ‘¤â„“ â†¦â†’ 1)(x) = ğ‘“ (ğœ â‰¤â„“, xâ‰¤â„“ ), ğœ>â„“, ğ‘¤ â‰¤â„“ â†¦â†’ ğœ™ (ğœ â‰¤â„“, xâ‰¤â„“ ), ğ‘¤>â„“ â†¦â†’ 1 , for some functions ğ‘“
(cid:75)
â–¡

ğ‘† â€²
(cid:74)

2 =

ğ‘ (ğœ, x) = ğœ™ (ğœ â‰¤â„“, xâ‰¤â„“ ).
(cid:75)

ğ‘  (ğœ, x) = (ğ‘“ (ğœ â‰¤â„“, xâ‰¤â„“ ), ğœ>â„“ ),
ğ‘†
(cid:74)
(cid:75)
Restatement of Lemma 6 (Semantic Preservation of â‡•Î“)
If Î“ âŠ¢ ğ‘† : data and ğ‘† â‡•Î“ (ğ‘†ğ· , ğ‘†ğ‘€, ğ‘†ğ‘„ ) then
ğ‘†ğ· ; ğ‘†ğ‘€ ; ğ‘†ğ‘„
(cid:74)

ğ‘†
(cid:74)

ğ‘†
(cid:74)

=

(cid:75)

(cid:75)

.

Proof. Follows by adapting proof from [Gorinova et al. 2019].

Restatement of Lemma 10 (Semantic Preservation of â‡•Î“ 2)
If Î“ âŠ¢2 ğ‘† : l1 and ğ‘† â‡•Î“ ğ‘†1, ğ‘†2, ğ‘†3 then

.

=

ğ‘†
(cid:74)

(cid:75)

ğ‘†1; ğ‘†2; ğ‘†3
(cid:74)

(cid:75)

Proof. Follows by adapting proof from [Gorinova et al. 2019].

â–¡

â–¡

Lemma 13. For a SlicStan expression ğ¸ and a function ğœ™ (ğ‘¥, ğ‘¦) = ğ‘‰ , where ğ‘‰ is a value such that

(ğœ, ğ‘¥, ğ‘¦), ğ¸ â‡“ ğ‘‰ for every ğ‘¥ and ğ‘¦ and some ğœ, if ğ‘¥ âˆ‰ ğ‘…(ğ¸), then:

âˆƒğœ™ â€² such that ğœ™ (ğ‘¥, ğ‘¦) = ğœ™ â€²(ğ‘¦) for all ğ‘¥, ğ‘¦

Proof. By induction on the structure of ğ¸.

â–¡

Restatement of Theorem 1 (Shredding induces a factorisation of the density).
Suppose Î“ âŠ¢ ğ‘† : data and ğ‘† â‡•Î“ ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ and Î“ = Î“ğœ âˆª Î“D âˆª Î“ğœ½ âˆª Î“ğ‘„ . For all ğœ, D, ğœ½ , and ğ‘„: if
ğœ, D, ğœ½, ğ‘„ |= Î“ğœ, Î“D, Î“ğœ½ , Î“ğ‘„ , and

ğ‘ (ğœ)(D, ğœ½, ğ‘„) âˆ ğ‘ (D, ğœ½, ğ‘„) and (cid:101)ğ‘Š (ğ‘†ğ‘„ ) = dom(Î“ğ‘„ ) then:
(cid:75)

ğ‘†
(cid:74)

(1)
(2)

ğ‘ (ğœğ· )(D, ğœ½, ğ‘„) âˆ ğ‘ (ğœ½, D)
ğ‘†ğ‘€
(cid:75)
(cid:74)
ğ‘ (ğœğ‘€ )(D, ğœ½, ğ‘„) = ğ‘ (ğ‘„ | ğœ½, D)
ğ‘†ğ‘„
(cid:75)
(cid:74)
ğ‘  (ğœ)(D, ğœ½, ğ‘„) and ğœğ‘€ =
where ğœğ· =
(cid:75)

ğ‘†ğ·
(cid:74)

ğ‘  (ğœğ· )(D, ğœ½, ğ‘„).
(cid:75)
Proof. We prove this by establishing a more general result:
For ğœ, D, ğœ½, ğ‘„ |= Î“ğœ, Î“D, Î“ğœ½ , Î“ğ‘„ , ğ´ = (cid:101)ğ‘Š (ğ‘†ğ‘„ ) âŠ† ğ‘„ and some ğµ âŠ† ğ‘„ \ ğ´, if

ğ‘†ğ‘€
(cid:74)

ğ‘ (D, ğœ½, ğ´ | ğµ) then:

ğ‘†
(cid:74)

ğ‘ (ğœ)(D, ğœ½, ğ‘„) âˆ
(cid:75)

(1)

ğ‘†ğ·
(cid:74)

ğ‘ (ğœ)(D, ğœ½, ğ‘„) = 1
(cid:75)

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:46

(2)
(3)

ğ‘†ğ‘€
(cid:74)
ğ‘†ğ‘„
(cid:74)

ğ‘ (ğœğ· )(D, ğœ½, ğ‘„) = ğ‘ (ğœ½, D)
(cid:75)
ğ‘ (ğœğ‘€ )(D, ğœ½, ğ‘„) = ğ‘ (ğ´ | ğœ½, D, ğµ)
(cid:75)

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

Note that in the case where (cid:101)ğ‘Š (ğ‘†ğ‘„ ) = ğ‘„, we have ğ´ = ğ‘„ and ğµ = âˆ…, and the original statement

of the theorem,

ğ‘†ğ‘„
(cid:74)
Lemma 4 and Lemma 5, Lemma 6.

ğ‘ (ğœğ‘€ )(D, ğœ½, ğ‘„) = ğ‘ (ğ‘„ | ğœ½, D), holds.
(cid:75)

We prove the extended formulation above by induction on the structure of ğ‘† and use of Lemma 2,

Take any ğœ, D, ğœ½, ğ‘„ |= Î“ğœ, Î“D, Î“ğœ½ , Î“ğ‘„ and let

Î¦(ğ‘†, ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ ) â‰œ

Î“ âŠ¢ ğ‘† : data âˆ§ ğ‘† â‡•Î“ ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ âˆ§ ğ´ = (cid:101)ğ‘Š (ğ‘†ğ‘„ )
=â‡’ âˆƒğµ âŠ† ğ‘„ \ ğ´.âˆ€ğœğ·, ğœğ‘€ . (

ğ‘†
(cid:74)

ğ‘ (ğœ)(D, ğœ½, ğ‘„) âˆ ğ‘ (D, ğœ½, ğ´ | ğµ) âˆ§
ğ‘†ğ·
(cid:75)
(cid:74)
ğ‘ (ğœ)(D) = 1
ğ‘†ğ·
(cid:75)
(cid:74)
ğ‘ (ğœğ· )(D, ğœ½ ) = ğ‘ (ğœ½, D)
ğ‘†ğ‘€
(cid:75)
(cid:74)

=â‡’
âˆ§
âˆ§ âˆƒğµ âŠ† ğ‘„ \ (cid:101)ğ‘Š (ğ‘†ğ‘„ ).

(cid:75)

(ğœ)(D, ğœ½, ğ‘„) = ğœğ· âˆ§

(ğœğ· )(D, ğœ½, ğ‘„) = ğœğ‘€

ğ‘†ğ‘€
(cid:74)

(cid:75)

ğ‘†ğ‘„
(cid:74)

ğ‘ (ğœğ‘€ )(D, ğœƒ, ğ‘„) = ğ‘ (ğ´ | ğœ½, D, ğµ)
(cid:75)

(cid:17)

Take any Î“, ğ‘†, ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ such that ğ‘† â‡•Î“ ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ , ğ´ = (cid:101)ğ‘Š (ğ‘†ğ‘„ ), and take any ğœ, D, ğœ½, ğ‘„ |=
ğ‘ (ğœ)(D, ğœ½, ğ‘„) âˆ ğ‘ (D, ğœ½, ğ´ | ğµ).
(cid:75)

Î“ğœ, Î“D, Î“ğœ½ , Î“ğ‘„ , an unnormalised density ğ‘ and ğµ âŠ† ğ‘„\ğ´, such that
We prove by rule induction on the derivation of ğ‘† â‡•Î“ ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ that Î¦(ğ‘†, ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ ).

ğ‘†
(cid:74)

(Shred Seq)

Let ğ‘† = ğ‘†1; ğ‘†2 and ğ‘†1 â‡•Î“ ğ‘†1ğ·, ğ‘†1ğ‘€, ğ‘†1ğ‘„ and ğ‘†2 â‡•Î“ ğ‘†2ğ·, ğ‘†2ğ‘€, ğ‘†2ğ‘„ . Thus ğ‘† â‡•Î“

(ğ‘†1ğ· ; ğ‘†2ğ· ), (ğ‘†1ğ‘€ ; ğ‘†2ğ‘€ ), (ğ‘†1ğ‘„ ; ğ‘†2ğ‘„ ).

Assume Î¦(ğ‘†1, ğ‘†1ğ·, ğ‘†1ğ‘€, ğ‘†1ğ‘„ ) and Î¦(ğ‘†2, ğ‘†2ğ·, ğ‘†2ğ‘€, ğ‘†2ğ‘„ ).
Let:
â€¢ ğ´1 = (cid:101)ğ‘Š (ğ‘†1ğ‘„ ) and ğµ1 âŠ† ğ‘„ \ ğ´1 is such that
(ğœ)(D, ğœ½, ğ‘„) = ğœ â€².
â€¢
(cid:75)
ğ‘ (ğœ)(D, ğœ½, ğ‘„) âˆ ğ‘1(D, ğœ½, ğ´1 | ğµ1).
â€¢
(cid:75)
â€¢ ğ´2 = (cid:101)ğ‘Š (ğ‘†2ğ‘„ ) and ğµ2 âŠ† ğ‘„ \ ğ´2 is such that
ğ‘ (ğœ â€²)(D, ğœ½, ğ‘„) âˆ ğ‘2(D, ğœ½, ğ´2 | ğµ2).
â€¢
(cid:75)
ğ‘ =
(cid:75)

Thus, by Lemma 2,

ğ‘†1
(cid:74)
ğ‘†1
(cid:74)
ğ‘†2
(cid:74)

ğ‘ =
(cid:75)

ğ‘†2ğ‘„
(cid:74)

ğ‘†1ğ‘„
(cid:74)

ğ‘ (ğœğ‘€ )(D, ğœ½, ğ‘„) = ğ‘1(ğ´1 | D, ğœ½, ğµ1).
(cid:75)

ğ‘ (ğœğ‘€ )(D, ğœ½, ğ‘„) = ğ‘2(ğ´2 | D, ğœ½, ğµ2).
(cid:75)

ğ‘†
(cid:74)

ğµ1)ğ‘2(D, ğœ½, ğ´2 | ğµ2).

ğ‘†1; ğ‘†2
(cid:74)
ğ‘ (ğœ)(D, ğœ½, ğ‘„) =
ğ‘†1ğ·
(cid:74)
(cid:75)
ğ‘ = 1.
(cid:75)
From Î¦(ğ‘†1, ğ‘†1ğ·, ğ‘†1ğ‘€, ğ‘†1ğ‘„ ) and Î¦(ğ‘†2, ğ‘†2ğ·, ğ‘†2ğ‘€, ğ‘†2ğ‘„ ) we also have:

For (1), we have âˆ€ğœ |= Î“ğœ .
ğ‘†1ğ·
(cid:74)

ğ‘†2
(cid:74)
ğ‘†2ğ·
(cid:74)

ğ‘†1ğ· ; ğ‘†2ğ·
(cid:74)

ğ‘ Ã—
(cid:75)

ğ‘†2ğ·
(cid:74)

ğ‘ Ã—
(cid:75)

ğ‘ =
(cid:75)

ğ‘†1
(cid:74)

ğ‘ , so ğ‘ (D, ğœ½, ğ´ | ğµ) âˆ ğ‘1(D, ğœ½, ğ´1
(cid:75)
ğ‘ (ğœ)(D, ğœ½, ğ‘„) = 1. Thus, by Lemma 2,
(cid:75)

|

â€¢
â€¢

ğ‘†1ğ‘„
(cid:74)
ğ‘†2ğ‘„
(cid:74)

ğ‘ (ğœğ‘€ )(D, ğœ½, ğ‘„) = ğ‘ (ğ´1 | ğœ½, D, ğµ1)
(cid:75)
ğ‘ (ğœ â€²
ğ‘€ )(D, ğœ½, ğ‘„) = ğ‘ (ğ´2 | ğœ½, D, ğµ2)
(cid:75)

ğ´ = (cid:101)ğ‘Š (ğ‘†ğ‘„ ) = (cid:101)ğ‘Š (ğ‘†1ğ‘„ ; ğ‘†2ğ‘„ ) = (cid:101)ğ‘Š (ğ‘†1ğ‘„ ) âˆª (cid:101)ğ‘Š (ğ‘†2ğ‘„ ) = ğ´1 âˆª ğ´2

From ğ‘† well typed, it must be the case that ğ´1 âˆ© ğ´2 = âˆ…. Thus, we write ğ´ = ğ´1, ğ´2.
We will prove that the property holds for ğµ = ğµ1 âˆª ğµ2 \ ğ´1 \ ğ´2.
By semantic preservation of â‡•Î“ (Lemma 6),

ğ‘†1
ğ‘ =
(cid:75)
(cid:74)
ğ‘ âˆ 1 Ã— ğ‘1(ğœ½, D) Ã— ğ‘1(ğ´1 | ğœ½, D, ğµ1). Similarly,
ğ‘†2
(cid:74)
(cid:75)

ğ‘†1ğ‘„
(cid:74)
ğ‘2(ğœ½, D)ğ‘2(ğ´2 | ğœ½, D, ğ´1, ğµ1).

ğ‘†1ğ· ; ğ‘†1ğ‘€ ; ğ‘†1ğ‘„
ğ‘†1ğ·
ğ‘ Ã—
(cid:74)
(cid:75)
(cid:74)
ğ‘ âˆ 1 Ã— ğ‘2(ğœ½, D) Ã— ğ‘2(ğ´2 | ğœ½, D, ğµ2) =
(cid:75)

ğ‘ =
(cid:75)

ğ‘†1ğ‘€
(cid:74)

ğ‘ Ã—
(cid:75)

But ğ‘ (ğœ½, D, ğ´ | ğµ) âˆ ğ‘1 (ğœ½, D, ğ´1 | ğµ1)ğ‘2(ğœ½, D, ğ´2 | ğµ2), so:

ğ‘ (ğœ½, D, ğ´ | ğµ) âˆ ğ‘1(ğœ½, D)ğ‘1(ğ´1 | ğœ½, D, ğµ1)ğ‘2(ğœ½, D)ğ‘2(ğ´2 | ğœ½, D, ğ´1, ğµ1)

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:47

So,

ğ‘ (ğœ½, D) =

âˆ

âˆ«

âˆ«

ğ‘ (D, ğœ½, ğ´ | ğµ)ğ‘ (ğµ)ğ‘‘ğ´ğ‘‘ğµ

ğ‘1 (ğœ½, D)ğ‘1(ğ´1 | ğœ½, D, ğµ1)ğ‘2(ğœ½, D)ğ‘2(ğ´2 | ğœ½, D, ğ´1, ğµ1)ğ‘ (ğµ)ğ‘‘ğ´1ğ‘‘ğ´2ğ‘‘ğµ

âˆ«

âˆ«

âˆ ğ‘1(ğœ½, D)ğ‘2(ğœ½, D)

= ğ‘1(ğœ½, D)ğ‘2(ğœ½, D)

= ğ‘1(ğœ½, D)ğ‘2(ğœ½, D)
âˆ ğ‘1(ğœ½, D)ğ‘2(ğœ½, D)

ğ‘ (ğµ)ğ‘1(ğ´1 | ğœ½, D, ğµ1)ğ‘2(ğ´2 | ğœ½, D, ğ´1, ğµ1)ğ‘‘ğ´1ğ‘‘ğ´2ğ‘‘ğµ

(cid:18)âˆ«

ğ‘ (ğµ)

ğ‘1(ğ´1 | ğœ½, D, ğµ1)

(cid:18)âˆ«

ğ‘2(ğ´2 | ğœ½, D, ğ´1, ğµ1)ğ‘‘ğ´2

(cid:19)

(cid:19)

ğ‘‘ğµ

ğ‘‘ğ´1

Finally, for last property on ğ‘†, we use the chain rule of probability, semantics property of

Thus

ğ‘†ğ‘€
(cid:74)

ğ‘ =
(cid:75)

ğ‘†1ğ‘€ ; ğ‘†2ğ‘€
(cid:74)

ğ‘ âˆ ğ‘1(ğœ½, D)ğ‘2(ğœ½, D) âˆ ğ‘ (ğœ½, D)
(cid:75)

sequencing, and the result from above to get:

ğ‘ (ğ´ | D, ğœ½, ğµ) =

âˆ

ğ‘ (D, ğœ½, ğ´ | ğµ)
ğ‘ (D, ğœ½ | ğµ)
ğ‘1(D, ğœ½ )ğ‘2(D, ğœ½ )ğ‘1(ğ´1 | D, ğœ½, ğµ1)ğ‘2(ğ´2 | D, ğœ½, ğµ2)
ğ‘ (D, ğœ½ )

Ã—

ğ‘ (ğµ)
ğ‘ (ğµ | D, ğœ½ )

Thus:

Where:

âˆ ğ‘1(ğ´1 | D, ğœ½, ğµ1)ğ‘2(ğ´2 | D, ğœ½, ğµ2)
=

ğ‘†1ğ‘„
(cid:74)

ğ‘†2ğ‘„
(cid:74)

ğ‘ =
(cid:75)

ğ‘
(cid:75)

ğ‘†ğ‘„
(cid:74)

ğ‘
(cid:75)

ğ‘ (ğ´ | D, ğœ½, ğµ) =

ğ‘1(ğ´1 | D, ğœ½, ğµ1)ğ‘2 (ğ´2 | D, ğœ½, ğµ2)
ğ‘

ğ‘1(ğ´1 | D, ğœ½, ğµ1)ğ‘2 (ğ´2 | D, ğœ½, ğµ2)ğ‘‘ğ´

ğ‘1(ğ´1 | D, ğœ½, ğµ1)

(cid:18)âˆ«

ğ‘2(ğ´2 | D, ğœ½, ğµ2)ğ‘‘ğ´2

(cid:19)

ğ‘‘ğ´1

âˆ«

âˆ«

ğ‘ =

=

= 1

So ğ‘ = 1, and ğ‘ (ğ´ | D, ğœ½, ğµ) = ğ‘1(ğ´1 | D, ğœ½, ğµ1)ğ‘2(ğ´2 | D, ğœ½, ğµ2) =
Thus:
ğ‘†ğ·
(cid:74)
ğ‘†ğ‘€
(cid:74)
ğ‘†ğ‘„
(cid:74)

â€¢
â€¢
â€¢
Î¦((ğ‘†1; ğ‘†2), (ğ‘†1ğ· ; ğ‘†2ğ· ), (ğ‘†1ğ‘€ ; ğ‘†2ğ‘€ ), (ğ‘†1ğ‘„ ; ğ‘†2ğ‘„ )) from here.

ğ‘ = 1
ğ‘†1ğ· ; ğ‘†2ğ·
(cid:75)
(cid:74)
ğ‘†1ğ‘€ ; ğ‘†2ğ‘€
ğ‘ âˆ ğ‘1(ğœ½, D)ğ‘2(ğœ½, D) = ğ‘ (ğœ½, D)
(cid:75)
(cid:74)
ğ‘†1ğ‘„ ; ğ‘†2ğ‘„
ğ‘ = ğ‘1(ğ´1 | ğœ½, D, ğµ1)ğ‘2(ğ´2 | ğœ½, D, ğ´1, ğµ1) = ğ‘ (ğ´1, ğ´2 | ğœ½, D, ğµ)
(cid:75)
(cid:74)

ğ‘ =
(cid:75)
ğ‘ =
(cid:75)
ğ‘ =
(cid:75)

ğ‘†ğ‘„
(cid:74)

ğ‘ .
(cid:75)

Restatement of Lemma 9 (Shredding produces single-level statements 2)

ğ‘† â‡•Î“ ğ‘†1, ğ‘†2, ğ‘†3 =â‡’ Î“ âŠ¢ l1(ğ‘†1) âˆ§ Î“ âŠ¢ l2(ğ‘†2) âˆ§ Î“ âŠ¢ l3(ğ‘†3)

Proof. By rule induction on the derivation of ğ‘† â‡•Î“ ğ‘†1, ğ‘†2, ğ‘†3.

â–¡

â–¡

Restatement of Lemma 10 (Semantic preservation of â‡•Î“, âŠ¢2)
If Î“ âŠ¢2 ğ‘† : l1 and ğ‘† â‡•Î“ ğ‘†1, ğ‘†2, ğ‘†3 then

.

=

ğ‘†
(cid:74)

(cid:75)

ğ‘†1; ğ‘†2; ğ‘†3
(cid:74)

(cid:75)

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:48

Proof.

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

â–¡

Restatement of Lemma 11 (Property of single-level statements 2)
Let Î“ğœ, Î“x, ğ‘† be a SlicStan program, and Î“ âŠ¢2 ğ‘† : l1, and ğ‘† is single-level statement of level â„“, Î“ âŠ¢2 â„“ (ğ‘†).
Then there exist unique functions ğ‘“ and ğœ™, such that for any ğœ, x |= Î“ğœ, Î“x:

(1) If â„“ = l1, then
(2) If â„“ = l2, then
(3) If â„“ = l3, then

(ğœ)(ğ‘¥) = (cid:0)ğ‘“ (ğœl1, xl1), ğœl2, ğœl3(cid:1) ,
(ğœ)(ğ‘¥) = (cid:0)ğœl1, ğ‘“ (ğœl1, ğœl2, xl1, xl2), ğœl3(cid:1) , ğœ™ (ğœl1, ğœl2)(xl1, xl2)
(ğœ)(ğ‘¥) = (cid:0)ğœl1, ğœl2, ğ‘“ (ğœl1, ğœl3, xl1, xl3)(cid:1) , ğœ™ (ğœl1, ğœl3)(xl1, xl3)

ğœ™ (ğœl1)(xl1)

ğ‘†
(cid:74)
ğ‘†
(cid:74)
ğ‘†
(cid:74)

(cid:75)
(cid:75)
(cid:75)

Proof. By understanding factor and sample statements as assignment to a reserved weight
â–¡

variables of different levels (similarly to Lemma 5) and noninterference (Lemma 7).

Restatement of Lemma 12 (Existence of model to genqant transformation)
For any Slic-
Stan program Î“, ğ‘† such that Î“ âŠ¢ ğ‘† : l1, and a variable ğ‘§ âˆˆ dom(Î“) such that Î“(ğ‘§) = (intâŸ¨ğ¾âŸ©, model),
there exists a SlicStan program Î“â€², ğ‘† â€², such that,

Î“, ğ‘†

ğ‘§
âˆ’â†’ Î“â€², ğ‘† â€²

and

Î“â€²(ğ‘§) = (intâŸ¨ğ¾âŸ©, genquant)

Proof. Take a SlicStan program Î“, ğ‘†, a typing environment Î“ğ‘€ , a variable ğ‘§, and statements

ğ‘†ğ·, ğ‘†ğ‘€ and ğ‘†ğ‘„ , such that:

Î“(ğ‘§) = (intâŸ¨ğ¾âŸ©, model)

Î“ âŠ¢ ğ‘† : data Î“

ğ‘§
âˆ’â†’ Î“ğ‘€ ğ‘† â‡•Î“ ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„

Î“ğ‘€ âŠ¢2 ğ‘†ğ‘€ : l1

Take also statements ğ‘†1, ğ‘†2, ğ‘†3, and ğ‘† â€²

ğ‘€ , and a typing environment Î“ne such that

ğ‘†ğ‘€ â‡•Î“ğ‘€ ğ‘†1, ğ‘†2, ğ‘†3

Î“ne = ne(Î“, Î“ğ‘€, ğ‘§)

ğ‘† â€²
ğ‘€ = ğ‘†1; ğ‘“ = ğœ™ (Î“ne){elim(intâŸ¨ğ¾âŸ©ğ‘§) ğ‘†2}; factor(ğ‘“ [dom(Î“ne)]); ğ‘†3; gen(ğ‘§)ğ‘†2; st(ğ‘†2)

Let Î“â€² is such that dom(Î“â€²) = dom(Î“) âˆª {ğ‘“ } and for all ğ‘¥ : ğœ, â„“ âˆˆ Î“:

Î“â€²(ğ‘¥) =

ï£±ï£´ï£´ï£´ï£²
ï£´ï£´ï£´
ï£³

(ğœ, â„“)
(ğœ, â„“)
(ğœ, genqant)

if â„“ â‰  model
if â„“ = model and Î“ğ‘€ (ğ‘¥) â‰  (ğœ, l2)
if â„“ = model and Î“ğ‘€ (ğ‘¥) = (ğœ, l2)

By semantic preservation of shredding (Lemma 6, Lemma 10) and type preservation of the
operational semantics ([Gorinova et al. 2019]), Î“ âŠ¢ ğ‘†ğ· ; ğ‘†1; ğ‘†2; ğ‘†3; ğ‘†ğ‘„ : data, and thus, by (Seq),
Î“ âŠ¢ ğ‘†ğ· : data, Î“ âŠ¢ ğ‘†1 : data, . . . , Î“ âŠ¢ ğ‘†ğ‘„ : data.

By definition of Î“â€², Î“â€²data âŠ‚ Î“data. ğ‘†ğ· is single-level of level data and Î“ âŠ¢ ğ‘†ğ· : data, so

Î“data âŠ¢ ğ‘†ğ· : data and thus Î“â€² âŠ¢ ğ‘†ğ· : data. Similarly, Î“ âŠ¢ ğ‘†1 : D and Î“ âŠ¢ ğ‘†3 : D.

Î“ âŠ¢ ğ‘†2 : data, so using (Phi), (Elim) and (Factor), and noting that by definition dom(Î“ne) âŠ‚

dom(Î“ğ‘€,l1), so Î“ne âŠ‚ Î“, we can derive:

Î“â€² âŠ¢ ğ‘“ = ğœ™ (Î“ne){elim(intâŸ¨ğ¾âŸ©ğ‘§) ğ‘†2}; factor(ğ‘“ [dom(Î“ne)]) : data

By Î“ âŠ¢ ğ‘†2 : data and the definition of Î“â€², and using (Gen) and definition of st, we also derive:

Î“â€² âŠ¢ gen(ğ‘§) ğ‘†2; st(ğ‘†2) : genqant

Finally, ğ‘†ğ‘„ is a single-level statement of level genqant and for all ğ‘¥ : ğœ, â„“ âˆˆ Î“, ğ‘¥ : ğœ, â„“ â€² âˆˆ Î“,

where â„“ â‰¤ â„“ â€². Therefore, Î“ âŠ¢ ğ‘†ğ‘„ : data implies Î“â€² âŠ¢ ğ‘†ğ‘„ : data.

Altogether, this gives us Î“â€² âŠ¢ ğ‘†ğ· ; ğ‘† â€²

ğ‘€ ; ğ‘†ğ‘„ , and so by (Elim Gen), Î“, ğ‘†

ğ‘§
âˆ’â†’ Î“â€², ğ‘†ğ· ; ğ‘† â€²

ğ‘€, ğ‘†ğ‘„ .

â–¡

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:49

Lemma 14. Let Î“, ğ‘† be a SlicStan program, such that ğœ, x |= Î“,

ğ‘ (ğœ)(x) =
(cid:75)
ğœ“ (x) for some function ğœ“ . If ğ‘“ âˆ‰ dom(Î“) is a fresh variable, ğ‘§, ğ‘§1, . . . ğ‘§ğ‘› âˆˆ dom(Î“x) are discrete
variables of base types intâŸ¨ğ¾âŸ©, intâŸ¨ğ¾1âŸ©, . . . , intâŸ¨ğ¾ğ‘›âŸ© respectively, and ğ‘† â€² is a statement such that

ğ‘  (ğœ)(x) = ğœ â€² and
(cid:75)

ğ‘†
(cid:74)

ğ‘†
(cid:74)

then

ğ‘† â€² =
ğ‘† â€²
(cid:74)

ğ‘“ = ğœ™ (intâŸ¨ğ¾1âŸ©ğ‘§1, . . . intâŸ¨ğ¾ğ‘›âŸ©ğ‘§ğ‘›){elim(intâŸ¨ğ¾âŸ©ğ‘§) ğ‘† };
ğ‘ (ğœ)(x) = (cid:205)ğ¾
(cid:75)

ğ‘  (ğœ)(x) = ğœ â€²â€² with ğœ â€²â€²[âˆ’ğ‘“ ] = ğœ â€² and
(cid:75)

ğ‘† â€²
(cid:74)

ğ‘§=1 ğœ“ (x).

factor(ğ‘“ [ğ‘§1, . . . , ğ‘§ğ‘›]);

Proof. By examining the operational semantics of assignment, factor, and the derived forms
â–¡

elim and ğœ™.

Lemma 15. Let Î“, ğ‘† be a SlicStan program, such that ğœ, x |= Î“,

ğ‘ (ğœ)(x) =
(cid:75)
ğœ“ (x) for some function ğœ“ . If ğ‘§ âˆˆ dom(Î“x) is a discrete variable of base type intâŸ¨ğ¾âŸ©, and ğ‘† â€² is a statement
such that

ğ‘  (ğœ)(x) = ğœ â€² and
(cid:75)

ğ‘†
(cid:74)

ğ‘†
(cid:74)

ğ‘† â€² =

gen(ğ‘§) ğ‘†;

st(ğ‘†);

ğ‘† â€²
(cid:74)

ğ‘† â€²
(cid:74)

ğ‘  (ğœ)(x) = ğœ â€², ğœ“ (x) is normalisable with respect to ğ‘§ with ğœ“ (x) âˆ ğ‘ (ğ‘§ | x \ {ğ‘§}), and
(cid:75)

then
ğ‘ (ğœ)(x) = ğ‘ (ğ‘§ | x \ {ğ‘§}).
(cid:75)
Proof. By examining the operational semantics of âˆ¼ and target, and by induction on the structure
â–¡

of ğ‘† to prove

st(ğ‘†)

ğ‘  =
(cid:75)

ğ‘†
(cid:74)

ğ‘  and
(cid:75)

st(ğ‘†)
(cid:74)

ğ‘ = 1.
(cid:75)

(cid:74)

Typing Rules for Derived Forms:

(Elim)
Î“â€² âŠ¢ ğ‘† : data ğ‘…Î“âŠ¢genqant(ğ‘†) = âˆ… Î“â€² = Î“ [ğ‘§ â†¦â†’ intâŸ¨ğ¾âŸ©, model]
Î“ âŠ¢ elim(intâŸ¨ğ¾âŸ©ğ‘§) ğ‘† : model

(Gen)
Î“(ğ‘§) = (int, genqant)

Î“ âŠ¢ ğ‘† : data

Î“ âŠ¢ gen(intâŸ¨ğ¾âŸ© ğ‘§) ğ‘† : genqant

(Phi)
Î“â€² âŠ¢ ğ‘† : data âˆ€â„“ â€² > â„“.ğ‘…Î“âŠ¢â„“â€² (ğ‘†) = âˆ… Î“â€² = Î“[ğ‘§1 â†¦â†’ (intâŸ¨ğ¾1âŸ©, â„“), . . . , ğ‘§ğ‘ â†¦â†’ (intâŸ¨ğ¾ğ‘ âŸ©, â„“)]
Î“ âŠ¢ ğœ™ (intâŸ¨ğ¾1âŸ© ğ‘§1, . . . , intâŸ¨ğ¾ğ‘ âŸ© ğ‘§ğ‘ ) ğ‘† : real, â„“

Restatement of Theorem 4 (Semantic preservation of
For SlicStan programs Î“, ğ‘† and Î“â€², ğ‘† â€², and a discrete parameter ğ‘§: Î“, ğ‘†

ğ‘§
âˆ’â†’)

Proof.

ğ‘§
âˆ’â†’ Î“â€², ğ‘† â€² â†’

=

ğ‘†
(cid:74)

(cid:75)

.

ğ‘† â€²
(cid:74)

(cid:75)

Let Î“, ğ‘† and Î“â€², ğ‘† â€² be SlicStan programs, and ğ‘§ be a discrete parameter, such that Î“, ğ‘†

ğ‘† â‡•Î“ ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„ , ğ‘† â‡•Î“â€² ğ‘† â€²

ğ·, ğ‘† â€²
Let Î“ = Î“ğœ, Î“data, Î“model, Î“genqant, Î“â€² = Î“â€²

ğ‘€, ğ‘† â€²

ğ‘„ , and ğ‘†ğ‘€ â‡•Î“â€²â€² ğ‘†1, ğ‘†2, ğ‘†3 for Î“â€²â€² such that Î“

ğœ, Î“â€²data, Î“â€²model, Î“â€²genqant and
l3 be the usual partitioning of each of the typing environments.

l1, Î“â€²â€²

l2, Î“â€²â€²

Î“â€²â€² = Î“â€²â€²

ğœ , Î“â€²â€²

Let ğ‘§ be a store such that ğ‘§ |= {ğ‘§ : Î“(ğ‘§)}.
Let D, ğœ½ and ğ‘„ be stores such that D |= Î“data, ğ‘§, ğœ½ |= Î“model, and ğ‘„ |= Î“genqant.
Let ğœ½ 1, ğœ½ 2 and ğœ½ 3 be a partitioning of ğœ½ , such that D, ğœ½ 1 |= Î“â€²â€²
ğ‘§
âˆ’â†’ Î“â€²â€², ğœ½ 2 = ğ‘§.
Then, by definition of Î“
By Theorem 1:

l1, ğ‘§, ğœ½ 2 |= Î“â€²â€²

l2, and ğœ½ 3 |= Î“â€²â€²
l3.

ğ‘§
âˆ’â†’ Î“â€², ğ‘† â€². Let
ğ‘§
âˆ’â†’ Î“â€²â€² and Î“â€²â€² âŠ¢2 ğ‘†ğ‘€ : l1.

â€¢
â€¢

ğ‘†ğ·
(cid:74)
ğ‘†ğ‘€
(cid:74)

ğ‘ (ğœ)(D, ğ‘§, ğœ½, ğ‘„) = 1
(cid:75)
ğ‘ (ğœğ· )(D, ğ‘§, ğœ½, ğ‘„) âˆ ğ‘ (ğ‘§, ğœ½, D)
(cid:75)

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:50

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

â€¢

Î“, ğ‘†

ğ‘ (ğœğ‘€ )(D, ğ‘§, ğœ½, ğ‘„) = ğ‘ (ğ‘„ | ğ‘§, ğœ½, D)
(cid:75)

ğ‘†ğ‘„
(cid:74)
ğ‘‘
âˆ’â†’ Î“â€², ğ‘† â€², thus ğ‘† â€² must be of the form

ğ‘† â€² = ğ‘†ğ· ; ğ‘†1;

ğ‘“ = ğœ™ (Î“l1â€²â€²){elim(intâŸ¨ğ¾âŸ©ğ‘§) ğ‘†2};

factor(ğ‘“ [dom(Î“â€²â€²

l1)]); ğ‘†3; gen(ğ‘§)ğ‘†2; st(ğ‘†2); ğ‘†ğ‘„

where Î“ âŠ¢ ğ‘† : data, ğ‘† â‡•Î“ ğ‘†ğ·, ğ‘†ğ‘€, ğ‘†ğ‘„, Î“

ğ‘§
âˆ’â†’ Î“â€²â€², Î“ âŠ¢2 ğ‘†ğ‘€ : l1, and ğ‘†ğ‘€ â‡•Î“â€²â€² ğ‘†1, ğ‘†2, ğ‘†3.

The relation â‡•Î“ is semantics-preserving for well-typed programs with respect to both âŠ¢ and âŠ¢2

(Lemma 6 and Lemma 10). Thus

=

ğ‘†
(cid:74)

(cid:75)

ğ‘†ğ· ; ğ‘†1; ğ‘†2; ğ‘†3; ğ‘†ğ‘„
(cid:74)

(cid:75)

.

We present a diagrammatic derivation of the change on store and density that each sub-part in

the original and transformed program makes in Figure 13.

Combining all of these results gives that:

ğ‘† â€²
(cid:74)

ğ‘  (ğœ)(D, ğœ½, ğ‘„) = ğœ â€²â€² = ğœ â€²[ğ‘“ â†¦â†’ ğ‘£] =
(cid:75)
ğ‘§
âˆ’â†’ preserves store semantics (up to creating of one new fresh

ğ‘  (ğœ)((D, ğœ½, ğ‘„)) [ğ‘“ â†¦â†’ ğ‘£]
(cid:75)

ğ‘†
(cid:74)

In other words, the transformation
variable f).

For the density, we get:

ğ‘† â€²
(cid:74)

ğ‘ (ğœ)(D, ğœ½, ğ‘„)
(cid:75)

= ğœ™1(D, ğœ½ 1)

(cid:34)

âˆ‘ï¸

ğ‘§

(cid:35)

ğœ™2 (D, ğœ½ 1, ğ‘§)

ğœ™3(D, ğœ½ 1, ğœ½ 3)ğ‘ (ğ‘§ | D, ğœ½ 1)ğ‘ (ğ‘„ | D, ğœ½ )

from Figure 13

=

âˆ

(cid:34)

âˆ‘ï¸

ğ‘§

(cid:34)

âˆ‘ï¸

ğ‘§

ğœ™1(D, ğœ½ 1)ğœ™2(D, ğœ½ 1, ğ‘§)ğœ™3(D, ğœ½ 1, ğœ½ 3)

ğ‘ (ğ‘§ | D, ğœ½ 1)ğ‘ (ğ‘„ | D, ğœ½ )

(cid:35)

(cid:35)

ğ‘ (D, ğœ½ 1, ğ‘§, ğœ½ 2)

ğ‘ (ğ‘§ | D, ğœ½ 1)ğ‘ (ğ‘„ | D, ğœ½ )

= ğ‘ (D, ğœ½ 1, ğœ½ 2)ğ‘ (ğ‘§ | D, ğœ½ 1)ğ‘ (ğ‘„ | D, ğœ½ )

= ğ‘ (D, ğœ½ 1, ğœ½ 2)ğ‘ (ğ‘§ | D, ğœ½ 1, ğœ½ 3)ğ‘ (ğ‘„ | D, ğœ½ )

= ğ‘ (D, ğœ½, ğ‘„)

by the distributive
law

by Theorem 1
and Lemma 10

marginalisation of ğ‘§

by ğ‘§ âŠ¥âŠ¥ ğœ½ 3 | ğœ½ 1
(Theorem 3)

by the chain rule
for probability

âˆ

ğ‘ (ğœ)(D, ğœ½, ğ‘„)
(cid:75)
Together, this gives us

ğ‘†
(cid:74)

ğ‘†
(cid:74)

(up to ğ‘† â€² creating one new fresh variable f).

=

ğ‘† â€²
(cid:74)

(cid:75)

(cid:75)

â–¡

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:51

ğœ

ğ‘†ğ·

ğœ (ğ· ) , 1

ğ‘†1

ğœ (ğ·1) ,
ğœ™1 (ğœ (ğ·1)
l1

) ( D, ğœ½ 1)

by Lemma 11

by Lemma 14

ğ‘†2

ğ‘† â€²
2

(cid:16)
ğœ (ğ·1)
l1
ğœ™2 (ğœ (ğ·1)
l1

(cid:17),

, ğ‘“2 (ğœ (ğ·1)
, ğ‘“2 (ğœ (ğ·1)

l1,l2), ğœ (ğ·1)
l3
l1,l2)) ( D, ğœ½ 1, ğ‘§)

by Lemma 11

ğ‘†3

(cid:16)
ğœ (ğ·1)
l1
ğœ™3 (ğœ (ğ·1)
l1

, ğ‘“2 (ğœ (ğ·1)
, ğ‘“3 (ğœ (ğ·1)

l1,l2), ğ‘“3 (ğœ (ğ·1)
l1,l3)
l1,l3)) ( D, ğœ½ 1, ğœ½ 3)

(cid:17),

(cid:16)
ğœ (ğ·1)
, ğœ (ğ·1)
l2
l1
(cid:205)ğ‘§ ğœ™2 (ğœ (ğ·1)
, ğ‘“2 (ğœ (ğ·1)

, ğ‘“ â†¦â†’ ğ‘£, ğœ (ğ·1)

l3
l1,l2)) ( D, ğœ½ 1, ğ‘§)

(cid:17),

l1

ğ‘†3 by Lemma 11 and ğ‘“ fresh

(cid:16)
ğœ (ğ·1)
l1
ğœ™3 (ğœ (ğ·1)
l1

, ğœ (ğ·1)
l2
, ğ‘“3 (ğœ (ğ·1)

, ğ‘“ â†¦â†’ ğ‘£, ğ‘“3 (ğœ (ğ·1)
l1,l3)
l1,l3)) ( D, ğœ½ 1, ğœ½ 3)

(cid:17),

gen(ğ‘§)ğ‘†2 by Lemma 15

(cid:16)
ğœ (ğ·1)
l1

, ğ‘“2 (ğœ (ğ·1)

l1,l2), ğ‘“ â†¦â†’ ğ‘£, ğ‘“3 (ğœ (ğ·1)
l1,l3)
ğ‘ (ğ‘§ | D, ğœ½ 1)

(cid:17),

by Theorem 1

ğ‘†ğ‘„

ğ‘†ğ‘„ by Theorem 1 and ğ‘“ fresh

ğ‘“ğ‘”
ğœ™ğ‘” (ğœ (ğ·1)
l1

(cid:16)
ğœ (ğ·1)
l1
, ğ‘“2 (ğœ (ğ·1)

l1,l2), ğ‘“3 (ğœ (ğ·1)
l1,l3)
l1,l3)) ( D, ğœ½, ğ‘„)

, ğ‘“2 (ğœ (ğ·1)
l1,l2), ğ‘“3 (ğœ (ğ·1)
= ğ‘ (ğ‘„ | D, ğœ½ )

(cid:17),

(cid:16)
ğœ (ğ·1)
ğ‘“ğ‘”
l1
ğœ™ğ‘” (ğœ (ğ·1)
l1

(cid:17)

, ğ‘“2 (ğœ (ğ·1)
, ğ‘“2 (ğœ (ğ·1)

l1,l2), ğ‘“3 (ğœ (ğ·1)
, ğ‘“ â†¦â†’ ğ‘£,
l1,l3)
l1,l2), ğ‘“3 (ğœ (ğ·1)
l1,l3)) ( D, ğœ½, ğ‘„)
= ğ‘ (ğ‘„ | D, ğœ½ )

Fig. 13. Diagrammatic proof of semantic preservation of

ğ‘§
âˆ’â†’

B EXAMPLES

B.1 Sprinkler
Often, beginners are introduced to probabilistic modelling through simple, discrete variable exam-
ples, as they are more intuitive to reason about, and often have analytical solutions. Unfortunately,

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:52

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

Graphical model

SlicStan

sprin-
kler

cloudy

wet

rain

SlicStan + discrete parameters support

1

2

3

4

5

6

7

data real[2] p_rain, p_sprinkler;
data real[2][2] p_wet;
real p âˆ¼ beta(1, 1);
int<2> cloudy âˆ¼ bern(p);
int<2> sprinkler âˆ¼ bern(p_sprinkler[cloudy]);
int<2> rain âˆ¼ bern(p_rain[cloudy]);
int<2> wet âˆ¼ bern(p_wet[sprinkler][rain]);

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

...
f1 = ğœ™(int<2> rain, int<2> sprinkler){

elim(int<2> cloudy){
cloudy âˆ¼ bern(p);
sprinkler âˆ¼ bern(p_sprinkler[cloudy]);
rain âˆ¼ bern(p_rain[cloudy]); }}

f2 = ğœ™(int<2> rain, int<2> wet){
elim(int<2> sprinkler){

factor(f1[rain,sprinkler]);
wet âˆ¼ bern(p_wet[sprinkler,rain]); }}

f3 = ğœ™(int<2> wet){ elim(int<2> rain){

factor(f2[rain,wet]); }}
f4 = ğœ™(){ elim(int<2> wet){
factor(f3[wet]); }}

factor(f4);
...

Fig. 14. The â€˜Sprinklerâ€™ example.

one cannot express such examples directly in PPLs that do not support discrete parameters. One
well-known discrete variable example, often used in tutorials on probabilistic modelling, is the
â€˜Sprinklerâ€™ example. It models the relationship between cloudy weather, whether it rains, whether
the garden sprinkler is on, and the wetness of the grass. In Figure 14, we show a version of the
sprinkler model written in SlicStan with discrete parameters (left) and the marginalisation part of
its corresponding transformed version (right).

As cloudy âŠ¥âŠ¥ wet | sprinkler, rain, we do not need to include wet in the elimination of cloudy,
and the new factor is computed for different values of only sprinkler and rain (lines 2â€“6). The rest
of the variables are eliminated one-by-one, involving all remaining variables (lines 7â€“15).

The snippet of the SlicStan code generated by our transformation is an exact implementation of
the variable elimination algorithm for this model. This not only facilitates a platform for learning
probabilistic programming using standard introductory models, but it can also be a useful tool for
learning concepts such as marginalisation, conditional independence, and exact inference methods.

B.2 Soft-K-means model
In Figure 15, we present the standard soft-k-means clustering model as it is written in SlicStan with
support for discrete model parameters (left). The right column shows the resulting code that our
program transformation generates. This code consists of plain SlicStan code and no support for
discrete model parameters is needed to perform inference on it.

The model can be used for (softly) dividing ğ‘ data points y in ğ·-dimensional Euclidean space

into ğ¾ clusters which have means ğ and probability ğ….

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:53

SlicStan + discrete

SlicStan

data int D;
data int K;
data real[K] pi;
data real N = 3;

data real[D][N] y;

real[D][K] mu;
for(d in 1 : D) {
for(k in 1 : K){

mu[d][k] âˆ¼ normal(0, 1);

}}

int<K> z1 âˆ¼ categorical(pi);
int<K> z2 âˆ¼ categorical(pi);
int<K> z3 âˆ¼ categorical(pi);

for(d in 1 : D) {

y[d][1] âˆ¼ normal(mu[d][z1], 1);
y[d][2] âˆ¼ normal(mu[d][z2], 1);
y[d][3] âˆ¼ normal(mu[d][z3], 1);

}

...
for(d in 1:D){

for(k in 1:K){

mu[d,k] âˆ¼ normal(0, 1);}}

factor( elim(int<K> z1){
z1 âˆ¼ categorical(pi);
for(data int d in 1:D){

y[d,1] âˆ¼ normal(mu[d,z1], 1);}});

factor( elim(int<K> z2){
z2 âˆ¼ categorical(pi);
for(data int d in 1:D){

y[d,2] âˆ¼ normal(mu[d,z2], 1);}});

factor( elim(int<K> z3){
z3 âˆ¼ categorical(pi);
for(data int d in 1:D){

y[d,3] âˆ¼ normal(mu[d,z3], 1);}});

gen(int z3){

z3 âˆ¼ categorical(pi);
for(data int d in 1:D){

y[d,3] âˆ¼ normal(mu[d,z3], 1);}}

gen(int z2){

z2 âˆ¼ categorical(pi);
for(data int d in 1:D){

y[d,2] âˆ¼ normal(mu[d,z2], 1);}}

gen(int z1){

z1 âˆ¼ categorical(pi);
for(data int d in 1:D){

y[d,1] âˆ¼ normal(mu[d,z1], 1);}}

Fig. 15. Soft ğ¾-means.

B.3 A causal inference example
The question of how to adapt PPLs to causal queries, has been recently gaining popularity. One way
to express interventions and reason about causality, is to assume a discrete variable specifying the
direction (or absence of) causal relationship, and specify different behaviour for each case using if
statements [Winn 2012]. We show a simple causal inference example (Figure 16) written in SlicStan
with direct support for discrete parameters (left) and the code that our transformation generates
(right) on which we can perform inference using a combination of e.g. HMC and ancestral sampling.
This model can be read as follows. Assume that we are in a situation where we want to answer
a causal question. We want to answer this question based on ğ‘ paired observations of ğ´ and
ğµ, in some of which we might have intervened (doB). Our model proceeds by drawing a (prior)

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:54

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r

SlicStan + discrete

data real q;
data int N;
data int[N] A, B, doB;
data real prob_intervention;

real pAcausesB âˆ¼ beta(1, 1);
int<2> AcausesB âˆ¼ bernoulli(pAcausesB);

for (n in 1:N)
if(doB[n] > 0)
B[n] âˆ¼ bernoulli(prob_intervention);

if (AcausesB > 1){
for (n in 1:N){
A[n] âˆ¼ bernoulli(0.5);
if (doB[n] < 1){

if (A[n] > 0) { B[n] âˆ¼ bernoulli(q); }

else { B[n] âˆ¼ bernoulli(1 - q); }
}
}
}
else {
for (n in 1:N){
if (doB[n] < 1){ B[n] âˆ¼ bernoulli(0.5); }

if (B[n] > 0){ A[n] âˆ¼ bernoulli(q); }
else { A[n] âˆ¼ bernoulli(1 - q); }
}
}

SlicStan

data real q;
data int N;
data int[N] A, B, doB;
data real prob_intervention;

real pAcausesB âˆ¼ beta(1, 1);

for(data int n in 1:N)
if(doB[n] > 0)
B[n] âˆ¼ bernoulli(prob_intervention);

factor(elim(int<2> AcausesB){
AcausesB âˆ¼ bernoulli(pAcausesB);
if(AcausesB > 1){
for(data int n in 1:N){
A[n] âˆ¼ bernoulli(0.5);
if(doB[n] < 1){

if(A[n] > 0){B[n] âˆ¼ bernoulli(q);}

else{ B[n] âˆ¼ bernoulli(1 - q); }
}

}
}
else{
for(data int n in 1:N){

if(doB[n] < 1){ B[n] âˆ¼ bernoulli(0.5);

}

if(B[n] > 0){ A[n] âˆ¼ bernoulli(q); }
else{ A[n] âˆ¼ bernoulli(1 - q); }

}}});

Fig. 16. A causal inference example.

probability that ğ´ causes ğµ from a beta distribution, and then specifying ğ´ and ğµ for different
scenarios (intervention, ğ´ causes ğµ and no intervention, ğµ causes ğ´ and no intervention) using
conditional statements.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

