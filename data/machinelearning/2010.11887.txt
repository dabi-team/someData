1

2
2
0
2

b
e
F
8
1

]
L
P
.
s
c
[

2
v
7
8
8
1
1
.
0
1
0
2
:
v
i
X
r
a

Conditional independence by typing

MARIA I. GORINOVA, University of Edinburgh
ANDREW D. GORDON, Microsoft Research and University of Edinburgh
CHARLES SUTTON, University of Edinburgh
MATTHIJS V√ÅK√ÅR, Utrecht University

A central goal of probabilistic programming languages (PPLs) is to separate modelling from inference. However,
this goal is hard to achieve in practice. Users are often forced to re-write their models in order to improve
efficiency of inference or meet restrictions imposed by the PPL. Conditional independence (CI) relationships
among parameters are a crucial aspect of probabilistic models that capture a qualitative summary of the
specified model and can facilitate more efficient inference.

We present an information flow type system for probabilistic programming that captures conditional
independence (CI) relationships, and show that, for a well-typed program in our system, the distribution it
implements is guaranteed to have certain CI-relationships. Further, by using type inference, we can statically
deduce which CI-properties are present in a specified model.

As a practical application, we consider the problem of how to perform inference on models with mixed
discrete and continuous parameters. Inference on such models is challenging in many existing PPLs, but can
be improved through a workaround, where the discrete parameters are used implicitly, at the expense of
manual model re-writing. We present a source-to-source semantics-preserving transformation, which uses
our CI-type system to automate this workaround by eliminating the discrete parameters from a probabilistic
program. The resulting program can be seen as a hybrid inference algorithm on the original program, where
continuous parameters can be drawn using efficient gradient-based inference methods, while the discrete
parameters are inferred using variable elimination.

We implement our CI-type system and its example application in SlicStan: a compositional variant of Stan.1

CCS Concepts: ‚Ä¢ Theory of computation ‚Üí Random walks and Markov chains; Type structures; Opera-
tional semantics; ‚Ä¢ Mathematics of computing ‚Üí Statistical software; ‚Ä¢ Computing methodologies ‚Üí
Learning in probabilistic graphical models.

Additional Key Words and Phrases: probabilistic programming, information flow types, static analysis, condi-
tional independence, compiler correctness

ACM Reference Format:
Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r. 2021. Conditional independence
by typing. ACM Trans. Program. Lang. Syst. 1, 1, Article 1 (January 2021), 54 pages.

1 INTRODUCTION
The number of probabilistic programming languages (PPLs) has grown far and wide, and so has the
range of inference techniques they support. Some focus on problems that can be solved analytically,
and provide a symbolic solution [Gehr et al. 2016], others are very flexible in the models they can
express and use general-purpose inference algorithms [Wood et al. 2014]. Some use gradient-based
methods [Carpenter et al. 2017], or message-passing methods [Minka et al. 2014] to provide an
efficient solution at the cost of restricting the range of expressible programs. Each option presents
its own challenges, whether in terms of speed, accuracy or inference constraints, which is why
PPL users often are required to learn a set of model re-writing techniques: to be able to change the
program until it can be feasibly used within the backend inference algorithm.

1The implementation is available at https://github.com/mgorinova/SlicStan.

2021. 0164-0925/2021/1-ART1 $15.00
https://doi.org/

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

 
 
 
 
 
 
1:2

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

Take for example Stan [Carpenter et al. 2017], which is used by practitioners in a wide range of
sciences and industries to analyse their data using Bayesian inference. While efficient inference
algorithms exist for continuous-only and for some discrete-only models, it is much less clear
what algorithm to use for arbitrary models with large numbers of both discrete and continuous
(latent, i.e., unobserved) parameters. Stan has made a conscious choice not to support probabilistic
models with discrete parameters, so as to perform inference using (dynamic) Hamiltonian Monte
Carlo (HMC) [Betancourt and Girolami 2015; Hoffman and Gelman 2014; Neal et al. 2011]), which
provides efficient, gradient-based inference for differentiable models. As a result, Stan has often
been criticised [Gelman et al. 2015] for its lack of support for discrete parameters. What is usually
overlooked is that many models with discrete parameters can, in fact, be accommodated in Stan, by
manually marginalising (summing) out the discrete parameters and drawing them conditionally
on the continuous parameters [Stan Development Team 2019b, Chapter 7]. One of the core model
rewriting techniques is marginalisation: summing over all possible values that a random variable
can take to obtain a marginal density function that does not involve that variable. Marginalising
efficiently is not always an obvious procedure, as it requires exploiting conditional independence
relationships among the variables in the model. For probabilistic graphical models, there are well-
known algorithms for enumerating all of the conditional independence assumptions implied by a
model. But probabilistic programs are much more general, including control flow and assignment.
For this more general case, it is much less clear how to determine conditional independence
relationships automatically, and doing so requires combining ideas from traditional program
analysis and from probabilistic graphical modelling.

In this paper, we introduce an information flow type system that can deduce conditional inde-
pendence relationships between parameters in a probabilistic program. Finding such relationships
can be useful in many scenarios. As an example application, we implement a semantics-preserving
source-to-source transformation that automatically marginalises discrete parameters. We work in
SlicStan [Gorinova et al. 2019], a form of Stan with a more compositional syntax than the original
language. Our system extends SlicStan to support discrete parameters in the case when the discrete
parameter space is bounded. This transform corresponds to the variable elimination algorithm
[Koller and Friedman 2009; Zhang and Poole 1994]: an exact inference algorithm, efficient in models
with sparse structure. Combining this transformation with an efficient algorithm for continuous
parameters, like HMC, gives us a model-specific, automatically derived inference strategy, which is
a composition of variable elimination and the algorithm of choice. While we only focus on one
application in this paper, our type system for conditional independence is applicable to program
transformations of probabilistic programs more generally, and we believe it can enable other
composed-inference strategies.

In short, we make the following contributions:

(1) Factorised semantics for SlicStan: As a basis for proving correctness of our transformation, we
extend SlicStan‚Äôs type system, so that shredding (which slices a SlicStan program into Stan
for execution) correctly separates well-typed programs into data preprocessing, main model,
and purely generative code (Theorem 1).

(2) Main theoretical result: We show how a very simple, relatively standard information flow
type system can be used to capture a conditional independence in probabilistic programs (¬ß 3)
and establish a correspondence between well-typed programs and conditional independence
properties of the probability distribution it implements (Theorem 2, Theorem 3).

(3) Main practical result: We describe and implement (in SlicStan) a source-to-source transfor-
mation that repeatedly uses the result from (2) to efficiently marginalise out the discrete
parameters of the program, and we give a generative procedure for drawing these parameters

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:3

// Stan target program
data{ real x; }
parameters{ real ùúá; }
model{ x ‚àº normal(ùúá, 1); }
generated quantities{
real x_pred = normal_rng(ùúá, 1); }

// SlicStan from POPL‚Äô19

// Extended SlicStan

real ùúá;
data real x ‚àº normal(ùúá, 1);
real x_pred = normal_rng(ùúá, 1);

real ùúá;
data real x ‚àº normal(ùúá, 1);
real x_pred ‚àº normal(ùúá, 1);

Fig. 1. Example of difference to previous version of SlicStan

(¬ß 4), thus automating inference for mixed discrete-continuous models. We prove that our
transformation is semantics-preserving (Theorem 4).

2 SLICSTAN: EXTENDED SYNTAX AND SEMANTICS
SlicStan [Gorinova et al. 2019] is a Stan-like probabilistic programming language. Compared to
Stan, it provides extra compositionality by dropping the requirement that programs be block-
structured. SlicStan uses type inference in an information-flow type system [Abadi et al. 1999;
Gordon et al. 2015; Volpano et al. 1996] to automatically rearrange the program into parts roughly
corresponding to the block structure of Stan: pre-processing (data), model, and post-processing
(generated quantities). Originally, this shredding was developed to compile SlicStan to Stan. In
this paper, we show that it can be used, more generally, to automatically compile to an efficient
program-specific inference scheme.

Like Stan, SlicStan is imperative and allows for deterministic assignment, for-loops, if-statements,
probabilistic assignment, and factor-statements. One contribution of this work is that we present
an updated version of SlicStan.

A key difference to the original version of SlicStan is the treatment of sampling (‚àº) statements. In
the original SlicStan paper [Gorinova et al. 2019], a statement such as ùë• ‚àº N (0, 1) was understood
simply as a syntactic sugar for factor(N (ùë• | 0, 1)): adding a factor to the underlying density of
the model, rather than performing actual sampling. In our updated version of SlicStan, sampling
statements are part of the core syntax. The semantics of ùë• ‚àº N (0, 1) remains equivalent to that
of factor(N (ùë• | 0, 1)) in terms of density semantics, however it could be implemented differently
depending on the context. In particular, ùë• ‚àº N (0, 1) could be implemented as a simple call to a
random number generator in Stan, ùë• = Nùëüùëõùëî (0, 1), like in the example in Figure 1.

This way of treating ‚àº statements differently is useful, as it allows for an increase of the func-
tionality of the SlicStan‚Äôs information-flow analysis. Consider, for example the SlicStan program
on the right of Figure 1. Using the original type system, both ùúá and ùë•pred will be of level model,
as they are both involved in a ‚àº statement. Thus, when translated to Stan, both ùúá and ùë•pred must
be inferred with HMC (or another similar algorithm), which is expensive. However, the updated
type system of this paper allows for ùë•pred to be of level genqant, which is preferable: in the
context of Stan, this means only ùúá needs to be inferred with HMC, while ùë•pred can be simply drawn
using a random number generator. More generally, the updated SlicStan type system allows for
factorising the density defined by the program: for data D, parameters ùúΩ and generated quantities
ùëÑ, a program defining a density ùëù (D, ùúΩ, ùëÑ) can be sliced into two programs with densities ùëù (D, ùúΩ )
and ùëù (ùëÑ | D, ùúΩ ) respectively (Theorem 1). The parameters ùúΩ are inferred using HMC (or another
general-purpose inference algorithm) according to ùëù (D, ùúΩ ), while the quantities ùëÑ are directly
generated according to ùëù (ùëÑ | D, ùúΩ ).

Treating ‚àº statements differently based on context is very similar in spirit to existing effect-
handling based PPLs [Moore and Gorinova 2018] like Edward2 and Pyro, where ‚àº can be handled

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:4

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

in different ways. However, in our case, this difference in treatment is determined statically,
automatically, and only in the translation to Stan or another backend.

Another difference between Gorinova et al. [2019]‚Äôs SlicStan and our updated version is the

target(ùëÜ) expression, which we use to capture locally the density defined by statements.

These changes are a small but useful contribution of the current work: they are key to allowing

us to decompose the program and compose different inference strategies for efficiency.

In the rest of this section, we give the updated formal syntax, typing and semantics of SlicStan

and describe shredding ‚Äî the procedure key to the translation of Stan / inference composition.

2.1 Syntax
SlicStan has the following types, programs, L-values, statements, and expressions. We highlight the
difference with [Gorinova et al. 2019] with boxes.

SlicStan Types:

SlicStan Program:

‚Ñì ::= data | model | genqant
ùëõ ‚àà N
ùúè ::= real | int |
ùëá ::= (ùúè, ‚Ñì)

int‚ü®ùëõ‚ü© | ùúè []

level type
size
base type
type

ùëÉ ::= Œì, ùëÜ

program

SlicStan L-Values:

ùêø ::= ùë• [ùê∏1] ¬∑ ¬∑ ¬∑ [ùê∏ùëõ]

L-value

SlicStan Typing Environments:

Œì ::= {ùë•1 ‚Ü¶‚Üí ùëá1, . . . , ùë•ùëõ ‚Ü¶‚Üí ùëáùëõ }

typing environment

SlicStan Statements:

SlicStan Expressions:

ùëÜ ::=

statement

assignment
ùêø = ùê∏
ùëÜ1; ùëÜ2
sequence
for(ùë• in ùê∏1 : ùê∏2) ùëÜ for loop
if(ùê∏) ùëÜ1 else ùëÜ2
skip
factor(E)

if statement
skip
factor statement

ùêø ‚àº ùëë (ùê∏1, ..., ùê∏ùëõ)

sample statement

expression

ùê∏ ::=
ùë•
ùëê
[ùê∏1, ..., ùê∏ùëõ]
ùê∏1 [ùê∏2]
ùëì (ùê∏1, . . . , ùê∏ùëõ)
[ùê∏ | ùë• in ùê∏1 : ùê∏2]
target(S)

variable
constant
array
array element
function call
array comprehension

evaluating a density

SlicStan programs consist of a pair Œì, ùëÜ of a typing environment Œì (a finite map that assigns global
variables ùë• to their types ùëá ) and a statement ùëÜ. Following the usual style of declaring variables in C-
like languages, we informally present programs Œì, ùëÜ in examples by sprinkling the type declarations
of Œì throughout the statement ùëÜ. For example, we write data real ùë• ‚àº normal(0, 1) for the program
{ùë• ‚Ü¶‚Üí (real, data)}, ùë• ‚àº normal(0, 1). Sometimes, we will leave out types or write incomplete types
in our examples. In this case, we intend for the missing types to be determined using type inference.
As we discuss in detail in ¬ß¬ß 2.3, a factor(ùê∏) statement can be read as multiplying the current
weight (contribution to the model‚Äôs joint density) of the program trace by the value of ùê∏. Conversely,
a target(ùëÜ) expression initialises the weight to 1 and returns the weight that is accumulated after
evaluating ùëÜ. For example, if:

ùëÜ = x ‚àº normal(0,1); y = 2 * x; z ‚àº normal(y,1);

= factor(normal_pdf(x|0,1)); y = 2 * x; factor(normal_pdf(z|y,1));

Then target(ùëÜ) is semantically equivalent to normal_pdf(x|0,1)* normal_pdf(z|2 * x,1).

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:5

We extend the base types of the language of [Gorinova et al. 2019] with int‚ü®ùëõ‚ü©, which denotes a
positive integer constrained from above by an integer ùëõ. For example if ùë• is of type int‚ü®2‚ü©, then
ùë• can only be 1 or 2. These types allow us to specify the support of discrete variables, and they
can easily be extended to include both upper and lower bounds. For the purpose of our typing
rules, we treat int‚ü®ùëõ‚ü© identically to int. We only differentiate between these types in ¬ß 4, where our
transformation uses the size annotation to eliminate a discrete variable.

2.2 Typing
Types ùëá in SlicStan range over pairs (ùúè, ‚Ñì) of a base type ùúè, and a level type ‚Ñì. The level types ‚Ñì form
a lattice ({data, model, genqant}, ‚â§), where data ‚â§ model ‚â§ genqant. We write (cid:195)ùëõ
ùëñ=1 ‚Ñìùëñ for
the least upper bound of the levels ‚Ñì1, . . . , ‚Ñìùëõ. We call variables of level data data (variables), of level
model model parameters, and of level genqant generated quantities. We refer to variables that are
either of level model or genqant simply as parameters. Given a typing environment Œì, we can
consider the well-typedness of expressions and statements, given the types assigned to variables
by Œì. The judgment Œì ‚ä¢ ùê∏ : (ùúè, ‚Ñì) means that expression ùê∏ has type ùúè and reads only level ‚Ñì and
below. The judgment Œì ‚ä¢ ùëÜ : ‚Ñì means that statement ùëÜ assigns only to level ‚Ñì and above. We write
Œì ‚ä¢ ùëÜ as a shorthand for Œì ‚ä¢ ùëÜ : data.

The typing rules for expressions are those of [Gorinova et al. 2019] with added rules for the two
constructs of array comprehensions and target(ùëÜ)-expressions. The typing rules for statements are
as in [Gorinova et al. 2019], with three differences (highlighted in boxes). (Factor) and (Sample)
add typing rules for the now new language constructs factor(ùê∏) and ùêø ‚àº ùëë (ùê∏1, ..., ùê∏ùëõ). The lan-
guage supports a finite number of built-in functions ùëì with type ùúè1, . . . , ùúèùëõ ‚Üí ùúè and (conditional)
distributions ùëë ‚àà Dist(ùúè1, . . . , ùúèùëõ; ùúè) over ùúè given values of types ùúè1, . . . , ùúèùëõ.

Typing Rules for Expressions:

(ESub)
Œì ‚ä¢ ùê∏ : (ùúè, ‚Ñì)

‚Ñì ‚â§ ‚Ñì ‚Ä≤

(Var)

Œì ‚ä¢ ùê∏ : (ùúè, ‚Ñì ‚Ä≤)

Œì, ùë• : ùëá ‚ä¢ ùë• : ùëá

(Const)

ty(ùëê) = ùúè
Œì ‚ä¢ ùëê : (ùúè, data)

(PrimCall)(ùëì : ùúè1, . . . , ùúèùëõ ‚Üí ùúè)
Œì ‚ä¢ ùê∏ùëñ : (ùúèùëñ, ‚Ñìùëñ ) ‚àÄùëñ ‚àà 1..ùëõ

Œì ‚ä¢ ùëì (ùê∏1, . . . , ùê∏ùëõ) : (ùúè, (cid:195)ùëõ

ùëñ=1 ‚Ñìùëñ )

(ArrEl)
Œì ‚ä¢ ùê∏1 : (ùúè [], ‚Ñì)

Œì ‚ä¢ ùê∏2 : (int, ‚Ñì)

Œì ‚ä¢ ùê∏1 [ùê∏2] : (ùúè, ‚Ñì)

(Target)
Œì ‚ä¢ ùëÜ : ‚Ñì ‚Ä≤‚Ä≤ ‚àÄ‚Ñì ‚Ä≤ > ‚Ñì.ùëÖŒì‚ä¢‚Ñì‚Ä≤ (ùëÜ) = ‚àÖ2
Œì ‚ä¢ target(ùëÜ) : (real, ‚Ñì)

(Arr)
Œì ‚ä¢ ùê∏ùëñ : (ùúè, ‚Ñì) ‚àÄùëñ ‚àà 1..ùëõ
Œì ‚ä¢ [ùê∏1, ..., ùê∏ùëõ] : (ùúè [], ‚Ñì)

(ArrComp)
Œì ‚ä¢ ùê∏1 : (int, ‚Ñì)

Œì ‚ä¢ ùê∏2 : (int, ‚Ñì)

Œì, ùë• : (int, ‚Ñì) ‚ä¢ ùê∏ : (ùúè, ‚Ñì)

ùë• ‚àâ dom(Œì)

Œì ‚ä¢ [ùê∏ | ùë• in ùê∏1 : ùê∏2] : (ùúè [], ‚Ñì)

Typing Rules for Statements:

(SSub)
Œì ‚ä¢ ùëÜ : ‚Ñì ‚Ä≤

‚Ñì ‚â§ ‚Ñì ‚Ä≤

(Assign)3
Œì(ùêø) = (ùúè, ‚Ñì)

Œì ‚ä¢ ùê∏ : (ùúè, ‚Ñì)

Œì ‚ä¢ ùëÜ : ‚Ñì

Œì ‚ä¢ (ùêø = ùê∏) : ‚Ñì

(If)
Œì ‚ä¢ ùê∏ : (real, ‚Ñì) Œì ‚ä¢ ùëÜ1 : ‚Ñì Œì ‚ä¢ ùëÜ2 : ‚Ñì
Œì ‚ä¢ if(ùê∏) ùëÜ1 else ùëÜ2 : ‚Ñì

2We use ‚Ñì‚Ä≤ > ‚Ñì as a shorthand for ‚Ñì ‚â§ ‚Ñì‚Ä≤ ‚àß ¬¨‚Ñì‚Ä≤ ‚â§ ‚Ñì

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:6

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

(Seq)
Œì ‚ä¢ ùëÜ1 : ‚Ñì

Œì ‚ä¢ ùëÜ2 : ‚Ñì S(ùëÜ1, ùëÜ2) ‚àß G(ùëÜ1, ùëÜ2)

Œì ‚ä¢ (ùëÜ1; ùëÜ2) : ‚Ñì

(Factor)
Œì ‚ä¢ ùê∏ : (real, model)
Œì ‚ä¢ factor(ùê∏) : model

(Skip)

Œì ‚ä¢ skip : ‚Ñì

(Sample)3(ùëë ‚àà Dist(ùúè1, . . . , ùúèùëõ; ùúè))
Œì(ùêø) = (ùúè, ‚Ñì ‚Ä≤) Œì ‚ä¢ ùê∏ùëñ : (ùúèùëñ, ‚Ñì), ‚àÄùëñ ‚àà 1..ùëõ ‚Ñì = ‚Ñì ‚Ä≤ ‚äî model
Œì ‚ä¢ ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ) : ‚Ñì

(For)
Œì ‚ä¢ ùê∏1 : (int, ‚Ñì)

Œì ‚ä¢ ùê∏2 : (int, ‚Ñì)

Œì, ùë• : (int, ‚Ñì) ‚ä¢ ùëÜ : ‚Ñì
Œì ‚ä¢ for(ùë• in ùê∏1 : ùê∏2) ùëÜ : ‚Ñì

ùë• ‚àâ dom(Œì)

ùë• ‚àâ ùëä (ùëÜ)

In these rules, we make use of the following notation (see Appendix A for precise definitions).
‚Ä¢ ùëä (ùëÜ): the set of variables ùë• that have been assigned to in ùëÜ.
‚Ä¢ ùëÖŒì‚ä¢‚Ñì (ùëÜ): the set of variables ùë• that are read at level ‚Ñì in ùëÜ.
‚Ä¢ ùëäŒì‚ä¢‚Ñì (ùëÜ): the set of variables ùë• of level ‚Ñì that have been assigned to in ùëÜ.
‚Ä¢ (cid:101)ùëäŒì‚ä¢‚Ñì (ùëÜ): the set of variables ùë• of level ‚Ñì that have been ‚àº-ed in ùëÜ.
‚Ä¢ ùëä (cid:101)ùëäŒì‚ä¢‚Ñì (ùëÜ) = ùëäŒì‚ä¢‚Ñì (ùëÜ) ‚à™ (cid:101)ùëäŒì‚ä¢‚Ñì (ùëÜ)
The intention in SlicStan is that statements of level ‚Ñì are executed before those of ‚Ñì ‚Ä≤ if ‚Ñì < ‚Ñì ‚Ä≤. In
order to follow that implementation strategy without reordering possibly non-commutative pairs
of statements, we impose the condition S(ùëÜ1, ùëÜ2) when we sequence ùëÜ1 and ùëÜ2 in (Seq).

Definition 1 (Shreddable seq). S(ùëÜ1, ùëÜ2) ‚âú ‚àÄ‚Ñì1, ‚Ñì2.(‚Ñì2 < ‚Ñì1) =‚áí ùëÖŒì‚ä¢‚Ñì1 (ùëÜ1) ‚à© ùëäŒì‚ä¢‚Ñì2 (ùëÜ2) = ‚àÖ.

For example, this excludes the following problematic program:

data real sigma = 1;
model real mu ‚àº normal(0, sigma);
sigma = 2;

Above, sigma and the statements sigma=1 and sigma=2 are of level data, which means they
should be executed before the statement mu ‚àº normal(0,sigma), which is of level model. However,
this would change the intended semantics of the program, giving mu a N (0, 2) prior instead of
the intended N (0, 1) prior. This problematic program fails to typecheck in SlicStan, as it is not
shreddable: ¬¨S(mu ‚àº normal(0,sigma), sigma = 2).

Definition 2 (Generative seq). G(ùëÜ1, ùëÜ2) ‚âú ‚àÄ‚Ñì ‚â† model. (cid:101)ùëäŒì‚ä¢‚Ñì (ùëÜ1) ‚à© ùëä (cid:101)ùëäŒì‚ä¢‚Ñì (ùëÜ2) = ‚àÖ ‚àß

ùëä (cid:101)ùëäŒì‚ä¢‚Ñì (ùëÜ1) ‚à© (cid:101)ùëäŒì‚ä¢‚Ñì (ùëÜ2) = ‚àÖ

To be able to read ùë• ‚àº N (0, 1) at level genqant, depending on the context, either as a prob-
abilistic assignment to ùë• or as a density contribution, we impose the condition G(ùëÜ1, ùëÜ2) when
we sequence ùëÜ1 and ùëÜ2. This excludes problematic programs like the following, in which the
multiple assignments to y create a discrepancy between the density semantics of the program
ùëù (ùë¶) = N (ùë¶ | 0, 1)N (ùë¶ | 0, 1) and the sampling-based semantics of the program y = 5.

genquant real y ‚àº normal(0, 1);
y ‚àº normal(0, 1);
y = 5;

3 Here we use Œì (ùêø) to look up the type of the L-value ùêø in Œì. Sometimes we will use an overloaded meaning of this notation
(Definition 14) to look-up the level type of a general expression. Which Œì (.) we refer to will be clear from context.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:7

This problematic program fails to typecheck in SlicStan owing to the G constraint:
¬¨G(y ‚àº normal(0,1), y ‚àº normal(0,1)), and also ¬¨G(y ‚àº normal(0,1), y = 5).

2.3 Operational Semantics of SlicStan Statements
In this paper, we use a modified version of the semantics given in Gorinova et al. [2019]. We extend
the call-by-value operational semantics given in that paper, and derive a more equational form that
also includes the generated quantities.

We define a standard big-step operational semantics for SlicStan expressions and statements:

Big-step Relation

(ùë†, ùê∏) ‚áì ùëâ
(ùë†, ùëÜ) ‚áì (ùë† ‚Ä≤, ùë§)

expression evaluation
statement evaluation

Here, ùë† and ùë† ‚Ä≤ are states, ùëâ is a value and ùë§ ‚àà R>0 is a weight. Our statements can read and write the
state with arbitrary destructive updates. The weight can be thought of as an element of state that
stores a positive real value which only gets accessed by multiplying it with the value of an expression
ùê∏, through the use of factor(ùê∏)-statements. It can only be read through a target(ùëÜ)-statement which
initialises the weight to 1, evaluates the statement ùëÜ and returns the final weight.

Formally, states and values are defined as follows.

Values and States:

ùëâ ::=
ùëê
[ùëâ1, . . . , ùëâùëõ]

value

constant
array

ùë† ::= ùë•1 ‚Ü¶‚Üí ùëâ1, . . . , ùë•ùëõ ‚Ü¶‚Üí ùëâùëõ

ùë•ùëñ distinct

state (finite map from variables to values)

In the rest of the paper, we use the notation for states ùë† = ùë•1 ‚Ü¶‚Üí ùëâ1, . . . , ùë•ùëõ ‚Ü¶‚Üí ùëâùëõ:
‚Ä¢ ùë† [ùë• ‚Ü¶‚Üí ùëâ ] is the state ùë†, but where the value of ùë• is updated to ùëâ if ùë• ‚àà dom(ùë†), or the element

ùë• ‚Ü¶‚Üí ùëâ is added to ùë† if ùë• ‚àâ dom(ùë†).

‚Ä¢ ùë† [‚àíùë•] is the state s, but where ùë• is removed from the domain of ùë† (if it were present).
We also define lookup and update operations on values:
‚Ä¢ If ùëà is an ùëõ-dimensional array value for ùëõ ‚â• 0 and ùëê1, . . . , ùëêùëõ are suitable indexes into ùëà , then

the lookup ùëà [ùëê1] . . . [ùëêùëõ] is the value in ùëà indexed by ùëê1, . . . , ùëêùëõ.

‚Ä¢ If ùëà is an ùëõ-dimensional array value for ùëõ ‚â• 0 and ùëê1, . . . , ùëêùëõ are suitable indexes into ùëà , then
the (functional) update ùëà [ùëê1] . . . [ùëêùëõ] := ùëâ is the array that is the same as ùëà except that the
value indexed by ùëê1, . . . , ùëêùëõ is ùëâ .

The relation ‚áì is deterministic but partial, as we do not explicitly handle error states. The purpose
of the operational semantics is to define a density function in ¬ß¬ß 2.4, and any errors lead to the
density being undefined. The big-step semantics is defined as follows.

Operational Semantics of Expressions:

(Eval Const)

(Eval Var)
ùëâ = ùë† (ùë•)

ùë• ‚àà dom(ùë†)

(ùë†, ùëê) ‚áì ùëê

(ùë†, ùë•) ‚áì ùëâ

(Eval Arr)

(ùë†, ùê∏ùëñ ) ‚áì ùëâùëñ ‚àÄùëñ ‚àà 1..ùëõ
(ùë†, [ùê∏1, . . . , ùê∏ùëõ]) ‚áì [ùëâ1, . . . , ùëâùëõ]

(Eval ArrEl)
(ùë†, ùê∏1 ‚áì ùëâ )

(ùë†, ùê∏2 ‚áì ùëê)

(ùë†, ùê∏1 [ùê∏2]) ‚áì ùëâ [ùëê]

(Eval PrimCall)4
(ùë†, ùê∏ùëñ ) ‚áì ùëâùëñ ‚àÄùëñ ‚àà 1 . . . ùëõ ùëâ = ùëì (ùëâ1, . . . , ùëâùëõ)
(ùë†, ùëì (ùê∏1, . . . , ùê∏ùëõ)) ‚áì ùëâ

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:8

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

(Eval ArrComp)5
(ùë†, ùê∏1) ‚áì ùëõ

(ùë†, ùê∏2) ‚áì ùëö (ùë†, ùê∏ [ùëñ/ùë•]) ‚áì ùëâùëñ, ‚àÄùëõ ‚â§ ùëñ ‚â§ ùëö

(ùë†, [ùê∏ | ùë• in ùê∏1 : ùê∏2]) ‚áì [ùëâùëõ, . . . , ùëâùëö]

(Eval Target)
(ùë†, ùëÜ) ‚áì (ùë† ‚Ä≤, ùë§)
(ùë†, target(ùëÜ)) ‚áì ùë§

Operational Semantics of Statements:

(Eval Assign) (where ùêø = ùë• [ùê∏1] . . . [ùê∏ùëõ])
(ùë†, ùê∏ùëñ ) ‚áì ùëâùëñ ‚àÄùëñ ‚àà 1..ùëõ

(ùë†, ùê∏) ‚áì ùëâ ùëà = ùë† (ùë•) ùëà ‚Ä≤ = (ùëà [ùëâ1] . . . [ùëâùëõ] := ùëâ )
(ùë†, ùêø = ùê∏) ‚áì (ùë† [ùë• ‚Ü¶‚Üí ùëà ‚Ä≤], 1)

(Eval Skip)

(ùë†, skip) ‚áì (ùë†, 1)

(Eval ForTrue)
{(ùë†, ùê∏ùëñ ) ‚áì ùëêùëñ }ùëñ=1,2

(Eval Seq)
(ùë†, ùëÜ1) ‚áì (ùë† ‚Ä≤, ùë§)

(ùë† ‚Ä≤, ùëÜ2) ‚áì (ùë† ‚Ä≤‚Ä≤, ùë§ ‚Ä≤)

(Eval ForFalse)
(ùë†, ùê∏1) ‚áì ùëê1

(ùë†, ùê∏2) ‚áì ùëê2

ùëê1 > ùëê2

(ùë†, ùëÜ1; ùëÜ2) ‚áì (ùë† ‚Ä≤‚Ä≤, ùë§ ‚àó ùë§ ‚Ä≤)

(ùë†, for(ùë• in ùê∏1 : ùê∏2) ùëÜ) ‚áì (ùë†, 1)

ùëê1 ‚â§ ùëê2

(ùë† [ùë• ‚Ü¶‚Üí ùëê1], ùëÜ) ‚áì (ùë† ‚Ä≤, ùë§)

(ùë† ‚Ä≤[‚àíùë•], for(ùë• in (ùëê1 + 1) : ùëê2) ùëÜ) ‚áì (ùë† ‚Ä≤‚Ä≤, ùë§ ‚Ä≤)

(ùë†, for(ùë• in ùê∏1 : ùê∏2) ùëÜ) ‚áì (ùë† ‚Ä≤‚Ä≤, ùë§ ‚àó ùë§ ‚Ä≤)

(Eval IfTrue)
(ùë†, ùê∏) ‚áì ùëê ‚â† 0.0

(ùë†, ùëÜ1) ‚áì (ùë† ‚Ä≤, ùë§)

(ùë†, if(ùê∏) ùëÜ1 else ùëÜ2) ‚áì (ùë† ‚Ä≤, ùë§)

(Eval IfFalse)
(ùë†, ùê∏) ‚áì 0.0
(ùë†, ùëÜ2) ‚áì (ùë† ‚Ä≤, ùë§)
(ùë†, if(ùê∏) ùëÜ1 else ùëÜ2) ‚áì (ùë† ‚Ä≤, ùë§)

(Eval Factor)
(ùë†, ùê∏) ‚áì ùëâ
(ùë†, factor(ùê∏)) ‚áì (ùë†, ùëâ )

(Eval Sample)6
(ùë†, ùêø) ‚áì ùëâ

(ùë†, ùê∏ùëñ ) ‚áì ùëâùëñ, ‚àÄ1 ‚â§ ùëñ ‚â§ ùëõ ùëâ ‚Ä≤ = ùëë (ùëâ |ùëâ1, . . . , ùëâùëõ)

(ùë†, ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ)) ‚áì (ùë†, ùëâ ‚Ä≤)

Most rules of the big-step operational semantics are standard, with the exception of (Eval
Factor) and (Eval Sample), which correspond to the PPL-specific language constructs factor and
ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ). While we refer to the latter construct as probabilistic assignment, its formal
semantics is not that of an assignment statement: both the left and the right hand-side of the
‚Äúassignment‚Äù are evaluated to a value, in order for the density contribution ùëë (ùëâ | ùëâ1, . . . , ùëâùëõ) to be
evaluated and factored into the weight of the current execution trace. Contrary to (Eval Assign),
there is no binding of a result to a variable in (Eval Sample). Of course, as is common in probabilistic
programming, it might, at times7, be beneficial to execute these statements as actual probabilistic
assignments. Our treatment of these statements is agnostic of such implementation details, however.
The design of the type system ensures that information can flow from a level ‚Ñì to a higher one
‚Ñì ‚Ä≤ ‚â• ‚Ñì, but not a lower one ‚Ñì ‚Ä≤ < ‚Ñì: a noninterference result. To state this formally, we introduce the
notions of conformance between a state ùë† and a typing environment Œì and ‚Ñì-equality of states.

We define a conformance relation on states ùë† and typing environments Œì. A state ùë† conforms to

an environment Œì, whenever ùë† provides values of the correct types for the variables used in Œì:
Conformance Relation:

ùë† |= Œì

state ùë† conforms to environment Œì

Rule for the Conformance Relation:

4 ùëì (ùëâ1, . . . , ùëâùëõ) means applying the built-in function ùëì on the values ùëâ1, . . . , ùëâùëõ.
5Here, we write ùê∏ [ùê∏‚Ä≤/ùë• ] for the usual capture avoiding substitution of ùê∏‚Ä≤ for ùë• in ùê∏.
6By ùëë (ùëâ |ùëâ1, . . . , ùëâùëõ), we mean the result of evaluating the intended built-in conditional distribution ùëë on ùëâ , ùëâ1, . . . , ùëâùëõ.
7For example, in our Stan backend for SlicStan, if such a statement is of level model, it will be executed as density contribution,
while if it is of level genqant, it will be executed as a probabilistic assignment.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:9

(Stan State)

ùëâùëñ |= ùúèùëñ ‚àÄùëñ ‚àà ùêº

(ùë•ùëñ ‚Ü¶‚Üí ùëâùëñ )ùëñ ‚ààùêº

|= (ùë•ùëñ : ùúèùëñ )ùëñ ‚ààùêº

Here, ùëâ |= ùúè denotes that the value ùëâ is of type ùúè, and it has the following definition:
‚Ä¢ ùëê |= int, if ùëê ‚àà Z, and ùëê |= real, if ùëê ‚àà R.
‚Ä¢ [ùëâ1, . . . , ùëâùëõ] |= ùúè [ùëõ], if ‚àÄùëñ ‚àà 1 . . . ùëõ.ùëâùëñ |= ùúè.
Definition 3 (‚Ñì-eqal states).

Given a typing environment Œì, states ùë†1 |= Œì and ùë†2 |= Œì are ‚Ñì-equal for level ‚Ñì (written ùë†1 ‚âà‚Ñì ùë†2), if
they differ only for variables of a level strictly higher than ‚Ñì:

Lemma 1 (Noninterference of ‚ä¢).

ùë†1 ‚âà‚Ñì ùë†2 ‚âú ‚àÄùë• : (ùúè, ‚Ñì ‚Ä≤) ‚àà Œì. (‚Ñì ‚Ä≤ ‚â§ ‚Ñì =‚áí ùë†1(ùë•) = ùë†2(ùë•))

Suppose ùë†1 |= Œì, ùë†2 |= Œì, and ùë†1 ‚âà‚Ñì ùë†2 for some ‚Ñì. Then for SlicStan statement ùëÜ and expression ùê∏:

(1) If Œì ‚ä¢ ùê∏ : (ùúè, ‚Ñì) and (ùë†1, ùê∏) ‚áì ùëâ1 and (ùë†2, ùê∏) ‚áì ùëâ2 then ùëâ1 = ùëâ2.
(2) If Œì ‚ä¢ ùëÜ : ‚Ñì and (ùë†1, ùëÜ) ‚áì ùë† ‚Ä≤
2.
1 ‚âà‚Ñì ùë† ‚Ä≤

1, ùë§1 and (ùë†2, ùëÜ) ‚áì ùë† ‚Ä≤

2, ùë§2 then ùë† ‚Ä≤

Proof. (1) follows by rule induction on the derivation Œì ‚ä¢ ùê∏ : (ùúè, ‚Ñì), and using that if Œì ‚ä¢ ùê∏ : (ùúè, ‚Ñì),
ùê∏ reads ùë• and Œì(ùë•) = (ùúè ‚Ä≤, ‚Ñì ‚Ä≤), then ‚Ñì ‚Ä≤ ‚â§ ‚Ñì. (2) follows by rule induction on the derivation Œì ‚ä¢ ùëÜ : ‚Ñì
‚ñ°
and using (1). We present more details of the proof in Appendix A.

2.4 Density Semantics
The semantic aspect of a SlicStan program Œì, ùëÜ that we are the most interested in is the final
weight ùë§ obtained after evaluating the program ùëÜ. This is the value the program computes for
the unnormalised joint density ùëù‚àó (x) = ùëù‚àó (D, ùúΩ, ùëÑ) over the data D, the model parameters ùúΩ , and
generated quantities ùëÑ of the program (see ¬ß¬ß 2.6). Given a program Œì, ùëÜ, we separate the typing
environment Œì into disjoint parts: Œìùúé and Œìx, such that Œìùúé contains precisely the variables that are
deterministically assigned in ùëÜ and Œìx contains those which never get deterministically assigned;
that is the variables x with respect to which we define the target unnormalised density ùëù‚àó (x):

Œìùúé = {(ùë• : ùëá ) ‚àà Œì | ùë• ‚àà ùëä (ùëÜ)}

Œìx = Œì \ Œìùúé .

Similarly, any conforming state ùë† |= Œì separates as ùúé ‚äé x with

ùúé = {(ùë• ‚Ü¶‚Üí ùëâ ) ‚àà ùë† | ùë• ‚àà ùëä (ùëÜ)} x = ùë† \ ùúé.

Then, ùúé |= Œìùúé and x |= Œìx.

The semantics of a SlicStan program Œìùúé, Œìx, ùëÜ is a function

yields a pair of a state ùúé ‚Ä≤ and a weight ùë§, such that:
ùëÜ
(cid:74)

(cid:75)

(ùúé)(x) = ùúé ‚Ä≤, ùë§, where ùúé ‚äé x, ùëÜ ‚áì ùúé ‚Ä≤ ‚äé x, ùë§ .

on states ùúé |= Œìùúé and x |= Œìx that

ùëÜ
(cid:74)

(cid:75)

ùëÜ
(cid:74)

The function

use the notation:
ùëÜ
(cid:74)
density semantics of Œì, ùëÜ. We will be particularly interested in the density semantics.

We will sometimes refer only to one of the two elements of the pair ùúé, ùë§. In those cases we
ùëù the
(cid:75)

ùë† (ùúé)(x),
(cid:75)
ùëù (ùúé) is some positive function ùúô (x) of x. If x1, x2 is a partitioning of x and
‚à´ ùúô (x)dx1 is finite, we say ùúô (x) is an unnormalised density corresponding to the normalised
(cid:75)
density ùëù (x1 | x2) = ùúô (x)/‚à´ ùúô (x)dx1 over x1 and we write
ùëù (ùúé)(x) ‚àù ùëù (x1 | x2). Sometimes,
(cid:75)
when ùúé is clear from context, we will leave it implicit and simply write ùëù (x) for ùëù (x; ùúé).

ùë† the state semantics and
(cid:75)

ùëù (ùúé)(x) =
(cid:75)

(ùúé)(x). We call

ùëÜ
(cid:74)
ùëÜ
(cid:74)

ùëÜ
(cid:74)

ùëÜ
(cid:74)

ùëÜ
(cid:74)

(cid:75)

Next, we observe how the state and density semantics compose.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:10

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

Lemma 2 (Semantics composes). The state and density semantics compose as follows:

ùëÜ1; ùëÜ2
(cid:74)

ùë† (ùúé)(x) =
(cid:75)

ùëÜ2
(cid:74)

ùë† (
(cid:75)

ùëÜ2
(cid:74)

ùë† (ùúé)(x))(x)
(cid:75)

ùëÜ1; ùëÜ2
(cid:74)

ùëù (ùúé)(x) =
(cid:75)

ùëÜ1
(cid:74)

ùëÜ2
ùëù (ùúé)(x)√ó
(cid:74)
(cid:75)

ùëù (
(cid:75)

ùëÜ1
(cid:74)

ùë† (ùúé)(x))(x)
(cid:75)

Throughout the paper we use the following notation to separate the store in a concise way.
Definition 4 (Œì‚Ñì (ùë†) or ùë†‚Ñì ).

For a typing environment Œì and a store ùë† |= Œì, let Œì‚Ñì (ùë†) = {(ùë• ‚Ü¶‚Üí ùëâ ) ‚àà ùë† | Œì(ùë•) = (_, ‚Ñì)}. When it is
clear which typing environment the notation refers to, we write simply ùë†‚Ñì instead of Œì‚Ñì (ùë†).

Using this definition, we re-state the noninterference result in the following convenient form.

Lemma 3 (Noninterference of ‚ä¢ reformulated). Let Œìùúé, Œìx ‚ä¢ ùëÜ be a well-typed SlicStan
program. For all levels ‚Ñì ‚àà {data, model, genquant}, there exist unique functions ùëì‚Ñì , such that for all
ùúé |= Œìùúé , x |= Œìx and ùúé ‚Ä≤ such that

‚Ñì = ùëì‚Ñì ({ùúé‚Ñì‚Ä≤, x‚Ñì‚Ä≤
ùúé ‚Ä≤

| ‚Ñì ‚Ä≤ ‚â§ ‚Ñì }).

ùëÜ
(cid:74)

ùë† (ùúé)(x) = ùúé ‚Ä≤,
(cid:75)

2.5 Shredding and Translation to Stan
A key aim of SlicStan is to rearrange the input program into three phases of execution, corresponding
to the levels of the type system: data preprocessing, core model code to run MCMC or another
inference algorithm on, and genqant, or generated quantities, which amount to sample post-
processing after inference is performed. The motivation for these phases is that they all naturally
appear in the workflow of probabilistic programming. The blocks of the Stan are built around this
phase distinction, and compilation of SlicStan to Stan and comparable back-ends requires it.

The phases impose different restrictions on the code and make it incur differing computational
costs. The model phase is by far the most expensive to evaluate: code in this phase tends to be
executed repeatedly within the inner loop of an inference algorithm like an MCMC method. Further,
it tends to be automatically differentiated [Griewank and Walther 2008] in case gradient-based
inference algorithms are used, which restricts the available programming features and increases
the space and time complexity of evaluation. Type inference in SlicStan combined with shredding
allows the user to write their code without worrying about the performance of different phases, as
code will be shredded into its optimal phase of execution.

The shredding relation is in the core of this rearrangement. Shredding takes a SlicStan statement
ùëÜ and splits it into three single-level statements (Definition 5). That is, ùëÜ ‚áïŒì ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ means we
split ùëÜ into sub-statements ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ , were ùëÜùê∑ mentions only data variables, ùëÜùëÄ mentions data
and model variables, and ùëÜùëÑ is the rest of the program, and such that the composition ùëÜùê∑ ; ùëÜùëÄ ; ùëÜùëÑ
behaves the same as the original program ùëÜ. When combined with type inference, shredding
automatically determines optimal statement placement, such that only necessary work is executed
in the ‚Äòheavy-weight‚Äô model part of inference.

We adapt the shredding from [Gorinova et al. 2019], so that the following holds for the three

sub-statements of a shredded well-typed SlicStan program Œì ‚ä¢ ùëÜ:

‚Ä¢ ùëÜùê∑ implements deterministic data preprocessing: no contributions to the density are allowed.
‚Ä¢ ùëÜùëÄ is the inference core: it is the least restrictive of the three slices ‚Äî either or both of ùëÜùê∑
and ùëÜùëÑ can be merged into ùëÜùëÄ . It can involve contributions to the density which require
advanced inference for sampling. Therefore, this is the part of the program which requires
the most computation during inference (in Stan, what is run inside HMC);

‚Ä¢ ùëÜùëÑ represents sample post-processing: any contributions to the density are generative. That is,

they can immediately be implemented using draws from random number generators.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:11

In terms of inference, we can run ùëÜùê∑ once as a pre-processing step. Then use a suitable inference
algorithm for ùëÜùëÄ (in the case of Stan, that‚Äôs HMC, but we can use other MCMC or VI algorithms),
and, finally, we use ancestral sampling for ùëÜùëÑ . 8
Shredding Relation

ùëÜ ‚áïŒì (ùëÜùê∑ , ùëÜùëÄ, ùëÜùëÑ )

statement shredding

Shredding Rules for Statements:

(Shred Assign)

Œì(ùêø) = (_, data) ‚Üí ùëÜùê∑ = ùêø = ùê∏, ùëÜùëÄ = ùëÜùëÑ = skip
Œì(ùêø) = (_, model) ‚Üí ùëÜùëÄ = ùêø = ùê∏, ùëÜùê∑ = ùëÜùëÑ = skip
Œì(ùêø) = (_, genqant) ‚Üí ùëÜùëÑ = ùêø = ùê∏, ùëÜùê∑ = ùëÜùëÄ = skip
ùêø = ùê∏ ‚áïŒì (ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ )

(Shred Factor)

Œì(ùê∏) = data ‚Üí ùëÜùê∑ = factor(ùê∏), ùëÜùëÄ = ùëÜùëÑ = skip
Œì(ùê∏) = model ‚Üí ùëÜùëÄ = factor(ùê∏), ùëÜùê∑ = ùëÜùëÑ = skip
Œì(ùê∏) = genqant ‚Üí ùëÜùëÑ = factor(ùê∏), ùëÜùê∑ = ùëÜùëÄ = skip
factor(ùê∏) ‚áïŒì (ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ )

(Shred Seq)
ùëÜ1 ‚áïŒì ùëÜùê∑1, ùëÜùëÄ1, ùëÜùëÑ1
ùëÜ2 ‚áïŒì ùëÜùê∑2, ùëÜùëÄ2, ùëÜùëÑ2
ùëÜ1; ùëÜ2 ‚áïŒì (ùëÜùê∑1; ùëÜùê∑2 ), (ùëÜùëÄ1; ùëÜùëÄ2 ), (ùëÜùëÑ1; ùëÜùëÑ2)

(Shred Skip)

skip ‚áïŒì (skip, skip, skip)

(Shred Sample)

Œì(ùêø, ùê∏1, . . . , ùê∏ùëõ) = data ‚Üí ùëÜùê∑ = ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ), ùëÜùëÄ = ùëÜùëÑ = skip)
Œì(ùêø, ùê∏1, . . . , ùê∏ùëõ) = model ‚Üí ùëÜùëÄ = ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ), ùëÜùê∑ = ùëÜùëÑ = skip)
Œì(ùêø, ùê∏1, . . . , ùê∏ùëõ) = genqant ‚Üí ùëÜùëÑ = ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ), ùëÜùê∑ = ùëÜùëÄ = skip)
ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ) ‚áïŒì (ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ )

(Shred If)

ùëÜ1 ‚áïŒì (ùëÜùê∑1, ùëÜùëÄ1, ùëÜùëÑ1)

ùëÜ2 ‚áïŒì (ùëÜùê∑2, ùëÜùëÄ2, ùëÜùëÑ2)

if(ùëî) ùëÜ1 else ùëÜ2 ‚áïŒì (if(ùëî) ùëÜùê∑1 else ùëÜùê∑2 ), (if(ùëî) ùëÜùëÄ1 else ùëÜùëÄ2), (if(ùëî) ùëÜùëÑ1 else ùëÜùëÑ2)
(Shred For)

ùëÜ ‚áïŒì (ùëÜùê∑ , ùëÜùëÄ, ùëÜùëÑ )
for(ùë• in ùëî1 : ùëî2) ùëÜ ‚áïŒì (for(ùë• in ùëî1 : ùëî2) ùëÜùê∑ ), (for(ùë• in ùëî1 : ùëî2) ùëÜùëÄ ), (for(ùë• in ùëî1 : ùëî2) ùëÜùëÑ )

Here, Œì(ùê∏) (Definition 14) gives the principal type of an expression ùê∏, while Œì(ùê∏1, . . . , ùê∏ùëõ)

(Definition 15) gives the least upper bound of the principal types of ùê∏1, . . . , ùê∏ùëõ.

The (Shred If) and (Shred For) rules make sure to shred if and for statements so that they are
separated into parts which can be computed independently at each of the three levels. Note that the
usage of if and for guards is simplified, to avoid stating rules for when the guard(s) are of different
levels. For example, if we have a statement if(ùê∏) ùëÜ1 else ùëÜ2, where ùê∏ is of level model, we cannot
access ùê∏ at level data, thus the actual shredding rule we would use is:

(Shred If Model Level)

ùëÜ1 ‚áïŒì (ùëÜùê∑1, ùëÜùëÄ1, ùëÜùëÑ1)

ùëÜ2 ‚áïŒì (ùëÜùê∑2, ùëÜùëÄ2, ùëÜùëÑ2)

if(ùëî) ùëÜ1 else ùëÜ2 ‚áïŒì skip, (if(ùëî) ùëÜùê∑1 ; ùëÜùëÄ1 else ùëÜùê∑2; ùëÜùëÄ2), (if(ùëî) ùëÜùëÑ1 else ùëÜùëÑ2)

8Ancestral (or forward) sampling refers to the method of sampling from a joint distribution by individually sampling
variables from the factors constituting the joint distribution. For example, we can sample from ùëù (ùë•, ùë¶) = ùëù (ùë•)ùëù (ùë¶ | ùë•) by
randomly generating ÀÜùë• according to ùëù (ùë•), and then randomly generating ÀÜùë¶ according to ùëù (ùë¶ | ùë• = ÀÜùë•).

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:12

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

These shredding rules follow very closely those given by Gorinova et al. [2019]. The main
difference is that sample statements (ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ)) are allowed to be of genqant level and
can be included in the last, generative slice of the program (see rule (Shred Sample)). In other words,
such genqant sample statements are those statements that can be interpreted as probabilistic
assignment (using random number generator functions) to directly sample from the posterior
distribution according to ancestral sampling.

We provide proofs for the following key results in Appendix A: shredding produces single-level

statements (Definition 5 and Lemma 4) and shredding is semantics preserving (Lemma 6).

Intuitively, a single-level statement of level ‚Ñì is one that updates only variables of level ‚Ñì.

Definition 5 (Single-level Statement Œì ‚ä¢ ‚Ñì (ùëÜ)). We define single-level statements ùëÜ of level ‚Ñì

with respect to Œì (written Œì ‚ä¢ ‚Ñì (ùëÜ)), by induction:
Single Level Statements:
(Assign Single)

Œì(ùë•) = (_, ‚Ñì)
Œì ‚ä¢ ‚Ñì (ùë• [ùê∏1] ¬∑ ¬∑ ¬∑ [ùê∏ùëõ] = ùê∏)

(Seq Single)
Œì ‚ä¢ ‚Ñì (ùëÜ)

Œì ‚ä¢ ‚Ñì (ùëÜ ‚Ä≤)

Œì ‚ä¢ ‚Ñì (ùëÜ; ùëÜ ‚Ä≤)

(For Single)

Œì, ùë• : (int, ‚Ñì) ‚ä¢ ‚Ñì (ùëÜ)
Œì ‚ä¢ ‚Ñì (for(ùë• in ùê∏1 : ùê∏2)ùëÜ)

(If Single)
Œì ‚ä¢ ‚Ñì (ùëÜ2)
Œì ‚ä¢ ‚Ñì (ùëÜ1)
Œì ‚ä¢ ‚Ñì (if(ùê∏) ùëÜ1 else ùëÜ2)

(Skip Single)

Œì ‚ä¢ ‚Ñì (skip)

(Factor Single)
Œì ‚ä¢ ùê∏ : ‚Ñì ‚àÄ‚Ñì ‚Ä≤ < ‚Ñì.Œì ‚ä¨ ùê∏ : ‚Ñì ‚Ä≤
Œì ‚ä¢ ‚Ñì (factor(ùê∏))

(Sample Single)
Œì ‚ä¢ ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ) : ‚Ñì ‚àÄ‚Ñì ‚Ä≤ < ‚Ñì.Œì ‚ä¨ ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ) : ‚Ñì ‚Ä≤
Œì ‚ä¢ ‚Ñì (ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ))

Lemma 4 (Shredding produces single-level statements).

Œì ‚ä¢ ùëÜ ‚àß ùëÜ ‚áïŒì (ùëÜùê∑ , ùëÜùëÄ, ùëÜùëÑ ) =‚áí Œì ‚ä¢ data(ùëÜùê∑ ) ‚àß Œì ‚ä¢ model(ùëÜùëÄ ) ‚àß Œì ‚ä¢ genquant(ùëÜùëÑ )

We prove a result about the effect of single-level statements on the store and weight of well-typed
programs (Lemma 5). Intuitively, this result shows that a single-level statement of level ‚Ñì acts on
the state and weight in a way that is independent of levels greater than ‚Ñì.

Lemma 5 (Property of single-level statements).

Let Œìùúé, Œìx, ùëÜ be a SlicStan program, such that ùëÜ is a single-level statement of level ‚Ñì, Œì ‚ä¢ ‚Ñì (ùëÜ). Then
there exist unique functions ùëì and ùúô, such that for any ùúé, x |= Œìùúé, Œìx:

(ùúé)(ùë•) = ùëì (ùúé ‚â§‚Ñì, x‚â§‚Ñì ) ‚à™ ùúé>‚Ñì, ùúô (ùúé ‚â§‚Ñì )(x‚â§‚Ñì ),
where we write ùúé ‚â§‚Ñì = {(ùë• ‚Ü¶‚Üí ùëâ ) ‚àà ùúé | Œìùúé (ùë•) = (_, ‚Ñì)} and ùúé>‚Ñì = ùúé \ ùúé ‚â§‚Ñì .

ùëÜ
(cid:74)

(cid:75)

If Œì ‚ä¢ ùëÜ : data and ùëÜ ‚áïŒì (ùëÜùê∑ , ùëÜùëÄ, ùëÜùëÑ ) then

Lemma 6 (Semantic Preservation of ‚áïŒì).
ùëÜ
(cid:74)

(cid:75)

=

ùëÜùê∑ ; ùëÜùëÄ ; ùëÜùëÑ
(cid:74)

(cid:75)

.

2.6 Density Factorisation
As an extension of [Gorinova et al. 2019], we show that shredding induces a natural factorization of
the density implemented by the program: ùëù (D, ùúΩ, ùëÑ) = ùëù (ùúΩ, D)ùëù (ùëÑ | ùúΩ, D). 9 This means that we
can separate the program into a deterministic preprocessing part, a part that uses a ‚Äòheavy-weight‚Äô
inference algorithm, such as HMC, and a part that uses simple ancestral sampling.

9Here, ùëù (ùëÑ | ùúΩ, D) denotes the conditional probability density of ùëÑ, given the values of ùúΩ and D.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:13

Theorem 1 (Shredding induces a factorisation of the density).

Suppose Œì ‚ä¢ ùëÜ : data and ùëÜ ‚áïŒì ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ and Œì = Œìùúé, ŒìD, ŒìùúΩ , ŒìùëÑ . For all ùúé, D, ùúΩ , and ùëÑ: if
ùúé, D, ùúΩ, ùëÑ |= Œìùúé, ŒìD, ŒìùúΩ , ŒìùëÑ , and

ùëù (ùúé)(D, ùúΩ, ùëÑ) ‚àù ùëù (D, ùúΩ, ùëÑ) and (cid:101)ùëä (ùëÜùëÑ ) = dom(ŒìùëÑ ) then:
(cid:75)

ùëÜ
(cid:74)

(1)
(2)

ùëù (ùúéùê∑ )(D, ùúΩ, ùëÑ) ‚àù ùëù (ùúΩ, D)
ùëÜùëÄ
(cid:75)
(cid:74)
ùëù (ùúéùëÄ )(D, ùúΩ, ùëÑ) = ùëù (ùëÑ | ùúΩ, D)
ùëÜùëÑ
(cid:75)
(cid:74)
ùë† (ùúé)(D, ùúΩ, ùëÑ), ùúéùëÄ =
where ùúéùê∑ =
ùëÜùëÄ
(cid:74)
(cid:75)

ùëÜùê∑
(cid:74)

ùë† (ùúéùê∑ )(D, ùúΩ, ùëÑ), and ùëù (D, ùúΩ, ùëÑ) = ùëù (D, ùúΩ )ùëù (ùëÑ | D, ùúΩ ).
(cid:75)
Proof. This follows by proving a more general result using induction on the structure of ùëÜ,
‚ñ°

Lemma 6, Lemma 2 and Lemma 4. See Appendix A for full proof.

The given SlicStan program ùëÜ defines a joint density ùëù (D, ùúΩ, ùëÑ). By shredding we obtain a model
block ùëÜùëÄ that defines ùëù (ùúΩ, D) and a genqant block ùëÜùëÑ that defines ùëù (ùëÑ | ùúΩ, D). Hence, inference
in Stan using these blocks recovers the semantics ùëù (D, ùúΩ, ùëÑ) of the SlicStan program.

3 THEORY: CONDITIONAL INDEPENDENCE BY TYPING
This section presents the main theoretical contribution of the paper: an information flow type
system for conditional independence. We present a type system and show that a well-typed program
in that system is guaranteed to have certain conditional independencies in its density semantics. As
a reminder, determining the conditional independence relationships between variables is important,
as such relationships capture a qualitative summary of the specified model and can facilitate more
efficient inference. For example, in ¬ß 4 we present an application that uses our type system: a
semantic-preserving transformation that allows for discrete parameters to be introduced in SlicStan,
which was previously not possible due to efficiency constraints.

Our aim is to optimise probabilistic programs by transforming abstract syntax trees or interme-
diate representations (as in the Stan compiler) that are close to abstract syntax. Hence, we seek a
way to compute conditional dependencies by a type-based source analysis, rather than by explicitly
constructing a separate graphical representation of the probabilsitic model.

Given three disjoint sets of random variables (RVs) ùê¥, ùêµ and ùê∂, we say that ùê¥ is conditionally
independent of ùêµ given ùê∂, written ùê¥ ‚ä•‚ä• ùêµ | ùê∂, if and only if their densities factorise as ùëù (ùê¥, ùêµ | ùê∂) =
ùëù (ùê¥ | ùê∂)ùëù (ùêµ | ùê∂). (An alternative formulation states that ùê¥ ‚ä•‚ä• ùêµ | ùê∂ if and only if ùëù (ùê¥, ùêµ, ùê∂) =
ùúô1(ùê¥, ùê∂)ùúô2(ùêµ, ùê∂) for some functions ùúô1 and ùúô2.) Deriving conditional independencies in the presence
of a graphical model (such as a factor graph10) is straightforward, which is why some PPLs focus on
building and performing inference on graphs (for example, Infer.NET [Minka et al. 2014]). However,
building and manipulating a factor graph in generative PPLs (e.g. Gen [Cusumano-Towner et al.
2019], Pyro [Uber AI Labs 2017], Edward2 [Tran et al. 2018], PyMC3 [Salvatier et al. 2016]) or
imperative density-based PPLs (SlicStan, Stan) is not straightforward. Dependencies between
modelled variables might be separated by various deterministic transformations, making it harder
to track the information flow, and ‚Äì more importantly ‚Äì more difficult to isolate parts of the model
needed for transformations such as variable elimination. In the case of SlicStan, each program can
still be thought of as specifying a factor graph implicitly. In this paper, we focus on the problem
of how to work with conditional independence information implicitly encoded in a probabilistic
program, without having access to an explicit factor graph. For example, consider Program A:

10A factor graph is a bipartite graph that shows the factorisation of a multivariable function. Variables are circular nodes,
and each factor of the function is a square node. An edge exists between a variable node ùë• and a factor node ùúô if and only if
ùúô is a function of ùë•. See Program A and its corresponding factor graph as an example, or [Koller and Friedman 2009] for
details.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:14

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

A. Simple Hidden Markov Model (HMM)

ùëß1 ‚àº ùëè (ùúÉ0)

ùëß2 ‚àº ùëè (foo(ùúÉ0, ùëß1))

ùëß1

int<2> z1 ‚àº bern(ùúÉ0);
real ùúÉ1 = foo(ùúÉ0, z1);
int<2> z2 ‚àº bern(ùúÉ1);
real ùúô1 = foo(1, z1);
real ùúô2 = foo(1, z2);
int<2> y1 ‚àº bern(ùúô1);
int<2> y2 ‚àº bern(ùúô2);

ùë¶1 ‚àº ùëè (foo(1, ùëß1))

ùë¶2 ‚àº ùëè (foo(1, ùëß2))

ùë¶1

ùëß2

ùë¶2

The factor graph above represents the factorisation of the joint density function over the parame-
ters of the program: ùëù (ùëß1, ùëß2, ùë¶1, ùë¶2) = ùëè (ùëß1 | ùúÉ0)ùëè (ùë¶1 | foo(1, ùëß1))ùëè (ùëß2 | foo(ùúÉ0, ùëß1))ùëè (ùë¶2 | foo(1, ùëß2)).
Each of the four factors is represented by a square node in the graph, and it connects to the variables
(circle nodes) that the factor depends on. This representation is useful for thinking about conditional
independencies. For example, it is immediately evident from the graph that variables which connect
to the same square node cannot be conditionally independent as they share a factor. More generally,
if there is an (uninterrupted by observed variables) direct path between two variables, then these
two variables are not conditionally independent [Frey 2002].

When looking at the factor graph, it is straightforward to see that ùëß1 and ùëß2 are not conditionally
independent, and neither are ùëß1 and ùë¶1 nor ùëß2 and ùë¶2, as there is a direct path between each of
these pairs. When looking at the program, however, we need to reason about the information flow
through the deterministic variables ùúÉ1, ùúô1 and ùúô2 to reach the same conclusion.

Moreover, manipulation of the program based on conditional dependencies can also be more
difficult without a factor graph. As an example, consider the problem of variable elimination (which
we discuss in more details in ¬ß¬ß 4.3). If we are to eliminate ùëß1 in the factor graph, using variable
elimination, we would simply merge the factors directly connected to ùëß1, sum over ùëß1, and attach
the new factors to all former neighbours of ùëß1 (in this case ùë¶1 and ùëß2, but not ùë¶2). However, in the
case of an imperative program, we need to isolate all the statements that depend on ùëß1, and group
them together without changing the meaning of the program beyond the elimination:

B. HMM with ùëß1 marginalised out
factor(sum([target(

z1 ‚àº bern(ùúÉ0); real ùúÉ1 = foo(ùúÉ0, z1);
z2 ‚àº bern(ùúÉ1); real ùúô1 = foo(1, z1);
y1 ‚àº bern(ùúô1); ) | z1 in 1 : 2 ]));

real ùúô2 = foo(1, z2);
int<2> y2 ‚àº bern(ùúô2);

.

(cid:205)ùëß1 [ùëè (ùëß1 | ùúÉ0)
√óùëè (ùë¶1 | foo(1, ùëß1))
√óùëè (ùëß2 | foo(ùúÉ0, ùëß1)) ]

ùë¶1

ùëß2

ùë¶2

ùë¶2 ‚àº ùëè (foo(1, ùëß2))

We need a way to analyse the information flow to determine conditional independencies between
variables. In the example above, we can leave ùë¶2 out of the elimination of ùëß1, because ùëß1 and ùë¶2 are
conditionally independent given ùëß2, written ùëß1 ‚ä•‚ä• ùë¶2 | ùëß2.

To analyse the information flow, we introduce a novel type system, which we refer to via the
relation ‚ä¢2. It works with a lower semi-lattice ({l1, l2, l3}, ‚â§) of levels, where l1 ‚â§ l2 and l1 ‚â§ l3
and l2 and l3 are unrelated. (Recall that a lower semi-lattice is a partial order in which any two
elements ‚Ñì1, ‚Ñì2 have a greatest lower bound ‚Ñì1 ‚äì ‚Ñì2 but do not always have an upper bound.) A
well-typed program induces a conditional independence relationship for the (random) variables
(RVs) in the program: l2-RVs ‚ä•‚ä• l3-RVs | l1-RVs.

In the example above, this result allows us to eliminate l2-variables (ùëß1), while only considering
l1-variables (ùë¶1 and ùëß2) and knowing l3-variables (ùë¶2) are unaffected by the elimination. We can use

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:15

xl3

xl2

xl3

xl2

ùëÜ3
(cid:74)

ùëù
(cid:75)

ùëÜ2
(cid:74)

ùëù
(cid:75)

xl1

ùëÜ1
(cid:74)

ùëù
(cid:75)

xl1

(a) Factor graph of variables of different levels.

(b) Information flow between levels.

Fig. 2. Intuition for the semi-lattice case l1 < l2 and l1 < l3, where x‚Ñì is of level ‚Ñì. We get xl2 ‚ä•‚ä• xl3 | xl1.

a shredding relation almost identical to that of ¬ß¬ß 2.5 to slice the program in a semantics-preserving
way, and isolate the sub-statements needed for elimination. Here, ùúÉ1 and ùúô1 must be of level l2 for
the program to be well-typed. Thus, all statements involving ùëß1, ùúÉ1 or ùúô1 are of level l2, and the
shredding relation groups them together inside of the elimination loop for ùëß1.

Figure 2 shows the relationship between the levels l1, l2, l3 and the shredding relation. Informa-
tion flows from l1 to l2 and l3, but there is no flow of information between l2 and l3 (Figure 2b).
A ‚ä¢2-well-typed program ùëÜ is shredded by ‚áïŒì into ùëÜ1, ùëÜ2 and ùëÜ3, where ùëÜ1 only mentions l1 vari-
ables, ùëÜ2 only mentions l1 and l2 variables, and ùëÜ3 only mentions l1 and l3 variables. This can
be understood as a new factor graph formulation of the original program ùëÜ, where each of the
substatements ùëÜ1, ùëÜ2, ùëÜ3 defines a factor connected to any involved variables (Figure 2a).

Our approach relies on determining the l1, l2, l3 level types by type inference, as they are not
intrinsic to the variables or program in any way, but are designed solely to determine conditional
independence relationships. These types are not accessible by the probabilistic programming user.
Our type system makes it possible to answer various questions about conditional independence in
a program. Assuming a program defining a joint density ùëù (x), we can use the type system to:

(1) Check if x2 ‚ä•‚ä• x3 | x1 for some partitioning x = x1, x2, x3.
(2) Find an optimal variable partitioning. Given a variable ùë• ‚àà x, find a partitioning x = x1, x2, x3,

such that ùë• ‚àà x2, x2 ‚ä•‚ä• x3 | x1, and x1 and x2 are as small as possible.

(3) Ask questions about the Markov boundary of a variable. Given two variables ùë• and ùë• ‚Ä≤, find
the partitioning x = ùë•, x1, x2, such that ùë• ‚ä•‚ä• x1 | x2 and x2 is as small as possible. Is ùë• ‚Ä≤ in x2?
In other words, is ùë• ‚Ä≤ in the Markov boundary of ùë•?

In the rest of ¬ß 3, we give the ‚ä¢2 type system (¬ß¬ß 3.1), state a noninterference result (Lemma 7,
Lemma 8) and show that semantics is preserved when shredding ‚ä¢2-well-typed programs (Lemma 10).
We present the type system and transformation rules in a declarative style. The implementation
relies on type inference, which we discuss in ¬ß¬ß 4.4. We derive a result about the way shredding
factorises the density defined by the program (Theorem 2). We prove a conditional independence
result (¬ß¬ß 3.2, Theorem 3) and discuss the scope of our approach with examples (¬ß¬ß 3.3).

3.1 The ‚ä¢2 Type System
We introduce a modified version of SlicStan‚Äôs type system. Once again, types ùëá range over pairs
(ùúè, ‚Ñì) of a base type ùúè, and a level type ‚Ñì, but levels ‚Ñì are one of l1, l2, or l3, which form a lower
semi-lattice ({l1, l2, l3}, ‚â§), where l1 ‚â§ l2 and l1 ‚â§ l3. This means, for example, that an l2
variable can depend on an l1 variable, but an l3 variable cannot depend on an l2 variable, as level
types l2 and l3 are incomparable.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:16

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

The type system is a standard information flow type system, very similar to the ‚ä¢ system
introduced in ¬ß¬ß 2.2. We mark the only non-standard rules, (Sample2), (Factor2), and (Seq2), which
also differ from those of ‚ä¢. (Sample2) and (Factor2) both have the same effect as an assignment to
an implicit weight variable that can be of any of the three levels. (Seq2) is a less restrictive version
of (Seq) and exactly as in [Gorinova et al. 2019], and it makes sure the program can be sliced later.
Note also that the non-interference between l2 and l3 relies on the (PrimCall2) rule not being
ùëñ=1 ‚Ñìùëñ does not exist.

derivable when the least upper bound (cid:195)ùëõ

Typing Rules for Expressions:

(ESub2)
Œì ‚ä¢2 ùê∏ : (ùúè, ‚Ñì)

‚Ñì ‚â§ ‚Ñì ‚Ä≤

(Var2)

Œì ‚ä¢2 ùê∏ : (ùúè, ‚Ñì ‚Ä≤)

Œì, ùë• : ùëá ‚ä¢2 ùë• : ùëá

(Const2)

ty(ùëê) = ùúè
Œì ‚ä¢2 ùëê : (ùúè, l1)

(Arr2)
Œì ‚ä¢2 ùê∏ùëñ : (ùúè, ‚Ñì) ‚àÄùëñ ‚àà 1..ùëõ
Œì ‚ä¢2 [ùê∏1, ..., ùê∏ùëõ] : (ùúè [ùëõ], ‚Ñì)

(ArrEl2)
Œì ‚ä¢2 ùê∏1 : (ùúè [ùëõ], ‚Ñì)

Œì ‚ä¢ ùê∏2 : (int, ‚Ñì)

Œì ‚ä¢2 ùê∏1 [ùê∏2] : (ùúè, ‚Ñì)

(PrimCall2)(ùëì : ùúè1, . . . , ùúèùëõ ‚Üí ùúè)
Œì ‚ä¢2 ùê∏ùëñ : (ùúèùëñ, ‚Ñìùëñ ) ‚àÄùëñ ‚àà 1..ùëõ

Œì ‚ä¢2 ùëì (ùê∏1, . . . , ùê∏ùëõ) : (ùúè, (cid:195)ùëõ

ùëñ=1 ‚Ñìùëñ )

(ArrComp2)
‚àÄùëñ = 1, 2.Œì ‚ä¢2 ùê∏ùëñ : (int, ‚Ñì)

Œì, ùë• : (int, ‚Ñì) ‚ä¢ ùê∏ : (ùúè, ‚Ñì) ùë• ‚àâ dom(Œì)

Œì ‚ä¢2 [ùê∏ | ùë• in ùê∏1 : ùê∏2] : (ùúè [ùëõ], ‚Ñì)

(Target2)
Œì ‚ä¢2 ùëÜ : ‚Ñì ‚Ä≤‚Ä≤ ‚àÄ‚Ñì ‚Ä≤ > ‚Ñì.ùëÖŒì‚ä¢‚Ñì‚Ä≤ (ùëÜ) = ‚àÖ
Œì ‚ä¢2 target(ùëÜ) : (real, ‚Ñì)

Typing Rules for Statements:

(SSub2)
Œì ‚ä¢2 ùëÜ : ‚Ñì ‚Ä≤

‚Ñì ‚â§ ‚Ñì ‚Ä≤

(Assign2)
Œì(ùêø) = (ùúè, ‚Ñì)

Œì ‚ä¢2 ùê∏ : (ùúè, ‚Ñì)

Œì ‚ä¢2 ùëÜ : ‚Ñì

Œì ‚ä¢2 (ùêø = ùê∏) : ‚Ñì

(Sample2)
Œì ‚ä¢2 factor(D(ùêø | ùê∏1, . . . , ùê∏ùëõ)) : ‚Ñì
Œì ‚ä¢2 ùêø ‚àº Ddist (ùê∏1, . . . ùê∏ùëõ) : ‚Ñì

(Factor2)
Œì ‚ä¢2 ùê∏ : (real, ‚Ñì)
Œì ‚ä¢2 factor(ùê∏) : ‚Ñì

(Seq2)
Œì ‚ä¢2 ùëÜ1 : ‚Ñì

Œì ‚ä¢2 ùëÜ2 : ‚Ñì S(ùëÜ1, ùëÜ2)

Œì ‚ä¢2 (ùëÜ1; ùëÜ2) : ‚Ñì

(If2)
Œì ‚ä¢2 ùê∏ : (bool, ‚Ñì)

Œì ‚ä¢2 ùëÜ1 : ‚Ñì

Œì ‚ä¢2 ùëÜ2 : ‚Ñì

(Skip2)

Œì ‚ä¢2 if(ùê∏) ùëÜ1 else ùëÜ2 : ‚Ñì

Œì ‚ä¢2 skip : ‚Ñì

(For2)
Œì ‚ä¢2 ùê∏1 : (int, ‚Ñì)

Œì ‚ä¢2 ùê∏2 : (int, ‚Ñì)

Œì, ùë• : (int, ‚Ñì) ‚ä¢2 ùëÜ : ‚Ñì

ùë• ‚àâ dom(Œì)

ùë• ‚àâ ùëä (ùëÜ)

Œì ‚ä¢2 for(ùë• in ùê∏1 : ùê∏2) ùëÜ : ‚Ñì

We state and prove a noninterference result for ‚ä¢2, which follows similarly to the result for ‚ä¢.

Lemma 7 (Noninterference of ‚ä¢2). Suppose ùë†1 |= Œì, ùë†2 |= Œì, and ùë†1 ‚âà‚Ñì ùë†2 for some ‚Ñì. Then for a

SlicStan statement ùëÜ and expression ùê∏:

(1) If Œì ‚ä¢2 ùê∏ : (ùúè, ‚Ñì) and (ùë†1, ùê∏) ‚áì ùëâ1 and (ùë†2, ùê∏) ‚áì ùëâ2 then ùëâ1 = ùëâ2.
(2) If Œì ‚ä¢2 ùëÜ : ‚Ñì and (ùë†1, ùëÜ) ‚áì ùë† ‚Ä≤
2.
1 ‚âà‚Ñì ùë† ‚Ä≤

1, ùë§1 and (ùë†2, ùëÜ) ‚áì ùë† ‚Ä≤

2, ùë§2 then ùë† ‚Ä≤

Proof. (1) follows by rule induction on the derivation Œì ‚ä¢2 ùê∏ : (ùúè, ‚Ñì), and using that if Œì ‚ä¢2 ùê∏ :
(ùúè, ‚Ñì), ùë• ‚àà ùëÖ(ùê∏) and Œì(ùë•) = (ùúè ‚Ä≤, ‚Ñì ‚Ä≤), then ‚Ñì ‚Ä≤ ‚â§ ‚Ñì. (2) follows by rule induction on the derivation
‚ñ°
Œì ‚ä¢2 ùëÜ : ‚Ñì and using (1).

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:17

Once again we derive a more convenient form of the noninterference result. Because the level
types l2 and l3 are not comparable in the order ‚â§, changes in the store at l2 do not affect the store
at l3 and vice versa.

Lemma 8 (Noninterference of ‚ä¢2-well-typed programs).

Let Œìùúé, Œìx, ùëÜ be a SlicStan program, and Œì ‚ä¢2 ùëÜ : l1. There exist unique functions ùëì , ùëî and ‚Ñé, such that
for all ùúé |= Œìùúé , x |= Œìx and ùúé ‚Ä≤ such that
ùë† (ùúé)(x) = ùúé ‚Ä≤:
(cid:75)
l2 = ùëî(ùúél1, ùúél2, xl1, xl2), ùúé ‚Ä≤

l3 = ‚Ñé(ùúél1, ùúél3, xl1, xl3)

l1 = ùëì (ùúél1, xl1), ùúé ‚Ä≤
ùúé ‚Ä≤

ùëÜ
(cid:74)

Proof. Follows from noninterference (Lemma 7).

‚ñ°

Next, we extend the shredding relation from ¬ß¬ß 2.5, and the concept of single-level statements,
to SlicStan programs that are well-typed with respect to ‚ä¢2. This is done by simply treating l1 as
data, l2 as model, and l3 as genqant for the purpose of shredding. We include the full definition
of shredding with respect to ‚ä¢2 for completeness below. We use the same notation ‚áïŒì, and we
generally treat the standard shredding relation from 2.5 and the conditional independence shredding
relation presented here, as the same relation, as there is no difference between the two, other than
the naming of levels.
Shredding Rules for Statements:

(Shred2 Assign)
Œì(ùêø) = l1 ‚Üí ùëÜ1 = ùêø = ùê∏, ùëÜ2 = ùëÜ3 = skip
Œì(ùêø) = l2 ‚Üí ùëÜ2 = ùêø = ùê∏, ùëÜ1 = ùëÜ3 = skip
Œì(ùêø) = l3 ‚Üí ùëÜ3 = ùêø = ùê∏, ùëÜ1 = ùëÜ2 = skip
ùêø = ùê∏ ‚áïŒì (ùëÜ1, ùëÜ2, ùëÜ3)

(Shred2 Seq)
ùëÜ1 ‚áïŒì ùëÜ (1)
, ùëÜ (1)
2
1
ùëÜ1; ùëÜ2 ‚áïŒì (ùëÜ (1)
1

, ùëÜ (1)
3
; ùëÜ (2)
1

ùëÜ2 ‚áïŒì ùëÜ (2)
, ùëÜ (2)
1
2
), (ùëÜ (1)
; ùëÜ (2)
3
2

, ùëÜ (2)
3
; ùëÜ (2)
3

)

), (ùëÜ (1)
2

(Shred2 Factor)
Œì(ùê∏) = l1 ‚Üí ùëÜ1 = factor(ùê∏), ùëÜ2 = ùëÜ3 = skip
Œì(ùê∏) = l2 ‚Üí ùëÜ2 = factor(ùê∏), ùëÜ1 = ùëÜ3 = skip
Œì(ùê∏) = l3 ‚Üí ùëÜ3 = factor(ùê∏), ùëÜ1 = ùëÜ2 = skip
factor(ùê∏) ‚áïŒì (ùëÜ1, ùëÜ2, ùëÜ3)

(Shred2 Skip)

skip ‚áïŒì (skip, skip, skip)

(Shred2 Sample)
Œì(ùêø, ùê∏1, . . . , ùê∏ùëõ) = l1 ‚Üí ùëÜ1 = ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ), ùëÜ2 = ùëÜ3 = skip
Œì(ùêø, ùê∏1, . . . , ùê∏ùëõ) = l2 ‚Üí ùëÜ2 = ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ), ùëÜ1 = ùëÜ3 = skip
Œì(ùêø, ùê∏1, . . . , ùê∏ùëõ) = l3 ‚Üí ùëÜ3 = ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ), ùëÜ1 = ùëÜ2 = skip
ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ) ‚áïŒì (ùëÜ1, ùëÜ2, ùëÜ3)

(Shred2 If)

ùëÜ1 ‚áïŒì ùëÜ (1)
1
if(ùëî) ùëÜ1 else ùëÜ2 ‚áïŒì (if(ùëî) ùëÜ (1)
1

, ùëÜ (1)
, ùëÜ (1)
3
2
else ùëÜ (2)

1

ùëÜ2 ‚áïŒì ùëÜ (2)
1
), (if(ùëî) ùëÜ (1)
2

, ùëÜ (2)
, ùëÜ (2)
3
2
else ùëÜ (2)

2

), (if(ùëî) ùëÜ (1)
3

else ùëÜ (2)

3

)

(Shred2 For)

ùëÜ ‚áïŒì ùëÜ1, ùëÜ2, ùëÜ3
for(ùë• in ùëî1 : ùëî2) ùëÜ ‚áïŒì (for(ùë• in ùëî1 : ùëî2) ùëÜ1), (for(ùë• in ùëî1 : ùëî2) ùëÜ2), (for(ùë• in ùëî1 : ùëî2) ùëÜ3)

As before, shredding produces single-level statements, and shredding preserves semantics with

respect to ‚ä¢2-well-typed programs.

Lemma 9 (Shredding produces single-level statements, ‚ä¢2).

b If ùëÜ ‚áïŒì ùëÜ1, ùëÜ2, ùëÜ3 then Œì ‚ä¢ l1(ùëÜ1), Œì ‚ä¢ l2(ùëÜ2), and Œì ‚ä¢ l3(ùëÜ3).

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:18

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

Lemma 10 (Semantic preservation of ‚áïŒì, ‚ä¢2).

If Œì ‚ä¢2 ùëÜ : l1 and ùëÜ ‚áïŒì ùëÜ1, ùëÜ2, ùëÜ3 then

=

ùëÜ
(cid:74)

(cid:75)

ùëÜ1; ùëÜ2; ùëÜ3
(cid:74)

(cid:75)

.

In addition, we derive a result about the effect of single-level statements on the store and weight

of ‚ä¢2-well-typed programs.

Lemma 11 (Property of ‚ä¢2 single-level statements).

Let Œìùúé, Œìx, ùëÜ be a SlicStan program, and Œì ‚ä¢2 ùëÜ : l1, and ùëÜ be single-level statement of level ‚Ñì, Œì ‚ä¢2 ‚Ñì (ùëÜ).
Then there exist unique functions ùëì and ùúô, such that for any ùúé, x |= Œìùúé, Œìx:

(1) If ‚Ñì = l1, then
(2) If ‚Ñì = l2, then
(3) If ‚Ñì = l3, then

(ùúé)(ùë•) = (cid:0)ùëì (ùúél1, xl1), ùúél2, ùúél3(cid:1) ,
(ùúé)(ùë•) = (cid:0)ùúél1, ùëì (ùúél1, ùúél2, xl1, xl2), ùúél3(cid:1) , ùúô (ùúél1, ùúél2)(xl1, xl2)
(ùúé)(ùë•) = (cid:0)ùúél1, ùúél2, ùëì (ùúél1, ùúél3, xl1, xl3)(cid:1) , ùúô (ùúél1, ùúél3)(xl1, xl3)

ùúô (ùúél1)(xl1)

We give proofs for Lemma 9, 10, and 11 in Appendix A. These results allows us to derive the
second key theorem of this paper, Theorem 2, which, similarly to Theorem 1, gives us a result on
the way shredding factorises the density defined by the program.

Here, and throughout the paper, we use subscripts to refer to specific subsets of Œì. For example,
Œìl1 stands for the subset of the parameters Œìx, such that ùë• : (ùúè, ‚Ñì) ‚àà Œìl1 if and only if ùë• : (ùúè, ‚Ñì) ‚àà Œìx
and ‚Ñì = l1.

Theorem 2 (Shredding induces a factorisation of the density (2)).

Suppose Œì ‚ä¢2 ùëÜ : l1 with Œì = Œìùúé, Œìl1, Œìl2, Œìl3, ùëÜ ‚áïŒì ùëÜ1, ùëÜ2, ùëÜ3. Then for ùúé, ùúΩ 1, ùúΩ 2, ùúΩ 3 |= Œìùúé, Œì1, Œì2, Œì3,
and ùúé ‚Ä≤, ùúé ‚Ä≤‚Ä≤ such that

(ùúé ‚Ä≤)(ùúΩ 1, ùúΩ 2, ùúΩ 3) = ùúé ‚Ä≤‚Ä≤ we have:

(ùúé)(ùúΩ 1, ùúΩ 2, ùúΩ 3) = ùúé ‚Ä≤, and

ùëÜ
(cid:74)
ùëÜ
(cid:74)
ùëÜ
(cid:74)

(cid:75)
(cid:75)
(cid:75)

(1)
(2)
(3)

ùëÜ1
(cid:74)
(cid:75)
ùëù (ùúé)(ùúΩ 1, ùúΩ 2, ùúΩ 3) = ùúô1(ùúΩ 1)
(cid:75)
ùëù (ùúé ‚Ä≤)(ùúΩ 1, ùúΩ 2, ùúΩ 3) = ùúô2(ùúΩ 1, ùúΩ 2)
(cid:75)
ùëù (ùúé ‚Ä≤‚Ä≤)(ùúΩ 1, ùúΩ 2, ùúΩ 3) = ùúô3 (ùúΩ 1, ùúΩ 3)
(cid:75)

ùëÜ1
(cid:74)
ùëÜ2
(cid:74)
ùëÜ3
(cid:74)

ùëÜ2
(cid:74)

(cid:75)

Proof. By applying Lemma 11 to each of ùëÜ1, ùëÜ2, ùëÜ3, which are single-level statements (Lemma 9).
‚ñ°

3.2 Conditional Independence Result for ‚ä¢2-Well-Typed Programs
Theorem 3 states the key theoretical result of this paper: the typing in programs well-typed
with respect to ‚ä¢2 corresponds to a conditional independence relationship. In our proofs, we use
the factorisation characterisation of conditional independence stated by Definition 6. This is a
well-known result in the literature (e.g. [Murphy 2012, Theorem 2.2.1.]).

Definition 6 (Characterisation of conditional independence as factorisation).

For variables ùë•, ùë¶, ùëß and a density ùëù (ùë•, ùë¶, ùëß), ùë• is conditionally independent of ùë¶ given ùëß with respect to
ùëù, written ùë• ‚ä•‚ä•ùëù ùë¶ | ùëß, if and only if ‚àÉùúô1, ùúô2 such that ùëù (ùë•, ùë¶, ùëß) = ùúô1(ùë•, ùëß)ùúô2(ùë¶, ùëß).

An equivalent formulation is ùëù (ùë•, ùë¶ | ùëß) = ùëù (ùë• | ùëß)ùëù (ùë¶ | ùëß).
We extend the notion of conditional independence to apply to a general function ùúô (ùë•, ùë¶, ùëß), using the

notation ùë• ‚ä•ùúô ùë¶ | ùëß to mean ‚àÉùúô1, ùúô2 such that ùúô (ùë•, ùë¶, ùëß) = ùúô1 (ùë•, ùëß)ùúô2(ùë¶, ùëß).

Theorem 3 (‚ä¢2-well-typed programs induce a conditional independence relationship).
For a SlicStan program Œì, ùëÜ such that Œì ‚ä¢2 ùëÜ : l1, Œì = Œìùúé, Œìl1, Œìl2, Œìl3, and for ùúé, ùúΩ 1, ùúΩ 2, ùúΩ 3 |=
Œìùúé, Œìl1, Œìl2, Œìl3, we have ùúΩ 2 ‚ä•ùúô ùúΩ 3 | ùúΩ 1.

ùëÜ
(cid:74)

When

ùëù (ùúé)(ùúΩ 1, ùúΩ 2, ùúΩ 3) ‚àù ùëù (ùúΩ 1, ùúΩ 2, ùúΩ 3), we have ùúΩ 2 ‚ä•‚ä•ùëù ùúΩ 3 | ùúΩ 1.
(cid:75)
Proof. Let ùúΩ = ùúΩ 1, ùúΩ 2, ùúΩ 3, ùëÜ ‚áïŒì ùëÜ1, ùëÜ2, ùëÜ3, and let ùúé ‚Ä≤ and ùúé ‚Ä≤‚Ä≤ be such that ùúé ‚Ä≤ =

ùúé ‚Ä≤‚Ä≤ =

ùëÜ2
(cid:74)

ùë† (ùúé ‚Ä≤)(ùúΩ ). Then, by semantic preservation of shredding (Lemma 10), we have
(cid:75)
ùëÜ
(cid:74)

ùëù (ùúé)(ùúΩ ) =
(cid:75)

ùëÜ1; ùëÜ2; ùëÜ3
(cid:74)

ùëù (ùúé)(ùúΩ )
(cid:75)

by Lemma 10

ùëÜ1
(cid:74)

ùë† (ùúé)(ùúΩ ), and
(cid:75)

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:19

real x1 ‚àº normal(0,1)
real x2 ‚àº normal(0,1)
real x3 ‚àº normal(x1+x2,1)
real x4 ‚àº normal(x3,1)
real x5 ‚àº normal(x3,1)

C. Cross Model

ùë•1

ùë•4

ùë•3

ùë•2

ùë•5

(a) A simple ‚Äòcross‚Äô model.

(b) Graphical model.

ùë•1 ‚ä•‚ä• ùë•2
ùë•1 ‚ä•‚ä• ùë•5 | {ùë•3} ‚à™ ùê¥, ‚àÄùê¥ ‚äÜ {ùë•2, ùë•4}
ùë•2 ‚ä•‚ä• ùë•5 | {ùë•3} ‚à™ ùê¥, ‚àÄùê¥ ‚äÜ {ùë•1, ùë•4}

ùë•1 ‚ä•‚ä• ùë•4 | {ùë•3} ‚à™ ùê¥, ‚àÄùê¥ ‚äÜ {ùë•2, ùë•5}
ùë•2 ‚ä•‚ä• ùë•4 | {ùë•3} ‚à™ ùê¥, ‚àÄùê¥ ‚äÜ {ùë•1, ùë•5}
ùë•4 ‚ä•‚ä• ùë•5 | {ùë•3} ‚à™ ùê¥, ‚àÄùê¥ ‚äÜ {ùë•1, ùë•2}

(c) CI relationships.

Fig. 3. The cross model, as written in SlicStan (a) with its DAG (b) and CI relationships (c).

ùëÜ1
(cid:74)

ùëù (ùúé)(ùúΩ ) √ó
(cid:75)

ùëÜ3
ùëÜ2
=
(cid:74)
(cid:74)
= ùúô1(ùúΩ 1) √ó ùúô2(ùúΩ 1, ùúΩ 2) √ó ùúô3(ùúΩ 1, ùúΩ 3)
= ùúô ‚Ä≤(ùúΩ 1, ùúΩ 2) √ó ùúô3(ùúΩ 1, ùúΩ 3)

ùëù (ùúé ‚Ä≤)(ùúΩ ) √ó
(cid:75)

ùëù (ùúé ‚Ä≤‚Ä≤)(ùúΩ )
(cid:75)

by Lemma 2

by Theorem 2

for some ùúô1, ùúô2, and ùúô3, ùúô ‚Ä≤(ùúΩ 1, ùúΩ 2) = ùúô1(ùúΩ 1) √ó ùúô2(ùúΩ 1, ùúΩ 2). Thus ùúΩ 2 ‚ä•ùúô ùúΩ 3 | ùúΩ 1 by definition of ‚ä•ùúô .
Suppose ùúô (ùúΩ 1, ùúΩ 2, ùúΩ 3) ‚àù ùëù (ùúΩ 1, ùúΩ 2, ùúΩ 3). Then ùëù (ùúΩ 1, ùúΩ 2, ùúΩ 3) = ùúô (ùúΩ 1, ùúΩ 2, ùúΩ 3) √ó ùëç = ùúô ‚Ä≤(ùúΩ 1, ùúΩ 2) √ó
ùúô3(ùúΩ 1, ùúΩ 3) √ó ùëç = ùúô ‚Ä≤(ùúΩ 1, ùúΩ 2) √ó ùúô ‚Ä≤‚Ä≤(ùúΩ 1, ùúΩ 3), where ùëç is a constant and ùúô ‚Ä≤‚Ä≤(ùúΩ 1, ùúΩ 3) = ùúô3(ùúΩ 1, ùúΩ 3) √ó ùëç .
‚ñ°
Therefore, ùúΩ 2 ‚ä•‚ä•ùëù ùúΩ 3 | ùúΩ 1.

3.3 Scope of the Conditional Independence Result
We have shown that ‚ä¢2-well-typed programs exhibit a conditional independence relationship in their
density semantics. However, it is not the case that every conditional independence relationship can
be derived from the type system. In particular, we can only derive results of the form ùúΩ 2 ‚ä•‚ä• ùúΩ 3 | ùúΩ 1,
where ùúΩ 1, ùúΩ 2, ùúΩ 3 is a partitioning of ùúΩ |= Œìx for a SlicStan program Œìùúé, Œìx, ùëÜ. That is, the relationship
includes all parameters in the program.

We discuss the scope of our approach using an example and show a situation where trying to

derive a conditional independence result that does not hold results in a failure to type check.
3.3.1 Example of ‚ä¢2-well-typed program ‚Üí conditional independence.
Consider the Cross Model in Figure 3, its SlicStan program (a), its directed graphical model (b) and
the conditional independence (CI) relationships that hold for that model (c).

Out of the many relationships above, we can derive all relationships that involve all the variables.
That is, we can use our type system to derive all conditional independence relationships that hold
and are of the form ùê¥ ‚ä•‚ä• ùêµ | ùê∂, where ùê¥, ùêµ, ùê∂ is some partitioning of {ùë•1, . . . , ùë•5}. However, note
the following properties of conditional independence:

ùê¥ ‚ä•‚ä• ùêµ | ùê∂ ‚áê‚áí ùêµ ‚ä•‚ä• ùê¥ | ùê∂

and ùê¥ ‚ä•‚ä• ùêµ1, ùêµ2 | ùê∂ ‚áê‚áí ùê¥ ‚ä•‚ä• ùêµ1 | ùê∂ and ùê¥ ‚ä•‚ä• ùêµ2 | ùê∂

Some of the relationships above can be combined and written in other ways, e.g. ùë•1 ‚ä•‚ä• ùë•4 | ùë•2, ùë•3
and ùë•1 ‚ä•‚ä• ùë•5 | ùë•2, ùë•3 can be written as a single relationship ùë•1 ‚ä•‚ä• ùë•4, ùë•5 | ùë•2, ùë•3, thus expressing
them as a single relationship that includes all variables in the program.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:20

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

Exploring different mappings between the parameters ùë•1, . . . , ùë•5 and the type levels l1, l2, l3, for
which the above program typechecks, we can derive all CI relationships that hold for this model,
except for one: ùë•1 ‚ä•‚ä• ùë•2, which we cannot derive with our approach.
3.3.2 Conditional independence relationship does not hold ‚Üí type error.
Suppose that we try to derive the result ùë•1 ‚ä•‚ä• ùë•2 | ùë•3, ùë•4, ùë•5. This does not hold for Program C. By
Theorem 3, we have that a program being ‚ä¢2-well-typed implies that l2 ‚ä•‚ä• l3 | l1. So, we can
derive ùë•1 ‚ä•‚ä• ùë•2 | ùë•3, ùë•4, ùë•5 using Theorem 3 if we show that Œì ‚ä¢2 ùëÜ : l1, for Œì = {ùë•1 : l2, ùë•2 : l3, ùë•3 :
l1, ùë•4 : l1, ùë•5 : l1} and ùëÜ being Program C.

To typecheck Œì ‚ä¢2 ùëÜ : l1, we need to typecheck ùë•3 ‚àº normal(ùë•1 + ùë•2, 1) at some level ‚Ñì. Thus,
by (Sample2) and (PrimCall2), ùë•1, ùë•2 and ùë•3 need to typecheck at ‚Ñì. The types of ùë•1, ùë•2 and ùë•3
are l2, l3 and l1, respectively. So, using (ESub2), it must be the case that l2 ‚â§ ‚Ñì, and l3 ‚â§ ‚Ñì, and
l1 ‚â§ ‚Ñì. However, no such level exists in our lower semi-lattice, as l2 and l3 have no upper bound.
Therefore, typechecking fails and we cannot derive ùë•1 ‚ä•‚ä• ùë•2 | ùë•3, ùë•4, ùë•5.

4 APPLICATION: DISCRETE PARAMETERS SUPPORT THROUGH A

SEMANTICS-PRESERVING TRANSFORMATION

This section presents the main practical contribution of our work: a semantics-preserving procedure
for transforming a probabilistic program to enable combined inference of discrete and continuous
model parameters, which we have implemented for SlicStan. The procedure corresponds to variable
elimination (VE) for discrete parameters implemented in the probabilistic program itself, which can
be combined with gradient-based methods, such as HMC, to perform inference on all parameters.
PPLs that have gradient-based methods in the core of their inference strategy do not, in general,
support directly working with discrete parameters. Stan disallows discrete model parameters
altogether, while Pyro [Uber AI Labs 2017] and Edward2 [Tran et al. 2018] throw a runtime
error whenever discrete parameters are used within a gradient-based method. However, working
with discrete parameters in these languages is still possible, albeit in an implicit way. In many
cases, discrete parameters can be marginalised out manually, and then drawn conditionally on the
continuous parameters. Stan‚Äôs user guide shows many examples of this approach [Stan Development
Team 2019a, Chapter 7]. Pyro provides an on-request marginalisation functionality, which automates
this implicit treatment for plated factor graphs [Obermeyer et al. 2019].

The key idea of the workaround is to marginalise out the discrete parameters by hand, so that
the resulting program corresponds to a density function that does not depend on any discrete
parameters. That is, the user writes a program that computes (cid:205)
ùëù (ùúΩ ùëë, ùúΩ ùëê ) = ùëù (ùúΩ ùëê ), where the
density semantics of the original program was ùëù (ùúΩ ùëë, ùúΩ ùëê ) for discrete parameters ùúΩ ùëë and continuous
parameters ùúΩ ùëê . This allows for continuous parameters of the program to be sampled with HMC,
or other gradient-based inference algorithms, whereas that would have not been possible for the
program with both discrete and continuous latent variables.

ùúΩ ùëë

Because a SlicStan program computes a density directly, it is easy to modify it to marginalise a
variable. For a SlicStan program Œì, ùëÜ, with parameters x |= Œìx, and a discrete parameter ùëß of type
int‚ü®ùêæ‚ü©, the program elim(int‚ü®ùêæ‚ü©ùëß) ùëÜ ‚âú factor(sum([target(ùëÜ) | ùëß in 1 : ùêæ])11 marginalises ùëß:

factor(sum([target(ùëÜ) | ùëß in 1 : ùêæ]))

(cid:74)

ùëù (ùúé)(x) =
(cid:75)

ùêæ
‚àëÔ∏Å

ùëÜ
ùëß=1(cid:74)

ùëù (ùúé)(x) ‚àù
(cid:75)

ùêæ
‚àëÔ∏Å

ùëß=1

ùëù (x) = ùëù (x \ {ùëß})

In other words, we can easily marginalise out all discrete variables in a probabilistic program,
by encapsulating the entire program in nested loops (nested array comprehension expressions in
our examples). However, this approach becomes infeasible for more than a few variables. Variable

11Here, we assume the function sum is available in the language.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:21

D. A Hidden Markov Model (HMM)
...
int<2> z1 ‚àº bernoulli(theta[1]);
int<2> z2 ‚àº bernoulli(theta[z1]);
int<2> z3 ‚àº bernoulli(theta[z2]);
data real y1 ‚àº normal(phi[z1], 1);
data real y2 ‚àº normal(phi[z2], 1);
data real y3 ‚àº normal(phi[z3], 1);

E. Inefficient marginalisation

...
factor(sum [target(

factor(sum [target(

factor(sum [target(

z1 ‚àº bernoulli(theta[1]);
z2 ‚àº bernoulli(theta[z1]);
z3 ‚àº bernoulli(theta[z2]);
y1 ‚àº normal(phi[z1], 1);
y2 ‚àº normal(phi[z2], 1);
y3 ‚àº normal(phi[z3], 1);)

| z1 in 1:2]);

| z2 in 1:2]);

| z3 in 1:2]);

F. Efficient marginalisation

...
real[2] f1 = // new factor on z2

[sum([target(

z1 ‚àº bernoulli(theta[1]);
z2 ‚àº bernoulli(theta[z1]);
y1 ‚àº normal(phi[z1], 1); )

| z1 in 1:2])

| z2 in 1:2]

real[2] f2 = // new factor on z3

[sum([target(

factor(f1[z2]);
y2 ‚àº normal(phi[z2], 1);
z3 ‚àº bernoulli(theta[z2]); )

| z2 in 1:2])

| z3 in 1:2]

factor(sum [target(
factor(f2[z3]);
y3 ‚àº normal(phi[z3], 1); )

| z3 in 1:2]);

elimination [Koller and Friedman 2009; Zhang and Poole 1994] exploits the structure of a model to
do as little work as possible. Consider the HMM snippet (Program D) with three discrete (binary)
hidden variables ùëß1, ùëß2 and ùëß3, and observed outcomes ùë¶1, ùë¶2 and ùë¶3. Naively marginalising out the
hidden variables results in nested loops around the original program (Program E). In the general
case of ùëÅ hidden variables, the resulting program is of complexity ùëÇ (2ùëÅ ).

However, this is wasteful: expressions like ùëß3 ‚àº bernoulli(ùúÉ [ùëß2]) do not depend on ùëß1, and so do
not need to be inside of the ùëß1-elimination loop. Variable elimination (VE) avoids this problem by
pre-computing some of the work. Program F implements VE for this model: when eliminating a
variable, say ùëß1, we pre-compute statements that involve ùëß1 for each possible value of ùëß1 and store
the resulting density contributions in a new factor, ùëì1. This new factor depends on the variables
involved in those statements ‚Äî the neighbours of ùëß1 ‚Äî in this case that is solely ùëß2. We then repeat
the procedure for the other variables, re-using the already computed factors where possible.

In the special case of an HMM, and given a suitable elimination order, variable elimination
recovers the celebrated forward algorithm [Rabiner 1989], which has time complexity ùëÇ (ùëÅ ). Our
goal is to automatically translate the source code of Program D to Program F, exploiting statically
detectable independence properties in the model.

4.1 Goal
Our ultimate goal is to transform a program ùëÜ with continuous parameters ùúΩ ùëê , discrete parameters
ùëù (ùúé)(ùúΩ ùëë, ùúΩ ùëê, D) ‚àù ùëù (ùúΩ ùëë, ùúΩ ùëê | D), into two subprograms: ùëÜhmc
ùúΩ ùëë , data D and density semantics
(cid:75)
and ùëÜgen, such that:

ùëÜ
(cid:74)

‚Ä¢ The density defined by ùëÜhmc is the marginal ùëù (ùúΩ ùëê | D), with the discrete parameters ùúΩ ùëë
marginalised out. This first statement, ùëÜhmc, represents the marginalisation part of the program

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:22

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

(see ¬ß¬ß 4.3) and allows for Hamiltonian Monte Carlo (HMC) sampling of ùúΩ ùëê , as it does not
involve any discrete parameters.

‚Ä¢ The density defined by ùëÜgen is the conditional ùëù (ùúΩ ùëë | ùúΩ ùëê, D). This second statement, ùëÜgen,
represents the generative part of the program (¬ß¬ß 4.5) and it encodes a way to draw ùúΩ ùëë
generatively, without using HMC or another heavy-weight inference algorithm.

Similarly to the extended SlicStan slicing based on information-flow type inference, here we also
want to transform and slice into sub-programs, each focusing on a subset of the parameters, and
preserving the overall meaning:

ùëÜ
(cid:74)

ùëù ‚àù ùëù (ùúΩ ùëë, ùúΩ ùëê | D) = ùëù (ùúΩ ùëê | D) √ó ùëù (ùúΩ ùëë | ùúΩ ùëê, D) ‚àù
(cid:75)

ùëÜhmc
(cid:74)

ùëù √ó
(cid:75)

ùëÜgen
(cid:74)

ùëù =
(cid:75)

ùëÜhmc; ùëÜgen
(cid:74)

ùëù
(cid:75)

12

Our approach performs a semantics-preserving transformation, guided by information-flow
and type inference, which creates an efficient program-specific inference algorithm automatically,
combining HMC with variable elimination.

4.2 Key Insight
The key practical insight of this work is to use the adaptation of SlicStan‚Äôs level types of ¬ß 3 and
its information flow type system to rearrange the program in a semantics-preserving way, so that
discrete parameters can be forward-sampled, instead of sampled using a heavy-weight inference
algorithm. We achieve this by a program transformation for each of the discrete variables. Assuming
that we are applying the transformation with respect to a variable ùëß, we use:

‚Ä¢ The top-level information flow type system Œì ‚ä¢ ùëÜ : data from ¬ß¬ß 2.2, which involves the
level types data ‚â§ model ‚â§ genqant. This partitions the modelled variables x into data
D, model parameters ùúΩ and generated quantities ùëÑ. When we use type inference for ‚ä¢ in
conjunction with shredding ùëÜ ‚áïŒì ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ (¬ß¬ß 2.5), we slice the statement ùëÜ into a data
part ùëÜùê∑ (involving only variables in D), a non-generative part ùëÜùëÄ (involving D and ùúΩ ) and a
generative part ùëÜùëÑ (involving D, ùúΩ and ùëÑ).

‚Ä¢ The conditional independence information flow type system, Œì ‚ä¢2 ùëÜ : l1 from ¬ß 3, which uses
a lower semi-lattice of level types l1 ‚â§ l2, l1 ‚â§ l3. A ‚ä¢2-well-typed program induces a
conditional independence relationship: l2-variables are conditionally independent of l3-
variables given l1-variables: xl2 ‚ä•‚ä• xl3 | xl1, where x = xl1, xl2, xl3 = ùúΩ, D. When we use
type inference for ‚ä¢2 in conjunction with shredding ùëÜ ‚áïŒì ùëÜ1, ùëÜ2, ùëÜ3 (¬ß¬ß 2.5), we isolate ùëÜ2: a
part of the program that does not interfere with ùëÜ3. We can marginalise out l2-variables in
that sub-statement only, keeping the rest of the program unchanged.

‚Ä¢ The discrete variable transformation relation Œì, ùëÜ

ùëß
‚àí‚Üí Œì‚Ä≤, ùëÜ ‚Ä≤ (defined in ¬ß¬ß¬ß 4.6.2), which takes a
SlicStan program Œì, ùëÜ that has discrete model parameter ùëß, and transforms it to a SlicStan pro-
gram Œì‚Ä≤, ùëÜ ‚Ä≤, where ùëß is no longer a model-level parameter but instead one of level genqant.
We define the relation in terms of ‚ä¢ and ‚ä¢2 as per the (Elim Gen) rule.

4.3 Variable Elimination
Variable elimination (VE) [Koller and Friedman 2009; Zhang and Poole 1994] is an exact inference
algorithm often phrased in terms of factor graphs. It can be used to compute prior or posterior
marginal distributions by eliminating, one by one, variables that are irrelevant to the distribution
of interest. VE uses dynamic programming combined with a clever use of the distributive law of
multiplication over addition to efficiently compute a nested sum of a product of expressions.

12This expression is simplified for readability.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:23

ùëè (ùëß1 | ùúÉ1)

ùëè (ùë¶1 | ùúôùëß1 )

ùëß1

ùë¶1

ùëè (ùëß2 | ùúÉùëß1 )

ùëè (ùë¶2 | ùúôùëß2 )

ùëè (ùëß3 | ùúÉùëß2 )

ùëè (ùë¶3 | ùúôùëß3 )

ùëß3

ùë¶3

ùëß2

ùë¶2

ùëì1 (ùëß2, ùë¶1) =
(cid:205)ùëß1 [ùëè (ùëß1 | ùúÉ1)
√óùëè (ùë¶1 | ùúôùëß1 )
√óùëè (ùëß2 | ùúÉùëß1 ) (cid:3)

ùëß2

ùë¶2

ùëè (ùë¶2 | ùúôùëß2 )

ùë¶1

ùëè (ùëß3 | ùúÉùëß2 )

ùëè (ùë¶3 | ùúôùëß3 )

ùëß3

ùë¶3

(a) To eliminate ùëß1, we remove ùëß1 and all its neigh-
bouring factors (in red). Create a new factor ùëì1, by
summing out ùëß1 from the product of these factors.

(b) Connect ùëì1 (in green) to the former neighbours
of ùëß1. The remaining factor graph defines the mar-
ginal ùëù (ùëß2, ùëß3 | y).

ùëì1 (ùëß2, ùë¶1)

ùëß2

ùë¶2

ùëè (ùë¶2 | ùúôùëß2 )

ùë¶1

ùëè (ùëß3 | ùúÉùëß2 )

ùëè (ùë¶3 | ùúôùëß3 )

ùëß3

ùë¶3

ùëì2 (ùëß3, ùë¶2, ùë¶1) = (cid:205)ùëß2 [ùëì1 (ùëß2, ùë¶1)
√óùëè (ùë¶2 | ùúôùëß2 ) √ó ùëè (ùëß3 | ùúÉùëß2 )(cid:3)

ùëè (ùë¶3 | ùúôùëß3 )

ùë¶1

ùë¶2

ùëß3

ùë¶3

(c) To eliminate ùëß2, we remove ùëß2 and all its neigh-
bouring factors (in red). Create a new factor ùëì2, by
summing out ùëß2 from the product of these factors.

(d) Connect ùëì2 (in green) to the former neighbours
of ùëß2. The remaining factor graph defines the mar-
ginal ùëù (ùëß3 | y).

Fig. 4. Step by step example of variable elimination.

We already saw an example of variable elimination in ¬ß 3 (Programs A and B). The idea is to
eliminate (marginalise out) variables one by one. To eliminate a variable ùëß, we multiply all of
the factors connected to ùëß to form a single expression, then sum over all possible values for ùëß to
create a new factor, remove ùëß from the graph, and finally connect the new factor to all former
neighbours13of ùëß. Recall Program D, with latent variables ùëß1, ùëß2, ùëß3 and observed data y = ùë¶1, ùë¶2, ùë¶3.
Figure 4 shows the VE algorithm step-by-step applied to this program. We eliminate ùëß1 to get the
marginal on ùëß2 and ùëß3 (4a and 4b), then eliminate ùëß2 to get the marginal on ùëß3 (4c and 4d).

4.4 Conditional Independence Relationships and Inferring the Markov Blanket
The key property we are looking for, in order to be able to marginalise out a variable independently
of another, is conditional independence given neighbouring variables. If we shred a ‚ä¢2-well-typed
program into ùëÜ1, ùëÜ2 and ùëÜ3, and think of
ùëù as factors, it is easy to visualise the
ùëù and
ùëÜ2
(cid:75)
(cid:75)
(cid:74)
factor graph corresponding to the program: it is as in Figure 5a. Eliminating all xl2 variables, ends
ùëù factor (Figure 5b).
up only modifying the
(cid:75)

When using VE to marginalise out a parameter ùëß, we want to find the smallest set of other
parameters ùê¥, such that ùëß ‚ä•‚ä• ùêµ | ùê¥, where ùêµ is the rest of the parameters. The set ùê¥ is also called
ùëß‚Äôs minimal Markov blanket or Markov boundary. Once we know this set, we can ensure that we
involve the smallest possible number of variables in ùëß‚Äôs elimination, which is important to achieve
a performant algorithm.

ùëÜ3
(cid:74)

ùëÜ2
(cid:74)

ùëÜ1
(cid:74)

ùëù,
(cid:75)

For example, when we eliminate ùëß1 in Program D, both ùëß2 and ùë¶1 need to be involved, as ùëß1
shares a factor with them. By contrast, there is no need to include ùë¶2, ùëß3, ùë¶3 and the statements
associated with them, as they are unaffected by ùëß1, given ùëß2. The variables ùë¶1 and ùëß2 form ùëß1‚Äôs
Markov blanket: given these variables, ùëß1 is conditionally independent of all other variables. That
is, ùëß1 ‚ä•‚ä• ùëß3, ùë¶2, ùë¶3 | ùëß2, ùë¶1.

The type system we present in ¬ß 3 can tell us if the conditional independence relationship
xl2 ‚ä•‚ä• xl3 | xl1 holds for a concrete partitioning of the modelled variables x = xl1, xl2, xl3. But

13‚ÄòNeighbours‚Äô refers to the variables which are connected to a factor which connects to ùëß.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:24

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

ùëÜ1
(cid:74)

ùëù
(cid:75)

ùëÜ1
(cid:74)

ùëù
(cid:75)

xl2

xl1

xl3

ùëÜ2
(cid:74)

ùëù
(cid:75)

ùëÜ3
(cid:74)

ùëù
(cid:75)

xl1

xl3

(cid:205)

xl2

ùëÜ2
(cid:74)

ùëù
(cid:75)

ùëÜ3
(cid:74)

ùëù
(cid:75)

(a) A ‚ä¢2-well-typed program with parameters x.

(b) Eliminating xl2 consists of modifying only

ùëÜ2
(cid:74)

ùëù .
(cid:75)

Fig. 5. The factor graph and VE induced by the shedding ùëÜ ‚áïŒì ùëÜ1, ùëÜ2, ùëÜ3 according to the semi-lattice
l1 ‚â§ l2, l3.

to find the Markov blanket of a variable ùëß we want to eliminate, we rely on type inference. We
define a performance ordering between the level types l3 ‚â∫ l1 ‚â∫ l2, where our first preference
is for variables to be of level l3, level l1 is our second preference, and l2 is our last resort. In our
implementation, we use bidirectional type-checking [Pierce and Turner 2000] to synthesise hard
constraints imposed by the type system, and resolve them, while optimising for the soft constraints
given by the ‚â∫ ordering. This maximises the number of variables that are conditionally independent
of ùëß given its blanket (l3) and minimises the number of variables forming the blanket (l1). Fixing ùëß
to be of l2 level, and l2 being the least preferred option, ensures that only ùëß and variables dependent
on ùëß through deterministic assignment are of that level.

4.5 Sampling the Discrete Parameters
Variable elimination gives a way to efficiently marginalise out a variable ùëß from a model defining
density ùëù (x), to obtain a new density ùëù (x \ {ùëß}). In the context of SlicStan, this means we have the
tools to eliminate all discrete parameters ùúΩ ùëë , from a density ùëù (D, ùúΩ ùëê, ùúΩ ùëë ) on data D, continuous
parameters ùúΩ ùëê and discrete parameters ùúΩ ùëë . The resulting marginal (cid:205)
ùëù (D, ùúΩ ùëê, ùúΩ ùëë ) = ùëù (D, ùúΩ ùëê )
does not involve discrete parameters, and therefore we can use gradient-based methods to infer ùúΩ ùëê .
However, the method so far does not give us a way to infer the discrete parameters ùúΩ ùëë .

ùúΩ ùëë

To infer these, we observe that ùëù (x) = ùëù (x \ {ùëß})ùëù (ùëß | x \ {ùëß}), which means that we can
preserve the semantics of the original model (which defines ùëù (x)), by finding an expression for
the conditional ùëù (ùëß | x \ {ùëß}). If x1, x2 is a partitioning of x \ {ùëß} such that ùëß ‚ä•‚ä• x2 | x1, then
(from Definition 6) ùëù (x) = ùúô1 (ùëß, x1)ùúô2(x1, x2) for some functions ùúô1 and ùúô2. Thus, ùëù (ùëß | x \ {ùëß}) =
ùúô1(ùëß, x1) ¬∑ (ùúô2(x1, x2)/ùëù (x \ {ùëß})) ‚àù ùúô1(ùëß, x1).

In the case when ùëß is a discrete variable of finite support, we can calculate the conditional
ùúô1 (ùëß,x1)
. We can apply this calculation to the factorisation of
probability exactly: ùëù (ùëß | x \ {ùëß}) =
(cid:205)ùëß ùúô1 (ùëß,x1)
a program Œì ‚ä¢2 ùëÜ that is induced by shredding (Theorem 2). In that case, xl2, xl1,
ùëù play the
(cid:75)
roles of ùëß, x1, and ùúô1, respectively. Consequently, we obtain a formula for drawing xl2 conditional
on the other parameters: xl2 ‚àº categorical (cid:16) (cid:104)
ùëÜ2
(cid:74)
xl2

| xl2 ‚àà supp(xl2)

ùëÜ2
(cid:74)

(cid:105) (cid:17).

(cid:205)

ùëù (xl2,xl1)
(cid:75)
ùëÜ2
(cid:74)

ùëù (xl2,xl1)
(cid:75)

4.6 A Semantics-Preserving Transformation Rule
In this section we define a source-to-source transformation that implements a single step of variable
elimination. The transformation re-writes a SlicStan program Œì, ùëÜ with a discrete model-level
parameter ùëß, to a SlicStan program, where ùëß is a genqant-level parameter. Combining the rule
with the shredding presented in ¬ß 2 results in support for efficient inference (see ¬ß¬ß 4.8 for discussion
of limitations) of both discrete and continuous random variables, where continuous variables can
be inferred using gradient-based methods, such as HMC or variational inference, while discrete
variables are generated using ancestral sampling. The transformation allows for SlicStan programs

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:25

with explicit use of discrete parameters to be translated to Stan. We show a step-by-step example
of our discrete parameter transformation in ¬ß¬ß 4.7.
4.6.1 The ùúô, elim and gen derived forms.
We introduce three derived forms that allow us to state the rule concisely.

Variable Elimination Derived Forms

elim(int‚ü®ùêæ‚ü© ùëß) ùëÜ ‚âú factor(sum( [target(ùëÜ) | ùëß in 1 :ùêæ] ))
ùúô (int‚ü®ùêæ1‚ü© ùëß1, . . . , int‚ü®ùêæùëÅ ‚ü© ùëßùëÅ ) ùëÜ

‚âú [. . . [target(ùëÜ) | ùëß1 in 1 : ùêæ1] | ¬∑ ¬∑ ¬∑ | ùëßùëÅ in 1 : ùêæùëÅ ]

gen(int‚ü®ùêæ‚ü© ùëß) ùëÜ ‚âú ùëß ‚àº categorical( [target(ùëÜ) | ùëß in 1 : ùêæ] )

elim(int‚ü®ùêæ‚ü©ùëß) ùëÜ

The elimination expression elim(int‚ü®ùêæ‚ü©ùëß) ùëÜ adds a new factor that is equivalent to marginal-
ùëù (ùúé)(x) = (cid:205)ùêæ
ising ùëß in ùëÜ. In other words,
ùëù (ùúé)(x) (see Lemma 14). A
ùëß=1
(cid:75)
(cid:75)
ùúô-expression ùúô (int‚ü®ùêæ1‚ü© ùëß1, . . . , int‚ü®ùêæùëÅ ‚ü© ùëßùëÅ ) ùëÜ simply computes the density of the statement ùëÜ
in a multidimensional array for all possible values of the variables ùëß1, . . . ùëßùëÅ . In other words,
ùëù (ùúé)(x) (Lemma 14).
(ùëì = ùúô (int‚ü®ùêæ1‚ü© ùëß1, . . . , int‚ü®ùêæùëÅ ‚ü© ùëßùëÅ ) ùëÜ) ; factor(ùëì [ùëß1] . . . [ùëßùëÅ ])
(cid:74)
(cid:75)
The ùúô-expression allows us to pre-compute all the work that we may need to do when marginalis-
ing other discrete variables, which results in efficient nesting. Finally, the generation expression
computes the conditional of a variable ùëß given the rest of the parameters, as in ¬ß¬ß 4.5 (see Lemma 15).

ùëù (ùúé)(x) =
(cid:75)

ùëÜ
(cid:74)

ùëÜ
(cid:74)

(cid:74)

4.6.2 Eliminating a single variable ùëß. The (Elim Gen) rule below specifies a semantics-preserving
transformation that takes a SlicStan program with a discrete model-level parameter ùëß, and trans-
forms it to one where ùëß is genqant-level parameter. In practice, we apply this rule once per
discrete model-level parameter, which eliminates those parameters one-by-one, similarly to the
variable elimination algorithm. And like in VE, the ordering in which we eliminate those variables
can impact performance.

The (Elim Gen) rule makes use of two auxiliary definitions that we define next. Firstly, the
neighbours of ùëß, Œìne, are defined by the relation ne(Œì, Œì‚Ä≤, ùëß) (Definition 7), which looks for non-data
and non-continuous l1-variables in Œì‚Ä≤.

Definition 7 (Neighbours of ùëß, ne(Œì, Œì‚Ä≤, ùëß)). For a ‚ä¢ typing environment Œì, a ‚ä¢2 typing environ-

ment Œì‚Ä≤ = Œì‚Ä≤

and a variable ùëß ‚àà dom(Œì‚Ä≤

ùúé, Œì‚Ä≤
x
ne(Œì, Œì‚Ä≤, ùëß) ‚âú {ùë• : (ùúè, ‚Ñì) ‚àà Œì‚Ä≤

x), the neighbours of ùëß are defined as:

x | ‚Ñì = l1 and Œì(ùë•) = (int‚ü®ùêæ‚ü©, model) for some ùêæ }

Secondly, st(ùëÜ2) (Definition 8) is a statement that has the same store semantics as ùëÜ2, but density
semantics of 1:
ùëù = 1. This ensures that the transformation preserves
(cid:75)
both the density semantics and the store semantics of ùëÜ and is needed because gen(ùëß)ùëÜ2 discards
any store computed by ùëÜ2, thus only contributing to the weight.

ùë† , but
(cid:75)

ùë† =
(cid:75)

st(ùëÜ2)

st(ùëÜ2)

ùëÜ2
(cid:74)

(cid:74)

(cid:74)

Definition 8. Given a statement ùëÜ, we define the statement st(ùëÜ) by replacing all factor(ùê∏)- and

ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ)-substatements in ùëÜ by skip (see Appendix A for the precise definition).

The elim-gen rule:

(Elim Gen)

Œì(ùëß) = (int‚ü®ùêæ‚ü©, model)

Œìne = ne(Œì, ŒìùëÄ, ùëß)

ùëÜ ‚Ä≤ = ùëÜùê∑ ; ùëÜ ‚Ä≤

ùëÄ ; ùëÜùëÑ

Œì ‚ä¢ ùëÜ : data ùëÜ ‚áïŒì ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ

ùëÄ = ùëÜ1; ùëì = ùúô (Œìne){elim(int‚ü®ùêæ‚ü©ùëß) ùëÜ2}; factor(ùëì [dom(Œìne)]); ùëÜ3; gen(ùëß)ùëÜ2; st(ùëÜ2)
ùëÜ ‚Ä≤
ùëß
‚àí‚Üí ŒìùëÄ ŒìùëÄ ‚ä¢2 ùëÜùëÄ : l1
ùëß
‚àí‚Üí Œì‚Ä≤, ùëÜ ‚Ä≤

ùëÜùëÄ ‚áïŒìùëÄ ùëÜ1, ùëÜ2, ùëÜ3

Œì, ùëÜ

Œì

Œì‚Ä≤ ‚ä¢ ùëÜ ‚Ä≤ : data

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:26

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

We can use the (Elim Gen) rule to transforms a SlicStan program, with respect to a parameter ùëß,

as described by Algorithm 1. This involves three main steps:

(1) Separate out ùëÜùëÄ ‚Äî the model-level sub-part of ùëÜ ‚Äî using the top-level type system ‚ä¢ (line 1

of Algorithm 1).

(2) Separate out ùëÜ2 ‚Äî the part of ùëÜùëÄ that involves the discrete parameter ùëß ‚Äî using the conditional

independence type system ‚ä¢2 (lines 2‚Äì8).

(3) Perform a single VE step by marginalising out ùëß in ùëÜ2 and sample ùëß from the conditional

probability specified by ùëÜ2 (lines 10‚Äì11).

Algorithm 1. Single step of applying (Elim Gen)

Arguments: (Œì, ùëÜ), ùëß
Requires: Œì ‚ä¢ ùëÜ : data
Returns: (Œì‚Ä≤, ùëÜ ‚Ä≤)

// A program (Œì, ùëÜ); the variable ùëß to eliminate
// (Œì, ùëÜ) is well-typed
// The transformed program

1: Slice (Œì, ùëÜ) into ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ according to ùëÜ ‚áïŒì ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ .
2: Derive incomplete ŒìùëÄ from Œì based on Œì
3:
4:
5:

6:
7: Infer missing types of ŒìùëÄ according to ŒìùëÄ ‚ä¢2 ùëÜùëÄ : l1.
8: Slice (ŒìùëÄ, ùëÜùëÄ ) into ùëÜ1, ùëÜ2, ùëÜ3 according to ùëÜùëÄ ‚áïŒìùëÄ ùëÜ1, ùëÜ2, ùëÜ3.
9:
10: Œìne = ne(Œì, ŒìùëÄ, ùëß)
ùëÜ ‚Ä≤
ùëÄ = (ùëÜ1;
11:

ùëß
‚àí‚Üí ŒìùëÄ . // data of Œì is of level l1 in ŒìùëÄ .

// Continuous model var. of Œì are l1 in ŒìùëÄ .
// ùëß is of level l2 in ŒìùëÄ .
// All other model variables are given
// a type level placeholder in ŒìùëÄ .

// Determine the discrete neighbours of ùëß.
// Eliminate ùëß and re-generate ùëß.

ùëì = ùúô (Œìne){elim(int‚ü®ùêæ‚ü©ùëß) ùëÜ2};
factor(ùëì [dom(Œìne)]);
ùëÜ3;
gen(ùëß) ùëÜ2;
st(ùëÜ2))
ùëÄ ; ùëÜùëÑ

12: ùëÜ ‚Ä≤ = ùëÜùê∑ ; ùëÜ ‚Ä≤
13: Infer an optimal Œì‚Ä≤ according to Œì‚Ä≤ ‚ä¢ ùëÜ ‚Ä≤ : data
14: return (Œì‚Ä≤, ùëÜ ‚Ä≤)

All other sub-statements of the program, ùëÜùê∑, ùëÜ1, ùëÜ3 and ùëÜùëÑ , stay the same during the transfor-
mation. By isolating ùëÜ2 and transforming only this part of the program, we make sure we do not
introduce more work than necessary when performing variable elimination.

To efficiently marginalise out ùëß, we want to find the Markov boundary of ùëß given all data and
continuous model parameters: the data is given, and marginalisation happens inside the continuous
parameters inference loop, so we can see continuous parameters as given for the purpose of discrete
parameters marginalisation. Thus we are looking for the relationship: ùëß ‚ä•‚ä• ùúΩ ùëë2 | D, ùúΩ ùëê, ùúΩ ùëë1, where
D is the data, ùúΩ ùëê are the continuous model-level parameters, ùúΩ ùëë1 is a subset of the discrete model-
level parameters that is as small as possible (the Markov blanket), and ùúΩ ùëë2 is the rest of the discrete
model-level parameters. We can find an optimal partitioning of the discrete parameters ùúΩ ùëë1, ùúΩ ùëë2 that
respects this relationship of interest using the type system from ¬ß 3 together with type inference.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:27

The judgement ŒìùëÄ ‚ä¢2 ùëÜùëÄ : l1 induces a conditional independence relationship of the form
ùëß
‚àí‚Üí ŒìùëÄ (Definition 9) constrains the
xl2 ‚ä•‚ä• xl3 | xl1, where x |= Œìx (Theorem 3). The relation Œì
form of ŒìùëÄ based on Œì. This is needed to make sure we are working with a relationship of the form
we are interested in ‚Äî ùëß ‚ä•‚ä• ùúΩ ùëë2 | D, ùúΩ ùëê, ùúΩ ùëë1 ‚Äî and that base types ùúè are the same between Œì and ŒìùëÄ .
ùëß
In particular, Œì
‚àí‚Üí ŒìùëÄ constrains ùëß to be the only l2 parameter in ŒìùëÄ and all data and continuous
model-level parameters of Œì are l1 in ŒìùëÄ . Note, dom(ŒìùëÄ ) ‚äÜ dom(Œì) and ŒìùëÄ only contains variables
that are of level model and below in Œì. Variables that are of level genqant in Œì are not in ŒìùëÄ .

Definition 9 (Œì

ùëß
‚àí‚Üí Œì‚Ä≤).

For a ‚ä¢ typing environment Œì and a ‚ä¢2 typing environment Œì‚Ä≤, a variable ùëß and a statement ùëÜ, we have:
x,l2 = {ùëß : ùúè, l2} for some ùúè

Œì(ùëß) = (ùúè, model) and Œì‚Ä≤
ùë• : (ùúè, ‚Ñì) ‚àà Œì such that ‚Ñì ‚â§ model ‚áê‚áí ùë• : (ùúè, ‚Ñì ‚Ä≤) ‚àà Œì‚Ä≤ for some ‚Ñì ‚Ä≤ ‚àà {l1, l2, l3}
ùë• : (ùúè, data) ‚àà Œì ‚Üí ùë• : (ùúè, l1) ‚àà Œì‚Ä≤
ùë• : (ùúè, model) ‚àà Œìx and ùúè = real or ùúè = real[]...[] ‚Üí ùë• : (ùúè, l1) ‚àà Œì‚Ä≤

Œì

ùëß
‚àí‚Üí Œì‚Ä≤ =

Ô£±Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥

Following convention from earlier in the paper, we use level subscripts to refer to specific subsets
x,l2 refers to the subset of parameters x in Œì‚Ä≤, which are of level l2.

of Œì: in the above definition, Œì‚Ä≤

Ô£≥

4.7 Marginalising Multiple Variables: An example
To eliminate more than one discrete parameter, we apply the (Elim Gen) rule repeatedly. Here, we
work through a full example, showing the different steps of this repeated (Elim Gen) transformation.
Consider an extended version of the HMM model from the beginning of this section (Program

D), reformulated to include transformed parameters:

G. An extended HMM

The typing environment

ùëÜ = real[2] phi ‚àº beta(1, 1);

Œì = {ùë¶1,2,3 : (real, data),

real[2] theta ‚àº beta(1, 1);
real theta0 = theta[0];
int<2> z1 ‚àº bernoulli(theta0);
real theta1 = theta[z1];
int<2> z2 ‚àº bernoulli(theta1);
real theta2 = theta[z2];
int<2> z3 ‚àº bernoulli(theta2);
real phi1 = phi[z1];
real phi2 = phi[z2];
real phi3 = phi[z3];
data real y1 ‚àº normal(phi1, 1);
data real y2 ‚àº normal(phi2, 1);
data real y3 ‚àº normal(phi3, 1);
real theta3 = theta[z3];
int genz ‚àº bernoulli(theta4);

ùúô : (real[2], model),
ùúÉ : (real[2], model),
ùúÉ0,1,2 : (real, model),
ùúô1,2,3 : (real, model),
ùëß1,2,3 : (int<2>, model),
ùúÉ3 : (real, genqant),
ùëîùëíùëõùëß : (int<2>, genqant)}

The variables we are interested in transforming are ùëß1, ùëß2 and ùëß3: these are the model-level
discrete parameters of Program G. The variable genz is already at genqant level, so we can
sample this with ancestral sampling (no need for automatic marginalisation).

We eliminate ùëß1, ùëß2 and ùëß3 one by one, in that order. The order of elimination generally has a
significant impact on the complexity of the resulting program (see also ¬ß¬ß 4.8), but we do not focus
on how to choose an ordering here. The problem of finding an optimal ordering is well-studied
[Amir 2010; Arnborg et al. 1987; Kj√¶rulff 1990] and is orthogonal to the focus of our work.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:28

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

4.7.1 Eliminating ùëß1. Eliminating a single variable happens in three steps, as shown in Figure 6:
standard shredding into ùëÜùê∑, ùëÜùëÄ and ùëÜùëÑ , conditional independence shredding of ùëÜùëÄ into ùëÜ1, ùëÜ2 and
ùëÜ3, and combining everything based on (Elim Gen).

(1) Standard shredding: ùëÜ ‚áïŒì ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ . Firstly, we separate out the parts of the program that
depend on discrete parameters generatively. That is any part of the program that would be
in generated quantities with respect to the original program. In our case, this includes the
last two lines in ùëÜ. This would also include the gen parts of the transform program, that
draw discrete parameters as generated quantities. Thus, ùëÜ ‚áïŒì ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ , where ùëÜùê∑ is empty,

(1) Standard shredding of ùëÜ

(3) Applying (Elim Gen): Program G-1

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

1

2

3

4

5

6

7

8

9

10

11

12

13

14

ùëÜùê∑ = skip;
ùëÜùëÄ = phi ‚àº beta(1, 1);

theta ‚àº beta(1, 1);
theta0 = theta[0];
z1 ‚àº bernoulli(theta0);
theta1 = theta[z1];
z2 ‚àº bernoulli(theta1);
theta2 = theta[z2];
z3 ‚àº bernoulli(theta2);
phi1 = phi[z1];
phi2 = phi[z2];
phi3 = phi[z3];
y1 ‚àº normal(phi1, 1);
y2 ‚àº normal(phi2, 1);
y3 ‚àº normal(phi3, 1);

ùëÜùëÑ = theta3 = theta[z3];

genz ‚àº bernoulli(theta3);

(2) CI shredding of ùëÜùëÄ

ùëÜ1 = phi ‚àº beta(1, 1);

theta ‚àº beta(1, 1);
theta0 = theta[0];
ùëÜ2 = z1 ‚àº bernoulli(theta0);

theta1 = theta[z1];
z2 ‚àº bernoulli(theta1);
phi1 = phi[z1];
y1 ‚àº normal(phi1, 1);

ùëÜ3 = theta2 = theta[z2];

z3 ‚àº bernoulli(theta2);
phi2 = phi[z2];
phi3 = phi[z3];
y2 ‚àº normal(phi2, 1);
y3 ‚àº normal(phi3, 1);

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

phi ‚àº beta(1, 1);
theta ‚àº beta(1, 1);
theta0 = theta[0];

f1 = ùúô([int<2> z2]){
elim(int<2> z1){

z1 ‚àº bernoulli(theta0);
theta1 = theta[z1];
z2 ‚àº bernoulli(theta1);
phi1 = phi[z1];
y1 ‚àº normal(phi1, 1);

}}

factor(f1[z2]);

theta2 = theta[z2];
z3 ‚àº bernoulli(theta2);
phi2 = phi[z2];
phi3 = phi[z3];
y2 ‚àº normal(phi2, 1);
y3 ‚àº normal(phi3, 1);

gen(int z1){

z1 ‚àº bernoulli(theta0);
theta1 = theta[z1]
z2 ‚àº bernoulli(theta1);
phi1 = phi[z1];
y1 ‚àº normal(phi1, 1);

}
theta1 = theta[z1];
phi1 = phi[z1];

theta3 = theta[z3];
genz ‚àº bernoulli(theta3);

Fig. 6. Step-by-step elimination of ùëß1 in Program G.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:29

ùëÜùëÑ = (theta3 = theta[z3];genz ‚àº bernoulli(theta3)), and ùëÜùëÄ is the rest of the program (see
Figure 6, (1)).

(2) Conditional independence shredding: ùëÜùëÄ ‚áïŒìùëÄ ùëÜ1, ùëÜ2, ùëÜ3. In the next step, we want to establish
a conditional independence relationship ùëß1 | ùê¥ ‚ä•‚ä• y, ùúô0, ùúÉ0, ùêµ, where ùëß1 is some discrete
parameter and ùê¥, ùêµ is a partitioning of the rest of the discrete parameters in the model:
{ùëß2, ùëß3}. We derive a new, ‚ä¢2 typing environment ŒìùëÄ , using Œì

ùëß
‚àí‚Üí ŒìùëÄ :

ŒìùëÄ = {ùë¶1,2,3 : (real, l1), ùúô : (real[2], l1), ùúÉ : (real[2], l1),
ùëß1 : (int<2>, l2), ùëß2 : (int<2>, ?), ùëß3 : (int<2>, ?)
ùúÉ0 : (real, l1), ùúÉ1,2 : (real, ?), ùúô1,2,3 : (real, ?)}

Here, we use the notation ? for a type placeholder, which will be inferred using type inference.
The optimal ŒìùëÄ under the type inference soft constraint l3 ‚â∫ l1 ‚â∫ l2 such that ŒìùëÄ ‚ä¢2 ùëÜùëÄ : l1
is such that the levels of ùúÉ1 and ùúô1 are l2, ùëß2 is l1 and ùúÉ2, ùúô2 and ùúô3 are l3. Shredding then
gives us ùëÜùëÄ ‚áïŒìùëÄ ùëÜ1, ùëÜ2, ùëÜ3, as in Figure 6, (2).

(3) Combining based on (Elim Gen). Having rearranged the program into suitable sub-statements,

we use (Elim Gen) to get Program G-1 (Figure 6, (3)) and:
Œì‚Ä≤ = {ùë¶1,2,3 : (real, data), ùúô : (real, model),

ùúÉ1 : (real, genqant), ùúÉ0,2 : (real, model),
ùúô1 : (real, genqant), ùúô2,3 : (real, model),
ùëß1 : (int, genqant), ùëß2,3 : (int<2>, model),
ùúÉ3 : (real, genqant), ùëîùëíùëõùëß : (int<2>, genqant)}

Eliminating ùëß2. We apply the same procedure to eliminate the next variable, ùëß2, from the updated
Program G-1. The variable ùëß1 is no longer a model-level parameter, thus the only neighbouring
parameter of ùëß2 is ùëß3. Note also that the computation of the factor ùëì1 does not include any free
discrete parameters (both ùëß1 and ùëß2 are local to the computation due to elim and ùúô). Thus, we do
not need to include the computation of this factor anywhere else in the program (it does not get
nested into other computations). We obtain a new program, Program G-2:

Program G-2

phi ‚àº beta(1, 1);
theta ‚àº beta(1, 1);
theta0 = theta[0];

f1 = ùúô([int<2> z2]){ elim(int<2> z1){

z1 ‚àº bernoulli(theta0);
theta1 = theta[z1];
z2 ‚àº bernoulli(theta1);
phi1 = phi[z1];
y1 ‚àº normal(phi1, 1);

}}

f2 = ùúô([int<2> z3]){ elim(int<2> z2){

factor(f1[z2]);
theta2 = theta[z2];
z3 ‚àº bernoulli(theta2);
phi2 = phi[z2];

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

y2 ‚àº normal(phi2, 1);

}}

factor(f2[z3]);
phi3 = phi[z3];
y3 ‚àº normal(phi3, 1);

gen(int z2){

factor(f1[z2]);
theta2 = theta[z2];
z3 ‚àº bernoulli(theta2);
phi2 = phi[z2];
y2 ‚àº normal(phi2, 1);

}
theta2 = theta[z2];
phi2 = phi[z2];

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:30

34

35

36

37

38

39

gen(int z1){

z1 ‚àº bernoulli(theta0);
theta1 = theta[z1];
z2 ‚àº bernoulli(theta1);
phi1 = phi[z1];
y1 ‚àº normal(phi1, 1);

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

40

41

42

43

44

45

}
theta1 = theta[z1];
phi1 = phi[z1];

theta3 = theta0[z3];
.
genz ‚àº bernoulli(theta3);

Eliminating ùëß3. Finally, we eliminate ùëß3, which is the only discrete model-level parameter left in
the program. Thus, ùëß3 has no neighbours and ùëì3 is of arity 0: it is a real number instead of a vector.

The final program generated by our implementation is Program G-3:

Program G-3

phi0 ‚àº beta(1, 1);
theta0 ‚àº beta(1, 1);

f1 = ùúô(int<2> z2){ elim(int<2> z1){

z1 ‚àº bernoulli(theta0);
theta1 = theta[z1];
z2 ‚àº bernoulli(theta1);
phi1 = phi[z1];
y1 ‚àº normal(phi1, 1);

}}

f2 = ùúô(int<2> z3){elim(int<2> z2){

factor(f1[z2]);
theta2 = theta[z2];
z3 ‚àº bernoulli(theta2);
phi2 = phi[z2];
y2 ‚àº normal(phi2, 1);

}}

f3 = ùúô(){elim(int<2> z3){

factor(f2[z3]);
phi3 = phi[z3];
y3 ‚àº normal(phi3, 1);

}}

factor(f3);

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

gen(int z3){

factor(f2[z3]);
phi3 = phi[z3];;
y3 ‚àº normal(phi3, 1);

}
phi3 = phi[z3];
gen(int z2){

factor(f1[z2]);
theta2 = theta[z2];;
z3 ‚àº bernoulli(theta2);
phi2 = phi[z2];;
y2 ‚àº normal(phi2, 1);

}
theta2 = theta[z2];
phi2 = phi[z2];
gen(int z1){

z1 ‚àº bernoulli(theta0);
theta1 = theta[z1];
z2 ‚àº bernoulli(theta1);
phi1 = phi[z1];
y1 ‚àº normal(phi1, 1);

}
theta1 = theta[z1];
phi1 = phi[z1];

gen3 = theta[z3];
genz ‚àº bernoulli(theta3);

4.8 Relating to Variable Elimination and Complexity Analysis
Assume D, ùúΩ ùëë , and ùúΩ ùëê are the data, discrete model-level parameters, and continuous model-level
parameters, respectively. As ùëÜ2 is a single-level statement of level l2, the density semantics of ùëÜ2 is
of the form ùúì (xl1, xl2) = ùúì (D, ùúΩ ùëê, ùúΩ ùëë,l1, ùëß) (Lemma 11).

As elim(int‚ü®ùêæ‚ü©ùëß) _ binds the variable ùëß and ùúô (Œìne){_} binds the variables in dom(Œìne), the ex-
pression ùúô (Œìne){elim(int‚ü®ùêæ‚ü©ùëß) ùëÜ2 depends only on continuous parameters and data, and it contains
no free mentions of any discrete variables. This means that the expression will be of level l1 and

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:31

shredded into ùëÜ1 during the marginalisation of any subsequent discrete variable ùëß ‚Ä≤. The substate-
ment ùëÜ2 will always be some sub-statement of the original program (prior to any transformations),
up to potentially several constant factors of the form factor(ùëì [dom(Œìne)]).

This observation makes it easy to reason about how repeated application of the (Elim Gen)
transform changes the complexity of the program. If the complexity of a SlicStan program with ùëÅ
discrete parameters of support 1, . . . , ùêæ, is O (ùëÜ), then the complexity of a program where we naively
marginalised out the discrete variables (Program E) will be O (ùëÜ √ó ùêæ ùëÅ ). In contrast, transforming
with (Elim Gen) gives us a program of complexity at most O (ùëÅ √ó ùëÜ √ó ùêæ ùëÄ+1) where ùëÄ is the largest
number of direct neighbours in the factor graph induced by the program. Further, the complexity
could be smaller depending on the elimination ordering of choice. This result is not surprising, as
we conjecture that repeated application of (Elim Gen) is equivalent to variable elimination (though
we do not formally prove this equivalence), which is of the same complexity.

It is clear from this complexity observation that VE is not always efficient. When the dependency
graph is dense, ùëÄ will be close to ùëÅ , thus inference will be infeasible for large ùëÅ . Fortunately,
in many practical cases (such as those discussed in ¬ß 5), this graph is sparse (ùëÄ ‚â™ ùëÅ ) and our
approach is suitable and efficient. We note that this is a general limitation of exact inference of
discrete parameters, and it is not a limitation of our approach in particular.

4.9 Semantic Preservation of the Discrete Variable Transformation
The result we are interested in is the semantic preservation of the transformation rule

ùëß
‚àí‚Üí.

Theorem 4 (Semantic preservation of

ùëß
‚àí‚Üí).

For SlicStan programs Œì, ùëÜ and Œì‚Ä≤, ùëÜ ‚Ä≤, and a discrete parameter ùëß: Œì, ùëÜ

ùëß
‚àí‚Üí Œì‚Ä≤, ùëÜ ‚Ä≤ implies

=

ùëÜ
(cid:74)

(cid:75)

ùëÜ ‚Ä≤
(cid:74)

.
(cid:75)

Proof. Note that shredding preserves semantics with respect to both ‚ä¢ and ‚ä¢2 (Lemma 6 and
10), examine the meaning of derived forms (Lemma 14 and 15), note properties of single-level
statements (Lemma 11), and apply the results on factorisation of shredding (Theorem 1) and
‚ñ°
conditional independence (Theorem 3). We present the full proof in Appendix A.

In addition, we also show that it is always possible to find a program derivable with (Elim Gen),

such that a model-level variable ùëß is transformed to a genqant-level variable.

Lemma 12 (Existence of model to genqant transformation). For any SlicStan program
Œì, ùëÜ such that Œì ‚ä¢ ùëÜ : l1, and a variable ùëß ‚àà dom(Œì) such that Œì(ùëß) = (int‚ü®ùêæ‚ü©, model), there exists a
SlicStan program Œì‚Ä≤, ùëÜ ‚Ä≤, such that:

Œì, ùëÜ

ùëß
‚àí‚Üí Œì‚Ä≤, ùëÜ ‚Ä≤

and

Œì‚Ä≤(ùëß) = (int‚ü®ùêæ‚ü©, genquant)

Proof. By inspecting the level types of variables in each part of a program derivable using (Elim
‚ñ°

Gen). We include the full proof in Appendix A.

The practical usefulness of Theorem 4 stems from the fact that it allows us to separate inference
for discrete and continuous parameters. After applying (Elim Gen) to each discrete model-level
parameter, we are left with a program that only has genqant-level discrete parameters (Lemma 12).
We can then slice the program into ùëÜhmc and ùëÜgen and infer continuous parameters by using HMC
(or other algorithms) on ùëÜhmc and, next, draw the discrete parameters using ancestral sampling by
running forward ùëÜgen. Theorem 4 tells us that this is a correct inference strategy.

When used in the context of a model with only discrete parameters, our approach corresponds
to exact inference through VE. In the presence of discrete and continuous parameters, our transfor-
mation gives an analytical sub-solution for the discrete parameters in the model.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:32

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

A limitation of our method is that, due to its density-based nature, it can only be applied to models
of fixed size. It cannot, in its current form, support models where the number of random variables
changes during inference, such as Dirichlet Processes. However, this is a typical constraint adopted
in Bayesian inference for efficiency. Another limitation is that discrete variables need to have finite
(and fixed) support. For example, the method cannot be applied to transform a Poisson-distributed
variable. In some but not all applications, truncating unbounded discrete parameters at a realistic
upper bound would suffice to make the method applicable.

An advantage of our method is that it can be combined with any inference algorithm that
requires a function proportional to the joint density of variables. This includes gradient-based
algorithms, such as HMC and variational inference, but it can also be used with methods that allow
for (e.g. unbounded) discrete variables as an analytical sub-solution that can optimise inference. For
example, consider a Poisson variable ùëõ ‚àº Poisson(ùúÜ) and a Binomial variable ùëò ‚àº Binomial(ùëõ, ùëù).
While ùëõ is of infinite support, and we cannot directly sum over all of its possible values, analytically
marginalising out ùëõ gives us ùëò ‚àº Poisson(ùúÜùëù). Future work can utilise such analytical results in
place of explicit summation where possible.

4.10 Scope and limitations of (Elim Gen)

Program H

data int K;
real[K][K] phi;
real[K] mu;
int<K> z1 ‚àº

categorical(phi[0]);

int<K> z2;
int<K> z3;

if (z1 > K/2) {

z2 ‚àº categorical(phi[z1]);
z3 ‚àº categorical(phi[z2]);

}
else {

z2 ‚àº categorical(phi[z1]);
z3 ‚àº categorical(phi[z1]);

}

data real y1 ‚àº

normal(mu[z1],1);

data real y2 ‚àº

normal(mu[z2],1);

data real y3 ‚àº

normal(mu[z3],1);

Program H-A: Optimal
transformation
. . .

factor(elim(int<2> z1) {
z1 ‚àº categorical(phi[0]);
y1 ‚àº normal(mu[z1], 1));

if (z1 > K/2) {
elim(int<2> z2) {
elim(int<2> z3) {
z2 ‚àº categorical(phi[z1]);
z3 ‚àº categorical(phi[z2]);
y2 ‚àº normal(mu[z2],1);
y3 ‚àº normal(mu[z3],1);

}}}

else {
elim(int<2> z2) {
z2 ‚àº categorical(phi[z1]));
y2 ‚àº normal(mu[z2],1);
}
elim(int<2> z3) {
z3 ‚àº categorical(phi[z1]));
y3 ‚àº normal(mu[z3],1);

}}});

Program H-B: Our
transformation
. . .

f1 = ùúô(int<2> z2, int<2> z3){

elim(int<2> z1){
z1 ‚àº categorical(phi[0]);
if(z1 > K/2){

z2 ‚àº categorical(phi[z1]);
z3 ‚àº categorical(phi[z2]);

}
else{

z2 ‚àº categorical(phi[z1]);
z3 ‚àº categorical(phi[z1]);

}
y1 ‚àº normal(mu[z1], 1);
y2 ‚àº normal(mu[z2], 1);
y3 ‚àº normal(mu[z3], 1);

}}
f2 = ùúô(int<2> z3){
elim(int<2>z2)

factor(f1[z2,z3]);}

f3 = ùúô(){

elim(int<2> z3)

factor(f2[z3]);}

factor(f3);

Fig. 7. A program with different conditional dependencies depending on control flow.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:33

Previously, we discussed the scope of the conditional independence result of the paper (¬ß¬ß 3.3).
Similarly, here we demonstrate with an example, a situation where our approach of eliminating
variables one-by-one using (Elim Gen) is not optimal.

Consider the simple control-flow Program H below. In this example ùëß2 and ùëß3 are not conditionally
independent given ùëß1 = 1, but they are conditionally independent given ùëß1 > ùêæ/2. This indepen-
dence is also referred to as context-specific independence [Boutilier et al. 1996; Minka and Winn
2009]. We can use different elimination strategy depending on which if-branch of the program we
find ourselves. Program H-A demonstrates this: its complexity is O ( ùêæ
2ùêæ 3+ùêæ 2).
The typing relation ‚ä¢2 can only detect overall (in)dependencies, where sets of variables are
conditionally independent given some ùëã , regardless of what value ùëã takes. Thus, our static analysis
is not able to detect that ùëß2 ‚ä•‚ä• ùëß3 | ùëß1 = 0. This results in Program H-B, which has complexity
O (ùêæ 3 + ùêæ 2 + ùêæ): the same complexity as the optimal Program H-A, but with a bigger constant.

2 √ó2√óùêæ) = O ( 1

2 √óùêæ 2+ ùêæ

Even if we extend our approach to detect that ùëß2 and ùëß3 are independent in one branch, it is
unclear how to incorporate this new information. Our strategy is based on computing intermediate
factors that allow re-using already computed information: eliminating ùëß1 requires computing a new
factor ùëì1 that no longer depends on ùëß1. We represented ùëì1 with a multidimensional array indexed
by ùëß2 and ùëß3, and we need to define each element of that array, thus we cannot decouple them for
particular values of ùëß1.

Runtime systems that compute intermediate factors in a similar way, such as Pyro [Uber AI Labs
2017], face that same limitation. Birch [Murray and Sch√∂n 2018], on the other hand, will be able
to detect the conditional independence in the case ùëß1 > ùêæ/2, but it will not marginalise ùëß1, as it
cannot (analytically) marginalise over branches. Instead, it uses Sequential Monte Carlo (SMC) to
repeatedly sample ùëß1 and proceed according to its value.

5 IMPLEMENTATION AND EMPIRICAL EVALUATION
The transformation we introduce can be useful for variety of models, and it can be adapted to PPLs
to increase efficiency of inference and usability. Most notably, it can be used to extend Stan to allow
for direct treatment of discrete variables, where previously that was not possible.

In this section, we present a brief overview of such a discrete parameter extension for SlicStan
(¬ß¬ß 5.1). To evaluate the practicality of (Elim Gen), we build a partial NumPyro [Phan et al. 2019]
backend for SlicStan, and compare our static approach to variable elimination for discrete parameters
to the dynamic approach of NumPyro (¬ß¬ß 5.2). We find that our static transformation strategy speeds
up inference compared to the dynamic approach, but that for models with a large number of discrete
parameters performance gains could be diminished by the exponentially growing compilation time
(¬ß¬ß 5.3).

In addition to demonstrating the practicality of our contribution through empirical evaluation,

we also discuss the usefulness of our contribution through examples, in Appendix B.

5.1 Implementation
We update the original SlicStan14 according to the modification described in ¬ß 2, and extend it to
support automatic variable elimination through the scheme outlined in ¬ß 4. As with the first version
of SlicStan, the transformation produces a new SlicStan program that is then translated to Stan.

The variable elimination transformation procedure works by applying (Elim Gen) iteratively,
once for each discrete variable, as we show in ¬ß¬ß 4.7. The level types l1, l2 and l3 are not exposed to
the user, and are inferred automatically. Using bidirectional type-checking, we are able to synthesise
a set of hard constraints that the levels must satisfy. These hard constraints will typically be satisfied

14Available at https://github.com/mgorinova/SlicStan.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:34

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

by more than one assignment of variables to levels. We search for the optimal types with respect to
the soft constraints l3 ‚â∫ l1 ‚â∫ l2, using the theorem prover Z3 [De Moura and Bj√∏rner 2008].

5.2 Empirical evaluation
To evaluate the practicality of our approach, we compare to the prior work most closely related
to ours: that of Obermeyer et al. [2019], who implement efficient variable-elimination for plated
factor graphs in Pyro [Uber AI Labs 2017]. Their approach uses effect-handlers and dynamically
marginalises discrete variables, so that gradient-based inference schemes can be used for the
continuous parameters. This VE strategy has also been implemented in NumPyro [Phan et al. 2019].
As both ours and Pyro‚Äôs strategies correspond to VE, we do not expect to see differences in
complexity of the resulting programs. However, as in our case the VE algorithm is determined
and set up at compile time, while in the case of Pyro/NumPyro, this is done at run time. The main
question we aim to address is whether setting up the variable elimination logistics at compile time
results in a practical runtime speed-up.

To allow for this comparison, we built a partial NumPyro backend for SlicStan. For each model

we choose, we compare the runtime performance of three NumPyro programs:

(1) The NumPyro program obtained by translating a SlicStan program with discrete parameters to
NumPyro directly (labelled ‚ÄòNumPyro‚Äô). This is the baseline: we leave the discrete parameter
elimination to NumPyro.

(2) The NumPyro program obtained by translating a transformed SlicStan program, where all
discrete parameters have been eliminated according to (Elim Gen) (labelled ‚ÄòSlicStan‚Äô). The
variable elimination set-up is done at compile time; NumPyro does not do any marginalisation.
(3) A hand-optimised NumPyro program, which uses the plate and markov program constructs
to specify some of the conditional independencies in the program (labelled ‚ÄòNumPyro-Opt‚Äô).
In each case, we measure the time (in seconds) for sampling a single chain consisting of 2500

warm-up samples, and 10000 samples using NUTS [Hoffman and Gelman 2014].

In addition, we report three compilation times:
(1) The compilation time of the NumPyro program obtained by translating a SlicStan program

with discrete parameters to NumPyro directly (labelled ‚ÄòNumPyro‚Äô).

(2) The compilation time of the NumPyro program obtained by translating a transformed SlicStan

program, where all discrete parameters have been eliminated (labelled ‚ÄòSlicStan‚Äô).

(3) The time taken for the original SlicStan program to be transformed using (Elim Gen) and

translated to NumPyro code (labelled ‚ÄòSlicStan-to-NumPyro‚Äô).

We consider different numbers of discrete parameters for each model, up to 25 discrete parameters.
We do not consider more than 25 parameters due to constraints of the NumPyro baseline, which we
discuss in more detail in ¬ß¬ß 5.3. We run experiments on two classes of model often seen in practice:
hidden Markov models (¬ß¬ß¬ß 5.2.1) and mixture models (¬ß¬ß¬ß 5.2.2). To ensure a fair comparison,
the same elimination ordering was used across experiments. Experiments were run on a dual-core
2.30GHz Intel Xeon CPU and a Tesla T4 GPU (when applicable). All SlicStan models used in the
experiments are available at the SlicStan repo.

5.2.1 Hidden Markov models. We showed several examples of simple HMMs throughout the paper
(Program A, Program D, Program G) and worked through a complete example of VE in an HMM
(4.7). We evaluate our approach on both the simple first-order HMM seen previously, and on two
additional ones: second-order HMM and factorial HMM.

First-order HMM. The first-order HMM is a simple chain of ùëÅ discrete variables, each taking a
value from 1 to ùêæ according to a categorical distribution. The event probabilities for the distribution

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:35

of ùëßùëõ are given by ùúΩ ùëßùëõ‚àí1, where ùúΩ is some given ùêæ √ó ùêæ matrix. Each data point y is modelled
as coming from a Gaussian distribution with mean ùúáùëßùëõ and standard deviation 1, where ùùÅ is a
ùêæ‚àídimensional continuous parameter of the model.

ùúáùëò ‚àº N (0, 1)

for ùëò ‚àà 1, . . . , ùêæ

ùëß1 ‚àº categorical(ùúΩ 1)

ùëßùëõ ‚àº categorical(ùúΩ ùëßùëõ‚àí1)
ùë¶ùëõ ‚àº N (ùúáùëßùëõ, 1)

for ùëõ ‚àà 2, . . . , ùëÅ

for ùëõ ‚àà 1, . . . , ùëÅ

We measure the compilation time and the time taken to sample 1 chain with each of the 3
NumPyro programs corresponding to this model. We use ùêæ = 3 and different values for ùëÅ , ranging
from ùëÅ = 3 to ùëÅ = 25. Figure 8 shows a summary of the results. We see that both on CPU and
GPU, the program transformed using SlicStan outperforms the automatically generated NumPyro
and also the manually optimised NumPyro-Opt. Each of the three programs has compilation
time exponentially increasing with the number of variables, however SlicStan‚Äôs compilation time
increases the fastest. We discuss this drawback in more detail in ¬ß¬ß 5.3, highlighting the importance
of an extended loop-level analysis being considered in future work.

Second-order HMM. The second-order HMM is very similar to the first-order HMM, but the
discrete variables depend on the previous 2 variables, in this case taking the maximum of the two.

ùúáùëò ‚àº N (0, 1)
ùëß1 ‚àº categorical(ùúÉ1),

for ùëò ‚àà 1, . . . , ùêæ
ùëß2 ‚àº categorical(ùúÉùëß1)

ùëßùëõ ‚àº categorical(ùúÉmax(ùëßùëõ‚àí2,ùëßùëõ‚àí1) )
ùë¶ùëõ ‚àº N (ùúáùëßùëõ, 1)

for ùëõ ‚àà 1, . . . , ùëÅ

for ùëõ ‚àà 3, . . . , ùëÅ

Similarly to before, we run the experiment for ùêæ = 3 and different values for ùëÅ , ranging from
ùëÅ = 3 to ùëÅ = 25. We show the results in Figure 9, which once again shows SlicStan outperforming
NumPyro and NumPyro-Opt in terms of runtime, but having slower compilation time for a larger
number of discrete parameters.

Factorial HMM. In a factorial HMM, each data point ùë¶ùëõ is generated using two independent

hidden states ùëßùëõ and ‚Ñéùëõ, each depending on the previous hidden states ùëßùëõ‚àí1 and ‚Ñéùëõ‚àí1.

ùúáùëò ‚àº N (0, 1)

for ùëò ‚àà 1, . . . , ùêæ 2

ùëß1 ‚àº categorical(ùúÉ1),

‚Ñé1 ‚àº categorical(ùúÉ1)

ùëßùëõ ‚àº categorical(ùúÉùëßùëõ‚àí1),

‚Ñéùëõ ‚àº categorical(ùúÉ‚Ñéùëõ‚àí1)

for ùëõ ‚àà 2, . . . , ùëÅ

ùë¶ùëõ ‚àº N (ùúáùëßùëõ‚àó‚Ñéùëõ, 1)

for ùëõ ‚àà 1, . . . , ùëÅ

We run the experiment for ùêæ = 3 and different length of the chain ùëÅ , ranging from ùëÅ = 1 (2
discrete parameters) to ùëÅ = 12 (24 discrete parameters). We show the results in Figure 10: similarly
to before, SlicStan outperforms both NumPyro and NumPyro-Opt in terms of runtime. We also
observe that, in the case of SlicStan, the time taken to sample a single chain increases more slowly
as we increase the number of discrete variables.

5.2.2 Mixture models. Another useful application of mixed discrete and continuous variable models
is found in mixture models. We run experiments on two models: soft ùêæ-means clustering and linear
regression with outlier detection.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:36

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

Fig. 8. HMM results

Fig. 9. Second-order HMM results

Fig. 10. Factorial HMM results

Fig. 11. Soft K-means results

Fig. 12. Outliers results

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

510152025Number of discrete parameters18.519.019.520.020.521.021.522.022.5Time (sec) per chainFirst-order HMM: Runtime, CPUSlicStanNumPyroNumPyro-Opt510152025Number of discrete parameters14.014.515.015.516.016.5Time (sec) per chainFirst-order HMM: Runtime, GPUSlicStanNumPyroNumPyro-Opt35812151825Number of discrete parameters020406080100Compilation time (sec)First-order HMM: Compilation timesSlicStanNumPyroSlicStan-to-NumPyro510152025Number of discrete parameters181920212223242526Time (sec) per chainSecond-order HMM: Runtime, CPUSlicStanNumPyroNumPyro-Opt510152025Number of discrete parameters1415161718192021Time (sec) per chainSecond-order HMM: Runtime, GPUSlicStanNumPyroNumPyro-Opt35812151825Number of discrete parameters020406080100120Compilation time (sec)Second-order HMM: Compilation timesSlicStanNumPyroSlicStan-to-NumPyro510152025Number of discrete parameters20222426283032Time (sec) per chainFactorial HMM: Runtime, CPUSlicStanNumPyroNumPyro-Opt510152025Number of discrete parameters141618202224Time (sec) per chainFactorial HMM: Runtime, GPUSlicStanNumPyroNumPyro-Opt261014182224Number of discrete parameters0102030405060Compilation time (sec)Factorial HMM: Compilation timesSlicStanNumPyroSlicStan-to-NumPyro510152025Number of discrete parameters304050607080Time (sec) per chainSoft K-means: Runtime, CPUSlicStanNumPyroNumPyro-Opt510152025Number of discrete parameters20253035404550Time (sec) per chainSoft K-means: Runtime, GPUSlicStanNumPyroNumPyro-Opt35812151825Number of discrete parameters050100150200250300350400Compilation timeSoft K-means: Compilation timesSlicStanNumPyroSlicStan-to-NumPyro510152025Number of discrete parameters19202122232425Time (sec) per chainOutlier detection: Runtime, CPUSlicStanNumPyroNumPyro-Opt510152025Number of discrete parameters1415161718Time (sec) per chainOutlier detection: Runtime, GPUSlicStanNumPyroNumPyro-Opt35812151825Number of discrete parameters020406080Compilation time (sec)Outlier detection: Compilation timesSlicStanNumPyroSlicStan-to-NumPyroConditional independence by typing

1:37

Soft K-means. The Gaussian mixture model underlines the celebrated soft ùêæ-means algorithm.
Here, we are interested in modelling some ùê∑-dimensional data that belongs to one of ùêæ (unknown)
Gaussian clusters. Each cluster ùëò is specified by a ùê∑-dimensional mean ùúá.,ùëò . Each data point ùë¶.,ùëõ is
associated with a cluster ùëßùëõ.

ùúáùëë,ùëò ‚àº N (0, 1)

for ùëë ‚àà 1, . . . , ùê∑ and ùëò ‚àà 1, . . . , ùêæ

ùëßùëõ ‚àº categorical(ùúã)

for ùëõ ‚àà 1, . . . , ùëÅ
for ùëë ‚àà 1, . . . , ùê∑ and ùëõ ‚àà 1, . . . , ùëÅ

ùë¶ùëë,ùëõ ‚àº N (ùúáùëë,ùëßùëõ, 1)

We run the experiments for ùêæ = 3, ùê∑ = 10, and ùëÅ = 3, . . . , 25 and show the results in Figure 11.
We observe a clear linear trend of the runtime growing with N, with SlicStan performing better
and its runtime growing more slowly than that of NumPyro. While the SlicStan-translated code
runs faster than NumPyro-Opt for ùëÅ ‚â§ 25, we observe that the SlicStan runtime grows faster than
that of the manually optimised NumPyro-Opt code.

Outlier detection. The final model we consider is a Bayesian linear regression that allows for
outlier detection. The model considers data points (ùë•ùëõ, ùë¶ùëõ), where ùë¶ lies on the line ùõºùë• + ùõΩ with some
added noise. The noise ùúéùëßùëõ depends on a Bernoulli parameter ùëßùëõ, which corresponds to whether or
not the point (ùë•ùëõ, ùë¶ùëõ) is an outlier or not. The noise for outliers (ùúé1) and the noise for non-outliers
(ùúé2) are given as hyperparameters.

ùõº ‚àº N (0, 10),

ùõΩ ‚àº N (0, 10)

ùúã (ùëüùëéùë§)
1

‚àº N (0, 1),

ùúã (ùëüùëéùë§)
2

‚àº N (0, 1),

ùúã =

ùëßùëõ ‚àº bernoulli(ùúã)
ùë¶ùëõ ‚àº N (ùõºùë•ùëõ + ùõΩ, ùúéùëßùëõ )

exp ùúã (ùëüùëéùë§)
1
for ùëõ ‚àà 1, . . . , ùëÅ

for ùëõ ‚àà 1, . . . , ùëÅ

exp ùúã (ùëüùëéùë§)
1
+ exp ùúã (ùëüùëéùë§)
2

Similarly to the earlier HMM models, SlicStan has the smallest runtime per chain, but at the

expense of fast growing compile time (Figure 12).

5.3 Analysis and discussion
Our method can be applied to general models containing a fixed and known number of finite-
support discrete parameters, which significantly reduces the amount of manual effort that was
previously required for such models in languages like Stan [Damiano et al. 2018]. In addition, as
shown in Figures 8‚Äì12, SlicStan outperforms both the NumPyro baseline and the hand-optimised
NumPyro-Opt, in terms of runtime. This suggests that a static-time discrete variable optimisation,
like the one introduced in this paper, is indeed beneficial and speeds up inference.

One limitation of our experimental analysis is the relatively small number of discrete parameters
we consider. Due to the array dimension limit imposed by PyTorch / NumPy, Pyro cannot have
more than 25 discrete variables (64 for CPU) unless the dependence between them is specified
using markov or plate (as with NumPyro-Opt). For NumPyro this hardcoded limit is 32. Thus, it
would not be possible to compare to the NumPyro baseline for a larger number of variables, though
comparing to the hand-optimised NumPyro-Opt would still be possible.

Perhaps the biggest limitation of the discrete parameters version of SlicStan is the exponentially
growing compilation time. Using a semi-lattice instead of a lattice in the ‚ä¢2 level type analysis
breaks the requirement of the bidirectional type system that ensures efficiency of type inference.
The constraints generated by the type system can no longer be resolved by SlicStan‚Äôs original
linear-time algorithm. While polynomial-time constraint-solving strategy may still exist, we choose

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:38

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

to employ Z3 to automatically resolve the type inference constraints, and leave the consideration
for more efficient type inference algorithm for future work.

This also highlights the importance of a future SlicStan version that considers arrays of discrete
parameters. Our algorithm currently supports only individual discrete parameters. In the cases
where the size of an array of discrete parameters is statically known, the (Elim Gen) procedure
can be applied to a program where such arrays have been ‚Äòflattened‚Äô into a collection of individual
discrete variables, which is the strategy we adopt for the experiments in this section. But to be
applicable more widely, the (Elim Gen) rule needs to be generalised based on array element level
dependence analysis, for example by incorporating ideas from the polyhedral model [Feautrier
1992]. As the array level dependence analysis that would be required in most practical use-cases is
very straightforward, we believe this would be a useful and feasible applied extension of our work.
In addition, this would significantly decrease the number of program variables for which we need
to infer a level type during the (Elim Gen) transformation, thus making compilation practical for
larger or arbitrary numbers of discrete parameters.

6 RELATED WORK
This paper provides a type system that induces conditional independence relationships, and it
discusses one practical application of such type system: an automatic marginalisation procedure
for discrete parameters of finite support.

Conditional independence. The theoretical aim of our paper is similar to that of Barthe et al.
[2019], who discuss a separation logic for reasoning about independence, and the follow-up work
of Bao et al. [2021], who extend the logic to capture conditional independence. One advantage of
our method is that the verification of conditional independence is automated by type inference,
while it would rely on manual reasoning in the works of Barthe et al. [2019] and Bao et al. [2021].
On the other hand, the logic approach can be applied to a wider variety of verification tasks.
Amtoft and Banerjee [2020] show a correspondence between variable independence and slicing
a discrete-variables-only probabilistic program. The biggest difference to our work is that their
work considers only conditional independence of variables given the observed data: that is CI
relationships of the form x1 ‚ä•‚ä• x2 | D for some subsets of variables x1 and x2 and data D. The
language of Amtoft and Banerjee [2020] requires observed data to be specified syntactically using
an observe statement. Conditional independencies are determined only given this observed data,
and the method for determining how to slice a program is tied to the observe statements. From
the Amtoft and Banerjee [2020] paper: ‚ÄúA basic intuition behind our approach is that an observe
statement can be removed if it does not depend on something on which the returned variable ùë•
also depends.‚Äù In contrast, we are able to find CI relationships given any variables we are interested
in (x1 ‚ä•‚ä• x2 | x3 for some x1, x2, and x3), and type inference constitutes of a straightforward
algorithm for finding such relationships. On the other hand, Amtoft and Banerjee [2020] permit
unbounded number of variables (e.g. while (y > 0) y ‚àº bernoulli(0.2)), while it is not clear how
to extend SlicStan/Stan to support this. While not in a probabilist programming setting, Lobo-Vesga
et al. [2020] use taint analysis to find independencies between variables in a program, in order to
facilitate easy trade off between privacy and accuracy in differential privacy context.

Automatic marginalisation. The most closely related previous work, in terms of the automatic
marginalisation procedure, is that of Obermeyer et al. [2019] and that of Murray et al. [2018]. Ober-
meyer et al. [2019] implement efficient variable-elimination for plated factor graphs in Pyro [Uber
AI Labs 2017]. Their approach uses effect-handlers and can be implemented in other effect-handling
based PPLs, such as Edward2 [Tran et al. 2018]. Murray et al. [2018] introduce a ‚Äòdelayed sampling‚Äô
procedure in Birch [Murray and Sch√∂n 2018], which optimises the program via partial analytical

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:39

solutions to sub-programs. Their method corresponds to automatic variable elimination and, more
generally, automatic Rao‚ÄìBlackwellization. While we focus on discrete variable elimination only,
our conditional independence type system can be directly used for more general analysis. The
method from ¬ß 4 can be extended to marginalise out and sample continuous variables whenever
they are part of an analytically-tractable sub-program, similarly to delayed sampling in Birch.
One key difference of our approach is that the program re-writes are guided by the type system
and happen at compile time, before inference is run. In contrast, both Pyro and Birch maintain a
dynamic graph that guides the analysis at runtime.

Symbolic inference. Where a full analytical solution is possible, several probabilistic programming
languages can derive it via symbolic manipulation, including Hakaru [Narayanan et al. 2016] and PSI
[Gehr et al. 2016, 2020], while Dice [Holtzen et al. 2020] performs exact inference for models with
discrete parameters only, by analysing the program structure. In contrast, we focus on re-writing
the program, and decomposing it into parts to be used with fast and more general asymptotically
exact or approximate inference algorithms, like HMC, variational inference or others.

Extending HMC to support discrete parameters. The idea of modifying HMC to handle discrete
variables and discontinuities has been previously explored [Nishimura et al. 2017; Pakman and
Paninski 2013; Zhang et al. 2012; Zhou 2020]. More recently, Zhou et al. [2019] introduced the
probabilistic programming language LF-PPL, which is designed specifically to be used with the
Discontinuous Hamiltonian Monte Carlo (DHMC) algorithm [Nishimura et al. 2017]. The algorithm,
and their framework can also be extended to support discrete parameters. LF-PPL provides support
for an HMC version that itself works with discontinuities. Our approach is to statically rewrite the
program to match the constraints of Stan, vanilla HMC, and its several well-optimised extensions,
such as NUTS [Hoffman and Gelman 2014].

Composable and programmable inference. Recent years have seen a growing number of techniques
that allow for tailored-to-the-program compilation to an inference algorithm. For example, Gen
[Cusumano-Towner et al. 2019] can statically analyse the model structure to compile to a more
efficient inference strategy. In addition, languages like Gen and Turing [Ge et al. 2018] facilitate
composable and programmable inference [Mansinghka et al. 2018], where the user is provided with
inference building blocks to implement their own model-specific algorithm. Our method can be
understood as an automatic composition between two inference algorithms: variable elimination
and HMC or any other inference algorithm that can be used to sample continuous variables.

7 CONCLUSION
This paper introduces an information flow type system that can be used to check and infer condi-
tional independence relationships in a probabilistic programs, through type checking and inference,
respectively. We present a practical application of this type system: a semantics-preserving transfor-
mation that makes it possible to use, and to efficiently and automatically infer discrete parameters
in SlicStan, Stan, and other density-based probabilistic programming languages. The transformed
program can be seen as a hybrid inference algorithm on the original program, where continuous
parameters can be drawn using efficient gradient-based inference methods, like HMC, while the
discrete parameters are drawn using variable elimination.

While the variable elimination transformation uses results on conditional independence of
discrete parameters, our type system is not restricted to this usage. Conditional independence
relationships can be of interest in many context in probabilistic modelling, including more general
use of variable elimination, message-passing algorithms, Rao-Blackwellization, and factorising a

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:40

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

program for a composed-inference approach. We believe conditional independence by typing can
enable interesting future work that automates the implementation of such methods.

ACKNOWLEDGMENTS
We thank Vikash Mansinghka for suggesting the outlier detection example, which we used for
evaluation, as well as Lawrence Murry for clarifying the behaviour of Birch, and anonymous review-
ers whose helpful suggestions improved the paper. Maria Gorinova was supported by the EPSRC
Centre for Doctoral Training in Data Science, funded by the UK Engineering and Physical Sciences
Research Council (grant EP/L016427/1) and the University of Edinburgh. Matthijs V√°k√°r was funded
by the European Union‚Äôs Horizon 2020 research and innovation programme under the Marie
Sk≈Çodowska-Curie grant agreement No. 895827.

REFERENCES
Mart√≠n Abadi, Anindya Banerjee, Nevin Heintze, and Jon G. Riecke. 1999. A Core Calculus of Dependency. In POPL. ACM,

147‚Äì160.

Eyal Amir. 2010. Approximation algorithms for treewidth. Algorithmica 56, 4 (2010), 448‚Äì479.
Torben Amtoft and Anindya Banerjee. 2020. A Theory of Slicing for Imperative Probabilistic Programs. ACM Transactions

on Programming Languages and Systems (TOPLAS) 42, 2 (2020), 1‚Äì71.

Stefan Arnborg, Derek G Corneil, and Andrzej Proskurowski. 1987. Complexity of finding embeddings in a k-tree. SIAM

Journal on Algebraic Discrete Methods 8, 2 (1987), 277‚Äì284.

Jialu Bao, Simon Docherty, Justin Hsu, and Alexandra Silva. 2021. A Bunched Logic for Conditional Independence. In 2021

36th Annual ACM/IEEE Symposium on Logic in Computer Science (LICS). IEEE, 1‚Äì14.

Gilles Barthe, Justin Hsu, and Kevin Liao. 2019. A probabilistic separation logic. Proceedings of the ACM on Programming

Languages 4, POPL (2019), 1‚Äì30.

Michael Betancourt and Mark Girolami. 2015. Hamiltonian Monte Carlo for hierarchical models. Current trends in Bayesian

methodology with applications 79 (2015), 30.

Craig Boutilier, Nir Friedman, Moises Goldszmidt, and Daphne Koller. 1996. Context-Specific Independence in Bayesian
Networks. In Proceedings of the Twelfth International Conference on Uncertainty in Artificial Intelligence (UAI‚Äô96). 115‚Äì123.
Bob Carpenter, Andrew Gelman, Matthew Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker,
Jiqiang Guo, Peter Li, and Allen Riddell. 2017. Stan: A Probabilistic Programming Language. Journal of Statistical Software,
Articles 76, 1 (2017), 1‚Äì32. https://doi.org/10.18637/jss.v076.i01

Marco F. Cusumano-Towner, Feras A. Saad, Alexander K. Lew, and Vikash K. Mansinghka. 2019. Gen: A General-Purpose
Probabilistic Programming System with Programmable Inference. In Proceedings of the 40th ACM SIGPLAN Conference
on Programming Language Design and Implementation (Phoenix, AZ, USA) (PLDI 2019). Association for Computing
Machinery, New York, NY, USA, 221‚Äì236. https://doi.org/10.1145/3314221.3314642

Luis Damiano, Brian Peterson, and Michael Weylandt. 2018. A Tutorial on Hidden Markov Models using Stan. StanCon

(2018). https://doi.org/10.5281/zenodo.1284341.

Leonardo De Moura and Nikolaj Bj√∏rner. 2008. Z3: An efficient SMT solver. In International conference on Tools and

Algorithms for the Construction and Analysis of Systems (TACAS). Springer, 337‚Äì340.

Paul Feautrier. 1992. Some efficient solutions to the affine scheduling problem. Part II. Multidimensional time. International

journal of parallel programming 21, 6 (1992), 389‚Äì420.

Brendan J. Frey. 2002. Extending Factor Graphs so as to Unify Directed and Undirected Graphical Models. In Proceedings
of the Nineteenth Conference on Uncertainty in Artificial Intelligence (Acapulco, Mexico) (UAI‚Äô03). Morgan Kaufmann
Publishers Inc., San Francisco, CA, USA, 257‚Äì264.

Hong Ge, Kai Xu, and Zoubin Ghahramani. 2018. Turing: a language for flexible probabilistic inference. In International
Conference on Artificial Intelligence and Statistics (AISTATS). 1682‚Äì1690. http://proceedings.mlr.press/v84/ge18b.html
Timon Gehr, Sasa Misailovic, and Martin Vechev. 2016. PSI: Exact symbolic inference for probabilistic programs. In

International Conference on Computer Aided Verification. Springer, 62‚Äì83.

Timon Gehr, Samuel Steffen, and Martin Vechev. 2020. ùúÜPSI: Exact inference for higher-order probabilistic programs. In
Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation. 883‚Äì897.
Andrew Gelman, Daniel Lee, and Jiqiang Guo. 2015. Stan: A probabilistic programming language for Bayesian inference

and optimization. Journal of Educational and Behavioral Statistics 40, 5 (2015), 530‚Äì543.

Andrew D. Gordon, Claudio V. Russo, Marcin Szymczak, Johannes Borgstr√∂m, Nicolas Rolland, Thore Graepel, and Daniel
Tarlow. 2015. Probabilistic Programs as Spreadsheet Queries. In ESOP (Lecture Notes in Computer Science, Vol. 9032).
Springer, 1‚Äì25.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:41

Maria I Gorinova, Andrew D Gordon, and Charles Sutton. 2019. Probabilistic programming with densities in SlicStan:

efficient, flexible, and deterministic. Proceedings of the ACM on Programming Languages 3, POPL (2019), 35.

Andreas Griewank and Andrea Walther. 2008. Evaluating derivatives: principles and techniques of algorithmic differentiation.

SIAM.

Matthew D Hoffman and Andrew Gelman. 2014. The No-U-turn sampler: Adaptively setting path lengths in Hamiltonian

Monte Carlo. Journal of Machine Learning Research 15, 1 (2014), 1593‚Äì1623.

Steven Holtzen, Guy Van den Broeck, and Todd Millstein. 2020. Dice: Compiling Discrete Probabilistic Programs for Scalable

Inference. arXiv preprint arXiv:2005.09089 (2020).

Uffe Kj√¶rulff. 1990. Triangulation of graphs‚Äìalgorithms giving small total state space. (1990).
Daphne Koller and Nir Friedman. 2009. Probabilistic graphical models: principles and techniques. MIT press.
Elisabet Lobo-Vesga, Alejandro Russo, and Marco Gaboardi. 2020. A programming framework for differential privacy with

accuracy concentration bounds. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 411‚Äì428.

Vikash K. Mansinghka, Ulrich Schaechtle, Shivam Handa, Alexey Radul, Yutian Chen, and Martin Rinard. 2018. Probabilistic
Programming with Programmable Inference. In Proceedings of the 39th ACM SIGPLAN Conference on Programming
Language Design and Implementation (Philadelphia, PA, USA) (PLDI 2018). ACM, New York, NY, USA, 603‚Äì616. https:
//doi.org/10.1145/3192366.3192409

Tom Minka and John Winn. 2009. Gates. In Advances in Neural Information Processing Systems, D. Koller, D. Schuur-
mans, Y. Bengio, and L. Bottou (Eds.), Vol. 21. Curran Associates, Inc. https://proceedings.neurips.cc/paper/2008/file/
4b0a59ddf11c58e7446c9df0da541a84-Paper.pdf

T. Minka, J.M. Winn, J.P. Guiver, S. Webster, Y. Zaykov, B. Yangel, A. Spengler, and J. Bronskill. 2014. Infer.NET 2.6. Microsoft

Research Cambridge. http://research.microsoft.com/infernet.

Dave Moore and Maria I. Gorinova. 2018. Effect Handling for Composable Program Transformations in Edward2. International

Conference on Probabilistic Programming (2018). https://arxiv.org/abs/1811.06150

Kevin P Murphy. 2012. Machine learning: a probabilistic perspective. MIT press.
Lawrence M. Murray, Daniel Lund√©n, Jan Kudlicka, David Broman, and Thomas B. Sch√∂n. 2018. Delayed Sampling and
Automatic Rao-Blackwellization of Probabilistic Programs. Proceedings of Machine Learning Research, Twenty-First
International Conference on Artificial Intelligence and Statistics (AISTATS) 84 (2018), 1037‚Äì1046. http://proceedings.mlr.
press/v84/murray18a.html

Lawrence M Murray and Thomas B Sch√∂n. 2018. Automated learning with a probabilistic programming language: Birch.

Annual Reviews in Control 46 (2018), 29‚Äì43.

Praveen Narayanan, Jacques Carette, Wren Romano, Chung-chieh Shan, and Robert Zinkov. 2016. Probabilistic Inference by
Program Transformation in Hakaru (System Description). In Functional and Logic Programming, Oleg Kiselyov and Andy
King (Eds.). Springer International Publishing, Cham, 62‚Äì79.

Radford M Neal et al. 2011. MCMC using Hamiltonian dynamics. Handbook of Markov Chain Monte Carlo 2, 11 (2011).
Akihiko Nishimura, David Dunson, and Jianfeng Lu. 2017. Discontinuous Hamiltonian Monte Carlo for sampling discrete

parameters. arXiv preprint arXiv:1705.08510 (2017).

Fritz Obermeyer, Eli Bingham, Martin Jankowiak, Justin Chiu, Neeraj Pradhan, Alexander Rush, and Noah Goodman. 2019.

Tensor Variable Elimination for Plated Factor Graphs. International Conference on Machine Learning (2019).

A Pakman and L Paninski. 2013. Auxiliary-variable exact Hamiltonian Monte Carlo samplers for binary distributions.

Advances in Neural Information Processing Systems (2013).

Du Phan, Neeraj Pradhan, and Martin Jankowiak. 2019. Composable Effects for Flexible and Accelerated Probabilistic

Programming in NumPyro. arXiv preprint arXiv:1912.11554 (2019).

Benjamin C Pierce and David N Turner. 2000. Local type inference. ACM Transactions on Programming Languages and

Systems (TOPLAS) 22, 1 (2000), 1‚Äì44.

Lawrence R Rabiner. 1989. A tutorial on hidden Markov models and selected applications in speech recognition. Proc. IEEE

77, 2 (1989), 257‚Äì286.

John Salvatier, Thomas V Wiecki, and Christopher Fonnesbeck. 2016. Probabilistic programming in Python using PyMC3.

PeerJ Computer Science 2 (2016), e55.

Stan Development Team. 2019a. Stan language reference manual. Version 2.26.0. http://mc-stan.org.
Stan Development Team. 2019b. Stan user‚Äôs guide. Version 2.26.0. http://mc-stan.org.
Dustin Tran, Matthew D. Hoffman, Srinivas Vasudevan, Christopher Suter, Dave Moore, Alexey Radul, Matthew Johnson,
and Rif A. Saurous. 2018. Edward2: Simple, Distributed, Accelerated. (2018). https://github.com/tensorflow/probability/
tree/master/tensorflow_probability/python/edward2 Advances in Neural Information Processing Systems (NeurIPS).

Uber AI Labs. 2017. Pyro: A deep probabilistic programming language. http://pyro.ai/.
Dennis M. Volpano, Cynthia E. Irvine, and Geoffrey Smith. 1996. A Sound Type System for Secure Flow Analysis. J. Comput.

Secur. 4, 2/3 (1996), 167‚Äì188.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:42

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

John Winn. 2012. Causality with gates. In International Conference on Artificial Intelligence and Statistics (AISTATS). 1314‚Äì1322.

http://proceedings.mlr.press/v22/winn12.html

Frank Wood, Jan Willem van de Meent, and Vikash Mansinghka. 2014. A New Approach to Probabilistic Programming

Inference. In Proceedings of the 17th International conference on Artificial Intelligence and Statistics. 1024‚Äì1032.

Nevin Lianwen Zhang and David Poole. 1994. A simple approach to Bayesian network computations. In Proceedings of the
Biennial Conference-Canadian Society for Computational Studies of Intelligence. Canadian Information Processing Society,
171‚Äì178.

Yichuan Zhang, Zoubin Ghahramani, Amos J Storkey, and Charles A. Sutton. 2012. Continuous relaxations for discrete
Hamiltonian Monte Carlo. In Advances in Neural Information Processing Systems, F. Pereira, C. J. C. Burges, L. Bottou, and
K. Q. Weinberger (Eds.). Curran Associates, Inc., 3194‚Äì3202. http://papers.nips.cc/paper/4652-continuous-relaxations-
for-discrete-hamiltonian-monte-carlo.pdf

Guangyao Zhou. 2020. Mixed Hamiltonian Monte Carlo for Mixed Discrete and Continuous Variables. In Advances in Neural

Information Processing Systems (NeurIPS).

Yuan Zhou, Bradley J. Gram-Hansen, Tobias Kohn, Tom Rainforth, Hongseok Yang, and Frank Wood. 2019. LF-PPL: A
Low-Level First Order Probabilistic Programming Language for Non-Differentiable Models. In International Conference
on Artificial Intelligence and Statistics (AISTATS). http://proceedings.mlr.press/v89/zhou19b.html

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:43

A DEFINITIONS AND PROOFS

A.1 Definitions

Definition 10 (Assigns-to set ùëä (ùëÜ)). W(S) is the set that contains the names of global variables

that have been assigned to within the statement S. It is defined recursively as follows:
ùëä (ùë• [ùê∏1] . . . [ùê∏ùëõ] = ùê∏) = {ùë• }
ùëä (ùëÜ1; ùëÜ2) = ùëä (ùëÜ1) ‚à™ ùëä (ùëÜ2)
ùëä (if(ùê∏) ùëÜ1 else ùëÜ2) = ùëä (ùëÜ1) ‚à™ ùëä (ùëÜ2)
ùëä (for(ùë• in ùê∏1 : ùê∏2) ùëÜ) = ùëä (ùëÜ) \ {ùë• }

ùëä (skip) = ‚àÖ
ùëä (factor(ùê∏)) = ‚àÖ
ùëä (ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ)) = ‚àÖ

Definition 11 (Reads set ùëÖ(ùëÜ)). R(S) is the set that contains the names of global variables that

have been read within the statement S. It is defined recursively as follows:
ùëÖ(ùë•) = {ùë• }
ùëÖ(ùëê) = ‚àÖ
ùëÖ( [ùê∏1, . . . , ùê∏ùëõ]) = (cid:208)ùëõ
ùëñ=1 ùëÖ(ùê∏ùëñ )
ùëÖ(ùê∏1 [ùê∏2]) = ùëÖ(ùê∏1) ‚à™ ùëÖ(ùê∏2)
ùëÖ(ùëì (ùê∏1, . . . , ùê∏ùëõ)) = (cid:208)ùëõ
ùëÖ( [ùê∏|ùë• in ùê∏1 : ùê∏2]) = ùëÖ(ùê∏) ‚à™ ùëÖ(ùê∏1) ‚à™ ùëÖ(ùê∏2)
ùëÖ(target(ùëÜ)) = ùëÖ(ùëÜ)
ùëÖ(ùë• [ùê∏1] . . . [ùê∏ùëõ] = ùê∏) = (cid:208)ùëõ

ùëÖ(ùëÜ1; ùëÜ2) = ùëÖ(ùëÜ1) ‚à™ ùëÖ(ùëÜ2)
ùëÖ(if(ùê∏) ùëÜ1 else ùëÜ2) = ùëÖ(ùê∏) ‚à™ ùëÖ(ùëÜ1) ‚à™ ùëÖ(ùëÜ2)
ùëÖ(for(ùë• in ùê∏1 : ùê∏2) ùëÜ) = ùëÖ(ùê∏1) ‚à™ ùëÖ(ùê∏2) ‚à™ ùëÖ(ùëÜ) \
{ùë• }
ùëÖ(skip) = ‚àÖ
ùëÖ(factor(ùê∏)) = ùëÖ(ùê∏)
ùëÖ(ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ)) = ùëÖ(ùêø) ‚à™ ùëÖ(ùê∏1) ‚à™ ¬∑ ¬∑ ¬∑ ‚à™
ùëÖ(ùê∏ùëõ)

ùëñ=1 ùëÖ(ùê∏ùëñ )

ùëñ=1 ùëÖ(ùê∏ùëñ ) ‚à™ ùëÖ(ùê∏)

Definition 12 (Samples-to set (cid:101)ùëä (ùëÜ)). (cid:101)ùëä (ùëÜ) is the set that contains the names of global variables

that have been sampled within the statement S. It is defined recursively as follows:
(cid:101)ùëä (ùêø = ùê∏) = ‚àÖ
(cid:101)ùëä (ùëÜ1; ùëÜ2) = (cid:101)ùëä (ùëÜ1) ‚à™ (cid:101)ùëä (ùëÜ2)
(cid:101)ùëä (if(ùê∏) ùëÜ1 else ùëÜ2) = (cid:101)ùëä (ùëÜ1) ‚à™ (cid:101)ùëä (ùëÜ2)
(cid:101)ùëä (for(ùë• in ùê∏1 : ùê∏2) ùëÜ) = (cid:101)ùëä (ùëÜ) \ {ùë• }

(cid:101)ùëä (skip) = ‚àÖ
(cid:101)ùëä (factor(ùê∏)) = ‚àÖ
(cid:101)ùëä (ùë• [ùê∏1] . . . [ùê∏ùëõ] ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ)) = {ùë• }

Definition 13 (Free variables ùêπùëâ (ùëÜ)). ùêπùëâ (ùëÜ) is the set that contains the free variables that are

used in a statement ùëÜ. It is recursively defined as follows:

ùêπùëâ (ùë•) = {ùë• }
ùêπùëâ (ùëê) = ‚àÖ
ùêπùëâ ( [ùê∏1, . . . , ùê∏ùëõ]) = (cid:208)ùëõ
ùëñ=1 ùêπùëâ (ùê∏ùëñ )
ùêπùëâ (ùê∏1 [ùê∏2]) = ùêπùëâ (ùê∏1) ‚à™ ùêπùëâ (ùê∏2)
ùêπùëâ (ùëì (ùê∏1, . . . , ùê∏ùëõ)) = (cid:208)ùëõ
ùëñ=1 ùêπùëâ (ùê∏ùëñ )
ùêπùëâ ( [ùê∏|ùë• in ùê∏1 : ùê∏2]) = ùêπùëâ (ùê∏) ‚à™ ùêπùëâ (ùê∏1) ‚à™
ùêπùëâ (ùê∏2)
ùêπùëâ (target(ùëÜ)) = ùêπùëâ (ùëÜ)
ùêπùëâ (ùë• [ùê∏1] . . . [ùê∏ùëõ] = ùê∏) = (cid:208)ùëõ

ùëñ=1 ùêπùëâ (ùê∏ùëñ ) ‚à™ ùêπùëâ (ùê∏)

ùêπùëâ (ùëÜ1; ùëÜ2) = ùêπùëâ (ùëÜ1) ‚à™ ùêπùëâ (ùëÜ2)
ùêπùëâ (if(ùê∏) ùëÜ1 else ùëÜ2) = ùêπùëâ (ùê∏)‚à™ùêπùëâ (ùëÜ1)‚à™ùêπùëâ (ùëÜ2)
ùêπùëâ (for(ùë• in ùê∏1 : ùê∏2) ùëÜ) = ùêπùëâ (ùê∏1) ‚à™ ùêπùëâ (ùê∏2) ‚à™
ùêπùëâ (ùëÜ) \ {ùë• }
ùêπùëâ (skip) = ‚àÖ
ùêπùëâ (factor(ùê∏)) = ùêπùëâ (ùê∏)
ùêπùëâ (ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ)) = ùêπùëâ (ùêø) ‚à™ùêπùëâ (ùê∏1) ‚à™¬∑ ¬∑ ¬∑‚à™
ùêπùëâ (ùê∏ùëõ)

Definition 14. We overload the notation Œì(ùêø) that looks up the type of an L-value in Œì. When

applied to a more general expression ùê∏, Œì(ùê∏) looks up the type level of ùê∏ in Œì:

Œì(ùë•) = ‚Ñì, where ‚Ñì is the level of ùë• in Œì
Œì(ùëê) = data
Œì( [ùê∏1, . . . , ùê∏ùëõ]) = (cid:195)ùëõ

ùëñ=1 Œì(ùê∏ùëñ )

Œì(ùê∏1 [ùê∏2]) = Œì(ùê∏1) ‚äî Œì(ùê∏2)
Œì(ùëì (ùê∏1, . . . , ùê∏ùëõ)) = (cid:195)ùëõ
Œì([ùê∏|ùë• in ùê∏1 : ùê∏2]) = Œì(ùê∏) ‚äî Œì(ùê∏1) ‚äî Œì(ùê∏2)

ùëñ=1 Œì(ùê∏ùëñ )

Definition 15. Œì(ùê∏1, . . . , ùê∏ùëõ) ‚â° Œì(ùê∏1) ‚äî ¬∑ ¬∑ ¬∑ ‚äî Œì(ùê∏ùëõ).

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:44

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

Definition 16 (ùëÖŒì‚ä¢‚Ñì (ùëÜ)). ùëÖŒì‚ä¢‚Ñì (ùëÜ) is the set that contains the names of global variables that have

been read at level ‚Ñì within the statement ùëÜ. It is defined recursively as follows:
Œì(ùë•) = (_, ‚Ñì)
ùëñ=1 ùëÖ(ùê∏ùëñ ) ‚à™ ùëÖ(ùê∏)

(cid:26) (cid:208)ùëõ
‚àÖ

if
otherwise

ùëÖŒì‚ä¢‚Ñì (ùë• [ùê∏1] . . . [ùê∏ùëõ] = ùê∏) =
ùëÖŒì‚ä¢‚Ñì (ùëÜ1; ùëÜ2) = ùëÖŒì‚ä¢‚Ñì (ùëÜ1) ‚à™ ùëÖŒì‚ä¢‚Ñì (ùëÜ2)
ùëÖŒì‚ä¢‚Ñì (if(ùê∏) ùëÜ1 else ùëÜ2) = ùëÖŒì‚ä¢‚Ñì (ùê∏) ‚à™ ùëÖŒì‚ä¢‚Ñì (ùëÜ1) ‚à™ ùëÖŒì‚ä¢‚Ñì (ùëÜ2)
ùëÖŒì‚ä¢‚Ñì (for(ùë• in ùê∏1 : ùê∏2) ùëÜ) = ùëÖŒì‚ä¢‚Ñì (ùê∏1) ‚à™ ùëÖŒì‚ä¢‚Ñì (ùê∏2) ‚à™ ùëÖŒì‚ä¢‚Ñì (ùëÜ) \ {ùë• }
ùëÖŒì‚ä¢‚Ñì (skip) = ‚àÖ
ùëÖŒì‚ä¢‚Ñì (factor(ùê∏)) =

‚Ñì = model

(cid:26) ùëÖ(ùê∏)
‚àÖ

if
else
ùëÖ(ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ))

ùëÖŒì‚ä¢‚Ñì (ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ)) =

‚àÉùúè .Œì(ùë•) = (ùúè, ‚Ñì ‚Ä≤)}

‚àÖ

otherwise.

Ô£±Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥
Ô£≥

if

‚Ñì = (cid:195){‚Ñì ‚Ä≤ | ‚àÉùë• ‚àà ùêπùëâ (ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ)

Definition 17 (ùëäŒì‚ä¢‚Ñì (ùëÜ)). ùëäŒì‚ä¢‚Ñì (ùëÜ) ‚âú {ùë• ‚àà ùëä (ùëÜ) | Œì(ùë•) = (ùúè, ‚Ñì) for some ùúè }
Definition 18 ( (cid:101)ùëäŒì‚ä¢‚Ñì (ùëÜ)). (cid:101)ùëäŒì‚ä¢‚Ñì (ùëÜ) ‚âú {ùë• ‚àà (cid:101)ùëä (ùëÜ) | Œì(ùë•) = (ùúè, ‚Ñì) for some ùúè }
Definition 19. Given a statement ùëÜ, we define the statement st(ùëÜ) by structural induction on ùëÜ:
st(ùë• [ùê∏1] . . . [ùê∏ùëõ] = ùê∏) = ùë• [ùê∏1] . . . [ùê∏ùëõ] = ùê∏
st(ùëÜ1; ùëÜ2) = st(ùëÜ1); st(ùëÜ2)
st(if(ùê∏) ùëÜ1 else ùëÜ2) = if(ùê∏) st(ùëÜ1) else st(ùëÜ2))
st(for(ùë• in ùê∏1 : ùê∏2) ùëÜ) = for(ùë• in ùê∏1 : ùê∏2) st(ùëÜ)
st(skip) = skip
st(factor(ùê∏)) = skip
st(ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ)) = skip
Definition 20 (Neighbours of ùëß, ne(Œì, Œì‚Ä≤, ùëß)).

For a ‚ä¢ typing environment Œì, a ‚ä¢2 typing environment Œì‚Ä≤ = Œì‚Ä≤
neighbours of ùëß are defined as:

ùúé, Œì‚Ä≤
x

and a variable ùëß ‚àà dom(Œì‚Ä≤

x), the

ne(Œì, Œì‚Ä≤, ùëß) ‚âú {ùë• : (ùúè, ‚Ñì) ‚àà Œì‚Ä≤

x | ‚Ñì = l1 and Œì(ùë•) = (int‚ü®ùêæ‚ü©, model) for some ùêæ }

A.2 Proofs
Restatement of Lemma 1 (Noninterference of ‚ä¢)
some ‚Ñì. Then for SlicStan statement ùëÜ and expression ùê∏:

Suppose ùë†1 |= Œì, ùë†2 |= Œì, and ùë†1 ‚âà‚Ñì ùë†2 for

(1) If Œì ‚ä¢ ùê∏ : (ùúè, ‚Ñì) and (ùë†1, ùê∏) ‚áì ùëâ1 and (ùë†2, ùê∏) ‚áì ùëâ2 then ùëâ1 = ùëâ2.
(2) If Œì ‚ä¢ ùëÜ : ‚Ñì and (ùë†1, ùëÜ) ‚áì ùë† ‚Ä≤
2.
1 ‚âà‚Ñì ùë† ‚Ä≤

1, ùë§1 and (ùë†2, ùëÜ) ‚áì ùë† ‚Ä≤

2, ùë§2 then ùë† ‚Ä≤

Proof. (1) follows by rule induction on the derivation Œì ‚ä¢ ùê∏ : (ùúè, ‚Ñì), and using that if Œì ‚ä¢ ùê∏ : (ùúè, ‚Ñì),
ùë• ‚àà ùëÖ(ùê∏) and Œì(ùë•) = (ùúè ‚Ä≤, ‚Ñì ‚Ä≤), then ‚Ñì ‚Ä≤ ‚â§ ‚Ñì. (2) follows by rule induction on the derivation Œì ‚ä¢ ùëÜ : ‚Ñì
and using (1).

Most cases follow trivially from the inductive hypothesis. An exception is the (Target) case,

which we show below.

(Target)

1, ùë§1, and ùë†2, ùëÜ ‚áì ùë† ‚Ä≤

We use the premise ‚àÄ‚Ñì ‚Ä≤ > ‚Ñì.ùëÖŒì‚ä¢‚Ñì‚Ä≤ (ùëÜ) = ‚àÖ, together with a lemma that for ùëÜ, ùë†1 and ùë†2
such that ùë†1, ùëÜ ‚áì ùë† ‚Ä≤
2, ùë§2, and ‚àÄùë• ‚àà ùëÖ(ùëÜ).ùë†1(ùë•) = ùë†2(ùë•), we have that
ùë§1 = ùë§2. (This lemma follows by structural induction on ùëÜ.) In the case of (Target),
ùë†1, target(ùëÜ) ‚áì ùë§1, and ùë†2, target(ùëÜ) ‚áì ùë§2 and ùëÖ(ùëÜ) = (cid:208)‚Ñì‚Ä≤ ùëÖŒì‚ä¢‚Ñì‚Ä≤ (ùëÜ) = (cid:0)(cid:208)‚Ñì‚Ä≤ ‚â§‚Ñì ùëÖŒì‚ä¢‚Ñì‚Ä≤ (ùëÜ)(cid:1) ‚à™
((cid:208)‚Ñì‚Ä≤>‚Ñì ùëÖŒì‚ä¢‚Ñì‚Ä≤ (ùëÜ)) = (cid:208)‚Ñì‚Ä≤ ‚â§‚Ñì ùëÖŒì‚ä¢‚Ñì‚Ä≤ (ùëÜ). Then, for any ùë• ‚àà ùëÖ(ùëÜ), ùë• ‚àà ùëÖŒì‚ä¢‚Ñì‚Ä≤ (ùëÜ) for some ‚Ñì ‚Ä≤ ‚â§ ‚Ñì
, so Œì(ùë•) = (ùúè, ‚Ñìùë• ) such that ‚Ñìùë• ‚â§ ‚Ñì ‚Ä≤ ‚â§ ‚Ñì. And thus, by definition of ‚âà‚Ñì , ùë†1(ùë•) = ùë†2(ùë•)
for any ùë• ‚àà ùëÖ(ùëÜ). By applying the lemma above, we then get ùë§1 = ùë§2, as required.

‚ñ°

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

Restatement of Lemma 4 (Shredding produces single-level statements)

ùëÜ ‚áïŒì (ùëÜùê∑ , ùëÜùëÄ, ùëÜùëÑ ) =‚áí Œì ‚ä¢ data(ùëÜùê∑ ) ‚àß Œì ‚ä¢ model(ùëÜùëÄ ) ‚àß Œì ‚ä¢ genquant(ùëÜùëÑ )

Proof. By rule induction on the derivation of ùëÜ ‚áïŒì ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ .

1:45

‚ñ°

Restatement of Lemma 5 (Property of single-level statements)
Let Œìùúé, Œìx ‚ä¢ ùëÜ be SlicStan program, such that ùëÜ is single-level statement of level ‚Ñì, Œì ‚ä¢ ‚Ñì (ùëÜ). Then there
exist unique functions ùëì and ùúô, such that for any ùúé, x |= Œìùúé, Œìx:

(ùúé)(ùë•) = ùëì (ùúé ‚â§‚Ñì, x‚â§‚Ñì ) ‚à™ ùúé>‚Ñì, ùúô (ùúé ‚â§‚Ñì )(x‚â§‚Ñì ),
where we write ùúé ‚â§‚Ñì = {(ùë• ‚Ü¶‚Üí ùëâ ) ‚àà ùúé | Œìùúé (ùë•) = (_, ‚Ñì)} and ùúé>‚Ñì = ùúé \ ùúé ‚â§‚Ñì .

ùëÜ
(cid:74)

(cid:75)

Proof. This property follows from noninterference (Lemma 1), if we understand factor and
sample statements as assignments to a reserved weight variables of different levels. Let Œì, ùëÜ be a
SlicStan program and suppose we obtain ùëÜ ‚Ä≤ by:

‚Ä¢ Substituting every factor(ùê∏) statement with ùë§‚Ñì = ùë§‚Ñì ‚àó ùê∏, where Œì(ùê∏) = real, ‚Ñì and ùë§data,
ùë§model and ùë§qenqant are write-only, distinct and reserved variables in the program.
‚Ä¢ Substituting every ùêø ‚àº ùëë (ùê∏1, . . . , ùê∏ùëõ) statement with ùë§‚Ñì = ùë§‚Ñì ‚àó ùëëpdf (ùêø | ùê∏1, . . . , ùê∏ùëõ), where

Œì(ùëëpdf (ùêø | ùê∏1, . . . , ùê∏ùëõ)) = real, ‚Ñì.

Then for all ùúé, x |= Œì, we have

ùëÜ
(cid:74)
non-interference (Lemma 1), for any level ‚Ñì and store ùúé2 ‚âà‚Ñì ùúé, if ùúé ‚Ä≤
2 ‚âà‚Ñì ùúé ‚Ä≤. Thus ùúé ‚Ä≤
ùúé ‚Ä≤
‚Ñì,
and ùúô. Finally, this gives us

ùëù (ùúé)(x) = (cid:206)‚Ñì ùúé ‚Ä≤(ùë§‚Ñì ), where ùúé ‚Ä≤ =
ùë† (ùúé, ‚àÄ‚Ñì.ùë§‚Ñì ‚Ü¶‚Üí 1)(x). By
ùëÜ ‚Ä≤
(cid:74)
(cid:75)
(cid:75)
ùë† (ùúé2, ‚àÄ‚Ñì.ùë§‚Ñì ‚Ü¶‚Üí 1)(x), then
ùëÜ ‚Ä≤
(cid:75)
(cid:74)
2(ùë§‚Ñì‚Ä≤) = ùúé2(ùë§‚Ñì‚Ä≤) for ‚Ñì ‚Ä≤ ‚â§ ‚Ñì, and therefore, when ùëÜ is a single-level statement of level
ùë† (ùúé, ‚àÄ‚Ñì.ùë§‚Ñì ‚Ü¶‚Üí 1)(x) = ùëì (ùúé ‚â§‚Ñì, x‚â§‚Ñì ), ùúé>‚Ñì, ùë§ ‚â§‚Ñì ‚Ü¶‚Üí ùúô (ùúé ‚â§‚Ñì, x‚â§‚Ñì ), ùë§>‚Ñì ‚Ü¶‚Üí 1 , for some functions ùëì
(cid:75)
‚ñ°

ùëÜ ‚Ä≤
(cid:74)

2 =

ùëù (ùúé, x) = ùúô (ùúé ‚â§‚Ñì, x‚â§‚Ñì ).
(cid:75)

ùë† (ùúé, x) = (ùëì (ùúé ‚â§‚Ñì, x‚â§‚Ñì ), ùúé>‚Ñì ),
ùëÜ
(cid:74)
(cid:75)
Restatement of Lemma 6 (Semantic Preservation of ‚áïŒì)
If Œì ‚ä¢ ùëÜ : data and ùëÜ ‚áïŒì (ùëÜùê∑ , ùëÜùëÄ, ùëÜùëÑ ) then
ùëÜùê∑ ; ùëÜùëÄ ; ùëÜùëÑ
(cid:74)

ùëÜ
(cid:74)

ùëÜ
(cid:74)

=

(cid:75)

(cid:75)

.

Proof. Follows by adapting proof from [Gorinova et al. 2019].

Restatement of Lemma 10 (Semantic Preservation of ‚áïŒì 2)
If Œì ‚ä¢2 ùëÜ : l1 and ùëÜ ‚áïŒì ùëÜ1, ùëÜ2, ùëÜ3 then

.

=

ùëÜ
(cid:74)

(cid:75)

ùëÜ1; ùëÜ2; ùëÜ3
(cid:74)

(cid:75)

Proof. Follows by adapting proof from [Gorinova et al. 2019].

‚ñ°

‚ñ°

Lemma 13. For a SlicStan expression ùê∏ and a function ùúô (ùë•, ùë¶) = ùëâ , where ùëâ is a value such that

(ùúé, ùë•, ùë¶), ùê∏ ‚áì ùëâ for every ùë• and ùë¶ and some ùúé, if ùë• ‚àâ ùëÖ(ùê∏), then:

‚àÉùúô ‚Ä≤ such that ùúô (ùë•, ùë¶) = ùúô ‚Ä≤(ùë¶) for all ùë•, ùë¶

Proof. By induction on the structure of ùê∏.

‚ñ°

Restatement of Theorem 1 (Shredding induces a factorisation of the density).
Suppose Œì ‚ä¢ ùëÜ : data and ùëÜ ‚áïŒì ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ and Œì = Œìùúé ‚à™ ŒìD ‚à™ ŒìùúΩ ‚à™ ŒìùëÑ . For all ùúé, D, ùúΩ , and ùëÑ: if
ùúé, D, ùúΩ, ùëÑ |= Œìùúé, ŒìD, ŒìùúΩ , ŒìùëÑ , and

ùëù (ùúé)(D, ùúΩ, ùëÑ) ‚àù ùëù (D, ùúΩ, ùëÑ) and (cid:101)ùëä (ùëÜùëÑ ) = dom(ŒìùëÑ ) then:
(cid:75)

ùëÜ
(cid:74)

(1)
(2)

ùëù (ùúéùê∑ )(D, ùúΩ, ùëÑ) ‚àù ùëù (ùúΩ, D)
ùëÜùëÄ
(cid:75)
(cid:74)
ùëù (ùúéùëÄ )(D, ùúΩ, ùëÑ) = ùëù (ùëÑ | ùúΩ, D)
ùëÜùëÑ
(cid:75)
(cid:74)
ùë† (ùúé)(D, ùúΩ, ùëÑ) and ùúéùëÄ =
where ùúéùê∑ =
(cid:75)

ùëÜùê∑
(cid:74)

ùë† (ùúéùê∑ )(D, ùúΩ, ùëÑ).
(cid:75)
Proof. We prove this by establishing a more general result:
For ùúé, D, ùúΩ, ùëÑ |= Œìùúé, ŒìD, ŒìùúΩ , ŒìùëÑ , ùê¥ = (cid:101)ùëä (ùëÜùëÑ ) ‚äÜ ùëÑ and some ùêµ ‚äÜ ùëÑ \ ùê¥, if

ùëÜùëÄ
(cid:74)

ùëù (D, ùúΩ, ùê¥ | ùêµ) then:

ùëÜ
(cid:74)

ùëù (ùúé)(D, ùúΩ, ùëÑ) ‚àù
(cid:75)

(1)

ùëÜùê∑
(cid:74)

ùëù (ùúé)(D, ùúΩ, ùëÑ) = 1
(cid:75)

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:46

(2)
(3)

ùëÜùëÄ
(cid:74)
ùëÜùëÑ
(cid:74)

ùëù (ùúéùê∑ )(D, ùúΩ, ùëÑ) = ùëù (ùúΩ, D)
(cid:75)
ùëù (ùúéùëÄ )(D, ùúΩ, ùëÑ) = ùëù (ùê¥ | ùúΩ, D, ùêµ)
(cid:75)

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

Note that in the case where (cid:101)ùëä (ùëÜùëÑ ) = ùëÑ, we have ùê¥ = ùëÑ and ùêµ = ‚àÖ, and the original statement

of the theorem,

ùëÜùëÑ
(cid:74)
Lemma 4 and Lemma 5, Lemma 6.

ùëù (ùúéùëÄ )(D, ùúΩ, ùëÑ) = ùëù (ùëÑ | ùúΩ, D), holds.
(cid:75)

We prove the extended formulation above by induction on the structure of ùëÜ and use of Lemma 2,

Take any ùúé, D, ùúΩ, ùëÑ |= Œìùúé, ŒìD, ŒìùúΩ , ŒìùëÑ and let

Œ¶(ùëÜ, ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ ) ‚âú

Œì ‚ä¢ ùëÜ : data ‚àß ùëÜ ‚áïŒì ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ ‚àß ùê¥ = (cid:101)ùëä (ùëÜùëÑ )
=‚áí ‚àÉùêµ ‚äÜ ùëÑ \ ùê¥.‚àÄùúéùê∑, ùúéùëÄ . (

ùëÜ
(cid:74)

ùëù (ùúé)(D, ùúΩ, ùëÑ) ‚àù ùëù (D, ùúΩ, ùê¥ | ùêµ) ‚àß
ùëÜùê∑
(cid:75)
(cid:74)
ùëù (ùúé)(D) = 1
ùëÜùê∑
(cid:75)
(cid:74)
ùëù (ùúéùê∑ )(D, ùúΩ ) = ùëù (ùúΩ, D)
ùëÜùëÄ
(cid:75)
(cid:74)

=‚áí
‚àß
‚àß ‚àÉùêµ ‚äÜ ùëÑ \ (cid:101)ùëä (ùëÜùëÑ ).

(cid:75)

(ùúé)(D, ùúΩ, ùëÑ) = ùúéùê∑ ‚àß

(ùúéùê∑ )(D, ùúΩ, ùëÑ) = ùúéùëÄ

ùëÜùëÄ
(cid:74)

(cid:75)

ùëÜùëÑ
(cid:74)

ùëù (ùúéùëÄ )(D, ùúÉ, ùëÑ) = ùëù (ùê¥ | ùúΩ, D, ùêµ)
(cid:75)

(cid:17)

Take any Œì, ùëÜ, ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ such that ùëÜ ‚áïŒì ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ , ùê¥ = (cid:101)ùëä (ùëÜùëÑ ), and take any ùúé, D, ùúΩ, ùëÑ |=
ùëù (ùúé)(D, ùúΩ, ùëÑ) ‚àù ùëù (D, ùúΩ, ùê¥ | ùêµ).
(cid:75)

Œìùúé, ŒìD, ŒìùúΩ , ŒìùëÑ , an unnormalised density ùëù and ùêµ ‚äÜ ùëÑ\ùê¥, such that
We prove by rule induction on the derivation of ùëÜ ‚áïŒì ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ that Œ¶(ùëÜ, ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ ).

ùëÜ
(cid:74)

(Shred Seq)

Let ùëÜ = ùëÜ1; ùëÜ2 and ùëÜ1 ‚áïŒì ùëÜ1ùê∑, ùëÜ1ùëÄ, ùëÜ1ùëÑ and ùëÜ2 ‚áïŒì ùëÜ2ùê∑, ùëÜ2ùëÄ, ùëÜ2ùëÑ . Thus ùëÜ ‚áïŒì

(ùëÜ1ùê∑ ; ùëÜ2ùê∑ ), (ùëÜ1ùëÄ ; ùëÜ2ùëÄ ), (ùëÜ1ùëÑ ; ùëÜ2ùëÑ ).

Assume Œ¶(ùëÜ1, ùëÜ1ùê∑, ùëÜ1ùëÄ, ùëÜ1ùëÑ ) and Œ¶(ùëÜ2, ùëÜ2ùê∑, ùëÜ2ùëÄ, ùëÜ2ùëÑ ).
Let:
‚Ä¢ ùê¥1 = (cid:101)ùëä (ùëÜ1ùëÑ ) and ùêµ1 ‚äÜ ùëÑ \ ùê¥1 is such that
(ùúé)(D, ùúΩ, ùëÑ) = ùúé ‚Ä≤.
‚Ä¢
(cid:75)
ùëù (ùúé)(D, ùúΩ, ùëÑ) ‚àù ùëù1(D, ùúΩ, ùê¥1 | ùêµ1).
‚Ä¢
(cid:75)
‚Ä¢ ùê¥2 = (cid:101)ùëä (ùëÜ2ùëÑ ) and ùêµ2 ‚äÜ ùëÑ \ ùê¥2 is such that
ùëù (ùúé ‚Ä≤)(D, ùúΩ, ùëÑ) ‚àù ùëù2(D, ùúΩ, ùê¥2 | ùêµ2).
‚Ä¢
(cid:75)
ùëù =
(cid:75)

Thus, by Lemma 2,

ùëÜ1
(cid:74)
ùëÜ1
(cid:74)
ùëÜ2
(cid:74)

ùëù =
(cid:75)

ùëÜ2ùëÑ
(cid:74)

ùëÜ1ùëÑ
(cid:74)

ùëù (ùúéùëÄ )(D, ùúΩ, ùëÑ) = ùëù1(ùê¥1 | D, ùúΩ, ùêµ1).
(cid:75)

ùëù (ùúéùëÄ )(D, ùúΩ, ùëÑ) = ùëù2(ùê¥2 | D, ùúΩ, ùêµ2).
(cid:75)

ùëÜ
(cid:74)

ùêµ1)ùëù2(D, ùúΩ, ùê¥2 | ùêµ2).

ùëÜ1; ùëÜ2
(cid:74)
ùëù (ùúé)(D, ùúΩ, ùëÑ) =
ùëÜ1ùê∑
(cid:74)
(cid:75)
ùëù = 1.
(cid:75)
From Œ¶(ùëÜ1, ùëÜ1ùê∑, ùëÜ1ùëÄ, ùëÜ1ùëÑ ) and Œ¶(ùëÜ2, ùëÜ2ùê∑, ùëÜ2ùëÄ, ùëÜ2ùëÑ ) we also have:

For (1), we have ‚àÄùúé |= Œìùúé .
ùëÜ1ùê∑
(cid:74)

ùëÜ2
(cid:74)
ùëÜ2ùê∑
(cid:74)

ùëÜ1ùê∑ ; ùëÜ2ùê∑
(cid:74)

ùëù √ó
(cid:75)

ùëÜ2ùê∑
(cid:74)

ùëù √ó
(cid:75)

ùëù =
(cid:75)

ùëÜ1
(cid:74)

ùëù , so ùëù (D, ùúΩ, ùê¥ | ùêµ) ‚àù ùëù1(D, ùúΩ, ùê¥1
(cid:75)
ùëù (ùúé)(D, ùúΩ, ùëÑ) = 1. Thus, by Lemma 2,
(cid:75)

|

‚Ä¢
‚Ä¢

ùëÜ1ùëÑ
(cid:74)
ùëÜ2ùëÑ
(cid:74)

ùëù (ùúéùëÄ )(D, ùúΩ, ùëÑ) = ùëù (ùê¥1 | ùúΩ, D, ùêµ1)
(cid:75)
ùëù (ùúé ‚Ä≤
ùëÄ )(D, ùúΩ, ùëÑ) = ùëù (ùê¥2 | ùúΩ, D, ùêµ2)
(cid:75)

ùê¥ = (cid:101)ùëä (ùëÜùëÑ ) = (cid:101)ùëä (ùëÜ1ùëÑ ; ùëÜ2ùëÑ ) = (cid:101)ùëä (ùëÜ1ùëÑ ) ‚à™ (cid:101)ùëä (ùëÜ2ùëÑ ) = ùê¥1 ‚à™ ùê¥2

From ùëÜ well typed, it must be the case that ùê¥1 ‚à© ùê¥2 = ‚àÖ. Thus, we write ùê¥ = ùê¥1, ùê¥2.
We will prove that the property holds for ùêµ = ùêµ1 ‚à™ ùêµ2 \ ùê¥1 \ ùê¥2.
By semantic preservation of ‚áïŒì (Lemma 6),

ùëÜ1
ùëù =
(cid:75)
(cid:74)
ùëù ‚àù 1 √ó ùëù1(ùúΩ, D) √ó ùëù1(ùê¥1 | ùúΩ, D, ùêµ1). Similarly,
ùëÜ2
(cid:74)
(cid:75)

ùëÜ1ùëÑ
(cid:74)
ùëù2(ùúΩ, D)ùëù2(ùê¥2 | ùúΩ, D, ùê¥1, ùêµ1).

ùëÜ1ùê∑ ; ùëÜ1ùëÄ ; ùëÜ1ùëÑ
ùëÜ1ùê∑
ùëù √ó
(cid:74)
(cid:75)
(cid:74)
ùëù ‚àù 1 √ó ùëù2(ùúΩ, D) √ó ùëù2(ùê¥2 | ùúΩ, D, ùêµ2) =
(cid:75)

ùëù =
(cid:75)

ùëÜ1ùëÄ
(cid:74)

ùëù √ó
(cid:75)

But ùëù (ùúΩ, D, ùê¥ | ùêµ) ‚àù ùëù1 (ùúΩ, D, ùê¥1 | ùêµ1)ùëù2(ùúΩ, D, ùê¥2 | ùêµ2), so:

ùëù (ùúΩ, D, ùê¥ | ùêµ) ‚àù ùëù1(ùúΩ, D)ùëù1(ùê¥1 | ùúΩ, D, ùêµ1)ùëù2(ùúΩ, D)ùëù2(ùê¥2 | ùúΩ, D, ùê¥1, ùêµ1)

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:47

So,

ùëù (ùúΩ, D) =

‚àù

‚à´

‚à´

ùëù (D, ùúΩ, ùê¥ | ùêµ)ùëù (ùêµ)ùëëùê¥ùëëùêµ

ùëù1 (ùúΩ, D)ùëù1(ùê¥1 | ùúΩ, D, ùêµ1)ùëù2(ùúΩ, D)ùëù2(ùê¥2 | ùúΩ, D, ùê¥1, ùêµ1)ùëù (ùêµ)ùëëùê¥1ùëëùê¥2ùëëùêµ

‚à´

‚à´

‚àù ùëù1(ùúΩ, D)ùëù2(ùúΩ, D)

= ùëù1(ùúΩ, D)ùëù2(ùúΩ, D)

= ùëù1(ùúΩ, D)ùëù2(ùúΩ, D)
‚àù ùëù1(ùúΩ, D)ùëù2(ùúΩ, D)

ùëù (ùêµ)ùëù1(ùê¥1 | ùúΩ, D, ùêµ1)ùëù2(ùê¥2 | ùúΩ, D, ùê¥1, ùêµ1)ùëëùê¥1ùëëùê¥2ùëëùêµ

(cid:18)‚à´

ùëù (ùêµ)

ùëù1(ùê¥1 | ùúΩ, D, ùêµ1)

(cid:18)‚à´

ùëù2(ùê¥2 | ùúΩ, D, ùê¥1, ùêµ1)ùëëùê¥2

(cid:19)

(cid:19)

ùëëùêµ

ùëëùê¥1

Finally, for last property on ùëÜ, we use the chain rule of probability, semantics property of

Thus

ùëÜùëÄ
(cid:74)

ùëù =
(cid:75)

ùëÜ1ùëÄ ; ùëÜ2ùëÄ
(cid:74)

ùëù ‚àù ùëù1(ùúΩ, D)ùëù2(ùúΩ, D) ‚àù ùëù (ùúΩ, D)
(cid:75)

sequencing, and the result from above to get:

ùëù (ùê¥ | D, ùúΩ, ùêµ) =

‚àù

ùëù (D, ùúΩ, ùê¥ | ùêµ)
ùëù (D, ùúΩ | ùêµ)
ùëù1(D, ùúΩ )ùëù2(D, ùúΩ )ùëù1(ùê¥1 | D, ùúΩ, ùêµ1)ùëù2(ùê¥2 | D, ùúΩ, ùêµ2)
ùëù (D, ùúΩ )

√ó

ùëù (ùêµ)
ùëù (ùêµ | D, ùúΩ )

Thus:

Where:

‚àù ùëù1(ùê¥1 | D, ùúΩ, ùêµ1)ùëù2(ùê¥2 | D, ùúΩ, ùêµ2)
=

ùëÜ1ùëÑ
(cid:74)

ùëÜ2ùëÑ
(cid:74)

ùëù =
(cid:75)

ùëù
(cid:75)

ùëÜùëÑ
(cid:74)

ùëù
(cid:75)

ùëù (ùê¥ | D, ùúΩ, ùêµ) =

ùëù1(ùê¥1 | D, ùúΩ, ùêµ1)ùëù2 (ùê¥2 | D, ùúΩ, ùêµ2)
ùëç

ùëù1(ùê¥1 | D, ùúΩ, ùêµ1)ùëù2 (ùê¥2 | D, ùúΩ, ùêµ2)ùëëùê¥

ùëù1(ùê¥1 | D, ùúΩ, ùêµ1)

(cid:18)‚à´

ùëù2(ùê¥2 | D, ùúΩ, ùêµ2)ùëëùê¥2

(cid:19)

ùëëùê¥1

‚à´

‚à´

ùëç =

=

= 1

So ùëç = 1, and ùëù (ùê¥ | D, ùúΩ, ùêµ) = ùëù1(ùê¥1 | D, ùúΩ, ùêµ1)ùëù2(ùê¥2 | D, ùúΩ, ùêµ2) =
Thus:
ùëÜùê∑
(cid:74)
ùëÜùëÄ
(cid:74)
ùëÜùëÑ
(cid:74)

‚Ä¢
‚Ä¢
‚Ä¢
Œ¶((ùëÜ1; ùëÜ2), (ùëÜ1ùê∑ ; ùëÜ2ùê∑ ), (ùëÜ1ùëÄ ; ùëÜ2ùëÄ ), (ùëÜ1ùëÑ ; ùëÜ2ùëÑ )) from here.

ùëù = 1
ùëÜ1ùê∑ ; ùëÜ2ùê∑
(cid:75)
(cid:74)
ùëÜ1ùëÄ ; ùëÜ2ùëÄ
ùëù ‚àù ùëù1(ùúΩ, D)ùëù2(ùúΩ, D) = ùëù (ùúΩ, D)
(cid:75)
(cid:74)
ùëÜ1ùëÑ ; ùëÜ2ùëÑ
ùëù = ùëù1(ùê¥1 | ùúΩ, D, ùêµ1)ùëù2(ùê¥2 | ùúΩ, D, ùê¥1, ùêµ1) = ùëù (ùê¥1, ùê¥2 | ùúΩ, D, ùêµ)
(cid:75)
(cid:74)

ùëù =
(cid:75)
ùëù =
(cid:75)
ùëù =
(cid:75)

ùëÜùëÑ
(cid:74)

ùëù .
(cid:75)

Restatement of Lemma 9 (Shredding produces single-level statements 2)

ùëÜ ‚áïŒì ùëÜ1, ùëÜ2, ùëÜ3 =‚áí Œì ‚ä¢ l1(ùëÜ1) ‚àß Œì ‚ä¢ l2(ùëÜ2) ‚àß Œì ‚ä¢ l3(ùëÜ3)

Proof. By rule induction on the derivation of ùëÜ ‚áïŒì ùëÜ1, ùëÜ2, ùëÜ3.

‚ñ°

‚ñ°

Restatement of Lemma 10 (Semantic preservation of ‚áïŒì, ‚ä¢2)
If Œì ‚ä¢2 ùëÜ : l1 and ùëÜ ‚áïŒì ùëÜ1, ùëÜ2, ùëÜ3 then

.

=

ùëÜ
(cid:74)

(cid:75)

ùëÜ1; ùëÜ2; ùëÜ3
(cid:74)

(cid:75)

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:48

Proof.

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

‚ñ°

Restatement of Lemma 11 (Property of single-level statements 2)
Let Œìùúé, Œìx, ùëÜ be a SlicStan program, and Œì ‚ä¢2 ùëÜ : l1, and ùëÜ is single-level statement of level ‚Ñì, Œì ‚ä¢2 ‚Ñì (ùëÜ).
Then there exist unique functions ùëì and ùúô, such that for any ùúé, x |= Œìùúé, Œìx:

(1) If ‚Ñì = l1, then
(2) If ‚Ñì = l2, then
(3) If ‚Ñì = l3, then

(ùúé)(ùë•) = (cid:0)ùëì (ùúél1, xl1), ùúél2, ùúél3(cid:1) ,
(ùúé)(ùë•) = (cid:0)ùúél1, ùëì (ùúél1, ùúél2, xl1, xl2), ùúél3(cid:1) , ùúô (ùúél1, ùúél2)(xl1, xl2)
(ùúé)(ùë•) = (cid:0)ùúél1, ùúél2, ùëì (ùúél1, ùúél3, xl1, xl3)(cid:1) , ùúô (ùúél1, ùúél3)(xl1, xl3)

ùúô (ùúél1)(xl1)

ùëÜ
(cid:74)
ùëÜ
(cid:74)
ùëÜ
(cid:74)

(cid:75)
(cid:75)
(cid:75)

Proof. By understanding factor and sample statements as assignment to a reserved weight
‚ñ°

variables of different levels (similarly to Lemma 5) and noninterference (Lemma 7).

Restatement of Lemma 12 (Existence of model to genqant transformation)
For any Slic-
Stan program Œì, ùëÜ such that Œì ‚ä¢ ùëÜ : l1, and a variable ùëß ‚àà dom(Œì) such that Œì(ùëß) = (int‚ü®ùêæ‚ü©, model),
there exists a SlicStan program Œì‚Ä≤, ùëÜ ‚Ä≤, such that,

Œì, ùëÜ

ùëß
‚àí‚Üí Œì‚Ä≤, ùëÜ ‚Ä≤

and

Œì‚Ä≤(ùëß) = (int‚ü®ùêæ‚ü©, genquant)

Proof. Take a SlicStan program Œì, ùëÜ, a typing environment ŒìùëÄ , a variable ùëß, and statements

ùëÜùê∑, ùëÜùëÄ and ùëÜùëÑ , such that:

Œì(ùëß) = (int‚ü®ùêæ‚ü©, model)

Œì ‚ä¢ ùëÜ : data Œì

ùëß
‚àí‚Üí ŒìùëÄ ùëÜ ‚áïŒì ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ

ŒìùëÄ ‚ä¢2 ùëÜùëÄ : l1

Take also statements ùëÜ1, ùëÜ2, ùëÜ3, and ùëÜ ‚Ä≤

ùëÄ , and a typing environment Œìne such that

ùëÜùëÄ ‚áïŒìùëÄ ùëÜ1, ùëÜ2, ùëÜ3

Œìne = ne(Œì, ŒìùëÄ, ùëß)

ùëÜ ‚Ä≤
ùëÄ = ùëÜ1; ùëì = ùúô (Œìne){elim(int‚ü®ùêæ‚ü©ùëß) ùëÜ2}; factor(ùëì [dom(Œìne)]); ùëÜ3; gen(ùëß)ùëÜ2; st(ùëÜ2)

Let Œì‚Ä≤ is such that dom(Œì‚Ä≤) = dom(Œì) ‚à™ {ùëì } and for all ùë• : ùúè, ‚Ñì ‚àà Œì:

Œì‚Ä≤(ùë•) =

Ô£±Ô£¥Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥Ô£¥
Ô£≥

(ùúè, ‚Ñì)
(ùúè, ‚Ñì)
(ùúè, genqant)

if ‚Ñì ‚â† model
if ‚Ñì = model and ŒìùëÄ (ùë•) ‚â† (ùúè, l2)
if ‚Ñì = model and ŒìùëÄ (ùë•) = (ùúè, l2)

By semantic preservation of shredding (Lemma 6, Lemma 10) and type preservation of the
operational semantics ([Gorinova et al. 2019]), Œì ‚ä¢ ùëÜùê∑ ; ùëÜ1; ùëÜ2; ùëÜ3; ùëÜùëÑ : data, and thus, by (Seq),
Œì ‚ä¢ ùëÜùê∑ : data, Œì ‚ä¢ ùëÜ1 : data, . . . , Œì ‚ä¢ ùëÜùëÑ : data.

By definition of Œì‚Ä≤, Œì‚Ä≤data ‚äÇ Œìdata. ùëÜùê∑ is single-level of level data and Œì ‚ä¢ ùëÜùê∑ : data, so

Œìdata ‚ä¢ ùëÜùê∑ : data and thus Œì‚Ä≤ ‚ä¢ ùëÜùê∑ : data. Similarly, Œì ‚ä¢ ùëÜ1 : D and Œì ‚ä¢ ùëÜ3 : D.

Œì ‚ä¢ ùëÜ2 : data, so using (Phi), (Elim) and (Factor), and noting that by definition dom(Œìne) ‚äÇ

dom(ŒìùëÄ,l1), so Œìne ‚äÇ Œì, we can derive:

Œì‚Ä≤ ‚ä¢ ùëì = ùúô (Œìne){elim(int‚ü®ùêæ‚ü©ùëß) ùëÜ2}; factor(ùëì [dom(Œìne)]) : data

By Œì ‚ä¢ ùëÜ2 : data and the definition of Œì‚Ä≤, and using (Gen) and definition of st, we also derive:

Œì‚Ä≤ ‚ä¢ gen(ùëß) ùëÜ2; st(ùëÜ2) : genqant

Finally, ùëÜùëÑ is a single-level statement of level genqant and for all ùë• : ùúè, ‚Ñì ‚àà Œì, ùë• : ùúè, ‚Ñì ‚Ä≤ ‚àà Œì,

where ‚Ñì ‚â§ ‚Ñì ‚Ä≤. Therefore, Œì ‚ä¢ ùëÜùëÑ : data implies Œì‚Ä≤ ‚ä¢ ùëÜùëÑ : data.

Altogether, this gives us Œì‚Ä≤ ‚ä¢ ùëÜùê∑ ; ùëÜ ‚Ä≤

ùëÄ ; ùëÜùëÑ , and so by (Elim Gen), Œì, ùëÜ

ùëß
‚àí‚Üí Œì‚Ä≤, ùëÜùê∑ ; ùëÜ ‚Ä≤

ùëÄ, ùëÜùëÑ .

‚ñ°

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:49

Lemma 14. Let Œì, ùëÜ be a SlicStan program, such that ùúé, x |= Œì,

ùëù (ùúé)(x) =
(cid:75)
ùúì (x) for some function ùúì . If ùëì ‚àâ dom(Œì) is a fresh variable, ùëß, ùëß1, . . . ùëßùëõ ‚àà dom(Œìx) are discrete
variables of base types int‚ü®ùêæ‚ü©, int‚ü®ùêæ1‚ü©, . . . , int‚ü®ùêæùëõ‚ü© respectively, and ùëÜ ‚Ä≤ is a statement such that

ùë† (ùúé)(x) = ùúé ‚Ä≤ and
(cid:75)

ùëÜ
(cid:74)

ùëÜ
(cid:74)

then

ùëÜ ‚Ä≤ =
ùëÜ ‚Ä≤
(cid:74)

ùëì = ùúô (int‚ü®ùêæ1‚ü©ùëß1, . . . int‚ü®ùêæùëõ‚ü©ùëßùëõ){elim(int‚ü®ùêæ‚ü©ùëß) ùëÜ };
ùëù (ùúé)(x) = (cid:205)ùêæ
(cid:75)

ùë† (ùúé)(x) = ùúé ‚Ä≤‚Ä≤ with ùúé ‚Ä≤‚Ä≤[‚àíùëì ] = ùúé ‚Ä≤ and
(cid:75)

ùëÜ ‚Ä≤
(cid:74)

ùëß=1 ùúì (x).

factor(ùëì [ùëß1, . . . , ùëßùëõ]);

Proof. By examining the operational semantics of assignment, factor, and the derived forms
‚ñ°

elim and ùúô.

Lemma 15. Let Œì, ùëÜ be a SlicStan program, such that ùúé, x |= Œì,

ùëù (ùúé)(x) =
(cid:75)
ùúì (x) for some function ùúì . If ùëß ‚àà dom(Œìx) is a discrete variable of base type int‚ü®ùêæ‚ü©, and ùëÜ ‚Ä≤ is a statement
such that

ùë† (ùúé)(x) = ùúé ‚Ä≤ and
(cid:75)

ùëÜ
(cid:74)

ùëÜ
(cid:74)

ùëÜ ‚Ä≤ =

gen(ùëß) ùëÜ;

st(ùëÜ);

ùëÜ ‚Ä≤
(cid:74)

ùëÜ ‚Ä≤
(cid:74)

ùë† (ùúé)(x) = ùúé ‚Ä≤, ùúì (x) is normalisable with respect to ùëß with ùúì (x) ‚àù ùëù (ùëß | x \ {ùëß}), and
(cid:75)

then
ùëù (ùúé)(x) = ùëù (ùëß | x \ {ùëß}).
(cid:75)
Proof. By examining the operational semantics of ‚àº and target, and by induction on the structure
‚ñ°

of ùëÜ to prove

st(ùëÜ)

ùë† =
(cid:75)

ùëÜ
(cid:74)

ùë† and
(cid:75)

st(ùëÜ)
(cid:74)

ùëù = 1.
(cid:75)

(cid:74)

Typing Rules for Derived Forms:

(Elim)
Œì‚Ä≤ ‚ä¢ ùëÜ : data ùëÖŒì‚ä¢genqant(ùëÜ) = ‚àÖ Œì‚Ä≤ = Œì [ùëß ‚Ü¶‚Üí int‚ü®ùêæ‚ü©, model]
Œì ‚ä¢ elim(int‚ü®ùêæ‚ü©ùëß) ùëÜ : model

(Gen)
Œì(ùëß) = (int, genqant)

Œì ‚ä¢ ùëÜ : data

Œì ‚ä¢ gen(int‚ü®ùêæ‚ü© ùëß) ùëÜ : genqant

(Phi)
Œì‚Ä≤ ‚ä¢ ùëÜ : data ‚àÄ‚Ñì ‚Ä≤ > ‚Ñì.ùëÖŒì‚ä¢‚Ñì‚Ä≤ (ùëÜ) = ‚àÖ Œì‚Ä≤ = Œì[ùëß1 ‚Ü¶‚Üí (int‚ü®ùêæ1‚ü©, ‚Ñì), . . . , ùëßùëÅ ‚Ü¶‚Üí (int‚ü®ùêæùëÅ ‚ü©, ‚Ñì)]
Œì ‚ä¢ ùúô (int‚ü®ùêæ1‚ü© ùëß1, . . . , int‚ü®ùêæùëÅ ‚ü© ùëßùëÅ ) ùëÜ : real, ‚Ñì

Restatement of Theorem 4 (Semantic preservation of
For SlicStan programs Œì, ùëÜ and Œì‚Ä≤, ùëÜ ‚Ä≤, and a discrete parameter ùëß: Œì, ùëÜ

ùëß
‚àí‚Üí)

Proof.

ùëß
‚àí‚Üí Œì‚Ä≤, ùëÜ ‚Ä≤ ‚Üí

=

ùëÜ
(cid:74)

(cid:75)

.

ùëÜ ‚Ä≤
(cid:74)

(cid:75)

Let Œì, ùëÜ and Œì‚Ä≤, ùëÜ ‚Ä≤ be SlicStan programs, and ùëß be a discrete parameter, such that Œì, ùëÜ

ùëÜ ‚áïŒì ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ , ùëÜ ‚áïŒì‚Ä≤ ùëÜ ‚Ä≤

ùê∑, ùëÜ ‚Ä≤
Let Œì = Œìùúé, Œìdata, Œìmodel, Œìgenqant, Œì‚Ä≤ = Œì‚Ä≤

ùëÄ, ùëÜ ‚Ä≤

ùëÑ , and ùëÜùëÄ ‚áïŒì‚Ä≤‚Ä≤ ùëÜ1, ùëÜ2, ùëÜ3 for Œì‚Ä≤‚Ä≤ such that Œì

ùúé, Œì‚Ä≤data, Œì‚Ä≤model, Œì‚Ä≤genqant and
l3 be the usual partitioning of each of the typing environments.

l1, Œì‚Ä≤‚Ä≤

l2, Œì‚Ä≤‚Ä≤

Œì‚Ä≤‚Ä≤ = Œì‚Ä≤‚Ä≤

ùúé , Œì‚Ä≤‚Ä≤

Let ùëß be a store such that ùëß |= {ùëß : Œì(ùëß)}.
Let D, ùúΩ and ùëÑ be stores such that D |= Œìdata, ùëß, ùúΩ |= Œìmodel, and ùëÑ |= Œìgenqant.
Let ùúΩ 1, ùúΩ 2 and ùúΩ 3 be a partitioning of ùúΩ , such that D, ùúΩ 1 |= Œì‚Ä≤‚Ä≤
ùëß
‚àí‚Üí Œì‚Ä≤‚Ä≤, ùúΩ 2 = ùëß.
Then, by definition of Œì
By Theorem 1:

l1, ùëß, ùúΩ 2 |= Œì‚Ä≤‚Ä≤

l2, and ùúΩ 3 |= Œì‚Ä≤‚Ä≤
l3.

ùëß
‚àí‚Üí Œì‚Ä≤, ùëÜ ‚Ä≤. Let
ùëß
‚àí‚Üí Œì‚Ä≤‚Ä≤ and Œì‚Ä≤‚Ä≤ ‚ä¢2 ùëÜùëÄ : l1.

‚Ä¢
‚Ä¢

ùëÜùê∑
(cid:74)
ùëÜùëÄ
(cid:74)

ùëù (ùúé)(D, ùëß, ùúΩ, ùëÑ) = 1
(cid:75)
ùëù (ùúéùê∑ )(D, ùëß, ùúΩ, ùëÑ) ‚àù ùëù (ùëß, ùúΩ, D)
(cid:75)

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:50

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

‚Ä¢

Œì, ùëÜ

ùëù (ùúéùëÄ )(D, ùëß, ùúΩ, ùëÑ) = ùëù (ùëÑ | ùëß, ùúΩ, D)
(cid:75)

ùëÜùëÑ
(cid:74)
ùëë
‚àí‚Üí Œì‚Ä≤, ùëÜ ‚Ä≤, thus ùëÜ ‚Ä≤ must be of the form

ùëÜ ‚Ä≤ = ùëÜùê∑ ; ùëÜ1;

ùëì = ùúô (Œìl1‚Ä≤‚Ä≤){elim(int‚ü®ùêæ‚ü©ùëß) ùëÜ2};

factor(ùëì [dom(Œì‚Ä≤‚Ä≤

l1)]); ùëÜ3; gen(ùëß)ùëÜ2; st(ùëÜ2); ùëÜùëÑ

where Œì ‚ä¢ ùëÜ : data, ùëÜ ‚áïŒì ùëÜùê∑, ùëÜùëÄ, ùëÜùëÑ, Œì

ùëß
‚àí‚Üí Œì‚Ä≤‚Ä≤, Œì ‚ä¢2 ùëÜùëÄ : l1, and ùëÜùëÄ ‚áïŒì‚Ä≤‚Ä≤ ùëÜ1, ùëÜ2, ùëÜ3.

The relation ‚áïŒì is semantics-preserving for well-typed programs with respect to both ‚ä¢ and ‚ä¢2

(Lemma 6 and Lemma 10). Thus

=

ùëÜ
(cid:74)

(cid:75)

ùëÜùê∑ ; ùëÜ1; ùëÜ2; ùëÜ3; ùëÜùëÑ
(cid:74)

(cid:75)

.

We present a diagrammatic derivation of the change on store and density that each sub-part in

the original and transformed program makes in Figure 13.

Combining all of these results gives that:

ùëÜ ‚Ä≤
(cid:74)

ùë† (ùúé)(D, ùúΩ, ùëÑ) = ùúé ‚Ä≤‚Ä≤ = ùúé ‚Ä≤[ùëì ‚Ü¶‚Üí ùë£] =
(cid:75)
ùëß
‚àí‚Üí preserves store semantics (up to creating of one new fresh

ùë† (ùúé)((D, ùúΩ, ùëÑ)) [ùëì ‚Ü¶‚Üí ùë£]
(cid:75)

ùëÜ
(cid:74)

In other words, the transformation
variable f).

For the density, we get:

ùëÜ ‚Ä≤
(cid:74)

ùëù (ùúé)(D, ùúΩ, ùëÑ)
(cid:75)

= ùúô1(D, ùúΩ 1)

(cid:34)

‚àëÔ∏Å

ùëß

(cid:35)

ùúô2 (D, ùúΩ 1, ùëß)

ùúô3(D, ùúΩ 1, ùúΩ 3)ùëù (ùëß | D, ùúΩ 1)ùëù (ùëÑ | D, ùúΩ )

from Figure 13

=

‚àù

(cid:34)

‚àëÔ∏Å

ùëß

(cid:34)

‚àëÔ∏Å

ùëß

ùúô1(D, ùúΩ 1)ùúô2(D, ùúΩ 1, ùëß)ùúô3(D, ùúΩ 1, ùúΩ 3)

ùëù (ùëß | D, ùúΩ 1)ùëù (ùëÑ | D, ùúΩ )

(cid:35)

(cid:35)

ùëù (D, ùúΩ 1, ùëß, ùúΩ 2)

ùëù (ùëß | D, ùúΩ 1)ùëù (ùëÑ | D, ùúΩ )

= ùëù (D, ùúΩ 1, ùúΩ 2)ùëù (ùëß | D, ùúΩ 1)ùëù (ùëÑ | D, ùúΩ )

= ùëù (D, ùúΩ 1, ùúΩ 2)ùëù (ùëß | D, ùúΩ 1, ùúΩ 3)ùëù (ùëÑ | D, ùúΩ )

= ùëù (D, ùúΩ, ùëÑ)

by the distributive
law

by Theorem 1
and Lemma 10

marginalisation of ùëß

by ùëß ‚ä•‚ä• ùúΩ 3 | ùúΩ 1
(Theorem 3)

by the chain rule
for probability

‚àù

ùëù (ùúé)(D, ùúΩ, ùëÑ)
(cid:75)
Together, this gives us

ùëÜ
(cid:74)

ùëÜ
(cid:74)

(up to ùëÜ ‚Ä≤ creating one new fresh variable f).

=

ùëÜ ‚Ä≤
(cid:74)

(cid:75)

(cid:75)

‚ñ°

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:51

ùúé

ùëÜùê∑

ùúé (ùê∑ ) , 1

ùëÜ1

ùúé (ùê∑1) ,
ùúô1 (ùúé (ùê∑1)
l1

) ( D, ùúΩ 1)

by Lemma 11

by Lemma 14

ùëÜ2

ùëÜ ‚Ä≤
2

(cid:16)
ùúé (ùê∑1)
l1
ùúô2 (ùúé (ùê∑1)
l1

(cid:17),

, ùëì2 (ùúé (ùê∑1)
, ùëì2 (ùúé (ùê∑1)

l1,l2), ùúé (ùê∑1)
l3
l1,l2)) ( D, ùúΩ 1, ùëß)

by Lemma 11

ùëÜ3

(cid:16)
ùúé (ùê∑1)
l1
ùúô3 (ùúé (ùê∑1)
l1

, ùëì2 (ùúé (ùê∑1)
, ùëì3 (ùúé (ùê∑1)

l1,l2), ùëì3 (ùúé (ùê∑1)
l1,l3)
l1,l3)) ( D, ùúΩ 1, ùúΩ 3)

(cid:17),

(cid:16)
ùúé (ùê∑1)
, ùúé (ùê∑1)
l2
l1
(cid:205)ùëß ùúô2 (ùúé (ùê∑1)
, ùëì2 (ùúé (ùê∑1)

, ùëì ‚Ü¶‚Üí ùë£, ùúé (ùê∑1)

l3
l1,l2)) ( D, ùúΩ 1, ùëß)

(cid:17),

l1

ùëÜ3 by Lemma 11 and ùëì fresh

(cid:16)
ùúé (ùê∑1)
l1
ùúô3 (ùúé (ùê∑1)
l1

, ùúé (ùê∑1)
l2
, ùëì3 (ùúé (ùê∑1)

, ùëì ‚Ü¶‚Üí ùë£, ùëì3 (ùúé (ùê∑1)
l1,l3)
l1,l3)) ( D, ùúΩ 1, ùúΩ 3)

(cid:17),

gen(ùëß)ùëÜ2 by Lemma 15

(cid:16)
ùúé (ùê∑1)
l1

, ùëì2 (ùúé (ùê∑1)

l1,l2), ùëì ‚Ü¶‚Üí ùë£, ùëì3 (ùúé (ùê∑1)
l1,l3)
ùëù (ùëß | D, ùúΩ 1)

(cid:17),

by Theorem 1

ùëÜùëÑ

ùëÜùëÑ by Theorem 1 and ùëì fresh

ùëìùëî
ùúôùëî (ùúé (ùê∑1)
l1

(cid:16)
ùúé (ùê∑1)
l1
, ùëì2 (ùúé (ùê∑1)

l1,l2), ùëì3 (ùúé (ùê∑1)
l1,l3)
l1,l3)) ( D, ùúΩ, ùëÑ)

, ùëì2 (ùúé (ùê∑1)
l1,l2), ùëì3 (ùúé (ùê∑1)
= ùëù (ùëÑ | D, ùúΩ )

(cid:17),

(cid:16)
ùúé (ùê∑1)
ùëìùëî
l1
ùúôùëî (ùúé (ùê∑1)
l1

(cid:17)

, ùëì2 (ùúé (ùê∑1)
, ùëì2 (ùúé (ùê∑1)

l1,l2), ùëì3 (ùúé (ùê∑1)
, ùëì ‚Ü¶‚Üí ùë£,
l1,l3)
l1,l2), ùëì3 (ùúé (ùê∑1)
l1,l3)) ( D, ùúΩ, ùëÑ)
= ùëù (ùëÑ | D, ùúΩ )

Fig. 13. Diagrammatic proof of semantic preservation of

ùëß
‚àí‚Üí

B EXAMPLES

B.1 Sprinkler
Often, beginners are introduced to probabilistic modelling through simple, discrete variable exam-
ples, as they are more intuitive to reason about, and often have analytical solutions. Unfortunately,

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:52

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

Graphical model

SlicStan

sprin-
kler

cloudy

wet

rain

SlicStan + discrete parameters support

1

2

3

4

5

6

7

data real[2] p_rain, p_sprinkler;
data real[2][2] p_wet;
real p ‚àº beta(1, 1);
int<2> cloudy ‚àº bern(p);
int<2> sprinkler ‚àº bern(p_sprinkler[cloudy]);
int<2> rain ‚àº bern(p_rain[cloudy]);
int<2> wet ‚àº bern(p_wet[sprinkler][rain]);

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

...
f1 = ùúô(int<2> rain, int<2> sprinkler){

elim(int<2> cloudy){
cloudy ‚àº bern(p);
sprinkler ‚àº bern(p_sprinkler[cloudy]);
rain ‚àº bern(p_rain[cloudy]); }}

f2 = ùúô(int<2> rain, int<2> wet){
elim(int<2> sprinkler){

factor(f1[rain,sprinkler]);
wet ‚àº bern(p_wet[sprinkler,rain]); }}

f3 = ùúô(int<2> wet){ elim(int<2> rain){

factor(f2[rain,wet]); }}
f4 = ùúô(){ elim(int<2> wet){
factor(f3[wet]); }}

factor(f4);
...

Fig. 14. The ‚ÄòSprinkler‚Äô example.

one cannot express such examples directly in PPLs that do not support discrete parameters. One
well-known discrete variable example, often used in tutorials on probabilistic modelling, is the
‚ÄòSprinkler‚Äô example. It models the relationship between cloudy weather, whether it rains, whether
the garden sprinkler is on, and the wetness of the grass. In Figure 14, we show a version of the
sprinkler model written in SlicStan with discrete parameters (left) and the marginalisation part of
its corresponding transformed version (right).

As cloudy ‚ä•‚ä• wet | sprinkler, rain, we do not need to include wet in the elimination of cloudy,
and the new factor is computed for different values of only sprinkler and rain (lines 2‚Äì6). The rest
of the variables are eliminated one-by-one, involving all remaining variables (lines 7‚Äì15).

The snippet of the SlicStan code generated by our transformation is an exact implementation of
the variable elimination algorithm for this model. This not only facilitates a platform for learning
probabilistic programming using standard introductory models, but it can also be a useful tool for
learning concepts such as marginalisation, conditional independence, and exact inference methods.

B.2 Soft-K-means model
In Figure 15, we present the standard soft-k-means clustering model as it is written in SlicStan with
support for discrete model parameters (left). The right column shows the resulting code that our
program transformation generates. This code consists of plain SlicStan code and no support for
discrete model parameters is needed to perform inference on it.

The model can be used for (softly) dividing ùëÅ data points y in ùê∑-dimensional Euclidean space

into ùêæ clusters which have means ùùÅ and probability ùùÖ.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

Conditional independence by typing

1:53

SlicStan + discrete

SlicStan

data int D;
data int K;
data real[K] pi;
data real N = 3;

data real[D][N] y;

real[D][K] mu;
for(d in 1 : D) {
for(k in 1 : K){

mu[d][k] ‚àº normal(0, 1);

}}

int<K> z1 ‚àº categorical(pi);
int<K> z2 ‚àº categorical(pi);
int<K> z3 ‚àº categorical(pi);

for(d in 1 : D) {

y[d][1] ‚àº normal(mu[d][z1], 1);
y[d][2] ‚àº normal(mu[d][z2], 1);
y[d][3] ‚àº normal(mu[d][z3], 1);

}

...
for(d in 1:D){

for(k in 1:K){

mu[d,k] ‚àº normal(0, 1);}}

factor( elim(int<K> z1){
z1 ‚àº categorical(pi);
for(data int d in 1:D){

y[d,1] ‚àº normal(mu[d,z1], 1);}});

factor( elim(int<K> z2){
z2 ‚àº categorical(pi);
for(data int d in 1:D){

y[d,2] ‚àº normal(mu[d,z2], 1);}});

factor( elim(int<K> z3){
z3 ‚àº categorical(pi);
for(data int d in 1:D){

y[d,3] ‚àº normal(mu[d,z3], 1);}});

gen(int z3){

z3 ‚àº categorical(pi);
for(data int d in 1:D){

y[d,3] ‚àº normal(mu[d,z3], 1);}}

gen(int z2){

z2 ‚àº categorical(pi);
for(data int d in 1:D){

y[d,2] ‚àº normal(mu[d,z2], 1);}}

gen(int z1){

z1 ‚àº categorical(pi);
for(data int d in 1:D){

y[d,1] ‚àº normal(mu[d,z1], 1);}}

Fig. 15. Soft ùêæ-means.

B.3 A causal inference example
The question of how to adapt PPLs to causal queries, has been recently gaining popularity. One way
to express interventions and reason about causality, is to assume a discrete variable specifying the
direction (or absence of) causal relationship, and specify different behaviour for each case using if
statements [Winn 2012]. We show a simple causal inference example (Figure 16) written in SlicStan
with direct support for discrete parameters (left) and the code that our transformation generates
(right) on which we can perform inference using a combination of e.g. HMC and ancestral sampling.
This model can be read as follows. Assume that we are in a situation where we want to answer
a causal question. We want to answer this question based on ùëÅ paired observations of ùê¥ and
ùêµ, in some of which we might have intervened (doB). Our model proceeds by drawing a (prior)

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

1:54

Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs V√°k√°r

SlicStan + discrete

data real q;
data int N;
data int[N] A, B, doB;
data real prob_intervention;

real pAcausesB ‚àº beta(1, 1);
int<2> AcausesB ‚àº bernoulli(pAcausesB);

for (n in 1:N)
if(doB[n] > 0)
B[n] ‚àº bernoulli(prob_intervention);

if (AcausesB > 1){
for (n in 1:N){
A[n] ‚àº bernoulli(0.5);
if (doB[n] < 1){

if (A[n] > 0) { B[n] ‚àº bernoulli(q); }

else { B[n] ‚àº bernoulli(1 - q); }
}
}
}
else {
for (n in 1:N){
if (doB[n] < 1){ B[n] ‚àº bernoulli(0.5); }

if (B[n] > 0){ A[n] ‚àº bernoulli(q); }
else { A[n] ‚àº bernoulli(1 - q); }
}
}

SlicStan

data real q;
data int N;
data int[N] A, B, doB;
data real prob_intervention;

real pAcausesB ‚àº beta(1, 1);

for(data int n in 1:N)
if(doB[n] > 0)
B[n] ‚àº bernoulli(prob_intervention);

factor(elim(int<2> AcausesB){
AcausesB ‚àº bernoulli(pAcausesB);
if(AcausesB > 1){
for(data int n in 1:N){
A[n] ‚àº bernoulli(0.5);
if(doB[n] < 1){

if(A[n] > 0){B[n] ‚àº bernoulli(q);}

else{ B[n] ‚àº bernoulli(1 - q); }
}

}
}
else{
for(data int n in 1:N){

if(doB[n] < 1){ B[n] ‚àº bernoulli(0.5);

}

if(B[n] > 0){ A[n] ‚àº bernoulli(q); }
else{ A[n] ‚àº bernoulli(1 - q); }

}}});

Fig. 16. A causal inference example.

probability that ùê¥ causes ùêµ from a beta distribution, and then specifying ùê¥ and ùêµ for different
scenarios (intervention, ùê¥ causes ùêµ and no intervention, ùêµ causes ùê¥ and no intervention) using
conditional statements.

ACM Trans. Program. Lang. Syst., Vol. 1, No. 1, Article 1. Publication date: January 2021.

