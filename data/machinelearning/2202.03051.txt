2
2
0
2

y
a
M
7
1

]

G
L
.
s
c
[

2
v
1
5
0
3
0
.
2
0
2
2
:
v
i
X
r
a

Using Partial Monotonicity in Submodular Maximization

Loay Mualem∗

Moran Feldman†

May 18, 2022

Abstract

Over the last two decades, submodular function maximization has been the workhorse of
many discrete optimization problems in machine learning applications. Traditionally, the study
of submodular functions was based on binary function properties. However, such properties
have an inherit weakness, namely, if an algorithm assumes functions that have a particular
property, then it provides no guarantee for functions that violate this property, even when
the violation is very slight. Therefore, recent works began to consider continuous versions of
function properties. Probably the most signiﬁcant among these (so far) are the submodularity
ratio and the curvature, which were studied extensively together and separately.

The monotonicity property of set functions plays a central role in submodular maximization.
Nevertheless, and despite all the above works, no continuous version of this property has been
suggested to date (as far as we know). This is unfortunate since submoduar functions that
are almost monotone often arise in machine learning applications. In this work we ﬁll this gap
by deﬁning the monotonicity ratio, which is a continues version of the monotonicity property.
We then show that for many standard submodular maximization algorithms one can prove
new approximation guarantees that depend on the monotonicity ratio; leading to improved
approximation ratios for the common machine learning applications of movie recommendation,
quadratic programming and image summarization.

Keywords: monotonicity ratio, submodular maximization, cardinality constraint, matroid con-
straint, movie recommendation, quadratic programming, image summarization

1

Introduction

Over the last two decades, submodular function maximization has been the workhorse of many
discrete optimization problems in machine learning applications such as data summarization [17,
19, 31, 32, 42, 49], social graph analysis [45], adversarial attacks [36], dictionary learning [15],
sequence selection [41, 50], interpreting neural networks [18] and many more. Traditionally, the
study of submodular functions was based on binary properties of functions. A function can be either
submodular or non-submodular, monotone or non-monotone, etc. Such properties are simple, but
they have an inherit weakness—if an algorithm assumes functions that have a particular property,
then it provides no guarantee for functions that violate this property, even if the violation is very
slight.

Given the above situation, recent works began to consider continuous versions of function prop-
erties. Probably the most signiﬁcant among these continuous versions so far are the submodularity
ratio and the curvature. The submodularity ratio (originally deﬁned by Das and Kempe [16]) is

∗Computer Science Department, University of Haifa. Email: loaymua@gmail.com
†Computer Science Department, University of Haifa. Email: moranfe@cs.haifa.ac.il

1

 
 
 
 
 
 
∈

[0, 1] replacing the binary submodularity property that a set function can either
a parameter γ
have or not have. A value of 1 corresponds to a fully submodular function, and lower values of
γ represent some violation of submodularity (the worse the violation, the lower γ). Similarly, the
curvature (deﬁned by Conforti and Cornu´ejol [13]) is a parameter c
[0, 1] replacing the binary
linearity property that a set function can either have or not have. A value of 1 corresponds to a
fully linear function, and lower values of c represent some violation of linearity.

∈

A central conceptual contribution of Das and Kempe [16] was that they were able to demonstrate
that continuous function properties further extend the usefulness of submodular maximization to
new machine learning applications (such as subset selection for regression and dictionary selection).
This has motivated a long list of works on such properties (see [3, 25, 26, 29, 34] for a few exam-
ples), including works that combine both the submodularity ratio and the curvature (see, e.g., [3]).
However, to the best of our knowledge, no continuous version of the binary monotonicity property
has been suggested so far.1

We note that the monotonicity property of set functions plays a central role in submodular
maximization, and basically every problem in this ﬁeld has been studied for both monotone and
non-monotone objective functions. Naturally, monotone objective functions enjoy improved ap-
proximation guarantees compared to general functions, and it is natural to ask how much of this
improvement applies also to functions that are almost monotone (in some sense). Since such func-
tions often arise in machine learning applications when a diversity promoting component is added
to a basic monotone objective, obtaining better guarantees for them should strongly enhance the
usefulness of submodular maximization as a tool for many machine learning applications.

Formally, a non-negative set function f : 2N

→
T
monotone if f (S)
ratio of such a function f as the maximum value m
two sets S

is (increasingly)
. Similarly, we deﬁne the monotonicity
f (T ) for every
f (S)
. Equivalently, one can deﬁne the monotonicity ratio m by

f (T ) for every two sets S

R≥0 over a ground set

[0, 1] such that m

⊆ N
∈

N

≤

⊆

⊆

T

·

⊆

⊆ N

m , min
S⊆T ⊆N

f (T )
f (S)

,

where the ratio f (T )/f (S) is assumed to be 1 whenever f (S) = 0. Intuitively, the monotonicity
ratio measures how much of the value of a set S can be lost when additional elements are added
to S. One can view m as a measure of the distance of f from being monotone. In particular, m is
equal to 1 if and only if f is monotone.

Our main contribution in this paper is demonstrating the usefulness of the monotonicity ratio

in machine learning applications, which we do in two steps.

• First, we show (in Sections 3, 4 and 5) that for many standard submodular maximization
algorithms one can prove new approximation guarantees that depend on the monotonicity
ratio. These approximation guarantees interpolate between the known approximation ratios
of these algorithms for monotone and non-monotone submodular functions.

• Then, using the above new approximation guarantees, we derive new approximation ratios
for the standard applications of movie recommendation, quadratic programming and image
summarization. Our guarantees improve over the state-of-the-art for most values of the
problems’ parameters. See Section 6 for more detail.

1Following the appearance of the pre-print version of this paper, we learned that Iyer deﬁned in his Ph.D. thesis [30]
such a property, and moreover, this property is identical in name and deﬁnition to the one we deﬁne. However, Iyer
only used this property to prove the result that appears below as Theorem 4.1; and thus, our work is the ﬁrst to
systematically study this property.

2

Remark. Computing the monotonicity ratio m of a given function seems to be a diﬃcult task.
Therefore, the algorithms we analyze avoid assuming access to m, and the value of m is only used
in the analyses of these algorithms. Nevertheless, in the context of particular applications, we are
able to bound m, and plugging this bound into our general results yields our improved guarantees
for these applications.

1.1 Our Results

−

, a set function f : 2N

N
f (T ) for every two sets S

Given a ground set
∪
−
T . Submodular maximization
)
u
{
}
problems ask to maximize such functions subject to various constraints. To allow for multiplicative
approximation guarantees for these problems, it is usually assumed that the objective function f
is non-negative. Accordingly, we consider in this paper the following three basic problems.

→
and element u

R is submodular if f (S

∈ N \

)
u
}

f (S)

⊆ N

f (T

∪ {

≥

⊆

T

• Given a non-negative submodular function f : 2N

that (approximately)
maximizes f . This problem is termed “unconstrained submodular maximization”, and is
studied in Section 3.

R, ﬁnd a set S

⊆ N

→

• Given a non-negative submodular function f : 2N

,
≤ |N |
ﬁnd a set S
of size at most k that (approximately) maximizes f among such sets. This
problem is termed “maximizing a submodular function subject to a cardinality constraint”,
and is studied in Section 4.

R and an integer parameter 0

⊆ N

→

≤

k

• Given a non-negative submodular function f : 2N

over the same
M
ground set, ﬁnd a set S
and (approximately) maximizes f
among such sets. This problem is termed “maximizing a submodular function subject to
a matroid constraint”, and is studied in Section 5 (see Section 5 also for the deﬁnition of
matroids).

→
that is independent in

R and a matroid

⊆ N

M

We present both algorithmic and inapproximability results for the above problems. Our algo-
rithmic results reanalyze a few standard algorithms, and are mostly proved using adaptations of
the original analyses of these algorithms. However, as these adaptations are non-black box and
often involve a technical challenge, it is quite surprising that for almost all algorithms we get an
approximation ratio of m
αnon-monotone, where m is the monotonicity ratio,
·
αmonotone is the approximation ratio known for the algorithm when f is guaranteed to be mono-
tone, and αnon-monotone is the approximation ratio known for the algorithm when f is a general
non-negative submodular function.

αmonotone + (1

m)

−

·

0 and m

While the above mentioned algorithmic results lead to our improved guarantees for applications,
our inapproximability results represent our main technical contribution. In general, these results
are based on the symmetry gap framework of Vondr´ak [51]. The original version of this framework
is able to deal both with the case of general (not necessarily monotone) submodular functions,
and with the case of monotone submodular functions; which in our terms correspond to the cases
of m
1, respectively. However, to prove our inapproximability results, we had to
show that the framework extends to arbitrary lower bounds on m, which was challenging because
the original proof of the framework is highly based on derivatives of continuous functions. From
this point of view, submodularity is deﬁned as having non-positive second-order derivatives, and
monotonicity is deﬁned as having non-negative ﬁrst-order derivatives. However, the deﬁnition of
the monotonicity ratio cannot be easily restated in terms of derivatives; and thus, handling it
required us to come up with a diﬀerent proof approach.

≥

≥

Interestingly, our inapproximability result for unconstrained submodular maximization proves
that the optimal approximation ratio for this problem does not exhibit a linear dependence on
m. Thus, the nice linear dependence demonstrated by almost all our algorithmic results is prob-

3

ably an artifact of looking at standard algorithms rather than representing the true nature of the
monotonicity ratio, and we expect future algorithms tailored to take advantage of the monotonicty
ratio to improve over this linear dependence. The reason that we concentrate in this work on
reanalyzing standard submodular maximization algorithms rather than inventing new ones is that
we want to stress the power obtained by using the new notion of monotonicity ratio, as opposed
to power gained via new algorithmic innovations. This is in line with the research history of the
submodularity ratio and the curvature. For both of these parameters, the original works concen-
trated on reanalyzed the standard greedy algorithm in view of the new suggested parameter; and
the invention of algorithms tailored to the parameter was deferred to later works (see [48] and [12]
for examples of such algorithms for the curvature and submodularity ratio, respectively).

Over the years, the standard submodular maximization algorithms have been extended and
improved in various ways. Some works presented accelerated and/or parallelized versions of these
algorithms, while other works generalized the algorithms beyond the realm of set functions (for
example, to (DR-)submodular functions over lattices or continuous domains). Since our motivation
in this paper is related to the monotonicity ratio, which is essentially independent of the extensions
and improvements mentioned above, we mostly analyze the vanilla versions of all the algorithms
considered. This keeps our analyses relatively simple. However, our experiments are based on more
state-of-the-art versions of the algorithms. Similarly, many continuous properties (including the
submodularity ratio) have weak versions that only depend on the behavior of the function for nearly
feasible sets, and immediately enjoy most of the results that apply to the original strong property.
The deﬁnition of such weak versions is useful for capturing additional application, but often add
little from a theoretical perspective. Therefore, in the theoretical parts of this paper we consider
only the monotonicity ratio as it is deﬁned above; but for the sake of one of our applications we
later deﬁne also the natural corresponding weak property.

1.2 Additional Related Work

Lin and Bilmes [37] described an algorithm that takes advantages of a continuous partial mono-
tonicity property, but unlike the monotonicity ratio, their property was deﬁned in terms of the
particular submodular objective they were interested in. More recently, Cui et al. [14] considered
a weaker, but still binary, version of monotonicity called weak-monotonicity.

2 Preliminaries and Basic Observations

−

→

⊆ N

R, we deﬁne f (u

, we use S + u and S

We begin this section by deﬁning the notation that we use throughout the paper. Using this
notation, we can then state some useful basic observations. Given an element u
and a set
∈ N
u
u as shorthands for S
S
. Additionally, given a set
u
}
}
S) , f (S + u)
function f : 2N
f (S) (this value is known as the marginal
contribution of u to S with respect to f ). Similarly, given an additional set T
, we deﬁne
f (S). We also use 1S to denote the characteristic vector of the set S, i.e.,
f (T
a vector in [0, 1]N that has 1 in the coordinates corresponding to elements that appear in S and
0 in the rest of the coordinates. Finally, if f is non-negative, then we say that it is m-monotone
if its monotonicity ratio is at least m; and given an event
] the indicator of
this event, i.e., a random variable that takes the value 1 when the event happens, and the value 0
otherwise.

, we denote by 1[

S) , f (S

∪ {
−

and S

⊆ N

\ {

T )

−

∪

E

E

|

|

Next, we present two well-known continuous extensions of set functions. Given a set function
R deﬁned as follows. For every
with

R, its multilinear extension is a function F : [0, 1]N

[0, 1]N , let R(x) to be a random subset of

that includes every element u

f : 2N
→
vector x

→

∈ N

∈

N

4

probability xu, independently. Then, F (x) = E[f (R(x))]. The Lov´asz extension of f is a function
ˆf : [0, 1]N

R deﬁned as follows. For every vector x

[0, 1]N ,

→

∈

ˆf (x) =

1

0
Z

f (Tλ(x))dλ ,

u
{

where Tλ(x) ,
. The Lov´asz extension of a submodular function is known to be
}
convex. More important for us is the following known lemma regarding this extension. This lemma
stems from an equality, proved by Lov´asz [38], between the Lov´asz extension of a submodular
function and another extension known as the convex closure.

xu ≥

∈ N |

λ

Lemma 2.1. Let f : 2N
every x
marginals of Dx agree with x), ˆf (x)

[0, 1]N and random set Dx

→

∈

R be a submodular function, and let ˆf be its Lov´asz extension. For
(i.e., the

Dx] = xu for every u

obeying Pr[u

∈ N

⊆ N
E[f (Dx)].

≤

∈

As a consequence of the last lemma, we get the following useful corollary.2

Corollary 2.2. Let f : 2N
deterministic set O
D])

f (O).

⊆ N

·

R≥0 be a non-negative m-monotone submodular function. For every
D)]

, E[f (O

maxu∈N Pr[u

and random set D

m)

→

(1

(1

⊆ N

∪

≥

−

−

·

∈

Proof. Let x be the vector of marginals of O
by Lemma 2.1,

∪

D, i.e., xu = Pr[u

O

∪

∈

D] for every u

. Then,

∈ N

E[f (O

D)]

∪

≥

=

=

1

ˆf (x) =

f (Tλ(x))dλ

0
maxu∈N Pr[u∈D]

Z

1

maxu∈N Pr[u∈D]

0
Z

0
Z

f (Tλ(x))dλ +

f (Tλ(x))dλ

maxu∈N Pr[u∈D]

Z

f (O

∪

Tλ(x))dλ + (1

max
u∈N

−

Pr[u

D])

·

∈

f (O) ,

where the last equality holds since the elements of O appear in Tλ(x) for every λ
other element appears in Tλ(x) when λ > Pr[u
the expression f (O
by m

[0, 1], and no
D]. Using the deﬁnition of the monotonicity ratio,
Tλ(x)) on the rightmost side of the previous equation can be lower bounded

f (O), which yields

∪

∈

∈

·

E[f (O

D)]

∪

m

f (O)dλ + (1

Pr[u

D])

f (O)

maxu∈N Pr[u∈D]

≥
0
Z
= m

·

= (1

max
u∈N
(1

−

−

Pr[u

m)

·
f (O) + (1

D]

∈
max
u∈N

·

·
Pr[u

D])

·

∈

max
u∈N

Pr[u

−
max
u∈N
f (O) .

−

∈
D])

·
f (O)

∈

·

We conclude this section with the following observation, which immediately follows from the
deﬁnition of the monotonicity ratio. We view this observation as evidence that the class of non-
negative m-monotone functions is a natural class for every m
[0, 1], and not just for m = 0
(the class of all non-negative set functions) and m = 1 (the class of all non-negative monotone set
functions).

∈

2One can observe that Corollary 2.2 is a generalization of the often used Lemma 2.2 of [6].

5

1

0.8

0.6

0.4

0.2

o
i
t
a
r

n
o
i
t
a
m
i
x
o
r
p
p
a

0

0

0.2

0.4

0.6

0.8

1

m

Figure 1: Graphical presentation of Theorem 3.1. The lower line represents the approximation
guarantee (as a function of m) of the algorithm whose existence is guaranteed by the theorem;
and the upper line represents the inapproximability result stated in the theorem. The shaded area
between the lines includes the optimal approximation ratio (for any given m). Since this shaded
area does not include a straight segment connecting the points (0, 1/2) and (1, 1), the optimal
approximation ratio does not have a linear dependence on m.

≥

Observation 2.3. For every two non-negative m-monotone functions f, g : 2N
c

0, the following functions are also non-negative and m-monotone:
• h(S) = f (S) + g(S),
• h(S) = f (S) + c, and
• h(S) = c

f (S).

·

R≥0 and constant

→

3 Unconstrained Maximization

R≥0, and the objective is to ﬁnd a set S

Recall that in the unconstrained submodular maximization problem, we are given a non-negative
submodular function f : 2N
that (approximately)
maximizes f (S). Buchbinder et al. [7] gave the ﬁrst 1/2-approximation algorithm for this problem,
known as the double greedy algorithm. The 1/2-approximation guarantee of double greedy is known
to be optimal in general due to a matching inapproximability result due to Feige et al. [21]. Nev-
ertheless, in this section we study the extent to which one can improve over this guarantee as a
function of the monotonicity ratio m of f . Formally, we prove the following theorem.

⊆ N

→

Theorem 3.1. There exists a polynomial time algorithm that obtains an approximation ratio of
for unconstrained submodular maximization, but no such algorithm obtains an
max
approximation ratio of 1/(2

m) + ε for any constant ε > 0.3

m, (2 + m)/4
}
{

−

The guarantees stated in Theorem 3.1 are plotted in Figure 1. This ﬁgure demonstrates that
while Theorem 3.1 does not settle the approximability of unconstrained submodular maximization

3In the second part of Theorem 3.1, like in all the other inapproximability results in this paper, we make the
standard assumption that the objective function f can be accessed only through a value oracle that given a set
S ⊆ N returns f (S).

6

as a function of m, the gap between its positive and negative results is quite small. More impor-
tantly, Figure 1 also shows that the optimal approximation ratio for unconstrained submodular
maximization cannot have a linear dependence on m.

The following simple proposition proves the ﬁrst part of Theorem 3.1.

Proposition 3.2. There exists a polynomial time algorithm that obtains an approximation ratio
of max

for unconstrained submodular maximization.

m, (2 + m)/4
}
{

Proof. The analysis of the double greedy algorithm by Buchinder et al. [7] shows that this algorithm
outputs a solution set of expected value at least

2f (OP T ) + f (∅) + f (

)

,

N

4

where OP T is an arbirary optimal solution. In general, this only shows 1/2-approximation, as is
claimed by [7]. However, when the monotonicity ratio is taken into account,

2f (OP T ) + f (∅) + f (

2f (OP T ) + f (

N

)

≥

N

)

2f (OP T ) + m

≥

4

f (OP T )

·

=

2 + m
4

·

f (OP T ) ,

4

4

where the ﬁrst inequality follows from the non-negativity of f , and the second inequality holds since
. Hence, the double greedy algorithm of Buchinder et al. [7] is a polynomial
OP T is a subset of
time algorithm guaranteeing (2 + m)/4-approximation.

N

To complete the proof of the proposition, we note that the trivial algorithm that always outputs
f (OP T ). Hence, outputting
-
m, (2 + m)/4
}
{

has an approximation ratio of at least m because f (

and the output of double greedy guarantees max

the set
the better solution among
approximation.

m

N

N

N

≥

)

·

We now would like to prove the second part of Theorem 3.1. We do this using a generalization
of the symmetry gap framework of Vondr´ak [51] that is given as Theorem 3.3. To formally state
Theorem 3.3, we ﬁrst need to present some deﬁnitions from [51].

F ⊆

2N of feasible sets. The problem max

Deﬁnition 3.1 (Strong symmetry). Consider a non-negative submodular function f and a collec-
is strongly symmetric with respect
tion
∈ F}
to a group of permutations
, and (2)
and σ
whenever Eσ∈G[1σ(S)] = Eσ∈G[1σ(S′)], where Eσ∈G represents the expectation
S′
S
over picking σ uniformly at random out of

|
, if (1) f (S) = f (σ(S)) for all S

f (S)
{

∈ F ⇐⇒

⊆ N

∈ F

∈ G

on

N

S

G

.

G

Deﬁnition 3.2 (Symmetry gap). Consider a non-negative submodular function f and a collection
[0, 1]N be the
F
is strongly symmetric with respect to a

2N of feasible sets. Let F (x) be the multilinear extension of f and P (

. Then, if the problem max

⊆

S

)

of permutation, then its symmetry is deﬁned as

f (S)
{

|

∈ F}

F ⊆
convex hull of
graph

F

G

where ¯x , Eσ∈G[σ(x)].

max
max

F (¯x)
{
F (x)
{

|
|

x
x

P (
P (

F
F

)
}
)
}

∈
∈

,

Deﬁnition 3.3 (Reﬁnement). Consider a set
˜
F ⊆

2N ×X is a reﬁnement of

F

if

2N , and let X be some set. We say that

F ⊆

˜F =

S

n

⊆ N ×

P (

F

∈

X

x

(cid:12)
(cid:12)
(cid:12)

), where xu = |S∩({u}×X)|

|X|

for all u

.

∈ N

o

7

F
[0, 1]N

Theorem 3.3. Consider a non-negative m-monotone submodular function f and a collection
F ⊆
2N of feasible sets such that the problem max
is strongly symmetric with respect to
be the class of problems
some group
in which ˜f is a non-negative m-monotone submodular function, and ˜F is a
˜f (S)
max
{
reﬁnement of F . Then, for every ε > 0, any (even randomized) (1 + ε)γ-approximation algorithm
for the class

∈
would require exponentially many value queries to ˜f .

and has a symmetry gap γ. Let

of permutations over

f (S)
{

∈ F}

G
S

˜F

N

S

C

}

|

|

C

While adapting the proof of Vondr´ak [51] to obtain Theorem 3.3 is not trivial, as is discussed
in Section 1.1, the adaptation is quite technical and non-inspiring. Therefore, we defer the proof
of Theorem 3.3 to Appendix A.

F

To use Theorem 3.3, we need to deﬁne a submodular maximization problem with a signiﬁcant
mod 2)
, f (S) = m
u, v
symmetry gap. Speciﬁcally, let us choose
}
{
= 2N , where m is an arbitrary constant m
[0, 1]. The function f is submodular and
and
non-negative since it a convex combination of the functions 1[S
mod 2 which are
well-known to have these properties. One can also verify via the deﬁnitions that the monotonicity
is strongly symmetric with
ratio of f is exactly m, and that the problem max
S
respect to the group
. The following lemma calculates the
symmetry gap of this problem.

f (S)
{
of the two possible permutations of

= ∅] and

= ∅] + (1

∈ F}

S
(
|

|
N

1[S

S
|

m)

N

−

=

∈

G

·

|

|

·

Lemma 3.4. The problem max

f (S)
{

|

S

∈ F}

has a symmetry gap of

1
2−m .

Proof. Observe that our deﬁnition of

F

implies that P (

) = [0, 1]N . Therefore,

max

F (x)
{

|

x

∈

P (

F

)
}

= max

F (x)
{

|

x

∈

= max

f (S)
{

|

S

}

⊆ N }

= 1 ,

(1)

where the second equality holds since, for every vector x, F (x) is a convex combination of values
of f for subsets of

; and on the other hand, for every set S

, f (S) = F (1S).

Observe now that the deﬁnition of f implies that

N

⊆ N

F (x) = m[1

(1
−
−
= xu + xv −

xu)(1
xuxv(2

xv)] + (1
m) .

−

−

m)

·

−

[xu(1

−

xv) + xv(1

xu)]

−

Since ¯x is a vector that has the value (xu + xv)/2 in both its coordinates, if we we use the shorthand
y = (xu + xv)/2, then we get

F (¯x) = 2y

(2

−

−

m)y2 .

This expression is maximized for y = 1/(2

−

m), and the maximum attained for this y is

2

−

2

m −

m)
m)2 =

2

(2
(2

−
−

1

−

.

m

Since the value y = 1/(2

−

m) is obtained, for example, when x = (y, y)

[0, 1]N , the above implies

∈

Together with Equation (1), this implies the lemma.

max

F (¯x)
{

|

x

∈

P (

F

=

)
}

2

1

−

.

m

The second part of Theorem 3.1 now follows from Theorem 3.3, Lemma 3.4 and the properties
is equal to the entire set 2N ×X for

of f discussed before the lemma because any reﬁnement ˜
F
some set X.

of

F

8

6
6
4 Maximization subject to a Cardinality Constraint

⊆ N

In this section we consider the problem of maximizing a non-negative submodular function f : 2N
→
R≥0 subject to a cardinality constraint. In other words, we are given an integer value 1
,
≤ |N |
of size at most k (approximately) maximizing f among
and the objective is to output a set S
such sets. When the objective function f is guaranteed to be monotone, it is long known that a
standard greedy algorithm (Algorithm 1 below) guarantees (1
1/e)-approximation for the above
problem [44], and that this is essentially the best possible for any polynomial time algorithm [43].
Unfortunately, however, the greedy algorithm has no constant approximation guarantee when the
objective function is not guaranteed to be monotone (see [4] for a simple example demonstrating
In Section 4.1 we prove Theorem 4.1, which generalizes the result of [44], and proves an
this).
1/e to 0 as
approximation guarantee for the greedy algorithm that deteriorates gracefully from 1
the monotonicity ratio m goes from 1 to 0.

−

−

≤

k

Theorem 4.1. The Greedy algorithm (Algorithm 1) has an approximation ratio of at least m(1
−
1/e) for the problem of maximizing a non-negative m-monotone submodular function subject to a
cardinality constraint.

Following a long line of works [6, 20, 23, 35, 46, 51], the state-of-the-art approximation guarantee
for the case in which the objective function f is not guaranteed to be monotone is currently
0.385 [5]. However, the algorithm obtaining this approximation ratio is quite involved, which limits
its practicality. Arguably, the state-of-the-art approximation ratio obtained by a “simple” algorithm
is the 1/e
0.367-approximation obtained by an algorithm called Random Greedy (Algorithm 2
below). Furthermore, this algorithm has the nice property that for monotone objective functions it
recovers the optimal 1
1/e approximation guarantee. In Section 4.2 we prove Theorem 4.2, which
gives an approximation guarantee for Random Greedy that smoothly changes as a function of m
and recovers the above mentioned 1/e and 1
1/e guarantees in the cases of m = 0 and m = 1,
respectively.

−

−

≈

Theorem 4.2. The Random Greedy algorithm (Algorithm 2) has an approximation ratio of at least
m(1
(1/e) for the problem of maximizing a non-negative m-monotone submodular
·
function subject to a cardinality constraint.

1/e) + (1

m)

−

−

−

As mentioned above, when f is monotone, the optimal approximation ratio is known to be
1
1/e. However, there is still gap between the state-of-the-art 0.385-approximation for the
non-monotone case and the state-of-the-art inapproximability result due to Oveis Gharan and
Vondr´ak [46], which shows that no polynomial time algorithm can guarantee a better than roughly
0.491-approximation.
In Section 4.3 we prove Theorem 4.3, which proves an inapproximability
result that smoothly depends on m and recovers the above mentioned inapproximability results in
the special cases of m = 0 and m = 1.

Theorem 4.3. For any constant ε > 0, no polynomial time algorithm can obtain an approximation
ratio of

maxx∈[0,1]{

α(mx2 + 2x

min
α∈[0,1]

−

2x2) + 2(1
1, 2(1
max
{

α)(1
α)
}

−
−

−

ex−1)(1

(1

m)x)
}

−

−

+ ε

for the problem of maximizing a non-negative m-monotone submodular function subject to a cardi-
nality constraint.

9

Greedy
Random Greedy
Inapproximability

1

0.8

0.6

0.4

0.2

o
i
t
a
r

n
o
i
t
a
m
i
x
o
r
p
p
a

0

0

0.2

0.4

0.6

0.8

1

m

Figure 2: Graphical representation of the results of Section 4. This plots depicted the approximation
guarantees we prove for the Greedy algorithm (Theorem 4.1) and the Random Greedy algorithm
(Theorem 4.2), and our inapproximability result (Theorem 4.3).

Unfortunately, the mathematical expression given in Theorem 4.3 is not very readable. To get
an intuitive understanding of its behavior, we numerically evaluated it for various values of m. The
plot obtained in this way appears in Figure 2. For context, this ﬁgure also includes all the other
results proved in this section. As is evident from Figure 2, Theorem 4.3 improves over the 1
1/e
inapproximability result of Nemhauser and Wolsey [43] only for m that is smaller than roughly 0.56.
This is surprising since, intuitively, one would expect the best possible approximation ratio to be
1/e for any m < 1. However, we were unable to prove an inapproximability
strictly worse than 1
that is even slightly lower than 1
1/e for any value m > 0.56. Understanding whether this is an
artifact of our proof or a real phenomenon is an interesting question that we leave open.

−

−

−

4.1 Analysis of the Greedy Algorithm

In this section we prove Theorem 4.1, which we repeat here for convenience.

Theorem 4.1. The Greedy algorithm (Algorithm 1) has an approximation ratio of at least m(1
−
1/e) for the problem of maximizing a non-negative m-monotone submodular function subject to a
cardinality constraint.

The greedy algorithm starts with an empty solution, and then augments this solution in k
iterations (recall that k is the maximum cardinality allowed for a feasible solution). Speciﬁcally, in
iteration i, the algorithm adds to the current solution the element ui with the best (largest) marginal
contribution with respect to the current solution—but only if this addition does not decrease the
value of the solution. A formal description of the greedy algorithm appears as Algorithm 1. Note
that in this description the solution of the algorithm after i iterations, for every integer 0
n,
is denoted by Ai.

≤

≤

i

Our ﬁrst step towards proving Theorem 4.1 is the following lemma, which lower bounds the
increase in the value of f (Ai) as a function of i. Speciﬁcally, the lemma shows that this increase is
signiﬁcant as long as there is a signiﬁcant gap between between f (Ai−1) and m
f (OP T ), where
OP T is an arbitrary optimal solution.

·

10

Algorithm 1: The Greedy Algorithm (f, k)
1 Let A0 ←
2 for i = 1 to k do
3

∅.

Let ui be the element of
if f (ui |
Ai−1)
else Let Ai ←

≥
Ai−1.

N \
0 then Let Ai ←

4

5

6 return Ak.

Ai−1 maximizing f (ui |
Ai−1 + ui.

Ai−1).

Lemma 4.4. For every integer 1

i

≤

≤

k, f (Ai)

−

f (Ai−1)

≥

k−1[m

·

f (OP T )

f (Ai−1)].

−

Proof. We need to distinguish between two cases. Consider ﬁrst the case in which f (ui |
In this case,

Ai−1)

0.

≥

f (Ai)

−

f (Ai−1) = f (ui |
OP T
|

Ai−1)

≥
Ai−1|

OP T
|

Ai−1|

\
k

f (ui |

·

Ai−1)

\
k
f (OP T

·
Ai−1)
k

∪

−

f (u

max
u∈OP T \Ai−1
f (Ai−1)

|

Ai−1)

≥ P
f (OP T )
k

m

·

≥

≥

≥

u∈OP T \Ai−1
k
f (Ai−1)

−

f (u

|

Ai−1)

,

where the ﬁrst inequality holds since
k because OP T is a feasible solution,
Ai−1| ≤ |
the second inequality is due to the way used by the greedy algorithm to choose the element ui, the
penulatimate inequality follows from the submodularity of f , and the last inequality holds since f
is m-monotone.

OP T
|

OP T

| ≤

\

Consider now the case in which f (ui |

Ai−1) < 0. In this case, f (Ai)

f (Ai−1) = 0 because

−

Ai = Ai−1. Furthermore, repeating the arguments used to prove the above inequality yields

f (OP T )

m

·

−

f (Ai−1)

OP T

≤ |

OP T

≤ |

Ai−1| ·
Ai−1| ·

\

\

max
u∈OP T \Ai−1

f (u

max
u∈N \Ai−1

f (u

|

Ai−1)

|
Ai−1)

0 .

≤

Rearranging the last lemma, we get the following inequality.

m

·

f (OP T )

f (Ai)

(1

−

≤

1/k)

[m

·

·

−

f (OP T )

−

f (Ai−1)] .

(2)

This inequality bounds the rate in which the gap between m
This allows us to prove Theorem 4.1.

·

f (OP T ) reduces as a function of i.

Proof of Theorem 4.1. Combining Inequality (2) for every integer 1

f (OP T )

m

·

f (Ak)

(1

−

≤

−

1/k)k

[m

·

·

f (OP T )

Rearranging this inequality, we get

k yields

i

≤

f (A0)] .

≤

−

f (Ak)

m

·

≥

f (OP T )

m

·

−

(1

−

1/k)k

·

[f (OP T )

f (A0)]

−

m

≥

1

−

·

(cid:18)

1
e

·

(cid:19)

f (OP T ) ,

where the last inequality follows from the non-negativity of f and the inequality (1

1/k)k

1
e .

≤

−

11

4.2 Analysis of Random Greedy

In this section we prove Theorem 4.2, which we repeat here for convenience.

Theorem 4.2. The Random Greedy algorithm (Algorithm 2) has an approximation ratio of at least
(1/e) for the problem of maximizing a non-negative m-monotone submodular
m(1
·
function subject to a cardinality constraint.

1/e) + (1

m)

−

−

Like the standard greedy algorithm from Section 4.1, the Random Greedy algorithm starts with
an empty solution, and then augments it in k iterations. Speciﬁcally, in iteration i the algorithm
ﬁnds a set Mi of at most k elements whose total marginal contribution with respect to the current
solution is maximal. Then, at most one element of Mi is added to the algorithm’s current solution
in a random way guaranteeing that every element of Mi is added to the solution with probability
exactly 1/k. A formal presentation of the Random Greedy algorithm appears as Algorithm 2. Note
that in this presentation the solution of the algorithm after i iterations is denoted by Ai.

∅.

Algorithm 2: Random Greedy (f, k)
1 Let A0 ←
2 for i = 1 to k do
Let Mi ←
3
with probability (1

arg maxB⊆N \Ai−1,|B|≤k{
/k) do
Mi|
− |

4

P

Ai−1.

Ai ←
otherwise

5

6

7

8

Let ui be a uniformly random element of Mi.
Set Ai ←

Ai−1 + ui.

u∈B f (u

.
Ai−1)
}

|

9 return Ak.

We start the analysis of the Random Greedy algorithm with the following lemma.

Lemma 4.5. For every integer 0

i

k and element u

∈
≤
Proof. Note that in each iteration i of Algorithm 2, any element u
current solution with probability of at most 1/k. Hence,

∈ N

≤

, Pr[u

Ai]

≤

1

−

(1

−

1/k)i.

Ai−1 is added to the

∈ N \

Pr[u

∈

Ai] = 1

Pr[u /
∈

−

Ai] = 1

i

−

Yj=1

Pr[u

u

Aj |

6∈

6∈

Aj−1]

(1

1

−

−

≤

1/k)i

.

Plugging the guarantee of the last lemma into Corollary 2.2 yields the following lower bound

on the expected value of Ai ∪
Corollary 4.6. For every integer 0
m

f (OP T ) + (1

m)(1

OP T .

i

≤
≤
f (OP T ).

−

1
k )i

·

−

·

Using the last corollary we are now ready to prove Theorem 4.2.

k, E[f (Ai∪

OP T )]

[1

(1

m)

(1

(1

·

−

−

−

−

≥

1
k )i)]

·

f (OP T ) =

Proof of Theorem 4.2. Let
Greedy during its ﬁrst i

−

Ei−1 be an arbitrary possible choice for the random decisions of Random
1 iterations. Observe that, conditioned on

Ei−1 happening,

u∈Mi

f (u
k

|

Ai−1)

E[f (Ai)

−

f (Ai−1)] =

P

≥ P

u∈OP T \Ai−1
k

f (u

|

Ai−1)

f (Ai−1 ∪

OP T )
k

−

≥

f (Ai−1)

,

12

where the ﬁrst inequality follows from the choice of Mi by the algorithm, and the second inequality
follows from submodularity. Taking now expectation over the choice
Ei−1 that realized, the last
inequality yields

E[f (Ai)

f (Ai−1)]

−

≥

≥

E[f (Ai−1 ∪
m

OP T )]
k
f (OP T ) + (1

·

E[f (Ai−1)]

−

(3)

−

m)(1

−

1
k )i−1
k

·

f (OP T )

−

E[f (Ai−1)]

,

where the second inequality is due to Corollary 4.6.

The last inequality lower bounds the expected increase in the value of the solution of Random
Greedy in every iteration. This implies also a lower bound on the expected value of f (Ai). To
complete the proof of the theorem, we need to prove a closed form for this implied lower bound,
which we do by induction. Speciﬁcally, let us prove by induction on i that

E[f (Ai)]

m

≥ "

1

·  

−

(cid:18)

1
k

1

−

i

!

(cid:19)

+ (1

m)

−

i
k ·

·

1
k

1

−

(cid:18)

i−1

# ·

(cid:19)

f (OP T )

(4)

for every integer 0
1/k)k−1.
1/e

(1

≤

k, which implies the theorem by plugging i = k because (1

i

≤

1/k)k

−

≤

≤
For i = 0, Inequality (4) holds since the non-negativity of f guarantees that f (A0)

−

( 0
k )

m)

(1
(1
and let us prove Inequality (4) for this value of i assuming that its holds for i
(cid:2)

(1

(1

−

−

−

−

·

·

·

·

1
k )0)
(cid:3)

1
k )−1 + m

−

≥
f (OP T ). Consider now some integer 0 < i

0 =
k,
1. By Inequality (3),

≤

E[f (Ai)] = E[f (Ai−1)] + E[f (Ai)

f (Ai−1)]

E[f (Ai−1)] +

m

·

−

f (OP T ) + (1

m)(1

−

−

1
k )i−1
k

·

f (OP T )

−

E[f (Ai−1)]

≥

=

1
k

1

−

(cid:18)

·

(cid:19)

E[f (Ai−1)] +

m + (1

−

m)(1
k

−

1
k )i−1

f (OP T ) .

·

Plugging the induction hypothesis into the last inequality, we get

E[f (Ai)]

1
k

1

−

≥

(cid:18)

m

· "

1

·  

(cid:19)

−

(cid:18)

1
k

1

−

i−1

(cid:19)

!

+ (1

m)

·

−

+

1

i

−
k

·

m + (1

1

1
k

−

m)(1
k

(cid:18)

−

i−2

# ·
1
k )i−1

(cid:19)

−

f (OP T )

f (OP T )

·

=

m

1

"

−

1
(cid:18)

−

1
k

i

!

(cid:19)

+ (1

m)

−

i
k ·

·

1
k

1

−

(cid:18)

i−1

# ·

(cid:19)

f (OP T ) .

4.3

Inapproximability for a Cardinality Constraint

In this section we prove Theorem 4.3, which we repeat here for convenience.

Theorem 4.3. For any constant ε > 0, no polynomial time algorithm can obtain an approximation
ratio of

maxx∈[0,1]{

α(mx2 + 2x

min
α∈[0,1]

−

2x2) + 2(1
1, 2(1
max
{

α)(1
α)
}

−
−

−

ex−1)(1

(1

m)x)
}

−

−

+ ε

for the problem of maximizing a non-negative m-monotone submodular function subject to a cardi-
nality constraint.

13

 
We prove Theorem 4.3 using the symmetry gap technique, and speciﬁcally, via our extension
of this technique proved in Theorem 3.3. To use this theorem, we need to construct an instance of
our problem in which there is a large gap between the values of the best (general) solution and the
best symmetric solution. Our instance is based on an instance constructed by Oveis Gharan and
Vondr´ak [46]. However, the objective function in the original instance of [46] is not m-monotone
for any m > 0, and therefore, we need to modify it so that it becomes m-monotone for a value
m

∈
Fix some positive integer value r to be determined later and some value α
a, b
{

[0, 1]. The ground
∈
set of the instance we construct is
, and the constraint of the instance is a
[r]
ai, bi |
}
cardinality constraint allowing a feasible solution to include up to 2 elements. The objective function
of our instance is the function f : 2N
α)[f2(S) + f3(S)],
where

R≥0 deﬁned by f (S) = α

[0, 1] of our choosing.

f1(S) + (1

}∪{

→

N

−

=

∈

i

·

f1(S) = m

1[S
f2(S) = 1[S

·

a, b
ai |

= ∅] + (1
−
= ∅]

[r]

} 6
i

∈

} 6

(1

·

m)

·

−

∩ {

∩ {

S
(
|
(1

a, b

mod 2) ,

∩ {
m)

}|
1[a

−

·

S])

∈

and

f3(S) = 1[S

bi |

∩ {

i

∈

[r]

= ∅]

} 6

(1

·

−

(1

−

m)

·

1[b

∈

S]) .

Let us denote the above described instance of submodular maximization subject to a cardinality

constraint by

I

. We begin the analysis of

Lemma 4.7. The objective function f of

I

I

by proving some properties of its objective function.

is non-negative, m-monotone and submodular.

Proof. We prove below that the functions f1, f2 and f3 have the properties stated in the lemma.
This implies that f also has these properties by Observation 2.3 and the well-known closure of
the class of submodular functions to multiplication by a non-negative constant and addition (see,
e.g., Lemma 1.2 of [4]). The function f1 is identical to the function proved in Section 3 to have
the properties stated in the lemma, and the functions f2 and f3 are identical to each other up to
switching the roles of a with b and ai with bi. Therefore, to prove that both f2 and f3 have the
properties stated by the lemma it suﬃces to show that f2 has these properties, which we do in the
rest of this proof.

Clearly, f2 is non-negative. To see that f2 is a submodular function, note that
• For every set S
• For every integer 1
(1
−
• For every element u

S) =
r and set S

a, f2(a
i
≤
S]).

m).
−
·
S) = 1[S

ai |
∩ {
⊆ N −

i
[r]
∈
} 6
ai, f2(ai

= ∅]

1[S

∅]

m)

∩ {

a)

(1

(1

⊆ N −
≤
∈
(
N −

1[a

[r]
}
Since all the above marginal contributions are down-monotone functions of S (i.e., functions whose
value can only decrease when elements are added to S), the function f2 is submodular.

and set S

u, f2(u

S) = 0.

⊆ N −

ai |

\ {

i

|

[r]
}

∈

=

ai

−

−

∈

∈

i

·

·

|

|

|

It remains to argue why f2 is m-monotone. Consider any two sets S

then the inequality m
f (S)
the case in which f2(S) > 0, which implies that S
(1
−
and hence, m

1. Since S is a subset of T , we also get f2(T ) = (1
m

. If f2(S) = 0,
f (T ) follows from the non-negativity of f2. Therefore, consider
= ∅; and therefore, f2(S) =
[r]
1[a
m,

1 = m

ai |

S])
∈
f2(S)

f2(T ).

⊆ N

1[a

∩ {

T ])

m)

m)

} 6

(1

(1

⊆

−

−

−

≤

≥

∈

∈

T

i

·

·

·

≤
≤

·

·

≤

A cardinality constraint is symmetric in the sense that the feasibility of a set depends only on
the number of elements in it, and is completely independent of the identity of these elements. Let
that are equivalent to applying any number of
us now denote by
the following two steps: (1) switching a with b and ai with bi for every i
[r], or (2) switching ai
[r]. The ﬁrst step preserves the value of f because it simply switches
with aj for two integers i, j

the group of permutations of

N

∈

G

∈

14

the values of f2 and f3, while leaving the value of f1 unaﬀected; and the second step preserves the
value of f since it deals with elements that both f1 and f3 ignore, and f2 treats in the same way.
Hence, for every set S
, we have f (S) = f (σ(S)), which implies the
following observation.

and permutation σ

⊆ N

∈ G

Observation 4.8. The instance

I

is strongly symmetric with respect to

.

G

To use Theorem 3.3, we still need to bound the symmetry gap of

, which we do next.

I

Lemma 4.9. The symmetry gap of

is at most

−

−

≤

−

−

−

−

−

−

−

(1

(1

(1

(1

α)[1

x)/r)r](1

m)x)
}

m)x)
}

α(mx2 + 2x

α(mx2 + 2x

maxx∈[0,1]{

maxx∈[0,1]{

−
α)(1
α)
}

−
α)
}
ex−1)(1

−
−
are the sets

α), respectively. Therefore, the value of the optimal solution for

I
2x2) + 2(1
−
1, 2(1
max
{
2x2) + 2(1
1, 2(1
max
{
whose values according
a, b1}
Proof. Two possible feasible solutions for
{
is at least
to f are 1 and 2(1
max
. Since the symmetry gap is the ratio between the value of the best symmetric
α)
1, 2(1
}
{
solution and the value of the best solution, to prove the lemma it remains to argue that the best
symmetric solution for
x)/r)r](1
.
m)x)
}

has a value of maxx∈[0,1]{
We remind the reader that a symmetric solution for

∈
2. Since a and b can be exchanged with each other by the permutations of

[0, 1]N
y
, the
obeying
k
values of the coordinates of a and b in ¯y must be equal to each other. Similarly, every two elements
of
, and therefore, the values of the
ai, bi ∈
{
coordinates of these elements in ¯y must all be identical. Thus, any symmetric solution ¯y can be
represented as

−
is ¯y = Eσ∈G[y] for some vector y

can be exchanged by the permutations of

α(mx2 + 2x

a1, b1}
{

2x2) + 2(1

+ 2/r .

k1 ≤

[r]
}

α)[1

and

(1

(1

(1

−

−

−

−

−

−

−

−

∈

G

G

I

I

I

I

i

for some values x, z
solution (according to the multilinear extension F of f ) is

[0, 1] obeying 2x + 2rz

≤

∈

¯yu =

x if u = a or u = b ,
z
(

if u

i

ai, bi |

[r]
}

∈ {
2 (or equivalently, z

∈

(1

−

≤

x)/r). The value of this

α[m(1

(1
−
= α(mx2 + 2x

−

x)2) + 2(1
−
2x2) + 2(1

m)x(1

α)(1

−

−

x)] + 2(1
−
z)r)(1

(1

−

−

(1

−

−

−

−
m)x) .

α)(1

(1

z)r)(1

−

(1

−

−

m)x)

Since this expression is a non-decreasing function of z, the maximum value of any symmetry solution
for

is

I

max
x,z∈[0,1]
z≤(1−x)/r

α(mx2 + 2x
{

−

2x2) + 2(1

α)(1

(1

−

−

−

z)r)(1

(1

m)x)
}

−

−

= max

x∈[0,1]{

α(mx2 + 2x

2x2) + 2(1

−

α)[1

(1

−

−

(1

−

−

x)/r)r](1

(1

m)x)
}

−

−

.

Since any reﬁnement of a cardinality constraint is a cardinality constraint over a larger ground
set, plugging Lemma 4.7, Observation 4.8 and Lemma 4.9 into Theorem 3.3 yields the following
corollary.

15

Corollary 4.10. For every constant ε′ > 0, no polynomial time algorithm for maximizing a non-
negative m-monotone submodular function subject to a cardinality contraint obtains an approxima-
tion ratio of

maxx∈[0,1]{

α(mx2 + 2x

−

2x2) + 2(1
1, 2(1
max
{

α)(1
α)
}

−
−

−

ex−1)(1

(1

m)x)
}

−

−

+ 2/r + ε′

.

Theorem 4.3 now follows from the last corollary by choosing ε′ = ε/2, r =

maxx∈[0,1]{

α′(mx2 + 2x

α = arg min
α′∈[0,1]

−

2x2) + 2(1
1, 2(1
max
{

α′)(1
α′)
}

−
−

−

ex−1)(1

−

5 Maximization subject to a Matroid Constraint

and

4/ε
⌉
⌈
m)x)
(1
}

−

.

\

I

M

∈ I

is deﬁned as a pair

over the ground set

T and T
T

, then S
S such that S + u

is a non-empty subset of 2N obeying two properties for every two sets S, T

In this section we consider the problem of maximizing a non-negative submodular function subject
),
to a matroid constraint. A matroid
,
N
I
where
: (i) if
S
, then there exists an element
∈ I
|
⊆
is called independent with respect to a matroid
u
∈
); and the matroid
M
constraint corresponding to a given matroid
allows only independent sets with respect to this
matroid as feasible solutions. Hence, we can restate the problem we consider in this section in
R≥0 and a
the following more formal way. Given a non-negative submodular function f : 2N
matroid
(approximately)
,
N
maximizing f among all such sets.

) over the same ground set, output an independent set S

(otherwise, we say that S is dependent with respect to

; and (ii) if S, T
. A set S

if it belongs to

∈ I
∈ I

⊆ N

⊆ N

and

= (

S
|

∈ I

T
|

= (

M

M

M

M

→

N

<

I

I

|

When the objective function f is guaranteed to be monotone, a standard greedy algorithm
guarantees 1/2-approximation for the above problem [24]. Our ﬁrst result for this section (whose
proof appears in Section 5.1) shows how this approximation guarantee changes as a function of m
(note that since matroid constraints generalize cardinality constraints, the greedy algorithm has no
constant guarantee for non-monotone functions in this case as well).

Theorem 5.1. The Greedy algorithm (Algorithm 3) has an approximation ratio of at least m/2 for
the problem of maximizing a non-negative m-monotone submodular function subject to a matroid
constraint.

−

The approximation ratio of the greedy algorithm was improved over by the seminal work of
C˘alinescu et al. [9], who described the Continuous Greedy algorithm whose approximation ratio
is 1
1/e when f is monotone; matching the inapproximability result proved by Nemhauser and
Wolsey [43] for the special case of a cardinality constraint. In contrast, when the objective f is not
guaranteed to be monotone, the approximability of the problem is less well-understood. On the
one hand, after a long line of works [20, 23, 35, 46, 51], the state-of-the-art approximation ratio for
the problem is 0.385 [5], but on the other hand, it is only known that no polynomial time algorithm
for the problem can obtain an approximation ratio of 0.478 [46].

Unfortunately, the above mentioned state-of-the-art 0.385-approximation algorithm is quite
involved. Therefore, we chose to consider in this work two other algorithms. The ﬁrst algorithm
is the Measure Continuous Greedy algorithm (due to [23]) which guarantees an approximation
ratio of 1/e
0.367. This algorithm performs only slightly worse than the above state-of-
the-art, and is in fact a central component of all the currently known algorithms achieving better
than 1/e-approximation. Measured Continuous Greedy is also known to guarantee (1

o(1)

1/e

−

≈

−

−

16

o(1))-approximation when the objective f is monotone, and the next theorem (which we prove in
Section 5.2) shows that the approximation guarantee of this algorithm changes smoothly with the
monotonicity ratio of f between the above two expressions.

Theorem 5.2. The Measured Continuous Greedy algorithm (Algorithm 4) has an approximation
ratio of at least m(1
o(1) for the problem of maximizing a non-negative
m-monotone submodular function subject to a matroid constraint, where the o(1) term diminishes
with the size of the ground set

1/e) + (1

(1/e)

m)

.4

−

−

−

·

N

M

The other algorithm we consider is an algorithm called Random Greedy for Matroids (due
to [6]). Unlike Measured Continuous Greedy and almost all the other algorithms suggested for
non-monotone objectives to date, this algorithm is combinatorial, which makes it appealing in
practice. Buchbinder et al. [6] proved an approximation ratio of roughly (1 + e−2)/4 for Random
Greedy for Matroids. The next theorem shows how this approximation guarantee improves as
a function of the monotonicity ratio.
In this theorem we refer to the rank k of the matroid
, which is simply deﬁned as the size of the largest independent set with respect to this
constraint
matroid. We also note that the algorithm we analyze is identical to the algorithm of [6] up to two
modiﬁcations. The ﬁrst modiﬁcation is in the number of iterations that the algorithm makes. To
get the result of Buchbinder et al. [6], it suﬃces to use k iterations. However, the optimal number of
iterations increases with m, and therefore, our version of the algorithm uses more than k iterations.
Furthermore, since we do not want to assume knowledge of m in the algorithm, we use a number
of iterations that is appropriate for m = 1, which requires us to make the second modiﬁcation to
the algorithm; namely, to allow an iteration to update the solution of the algorithm only when this
update is beneﬁcial. This guarantees that doing more iterations can never decrease the value of
the algorithm’s solution.

Theorem 5.3. For every ε
(0, 1), the Random Greedy for Matroids algorithm (Algorithm 5)
has an approximation ratio of at least 1+m+e−2/(1−m)
ok(1) for the problem of maximizing a
non-negative m-monotone submodular function subject to a matroid constraint (except in the case
of m = 1 in which the approximation ratio is 1/2
ok(1)). The notation ok(1) represents a
term that diminishes with the rank k of the matroid constraint.

−

−

−

−

∈

ε

ε

4

Theorem 5.3 is proved in Section 5.3. We ﬁnish this section with the following theorem (proved in
Section 5.4), which generalizes the 0.478 inapproximability result of Oveis Gharan and Vondr´ak [46]
for general non-negative submodular functions.

Theorem 5.4. For any constant ε > 0, no polynomial time algorithm can obtain an approximation
ratio of

min
α∈[0,1]

max
x∈[0,1/2]{

α(mx2 + 2x

2x2) + 2(1

α)(1

−

−

e−1/2)(1

(1

m)x)
}

−

−

+ ε

−

for the problem of maximizing a non-negative m-monotone submodular function subject to a matroid
constraint.

Unfortunately, the mathematical expression given in Theorem 5.4 is not very readable. There-
fore, to get an intuitive understanding of its behavior, we numerically evaluated it for various values

4Technically, Measured Continuous Greedy is an algorithm for maximizing the multilinear extesnion of a non-
negative submodular function subject to a general solvable down-closed convex body P constraint, and we prove in
Section 5.2 that it guarantees the approximation ratio stated in Theorem 5.2 for this setting. However, this implies
the result stated in Theorem 5.2 using a standard reduction (see Section 5.2 for further detail).

17

Greedy
Measured Continuous Greedy
Random Greedy for Matroids
Inapproximability

1

0.8

0.6

0.4

0.2

o
i
t
a
r

n
o
i
t
a
m
i
x
o
r
p
p
a

0

0

0.2

0.4

0.6

0.8

1

m

Figure 3: Graphical representation of the results of Section 5. This plots depicted the approximation
guarantees we prove for the greedy algorithm (Theorem 5.1), the Measured Continuous Greedy
algorithm (Theorem 5.2) and the Random Greedy for Matroids algorithm (Theorem 5.3), and
our inapproximability result (Theorem 5.4). The dashed line corresponds to an approximation
1/e, which is another inapproximability result, inherited from monotone submodular
ratio of 1
functions [43].

−

of m. The plot obtained in this way appears in Figure 3. For context, this ﬁgure also includes
all the other results proved in this section. Somewhat surprisingly, Figure 3 shows that Theo-
rem 5.4 does not generalize the 1
1/e inapproximability result of Nemhauser and Wolsey [43] for
monotone functions despite the fact that this inapproximability result holds for every monotonicity
1/e
ratio m
inapproximability of [43] for large values of m.

[0, 1]. This behavior resembles the inability of Theorem 4.3 to improve over the 1

−

−

∈

5.1 Analysis of the Greedy algorithm

A version of the greedy algorithm designed for matroid constraints appears as Algorithm 3. This
algorithm starts with an empty solution, and then iteratively adds elements to this solution, where
the element added in each iteration is the element with the largest marginal contrition with respect
to the current solution among all the elements whose addition to the solution does not violate
feasibility. The algorithm terminates when no additional elements can be added to the solution
without decreasing its value.

Theorem 5.1. The Greedy algorithm (Algorithm 3) has an approximation ratio of at least m/2 for
the problem of maximizing a non-negative m-monotone submodular function subject to a matroid
constraint.

Proof. Lemma 3.2 of [27] shows that the greedy algorithm outputs a solution S of value at least
OP T )/2 for the problem of maximizing a non-negative submodular function f subject to a
f (S

∪

18

Algorithm 3: The Greedy Algorithm (for a Matroid Constraint) (f,
1 Let A0 ←
2 while true do
3

∅, and i

←

0.

Let ui+1 be the element of
if f (ui+1 |
Ai)
≥
else return Ai.

v
{
∈ N \
0 then Let Ai+1 ←

4

5

Ai + v

maximizing f (ui+1 |
Ai |
Ai + ui+1, and then, increase i by 1.

∈ I}

Ai).

= (

N

))

,

I

M

matroid constraint, where OP T is an optimal solution for the problem.5 The theorem now follows
since for an m-monotone function f we are guaranteed to have f (S

f (OP T ).

OP T )

m

∪

≥

·

5.2 Analysis of Measured Continuous Greedy

In this section, we reanalyze the Measured Continuous Greedy algorithm of [23] in view of the
R≥0 and a down-closed
monotonicity ratio. Given a non-negative submodular function f : 2N
[0, 1]N , Measured Continuous Greedy is an algorithm designed to ﬁnd
solvable6 convex body P
a vector x
P that approximately maximize F (x), where F is the multilinear extension of f .
Speciﬁcally, we prove the following theorem.

→

⊆

∈

R≥0, a solvable
Theorem 5.5. Given a non-negative m-monotone submodular function f : 2N
0, Measured Continuous Greedy outputs a
down-close convex body P
vector x
f (OP T ), where F is the multilinear
extension of f and OP T is the set maximizing f among all sets whose characteristic vectors belong
to P . Furthermore, x

[0, 1]N and a parameter T

[0, 1]N obeying F (x)

P whenever T

e−T ) + (1

m)T e−T ]

[0, 1].

[m(1

→

−

−

≥

≥

⊆

∈

·

∈

∈

We note that Feldman et al. [23] discussed conditions that guarantee that x belongs to P also
for some values of T that are larger than 1. However, the above stated form of Theorem 5.5 already
suﬃces to prove Theorem 5.2. Let us explain why this is the case. When P is the matroid polytope
PM of a matroid
, there are algorithms called Pipage Rounding [9] and Swap Rounding [11]
M
that, given a vector x
≥
F (x)
f (OP T ). Therefore, one can obtain an algorithm for maximizing f subject to the
o(1)
·
−
matroid
by executing Measured Continuous Greedy with P = PM and T = 1, and then applying
either Pipage Rounding or Swap Rounding to the resulting vector; which yields an algorithm with
the properties speciﬁed by Theorem 5.2.

P produce a set S that is independent in

and also obeys E[f (S)]

M

M

∈

We now describe the version of Measured Continuous Greedy that we analyze (given as Algo-
rithm 4). For simplicity, we chose to analyze a continuous version of this algorithm that assumes
direct access to the multilinear extension F of the objective function rather than just to the objective
function itself. We refer the reader to [23] for details about discretizing the algorithm and avoiding
the assumption of direct access to F . We also note that the o(1) error term in the approximation
guarantee stated in Theorem 5.5 is due to these issues. Our description of Measured Continuous
Greedy requires some additional notation, namely, given two vectors x and y, we denote by x
y
their coordinate-wise maximum and by x

y their coordinate-wise multiplication.

∨

Measured Continuous Greedy starts at “time” 0 with the empty solution, and improves this
solution during the time interval [0, T ]. We denote the solution of the algorithm at time t by

⊙

5In fact, Lemma 3.2 of [27] proves a more general result for p-set systems, but it implies the stated result since

matroids are 1-set systems.

6A body P ⊆ [0, 1]N is solvable if one can eﬃciently optimize linear functions subject to it, and is down-closed
if y ∈ P implies x ∈ P for every vector x ∈ [0, 1]N obeying x ≤ y (this inequality should be understood to hold
coordinate-wise).

19

∈

[0, T ], the algorithm calculates a vector w whose u-coordinate is the
y(t). At every time t
gain that can be obtained by increasing this coordinates in the solution y(t) to be 1 (i.e., wu(t) =
F (y(t))). Then, the algorithm ﬁnds a vector x(t)
F (y(t)
P that maximizes the objective
1{u})
−
∨
x(t) (to
x(t), and adds to the solution y(t) an inﬁnitesimal part of (1N −
function w(t)
·
understand where the last expression comes from, we note that when x is integral, fully adding
x(t) to y(t) sets to 1 all the coordinates that are 1 in x(t), which matches the “spirit”
(1N −
⊙
of the deﬁnition of w).

y(t))

y(t))

⊙

∈

Algorithm 4: Measured Continuous Greedy(f, P, T )
1 Let y(0)
2 foreach t
3

1∅.
[0, T ) do

←
∈

For each u
←
Let x(t)
w(t)
·
Increase y(t) at a rate of dy(t)

, let wu(t)
∈ N
arg maxx∈P {

←

∨

F (y(t)
x
.
}
dt = (1N −

4

5

y(t))

x(t).

⊙

1{u})

F (y(t)).

−

6 return y(T ).

The ﬁrst step in the analysis of Measured Continuous Greedy is bounding the maximum value

of the coordinates of the solution y(t).

Lemma 5.6. For every t

[0, T ],

∈

y(t)
k

Proof. Fix an arbitrary element u
Algorithm 4, yu(t) obeys the diﬀerential inequality

∈ N

1

e−t.

k∞ ≤
, and let us explain why yu(t)

−

1

−

≤

e−t. By Line 5 of

dyu(t)
dt

= (1

yu(t))

xu(t)

1

−

≤

·

−

yu(t) ,

and the solution of this diﬀerential inequality for the initial condition yu = 0 is

We are now ready to prove Theorem 5.5

yu(t)

1

−

≤

e−t .

Proof of 5.5. Recall that x(t) is a vector inside P for every time t
closed, (1N −
⊙
y(T ) = (1
1∅ +
y(t))
T )
−
belongs to P by the convexity of P .

x(t) and 1∅ both belong to P as well. This means that for T
T
0 (1N −

[0, T ], and since P is down-
1 the vector
x(t)dt is a convex combination of vectors in P , and therefore

y(t))

≤

⊙

∈

·

It remains to lower bound the value of F (y(T )). By the chain rule,

R

dF (y(t))
dt

=

Xu∈N (cid:18)

dyu(t)
dt

∂F (y)
∂yu

·

(1

−

yu(t))

xu(t)

·

∂F (y)
∂yu

·

=

(cid:19)

Xu∈N (cid:18)

.

y=y(t)

(cid:19)

y=y(t)
(cid:12)
(cid:12)
(cid:12)

Since F is multilinear, its partial derivative with respect to a single coordinate is equal to the
diﬀerence between the value of the function for two diﬀerent values of this coordinate over the
diﬀerence between these values. Plugging this observation into the previous inequality yields

(cid:12)
(cid:12)
(cid:12)

dF (y(t))
dt

=

Xu∈N (cid:18)

(1

−

yu(t))

·

xu(t)

·

F (y(t)

∨
1

20

1{u})

−
yu(t)

−

F (y(t))

= x(t)

w(t) .

·

(cid:19)

One possible candidate to be x(t) is 1OP T . Hence, by the deﬁnition of x(t), x(t)
Combining this inequality with the previous one, we get

·

w(t)

1OP T ·

≥

w(t).

dF (y(t))
dt

1OP T ·
F (y(t)
(1
[1

−

≥

≥

≥

w(t) =

F (y(t)

1{u})

∨

−

F (y(t))

Xu∈OP T
(cid:2)
F (y(t))
−
e−t)]

1OP T )
m)(1

−

·

∨

−

[1

≥
f (OP T )

−

m)

(1
k∞]
·
· k
F (y(t)) = [m + (1

−

(cid:3)
y(t)

−

f (OP T )
m)e−t]

−

F (y(t))
f (OP T )

−

·

F (y(t)) ,

−

where the second inequality holds by the submodularity of f , the penultimate inequality holds by
Corollary 2.2, and the last inequality follows from Lemma 5.6.

Solving the diﬀerential inequality that we got for the initial condition F (y(0))

by the non-negativity of f ) yields

0 (which holds

≥

F (y(t))

m(1

−

≥

e−t) + (1

m)te−t

−

and the theorem now follows by plugging t = T .

(cid:2)

f (OP T ) ,

·

(cid:3)

5.3 Analysis of Random Greedy for Matroids

In this section we prove Theorem 5.3, which we repeat here for convenience.

Theorem 5.3. For every ε
(0, 1), the Random Greedy for Matroids algorithm (Algorithm 5)
has an approximation ratio of at least 1+m+e−2/(1−m)
ok(1) for the problem of maximizing a
non-negative m-monotone submodular function subject to a matroid constraint (except in the case
of m = 1 in which the approximation ratio is 1/2
ok(1)). The notation ok(1) represents a
term that diminishes with the rank k of the matroid constraint.

−

−

−

−

∈

ε

ε

4

To prove the theorem, we ﬁrst need to state the algorithm it refers to. Towards this goal, let
contains a set D of 2k “dummy” elements that are known to the

us assume that the ground set
algorithm and have the following two properties.

N

• f (S) = (S
• S

\

∈ I

D) for every set S

if and only if S

D

\

∈ I

.
⊆ N
S
and
|

k.

| ≤

This assumption is useful since it allows us to assume that the optimal solution OP T is a base of
, and thus, simpliﬁes the description of our algorithm (Random Greedy for Matroids). We can
M
justify our assumption using the following procedure: (i) add 2k dummy elements to the ground set,
(ii) extend f and
according to the above properties, (iii) execute Random Greedy for Matroids on
the resulting instance, and (iv) remove from the output of the algorithm any dummy elements that
end up in it. This procedure guarantees that any approximation guarantee obtained by Random
Greedy for Matroids using our assumption can be obtained also without the assumption.

I

Our version of the Random Greedy for Matroids algorithm is given as Algorithm 5. Like the
original version of the algorithm (due to [6]), our version starts with a base of
consisting only
of dummy elements, and then modiﬁes it in a series of iterations. In each iteration i, the algorithm
starts with a solution Si−1, and then identiﬁes a base Mi of
whose elements have the largest
total marginal contribution with respect to Si−1 (Mi is also required to be disjoint from Si−1). The
Si−1, and adds it to the solution Si−1 at the
algorithm then picks a uniformly random element ui ∈
expense of an element gi(ui) of Si−1 given by a function gi that is chosen carefully (the existence
of such a function follows, for example, from Corollary 39.12a of [47]).

M

M

As mentioned above, our version of Random Greedy for Matroids diﬀers compared to the version
of [6] in two respects. First, we check whether replacing g(ui) with ui is beneﬁcial, and make the

21

(0, 1) and makes
swap only if this is indeed the case. Second, our algorithm gets a parameter ε
k/ε iterations instead of k (we assume without loss of generality that k/ε is integral; otherwise, we
can replace ε with a value which is smaller than ε by at most a factor of 2 and has this property).

∈

Algorithm 5: Random Greedy for Matroids(f,

= (

,

), ε)

N

I

M

1 Initialize S0 to be an arbitrary base containing only elements of D.
2 for i = 1 to k/ε do
Let Mi ⊆
3

that contains only elements of

N be a base of

N \

M
Si−1) among all such bases.

f (u

u∈Mi

|

4

5

6

7

gi(u) + u

Let gi be a function mapping each element of Mi to an element of Si−1 obeying
P
Si−1 −
Let ui be a uniformly random element from Mi.
if f (Si−1 −
gi(ui) + ui) > f (Si−1) then Let Si ←
else Let Si ←

gi(ui) + ui.

Si−1 −

for every u

Si−1.

Si−1.

∈ I

∈

8 return Sk/ε.

Si−1 and maximizes

Since Theorem 5.3 is trivial for a constant k, we can assume in the analysis of Algorithm 5 that
k is larger than any given constant. The ﬁrst step in this analysis is proving the following lower
bound on the expected value of OP T

Si.

∪
Observation 5.7. For every integer 0
f (OP T ).

k/ε, E[f (OP T

i

≤

Si)]

∪

≥

1
2 (1 + m + (1

m)(1

−

−

2/k)i)

·

≤

i

≤

k/ε and element u

D, let pu,i denote the probability u
Proof. For every integer 0
≤
2/k) + 1/k. To see
belongs to Si. We would like to argue that when i > 0, we have pu,i ≤
why this is the case, note that u belongs to Si only if one of the following happens: (i) u belongs to
Si−1 and is not removed from the solution (happens with probability pu,i−1(1
1/k) since gi(ui) is
a uniformly random element of Si−1), or (ii) u belongs to Mi−1 and is chosen as ui (happens with
probability at most (1

pu,i)/k). Therefore,

pu,i−1(1

∈ N \

−

−

−
pu,i−1 ·
Next, we aim to prove by induction that pu,i ≤

pu,i ≤

1/k) + (1

(1

−

−

pu,i−1)/k = pu,i−1 ·

2/k) + 1/k .

(1

−

(5)

1
2 (1
D implies that pu,0 = 0 = 1

(1

−

−

2/k)i) for every integer 0

k/ε.
≤
2/k)0). Assume now
1. By the induction hypothesis and

2 (1

(1

−

−

≤

i

∈ N \

1, and let us prove it for i

For i = 0, this is true since u
that the claim holds for i
Inequality (5),

−

≥

pu,i−1(1

2 (1
pu,i ≤
−
The observation now follows since Corollary 2.2 guarantees that E[f (OP T

2/k) + 1/k

2/k) + 1/k = 1

2/k)i−1)(1

1
2 (1

(1

−

−

−

≤

(Si \

D))]

(1

(1

m)

·

−

−

≥

maxu∈N \D pi,u)

f (OP T ).

·

2/k)i) .

(1

−

Si)] = E[f (OP T

−

∪

∪

Below we prove a lower bound on the value of the solution of Algorithm 5 after any number
of iterations. However, to prove this lower bound we ﬁrst need to prove the following technical
observation.

Observation 5.8. For every positive integer i,

i−1

2
k

1

−

(cid:18)

(cid:19)

e− 2i

k

≥

k
i ·

−

ok(1) .

22

Proof. Note that

e− 2i

k =

k

e− 2
(cid:16)

i

(cid:17)
2
k

≤
i

(cid:18)

+

2
k

1

−

+

4i
k2

1

−

4
k2 ·

i

+

i

4
k2

1
k

i

(cid:19)

≤
i−1

(cid:18)

≤

(cid:19)

2
k

−

1

−

1

(cid:18)

(cid:19)
2
k

+

(cid:19)

4i
k2 ·

i

1

−

(cid:18)
e− i−1

k

2
k

i−1

+

4
k2

(cid:19)

,

1

−

≤

(cid:18)
where the third inequality holds for k
the function (1

2/k + x)i is i(1

(cid:18)

(cid:19)

≥

−

−
4/k2

4, and the second inequality holds since the derivative of

2/k + x)i−1, which implies

2
k

1

−

+

4
k2

(cid:18)

i

=

1
(cid:18)

−

(cid:19)

2
k

i

+

(cid:19)

0
Z

2/k + x)i−1dx

i(1

−

2
k

1

−

(cid:19)

≤

(cid:18)

i

+

4i
k2 (1

−

2/k + 4/k2)i−1dx .

To complete the proof of the observation, it remains to note that, since the maximum of the

function x2e−x for x

0 is 4e−2,

≥

4i
k2 ·

e− i−1

k

16e−2
i

·

≤

1
k =

e

k
i ·

ok(1) .

We are now ready to prove the promised lower bound on the value of the solution Si of Algo-

rithm 5 after any number of iterations.

Lemma 5.9. For every integer 0

i

≤

≤

k/ε,

E[f (Si)]

1 + m
4

·

≥

(cid:20)

1

−

(cid:16)

e− 2i

k

+

(1

m)i

−
2k

e− 2i

k

·

−

ok(1)
(cid:21)

·

f (OP T ) .

(cid:17)

Proof. For i = 0 the lemma follows from the non-negativity of f since the right hand side of the
inequality that we need to prove is non-positive for i = 0. Together with Observation 5.8, this
implies that it suﬃces to prove the following inequality

E[f (Si)]

1 + m
4

≥ "

1

−

·  

1
(cid:18)

−

2
k

i

!

(cid:19)

(1

+

m)i

−
2k

1

−

·

(cid:18)

2
k

(cid:19)

i−1

# ·

f (OP T ) ,

(6)

and the rest of the proof is devoted to this goal.

i

≤

Fix an arbitrary integer 1

k/ε. We would like to derive a lower bound on the expected
≤
marginal contribution of the element ui to the set Si−1, and an upper bound on the expected
marginal contribution of the element g(ui) to the set Si−1 \
g(ui). Let Ai−1 be an event ﬁxing
Ai−1 be the set of
all random choices of Algorithm 5 up to iteration i
all possible Ai−1 events. Conditioned on any event Ai−1 ∈ Ai−1, the sets Si−1 and Mi becomes
deterministic, and we can deﬁne M ′
Si−1 plus enough
dummy elements of D

i as a set containing the elements of OP T

Si−1 to make the size of M ′

1 (including), and let

i exactly k. Then,

−

\

\

E[f (u

Si−1)

|

|

Ai−1] =

=

u∈Mi

Si−1)

f (u
k

|

u∈OP T \Si−1
k

f (u

|

P

P

u∈M ′
i

f (u

|

Si−1)

k
f (OP T

≥ P
Si−1)

≥

∪

Si−1)
k

−

f (Si−1)

,

where Si, Mi and M ′
the deﬁnition of Mi and the second inequality holds by the submodularity of f . Similarly,

i represent here their values conditioned on Ai, the ﬁrst inequality follows from

E[f (g(ui)

Si−1 −

|

g(ui))

|

Ai−1] =

u∈Mi

f (g(ui)
k

P

Si−1 −

|

g(u))

f (Si−1)
−
k

≤

f (∅)

f (Si−1)
k

,

≤

23

where the ﬁrst inequality follows from the submodularity of f . Taking expectation over the event
Ai−1, we get

E[f (ui |

Si−1)]

≥

E[f (OP T

∪

1
2 (1 + m + (1

−

Si−1)]
k
m)(1

−

E[f (Si−1)]

−

2/k)i−1)
k

≥
where the last inequality is due to Observation 5.7, and

f (OP T )

·

−

E[f (Si−1)]

,

E[f (g(ui)

Si−1 −

|

g(ui))]

≤

E[f (Si−1)]
k

.

Combing the last two inequalities now yields

E[f (Si)]

E[f (Si−1 −

g(ui) + ui)]
≥
= E[f (Si−1)] + E[f (ui |
E[f (Si−1)] + E[f (ui |
≥
1

E[f (Si−1)] +

≥

(cid:18)

−

·

(cid:19)

2
k

g(ui))]
E[f (g(ui)

Si−1 −
Si−1)]
−
1
2 (1 + m + (1

−

E[f (g(ui)
|
Si−1 −
|
m)(1
−
k

−

Si−1 −
g(ui)]
2/k)i−1)

(7)

g(ui)]

f (OP T )

·

,

where the ﬁrst inequality follows from the submodularity of f since g(ui)
and ui ∈
every integer 0

Since Inequality (7) holds for every integer 1

k/ε,

Mi.

≤

≤

i

i

≤

≤

= ui because g(ui)

Si−1

∈

k/ε, we can use it repeatedly to get, for

E[f (Si)]

1
2k 

≥

i

(1 + m)

1

2
k

−

i−j

+ (1

i

m)

−

Xj=1 (cid:18)
Since the non-negativity of f guarantees that f (S0)
and therefore, completes the proof of the lemma.

(cid:19)



≥

Xj=1 (cid:18)

2
k

1

−

i−1



·

(cid:19)

f (OP T ) +

1

(cid:18)

2
k

−

i

·

(cid:19)

f (S0) .

0, the last inequality implies Inequality (6),



−

One can show that the lower bound for f (Si) proved by Lemma 5.9 is maximized when i =
m). Unfortunately, we cannot simply plug this i value into the lower bound due to two
k/(1
issues: this value of i might not be integral, and this value of i might be larger than the number
k/ε of iterations. The following two lemmata prove the approximation guarantee of Theorem 5.3
despite these issues, and together they complete the proof of the theorem.

Lemma 5.10. When m

1

−

≤

ε, the approximation ratio of Algorithm 5 is at least

1 + m + e−2/(1−m)
4

−

ok(1) .

. Due to the condition of the lemma, Algorithm 5 makes at least i′
Proof. Let i′ =
m)
⌋
iterations. Furthermore, since Algorithm 5 makes a swap in its solution only when this swap is
beneﬁcial, the expected value of the output of the algorithm is at least

k/(1
⌊

−

′

e− 2i

k

(1

+

(cid:17)
k − 2
1−m

2

+

m)i′

−
2k
k

1
−
2k ·

′

e− 2i

k

·
e− 2

1−m

−

−

E[f (Si′)]

1 + m
4
1 + m
4

1 + m
4

·

·

·

≥

≥

(cid:20)

(cid:20)

≥ "

1

(cid:16)
1

(cid:16)

−

e

−

e− 2

1−m

1

−

(cid:16)

(cid:17)

2
k

e

−

(cid:17)

f (OP T )

f (OP T )

·

ok(1)
(cid:21)
ok(1)
(cid:21)
1
2k −

−

·

e− 2

1−m

ok(1)

# ·

f (OP T ) ,

1

+

1
2 ·

−
2

24

6
x/(1+x)
1−x/(1+x) =

−

x.

−

where the ﬁrst inequality follows from Lemma 5.9, and the second inequality holds since k/(1
m). Since the terms e2/k−1
m)
can be replaced with ok(1)), the last inequality implies the lemma.

−
2k are both diminishing with k (and therefore,

and 1

k/(1

≤

−

≤

−

i′

1

2

Lemma 5.11. When 1

ε

−

≤

m < 1, the approximation ratio of Algorithm 5 is at least

1 + m + e−2/(1−m)
4

ε

−

−

ok(1) ,

and when m = 1 the approximation ratio of this algorithm is at least 1/2

ε

−

−

ok(1).

Proof. The output set of Algorithm 5 is f (Sk/ε). By Lemma 5.9, the expected value of this set is
at least

E[f (Sk/ε)]

·

1 + m
4
≥
(cid:20)
1 + m
4
·
1 + m
2(ε + 2) −

(cid:16)

1

1

−

(cid:16)

−

e− 2

ε

(cid:17)

ok(1)
(cid:21)

·

≥

=

(cid:20)

(cid:20)

e− 2

ε

1

+

m

−
2ε

e− 2

ε

·

−

−

(cid:17)
ok(1)
(cid:21)
f (OP T )

f (OP T )

·

o1(k)
(cid:21)
1 + m
4

≥

f (OP T )

·

1 + m

≥

(cid:20)

4 −

(cid:20)
ε
4 −

·

(cid:18)
ok(1)
(cid:21)

f (OP T ) ,

·

1

1
1 + 2/ε

−

ok(1)
(cid:21)

·

−

(cid:19)

f (OP T )

where the third inequality holds since for every x

0, ln(1/(1 + x)) = ln(1

x/(1 + x))

−

≥

≥

The above inequality completes the proof for the case of m = 1. To complete the proof also for

the case of 1

ε

−

≤

m < 1, it suﬃce to observe that in this case

e−2/(1−m)

e−2/ε

≤

1

≤

1 + 2/ε ≤

ε
2

.

5.4

Inapproximability for a Matroid Constraints

In this section we prove Theorem 5.4, which we repeat here for convenience.

Theorem 5.4. For any constant ε > 0, no polynomial time algorithm can obtain an approximation
ratio of

min
α∈[0,1]

max
x∈[0,1/2]{

α(mx2 + 2x

2x2) + 2(1

α)(1

−

−

e−1/2)(1

(1

m)x)
}

−

−

+ ε

−

for the problem of maximizing a non-negative m-monotone submodular function subject to a matroid
constraint.

I

I

I

except for the following diﬀerence. In

The proof of Theorem 5.4 is very similar to the proof of Theorem 4.3. Recall that in Section 4.3,
of submodular maximization subject to a
we proved Theorem 4.3 by constructing an instance
cardinality constraint, and then applying Theorem 3.3 to this instance. The proof of Theorem 5.4
′ of submoduar maximization subject to a matroid constrained that is
is based on an instance
identical to
, the constraint is a cardinality constraint
′,
allowing the selection of up to 2 elements from the ground set
we have instead a (simpliﬁed) partition matroid constraint allowing the selection of up to 1 element
from

ai, bi |
{
stated in Lemma 4.7 apply to both of them. Furthermore, one can verify that
symmetric with respect to the group
concentrate on analyzing the symmetry gap of

′ have the same objective function, the properties of this function
′ is strongly
of permutation deﬁned in Section 4.3. Therefore, we

and up to 1 element from

Since the instances

. In
[r]
}

ai, bi |

a, b
{

a, b
{

.
[r]
}

} ∪ {

and

N

=

∈

∈

′.

G

I

I

I

I

I

}

i

i

I

25

Lemma 5.12. The symmetry gap of

′ is at most

I

max
x∈[0,1/2]{

α(mx2 + 2x

max
x∈[0,1/2]{

α(mx2 + 2x

≤

2x2) + 2(1

2x2) + 2(1

−

−

α)[1

α)(1

−

−

−

−

(1

1/(2r))r](1

(1

m)x)
}

−

−

−
e−1/2)(1

(1

m)x)
}

−

−

+ 1/(2r) .

′ is the set

I

a, b1}
{

α(mx2 + 2x

whose value according to f is 1.
Proof. One possible feasible solution for
′ is at least 1. Since the symmetry gap is the
Therefore, the value of the optimal solution for
I
ratio between the value of the best symmetric solution and the value of the best solution, to prove
the lemma it remains to argue that the best symmetric solution for
has a value of at most
maxx∈[0,1/2]{

We remind the reader that a symmetric solution for
r

[0, 1]N
1. Since a and b can be exchanged with each other by
obeying ya + yb ≤
, the values of the coordinates of a and b in ¯y must be equal to each other.
the permutations of
Similarly, every two elements of
, and
[r]
}
therefore, the values of the coordinates of all these elements in ¯y must be all identical. Thus, any
symmetric solution ¯y can be represented as

i=1 yai + ybi ≤
i
ai, bi ∈
{

I
.
m)x)
}
′ is ¯y = Eσ∈G [y] for some vector y

can be exchanged by the permutations of

1/(2r))r](1

2x2) + 2(1

1 and

α)[1

P

(1

(1

−

−

−

−

−

−

∈

∈

G

G

I

¯yu =

x if u = a or u = b ,
z
(

if u

i

ai, bi |

∈ {

∈

[r]
}

for some values x
multilinear extension F of f ) is

[0, 1/2] and z

∈

[0, 1/(2r)]. The value of this solution (according to the

∈

−

α[m(1

(1
−
= α(mx2 + 2x
α(mx2 + 2x

x)2) + 2(1
−
2x2) + 2(1
2x2) + 2(1

−

−

≤

m)x(1

α)(1

α)(1

−

−

−

−

−

(1

α)(1

x)] + 2(1
−
z)r)(1
(1
1/(2r))r)(1

−

−

(1

−

−

−

(1

−

−
m)x)

m)x) .

(1

−

z)r)(1

(1

−

−

m)x)

′ by
Therefore, one can obtain an upper bound on the value of the best symmetric solution for
taking the maximum of the last expression over all the values that x can take, which completes the
proof of the lemma.

I

Since any reﬁnement of a (simpliﬁed) partition matroid constraint is a (generalized) partition
matroid constraint on its own right, plugging Lemmata 4.7 and Lemma 5.12 into Theorem 3.3
yields the following corollary.

Corollary 5.13. For every constant ε′ > 0, no polynomial time algorithm for maximizing a non-
negative m-monotone submodular function subject to a matroid contraint obtains an approximation
ratio of

max
x∈[0,1/2]{

α(mx2 + 2x

2x2) + 2(1

α)(1

−

−

e−1/2)(1

(1

m)x)
}

−

−

−

+ 1/(2r) + ε′

.

Theorem 5.4 now follows from the last corollary by choosing ε′ = ε/2, r =

ε−1
⌈

⌉

and

α = arg min
α′∈[0,1]

max
x∈[0,1/2]{

α′(mx2 + 2x

2x2) + 2(1

α′)(1

−

−

e−1/2)(1

(1

m)x)
}

−

−

.

−

26

6 Applications and Experiment Results

Many machine learning applications require optimization of non-monotone submodular functions
subject to some constraint. Unfortunately, such functions enjoy relatively low approximation guar-
antees. Nevertheless, in many cases the non-monotone objective functions have a signiﬁcant mono-
tone component that can be captured by the monotonicity ratio. In this section, we discuss three
concrete applications with non-monotone submodular objective functions. For each application we
provide a lower bound on the monotonicity ratio m of the objective function, which translates via
our results from the previous sections into an improved approximation guarantee for the application.
To demonstrate the value of our improved guarantees in experiments, we took the following
approach. The output of an approximation algorithm provides an upper bound on the value of
the optimal solution for the problem (formally, this upper bound is the value of the output over
the approximation ratio of the algorithm). Thus, we plot in each experiment the upper bound on
the value of the optimal solution obtained with and without taking into account the monotonicity
ratio, which gives a feeling of how the magnitude of our improvements compare to other values of
interest (such as the gaps between the performances of the algorithms considered).

6.1 Personalized Movie Recommendation

The ﬁrst application we consider is Personalized Movie Recommendation. Consider a movie rec-
ommendation system where each user speciﬁes what genres she is interested in, and the system has
to provide a representative subset of movies from these genres. Assume that each movie is repre-
sented by a vector consisting of users’ ratings for the corresponding movie. One challenge here is
that each user does not necessarily rate all the movies, hence, the vectors representing the movies
do not necessarily have similar sizes. To overcome this challenge, a low-rank matrix completion
techniques [10] can be performed on the matrix with missing values in order to obtain a complete
rating matrix. Formally, given few ratings from k users to n movies we obtain in this way a rating
matrix M of size k
n. Following [39], to score the quality of a selected subset of movies, we use
×
the following function.

f (S) =

λ

su,v .

(8)

su,v −

N

is the set of n movies, λ

Xu∈N Xv∈S
Here,
[0, 1] is a parameter and su,v denotes the similarity between
movies u and v (the similarity su,v can be calculated based on the matrix M in multiple ways:
cosine similarity, inner product, etc). Note that the ﬁrst term in the deﬁnition of f captures the
coverage, while the second term captures diversity. Thus, the parameter λ denotes the importance
of diversity in the returned subset.

Xu∈S Xv∈S

∈

One can verify that the above deﬁned function f is non-negative and submodular. The next
In this theorem we assume that the
theorem analyzes the monotonicity ratio of this function.
similarity scores su,v are non-positive and obey the equality su,v = sv,u for every u, v
. Note
that the above mentioned ways to deﬁne these scores have these properties. Interestingly, it turns
out that the function f is monotone when λ is small enough despite the fact that this function
is traditionally treated as non-monotone (e.g., in [22, 39]). This is a welcomed unexpected result
of the use of the monotonicity ratio, which required us to really understand the degree of non-
monotonicity represented by the objective function.

∈ N

Theorem 6.1. The objective function f is monotone for 0
1/2

1.

λ

≤

≤

λ

≤

≤

1/2 and 2(1

−

λ)-monotone for

27

Proof. We ﬁrst prove the ﬁrst part of the theorem. Thus, we assume λ
show that for arbitrary set S
non-negative. This holds because

and element u

∈ N \

⊆ N

S the marginal contribution f (u

≤

1/2, and we need to
S) is

|

f (u

|

S) =

=

Xv∈N

Xv∈N

sv,u −

λ

"

Xv∈S

sv,u −

λ

2

"

Xv∈S

su,v +

sv,u + su,u

#

Xv∈S

sv,u + su,u

# ≥

Xv∈N

sv,u −

Xv∈S

sv,u −

su,u ≥

0 ,

where the second equality holds because su,v = sv,u, and the ﬁrst inequality holds since λ
the case we consider and the su,v values are non-negative.

≤

1/2 in

It remains to prove the second part of the theorem. Thus, we assume from now on λ

[1/2, 1],

and we consider two sets S
2(1

λ)

≥
f (S). The ﬁrst step towards showing this is to prove the following lower bound on f (S).

⊆ N

⊆

T

. To prove the theorem we need to show that f (T )

∈

−

·

f (S) = 2(1

2(1

≥

λ)

λ)

·

·

−

−

f (S) + (2λ

f (S) + (2λ

1)

1)

−

−

where the inequality holds since λ
lower bound, we now get

≤

·

su,v −

λ

· "

Xu∈N Xv∈S

su,v

#

Xu∈S Xv∈S
λ)

−

·

su,v = 2(1

f (S) + (2λ

1)

·

−

(9)

su,v ,

Xu∈T \S Xv∈S
1, and the second equality holds since su,v = sv,u. Using this

Xu∈S Xv∈T \S

f (T ) = f (S) +

su,v −

Xu∈N Xv∈T \S

su,v +

Xu∈T \S Xv∈S

su,v +

Xu∈T \S Xv∈T \S

su,v


λ

λ


Xu∈S Xv∈T \S

2


su,v −

= f (S) +

Xu∈N Xv∈T \S
2λ)

−

·

f (S) + (1

≥

su,v +

su,v


Xu∈T \S Xv∈T \S
f (S) ,

Xu∈S Xv∈T \S

2(1
su,v ≥

−

λ)

·

Xu∈S Xv∈T \S

where the ﬁrst inequality holds since λ

≤

1, and the second inequality holds by Inequality (9).

To demonstrate the value of our lower bound on the monotonicity ratio, we followed the exper-
imental setup of the prior work [39] and used a subset of movies from the MovieLens data set [28]
which includes 10,437 movies. Each movie in this data set is represented by a 25 dimensional
feature vector calculated using user ratings, and we used the inner product similarity to obtain the
similarity values su,v based on these vectors.

In our experiment we employed accelerated versions of the algorithms analyzed in Section 4 for a
cardinality constraint. Speciﬁcally, instead of the Greedy algorithm we used Threshold Greedy [1]
and Sample Greedy [40]; and instead of Random Greedy we used a threshold based version of
this algorithm due to [8] that we refer to as Threshold Random Greedy.7 All three algorithms
had almost identical performance in our experiments (see Appendix B), and therefore, to avoid
confusion, in the plots of this section we draw only the output of Threshold Random Greedy.

7Algorithm 6 in [8].

28

l

e
u
a
V
e
v
i
t
c
e
j
b
O

7

6

5

4

3

2

1

0

×105

×107

×107

Threshold Random Greedy
Random
Previous Upper Bound
Our Upper Bound

l

e
u
a
V
e
v
i
t
c
e
j
b
O

1.0

0.8

0.6

0.4

0.2

0.0

Threshold Random Greedy
Random
Previous Upper Bound
Our Upper Bound

l

e
u
a
V
e
v
i
t
c
e
j
b
O

1.0

0.8

0.6

0.4

0.2

0.0

0.5

0.6

0.7

λ value

0.8

0.9

20

40

60

80

100

120

140

20

40

60

80

100

120

140

Number of Movies

Number of Movies

(a) Results when up to 10 movies
can be selected for varying λ.

(b) Results for λ = 0.55 when
the maximum number movies in
the solution varies.

(c) Results for λ = 0.85 when
the maximum number movies in
the solution varies.

Figure 4: Experimental results for Personalized Movie Recommendation. Each plot includes the
output of the algorithms we consider as well the previous and improved upper bounds on the
optimal value (the area between these two bounds is shaded).

Each plot of Figure 4 depicts the outputs of Threshold Random Greedy and a scarecrow algo-
rithm called Random that simply outputs a random subset of movies of the required size. Each
point in the plots represents the average value of the outputs of 10 executions of these algorithms.
We also depict in each plot the upper bound on the value of the optimal solution based on the
general approximation ratio of Random Greedy and the improved approximation ratio implied by
Theorems 4.2 and 6.1—the area between the two upper bounds is shaded. In Figure 4a we plot
these values for the case in which we asked the algorithms to pick at most 10 movies, and we vary
the parameter λ. In Figures 4b amd 4c we plotted the same values for a ﬁxed parameter λ, while
varying the maximum cardinality (number of movies) allowed for the output set. Since the height
of the shaded area is on the same order of magnitude as the values of the solutions produced by
Threashold Random Greedy (especially when λ is close to 1/2), our results demonstrate that the
improved upper bound we are able to prove is much tighter than the state-of-the-art. Furthermore,
our improved upper bound shows that the gap between the empirical outputs of Threshold Random
Greedy and Random is much more signiﬁcant as a percentage of the value of the optimal solution
than one could believe based on the weaker bound.

6.2 Personalized Image Summarization

of images from ℓ disjoint categories (e.g.,
Consider a setting in which we get as input a collection
birds, dogs, cats) and the user speciﬁes r
[ℓ] categories, and then demands a subset of the images
in these categories that summarize all the images of the categories. Following [39] again, we use
the following function to evaluate a given subset of images.

N

∈

f (S) =

max
v∈S

su,v −

1

su,v ,

(10)

|N | Xu∈S Xv∈S
where su,v is a non-negative similarity between images u and v.

Xu∈N

One can verify that the above function f is non-negative and submodular. Unfortunately,
however, this function can have a very low monotonicity ratio. To compensate for this, we observe
that most the analyses we described in the previous sections use the monotonicity ratio only to
show that f (S
f (S) for sets S and T that are feasible. This motivates the following
weak version of the monotonicity ratio. We note that many continuous properties of set functions
have such weak versions. For example, the original paper presenting the submodularity-ratio [16]

T )

m

≥

∪

·

29

presented in fact the weak version of this property, and the non-weak version was only formulated
at a later point.

Deﬁnition 6.1. Consider the problem of maximizing a non-negative function f subject to some
constraint. In the context of this problem, we say that f is m-weakly monotone if for every two
feasible sets S and T it holds that f (S
f (S). Furthermore, the weak monotonicity ratio
of the problem is the maximum value m for which the above holds.

T )

m

≥

∪

·

Theorem 6.2. The objective function f given by Equation (10) is 1
the size of feasible solutions is at most k for some 1

i

.
≤ |N |

≤

2k
|N | -weakly monotone when

−

Proof. When k
two feasible sets S, T

≥ |N |

/2, the theorem is trivial. Thus, we can assume below k <

/2. Consider

|N |

, and let us lower bound f (S

T ).

∪

∈ N

f (S

∪

T ) =

Xu∈N

max
v∈S∪T

su,v −

max
v∈S∪T

su,v −

2k

|N | (cid:19) Xu∈N

≥

=

Xu∈N
1
(cid:18)

−

1

su,v

T

|N | Xu∈S∪T Xv∈S∪T
S
∪
|
|
|N | Xu∈S∪T
su,v ≥

max
v∈S∪T

1

−

max
v∈S∪T

su,v ≥
2k

(cid:18)

|N | (cid:19) Xu∈N

max
v∈S∪T

su,v −

2k

|N | Xu∈S∪T

max
v∈S∪T

su,v

Xu∈N
max
v∈S

su,v .

Using this lower bound, we now get

f (S) =

max
v∈S

su,v −

Xu∈E

1

|N | Xu∈S Xv∈S

su,v ≤

Xu∈E

max
v∈S

su,v ≤

T )

f (S
1

∪
2k/

−

|N |

,

which completes the proof of the theorem since S and T have been chosen as arbitrary feasible
sets.

Our experiments for this setting are based on a subset of the CIFAR-10 dataset [33] which
includes 10,000 Tiny Images. These images belong to 10 classes, with 1000 images per class. Each
image consists of 32
32 RGB pixels represented by a 3072 dimensional vector. To compute the
similarity su,v between images, we used the dot product.

×

In our ﬁrst experiment, we simply looked for a summary consisting of a limited number of
images. Since this is a cardinality constraint, we again used the scarecrow algorithm Random and
the accelerated versions mentioned in Section 6.1 of the algorithms from Section 4. In Figure 5a
we depict the outputs of Threshold Random Greedy and Random for various limits on the number
of images in the summary (like in Section 6.1 we omit the other non-scarecrow algorithms since
their performance is essentially identical to the one of Threshold Random Greedy, and we refer the
reader to Appendix B for more detail). Figure 5a also includes the upper bounds on the optimal
solution obtained via the previous approximation ratio for Random Greedy and our improved
approximation ratio (the area between the two upper bounds is shaded). We can see that the upper
bound obtained via our improved approximation ratio is much tighter, and this upper bound also
demonstrates that the gap between the non-scarecrow and the scarecrow algorithms is signiﬁcant
compared to the optimal solution.

In our second experiment, we looked for a summary containing up to k images from each cat-
egory selected by the user for some parameter k (we assumed in the experiment that the user
chose the categories: “airplane”, “automobile” and “bird”). Since this is a (generalized partition)

30

l

e
u
a
V
e
v
i
t
c
e
j
b
O

3.5

3.0

2.5

2.0

1.5

1.0

0.5

0.0

×107

Threshold Random Greedy
Random
Previous Upper Bound
Our Upper Bound

2

4

6

8

10

Maximum Number of Images

l

e
u
a
V
e
v
i
t
c
e
j
b
O

1.2

1.0

0.8

0.6

0.4

0.2

0.0

×107

Measured Continuous Greedy
Random Greedy for Matroids
Random
Previous Upper Bound
Our Upper Bound

1
4
Maximum Number of Images per Category

2

3

(a) Results for Personalized Image Summariza-
tion with a cardinality constraint for varying
number of images in the summary produced.

(b) Results for Personalized Image Summariza-
tion with a matroid constraint. The x-axis gives
the maximum number k of images allowed from
each category.

Figure 5: Personalized Image Summerization Results

matroid constraint, in this experiment we used versions of the algorithms from Section 5. Specif-
ically, we used Random Greedy for Matroids and an accelerated version of Measured Continuous
Greedy based on the acceleration technique underlying the Accelerated Continuous Greedy of [1].
Additionally, we used in this experiment a scarecrow algorithm called Random that outputs a set
containing a random selection of k images from each one of the chosen categories. The values of
the outputs of all these algorithms are depicted in Figure 5b (values shown are averaged over 10
executions).

Figure 5b also includes two upper bounds on the value of the optimal solution. The previous
upper bound is an upper bound computed based on the previously known approximation ratios of
Random Greedy for Matroids and Measured Continuous Greedy. In contrast, our upper bound is
computed based on the approximation ratios proved in Theorems 5.2 and 5.3 and the weak mono-
tonicity ratio proved in Theorem 6.2.8 As is evident from the similarity between Figures 5a and 5b,
our observations from the ﬁrst experiment extend also the more general constraint considered in
the current experiment.

6.3 Quadratic Programming

Consider the function

F (x) =

1
2

xT Hx + hT x + c .

(11)

By choosing appropriate matrix H, vector h and scalar c, this function can be made to have
various properties. Speciﬁcally, we would like to make it non-negative and DR-submodular (DR-
submodularity is an extension of submodularity to continuous functions—see Appendix C for more
detail). Our goal in this section is to maximize F under a polytope constraint given by

P =

x
{

Rn

≥0 |

Ax

b, x

u, A

Rm×n
≥0

, b

Rm

≥0}

≤
8From a purely formal point of view this upper bound is not fully justiﬁed since Measured Continuous Greedy is
a rare example of an algorithm whose analysis cannot use in a black box fashion the weak monotonicity ratio instead
of the monotonicity ratio. However, due to probabilistic concentration, we expect the upper bound to still hold up
to at most a small error.

≤

∈

∈

∈

31

for some dimensions n and m.

Following Bian et al. [2], we set m = n, choose the matrix H

Rn×n to be a randomly generated
1, 0],
symmetric matrix whose entries are drawn uniformly at random (and independently) from [
Rm×n to be a randomly generated matrix whose entries are drawn uniformly at
and choose A
random from [v, v + 1] for v = 0.01 (this choice of v guarantees that the entries of A are strictly
positive). We also set b = ¯1 (i.e., b is the all ones vector), and u to be the upper bound on P given
HT u for a parameter β > 0
by uj = minj∈[m] bi/Ai,j for every j
(in [2] β was ﬁxed to 0.1).

[n]. Finally, we set h =

−

−

∈

∈

∈

β

·

The non-positivity of H guarantees that f is DR-submodular. To make sure that f is also
2 xT Hx + hT x (where ¯0 is the all zeros
non-negative, the value of c should be at least
vector). This value can be approximately obtained by using quadprogIP9 [52]. Let the value of
M
M + α
this minimum be M ; then we set c =
|

|
The deﬁnition of the monotonicity ratio can be extend to the continuous setting we consider in

for some parameter α > 0.

min¯0≤x≤u

−

−

1

this section as follows.

m = inf

¯0≤x≤y≤u

F (y)
F (x)

,

where the ratio F (y)/F (x) should be understood to have a value of 1 whenever F (x) = 0. The
following theorem analyzes the monotonicity ratio of the function given in Equation (11) based on
this deﬁnition.

(0, 1/2), the objective function F given by Equation (11) is (1−2β)·α
1+α -

Theorem 6.3. For β
monotone. Furthermore, when min¯0≤x≤u( 1
Proof. Fix two vectors ¯0
≤
and an upper bound on F (x). The lower bound on F (y) is as following.

2 xT Hx + hx)

0, F is even (1

≥

≤

≤

∈

y

x

u. We begin this proof by providing a lower bound on F (y)

2β)-monotone.

−

F (y) =

1
2

yT Hy + hT y + c

min
¯0≤x≤u

≥

1
2

(cid:18)

xT Hx + hx

+ c .

(cid:19)

To get the upper bound on F (x), we ﬁrst need to prove an upper bound on c.

c

min
0≤x≤u

≥ −

1
2

xT Hx + hT x

=

min
0≤x≤u

−

(cid:18)
The promised upper bound on F (x) now follows.

(cid:19)

(cid:18)

1
2

xT Hx

−

βuT Hx

(cid:19)

1
2 −

≥ −

(cid:18)

β

uT Hu .

(cid:19)

F (x) =

1
2

xT Hx + hT x + c

hT x + c

≤

≤

hT u + c =

−

βuT Hu + c

≤

1/2

+ c =

1

β

,

2β

βc

−

c

−

where the ﬁrst inequality holds since H is non-positive, and the second inequality holds since h is
non-negative.

Recall now that c =

M
M + α
|

−

min
0≤x≤u

(cid:18)

and therefore,

, which implies
|
1
2

xT Hx + hT x

(cid:19)

= M

c
1 + α

,

≥ −

F (y)

c
1 + α

cα

+ c =

1 + α ≥
It remains to consider the case in which min¯0≤x≤u

≥ −

F (x) .

(1

2β)α

·

−
1 + α
1
2 xT Hx + hx
(cid:1)
F (x) .

0. In this case

≥

−
9We used IBM CPLEX optimization studio https://www.ibm.com/products/ilog-cplex-optimization-studio.

≥

≥

·

F (y)

c

(1

(cid:0)
2β)

32

Previous Upper Bound
Our Upper Bound
Non monotone FW

e
u
a
v

l

n
o
i
t
c
n
u
F

6

4

2

0

5.0

7.5

10.0

12.5

15.0

Dimensionality

e
u
a
v

l

n
o
i
t
c
n
u
F

1.6

1.4

1.2

1.0

0.8

0.6

0.4

0.2

0.0

0.2

0.3

0.4

e
u
a
v

l

n
o
i
t
c
n
u
F

2.00

1.75

1.50

1.25

1.00

0.75

0.50

0.25

0.00

0.8

0.9

1.0

0.05

0.10

0.15

0.20

0.25

0.30

β value

0.7

0.5

0.6

α value

(a) Varying the dimensionality n
for ﬁxed α = 0.3 and β = 0.2.

(b) Varying α for ﬁxed β = 0.2 and
n = 4.

(c) Varying β for ﬁxed α = 0.5 and
n = 4.

Figure 6: Results of the Quadratic Programming experiments.

We applied the Non-monotone Frank-Wolfe algorithm of Bian et al. [2] to the above deﬁned
optimization problem (Non-monotone Frank-Wolfe algorithm is related to the Measured Continuous
Greedy algorithm studied in Section 5.2, and we refer the reader to Appendix C for further detail
about this algorithm and its analysis). Figure 6 depicts the results we obtained. Speciﬁcally,
Figure 6a shows the value of the solution obtained by Non-monotone Frank-Wolfe for α = 0.3 and
β = 0.2 as the dimensionality n varies. The shaded area is the area between the previous upper
bound on the optimal value (that ignores the monotonicity ratio), and our upper bound that takes
advantage of the monotonicity ratio bound given by Theorem 6.3. Figures 6b and 6c are similar,
but they ﬁx the dimensionality n to be 4, and vary α or β instead. Let us discuss now some
properties of Figure 6.

• Each data point in Figure 6 corresponds to a single instance drawn from the distribution de-
scribed above. This implies that the plots in Figure 6 vary for diﬀerent runs of our experiment,
but the plots that we give represent a (single) typical run.

• The size of the the shaded area depends on α and β, but also on the sign of min¯0≤x≤u( 1

2 xT Hx+
hx). This is the reason that this size behaves somewhat non-continuously in Figure 6c.
Interestedly, the sign of this minimum is mostly a function of β. In other words, there are
values of β for which the minimum is non-negative with high probability, and other values
for which the minimum is negative with high probability.

• One can see that the use of the monotonicity ratio signiﬁcantly improves the upper bound
2 xT Hx + hx) happens to be

on the optimal value, especially when the minimum min¯0≤x≤u( 1
non-negative.

7 Conclusion

In this paper we have deﬁned the monotonicity ratio, analyzed how the approximation ratios of
standard submodular maximization algorithms depend on this ratio, and then demonstrated that
this leads to improved approximation guarantees for the applications of movie recommendation, im-
age summarization and quadratic programming. We believe that the monotonicity ratio is a natural
parameter of submodular maximization problems, reﬁning the binary distinction between mono-
tone and non-monotone objective functions and improving the power of submodular maximization
tools in machine learning applications. Thus, we hope to see future work towards understanding

33

 
the optimal dependence on m of the approximation ratios of various submodular maximization
problems.

An important take-home message from our work is that, at least in the unconstrained submod-
ular maximization case, the optimal algorithm has an approximation ratio whose dependence on
m is non-linear. Such algorithms are rarely obtained using current techniques, which might be one
of the reasons why these techniques have so far failed to obtain tight approximation guarantees for
constrained non-monotone submodular maximization.

A Proof of Theorem 3.3

In this section, we show how the proof of the symmetry gap technique due to Vondr´ak [51] can be
adapted to prove Theorem 3.3. Let us begin the section by restating the theorem itself.

Theorem 3.3. Consider a non-negative m-monotone submodular function f and a collection
F ⊆
2N of feasible sets such that the problem max
is strongly symmetric with respect to
be the class of problems
some group
in which ˜f is a non-negative m-monotone submodular function, and ˜F is a
˜f (S)
max
{
reﬁnement of F . Then, for every ε > 0, any (even randomized) (1 + ε)γ-approximation algorithm
for the class

∈
would require exponentially many value queries to ˜f .

and has a symmetry gap γ. Let

of permutations over

f (S)
{

∈ F}

G
S

˜F

N

S

C

}

|

|

C

The crux of the symmetry gap technique is two lemmata due to [51] that we restate below.
Lemma A.1 shows that given a non-negative set function f , one can obtain from it two continuous
versions: a continuous version ˆF that resembles f itself, and a continuous version ˆG that resembles
a symmetrized version of f . Distinguishing between ˆF and ˆG is diﬃcult, however, this does
not translate into an hardness for discrete problems since ˆF and ˆG are continuous. Therefore,
Vondr´ak [51] proved also Lemma A.2, which shows how these continuous functions can be translated
back into set functions with appropriate properties.

Lemma A.1 (Lemma 3.2 of [51]). Consider a function f : 2N
of permutations
N
Eσ∈G[1σ(x)] and ﬁx any ε > 0. Then, there is δ > 0 and functions ˆF , ˆG : [0, 1]N
also symmetric with respect to

R≥0 invariant under a group
. Let F (x) be the multilinear extension of F , deﬁne ¯x =
R≥0 (which are

), satisfying the following:

on the ground set

→

→

G

G

[0, 1]N , ˆG(x) = ˆF (¯x).
∈
ˆF (x)
[0, 1]N ,
F (x)
∈
|
x
¯x
k2 ≤
k

1. For all x
2. For all x
3. Whenever
4. The ﬁrst partial derivatives of ˆF and ˆG are absolutely continuous.
0 and ∂ ˆG
5. If f is monotone, then, for every element u
∂2 ˆF
,

, ∂ ˆF
6. If f is submodular then, for every two elements u, v

δ, ˆF (x) = ˆG(x) and the value depends only on ¯x.

∂xu ≥

∂xu ≥

∈ N

| ≤

−

−

ε.

everywhere.

∈ N

∂xu∂xv ≤

0 everywhere.
∂2 ˆG

0 and

∂xu∂xv ≤

0 almost

Lemma A.2 (Lemma 3.1 of [51]). Let n be a positive integer, and let F : [0, 1]N
→
If we deﬁne f : 2N ×X
. Then,
X)
|

R≥0 so that f (S) = F (x), where xu = 1
n |

1. if ∂F
2. and if the ﬁrst partial derivatives of F are absolutely continuous and

0 everywhere for each element u

u
(
{
, then f is monotone,

∂xu ≥

∈ N

} ×

→

∩

S

R and X = [n].

∂2F

∂xu∂xv ≤

0 almost

everywhere for all elements u, v

, then f is submodular.

∈ N

One can note that the above lemmata have the property that if the function f plugged into
Lemma A.1 is monotone, then the discrete functions obtained by applying Lemma A.2 to the
functions ˆF and ˆG are also monotone. This is the reason that the framework of [51] applies to

34

monotone functions (as well as general, not necessarily monotone, functions). Therefore, to get
the proof of [51] to yield Theorem 3.3, it suﬃces to prove the following two modiﬁed versions of
Lemmata A.1 and A.2. These modiﬁed versions preserve m-monotonicity for any m
[0, 1], rather
than just standard monotonicity.

∈

R≥0 that is m-
Lemma A.3 (modiﬁed version of Lemma A.1). Consider a function f : 2N
→
. Let F (x) be the
monotone and invariant under a group of permutations
on the ground set
multilinear extension of F , deﬁne ¯x = Eσ∈G[1σ(x)] and ﬁx any ε > 0. Then, there is δ > 0
and functions ˆF , ˆG : [0, 1]N
), satisfying the
following:

R≥0 (which are also symmetric with respect to

N

G

G

→
[0, 1]N , ˆG(x) = ˆF (¯x).
1. For all x
∈
ˆF (x)
[0, 1]N ,
F (x)
2. For all x
∈
|
¯x
x
3. Whenever
k2 ≤
k
4. For every two vectors x, y
5. If f is submodular then, for every two elements u, v

[0, 1]N obeying x

| ≤

≤

−

−

ε.

∈

everywhere.

δ, ˆF (x) = ˆG(x) and the value depends only on ¯x.

y, m

F (y).

F (x)
,

·
∈ N

≤
∂2 ˆF
∂xu∂xv ≤

0 and

∂2 ˆG

∂xu∂xv ≤

0 almost

Lemma A.4 (modiﬁed version of Lemma A.2). Let n be a positive integer, and let F : [0, 1]N
and X = [n]. If we deﬁne f : 2N ×X
Then,

R≥0 so that f (S) = F (x), where xu = 1
n |

u
(
{

→

∩

S

} ×

R
→
.
X)
|

1. if for some value m
[0, 1]N that obey x

[0, 1] the inequality m
∈
y, then f is m-monotone,
2. and if the ﬁrst partial derivatives of F are absolutely continuous and

≤

≤

F (x)

·

F (y) holds for any two vectors x, y

∈

∂2F

∂xu∂xv ≤

0 almost

everywhere for all elements u, v

, then f is submodular.

∈ N

The proof of Lemma A.3 is quite long and appears below. However, before getting to this proof,

let ﬁrst give the much simpler proof of Lemma A.4.

Proof of Lemma A.4. The second point in Lemma A.4 follows immediately from Lemma A.2, so
F (y) for
we concentrate on proving the ﬁrst point. In other words, we assume that m
every two vectors x, y
f (T ) for every
.
two sets S
Let us deﬁne two vectors x(S), x(T )

[0, 1]N as follows. For every u

y, and we need to show that m

[0, 1]N obeying x

·
f (S)

F (x)

⊆ N

≤

≤

≤

⊆

∈

T

·

,

⊆

∈ N

x(S)
u =

1
n |

S

u
(
{

} ×

X)
|

∩

and x(T )

u =

1
n |

T

u
(
{

} ×

X)
|

∩

.

x(T ), which implies m
Since S
proves the lemma since f (S) = F (x(S)) and f (T ) = F (x(T )) by the deﬁnition of f .

T , we get x(S)

F (x(S))

≤

⊆

≤

F (x(T )); and the last inequality

·

We now get to the proof of Lemma A.3. We use in this proof functions ˆF and ˆG that are similar
to the ones constructed by Vondr´ak [51] in the proof of Lemma A.1. Speciﬁcally, like in the proof
of [51], we deﬁne

ˆG(x) = G(x) + 256M

αJ(x) ,

|N |

where M is the maximum value that the function f takes on any set, G is a symmetrized version
of the multilinear extension F of f deﬁned as G(x) = F (¯x), J(x) ,
u∈N xu −
2, and α is a positive value that is independent of x. Similarly, the function ˆF was

2 + 3

|N | ·

|N |

u∈N xu

P

deﬁned by Vondr´ak [51] as
(cid:0)P

(cid:1)

ˆF (x) = ˜F (x) + 256M

αJ(x) ,

|N |

35

where the function ˜F interpolates between the multilinear extension F of f and its symmetrized
version G, and is given by

˜F (x) = (1

φ(D(x)))

·

−

F (x) + φ(D(x))

G(x) .

·

¯x

−

x
k

2, and φ : R≥0 →
2
k

Here, D(x) ,
lemma.
Lemma A.5 (Lemma 3.7 of [51]). For any α, β > 0, there is δ > (0, β) and a function φ : R≥0 →
[0, 1] with an absolutely continuous ﬁrst derivative such that

[0, 1] is a function which is deﬁned using the following

• For t
[0, δ], φ(t) = 1.
∈
• For t
β, φ(t) < e−1/α.
≥
• For all t
tφ′(t)
|
• For almost all t
0,

0,

≥

4α.
| ≤
t2φ′′(t)
|

| ≤

≥

10α.

ε

2000M |N |3 and β =

Vondr´ak [51] proved that the above functions ˆF and ˆG have all the properties guaranteed by
Lemma A.1 for the δ whose existence is guaranteed by Lemma A.5 when the values of α and β are
16M |N | . Moreover, the proof of [51] continues to work as long
set to be α =
ε
as α
and
, and we prove only the part of Lemma A.3 that is not stated in the guarantees
β = min
of Lemma A.1, which is Property 4 of the lemma. We begin by showing that the function ˆG indeed
has this property.

1,
16M |N | . Therefore, we assume below that α = min
{

2000M |N |3 and β
ε
α2,
16M |N | }
{

ε
2000M |N |3 }

≤

≤

ε

ε

Lemma A.6. For every two vectors x, y

[0, 1]N obeying x

∈

y, m

·

≤

ˆG(x)

≤

ˆG(y).

Proof. Consider the random sets R(¯x) and R(¯y). Since ¯x
¯y, the set R(¯y) stochastically dominates
R(¯x). In other words, one can correlate the randomness of these sets in a way that does not alter
R(¯y) holds deterministically. Assuming
their distributions, but guarantees that the inclusion R(¯x)
this done, we get

⊆

≤

G(x) = m

m

·

·

F (¯x) = m

·

E[f (R(¯x))]

≤

E[f (R(¯y))] = F (¯y) = G(y) ,

(12)

where the inequality follows from the linearity of the expectation and the m-monotonicity of f .

Observe now that for every element u

, the partial derivative of J with respect to zu at any

∈ N

point z

∈

[0, 1]N is

∂J(z)
∂zu

= 3

|N | −

2

zv ≥ |N | ≥

0 .

Xv∈N
J(x)

Hence, the inequality x
implies the lemma.

≤

y implies m

J(x)

·

≤

J(y). Together with Inequality (12), this

≤

One can observe that the arguments used to prove Inequality(12) in the proof of the last lemma
F (y), which is a fact that we use below. However, proving that ˆF also
also show that m
has this property (and therefore, obeys Property 4 of Lemma A.3) is more involved. As a ﬁrst step
towards this goal, we bound the gradient of

F (x)

≤

·

˜F (x)

−

F (x) = φ(D(x))

[G(x)

·

−

F (x)] .

The following lemma does that in the regime in which D(x) is small, and the next lemma handles
the other regime.

36

Lemma A.7. For every element u
value of the partial derivative ∂{φ(D(x))·[G(x)−F (x)]}

and vector x

∈

∈ N
∂xu

is at most 72√βM

[0, 1]N obeying D(x)

≤
72αM

β, the absolute

.
|N |

|N | ≤

Proof. Observe that

∂

φ(D(x))
{

[G(x)
·
∂xu

F (x)]
}

−

= φ′(D(x))

∂D(x)
∂xu

·

·

[G(x)

−

F (x)] + φ(D(x))

∂G(x)

·

(cid:20)

∂xu −

∂F (x)
∂xu (cid:21)

.

To use this equation to bound the absolute value of the left hand side, we need to make some
observations. First, Lemma 3.6 of [51] shows that

D(x), which implies

D(x)

k∇

k2 = 2

∂D(x)

∂xu ≤ k∇

D(x)

k2 = 2

p

D(x) .

Additionally, Lemma 3.5 of [51] shows that

G(x)
|

−

F (x)

8M

D(x), and therefore,

|N | ·

∂D(x)
∂xu

·

·

[G(x)

−

φ′(D(x))
(cid:12)
(cid:12)
(cid:12)
(cid:12)

p

φ′(D(x))

φ′(D(x))

F (x)]
(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ |

≤ |
=

| ≤
∂D(x)
∂xu (cid:12)
(cid:12)
D(x)
(cid:12)
·
(cid:12)
16M

· |

| ·

(cid:12)
(cid:12)
2
(cid:12)
(cid:12)
φ′(D(x))
p

| ·

G(x)

F (x)
|

−

8M

D(x)

|N | ·

D(x)
|
p
where the second inequality follows from Lemma A.5 and our assumption that D(x)

D(x)

|N | ·

64α

p

| ·

≤

·

βM

,

|N |

β.

≤

We now observe that

·

φ(D(x))
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:20)
φ(D(x))

≤

∂G(x)

∂xu −
G(x)

· k∇

∂F (x)
∂xu (cid:21)(cid:12)
(cid:12)
F (x)
(cid:12)
− ∇
(cid:12)

∂G(x)

= φ(D(x))

·

(cid:12)
(cid:12)
φ(D(x))
(cid:12)
(cid:12)

·

∂xu −
8M

|N | ·

k2 ≤

where the second inequality holds since Lemma 3.5 of [51] shows that
D(x); and the last inequality holds by our assumption that D(x)

∂F (x)
∂xu (cid:12)
(cid:12)
D(x)
(cid:12)
(cid:12)

p

k∇
≤

range of φ is [0, 1].
p

Combining all the above yields

βM

,

|N |

8

≤
G(x)

p
−

F (x)

8M

|N | ·
β and by recalling that the

k2 ≤

∂

φ(D(x))
{

[G(x)
·
∂xu

F (x)]
}

−

(cid:12)
(cid:12)
(cid:12)
(cid:12)

where the second inequality holds since α

1.

64α

βM

+ 8

βM

|N | ≤

72

βM

,

|N |

|N |

≤

p

p

p

(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤
and vector x

Lemma A.8. For every element u
value of the partial derivative ∂{φ(D(x))·[G(x)−F (x)]}

∈ N
∂xu

[0, 1]N obeying D(x)

∈

is at most 72αM

3/2.

|N |

β, the absolute

≥

Proof. Repeating the proof of Lemma A.7, except for the use of the inequality D(x)
does not hold in the current lemma) and the inequality φ(x)
purpose), we get

β (which
1 (which too weak for our current

≤

≤

φ(D(x))
(cid:12)
(cid:12)
(cid:12)
(cid:12)

∂G(x)

·

(cid:20)

∂xu −

∂F (x)
∂xu (cid:21)(cid:12)
(cid:12)
(cid:12)
(cid:12)

64αM

≤

|N | ·

D(x) +

φ(D(x))
|

| ·

8M

|N | ·

D(x) .

p

p

The expression φ(D(x)) can be upper bounded by e−1/α
2
¯x
x
2 ≤ |N |
k
k
−
inequality.

α by Lemma A.5. Also, D(x) =
. The lemma now follows by plugging these two upper bounds into the previous

≤

37

Corollary A.9. For every element u
derivative ∂{φ(D(x))·[G(x)−F (x)]}

∈ N
is at most 72αM

and vector x
3/2.

[0, 1]N , the absolute value of the partial

∈

∂xu

|N |
The last corollary implies that ˜F can be presented as the sum of F and a component that
changes slowly. Therefore, if we add to ˜F a function that increases quickly enough (as is done to
deﬁne ˆF ), then we should get a function that can be represented as F plus a monotone component.
This is the intuition formalized in the proof of the next lemma.
Lemma A.10. The function ˆF (x)
Proof. By the deﬁnition of ˆF (x),

F (x) has non-negative partial derivatives for every x

[0, 1]N .

−

∈

ˆF (x)

−

F (x) = ˜F (x)

F (x) + 256M

αJ(x) .

|N |

−

By Corollary A.9 and the observation that all the partial derivatives of J(x) are at least
the proof of Lemma A.6), the last equality implies, for every element u

,

∈ N

(see

|N |

≥
We are now ready to show that ˆF obeys Property 4 of Lemma A.3.

≥ −

|N |

72αM

3/2 + 256αM

2
|N |

0 .

∂[ ˆF (x)

F (x)]

−
∂xu

Lemma A.11. For every two vectors x, y

[0, 1]N obeying x

∈

y, m

·

≤

ˆF (x)

≤

ˆF (y).

Proof. Note that 1∅ = 1∅, which implies that G(1∅) = F (1∅), and therefore,

−
Plugging this observation into the deﬁnition of ˆF now gives

·

˜F (1∅)

F (1∅) = φ(D(1∅))

[G(1∅)

F (1∅)] = 0 .

−

ˆF (1∅)

F (1∅) = ˜F (1∅)

F (1∅) + 256M

−

−

αJ(1∅) = 256M

|N |

αJ(1∅) .

|N |

Since all the ﬁrst partial derivatives of ˆF (z)

F (z) are non-negative by Lemma A.10, the last

−

inequality implies

Hence,

ˆF (y)

F (y)

−

≥

ˆF (x)

F (x)

−

≥

256M

αJ(x)

|N |

0 .

≥

m

ˆF (x)

m

[F (x) + ˆF (y)

F (y)]

F (y) + m

[ ˆF (y)

F (y)]

F (y) + [ ˆF (y)

F (y)] = ˆF (y) ,

·

·

≤

·
where the second inequality holds by the discussion immediately after the proof of Lemma A.6,
and the last inequality holds since m

1 and ˆF (y)

F (y)

≤

−

≤

−

−

0.

≤

−

≥

B Additional Plots for Section 6

As discussed in Section 6, the various algorithms we use in the context of a cardinality constraint
have very similar empirical performance. Figure 7a presents the performance of all these algorithms
in the movie recommendation setting with the number of movies in the summery varying. One can
observe that the lines of the three non-scarecrow algorithms almost overlap. Figure 7b presents
the performance of the non-scarecrow algorithms in the image summarization setting.
In this
ﬁgure we had to ignore the scarecrow algorithm Random because otherwise the lines of the three
non-scarecrows algorithms are indistinguishable. Furthermore, we had to zoom in on a very small
range of y-axis values. Despite these steps, the lines of Sample Greedy and Threshold Greedy
still completely overlap, but the large zoom allows us to see that Threshold Random Greedy is
marginally worse.

38

Threshold Random Greedy
Random
Threshold Greedy
Sample Greedy

×106

4.0

3.5

3.0

2.5

2.0

1.5

1.0

0.5

0.0

l

e
u
a
V
e
v
i
t
c
e
j
b
O

20

40

60

80

100

120

140

Number of Movies

(a) Performance of the various algorithms in the
movie recommendation setting (for λ = 0.75).

l

e
u
a
V
e
v
i
t
c
e
j
b
O

1.37

1.36

1.35

1.34

1.33

1.32

×107

Threshold Random Greedy
Sample Greedy
Threshold Greedy
Random

2

4

6

8

10

Maximum Number of Images

(b) Performance of the non-scarecrow algorithms
in the image summarization setting with a car-
dinality constraint. The shaded area represents
the standard deviation of Threshold Random
Greedy.

Figure 7: Comparing the performance of algorithms for a cardinality constraint in our experiments.

C Maximizating DR-submodular Functions subject to a Polytope

Constraint

There are (at least) two natural ways in which the notion of submodularity can be extended from
set functions to continuous functions. The more restrictive of these is known as DR-submodularity
n
Xi is a closed range in R for every
(ﬁrst deﬁned by [3]). Given a domain
, positive value k
i
∈ X
and coordinate i

R is DR-submodular if for every two vectors a, b

i=1 Xi, where

[n], a function F :

[n] the inequality

X →

Q

=

X

∈

∈

F (a + kei)

F (a)

−

≥

F (b + kei)

F (b)

−

holds whenever a
(here and throughout the section ei denotes the standard i-th
basis vector, and comparison between two vectors should be understood to hold coordinate-wise).
If F is continuously diﬀerentiable, then the above deﬁnition of DR-submodulrity is equivalent to

b and b+kei ∈ X

≤

F being an antitone mapping from

∇
that obey a
Hessian is non-positive at every vector x

≤

F (a)
∈ X
b). Moreover, when F is twice diﬀerentiable, it is DR-submodular if and only if its

F (b) for every two vectors a, b

≥ ∇

∇

X

to Rn (i.e.,

In this section we consider the problem of maximizing a non-negative DR-submodular function
F : 2N
(usually polytope) con-
straint. As is standard when dealing with problems of this kind, we assume that F is L-smooth,
i.e., for every two vectors x, y

R≥0 subject to a solvable down-closed10 convex body P

it obeys

⊆ X

→

.

∈ X

∈ X

F (x)

F (y)

k2 ≤

L

x
k

y

k2

−

− ∇

k∇

for some non-negative parameter L. Additionally, for simplicity, we assume that
assumption is without loss of generality because the natural mapping from
all our results.

X

= [0, 1]n. This
to [0, 1]n preserves

X

10In Section 5.2, down-closeness of was deﬁned for the special case of P ⊆ [0, 1]N . More generally, a body P ⊆ X

is down-closed if b ∈ P implies a ∈ P for every vector a ∈ X obeying a ≤ b.

39

We analyze a variant of the Frank-Wolfe algorithm for the above problem due to [2] called Non-
monotone Frank-Wolfe. This variant was motivated by the Measured Continuous Greedy algorithm
studied in Section 5.2, and its assumes access to the ﬁrst order derivatives of F . The details of
the algorithm we consider appear as Algorithm 6. This algorithm gets a quality control parameter
(0, 1), and it is assumed that ε−1 is an integer (if this is not the case, one can ﬁx that by
ε
reducing ε by at most a factor 2). Algorithm 6 and its analysis also employ the notation deﬁned
in Section 5.2, namely, given two vectors x, y, their coordinate-wise multiplication is denoted by
x

y. Additionally, we denote by ¯0 and ¯1 the all zeros and all ones vectors, respectively.

∈

⊙

Algorithm 6: Non-monotone Frank-Wolfe(ε)
1 Let y(0)
←
2 while t
≤
s(t)
3
←
y(t+ε)
←
t
t + ε.
←
6 return y(1).

¯0 and t = 0.
1 do
arg maxx∈P x
(¯1
y(t) + ε

−
y(t))

y(t))

·
−

s(t).

⊙ ∇

((¯1

⊙

5

4

·

F (y(t))).

To analyze Algorithm 6 we need to deﬁne two additional parameters. The ﬁrst parameter is
x
k2 of P , which is a standard parameter. The other parameter is the
the diameter D = maxx∈P k
monotonicity ratio of F , which can be extended to the continuous setting we study in the following
natural way.11

m = inf

x,y∈X
x≤y

F (y)
F (x)

,

where the ratio F (y)/F (x) should be understood to have a value of 1 whenever F (x) = 0. Addi-
tionally, let us denote by o an arbitrary optimal solution for the problem described above. Using
these deﬁnitions, we are now ready to state the result that we prove for Algorithm 6.

Theorem C.1. When given a non-negative m-monotone DR-submodular function F :
and a down-closed solvable convex body P
gorithm 6) outputs a solution y

R≥0
, the Measured Greedy Frank-Wolfe algorithm (Al-
εLD2 .

P such that F (y)

1/e) + (1

(1/e)]

X →

F (o)

[m(1

⊆ X

m)

∈

≥

−

−

·

·

−

Our ﬁrst objective towards proving Theorem C.1 is to lower bound the expression F (o + y(t)
o)), which we do in the next two lemmata.

−

·

(¯1

Lemma C.2. For every integer i

[0, ε−1], y(εi)

¯0 and

≥

y(εi)
k

k∞ ≤

(1

1

−

−

ε)−i.

∈

Proof. We prove the lemma by induction on i. For i = 0, the lemma follows directly from the
initialization y(0) = ¯0 because 1
1, and
−
let us prove it for an integer 0 < i

ε)−0 = 0. Assume now that the lemma holds for i

−
1. Observe that, for every j

[n],

(1

−

≤

j = yε(i−1)
yεi

j

+ ε

·

1

yε(i−1)
j

−

sε(i−1)
j

·

≥

(cid:16)

(cid:17)

∈
yε(i−1)
j

0 ,

≥

11In Section 6.3 we showed how the monotonicity ratio can be extended to the particular continuous setting studied
in that section. The deﬁnition of Section 6.3 is obtained from the more general deﬁnition we give here by setting
X = Qn

i=1[0, ui].

40

where the ﬁrst inequality holds since yε(i−1)
s(ε(i−1))
j

≤
is non-negative by deﬁnition. Moreover,

j

1 by the induction hypothesis and the value of

j = yε(i−1)
yεi

j

+ ε

·

= ε + (1

ε)

1

yε(i−1)
j
−
(cid:16)
yε(i−1)
j

·
(cid:17)
ε + (1

−
·
h
where again the ﬁrst inequality holds since s(ε(i−1))
inequality holds by the induction hypothesis.

≤

−

·

∈ X

sε(i−1)
j

yε(i−1)
j

+ ε

1

yε(i−1)
j

≤
1

ε)

(1

−

·
(cid:16)
ε)(i−1)

−
= 1

−

−
, which implies si

i

(cid:17)
(1

−

ε)i

,

1; and the second

j ≤

Lemma C.3. For every integer i
F (o) =

m + (1

m)(1

ε)i

∈
F (o).

−

−

·

[0, ε−1], F (o + y(εi)

(¯1

·

−

o))

≥

(1

(1

−

−

m)

1

(1

−

−

ε)i

(cid:2)

(cid:0)

·

(cid:1)(cid:3)

Proof. Observe that

(cid:2)

(cid:3)

F (o + y(εi)

(¯1

·

−

o))

1

(cid:16)
1

(cid:16)
1

≥

≥
=

F (o) +

y(εi)
k

k∞ ·

F

o +

y(εi)

(¯1
·
y(εi)
k

o)
−
k∞ !

y(εi)

− k

k∞

·

(cid:17)

y(εi)

− k
(1

−

−

k∞
m)

(cid:17)
· k

·
y(εi)

(cid:16)

F (o) + m

F (o)

k∞ ·

y(εt)

· k
F (o) ,

k∞

·

(cid:17)

where the ﬁrst inequality holds since the DR-submodularity of F implies that F is concave along
(¯1
positive directions (such as the direction y(εi)
k∞), and the second inequality holds
since the monotonicity ratio of F is at least m. Plugging Lemma C.2 into the previous inequality
completes the proof of the lemma.

y(εi)
o)/
k

−

·

Using the previous lemma, we can now provide a lower bound on the increase in the value of

y(t) as a function of t.

Lemma C.4. For every integer 0
F (o)

F (y(εi))]

ε2LD2.

−

−

Proof. By the chain rule,

i < ε−1, F (y(ε(i+1)))

F (y(εi))

ε

·

≥

[(m + (1

m)

(1

·

−

−

ε)i)

·

−

≤

F (yε(i+1))

−

F (y(εi)) = F (y(εi) + ε

s(εi)

(¯1

y(εi)))

F (y(εi))

·
F (y(εi) + r

⊙
s(εi)

−

−
y(εi)))

=

ε

0 ∇
ε

Z

0 ∇

≥

Z
= ε

(¯1

−

⊙

(¯1

⊙

−

·

(s(εi)

·
(s(εi)

F (y(εi))

y(εi))) dr

ε2LD2

F (y(εi))

·

· ∇

(1

⊙

−

y(εi)))

−

−
ε2LD2 ,

(s(εi)

(¯1

⊙

−

·

y(εi))) dr

where the ﬁrst inequality holds by the L-smoothness of F . Furthermore,

F (y(εi))

(s(εi)

(¯1

⊙

−

·

∇

y(εi))) = ((¯1

y(εi))
F (y(εi)))

−

m + (1

F (y(εi)))
y(εi))
ε)i

−
(1

·

⊙

⊙ ∇
((¯1

·
m)

s(εi)

o)

≥
F (o)

((¯1

y(εi))
≥
−
F (o + y(εi)(¯1
F (y(εi)) ,

=

∇

⊙ ∇

F (y(εi)))

o
·
F (y(εi))

o))

−

−

·
where the ﬁrst inequality holds by the deﬁnition of s(εi) since o is a candidate to be this vector, the
second inequality follows from the concavity of F along positive directions, and the last inequality
holds by Lemma C.3. The lemma now follows by combining the two above inequalities.

−

−

−

≥

(cid:3)

(cid:2)

·

41

 
We are now ready to prove Theorem C.1.

Proof of Theorem C.1. Rearranging the guarantee of Lemma C.4, we get

F (yε(i+1))

(1

ε)

F (y(εi)) + ε[m + (1

≥
Since this inequality applies for every integer 0

−

·

m)

(1

·

−

−

ε)i]

·

F (o)

−

ε2LD2 .

i < ε−1, we can use it repeatedly to obtain

≤

F (y(1))

ε

·

≥

1/ε

(1

Xi=1
1/ε

ε)1/ε−i

−

·

(cid:2)

(m + (1

m)

(1

·

−

−

ε)i−1)

F (o)

·

−

εLD2

+ (1

ε)1/ε

F (¯0)

·

−

mε

·

≥

(1

1
ε −i

ε)

·

−

F (o) + ε(1

m)

·

−

Xi=1
1
−

−

(1

ε)1/ε

−
ε
e−1) + (1

·
m)

−

F (o) + ε(1

m)

−
F (o)

εLD2 ,

−

e−1

·

·

(cid:3)

= mε

·
m(1

≥

(cid:2)
ε)1/ε

1/ε

[(1

Xi=1
(1

−

·

ε)1/ε−1

F (o)

·

−

(cid:3)

−

εLD2]

ε)1/ε−1

εLD2

F (o)
·
ε

−

where the second inequality follows from the non-negativity of F , and the last inequality holds
since (1

ε)1/ε−1.

e−1

(1

−

≤

≤

−

References

[1] Ashwinkumar Badanidiyuru and Jan Vondr´ak. Fast algorithms for maximizing submodular

functions. In SODA, pages 1497–1514, 2014.

[2] An Bian, Kﬁr Yehuda Levy, Andreas Krause, and Joachim M. Buhmann. Non-monotone
continuous DR-submodular maximization: Structure and algorithms. In NeurIPS, pages 486–
496, 2017.

[3] Andrew An Bian, Joachim M. Buhmann, Andreas Krause, and Sebastian Tschiatschek. Guar-
In ICML,

antees for greedy maximization of non-submodular functions with applications.
pages 498–507, 2017.

[4] Niv Buchbinder and Moran Feldman. Submodular functions maximization problems. In Te-
oﬁlo F. Gonzalez, editor, Handbook of Approximation Algorithms and Metaheuristics, Second
Edition, Volume 1: Methologies and Traditional Applications, pages 753–788. Chapman and
Hall/CRC, 2018.

[5] Niv Buchbinder and Moran Feldman. Constrained submodular maximization via a nonsym-

metric technique. Math. Oper. Res., 44(3):988–1005, 2019.

[6] Niv Buchbinder, Moran Feldman, Joseph Naor, and Roy Schwartz. Submodular maximization
In Chandra Chekuri, editor, SODA, pages 1433–1452. SIAM,

with cardinality constraints.
2014.

[7] Niv Buchbinder, Moran Feldman, Joseph Naor, and Roy Schwartz. A tight linear time (1/2)-
approximation for unconstrained submodular maximization. SIAM J. Comput., 44(5):1384–
1402, 2015.

[8] Niv Buchbinder, Moran Feldman, and Roy Schwartz. Comparing apples and oranges: Query

trade-oﬀ in submodular maximization. Math. Oper. Res., 42(2):308–329, 2017.

42

[9] Gruia C˘alinescu, Chandra Chekuri, Martin P´al, and Jan Vondr´ak. Maximizing a monotone
submodular function subject to a matroid constraint. SIAM J. Comput., 40(6):1740–1766,
2011.

[10] Emmanuel J Cand`es and Benjamin Recht. Exact matrix completion via convex optimization.

Foundations of Computational mathematics, 9(6):717–772, 2009.

[11] Chandra Chekuri, Jan Vondr´ak, and Rico Zenklusen. Dependent randomized rounding via

exchange properties of combinatorial structures. In FOCS, pages 575–584, 2010.

[12] Lin Chen, Moran Feldman, and Amin Karbasi. Weakly submodular maximization beyond
cardinality constraints: Does randomization help greedy? In ICML, pages 803–812, 2018.

[13] Michele Conforti and G´erard Cornu´ejols. Submodular set functions, matroids and the greedy
algorithm: Tight worst-case bounds and some generalizations of the rado-edmonds theorem.
Discret. Appl. Math., 7(3):251–274, 1984.

[14] Min Cui, Donglei Du, Dachuan Xu, and Ruiqi Yang. Approximation algorithm for maximizing

nonnegative weakly monotonic set functions. In CSoNet, pages 50–58, 2021.

[15] Abhimanyu Das and David Kempe. Submodular meets spectral: greedy algorithms for subset
selection, sparse approximation and dictionary selection. In ICML, pages 1057–1064, 2011.

[16] Abhimanyu Das and David Kempe. Approximate submodularity and its applications: Subset
selection, sparse approximation and dictionary selection. J. Mach. Learn. Res., 19:3:1–3:34,
2018.

[17] Anirban Dasgupta, Ravi Kumar, and Sujith Ravi. Summarization through submodularity and
dispersion. In ACL, pages 1014–1022. The Association for Computer Linguistics, 2013.

[18] Ethan R. Elenberg, Alexandros G. Dimakis, Moran Feldman, and Amin Karbasi. Streaming
weak submodularity: interpreting neural networks on the ﬂy. In NeurIPS, pages 4047–4057,
2017.

[19] Ehsan Elhamifar and M Clara De Paolis Kaluza. Online summarization via submodular and

convex optimization. In CVPR, pages 1783–1791, 2017.

[20] Alina Ene and Huy L. Nguyen. Constrained submodular maximization: Beyond 1/e. In Irit

Dinur, editor, FOCS, pages 248–257. IEEE Computer Society, 2016.

[21] Uriel Feige, Vahab S. Mirrokni, and Jan Vondr´ak. Maximizing non-monotone submodular

functions. SIAM J. Comput., 40(4):1133–1153, 2011.

[22] Moran Feldman, Christopher Harshaw, and Amin Karbasi. Greed is good: Near-optimal

submodular maximization via greedy optimization. In COLT, pages 758–784, 2017.

[23] Moran Feldman, Joseph (Seﬃ) Naor, and Roy Schwartz. A uniﬁed continuous greedy algo-
rithm for submodular maximization. In Rafail Ostrovsky, editor, FOCS, pages 570–579. IEEE
Computer Society, 2011.

[24] M. Fisher, G. Nemhauser, and L. Wolsey. An analysis of approximations for maximizing

submodular set functions–II. Mathematical Programming, 8:73–87, 1978.

43

[25] Mehrdad Ghadiri, Richard Santiago, and F. Bruce Shepherd. A parameterized family of meta-

submodular functions. CoRR, abs/2006.13754, 2020.

[26] Mehrdad Ghadiri, Richard Santiago, and F. Bruce Shepherd. Beyond submodular maximiza-
tion via one-sided smoothness. In D´aniel Marx, editor, SODA, pages 1006–1025. SIAM, 2021.

[27] Anupam Gupta, Aaron Roth, Grant Schoenebeck, and Kunal Talwar. Constrained non-
monotone submodular maximization: Oﬄine and secretary algorithms. In WINE, pages 246–
257, 2010.

[28] F. Maxwell Harper and Joseph A. Konstan. The movielens datasets: History and context.

Acm transactions on interactive intelligent systems (TiiS), 5(4):1–19, 2015.

[29] Rishabh K. Iyer, Stefanie Jegelka, and Jeﬀ A. Bilmes. Curvature and optimal algorithms
for learning and minimizing submodular functions. In Christopher J. C. Burges, L´eon Bot-
tou, Zoubin Ghahramani, and Kilian Q. Weinberger, editors, Advances in Neural Information
Processing Systems (NeurIPS), pages 2742–2750, 2013.

[30] Rishabh Krishnan Iyer. Submodular optimization and machine learning: Theoretical results,
unifying and scalable algorithms, and applications. PhD thesis, University of Washington,
2015.

[31] Ehsan Kazemi, Shervin Minaee, Moran Feldman, and Amin Karbasi. Regularized submodular

maximization at scale. In ICML, pages 5356–5366. PMLR, 2021.

[32] Katrin Kirchhoﬀ and Jeﬀ Bilmes. Submodularity for data selection in machine translation. In

EMNLP, pages 131–141, 2014.

[33] Alex Krizhevsky. Learning multiple layers of features from tiny images. Master’s thesis,

University of Toronto, 2009.

[34] Alan Kuhnle, J. David Smith, Victoria G. Crawford, and My T. Thai. Fast maximization of
non-submodular, monotonic functions on the integer lattice. In Jennifer G. Dy and Andreas
Krause, editors, ICML, pages 2791–2800. PMLR, 2018.

[35] Jon Lee, Vahab S. Mirrokni, Viswanath Nagarajan, and Maxim Sviridenko. Non-monotone
submodular maximization under matroid and knapsack constraints. In Michael Mitzenmacher,
editor, STOC, pages 323–332. ACM, 2009.

[36] Qi Lei, Lingfei Wu, Pin-Yu Chen, Alex Dimakis, Inderjit S. Dhillon, and Michael J. Witbrock.
Discrete adversarial attacks and submodular optimization with applications to text classiﬁ-
cation. In Ameet Talwalkar, Virginia Smith, and Matei Zaharia, editors, MLSys. mlsys.org,
2019.

[37] Hui Lin and Jeﬀ Bilmes. Multi-document summarization via budgeted maximization of sub-

modular functions. In Human Language Technologies (HLT), pages 912–920, 2010.

[38] L´aszl´o Lov´asz. Submodular functions and convexity. In A. Bachem, M. Gr¨otschel, and B. Ko-
rte, editors, Mathematical Programming: the State of the Art, pages 235–257. Springer, 1983.

[39] Baharan Mirzasoleiman, Ashwinkumar Badanidiyuru, and Amin Karbasi. Fast constrained
In ICML, pages 1358–1367.

submodular maximization: Personalized data summarization.
PMLR, 2016.

44

[40] Baharan Mirzasoleiman, Ashwinkumar Badanidiyuru, Amin Karbasi, Jan Vondr´ak, and An-

dreas Krause. Lazier than lazy greedy. In AAAI, pages 1812–1818, 2015.

[41] Marko Mitrovic, Ehsan Kazemi, Moran Feldman, Andreas Krause, and Amin Karbasi. Adap-

tive sequence submodularity. NeurIPS, 32:5352–5363, 2019.

[42] Marko Mitrovic, Ehsan Kazemi, Morteza Zadimoghaddam, and Amin Karbasi. Data sum-
marization at scale: A two-stage submodular approach. In ICML, pages 3596–3605. PMLR,
2018.

[43] G. L. Nemhauser and L. A. Wolsey. Best algorithms for approximating the maximum of a

submodular set function. Mathematics of Operations Research, 3(3):177–188, 1978.

[44] G. L. Nemhauser, L. A. Wolsey, and M. L. Fisher. An analysis of approximations for maxi-

mizing submodular set functions–I. Mathematical Programming, 14:265–294, 1978.

[45] Ashkan Norouzi-Fard, Jakub Tarnawski, Slobodan Mitrovic, Amir Zandieh, Aidasadat
Mousavifar, and Ola Svensson. Beyond 1/2-approximation for submodular maximization on
massive data streams. In ICML, pages 3829–3838. PMLR, 2018.

[46] Shayan Oveis Gharan and Jan Vondr´ak. Submodular maximization by simulated annealing.

In Dana Randall, editor, SODA, pages 1098–1116. SIAM, 2011.

[47] Alexander Schrijver. Combinatorial Optimization: Polyhedra and Eﬃciency. Springer, 2003.

[48] Maxim Sviridenko, Jan Vondr´ak, and Justin Ward. Optimal approximation for submodular
and supermodular optimization with bounded curvature. Math. Oper. Res., 42(4):1197–1218,
2017.

[49] Sebastian Tschiatschek, Rishabh K Iyer, Haochen Wei, and Jeﬀ A Bilmes. Learning mixtures
of submodular functions for image collection summarization. In NeurIPS, pages 1413–1421,
2014.

[50] Sebastian Tschiatschek, Adish Singla, and Andreas Krause. Selecting sequences of items via
submodular maximization. In Satinder P. Singh and Shaul Markovitch, editors, AAAI, pages
2667–2673. AAAI Press, 2017.

[51] Jan Vondr´ak. Symmetry and approximability of submodular maximization problems. SIAM

J. Comput., 42(1):265–304, 2013.

[52] Wei Xia, Juan-Carlos Vera, and Luis F. Zuluaga. Globally solving nonconvex quadratic pro-
grams via linear integer programming techniques. INFORMS J. Comput., 32(1):40–56, 2020.

45

