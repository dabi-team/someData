A DICOM Framework for Machine Learning Pipelines against
Real-Time Radiology Images

Pradeeban Kathiravelu†, Puneet Sharma†, Ashish Sharma†, Imon Banerjee†, Hari Trivedi†,
Saptarshi Purkayastha⋄, Priyanshu Sinha‡, Alexandre Cadrin-Chenevert⋆, Nabile Safdar†, Judy
Wawira Gichoya†
†Emory University, Atlanta, GA, USA, ⋄Indiana University Purdue University, Indianapolis, IN, USA,
‡Mentor Graphics India Pvt. Ltd., Noida, India, ⋆CISSS Lanaudiere, Laval University, Quebec City, Canada

0
2
0
2

g
u
A
5

]

V

I
.
s
s
e
e
[

4
v
5
6
9
7
0
.
4
0
0
2
:
v
i
X
r
a

ABSTRACT
Real-time execution of machine learning (ML) pipelines on radiol-
ogy images is hard due to limited computing resources in clinical
environments, whereas running them in research clusters requires
efficient data transfer and processing capabilities. We propose Nif-
fler, an integrated framework that enables the execution of ML
pipelines at research clusters by efficiently querying and retrieving
radiology images from the Picture Archiving and Communication
Systems (PACS) of the hospitals. Niffler uses the Digital Imaging
and Communications in Medicine (DICOM) protocol to fetch and
store imaging data and provides metadata extraction capabilities
and Application programming interfaces (APIs) to apply filters on
the images. Niffler further enables the sharing of the outcomes
from the ML pipelines in a de-identified manner. Niffler has been
running stable for more than 19 months and has supported several
research projects at the department. In this paper, we present its
architecture and three of its use cases: an inferior vena cava (IVC)
filter detection from the images in real-time, identification of scan-
ner utilization, and scanner clock calibration. Evaluations on the
Niffler prototype highlight its feasibility and efficiency in facilitat-
ing the ML pipelines on the images and metadata in real-time and
retrospectively.

CCS CONCEPTS
• Applied computing → Health care information systems.

KEYWORDS
Machine Learning (ML), Picture Archiving and Communication
System (PACS), Digital Imaging and Communications in Medicine
(DICOM)

ACM Reference Format:
Pradeeban Kathiravelu†, Puneet Sharma†, Ashish Sharma†, Imon Banerjee†,
Hari Trivedi†, Saptarshi Purkayastha⋄, Priyanshu Sinha‡, Alexandre Cadrin-
Chenevert⋆, Nabile Safdar†, Judy Wawira Gichoya†. 2020. A DICOM Frame-
work for Machine Learning Pipelines against Real-Time Radiology Images.
In Preprint. ACM, New York, NY, USA, 7 pages. https://doi.org/XXXXX

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
Preprint, August 5, 2020, Emory University, GA, USA
© Preprint - 2020 Association for Computing Machinery.
ACM ISBN 978-x-xxxx-xxxx-x/YY/MM.
https://doi.org/XXXXX

1 INTRODUCTION
The growing ML research in radiology highlights the potential
for real-time processing of images from the hospital scanners. Ra-
diology departments consist of several clinical systems such as
PACS [17] and Vendor-Neutral Archives (VNAs) [26] that receive
images real-time from various scanners. A medical professional
requires a certain amount of time to access and process the images
produced by the scanners. Such diagnosis can be automated and
accelerated, by extracting and processing the imaging data and
their textual metadata from the healthcare images in the PACS
with the help of ML pipelines. However, clinical systems have lim-
ited processing and memory resources to execute ML pipelines
on radiology images efficiently [7]. Biomedical informatics (BMI)
research clusters and cloud environments are designed for heavy
computing workload. Despite the advancements in ML frameworks
on medicine, a real-time big data processing framework, spanning
a hospital network to a research cluster, is still lacking.

Patient wait times for examination and diagnosis significantly
impacts the effectiveness of patient care [29]. As radiologists are
often a scarce resource, their availability affects the wait times.
Rapid progress in the last decade in computer vision and natural
language processing has ignited imaginations that Artificial Intel-
ligence (AI) will lead to lower costs, fewer errors, more efficiency,
and better health care [25]. ML pipelines have been proposed to
reliably prognosis and predict cancer to mitigate the workload of
the diagnostic radiologists. Furthermore, scanner optimization and
effective scheduling of patients to the available scanners can sig-
nificantly reduce the wait times. Real-time processing of images
and their metadata can facilitate such scheduling optimizations,
by running computations and analytics on system performance
metrics.

Several factors should be satisfied to run the computational
pipelines in real-time on research clusters. First, there should a
fast and secure data transfer from the PACS to the research clusters.
Second, an efficient processing framework must be built to process
the received images, facilitating the execution of ML pipelines on
them. Enabling secured transfer and access to large volumes of data
to be processed by the algorithms is mandatory for such executions.
DICOM standardizes the format the healthcare imaging and com-
munications are stored and transferred across the network [27, 28].
DICOM network protocol facilitates the reliable transfer of imag-
ing data and Structured Reports (SR) [9] between the PACS and
computing servers such as data centers, clouds, and research clus-
ters. However, running the workflows on third-party public clouds

 
 
 
 
 
 
Preprint, August 5, 2020, Emory University, GA, USA

Kathiravelu, et al.

comes with privacy concerns on sensitive healthcare data. There-
fore, executing the ML pipelines on research clusters is often the
only viable and secure option for healthcare images with protected
health information (PHI).

This paper presents Niffler, an ML framework that retrieves
images from the PACS using DICOM network listeners, and ex-
tracts and processes metadata from the acquired images at the
research clusters. It then executes ML pipelines and real-time an-
alytics pipelines on radiology images and their textual metadata.
The data retrieval includes a push-based real-time data transfer
and query-driven specific data pulls, to analyze both real-time and
retrospective studies. We have demonstrated the capability and sta-
bility of Niffler in receiving data in real-time securely, by running
it continuously over 19 months on the research clusters to receive
images from two PACS. The Niffler prototype deployment receives
real-time data from one PACS while retrieving query-based data
from an enterprise archive PACS that stores historical data. Thus,
Niffler facilitates inference pipelines for the clinical validation of
AI models, enabling Real-Time Analytics (RTA) [32].

We propose and prototype three use cases of Niffler. The first
use case is an IVC filter detection on radiology images of modality
XR, DX, CR, DR, and DX CR, for chest, spine, abdomen, small
intestines, gallbladder, and thorax. We used the RetinaNet object
detection [20] as our IVC filter detection model on the images.
The ML pipeline understands the context of care for patients with
IVC filters, including whether the patients are anticoagulated, their
anticoagulation profile, and if they have an upcoming filter retrieval
appointment. We observe high accuracy and efficiency with Niffler
in IVC filter detection. The second use case is computing scanner
utilization by performing computations on metadata. We were able
to calculate the scanner utilization more accurately with Niffler,
compared to the clinical data warehouse (CDW) [14]. The third
use case finds the scanner clock miscalibrations by comparing the
time the real-time images are received in the research cluster with
the time the images acquired by the scanner, as indicated in the
metadata.

2 BACKGROUND AND MOTIVATION
Open-source frameworks such as PyTorch [18] and Tensorflow [1],
as well as the pre-trained models released through various model
zoos, have catalyzed the maturation frameworks for Artificial In-
telligence (AI) training. Multiple systems are now available for
testing AI models in real-life settings. A review of the exhibits at
the annual radiology meeting âĂŞ RSNA 2019 shows these tools are
developed as market places for already approved FDA algorithms
or systems embedded into existing PACS and imaging equipment
like chest Xrays. The American College of Radiology has developed
an open-source system called the ACR AI-LAB [3] to democratize
AI among radiologists by supporting on-premise federated learning.
Niffler aims to execute ML pipelines in the CPUs and GPUs readily
available in the research clusters on the radiology images retrieved
in real-time. It facilitates the validation of the ML pipelines and
integration with systems such as the ACR AI-LAB.

Real-time decision-making pipelines for radiologists support
triage of emergent studies and reduce the rate of addendums [6]. It
also supports direct calls from the referring doctor to the correct

person, such as calls to technologists when a study is ordered and
not performed, and to the reading room when a study has been
dictated. Researchers have built a web-based framework for quan-
titative imaging informatics [11]. The framework offers radiology
image metadata with the Annotation and Image Markup (AIM)
standard [24], and implements AIM as a web service with semantic
image annotation. It is extensible but is limited in its capabilities.
For example, a de-identification pipeline cannot be attached to it.
Rather, DICOM images must be manually de-identified to provide
anonymization before loading them to the web service. Through
its extensible and compact architecture, Niffler also supports the
integration of features such as de-identification and conversion
between various image formats.

Despite advances in AI in medicine, there is a low rate of val-
idation of medical imaging AI studies where only 6% (31/516) of
published studies in 2018 performed external validation (i.e., diag-
nostic cohort, multi-institution data, prospective) [19]. Even the
FDA’s streamlined AI approval process often only requires a few
test samples, with further testing viewed as post-marketing surveil-
lance [12, 13]. Beyond infrastructure for training algorithms, there
is still a critical gap in providing tooling to help inference evalua-
tion of AI systems in local systems before large scale deployment.
Real-life testing of ML pipelines can take months to set up after the
initial training, with time invested in developing imaging streams
that are not in production, security requirements for on-premise
deployment and with minimal disruption on the workflow. Among
20 ML articles in Nature Medicine in 2018/2019, only one had a
graphical user interface for model interaction, while ten provided
code that requires significant time to set up [2]. Niffler aims to
provide a framework that is easy to configure and use, to retrieve
images and run ML pipelines natively on the research clusters with
its support for containerized ML workflows.

AI models are brittle, and they do not generalize. Dataset shift
refers to original training data characteristics change, causing de-
clines in AI performance over time [30]. It requires continuous
monitoring and recalibration. Differences in radiology equipment
within/across institutions affect generalizability, and a model can
learn and fine-tune itself based on equipment-specific details, affect-
ing performance and clinical utility [35]. Clinical features like chest
tubes for pneumothorax undermine model performance, as they
detect the tubes rather than pneumothorax [31]. Niffler queries
and retrieves DICOM data with minimal latency, and facilitates
subsequent extraction and processing of imaging data and the tex-
tual metadata. Thus, Niffler supports continuous monitoring and
recalibration for various ML workflows for multiple studies based
on pre-defined filters.

There is a gap between engineering metrics to evaluate algo-
rithms, and what is clinically useful. Model results are typically
presented as confusion matrices or ROC (Receiver Operating Char-
acteristic) curves, but they do not translate to clinical use. Identify-
ing sampling biases usually requires manual review and domain
expertise and may not be apparent during model testing before
actual images are reviewed. Most significantly, radiologists must
participate in AI development, collect test cases, establish ground
truth, choose appropriate metrics and performance thresholds, and
evaluate test cases with continuously monitoring outputs. Our vi-
sion for Niffler is to develop and test an AI inference pipeline that

A DICOM Framework for Machine Learning Pipelines against Real-Time Radiology Images

Preprint, August 5, 2020, Emory University, GA, USA

combines clinical and imaging data. Thus, we aim to facilitate radi-
ologists’ participation in AI clinical validation.

3 THE NIFFLER FRAMEWORK
We designed Niffler as a framework that retrieves DICOM images
real-time and on-demand from PACS to a research cluster. By ex-
tracting and analyzing the metadata at the research clusters, Niffler
enables the creation of image subsets that can be further processed,
used as data for ML workflows, or shared with other researchers.

3.1 Architecture
Figure 1 depicts a sample Niffler deployment. Niffler consists of
instances of DICOM listeners for receiving DICOM images real-
time, and retrospective DICOM extractors to query and retrieve
images on-demand. It consists of a Metadata Extractor that extracts
the textual metadata from the retrieved DICOM images. Niffler
stores the images in its storage and the metadata in a Metadata
Store. Its Application Layer provides unified access to data and
metadata in the storage and the metadata store. Thus, ML and
processing pipelines run efficiently on the images and metadata
stored in Niffler.

Figure 1: Deployment Architecture

In the standard healthcare system, the radiology department may
consist of several PACS, each receiving radiology images from scan-
ners of various modalities. Our current deployment environment
consists of 2 PACS from our institutional radiology department,
configured to accept DICOM retrieval queries from Niffler. We de-
ployed Niffler in a standard server with 12 GB memory and 1 TB
of hard disk, in the research cluster. In this sample deployment,
the primary PACS receives data in real-time from the scanners.
The radiology department has configured an archival process that
copies the images from the primary PACS to the shadow PACS and
then cleans up the primary PACS every week. Hence, the shadow
PACS stores imaging data for several years, supporting retrospec-
tive queries.

The real-time DICOM listener receives images from the primary
PACS continuously as a DICOM imaging stream. The retrospective

DICOM extractor performs on-demand queries issued by the users
on the shadow PACS. Niffler consists of multiple DICOM StoreSCP
processes configured at the research cluster, one for each PACS.
The images from the PACS are stored separately in a storage, in
a hierarchical folder structure: patient-folder/study-folder/series-
folder/instance.dcm.

The Metadata Extractor executes its extraction query on all the
images in the storage, extracts the relevant metadata from the DI-
COM headers, and stores the metadata free from PHI in a Metadata
Store. The Application Layer facilitates access to the DICOM images
from the storage and the respective metadata from the metadata
store. It provides utility functions such as de-identification, image
conversion, and scripts such as scanner utilization computation
and scanner time calibration. The ML pipelines run either directly
or via the application layer on the images and the metadata. Niffler
deletes the images from the storage periodically once the metadata
extraction and the execution of the ML pipelines on the images
are complete. Subsets of images relevant for a study can be shared
with the other researchers, typically after processing them such
as, de-identifying them, converting them into png images, or after
running the ML pipelines on them together with their results.

The metadata store uses a NoSQL [15] database due to its scalabil-
ity and support for data in JSON format for the hierarchical format
of DICOM metadata. The database consists of several collections,
each representing a profile. Each profile represents the DICOM at-
tributes that must be extracted for one or more experiments. The
Metadata Extractor reads the folder consisting of the profiles stored
as text files. It parses the DICOM headers from the images received
in the storage, and stores the relevant attributes defined in the
profiles into their respective collections. An experiment can use
existing profiles or create a new profile at run time without halting
the execution. As each profile creates a collection, the access can be
limited to the respective researcher at the collection level, using the
access controls offered by the NoSQL metadata store. The metadata
is used to filter cohorts and sub cohorts that allow dataset creation
for model inference. For example, to test whether an IVC filter
model performance drops with the change of equipment, cohorts
of data filtered by modality, and manufacturer are easily created at
the metadata level.

The application layer provides a unified data explorer access to
both data and metadata. It allows the users to determine the cohort
components required for model inference. For example, an end-user
will access the metadata (without specific clinical information) and
filter with a query like “I want all Abdomen X-rays for studies
between 2012 and 2019 with sub cohorts of manufacturers and their
anticoagulation medication and problem list”. Since the pipeline
is a prospectively populated system with an option for a query to
extract images meeting a specific criterion, this limits the amount
of information stored in the research clusters that are duplicated.
Without the integrated pipeline, a researcher would have to submit
multiple queries to the PACS research team and CDW, work on
anonymizing the data collected, merge the data, and then run the
model inference. Thus, Niffler supports prospective dynamic cohort
and subcohort creation, eliminating the need for duplicate data
storage and aggregation, with anonymized model output. Through
its cloud-native architecture that natively supports the execution of

Research ClusterRadiology DepartmentMetadata StoreReal-TimeDICOM ListenerMLPipelinesDICOMApplication LayerShadow PACS(Retrospective)Primary PACS(Real-time)Archival ProcessStorageOn-DemandQueriesRetrospectiveDICOM ExtractorMetadataMetadata ExtractorNifflerDICOMPreprint, August 5, 2020, Emory University, GA, USA

Kathiravelu, et al.

pipelines as containers, Niffler provides an infrastructure-agnostic
execution with seamless scaling and migration.

3.2 Niffler Execution
Niffler autostarts at login as a service with its storage and metadata
extraction processes. Niffler Metadata Extractor opens a Pickle file
that consists of a set of DICOM series: P – set of series whose
metadata is already extracted but the images are not deleted, and D
– set of series that are already processed and deleted. If the Pickle
file does not exist, the sets are initialized as empty sets, and the
Pickle file is created.

At the core of the Metadata Extractor is an extract_metadata
process that runs periodically (by default, set at every 10 minutes)
as a thread. However, only one instance of extract_metadata is
run at any given time. It traverses all the DICOM series (S) in the
storage. As the data is, by default, stored in the file system, the
Metadata Extractor uses the f ind operating system command, as
a sub-process. In each iteration, the Metadata Extractor extracts
metadata from the first image of each series that is not extracted yet.
For performance reasons, Niffler extracts metadata from only one
image per series. However, we can configure it to extract more than
one (such as first, last, and a middle instance in any given series) or
all the images of each series. The sets are updated as depicted in (1)
following an iteration of extraction.

∀s ∈ S, s (cid:60) P ∧ s (cid:60) D =⇒ P ← P ∪ {s}

(1)
Niffler has a periodic clear_storage process. By default, this pro-
cess runs once at 23:59 each night. It deletes the images whose
metadata is already extracted, making sure no ML or processing
workflow is processing them. The sets are updated as depicted in
(2) following an iteration of deletion.

∀s ∈ P =⇒ D ← D ∪ {s}, P ← P \ {s}
(2)
An update_pickle process runs periodically (by default, every 20
minutes), to ensure that the sets P and D are written to the Pickle
file. This approach of writing the sets to the filesystem and reading
them upon startup ensures that the Metadata Extractor processes
resume where they stopped when Niffler halts involuntarily or
stopped for updates. This state-awareness aims to support seamless
updates and improve fault-tolerance, ensuring that the progress
made by the extraction and deletion processes is not lost upon
failures and restarts.

3.3 Implementation
We developed the Niffler prototype as an open-source platform1,
with its core in Python3. Niffler uses the Pydicom library to extract
metadata and process the DICOM images. The application layer
and the ML pipelines are developed in multiple languages. The
application layer consists of several toolkits. Among these, the
scanner utilization is in Java, whereas scanner timeshift calibration
is in Javascript. Among the ML pipelines, the IVC filter detection
container is developed in Python3.

Two instances of the DCM4CHE [34] StoreSCP tool is config-
ured to receive all images in 2 different ports (4242 and 4243). The

1The source code can be found at https://github.com/Emory-HITI/Niffler

first one listens to all the images sent from the real-time PACS
and accepts them. The second one receives the images on-demand
via CM4CHE MoveSCU queries. The DCM4CHE MoveSCU is con-
figured to retrieve images based on specific queries, which are
optionally first filtered based on a FindSCU. The Niffler prototype
uses the local file system as the storage and MongoDB [4] as its
Metadata Store. We configured a replicated MongoDB cluster to
support the scaling and redundancy of the metadata store, as mongo
replicasets can be added to the MongoDB cluster without reconfig-
uring the database. The folders that store the DICOM images are
identified as their unique IDs such as PatientID, StudyInstanceUID,
and SeriesInstanceUID, and thus indexed and easily identifiable
from the metadata. Given below is a sample (anonymized) entry in
the metadata store for a DICOM image.

: O b j e c t I d ( " 5 e 7 e 1 d 1 a 5 8 a 2 a 1 2 a d f f 6 4 8 1 1 " ) ,

"XXXX " ,

"XXXX " ,

:
" 2 0 2 0 0 3 2 7 " ,
" 0 5 0 3 4 8 . 1 2 8 " ,
:
" 2 0 2 0 0 3 2 7 " ,
" 0 5 0 5 0 3 . 2 7 1 " ,

"XXXX " ,

"XXXX " ,

" 2 0 2 0 0 3 2 7 " ,
" 0 5 0 5 0 3 . 2 7 1 " ,

" 7 " ,
[ " DERIVED " ,

:

:

:

:
:

:
:

:
:

{ " _ i d "
" P a t i e n t I D "
" S t u d y I n s t a n c e U I D "
" S t u d y D a t e "
" StudyTime "
" S e r i e s I n s t a n c e U I D "
" S e r i e s D a t e "
" S e r i e s T i m e "
" S O P I n s t a n c e U I D "
" A c q u i s i t i o n D a t e "
" A c q u i s i t i o n T i m e "
" 1 " ,
" E x p o s u r e "
" ExposureTime "
:
" ImageType "
" PRIMARY "
] ,
" M o d a l i t y "
" S t a t i o n N a m e "
" S t u d y D e s c r i p t i o n "
" I n s t i t u t i o n N a m e "
" S e r i e s N u m b e r "
" S e r i e s D e s c r i p t i o n "
" B o d y P a r t E x a m i n e d "
:
" D e v i c e S e r i a l N u m b e r "
}

"DX " ,

:

:

:

:

" XR CHEST 1 VIEW PORTABLE " ,

"XXXX " ,
:

:
" 2 " ,
:

"XXXX " ,

" AP " ,

" PORT CHEST " ,
" 0 0 2 6 9 1 "
:

We deployed Niffler in a server secured by strict firewall rules
and configured the MongoDB instances with authentication. For
data transfer efficiency, Niffler supports receiving data in a secure
compressed DICOM data stream. In our sample deployment, the
images received from the PACS are in JPEG lossless compressed
form. Niffler uses GDCM [10] to export the compressed DICOM
images to a PNG format, for the ML pipelines to consume in a
de-identified manner. Niffler supports running ML pipelines as
Docker [22] containers on the images and metadata that it stores. By
supporting ML pipelines as Docker containers, Niffler minimizes the
repetitive and complicated configuration steps while automating
the end-to-end process with seamless deployment.

4 EVALUATION
Niffler extracted data from 715 scanners, receiving DICOM data
up to 350 GB each day and continuously running for more than
19 months. Niffler has facilitated several ML workflows in our
department. In this section, we will look into three such use cases
to evaluate the performance of Niffler supporting radiologists ML
and processing workflows in real-time.

A DICOM Framework for Machine Learning Pipelines against Real-Time Radiology Images

Preprint, August 5, 2020, Emory University, GA, USA

4.1 IVC Filter (IVCF) Detection
To measure the performance efficiency and viability of Niffler, we
built an IVCF detection pipeline as a container to execute on the
DICOM retrieved in real-time with Niffler. The pipeline uses the
Keras RetinaNet object detection pre-trained model to determine
whether an IVCF is detected in the subcategories of the images.
The backbone encoder CNN was based on the Resnet-50 architec-
ture [16] pre-trained on the COCO object detection dataset [21].
The model was trained on 503 abdominal, thoracoabdominal, and
lumbar radiographs from various projection views and validated on
127 images. During the real-time inference, first the Niffler Meta-
data Extractor applied the filters on modality and body parts to
create a DICOM subset, consisting of 989 DICOM images. The IVCF
detection container ran its inference on the identified images, in-
cluding chest Xray, abdomen radiographs, and Spine Xrays. The
pipeline drew a bounding box around the identified IVCF in the
images and outputs a PNG image with the detection box, as Figure 2
shows.Two interventional radiologists reviewed all the outputs and
determined that the IVCF detection algorithm classified the test
images with high accuracy of 96.0% on the 989 test images retrieved
in real-time with Niffler.

As we receive the images in real-time, the Metadata Extractor
applies the filters on modality and body parts to create a subset of
data. The object detection algorithm of the ML pipeline executes,
taking the identified images as its input. The IVCF detection con-
tainer first converts the DICOM images into PNG images before
running its inference on the PNG images, including chest Xray,
abdomen radiographs, and Spine Xrays. Then the pipeline draws a
bounding box around the filter and outputs a PNG image with the
detection box, as shown in Figure 2. The Retinanet IVCF detection
algorithm classified the test images with high accuracy of 96.0% on
the images retrieved in real-time with Niffler.

Figure 2: IVCF Detection and Localization on Various Views

4.2 Calculating Scanner Utilization
Next, we demonstrate the potential to use DICOM metadata to un-
derstand the scanners’ system performance metrics for operational
efficiency, individually for each scanner, and for the healthcare
networks to schedule the patients efficiently across the scanners
and hospitals. Niffler calculates the time each scanner is used for

an examination, using the AcquisitionTime attribute in the DICOM
metadata. Then it computes the scanner utilization at any time of
the day by dividing the calculated examination time by the total
time the scanner is turned on for the day. We calculated scanner
utilization by using the metadata from the DICOM images received
real-time by Niffler for a day, for a specific scanner. We then com-
pared it against the data derived from CDW. Figure 3 indicates the
time windows a scanner is used for examinations, as indicated by
Niffler and CDW.

Figure 3: Visualizing Scanner Utilization Measurements

We observe that Niffler more accurately identified when a scan-
ner is used in an examination and when it is idling in between the
examinations. CDW is more prone to human errors. It reported
overlapping examinations for a scanner, which is not possible as a
scanner can perform no more than one examination at any time.
Niffler correctly identified the scanner utilizations as the metadata
consists of the actual acquisition time. Consequently, using Nif-
fler, we can evaluate the scanner performance and optimize how
the scanners are utilized. For instance, combined with the clinical
data, we may identify why certain scanners have longer wait times
between examinations and whether a longer examination time is
justified or necessary to provide the acquired image with acceptable
quality.

4.3 Scanner Clock Calibration
Finally, we used Niffler to identify the scanners that have miscon-
figured time, using the metadata of the images received in real-time.
When metadata attributes such as AcquisitionTime and SeriesTime
have a wrong timestamp due to the scanner time misconfiguration
(typically, due to a wrong timezone setting), extracting useful infor-
mation from the metadata becomes harder. Niffler contains a script
that compares the time the images are received at the metadata
store against the acquisition time from the metadata. Typically the
difference does not exceed 20 minutes, accounting for the time
the image to be received over the network and the metadata to be
extracted and saved. Niffler correctly identified five scanners with
misconfigured time.

Our evaluations highlight that Niffler provides fast processing
of ML models in real-time with high-efficiency, by running the
filtering at metadata level and the ML pipelines using CPU only on
the identified images. We also highlight the potential in using Niffler
in operating the scanners better, with information not otherwise
readily available in the clinical systems.

Preprint, August 5, 2020, Emory University, GA, USA

Kathiravelu, et al.

4.4 Discussion
The prototype and the evaluations highlight the potential and per-
formance of Niffler in executing ML pipelines and metadata process-
ing workflows in real-time in a research cluster. However, Niffler
requires extension and further development for clinical validation.
In the IVCF detection, we currently do not know if the patient is
anticoagulated and can have this filter removed, or whether they
have contraindication of filter removal or already have an upcoming
scheduled appointment for filter retrieval. As future work, we pro-
pose to support end-to-end clinical validation of the ML pipelines
with the consumption of Electronic Medical Record (EMR) from
the RTA on the laboratory information (INR, anticoagulation pro-
file), medications (whether the patient is on any anticoagulant),
problem list (for example, if a patient has a history of GI bleed
and hence cannot be anticoagulated) and the upcoming clinical
appointments where a patient can be seen in the clinic. Linkage
to an ADT message would allow just in time clinical review of the
patients in same-day appointments. In the IVCF detection pipeline,
such a linkage will provide education to providers on the benefits
of the IVCF removal when no longer required.

By merging the Niffler real-time images with the RTA stream,
we can create a live AI inference pipeline that accelerates the de-
velopment of clinically useful algorithms. To our knowledge, this
will be the first AI inference pipeline that combines real-time image
and clinical data information during AI validation. We propose inte-
grating the RTA clinical data pipeline with the imaging pipeline to
provide tooling for data curation for model inference and training.
Specifically, Niffler will receive an HL7 feed from the RTA system,
which will be normalized into Fast Healthcare Interoperability Re-
sources (FHIR) [5] resource groups. For the IVCF detection, we will
limit the scope of integration to cover the following resource groups
âĂŞ Patient, Organization, Appointment and Schedule, Medication,
and Observation. The FHIR resource groups will be added to our
existing DICOM metadata and stored as MongoDB collections in
the metadata store.

5 CONCLUSION
In this paper, we presented Niffler, a framework that supports the
seamless transfer of data from the PACS to the research clusters
and enables efficient execution of ML pipelines on the images,
reports, and the extracted textual metadata. Niffler facilitates the
execution of ML models with a minimal tuning of infrastructure.
It further enables the development of models against real-time
data streams and helps gather large-scale prospective data in a
centralized store to facilitate imaging research. We demonstrated
the potential for seamless execution of ML pipelines in real-time
with three use cases of Niffler– one on ML workflows on the DICOM
images, and the other two by processing the extracted metadata.
Our evaluations and prolonged execution of the Niffler prototype
highlight its support for efficient processing of data.

As future work, we propose to add de-identification pipelines
from The Cancer Imaging Archive (TCIA) [8], allowing human cu-
ration and a centralized process for IRB, thus ensuring that the data
pipelines produce high-quality data in a secure and scalable manner.
We propose using standardized instruments of the unified theory
of acceptance and use of technology (UTAUT) [33] to measure

the perceived usefulness and satisfaction of the inference pipeline
for AI validation. We will use the applied cognitive task analysis
(ACTA) [23] previously validated for extracting task information
from subject matter experts and adapt it for clinical validation. This
approach will entail a task interview with think aloud observations
as radiologists validate AI models on the inference pipeline, fol-
lowed by a knowledge audit of the decision making for determining
clinical performance and utility of the ML pipelines.

REFERENCES
[1] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey
Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al.
2016. Tensorflow: A system for large-scale machine learning. In 12th {USENIX}
Symposium on Operating Systems Design and Implementation ({OSDI} 16). 265–
283.

[2] Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman Alfozan,
and James Zou. 2020. An online platform for interactive feedback in biomedical
machine learning. Nature Machine Intelligence 2, 2 (2020), 86–88.

[3] ACR. 2020. ACR AI-LAB. Available at https://www.acrdsi.org/Get-Involved/AI-

LAB.

[4] Kyle Banker. 2011. MongoDB in action. Manning Publications Co.
[5] Duane Bender and Kamran Sartipi. 2013. HL7 FHIR: An Agile and RESTful
approach to healthcare information exchange. In Proceedings of the 26th IEEE
international symposium on computer-based medical systems. IEEE, 326–331.
[6] John L Burns, Dan Hasting, Judy W Gichoya, Ben McKibben, Lindsey Shea, and
Mark Frank. 2020. Just in Time Radiology Decision Support Using Real-time
Data Feeds. Journal of Digital Imaging 33, 1 (2020), 137–142.

[7] Junghwan Cho, Kyewook Lee, Ellie Shin, Garry Choy, and Synho Do. 2015.
arXiv preprint

Medical image deep learning with hospital PACS dataset.
arXiv:1511.06348 (2015).

[8] Kenneth Clark, Bruce Vendt, Kirk Smith, John Freymann, Justin Kirby, Paul
Koppel, Stephen Moore, Stanley Phillips, David Maffitt, Michael Pringle, et al.
2013. The Cancer Imaging Archive (TCIA): maintaining and operating a public
information repository. Journal of digital imaging 26, 6 (2013), 1045–1057.
[9] David A Clunie. 2000. DICOM structured reporting. PixelMed publishing.
[10] GDCM Developers. 2010. Grass Roots DiCoM.
[11] ePAD. 2020. ePAD: web-based platform for quantitative imaging in the clinical

workflow . Available at https://epad.stanford.edu.

[12] FDA. 2020. Digital Health Software Precertification (Pre-Cert) Program | FDA.
Available at https://www.fda.gov/medical-devices/digital-health/digital-health-
software-precertification-pre-cert-program.

[13] FDA. 2020. Food & Drug Administration. Digital Health Innovation Action Plan.

Available at https://www.fda.gov/medical-devices/digital-health.

[14] Andrew Grant, Andriy Moshyk, Hassan Diab, Philippe Caron, Fabien de Lorenzi,
Guy Bisson, Line Menard, Richard Lefebvre, Patricia Gauthier, Richard Grondin,
et al. 2006. Integrating feedback from a clinical data warehouse into practice
organisation. International journal of medical informatics 75, 3-4 (2006), 232–239.
[15] Jing Han, E Haihong, Guan Le, and Jian Du. 2011. Survey on NoSQL database. In
2011 6th international conference on pervasive computing and applications. IEEE,
363–366.

[16] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual
learning for image recognition. In Proceedings of the IEEE conference on computer
vision and pattern recognition. 770–778.

[17] HK Huang, NJ Mankovich, RK Taira, PS Cho, BK Stewart, BK Ho, KK Chan, and
Y Ishimitsu. 1988. Picture archiving and communication systems (PACS) for
radiological images: state of the art. Critical reviews in diagnostic imaging 28, 4
(1988), 383–427.
[18] Nikhil Ketkar. 2017.

Introduction to pytorch.

In Deep learning with python.

Springer, 195–208.

[19] Dong Wook Kim, Hye Young Jang, Kyung Won Kim, Youngbin Shin, and Seong Ho
Park. 2019. Design characteristics of studies reporting the performance of artificial
intelligence algorithms for diagnostic analysis of medical images: results from
recently published papers. Korean journal of radiology 20, 3 (2019), 405–410.
[20] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollár. 2017.
Focal loss for dense object detection. In Proceedings of the IEEE international
conference on computer vision. 2980–2988.

[21] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
Ramanan, Piotr Dollár, and C Lawrence Zitnick. 2014. Microsoft coco: Common
objects in context. In European conference on computer vision. Springer, 740–755.
[22] Dirk Merkel. 2014. Docker: lightweight linux containers for consistent develop-

ment and deployment. Linux journal 2014, 239 (2014), 2.

[23] Laura G Militello and Robert JB Hutton. 1998. Applied cognitive task analy-
sis (ACTA): a practitioner’s toolkit for understanding cognitive task demands.
Ergonomics 41, 11 (1998), 1618–1641.

A DICOM Framework for Machine Learning Pipelines against Real-Time Radiology Images

Preprint, August 5, 2020, Emory University, GA, USA

[24] Pattanasak Mongkolwat, Vladimir Kleper, Skip Talbot, and Daniel Rubin. 2014.
The National Cancer Informatics Program (NCIP) Annotation and Image Markup
(AIM) Foundation model. Journal of digital imaging 27, 6 (2014), 692–701.
[25] Nariman Noorbakhsh-Sabet, Ramin Zand, Yanfei Zhang, and Vida Abedi. 2019.
Artificial intelligence transforms the future of healthcare. The American journal
of medicine (2019).

[26] Liron Pantanowitz, Ashish Sharma, Alexis B Carter, Tahsin Kurc, Alan Sussman,
and Joel Saltz. 2018. Twenty years of digital pathology: An overview of the road
travelled, what is on the horizon, and the emergence of vendor-neutral archives.
Journal of pathology informatics 9 (2018).

[27] Charles Parisot. 1995. The DICOM standard. The International Journal of Cardiac

Imaging 11, 3 (1995), 171–177.

[28] Oleg S Pianykh. 2009. Digital imaging and communications in medicine (DICOM):
a practical introduction and survival guide. Springer Science & Business Media.
[29] Olanrewaju A Soremekun, James K Takayesu, and Stephen J Bohan. 2011. Frame-
work for analyzing wait times and other factors that impact patient satisfaction
in the emergency department. The Journal of emergency medicine 41, 6 (2011),
686–692.

[30] Adarsh Subbaswamy and Suchi Saria. 2020. From development to deployment:
dataset shift, causality, and shift-stable models in health AI. Biostatistics 21, 2

(2020), 345–352.

[31] Andrew G Taylor, Clinton Mielke, and John Mongan. 2018. Automated detec-
tion of moderate and large pneumothorax on frontal chest X-rays using deep
convolutional neural networks: A retrospective study. PLoS medicine 15, 11
(2018).

[32] Sebastian Trinks and Carsten Felden. 2017. Real time analyticsâĂŤState of the
art: Potentials and limitations in the smart factory. In 2017 IEEE International
Conference on Big Data (Big Data). IEEE, 4843–4845.

[33] Viswanath Venkatesh, James YL Thong, and Xin Xu. 2016. Unified theory of
acceptance and use of technology: A synthesis and the road ahead. Journal of
the Association for Information Systems 17, 5 (2016), 328–376.

[34] Max J Warnock, Christopher Toland, Damien Evans, Bill Wallace, and Paul Nagy.
2007. Benefits of using the DCM4CHE DICOM archive. Journal of Digital Imaging
20, 1 (2007), 125–129.

[35] John R Zech, Marcus A Badgeley, Manway Liu, Anthony B Costa, Joseph J Titano,
and Eric Karl Oermann. 2018. Variable generalization performance of a deep
learning model to detect pneumonia in chest radiographs: a cross-sectional study.
PLoS medicine 15, 11 (2018).

