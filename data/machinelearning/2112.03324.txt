Neuro-Symbolic Inductive Logic Programming with Logical Neural Networks

Prithviraj Sen, Breno W. S. R. de Carvalho, Ryan Riegel, Alexander Gray

IBM Research

1
2
0
2
c
e
D
6

]
I

A
.
s
c
[

1
v
4
2
3
3
0
.
2
1
1
2
:
v
i
X
r
a

Abstract

Recent work on neuro-symbolic inductive logic programming
has led to promising approaches that can learn explanatory
rules from noisy, real-world data. While some proposals ap-
proximate logical operators with differentiable operators from
fuzzy or real-valued logic that are parameter-free thus di-
minishing their capacity to ﬁt the data, other approaches are
only loosely based on logic making it difﬁcult to interpret
the learned “rules”. In this paper, we propose learning rules
with the recently proposed logical neural networks (LNN).
Compared to others, LNNs offer strong connection to classi-
cal Boolean logic thus allowing for precise interpretation of
learned rules while harboring parameters that can be trained
with gradient-based optimization to effectively ﬁt the data. We
extend LNNs to induce rules in ﬁrst-order logic. Our experi-
ments on standard benchmarking tasks conﬁrm that LNN rules
are highly interpretable and can achieve comparable or higher
accuracy due to their ﬂexible parameterization.

1

Introduction

Inductive logic programming (ILP) (Muggleton 1996) has
been of long-standing interest where the goal is to learn
logical rules from labeled data. Since rules are explicitly
symbolic, they provide certain advantages over black box
models. For instance, learned rules can be inspected, under-
stood and veriﬁed forming a convenient means of storing
learned knowledge. Consequently, a number of approaches
have been proposed to address ILP including, but not limited
to, statistical relational learning (Getoor and Taskar 2007)
and more recently, neuro-symbolic methods.

Since logical operators such as conjunction and disjunction
are not differentiable, one issue that most neuro-symbolic
ILP techniques have to address is how to learn rules using
gradient-based optimization. A popular solution is to employ
extensions from fuzzy or real-valued logic that are either
differentiable or have subgradients available. For instance,
NeuralLP (Yang, Yang, and Cohen 2017) substitutes logical
conjunction with product t-norm (x ∧ y ≡ xy) and logic
tensor networks (Donadello, Seraﬁni, and d’Avila Garcez
2017) with Łukasiewicz t-norm (x ∧ y ≡ max(0, x + y −
1)). In an interesting experiment, Evans and Grefenstette
(2018) show that among the various options, product t-norm
seems to lead to the best ILP result. This indicates that the
learning approach, rather than the user, should be in charge

of substituting logical connectives besides learning the rules
themselves. Neural logic machine (NLM) (Dong et al. 2019)
achieves this but at the cost of interpretability. More precisely,
it models propositional formulae (consisting of conjunctions,
disjunctions and/or negations) with multi-layer perceptrons
(MLP). Once trained, it may not be possible to interpret NLM
as rules since there exists no standard translation from MLP
to logic. What is needed is an extension of classical logic
with ties strong enough to be amenable to interpretation and
can learn not only rules but also the logical connectives using
gradient-based optimization.

In this paper, we propose ILP with the recently proposed
logical neural nerworks (LNN) (Riegel et al. 2020). Instead
of forcing the user to choose a function that mimics a logical
connective, LNNs employ constraints to ensure that neurons
behave like conjunctions or disjunctions. By decoupling neu-
ron activation from the mechanism to ensure that it behaves
like a logical connective, LNNs offer tremendous ﬂexibility
in how to parameterize neurons thus ensuring that they ﬁt the
data better while maintaining close connections with classical
Boolean logic which, in turn, facilitates principled interpre-
tation. We propose ﬁrst-order extensions of LNNs that can
tackle ILP. Since vanilla backpropagation is insufﬁcient for
constraint optimization, we propose ﬂexible learning algo-
rithms capable of handling a variety of (linear) inequality and
equality constraints. We experiment with diverse benchmarks
for ILP including gridworld and knowledge base comple-
tion (KBC) that call for learning of different kinds of rules
and show how our approach can tackle both effectively. In
fact, our KBC results represents a 4-16% relative improve-
ment (in terms of mean reciprocal rank) upon the current
best rule-based KBC results on popular KBC benchmarks.
Additional, we show that joint learning of rules and logical
connectives leads to LNN rules that are easier to interpret vs.
other neuro-symbolic ILP approaches.

2 Related Work
∂ILP (Evans and Grefenstette 2018) is another neuro-
symbolic ILP technique whose main parameter is a ten-
sor with one cell per candidate logic program. Since the
number of candidates is exponential in both the number
of available predicates and the number of constituent rules
in the program, ∂ILP’s complexity is exponential making
it impractical for anything but the smallest learning task.

 
 
 
 
 
 
To reign in the complexity, ∂ILP asks the user to specify
the ILP task using a template consisting of two rules each
containing a maximum of two predicates. In reality, most
neuro-symbolic ILP approaches ask the user to specify a tem-
plate. NeuralLP’s (Yang, Yang, and Cohen 2017) template
is meant for link prediction in incomplete knowledge bases
(sometimes called open path or chain rule) which only in-
cludes binary predicates and is of the form T (X1, Xn) ←
R1(X1, X2) ∧ R2(X2, X3) ∧ . . . Rn−1(Xn−1, Xn) positing
that the head predicate T (X1, Xn) can be modeled as a path
from X1 to Xn. NLM (Dong et al. 2019) is restricted to learn-
ing rules where the head and body predicates each contain the
same set of variables. For instance, to model the rule learned
by NeuralLP, NLM would ﬁrst need to add arguments to
R1 so that the new predicate contains all variables including
X3, . . . Xn. In contrast, our approach can use more ﬂexible
templates that can express programs beyond two rules, allows
the use of n-ary predicates (n possibly > 2), and allows the
head to have fewer variables than the body thus going beyond
all of the above mentioned approaches.

Neural theorem provers (NTP) (Rockt¨aschel and Riedel
2017) generalize the notion of uniﬁcation by embedding
logical constants into a high-dimensional latent space. NTPs
can achieve ILP by learning the embedding for the unknown
predicate which forms part of the rule, and subsequently
comparing with embeddings of known predicates. NTPs can
have difﬁculty scaling to real-world tasks since the decision
to unify two constants is no longer Boolean-valued leading
to an explosion of proof paths that need to be explored. To
improve scalability, recent proposals either greedily choose
(GNTP (Minervini et al. 2020a)) or learn to choose (CTP
(Minervini et al. 2020b)) most promising proof paths. We
compare against CTP in Section 5.

Lifted relational neural networks (LRNN) (Sourek et al.
2017) model conjunctions using (generalized) sigmoid but
ﬁx certain parameters to ensure that it behaves similar to
Łukasiewicz t-norm. This limits how well LRNN can model
the data, which is contrary to our goal as stated in the pre-
vious section. While other combinations of logic and neural
networks exist, e.g. logic tensor networks (Donadello, Ser-
aﬁni, and d’Avila Garcez 2017), RelNN (Kazemi and Poole
2018), DeepProbLog (Manhaeve et al. 2018), to the best of
our knowledge, none of these learn rules to address ILP.

3 Generalized Propositional Logic with

Logical Neural Networks

Logical neural networks (LNN) (Riegel et al. 2020) allow the
use of almost any parameterized function as a logical connec-
tive. We illustrate how LNNs generalize conjunction (∧). Let
0 denote false and 1 denote true. Let a, b ∈ {0, 1} and
x, y ∈ [0, 1] denote Boolean-valued and continuous-valued
variables, respectively. While Boolean logic deﬁnes the out-
put of ∧ when x, y attain the extremities of their permissible
domains (shown in Figure 1 (a)), to fully deﬁne real-valued
logic’s ∧ we need to also extend its deﬁnition to x, y ∈ (0, 1).
Intuitively, the characteristic shape of ∧ is to produce a 1)
low output when either input is low, and 2) high output when
both inputs are high. A simple way to capture low vs. high is

a
0
0
1
1

a ∧ b
0
0
0
1

b
0
1
0
1
(a)

x
[0, 1 − α]
[0, 1 − α]
(1 − α, 1]
[α, 1]

y
[0, 1 − α]
(1 − α, 1]
[0, 1 − α]
[α, 1]
(b)

x ∧ y
[0, 1 − α]
[0, 1 − α]
[0, 1 − α]
[α, 1]

Figure 1: (a) Truth table for ∧ in Boolean logic, and (b) Shape
of ∧ extended to real-valued logic.

via a user-deﬁned hyperparameter α ∈ ( 1
2 , 1]: x ∈ [0, 1 − α]
constitutes low and x ∈ [α, 1] constitutes high. Figure 1 (b)
expresses ∧ for real-valued logic in terms of α.

LNNs propose constraints to enforce the shape of ∧. Let
f : [0, 1] × [0, 1] → [0, 1] denote a monotonically increasing
function (in both inputs). In other words, f (x, y(cid:48)) ≥ f (x, y)
∀y(cid:48) ≥ y and f (x(cid:48), y) ≥ f (x, y) ∀x(cid:48) ≥ x. In accordance with
ﬁgure 1 (b), LNNs enforce the following constraints:

f (x, y) ≤ 1 − α,
f (x, y) ≤ 1 − α,
f (x, y) ≤ 1 − α,
f (x, y)

≥ α,

∀ x, y ∈ [0, 1 − α]
∀ x ∈ [0, 1 − α], ∀y ∈ (1 − α, 1]
∀ x ∈ (1 − α, 1], ∀y ∈ [0, 1 − α]
∀ x, y ∈ [α, 1]

Since f is monotonically increasing, we can move all con-
straints to their corresponding extremities and eliminate the
ﬁrst constraint since it is redundant given the second and
third.

f (1 − α, 1) ≤ 1 − α, f (1, 1 − α) ≤ 1 − α, f (α, α) ≥ α

Further simpliﬁcations may be obtained for speciﬁc choice
of f . For inspiration, we look towards triangular norm (t-
norm) (Esteva and Godo 2001) which is deﬁned as a symmet-
ric, associative and non-decreasing function T : [0, 1]2 →
[0, 1] satisfying boundary condition T (1, x) = x, ∀x ∈
[0, 1]. Popular t-norms include product t-norm, xy, and
Łukasiewicz t-norm, max(0, x + y − 1). We extend the lat-
ter to deﬁne LNN-∧ (other t-norms may also be extended
similarly):

LNN-∧(x, y; β, w1, w2) =

(cid:40) 0
1
β − w1(1 − x) − w2(1 − y)

if β − w1(1 − x) − w2(1 − y) < 0
if β − w1(1 − x) − w2(1 − y) > 1
otherwise

where β, w1, w2 denote learnable parameters subject to the
following constraints translated from above1:
LNN-∧(1 − α, 1; β, w1, w2) = β − w1α ≤ 1 − α
LNN-∧(1, 1 − α; β, w1, w2) = β − w2α ≤ 1 − α

LNN-∧(α, α; β, w1, w2) = β − (w1 + w2)(1 − α) ≥ α
To ensure that LNN-∧ is monotonically increasing, we also
need to enforce non-negativity of w1, w2. It is easy to extend
LNN-∧ to an n-ary conjunction (n ≥ 2):

LNN-∧(x; β, w) ≡

relu1(β − w(cid:62)(1 − x))

subject to: w ≥ 0, β − αw ≤ (1 − α)1

β − (1 − α)1(cid:62)w ≥ α

(1)

1We remove the upper and lower clamps since they do not apply

in the active region of the constraints.

(a)

(b)

(c)

(d)

(e)

Figure 2: (a) Lukasiewicz t-norm vs. (b) Product t-norm vs. LNN-∧ with (c) α = 0.7, (d) α = 0.9. (e) LNN-∨ (α = 0.7).

where relu1(x) denotes max(0, min(1, x)) (Krizhevsky
2010) and, x, w and 1 denote vectors of continuous-valued
inputs, weights, and 1s, respectively.

Note that, Figure 1 (b) does not enforce constraints on
1 − α < x, y < α. Essentially, α acts as a tunable knob
that controls the size of this unconstrained region where we
can learn LNN operators without impedance which is an ar-
guably better approach than choosing a parameter-less t-norm
that would arbitrarily interpolate from Boolean-logic’s ∧ to
real-valued logic’s ∧. Figure 2 illustrates how Łukasiewicz
(Figure 2 (a)) and product (Figure 2 (b)) t-norms differ
from LNN-∧ learned by ﬁtting to the four rows in Fig-
ure 1 (a)’s truth-table. Even pictorially, LNN-∧ looks dis-
tinctly conjunction-like, i.e., when either x or y is low it
produces a value close to 0 while rising quickly to 1 when
both x, y are high. When α = 0.9 (Figure 2 (d)), the region
devoid of constraints is larger than at α = 0.7 (Figure 2
(c)) (∵ [0.1, 0.9] ⊃ [0.3, 0.7]), so the curve can rise later to
provide a better ﬁt . In contrast, Łukasiewicz t-norm remains
at 0 until the x + y = 1 line, post which it increases linearly.
Product t-norm is similar, adding a slight, upward curve.

Other propositional logic operators include negation (¬)
and disjunction (∨). LNN negation is given by 1 − x and
LNN disjunction, LNN-∨, is deﬁned in terms of LNN-∧:

LNN-∨(x; β, w) = 1 − LNN-∧(1 − x; β, w)

where constraints deﬁned in Equation 1 apply. Figure 2 (e)
pictorially depicts LNN-∨ (with α = 0.7). In contrast to Fig-
ure 2 (c), it clearly shows how maximum output is achieved
for smaller values of x, y, as a disjunction operator should.

4 Learning First-Order LNNs

Following previous work (Yang, Yang, and Cohen 2017;
Evans and Grefenstette 2018; Dong et al. 2019), we also uti-
lize program templates expressed in higher-order logic to be
fed by the user to guide the learning in the right direction. Our
deﬁnition of a program template draws inspiration from meta-
interpretive learning (Muggleton et al. 2014). In contrast to
previous work on neuro-symbolic AI however, our deﬁnition
of a program template is more general and includes as special
cases the templates utilized by Evans and Grefenstette (con-
siders only rules whose body contains up to 2 predicates),
Yang, Yang, and Cohen (considers only binary predicates)
and Dong et al. (considers only rules whose head includes all
variables contained in the body). After introducing our logic
program template, we then describe how to combine it with
data to construct a neural network that may then be trained
to learn the logic program of interest.

Let pred(X1, . . . Xn) denote an n-ary predicate which
returns true (1) or false (0) for every possible joint as-
signment of X1, . . . Xn to constants in the knowledge base.
The main construct in ﬁrst-order logic (FOL) is a rule or
clause:

h ← b1 ∧ b2 ∧ . . . bm
where b1, . . . bm denote predicates in its body and h denotes
the head predicate. If the conjunction of all predicates in
the body is true then the head is also true. The head h in
a clause may contain fewer logical variables than the body
b1, . . . bm which means that there must exist an assignment
to the missing variables in the head for it to hold. More
precisely, if B = b1, . . . bm denotes the body and is deﬁned
over logical variables Y then h(X), such that X ⊆ Y, is
true if ∃Y \ X : B(Y) is true. Assignments that lead to
the predicate being true are also called facts.

Figure 3 (a) introduces a toy knowledge base (KB) which
will serve as a running example. The KB contains three bi-
nary predicates, each containing their respective facts along
with a unique identiﬁer for easy reference. Thus, A(X, Y )’s
facts are A(1, 2) (denoted a1) and A(1, 5) (denoted a2). Fig-
ure 3 (b) shows a template for learning R(X, Z) with three
crucial pieces of information: 1) the ﬁrst predicate in its body
P is binary and while we do not know the identity of this
predicate we know its domain Dom(P ) is {A, B}, 2) to keep
the example simple, the second predicate in the body Q has
a singleton domain ({C}), and lastly 3) the second argument
in the ﬁrst predicate should be equal to the ﬁrst argument in
the second predicate indicated by repeated use of Y . Figure
3 (b) (bottom) expresses the same template as a tree where
P (X, Y ) and Q(Y, Z) are annotated with their respective do-
mains forming children of R(X, Z) whose label ∧ indicates
that the predicates in its body are to be conjuncted together.
Figure 3 (c) shows a more complex template that disjuncts
R(X, Z) with O(X, Z), such that Dom(O) = {A, B}, to
produce S(X, Z). Figure 3 (d) shows generated facts (with
unknown truth-values) that can be possibly produced when
this template is combined with the KB from Figure 3 (a). P, Q
and O contain the union of all facts included in the predicates
in their respective domains. Since p1 and q1 are the only two
facts that agree on value of Y , P Q, the predicate produced by
the body of R, contains only one generated fact. R is obtained
by dropping Y , which is then unioned with O to produce S.
By comparing generated facts in S with labels in the training
data, it is possible to learn a full program which in this case
constitutes learning: 1) which predicates to replace P, Q and
O with, and 2) the logical connectives, LNN-∧ and LNN-∨,
used to model R and S with, respectively. We next state a
more formal problem deﬁnition.

 0 0.4 0.7 1 0 0.4 0.7 1 0 0.4 0.7 1xy 0 0.4 0.7 1 0 0.4 0.7 1 0 0.4 0.7 1 0 0.4 0.7 1xy 0 0.4 0.7 1 0 0.4 0.7 1 0 0.4 0.7 1 0 0.4 0.7 1xy 0 0.4 0.7 1 0 0.4 0.7 1 0 0.4 0.7 1 0 0.4 0.7 1xy 0 0.4 0.7 1 0 0.4 0.7 1 0 0.4 0.7 1 0 0.4 0.7 1xy 0 0.4 0.7 1A X Y
2
1
a1
5
1
a2

B X Y
2
1
b1

C W Z
5
2
c1

(a)

R(X, Z) ← P (X, Y ) ∧ Q(Y, Z)

P ∈ {A, B}, Q ∈ {C}

R(X, Z)

∧

P (X, Y )
P ∈ {A, B}

Q(Y, Z)
Q ∈ {C}

P (X, Y )
P ∈ {A, B}

Q(Y, Z)
Q ∈ {C}

(b)

(c)

S(X, Z)

∨

P X Y
2
1
p1
5
1
p2

Q Y
2
q1

Z
5

O X Z
2
1
o1
5
1
o2

R(X, Z)

∧

O(X, Z)
O ∈ {A, B}

P Q X Y
2
pq1

1

Z
5

R X Z
5
1
r1

S X Z
5
1
s1
1
2
s2
(d)

Figure 3: (a) A toy KB. (b) An example rule template (top) and its tree form (bottom). (c) A more complex program template. (d)
Generated facts for our running example.

Let T = (V, E, L) denote a tree-structured program tem-
plate where V denotes the set of nodes, E denotes the set of
edges and L denotes a mapping from V to node labels. L
maps T ’s leaves to the corresponding domain of predicates
in the KB. In the worst case, the domain can be the subset
of predicates in the KB that agrees with the arity of the leaf.
L maps internal nodes to a logical operator {∧, ∨, ¬}. The
ILP task can then be stated as, given T , a knowledge base
KB, and truth-values corresponding to generated facts in the
root of T , to learn all logical connectives involved along with
selecting predicates for each leaf in T .

In the remainder of this section, we describe how to achieve
the above ILP task given ground truth values for generated
facts belonging to the root of the template. Let ψ(v) denote
the truth value associated with (generated) fact v. Our strategy
is to build a neural network that connects the truth values
of generated facts from the root of the template to other
(generated) facts in its lineage right down to the facts in
the base KB whose truth values are deﬁned to be 1. The
whole neural network can then be trained end-to-end using
backpropagation. Let V(X) denote any node in T whose
predicate is deﬁned over variables X and whose children in
T is denoted by N (V). Also, let V(x) denote a fact obtained
by the substitution X = x and F(V) denote all facts of V.

4.1 Combining Base Facts
Let V(X) denote a leaf in T with domain L(V) then F(V)
is given by (cid:83)
P∈L(V) F(P). Computing ψ(V(X = x)) cor-
responding to X = x requires truth values of all facts corre-
sponding to the same substitution. We provide two options
that associate parameters with predicates in L(V): 1) atten-
tion (Yang, Yang, and Cohen 2017) and 2) our proposed
LNN-pred operator:

1) ψ(V(x)) =

(cid:88)

P∈L(V)

wPψ(P(x))



2) ψ(V(x)) =1 − relu1

β −

(cid:88)

P∈L(V)



wPψ(P(x))



where β, wP denote learnable parameters. One issue with
attention is that it may lack sparsity assigning a majority of
predicates in L(V) non-zero weights thus hampering inter-
pretability. To address this, we propose an alternate parame-
terization, LNN-pred, that is a simpler version of LNN-∨

and lacks all constraints except for non-negativity of wP
(since we do not require disjunctive semantics). As an exam-
ple, the lower left corner of Figure 4 shows how to compute
ψ(p1) from ψ(a1), ψ(b1) since a1, b1 form the lineage for p1
(Figure 3). Here, β1, w1 denote LNN-pred’s parameters.

4.2 Combining Facts with Conjunction
We handle conjunctions in two steps: 1) ﬁrst construct the
result of the body of the clause, and then 2) construct the
head, dropping variables if needed. Let V(Y) in T be such
that L(V) = ∧ and N (V) denote its children. Also, let I(X)
denote the intermediate predicate produced from the body of
V(Y) potentially containing additional variables such that
X ⊇ Y. We use LNN-∧ to compute ψ of I(x):





ψ(I(x)) = relu1

β −

(cid:88)

P∈N (V)

wP(1 − ψ(P(xvar(P))))



where var(P) denotes predicate P’s arguments and xvar de-
notes the substitution restricted to variables in var. When
X ⊃ Y, multiple facts from F(I) may combine to produce a
fact in V(Y) and we use maxout for this:

ψ(V(y)) = maxout({ψ(I(x)) | xY = y, ∀I(x) ∈ F(I)})

where maxout({x1, . . .}) (Goodfellow et al. 2013) returns
the maximum of the set. Figure 4 shows how ψ(pq1) is com-
puted from ψ(p1), ψ(q1) where β2, w2 denotes LNN-∧’s
parameters. Since pq1 is the only intermediate fact leading to
r1, we do not need maxout in this case. However, if that was
not the case, Figure 4 shows where maxout would appear.

4.3 Combining Facts with Disjunction
Given V(X) in T such that L(V) = ∨, ψ(V(x)) can be
computed using LNN-∨:



ψ(V(x)) = 1 − relu1

β −



wPψ(P(x))



(cid:88)

P∈N (V)

In Figure 4 shows how ψ(s1) is computed from ψ(r1) and
ψ(o2) where βr, w4 denotes LNN-∨’s parameters.

4.4 Other Operations and Extensions
Implementing negation is more involved since it requires that
we consider assignments that may lead to facts in V but are

s1

1-relu-1(·)

−

[r1, o2]w4

β4

w4

+

(cid:99)λ2

Υ2

(cid:99)µ2

σ

relu

r1

o2

maxout

pq1

λ2

Γ2

µ2

relu-1

Γ4µ4

Υ4λ4

µ4

Γ4

relu

λ4

σ

(cid:99)µ4

Υ4

(cid:99)λ4

−

β2

w2

Υ2λ2

Γ2µ2

+

w(cid:62)

2 (1 − [p1, q1](cid:62))

LNN-∨

LNN-∧

1-relu-1(·)

p1

q1

1-relu-1(·)

relu

relu

β1

w1

(cid:99)β1

(cid:99)w1

−

1(c1)

−

[1, 1]w1

[1, 0]w3

relu

relu

β3

w3

(cid:99)β3

(cid:99)w3

LNN-pred

1(a1)

1(b1)

1(a2)

LNN-pred

Frerix, Nießner, and Cremers (2020) recently showed how
to handle a system of linear inequality constraints of the form
Az ≤ b where A denotes a matrix containing coefﬁcients in
the constraints, z denotes the parameters (in our case, some
concatenation of β and w), and b denotes the constants in
the constraints. We begin with the Minkowski-Weyl theorem:
Theorem 4.1. A set C = {z | Az ≤ b} is a convex polyhe-
dron if and only if:

C = (cid:8)Υµ + Γλ (cid:12)

(cid:12) µ, λ ≥ 0, 1(cid:62)λ = 1(cid:9)

where Υ and Γ contain a ﬁnite number of rays and vertices,
respectively.
which states that there exists a translation from A, b to Υ, Γ
obtained via the double-description method (Motzkin et al.
1953). Assuming we can generate non-negative vectors µ, λ
and additionally ensure that λ sums to 1, then one can access
a point z = [β, w(cid:62)](cid:62) from the feasible set C by computing
Υµ+Γλ. Sampling vectors µ, λ can be achieved, for instance,
by using relu (Nair and Hinton 2010) and softmax:

Figure 4: Neural network constructed for s1 ∈ F(S). σ
denotes softmax.

µ = max(0, (cid:98)µ)

λ =

exp((cid:98)λ)
Z

, Z = 1(cid:62) exp((cid:98)λ)

not present in its child predicate P. Given a universe of all
possible assignments U, we express ψ(V(x)) as:

ψ(V(x)) = 1 − ψ(P(x)), ∀x ∈ U
where ψ(P(x)) is deﬁned as 0 if P(x) /∈ F(P).

Note that, any LNN operator introduced for V(X) is
shared across all V(x) ∈ F(V) since the result of ILP
should be agnostic of individual facts. Thus, even though
the (sub)network constructed for V(x) may differ from
V(x(cid:48))’s, e.g., s2’s neural network (not shown) is simpler
than s1’s, gradient updates ﬂow to the same LNN parame-
ters. For simplicity, we only discussed templates compris-
ing a tree of Horn clauses but the ideas presented here
can easily extend to DAG-structured templates and going
beyond equality conditions in the body of a clause, e.g.,
R(X, Z) ← P (X, Y ) ∧ Q(Y (cid:48), Z) ∧ Y > Y (cid:48).

4.5 Learning Constrained Activations
So far, we have shown how to construct a neural network
from a KB and template comprising parameters of LNN oper-
ators but we have not addressed how to enforce constraints on
said parameters. More precisely, βi, wi, ∀i = 1, . . . 4 in Fig-
ure 4 need to satisfy the respective constraints associated with
the LNN operators they form parameters for (as described
in Section 3). Since backpropagation does not handle con-
straints, we propose to apply a recently proposed approach
to “fold” in a system of linear constraints as layers into the
neural network (Frerix, Nießner, and Cremers 2020). We note
that Riegel et al. (2020) also devise a training algorithm for
learning LNN operators but this is tightly connected to a spe-
ciﬁc kind of LNN operator called tailored activation. For the
small systems of inequality constraints introduced by LNN-∧,
LNN-∨ and LNN-pred, the approach presented here conve-
niently allows learning all (constrained) parameters of LNNs
using vanilla backpropagation alone.

[β, w(cid:62)](cid:62) = Υµ + Γλ

Additionally, these operations can be easily included into
any neural network as additional layers. For instance, Figure
4 contains in dashed boxes the above set of layers needed
to generate wi, βi, ∀i = 1, . . . 4. The resulting neural net-
work is self-contained, and can be trained by vanilla back-
propagation end-to-end thus ensuring that the learned LNN
parameters satisfy their respective constraints.

5 Experiments
Our experiments compare ILP with LNN against other neuro-
symbolic ILP approaches on standard benchmarks. We eval-
uate rules in terms of application-speciﬁc goodness metrics
and interpretability.

5.1 Gridworld
The goal in Gridworld is to learn rules that can help an agent
move across an N × N regular grid. Some of the cells on
the grid are deemed obstacles that the agent cannot step onto,
and the agent’s goal is to arrive at the cell which has been
deemed the destination.
Predicates, Template and Rewards: We include two kinds
of base predicates to describe the grid 1) HasObstacle-
dir(X, Y ) is true if the cell next to X, Y in direction dir
contains an obstacle, 2) HasTarget-dir(X, Y ) is true if
the destination lies in direction dir from cell X, Y . There
are four directions, North, South, East, and West, and includ-
ing their negated counterparts, ¬HasObstacle-dir(X, Y )
and ¬HasTarget-dir(X, Y ), brings the total number of
base predicates to 8. The template is S(X, Y ) ← P (X, Y ) ∧
Q(X, Y ) where P ’s domain includes all HasObstacle-dir
predicates and their negated counterparts, and Q’s domain
includes all HasTarget-dir predicates and their negated
counterparts. We set α = 0.8 and use a simple reward mech-
anism: +1 for moving towards the destination, -1 for moving

(1.791)

LNN-∧

2.239

2.322

(1.056)

LNN-pred

LNN-pred (1.005)

1.077

1.052

¬HasObstacleSouth(X, Y )

HasTargetSouth(X, Y )

(a)

(b)

(c)

Figure 5: Gridworld: (a) Avg. Rewards vs. Training Grids. (b) LNN Rule and (c) LNN-∧ for GoSouth(X,Y).

away, and -2 for stepping on an obstacle. The learning ob-
jective is to maximize rewards on randomly generated 5 × 5
grids with 3 obstacles sampled uniformly at random. We test
the learned rules on grids with 12 obstacles.
Results: We compare our approach based on LNN-pred and
LNN-∧, against NeuralLP which uses attention and product
t-norm. Figure 5 (a) shows mean rewards averaged across
all cells of 50 test grids produced by the learned rules on the
y-axis vs. number of training grids observed on the x-axis.
NeuralLP requires a lot more grids before it can learn the
desired rules whereas we learn almost perfect rules after ob-
serving as few as 20 training grids. Essentially, in comparison
to product t-norm, due to the extra learnable parameters in
LNN-∧, we can learn with fewer learning iterations. Figure 5
(b) shows the weights for the LNN rule for GoSouth(X, Y )
on the edges and biases in parenthesis. This rule allows the
agent to go South if 1) target is in that direction and, 2) there
is no obstacle to the immediate South of the current cell. De-
spite the leaves of the template containing 8 predicates each in
their respective domains, the learned LNN-preds are quite
sparse and thus highly interpretable. The left LNN-pred as-
signs 1 non-zero weight to ¬HasObstacleSouth out of
all HasObstacle-dir predicates and their negated counter-
parts, and the right LNN-pred assigns 1 non-zero weight to
HasTargetSouth out of all HasTarget-dir predicates
and their negated counterparts. This may be due to the use
of relu1 in LNN-pred whose sparsity-inducing properties
have been noted before (Krizhevsky 2010). In Figure 5 (c),
we also plot GoSouth(X, Y )’s learned LNN-∧.

5.2 Knowledge Base Completion
Knowledge base completion (KBC) is a standard benchmark
for ILP. We experiment with publicly available KBC datasets
Kinship, UMLS (Kok and Domingos 2007), WN18RR
(Dettmers et al. 2018), and FB15K-237 (Toutanova and Chen
2015) 2 (see Table 1 for statistics). We compare against a
host of rule-based KBC approaches: NeuralLP (Yang, Yang,
and Cohen 2017), DRUM (Sadeghian et al. 2019), CTP (Min-
ervini et al. 2020b) which is an improvement on neural theo-
rem provers (Rockt¨aschel and Riedel 2017), and the recently
proposed RNNLogic3 (Qu et al. 2021).

2All available at github.com/shehzaadzd/MINERVA
3We compare with rules-only RNNLogic (“w/o embd.”), since

using embeddings is out of scope of this work.

Table 1: Statistics of KBC datasets.

Name
UMLS
Kinship
WN18RR
FB15K-237

Vertices
135
104
40945
14505

Predicates
49
26
11
237

Facts
5216
10686
86835
272115

Queries
661
1074
3134
20466

Task Description and Template: A popular abstraction of
the KBC task is to complete edges or triples missing from
the knowledge graph (KG). More precisely, given a query
(cid:104)h, r, ?(cid:105), where h denotes a source vertex and r denotes a
relation from the KG, most KBC approaches provide a ranked
list of destination vertices. Most of the aforementioned rule-
based KBC approaches exclusively focus on learning chain
FOL rules as discussed in Section 2. There are at least two
prevalent approaches to learn chain rules for KBC. The ﬁrst
approach (Yang, Yang, and Cohen 2017; Sadeghian et al.
2019) represents each predicate in the body as a mixture of
relations present in the KG, and subsequently combines these
via a conjunction operator. Figure 3 (c)’s template captures
this where the subtree rooted at R deﬁnes chain rules of
length 2 predicates and O captures length 1 thus enabling
learning of chain rules capturing multi-hop paths of length
up to 2. The only change we need to make to this template
is to include all relations in the KG into the domains of the
leaves. It is also easy to extend the template to learn longer
chain rules. A different approach, pioneered by MINERVA
(Das et al. 2018) and RNNLogic (Qu et al. 2021), is to deﬁne
the chain rule as a mixture over all possible paths that can
exist in the KG. This latter approach leads to more effective
KBC and thus we report results by expressing it in our LNN
framework as follows: 1) Express each possible multi-hop
path as a base relation, and 2) Use one LNN-pred operator to
express a mixture over all multi-hop paths.
Metrics and Methodology: We learn a chain rule per rela-
tion present in the KG. Following previous work (Yang, Yang,
and Cohen 2017), we also add inverse relations to the KG
which switches the source and destination vertices. We also
include inverse triples into our test set. We compute ﬁltered
ranks for destinations (Bordes et al. 2013), which removes all
true triples ranked above, and compute the following metrics
based on Sun et al. (2020)’s suggestions. Let n denote the
number of destinations that have a score strictly greater than

-1.2-1-0.8-0.6-0.4-0.2 0 0.2 0.4 0.6 0.8 0 20 40 60 80 100OursNeuralLP 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1¬HasObstacleSouthHasTargetSouth 0 0.2 0.4 0.6 0.8 1GoSouth LNN-∧Table 2: KBC Results: Bold font denotes best in row. CTP
does not scale to WN18RR, FB15K-237. * indicates results
copied from original paper.

Kinship

UMLS

WN18RR

FB15K-237

Hits@10
Hits@3
MRR
Hits@10
Hits@3
MRR
Hits@10
Hits@3
MRR
Hits@10
Hits@3
MRR

NeuralLP
89.1
63.0
48.8
93.0
75.4
55.3
50.2
43.3
33.7
32.8
19.8
17.4

DRUM CTP
93.9
86.1
79.7
48.2
70.3
40.0
97.0
97.9
91.0
91.2
80.1
61.8
−
52.1
−
44.6
−
34.8
−
33.1
−
20.0
−
17.5

RNNLogic
91.1
72.9
64.5
91.1
82.1
71.0
53.1∗
47.5∗
45.5∗
44.5∗
31.5∗
28.8∗

Ours
98.4
89.3
81.9
99.4
98.3
90.0
55.5
49.7
47.3
47.0
34.2
30.7

destination t’s and let the number of destinations assigned
the same score as t’s be denoted by m (including t), then we
compute t’s mean reciprocal rank (MRR) and Hits@K as:

MRR =

1
m

n+m
(cid:88)

r=n+1

1
r

, Hits@K =

1
m

n+m
(cid:88)

r=n+1

δ(r ≤ K)

where δ() denotes the Dirac delta function. For each method,
we report averages across all test set triples. We learn chain
rules containing up to 3 predicates for Kinship and UMLS, 4
for FB15K-237, and 5 for WN18RR in the body of the rule.
We provide additional details including the training algorithm
used and hyperparameter tuning in Appendix A.
Results: Table 2 reports results for all methods. While CTP
improves upon the efﬁciency of neural theorem provers
(Rockt¨aschel and Riedel 2017), it still does not scale be-
yond Kinship and UMLS (indicated by −). Also, we copy
previously published results for RNNLogic on WN18RR and
FB15K-2374 (indicated by ∗). On the smaller datasets, CTP
is the best baseline but our results are signiﬁcantly better
producing 16.5% and 12.4% relative improvements in MRR
on Kinship and UMLS, respectively. On the larger datasets,
RNNLogic is the current state-of-the-art within rule-based
KBC and we outperform it producing 4% and 6.6% rela-
tive improvements in MRR on WN18RR and FB15K-237,
respectively. Despite both learning a mixture over relation
sequences appearing on KG paths, one reason for our relative
success could be that RNNLogic uses an inexact training algo-
rithm (Qu et al. 2021), relying on expectation-maximization,
ELBO bound, whereas we employ no such approximations.
Learned Rules for FB15K-237: Table 3 presents a few
rules learned from FB15K-237. Rule 1 in Table 3 infers
the language a person speaks by exploiting knowledge of
the language spoken in her/his country of nationality. In
nationality
−→
terms of multi-hop path, this looks like: P (person)

spoken in

N (nation)
−→ L(language). Similarly, Rule 2 uses the
ﬁlm country relation instead of nationality to infer the lan-
guage used in a ﬁlm. Besides spoken in, FB15K-237 contains

4Despite exchanging multiple emails with its authors, we were

unable to run RNNLogic code on the larger KBC datasets.

Table 3: Learned rules from FB15K-237.

person language(P, L) ← nationality(P, N ) ∧ spoken in(L, N )
ﬁlm language(F, L) ← ﬁlm country(F, C) ∧ spoken in(L, C)

1)
2)
3) tv program language(P, L) ← country of tv program(P, N ) ∧

ofﬁcial language(N, L)

4)
5) tv program country(P, N ) ← tv program actor(P, A) ∧

burial place(P, L) ← nationality(P, N ) ∧ located in(L, N )

born in(A, L) ∧ located in(L, N )

6) ﬁlm release region(F, R) ← ﬁlm crew(F, P ) ∧

7)

marriage location(P, L) ← celebrity friends(P, F ) ∧

marriage location(P, L) ∧ located in(L, R)

marriage location(F, L(cid:48)) ∧ location adjoins(L(cid:48), L)

other relations that can be utilized to infer language such as
the ofﬁcial language spoken in a country. Rule 3 uses this
relation to infer the language spoken in a TV program by
ﬁrst exploiting knowledge of its country of origin. Rules 5,
6 and 7 are longer rules containing 3 relations each in their
body. Rule 5 infers a TV program’s country by ﬁrst exploiting
knowledge of one of its actor’s birth place and then determin-
ing which country the birth place belongs to. Rule 6 is similar
but uses a ﬁlm crew member’s marriage location instead to
infer the region where the ﬁlm was released. Lastly, Rule
7 infers the marriage location of a celebrity by exploiting
knowledge of where their friends got married.
Additional KBC Results: Due to space constraints, in
Appendix B we report results on the Countries dataset
(Bouchard, Singh, and Trouillon 2015) for which ground
truth rules are known. On Countries, our KBC accuracy is
comparable to other approaches and the learned LNN rules
form a close match with the ground truth rules speciﬁed in
Nickel, Rosasco, and Poggio (2016).

6 Conclusion
Our experiments show that learning rules and logical connec-
tives jointly is not only possible but leads to more accurate
rules than other neuro-symbolic ILP approaches. Templates
provide a ﬂexible way to express a wide range of ILP tasks.
The templates used for Gridworld and KBC are distinct, yet
we outperformed baselines in both cases. LNN rules use
weights sparingly and are eminently interpretable while LNN
operators’ constraint formulation ensures close ties to classi-
cal logic’s precise semantics compared to other approaches
(e.g., NLM). While our neural network requires grounding
the KB, our approach is still scalable enough to tackle the
larger KBC benchmarks whereas others are not (e.g., CTP).
In terms of future work, we aim to combine the ideas pre-
sented here with embedding of predicates and constants in a
high-dimensional latent space to hopefully further improve
performance. We would also like to extend our approach to
learn more general Prolog-style rules.

References
Bordes, A.; Usunier, N.; Garcia-Duran, A.; Weston, J.; and
Yakhnenko, O. 2013. Translating embeddings for modeling
multi-relational data. In NeurIPS.
Bouchard, G.; Singh, S.; and Trouillon, T. 2015. On Approx-

imate Reasoning Capabilities of Low-Rank Vector Spaces.
In AAAI.
Das, R.; Dhuliawala, S.; Zaheer, M.; Vilnis, L.; Durugkar,
I.; Krishnamurthy, A.; Smola, A.; and McCallum, A. 2018.
Go for a Walk and Arrive at the Answer: Reasoning Over
Paths in Knowledge Bases using Reinforcement Learning. In
ICLR.
Dettmers, T.; Minervini, P.; Stenetorp, P.; and Riedel, S. 2018.
Convolutional 2d knowledge graph embeddings. In Thirty-
second AAAI conference on artiﬁcial intelligence.
Donadello, I.; Seraﬁni, L.; and d’Avila Garcez, A. S. 2017.
Logic Tensor Networks for Semantic Image Interpretation.
In IJCAI.
Dong, H.; Mao, J.; Lin, T.; Wang, C.; Li, L.; and Zhou, D.
2019. Neural Logic Machines. In ICLR.
Esteva, F.; and Godo, L. 2001. Monoidal t-norm based logic:
Towards a logic for left-continuous t-norms. Fuzzy Sets and
Systems.
Evans, R.; and Grefenstette, E. 2018. Learning Explanatory
Rules from Noisy Data. JAIR.
Frerix, T.; Nießner, M.; and Cremers, D. 2020. Homogeneous
Linear Inequality Constraints for Neural Network Activations.
In CVPR Workshops.
Getoor, L.; and Taskar, B. 2007. Introduction to Statistical
Relational Learning (Adaptive Computation and Machine
Learning). The MIT Press.
Goodfellow, I.; Warde-Farley, D.; Mirza, M.; Courville, A.;
and Bengio, Y. 2013. Maxout Networks. In ICML.
Kazemi, S. M.; and Poole, D. 2018. RelNN: A Deep Neural
Model for Relational Learning. In AAAI.
Kok, S.; and Domingos, P. 2007. Statistical predicate inven-
tion. In Proceedings of the 24th international conference on
Machine learning, 433–440.
Krizhevsky, A. 2010. Convolutional deep belief networks on
CIFAR-10. Unpublished Manuscript.
Manhaeve, R.; Dumancic, S.; Kimmig, A.; Demeester, T.;
and Raedt, L. D. 2018. DeepProbLog: Neural Probabilistic
Logic Programming. CoRR.
Minervini, P.; Bosnjak, M.; Rockt¨aschel, T.; Riedel, S.; and
Grefenstette, E. 2020a. Differentiable reasoning on large
knowledge bases and natural language. In AAAI.
Minervini, P.; Riedel, S.; Stenetorp, P.; Grefenstette, E.; and
Rockt¨aschel, T. 2020b. Learning Reasoning Strategies in
End-to-End Differentiable Proving. In ICML.
Motzkin, T. S.; Raiffa, H.; Thompson, G. L.; and Thrall, R. M.
1953. The double description method. Contributions to the
Theory of Games.
Muggleton, S. 1996. Learning from positive data. In Worshop
on ILP.
Muggleton, S. H.; Lin, D.; Pahlavi, N.; and Tamaddoni-
Nezhad, A. 2014. Meta-interpretive Learning: Application
to Grammatical Inference. Machine Learning.
Nair, V.; and Hinton, G. 2010. Rectiﬁed Linear Units Improve
Restricted Boltzmann Machines. In ICML.

Nickel, M.; Rosasco, L.; and Poggio, T. 2016. Holographic
Embeddings of Knowledge Graphs. In AAAI.
Qu, M.; Chen, J.; Xhonneux, L.-P.; Bengio, Y.; and Tang, J.
2021. {RNNL}ogic: Learning Logic Rules for Reasoning on
Knowledge Graphs. In ICLR.
Riegel, R.; Gray, A.; Luus, F.; Khan, N.; Makondo, N.; Akhal-
waya, I. Y.; Qian, H.; Fagin, R.; Barahona, F.; Sharma, U.;
Ikbal, S.; Karanam, H.; Neelam, S.; Likhyani, A.; and Srivas-
tava, S. 2020. Logical Neural Networks. CoRR.
Rockt¨aschel, T.; and Riedel, S. 2017. End-to-End Differen-
tiable Proving. In NeurIPS.
Sadeghian, A.; Armandpour, M.; Ding, P.; and Wang, D. Z.
2019. DRUM: End-To-End Differentiable Rule Mining On
Knowledge Graphs. In NeurIPS.
Sourek, G.; Svatos, M.; Zelezny, F.; Schockaert, S.; and
Kuzelka, O. 2017. Stacked Structure Learning for Lifted
Relational Neural Networks. In International Conference on
Inductive Logic Programming.
Sun, Z.; Vashishth, S.; Sanyal, S.; Talukdar, P.; and Yang,
Y. 2020. A Re-evaluation of Knowledge Graph Completion
Methods. In ACL.
Toutanova, K.; and Chen, D. 2015. Observed versus latent
features for knowledge base and text inference. In Proceed-
ings of the 3rd workshop on continuous vector space models
and their compositionality, 57–66.
Yang, F.; Yang, Z.; and Cohen, W. W. 2017. Differentiable
Learning of Logical Rules for Knowledge Base Reasoning.
In NeurIPS.

A Implementation Details for KBC

Experiments

Given a training knowledge graph G = (cid:104)V, R, E(cid:105) whose
vertices are given by V, edges are given by E and relations
are given by R, we learn a chain FOL rule for each r ∈ R
independently. Each edge in E is given by a triple (cid:104)h, r, t(cid:105)
where h, t ∈ V denote source and destination vertices, and
r ∈ R denotes a relation. Following previous work (Yang,
Yang, and Cohen 2017), we also add inverse relations. In
other words, for each r ∈ R we introduce a new relation r−1
by adding for each (cid:104)h, r, t(cid:105) ∈ E a new triple (cid:104)t, r−1, h(cid:105) to
G. Learning to predict destinations for a given relation r in
the augmented set of relations is essentially a binary classi-
ﬁcation task where (cid:104)h, r, t(cid:105) ∈ E and (cid:104)h, r, t(cid:105) /∈ E, ∀h, t ∈ V,
denote positive and negative examples, respectively.
Training Algorithm & Hyperparameter Settings: In each
iteration, we sample uniformly at random a mini-batch of
positive triples B+ from (cid:104)h, r, t(cid:105) ∈ E and negative triples
B− from (cid:104)h, r, t(cid:105) /∈ E, ∀h, t ∈ V, such that |B+| = |B−| to
minimize the following loss:

(cid:88)

(cid:88)

(cid:104)h,r,t(cid:105)∈B+

(cid:104)h(cid:48),r,t(cid:48)(cid:105)∈B−

max{0, score(h(cid:48), t(cid:48))−score(h, t)+γ}

where γ denotes the margin hyperparameter. We use
Adagrad (?) with step size ∈ {0.1, 1.0}, margin γ ∈
{0.1, 0.5, 1.0, 2.0} and batch size |B+| = |B−| = 8. We
use the validation set to perform hyperparameter tuning and

1.125

LNN-∧ (1.119)

locIn(X,Z)

1.125

1.125

(0)

LNN-pred

(0)

LNN-pred

(0)

LNN-pred

1.034

0.042

1.033

0.042

0.001

1.075

ngbrOf(X,W)

locIn(X,W)

ngbrOf(W,Y)

locIn(W,Y)

ngbrOf(Y,Z)

locIn(Y,Z)

NeuralLP
locIn(X, Z) ←locIn(X, W ) ∧ locIn(W, Y ) ∧ ngbrOf(Z, Y )

locIn(X, Z) ←locIn(X, W ) ∧ locIn(W, Y ) ∧ ngbrOf(Y, Z)

locIn(X, Z) ←locIn(X, W ) ∧ locIn(W, Y ) ∧ locIn(Z, Y )

locIn(X, Z) ←locIn(X, W ) ∧ locIn(W, Y ) ∧ locIn(Y, Z)

locIn(X, Z) ←locIn(X, Y ) ∧ locIn(Y, Z)

CTP : ngbrOf(X, Y ) ← ngbrOf(Y, X)

Figure 6: LNN-rule (left) vs. NeuralLP’s (5) rules (top right) vs. CTP’s rule (bottom right) for Countries-S3.

Table 4: AUC-PR Results on Countries

NLM
58.06 ± 2.4
40.57 ± 5.3
53.37 ± 2.8

NTP-λ
100 ± 0
93.04 ± 0.4
77.26 ± 17.0

CTP
99.6 ± 0.5
92.4 ± 1.7
55.4 ± 3.5

NeuralLP
100 ± 0
75.1 ± 0.3
92.2 ± 0.2

Ours
100 ± 0
92.3 ± 0
91.3 ± 0

S1
S2
S3

learn rules of length up to 4 for FB15K-237, 5 for WN18RR,
and 3 for Kinship, UMLS.

B Additional KBC Experiments

Besides the experiments presented in Section 5, we also
experiment with the Countries dataset (Bouchard, Singh,
and Trouillon 2015) which contains 272 vertices, 1158 facts
and 2 predicates locatedIn(X, Y ) (abbreviated locIn)
and neighborOf(X, Y ) (abbreviated ngbrOf). Follow-
ing previous work (Das et al. 2018), we report area under the
precision-recall curve (AUC-PR).

Nickel, Rosasco, and Poggio (2016) permute the facts in
this dataset to pose 3 learning tasks {S1, S2, S3} each cor-
responding to learning a different rule. S1 and S2’s rules
contain 2 predicates in their bodies, whereas S3’s body con-
tains 3. We use S(X, Z) ← P (X, Y ) ∧ Q(Y, Z) as template
for S1 and S2, and S(X, Z) ← P (X, W ) ∧ Q(W, Y ) ∧
O(Y, Z) for S3, where Dom(P ) = Dom(Q) = Dom(O) =
{locIn, ngbrOf}. We compare against NeuralLP5 (Yang,
Yang, and Cohen 2017), neural theorem provers6 (NTP-λ)
(Rockt¨aschel and Riedel 2017), conditional theorem provers7
(CTP) (Minervini et al. 2020b) and neural logic machines8
(NLM) (Dong et al. 2019).

Table 4 reports averages across 3 runs. The NLM imple-
mentation we report results with is quite pessimistic almost
never predicting a link. All other approaches achieve perfect
AUC-PR on S1. We outperform NeuralLP on S2 and NTP
shows high variance on S39 perhaps due to its excessive pa-
rameterization (NTP learns embeddings for predicates and
vertices). CTP performs well on the ﬁrst two tasks but fails
on S3. To ﬁnd out why, we take a close look at the learned
rules next.

5github.com/fanyangxyz/Neural-LP
6github.com/uclnlp/ntp
7github.com/uclnlp/ctp
8github.com/google/neural-logic-machines
9NTP’s high variance on S2 is also noted in Das et al. (2018).

The goal in S2 and S3 (Countries) is to learn the following

rules (Nickel, Rosasco, and Poggio 2016):
(S2) locIn(X,Z) ← ngbrOf(X,Y) ∧ locIn(Y,Z)
(S3) locIn(X,Z) ← ngbrOf(X,W) ∧ ngbrOf(W,Y) ∧
locIn(Y,Z)

We compare the rules learned by our approach, NeuralLP
and CTP for Countries-S3. NeuralLP produces a weighted
list of 5 rules (see Figure 6 top right, weights omitted) none
of which capture the correct rule shown above. CTP learns
that ngbrOf is a symmetric relation (Minervini et al. 2020b)
which makes sense (Figure 6 bottom right). Unfortunately
however, all facts that need to be proved in the test set of
Countries-S3 pertain to locIn predicate which explains
why CTP’s AUC-PR for Countries-S3 is so poor (Table 4).
In contrast, the learned LNN-rule shown in Figure 6 (left)
is a near perfect translation of the correct logical rule into
real-valued logic. Note that, the leftmost and middle LNN-
preds place a large weight on ngbrOf vs. a small weight
on locIn while the rightmost LNN-pred does the opposite,
which lines up perfectly with the rule to be learned.

We also compared the rules learned for S2. Just as in the
case of S3, for S2, the learned LNN rule’s (shown in Figure
7) left LNN-pred places a large weight on ngbrOf while
placing a small weight on locIn whereas the right LNN-
pred does the opposite, closely matching the correct FOL
rule shown above. The list of rules learned by NeuralLP
(weight depicted in parenthesis) is shown below:

locIn(X, Z) ← locIn(X, Y ) ∧ ngbrOf(Z, Y )
locIn(X, Z) ← locIn(X, Y ) ∧ ngbrOf(Y, Z)
locIn(X, Z) ← locIn(X, Y ) ∧ locIn(Z, Y )
locIn(X, Z) ← locIn(X, Z)
locIn(X, Z) ← locIn(X, Y ) ∧ locIn(Y, Z)
none of which match the correct rule to be learned for S2.
CTP learns the following rule (Minervini et al. 2020b):

LNN-∧ (1.056)

locIn(X,Z)

1.059
LNN-pred

(0)

1.059
LNN-pred (0)

1.228

0.002

0.04

1.186

ngbrOf(X,Y)

locIn(X,Y)

ngbrOf(Y,Z)

locIn(Y,Z)

Figure 7: LNN rule learned from Countries-S2

ngbrOf(X, Z) ← ngbrOf(X, Y ) ∧ locIn(Y, Z)

Not only does this rule not match the correct rule to be
learned, it is also not very useful from the perspective of
proving facts in the test set which pertain to predicate locIn
exclusively.

