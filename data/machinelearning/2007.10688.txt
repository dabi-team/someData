0
2
0
2

l
u
J

1
2

]
L
P
.
s
c
[

1
v
8
8
6
0
1
.
7
0
0
2
:
v
i
X
r
a

What Programs Want
Automatic Inference of Input Data Speciﬁcations

Caterina Urban1,2

1 INRIA, Paris, France
2 DIENS, ´Ecole Normale Sup´erieure, CNRS, PSL University, Paris, France
caterina.urban@inria.fr

Abstract. Nowadays, as machine-learned software quickly permeates
our society, we are becoming increasingly vulnerable to programming er-
rors in the data pre-processing or training software, as well as errors in the
data itself. In this paper, we propose a static shape analysis framework
for input data of data-processing programs. Our analysis automatically
infers necessary conditions on the structure and values of the data read by
a data-processing program. Our framework builds on a family of underly-
ing abstract domains, extended to indirectly reason about the input data
rather than simply reasoning about the program variables. The choice of
these abstract domain is a parameter of the analysis. We describe various
instances built from existing abstract domains. The proposed approach
is implemented in an open-source static analyzer for python programs.
We demonstrate its potential on a number of representative examples.

1

Introduction

Due to the availability of vast amounts of data and corresponding tremendous
advances in machine learning, computer software is nowadays an ever increasing
presence in every aspect our society. As we rely more and more on machine-
learned software, we become increasingly vulnerable to programming errors but
(in contrast to traditional software) also errors in the data used for training.

In general, before software training, the data goes through long pre-processing
pipelines3. Errors can be missed, or even introduced, at any stage of these
pipelines. This is even more true when data pre-processing stages are disre-
garded as single-use glue code and, for this reason, are poorly tested, let alone
statically analyzed or veriﬁed. Moreover, this kind of code is often written in a
rush and is highly dependent on the data (e.g., the use of magic constants is
not uncommon) All this together, greatly increases the likelihood for errors to
be noticed extremely late in the pipeline (which entails a more or less important
waste of time), or more dangerously, to remain completely unnoticed.

3 https://www.nytimes.com/2014/08/18/technology/for-big-data-scientists-

hurdle-to-insights-is-janitor-work.html

 
 
 
 
 
 
2

Caterina Urban

5

6

7

8

9

10

11

1 g r a d e 2gpa = { ’ A ’ : 4 . 0 , ’ B ’ : 3 . 0 , ’ C ’ : 2 . 0 , ’ D ’ : 1 . 0 , ’ F ’ : 0 . 0 }
2 s t u d e n t s = i n t ( input ( ) )
3 f o r
4

in range ( s t u d e n t s ) :

name = input ( )
c l a s s e s = i n t ( input ( ) )
gpa = 0 . 0
f o r

in range ( c l a s s e s ) :

g r a d e = input ( )
gpa += g r a d e 2gpa [ g r a d e ]

r e s u l t = gpa / c l a s s e s
print ( ’ { } : { } ’.format ( name ,

r e s u l t ) )

Fig. 1: Simple GPA calculator for multiple students.

Motivating Example. As an example, let us consider the data processing
python code shown in Figure 1, which calculates the simple GPA for a given
number of students (cf. Line 2). For each class taken by a student (cf. Line 7),
their (A-F) grade is converted into a numeric (4-0) grade, and all numeric grades
are added together (cf. Line 9). The GPA is obtained by dividing this by the
number of classes taken by the student (cf. Line 10).

Even this small program makes several assumptions on its input data. For
instance, it assumes that the very ﬁrst input read by the program (cf. Line 2)
is a string representation of an integer number that indicates how many student
records follow in the data ﬁle (cf. Line 3). A similar assumption holds for the
second input read for each student record (cf. Line 5), which should indicate
how many student grades follow in the data ﬁle (cf. Line 7). This number should
be diﬀerent from zero (or the division at Line 10 would raise a ZeroDivisionError).
Finally, the program assumes that each grade read at Line 8 is a string in the set
{’A’, ’B’, ’C’, ’D’, ’F’} (or the dictionary access at Line 9 would raise a KeyError).
Note that, not all assumptions necessarily lead to a program error if violated.
For instance, consider the following data stream:

1 Emma 1 A F

(cid:2)

A mistake is indicated by the arrow: the number of classes taken by the student
Emma is oﬀ by one (i.e., it should be 2 instead of 1). In this case the program in
Figure 1 will not raise any error but will instead compute a wrong (but plausible!)
GPA for Emma (i.e., 4.0 instead of 2.0).

Our Approach. To address these issues, we propose an abstract interpretation-
based shape analysis framework for input data of data-processing programs. The
analysis automatically infers implicit assumptions on the input data that are em-
bedded in the source code of a program. Speciﬁcally, we infer assumptions on the
structure of the data as well as on the values and the relations between the data.
We propose a new data shape abstract domain, capable of reasoning about the
input data in addition to the program variables. The domain builds on a family
of underlying over-approximating abstract domains, which collect constraints

What Programs Want

3

on the program variables and, indirectly, on the input data of a program. The
abstract domain is parametric in the choice of the underlying domains.

Thus, our analysis infers necessary conditions on the data read by the pro-
gram, i.e., conditions such that, if violated, guarantee that the program will
execute unsuccessfully or incorrectly. This approach suﬀers from false negatives.
However, we argue that this is preferable in practice to overwhelming data sci-
entists with possibly many false positives (as with suﬃcient conditions).

Back to our motivating example, the analysis (parameterized by the sign
abstract domain [13] and the ﬁnite string set domain [9]) infers that data ﬁles
read by the program in Figure 1 have the following shape:

d1






d3

1

2

3

int ≥ 0
string
int ≥ 0

(cid:40) 4 string ∈ {’A’, ’B’, ’C’, ’D’, ’F’}

...
...

. . .

where di denotes the data at line i of the data ﬁle. Thus, the analysis would
detect the mistake discussed above, since a data ﬁle containing the erroneous
data does not match this inferred condition.

Note that, in general, a mismatch between a data ﬁle and a data-processing
program indicates a mistake either in data or in the source code of the program.
Our analysis does not aim to address this question. More generally, the result of
our analysis can be used for a wide range of applications: from code speciﬁcations
[14], to grammar-based testing [29], to automatically checking and guiding the
cleaning of the data [1,38].

Outline. Section 2 introduces the syntax and concrete semantics of our data-
processing programs. In Section 3, we deﬁne and present instances of the under-
lying abstract domains. We describe the rest our data shape abstract domain in
Section 4 and deﬁne the abstract semantics in Section 5. Our prototype static
analyzer is presented in 6. Finally, Section 7 discusses related work and Section 8
concludes and envisions future work.

2

Input Data-Aware Program Semantics

Input Data. We consider tabular data stored, e.g., in CSV ﬁles. We note, how-
ever, that what we present easily generalizes to other ﬁles as, e.g., spreadsheets.
Let S be a set of string values. Furthermore, let Sint ⊆ S and Sﬂoat ⊆ S
be the sets of string values that can be interpreted as integer and ﬂoat values,
respectively. We formalize a data ﬁle as a possibly empty (r × c)-matrix of string
values, where r ∈ N and c ∈ N denote the number of matrix row (i.e., data

4

Caterina Urban

A ::= X
| v
|
| A1 (cid:5) A2

input() |

int(A) | ﬂoat(A)

B ::= A1 (cid:46)(cid:47) A2

| B1 ∨ B2 | B1 ∧ B2

S ::= lX := A

if lB then S1 else S2 ﬁ
for lA do S od | while lB do S od

|
|
| S1; S2

P ::= Sl

Fig. 2: Syntax

X ∈ X
v ∈ V

(cid:5) ∈ {+, −, ∗, /}

(cid:46)(cid:47) ∈ {<, ≤, =, (cid:54)=, >, ≥}

l ∈ L, X ∈ X
l ∈ L
l ∈ L

l ∈ L

records) and columns (i.e., data ﬁelds), respectively. We write (cid:15) to denote an
empty data ﬁle. Let

(cid:91)

(cid:91)

D def=

Sr×c

(2.1)

r∈N

c∈N

be the set of all data ﬁles. Without loss of generality, to simplify our formaliza-
tion, we assume that data records contain only one ﬁeld, i.e., r = 1. We lift this
assumption and consider multiple data ﬁelds in Section 3.2.

Data-Processing Language. We consider a toy python-like programming
language for data manipulation, which we use for illustration throughout the rest
of the paper. Let X be a ﬁnite set of program variables, and let V def= Z∪F∪S be a
set of values partitioned in sets of integer (Z), ﬂoat (F), and string (S) values. The
syntax of programs is deﬁned inductively in Figure 2. A program P consists of
an instruction S followed by a unique label l ∈ L. Another unique label appears
within each instruction. Programs can read data from an input data ﬁle: the
input() expression consumes a record from the input data ﬁle. Without loss
of generality, to simplify our formalization, we assume that only the right-hand
sides of assignments can contain input() sub-expressions. (Programs can always
be rewritten to satisfy this assumption.) The for A do S od instruction repeats
an instruction S for A times. The rest of the language syntax is standard.

Input-Aware Semantics. We can now deﬁne the (concrete) semantics of the
data-processing programs. This semantics diﬀers from the usual semantics in that
it is input data-aware, that is, it explicitly considers the data read by programs.
An environment ρ : X → V maps each program variable X ∈ X to its value

ρ(X) ∈ V. Let E denote the set of all environments.

The semantics of an arithmetic expression A is a function A

: E×D → V×
D mapping an environment and a data ﬁle to the value (in V) of the expression

A

(cid:75)

(cid:74)

What Programs Want

5

S (cid:114)lX := A(cid:122) W def= {(cid:104)ρ, D(cid:105) ∈ E × D | (cid:104)v, R(cid:105) = A

S (cid:114)if lB then S1 else S2 ﬁ(cid:122) W def= W 1 ∪ W 2

(cid:104)ρ, D(cid:105), (cid:104)ρ[X (cid:55)→ v], R(cid:105) ∈ W }

A
(cid:75)
(cid:74)

W 1 def= {(cid:104)ρ, D(cid:105) ∈ E × D | tt = B

W 2 def= {(cid:104)ρ, D(cid:105) ∈ E × D | ﬀ = B

ρ, (cid:104)ρ, D(cid:105) ∈ S

ρ, (cid:104)ρ, D(cid:105) ∈ S

B
(cid:74)
B
(cid:74)

(cid:75)

(cid:75)

W }

W }

(cid:75)

S1
(cid:74)
S2
(cid:74)

(cid:75)
A
(cid:75)
(cid:74)
(cid:104)ρ, D(cid:105), v > 0,

S (cid:114)for lA do S od(cid:122) W def= {(cid:104)ρ, D(cid:105) ∈ E × D | (cid:104)0, D(cid:105) = A

(cid:104)ρ, D(cid:105), (cid:104)ρ, D(cid:105) ∈ W } ∪ W (cid:48)

(cid:26)

W (cid:48) def=

(cid:104)ρ, D(cid:105) ∈ E × D

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:104)v, D(cid:105) = A

A
(cid:75)
(cid:74)
(cid:104)ρ, D(cid:105) ∈ S (cid:113)S; for lA − 1 do S od(cid:121) W

(cid:27)

S (cid:114)while lB do S od(cid:122) W def= lfp F

F (Y ) def= {(cid:104)ρ, D(cid:105) ∈ E × D | ﬀ = B

ρ, (cid:104)ρ, D(cid:105) ∈ W } ∪ W (cid:48)

B
(cid:74)
B
(cid:74)

(cid:75)

(cid:75)
ρ, (cid:104)ρ, D(cid:105) ∈ S

Y }

S
(cid:74)

(cid:75)

W (cid:48) def= {(cid:104)ρ, D(cid:105) ∈ E × D | tt = B

S

S1; S2
(cid:74)

(cid:75)

W def= S

◦ S

S1
(cid:74)

(cid:75)

W

S2
(cid:74)

(cid:75)

Fig. 3: Input-Aware Concrete Semantics of Instructions

in the given environment and given the data read from the ﬁle (if any), and the
(rest of) the data ﬁle (in D) after the data is consumed.

Example 1. Let ρ be an environment that maps the variable gpa to the value 3.0,



4.0



and let D =

1.0



 be a data ﬁle containing three data records. We consider the

3.0

expression gpa + input(), which simpliﬁes the right-hand side of the assignment

at line 9 in Figure 1. Its semantics is A

gpa + input()
(cid:75)
(cid:74)

=

7.0,

(cid:18)

(cid:21)(cid:19)

(cid:20)1.0
3.0

.

(cid:4)

We also deﬁne the standard input-agnostic semantics A(cid:48)

: E → P (V)
mapping an environment to the set of all possible values of the expression in the
environment: A(cid:48)

ρ def= {v ∈ V | ∃D ∈ D : (cid:104)v, (cid:105) = A
Similarly, the semantics of a boolean expression B

(cid:104)ρ, D(cid:105)}.
: E → {tt, ﬀ} maps an

A

A

(cid:75)

(cid:74)

(cid:75)

(cid:74)

environment to the truth value of the expression in the given environment.

A
(cid:75)
(cid:74)
B
(cid:75)
(cid:74)

P

The semantics of programs ∆

: L → P (E × D) maps each program label
l ∈ L to the set of all pairs of environments that are possible when the program
execution is at that label, and input data ﬁles that the program can fully read
without errors starting from that label. We deﬁne this semantics backwards,
starting from the ﬁnal program label where all environments in E are possible
but only the empty data ﬁle (cid:15) can be read from that program label:

(cid:74)

(cid:75)

= ∆ (cid:113)Sl(cid:121)

def= ∆

∆

P
(cid:74)

(cid:75)

(cid:32)

(cid:40)

λp.

S

(cid:74)

(cid:75)

E × {(cid:15)}
undeﬁned otherwise

p = l

(cid:33)

(2.2)

6

Caterina Urban

Fig. 4: Data Shape Abstract Domain.

In Figure 3, we (equivalently) deﬁne the semantics ∆
: (L → P (E × D)) →
(L → P (E × D)) of each instruction pointwise within P (E × D): each function
: P (E × D) → P (E × D) takes as input a set W of pairs of environments
S
and data ﬁles and outputs the pairs of possible environments and data ﬁles that
can be read from the program label within the instruction S.

S
(cid:74)

S

(cid:75)

(cid:74)

(cid:75)

Example 2. Let ρ(cid:48) be an environment that maps the variable gpa to the value 7.0,

and let R =

be a data ﬁle. We consider the assignment gpa := gpa+input()

which simpliﬁes the assignment at line 9 in Figure 1. Its semantics, given W =
{(cid:104)ρ(cid:48), R(cid:105)}, is S
W = {(cid:104)ρ, D(cid:105)} where ρ maps the variable

(cid:21)

(cid:20)1.0
3.0

gpa := gpa + input()
(cid:74)
gpa to the value 3.0 and D =

1.0

4.0





(cid:75)



 (see Example 1).

(cid:4)

3.0

(cid:75)

P
(cid:74)

Data Shape Abstraction. In the following sections, we design a decidable
abstraction of ∆
which over-approximates the concrete semantics of P at
each program label l ∈ L. As a consequence, this abstraction yields necessary
preconditions for a program to execute successfully and correctly. In particular,
if a data ﬁle is not in the abstraction, the program will deﬁnitely eventually run
into an error or compute a wrong result if it tries to read data from it. On the
other hand, if a data ﬁle is in the abstraction there is no guarantee that the
program will execute successfully and correctly when reading data from it.

(cid:74)

P

We derive the abstraction ∆(cid:92)

: L → Q by abstract interpretation [12].
No approximation is made on L. On the other hand, each program label l ∈ L
is associated to an element Q ∈ Q of the data shape abstract domain Q. Q
over-approximates the possible environments and data ﬁles read starting from l.
An overview of the data shape abstract domain is given in Figure 4. It is
parameterized by a family K1, . . . , Kk of constraining abstract domains, which
collect constraints on the program variables, and an input abstract domain H,

(cid:75)

What Programs Want

7

which collects constraints on the input data read by the program. We now present
and describe instances of these abstract domains, before deﬁning ∆(cid:92)

.

P
(cid:74)

(cid:75)

3 Constraining Abstract Domains

The constraining abstract domains abstract the possible environments at each
program label. Thus, they constrain the values of the variables of the analyzed
program and also indirectly constraint the input data read by the program.

Any constraining domain K that we present is characterized by a choice of:

γK

• a set K of computer-representable abstract domain elements;
• a partial order (cid:118)K between domain elements;
• a concretization function γK : K → P (E) mapping abstract domain elements
to sets of possible environments, or, when possible, a Galois connection
(cid:104)P (E) , ⊆(cid:105) −−−→←−−−

(cid:104)K, (cid:118)K(cid:105);
• a least element ⊥K ∈ K such that γK(⊥K) = ∅;
• a greatest element (cid:62)K ∈ K such that γK((cid:62)K) = E;
• a sound join operator (cid:116)K such that γK(K1) ∪ γK(K2) ⊆ γK(K1 (cid:116)K K2);
• a sound widening (cid:79)K if K does not satisfy the ascending chain condition;
• a sound backward assignment operator assignK

αK

X := A
(cid:74)
ρ : ρ[X (cid:55)→ v] ∈ γ(K)} ⊆ γK(assignK

{ρ ∈ E | ∃v ∈ A(cid:48)

A

K); and

such that
(cid:75)
X := A
(cid:74)

(cid:75)

• a sound ﬁlter operator filterK

(cid:75)
{ρ ∈ γK(K) | tt ∈ B

B
(cid:74)
ρ} ⊆ γK(filterK

(cid:75)

(cid:74)

such that

B

(cid:75)

(cid:74)

K).

B

(cid:74)

(cid:75)

Essentially any of the existing classical abstract domains [10,11,35, etc.] can
be a constraining domain. Some of their operators just need to be augmented
with certain operations to ensure the communication with the input domain H,
which (directly) constraints the input data.

Speciﬁcally, the backward assignment operation assignK

needs to
be preceded by a replace(A, I) operation, which replaces each input() sub-
expressions of A with a fresh special input variable I ∈ I, The input variables
are added to the constraining domain on the ﬂy to track the value of the input
data as well as the order in which the data is read by the program.

X := A

(cid:75)

(cid:74)

Example 3. Let us consider again the assignment gpa := gpa + input() which
simpliﬁes line 9 in Figure 1. On way to track the order in which input data is read
by the program is to parameterize the fresh input variables by the program label
at which the corresponding input() expression occur. If we use line numbers as
labels, in this case we only need one fresh input variable I9 (for multiple input()
expressions at the same program label 9 we can add superscripts: I 1
9 , . . . ).
Thus, replace(gpa + input(), {I9}) = gpa + I9.
(cid:4)

9 , I 2

Once the assignment or ﬁlter operation has been performed, the operation
record(I) extracts from the domain the constraints on each newly added input
variable I so that they can be directly recorded in the input domain H. The
input variables can then be removed from the constraining domain K.

8

Caterina Urban

3.1 Non-Relational Constraining Abstract Domains

In the following, we present a few instances of non-relational constraining do-
mains. These domains abstract each program variable independently. Thus, each
constraining domain element K ∈ KU of KU is a map K : X → U from program
variables to elements of a basis abstract domain U.

A

In the following, we write U

K to denote the value (in U) of an arithmetic
expression A given the abstract domain element K ∈ KU . In particular, for a
binary expression A1 (cid:5) A2, we deﬁne U
K
K (cid:5)U U
and thus we assume that the basis U is equipped with the operator (cid:5)U.

(cid:75)
The concretization function γKU : KU → P (E) is:

A1 (cid:5)U A2
(cid:74)

K = U

A2

A1

(cid:75)

(cid:74)

(cid:75)

(cid:74)

(cid:75)

(cid:74)

γKU (K) def= {ρ ∈ E | ∀X ∈ X : str(ρ(X)) ∈ γU(K(X))}

(3.1)

where γU : U → S and str : V → S converts ﬂoat and integer values to strings
such that str(F) = Sﬂoat and str(Z) = Sint. The partial order (cid:118)K, join (cid:116)K, and
widening (cid:79)K are straightforwardly deﬁned pointwise.

For these constraining domains, the replace(A, I) operation temporarily
enlarges the domain of the current abstract element K ∈ KU to also include
input variables, i.e., K : X ∪ I → U. The record(I) operation simply returns
the value K(I) ∈ U. All input variable are then removed from the domain of K.

Type Constraining Abstract Domain. The ﬁrst instance that we consider
is very simple but interesting to catch exceptions that would be raised when
casting inputs to integers or ﬂoats, as at lines 2 and 5 in Figure 1.

We deﬁne the basis type domain T, to
track the type of input data that can be stored
in the program variables. Its elements belong
to the type lattice T represented by the Hasse
diagram in Figure 5. T deﬁnes the type hier-
archy (reminiscent of that of python) that
we use for our analysis. Data is always read
as a string (cf. Section 2). Thus, string is
the highest type in the hierarchy. Some (but
not all) strings can be cast to ﬂoat or integer,
thus the float and int types follow in the
hierarchy. Finally, ⊥T indicates an exception.

string

float

int

⊥T

Fig. 5: The T type lattice.

We deﬁne the concretization function γT : T → S as follows:

γT(string) def= S

γT(float) def= Sﬂoat

γT(int) def= Sint

γT(⊥T) def= ∅

(3.2)

The partial order (cid:118)T, join (cid:116)T, and meet (cid:117)T are deﬁned by Figure 5. No widening
(cid:79)T is necessary since the basis type domain T is ﬁnite.

Each element K ∈ KT of the type constraining abstract domain KT is thus a
map K : X → T from program variables to type elements. The bottom element is
the constant map λX.⊥T which represent a program exception. The top element

What Programs Want

9

is λX.string or, better, λX.type(X), where type(X) is the type inferred for
X by a static type inference previously run on the program (e.g., [28,36] for
python). In the latter case, the analysis with KT might reﬁne the inferred type
(e.g., type(X) = float but the analysis ﬁnds K(X) = int). In particular, such
a reﬁnement is done by the assignKT

and filterKT
operator reﬁnes the type of input data mapped
to from the variables that appear in the assigned expression A. Speciﬁcally,
assignKT
K def= refinereplace(A,I)(K[X (cid:55)→ type(X)], K(X)), where the
refineA : K → T → K function is deﬁned as follows:

The assignKT

operators.

X := A

X := A

X := A

B

(cid:74)

(cid:75)

(cid:75)

(cid:74)

(cid:75)

(cid:75)

(cid:74)

(cid:74)

refineX (K, T ) def= K[X (cid:55)→ K(X) (cid:117)T T ]
refinev(K, T ) def= K
refineI (K, T ) def= K[I (cid:55)→ T ]

X ∈ X
v ∈ V
I ∈ I

refineint(A)(K, T ) def= refineA(K, T (cid:117)T int)
refineﬂoat(A)(K, T ) def= refineA(K, T (cid:117)T float)
refineA1(cid:5)A2 (K, T ) def= refineA1(refineA2(K, T (cid:48)), T (cid:48))

T (cid:48) = T (cid:117)T float

Note that, for soundness, the current value K(X) of the assigned variable X must
be forgotten before the reﬁnement (i.e., K[X (cid:55)→ type(X)]). We reﬁne variables
within an arithmetic operation A1 (cid:5) A2 to contain data of at most type float.

Example 4 (continue from Example 3). Let us consider again the assignment
gpa := gpa+input() which simpliﬁes line 9 in Figure 1 and let K be an abstract
domain element which maps the variable gpa to the type value int, while a
previously ran type inference has determined that type(gpa) = float. We have:

assignKT
= refinegpa(refineI9(K[gpa (cid:55)→ float], int), int)
= refinegpa(K[gpa (cid:55)→ float][I9 (cid:55)→ int], int) = K[I9 (cid:55)→ int][gpa (cid:55)→ int]

K def= refinegpa+I9(K[gpa (cid:55)→ float], int)

gpa := gpa + input()
(cid:74)

(cid:75)

which indicates that the program expects to read an integer at line 9. Note that,
this is a result of our choice for K. Indeed, with K mapping gpa to float,
we have assignKT
K = K[I9 (cid:55)→ float][gpa (cid:55)→ float]
(which is what the program in Figure 1 actually expects).
(cid:4)

gpa := gpa + input()
(cid:75)

(cid:74)

Similarly, the ﬁlter operator filterKT

is deﬁned as follows:

B

(cid:74)

(cid:75)

filterKT
filterKT
filterKT
filterKT
filterKT

A1 = A2
(cid:74)
A1 (cid:54)= A2
(cid:74)
A1 (cid:46)(cid:47) A2
(cid:74)
B1 ∨ B2
(cid:74)
B1 ∧ B2
(cid:74)

(cid:75)
(cid:75)
(cid:75)
(cid:75)
(cid:75)
where (cid:46)(cid:47) ∈ {<, ≤, >, ≥}.

A1

K), T

K def= refineA1(refineA2 (K, T
(cid:74)
K def= K
K def= refineA1(refineA2 (K, float), float)
K def= filterKT
K (cid:116)KN
K
K ◦ filterKT
K def= filterKT

filterKT

B1
B2

(cid:75)

(cid:74)

B2
(cid:75)
(cid:74)
K
B1
(cid:74)

(cid:75)

(cid:74)
(cid:74)

(cid:75)
(cid:75)

A2

K)

(cid:75)

The soundness of the domain operators is straightforward:

Lemma 1. The operators of the type constraining domain KT are sound.

10

Caterina Urban

Value Constraining Abstract Domains. Numerical abstract domains such
as the interval domain [11] or the sign domain [13] can be used to track the input
data values that can be stored in the program variables. In particular, the latter
is useful to catch exceptions raised when diving by zero, as at line 10 in Figure 1.
The sign lattice N shown in Figure 6 rep-
resents the elements of the basis sign do-
main N. We deﬁne the concretization function
γN : N → S as follows:

(cid:54)= 0

≤ 0

≥ 0

(cid:62)N

< 0

= 0

> 0

⊥N

γN((cid:62)N) def= S
γN((cid:67)0) def= S(cid:67)0
ﬂoat
γN(⊥N) def= ∅

(3.3)

Fig. 6: The N sign lattice.

where (cid:67) ∈ {<, ≤, =, (cid:54)=, >, ≥} and S(cid:67)0
ﬂoat de-
notes the set of string values that can be in-
terpreted as ﬂoat values that satisfy (cid:67)0. The partial order (cid:118)N, join (cid:116)N, and
meet (cid:117)N are deﬁned by the Hasse diagram in Figure 6. Again, no widening (cid:79)N
is necessary since the basis domain N is ﬁnite.

Each element K ∈ KN of the sign constraining abstract domain KN is thus

a map K : X → N from program variables to sign elements.

For this domain, the backward assignment operator is assignKN

X := A

refinereplace(A,I)(K[X (cid:55)→ (cid:62)N], K(X)), where refineA : K → N → K is:

(cid:74)

K def=

(cid:75)

refineX (K, N ) def= K[X (cid:55)→ K(X) (cid:117)N N ]
refinev(K, N ) def= K
refineI (K, N ) def= K[I (cid:55)→ N ]

X ∈ X
v ∈ V
I ∈ I

refineint(A)(K, N ) = refineﬂoat(A)(K, N ) def= refineA(K, N )
refineA1+A2 (K, N ) def= refineA1(refineA2(K, N −N N
refineA1−A2 (K, N ) def= refineA1(refineA2(K, N
A1
(cid:75)
refineA1∗A2 (K, N ) def= refineA1(refineA2(K, N /N N
refineA1/A2 (K, N ) def= refineA1(K (cid:48), N ∗N N
K)
K (cid:48) = refineA2 (K, (cid:54)= 0 (cid:117)N (N

A2
(cid:74)

A1

A1

(cid:75)

(cid:75)

(cid:74)

(cid:75)

(cid:74)

(cid:74)

A1

K), N −N N
K −N N ), N +N N
K), N /N N

K /N N ))

A2
(cid:74)
A2
(cid:74)
A2
(cid:74)

K)
(cid:75)
K)
(cid:75)
K)
(cid:75)

(cid:74)

(cid:75)

Note that we reﬁne variables in the denumerator A2 of a division expression
A1 ÷ A2 to have values diﬀerent from zero.

Example 5. Let us consider the assignment result := gpa / classes at line 10
in Figure 1 and let K be an abstract domain element which maps the variables
gpa and result to the sign value ≥ 0 and the variable classes to (cid:62)N. We have:

(cid:74)

result := gpa / classes
(cid:75)

assignKN
= refinegpa(refineclasses(K[gpa (cid:55)→ (cid:62)N], (cid:54)= 0), ≥ 0)
= refinegpa(K[result (cid:55)→ (cid:62)N][classes (cid:55)→(cid:54)= 0], ≥ 0)
= K[result (cid:55)→ (cid:62)N][classes (cid:55)→(cid:54)= 0][gpa (cid:55)→≥ 0]

K def= refinegpa/classes(K[result (cid:55)→ (cid:62)N], ≥ 0)

which, in particular, indicates that the program expects the variable classes
(read at line 5 in Figure 1) to have a value diﬀerent from zero.
(cid:4)

What Programs Want

11

is deﬁned as follows:

Instead, the ﬁlter operator filterKN

B
(cid:74)

(cid:75)
K def= refineA(K, (cid:67)0)
K def= filterKN
K def= filterKN
K def= filterKN

(cid:67) ∈ {<, ≤, =, (cid:54)=, >, ≥}
A2 (cid:54)= 0

filterKN

filterKN
filterKN
filterKN

(cid:74)

A (cid:67) 0
A1 (cid:46)(cid:47) A2
B1 ∨ B2
B1 ∧ B2

(cid:74)
(cid:74)
(cid:74)

(cid:75)
(cid:75)
(cid:75)
(cid:75)

K
filterKN

A1 − A2 (cid:46)(cid:47) 0
(cid:74)
(cid:75)
K (cid:116)KN
B1
(cid:74)
K ◦ filterKN
B2
(cid:74)

(cid:74)

K

B2
(cid:75)
K

(cid:75)
(cid:75)
The soundness of the sign constraining domain operators follows directly

(cid:74)
B1

(cid:75)

from the soundness of the sign abstract domain [13].

Lemma 2. The operators of the sign constraining domain KN are sound.

String Constraining Abstract Domains. Finally, we build a last instance of
non-relational constraining domain on the ﬁnite string set domain [9], to track
the string data values that can be stored in the program variables. Other more
sophisticated string domains exist [2,10, etc.]. However, even this simple domain
suﬃces to catch KeyError exceptions that might occur, e.g., at line 9 in Figure 1.
Each abstract domain element K ∈ KW of the string domain KW is a map
K : X → W from program variables to an element W ∈ W of the basis domain
W. Elements of W are ﬁnite sets of at most m string, or the top element (cid:62)W which
abstracts larger sets of strings, i.e., W def= P (S)∪{(cid:62)W}. In the following, we write
⊥W to denote the empty string set. The concretization function γW : W → S is:

γW((cid:62)W) def= S

γW(W ) def= W

(3.4)

The partial order (cid:118)W, join (cid:116)W, and meet (cid:117)W are the set operations ⊆, ∪, and
∩ extended to also handle (cid:62)W:

W1 (cid:118) W2 ⇔ W2 = (cid:62)W ∨ (W1 (cid:54)= (cid:62)W ∧ W1 ⊆ W2)

W1 (cid:116)W W2

def=

W1 (cid:117)W W2

def=

(cid:40)

(cid:62)W
W1 ∪ W2
W1
W2
W1 ∩ W2






W1 = (cid:62)W ∨ W2 = (cid:62)W ∨ |W1 ∪ W2| > m
otherwise
W2 = (cid:62)W
W1 = (cid:62)W
otherwise

The widening W1(cid:79)WW2 yields (cid:62)W unless W2 ⊆ W1 (in which case it yields W1).
K def=

We can now deﬁne the backward assignment operator assignKW

X := A
(cid:74)
refinereplace(A,I)(K[X (cid:55)→ (cid:62)W], K(X)), where refineA : K → W → K is:

(cid:75)

refineX (K, W ) def= K[X (cid:55)→ K(X) (cid:117)W W ]
refinev(K, W ) def= K
refineI (K, W ) def= K[I (cid:55)→ W ]

X ∈ X
v ∈ V
I ∈ I
refineint(A)(K, W ) = refineﬂoat(A)(K, W ) def= refineA(K, W ) W = (cid:62)W
refineint(A)(K, W ) = refineﬂoat(A)(K, W ) def= refineA(K, ⊥W) W (cid:54)= (cid:62)W
refineA1(cid:5)A2 (K, W ) def= refineA1(refineA2(K, W ), W )
W = (cid:62)W
refineA1(cid:5)A2 (K, W ) def= refineA1(refineA2(K, ⊥W), ⊥W)
W (cid:54)= (cid:62)W

12

Caterina Urban

Note that, variables in numerical expressions (such as int(A), ﬂoat(A) or A1 (cid:5)
A2) should not have a speciﬁc string value (i.e, a value diﬀerent from (cid:62)W).

Example 6. Let us consider a small extension of our toy language with dictio-
naries. In particular, we extend the grammar of arithmetic expressions with
dictionary display (in python terminology) expressions {v0 : v1, v2 : v3, . . . },
v0, v1, v2, v3, . . . ∈ V, for dictionary creation (cf. line 1 in Figure 1) and dictionary
access expressions X[A] (such as grade2gpa[grade] at line 9 in Figure 1).

For each dictionary, we assume that abstract domains only keep track of two
summary variables [25], one representing the dictionary keys and one represent-
ing its values. For instance, let us consider the grade2gpa dictionary in Figure 1
and let the string domain element K map the variable keys(grade2gpa) to the
set of strings {’A’, ’B’, ’C’, ’D’, ’F’} and values(grade2gpa) to (cid:62)N.

We can extend refineA deﬁned above to handle dictionary access expressions
as follows: refineX[A](K, W ) def= refineA(K, K(keys(X))). No reﬁnement can be
made on X since, for soundness, only weak updates are allowed on summary
variables [7]. For the assignment gpa := gpa + grade2gpa[grade] at line 9 in Fig-
ure 1 we thus have assignKW
K = K[grade (cid:55)→
{(cid:48)A(cid:48),(cid:48) B(cid:48),(cid:48) C (cid:48),(cid:48) D(cid:48),(cid:48) F (cid:48)}], which indicates the string values expected by the pro-
gram for the variable grade (read at line 8 in Figure 1).
(cid:4)

gpa := gpa + grade2gpa[grade]

(cid:75)

(cid:74)

The ﬁlter operator filterKW

is deﬁned as follows:

B

(cid:74)

(cid:75)

filterKW
filterKW
filterKW

filterKW

A1 = A2
(cid:74)
A1 (cid:54)= A2
(cid:74)
A1 (cid:46)(cid:47) A2
(cid:74)

(cid:75)
(cid:75)
(cid:75)

A1 (cid:46)(cid:47) A2

(cid:74)

(cid:75)

filterKW
filterKW

(cid:75)
(cid:75)
where (cid:46)(cid:47) ∈ {<, ≤, >, ≥}.

(cid:74)
(cid:74)

B1 ∨ B2
B1 ∧ B2

K), W

A1
(cid:74)

(cid:75)

K def= refineA1(refineA2 (K, W
K def= K
K def= refineA1(refineA2 (K, W

A1
(cid:74)
K = (cid:62)W ∧ W
W
(cid:74)
K def= refineA1(refineA2 (K, ⊥W), ⊥W)
K (cid:54)= (cid:62)W ∨ W
W
filterKW
B1
(cid:74)
B1
B2
(cid:75)

A2
(cid:74)
(cid:75)
K (cid:116)KW
(cid:75)
K ◦ filterKW
(cid:75)

K def= filterKW
K def= filterKW

A2

(cid:74)
(cid:74)

(cid:74)

(cid:75)

(cid:75)

K), W
A1

(cid:74)

A1
(cid:74)
B2
(cid:75)
K

K)

A2

(cid:75)

A2
K)
K = (cid:62)W

(cid:75)

(cid:74)

(cid:74)
(cid:75)

K (cid:54)= (cid:62)W

(cid:75)
K

The soundness of the string constraining domain operators follows directly

from the soundness of the ﬁnite string set abstract domain [9].

Lemma 3. The operators of the string constraining domain KW are sound.

3.2 Other Constraining Abstract Domains

We now brieﬂy discuss other instances of constraining domain.

Relational Constraining Abstract Domains. Other constraining domain
can be built on relational abstract domains. Popular such domains are octagons
[35] or polyhedra [16], which track linear relations between program variables.

What Programs Want

13

We refer to the literature for the formal deﬁnition of these abstract domains
and only discuss here the implementation of the additional operations needed to
communicate with the input domain H. In particular, similarly to non-relational
domains, the replace(E, I) operation temporarily adds the input variables in
I to the current abstract element K ∈ K. These are unconstrained at ﬁrst and
might become subjects to constraints after an assignment or ﬁlter operation.

The implementation of the record(I) operation is more complex for rela-
tional domains: record(I) extracts from the current abstract element K, an
abstract domain element K containing all and only the constraints in K that
involve the input variable I. The domain dom(K) of K is the subset of dom(K)
containing only the variables appearing in these constraints. The input variables
can then be projected away from K.

Example 7. Let us consider again the assignment gpa := gpa + input() which
simpliﬁes line 9 in Figure 1 and let K = {gpa ≥ 0, grades > 0} be a polyhedra
deﬁned over the variables gpa and grades, i.e., dom(K) = {gpa, grades}. After
replace(gpa+input(), {I9}) (cf. Example 3), K is unchanged but its domain is
enlarged to also include the input variable I9, i.e., dom(K) = {gpa, grades, I9}.
The result of the (replaced) assignment gpa := gpa + I9 is then the polyhedra
K (cid:48) = {gpa + I9 ≥ 0, grades > 0}. Finally, the record(I9) operation returns the
polyhedra K = {gpa + I9 ≥ 0}, where dom(K) = {gpa, I9}.
(cid:4)

In the following, we assume that input variables are parameterized by the
program label at which their corresponding input() expressions occur, as in Ex-
ample 3. Note that, there is not necessarily a one-to-one correspondence between
input() expressions in a program and data record in a data ﬁle. Indeed, multi-
ple records can be read by the same input() expression (i.e., in a for loop as in
Figure 1) or, vice versa, the same data record could be read by multiple input()
expressions (i.e., in diﬀerent if branches). In particular, the latter case implies
that two abstract domain elements K1 and K2 might be deﬁned over diﬀerent in-
put variables. Thus, relational constraining domains need to be equipped with a
uniﬁcation operation unify(K1, K2) to match diﬀerent input variables that cor-
respond to the same data record. One simple option to deal with this problem
is to keep track of the order in which the input variables are added to a domain
element by each replace(E, I) operation. The unify(K1, K2) operation then
simply consists in matching input variables in their order.

Container Constraining Abstract Domains. We now lift the assumption
that data records only have one ﬁeld (cf. Section 2). We extend the grammar of
expressions to also include data access expressions X[A], X ∈ X , (similarly to
what we did in Example 6 for dictionaries). Similarly, we extend the grammar
of statements to also include assignments of the form X[A1] := A2. We call
variables like the X we used in these expressions, array variables.

In this case, abstract domains should be able to also handle reads and updates
of array variables in addition to numerical and string variables as so far. The most
basic option to do so is to use summarization [25] (as in Example 6) and only

14

Caterina Urban

perform weak updates [7]. It is sometimes possible to fully expand array variables
to improve precision [4], or use a combination of expansion and summarization
(i.e., expand part of the array up to a certain size and summarize the rest).

Many other abstract domains exist that are speciﬁcally designed to analyze
arrays [15,26,27,33, etc.] or, more generally, containers (e.g., sets, dictionaries)
[18,17,20,21,22, etc.]. Any of these can be instantiated as a constraining domain
(as we showed in this section) and used within our framework.

4

Input Abstract Domain

The input abstract domain H, as mentioned, directly constrains the input data
read by a program. An element H ∈ H of H is a stack of mutable length h:

R0 | R1 | · · · | Rh−1 | Rh

Ri ∈ R

of assumptions on (part of) the input data, or the special element ⊥Q or (cid:62)Q. The
top element (cid:62)Q denotes unconstrained input data, while ⊥Q indicates a program
exception. A stack element grows or shrinks based on the level of nesting of the
currently analyzed input() expression.

Each layer Ri ∈ R is a list of r assumptions repeated M times: R def=
i=1 | Ji ∈ C ∪ {(cid:70)} ∪ R} . The multiplier M follows this grammar:

{M · (Ji)r

M ::= X ∈ X | I ∈ I | v ∈ Z | M1 (cid:5) M2

(cid:5) ∈ {+, −, ∗, /}

while an assumption Ji can be a basic assumption in C, the dummy assumption
(cid:70), or another list of repeated assumptions in R.

A basic assumption C ∈ C is a family of constraints, one for each constraining
domain K1, . . . , Kk in Q, associated to a particular program label l ∈ L: C def=
(cid:9), where Ki = Ui if Ki is a non-relational domain, or
(cid:8)(cid:104)l, (Yi)k
i=1(cid:105) | l ∈ L, Yi ∈ Ki
Ki otherwise (cf. Section 3).

Example 8. Let us consider the assignment grade := I8 where I8 is the result
of replace(input(), {I8}) at line 8 in Figure 1. Moreover, let KT ∈ KT and
KW ∈ KW map the variable grade to string and {’A’, ’B’, ’C’, ’D’, ’F’}, re-
spectively. After the analysis of the assignment, we have KT (I8) = string and
KW (I8) = {’A’, ’B’, ’C’, ’D’, ’F’}. The call to the function record(I8) in the
two constraining domains KT and KW eﬀectively creates the basic assumption
(cid:104)l8, [string, {’A’, ’B’, ’C’, ’D’, ’F’}](cid:105) in the input domain H.
(cid:4)

A repeated assumption M · (Ji)r

i=1 constrains all data read by a for loop.

Example 9 (continue from Example 8). Let us consider the for loop at lines
7-9 in Figure 1. The input() expression at line 8 is constrained by the basic
assumption (cid:104)l8, [string, {’A’, ’B’, ’C’, ’D’, ’F’}](cid:105). Thus, all data read by the for
loop is constrained by classes · [(cid:104)l8, [string, {’A’, ’B’, ’C’, ’D’, ’F’}](cid:105)].
(cid:4)

What Programs Want

15

Finally, data read by a while loop is generally approximated by the dummy
assumption (cid:70), which denotes an unknown number of unconstrained data records.

The concretization function γH : H → P (D) is deﬁned as follows:

γH(⊥H) def= ∅
γH(H) def= {D ∈ D | D |= H}
γH((cid:62)H) def= D

(4.1)

In particular, the concretization of a stack element H ∈ H is the set of data
ﬁles that satisfy the assumptions ﬁxed by the stack element. We omit the formal
deﬁnition of the satisfaction relation |= due to space limitations. The following
example should provide an intuition:

Example 10. Let us assume that the program in Figure 1 is analyzed with Q
instantiated with the type KT, sign KN, and string KW constraining domains.
Let us consider the following stack element H ∈ H at line 5:

1 · [(cid:104)l5, [int, (cid:54)= 0, (cid:62)W](cid:105), I5 · [(cid:104)l8, [string, (cid:62)N, {’A’, ’B’, ’C’, ’D’, ’F’}](cid:105)]] | 1 · []

The data ﬁle





2


 satisﬁes H since 2 ∈ γT(int)∩γN((cid:54)= 0)∩γW((cid:62)W) and, similarly,
A

F

A, F ∈ γT(string) ∩ γN((cid:62)N) ∩ γW({’A’, ’B’, ’C’, ’D’, ’F’}). Moreover, I5 = 2 and,




1

indeed, there are exactly two data records following 2. Instead, the data ﬁle



A



(cf. the motivating example in the Introduction) does not satisfy H since I5 = 1
is followed by two data records instead of one.
(cid:4)

F

Any data ﬁle satisﬁes the dummy assumption (cid:70). Thus any stack element

starting with the dummy assumption (e.g, 1 · [(cid:70)]) is equivalent to (cid:62)H.

1 , . . . , J 1
r1

1 , . . . , J 2
r2

We deﬁne the partial order (cid:118)H such that H1 (cid:118)H H2 only if γH(H1) ⊆ γH(H2).
Thus, H1 (cid:118)H H2 is always true if H1 = ⊥H or H2 = (cid:62)H. Otherwise, H1 and
H2 must have the same number of layers to be comparable and (cid:118)H is deﬁned
(cid:3) ∈ R and R2 = M2 ·
laywer-wise. Speciﬁcally, for each R1 = M1 · (cid:2)J 1
(cid:3) ∈ R, R1 (cid:118)R R2 if and only if M1 = M2 and r1 = r2 (i.e., R1 and R2
(cid:2)J 2
consists of the same number of assumptions repeated the same number of times),
and (cid:86)r1=r2
i , i.e., R1 imposes stronger constraints on the input data than
R2. The partial order J1 (cid:118)J J2 is again J1 (cid:118)R, if J1, J2 ∈ R. Otherwise, J1 (cid:118)J J2
(cid:3)(cid:105) ∈ C
is always true when J2 = (cid:70). For basic assumptions J1 = (cid:104)l1, (cid:2)Y 1
(cid:3)(cid:105) ∈ C, J1 (cid:118)J J2 is true if and only if (cid:86)k
and J2 = (cid:104)l1, (cid:2)Y 2
Y 2,
i1
where Ki = Ui if Ki is a non-relational domain, or Ki otherwise. Note that, for
relational domains, a uniﬁcation must be performed prior to (cid:118)J as discussed in
Section 3. No comparison is possible when J1 ∈ C and J2 ∈ R, or vice versa.

0 , . . . , Y 2
k

0 , . . . , Y 1
k

i=1 J 1

Y 1 (cid:118)Ki

i (cid:118)J J 2

This is a rather rigid deﬁnition for (cid:118)H. Indeed, in some cases, H1 (cid:54)(cid:118)H H2
even though γH(H1) ⊆ γH(H2), e.g., consider H1 = 1 · [(cid:104)la, [int](cid:105), (cid:104)lb, [float](cid:105)]

16

Caterina Urban

and H2 = 2 · [(cid:104)lc, [float](cid:105)]. Such incomparable stack elements may result from
syntactically diﬀerent but semantically close programs [19] (e.g., in one program
a loop has been unrolled but not in the other), but never during the analysis of
a single program. Thus, for our purposes, this deﬁnition of (cid:118)H suﬃces.

The backward assignment operator assignH

The join (cid:116)H is deﬁned analogously to (cid:118)H. We omit its formal deﬁnition due
to space limitations. The join of incomparable stack layers is approximated with
the dummy layer 1 · [(cid:70)]. Thus, no widening (cid:79)H is needed.
X := A
(cid:74)

and ﬁlter operator
filterH
operate on each stack layer independently. For each R = M ·
(Ji)r
i=1 ∈ R, the assignment replaces any occurrence of X in the multiplier
M with the expression replace(A, I). The assignment (resp. ﬁlter) operation
is done recursively on each assumption Ji. When Ji ∈ C, the assignment (resp.
ﬁlter) is delegated to the constraining domains directly.

B

(cid:75)

(cid:75)

(cid:74)

Example 11 (continue from Example 9). Let us consider again the assumption
classes · [(cid:104)l8, [string, {’A’, ’B’, ’C’, ’D’, ’F’}](cid:105)], which constrains the data read
by the for loop at lines 7-9 in Figure 1, and the assignment classes := input() (cf.
line 5). The assignment simply replaces the multiplier classes in the assumption
with the input variable I5: I5 · [(cid:104)l8, [string, {’A’, ’B’, ’C’, ’D’, ’F’}](cid:105)].
(cid:4)

During the analysis of a for loop, the repeat

operator modiﬁes the mul-
tiplier of the assumption in the ﬁrst stack layer: repeat
(M · [J, . . . ] | · · · |
Rh) def= (A ∗ M ) · [J, . . . ] | · · · | Rh. The resulting multiplier expression is then
simpliﬁed, whenever possible (e.g, (X + 1) − 1 is simpliﬁed to X).

A

A

(cid:74)

(cid:75)

(cid:74)

(cid:75)

Finally, it remains to discuss how stack elements H ∈ H grow and shrink
during the analysis of a program. Whenever the analysis enters the body of
an if or loop statement, the push(H) operation simply adds an extra layer to
H containing the empty assumption 1 · []: push(H) def= 1 · [] | H. When the
analysis later leaves the body of the statement, the pop(H) operation inserts the
assumption in the ﬁrst layer into the assumption in the second layer: pop(R0 |
M · [J, . . . ] | · · · | Rh) = M · [R0, J, . . . ] | · · · | Rh. Instead, the pop operation
merges the assumption in the ﬁrst layer with the (ﬁrst) assumption in the second
layer: pop(R0 | M · [J, . . . ] | · · · | Rh) = M · [R0 (cid:116)J J, . . . ] | · · · | Rh.

The input domain operators ultimately build on the operators of the con-
straining domains. Thus, their soundness directly follows from that of the con-
straining domain operators.

Lemma 4. The operators of the input domain H are sound.

5

Input Data-Aware Program Abstraction

We can now use the data shape abstract domain Q to deﬁne the abstract seman-
. We write (cid:104)(cid:104)K1, . . . , Kk(cid:105), H(cid:105) ∈ Q to denote an element of Q, where
tics ∆(cid:92)
K1 ∈ K1, . . . , Kk ∈ Kk are elements of the constraining domains K1, . . . , Kk and

P

(cid:74)

(cid:75)

What Programs Want

17

S (cid:92) (cid:114)lX := A(cid:122) Q def= assignQ

X := A
(cid:75)
(cid:74)

Q

S (cid:92) (cid:114)if lB then S1 else S2 ﬁ(cid:122) Q def= Q1 (cid:116)Q Q2

Q1

def= pop ◦ filterQ

Q2

def= pop ◦ filterQ

(cid:75)
S (cid:92) (cid:114)for lA do S od(cid:122) Q def= lfp(cid:92)

B
(cid:75)
(cid:74)
¬B
(cid:74)

◦ S (cid:92)

S1
(cid:74)
◦ S (cid:92)

(cid:75)
S2
(cid:74)

(cid:75)

◦ push(Q)

◦ push(Q)

G(Y ) def= pop ◦ repeat

◦ S (cid:92)

S (cid:92) (cid:114)while lB do S od(cid:122) Q def= lfp(cid:92) F

pop◦repeat

A

A
(cid:75)
(cid:74)

(cid:74)
S
(cid:74)

(cid:75)

◦push(W ) G
(cid:75)

S

◦S(cid:92)
(cid:75)
(cid:74)
◦ push(Y )

F (Y ) def= pop ◦ filterQ

S (cid:92)

S1; S2
(cid:74)

(cid:75)

Q def= S (cid:92)

◦ S (cid:92)

S1
(cid:74)

(cid:75)

¬B
(cid:74)

S2
(cid:74)

(cid:75)

(cid:75)
Q

◦ push(Q) (cid:116)Q pop ◦ filterQ

B
(cid:74)

(cid:75)

◦ S (cid:92)

S
(cid:74)

(cid:75)

◦ push(Y )

Fig. 7: Input-Aware Abstract Semantics of Instructions

H ∈ H is an element of the input domain. The abstract data shape semantics
of a data-processing program P is thus:

∆(cid:92)

P

(cid:74)

(cid:75)

= ∆(cid:92) (cid:113)Sl(cid:121)

def= ∆(cid:92)

(cid:32)

λp.

S

(cid:74)

(cid:75)

(cid:40)

(cid:104)(cid:104)(cid:62)K1, . . . , (cid:62)Kk (cid:105), 1 · [](cid:105) p = l
undeﬁned

otherwise

(cid:33)

(5.1)

(cid:75)

(cid:74)

S

The semantics ∆(cid:92)
: (L → Q) → (L → Q) of each instruction is (equiva-
lently) deﬁned pointwise within Q in Figure 7: each function S (cid:92)
: Q → Q
over-approximates the possible environments and data ﬁles that can be read
from the program label within the instruction S. The assignQ
opera-
tor ﬁrst invokes assignKi
on each constraining domain Ki. Then, the
X := A
(cid:74)
record(I) operation is executed for each input variable I ∈ I corresponding
to an input() sub-expression of A. Finally, the assignment is performed on the
input domain by assignH
operation is ﬁrst
X := A
(cid:74)
(cid:74)
(cid:75)
executed on each constraining domain Ki by filterKi
, and then on the in-
, push, pop, pop have no eﬀect on
put domain by filterH
B
(cid:75)
the constraining domains and only modify the input domain (cf. Section 4).

. Similarly, the filterQ
(cid:75)
B
(cid:74)
. The repeat
(cid:75)

X := A
(cid:74)

B

A

S

(cid:75)

(cid:75)

(cid:74)

(cid:75)

(cid:75)

(cid:74)

(cid:74)

The abstract semantics of each instruction is sound:

Lemma 5. S

γQ(Q)
(cid:75)
(cid:74)

⊆ γQ(S (cid:92)

)

Q
(cid:75)
(cid:74)

where the concretization function γQ : Q → P (E × D) is γQ((cid:104)(cid:104)K1, . . . , Kk(cid:105), H(cid:105)) def=
{(cid:104)ρ, D(cid:105) ∈ E × D | ρ ∈ γK1(K1) ∩ · · · ∩ γK1 (Kk), D ∈ γH(H)}.

Thus, the abstract data shape semantics ∆(cid:92)

is also sound:

P

(cid:74)

(cid:75)

Theorem 1. For each data-processing program P , we have ∆

P

(cid:74)

(cid:75)

⊆ γQ(∆(cid:92)

P

).
(cid:75)

(cid:74)

18

Caterina Urban

6

Implementation

We have implemented our input data shape analysis in the open-source proto-
type static analyzer Lyra4. The implementation is in python and, at the time
of writing, accepts data processing programs written in a subset of python
without user-deﬁned classes. Programs are expected to be type-annotated, ei-
ther manually or by a type inference [28].

For the analysis, various constraining domains are available: in addition to the
type, sign, and string domains presented in Section 3.1, Lyra is equipped with
the character inclusion domain [10], as well as the intervals [11], octagons [35],
and polyhedra domains [16], which build upon the apron library [32]. A native
(non-apron-based) implementation of the intervals domain is also available. For
containers (e.g., lists, sets, dictionaries, . . . ), a summarization-based abstraction
[25] is the default. Lists, tuples, and dictionaries can be expanded up to a ﬁxed
bound beyond which they are summarized (cf. Section 3.2).

The data shape analysis is performed backwards on the control ﬂow graph
of the program with a standard worklist algorithm [37], using widening at loop
heads to enforce termination. The precision of the analysis can be improved
by running a forward pre-analysis which collects values information about the
program variables (e.g., in Figure 1, this would allow the data shape analysis to
know the values of the keys of the grade2gpa dictionary already at line 9 even
if the dictionary is not created until line 1, cf. Example 6).

Lyra outputs the analysis results in json format so that other applications

(e.g., automated data checking tools [1,38]) can easily interface with it.

Below, we demonstrate the expressiveness of our data shape abstract domain

on more examples besides the program shown in Figure 1.

Magic Trick. Let us consider the following python program fragment:

1 T = i n t ( input ( ) )
2 f o r x in range (T) :
3

l 1 = i n t ( input ( ) )
f o r i

in range ( 1 , l 1 ) :

4

5

6

7

8

9

10

11

12

13

14

input ( )

L1 = l i s t (map( int , input ( ) . s p l i t ( ) ) )
f o r i

in range ( l 1+1 , 5 ) :

input ( )

l 2 = i n t ( input ( ) )
f o r i

in range ( 1 , l 2 ) :

input ( )

L2 = l i s t (map( int , input ( ) . s p l i t ( ) ) )
f o r i

in range ( l 2+1 , 5 ) :

input ( )

(from a solution to the Magic Trick problem of the Google Code Jam 2014
programming competition5). We instantiate our data shape domain Q with the
type constraining domain KT and the interval constraining domain KI. In this

4 https://github.com/caterinaurban/Lyra
5 https://codingcompetitions.withgoogle.com/codejam/archive/2014

case, our data shape analysis with Q(KT, KI), determines that correct data ﬁles
for the program have the following shape:

What Programs Want

19

d1
1






4

4











2

...

1

1
(cid:104)int, [0, inf](cid:105)
(cid:104)int, [1, 4](cid:105)

. . .

. . .

(cid:104)int, [1, 4](cid:105)

2
3 (cid:104)string, [− inf, inf](cid:105) (cid:104)string, [− inf, inf](cid:105) . . .
...
6 (cid:104)string, [− inf, inf](cid:105) (cid:104)string, [− inf, inf](cid:105) . . .
7
8 (cid:104)string, [− inf, inf](cid:105) (cid:104)string, [− inf, inf](cid:105) . . .
...
11 (cid:104)string, [− inf, inf](cid:105) (cid:104)string, [− inf, inf](cid:105) . . .
...

. . .

. . .

. . .

. . .

. . .

where d1
record in the data ﬁle. In particular, we know that 1 ≤, d1
from the for loops at lines 4-5 and 7-8 (resp. at lines 10-11 and 13-14).

1 denotes the ﬁrst (i.e., and in fact the only) data ﬁeld 1 of the ﬁrst data
7 ≤ 4)
(cid:4)

2 ≤ 4 (resp. 1 ≤ d1

Bird Watching. Let us consider now the following python program fragment:

1 N, M, S = map( int ,
2 p r e = [ [ ]
3 f o r
4

f o r
in range (M) :

t = map( int ,

f ,
p r e [ t ] . append ( f )

5
6 f o r n in p r e [ S ] :
7

. . .

input ( ) . s p l i t ( ) )

in range (N) ]

input ( ) . s p l i t ( ) )

(from a solution to the Bird Watching problem of the SWERC 2019-2020 pro-
gramming competition6). We instantiate Q with the type constraining domain
KT and the octagon constraining domain KO. A forward numerical pre-analysis
with the octagon domain O determines, in particular, that 0 ≤ len(pre) ≤ N − 1
(cf. line 2). Thus, our backward data shape analysis with Q(KT, KO) determines
that correct data ﬁles for the program have the following shape:

1
1 (cid:104)int, 0 ≤ d1
1(cid:105)
2 (cid:104)int, true(cid:105)
3 (cid:104)int, true(cid:105)
...

. . .

2
(cid:104)int, 0 ≤ d2
1(cid:105)
2 ≤ d1
1(cid:105)
3 ≤ d1
1(cid:105)

(cid:104)int, 0 ≤ d2
(cid:104)int, 0 ≤ d2

. . .

d2
1






3
(cid:104)int, 0 ≤ d3
1 ≤ d1

1 − 1(cid:105)

where dj
that 0 ≤ d3
for 2 ≤ i, from the list access at line 5.

i denotes the data ﬁeld j of the data record i. In particular, we know
i ≤ d1
1 − 1 from the list access at line 6 and, similarly, 0 ≤ d2
1,
(cid:4)

1 ≤ d1

6 https://swerc.eu/2019/

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

20

Caterina Urban

Adult Census Data. Let us consider the following fragment of a pre-processing
python function for the Adult Census dataset7:

1 def p r e p r o c e s s d a t a ( d a t a ) :
2

new data = [ ]
f o r i

in range ( len ( l i s t ( d a t a ) ) ) :

p e r s o n n e w = [ ]

p e r s o n n e w . append ( d a t a [ i ] [ 0 ] )

w = d a t a [ i ] [ 1 ]
i f w == " P r i v a t e " :

p e r s o n n e w . append (w)

e l i f w == " S e l f - emp - not - i n c " or w == " S e l f - emp - i n c " :

p e r s o n n e w . append ( " S e l f - E m p l o y e d " )

e l i f w == " F e d e r a l - g o v " or w == " L o c a l - g o v " or w == " S t a t e - g o v " :

p e r s o n n e w . append ( " G o v e r n m e n t " )

e l i f w == " W i t h o u t - p a y " or w == " N e v e r - w o r k e d " :

p e r s o n n e w . append ( " O t h e r " )

e l s e : r a i s e E x c e p t i o n ( " W o r k c l a s s n o t m a t c h e d : " , w,

i )

. . .

new data . append ( p e r s o n n e w )

return new data

(taken from [39]) where the function argument data has been loaded from a CSV
ﬁle. Our backward shape analysis instantiated with the string set constraining
domain KW determines that correct CSV ﬁles have the following shape:

1

2

3

...

1
(cid:62)W
(cid:62)W
(cid:62)W

. . .

2
W
W
W

. . .

...
. . .
. . .
. . .

. . .

where W is the set of strings { ’Private’, ’Self-emp-not-inc’, ’Self-emp-inc’,
’Federal-gov’, ’Local-gov’, ’State-gov’, ’Without-pay’, ’Never-worked’ }.
(cid:4)

7 Related Work

Learning the input format of a given program is not a new research area but it
has recently seen increased interest, especially in the contest of grammar-based
automated test generation and fuzzing applications [23,30,34, etc.].

Many of the approaches in the literature are black-box, e.g., glade [3] and
Learn&Fuzz [24]. These generally generate input grammars or grammar-like
structures that are strictly meant as intermediate representation to be fed to a
test generation engine and are not meant to be readable by a human. On the
other hand, the result of our analysis is human-readable and can be used for
other purposes than test generation, e.g., code speciﬁcation and data cleaning.
Moreover, these approaches have to rely on samples of valid inputs, while our
approach only needs the program to be analyzed.

7 https://archive.ics.uci.edu/ml/datasets/adult

What Programs Want

21

Another sample-free approach is autogram [31], which uses dynamic data
ﬂow analysis to generate readable and usable grammars. One disadvantage of
this approach is that it will skip parts of the input if these are not stored in some
program variables (e.g. if a program scans over a comment). On the contrary, in
such a case, our approach will not know any value information about the skipped
data but will still know that this data should be present in the data ﬁle (see the
Magic Trick example in Section 6 for instance).

To the best of our knowledge ours is the ﬁrst approach that uses static
analysis to infer the input format of a given program. Moreover, contrary to the
above grammar synthesis approaches, our approach infers semantic (and not just
syntactic) information on the input data of a program. Closest to ours, is the
work of Cheng and Rival [8] on the static analysis of spreadsheet applications.
They however only focused on type-related properties.

Finally, the main diﬀerence compared to the inference of necessary precon-
ditions proposed by Cousot et al. [14] or the (bi-)abduction [6] used in tools like
Infer [5] is that our analysis can also deal with inputs read at any point during
the program (thus notably also inside loops whose execution may depend on
other inputs — this is where the need for the stack comes from, cf. Section 4).

8 Conclusion and Future Work

In this paper, we have proposed a parametric static shape analysis framework
based on abstract interpretation for inferring semantics properties of input data
of data-processing programs. Speciﬁcally, our analysis automatically infers nec-
essary conditions on the structure and values of the input data for the data-
processing program to run successfully and correctly.

It remains for future work to explore possible applications of the result our
analysis. In particular, we are interested in developing better grammar-based
testing approaches. We are also interested in developing tools for assisting and
guiding or even automating the checking and cleaning of data.

References

1. R. S. Abdelbar. Automated Checking of Implicit Assumptions on Textual Data.

Bachelor’s thesis, ETH Zurich, Switzerland, 2018.

2. V. Arceri and I. Mastroeni. An Automata-based Abstract Semantics for String

Manipulation Languages. In VPT@Programming, pages 19–33, 2019.

3. O. Bastani, R. Sharma, A. Aiken, and P. Liang. Synthesizing Program Input

Grammars. In PLDI, pages 95–110, 2017.

4. B. Blanchet, P. Cousot, R. Cousot, J. Feret, L. Mauborgne, A. Min´e, D. Monniaux,
and X. Rival. Design and Implementation of a Special-Purpose Static Program
Analyzer for Safety-Critical Real-Time Embedded Software.
In The Essence of
Computation, pages 85–108, 2002.

5. C. Calcagno, D. Distefano, J. Dubreil, D. Gabi, P. Hooimeijer, M. Luca, P. W.
O’Hearn, I. Papakonstantinou, J. Purbrick, and D. Rodriguez. Moving Fast with
Software Veriﬁcation. In NFM, pages 3–11, 2015.

22

Caterina Urban

6. C. Calcagno, D. Distefano, P. W. O’Hearn, and H. Yang. Compositional Shape
Analysis by Means of Bi-Abduction. Journal of the ACM, 58(6):26:1–26:66, 2011.
7. D. R. Chase, M. N. Wegman, and F. K. Zadeck. Analysis of Pointers and Struc-

tures. In PLDI, pages 296–310, 1990.

8. T. Cheng and X. Rival. Static Analysis of Spreadsheet Applications for Type-

Unsafe Operations Detection. In ESOP, pages 26–52, 2015.

9. A. S. Christensen, A. Møller, and M. I. Schwartzbach. Extending Java for High-
Level Web Service Construction. ACM Transactions on Programming Languages
and Systems, 25(6):814–875, 2003.

10. G. Costantini, P. Ferrara, and A. Cortesi. A Suite of Abstract Domains for Static
Analysis of String Values. Software - Practice and Experience, 45(2):245–287, 2015.
11. P. Cousot and R. Cousot. Static Determination of Dynamic Properties of Pro-

grams. In Symposium on Programming, pages 106–130, 1976.

12. P. Cousot and R. Cousot. Abstract Interpretation: a Uniﬁed Lattice Model for
Static Analysis of Programs by Construction or Approximation of Fixpoints. In
POPL, pages 238–252, 1977.

13. P. Cousot and R. Cousot. Abstract Interpretation and Application to Logic Pro-

grams. Journal of Logic Programming, 13(2&3):103–179, 1992.

14. P. Cousot, R. Cousot, M. F¨ahndrich, and F. Logozzo. Automatic Inference of

Necessary Preconditions. In VMCAI, pages 128–148, 2013.

15. P. Cousot, R. Cousot, and F. Logozzo. A parametric segmentation functor for fully
automatic and scalable array content analysis. In POPL, pages 105–118, 2011.
16. P. Cousot and N. Halbwachs. Automatic Discovery of Linear Restraints Among

Variables of a Program. In POPL, pages 84–96, 1978.

17. A. Cox, B. E. Chang, and X. Rival. Automatic Analysis of Open Objects in

Dynamic Language Programs. In SAS, pages 134–150, 2014.

18. A. Cox, B. E. Chang, and S. Sankaranarayanan. QUIC Graphs: Relational Invari-

ant Generation for Containers. In ECOOP, pages 401–425, 2013.

19. D. Delmas and A. Min´e. Analysis of Software Patches Using Numerical Abstract

Interpretation. In SAS, pages 225–246, 2019.

20. I. Dillig, T. Dillig, and A. Aiken. Fluid Updates: Beyond Strong vs. Weak Updates.

In ESOP, pages 246–266, 2010.

21. I. Dillig, T. Dillig, and A. Aiken. Precise Reasoning for Programs Using Containers.

In POPL, pages 187–200, 2011.

22. J. Fulara. Generic Abstraction of Dictionaries and Arrays. Electronic Notes in

Theoretical Computer Science, 287:53–64, 2012.

23. P. Godefroid, A. Kiezun, and M. Y. Levin. Grammar-Based Whitebox Fuzzing.

In PLDI, pages 206–215, 2008.

24. P. Godefroid, H. Peleg, and R. Singh. Learn&Fuzz: Machine Learning for Input

Fuzzing. In ASE, pages 50–59, 2017.

25. D. Gopan, F. DiMaio, N. Dor, T. W. Reps, and S. Sagiv. Numeric Domains with

Summarized Dimensions. In TACAS, pages 512–529, 2004.

26. D. Gopan, T. W. Reps, and S. Sagiv. A framework for numeric analysis of array

operations. In POPL, pages 338–350, 2005.

27. N. Halbwachs and M. P´eron. Discovering properties about arrays in simple pro-

grams. In PLDI, pages 339–348, 2008.

28. M. Hassan, C. Urban, M. Eilers, and P. M¨uller. MaxSMT-Based Type Inference

for Python 3. In CAV, pages 12–19, 2018.

29. M. Hennessy and J. F. Power. An Analysis of Rule Coverage as a Criterion in
In ASE, pages

Generating Minimal Test Suites for Grammar-Based Software.
104–113, 2005.

What Programs Want

23

30. C. Holler, K. Herzig, and A. Zeller. Fuzzing with Code Fragments. In USENIX

Security, pages 445–458, 2012.

31. M. H¨oschele and A. Zeller. Mining Input Grammars from Dynamic Taints.

In

ASE, pages 720–725, 2016.

32. B. Jeannet and A. Min´e. Apron: A Library of Numerical Abstract Domains for

Static Analysis. In CAV, page 661667, 2009.

33. J. Liu and X. Rival. An Array Content Static Analysis Based on Non-Contiguous

Partitions. Computer Languages, Systems & Structures, 47:104–129, 2017.

34. R. Majumdar and R. Xu. Directed Test Generation using Symbolic Grammars. In

ASE, pages 134–143, 2007.

35. A. Min´e. The Octagon Abstract Domain. Higher Order and Symbolic Computation,

19(1):31–100, 2006.

36. R. Monat, A. Ouadjaout, and A. Min´e. Static Type Analysis by Abstract Inter-

pretation of Python Programs. In ECOOP, 2020.

37. F. Nielson, H. R. Nielson, and C. Hankin. Principles of Program Analysis. Springer,

1999.

38. M. Schumacher. Automated Generation of Data Quality Checks. Master’s thesis,

ETH Zurich, Switzerland, 2017.

39. C. Urban, M. Christakis, V. W¨ustholz, and F. Zhang. Perfectly Parallel Fairness

Certiﬁcation of Neural Networks. CoRR, abs/1912.02499, 2019.

