Mining Hidden Populations through Attributed Search

Suhansanu Kumar, Heting Gao, Changyu Wang, Hari Sundaram, Kevin Chen-Chuan Chang
Department of Computer Science
. University of Illinois, Urbana Chamapaign
{skumar56,hgao17,changyuw,hs1,kcchang}@illinois.edu

9
1
0
2

y
a
M
1
1

]
I
S
.
s
c
[

1
v
5
0
5
4
0
.
5
0
9
1
:
v
i
X
r
a

ABSTRACT
Researchers often query online social platforms through their ap-
plication programming interfaces (API) to find target populations
such as people with mental illness [7] and jazz musicians [10]. En-
tities of such target population satisfy a property that is typically
identified using an oracle (human or a pre-trained classifier). When
the property of the target entities is not directly queryable via the
API, we refer to the property as ‘hidden’ and the population as
hidden population. Finding individuals who belong to these popu-
lations on social networks is hard because they are non-queryable,
and the sampler has to explore from a combinatorial query space
within a finite budget limit. By exploiting the correlation between
queryable attributes and the population of interest and by hierarchi-
cally ordering the query space, we propose a Decision tree-based
Thompson sampler (DT-TMP) that efficiently discovers the right com-
bination of attributes to query. Our proposed sampler outperforms
the state-of-the-art samplers in online experiments, for example by
54% in Twitter. When the number of matching entities to a query is
known in offline experiments, DT-TMP performs exceedingly well
by a factor of 0.9-1.5× over the baseline samplers.

CCS CONCEPTS
• Computing methodologies → Discrete space search; Clas-
sification and regression trees; • Information systems → Social
networks; Web interfaces;

1 INTRODUCTION
Social networks have made available large amounts of public in-
formation online. This colossal information has led to the growth
of industries such as social media marketing and management, on-
line advertisements. Futher, it has led to scientific advancements in
analysis and mining of social information by several organizations
including ICWSM and ASONAM.

However, with the enormous size of crowds on social networks
such as Twitter and Facebook, we are facing difficulty in mining
information concerning a target group of the population. For ex-
ample, social scientists and advertisers are increasingly interested
in understanding the online behavior of a specific population. Ex-
amples include: people with mental illnesses [7], sex workers [19],
cyber bullying [26], hacked accounts [14] to name a few. More
generally, the researchers’ goal is to find people that satisfy a cer-
tain property, but crucially, API doesn’t provide direct querying
of the hidden property. For example, one cannot use the phrase
“mental illness” on Twitter to identify people on Twitter potentially
suffering from depression because they rarely use that phrase in
any of their tweets to self-describe. Thus when we refer to “hidden
populations,” we are more concretely referring to populations with
a non-queryable property.

In this paper, we focus on identifying hidden populations through
attributed search. Many social networks allow for searching via
attributed query, in addition to textual query. For example, we can
also specify time and location attributes on Twitter in addition to
text. In contrast to attributed search, text search has received consid-
erable attention in the IR community. While there exist significant
work on web crawling [23, 4, 2], we are missing such technologies
to mine the entities e.g., users on Twitter or GitHub) using their
social attributes (e.g., for Twitter: their tweets, location; for GitHub:
programming language). To address this gap, we explore the prob-
lem of hidden population sampling from online social platforms
using attributed search for the first time.

There are two prominent reasons why attributed search of hid-

den populations on social networks is challenging:

Combinatorial search space: A combination of queryable at-
tributes expresses a query issued to the application programming
interface (API). Thus, the size of query space is the product of
the attribute cardinalities (the number of possible values for each
attribute) and grows exponentially as the number of attributes
increases. Since social networks employ rate limits affecting the
number of queries (e.g., Twitter API allows only 60 API calls in an
hour) and search result limits (e.g., Twitter API returns at most 100
entities in single API call) affecting the number of results obtained
in a single query, a naive hidden population sampler is likely to
remain in exploration phase after it exhausts the query budget.

Black-box API: The internal mechanism of online APIs is often
propriety information unavailable to users. The sampler interacts
with API using query to get a subset of entities (returned result)
matching the query. Some of the challenges associated with an
unknown query system are: a) stochastic feedback i.e., different
pages of a query very likely have different number of hidden entities,
b) re-sampling of a hidden entity, i.e. the API returns the same
hidden entity for two different queries when the entity satisfies
both queries, c) variable size of returned results, i.e. the API fewer
than the page-size of entities when there is not enough matching
entities in the population. Thus, it becomes difficult for online
samplers to efficiently discover high-quality queries that would
lead to the sampling of a high number of hidden entities.

The key insight for hidden population sampling is to identify
high-quality queries and issue them multiple times. First, we ad-
dress the problem of combinatorial search space by hierarchically
organizing the query space in the form of a tree. Subsequently, we
use a decision-tree based search strategy to systematically explore
the query space by expanding along high yielding decision-tree
branches. Second, we address the problem of black-box API by
using the returned set of results to estimate the quality of not just
the issued query but also related queries sharing one or more at-
tribute combinations. We employ a reward function to estimate
the unique un-sampled hidden entities that can be obtained by

 
 
 
 
 
 
Conference’17, July 2017, Washington, DC, USASuhansanu Kumar, Heting Gao, Changyu Wang, Hari Sundaram, Kevin Chen-Chuan Chang

Figure 1: The entity population is represented by a cube (color indi-
cates the distribution of hidden entities). DT-TMP hierarchically ex-
plores the entity population using a drill down approach. It first
finds the best query plane (general query), followed by the best line
in a query plane (more specific) query and so on.

issuing a query. Our unified reward function takes into account
the stochastic feedback and re-sampling effect while allowing for
a exploration-exploitation among queries. We use reinforcement
learning based Thompson sampling to define the reward function.
We put together the above insights to propose a Decision-Tree
Thompson sampling (DT-TMP) algorithm. We illustrate the working
of DT-TMP using a 3D toy model in Figure 1 comprised of three
queryable attributes represented by three dimensions. The DT-TMP
algorithm maintains a query pool from where it queries the API.
We initialize the query pool with the most general query, i.e. the al-
gorithm searches from the entire population. Then, after an epoch
time, the algorithm identifies the most promising query (i.e. at-
tribute and the corresponding value)—the one with the highest
reward. The query pool expands to add new queries as shown
in the second subplot. That is, DT-TMP issues a query with this
attribute value as a predicate to identify the next attribute and
corresponding attribute value to use as a conjunct. Thus, the algo-
rithm over iterations converges to explore among the high hidden
entity density regions of the population. Based on the returned set
feedback, DT-TMP updates reward function corresponding to every
query in the query pool. Finally, the algorithm terminates when
we’ve exhausted the query budget.

In summary, this paper makes the following contributions:

• We propose a novel hidden population sampling problem
in online social platforms via attributed search. Further, we
propose a reinforcement learning based sampling strategy
that performs hierarchical exploration of the combinatorial
query space.

• Our generalized sampling strategy applies to diverse web-
forms having a variable number and type of attributes with
varying attribute cardinalities.

• We perform a comprehensive set of experiments over a suite
of twelve sampling tasks on three online web-query plat-
forms: Twitter, RateMDs and GitHub, and three offline entity
datasets: Patent, Adult and Auto that illustrates the efficacy
of DT-TMP sampler. DT-TMP outperforms all baseline sam-
plers, for example by a margin of 54% on Twitter.

• We perform an extensive ablation study to understand the
impact of different sampling factors. We find page-size, at-
tribute cardinality, the number of queryable attributes and
correlation between queryable attributes and the hidden
property are the prominent factors that affect sampling.

Figure 2: Twitter query interface shown as a typical exam-
ple of online social platform interface comprising several
queryable attributes.

2 PROBLEM STATEMENT
In this section, we motivate the problem of hidden population
sampling through a real-world example. A formal definition of
the sampling problem follows the motivating example. Finally, we
present the challenges associated with the problem, and the desired
characteristics of an ideal sampler.

Consider a scenario in which a healthcare expert or a researcher
is interested in reaching out to the depressed people on Twitter.
Assume that the expert has designed a classifier for identifying
whether a Twitter user is depressed or not based on the user’s profile
description and activity [6, 31]. The expert’s objective is then to
retrieve a maximum number of Twitter users that have the hidden
property of depression. However, it is not trivial under present
circumstances to sample the depressed population from Twitter due
to several bottlenecks. The database of Twitter accounts is accessible
only through Twitter’s application programming interface (API). As
shown in Figure 2, Twitter allows its user accounts to be queried by
only some specific attributes such as time, location and text. Besides,
Twitter permits only 180 API calls in a 15-minute window. Notice
that the depressed population is distributed across the entire Twitter
population necessitating the sampler to consider all types of queries.
Furthermore, the distribution of the depressed population across
different queries is unknown making it difficult to frame queries
that would yield in a high discovery of the depressed population
within a limited budget of API calls.

To explain the sampling framework, we describe two major fea-
tures of online social platform services like Twitter API: query
interface and returned-result set. Query interface as shown in Fig-
ure 2 lets the expert query Twitter by setting attribute-values to

Mining Hidden Populations through Attributed Search

Conference’17, July 2017, Washington, DC, USA

the queryable attributes. For example, the expert may set the loca-
tion attribute to ‘New York’ and text-attribute to ‘mental health’
and time attribute to ‘*’ (or ignoring it). In other words, the query
can be interpreted as a conjunction over queryable attributes say
Ai (i = 1, 2, . . . r ) where attribute-values zi of the attributes are
obtained from their respective attribute domains zi ∈ di where
di = dom(Ai ) ∪ {∗}. Formally, we shall represent a query involving
r queryable attributes by (cid:211)r
i=1 zi . In this work, we consider only
conjunctive combination of attributes as a query.

On issuance of a query, Twitter API by default returns a result
page comprising m (=20) entities and a pointer to the next page of
results. The sampler may obtain the subsequent m results for the
same query by issuing another API call or get another m results by
issuing a different query. Thus, the sampler incurs a unit cost of
communication for each query issued. Subsequently, the profiles
of entities returned by the API are analyzed to identify whether
they satisfy the hidden property of depression or not. Since the
cost incurred in determining the entity’s hidden property is directly
proportional to the API call cost, we use API cost as the sole cost
constraint of the problem.

Now, we formally define the hidden sampling problem as follows.
Problem definition: Suppose entities on an online social plat-
form are queryable using a conjunctive combination of r queryable
attributes Ai for i = 1, 2, . . . r . Further, consider that there exists a
target subpopulation satisfying a hidden property that is verifiable by
an oracle (usually a classifier). Given a budget B of API calls, the sam-
pler’s objective is to maximize the count of sampled entities satisfying
the hidden (target) property.

Problem hardness: The sampling of hidden population is chal-
lenging in the real-world setting due to several reasons. One, the
number of possible queries that can be constructed using the queryable
attributes ((cid:206)
i |di |) is exponential in the size of attribute domains.
Given a fixed API budget, query selection from an exponential
query space makes the problem particularly challenging. Two, the
API returns m or fewer results, and when similar queries are used, it
often leads to re-sampling of same entities. It therefore becomes per-
tinent to handle the re-sampling issue so that maximum number of
distinct hidden entities can be sampled. Three, the limited API calls
necessitates that the sampler manages an exploration-exploitation
tradeoff. Given that the sampler is oblivious of the correlation be-
tween the queryable attributes and the hidden property, it has to
tradeoff the API calls between learning the correlation and issu-
ing the highly correlated queries. In addition, a hidden population
sampler is intended to be used for sampling a diverse set of entities
such as books, restaurants, products or people through the web
interface of online platforms such as the library, Yelp, Amazon and
LinkedIn respectively. Given the variety of online platform settings
comprising of different sorts of queryable attributes and an unspec-
ified hidden property, an ideal sampler should exhibit the following
characteristics.

Simplicity: The model should be applicable to web-forms having
different number and types of attributes with varying attribute car-
dinality. Online: The model can be updated using only the feedback
obtained by the returned result analysis. Unsupervised: The lack of
training examples is usually the prime motivation behind hidden
population sampling. Prior distributional information about the
hidden population is unavailable to the sampler; thus necessitating

Table 1: Terms and their definitions.

Term
Page size

Query pre-
cision
Attribute
cardinality
Attribute
domain

Notation

Definition

m Maximum number of results re-

pq

turned in a single API call.
Fraction of target entities in the pop-
ulation matching a given query.

|dom(Ai )| Number of attribute-values of a

dom(Ai )

given attribute.
Set of all possible attribute-values
of a given attribute.

the algorithm to be unsupervised. Task-independence: The sampler
is oblivious of the hidden property, and it could therefore be used
for sampling any well-defined hidden population, i.e., the sampler
should be able to adapt when plugged-in with a different black-box
classifier used as the oracle. Perpetual: Ideally, a sampler is expected
to be efficient both when the budget is limited and when the bud-
get is asymptotically large. Flexibility: The model could be easily
extended when extra information such as attribute semantics or
attribute correlations is partially available.

In the following section, we propose a hidden population sampler
that exhibits every aforementioned characteristic. Table 1 lists some
of the frequently used terms and their definitions in this paper.

3 DECISION TREE-MULTI ARMED BANDIT
In this section, we discuss in detail our proposed unsupervised online
method for sampling the hidden target population.

3.1 Decision problem
We show that the process of sampling hidden population from
online social platforms as described in Section 2 is primarily a
decision problem. The sampler continuously decides which query to
issue to the API such that the sampler obtains a maximum possible
number of entities from the hidden population within the given
API budget. Based on the sampled entities, the sampler maintains a
probabilistic model of the entity database that gets updated over
time. The model is used to construct a query. The returned-results
obtained from issuing the constructed query is subsequently used
to update the model. This cycle of query construction, returned-
result analysis, and model updation continues until the API budget
runs out. We deliberate upon each component of the cyclic process
separately.

We maintain the model of the entity database using a set of
probabilistic parameters. In the absence of any prior semantics or
syntactic information about the attributes, the model treats each
queryable attribute such as location, time and keywords in Twitter
as independent variables. Furthermore, we model the attribute-
values of every attribute independently, i.e. ‘New York’, ‘Los Ange-
les‘ and ‘Chicago’ corresponding to location attribute is modeled
independently as well. The above assumptions concerning the en-
tity database allow our model to be applicable across a suite of
online social platforms. The probability model of the entity data-
base is used to not only estimate the utility of issuing each possible
query but also to construct the next query.

Conference’17, July 2017, Washington, DC, USASuhansanu Kumar, Heting Gao, Changyu Wang, Hari Sundaram, Kevin Chen-Chuan Chang

Figure 3: Model description of DT-TMP. For hidden population of ‘mental illness’ (represented in red color), the DT-TMP searches the population
for the best combinatorial query comprising of two queryable attributes: income and age. It first uses <*, *> query to find the best single
attributed query from queries such as <Low, *> and <*, Young>. Subsequently, it finds the best query <Low, *> along which it expands its
query search. The decision tree on the right shows the query expansion withe the query expansion along green links.

The sampler interacts with the online social platform via the
query interface. As stated in Section 2, we represent the query as a
conjunctive combination of discrete attributes. In compliance with
our problem formulation, we approximate continuous attributes by
discretizing them into different bins and handle text search by an
expert-based selection of a few relevant textual phrases. Note, that
the number of possible queries that can be constructed using the
queryable attribute is still exponential, i.e. (cid:206)
i |di | which is typically
very high. The exponential number of choices makes the decision
problem even more challenging.

On issuance of an attributed query, the online social platform
returns a list of entities: ‘returned result set’. As shown in the
Twitter example, the same attributed query can be used to gather
more results by traversing over the next pages. The returned results
act as feedback for the sampler which is used to update the model.
The number of entities belonging to the hidden population indicates
the quality of the query. Thus, the core objective of the hidden
population sampler is to find high-quality queries and to issue
those queries repeatedly.

Next, we describe a detailed solution to the cyclic process of
decision making for hidden population sampling by employing
a decision-tree guided multi-armed bandit algorithm. In the later
sections, we show the utility of our proposed sampler over a range
of tasks.

3.2 Proposed DT-TMP algorithm
In this section, we present solutions to the three prominent chal-
lenges encountered by a hidden population sampler in the real-
world setting. The challenges are exponential query space, uncon-
ventional reward feedback, and an unknown correlation between
queryable attributes and hidden property. Next, we fully describe
the proposed Decision-Tree Thompson sampler (DT-TMP).

First, as noted in the problem statement, any hidden popula-
tion sampler constructs its queries by choosing attribute-values zi
from di of each queryable attribute Ai . The size of query space is
therefore exponential in the attribute cardinality (cid:206)
i |di |. We deal
with the problem of exponential query space by hierarchically or-
dering the queries from the most general to the least general (or

the most specific) query. Figure 4 shows the hierarchical organi-
zation of queries. For instance, a query where location attribute
is set to ‘Chicago’ and text attribute is ignored (or set to ‘*’) is a
generalization of the query where location is set to ‘Chicago’ and
text attribute is set to ‘#Cubs’ since the former includes all entities
matching the later. In principle, a query q1 is a generalization of
query q2 if the set of population entities matching query q1 is a
superset of the set of entities matching q2. Hence, the most general
query is one where zi set to ‘*’ for every attribute.

Second, the analysis of the returned result set by the API is a
non-trivial task because of the partial information available during
sampling and the re-sampling issue. In each API call, the sampler
obtains partial information in the form of the returned set of m or
fewer results. For illustration, consider that a query where location
attribute is set to ‘Chicago’ yields 5 entities from the depressed
population out of 20 returned entities on the first result page. We
shall assume the query precision or the fraction of hidden entities
matching this query is 5/20 = 0.4. In other words, it is very likely
to obtain another 5 hidden entities when a new API call is made
for the next result page of the same query. More generally, we
model probabilistically the query precision using a Beta distribution
which is typically used to model probability of probabilities [28].
Furthermore, a query where location is set to ‘Chicago’ is very
likely to lead to the entities that also satisfy queries where the text
attribute is ‘#Cubs’. The sampler, therefore, needs to update the
quality metric of queries where text attribute is set to ‘#Cubs’ so
that it avoids making redundant queries that lead to re-sampling
of same hidden entities. We avoid the re-sampling by estimating
the expected number of distinct unseen entities to be discovered
by issuing a query q. Without making any assumption about the
ordering of results for a specific query, we assume that the results
are returned either via sampling with or without replacement from
the set of entities matching the given query. For sampling with
replacement, we derive a reward function as follows.

Assume that the number of entities in the database satisfying
a query q is Nq . Further, assume that the sampler has already ob-
served nq distinct entities satisfying the query q out of which there

<low, *><mid, *><*, young><*, old><*, old><low, old><mid, old><high, old><low, old><low, old><mid, old><mid, old><*, *><*, *><low, *><high, *><*, young><*, old><low, Old><high, Old>Queries covering different parts of the populationQueries in the Decision-Treeageincome<mid, old>Mining Hidden Populations through Attributed Search

Conference’17, July 2017, Washington, DC, USA

are Sq number of target entities and Fq number of non-target en-
tities. From Standard Probability Theory, we therefore obtain the
following expected reward rq when query q is executed.

E[rq ] =

Sq
Sq + Fq
(cid:32)(cid:32)(cid:32)
(cid:32)(cid:32)(cid:32)
(cid:123)(cid:122)
(cid:125)
(cid:124)
expected # targets

·

·

Nq − nq
Nq
(cid:123)(cid:122)
new

(cid:32)(cid:32)(cid:32)(cid:32)

(cid:32)(cid:32)(cid:32)(cid:32)

(cid:124)

(cid:125)

(cid:16)1 − (cid:0)1 −
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)

(cid:124)

(cid:123)(cid:122)
unique

1

(cid:17)

(cid:1)m

Nq
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)

(cid:125)

(1)

where m is the maximum number of results returned by the
web API in response to a single query. The expected reward is the
estimated number of new distinct hidden entities that are likely to
be obtained by re-issuing the query q.

For sampling with replacement, we update the reward function
by dropping the third term since unique entities within the result
page of a query is guaranteed (i.e.
m). When Nq is
unknown, we assume that Nq >> nq , therefore the reward function
approximates to just the first term (i.e.

Nq −nq
Nq

Sq
Sq +Fq

Sq
Sq +Fq

m).

The query precision for any query is an unknown measure to
an unsupervised hidden population sampler. If the precision val-
ues are known, the sampler would straightforwardly formulate its
queries using only the high precision queries. In order to obtain an
unbiased estimate of the precision, the sampler needs to explore
over the combinatorially large query space. While a naive explo-
ration of queries is beneficial for formulating better future queries
learned from the unbiased estimates, it leads to poor immediate re-
sults. We, therefore, employ Thompson sampling for handling this
exploration-exploitation tradeoff of queries. Thompson sampling
is a well-known optimal MAB algorithm that achieves the lower
regret bound of the MAB problem [1]. Notice that Thompson sam-
pling is consistent with the independence assumption of attributes
and attribute-values made in Section 3.1.

Now, we generalize the intuitions presented above to propose
a simple yet effective hidden population sampler: Decision-Tree
Thompson sampler (DT-TMP).

Description of algorithm: DT-TMP is a unique combination of a
standard Decision Tree [24] and Thompson sampling [30]. DT-TMP
maintains a query pool Q comprising of queries explored by the
algorithm. The query pool is initialized with the most general query.
Typically, the most general query can be represented using the
queryable attributes as (cid:211)r
i=1 ∗. The most general query is initially
used to sample from the entire population. DT-TMP expands the
query pool by adding more specific queries.

For every query q ∈ Q, DT-TMP tries to predict the future reward
that would be obtained when query q is issued. Based on the pre-
diction, DT-TMP chooses the best query to issue. A query issued to
the API yields a result page comprising m entities. Each returned
entity is evaluated as a success or failure depending on whether it
belongs to the hidden population or not. We model each success
and failure of every returned entity as a random sample drawn from
a unknown Beta distribution of the query that the model learns
over iterations. We use a non-informative uniform prior Beta(1, 1)
as the starting state for every query. This choice of Beta distribu-
tion permits us to efficiently update the posterior distribution upon
receiving the returned results.

We now show how to update the posterior distribution of any
query q′ ∈ Q when another query q is issued. If q is a generalization

of q′, we increment the success or failure parameter of Beta distri-
bution by one depending on whether the returned entity is in target
populace or not, and the returned entity matches query q. In the
other case, when the specific query q accounts for only a fractional
part of the general query q′, we update the Beta distribution of the
general query proportionately. That is, if q is a specific version of
q′, we increment the success or failure parameter of q by the ratio
of population size matching query q to population size matching
query q′. We are able to estimate this fraction directly from the
returned result since the query pool is expanded hierarchically from
the most general to the most specific queries.

At each step of the iteration, DT-TMP employs Thompson sam-
pling to select the best query among the query pool. Note, that the
query pool is fixed over epoch time h to ensure that enough entities
are sampled before expanding the query pool. The query pool is
expanded by adding new specific queries corresponding to the best
query in Q. We prove using Lemma 3.1 that expansion of a general
query always leads to an equally good or a higher precision specific
query. Thus, DT-TMP continues to find the highest quality query
until the budget is finished.

Lemma 3.1. The query precision of the specific queries are cen-
tered around the query precision of their corresponding general query.
Further, there exists a leaf node of the decision tree with the highest
quality precision.

Proof. Lets assume that the query precision of a general query
qд is pд, and it has n immediate specific queries qi as children in the
decision tree. Assume that the query precision of the i-th specific
query qi is pi where i ∈ {1, 2, . . . n}. Further, we denote fi as the
ratio of the size of the population matching query qi to the size
of population matching the general query qд. Since the disjoint
specific queries cover the general query, (cid:205)

By preservation of hidden entities, the query precision of the
general query pд can be expressed as the weighted average of the
specific queries’s precision. That is,

i fi = 1.

pд = p1 f1 + p2 f2 + . . . pn fn
Since, pд is a weighted average, it is bounded by the maximum

and minimum of the specific queries’ precision.

Following the above argument, we note that there always exists
a specific query whose precision is strictly greater or equal to the
query precision of the general query. Since, the leaf nodes are the
most specific queries in the decision tree of DT-TMP, it therefore
follows that one of the leaf nodes of the decision tree has the highest
□
precision.

Algorithm 1 summarizes the DT-TMP algorithm via pseudo-code.
We provide a diagrammatic representation of DT-TMP algorithm
in Figure 4 in a stylized sampling environment where there are
only two binary queryable attributes. Next, we perform a detailed
analysis of the DT-TMP algorithm.

Analysis of algorithm: Even though DT-TMP models the com-
plex relationship among queryable attributes and hidden attributes
while keeping an exploration-exploitation tradeoff among different
queries, it is surprisingly easy to implement and has a linear space
and quadratic time complexity. For practical reasons, we assume
number of attributes r and result size m to be constant. In each

Conference’17, July 2017, Washington, DC, USASuhansanu Kumar, Heting Gao, Changyu Wang, Hari Sundaram, Kevin Chen-Chuan Chang

iteration in the outer-loop, the maximum number of queries added
to the query pool is limited by n where n = (cid:205)r
i=1 |dom(Ai )|; the
budget B limits the number of iterations. Furthermore, the decision
tree takes O(Q) space which is bounded by O(nB). Every query in
Q uses a constant space parameter set to estimate the reward distri-
bution. Thus, the overall space complexity of the DT-TMP is O(nB).
A similar analysis implies the time complexity of DT-TMP is O(n
B)
since each iteration (sampling from and updating of Beta distribu-
tions is performed in constant time) involving updation of specific
and general query combinations take O(n) time. Finally, we notice
that DT-TMP can easily be parallelized by having the worker nodes
use the preceding iteration’s reward distributions while having the
master node maintain the central decision tree.

2

Lastly, we note that at limiting budgets DT-TMP behaves as TMP

when the query pool expands to the entire query space.

Lemma 3.2. At asymptotic limits of the budget, DT-TMP tends to a

naive Thompson sampler.

Proof. Given that every branch is initialized with a query pre-
cision Beta(1, 1), there is a non-zero probability of selecting any
branch using best query selection of DT-TMP (line 9 of Algorithm 1).
DT-TMP will therefore explores every branch of search tree at as-
ymptotic limits of budget. Since, at asymptotic budget limits, all
branches of the decision tree will be explored, hence the query pool
will expand to cover the entire query space. When the query pool
Q covers the entire query space, DT-TMP and TMP are identical. □

3.3 Guarantees of the proposed algorithm
Different number of attributes, attribute cardinalities, attribute dis-
tributions and the use of decision-based search tree structure makes
the analysis of DT-TMP difficult. Furthermore, it is non-trivial to
extend the standard regret analysis used for analyzing MABs to the
DT-TMP algorithm. First, unlike MAB which has just one optimal
arm (or query), a standard DT-TMP’s optimality involves a set of
queries. Second, the underlying quality of a query is fixed in MABs
while DT-TMP has unconventional reward feedback as described
in Section 3.2. Third, on the issuance of a query, the MABs get
one result while DT-TMP gets the result set R that can be of size
anywhere between 0 and m.

In the following lemma, we show that when specific query’s
quality is correlated with the general query’s quality, DT-TMP based
search tree is useful.

Lemma 3.3. For a sufficiently large dataset when the query preci-
sion of specific queries within one general query are more similar to
each another than specific queries of other general query (clustering
effect), DT-TMP requires fewer number of queries to find the optimal
query than TMP.

Proof. For this proof, we shall consider three scenarios of the
clustering of the precision values of specific queries centered around
their corresponding general queries. 1) when the clusters are well
separated or the general queries are disjoint, 2) when any two
cluster among the clusters are disjoint except few specific queries
that are common to both. 3) when the clusters corresponding to
the general queries are overlapping.

First, consider that there are n disjoint general queries q1, q2, . . . qn
and their corresponding query precision be p1, p2, . . . pn . Further,

Figure 4: Decision tree diagram shows how new attribute-
values pairs are added for exploration as DT-TMP samples
queries from two binary attributes A1 and A2. The query at
root of the tree covers the entire database represented by box
in right subplot. General queries are situtated at higher lev-
els of the tree while specific queries that cover only smaller
subsets of population are situated at lower levels of the tree.

Algorithm 1 Decision tree- Thompson sampler

i=1 ∗}

1: Sq = 1, Fq = 1, ∀q. ▷Successes and failures of query q
2: Q = {(cid:211)r
3: S = ϕ
4: for t = 1, 2, . . . B/h do
5:

▷ query pool
▷ sample set of entities
▷ Communication rounds

for j = 1, 2, . . . , h do
for q ∈ Q do

rq ∼ Beta (Sq, Fq ) × Nq −nq
Nq

(cid:1)m (cid:17)
▷ for sampling with replacement

(cid:16)1 − (cid:0)1 − 1
Nq

× Nq

q∗ = arдmaxq ∈Q rq
R = Execute query q∗
S = S ∪ R
sq∗ = Number of successes in R
Sq∗ , Fq∗ = Sq∗ + sq∗ , Fq∗ + |R| − sq∗
# update Beta parameters of other queries
for q′ ∈ descendant(q∗) ∩ Q do

▷ Returned result

▷ Descendent nodes in DT are specific queries of q∗
Sq′+= # success in R matching q′
Fq′+= # failures in R matching q′

for q′ ∈ ancestor (q∗) ∩ Q do

▷ Ancestor nodes in DT are general queries of q∗
ρ = Est. population size of q / population size of q′
Sq′+= ρ× # success in R
Fq′+= ρ× # failures in R

Q = Query-expansion(Q, q∗, S) ▷ adds new queries to the

query pool

Algorithm 2 Query-expansion(Q, q∗, S)

1: for j = 1, 2, . . . , r do
if Aj == ∗ then
2:

for v ∈ dom(Qj ) ∧ v ∈ Sj do ▷ add all possible

attribute-values observed in sample

Q = Q ∪ q∗(Aj = v) ▷ We add new specific query
for unexplored attribute-attribute value pair corresponding to
the best query q∗
return Q

6:

7:

8:

9:

10:

11:

12:

13:

14:

15:

16:

17:

18:

19:

20:

21:

22:

23:

24:

3:

4:

1, 00, 0*, *A1A20, *1, **, 0*, 1A21, 01, 11, 10, 1Query spaceepoch 1epoch 2epoch 3A1A2Mining Hidden Populations through Attributed Search

Conference’17, July 2017, Washington, DC, USA

assume that there are ni specific queries, qi, j where j ∈ {1, 2, . . . ni }
within a general query qi . From Lemma 3.1, the query precision of
specific queries qi, j are clustered around qi ’s precision, i.e. the spe-
cific query qi, j ’s precision pi, j lies in the range [pi − ∆pi , pi + ∆pi ]
where ∆pi > 0. Since, the clusters are well separated we note that
the query precision of the specific queries satisfy the following con-
dition: |pi − pj | > ∆pi + ∆pj for any pair of general queries qi and
qj . The above condition would imply that the all specific queries
corresponding to a general query are well-separated. First, we shall
proof the separation of clusters composed of precision values of
specific queries under the aforementioned condition. Next, we shall
proof the efficacy of DT-TMP over TMP when the clusters satisfy the
condition.

We shall now prove that the precision range of specific queries
corresponding a general query qi is disjoint from the range of
specific queries’ precision corresponding to another general query
qj where i (cid:44) j.

Without loss of generality, we assume that pi > pj . From the
clustering condition stated above, pi − pj > ∆pi + ∆pj . By re-
arranging the terms, we get

pi − ∆pi > pj + ∆pj

Since, ∆pi , ∆pj > 0, thus

pi + ∆pi > pi − ∆pi > pj + ∆pi > pj − ∆pj

It follows form the above inequalities that,

[pi − ∆pi , pi + ∆pi ] ∩ [pj − ∆pj , pj + ∆pj ] = ϕ

Thus, we observe that the precision range of specific queries
belonging to a general query qi which is [pi − ∆pi , pi + ∆pi ] doesn’t
overlap with precision range induced by any another general query
qj .

We shall now use the above clustering condition of the precision
ranges of the specific queries to show that the DT-TMP requires
lesser number of samples than TMP to find the best query in the
query space.

Without loss of generality, assume that p1 > p2 > · · · > pn .
Further, assume the query precision of a specific query qi, j within
the general query qi are ordered by their precision values pi, j . We
shall now show the sample complexity of DT-TMP for identifying
the best query p1,1 is lesser than the sample complexity of TMP.
Note that it follows from Lemma 3.1 that p1,1 ≥ p1.

From sampling theorem [3], we know that the number of samples
from sub-optimal query qi, j needed to discern the best query q1,1
with a confidence interval of δ is O( 1
), where ϵ = p1,1 − pi, j .
TMP searches among the specific queries corresponding to all
general queries to identify the best query q1,1. Thus, TMP would have
j=1 O( 1
(cid:205)ni
a sample complexity of (cid:205)n
), where [i, j] (cid:44) [1, 1]
ϵ 2
i, j

ϵ 2 ln 2

ln 2
δ

δ

i=1
to find the best query q1,1.

On the other hand, DT-TMP is a two phase sampler. In the first
phase, it identifies the best cluster or general query. In the second
phase, it identifies the best specific query within the best chosen
general query q1 (cluster). In the second phase, DT-TMP explores
among only the specific queries corresponding to q1 to identify
q1,1. Thus, the sample complexity of DT-TMP to identify the best

specific query q1,1 is,

2

n1
(cid:213)

)

+ (

ln

n
(cid:213)

O(

i=2
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)

(cid:124)

1
(p1 − pi )2
(cid:123)(cid:122)
phase 1

δ
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)

(cid:125)

2

)

ln

1
(p1,1 − p1, j )2
(cid:123)(cid:122)
phase 2

j=2
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)
(cid:124)

δ
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)

(cid:125)

Note, that the phase two of DT-TMP matches with the best query
finding among the specific queries of query q1. However, we note
that the sample complexity for searching among the specific queries
qi, j where i (cid:44) 1 is lesser than the sample complexity involved in
finding the best clusters. Assuming that ∆pi ’s are similar (i.e., ∆pi ≈
∆pj , ∀i, j), we note that TMP would require around O((cid:205)n
sample complexity in-comparison to DT-TMP’s O( n1n

j=1 nj
(p1−pi )2 ln 2

Thus, we observe that as the number of queryable attributes n in-
creases and the attribute cardinalities of the attributes ni increases,
DT-TMP’s relative improvement over TMP increases.

δ

1

(p1−pi )2 ln 2
).

δ

))

Second, we note that when the specific clusters are shared, it
can be reduced to disjoint case by considering two sub-cases: a)
when q1,1 is a shared specific query, thus even if DT-TMP chooses
a a sub-optimal query will lead to q1,1. b) when q1,1 is not shared,
it can still be proved that the query precision of q1 is highest and
thus DT-TMP finds the optimal query. Third, when the clusters are
overlapping, it is harder to proof the efficacy of DT-TMP since the
best specific query may belong to a sub-optimal general query. We
leave the proof of overlapping case for future work.

□

4 OFFLINE EXPERIMENTS
In this section, we present experimental findings by executing dif-
ferent hidden population sampling strategies over offline real-world
datasets. First, we discuss the the real-world datasets and query
interface that allows samplers to access the entities within these
datasets. Next, we discuss the evaluation metric used to compare
the efficacy of the baseline and proposed samplers. Thereafter, we
present a brief summary of various baseline sampling strategies.
Finally, we show the results of the samplers’ performances and
interpret the results.

4.1 Datasets
Now, we present a summary of three real-world datasets used for
offline experiments along with a description of the query interface
(API).

In similarity to the offline experiments in [29], we simulate a
typical online social platform using data from three real-world en-
tity datasets. The datasets—Patent [9], Auto1, and Adult [15]—are
obtained from notably diverse domains. The datasets vary in the
number of attributes, their attributes’ cardinality and the distribu-
tion of arm sizes of the attributes (i.e. number of records across
attribute values). The local server allows us to vary the parameters
of sampling such as the result size, the attribute cardinalities and
the attribute correlation values. We query the local server using
queryable attributes and evaluate our algorithms based on the cov-
erage of the hidden population entities. Table 2 summarizes the sta-
tistics of the three datasets concerning the respective hidden target

1https://www.kaggle.com/orgesleka/used-cars-database

Conference’17, July 2017, Washington, DC, USASuhansanu Kumar, Heting Gao, Changyu Wang, Hari Sundaram, Kevin Chen-Chuan Chang

population as: patents authored by Japanese researchers, automo-
biles that have less than 40K kilometers mileage and adults who
earn more than $50K per annum. We use all queryable attributes
specified in the table for searching the corresponding hidden target
population in the datasets.

Hidden target selection. For experimental validation, we choose
the hidden property of the hidden population as the attributes that
are not expressible as a combination of one or more queryable at-
tributes. For example, the queryable attributes such as category, sub-
category and class of a patent cannot be used to search for authors
with a specific nationality (hidden property). More importantly, the
choice of hidden property for offline datasets was motivated by
real-world scenarios. We note that academic search engines such as
PubMed, Google Scholar and Microsoft Search are not searchable
using properties such as the author’s nationality and their writing
style. Similarly, mileage information is a non-queryable property
of the automobiles in the popular advertisement website Craigslist.
Lastly, income is often a hidden non-queryable property of users
in existing search interfaces of popular sites such as LinkedIn and
Angelist but can be easily inferred given their job description. In
out datasets, the target population comprises 18.73%, 5.58% and
23.93% of the population size in Patent, Auto and Adult datasets
respectively.

Patent dataset is a collection of two million patent records from
US patent records. The queryable attributes includes categorical
attributes such as category and subcategory of patents. Given that
nationality of the inventor is a hidden property, we choose the
patents that are invented by Japanese researchers as the target
entities in the dataset. Patents authored by Japanese researchers was
chosen for only illustrative reasons. We observe similar empirical
performance across samplers when the target population is set to
patents authored by researchers from other countries such as China
and India.

Auto dataset is a collection of 371,469 auto-vehicle records crawled
from Ebay-Kleinanzeigen. The set of queryable attributes allows
users to search for cars by searching over a variety of attributes
such as car type, model and their brand. For this dataset, we define
the hidden target population of automobiles by setting an arbitrary
threshold of their travel miles.

Adult dataset is a collection of 48,842 records of adults extracted
by Barry Becker from the 1994 Census database. Similar to online
social networks such as Facebook and Pokec, the users can be
searched within the entity database based on their public attributes
such as education, marital status and gender. For this dataset, we
consider income as the private or hidden attribute of an individual.
In the absence of a well-defined query interface system, we sim-
ulate the query interface in the following way. The query interface
to the datasets allows only conjunctive queries formed using the
queryable attributes listed in Table 2. For each query, the user in-
curs a unit cost in API call. The query interface returns a set of
k random results (default value of page size is set to 10 unless
otherwise stated) drawn from the query matching entities with
replacement. We observe similar empirical result across samplers
when the query interface returned k random results drawn from
the matching entities without replacement.

Table 2: Description of real-world dataset: Patent, Auto and
Adult and their respective queryable attributes with cardi-
nalities in parenthesis, and the target hidden attribute.

Dataset
Patent

Auto

Adult

Queryable attributes
category (6), subcategory (26),
assignee type (7), nclass (417)
vehicle type (9), model (252),
brand (40), fuel type (8), repair-
ing (3)
class (9), education (16), marital
status (7), occupation (15), rela-
tionship (6), sex (2)

Hidden property
inventor’s nationality

mileage

income

4.2 Evaluation
We assess the performance of a sampler by the number of distinct
entities of the hidden target population that the sampler collects
within a given query budget B. Alternative definitions include cov-
erage, query harvest rate and precision [16]. Owing to the similarity
in performance of samplers across the aforementioned evaluation
metrics, we focus on the simplest evaluation metric: recall. Formally,
recall (R) of a sampler after making budget B API calls is calculated
as follows,

R =

#(hidden target entities retrieved)
#(target entities in dataset)

= NS
ND

(2)

We observe that recall R is a very small quantity under limited
budget constraint because of the large number of ND target entities
in datasets like Patent. Since, it is possible to sample only a limited
NS number of target entities to be sampled within a limited budget,
the overall recall value across all samplers is pretty low ( NS
<<
ND
1). Therefore, we normalize the recall values by the theoretically
maximum recall attainable at a budget B which is same as getting all
target entities in every result of API call i.e. (page-size × B) unique
target entities.

All evaluation results are reported over 100 independent runs.

4.3 Baselines
We now enumerate different sampling strategies to compare against
our proposed sample.

• Uniform sampling over entire database (UNI). As evident
from the name, this sampler samples the hidden population
by repeatedly issuing the most generic query until it exhausts
the budget B. Thus, the sample obtained using this sampler
is a uniform sample over the entire population.

• Uniform query sampling from the query space or pure ex-
ploration sampling (EXP). At each time step, EXP queries the
web API by randomly sampling with replacement a single
query from all possible queries. Thus, this method performs
exploration for B rounds, and hence named as exploration
sampling or EXP.

• Thompson sampling (TMP) is a standard Thompson sam-
pler [30] where the reward from each arm and draws the
best expected arm in each draw. In other words, it is a DT-TMP
sampler without decision tree.

Mining Hidden Populations through Attributed Search

Conference’17, July 2017, Washington, DC, USA

Notice that there are 630K, 2M, 181K possible queries obtained from
the combinatorial combination of attribute-values corresponding to
the queryable attribute ((cid:206)r
i=1 di ) but only a few non-empty queries.
In our experiments, we allow the non-empty queries to be used
as the arms of baseline samplers; DT-TMP however lacks this infor-
mation. However, we assume that DT-TMP obtains Nq number of
matching entities corresponding to a query q when query is issued
as observed in real-world APIs like Google, Amazon, Facebook and
LinkedIn API. The UNI sampler that samples random entities from
the entire population performs significantly better than naive MAB
samplers; however, note that UNI is used as a theoretical baseline
and not a feasible sampler for several real-world online platforms
like Facebook, LinkedIn and Twitter. Similar to UNI, RW and LS sam-
plers are not target specific samplers. The greedy based CB suffers
from the problem of getting stuck in local high quality queries,
whereas DT-TMP by the virtue of Thompson sampling maintains an
optimal exploration-exploitation tradeoff. Decision tree based MAB
sampler (DT-TMP) significantly outperforms the second best base-
line sampler by a margin of 101.86%, 151.16% and 58.30% in Patent,
Auto and Adult dataset respectively. High recall performance of
DT-TMP is due to the fact that it exploits the hierarchical structure
of the combinatorial action space to greedily explore the attribute
combinations (query) that yield a high number of hidden target
entities.

In this section, we discussed the experimental outcomes of offline
real-world experiments. We used state-of-the-art MAB sampler
(TMP) and hidden database samplers (RW, LS and CB) as the baseline
samplers. DT-TMP is shown to perform remarkably well over all
hidden population tasks across three different datasets by exploiting
the structure in combinatorial query space. In the next section, we
observe the sampling performances on online real-world datasets.

5 ONLINE EXPERIMENTS
In this section, we deploy our different sampling strategies on
three real-world online web-query platforms—Twitter, RateMDs
and GitHub.

5.1 Twitter
Twitter is a popular micro-blogging website that allows users to
interact with each other via short messages called as “tweets”. As
of December 2017, Twitter reported an estimate of 330 million
monthly active users generate half a billion tweet everyday [32].
Given the enormous content size and the API limitations, it is
infeasible to sample the entire content. Thus, we need to design
effective sampling strategies to sieve just the relevant information
relating to the hidden population.

Twitter allows combinatorial queries for very few attributes; we
use location and hashtags as the two queryable attributes. We con-
sider the hashtags of top 10 National Football League (NFL) teams
in USA 2 as the first queryable attribute. The second queryable
attribute is the home cities corresponding to the 10 NFL teams.

Twitter REST API is used to gather tweets corresponding to all
possible combinatorial attributes (query). Since Twitter API allows
only seven days of data to be accessed, we collected all possible
queryable tweets between a fixed time frame of 6 days (26 April

2https://www.usatoday.com/sports/nfl/rankings/

Figure 5: Sampling performance of baseline and proposed
DT-TMP sampler. DT-TMP is shown to be the best sampling
strategy. Decision tree based search allows DT-TMP to explore
high yielding queries in a combinatorial query space while
simultaneously exploring-exploiting high yielding queries.
The bands indicate 95% two-sided confidence interval.

• Lazy slice cover search (LS) [29] is an optimal algorithm
for retrieving the entire entity set from the online social
platforms while minimizing the number of queries.

• Content-based search (CB) [22] is a greedy query design al-
gorithm that uses the sampled entities to construct new high
yielding queries that are unique to the hidden population us-
ing the tf-idf (term frequency inverse document frequency)
ranking.

• Random Walk (RW) [5] is an efficient algorithm for randomly
sampling from the entity database by creating queries via
random walk approach over the space of queries.

Several works in reinforcement learning literature [13] exist such
as Successive Elimination, UCB, UCT which along-with Thomp-
son sampler are known to be optimal for handling exploration-
exploitation in MABs, but we exclude them from this study since it
is not the focus of this work.

Finally, we set the epoch h of DT-TMP sampler by default to 10
for all datasets. This setting ensures that the sampler uses feedback
gained from 10m (typically 100) new observations to expand the
query pool appropriately.

4.4 Results on offline datasets
We now present a detailed description of experimental findings
obtained from experiments performed on real-world datasets.

Now, we present the performance of baseline and proposed sam-
plers under a variable query budget (ranging from 100 to 1K API
calls) on the three real-world datasets—Patent, Auto and Adult.
Figure 5 shows the recall value for different sampling strategies
across varying query budgets. We observe similar performances
of naive MAB based samplers, EXP and TMP along-with UNI. The
low performance of naive MAB based samplers is expected given
the exponential query space. The naive samplers have to explore
among 2600, 11314 and 5970 non-empty queries (queries that have
at least one matching entity in the dataset) in Patent, Auto and
Adult dataset respectively. Thus, the exponential size of the query
space causes these samplers to get stuck in the exploration phase.

2004006008001000# QUERYS ISSUED0.0020.0040.0060.0080.0100.0120.0140.0160.018RECALLPATENT2004006008001000# QUERYS ISSUED0.010.020.030.040.050.060.07AUTO2004006008001000# QUERYS ISSUED0.050.100.150.200.250.30ADULTRWTMPCBLSEXPDT-TMPConference’17, July 2017, Washington, DC, USASuhansanu Kumar, Heting Gao, Changyu Wang, Hari Sundaram, Kevin Chen-Chuan Chang

implementation of DT-TMP. This lack of information about matching
results in Twitter of a given query led us to modify the expected
reward to the fraction of target entities discovered in each API call.
Furthermore, note that the individual attributes, i.e. hashtags and
locations are the most general queries on Twitter.

Figure 6 reveals that DT-TMP is the predominant sampling strat-
egy. It outperforms the second best sampler TMP by a margin of
42.7% when the task is to sample female users. It shows similar
improvement of 39.83% and 79.24% over the second best samplers
when the hidden target population is set to users that have verified
accounts and when the target population of early Twitter adopters
respectively. Consistently superior of DT-TMP across different tasks
demonstrates the usefulness of the algorithm.

5.2 RateMDs
RateMD (https://ratemds.com) is a free healthcare website that
allows users to read and submit reviews about doctors. Accord-
ing to the website, more than 100 million potential patients use
RateMDs for information before making important healthcare de-
cisions. There are four queryable attributes—gender, specialties,
verified and patient acceptance—used to search for doctors. For
gender information, the users have two options, male and female.
For specialties, the users can specify one of the 57 specialties of
doctors including dentist, pathologist and pediatrician. For patient
acceptance, the users can restrict the result on doctors who cur-
rently accept new patients. For doctor verification, the users can
restrict the search to only doctors verified by RateMD. Each query
returns one page of 10 doctors and the user can also specify which
page to retrieve. We obtained the dataset by querying 10 pages
for each of the attribute-value combinations in August 2018. Each
doctor page is a profile consist of user ratings, credentials and
acceptable insurance.

We consider three hidden population of doctors: doctors with 5-
star rating, doctors who received more than 10 ratings, and doctors
who accept at least three insurance. The experiments are conducted
on the baseline and the proposed samplers; the results are evaluated
using the same metric as aforementioned online experiments. We
observe the superior performance of DT-TMP in Figure 7 across
different tasks. It outperforms the competition by a margin of 55.8%,
64% and 25.7% over the three different tasks. Overall the throughput
rate falls with sampling budget. Since, the number of doctors are
limited, the rate at which newer target doctors are found decreases
over time.

5.3 GitHub
GitHub is the most popular open-source version control system that
allows individuals to manage and collaborate on software-related
projects. As of April 2017, Github reported an estimate of 20 mil-
lion users and 57 million repositories [12]. Unlike Twitter, GitHub
allows a number of user attributes to query for users. We use three
queryable attributes. For the first queryable attribute, we use the
ten most popular programming languages used on GitHub 4 to
search for users using these languages in their projects. For the
second queryable attribute, we discretize the “number of followers”
attribute into three queryable ranges: ≤ 10, > 100 and otherwise.

Figure 6: Throughput rate for different sampling strategies
in Twitter. Combinatorial MAB (DT-TMP) does the best.

2018 till May 1, 2018). Note, that Twitter API 3 returns by default
of 20 tweets per API call and a maximum of 100 tweets. We vary
the result-size from 10 to 100 and observe negligible impact of the
page size on relative performance of the samplers. Further, the
API returns tweets ordered by tweet’s creation time, i.e. for a fixed
query, Twitter returns the most recent tweets as the first page and
older tweets as the subsequent pages.

We consider three hidden population sampling tasks on Twitter.
We employ properties of Twitter users that are not queryable via
Twitter API to define three hidden populations: female users, users
who have verified Twitter accounts, and early adopters of Twitter
based on the when the users created their account. We use an off-
the-shelf gender predictor [21] as our ground truth classifier for
predicting user’s gender; other two properties are available from
user profile information. Consider a sports advertiser interested in
reaching out to potential football fans who are female on Twitter.
Such an advertiser would want to maximize the coverage of female
Twitter users in their sample.

We use throughput-rate as the online sampling evaluation metric.
In the absence of information about the size of the underlying
target population, it is not possible to use recall as the evaluation
metric. In the context of hidden population sampling, we define the
throughput rate as the ratio of the number of unique target entities
sampled to theoretical maximum possible target entities that can be
sampled. Thus, the throughput rate (T R) of a sampler after making
budget B API calls is defined as,

T R =

#(hidden target entities retrieved)
B × k

(3)

where k is the page size. Note that throughput rate penalizes queries
that yield results of size less page size. For example, consider for
page size k = 20, a query q1 that returns just a set of 5 target entities
has the same throughput rate as another query q2 that returns 5
target and 15 non-target entities, since the API cost incurred by
both queries is same, and they both discover 5 target entities.

Due to API restrictions, we can implement only certain samplers
on Twitter. Since Twitter API doesn’t support uniform sampling,
UNI could not be implemented. Therefore, we compare our sampler
with five baseline sampling strategies—EXP, LS, RW, CB and TMP.
Further, non-random ranking and absence of query size restricts the

3https://developer.twitter.com/en/docs

4http://githut.info/

2004006008001000# QUERYS ISSUED0.0000.0250.0500.0750.1000.1250.1500.1750.200THROUGHPUT RATEgender=femaleRWTMPCBLSEXPDT-TMP2004006008001000# QUERYS ISSUED0.000.020.040.060.080.100.120.140.16verified=True2004006008001000# QUERYS ISSUED0.000.010.020.030.040.05creation year<= 2008Mining Hidden Populations through Attributed Search

Conference’17, July 2017, Washington, DC, USA

6.1 Why does combinatorial querying work?
We observe that querying online APIs via combination of one or
more attributes leads to higher coverage of hidden target popu-
lation than querying via individual attribute at a time. In a non-
combinatorial querying system, only one attribute can be used to
define a query. Therefore, each queryable attribute Ai contributes di
(Ai ’s cardinality) different queries to the non-combinatorial query-
ing space. Whereas, a combinatorial query space is defined by
conjunction of one or more queryable attributes. The size of com-
binatorial query space is exponential. One of the advantages of
non-combinatorial querying system over combinatorial querying
system is its limited size of query space. This facilitates existing
reinforcement learners to efficiently explore-exploit high yielding
queries in non-combinatorial query systems. However, we shall
show via DT-TMP sampler that correlation between attributes and
hierarchical structure within combinatorial query space can be
exploited to design even more efficient sampling strategies.

Furthermore, using a specific sampling scenario, we prove the ad-
vantage of using combinatorial query system over non-combinatorial
query system.

Lemma 6.1. For a sufficiently large dataset and a query sytem
defined over a uniformly distributed attribute, DT-TMP requires a
fewer number of queries to find the best query when the universal
query (‘*’) is available than TMP.

Proof. Lets consider a query system defined over a uniformly
distributed attribute with 1, 2, . . . k attribute values. Further, con-
sider that m samples are returned in a single result page for each API
call. Further assume that only m′ samples from each attribute value
is needed to discern the best attribute value at a given confidence
interval δ [8].

Thus, a naive query system would require ⌈ m′

m ⌉ API calls corre-
sponding to each attribute value to figure out the best query. Thus
the total number of API calls issued by the non-combinatorial query
system is k ⌈ m′

However, consider another query system that allows ‘*’ query.
In other words for each API call, we obtain m samples that are
drawn from any of the k attribute values. Given that the attribute
is uniformly distributed, therefore only ⌈k m′
m ⌉ expected number of
API calls are required to obtain m′ samples for each attribute value.
m ⌉, therefore a combinatorial query requires
fewer number of queries in expectation than a non-combinatorial
□
query system.

m ⌉ < k ⌈ m′

Since, ⌈k m′

m ⌉.

Figure 9 shows our proposed DT-TMP sampler that uses combi-
natorial querying system outperforms all non-combinatorial based
samplers. Owing to the efficient utilization of hierarchy in query
space, DT-TMP outperforms its competition. At a query budget of
1000, DT-TMP outperforms the best non-combinatorial query sam-
pler, TMP, by margin of 112.75%, 23.25% and 10.64% on the datasets—
Patent, Auto and Adult respectively.

Figure 10 shows that when arms of two attributes are combined
to generate a new query, it performs better than the two corre-
sponding arms that are queried disjointly. The leftmost and the
topmost sliders shows the quality of arms of individual attributes.
The left matrix is the combinatorial queries of the two attributes:
“education” and “marital status”. The right matrix is the combination

Figure 7: Throughput rate for different sampling strategies
in RateMD. Combinatorial MAB (DT-TMP) does the best.

Figure 8: Throughput rate for different sampling strategies
in Github. Combinatorial MAB (DT-TMP) does the best.

For the third queryable attribute, we discretize the number of repos-
itories of a user into two queryable ranges: ≤ 10 and > 10. Similar
to Twitter, Github returns by default a set of 20 users for each query
and 100 users at maximum. Furthermore, for a given query, GitHub
API returns a maximum possible results of 1000. We use the default
ranking of API to get the results of a query.

For the first task, we consider GitHub users whose nationality is
China as the first hidden target population. For identifying Chinese
users, we employ the location information in the users’ profile to
predict their nationality. For the next two tasks, we set hidden target
population to committed GitHub users (users who contributed to
projects on more than 50% of days in the year 2017) and users who
work or study at educational institutions (inferred by their email
address). The experiments are conducted on the baseline and the
proposed samplers; the results are evaluated using the same metric
as aforementioned online experiments.

Figure 8 reveals that DT-TMP is the best sampling strategy. It is
statistically the best sampler for the first two tasks at a confidence
interval of 95%. For the last task, since the overall number of ac-
counts declaring education affiliation is very low, the feedback is
very weak leading to similar poor performance across all task.

6 DISCUSSION
In this section, we discuss ways to improve sampling of hidden
target population by using attribute combinations for querying.
In section 6.3, we discuss limitations of our proposed approach.

2004006008001000# QUERYS ISSUED0.000.050.100.150.200.25THROUGHPUT RATEavg rating=5RWTMPCBLSEXPDT-TMP2004006008001000# QUERYS ISSUED0.10.20.30.40.50.60.70.8rating count>=102004006008001000# QUERYS ISSUED0.0000.0250.0500.0750.1000.1250.1500.1750.200# insurance accepted>=52004006008001000# QUERYS ISSUED0.000.020.040.060.080.100.120.14THROUGHPUT RATElocation=ChinaRWTMPCBLSEXPDT-TMP2004006008001000# QUERYS ISSUED0.0000.0250.0500.0750.1000.1250.1500.1750.200contributor=True2004006008001000# QUERYS ISSUED0.0000.0020.0040.0060.0080.010affliliation=education instituteConference’17, July 2017, Washington, DC, USASuhansanu Kumar, Heting Gao, Changyu Wang, Hari Sundaram, Kevin Chen-Chuan Chang

samplers. We observe that recall of DT-TMP is better than baseline
samplers by a significant factor. Furthermore, we note DT-TMP has
the second best improvement in recall value. UNI has the best im-
provement in recall value as the page size increases. This is due to
the fact that UNI avoids the over-sampling issue as discussed later.
However, it should be noted that UNI is typically not possible in
practice since it is not supported by APIs of most real-world data
sources such as Facebook, Twitter and LinkedIn.

For MAB samplers, we observe that increasing page size from
5 to 10 leads to diminishing returns, which is used to refer to the
phenomenon that the recall value increases by lesser than α% as
the page size increase by α%. The diminishing returns takes place
due to two reasons. One, at high page size, generic queries are more
likely to over-sample the same entities that are sampled by their
specific queries. Two, we observe non-uniform skewed distribution
of population over queryable attributes. Thus, non-uniform query
sizes lead to under-sampling of entities. Under-sampling of entities
refers to the scenario when the query size is less than page size,
thus forcing the API to return less than page size results.

Table 3: Percentage improvement in recall value when page
size increase from 5 to 10. UNI that samples uniformly over
the database shows an expected improvement of nearly 100%.
DT-TMP is the best performing sampler. However, we observe
the effect of diminishing results. At very high page size, all
samplers behave similarly.

Patent

Auto

Adult

Samplers

UNI
TMP
EXP

RW
LS
CB

R5
1.39E-03
4.96E-04
7.50E-04

6.13E-04
5.20E-04
2.17E-03

∆R5→10%
96.94
89.24
90.30

87.78
138.12
107.59

R5
4.02E-04
5.02E-04
3.37E-04

3.00E-04
1.91E-04
3.60E-04

∆R5→10%
93.39
58.20
49.85

22.95
72.36
147.54

R5
5.43E-02
1.92E-02
1.69E-02

1.04E-02
1.43E-02
7.89E-02

DT-TMP

5.34E-03

83.13

1.32E-03

60.47

1.22E-01

∆R5→10%
93.03
37.08
39.68

44.56
69.58
49.89

65.85

6.2.2 Effect of number of queryable attributes. We now explore
the effect of number of queryable attributes on discover-ability of
hidden target population. We try different subsets of queryable at-
tributes described in Table 2 for the offline datasets to observe this
effect. We average the results of attribute combinations (subsets)
where equal number of queryable attributes are used. Figure 11
shows the efficacy of DT-TMP over baseline samplers as the number
of queryable attributes increases. Existing samplers suffer from
high exploration space associated with large number of queryable
attributes. DT-TMP applies the decision tree based search to pref-
erentially explore high yielding queries in large query spaces. It
therefore performs significantly better than baseline samplers. How-
ever when number of queryable attributes is one, it is observed
in “auto” subplot of Figure 11 that DT-TMP performs slightly worse
than baseline samplers; for all other subplots the samplers are sta-
tistically indistinguishable at a confidence interval of 95%. This
happens because DT-TMP trades off the explore-exploit phase in
typical MABs to greedily explore new attribute combinations. It

Figure 9: Comparing the recall value of non-combinatorial
query based baseline samplers (TMP, EXP) and combinatorial
sampler (DT-TMP) in real-world datasets. Combinatorial sam-
pler outperforms all non-combinatorial sampler by 48.88%
(AUC measure) average overall datasets.

Figure 10: Comparison between combinatorial queries and
disjoint combination of queries shown via heat-map of two
attributes, “marital status” and “education”, in Adult dataset.
Darker shade represents higher quality arms.

of two arms which are queried disjointly and their quality is mea-
sured via average quality of the two corresponding arms. Observe
that the real-world arm combinations help us explore very high
quality combinatorial arms (darker high quality regions defined by
setting “education” to 9 or 10 and marital status set to 5). Notice
that such types of correlation between attributes helps recover high
yielding arms by the decision tree. However when the queryable
attributes are independent, decision tree works identical to a naive
MAB sampler.

6.2 Digging deeper: Factors affecting sampling
We now explore three prominent factors that impact hidden pop-
ulation sampling. This analysis will help users to be mindful of
different factors that may affect their hidden population sampling.

6.2.1 Effect of page size. Page size is directly proportional to the
performance of a sampler. Higher page size means larger number
of samples obtained in every API call. More samples leads to higher
recall values. Table 3 depicts the percentage improvement in recall
value as a consequence of increasing the page size across various

2004006008001000# QUERYS ISSUED0.0020.0040.0060.0080.0100.0120.0140.0160.018RECALLPATENTDT-TMPEXPTMP2004006008001000# QUERYS ISSUED0.010.020.030.040.050.060.07AUTO2004006008001000# QUERYS ISSUED0.050.100.150.200.250.30ADULT0123456789101112131415education0123456789101112131415education00123456marital statushigh quality region0.00.20.40.60.81.0Mining Hidden Populations through Attributed Search

Conference’17, July 2017, Washington, DC, USA

Figure 11: Recall value of different samplers at budget of 100
API calls. As the number of queryable attributes increases,
DT-TMP’s performance increases due to it’s flexibility in ex-
ploring over large query space. Large number of attributes
creates exponential more arms to explore for naive MAB
samplers, thereby causing a drop in their performance.

Figure 13: Recall value for different sampling strategies at
budget of 100 API calls across different shuffle rates. The
sampling performance falls with increasing shuffle rate.
The performance depicts that DT-TMP is better at learning
the correlation between hidden property and queryable at-
tributes.

number of hidden population entities and vice versa. We control
the vary between queryable attributes and hidden attributes by
randomly shuffling a fractional (shuffle ratio) subset of the dataset.
Figure 13 shows that the performance of all samplers fall as the
shuffle ratio increases. This happens because the at high shuffle
rate the hidden population entities are uniformly distributed across
different queries of the population, thus leading to poor recall values.
The relatively higher performance of DT-TMP over the baseline
samplers at even higher shuffle ratio is on account of the fact that
DT-TMP avoids re-sampling of entities.

6.3 Limitations
Now, we discuss four limitations of this work. First, our algorithms
are agnostic to the ranking function and therefore ordering of the
results. However, when the ranking function is correlated with the
hidden target attribute, agnostic samplers may not perform well.
We note that non-stationary reinforcement learners should be used
to handle the effect of non-stationary reward induced by unknown
ranking functions. Second, our algorithms rely upon a classifier for
identifying target population when the hidden target attribute is
implicit. Our future work is to discern the effect of classifier(s) in
hidden population sampling. Third, our MABs handle continuous
and infinite valued attributes by discretizing the attribute to ensure
that there is finite arms of MAB. Third, much of our work assumes
content to be static. In future, it will therefore be useful to modify
the DT-TMP sampling strategy to handle streaming datasets.

7 EXISTING WORK
In this section, we discuss various methods that are closely related
to the problem of sampling hidden population from OSNs.

Focused crawling is a well-studied problem wherein a crawler
tries to maximize the coverage of a given target topic such as “semi-
conductor related web-pages” by traversing web-links. Chakraborti
et al. [4] proposed focused crawler that iteratively explores web-
links that are more likely to fetch topic web-pages. Similar works
on crawling are focused around exploiting the information of web-
page such as it’s content link structure, URL and metadata [20, 11]

Figure 12: Recall value for different sampling strategies at
budget of 100 API calls across variable attribute cardinality.
Combinatorial MAB (DT-TMP) does increasingly better over
large attribute space created by high attribute cardinalities.

therefore performs slightly poorly compared to baseline MAB sam-
plers when the number of combinations is very few. Since UNI is
independent of attributes, we do not include it in Figures 11 and 12.

6.2.3 Effect of queryable attributes’ cardinality. Attribute cardi-
nality controls the size of query space—higher attribute cardinality
implies larger query space. We simulate the attribute cardinality
in real-world datasets by modifying the attribute cardinalities in
Table 2 to fixed number say c. For each attribute, we preserve the
top yielding c − 1 attribute-values and merge the low yielding re-
maining attribute-values into a new attribute-value. The merging
preserves the discover-ability of hidden entities in the dataset over
each attribute. We observe the effect of varying attribute cardinal-
ity in Figure 12. DT-TMP owing to it’s search tree strategy is very
effective at exploring and exploiting rewards distributed over large
query space which is induced by high cardinality attributes.

6.2.4 Effect of correlation between queryable attributes and the
hidden property. Correlation between the queryable attributes and
the hidden property is one of the most important metrics. Highly
correlated queryable attributes help form queries that yield high

1234# QUERYABLE ATTRIBUTES0.00.10.20.30.40.5NORMALIZED RECALL @ B = 100PATENT12345# QUERYABLE ATTRIBUTES0.0000.0250.0500.0750.1000.1250.1500.1750.200AUTORWTMPCBLSEXPDT-TMP123456# QUERYABLE ATTRIBUTES0.00.10.20.30.40.5ADULT101102ATTRIBUTE CARDINALITY0.00.10.20.30.40.50.60.70.8NORMALIZED RECALL @B=100PATENTRWTMPCBLSEXPDT-TMP101102ATTRIBUTE CARDINALITY0.000.050.100.150.200.25AUTO101102ATTRIBUTE CARDINALITY0.00.10.20.30.40.50.60.70.8ADULT0.00.20.40.60.81.0SHUFFLE RATIO0.00.10.20.30.40.50.60.70.8NORMALIZED RECALL @B=100PATENTRWTMPCBLSEXPDT-TMP0.00.20.40.60.81.0SHUFFLE RATIO0.0000.0250.0500.0750.1000.1250.1500.1750.200AUTO0.00.20.40.60.81.0SHUFFLE RATIO0.00.10.20.30.40.5ADULTConference’17, July 2017, Washington, DC, USASuhansanu Kumar, Heting Gao, Changyu Wang, Hari Sundaram, Kevin Chen-Chuan Chang

to efficiently crawl target pages. In contrast to the focused crawling
that uses graph based interface, our samplers use a form based
interface to iteratively query for a hidden population.

Hidden web crawling is an area of research that tries to gather
the entire population or database contents by efficiently querying
or crawling via database’s interface. Raghavan et al [25] first pro-
posed a task specific hidden web crawler called as Hidden Web
Exposer that crawled the hidden web forms by maintaining Label
Value Set table used for filling out the forms. Wu et al[33] proposed
attribute value graph traversal based heuristics to crawl the hid-
den databases. Several other works such as [34] tries to sample
hidden database entirely in fewest number of queries. Sheng et
al[29] showed optimal algorithms for crawling entire hidden web
database from form based interfaces. However, in contrast to the
previous studies in hidden web crawling that aims at discovering
the entire hidden database, our sampler is focused towards a target
hidden population. Furthermore, most of the previous works have
either been been limited to textual query interfaces or require a
prior knowledge or seed set of the well defined topic [18]. Another
limitation of existing form based interfaces is that they consider all
results pertaining to a query to be obtained in a single API query
[22, 29] which is not a realistic assumption for most web interfaces
such as GitHub and Twitter.

Query reformulation is another line of research that works at
identifying better queries for higher recall in text retrieval systems.
Existing retrieval systems in literature are predominantly designed
to search for new queries that yield higher reward [17]. Query
reformulation systems [27] typically rewrites a query to find a new
query that maximizes the number of relevant document returned.
In contrast to the query retrieval systems that retrieves documents
usually expressed by rich textual information, our work focuses
is entity retrieval problem where discovered entities provide very
limited information in form of few attributes and the query interface
is limited to queryable attributes of the entities. To the best of the
knowledge, this is the first work that aims at retrieving hidden target
entities in OSNs by querying their faceted APIs using attribute
combinations.

8 CONCLUSION AND FUTURE WORK
This paper proposed a novel algorithm for sampling hidden target
populations from online social networks. However, sampling in-
dividuals from hidden populations is hard due to API rate limits,
limited access methods (or limited number of queryable attributes)
and combinatorial query space to search from. To address these
challenges, we modeled the problem as a Multi-Armed Bandit prob-
lem. We proposed a state-aware DT-TMP that exploited structure in
combinatorial query space to discover high yielding queries. Our
proposed sampler is better than the competing samplers by fac-
tor of 0.9-1.5× on offline real-world datasets where query size is
returned by the API. Our samplers perform by margin of 54% on
Twitter hidden population tasks and 49% on RateMD experiments.
Exploring the effect of classifiers in discovering hidden populations
is the focus of our future work.

REFERENCES
[1]

S. Agrawal and N. Goyal. 2013. Further optimal regret bounds for thompson
sampling. In Artificial Intelligence and Statistics, 99–107.

[2] M. Álvarez, J. Raposo, A. Pan, F. Cacheda, F. Bellas, and V. Carneiro. 2007.
Crawling the content hidden behind web forms. In International Conference on
Computational Science and Its Applications. Springer, 322–333.

[3] O. Bousquet, S. Boucheron, and G. Lugosi. 2003. Introduction to statistical

[4]

[5]

learning theory. In Summer School on Machine Learning. Springer, 169–207.
S. Chakrabarti, M. Van den Berg, and B. Dom. 1999. Focused crawling: a new
approach to topic-specific web resource discovery. Computer networks, 31, 11,
1623–1640.
A. Dasgupta, G. Das, and H. Mannila. 2007. A random walk approach to sam-
pling hidden databases. In Proceedings of the 2007 ACM SIGMOD international
conference on Management of data. ACM, 629–640.

[6] M. De Choudhury, M. Gamon, S. Counts, and E. Horvitz. 2013. Predicting

depression via social media.

[8]

[7] M. De Choudhury, S. S. Sharma, T. Logar, W. Eekhout, and R. C. Nielsen. 2017.
Gender and cross-cultural differences in social media disclosures of mental
illness. In Proceedings of the 2017 ACM Conference on Computer Supported
Cooperative Work and Social Computing (CSCW ’17). ACM, Portland, Oregon,
USA, 353–369.
E. Even-Dar, S. Mannor, and Y. Mansour. 2002. Pac bounds for multi-armed
bandit and markov decision processes. In International Conference on Compu-
tational Learning Theory. Springer, 255–270.
B. H. Hall, A. B. Jaffe, and M. Trajtenberg. 2001. The NBER patent citation data
file: Lessons, insights and methodological tools. Tech. rep. National Bureau of
Economic Research.
D. D. Heckathorn and J. Jeffri. 2001. Finding the beat: using respondent-driven
sampling to study jazz musicians. Poetics, 28, 4, 307–329.

[9]

[10]

[11] M. Hersovici, M. Jacovi, Y. S. Maarek, D. Pelleg, M. Shtalhaim, and S. Ur. 1998.
The shark-search algorithm. an application: tailored web site mapping. Com-
puter Networks and ISDN Systems, 30, 1, 317–326.
G. Inc. 2017. Celebrating nine years of github with an anniversary sale. (2017).
L. P. Kaelbling, M. L. Littman, and A. W. Moore. 1996. Reinforcement learning:
a survey. Journal of artificial intelligence research, 4, 237–285.

[12]
[13]

[15]

[16]

[14] H. Karimi, J. Tang, and Y. Li. 2018. Toward end-to-end deception detection in
videos. In IEEE International Conference on Big Data. IEEE, 1278–1283.
R. Kohavi. [n. d.] Scaling up the accuracy of naive-bayes classifiers: a decision-
tree hybrid. In.
R. R. Larson. 2010. Introduction to information retrieval. Journal of the American
Society for Information Science and Technology, 61, 4, 852–853.
C. Li, P. Resnick, and Q. Mei. 2016. Multiple queries as bandit arms. In Proceed-
ings of the 25th ACM International on Conference on Information and Knowledge
Management. ACM, 1089–1098.
P. Liakos, A. Ntoulas, A. Labrinidis, and A. Delis. 2016. Focused crawling for
the hidden web. World Wide Web, 19, 4, 605–631.

[17]

[18]

[22]

[20]

[21]

[19] M. Malekinejad, L. G. Johnston, C. Kendall, L. R. F. S. Kerr, M. R. Rifkin, and
G. W. Rutherford. 2008. Using respondent-driven sampling methodology for hiv
biological and behavioral surveillance in international settings: a systematic
review. AIDS and Behavior, 12, 1, 105–130.
F. Menczer and R. K. Belew. 2000. Adaptive retrieval agents: internalizing local
context and scaling up to the web. Machine Learning, 39, 2, 203–242.
L. Mullen, C. Blevins, and B. Schmidt. 2015. Gender: predict gender from names
using historical data. R package version 0.5, 1.
A. Nazi, S. Thirumuruganathan, V. Hristidis, N. Zhang, and G. Das. 2015. Query-
ing hidden attributes in an online community network. In Mobile Ad Hoc and
Sensor Systems (MASS), 2015 IEEE 12th International Conference on. IEEE, 657–
662.
C. Olston, M. Najork, et al. 2010. Web crawling. Foundations and Trends® in
Information Retrieval, 4, 3, 175–246.
J. R. Quinlan. 1986. Induction of decision trees. Machine learning, 1, 1, 81–106.
S. Raghavan and H. Garcia-Molina. 2000. Crawling the hidden web. Tech. rep.
Stanford.
E. Raisi and B. Huang. 2017. Cyberbullying detection with weakly supervised
machine learning. In ASONAM. ACM, 409–416.
S. Y. Rieh et al. 2006. Analysis of multiple query reformulations on the web: the
interactive information retrieval context. Information Processing & Management,
42, 3, 751–768.

[24]
[25]

[27]

[23]

[26]

[28] D. Robinson. 2017. Introduction to empirical bayes: examples from baseball

[29]

statistics. (2017).
C. Sheng, N. Zhang, Y. Tao, and X. Jin. 2012. Optimal algorithms for crawling a
hidden database in the web. Proceedings of the VLDB Endowment, 5, 11, 1112–
1123.

[31]

[30] W. R. Thompson. 1933. On the likelihood that one unknown probability exceeds
another in view of the evidence of two samples. Biometrika, 25, 3/4, 285–294.
S. Tsugawa, Y. Kikuchi, F. Kishino, K. Nakajima, Y. Itoh, and H. Ohsaki. 2015.
Recognizing depression from twitter activity. In Proceedings of the 33rd Annual
ACM Conference on Human Factors in Computing Systems. ACM, 3187–3196.
Twitter Inc. 2018. Annual report, http://bit.ly/2LhgDEc. (2018).

[32]

Mining Hidden Populations through Attributed Search

Conference’17, July 2017, Washington, DC, USA

[33]

[34]

P. Wu, J.-R. Wen, H. Liu, and W.-Y. Ma. 2006. Query selection techniques for
efficient crawling of structured web sources. In Data Engineering, 2006. ICDE’06.
Proceedings of the 22nd International Conference on. IEEE, 47–47.
Q. Zheng, Z. Wu, X. Cheng, L. Jiang, and J. Liu. 2013. Learning to crawl deep
web. Information Systems, 38, 6, 801–819.

