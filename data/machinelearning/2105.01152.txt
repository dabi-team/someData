1
2
0
2

y
a
M
3

]
E
M

.
t
a
t
s
[

1
v
2
5
1
1
0
.
5
0
1
2
:
v
i
X
r
a

What can the millions of random treatments [...] reveal about causes?

What can the millions of random treatments in
nonexperimental data reveal about causes?

Andre F. Ribeiro
Harvard University
79 John F. Kennedy Street, Cambridge, MA USA 02138

Frank Neﬀke
Harvard University
79 John F. Kennedy Street, Cambridge, MA USA 02138

Ricardo Hausmann
Harvard University
79 John F. Kennedy Street, Cambridge, MA USA 02138

andre ribeiro@hks.harvard.edu

frank neffke@hks.harvard.edu

ricardo hausmann@hks.harvard.edu

Editor: -

Abstract

We propose a new method to estimate causal eﬀects from nonexperimental data. Each
pair of sample units is ﬁrst associated with a stochastic ’treatment’ - diﬀerences in factors
between units - and an eﬀect - a resultant outcome diﬀerence. It is then proposed that
all such pairs can be combined to provide more accurate estimates of causal eﬀects in
observational data, provided a statistical model connecting combinatorial properties of
treatments to the accuracy and unbiasedness of their eﬀects. The article introduces one
such model and a Bayesian approach to combine the O(n2) pairwise observations typically
available in nonexperimnetal data. This also leads to an interpretation of nonexperimental
datasets as incomplete, or noisy, versions of ideal factorial experimental designs.

This approach to causal eﬀect estimation has several advantages: (1) it expands the
number of observations, converting thousands of individuals into millions of observational
treatments; (2) starting with treatments closest to the experimental ideal, it identiﬁes
noncausal variables that can be ignored in the future, making estimation easier in each
subsequent iteration while departing minimally from experiment-like conditions; (3) it re-
covers individual causal eﬀects in heterogeneous populations. We evaluate the method in
simulations and the National Supported Work (NSW) program, an intensively studied pro-
gram whose eﬀects are known from randomized ﬁeld experiments. We demonstrate that the
proposed approach recovers causal eﬀects in common NSW samples, as well as in arbitrary
subpopulations and an order-of-magnitude larger supersample with the entire national pro-
gram data, outperforming Statistical, Econometrics and Machine Learning estimators in
all cases. As a tool, the approach also allows researchers to represent and visualize possible
causes, and heterogeneous subpopulations, in their samples1.

Keywords: Causal Eﬀect Estimation, Experimental Design, Signal Processing, Eﬀect
heterogeneity

1. This research was conducted in 2017/18.

1

 
 
 
 
 
 
Ribeiro, Neffke and Hausmann

1. Introduction

Most questions of interest in the social, behavioral and life sciences – What makes economies
grow? What explains criminal behavior? What can prevent or cure a disease? – are ul-
timately questions about what causes an outcome of interest. Data used to answer such
questions typically have no shortage of correlational patterns, but correlations are often
poor guides to the causal process that produced them. The central methodological diﬃ-
culty in scientiﬁc inquiry remains that of estimating the causal eﬀect of a treatment, or
independent variable, on an outcome. Compared to the tremendous success of Machine
Learning algorithms in prediction and pattern recognition tasks in correlation-rich data,
such as in face recognition and textual topic modelling, Machine Learning approaches are
still of limited use when estimating causal eﬀects (Pearl, 2019; Athey, 2017). This has led to
a paradoxical situation: in the midst of the big-data revolution, many prominent scientists
have declared randomized ﬁeld experiments - with often just hundreds of participants - as
the sole standard for empirical research (Imbens, 2010; Duﬂo et al., 2008). Experiments
are attractive because, once individuals have been randomly divided into treated and non-
treated subgroups, it suﬃces to compare their average outcomes to estimate causal eﬀects.
Yet, randomized trials have many drawbacks: they are expensive, slow and sometimes im-
possible or unethical to carry out and they elucidate only if treatments work, rather than
why they work (Deaton, 2010; Imbens, 2010; Heckman and Smith, 1995). Furthermore,
a focus on average eﬀects creates problems when diﬀerent individuals experience diﬀerent
eﬀects. Indeed, Xie (Xie, 2013) (2016, p. 6263) considers this a fundamental conundrum:
’the ubiquitous presence of individual-level variability [in social phenomena] makes it im-
possible to study individual-level causal eﬀects. To draw a causal inference, it is necessary
to pool information from diﬀerent members in a population into aggregates’. As we will
demonstrate, eﬀect heterogeneity aﬀects the accuracy of current observational methods even
in datasets of moderate size. While discourse about causes are often dominated by all-or-
nothing hypothesis testing in the Sciences, there is great practical need for tools that can
introduce causal insights into the earlier phases of scientiﬁc discovery or provide insights
from larger data. Here, we study a problem representation and method that facilitates the
use of recent Machine Learning and high-dimensional techniques to that end.

1.1 Model Summary

In particular, we consider the problem of estimating Average Treatment Eﬀects (ATE) or
Individual Treatment Eﬀects (ITE) of a given treatment on an outcome, y ∈ R. The prob-
lem of estimating the eﬀect of a treatment-of-interest nonexperimentally have been studied
extensively, in particular from comparisons between treated and non-treated subjects’ out-
comes
(Morgan, 2007; Stuart, 2010; Colson et al., 2016). Although for nonexperimental
estimation, these approaches often draw on Experimental Design concepts and have received
attention, especially, in Econometrics and Applied Statistics.

The central goal of the present work is to better understand and exploit the heterogeneity
of statistical conditions between pairs of individuals in everyday datasets, as they relate to
causality. Consider a nonexperimental dataset with n observations and m variables, from
a variable set X m. An observed diﬀerence in outcome yij = yi − yj between any two
individuals, 0 < i, j ≤ n, can carry both a lot or very little information about a variable, or

2

What can the millions of random treatments [...] reveal about causes?

variable subset, v ⊂ X m. When individuals diﬀer only by a single variable v = {a}, strict
claims can be made for the eﬀect of a, as the pairing characterizes an ideal counterfactual
(given conditions reviewed below). More commonly, however, pairwise conditions are in a
spectrum of usefulness for each variable and individual. Imagine the existence of a prior
stochastic process that can describe how individual pairwise conditions translate to the
validity of pairwise observations, yij, for each variable subset v. Such model would allow us
to use all pairs, and the full range of experiments ’run by nature’, to help estimate causal
eﬀects.

An obvious analogy is to Signal Processing and Fusion (MacKay, 2003; Hall et al., 2008),
where the use of millions of (noisy) observations often outperform any individual
observation by orders of magnitude – provided a suitable prior statistical model
for measurements. We characterize all population pairwise conditions by considering all
their possible combinations of diﬀerences and intersections. The model then connects such
combinatorial conditions to the validity of pairwise estimates. The eﬀect f (v) of variables
v is ﬁrst described as f (v) ∼ N (yij, σij(v)), which carries the assumption of Gaussian
measurements having a common mean, for each v, but distinct standard deviations σij across
pairs. In datasets below, there are in the order of 50-200M such pairs. Here, variables yij and
v are assumed observable. We relate the unobservables, f (v) and σij(v), to the asymmetric
diﬀerences of pairs under its two commutations – corresponding to the eﬀect of ’treatments’
and their observed confounders. We also show these have straight-forward interpretations
as vector angles in covariate space. Since each pair is seen as a deviation from an ideal
factorial experimental run, it becomes useful to characterize a nonexperimental dataset,
overall, as a noisy version of an ideal Factorial Experimental Design.

Using the proposed combinatorial population model, we also derive other sources of
measurement ’noise’ from the causal eﬀect estimation literature. The way we formulate
such added deviations is purposively standard, allowing us to later benchmark the proposed
approach (using all pairs) to alternatives selecting pairs or other popular estimators.
It
would be easy to add more intricate conditions, that can be formulated combinatorically,
but we show that simple conditions outperform more complex estimators. This is the case,
for example, of estimators designed to account for unobservables and endogeneity, when
replicating the outcome of the studied Randomized Experiments.

A popular recent strategy (Louizos et al., 2017; Wang and Blei, 2020; Abadie et al.,
2015) is to stipulate prior models assuming a proxy confounding variable (either observed
or unobserved) in the data. Latent-Confounder approaches require assuming and training
complex functional models to infer the latent variable, then adjusting eﬀect estimates ac-
In practice, pairs of individuals vary in how they diﬀer, and consequently in
cordingly.
what variables can confound estimates in each case. Instead of requiring a single variable to
account for this potentially complex and contingent relationship, a prior statistical model
for pairwise conditions allow estimates to be considered in a pair-by-pair case - simply
penalizing pairs, or observations yij, that are ruled unﬁt in some fundamental way.

This article’s main contribution is therefore to demonstrate the practical beneﬁts of
modeling and combining large numbers of disparate pairwise observations. Beyond practical
usefulness, understanding how population combinatorial patterns relate to causality is also
of great importance to population-based research, such as the study of genetic variation
in the Medical Sciences and demographics in the Social Sciences. We discuss implications

3

Ribeiro, Neffke and Hausmann

Figure 1: (a) for a set of population attributes X 3 = {a, b, c}, where xi ⊂ X 3 is a subset
describing individual i (resp. j) and (cid:9) is set diﬀerence, illustration for the sam-
ple balance condition xi(cid:9)xj ⊥ y | xj(cid:9)xi for a pairwise diﬀerence xi(cid:9)xj = {a}
(’treatment’) between two individuals (ij), with xj(cid:9)xi = {b, c}, (b) for a n-sized
nonexperimental sample and m factors, decomposition of the sample n(n − 1)/2
pairs into the same number of treatments (xi(cid:9)xj), matches (xi ∩ xj) and possible
confounders (xj(cid:9)xi), (c) Factorial cube C3 with factors X 3 = {a, b, c} which can
assume high and low (Boolean) values, notated +a and -a, C’s vertices corre-
spond to all possible factorial experimental runs and edges to treatments, vectors
(gray) depict 8 individuals’ positions according to a 8×3 standardized observation
matrix X, f (a) is the causal eﬀect of variable a (resp. b, c) in the proposed rep-
resentation; (d-g) representative individual pairings and their implied factorial
treatments.

4

-a-b-c+a+bxiabg) no treatmentf) treatment with obs. confounding riske) multivariatetreatmentd) univariatetreatmentf(a){+a,+b,-c}{-a,+b,+c}{+a,+b,+c}{+a,-b,-c}{-a,-b,+c}{-a,-b,-c}{-a,+b,-c}{+a,-b,+c}c)f(b)f(c)...Ο(n2) observational pairsx1Θx2x2Θx1x1∩x2xiΘxjxjΘxixi∩xjobservational treatment, match, confoundersb)(1,2)(1,3)(1,4)(i,j)(n,n)...yijxi  xjxj   xiabca)--What can the millions of random treatments [...] reveal about causes?

of concepts developed here to the study of genetic population variation, and Genome-wide
Association studies, in (Ribeiro, 2020).

1.2 Sample Balance and Treatment-Assignment Ignorability Conditions

The previous discussion leads to a simple but also very conservative model, where the risk of
(observed) confounding increases with extraneous variables between pairs. We also extend
the model to account for common, more speciﬁc, conditions from the literature, such as
reduced noise for pairs satisfying treatment-covariate sample independence conditions and
with small treatments. Let xi ⊂ X m be a set of attributes describing an individual i (resp.
j) and (cid:9) indicate (asymmetric) set-diﬀerence. The former condition, xi(cid:9)xj ⊥ y | xj(cid:9)xi,
is illustrated in Fig.1(a). In the previous model, variables xj(cid:9)xi were assumed capable of
confounding pairwise estimates, aﬀecting both the treatment and outcome at the same time.
With this added assumption, the pairs where treatment-outcome variables are independent,
conditional on non-treated variation, are now also deemed useful. Each such assumption
thus further scales the number of useful pairs. This condition is, abstractly, ’the most
developed and popular strategy for causal analysis in observational studies’ (Pearl, 2010;
It
King and Nielsen, 2019).
requires, however, a further ’ignorable treatment assignment’ assumption (Rubin, 1974;
Angrist and Krueger, 2001; Louizos et al., 2017). Namely, it requires that, conditional on
the observed variables, there are no unobserved diﬀerences between treatment and control
groups. The common way to satisfy this assumption is to include in X m any variable that
aﬀect either outcomes or treatments. This is because, theoretically at least, for any variable
set satisfying ignorability, any superset will too (VanderWeele and Shpitser, 2011). Due
to the centrality of this condition in the causal eﬀect estimation literature, and its further
required assumptions, we brieﬂy review them.

It is used by a wide range of methods across disciplines.

In randomized experiments, randomization enables unbiased estimation of treatment
eﬀects across local population groups. For each observed variable, randomization implies,
as a simple application of the law of large numbers, that any treatment-subgroups will be,
what is often called, ’balanced’ on average. Unfortunately, the assignment of treatments to
subjects is typically not random in observational datasets. Most causal eﬀect estimator in
use today attempt to reduce the treatment assignment bias, and mimic randomization, by
increasing a balance score between treatment and control units in use. The idea is to create
a subsample of sample units that received the treatment that is comparable on all observed
covariates to units that did not receive the treatment.

A balancing score b(X) is a function of the observed covariates X such that the condi-
tional distribution of X given b(X) is the same for treated and control units - thus reﬂecting
the previous assumption. There are three general approaches to derive such functions. The
ﬁrst and most trivial function is b(X) = X, which is the case of exact matching (we review
these methods in detail below). A second approach, which broadly underlie popular Propen-
sity Score and Latent-Confounder estimators, is to use dimensionality reduction techniques
to deﬁne a simpler function π(X). With this function, it is easier to balance samples,
[v ⊥ y | X] ≈ [v ⊥ y | π(X)]. On the other hand, the approach requires not only the added
assumption, but also more complex models, both statistically and computationally. With
ignorability, it has been shown analytically (Rosenbaum and Rubin, 1983) that Propensity

5

Ribeiro, Neffke and Hausmann

scores are the ’coarsest’ balancing function taking the multidimensional X into one dimen-
sion. It uses a logistic regression to calculate the probability of a unit being assigned to a
particular treatment, given X. A third approach is to use explicit, or non-parametric, bal-
ance functions. The simplest such function is a diﬀerence-of-means (i.e., between covariate
means across treated and nontreated samples). There are additional analytic advantages to
this approach (King and Nielsen, 2019) - such as, concurrently, decreasing model depen-
dence. Due to the focus on large numbers of pairwise observations, we favor this alternative.
That is, for a large number of pairs, it is undesirable to run a large number of regressions2.
The assumption of ignorability that often accompanies observational methods has been
challenged recently, such as when not all relevant variables can be included (Wang and Blei,
2020; Athey et al., 2020; Louizos et al., 2017). While sometimes calling confounders
’unobserved’, these parametric estimators assume partially-observed confound-
ing variables (whose correlations with observed variables can be exploited when training a
proxy). Beyond analytical discussions, there is however a more practical problem underlying
ignorability. Popular ATE estimation methods such as Propensity Scores are often sensitive
to inclusion of non-causal variables (A. and E., 2005; Zhao, 2008; Iacus et al., 2012). These
opposing constraints (to include as many variables as possible versus not including non-
causes) create practical diﬃculties for researchers and threaten the validity of observational
estimates - especially in datasets with many variables. Addressing selection bias is essential
to identify extraneous eﬀects of other causes on the treatment-of-interest, but does not ad-
dress the second problem. Conducting model selection and eﬀect estimation in a common
(Chernozhukov et al., 2015).
framework is a promising direction to rule out non-causes
Because of the use of pairwise outcome diﬀerences, yij, we argue it is natural to translate
these two problems into distance metric learning problems. The approach leads, as a result,
to a data representation that is more easily interpretable by researchers, reﬂecting Factorial
Experimental Designs. Other immediate advantages of the approach are discussed below.

1.3 Reproducing Eﬀect Estimates from Large Randomized Experiments

We assess the proposed method’s performance in simulations and a seminal real-world exam-
ple, comparing it to current Statistics, Econometrics and Machine Learning estimators. We
demonstrate that the proposed approach also remain accurate in heterogeneous and diverse
samples. The simulations introduce confounders and heterogeneous subpopulations into
synthetic data, demonstrating that observational methods generally become biased or inac-
curate, unlike the proposed. As real-world application, we consider the National Supported
Work (NSW) program. Starting with a seminal contribution by Lalonde (Lalonde, 1986),
studies have used this Randomized Control Trial to benchmark nonexperimental techniques
- including an historical ’face-oﬀ between regression and propensity-score matching’ (An-
grist, 2009). Observational methods generally fail to recover the experimental causal eﬀect
estimate, except in a smaller handpicked NSW subsample (A. and E., 2005; Dehejia and
Wahba, 1999; Zhao, 2006; Colson et al., 2016). This literature exemplify a typical sce-
nario across disciplines: estimating causal eﬀects nonexperimentally require several (hard

2. We would also mention that we experimented with other alternatives, such as HSIC tests and Distance
Correlations (Sejdinovic et al., 2013), while results with these alternatives are comparable to those used
in reported results, we favor explicit balance scores due to their computational eﬃciency and very natural
interpretation in the geometrical framework formulated below.

6

What can the millions of random treatments [...] reveal about causes?

to justify) population and variable selection assumptions (in this case, expert selection of
samples and variables with desirable economic characteristics). We demonstrate, however,
that the proposed approach can recover the NSW experimental eﬀects not only in Lalonde’s
original unsolved challenge (with 740 participants and 6 variables) but also in the full NSW
data with over 10000 participants and 1000 variables, without ex ante assumptions from
researchers.

We compare the approach to a range of previous solutions, including those making typi-
cal ignorability assumptions, as well as approaches relaxing other assumptions, such as miss-
ing variables and endogeneity. We show that the previous simple model outperform these
solutions, when trying to reproduce the results of the previous Randomized Experiment.
Our initial goal was to address the common case of large datasets with many variables.
Perhaps surprisingly, however, this is also the case for samples with very few variables,
where Instrument-based and Latent-Confounder approaches should be most relevant.

2. Stochastic Factorial Estimation (SFE)

We ﬁrst introduce the proposed approach, then review the related literature in
further detail. Randomized Controlled Trials (RCTs), and the observational estimators
they have inspired (Rubin, 1974), often focus on the causal eﬀect of a single treatment or
intervention. However, observed outcomes are often the result of many interacting causes.
This limitation of RCTs had already been noted by Fisher in 1926: ’No aphorism is more
frequently repeated in connection with ﬁeld trials, than that we must ask Nature few ques-
tions, or, ideally, one question, at a time.’
(Fisher, 1927) (1926, p. 503) Instead, he
proposed submitting Nature ’logical and carefully thought out questionnaire[s]’, leading to
factorial experimental designs. Factorial designs have since been mostly studied for the
design or analysis of experiments (Dasgupta et al., 2015).

A factorial experiment is a complex experiment consisting of many runs. It is designed
to estimate the causal eﬀect of m factors on an outcome of interest y. When factors are
binary, the design contains 2m factorial runs, or, possible factor combinations. Fig.1(c)
depicts geometrically a 3-factor design with a cube C : {-1, +1}3. We call the set of factors
in which two runs diﬀer a factorial treatment. A factorial run corresponds to C’s vertices and
treatments to edges. We consider all individuals in a nonexperimental dataset as stochastic
factorial runs and the entire dataset as an incomplete random factorial design. Critically,
the full set of observed factorial treatments express necessary combinatorial patterns of
variable variation and ﬁxation necessary to make claims about each variable’s piecewise
eﬀects on y.

We consider this geometric representation for the nonexperimental causal eﬀect estima-
tion problem next, then discuss a Bayesian procedure that combine eﬀect estimates from
each pair of individuals, given how strongly they depart from ideal factorial treatments. We
call the resulting method Stochastic Factorial Estimation (SFE).

2.1 Geometric Representation

Consider a Factorial Experiment studying the eﬀects of a set of factors X m = {a, b, c, ...}.
The experiment’s runs are the vertices of the cube C(X )m : {-1, +1}m. Factorial treatments
are pairs of runs that diﬀer on a set of factors (the ’treatment’), while having all other

7

Ribeiro, Neffke and Hausmann

factors in common. Namely, let xi, xj ∈ Cm be runs and their corresponding treatment
be the set of factors run i has exclusively, xi(cid:9)xj. In addition, we let the size of C’s edges
correspond to the causal eﬀect, f (xi(cid:9)xj), of their associated treatment. We discuss an
extension to the continuous variables case in Appendix B.

Consider now an observational matrix X with variables X m. Fig.1(c) depicts an example
with n=8 individuals and m=3 variables, where values have been normalized to the unit
interval, X : [-1, +1]m. The O(n2) pairs of individuals are in a myriad of conﬁgurations.
As a result, diﬀerent pairs are useful for estimating eﬀects of diﬀerent variables. Fig.1(d)
illustrates a pair corresponding to a factorial treatment with {a} as treatment. The pair
captures the main intuition behind factorial designs: a single variable, a, diﬀers between
individuals while all other variables are ﬁxed. Fig.1(e) depicts another factorial treatment.
Here, however, the treatment is multivariate, {a, b}. Because the treatment consists of
two potential causes, it is impossible to infer their separate eﬀects from the pair alone.
However, we can still learn about their combined eﬀect. Fig.1(f) shows an imperfect factorial
treatment. There, the outcome diﬀerence is not necessarily due to variables in the treatment
and may reﬂect extraneous variation from other variables. Although not ﬁxed within the
pair, these nontreated variables could coincide in expectation across treated and non-treated
individuals - i.e., they could be ’balanced’ in the sample. We can also learn from pairs in
this case. Finally, Fig.1(g) illustrates a pair without treatment. We disregard such cases in
the estimation.

We will use observed factorial treatments like the ones depicted in Fig.1(d-g) to iter-
atively transform X, such that distances between individuals come to represent expected
treatment eﬀects on y,

Ty(X m) =






xi ∈ Rm : |xi − xj|2 = py(xi, xj)f (xi(cid:9)xj), ∀ 0 < i, j ≤ n.



,


(1)

where Ty(X) is a map [-1, +1]m → Rm, xi (in bold) is the transformed position for
individual i, py(xi, xj) is the probability that the pairing of i and j reproduces the factorial
treatment v=xi(cid:9)xj, and, f (v) is the treatment’s eﬀect. The use of factorial treatments leads
to an estimator for outcome diﬀerences yij as distances in Ty(X m). We discuss py(xi, xj)
and the resulting stochastic model next.

2.2 Stochastic Model and Assumptions

Let 0 < i, j ≤ n be any two individuals and g(x), h(x) be two functionals over x. We do not
postulate a model that relates an individual’s characteristics to her outcomes, yi = g(xi)+(cid:15).
Instead, we interpret yij = yi − yj as a noisy observation of the true causal eﬀect of observed
factor diﬀerences, xi(cid:9)xj. Noise increases as xi(cid:9)xj departs from factorial, balanced and
univariate treatments. Such departure is described by a distribution py(xi, xj). That is, we

8

What can the millions of random treatments [...] reveal about causes?

interpret diﬀerences in characteristics between a pair of individuals, xi(cid:9)xj, as ‘treatment’
diﬀerences that cause diﬀerences in outcomes yij = yi−yj,

yij ∼ g(xi(cid:9)xj) + (cid:15)ij,

(cid:15)ij ∼ N (0, h(xj(cid:9)xi)),

(2)

where (cid:15)ij is a Gaussian noise with mean 0 and variance σ2 = h(xj(cid:9)xi). Eq. (2) pos-
tulates that (cid:15)ij reﬂects distortions in observed eﬀects yij due to variables that individual
j, alone, has. We will say that, when (cid:15)ij = 0, pairwise observations correspond to facto-
rial treatments: pairwise observations with little risk of observed confounding. Or, simi-
larly, that each observational pair, xi(cid:9)xj, in the sample represents a factorial treatment,
v=xi(cid:9)xj, with probability py(xi, xj).

A ﬁrst way to estimate eﬀects f (v) is to focus on pairs that approximate a given factorial
treatment v with near certainty: py(v) → 1. The deﬁning characteristic for this type of
pair is that, when estimating the eﬀect for an individual i, the other individual j has no ob-
served extraneous factors that could confound the eﬀect yij, xj(cid:9)xi = ∅. This is the ﬁrst key
condition behind Factorial experimentation. In this ﬁrst condition, the experimenter keeps
all relevant conditions ﬁxed, except for a treatment. Since factors can, however, be beyond
the experimenter’s control, a second condition is popular: randomize treatment assignment
such that subpopulations are balanced in expectation in the treated and nontreated sub-
samples. Nonexperimental methods using balancing scores are often seen as attempting
to reproduce randomized conditions from nonexperimental data (Rosenbaum and Rubin,
1983; King and Nielsen, 2019).

In Econometrics

Randomization is essentially a mechanism to address selection bias. For a treatment
indicator d ∈ {−1, +1}, selection biases appear when the treatment d is not indepen-
dent either of other factors, X, or the outcome, y.
(Heckman, 1979),
when p(d|X, y) = p(d) it is said, under ignorability, that the sample is not subject to se-
lection bias. Computational approaches sometimes make a distinction between covariate,
p(d|X) = p(d), and outcome, p(d|y) = p(d), induced bias. These distinctions are discussed
in detail in (Zadrozny, 2004; Fan and Davidson, 2007). In Propensity scores or Latent-
Confounders based approaches, treated and untreated individuals with the same π(X) are
expected to have similar distributions across any observed baseline covariates - reproducing
a randomization experimental procedure. This is often used as diagnostic for their outputs.
The former approach is mature and has been studied extensively, both theoretically and
practically. There are serious questions as to whether the previous goal can typically be
achieved in practice, and whether these methods’ assumptions, in fact, hold (King and
Nielsen, 2019; A. and E., 2005). Instead of estimating a parametric model π(X) for a given
treatment, we calculate explicit balance scores for all O(n2) pairwise treatments (univariate
or multivariate), with simple matrix operations. The calculation is repeated thousands of
times in a Bayesian optimization procedure that progressively estimate treatment eﬀects.
The approach thus uses ’weak’ but numerous balancing scores. This reﬂects its alternative
Signal Processing perspective, as opposed to the more typical, based on Model Inference.
In the present framework, the notion of sample balance thus leads to an observational pair’s
balance, φbl
ij = 0] denote the probability that

ij = p(xi(cid:9)xj) − p(xi(cid:9)xj|xj(cid:9)xi). We let p[φbl

9

Ribeiro, Neffke and Hausmann

the observational pair (ij) is not subject to covariate induced bias, in which case it can also
be used to estimate eﬀects. This is given a simple geometrical interpretation below.

The implicit goal of causal eﬀect estimation is to devise eﬀect estimates with high
external validity. It is worth considering the impact of multivariate treatments on external
validity. Multivariate treatment eﬀects estimate the simultaneous eﬀects of all variables in
the treatment, xi(cid:9)xj. Eﬀects need not generalize to the 2|xi(cid:9)xj | diﬀerent instantiations of
the treated variables. Under multivariate treatment conditions, it is impossible to attribute
eﬀects to any single cause. As a consequence, the cardinality of a treatment, |xi(cid:9)xj|, is
inversely related to the external validity of the derived eﬀect estimates. The notion leads to
the pairs’ treatment size, φcx
ij = 1] denote the probability that the
the observational pair (ij) has a univariate treatment, indicating the propensity for higher
external validity.

ij = |xi(cid:9)xj|. We let p[φcx

2.3 Optimization

ij = 1] and p[φbl

We consider that py(xi, xj) → 1 when conditions p[φcx
ij = 0] are fulﬁlled
by stipulating Bayesian priors for: sizes of factorial treatments, xi(cid:9)xj, and balance of
non-factorial variations, xj(cid:9)xi. This Bayesian formulation leads to an objective function
Γ(xi) over individual positions xi that we later minimize. The overall procedure transforms
pairwise distances |xi−xj| in X to reﬂect observed outcome diﬀerences, yij, according to the
smallest and most balanced factorial treatments. Appendix A contains a detailed derivation
of Γ(xi) from eq.(2), similar to those underlying LASSO and Ridge-Regressions (Hastie,
2001). The objective has the form

Γ(xi) = min
xi

n
(cid:88)

(1 + φcx

ij )[(cid:104)xi, xj(cid:105) + |yij|]2 + φbl

ij(cid:104)xi, xj(cid:105)2,

,

(3)

j=1
|xi + xj|
m
n
(cid:88)

k=0

ˆφcx
ij =

ˆφbl
ij = |

1
n

(cid:104)xk, xi + xj(cid:105)|,

ij and φbl

where (cid:104)., .(cid:105) is the dot-product, φcx

ij are treatment size and balance estimates.
When both φij terms are zero and (cid:104)xi, xj(cid:105) is negative, the pair corresponds to a factorial
treatment, Fig.1(d-g), and the residual (cid:104)xi, xj(cid:105) + |yij| is minimized. Term φbl
ij penalizes
unbalanced non-factorial treatments, Fig.1(f), and the consequent risk of confounded es-
timates (given the discussed assumptions). Term φcx
ij penalizes multivariate treatments,
Fig.1(e), and the consequent risk of low external validity. The estimators used in the Ex-
perimental section, ˆφcx
ij, are simple treatment size and balance estimators derived
directly from the previous geometrical representation (Appendix A).

ij and ˆφbl

In the output space, Ty(X), the ATE of any factor a can be calculated simply as the
diﬀerence in coordinates a between the mean position of all individuals with factor a, ¯x+a,
and those without, ¯x-a,

ATE(a) =(cid:112)|¯x+a − ¯x-a|(a),

(4)

10

What can the millions of random treatments [...] reveal about causes?

for any a and where ¯x ∈ Ty(X). That is, in Ty(X) coordinate diﬀerences correspond
to treatment eﬀects and distances to outcome diﬀerences (the squared-sum of treatment
eﬀects). Since each factor a with non-zero eﬀects divides a population in two subpopulations,
(+a, -a), the method’s output also gives researchers means to represent and visualize relevant
subpopulations in their samples.

2.4 Related Work

In the Sciences, problems of integrating noisy diagnostic measurements are sometimes called
‘Inverse problems’. Tikhonov regularization approaches, such as Ridge and LASSO regres-
sions, are popular solutions to inverse problems. They perform both variable selection and
regularization in order to enhance the prediction accuracy and interpretability of the sta-
tistical models they put forward to explain observations. Regularized inverse problems can
be seen as special cases of Bayesian inference (Tarantola, 2005). We devise a solution on
this framework, using well-known Bayesian interpretations of the previous solutions.

Diﬀerent disciplines can diﬀer in how they approach causality, with the two most popular
frameworks (Morgan, 2007) identiﬁed as the Pearl (Pearl, 2000) and Rubin (Rubin, 1974)
frameworks. Due to focus on Experimental Design concepts and pairwise comparisons,
we review Rubin’s framework, also known as the counterfactual (or potential outcomes)
formulation. We do not wish to disregard, however, the critical contributions of other
frameworks, and the solutions developed under them.

Consider a treatment indicator variable d ∈ {-1, +1} and that a treated individual i has
i ∈ R. The individual treatment eﬀect of d, ITEi(d), is deﬁned as the

observed outcome y+d
counterfactual outcome diﬀerence,

ITEi(d) = y+d

i −y-d
i

.

(5)

According to the counterfactual framework, it is impossible to observe the outcome that
individual i would have had in the counterfactual situation where she would not have been
treated, y-d
. A Randomized Controlled Trial (RCT) solves this problem with the help of an
i
homogeneity assumption: since the treatment is administered at random, the nontreated
subpopulation’s outcome serves, in expectation, as a counterfactual outcome for the treated
subpopulation. The manipulation allows researchers to calculate average treatment eﬀects
easily,

ATE(d) = E[y+d]−E[y-d].

(6)

Nonexperimental approaches, in contrast, often require researchers to specify a data

generating process (DGP) for the observed data. A DGP speciﬁes at least:

- a causal model describing how the treatment aﬀects the outcome variable, as well as

how other potential causes may confound the treatment’s eﬀect;

- a population in which this model holds.

This approach puts, however, ’the cart before the horse’: most research is undertaken
because the DGP is poorly understood. We address this problem by combining insights
from nonexperimental causal eﬀect estimation and model selection.

11

Ribeiro, Neffke and Hausmann

Experimental Designs (ED) prescribe conditions, to be veriﬁed, or manipulated, by
researchers, under which outcome diﬀerences, yij=yi−yj, are true causal eﬀects. We con-
sidered two commonplace ED conditions. In the ﬁrst, the experimenter keeps all relevant
conditions ﬁxed, except for a treatment. This is the distinguishing strategy of Factorial
experimentation. In the second, researchers try to maintain population representativeness
in their samples. This is the central strategy underlying Randomized experimentation.
(Imai et al., 2008) and balance-
These two conditions inspired the development of exact
based matching estimators (Heckman, 1979; Rubin, 1974; Diamond and Sekhon, 2012) in
observational analysis,

ATE(d) = E[yi−yj], iﬀ xi(cid:9)xj={d}
ATE(d) = E[yi−yj], iﬀ xi(cid:9)xj={d} & y ⊥ {d} | X −d

(exact)

(balance−based)

(7)

These estimators try to ﬁnd pairs fulﬁlling the previous conditions for a treatment-of-
interest, typically, a variable d. They have been used across disciplines
(Stuart, 2010;
Colson et al., 2016) such as statistics (Rubin and Stuart, 2006), epidemiology (Brookhart
et al., 2006), sociology (Morgan and Harding, 2006), economics (Abadie and Imbens, 2006)
and political science (Ho et al., 2007).

We deﬁned a combinatorial-based model for random treatments, eq.(2), which can be
used to combine large numbers of pairwise observations. Using pairwise comparisons, SFE
is related to matching estimators (Rubin, 1974; Stuart, 2010) but diﬀerent in two important
ways. Factorial treatments, eq.(2), are more speciﬁc statistical entities than matches. The
approach articulates statistical roles for all possible combinatorial conditions appearing in
pairings, such as when there are extraneous varying variables, xj(cid:9)xi, as well as multivariate
treatments, xi(cid:9)xj. The formulation of a random treatment model enables the use of all
available treatments and treatment types (such as multivariate treatments) in datasets.
To that end, we decomposed all sample pairs into three components: xi(cid:9)xj (treatment),
xi ∩ xj (match), xj(cid:9)xi (possible confounders). Fig.1(b) illustrates the decomposition. The
decomposition leads to a simple geometrical interpretation of observational pairs and a
density py(xi, xj) that indicates pairs’ departure from ideal factorial treatments: univariate
treatments with no observed confounders (Appendix A discusses this geometric connection
in further detail, as well as density versions for categorical and continuous variables).

This leads to a second important diﬀerence. The decomposition allows the method to
autonomously reduce the input data dimensionality. A Bayesian procedure ﬁrst estimates
the eﬀects of treatments xi(cid:9)xj with largest py(xi, xj), which simpliﬁes the estimation of
eﬀects for the remaining treatments, and repeats. Estimation is progressively simpliﬁed
because variables without any signiﬁcant eﬀect on y can be ignored in each step, relaxing
the conditions-to-be-fulﬁlled for the remaining variables (such as the penalties, φij, for
sample balance and treatment sizes). This is an eﬀective strategy because, contrary to
matching assumptions, treatments in nonexperimental data are overwhelmingly multivariate
or have negligible eﬀects on outcomes. While not directly about the treatment-of-interest,
each observational treatment provides some information about which variables have any
signiﬁcant eﬀect on y and which do not. In the Experimental section, we consider both
(Colson et al.,
traditional and iterative extensions to balance-based matching methods
2016; van Der Laan J. et al., 2007; Diamond and Sekhon, 2012), as well as other recent

12

What can the millions of random treatments [...] reveal about causes?

Econometrics (Chernozhukov et al., 2015) and Machine Learning methods (Louizos et al.,
2017; van Der Laan J. et al., 2007).

Whereas matching estimators typically focus on the causal eﬀect of a single variable,
this considers that, somewhat counter-intuitively, the problem of estimating the eﬀect of
one causal variable can become easier once we try to estimate the eﬀect of all causes.
This is due to the curse of dimensionality from which matching estimators suﬀer. Initially
estimating the eﬀects only of (sets of) variables that are closest to experimental conditions,
allows us to ignore variables estimated as having negligible eﬀects in future iterations,
progressively lowering the dimensionality of the matching process. The output of this
process, Ty(X), represents eﬀects analogously to factorial designs. The previous model,
eq.(2), and objective, eq.(3), combine eﬀect estimation and model selection within
the standard framework of sparcity-based model selection (e.g., LASSO, Unbiased-
LASSO, Ridge regressions) (Appendix A).

Notice that because diﬀerences yij are estimated (as opposed to a functional for y con-
ditional on X), eq.
(2), the approach does not require i.i.d. assumptions on subjects.
The assumption of i.i.d. observations, although common in Machine Learning, can bias
estimates for models that stipulate a functional relationship between factors and output,
y ∼ g(X). This is because, if any two groups are misrepresented in a sample, average
outcome diﬀerences (i..e., eﬀects) will consequently reﬂect such biases in selection. Opti-
mization is, instead, used here to combine pairwise observations under a simple Bayesian
rationale and learn distances, eq. (1). This is a central advantage of pairwise observational
estimators (Stuart, 2010). The approach can, on the other hand, be potentially sensitive to
unobserved pairwise diﬀerences, leading, in the present interpretation, to incomplete facto-
rial designs. This is however ameliorated by learning from multi-variate treatments, which
are overwhelmingly common in everyday datasets. We consider next how practical the
presented approach can be in common conditions, compared to pairwise and non-pairwise
solutions.

3. Results

3.1 Simulation

We ﬁrst test SFE in synthetic datasets. The design is similar to previous studies (A. and
E., 2005; Athey and Imbens, 2016). In the ﬁrst simulations, the treatment eﬀect is homoge-
neous. Each of 3 subpopulations are, however, randomly underrepresented in the treatment.
Fig.2(a) shows the DGP in graphical-model notation and Fig.2(b) Average Treatment Ef-
fects (ATE) and their Mean Squared Errors (MSE) from several popular methods, which
includes all methods in (Colson et al., 2016) plus 5 methods making use of Machine Learning
(super-learner,genetic,latent,instrument,sfe), Distance Metric Learning (genetic,latent,sfe)
and high-dimensional Econometric (instrument) techniques3. The counterfactual outcomes
y+treat and y-treat for each individual and ITEi(treat) = y+treat−y-treat are known. In this
setting, all methods recover the ground-truth (dashed line) with little bias. SFE has, how-
ever, the smallest MSE, even below the ground-truth’s MSE, illustrating the advantage of
using many pairs.

3. see (Colson et al., 2016) for further algorithmic details.

13

Ribeiro, Neffke and Hausmann

Figure 2: Montecarlo simulations.

(a) A priori Data-Generating Process (DGP) in
graphical-model notation (gray variables are observed), population of 1000 in-
dividuals with 3 disjoint subpopulations type = {a, b, c} with sizes 600, 300, and
100, treat is a treatment indicator and y an outcome; (b) Average treatment eﬀect
(ATE) and Mean Squared Error (MSE, error bars) estimates from 1,000 simu-
lations under observational conditions using several methods (columns), ground-
truth is dotted, eﬀects drawn from a Gaussian with mean and standard deviation
0.5 for all subpopulations, treatment propensities for each subpopulation drawn
from a uniform distribution over [0.2, 0.5], methods are: propensity-score match-
ing (ps), propensity-score with inverse probability of treatment weighting (ps-
iptw ), mahalanobis covariate matching (mahab) with 1-4 neighbor matchings,
optimal matching (optimal ), ordinary least-squares (ols), genetic balance opti-
mization (genetic)
(Diamond and Sekhon, 2012), SuperLearner ensembles (su-
perlearner ) (van Der Laan J. et al., 2007; Colson et al., 2016), high-dimensional
(Chernozhukov et al., 2015; Belloni et al.,
instrument selection (instrument)
2014), latent causal variables deep-learning (latent)
(Louizos et al., 2017) and
stochastic factorial estimation (sfe), using eq.(4); (c) simulations under heteroge-
neous conditions, eﬀects drawn from Gaussians with mean 1.0 for subpopulation
b and 0 for c (both with standard deviation 0.5); (d) avg. factor ATE for simula-
tions with 10 subpopulations (unitary eﬀects) and increasingly complete samples
γ/210 in respect to pairwise diﬀerences (γ is the number of random sampled C10
edges, horizontal axis), (e) DGP with added ut variables (plate) that are increas-
ingly correlated with y; (f ) ATE estimates for simulations under confounding,
heterogeneous and endogenous conditions, 1 ≤ t ≤ 10.

14

0.250.500.751.00ground-truthgeneticmahab−1:1mahab−1:2mahab−1:3mahab−1:4olsoptimalpsps−iptwsuper−learnersfe (this*)c)0.250.500.751.00bacytreaty | treat=1  ~ Gaussian(0.5, 0.5)treat | type ~ 0.5 - Uniform(0,0.3 | type){a)b)y | a=1, treat=1 ~ Gaussian(0.5, 0.5)y | b=1, treat=1 ~ Gaussian(1, 0.5)y | c=1, treat=1 ~ Gaussian(0, 0.5) plot(b)plot(c)ATEATE0.40.60.812345678910tATEytreaty | treat = 0   ~ Gaussian(0, 0.5)y | treat = 1   ~ Gaussian(0.5, 0.5)treat | type   ~ 0.5 - Uniform(0,0.3 | type)e)y | b=1, treat = 1  ~ Gaussian(1, 0.5)y | c=1, treat = 1  ~ Gaussian(0, 0.5)ut  ~  corr(y, ut) = 1-1/t utf)1234ground-truthgeneticmahab−1:1mahab−1:2mahab−1:3mahab−1:4olsoptimalpsps−iptwsuper−learnersfe (this*)instrumental1148,113-62,107                 2               3               4               5               6                                8               9               10             11              171213bacy | treat=0  ~ Gaussian(0, 0.5)latentinstrumentallatent141               2               3               4               5               6               7               8               9             10             11            12             13            14120.800.850.900.010.050.10.150.20.250.30.350.40.45incompleteness, γ / 210ATEd)114102-78,913 125678910111213147 What can the millions of random treatments [...] reveal about causes?

Figure 3: (a) Factorial subspace {b, c, treat} of Ty(X) for the simulations in Fig.2(b), pluses
(+) show the (average) positions of treated and nontreated subpopulations, the
AT E corresponds to coordinate diﬀerences between these subpopulations on the
treat axis; (b) subspace {b, treat}, treated individuals in green, nontreated in
red, diagonal axis indicates the variables’ combined eﬀect, the ATE is an aggre-
gation of individual eﬀects, distances (solid lines) and their projections, δij and
δkl, illustrate individual treatment eﬀects for two example pairs: pair (ij) with
both individuals in subpopulation b, with +b and distinct treat, and (kl) with
individuals not in b, with −b and distinct treat.

15

−0.8−0.6−0.4−0.2 0.0 0.2 0.4 0.6 0.8−0.8−0.6−0.4−0.2 0.0 0.2 0.4 0.6 0.8−0.8−0.6−0.4−0.2 0.0 0.2 0.4 0.6{+b,+c,+treat}{-b,+c,+treat}{+b,-c,+treat}{+b,+c,-treat}{+b,-c,-treat}type ctype btreat{-b,-c,+treat}{-b,+c,-treat}{-b,-c,-treat}−0.50.00.5−0.50.00.5type btreat{+b,+treat}{-b,+treat}{+b,-treat}{-b,-treat}treatednoyes0.000.250.500.751.00yATE+b+b-b-ba)b)δijδkl(ij)(kl)Ribeiro, Neffke and Hausmann

In the next simulations, we assume that subpopulations respond diﬀerently to the treat-
ment. Subpopulation b observes double the expected eﬀect, whereas c is immune. The
resulting heterogeneity introduces signiﬁcant biases in most estimates, Fig.2(c). Whereas
most estimators become increasingly inaccurate as populations become more diverse, SFE
continues to provide accurate and unbiased ATE estimates.

Fig.2(d) shows simulations with 10 subpopulations and samples that are decreasingly
incomplete (i.e., approaching a Factorial Design). At each instant, a number γ of the 210
hypercube edges C10 is sampled uniformly without replacement. Treatment propensities
are as before and eﬀects are unitary. The ﬁgure shows mean AT E estimates across factors
(vertical axis) with increasing γ/210 (horizontal axis). The ﬁgure demonstrates that while
the central assumption in the present work is factorial incompleteness, the assumption, in
fact, impact other methods more severely. Making such assumptions explicit is, we
believe, one of the proposed representation’s strengths.

Fig.3(a) illustrates SFE’s factorial representation. It shows a 3D subspace of the esti-
mated space Ty(X). Dots show individuals’ positions and their outcomes (colors). Spatial
diﬀerences in Ty(X) reﬂect diﬀerences in outcomes y. The AT E corresponds to diﬀerences
in the treat coordinate between treated and nontreated subpopulations, eq.(4). Results
demonstrate that SFE achieves lower MSE in homogeneous synthetic samples and can re-
cover unbiased individual eﬀects under heterogeneity.

3.2 National Supported Work (NSW) Program

We now consider a real-world application: the NSW employment program (details in the
Appendix B), where eligible applicants were randomized into treatment and control groups.
In his seminal article (Lalonde, 1986), Lalonde selected a subsample of the NSW partic-
ipants and replaced its nontreated subgroup with samples from national surveys, leading
to 6 distinct datasets. By doing so, he ’unbalanced’ the NSW data (i.e., subpopulations’
treatment propensities) - previously balanced by the NSW’s experimental design. Lalonde
then showed that observational methods failed to recover the experimental eﬀect, a ﬁnd-
ing corroborated by later authors
(Zhao, 2006; A. and E., 2005). Subsequent research
(Dehejia and Wahba, 2002, 1999; Zhao, 2006) showed, however, that in a more restricted
sample (henceforth the ’DW’ subsample) covariate matching and other methods recover
the experimental eﬀect. This small sample continues to be used to this day (Colson et al.,
2016).

Fig.4(a) shows ATE estimates calculated by diﬀerent methods (columns), using Lalonde’s
variables and sample restrictions, as well as the experimental (dashed line). Each dot is an
estimate in one Lalonde sample. As in Lalonde’s study, methods struggle to recover the
NSW eﬀect. In contrast, SFE estimates are consistently close to the experimental eﬀect -
within U$37, well inside the experimental 95% conﬁdence interval.

ATEs neglect that the NSW eﬀect may diﬀer across subpopulations. Fig.4(b) shows
experimental eﬀects for several subpopulations. Far from homogeneous, the program’s eﬀect
was particularly large for older, married and relatively educated workers. Fig.4(c) shows
that, unlike other methods, SFE estimates these heterogeneous eﬀects with negligible bias
in all subsamples.

16

What can the millions of random treatments [...] reveal about causes?

Figure 4: (a) Lalonde (Lalonde, 1986) reproduction, estimated AT E for the National Sup-
ported Work (NSW) program with diﬀerent methods (columns) over the 6 control
surrogates drawn by Lalonde (dots), the dotted line shows the experimental esti-
mate, variables as in (Lalonde, 1986): y is the worker’s real post-program annual
earnings (in 1981 dollars), X variables are workers’ age, years of schooling, wage
before entering the program, treatment status, race indicators (African-American,
Hispanic) and whether the worker holds a high-school degree; (b) experimental
eﬀects of subpopulations (columns) in blocked samples (and their resulting sam-
ple sizes n); (c) estimated eﬀects (diﬀerence from experimental, in dollars) for
subpopulations (columns) according to each method, note that existing meth-
ods require 12 separate estimations, SFE represents subpopulations explicitly,
making subpopulation-speciﬁc eﬀects available from Ty(X), eq.(4), without re-
estimation; SFE estimates are closer to the ground-truth in both the Lalonde
sample population and blocked subsamples.

17

−200002000−200002000ps−200002000ps−iptw−200002000mahab−1:1−200002000mahab−1:2−200002000−200002000mahab−1:4−200002000optimal−200002000super−learner−200002000genetic−200002000sfe (this*)−5000500100015002000age<24(n= 408 )age>=24(n= 314 )african-am. (n= 578 )degree(n= 159 )education<10(n= 368 )education>=10(n= 354 )hispanic(n= 76 )married (n= 117 )not african-am. (n= 144 )no degree(n= 563 )not hispanic(n= 646 )not married (n= 605 )−5000500100015002000experimentalgeneticmahab−1:1mahab−1:2mahab−1:3mahab−1:4olsoptimalpsps−iptwsuper−learnerinstrumentalage<24(n= 408 )age>=24(n= 314 )african-am. (n= 578 )degree(n= 159 )education<10(n= 368 )education>=10(n= 354 )hispanic(n= 76 )married (n= 117 )not african-am. (n= 144 )no degree(n= 563 )not hispanic(n= 646 )not married (n= 605 )(a)(b)(c)difference toexperimental ($)ATE ($)ATE ($)olsmahab−1:3latentsfe (this*)−200002000latent−200002000instrumentalRibeiro, Neffke and Hausmann

Figure 5: (a) ATE diﬀerence from experimental groundtruth (in dollars) using Lalonde’s
expert DGP and progressively fewer ex ante assumptions from previous studies
(Lalonde, 1986; Dehejia and Wahba, 1999; Zhao, 2006; Colson et al., 2016), lead-
ing to the full NSW dataset (rightmost) with 1231 variables, 1923 treated and
8001 non-treated individuals; estimates become progressively harder for most
approaches as sample restrictions are loosened with the exception of SFE; (b)
ATE estimates with an automatically devised DGP (Appendix B details the
procedure), yielding a DGP with variables: worker’s work-ethic, race (African-
American), previous school attendance, previous work, alcoholic drink consump-
tion and location (New York city); all methods perform well throughout all sam-
ples using the DGP devised with SFE.

3.2.1 Unknown or Unconsidered causes

Both Lalonde and Dehejia and Whaba restricted the sample population and model variables.
Fig.5(a) shows results in 4 nested subsamples: DW, Lalonde, all males in the NSW and,
ﬁnally, the full NSW dataset. This ﬁgure uses variables Lalonde picked based on his expert
judgment. All methods perform well in the DW sample. However, their performance
degrades as sample restrictions are relaxed. Fig.5(a) and Fig.4(c) suggest that SFE, in
contrast, can estimate eﬀects in heterogeneous populations, relieving the need for population
selection. Can SFE also help determine which variables to include as causes? Fig.5(b)
show estimates with variables selected by SFE from the 1232 NSW variables (selection
procedure details in the Appendix B). Using this alternative set of 5 variables improves SFE
performance. More surprisingly, it also improves other estimators. Using these variables,
all observational methods approach the ground-truth (matching methods, in particular),
even as sample restrictions are removed. This suggests that the autonomously identiﬁed
DGP approximates the true DGP more closely than the one derived from expert judgment.
But why did all observational methods perform well in the DW sample? To explain
this, Fig.6(a) plots individuals’ coordinates on the two variables with the highest ATEs in a

18

Dehejia and Wahba (DW)LalondeAll-malesNSW0500100015002000n. treated21,143,4,95-8,10,110100020003000400050000500100015002000n. treateddifference from experimental ($)23-91210111,14ground-trutholspsps−iptwmahab−1:1mahab−1:2mahab−1:3mahab−1:4optimalsuper−learnergeneticinstrumental12a)b)3456789101112Dehejia and Wahba (DW)LalondeAll-malesNSWlatentsfe (this*)131413What can the millions of random treatments [...] reveal about causes?

Figure 6: (a) Subspace of Ty(X) consisting of two variables (ranking of attended college and
work-ethics) versus outcome y (wages), variables selected after running SFE on
a matched NSW-National survey (Appendix B describes the procedure, dataset
has 441 variables, 8001 individuals), survey respondents are blue and individuals
in the Dehejia and Wahba (DW) sample are red; (b) illustration of diminishing
exponential returns across subpopulations and the area of concentration of the
DW sample (small cube); (c) (δi − ¯δ)2 histogram for treated individuals in DW,
Lalonde and the full NSW experimental samples, δi are before-after individual
outcome diﬀerences, 0 < i ≤ n, and ¯δ their mean in each sample; results illustrate
how the DW sample contains a highly homogeneous subpopulation.

19

−0.8−0.6−0.4−0.2 0.0 0.2 0.4 0.6 0.80.00.20.40.60.81.0−1.0−0.5 0.0 0.5 1.0work ethicscollegerankingy−1.0−0.5 0.0 0.5 1.00.00.20.40.60.81.0−1.0−0.5 0.0 0.5 1.0ya)b)DW NSW subsampleNational survey (Panel Study of Income Dynamics 1975)01002003000e+001e+082e+083e+084e+08(δi - δ)2countNSW sampleFullLalondeDWc)Ribeiro, Neffke and Hausmann

NSW-National Survey matched dataset: work-ethics and college ranking. It illustrates how
wages increase exponentially with college ranking, while, at the same time, this relation
varies with individuals’ work-ethic. The ﬁgure shows in red the matched DW subsample.
This suggests that the reason why observational methods recover eﬀects in the DW sample
with apparent ease is that this subsample consist of individuals with high eﬀect homogeneity.

3.3 Discussion

Which DGP was selected by SFE? Table 1 in the Appendix B lists the 20 variables with the
largest eﬀects against 20 selected by a traditional model-selection algorithm, a regularized
(LASSO) regression. The two lists are very diﬀerent. Among the variables selected by
a LASSO are alimony money received, unemployment in past two years, money received
from training, money from social security. Several of these reﬂect consequences, or just
components, of an individual’s income. In contrast, the top variables selected by SFE are
work-ethics, race (African-American), NSW treatment, recent school attendance and recent
employment. All these variables are arguably connected to causes of income diﬀerences such
as education, work attitudes and discrimination.

These results suggest that SFE may also shed light on the direction of causation. To ex-
plore this further, we revisit the earlier simulations, adding variables that are consequences,
not causes, of the outcome variable. We progressively add 10 variables ut, 0 < t ≤ 10,
which are increasingly correlated with y, with expected Pearson correlations 1 − 1
t . Fig.2(e)
shows the expanded graphical-model and Fig.2(f) ATE estimates. For most methods, even
a small numbers of consequences signiﬁcantly biases estimates. In contrast, SFE estimates
remain unbiased.

We introduced SFE in this article, a computational tool for nonexperimental causal
eﬀect estimation which we compared to several estimators from the Statistics and Machine
Learning literature. SFE allows researchers to represent nonexperimental data as incomplete
factorial designs, eq.(1). We have shown that, as result, it can recover the ground-truth in
synthetic data and in Lalonde’s seminal setting - estimating causal eﬀects with less bias and
error than alternatives. We have also shown eﬀect estimates at the individual level and in
the entire nationwide NSW program, not relying on ex ante model and population selection
criteria, outperforming estimates that used expert speciﬁcations. A more abstract goal was
to demonstrate that the troves of data on pairwise treatments and confounders in common
nonexperimental data can be very useful when estimating causal eﬀects. Many ﬁelds, from
Medicine to the Social Sciences, face new realities where historical data is increasingly
accessible and new data is constantly accumulating. The tool could enable new uses for
such data in scientiﬁc investigation.

References

J. S. A. and P. T. E. Does matching overcome lalonde’s critique of nonexperimental esti-
mators? Journal of Econometrics, 125(1):305–353, 2005. doi: 10.1016/j.jeconom.2004.
04.011.

A. Abadie and G. W. Imbens. Large sample properties of matching estimators for average
treatment eﬀects. Econometrica, 74(1):235–267, 2006. doi: 10.1111/j.1468-0262.2006.

20

What can the millions of random treatments [...] reveal about causes?

00655.x.

A. Abadie, A. Diamond, and J. Hainmueller. Comparative politics and the synthetic control
method. American Journal of Political Science, 59(2):495–510, 2015. doi: 10.1111/ajps.
12116.

J. D. Angrist. Mostly harmless econometrics :an empiricist’s companion. Princeton Uni-

versity Press, Princeton, 2009. ISBN 1-282-60809-6.

J. D. Angrist and A. B. Krueger. Instrumental variables and the search for identiﬁcation:
From supply and demand to natural experiments. Journal of Economic Perspectives, 15
(4):69–85, 2001. ISSN 0895-3309.

S. Athey. Beyond prediction: Using big data for policy problems. Science, 355(6324):
ISSN 0036-8075. doi: 10.1126/science.aal4321. URL http://science.

483–485, 2017.
sciencemag.org/content/355/6324/483.

S. Athey and G. Imbens. Recursive partitioning for heterogeneous causal eﬀects. Proceedings
ISSN 0027-8424. doi:

of the National Academy of Sciences, 113(27):7353–7360, 2016.
10.1073/pnas.1510489113. URL http://www.pnas.org/content/113/27/7353.

S. Athey, G. W. Imbens, and M. Pollmann. Comment on: ”the blessings of multiple causes”
by yixin wang and david m. blei. Journal of the American Statistical Association, 114
(528):1602–1604, 2020. doi: 10.1080/01621459.2019.1691008.

A. Belloni, V. Chernozhukov, and C. Hansen. Inference on treatment eﬀects after selection
among high-dimensional controls. Review of economic studies, 81(2):608–608, 2014. ISSN
0034-6527. URL http://search.proquest.com/docview/1761476969/.

M. A. Brookhart, S. Schneeweiss, K. J. Rothman, R. J. Glynn, J. Avorn, and T. Strmer.
Variable selection for propensity score models. American Journal of Epidemiology, 163
(12):1149–1156, 2006. ISSN 0002-9262.

N. Bshouty and C. Tamon. On the fourier spectrum of monotone functions. Journal of the

ACM (JACM), 43(4):747–770, 1996. ISSN 0004-5411.

V. Chernozhukov, C. Hansen, and M. Spindler. Post-selection and post-regularization infer-
ence in linear models with many controls and instruments †. American Economic Review,
105(5):486–490, 2015. ISSN 0002-8282.

K. E. Colson, K. E. Rudolph, S. C. Zimmerman, D. E. Goin, E. A. Stuart, D. L. M. Van, and
J. Ahern. Optimizing matching and analysis combinations for estimating causal eﬀects.
Nature Scientiﬁc Reports, 6(1), 2016. doi: 10.1038/srep23222.

T. Dasgupta, N. S. Pillai, and D. B. Rubin. Causal inference from 2k factorial designs by
using potential outcomes. Journal of the Royal Statistical Society: Series B (Statistical
Methodology), 77(4):727–753, 2015. ISSN 1369-7412.

A. Deaton.

Instruments, randomization, and learning about development. Journal of
Economic Literature, 48(2):424–55, June 2010. doi: 10.1257/jel.48.2.424. URL http:
//www.aeaweb.org/articles?id=10.1257/jel.48.2.424.

21

Ribeiro, Neffke and Hausmann

R. Dehejia and S. Wahba. Causal eﬀects in nonexperimental studies: Reevaluating the
evaluation of training programs. Journal of the American Statistical Association, 94:
1053, 1999.

R. H. Dehejia and S. Wahba. Propensity score-matching methods for nonexperimental
causal studies. Review of Economics and Statistics, 84(1):151–161, 2002. doi: 10.1162/
003465302317331982.

A. Diamond and J. S. Sekhon. Genetic matching for estimating causal eﬀects: A general
multivariate matching method for achieving balance in observational studies. The Review
of Economics and Statistics, 95(3):932–945, 2018/08/20 2012. doi: 10.1162/REST{\ }
a{\ }00318. URL https://doi.org/10.1162/REST a 00318.

E. Duﬂo, R. Glennerster, and M. Kremer. Using Randomization in Development Economics
Research: A Toolkit, volume 4 of Handbook of Development Economics, chapter 61, pages
3895–3962. Elsevier, January 2008. URL https://ideas.repec.org/h/eee/devchp/5-61.
html.

W. Fan and I. Davidson. On sample selection bias and its eﬃcient correction via model
averaging and unlabeled examples. Society for Industrial and Applied Mathematics. Pro-
ceedings of the SIAM International Conference on Data Mining, page 320, 2007.

M. Figueiredo. Adaptive sparseness for supervised learning. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 25(9):1150–1159, 2003. ISSN 0162-8828. URL http:
//search.proquest.com/docview/28255537/.

R. Fisher. Arrangement of ﬁeld experiments. Agricultural Journal of India, 22, 1927. URL

http://search.proquest.com/docview/1311589889/.

M. Furst, J. Jackson, and S. Smith. Improved learning of ac0 functions. In Annual Work-
shop on Computational Learning Theory: Proceedings of the fourth annual workshop on
Computational learning theory; 05-07 Aug. 1991, pages 317–325, 1991. ISBN 1558602135.
URL http://search.proquest.com/docview/31297843/.

D. L. D. L. Hall, M. E. Liggins, and J. Llinas. Handbook of multisensor data fusion :theory
and practice. CRC Press, Boca Raton, Florida, 2008. ISBN 1-351-83537-8; 1-315-21948-4;
1-281-77445-6; 9786611774455; 1-4200-5309-4.

T. Hastie. The Elements of Statistical Learning : Data Mining, Inference, and Prediction.
Springer Series in Statistics. Springer New York : Springer, New York, NY, 2001. ISBN
9780387216065.

J. J. Heckman. Sample selection bias as a speciﬁcation error. Econometrica, 47(1):153–161,

1979. ISSN 00129682.

J. J. Heckman and J. A. Smith. Assessing the case for social experiments. Journal of

Economic Perspectives, 9(2):85–110, 1995. doi: 10.1257/jep.9.2.85.

J. J. Heckman, H. Ichimura, and P. Todd. Matching as an econometric evaluation estimator.

Review of Economic Studies, 65(2):261–294, 1998. doi: 10.1111/1467-937X.00044.

22

What can the millions of random treatments [...] reveal about causes?

D. E. Ho, K. Imai, G. King, and E. A. Stuart. Matching as nonparametric preprocessing
for reducing model dependence in parametric causal inference. Political Analysis, 15(3):
199–236, 2007. ISSN 1047-1987.

S. M. Iacus, G. King, and G. Porro. Causal inference without balance checking: Coarsened

exact matching. Political Analysis, 20(1):1–24, 2012. doi: 10.1093/pan/mpr013.

K. Imai, G. King, and E. Stuart. Misunderstandings between experimentalists and obser-

vationalists about causal inference. 171(2), 2008. ISSN 0964-1998.

G. W. Imbens. Better late than nothing: Some comments on deaton (2009) and heckman
and urzua (2009). Journal of Economic Literature, 48(2):399–423, June 2010. doi: 10.
1257/jel.48.2.399. URL http://www.aeaweb.org/articles?id=10.1257/jel.48.2.399.

J. Kiefer and J. Wolfowitz. Stochastic estimation of the maximum of a regression func-
tion. The Annals of Mathematical Statistics, 23(3):462–466, 1952. doi: 10.1214/aoms/
1177729392.

G. King and R. Nielsen. Why propensity scores should not be used for matching. Political

analysis, 27(4):435–454, 2019. doi: 10.1017/pan.2019.11.

R. J. Lalonde. Evaluating the econometric evaluations of training programs with experi-

mental data. The American Economic Review, 76(4):604–620, 1986.

Y. Lecun, Y. Bengio, and G. Hinton. Deep learning. Nature, 521(7553):436–444, 2015. doi:

10.1038/nature14539.

C. Louizos, U. Shalit, J. M. Mooij, D. Sontag, R. Zemel, and M. Welling. Causal eﬀect infer-
ence with deep latent-variable models. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach,
R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information
Processing Systems 30, pages 6446–6456. Curran Associates, Inc., 2017. URL http://
papers.nips.cc/paper/7223-causal-eﬀect-inference-with-deep-latent-variable-models.pdf.

D. J. C. MacKay.

Information theory, inference, and learning algorithms. Cambridge
University Press, Cambridge, UK; New York, 2003. ISBN 0521642981; 9780521642989;
0521644445; 9780521644440.

V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare, A. Graves,
M. Riedmiller, A. K. Fidjeland, G. Ostrovski, S. Petersen, C. Beattie, A. Sadik,
I. Antonoglou, H. King, D. Kumaran, D. Wierstra, S. Legg, and D. Hassabis. Human-
level control through deep reinforcement learning. Nature, 518(7540):529, 2015. doi:
10.1038/nature14236.

S. Morgan and D. Harding. Matching estimators of causal eﬀects: Prospects and pitfalls in
theory and practice. Sociological Methods and Research, 35(1):3–60, 2006. ISSN 00491241.
URL http://search.proquest.com/docview/208058495/.

S. L. S. L. Morgan. Counterfactuals and causal inference : methods and principles for social
research. New York, 2007. ISBN 9780521856157. Includes bibliographical references (p.
291-316) and index.; ID: http://id.lib.harvard.edu/aleph/010910135/catalog.

23

Ribeiro, Neffke and Hausmann

J. Pearl. Causality : models, reasoning, and inference. Cambridge, U.K. ; New York,
2000. ISBN 0521773628. Includes bibliographical references (p. 359-373) and indexes.;
ID: http://id.lib.harvard.edu/aleph/008372583/catalog.

J. Pearl. 3. the foundations of causal inference. Sociological Methodology, 40(1):75–149,
2020/06/25 2010. doi: 10.1111/j.1467-9531.2010.01228.x. URL https://doi.org/10.1111/
j.1467-9531.2010.01228.x.

J. Pearl. The seven tools of causal inference, with reﬂections on machine learning. Com-

munications of the ACM, 62(3):54–60, 2019. ISSN 00010782.

A. Ribeiro. An experimental-design perspective on population genetic variation. Proceedings

of the National Academy of Sciences (PNAS) (Under Review), 2020.

P. R. Rosenbaum and D. B. Rubin. The central role of the propensity score in observational
studies for causal eﬀects. Biometrika, 70(1):41–55, 1983. doi: 10.1093/biomet/70.1.41.

D. B. Rubin. Estimating causal eﬀects of treatments in randomized and nonrandomized
studies. Journal of educational psychology, 66(5):688–701, 1974. doi: 10.1037/h0037350.

D. B. Rubin and E. A. Stuart. Aﬃnely invariant matching methods with discriminant
mixtures of proportional ellipsoidally symmetric distributions. The Annals of Statistics,
34(4):1814–1826, 2006. ISSN 00905364.

D. Sejdinovic, B. Sriperumbudur, A. Gretton, and K. Fukumizu. Equivalence of distance-
based and rkhs-based statistics in hypothesis testing. The Annals of Statistics, 41(5):
2263–2291, 2013. doi: 10.1214/13-AOS1140.

R. A. Servedio. On learning monotone dnf under product distributions. Information and

Computation, 193(1):57–74, 2004. ISSN 0890-5401.

E. A. Stuart. Matching methods for causal inference: A review and a look forward. Sta-
tistical science : a review journal of the Institute of Mathematical Statistics, 25(1), 2010.
ISSN 0883-4237.

A. Tarantola. Inverse problem theory and methods for model paramenter estimation. Society
for Industrial and Applied Mathematics, Philadelphia, PA, 2005. ISBN 0898715725.

M. van Der Laan J., E. C. Polley, and A. E. Hubbard. Super learner. Statistical applications

in genetics and molecular biology, 6:Article25, 2007.

T. J. VanderWeele and I. Shpitser. A new criterion for confounder selection. Biometrics,
67(4):1406–1413, 12 2011. doi: 10.1111/j.1541-0420.2011.01619.x. URL https://pubmed.
ncbi.nlm.nih.gov/21627630.

Y. Wang and D. M. Blei. The blessings of multiple causes. Journal of the American
Statistical Association, 114(528):1574–1596, 2020. doi: 10.1080/01621459.2019.1686987.

Y. Xie. Population heterogeneity and causal inference. Proceedings of the National Academy

of Sciences, 110(16):6262, 2013. doi: 10.1073/pnas.1303102110.

24

What can the millions of random treatments [...] reveal about causes?

B. Zadrozny. Learning and evaluating classiﬁers under sample selection bias.

In ACM
International Conference Proceeding Series; Vol. 69: Proceedings of the twenty-ﬁrst in-
ternational conference on Machine learning; 04-08 July 2004, volume 69, 2004. ISBN
1581138285. URL http://search.proquest.com/docview/31264458/.

Z. Zhao. Matching estimators and the data from the national supported work demonstration

again. Bonn, Germany, 2006.

Z. Zhao. Sensitivity of propensity score methods to the speciﬁcations. Economics Letters,

98(3):309–319, 2008. doi: 10.1016/j.econlet.2007.05.010.

25

Ribeiro, Neffke and Hausmann

Figure 7: example vector pair and the relationship among its dot-product, vector sum and
vector diﬀerence, as well as, functionals - g(x) and h(x) - and outcome pairwise
diﬀerences, yij.

Appendix A. Objective Function

In this section, we devise eq.(3) for binary observed variables. We consider an extension for
continuous variables in Sect.B.

A.1 Treatment Likelihood

Let’s ﬁrst deﬁne requirements for a pair of individuals (ij) to represent an univariate treat-
ment {a} with certainty, a ∈ X m. A ﬁrst requirement relates to the treated variable a
itself4. The requirement is that xi(a) · ¬xj(a) = 1, where ¬ and · are the boolean NOT and
AND operators and 1 is a m-sized vector with all +1 values. A second requirement relates
to other variables, b (cid:54)= a. The requirement is that these variables are either also treated,
xi(b) · ¬xj(b) = 1, or common, xi(b) · xj(b) = 1, between i and j.

With these requirements, we will deﬁne individuals’ positions, xi, as random obser-
vations of factorial runs. The norm of vectors, |xi| and |xj|, relate to the likelihood of
treatment and angles, θij, to observed confounding conditions among pairs of individuals.
Their dot-product, (cid:104)xi, xj(cid:105) = |xi||xj| cos θij, will reﬂect both factors and become a key
element in the optimization.

Before formulating this relationship in detail, reconsider eq.(2). Let g(x) = max(0, x)
which makes nonpositive coordinates in x zero5. We can decompose an individual pair
into vectors for their diﬀerence, xi−xj, and sum, xi+xj. Due to the sign convention, the
ﬁrst contains treated coordinates and the second non-treated coordinates. The dot-product
relates the sum of the two vectors geometrically when g(x)=h(x). According to eq.(2), this
corresponds to the assumption that the variance is proportional to the expected eﬀect of
non-treated variables, i.e., the expected amount of confounding. The relationship leads to
a general least-squares solution (considered in further detail below), where we minimize

4. for short, we use x to refer to both Boolean vectors and set variables (i.e., the set of variables with value

+1).

5. this function is often called a rectiﬁer and is currently the most popular activation function in deep

neural networks.

26

xixj|g(xi-xj)| - yij|h(xi+xj)|What can the millions of random treatments [...] reveal about causes?

Figure 8: Representative pairings of individuals (leftmost column) and their related dot-
product (middle column) and treatments as Venn diagrams (rightmost column):
(a) univariate individual-level treatment with no observed confounding risk; (b)
multivariate treatment with no confounding risk; (c) univariate treatment with
confounding risk, (d) no treatment.

a residual, yij − |g(xi−xj)|, and a penalty, |h(xj+xj)|. Notice that |g(xi−xj)| is also a
distance. Fig.7 sketches the (distance) residual and cost for an example pair. Letting
x(cid:48) = g(x), the Law of Cosines leads to

(cid:16)

yij − |x(cid:48)

(cid:17)
i − x(cid:48)
j|

+ |x(cid:48)

i + x(cid:48)

j|,

(cid:16)

=

yij − |x(cid:48)
+ |x(cid:48)
= yij + 4(cid:104)x(cid:48)

i|2 − |x(cid:48)

(cid:17)
i, x(cid:48)
j(cid:105)

i|2 + 2(cid:104)x(cid:48)
i, x(cid:48)

j(cid:105),

i|2 + |x(cid:48)
i|2 + 2(cid:104)x(cid:48)
i, x(cid:48)
j(cid:105),

(8)

Let’s then deﬁne the probability py(xi, xj) and its relation to the dot-product in further
detail. We deﬁned a variable a ∈ X m as being under a factorial treatment when a vari-
able is treated and all other variables are either common or also treated. Fig.8(a-d) (3rd
column) depicts these conditions as Venn diagrams for the cases in Fig.1 (main article).
The dot-product in the 2m-dimensional Boolean vector space (Furst et al., 1991) has the
interpretation

(cid:104)zi, zj(cid:105) =

1
2m

m
(cid:88)

a=1

zi(a)zj(a) = EU [zi · zj]

(9)

27

api(a=0)pj(a=1)≈1.0certainly varyingvariables(treatment)certainly not varyingvariablespi(a=1)pj(a=1)or pi(a=0)pj(a=0)≈1.0aba)b)c)d)= -1-1 <               < +1= +1babababRibeiro, Neffke and Hausmann

where z ∈ {-1, +1}m and the expectation is taken uniformly over all a ∈ X . The dot-
product indicates the expected number of common variables between vectors. It also deﬁnes
the (cid:96)2-norm |z| = (cid:112)(cid:104)z, z(cid:105) = (cid:112)EU [z2]. We consider, instead,

(cid:104)zi, ¬zj(cid:105) = EU [zi · ¬zj],

(10)

which indicates the expected number of treated variables between vectors, when X
variables are uniformly distributed (notated U ). Non-uniform distributions and continuous
treatments are considered in Sect.B. Due to the {-1, +1} sign convention, the product in
the standardized covariate space X leads to the relation

EU [xi · ¬xj] =

(cid:40)

−(cid:104)xi, xj(cid:105),
0,

if (cid:104)xi, xj(cid:105) ≤ 0
otherwise

.

(11)

When (cid:104)xi, xj(cid:105) = −1, the probability of drawing a treated variable when comparing i
and j is 1.0 - i.e., xi · ¬xj= + 1, ∀a ∈ X . We also associate the pair with a treatment size,
ij , and a possible confounding risk in relation to the remaining n−2 individuals, φbl
φcx
ij. We
consider these in a Bayesian framework next.

A.2 Sample Balance and optimization

We now turn to conditions φij. We will represent these conditions geometrically, while,
at the same time, relating them to the density py(xi, xj). Eq.(2) implies the following
likelihood over expected eﬀects6:

(cid:89)

i,j

N [yij | py(xi, xj)f (xi(cid:9)xj), h(xj(cid:9)xi)].

(12)

To consider also learning from pairs with balanced treatments, we introduce a Gaussian
prior N (xi(cid:9)xj |0, φbl
ij is a strictly positive scalar
If not a factorial treatment, the probability that the pair represents the
for each pair.
treatment xi(cid:9)xj depends on the likelihood that non-common factors in the pair (2-sample)
are balanced in the remainder of the sample.

ij) for the probability py(xi, xj), where φbl

Combining the likelihood in eq.(12) with the Gaussian prior, we obtain

(cid:89)

i,j

N [yij | py(xi, xj)f (xi(cid:9)xj), φcx

ij ] × N [xi(cid:9)xj | 0, φbl
ij],

(13)

where φcx

ij = h(xi(cid:9)xj) is the pair’s variance. This formulates Bayesian priors for condi-

tions φij from eq.(2) in a way similar to a Tikhonov regularization (Figueiredo, 2003).

6. The typical likelihood notation N [y|µ, σ2], for an observation y with mean µ and variance σ2, is used.

28

What can the millions of random treatments [...] reveal about causes?

Considering a single position xi and treatment v, our goal is to transform xi such that
|xi − xj|2 = py(xi, xj)f (xi(cid:9)xj) for 0 < j ≤ n. Combining likelihoods in eq.(13) and eq.(11),
taking logarithms and dropping constants we arrive at the objective

Γ(xi) = min
xi

n
(cid:88)

(1 + ˆφcx

ij )[(cid:104)xi, xj(cid:105) + yij]2 + ˆφbl

ij(cid:104)xi, xj(cid:105)2 + bi,

,

(14)

j=1
|xi + xj|
m
n
(cid:88)

ˆφcx
ij =

ˆφbl
ij = |

1
n

(cid:104)xk, xi + xj(cid:105)|,

k=0
yij = max(0, yi − yj).

We consider the overall objective function ﬁrst, then pairwise penalties estimates, no-
tated ˆφij, followed by the intercept bi and outcome diﬀerences yij. If we minimize eq.(14)
with respect to the m-sized vector xi we get a maximum a-posteriori likelihood estimate for
individuals’ positions. The objective function argument is an individual’s position xi (rows-
pace vectors) and not factor positions (column space vectors). More speciﬁcally, eq.(14)
leads to an iterative gradient minimization procedure for each individual, xt+1
i),
with η as learning rate and xt=0
i = xi. Considering the entire sample population, we itera-
tively minimize their gradient sum, (cid:80)
i − Γ(xt
i)]. Both Statistics and Machine Learning
researchers have considered the problem of minimizing an objective function in the form of
a sum of gradients. We use a Stochastic Gradient Descent (SGD) (Kiefer and Wolfowitz,
1952) which samples a subset of summand functions at every step and has found wide-
spread use in Machine Learning (Mnih et al., 2015; Lecun et al., 2015). The scheme allows
us to consider billions of observation pairs when estimating eﬀects. We discuss other im-
plementation details in Sect.B.2. The resulting optimization transforms the original space
X into Ty(X). It transforms treatment vector diﬀerences, until they reﬂect diﬀerence in
outcomes that approximate, according to the deﬁned costs, those that would be observed
in factorial experiments.

i = xt

i−ηΓ(xt

i[xt

Eq.(14) deﬁnes yij as nonnegative outcome diﬀerences. The scalar term bi is an individ-
ual’s intercept with expected zero mean that is also minimized. Terms ˆφbl
ij reﬂect
diﬀerence-of-means balance and treatment size conditions for pairs of individuals i and j.
Pairs with both zero penalties (balanced and univariate treatments) reproduce, according
to the previous assumptions, factorial or randomized treatments. In this case, (cid:104)xi, xj(cid:105) is
made to reﬂect yij.

ij and ˆφcx

Calculations will run over thousands of iterations for large observation matrices X.
Therefore, it is important to deﬁne simple penalties φij. We deﬁned treatments by dividing
pairs’ variables into treated and common variable subsets. With the [-1, +1] sign convention,
the vector xi +xj has non-zero values for non-treated variables. In eq.(14), the penalty ˆφcx
ij is
therefore a normalized estimate for the number of non-treated variables. Non-treated (i.e.,
non-zero) coordinates in xi + xj can confound outcome eﬀect observations, yij, Fig.7(c). We
did not deem pairs under these conditions as necessarily unsuitable for estimation. Instead,
we considered that the pair has coordinates that need to be balanced in individuals k that do
not belong to the pair, k (cid:54)= i, j. For an out-of-pair individual k, (cid:104)xk, xi+xj(cid:105) is the projection

29

Ribeiro, Neffke and Hausmann

of that individual’s vector xk onto xi+xj. The penalty ˆφbl
ij is a sum of such projections from
all other n − 2 individuals (signed, due to the same convention). Orthogonal vectors have
null projections, and, balanced vector-sets have null sums.

Appendix B. Supporting Material

B.1 Continuous Treatments

We can also use the previous method with continuous variables, when it is assumed that
there is uncertainty over the intensity of treatments. This can be carried out either by
extending py(xi, xj) directly or by considering a third Bayesian factor for treatment inten-
sity in eq.(12) (together with treatment balance and size). We consider the former.
In
Computational Learning Theory, a product distribution (Servedio, 2004; Bshouty and Ta-
mon, 1996) is a distribution over {0, 1}m which generalizes the relationship in eq.(9) to the
non-uniform case. We deﬁne a distribution

Dij =

(cid:89)

pj(+a)

(cid:89)

pj(-a),

pi(+a)≤pi(-a)

pi(+a)>pi(-a)

(15)

where pi(+a) is the probability that individual i has factor a and pi(-a) that he doesn’t,
a ∈ X . The ﬁrst therefore indicates certainty of positive treatment status and the second
of negative. Any continuous value in between corresponds to individuals with uncertain
treatment statuses.

This generalization preserves the relationship in eq.(11), where xi becomes the observa-
tional random vector with xi(a) = pi(+a) − pi(-a). In this case, the dot-product reﬂects the
expectation over Dij instead of U (Servedio, 2004). With a single observation per individ-
ual, a simple way of obtaining these vectors is unity-base normalizing (i.e., feature scaling)
the observation matrix X and assuming any applicable prior for values in-between, [-1, +1].
This makes maximum and minimum correspond to treated and nontreated statuses, with
intermediary treatments having, for example, exponentially decreasing intensities.

B.2 Implementation

The method can be carried out for all individuals in parallel with matrix operations. For
results in this article, we ﬁrst unity-base normalize X,

T 0(X) = 2(X − Xmin) (cid:11) (Xmax − Xmin) − 1.0,

(16)

where Xmin and Xmax are m × n matrices with per-column maximum and minimum

values of X and (cid:11) is the element-wise (schur) division.

Eq.(16) calculates the initial space T 0(X). Subsequent transformations are performed
by gradient descent over the sample population. The resulting method is summarized in
Algorithm.1. All results in this article use 10,000 iterations and a learning rate of η = 0.025.
An optimized C++ version estimates a space Ty(X) for the NSW dataset in under 5 minutes
on a Macbook laptop.

30

What can the millions of random treatments [...] reveal about causes?

Data: X, y
Parameter: η (learning rate)
Result: Xy = Ty(X)
calculate matrices Xmin and Xmax,
calculate matrix Yij ;
X0 := T 0(X)
while approximate minimum not obtained do
randomly shuﬄe m examples from X;
for i := 1 to m do

ij , Φbl
ij

calculate matrices Φcx
A := 1
m Xi ∗ Xi
A := (A ⊗ Φcx
∇X := 1
Xi := X T

m (A ∗ X T
i−1 − η∇X

i−1)T

ij − Yij)2 + A2 ⊗ Φbl

ij ;

// yij = max(0, yi − yj)

// ⊗ is the schur product

end
X0 := Xm

end
return X0

Algorithm 1: Space Xy estimation.

B.3 NSW Study Details

The NSW was a 1970s subsidized work program, running in 15 cities across the US for 4
years. It targeted individuals with longstanding employment problems: ex-oﬀenders, former
drug addicts, recipients of welfare beneﬁts, and school dropouts. At the time of enrollment,
each NSW participant was given a retrospective baseline interview, generally covering the
previous two years, followed by up to four follow-up interviews scheduled at nine-month
intervals. Survey questions covered demographic and behavior topics such as age, sex, race,
marital status, education, number of children, employment history, job search, job training,
mobility, housing, household, welfare assistance, military discharge status, drug use and
extralegal activities. Most questions were objective and probed for speciﬁc information
loosely around the previous themes (e.g., ’what kind of school are you going to? 1 = high
school, 2 = vocational, 3 = college, 99 = other’, ’was heroin used in the last 30 days?’ etc.)
Some questions were subjective (e.g., ’tell me how important each one is to you. knowing
the right people, education, luck, hard work, ...’)

To assemble control surrogates for the NSW, Lalonde used the Panel Study of In-
come Dynamics (PSID), a household survey, and the Westat’s matched Current Popu-
lation Survey-Social Security Administration ﬁle (CPS). He drew 3 subsamples from each
the PSID and CPS (6 in total). Control groups had 450, 550, 726, 2666, 2787 and 16289
individuals7. Lalonde ex ante assumptions for the NSW, PSID and CPS regarded mainly
participants’ assignment date, gender, retirement status, age and prior wages. DW added
further assumptions regarding prior wages for the NSW and used Lalonde’s control groups.

7. thus approximately 100K-200M treatments.

31

Ribeiro, Neffke and Hausmann

Table 1: 20 top-variables according to Ty(X) and LASSO regression in the complete NSW,
ordered by estimated eﬀect or correlation. Bolded variables were selected in the
employed model selection criteria (see Sect.B.3).

select by

Eq.(4)

LASSO
regres-
sion,
β

NSW Variables
importance getting ahead in life: hard work, african american,
treatment, not in school last 6 months, worked <40 hours last 4
weeks, alcohol and hard-liquor consumption, target NSW group
(AFDC, ex-oﬀender, ex-addict, youth, other), importance getting ahead
in life: education, age >18, technical eligibility ﬂags, site location (New
York City), looking for work last in the last 4 weeks, site location
(Philadelphia), no job in the last 6 months, searched for jobs directly from
employer, earing less than program minimum (eligibility criteria), other
gross eligibility ﬂag (not revealed in the public ﬁle), youth group,
employed <9 months last year, program assignment year 1976
amount of alimony money, unemployed in 8th pre-program month
(timeline), amount of money from training, NSW program, amount of
money from social security, amount of SSI dollars, consumed drug other
than marijuana, amount of money from alimony/child support, money
from welfare, receive workman’s compensation, amount money from other
welfare programs, gender, gender (eligibility ﬂag), any money from
workman’s compensation, other gross eligibility ﬂag (not revealed in
public ﬁle), ever gone to school, how related to the person living with the
participant (one of max. 12 persons living with participant), number of
children, holds bachelor’s degree, amount of money from AFDC program,
how old is relative (one of max. 12 persons living with participant)

For the ’missing causes’ study, we ﬁrst estimated a model Ty(X) where

X = {all 1231 variables in the N SW dataset}.

(17)

We use the same outcome variable y as Lalonde, post-program annual earnings (in 1982
dollars). While using all NSW variables (i.e., the answer to every survey question), we
only restrict them in one way. The restriction doesn’t reduce the participant and variable
counts. We ignore any variable values that are negative or ’99’, taking them as omitted -
these values are then mapped to x(a) = 0 values according to eq.(16). These correspond
to unknown, not responded or exceptional values in the survey. We assume SFE should be
able to handle other types of entry. Most variables are binary and naturally normalized to
[-1, +1] according to eq.(16). Other variables are coded to reﬂect a spectrum (e.g., ’even
though the 1000 could result in arrest, how likely is that you would take the chance? 1 =
very likely, 2 = somewhat likely, 3 = somewhat unlikely, 4 = not likely at all’) and they
are accordingly mapped to [-1, +1]. Continuous and count variables are similarly linearly
normalized to ﬁt the interval (with maxima mapped to +1 and minima to -1). Following
Lalonde’s protocol, we ’annualized’ the data. Participants’ assignment date and location

32

What can the millions of random treatments [...] reveal about causes?

are not in the NSW data (only the participant’s relative time in the program). Lalonde
recovered site locations and assignment years by matching reported sites’ unemployment
to unemployment in Earnings and Employment magazines. This is described in detail in
(Lalonde, 1986). Annualization allowed Lalonde to select only the 1975 participants. We,
instead, added participants’ estimated year of assignment and program site location as extra
variables.

Table 1(ﬁrst row) lists the 20 variables with largest AT E(a) in the NSW, ordered by
eﬀect size. We also show the output of a LASSO estimator, as a more typical model selection
procedure, Table 1(second row). The NSW treatment indicator appears as the third most
inﬂuential variable, but it doesn’t appear in the list of variables selected by LASSO, Table
1. Eﬀect sizes relate to norms in Ty(X) and dependence among variables to angles8. To
compare a SFE-devised DGP with Lalonde’s, we next select a variable set of the same size
as the one used by Lalonde. We choose eﬀective and non-redundant causes. Let then M be
a set of unrelated variables M ⊂ X , where X is the previous set of 20 eﬀective variables.
Furthermore, let M k=K(X ) be a subset of X with K variables and

M k(X) = M k−1(X) ∪ arg min
b∈X −M k−1,
a∈M k−1

cos2(a, b),

(18)

where M 0(X) = {a} and a is the variable with highest AT E(a). We use eq.(18) and
0 < K ≤ 7, which selects the bolded variables in Table 1(ﬁrst row). We use K = 7
to match Lalonde’s model size. This is a simple variable selection method. It uses only
the estimated causal eﬀects and expected dependence among variables. Across-population
heterogeneity and others factors readily available in the representation could play roles in
more sophisticated criteria.

The method leads to the following selected variables (ordered by the greedy selection),

X = {work ethics, af rican american, school, worked, drink, nyc}.

(19)

The work ethics variable is related to the survey question ’I’ll read a list of things some
people feel are important in getting ahead in life. Tell me how important each one is to
you?’ The answer follows the scale {important, unknown, not important} and the variable
corresponds to the item ’hard work’. Other items were ’luck’, ’education’, ’knowing the
right people’ and ’knowing the community’ (the item ’education’ also appeared as a top-20
variable, Table 1). The african american variable indicates the participant’s race, similar
to a variable selected by Lalonde. The school variable indicates whether the participant was
in school within the last 6 months. The worked variable indicates whether the participant
worked less than 40 hours in the previous 4 weeks (prior to assignment). The drink variable
indicates the participant’s answer to ’do you ever drink beer, wine, gin or other hard liquor?’
The nyc variable indicates that the participant’s NSW site location was New York City.
Another location (Philadelphia) and an assignment year (1976) also appear in the top-20
list.

8. remember that the cosine of angles between pairs of vectors in standardized datasets correspond to their

Pearson correlation.

33

Ribeiro, Neffke and Hausmann

Similar to Lalonde, we established a correspondence between the NSW and the PSID for
these variables. We ignored nyc as the PSID has no public location information. We mapped
It is an aggregate of indicators:
hardwork to the ’earning acts’ PSID variable (V2941).
’[Family] head seldom or never late for work, head rarely or never fails to go to work when
not sick, head has extra jobs, head likes to do diﬃcult or challenging things, etc.’ And
we mapped drink to PSID’s annual expenditures on alcoholic beverages variable (V2472)
divided by income.

The estimates for this alternative model speciﬁcation across the previous two samples
are depicted in Fig. 5 (main text). These results conﬁrm some of the reasons Heckman
et al.
(Heckman et al., 1998; Dehejia and Wahba, 2002) put forward to explain the poor
’locations in diﬀerent
performance of matching estimators in Lalonde’s NSW subsample:
labor markets’ appear as an eﬀective factor and that the expansion of the ’limited selected
observed variables’ can improve methods’ accuracy. Results suggest that issues like these
can, however, be overcome by observational methods by considering missing causes, non-
causes, and how to identify them. They also suggest that SFE can be used to both estimate
causal eﬀects and help with model speciﬁcations for other estimators.

B.4 Analysis: Bias-Variance Tradeoﬀ

We now motivate the choice to model pairwise individual diﬀerences with an alternative
analytic argument. Consider an outcome diﬀerence predictor ˆyij for individual i (i.e., for
outcome diﬀerences from others). Most eﬀect estimators consider the least-biased estimate
for a population. We consider, instead, what would be the least-biased estimate for an
individual. Repeated samples of xi, yi can increase the estimator’s accuracy. As assumed
in Rubin’s framework (Rubin, 1974), these are rarely available, while observations from
other individuals are often abundant. We therefore consider the error incurred by i when
using an observation from a second individual j. Properties for the following dot-product
based estimator are well known (Hastie, 2001)(2001, p. 50), as well as the relationship
to the Gram–Schmidt procedure (the same results can also be derived through product
distributions (Servedio, 2004)). What distinguishes the following is the formulation of an
estimator for outcome diﬀerences, yij, as opposed to outcomes, yi.

For i and an observational pair (ij), the observed outcome diﬀerence yij can only be due
to attributes in xi not present in xj. This leads to a ’counterfactual’ estimator for eﬀects at
the individual-level. According to the estimator, the observed outcome diﬀerence between
individuals is due to the eﬀect of attributes that only i has, minus the eﬀect of attributes
that only j has, yij ∼ f (xi(cid:9)xj) − f (xj(cid:9)xi).

For an individual i, observations from other individuals lead to the eﬀect predictor

ˆyij =

1
|xj − xi|

(cid:88)

a∈X

fi(a)xi(a) + εij =

(cid:104)fi, xi − xj(cid:105)
|xi − xj|

+ εij,

(20)

where fi ∈ Rm is an individual vector of eﬀects in y-scale, x ∈ [-1, +1]m, E(ε) = 0 and
V ar(ε) = 0. Due to the sign convention, the estimator sums the eﬀects of variables in xi
but not in xj, subtracts the eﬀects of variables in xj but not in xi and cancels out the eﬀect
of variables in both.

34

What can the millions of random treatments [...] reveal about causes?

The estimator’s squared error loss can be decomposed in 3 components corresponding

to a heterogeneity bias, variance and irreducible error εij,

Errij = E[(yij − ˆyij)2],
(cid:104)(cid:16)

= E

yij −

(cid:104)fi, (xi − xj)(cid:105)
(cid:104)xi − xj(cid:105)
ij + ε2

ij],

ij + V ar2

(cid:17)2(cid:105)

,

= [Heter2

=

Heterij = E[ˆyij] − yij,
(cid:104) 1
2
(cid:104) 1
2
1
4

(cid:16) (cid:104)fi, xi − xj(cid:105)
(cid:104)xi − xj(cid:105)
(cid:104)fi − fj, xi − xj(cid:105)
(cid:104)xi − xj(cid:105)

=

=

−

|fi − fj|2cos(θij)2 − yij,

(cid:104)fj, xi − xj(cid:105)
(cid:104)xi − xj(cid:105)
(cid:105)2

− yij,

(cid:17)(cid:105)2

− yij,

(21)

V arij = E[ˆyij − E[ˆyij]],

=

ε2
ij
|xi − xj|2 .

where θij is the angle between vectors fi and xi − xj. The second term is a squared
heterogeneity bias, the y-amount by which the estimate diﬀers from the mean using other
individuals’ eﬀects. The last term is the variance, the expected squared deviation around
the estimated mean in y-amounts.

According to this, variance and heterogeneity are related to two distances (norms of
position diﬀerences) between individuals i and j. These are, in turn, related to spaces X
and Ty(X). Variance is related to distances in the [-1, +1]m covariate space, |xi − xj|, and
heterogeneity to distances over eﬀects, |fi − fj|. Larger distances in X correspond to treat-
ments over more variables, decreasing the estimator’s variance in eq.(20). Larger distances
in Ty(X) correspond to estimates between more heterogeneous individuals, increasing the
heterogeneity bias. Decreasing this bias increases the estimate’s external validity (for the
individual, not the sample population), while decreasing variance increases its internal va-
lidity.

Particularly, eq.(21) suggest that, for a given θij, there are two sources of bias: the diﬀer-
ence in variable eﬀects among individuals, fi(a) − fj(a), and the covariate space dimension,
m. For the former, an estimate with minimal Heterij must have yij = 1
4 |fi − fj|. This cor-
responds to the minimized residual illustrated in Fig.7(c) and implemented by eq.(14). For
m, decreasing the space to a dimension d < m can increase the variance, V arij, in eq.(20)
but decrease Heterij. This motivated the introduction of the treatment size penalty φcx
ij .
Both the decision to use only variables that diﬀer among pairs and the proposed optimiza-
tion procedure can therefore be seen as attempts to reduce individual heterogeneity bias,
Heterij.

Heterogeneity is also decreasing with cos2 θij, which, in turn, reﬂects statistical corre-
lation. This indicates that heterogeneity is maximal for individuals with highly correlated
variables (e.g., sharing many attributes) that observe diﬀerent eﬀects. This motivated the

35

Ribeiro, Neffke and Hausmann

introduction of the treatment balance penalty φbl
ij, which penalized non-orthogonal pairs,
as well as the variable selection criteria in eq.(18). Together, these considerations suggest
a metric space as representation for a sample population, consisting of a set of orthogo-
nal dimensions with correlated covariates (cos2 θij ≈ 1) that are minimally heterogeneous
(yij ≈ 1

4 |fi − fj| ).

Starting with a single individual i and her individual sample {xi, yi}, we start with max-
imal internal-validity. As we increase the population scope and consider other individuals’
samples {xj, yj}, we can increase estimates’ external validity. Learning a representation
for individual diﬀerences, ˆyij, allowed for more accurate (individual) eﬀect estimates while
inter-individual eﬀect diﬀerences, Heterij, were minimized explicitly. This lead to a space
that is ’minimal’ but that still reﬂects observed outcome diﬀerences, yij.

36

