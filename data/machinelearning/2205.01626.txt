2
2
0
2

r
p
A
2
1

]
E
N
.
s
c
[

1
v
6
2
6
1
0
.
5
0
2
2
:
v
i
X
r
a

Automated Learning of Interpretable Models with Quantiﬁed
Uncertainty

G.F. Bomarito∗ and P.E. Leser∗

National Aeronautics and Space Administration, Langley Research Center, Hampton,
VA

N.C.M. Strauss, K.M. Garbrecht, and J.D. Hochhalter

University of Utah, Salt Lake City, UT

May 4, 2022

Abstract

Interpretability and uncertainty quantiﬁcation in machine learning can provide justiﬁcation
for decisions, promote scientiﬁc discovery and lead to a better understanding of model behavior.
Symbolic regression provides inherently interpretable machine learning, but relatively little work
has focused on the use of symbolic regression on noisy data and the accompanying necessity
to quantify uncertainty. A new Bayesian framework for genetic-programming-based symbolic
regression (GPSR) is introduced that uses model evidence (i.e., marginal likelihood) to formulate
replacement probability during the selection phase of evolution. Model parameter uncertainty
is automatically quantiﬁed, enabling probabilistic predictions with each equation produced by
the GPSR algorithm. Model evidence is also quantiﬁed in this process, and its use is shown to
increase interpretability, improve robustness to noise, and reduce overﬁtting when compared to a
conventional GPSR implementation on both numerical and physical experiments.

1

Introduction

Machine learning (ML) has become ubiquitous in scientiﬁc disciplines. In some applications, accurate
data-driven predictions are all that is required; however, in many others, interpretability and explain-
ability of the model is equally important. Interpretability and explainability can provide justiﬁcation
for decisions, promote scientiﬁc discovery and ultimately lead to better control/improvement of mod-
els [1, 2]. In a complementary fashion, ML models can provide further insight by conveying their level
of uncertainty in predictions [3]. Especially in cases of low risk tolerance this type of insight is crucial
for building trust in ML models [4].

Rather than focus on black-box ML methods (e.g., neural networks or Gaussian process regres-
sion) combined with post hoc explainability tools, the current work focuses on inherently interpretable
methods. Interpretable ML methods can be competitive with black-box ML in terms of accuracy and
do not require a separate explainability toolkit [4, 5]. Symbolic regression is one such inherently inter-
pretable form of ML wherein an analytic equation is produced that best models input data. Symbolic
regression has been successful in a range of scientiﬁc applications such as deriving conservation laws

*These authors contributed equally to this work

1

 
 
 
 
 
 
in physics [6], inferring dynamic relationships [7, 8], and producing interpretable mechanics models
[9]. Unfortunately, little attention has been paid to the use of symbolic regression on noisy data and
the consideration of uncertainty.

Schmidt and Lipson [10] tackled the problem of noisy training data in symbolic regression through
the inclusion of uniform random variables in model formation. Though uniform random variables can
be transformed to represent more complex distributions, doing so drastically increases complexity of
equations that must be produced. This can make the symbolic regression process less tractable and
less interpretable.

Hirsh et al. [11] incorporated Bayesian uncertainty quantiﬁcation into the sparse identiﬁcation of
nonlinear dynamics (SINDy) method through the use of sparsifying priors. In this technique, a linear
combination of candidate terms (i.e., simple functions of the input data) is produced with random
coeﬃcients that are estimated through Bayesian inference. The reliance on candidate terms and linear
combinations thereof constitutes only a limited form of symbolic regression (as opposed to the more
traditional free-form symbolic regression). As such, the form of the resulting equation may be overly
constrained and less insightful.

Others have implemented Bayesian methods in symbolic regression [e.g., 12, 13]; however, they
focused more on the improved eﬃciency of symbolic regression methods rather than the ability to
produce probabilistic models with quantiﬁed uncertainty. For instance, Jin et al. [12] used a form of
Markov chain Monte Carlo as a means for equation production. Also, Zhang [13] used a Bayesian
framework to inﬂuence the population dynamics in genetic programming for improved evolution speed
and decreased complexity.

In the current work, a new Bayesian framework for genetic-programming-based symbolic regression
(GPSR) is developed. In this framework, Baysian inference is applied to infer unknown distributions
of parameters in free-form equations. The marginal likelihood of the equations are then used in a
Bayesian model selection scheme to inﬂuence evolution towards equations for which the data provides
the most evidence. The result is a GPSR framework that can produce interpretable models with
quantiﬁed uncertainty. Additionally, the Bayesian framework provides regularization with several
beneﬁts compared to standard GPSR: increased interpretability, increased robustness to noise, and
less tendency to overﬁt.

2 Methods

i.e., at-
Symbolic regression is the search for analytic equations that best describe some dataset:
tempting to ﬁnd a function f : Rd → R such that f (x) = y given a dataset D{(xi, yi)}N
i=0 with
d-dimensional input features x and label y. Several methodologies have been applied to the task
of free-form symbolic regression such as genetic programming [14], prioritized grammar enumeration
[15], Markov chain Monte Carlo [12], divide and conquer [16], and deep learning [17, 18]. Genetic
programming-based symbolic regression (GPSR) is perhaps the most popular and successful [19]. The
focus of the current work is the integration of uncertainty quantiﬁcation into the GPSR framework
for the robust selection of models when data is noisy. This section will ﬁrst outline a conventional
GPSR framework, then describe how it can be modiﬁed for consideration of uncertainty.

2.1 Conventional GPSR implementation

GPSR is an evolutionary approach to symbolic regression, wherein a population of candidate equations
is evolved until they adequately describe the input dataset. The population is ﬁrst randomly initialized;
then, in subsequent generations, the population is evolved through crossover and mutation before
entering a selection phase. The open-source Python package Bingo[20] is used in this work for GPSR.
The internal representation of equations plays an important role in GPSR [21]. For example,
equations can be represented as an acyclic graph (see Figure 1), where the number of nodes in the
acyclic graph is a measure of the equation complexity. A common diﬃculty in GPSR is equation bloat

2

(i.e., the tendency to produce increasingly complex equations), which counteracts interpretability. The
acyclic graph encoding is chosen in this work, rather than the more common tree encoding, for its
superior computational performance and reduced bloat [21].

The random initialization, crossover, and mutation of equations is based on generating, mixing,
and modifying acylic graph components. A brief description of these algorithms is outlined here;
for a more complete description see the Bingo repository [20]. Random initialization of an equation
consists of generating a sequence of nodes and directed connections. Single point crossover is used to
swap sections of two parent equations resulting in two new children. Mutation occurs as a random
choice from the following: point (node) mutation; edge (directed connection) mutation; node and
edge mutation; prune mutation; and branch mutation. Notably, all of these operations preserve the
maximum acyclic graph size and as such a maximum complexity limit can be set.

The consideration of real-valued numerical constants has been a diﬃculty for GPSR in the past.
Existence of these parameters in equations can increase the search domain and increase bloat pressure.
In early attempts, these parameters would be represented as ﬁxed-value terminals that then must be
combined or mutated in equations to allow for derived quantities. This placed undue burden upon
the evolutionary optimization and long periods of evolution could be devoted to simple variation of
numerical parameters. More recently there has been a push for the inclusion of local optimization
[22, 23] of these parameters. In this approach, real-valued numerical constants are treated as abstract
placeholders: i.e., equations f ∗(x, θ) include an explicit dependence upon numerical parameters θ ∈
Rp. These parameters are then optimized based on the training data θ∗ = argminθ R(f ∗, D, θ) to
yield a ﬁnal equation f (x) = f ∗(x, θ∗); here R is an error metric such as root mean squared error
(RMSE). In this way, the optimization of numerical constants is separated from the evolution of the
equation form. Local optimization of numerical constants with RMSE is used in the current work
for the conventional GPSR implementation. As will be shown in Section 2.2, the optimization of
constants in this manner allows for a natural probabilistic extension wherein the constants can be
considered random variables and the optimization is used for initializing their estimation.

The last remaining aspect of the GPSR implementation in this work is the choice of selection
method. The selection process is an important factor in the evolutionary dynamics of the population.
The most common form of selection in genetic programming is tournament selection, where individuals
in the population compete against other randomly selected individuals for entrance into the next
generation, and the individual with best ﬁtness survives. Commonly, an error metric such as RMSE
is used to measure ﬁtness in symbolic regression. Newer selection algorithms have been aimed at
reducing the tendency to prematurely converge to a local optimum (i.e., combating the tendency to
exploit rather than explore) [e.g., 24, 25]. The conventional GPSR implementation in the current
work uses one of these forms of selection known as deterministic crowding [24].
In deterministic
crowding, individuals are paired with their most-similar oﬀspring (pairing phase); the individual with
better ﬁtness survives into the next generation (replacement phase). Probabilistic extensions have
been made to the replacement phase of the deterministic crowding method [26, 27]; however, the
form of the replacement probability has been completely heuristic. Section 2.2 will illustrate how a

+

×

x0

x1

Figure 1: Acyclic graph representation of the equation f (x) = x0 + x0x1 with complexity of 4.

3

probabilistic formulation for equation ﬁtness can allow for the more principled use of Bayesian model
selection in replacement.

2.2 Bayesian GPSR implementation

Extending GPSR to the quantiﬁcation of uncertainty requires a probabilistic reformulation of the
local optimization. Here, θ ∈ Rp is now considered a realization of a random variable Θ such that
θ = Θ(ω), where ω ∈ Ω is a random event in the sample space Ω. The solution to the inverse problem
is the probability distribution of Θ conditioned on both the data, D, and a particular GPSR-generated
model, f , referred to as the posterior distribution. Note that the explicit dependence of f (x, θ) on x
is dropped from the notation in the following discussion to preserve clarity. The posterior probability
density function (PDF) is given by Bayes’ Theorem

π(θ|D, f ) =

π(D|θ, f )π(θ|f )
π(D|f )

=

π(D|θ, f )π(θ|f )
Rp π(D|θ, f )π(θ|f )dθ

(cid:82)

,

(1)

where π(θ|f ) is the prior density function, which encodes a priori knowledge about the probability
of the parameters, and π(D|θ, f ) is the likelihood function, which represents the probability density
for observation D when θ takes a speciﬁc value.

The form of the likelihood function is dependent on the relationship between f and D. A typical
assumption used in Bayesian inference is that there is some noise, ε, associated with the measurements
such that

D = f (θ) + ε,

(2)

where the noise is independently and identically distributed according to a zero-mean Gaussian dis-
tribution, N (0, σ2), with unknown variance σ2. The likelihood function associated with Equation (2)
is known in closed form. This form can be modiﬁed depending on the nature of the problem (e.g.,
the noise could be multiplicative or follow some other distribution) and the likelihood function would
change accordingly. Equation (2) is used for the examples presented herein.

The denominator π(D|f ) in Equation (1) is referred to as the marginal likelihood and is a nor-
malizing constant to ensure the posterior PDF is proper (i.e., integrates to 1) for a given model.
This potentially high-dimensional integral is typically ignored since it is diﬃcult to compute and not
required for random walk algorithms such as Markov chain Monte Carlo (MCMC), which exploit the
proportionality π(θ|D, f ) ∝ π(D|θ, f )π(θ|f ) to draw samples from the posterior distribution. How-
ever, the marginal likelihood is a powerful quantity in Bayesian model selection as it can be used to
compute the relative posterior probability of one model versus another using Bayes’ factor (BF),

B =

π(f1|D)
π(f2|D)

=

π(D|f1)π(f1)
π(D|f2)π(f2)

,

(3)

where π(D|fi) and π(fi) are the marginal likelihood and prior probability of the ith model, respectively.
In the GPSR context, the BF can be used to measure relative ﬁtness when comparing equations
during the selection phase. This has the dual advantage of accounting for uncertainty and penalizing
complexity through what has been referred to as the Bayesian Occam’s Razor [28]. The marginal
likelihood π(D|f ) represents the space of possible data that can be represented by a given model. As
the dimension p increases and the model becomes more ﬂexible, the probability density function of
the data is dispersed.

Judicious selection of prior distributions is a critical part of Bayesian inference and particularly
model selection due to the sensitivity of π(D|f ) to both prior bounds and dimensionality. Subjective
versus objective priors is a point of contention in Bayesian statistics [29, 30]. In the context of GPSR,
where models are being generated from an immense space of operators and combinations thereof, it
would be challenging if not impossible to be subjective; e.g., to have an expert perform elicitation or
to use previous experimentation to inﬂuence the selection of priors for an unknown model. Priors for

4

the Bayesian GPSR implementation are thus aimed at being objective in that the inference is only
inﬂuenced by data to the extent possible. For example, π(fi) = π(fj) was assumed here to not favor
any particular model over another, yielding a BF equal to the ratio of marginal likelihoods.

Objective choices for π(θ|f ) are more challenging as optimally non-informative priors depend on
the form of the model [31]. A simple choice, although suboptimal in terms of reducing the inﬂuence
of the prior, is an improper uniform distribution π(θ|f ) ∝ 1 for θ ∈ Rp. However, this causes issues
when computing BF due to indeterminate constants appearing in Equation (3). O’Hagan introduced
the fractional Bayes factor (FBF) [32] to address this issue:

where

Bγ =

q1(γ)
q2(γ)

,

qi(γ) =

(cid:82)
Rp π(D|θ, fi)π(θ|fi)dθ
(cid:82)
Rp π(D|θ, fi)γπ(θ|fi)dθ

.

(4)

(5)

The unknown constants in the marginal likelihood are normalized out using the γ ∈ (0, 1] power of
the likelihood function, allowing for consistent model selection when using improper uniform priors to
compute BF. Following O’Hagan’s recommendation for improved robustness to prior misspeciﬁcation,
γ = 1

N was chosen for this work.

√

Estimating marginal likelihood is challenging using MCMC, and computing the FBF requires two
separate runs of an MCMC sampler to target the additional normalizing γ posterior. Sequential Monte
Carlo (SMC) evolves a set of weighted particles through a sequence of reweighting, resampling, and
local abbreviated MCMC steps and can be used as a drop-in replacement for MCMC [33]. SMC has
several advantages over MCMC, including the ability to produce direct, unbiased estimates of the
marginal likelihood, π(D|f ), as well as potential reductions in computation time relative to MCMC
through parallelization of the π(D|θ, f ) evaluations. Furthermore, SMC relies on a sequence of target
distributions based on an annealed likelihood, which is conveniently the same form as the FBF; i.e.,
π(D|θ, f )φt with φt monotonically increasing from 0 at t = 0 to 1 at t = 1 during the sequential
sampling process. Therefore, qi(γ) is a natural byproduct of a single run of an SMC sampler if φt = γ
is included as the tth step of the sequence and the marginal likelihood is estimated at both the tth
and ﬁnal steps.

Initialization of the SMC algorithm is a practical challenge when considering arbitrary equations
with priors over the entire real space Rp. To prevent early divergence and degeneracy of the particles
(i.e., a signiﬁcant portion of particles having zero weight), it is important to locate the initial particles
near to and encompassing the unknown region of non-zero posterior probability. A multistart local
optimization approach is adopted here to quickly identify local RMSE minima. These local minima are
considered potential regions of high posterior probability. Multivariate normal distributions (MVN)
centered at each local minimum are used to approximate the posterior distribution,

π(θ|D, f ) ≈ M V N (θ∗, Σ∗),

(6)

where the availability of partial derivatives is exploited to estimate the covariance matrix. The restric-
tion of N > p was relaxed in the symbolic regression framework so, in place of the unbiased estimator
in [34] with denominator N − p, a biased1 estimator was used,

Σ∗ =

χi,k =

(cid:80)N

i=0[yi − f (xi, θ∗)]2
N
∂f (xi, θ∗)
∂θ∗
k

.

(χT χ)−1,

(7)

(8)

1Errors associated with this approximation only inﬂuence the inference process through the placement of initial

particles, and the eﬀect was assumed to be minimal.

5

The SMC algorithm is initialized by sampling particles from each MVN distribution in equal
proportion (i.e., there was no attempt to combine co-located distributions). The number of multistarts
dictates how much the initial population is allowed to explore the inﬁnite parameter space, with an
increasing number of multistarts corresponding to increasing the chance of SMC identifying all modes
of the true posterior distribution.

The proposed Bayesian GPSR implementation is an extension of probabilistic crowding [26], where
the ﬁtness and thus the replacement probability is based on the FBF. The open-source, vectorized
SMC Python implementation SMCPy [35] is used to eﬃciently compute normalized marginal likelihoods
qi(γ) for each individual. After pairing most-similar oﬀspring, a replacement probability is deﬁned as
p(f1|q1, q2) = q1/(q1 + q2). For FBF= 1, this selection probability is equal to 0.5. For cases where
FBF > 1, the ﬁrst model is more likely to proceed to the next generation, etc. See Algorithm 1 for a
summary.

Algorithm 1 Probabilistic Crowding using Bayesian Model Selection
Require: Population of equations at ith generation (Fi), training data (D)
1: for most-similar pairs (f1, f2) in Fi do
2:
3:
4:
5:
6:
7:

q1 ← SMC(f1, D)
q2 ← SMC(f2, D)
p(f1|q1, q2) = q1/(q1 + q2)
Sample u ∼ Uniform(0, 1)
if u ≤ p(f1|q1, q2) then

Fi+1 ← f1

else

8:
9:
10:
11: end for

end if

Fi+1 ← f2

2.3 Demonstration

To demonstrate the utility of the FBF for GPSR selection as well as the ability of SMC to estimate
the FBF, a numerical experiment was conducted. A true function y = 2 sin x0 + 3 was deﬁned and
synthetic data was generated by adding zero-mean Gaussian noise.2 Polynomials of increasing order
(0 to 6) were ﬁt to the data using two methods: (i) a deterministic minimization of RMSE and (ii)
probabilistic parameter estimation using SMC as described in Section 2.2. The deterministic and
probabilistic ﬁts for polynomial orders 3 and 6 are compared along with the training data in Figure 2.
Since SMC produces a probabilistic ﬁt of model parameters and simultaneously estimates measurement
noise, both the 95% credible and prediction intervals are shown3. The maximum a posteriori (MAP)
ﬁt, f (x0, θMAP), where θMAP are the most probable parameters, is also shown. While the RMSE and
MAP ﬁt are very similar as expected,4 the probabilistic ﬁt expresses increased uncertainty through
widening intervals at the edges of the domain where the largest errors with respect to the true model
are seen, an advantage over the deterministic ﬁt.

For each SMC run, the FBF was also computed as an alternative ﬁtness measure to RMSE.
Results are shown in Figure 3. As expected, the FBF naturally penalizes complexity as illustrated
by a decrease in FBF after polynomial order 3. In contrast, RMSE continues to decrease, showing
a propensity for overﬁtting and equation bloat. Therefore, it is believed that using the FBF ﬁtness

2Note that this example is kept intentionally vague to focus the reader on general ﬁtness metric trends; a more

detailed discussion of the example is provided in Section 3.1.

3Credible intervals represent model parameter uncertainty while prediction intervals include estimated measurement

noise as well.

4Maximum likelihood estimation and MAP are equivalent when using uniform priors on θ, as was the case in this

example.

6

metric will lead to identiﬁcation of more parsimonious equations and improved robustness to noise in
the data.

3 Experiments and Discussion

In this section, Bayesian GPSR is applied ﬁrst to a numerical example and then to an experimental
example5. The ability of Bayesian GPSR to produce interpretable models and make probabilistic
predictions is illustrated. Comparisons are made to conventional GPSR that illustrate several beneﬁts
to the Bayesian extension beyond its ability to produce probabilistic predictions.

3.1 Numerical example

In a ﬁrst exposition of Bayesian GPSR, a synthetic example is considered that allows for numerical
adjustment and investigation. In this example, datasets are generated using the function:

y = 2 sin(x0) + 3 + (cid:15),

(9)

where (cid:15) is sampled from a normal distribution with zero mean and standard deviation, σ. Here, x is
one-dimensional (d = 1) and drawn from a uniform distribution with bounds (0, 3π
2 ). Several training
datasets are generated, each with twenty datapoints (N = 20), which vary based on σ as well as the
random seed used for x and (cid:15). Testing datasets of size N = 1000 are generated in a similar fashion,
but only vary based on σ (i.e., a single random seed is used for x and (cid:15)).

For all GPSR runs in this subsection (both conventional and Bayesian) the following hyperpa-
rameters are used: population size of 120, complexity limit of 646, number of generations 1000. The
Levenberg-Marquardt method, as implemented in SciPy[36], is used for optimization of numerical
constants. GPSR was restricted to evolution of polynomials by limiting the use of mathematical
operators to [+, −, ×]. This restriction on operators precludes the ability of ﬁnding the true model,
allowing for better study of overﬁtting and generalization properties of the method.

For each training dataset, both GPSR and Bayesian GPSR were run once. The result of one of

the Bayesian GPSR runs was the equation

f (x, θ) = θ1 + (θ2 + θ3x0)(x0 + x0(θ2 + θ3x0))

(10)

with accompanying posterior distributions for θ and σ. The marginal distributions of θ and σ are
illustrated in Figures 4a and 4b, respectively. The θ parameters are largely uncorrelated to each
other except for θ2 and θ3 which are highly correlated. The correlation of these two parameters are
illustrated in the pairwise plot in Figure 4c. It is also seen that θ2 and θ3 exhibit bimodal behavior in
this result; which indicates the ability of the Bayesian framework to accurately address such scenarios.
The predictive capability of Equation (10) is illustrated in Figure 5. Most importantly, the model
gives probabilistic predictions. The MAP prediction could be used in cases where a deterministic
prediction is needed; credible and prediction intervals can also be used to illustrate the degree of
certainty in those predictions. To help illustrate the importance of the probabilistic prediction, the
right side of Figure 5 extends beyond the data and shows the behavior of the model upon extrapolation.
There, the degree of uncertainty in the prediction starts to increase, thus indicating that predictions
in the extrapolated region are less trustworthy.

In addition to having the ability to quantify uncertainty, Bayesian GPSR has several advantages
over conventional GPSR. Firstly, Bayesian GPSR is more robust to noise. Given the same noisy,

5Examples with input dimension of d = 1 are used here for simplicity but Bayesian GPSR can be used in higher
dimensions just as other GPSR techniques (see [9] for an example of a similar GPSR implemenation applied to higher-
dimensional data).

6Equations reaching the maximum complexity of 64 were infrequent; thus, results presented here are expected to be

relatively invariant of this choice

7

Figure 2: Polynomial models ﬁt to noisy data using SMC (probabilistic) and RMSE (deterministic).
Data was generated from y = 2 sin x0 +3 with added Gaussian noise. The probabilistic ﬁt is illustrated
with the MAP prediction and the 95% credible/prediction intervals.

Figure 3: FBF- and RMSE-based ﬁtness for polynomials of increasing order. RMSE is normalized by
the standard deviation of the added noise.

(a)

(b)

(c)

Figure 4: The distributions accompanying Equation (10) as a result of using Bayesian GPSR in the
numerical example. (a) Marginal densities for model parameters, (b) the marginal estimate of the
noise scale, and (c) pairwise plot illustrating covariance between two model parameters. Note that
distributions are illustrated with a ﬁtted kernel density estimate as opposed to the discrete particle
representation used in SMC.

8

01234x00123456yPolynomialorder:301234x0Polynomialorder:6TrueEquationRMSEFitBayesianMAPPrediction95%CredibleInterval95%PredictionIntervalTrainingData0123456PolynomialOrder0.00.10.20.3FBF1.01.52.02.5NormalizedRMSEFBFRMSE−50012Densityθ1θ2θ30.40.602468DensityσTrue−50θ2−1.0−0.50.00.51.0θ3Figure 5: Probabilistic prediction using Equation (10) and the SMC-estimated parameter uncertainty
compared to the training data and true equation.

data-generating function, Bayesian GPSR produces models which are more invariant to the speciﬁcs
of the dataset. Figure 6 shows the results of Bayesian GPSR and conventional GPSR being trained
on the same 3 datasets which were generated using Equation (9) and diﬀerent random seeds. Models
produced with conventional GPSR vary wildly based on diﬀerent datasets whereas Bayesian GPSR
produces more noise-invariant models. The extrapolatory behavior of Bayesian GPSR models does
degrade in quality with distance from the training data; however, it represents a large improvement
over conventional GPSR. Conventional GPSR includes no measure of conﬁdence in predictions whereas
Bayesian GPSR predictions indicate conﬁdence in its predictions. As such, users of Bayesian GPSR
can know when to exercise caution, such as in extrapolatory regions.

The use of a Bayesian framework in GPSR provides a level of regularization against overﬁtting.
This can be seen when comparing the training and test error in Figure 7. Test error is quantiﬁed as
the RMSE on the larger test dataset; the true model would have a test error of σ. In both Bayesian
and conventional GPSR, training error decreases with continued evolution. In conventional GPSR,
however, the test error starts to increase early in the evolution. The test error for Bayesian GPSR,
though oscillating, remains relatively constant and only slightly above the value of σ. This trend is
consistent across datasets with varying noise levels, as seen in Figure 8. Bayesian GPSR consistently
ﬁnds models with test errors near σ and conventional GPSR produces models that are overﬁt to the
training data.
It should be noted that in the zero-noise case, conventional GPSR produces more
accurate models. However, once any amount of noise was added to the training data, Bayesian GPSR
is preferred.

The Bayesian framework also provides GPSR with a level of regularization against the generation of
overly complex equations (i.e., bloat). In conventional GPSR, candidate equations grow continuously
in complexity and number of model parameters (i.e., dimension of θ), whereas candidates equations
in Bayesian GPSR are less prone to bloat. Bloat control methods such as parsimony pressure, early
stopping, and strict complexity limits (using crossvalidation to select the additional hyperparameters)
could be employed in GPSR; however, the objective function in the evolution of the population
becomes misaligned with the ultimate model choice. These methods ﬁnd a best model encountered
in the evolution based on one metric while incentivizing the evolution based on another. Essentially,
these methods become a form of post-hoc model selection rather than a driver of the evolutionary
process itself. Figure 9a illustrates that Bayesian GPSR tends to ﬁnd a complexity that is appropriate
for the dataset after which bloat slows or stops. In contrast to other mechanisms for bloat control, the

9

0123456x0012345678yTrueEquationMAPPrediction95%CredibleInterval95%PredictionIntervalTrainingData(a)

(b)

Figure 6: Three examples of model predictions produced by (a) conventional GPSR and (b) Bayesian
GPSR.

(a)

(b)

Figure 7: Testing and training error for conventional GPSR and Bayesian GPSR.

Figure 8: Relationship between testing error and noise level for conventional GPSR and Bayesian
GPSR.

10

012345x0−5.0−2.50.02.55.0yTrainingDataPrediction012345x0−5.0−2.50.02.55.0yTrainingDataMAPPrediction95%PredictionInterval02004006008001000Generation10−1100NormalizedTrainingErrorGPSRBayesianGPSR02004006008001000Generation100TestingErrorGPSRBayesianGPSRσ0.00.20.40.60.81.0Noiseσ10−2100102TestingErrorGPSRBayesianGPSRσBayesian framework automatically identiﬁes an appropriate level of complexity based on the training
data. Figure 9b shows that in lower noise scenarios Bayesian GPSR permits more complex equations
and in high-noise scenarios less complexity is needed.

Lastly, Bayesian GPSR produces models which are signiﬁcantly more interpretable than conven-
tional GPSR. This is primarily due to the reduced complexity of resulting equations.7 For example,
a best ﬁt equation of a Bayesian GPSR run with approximately median-complexity is

f = θ1 + (1 − θ2)x0 + x2

0 + θ2x3

0(θ3 + θ2x0),

(11)

whereas a best ﬁt equation of a conventional GPSR run with approximately median complexity is

f =θ1 + x0 + θ2(x0 + x3
+ x0(θ6(θ7 + x2
− (x3

0(θ3 − x2
0 + (θ8 + x4

0)(θ4 + θ5x2
0(x3
0 − θ5)x2
0 − x0))) − x0)

0(θ4 + θ5x2

0(x3

0 − x0)) − θ5 − x3

0(x3
0 − (x0)))(θ9 + x3

0 − x4
0)
0(x3
0 + θ10x3

0 − x0))

(12)

The reduced complexity clearly aids in interpretability.

3.2 Galileo Example

In this section, Bayesian GPSR is applied to physical data from the scientiﬁc notebooks of Galileo
Galilei. The goal is to illustrate the ability of Bayesian GPSR to develop a predictive and interpretable
equation with quantiﬁed uncertainty. The Galileo experiments in this section were chosen speciﬁcally
because they represent iconic, noisy data in a scenario where the true physics (i.e., data-generating
function) of the problem is known.

While Galileo was teaching at the University of Padua, he performed a series of experiments
studying projectile motion and free fall.
In one of those experiments, he dropped a ball down an
inclined plane and then oﬀ a horizontal shelf as illustrated in Figure 10a. He recorded the initial drop
height of the ball H and the horizontal distance traveled during free fall D. He also performed the
same experiment without the horizontal shelf giving an initial downward velocity to the ball (seen in
Figure 10b). The data Galileo gathered for these examples[37] are included in Table 1.

An identical GPSR setup is used from the previous section, with the exceptions of the mathemat-
ical operator set and local optimization algorithm. To enable the discovery of of the true physical
equations, an extended set of operators are used: [+, −, ×, /, pow, sqrt]. In the Galileo examples, the
datasets are much smaller: N = 5 and N = 7. This poses a limitation for Levenberg-Marquardt; i.e.,
when the number of parameters in a given equation exceeds the number of datapoints. In these cases,
the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm, as implemented in SciPy[36], was used
for local optimization.

7Neural networks can be represented by an analytic equation, but it is so complex that they are considered black-box.

Table 1: Data gathered by Galileo in his free fall experiments [37, 38]. Data is in units of punti.

With Shelf
H
D
1000
1500
828
1340
800
1328
600
1172
300
800

Without Shelf
D
573
534
495
451
395
337
253

H
1000
800
600
450
300
200
100

11

(a)

(b)

Figure 9: Representations of bloat for conventional GPSR and Bayesian GPSR as a function of (a)
generation and (b) level of noise in the data.

(a)

(b)

Figure 10: Schematic of Galileo’s experiment (a) with shelf and (b) without shelf.

Experiment with shelf

The experiment with the horizontal shelf is the easier of the two to describe mathematically. The
underlying physics is captured by the following relationship [38]

D = k

√

H,

(13)

where k is dependent upon the geometry of the table and ramp, and k = 47.09 best ﬁts the Galileo
dataset in a least-squares sense.

Due to inherent randomness, Bayesian GPSR was repeated ﬁve times using Galileo’s ramp-with-
shelf data. In all repetitions, the correct model form was found and the ﬁnal population consisted
primarily of diﬀerent algebraic forms of Equation (13). A representative result is illustrated in Fig-
ure 11, which has the following form:

f (x, θ) = θ1

x0.

(14)

√

Not only is the underlying physics identiﬁed from this small dataset, but a reasonable description of
uncertainty is produced. The posterior distribution for θ and σ is illustrated in Figures 11b and 11c,
noting that the MAP θ1 aligns well with the least-squares ﬁt.

12

2468NumberofParametersGPSRBayesianGPSR02004006008001000Generation102030Complexity468NumberofParametersGPSRBayesianGPSR0.00.20.40.60.81.0Noiseσ10203040ComplexityHDHD(b)

(c)

(a)

Figure 11: Representative example of Bayesian GPSR result (Equation (14)) for the ramp-with-shelf
data: (a) probabilistic prediction compared to the training data, (b) estimated probability density
function of θ1, and (c) estimated probability density function of noise standard deviation, σ.

In all of the Bayesian GPSR repetitions, the ﬁnal population contained numerically approximate
equations. These equations are characterized by an equation form that does not algebraically simplify
to the true physics but approximates it numerically. An example of one such equation is

f (x, θ) =

√

θ1
x0
1 + θ2x0

,

(15)

where θ1 is distributed similarly to previous equation and θ2 ≈ −7.6 × 10−19. Occasionally, these
numerically approximate equations are favored over the true physical equation in terms of the FBF,
making them overﬁt solutions to the GPSR problem. Though the Bayesian GPSR does provide
regularization against overﬁtting, existence of overﬁt solutions within the ﬁnal population cannot
be completely discounted. It remains a user’s responsibility to appropriately and critically compare
produced models. In Galileo’s ramp-with-shelf example, identiﬁcation of such overﬁt solutions was
trivial, but use of a ﬁtness-complexity Pareto front [6] or cross-validation could be useful in more
complex cases.

Experiment without shelf

The physical relationship is more complex in Galileo’s experiment without the horizontal shelf because
the ball enters free fall with an initial downward velocity (and less horizontal velocity). It is described
by the relationship [38]

H =

k1D2
1 + k2D

(16)

where k1 and k2 are dependent upon the geometry of the table and ramp. The values of the best ﬁt
parameters (in a lest-squares sense) for the Galilieo data are k1 = 1.099×10−3 and k2 = −1.121×10−3.
The maximum distance traveled occurs at the asymptote of this equation. In other words, the terminal
distance is −1/k2 (892 punti in Galileo’s example).

13

20040060080010001200H4006008001000120014001600DMAPPrediction95%CredibleInterval95%PredictionIntervalTrainingData44464850520.00.51.0Densityθ1Least-squares0501001500.000.020.04DensityσBayesian GPSR was performed 11 times with the Galileo ramp-without-shelf data. This data

proved to be a much more diﬃcult task for Bayesian GPSR. The true physical model, e.g.,

f (x, θ) =

θ1x2
0
1 + θ2x0

,

(17)

was present in the ﬁnal population in 5 of the 11 repetitions. A representative result that has this
functional form is illustrated in Figure 12a. The equation does a reasonable job capturing the trend
of the data with exception of the datapoint near D = 535, which is near the upper edge of the 95%
prediction interval. The parameter estimates of this result are included in Figure 13a. The estimates
of the two parameters match well with their least squares estimates. Of the ﬁve Bayesian GPSR
repetitions that contained the true physical equation, four contained equations with signiﬁcantly
better description of the data (as measured by FBF).

One of the equations identiﬁed frequently across the repetitions with high FBF is

f (x, θ) =

x2
0(θ1 + θ2x0)
θ3x2
0 + θ4x0 + θ5

.

(18)

A representative result which has this functional form is illustrated in Figure 12b. After reparametriza-
tion, Equation (18) becomes

f (x, θ) =

(cid:18) θ1x2

0

1 + θ2x0

(cid:19) (cid:18) 1 + θ3x0
1 + θ4x0

(cid:19)

.

(19)

The left parenthetical is the true physical equation and the right is an augmentation that allows for
the addition of a second asymptote. In the result shown in Figure 12b the values of θ3 ≈ θ4 ≈ − 1
535.5
lead to an augmentation that is approximately 1 except in the neighborhood of x0 = 535.5 where there
is asymptotic behavior. The asymptotic behavior allows for the equation to nearly exactly match the
datapoint at D = 535 without signiﬁcantly modifying the equation elsewhere. Ultimately, this leads
to parameter estimates for θ1 and θ2 that are similar to their true values and a much smaller estimate
of the noise level σ (Figure 13b).

Due to the interpretable nature of Bayesian GPSR some forms of overﬁtting like Equation (19)
can be identiﬁed and mitigated a posteriori ; nevertheless, it is worth investigating why this type
of overﬁtting occurred.
It has been shown that Galileo’s no-shelf dataset is biased relative to the
underlying physics [37, 39], likely due to experimental limitations of the era. With this in mind it
is worth testing the validity of the underlying assumption that the noise in the stochastic model
(Equation (2)) is normally distributed. To this end, the residuals of Galileo’s ramp-without-shelf
data relative to the least-squares ﬁt of the true physics were calculated and subsequently used in a
Shapiro-Wilk [40] normality test. The test showed that the residuals are not normally distributed
with power α = 0.1 and p value 0.06. On the other hand, the residuals with respect to the overﬁt
Equation (19) become more normally distributed (p value of 0.18).

The lack of normality of the noise in Galileo’s no-shelf experiment is investigated further by
producing new synthetic datasets where the noise is normally distributed. To create these datasets,
the least-squares ﬁt of the true physics, Equation (16), is used as the data generating function. For
each dataset, N = 7 realizations of D are drawn from a uniform distribution, Di ∼ Uniform(0, 800),
and added to samples from a zero-mean noise distribution with σ equal to the standard deviation of
the residuals (i.e., approximating the same level of noise as Galileo’s experiments). Six datasets were
constructed and used for Bayesian GPSR with hyperparameters identical to those used above. In all
six cases, the true physical equation existed in the ﬁnal population with the best (or approximately
equal to the best) ﬁtness. In most cases, the true physical form was also the most frequently occuring
equation in the population. Given these results, it can be concluded that the idiosyncrasies of Galileo’s
no-shelf data is at least partially responsible for the tendency to overﬁt. Future eﬀorts could be focused
on the incorporation or generation of non-Gaussian noise models to more directly address the issue.

14

(a) Correct form Equation (17)

(b) Overﬁt form Equation (19)

Figure 12: Probabilistic ﬁts produced by Bayesian GPSR for the no-shelf data illustrating the diﬀer-
ence between (a) the correct form of the equation and (b) an equation exhibiting overﬁtting.

(a)

(b)

Figure 13: Estimated probability density functions of θ1, θ2 and noise standard deviation, σ for (a)
the correct form of the equation and (b) an equation exhibiting overﬁtting. Dashed lines indicate the
least-squares ﬁts of θ1 and θ2

.

15

200300400500600D020040060080010001200HMAPPrediction95%CredibleInterval95%PredictionIntervalTrainingData200300400500600D020040060080010001200H520530540700800900910.10910.15910.20910.25910.301/θ1050100Density921.55921.60921.65921.70921.75921.80921.851/θ102040Density891.90891.91891.92891.93891.94891.95−1/θ20200400Density889.30889.35889.40889.45−1/θ202040Density102030σ0.000.050.10Density0246810σ0.00.20.4Density4 Conclusion

A new Bayesian framework for genetic-programming-based symbolic regression (GPSR) was devel-
oped. For each equation in the population, Bayesian inference was used to estimate probability
density functions of the unknown constants given the available data. This automatic quantiﬁcation
of uncertainty meant that any equation could be used to make probabilistic predictions using, for
example, Monte Carlo simulation. As a byproduct of this process, the normalized marginal likelihood
of the fractional Bayes’ factor was computed and used to represent the equation ﬁtness. Coupled with
the probabilistic crowding algorithm, this new ﬁtness metric enables Bayesian model selection during
population evolution where the replacement probability is rooted in model evidence. The impact of
this approach on the equations produced during symbolic regression was studied through both a nu-
merical example and a real-world example. The proposed method was able to produce interpretable,
data-driven models that incorporate uncertainty. Additionally, the proposed method was shown to
increase interpretability, improve robustness to noise, and reduce overﬁtting when compared to a
non-Bayesian GPSR implementation.

A number of open issues are left to future work. First, in the examples presented, an additive
Gaussian noise assumption was made. While this assumption could easily be altered depending on the
application of interest, the choice, once made, is ﬁxed throughout GPSR. There is potential to allow
the GPSR algorithm to modify the likelihood function during evolution to better ﬁt the data. Second,
it is common to know a priori what parameters should appear in the generated equations (e.g., known
physical constants). While not currently implemented, this knowledge could be encoded as subjective
priors which would then be available to the GPSR algorithm for inclusion during Bayesian inference.
It is noteworthy, in closing, that this paper provides a simple but generic approach to incorporating
model evidence in GPSR. Any of the plethora of advancements in the ﬁeld of uncertainty quantiﬁcation
could be incorporated to enhance the ﬂexibility and applicability of the method.

References

[1] Amina Adadi and Mohammed Berrada. Peeking inside the black-box: a survey on explainable

artiﬁcial intelligence (xai). IEEE access, 6:52138–52160, 2018.

[2] Mengnan Du, Ninghao Liu, and Xia Hu. Techniques for interpretable machine learning. Com-

munications of the ACM, 63(1):68–77, 2019.

[3] Umang Bhatt, Alice Xiang, Shubham Sharma, Adrian Weller, Ankur Taly, Yunhan Jia, Joydeep
Ghosh, Ruchir Puri, Jos´e MF Moura, and Peter Eckersley. Explainable machine learning in de-
ployment. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency,
pages 648–657, 2020.

[4] C Rudin. Please stop explaining black box models for high stakes decisions. arxiv 2018. arXiv

preprint arXiv:1811.10154.

[5] Cynthia Rudin and Joanna Radin. Why are we using black box models in ai when we don’t need
to? a lesson from an explainable ai competition. Harvard Data Science Review, 1(2), 2019.

[6] Michael Schmidt and Hod Lipson. Distilling free-form natural laws from experimental data.

science, 324(5923):81–85, 2009.

[7] Steven L Brunton, Joshua L Proctor, and J Nathan Kutz. Discovering governing equations from
data by sparse identiﬁcation of nonlinear dynamical systems. Proceedings of the national academy
of sciences, 113(15):3932–3937, 2016.

[8] Nicholas Galioto and Alex Arkady Gorodetsky. Bayesian system id: Optimal management of
parameter, model, and measurement uncertainty. Nonlinear Dynamics, 102(1):241–267, 2020.

16

[9] GF Bomarito, TS Townsend, KM Stewart, KV Esham, JM Emery, and JD Hochhalter. Devel-
opment of interpretable, data-driven plasticity models with symbolic regression. Computers &
Structures, 252:106557, 2021.

[10] Michael D Schmidt and Hod Lipson. Learning noise. In Proceedings of the 9th annual conference

on Genetic and evolutionary computation, pages 1680–1685, 2007.

[11] Seth M Hirsh, David A Barajas-Solano, and J Nathan Kutz. Sparsifying priors for bayesian

uncertainty quantiﬁcation in model discovery. arXiv preprint arXiv:2107.02107, 2021.

[12] Ying Jin, Weilin Fu, Jian Kang, Jiadong Guo, and Jian Guo. Bayesian symbolic regression. arXiv

preprint arXiv:1910.08892, 2019.

[13] Byong-Tak Zhang. Bayesian methods for eﬃcient genetic programming. Genetic Programming

and Evolvable Machines, 1(3):217–242, 2000.

[14] John R Koza and John R Koza. Genetic programming: on the programming of computers by

means of natural selection, volume 1. MIT press, 1992.

[15] Tony Worm and Kenneth Chiu. Prioritized grammar enumeration: symbolic regression by dy-
namic programming. In Proceedings of the 15th annual conference on Genetic and evolutionary
computation, pages 1021–1028, 2013.

[16] Silviu-Marian Udrescu and Max Tegmark. Ai feynman: A physics-inspired method for symbolic

regression. Science Advances, 6(16):eaay2631, 2020.

[17] Brenden K Petersen, Mikel Landajuela Larma, T Nathan Mundhenk, Claudio P Santiago, Soo K
Kim, and Joanne T Kim. Deep symbolic regression: Recovering mathematical expressions from
data via risk-seeking policy gradients. arXiv preprint arXiv:1912.04871, 2019.

[18] Mojtaba Valipour, Bowen You, Maysum Panju, and Ali Ghodsi. Symbolicgpt: A generative

transformer model for symbolic regression. arXiv preprint arXiv:2106.14131, 2021.

[19] William La Cava, Patryk Orzechowski, Bogdan Burlacu, Fabr´ıcio Olivetti de Fran¸ca, Marco
Virgolin, Ying Jin, Michael Kommenda, and Jason H Moore. Contemporary symbolic regression
methods and their relative performance. arXiv preprint arXiv:2107.14351, 2021.

[20] Geoﬀrey Bomarito. Bingo. https://github.com/nasa/bingo, 2022.

[21] Michael Schmidt and Hod Lipson. Comparison of tree and graph encodings as function of problem
complexity. In Proceedings of the 9th annual conference on Genetic and evolutionary computation,
pages 1674–1679, 2007.

[22] Michael Kommenda, Gabriel Kronberger, Stephan Winkler, Michael Aﬀenzeller, and Stefan Wag-
ner. Eﬀects of constant optimization by nonlinear least squares minimization in symbolic re-
gression. In Proceedings of the 15th annual conference companion on Genetic and evolutionary
computation, pages 1121–1128, 2013.

[23] Vinicius Veloso De Melo, Benjamin Fowler, and Wolfgang Banzhaf. Evaluating methods for
constant optimization of symbolic regression benchmark problems. In 2015 Brazilian conference
on intelligent systems (BRACIS), pages 25–30. IEEE, 2015.

[24] Samir W Mahfoud. Niching methods for genetic algorithms. PhD thesis, University of Illinois at

Urbana-Champaign, 1995.

[25] Michael Schmidt and Hod Lipson. Age-ﬁtness pareto optimization.

In Genetic programming

theory and practice VIII, pages 129–146. Springer, 2011.

17

[26] Ole J Mengshoel and David E Goldberg. Probabilistic crowding: Deterministic crowding with

probabilistic replacement. 1999.

[27] Severino F Galan and Ole J Mengshoel. Generalized crowding for genetic algorithms. In Pro-
ceedings of the 12th annual conference on Genetic and evolutionary computation, pages 775–782,
2010.

[28] Iain Murray and Zoubin Ghahramani. A note on the evidence and bayesian occam’s razor. 2005.

[29] Michael Goldstein. Subjective bayesian analysis: principles and practice. Bayesian analysis, 1

(3):403–420, 2006.

[30] James Berger. The case for objective bayesian analysis. Bayesian analysis, 1(3):385–402, 2006.

[31] James O Berger, Jose M Bernardo, and Dongchu Sun. Overall objective priors. Bayesian Analysis,

10(1):189–221, 2015.

[32] Anthony O’Hagan. Fractional bayes factors for model comparison. Journal of the Royal Statistical

Society: Series B (Methodological), 57(1):99–118, 1995.

[33] Pierre Del Moral, Arnaud Doucet, and Ajay Jasra. Sequential monte carlo samplers. Journal of

the Royal Statistical Society: Series B (Statistical Methodology), 68(3):411–436, 2006.

[34] Ralph C Smith. Uncertainty quantiﬁcation: theory, implementation, and applications, volume 12,

page 162. Siam, 2013.

[35] Patrick Leser. SMCPy - Sequential Monte Carlo with Python. https://github.com/nasa/

smcpy, 2022.

[36] Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cour-
napeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, St´efan J. van der
Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson,
Eric Jones, Robert Kern, Eric Larson, C J Carey, ˙Ilhan Polat, Yu Feng, Eric W. Moore, Jake
VanderPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A. Quintero,
Charles R. Harris, Anne M. Archibald, Antˆonio H. Ribeiro, Fabian Pedregosa, Paul van Mul-
bregt, and SciPy 1.0 Contributors. SciPy 1.0: Fundamental Algorithms for Scientiﬁc Computing
in Python. Nature Methods, 17:261–272, 2020. doi: 10.1038/s41592-019-0686-2.

[37] Stillman Drake. Galileo at work: His scientiﬁc biography. Courier Corporation, 2003.

[38] David A Dickey and J Tim Arnold. Teaching statistics with data of historic signiﬁcance: Galileo’s

gravity and motion experiments. Journal of Statistics Education, 3(1), 1995.

[39] Stillman Drake and James MacLachlan. Galileo’s discovery of the parabolic trajectory. Scientiﬁc

American, 232(3):102–111, 1975.

[40] S Shaphiro and M Wilk. An analysis of variance test for normality. Biometrika, 52(3):591–611,

1965.

18

