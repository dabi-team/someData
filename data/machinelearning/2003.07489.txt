Catch the Ball: Accurate High-Speed Motions
for Mobile Manipulators via Inverse Dynamics Learning

Ke Dong1, Karime Pereida1, Florian Shkurti2 and Angela P. Schoellig1

0
2
0
2

r
a

M
7
1

]

O
R
.
s
c
[

1
v
9
8
4
7
0
.
3
0
0
2
:
v
i
X
r
a

Abstract— Mobile manipulators consist of a mobile platform
equipped with one or more robot arms and are of interest for
a wide array of challenging tasks because of their extended
workspace and dexterity. Typically, mobile manipulators are
deployed in slow-motion collaborative robot scenarios. In this
paper, we consider scenarios where accurate high-speed motions
are required. We introduce a framework for this regime of
tasks including two main components: (i) a bi-level motion
optimization algorithm for real-time trajectory generation,
which relies on Sequential Quadratic Programming (SQP) and
Quadratic Programming (QP), respectively; and (ii) a learning-
based controller optimized for precise tracking of high-speed
motions via a learned inverse dynamics model. We evaluate
our framework with a mobile manipulator platform through
numerous high-speed ball catching experiments, where we
show a success rate of 85.33%. To the best of our knowledge,
this success rate exceeds the reported performance of existing
related systems [1], [2] and sets a new state of the art.

I. INTRODUCTION

Mobile manipulators combine mobile platforms and robot
arms. Unlike ﬁxed-base industrial arms, mobile manipulators
have a larger workspace and can deal with more ﬂexible
and complex tasks such as housekeeping, construction, and
airplane assembly [3]. Current research on mobile manipula-
tors mainly focuses on techniques in slow-motion scenarios,
such as kinematics redundancy resolution [4], optimal path
planning [3] and control [5]. However, mobile manipula-
tors are capable of high-speed motions, and thus have the
potential to be used in applications such as industrial high-
speed pick-and-place, or other challenging tasks such as table
tennis [6]. In this paper we focus on high-speed trajectory
generation and accurate tracking for mobile manipulators,
with an emphasis on not compromising accuracy at higher
speeds.

We focus on a benchmark task for accurate high-speed
motions: object catching, speciﬁcally, ball catching. Within
a fraction of a second, the robot needs to (i) predict the ball’s
trajectory, (ii) generate and update a trajectory for graceful
catching, and (iii) accurately track it with the mobile manipu-
lator. There are numerous papers [1], [7], [8], [9] that address
the ball catching problem with a ﬁxed-base manipulator.
However, using a mobile manipulator introduces additional
challenges, due to the interplay between the following three
characteristics:

1 Ke Dong, Karime Pereida and Angela P. Schoellig are with the Dynamic
Systems Lab (www.dynsyslab.org) at the University of Toronto Institute for
Aerospace Studies (UTIAS), and the Vector Institute for artiﬁcial Intelli-
gence, Canada. Email: ke.dong, karime.pereida@robotics.utias.utoronto.ca,
schoellig@utias.utoronto.ca

2 Florian Shkurti

is with Department of Computer Science at

the

University of Toronto, Canada. Email: ﬂorian@cs.toronto.edu

Fig. 1: Ball catching experimental setup. On average, the ball is thrown by
a human operator from a distance of about 4 m towards the robot with a
speed of typically 6 m/s, resulting in a ﬂight time of about 1 s. A video of
the experiment results is available at http://tiny.cc/ball_catch.

Controlling wheel-driven bases: The mobile bases that
are driven by Mecanum wheels [10], as used in this paper,
usually have lower position accuracy than manipulators.
One example is the position accuracy of the Kuka KMR
Quantec driven by Mecanum wheels of ±5 mm [11] while
the accuracy of the UR10 arm is ±0.05 mm [12]. Thus extra
efforts are needed to accurately control the base.

High precision in position and time: Precise end effector
trajectory tracking, both spatially and temporally and in
position and orientation, is a pre-requisite for successful
catching. A precision of 16 mm in position and 3 ms in
time must be achieved in this paper. These parameters vary
depending on the gripper [2].

Real-time computation: On average, the duration of the
ball’s free ﬂight trajectory is one second, which puts a hard
constraint on the computation time of ball prediction, motion
planning and control. Motion planning is very challenging
since complex constraints such as the nonlinear robot dy-
namics and forward kinematics must be considered.

Given the three challenges above, accurate high-speed mo-
tion generation for mobile manipulator ball catching has not
been widely explored, with a few very notable exceptions [2].
In this paper we introduce: (i) a bi-level motion planning
scheme that generates smooth trajectories despite nonlinear
constraints in real time, and (ii) a learning-based controller
improving tracking accuracy and enabling the mobile ma-
nipulator to follow trajectories sufﬁciently accurately. Our
proposed bi-level optimization scheme for motion planning
uses sequential quadratic programming (SQP) to select the
catching pose, and solves a low-level quadratic program

 
 
 
 
 
 
(QP) that generates the trajectory to the catching pose.
Our proposed learning-based controller learns the inverse
dynamics of the system [13] to improve the control accuracy
of the mobile manipulator. We use a modiﬁed Kalman Filter
for improved ball state estimation, which incorporates the
inﬂuence of aerodynamic drag in the state prediction step.

We present a thorough analysis and evaluation of major
components of the system. Experiment data shows that our
bi-level optimization scheme has an average run time of
5.1 ms, and the inverse dynamics learning method can reduce
tracking error up to 79.1%. A success rate of 85.33% of
real robot ball catching task is achieved, which is higher
than the 80% success rate reported in [1], [2]. A video with
experiments showing accurate high-speed motions can be
found at http://tiny.cc/ball_catch.

The contributions of this paper are two-fold. First, we
propose an algorithmic framework to generate and accurately
follow high-speed trajectories with a mobile manipulator.
The proposed framework has a bi-level optimization scheme
for motion planning, which can generate smooth joint trajec-
tories under complex constraints in real-time. Additionally,
the proposed framework has a learning-based controller to
improve the tracking performance of the mobile manipulator.
Our second contribution is the extensive evaluation of the
performance of the proposed framework on the mobile
manipulator, which includes a thorough error analysis of
major components. This framework is tested on real robot
catching experiments and achieves a success rate of 85.33%.
This success requires a tight interplay between different sys-
tem components and hardware constraints. Implementation
details of such a complex system are presented, and should
a resource for similar system designs.

DoF arms and an omnidirectional mobile base. In their work,
the mobile base is restricted to motion in the x axis only.
Further, they use customized hardware capable of high-speed
motions. In contrast, in our work, we achieve high-speed mo-
tions in the x−y plane with the mobile base, which brings the
motion capacity of omnidirectional platforms into full play.
Moreover, we use an off-the-shelf mobile manipulator and
a learning-based controller for improved tracking accuracy,
which makes our approach easy to generalize to other robotic
platforms without the need for customized hardware and low-
level access.

There are numerous works that try to improve the tracking
performance of high-speed and aggressive trajectories. Non-
learning-based methods [5], [14] rely on accurate analytical
system dynamics models, which are hard to obtain. Learning-
based methods mainly focus on learning the system’s dy-
namics or inverse dynamics models [15], [16]. In [16], a
Deep Neural Network (DNN) is used for direct
inverse
control of a quadrotor. However, guaranteeing stability with
a DNN in the control loop can be very difﬁcult. In contrast,
the inverse dynamics learning method from [13] uses a
DNN as an add-on module outside the original closed-loop
system, which is safer in terms of stability.. This method’s
ability for improved, impromptu trajectory tracking has been
demonstrated on quadrotors [13], [17], but not on mobile
manipulators.

III. SYSTEM OVERVIEW AND PROBLEM STATEMENT

This section presents a system overview of the mobile
manipulator and the ﬂying ball. Finally, a formal statement
of the ball catching problem is given.

II. RELATED WORK

A. System Overview

A large body of work has been devoted to ball catching
with a ﬁxed-base manipulator [1], [7], [8], [9], with special
focus on motion planning. Early pioneering work in this
ﬁeld used heuristic methods for selecting the catching point
and generated the joint trajectory via interpolation [7]. Such
methods are simple, as they restrict catching points to a
certain area, but may not ﬁnd the optimal robot motion for
catching. Recent work uses nonlinear optimization methods
for selecting a catching pose, and parameterization methods,
like trapezoidal velocity proﬁle and third-order polynomials,
for path generation for simplicity. In [1], a ball catching sys-
tem consisting of a ﬁxed-base 7 Degree-of-Freedom (DoF)
arm and a four-ﬁnger hand is presented. It uses SQP for
high-level goal selection, and restricts joint trajectories to
trapezoidal velocity proﬁles. In contrast, in our framework,
we do not parameterize the trajectory. Instead, we use a QP
to generate intermediate waypoints which deﬁne smooth and
ﬂexible trajectories. In the realm of high-speed manipulation,
the work in [8] proposes a control law based on dynamical
systems that enables the system to catch fast-moving objects.
However, only ﬁxed-base manipulators are used.

The work most similar to ours is the mobile humanoid
system presented in [2], which consists of two light-weight 7

The mobile manipulator system considered in this paper
consists of a 6-DoF manipulator rigidly mounted on a 3-
DoF omnidirectional mobile base. The yaw rotation of the
mobile base is not used in this work since it is too slow for
the application at hand. Thus the system has 8 DoF in total.
We refer to these DoF as robot joints, for brevity. The joint
conﬁguration vector of the robot is q = [qT
b ](cid:62), where qa =
[θ1, θ2, ..., θ6](cid:62) is a vector containing the arm joint angles
and qb = [xb, yb](cid:62) represents the Cartesian position of the
mobile base. The forward kinematics equations of the mobile
manipulator shown in Fig. 2 are assumed to be known [18].
The ﬂying ball’s motion is modeled as a point mass under
the inﬂuence of aerodynamic drag and gravity. The aerody-
namic drag is proportional to the square of the speed [19].
The ball’s equation of motion can be written as follows:

a , qT

¨b = −g − KD|| ˙b|| ˙b,

(1)

where b = [bx, by, bz](cid:62) is the ball’s Cartesian position in
the world frame and ˙b, ¨b are the corresponding velocity
and acceleration, g = [0, 0, g](cid:62) (g = 9.81) is the gravitational
acceleration, KD is the aerodynamic drag coefﬁcient, and ||·||
is the Euclidean norm.

Fig. 2: The mobile manipulator with the world frame, wF, base frame bF,
arm frame aF and end effector frame eeF is shown. Rotation axes of the
six arm joints are also presented. Adapted from [20].

B. Problem Statement

0 , ˙bT

Given initial robot conﬁguration q0, ball state [bT

0 ]T ,
and time t0, the goal is to catch the ball with the robot’s
end effector at a certain catch time t f > t0. To achieve this,
two conditions need to be satisﬁed: 1) at catch time t f , the
origin of the end effector frame should coincide with the
balls position; and 2) the z axis of the end effector frame
should be aligned with the balls velocity vector. Formally,
these constraints can be written as:

wPee(q f ) = b(t f )
cos(<w zee(q f ), − ˙b(t f ) >) = 1,

(2)

is the robot joint conﬁguration at catch time t f ,
where q f
wPee is the position of the end effector frame’s origin in
the world frame, wzee is the vector of the z axis of the end
effector in the world frame, and < ·, · > refers to the angle
between two vectors.

IV. METHODOLOGY

This section presents the framework we propose, which
includes three main components: (i) ball estimation and
prediction, (ii) bi-level motion planning, and (iii) low-level
control with inverse dynamics learning, as shown in Fig. 3.

A. Ball Estimation and Prediction

The ﬁrst component estimates the ball state and uses it
to generate trajectory predictions within a ﬁnite horizon. To
estimate the ball state sb = [bT , ˙bT ]T , we use a modiﬁed
discrete-time Kalman ﬁlter that considers the inﬂuence of air
drag in the state prediction step, as presented in [19]. In the
state prediction step at the discrete time index k, we predict
the ball state sb[k +1|k] at time step k +1 given measurements
up to time k according to the estimated state at the previous
time step sb[k|k] and motion model in (1) as follows:

¨b[k|k] = −g − KD|| ˙b[k|k]|| ˙b[k|k]

˙b[k + 1|k] = ˙b[k|k] + δk ¨b[k|k]

b[k + 1|k] = b[k|k] + δk ˙b[k|k] +

1
2

δ 2
k

¨b[k|k],

(3)

where δk is the time interval between time index k + 1 and
k. The update step and variance propagation and update are
the same as the vanilla Kalman ﬁlter [21]. The aerodynamic
drag coefﬁcient KD is estimated via a Recursive Least-square
estimator [19] in an off-line fashion.

For the trajectory prediction, given the estimated ball state
ˆsb at time t0, future ball trajectory predictions are made

Fig. 3: Diagram of the overall framework for accurate high-speed ball
catching. Note that the estimation module shown here is for ball state
estimation, with separate, but not shown estimation modules for arm and
base controllers.

via numerically integrating (1) for a ﬁnite horizon. Hence,
ball trajectory predictions will change when a new state
measurement comes, and a new motion plan should be made.
This requires that the motion planner can make new plans in
a very short time (typically 20 ms [9]) so that the information
of the latest ball trajectory prediction can be used in the latest
robot motion plan.

B. Motion Planning

In order to achieve better performance, the mobile plat-
form trajectory needs to be updated when a new ball trajec-
tory prediction is available. The motion planner is bi-level:
1) the high-level planner calculates a feasible and optimal
catching conﬁguration q f and catch time t f that enable the
end effector to intercept the ball’s trajectory at time t f , and
2) the low-level planner generates a smooth joint trajectory
q f (t) that takes the robot from its current to the desired
catch conﬁguration. Moreover,
the motion planner must
take into account kinematic redundancy, collision avoidance,
and robot kinematic and dynamic constraints (e.g. position,
velocity and torque constraints). This problem is a nonlinear
and non-convex optimization problem [9]. Solving such an
optimization problem even off-line is still an open question
in the ﬁeld [1], [9].

To tackle this planning problem in an on-line fashion, we
need to make the following three simpliﬁcations. Similar
simpliﬁcations are also made in the ball catching literature
and work well in experiments [1], [2], [9], [22].
Simpliﬁcation 1 (Arm-base collision): There

no
nearby obstacles and no arm self-collision check; hence,
no obstacle or self-collision check is needed. The only
collision that may happen is the collision between the arm
end effector and the mobile base.

are

This simpliﬁcation is reasonable because during robot
catching experiments, usually the arm will extend to reach
out for a catching. In such a scenario, arm self-collision
is rare but collisions between the arm and mobile base are
possible. Speciﬁcally, to prevent such a collision, we require
the arm end effector to stay inside a semi-cylinder centered
on the arm’s base:

aP2

ee,x(q) + aP2

ee,y(q) ≤ R2

coll
0 ≤ aPee,z(q) ≤ Hcoll,

(4)

where [aPee,x, aPee,y, aPee,z] is the end effector’s position in the
arm frame which can be calculated via forward kinematics

functions given the robot conﬁguration q, Rcoll is the cylin-
der’s radius and Hcoll is the cylinder’s height.

Through experiments, we noticed that as long as the end
effector is inside this semi-cylinder space at catch time, the
whole generated end effector trajectory usually will stay in
that space. Thus constraints in (4) is only checked for q f
instead of every q(t) for t0 ≤ t ≤ t f .

Simpliﬁcation 2 (Kinematic planning): We use kinemat-
ics models to depict
the joint motion, specify objective
functions and constraints on the joint accelerations, instead
of torques.

This simpliﬁcation works in experiments as long as max-
imum joint acceleration values are chosen conservatively
and low-level joint controls work properly. We use a double
integrator as the kinematics model of a single joint and take
joint acceleration as the control input:
(cid:20)qi[k + 1]
(cid:21)
(cid:21) (cid:20)qi[k]
(cid:21)
˙qi[k + 1]
˙qi[k]

(cid:20)1
γ
0 1

(cid:20) 1
2 γ 2
γ

ui[k],

(5)

+

=

(cid:21)

where index i represents the i-th joint, γ is the step size1, and
ui[k] is the control input. To ensure the trajectory feasibility,
we have the following box constraints:

qmin ≤ q[k] ≤ qmax,
˙qmin ≤ ˙q[k] ≤ ˙qmax,
¨qmin ≤ u[k] ≤ ¨qmax,

(6)

where qmin, ˙qmin, ¨qmin, qmax, ˙qmax, ¨qmax are minimum and
maximum value of joint positions, velocities and acceler-
ations, respectively.

Simpliﬁcation 3 (Quadratic cost function): The

cost
functions in the high- and low-level planners are quadratic.
We use quadratic cost functions because they are popular in
the optimization ﬁeld and usually easy to deal with.

With these three simpliﬁcations, we solve the motion plan-
ning problem in a bi-level fashion. The high-level planner
selects the ﬁnal catching conﬁguration q f and catch time t f ,
while including the nonlinear non-convex constraints in (2)
and (4). Given the solution q∗
f ,t∗
f , the low-level path planner
determines the intermediate trajectory waypoints q(tk),t0 <
tk < t f , but is restricted only by the linear constraints in
(5) and (6). This is a quadratic program that can be solved
f ,t∗
very efﬁciently. To ensure that the optimal values (q∗
f )
calculated by the high-level planner are feasible for the
low-level planning problem, a box constraint on q f which
depends on t f and initial robot conditions is deﬁned.

Compared to the parameterization methods used in liter-
ature for the low-level planning problem, like trapezoidal
velocity proﬁles [1], [2] and third-order polynomials [6], the
QP technique we use allows more ﬂexible trajectories due to
the increased number of decision variables. Furthermore, via
constraints of kinematic models in the quadratic program for-
mulation, the generated trajectories are smoother and should
be closer to the robot’s actual behaviors when compared

1The step size γ used for joint motion equations is not necessarily the

same as the step size δk used for the Kalman ﬁlter

to trapezoidal velocity proﬁles and third-order polynomials.
Details on the high- and low-level planners follow.

1) High-level goal planner: Given the initial robot con-
ﬁguration and velocity (q0, ˙q0), ball position and velocity
trajectory prediction (b(t), ˙b(t)) and initial time t0, the high-
level planner aims to ﬁnd the optimal ﬁnal catching conﬁg-
uration and catch time (q∗
f ). Formally, this can be written
as the following optimization problem:

f ,t∗

(q∗

f ,t∗

f ) = arg min

Γh(q f ,t f )

s.t.

q f ,t f
ee,x(q f ) + aP2

aP2
0 ≤ aPee,z(q f ) ≤ Hcoll,
wPee(q f ) = b(t f )

ee,y(q f ) ≤ R2

coll,

(7)

cos(<w zee(q f ), −

˙b(t f )
|| ˙b(t f )||

>) = 1

|q f − q0| ≤ ∆q(q0, ˙q0,t f − t0),

where Γh is a user-deﬁned quadratic cost function for the
high-level planner, and ∆q(q0, ˙q0,t f − t0) is the box con-
straint on q f given initial joint position, velocity and duration
time.

Accurately calculating ∆q(q0, ˙q0,t f −t0) requires calculat-
ing the optimal intermediate waypoints q(t) between q(t0)
and q(t f ) under kinematic constraints (7) for every catch time
guess t f need to be calculated. This is too time-consuming
and an approximation is needed. In this paper, we use the
following approximation:

∆qi(q0,i, ˙q0,i, ∆t) =

(cid:32)

(cid:18)

λ

˙qmax,i

∆t −

˙qmax,i − ˙q0,i
¨qmax,i

(cid:19)

+

max,i − ˙q2
˙q2
0,i
2 ¨qmax,i

(cid:33)

,

(8)

where ∆t = t f − t0 is the duration time, ˙qmax,i, ¨qmax,i are the
maximum velocity and acceleration of the i-th joint, λ ∈
(0, 1) is a proportion parameter that needs to be tuned. The
underlying assumption is that the maximum joint movement
is proportional to the distance that the joint can traverse
under the trapezoidal velocity proﬁle [1]. Namely the joint
ﬁrst accelerates to its maximum speed and holds that speed
until the end. We choose this approximation because of its
simplicity and few corner cases needed to be considered
in implementations. Other trajectory proﬁles like third-order
polynomial can also be used for approximation [6]. The SQP
algorithm is used to solve the problem speciﬁed in (7).

f and catch time t∗

2) Low-level path planner: Given the desired conﬁgura-
tion q∗
f from the high-level goal planner, the
task of the low-level path planner is to generate a sequence
of intermediate trajectory waypoints for each joint.

For the i-th joint, this problem can be formulated as:

(cid:21)
(cid:21) (cid:20)qi[k]
˙qi[k]

(cid:21)

(cid:20) 1
2 γ 2
γ

+

ui[k]

(9)

U∗

i = arg min

Γl(Pi, Ui)

s.t.

=

(cid:20)1
0

Ui
(cid:21)
(cid:20)qi[k + 1]
˙qi[k + 1]

γ
1
qmin,i ≤ qi[k] ≤ qmax,i
˙qmin,i ≤ ˙qi[k] ≤ ˙qmax,i
¨qmin,i ≤ ui[k] ≤ ¨qmax,i
qi[0] = q0,i, ˙qi[0] = ˙q0,i
qi[K] = q∗
f ,i, ˙qi[K] = 0,

where Γl is a user-deﬁned quadratic cost function for the
low-level planner, K = f loor((t∗
f −t0)/γ) is the ﬁnite horizon
and f loor(x) returns the greatest integer less than or equal
to x, Pi = [qi[1], · · · , qi[K]]T and Ui = [ui[1], · · · , ui[K]]T are
the position and control input sequence of the i-th joint.

This is an optimal control problem that consists of
quadratic cost functions and linear constraints. Standard
quadratic programming methods can be used to solve this
problem efﬁciently [23]. With the solution of optimal control
input sequence Ui and initial conditions qi[0] = q0,i, ˙qi[0] =
˙q0,i, the optimal position sequence Pi can be constructed via
the kinematic model in (5).

C. Low-level Joint Control

Given the desired position trajectories generated by the
motion planners, the task of the low-level joint controllers is
to accurately track the trajectory. Accurate trajectory tracking
is challenging due to the high-speed joint trajectories re-
quired for successful ball catching. Moreover, joint trajectory
replanning may introduce discontinuities into the desired
trajectories, which may be harder to track. To overcome these
problems, we use the inverse dynamics learning technique
developed in [13], shown in Fig. 4. It uses DNNs as an add-
on block to baseline feedback control systems to achieve a
unity map between desired and actual outputs.

This method learns an inverse dynamics model of the
baseline closed-loop system: ˆy[k] = f (x[k], x[k + r]), where
x[k] is the system’s discrete state at time index k, ˆy[k] is the
reference signal to the baseline control system, and r is the
relative degree [13]. For discrete-time systems, the vector
relative degree can be intuitively understood as the number
of time steps before a change in the input is reﬂected in the
output, which can be easily determined experimentally from
the systems step response [13].

Speciﬁcally, for a single robot joint of the mobile manip-

ulator, the DNN’s inputs and outputs are:

j [k + 1] = NN(q[k], yd
ˆyd

j [k + r]) ,

(10)

where yd
j [k] is the reference signal sampled from desired
trajectories for the j-th joint at time index k, and ˆyd
j [k + 1] is
the DNN’s modiﬁed reference signal. As mentioned in [13],
subtracting yd
j [k + 1] from both the inputs and outputs of
the neural network can improve the DNN’s generalization
ability since only the reference signal offsets ˜yd
j [k + 1] =

Fig. 4: A diagram of the inverse dynamics learning framework and the
training phase. The DNN module modiﬁes the reference signal
to the
baseline system for trajectory tracking performance improvement. Adapted
from [13].

j [k + 1] instead of the reference signal itself

ˆyd
j [k + 1] − yd
ˆyd
j [k + 1] are learned:
j [k + 1] = NN(q[k] − yd
˜yd

j [k + 1], yd

j [k + r] − yd

j [k + 1]) . (11)

The modiﬁed position reference signal can then be sent to
the baseline control system to actuate the robot joint.

V. FRAMEWORK IMPLEMENTATION AND EVALUATION

This section presents implementation details and evalua-

tion of each of the three framework components.

A. Ball Estimation and Trajectory Prediction

First, we describe the implementation details of the ball
state estimation and trajectory prediction. The modiﬁed
Kalman ﬁlter, stated in Section IV-A, is used to reduce
noise in VICON position and velocity measurements. In ex-
periments, VICON position measurements are very precise.
Therefore, ball state estimation consists of position mea-
surements from the VICON system and velocity estimation
from the Kalman ﬁlter. Trajectory prediction is done through
numerical integration with a step size of 0.1 ms.

Both the Kalman ﬁlter (3) and trajectory prediction (1)
need an estimate of the aerodynamic drag coefﬁcient KD.
To estimate it, we record ball state data from 20 random
ball tosses and use a recursive least-squares estimator. The
estimated value of KD is 0.0238 m−1.

B. Motion Planning

We ﬁrst describe the implementation details of the high-
level and low-level motion planner. The goal of the high-level
planner is to ﬁnd a catch conﬁguration q f and catch time t f
while minimizing the robot movement:

Γh(q f ,t f ) = wa(cid:107)qa,0 − qa, f (cid:107)2

2 + wb(cid:107)qb,0 − qb, f (cid:107)2
2 ,

(12)

where wa, wb are weight parameters that penalize movement
of the arm joints and the mobile base, respectively. As
mentioned in Section II, control accuracy of the mobile
base is usually lower than the arm [11], [12]. Therefore, we
select wa = 1, wb = 5 to reduce the mobile base motion. The
proportion parameter used in the high-level planner (8) is set
to be λ = 0.4. The high-level planner uses the SQP algorithm

which we implemented using the NLopt c++ library [24].
The initial guess for the optimization variables (q f ,t f ) are
the robot’s current conﬁguration and a hard-coded catch time
guess t f = 0.5 s.

The goal of the low-level planner is to generate a smooth
trajectory from current conﬁguration q0 to catch conﬁgu-
ration q f . This is achieved by penalizing joint acceleration
change from one time step to the next during the trajectory,
which can be written as follows for the i-th joint:

Γl(Pi, Ui) =

K−1
∑
k=0

||ui[k + 1] − ui[k]||2
2 ,

(13)

where K is calculated according to Section IV-B.2, and the
discretization step size is γ = 0.05 ms. We solve the QP in
the low-level planner with qpOASES c++ library [25].

We use numerical experiments to evaluate the motion
planner’s performance since we cannot control the ball initial
state in real experiments when the ball is thrown by a human
operator. We generated 2560 initial ball state samples, whose
positions are uniformly distributed in a circle around the
robot. In order to ensure that the resulting ball trajectories
are feasible given the robot’s motion constraints, we ﬁrst note
that the end effector can move 0.65 m in 0.86 s, as described
in Section VI-B. We restrict the initial ball states to be such
that after 0.7 s the ball is predicted, via numerical integration
of (1), to be located inside a 0.25 m diameter sphere centered
around the end effector of the given robot conﬁguration.

The proposed motion planner can ﬁnd a trajectory for
95.23% of all initial ball samples. The average computation
time is 5.10 ms, with 4.80 ms used for the high-level non-
linear planner, and 0.3 ms used for the low-level (quadratic
program) planner on an Intel Xeon CPU i7-8850H 2.60GHz
computer. No sophisticated techniques like multi-threaded
programming are used to speed up computation time.

C. Low-level Control

We ﬁrst describe the implementation of the learning-based
low-level controller. We ﬁrst estimate experimentally the
relative degree r of each joint, which is 8 for arm joints
and 14 for mobile base joints.

To learn the mapping function in (11), we train 8
DNNs, one for each joint. Each DNN consists of two
hidden layers and each layer contains 10 neurons. The
ReLU function is used as the activation function. To cre-
ate the training and testing dataset, we use the low-level
path planner (described in Section IV-B.2) to generate tra-
jectories similar to those used in real ball catching ex-
periments. We characterize these trajectories by bounding
the maximum joint displacement ∆q in a given amount
of time ∆t. In our experiments we set ∆t = 2s, 3s, 4s,
trajectories with different speeds and ∆q =
to represent
[1.36, 1.36, 1.36, 1.75, 1.75, 2.53, 0.76, 0.76]T , where the ﬁrst
six joint displacements correspond to the arm and are
speciﬁed in radians, and the last two joint displacements
correspond to the mobile base and are speciﬁed in meters.

The trajectories are executed using the robot’s baseline
control system. It consists of off-board PD controllers that

generate desired joint velocities and on-board controllers of
the UR10 arm and mobile base that turn desired velocities
into joint torques (UR10 arm) or wheel rotation velocities
(mobile base). In this way we collect a dataset with 1000
data pairs for each joint. The dataset is divided with 80%
is used for training and the rest is used for validation. We
use Adam optimizer implemented in Tensorﬂow to train the
neural network with 50 training iterations.

To test

the inﬂuence of inverse dynamics learning on
tracking performance, we generate testing trajectories by
setting ∆q = [0.8, 0.8, 0.8, 1.1, 1.1, 1.1, 0.20, 0.20]T and ∆t =
1 s, which are different from training and validation trajec-
tories in the dataset. The testing trajectories are executed
ten times each when the robot uses the learning technique
and ten times each when no learning technique is used. The
trajectory tracking rooted-mean-squared error (RMSE) over
the ten trajectories is shown in Table I. It can be seen that
the inverse dynamics learning method can reduce tracking
errors between 35% ∼ 80% with the highest error reduction
corresponding to the mobile base.

TABLE I: Joint trajectory tracking error comparison

Joint With DNN [◦] Without DNN [◦]

Reduction

arm 1
2
3
4
5
6

0.0218
0.0300
0.0264
0.0309
0.035
0.034

0.0508
0.0508
0.0506
0.0561
0.0562
0.0561

57.2%
40.9%
47.8%
45.0%
36.5%
37.1%

Joint With DNN [m] Without DNN [m]

Reduction

base x
y

0.0041
0.0047

0.0196
0.0183

79.1%
74.0%

VI. EXPERIMENTS

This section presents the experimental setup and ball
catching experimental results. A video demonstrating the
real robot experiments can be found at http://tiny.cc/
ball_catch.

A. Experimental Setup

The mobile manipulator used in this experiment consists
of a 6-DOF UR10 arm and a 3-DOF Ridgeback omnidi-
rectional mobile base driven by four Mecanum wheels. We
use symmetric joint motion boundary values, i.e. qmin =
−qmax, ˙qmin = − ˙qmax, ¨qmin = − ¨qmax. The six arm joints have
the same maximum joint positions of 180◦ and accelerations
of 458◦/s2. Their maximum joint velocities are 103◦/s,
103◦/s, 103◦/s, 126◦/s, 126◦/s, and 180◦/s for arm joint
1 ∼ 6 respectively. The maximum positions, velocities and
accelerations of the mobile base in the x and y axes are 3m,
1.0m/s, 2.5m/s2, respectively.

The three-ﬁnger end effector grasps a 94.90 mm diameter
is used to catch the ball, as shown in
metal cup that
Fig. 5. The proposed framework is implemented via Robot
Operation System (ROS) and runs on a ThinkPad P52 laptop.
The ball used in these experiments is a standard 61.76 mm
tennis ball with a weight of 81.76 g. The ball is wrapped

Fig. 5: The 61.76 mm diameter ball and 94.90 mm diameter cup used in this
paper. The position accuracy requirement in the x, y, z axes is approximately
(94.90−61.76)/2 = 16.57 mm. The typical speed at the catch time is around
5 m/s, leading to the 16.57/5 ≈ 3 ms time precision requirement.

with retro-reﬂective tape in order to be visible to the VICON
motion capture system, which provides position and velocity
measurements to be used in the ball state estimation module.

B. Ball Catching Experiment

We conducted experiments to test three main characteris-
tics of the proposed framework: (i) ball catching success rate,
(ii) impact of the learning-based controller, and (iii) impact
of QP-based low-level planner.

1) Experiment A: Ball Catching Success Rate:

In this
experiment, we use the framework proposed in Section IV
and throw balls from different locations while the robot
has different initial conﬁgurations. Three initial robot con-
ﬁgurations are chosen. For each initial robot conﬁguration,
we throw the ball from ﬁve different locations, ﬁve throws
for each location, for a total of 75 ball catching experi-
ments. All ball trajectories are shown in Fig. 6. Of the 75
ball throws, 65 balls are caught successfully by the robot,
which is a 85.33% success rate. The end effector posi-
tion trajectory tracking RMSE over the 75 experiments are
11.03 mm, 14.01 mm, 13.25 mm for x, y, z axes respectively.
Among the successful catches, the maximum end effector
displacement in a catch is 0.65 m in 0.86 s with a mobile
base displacement of 0.26 m in that catch. The corresponding
arm and base position trajectories for this catch are shown
in Fig. 7a and 7b. It can be seen that our mobile base is
able to move accurately in both x and y directions while the
humanoid in [2] can only move in one direction.

2) Experiment B: Impact of Learning-based Controller:
In this experiment, we are interested in showing that the
learning-based controller improves tracking performance,
therefore improving the success rate of the overall frame-
work. It is hard to repeat a ball trajectory twice because a
human throws it. To do a fair comparison in this experiment
we throw balls from the same location (2.5, 2.0, 0) while
the robot has the same initial conﬁguration, as shown in
Fig. 1. We make 40 throws when the robot uses inverse
dynamics learning and 40 when the robot does not use
inverse dynamics learning for a total of 80 throws. The
success rate for this particular conﬁguration is 75% when
using inverse dynamics learning and 65% when not using
it. The ten percent decrease shows the effectiveness of

Fig. 6: Ball trajectories of Experiment A. Starting from the left corner and
in the anti-clockwise direction, the ﬁve ball throwing positions in the xy
plane in meters are (2.8, −3.1), (2.9, 0.0), (2.5, 2.0), (0.0, 2.8), (−2.0, 2.0).
Ball trajectories are colored according to its throwing location.

(a)

(b)

Fig. 7: An example of (a) arm joint and (b) mobile base tracking per-
formance. Dashed lines represent desired trajectories, while solid lines
represent actual trajectories. For a better illustration effect, we subtract initial
values from trajectory waypoints, and thus joint angles relative to their initial
values are shown here.

inverse dynamics learning. Note that the success rate for
this particular conﬁguration is lower than the success rate in
Experiment A. Visual inspection of the data and video show
that the geometrical setup, i.e. ball throwing location and
robot initial conﬁguration, used in this experiment requires
more robot maneuvers than other geometrical setups used in
Experiment A.

3) Experiment C: Impact of QP-based Low-level Planner:
In this experiment, we are interested in showing the impact of
the QP-based low-level planner in the ball catching success
rate. To do this, we implemented the trapezoidal velocity
proﬁle method in [1] for the low-level planner, and tested

X[m]−2−1012Y[m]−3−2−1012Z[m]0.61.11.62.12.60.00.20.40.60.8Time[s]−0.50−0.250.000.250.50Jointangle[rad](1)(2)(3)(4)(5)(6)(1)(2)(3)(4)(5)(6)0.00.20.40.60.8Time[s]−0.25−0.20−0.15−0.10−0.050.00Baseposition[m]xyxyit by throwing 40 balls with the geometrical setup as in
Experiment B. Note that the inverse dynamics learning is still
used. The robot achieves a success rate of 72.5%, similar to
the success rate of 75% when using the QP method.

The QP method does not have a signiﬁcant impact on ball
catching success rate. One possible reason is that the way the
robot accelerates and decelerates does not have a large impact
on the ball catching success due to the short duration of the
trajectory [1]. However, the QP method does allow for more
ﬂexible and smooth trajectories, which may improve the
performance of tasks with longer duration. Finally, similar
success rates with the two different low-level planners may
be due to the high accuracy of the learning-based controller
when tracking arbitrary trajectories.

C. Failure analysis

The success of ball catching tasks requires a tight in-
tegration of every system component. The malfunction of
any component will result in a failure. Among all throws in
Experiment A, B, C, failure has occurred for the following
reasons: inaccurate ball trajectory prediction, large tracking
errors, and failure to ﬁnd feasible solutions of the high-
level planning problem. Large tracking errors occur when
maneuvers are too aggressive and overshooting happens. We
could improve this by penalizing aggressive trajectories.

VII. CONCLUSION

We presented a framework for accurate high-speed motion
generation and execution on mobile manipulators with the
application scenario of ball catching. A modiﬁed Kalman
ﬁlter that considers aerodynamics is used for estimating
the ball’s velocity, and ball trajectory prediction is done
via numerical integration. A bi-level optimization scheme
is proposed to handle complex trajectory requirements in
real-time, with an average run time of 5.1 ms. The high-
level goal planning problem is formulated as a non-linear
optimization problem and solved by SQP. The low-level
path planning problem is solved by QP for more ﬂexible
and smooth trajectories. The joint control
is driven by
an inverse dynamics learning method. This learning-based
controller reduces joint tracking errors by up to 79.1%, which
translate into a 10% increase in success rate compared to a
non-learning-based joint controller. The proposed framework
is validated via extensive real robot catching experiments
under different conﬁgurations and achieves a success rate of
85.33%, setting a new state of the art. In future work we aim
to focus on dynamic planning instead of kinematic planning,
which should improve the feasibility of joint trajecotries.

REFERENCES

[1] B. B¨auml, T. Wimb¨ock, and G. Hirzinger, “Kinematically optimal
catching a ﬂying ball with a hand-arm-system,” in Proc. of
the
IEEE/RSJ International Conference on Intelligent Robots and Systems
(IROS), 2010, pp. 2592–2599.

[2] B. B¨auml, O. Birbach, T. Wimb¨ock, U. Frese, A. Dietrich, and
G. Hirzinger, “Catching ﬂying balls with a mobile humanoid: Sys-
tem overview and design considerations,” in Proc. of the IEEE-RAS
International Conference on Humanoid Robots.
IEEE, 2011, pp.
513–520.

[3] D. M. Bodily, T. F. Allen, and M. D. Killpack, “Motion planning
for mobile robots using inverse kinematics branching,” in 2017 IEEE
International Conference on Robotics and Automation (ICRA).
IEEE,
2017, pp. 5043–5050.

[4] A. De Luca, G. Oriolo, and P. R. Giordano, “Kinematic modeling
and redundancy resolution for nonholonomic mobile manipulators,”
in Proc. of
the IEEE International Conference on Robotics and
Automation (ICRA).

IEEE, 2006, pp. 1867–1873.

[5] L.-P. Ellekilde and H. I. Christensen, “Control of mobile manipulator
using the dynamical systems approach,” in Proc. of the IEEE Interna-
tional Conference on Robotics and Automation (ICRA).
IEEE, 2009,
pp. 1370–1376.

[6] O. Koc¸, G. Maeda, and J. Peters, “Online optimal trajectory generation
for robot table tennis,” Robotics and Autonomous Systems, vol. 105,
pp. 121–137, 2018.

[7] U. Frese, B. Bauml, S. Haidacher, G. Schreiber, I. Sch¨afer, M. Hahnle,
and G. Hirzinger, “Off-the-shelf vision for a robotic ball catcher,” in
Proc. of the IEEE/RSJ International Conference on Intelligent Robots
and Systems (IROS), vol. 3, 2001, pp. 1623–1629.

[8] S. S. Mirrazavi Salehian, M. Khoramshahi, and A. Billard, “A dynam-
ical system approach for catching softly a ﬂying object: Theory and
experiment,” IEEE Transaction on Robotics, 2016.

[9] R. Lampariello, D. Nguyen-Tuong, C. Castellini, G. Hirzinger, and
J. Peters, “Trajectory planning for optimal robot catching in real-
time,” in Proc. of the IEEE International Conference on Robotics and
Automation (ICRA).

IEEE, 2011, pp. 3719–3726.

[10] P. A. Flores ´Alvarez, “Modelling, simulation and experimental ver-
iﬁcation of a wheeled-locomotion system based on omnidirectional
wheels,” Master’s thesis, Pontiﬁcia Universidad Cat´olica del Per´u,
Ilmenau, Germany, 2016.

[11] KUKA, “Mobile robotics kmr quantec,” https://www.kuka.com/en-ca/
products/mobility/mobile-robots/kmr-quantec, [Online; accessed 20-
February-2020].

[12] U.

Robots,

“Technical

speciﬁcations

universal-robots.com/media/50880/ur10{ }bz.pdf,
20-February-2020].

ur10,”

https://www.
[Online; accessed

[13] S. Zhou, M. K. Helwa, and A. P. Schoellig, “Design of deep neural
networks as add-on blocks for improving impromptu trajectory track-
ing,” in Proc. of the IEEE Conference on Decision and Control (CDC),
2017, pp. 5201–5207.

[14] H. Seraji, “A uniﬁed approach to motion control of mobile manipula-
tors,” The International Journal of Robotics Research, vol. 17, no. 2,
pp. 107–118, 1998.

[15] A. Punjani and P. Abbeel, “Deep learning helicopter dynamics mod-
els,” in Proc. of the IEEE International Conference on Robotics and
Automation (ICRA).

IEEE, 2015, pp. 3223–3230.

[16] M. T. Frye and R. S. Provence, “Direct inverse control using an
artiﬁcial neural network for the autonomous hover of a helicopter,”
in Prof of the IEEE International Conference on Systems, Man, and
Cybernetics (SMC).

IEEE, 2014, pp. 4121–4122.

[17] Q. Li, J. Qian, Z. Zhu, X. Bao, M. K. Helwa, and A. P. Schoellig,
“Deep neural networks for improved, impromptu trajectory tracking of
quadrotors,” in Proc. of the IEEE International Conference on Robotics
and Automation (ICRA).

IEEE, 2017, pp. 5183–5189.

[18] K. P. Hawkins, “Analytic inverse kinematics for the universal robots
ur-5/ur-10 arms,” Georgia Institute of Technology, Tech. Rep., 2013.
[19] M. M¨uller, S. Lupashin, and R. D’Andrea, “Quadrocopter ball jug-
gling,” in Proc. of the IEEE/RSJ international conference on Intelligent
Robots and Systems.

IEEE, 2011, pp. 5113–5120.

[20] M. Jakob, “Position and force control with redundancy resolution
for mobile manipulators,” Master’s thesis, University of Stuttgart,
Stuttgart, Germany, 2018.

[21] T. D. Barfoot, State estimation for robotics. Cambridge University

Press, 2017.

[22] S. Kim, A. Shukla, and A. Billard, “Catching objects in ﬂight,” IEEE

Transactions on Robotics, vol. 30, no. 5, pp. 1049–1065, Oct 2014.

[23] S. Boyd, S. P. Boyd, and L. Vandenberghe, Convex optimization.

Cambridge university press, 2004.

[24] S. G. Johnson, “The nlopt nonlinear-optimization package,” http:
//github.com/stevengj/nlopt, [Online; accessed 20-February-2020].
[25] H. Ferreau, C. Kirches, A. Potschka, H. Bock, and M. Diehl,
“qpOASES: A parametric active-set algorithm for quadratic program-
ming,” Mathematical Programming Computation, vol. 6, no. 4, pp.
327–363, 2014.

