RL-Based User Association and Resource
Allocation for Multi-UAV enabled MEC

Liang Wang∗, Peiqiu Huang†, Kezhi Wang∗, Guopeng Zhang‡, Lei Zhang§, Nauman Aslam∗ and Kun Yang¶
∗Department of Computer & Information Sciences, Northumbria University, Newcastle upon Tyne, UK
†School of Informacion Science & Engineering, Central South University, China
‡School of Computer Science & Technology, China University of Mining and Technology, China
§School of Engineering, University of Glasgow, UK
¶University of Electronic Science and Techology of China, Zhongshan Institute, China
¶School of Computer Science & Electronic Engineering, University of Essex, UK

9
1
0
2

r
p
A
8

]
I

N
.
s
c
[

1
v
1
6
9
7
0
.
4
0
9
1
:
v
i
X
r
a

Abstract—In this paper, multi-unmanned aerial vehicle (UAV)
enabled mobile edge computing (MEC), i.e., UAVE is studied,
where several UAVs are deployed as ﬂying MEC platform to
provide computing resource to ground user equipments (UEs).
Compared to the traditional ﬁxed location MEC, UAV enabled
MEC (i.e., UAVE) is particular useful
in case of temporary
events, emergency situations and on-demand services, due to its
high ﬂexibility, low cost and easy deployment features. However,
operation of UAVE faces several challenges, two of which are
how to achieve both 1) the association between multiple UEs
and UAVs and 2) the resource allocation from UAVs to UEs,
while minimizing the energy consumption for all the UEs. To
address this, we formulate the above problem into a mixed
integer nonlinear programming (MINLP), which is difﬁcult to
be solved in general, especially in the large-scale scenario.
We then propose a Reinforcement Learning (RL)-based user
Association and resource Allocation (RLAA) algorithm to tackle
this problem efﬁciently and effectively. Numerical results show
that the proposed RLAA can achieve the optimal performance
with comparison to the exhaustive search in small scale, and have
considerable performance gain over other typical algorithms in
large-scale cases.

Index Terms—Reinforcement Learning, Mobile Edge Com-
puting, Unmanned Aerial Vehicle, User Association, Resource
Allocation

I. INTRODUCTION

Nowadays, user equipments (UEs) such as smart phones,
tablets, wearable devices and other Internet of smart things are
becoming increasingly popular and bringing huge convenience
to our daily life. Moreover, many emerging mobile applica-
tions (e.g., augmented reality, smart navigation and interactive
service) are receiving more and more attention but most of
those applications are resource intensive, which makes the
UEs very difﬁcult to execute them, due to limited battery and
computation resource (e.g. CPU, storage or memory) in UEs.
Fortunately, mobile edge computing (MEC) has recently
been proposed as a means to enable UEs with intensive
computational tasks to ofﬂoad them to the edge cloud, which
can not only prolong the battery life of UEs, but also increase
UEs’ computational capacity. Ofﬂoading decision making and
resource allocation have been studied in [1], [2], while MEC
with Cloud Radio Access Network (C-RAN) has been investi-
gated in [3], [4], [5]. The above works either consider there is

only one MEC (e.g., [1], [7]), or consider the MECs have ﬁxed
location (e.g., [8], [3]), which may not be practical in some
scenarios. For instance, the single MEC is normally resource-
limited and may not be able to meet the requirement of all
the UEs at the same time. Also, MEC with ﬁxed location
lacks ﬂexibility and may not be suitable to the cases where
the number and the requirement of UEs keep changing.

Unmanned aerial vehicle (UAV), due to the features of
low cost, high ﬂexibility and easy to deployment, have re-
cently attracted much attention in wireless communication,
e.g., serving as base station [9] or mobile relays [10]. UAV
enabled MEC (e.g., [6]) have been proposed by integrating
MEC server to UAVs (i.e., UAVE), to provide computing
resource to ground UEs. Compared with the traditional ﬁxed
location MEC, UAVE is of particular interest to the scenario
such as 1) temporary events (i.e., in case of a large number
of people gathering in the ground celebrating a big event
or watching football match); 2) emergency situations (i.e., in
case of earthquake and the infrastructure may be destroyed or
temporary unavailable) or other on-demand services. However,
the operation of UAVE faces many challenges, two of which
are how to achieve 1) the association between multiple UEs
and UAVs and 2) the resource allocation from the UAVs
to the UEs, while meeting the quality of service (QoS) and
minimizing the whole energy consumption for all the UEs.

To address these challenges, we formulate above problem
into a mixed integer non-linear programming (MINLP), which
is very difﬁcult
to be addressed in general, especially in
the large-scale scenario (e.g., when there is a large num-
ber of UEs in the ground waiting to be served). We then
propose a Reinforcement Learning-based user Association
and resource Allocation (RLAA) algorithm to deal with this
problem efﬁciently and effectively. Numerical results show
that the proposed RLAA can achieve the optimal performance
compared to the exhaustive search in small scale, and have
considerable performance gain over other typical algorithms
in large-scale scenarios.

The rest of the paper is organized as follows. We show
the system model and the optimization problem in Section II.
Then, our proposed RLAA algorithm is introduced in Section

 
 
 
 
 
 
Also, assume that the j-th (j ∈ M) UAV can serve more
than one UE in each time slot and this task has to be completed
either via ofﬂoading or local execution. Therefore, one can
have

M
(cid:88)

C2 :

Tj
(cid:88)

aijt = 1, ∀i ∈ N

(3)

j=0

t=0

A. Task Ofﬂoading

In ofﬂoading scenario, we assume the horizontal distance

between i-th UE and the j-th UAV in t-th time slot as

Rijt =

(cid:113)

(Xjt − xi)2 + (Yjt − yi)2

(4)

Then, the ofﬂoading data rate can be given by

Fig. 1. A Multi-UAV enabled MEC system

III. The simulation result is given in Section IV, followed by
the conclusion remarks in Section V.

rijt = B log2(1 +

αP T r
i
jt + R2
ijt

H 2

), ∀i ∈ N , j ∈ M, t ∈ Tj

(5)

II. SYSTEM MODEL
As shown in Fig. 1, we consider there are i ∈ N =
{1, 2, ..., N } UEs, each of which has a computation-intensive
task to be executed. Also, we consider there are j ∈ M =
{1, 2, ..., M } UAVs deployed as the MEC platform, ﬂying in a
circle with radius Rj. Deﬁne a new vector j ∈ M(cid:48) = {0, M}
to denote the possible place where the tasks from ground
UEs can be executed at, in which j = 0 denotes that UE
conducts task itself without ofﬂoading. Similar to [6], we
assume that the j-th UAV’s ﬂight period can be discretized
into t ∈ Tj = {1, 2, ..., Tj} time slots. Deﬁne a new vector
t ∈ T (cid:48)
j = {0, Tj} to denote the possible time slots when the
tasks from ground UEs can be executed at, in which t = 0
denotes that UE conducts task itself. Also we assume that the
UAV’s location change within each time slot can be ignored,
compared to the distances from the UAV to all UEs.

Denote the coordinate of the j-th UAV at t-th time slot as
[Xjt, Yjt, Hjt] and the coordinate of the i-th UE as [xi, yi, 0].
Similar to [3], assume i-th UE has a computational intensive

task Ii to be executed as

Ii = (Di, Fi), ∀i ∈ N

(1)

where Fi denotes the total number of CPU cycles required to
complete this task and Di denotes the amount of data needed
to be transmitted to UAV if deciding to ofﬂoad, in which Di
and Fi can be obtained by using the approaches provided
in [11]. Assume that each UE can decide either to execute
the task locally or choose to ofﬂoad to one of the UAVs in
one time slot and also assume that the task can be completed
in this time slot. Similar to [1], we do not consider the time
for returning the results back to UE from UAV. Thus, one can
have

C1 : aijt = {0,1}, ∀i ∈ N , j ∈ M(cid:48), t ∈ T (cid:48)
j

(2)

where aijt = 1, j (cid:54)= 0, t (cid:54)= 0 denotes that the i-th UE choose
the j-th UAV in the t-th time slot to ofﬂoad, while aijt = 1,
j = 0, t = 0 denotes that i-th UE execute the task itself and
otherwise, aijt = 0. Note that t = 0, if and only if j = 0.

where B is denoted as the channel bandwidth, P T r
as the
i
transmission power of the i-th UE, α= g0G0
σ2 , G0 ≈ 2.2846, g0
as the channel power gain at the reference distance 1 m and
σ2 as the noise power [12].

Also, one can see that the time to ofﬂoad the data from i-th

UE to the j-th UAV in t-th time interval can be given as

T T r
ijt =

Di
rijt

, ∀i ∈ N , j ∈ M, t ∈ Tj

(6)

Also, the time to execute the task can be expressed as

T C
ijt =

Fi
fijt

, ∀i ∈ N , j ∈ M, t ∈ Tj

(7)

where fijt is the computation resource that the jth UAV could
provide to the i-th UE. Then, we can have the total time
consumption as

Tijt = T T r

ijt + T C

ijt, ∀i ∈ N , j ∈ M, t ∈ Tj

(8)

Moreover, the total energy consumption of the i-th UE to the
j-th UAV in t-th time slot can be given as

ET r

ijt = P T r

i T T r

ijt , ∀i ∈ N , j ∈ M, t ∈ Tj

(9)

Similar to [1], we assume each UAV in every time slot can
only accept limited amount of ofﬂoaded task. Then, one has

C3 :

N
(cid:88)

i=1

aijt ≤ K, ∀j ∈ M, t ∈ Tj

(10)

where K is the maximal number of UEs that each UAV can
accept in each time slot.

B. Local Execution

If the UE decides to execute the task locally, the power
consumption for the i-th UE can be given by ki(fijt)vi, where
j = 0, t = 0, and ki ≥ 0 is the effective switched capacitance
and vi can be normally to 3 [1]. Then, the local execution
ijt = Fi
time can be given by T C
, (j = 0, t = 0) and then, the
fijt
total energy consumption can be given as ki(fijt)viT C
ijt.

C. Problem Formulation

III. PROPOSED ALGORITHM

Then, one can have the energy consumption of each UE as

Eijt =

(cid:40)

ki(fijt)viT C
ijt,
i T T r
P T r
ijt ,

if j = 0, t = 0
if j ∈ M, t ∈ Tj

(11)

the total

Also,
expressed as

time spent

to complete each task can be

Tijt =

(cid:40)

T C
ijt,
ijt + T C
T T r
ijt,

if j = 0, t = 0
if j ∈ M, t ∈ Tj

(12)

In this section, we show our proposed RLAA algorithm.
First, we introduce three important elements in RLAA (i.e.,
actions, states, and reward functions).

• Actions: At each episode eps, each UE takes an action.
If the UE decides to ofﬂoad the task to the j-th UAV
in t-th time interval, the action is denoted as ρjt, ∀j ∈
M, t ∈ Tj. If UE decides to execute the task locally, the
action is as ρ00. Then, one can deﬁne the collection of
actions as follows:

One can assume that the maximal computation resource which
the j-th UAV can provide is as f max

. Then, one can have

j

C4 :

N
(cid:88)

i=1

aijtfijt ≤ f max

j

, ∀j ∈ M, t ∈ Tj

(13)

Also, as the task normally has to be completed in certain
amount of the time and thus without loss of generality, we
assume the task must be completed in time T max without
loss of generality. In our paper, assume all the transmitting
and computing process for each task must be completed within
one time interval T max, Then, we have

C5 :

M
(cid:88)

j=0

aijtTijt ≤ T max, ∀i ∈ N , t ∈ T (cid:48)
j

(14)

Denote A = {aijt, ∀i ∈ N , j ∈ M(cid:48), t ∈ T (cid:48)
j }. Then, one can have

{fijt, ∀i ∈ N , j ∈ M(cid:48), t ∈ T (cid:48)

j }, F =

N
(cid:88)

M
(cid:88)

Tj
(cid:88)

aijtEijt

P :min
A,F

t=1

j=0

i=1
subject to
C1 : aijt ∈ {0, 1}, ∀i ∈ N , j ∈ M(cid:48), t ∈ T (cid:48)
j

M
(cid:88)

Tj
(cid:88)

j=0

t=0

aijt = 1, ∀i ∈ N

aijt ≤ K, ∀j ∈ M, t ∈ Tj

(15a)

(15b)

(15c)

(15d)

(15e)

aijfijt ≤ f max

j

, ∀j ∈ M, t ∈ Tj

(15f)

aijtTijt ≤ T max, ∀i ∈ N , t ∈ T (cid:48)
j

(15g)

Note that the above problem P is a MINLP problem, which
is difﬁcult to be solved optimally in general. Some existing
algorithms like exhaustive search or branch and bound algo-
rithm may solve this problem, but with prohibitive complexity.
Therefore, in this paper, we aim to obtain an efﬁcient solution
to solve this problem. To this end, we propose the RLAA
algorithm to deal with P effectively and efﬁciently.

C2 :

C3 :

C4 :

C5 :

N
(cid:88)

i=1
N
(cid:88)

i=1
M
(cid:88)

j=0

C = {ρ00, ρ11, ..., ρ1T1 , ..., ρM 1, ..., ρM TM }.

(16)

For above ofﬂoading action ρjt, ∀j ∈ M, t ∈ Tj, the
minimal computation resources of the i-th UE can be
given by

f min
ijt =

Fi
T max − Di
rijt

, ∀j ∈ M, t ∈ Tj

(17)

For local execution action ρ00, the minimal computation
resources of the i-th UE is given as

f min
ijt =

Fi
T max , j = 0, t = 0

(18)

Note that not all actions can guarantee that the task can
be completed within one time interval, as the available
computation resources may be less than the minimal
computation resources (i.e., f min
in (17) and (18)).
Similarly, the communication resource can also not be
guaranteed (i.e., C3 in (15e)). Therefore we may remove
some actions in C, resulting in the collection of feasible
actions for the i-th UE as Ci.

ijt

• States: Then, we deﬁne the states as follows:

s = {ω1, . . . , ωi, . . . , ωN }

(19)

where ωi represents the decision of the i-th UE. Specif-
ically, if the i-th UE (i ∈ N ) ofﬂoads the task to the
j-th UAV in t-th time interval, we assign action ρjt
∀j ∈ M, t ∈ Tj to state ωi. It is worth mentioning that if
the i-th UE decides to execute the task locally, we assign
action ρ00 to state ωi.

• Reward Functions: We deﬁne the reward function as

Z(s, ρjt) =

1
Eijt

(20)

The above proposed reward function can keep reducing
the energy consumption of each UE and may ﬁnally
achieve the minimization of the energy consumption of
all UEs.

Then, we present RLAA in Algorithm 1. In the beginning,
states s is initialized. The Q-table is also initialized, which
line 1 in
is used to record every state and action (i.e.,
Algorithm 1). At each episode, we obtain the collection of the
actions Ci for the i-th UE. Then, according to the (cid:15)-greedy
policy [13], the i-th UE either chooses a random action with

probability (cid:15) or follows the greedy policy with probability
1 − (cid:15), which is expresses as

ρjt =






ρ,
argmax
ρjt∈Ci

Q(s, ρjt),

if rand(0, 1) < (cid:15)
otherwise

(21)

where ρ is an action randomly selected from Ci, rand(0,1)
denotes a random number uniformly distributed over the
interval [0,1] (i.e., line 4 - line 8 in Algorithm 1).

Then, the resource allocation is conducted for the i-th UE
(i.e., line 9 in Algorithm 1). If the i-th UE ofﬂoad the task
to the j-th UAV in t-th time slot, the minimal computation
resource f min
in (17) is allocated. If the i-th UE execute
task locally, the minimal computation resource f min
in (18)
is allocated. Based on the proposed reward function in (20), the
i-th UE can then obtain a reward (i.e., line 10 in Algorithm 1).
Next, we update the Q-table (line 11), where the updating

ijt

ijt

rule of Q-table is given as

Q(s, c) ←Q(s, c) + β{Z(s, c)
+ γmax
c∈Ci

Q(s(cid:48), c) − Q(s, c)},

(22)

where γ is the reward decay over the interval [0,1], β is the
learning rate over the interval [0,1], and s(cid:48) is the next state.
Also, states s is updated based on action ρjt. Speciﬁcally, we
assign action ρjt, ∀j ∈ M(cid:48), t ∈ T (cid:48)

j to state ωi.

The above process will be repeated until the maximum
episode (epsmax) is reached. Finally, each UE selects an action
according to Q-table (line 16). Speciﬁcally, for the i-th UE,
the action in Ci corresponding to the largest value of Q-table
is selected.

Algorithm 1 Our proposed RLAA

1: Initialize s and Q-table;
2: while eps ≤ epsmax
3:
4:
5:

if rand(0,1)< (cid:15)

for i = 1:N

Select an action ρjt randomly from Ci for the i-th

UE;

else

Select an action ρjt = argmax
ρjt∈Ci

UE;

end if
Allocate computation resource f min

ijt

for the i-th UE;

from (17) and (18)

Obtain a reward Z(s, ρjt) according to (20);
Update Q-table according to (22);
Update s;

11:
12:
13:
14:
15: end while
16: Select an action for each UE.

end for
eps ← eps + 1;

IV. SIMULATION RESULTS
In this section, the simulation for the proposed multi-UAV
enabled MEC system is conducted, where the parameters of

6:
7:

8:
9:

10:

TABLE I
SIMULATION PARAMETERS

i

Parameters
Radius Rj for all UAVs
Flying height Hjt for all UAVs
Bandwidth B
Transmission power P T r
Noise variance σ2
G0
Channel power gain g0
Data Size Di
Execution task Fi
Time duration T max
Location of UEs
f max
j
(cid:15)-greedy policy probability
Reward decay γ
Learning rate β
ki for all UEs
vi for all UEs
epsmax
Tj for all UAVs

Settings
800 m
350 m
1 MHz
1 W
−90 dbm/Hz
2.2846
1.42×10−4
[100, 1000] KB
[108, 109] cycles
1 s
[−2000, 2000] × [−1000, 1000] m
150 GHz
0.9
0.9
0.2
10−27
3
10000
12

the tests are shown in Table. I, in which the channel bandwidth
is set to B = 1 MHz, the noise variance is set to σ2 = −90
dbm/Hz, the channel power gain at the reference distance 1 m
is set to g0 = 1.42 × 10−4 [12], the transmission power P T r
is set to 1 W, the time interval T max is set to 1 s, the ki is
set to 10−27 for all the UEs. Also, we assume each UAV can
support K = 150 UEs in one time slot. All UEs are assumed
to be randomly distributed in a rectangle area of coordinates
[−2000, 2000]×[−1000, 1000] m. We randomly select the data
size Di of each task from the interval of [100, 1000] KB and
select Fi from the interval of [108, 109] cycles.

i

In order to evaluate the performance of our proposed
RLAA, the following four algorithms are used as comparison
algorithms.

• Exhaustive search (ES): We examine all the possibili-
ties, with the objective of minimizing the overall energy
consumption for all the UEs.

• Local execution (LE): We assume all tasks are executed

• Random ofﬂoading (RO): Each UE randomly selects

the UAV and the time slot to ofﬂoad its task.

• Greedy ofﬂoading (GO): Each UE selects the nearest
UAV to ofﬂoad its task. If the UAV is overloaded (i.e.,
C3 is violated), then selects the second nearest UAV to
ofﬂoad and so on.

Firstly, we compare the performance of RLAA with its four
compared algorithms on a set of small scale instances (i.e.,
the number of UEs ranges from 3 to 7). We assume that there
are two UAVs ﬂying in circles with the same radius and the
center coordinates of two UAVs are set to [1200, 1200, 350]
and [−1200, −1200, 350], respectively. From Fig. 2, one can
see that RLAA has the same performance as ES, both of which
can achieve the minimal enery consumption. Also, one can see
that GO achieves better performance than RO, whereas LE
achieve the worst performance for all examined values. This

Q(s, ρjt) for the i-th

locally and there are no ofﬂoading.

Fig. 2. The overall energy consumption of ES, LE, RO, GO and RLAA
versus the number of UEs.

Fig. 4. The overall energy consumption of RLAA, LE, RO and GO versus
the number of UEs with 5 UAVs.

and [0, 0, 350], respectively. One sees that our proposed RLAA
still outperforms other compared algorithms, with signiﬁcant
amount of energy being saved for all the UEs.

V. CONCLUSION

In this paper, we studied a multi-UAV enabled MEC system,
in which the UAVs are assumed to ﬂy in circles over the
ground UEs to provide the computation services. The proposed
problem is formulated as a MINLP, which is hard to deal
with in general. We propose a RLAA algorithm to address it
effectively. Simulation results show that RLAA can achieve
the same performance as the exhaustive search in small scale
cases, whereas in large case scenario, RLAA still have con-
siderate performance gain over other traditional approaches.

VI. ACKNOWLEDGEMENTS

This work was supported in part by the Zhongshan City
Team Project (Grant No. 180809162197874), National Natural
Science Foundation of China (Grant No. 61620106011 and
61572389) and UK EPSRC NIRVANA project (Grant No.
EP/L026031/1).

REFERENCES

[1] X. Lyu, H. Tian, W. Ni, Y. Zhang, P. Zhang, and R. P. Liu, “Energy-
Efﬁcient Admission of Delay-Sensitive Tasks for Mobile Edge Comput-
ing,” IEEE Transactions on Communications, vol. 66, no. 6, pp. 2603–
2616, June 2018.

[2] K. Yang, S. Ou, and H. Chen, “On effective ofﬂoading services for
resource-constrained mobile devices running heavier mobile internet
applications,” IEEE Communications Magazine, vol. 46, no. 1, pp. 56–
63, January 2008.

[3] L. Zhang, K. Wang, D. Xuan, and K. Yang, “Optimal Task Allocation
in Near-Far Computing Enhanced C-RAN for Wireless Big Data Pro-
cessing,” IEEE Wireless Communications, vol. 25, no. 1, pp. 50–55,
February 2018.

[4] H. Mei, K. Wang, and K. Yang, “Multi-layer cloud-ran with cooperative
resource allocations for low-latency computing and communication
services,” IEEE Access, vol. 5, pp. 19 023–19 032, 2017.

Fig. 3. The overall energy consumption of RLAA, LE, RO and GO versus
the number of UEs with 3 UAVs.

is because that our proposed RLAA can choose most energy-
efﬁcient action for all the UEs according to computation and
communication requirement, while others either make UE to
execute all the task locally (i.e., LE), or randomly ofﬂoad
the tasks (i.e., RO), or just ﬁnd the nearest UAV (i.e., GO),
resulting in worse performance.

Next, we compare the performance of RLAA with LE, RO
and GO on a set of large scale instances, where the number of
UEs is increased to 100∼1000. The number of the UAVs is
set to 3, where the center coordinates are [1200, 1200, 350],
[−1200, −1200, 350] and [−1200, 1200, 350],
respectively.
Note that we do not examine ES here, due to its prohibitive
complexity. From Fig. 3, one can see that our proposed RLAA
still performs best, followed by GO, RO and LE, as expected.
In Fig. 4, we further increase the number of UAVs to 5,
where the center coordinates are set to as [1200, 1200, 350],
[−1200, −1200, 350], [−1200, 1200, 350], [1200, −1200, 350]

[5] X. Wang, K. Wang, S. Wu, S. Di, K. Yang, and H. Jin, “Dynamic
resource scheduling in cloud radio access network with mobile cloud
computing,” in 2016 IEEE/ACM 24th International Symposium on
Quality of Service (IWQoS), June 2016, pp. 1–6.

[6] Q. Wu and R. Zhang, “Common throughput maximization in uav-
enabled ofdma systems with delay consideration,” IEEE Transactions
on Communications, vol. 66, no. 12, pp. 6614–6627, Dec 2018.

[7] X. Chen, “Decentralized Computation Ofﬂoading Game for Mobile
Cloud Computing,” IEEE Transactions on Parallel and Distributed
Systems, vol. 26, no. 4, pp. 974–983, April 2015.

[8] X. Wang, K. Wang, S. Wu, S. Di, H. Jin, K. Yang, and S. Ou, “Dynamic
Resource Scheduling in Mobile Edge Cloud with Cloud Radio Access
Network,” IEEE Transactions on Parallel and Distributed Systems,
vol. 29, no. 11, pp. 2429–2445, Nov 2018.

[9] J. Lyu, Y. Zeng, R. Zhang, and T. J. Lim, “Placement Optimization of
UAV-Mounted Mobile Base Stations,” IEEE Communications Letters,
vol. 21, no. 3, pp. 604–607, March 2017.

[10] Y. Chen, N. Zhao, Z. Ding, and M. Alouini, “Multiple UAVs as
Relays: Multi-Hop Single Link Versus Multiple Dual-Hop Links,” IEEE
Transactions on Wireless Communications, vol. 17, no. 9, pp. 6348–
6359, Sept 2018.

[11] L. Yang, J. Cao, S. Tang, T. Li, and A. T. S. Chan, “A Framework
for Partitioning and Execution of Data Stream Applications in Mobile
Cloud Computing,” in 2012 IEEE Fifth International Conference on
Cloud Computing, June 2012, pp. 794–802.

[12] H. He, S. Zhang, Y. Zeng, and R. Zhang, “Joint Altitude and Beamwidth
Optimization for UAV-Enabled Multiuser Communications,” IEEE Com-
munications Letters, vol. 22, no. 2, pp. 344–347, Feb 2018.

[13] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G.
Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski
et al., “Human-level control
learning,”
Nature, vol. 518, no. 7540, pp. 529–533, 2015.

through deep reinforcement

