1

miniKanren as a Tool for Symbolic Computation in Python

BRANDON T. WILLARD, University of Chicago

In this article, we give a brief overview of the current state and future potential of symbolic computation within the Python
statistical modeling and machine learning community. We detail the use of miniKanren (Byrd 2009) as an underlying framework
for term rewriting and symbolic mathematics, as well as its ability to orchestrate the use of existing Python libraries per
Rocklin (2013). We also discuss the relevance and potential of relational programming for implementing more robust, portable,
domain-specific “math-level” optimizations–with a slight focus on Bayesian modeling. Finally, we describe the work going
forward and raise some questions regarding potential cross-overs between statistical modeling and programming language
theory.

ACM Reference format:
Brandon T. Willard. 2016. miniKanren as a Tool for Symbolic Computation in Python. 1, 1, Article 1 (January 2016), 21 pages.
DOI: 10.1145/nnnnnnn.nnnnnnn

INTRODUCTION

1
Throughout, we will focus on two categories of tools within the modern machine learning, statistics, and data
science world: Tensor Libraries and Probabilistic Programming Languages (PPLs).

For our purposes, it’s sufficient to say that tensor libraries are the modern wrappers for standard linear algebra
operations–traditionally offered by BLAS (BLA 2020) and LAPACK (LAP 2020)–with extensions to handle general
arrays, perform tensor operations, and efficiently compute gradients–usually via automatic differentiation (AD).
These libraries are the main workhorses of deep learning (DL) libraries, and, because of this strong association,
tensor libraries often provide deep learning-specific functionality (e.g. tools for constructing DL models, common
activation functions, etc.)

Probabilistic programming languages are domain-specific languages that aid in the specification of statistical
models and the application of estimation methods on said models. Often, PPLs will reflect the formal, probability
theory-based language used to specify statistical models, but that connection with probability theory tends to
serve primarily in an interface role. PPLs also implement related elements–like random variables and statistical
distributions–and, in some cases, they provide limited support for the laws and identities of probability theory
(e.g. addition and multiplication of random variables).

Nowadays, PPLs are increasingly backed by tensor libraries, so the two subjects are connected in this way.
There is an appreciable amount of symbolic computation behind the standard Deep Learning libraries of today,

like Theano (Bergstra et al. 2010), TensorFlow (Ten 2020), and PyTorch (PyT 2020).

At the very least, these libraries provide classes that represent tensor algebra in graphical form and functions
that manipulate graphs. Furthermore, these graphs are used to compute derivatives–via Automatic Differentiation
(AD), parallelize or vectorize operations, and, in limited cases, explicitly perform algebraic simplifications.

Regardless of whether or not you’re in a camp that says AD falls well within standard symbolic mathematics,
these libraries are undoubtedly performing symbolic calculations, and most of them are on a path toward even
more symbolic computation and outright symbolic mathematics.

Theano’s optimizations are perhaps the best example of more open-ended symbolic computation within
modern tensor libraries. It provides an entire subsystem for incorporating custom “graph optimizations” that

© 2016 ACM. This is the author’s version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of
Record was published in , http://dx.doi.org/10.1145/nnnnnnn.nnnnnnn.

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

0
2
0
2

y
a
M
8
2

]
L
P
.
s
c
[

3
v
4
4
6
1
1
.
5
0
0
2
:
v
i
X
r
a

 
 
 
 
 
 
1:2

• Brandon T. Willard

implements pattern matching, term substitution, utilizes common sub-expression elimination (CSE), offers
multiple graph traversal strategies and fixed-point operators, etc. The optimization system is used to perform
graph canonicalization and specialization through a number of standard matrix algebra identities, and, with
these, it is able to avoid numerous unnecessary numeric calculations and increase the overall “flexibility” of
function/model specification.

Unfortunately, most other tensor libraries do not offer as much in the way of user-level Python manipulation of
graphs. In the case of TensorFlow, an internal graph canonicalization and optimization library Grappler (Larsen
and Shpeisman 2019) is being actively developed. At the moment–its core work is done exclusively in C++ and
the potential for robust user-defined optimizations isn’t clear.

Outside of the aforementioned tensor libraries, other projects approach similar symbolic-oriented operations–
like AD–through function tracing (JAX 2020) and Python AST parsing (tan 2020). As with most tensor libraries,
these projects aren’t particularly focused on supporting generic graph manipulation or symbolic mathematics.
Nevertheless, they demonstrate another burgeoning entry-point to general symbolic computation.

At this point in time, there is a fairly well established set of modern machine learning and statistical modeling
libraries that are all fundamentally built upon the basics of symbolic graphs representing tensor algebra operations.
They all vary in the degree to which they implement symbolic mathematics or programmatically encode the
underlying high-level math. Regardless, the case for more advanced symbolic computation and mathematics is
slowly being made by multiple influential projects, and there’s already enough reason and prior work to start
assessing the directions this could go, and how we might get the most out of it.

Ideally, symbolic work within the machine learning and statistical modeling community would progress by
developing constructively on top of well established projects, so that quality code can be reused, existing expertise
can be leveraged, and community involvement from domain experts is easily incorporated.

Within the Python community, Rocklin (2013) states the same sentiments with regards to the intelligent use of
optimized linear algebra functions and the basics of term rewriting. This work follows the same principles, but
focuses on the areas of statistical modeling and, more specifically, Bayesian modeling. That is to say, we seek
flexible, compartmentalized and open systems that are easily integrated with established libraries and map well
to their high-level abstractions. Ideally, we could have all this without much context switching–in other words,
the need to operate in more than one programming languages or between programming languages.

2 WHAT WE WANT TO DO IN STATISTICAL MODELING
We believe that the statistical modeling and machine learning communities need a framework within which they
can develop their own high-level, symbolic ”optimizations” specific to the domains of statistical modeling and
machine learning. Ideally, such a framework would have the properties outlined in Section 1 and build upon the
already well established Python machine learning and statistics ecosystem, instead of attempting to outright
reinvent it or rewrite its staple offerings.

These symbolic optimizations should be usable internally by new and existing libraries to drive advanced
automations. As well, they should be usable in an interactive way by researchers, where the researchers
themselves can dynamically add new theorems and immediately use the resulting automations for high-level
testing, experimentation, and concrete applications.

Statistical modeling is surprisingly amenable to symbolic methods (Carette and Shan 2016; Carette et al. 2008)–
and especially when one restricts the context to specific practices like Bayesian modeling (Shan and Ramsey
2017), where there exist fundamental relations–such as ”conjugacy” (Robert 2007, Chapter 3.3)–that are easily
automated with simple pattern matching.

Another example is Rao-Blackwellization. Rao-Blackwellization is derived from the Rao-Blackwell Theorem
(Casella and Robert 1996), which states–roughly–that analytically computed conditional expectations outperform

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

miniKanren as a Tool for Symbolic Computation in Python •

1:3

their un-integrated counterparts. In other words, if you can get a closed-form answer to an integral, instead of
estimating the integral with samples, you should use the closed-form answer.

It applies in a rather general sense to numerous Markov Chain Monte Carlo methods, but its automation is

something that falls well outside of most libraries, arguably due to its symbolic computation requirements.

The Rao-Blackwellizations appearing in published material are often driven by simple high-level identities–
identities which we can alternatively classify as relations. Some of those relations reflect basic theorems in
probability theory and statistics, like the following normal (or Gaussian) random variable identity–expressed as a
rule:

(sum-of-normals)

X ∼ N(cid:0)µx , σ 2

x

(cid:1),

Y ∼ N(cid:16)
Z ∼ N(cid:0)µx + µy, σ 2

µy, σ 2
y
x + σ 2
y

(cid:17)

(cid:1)

, X + Y = Z

(1)

There are numerous examples like (1), and they all take the form of relations. Hiding behind these relations

are the closed-form integrals that would otherwise be painstaking to compute directly with symbolic algebra.

As a matter of fact, there are at least two ways to frame identities like these: in terms of random variables,
and in terms of their corresponding distribution functions. This means that one can turn theorems like Rao-
Blackwellization into an integration problem. Unfortunately, term graphs produced by the distribution-based
approach can be much more complex than the corresponding random variable graphs. Our focus will be on the
latter approach, since it offers more opportunities to solve equivalent integration problems using only collections
of simple random variable identities.

This general idea has analogs in the approaches used by modern symbolic integration systems themselves.
When such systems employ Fox H and Meijer G functions (Peasgood 2009; Roach 1997), they are effectively using
only a few simple algebraic convolution identities applied to broad classes of hypergeometric functions–many of
which can be encoded by simple look-up tables.

Since those systems are intended to reach a much greater number of functions and constraints, they are
necessarily more complex; however, a majority of the work being done by statistical modeling deals with a
comparatively smaller set of standard distributions, so major improvements can be made without invoking the
complexity of symbolic integration systems.

Currently, statistical modeling systems do not directly support these types of “knowledge” additions, nor do
they attempt to systematically employ these well-known and far-reaching theorems–like Rao-Blackwellization.
Instead, this kind of work is still restricted to the user-level, where it is performed by hand and used as input to
such systems. At the present, the best systems simply provide broadly useful identities and theorems as advice in
their manuals and message boards.

In particular, Stan (Stan Development Team 2014) is known for having a well written manual that details
user-level manipulations to account for common sampling issues arising due to poorly specified models (Gelman
2019). Note that the description ”poorly specified” is conditional on the given estimation approach.

Among the advice given in Stan’s manual is the classic pathological ”funnel” model of Neal (2003). This model
can be reparameterized using the following rule between a standard Gaussian random variable and its affine
transform:

(normal-affine-transform)

Y ∼ N(0, 1), X = µ + σY
X ∼ N(µ, σ 2)

(2)

Under (2), terms in the funnel model can be expanded resulting in an equivalent model that exhibits much

better sampling properties.

The work we detail here is motivated by the desire to see relations like these used within statistical modeling
systems, so that model specification is more flexible and less brittle with respect to the exact specification of a
model.

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

1:4

• Brandon T. Willard

Systems like Stan and the Python-based PyMC (Salvatier et al. 2016) are PPLs, so their role as programming
languages is clear, and–in line with most programming languages–compiler optimizations can be used to improve
performance and expand the expressive potential of a language’s syntax.

Projects like Stan and PyMC rely almost exclusively on AD and have more or less superseded older projects
based on different, non-gradient-based generalized methodologies, like BUGS (Lunn et al. 2009). BUGS used
some of the domain-specific identities implied here to construct a surprisingly robust expert system that could
automatically construct a sampler for a given model. We would like to make such systems easier to produce and
extend, and we would like to see them built on top of tensor libraries, so that the AD-driven methods of modern
PPLs can be used in tandem.

One noteworthy example is PyMC’s internal logic for determining an appropriate sampler. This logic could
benefit from an easily extensible, expert-like system that matches models to samplers. Just like the optimization
system in Theano, the graph of a PyMC model can be manipulated to produce a more suitable, yet equivalent,
model for a given sampler, or–conversely–produce a customized sampler for a given model. In extreme cases, the
posterior distribution ultimately estimated by PyMC could be returned in closed-form. A small example of this is
given in Section 4.6.

Otherwise, there are entire classes of efficient, model-specific samplers that are currently out of these PPLs’
reach, and the addition of some straight-forward and flexible term rewriting capabilities would make them
immediately available. Some examples involve Gibbs samplers, scale mixture representations for sparsity priors
(Bhadra et al. 2016), non-Gaussian models (Polson et al. 2013), and parameter expansions (Scott 2010).

As a proof of concept using Theano’s existing optimization system, automatic simplification of random variables
was demonstrated in Willard (2017). While it is more than possible to extend the same approach into auto-
conjugation and related statistical optimizations, the scalability and means of specifying new optimizations
within Theano wasn’t promising.

One important concern involves the need to use identities in more than one direction. For instance, one
direction of the identity underlying (2) is useful for computational reasons (e.g. the funnel problems) and the other
direction helps one determine the distribution type of sub-term (i.e. given Y ∼ N(0, 1) we can derive distribution
of X ) in a larger model. The latter information might be needed by a system that constructs custom samplers, or
to reformulate a model so that it can be used by a given sampling routine.

This otherwise natural use of identities isn’t covered well by modern programming frameworks, and that’s

where logic and relational programming becomes a real consideration.

Considerations like these also lead quickly into the domain of term rewriting (Baader and Nipkow 1999). Graph
normalization/canonicalization, rewrite rule completion (Huet 1981), and general equational reasoning are all
ground-level subjects in the features we’ve described.

With this in mind, it’s likely that our objectives won’t often lead to the classical term rewriting niceties, like
easily determined normal forms and term orderings with strong guarantees. Given our desire for an interactive
system in which to perform ad hoc additions and experimentation, it seems even less likely. Even so, when
such niceties are available, we would at least like a suitable framework in which to derive and apply them.
Furthermore, if it’s ever possible to produce any results from a less-than-perfect set of identities, then we would
like a framework that facilitates that, too.

Overall, we seek a middle ground that provides an approachable, powerful, yet light-weight framework for

creating and orchestrating domain-specific relations.

As well, we would like this framework to promote joint development between experts in statistics, machine
learning, term rewriting, type theory, code synthesis, and related areas. We believe miniKanren could serve an
important role within this intersection of requirements.

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

miniKanren as a Tool for Symbolic Computation in Python •

1:5

3 WHERE MINIKANREN FITS IN
Computer science researchers have been–and continue to–actively pursue topics in symbolic computation
specifically within the area of statistical modeling (Sato et al. 2018; Shan and Ramsey 2017; Walia et al. 2018).
While very in-line with the automations described here, much of this work takes the form of entirely new
languages or very broad theoretical work that doesn’t always lend itself to more immediate input from experts in
the areas of statistical modeling methods.

In other cases, the limitations involve the degree of specialization, where exclusive focus is often on neural
network-specific DSLs and frameworks, or only certain types of optimizations (Vasilache et al. 2018; Wei et al.
2017).

Regarding Python and statistical modeling, the recent automatic conjugation and rescaling examples of
Gorinova et al. (2018); Hoffman (2018) are perhaps the most germane; however, their approach relies entirely on
an existing pattern-matching and rewrite system (Radul 2020) that is non-relational and uses the Python stack
for backtracking. As we’ve stated earlier, the use of relations has important conceptual and implementation
advantages (e.g. the concepts being implemented are fundamentally relational, and the inherent code reuse
arising from ”bidirectional” applications of identities).

As well, use of the Python stack for backtracking puts severe limitations on the size of graphs manageable
by such a system. Python throws RecursionErrors when the stack reaches a fixed size, and term graphs
representing real models are by no means small, so unification alone is liable to cause irreconcilable errors. Our
implementation of unification in Python (Willard 2020c) demonstrates this exact problem in its unit tests, and, as
a result, the library uses a coroutine-based trampoline to avoid excessive use of the Python stack.

Simply increasing the recursion limit (e.g. via sys.setrecursionlimit) is–at best–a single-case solution,
and it’s often safer to pursue a more ”pythonic” rewrite (i.e. loop or list comprehension-based approach). Also,
Python currently lacks even the most basic forms of tail recursion elimination–and it’s very unlikely to appear in
later versions (Rossum 2009).

Furthermore, Hoffman (2018) doesn’t provide clear examples of how rewrite rules are specified in their proposed
system, so it’s difficult to assess exactly how expressive their DSL is, or even how well it works within Python
and its standard collection types.

This is where miniKanren comes in. It serves as a minimal, lightweight relational DSL that orchestrates
unification and reification and operates exclusively within an existing host language. Furthermore, its core
functionality is succinctly described in a single page of code, which helps make its inner workings very transparent
to the interested developer (Hemann and Friedman 2013).

In contrast with other unification-driven systems, its ”internal” mechanics maintain direct connections with
multiple high-level theoretical concepts (e.g. unification, complete search, relational programming, CPS, etc.), so,
for–instance–its use as a type theory prototyping language automatically provides exciting connections to both
basic and cutting-edge symbolic computation (e.g. automatic theorem proving (Near et al. 2008)). As a matter of
fact, the use of typing rules to describe the automation of high-level inference algorithms in Walia et al. (2018) is
a direct example of how elements of type theory can be used in high-level statistical model optimization, and
miniKanren can serve as a bridge to fast implementations.

miniKanren inherently provides a degree of high-level portability and low-level flexibility. Relations can be built
on top of other relations, and, in these cases, the goals that implement such composite relations in miniKanren are
often easily ported to miniKanrens in other host languages. miniKanren doesn’t enforce a formal, host-language
independent semantics, yet it still lends well to this kind of portability. This lack of formal semantics also makes it
easier to address performance and domain specific issues in multiple ways–like the RecursionErrors described
above. With these properties, miniKanren has exactly the type of generality and flexibility to serve as a basis for

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

1:6

• Brandon T. Willard

more fluid collaboration–in symbolic computation–between independent communities of computer scientists
and statisticians.

In the following section, we will illustrate many of these points using our Python implementation of miniKanren.

4 SYMBOLIC COMPUTATION IN PYTHON DRIVEN BY MINIKANREN
In the following sections we detail our implementation of miniKanren (Willard 2020d), operating under the
PyPi name miniKanren and Python package name kanren. We also describe its ecosystem of complementary
packages etuples, cons, and symbolic-pymc.

kanren is a fork that tries to maintain syntactic parity with its predecessor logpy (Rocklin 2018), but now
deviates significantly in terms of core mechanics and offerings. The most important difference is in the relational
status of logpy’s goals; most were not truly relational. This was largely due to the use of an exception-based
goal reordering system, which served as the exclusive means of handling missing cons-based capabilities and
minimalistic constraints. Basically, one could attempt to develop entirely in standard Python at the goal constructor
level, and throw special EarlyGoalError exceptions when goal constructor arguments were not sufficiently
ground for a given task. The exception would cause the goals to be reordered until an ordering satisfied these
goals’ groundedness requirements.

This exception-based approach was combined with a lightweight tuple-based, Lisp-like expression evaluator
that operated in tandem with the goal reordering. Both of these components were built directly into the core
stream processing functions and introduced additional complexity and challenges, but, most of all, they made it
much easier to construct non-relational goals and imposed new, non-miniKanren semantics that increased the
barrier to entry beyond a simple understanding of core Python and miniKanren.

Our implementation of miniKanren’s core mechanics does not operate on Lisp-like idioms, yet it maintains an
operational similarity to the Scheme implementations. Additionally, it provides a straight-forward object-oriented
framework for implementing truly relational constraints. These points will be covered in more detail in the
following sub-sections.

First, we must note that both Python implementations share the same small, but noteworthy, deviations
from the standard Scheme-based miniKanrens. Specifically, the basic miniKanren states are implemented using
Python’s built-in dict type, the ≡ goal is represented by the function eq, there is no fresh–instead, fresh
logic variables are constructed explicitly using the function var–and the functionality of bind and mplus are
represented by the logical “and” and “or” functions lall and lany and are essentially the conj and disj stream
functions of Hemann and Friedman (2013).

4.1 Goals as Generators
Our implementation of miniKanren represents goals using Python’s built-in generators (Gen 2020; Foundation
2020).

Listing 4.1 illustrates the general form of a miniKanren goal and some of the idioms available to them.

Listing 4.1: Example idioms for generator-based goals in Python.

1 def relationo(*args):

"""Construct a goal for this relation."""

def relationo_goal(S):

"""Generate states for the relation `relationo`.

2

3

4

5

6

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

miniKanren as a Tool for Symbolic Computation in Python •

1:7

Listing 4.1 – continued

I.e. this is the goal that's generated.

Parameters
----------
S: Mapping

The miniKanren state (e.g. unification mappings/`dict`).

Yields
------
miniKanren states.

"""
nonlocal args

args_rf = reify(args, S)

x = 1
for a in args_rf:

S_new = S.copy()

if isvar(a) or x > 3:
S_new[a] = x

z = yield S_new #

if not z:

x += 1

if some_condition:

yield S

#

else:

return

a_lv = var()
yield from lall(conso(1, a_lv, args), eq(a_lv, [2, 3]))

#

yield from relationo(*new_args)

#

return relationo_goal

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

Simply put, a goal is responsible for either explicitly generating its goal stream (e.g. Line 30 and 36) or deferring

to other goals and/or goal combinations via the stream manipulation functions lall and lany (e.g. Line 41).

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

1:8

• Brandon T. Willard

The idioms described in Listing 4.1 are realized in a number of low-level goal implementations within kanren.
One good example is the permuteo goal, which relates an ordered collection to its permutations. Within
permuteo, low-level Python steps are taken in order to efficiently compute differences of hashable collections
when the arguments are ground, and, when one argument is unground, Python’s built-in permutation generator
itertools.permutations is used to efficiently generate unification arguments for the unground term. This
strictly Python-based low-level implementation of a goal is both completely relational and considerably more
scalable than an implementation built on the basic miniKanren relations and amounting to Bogosort (Kiselyov
et al. 2005).

Within ordinary goals like relationo_goal one is able to leverage the naturally delayed nature of Python’s
generators and seamlessly define recursive goals (e.g. Line 43) by calls to the outer goal constructor relationo,
and, in the case of goal constructors that do not define their own low-level goals, recursion is facilitated by the
η-delay function, Zzz, of Hemann and Friedman (2013).

This approach also makes it possible for goals to more easily control the type and order of the results it streams.
The loop around Line 30 in Listing 4.1, demonstrates how a goal can easily keep and manage its state–e.g. the
variable x–and use it to affect the goal stream it produces.

Also, using Python’s coroutine capabilities, Line 30 shows how it’s possible to send results back to a goal
when the process evaluating the stream uses generator.send (PEP 2020a). In this case, a goal could be given
“upstream” information.

Also, using Python’s __length_hint__ (PEP 2020b) spec, goals and stream manipulation functions could be
told when a stream is empty or simply make decisions based on partial information about a stream’s size. Such
information could help determine efficient orderings within lall conjunctions and between conde branches,
by–say–allowing these operators to choose finite streams over potentially infinite ones in certain cases.

Overall, the resulting simplicity of this approach is an example of how well miniKanren’s underlying mechanics
can be adapted to host languages in which the standard list-based approach isn’t as natural or efficient as it is in
Scheme.

4.2 Constraints
Our Python implementation follows the approach of Hemann and Friedman (2017) to implement a minimal
constraint system in miniKanren. Listing 4.2 provides some simple illustrations of the standard disequality
(named neq here) and type constraints–the latter using Python’s isinstance naming scheme.

1 >>> from kanren.constraints import neq, isinstanceo

Listing 4.2: Basic constraint goals example.

2
3 >>> run(0, x,
4 ...
5 ...
6 ...
7 (2,)

neq(x, 1), # Not "equal" to 1
neq(x, 3), # Not "equal" to 3
membero(x, (1, 2, 3)))

8
9 >>> from numbers import Integral
10 >>> run(0, x,
11 ...
12 ...

isinstanceo(x, Integral),
membero(x, (1.1, 2, 3.2, 4)))

# `x` must be of type `Integral`

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

miniKanren as a Tool for Symbolic Computation in Python •

1:9

Listing 4.2 – continued

13 (2, 4)

14

When constraints are used, the state type–normally an ordinary Python dict–is replaced with a new type:
ConstrainedState. This type is a subclass of the interface Mapping, so it behaves effectively the same as a
standard dict. The main functionality provided by ConstrainedState is constraint store tracking and validation.
Constraint store validation occurs after each successful unification involving a ConstrainedState. Adding
new constraints involves constructing a custom constraint store class and a goal that assigns the constraint and
adds or updates the associated store in a miniKanren state. For convenience, there is an abstract PredicateStore
type that simplifies the construction of predicate-based constraints.

Given that constraint checking is tied directly to the Mapping interface, one can dispatch on key addition,

deletion, and updating in order to implement more efficient constraint store management and validation.

cons

4.3
One of the main challenges involved in implementing miniKanren in some host languages is the lack of immediate
support for important Scheme/Lisp-like elements. The most notable for Python being cons.

cons support is important for maintaining certain forms of simplicity and expressiveness in term rewriting.
For instance, while “pattern matching”–or unification–alone can be rather straight-forward to implement, and
more than a couple of the software systems mentioned here have introduced basic pattern matching, they all
tend to lack the expressive simplicity afforded by list-based terms and proper cons semantics.

A good example is Theano’s unification system (Gra 2020); although it does provide a tuple-based interface for
defining forms to match and replace, and it supports logic variables within said forms, it doesn’t provide a means
of expressing a cons pair. As a result, attempting to construct a pattern that matches a specific operator (or car)
and an unspecified number/type of arguments (or cdr)–or vice versa–falls outside of the system’s reach.

Our Python implementation of miniKanren preserves nearly all the same algebraic datatype semantics of Lisp’s
cons by way of our cons package (Willard 2020e). The cons package provides a minimal ConsType class, along
with a set of easily extensible generic functions for car and cdr.

As Listing 4.3 demonstrates, with cons we’re able to succinctly express the aforementioned “pattern” for all

the built-in ordered collection types, and reify accordingly.

Listing 4.3: cons pair unification and reification using Python’s built-in lists.

1 >>> from collections import OrderedDict
2 >>> from cons import cons
3 >>> from unification import unify, reify, var

4
5 >>> unify([1, 2], cons(var('car'), var('cdr')), {})
6 {˜car: 1, ˜cdr: [2]}

7
8 >>> unify((1, 2, 3), cons(var('car'), var('cdr')), {})
9 {˜car: 1, ˜cdr: (2, 3)}

10
11 >>> unify(OrderedDict([('a', 1), ('b', 2)]), cons(var('car'), var('cdr')), {})
12 {˜car: ('a', 1), ˜cdr: [('b', 2)]}

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

1:10

• Brandon T. Willard

13
14 >>> reify(cons(1, var('cdr')), {var('cdr'): [2, 3]})
15 [1, 2, 3]

16
17 >>> reify(cons(1, var('cdr')), {var('cdr'): (2, 3)})
18 (1, 2, 3)

19

Listing 4.3 – continued

Later, in Listing 4.12, we provide another example of how a cons-compliant unification system makes non-trivial

patterns easier to express.

4.4 S-Expressions
Since Python doesn’t already provide a programmatically convenient form of expressions or terms, we’ve
constructed a simple ExpressionTuple class–or etuple for short–that extends the built-in tuple with the ability
to evaluate itself, cache the results, and maintain the cached results between non-modifying reconstructions and
re-evaluations of the same etuple.

Python does provide AST objects that fully represent its built-in expressions, but they are cumbersome to work
with and do not provide much of the desired functionality for term rewriting (e.g. access to nested elements is too
indirect, their construction and use involves irrelevant meta information, etc.) See Willard (2018) for examples of
term rewriting using Python AST objects and miniKanren.

As we demonstrate in a later example (i.e. Listing 4.9), etuples are an extremely convenient way to leverage a
target library’s user-level functions (e.g. TensorFlow’s matrix multiplication function) without having to manually
construct fully reifiable term graphs–many of which require detailed information that may not be available at
the time of a goal’s evaluation.

Listing 4.4: Constructing a simple etuple.

1 >>> from operator import add
2 >>> from etuples import etuple, etuplize

3
4 >>> et = etuple(add, 1, 2)
5 >>> et
6 ExpressionTuple((<built-in function add>, 1, 2))

7

etuples can be indexed–and generally treated–like immutable tuples:

Listing 4.5: etuple indexing example.

1 >>> et[0:2]
2 ExpressionTuple((<built-in function add>, 1))

3

Evaluation is available through a simple cached property:

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

miniKanren as a Tool for Symbolic Computation in Python •

1:11

Listing 4.6: etuple evaluation example.

1 >>> et.eval_obj
2 3

3

Furthermore, it is easy to specify conversions to and from etuples for arbitrary types.
Listing 4.7 constructs two custom classes, Node and Operator, and specifies the car and cdr for the Node type
via the generic functions (Rocklin 2019) rands rator, respectively. An apply dispatch is also specified, which
represents a combination of cons (via the aforementioned cons library) and an S-expression evaluation.

Listing 4.7: Adding etuple support to a standard Python class.

1 from collections.abc import Sequence

2
3 from etuples import rator, rands, apply
4 from etuples.core import ExpressionTuple

5

6
7 class Node:

def __init__(self, rator, rands):

self.rator, self.rands = rator, rands

def __eq__(self, other):

return self.rator == other.rator and self.rands == other.rands

8

9

10

11

12

13

14
15 class Operator:

def __init__(self, op_name):
self.op_name = op_name

def __call__(self, *args):

return Node(Operator(self.op_name), args)

def __repr__(self):

return self.op_name

def __eq__(self, other):

return self.op_name == other.op_name

16

17

18

19

20

21

22

23

24

25

26

27

28
29 rands.add((Node,), lambda x: x.rands)
30 rator.add((Node,), lambda x: x.rator)

31

32
33 @apply.register(Operator, (Sequence, ExpressionTuple))

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

1:12

• Brandon T. Willard

34 def apply_Operator(rator, rands):

return Node(rator, rands)

35

36

Listing 4.7 – continued

With the specification of rands, rator, and apply for Node types, it is now possible to convert Node objects
to etuples using the etuplize function. Listing 4.8 demonstrates this process and shows how the underlying
object is preserved through conversion and evaluation.

Listing 4.8: Converting a supported class instance into an etuple.

1 >>> mul_op, add_op = Operator("*"), Operator("+")
2 >>> mul_node = Node(mul_op, [1, 2])
3 >>> add_node = Node(add_op, [mul_node, 3])
4 >>> et = etuplize(add_node)

5
6 >>> pprint(et)
7 e(+, e(*, 1, 2), 3)

8
9 >>> et.eval_obj is add_node
10 True

11

4.5 Relations for Term Rewriting
Our Python implementation of miniKanren is motivated by the need to cover some of the symbolic computation
objectives laid out here, so, in response, it provides relations that are specific to those needs.

The most important set of relations involve graph traversal and manipulation. symbolic-pymc provides “meta”
relations for applying goals to arbitrary “walkable” structures (i.e. collections that fully support cons semantics
via car and cdr).

Listing 4.9 constructs an example goal that represents two simple mathematical identities: i.e. x + x = 2x and

log exp x = x.

Listing 4.9: An example goal that implements some basic mathematical relations.

1 def single_math_reduceo(expanded_term, reduced_term):

2

3

4

5

6

7

8

9

10

"""Construct a goal for some simple math reductions."""
# Create a logic variable to represent our variable term "x"
x_lv = var()
return lall(

# Apply an `isinstance` constraint on the logic variable
isinstanceo(x_lv, Real),
isinstanceo(x_lv, ExpressionTuple),
conde(

# add(x, x) == mul(2, x)

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

miniKanren as a Tool for Symbolic Computation in Python •

1:13

Listing 4.9 – continued

[eq(expanded_term, etuple(add, x_lv, x_lv)),
eq(reduced_term, etuple(mul, 2, x_lv))],

# log(exp(x)) == x
[eq(expanded_term, etuple(log, etuple(exp, x_lv))),

eq(reduced_term, x_lv)]),

11

12

13

14

15

16

17

)

We can combine the goal in Listing 4.9 with the “meta” goal, reduceo, which applies a goal recursively until
a fixed-point is reached–assuming the relevant goal is a reduction, of course. (The meta goal should really be
named fixedpointo.) Additionally, we create another partial function that sets some default arguments for the
walko meta goal.

Listing 4.10: Partial functions for a fixed-point calculation and graph walking.

1 math_reduceo = partial(reduceo, single_math_reduceo)
2 term_walko = partial(walko, rator_goal=eq, null_type=ExpressionTuple)

3

Listing 4.11 applies the goals to two unground logic variables, demonstrating how miniKanren nicely covers
both term expansion and reduction, as well as graph traversal and fixed-point calculations, in a single concise
framework. (The symbols prefixed by ˜_ in the output are unground logic variables.)

Listing 4.11: Simultaneous mathematical term “expansion” and “reduction”.

1 >>> expanded_term = var()
2 >>> reduced_term = var()
3 >>> res = run(10, [expanded_term, reduced_term],
4 >>>

term_walko(math_reduceo, expanded_term, reduced_term))

5
6 >>> rjust = max(map(lambda x: len(str(x[0])), res))
7 >>> print('\n'.join((f'{str(e):>{rjust}} == {str(r)}' for e, r in res)))

8

9

10

11

12

13

14

add(˜_2291, ˜_2291) == mul(2, ˜_2291)

˜_2288() == ˜_2288()

log(exp(add(˜_2297, ˜_2297))) == mul(2, ˜_2297)

˜_2288(add(˜_2303, ˜_2303)) == ˜_2288(mul(2, ˜_2303))

log(exp(log(exp(add(˜_2309, ˜_2309))))) == mul(2, ˜_2309)
˜_2288(˜_2294) == ˜_2288(˜_2294)
log(exp(log(exp(log(exp(add(˜_2315, ˜_2315))))))) == mul(2, ˜_2315)

15
16 log(exp(log(exp(log(exp(log(exp(add(˜_2325, ˜_2325))))))))) == mul(2, ˜_2325)

˜_2288(˜_2300()) == ˜_2288(˜_2300())

17

18

˜_2288(˜_2294, add(˜_2331, ˜_2331)) == ˜_2288(˜_2294, mul(2,

(cid:44)→

˜_2331))

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

1:14

• Brandon T. Willard

To further demonstrate the expressive power of miniKanren in this context, in Listing 4.12 we show how easy
it is to perform term reduction, expansion, or both under structural constraints on the desired terms. Specifically,
we ask for the first ten expanded/reduced term pairs where the expanded term is a logarithm with at least one
argument.

In Listing 4.12, we use cons three times to constrain the logic variable expanded_term to only log terms with
an add term as the first argument, and we’ll further restrict the add term to one not containing another add as its
first argument.

Listing 4.12: Constrained term “expansion”” and “reduction”.

1 >>> from kanren.constraints import neq
2 >>>
3 >>>
4 >>> log_arg = var()
5 >>> first_arg = var()
6 >>> first_arg_car, first_arg_cdr = var(), var()
7 >>>
8 >>> res = run(10, [expanded_term, reduced_term],
9 >>>
10 >>>
11 >>>
12 >>>
13 >>>

eq(etuple(log, log_arg), expanded_term),
eq(etuple(add, first_arg, var()), log_arg),
conso(first_arg_car, first_arg_cdr, first_arg),
neq(first_arg_car, add),
term_walko(math_reduceo, expanded_term, reduced_term))

14
15 >>> rjust = max(map(lambda x: len(str(x[0])), res))
16 >>> print('\n'.join((f'{str(e):>{rjust}} == {str(r)}' for e, r in res)))
17 >>>

log(add((˜_771 . ˜_772), (˜_771 . ˜_772))) ==

(cid:44)→
18 >>>

(cid:44)→
19 >>>

(cid:44)→
20 >>>

(cid:44)→
21 >>>

(cid:44)→
22 >>>

(cid:44)→
23 >>>

(cid:44)→
24 >>>

(cid:44)→
25 >>>

(cid:44)→

log(mul(2, (˜_771 . ˜_772)))

log(add(log(exp(add(˜_815, ˜_815))), add(˜_829, ˜_829))) ==

log(add(mul(2, ˜_815), mul(2, ˜_829)))

log(add((˜_771 . ˜_772), add(˜_851, ˜_851))) ==

log(add((˜_771 . ˜_772), mul(2, ˜_851)))

log(add(˜_806(add(˜_869, ˜_869)), add(˜_887, ˜_887))) ==

log(add(˜_806(mul(2, ˜_869)), mul(2, ˜_887)))

log(add((˜_771 . ˜_772), ˜_844(add(˜_909, ˜_909)))) ==

log(add((˜_771 . ˜_772), ˜_844(mul(2, ˜_909))))

log(add(log(exp(˜_788)), add(˜_935, ˜_935))) ==

log(add(˜_788, mul(2, ˜_935)))

log(add((˜_771 . ˜_772), log(exp(add(˜_945, ˜_945))))) ==

log(add((˜_771 . ˜_772), mul(2, ˜_945)))

log(add(˜_806(˜_808, add(˜_967, ˜_967)), add(˜_985, ˜_985))) ==

log(add(˜_806(˜_808, mul(2, ˜_967)), mul(2, ˜_985)))

log(add((˜_771 . ˜_772), ˜_844(˜_846, add(˜_1007, ˜_1007)))) ==

log(add((˜_771 . ˜_772), ˜_844(˜_846, mul(2, ˜_1007))))

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

miniKanren as a Tool for Symbolic Computation in Python •

1:15

Listing 4.12 – continued

26 >>> log(add(log(exp(log(exp(add(˜_1021, ˜_1021))))), add(˜_1035, ˜_1035))) ==

log(add(mul(2, ˜_1021), mul(2, ˜_1035)))

(cid:44)→

27

By properly supporting cons semantics, we were able to constructively express a non-trivial term constraint

with only four simple goals.

4.6 The symbolic-pymc Package
In order to bring together miniKanren and the popular tensor libraries Theano and TensorFlow, our project
symbolic-pymc provides “meta” type analogs for the essential tensor graph types of each “backend” tensor
library. These meta types allow for more graph mutability than the “base” libraries themselves tend to provide.
They also allow one to use logic variables where the base libraries wouldn’t.

Basic use of symbolic-pymc involves either conversion of an existing base–i.e. Theano or TensorFlow–graph
into a corresponding meta graph, or direct construction of meta graphs that are later converted (or “reified”) to
one of the base graph types. miniKanren goals generally work at the meta graph level, where–for instance–one
would apply goals that unify a converted base graph with a pure meta graph containing logic variables.

While it is possible to achieve the same results with only etuples, meta graphs are a convenient form that
allow developers to think and operate at the standard Python object level. They also provide a more direct means
of graph validation and setup, since checks can–and are–performed during meta graph construction, whereas
standard etuples would not be able to perform such operations until the resulting etuple is fully constructed
and evaluated. Likewise, meta graphs are more appropriate for specifying and obtaining derived information,
like shapes and data types, for a (sub)graph instead of miniKanren.

To demonstrate the use of symbolic-pymc, we consider a simple conjugate model constructed using PyMC3

in Listing 4.13.

Listing 4.13: A beta-binomial conjugate model in PyMC3.

1 import pymc3 as pm

2
3 with pm.Model() as model:

p = pm.Beta("p", alpha=2, beta=2)
y = pm.Binomial("y", n=totals, p=p, observed=obs_counts)

4

5

6

A user will generally have some data specifying the values for totals and obs_counts and will want to
estimate the posterior distribution of p. In the Bayesian world, posterior distributions are generally the object of
interest and estimation.

More specifically, we want to estimate the distribution for a rate of success, p, given a total number of events,
totals, and observed successes, obs_counts, under the assumption that the events are binomially distributed
with rate p. We let p take a beta distribution prior, and that completes our Bayesian specification of a model.

Mathematically, this simple model is stated as follows:

Y ∼ Binom(N , p)
p ∼ Beta(2, 2)

(3)

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

1:16

• Brandon T. Willard

and it has a well known closed-form posterior distribution given by

(p | Y = y) ∼ Beta(2 + y, 2 + N − y)
Instead of wasting resources estimating the posterior numerically (e.g. using pm.sample(model) to run a
Markov Chain Monte Carlo sampler), we can simply extract the underlying Theano graph from model and apply
a relation that represents the underlying conjugacy and use the resulting posterior.

(4)

The general rule implied by this situation is

(beta-binomial-conjugate)

Y ∼ Binom(N , p),
p ∼ Beta(α, β)
(p | Y = y) ∼ Beta(α + y, β + N − y)

(5)

Listing 4.14 converts the PyMC3 model object, model, into a standard Theano graph that represents the

relationship between random variables in the model.

Listing 4.14: Converting a PyMC3 model into a Theano graph of the model’s sample-space.

1 from symbolic_pymc.theano.pymc3 import model_graph
2 from symbolic_pymc.theano.utils import canonicalize

3

4
5 # Convert the PyMC3 graph into a symbolic-pymc graph
6 fgraph = model_graph(model)

7
8 # Perform a set of standard algebraic simplifications using Theano
9 fgraph = canonicalize(fgraph, in_place=False)

10

Listing 4.15 uses miniKanren to construct a goal, betabin_conjugateo, that matches terms taking the form of
Equation (3) in the first argument and the resulting posterior of Equation (4) in the second argument. It makes
use of both meta objects and etuples.

Listing 4.15: A miniKanren goal that implements the beta-binomial conjugate rule in (5).

1 def betabin_conjugateo(x, y):

2

3

4

5

6

7

8

9

10

11

12

"""Replace an observed Beta-Binomial model with an unobserved posterior

Beta-Binomial model."""

(cid:44)→
obs_lv = var()

beta_size, beta_rng, beta_name_lv = var(), var(), var()
alpha_lv, beta_lv = var(), var()
# We use meta objects directly to construct the "pattern" we want to match
beta_rv_lv = mt.BetaRV(alpha_lv, beta_lv, size=beta_size, rng=beta_rng,

(cid:44)→

name=beta_name_lv)

binom_size, binom_rng, binom_name_lv = var(), var(), var()
N_lv = var()
binom_lv = mt.BinomialRV(N_lv, beta_rv_lv, size=binom_size, rng=binom_rng,

(cid:44)→

name=binom_name_lv)

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

miniKanren as a Tool for Symbolic Computation in Python •

1:17

Listing 4.15 – continued

# Here we use etuples for the output terms
obs_sum = etuple(mt.sum, obs_lv)
alpha_new = etuple(mt.add, alpha_lv, obs_sum)
beta_new = etuple(mt.add, beta_lv, etuple(mt.sub, etuple(mt.sum, N_lv), obs_sum))

beta_post_rv_lv = etuple(

mt.BetaRV, alpha_new, beta_new, beta_size, beta_rng, name=etuple(add,

(cid:44)→

beta_name_lv, "_post")

)
binom_new_lv = etuple(
mt.BinomialRV,
N_lv,
beta_post_rv_lv,
binom_size,
binom_rng,
name=etuple(add, binom_name_lv, "_post"),

)

return lall(eq(x, mt.observed(obs_lv, binom_lv)), eq(y, binom_new_lv))

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

Finally, Listing 4.16 shows how the goal can be applied to the model’s graph and how a new Theano graph and

PyMC3 model is constructed from the output.

Listing 4.16: Running the beta-binomial conjugate goal and creating a PyMC3 model for the results.

1 from symbolic_pymc.theano.pymc3 import graph_model

2

3
4 q = var()
5 res = run(1, q, betabin_conjugateo(fgraph.outputs[0], q))

6
7 expr_graph = res[0].eval_obj
8 fgraph_conj = expr_graph.reify()

9
10 # Convert the Theano graph into a PyMC3 model
11 model_conjugated = graph_model(fgraph_conj)

12

Willard (2020b) gives a more thorough walk-through of symbolic-pymc and miniKanren–using TensorFlow

graphs.

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

1:18

• Brandon T. Willard

5 DISCUSSION
Looking forward, the “functions grimoire” project of Johansson (2020), Fungrim, is a great example of community-
sourced and programmatically encoded domain knowledge in mathematics. It serves as a prime example of an
independently developed, high-level knowledge encoding effort from which relations could be sourced and used
by miniKanren in Python. In Byrd (2020) miniKanren is used to reason over an external database of medical
knowledge, so the a precedent for this type of work has already been set.

One currently unexplored area involves interactions between miniKanren and symbolic algebra libraries.
Although a lot of symbolic algebra is possible using miniKanren alone, we don’t necessarily expect it to replace
symbolic algebra libraries any time soon. Luckily, when our statistical modeling goals require advanced symbolic
algebra functionality provided by existing libraries, like SymPy (SymPy Development Team 2014), they can be
used directly from within miniKanren. For example, one could use SymPy to perform a Laplace transform–or
its inverse–within an implementation of a normal scale mixture (Bhadra et al. 2020) relation between random
variables, since the underlying mathematical relation is functionally described by Laplace transforms in both
directions.

A combination of miniKanren and computer algebra could also be used to realize elements of the computer

algebra and interactive theorem proving synthesis described in Kaliszyk and Wiedijk (2007).

Perhaps another concrete example of how a symbolic algebra library could be leveraged by miniKanren is given
by the system described in Walia et al. (2018). Here, miniKanren could be used to implement the typing rules,
and the integrate steps could be outsourced to SymPy. By targeting standard NumPy (Numpy Developers 2017)
output, the results could be used by any number of systems, like JAX, that provide vectorization, JIT compilation,
etc.

Ultimately, we’ve described the construction of a strictly Python version of the system in Walia et al. (2018)
that makes use of multiple popular, actively developed projects specializing in their respective domains (e.g.
symbolic integration, vectorization, JIT compilation). The original implementation uses a complex pipeline (Walia
et al. 2018, Figure 1) that operates across multiple independent systems, one of which is Hakaru (Narayanan et al.
2016). Hakaru is an entirely independent system and programming language for probabilistic programming. In
contrast, the system we describe is simply an orchestration of existing Python libraries driven by miniKanren,
and it can make use of whichever tensor libraries, compilation frameworks, and PPLs are most suitable.

Regarding miniKanren itself, consider the following idiom:

1 (conde ((== lhs match-form-1)

(== rhs replace-form-1))
((== lhs match-form-2)
(== rhs replace-form-2))
...)

2

3

4

5

6

condes like this are natural for encoding identities of the form match-form-1 = replace-form-1 that are applied
to the terms lhs and rhs. They also appear in implementations of relational interpreters where they encode the
supported forms of a target language (e.g. variable assignment, conditionals, etc.)

These conde idioms comprise a large portion of the miniKanren work implied here, and their size could grow
very quickly over time. This leads to performance questions that are possibly answered by work on guided search
(Swords and Friedman; Zhang et al. 2018) and discerning conde branch selection (Boskin et al. 2018).

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

miniKanren as a Tool for Symbolic Computation in Python •

1:19

There is also little reason to think that a single conde will–or even should–encode most of a system’s imple-
mented identities, so a means of compiling goals–say–for the purposes of merging branches might be worth
considering, as well.

With equational identities nicely encoded by conde forms, there’s also the possibility that the rewrite-
completion algorithms mentioned in Section 2 could be applied automatically. When a complete and reduced
rewrite system can be generated from a conde, it would be interesting to know whether or not the resulting
system improves the general performance of miniKanren.

Also, is it possible that some cases of non-terminating goal orderings could be avoided by completion? Likewise,
could the results of completion be used to produce a new, equivalent conde that results in fewer goal evaluations
and/or failed branches?

Alternatively, is it possible that miniKanren could be utilized by a completion algorithm itself so that it produces
potentially relevant results when it otherwise wouldn’t terminate (e.g. via infinite goal streams)? What are the
advantages of performing completion in a relational fashion, and what unique elements can miniKanren provide
to that situation (e.g. easier implementation of experimental completion algorithms)?

Proving rewrite termination and completion itself can involve SAT problems (Endrullis et al. 2008; Klein and

Hirokawa 2011); can miniKanren’s constraint capabilities–among other things–be applied in this area?

Our Python implementation of miniKanren comes with experimental support for associative and commutative
(AC) relations. We’ve found utility in assigning these two properties to existing operators from other libraries
(e.g. addition operators in Theano and TensorFlow) as a means of adding flexibility to the exact representation of
graphs. This is especially important in instances where graph normalization isn’t entirely consistent or available
via the targeted graph backend (e.g. TensorFlow).

The process of implementing these AC relations has opened a few questions that cannot be properly treated
here. Questions such as ”How can operators with arbitrary–but known and fixed–arities be efficiently supported?”
and ”How can we overcome some of the goal ordering issues that arise due to commutativity?”.

In (Willard 2020a), we address the latter question with a “groundedness”-based term reordering goal. This
reordering is performed on the cdr sub-terms as a relation is applied between term graphs, since the order in
which a relation is applied to corresponding sub-terms is–generally–immaterial. In other words, when walking a
goal relo between the lists ’(a b) and ’(c 2), for fresh variables a, b, and c, the goal can be applied in any order,
e.g. (relo a c) then (relo b 2), or (relo b 2) then (relo a c). When–for instance–(relo a b) diverges
because both arguments are fresh, while (relo b 2) fails, a walk that performs the former ordering will diverge,
while one that does the latter will fail. The “groundedness” ordering goal simply reorders the corresponding pairs
according to how grounded they are to arrive at the non-diverging order of application.

Finally, we would like to point out the potential for an exciting “feedback loop”: as statistical modeling improves
the processing of miniKanren (Zhang et al. 2018), miniKanren can also improve the process of statistical modeling.

ACKNOWLEDGMENTS
The author would like to thank Jason Hemann and William Byrd for their invaluable input and inspiring work.

REFERENCES
BLAS (Basic Linear Algebra Subprograms), 2020. URL https://www.netlib.org/blas/.
Generators - Python Wiki, 2020. URL https://wiki.python.org/moin/Generators.
Graph optimization — Theano 1.0.0 documentation, 2020. URL http://www.deeplearning.net/software/theano/extending/optimization.html#

PatternSub.

JAX. Google, May 2020. URL https://github.com/google/jax.
LAPACK — Linear Algebra PACKage, 2020. URL https://www.netlib.org/lapack/.
PEP 342 – Coroutines via Enhanced Generators, 2020a. URL https://www.python.org/dev/peps/pep-0342/. Library Catalog: www.python.org.
PEP 424 – A method for exposing a length hint, 2020b. URL https://www.python.org/dev/peps/pep-0424/. Library Catalog: www.python.org.

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

1:20

• Brandon T. Willard

PyTorch. pytorch, May 2020. URL https://github.com/pytorch/pytorch.
TensorFlow. Google, May 2020. URL https://github.com/tensorflow/tensorflow.
Tangent. Google, May 2020. URL https://github.com/google/tangent.
Franz Baader and Tobias Nipkow. Term Rewriting and All That. Cambridge university press, 1999. URL https://books.google.com/books?hl=

en&lr=&id=N7BvXVUCQk8C&oi=fnd&pg=PR9&ots=cN35RbZA i&sig=zNk3Wk4w 4YRY6AMKxudY0gIuUI.

James Bergstra, Olivier Breuleux, Fr´ed´eric Bastien, Pascal Lamblin, Razvan Pascanu, Guillaume Desjardins, Joseph Turian, David Warde-Farley,
and Yoshua Bengio. Theano: A CPU and GPU Math Expression Compiler. In Proceedings of the Python for Scientific Computing Conference
(SciPy), Austin, TX, June 2010.

Anindya Bhadra, Jyotishka Datta, Nicholas G. Polson, and Brandon Willard. Default bayesian analysis with global-local shrinkage priors.

Biometrika, 103(4):955–969, December 2016. ISSN 0006-3444. doi: 10.1093/biomet/asw041.

Anindya Bhadra, Jyotishka Datta, Nicholas G. Polson, and Brandon Willard. Global-local mixtures. Sankhya A, pages 1–22, February 2020.

URL http://arxiv.org/abs/1604.07487.

Benjamin Strahan Boskin, Weixi Ma, David Thrane Christiansen, and Daniel P. Friedman. A Surprisingly Competitive Conditional Operator.

2018. URL https://www.brinckerhoff.org/scheme2018/papers/Boskin Ma Christiansen Friedman.pdf.

William E. Byrd. Relational Programming in miniKanren: Techniques, Applications, and Implementations. PhD thesis, faculty of the University
Graduate School in partial fulfillment of the requirements for the degree Doctor of Philosophy in the Department of Computer Science,
Indiana University, 2009. URL http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.363.5478.

William E. Byrd. Webyrd/mediKanren, May 2020. URL https://github.com/webyrd/mediKanren.
Jacques Carette and Chung-Chieh Shan. Simplifying Probabilistic Programs using Computer Algebra. In Marco Gavanelli and John Reppy,
editors, Practical Aspects of Declarative Languages, pages 135–152, Cham, 2016. Springer International Publishing. ISBN 978-3-319-28228-2.
Jacques Carette, Spencer Smith, John McCutchan, Christopher Anand, and Alexandre Korobkine. Case studies in model manipulation for

scientific computing. In International Conference on Intelligent Computer Mathematics, pages 24–37. Springer, Springer, 2008.

George Casella and Christian P. Robert. Rao-Blackwellisation of sampling schemes. Biometrika, 83(1):81–94, 1996. URL http://biomet.

oxfordjournals.org/content/83/1/81.short.

J¨org Endrullis, Johannes Waldmann, and Hans Zantema. Matrix interpretations for proving termination of term rewriting. Journal of

Automated Reasoning, 40(2-3):195–220, 2008.

Python Software Foundation. 6. Expressions — Python 3.8.3 documentation, 2020. URL https://docs.python.org/3/reference/expressions.

html#yieldexpr.

Andrew Gelman. Transforming parameters in a simple time-series model; debugging the Jacobian, January 2019. URL https://statmodeling.

stat.columbia.edu/2019/01/25/transforming-parameters-in-a-simple-time-series-model-debugging-the-jacobian/.

Maria I. Gorinova, Dave Moore, and Matthew D. Hoffman. Automatic Reparameterisation in Probabilistic Programming. 2018.
Jason Hemann and Daniel P. Friedman. µKanren: A minimal functional core for relational programming.
Programming Workshop 2013, 2013. URL http://webyrd.net/scheme-2013/papers/HemannMuKanren2013.pdf.

In Scheme and Functional

Jason Hemann and Daniel P. Friedman. A framework for extending microkanren with constraints. arXiv preprint arXiv:1701.00633, 2017.
Matthew D. Hoffman. Autoconj: Recognizing and Exploiting Conjugacy Without a Domain-Specific Language. In Advances in Neural

Information Processing Systems, pages 10737–10747, 2018.

G´erard Huet. A complete proof of correctness of the Knuth-Bendix completion algorithm. Journal of Computer and System Sciences, 23(1):

11–21, 1981.

Fredrik Johansson. Fungrim, May 2020. URL https://github.com/fredrik-johansson/fungrim.
Cezary Kaliszyk and Freek Wiedijk. Certified computer algebra on top of an interactive theorem prover. In Towards Mechanized Mathematical

Assistants, pages 94–105. Springer, 2007. URL http://link.springer.com/chapter/10.1007/978-3-540-73086-6 8.

Oleg Kiselyov, Chung-chieh Shan, Daniel P. Friedman, and Amr Sabry. Backtracking, interleaving, and terminating monad transform-

ers:(functional pearl). ACM SIGPLAN Notices, 40(9):192–203, 2005.

Dominik Klein and Nao Hirokawa. Maximal completion. In 22nd International Conference on Rewriting Techniques and Applications (RTA’11).

Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2011.

Rasmus Munk Larsen and Tatiana Shpeisman. TensorFlow Graph Optimizations. 2019. URL https://research.google/pubs/pub48051/.
David Lunn, David Spiegelhalter, Andrew Thomas, and Nicky Best. The BUGS project: Evolution, critique and future directions. Statistics in

medicine, 28(25):3049–3067, 2009.

Praveen Narayanan, Jacques Carette, Wren Romano, Chung-chieh Shan, and Robert Zinkov. Probabilistic inference by program transformation

in Hakaru (system description). In International Symposium on Functional and Logic Programming, pages 62–79. Springer, 2016.

Radford M. Neal. Slice sampling. Annals of statistics, pages 705–741, 2003. URL http://www.jstor.org/stable/3448413.
Joseph P. Near, William E. Byrd, and Daniel P. Friedman. Alpha-leanTAP: A Declarative Theorem Prover for First-Order Classical Logic. In

ICLP, volume 5366, pages 238–252. Springer, 2008.

Numpy Developers. Numpy, 2017. URL http://www.numpy.org.
Richard Peasgood. A Method to Symbolically Compute Convolution Integrals. 2009. URL https://uwspace.uwaterloo.ca/handle/10012/4884.

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

miniKanren as a Tool for Symbolic Computation in Python •

1:21

Nicholas G. Polson, James G. Scott, and Jesse Windle. Bayesian inference for logistic models using P´olya–Gamma latent variables. Journal of
the American Statistical Association, 108(504):1339–1349, 2013. URL http://www.tandfonline.com/doi/abs/10.1080/01621459.2013.829001.

Alexey Radul. Rules, May 2020. URL https://github.com/axch/rules.
Kelly Roach. Meijer G function representations. In Proceedings of the 1997 International Symposium on Symbolic and Algebraic Computation,

pages 205–211. ACM, 1997.

Christian Robert. The Bayesian Choice: From Decision-Theoretic Foundations to Computational Implementation. Springer Science & Business
Media, 2007. URL https://books.google.com/books?hl=en&lr=&id=6oQ4s8Pq9pYC&oi=fnd&pg=PR7&dq=robert+bayesian+choice&ots=
qCKZiHXdKh&sig=69Qk38It3hHD84ufC2dvXtumFlY.

Matthew Rocklin. Mathematically Informed Linear Algebra Codes through Term Rewriting. PhD thesis, PhD Thesis, August, 2013. URL

http://people.cs.uchicago.edu/∼mrocklin/storage/dissertation.pdf.

Matthew Rocklin. Logpy: Logic Programming in Python, January 2018. URL https://github.com/logpy/logpy.
Matthew Rocklin. Multipledispatch, January 2019. URL https://github.com/mrocklin/multipledispatch.
Guido Van Rossum.

Neopythonic: Tail Recursion Elimination, April 2009.

URL https://neopythonic.blogspot.com/2009/04/

tail-recursion-elimination.html. Library Catalog: Blogger.

John Salvatier, Thomas V. Wiecki, and Christopher Fonnesbeck. Probabilistic programming in Python using PyMC3. PeerJ Computer Science,

2:e55, April 2016. ISSN 2376-5992. doi: 10.7717/peerj-cs.55.

Tetsuya Sato, Alejandro Aguirre, Gilles Barthe, Marco Gaboardi, Deepak Garg, and Justin Hsu. Formal verification of higher-order probabilistic

programs. arXiv preprint arXiv:1807.06091, 2018.

James G. Scott. Parameter expansion in local-shrinkage models. arXiv preprint arXiv:1010.5265, 2010. URL http://arxiv.org/abs/1010.5265.
Chung-chieh Shan and Norman Ramsey. Exact Bayesian Inference by Symbolic Disintegration. In Proceedings of the 44th ACM SIGPLAN
Symposium on Principles of Programming Languages, POPL 2017, pages 130–144, New York, NY, USA, 2017. ACM. ISBN 978-1-4503-4660-3.
doi: 10.1145/3009837.3009852.

Stan Development Team. Stan: A C++ Library for Probability and Sampling, Version 2.2. 2014. URL http://mc-stan.org/.
Cameron Swords and Daniel P. Friedman. Guided Search in miniKanren.
SymPy Development Team. SymPy: Python Library for Symbolic Mathematics. 2014. URL http://www.sympy.org.
Nicolas Vasilache, Oleksandr Zinenko, Theodoros Theodoridis, Priya Goyal, Zachary DeVito, William S. Moses, Sven Verdoolaege, Andrew
Adams, and Albert Cohen. Tensor Comprehensions: Framework-Agnostic High-Performance Machine Learning Abstractions. arXiv
preprint arXiv:1802.04730, 2018.

Rajan Walia, Praveen Narayanan, Jacques Carette, Sam Tobin-Hochstadt, and Chung-chieh Shan. From high-level inference algorithms to

efficient code. arXiv:1805.06562 [cs, math], May 2018. URL http://arxiv.org/abs/1805.06562.

Richard Wei, Lane Schwartz, and Vikram Adve. DLVM: A modern compiler framework for neural network DSLs. Urbana, 51:61801, 2017.
Brandon T. Willard. A Role for Symbolic Computation in the General Estimation of Statistical Models, January 2017. URL https://

brandonwillard.github.io/a-role-for-symbolic-computation-in-the-general-estimation-of-statistical-models.html.

Brandon T. Willard. Readable Strings and Relational Programming in Hy, December 2018. URL https://brandonwillard.github.io/

readable-strings-and-relational-programming-in-hy.html. Library Catalog: brandonwillard.github.io.

Brandon T. Willard. Pull Request #27 · pythological/kanren, 2020a. URL https://github.com/pythological/kanren/pull/27. Library Catalog:

github.com.

Brandon T. Willard. A Tour of Symbolic PyMC, May 2020b. URL https://pymc-devs.github.io/symbolic-pymc/symbolic-pymc-tour.html.
Brandon T. Willard. Logical-unification. Pythological, April 2020c. URL https://github.com/pythological/unification.
Brandon T. Willard. Pythological/kanren, 2020d. URL https://github.com/pythological/kanren. Library Catalog: github.com.
Brandon T. Willard. Pythological/python-cons. Pythological, March 2020e. URL https://github.com/pythological/python-cons.
Lisa Zhang, Gregory Rosenblatt, Ethan Fetaya, Renjie Liao, William E. Byrd, Matthew Might, Raquel Urtasun, and Richard Zemel. Neural Guided
Constraint Logic Programming for Program Synthesis. arXiv:1809.02840 [cs, stat], September 2018. URL http://arxiv.org/abs/1809.02840.

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

