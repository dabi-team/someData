Explicit approximation of stochastic optimal feedback control
for combined therapy of cancer (cid:63)

Mazen Alamir a

aUniv. Grenoble Alpes, CNRS, Grenoble INP, GIPSA-lab, 38000 Grenoble, France

0
2
0
2

t
c
O
3
2

]

Y
S
.
s
c
[

2
v
7
3
9
4
0
.
5
0
9
1
:
v
i
X
r
a

Abstract

In this paper, a tractable methodology is proposed to approximate stochastic optimal feedback treatment in the context of
mixed immuno-chemo therapy of cancer. The method uses a ﬁxed-point value iteration that approximately solves a stochastic
dynamic programming-like equation. It is in particular shown that the introduction of a variance-related penalty in the latter
induces better results that cope with the consequences of softening the health safety constraints in the cost function. The
convergence of the value function iteration is revisited in the presence of the variance related term. The implementation
involves some Machine Learning tools in order to represent the optimal function and to perform complexity reduction by
clustering. Quantitative illustration is given using a commonly used model of combined therapy involving twelve highly
uncertain parameters.

Keywords. Stochastic optimal control; Stochastic Dynamic Programming, Cancer therapy; Support Vector Machine,

Clustering; Fixed-Point value iteration; Convergence analysis.

1 Introduction

Rationalizing drug delivery is an active research ﬁeld
that commonly involves population models with high
number of uncertain parameters. Unfortunately, these
parameters which are by nature highly variable between
individuals, are inaccessible to identiﬁcation because of
the lack of excitation [9].

The great majority of applied mathematical-like works
solve deterministic optimal control problems which are
formulated using the nominal values of the parameters
[15,6,11]. While this might be important to draw qualita-
tive conclusions regarding the patterns of optimal strate-
gies (intensive treatment, presence of singular arcs, etc);
the resulting proﬁles do not accommodate for the high
dispersion of the parameters.

Using repetitive solutions of such open-loop nominal
scheduling strategies in a feedback mode through the
receding-horizon principle (apply the ﬁrst part of the op-
timal strategy and recompute a new optimal injection
proﬁle at the next decision instant and so on leading to

(cid:63) This paper was not presented at any IFAC meeting.
Corresponding author M. Alamir. Tel. +33476826326. Fax
+33476826388.

Email address: mazen.alamir@grenoble-inp.fr (Mazen

Alamir).

the so called Model Predictive Control design (MPC).)
obviously reduces the drawback of parameters mismatch
[4,5]. However, the performances can only be observed
a posteriori as nothing is explicitly done to address the
presence of uncertainties.

Another option is to use a parameterized state feedback
law and to optimally tune its design parameters using
explicitly the statistical description of the model’s pa-
rameters dispersion by means of the randomized opti-
mization framework [1]. Unfortunately, as far as avail-
able works are concerned, this is to be done for each ini-
tial state in the proposed frameworks.

Stochastic model predictive control (SMPC) oﬀers an
attractive alternative through the use of a set of sce-
narios in the on-line computation in order to minimize
the approximate version of the expectation of the cost
function [13,12,2]. This lead to a solution for each initial
state but does not give a global overview on the per-
formance on a whole region of the state space. On the
other hand, this solution can be scalable in the dimen-
sion of the state which enables the use of almost arbi-
trarily complex models of the underlying dynamics.

Stochastic Dynamic Programming (SDP) [7,3,10] is a
framework that, at least conceptually, outperforms the
previous approaches in that it gives an 1) explicit state
feedback law that 2) explicitly incorporates the statisti-

Preprint submitted to Automatica

26 October 2020

 
 
 
 
 
 
cal description of the parameters dispersion while being
3) deﬁned on a whole region of interest within the state
space.

2 Problem statement

2.1 The dynamic model

Unfortunately, the price to pay to get these advantages
is to represent the Bellman function over the extended
space of state and control making this approach non
scalable in the dimension of the state and control. More-
over, when minimizing the residual of the SDP equation,
each call involves the computation of statistically deﬁned
quantities and this, for the computation to be relevant,
should theoretically involve a high number of randomly
sampled instances of the uncertain model’s parameters.
Note however that this last drawback is obviously shared
by the SMPC approach.

The literature on solving the stochastic dynamic pro-
gramming equation is huge and a complete survey of it is
out of the scope of this paper. For a complete and recent
survey, one can consult [3]. This paper does not claim a
particularly novel algorithm to solve the SDP equation.
Rather it focuses on the issue of introducing a variance-
related term in the deﬁnition of the cost function, inves-
tigates its impact on handling the health-related con-
straint in the combined therapy of cancer and revis-
its the convergence proof of the underlying value func-
tion ﬁxed-point iteration when such additional variance-
related term is added.

More precisely, a simple framework is proposed for a
moderate sized models 1 in which Machine Learning
(ML) tools are used. More precisely, the model’s struc-
ture uses a Support Vector Machine (SVM) regression
model to represent the value function. On the other
hand, a clustering approach is used to approximate the
statistical quantities using a lower number of samples.
This leads to a tractable approximate solution that
can be obtained in less than 20 minutes when using a
grid of 9604 points in the state/control space when no
parallelization is used. Drastic reduction of the compu-
tation time can be obtained since the proposed scheme
is amenable to massive parallelization.

This paper is organized as follows: The problem of com-
bined therapy is stated in Section 2. Some recalls regard-
ing SDP are proposed in Section 3 and some results are
proposed for the convergence of a ﬁxed-point iteration
that is used to solve the associated equations. Section 4
details the proposed approximate solution’s framework
while Section 5 shows the results on the combined ther-
apy of cancer and discusses some issues. Finally, the pa-
per ends with Section 6 that summarizes the paper’s
contributions and gives some hints for further investiga-
tion.

Let us consider the population model used in [8] to de-
scribe the dynamics involved in the combined immuno-
chemo therapy:

˙x1 = ax1(1 − bx1) − c1x4x1 − k3x3x1
˙x2 = −δx2 − k2x3x2 + s2
˙x3 = −γ0x3 + u2

x4 − rx4 − p0x4x1 − k1x4x3 + s1u1

x1
h + x1

˙x4 = g

where

(1)
(2)
(3)

(4)

x1
x2
x3
x4
u1
u2

tumor cell population
circulating lymphocytes population
chemotherapy drug concentration
eﬀector immune cell population
rate of introduction of immune cells
rate of introduction of chemotherapy

The description of the role of each groups of term is given
in Table 1 for the sake of clarity.

Eq. Term

Description

(1)

ax1(1 − bx1)

Logistic tumor growth

(1) −c1x4x1

Death of tumor due to eﬀector cells

(1) −k3x3x1

Death of tumor due to chemotherapy

(2) −δx2

Death of circulating lymphocytes

(2) −k2x3x2

Death of lymphocytes due to chemo

(2)

s2

Constant source of lymphocytes

(3) −γ0x3
x1
h + x1

(4)

g

Exponential decay of chemotherapy

x4

Stimulation of tumor on eﬀector cells

(4) −rx4

Death of eﬀector cells

(4) −p0x4x1

Inactivation of eﬀector cells by tumor

(4) −k1x4x3

Death of eﬀector cells due to chemo

Table 1
Signiﬁcation of the terms involved in the dynamic model
(1)-(4) [source [8]]

When referred to the nominal values of the parameters
involved in the model (1)-(4), the following values are
used:

1 the combined therapy model used involves four states and
two controls which are commonly encountered sizes in all
the related works.

a = 0.25, b = 1.02 × 10−14, c1 = 4.41 × 10−10, g = 1.5 × 10−2
h = 20.2, k2 = k3 = 0.6, k1 = 0.8, p0 = 2 × 10−11, r = 0.04
s1 = 1.2 × 107, s2 = 7.5 × 106, δ = 1.2 × 10−2, γ0 = 0.9

2

Note that the dynamic model (1)-(4) involves 14 param-
eters. It is worth noting however that the order of mag-
nitude of x1 is about 109 while h ≈ 20. This means that
h acts only when the tumor is almost disappearing 2 .
That is the reason why in the remainder of this paper,
this parameter is supposed to be known and hence it is
not included in the set of uncertain parameters. As it
is shown later, this enables a separable structure of the
evolution map to be used [see (6)].

Gathering all the other parameters in a vector p ∈ R13
and using some discretization scheme with some sam-
pling period τ , it is possible to put the dynamics above
in the following condensed form for the easiness of nota-
tion:

x+ = f (x, u, p)

(x, u, p) ∈ R4 × R2 × R13

= Φ(x, u)Ψ(p)

(5)
(6)

for straightforward deﬁnition of Φ and Ψ.

The trajectory of the system starting at initial state x
under a control proﬁle u and when the parameter value
p holds is denoted by xu(k|x, p), namely:

xu(k + 1|x, p) = f (cid:0)xu(k|x, p), u(k), p(cid:1)
xu(0|x, p) = x

2.2 The control objective and constraints

The aim of the combined therapy is to reduce the size
of the tumor population x1 while keeping the level of
lymphocyte cells x2 above an upper bound xmin
. This
has to be done using quantized drug delivery:

2

u ∈ U := {0, umax

1

} × {0, umax

2

}

(7)

so that an inﬁnite sequence of control lying inside U is
denoted hereafter by U∞.

In order to address the control objective, the following
stage cost function can be used that incorporates the
constraint on x2 as a soft constraint:

L(x, u) := x2

1 + ρc max{0, xmin

2 − x2} + ρ1u1 + ρ2u2 (8)

so that if the model’s parameters were perfectly
known, an optimization problem can be deﬁned for all

given initial state x as follows:

P(x|p) :

min
u∈U∞

J(u|x, p) :=

(cid:16)

γkL

∞
(cid:88)

k=0

xu(k|x, p), u(k)

(cid:17)

(9)

for some γ ∈ (0, 1]. Now, since the parameters are sup-
posed to be unknown, the stochastic control approach
amounts at replacing the deterministic cost function (9)
by a statistically deﬁned one such as:

Jα(u|x, Π) := µ(J(u|x, ·)) + ασ(J(u|x, ·))
α (u, x)

=: S (J)

(10)

(11)

where µ(·) and σ(·) stand respectively for the expecta-
tion and the variance of their argument when p is sam-
pled according to some supposedly known Probability
Density Function (pdf) Π. Note that (11) simply intro-
duces a short notation of the r.h.s of (10).

This leads to the following stochastic optimization prob-
lem:

Pα(x|Π) : min
u∈U∞

Jα(u|x, Π)

(12)

Note that in many stochastic control-related works, at-
tention is focused on the expectation of the cost function
so that α = 0 is widely used in (10). This is not totally
appropriate in the case of cancer therapy. Indeed, expec-
tation is a relevant indicator only when high number of
realizations are expected to take place 3 in which only
the global average is of interest. In the case of cancer
therapy, a scenario is a patient being treated. This is why
one should obviously be interested in the risk that each
patient aﬀord during the treatment. In such cases, it
is precisely those bad scenarios with non negligible likeli-
ness that really matter. This has to do not only with the
expectation but deﬁnitively with the associated variance
as well. This explains the use of α > 0 in (12).

A part of the discussion and a large part of the results
shown in this paper are dedicated to showing the rele-
vance of introducing the variance related term the cancer
therapy stochastic control problem’s formulation on one
hand, and on the convergence of the computation scheme
in the presence of a non vanishing α in the stochastic
cost formulation.

In the next section, some recalls are proposed on the
Stochastic Dynamic Programming equations that might
be invoked to approximately solve the stochastic opti-
mization problem (12).

2 On the other hand, without h, the eﬀector immune pop-
ulation will keep growing while the tumor is absent which
contradicts its very deﬁnition as a tumor stimulated immune
population.

3 such as saving energy in building management for instance
despite of bad knowledge of exogenous parameters such as
power demands and whether conditions.

3

3 Recalls and preliminary results

3.1 Stochastic Dynamic Programming

SDP attempts to solve the following functional equation
in which the unknown function V (·) is the optimal solu-
tion of (12). More precisely:

V (x) := min
u∈U

Q(x, u)

where

Q(x, u) := L(x, u) + γ min
v∈U

where x+ = f (x, u, p)

(cid:104)
S (Q)

α (x, u, v)

(cid:105)

(13)

(14)

(15)

in which S (Q)(x, u, v) is deﬁned in a similar way as
S (J)(u, x) [see (11)]:

(cid:17)

α (x, u, v) := µ(cid:0)Q(f (x, u, ·), v)
S (Q)

+ασ(cid:0)Q(f (x, u, ·), v)
(16)
where here again, µ(·) and σ(·) are respectively the ex-
pectation and the variance of their argument when p
(involved in the deﬁnition of f (x, u, p)) is sampled ac-
cording to the pdf Π.

(cid:17)

The fact that V satisfying (13)-(14) is a solution to (12)
is a direct consequence of the Bellman principle and the
fact that L = µ(L) + σ(L) = L + 0 since L(x, u) is a
deterministic p-unrelated term.

From the above, it comes out that the truly unknown
function to ﬁnd is Q(·, ·) since the optimal value function
V (·) as well as the optimal control are then recovered
from the static optimization problem (13).

Now it is not hard to see from (14) that Q is a solution
of a ﬁxed-point iteration:

Q(i+1) = F

(cid:16)

Q(i)(cid:17)

(17)

where the operator F (commonly called the Bellman
operator) is deﬁned by:

F (Q)(x, u) := L(x, u) + γ min
v∈U

(cid:105)
(cid:104)
S (Q)(f (x, u, ·), v)

(18)

and assumptions are needed. They are introduced here-
after.

First of all, the following continuity assumption of the
dynamics is used:

Assumption 1 (Continuous dynamics) The map f
describing the discrete-time state evolution (5) is contin-
uous in its arguments.

Regarding the uncertain vector p, the following assump-
tion is needed

Assumption 2 (Finitely supported uncertainties)
there exists a compact set P to which belong all possible
realizations of the uncertain vector p.

This seems a quite reasonable assumption when physi-
cally meaningful model’s parameters are invoked. Still,
this is rigorously not the case for Gaussian distributions
for instance for which any arbitrarily high values are rig-
orously admissible.

Deﬁnition 3.1 (Bounded excursion) A map G de-
ﬁned on X × U is said to have B-bounded excursions if
the following inequality holds:

|G(f (x, u, p), v) − µ(G(f (x, u, ·), v))| ≤ B

(19)

for all (x, u, v, p) ∈ X × U2 × P.

This deﬁnition simply states that the excursion of
the realizations G(f (x, u, p), v) from the mean value
µ(cid:0)G(f (x, u, ·), v)(cid:1) is bounded. It goes without say-
ing that, under Assumption 1, such a bound exists as
soon as the map G is continuous. since all the involved
bounding sets are compact.

Lemma 1 (Fixed-Point convergence) Under As-
sumptions 1 and 2, if the ﬁxed point map F invoked
in (17) produces only continuous maps Q(i) with B-
bounded excursions for some B > 0, then the ﬁxed point
iteration converges on Z := X × U provided that the
penalty α on the variance term in (16) satisﬁes:

α <

γ − 1
2γB

(20)

In the next section, some convergence results regarding
the above ﬁxed-point iterations are derived in a general
conceptual setting before a speciﬁc implementation is
proposed in Section 4 for the cancer combined therapy.

and for suﬃciently small sampling period τ that is used
to derive the discrete-time dynamics (5).

Proof. See Appendix A.1.

3.2 Fixed-Point iteration convergence analysis

In order to derive suﬃcient conditions for the conver-
gence of the ﬁxed-point iteration (17), some deﬁnitions

From the above lemma, one can clearly derive the stan-
dard convergence result that is known to hold when no
penalty on the variance is used (see for instance [7,10,3]
and the references therein):

4

Corollary 2 (Convergence for pure expectation)
Under the assumptions of Lemma 1, if the cost is deﬁned
exclusively on the expectation (no penalty on the vari-
ance in (16)), then the ﬁxed point iteration is convergent
on Z = X × U.

It is worth underlying that the convergence results cited
above depend on the assumption according to which the
successive iterates Q(i) produced by the Bellman map
F admit a B-bounded excursions with common upper
bound B. The way this condition is enforced is discussed
in the next section.

4 The proposed computation framework

4.1 Parametrization of Q(x, u)

In the previous section, the SDP equation and the re-
lated ﬁxed-point iteration have been deﬁned in a concep-
tual framework. In this framework, the unknown func-
tion Q(x, u) one is looking for has no speciﬁc ﬁnite-
dimensional representation that would be compatible
with concrete computation schemes. In this section, this
parameterization aspect is addressed.

For the sake of simplicity, the notation z = (x, u) and
Z := X×U is used so that Q(z), f (z, p) stands for Q(x, u)
and f (x, u, p) respectively. The ﬁnite dimensional pa-
rameterization of Q is obtained through the following
steps:

• First of all, a ﬁxed grid of points Z := {z(i)}ng

deﬁned on the compact subset Z of interest.

i=1 is

• Denote by q := {qi}ng

i=1 the vector of values of the

function Q at the grid points, namely qi = Q(z(i)).

• Choose some regression model (Polynomial, Gaus-
sian, Support Vector Machine Regressor (SVMR),
etc.) and denoted it by ˆQ. As far as this work is con-
cerned, a SVMR with gaussian basis is used with the
default parameters used in the scikit-learn Machine
Learning (ML) library [14].

• This choice enables to associate to each vector of val-
ues q ∈ Rng a function ˆQ(·|q) deﬁned on Z which is
precisely the one identiﬁed (or learned to use a ML
vocabulary) using the learning data (Z, q).

Based on the above items, it is now possible to state the
following deﬁnition:

Deﬁnition 4.1 (Admissible regression model) A
regression model is said to be admissible if and only if for
all set Z of ﬁnite grid points in Z and any compact set
of function values Q ⊂ Rng , there exists B > 0 such that
all identiﬁed maps ˆQ(·|q) with q ∈ Q shows B-bounded
excursions in the sense of Deﬁnition 3.1.

5

4.2 Main convergence result

Using the above preliminary results and deﬁnitions, the
following main result regarding the convergence of the
proposed Fixed-Point iteration scheme can be stated as
follows:

Assumptions
Proposition 3 (Main result) Under
1 and 2,
if an admissible regression model(in the
sense of Deﬁnition 4.1) is used over some grid points
Z := {z(i)}ng
i=1 with the initialization qi = L(z(i)) to
solve the stochastic optimal feedback of the combined
therapy of cancer as stated in Section 2, then the result-
ing ﬁxed-point iteration (18) with γ ∈ (0, 1) is conver-
gent provided that the variance related penalty α and the
sampling period τ are taken suﬃciently small.

Proof. See appendix A.2.

The only remaining task is to ﬁnd a regression model
that is admissible in the sense of Deﬁnition 4.1. Fortu-
nately, there are many options. The one that is used in
the remainder of this paper is the Support Vector Ma-
chine regressor (SVMR) which shows the following struc-
ture:

ˆQ(z|q) := β0(q) +

ng
(cid:88)

i=1

βi(q)G(z(i), z)

(21)

where the coeﬃcients βi(q) admits uniform bound if q
belongs to some compact set Q.

Remark 4 It is worth mentioning at this stage that the
convergence of the ﬁxed point-iteration does not tell us
much on the distance of the resulting solution to the true
optimal solution. This heavily depends on the density of
the grid Z on one hand and on the quality of the approx-
imation of the statistical quantities involved in the very
deﬁnition of the cost function on the other hand. These
two aspects remain obviously at the origin of the curse
of dimensionality that restricts the application of the un-
derlying SDP approach to system of moderate sizes.

4.3 Computation of the expectation and variance

The ﬁxed-point iteration (18) requires the computation
of the map S (Q)(f (x, u, ·), v) which involves the com-
putation of the expectations and variances of quantities
over the probability space of parameter values. In this
section, the way this is done concretely is explained.

Recall that the r.h.s of the dynamics in (6) can be decom-
posed into two multiplicative terms x+ = Φ(x, u)Ψ(p)
where only the second term is parameter-dependent.
Consequently, the computation of the expectation of x+
needs the statistics of Ψ(p) ∈ R14 to be approximated.
This is done by identifying ncl clusters based on a set Sψ

of ns samples of the vector Ψ(·) that are drawn using the
pdf Π. The centers of the computed clusters, denoted
by Ψ(j), j = 1, . . . , ncl can be used as representatives of
their clusters. Moreover, the ratio πj between the sizes
of these clusters and the total population ns can be used
as a measure of their probabilities, namely

πj :=

1
ns

(cid:110)

card

ψ ∈ Sψ

| ψ = Ψ(j)(cid:111)

(22)

Based on the above deﬁnitions, the following approxi-
mation are used in the approximation of terms in (16):

ˆµ(cid:0)x, u, v|q(cid:1) :=

(cid:16)
πj ˆQ

ncl(cid:88)

j=1

Φ(x, u)Ψ(j), v|q

(cid:17)

(23)

ˆσ(cid:0)x, u, v, |q(cid:1) :=
(cid:34)
ncl(cid:88)

(cid:16)
ˆQ

πj

Φ(x, u)Ψ(j), v|q

(cid:17)

− ˆµ(cid:0)x, u, v|q(cid:1)

(cid:35)2

(24)

j=1

Using these expression, the weighted sum (16) of the
above term can be used to approximated by:

α (x, u, v|q) := ˆµ(cid:0)x, u, v|q(cid:1) + αˆσ(cid:0)x, u, v|q(cid:1)
ˆS (Q)

(25)

The updated values of qi at the underlying grid points
z(i) can therefore be obtained through:

q+
i

:= L(z(i)) + γ min
v∈U

(cid:104) ˆS (Q)

(cid:105)
α (f (z(i)), v|q)

(26)

for each element z(i) of the underlying grid Z. Note that
the optimization problem in v can be solved by simple
enumeration over the four elements of the set U.

This implements a ﬁxed-point iteration on the vector of
values q than can be shortly written as follows:

has been investigated using the following parameters. A
number ns = 104 samples have been drawn to perform
the clustering of set of values of Ψ (see Section 4.3). The
number of identiﬁed clusters was taken equal to ncl = 20.

i

Regarding the pdf Π, the following deﬁnition has been
used pi = (1 + ν)pnom
where ν is a normal distribu-
tion with 0 mean and variance σ = 0.4. The grid Z has
been taken as the cartesian product of a uniform grid
on x (having 7 uniformly distributed values over the
normalized interval [0, 1] per component) and the four
values control set U. This induces a set Z composed of
74 × 4 = 9604 elements.

Clustering has been performed using the scikit-learn li-
brary’s KNN (k-nearest neighbors) utility. The scikit
learn library’s SVM regression model has been used with
radial basis function’s kernel and the default values of
the remaining parameter. The sampling period τ = 0.25
Day is used and the lower bound xmin
2 = 0.05 is used for
the normalized 4 lymphocyte population size.

Three diﬀerent controllers are compared. Namely:

(1) The nominal controller for which Π is a dirac dis-
tribution centered at the nominal vector of param-
eters. The is referred to as Controller #1.

(2) The expectation-based controller for which the
distribution of the parameter is the one described
above 5.1 where no penalty on the variance term
(α = 0). The is referred to as Controller #2.

(3) The mixed expectation/variance-based controller
for which the penalty α = 0.1 is used on the
variance-related term. The is referred to as Con-
troller #3.

q+ = F (q)

(27)

5.2 Results

where the notation F used in (17) is overloaded using
the ﬁnite-dimensional parametrization q of Q. This is
the ﬁxed-point iteration that is proved to be convergent
under the assumptions of Proposition 3.

In Section 5, the instantiation of the framework on the
combined therapy of cancer is detailed and the corre-
sponding results are commented.

5 Numerical

investigation on the combined

therapy of cancer

5.1 Parameters used in the numerical investigation

Despite the fact that the convergence of the ﬁxed-point
iteration has been proved only for γ ∈ (0, 1) and for
suﬃciently small α and τ , the value γ = 1 has been used
to show that convergence does occur for this ideal value
(no discount on the cost function). On the other hand
α = 0.1 for Controller #3.

First of all, Figure 1 shows a typical convergence curve
for the ﬁxed-point iteration. The diﬀerence between
two successive solutions during the iterations, namely
(cid:107)q(i+1) − q(i)(cid:107)∞ is shown. Note that because of the use
of γ = 1, no strict contraction is obtained but eventu-
ally, contraction is settled and the solution is obtained.

As far as stochastic controller design is concerned (nom-
inal controller is also investigated), the above framework

4 The state components have been normalized using respec-
tively the reference values (109, 109, 1, 109).

6

More precisely, Figure 2 shows the histogram of the ra-
tios between the closed-loop performance as deﬁned in
(28) when the stochastic controllers are used compared
to the nominal. One can clearly observe two features:

(1) Both stochastic controllers lead to statistically bet-

ter results than the nominal.

(2) The stochastic Controller #3 that incorporates
penalty on the variance shows better results than
the one using only the expectation-related penalty
term.

(3) It seems clear that even when focusing on the mean
value of the cost function, the controller # 3 shows
a better average than the controller # 2. This might
seem contradictory with the fact that the latter is
supposed to minimize this expectation. It can be
conjectured that this comes from the fact that the
expectation cannot be suﬃciently well represented
by the average over the 20 clusters (see Section 4.3)
that are used to induce tractable computation of
the expectation and the variance and considering
the penalty on the variance correct this bias in a
favorable way.

Figure 3 shows the comparison between the average lev-
els of the lymphocytes population cells sizes (compared
to the nominal) when the stochastic controllers are used.
Here again, it comes out that the performances of the
controller # 3 are slightly bette than that of the second
expectation-only-based controller.

Fig. 1. Typical convergence curve for ﬁxed-point iterations:
Evolution of the diﬀerence (cid:107)q(i+1) − q(i)(cid:107)∞ between two
successive iterations. γ = 1, α = 0.1.

Figures 2 and 3 show the beneﬁt from using the stochas-
tic formulation compared to the nominal one. In order
to show this, Nsam := 20000 diﬀerent simulations are
constructed by drawing randomly samples of pairs of
initial states and parameter vectors and the resulting
closed-loop cost function is simulated before statistics
are drawn. More precisely, 100 initial states are sampled
and for each of these initial state, 200 random param-
eter vectors samples are drawn. Namely, for each given
pair (x(i), p(i)), i = 1, . . . , Nsam

Jcl(x(i), p(i)) :=

Nsim(cid:88)

k=0

L(x(k), u(k))

(28)

Fig. 2. Comparison between the closed-loop performance ra-
tios relatively to the nominal controller for the two stochastic
formulations for the 20000 randomly sampled initial states
and parameter vectors.

where Nsim = 50 is the simulation horizon length (12.5
Days) while x(k) and u(k) stand for the closed-loop tra-
jectories at instant k starting at initial instant k = 0 at
x(i) and when the parameter vector p(i) is used. Then dif-
ferent statistical comparisons are done when the above
procedure is executed using the three controllers men-
tioned above, namely, the nominal, the stochastic con-
troller based on the expectation term only (α = 0) and
ﬁnally the stochastic controller using a penalty α = 0.1
on the variance.

Fig. 3. Comparison between the average lymphocytes popu-
lation level ratios relatively to the nominal controller for the
two stochastic formulations for the 20000 randomly sampled
initial states and parameter vectors.

Another way to look at the constraint satisfaction is to
count the number of scenarios where the health con-
straint x2 ≥ xmin
is satisﬁed. Figure 4 shows the per-
centage of improvement in the constraints satisfaction
compared to the nominal when the stochastic controllers
are used.

2

7

Fig. 4. Safety constraints satisfaction improvement relatively to the nominal controller for the two stochastic formulations.
Abscissa represents the initial state number (100 are randomly selected) and the percentage refers to the 200 parameter vectors
that are simulated for the same initial state.

6 Conclusion and future works

In this paper a tractable stochastic control design for the
combined therapy of cancer is proposed. The method is
based on an approximate solution of the SDP equations
through a value function ﬁxed-point iteration. The con-
vergence of the latter in the presence of variance related
penalty in the cost function is proved under mild techni-
cal assumption. The result suggests that the inclusion of
a variance-related term in the cost function might give
better result by partially compensating for the errors
induced by the approximation of the statistical quanti-
ties through computations involving a reduced number
of clusters. Undergoing work involves the use of GPU-
based computation framework to handle a higher order
of magnitude of the samples size in order to examine how
these qualitative results scale with the dimension of the
populations over which they are evaluated.

References

[1] M. Alamir. On probabilistic certiﬁcation of combined cancer
Journal of

therapies using strongly uncertain models.
Theoretical Biology, 384:59 – 69, 2015.

[2] M. Alamir. On the use of supervised clustering in stochastic

NMPC design. CoRR, abs/1811.09069, 2018.

[3] D. P. Bertsekas. Dynamic programming and optimal control.

2017.

[4] S. Chareyron and M. Alamir. Mixed immunotherapy
and chemotherapy of tumors: Feedback design and model
updating schemes. Journal of Theoretical Biology, 45:444–
454, 2009.

[5] Tao Chen, Norman F. Kirkby, and Raj Jena. Optimal
dosing of cancer chemotherapy using model predictive control
and moving horizon state/parameter estimation. Computer
Methods and Programs in Biomedicine, 108(3):973 – 983,
2012.

8

[6] Lisette G. de Pillis, Weiqing Gu, and Ami E. Radunskaya.
tumors:
interpretations.

Mixed immunotherapy and chemotherapy of
modeling,
Journal of theoretical biology, 238(4):841–862, 2006.

and biological

applications

[7] T. Jaakoola, M. I. Jordan, and S. P. Singh. On the
convergence of stochastic iterative dynamic programming
Journal of Machine Learning Research,
algorithms.
6(6):1185–1201, 1994.

[8] K. Kassara and A. Moustaﬁd. Angiogenesis inhibition and
tumor-immune interactions with chemotherapy by a control
set-valued method. Mathematical Biosciences, 231(2):135 –
143, 2011.

[9] Kanchi Lakshmi Kiran and S. Lakshminarayanan. Global
sensitivity analysis and model-based reactive scheduling of
targeted cancer immunotherapy. Biosystems, 101(2):117 –
126, 2010.

[10] Robert Kirkby. Convergence of discretized value function
iteration. Computational Economics, 49(1):117–153, Jan
2017.

[11] U. Ledzewicz, H. Schattler, and A. d’Onofrio. Optimal
In 47th IEEE

control for combination therapy in cancer.
Conference on Decision and Control, 2008.

[12] A. Mesbah. Stochastic model predictive control with active
uncertainty learning: A survey on dual control. Annual
Reviews in Control, 45:107 – 117, 2018.

[13] A. Mesbah, S. Streif, R. Findeisen, and R. Braatz. Stochastic
control with probabilistic
the American Control

nonlinear model predictive
constraints.
In Proceedings of
Conference ACC2014, June 2014.

[14] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,
B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss,
V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau,
M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn:
Machine learning in Python. Journal of Machine Learning
Research, 12:2825–2830, 2011.

[15] G. W. Swan. General applications of optimal control in
cancer chemotherapy. IMA Journal of mathematics Applied
in Medicine & Biology, 5:303–316, 1988.

A Appendix

it comes from the previous equation that:

A.1 Proof of Lemma 1

Proof. We shall prove that under the assumptions of
the Lemma, the following inequality holds on the ﬁxed-
point map F

(cid:107)F (Q1) − F (Q2)(cid:107)∞ ≤ γ

(cid:48)

(cid:107)Q1 − Q2(cid:107)∞

(A.1)

where

(cid:107)Q(cid:107)∞ =

sup
(x,u)∈X×U

|Q(x, u)|

(A.2)

(cid:48)

for some γ
∈ [0, 1) which would obviously be suﬃcient
to prove the result. To do so, let us begin by deriving up-
per bounds on the norm of |F (Q1)(x, u) − F (Q2)(x, u)|.
Note that one has by deﬁnition of F :

|Gµ(x, u)| ≤(1 + O(τ ))

(cid:90)

Π(p)(cid:107)Q1 − Q2(cid:107)∞dp (A.6)

=(1 + O(τ ))(cid:107)Q1 − Q2(cid:107)∞

(A.7)

Bounding |Gσ(x, u)|

one can write after straightforward manipulations
(mainly using the identity a2 − b2 = (a − b)(a + b)):

Gσ(x, u) =
(cid:90)

(cid:104)
Π(p)

Q1(f (x, u, p), v†

1) − Q2(f (x, u, p), v†

2)−

µ(cid:0)Q1(f (x, u, ·), v†
(cid:104)

Q1(f (x, u, p), v†
µ(cid:0)Q1(f (x, u, ·), v†

1) − Q2(f (x, u, ·), v†
1) + Q2(f (x, u, p), v†
1) + Q2(f (x, u, ·), v†

2)(cid:1)(cid:105)
2)−
2)(cid:1)(cid:105)

×

dp

[F (Q1) − F (Q2)](x, u) := γ

(cid:104)

(cid:105)
Gµ(x, u) + αGσ(x, u)

Therefore,

where Gµ comes from the mean-related term in (16):

(A.3)

Gµ(x, u) :=

(cid:104)
µ

(cid:105)
Q1(f (x, u, ·), v†
1)

(cid:104)
Q2(f (x, u, ·), v†
2)
− µ

(cid:105)

(A.4)

1 and v†

where v†
2 are the solution of the corresponding
optimisation problems. Similarily: Gσ is induced by the
variance-related term in (16), namely:

Gσ(x, u) :=

(cid:34)

µ

(cid:34)

µ

(cid:16)
Q1(f (x, u, ·), v†

1) − µ(cid:2)Q1(f (x, u, ·), v†

(cid:16)
Q2(f (x, u, ·), v†

2) − µ(cid:2)Q2(f (x, u, ·), v†

(A.5)

−

1)(cid:3)(cid:17)2(cid:35)
2)(cid:3)(cid:17)2(cid:35)

Let us consider successively upper bounds on |Gµ| and
|Gσ|.

Bounding |Gµ(x, u)|:

By using the pdf Π, it is possible to write:

|Gµ(x, u)| ≤
(cid:90)

Π(p)

(cid:12)
(cid:12)Q1(f (x, u, p), v†
(cid:12)

(cid:12)
1) − Q2(f (x, u, p), v†
(cid:12)
2)
(cid:12) dp

Now since by deﬁnition:

(f (x, u, p), v†

i ) ∈ (1 + O(τ ))X × U

9

|Gσ(x, u)| ≤
(cid:90)

Π(p)

(cid:104)
Q1(f (x, u, p), v†

1) − Q2(f (x, u, p), v†
2)

(cid:105)
×

1) + Q2(f (x, u, p), v†
1) + Q2(f (x, u, ·), v†

2)−
2)(cid:1)(cid:105)

|dp

(cid:104)
Q1(f (x, u, p), v†
|
µ(cid:0)Q1(f (x, u, ·), v†
+
|µ(cid:0)Q1(f (x, u, ·), v†
(cid:90)
(cid:104)
Π(p)

|

1) − Q2(f (x, u, ·), v†

2)(cid:1)|×

Q1(f (x, u, p), v†

1) + Q2(f (x, u, p), v†

2)−

µ(cid:0)Q1(f (x, u, ·), v†

1) + Q2(f (x, u, ·), v†

2)(cid:1)(cid:105)

dp|

Note that the second term in the above addition vanishes
by deﬁnition of the mean of Q1 + Q2. Regarding the ﬁrst
term, it can be bounded using the fact that Q1 and Q2
are both of ﬁnite excursion on X × U. Indeed

(cid:104)
Q1(f (x, u, p), v†
|
µ(cid:0)Q1(f (x, u, ·), v†

1) + Q2(f (x, u, p), v†
1) + Q2(f (x, u, ·), v†

2)−
2)(cid:1)(cid:105)

| ≤ 2B

Using this in the ﬁrst term of the last inequality bound-
ing |Gσ(x, u)| leads to

|Gσ(x, u)| ≤ 2B(1 + O(τ ))(cid:107)Q1 − Q2(cid:107)∞

(A.8)

Using (A.7) and (A.8) in (A.3) enables to induce that

(cid:107)F (Q1) − F (Q2)(cid:107)∞ ≤ γ(1 + 2αB + O(τ ))(cid:107)Q1 − Q2(cid:107)∞
(A.9)
which obviously means that for all α satisfying the con-
dition (20), the ﬁxed point is contractive and hence con-
(cid:50)
vergent.

A.2 Proof of Proposition 3

All we have to prove is that when initializing the qi as
stated in the proposition, all the following values of q lie
in some compact set Q. Once this is shown the results
fallows directly from Deﬁnition 4.1 which guarantees
that some unique B exists which can be used in Lemma
1 to conclude.

To prove the existence of the compact set Q, the bound-
edness of the state evolution of the combined therapy
of cancer is invoked, that is to say, under any bounded
sequence u ∈ U∞, the state vector belongs at any in-
stant in the future to some bounded set ¯X (this is a
known property of the model (1)-(4) that can be eas-
ily shown by proving that for each component of the
state, the r.h.s becomes negative when the component
is suﬃciently high).

Having this property at hand and given the initialization
qi = L(z(i), it comes from the deﬁnition of the ﬁxed-
point iteration that the values qi at any iteration satisfy
the inequality:

qi ≤

γ
1 − γ

(cid:20)

(cid:21)

max
z∈¯X×U

L(z)

(A.10)

which obviously means that the ﬁxed point iteration pro-
duces vectors that always remains in some compact set
(cid:50)
Q which ends the proof.

10

