1
2
0
2

r
p
A
1
2

]

G
L
.
s
c
[

1
v
1
5
7
0
1
.
4
0
1
2
:
v
i
X
r
a

Discovering Classiﬁcation Rules for
Interpretable Learning with Linear Programming

M. Hakan Akyüz
Erasmus University Rotterdam, 3000 DR, Rotterdam, The Netherlands

Ş. İlker Birbil
University of Amsterdam, 11018 TV, Amsterdam P.O. Box 15953, The Netherlands

Abstract: Rules embody a set of if-then statements which include one or more conditions to classify a subset
of samples in a dataset. In various applications such classiﬁcation rules are considered to be interpretable by
the decision makers. We introduce two new algorithms for interpretability and learning. Both algorithms take
advantage of linear programming, and hence, they are scalable to large data sets. The ﬁrst algorithm extracts
rules for interpretation of trained models that are based on tree/rule ensembles. The second algorithm generates
a set of classiﬁcation rules through a column generation approach. The proposed algorithms return a set of
rules along with their optimal weights indicating the importance of each rule for classiﬁcation. Moreover, our
algorithms allow assigning cost coeﬃcients, which could relate to diﬀerent attributes of the rules, such as; rule
lengths, estimator weights, number of false negatives, and so on. Thus, the decision makers can adjust these
coeﬃcients to divert the training process and obtain a set of rules that are more appealing for their needs. We
have tested the performances of both algorithms on a collection of datasets and presented a case study to elaborate
on optimal rule weights. Our results show that a good compromise between interpretability and accuracy can be
obtained by the proposed algorithms.

Keywords: Rule generation; linear programming; interpretability

1. Introduction. Medical diagnosis, educational and juridical decisions often have important con-
sequences for the society. Therefore, both the accuracy and interpretability of these decisions are of
crucial importance. In particular, these decisions should be understandable by the decision makers. Rule
sets consisting of a few intuitively coherent rules have shown to accomplish this purpose in such domains
(Lakkaraju et al., 2016). Here, we ﬁrst aim at rule extraction from powerful ensemble methods and then
solely focus on rule generation. In both cases, our objective is to obtain a set of classiﬁcation rules that
balances the trade-oﬀ between accuracy and interpretability. Our main tools in this eﬀort are linear
optimization and column generation.

A rule is an independent if-then statement, which contains one or more conditions that assign a class
to a set of samples. For example in binary classiﬁcation, “if (Clump Thickness is greater than six)
and (Single Epithelial Cell Size is less than four) then the tumor is malignant” is such a rule
that can be used for breast cancer diagnosis. When a sample satisﬁes this rule, then it receives a label
corresponding to one of the two classes. In case a sample is covered by more than one rule, then majority
voting among the assigned labels is used to determine the class of the sample.

Growing decision trees is closely related to rule-based learning. A Decision Tree (DT) naturally
results with a set of leaves, where each leaf corresponds to a diﬀerent rule. On one hand, rule learning
is considered to be more ﬂexible for interpretability than tree-based learning approaches. Fürnkranz
(1999) lists superiorities of rule-based learning over tree-based learning. Leaves (rules) of a DT are not
independent from each other. For example, in a binary tree when a splitting is performed at a node,
the left child grows a rule, while its right sibling grows its negation. As a result, every sample obeys to
exactly one rule and it is classiﬁed according to the corresponding leaf. Thus, inaccurate rules, which are
negations of their siblings after splitting, can be created. This may render false classiﬁcation of samples
and reduce both accuracy and interpretability. However, independently constructed rules do not need
such a negation rule, and hence, rule-based learning can be considered more ﬂexible for interpretability.
On the other hand, unlike DTs, an independent set of rules does not necessarily cover the entire sample
space. This may result in a state where a test sample can not be classiﬁed with the proposed rule set.
This drawback is often handled by assigning a default label to those uncovered samples (Fürnkranz et al.,
2012). To minimize the number of uncovered samples during testing, the training data is required to be
fully covered. Separate-and-conquer algorithm by Fürnkranz (1999) achieves this heuristically by ﬁtting

1

 
 
 
 
 
 
Akyüz, Birbil: RUX & RUG

2

rules on uncovered training samples, and new rules are generated until each training sample is covered
by at least one rule. Instead of such a sequential covering, we take advantage of our linear programming
(LP) approach and explicitly impose a covering constraint on the training set.

In this paper, we propose two algorithms for interpretability and learning that are based on mathe-
matical programming. We ﬁrst give an LP model that is used by our Rule Extraction (RUX) algorithm,
which selects rules from tree or rule ensembles for interpretation. Then, we develop a Rule Generation
(RUG) algorithm, which generates classiﬁcation rules using column generation (CG).

Rule extraction methods attempt to select a set of rules from accurate complex or black-box models
to interpret the predictions of these models (Hayashi and Oishi, 2018). For instance, several works in the
literature aim at interpreting Random Forest (RF) models by extracting rules from the trees in the forest
(Liu et al., 2012; Lu Thi et al., 2015; Adnan and Islam, 2017; Wang et al., 2020; Birbil et al., 2020). Most
of these studies use heuristic approaches to select the desired set of rules. Birbil et al. (2020) suggest a
set covering formulation to extract intrepretable rules from RFs. Other applications include extraction
of rules from artiﬁcial neural networks (Andrews et al., 1995) and support vector machines (Barakat and
Bradley, 2010).

There are several studies that are closely related to ours, since they also employ mathematical pro-
gramming for rule learning. Malioutov and Varshney (2013) propose a rule-based binary classiﬁer solving
a binary program that minimizes the number of rules for a boolean compressed sensing problem. Wang
and Rudin (2015) present a mixed integer linear programming (MILP) formulation to learn decision rules
for binary classiﬁcation (e.g., patterns). They give a discussion on how their classiﬁer is equivalent to
DTs and RFs. A three-phase framework, which relaxes the MILP problem, is oﬀered to solve larger
instances. Pattern selecting phase solves the MILP formulation over the generated rules with an objec-
tive of minimizing the number of misclassiﬁed samples, the number of patterns generated, and the total
length of each pattern. Dash et al. (2020) oﬀer a CG-based framework to ﬁnd optimal rule set for binary
classiﬁcation, where the objective is to ﬁnd a trade-oﬀ between classiﬁcation rule simplicity and accuracy.
One-hot encoding is used to binarize categorical data, and numerical data is also discretized with sample
deciles as thresholds. For large instances, the pricing subproblem is either solved with time limits, or
the model columns are generated by a greedy heuristic. Malioutov and Meel (2018) solve a Max-Sat
formulation by constraint programming to construct interpretable classiﬁcation rules. Ghosh and Meel
(2019) also propose a framework based on MaxSAT formulation that can be applied to binary classiﬁca-
tion problems with binary features. Their approach is incremental and takes advantage of partitioning
the data set into several clusters. Their objective is to minimize the number of generated rules and the
number of misclassiﬁed samples.

With our current work, we make the following contributions.

(cid:5) RUX and RUG are based on an LP model and thus, both algorithms are scalable for large

datasets. This is diﬀerent than existing studies that use MILP formulations.

(cid:5) The proposed algorithms directly address multi-class problems whilst existing studies using
optimization-based approaches are for binary classiﬁcation. To that end, the objective func-
tion in our LP formulation minimize classiﬁcation error using a loss function instead of explicitly
counting misclassiﬁed samples.

(cid:5) Both RUX and RUG can work with continuous or categorical features, and hence, they do not

require encoding of the data.

(cid:5) Along with the set of rules, our algorithms also return the optimal weights for the rules. These

weights allow to attach importance to each rule for interpreting the classiﬁcation.

(cid:5) Both algorithms admit assigning cost coeﬃcients to the rules. These coeﬃcients could relate to
diﬀerent attributes of the rules, such as; rule lengths, estimator weights, number of false negatives,
and so on. The objective function also allows penalizing rules that may have undesired outcomes
(like long rule lengths). Thus, the decision makers can use these coeﬃcients to lead the training

Akyüz, Birbil: RUX & RUG

3

process to obtain a set of rules more appealing for their needs.

(cid:5) The novelty in our column generation approach is the use of a regular decision tree (DT) with
sample weights as the pricing subproblem. Training trees with sample weights is very fast, and
also standard in all machine learning packages as boosting methods also rely on sample weights.
(cid:5) We present our algorithms for multi-class classiﬁcation problems. The proposed ideas can also
be extended to discovering regression rules for interpretable learning with linear programming.

2. Rule Extraction. We consider a classiﬁcation problem with K classes and denote the set of class
labels by K. The training dataset consists of samples with features xi ∈ Rp for i ∈ I and labels yi for
i ∈ I. To work with multiple classes, we deﬁne a vector-valued mapping y(xi) ∈ K ⊂ RK as in Zhu et al.
(2009). That is, if yi = k, then

y(xi) = (− 1

K−1 , − 1

K−1 , . . . , 1, . . . , − 1

K−1 )(cid:124),

(1)

where the value one appears only at the kth component of the vector.

Suppose that we have a collection of rules indexed by J . A rule j ∈ J assigns the vector Rj(xi) ∈ K
to input xi, only if rule j covers sample i. This vector is also formed in the same manner as in (1). To
predict the class of a given sample xi with this collection of rules, we use a set of nonnegative weights
wj, j ∈ J associated with the rules and evaluate

ˆy(xi) =

(cid:88)

j∈J

aijRj(xi)wj,

(2)

where aij ∈ {0, 1} indicates whether rule j covers sample i or not. Then, the index of the largest
component of the resulting vector ˆy(xi) is assigned as the predicted label ˆyi of sample i ∈ I. Note that
(2) is similar to the weighting of the classiﬁers in standard boosting methods. Here, instead of classiﬁers,
we use rules for classifying only the covered samples.

In order to evaluate the classiﬁcation error, we use the hinge loss and deﬁne the total classiﬁcation

loss by

max (cid:8)1 −

(cid:88)

i∈I

ˆaijwj, 0(cid:9),

(cid:88)

j∈J

where ˆaij = κaijRj(xi)(cid:124)y(xi) with κ = (K − 1)/K. This loss function allows us to write a linear
programming model, where the objective is to ﬁnd the set of rules that minimizes the total loss. To this
end, we introduce the auxiliary variables vi, i ∈ I standing for vi ≥ max (cid:8)1 − (cid:80)
j∈J ˆaijwj, 0(cid:9), and obtain
our master problem

minimize

subject to

(cid:80)

(cid:80)

j∈J cjwj

i∈I vi + (cid:80)
j∈J ˆaijwj + vi ≥ 1,

(cid:80)

j∈J aijwj ≥ ε,

vi ≥ 0,

wj ≥ 0,

i ∈ I;

i ∈ I;

i ∈ I;

j ∈ J ,

(3)

where cj ≥ 0, j ∈ J are the cost coeﬃcients. These coeﬃcients and the second set of constraints require
further explanation. The cost coeﬃcients serve two important roles: First, solutions involving many rules
with nonzero weights are avoided. The less the number of rules in the resulting set, the easier it is to
interpret a solution. In other words, we prefer sparse solutions and cj serves to that preference. Second,
in many diﬀerent application domains, rules have actual costs that need to be taken into consideration.
As we also highlight in our title, when interpretability is of concern, one could try to obtain rules with
few features because shorter rules are considered to be easier to interpret (Lakkaraju et al., 2016). In
this case, the number of conditions in a rule can be set as the rule cost. As another example, consider a
classiﬁcation problem in medical diagnosis, where false negatives are likely to be perceived as more costly
than false positives. Such an evaluation could also be easily incorporated with a rule cost in the proposed

Akyüz, Birbil: RUX & RUG

4

model. We should point out that there exists a trade-oﬀ between model accuracy and the rule set size.
This can also be handled with our formulation by introducing a ﬁxed cost coeﬃcient, i.e., using the same
value for all cj, j ∈ J .

The master problem (3) also involves a set of covering constraints with the ﬁxed right-hand-side, ε > 0.
These constraints make sure that each sample is covered by at least one rule. The need for these covering
constraints is exempliﬁed as follows:

Consider a binary classiﬁcation problem, where we select three samples {xi, xk, xl} along
with their labels yi = 1, yk = −1 and yl = −1. Suppose that we have two rules j and j(cid:48)
such that the former covers all three, whereas the latter covers only the last two samples.
Here, the rules use majority voting as it is applied to the leaves in trained DTs. The
labels assigned by the rules j and j(cid:48) are as follows: Rj(xi) = Rj(xk) = Rj(xl) = −1 and
Rj(cid:48)(xk) = Rj(cid:48)(xl) = −1. The ﬁrst set of constraints in (3) then becomes

−aijwj

+vi

akjwj +akj(cid:48)wj(cid:48)
aljwj +alj(cid:48)wj(cid:48)

+vk

≥ 1,
≥ 1,
+vl ≥ 1.

For simplicity, if we also assume that cj = cj(cid:48), then the optimal solution becomes wj =
vk = vl = 0 and wj(cid:48) = vi = 1. With this solution, sample xi is not covered.

We remark that covering each sample in a dataset is crucial from the perspective of giving a reliable
interpretation with the obtained rules. This is particularly important when the resulting set of rules
are is to interpret the classiﬁcation of individual samples in the dataset. Clearly, varying ε may lead
to a change in the set of optimal rules. For instance a large ε value may impose larger rule weights on
those samples covered with only few rules. However, we point out that the role of this constraint is just
coverage, and hence, setting ε to a small strictly positive value is suﬃcient∗.

Up until this point, we have not speciﬁed any details about the rule set J . On one hand, this rule
set can be static in the sense that it can be obtained by extracting the rules available through a trained
tree ensemble algorithm or by using the rules resulting from a rule-based method (Cohen and Singer,
1999). For instance, consider a Random Forest model trained on a given dataset. Then, the rule set J
can be obtained from the leaves of the trees in the forest, since each leaf corresponds to a rule. Solving
(3) with such a rule set allows us to extract the rules that were most critical for classiﬁcation. As we have
mentioned before, we can assign the length of a rule as its cost and try to obtain rules with desirable
lengths for interpretation. In a similar vein, consider another example with a trained AdaBoost (Freund
and Schapire, 1997) model for which the base estimators are set as DTs. Again, the leaves of the trees from
AdaBoost can be used to construct the rule set J in (3), which is then solved to extract an interepretable
set of rules. The costs of the rules in this case could be the inverse of the estimator weights assigned by
the AdaBoost algorithm to the trees. In this way, the obtained set of rules is more likely to inherit the
importance of the DTs from the AdaBoost model. Using these trained models to construct our master
problem leads to our ﬁrst algorithm RUX, which is based on tree ensembles. We show in Section 4 that
RUX can indeed extract only a selection of rules from the trained models without signiﬁcantly sacriﬁcing
accuracy. The computational complexity for RUX is determined by the underlying LP solver used. In
practice, most of the LP solvers often use interior point methods that work in polynomial-time.

3. Rule Generation. Suppose now that we do not have the entire set of rules J explicitly or
the size of this collection is too large to be constructed by an existing learning framework. Thus, the
rules should be generated in an iterative fashion. Since (3) is a linear programming problem and rules
correspond to columns, this iterative scheme leads to the well-known column generation approach in

∗In case one insists on treating ε as a hyperparameter and proceeds with tuning, it is important to know that
there will be intervals of ε values where the optimal set of rules remains the same. We have given this parametric
analysis in Appendix B. Using this analysis, the tuning can be conducted in a computationally eﬃcient manner.

Akyüz, Birbil: RUX & RUG

5

optimization (Desaulniers et al., 2006). At each iteration of column generation, a linear programming
model is constructed with a subset of the columns (column pool ) of the overall model. This model is called
the restricted master problem. After solving the restricted master problem, the dual optimal solution is
obtained. Then using this dual solution, a pricing subproblem is solved to identify the columns with
negative reduced costs. These columns are the only candidates for improving the objective function value
when they are added to the column pool. The next iteration continues after extending the column pool
with the negative reduced cost columns.

In order to apply column generation to our problem, we deﬁne a subset of rules Jt ⊂ J at iteration t
and form the restricted master problem by replacing J with Jt in (3). Let us denote the dual variables
associated with the ﬁrst set of constraints by βi, i ∈ I. Likewise, let γi, i ∈ I be the dual variables
corresponding to the coverage constraints. In vector notation, we simply use β and γ. Then, the dual
restricted master problem at iteration t becomes

maximize

subject to

(cid:80)

i∈I (βi + εγi)

(cid:80)

i∈I (ˆaijβi + aijγi) ≤ cj,

j ∈ Jt;

0 ≤ βi ≤ 1,

γi ≥ 0,

i ∈ I;

i ∈ I.

(4)

If we denote the optimal dual solution at iteration t by β(t) and γ(t), then improving the objective
function value of problem (4) requires ﬁnding at least one rule j(cid:48) ∈ J /Jt such that

¯cj(cid:48) = cj(cid:48) −

(cid:88)

(cid:16)

i∈I

ˆaij(cid:48)β(t)

i + aij(cid:48)γ(t)

i

(cid:17)

< 0,

(5)

where ¯cj(cid:48) is the reduced cost of column j(cid:48).
In fact, this condition simply checks whether j(cid:48) ∈ J /Jt
violates the dual feasibility. To ﬁnd those rules with negative reduced costs, we formulate the pricing
pricing subproblem as

max
j∈J /Jt

(cid:40)

(cid:88)

i∈I

(cid:41)

ˆaijβ(t)

i + aijγ(t)

i

.

(6)

Linear programming theory ensures that if the pricing subproblem does not return any rule with a
negative reduced cost, then we have the optimal solution to our master problem (3) with the current set
of rules, Jt. Otherwise, we have at least one rule with a negative reduced cost. After adding one or more
rules with negative reduced costs to Jt, we proceed with Jt+1 and solve the restricted master problem
or, equivalently, its dual (4). Algorithm 1 shows the steps of the exact rule generation approach. It is
important to note that the sole purpose of solving pricing subproblem (6) is to return a subset of rules
with negative reduced costs. We denote this subset by J− ⊆ J /Jt.

Algorithm 1 Exact Rule Generation
Input: training data, (xi, yi)i∈I
t = 0
Construct initial rule pool, J0
while True do

(β(t), γ(t)) ← Solve (4)
J− ← Solve pricing subproblem, (6)
if J− = ∅ then
return Jt

end if
t ← t + 1
Jt = Jt−1 ∪ J−

end while

We have overlooked two important steps in Algorithm 1. The ﬁrst one is the construction of the initial
rule pool J0 (line three). One possible solution for this step is to train a DT and use its leaves as the

Akyüz, Birbil: RUX & RUG

6

starting set of rules. The second step is solving the pricing subproblem (line six). Note that solving (6)
is associated with ﬁnding a rule with the highest accuracy when the samples have weights β(t)
, i ∈ I. As
constructing an optimal binary decision tree is known to be N P-complete (Laurent and Rivest, 1976),
solving problem (6) is rather diﬃcult even when γ(t) = 0. This also allows us to come up with the
proxy pricing subproblem of column generation as shown in Figure 1. Here, treating γi = 0 allows the
construction of a DT using the dual values β(t) as sample weights. DTs can be solved very quickly using
standard libraries that are available in all machine learning packages. Therefore, we propose to train a
DT as a heuristic pricing approach, where the sample weights correspond to dual variables β(t)
, i ∈ I.
Then, we can check whether any leaf of the DT satisﬁes (5) before adding those rules to the current rule
pool. Notice that a negative reduced cost column (rule) with γi = 0 would also have a negative reduced
cost when the pricing subproblem is solved exactly.

i

i

Figure 1: Proposed rule generation algorithm.

Figure 1 shows the proposed heuristic approach for rule generation. The procedure DecisionTree takes
a vector of sample weights as an input and returns a set of rules ¯J (leaves of the decision tree). The vector
e is the vector of ones. The subset ¯J− ⊆ ¯J contains those rules with negative reduced costs satisfying (5).
As we use the dual solution γ(t) only for checking the reduced cost, training decision trees with sample
weights in this manner boils down to solving a proxy pricing subproblem. Indeed, our rule generation
algorithm RUG does not guarantee to solve the overall problem (3) to optimality. Fortunately, this may
be to our advantage since a suboptimal solution can rectify the problem of overﬁtting to the training
data. In fact, overﬁtting due to exact optimality is a common concern also in recent optimization-based
approaches to learning (Günlük et al., 2018; Verwer and Zhang, 2019). Avid readers of optimization-based
learning would also notice that there are some connections between RUG and the boosting methods. We
elaborate on this point in Appendix C.

We remark once again that growing decision trees with sample weights is a standard tool in every
library on machine learning. Likewise, there are various options to solve linear programs. Both growing
DTs and solving LPs can be achieved in polynomial-time. Therefore, the proposed algorithm in Figure 1
is extremely easy to implement with the existing packages of popular programming languages.

4. Computational Study. We have evaluated the performances of the proposed algorithms on a
collection of frequently used datasets. The details of these datasets are given in Appendix A. Both the
rule extraction (RUX) and the rule generation (RUG) algorithms are implemented in Python †. Since our
computation times do not exceed one minute even on a standard laptop computer, we do not report them
here. We have used stratiﬁed 10 × 3 nested cross validation to estimate the generalization performance
of the tested methods. In all experiments, the right-hand-side value of each covering constraint is set to
ε = 0.01 .

†Our implementation is available at https://github.com/sibirbil/RuleDiscovery.

Akyüz, Birbil: RUX & RUG

7

4.1 Numerical Experiments. First, we apply our RUX algorithm to trained random forest (RF)
and AdaBoost (ADA) models. For both RF and ADA, we have selected the maximum-depth parameter
from the set {1, 2, 3} and the number-of-estimators parameter from the set {100, 200}. After obtaining
the best parameter set, we have used the corresponding trained model to apply RUX. We denote the
models after applying RUX to RF and ADA by RUX-RF and RUX-ADA, respectively. In RUX-RF, we
have used the rule-length as the cost coeﬃcients cj, j ∈ J in (3). For RUX-ADA, the cost coeﬃcients
are assigned as the inverse of the estimator weights of the trees in the trained ADA model. That is, the
rules coming from the same tree receive the same cost coeﬃcient.

Table 1 summarizes our results. Overall, we observe that RUX-RF and RUX-ADA give accuracies
on par with RF and ADA. In fact, RUX-RF can even outperform RF on several datasets. These are
banknote, tictactoe, adult, bank-mkt, magic, mushroom, musk, phoneme and mammography.
On average, RUX-RF and RUX-ADA obtain far fewer number of rules than their counterparts RF and
ADA, respectively. When we compare RUX variants, we observe that RUX-ADA generally obtains
smaller sets with shorter rule lengths than RUX-RF. This is due to the larger trees preferred by RF
models as the average number of rules obtained with RF is higher than ADA. Take for instance glass
and sensorless, for which ADA returns more rules than RF. For those instances, we clearly see that
the average rule length resulting from RUX-RF is smaller than those from RUX-ADA.

Table 1: The performances of Random Forest (RF), AdaBoost (ADA) as well as Rule Extraction applied to
RF and ADA - denoted as RUX-RF and RUX-ADA. In the table, ACC., # RULES, and RULE LEN. stand for
accuracy, number of rules and rule length, respectively. The ﬁrst value in each cell gives the mean, whereas the
value in parenthesis gives the standard deviation.

Dataset

RF

Acc.

# Rules

Acc.

ADA

# Rules

Acc.

0.955 (0.018)
BANKNOTE
0.832 (0.059)
HEARTS
0.713 (0.014)
ILPD
0.929 (0.041)
IONOSPHERE
0.695 (0.060)
LIVER
0.759 (0.033)
PIMA
0.768 (0.049)
TICTACTOE
0.766 (0.025)
TRANSFUSION
0.953 (0.030)
WDBC
0.798 (0.004)
ADULT
0.781 (0.014)
BANK_MKT
0.804 (0.007)
MAGIC
0.981 (0.008)
MUSHROOM
0.904 (0.007)
MUSK
0.957 (0.000)
OILSPILL
PHONEME
0.800 (0.017)
MAMMOGRAPHY 0.983 (0.002)
0.910 (0.094)
SEEDS
0.978 (0.039)
WINE
0.687 (0.072)
GLASS
0.854 (0.055)
ECOLI
0.768 (0.008)
SENSORLESS
0.844 (0.030)
Average

1009.8 (379.538)
751.1 (496.415)
664.0 (526.334)
997.3 (322.732)
962.0 (349.497)
1265.7 (409.449)
1280.0 (413.118)
745.6 (122.06)
1060.3 (385.359)
1587.6 (4.088)
1507.1 (250.918)
1278.1 (412.559)
1033.4 (328.702)
1262.4 (407.446)
1093.1 (465.142)
1353.8 (385.843)
1259.0 (406.919)
803.5 (400.555)
685.9 (360.995)
1262.7 (355.563)
1164.2 (411.335)
1456.2 (12.985)
1112.855 (345.798)

0.999 (0.003)
0.815 (0.069)
0.700 (0.059)
0.934 (0.041)
0.747 (0.075)
0.760 (0.034)
1.000 (0.000)
0.794 (0.030)
0.970 (0.026)
0.866 (0.004)
0.844 (0.012)
0.872 (0.004)
1.000 (0.000)
0.994 (0.003)
0.970 (0.011)
0.858 (0.030)
0.987 (0.003)
0.933 (0.078)
0.955 (0.051)
0.794 (0.066)
0.836 (0.050)
0.892 (0.014)
0.887 (0.030)

667.8 (358.674)
220.0 (63.246)
655.8 (322.577)
779.3 (436.083)
330.3 (172.687)
415.7 (144.178)
1360.0 (386.437)
404.8 (156.886)
612.0 (390.43)
1450.0 (27.125)
1271.2 (195.308)
1437.8 (48.26)
441.3 (115.858)
1513.6 (8.168)
1098.5 (447.0)
1202.7 (46.55)
1026.3 (413.774)
739.4 (435.589)
558.6 (226.358)
1324.1 (373.676)
917.2 (445.408)
1562.6 (10.752)
908.591 (237.501)

0.991 (0.008)
0.809 (0.080)
0.696 (0.048)
0.912 (0.051)
0.692 (0.083)
0.742 (0.048)
0.998 (0.004)
0.769 (0.031)
0.954 (0.017)
0.857 (0.004)
0.843 (0.012)
0.850 (0.011)
1.000 (0.000)
0.970 (0.007)
0.963 (0.018)
0.845 (0.024)
0.986 (0.002)
0.876 (0.108)
0.938 (0.049)
0.679 (0.078)
0.795 (0.080)
0.541 (0.041)
0.850 (0.037)

RUX-RF
# Rules

24.2 (6.844)
55.3 (32.575)
69.6 (58.064)
32.7 (9.9)
110.6 (11.138)
173.5 (25.418)
100.0 (12.824)
34.5 (14.864)
50.7 (3.773)
111.1 (53.532)
337.6 (30.376)
244.7 (39.26)
11.6 (4.006)
183.6 (23.491)
60.7 (19.574)
168.3 (28.81)
153.7 (21.401)
17.3 (7.056)
19.4 (2.221)
45.8 (5.116)
41.4 (6.168)
78.2 (5.633)
96.568 (19.184)

Rule Len.

Acc.

2.118 (0.081)
2.094 (0.824)
1.778 (0.742)
2.277 (0.162)
2.375 (0.201)
2.643 (0.055)
3.000 (0.000)
2.158 (0.217)
2.632 (0.244)
2.850 (0.055)
2.854 (0.018)
2.740 (0.019)
2.478 (0.165)
2.949 (0.015)
2.519 (0.536)
2.565 (0.032)
2.540 (0.044)
1.783 (0.356)
1.905 (0.235)
2.364 (0.101)
2.087 (0.105)
2.559 (0.053)
2.421 (0.194)

0.995 (0.006)
0.799 (0.080)
0.703 (0.062)
0.906 (0.036)
0.698 (0.091)
0.753 (0.037)
1.000 (0.000)
0.766 (0.018)
0.963 (0.027)
0.860 (0.003)
0.854 (0.007)
0.875 (0.008)
1.000 (0.000)
0.978 (0.007)
0.964 (0.014)
0.865 (0.018)
0.986 (0.003)
0.886 (0.159)
0.939 (0.041)
0.716 (0.113)
0.812 (0.035)
0.632 (0.071)
0.861 (0.038)

RUX-ADA
#Rules

36.6 (15.493)
28.9 (3.9)
90.2 (49.198)
67.9 (17.748)
37.5 (20.823)
55.6 (22.481)
79.0 (6.074)
12.3 (6.667)
50.6 (9.812)
72.7 (7.973)
235.2 (47.098)
310.8 (21.181)
12.2 (2.44)
206.7 (22.186)
61.0 (6.65)
188.4 (10.091)
108.2 (23.266)
17.1 (8.399)
22.3 (6.55)
55.6 (6.753)
42.1 (7.593)
101.4 (6.45)
86.014 (14.947)

Rule Len.

1.864 (0.681)
1.000 (0.000)
2.020 (0.644)
2.317 (0.744)
1.155 (0.327)
1.390 (0.412)
3.000 (0.000)
1.263 (0.465)
1.689 (0.806)
2.495 (0.026)
2.600 (0.267)
2.658 (0.017)
1.683 (0.794)
2.950 (0.010)
2.763 (0.277)
2.463 (0.035)
2.290 (0.207)
2.207 (0.592)
1.954 (0.419)
2.742 (0.048)
2.600 (0.343)
2.818 (0.034)
2.178 (0.325)

We report our results with the proposed RUG algorithm in Table 2. In addition to RF and ADA, we
have also added a DT algorithm for comparison. The same set of values {1, 2, 3} is used for tuning the
maximum-depth parameter both in DT and RUG (for constructing the initial column pool and the proxy
pricing subproblem; see Figure 1). In RUG, we have used the rule length as cost coeﬃcients. When we
compare the accuracies of diﬀerent methods, we observe that the average performance of RUG is better
than those of DT and RF, and close to ADA. Since the resulting models from DT are interpretable,
we also report the rule numbers as well as the rule lengths for DT. RUG outperforms DT in terms of
accuracy at the expense of generating more rules. However, the average lengths of the rules obtained
with RUG are shorter than those obtained with DT in all instances.

In their recent work, Dash et al. (2020) propose a rule learning approach based on column generation.
They also give a comparison against other studies and present that their algorithm shows one of the best
performances. We compare their results against a variant of RUG in Table 4 of Appendix D. We remark
that their numerical study is limited to binary classiﬁcation instances, and hence, the benchmarking is
conducted only on a subset of datasets that we have used in our previous two tables. On average, our
results are on par with the results obtained with their method in terms of accuracy and interpretability.
It is important to note that both RUX variants and RUG are an order of magnitude faster on large
datasets than the approach of Dash et al. (2020). Appendix D involves a further discussion.

Even though RUX variants and RUG obtain few number of rules with short lengths for many datasets,

Akyüz, Birbil: RUX & RUG

8

Table 2: The performances of Random Forest (RF), AdaBoost (ADA), Decision Tree (DT) and Rule Generation
(RUG). Here, ACC., # RULES, and RULE LEN. stand for accuracy, number of rules, and rule length, respectively.
The ﬁrst value in each cell gives the mean, whereas the value in parenthesis gives the standard deviation.

Dataset

RF
Acc.

ADA
Acc.

0.955 (0.018)
BANKNOTE
0.832 (0.059)
HEARTS
0.713 (0.014)
ILPD
0.929 (0.041)
IONOSPHERE
0.695 (0.060)
LIVER
0.759 (0.033)
PIMA
0.768 (0.049)
TICTACTOE
0.766 (0.025)
TRANSFUSION
0.953 (0.030)
WDBC
0.798 (0.004)
ADULT
0.781 (0.014)
BANK_MKT
0.804 (0.007)
MAGIC
0.981 (0.008)
MUSHROOM
0.904 (0.007)
MUSK
0.957 (0.000)
OILSPILL
PHONEME
0.800 (0.017)
MAMMOGRAPHY 0.983 (0.002)
0.910 (0.094)
SEEDS
0.978 (0.039)
WINE
0.687 (0.072)
GLASS
0.854 (0.055)
ECOLI
0.768 (0.008)
SENSORLESS
0.844 (0.030)
Average

0.999 (0.003)
0.815 (0.069)
0.700 (0.059)
0.934 (0.041)
0.747 (0.075)
0.760 (0.034)
1.000 (0.000)
0.794 (0.030)
0.970 (0.026)
0.866 (0.004)
0.844 (0.012)
0.872 (0.004)
1.000 (0.000)
0.994 (0.003)
0.970 (0.011)
0.858 (0.030)
0.987 (0.003)
0.933 (0.078)
0.955 (0.051)
0.794 (0.066)
0.836 (0.050)
0.892 (0.014)
0.887 (0.030)

Acc.

0.937 (0.017)
0.775 (0.041)
0.715 (0.009)
0.897 (0.051)
0.675 (0.068)
0.738 (0.037)
0.714 (0.034)
0.758 (0.035)
0.919 (0.030)
0.844 (0.005)
0.775 (0.008)
0.787 (0.009)
0.985 (0.004)
0.915 (0.011)
0.963 (0.013)
0.769 (0.020)
0.984 (0.002)
0.890 (0.081)
0.904 (0.071)
0.687 (0.056)
0.804 (0.041)
0.425 (0.002)
0.812 (0.029)

DT
#Rules

8.0 (0.0)
7.4 (1.897)
2.0 (0.0)
5.1 (1.729)
5.4 (2.319)
4.4 (1.265)
8.0 (0.0)
6.0 (2.667)
7.0 (1.633)
8.0 (0.0)
8.0 (0.0)
7.2 (1.687)
7.0 (0.0)
8.0 (0.0)
4.8 (1.687)
6.0 (2.108)
6.8 (1.932)
6.2 (1.317)
7.6 (0.966)
7.7 (0.675)
8.0 (0.0)
6.0 (0.0)
6.573 (0.995)

Rule Len.

Acc.

3.0 (0.0)
2.8 (0.632)
1.0 (0.0)
2.5 (0.527)
2.3 (0.675)
2.1 (0.316)
3.0 (0.0)
2.4 (0.843)
2.8 (0.422)
3.0 (0.0)
3.0 (0.0)
2.8 (0.422)
3.0 (0.0)
3.0 (0.0)
2.2 (0.422)
2.5 (0.527)
2.7 (0.483)
2.8 (0.422)
3.0 (0.0)
3.0 (0.0)
3.0 (0.0)
3.0 (0.0)
2.677 (0.259)

0.999 (0.003)
0.802 (0.066)
0.689 (0.042)
0.912 (0.039)
0.680 (0.089)
0.747 (0.057)
0.968 (0.031)
0.775 (0.033)
0.965 (0.025)
0.859 (0.004)
0.852 (0.010)
0.865 (0.007)
1.000 (0.001)
0.940 (0.007)
0.962 (0.010)
0.863 (0.021)
0.986 (0.003)
0.914 (0.100)
0.950 (0.067)
0.640 (0.084)
0.816 (0.062)
0.690 (0.038)
0.858 (0.036)

RUG
#Rules

42.9 (6.871)
18.7 (6.038)
34.4 (27.253)
41.6 (10.997)
33.8 (26.41)
26.8 (13.206)
50.5 (10.865)
35.1 (23.187)
39.6 (11.711)
51.6 (24.213)
114.5 (13.142)
96.4 (23.172)
11.2 (4.59)
86.4 (7.058)
36.3 (9.557)
93.1 (13.503)
62.3 (20.271)
17.2 (10.13)
19.0 (6.342)
29.3 (10.457)
16.5 (5.061)
27.6 (4.427)
44.764 (13.112)

Rule Len.

2.063 (0.236)
1.169 (0.358)
1.492 (0.665)
1.802 (0.624)
1.289 (0.481)
1.241 (0.39)
3.0 (0.0)
1.771 (0.454)
2.034 (0.452)
2.321 (0.153)
2.629 (0.058)
2.47 (0.303)
2.138 (0.377)
2.78 (0.081)
1.642 (0.507)
2.318 (0.078)
2.318 (0.28)
2.029 (0.209)
1.52 (0.314)
2.545 (0.207)
2.498 (0.211)
2.744 (0.097)
2.082 (0.297)

there are also several datasets where the resulting sets of rules are still challenging to interpret. However,
note that the results that we present in Table 1 and Table 2 are given for all rules with nonzero optimal
weights. Using a threshold weight for a rule and monitoring the accuracy, one can end up with a set of
rules that is easier to interpret. We elaborate on this point in the next subsection with a case study.

4.2 Case Study. We demonstrate an interpretation of RUG results using “Breast Cancer Wisconsin
(Original)” dataset (Dua and Graﬀ, 2017). This dataset has nine features with integer values from [1, 10]
and two diagnosis classes (benign or malignant). RUG reaches the accuracy level of 0.96 and generates
18 rules that we denote as R1 to R18. Figure 2 shows that RUG can also attain accuracy level of 0.95
using only the ﬁrst 12 rules. The plot given in Figure 2 be used by decision makers (DMs) to interpret
the rules and their weights obtained with RUG. The horizontal axis lists the rules in descending order of
their optimal weights assigned by RUG. Here, the rule weights shown on the left side of the vertical axis
are normalized by dividing the weights with the largest among them. On the right side, we present the
accuracy of RUG on the test data cumulatively adding one rule at a time in the model. In other words,
using only the ﬁrst rule results with the accuracy of 0.92. With the addition of second and third rules, the
accuracy level increases to 0.93. This can be traced following the blue line and the corresponding point
for each rule. When rule twelve is added, the accuracy of RUG catches that of the RF. As a remark, there
is a slight deterioration in the accuracy when rule four is included and it rebounds back with addition
of rule eleven. This can be expected since the performance is evaluated on the test data. Above each
bar in the plot, we give the cumulative percentage of test instances covered by the rules. That is, rule
one covers 73% of the test data and coverage gradually increases with the addition of subsequent rules.
The coverage of samples reaches to 95% with only three rules and when the ﬁrst nine rules are used, the
coverage becomes full. Overall, interpretability plot is a playground for DMs to choose the best trade-oﬀ
between accuracy and interpretability depending on the sensitivity of the application.

We next compare the rules extracted by RUG against the rules (leaves) of a DT trained on the same
dataset with the same setting (tree depth of three). Figure 3 lists the sets of rules resulting from RUG
and DT in blocks (a) and (b), respectively. DT yields seven rules (leaves) with an accuracy of 0.92.
To make a fair comparison, only the ﬁrst three rules of RUG is shown where the accuracy of the RUG
reaches 0.93. Rules R1 to R3 are in descending order of their weights. As a reminder, these are the same
ﬁrst three rules shown in Figure 2. Even with fewer number of rules, the accuracy of RUG is better than
DT.

We also observe that RUG extracts more interpretable rules than DT. A drawback of DT rules (D1-D7)
is their interdependent structure. For example D3 is constructed as the complement of the statement

Akyüz, Birbil: RUX & RUG

9

Figure 2: Interpretation plot. RUG surpasses accuracy level of DT by using the ﬁrst 3 rules that ordered
in terms of their normalized weights (bar heights). The percentages show the cumulative fractions of the
samples covered after adding each rule.

“Bare Nuclei ≤ 5” in D1 and D2. However, D3 has two observations; one originally labeled as malignant
and the other as benign. This implies a false negative classiﬁcation of a patient in one out of two cases
(50%). Similar structure can be observed for DT rules D5 to D7, where they are created as the complement
of “Uniformity of Cell Shape ≤ 3” in rules D1 to D4. Such an unbalanced structure is not observed for
the rules extracted by RUG. More importantly, a false negative classiﬁcation can be compensated in two
ways by RUG: First, multiple rules covering a sample gives more chance to correct classiﬁcation of the
sample. In case there are two or more rules that do not agree, the rule weights can compromise the ﬁnal
class of a sample and correctly classify it based on the loss function’s structure. An example of such a
case can be illustrated using the false negative classiﬁcation of the sample with D3. Using RUG, the
patient data is covered by four rules; R4, R9 and R15 with weights 0.43, 0.29 and 0.14 as malignant, and
R13 with weight 0.14 as benign. Using the labels assigned by the rules and their weights, this sample is
classiﬁed as malignant. This implies that, RUG has detected the tumor and made the correct diagnosis
for the patient. Second way comes from the ﬂexibility of the LP model behind RUG. The rules that
yield false negative classiﬁcations can be explicitly penalized in the objective function. That is, each rule
yielding a false negative classiﬁcation of a sample can be assigned a high cost coeﬃcient (penalty), and
consequently, model (3) can be enforced to choose another rule. As an example, R13 can be penalized
for this case and left outside the solution to promote correct classiﬁcation.

5. Conclusion. We have proposed a linear programming (LP) approach to discover a set of critical
rules in multi-class classiﬁcation. The objective of this LP is to ﬁnd a set of rule weights such that the
sum of the classiﬁcation error and the total rule cost is minimized. Using the optimal weights of the
LP, a set of interpretable rules is obtained that can be used for classiﬁcation. This approach has led
to two algorithms that are both simple, fast and easy-to-implement. The numerical experiments have
shown that the proposed algorithms may be used for hitting the right balance between accuracy and
interpretability.

The ﬁrst algorithm works with a predeﬁned set of rules. To demonstrate our algorithm, we have used
the models trained by Random Forest and AdaBoost algorithms. These two algorithms are frequently
used for their remarkable accuracy. However, it is very diﬃcult to interpret the trained models as both
algorithms return tree ensembles involving thousands of rules. With Random Forest, we have used the
rule lengths as cost coeﬃcients in our algorithm to obtain shorter rules for interpretation. As AdaBoost
returns also a set of estimator weights, we have used these weights as cost coeﬃcients to mimic the
performance of the trained AdaBoost model. Our numerical results show that the performance of our

Akyüz, Birbil: RUX & RUG

10

Figure 3: Rules generated by RUG versus the rules (leaves) obtained with DT. RUG rules are shown in
descending order of their weights.

rule extraction algorithm is close to –for several datasets even better than– its ensemble counterparts.
More importantly, this performance comes with much fewer rules than the rules produced with both
Random Forest and AdaBoost. On one hand, the set of rules required to apply our rule extraction
algorithm may result from tree ensembles. On the other hand, this set may also come from other learning
methods such as rule ensembles that produce a large collection of rules. Testing our algorithm further
with those rule ensembles is an interesting future research direction.

Instead of a given collection of rules, our second algorithm uses a rule generation mechanism that
iteratively solves LPs and builds up a set of rules. This algorithm has a solid mathematical basis as its
core idea comes from the well-known column generation approach in large-scale linear programming. A
signiﬁcant advantage of this algorithm is having more control on the generation of the rules. However,
there is a challenge that lies within the diﬃcult exact pricing subproblem. As a remedy, we have proposed
to solve a proxy subproblem by training decision trees with sample weights. These sample weights are
obtained from the dual of the LPs at that iteration. Decision trees can be easily trained with the existing
software packages, and hence, this proxy pricing problem can be implemented quite eﬃciently. We have
compared the performance of our rule generation algorithm with the highly interpretable Decision Tree
algorithm, and with the highly accurate tree ensemble algorithms, Random Forest and AdaBoost. At the
expense of more but shorter rules than Decision Trees, our rule generation algorithm performs on par
with tree ensemble algorithms in terms of accuracy.

This study is conducted for multi-class classiﬁcation. With a piecewise-linear loss function (e.g. mean
absolute deviation), our LP model can also be reformulated for regression problems. An alternative
approach can be to incorporate the dual values corresponding to coverage constraints within the solution
of the proxy pricing subproblem. This might require developing a specially tailored DT that depends on
the usage of γ values. These are other lines of research that we plan to pursue in the future.

R1:IfMarginalAdhesion≥8thenMalignantR2: IfBare Nuclei ≤2andUniformity of Cell Shape ≤3 thenBenignR3:IfMarginalAdhesion≥2andUniformityofCellSize≥5thenMalignantD1:IfUniformityofCellShape≤3andBareNuclei≤5andBareNuclei≤2thenBenignD2:IfUniformityofCellShape≤3andBareNuclei≤5andBareNuclei≥3thenBenignD3:IfUniformityofCellShape≤3andBareNuclei≥6andUniformityofCellShape≤1thenBenignD4:IfUniformityofCellShape≤3andBareNuclei≥6andUniformityofCellShape≥2thenMalignantD5:IfUniformityofCellShape≥4andUniformityofCellSize≤1thenBenignD6:IfUniformityofCellShape≥4andUniformityofCellSize≥2andBlandChromatin≤2thenMalignantD7:IfUniformityofCellShape≥4andUniformityofCellSize≥2andBlandChromatin≥3thenMalignant(a) RUG(b) DTAkyüz, Birbil: RUX & RUG

References

11

Adnan, M. N. and Islam, M. Z. (2017). Forex++: A new framework for knowledge discovery from decision

forests. Australasian Journal of Information Systems, 21.

Andrews, R., Diederich, J., and Tickle, A. B. (1995). Survey and critique of techniques for extracting

rules from trained artiﬁcial neural networks. Knowledge-based systems, 8(6):373–389.

Barakat, N. and Bradley, A. P. (2010). Rule extraction from support vector machines: a review.

Neurocomputing, 74(1-3):178–190.

Birbil, S. I., Edali, M., and Yuceoglu, B. (2020). Rule covering for interpretation and boosting. arXiv

preprint arXiv:2007.06379.

Cohen, W. W. (1995). Fast eﬀective rule induction. In Machine learning proceedings 1995, pages 115–123.

Elsevier.

Cohen, W. W. and Singer, Y. (1999). A simple, fast, and eﬀective rule learner. AAAI/IAAI, 99(335-

342):3.

Dash, S., Günlük, O., and Wei, D. (2020). Boolean decision rules via column generation. arXiv preprint

arXiv:1805.09901.

Demiriz, A., Bennett, K. P., and Shawe-Taylor, J. (2002). Linear programming boosting via column

generation. Machine Learning, 46(1-3):225–254.

Desaulniers, G., Desrosiers, J., and Solomon, M. M. (2006). Column generation, volume 5. Springer

Science & Business Media.

Dua, D. and Graﬀ, C. (2017). UCI machine learning repository.

Freund, Y. and Schapire, R. E. (1997). A decision-theoretic generalization of on-line learning and an

application to boosting. Journal of computer and system sciences, 55(1):119–139.

Fürnkranz, J. (1999). Separate-and-conquer rule learning. Artiﬁcial Intelligence Review, 13(1):3–54.

Fürnkranz, J., Gamberger, D., and Lavrač, N. (2012). Foundations of rule learning. Springer Science &

Business Media.

Ghosh, B. and Meel, K. S. (2019). Imli: An incremental framework for maxsat-based learning of inter-
pretable classiﬁcation rules. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and
Society, pages 203–210.

Grove, A. J. and Schuurmans, D. (1998). Boosting in the limit: Maximizing the margin of learned

ensembles. In AAAI/IAAI, pages 692–699.

Günlük, O., Kalagnanam, J., Menickelly, M., and Scheinberg, K. (2018). Optimal decision trees for

categorical data via integer programming. arXiv preprint arXiv:1612.03225.

Hayashi, Y. and Oishi, T. (2018). High accuracy-priority rule extraction for reconciling accuracy and

interpretability in credit scoring. New Generation Computing, 36(4):393–418.

Kubat, M., Holte, R. C., and Matwin, S. (1998). Machine learning for the detection of oil spills in satellite

radar images. Machine learning, 30(2):195–215.

Lakkaraju, H., Bach, S. H., and Leskovec, J. (2016). Interpretable decision sets: A joint framework for
description and prediction. In Proceedings of the 22nd ACM SIGKDD international conference on
knowledge discovery and data mining, pages 1675–1684.

Akyüz, Birbil: RUX & RUG

12

Laurent, H. and Rivest, R. L. (1976). Constructing optimal binary decision trees is np-complete.

Information processing letters, 5(1):15–17.

Liu, S., Patel, R. Y., Daga, P. R., Liu, H., Fu, G., Doerksen, R. J., Chen, Y., and Wilkins, D. E. (2012).
Combined rule extraction and feature elimination in supervised classiﬁcation. IEEE transactions on
nanobioscience, 11(3):228–236.

Lu Thi, K. P., Vo Thi, N. C., and Phung, N. H. (2015). Extracting rule rf in educational data classiﬁcation:
From a random forest to interpretable reﬁned rules. In 2015 International Conference on Advanced
Computing and Applications (ACOMP), pages 20–27.

Malioutov, D. and Meel, K. S. (2018). Mlic: A maxsat-based framework for learning interpretable
classiﬁcation rules. In International Conference on Principles and Practice of Constraint Programming,
pages 312–327. Springer.

Malioutov, D. and Varshney, K. (2013). Exact rule learning via boolean compressed sensing.

In

International Conference on Machine Learning, pages 765–773. PMLR.

Mason, L., Baxter, J., Bartlett, P. L., and Frean, M. R. (2000). Boosting algorithms as gradient descent.

In Advances in neural information processing systems, pages 512–518.

Schapire, R. E., Freund, Y., Bartlett, P., Lee, W. S., et al. (1998). Boosting the margin: A new explanation

for the eﬀectiveness of voting methods. The annals of statistics, 26(5):1651–1686.

Su, G., Wei, D., Varshney, K. R., and Malioutov, D. M. (2016). Learning sparse two-level boolean rules.
In 2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP), pages
1–6. IEEE.

Verwer, S. and Zhang, Y. (2019). Learning optimal classiﬁcation trees using a binary linear program
formulation. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 33, pages 1625–
1632.

Wang, S., Wang, Y., Wang, D., Yin, Y., Wang, Y., and Jin, Y. (2020). An improved random forest-based

rule extraction method for breast cancer diagnosis. Applied Soft Computing, 86:105941.

Wang, T. and Rudin, C. (2015). Learning optimized or’s of and’s. arXiv preprint arXiv:1511.02210.

Wang, T., Rudin, C., Doshi-Velez, F., Liu, Y., Klampﬂ, E., and MacNeille, P. (2017). A bayesian
framework for learning rule sets for interpretable classiﬁcation. The Journal of Machine Learning
Research, 18(1):2357–2393.

Zhu, J., Zou, H., Rosset, S., and Hastie, T. (2009). Multi-class adaboost. Statistics and its Interface,

2(3):349–360.

Akyüz, Birbil: RUX & RUG

13

Appendix A. Properties of the Test Instances. We have used 22 datasets in our experiments.
The properties of these datasets are summarized in Table 3. The ﬁrst 17 datasets are for binary classiﬁ-
cation, whereas the remaining datasets are for multi-class classiﬁcation.

Table 3: The properties of the datasets. Here, SAMPLE SIZE, CLASSES and FEATURES stand for the number
of observations, the number of classes and the number of features, respectively. The datasets are from the following
sources: oilspill from Kubat et al. (1998), phoneme from an online repository, remaining from (Dua and Graﬀ,
2017)

Instance

Sample Size Classes Features

banknote
hearts
ilpd
ionosphere
liver
pima
tic-tac-toe
transfusion
wdbc
adult
bank-mkt
magic
mushroom
musk
oilspill
phoneme
mammography
seeds
wine
glass
ecoli
sensorless

1372
303
583
351
345
768
958
748
569
32561
11162
19020
8124
6598
937
5404
11183
210
178
214
336
58509

2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
3
3
6
8
11

4
13
10
34
6
8
9
4
31
14
16
10
22
166
49
5
6
7
13
9
7
48

Appendix B. Parametric Model. Before we analyze the parametric model, let us ﬁrst rewrite

problem (3) in canonical form using matrix notation. To simplify our exposition, we deﬁne

z =






w
v
u






, d =











c
e
0

, b =

(cid:35)

(cid:34)

e
e

and M =

(cid:34) ˆA I
A 0

(cid:35)

,

0
I

where w = [wj]j∈J , v = [vi]i∈I, c = [cj]j∈J ˆA = [ˆaij]i∈I,j∈J , A = [aij]i∈I,j∈J along with e and 0
denoting vector of ones and zeros, respectively. The auxiliary vector u is used as a slack variable to
obtain a model in canonical form. With this notation, the master problem and its dual become

and

min{d(cid:124)z : M z = b, z ≥ 0}

max{b(cid:124)α : M (cid:124)α ≤ d},

(7)

(8)

respectively. We note that the ﬁrst set of constraints in (3) is also written as an equality. This is still
a valid formulation, since the vector v plays the role of slack variables. Recall that the second set of
constraints in the master problem guarantees coverage of the samples. Without loss of generality, we have
set the right-hand-side of these constraints to one, i.e. ε = 1. Therefore, one may deﬁne a hyperparameter
(cid:124)
= [0(cid:124), e(cid:124)]. Such
δ > −1 and consider a set of alternative right-hand-side values b(δ) = b + δ¯b with ¯b
a change in the right-hand-side value leads to a parametric linear program. Next, we give an interval of
δ values so that as long as δ remains in this interval, the optimal basis does not change and there is no
need to solve the master problem again.

Suppose that we have solved problem (7) and obtained the optimal solutions z∗ and α∗. Let us
denote the indices of the basic and nonbasic variables with B and N , respectively. By rearranging the
corresponding columns, we can write

M z∗ = M Bz∗

B + M N z∗

N = b

Akyüz, Birbil: RUX & RUG

and

14

Hence, we obtain z∗
the feasibility of the dual solution. The primal solution, however, becomes

B=M −1

B b, z∗

B

(cid:124)

d(cid:124)z∗ = d
B + d
N = 0 and α∗ = dBM −1

Bz∗

(cid:124)

N z∗
N .
. Clearly, replacing b with b(δ) does not aﬀect

B(δ) = M −1
z∗

B b(δ) = M −1

B b + δM −1

B

¯b = z∗

B + δ ¯z∗
B.

We observe for z∗

N (δ) = 0 that

B(δ) = b(δ),
B(δ) = b(δ)(cid:124)α∗.
This shows that current basis remains optimal as long as z∗
interval for δ values:

M Bz∗
d(cid:124)z∗

B(δ) ≥ 0. This leads to the following simple

i>0
. During hyperparameter tuning, if δ goes out of this interval, then
where [z∗
problem (8) can be solved after replacing b with b(δ). Consequently, the same line of parametric analysis
can be applied to ﬁnd the next interval of values.

i ]i∈B = z∗
B

and [¯z∗

i<0

max
i∈B,b(cid:48)
i ]i∈B = ¯z∗
B

{−1, − z∗
i
¯z∗
i

} ≤ δ ≤ min
i∈B,b(cid:48)

{− z∗
i
¯z∗
i

},

Appendix C. Relation to Boosting Methods. The relation between the proposed rule genera-

tion algorithm (RUG) and the boosting methods can be summarized in three parts:

(i) In boosting methods, a sequence of weak classiﬁers are trained in tandem, and each classiﬁer
depends on the classiﬁers that come before it. To improve accuracy with every new classiﬁer,
the weights of the misclassiﬁed points are increased. Moreover, each classiﬁer in the sequence
receives a weight according to its classiﬁcation performance, while the weights of the previous
classiﬁers are ﬁxed. In our master problem (3), we also assign weights to the rules and these rules
can be considered as weak classiﬁers. However, when we apply rule generation, we do not ﬁx
the weights of rules. Instead, we obtain the optimal rule weights by solving a linear program at
each iteration. Therefore, rule weights are determined simultaneously rather than being assigned
sequentially.

(ii) The duality discussion with our linear programs also lends itself to an interesting discussion about
our approach and the margin maximization idea in boosting methods as presented by Schapire
et al. (1998), Grove and Schuurmans (1998) and Demiriz et al. (2002). These authors establish
that a sample with a large margin is likely to be classiﬁed correctly. Thus, margin maximization
is about assigning larger weights to those samples with small margins. Clearly, the ﬁrst set of
constraints in (3) always holds as equalities due to the nonnegative costs of the variables vi, i ∈ I.
Using complementary slackness conditions in linear programming, we have the following facts:

ˆaijwj > 1 implies vi = 0 and βi = 0.
ˆaijwj ≤ 1.

j∈Jk

• (cid:80)
• βi > 0 only if (cid:80)
j∈Jk
• 0 < βi < 1 only if (cid:80)
• (cid:80)

j∈Jk

ˆaijwj = 1 (marginal accuracy for sample i).

j∈Jk

ˆaijwj < 1 implies βi = 1 (misclassiﬁcation of sample i).

This shows that the optimal dual variable β(t)
becomes positive only if sample i is misclassiﬁed, or
it is correctly classiﬁed but remains on the boundary. So at the next iteration of rule generation,
only those samples that have small margins are considered.

i

(iii) Mason et al. (2000) relate boosting algorithms to gradient descent. It is well-known that the
dual optimal solution plays the role of gradient vector for the primal problem. This points out
yet another connection between our approach and the boosting methods.

Akyüz, Birbil: RUX & RUG

15

Table 4: The performances of CG Dash et al. (2020), BRS Wang et al. (2017), AM and BCD Su et al. (2016),
RIPPER Cohen (1995), and RUG-T. Here, ACC., and COMP. stand for accuracy and complexity, respectively.
Complexity is deﬁned as the summation of the number of generated rules and the number of conditions in the
rules.

Dataset

CG

BRS

AM

BCD

RIPPER

RUG-T

Acc. Comp. Acc. Comp. Acc. Comp. Acc. Comp. Acc. Comp. Acc. Comp.

0.99
banknote
0.79
hearts
0.70
ilpd
0.87
ionosphere
0.54
liver
0.74
pima
1.00
tic-tac-toe
0.77
transfusion
0.95
wdbc
0.82
adult
0.87
bank_mkt
0.83
magic
1.00
mushroom
musk
0.93
The figures in columns 2-11 are taken from Dash et al. (2020)

24.2
11.5
0
16
8.7
2.7
24.9
0
11.6
15
6.8
11.5
15.4
101.3

25
11.3
10.9
12.3
5.2
4.5
32
5.6
13.9
88
9.9
93
17.8
123.9

0.99
0.73
0.72
0.91
0.56
0.73
0.84
0.76
0.96
0.83
0.90
0.81
1.00
0.97

0.99
0.79
0.70
0.90
0.60
0.74
1.00
0.78
0.94
0.84
0.90
0.85
1.00
0.96

30.4
24
4.4
12
15.1
17.4
32
6
16
39.1
13.2
97.2
17.5
33.9

0.99
0.74
0.72
0.92
0.52
0.73
0.82
0.76
0.96
0.82
0.90
0.80
1.00
0.92

21.3
15.4
0
14.6
4
2.1
12.6
0
17.3
13.2
2.1
9
14.6
24.4

0.99
0.79
0.7
0.88
0.57
0.73
0.98
0.79
0.93
0.84
0.90
0.85
1.00
0.96

28.6
16
9.5
14.6
5.4
17
32.9
6.8
16.8
133.3
56.4
177.3
17
143.4

0.99
0.82
0.70
0.91
0.69
0.74
0.91
0.76
0.94
0.85
0.82
0.83
1.00
0.93

48.7
19.7
10.6
24.9
58.6
30.9
70
26.9
28.8
43.8
85.6
72.8
31
87.2

Appendix D. Comparison with Recent Binary Classiﬁcation Methods for Interpretation.
Table 4 presents a comparison of RUG against existing studies from the literature. In the table, “CG”
stands for the column generation framework by Dash et al. (2020), “BRS” is the Bayesian Rule Set
approach by Wang et al. (2017), “AM” and “BCD” are alternating minimization and block coordinate
descent algorithms by Su et al. (2016), respectively. The last one “RIPPER” ‡ is the well-known rule
generation heuristic of Cohen (1995). The acronym “ACC.” stands for the mean accuracy and “COMP.”
denotes the complexity. Dash et al. (2020) deﬁne complexity as the sum of the number of rules and
the number of conditions for each rule. Although complexity is not directly addressed in our study, it
is calculated for RUG for the sake of completeness. To make a fair comparison, we have additionally
considered RUG with threshold values (RUG-T), for which the number of subproblem calls is restricted
to ﬁve, and the rules satisfying the weight threshold of wj ≥ 0.05, j ∈ J are selected for testing. The
last two columns Table 4 give the mean accuracies and the complexity values for RUG-T, respectively.
Dash et al. (2020) consider only binary classiﬁcation. Thus, the multi-class classiﬁcation datasets in
the previous tables are excluded. Moreover, two datasets from Dash et al. (2020) are excluded since
we have failed to access those instances. The average accuracy of RUG-T is on par with the CG which
has superior accuracy than BRS, AM, BCG and RIPPER. For hearts, ILPD, ionosphere, liver
and adults datasets, RUG-T outperforms CG in accuracy. However, the accuracy is in favor of CG
when compared to RUG-T on datasets tic-tac-toe, transfusion, bank-mkt, magic and musk. The
average complexity of RUG-T is slightly worse than that of CG except musk dataset. RUG-T exposes
a worthwhile example on how to ﬁne-tune parameters of RUG so that a good balance can be achieved
for interpretability. We also observe that RUG is robust in the sense that reducing the number of RMP
calls does not reduce the accuracy drastically. Besides, applying a threshold to select rules contributes
to interpretability without a severe damage on accuracy. Fortunately, RUG-T is signiﬁcantly faster than
the CG. Indeed, all our algorithms run in less than a minute, while CG is reported to take around 20
minutes for all datasets except mushroom and tic-tac-toe.

‡This is the JRip implementation in Weka.

