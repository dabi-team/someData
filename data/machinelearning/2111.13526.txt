2
2
0
2

r
p
A
3

]

G
L
.
s
c
[

2
v
6
2
5
3
1
.
1
1
1
2
:
v
i
X
r
a

An Optimization Framework for Federated

Edge Learning

Yangchen Li, Ying Cui, and Vincent Lau

Abstract

The optimal design of federated learning (FL) algorithms for solving general machine learning (ML)

problems in practical edge computing systems with quantized message passing remains an open problem.

This paper considers an edge computing system where the server and workers have possibly different

computing and communication capabilities and employ quantization before transmitting messages. To

explore the full potential of FL in such an edge computing system, we ﬁrst present a general FL

algorithm, namely GenQSGD, parameterized by the numbers of global and local iterations, mini-batch

size, and step size sequence. Then, we analyze its convergence for an arbitrary step size sequence and

specify the convergence results under three commonly adopted step size rules, namely the constant,

exponential, and diminishing step size rules. Next, we optimize the algorithm parameters to minimize

the energy cost under the time constraint and convergence error constraint, with the focus on the overall

implementing process of FL. Speciﬁcally, for any given step size sequence under each considered step

size rule, we optimize the numbers of global and local iterations and mini-batch size to optimally

implement FL for applications with preset step size sequences. We also optimize the step size sequence

along with these algorithm parameters to explore the full potential of FL. The resulting optimization

problems are challenging non-convex problems with non-differentiable constraint functions. We propose

iterative algorithms to obtain KKT points using general inner approximation (GIA) and tricks for solving

complementary geometric programming (CGP). Finally, we numerically demonstrate the remarkable

gains of GenQSGD with optimized algorithm parameters over existing FL algorithms and reveal the

signiﬁcance of optimally designing general FL algorithms.

Federated learning, stochastic gradient descent, quantization, convergence analysis, optimization.

Index Terms

Yangchen Li and Ying Cui are with Shanghai Jiao Tong University, China. Vincent Lau is with HKUST, Hong Kong. This

paper will be presented in part at IEEE GLOBECOM 2021 [1].

April 5, 2022

DRAFT

 
 
 
 
 
 
2

I. INTRODUCTION

With the development of mobile Internet and the Internet of Things (IoT), a massive amount

of data is generated at the edge of wireless networks and stored in a distributed manner.

Leveraging on the emerging machine learning (ML) technologies, these distributed databases,

usually containing privacy-sensitive data, can be used to train models for intelligent applications,

such as keyboard search suggestions, human activity recognition, human mobility prediction,

ranking browser history suggestions, and patient clustering. Thus, it may be impossible or

undesirable to upload distributed databases to a central server due to energy and bandwidth

limitations or privacy concerns. Recent years have witnessed the growing interest in federated

learning (FL) in edge computing systems, also referred to as federated edge learning, where

the server periodically updates the global model by aggregating and averaging the local models

trained and uploaded by the workers [2], [3]. Therefore, FL can successfully protect data privacy

for privacy-sensitive applications and improve communication efﬁciency.

Typical FL algorithms, such as Parallel Mini-batch SGD (PM-SGD) [4], Federated Averaging

(FedAvg) [5], and Parallel Restarted SGD (PR-SGD) [6], are designed based on stochastic

gradient descent (SGD) algorithms1 and are usually parameterized by the numbers of global

and local iterations, mini-batch size, and step size sequence. Speciﬁcally, in PM-SGD, each

worker utilizes one mini-batch in each local iteration and conducts only one local iteration

within a global iteration; in FedAvg, participated workers utilize all their local samples and

conduct the same number of local iterations within a global iteration; and in PR-SGD, each

worker conducts multiple local iterations within a global iteration. In addition, [4] and [5] adopt

a constant step size when implementing global iterations, and [4] analyzes the convergence of

PM-SGD for convex ML problems; [6] adopts both constant and time-varying step size sequences

when implementing global iterations and analyzes the convergence of PR-SGD for non-convex

ML problems.

The main limitations of the above FL algorithms lie in the following two aspects. Firstly, [4]–

[6] assume that the server and workers send accurate model updates, which may contain a large

number of information bits. Due to limited communication resources, accurate model updates

may not be delivered timely. To address this issue, [8] and [9] propose to quantize the local model

1Some recent proposed FL algorithms are based on stochastic successive convex approximation (SSCA) [7], which are out

of the scope of this paper.

April 5, 2022

DRAFT

3

updates before transmitting them to the server. In particular, in [8], the authors propose an FL

algorithm, namely FedPAQ, where the participated workers employ general random quantization

on the local model updates; in [9], the authors propose a quantization scheme, namely UVeQFed,

for the local model updates generated by FedAvg. Note that [8], [9] assume that the server sends

the exact model updates, which may consume a lot of transmission time and energy. Secondly,

in [4]–[6], [8], [9], some algorithm parameters (such as the step size sequences in [5], [6],

[8], [9]) are usually chosen empirically and experimentally, and some (such as the number of

local iterations for all workers in [4]) are ﬁxed. Choosing parameters via numerous experiments

may be time-consuming in practice and does not have any theoretical guarantee. To deal with

this issue, the authors in [10]–[13] consider the optimization of the algorithm parameters to

minimize the convergence error [10], energy consumption [11], completion time [12], and the

weighted sum of the energy consumption and completion time [13], respectively. Unfortunately,

the results in [10]–[13] hold only for strongly-convex ML problems and accurate model updates,

as the formulations rely on the convergence errors derived under these restrictions. However, in

many ML applications, the training problems are non-convex.

In summary, there are two issues unresolved in designing FL algorithms for general (not

necessarily convex) ML problems in the presence of quantization errors for global and local

model updates. First, the convergence analysis of an FL algorithm with arbitrary step size rules

and algorithm parameters is unknown. Second, the optimal choice of FL algorithm parameters

for reducing the convergence error as well as computing and communication costs when imple-

menting FL in practical edge computing systems is open. This paper aims to shed some light

on the two fundamental problems. Speciﬁcally, we consider a practical edge computing system

where the server and workers may have different computing and communication capabilities

and employ quantization on their model updates. We concentrate on the overall implementing

process of FL and optimize the algorithm parameters of a general FL algorithm for general ML

problems. Note that short time-scale optimal computing and communication resource allocation

for one global iteration [14]–[18] is out of the scope of this paper. The main contributions of

this paper are summarized below.

•

General FL Algorithm with Quantized Message Passing: We present a general quantized

parallel mini-batch SGD algorithm, namely GenQSGD, where the server and all workers

send quantized model updates to effectively adapt to the communication capabilities of

the server and all workers. GenQSGD is parameterized by the numbers of global and

April 5, 2022

DRAFT

4

local iterations, mini-batch size, and step size sequence, which can be ﬂexibly chosen to

adequately adapt to the computing capabilities of the server and all workers and effectively

improve the convergence speed. On the contrary, the server [4]–[6], [8] and workers [4]–[6]

send accurate model updates. Besides, some algorithm parameters are ﬁxed in [4]–[6], [8],

and the quantization parameters for all workers are identical in [8].

General Convergence Analysis: We analyze the convergence of GenQSGD with an arbi-

trary step size sequence and specify the results under three commonly adopted step size rules,

i.e., the constant step size rule [19], [20], exponential step size rule [21], and diminishing step

size rule [19], [20]. In contrast, the convergences of PM-SGD and PR-SGD are characterized

only for accurate model updates in [4] and [6] respectively, and the convergence of FedPAQ

is analyzed solely for speciﬁc step size rules in [8].

Optimization of Algorithm Parameters for Fixed Step Size Sequences: Considering

applications with preset step size sequences, we optimize the numbers of global and local

iterations and mini-batch size for a ﬁxed step size sequence under each of the three step

size rules to minimize the energy cost under the time constraint and convergence error

constraint. The three optimization problems are challenging non-convex problems with non-

differentiable constraint functions. We propose iterative algorithms to solve these problems

using general inner approximation (GIA) [22] and tricks for solving complementary geo-

metric programming (CGP) [23]. We also characterize their convergences to KKT points.

Optimization of All Algorithm Parameters: Aiming to explore the full potential of FL,

we optimize the numbers of global and local iterations, mini-batch size, and step size

sequence to minimize the energy cost under the time constraint, convergence error constraint,

and step size constraint. Due to the presence of a dimension-varying vector variable, the

corresponding non-convex optimization problem with non-differentiable constraint functions

is even more complicated than those for ﬁxed step size sequences. To tackle this extra

challenge, we ﬁrst show that the constant step size rule achieves the minimum convergence

error among all step size rules. Then, based on this property, we equivalently transform the

original problem to a more tractable one and propose an iterative algorithm to obtain a KKT

point using GIA and CGP. Note that in [4]–[6], some algorithm parameters are chosen via

time-consuming experiments, which do not have any theoretical guarantees.

Numerical Results: We numerically demonstrate the convergence of GenQSGD and illus-

trate that the optimization-based GenQSGD can achieve a trade-off among the time cost,

•

•

•

•

April 5, 2022

DRAFT

energy cost, and convergence error. We also numerically show remarkable gains of the

proposed GenQSGD with optimized algorithm parameters over existing FL algorithms.

5

X

letters (e.g.,

) to represent vectors, scalar constants, and sets, respectively.

Notation: We use boldface letters (e.g., x), non-boldface letters (e.g., x or X), and calligraphic
], and I[
·
represent the l2-norm, expectation, and indicator function, respectively. The set of real numbers,
positive real numbers, and positive integers are denoted by R, R+, and Z+, respectively. All-ones
vector is denoted by 1.

k · k2, E[
·

]

We consider an edge computing system consisting of one server and N workers, which are

II. SYSTEM MODEL

,

1, 2,

assume that each worker n

connected via wireless links. Let 0 and
set of worker indices, respectively. For ease of exposition, we also denote ¯
N
∈ In with

} ∪ N
holds In samples, denoted by ξi, i
= In. Note
∈ In can be viewed as the realizations of a random variable, denoted by ζn. The server
and N workers aim to collaboratively train a global model by solving an ML problem based on

denote the server index and the

{
|In|

that ξi, i

. We

∈ N

, N

· · ·

N

,

}

{

0

RD. Speciﬁcally, for a given x

the local data stored on the N workers. The global model is parameterized by a D-dimensional
RD, deﬁne the loss incurred by ζn as F (x; ζn) and
vector x
deﬁne the expected loss as fn(x) , E [F (x; ζn)], with the expectation taken with respect to the
R of the model

. Then, the expected risk function f : RD

distribution of ζn, for all n

∈

∈

→

parameters x

∈

∈ N
RD is deﬁned as:

f (x) , 1
N

fn(x).

(1)

n
X
∈N
To be general, we do not assume f (x) to be convex. Our goal is to minimize the expected risk

function with respect to the model parameters x in the edge computing system.

Problem 1 (ML Problem).

where f (x) is given by (1).2

f ∗ , min
x

f (x)

(2)

Problem 1 is an unconstrained problem which may be convex or non-convex. The goal of

solving an unconstrained problem is generally to design an iterative algorithm to obtain a

2A constrained ML problem can be transformed into an unconstrained ML problem by augmenting the objective function of
the original problem with a weighted sum of the constraint functions. The weights can be numerically adjusted to guarantee
that the constraints are satisﬁed. Thus, the proposed GenQSGD can be applied to solve a constrained ML problem.

April 5, 2022

DRAFT

stationary point.3 The server and N workers all have computing and communication capabilities.

6

Let F0 and Fn denote the CPU frequencies (cycles/s) of the server and worker n

,

∈ N

respectively. Let p0 and pn denote the transmission powers of the server and worker n

∈ N
respectively. In the process of collaborative training, the server multicasts messages to the N

,

workers at an average rate r0 (b/s) over the whole frequency band, and the N workers transmit

their messages to the server at average transmission rates rn, n

(b/s) using frequency division

∈ N

multiple access (FDMA). The server and all N workers employ quantization before transmitting

messages. Throughout this paper, for each node, we consider an arbitrary random quantizer
Z+ (corresponding to the

RD, which has a tunable quantization parameter s

; s) : RD

Q(

·

→

number of quantization levels)4 and satisﬁes the following assumption [8, Assumption 1].

∈

Assumption 1 (Random Quantization). For all y
E [Q(y; s)] = y and (ii) E
qs k

Q(y; s)

2
2
k

≤

−

y

k

y

RD and s

Z+, Q(

; s) satisﬁes: (i)

∈
∈
2
2, for some constant5 qs > 0.
k

·

For an input vector y

(cid:3)

(cid:2)
RD, the number of bits to specify the quantized vector Q(y; s), i.e.,
Z+ to denote the

∈

represent y, is denoted by Ms (bits). In this paper, we use s0 ∈
random quantization parameters for the server and worker n
∈ N

Z+ and sn ∈
, respectively.

Remark 1 (General Edge Computing System). The edge computing system considered here is

general in the sense that the system parameters, i.e., Fn, pn, rn, sn, n

¯
N

∈

, can be different.

III. ALGORITHM DESCRIPTION AND CONVERGENCE ANALYSIS FOR GENQSGD

In this section, we ﬁrst present a general quantized parallel mini-batch SGD algorithm for

solving Problem 1 in the edge computing system. Then, we analyze its convergence.

A. Algorithm Description

The proposed GenQSGD algorithm is parameterized by K , (Kn)n
K0 ,

Z+, and
. Speciﬁcally, K0 represents the number

+ , where

, K0}

+ , B

¯
N ∈
∈

ZN +1

γ(k0)

1, 2,

RK0

0 ∈

· · ·

∈

k0

{

Γ ,

(cid:0)

of global iterations, Kn represents the number of local iterations executed by worker n

∈ N
within one global iteration, B represents the local mini-batch size used for local iterations at

(cid:1)

∈K

3Note that any stationary point of a convex problem is globally optimal, and a stationary point of a non-convex problem may

be a locally optimal point, globally optimal point, or saddle point.

4Usually, s is the number of quantization levels or its increasing function.
5qs depends on (usually decreases with) s.

April 5, 2022

DRAFT

Algorithm 1 GenQSGD

ZN +1

Input: K
+ , B
∈
Output: x∗ (K, B, Γ).

∈

Z+, and Γ

RK0
+ .

∈

−

1: Initialize: The server generates x(0)

0 , sets ∆ˆx(0) =
x(0)
0 , and sends Q(∆ˆx(0); s0) to all N workers. The
N workers set ˆx(0) = 0.
, K0 do
do

· · ·
for worker n

2: for k0 = 1, 2,
3:
4:

Compute ˆx(k0) according to:
ˆx(k0):= ˆx(k0−1)+γ(k0−1)Q(∆ˆx(k0−1);s0), (3)
and set x(k0,0)
for kn = 1, 2,

= ˆx(k0).

, Kn do

n

∈ N

· · ·
Randomly select a mini-batch
update x(k0,kn)
according to:
n
x(k0,kn)

:= x(k0,kn−1)
n

n

B

(k0,kn)
n

and

5:
6:

7

x(k0,kn−1)
n

; ξ

.

(4)

(cid:16)

(cid:17)

−ˆx(k0)

,

and

send

γ(k0)
B

F

∇
Xξ∈B(k0 ,kn )
x(k0 ,Kn )

n

n

end for
Compute

7:
8:

9:
10:

γ(k0 )
; sn

x(k0 ,Kn )

−ˆx(k0 )

n

γ(k0 )

Q
end for
(cid:16)
The server computes ∆ˆx(k0) according to:

to the server.

(cid:17)

∆ˆx(k0):=

Q

1
N

x(k0,Kn)
n

ˆx(k0)

−
γ(k0)

!
and sends Q(∆ˆx(k0); s0) to all N workers.

n∈N
X

; sn

, (5)

11: end for
12: The server7 and all N workers compute ˆx(K0+1)
according to (3), and set x∗ (K, B, Γ) = ˆx(K0+1).

each worker, and γ(k0) represents the (constant) step size6 used in the local iterations within the

k0-th global iteration. Besides, let

Kn ,

{

1, 2,

, Kn}

· · ·

denote the local iteration index set for

worker n

.
∈ N
For all k0 ∈ K0, ˆx(k0)

∈

RD denotes the global model recovered by all N workers (and the

∈

server, if it needs to obtain the ﬁnal global model) at the beginning of the k0-th global iteration,
x(k0,0)
n

RD denotes the initial local model of worker n

at the beginning of the k0-th global
RD denotes the average of the quantized overall local model updates

iteration, and ∆ˆx(k0)
(termed the global model update) at the k0-th global iteration. For all k0 ∈ K0, kn ∈ Kn, n
x(k0,kn)
n

∈ N
denote the local model of worker n and the mini-batch

RD and

∈ N

∈

,

ξi : i

(k0,kn)
n
B

⊆ {

∈ In}

∈

used by worker n, respectively, at the kn-th local iteration within the k0-th global iteration.

The proposed GenQSGD is presented in Algorithm 1. During the k0-th global iteration (Step 3-

Step 11), each worker n
1)-th global iteration and the quantized global model update (Step 4), executes Kn local
(k0 −
iterations of the mini-batch SGD algorithm with mini-batch size B and constant step size γ(k0)

initializes its local model based on the global model at the

∈ N

(Step 5-Step 7), and sends the quantized overall local model update to the server (Step 8); the

server aggregates and computes the average of the quantized overall local model updates, i.e.,

global model update, and sends the quantized result to all N workers (Step 10).

6For ease of exposition, we consider a constant step size for the local iterations within one global iteration, as in [6], [8]. The

convergence analysis and optimization results in this paper can be readily extended to the case with any step size rule.

April 5, 2022

DRAFT

 
Remark 2 (Generality of GenQSGD). GenQSGD is general in the sense that K, B, and Γ

can be ﬂexibly chosen, and it includes some existing algorithms as special cases. For the sake

8

of discussion, we let s =

present the case without quantization. In particular, GenQSGD

with Kn = 1, n
Kn = l In

B , l

Z+, n

∈ N

∈

∈ N

∞
for sn =

for sn =

, n

∞

, n

∞

¯
N
¯
N

∈

∈

reduces to PM-SGD [4]; and GenQSGD with

reduces to FedAvg [5].

B. Convergence Analysis

In the rest of this paper, we assume that the following typical assumptions are satisﬁed [6].

Assumption 2 (I.I.D. Samples). ζn, n

are I.I.D..

∈ N

Assumption 3 (Smoothness). For all n

, fn(x) is continuously differentiable, and its gradi-

∈ N

ent is Lipschitz continuous, i.e., there exists a constant L > 0 such that

fn(x)

k∇

− ∇

fn(y)

k2 ≤

L

x

k

−

y

k2, for all x, y

∈

RD.

, there exists a constant σ > 0 such that

k∇

(cid:2)

Assumption 4 (Bounded Variances). For all n
E

σ2, for all x

F (x; ζn)

fn(x)

∈ N
RD.

− ∇

∈

2
2

k

(cid:3)

≤

Assumption 5 (Bounded Second Moments). For all n
that E

G2, for all x

F (x; ζn)

RD.

k∇
(cid:2)

2
2

k

(cid:3)

≤

For notational simplicity, we denote

{

k

∈
Kmax ,
∈ Kn
∈ Kmax \ Kn
, k0 ∈ K0, k

x(k0,kn)
,
n
x(k0,Kn)
n

, k

˜x(k0,k)
n

Kn] , k

∈ Kmax,

≤

,

˜x(k0,k)
n



¯x(k0,k) , 1

N

Nk ,

n
X
∈N
I [k

n
X
∈N

∈ Kmax,

, there exists a constant G > 0 such

∈ N

1, 2,

, maxn

· · ·

∈N

, k0 ∈ K0, k

and deﬁne:

Kn}
∈ Kmax, n

,

∈ N

(6)

(7)

(8)

with Kn <

∈ N

The goal is to synchronize the local iterations by letting each worker n

Kn run extra maxn

Kn virtual local updates without changing its local model [6].
maxn
Thus, ¯x(k0,k) in (7) can be interpreted as the average of the local models at the k-th synchronized

Kn−

∈N

∈N

local iteration within the k0-th global iteration, and Nk in (8) can be viewed as the number of

workers conducting true local updates at the k-th synchronized local iteration within each global

iteration. The convergence of GenQSGD is summarized below.

April 5, 2022

DRAFT

Theorem 1 (Convergence). Suppose that Assumptions 1,2,3,4,5 are satisﬁed and the step size

9

γ(k0)

∈

0, 1
L

for all k0 ∈ K0. Then, for all K

generated by GenQSGD satisﬁes:8

(cid:0)

(cid:3)

ZN +1
+

and B

∈

Z+,

¯x(k0,k) : k0 ∈ K0, k
(cid:8)

∈ Kmax

(cid:9)

∈

2

γ(k0)

k0

0

∈K

P

E

max

Nk
N
γ(k0)

k

∈K

P
k0

∈K

0

f

¯x(k0,k

−

1)

∇

h(cid:13)
k
(cid:13)
∈K

max

Nk
(cid:0)
N

i

≤

(cid:1)(cid:13)
(cid:13)

CA(K, B, Γ),

where

CA(K, B, Γ) ,

P

P

c1

Kn

n
∈N
c3

P
+

k0

0

P
∈K
k0

(cid:0)
∈K

0

B
P

k0

0

γ(k0) +
c4

2

∈K
γ(k0)
γ(k0) +
(cid:1)
ˆx(1)
f

c2 maxn

K 2
n

∈N

3

γ(k0)

(cid:0)

0

(cid:1)
γ(k0)

0

k0
∈K
γ(k0)

k0

0

P
k0
∈K
qs0,snK 2
n
P
Kn

n

P

f ∗
P

−

∈K

∈N
P
n
k0
∈N
, c2 , 4G2L2, c3 , Lσ2

γ(k0)
(cid:0)

∈K

0

P

2

.

(cid:1)

(9)

N , c4 = 2LG2,

Here, qs0,sn

, qs0 + qsn + qs0qsn, c1 , 2N
and f ∗ is the optimal value of Problem 1.

P

(cid:0)

(cid:0)

(cid:1)

(cid:1)

Proof: See Appendix A.

Remark 3 (Generality of Convergence of GenQSGD). Theorem 1 for the convergence of GenQSGD

with sn =

, n

¯
N

∈

∞

and B = 1 reduces to the convergence of PR-SGD in [6, Theorem 3].9

Theorem 1 indicates that the convergence of GenQSGD is inﬂuenced by the algorithm pa-

¯
N

∈

rameters K, B, Γ and the quantization parameters sn, n

. In the following, we illustrate

how the four terms on the R.H.S of (9) change with K, B, Γ, and sn, n

. The ﬁrst term
and decreases with γ(k0) for all k0 ∈ K0; the second term
Kn; the third term decreases with B due to the decrease of the variance

∈ N

∈

¯
N

decreases with Kn for all n

increases with maxn

∈N

of a stochastic gradient; and the last term increases with qsn (decreases with sn) and vanishes
as sn → ∞

for all n

¯
N

∈

.

Next, we introduce three commonly adopted step size rules, supported by Tensorﬂow [24] and

PyTorch [25], and specify the convergence results under the three step size rules from Theorem 1.

Constant Step Size Rule: For any γC ∈

•

0, 1
L

, Γ satisﬁes:

(cid:3)
(cid:0)
Γ = γC1.

(10)

8Following the convention in literature [6], we use the expected squared gradient norm to characterize the convergence

performance for a general ML problem.

9The convergence error of PR-SGD [6] depends on the bound on the variance of the stochastic gradient and does not directly

rely on the mini-batch size.

April 5, 2022

DRAFT

Lemma 1 (Convergence under Constant Step Size Rule). If Γ satisﬁes (10), then

10

CA(K, B, Γ) =

c1

n

γCK0

Kn

∈N
,CC(K, B, Γ),

P

+c2γ2

C max
n
∈N

K 2

n +

c4γC

c3γC
B

+

qs0,snK 2
n
Kn

n

∈N

∈N

n

P
P

(11)

and CC(K, B, Γ)

∈N
if Γ satisﬁes (10) with γC = √N

→

c2γ2

C maxn

K 2

n+ c3γC

B +

c4γC

n∈N qs0,sn K 2
n
n∈N Kn

and Kn = ¯K, qs0,sn = 1

N ¯K , n

P
P

as K0 → ∞
with ¯K

. Furthermore,
(K0 ¯K)1/4
N 3/4

,

∈ N

≤

then CA(K, B, Γ) =

O

K −
0

L√K0 ¯K
.

1
2

(cid:16)

(cid:17)

Proof: We readily show (11) by substituting (10) into (9). Then, the limit of CC(K, B, Γ)
and Kn = ¯K,
can be easily derived. By substituting Γ given by (10) with γC = √N
(K0 ¯K)1/4
N 3/4

into (9), we have CA(K, B, Γ) =

qs0,sn = 1

with ¯K

N ¯K , n

L√K0 ¯K

f ∗)

+

2L(f(ˆx(1))−
√N K0 ¯K

∈ N

2L(f(ˆx(1))−
√N K0 ¯K

f ∗)

+

c2
L2√N K0 ¯K

+

σ2
B√N K0 ¯K

+

c4
L√N K0 ¯K

, where

c2N ¯K
L2K0

+

σ2
B√N K0 ¯K

(a) is due to ¯K

≤

+

c4
L√N K0 ¯K

(K0 ¯K)1/4
N 3/4

≤
(a)

≤

. Thus, we have CA(K, B, Γ) =

show Lemma 1.
Exponential Step Size Rule: For any γE ∈
γ(k0) = ρk0
E

•

0, 1
L

and ρE ∈
γE, k0 ∈ K0.

(cid:3)

1
(cid:0)
−

O

1
2

K −
0

(cid:16)

(cid:17)

. Therefore, we can

(0, 1), Γ satisﬁes:

(12)

Lemma 2 (Convergence under Exponential Step Size Rule). If Γ satisﬁes (12), then

CA(K, B, Γ) =

1

(cid:0)
+

ρK0
E
1

−
a3

a1c1

∈N

n
ρ2K0
E
(cid:1) P
−
ρK0
E

+

+

Kn
c3
B

(cid:18)

−

(cid:1)
+a2c2 maxn
(cid:1)

1
(cid:0)
a1c1
(cid:0)
n∈N Kn
, and a3 , γE
1+ρE

K 2
n

∈N

a2c2

c4

maxn

1

−

(cid:0)
n

ρ3K0
E
ρK0
1
(cid:1)
E
−
qs0,snK 2
n
(cid:1)
(cid:0)
∈N
Kn
n
P
(cid:19)
∈N
a3c4
n+a3c3
B +
P

K 2

n∈N qs0,sn K 2
n
n∈N Kn
. Furthermore, if Γ satisﬁes (12) with γE = √N

as K0 → ∞

P
P

∈N

, where

L√K0 ¯K

, CE(K, B, Γ),

(13)

and CE(K, B, Γ)
a1 , 1
ρE
−
γE

→
, a2 , γ2

P
E
1+ρE +ρ2
E

and Kn = ¯K, qs0,sn = 1

N ¯K , n

Proof: See Appendix B.

with ¯K

(K0 ¯K)1/4
N 3/4

≤

∈ N

, then CA(K, B, Γ) =

1
2

K −
0

.

(cid:17)

O

(cid:16)

Diminishing Step Size Rule: The step size sequence Γ for diminishing step size rule satisﬁes:

•

γ(k0)

,

→ ∞

2

γ(k0)

0,

→

(14)

(cid:0)
. We further consider the following widely used step size sequence Γ satisfying

(cid:1)

k0
X
∈K

0

k0
X
∈K

0

as K0 → ∞
the diminishing step size rule in (14): For any γD ∈
ρDγD
k0 + ρD

γ(k0) =

=

γD
1 + k0
ρD

0, 1
L

and ρD ∈

R+,

(cid:0)
(cid:3)
, k0 ∈ K0.

(15)

DRAFT

April 5, 2022

Lemma 3 (Convergence under Diminishing Step Size Rule). If Γ satisﬁes (15), then10

11

CA(K, B, Γ) <

b1c1

ln

K0+ρD+1
ρD+1

(cid:16)

+

ln

b3c4

(cid:17)P

n

∈N
K0+ρD+1
P
ρD+1

Kn

n
∈N
qs0,snK 2
n

Kn

n

b2c2 maxn

K 2
n

+

∈N
K0+ρD+1
ρD+1

(cid:17)

, CD(K, B, Γ),

ln

(cid:16)

+

B ln

b3c3
K0+ρD+1
ρD+1

(cid:16)

(cid:17)

(16)

∈N
and for all Γ satisfying (14), CD(K, B, Γ)
Dγ2
ρ2
(ρD+1)3+ ρ2
2(ρD+1)2 , and b3 , ρDγD
D
and Kn = ¯K, qs0,sn = 1

(cid:16)
(cid:17)P
ρD+1 . Furthermore, if Γ satisﬁes (15) with γD = √N
(ρD+1)2+ρDγD
with ¯K

0 as K0 → ∞

, then CA(K, B, Γ) =

, where b1 , 1

Dγ2
D

ρDγD

→

(K0 ¯K)1/4
N 3/4

N ¯K , n

K −
0

1
2

.

L√K0 ¯K

, b2 ,

∈ N

≤

O

(cid:16)

(cid:17)

Proof: See Appendix C.

For any given γE, γC ∈

with γE = γC, as ρE →
given by (12) approaches the constant step size rule given by (10), and the result in Lemma 2

1, the exponential step size rule

0, 1
L

(cid:0)

(cid:3)

approaches that in Lemma 1 correspondingly. Lemma 1 and Lemma 2 indicate that for the

¯x(k0,k) : k0 ∈ K0, k
(cid:8)

constant and exponential step size rules,
is guaranteed to converge to within some range of a stationary point of Problem 1, as K0 → ∞
contrast, Lemma 3 indicates that for the diminishing step size rule,
∈ Kmax
generated by GenQSGD is guaranteed to converge to a stationary point of Problem 1, as
(cid:9)
K0 → ∞
diminishing step size rules yield the same convergence rate in order.11

. Besides, Lemmas 1–3 indicate that GenQSGD under the constant, exponential, and

(cid:9)
¯x(k0,k) : k0 ∈ K0, k

generated by GenQSGD

∈ Kmax

. In

(cid:8)

IV. PERFORMANCE METRICS AND TYPICAL FORMULATIONS

In this section, we ﬁrst introduce performance metrics for implementing GenQSGD in the

edge computing system. Then, we brieﬂy discuss typical formulations for optimizing the overall

implementing process of GenQSGD.12

10A tighter bound on CA(K, B, Γ) can be found in Appendix C. We use the upper bound CD(K, B, Γ) in (16) in the

subsequent optimization for tractability.

11The constant and exponential step size rules usually yield faster convergence than the diminishing step size rule when the
step size parameters are properly chosen. Besides, the exponential and diminishing step size rules generally lead to more robust
convergence speeds against the choice of step size parameters.

12In practice, one model update usually contains a large number of information bits due to the high model dimension, and
hence its transmission lasts several time slots (with different channel states). Therefore, we consider the average rates of the
server and workers in optimizing the overall implementing process of GenQSGD. Note that most existing work on short time-
scale optimal computing and communication resource allocation relies on the assumption that the transmission of one model
update can be completed within one time slot, which may not be reasonable for a high dimensional ML model [14]–[18].

April 5, 2022

DRAFT

A. Performance Metrics

12

Let Cn denote the number of CPU-cycles required for worker n

F (x; ξi)
∈ In, and let C0 denote the number of CPU-cycles required for the
server to compute one global model update. Then, within each global iteration, the computation

RD and i

to compute

for all x

∈ N

∇

∈

time for local model training at the N workers is B maxn
executed in a parallel manner; the computation time for global averaging at the server is C0
F0

, as the local iterations are

; the

∈N

KnCn
Fn

communication time for all N workers to send their quantized local model updates to the server

is maxn

Msn
rn

∈N

, as the quantized messages are transmitted at given transmission rates using

FDMA; and the communication time for the server to multicast the quantized global model
update to all N workers is Ms0
r0
as the time cost, is given by:

. Thus, the overall time for implementing GenQSGD, referred to

T (K, B) = K0

B max
n
∈N

(cid:18)

Cn
Fn

Kn +

C0
F0

+ max
n
∈N

Msn
rn

+

Ms0
r0 (cid:19)

.

(17)

Let α0 and αn denote the constant factors determined by the switched capacitances of the server

and worker n

∈ N

, respectively [26]. Then, within each global iteration, the computation energy

for local model training at the N workers is B

n

αnKnCnFn

2; the computation energy for

global averaging at the server is α0C0F0

P
their quantized local model updates to the server is
for the server to multicast the quantized global model update to all N workers is p0Ms0
r0

2; the communication energy for all N workers to send

; and the communication energy

pnMsn
rn

. Thus,

P

∈N

n

∈N

the overall energy for implementing GenQSGD, referred to as the energy cost, is given by:

E(K, B) = K0

B

αnCnF 2

n Kn + α0C0F 2

0 +

n
X
∈N

pnMsn

rn !

.

(18)

¯
Xn
N
∈

In this paper, we assume L, σ, G, and a lower bound13 on f ∗ (equivalently, the values of c1,

c2, c3, and c4) can be obtained by the server from pre-training based on the data samples stored

on the server. We use CA(K, B, Γ) given by (9), CC(K, B, Γ) given by (11), CE(K, B, Γ) given

by (13), and CD(K, B, Γ) given by (16) as the measures of convergence errors of GenQSGD

for arbitrary, constant, exponential, and diminishing step size rules, respectively.

B. Typical Formulations

In this subsection, we discuss formulations for optimally balancing among the three per-

formance metrics, i.e., time cost, energy cost, and convergence error. Speciﬁcally, we impose

13In practice, f ∗ is usually unknown before solving Problem 1. However, in some cases, we can bound f ∗ from below. In the
(cid:17), with slight abuse of notation.

following, we also use c1 to represent the corresponding upper bound on 2N (cid:16)f (cid:16)ˆx(1)

− f ∗

(cid:17)

April 5, 2022

DRAFT

 
constraints on the performance metrics with ﬁrm requirements (if they exist) and minimize the

13

rest14 by optimizing the algorithm parameters K

∈
1
L
For tractability, we relax the integer constraints, K

(cid:22)

≺

Γ

0

ZN +1

+ , B

Z+, and Γ satisfying:

∈

1.

(19)

Z+, to their continuous
0 and B > 0, respectively. Note that a nearly optimal point satisfying

ZN +1
+

and B

∈

∈

counterparts, K

≻

the original integer constraints can be easily constructed based on an optimal point of a relaxed

problem. In this paper, as an example, we focus on minimizing the energy cost E(K, B) subject to

the following time constraint and convergence error constraint for any given m

∈ {

T (K, B)

Tmax,

≤

Cm(K, B, Γ)

Cmax,

≤

A, C, E, D

:

}
(20)

(21)

where Tmax and Cmax denote the limits on the time cost and convergence error, respectively.

Speciﬁcally, in Sec. V, we optimize K and B for any ﬁxed Γ satisfying (10), (12), and (15),

respectively; and in Sec. VI, we jointly optimize K, B, and Γ. The optimization problems can be

solved by the server (in an ofﬂine manner) before the implementation of GenQSGD.15 We shall

see that the proposed optimization framework is applicable for the other problems mentioned

above and applies to the parameter optimization of existing FL algorithms, such as PM-SGD,

FedAvg, and PR-SGD, by ﬁxing some algorithm parameters and optimizing the others.

V. OPTIMIZATION OF ALGORITHM PARAMETERS FOR FIXED STEP SIZE SEQUENCES

In many current applications, the step size sequences are treated as hyperparameters and

chosen by the server in advance to reduce the convergence error and to improve the convergence

speed of centralized learning. Thus, in this section, we optimize the global and local iteration

numbers and mini-batch size for a ﬁxed step size sequence under each of the three step size

rules to minimize the energy cost under the time constraint and convergence error constraint, as

illustrated in Fig. 1.

14If there are more than one performance metrics to be minimized, we minimize the weighted sum of them. If all three
performance metrics have to satisfy ﬁrm requirements, we formulate a feasibility problem with the goal of ﬁnding any variables
that satisfy the corresponding constraints.

15Recall that the parameters of the expected risk function f , i.e., L, σ, G, and a lower bound of f ∗ can be obtained by the
server from pre-training based on the data samples stored on the server; the system parameters, i.e., Fn, pn, rn, sn, n ∈ ¯N , are
known to the server; and in applications with preset step size sequences, Γ has been chosen by the server.

April 5, 2022

DRAFT

14

Original problems

Problem 2 with ! = "
Constant step size rule

Theorem 2

Equivalent
formulations

Problem 3

Problem 2 with ! = #
Exponential step size rule

Theorem 4

Problem 5

Problem 2 with ! = $
Diminishing step size rule

Theorem 6

Problem 7

Algorithms

Problem 4
Approximate GP 
at iteration  

Problem 6
Approximate GP 
at iteration  

Problem 8
Approximate GP 
at iteration  

Theorem 3

Algorithm 2

KKT point of 
Problem 3

Theorem 5

Algorithm 3

KKT point of 
Problem 5

Theorem 7

Algorithm 4

KKT point of 
Problem 7

Fig. 1: Proposed solutions to optimization of algorithm parameters for ﬁxed step size sequences.

A. Problem Formulation

For any ﬁxed Γ satisfying (10), (12), and (15), i.e., for any m

and B to minimize E(K, B) under the constraints in (20) and (21).

C, E, D

}

, we optimize K

∈ {

Problem 2 (Optimization of Global and Local Iteration Numbers and Mini-batch Size for Fixed

Step Size Sequences). For any given m

C, E, D

,

∈ {
min
0,B>0
≻

K

}
E(K, B)

s.t.

(20), (21).

Apparently, the minimum energy cost (i.e., the optimal value of Problem 2) does not increase

(usually decreases) with the limits on the time cost and convergence error, i.e., Tmax and Cmax,

indicating an optimal trade-off among the energy cost, time cost, and convergence error. The

constraints in (20) and (21) are non-convex and contain non-differentiable functions, and the

objective function is non-convex. Thus, Problem 2 with m = C, E, D are challenging non-convex

problems with non-differentiable constraint functions.16 In Sec. V-B, Sec. V-C, and Sec. V-D, we

will develop algorithms for solving Problem 2 with m = C, m = E, and m = D, respectively.

B. Solution to Problem 2 with m = C

To address the challenge caused by the non-differentiable constraint functions in (20) and (21)

with m = C, we equivalently transform Problem 2 with m = C into the following problem with

differentiable constraint functions.

Problem 3 (Equivalent Problem of Problem 2 with m = C). For any given γC ∈

min

0,B,T1,T2>0

K

≻

E(K, B)

0, 1
L

,

(cid:0)

(cid:3)

16The goal of solving a constrained non-convex problem is usually to obtain a KKT point.

April 5, 2022

DRAFT

s.t.

Cn
Fn

KnT −

1
1 ≤

1, n

,

∈ N

KnT −

1, n

1
2 ≤
C0
F0

c1

+ max
n
∈N

(cid:18)(cid:18)

,

+

∈ N
Msn
rn

γCK0

Kn

n

∈N

+ c2γ2

Ms0
r0 (cid:19)
CT 2
2 +

+ BT1

(cid:19)

+

c3γC
B

K0
Tmax ≤
c4γC

1,

n

n

∈N

∈N

P
P

15

(22)

(23)

(24)

qs0,snK 2
n
Kn

≤

Cmax.

(25)

Theorem 2 (Equivalence between Problem 2 with m = C and Problem 3). If (K∗, B∗, T ∗1 , T ∗2 )
is an optimal point of Problem 3, then (K∗, B∗) is an optimal point of Problem 2 with m = C.

P

Proof: By introducing auxiliary variables T1, T2 > 0, replacing maxn

Cn
Fn

∈N

Kn in (20) and

K 2

maxn

n in (21) with m = C with T1 and T 2

2 , respectively, and adding the inequality con-
straints in (22) and (23), we transform Problem 2 with m = C into Problem 3. Suppose that there

∈N

= (K∗, B∗), where K† , (K †n)n
exists (K†, B†)
m = C and E(K†, B†) < E(K∗, B∗). Construct ˆT1 = maxn
K †n.
Obviously, (K†, B†, ˆT1, ˆT2) satisﬁes all constraints of Problem 3 and E(K†, B†) < E(K∗, B∗),
contradicting with the optimality of (K∗, B∗, T ∗1 , T ∗2 ) for Problem 3. Thus, by contradiction, we
can show that (K∗, B∗) is an optimal point of Problem 2 with m = C. Therefore, we can show

, satisfying all constraints of Problem 2 with

K †n and ˆT2 = maxn

Cn
Fn

¯
N

∈N

∈N

∈

Theorem 2.

By Theorem 2, we can solve Problem 3 instead of Problem 2 with m = C. Note that E(K, B)

and the constraint function in (24) are posynomials, the constraint functions in (22) and (23)

are monomials, the ﬁrst term of the constraint function in (25) is a ratio between a constant

and a posynomial, and the last term of the constraint function in (25) is a ratio between two

posynomials. Thus, Problem 3 is a non-convex problem that is more complicated than a CGP.

In the following, using GIA [22] and tricks for solving CGP [23], we propose an iterative

algorithm to obtain a KKT point of Problem 3. The idea is to construct and solve a sequence of

successively reﬁned approximate geometric programs (GPs). Speciﬁcally, at iteration t, update

K(t), B(t)

by solving Problem 4, which is parameterized by K(t
−

1) obtained at iteration t

1.

−

(cid:0)

(cid:1)

Problem 4 (Approximate GP of Problem 3 at Iteration t). For any given γC ∈

min

0,B,T1,T2>0

E(K, B)

(22), (23), (24),

K

≻
s.t.

0, 1
L

,

(cid:0)

(cid:3)

April 5, 2022

DRAFT

6
Algorithm 2 Algorithm for Obtaining a KKT Point of Problem 3

16

1: Initialize: Choose any feasible solution
2: repeat
3:

K(t), B(t), T (t)

Compute
standard convex optimization techniques.
Set t := t + 1.

4:
5: until Some convergence criteria is met.

1 , T (t)

(cid:17)

(cid:16)

2

K(0), B(0), T (0)

1

, T (0)
2

of Problem 3, and set t = 1.

(cid:16)

(cid:17)

by transforming Problem 4 into a GP in convex form and solving it with

c1

+

c2γ2
CT 2
2
Cmax

+

c3γC
CmaxB

+

β(t−1)
n

CmaxγCK0

where β(t
−
n

1)

Kn
β(t−1)
n

n
∈N
(cid:16)
, K (t−1)
n∈N K (t−1)

Q

n

n

(cid:17)
and

P

K(t), B(t), T (t)
(cid:16)

1 , T (t)

2

(cid:17)

c4γC

n

∈N

Cmax

P
n

∈N

qs0,snK 2
n
β(t−1)
n

Kn
β(t−1)
n

1, (26)

≤

denotes an optimal solution of Problem 4.

Q

(cid:16)

(cid:17)

The constraint function in (26), constructed by adopting a commonly used trick in CGP [23,

Lemma1] that is based on the arithmetic-geometric mean inequality, is an approximation of the

constraint function in (25) at K(t
−

1) and is a posynomial. As a result, Problem 4 is a standard

GP and can be readily transformed into a convex problem and solved by using standard convex

optimization techniques such as interior-point methods. In particular, if an interior-point method

is applied, the computational complexity for solving Problem 4 is

(N 3.5) [27]. The details are

O

summarized in Algorithm 2. Following [23, Proposition 3], we have the following result.

Theorem 3 (Convergence of Algorithm 2).

converges to a KKT point of Problem 3, as t

K(t), B(t), T (t)

1 , T (t)

2

obtained by Algorithm 2

(cid:16)
→ ∞

.

(cid:17)

Proof: By the arithmetic-geometric mean inequality, we know that

0, 1T η = 1. Letting Kn = ηnvn and β(t
−
n

1)

n ηnvn ≥
= ηn for all n

P

n vηn
n ,
, we

Q
∈ N

, which indicates that (26) satisﬁes Property (i) in [22].

where v

≻

have

n

∈N

0 and η
Kn ≥

(cid:23)

n

∈N

P
By letting β(t
−
n

1)

β(t−1)
n

Kn
β(t−1)
n

Q

(cid:16)
= K (t−1)
n∈N K (t−1)

n

n

(cid:17)

, we have

K (t
−
n

1)

=

n

∈N

n

∈N

β(t−1)
n

K (t−1)
n
β(t−1)
n

, which indicates

that (26) satisﬁes Property (ii) in [22]. Furthermore, we readily show that (26) satisﬁes Property

P

(iii) in [22] by taking the derivatives of

Kn and

n

∈N

n

∈N

Kn
β(t−1)
n

with respect to

. Besides, as the convex form of Problem 4 (which is a GP) satisﬁes the Slater’s

Kn, n

∈ N

condition [23], Problem 4 has a zero duality gap. Thus, all the conditions for [22, Theorem 1]

P

P

Q

Q

(cid:16)

(cid:16)

β(t−1)
n

(cid:17)

(cid:17)

are satisﬁed. By [22, Theorem 1], Theorem 3 is readily shown.

April 5, 2022

DRAFT

17

C. Solution to Problem 2 with m = E

Compared to Problem 2 with m = C, Problem 2 with m = E has an extra challenge caused

by the products of exponential functions and posynomials. To address the challenge caused by

the non-differentiable constraint functions in (20) and (21) with m = E as well as the extra

challenge, we equivalently transform Problem 2 with m = E into the following problem.

Problem 5 (Equivalent Problem of Problem 2 with m = E). For any given γE ∈
ρE ∈

(0, 1),

0, 1
L

and

(cid:0)

(cid:3)

min

E(K, B)

K

s.t.

0,B,T1,T2,X0>0

≻
(22), (23), (24),

Kn + a3c4

n
∈N
Kn + a3c4X 2
0

(cid:1) P
n
∈N

a1c1 +

a2c2T 2

Cmax + a2c2T 2

(cid:0)

2 + a3c3
2 X 3

0

B + CmaxX0
0 + a3c3X 2
1
ρE

(cid:17) P

B

,

X0K0 ln

(cid:16)
X0 ln

K0 ln

1
X0 ≤
1
ρE ≤

X0 < 1.

ln

1
X0

,

qs0,snK 2
n

qs0,snK 2
n

1,

≤

n

∈N

P
n

∈N

P

(27)

(28)

(29)

(30)

Theorem 4 (Equivalence between Problem 2 with m = E and Problem 5). If (K∗, B∗, T ∗1 , T ∗2 , X ∗0 )
is an optimal point of Problem 5, then (K∗, B∗) is an optimal point of Problem 2 with m = E.

Proof: See Appendix D.

By Theorem 4, we can solve Problem 5 instead of Problem 2 with m = E. As the form of

Problem 5 is similar to that of Problem 3, we propose an iterative algorithm to obtain a KKT

point of Problem 5 using the methods proposed in Sec. V-B. Speciﬁcally, at iteration t, update
2 , X (t)
K(t), B(t), T (t)
(cid:17)
(cid:16)
obtained at iteration t

by solving Problem 6, which is parameterized by

1), T (t
−
2

1), B(t
−

K(t
−

1.

(cid:16)

1)

0

, X (t
−
0

−

1)

(cid:17)

Problem 6 (Approximate GP of Problem 5 at Iteration t). For any given γE ∈
ρE ∈

(0, 1),

0, 1
L

and

(cid:0)

(cid:3)

min

0,B,T1,T2,X0>0

E(K, B)

(22), (23), (30),

K

≻
s.t.

April 5, 2022

DRAFT

Algorithm 3 Algorithm for Obtaining a KKT Point of Problem 5

18

1: Initialize: Choose any feasible solution
2: repeat
3:

Compute
it with standard convex optimization techniques.
Set t := t + 1.

K(t), B(t), T (t)
(cid:16)

2 , X (t)

1 , T (t)

4:
5: until Some convergence criteria is met.

(cid:17)

0

K(0), B(0), T (0)

1

, T (0)
2

, X (0)
0

of Problem 5, and set t = 1.

(cid:16)

(cid:17)

by transforming Problem 6 into a GP in convex form and solving

a1c1 +

(cid:0)

CmaxKn
λ(t−1)
1,n (cid:19)

n
∈N (cid:18)
Q

a2c2T 2
λ(t−1)
1,n

2 + a3c3

B + CmaxX0
λ(t−1)
2,n

n

∈N

Kn + a3c4
λ(t−1)
3,n

(cid:1) P

a3c3X 2
0 Kn
Bλ(t−1)
3,n (cid:19)

(cid:18)
(cid:19)
X0 + X (t
−

0

1)

0 Kn

a2c2T 2

2 X 3
λ(t−1)
2,n

ln

1
X (t−1)
0
(t−1)
0
(t−1)
0

K

K

ln 1
ρE

ln 1
ρE

(cid:18)

+1

K0

(cid:17)

+1

1)

K (t
−
0

ln 1
ρE

+ 1

(cid:16)

(cid:17)

qs0,snK 2
n

n

∈N

P

a3c4qs0,sn X 2

0 K 2
n

λ(t−1)
4,n

(cid:18)

1,

≤

K

(t−1)
0

1
ln 1
ρE

+1

X0

(cid:18)
X0
X (t−1)
0
ln

K (t−1)
0
(cid:16)

ln 1
ρE
K (t−1)
0

+ K0 ln 1
ρE

1
X (t−1)
0

+ 1 ≤

(cid:19)

1,

1,

(31)

λ(t−1)
4,n ≤

(cid:19)

(32)

(33)

where β(t
−
n

1)

, K (t−1)

n

n∈N K (t−1)

n

, λ(t
−
0

1)

,

Cmax + a2c2

2

1)

T (t
−
2

P
+ a3c4

2

1)

X (t
−
0
(cid:16)
K (t−1)
n

3

(cid:17)

(cid:17)
, λ(t
−
3,n

n

∈N
, a3c3

P
1)

qs0,sn

1)

K (t
−
n
(cid:16)
(cid:17)
X (t−1)
K (t−1)
n
0
(cid:16)
B(t−1)λ(t−1)

2

(cid:17)
0

(cid:16)

2

(cid:17)
, λ(t
1)
−
1,n

, λ(t
−
4,n

1)

1)

n

K (t
−
n
∈N
T (t−1)
2
(cid:16)

2

a2c2
P

X (t−1)
0
(cid:17)
(cid:16)
λ(t−1)
0
K(t), B(t), T (t)
(cid:16)

1 , T (t)

2 , X (t)

0

(cid:17)

denotes an optimal solution of Problem 6.

3

+

1)

(cid:17)

X (t
−
0
(cid:16)
, CmaxK (t−1)
n
λ(t−1)
0
, a3c4qs0,sn

a3c3

X (t−1)
0
(cid:16)
B(t−1)

2

(cid:17)

!

1)

,

, λ(t
−
2,n
X (t−1)
0
(cid:16)
(cid:17)
λ(t−1)
0

2

K (t−1)
n

(cid:16)

2

(cid:17)

, and

The constraint functions in (31), (32), and (33), constructed based on the arithmetic-geometric

mean inequality and ﬁrst-order Taylor series expansion, are approximations of the constraint

functions in (27), (28), and (29) at (K(t
−

1), B(t
−

1), T (t
−
2

1)

, X (t
−
0

1)

), respectively, and are posyno-

mials. Consequently, Problem 6 is a standard GP and can be readily transformed into a convex

problem and solved by using standard convex optimization techniques. If an interior-point method

is applied, the computational complexity for solving Problem 6 is

(N 3.5) [27]. The details are

O

summarized in Algorithm 3. Analogously, we have the following result.

Theorem 5 (Convergence of Algorithm 3).

K(t), B(t), T (t)

1 , T (t)

2 , X (t)

0

obtained by Algorithm 3

(cid:16)
converges to a KKT point of Problem 5, as t

.

→ ∞

(cid:17)

Proof: By the ﬁrst-order Taylor series expansion [28], we can show that the approximations

April 5, 2022

DRAFT

 
Algorithm 4 Algorithm for Obtaining a KKT Point of Problem 7

19

1: Initialize: Choose any feasible solution
2: repeat
3:

K(t), B(t), T (t)

Compute
standard convex optimization techniques.
Set t := t + 1.

4:
5: until Some convergence criteria is met.

1 , T (t)

(cid:17)

(cid:16)

2

K(0), B(0), T (0)

1

, T (0)
2

of Problem 7, and set t = 1.

(cid:16)

(cid:17)

by transforming Problem 8 into a GP in convex form and solving it with

of X0 ln 1
X0

in (28) and ln 1
X0

in (29), i.e., (ln 1

ˆX0 −

1)X0 + ˆX0 and

X0
ˆX0

+ ln 1
ˆX0

−

+ 1, satisfy

Properties (i), (ii), and (iii) in [22]. Following the proof of Theorem 3, we can show Theorem 5.

D. Solution to Problem 2 with m = D

Compared to Problem 2 with m = C, Problem 2 with m = D has an extra challenge caused

by the products of logarithmic functions and posynomials. To address the challenge caused by

the non-differentiable constraint functions in (20) and (21) with m = D as well as the extra

challenge, we equivalently transform Problem 2 with m = D into the following problem.

Problem 7 (Equivalent Problem of Problem 2 with m = D). For any given γD ∈
ρD > 0,

0, 1
L

and

(cid:0)

(cid:3)

min

0,B,T1,T2>0

E(K, B)

(22), (23), (24),

K

≻
s.t.

b1c1K0

Kn

n

+b2c2T 2

2 K0+

b3c3K0
B

+

b3c4K0

n

qs0,snK 2
n
Kn

∈N

≤

CmaxK0 ln

K0 + ρD + 1
ρD + 1

(cid:18)

. (34)

(cid:19)

∈N

P

∈N
Theorem 6 (Equivalence between Problem 2 with m = D and Problem 7). If (K∗, B∗, T ∗1 , T ∗2 )
is an optimal point of Problem 7, then (K∗, B∗) is an optimal point of Problem 2 with m = D.

n
P
P

Proof: Following the proof of Theorem 2, we readily show Theorem 6.

By Theorem 6, we can solve Problem 7 instead of Problem 2 with m = D. As the form of

Problem 7 is similar to that of Problem 3, we propose an iterative algorithm to obtain a KKT

point of Problem 7 using the methods proposed in Sec. V-B. Speciﬁcally, at iteration t, update

K(t), B(t)

by solving Problem 8, which is parameterized by K(t
−

1) obtained at iteration t

1.

−

(cid:0)

(cid:1)

April 5, 2022

DRAFT

Problem 8 (Approximate GP of Problem 7 at Iteration t). For any given γD ∈
ρD > 0,

0, 1
L

and

(cid:0)

(cid:3)

20

min

E(K, B)

K

s.t.

0,B,T1,T2>0

≻
(22), (23), (24),

b1c1

Kn
(t−1)
n

(cid:19)

Qn∈N (cid:18)

β

(t−1)
n

β

+ b2c2T 2

2 + b3c3

B +

b3c4

n∈N qs0,sn K 2
n
(t−1)
n

β

P

n∈N (cid:18)

β

Q

Kn
(t−1)
n

(cid:19)

Cmax

ln

K (t−1)
0

+ρD+1

ρD+1

+ K (t−1)
0
K (t−1)
0

+ρD+1

where β(t
−
n

1)

, K (t−1)

n

n∈N K (t−1)

n

P

(cid:18)
, and

(cid:18)
K(t), B(t), T (t)
(cid:16)

(cid:19)
1 , T (t)

2

(cid:17)

+

Cmax

K (t−1)
0
(cid:16)
K (t−1)
0
(cid:16)

K0

+ρD+1

2

(cid:17)

(cid:17)

1,

≤

(35)

(cid:19)

denotes an optimal solution of Problem 8.

The constraint function in (35), constructed based on the arithmetic-geometric mean inequality

and ﬁrst-order Taylor series expansion, is an approximation of the constraint function in (34) at

K(t

−

1) and is a posynomial. Thus, Problem 8 is a standard GP and can be readily transformed into

a convex problem and solved by using standard convex optimization techniques. If an interior-

point method is applied, the computational complexity for solving Problem 8 is

(N 3.5) [27].

O

The details are summarized in Algorithm 4. Analogously, we have the following result.

Theorem 7 (Convergence of Algorithm 4).

converges to a KKT point of Problem 7, as t

K(t), B(t), T (t)

1 , T (t)

2

obtained by Algorithm 4

(cid:16)
→ ∞

.

(cid:17)

Proof: By the ﬁrst-order Taylor series expansion [28], we can show that the approximation

of K0 ln

ˆK0+ρ+1
ρ+1
(ii), and (iii) in [22]. Following the proof of Theorem 3, we can show Theorem 7.

in (34), i.e.,

ˆK0
ˆK0+ρ+1

ˆK0
ˆK0+ρ+1

K0+ρ+1
ρ+1

K0 −

ln

+

(cid:17)

(cid:17)

(cid:16)

(cid:17)

(cid:16)

(cid:16)

2

, satisﬁes Properties (i),

VI. OPTIMIZATION OF ALL ALGORITHM PARAMETERS

The step size sequence of an FL algorithm chosen only for improving the convergence perfor-

mance of centralized learning may not yield satisfactory communication time and communication

energy when implementing it in an edge computing system. To explore the full potential of FL,

in this section, we optimize all the algorithm parameters, including the numbers of global and

local iterations, mini-batch size, and step size sequence, to minimize the energy cost under the

time constraint and convergence error constraint, as illustrated in Fig. 2.

April 5, 2022

DRAFT

21

Original problem

Problem 9

Lemma 4

Theorem 8

Equivalent
formulation

Problem 11

Algorithm
Problem 12
Approximate GP 
at iteration  

Theorem 9 KKT point of 
Problem 11
Algorithm 5

Fig. 2: Proposed solution to optimization of all algorithm parameters.

A. Problem Formulation

We optimize K, B, and Γ to minimize E(K, B) under the constraints in (19), (20), and (21)

with m = A.

Problem 9 (Optimization of All Algorithm Parameters).

K,Γ

min
≻

0,B>0
s.t.

E(K, B)

(19), (20),

CA(K, B, Γ)

Cmax.

≤

(36)

Similar to Problem 2, Problem 9 is a non-convex problem with non-differentiable constraint

functions. Different from most optimization problems, the dimension of Γ, i.e., K0, is a variable,

making Problem 9 very challenging.

B. Solution

In this part, we develop an iterative algorithm to obtain a KKT point of an equivalent problem

of Problem 9. To address the challenge due to the dimension-varying optimization variable Γ,

we ﬁrst consider the minimization of the convergence error with respect to the step size sequence

Γ satisfying (19) with ﬁxed length K0 subject to the following constant:

γ(k0) = S,

(37)

where S

0, K0
L

∈

k0
X
∈K
represents the sum of the elements in Γ.17

0

Problem 10 (Convergence Error Minimization). For any given K

(cid:0)

(cid:3)

S

∈

0, K0
L

,

(cid:0)

(cid:3)

min
Γ

CA(K, B, Γ)

s.t.

(19), (37).

17The range of S, i.e.,

0, K0
(cid:0)

L (cid:3)

, is determined by (19).

ZN +1

+ , B

∈

∈

Z+, and

April 5, 2022

DRAFT

Then, we solve Problem 10.

Lemma 4 (Optimal Step Size Sequence Γ). An optimal solution of Problem 10 is S
K0

1.

22

(

Proof: By Cauchy-Schwartz inequality, we have P
k0∈K0(γ(k0))2
P
S

γ(k0) = P
P
(b) take the equality if and only if γ(k0) = S
K0

k0∈K0(γ(k0))2
k0∈K0

= S2
K0

γ(k0))3

k0∈K0

SK0

and P
P
k0∈K0(γ(k0))2
and P
γ(k0)
k0∈K0
ZN +1
P
+ , B

= S
K0

P

≥

SK0

, where (a) and
for all k0 ∈ K0. Note that the coefﬁcients of the
S is a constant.
1,

γ(k0) = 1
, CA(K, B, Γ) is minimized at S
K0

are positive, and the term
Z+, and S

0, K0
L

k0∈K0

P

1

∈

∈

k0∈K0(γ(k0))3
terms P
γ(k0)
k0∈K0
P
Thus, for any given K

k0∈K0(γ(k0))3
k0∈K0
(b)
(

γ(k0) = P
γ(k0))2

k0∈K0

k0∈K0(γ(k0))3
S

(a)

≥

which satisﬁes all constraints of Problem 10. Therefore, we can show Lemma 4.

∈

(cid:0)

(cid:3)

Lemma 4 indicates that the constant step size rule achieves the minimum convergence error
with ﬁnite iterations. Based on Lemma 4, we replace γ(k0) in (19) and (36) with γ for all k0 ∈ K0
and optimize γ instead. Besides, we adopt the method proposed in Sec. V-B to address the

challenge caused by the non-differentiable constraint functions in (20) and (36). Consequently,

we can equivalently convert Problem 9 into the following problem.

Problem 11 (Equivalent Problem of Problem 9).

min

0,B,γ,T1,T2>0

K

≻

E(K, B)

s.t.

(22), (23), (24),

+ c2γ2T 2

2 +

c4γ

c3γ
B

+

c1

n

γK0

0

P
γ
≤

≤

Kn

∈N
1/L.

n

∈N
n

∈N

P
P

qs0,snK 2
n
Kn

≤

Cmax,

(38)

(39)

Theorem 8 (Equivalence between Problem 9 and Problem 11). If (K∗, B∗, γ∗, T ∗1 , T ∗2 ) is an
optimal point of Problem 11, then (K∗, B∗, γ∗1) is an optimal point of Problem 9.

Proof: See Appendix E.

By Theorem 8, we can solve Problem 11 instead of Problem 9. As the form of Problem 11

is similar to that of Problem 3, we propose an iterative algorithm to obtain a KKT point of

Problem 11 using the methods proposed in Sec. V-B. Speciﬁcally, at iteration t, update

K(t),

B(t), γ(t)

by solving Problem 12, which is parameterized by K(t
−

1) obtained at iteration t
(cid:0)

1.

−

(cid:1)

April 5, 2022

DRAFT

Algorithm 5 Algorithm for Obtaining a KKT Point of Problem 11

23

1: Initialize: Choose any feasible solution
2: repeat
3:

Compute
it with standard convex optimization techniques.
Set t := t + 1.

K(t), γ(t), B(t), T (t)
(cid:16)

1 , T (t)

4:
5: until Some convergence criteria is met.

(cid:17)

2

K(0), γ(0), B(0), T (0)

1

, T (0)
2

of Problem 11, and set t = 1.

(cid:16)

(cid:17)

by transforming Problem 12 into a GP in convex form and solving

Problem 12 (Approximate GP of Problem 11 at Iteration t).

min

0,B,γ,T1,T2>0

E(K, B)

(22), (23), (24), (39),

K

≻
s.t.

c1

+ c2γ2T 2

2 +

β(t−1)
n

c3γ
B

+

c4γ

n

∈N

qs0,snK 2
n
β(t−1)
n

Cmax,

≤

(40)

Kn
β(t−1)
n

γK0

n
∈N
(cid:16)
, K (t−1)
Q
n∈N K (t−1)

n

n

where β(t
−
n

1)

lem 12.

P

(cid:17)
and

K(t), B(t), γ(t), T (t)
(cid:16)

1 , T (t)

2

(cid:17)

P
∈N

n

Kn
β(t−1)
n

Q

denotes an optimal solution of Prob-

(cid:16)

(cid:17)

The constraint function in (40), constructed based on the arithmetic-geometric mean inequality,

is an approximation of the constraint function in (38) at K(t
−

1) and is a posynomial. Conse-

quently, Problem 12 is a standard GP and can be readily transformed into a convex problem

and solved by using standard convex optimization techniques. If an interior-point method is

applied, the computational complexity for solving Problem 12 is

(N 3.5) [27]. The details are

O

summarized in Algorithm 5. Analogously, we have the following result.

Theorem 9 (Convergence of Algorithm 5).

K(t), B(t), γ(t), T (t)

1 , T (t)

2

obtained by Algorithm 5

(cid:16)
converges to a KKT point of Problem 11, as t

.

→ ∞

(cid:17)

Proof: We can show Theorem 9 following the proof of Theorem 3 directly.

VII. NUMERICAL RESULTS

In this section, we evaluate the performances of the proposed optimization-based GenQSGD

for given and optimized step size sequences. We consider a ten-class classiﬁcation problem

with the MNIST dataset (I = 6

104) and partition it into N = 10 subsets, each of which

×

is stored on one worker. We consider a neural network with three layers (i.e., two-layer neural

network), including an input layer composed of 784 cells, a hidden layer composed of 128

April 5, 2022

DRAFT

s
s
o
L

g
n

i

n

i
a
r
T

1.4

1.2

1

0.8

0.6

0.4

0.2

Gen-O
Gen-C
Gen-E
Gen-D

200

400

600

800 1000 1200 1400

Global Iteration

)

%

(

y
c
a
r
u
c
c
A
t
s
e
T

95

90

85

80

75

70

)

%

(

y
c
a
r
u
c
c
A
t
s
e
T

96

94

92

90

88

86

0.2

Gen-O
Gen-C
Gen-E
Gen-D

200

400

600

800 1000 1200 1400

Global Iteration

accuracy (Gen-O)
accuracy (Gen-C)
accuracy (Gen-E)
accuracy (Gen-D)

loss (Gen-O)
loss (Gen-C)
loss (Gen-E)
loss (Gen-D)

24

1

0.9

0.8

0.7

0.6

0.5

0.4

s
s
o
L

g
n

i

n

i
a
r
T

0.21

0.22

0.23

0.24

0.25

Convergence Error Limit Cmax

(a) Training loss.

(b) Test accuracy.

Fig. 3: The training loss and test accuracy of GenQSGD versus global
iterations at Cmax = 0.25 and Tmax = 100000.

Fig. 4: The training loss and test
accuracy of GenQSGD versus Cmax
at Tmax = 100000.

×103

×103

t
s
o
C
y
g
r
e
n
E

13

12

11

10

9

8

7

Gen-O
Gen-C
Gen-E
Gen-D

t
s
o
C
y
g
r
e
n
E

16

15

14

13

12

11

10

Gen-O
Gen-C
Gen-E
Gen-D

0.2

0.21

0.22

0.23

0.24

0.25

5000

6000

Convergence Error Limit Cmax

8000
7000
Time Limit Tmax

9000

10000

(a) Energy cost versus Cmax
Tmax = 10000.

at

(b) Energy cost versus Tmax
Cmax = 0.2.

at

Fig. 5: The energy cost for implementing GenQSGD with the constant, exponential, and diminishing step size
rules versus Cmax and Tmax.

cells, and an output layer composed of 10 cells. We use the sigmoid activation function for

the hidden layer and the softmax activation function for the output layer. We also use the

cross entropy loss function to measure the classiﬁcation performance of the considered neural

network. For the ML problem, we set L = 0.084, σ = 33.18, and G = 33.63, which are

obtained by pre-training. We consider the three step size sequences given by (10), (12), and

(15) under the constant (C), exponential (E), and diminishing (D) step size rules introduced

in Sec. III-B, with the sequence parameters γC = 0.01, γE = 0.02, γD = 0.02, ρE = 0.9995

and ρD = 600. For each step size sequence, we consider PM-SGD with Kn = 1, n
(PM), FedAvg with Kn = l In

[5] (FA), and PR-SGD with B = 1 [6] (PR),

Z+, n

∈ N

[4]

B , l

∈

∈ N

with the remaining algorithm parameters being optimized using the proposed method (opt) and

ﬁxed (ﬁx), respectively. The corresponding baseline FL algorithms are denoted by PM-C/E/D-

opt/ﬁx, FA-C/E/D-opt-ﬁx, and PR-C/E/D-opt-ﬁx, respectively. The proposed optimization-based

GenQSGD under the given three step size sequences are denoted by Gen-C/E/D, and the proposed

optimization-based GenQSGD with optimized step size sequence is denoted by Gen-O. We adopt

April 5, 2022

DRAFT

25

Gen-O

Gen-C

PM-C-opt

FA-C-opt

PR-C-opt

PM-C-fix

FA-C-fix

PR-C-fix

Gen-O

Gen-E

PM-E-opt

FA-E-opt

PR-E-opt

PM-E-fix

FA-E-fix

PR-E-fix

Gen-O

Gen-D

PM-D-opt

FA-D-opt

PR-D-opt

PM-D-fix

FA-D-fix

PR-D-fix

5x104

t
s
o
C
y
g
r
e
n
E

1x104

5x104

t
s
o
C
y
g
r
e
n
E

1x104

5x104

t
s
o
C
y
g
r
e
n
E

1x104

11 12 13 14 15 16

20

24

28

32

11 12 13 14 15 16

20

24

28

32

11 12 13 14 15 16

20

24

28

32

Quantization Parameters log2 s0

Quantization Parameters log2 s0

Quantization Parameters log2 s0

(a) The constant step size rule.

(b) The exponential step size rule.
(c) The diminishing step size rule.
Fig. 6: The energy cost under the constant, exponential, and diminishing step size rules versus log2 s0 at Cmax =
0.25 and Tmax = 100000.

Gen-O

Gen-C

PM-C-opt

FA-C-opt

PR-C-opt

PM-C-fix

FA-C-fix

PR-C-fix

Gen-O

Gen-E

PM-E-opt

FA-E-opt

PR-E-opt

PM-E-fix

FA-E-fix

PR-E-fix

Gen-O

Gen-D

PM-D-opt

PM-D-fix

FA-D-opt

FA-D-fix

PR-D-opt

PR-D-fix

t
s
o
C
y
g
r
e
n
E

5x104

1x104

5x104

t
s
o
C
y
g
r
e
n
E

1x104

5x104

t
s
o
C
y
g
r
e
n
E

1x104

11 12 13 14 15 16

20

24

28

32

11 12 13 14 15 16

20

24

28

32

11 12 13 14 15 16

20

24

28

32

Quantization Parameters log2 sn, n ∈ N

Quantization Parameters log2 sn, n ∈ N

Quantization Parameters log2 sn, n ∈ N

(a) The constant step size rule.

(b) The exponential step size rule.

(c) The diminishing step size rule.

Fig. 7: The energy cost under the constant, exponential, and diminishing step size rules versus log2 sn, n
Cmax = 0.25 and Tmax = 100000.

at

∈ N

the convergence criterion

0.01 for Algorithms 2–5, where

represents

x(t)

k

−

x(t

−

1)

k2 ≤

x(t)

{

}

1, 2, 3, 4, 5

the generated sequence. For simplicity, we divide the set of workers, i.e.,
N1 =
and Fn = F (2), sn = s(2)
s(1)+s(2)
2

= 214, respectively. We use F (1)

6, 7, 8, 9, 10
{
Z+ for all n

N2 =
∈

F (2) and s(1)

and

{

}

, into two classes,
Z+ for all n
∈ N1
109(cycles/s) and

∈

. We set Fn = F (1), sn = s(1)
}
∈ N2 such that F (1)+F (2)
s(2) to characterize the differences in computation
F (2) =
109

= 1

×

2

capabilities and quantization parameters between the two classes of workers. We choose F (1)
10 and s(1)

s(2) = 1, if not speciﬁed otherwise. Besides, we choose αn= 2

, F0 = 3

10−

N

28, n

¯
N
∈
108 (cycles), n

×

×

×
, pn = 1.5

∈ N

(cycles/s), C0=100 (cycles), p0=20 (W), r0 = 7.5

107 (b/s), Cn = 1

×

(W), n

, and rn = 5

106 (b/s), n

∈ N

×

.

∈ N

Fig. 3 plots the training loss and test accuracy of the proposed optimization-based GenQSGD

versus the global iteration index, which shows the convergence performance. From Fig. 3, we

can see that Gen-O converges faster than Gen-C, Gen-E, and Gen-D, indicating the additional

advantage of optimizing the step size sequence. Fig. 4 shows the training loss and test accuracy

of the proposed optimization-based GenQSGD versus the convergence error limit Cmax. Fig. 4

indicates that by imposing the convergence error constraint in (36), we can effectively control the

April 5, 2022

DRAFT

5x104

t
s
o
C
y
g
r
e
n
E

1x104

1

Gen-O

Gen-C

PM-C-opt

FA-C-opt

PR-C-opt

PM-C-fix

FA-C-fix

PR-C-fix

5
Diﬀerence of Computation Capabilities F (1)/F (2)

3

7

5x104

t
s
o
C
y
g
r
e
n
E

1x104

9

1

Gen-O

Gen-E

PM-E-opt

FA-E-opt

PR-E-opt

PM-E-fix

FA-E-fix

PR-E-fix

Gen-O

Gen-D

PM-D-opt

FA-D-opt

PR-D-opt

PM-D-fix

FA-D-fix

PR-D-fix

t
s
o
C
y
g
r
e
n
E

5x104

1x104

9

1

5
Diﬀerence of Computation Capabilities F (1)/F (2)

3

7

5
Diﬀerence of Computation Capabilities F (1)/F (2)

3

7

26

9

(a) The constant step size rule.

(b) The exponential step size rule.

(c) The diminishing step size rule.

Fig. 8: The energy cost under the constant, exponential, and diminishing step size rules versus F (1)/F (2) at
Cmax = 0.25 and Tmax = 100000.

5x104

Gen-O

Gen-C

PM-C-opt

FA-C-opt

PR-C-opt

PM-C-fix

FA-C-fix

PR-C-fix

5x104

Gen-O

Gen-E

PM-E-opt

FA-E-opt

PR-E-opt

PM-E-fix

FA-E-fix

PR-E-fix

Gen-O

Gen-D

PM-D-opt

FA-D-opt

PR-D-opt

PM-D-fix

FA-D-fix

PR-D-fix

t
s
o
C
y
g
r
e
n
E

1x104

1

5
Diﬀerence of Quantization Parameters s(1)/s(2)

3

7

t
s
o
C
y
g
r
e
n
E

1x104

9

1

5
Diﬀerence of Quantization Parameters s(1)/s(2)

3

7

5x104

t
s
o
C
y
g
r
e
n
E

1x104

9

1

5
Diﬀerence of Quantization Parameters s(1)/s(2)

3

7

9

(a) The constant step size rule.

(b) The exponential step size rule.

(c) The diminishing step size rule.

Fig. 9: The energy cost under the constant, exponential, and diminishing step size rules versus s(1)/s(2) at
Cmax = 0.25 and Tmax = 100000.

training loss and test accuracy. Fig. 5(a) and Fig. 5(b) illustrate the energy cost of the proposed

optimization-based GenQSGD versus Cmax and Tmax, respectively. From Fig. 5, we can see

that Gen-O outperforms Gen-C, Gen-E, and Gen-D, indicating the importance of optimally

choosing the step size sequence for implementing GenQSGD. Besides, Fig. 5 indicates that the

proposed optimization framework can achieve a trade-off among the time cost, energy cost, and

convergence error.

Fig. 6 and Fig. 7 illustrate the energy costs of all FL algorithms versus log2 s0 and log2 sn, n
∈
, respectively. From Fig. 6 and Fig. 7, we see that the energy cost decreases with the

N
quantization accuracy when the quantization accuracy is small, since increasing quantization

accuracy can reduce the number of global iterations to achieve a speciﬁc convergence error; and

the energy cost increases with the quantization accuracy when the quantization accuracy is large,

since a higher quantization accuracy leads to a larger number of transmitted bits in each global

iteration. Fig. 8 and Fig. 9 illustrate the energy costs of all FL algorithms versus F (1)/F (2) and

s(1)/s(2), respectively. From Fig. 8 and Fig. 9, we see that the energy costs increase with the

April 5, 2022

DRAFT

27

differences in computation capabilities and quantization parameters between the two classes of

workers. Finally, from Fig. 6–Fig. 9, we can see that for each given step size sequence, the

proposed optimization-based GenQSGD signiﬁcantly outperforms all the baseline FL algorithms

as it allows more algorithm parameters to be optimized; and Gen-O exhibits extra gain over

Gen-C, Gen-E, and Gen-D, which is derived by the proposed optimization framework. These

observations indicate the importances of designing a general FL algorithm and optimally adapting

its algorithm parameters to the underlying edge computing system and ML problem.

VIII. CONCLUSION

This paper studied the optimal design of FL algorithms for solving general ML problems in

practical edge computing systems with quantized message passing. We presented a general FL

algorithm, namely GenQSGD, parameterized by the numbers of global and local iterations, mini-

batch size, and step size sequence, and analyzed its convergence for a general (not necessarily

convex) ML problem. Moreover, we proposed a powerful optimization framework for optimizing

the algorithm parameters or any subset of them to optimally balance among the time cost, energy

cost, and convergence error. Finally, numerical results reveal several important design insights

for FL. Firstly, the derived convergence error of GenQSGD effectively characterizes its training

loss and test accuracy and hence plays a crucial role in the optimal design of FL. Secondly, a

trade-off among the time cost, energy cost, and convergence error can be achieved by properly

choosing the algorithm parameters of FL. Last but not least, the more algorithm parameters can be

optimized, the better trade-off can be archived. Therefore, the proposed optimization framework

for FL design lays the foundation for optimizing the overall performance of federated edge

learning.

APPENDIX A: PROOF OF THEOREM 1

To prove Theorem 1, we ﬁrst show the following three lemmas. For ease of exposition, we

deﬁne Kmax , maxn

∈N

Kn in the following.

Lemma 5. Suppose that Assumption 1 and Assumption 3 are satisﬁed and the step size γ(k0)
0, 1
L
k0 ∈ K0}
(cid:3)
(cid:0)

ZN +1
+
generated by GenQSGD satisfy:

for all k0 ∈ K0. Then, for all K

∈
¯x(k0,Kmax) :

and B

Z+,

and

∈

∈

(cid:8)

ˆx(k0) : k0 ∈ K0
(cid:8)
ˆx(k0+1)

¯x(k0,Kmax)

−

(cid:9)
2

.

(cid:21)

2
(cid:13)
(cid:13)
(cid:13)

E

L
2

+

(cid:17)i

(cid:20)(cid:13)
(cid:13)
(cid:13)

E

f

ˆx(k0+1)

E

f

¯x(k0,Kmax)

h

(cid:16)

≤

(cid:17)i

h

(cid:16)

April 5, 2022

DRAFT

RD, we have:

28

Proof: For all x, y

∈
1
N

f (x)

f (y)

k2

− ∇

k∇

(a)
=

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
Assumption 3. Note that (41) indicates that

(cid:13)
(cid:13)
2
(cid:13)
where (a) follows from (1), (b) follows from the triangle inequality, and (c) follows from
(cid:13)
(cid:13)
f (

) is Lipschitz continuous. Thus, we have:

n∈N
X

n∈N k∇
X

fn(x)

fn(y)

k2

≤

L

x
k

−

y

k2 ,

− ∇

(41)

fn(x)

(

∇

− ∇

fn(y))

(b)

≤

1
N

(c)

f

ˆx(k0+1)

f

¯x(k0,Kmax)

≤

+

f
∇

(cid:16)

(cid:17)
Besides, we have:

(cid:16)

(cid:17)

(cid:16)

(cid:17)

(cid:16)

¯x(k0,Kmax)

T

∇
ˆx(k0+1)

·
¯x(k0,Kmax)

−

ˆx(k0+1)

−

¯x(k0,Kmax)

+

L
2

(cid:13)
(cid:13)
(cid:13)

, k0 ∈ K0.

(42)

2

2
(cid:13)
(cid:13)
(cid:13)

(cid:17)

E

ˆx(k0+1)
h

i

(d)
= ˆx(k0) + E

(f )
= ˆx(k0) +

h

1
N

Q(∆ˆx(k0); s0)
i
x(k0,Kn)

n

n∈N (cid:16)
X

(e)
= ˆx(k0) + E

1
N

"

Q

x(k0,Kn)

n

(g)

n∈N
X
= ¯x(k0,Kmax), k0 ∈ K0,

(cid:16)

ˆx(k0)

−

(cid:17)

ˆx(k0); sn

−

#

(cid:17)

(43)

where (d) is due to (3), (e) is due to (5) and Assumption 1 (i), (f) is due to Assumption 1 (i),
and (g) is due to (6) and (7). By taking expectation of both sides of (42), we have:

ˆx(k0+1)

E

f

h
+

(cid:16)
L
2

E

≤
(cid:17)i
ˆx(k0+1)

E

f

¯x(k0,Kmax)
(cid:16)

2

h
¯x(k0,Kmax)

+ E

(cid:17)i
(h)
= E

(cid:20)
f

f
∇
(cid:16)
¯x(k0,Kmax)

¯x(k0,Kmax)

ˆx(k0+1)
(cid:16)
E

−
ˆx(k0+1)

¯x(k0,Kmax)

(cid:20)(cid:13)
(cid:13)
where (h) is due to (43). Therefore, we can show Lemma 5.
(cid:13)

(cid:20)(cid:13)
(cid:13)
(cid:13)

(cid:17)i

(cid:16)

(cid:21)

h

2
(cid:13)
(cid:13)
(cid:13)

−

(cid:17)(cid:21)
¯x(k0,Kmax)

−

2

(cid:21)

2
(cid:13)
(cid:13)
(cid:13)

, k0 ∈ K0,

T

(cid:17)
+

L
2

Lemma 6. Suppose that Assumptions 2, 3, 4, and 5 are satisﬁed and the step size γ(k0)
for all k0 ∈ K0. Then, for all K
and B
k

generated by GenQSGD satisfy:

ˆx(k0) : k0 ∈ K0
(cid:8)

ZN +1
+

Z+,

∈

∈

∈ Kmax}

and

0, 1
L
∈
¯x(k0,k) : k0 ∈ K0,
(cid:9)
(cid:8)
¯x(k0,k−1)

(cid:0)

2

(cid:3)

E

f

h

¯x(k0,Kmax)
(cid:16)

(cid:17)i

≤

E

f

h

+

ˆx(k0)
(cid:17)i
(cid:16)
2G2L2K 2

−

max

γ(k0)
2

k∈Kmax
X
3
+

γ(k0)
(cid:16)

(cid:17)

E

Nk
N

Lσ2

f
∇

(cid:16)
2

(cid:20)(cid:13)
(cid:13)
γ(k0)
(cid:13)
2N B
(cid:0)

(cid:1)

!

k∈Kmax
X

(cid:21)

2
(cid:17)(cid:13)
(cid:13)
Nk
(cid:13)
N

.

Proof: Assumptions 2, 3, 4, and 5 in this paper indicate that Assumption 1 and Assumption

2 in [6] are satisﬁed. By Assumption 4, we have E

σ2
B , n
proof for (25) in [6], we can show:

, k0 ∈ K0, kn ∈ Kn for all x

∈ N

∈

1
B

≤
∇
RD [29, (5.8)]. Therefore, by slightly extending the

− ∇

(cid:21)

2

ξi∈B

P

(k0,kn)
n

F (x; ξi)

fn (x)

(cid:20)(cid:13)
(cid:13)
(cid:13)

2

(cid:13)
(cid:13)
(cid:13)

E

f

¯x(k0,k)

h

(cid:16)

≤

(cid:17)i

E

f

¯x(k0,k−1)

(cid:16)

(cid:17)i
h
2NkG2L2K 2
max
+
N

γ(k0)Nk
2N
3

γ(k0)

−

E

f
∇
(cid:20)(cid:13)
NkLσ2
(cid:13)
(cid:13)

+

¯x(k0,k−1)

2

(cid:16)

γ(k0)

2

2N 2B
(cid:0)

2
(cid:21)
(cid:17)(cid:13)
(cid:13)
(cid:13)
, k0 ∈ K0, k

(cid:0)

(cid:1)
which relies on Assumptions 1 and 2 in [6], and the constant step size condition. By noting that
¯x(k0,0) = ˆx(k0), k0 ∈ K0 and summing (44) over k
Lemma 7. Suppose Assumption 1 and Assumption 5 are satisﬁed and the step size γ(k0)
for all k0 ∈ K0. Then, for all K
and B

∈ Kmax, we can show Lemma 6.

ZN +1
+

Z+,

and

∈

∈

(cid:3)

(cid:1)

0, 1
L
∈
¯x(k0,k) : k0 ∈ K0,
(cid:8)

(cid:0)

ˆx(k0) : k0 ∈ K0
(cid:8)

(cid:9)

∈ Kmax,

(44)

April 5, 2022

DRAFT

 
k

∈ Kmax}

generated by GenQSGD satisfy:

29

E

ˆx(k0+1)

¯x(k0,Kmax)

−

(cid:20)(cid:13)
(cid:13)
(cid:13)

2G2

γ(k0)
N
(cid:0)

2

(cid:1)

n∈N
X

≤

2

(cid:21)

2
(cid:13)
(cid:13)
(cid:13)

(qsn + qs0 + qs0 qsn )K 2
n.

(45)

Proof: First, we have:
2

Q

x(k0,Kn)

n

ˆx(k0); sn

E

−

(cid:16)

(cid:20)(cid:13)
(cid:13)
(cid:13)

Besides, we have:

(a)

2
(cid:17)(cid:13)
(cid:13)
(cid:13)

≤
(b)

(cid:21)

≤

E

Q

x(k0,Kn)

n

ˆx(k0); sn

(cid:20)(cid:13)
(cid:16)
(cid:13)
(qsn + 1) E
(cid:13)

−
x(k0,Kn)

n

−
(cid:17)
(cid:16)
ˆx(k0)

2

−

2
(cid:21)
(cid:17)(cid:13)
(cid:13)
, k0 ∈ K0,
(cid:13)

(cid:20)(cid:13)
(cid:13)
(cid:13)

, n

∈ N

x(k0,Kn)

n

ˆx(k0)

−

+E

x(k0,Kn)

n

ˆx(k0)

−

2

2

2
(cid:21)
(cid:13)
(cid:13)
(46)
(cid:13)

(cid:20)(cid:13)
(cid:13)
(cid:13)

(cid:21)

2
(cid:13)
(cid:13)
(cid:13)

where (a) is deduced from the deﬁnition of variance, and (b) follows by Assumption 1 (ii).

ˆx(k0); sn

−

2





(cid:17)

(cid:13)
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

Q

x(k0,Kn)

n

ˆx(k0); sn

; s0

−

x(k0,Kn)

n

−

(cid:17)
ˆx(k0); sn

(cid:17)

1
N

! −

n∈N
X

x(k0,Kn)

n

2





(cid:13)
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

(cid:16)

Q

(cid:16)
2

(cid:17)(cid:17)

(cid:13)
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
Q

E

ˆx(k0+1)

¯x(k0,Kmax)

2

(c)
= E

−

1
N

(cid:21)

2
(cid:13)
(cid:13)
(cid:13)
x(k0,Kn)

n

Q

−

n∈N
X

(cid:16)

Q

x(k0,Kn)

n



ˆx(k0) + Q
(cid:13)
(cid:13)
(cid:13)
(cid:13)
ˆx(k0); sn
(cid:13)

; s0



! −

(cid:17)

1
N

n∈N
X
1
N

n∈N
X
ˆx(k0)

ˆx(k0); sn

−

x(k0,Kn)

n

−

−

(cid:17)

(cid:16)

=E

Q

(cid:20)(cid:13)
(cid:13)
(cid:13)
"(cid:13)
(cid:13)
(cid:13)
1
(cid:13)
(cid:13)
N

+

(cid:16)

n∈N (cid:16)
X
1
N

Q

(d)

≤

(e)

≤

(f )

≤
(g)

2E



(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)
+ 2E

E

2qs0

2qs0
N
2qs0
N

1
N

1
N







(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
n∈N
X



Q

x(k0,Kn)

n

n∈N
X

(cid:16)

Q

x(k0,Kn)

n

ˆx(k0); sn

; s0

−

−

(cid:17)

ˆx(k0); sn

(cid:17)
2

n∈N (cid:16)
X

(cid:16)

Q

x(k0,Kn)

n

n∈N
X
Q

(cid:16)
x(k0,Kn)

n

E

ˆx(k0); sn

−

ˆx(k0); sn

−

(cid:13)
(cid:13)
(cid:17)
2
(cid:13)
2
(cid:13)
(cid:13)
2
(cid:21)
(cid:17)(cid:13)
(cid:13)
2
ˆx(k0)
(cid:13)

1
N

E

+2E




+

2
N





(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
n∈N
X




x(k0,Kn)

n

1
N

! −

n∈N
X

(cid:16)

2

x(k0,Kn)

n

ˆx(k0)

−

−

(cid:16)



(cid:17)(cid:17)

(cid:13)
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
x(k0,Kn)
n



Q

n∈N (cid:16)
X
Q

(cid:16)

x(k0,Kn)

n

ˆx(k0); sn

−

−

(cid:17)

x(k0,Kn)

n

(cid:16)

−

ˆx(k0)

ˆx(k0); sn

−

x(k0,Kn)

n

ˆx(k0)

−

−

2

2





(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:17)(cid:17)
2

2

(cid:21)

(cid:17)(cid:13)
(cid:13)
(cid:13)

(cid:20)(cid:13)
(cid:16)
(cid:13)
(qsn +1)E
(cid:13)

≤

(cid:17)
(cid:16)
, k0 ∈ K0,
where (c) follows by (3), (5), (6), and (7), (d) and (f) follow by the inequality

(cid:20)(cid:13)
(cid:13)
(cid:13)
≤
2, (e) follows by Assumption 1 (ii), and (g) is due to Assumption 1 (ii) and (46).

(cid:16)
x(k0,Kn)

i=1 zik

x(k0,Kn)

2
(cid:13)
(cid:13)
(cid:13)

2
(cid:13)
(cid:13)
(cid:13)

(cid:20)(cid:13)
(cid:13)
(cid:13)

n∈N
X

n∈N
X

ˆx(k0)

2
N

(47)

qsn

−

−

+

k

(cid:21)

(cid:21)

n

n

n

2

2

(cid:20)(cid:13)
(cid:13)
E
(cid:13)

P

n
i=1 k

zik
n
By (4) and x(k0,0)

n

P

= ˆx(k0), we have:

E

x(k0,Kn)

n

ˆx(k0)

−

(cid:20)(cid:13)
(cid:13)
(cid:13)

γ(k0)

2

E

(cid:16)

(cid:17)

2

2

≤

(cid:21)

(cid:13)
(cid:13)
(cid:13)





(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

x(k0,k−1)
n

ˆF

∇

(cid:16)

k∈Kn
X

where (h) follows by Assumption 5 and the inequality

i=1 zik
tion 1 (ii), we can substitute (48) into (47) and show Lemma 7.

k

P

P

2

(h)



≤

(cid:13)
(cid:13)
(cid:17)
2
(cid:13)
n
(cid:13)
(cid:13)



2

γ(k0)

(cid:17)

n

(cid:16)
2

≤

nG2, k0 ∈ K0,
K 2
zik

n
i=1 k

2. By Assump-

(48)

By Lemma 5, Lemma 6, and Lemma 7, we have:

E

f

ˆx(k0+1)

h

(cid:16)

(cid:17)i

E

≤

h

+

γ(k0)
2

f

ˆx(k0)

(cid:16)
Lσ2

(cid:17)i
γ(k0)

−
2

E

Nk
N

f
∇

(cid:20)(cid:13)
(cid:13)
LG2
(cid:13)

(cid:16)
γ(k0)

2

¯x(k0,k−1)

2

+

2
(cid:21)
(cid:17)(cid:13)
(cid:13)
n∈N qs0,sn K 2
(cid:13)
n

2G2L2K 2

max

γ(k0)
(cid:16)

3

(cid:17)

, k0 ∈ K0.

(49)

k∈Kmax
X
Nk
N

+

2N B
(cid:0)

(cid:1)

!

k∈Kmax
X

(cid:0)

N
P

(cid:1)

April 5, 2022

DRAFT

 
 
 
 
Then, by (49) and (8), we have:

γ(k0)
2

+

E

Nk
N

k∈Kmax
X
2G2L2K 2

(cid:20)(cid:13)
(cid:13)
(cid:13)
maxγ(k0)

f
∇

¯x(k0,k−1)
(cid:16)

Kn +

2

≤

(cid:21)

2
(cid:17)(cid:13)
(cid:13)
Lσ2
(cid:13)

2N B
P

E

f

ˆx(k0)

E

f

ˆx(k0+1)

−

h

n∈N Kn

(cid:17)i
(cid:16)
+ LG2

h
(cid:16)
qs0,sn K 2
n

(cid:17)i
γ(k0)
N

! (cid:0)
Summing both sides of (50) over k0 ∈ K0, we readily show Theorem 1.

n∈N
X

n∈N
X

APPENDIX B: PROOF OF LEMMA 2

30

2

(cid:1)

, k0 ∈ K0.

(50)

We readily show (13) by substituting

γ(k0)(a)
=

γE(1
1

ρK0
E )
−
ρE
−

,

k0

0

∈K

k0

0

∈K

γ(k0)

2 (b)
=

E(1
γ2
1

ρ2K0
E )
ρ2
E

,

−

−

3 (c)
=

E(1
γ3
1

ρ3K0
E )
ρ3
E

γ(k0)

0

−

k0

∈K

and
k0 ∈ K0. Then, the limit of CE(K, B, Γ) can be easily derived. Note that for any K0 ∈
(cid:0)
P
constant AE ∈
(12) into (9) and by

into (9), where (a), (b), and (c) follow by summing (12) over
Z+ and
. By substituting

), there exists a ρE ∈

(0, 1) such that

< 1, we have:

(cid:1)
(1, +

ρk0
E ≤

P
k0∈K0

AE
K0

k0∈K0

P

P

∞

−

1

1

(cid:1)

(cid:0)

AE
K0

, P
P

k0∈K0

ρ3k0
E
ρk0
E

ρk0
E ≤

k∈K0

P

c1AE

k0∈K0
ρ2k0
E
ρk0
E
c4γE

k0∈K0

+

< 1, and P
P
c3γE
B

n +

K 2

CA(K, B, Γ) <

E max
n∈N
By substituting Γ given by (12) with γC = √N

n∈N Kn

γEK0

P

+ c2γ2

(K0 ¯K)1/4
N 3/4

¯K

≤

into (51), we have CA(K, B, Γ) =

O

L√K0 ¯K

n∈N qs0,sn K 2
n
n∈N Kn

.

and Kn = ¯K, qs0,sn = 1

N ¯K , n

P
P

(51)

with

∈ N

1
2

K −
0

. Therefore, we can show Lemma 2.

APPENDIX C: PROOF OF LEMMA 3

(cid:16)

(cid:17)

K0
1

0

k0

∈K

γ(k0)
(x+ρD)2 dx = ρ2
1
P
Dγ3
(ρD+1)3 + ρ3
D

Dγ3
D
2(ρD +1)2 −

(a)
K0+1
>ρDγD
1
Dγ2
Dγ2
(ρD+1)2 + ρ2
R
D
D
ρD+1 −
Dγ3
ρ3
D

1
x+ρD
Dγ2
ρ2
D
K0+ρD

By summing (15) over k0 ∈ K0, we have

2

2 (b)
<

0

1

k0

ρDγD
ρD+1

K0
1

+ρ2

(cid:16)
Dγ3
D

γ(k0)
3

(c)
P
<
1
(cid:16)
x+ρD

Dγ2
D
(cid:17)
(x+ρD)3 dx = ρ3
(cid:1)
+ ρ3
(k0, k0 + 1] for all k0 ∈ K0, (b) is due to

∈K
ρDγD
(cid:0)
ρD+1
, x
all k0 ∈ K0\{
respectively. Thus, we have CA(K, B, Γ) <

, and (c) is due to

(k0+ρD)3 <

(cid:17)
∈

}

1

R

R

1

1

1

1

P
2(K0+ρD)2 , where (a) is due to
(x+ρD)2 , x
[k0 −
∈
1, k0) for all k0 ∈ K0\{
D γ2
ρ2
D
2(K0+ρD)2 (cid:19)
K0+ρD +1
ρD +1

(k0+ρD)2 <
[k0 −
+

(cid:1)
(cid:0)
1
>
k0+ρD
1, k0) for
,

n∈N Kn

K 2

∈

max

}

1

c2

b2

ln

−

(cid:18)

(cid:16)

(cid:17)

dx = ρDγD ln

K0+ρD+1
ρD+1

,

, and

(cid:16)
∈K

0

k0

(cid:17)
3

γ(k0)

(x+ρD)3 , x

b1c1

K0+ρD +1
ρD +1

ln

(cid:16)

(cid:17) P

< CD(K, B, Γ). Then, the limit for Γ satisfying (14) can

(cid:16)

ln

b3

c4

P

P

ρD γD
K0+ρD
−
K0+ρD+1
ρD +1

c3
B +

n∈N qs0,sn K 2
n
n∈N Kn

(cid:17) (cid:16)

+
be easily derived. Note that for any K0 ∈
ρD ∈
k0∈K0 (cid:16)
k0∈K0

R+ such that

2
ρD
k0+ρD (cid:17)
ρD
k0+ρD

P
< 1, and P
P

ρD
k0+ρD (cid:17)
ρD
k0+ρD

k0∈K0 (cid:16)
k0∈K0

(cid:17)
AD
K0

k0+ρD ≤

k0∈K0

ρD

P

P

1

3

Z+ and constant AD ∈
. By substituting (15) into (9) and

(1, +

∞

), there exists a
AD
,
K0

k0+ρD ≤

ρD

1

k0∈K0

P

< 1, we have:

CA(K, B, Γ) <

D max
n∈N
By substituting Γ given by (15) with γC = √N

n∈N Kn

γDK0

P

+ c2γ2

c1AD

K 2

n +

c3γD
B

+

c4γD

n∈N qs0,sn K 2
n
n∈N Kn

,

and Kn = ¯K, qs0,sn = 1

N ¯K , n

P
P

L√K0 ¯K

(52)

with

∈ N

(K0 ¯K)1/4
N 3/4

¯K

≤

April 5, 2022

into (52), we have CA(K, B, Γ) =

O

1
2

K −
0

. Therefore, we can show Lemma 3.

(cid:16)

(cid:17)

DRAFT

 
31

APPENDIX D: PROOF OF THEOREM 4

First, we construct the following problem.

Problem 13 (Equivalent Problem of Problem 2 with m = E). For any given γE ∈
ρE ∈

(0, 1),

0, 1
L

and

(cid:0)

(cid:3)

min
K≻0,B,T1,T2>0

E(K, B)

s.t.

(22), (23), (24),

a1c1

ρK0
E

n∈N Kn

a2c2

1

(cid:16)

−

+

1

−

ρ3K0
E
(cid:17)
ρK0
E
(cid:17)

−

1

maxn∈N K 2
n

a3

1

+

ρ2K0
E
(cid:17)

−
ρK0
E
(cid:17)

−

(cid:16)
1

c4

+

c3
B

(cid:18)

P

n∈N qs0,sn K 2
n
n∈N Kn

≤

(cid:19)

Cmax.

(53)

(cid:16)
Following the proof of Theorem 2, by contradiction, we can show that (K∗, B∗, T ∗1 , T ∗2 ) is

(cid:17) P

P

(cid:16)

(cid:16)

optimal for Probelm 13, where (K∗, B∗, T ∗1 , T ∗2 ) is from an optimal point of Problem 5.

Then, it remains to show the equivalence between Problem 13 and Problem 2 with m = E.

We introduce an optimization variable X0 ∈
E , and replace
X0 = ρK0
E with the constraints in (28), (29), and (30). Consequently, Problem 13 is equivalent
to Problem 2 with m = E and hence (K∗, B∗) is an optimal point of Problem 2 with m = E.

R+, add the constraint X0 = ρK0

Therefore, we can show Theorem 4.

APPENDIX E: PROOF OF THEOREM 8

First, we construct the following problem.

Problem 14 (Equivalent Problem of Problem 9).

min
K≻0,B,γ>0

E(K, B)

s.t.

(20), (39),

c1
n∈N Kn

γK0

+ c2γ2 max
n∈N

K 2

n +

c4γ

c3γ
B

+

n∈N qs0,sn K 2
n
n∈N Kn

Cmax.

≤

(54)

P
P

Following the proof of Theorem 2, by contradiction, we can show that (K∗, B∗, γ∗) is optimal

P

for Problem 14, where (K∗, B∗, γ∗) is from an optimal point of Problem 9.

Then, it remains to show the equivalence between Problem 14 and Problem 9. Suppose

that there exists

K†, B†, Γ†

= (K∗, B∗, γ∗1) satisfying all constraints of Problem 9 and

E

K†, B†

(cid:0)
in (39). By Lemma 4, CA(K†, B†, ˆγ1)

< E (K∗, B∗). Construct ˆγ = 1TΓ†
(cid:1)
K †
0
CA(K†, B†, Γ†)

(cid:1)

(cid:0)

≤

≤

. As Γ† satisﬁes (19), ˆγ satisﬁes the constraint

Cmax, implying that

K†, B†, ˆγ

satisﬁes all constraints of Problem 14 and E

< E (K∗, B∗), which in turn contradicts
(cid:1)

(cid:0)

K†, B†

(cid:0)

(cid:1)

April 5, 2022

DRAFT

6
32

with the optimality of (K∗, B∗, γ∗) for Problem 14. Thus, by contradiction, we can show that

(K∗, B∗, γ∗1) is optimal for Problem 9. Therefore, we can show Theorem 8.

REFERENCES

[1] Y. Li, Y. Cui, and V. Lau, “Optimization-based GenQSGD for federated edge learning,” in IEEE GLOBECOM, 2021, pp.

1–6.

[2] G. Zhu, D. Liu, Y. Du, C. You, J. Zhang, and K. Huang, “Toward an intelligent edge: Wireless communication meets

machine learning,” IEEE Commun. Mag., vol. 58, no. 1, pp. 19–25, 2020.

[3] Z. Zhou, X. Chen, E. Li, L. Zeng, K. Luo, and J. Zhang, “Edge intelligence: Paving the last mile of artiﬁcial intelligence

with edge computing,” Proc. IEEE, vol. 107, no. 8, pp. 1738–1762, 2019.

[4] O. Dekel, R. Gilad-Bachrach, O. Shamir, and L. Xiao, “Optimal distributed online prediction using mini-batches,” J. Mach.

Learn. Res., vol. 13, p. 165C202, Jan. 2012.

[5] H. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, “Communication-efﬁcient learning of deep

networks from decentralized data,” in Proc. of AISTATS, Apr. 2017, pp. 1273–1282.

[6] H. Yu, S. Yang, and S. Zhu, “Parallel restarted SGD with faster convergence and less communication: demystifying why

model averaging works for deep learning,” in Proc. of AAAI, Jan. 2019, pp. 5693–5700.

[7] Y. Cui, Y. Li, and C. Ye, “Sample-based and feature-based federated learning for unconstrained and constrained

nonconvex optimization via mini-batch SSCA,” IEEE Trans. Signal Process. (major revision), 2021. [Online]. Available:

https://arxiv.org/abs/2104.06011

[8] A. Reisizadeh, A. Mokhtari, H. Hassani, A. Jadbabaie, and R. Pedarsani, “FedPAQ: A communication-efﬁcient federated

learning method with periodic averaging and quantization,” in Proc. of AISTATS, Aug. 2020, pp. 2021–2031.

[9] N. Shlezinger, M. Chen, Y. C. Eldar, H. V. Poor, and S. Cui, “UVeQFed: Universal vector quantization for federated

learning,” IEEE Trans. Signal Process., vol. 69, pp. 500–514, 2021.

[10] S. Wang, T. Tuor, T. Salonidis, K. K. Leung, C. Makaya, T. He, and K. Chan, “Adaptive federated learning in resource

constrained edge computing systems,” IEEE J. Sel. Areas Commun., vol. 37, no. 6, pp. 1205–1221, Jun. 2019.

[11] Z. Yang, M. Chen, W. Saad, C. S. Hong, and M. Shikh-Bahaei, “Energy efﬁcient federated learning over wireless

communication networks,” IEEE Trans. Wireless Commun., vol. 20, no. 3, pp. 1935–1949, 2021.

[12] T. T. Vu, D. T. Ngo, N. H. Tran, H. Q. Ngo, M. N. Dao, and R. H. Middleton, “Cell-free massive mimo for wireless

federated learning,” IEEE Trans. Wireless Commun., vol. 19, no. 10, pp. 6377–6392, 2020.

[13] N. H. Tran, W. Bao, A. Zomaya, M. N. H. Nguyen, and C. S. Hong, “Federated learning over wireless networks:

Optimization model design and analysis,” in Proc. IEEE INFOCOM, 2019, pp. 1387–1395.

[14] M. Chen, Z. Yang, W. Saad, C. Yin, H. V. Poor, and S. Cui, “A joint learning and communications framework for federated

learning over wireless networks,” IEEE Trans. Wireless Commun., vol. 20, no. 1, pp. 269–283, 2021.

[15] Q. Zeng, Y. Du, K. Huang, and K. K. Leung, “Energy-efﬁcient radio resource allocation for federated edge learning,” in

Proc. IEEE ICC Workshops, 2020, pp. 1–6.

[16] J. Yao and N. Ansari, “Enhancing federated learning in fog-aided iot by cpu frequency and wireless power control,” IEEE

Internet Things J., vol. 8, no. 5, pp. 3438–3445, 2021.

[17] M. Chen, H. V. Poor, W. Saad, and S. Cui, “Convergence time minimization of federated learning over wireless networks,”

in IEEE ICC, Jun. 2020, pp. 1–6.

[18] M. Huh, D. Yu, and S.-H. Park, “Signal processing optimization for federated learning over multi-user mimo uplink

channel,” in ICOIN, 2021, pp. 495–498.

April 5, 2022

DRAFT

33

[19] S. Boyd and A. Mutapcic, “Subgradient methods,” lecture notes of EE392o, Stanford University, Autumn, Oct. 2003.

[20] D. Bertsekas, “Nonlinear programming,” Athena Scientiﬁc, vol. 48, Jan. 1995.

[21] X. Li, Z. Zhuang, and F. Orabona, “A second look at exponential and cosine step sizes: Simplicity, adaptivity, and

performance,” in Proc. ICML, vol. 139, 2021, pp. 6553–6564.

[22] B. R. Marks and G. P. Wright, “A general inner approximation algorithm for nonconvex mathematical programs,” Operations

Research, vol. 26, no. 4, pp. 681–683, Aug. 1978.

[23] M. Chiang, C. W. Tan, D. P. Palomar, D. O’neill, and D. Julian, “Power control by geometric programming,” IEEE Trans.

Wireless Commun., vol. 6, no. 7, pp. 2640–2651, Jul. 2007.

[24] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S. Ghemawat, G. Irving, M. Isard, M. Kudlur,

J. Levenberg, R. Monga, S. Moore, D. G. Murray, B. Steiner, P. Tucker, V. Vasudevan, P. Warden, M. Wicke, Y. Yu, and

X. Zheng, “Tensorﬂow: A system for large-scale machine learning,” in Proc. OSDI, 2016, pp. 265–283.

[25] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison,

A. Kopf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S. Chintala, “Pytorch:

An imperative style, high-performance deep learning library,” in Proc. NeurIPS, vol. 32, 2019.

[26] C. You, K. Huang, H. Chae, and B. Kim, “Energy-efﬁcient resource allocation for mobile-edge computation ofﬂoading,”

IEEE Trans. Wireless Commun., vol. 16, no. 3, pp. 1397–1411, 2017.

[27] S. Boyd and L. Vandenberghe, Convex Optimization. Cambridge University Press, 2004.

[28] Y. Sun, P. Babu, and D. P. Palomar, “Majorization-minimization algorithms in signal processing, communications, and

machine learning,” IEEE Trans. Signal Process., vol. 65, no. 3, pp. 794–816, 2017.

[29] L. Bottou, F. E. Curtis, and J. Nocedal, “Optimization methods for large-scale machine learning,” SIAM Review, vol. 60,

no. 2, pp. 223–311, May. 2018.

April 5, 2022

DRAFT

