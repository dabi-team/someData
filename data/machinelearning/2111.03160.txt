Predictive Machine Learning of Objective Boundaries for Solving
COPs

Helge Spieker

Arnaud Gotlieb

Simula Research Laboratory, Oslo, Norway; {helge,arnaud}@simula.no

Abstract

Solving Constraint Optimization Problems (COPs) can be dramatically simpliﬁed by boundary estima-
tion, that is, providing tight boundaries of cost functions. By feeding a supervised Machine Learning (ML)
model with data composed of known boundaries and extracted features of COPs, it is possible to train the
model to estimate boundaries of a new COP instance. In this paper, we ﬁrst give an overview of the existing
body of knowledge on ML for Constraint Programming (CP) which learns from problem instances. Second,
we introduce a boundary estimation framework that is applied as a tool to support a CP solver. Within
this framework, diﬀerent ML models are discussed and evaluated regarding their suitability for boundary
estimation, and countermeasures to avoid unfeasible estimations that avoid the solver to ﬁnd an optimal
solution are shown. Third, we present an experimental study with distinct CP solvers on seven COPs.
Our results show that near-optimal boundaries can be learned for these COPs with only little overhead.
These estimated boundaries reduce the objective domain size by 60-88% and can help the solver to ﬁnd
near-optimal solutions early during search.

1 Introduction

Constraint Optimization Problems (COPs) are commonly solved by systematic tree search, such as branch-
and-bound, where a specialized solver prunes those parts of the search space with worse cost than the current
best solution. In Constraint Programming (CP), these systematic techniques work without prior knowledge and
are steered by the constraint model. However, the worst-case computational cost to fully explore the search
space is exponential and the search performance depends on solver conﬁguration, such as selection of right
parameters, heuristics, and search strategies, as well as appropriate formulations of the constraint problems to
enable eﬃcient pruning of the search space.

Machine Learning (ML) methods, on the other hand, are data-driven and are trained with labeled data
or by interaction with their environment, without explicitly considering the problem structure or any solving
procedure. At the same time, ML methods can only approximate the optimum and are therefore not a full
alternative. The main computational cost of these methods lies in their training, but the cost when estimating
an outcome for a new input is low. This low inference cost makes ML an interesting candidate for integration
with more costly tree search. Previous research has examined this integration to several extents, albeit selecting
the appropriate algorithm within a solver and to conﬁgure it for a given instance, learning additional constraints
to model a problem, or learning partial solutions.

In this paper, we provide an overview of the body of knowledge on using ML for CP. We focus on approaches
where the ML model is trained in a supervised way from existing problem instances with solutions, and collected
information gathered while solving them. We discuss of the characteristics of supervised ML and CP and how
to use predictive ML to improve CP solving procedures. A graphical overview of predictive ML applications for
CP is shown in Figure 1.

1
2
0
2

v
o
N
4

]
I

A
.
s
c
[

1
v
0
6
1
3
0
.
1
1
1
2
:
v
i
X
r
a

1

 
 
 
 
 
 
Figure 1: Overview of the applications of ML and CP considered in this paper. Depending on the application
type, training data can be extracted at diﬀerent points in the CP solving process.

The second part of the paper discusses a boundary estimation method called Bion, which combines logic-
driven constraint optimization and data-driven ML, for solving COPs. A ML-based estimation model predicts
boundaries for the objective variable of a problem instance, which can then be exploited by a CP solver to
prune the search space. To reduce the risk of inaccurate estimations, which can render the COP unsatisﬁable,
the ML model is trained with an asymmetric loss function and adjusted training labels. Setting close bounds
for the objective variable is helpful to prune the search space [54, 34]. However, estimating tight bounds in a
problem- and solver-agnostic way is still an open problem [35]. Such a generic method would allow many COP
instances to be solved more eﬃciently. Our method has ﬁrst been introduced in [67], where an initial analysis of
the results led us to conclude that Bion was a promising approach to solve COPs. Here, we revisit and broaden
the presentation of Bion in the general context of predictive machine learning for constraint optimization. We
extend our experimental evaluation analysis and show that boundary estimation is eﬀective to support COP
solving.

Bion is a two-phase procedure: First, an objective boundary for the problem instance is estimated with a
previously trained ML regression model ; Second, the optimization model is extended by a boundary constraint
on the objective variable and a constraint solver is used to solve the problem instance. This two-phases approach
decouples the boundary estimation from the actual solver and enables its combination with diﬀerent optimized
solvers. Training the estimation model with many problem instances is possible without any domain- or expert-
knowledge and applies to a wide range of problems. Solving practical assignment, planning or scheduling
problems often requires to repeatedly solve the very same COP with diﬀerent inputs. Bion is well ﬁtted for
these problems, where training samples, which resemble realistic scenarios, can be collected from previous
iterations. Besides, for any COP, Bion can be used to pre-train problem-speciﬁc ML models which are then
deployed to solve new instances.

The remainder of this paper is structured as follows. In Section 2, we discuss the necessary background
for the integration of predictive ML and CP, including data curation and preparation of problem instances
to be usable in ML. Section 3 reviews existing work on predictive ML and CP for algorithm selection and
conﬁguration, constraint learning, and learning to solve. Afterwards, we introduce Bion in Section 4, a ML-
based method to estimate boundaries of the objective variable of COPs as a problem- and solver-independent
method tool to support constraint optimization solvers. We discuss training techniques to avoid inaccurate
estimations, compare various ML models such as gradient tree boosting, support vector machine and neural

2

Algorithm Selection &  Configuration (Section 3.1) CP SolverProblem Instance Constraint Model Solution Boundary Estimation (Section 4) Training Data Constraint Learning (Section 3.2) Learning to Solve (Section 3.3) Constraint ProgrammingFeature ExtractionLearning AlgorithmTrained ModelPredictive Machine Learningnetworks, with symmetric and asymmetric loss functions. A technical CP contribution lies in the dedicated
feature selection and user-parameterized label shift, a new method to train these models on COP characteristics.
In Section 5, Bion’s ability to prune objective domains, as well as the impact of the estimated boundaries on
solver performance, is evaluated on seven COPs that were previously used in the MiniZinc challenges to compare
CP solvers eﬃciency. Finally, Section 6 concludes the paper with an outlook on future applications of predictive
ML to CP.

2 Background

This section presents a background discussion on constraint optimization and supervised machine learning.
We introduce the necessary terminology and foundations under the context of predictive ML for CP. For an
in-depth introduction beyond the scope of this paper, we refer the interested reader to the relevant literature
in constraint optimization [62, 51] and machine learning [36, 30, 55].

2.1 Constraint Optimization Problems

Throughout this paper, constraint optimization is considered in the context of Constraint Programming over
Finite Domains [62]. In that respect, every variable x of an optimization problem is associated with a ﬁnite set
of possible values, called a Finite Domain (FD) and, noted Dx. Each value is associated with a unique integer
without any loss of generality and thus, Dx ⊆ x..x, where x (resp. x) denotes the lower (resp. upper) bound
of Dx. Each variable x takes one, yet unknown value in its domain, i.e., x ∈ Dx and x ≤ x ≤ x, even if not all
the values of x..x are necessarily part of Dx.

A constraint is a relation among a subset of the decision variables, which restrain the possible set of tu-
ples of values taken by these variables.
In Constraint Programming over FD, diﬀerent type of constraints
can be considered, including arithmetical, logical, symbolic or global relations. For instance, x + y ∗ z = 5
is an arithmetical constraint while x = f ∨ y = t ∨ (z > 0) = t, where t (resp.
f ) stands for True (resp.
is a logical constraint. Symbolic and global constraints include a large panel of non-ﬁxed length
False),
relations such as all different([x1, . . . , xn]), which constrains each variable xi to take a diﬀerent value,
element([x1, . . . , xn], i, v), which enforces the relation v = xi, where v, i and x1, . . . , xn can all be unknowns.
More details and examples can be found in [62, 51].

Deﬁnition 1 (Constrained Optimization Problem (COP)). A COP is a triple (cid:104)V, C, fz(cid:105) where V denotes a set
of FD variables, called decision variables, C denotes a set of constraints and fz denotes an optimization function
which depends on the variables of V. fz’s value ranges in the domain of the variable z (z in z..z), called the
objective variable.

Solving a COP instance requires ﬁnding a variable assignment, i.e., the assignment of each decision variable
to a unique value from its domain, such that all constraints are satisﬁed and the objective variable z takes an
optimal value. Note that COPs have to be distinguished from well-known Constraint Satisfaction Problems
(CSPs) where the goal is only to ﬁnd satisfying variable assignments, without taking care of the objective
variable.

Deﬁnition 2 (Feasible/Optimal Solutions). Given a COP instance (cid:104)V, C, fz(cid:105), a feasible solution is an assign-
ment of all variables V in their domain, such that all constraints are satisﬁed. zcur denotes the value of objective
variable z for such a feasible solution. An optimal solution is a feasible solution, which optimizes the function
fz to the optimal objective value zopt.

Deﬁnition 3 (Satisﬁable/Unsatisﬁable/Solved COP). A COP instance (cid:104)V, C, fz(cid:105) is satisﬁable (resp. unsatis-
ﬁable) iﬀ it has at least one feasible solution (resp. no solution). A COP is said to be solved if and only if at
least one of its optimal solutions is provided.

3

Solving a COP instance can be done by a typical branch-and-bound search process which incrementally
improves a feasible solution until an optimal solution is found. Roughly speaking, in case of minimization,
branch-and-bound works as follows: starting from an initial feasible solution, it incrementally adds to C the
constraint z < zcur, such that any later found feasible solution has necessarily a smaller objective value than
the current value. This is helpful to cut the search tree of all feasible solutions which have a value equal to
or larger than the current one. If there is no smaller feasible value and all possible variable assignments have
been explored, then the current solution is actually an optimal solution. Interestingly, the search process can
be time-controlled and interrupted at any time. Whenever the search process is interrupted before completion,
it returns zcur as the best feasible solution found so far by the search process, i.e., a near-optimal solution. This
solution is provided with neither proof of optimality nor guarantee of proximity to an optimal solution, but it
is still suﬃcient in many applications.

This branch-and-bound search process is fully implemented in many Constraint Programming (CP) solvers.
These solvers provide a wide range of features and heuristics to tune the search process for speciﬁc optimization
problems. At the same time, they do not reuse any of the already-solved instances of a constraint problem to
improve the optimization process for a new instance. In addition to presenting existing works on predictive
learning for constraint optimization, this paper proposes a new method to reuse existing known boundaries to
nurture a machine learning model to improve the optimization process for a new instance.

2.2 Supervised Machine Learning

At the core of the predictive applications described in this paper, a supervised ML model is trained and deployed.
In supervised machine learning, the model is trained from labeled input/output examples to approximate the
underlying, usually unknown function.

Deﬁnition 4 (Supervised Machine Learning). Given a set of training examples {(x1, y1), (x2, y2), . . . , (xn, yn)},
a supervised machine learning model approximates a function P : X → Y , with X being the input space, and Y
being the output space. Here, xi is a vector of instance features and yi is the corresponding label, representing
the target value to be predicted.

Every value in x corresponds to a feature, that is, a problem instance characteristic that describes the input
to the model. In most cases, the input consists of multiple features and is also described as the feature vector.
The output of the model, ˆy, is deﬁned as a vector, too, although it is more common to have a model that only
predicts a single value. This is the case in regression problems, when predicting a continuous value, or binary
classiﬁcation, when deciding whether to activate a functionality or not.

The model P is trained from a training set, consisting of example instances (xi, yi). Training the model
describes the process to minimize the error between estimated value ˆy and true (observed) value y of the training
examples. The error is assessed with a loss function, that can be diﬀerent depending on the task of the machine
learning model. We show examples for two commonly used types of loss functions. For regression problems,
where a continuous output value is estimated, the loss is assessed via the mean squared error. In classiﬁcation,
where the input is assigned to one of multiple classes, the cross-entropy loss is calculated.

Deﬁnition 5 (Mean Squared Error (MSE)). Given a set of N estimated and observed target values {(ˆy1, y1), (ˆy2, y2), . . . , (ˆyN , yN )},
the MSE is calculated as:

L =

1
N

N
(cid:88)

i=1

(ˆyi − yi)2

Within the calculation of MSE, positive and negative errors have the same eﬀect, but larger errors are

stronger penalized, i.e. they have a larger inﬂuence, than smaller errors.

4

y

Training sample (x, y)
Estimation (x, ˆy)
Estimation error ˆy − y

x

Figure 2: Training a supervised machine learning model: Illustrative example for linear regression y = a0 +a1 ∗x.
During training the weights a0, a1 are adjusted to minimize the estimation error.

Deﬁnition 6 (Cross-Entropy Loss). Given a set of N estimates and K classes, the cross-entropy (also log-
likelihood) is calculated as:

L = −

1
N

N
(cid:88)

K
(cid:88)

i=1

k=1

yik log ˆyik

with ˆyik being the probability of xi belonging to class k and

(cid:40)

yik =

if xi belongs to class k

1
0 otherwise

An example for the training scheme is shown in Figure 2 for a linear regression model. The weights a0, a1
of the linear function are adjusted such that the total error between estimated and true values is minimized.
In the given example the training examples do not strictly follow a linear trend and are therefore diﬃcult to
approximate with only a small error. This is an indicator to use a more complex model for better results and
to describe the output via diﬀerent features than only x, if possible.

2.3 Machine Learning Models

Many supervised ML models exist and have been shown to be applicable to a wide range of problems. However,
there is no one best model and depending on the application, diﬀerent models can show good performance.

In this section, we introduce ﬁve widely used machine learning models for the application in predictive ML
for CP: Gradient Tree Boosting, Neural Network, Support Vector Machine, k-Nearest Neighbors, and Linear
Regression. We brieﬂy discuss each model and highlight relevant characteristics for applying them for constraint
problems.

2.3.1 Gradient Tree Boosting

Gradient Tree Boosting (GTB), also Gradient Boosting Machine, is an ensemble method where multiple indi-
vidual weak models, whose error rate slightly outperforms random guessing, are combined into a strong learner
[31]. At each iteration, additional weak models are trained on a modiﬁed subset of data to add information to
the previous prediction. The individual weak models in GTB are decision trees, which by themselves have weak
estimation accuracy compared to other models, but are robust to handle diﬀerent types of inputs and features
[36, Ch. 10].

5

2.3.2 Neural Network

A multi-layer Neural Network (NN) approximates the function to-be-learned over multiple layers of nodes or
neurons. Neural networks can be applied for diﬀerent problems, e.g. classiﬁcation or regression, especially when
there is a large amount of training data. Designing a neural network requires selecting an architecture and the
number of layers and nodes, as well as performing a careful hyper-parameter optimization to achieve accurate
results [30].

An ensemble of multiple NNs can be formed to reduce the generalization error of a single NN [75], by taking
the average of all predictions. As errors are expected to be randomly distributed around the actual value, an
ensemble can reduce the error.

2.3.3 Support Vector Machine

Support Vector Machines (SVM) map their inputs into a high-dimensional feature space. This feature space is
deﬁned by a kernel function, which is a central component. Once the data has been mapped, linear regression is
performed in this high-dimensional space [27]. One common variant for regression problems are (cid:15)-SVR, which
are usually trained using a soft margin loss [66]. Under soft margin loss an error is penalized only if it is larger
than a parameter (cid:15), otherwise it is similar to a squared error function. Having the additional margin of allowed
errors avoids minimal adjustments during training and allows for higher robustness of the ﬁnal model.

2.3.4 Nearest Neighbors

Nearest neighbors methods, also k-Nearest Neighbors (kNN) or neighbors, relate an unseen instance to the
closest samples, i.e. the nearest neighbors, in the training set [45]. The distance between points is calculated
from a distance metric, which is often the euclidean distance. In case of k-nearest neighbors, the number of
neighbors to consider is ﬁxed to k, which is usually a small integer value. Other methods set the number of
neighbors dynamically from the data density in the training set and a threshold for the maximum distance. For
regression problems, the estimated value y is calculated by a weighted average over the neighbors’ values. The
weights are either uniform or proportional to the distance.

Nearest neighbor methods have the advantage to be simple and non-parameterized, i.e. they do not require
a training phase, but the complete training is necessary to process new instances. Because searching through
all training samples for each estimation is ineﬃcient for a large training set, tree-based data structures can be
used to organize the data for faster access, for example, K-D trees [17] or Ball trees [58].

2.3.5 Linear Regression

Linear regression (LR) is a simple statistical approach to ﬁnd a linear relationship between a set of input
features and the target value. Applying linear regression is eﬀective in scenarios where a linear relationship can
be assumed. In other scenarios, LR is less accurate than the other introduced methods. However, because it is
easy to train and apply, LR is commonly used as a baseline method to identify and justify the need for more
complex, non-linear methods in ML applications.

The model is formed by the linear relationships between each of the n features and the target value, the
dependent variable y. This relationship is captured by the parameter ai for each feature xi: y = a0 + a1x1 +
a2x2 + · · · + anxn. Linear regression is trained via the ordinary least squares method [36, Ch. 3], an iterative
method to minimize the squared error between estimated and true target.

2.4 Data Curation

Machine learning methods are data-driven and need a data corpus to be trained, before they can be used to
make estimations on new instances. In this section, we discuss the collection of a data corpus, its organization
for training the model, and the pre-processing to transform the data into a format that is usable as model input.

6

2.4.1 Collection

A suﬃcient amount of training data is the basis to train a supervised ML model. Data for CSPs and COPs,
that is, problem instances, can either be downloaded from open repositories for existing constraint problems,
collected from historical data, or synthetically generated.

For many problems, constraint models and instances can be freely accessed from online repositories. The CSP
library (CSPLib) [41] contains a large collection of constraint models, instances, and their results in diﬀerent
modeling languages. Furthermore, problem-speciﬁc libraries exist, such as TSPLib [60] for the traveling sales
person problem and related problems, or ASLib [21] for algorithm selection benchmarks. Finally, there are
repositories of constraint models and instances in language-speciﬁc repositories, for example in MiniZinc1 or
XCSP3.2

Having a generator allows us to create a large training corpus for a particular problem, but as it also requires
additional eﬀort to develop the generator program. This solution might not be suitable in all cases. Another
approach is to generate instances directly from the constraint model [33]. The constraint model is reformulated
by deﬁning the given instance parameters as variables to be found by the solver. Solving this reformulation
with random value assignment then leads to a satisﬁable problem instance of the original constraint model.

However, for all generators, the diﬀerence between generated instances, that are distributed over the whole
possible instance space, and realistic instances, that might only occupy a small niche of the possible instance
space, has to be considered by either adjusting the generator to create realistic instances or to ensure the training
and test set include realistic instances from other sources.

2.4.2 Data Organization

Data used to build a ML model is split into three parts: a) the training set, b) the development (dev) or validation
set, and c) the test set. The training set is used to train the model via a learning algorithm, whereas the dev
set is only used to control the parameters of the learning algorithm. The test set is not used during training or
to adjust any parameters, but only serves to evaluate the performance of the trained model. Especially the test
set should be similar to those instances that are most likely to be encountered in practical applications.

The training set holds the largest part of the data, ranging from 50-80% of the data, while the rest of the
data is equally divided between validation and test set. This is a rough estimate and the exact split is dependent
on the total size of the data set. In any case, it should be ensured the validation and test set are suﬃciently
large to evaluate the trained model.

2.4.3 Representation

The representation refers to the format into which a problem instance is transformed before it can be used as
ML input. An expressive representation is crucial for the design of a ML model with high inﬂuence on its later
performance. Representation consists of feature selection and data preparation, which are introduced in the
following.

Feature Selection Feature selection deﬁnes which information is available for the model to make predictions
and if insuﬃcient or the wrong information is present, it is not possible to learn an accurate prediction model,
independent of the selected machine learning technique. A good feature selection contains all features which are
necessary to calculate the output and captures relations between instance data and the quantity to estimate.

As a long-term vision, it is desirable to learn a model end-to-end, that is from the raw COP formulation
and instance parameters, without having to extract handcrafted features. Currently, most machine learning
techniques work with ﬁxed, numerical input and output vectors. There are machine learning techniques capable
to handle variable-length inputs and outputs, for example, recurrent neural networks like LSTM [37], but these

1Online at: https://github.com/MiniZinc/minizinc-benchmarks
2Online at: http://www.xcsp.org/

7

have, to the best of our knowledge, not yet been successfully applied in the area of predictive ML for CP and
will not be further discussed here. Instead we focus on the common case to handcraft a ﬁxed-size feature vector.
For the selection of features, we ﬁrst need to consider the application of the machine learning model. Is
it a problem-speciﬁc application, that handles only instances of one deﬁned optimization problem, or is it a
problem-independent application, that handles instances of many diﬀerent optimization problems?

In COP-speciﬁc applications, domain knowledge can be exploited. For example, when building a predictive
model for the travelling sales person (TSP) problem [40], features describing the spatial distribution of the cities
and the total area size are valuable [65]. Similarly, the constrained vehicle routing problem (CVRP) has been
investigated to identify problem-speciﬁc features that are beneﬁcial to reason over solution quality [12] or aid
the search process [11, 2, 48].

Without domain knowledge, more generic features have to be used to capture the characteristics and variance
of diﬀerent constraint models and their instances. One approach is the design of portfolio solvers, where a
learning model is used to decide which solver to run for a given problem instance [74, 57, 50, 64, 7, 8]. Feature
extraction exploits the structure of the general constraint model and the speciﬁc instance, its constraints,
variables and their domains. Features are further categorized as static features, which are constant for one
model and instance, and dynamic features, which change during search and are therefore especially relevant
for algorithm conﬁguration and selection tasks. As a representative explanation, Table 1 shows an overview
of features to describe problem instances. While many of these features are constant for multiple instances of
the same constraint problem, e.g. the number of constants or which constraints were deﬁned, the variables and
their domains depend on the instance parameters and can oﬀer descriptive information that discriminate several
instances of the same problem.

Several studies have been performed to analyze the ability of these generic features to characterize and
discriminate COP characteristics [61, 39, 5, 21]. Their main conclusion is that a small number of features can
be suﬃcient discriminators, but that there is no single set of best features for all constraint problems used in
their experiments. An approach to overcome this issue is therefore to start with a larger set of features than
practically necessary and, perform dimensionality reduction (see the next Section for a detailed explanation) to
remove features with little descriptive information.

Data Preparation Once the features are selected and retrieved, the next step is to pre-process the data,
such that it can be used by the machine learning model, by performing dimensionality reduction and scaling.

A dimensionality reduction step can shrink the size of the feature vector. Reducing the dimensionality, which
means having less model inputs, can thereby also reduce the model complexity. Features that are constant for
all instances are removed, as well as features that only show minimal variance below a given threshold. Other
dimensionality reduction techniques, e.g. principal component analysis (PCA), apply statistical procedures to
reduce the data to a lower-dimensional representation while preserving its variance. These reduction techniques
can further reduce the number of features, but at the downside that it is no longer possible to directly interpret
the meaning of each feature.

Feature scaling is necessary for many models and means to transform the values of each feature, which might
in diﬀerent ranges, into one common range. Scaled features reduce model complexity as it is not necessary
to have the weights of a model account for diﬀerent input ranges. One common technique is to scale the
feature by subtracting its mean and dividing by the standard deviation, which transforms the features to
approximately resemble a normal distribution with zero mean and unit variance. Another technique is called
minmax-normalization and scales the feature based on the smallest and largest occurring values, such that all
values scaled into the range [−1, 1].

Note that it is important to keep track of how each preparation step is performed on the training set, as
it has to be repeated in the same way on each new instance during testing and production. This means the
feature vector of a new instance contains the same features and each feature is scaled by the same parameters,
e.g. it is scaled by the training set’s mean and standard deviation.

8

Table 1: Examples for static COP features from the feature extractor mzn2feat [4], which analyses COPs
formulated in the MiniZinc constraint modeling language [56]. The descriptions are quoted from [4]. NV:
Number of variables, NC: Number of constraints, CV: variation coeﬃcient, H: entropy of a set of values

Category

Variables

Domains

Constraints

Features

The number of variables N V ; the number cv of constants; the number av of aliases; the ratio
av+cv
N V ; the ratio N V
N C ; the number of deﬁned variables (i.e. deﬁned as a function of other
variables); the number of introduced variables (i.e. auxiliary variables introduced during the
FlatZinc conversion); sum, min, max, avg, CV, and H of the: variables domain size, variables
degree, domain size to degree ratio
The number of: boolean variables bv and the ratio bv
integer variables iv and the ratio iv
and the ratio av
N C ; int constraints ic and the ratio ic
ﬂoat constraints f c and the ratio f c
N C ;
The total number of constraints N C, the ratio N C
N V , the number of constraints with FlatZinc
annotations; the logarithm of the product of the: constraints domain (product of the domain
size of each variable in that constraint) and constraints degree; sum, min, max, avg, CV, and
H of the: constraints domain, constraints degree, domain to degree ratio

N V ; ﬂoat variables f v and the ratio f v
N V ;
N V ; array constraints ac
N C ;

N V ; boolean constraints bc and the ratio bc

N C ; set constraints sc and the ratio sc

N V ; set variables sv and the ratio sv

Global Constraints The total number gc of global constraints, the ratio gc

N C and the number of global constraints

Graphs

Solving

Objective

for each one of the 27 equivalence classes in which we have grouped the 47 global constraints
From the Constraint Graph CG and the Variable Graph V G we compute min, max, avg, CV,
and H of the: CG nodes degree, CG nodes clustering coeﬃcient, V G nodes degree, V G nodes
diameter
The number of labeled variables (i.e. the variables to be assigned); the solve goal; the number
of search annotations; the number of variable choice heuristics; the number of value choice
heuristics
The domain dom, the degree deg, the ratios dom
N C of the variable v that has to be
optimized; the degree de of v in the variable graph, its diameter di, de
de . Moreover, named
µdom and σdom the mean and the standard deviation of the variables domain size and µdeg
and σdeg the mean and the standard deviation of the variables degree, we compute dom
,
µdom
dom−µdom
σdom

, and deg−µdeg

deg and deg

, deg
µdeg

di , di

σdeg

9

Figure 3: The inductive constraint programming loop (adapted from [20]). The CP and ML components can
interact with each other and react upon inﬂuences from the external world and observations.

3 Predictive Machine Learning for Constraint Optimization

Opportunities for integration of predictive ML in constraint programming are vast and relevant in several
research directions [16]. We ﬁrst look at general categorizations and approaches to the combination of predictive
ML and CP, before we discuss the body of knowledge in specialized research areas.

A recent work by Bessiere et al. introduces a general framework for the integration of ML and CP, called
the inductive constraint programming loop (ICP) [20]. The framework is based on four main building blocks:
a CP component, a ML component, which can be controlled, as well as an external world, that cannot be
controlled, and which produces observations. All these building blocks are interconnected and can receive and
the CP component receives new constraint problems via
provide information from and to each other, e.g.
a World-to-CP relation and returns solutions via a corresponding Apply-to-World relation. An overview of
the ICP framework and all deﬁned relations is shown in Figure 3. The majority of predictive machine learning
applications for CP can be embedded into the ICP framework, as they exploit the ML-to-CP relation, where the
ML model transfers information to the component, which is their main purpose. Furthermore, these applications
also exploit the opposite CP-to-ML relation to return feedback from the solver, e.g. runtimes, found solutions,
to the ML model for improvement.

Lombardi et al. present a general framework for embedding ML-trained models in optimization techniques,
called empirical model learning [46]. The approach deploys trained ML models directly in the COP as additional
global constraints. Experimental results show, that the embedded empirical ML model can improve the total
solving process. The proposed integration further leads to easier deployment of the trained ML model and to
reduce the complexity of the setup, but, at the same time, the complexity of the model itself is increased as
compared to the pure COP.

3.1 Algorithm Selection and Conﬁguration

The area of algorithm selection and conﬁguration applies predictive ML to analyze individual problem instances
and decide for the most appropriate solver, its heuristic, or the setting of certain tuning parameters of a solver.

10

Apply­to­WorldCP­to­MLCP ComponentWorld World­to­MLWorld­to­CP Observations  ML­to­CP ML ComponentProduces All these techniques have in common, that they work on a knowledge base that is mostly not restricted to a single
constraint optimization problem, but applicable to instances from many diﬀerent problems. Furthermore, these
approaches aﬀect changes onto the solver, but do not modify or adjust the constraint problem or the problem
instance.

Algorithm selection within a constraint solver can be used to decide, which search strategy to use. A search
strategy consists of a variable selection, that is which variable will next have a value assigned, and a value
selection, that is which value is assigned to the variable. Arbelaez and Sebag propose a classiﬁcation model to
select from up to 8 diﬀerent heuristics, consisting of both variable and value selection [9]. The search strategy is
repeatedly selected during search, e.g. upon backtracking, to be able to adapt to characteristics of the problem
instance in diﬀerent regions of the search space. The machine learning model uses a SVM (Support Vector
Machine, see Section 2.2) and a set of 57 features to describe an instance.

In [10], this work is extended to a life-long learning constraint solver, whose inner machine learning model is
repeatedly re-trained based on newly encountered problem instances and the experiences from selected search
heuristics. The methodology is reﬁned to select a heuristic for a predeﬁned checkpoint window, i.e. a heuristic
is ﬁxed for a sequence of decisions, before the next heuristic is selected. In total 95 features, describing static
features, such as the problem deﬁnition, and variable and constraint information, and dynamic features to
monitor the search performance.

Similarly, Gent et al. classify problem instances to decide whether solving them beneﬁts from lazy learning,
an eﬀective but costly CSP search method [32]. They analyze the primal graph of the instance to extract
instance features. The primal graph represents every variable as a node, and variables that occur in the scope of
a constraint are connected via edges. Using this graph structure allows to extract features like the edge density,
graph width, or the proportion of constraints that share the same variable.

Chu and Stuckey investigate methods to learn a value selection heuristic [25]. As part of their work, they
Ideally, one would require exactly solved
discuss the problem of gathering samples to train the ML model.
instances, but in practice this incurs high computational cost for every training instance. Their approach is to
deﬁne an alternative scoring function to be used as the training target. This scoring function is chosen such that
it does not require exact solving of the instance and therefore gathering the training data is cheaper overall.

Besides supervised ML techniques, adaptive ML methods, such as reinforcement learning, are also applied
in large neighborhood search [49] or to select tree

to conﬁgure search algorithms and their parameters, e.g.
search heuristics [47].

Reliable information about expected runtimes for an algorithm on a problem instance can be helpful not only
for algorithm selection and conﬁguration, but further for selecting hard benchmark instances, that distinguish
diﬀerent algorithms and to analyze hardness properties of problem classes [40]. Hutter et al. propose empiricial
performance models (EPM) for runtime prediction. These EPMs use a set of generic and problem-speciﬁc
features to model the runtime characteristics. Another study on runtime prediction for TSP has been published
in [53], where the authors deﬁne a set of 47 TSP-speciﬁc features to asses instance hardness and algorithm
performance. For a comprehensive overview on literature in runtime prediction, we refer the interested reader
to [40].

The previously discussed work considered algorithm conﬁguration and selection within one solver to optimize
its performance. As mentioned earlier, other approaches are focused towards combining multiple distinct solvers
into a portfolio solver [8]. Using machine learning and heuristics, the planning component of the portfolio solver
determines the execution schedule of the solver [50, 64]. In case of parallel portfolio solvers, a subset of solvers
is run in parallel until a solution is found or, if the optimal solution is wanted, can exchange information about
intermediate solutions found during search, e.g. sharing the best found objective bound [6]. Popular portfolio
solvers include SATZilla [74], CPHydra [57], Sunny-CP [3], or HaifaCSP [72].

11

3.2 Constraint Learning

During the last decade, considerable progress has been made in the ﬁeld of automatic constraint learning.
Starting from a dataset of solutions and non-solutions examples, several approaches have been proposed to
extract constraint models ﬁtting the data. Pioneering this question, the ICON European project3 explored
diﬀerent approaches to this problem. It is worth noticing that these approaches to learn in CP are diﬀerent
from the previously described usages of predictive ML to CP, as, unlike statistical ML, the learning model
is based on logic-driven approaches which extracts an exact model from examples. Nevertheless, constraint
learning approaches can be used to deﬁne predictive models to support other constraint models too, and are
therefore included here as well.

In [13, 14], Beldiceanu and Simonis have proposed ModelSeeker, an approach that returns the best candi-
date global constraint representing a pattern occurring in a set of positive examples. Following initial research
ideas published in [18], Bessiere et al. subsequently developed Constraint Acquisition as a strong inductive
constraint learning framework [19, 70, 71]. Starting from sequences of integers representing solution and non-
solutions, constraint acquisition progressively reﬁnes a admissible and maximal model which accommodates
In [43, 44], Lallouet and Legtchenko had already proposed a constraint
all positive and negative examples.
acquisition method based on inductive logic programming where both positive and negative examples can be
handled, but the method captured the constraint network structure using some input background knowledge.
Constraint Acquisition is independent of any background knowledge and just requires a bias, namely a sub-
set of a constraint language, to be given as input. Interestingly, these constraint learning approaches are all
derived from initial ideas developed in Inductive Logic Programming (ILP) [29]. The framework developed in
this paper does not originate from ILP and does not try to infer a full CSP or Constraint Optimization model
from sequences of positive and negative examples. Instead, it learns from existing solved instances to acquire
suggested boundaries for the optimization variables. In that respect, it can complement Constraint Acquisition
methods by exploiting solved instances and not only solutions and non-solutions.

3.3 Learning to Solve

Applications and research on predictive ML for CP are sometimes classiﬁed as learning to solve, putting an
emphasis on the ML component and its contribution to CP. These terminology is especially present in research
that focuses on learning to solve optimization problems without the need for an additional solver [73, 15, 28,
42, 22]. Connected to the development of deep learning techniques, these approaches are able to solve small
instances of constraint problems, but are not competitive to the capabilities of state-of-the-art constraint solvers.
A recent survey on the usage of reinforcement learning for combinatorial optimization can be found in [52].

4 Estimating Objective Boundaries

In this part of the paper, we present one application of predictive machine learning for constraint optimization,
namely Bion, a novel boundary estimation technique. Boundary estimation supports the constraint solver by
adding additional boundaries on the objective of a problem instance. The objective boundaries are estimated
via a machine learning model, that has been trained on previously solved problem instances. Through the
additional constraints, the search space of the constraint problem is pruned, which again allows to ﬁnd good
solutions early during search.

In general, exact solvers already include heuristics to ﬁnd feasible initial solutions that can be used for
bounding the search [38]. For example, some CP and MIP solvers use LP relaxations of the problem to ﬁnd
boundary. Other CP solvers rely on good branching heuristics and constraint propagation to ﬁnd close bounds
early [62]. These approaches are central to the modus operandi of the solvers and crucial for their performance.
Boundary estimation via predictive ML runs an additional bounding step before executing the solver and uses

3http://www.icon-fet.eu

12

a ML-based heuristic, that is learned from historical data to already bound the objective and search space of
the COP instance.

With boundary estimation, a diﬀerent approach to COP solving is taken. The CP solver exploits the
constraint structure of a COP and considers only the current instance. In contrast, we train the ML model,
which we refer to as the estimator, on the structure of instance parameters and the actual objective value from
example instances. Thus it only indirectly infers the model constraints, but it is not explicitly made aware of
them. Our approach combines data- and logic-driven approaches to solve COPs and beneﬁts from the estimation
provided by the data-driven prediction and also the optimal solution computed by the logic-driven COP solver.
In principle, Bion boosts the solving process by reducing the search space with estimated tight boundaries on
the optimal objective.

We now introduce the concept of estimated boundaries, which refers to providing close lower and upper

bounds for the optimal value zopt of fz.
Deﬁnition 7 (Estimation). An estimation is a domain ˆz..ˆz which deﬁnes boundaries for the domain of fz.
The domain boundaries are predicted by a supervised ML model P : Rn → R2, that is, (cid:104)ˆz, ˆz(cid:105) = P (x).

Deﬁnition 8 (Admissible/Inadmissible Estimations). An estimation ˆz..ˆz is admissible iﬀ zopt ∈ ˆz..ˆz. Other-
wise, the estimation is said to be inadmissible.

We further classify the two domain boundaries as cutting and limiting boundaries in relation to their eﬀect
on the solver’s search process. Depending on whether the COP is a minimization or maximization problem,
these terms refer to diﬀerent domain boundaries.

Deﬁnition 9 (Cutting Boundary). The cutting boundary is the domain boundary that reduces the number
of reachable solutions. For minimization, this is the upper domain boundary z; for maximization, the lower
domain boundary z.

Deﬁnition 10 (Limiting Boundary). The limiting boundary is the domain boundary that does not reduce the
number of reachable solutions, but only reduces the search space to be explored. For minimization, this is the
lower domain boundary z; for maximization, the upper domain boundary z.

For the sake of simplicity, in the rest of the paper, we focus exclusively on minimization problems, however,

Bion is similarly applicable to maximization problems.

4.1 Optimization with Boundary Constraints

We ﬁrst present the full process to solve a COP with Bion, which receives as inputs both an optimization
model, describing the problem in terms of the variables V and constraints C, and its instance parameters which
include data structure sizes, boundaries and constraints parameters. The COP is the same for all instances,
only the parameters given as a separate input can change. The process of solving COPs with an already trained
estimator is shown as a pseudocode formulation in Algorithm 1. For simplicity of the formulation, we represent
the static COP and the instance parameters merged into one triple (cid:104)V, C, fz(cid:105).

Boundary estimation adds a preprocessing step to COP solving, as well as a rule for handling unsatisﬁable
instances. During preprocessing, the current problem instance is analyzed and the trained estimator estimates
a boundary on the objective value of this speciﬁc instance. To provide the estimated boundary, instance-speciﬁc
features are extracted from the COP model and its instance parameters. These features serve as the input of
the estimator, which returns the estimated boundary value.

Afterwards, Bion adds the boundary value as an additional constraint on the objective variable to the opti-
mization model. The extended, now instance-speciﬁc model and the unmodiﬁed instance parameters are then
given to the solver. If the solver returns a solution, the process ends, as the problem is solved. However, if the
approximated objective value is too low, i.e. the estimation is inadmissible, it can render the problem unsatis-
ﬁable. In this case, Bion restarts the solver with the inverted boundary constraint, such that the estimation is

13

Algorithm 1 Pseudocode formulation for the COP solving process with Bion
1: function SolveWithBion(COP Instance (cid:104)V, C, fz(cid:105), Estimator P , Solver S)
2:
3:
4:
5:

x ← preprocess((cid:104)V, C, fz(cid:105))
(cid:104)ˆz, ˆz(cid:105) ← P (x)
C(cid:48) ← C ∪ {z ∈ [ˆz, ˆz]}
Result ← solve((cid:104)V, C(cid:48), fz(cid:105))
if Result = Unsatisﬁable then

(cid:46) Extract feature vector x from COP instance
(cid:46) Predict objective boundary
(cid:46) Update COP with boundary constraint
(cid:46) Solve updated COP with CP solver

C(cid:48)(cid:48) ← C ∪ {z /∈ [ˆz, ˆz]}
Result ← solve((cid:104)V, C(cid:48)(cid:48), fz(cid:105))

6:
7:
8:
9:
10:
11: end function

end if
return Result, x, z

(cid:46) Update COP with negated boundary constraint
(cid:46) Solve updated COP with CP solver

(cid:46) Return solver result; include x and z for future model training

a lower bound on z. If the COP is now satisﬁable, the estimation was inadmissible. Otherwise, unsatisﬁability
is due to other reasons. When the COP is solved, both the input and the objective value are stored for future
training of the estimator.

4.2 Feature Selection

Each COP consists of constraints, variables, and their domains. To use these components as estimator inputs,
it is necessary to extract and transform features, which describe a problem and its data in a meaningful way. As
we discussed, a good set of features captures relations between instance data and the quantity to estimate, i.e.,
the objective value. Furthermore, the features are dynamic in terms of the individual variability of an instance,
but static in the number of features, that is, each instance of one problem is represented by the same features.
Among the various types of variable structures one can ﬁnd in COPs, non-ﬁxed data structures such as arrays,
lists or sets, are the main contributors of variability and of major relevance for feature selection. For each of
these data structures, 9 common metrics from the main categories of descriptive statistics are calculated to
gather an abstract, but comprehensive description of the contained data: (1) the number of elements, including
the (2) minimum and (3) maximum values. The central tendency of the data is described by both (4) arithmetic
mean and (5) median, the dispersion by the (6) standard deviation and (7) interquartile range. Finally, (8)
skewness and (9) kurtosis describe the shape of the data distribution. Scalar variables are each added as features
with their value.

The constraints of a model are ﬁxed for all instances, but due to diﬀerent data inputs, the inferred ﬁnal models
for each problem instance diﬀer. To capture information about the variables generated during compilation and
model-speciﬁc, we use 95 features as implemented in the current version of mzn2feat [4], which are listed in
Table 2. Several of these features have the same value for all instances as they capture static properties of
the COP, but some add useful information for diﬀerent instances, which supports the learning performance.
Nevertheless, preliminary experiments showed that including the non-static features of the constraint model
improves estimation accuracy.

In general, all features can have varying relevance to express the data, depending on the model and the
necessary input. However, as Bion is designed to be problem-independent, the same features are at ﬁrst
calculated for all problems. During the data preprocessing phase of the model training, all features with zero
variance, that is, the same value for all instances, are removed to reduce the model complexity. Each feature is
further standardized by subtracting the mean and dividing by the standard deviation.

14

Symmetric Loss (Squared Error)
Asymmetric Loss (a = -0.8)

s
s
o
L

Residual

Figure 4: Quadratic symmetric and asymmetric loss functions. The asymmetric loss assigns a higher loss to a
negative residuals, but lower loss to overestimations, than the symmetric squared error loss.

4.3 Avoiding Inadmissible Estimations

One main risk, when automatically adding constraints to a COP, is to render the problem unsatisﬁable. In
the case of boundary estimation, an inadmissible estimation below the optimum value prohibits the solver from
ﬁnding any feasible solution. Even though this is often detected early by the solver, there is no guarantee and
thus it is necessary to tame this issue. To mitigate the risk, three counter-measures are considered in the design
of Bion.

First, during COP solving with Bion, unsatisﬁable instances provide information about the problem and
allow us to restart the solver with an inverted boundary constraint, such that an upper bound becomes a
lower bound; Second, training the estimator with an asymmetric loss function penalizes errors on the side of
inadmissible underestimates stronger than admissible overestimates, and thereby discourages misestimations;
Third, besides exploiting the training error, the estimator is explicitly trained to overestimate. This requires
adjusting the training label from the actual optimal objective value towards an overestimation.

4.3.1 Symmetric vs. Asymmetric Loss

Common loss functions used for training ML models, such as MSE, are symmetric and do not diﬀerentiate
between positive or negative errors. An asymmetric loss function, on the other hand, assigns higher loss values
for either under- or overestimations, which means that certain errors are more penalized than others. Figure 4
shows an example of quadratic symmetric and asymmetric loss functions.

Shifted Squared Error Loss is an imbalanced variant of squared error loss. The parameter a shifts the
penalization towards under- or overestimation and inﬂuences the magnitude of the penalty. Formally speaking,

Deﬁnition 11 (Shifted Squared Error Loss).

L(r) = r2 · (sgn(r) + a)2 with absolute error r = ˆy − y

where ˆy is the estimated value and y is the true target value, and a is a parameter which shifts the penalization
towards under- or overestimation.

In Section 5, we compare the usage of both symmetric and asymmetric loss functions plus label shift to

evaluate the importance of adjusting model training to the problem instances.

4.3.2 Label Shift

Boundary estimation only approximates the objective function of the COP, which means there is no requirement
on the convergence towards a truly optimum solution. Said otherwise, Bion can accept estimation errors after
training. This allows Bion to work with fewer training examples than what could be expected with a desired
exact training method. This is appropriate here, as collecting labeled data requires solving many COPs instances
ﬁrst, which can be very costly.

15

However, there is a risk that the trained model underestimates (in case of minimization) the actual objective
value. Such an inadmissible estimation, as deﬁned above, leads to an unsatisﬁable constraint system and
prohibits the COP solver from ﬁnding any feasible solution. On the other hand, a too loose, but admissible
overestimation may not suﬃciently approximate the actual optimum. To address this risk, we introduce label
shift in Bion, which adjusts the training procedure with one user-controlled parameter. Label shift is similar to
the concept of prediction shift described in [69], but based on the speciﬁc COP model.

Deﬁnition 12 (Label Shift).

y(cid:48) = y + λ (z − y)
y(cid:48) = y − λ (y − z)

(Overestimation)

(Underestimation)

where z is the upper bound of the objective domain, y is the optimal objective value of the training instance,
and y(cid:48) is the adjusted label for training the estimator, as the result of the label shift adjustment. Label shift
depends on λ, which is an adjustment factor to shift the target value y between the domain boundary and the
actual optimum. The trade-oﬀ between a close and admissible estimation and an inadmissible estimation is
thus controlled by the value of λ.

4.4 Estimated Boundaries during Search

Using Bion to solve a COP consists of the following steps:

1. (Initially) Train an estimator model for the COP

2. Extract a feature vector from each COP instance

3. Estimate both a lower and an upper objective boundaries

4. Update the COP with estimated boundaries

5. Solve the updated COP with the solver

The boundaries provided by the estimator can be embedded as hard constraints on the objective variable, i.e.,
by adding z ∈ ˆz . . . ˆz. The induced overhead is negligible, but dealing with misestimations requires additional
control. If all feasible solutions are excluded, because the cutting bound is wrongly estimated, the instance is
rendered unsatisﬁable. This issue is handled by reverting to the original domain.

If only optimal solutions are excluded, because the limiting bound is wrongly estimated, then only non-
optimal solutions can be returned and this stays impossible to notice. This issue cannot be detected in a single
optimization run of the solver. However, in practical cases where the goal is to ﬁnd good-enough solutions early
rather than ﬁnding truly-proven optima, it can be an acceptable risk to come-up with an good approximation
of the optimal solutions only.

Conclusively, hard boundary constraints are especially suited for cases where a high conﬁdence in the quality

of the estimator has been gained, and the occurrence of inadmissible estimations is unlikely.

5 Experiments

We experimentally evaluate our method Bion in three experiments, which focus on the impact of label shift and
asymmetric loss functions for training the estimator, on the estimators’ performance to bound the objective
domain, and on the impact of estimated boundaries on solver performance.

16

Table 2: Overview of benchmark problems. All considered problems are minimization problems with a large
variety in the number of available training instances.

Problem

MRCPSP
RCPSP
Bin Packing
Cutting Stock
Jobshop
VRP
Open Stacks

5.1 Setup

Objective

Max-Max
Leq-Max
Sum
Sum
Leq-Max
Sum
Max-Max

Search

Model-Speciﬁc
Model-Speciﬁc
Solver-Default
Solver-Default
Solver-Default
Model-Speciﬁc
Model-Speciﬁc

Instances

11182
2904
500
121
74
74
50

5.1.1 Constraint Optimization Problems

We selected seven problems, that were previously used in MiniZinc challenges [68] to evaluate CP solvers.
These problems are those with the largest number of instances in the MiniZinc benchmarks,4 ranging from 50
to multiple thousands. In practice, it is more likely to only have few examples instances available, therefore we
also include problems with few training examples. These COPs, which are all minimization problems, are listed
in Table 2 along with the type of objective function, whether they contain a custom search strategy, and the
number of available instances. Considering training sets of diﬀerent sizes, from 50 to over 11,000 instances, is
relevant to understand scenarios that can beneﬁt from boundary estimation. The column Objective describes
the objective function type, which is related to the solver’s ability to eﬃciently propagate domain boundaries.
The COPs have two main groups of objective functions. One group minimizes the sum, the other minimizes
the maximum of a list of variables. For the models minimizing the maximum, two formulations are present in
our evaluation models. Max-Max uses the MiniZinc built-in max (z = max(V )), whereas Leq-Max constraints
the objective to be greater-or-equal all variables (∀ v ∈ V : v ≤ z). Both formulations are decomposed into
diﬀerent FlatZinc constraints, which can have an impact on the ability to propagate constraints.

5.1.2 Training Settings

We implement Bion in Python using scikit-learn [59]. Exceptions are NNs, where Keras [24] and TensorFlow
[1] are used, and GTB, where XGBoost [23] is used, both to support custom loss functions. mzn2feat [4] is used
for COP feature extraction. In our comparison, we consider asymmetric (GTBa, NNa) and symmetric versions
(GTBs, NNs) of GTB and NN, and symmetric versions of SVM and linear regression.

The performed experiments are targeted towards evaluating the general eﬀectiveness of boundary estimation
over a range of diﬀerent problems. Therefore, we used the default parameters of each ML model as provided by
the chosen frameworks as much as possible. As loss factors for the asymmetric loss functions, we set a = −1 for
GTBa and a = −0.8 for NNa, where a smaller a caused problems during training. The model parameters were
not adjusted for individual problems. Parameter tuning is also often not performed in a practical application,
although it potentially allows to improve the performance for some problems. For Bin Packing, we introduced
a trivial upper boundary as there was originally no ﬁnite boundary in the model.

5.2 Boundary Estimation Performance

We evaluate the capability to learn close and admissible objective boundaries, that prune the objective variable’s
domain. To this end, we focus on 1) the impact of label shift and asymmetric loss functions for training the

4Accessible at https://github.com/MiniZinc/minizinc-benchmarks/

17

estimator, 2) the estimators’ performance to bound the objective domain, and 3) the impact of estimated
boundaries on solver performance.

Estimation performance is measured through repeated 10-fold validation. In each repetition, the instances
are randomly split into ten folds. Nine of these folds form the training set, the other the validation set. The
model is trained 10 times, one time with each fold as validation set. We repeat this process 30 times, to account
for stochastic eﬀects, and report median values.

Training times for the models are dependent on the number of training samples available. We trained on
commodity hardware without GPU acceleration. In general, training takes less than ﬁve seconds per model,
except for MRCPSP with up to 30 seconds. Another exception are the neural networks which take on average
1 minute to train and maximum 6 minutes for MRCPSP.

5.2.1 Adjustment Factors for Label Shift

To avoid inadmissible estimations, we introduced the label shift method. Label shift trains the estimator not on
the exact objective value, but adjusts the label of the training samples according to a conﬁguration parameter
λ.

We evaluate the eﬀect of the adjustment factor (λ ∈ {0, 0.1, 0.2, . . . , 1.0}) on the quality of estimations. The
results are shown in Figure 5, both the ratio of admissible estimations and the ratio of instances for which the
domain is pruned. Here, we do not distinguish the diﬀerent benchmark problems, but aggregate the results as
they show similar behavior for the diﬀerent problems.

)

%

(

e
l
b

i
s
s
i

m
d
A

100

75

50

25

0

LR
GTBs

GTBa
NNa

SVM
NNs

0.0 0.05 0.1 0.15 0.2 0.25 0.3 0.4 0.5 0.6 0.8
Adjustment Factor λ

Figure 5: Admissible estimations in relation to adjustment factor λ. Label shift increases admissible estimations
for both symmetric and asymmetric models.

The results conﬁrm that choosing λ is a trade-oﬀ, where a larger value increases admissible estimations, but
reduces pruning. Furthermore, the diﬀerence between symmetric and asymmetric loss is visible. Without label
shift, the symmetric models have close to 50% admissible estimations, which is expected as the symmetric error
is equally distributed between inadmissible underestimations and admissible overestimations. The asymmetric
models achieve 88/92% (GTBa/NNa) admissible estimations without label shift, but with an increased λ the
performance further improves. For GTBs and NNs, the largest ratio of domain pruning is achieved with an
adjustment factors of 0.4 and 0.3, whereas for the asymmetric versions λ = 0.2 is the best value. The best
adjustment for the linear model is 0.6, and 0.4 for SVM. The asymmetric estimators already overestimate the
actual objective value and therefore only need a small λ.

In conclusion, applying label shift is beneﬁcial to increase the number of admissible estimations and to
control the eﬀectiveness of boundary estimation. When choosing λ for a diﬀerent setting, a reasonable value is
λ ∈ [0.1, 0.5], it is therefore recommendable to start with a low λ and increase only, if the number of admissible
estimations is insuﬃcient.

18

5.3 Estimation Performance

We analyze here the capability of each model to estimate tight domain boundaries, as compared to the original
domains of the COP. As evaluation metrics, the size of the estimated domain is compared to the original
domain size. Furthermore, the distance between cutting boundary and optimal objective value is compared
between the estimated and original domain. A closer gap between cutting bound and objective value leads to a
relatively better ﬁrst solution when using the estimations and is therefore of practical interest. Table 3 shows
the estimation performance per problem and estimator. The results show that asymmetric models are able to
estimate closer boundaries than symmetric models. For each model, the estimation performance is consistent
over all problems.

Table 3: Reduction in objective domain through estimated boundaries (in %). Gap: Domain size between
cutting boundary and optimum ((1 − (|ˆz − zopt|/|z − zopt|)) ∗ 100). Size: Ratio between new and initial domain
size ((1 − (|ˆz − ˆz|/|z − z|)) ∗ 100). Cells show the median and the median absolute deviation (MAD): No
superscript indicator ≤ 5 ≤ + ≤ 10 < ∗ ≤ 20 < ∗∗ ≤ 30 < ∗∗∗.

GTBa

Gap

68
64*
69
64
64*
65
70

Size

65
66
69
61
60+
64
70

GTBs

Gap

Size

60
58*
60
60
59*
60
60

58
59
60
59
53
60
60

LR

NNa

NNs

SVM

Gap

48
48*
50
49
43**
50
50

Size

Gap

48
49
50
49
43
50
50

78*
41***
87
80
56**
80+
89

Size

68*
71+
81
76
33*
76+
88

Gap

Size

Gap

Size

50
48*
50
49
47*
50
50

48
49
48
49
42+
50
50

15
29*
19
13
15+
13
0

18
17
20
19
15
20
0

Bin Packing
Cutting Stock
Jobshop
MRCPSP
Open Stacks
RCPSP
VRP

First, we look at the share of admissible estimations. Most models achieve 100 % admissible estimations in
all problems. Exceptions exist for Cutting Stock (GTBa, GTBs, LR: 91 %, SVM: 50 %) and RCPSP (NNs,
SVM: 83 %, all other models: ≥ 98%). In general, NNa has the highest number of admissible estimations,
followed by GTBa. The largest reduction is achieved by NNa, making it the overall best performing model.
GTBa is also capable to consistently reduce the domain size by over 60 %, but not as much as NNa. Cutting
Stock and Open Stacks are diﬃcult problems for most models, as indicated by the deviations in the results.
LR and NNs reduce the domain size by approximately 50 %, when the label shift adjustment factor λ is 0.5, as
selected in the previous experiment.

Conclusively, these results show that Bion has an excellent ability to derive general estimation models from
the extracted instance features. The estimators reduce substantially the domains and provide tight boundaries.

5.4 Eﬀect on Solver Performance

Our ﬁnal experiment investigates the eﬀect of objective boundaries on the actual solver performance, as de-
scribed in Section 4.4. This includes both estimated boundaries as well as ﬁxed boundaries calculated from the
known best solution and the ﬁrst solution found by the solver without boundary constraints. The goal for this
combination of estimated and ﬁxed boundaries is to understand how helpful objective boundaries actually are
and also how well boundary estimation provides useful boundaries. By setting the ﬁxed boundary in relation
to the ﬁrst found solution, we enforce an actual, non-trivial reduction in the solution space for the solver.

The setup for the experiments is as follows. For each COP, 30 instances are randomly selected. Each instance

is solved using four distinct conﬁgurations, namely

1. the unmodiﬁed model without boundary constraints;

19

2. the estimations from NNa as upper and lower boundary constraints;

3. the estimations from NNa, only as an upper boundary constraint;

4. a ﬁxed upper boundary of the middle between the optimum and the ﬁrst found solution when using no

boundary constraints (zf irst): z = zopt + (cid:98)(zf irst − zopt)/2(cid:99).

We selected three distinct solvers with diﬀerent solving paradigms and features: Chuﬀed (as distributed with
MiniZinc 2.1.7) [26], Gecode 6.0.1 [63], and Google OR-Tools 6.8. These solvers represent state-of-the-art
implementations, as shown by their high rankings in the MiniZinc challenges. All runs are performed with a 4
hour timeout on a single CPU core of an Intel E5-2670 with 2.6 GHz.

Three metrics are used for evaluation (all in %), each comparing a run with some boundary constraint to
the unmodiﬁed run. The Equivalent Solution Time compares the time it takes the unmodiﬁed run to reach
a solution of similar or better quality than the ﬁrst found solution when using boundary constraints.
It is
calculated as (tOriginal − tBounds)/tOriginal ∗ 100. The Quality of First compares the quality of the ﬁrst found
solutions with and without boundary constraints and is calculated as (1 − zBounds/zOriginal) ∗ 100. The Time
to Completion, ﬁnally, relates the times until the search is completed and the optimal solution is found. It is
calculated in the same fashion as the Equivalent Solution Time.

The results are shown in Table 4, listed per solver and problem. We do not list the results for the Cutting
Stock problem for Chuﬀed and OR-Tools, because none of the conﬁgurations, including the unmodiﬁed run,
found a solution for more than one instance. Gecode found at least one solution for 26 of 30 instances, but none
completed, and we include the results for the 26 instances. For all other problems and instances all solvers and
conﬁgurations found at least one solution.

We obtain mixed results for the diﬀerent solvers and problems, which indicates that the capability to
eﬀectively use objective boundaries is both problem- and solver-speciﬁc, and that deploying tighter constraints
on the objective domain is not beneﬁcial in every setting. This holds true both for the boundaries determined by
boundary estimation (columns Upper and Both) and the ﬁxed boundary, which is known to reduce the solution
space in relation to the otherwise ﬁrst found solution when using no boundary constraints. The general intuition,
and also conﬁrmed by the literature, is that in many cases a reduced solution space allows more eﬃcient search
and for several of the COPs, this is conﬁrmed. An interpretation for why the boundary constraints in some
cases hinder eﬀective search, compared to the unbounded case, is that the solvers can apply diﬀerent techniques
for domain pruning or search once an initial solution is found. However, when the solution space is strongly
reduced ﬁnding this initial solution is diﬃcult as the right part of the search tree is only discovered late in the
process.

The best results are obtained for solving Jobshop with Chuﬀed, where the constraints improve both the time
to ﬁnd a good initial solution and the time until the search is completed. Whether both an upper and lower
boundary constraint can be useful is visible for the combination of Gecode and RCPSP. Here, posting only the
upper boundary is not beneﬁcial for the Equivalent Solution Time, but with both upper and lower boundary
Gecode is 14 % faster than without any boundaries. Chuﬀed has a similar behaviour for RCPSP regarding
Time to Completion, where the upper boundary alone has no eﬀect, but posting both bounds reduces the total
solving time by 4 %.

At the same time, we observe that posting both upper and lower boundaries, even though they reduce the
original domain boundaries, do not always help to improve the solver performance. Two examples are the
combination of Chuﬀed and Jobshop or OR-Tools with Open Stacks. In both cases does the lower boundary
constraints reduce the performance compared to the behaviour with only the upper boundary, here in terms of
Time to Completion.

In addition to the speciﬁc solver implementations, a reasons for the eﬀectiveness of objective boundaries the
actual ability of the COP model to propagate the posted boundary constraints seems relevant. However, when
considering the relation between the COPs objective function formulations (see Table 2) and eﬀectiveness of
boundary constraints, we do not observe a strong link in our results, that would clearly explain the measured
results.

20

Table 4: Eﬀect of boundaries on solver performance (in %). Fixed : Upper boundary set to middle between
optimum and ﬁrst found solution of unbounded run. Upper : Upper boundary set to estimated boundary. Both:
Upper and lower boundary set to estimated boundaries. Results are averaged over 30 instances, lower values
are better.

Equiv. Solution Time

Fixed

Upper

Bin Packing
Jobshop
MRCPSP
Open Stacks
RCPSP
VRP

Bin Packing
Cutting Stock
Jobshop
MRCPSP
Open Stacks
RCPSP
VRP

Bin Packing
Jobshop
MRCPSP
Open Stacks
RCPSP
VRP

-9.4
-96.5
0.0
-1.3
-3.2
0.4

53.5
5627.0
189.3
0.0
0.0
-17.2
0.0

-22.7
1.1
-3.2
-5.0
0.0
-95.3

36.1
-96.4
0.0
-1.3
197.4
0.0

0.3
7.3
-6.4
0.0
-1.5
56.8
0.0

35.0
0.0
-3.0
-2.6
147.2
0.0

Both

13.0
-96.6
0.0
-0.9
25.3
0.0

-0.6
-29.5
37.4
23.6
0.0
-14.4
0.0

39.2
0.0
45.3
-3.1
30.4
0.0

Quality of First

Fixed

Upper

-57.7
-60.0
-0.4
-13.2
0.0
0.0

0.0
-5.5
6.1
-0.4
-12.8
0.0
0.0

-57.0
-0.8
-0.4
-13.2
0.0
0.0

-37.9
-38.1
-10.8
-24.0
-3.3
-23.5

(a) Chuﬀed

-4.7
-8.5
-10.9
-10.8
-24.0
-2.8
-21.0

(b) Gecode

-37.4
-16.5
-10.8
-24.0
-3.3
-38.2

(c) OR-Tools

Both

-57.7
-60.0
0.0
-13.2
0.0
0.0

0.0
-2.6
6.1
-0.2
-12.8
0.0
0.0

-57.2
-0.8
0.0
-13.2
0.0
0.0

Time to Completion

Fixed

36.1
-27.6
1.2
2.0
-4.2
2.0

-10.3
–
0.0
1.3
8.9
-11.8
-19.0

104.4
0.0
-2.4
6.3
-6.6
32.0

Upper

2140.7
-53.6
0.3
-0.4
0.0
7.0

-4.0
–
0.0
0.0
6.4
12.0
-18.0

170.0
0.0
-2.1
-1.2
27.0
-3.0

Both

2364.5
-42.5
-3.4
2.9
-4.2
7.0

-13.0
–
0.0
4.0
6.8
-9.4
-8.0

172.4
0.0
1.2
2.3
7.8
-5.0

In conclusion, objective boundary constraints can generally improve solver performance. Still, there are
dependencies on the right combination of solver and COP model to make best use of the reduced domain. Which
combination is most eﬀective and what the actual reasons for better performance are is yet an open question
and, to the best of our knowledge, has not been clearly answered in the literature. From the comparison with a
ﬁxed objective boundary that is known to reduce the solution space, we observe that the estimated boundaries
are often competitive and provide a similar behaviour when the external requirements are met. This makes
boundary estimation a promising approach for further investigation and, once the external requirements on the
combination of solver and COP model are properly identiﬁed, also practical deployment.

6 Conclusion

Predictive ML has been shown to be very successful in supporting many important applications of CP, including
algorithm conﬁguration and selection, learning constraint models, and providing additional insights to support
CP solvers.

In the ﬁrst part of the paper, we presented the integration in these applications and discussed necessary

21

components for their success, such as data curation and trained ML models. Given the increasing interest in
ML and the vast development of the ﬁeld, we expect integration of predictive ML and CP to receive further
attention as well. We broadly identiﬁed three types of integration, that we expect to be most relevant for
future applications and research: The ﬁrst is to have a ML model included in the solver itself and thereby to
foster either learning during infer and search or lifelong learning of a solver. In this scenario, ML helps for
conﬁguration, ﬁltering consistency and propagators selection, labelling heuristics selection and potentially for
any solver decisions. Second, embedding ML models into the constraint model at compile time. Combining
ML and CP in one model allows us to model problems that can not be solved by one of the paradigms alone.
Furthermore, interaction of both paradigms can potentially enable further synergies at solving-time. The third
and ﬁnal category is a loose coupling between ML and CP by having a solver- and model- external ML component
that can make predictions, which can aﬀect both the solver and the model. Each of these three integration
types has advantages and drawbacks and diﬀerent application areas for which they are the most appropriate.

In the second part of the paper, we presented one application of predictive ML for CP, namely boundary
estimation. We introduced Bion, a novel boundary estimation method for constraint optimization problems
(COP), which belongs to the third type mentioned above. A ML model is trained to estimate close boundaries
on the objective value of a COP instance. To avoid inadmissible misestimations, training is performed using
asymmetric loss and label shift, a technique to automatically adjust training labels.

Boundary estimation has its strength in the combination of data-driven machine learning and exact constraint
optimization through branch-and-bound. Decoupling these two parts enables broad adaptation to diﬀerent
problems and compatibility with a wide range of solvers. Because estimator training requires a set of sample
instances, Bion is suited for scenarios where a COP has to be frequently solved with diﬀerent data inputs.
After additional instances have been solved, it is then possible to retrain the model to improve the estimations.
An experimental evaluation showed the capability to estimate admissible boundaries and prune the objective
domain with marginal overhead for the solver. Testing the estimated boundaries on CP solvers showed that
boundary estimation is eﬀective to support solving COPs.

The example of boundary estimation with Bion motivates the potential advantage of integrating ML and
constraint optimization, that we identiﬁed and discussed in the ﬁrst part of this article. At the same time, it
stresses the necessity for data-eﬃcient learning models and generic instance representations to capture relevant
problem and instance information.

Acknowledgment

This research was supported by the Research Council of Norway through the T-Largo grant (Project No.:
274786) and the European Commission through the H2020 project AI4EU (Project No.: 825619).

References

[1] Mart´ın Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeﬀrey Dean, Matthieu Devin,
Sanjay Ghemawat, Geoﬀrey Irving, Michael Isard, et al. Tensorﬂow: A system for large-scale machine
learning. In 12th {USENIX} symposium on operating systems design and implementation ({OSDI} 16),
pages 265–283, 2016.

[2] Luca Accorsi and Daniele Vigo. A Fast and Scalable Heuristic for the Solution of Large-Scale Capacitated

Vehicle Routing Problems. Research Report OR-20-2, University of Bologna, 2020.

[3] Roberto Amadini and Peter J. Stuckey. Sequential Time Splitting and Bounds Communication for a
Portfolio of Optimization Solvers. Lecture Notes in Computer Science, 8656 LNCS:108–124, 2014. ISSN
16113349. doi: 10.1007/978-3-319-10428-7 11.

22

[4] Roberto Amadini, Maurizio Gabbrielli, and Jacopo Mauro. An enhanced features extractor for a portfolio of
constraint solvers. In Symposium on Applied Computing, pages 1357–1359, 2014. ISBN 978-1-4503-2469-4.
doi: 10.1145/2554850.2555114.

[5] Roberto Amadini, Fabio Biselli, Maurizio Gabbrielli, Tong Liu, and Jacopo Mauro. Feature Selection
for SUNNY: A Study on the Algorithm Selection Library. In 2015 IEEE 27th International Conference
ISBN 978-1-5090-0163-7. doi:
on Tools with Artiﬁcial Intelligence (ICTAI), pages 25–32. IEEE, 2015.
10.1109/ICTAI.2015.18.

[6] Roberto Amadini, Maurizio Gabbrielli, and Jacopo Mauro. Sunny-cp: A sequential cp portfolio solver. In
Proceedings of the 30th Annual ACM Symposium on Applied Computing, SAC ’15, page 1861–1867, New
York, NY, USA, 2015. Association for Computing Machinery. ISBN 9781450331968. doi: 10.1145/2695664.
2695741. URL https://doi.org/10.1145/2695664.2695741.

[7] Roberto Amadini, Maurizio Gabbrielli, and Jacopo Mauro. A multicore tool for constraint solving. In
International Joint Conference on Artiﬁcial Intelligence, pages 232–238, 2015. ISBN 978-1-57735-738-4.

[8] Roberto Amadini, Maurizio Gabbrielli, and Jacopo Mauro. Parallelizing Constraint Solvers for Hard
RCPSP Instances. In Paola Festa, Meinolf Sellmann, and Joaquin Vanschoren, editors, LION 2016, volume
10079 of Lecture Notes in Computer Science, pages 227–233. Springer International Publishing, 2016. ISBN
978-3-319-50348-6. doi: 10.1007/978-3-319-50349-3 16.

[9] Alejandro Arbelaez and Michele Sebag. Online Heuristic Selection in Constraint Programming. In Inter-

national Symposium on Combinatorial Search, 2009.

[10] Alejandro Arbelaez, Youssef Hamadi, and Michele Sebag. Continuous Search in Constraint Programming.
In International Conference on Tools with Artiﬁcial Intelligence, pages 53–60, 2010. ISBN 978-1-4244-8817-
9. doi: 10.1109/ICTAI.2010.17.

[11] Florian Arnold and Kenneth S¨orensen. Knowledge-guided local search for the vehicle routing problem.
Computers & Operations Research, 105:32–46, 2019. ISSN 0305-0548. doi: 10.1016/j.cor.2019.01.002.

[12] Florian Arnold and Kenneth S¨orensen. What makes a VRP solution good? The generation of problem-
speciﬁc knowledge for heuristics. Computers & Operations Research, 106:280–288, 2019. ISSN 0305-0548.
doi: 10.1016/j.cor.2018.02.007.

[13] Nicolas Beldiceanu and Helmut Simonis. A constraint seeker: Finding and ranking global constraints
from examples. Lecture Notes in Computer Science (including subseries Lecture Notes in Artiﬁcial
doi:
Intelligence and Lecture Notes in Bioinformatics), 6876 LNCS:12–26, 2011.
10.1007/978-3-642-23786-7 4.

ISSN 03029743.

[14] Nicolas Beldiceanu and Helmut Simonis. A Model Seeker: Extracting Global Constraint Models from
In Principles and Practice of Constraint Programming, Lecture Notes in Com-
doi:

Positive Examples.
puter Science, pages 141–157, Berlin, Heidelberg, 2012. Springer.
10.1007/978-3-642-33558-7 13.

ISBN 978-3-642-33558-7.

[15] Irwan Bello, Hieu Pham, Quoc V. Le, Mohammad Norouzi, and Samy Bengio. Neural Combinatorial
Optimization. International Conference on Learning Representation, 2017. ISSN 1081-0706. doi: 10.1146/
annurev.cellbio.15.1.81.

[16] Yoshua Bengio, Andrea Lodi, and Antoine Prouvost. Machine Learning for Combinatorial Optimization:

A Methodological Tour d’Horizon. arXiv:1811.06128 [cs, stat], 2018.

23

[17] Jon Louis Bentley. Multidimensional binary search trees used for associative searching. Communications

of the ACM, 18(9):509–517, 1975. doi: 10.1145/361002.361007.

[18] Christian Bessiere, Remi Coletta, and Thierry Petit. Learning implied global constraints.

In IJCAI

International Joint Conference on Artiﬁcial Intelligence, pages 44–49, 2007.

[19] Christian Bessiere, Fr´ed´eric Koriche, Nadjib Lazaar, and Barry O’Sullivan. Constraint acquisition. Artiﬁcial

Intelligence, 24:315–342, 2015. doi: 10.1016/j.artint.2015.08.001.

[20] Christian Bessiere, Luc De Raedt, Tias Guns, Lars Kotthoﬀ, Mirco Nanni, Siegfried Nijssen, Barry
O’Sullivan, Anastasia Paparrizou, Dino Pedreschi, and Helmut Simonis. The Inductive Constraint Pro-
gramming Loop. IEEE Intelligent Systems, 32(5):44–52, 2017. doi: 10.1109/MIS.2017.3711637.

[21] Bernd Bischl, Pascal Kerschke, Lars Kotthoﬀ, Marius Lindauer, Yuri Malitsky, Alexandre Fr´echette, Holger
Hoos, Frank Hutter, Kevin Leyton-Brown, Kevin Tierney, and Joaquin Vanschoren. ASlib: A benchmark
library for algorithm selection. Artiﬁcial Intelligence, 237:41–58, 2016. ISSN 00043702. doi: 10.1016/j.
artint.2016.04.003.

[22] Quentin Cappart, Didier Ch´etelat, Elias Khalil, Andrea Lodi, Christopher Morris, and Petar Veliˇckovi´c.
Combinatorial optimization and reasoning with graph neural networks. arXiv:2102.09544 [cs, math, stat],
2021.

[23] Tianqi Chen and Carlos Guestrin. XGBoost. In Proceedings of the 22nd ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining - KDD ’16, pages 785–794. ACM Press, 2016. ISBN
978-1-4503-4232-2. doi: 10.1145/2939672.2939785.

[24] Fran¸cois Chollet and Others. Keras, 2015.

[25] Geoﬀrey Chu and Peter J. Stuckey. Learning Value Heuristics for Constraint Programming. In Interna-
tional Conference on AI and OR Techniques in Constraint Programming for Combinatorial Optimization
Problems, pages 108–123. Springer, 2015.

[26] Geoﬀrey Chu, Peter J. Stuckey, Andreas Schutt, Thorsten Ehlers, Graeme Gange, and Kathryn Francis.

Chuﬀed, a lazy clause generation solver, 2016.

[27] Corinna Cortes and Vladimir Vapnik. Support-vector networks. Machine Learning, 20(3):273–297, 1995.

doi: 10.1007/BF00994018.

[28] Hanjun Dai, Elias Khalil, Yuyu Zhang, Bistra Dilkina, and Le Song. Learning Combinatorial Optimization
Algorithms over Graphs. In Advances in Neural Information Processing Systems, pages 6351–6361, 2017.

[29] Luc De Raedt, Anton Dries, Tias Guns, and Christian Bessiere. Learning Constraint Satisfaction Prob-
lems: An ILP Perspective. In Christian Bessiere, Luc De Raedt, Lars Kotthoﬀ, Siegfried Nijssen, Barry
O’Sullivan, and Dino Pedreschi, editors, Data Mining and Constraint Programming: Foundations of a
Cross-Disciplinary Approach, Lecture Notes in Computer Science, pages 96–112. Springer International
Publishing, Cham, 2016. ISBN 978-3-319-50137-6. doi: 10.1007/978-3-319-50137-6 5.

[30] Pedro Domingos. A few useful things to know about machine learning. Communications of the ACM, 55

(10):78–78, 2012. doi: 10.1145/2347736.2347755.

[31] Jerome H. Friedman. Greedy Function Approximation: A Gradient Boosting Machine. The Annals of

Statistics, 29(5):1189–1232, 2001.

24

[32] Ian P. Gent, Chris Jeﬀerson, Lars Kotthoﬀ, Ian Miguel, Neil C.A. Moore, Peter Nightingale, and Karen
Petrie. Learning when to use lazy learning in constraint solving. In European Conference on Artiﬁcial
Intelligence (ECAI), pages 873–878, 2010. ISBN 9781607506058. doi: 10.3233/978-1-60750-606-5-873.

[33] Ian P. Gent, Bilal Syed Hussain, Christopher Jeﬀerson, Lars Kotthoﬀ, Ian Miguel, Glenna F. Nightingale,
and Peter Nightingale. Discriminating Instance Generation for Automated Constraint Model Selection. In
Principles and Practice of Constraint Programming, volume 8656 of LNCS, pages 356–365, 2014. ISBN
978-3-319-10427-0. doi: 10.1007/978-3-319-10428-7 27.

[34] Stefano Gualandi and Federico Malucelli. Exact Solution of Graph Coloring Problems via Constraint
ISSN

INFORMS Journal on Computing, 24(1):81–100, 2012.

Programming and Column Generation.
1091-9856. doi: 10.1287/ijoc.1100.0436.

[35] Minh Hoang Ha, Claude-Guy Quimper, and Louis-Martin Rousseau. General Bounding Mechanism for
Constraint Programs. In Principles and Practice of Constraint Programming, volume 9255, pages 30–38,
2015. ISBN 978-3-319-23218-8. doi: 10.1007/978-3-319-23219-5.

[36] Trevor Hastie, Robert Tibshirani, and Jerome Friedman. The Elements of Statistical Learning. Springer
Series in Statistics. Springer, New York, NY, second edition, 2009. ISBN 978-0-387-84857-0. doi: 10.1007/
978-0-387-84858-7.

[37] Sepp Hochreiter and Jurgen J¨urgen Schmidhuber. Long short-term memory. Neural Computation, 9(8),

1997. doi: 10.1162/neco.1997.9.8.1735.

[38] John N. Hooker. Integrated Methods for Optimization, volume 170 of International Series in Operations
Research & Management Science. Springer, second edition, 2012. ISBN 978-1-4614-1899-3. doi: 10.1007/
978-1-4614-1900-6.

[39] Frank Hutter, Holger H. Hoos, and Kevin Leyton-Brown. Identifying key algorithm parameters and instance
features using forward selection. Lecture Notes in Computer Science (including subseries Lecture Notes in
Artiﬁcial Intelligence and Lecture Notes in Bioinformatics), 7997 LNCS:364–381, 2013. ISSN 03029743.
doi: 10.1007/978-3-642-44973-4 40.

[40] Frank Hutter, Lin Xu, Holger H. Hoos, and Kevin Leyton-Brown. Algorithm runtime prediction: Methods
& evaluation. Artiﬁcial Intelligence, 206:79–111, 2014. ISSN 00043702. doi: 10.1016/j.artint.2013.10.003.

[41] Christopher Jeﬀerson, Ian Miguel, Brahim Hnich, Toby Walsh, and Ian P Gent. CSPLib: A problem

library for constraints. http://www.csplib.org, 1999.

[42] Mohit Kumar, Samuel Kolb, Stefano Teso, and Luc De Raedt. Learning MAX-SAT from Contextual
Examples for Combinatorial Optimisation. Proceedings of the AAAI Conference on Artiﬁcial Intelligence,
34(04):4493–4500, 2020. ISSN 2374-3468. doi: 10.1609/aaai.v34i04.5877.

[43] Arnaud Lallouet and Andrei Legtchenko. Building consistencies for partially deﬁned constraints with
decision trees and neural networks. International Journal on Artiﬁcial Intelligence Tools, 16(04):683–706,
2007. ISSN 02182130. doi: 10.1142/S0218213007003503.

[44] Arnaud Lallouet, Matthieu Lopez, Lionel Martin, and Christel Vrain. On learning constraint problems.
In International Conference on Tools with Artiﬁcial Intelligence, ICTAI, pages 45–52, 2010. doi: 10.1109/
ICTAI.2010.16.

[45] Daniel T. Larose. K-Nearest Neighbor Algorithm. Discovering Knowledge in Data: An Introduction to

Data Mining, pages 90–106, 2004. ISSN 0471687545. doi: 10.1002/0471687545.ch5.

25

[46] Michele Lombardi, Michela Milano, and Andrea Bartolini. Empirical decision model learning. Artiﬁcial

Intelligence, 244:343–367, 2017. doi: 10.1016/j.artint.2016.01.005.

[47] Manuel Loth, Mich`ele Sebag, Youssef Hamadi, and Marc Schoenauer. Bandit-based Search for Constraint
Programming. In International Conference on Principles and Practice of Constraint Programming, pages
464–480, 2013.

[48] Flavien Lucas, Romain Billot, Marc Sevaux, and Kenneth S¨orensen. Reducing Space Search in Combina-
torial Optimization Using Machine Learning Tools. In Ilias S. Kotsireas and Panos M. Pardalos, editors,
Learning and Intelligent Optimization, Lecture Notes in Computer Science, pages 143–150, Cham, 2020.
Springer International Publishing. ISBN 978-3-030-53552-0. doi: 10.1007/978-3-030-53552-0 15.

[49] Jean-Baptiste Mairy, Yves Deville, and Pascal Van Hentenryck. Reinforced adaptive large neighborhood
search. The Seventeenth International Conference on Principles and Practice of Constraint Programming
(CP 2011), page 55, 2011.

[50] Yuri Malitsky and Meinolf Sellmann. Instance-speciﬁc algorithm conﬁguration as a method for non-model-
based portfolio generation. Lecture Notes in Computer Science (including subseries Lecture Notes in Arti-
ﬁcial Intelligence and Lecture Notes in Bioinformatics), 7298 LNCS:244–259, 2012. ISSN 03029743. doi:
10.1007/978-3-642-29828-8 16.

[51] Kim Marriott and Peter J Stuckey. Programming with Constraints: An Introduction. MIT press, 1998.

[52] Nina Mazyavkina, Sergey Sviridov, Sergei Ivanov, and Evgeny Burnaev. Reinforcement learning for com-
binatorial optimization: A survey. Computers & Operations Research, 134:105400, 2021. ISSN 0305-0548.
doi: 10.1016/j.cor.2021.105400.

[53] Olaf Mersmann, Bernd Bischl, Heike Trautmann, Markus Wagner, Jakob Bossek, and Frank Neumann. A
novel feature-based approach to characterize algorithm performance for the traveling salesperson problem.
Annals of Mathematics and Artiﬁcial Intelligence, 69(2):151–182, 2013.
ISSN 10122443. doi: 10.1007/
s10472-013-9341-2.

[54] Michela Milano and Mark Wallace. Integrating operations research in constraint programming. 4OR, 4(3):

175–219, 2006. ISSN 1619-4500. doi: 10.1007/s10288-006-0019-z.

[55] Kevin P. Murphy. Probabilistic Machine Learning: An introduction. MIT Press, 2022. URL probml.ai.

[56] Nicholas Nethercote, Peter J. Stuckey, Ralph Becket, Sebastian Brand, Gregory J. Duck, and Guido Tack.
MiniZinc: Towards a Standard CP Modelling Language.
In Christian Bessi`ere, editor, Principles and
Practice of Constraint Programming – CP 2007, volume 4741, pages 529–543. Springer Berlin Heidelberg,
Berlin, Heidelberg, 2007. ISBN 978-3-540-74969-1. doi: 10.1007/978-3-540-74970-7 38.

[57] Eoin O’Mahony, Emmanuel Hebrard, Alan Holland, Conor Nugent, and Barry O’Sullivan. Using case-based
reasoning in an algorithm portfolio for constraint solving. In Irish Conference on Artiﬁcial Intelligence and
Cognitive Science, pages 210–216, 2008.

[58] Stephen M. Omohundro. Five balltree construction algorithms. Science, 51(1):1–22, 1989. doi: 10.1016/

S0092-8240(89)80047-3.

[59] F Pedregosa, G Varoquaux, A Gramfort, V Michel, B Thirion, O Grisel, M Blondel, P Prettenhofer,
R Weiss, V Dubourg, J Vanderplas, A Passos, D Cournapeau, M Brucher, M Perrot, and E Duchesnay.
Scikit-learn: Machine learning in python. Journal of Machine Learning Research, 12:2825–2830, 2011.

[60] Gerhard Reinelt. TSPLIB—A Traveling Salesman Problem Library. ORSA Journal on Computing, 3(4):

376–384, 1991. doi: 10.1287/ijoc.3.4.376.

26

[61] Mark Roberts and Adele Howe. Learning from planner performance. Artiﬁcial Intelligence, 173(5-6):

536–561, 2009. ISSN 00043702. doi: 10.1016/j.artint.2008.11.009.

[62] Francesca Rossi, Peter Van Beek, and Toby Walsh. Handbook of Constraint Programming (Foundations of

Artiﬁcial Intelligence). Elsevier Science Inc., New York, USA, 2006. ISBN 0-444-52726-5.

[63] Christian Schulte, Guido Tack, and Mikael Z. Lagerkvist. Modeling and Programming with Gecode. 2018.

[64] Jendrik Seipp, Silvan Sievers, Malte Helmert, and Frank Hutter. Automatic Conﬁguration of Sequential

Planning Portfolios. In AAAI Conference on Artiﬁcial Intelligence, 2015.

[65] Kate Smith-Miles, Jano Van Hemert, and Xin Yu Lim. Understanding TSP diﬃculty by learning from
evolved instances. Lecture Notes in Computer Science (including subseries Lecture Notes in Artiﬁcial
Intelligence and Lecture Notes in Bioinformatics), 6073 LNCS:266–280, 2010. ISSN 03029743. doi: 10.
1007/978-3-642-13800-3 29.

[66] Alex J. Smola and Bernhard Sch¨olkopf. A tutorial on support vector regression. Statistics and Computing,

14(3):199–222, 2004. doi: 10.1023/B:STCO.0000035301.49549.88.

[67] Helge Spieker and Arnaud Gotlieb. Learning Objective Boundaries for Constraint Optimization Problems.
In The 6th International Conference on Machine Learning, Optimization and Data Science - LOD 2020,
volume 12566 of LNCS. Springer, 2020.

[68] Peter J. Stuckey, Thibaut Feydy, Andreas Schutt, Guido Tack, and Julien Fischer. The MiniZinc Challenge

2008–2013. AI Magazine, 35(2):55–60, 2014. ISSN 0738-4602.

[69] Andrei Tolstikov and Frederik Janssen. Evaluation of Diﬀerent Heuristics for Accommodating Asymmetric

Loss Functions in Regression. Discovery Science, 10558:67–81, 2017.

[70] Dimosthenis C. Tsouros, Kostas Stergiou, and Christian Bessiere.

Structure-Driven Multiple Con-
In Principles and Practice of Constraint Programming, volume 11802, pages 709–
ISBN 978-3-030-30047-0 978-3-030-30048-7. doi:

straint Acquisition.
725. Springer International Publishing, Cham, 2019.
10.1007/978-3-030-30048-7 41.

[71] Dimosthenis C. Tsouros, Kostas Stergiou, and Christian Bessiere. Omissions in Constraint Acquisition. In
Helmut Simonis, editor, Principles and Practice of Constraint Programming, Lecture Notes in Computer
Science, pages 935–951, Cham, 2020. Springer International Publishing.
ISBN 978-3-030-58475-7. doi:
10.1007/978-3-030-58475-7 54.

[72] Michael Veksler and Ofer Strichman. Learning general constraints in CSP. Artiﬁcial Intelligence, 238:

135–153, 2016. ISSN 9783319180076. doi: 10.1016/j.artint.2016.06.002.

[73] Oriol Vinyals, Samy Bengio, and Manjunath Kudlur. Order Matters: Sequence to sequence for sets. In

International Conference on Learning Representations (ICLR), 2015.

[74] Lin Xu, Frank Hutter, H.H. Hoos, and K. Leyton-Brown. SATzilla-07: The design and analysis of an
algorithm portfolio for SAT. Proceedings of the 13th international conference on Principles and practice of
constraint programming, pages 712–727, 2007. ISSN 3540749691.

[75] Zhi Hua Zhou, Jianxin Wu, and Wei Tang. Ensembling neural networks: Many could be better than all.

Artiﬁcial Intelligence, 137(1-2):239–263, 2002. doi: 10.1016/S0004-3702(02)00190-X.

27

