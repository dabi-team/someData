2
2
0
2

y
a
M
2
1

]

C
D
.
s
c
[

3
v
7
1
9
2
0
.
8
0
1
2
:
v
i
X
r
a

Toward Efﬁcient Online Scheduling for
Distributed Machine Learning Systems

Menglu Yu, Jia Liu Senior Member, IEEE, Chuan Wu Senior Member, IEEE, Bo Ji Senior Member, IEEE

Elizabeth S. Bentley Member, IEEE

1

Abstract—Recent years have witnessed a rapid growth of distributed machine learning (ML) frameworks, which exploit the massive
parallelism of computing clusters to expedite ML training. However, the proliferation of distributed ML frameworks also introduces many
unique technical challenges in computing system design and optimization. In a networked computing cluster that supports a large
number of training jobs, a key question is how to design efﬁcient scheduling algorithms to allocate workers and parameter servers
across different machines to minimize the overall training time. Toward this end, in this paper, we develop an online scheduling
algorithm that jointly optimizes resource allocation and locality decisions. Our main contributions are three-fold: i) We develop a new
analytical model that considers both resource allocation and locality; ii) Based on an equivalent reformulation and observations on the
worker-parameter server locality conﬁgurations, we transform the problem into a mixed packing and covering integer program, which
enables approximation algorithm design; iii) We propose a meticulously designed approximation algorithm based on randomized
rounding and rigorously analyze its performance. Collectively, our results contribute to the state of the art of distributed ML system
optimization and algorithm design.

Index Terms—Online resource scheduling, distributed machine learning, approximation algorithm

(cid:70)

1 INTRODUCTION

Fueled by the rapid growth of data analytics and machine
learning (ML) applications, recent years have witnessed
an ever-increasing hunger for computing power. However,
with hardware capability no longer advancing at the pace of
the Moore’s law, it has been widely recognized that a viable
solution to sustain such computing power needs is to exploit
parallelism at both machine and chip scales. Indeed, the
recent success of deep neural networks (DNN) is enabled
by the use of distributed ML frameworks, which exploit
the massive parallelism over computing clusters with a
large number of GPUs. These distributed ML frameworks
have signiﬁcantly accelerated the training of DNN for many
applications (e.g., image and voice recognition, natural lan-
guage processing, etc.). To date, prevailing distributed ML
frameworks include TensorFlow [1], MXNet [2], PyTorch [3],
Caffe [4], to name just a few.

However, the proliferation of distributed ML frame-
works also introduces many unique technical challenges on
large-scale computing system design and network resource
optimization. Particularly, due to the decentralized nature,
at the heart of distributed learning system optimization lies
the problem of scheduling ML jobs and resource provision-
ing across different machines to minimize the total training

Menglu Yu is with the Department of Computer Science, Iowa State Univer-
sity, Ames, IA 50011, USA (e-mail: mengluy@iastate.edu).
Jia Liu is with the Department of Electrical and Computer Engineering, The
Ohio State University, Columbus, OH 43210, USA (e-mail: liu@ece.osu.edu).
Bo Ji is with the Department of Computer Science, Virginia Tech, Blacksburg,
VA 24061, USA (e-mail: boji@vt.edu).
Chuan Wu is with the Department of Computer Science, The University of
Hong Kong, Hong Kong (e-mail: cwu@cs.hku.hk).
Elizabeth S. Bentley is with the Air Force Research Laboratory, Information
Directorate, Rome, NY 13441, USA (e-mail: elizabeth.bentley.3@us.af.mil).
Digital Object Identiﬁer 10.1109/TNSE.2021.3104513.

time. Such scheduling problems involve dynamic and com-
binatorial worker and parameter server allocations, which
are inherently NP-hard. Also, the allocations of workers and
parameter servers should take locality into careful consider-
ation, since co-located workers and parameter servers can
avoid costly network communication overhead. However,
locality optimization adds yet another layer of difﬁculty in
scheduling algorithm design. Exacerbating the problem is
the fact that the future arrival times of training jobs at an ML
computing cluster are hard to predict, which necessitates
online algorithm design without the knowledge of future
job arrivals. So far in the literature, there remains a lack
of holistic theoretical studies that address all the aforemen-
tioned challenges. Most of the existing scheduling schemes
are based on simple heuristics without performance guar-
antee (see Section 2 for detailed discussions). This motivates
us to ﬁll this gap and pursue efﬁcient online scheduling
designs for distributed ML resource optimization, which
offer provable performance guarantee.

The main contribution of this paper is that we develop
an online scheduling algorithmic framework that jointly
yields resource scheduling and locality optimization deci-
sions with strong competitive ratio performance. Further,
we reveal interesting insights on how distributed ML frame-
works affect online resource scheduling optimization. Our
main technical results are summarized as follows:
• By abstracting the architectures of prevailing dis-
tributed ML frameworks, we formulate an online resource
scheduling optimization problem that: i) models the train-
ing of ML jobs based on the parameter server (PS) ar-
chitecture and stochastic gradient descent (SGD) method;
and ii) explicitly takes locality optimization into consid-
eration. We show that, due to the heterogeneous internal
(between virtual machines or containers) and external (be-

 
 
 
 
 
 
tween physical machines) communications, the locality-
aware scheduling problem contains non-deterministic con-
straints and is far more complex compared to the existing
works that are locality-oblivious (see, e.g., [5], [6]).
• To solve the locality-aware scheduling problem, we de-
velop an equivalent problem reformulation to enable
subsequent developments of online approximation algo-
rithms. Speciﬁcally, upon carefully examining the locality
conﬁgurations of worker-server relationships, we are able
to transform the original problem to a special-structured
integer nonlinear program with mixed cover/packing-
type constraints, and the low-complexity approximation
algorithm design with provable performance can be fur-
ther entailed.
• To tackle the integer nonlinear problem with mixed
cover/packing-type constraints, we propose an approx-
imation algorithm based on a meticulously designed ran-
domized rounding scheme and then rigorously prove its
performance. We note that the results of our randomized
rounding scheme are general and could be of independent
theoretical interest. Finally, by putting all algorithmic de-
signs together, we construct a primal-dual online resource
scheduling (PD-ORS) scheme, which has an overall com-
petitive ratio that only logarithmically depends on ML job
characteristics (e.g., required epochs, training samples).
Collectively, our results contribute to a comprehensive
and fundamental understanding of distributed machine
learning system optimization. The remainder of this paper
is organized as follows. In Section 2, we review the literature
to put our work in comparative perspectives. Section 3
introduces the system model and problem formulation.
Section 4 presents our algorithms and their performance
analysis. Section 5 presents numerical results and Section 6
concludes this paper.

2 RELATED WORK
As mentioned in Section 1, due to the high computa-
tional workload of ML applications, many distributed ML
frameworks (e.g., TensorFlow [1], MXNet [2], PyTorch [3],
Caffe [4]) have been proposed to leverage modern large-
scale computing clusters. A common distributed training
architecture implemented in these distributed ML frame-
works is the PS architecture [7], [8], which employs mul-
tiple workers and PSs (implemented as virtual machines
or containers) to collectively train a global ML model.
Coupled with the iterative ML training based on stochastic
gradient descent (SGD), the interactions between machines
in the distributed ML cluster are signiﬁcantly different
from those in traditional cloud computing platforms (e.g.,
MapReduce [9] and Dryad [10] and references therein). For
example, a MapReduce job usually partitions the input data
into independent chunks, which are then processed by the
map step in a parallel fashion. The output of the maps are
then fed to the reduce step to be aggregated to yield the
ﬁnal result. Clearly, the data ﬂows in MapReduce are a
“one-way trafﬁc”, which is unlike those iterative data ﬂows
in ML training jobs whose completions highly depend on
the ML job’s convergence property. As a result, existing job
scheduling algorithms for cloud systems are not suitable for
distributed ML frameworks.

2

Among distributed ML system studies, most of the early
attempts (see, e.g., [7], [8] and references therein) only con-
sidered static allocation of workers and parameter servers.
To our knowledge, the ﬁrst work on understanding the
performance of distributed ML frameworks is [11], where
Yan et al. developed analytical models to quantify the im-
pacts of model-data partitioning and system provisioning
for DNN. Subsequently, Chun et al.
[5] developed heuris-
tic dynamic system reconﬁguration algorithms to allocate
workers and parameter servers to minimize the runtime, but
without providing optimality guarantee. The ﬁrst dynamic
distributed scheduling algorithm with optimality guarantee
was reported in [12], where Sun et al. used standard mixed
integer linear program (MILP) solver to dynamically com-
pute the worker-parameter server partition solutions. Due
to NP-hardness of the MILP, the scalability of this approach
is limited. The most recent work [13] proposed an online
scheduling algorithm to schedule synchronous training jobs
in ML clusters with the goal to minimize the weighted
completion time. However, the consecutive time slots were
allocated for each training job, and the numbers of workers
and parameter servers could not be adjusted.

Another line of the research is to leverage the learning-
based approach to do the resource scheduling. There are a
number of recent works using deep reinforcement learning
(DRL) for resource allocation, device placement, and video
streaming. For example, Mao et al. [14] and Chen et al. [15]
designed a multi-resource cluster scheduler using DRL with
the goal to minimize average job slowdown. The proposed
scheduler picks one or more of the waiting jobs in the queue
and allocate to machines at each time slot, and the resource
demand of each job is unknown until after its arrival. Later,
Mao et al. [16], [17] used DRL to heuristically train schedul-
ing policies for graph-based parallel jobs by setting both par-
allelism level and execution order. Meanwhile, Mirhoseini
et al. [18], [19] utilized DRL to design a model for efﬁcient
placement of computational graphs onto hardware devices,
aiming at minimize the running time of each individual
TensorFlow job. Although various performance gains have
been empirically reported, these DRL-based studies do not
offer optimality performance guarantee due to the lack of
theoretical foundation of DRL as of today.

The most relevant work to ours is [6], where Bao et al.
developed an online primal-dual approximation algorithm,
OASiS, to solve the scheduling problem for distributed ML
systems. Our work differs from [6] in the following key
aspects: 1) In [6], the workers and parameter servers are
allocated on two strictly separated sets of physical machines,
i.e., no worker and parameter server can share the same
physical machine, which signiﬁcantly simpliﬁed the un-
derlying optimization problem. In this work, we consider
the cases that workers and parameter servers can be co-
located on the same physical machine, which is the common
practice in existing ML systems (see, e.g.,
[20], [21]). Such
co-location can signiﬁcantly reduce inter-server communica-
tion, expedite training, and improve resource utilization efﬁ-
ciency between workers and parameter servers. However, as
will be shown later, the co-location setting leads to an inte-
ger non-convex optimization problem with non-deterministic
constraints, which is much harder and necessitates new
algorithm design. 2) Ref. [6] advocates dynamic worker

3

Fig. 1:
training with the PS architecture.

Illustration of distributed

Fig. 2: The workﬂow of
training.

iterative

Fig. 3: Colocated parameter servers
and workers on physical machines.

number adjustment, but does not guarantee the same global
batch size across the training iterations. According to recent
literature [22], maintaining a consistent global batch size is
important for ensuring convergence of DNN training, when
the worker number varies. We ensure a consistent global
batch size in our model. We note that the co-location setting
was considered in [23]. However, the scheduling algorithm
therein is a heuristic and does not provide performance
guarantee. This motivates us to develop new algorithms
with provable performance to ﬁll this gap.

3 SYSTEM MODEL AND PROBLEM FORMULATION

In this section, we ﬁrst provide a quick overview on the
architecture of distributed ML frameworks to familiarize
readers with the necessary background. Then, we will in-
troduce our analytical models for ML jobs and resource
constraints, as well as the overall problem formulation.

1) Distributed Machine Learning: A Primer. As illus-
trated in Fig. 1, the key components of a PS-based dis-
tributed ML system include parameter servers, workers,
and the training dataset, which are usually implemented
over a connected computing cluster that contains multiple
physical machines. The training dataset of an ML job is
stored in distributed data storage (e.g., HDFS [24]) and
usually divided into equal-sized data chunks. Each data
chunk further contains multiple equal-sized mini-batches.

To date, one of the most widely adopted training algo-
rithms in distributed ML frameworks is the stochastic gra-
dient descent method (SGD) [25]. With SGD, the interactions
between workers and parameter servers are illustrated in
Fig 2. A worker is loaded with the DNN model (we focus
on data parallel training) with current values of the model
parameters (e.g., the weights of a DNN) and retrieves a
new data chunk from the data storage. In each training
iteration, a worker processes one mini-batch from its data
chunk to compute gradients (i.e., directions and magnitudes
of parameter changes).1 Upon ﬁnishing a mini-batch, the
worker sends the gradients to the parameter servers, re-
ceives updated global parameters, and then continues with
the next training iteration to work on the next mini-batch.
On the parameter server side, parameters are updated as:
w[k] = w[k − 1] + αkg[k], where w[k], αk, and g[k] denote
the parameter values, step-size, and stochastic gradient in
the k-th update, respectively.

1. As an example, in a DNN model, gradients can be computed by

the well-known “back-propagation” approach.

2) Modeling of Learning Jobs: We consider a time-
slotted system. The scheduling time-horizon is denoted as T
with |T | = T . We use I to represent the set of training jobs
and let ai denote the arrival time-slot of job i ∈ I. As shown
in Fig. 3, parameter servers and workers could spread over
multiple physical machines. We let H represent the set of
physical machines. For each job i, we use wih[t], sih[t] ≥ 0 to
represent the allocated numbers of workers and parameter
servers on machine h ∈ H in each time-slot t ≥ ai,
respectively. Further, we let Pi[t] (cid:44) {h ∈ H|sih[t] > 0} and
Wi[t] (cid:44) {h ∈ H|wih[t] > 0} denote the sets of physical
machines that contain parameter servers and workers for
job i in time-slot t, respectively.

We use a binary variable xi ∈ {0, 1} to indicate whether
job i is admitted (xi = 1) or not (xi = 0). We use τi to
denote the training for each sample of job i. We let bi(h, p)
denote the data rate of the link between a worker for job
i (on machine h) and a parameter server (on machine p).
Each worker or parameter server is exclusively assigned
to some job i, and bi(h, p) is reserved and decided by the
user upon job submission, which is common to ensure the
data transfer performance [6]. Note that the value of bi(h, p)
is locality-dependent where the slowest worker will become
the bottleneck since we focus on Bulk-Synchronous-Parallel
(BSP) scheme [26]. Speciﬁcally, we have:

bi(h, p) =

(cid:40)

b(i)
,
if h = p,
i
b(e)
, otherwise,
i

i

and b(e)

where b(i)
denote the internal and external com-
i
munication link rates, respectively. For example, as shown
in Fig. 3, since Job 1’s worker W4 and parameter server
PS2 are both on the same machine, they communicate at
the internal link rate b(i)
1 . On the other hand, since Job
1’s worker W3 and parameter server PS2 are on different
physical machines, they communicate at the external link
rate b(e)

1 . In practice, it usually holds that b(e)

i (cid:28) b(i)

.

i

Next, we calculate the amount of time for a worker
on machine h to process a sample. We use Fi to denote
the global batch size of job i, which is a ﬁxed constant
across all time-slots.2 We assume Fi
is equally divided

2. We note that this ﬁxed global batch size requirement is compli-
ant with the standard SGD implementation [27] and important for
ensuring convergence [22]. In contrast, the global batch size in some
existing works on dynamic ML resource allocation (e.g., [6]) could be
time-varying, which necessitates time-varying dynamic learning rate
adjustments to offset correspondingly and further complicates the SGD
implementation.

............PSMGradientsParametersParameterServerWorkerDatabaseforTrainingDatasetW1W2WNPS1......W1WNPSMPS1TimeTimeTimeTimeGradientsGradientsGradientsGradientsParametersParametersParametersParametersTimefortrainingamini-batchMachine 4Machine 1Machine 2Machine 5Machine 3Machine 6Job 1Job 2Job 3b(i)1PS1W1W1W2W5PS1PS2W2PS2W1W4PS1W3W3W3W3b(e)1among workers, i.e., the local batch size at each worker is:
Fi/ (cid:80)

h(cid:48)∈H wih(cid:48)[t].3

job i. Then,

We assume symmetric link speed in both directions
between a worker and a PS. Let gi denote the size of
gradients/parameters of
from a worker’s
perspective, to push gradients to and pull updated pa-
rameters from the PSs for job i,
the combined up-
link/downlink communication time can be computed as:
(2gi/ (cid:80)
h(cid:48)∈H sih(cid:48)[t])/(minp∈Pi[t] bi(h, p)), where the numer-
ator term gi/ (cid:80)
h(cid:48)∈H sih(cid:48)[t] follows from the assumption
of even parameter distribution among the PSs, and the
denominator is due to the fact that push/pull time is
decided by the slowest link among all connections from
the worker to all PSs (i.e., minp∈Pi[t] bi(h, p)). Hence, the
average computation and communication time to process a
sample on machine h ∈ Wi[t] for job i in time slot t can be
computed as:

+

τi
(cid:124)(cid:123)(cid:122)(cid:125)
Training time
per sample

(cid:124)

(cid:18) 2gi/ (cid:80)

h(cid:48)∈H sih(cid:48)[t]
minp∈Pi[t] bi(h, p)

(cid:19)(cid:30)(cid:18)

Fi
h(cid:48)∈H wih(cid:48)[t]

(cid:80)

(cid:123)(cid:122)
Communication time per sample

(cid:19)

.

(cid:125)

Recall that we focus on the BSP scheme, where all workers
are synchronized before they proceed to the next iteration.
In other words, the total number of samples trained on
machine h ∈ Wi[t] for job i in time slot t is determined by
the slowest link among all connections from all workers to
all PS (i.e., minp∈Pi[t],h(cid:48)∈Wi[t] bi(h(cid:48), p)). It then follows that
the number of samples trained on machine h ∈ Wi[t] for job i
in time-slot t can be computed as:

(cid:16)

τi +

wih[t]

2gi/ (cid:80)

h(cid:48) ∈H sih(cid:48) [t]

minp∈Pi[t],h(cid:48) ∈Wi[t] bi(h(cid:48),p)

(cid:17)(cid:46)(cid:16)

(cid:80)

Fi
h(cid:48) ∈H wih(cid:48) [t]

(cid:17) .

(1)

Note that in practice, ML users usually specify a ﬁxed ratio
between worker number and PS number (e.g., often 1:1 4)
when launching their training jobs to ensure appropriate
coordinations between workers and PSs in terms of channel
bandwidth, memory allocation, etc. To model this practice,
we deﬁne the ratio of worker number to PS number for each
job i as:

h(cid:48)∈H wih(cid:48)[t]
h(cid:48)∈H sih(cid:48)[t]
With γi, we can rewrite Eq. (1) as:

γi (cid:44)

(cid:80)
(cid:80)

,

∀i, t.

(2)

wih[t]

τi + γi
Fi

2gi
minp∈Pi[t],h(cid:48) ∈Wi[t] bi(h(cid:48),p)

.

Suppose that, for job i, there are Ki data samples in
its training dataset. In practice, Ki (cid:29) Fi. In ML systems,
an epoch is deﬁned as a round of training that exhausts
all data samples. We let Ei denote the number of epochs
needed by job i. In this paper, we assume that the epoch
of each job is predetermined. This is because it is often
difﬁcult to estimate the required number of epochs for
SGD-type methods’ convergence. Therefore, most SGD-type

3. Most distributed ML frameworks (e.g., Tensorﬂow [28]) set the

same local batch size to each worker for the distributed training.

4. In practice, the ratio between numbers and parameter servers are
speciﬁed by the user upon the job’s submission (e.g., 1:1 in Kuber-
netes [29]).

4

algorithms in practice stop after a ﬁxed number of iterations
(i.e., ﬁxed number of epochs, see, e.g.,
[30] and references
therein) to avoid excessive training delay.

Then, the total number of samples to be processed for
job i over the entire training process is EiKi. To make sure
that there are sufﬁcient workers allocated for job i over the
entire training horizon, we have:

(cid:88)

(cid:88)

t∈T

h∈H

wih[t]

τi + γi
Fi

2gi
minp∈Pi[t],h(cid:48) ∈Wi[t] bi(h(cid:48),p)

≥ xiEiKi, ∀i ∈ I. (3)

We note that, with co-located workers and parameter
servers on each machine, Eq. (3) is non-deterministic due to
the existence of the min{·} operator. As will be shown later,
this non-determistic constraint makes the scheduling design
far more complicated than related works [5], [6], [7], [8].

To model the fact that the largest number of assigned
concurrent workers is no more than the global batch size
(otherwise, some workers will be idle), we have:

(cid:88)

h∈H

wih[t] ≤ xiFi,

∀i ∈ I, ai ≤ t ≤ T.

(4)

3) Resource Constraint Modeling: We let R denote the
set of resources (e.g., CPU/GPU, memory, storage, etc.). Let
αr
i and βr
i be the amount of type-r resource required by a
worker and a parameter server for job i, respectively. Let C r
h
be the capacity of type-r resource on machine h. To ensure
the resources do not exceed type-r’s limit, we have:
i sih[t]) ≤ C r

h, ∀t ∈ T , r ∈ R, h ∈ H.

i wih[t] + βr

(αr

(cid:88)

(5)

i∈I

Note that for job i, its completion time ˜ti corresponds to
the latest time-slot where there remain some active workers
allocated for it. Therefore, we have:

˜ti = arg max
t∈T

(cid:27)

wih[t] > 0

(cid:26) (cid:88)

h∈H

,

∀i ∈ I.

(6)

To ensure that no workers and parameter servers are allo-
cated before job i’s arrival, we have:

wih[t] = sih[t] = 0,

∀i ∈ I, h ∈ H, t < ai.

(7)

4) Objective Function and Problem Statement: Let
ui(˜ti − ai) be the utility function for job i, which is non-
increasing with respect to the training time ˜ti−ai. The utility
functions could play the role of various performance metrics
based on job completion times (e.g., fairness). In this paper,
our goal is to maximize the overall utility for all jobs. Putting
all constraints and the objective function together, the ofﬂine
(with knowledge of ai, ∀i) distributed ML resource schedul-
ing problem (DMLRS) can be formulated as:

DMLRS: Maximize

x,w,s

xiui(˜ti − ai)

(cid:88)

i∈I

subject to Constraints (3) – (7).

Problem DMLRS is an integer nonlinear program, which
is NP-hard in general [31]. Also, Problem DMLRS involves
two non-deterministic constraints in (3) and (6), which are not
amenable for conventional optimization techniques. More-
over, the arrivals {ai, ∀i} are often unknown in practice,
which necessitates online optimization. Overcoming these
challenges constitutes the rest of this paper. To conclude this

I/T
˜ti/ai
ui(·)/Ki
R/H
Ei/Fi
xi
Cr
h
αr
i
βr
i
wih[t]
sih[t]

bi(h, p)

τi
gi

Wi[t]

Pi[t]

xπi
˜tπi
wπi
ht
sπi
ht
Πi
γi
ρr
h[t]
Qr
h(·)

TABLE 1: Notation.
The set of jobs/System timespan
Completion time of job i /Arrival time of job i
Job i’s utility function/Number of samples in i
The set of resource types/The set of machines
# of training epochs/Global batch size for job i
Admission decision variable to accept job i or not
Capacity of type-r resource on server h
Type-r resource required by a worker in job i
Type-r resource required by a PS in job i
Number of workers of job i on server h in t
Number of PSs of job i on server h in t
Bandwidth consumed by a worker of job i, where
bi(h, p) = b(e)
, if h (cid:54)= p or b(i)
Time to train a sample for job i
Size of gradients and parameters for job i
Set of physical machines containing workers
for job i in t
Machines containing parameter servers
for job i in t
Binary decision variable to select schedule π
for job i or not
The completion time slot of job i with schedule π
# of workers on server h in t for job i in schedule π
# of PSs on server h for schedule π in t
Set of all feasible schedules for job i
The ratio of worker number to PS number for job i
Allocated type-r resource on machine h in time t
Price function for type-r resource on machine h

, otherwise.

i

i

section, we summarize the key notation used in this paper
in Table 1 for easy reference.

4 ONLINE SCHEDULING ALGORITHM DESIGN
In this section, we structure the key components of
our online scheduling algorithm design for solving Prob-
lem DMLRS into three steps from Sections 4.1 to 4.3. We
state our main theoretical performance results in Section 4.4.

4.1 Reformulation for Non-Deterministic Constraint (6)

The ﬁrst challenge in solving Problem DMLRS stems from
the non-deterministic “argmax” structure in constraint (6).
To address this challenge, we let Πi be the set of all feasible
schedules for job i ∈ I that satisfy constraints (3), (4). Each
schedule πi ∈ Πi is deﬁned by the numbers of workers wπi
ht
and parameter servers sπi
ht allocated for job i on machine
h in each time-slot t, i.e., πi (cid:44) {wπi
ht, ∀t ∈ T , h ∈ H}.
Note that wπi
ht and sπi
ht are constants, not to be confused
with decision variables wih[t] and sih[t]. We deﬁne a binary
variable xπi ∈ {0, 1} that is equal to 1 if job i is admitted
and scheduled under schedule πi, or 0, otherwise. Clearly,
due to the combinatorial nature, |Πi| is exponential. We let
˜tπi denote job i’s completion time under schedule πi. Then,
one can equivalently reformulate Problem DMLRS as:

ht, sπi

R-DMLRS:

Maximize
x

subject to

(cid:88)

(cid:88)

i∈I
(cid:88)

πi∈Πi
(cid:88)

xπiui(˜tπi − ai)

(αr

i wπi

ht + βr

i sπi

ht)xπi ≤ C r
h,

i∈I

πi∈Γ(t,h)

∀t ∈ T , r ∈ R, h ∈ H,

(cid:88)

xπi ≤ 1,

∀i ∈ I,

πi∈Πi
xπi ∈ {0, 1},

∀i ∈ I, πi ∈ Πi,

(8)

(9)

5

where we use Γ(t, h) to represent the set of feasible sched-
ules that use machine h to deploy workers or parameter
servers in time-slot t. Constraint (8) guarantees that, in
any time-slot t and on any machine h, the total amount
of consumed type-r resources will not exceed the capacity
limit C r
h. Constraint (9) ensures that, for each job i, at most
one feasible schedule from Πi will be selected. Note that
Problem R-DMLRS is an integer linear program (ILP) and
a feasible solution to Problem R-DMLRS has a correspond-
ing feasible solution to the original Problem DMLRS, and
vice versa. Notice that the non-deterministic constraint (6)
no longer exists in Problem R-DMLRS. Further, if relaxing
binary xπi -variables to real-valued, Problem R-DMLRS is a
linear program (LP). However, it remains difﬁcult to solve
Problem R-DMLRS since it has an exponential number of xπi -
variables due to the combinatorial nature of feasible sched-
ules. We will address this challenge in the next subsection.

4.2 An Online Primal-Dual Framework for R-DMLRS

In what follows, we adopt a primal-dual online algorithmic
framework to reduce the number of binary variables, which
is an effective approach to address this kind of challenge
in the literature (see, e.g., [6], [32]). Note that, in the dual
of Problem R-DMLRS, the number of dual variables is
polynomial. Meanwhile, although there are an exponential
number of constraints in the dual problem, one only needs
to be concerned with the set of active (binding) constraints,
which are easier to deal with. To see this, we associate dual
variables pr
h[t] ≥ 0, ∀t ∈ T , h ∈ H, r ∈ R and λi > 0,
i ∈ I, with (8) and (9), respectively. Then, following the
standard procedure of dualization (relaxing the integrality
constraints), we obtain the following dual problem:

D-R-DMLRS:
(cid:88)

Minimize
λ,p

(cid:88)

(cid:88)

(cid:88)

λi +

h[t]C r
pr
h

i∈I

t∈T

h∈H

r∈R

subject to λi ≥ ui(˜tπi − ai) −

(cid:88)

(cid:88)

(cid:88)

i sπi

t∈T (πi)

h∈H(πi[t])
∀i ∈ I, πi ∈ Πi,

h[t],

ht)pr
∀t ∈ T , h ∈ H, r ∈ R,

r∈R

+ βr
pr
h[t] ≥ 0,
λi ≥ 0,

∀i ∈ I,

(10)

(αr

i wπi
ht

(11)

where T (πi) denotes the time-slots utilized by schedule πi
and H(πi[t]) denotes the set of machines containing workers
and/or parameter servers under πi in time-slot t. Here, pr
h[t]
can be viewed as the price for type-r resource in time t.
Then, the right-hand-side (RHS) of (11) can be interpreted
as job utility minus overall resource cost of job i using
schedule πi. Thus λi ≥ 0 can be viewed as the payoff of
admitting job i with πi. Next, we examine the properties of
Problem D-R-DMLRS. To minimize (10), we tend to reduce
λi and pr
h[t]
decrease, the left-hand-side (LHS) and RHS of (11) decreases
and increases, respectively (the term ui(˜tπi − ai) in the RHS
of (11) is a constant given πi). Therefore, λi will drop to a
value λ∗
i , which is equal to maximum of the RHS of (11)
i and dual price pr∗
achieved by some schedule π∗
(cid:88)
ht +βr

h[t] until they hit zero. However, as λi and pr

h [t], i.e.,
i sπ∗
ht )pr∗

i = ui(˜tπ∗
λ∗

i wπ∗

−ai)−

(αr

(cid:88)

(cid:88)

i

i

i

h [t].

t∈T (π∗
i )

h∈H(π∗

i [t])

r∈R

This optimality structural insight implies that Problem D-
R-DMLRS is equivalent to ﬁnding an optimal schedule π∗
i
and dual price pr∗
h [t] to maximize the RHS of (11). The
above insights motivate the following primal-dual-based
algorithm as shown in Algorithm 1.

Algorithm 1: Primal-Dual Online Resource Scheduling (PD-
ORS).

Initialization:
1. Let wih[t] = 0, sih[t] = 0, ∀i, t, h. Let ρr

Choose some appropriate initial values for pr

h[t] = 0, ∀h, r, t.
h[0].

Main Loop:
2. Upon the arrival of job i, determine a schedule π∗
i

to
maximize the RHS of (11) and its corresponding payoff
λi using Algorithm 2 (to be speciﬁed).

3. If λi > 0, set xi = 1. Set wih[t] and sih[t] according to

i ), h ∈ H(π∗

i [t]).
i wih[t]+βr

h[t]+αr

i sih[t], ∀t ∈ T (π∗

i ),

schedule π∗
• Update ρr
h ∈ H(π∗
• Update pr

i , ∀t ∈ T (π∗
h[t] ← ρr
i [t]), r ∈ R.
h[t] = Qr

i ), h ∈ H(π∗
i and go to Step 2.
4. If λi ≤ 0, set xi = 0 and reject job i and go to Step 2.

r ∈ R. Schedule job i based on π∗

h[t]), ∀t ∈ T (π∗

h(ρr

i [t]),

The intuition of Algorithm 1 is as follows: By the com-
plementary slackness condition of the Karush-Kuhn-Tucker
(KKT) conditions [27], the primal constraint (9) must be tight
when dual variable λi > 0, which implies that xi = 1 (Step
3) in Problem DMLRS. Otherwise, if λi = 0, then the RHS of
(11) is non-positive, meaning the utility is low compared
to the cost of resource consumption under schedule π∗
i .
Therefore, we should reject job i (xi = 0 in Step 4). However,
in order for the PD-ORS algorithm to work, two challenging
components need to be speciﬁed: the schedule π∗
i and how
to update the cost function Qr
h(·)5 In what follows, we will
ﬁrst focus on designing Qr
h(·) and defer the challenging
problem of ﬁnding π∗
h(·),
consider the following choice of Qr

i to Section 4.3. For the design of Qr

h(·):

Qr

h(ρr

h[t]) = L(U r/L)

ρr
h [t]
Cr
h ,

(12)

where constants U r, ∀r, and L are deﬁned as follows:
(τi + 2giγi/(b(i)

i Fi))(cid:101) − ai)

ui((cid:100) EiKi
Fi

U r (cid:44) max
i∈I

L (cid:44) min
i∈I

(cid:80)

i + βr
αr
i
1/(2µ)ui(T − ai)
r∈R(cid:100)EiKi(τi + 2giγi/(b(e)

i Fi)(cid:101)(αr

i + βr
i )

.

(14)

, ∀r ∈ R,(13)

≤

h∈H

T (cid:80)

i + βr
i )

r∈R(αr

(cid:100)EiKi(τi + 2giγi/(b(e)

The scaling factor µ in the deﬁnition of L satisﬁes as follows:
i Fi))(cid:101) (cid:80)
(cid:80)
r∈R C r
h

1
µ
Here, U r is the maximum unit-resource job utility to deploy
workers and parameter servers with type-r resource . Here,
ui((cid:100) EiKi
i Fi))(cid:101) − ai) is the largest utility
Fi
job i can achieve by using the maximum number of co-
located workers and parameter servers (hence communi-
cating rate is b(i)
) at all times during all Ei epochs, so
i

(τi + 2giγi/(b(i)

, ∀i ∈ I.

5. Here, we note that the “cost function” Qr

h(·) is interpreted from
servers’ perspective rather than jobs’ perspective. Speciﬁcally, higher
cost means servers allocated more resources to jobs, which implies
higher utility for the jobs since jobs receive more resources from servers.

6

i

(τi + 2giγi/(b(i)

. We use ρr

that (cid:100) EiKi
i Fi))(cid:101) − ai is the earliest possible
Fi
job completion time. Similarly, L represents the minimum
unit-time unit-resource job utility among all
jobs, with
ui(T − ai) being the smallest utility for job i, and work-
ers and parameter servers communicate at small external
rate b(e)
h[t] to denote the allocated amount of
type-r resource to machine h for (future) time slot t. The
intuition behind the Qr
h(·) function is as follows: i) At t = 0,
ρr
h[0] = 0, ∀h ∈ H, r ∈ R. Hence, the price pr
h[0] = L is the
lowest, ∀h, r, and any job can be admitted; ii) As allocated
resources increases, the price increases exponentially fast
to reject early coming jobs with low utility and to reserve
resources for later arrived jobs with higher utility; iii) When
some type-r resource is exhausted, i.e., ρr
h, ∃r ∈ R,
Qr
h] = U r and no job that requires type-r resources will
be admitted since the U r is the highest price. As will be
shown later, this price function leads to a logarithmically
scaling competitive ratio in online algorithm design. Note
that computing the price function in Algorithm 1 requires
the information of constants U r, L, which can usually be
estimated empirically based historical data.

h[t] = C r

h[C r

Here, we point out a few interesting insights on the
design choices of the cost function in Eq. (12). Note that U r
and L are deﬁned in Eqns (13) and (14), respectively. Here,
we intentionally choose U r to be dependent on r and L to
be independent on L due to the following reasons:

First, the rationality of choosing an upper bound U r
that varies with different resource types is to ensure that
when some type-r resource is exhausted, no more jobs that
require type-r resource should be allocated. In other words,
when the allocated amount of type-r resource reaches the
capacity of physical machine h, i.e., ρr
n, ∃r ∈ R,
the price pr
h) should reach the upper bound U r,
h(C r
indicating that any job that requires type-r resource will not
be allocated to h. However, jobs that do not require type-r
resource should still be able to be scheduled on machine h.
For example, jobs that do not require GPU can still be placed
on a machine with no available GPUs.

h[t] = C r

h = Qr

Second, the reason that we choose the lower bound
L to be independent of any resource type r is to yield
a larger ratio of U r
L . The larger the ratio of U r
L is, the
greater the price will be. Intuitively, the ratio U r
L can be
interpreted as the scheduling “uncertainty,” which increases
as the ratio gets larger, implying the price function reacts to
the accumulative resource consumption more aggressively.
Thus, choosing L to be independent of resource type r
allows the price function Qr
h(·) to react more aggressively to
the accumulative allocated resource amount. We note that
one can also choose the lower bound to be dependent on
resource type r by replacing L with Lr. By doing so, the
log-scaling theoretical competitive ratio in Theorem 5 still
holds and the proof in Appendix C only needs to be slightly
updated with the new notation Lr. However, the empirical
performance of using Lr as lower bound is worse since the
price function reacts less aggressively to the accumulative
allocated resources.

4.3 Determining Schedule π∗
Now, consider the problem of ﬁnding a schedule π∗
i in Step
2 of Algorithm 1 to maximize the RHS of (11). First, we note
that any schedule for job i has a unique completion time ˜ti,

i in Step 2 of Algorithm 1

(a) |Pi[t]| (cid:54)= 1.

(b) |Pi[t]| = 1, |Wi[t]| (cid:54)= 1.

(c) |Pi[t]|=|Wi[t]|=1, Pi[t](cid:54)=Wi[t].

(d) |Pi[t]|=|Wi[t]|=1, Pi[t]=Wi[t].

Fig. 4: Values of

only if in (d).

minp∈Pi[t],h∈Wi[t] bi(h,p) under various settings of Pi[t] and Wi[t]. Here,

2gi

minp∈Pi[t],h∈Wi[t] bi(h,p) = 2 gi
b(i)
i

2gi

if and

7

including the maximizer π∗
ﬁnding the maximum RHS of (11) can be decomposed as:

i for (11). Hence, the problem of





Max
w,s

Max
˜ti

s.t. αr

(cid:80)
r∈R

i wih[t] + βr

ui(˜ti −ai)− (cid:80)
t∈T

(cid:80)
h∈H
×(αr
i sih[t] ≤ ˆC r

pr
h[t]
i wih[t] + βr
h[t],
∀t ∈ T , r ∈ R, h ∈ H,



where ˆC r
h[t]. Note that in the inner problem,
ui(˜ti − ai) is a constant for any given ˜ti. Thus, the inner
problem can be simpliﬁed as:

Constraints (3)(4)(7) for xi = 1,

h[t] (cid:44) C r




i sih[t])

h − ρr

, (15)

Minimize
w,s

subject to

(cid:88)

(cid:88)

(cid:88)

t∈[ai,˜ti]

h∈H

r∈R

(cid:88)

(cid:88)

h[t](αr
pr

i wih[t] + βr

i sih[t])

wih[t]

t∈[ai,˜ti]

h∈H

τi + γi
Fi

2gi
minp∈Pi[t],h(cid:48)∈Wi[t] bi(h(cid:48),p)

(16)

≥ Vi,

i wih[t]+βr
αr
Constraint (4) for all t ∈ [ai, ˜ti],

i sih[t] ≤ ˆC r

(17)
h[t], ∀r, h, ∀t ∈ [ai, ˜ti], (18)

where Vi (cid:44) EiKi represents the total training workload (to-
tal count of samples trained, where a sample is counted Ei
times if trained for Ei times). Note that in Problem (16), the
only coupling constraint is (17). This observation inspires
a dynamic programming approach to solve Problem (16).
Consider the problem below if training workload at time t
is known (denoted as Vi[t]):

Minimize
wih[t],sih[t],∀h

subject to

(cid:88)

(cid:88)

h[t](αr
pr

i wih[t] + βr

i sih[t])

h∈H
(cid:88)

h∈H

r∈R

wih[t]

τi + γi
Fi

2gi
minp∈Pi[t],h(cid:48) ∈Wi[t] bi(h(cid:48),p)

Constraints (4)(18) for the given t.

(19)

≥ Vi[t],

(20)

Let Θ(˜ti, Vi) and θ(t, Vi[t]) denote the optimal values of
Problems (16) and (19), respectively. Then, Problem (16) is
equivalent to the following dynamic program:

Θ(˜ti, Vi) = min
v∈[0,Vi]

(cid:8)θ(˜ti, v) + Θ(˜ti − 1, Vi − v)(cid:9) .

(21)

We ﬁnd the optimal workload v to be completed in time
slot ˜ti by enumerating it from 0 to EiKi, and the remaining
workload EiKi−v will be carried out in time span [ai, ˜ti−1].
The optimal workload would be the schedule with mini-
mum costs, i.e., the objective function of Problem (19) is
minimum. Then we proceed to the next time slot ˜ti − 1 with
the workload EiKi − v, which is the same as ﬁnding the
optimal schedule and cost as the last time slot ˜ti except in
a smaller scale. Then, by enumerating all ˜ti ∈ [ai, T ] and

solving the dynamic program Θ(˜ti, Vi) in (21) for every
choice of ˜ti, we can solve Problem (15) and determine
the optimal schedule π∗
i . We summarize this procedure in
Algorithms 2 and 3:

Algorithm 2: Determine π∗

i in Step 2 of Algorithm 1.

i = ∅, wih[t] = sih[t] = 0, ∀i, t, h.

Initialization:
1. Let ˜ti = ai. Let λi = 0, π∗
Main Loop:
2. Compute Θ(˜ti, Vi) in (21) using Algorithm 3. Denote the
i = ui(˜ti − ai) − Θ(˜ti, Vi).
i ← πi.

resulted schedule as πi. Let λ(cid:48)
i and π∗
If λ(cid:48)
3. Let ˜ti ← ˜ti + 1. If ˜ti > T , stop; otherwise, go to Step 2.

i > λi, let λi ← λ(cid:48)

Algorithm 3: Solving Θ(˜ti, Vi) by Dynamic Programming.

Initialization:
1. Let cost-min = ∞, πi = ∅, and v = 0.
Main Loop:
2. Compute θ(˜ti, v) using Algorithm 4 (to be speciﬁed).
Denote the resulted cost and schedule as cost-v and ˆπi.
3. Compute Θ(˜ti − 1, Vi − v) by calling Algorithm 3 itself.
Denote the resulted cost and schedule as cost-rest and ˜πi.
4. If cost-min > cost-v + cost-rest then cost-min = cost-v +

cost-rest and let πi ← ˆπi ∪ ˜πi.

5. Let v ← v + 1. If v > Vi stop; otherwise go to Step 2.

In Algorithm 3, however, how to compute θ(t, v) in Step
2 (i.e., Problem (19)) is yet to be speciﬁed. A challenge in
solving (19) is the non-deterministic constraint in (20), where
bi(h, p) can be either b(i)
or b(e)
. Therefore, we need to
i
i
handle both cases. To this end, we observe the following
minp∈Pi[t],h∈Wi[t] bi(h,p) (also illustrated in
basic fact about
Fig. 4) as stated in Fact 1. We omit the proof of this fact
due to its simplicity, which is illustrated in Fig. 4.

2gi

Fact 1. The function (2gi/ minp∈Pi[t],h∈Wi[t] bi(h, p)) =
2gi/b(i)
if and only if |Pi[t]| = |Wi[t]| = 1 and Pi[t] = Wi[t];
i
otherwise, (2gi/ minp∈Pi[t],h∈Wi[t] bi(h, p)) = 2gi/b(e)

.

i

With Fact 1, we now consider the following two cases:
Case 1): b(i)
i

(Internal Communication): In Case 1), Fact 1
implies that Problem (19) reduces to a single-machine prob-
lem (i.e., discarding (cid:80)
h∈H{·} in (19) and (20)). Note further
that if we temporarily ignore the workload-coupling con-
straint (20) and use the worker-PS ratio in (2), Problem (19)
can be decoupled across resources and simpliﬁed as:






(cid:88)

r∈R

h[t]sih[t](αr

Min pr
s.t. sih[t](αr

i γi + βr

i γi + βr
i )
i ) ≤ ˆC r

h[t],

Constraint (4) for given r, h




,



(22)

pswwpswpswwwpswwpspswwwhere each summand in (22) is an integer linear program
(ILP) having a trivial solution wih[t] = sih[t] = 0, ∀h ∈ H.
However, wih[t] = 0, ∀h ∈ H, clearly violates the workload
constraint (20). Thus, when (22) is optimal, there should be
exactly one machine h(cid:48) ∈ H with wih(cid:48)[t] ≥ 1 and exactly
one machine h(cid:48)(cid:48) ∈ H with sih(cid:48)(cid:48)[t] ≥ 1. This observation
shows that the optimal solution of (19) tends to favor |Pi[t]| =
|Wi[t]| = 1 if the workload constraint (20) is not binding.

Notice that the workload constraint (20) in Case 1) be-
comes γisih[t] ≥ Vi[t](τi + 2giγi
). This implies the following
b(i)
i Fi
simple solution: We can ﬁrst sort each physical machine
h according to (cid:80)
r∈R pr
i ) and calculate the
minimum number of sih[t] = Vi[t](τi + 2giγi
)/γi from the
b(i)
i Fi
workload constraint. The last step is to check if the machine
satisfy the resource capacity constraint (18) and constraint
(4). If so, we return the schedule (wih[t], sih[t]) and the
corresponding cost value.

i γi + βr

h[t](αr

Case 2): b(e)

i

(External Communication): For those settings
that do not satisfy |Pi[t]| = |Wi[t]| = 1 and Pi[t] = Wi[t],
Fact 1 indicates that parameter servers and workers are com-
municating at external rate b(e)
. In this case, the workload
constraint (20) simply becomes: (cid:80)
h∈H wih[t] ≥ Vi[t](τi +
2giγi
b(e)
i Fi

). Then, we can rewrite Problem (19) as:

i

(cid:88)

h [t]wih[t] + ps
pw

h[t]sih[t]

Minimize
wih[t],sih[t],∀h

h∈H
i wih[t] + βr
subject to αr
(cid:88)

i sih[t] ≤ ˆC r

h[t], ∀h, r,

wih[t] ≤ Fi,

wih[t] ≥ Vi[t]

(cid:88)

h∈H

h∈H

(cid:19)

,

(cid:18)

τi +

2giγi
b(e)
i Fi
h[t] (cid:44) (cid:80)

h [t] (cid:44) (cid:80)

where pw
h[t]βr
i
denote the aggregated prices of all resources of allocating
workers and PSs on machine h in time t, respectively.

i and ps

r∈R pr

r∈R pr

h[t]αr

Unfortunately, Problem (23) is a highly challenging in-
teger programming problem with generalized packing and
cover type constraints (i.e., integer variables rather than 0-
1 variables) in (24)–(26), respectively, which is clearly NP-
Hard. Also, it is well-known that there are no polynomial
time approximation schemes (PTAS) even for the basic set-
cover and bin-packing problems unless P = NP [31]. In what
follows, we will pursue an instance-dependent constant
ratio approximation scheme to solve Problem (23) in this
paper. To this end, we propose a randomized rounding
scheme: First, we solve the linear programming relaxation
of Problem (23). Let { ¯wih[t], ¯sih[t], ∀h, t} be the fractional
optimal solution. We let δ ∈ (0, 1] be a parameter. Let
Gδ be a constant (the notation Gδ signiﬁes that Gδ is
dependent on δ) to be deﬁned later, and let w(cid:48)
ih[t] =
Gδ ¯wih[t], s(cid:48)
ih[t] = Gδ ¯sih[t], ∀h, t. Then, we randomly round
ih[t], s(cid:48)
{w(cid:48)
ih[t], ∀h, t} to obtain an integer solution as follows:
(cid:40)

wih[t] =

sih[t] =

(cid:40)

(cid:100)w(cid:48)
(cid:98)w(cid:48)

(cid:100)s(cid:48)
(cid:98)s(cid:48)

ih[t](cid:101), with probability w(cid:48)
ih[t](cid:99), with probability (cid:100)w(cid:48)
ih[t](cid:101), with probability s(cid:48)
ih[t](cid:99), with probability (cid:100)s(cid:48)

ih[t] − (cid:98)w(cid:48)
ih[t](cid:101) − w(cid:48)

ih[t](cid:99),
ih[t],

ih[t] − (cid:98)s(cid:48)
ih[t](cid:101) − s(cid:48)

ih[t](cid:99),
ih[t].

(27)

(28)

We will later prove in Theorem 3 (when 0 < Gδ ≤ 1) and
Theorem 4 (when Gδ > 1) that the approximation ratio of

(23)

(24)

(25)

(26)

8

this randomized rounding scheme in (27)-(28) enjoys a ratio
that is independent on the problem size.

Lastly, summarizing results in Cases 1) – 2) yields the fol-

lowing approximation algorithm for solving Problem (19):

Algorithm 4: Solving θ(t, v) (i.e., Problem (19)).

Initialization:
1. Let wih[t] = sih[t] = 0, ∀h. Let h = 1. Pick some δ ∈ (0, 1].
Let Gδ be deﬁned as in Eq. (29) or Eqn (30). Let D =
(cid:100)v(τi + 2giγi/(b(i)
i Fi))(cid:101). Let h∗ = ∅. Let cost-min= ∞.
Choose some integer S ≥ 1. Let iter ← 1.

Handling Internal Communication:
2. Sort machines in H according to (cid:80)

r∈R pr
in non-decreasing order into h1, h2, ..., hH .

h[t](αr

i γi + βr
i )

(cid:16)

3. Calculate the minimum number of sih[t] = Vi[t]

τi +

(cid:17)

/γi.

2giγi
b(i)
i Fi

i γi + βr

h[t]sih[t](αr

i ) and h∗ = h.

4. If Constraint (4) is not satisﬁed, go to Step 7.
5. If Constraint (24) is not satisﬁed, go to Step 7.
6. Return cost-min(cid:80)
r∈R pr
7. Let h ← h + 1. If h > H, stop; otherwise, go to Step 2.
Handling External Communication:
8. Solve the linear programming relaxation of Problem (23).
Let { ¯wih[t], ¯sih[t], ∀h, t} be the fractional optimal solu-
tion.
9. Let w(cid:48)
10. Generate an integer solution {wih[t], sih[t], ∀h, t} follow-
ing the randomized rounding scheme in (27)–(28).
11. If {wih[t], sih[t], ∀h, t} is infeasible or iter < S, then

ih[t] = Gδ ¯sih[t], ∀h, t.

ih[t] = Gδ ¯wih[t], s(cid:48)

iter ← iter + 1, go to Step 10.

Final Step:
12. Compare the solutions between internal and external
cases. Pick the one with the lowest cost among them
and return the cost and the corresponding schedule
{wih[t], sih[t], ∀h, t}.

In the internal communication part of Algorithm 4, we
ﬁrst sort the machines and then check each machine one by
one (Step 2). We calculate the minimum number of sih[t]
needed to satisfy the learning workload demand D (Step
3). If Constraint (4) is satisﬁed (Step 4), we further check
the resource capacity constraint (18) (Step 5). If we detect a
machine with all above constraints satisﬁed, we return the
cost and schedule accordingly (Step 6). After exploring one
machine, we move on to the next one as long as it is not the
last machine (Step 7). The external communication part is
based on LP relaxation (Step 8) and randomized rounding
(Step 9-12). Note that the randomized rounding will ﬁnd
at most S integer feasible solutions (Step 12). Finally, we
choose the lowest cost among the solutions from the internal
and external communication parts (Step 13).

4.4 Theoretical Performance Analysis

We now examine the competitive ratio of our PD-ORS
algorithm. Note that the key component in PD-ORS is our
proposed randomized rounding scheme in (27)–(28), which
is in turn the foundation of Algorithm 1. Thus, we ﬁrst prove
the following results regarding the randomized rounding
algorithm. Consider an integer program with generalized
cover/packing constraints: min{c(cid:62)x : Ax ≥ a, Bx ≤

9

Clearly, the left-hand-side (LHS) of the condition is the 45◦
straight line. In order for the condition to hold, the curve of
RHS should fall under this straight line. Based on typical
computing cluster parameters, we set Wb to 15, and set
r (cid:44) RH + 1 to 401 (R = 4, H = 100). We can see from Fig. 5
that as Wa increases, the curve of RHS crosses the dashed
line of LHS at a smaller δ-value. This means that, the larger
the value of Wa, the easier for 1−(
2 to become
positive. Hence, the probabilistic feasibility characterization
in Lemma 1 is useful for typical system parameters in
practice.

2
GδWa

δ )) 1

ln( 3m

2) Gδ > 1: We have the following approximation result

(see proof in Appendix B):
Lemma 2 (Rounding). Let Wa (cid:44) min{ai/[A]ij : [A]ij > 0}
and Wb (cid:44) min{bi/[B]ij : [B]ij > 0}. Let δ ∈ (0, 1] be a given
constant and deﬁne Gδ as:

Gδ (cid:44) 1 +

ln(3m/δ)
Wa

+

(cid:115)

(cid:18) ln(3m/δ)
Wa

(cid:19)2

+

2 ln(3m/δ)
Wa

.

Then, with probability greater than 1 − δ, ˆx achieves a cost at
most 3Gδ
times the cost of ¯x. Meanwhile, ˆx satisﬁes Pr
(Bˆx)i >
δ
(cid:111)
bi(1 + (

2 )Gδ, ∃i

ln( 3r

(cid:110)

≤ δ
3r .

δ )) 1

3
GδWb

Several important remarks for Lemmas 1 and 2 are

summarized as follows:

i) Note that Alg. 4 is a randomized algorithm. Therefore,
its performance is also characterized probabilistically, and
δ is used for such probabilistic characterization. Here, it
means that with probability 1−δ, one achieves an approx-
imation ratio at most 3Gδ
and a probabilistic feasibility
δ
guarantee as stated in Lemma 1 when 0 < Gδ ≤ 1 and
Lemma 2 when Gδ > 1. In other words, the statements
mean that the probability of getting a better approxi-
mation ratio is smaller under randomized rounding (i.e.,
better approximation ratio ⇒ smaller 3Gδ
δ ⇒ larger δ ⇒
smaller probability 1 − δ). That is, the trade-off between
the approximation ratio value and its achieving probabil-
ity is quantiﬁed by δ. A larger δ implies a smaller approx-
imation ratio, but the probability of obtaining a feasible
solution of this ratio is also smaller (i.e., more rounds of
rounding needed). Interestingly, for δ = 1, Lemmas 1 and
2 indicate that there is still non-zero probability to achieve
an approximation ratio not exceeding 3Gδ.
ii) Note that if we pick Gδ ∈ (0, 1], the approximation ratio
3Gδ
δ decreases (the smaller the approximation ratio, the
better) as δ increases based on Eqn. (35) in Appendix A.
However, the growth rate of Gδ is slower compared to
that of δ due to the log operator. On the other hand, if
we pick Gδ > 1, 3Gδ
δ decreases as δ increases according
to Eqn. (38) in Appendix B. Therefore, the approximation
ratio is ultimately controlled by parameter δ. Also, the
theoretical approximation ratio 3Gδ
is conservative. Our
δ
numerical studies show that the approximation ratio per-
formance in reality is much smaller than 3Gδ
δ .
iii) The probabilistic guarantee of the cover constraint
(Ax ≥ a) when 0 < Gδ ≤ 1 and packing constraint
(Bx ≤ b) when Gδ > 1, is unavoidable and due to
the fundamental hardness of satisfying both cover and

Fig. 5: The feasibility study.

+

, B ∈ Rr×n

+, and c ∈ Rn

+}, where A ∈ Rm×n

b, x ∈ Zn
+ , a ∈ Rm
+ ,
b ∈ Rr
+. Let ¯x be a fractional optimal solution.
Consider the randomized rounding scheme: Let x(cid:48) = Gδ ¯x
for some Gδ (to be speciﬁed). Randomly round x(cid:48) to ˆx ∈ Zn
+
as: ˆxj = (cid:100)x(cid:48)
j(cid:99) o.w. Note
that in the rounding process, if Gδ > 1 (Gδ ∈ (0, 1]), the
packing (cover) constraint is prone to be violated and the
cover (packing) constraint is easier to be satisﬁed. Hence,
depending on which constraint is more preferred to be
feasible, we consider two cases with respect to Gδ.

j(cid:99) and ˆxj = (cid:98)x(cid:48)

j(cid:101) w.p. x(cid:48)

j − (cid:98)x(cid:48)

1) 0 < Gδ ≤ 1: We have the following approximation

result (see proof in Appendix A):
Lemma 1 (Rounding). Let Wa(cid:44)min{ai/[A]ij : [A]ij>0} and
Wb(cid:44)min{bi/[B]ij : [B]ij>0}. Let δ ∈ (0, 1] be a given constant
and deﬁne Gδ as:

Gδ (cid:44) 1 +

3 ln(3r/δ)
2Wb

−

(cid:115)

(cid:19)2

(cid:18) 3 ln(3r/δ)
2Wb

+

3 ln(3r/δ)
Wb

.

Then, with probability greater than 1−δ, ˆx achieves a cost at most
3Gδ
(Aˆx)i ≤
δ

times the cost of ¯x. Meanwhile, ˆx satisﬁes Pr

(cid:110)

ai(1 − (

2
GδWa

ln( 3m

δ )) 1

2 )Gδ, ∃i

≤ δ

3m .

(cid:111)

ln( 3m

δ )) 1

2
GδWa

Remark 1 (Discussions on Feasibility). An insightful remark
of Lemma 1 is in order. Note that, theoretically, the expres-
sion 1 − (
2 in Lemma 1 could become nega-
tive. In this case, the last probabilistic inequality in Lemma 1
trivially holds and is not meaningful in characterizing the
feasibility, even though the inequality remains valid. In
order for the probabilistic statement to be meaningful in
characterizing the feasibility of the integer linear program,
ln( 3m
we solve for δ by enforcing 1 − (
2 > 0, which
yields δ ≥ 3m/e
. On the other hand, we prefer δ to
be small since it bounds the feasibility violation probability
and approximation ratio achievability in Lemma 1. Hence,
the smaller the value of 3m/e
, the less restrictive the
condition δ ≥ 3m/e

2
GδWa

δ )) 1

Gδ Wa
2

Gδ Wa
2

Gδ Wa
2

is.

To gain a deeper understanding on how restrictive the
condition δ ≥ 3m/e
is, we conduct a case study
and the results are illustrated in Fig. 5. Here, we let RHS
(cid:44) 3m/e
for convenience. We vary δ from 0.02 to 0.1.

Gδ Wa
2

Gδ Wa
2

0.020.040.060.080.1The value of 00.020.040.060.080.1The value of RHSWa=30=RHSWa=40Wa=35packing constraints, which are of conﬂicting nature: Any
strategy trying to better satisfy the packing constraints
(multiplying a Gδ-factor with Gδ ∈ (0, 1]) may increase
the probability of violating the cover constraints, and the
probability of violating the packing constraints may be
increased otherwise. However, the probabilistic bound
here is for worst case and may be pessimistic.
iv) The results in Lemmas 1 and 2 are in fact applicable
for general ILP with mixed cover/packing constraints.
Hence, the results and their insights in Lemmas 1 and
2 could be of independent theoretical interest.
By specializing Lemma 1 and Lemma 2 with parameters
in Problem (23), we have the following approximation re-
sults for Algorithm 4. The ﬁrst result corresponds to the case
where the feasibility of the resource constraint (packing) is
more favored, i.e., 0 < Gδ ≤ 1:

Theorem 3 (Approximation Performance of Alg. 4 When
Resource Constraint Feasibility is Favored). Let W1 (cid:44)
Vi[t](cid:0)τi + 2giγi
i , ∀r, h},
b(e)
i Fi
and δ ∈ (0, 1]. Deﬁne Gδ as:

(cid:1), W2 (cid:44) min{Fi, ˆC r

h[t]/αr

h[t]/βr

i , ˆC r

3 ln(3(RH +1)/δ)
2W2

Gδ (cid:44) 1+
(cid:115)

−

(cid:18) 3 ln(3(RH + 1)/δ)
2W2

(cid:19)2

+

3 ln(3(RH +1)/δ)
W2

.

(29)

Then, with probability greater than 1 − δ, Algorithm 4 ob-
tains a schedule {wih[t], sih[t], ∀t, h} that has an approx-
imation ratio at most 3Gδ
δ with Pr{LHS(26) ≤ W1(1 −
δ )) 1
2 )Gδ, ∃i} ≤ δ
(
3 .

ln( 3

2
GδW1

The next result corresponds to the case where the fea-
sibility of the workload constraint (cover) is more favored,
i.e., Gδ > 1:

Theorem 4 (Approximation Performance of Alg. 4 When
Workload Constraint Feasibility is Favored). Let W1 (cid:44)
Vi[t](cid:0)τi + 2giγi
i , ∀r, h},
b(e)
i Fi
and δ ∈ (0, 1]. Deﬁne Gδ as:
(cid:115)

(cid:1), W2 (cid:44) min{Fi, ˆC r

h[t]/αr

h[t]/βr

i , ˆC r

ln(3/δ)
W1

+

(cid:19)2

(cid:18) ln(3/δ)
W1

+

2 ln(3/δ)
W1

.

(30)

Gδ (cid:44) 1 +

Then, with probability greater than 1 − δ, Algorithm 4 ob-
tains a schedule {wih[t], sih[t], ∀t, h} that has an approxima-
tion ratio at most 3Gδ
h[t]Gδ(1 +
ln( 3(HR+1)
(

δ with Pr{LHS(24) > ˆC r
2 )} ≤

)) 1

δ
3(HR+1) .

3
GδW2

δ

Note that Eqn. (25) is guaranteed in practice since the
number of samples is typically far more than the number
of workers. The competitive ratio of our online algorithm
is the worst-case upper bound of the ratio of the overall
utility of admitted jobs devided by the ofﬂine optimal
solution of Problem DMLRS to the total utility of admitted
jobs achieved by Algorithm 1 in the overall time horizon.
Theorems 3 and 4 follow directly from Lemmas 1 and 2,
respectively, and we omit the proof here for brevity. Based
on these results, we can establish the overall competitive
ratio for Algorithm 1 as follows.

Theorem 5 (Competitive Ratio of Alg 1 when 0 < Gδ ≤ 1).
Let δ, Gδ and W1 be as deﬁned in Theorem 3. Let U r and L

10

be as deﬁned in (13) and (14), respectively. Then, with probability
greater than (1−(δ/3)S)T KiEi , PD-ORS in Algorithm 1 returns
a feasible solution that is 6Gδ

δ maxr∈R(1, ln U r

L )–competitive.

Theorem 6 (Competitive Ratio of Alg 1 when Gδ > 1). Let δ,
Gδ and W2 be as deﬁned in Theorem 4. Let U r and L be as deﬁned
in (13) and (14), respectively. Then, with probability greater than
(1 − (δ/3(HR + 1))S)T KiEi , PD-ORS in Algorithm 1 returns
a feasible solution that is 6Gδ

δ maxr∈R(1, ln U r

L )–competitive.

It is worth pointing out that in Theorems 5 and 6, the fea-
sibility achieving probability values, i.e., (1 − (δ/3)S)T KiEi
and (1 − (δ/3(HR + 1))S)T KiEi , can controlled by choosing
appropriate values of δ and S (i.e., rounds of rounding) to
offset the impact of total number of DP iterations T KiEi.
The smaller δ and the larger S are, the higher the feasibility
achieving probability. Theorems 5 and 6 can be proved by
weak duality and the approximation results in Theorems 3
and 4. We provide a proof in Appendix C.

Theorem 7 (Polynomial Running Time). By combin-
ing Algorithms 1–4,
time complexity of PD-ORS is
O((cid:80)|I|
i=1 T K 2

i (H 3 + S)), which is polynomial.

i E2

the

Proof. When solving θ(t, v) using Algorithm 4,
it takes
O(H log H) iterations to sort machines in internal commu-
nication case under each time slot t and looping all machines
to calculate the minimum number sih[t] takes O(H). Thus,
it takes (H log H) time for the internal communication part
in Algorithm 4. For the external communication part in
Algorithm 4, solving the LP relaxation of Problem (23) can
be approximately bounded O(H 3) if we use a polynomial
time LP solver (e.g., Vaidya’s algorithm [33]). According
to Algorithm 4, the rounding time is proportional to S.
Hence, the running time for the external communications
part is upper bounded by O(|H|3 + S). Combining the
discussions above, the running time complexity of Algo-
rithm 4 is O(H log H + H 3 + S) = O(H 3 + S). Moreover,
the number of states (t, v) is O(T KiEi) in the dynamic
programming (DP) for each job i, and the time complexity
of executing DP is O(KiEi). Thus, the time complexity is
O(T K 2
i ) in DP. In Algorithm 1, the number of steps in
the main loop is equal to the number of jobs. Therefore,
the overall running time complexity can be computed as
O((cid:80)|I|

i E2

i (H 3 + S)).

i=1 T K 2

i E2

5 NUMERICAL RESULTS
In this section, we conduct simulation studies to evaluate
the efﬁcacy of our proposed PD-ORS algorithm. We test
an ML system with jobs parameters generated uniformly
at random from the following intervals: Ei ∈ [50, 200],
Ki ∈ [20000, 500000], gi ∈ [30, 575] MB, τi ∈ [10−5, 10−4]
time slots, γi ∈ [1, 10], Fi ∈ [1, 200]. We consider four
types of resources: GPU, CPU, memory, and storage. For fair
comparisons, following similar settings in [34] [35] [36], we
set resource demand of each worker as follows: 0–4 GPUs,
1–10 vCPUs, 2–32 GB memory, and 5–10GB storage. We set
resource demand of each parameter server as follows: 1–10
vCPUs, 2–32GB memory and 5-10GB storage. The resource
capacity of each physical machine is set roughly 18 times of
the resource demands of a worker/PS following EC2 C5n
instances [37]. We set the job arrival pattern according to the

Google Cluster data [38], but with normalized job arrival
rates in alternating time-slots as follows: the arrival rates
are 1/3 and 2/3 in odd and even time-slots, respectively.
For fair comparisons, we adopt the Sigmoid utility function
θ1
[6], [39]: ui(t − ai) =
1+eθ2(t−ai−θ3 ) , where θ1 ∈ [1, 100]
indicates the priority of job i, θ2 indicates how critical the
time is for the job i, and θ3 ∈ [1, 15] is the estimated target
completion time. We set θ2 = 0 for time-insensitive jobs
(10% of jobs), θ2 ∈ [0.01, 1] for time-sensitive jobs (55% of
jobs) and θ2 ∈ [4, 6] for time-critical jobs (35% of jobs).

We ﬁrst compare our PD-ORS algorithm with three
baseline job scheduling policies: (1) FIFO in Hadoop and
Spark [40], where the jobs are processed in the order of their
arrival times. In our setting, the ﬁxed number of workers
(parameter servers) is between 1 to 30, (2) Dominant Resource
Fairness Scheduling (DRF) in Yarn [41] and Mesos [42], where
the jobs are scheduled based on their dominant resource
share in the cloud to achieve its max-min fairness. The num-
ber of workers and parameter servers are computed and al-
located dynamically, and (3) Dorm [36], where the numbers
of workers (parameter servers) are computed and placed by
an MILP resource utilization maximization problem with
fairness and adjustment overhead constraints. Workers and
parameter servers are placed in a round-robin fashion on
available machines in Baselines (1) and (2). The comparison
results are shown in Figs. 6 and 7. In Fig. 6, we set T = 20
and I = 50, while in Fig. 7, we set T = 20 and H = 100. We
can see that PD-ORS signiﬁcantly outperforms other policies
and the gains in total utility becomes more pronounced as
the numbers of jobs and machines increase.

Next, we compare our PD-ORS algorithm with the OA-
SiS algorithm in [6], which is also a dynamic scheduling
scheme. As mentioned earlier, the key difference in OASiS
is that parameter servers and workers are located on two
strictly separated sets of machines (i.e., no co-located work-
ers and PSs). Here, we let H = 100 and T = 20. For OASiS,
half of the machines host parameter servers and the other
half host workers. For fair comparisons, both algorithms
adopt the same Sigmoid utility function. The comparison
results are shown in Fig. 8. We can see that PD-ORS outper-
forms OASiS by allowing co-located parameter servers and
workers. We can see from Fig. 8 that the performance gap
between PD-ORS and OASiS widens as the number of jobs
increases, which implies that PD-ORS is more scalable. This
is due to the advantage afforded by colocation of workers
and parameter servers, which allows each physical machine
to be fully utilized. On the other hand, the strict separation
of workers and parameter servers in OASiS may lead to the
inability of placing workers on server-side machines, should
there be available resources or vice verse.

Next, we investigate the actual training time (completion
time - arrival time) under different methods, where T = 80,
H = 30 and I = 100. The median of the actual training
time is shown in Fig. 9. Here, we simply set its training
time to T (i.e., 80) if the job cannot be ﬁnished within the
scheduling time span T . As we can see from Fig. 9, PD-ORS
outperforms other scheduling policies, i.e., it has the small-
est median time. Also, due to the co-location advantage of
PD-ORS, its median time is smaller compared to OASiS,
where workers and parameter servers are placed in strictly
separated sets of machines. We expect that the difference

11

between PD-ORS and OASiS will become more noticeable
as the number of machines or the capacity of each machine
increases since it will allow more co-location placements.

Next, we demonstrate the competitive ratio of our al-
gorithm PD-ORS, which is the ratio between the total job
utility of the ofﬂine optimal solution and the total job utility
achieved by PD-ORS. Recall that Problem DMLRS is a non-
convex problem with constraints (e.g., Eq. (1)) that are not
amenable to be directly solved by conventional optimiza-
tion techniques. To obtain its ofﬂine optimum, all possible
combinations of wih[t], sih[t], ∀i, h, t need to be considered,
which is time prohibitive. Thus, we limit the number of jobs
I to 10 and time span T to 10, and the result is shown in
Fig. 10. As we can see from the ﬁgure, the performance ratio
is between 1.0 to 1.4, indicating that our proposed algorithm
PD-ORS has a good competitive ratio performance.

Lastly, we examine the performance of the randomized
rounding scheme in Algorithm 4, which is the key of PD-
ORS. We evaluate the rounding performance in terms of the
ratio between the optimal total utility and the total utility
obtained by our algorithm. The optimal utility is computed
using the Gurobi optimization solver. We let H = 100,
I = 50, T = 20. We vary the pre-rounding gain factor Gδ
(Theorems 3 and 4) from 0.2 to 1.2. The results are shown
in Fig. 11. The packing constraints are easier to satisfy with
a smaller Gδ, while the cover constraints are prone to be
violated as Gδ gets smaller. In our experiments, if the total
rounds of randomized rounding before we ﬁnd an integer
feasible solution exceeds a preset threshold (e.g, 5000), we
will discard the corresponding job. Theorem 3 suggests that
there is a trade-off: if we set Gδ to be close to one to
pursue a better total utility result, the rounding time could
be large to obtain a feasible solution. As Gδ increases, the
probability of violating the packing constraints increases,
meaning we need to have more rounding attempts to obtain
an integer feasible solution. However, according to our
numerical experiences, if the machine’s resource capacity
is relatively large compared to the jobs’ resource demands
per worker/PS, the number of rounding attempts is small
and not sensitive to the variation of Gδ. On the other
hand, as Gδ decreases, the probability of violating the cover
constraint increases. However, in practice, the model usually
converges with fewer number of iterations than the pre-
deﬁned training epochs since the required number of epochs
is usually overestimated [43]. In other words, the violation
of the cover constraint in one iteration may be acceptable.

As we can see from Fig. 11, the best approximation ratio
value is achieved when Gδ = 1. This is because if Gδ
approaches 0, it implies that δ decreases at a larger rate
(cf. Eq. (29)), resulting the increment of the performance
ratio. On the other hand, if Gδ goes to inﬁnity, it implies δ
decreases (cf. Eq. (30)), resulting in a much faster increment
of the performance ratio. Also, we can see from Fig. 11 that
the performance ratios for all choices of Gδ are much better
than the theoretical bounds in Theorems 3 and 4, which
shows that the approximation ratio is much tighter than the
worse-case bound suggested in Theorems 5 and 6.

Next, we show further experimental results with real-
world data traces. We ﬁrst compare our PD-ORS algorithm
with baseline scheduling algorithms, where we follow job
arrivals exactly based on timestamps recorded in the Google

12

Fig. 6: Total utility with increasing
number of machines (synthetic data).

Fig. 7: Total utility with increasing
number of jobs (synthetic data).

Fig. 8: Utility comparison between
PD-ORS and OASiS with increasing
number of jobs.

Fig. 9: Median of actual training time
comparison.

Fig. 10: Competitive ratio.

Fig. 11: Impact of pre-rounding gain
factor Gδ on competitive ratio.

Fig. 12: Total utility with increasing
number of machines (Google cluster
data trace).

Fig. 13: Total utility with increasing
number of jobs (Google cluster data
trace).

Fig. 14: Total utility with increasing
number of machines [T=80, I=100,
(10%, 55% , 35%)].

Cluster data [38] by scaling down the original job trace (i.e.,
a “snippet” of the trace). Here, we set T = 80, I = 100 and
H = 30. The comparison results are shown in Figures 12 -
13. Similarly, as we can see from the ﬁgures, our algorithm
PD-ORS outperforms other scheduling policies. In addition,
due to the co-location advantage of PD-ORS, it achieves
more total job utility compared to OASiS.

In the previous experiments, we have set the portions
for time-insensitive jobs, time-sensitive jobs and time-critical
jobs to 10%, 55% and 35%, respectively, which follows the
default setting in [6] for fair comparison. Theoretically, the
larger the portion of time-sensitive and time-critical jobs is,
the better the performance is in terms of job utility compared
to other scheduling policies. Based on the Google trace

analysis [44], there are four categories of scheduling class
of a job to indicate the latency sensitivity of the job, where
we label class 0 as time-insensitive, Classes 1 and 2 as time-
sensitive, and Class 3 as time-critical. In order to follow the
practical setting in the trace, we roughly set the ratio to
30%, 69% and 1%. We set T = 80. The number of machines
increases from 10 to 50 with the number of job ﬁxed to 100,
and the number of jobs increases from 20 to 100 with the
number of machines ﬁxed at 30. We let Figs. 14 and 16
follow the previous ratio setting (i.e., 10%, 55% and 35%),
and Figs. 15 and 17 follow the revised ratio setting (i.e.,
30%, 69% and 1%). We examine the utility gain compared to
OASiS, where it is normalized. We present our experimental
results in Figs. 14 – 17. We can see from the ﬁgures that as

1020304050The number of jobs200400600800100012001400Total utilityPD-ORSOASiSPD-ORSOASiSDORMDRFFIFO05101520253035Actual training time24681012The number of machines11.11.21.31.4Competitive ratio0.20.40.60.811.2ThevalueofG05101520Competitive ratio1020304050The number of machines1000150020002500300035004000Total utilityPD-ORSOASiS13

Fig. 15: Total utility with increasing
number of machines [T=80, I=100,
(30%, 69% , 1%)].

Fig. 16: Total utility with increasing
number of jobs [T=80, H=30, (10%,
55% , 35%)].

Fig. 17: Total utility with increasing
number of jobs [T=80, H=30, (30%,
69% , 1%)].

the portion of critical jobs decreases by 34%, the utility gain
becomes smaller. That is, the advantage of our proposed
algorithm PD-ORS becomes less prominent.

guarantee. Collectively, our results expand the theoretical
frontier of online optimization algorithm design for resource
optimization in distributed machine learning systems.

We note that although in theory we can compare our
PD-ORS algorithm (a special case with utility function
u(x) = x) with Optimus in [23] (which also takes co-
location into consideration), it is not straightforward to do
so in practice. Optimus requires an ofﬂine stage to estimate
the θ-parameters of the speed function f (pj, wj) (cf. θ0–θ3
in [ [23], Eq. (3)] for asynchronous training and θ0–θ4 for
synchronous training in [[23], Eq. (4)]). Estimating these pa-
rameters requires speciﬁc hardware and software packages
that are not available in our current experimental environ-
ment. Due to the above computing resource limitations and
time constraints, we are unable to conduct experiments to
directly compare PD-ORS and Optimus in this work. Also,
our focus in this work is on scheduling algorithmic designs
for deep learning training with main contributions being on
the theoretical aspects (proving rigorous scheduling perfor-
mance guarantees). Implementing our PD-ORS algorithm
in a similar testbed environment and having a comparison
with Optimus is very interesting and will be our next step
in future studies.

6 CONCLUSION

In this paper, we investigated online resource scheduling
for distributed machine learning jobs in a shared computing
cluster. We considered the most general setting that workers
and parameter servers can be co-located on the same set
of physical machines. We showed that this problem can be
formulated as a challenging integer nonlinear programming
problem with non-deterministic constraints. We developed
an efﬁcient online scheduling algorithm with competitive
ratio guarantee. Our main contributions are three-fold: i)
We developed a new analytical model that jointly considers
resource locality and allocation; ii) Through careful exam-
inations of worker-server conﬁguration relationships, we
resolved the locality ambiguity in the model and reduce
the problem to a mixed cover/packing integer program that
entails low-complexity approximation algorithm design; iii)
We proposed a meticulously designed randomized round-
ing algorithm to solve the mixed cover/packing integer
program and rigorously established its approximation ratio

REFERENCES

[1] M. Abadi, P. Barham et al., “TensorFlow: A system for large-scale

machine learning,” in Proc. of USENIX OSDI, 2016.

[2] T. Chen, M. Li, Y. Li, M. Lin, N. Wang, M. Wang, T. Xiao, B. Xu,
C. Zhang, and Z. Zhang, “MXNet: A ﬂexible and efﬁcient machine
learning library for heterogeneous distributed systems,” in Proc. of
NIPS Workshop on Machine Learning Systems (LearningSys), 2016.

[3] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,
T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison et al.,
“Pytorch: An imperative style, highperformance deep learning
library,” in In Advances in Neural Information Processing Systems,
2019, pp. 8024–8035.

[4] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick,
S. Guadarrama, and T. Darrell, “Caffe: Convolutional architecture
for fast feature embedding,” in Proc. of the 22nd ACM International
Conference on Multimedia, 2014, pp. 675–678.

[5] B.-G. Chun, B. Cho, B. Jeon et al., “Dolphin: Runtime optimization
for distributed machine learning,” in Proc. of ICML ML Systems
Workshop, 2016.

[6] Y. Bao, Y. Peng, C. Wu, and Z. Li, “Online job scheduling in
distributed machine learning clusters,” in Proc. of IEEE INFOCOM,
2018.

[7] M. Li, D. G. Andersen et al., “Scaling distributed machine learning
with the parameter server,” in Proc. of USENIX OSDI, 2014.
[8] T. M. Chilimbi, Y. Suzue, J. Apacible, and K. Kalyanaraman,
“Project Adam: Building an efﬁcient and scalable deep learning
training system,” in Proc. of USENIX OSDI, 2014.
J. Dean and S. Ghemawat, “Mapreduce: Simpliﬁed data processing
on large clusters,” in Commun. ACM, vol. 1, no. 51, 2008, pp. 107–
113.

[9]

[10] M. Isard, M. Budiu, Y. Yu, A. Birrell, and D. Fetterly, “Dryad: Dis-
tributed data-parallel programs from sequential building blocks,”
in In EuroSys 2007, 2007, pp. 59–72.

[11] F. Yan, O. Ruwase, Y. He, and T. Chilimbi, “Performance modeling
and scalability optimization of distributed deep learning systems,”
in Proc. of ACM KDD, 2015.

[12] P. Sun, Y. Wen, N. B. D. Ta, and S. Yan, “Towards distributed
machine learning in shared clusters: A dynamically-partitioned
approach,” in Proc. of IEEE Smart Computing, 2017.

[13] Q. Zhang, R. Zhou, C. Wu, L. Jiao, and Z. Li, “Online scheduling of
heterogeneous distributed machine learning jobs,” in Proceedings
of the Twenty-First International Symposium on Theory, Algorithmic
Foundations, and Protocol Design for Mobile Networks and Mobile
Computing, 2020, pp. 111–120.

[14] H. Mao, M. Alizadeh, I. Menache, and S. Kandula, “Resource
management with deep reinforcement learning,” in Proc. of ACM
HotNets, 2016.

[15] W. Chen, Y. Xu, and X. Wu, “Deep reinforcement learning for
multi-resource multi-cluster job scheduling,” in Proc. of IEEE
ICNP, 2017.

1020304050The number of machines01020Utility gain (%)1020304050The number of machines05000Total utilityPD-ORSPD-ORSOASiS20406080100The number of jobs020Utility gain (%)20406080100The number of jobs010002000Total utilityPD-ORSPD-ORSOASiS20406080100The number of jobs0510Utility gain (%)20406080100The number of jobs020004000Total utilityPD-ORSPD-ORSOASiS[16] H. Mao, M. Schwarzkopf, S. Venkatakrishnan, and M. Alizadeh,
“Learning graph-based cluster scheduling algorithms,” in Proc. of
SysML, 2018.

[17] H. Mao, M. Schwarzkopf, S. B. Venkatakrishnan, Z. Meng, and
M. Alizadeh, “Learning scheduling algorithms for data processing
clusters,” in Proc. of ACM SIGCOMM, 2019.

[18] A. Mirhoseini, A. Goldie, H. Pham, B. Steiner, Q. V. Le, and J. Dean,
“A hierarchical model for device placement,” in Proc. of ICLR,
2018.

[19] A. Mirhoseini, H. Pham, Q. V. Le, B. Steiner, R. Larsen, Y. Zhou,
N. Kumar, M. Norouzi, S. Bengio, and J. Dean, “Device placement
optimization with reinforcement learning,” in Proc. of ICML, 2017.
explained
in depth.” [Online]. Available: https://blog.kovalevskyi.com/
mxnet-distributed-training-explained-in-depth-part-1-b90c84bda725

[20] V. Kovalevskyi,

distributed

“MXNet

training

[21] “Distributed training in MXNet.” [Online]. Available: https:
//mxnet.incubator.apache.org/faq/distributed training.html
[22] P. Goyal, P. Dolla, R. Girshick, P. Noordhuis, L. Wesolowski,
A. Kyrola, A. Tulloch, Y. Jia, and K. He, “Accurate, large minibatch
SGD: Training imagenet in 1 hour,” arXiv preprint arXiv:1706.02677,
2017.

[23] Y. Peng, Y. Bao, Y. Chen, C. Wu, and C. Guo, “Optimus: An
efﬁcient dynamic resource scheduler for deep learning clusters,”
in Proc. of ACM EuroSys, 2018.

[24] “Apache Hadoop.” [Online]. Available: http://hadoop.apache.

org/.

[25] J. Dean, G. S. Corrado, R. Monga, K. Chen, M. Devin, Q. V. Le,
M. Z. Mao, M. Ranzato, A. Senior, P. Tucker, K. Yang, and A. Y. Ng,
“Large scale distributed deep networks,” in Proceedings of the 25th
International Conference on Neural Information Processing Systems -
Volume 1, ser. NIPS’12. USA: Curran Associates Inc., 2012, pp.
1223–1231.

[26] T. Cheatham, A. Fahmy, D. Siefanescu, and L. Valiani, “Bulk
synchronous parallel computing-a paradigm for transportable
software,” in Hawaii International Conference on Systems Sciences,,
2005.

[27] M. S. Bazaraa, H. D. Sherali, and C. M. Shetty, Nonlinear Program-
ming: Theory and Algorithms, 3rd ed. New York, NY: John Wiley
& Sons Inc., 2006.

[28] “Multi-worker

training with

keras.”

[Online]. Avail-

able:
worker with keras

https://www.tensorﬂow.org/tutorials/distribute/multi

[29] “Run deep learning with paddlepaddle on kubernetes,”
2017. [Online]. Available: https://kubernetes.io/blog/2017/02/
run-deep-learning-with-paddlepaddle-on-kubernetes/

[30] Z. Wang, K. Ji, Y. Zhou, Y. Liang, and V. Tarokh, “Spiderboost:
A class of faster variance-reduced algorithms for nonconvex opti-
mization,” in arXiv preprint arXiv:1810.10690, 2018.

[31] D. S. Hochbaum, Approximation Algorithms for NP-Hard Problems,

D. S. Hochbaum, Ed. PWS Publishing Company, 1997.

[32] N. Buchbinder and J. (Sefﬁ) Naor, The Design of Competitive Online
Algorithms via a Primal-Dual Approach. Now Publishers Inc., feb
2009, vol. 3.

[33] P. M. Vaidya, “An algorithm for linear programming which re-
quires o(((m + n)n2 + (m + n)1.5n)L) algorithmic operations,”
in 28th Annual IEEE Syposium on Foundations of Computer Science,
1987.

[34] M. Li, D. G. Andersen et al., “Scaling distributed machine learning
with the parameter server,” in Proc. of USENIX OSDI, 2014.
[35] T. M. Chilimbi, Y. Suzue, J. Apacible, and K. Kalyanaraman,
“Project adam: Building an efﬁcient and scalable deep learning
training system,” in Proc. of USENIX OSDI, 2014.

[36] P. Sun, Y. Wen, N. B. D. Ta, and S. Yan, “Towards distributed
machine learning in shared clusters: A dynamically-partitioned
approach,” in Proc. of IEEE Smart Computing, 2017.

[37] “Amazon ec2 instances.” [Online]. Available: https://aws.

amazon.com/ec2/instance-types

[38] C. Reiss, A. Tumanov et al., “Heterogeneity and dynamicity of
clouds at scale: Google trace analysis,” in Proc. of ACM SoCC, 2012.
[39] Z. Huang, B. Balasubramanian, M. Wang, T. Lan, M. Chiang, and
D. H. Tsang, “Need for speed: Cora scheduler for optimizing
completiontimes in the cloud,” in Proc. of IEEE INFOCOM, 2015.

[40] M. Zaharia, M. Chowdhury, M. J. Franklin, and et al, “Spark:
Cluster computing with working sets,” in n Proc. of USENIX
HotCloud, 2010.

[41] V. K. Vavilapalli, A. C. Murthy et al., “Apache hadoop yarn: Yet

another resource negotiator,” in Proc. of ACM SoCC, 2013.

14

[42] B. Hindman, A. Konwinski et al., “Mesos: A platform for ﬁne-
grained resource sharing in the data center,” in Proc. of USENIX
NSDI, 2011.

[43] M. Jeon, S. Venkataraman, A. Phanishayee, J. Qian, W. Xiao, and
F. Yang, “Multi-tenant gpu clusters for deep learning workloads:
Analysis and implications,” in MSR-TR-2018- 13, 2018.

[44] P. Minet, ´Eric Renault, I. Khouﬁ, and S. Boumerdassi, “Analyzing
traces from a google data center,” in International Wireless Com-
munications and Mobile Computing Conference (IWCMC), 2018, pp.
1167–1172.

[45] D. Bertsekas, Nonlinear Programming, 2nd ed. Athena Scientiﬁc,

1999.

Menglu Yu received her B.S. degree from the
Department of Electrical and Information Engi-
neering at Hunan University, China in 2014. She
is currently pursuing her Ph.D. degree in the
Department of Computer Science at Iowa State
University. Her primary research interests in-
clude optimization for distributed machine learn-
ing systems and data centers, as well as network
optimization.

Jia Liu (S’03–M’10–SM’16) is an Assistant Pro-
fessor in the Department of Electrical and Com-
puter Engineering at The Ohio State University,
where he joined in Aug. 2020. He received his
Ph.D. degree from the Department of Electri-
cal and Computer Engineering at Virginia Tech
in 2010. From Aug. 2017 to Aug. 2020, he
was an Assistant Professor in the Department
of Computer Science at Iowa State University.
His research areas include theoretical machine
learning, control and optimization for stochastic
networks, and optimization for data analytics infrastructure and cyber-
physical systems. Dr. Liu is a senior member of IEEE and a member of
ACM. He has received numerous awards at top venues, including IEEE
INFOCOM’19 Best Paper Award, IEEE INFOCOM’16 Best Paper Award,
IEEE INFOCOM’13 Best Paper Runner-up Award, IEEE INFOCOM’11
Best Paper Runner-up Award, and IEEE ICC’08 Best Paper Award. Dr.
Liu is a recipient of the NSF CAREER Award in 2020. He is a recipient
of the Google Faculty Research Award in 2020. He is also a winner of
the LAS Award for Early Achievement in Research from the College of
Liberal Arts and Sciences at Iowa State University in 2020, and the Bell
Labs President Gold Award in 2001. His research is supported by NSF,
AFOSR, AFRL, and ONR.

15

Chuan Wu received her B.Engr. and M.Engr.
degrees in 2000 and 2002 from the Depart-
ment of Computer Science and Technology, Ts-
inghua University, China, and her Ph.D. degree
in 2008 from the Department of Electrical and
Computer Engineering, University of Toronto,
Canada. Since September 2008, Chuan Wu has
been with the Department of Computer Science
at the University of Hong Kong, where she is cur-
rently a Professor. Her current research is in the
areas of cloud computing, distributed machine
learning systems and algorithms, and intelligent elderly care technolo-
gies. She is a senior member of IEEE, a member of ACM, and served as
the Chair of the Interest Group on Multimedia services and applications
over Emerging Networks (MEN) of the IEEE Multimedia Communication
Technical Committee (MMTC) from 2012 to 2014. She is an associate
editor of IEEE Transactions on Cloud Computing, IEEE Transactions
on Multimedia, ACM Transactions on Modeling and Performance Eval-
uation of Computing Systems, and IEEE Transactions on Circuits and
Systems for Video Technology. She was the co-recipient of the best
paper awards of HotPOST 2012 and ACM e-Energy 2016.

(S’11-M’12-SM’18)

received his B.E.
Bo Ji
and M.E. degrees in Information Science and
Electronic Engineering from Zhejiang University,
Hangzhou, China, in 2004 and 2006, respec-
tively, and his Ph.D. degree in Electrical and
Computer Engineering from The Ohio State Uni-
versity, Columbus, OH, USA, in 2012. Dr. Ji is an
Associate Professor in the Department of Com-
puter Science at Virginia Tech, Blacksburg, VA,
USA. Prior to joining Virginia Tech, he was an
Associate Professor in the Department of Com-
puter and Information Sciences and a faculty member of the Center for
Networked Computing at Temple University, where he was an Assistant
Professor from July 2014 to June 2020. He was also a Senior Member
of the Technical Staff with AT&T Labs, San Ramon, CA, from January
2013 to June 2014. His research interests are in the modeling, analysis,
control, optimization, and learning of computer and network systems,
such as wired and wireless networks, large-scale IoT systems, high
performance computing systems and data centers, and cyber-physical
systems. He currently serves on the editorial boards of the IEEE/ACM
Transactions on Networking, IEEE Internet of Things Journal, and IEEE
Open Journal of the Communications Society. Dr. Ji is a senior member
of the IEEE and a member of the ACM. He is a National Science Foun-
dation (NSF) CAREER awardee (2017) and an NSF CISE Research
Initiation Initiative (CRII) awardee (2017). He is also a recipient of the
IEEE INFOCOM 2019 Best Paper Award.

Elizabeth S. Bentley has a B.S. degree in Elec-
trical Engineering from Cornell University, a M.S.
degree in Electrical Engineering from Lehigh
University, and a Ph.D. degree in Electrical En-
gineering from University at Buffalo. She was
a National Research Council Post-Doctoral Re-
search Associate at the Air Force Research Lab-
oratory in Rome, NY. Currently, she is employed
by the Air Force Research Laboratory in Rome,
NY, performing in-house research and develop-
ment in the Networking Technology branch. Her
research interests are in cross-layer optimization, wireless multiple-
access communications, wireless video transmission, modeling and
simulation, and directional antennas/directional networking.

APPENDIX A
PROOF OF LEMMA 1

Proof. Consider the probabilities of the following “bad”
events: 1) c(cid:62) ˆx > 3Gδ
δ c(cid:62) ¯x; 2) ∃i such that (Aˆx)i < ai;
and 3) ∃i such that (Bˆx)i > bi. Note that events 2)
and 3) can be equivalently rewritten as: 2’) ∃i such that
< Wa} and 3’) ∃i such that E{(Bˆx)i
E{(Aˆx)i
> Wb}.
Since E{ˆx} = x(cid:48) = Gδ ¯x, by linearity of expectation, we have:

Wa
ai

Wb
bi

16

APPENDIX B
PROOF OF LEMMA 2
Proof. Similar to the case when 0 < Gδ ≤ 1, we can have the
expectation equations for the bad cases as in Eqns. (31)-(33).
We also can view each ˆxj as a sum of independent random
variables in [0, 1] in the same way. Then, we have that
(Aˆx)i
is also a sum of independent
random variables in [0, 1]. Using the Chernoff bound, we
have that:

j[A]ij ˆxj) Wa
ai

= ((cid:80)

Wa
ai

E{c(cid:62) ˆx} = c(cid:62)E{ˆx} = c(cid:62)Gδ ¯x = Gδc(cid:62) ¯x,

(cid:26)

= GδE

(A¯x)i

(cid:27)

≥ GδWa,

(cid:26)

(Aˆx)i

(cid:26)

(Bˆx)i

E

E

(cid:27)

(cid:27)

Wa
ai
Wb
bi

= GδE

(cid:26)

(B¯x)i

Wa
ai
Wb
bi

(cid:27)

≤ GδWb.

(33)

(cid:26)

Pr

(Aˆx)i

(31)

(32)

Pr{(Aˆx)i

Wa
ai

≤ (1 − (cid:15))GδWa} ≤ exp(−(cid:15)2 GδWa

2

).

Setting (1 − (cid:15))Gδ = 1, i.e., (cid:15) = 1 − 1
Gδ

, we have:

Then, by the Markov inequality and (31), we can obtain the
δ c(cid:62) ¯x
probability Pr

c(cid:62) ˆx > 3Gδ

≤ δ
3 .

(cid:110)

(cid:111)

Next, we note that each ˆxj can be viewed as a sum of
independent random variables in [0, 1] as follows: The ﬁxed
part of (cid:98)x(cid:48)
j(cid:99) random variables with value 1
with probability 1.

j(cid:99) is a sum of (cid:98)x(cid:48)

Then, we have that (Bˆx)i

is also
a sum of independent random variables in [0, 1]. Using the
Chernoff bound, we have

j[B]ij ˆxj) Wb
bi

Wb
bi

= ((cid:80)

(cid:110)

Pr

(Bˆx)i

Wb
bi

> (1 + (cid:15))GδWb

(cid:111)

(cid:16)

≤ exp

− (cid:15)2 GδWb

3

(cid:17)

.

Setting (1 + (cid:15))Gδ = 1, i.e., (cid:15) = 1
Gδ

−1, we have:

≤ Wa

Wa
ai
(cid:16)
−(1 − 1
Gδ

(cid:27)

(cid:18)

(cid:16)

−

1 −

≤ exp

1
Gδ

(cid:17)2

Gδ

Wa
2

(cid:19)

. (37)

(cid:17)

)2Gδ

Wa
2

= δ

3m and solving Gδ, we

Forcing exp
have:

Gδ (cid:44) 1 +

ln(3m/δ)
Wa

+

(cid:115)

(cid:18) ln(3m/δ)
Wa

(cid:19)2

+

2 ln(3m/δ)
Wa

.(38)

Using (32), the Chernoff bound, and following similar

arguments, we have:

(cid:110)

Pr

(Bˆx)i

Wb
bi

> (1 + (cid:15))GδWb

(cid:111)

(cid:16)

≤ exp

− (cid:15)2 GδWb

3

(cid:17)

.

(cid:17)

= δ

3r and solving for (cid:15), we have

Forcing exp
(cid:15) = (

3
GδWb

ln( 3r

(cid:16)

3

−(cid:15)2 GδWb
δ )) 1
Wb
bi

> (1 + (

2 . It follows that

(cid:26)

Pr

(Bˆx)i

Wb
bi

(cid:27)

> Wb

≤ exp

(cid:18)

−

(cid:16) 1
Gδ

(cid:17)2

− 1

Gδ

(cid:19)

Wb
3

. (34)

(cid:110)

Pr

(Bˆx)i

3
GδWb

ln(

3r
δ

))

1

2 )GδWb

(cid:111)

≤

δ
3r

,

Forcing exp
have:

(cid:16)
−( 1
Gδ

−1)2Gδ

Wb
3

(cid:17)

= δ

3r and solving Gδ, we

Gδ (cid:44) 1 +

3 ln(3r/δ)
2Wb

−

(cid:115)

(cid:19)2

(cid:18) 3 ln(3r/δ)
2Wb

+

3 ln(3r/δ)
Wb

. (35)

Using (32), the Chernoff bound, and following similar

arguments, we have:

which implies that:

(cid:40)

(cid:32)

(cid:115)

Pr

(Bˆx)i > bi

1 +

3
GδWb

ln

(cid:16) 3r
δ

(cid:33)

(cid:17)

(cid:41)

Gδ, ∃i

≤

δ
3r

.(39)

By using union bound and (37) and (39), we have that events
1)–3) occur with probability less than δ
3r = δ,
and the proof is complete.

3m + r · δ

3 + m · δ

(cid:110)

Pr

(Aˆx)i

Wa
ai

≤ (1 − (cid:15))GδWa

(cid:111)

(cid:16)

≤ exp

− (cid:15)2 GδWa

2

(cid:17)

.

(cid:16)

(cid:17)

Forcing exp
(cid:15) = (

2
GδWa

−(cid:15)2 GδWa
δ )) 1

ln( 3m

2
2 . It follows that

= δ

3m and solving for (cid:15), we have

Pr{(Aˆx)i

Wa
ai

≤ (1−(

2
GδWa

ln(

3m
δ

))

1

2 )GδWa} ≤

δ
3m

,

which implies that:

(cid:40)

(cid:32)

(cid:115)

Pr

(Aˆx)i ≤ ai

1−

2
GδWa

ln

(cid:16) 3m
δ

(cid:33)

(cid:17)

(cid:41)

Gδ, ∃i

≤

δ
3m

.(36)

By using union bound and (34) and (36), we have that events
1)–3) occur with probability less than δ
3r = δ,
and the proof is complete.

3m + r · δ

3 + m · δ

APPENDIX C
PROOF OF THE COMPETITIVE RATIO
We use OP T as the optimal objective value of Problem R-
DMLRS, which is also the optimum to Problem D-R-
DMLRS. We let ˆπi denote the approximate schedule ob-
tained by Algorithm 2, which inexactly solves Problem D-R-
DMLRS. Let Pi and Di be the primal and dual objective val-
ues of Problems R-DMLRS and D-RMLRS after determining
the schedule ˆπi in Algorithm 1. Let P0 and D0 be the initial
values of Problems R-DMLRS and D-RMLRS, respectively,
where P0 = 0 and D0 = (cid:80)
h. We
t∈T
also let PI and Di be the ﬁnal primal and dual objective
values returned by Algorithm 1. We present our main result
in Lemma 8.

r∈R P r

h [0]C r

h∈H

(cid:80)

(cid:80)

Lemma 8. If there exists constants (cid:15) ≥ 1, Gδ > 0 and δ ∈ (0, 1]
such that Pi−Pi−1 ≥ δ/3Gδ
(Di−Di−1), ∀i ∈ I, and if P0 = 0
and D0 ≤ 1

2 OP T , then Algorithm 1 is 6Gδ(cid:15)

-competitive.

δ

(cid:15)

(Pi −Pi−1), and DI −D0 =

Similarly, we can have the increment value of the dual
objective value Di as follows:

17

Proof of Lemma 8. Since PI = (cid:80)
i∈I
(cid:80)
(Di − Di−1), we can have:
i∈I

(cid:88)

PI =

(Pi − Pi−1) ≥

i∈I
δ/3Gδ
(cid:15)

=

(DI − D0).

δ/3Gδ
(cid:15)

(cid:88)

i∈I

(Di − Di−1)

By weak duality theorem [45], we have

DI ≥ OP T ≥ PI .

Thus, it follows that:

DI − D0 ≥

PI ≥

δ/3Gδ
(cid:15)

1
2

OP T,

(DI − D0) ≥

δ/3Gδ
2(cid:15)

OP T,

and the proof is complete.

Next, following similar arguments in [6], [32], we in-
troduce the relationship between the cost and resource
consumption before and after processing one job. Let pr,i
h [t]
be the unit cost of type-r resource on server h at time t after
handling job i. Let ρr,i
h [t] be the amount of type-r resource
allocated to jobs on server h at time t after processing
the job i. For ease of our subsequent analysis, we now
deﬁne the following allocation-cost relation that is implied
by Algorithm 1:

Deﬁnition 1. The allocation-cost relationship for Algorithm 1
with (cid:15) > 1, Gδ > 0 and δ ∈ (0, 1] is

pr,i−1
h

[t](ρr,i

h [t] − ρr,i−1

h

[t]) ≥

δ/3GδC r
h [t] − pr,i−1
h
(cid:15)
∀i ∈ I, h ∈ H, r ∈ R.

(pr,i

h

[t]),

The allocation-cost relationship shows that the cost in
each time slot for scheduling a new job is bounded by the
increase of term C r
h[t] in Problem D-R-DMLRS, and the
possible increment introduced by randomized rounding in
Algorithm 4. This is ensured by the update of the price
function and the rounding scheme, respectively.

hpr

If the allocation-cost relationship holds for (cid:15) ≥
Lemma 9.
1, Gδ > 0 and δ ∈ (0, 1], then Algorithm 1 ensures Pi − Pi−1 ≥
δ/3Gδ
(cid:15)

(Di − Di−1), ∀i ∈ I.

Proof of Lemma 9. For any job i ∈ I, if job i is rejected,
then we have Pi − Pi−1 = Di − Di−1 = 0 according to
Problems R-DMLRS and D-R-DMLRS, the inequality must
hold. If job i is accepted with schedule πi, i.e., xπi = 1, then
the increment value of the primal objective value Pi is

Pi − Pi−1 = ui(tπi − ai).

Since xπi = 1, according to Algorithm 1, the constraint (11)
is binding. Then, we can have

ui(tπi − ai)
= λi +

(cid:88)

(cid:88)

(cid:88)

= λi +

t∈T (πi)
(cid:88)

h∈H(πi[t])
(cid:88)

r∈R
(cid:88)

t∈T (πi)

h∈H(πi[t])

r∈R

(αr

i wπi

ht + βr

i sπi

ht)pr

h[t]

h[t](ρr,i
pr

h [t] − ρr,i−1

h

[t]).

Di − Di−1 = λi +

(cid:88)

(cid:88)

(cid:88)

t∈T (πi)

h∈H(πi[t])

r∈R

(pr,i

h [t] − pr,i−1

h

[t])C r
h.

Summing up the allocation-cost relationship over all t ∈
T (πi), h ∈ H(πi[t]), r ∈ R, we have

(Di − Di−1 − λi) + λi

Pi − Pi−1 ≥

δ/3Gδ
(cid:15)
δ/3Gδ
(cid:15)
As λi ≥ 0, (cid:15), Gδ > 0 and δ ∈ (0, 1], we have

(Di − Di−1) + (1 −

=

δ/3Gδ
(cid:15)

)λi.

Pi − Pi−1 ≥

δ/3Gδ
(cid:15)

(Di − Di−1).

This completes the proof of Lemma 9.

For speciﬁc h ∈ H, r ∈ R, we deﬁne (cid:15)r

h as the corre-
sponding parameter in the allocation-cost relationship for
any job i ∈ I and any time slot t ∈ T . Then, it holds that
(cid:15) = maxh,r{(cid:15)r
h}. Without loss of generality, we assume that
the resource demand of each worker or parameter server
is much smaller compared to the capacity of that resource
on one server, i.e., αr
h, βr
h. This is common in
real-world machine learning system as large percentage of
resources in the whole server. As ρr
h[t] increases from 0 to
C r
, and de-
rive a differential version of the allocation-cost relationship,
which is deﬁned as follows:

h, then we can claim that dρr

h − ρr,i−1

h[t] = ρr,i

i (cid:28) C r

i (cid:28) C r

h

Deﬁnition 2. The differential allocation-cost relationship for
Algorithm 1 with (cid:15)r

h[t]dρr
pr

h[t] ≥

dpr

h[t], ∀t ∈ T , h ∈ H, r ∈ R.

Next we show that a feasible (cid:15)r

allocation-cost relationship with price function pr
in (12).
Lemma 10. (cid:15)r
satisfy the differential allocation-cost relationship.

h = ln U r

L , and the price function deﬁned in (12)

h satisﬁes the differential
h[t] deﬁned

Proof of Lemma 10. The derivation of the marginal cost func-
tion is

dpr

h (ρr

ρr
h[t]
Cr
h ln(

h[t])dρr

h[t] = L(

h[t] = pr(cid:48)

U r
L
The differential allocation-cost relationship is
U r
L

ρr
h [t]
h dρr
Cr

ρr
h [t]
Cr
h ln(

h[t] ≥

U r
L

U r
L

L(

L(

)

)

)

)

1
h dρr
Cr

h[t].

)

1
h dρr
Cr

h[t],

which holds for (cid:15)r
max
r∈R
cost relationship. This completes the proof.

L ). Then, we can set (cid:15) =
L )), which satisﬁes the differential allocation-

(1, ln( U r

C r
U r
h
(cid:15)r
L
h
h ≥ ln( U r

With the aforementioned lemmas, we are now in a
position to prove Theorems 5 and 6. Note that the Theo-
rems provide probabilistic guarantees. We ﬁrst analyze the
performance ratio, which is followed by the probabilistic
feasibility discussion for both cases.

Proof of Theorems 5 and 6. According to Lemma 10,
marginal cost

the
function used in Algorithm 1 satisﬁes

h ≥ 1 is
C r
h
(cid:15)r
h

18

probability that no feasible integer solution returned after
S iterations rounding is at most (δ/3)S. It then follows that
the probability of at least one feasible integer solution found
is at least 1 − (δ/3)S. Moreover, the number of states (t, v)
in the dynamic programming for each job i is O(T KiEi).
Therefore, with probability greater than (1 − (δ/3)S)TiKiEi ,
PD-ORS in Algorithm 1 returns a feasible integer solution
with the proved competitive ratio.

2) When Gδ > 1 (Theorem 6): According to Theorem 4,
the probability of violating the packing constraint is no
greater that δ/3(HR + 1) at each randomized rounding
iteration. Following the similar arguments in 1), we can
show that with probability greater than (1 − (δ/3(HR +
1))S)TiKiEi , PD-ORS in Algorithm 1 returns a feasible in-
teger solution with the proved competitive ratio, and the
proof is complete.

the differential allocation-cost
maxr(1, ln U r
smaller than the capacity, we can derive

relationship with (cid:15) =
L ). Since the resource demand in a job i is much

dρr
dpr

h[t] = ρr,i
h[t] = pr(cid:48)

h − ρi−1
h (ρr

h [t],
h[t])(ρr,i

h [t] − ρr,i−1

h

[t]) = pr,i

h [t] − pr,i−1

h

[t].

So, the differential allocation-cost relationship in Deﬁni-
tion 2 implies the allocation-cost relationship in Deﬁnition 1
holds for (cid:15) = maxr(1, ln U r

L ).

According to Algorithm 1, we note that

1
µ

≤

(cid:100)EiKi(τi + 2giγi/(b(e)

i Fi))(cid:101) (cid:80)
(cid:80)
r∈R C r
h

T (cid:80)

h∈H

r∈R(αr

i + βr
i )

, ∀i ∈ I.

Then, the minimum amount of overall resource consump-
tion of job i can be computed as:

T (cid:80)

h∈H

(cid:80)

r∈R C r
h

µ
≤ (cid:100)EiKi(τi + 2giγi/(b(e)

i Fi))(cid:101)

(cid:88)

r∈R

Then, it follows that:

D0 =

(cid:88)

t,h,r

LC r
h

(αr

i + βr

i ).

(cid:88)

t,h,r
T (cid:80)

(cid:80)

min
i∈I,πi∈Πi
h,r C r
h
2µ

min
i,πi

1/(2µ)ui(tπi − ai)C r
h
i Fi)(cid:101)(αr

i + βr
i )

r∈R(cid:100)EiKi(τi + 2giγi/(b(e)
ui(tπi − ai)
r∈R(cid:100)EiKi(τi + 2giγi/(b(e)
(cid:88)
i + βr
i )

i Fi))(cid:101)

(αr

(cid:80)

i Fi)(cid:101)(αr

i + βr
i )

(cid:100)EiKi(τi + 2giγi/(b(e)

min
i∈I,πi∈Πi

(cid:80)

r∈R
ui(tπi − ai)
r∈R(cid:100)EiKi(τi + 2giγi/(b(e)
(cid:88)

(cid:100)EiKi(τi + 2giγi/(b(e)

i Fi))(cid:101)

(αr

i + βr
i )

r∈R

i Fi)(cid:101)(αr

i + βr
i )

, ∀i ∈ I.

=

=

≤

1
2

(a)
≤

1
2

ui(tπi − ai)
r∈R(cid:100)EiKi(τi + 2giγi/(b(e)
1
2

ui(tπi − ai)

OP T,

(b)
≤

1
2

(cid:80)

≤

i Fi)(cid:101)(αr

i + βr
i )

(a)

(i, π)

follows

selecting

=
where
by
arg mini∈I,πi∈Πi ui(tπi − ai), and (b) follows from the
assumption that the ofﬂine optimal solution accepts at
least one job, which is reasonable in real-world machine
learning system. Then we have OP T ≥ mini,π ui(tπi − ai).
According to Lemmas 8 and 9, the competitive ratio is
proved.

Recall that the randomized rounding algorithm is a key
component in our algorithm. Toward this end, we show
the probability of obtaining a feasible solution with the
proved competitive ratio. Here, we consider the following
two cases:

1) When 0 < Gδ ≤ 1 (Theorem 5): According to The-
orem 3, the probability of violating the cover constraint is
no greater than δ/3 at each randomized rounding iteration.
Recall that our Algorithm 1 runs a predetermined number
of S iterations to ﬁnd a feasible integer solution. Thus the

