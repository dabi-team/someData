0
2
0
2

g
u
A
2

]
T
G
.
s
c
[

1
v
0
4
5
0
0
.
8
0
0
2
:
v
i
X
r
a

Chaos of Learning Beyond Zero-sum and Coordination
via Game Decompositions

Yun Kuen Cheung∗1 and Yixin Tao †2

1Singapore University of Technology and Design
2Courant Institute, NYU

Abstract

Machine learning processes, e.g. “learning in games”, can be viewed as non-linear dynamical
systems. In general, such systems exhibit a wide spectrum of behaviors, ranging from stabil-
ity/recurrence to the undesirable phenomena of chaos (or “butterﬂy eﬀect”). Chaos captures
sensitivity of round-oﬀ errors and can severely aﬀect predictability and reproducibility of ML
systems, but AI/ML community’s understanding of it remains rudimentary. It has a lot out
there that await exploration.

Recently, Cheung and Piliouras [10, 11] employed volume-expansion argument to show that
Lyapunov chaos occurs in the cumulative payoﬀ space, when some popular learning algorithms,
including Multiplicative Weights Update (MWU), Follow-the-Regularized-Leader (FTRL) and
Optimistic MWU (OMWU), are used in several subspaces of games, e.g. zero-sum, coordination
or graphical constant-sum games.
It is natural to ask: can these results generalize to much
broader families of games? We take on a game decomposition approach and answer the question
aﬃrmatively.

Among other results, we propose a notion of “matrix domination” and design a linear pro-
gram, and use them to characterize bimatrix games where MWU is Lyapunov chaotic almost
everywhere. Such family of games has positive Lebesgue measure in the bimatrix game space,
indicating that chaos is a substantial issue of learning in games. For multi-player games, we
present a local equivalence of volume change between general games and graphical games, which
is used to perform volume and chaos analyses of MWU and OMWU in potential games.

1

Introduction

In the developments of AI/ML, understanding how selﬁsh agents learn in competitive game-
theoretic environments is of primary interest, and this is more strongly propelled recently due
to the success of Generative Adversarial Networks (GANs). As such, Evolutionary Game Theory
(EGT) [21, 35], a decades-old area devoted to the study of adaptive (learning) behaviors of agents
in competitive environments arising from Economics, Biology and Physics, has been brought to the
attention of AI/ML community. In contrast with the typical optimization (or no-regret) approach
in AI/ML, EGT provides us a (non-linear) dynamical-systemic perspective to understand ML pro-
cesses. This perspective is particularly helpful in studying “learning in games”, where instability
is commonly observed, but AI/ML community currently lacks of a rigorous mean to perform the
relevant analyses.

∗Yun Kuen Cheung acknowledges AcRF Tier 2 grant 2016-T2-1-170 and NRF 2018 Fellowship NRF-NRFF2018-07.
†Yixin Tao acknowledges NSF grant CCF-1527568 and CCF-1909538.

1

 
 
 
 
 
 
The theme of this paper is chaos, a central notion in the study of dynamical systems that
captures instability and unpredictability. We seek broad families of games in which popular learning
algorithms exhibit chaotic behaviors, by employing game decomposition techniques. Next, we
explain what are chaos and game decompositions, and why it is important for AI/ML community
to understand chaos. All missing proofs will appear in the appendix.

Chaos. Chaos generally means a system becomes unpredictable in the long run; Lyapunov chaos is
one of the most popular chaos notions which captures the butterﬂy eﬀect: when the starting point
of a dynamical system is slightly perturbed, the resulting trajectories and ﬁnal outcomes diverge
quickly; see Deﬁnition 1 for a formal deﬁnition. Lyapunov chaos means that such system is very
sensitive to round-oﬀ errors in computer simulations, and to measurement errors in real economies.
Indeed, Edward Lorenz, one of the pioneers of the modern chaos theory, started working on the topic
because he found round-oﬀ errors led to devastatingly diﬀerent outcomes in his weather simulation
program [26]. In the context of learning-in-game, Lyapunov chaos indicates that Nash equilibrium
is generally not achievable.

To see the importance for AI/ML community to understand chaos, recall that one of our primary
targets is to build predictable and reproducible ML systems. The soundness of a newly proposed
ML system is usually supported by a theory, which is in turn supported via experimental evidences.
However, there is often a gap between theory and experiments: theory is built upon the assumption
of inﬁnite precision, but experiments are done using ﬁnite-precision computers where round-oﬀ
occurs in every computation step. While the round-oﬀ error per step is small, it is unclear how it
can aﬀect the ﬁnal outcome of the system, let alone the cumulating eﬀect of all the errors across
multiple steps. Moreover, how the round-oﬀ is done depends on the OS, the CPU/GPU architecture,
the compiler and more, which vary from computer to computer, so reproducing the same result
across multiple computers is not as trivial as some of us had presumed. These unpredictability and
irreproducibility issues are exempliﬁed by two quotes from Ali Rahimi’s NIPS’2017 test-of-time
award speech [32]:

“Someone on another team changed the default rounding mode of some Tensorﬂow
internals from ‘truncate toward zero’ to ‘round to even’. Our training broke, our error
rate went from less than 25% error to

99.97% error.”

“If a machine learning algorithm does crazy things on a linear model, it’s going to do
crazy things on complex non-linear models too.”

∼

Game Decomposition. To understand how game decomposition works, we ﬁrst compare the
dynamical-systemic and optimization approaches. Historically, there is a trade-oﬀ of them between
generality of settings and scope of results.1 No-regret learning works even in general and adversarial
settings, but its eﬀectiveness is benchmarked w.r.t. the average of history, while it sheds little
insight on the daily behaviors of the learning-in-game systems. The dynamical-systemic approach
primarily aims at understanding the daily behaviors, but compelling results are often limited to
speciﬁc families of games because non-linear dynamical systems are inherently diﬃcult to analyze
in general.

A natural approach to extend those compelling results to more general families of games is via
game decomposition. To explain how it works, suppose there is a speciﬁc family of games, denoted
, for which some compelling results are shown. Given a general game, we seek to decompose
by

H
1Game-theoretically, coarse correlated equilibria (generated by time-average of no-regret algorithm) and Nash

equilibria (often ﬁxed points of game dynamics) might be viewed as the products of the two approaches.

2

H

and a residue component. If the residue is small, then it is
it into a sum of its projection on
plausible that those compelling results extend (approximately). For instance, if the residue is small,
then any Nash equilibrium of the projection is an approximate Nash equilibrium of the original
game. More generally, a game might be decomposed into three or more components which can be
studied separately. In seeking of games where learning is stable, the game decomposition approach
was used in several works [5, 6, 7, 24] with
being potential games. While we also employ game
decomposition technique, our target is in the opposite end of those of the cited works above, which
is to seek broad families of games where popular learning algorithms are Lyapunov chaotic.

H

Our Contributions. Our starting point is the recent works of Cheung and Piliouras [10, 11].
They considered a classical technique in the study of dynamical systems, called volume analysis.
Volume analysis considers a set of starting points of positive volume (e.g. a ball centred at a point).
When this set of starting points evolves according to the rule of dynamical system, it evolves to a
new set with a diﬀerent volume. Intuitively, volume is a measure of the range of possible outcomes,
so the larger it is, the more unpredictable the system is. Cheung and Piliouras observed that if the
set’s volume increases exponentially, then its diameter increases exponentially too, which implies
Lyapunov chaos.

Cheung and Piliouras employed the volume-expansion argument to show that Multiplicative
Weights Update (MWU) and Follow-the-Regularized-Leader (FTRL) algorithms in two-player zero-
sum and graphical constant-sum games are Lyapunov chaotic everywhere2in the cumulative payoﬀ
(dual) space; analogous result holds for the optimistic variant of MWU (OMWU) in two-player
coordination games. This indicates that when players repeatedly play the game by using the
learning algorithms, when the initiating condition is slightly perturbed, the cumulative payoﬀs
exhibit a wide range of possibilities in the long run. This implies instability in the mixed strategy
(primal) space.

The volume-expansion argument crucially relies on analyzing the sign of a function C(
) in the
·
) is
dual space. Volume-expansion with MWU/FTRL (resp. OMWU) occurs if and only if C(
·
) is always positive in zero-sum
positive (resp. negative). Cheung and Piliouras proved that C(
·
games and C(
It is natural to ask: are these chaos
) is always negative in coordination games.
·
results isolated in the sense that they hold only due to the very speciﬁc structures of those games,
or do these chaos results generalize broadly? In the other way around, we ask the following question:

How does the Lyapunov chaos phenomena of learning extend beyond
two-player zero-sum games, two-player coordination games
and multi-player graphical constant-sum games?

We answer the above question aﬃrmatively, both for two-player and multi-player settings.

Two-player normal form games. For the family of two-player normal-form games (bimatrix games)

, we present two new techniques to go beyond zero-sum game and coordination games.

–The ﬁrst technique is the well-known direct-sum decomposition
=
, in which every
Z ⊕ C
bimatrix game (A, B) is decomposed into the sum of a zero-sum game (Z,
Z) and a coordination
−
game (C, C) [3, 22]. We show that CG(
), the function that determines if the volume is expanding
·
or not in the game G, is a simple sum of the zero-sum game part and the coordination part:
CG(
) is always
) (Theorem 4). Recall we have discussed that C(Z,−Z)(
) + C(C,C)(
) = C(Z,−Z)(
·
·
·
·
) is always negative (as (C, C) is a coordination
Z) is a zero sum game) and C(C,C)(
positive (as (Z,
·

−

G

2By everywhere, it means the results hold in any bounded region of the dual space, for any suﬃciently small

step-size of the algorithm. There is also a very mild requirement on non-triviality of the game.

3

G

) is always relatively larger than
game). Thus, if C(Z,−Z)(
·
expansion in G.

), then we always have volume
C(C,C)(
·

−

–The second technique is the trivial matrices (see Deﬁnition 2). Intuitively, trivial matrices are
a set of matrices which do not aﬀect the volume changing behavior of the game: for any bimatrix
game (A, B) and any trivial matrices T1 and T2, C(A,B)(
) (Theorem 5). An
C(A+T1,B+T2)(
)
·
·
immediate application of trivial matrices is for bimatrix potential games [28]. For any bimatrix
potential game P, CP(
) for some coordination game (C, C), which implies
) is identical to C(C,C)(
·
·
OMWU is Lyapunov chaotic everywhere in P (Observation 6).

≡

By using these two techniques, we identify two characterizations of bimatrix games where MWU
and FTRL are Lyapunov chaotic almost everywhere (Theorem 9 and Theorem 11). These new
characterizations are based on our new notion of matrix domination (see Deﬁnition 4), and a linear
program (see Eqn. (8)) which is designed to prune out the trivial-matrix projection and keep the
residue part minimal. Such family of games has positive Lebesgue measure in the bimatrix game
space, so it is not conﬁned to any proper game subspace3. This provides a justiﬁcation to the claim
that the occurrences of chaos are not only circumstantial, but a rather substantial issue of learning
in games. Analogous result holds for OMWU too.

Multi-player normal-form games. For the family of multi-player (3 or more players) games, we ﬁrst
use an observation in [10], coupled with our new ﬁndings about bimatrix games discussed before,
to present a new family of graphical games in which MWU is Lyapunov chaotic almost everywhere
(Theorem 12); the new family of games strictly includes all graphical constant-sum games.

To facilitate volume analyses in general normal-form games, we establish their local equivalence
of volume change with graphical games. Precisely, we show that CG(p) for a general game G is the
same as CH(p) for some graphical game H; H will depend on the point p, that’s why we say the
equivalence is local (Theorem 13). This provides an intuitive procedure for understanding volume
changes. Additionally, we show that the volume-changing behaviors of MWU and OMWU are
opposite to each other in multi-player game (Proposition 14). We use these to analyze MWU and
OMWU in multi-player potential games; in particular, we show that CG(p) of a multi-player poten-
tial games is equal to CC(p) of a corresponding multi-palyer coordination game, while CC(p)
0
(Lemma 15).

≤

Further Related Work. Volume analysis has long been a technique of interest in the study of
population and game dynamics. It was discussed in a number of famous texts; see Hofbauer and
Sigmund [21, Section 11], Fudenberg and Levine [18, Section 3] and Sandholm [35, Chapter 9]. For
a modern overview of online learning algorithms from Machine Learning or Economics perspectives,
which includes the discussion about MWU and its variants, no-regret learning and potential games,
we recommend the texts of Cesa-Bianchi and Lugosi [8] and Hart and Mas-Collel [19].

In the study of no-regret learning (e.g. [25, 16]), a vast literature concerns general or even
adversarial settings, in which the online arrivals of payoﬀ values come with no pattern or even from
an adversary. More recently, settings where the online payoﬀs are more well-behaved, under the
term of “predictable sequence” coined by Rakhlin and Sridharan [33], have been studied. These
settings include game dynamics, as the online payoﬀs are determined by the mixed strategy choices
of the players, while these choices are updated gradually and somewhat predictably. For these
settings, online learning algorithms that perform particularly well, e.g. achieving regret bound below
(√T ) limit, are designed and studied [20, 12, 36]. For instance, Nesterov’s excessive
the canonical

O

3The family of zero-sum games and the family of coordination games are proper subspaces of the bimatrix game

space. Any proper subspace has Lebesgue measure zero.

4

(log T )
gap technique and optimistic mirror descent are found to achieve near-optimal regret
in zero-sum games [13, 34], and thus the empirical average of the learning sequence converges to
Nash equilibrium of the game (see Freund and Schapire [17] for an explanation). OMWU (with
time-varying step-sizes), and more generally optimistic variant of FTRL [33], are some canonical
examples of such online learning algorithms.

O

Recently, there is a stream of work that examines how learning algorithms behave in games
or min-max optimization from a dynamical-systemic perspective. Replicator dynamics (RD; the
continuous-time analogue of MWU) and continuous-time FTRL are found to achieve optimal regret
in general settings [27]. Furthermore, RD in zero-sum games or graphical constant-sum games
admits a constant of motion and preserves volume; these two properties are used to show that
such dynamical systems are near-periodic [21, 30, 27, 4], captured rigorously under the notion of
Poincar´e recurrence [31, 2]. However, when MWU, the forward Euler discretization of RD, is used
in discrete-time setting in zero-sum games, the near-periodicity is destroyed totally; indeed, the
system will never visit the same point (or its tiny neighbourhood) twice, converge to the boundary
of the strategy simplex, and ﬂuctuate there irregularly [1, 9].

In contrast, (discrete-time) OMWU in zero-sum game is shown to converge to Nash equilib-
rium [15]; yet, in the more general setting of min-max optimization, it was found that Optimistic
Gradient Descent Ascent (OGDA) can have limit points other than (local) min-max solutions [14].

Another notion of chaos called Li-Yorke chaos was shown to exist when a variant of MWU is

used in congestion games [29].

2 Preliminary

In this paper, every bold lower-case alphabet denotes a vector, every bold upper-case alphabet
denotes a matrix or a game. When we say a “game”, we always mean a normal-form game. Given
n, let ∆n denote the mixed strategy space of dimension n, i.e.

(z1, z2,
{

· · ·

, zn)

|

n
.
j=1 zj = 1
}

Normal-Form Games.We use N to denote the number of players of a game. Let Si denote the
S
strategy set of Player i, and S := S1 ×
denotes a strategy proﬁle of all players, and ui(s) denotes the payoﬀ to Player i when each player
picks si. A mixed strategy proﬁle is denoted by x = (x1, x2,
, xN ), and ui is extended to take
· · ·
mixed strategies as inputs via ui(x) = Es∼x [ui(s)]. Also, we let

P
. s = (s1, s2,

S2 × · · · ×

SN . Let ni =

Si|
|

, sN )

· · ·

∈

U i1i2···ig
j1j2···jg(x) = the expected payoﬀ to Player i1 when: for 1

f

≤

≤

g, Player if picks strategy jf ,

while for each player i /

, she picks a strategy randomly following xi

= Es−(i1,··· ,ig )∼x−(i1,··· ,ig )

, sig = jg, s−(i1,··· ,ig))

.

(1)

ig}
i1,
∈ {
ui1(si1 = j1,

· · ·

· · ·

(i1,

Note that
, ig) denotes the player set other than i1,
i ui(s) = 0 for all s
clear from the context. We say a game is a zero-sum game if
a game is a coordination game if ui(s) = uk(s) for all Players i and k and for all s

· · ·

· · ·

−

j1j2···jg if x is
S, and we say
S.

, ig. Also, we use U i1i2···ig

(cid:3)

(cid:2)

P

∈
∈

When N = 2, such games are called bimatrix games, for which we adopt the notations below.
Let (A, B) denote a bimatrix game, where for any j
S2, Ajk := u1(j, k), Bjk := u2(j, k).
x and y denote mixed strategies of Players 1 and 2 respectively. A bimatrix game is a zero-sum
k = [BTx]k, which
game if A =
we denote by Aj, Bk respectively when x, y are clear from context; Bj, Ak are deﬁned analogously.

B; it is a coordination game if A = B. Note that U 1

j = [Ay]j, U 2

S1, k

−

∈

∈

5

MWU, FTRL and OMWU in Games. All three algorithms have a step-size ǫ, and can be
implemented as updating in the cumulative payoﬀ (dual) space. In each round, the players’ actions
(mixed strategies) in the primal space are functions of the cumulative payoﬀ vectors to be deﬁned
below, and these actions are then used to determine the payoﬀs in the next round. For a player
Rd denote
with d strategies, let pt
the starting point chosen by the player. For MWU in a game, the update rule for Player i is

Rd denote her cumulative payoﬀ vector at time t, and let p0

∈

∈

·
j is the function deﬁned in (1), and xt is the mixed strategy determined by the formula

pt+1
j

= pt

j + ǫ

j (xt),
U i

(2)

where U i
below:

j = xj(pt) = exp(pt
xt

j)/(

ℓ∈Si exp(pt

ℓ))

For OMWU in a game, the update rule for Player i starts with p1 = p0, and for t

P

where xt is determined by (3).

pt+1
j = pt

j + ǫ

2U i

j (xt)

−

j (xt−1)
U i

,

(cid:3)

·

(cid:2)

(3)

2,

≥

For FTRL in a game, the update rule for Player i is same as (2), but xt is determined as below
using a convex regularizer function hi : ∆d
. As all
the results for MWU can be directly generalized to FTRL as discussed in [10, Appendix D], to
keep our exposition simple, in the rest of this paper, we focus on MWU and OMWU and their
comparisons. For bimatrix game, we use p, q to denote the cumulative payoﬀ vectors of Players 1
and 2 respectively.

R: xt = arg maxx∈∆d

pt , x

hi(x)

(cid:8)(cid:10)

→

−

(cid:9)

(cid:11)

Rd

)
0
}
∪ {

Rd and an update rule s(t + 1) = f (s(t)), where f : Rd

Dynamical Systems, Lyapunov Chaos and Volume Analysis. A learning-in-game system
can be viewed as a discrete-time dynamical system. We present a simpliﬁed deﬁnition of dynamical
systems that ﬁts our need. A discrete-time dynamical system in Rd is determined by a starting
Rd is a function.4 The
point s(0)
∈
sequence s(0), s(1), s(2),
is called a trajectory of the dynamical system. When f is clear from
· · ·
Rd denote the function such that Φ(t, s) is the value of
the context, we let Φ : (N
Rd, we let
s(t) generated by the dynamical system with starting point being s. Given a set U
Φ(t, U ) =

⊂
. Let B(s, r) denote the open ball with center s and radius r.
}

s
Φ(t, s)
|
{

There are a number of similar but not identical deﬁnitions of Lyapunov chaos, all capturing
the butterﬂy eﬀect: when the starting point is slightly perturbed, the resulting trajectories diverge
quickly. We use the following deﬁnition, which was also used in [10, 11] implicitly. Intuitively, a
S and any open ball B around s, as long
system is Lyapunov chaotic in an open set S if for any s
as Φ(t, B) remains inside S, there exists s′
grows exponentially
with t. Lyapunov exponent in the deﬁnition is a measure of how fast the exponential growth is;
the larger it is, the more unpredictable the dynamical system is.

∈
B such that

Φ(t, s′)
k

Φ(t, s)
k

→

→

−

×

U

∈

∈

Deﬁnition 1. We say a dynamical system is Lyapunov chaotic in an open set S
exists a constant λ > 0 and a Lyapunov exponent γ = γ(S) > 0, such that for any s
suﬃciently small δ > 0 and for all t satisfying 0

⊂
∈

Rd if there
S, for any

sup

s′∈B(s,δ) k

Φ(t, s′)

−

≤
Φ(t, s)

τ
t < min
{
λ

k ≥

Φ(τ, B(s, δ)) ( S
|

,
}

exp(γt).

δ

·

·

We say a dynamical system is Lyapunov chaotic everywhere if it is Lyapunov chaotic in any
bounded open set S

Rd.

4OMWU in game is not a dynamical system, as the update to s(t + 1) depends on both s(t), s(t − 1). But there

is a function f such that s(t + 1) ≈ f (s(t)), while the volume-changing behavior is not really aﬀected [11].

6

⊂

In the above deﬁnition, all norms and radii are Euclidean norms. For capturing round-oﬀ errors
in computer simulations and ML systems, it is more natural to use ℓ1-norm for which δ is the
round-oﬀ maximum error, say

10−16 when IEEE 754 binary64 (standard double) is used.

When S is a small set, it is usually easy to determine whether a dynamical system is Lyapunov
chaotic in S, since the dynamic can be locally approximated by a linear dynamical system, where
the eigenvalues of the local Jacobian characterizes chaotic behaviors (when f is smooth). But
when S is a large, determining whether Lyapunov chaos occurs is diﬃcult in general. Cheung and
Piliouras [10] found that volume analysis can be useful in this regard, based on the following simple
observation.

∼

∈

t)).

S(t) is Ω(exp( γ

Proposition 1. In Rd, if a set S has volume at least v, then the radius w.r.t. any point s
S is
at least v1/d/2. Thus, if the volume of Φ(t, S) of some dynamical system is Ω(exp(γt)) for some
λ, γ > 0, then the radius of S(t) w.r.t. any point s

∈
Cheung and Piliouras showed Lemma 2 below, which, for bimatrix games, reduces volume
analysis to analyzing the sign the function C(A,B)(p, q) deﬁned in Eqn. (4) below; the sign also
determines the local volume-changing behavior around the point (p, q) when MWU is used. Based
on Proposition 1 that converts volume expansion to radius expansion, the sign can be used to
determine if the dynamical system is Lyapunov chaotic. In Eqn. (4), x(p), y(q) are mixed strategies
of Players 1 and 2 respectively, computed using (3). Equality (5) can be derived easily, in which the
expectation E [
] is indeed E(j,k)∼(x(p),y(q)) [
], i.e. the underlying distribution is where j is drawn
·
·
following the distribution x(p), while k is drawn following the distribution y(q).
[BT

C(A,B)(p, q) =

x(p)]k)

y(q)]j )

xj(p)

yk(q)

(4)

[A

d ·

·

(Ajk −

·

·

(Bjk −

·

·

=

Xj∈S1 Xk∈S2
E [(Ajk −
Bj −
For multi-player game G, the analogous function CG(
) is given below; the U quantities were
·
deﬁned in (1). Lemma 2 is adapted from [10] for games with any number of players. Derivation
of (6) uses the Jacobian of the corresponding dynamical system and integration by substitution;
see Appendix B.

Ak)(Bjk −

Bk)] + E [Ajk]

E [Bjk] .

Aj −

(5)

−

·

−

CG(p1,

· · ·

, pN ) =

−

Xi∈[N ], j∈Si Xk>i, ℓ∈Sk

xijxkℓ

U ki

ℓj −

U k
ℓ

(cid:16)

U ik

jℓ −

(cid:17) (cid:16)

Lemma 2. Let G be a game. Suppose that S is a set in the dual space Rd, and

¯c(S) :=

inf
(p1,··· ,pN )∈S

CG(p1,

· · ·

, pN ) > 0.

U i
j

.

(cid:17)

(6)

(7)

t

≤

T , then for all t in this range, the volume of Φ(t, B) is at least Φ(0, B)

Then for MWU in the bimatrix game with any suﬃciently small step-size ǫ, as long as Φ(t, B)
⊂
exp( ¯c(S)
2 ǫ2
for all 0
·
and hence the radius of Φ(t, B) is at least Ω(exp( ¯c(S)
Lyapunov chaotic in S with Lyapunov exponent ¯c(S)

2d ǫ2
2d ǫ2.
If MWU is replaced by OMWU, then the same result holds by replacing the condition (7) with

S
t),
t)). Subsequently, the dynamical system is

≤

·

·

¯c(S) := inf (p1,··· ,pN )∈S[

−

CG(p1,

· · ·

, pN )] > 0.

Note that if we start from a Nash equilibrium in the primal space, MWU and OMWU will stay at
the equilibrium. However, if this equilibrium (x∗, y∗) satisﬁes the conditions in Corollary (3) below,
there are points arbitrarily close to the equilibrium that keep moving away from the equilibrium
(if the region

is large).

S

(x′, y′) = (x(p), y(q))
(p, q)
|
{

∈

}

7

Corollary 3 (Adapted from [11, Theorem 5]). Let (x∗, y∗) be a point in the interior of the primal
space. Suppose that there exists (p, q) in the dual space, such that x∗ = x(p) and y∗ = y(q).
Furthermore, suppose C(A,B)(p, q) > 0 and (p, q)
S where S is the set described in Lemma 2.
Then there are primal points arbitrarily close to (x∗, y∗) such that MWU in the game (A, B)
eventually leaves the corresponding primal set of S, i.e.

∈

S

When the game is zero-sum, i.e., B =

−
Since E [Ajk] = E [Aj] = E [Ak] and hence E [Ajk −
Aj −
variance of the random variable Ajk −
C(A,−B)(p, q). Thus, for any coordination game (A, A),
By (4), we have C(A,B)(p, q) =
−

Ak] =
Ak, and thus is non-negative.

A, hence C(A,B)(p, q) = E
Aj −

(Ajk −
(cid:2)

0, due to the observation about zero-sum games above.

C(A,A)(p, q) =

C(A,−A)(p, q)

−

(cid:3)

(x′, y′) = (x(p), y(q))
(p, q)
|
{
Aj −

.
}
E [Ajk]2.
E [Ajk], C(A,B)(p, q) is indeed the

∈
Ak)2

−

−

≤

3 Bimatrix Games

In this section, we focus on general bimatrix games (A, B). First, in Section 3.1, we present two
tools for analyzing C(A,B)(
), and then we provide an example to show how to use these two tools.
·
Finally, in Section 3.2, we present two characterizations such that the dynamics are Lyapunov
chaotic almost everywhere.

3.1 Tools for Analyzing Bimatrix Game

First Tool: Canonical Decomposition for Bimatrix Games. For every bimatrix game
(A, B), it admits a canonical decomposition [3, 22] into the sum of a zero-sum game (Z,
Z) and
a coordination game (C, C), where Z = 1

B) and C = 1

−

2 (A + B), i.e.

2 (A

−
(A, B) = (Z,

Z) + (C, C).

−

Z) the zero-sum part of the game (A, B), and (C, C) the coordination part of the
We call (Z,
) can be decomposed neatly into the two parts
game. Our ﬁrst result shows that the function C(
·
too.

−

Lemma 4. For any bimatrix game (A, B),

where Z = 1

2 (A

−

B) and C = 1

≡
2 (A + B).

C(A,B)(p, q)

C(Z,−Z)(p, q) + C(C,C)(p, q),

Proof. We use (5) to expand the following:

·

4

=E

C(C,C)(p, q)

C(Z,−Z)(p, q) + 4
·
Bjk −
(Ajk −
Aj + Bj −
E
(Ajk + Bjk −
(cid:2)
−
Aj + Bj −
Bjk −
(Ajk −
(cid:2)
(E [Ajk]
(cid:2)
−
−
=E [4(
Bjk + Bj + Bk)(Ajk −

Ak + Bk)2
Aj −
Ak + Bk)2

E [Ajk −
−
Bk)2
Ak −
Bj −
(cid:3)
(Ajk + Bjk −
(cid:3)
−
E [Bjk])2 + (E [Ajk] + E [Bjk])2
Ak)] + 4

E [Ajk]

Aj −

=E

−

·

·

Bjk]2

=4

C(A,B)(p, q).

·

+ E [Ajk + Bjk]2
Ak −
Bj −
Aj −

Bk)2

(cid:3)

E [Bjk]

8

By the end of Section 2, we discussed that for any zero-sum game, C(Z,−Z)(p, q) is always non-
negative, and for any coordinate game, C(C,C)(p, q) is always non-positive. By using the above
lemma, we can analyze the volume-changing behavior of a bimatrix game (A, B) by looking at its
zero-sum and coordination parts independently. One simple intuition is that if the coordination
(resp. zero-sum) part is small, then the volume-changing behavior of (A, B) is closer to the behavior
of the zero-sum (resp. coordination) part. We realize this intuition quantitatively in the next
subsection.

Second Tool: Trivial matrix. Trivial matrices are matrices which do not aﬀect the volume-
changing behavior, as depicted in Lemma 5 below.

Deﬁnition 2 (Trivial Matrix). T
and v1, v2,
Lemma 5. For any two trivial matrices T1, T2, for any two matrices A, B

Rn×m is a trivial matrix if there exists real numbers u1, u2,
[m].

, vm such that Tjk = uj + vk for all j

[n], k

· · ·

∈

∈

∈

Rn×m,

∈

, un

· · ·

One immediate application of this lemma is for two player potential games.

C(A,B)(p, q)

≡

C(A+T1,B+T2)(p, q).

Deﬁnition 3. A game G is a potential game if there exists a potential function
that for any Player i and any strategy proﬁle s

S,

: S

P

→

R such

(si, s−i)

P

− P

(s′

i, s−i) = ui(si, s−i)

ui(si′, s−i).

−

∈

For the potential game, we have the following observation:

Observation 6. For any bimatrix potential game (A, B), there is a coordination game (P, P) such
that A
.

P are trivial matrices. P is the matrix representation of the potential function

P
This observation immediately implies that the volume-changing behavior of potential game is

P, B

−

−

equivalent to that of a corresponding coordination game.

).
We give a concrete example to show how these tools help us to analyze the C(A,B)(
·

A Simple Example. We will show how to use our tools to demonstrate C(
0 everywhere for
)
·
the following game. In the example, each player has three strategies. The payoﬀ bimatrix (A, B) is
a, b, c
given below. The ﬁrst number gives the payoﬀ of the row player, who chooses strategy from
;
{
}
. We
1, 2, 3
the second number gives the payoﬀ of the column player, who chooses strategy from
}
{

≥

Strategy 1 Strategy 2 Strategy 3

Strategy a
Strategy b
Strategy c

(4, 4)
8, 8)
2)

(
−
(14,

−

(12,

4)

−
(0, 0)
8, 8)
(
−

(
−
(12,

6, 10)
4)

−
(4, 4)

0 8 −8
−8 0 8
8 0 0

ﬁrst use our ﬁrst tool to decompose this game into zero-sum part (Z,
4 4 2
(C, C), where Z =
and C =
0 0 4
6 0 4
which one is larger between C(Z,−Z)(
). However, we can further decompose the
) and C(C,−C))(
i
·
·
2 −2
0
4 2 4
coordination part by the second tool: C =
−2 0
2
2 0 2
4 2 4
2 −2 0
is a trivial matrix. It’s easy to see the second matrix on the RHS is 1
and the deﬁnition of the function C, for any point (p, q) in the dual space,

, where the ﬁrst matrix on the RHS
4 Z. Then by Lemmas 4 and 5,

. At this point, we still cannot easily ﬁgure out

Z) and coordination part

+

−

h

i

i

i

h

h

h

C(A,B)(p, q) = C(Z,−Z)(p, q) + C( 1

4

Z)(p, q) =

1

Z, 1
4

−

(1/4)2

(cid:0)

9

C(Z,−Z)(p, q)

0.

≥

·

(cid:1)

3.2 Results for Bimatrix Games

In this subsection, we identify several characterizations for general bimatrix games in which we
have chaotic behavior with MWU dynamic in a following set S in the cumulative payoﬀ (dual)
space Rn1+n2:

Sδ =

(p, q)
{

j

|∀

∈

S1, k

∈

S2, xj(p)

≥

δ and yk(q)

δ

.

}

≥

In order to show chaotic behavior of MWU in a speciﬁc bimatrix game (A, B), it is suﬃcient
to show C(A,B)(p, q) is strictly positive in the region Sδ, followed by applying Lemma 2. In the
previous subsection, we show that for each game (A, B), it can be decomposed into a zero-sum part
(Z,
Z) and a coordination part (C, C). Furthermore, C(A,B)(p, q) = C(Z,−Z)(p, q) + C(C,C)(p, q).
We also raise an intuition that if the zero-sum part is small, then the volume behavior in the game
(A, B) will be similar that in the coordination part; conversely, if the coordination part is small,
then the volume behavior will be similar to the zero-sum part. However, we have not yet presented
a way to compare the largeness of the two parts. This is what we do here.

−

3.2.1 First Characterization: Matrix Domination

The ﬁrst characterization we identify is matrix domination. In this part, we show that under certain
conditions, the zero-sum part is always no less than the coordination part, i.e. C(Z,−Z)(p, q)

≥
C(C,C)(p, q) for all (p, q). This directly implies C(A,B)(p, q) will be non-negative in the whole
−
dual space. Interestingly, the condition we identify is both necessary and suﬃcient. Similar result
can also be achieved in the case that coordination part is always no less than the zero-sum part.
We ﬁrst introduce the deﬁnition of the matrix domination.

Deﬁnition 4. We say matrix K dominates matrix L if they are of the same dimension, and for
any row indices j, j′ and column indices k, k′,

Kjk + Kj′k′

Kjk′

−

−

Kj′k

≥

Ljk + Lj′k′

Ljk′

−

−

Lj′k

.

(cid:12)
(cid:12)
Note that the domination induces a partial order on all matrices: if K dominates L and L dom-
(cid:12)
(cid:12)
inates M, then K dominates M. The theorem below gives the necessary and suﬃcient condition.

(cid:12)
(cid:12)

(cid:12)
(cid:12)

Theorem 7. C(A,B)(p, q) is non-negative for all p and q if and only if matrix of the zero-sum
part Z dominates the coordination part C.

The above theorem is based on the following crucial observation.

Observation 8. For any matrix Z,

C(Z,−Z)(p, q) =

1
4

Xj,j′∈S1
k,k′∈S2

xj(p)

yk(q)

·

·

xj′(p)

·

yk′(q)

Zjk + Zj′k′

Zjk′

−

−

·

(cid:0)

Zj′k

2 .

(cid:1)

Matrix domination only implies C(A,B)(p, q) is non-negative. In order to have C(A,B)(p, q) to

be strictly positive in the set S, we need θ-domination.

Deﬁnition 5. We say matrix K θ-dominates (θ > 0) matrix L if K dominates L, and there exist
j, j′, k, k′ such that

Kjk + Kj′k′

Kjk′

−

−

Kj′k

≥

Ljk + Lj′k′

Ljk′

−

−

Lj′k

+ θ.

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)
10

(cid:12)
(cid:12)

The following theorem holds due to Lemma 2.

Theorem 9. For any general bimatrix game (A, B) which is decomposed into zero-sum part (Z,
Z)
and coordination part (C, C), if Z θ-dominates C, then MWU with any suﬃciently small step-size
ǫ in the game (A, B) is Lyapunov chaotic in Sδ with Lyapunov exponent

−

θ2δ2
2(n1+n2) ǫ2.

Note that in Deﬁnition 5, K θ-dominates L if a ﬁnite number of inequalities are satisﬁed. In
the context of Theorem 9, it is easy to see that there is quite many games (A, B), such that Z θ-
dominates C with all those inequalities strictly satisﬁed. Thus, there exists an open neighbourhood
around these gamessuch that every game in the neighbourhood has its zero-sum part θ-dominates
its coordination part. This shows that such family of games has positive Lebesgue measure.

3.2.2 Second Characterization: Linear Program

Note that matrix domination is not always true. In some scenarios, the zero-sum matrix might
not dominate the coordination matrix. Yet, it is still possible that C(A,B)(p, q) is strictly positive
in the region Sδ =
, when every entry in the coordination
}
matrix is small.

δ and yk(q)

j, k xj(p)

(p, q)

|∀

≥

≥

{

δ

Precisely, for a general bimatrix game (A, B), if its coordination part (C, C) is small in the
sense that the absolute values of all entries in C are smaller than some constant r, then we can
(r2). This is not the only case we can bound C(C,−C)(
bound C(C,−C)(
) by a small term.
) by
·
·
Even the entries in matrix C are large, we can use trivial matrices to reduce them without aﬀecting
). This is done via a linear programming approach described below.
C(C,C)(
·
Given a matrix K, let r(K) be the optimal value of following linear program:

O

min
r≥0

r such that

gj −
gj + hk}j,k constructs a trivial matrix. Let K′ = K
Note that
gj + hk}j,k. By Lemma 5,
{
C(K,−K)(
) is closely
). The following lemma shows that the value of C(C,−C)(
) = C(K′,−K′)(
·
·
·
related to r(C).

Kjk −

hk ≤

j, k,

− {

(8)

−

≤

r.

∀

r

Lemma 10. For any (p, q) in Sδ =

(p, q)

{
(r(C))

δ)2

·

≤

j, k xj(p)

|∀
≥
C(C,−C)(p, q)

δ and yk(q)

δ

,

}

≥

r(C)2

≤

Then, by Lemma 10, the theorem below follows by applying Lemma 2.

Theorem 11. For any general bimatrix game (A, B) which is decomposed into zero-sum part
(r(C))2+(θδ)2, then MWU with any suﬃciently
(Z,
θ2
2(n1+n2) ǫ2.
small step-size ǫ in the game (A, B) is Lyapunov chaotic in Sδ with Lyapunov exponent

Z) and coordination part (C, C), if (r(Z)δ)2

≥

−

4 Multi-Player Games

Computing volume change of learning algorithm in multi-player game is slightly more involved than
the two-player case. We present a local equivalence formula of volume change between normal-
form and graphical games. This provides an intuitive procedure for understanding volume changes.
Proposition 14 shows that in multi-player game, the volume-changing behaviors of MWU and
OMWU are again opposite to each other (which was shown for bimatrix game in [11]).

11

∈

Graphical Games. A graphical game [23] is a special type of N -player game where the payoﬀs
can be compactly represented. In a graphical game H, for each pair of players i, k, there is an
edge-game which is a bimatrix game between the two players, denoted by (Hi,k, (Hk,i)T), where
Rni×nk is the payoﬀ matrix that denotes the payoﬀs to Player i. Then the payoﬀ to Player
Hi,k
i at strategy proﬁle s = (s1, s2,
, sN ) is the sum of payoﬀs to Player i in all her edge-games,
i.e. ui(s) =
si,sk . As is standard, this payoﬀ function is extended via expectation when
the inputs are mixed strategies.
P

Here, we ﬁrst use an observation from [10] to construct a family of multi-player graphical games
where MWU is Lyapunov chaotic in SN,δ :=
(p1,
. It was
}
{
observed that the function CH(p) deﬁned in (6) is the sum of C(Hi,k ,(Hk,i)T)(pi, pk) of all pairs of
Players i < k [10]. This observation yields Theorem 12.

Si, xij(pi)

k6=i H i,k

, pN )

[N ], j

· · ·

· · ·

|∀

≥

∈

∈

δ

i

↑ denote the family of bimatrix games which satisfy the condition either in
Theorem 12. Let
Theorem 9 or in Theorem 11. In an N -player graphical game where each edge-game is drawn from
↑, if all players are employing MWU with a suﬃciently small step-size ǫ, then the dynamical

G

G
system is Lyapunov chaotic in SN,δ with Lyapunov exponent N (N

1)θ2δ2ǫ2/4

−

N
i=1 ni.

Local Equivalence of General Games and Graphical Games. Next, we present a theorem
which connects the value of CG(p) of a general game to CH(p), where H is a graphical game.

P

Theorem 13. Given an N -player normal-form game G and any point p in the dual space, the
value of CG(p) is the same as CH(p), where H is a graphical game speciﬁed as follows: for each
Sk, the payoﬀ to Player i in her edge-game with Player k when
pair of Players i, k and j
Player i picks j and Player k picks ℓ is H ik

jℓ is deﬁned in Eqn. (1).

jℓ , where U ik

jℓ := U ik

Si, ℓ

∈

∈

This theorem shows that for any game G, the value of CG(p) is the same as in a particular
graphical game, where each pair of players, (i, k) play a bimatrix game whose utility is exactly the
utility of the original game G, but taking the expectation on the randomness of the other players’
strategies. If the original game G is a graphical game, then in the graphical game H ik
jℓ +c−i,−k,
where c−i,−k is a parameter which does not depend on Players i and k.

jℓ = U ik

Theorem 13 will be used in Appendix B to show the following proposition, which shows that the
volume-changing behaviors of MWU and OMWU are opposite to each other in multi-player game,
generalizing a prior result in [11].

Proposition 14. The volume integrands of MWU and OMWU in a multi-player game G are
(ǫ3). Thus, volume expands locally around
respectively 1 + CG(p)
a dual point p for MWU (resp. OMWU) if CG(p) is positive (resp. negative).

(ǫ3) and 1

CG(p)

ǫ2 +

ǫ2 +

O

O

−

·

·

Multiplayer Potential Game. By Observation 6, we know that the volume behavior of a
potential game is equivalent to a corresponding coordination game in bimatrix game.
In this
section, we want to show, this holds even in the multi player setting.

Lemma 15. Suppose
all players will receive

P
P

is the potential function of a potential game U. Let UP be a game that
(s) when players play strategies s. Then CU(p) = CUP (p)

0.

≤

In Appendix C, we will discuss some situations where CU(p) is strictly less than 0, thus OMWU

is Lyapunov chaotic therein.

12

References

[1] James P. Bailey and Georgios Piliouras. Multiplicative weights update in zero-sum games. In

EC, pages 321–338, 2018.

[2] Luis Barreira. Poincare recurrence: old and new. In XIVth International Congress on Mathe-

matical Physics. World Scientiﬁc., pages 415–422, 2006.

[3] Tamer Basar and Yu-Chi Ho. Informational properties of the nash solutions of two stochastic

nonzero-sum games. Journal of Economic Theory, 7(4):370–387, 1974.

[4] Victor Boone and Georgios Piliouras. From darwin to poincar´e and von neumann: Recurrence
and cycles in evolutionary and algorithmic game theory. In International Conference on Web
and Internet Economics (WINE), pages 85–99. Springer, 2019.

[5] Ozan Candogan, Ishai Menache, Asuman E. Ozdaglar, and Pablo A. Parrilo. Flows and
decompositions of games: Harmonic and potential games. Math. Oper. Res., 36(3):474–503,
2011.

[6] Ozan Candogan, Asuman E. Ozdaglar, and Pablo A. Parrilo. Dynamics in near-potential

games. Games Econ. Behav., 82:66–90, 2013.

[7] Ozan Candogan, Asuman E. Ozdaglar, and Pablo A. Parrilo. Near-potential games: Geometry

and dynamics. ACM Trans. Economics and Comput., 1(2):11:1–11:32, 2013.

[8] Nikolo Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge Uni-

versity Press, 2006.

[9] Yun Kuen Cheung. Multiplicative weights updates with constant step-size in graphical

constant-sum games. In NeurIPS 2018, pages 3532–3542, 2018.

[10] Yun Kuen Cheung and Georgios Piliouras. Vortices instead of equilibria in minmax opti-
mization: Chaos and butterﬂy eﬀects of online learning in zero-sum games. In Conference on
Learning Theory, COLT 2019, 25-28 June 2019, Phoenix, AZ, USA, pages 807–834, 2019.

[11] Yun Kuen Cheung and Georgios Piliouras. Chaos, extremism and optimism: Volume analysis

of learning in games. 2020. https://arxiv.org/abs/2005.13996.

[12] Chao-Kai Chiang, Tianbao Yang, Chia-Jung Lee, Mehrdad Mahdavi, Chi-Jen Lu, Rong Jin,
and Shenghuo Zhu. Online optimization with gradual variations. In COLT 2012 - The 25th
Annual Conference on Learning Theory, June 25-27, 2012, Edinburgh, Scotland, pages 6.1–
6.20, 2012.

[13] Constantinos Daskalakis, Alan Deckelbaum, and Anthony Kim. Near-optimal no-regret algo-

rithms for zero-sum games. Games and Economic Behavior, 92:327–348, 2015.

[14] Constantinos Daskalakis and Ioannis Panageas. The limit points of (optimistic) gradient de-
scent in min-max optimization. In Advances in Neural Information Processing Systems, pages
9256–9266, 2018.

[15] Constantinos Daskalakis and Ioannis Panageas. Last-iterate convergence: Zero-sum games and

constrained min-max optimization. ITCS, 2019.

13

[16] Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning

and an application to boosting. In EuroCOLT, pages 23–37, 1995.

[17] Yoav Freund and Robert E. Schapire. Game theory, on-line prediction and boosting. In COLT,

pages 325–332, 1996.

[18] Drew Fudenberg and David K. Levine. The Theory of Learning in Games. MIT Press Books.

The MIT Press, 1998.

[19] Sergiu Hart and Andreu Mas-Colell. Simple Adaptive Strategies:From Regret-Matching to
Uncoupled Dynamics. Number 8408 in World Scientiﬁc Books. World Scientiﬁc Publishing Co.
Pte. Ltd., June 2013.

[20] Elad Hazan and Satyen Kale. Extracting certainty from uncertainty: regret bounded by

variation in costs. Mach. Learn., 80(2-3):165–188, 2010.

[21] Josef Hofbauer and Karl Sigmund. Evolutionary Games and Population Dynamics. Cambridge

University Press, 1998.

[22] Adam Tauman Kalai and Ehud Kalai.

Engineering cooperation in two-player games.

http://www.robots.ox.ac.uk/

∼

sjrob/Outgoing/GT talks/kalai.pdf.

[23] Michael J. Kearns, Michael L. Littman, and Satinder P. Singh. Graphical models for game
theory. In UAI ’01: Proceedings of the 17th Conference in Uncertainty in Artiﬁcial Intelligence,
University of Washington, Seattle, Washington, USA, August 2-5, 2001, pages 253–260, 2001.

[24] Alistair Letcher, David Balduzzi, S´ebastien Racani`ere, James Martens, Jakob N. Foerster, Karl
Tuyls, and Thore Graepel. Diﬀerentiable game mechanics. J. Mach. Learn. Res., 20:84:1–84:40,
2019.

[25] Nick Littlestone and Manfred K Warmuth. The weighted majority algorithm. Information

and computation, 108(2):212–261, 1994.

[26] Edward N. Lorenz. Deterministic Nonperiodic Flow. Journal of the Atmospheric Sciences,

20(2):130–141, 03 1963.

[27] Panayotis Mertikopoulos, Christos Papadimitriou, and Georgios Piliouras. Cycles in adversar-

ial regularized learning. In SODA, pages 2703–2717, 2018.

[28] D. Monderer and L. S. Shapley. Potential games. Games and Economic Behavior, pages

124–143, 1996.

[29] Gerasimos Palaiopanos, Ioannis Panageas, and Georgios Piliouras. Multiplicative weights
update with constant step-size in congestion games: Convergence, limit cycles and chaos. In
NIPS, pages 5874–5884, 2017.

[30] Georgios Piliouras and Jeﬀ S. Shamma. Optimization despite chaos: Convex relaxations to

complex limit sets via poincar´e recurrence. In SODA, pages 861–873, 2014.

[31] H. Poincar´e. Sur le probl`eme des trois corps et les ´equations de la dynamique. Acta Math,

13:1–270, 1890.

[32] Ali

Rahimi.

NIPS

2017

test-of-time

award

presentation.

https://www.youtube.com/watch?v=ORHFOnaEzPc.

14

[33] Alexander Rakhlin and Karthik Sridharan. Online learning with predictable sequences. In
COLT 2013 - The 26th Annual Conference on Learning Theory, June 12-14, 2013, Princeton
University, NJ, USA, pages 993–1019, 2013.

[34] Alexander Rakhlin and Karthik Sridharan. Optimization, learning, and games with predictable

sequences. In NIPS, pages 3066–3074, 2013.

[35] William H. Sandholm. Population Games and Evolutionary Dynamics. MIT Press, 2010.

[36] Vasilis Syrgkanis, Alekh Agarwal, Haipeng Luo, and Robert E. Schapire. Fast convergence of
regularized learning in games. In Proceedings of the 28th International Conference on Neural
Information Processing Systems, NIPS’15, pages 2989–2997, 2015.

15

A Proofs in Section 3

Proof of Lemma 5. First, observe that it suﬃces to prove that the lemma holds when T1 is a trivial
matrix and T2 is the zero matrix. Then the lemma holds for any trivial matrices T1, T2 due to
symmetry: C(A,B)(p, q) = C(A+T1,B)(p, q) = C(A+T1,B+T2)(p, q).

Due to the deﬁnition of trivial matrix, we can write T 1

jk = uj + vk. Then

C(A+T1,B)(p, q)

C(A,B)(p, q)

−

=

E

Ajk + uj + vk −

Aj −

uj −





−





+ E [Ajk + uj + vk]

E [Bjk] + E [(Ajk −

Aj −

·

vℓyℓ −

Xℓ∈S2

Ak −

vk −

Xℓ∈S1
Ak)(Bjk −

uℓxℓ

Bk)]

Bj −

(Bjk −

Bj −

Bk)



E [Ajk]

·

−


E [Bjk]

=

E

−





−

= E [vk + uj]





vℓyℓ −

Xℓ∈S2
E [Bjk −

·

Xℓ∈S1
Bj −

uℓxℓ


Bk] + E [uj + vk]


E [Bjk] .

·

(Bjk −

Bj −

Bk)



+ E [uj + vk]

E [Bjk]

·

Bk] =

Bj −

By recalling that E [Bjk −
Proof of Observation 6. Let
Pjk be the potential value of a potential game when Player 1 plays
strategy j and Player 2 plays strategy k. Then according to the deﬁnition the potential function,
for any j1, j2 and k,

E [Bjk], we have C(A+T1,B)(p, q)

C(A,B)(p, q) = 0.

−

−

Aj2k =

Pj1k − Pj2k.

Aj1k −
Pjk + A1k − P1k. This implies that there exists v such that

In particular, for any j, k, Ajk =
Ajk =

Pjk + vk for any j and k.

Similarly, there exists u such that Bjk =

two-player potential games are coordination games plus trivial matrices.

Pjk + uj for any j and k. This implies that any

Proof of Theorem 7. We ﬁrst prove that if Z dominates C, then C(A,B)(p, q) is always non-negative.
By Observation 8,

C(A,B)(p, q) = C(Z,−Z)(p, q) + C(C,C)(p, q)
= C(Z,−Z)(p, q)

C(C,−C)(p, q)

−

=

1
4

Xj,j′,k,k′

xj(p)yk(q)xj′(p)yk′(q)
·

Zjk + Zj′k′

0.

≥

(cid:16)(cid:0)

Zjk′

−

−

2

Zj′k

−

Cjk + Cj′k′

Cjk′

−

−

(cid:1)

(cid:0)

2

Cj′k

(cid:17)

(cid:1)

In contrast, if Z does not dominate C, then there exist ˆj, ˆj′, ˆk, ˆk′ and δ > 0 such that

Cˆjˆk + Cˆj′ˆk′ −
(cid:16)

Cˆjˆk′ −

Cˆj′ˆk

2

(cid:17)

≥

Zˆjˆk + Zˆj′ˆk′ −
(cid:16)

Zˆjˆk′ −

Zˆj′ˆk

(cid:17)

2

+ δ.

16

For each η > 0, we construct p and q such that xˆj(p) = xˆj′(p) = yˆk(q) = yˆk′(q) = 1−η
2 . Further-
more, we let Υ denote the maximum absolute value of all entries in matrices A and B. Then, for
all j and k,

Υ. Therefore,

Υ and

Zjk| ≤
|

Cjk| ≤
|
C(A,B)(p, q) = C(Z,−Z)(p, q) + C(C,C)(p, q)
= C(Z,−Z)(p, q)

C(C,−C)(p, q)

−

=

1
4

Xj,j′,k,k′

xj(p)yk(q)xj′(p)yk′(q)
·

Zjk + Zj′k′

Zjk′

−

−

2

Zj′k

−

Cjk + Cj′k′

Cjk′

−

−

2

Cj′k

(cid:17)

(cid:1)

δ

≤ −

η

1

(cid:16)(cid:0)
−
2

4

(cid:19)

(cid:18)

+

2

S1|
|

2

S2|
· |

·

η

·

(cid:1)
16Υ2.

(cid:0)

Cjk + Cj′k′
The last inequality holds as
2
2
S2|
S1|
(cid:0)
· |
|

The value of

1−η
2

−

+

η

δ

4

·

·

(cid:16)

(cid:17)

2

Cjk′

Cj′k

Zjk + Zj′k′
≤
−
16Υ2 will be negative if we pick a small enough η.

Zj′k

Zjk′

−

−

−

−

(cid:1)

(cid:0)

(cid:1)

2

16Υ2.

Proof of Observation 8. Consider a random process, where j, j′
to distribution x(p), and k, k′
RHS of Observation 8 can be expressed as 1

S1 are randomly picked according
S2 are randomly picked according to distribution y(q). Then the
Zjk′

(Zjk + Zj′k′

Zj′k)2

∈

∈

E

.

Then we expand the squared term in the expectation. Observing the symmetries within the

4 ·

(cid:2)

−

−

(cid:3)

expansion, we immediately have

1
4 ·

E

(Zjk + Zj′k′

Zjk′

Zj′k)2

= E

(Zjk)2

−
Let Zj := [Zy]j and Zk = [ZTx]k. Then we have

−

(cid:2)

(cid:2)

(cid:3)

E

ZjkZjk′

(cid:2)

−

(cid:3)

−

(cid:3)

E

ZjkZj′k

+ E

ZjkZj′k′

.

(cid:2)

(cid:3)

(cid:2)

(cid:3)

E

ZjkZjk′

=

xjykZjk

yk′Zjk′ =

xj[Zy]j

ykZjk =

xj(Zj)2 = E

(Zj)2

.

Xk′

= E

(Zk)2

. Lastly, E

Xj
ZjkZj′k′

Xk
= E [Zjk]2. Thus, the RHS of Observation 8

Xj

(cid:3)

(cid:2)

(cid:2)

Similarly, E
is simpliﬁed to

Xj,k

(cid:3)
ZjkZj′k

(cid:2)

(cid:3)

(cid:2)
E

(cid:3)
(Zjk)2

(cid:2)
(Zj)2

E

(cid:3)
(Zk)2

E

+ E [Zjk]2 .

−
)
) in Eqn. (4), C(Z,−Z)(
We complete the proof by noting that from the deﬁnition of C(Z,−Z)(
·
·

−

(cid:3)

(cid:2)

(cid:2)

(cid:3)

(cid:2)

(cid:3)

can be rewritten as

E

while E [ZjZjk] =

j xjZj

(Zjk)2

−
k ykZjk =
(cid:2)

(cid:3)

E [ZjZjk]

−

E [ZkZjk] + E [Zjk]2 ,

j xjZjZj = E

(Zj)2

, and similarly E [ZjZjk] = E

(Zk)2

.

P

P

P

(cid:2)

(cid:3)

Proof of Theorem 9. We only need to prove ¯c(S) = inf (p,q)∈S C(A,B)(p, q)
≥
matrix Z θ-dominates C, which implies there exist j, j′, k, and k′ such that

(cid:3)
δ2θ2. This is because

(cid:2)

Zjk + Zj′k′

Zjk′

−

−

2

Zj′k

Qjk + Qj′k′

Qjk′

Qj′k

2 + θ2.

(cid:0)

−

≥
C(C,−C)(p, q) + θ2δ2, because every xj(p), yk(q) for
C(C,−C)(p, q) and C(A,B)(p, q) =

−

(cid:1)

(cid:1)
≥

(cid:0)

By applying Observation 8, C(Z,−Z)(p, q)
(p, q)
C(Z,−Z)(p, q) + C(C,C)(p, q), the result follows.

S is at least δ. By noting that C(C,C)(p, q) =

∈

−

17

Proof of Lemma 10. A key observation is

C(C,−C)(p, q) = min
g,h

Xjk

xj(p)yk(q) (Cjk −

gj −

hk)2 .

With this observation and comparing this with the deﬁnition of r(Z), it’s easy to ﬁgure out that
C(C,−C)(p, q)

δ)2, we ﬁrst let g∗ and h∗ to be the optimal choice of g and h

·

(r(C))
j,k xj(p)yk(q) (Cjk −
gj −
h∗
Cjk −
k} −

max
j,k {

g∗
j −

≤

P
2r(C)

hk)2. One immediate observation is 5

min
j,k {

Cjk −

g∗
j −

h∗
.
k}

r(C)2.
To see C(C,−C)(p, q)
≥
in C(C,−C)(p, q) = ming,h

≤

Therefore,

max

((cid:18)

max
j,k {

Cjk −

g∗
j −

h∗
k}

(cid:19)

This immediately implies that C(C,−C)(p, q)

2

,

≥

min
j,k {

Cjk −

g∗
j −

(cid:18)

2

h∗
k}

(cid:19)

) ≥

r(C)2.

(r(C))

δ)2.

·

B Local Equivalence of Volume Change between Normal-form and

Graphical Games

In this appendix, we concern the volume change of a learning algorithm in multi-player game.
We ﬁrst recap from [11] on how the volume change is computed for dynamical systems which
are gradual (i.e. those governed by a small step-size), followed by a continuous-time analogue of
OMWU in games, which are crucial for analyzing the volume change of discrete-time OMWU.
Then we compute the volume changes of MWU and OMWU in multi-player graphical games and
normal-form games respectively. Once these are done, the proofs of Proposition 14 and Theorem 11
become apparent.

B.1 Discrete-Time Dynamical Systems and Volume of Flow

We consider discrete-time dynamical systems in Rd. Such a dynamical system is determined recur-
Rd and an update rule of the form s(t + 1) = G(s(t)), for some
sively by a starting point s(0)
function G : Rd
Rd. Here, we focus on the special case when the update rule is gradual, i.e. it is
in the form of

→

∈

s(t + 1) = s(t) + ǫ

F (s(t)),

·

→

where F : Rd
Rd is a smooth function and step-size ǫ > 0. When F and ǫ are given, the ﬂow
of the starting point s(0) at time t, denoted by Φ(t, s(0)), is simply the point s(t) generated by
Rd at time t, denoted by Φ(t, S),
the above recursive update rule. Then the ﬂow of a set S
⊂
Φ(t, s)
. Since F does not depend on time t, we have the following equality:
is the set
}
Φ(t1 + t2, S) = Φ(t2, Φ(t1, S)).

∈

S

{

s

|

By equipping Rd with the standard Lebesgue measure, the volume of a measurable set S, denoted
Rd, if the discrete ﬂow

by vol(S), is simply its measure. Given a bounded and measurable set S

5If this is not true, we can let g and h in r(Z) to be gj = g∗

maxj,k{Cjk −g

∗
∗
k }−minj,k {Cjk −g
j −h

Then we can achieve r(C) =

maxj,k{Cjk −g

⊂
∗
∗
k}+minj,k{Cjk −g
j −h

∗
∗
j −h
k}

j −
∗
∗
j −h
k }

2

which make r(C) smaller.

and hk = h∗
k.

2

18

in one time step maps S to S′ = Φ(1, S) injectively, then by integration by substitution for multi-
variables,

where I is the identity matrix, and J(s) is the Jacobian matrix deﬁned below:

vol(S′) =

det (I + ǫ

·

J(s)) dV,

Zs∈S

J(s) =

∂
∂s1
∂
∂s1

∂
∂s1

F1(s)
F2(s)
...
Fd(s)

∂
∂s2
∂
∂s2

∂
∂s2

F1(s)
F2(s)
...
Fd(s)

· · ·
· · ·
. . .

· · ·









∂
∂sd
∂
∂sd

∂
∂sd

F1(s)
F2(s)
...
Fd(s)

.









(9)

(10)

Clearly, analyzing the determinant in the integrand in (9) is crucial in volume analysis; we call
it the volume integrand. When the determinant is expanded using the Leibniz formula, it becomes
ǫh +
a polynomial of ǫ, in the form of 1 + C(s)
1. Thus, when
the step-size ǫ is suﬃciently small, the sign of C(s) dictates on whether the volume expands or
contracts.

(ǫh+1) for some integer h

O

≥

·

B.2 Continuous-Time Analogue of OMWU

OMWU does not fall into the category of dynamical systems deﬁned above, since its update rule
is in the form of s(t + 1) = G(s(t), s(t
1)). Fortunately, Cheung and Piliouras [11] showed
that OMWU can be well-approximated by the online Euler discretization of a system of ordinary
diﬀerential equations (ODE), and thus it can be well-approximated by a dynamical system.
The ODE system is given below. p is a dual (cumulative payoﬀ) vector variable, u : R+

Rd
is the function such that u(t) gives the instantaneous payoﬀ vector at time t. We assume that u is
twice diﬀerentiable with bounded second-derivatives, and ˙u denotes the time-derivative of u.

→

−

˙p = u + ǫ

˙u,

·

(11)

Online Euler discretization (OED) of (11) refers to the following time-discretization of the ODE
are
, t). As the discretization
1))/ǫ. By using this approximation, OED of (11)

system. In applications, ˙u might not be explicitly given, and the sequence u(0), u(1), u(2),
available online (i.e., at time t we only have access of u(τ ) for τ = 0, 1,
step is ǫ, we approximate ˙u(t) by (u(t)
yields

u(t

· · ·

· · ·

−

−

p(t + 1) = p(t) + ǫ

u(t) + ǫ

·

(cid:20)
which is exactly the OMWU update rule in general context.

(cid:21)

u(t)

−

u(t
ǫ

·

1)

−

= p(t) + ǫ

u(t)

[2

·

·

−

u(t

−

1)] ,

When compared the OED with the standard Euler discretization

p(t + 1) = p(t) + ǫ

[u(t) + ǫ

˙u(t)] ,

·

·

OED incurs a local error that appears due to the approximation of ˙u(t). The local error can be
(ǫ3). Cheung and Piliouras [11] showed that eventually the determinant of the volume
bounded by
(ǫ3), the local error does not aﬀect the ﬁrst and second
integrand is a of the form 1 + C(s)
highest-order terms, and hence can be ignored henceforth.

ǫ2 +

O

O

·

19

B.3 MWU in Graphical Games

Let H be a graphical game of N players, where between every pair of Players i and k, the payoﬀ
bimatrices are (Hik, (Hki)T). In the dual space, let p = (p1,
, pN ) denote the cumulative payoﬀ
, xN ) denote the corresponding mixed strategy proﬁle, where xi is a
proﬁle, and let x = (x1,
function of pi. We will write xi and xi(pi) interchangeably. The expected payoﬀ to strategy j of
Player i is

· · ·

· · ·

uij(p) =

[Hik

Xk∈[N ]
k6=i

xk(pk)]j,

·

which will be used to compute the Jacobian matrices of MWU and OMWU.

For MWU, the Jacobian matrix J is a squared matrix with each row and each column indexed

by (i, j), where i is a Player and j

∈

Si. The precise values of its entries are given below:

j1, j2 ∈

∀

Si,

ǫJ(i,j1),(i,j2) = ǫ

∂uij1
∂pij2

·

= 0

(12)

and

i

= k, j

H ik
= ǫxkℓ ·
(cid:16)
Then by expansion using Leibniz formula, the determinant of (I + ǫ
·

ǫJ(i,j),(k,ℓ) = ǫ

Si, ℓ

jℓ −
J) is

Sk,

∈

∈

∀

·

∂uij
pkℓ

[Hik

·

xk]j

.

(13)

(cid:17)

(ǫJ(i,j),(k,ℓ))(ǫJ(k,ℓ),(i,j)) +

(ǫ3)

O

1

−

j∈Si Xk>i
Xi∈[N ]
ℓ∈Sk
ǫ2

−

·

= 1

xijxkℓ

H ki

ℓj −

[Hki

xi]ℓ

·

(cid:17) (cid:16)

H ik

jℓ −

[Hik

xk]j

·

(cid:17)

(ǫ3).

+

O

(14)

j∈Si Xk>i
Xi∈[N ]
ℓ∈Sk

(cid:16)

By noting the similarity of the double summation to C(A,B)(
) in (4), we can immediately rewrite
·
the above expression as

1 + ǫ2

·

Xi,k:1≤i<k≤N

C(Hik,(Hki)T)(pi, pk) +

(ǫ3).

O

(15)

B.4 OMWU in Graphical Games

For OMWU, as we pointed out already, we will ﬁrst consider its continuous analogue ﬁrst. Thus,
we need to compute ˙u in the continuous-time setting. By chain rule, we have

˙uij(p) =

Xk∈[N ]
k6=i
ℓ∈Sk

∂[Hik

xk(pk)]j

·
∂pkℓ

dpkℓ
dt

·

=

H ik

jℓ −

[Hik

xk]j

·

dpkℓ
dt

,

·

(cid:17)

xkℓ ·

(cid:16)

Xk∈[N ]
k6=i
ℓ∈Sk

and hence

dpij
dt

=

[Hik

Xk∈[N ]
k6=i

xk]j + ǫ

·

xkℓ ·

·

Xk∈[N ]
k6=i
ℓ∈Sk

20

H ik

jℓ −

(cid:16)

[Hik

xk]j

·

dpkℓ
dt

.

·

(cid:17)

6
Note that this is a recurrence formulae for

dp
dt . By iterating it6, we have

dpij
dt

=

[Hik

Xk∈[N ]
k6=i

xk]j + ǫ

·

xkℓ ·

(cid:16)

·

Xk∈[N ]
k6=i
ℓ∈Sk

H ik

jℓ −

[Hik

xk]j

·

[Hkr

Xr∈[N ]
r6=k

·

(cid:17)







xr]ℓ

+

·

(ǫ2).

O





Hence, its standard Euler discretization, which approximates the OED with local error
be written as below (where we ignore the

(ǫ3) error terms):

O

(ǫ3), can

O

pij(t + 1) = pij(t) + ǫ

[Hik

Xk∈[N ]
k6=i

xk]j + ǫ2

·

xkℓ ·

(cid:16)

Xk∈[N ]
k6=i
ℓ∈Sk

H ik

jℓ −

[Hik

xk]j

·

[Hkr

Xr∈[N ]
r6=k

·

(cid:17)







xr]ℓ

.

·





With this, we are ready to compute the Jacobian matrix J for OMWU. For all j1, j2 ∈
H ik
xi]ℓ
(cid:16)

ǫJ(i,j1),(i,j2) = ǫ2

H ki
(cid:16)

xij2 ·

xkℓ ·

ℓj2 −

j1ℓ −

xk]j1

[Hki

[Hik

(cid:17)

(cid:17)

·

·

·

Xk∈[N ]
k6=i
ℓ∈Sk

and for all i

= k, j

Si, ℓ

Sk,

∈

∈

ǫJ(i,j),(k,ℓ) = ǫxkℓ

Then by expansion using Leibniz formula, the determinant of (I + ǫ

H ik

jℓ −

[Hik

·

xk]j

+

(ǫ2)

O

(cid:16)

(cid:17)

Si,

(16)

(17)












P

1 +

ǫJ(i,j),(i,j)

−

Xi∈[N ]
j∈Si

j∈Si Xk>i
Xi∈[N ]
ℓ∈Sk

(ǫJ(i,j),(k,ℓ))(ǫJ(k,ℓ),(i,j))

T1

T2

(ǫ3).

+

O

|

{z

}

|

(ǫ3) terms).
By a direct expansions on T1 and T2, it is easy to see that T1 = 2T2 (after ignoring
On the other hand, the coeﬃcient of ǫ2 in T2 is exactly the same as the double summation in (14),
i,k:1≤i<k≤N C(Hik,(Hki)T)(pi, pk). Overall, we show that the determinant equals
thus it equals to
to

O

−

{z

}

1

ǫ2

·

−

Xi,k:1≤i<k≤N

C(Hik,(Hki)T)(pi, pk) +

(ǫ3).

O

(18)

Observation 16. The coeﬃcient of ǫ2 in (18) is the exact negation of the coeﬃcient of ǫ2 in (15).

6For the formality on why we can do iterations when ǫ is suﬃciently small, see [11].

21

J) is

·












6
B.5 Completing the Local Equivalence Proof

In a multiplayer normal-form game G, recall that notation (1). We point out the following formulae:

∂U i1i2···ig
j1j2···jg
∂pij
∂U i1i2···ig
j1j2···jg
∂pij

= 0

if i

i1, i2,

∈ {

;
, ig}

· · ·

= xij ·

U i1i2···igi
j1j2···jgj −
(cid:16)

U i1i2···ig
j1j2···jg

(cid:17)

if i /

i1, i2,

∈ {

.
, ig}

· · ·

MWU. Here, MWU update rule is pij(t + 1) = pij(t) + ǫ
j . When computing the Jacobian
matrix for this update rule using the formulae above, and comparing it with the Jacobian matrix
computed in (12) and (13), it is immediate that they are the same by setting H ik
jℓ . This
derives (6), and completes the proof of Theorem 13.

jℓ = U ik

·

U i

OMWU. As before, we use the continuous analogue and compute ˙u. By the chain rule and the
above formulae, we have

and hence

˙uij(p) =

Xk∈[N ]
k6=i
ℓ∈Sk

∂U i
j
∂pkℓ ·

dpkℓ
dt

=

xkℓ ·

U i
j

U ik
(cid:16)

jℓ −

·

(cid:17)

dpkℓ
dt

Xk∈[N ]
k6=i
ℓ∈Sk

dpij
dt

= U i

j + ǫ

xkℓ ·

U i
j

U ik
(cid:16)

jℓ −

·

(cid:17)

dpkℓ
dt

.

·

Xk∈[N ]
k6=i
ℓ∈Sk

Iterating the above recurrence yields

dpij
dt

= U i

j + ǫ

xkℓ ·

U i
j

U ik
(cid:16)

jℓ −

·

(cid:17)

U k

ℓ +

(ǫ2).

O

·

Xk∈[N ]
k6=i
ℓ∈Sk

Its standard Euler discretization is

pij(t + 1) = pij(t) + ǫ

j + ǫ2
U i

·

·

xkℓ ·

U i
j

U ik
(cid:16)

jℓ −

·

(cid:17)

U k
ℓ .

Xk∈[N ]
k6=i
ℓ∈Sk

Now we compute the Jacobian matrix for this standard Euler discretization. For j1, j2 ∈
xkℓ ·

ǫJ(i,j1),(i,j2) = ǫ2

xij2 ·

ℓj2 −

j1ℓ −

U i
j1

U k
ℓ

·

Si,

U ik
(cid:16)

U ki
(cid:16)

(cid:17)

(cid:17)

Xk∈[N ]
k6=i
ℓ∈Sk

and for all i

= k, j

Si, ℓ

Sk,

∈

∈

ǫJ(i,j),(k,ℓ) = ǫxkℓ

U ik
(cid:16)
By comparing this computed Jacobian matrix with the Jacobian matrix computed in (16) and (17),
(ǫ3) terms) by
it is immediate to see that their determinants are the same (after ignoring all
setting H ik
jℓ . With the result we just derived, together with Observation 16 and Theorem 13,
Proposition 14 follows.

jℓ = U ik

jℓ −

(ǫ2).

U i
j

O

O

+

(cid:17)

22

6
C Multi-player Potential Game

Proof of Lemma 15. We know that the potential game satisﬁes the following condition:

Therefore, ui(si, s−i) =
of player i.

P

(s′

(si, s−i)
−
P
(si, s−i) + vi(s−i). Note that vi(s−i) does not depend on si, the strategy

i, s−i) = ui(si, s−i)

ui(si′, s−i).

− P

By Theorem 13, let H(U) be the induced graphical game of U and H(UP ) be the induced

graphical game of UP . Then,

CU(p) = CH(U)(p)

C(H(U)ik ,(H(U)ki)T)(pi, pk)

=

=

Xi,k

(Theorem 13)

(By (15))

C(H(UP )ik,(H(UP )ki)T)(pi, pk)

(see explanation below)

Xi,k

= CH(UP )(p)
= CUP (p).

(By (15))

(Theorem 13)

The third equality holds as the diﬀerence between H(U)ik and H(UP )ik is a trivial matrix:

H(U)ik

jl =

jl = Uik
vi(s−i)

UP

ik
jl + E−(i,k)

vi(s−i)

= H(UP )ik

jl + E−(i,k)

vi(s−i)

;

where 7 E−(i,k)
strategy of player k. The same argument applies for (H(U)ki)T and (H(UP )ki)T.

doesn’t depend on j, the strategy of player i, and only depends on l, the

(cid:1)

(cid:0)

(cid:3)

(cid:2)

(cid:3)

(cid:2)

(cid:2)
To see CU(p)

(cid:3)

0, observe that the induced graphical game of UP between player i and k,
(H(UP )ik, (H(UP )ki)T), is also a bimatrix coordination game, which implies C(H(UP )ik,(H(UP )ki)T)(
)
·
0. As CU(p) =

i,k C(H(UP )ik,(H(UP )ki)T)(pi, pk), the result follows.

≤

≤

Next, we identify several cases such that CU(p) is strictly negative in the region

P

. Note that H(UP )ik, the in-
The conditions we pose are on the corresponding potential function
duced edge-game between player i and k, is also a coordination game, i.e. H(UP )ik = (H(UP )ki)T.

P

Sδ =

x
{

|∀

i, j xij > δ

.
}

Case 1:

•

jℓ = Es−(i,k)

where P ik
CU(p)

≤ −

min
x,g,h

P

(cid:2)

P ik

jℓ −

gik
j −

hik
ℓ

2

(cid:17)

θ,

≥

X1≤i<k≤N Xj∈Si,ℓ∈Sk (cid:16)
(si = j, sk = ℓ, s−(i,k))

. With this condition, we can prove that

θδ2 for any p in Sδ. One key observation for this is true is that

CU(p) =

(cid:3)
C(H(UP )ik,(H(UP )ki)T)(pi, pk)

Xi,k

=

−

Xi,k Xj,ℓ

xij(pi)xkℓ(pk)

P ik

jℓ −

gik
j −

hjℓ
ℓ

(cid:16)

2

,

(cid:17)

as H(UP )ik = UP ik

= Pik.

7E−(i,k) (cid:2)vi(s−i)(cid:3) is the expectation over all the strategies taken by the players other than i and k and vi(s−i)

does not depend on the strategy taken by player i.

23

•

•

Case 2:

If U is a graphical game, then if there exists a pair of player i1 and i2, such that the game
between i1 and i2 is a non-trivial game, then CU will be strictly negative in Sδ.

Q

M

i6=i1,i2

1.8 Let’s call this the trivial space, denoted by

ni2. On the other hand, trivial matrices form a

Case 3:
Consider the payoﬀ matrix of UP , the coordination game, between players i1 and i2 given a
ni such matrices, one for each
strategy proﬁle of the other players. There are total
ni2. We call these
strategy proﬁle of the other players, and each matrix is of dimension ni1 ×
matrices the projected matrices for players i1, i2.
denote the matrix space of ni1 ×

Let
subspace of dimension ni1 + ni2 −
We consider the direct decomposition
T ⊕V
M
1 bases form a basis of
where the ﬁrst ni1 + ni2 −
. Without loss of generality, we assume that all bases are of L2 norm 1.9
V
, each of the projected matrices can be written into a
Given the above-mentioned bases of
unique linear combination of these bases. Now, suppose there is a base Bℓ for l
ni1 + ni2
(i.e. this base is in the set of bases for
), such that all projected matrices have non-positive
(or non-negative) coeﬃcients of this base, and at least one of these projected matrices (which
we call a special projected matrix ) has strictly negative (or strictly positive) coeﬃcient of the
base. Then we claim that C(H(UP )i1 i2 ,(H(UP )i2i1 )T)(pi1 , pi2) will be strictly negative in Sδ.
This is because H(UP )i1i2 is a convex combination of all those projected matrices, and by
our assumption above, when H(UP )i1i2 is expressed as the linear combinations of the bases
, the coeﬃcient of Bℓ is strictly negative (or strictly positive), thus H(UP )i1i2 cannot
of
be a trivial matrix.

, and the remaining bases form a basis of

. Let a set of bases of

be B1, B2, B3,

M

M

M

· · ·

≥

=

V

T

T

.

, Bni1 ni2

,

Suppose further that there exists θ > 0 such that a special projected matrix has negative
(or positive) coeﬃcient for Bℓ which is smaller (or bigger) than
θ (or θ), then we are
−
for a distance of θδN −2,10 and hence as
guaranteed that H(UP )i1i2 is bounded away from
θ2δ2N −2. If there exists a
the calculations below show, C(H(UP )i1i2 ,(H(UP )i2 i1 )T)(pi1, pi2)
pair of player i1 and i2 such that this condition holds, then CU

θ2δ2N −2.

≤ −

T

≤ −

8Recall that a trivial matrix T can be represented as {uj + vk}j,k. Consider the natural linear map L such that
L(u1, u2, · · · , uni1 , v1, v2, · · · , vni2 ) maps to the trivial matrix T. Note that the kernel of L is of dimension 1, since if
L(u1, u2, · · · , uni1 , v1, v2, · · · , vni2 ) is the zero matrix, then we must have vk = −uj for all j, k, and hence the kernel
of L must be the span of the vector (1, 1, · · · , 1
). Thus, the dimension of all trivial matrices is the

, −1, −1, · · · , −1

|
{z
}
the u part

|

{z
the v part

}

dimension of the domain of L, which is ni1 + ni2 , minus the dimension of the kernel of L.

9Here, the norm is deﬁned w.r.t. the standard Frobenius matrix inner product.
10To see why, when the coeﬃcient for Bℓ is bounded away from zero, we are guaranteed that the special projected
matrix has a strictly positive distance from T , and this distance is at least θ. Then H(UP )i1i2 , which is a convex
combination of all projected matrices where each projected matrix (in particular, the special projected matrix) has
a weight at least δN−2, has a strictly positive distance from T too, which is at least θδN−2.

24

C(H(UP )i1i2 ,(H(UP )i2i1 )T)(pi1, pi2 )

xi1j(pi1)xi2,l(pi2 )(H(UP )i1i2

gj −

−

hk)2

=

min
g,h

−

min
g,h

≤ −

Xjl
δ2

Xjl
(H(UP )i1i2

δ2

=

−

≤ −

Xjl

δ2(θδN −2)2,

(H(UP )i1i2

gj −

−

hk)2

g∗
j −

−

h∗
k)2

k}jk is projection of H(UP )i1i2 on the trivial space. The ﬁrst inequality follows
j + h∗
g∗
where
{
Sδ; the second equality holds as the projection minimizing the distance to the trivial
as p
space, and the ﬁnal inequality comes from the distance from H(UP )i1i2 to the trivial space.

∈

For all these cases, we can have OMWU is CU to be strictly negative in domain Sδ, which

implies OMWU is Lyapunov chaotic in Sδ.

25

