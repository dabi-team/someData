Implicitly Learning to Reason in First-Order Logic

Vaishak Belle1, Brendan Juba2

1University of Edinburgh, UK & Alan Turing Institute, UK
vaishak@ed.ac.uk
2Department of Computer Science & Engineering, Washington University in St. Louis, USA
bjuba@wustl.edu

9
1
0
2

n
u
J

4
2

]
I

A
.
s
c
[

1
v
6
0
1
0
1
.
6
0
9
1
:
v
i
X
r
a

Abstract

We consider the problem of answering queries
about formulas of ﬁrst-order logic based on back-
ground knowledge partially represented explicitly
as other formulas, and partially represented as ex-
amples independently drawn from a ﬁxed prob-
ability distribution. PAC semantics,
introduced
by Valiant, is one rigorous, general proposal for
learning to reason in formal languages: although
weaker than classical entailment, it allows for a
powerful model theoretic framework for answering
queries while requiring minimal assumptions about
the form of the distribution in question. To date,
however, the most signiﬁcant limitation of that ap-
proach, and more generally most machine learning
approaches with robustness guarantees, is that the
logical language is ultimately essentially proposi-
tional, with ﬁnitely many atoms. Indeed, the the-
oretical ﬁndings on the learning of relational theo-
ries in such generality have been resoundingly neg-
ative. This is despite the fact that ﬁrst-order logic is
widely argued to be most appropriate for represent-
ing human knowledge.
In this work, we present
a new theoretical approach to robustly learning to
reason in ﬁrst-order logic, and consider universally
quantiﬁed clauses over a countably inﬁnite domain.
Our results exploit symmetries exhibited by con-
stants in the language, and generalize the notion
of implicit learnability to show how queries can
be computed against (implicitly) learned ﬁrst-order
background knowledge.

learning should be integrated with deduction. In particular,
he proposed a semantics to capture the quality possessed by
the output of (probably approximately correct) PAC-learning
algorithms when formulated in a logic. Although weaker than
classical entailment, it allows for a powerful model theoretic
framework for answering queries.

From the standpoint of

learning an expressive logi-
cal knowledge base and reasoning with it, most PAC re-
sults are somewhat discouraging. For example, in agnos-
tic learning [Kearns et al., 1994] where one does not re-
quire examples (drawn from an arbitrary distribution) to
be fully consistent with learned sentences, eﬃcient al-
gorithms for learning conjunctions would yield an eﬃ-
cient algorithm for PAC-learning DNF (also over arbi-
trary distributions), which current evidence suggests to
be intractable [Daniely and Shalev-Shwartz, 2016]. Thus,
it
is not surprising that when it comes to ﬁrst-order
logic (FOL), very little work tackles the problem in a
general manner.
that FOL
is widely argued to be most appropriate for represent-
ing human knowledge (e.g., [McCarthy and Hayes, 1969;
Moore, 1982; Levesque and Lakemeyer, 2001]). For exam-
ple, [Cohen and Hirsh, 1994] consider the problem of the
learnability of description logics with equality constraints.
While description logics are already restricted fragments of
FOL in only allowing unary and some binary predicates, it is
shown that such a fragment cannot be tractably learned, lead-
ing to the identiﬁcation of syntactic restrictions for learning
from positive examples alone. Analogously, when it comes
to the learning of logic programs [Cohen and Page, 1995],
which in principle may admit inﬁnitely many terms, syntactic
restrictions are also typical [De Raedt and Dˇzeroski, 1994].

This is despite the fact

1 Introduction

The tension between deduction and induction is perhaps the
most fundamental issue in areas such as philosophy, cog-
nition and artiﬁcial intelligence. The deduction camp con-
cerns itself with questions about the expressiveness of for-
mal languages for capturing knowledge about the world, to-
gether with proof systems for reasoning from such knowledge
bases. The learning camp attempts to generalize from exam-
ples about partial descriptions about the world. In an inﬂu-
ential paper, [Valiant, 2000] recognized that the challenge of

In this work, we present new results on learning to reason
in FOL knowledge bases. In particular, we consider the prob-
lem of answering queries about FOL formulas based on back-
ground knowledge partially represented explicitly as other
formulas, and partially represented as examples indepen-
dently drawn from a ﬁxed probability distribution. Our results
are based on a surprising observation made in [Juba, 2013]
about the advantages of eschewing the explicit construction
of a hypothesis, leading to a paradigm of implicit learnabil-
ity. Not only does it enable a form of agnostic learning while
circumventing known barriers, it also avoids the design of an
often restrictive and artiﬁcial choice for representing hypothe-

 
 
 
 
 
 
ses. (See, for example, [Khardon and Roth, 1999], which is
similar in spirit in allowing declarative background knowl-
In particu-
edge but only permits constant-width clauses.)
lar, implicit learning allows such learning from partially ob-
served examples, which is commonplace when knowledge
bases and/or queries address entities and relations not ob-
served in the data used for learning.

That work was limited to the propositional setting, how-
ever. Here, we develop a ﬁrst-order logical generalization.
Since reasoning in full FOL is undecidable we need to con-
sider a fragment, but the fragment we identify and are able to
learn and reason with is expressive and powerful. Consider
that standard databases correspond to a maximally consistent
and ﬁnite set of literals: every relevant atom is known to be
true and stored in the database, or known to be false, inferred
by (say) negation as failure. Our fragment corresponds to a
consistent but inﬁnite set of ground clauses, not necessarily
maximal. To achieve the generalization, we revisit the PAC
semantics and exploit symmetries exhibited by constants in
the language. Moreover, the underlying language is general
in the sense that no restrictions are posed on clause length,
predicate arity, and other similar technical devices seen in
PAC results. We hope the simplicity of the framework is ap-
pealing to the readers and hope our results will renew interest
in learnability for expressive languages with quantiﬁcational
power.

as

(SRL)

fall under

the banner of

that
learning

unifying statistical

[Richardson and Domingos, 2006]

We remark that our sole focus is in PAC-semantics
there are also other families of meth-
approaches, but
representa-
and logical
ods
for
rela-
statistical
tions,
[Kersting et al., 2011]).
tional
(e.g.,
SRL includes widely used formalisms such as Markov
Logic Networks
and
Inductive Logic Programming
such
frameworks
[Muggleton and De Raedt, 1994].
Generally speaking,
there are signiﬁcant diﬀerences to PAC-semantics ap-
proaches, such as in terms of the learning regime, the notion
of correctness and the underlying algorithmic machinery.
For example, Markov Logic Networks use approximate
maximum-likelihood learning strategies
to capture the
distribution of the data, whereas in PAC formulations, one
considers an arbitrary unknown distribution over the data
and studies the question of what formulas are learnable
whilst costing for the number of examples needed to be
sampled from that distribution. Of course, there is much
to be gained by attempting to integrate these communities;
see, for example, [Cohen and Page, 1995]. These diﬀerences
notwithstanding, the learning of logical theories is usually
restricted to ﬁnite-domain ﬁrst-order logic, and so it
is
essentially propositional, and in that regard, our setting is
signiﬁcantly more challenging.

2 Logical Framework
Language: We let L be a ﬁrst-order language with equal-
ity and relational symbols {P(x), . . . , Q(x1, . . . , xk), . . .}, vari-
ables {x, y, z, . . .}, and a countably inﬁnite set of rigid des-
ignators or names, say, the set of natural numbers N, serv-
ing as the domain of discourse for quantiﬁcation. Well-

deﬁned formulas are constructed using logical connectives
{¬, ∨, ∀, ∧, ∃, ⊃}, as usual. Together with equality, names es-
sentially realize an inﬁnitary version of the unique-name as-
sumption.1

The set of (ground) atoms is obtained as:2 ATOMS =
(cid:8)P(a1, . . . , ak) | P is a predicate, ai ∈ N(cid:9) . We sometimes refer
to elements of ATOMS as propositions, and ground formu-
las as propositional formulas. We will use p, q, e to denote
atoms, and α, β, φ, ψ to denote ground formulas.

Semantics: A L-model M is a {0, 1} assignment to the ele-
ments of ATOMS. Using |= to denote satisfaction, the seman-
tics for φ ∈ L is deﬁned as usual inductively, but with equality
as identity: M |= (a = b) iﬀ a and b are the same names, and
quantiﬁcation understood substitutionally over all names in
N: M |= ∀xφ(x) iﬀ M |= φ(a) for all a ∈ N. We say that φ
is valid iﬀ for every L-model M, M |= φ. Let the set of all
models be M.

Representation: Like in standard FOL, reasoning over
the full fragment of L is undecidable.
Interestingly, ow-
ing to a ﬁxed, albeit countably inﬁnite, domain of dis-
the compactness property that holds for classical
course,
ﬁrst-order logic does not hold in general [Levesque, 1998].
{∃xP(x), ¬P(1), ¬P(2), . . .}
For example,
is an unsatisﬁ-
able theory for which every ﬁnite subset is indeed satisﬁ-
able. However, as identiﬁed in [Belle, 2017], and earlier
in [Lakemeyer and Levesque, 2002], the case of disjunctive
knowledge is more manageable.
In particular, we will be
interested in learning and reasoning with incomplete knowl-
edge bases with disjunctive information [Belle, 2017]:

Deﬁnition 1: An acceptable equality is of the form x = a,
where x is any variable and a any name. Let e range over
formulas built from acceptable equalities and connectives
{¬, ∨, ∧}. Let c range over quantiﬁer-free disjunctions of
(possibly non-ground) atoms. Let ∀φ mean the universal clo-
sure of φ. A formula of the form ∀(e ⊃ c) is called a ∀-clause.
A knowledge base (KB) ∆ is proper+ if it is a ﬁnite non-empty
set of ∀-clauses. The rank of ∆ is the maximum number of
variables mentioned in any ∀-clause in ∆.

This fragment is very expressive. Consider that standard
databases correspond to a maximally consistent and ﬁnite set
of literals: every relevant atom is known to be true and stored
in the database, or known to be false, inferred by (say) nega-
tion as failure. In contrast, such KBs correspond to a consis-
tent but inﬁnite set of ground clauses, not necessarily maxi-
mal.

Grounding: A ground theory is obtained from ∆ by sub-
stituting variables with names. Suppose θ denotes a substitu-
tion. For any set of names C ⊆ N, we write θ ∈ C to mean

1Our language L is essentially equivalent

together a unique-name assumption for
stants [Levesque, 1998, Deﬁnition 3].

to standard FOL
inﬁnitely many con-

In general,

the unique-name
out capturing uncertainty about
[Giacomo et al., 2011; Srivastava et al., 2014], for example.

assumption does not
the identity of objects;

rule
see

2Because equality is treated separately, atoms and clauses do not

include equalities.

substitutions are only allowed wrt the names in C. Formally,
we deﬁne:

• GND(∆) = {cθ | ∀(e ⊃ c) ∈ ∆, θ ∈ N and |= eθ};
• For z ≥ 0, GND(∆, z) = {cθ | ∀(e ⊃ c) ∈ ∆, |= eθ, θ ∈ Z},
where Z is the set of names mentioned in ∆ plus z (arbi-
trary) new ones;

• For C ⊆ N, GND(∆, C) = {cθ | ∀(e ⊃ c) ∈ ∆, |= eθ, θ ∈
Z} where Z is the set of names mentioned in ∆ plus the
names in C;

• GND−(∆) = GND(∆, z) where z is the rank of ∆.

Reasoning: Unfortunately, arbitrary reasoning with such
KBs is also undecidable [Lakemeyer and Levesque, 2002,
Theorem 7]. Various proposals have appeared to consider that
problem: in [Lakemeyer and Levesque, 2002], for example, a
sound but incomplete evaluation-based semantics is studied.
In [Belle, 2017], it is instead shown that when the query is
limited to ground formulas, we can reduce ﬁrst-order entail-
ment to propositional satisﬁability:

Theorem 2: [Belle, 2017] Suppose ∆ is a proper+ KB, and
α is a ground formula. Then, ∆ |= α iﬀ GND−(∆ ∧ ¬α) is
unsatisﬁable.

Here, the RHS of the iﬀ is a propositional formula, obtained
by a ﬁnite grounding, as deﬁned above.

Example 3: Suppose ∆ = {∀x(Grad(x) ∨ Prof(x)), ∀x(x ,
charles ⊃ Grad(x))} and the query is Grad(logan). Given that
the KB’s rank is 1, consider the grounding of the KB and the
negated query wrt {charles, logan, jean} (here jean is chosen
arbitrarily). It is indeed unsatisﬁable.

It is worth noting that the proof here (and in other propos-
als with L-like languages [Levesque and Lakemeyer, 2001;
Lakemeyer and Levesque, 2002; Liu and Levesque, 2005]) is
established by setting up a bijection between names to show
that all names other than those that appear in the ﬁnite
grounding in the RHS behave “identically,” and so for en-
tailment purposes, it suﬃces to consider a ﬁnite set consist-
ing of the constants already mentioned and a few extra ones.
That idea can be traced back to [Levesque, 1998] (reformu-
lated here for our purposes):

[Levesque, 1998] Suppose α = ∀xφ(x) is a
Theorem 4:
∀-clause. (Its rank is 1.) Let C be the names mentioned in
GND(α, 1). Then for every a ∈ N, there is a b ∈ C such that
|= φ(a) iﬀ |= φ(b).

The essence of Theorem 2 is to exploit this idea to show

(reformulated here for our purposes):

Lemma 5: [Belle, 2017] Suppose α is as above. If GND(α, 1)
is satisﬁable, then so is GND(α, z) for z ≥ 1.

Thus, we can extend a model that satisﬁes GND(α, 1) to
one that satisﬁes GND(α), and so α itself. These observations
will now lead to an appealing account for implicit learnability
with proper+ KBs.

3 Generalizing PAC-Semantics

Inductive generalization (as opposed to deduction) inherently
has to cope with mistakes. Thus, the kind of knowledge pro-
duced by learning algorithms cannot hope to be valid in the
traditional (Tarskian) sense, except in extreme cases, such as
assuming we see every data point in a noise-free manner. The
PAC semantics was introduced by Valiant [2000] to capture
the quality possessed by the output of PAC-learning algo-
rithms when formulated in a logic. In the classical proposi-
tional formulation, we suppose a propositional language with
(say) n propositions, yielding a model theoretic space {0, 1}n.
We suppose that we observe examples independently drawn
from a distribution D over {0, 1}n. Then, suppose further that
these examples enable a learning algorithm to ﬁnd a formula
φ. We cannot expect this formula to be valid in the traditional
sense, as PAC-learning does not guarantee that the rule holds
for every possible binding, only that φ so produced agrees
with probability 1 − ǫ wrt future examples drawn from the
same distribution. This motivates a weaker notion of validity:

[(1 − ǫ)-valid] Given a distribution D over
Deﬁnition 6 :
{0, 1}n, we say that a Boolean function F is (1 − ǫ)-valid if
Prx∈D[F(x) = 1] ≥ 1 − ǫ. If ǫ = 0, we say F is perfectly valid.

Thus far, the PAC semantics and its application to the for-
malization of robust logic-based learning has been limited
to the propositional setting [Valiant, 2000; Michael, 2009;
Juba, 2013], that is, where the learning vocabulary is ﬁnitely
many atoms, and the background knowledge is essentially re-
stricted to a propositional formula.3 Generalizing that to the
FOL case has to address, among other things, what (1 − ǫ)-
validity would like, how FOL formulas could be found by al-
gorithms, and ﬁnally, how entailments can be computed. That
is precisely our goal for this paper.

We start by proposing an extension of the PAC seman-
tics for the inﬁnitary structures constructed for L, namely
M. For this, we will need to consider distributions on M,
which are deﬁned as usual [Billingsley, 1995]: we take M
to be the sample space (of elementary events), deﬁne a σ-
algebra M to be a set of subsets of M, which represent a col-
lection of (not necessarily elementary) events, and a function
Pr : M → [0, 1], which is the probability measure.

We are now ready to deﬁne (1 − ǫ)-validity as needed in the

PAC semantics.

Deﬁnition 7: Given a distribution Pr over M, we say a for-
mula φ ∈ L is (1 − ǫ)-valid iﬀ Pr(~φ(cid:127)) ≥ 1 − ǫ. If ǫ = 0,
then we say that φ is perfectly valid. Here, ~φ(cid:127) for any closed
formula φ ∈ L denotes the set {M ∈ M | M |= φ} .

In practice, the most important use of the notion of valid-
ity is to check the entailment of a formula from a knowl-
edge base, and by extension, the reader may wonder how
that carries over from classical validity. As also observed in
[Juba, 2013] (for the propositional case), the union bound al-
lows classical reasoning to have a natural analogue in the PAC

3Valiant [2000] uses a fragment of FOL for which proposition-
alization is guaranteed to yield a small propositional formula, and
only considers such a reduction to the propositional case.

semantics, shown below. Note that, as already mentioned, our
assumption henceforth is that knowledge bases are proper+,
and queries are ground formulas, both in the context of rea-
soning as well as learning.

Proposition 8: Let ψ1, . . . , ψk be ∀-clauses such that each ψi
is (1 − ǫi)-valid under a common distribution D for some ǫi ∈
[0, 1]. Suppose {ψ1, . . . , ψk} |= ϕ, for some ground formula ϕ.
Then ϕ is (1 − ǫ′)-valid under D for ǫ′ = Pi ǫi.

4 Partial Observability

The learning problem of interest here is to obtain knowledge
about the distribution D, which, of course, is not revealed di-
rectly, but in the form of a set of examples. The examples in
question are models independently drawn from D, and we are
then interested in knowing whether a query α is (1 − ǫ)-valid.
Intuitively, background knowledge ∆ may be provided addi-
tionally and so the examples correspond to additional knowl-
edge that the agent learns. This additional knowledge is never
materialized in the form of L-formulas, but is left implicit, as
postulated ﬁrst in [Juba, 2013].

When it comes to the examples themselves, however, we
certainly cannot expect the examples to reveal the full nature
of the world, and indeed, partial descriptions are common-
place in almost all applications [Michael, 2010]. In the case
of L, moreover, providing a full description may even be im-
possible in ﬁnite time. All of this motivates the following:

Deﬁnition 9: A partial model N maps ATOMS to {1, 0, ∗} .
We say N is consistent with a L-model M iﬀ for all p ∈
ATOMS, if N[p] , ∗ then N[p] = M[p]. Let N be the set of
all partial models.

Essentially, our knowledge of D will be obtained from a set

of partial models that are the examples.

Deﬁnition 10: A mask is a function θ that maps L-models to
partial models, with the property that for any M ∈ M, θ(M)
is consistent with M. A masking process Θ is a mask-valued
random variable (i.e., a random function). We denote the dis-
tribution over partial models obtained by applying a masking
process Θ to a distribution D over L-models by Θ(D).

The deﬁnition of masking processes allows the hiding of
entries to depend on the underlying example from D. More-
over, as discussed in [Juba, 2013] (for the propositional case),
reasoning in PAC-Semantics from complete examples is triv-
ial, whereas the hiding of all entries by a masking process
means that the problem reduces to classical entailment. So,
we expect examples to be of a sort that is in between these
extremes. In particular, for the sake of tractable learning, we
must consider formulas that can be evaluated eﬃciently from
the partial models with high probability. This leads to a no-
tion of witnessing.

Deﬁnition 11: We deﬁne a propositional formula φ ∈ L to be
witnessed to evaluate to true or false in a partial assignment
N by induction as follows:

• an atom Q(~c) is witnessed to be true/false iﬀ it is

true/false respectively in N;

• ¬φ is witnessed true/false iﬀ φ is witnessed false/true

respectively;

• φ ∨ ψ is witnessed true iﬀ either φ or ψ is, and it is wit-

nessed false iﬀ both φ and ψ are witnessed false;

• φ ∧ ψ is witnessed true iﬀ both φ and ψ are witnessed
true, and it is witnessed false iﬀ either φ or ψ is witnessed
false;

• φ ⊃ ψ is witnessed true iﬀ either φ is witnessed false or
ψ is witnessed true, and it is witnessed false iﬀ both φ is
witnessed true and ψ is witnessed false.

We deﬁne a ∀-clause ∀~xφ(~x) to be witnessed true in a partial
model N for the set of names C if for every binding of ~x to
names ~c ∈ C, the resulting ground clause φ(~c) is witnessed
true in N.

It is the witnessing of ∀-clauses that, in essence, enables
the implicit learning of quantiﬁed generalizations. Let us
Intuitively, from examples φ(~c1), . . . ,
see how that works.
one would like to generalize to ∀~xφ(~x), the latter being a
statement about inﬁnitely many objects. But what criteria
would justify this generalization, outside of (say) witness-
ing inﬁnitely many instances? Our result shows that, sur-
prisingly, it suﬃces to get ﬁnitely many examples, so as to
witness φ(~c1), . . . , φ(~ck) and yield universally quantiﬁed sen-
tences with high probability. This is possible because, via
Theorem 2, all the names not mentioned in the KB and the
query behave “identically.” Thus, provided we witness the
grounding of φ for a suﬃcient but ﬁnite set of constants, we
can treat the implicit KB as including ∀-clauses, as it yields
the same judgments on our queries.

Putting it all together, formally, in any given learning
epoch, let S be the class of queries we are interested in ask-
ing: that is, S is any ﬁnite set of ground formulas. Let C then
be all the names mentioned in S , the KB, and z extra new
ones chosen arbitrarily, where z is at least the rank of the KB.
If z = KB’s rank, then the rank of the implicit KB matches
that of the explicit KB; otherwise, it would be higher. So the
deﬁnition says that the witnessing of ∀~xφ(~x) happens when
φ(~c) is witnessed for all ~c ∈ C. We think this notion is par-
ticularly powerful, as it neither makes references to bindings
from the full set of names N (which is inﬁnite), nor to not
observing negative instances. Note also that witnessing does
not require observing all atoms: a clause is witnessed to eval-
uate to true if some literal appearing in it is true in the partial
model. Thus, the ∀-clause witnessed may involve predicates
not explicitly appearing in the partial model.

Witnessed formulas correspond to the implicit KB. In order
to capture the inferences that the implicit KB permits, we will
use partial models to simplify complex formulas in the KB or
query. To that end, we deﬁne:

Deﬁnition 12: Given a partial model N and a propositional
formula φ, the restriction of φ under N, denoted φ|N, is re-
cursively deﬁned: if φ is an atom witnessed in N, then φ|N
is the value that φ is witnessed to evaluate to under N; if
φ is an atom not set by N, then φ|N = φ; if φ = ¬ψ, then
φ|N = ¬(ψ|N); and if φ = α ∧ β, then φ|N = (α|N) ∧ (β|N).
(And analogously for Boolean connectives ∨ and ⊃ .) For a

partial model N and set of propositional formulas F, we let
F|N denote the set {φ|N : φ ∈ F}.

Notice that here we do not deﬁne restrictions for quantiﬁed
formulas, such as those appearning in the KB: while that is
possible it is not needed, as we will be leveraging Theorem 2
for reasoning.

5 Implicit Learnability

The central motivation here is learning to reason in FOL, and
as argued earlier, implicit learning circumvents the need for
an explicit hypothesis, especially since hypothesis ﬁtting is
intractable, unless one severly restricts the hypothesis space.
So, learning is integrated tightly into the application using the
knowledge extracted from data. Our deﬁnitions in the previ-
ous sections establish the grounds for which a ﬁrst-order im-
plict KB can be learned from ﬁnitely many ﬁnite-size exam-
ples, but also the grounds for deciding propositional entail-
ments of ∀-clauses speciﬁed explicitly – i.e., the background
(Of course, reasoning is not yet tractable, but
knowledge.
simply decidable; we return to this point later). Overall, the
learning regime is presented in Algorithm 1, and its correct-
ness is justiﬁed in Theorem 13.

Algorithm 1 Reasoning with implicit learning

Input: Partial models N(1), N(2), . . . , N(m), explicit KB ∆,
query α (a ground formula), number of names k at least
equal to ∆’s rank
Output:
rem 13)
Initialize v ← 0
for i = 1, . . . , m do

ˆp ∈ [0, 1] estimating α is ˆp-valid (See Theo-

for all k-tuples of names (c1, . . . , ck) from N(i) not ap-
pearing in ∆ ∧ ¬α do

if GND(∆ ∧ ¬α, {c1, . . . , ck})|N(i) is unsatisﬁable then

Increment v and skip to the next i.

end if
end for

end for
Return v/m

Theorem 13: Let δ, γ ∈ (0, 1) and k ∈ N be given. Suppose
we have m partial models drawn i.i.d. from a common distri-
2γ2 ln 2
bution D masked by a masking process Θ, where m ≥ 1
δ .
(Here, ln denotes the natural logarithm.) With probability at
least 1 − δ, Algorithm 1 returns a value ˆp s.t.

I if ∆ ⊃ α is at most p-valid, ˆp ≤ p + γ
II if there is a KB I such that

1. ∆ ∧ I |= α,
2. the rank of ∆ ∧ I is at most k, and
3. with probability at least p over partial models N ∈
Θ(D), there exists names c1, . . . , ck not appearing
in ∆ or α, such that every formula in I is witnessed
true in N for c1, . . . , ck together with the names ap-
pearing in ∆ and α

then ˆp ≥ p − γ.

Part I: ˆp ≤ p + γ if ∆ ⊃ α is at most p-valid. We
Proof:
ﬁrst note that when GND(∆ ∧ ¬α, C)|N(i)
|= ⊥ for any set of
names C, since N(i) is consistent with the actual model M(i)
that produced it, GND(∆ ∧ ¬α, C)|M(i)
|= ⊥ as well. Thus,
in this case, GND(∆ ∧ ¬α, C) is falsiﬁed by M(i). Since |C|
is at least the rank of ∆, it is easy to see that GND(∆ ∧ ¬α),
which is logically equivalent to ∆ ∧ ¬α, is falsiﬁable at M(i).
So, it must be that the negation of that theory (i.e., ∆ ⊃ α) is
satisﬁed at M(i).

2γ2 ln 2

Now, ∆ ⊃ α is by deﬁnition p-valid with respect to this
distribution on M(i) if the probability that ∆ ⊃ α is satisﬁed
by each M(i) is p. Moreover, it follows immediately from
Hoeﬀding’s inequality that for m ≥ 1
δ , the probability
that the fraction of times ∆ ⊃ α is satisﬁed by M(i) (out of m)
exceeds p by more than γ is at most δ/2. Thus, ˆp, which is at
most the fraction of times ∆ ⊃ α is actually satisﬁed by M(i),
likewise is at most p + γ with probability at least 1 − δ/2.
Part II: rate of witnessing an implicit KB lower bounds
ˆp. Note that by the grounding trick (Theorem 2), ∆ ∧ I |= α
implies that for any set of names c1, . . . , ck not appearing in
∆ or α, GND(∆ ∧ I ∧ α, {c1, . . . , ck}) |= ⊥. Suppose that
I is witnessed true for c1, . . . , ck together with the names
in ∆ and α in N(i). We note that in the restricted formula
GND(∆ ∧ I ∧ ¬α, {c1, . . . , ck})|N(i), the groundings of for-
mulas in I all simplify to 1 (true), and so GND(∆ ∧ I ∧
¬α, {c1, . . . , ck})|N(i) = GND(∆ ∧ ¬α, {c1, . . . , ck})|N(i). Thus,
GND(∆ ∧ ¬α, {c1, . . . , ck})|N(i)
|= ⊥, so v is incremented on
this iteration. Thus, indeed, ˆp = v/m is at least the fraction
of times out of m that I is witnessed true for some set of k
names. It again follows from Hoeﬀding’s inequality that for
m ≥ 1

δ , this is at least p − γ with probability 1 − δ/2.

2γ2 ln 2

By a union bound, the two parts hold simultaneously with

probability at least 1 − δ, as needed.

In essence, the no-overestimation condition is a soundness
guarantee and the no-underestimation condition is a limited
completeness guarantee: in other words, if the query logically
follows from the explicit KB and examples then the algorithm
returns success with an appropriate ˆp, and vice versa.

6 Tractable Reasoning

Algorithm 1 reduces reasoning with implicit learning to de-
ciding entailment. In order to obtain a tractable algorithm, we
generally need to restrict the reasoning task somehow. One
approach, taken in the previous work on propositional im-
plicit learning [Juba, 2013], is to “promise” that the query is
provable in some low-complexity fragment; for example, it is
provable by a small treelike resolution proof (where “small”
refers to the number of lines of the proof). Equivalently, we
give up on completeness, and only seek completeness with
respect to conclusions provable in low complexity in a given
fragment. In general, then, one obtains a running time guar-
antee that is parameterized by the size of the proof of the
query. We can take a similar approach here, by using an
algorithm for deciding entailment that is eﬃcient when pa-
rameterized in such terms. In general, what is needed is a

fragment for which we can decide the existence of proofs
eﬃciently, and that is “restriction-closed,” meaning that for
any partial model N, if we consider the restriction of each
line of the proof, we obtain a proof in the same fragment.
Most fragments we might consider, including speciﬁcally
treelike or bounded-width resolution, are restriction-closed.
(See [Juba, 2012] for details.)

We will motivate an entirely new strategy here, which
oﬀers a semantic perspective to the proof-theoretic view
in [Juba, 2013]. One classically sound model-theoretic
approach to constraining propositional reasoning is to limit
the power of the reasoner, as represented, for example,
by the work on tautological entailment [Levesque, 1984].
More recently, [Liu et al., 2004] suggest a simple evaluation
scheme for proper+ KBs that gradually increases the power
of the reasoner: level 0 is standard database lookup together
with unit propagation, level 1 allows for one case split in
a clause, level 2 allows two case splits, and so on. The
formal intuition is as follows: suppose s is a set of ground
clauses and φ is a ground query, and let us say its a clause
for simplicity. Let U(s) denote the the closure of s under
unit propagation, deﬁned as the least set s′ satisfying: (a)
s ⊆ s′ and (b) if literal l ∈ s′ and (¬l ∨ c) ∈ s′ then
c ∈ s′. Then let V(s) deﬁne all possible weakenings:
(cid:8)c | c is a ground clause and there is a c′ ∈ U(s) s.t. c′ ⊆ c(cid:9) .
Then we deﬁne s |=z φ (read: “entails at levels z”) iﬀ one of
the following holds:

• subsume: z = 0, and φ ∈ V(s);
• split: z > 0 and there is some clause c ∈ s such that for

all literals l ∈ c, s ∪ {l} |=(z−1) φ.

This scheme is sound as well as tractable:

Theorem 14: [Liu et al., 2004] Suppose ∆, φ are proposi-
tional formulas and z ∈ N. Then, determining if ∆ |=z φ can
be done in time O((|φ| × |∆|)z+1). Moreover, if ∆ |=z φ then
∆ |= φ.

We will now see how to leverage these results. First, how-
ever, we need the equivalent to restriction-closed, as dis-
cussed above.

Proposition 15: Suppose φ, ∆, z are as above. Then if ∆ |=z
φ, and N is any partial model then (∆|N) |=z (φ|N).

Basically, if φ is entailed at level z from ∆, then any restric-
tion of φ under N must also be entailed by ∆ restricted to N,
at least at level z if not lower. Notice that restricting a ground
formula is equivalent to simply conjoining the literals true at
N with both φ and ∆, from which the proof follows. Now,
recall from Theorem 2, given a proper+ KB ∆ and ground
query φ, we have ∆ |= φ iﬀ GND−(∆ ∧ ¬α) is unsatisﬁable.
Here, since α is already ground, we really only need to make
sure that ∆ is ground wrt all the names in ∆ ∧ ¬α and k new
ones, k being the rank of ∆. So let GNDα(∆) denote precisely
such a grounding of ∆. It then follows that GNDα(∆) |= α iﬀ
GND−(∆ ∧ ¬α) is unsatisﬁable iﬀ ∆ |= α. So let Algorithm 1′
be exactly like Algorithm 1 except that it accepts a parameter
z (for limited reasoning) and replaces the following check:

GND(∆ ∧ ¬α, {c1, . . . , ck})|N(i)
with

is

unsatisﬁable

GND(∆, {c1, . . . , ck, d1, . . . , dm})|N(i)
(α|N(i)), where
{d1, . . . , dm} is the set of names appearing in α but not
in ∆.

|=z

Theorem 16:
Let δ, γ, k, m be as in Theorem 13, and let
z ∈ N. Then with a probability at least 1 − δ, Algorithm 1′
returns a value ˆp such that: (I) and (II) is as in Theorem 13
except for (II.1) which states that ∆ ∧ I |=z α. The algorithm
runs in time O(1/γ2 × (|φ| × |∆|)z+1 × log(1/δ)).

Discussion.

Interestingly, in [Liu and Levesque, 2005],
it is shown that reasoning is also tractable in the ﬁrst-order
case if the knowledge base and the query both use a bounded
number of variables. This would then mean that we would no
longer be limited to ground queries and can handle queries
with quantiﬁers. This direction is left for future research.
Nonetheless, we note that deciding quantiﬁed (as opposed
to ground) queries appears to demand more from learning.
In general, in an inﬁnite domain, we cannot hope to observe
in a ﬁnite partial model that universally quantiﬁed formulas
are ever true. Thus, we anticipate that extensions that han-
dle queries with quantiﬁers will need a substantially diﬀer-
ent framework, presumably with stronger assumptions. One
possible framework takes a more credulous approach to the
learning problem (in contrast to our skeptical approach based
on witnessing truth): we suppose that when a formula is fre-
quently false on the distribution of examples, we also fre-
quently obtain a partial model that witnesses the formula
false—e.g., a partial model in which a binding of a candidate
∀-clause falsiﬁes it. This is undoubtedly an assumption about
the benevolent nature of the environment, captured as the
notion of concealment in [Michael, 2010], but it does make
learning conceptually simpler. In this framework, one per-
mits all conclusions that are not explicitly falsiﬁed. Whether
such an idea can be used for inductive generalization of FOL
formulas over arbitrary distributions remains to be seen.

7 Conclusions

In this work, we presented new results on the problem of
answering queries about formulas of ﬁrst-order logic (FOL)
based on background knowledge partially represented explic-
itly as other formulas, and partially represented as exam-
ples independently drawn from a ﬁxed probability distribu-
tion. By appealing to the paradigm of implicit learnability, we
sidestepped many major negative results, leading to a learning
regime that works with a general and expressive FOL frag-
ment. No restrictions were posed on clause length, predicate
arity, and other similar technical devices seen in PAC results.
Overall, we hope the simplicity of the framework is appeal-
ing to the readers and hope our results will renew interest
in learnability for expressive languages with quantiﬁcational
power.

Acknowledgements

B. Juba was supported by NSF Award CCF-1718380. This
work was partially performed while B. Juba was visiting the

[Liu and Levesque, 2005] Yongmei Liu and Hector

J.
Levesque. Tractable reasoning in ﬁrst-order knowledge
bases with disjunctive information. In Proc. AAAI, pages
639–644, 2005.

[Liu et al., 2004] Yongmei Liu, Gerhard Lakemeyer, and
Hector J. Levesque. A logic of limited belief for reason-
ing with disjunctive information. In KR, pages 587–597,
2004.

[McCarthy and Hayes, 1969] J. McCarthy and P. J. Hayes.
Some philosophical problems from the standpoint of artiﬁ-
cial intelligence. In Machine Intelligence, pages 463–502,
1969.

[Michael, 2009] Loizos Michael. Reading between the lines.

In IJCAI, 2009.

[Michael, 2010] Loizos Michael. Partial observability and
Artiﬁcial Intelligence, 174(11):639–669,

learnability.
2010.

[Moore, 1982] Robert C. Moore. The role of logic in knowl-
In
edge representation and commonsense reasoning.
AAAI, pages 428–433, 1982.
[Muggleton and De Raedt, 1994] S.

and
Inductive logic programming: Theory
The Journal of Logic Programming,

Muggleton

L. De Raedt.
and methods.
19:629–679, 1994.

[Richardson and Domingos, 2006] M.

and
P. Domingos. Markov logic networks. Machine learning,
62(1):107–136, 2006.

Richardson

[Srivastava et al., 2014] S. Srivastava, S. J. Russell, P. Ruan,
and X. Cheng. First-order open-universe pomdps. In UAI,
pages 742–751, 2014.

[Valiant, 2000] Leslie G Valiant. Robust logics. Artiﬁcial

Intelligence, 117(2):231–253, 2000.

Simons Institute for the Theory of Computing.

References

[Belle, 2017] V. Belle.

Open-universe weighted model

counting. In AAAI, 2017.

[Billingsley, 1995] P. Billingsley. Probability and Measure.

Wiley-Interscience, 3 edition, April 1995.

[Cohen and Hirsh, 1994] William W Cohen and Haym
Hirsh. The learnability of description logics with equality
constraints. Machine Learning, 17(2-3):169–199, 1994.
[Cohen and Page, 1995] William W Cohen and C David
Page. Polynomial learnability and inductive logic pro-
gramming: Methods and results. New Generation Com-
puting, 13(3-4):369–409, 1995.

[Daniely and Shalev-Shwartz, 2016] Amit Daniely and Shai
Complexity theoretic limitations on

Shalev-Shwartz.
learning dnf’s. In COLT, pages 815–830, 2016.

[De Raedt and Dˇzeroski, 1994] L. De Raedt and S. Dˇzeroski.
First-order jk-clausal theories are PAC-learnable. Artiﬁ-
cial Intelligence, 70(1):375–392, 1994.

[Giacomo et al., 2011] G. De Giacomo, Y. Lesp´erance, and
H. J. Levesque. Eﬃcient reasoning in proper knowledge
bases with unknown individuals. In IJCAI, pages 827–832,
2011.

[Juba, 2012] Brendan Juba. Learning implicitly in reasoning
in pac-semantics. arXiv preprint arXiv:1209.0056, 2012.

[Juba, 2013] Brendan Juba.

Implicit learning of common

sense for reasoning. In IJCAI, pages 939–946, 2013.
[Kearns et al., 1994] Michael J Kearns, Robert E Schapire,
and Linda M Sellie. Toward eﬃcient agnostic learning.
Machine Learning, 17(2-3):115–141, 1994.

[Kersting et al., 2011] K. Kersting, S. Natarajan,

and
D. Poole. Statistical relational AI: Logic, probability and
computation. 2011.

[Khardon and Roth, 1999] Roni Khardon and Dan Roth.
Learning to reason with a restricted view. Machine Learn-
ing, 35(2):95–116, 1999.

[Lakemeyer and Levesque, 2002] G. Lakemeyer and H. J.
Levesque. Evaluation-based reasoning with disjunctive in-
In Proc. KR,
formation in ﬁrst-order knowledge bases.
pages 73–81, 2002.

[Levesque and Lakemeyer, 2001] H.

and
G. Lakemeyer. The logic of knowledge bases. The MIT
Press, 2001.

Levesque

J.

[Levesque, 1984] H.J. Levesque. A logic of implicit and ex-
plicit belief. In Proceedings of the Fourth National Confer-
ence on Artiﬁcial Intelligence, pages 198–202. American
Association for Artiﬁcial Intelligence, 1984.

[Levesque, 1998] H. J. Levesque. A completeness result for
reasoning with incomplete ﬁrst-order knowledge bases. In
Proc. KR, pages 14–23, 1998.

