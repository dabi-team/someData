Learning Logic Programs By Discovering Where Not to Search

Andrew Cropper and Céline Hocquette

University of Oxford
andrew.cropper@cs.ox.ac.uk, celine.hocquette@cs.ox.ac.uk

2
2
0
2

b
e
F
0
2

]

G
L
.
s
c
[

1
v
6
0
8
9
0
.
2
0
2
2
:
v
i
X
r
a

Abstract

The goal of inductive logic programming (ILP) is to search
for a hypothesis that generalises training examples and back-
ground knowledge (BK). To improve performance, we intro-
duce an approach that, before searching for a hypothesis, ﬁrst
discovers where not to search. We use given BK to discover
constraints on hypotheses, such as that a number cannot be
both even and odd. We use the constraints to bootstrap a
constraint-driven ILP system. Our experiments on multiple
domains (including program synthesis and inductive general
game playing) show that our approach can substantially re-
duce learning times.

1 Introduction
The goal of inductive logic programming (ILP) (Muggleton
1991) is to search for a hypothesis (a set of rules) that gen-
eralises training examples and background knowledge (BK),
where hypotheses, examples, and BK are all logic programs.
For instance, consider learning list transformation rules
with an arbitrary head literal h. Assume we can build rules
using the unary relations odd and even and the binary rela-
tions head and tail. Then the rule space (the set of all possi-
ble rules) contains rules such as:

r1 = h ← tail(A,A)
r2 = h ← tail(A,B), tail(B,A)
r3 = h ← tail(A,B), tail(B,C), tail(A,C)
r4 = h ← tail(A,A), head(A,B), odd(B)
r5 = h ← head(A,B), odd(B), even(B)

The hypothesis space (the set of all hypotheses) is the pow-
erset of the rule space, so can be enormous.

To improve performance, users can impose an induc-
tive bias (Mitchell 1997) to restrict the hypothesis space1.
For instance, if told that tail is irreﬂexive, some systems
(Law, Russo, and Broda 2014) will remove rules with the lit-
eral tail(A,A) from the rule space, such as r1 and r4. As re-
moving a rule removes all hypotheses that contain it, strong
biases can greatly reduce the hypothesis space.

The main limitation with existing approaches is that they
need a human to provide a strong bias. Furthermore, ex-
isting bias approaches (Muggleton 1995) struggle to cap-

1All machine learning approaches need an inductive bias, i.e.

bias-free learning is futile (Mitchell 1997).

ture general properties, such as antitransitivity and func-
tional dependencies (Mannila and Räihä 1994). Therefore,
developing bias discovery approaches is a grand challenge
(Cropper et al. 2021).

In this paper, we introduce a bias discovery approach. The
idea is to use given BK to discover how to restrict the hy-
pothesis space before searching for a solution2. For instance,
consider the previous list transformation example. Assume
we have BK with only the facts:

head(ijcai,i)
head(ecai,e)
head(cai,c)
tail(ai,i)

tail(ijcai,jcai)
tail(ecai,cai)
tail(jcai,cai)
tail(cai,ai)

even(2)
even(4)
odd(1)
odd(3)

Given this BK, we can deduce that some rules will be un-
satisﬁable regardless of the concept we want to learn, i.e.
regardless of the training examples. For instance, as there is
no fact of the form tail(A,A), we can deduce that tail is ir-
reﬂexive, and thus remove r1 and r4 from the rule space, as
their bodies are unsatisﬁable3. Similarly, we can deduce that
tail is asymmetric and antitransitive and that odd and even
are mutually exclusive, and thus remove rules r2, r3, and r5.
With this approach, we can substantially reduce the hypothe-
sis space before searching for a solution, i.e. we can discover
where not to search.

Our bias discovery approach works in two stages. First,
we use BK to discover functional dependencies and re-
lational properties, such as irreﬂexivity, asymmetry, and
antitransitivity. To do so, we use a bottom-up approach
(Savnik and Flach 1993) implemented in answer set pro-
gramming (ASP). Second, we use the properties to build
constraints to restrict the hypothesis space. For instance, if
we discover that even and odd are mutually exclusive, we
build constraints to prohibit rules with both the body liter-
als odd(A) and even(A). We use the constraints to bootstrap
a constraint-driven ILP system (Cropper and Morel 2021).
The constraints remove non-optimal hypotheses from the hy-
pothesis space so that the system never considers them when

2A solution is a hypothesis that generalises the examples. An
optimal solution is the smallest solution in terms of its size in liter-
als.

3These properties may only hold with the given BK. However,
as the ILP problem is deﬁned in terms of the given BK, our ap-
proach is optimally sound (Proposition 1).

 
 
 
 
 
 
searching for a solution.

Contributions. We claim that our approach can reduce the
hypothesis space and learning times. To support this claim,
we make four main contributions:

• We introduce the constraint discovery problem and de-

ﬁne optimally sound constraints.

• We describe a bias discovery approach that discovers
functional dependencies and relational properties, such
as asymmetry and antitransitivity. We prove that our ap-
proach is optimally sound.

• We implement our approach in ASP and use it to boot-

strap a constraint-driven ILP system.

• We experimentally show on ﬁve domains that our ap-
proach can (i) substantially reduce learning times, and
(ii) scale to BK with millions of facts.

2 Related Work

This paper connects many areas of AI.

Program synthesis. The goal of program synthesis
(Shapiro 1983) is to automatically generate computer pro-
grams from examples. This topic, which Gulwani et al.
(2017) consider the holy grail of AI, interests a broad com-
munity (Evans and Grefenstette 2018; Ellis et al. 2018). We
focus on ILP, which induces human-readable logic pro-
grams, often from small numbers of training examples
(Cropper et al. 2021).

ILP. Many systems allow a human to manually spec-
ify conditions for when a rule cannot be in a hypothesis
(Muggleton 1995; Srinivasan 2001; Law, Russo, and Broda
2014). Most systems only reason about the conditions af-
ter constructing a hypothesis, such as Aleph’s rule prun-
ing mechanism. By contrast, we automatically discover con-
straints and remove rules that violate them from the hypoth-
esis space before searching for a hypothesis.

Constraints. Many systems use constraints

to re-
strict the hypothesis space (Corapi, Russo, and Lupu 2011;
Inoue, Doncescu, and Nabeshima 2013; Ahlgren and Yuen
2013; Kaminski, Eiter, and Inoue 2019; Cropper and Morel
2021). For instance, the Apperception (Evans et al. 2021) en-
gine has several built-in constraints, such as a unity condi-
tion, which requires that objects are connected via chains
of binary relations. By contrast, we automatically discover
constraints before searching for a hypothesis.

Bias approaches. Many systems use mode declarations to
build bottom clauses (Muggleton 1995) to bound the hypoth-
esis space. Bottom clauses are example speciﬁc, i.e. each
example has a bottom clause. By contrast, our bias discov-
ery approach only uses the BK, not the training examples.
We can, therefore, reuse the discovered bias across examples
and tasks.

Bias discovery. McCreath and Sharma (1995) automati-
cally deduce mode declarations from the BK, such as types
and whether arguments should be ground. Our approach
is different because, as we use constraints, we can express
properties modes cannot, such as antitransitivity, functional
dependencies, and mutual exclusivity.

Constraint induction. Inducing constraints is popular in
AI (De Raedt, Passerini, and Teso 2018). In ILP, inducing
constraints has been widely studied, notably by clausal dis-
covery approaches (De Raedt and Dehaspe 1997). These ap-
proaches induce constraints to include in a hypothesis to
eliminate models. By contrast, we do not include constraints
in hypotheses. Instead, we discover constraints to prune the
hypothesis space.

Preprocessing. Our discovery approach is a form of pre-
processing, which has been widely studied in AI, notably
to reduce the size of a SAT instance (Eén and Biere 2005).
Other preprocessing approaches in ILP focus on reducing
the size of BK (Dumanˇci´c et al. 2019) or predicate invention
(Hocquette and Muggleton 2020),. By contrast, we discover
constraints in the BK to prune the hypothesis space.

approach is

Other work. Our

related to auto-
mated constraint generation in constraint programming
(Charnley, Colton, and Miguel 2006), ﬁnding unsatisﬁable
cores in SAT (Lynce and Silva 2004), and condensed repre-
sentations in frequent pattern mining (De Raedt and Ramon
2004).

3 Problem Setting
We formulate our approach in the ILP learning from entail-
ment setting (De Raedt 2008). We assume familiarity with
logic programming (Lloyd 2012). The only clariﬁcation is
that by constraint we mean a Horn clause without a positive
literal.

3.1 ILP Problem
We deﬁne an ILP input. We restrict hypotheses and BK to
deﬁnite programs.

Deﬁnition 1 (ILP input). An ILP input
is a tuple
(E+, E−, B, H) where E+ and E− are sets of facts denot-
ing positive and negative examples respectively, B is BK,
and H is a hypothesis space, i.e a set of possible hypotheses.

We deﬁne an ILP solution:

Deﬁnition 2 (ILP solution). Given an ILP input
(E+, E−, B, H), a hypothesis H ∈ H is a solution when
it is complete (∀e ∈ E+, B ∪ H |= e) and consistent
(∀e ∈ E−, B ∪ H 6|= e).
Let cost : H 7→ R be an arbitrary function that measures the
cost of a hypothesis. We deﬁne an optimal solution:

Deﬁnition 3 (Optimal solution). Given an ILP input
(E+, E−, B, H), a hypothesis H ∈ H is optimal when (i)
H is a solution, and (ii) ∀H ′ ∈ H, where H ′ is a solution,
cost(H) ≤ cost(H ′).
In this paper, our cost function is the number of literals in a
hypothesis.

3.2 Constraint Discovery Problem
We denote the set of possible constraints as C. A hypothesis
H ∈ H is consistent with C ⊆ C if it does not violate any
constraint in C. We denote the subset of H consistent with
C as HC . We deﬁne the constraint discovery input:

Deﬁnition 4 (Constraint discovery input). A constraint
is a tuple (E+, E−, B, H, C) where
discovery input
(E+, E−, B, H) is an ILP input and C is a set of possible
constraints.
We deﬁne the constraint discovery problem:
Deﬁnition 5 (Constraint discovery problem). Given a con-
straint discovery input (E+, E−, B, H, C), the constraint
discovery problem is to ﬁnd C ⊆ C such that |HC | < |H|.
One might assume we want to discover sound constraints:
Deﬁnition
=
(E+, E−, B, H, C) be a constraint discovery input. Then
C ⊆ C is sound if and only if ∀H ∈ H if H is a solution for
I then H ∈ HC .
However, we often want to eliminate non-optimal solutions
from the hypothesis space. For instance, consider learning to
recognise lists with a single element and the hypothesis:

constraints). Let

(Sound

6

I

counter-example for each property. For instance, for a binary
relation p to be irreﬂexive there cannot be a counter-example
p(a,a). To implement this idea, we encapsulate all the rela-
tions in the BK, restricted to a user-speciﬁed set that may
appear in a hypothesis. For each relation p with arity a we
add this rule to the BK:

holds(p, (X1, X2, . . . , Xa)) ← p(X1, X2, . . . , Xa)

We then deduce properties with ASP programs. For instance,
we deduce asymmetry for binary relations by ﬁnding an an-
swer set of the program:

asymmetric(P) ← holds(P,(_,_)), not non_asymmetric(P)
non_asymmetric(P) ← holds(P,(A,B)), holds(P,(B,A))

Likewise, we deduce that two relations P and Q are mutu-
ally exclusive with the program:

f(A) ← length(A,B), one(B), two(B)
f(A) ← length(A,B), one(B)

exclusive(P,Q) ← holds(P,_), holds(Q,_), not both_hold(P,Q)
both_hold(P,Q) ← holds(P,Args), holds(Q,Args)

This hypothesis is a solution but is not optimal. We would
prefer to learn an optimal solution, such as:
f(A) ← length(A,B), one(B)

We, therefore, deﬁne optimally sound constraints:
Deﬁnition 7 (Optimally sound constraints). Let I =
(E+, E−, B, H, C) be a constraint discovery input. Then
C ⊆ C is optimally sound if and only if ∀H ∈ H if H is
an optimal solution for I then H ∈ HC .
In the next section we present an approach that discovers
optimally sound constraints using the BK.

4 BK Constraint Discovery
Our approach works in two stages. First, we use BK to iden-
tify relational properties and functional dependencies. Sec-
ond, we use the properties to build constraints on hypotheses
to bootstrap an ILP system.

4.1 Properties
Table 6 shows the properties we consider. We generalise
the properties, except antitransitive and antitriangular, to
higher arities. For instance, if a ternary relation p is in
the BK, we consider a ternary irreﬂexive constraint ←
p(A,A,A). We also identify higher-arity functional dependen-
cies (Mannila and Räihä 1994). For instance, for the rela-
tion append(Head,Tail,List), we can determine that the third
argument is functionally dependent on the ﬁrst two. Other
properties we consider and generalisations to higher arities
are in the appendix.

Property Identiﬁcation Rather than requiring a user to
specify which properties in Table 6 hold for BK rela-
tions, we automatically discover this information. There are
many efﬁcient algorithms for discovering data dependencies
(Papenbrock et al. 2015). However, as far as we are aware,
no single algorithm can capture all the properties in Table 6.
We, therefore, use a bottom-up approach (Savnik and Flach
1993) implemented in ASP. The idea is to try to ﬁnd a

We deduce that a relation is functional with the program:

functional(P) ← holds(P,_), not non_functional(P)
non_functional(P) ← holds(P,(A,B)), holds(P,(A,C)), B!=C

All the ASP programs are in the appendix.

4.2 Constraints
The output of stage one is a set of properties that hold for
background relations. If a property holds for a relation, we
generate the corresponding constraint to prohibit hypotheses
that violate the constraint. These constraints can potentially
be used by any ILP system. We implement our approach
to work with POPPER (Cropper and Morel 2021). POPPER
is a natural choice because it frames the ILP problem as a
constraint satisfaction problem. Moreover, it learns recur-
sive programs, supports predicate invention, and is open-
source4. We describe POPPER and our modiﬁcation named
DISCOPOPPER.

POPPER POPPER takes as input BK, training examples,
and a maximum hypothesis size. POPPER starts with an ASP
program P which can be viewed as a generator program be-
cause each model (answer set) of P represents a hypothesis
(a deﬁnite program). POPPER uses a meta-language formed
of head (h_lit/3) and body (b_lit/3) literals to represent hy-
potheses. The ﬁrst argument of each literal is the rule id, the
second is the predicate symbol, and the third is the literal
variables, where 0 represents A, 1 represents B, etc. For in-
stance, POPPER represents the rule last(A,B) ← tail(A,C),
head(C,B) as the set {h_lit(0,last,(0,1)), b_lit(0,tail,(0,2)),
b_lit(0,head,(2,1))}. A hypothesis constraint in POPPER is a
constraint written in its meta-language. For instance, the con-
straint ← h_lit(R,last,(0,1)), b_lit(R,last,(1,0)) prunes rules
that contain the head literal last(A,B) and the body literal
last(B,A).

4ILASP (Law, Russo, and Broda 2014) is an alternative system

but is closed-source and thus difﬁcult to adapt.

Name

Property

Constraint

Example

Irreﬂexive
Antitransitive
Antitriangular
Injective
Functional
Asymmetric
Exclusive

← p(A,A)

¬p(A,A)
p(A,B), p(B,C) → ¬p(A,C) ← p(A,B), p(B,C), p(A,C) ← succ(A,B), succ(B,C), succ(A,C)
p(A,B), p(B,C) → ¬p(C,A) ← p(A,B), p(B,C), p(C,A) ← tail(A,B), tail(B,C), tail(C,A)
p(A,B), p(C,B) → A=C
p(A,B), p(A,C) → B=C
p(A,B) → ¬p(B,A)
p(A) → ¬q(A)

← p(A,B), p(C,B), A6=C ← succ(A,B), succ(C,B), A6=C
← p(A,B), p(A,C), B6=C ← length(A,B), length(A,C), B6=C
← p(A,B), p(B,A)
← p(A), q(A)

← mother(A,B), mother(B,A)
← odd(A), even(A)

← brother(A,A)

Table 1: Properties and constraints. We generalise the properties, except antitransitive and antitriangular, to higher arities.

POPPER uses a generate, test, and constrain loop to search
for a solution. In the generate stage, it uses an ASP solver to
ﬁnd a model of P. If there is a model, POPPER converts it
to a hypothesis and tests it on the examples; otherwise, it
increments the hypothesis size and loops again. If a hypoth-
esis is not a solution, POPPER builds hypothesis constraints
and adds them to P to eliminate models and thus prunes
the hypothesis space. For instance, if a hypothesis does not
entail all the positive examples, POPPER builds a specialisa-
tion constraint to prune more speciﬁc hypotheses. This loop
repeats until POPPER ﬁnds an optimal solution or there are
no more hypotheses to test.

DISCOPOPPER We augment POPPER with the ability to
use the constraints from our discovery approach. We call this
augmented version DISCOPOPPER. We condition the con-
straints to only apply to a relation p if a property holds for
p. For instance, we add an asymmetric constraint to DIS-
COPOPPER:

← asymmetric(P), b_lit(R,P,(A,B)), b_lit(R,P,(B,A))
If asymmetric(mother) holds, DISCOPOPPER builds the con-
straint:

← b_lit(R,mother,(A,B)), b_lit(R,mother,(B,A))
This constraint prunes all models that contain the literals
b_lit(R,mother,(A,B)) and b_lit(R,mother,(B,A)), i.e. all rules
with the body literals mother(A,B) and mother(B,A). This
constraint applies to all variable substitutions for A and B.
For instance, the constraint also prunes the rule:

h ← sister(A,B), sister(B,C), mother(C,D), mother(D,C)
Likewise, we add an exclusivity constraint to DISCOPOP-
PER:

← exclusive(P,Q), b_lit(R,P,Vars), b_lit(R,Q,Vars)
For instance, if exclusive(odd,even) holds, DISCOPOPPER
builds the constraint:

← b_lit(R,odd,Vars), b_lit(R,even,Vars)
We add a functional constraint to DISCOPOPPER:

← functional(P), b_lit(R,P,(A,B)), b_lit(R,P,(A,C)), C!=B
For instance, if functional(tail) holds, DISCOPOPPER builds
the constraint:

← b_lit(R,tail,(A,B)), b_lit(R,tail,(A,C), C!=B
The ASP encodings for all the constraints are in the ap-
pendix.

4.3 Optimal Soundness
We now prove that our approach only builds optimally sound
constraints, i.e. it will not remove optimal solutions from the
hypothesis space. We ﬁrst show the following lemma:

Lemma 1. Each property in Table 6 has an associated con-
straint with an unsatisﬁable body.

Proof. Follows from rewriting each property and the univer-
sal quantiﬁcation.

We show the main result:

Proposition 1 (Optimally sound constraint discovery).
Given the properties in Table 6, our approach builds opti-
mally sound constraints.

Proof. Let H ∈ H \ HC . Assume H is an optimal solu-
tion. Since H ∈ H but H 6∈ HC there must be a hypothesis
constraint C1 ∈ C such that H violates C1. C1 is a con-
straint from Table 1 and prunes rules. Then there exists a
rule C2 ∈ H and a substitution θ such that C1θ ⊂ C2. C1
has been built from our library of properties and thus has
an unsatisﬁable body according to Lemma 1. Since C1 has
an unsatisﬁable body, then the body of C2 is unsatisﬁable.
Thus C2 does not change the coverage of H. Then H \ C2
is a solution which contradicts our assumption.

5 Experiments
To evaluate our claim that BK constraint discovery can re-
duce learning times, our experiments aim to answer the ques-
tion:

Q1 Can BK constraint discovery reduce learning times?

To answer Q1, we compare the performance of POPPER and
DISCOPOPPER (POPPER with BK constraint discovery).

To understand how much our approach can improve per-

formance, our experiments aim to answer the question:

Q2 What effect does BK constraint discovery have on learn-

ing times given larger hypothesis spaces?

To answer Q2, we compare the performance of POPPER and
DISCOPOPPER on progressively larger hypothesis spaces.

To understand the scalability of our approach, our experi-

ments aim to answer the question:

Q3 How long does our BK constraint discovery approach

take given larger BK?

To answer Q3, we measure BK constraint discovery time on
progressively larger BK.

As our approach is novel, there is no state-of-the-art
to compare against, i.e. comparing DISCOPOPPER against
other systems will not allow us to evaluate the beneﬁts of BK
constraint discovery. We have, however, included a compar-
ison of DISCOPOPPER with other systems in the appendix.

Reproducibility. All the experimental code and data are
included as supplementary material with this submission
and will be made publicly available if the paper be accepted.

5.1 Experimental Domains
We use ﬁve domains. We brieﬂy describe them. More details
are in the appendix.

Michalski

trains. The goal

is to ﬁnd a hypothe-
sis that distinguishes eastbound and westbound trains
(Larson and Michalski 1977). We use four increasingly com-
plex tasks.
IMDB.

dataset
rela-
(Mihalkova, Huynh, and Mooney
tions between movies, actors, directors, gender and movie
genre. We learn the binary relations workedunder, a
more complex variant workedwithsamegender, and the
disjunction of the two.

real-world
2007)

contains

This

Chess. The task is to learn a rule for the king-rook-
king (krk) endgame where the white king protects its rook
(Hocquette and Muggleton 2020).

IGGP. The goal of inductive general game playing
(Cropper, Evans, and Law 2020) (IGGP) is to induce rules to
explain game traces from the general game playing compe-
tition (Genesereth and Björnsson 2013). We use four games:
minimal decay (md), rock, paper, scissors (rps), buttons, and
coins.

Program synthesis. Learning recursive programs is a ma-
jor challenge (Muggleton et al. 2012) and most systems can-
not learn recursive programs. We use a standard synthesis
dataset (Cropper and Morel 2021)5.

5.2 Experimental Setup
We enforce a timeout of 10 minutes per task. We measure
the mean and standard error over 20 trials. We round times
over one second to the nearest second. More experimental
details and example solutions are in the appendix.

Q1. We compare the performance of POPPER and DIS-
COPOPPER on all tasks. We measure predictive accuracy and
learning time. We separately measure BK constraint discov-
ery time.

Q2. We compare the performance of POPPER and DIS-
COPOPPER when varying the size of the hypothesis space.
We vary the maximum size of a rule allowed in a hypothesis

5Our
a

approach

discovery

restriction

constraint
common

(Evans and Grefenstette

requires Datalog
BK,
2018;
Kaminski, Eiter, and Inoue 2019; Evans et al. 2021). However,
the BK for the synthesis tasks is a deﬁnite program. Therefore,
to discover BK constraints, we use a Datalog subset of the BK
restricted to an alphabet with 10 symbols (0-9), where the BK
constraint discovery time is 4s. We use the deﬁnite program BK
for the learning task.

ie the maximum number of literals allowed in a rule. We use
the md and trains2 tasks.

Q3. We measure BK constraint discovery time on progres-
sively larger BK. We generate BK for the synthesis tasks.
The BK facts are relations between strings of a ﬁnite alpha-
bet. For instance, the BK contains facts such as:

string((1,3,3,7))
tail((1,3,3,7),(3,3,7))

head((1,3,3,7),(1,)
append((1,),(3,3,7),(1,3,3,7))

We generate larger BK by increasing the size of the alphabet.

5.3 Experimental Results
Q1. Table 2 shows that DISCOPOPPER (i) never needs more
time than POPPER, and (ii) can drastically reduce learning
time. For instance, for the md task, learning time is reduced
from 485s to 20s. A paired t-test conﬁrms the signiﬁcance
of the difference at the p < 0.01 level.

Table 3 shows that BK constraint discovery time is al-
ways less than a second, except for the synthesis tasks. For
instance, for the real-world imdb3 task, BK constraint dis-
covery takes 0.02s yet reduces learning time from 411s to
303s.

Task

POPPER DISCOPOPPER Change

trains1
trains2
trains3
trains4

imdb1
imdb2
imdb3

krk

md
buttons
rps
coins

dropk
droplast
evens
ﬁnddup
last
len
sorted
sumlist

8 ± 0.5
114 ± 34
323 ± 49
600 ± 0

1 ± 0
4 ± 0.1
411 ± 17

103 ± 18

485 ± 41
600 ± 0
600 ± 0
600 ± 0

3 ± 0.3
5 ± 0.5
29 ± 5
122 ± 24
4 ± 0.7
26 ± 6
468 ± 38
22 ± 0.9

7 ± 0.4
46 ± 11
117 ± 32
600 ± 0

1 ± 0.1
4 ± 0.2
303 ± 18

11 ± 0.5

20 ± 3
578 ± 22
116 ± 27
582 ± 12

2 ± 0.2
2 ± 0.1
4 ± 0.6
53 ± 10
1 ± 0.1
9 ± 2
51 ± 7
9 ± 0.1

-12%
-59%
-63%
0%

0%
0%
-26%

-89%

-95%
-3%
-80%
-3%

-33%
-60%
-86%
-56%
-75%
-65%
-89%
-59%

Table 2: Learning times in seconds.

To understand why our approach works, consider the rps
task. Our approach quickly (0.02s) discovers that the relation
succ is irreﬂexive, injective, functional, antitransitive, anti-
triangular, and asymmetric. The resulting constraints reduce
the number of rules in the hypothesis space from 1,189,916
to 70,270. This reduction in turn reduces learning time from
10 minutes (timeout) to 116s.

Table 4 shows that DISCOPOPPER (i) has equal or higher
predictive accuracy than POPPER on all but the md task, and

Domain

trains
imdb
krk
md
buttons
rps
coins
synthesis

Time

0.22 ± 0.00
0.02 ± 0.00
0.10 ± 0.00
0.01 ± 0.00
0.02 ± 0.00
0.02 ± 0.00
0.03 ± 0.00
4.00 ± 0.40

Table 3: BK constraint discovery times in seconds.

Task

POPPER DISCOPOPPER Change

trains1
trains2
trains3
trains4

imdb1
imdb2
imdb3

krk

md
buttons
rps
coins

dropk
droplast
evens
ﬁnddup
last
len
sorted
sumlist

100 ± 0
98 ± 0
100 ± 0
100 ± 0

100 ± 0
100 ± 0
99 ± 0

99 ± 0

99 ± 0
94 ± 0
96 ± 0
82 ± 3

99 ± 0
100 ± 0
100 ± 0
99 ± 0
100 ± 0
100 ± 0
82 ± 3
100 ± 0

100 ± 0
99 ± 0
100 ± 0
100 ± 0

100 ± 0
100 ± 0
99 ± 0

99 ± 0

98 ± 0
99 ± 0
100 ± 0
92 ± 1

99 ± 0
100 ± 0
100 ± 0
99 ± 0
100 ± 0
100 ± 0
94 ± 2
100 ± 0

0%
+1%
0%
0%

0%
0%
0%

0%

-1%
+5%
+4%
+12%

0%
0%
0%
0%
0%
0%
+14%
0%

Table 4: Predictive accuracies.

(ii) can improve predictive accuracy6. A McNemar’s test
conﬁrms the signiﬁcance of the difference at the p < 0.01
level.

There are two reasons for this accuracy improvement.
First, POPPER sometimes does not ﬁnd a good solution
within the time limit. By contrast, as there are fewer hy-
potheses for DISCOPOPPER to consider, it sometimes ﬁnds
a solution quicker7. Second, as our approach is optimally
sound (Proposition 1), it is guaranteed to lead to a hypoth-
esis space that is a subset of the original one yet still con-
tains all optimal solutions. According to the Blumer bound
(Blumer et al. 1987), given two hypotheses spaces of differ-
ent sizes, searching the smaller space will result in higher
predictive accuracy compared to searching the larger one,
assuming the target hypothesis is in both.

6Both systems sometimes achieve high accuracy yet time out
after 10 minutes. The reason is that they can often ﬁnd a good so-
lution early in the search but need to continue to search to prove
optimality.

7The appendix includes a table that shows the number of hy-

potheses considered by POPPER and DISCOPOPPER.

)
s
d
n
o
c
e
s
(

e
m
T

i

50

40

30

20

10

0

1m 2m 3m 4m 5m 6m 7m 8m

Num. background facts (millions)

Figure 1: BK constraint discovery time when increasing the
number of background facts.

Q2. Table 5 shows that DISCOPOPPER can drastically re-
duce learning time as the hypothesis space grows (relative
to POPPER). For instance, for the trains2 task with a maxi-
mum rule size of 6 the learning times of POPPER and DIS-
COPOPPER are 37s and 33s respectively. With a maximum
rule size of 10, POPPER times out after 10 minutes, whereas
DISCOPOPPER learns a solution in 45s.

Task

Size

POPPER DISCOPOPPER Change

trains2
trains2
trains2
trains2
trains2
trains2

md
md
md
md
md
md

5
6
7
8
9
10

5
6
7
8
9
10

31 ± 1
37 ± 1
80 ± 27
106 ± 3
358 ± 7
600 ± 0

136 ± 4
595 ± 2
576 ± 13
596 ± 4
596 ± 3
591 ± 5

30 ± 1
33 ± 1
32 ± 2
30 ± 1
39 ± 1
45 ± 2

14 ± 0.4
33 ± 0.9
39 ± 0.9
40 ± 1.0
38 ± 1
39 ± 1

-3%
-10%
-60%
-71%
-89%
-92%

-89%
-94%
-93%
-93%
-93%
-93%

Table 5: Learning times when progressively increasing the
maximum rule size and thus the hypothesis space.

Q3. Figure 1 show that our approach scales linearly in the
size of the BK. For instance, for BK with around 8m facts,
our approach takes around 47s.

6 Conclusions and Limitations
To improve learning performance, we have introduced a bias
discovery approach. The three key ideas are (i) use the BK to
discover a bias to restrict the hypothesis space, (ii) express
the bias as constraints, and (iii) discover constraints before
searching for a solution. Proposition 1 shows that our ap-
proach is optimally sound. Our experimental results on ﬁve
domains show that our approach can (i) substantially reduce
learning times, and (ii) scale to BK with millions of facts.

Limitations and Future Work Our constraint discovery
approach requires Datalog BK. Future work should address

this limitation, such as by using top-down dependency dis-
covery methods (Flach and Savnik 1999).

We use a predeﬁned set of relational properties and de-
pendencies. The main direction for future work, therefore,
is to discover more general properties and constraints. For
instance, consider the two rules h ← empty(A), head(A,B)
and h ← empty(A), tail(A,B). The bodies of these rules are
unsatisﬁable because an empty list cannot have a head or a
tail. We cannot, however, currently capture this information.
Therefore, we think that this paper raises a research chal-
lenge of efﬁciently identifying more general properties and
constraints.

Appendices

A Properties

In

game

playing

general

inductive

competition

IGGP.
playing
(Cropper, Evans, and Law 2020) (IGGP) the task is to
induce a hypothesis to explain game traces from the general
game
(Genesereth and Björnsson
2013). Although seemingly a ‘toy’ problem, IGGP is rep-
resentative of many real-world problems, such as inducing
semantics of programming languages (Bartha and Cheney
2019). We consider four IGGP games: minimal decay (md),
buttons, rock paper scissors (rps) and coins. We learn the
next relation in each game.

Program Synthesis. This dataset includes list transforma-
tion tasks. It involves learning recursive programs which
has been identiﬁed as a difﬁcult challenge for ILP systems
(Muggleton et al. 2012).

Table 6 shows the relational properties we use, up to arity
three.

D.2 Experimental Setup

B ASP Encoding

Figure 2 shows the ASP encoding. In practice, we also
consider optional types, to reduce grounding. However, for
brevity, we only show the untyped encodings. We also only
show the encodings for unary, binary, and ternary relations.

C DISCOPOPPER Constraints

Figure 3 shows the constraints used by DISCOPOPPER.

D Experiments

D.1 Experimental domains

We describe characteristics of the domains and tasks used in
our experiments in Table 7 and 8. Figure 4 shows example
solutions for some of the tasks.

Michalski trains. The goal of these tasks is to ﬁnd a hy-
pothesis that distinguishes eastbound and westbound trains
(Larson and Michalski 1977). There are four increasingly
complex tasks. There are 1000 examples but the distribution
of positive and negative examples is different for each task.
We randomly sample the examples and split them into 80/20
train/test partitions.

IMDB

real-world

IMDB. The
dataset
(Mihalkova, Huynh, and Mooney 2007) includes relations
between movies, actors, directors, movie genre, and gender.
It has been created from the International Movie Database
(IMDB.com) database. We learn the relation workedunder/2,
a more complex variant workedwithsamegender/2, and the
disjunction of the two.

Chess. The task is to learn a chess pattern in the king-rook-
king (krk) endgame, which is the chess ending with white
having a king and a rook and black having a king. We learn
the concept of rook protection by its king.

We measure the mean and standard error of the predictive
accuracy and learning time. We use a 3.8 GHz 8-Core Intel
Core i7 with 32GB of ram. The systems use a single CPU.

Q1. We compare the performance of POPPER and DIS-
COPOPPER on all the tasks. We use POPPER with the divide
and conquer search strategy (Cropper 2022).

Q2. We compare the performance of POPPER and DIS-
COPOPPER when varying the size of the hypothesis space.
We vary the maximum size of a rule allowed in a hypothesis,
ie the maximum number of literals in a rule. We focus on the
md and trains2 tasks.

D.3 Experimental Results

Number of hypotheses generated Table 9 shows the num-
ber of hypotheses generated, these results are a supplement
to Tables 2 and 4. These results show that (i) DISCOPOP-
PER considers a smaller number of hypotheses compared to
POPPER apart on imdb1, imdb2 and buttons and (ii) DIS-
COPOPPER can consider only a signiﬁcantly smaller num-
ber of hypotheses compared to POPPER. For instance, to
ﬁnd a solution for the md task, POPPER considers 4564 hy-
potheses whereas DISCOPOPPER only considers 866. These
results can be explained by the fact that BK constraint dis-
covery can discover a large number of constraints. Each of
these constraints can prune a large number of rules from the
rule space, which in turn can prune of large number of hy-
potheses from the hypothesis space. However, although DIS-
COPOPPER searches a subset of the hypothesis space, there
is no guarantee that it will ﬁnd a solution before POPPER,
because the systems might consider hypotheses in a differ-
ent order, which explains the higher number of hypotheses
generated for imdb1, imdb2 and buttons.

Name

Property

Constraint

Example

8

Irreﬂexiveaaa
Injectiveabc−dbc
Injectiveabc−adc
Functionalabc−abd
Asymmetricabc−acb
Asymmetricabc−bac
Asymmetricabc−bca
Asymmetricabc−cab
Asymmetricabc−cba
Exclusiveab
Exclusiveabc
Singleton

← p(A,A,A)

← modulo(A,A,A)

¬p(A,A,A)
p(A,B,C), p(D,B,C) → A=D ← p(A,B,C), p(D,B,C), A6=D ← add(A,B,C), add(D,B,C), A6=D
p(A,B,C), p(A,D,C) → B=D ← p(A,B,C), p(A,D,C), B6=D ← add(A,B,C), add(A,D,C), B6=D
p(A,B,C), p(A,B,D) → C=D ← p(A,B,C), p(A,B,D), C6=D ← add(A,B,C), add(A,B,D), C6=D
p(A,B,C) → ¬p(A,C,B)
p(A,B,C) → ¬p(B,A,C)
p(A,B,C) → ¬p(B,C,A)
p(A,B,C) → ¬p(C,A,B)
p(A,B,C) → ¬p(C,B,A)
p(A,B) → ¬q(A,B)
p(A,B,C) → ¬q(A,B,C)
p(A), p(B) → A=B

← cons(A,B,C), cons(A,C,B)
← cons(A,B,C), cons(B,A,C)
← cons(A,B,C), cons(B,C,A)
← cons(A,B,C), cons(C,A,B)
← select(A,B,C), select(C,B,A)
← head(A,B), tail(A,B)
← select(A,B,C), append(A,B,C)
← one(A), one(B)

← p(A,B,C), p(A,C,B)
← p(A,B,C), p(B,A,C)
← p(A,B,C), p(B,C,A)
← p(A,B,C), p(C,A,B)
← p(A,B,C), p(C,B,A)
← p(A,B), q(A,B)
← p(A,B,C), q(A,B,C)
← p(A), p(B), A6=B

Table 6: Properties and constraints. This Table is a supplement to Table 1.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31

body_pred(P,1):-holds(P,(_,)).

body_pred(P,2):-holds(P,(_,_)).

body_pred(P,3):-holds(P,(_,_,_)).

prop(antitransitive,P):- body_pred(P,2), not antitransitive_aux(P).

prop(antitriangular,P):- body_pred(P,2), not antitriangular_aux(P).

prop(asymmetric_ab_ba,P):- holds(P,(A,B)), not holds(P,(B,A)).
prop(asymmetric_abc_acb,P):- holds(P,(A,B,C)), not holds(P,(A,C,B)).

prop(asymmetric_abc_bac,P):- holds(P,(A,B,C)), not holds(P,(B,A,C)).

prop(asymmetric_abc_bca,P):- holds(P,(A,B,C)), not holds(P,(B,C,A)).

prop(asymmetric_abc_cab,P):- holds(P,(A,B,C)), not holds(P,(C,A,B)).

prop(asymmetric_abc_cba,P):- holds(P,(A,B,C)), not holds(P,(C,B,A)).

prop(singleton,P):- body_pred(P,_), #count{Vars : holds(P,Vars)} == 1.

prop(unsat_pair,P,Q):- body_pred(Q,A), body_pred(P,A), P > Q, #count{Vars : holds(P,Vars), holds(Q,Vars)} == 0.

prop(unique_a_b,P):- body_pred(P,2), not unique_a_b_(P).

prop(unique_b_a,P):- body_pred(P,2), not unique_b_a_(P).

prop(unique_a_bc,P):- body_pred(P,3), not unique_a_bc_(P).

prop(unique_ab_c,P):- body_pred(P,3), not unique_ab_c_(P).

prop(unique_ac_b,P):- body_pred(P,3), not unique_ac_b_(P).

prop(unique_b_ac,P):- body_pred(P,3), not unique_b_ac_(P).

prop(unique_bc_a,P):- body_pred(P,3), not unique_bc_a_(P).

prop(unique_c_ab,P):- body_pred(P,3), not unique_c_ab_(P).

antitransitive_aux(P):- holds(P,(A,B)), holds(P,(B,C)), holds(P,(A,C)).

antitriangular_aux(P):- holds(P,(A,B)), holds(P,(B,C)),

unique_a_b_(P):-holds(P,(A,_)), #count{B : holds(P,(A,B))} > 1.

unique_b_a_(P):-holds(P,(_,B)), #count{A : holds(P,(A,B))} > 1.

unique_a_bc_(P):-holds(P,(A,_,_)), #count{B,C : holds(P,(A,B,C))} > 1.

unique_ab_c_(P):-holds(P,(A,B,_)), #count{C : holds(P,(A,B,C))} > 1.

unique_ac_b_(P):-holds(P,(A,_,C)), #count{B : holds(P,(A,B,C))} > 1.

unique_b_ac_(P):-holds(P,(_,B,_)), #count{A,C : holds(P,(A,B,C))} > 1.

unique_bc_a_(P):-holds(P,(_,B,C)), #count{A : holds(P,(A,B,C))} > 1.

unique_c_ab_(P):-holds(P,(_,_,C)), #count{A,B : holds(P,(A,B,C))} > 1.

Figure 2: ASP encoding to discover properties and functional dependencies in the BK.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18

:- prop(asymmetric_ab_ba,P), body_literal(Rule,P,_,(A,B)), body_literal(Rule,P,_,(B,A)).

:- prop(asymmetric_abc_acb,P), body_literal(Rule,P,_,(A,B,C)), body_literal(Rule,P,_,(A,C,B)).

:- prop(asymmetric_abc_bac,P), body_literal(Rule,P,_,(A,B,C)), body_literal(Rule,P,_,(B,A,C)).

:- prop(asymmetric_abc_bca,P), body_literal(Rule,P,_,(A,B,C)), body_literal(Rule,P,_,(B,C,A)).

:- prop(asymmetric_abc_cab,P), body_literal(Rule,P,_,(A,B,C)), body_literal(Rule,P,_,(C,A,B)).

:- prop(asymmetric_abc_cba,P), body_literal(Rule,P,_,(A,B,C)), body_literal(Rule,P,_,(C,B,A)).
:- prop(unique_a_b,P), body_literal(Rule,P,_,(A,_)), #count{B : body_literal(Rule,P,_,(A,B))} > 1.

:- prop(unique_a_bc,P), body_literal(Rule,P,_,(A,_,_)), #count{B,C : body_literal(Rule,P,_,(A,B,C))} > 1.

:- prop(unique_ab_c,P), body_literal(Rule,P,_,(A,B,_)), #count{C : body_literal(Rule,P,_,(A,B,C))} > 1.

:- prop(unique_ac_b,P), body_literal(Rule,P,_,(A,_,C)), #count{B : body_literal(Rule,P,_,(A,B,C))} > 1.

:- prop(unique_b_a,P), body_literal(Rule,P,_,(_,B)), #count{A : body_literal(Rule,P,_,(A,B))} > 1.

:- prop(unique_b_ac,P), body_literal(Rule,P,_,(_,B,_)), #count{A,C : body_literal(Rule,P,_,(A,B,C))} > 1.

:- prop(unique_bc_a,P), body_literal(Rule,P,_,(_,B,C)), #count{A : body_literal(Rule,P,_,(A,B,C))} > 1.

:- prop(unique_c_ab,P), body_literal(Rule,P,_,(_,_,C)), #count{A,B : body_literal(Rule,P,_,(A,B,C))} > 1.

:- prop(antitransitive,P), body_literal(Rule,P,_,(A,B)), body_literal(Rule,P,_,(B,C)), body_literal(Rule,P,_,(A,C)).

:- prop(antitriangular,P), body_literal(Rule,P,_,(A,B)), body_literal(Rule,P,_,(B,C)), body_literal(Rule,P,_,(C,A)).

:- prop(singleton,P), body_literal(Rule,P,_,_), #count{Vars : body_literal(Rule,P,A,Vars)} > 1.

:- prop(unsat_pair,P,Q), body_literal(Rule,P,_,Vars), body_literal(Rule,Q,_,Vars).

Figure 3: ASP encoding of constraints in DISCOPOPPER.

Task

trains

imdb1
imdb2
imdb3

md
buttons
rps
coins

krk

dropk
droplast
evens
ﬁnddup
last
len
sorted
sumlist

# examples

# relations

# constants

# facts

1000

383
71825
121801

54
530
464
2544

50

20
20
20
20
20
20
20
20

20

5
5
5

12
13
6
6

8

9
9
9
9
9
9
9
9

8561

28503

299
299
299

13
60
64
110

162

n/a
n/a
n/a
n/a
n/a
n/a
n/a
n/a

1330
1330
1330

29
656
405
1101

6744

n/a
n/a
n/a
n/a
n/a
n/a
n/a
n/a

Table 7: Experimental domain description.

Task

train1
train2
train3
train4

imdb1
imdb2
imdb3

krk

md
buttons
rps
coins

dropk
droplast
evens
ﬁnddup
last
len
sorted
sumlist

# rules

# literals max literals per rule

1
2
3
4

1
1
2

1

2
10
4
16

2
2
2
2
2
2
2
2

6
11
17
26

5
5
10

8

11
61
25
45

7
8
7
7
7
7
9
7

6
6
7
7

5
5
5

8

6
7
7
7

4
5
5
4
4
4
6
5

Comparison against other ILP systems We com-
pare9 DISCOPOPPER
POPPER, METAGOL
against
(Cropper and Muggleton 2016), and ALEPH (Srinivasan
2001):

METAGOL METAGOL is one of the few systems that can
learn recursive Prolog programs. METAGOL uses user-
provided metarules (program templates) to guide the
search for a solution. We use the approximate univer-

9We also tried to use ILASP3 (Law, Russo, and Broda 2014).
However, ILASP3 ﬁrst pre-computes every possible rule in a hy-
pothesis space. This approach is infeasible for our datasets. For in-
stance, on the trains tasks, ILASP3 took 2 seconds to pre-compute
rules with three body literals; 20 seconds for rules with four body
literals; and 12 minutes for rules with ﬁve body literals. Since the
simplest train task requires rules with six body literals, ILASP3 is
unusable. In addition, ILASP3 cannot learn Prolog programs so is
unusable in the synthesis tasks.

Table 8: Experimental tasks description.

sal set of metarules described by Cropper and Tourret
(2020).

ALEPH ALEPH excels at learning many large non-recursive
rules and should excel at the trains and IGGP tasks. Al-
though ALEPH can learn recursive programs, it struggles
to do so. DISCOPOPPER and ALEPH use similar biases
so the comparison can be considered reasonably fair.

Results. Tables 10 and 11 shows accuracies and learning
times respectively.

References
Ahlgren, J.; and Yuen, S. Y. 2013. Efﬁcient program synthe-
sis using constraint satisfaction in inductive logic program-
ming. J. Machine Learning Res., (1): 3649–3682.

1
2

1
2
3
4

1
2

1
2
3
4
5
6
7
8
9
10

1
2
3

1
2
3
4

1
2

Listing 1: trains2

east(A):-car(A,C),roof_open(C),load(C,B),triangle(B)

east(A):-car(A,C),car(A,B),roof_closed(B),two_wheels(C),roof_open(C).

Listing 2: trains4

f(A):-has_car(A,D),has_load(D,B),has_load(D,C),rectangle(B),diamond(C).

f(A):-has_car(A,B),has_load(B,C),hexagon(C),roof_open(B),three_load(C).

f(A):-has_car(A,E),has_car(A,D),has_load(D,C),triangle(C),has_load(E,B),hexagon(B).

f(A):-has_car(A,C),roof_open(C),has_car(A,B),roof_flat(B),short(C),long(B).

next_value(A,B):-c_player(D),c_pressButton(C),c5(B),does(A,D,C).

next_value(A,B):-c_player(C),my_true_value(A,E),does(A,C,D),my_succ(B,E),c_noop(D).

Listing 4: buttons

Listing 3: minimal decay

next(A,B):-c_p(B),c_c(C),does(A,D,C),my_true(A,B),my_input(D,C).

next(A,B):-my_input(C,E),c_p(D),my_true(A,D),c_b(E),does(A,C,E),c_q(B).

next(A,B):-my_input(C,D),not_my_true(A,B),does(A,C,D),c_p(B),c_a(D).

next(A,B):-c_a(C),does(A,D,C),my_true(A,B),c_q(B),my_input(D,C).

next(A,B):-my_input(C,E),c_p(B),my_true(A,D),c_b(E),does(A,C,E),c_q(D).

next(A,B):-c_c(D),my_true(A,C),c_r(B),role(E),does(A,E,D),c_q(C).

next(A,B):-my_true(A,C),my_succ(C,B).

next(A,B):-my_input(C,D),does(A,C,D),my_true(A,B),c_r(B),c_b(D).

next(A,B):-my_input(C,D),does(A,C,D),my_true(A,B),c_r(B),c_a(D).

next(A,B):-my_true(A,E),c_c(C),does(A,D,C),c_q(B),c_r(E),my_input(D,C).

Listing 5: rps

next_score(A,B,C):-does(A,B,E),different(G,B),my_true_score(A,B,F),beats(E,D),my_succ(F,C),does(A,G,D).

next_score(A,B,C):-different(G,B),beats(D,F),my_true_score(A,E,C),does(A,G,D),does(A,E,F).

next_score(A,B,C):-my_true_score(A,B,C),does(A,B,D),does(A,E,D),different(E,B).

Listing 6: coins

next_cell(A,B,C):-does_jump(A,E,F,D),role(E),different(B,D),my_true_cell(A,B,C),different(F,B).

next_cell(A,B,C):-my_pos(E),role(D),c_zerocoins(C),does_jump(A,D,B,E).

next_cell(A,B,C):-role(D),does_jump(A,D,E,B),c_twocoins(C),different(B,E).

next_cell(A,B,C):-does_jump(A,F,E,D),role(F),my_succ(E,B),my_true_cell(A,B,C),different(E,D).

Listing 7: sorted

f(A):-tail(A,B),empty(B).

f(A):-tail(A,D),head(A,B),head(D,C),geq(C,B),f(D).

Figure 4: Example solutions.

POPPER

DISCOPOPPER Change

Task

POPPER DISCOPOPPER ALEPH METAGOL

trains1
trains2
trains3
trains4

imdb1
imdb2
imdb3

krk

md
buttons
rps
coins

dropk
droplast
evens
ﬁnddup
last
len
sorted
sumlist

256 ± 17
1117 ± 169
1971 ± 174
3459 ± 103

2 ± 0
18 ± 0.7
517 ± 14

517 ± 40

4564 ± 288
7881 ± 193
4408 ± 273
5744 ± 128

269 ± 36
174 ± 26
837 ± 88
3705 ± 458
381 ± 64
1377 ± 224
3833 ± 201
1393 ± 2

230 ± 17
858 ± 101
1366 ± 170
2907 ± 57

4 ± 0
22 ± 1
425 ± 10

55 ± 5

866 ± 124
8625 ± 511
1049 ± 146
5866 ± 238

244 ± 24
121 ± 7
313 ± 33
3471 ± 430
199 ± 22
960 ± 145
1561 ± 131
1023 ± 1

-10%
-23%
-30%
-15%

+100%
+22%
-17%

-89%

-81%
+9%
-76%
+2%

-9%
-30%
-62%
-6%
-47%
-30%
-59%
-26%

trains1
trains2
trains3
trains4

imdb1
imdb2
imdb3

krk

md
buttons
rps
coins

dropk
droplast
evens
ﬁnddup
last
len
sorted
sumlist

100 ± 0
98 ± 0
100 ± 0
100 ± 0

100 ± 0
100 ± 0
99 ± 0

99 ± 0

99 ± 0
94 ± 0
96 ± 0
82 ± 3

99 ± 0
100 ± 0
100 ± 0
99 ± 0
100 ± 0
100 ± 0
82 ± 3
100 ± 0

100 ± 0
99 ± 0
100 ± 0
100 ± 0

100 ± 0
100 ± 0
99 ± 0

99 ± 0

98 ± 0
99 ± 0
100 ± 0
92 ± 1

99 ± 0
100 ± 0
100 ± 0
99 ± 0
100 ± 0
100 ± 0
94 ± 2
100 ± 0

100 ± 0
99 ± 0
100 ± 0
100 ± 0

100 ± 0
50 ± 0
50 ± 0

98 ± 0

94 ± 0
87 ± 0
100 ± 0
25 ± 5

52 ± 2
50 ± 0
71 ± 1
50 ± 0
49 ± 0
50 ± 0
82 ± 2
50 ± 0

27 ± 0
19 ± 0
79 ± 0
32 ± 0

16 ± 0
50 ± 0
50 ± 0

50 ± 0

11 ± 0
19 ± 0
18 ± 0
17 ± 0

50 ± 0
50 ± 0
50 ± 0
50 ± 0
55 ± 3
50 ± 0
50 ± 0
62 ± 4

Table 9: Number of hypotheses generated. Error is standard
error. These results are a supplement to Table 2 and 4.

Table 10: Predictive accuracies. We round accuracies to inte-
ger values. The error is standard deviation.

Bartha, S.; and Cheney, J. 2019. Towards Meta-interpretive
In Induc-
Learning of Programming Language Semantics.
tive Logic Programming - 29th International Conference,
ILP 2019, Plovdiv, Bulgaria, September 3-5, 2019, Proceed-
ings, 16–25.
Blumer, A.; Ehrenfeucht, A.; Haussler, D.; and Warmuth,
M. K. 1987. Occam’s Razor. Inf. Process. Lett., (6): 377–
380.
Charnley, J. W.; Colton, S.; and Miguel, I. 2006. Automatic
Generation of Implied Constraints. In ECAI 2006, 17th Eu-
ropean Conference on Artiﬁcial Intelligence, 73–77.
Corapi, D.; Russo, A.; and Lupu, E. 2011. Inductive Logic
In Inductive
Programming in Answer Set Programming.
Logic Programming - 21st International Conference, 91–97.
Cropper, A. 2022. Learning logic programs through divide,
constrain, and conquer. In AAAI 2022.
Cropper, A.; Dumancic, S.; Evans, R.; and Muggleton, S. H.
2021. Inductive logic programming at 30. Machine Learn-
ing.
Cropper, A.; Evans, R.; and Law, M. 2020. Inductive general
game playing. Machine Learning, (7): 1393–1434.
Cropper, A.; and Morel, R. 2021. Learning programs by
learning from failures. Machine Learning., (4): 801–856.
Cropper, A.; and Muggleton, S. H. 2016. Metagol System.
https://github.com/metagol/metagol.
Cropper, A.; and Tourret, S. 2020. Logical reduction of
metarules. Machine Learning, (7): 1323–1369.
De Raedt, L. 2008. Logical and relational learning. ISBN
978-3-540-20040-6.
De Raedt, L.; and Dehaspe, L. 1997. Clausal Discovery. Ma-
chine Learning, (2-3): 99–146.

De Raedt, L.; Passerini, A.; and Teso, S. 2018. Learning
Constraints From Examples. In Proceedings of the Thirty-
Second AAAI Conference on Artiﬁcial Intelligence, (AAAI-
18), 7965–7970.

De Raedt, L.; and Ramon, J. 2004. Condensed Represen-
tations for Inductive Logic Programming. In Principles of
Knowledge Representation and Reasoning: Proceedings of
the Ninth International Conference (KR2004), 438–446.
Dumanˇci´c, S.; Guns, T.; Meert, W.; and Blockeel, H. 2019.
Learning Relational Representations with Auto-encoding
Logic Programs. In Proceedings of the Twenty-Eighth Inter-
national Joint Conference on Artiﬁcial Intelligence, IJCAI
2019, 6081–6087.

Eén, N.; and Biere, A. 2005. Effective Preprocessing in SAT
In Theory and
Through Variable and Clause Elimination.
Applications of Satisﬁability Testing, 8th International Con-
ference, SAT 2005, 61–75.
Ellis, K.; Morales, L.; Sablé-Meyer, M.; Solar-Lezama, A.;
and Tenenbaum, J. 2018. Learning Libraries of Subrou-
tines for Neurally-Guided Bayesian Program Induction. In
NeurIPS 2018, 7816–7826.
Evans, R.; and Grefenstette, E. 2018. Learning Explanatory
Rules from Noisy Data. J. Artif. Intell. Res., 1–64.
Evans, R.; Hernández-Orallo, J.; Welbl, J.; Kohli, P.; and Ser-
got, M. J. 2021. Making sense of sensory input. Artif. Intell.,
103438.
Flach, P. A.; and Savnik, I. 1999. Database Dependency
Discovery: A Machine Learning Approach. AI Commun.,
(3): 139–160.
Genesereth, M. R.; and Björnsson, Y. 2013. The Interna-

McCreath, E.; and Sharma, A. 1995. Extraction of Meta-
Knowledge to Restrict the Hypothesis Space for ILP Sys-
In Eighth Australian Joint Conference on Artiﬁcial
tems.
Intelligence, 75–82.
Mihalkova, L.; Huynh, T.; and Mooney, R. J. 2007. Mapping
and revising markov logic networks for transfer learning. In
Aaai, volume 7, 608–614.
Mitchell, T. M. 1997. Machine learning.
Muggleton, S. 1991. Inductive Logic Programming. New
Generation Computing, (4): 295–318.
Muggleton, S. 1995. Inverse Entailment and Progol. New
Generation Comput., (3&4): 245–286.
Muggleton, S.; De Raedt, L.; Poole, D.; Bratko, I.; Flach,
P. A.; Inoue, K.; and Srinivasan, A. 2012.
ILP turns 20 -
Biography and future challenges. Machine Learning, (1):
3–23.
Papenbrock, T.; Ehrlich, J.; Marten, J.; Neubert, T.; Rudolph,
J.; Schönberg, M.; Zwiener, J.; and Naumann, F. 2015. Func-
tional Dependency Discovery: An Experimental Evaluation
of Seven Algorithms. Proc. VLDB Endow., (10): 1082–
1093.
Savnik, I.; and Flach, P. A. 1993. Bottom-up induction
In Proceed-
of functional dependencies from relations.
ings of the AAAI-93 Workshop on Knowledge Discovery in
Databases, 174–185.
Shapiro, E. Y. 1983. Algorithmic Program DeBugging. Cam-
bridge, MA, USA. ISBN 0262192187.
Srinivasan, A. 2001. The ALEPH manual. Machine Learn-
ing at the Computing Laboratory, Oxford University.

Task

POPPER DISCOPOPPER

ALEPH METAGOL

trains1
trains2
trains3
trains4

imdb1
imdb2
imdb3

krk

md
buttons
rps
coins

dropk
droplast
evens
ﬁnddup
last
len
sorted
sumlist

8 ± 0.5
114 ± 34
323 ± 49
600 ± 0

1 ± 0
4 ± 0.1
411 ± 17

103 ± 18

485 ± 41
600 ± 0
600 ± 0
600 ± 0

3 ± 0.3
5 ± 0.5
29 ± 5
122 ± 24
4 ± 0.7
26 ± 6
468 ± 38
22 ± 0.9

7 ± 0.4
46 ± 11
117 ± 32
600 ± 0

1 ± 0.1
4 ± 0.2
303 ± 18

11 ± 0.5

20 ± 3
578 ± 22
116 ± 27
582 ± 12

2 ± 0.2
2 ± 0.1
4 ± 0.6
53 ± 10
1 ± 0.1
9 ± 2
51 ± 7
9 ± 0.1

3 ± 0.2
2 ± 0.2
32 ± 7
147 ± 19

141 ± 23
600 ± 0
600 ± 0

0.4 ± 0

5 ± 0.1
204 ± 4
6 ± 0.1
594 ± 4

37 ± 5
75 ± 3
10 ± 1
9 ± 1
25 ± 1
24 ± 1
3 ± 0.4
0.3 ± 0

600 ± 0
600 ± 0
600 ± 0
600 ± 0

600 ± 0
600 ± 0
600 ± 0

208 ± 5

300 ± 0
300 ± 0
0.3 ± 0
0.4 ± 0

0.3 ± 0
300 ± 0
217 ± 26
300 ± 0
270 ± 20
300 ± 0
288 ± 11
225 ± 29

Table 11: Learning times. We round times over one second
to the nearest second. The error is standard deviation.

tional General Game Playing Competition. AI Magazine,
(2): 107–111.
Gulwani, S.; Polozov, O.; Singh, R.; et al. 2017. Program
synthesis. Foundations and Trends® in Programming Lan-
guages, 4(1-2): 1–119.
Hocquette, C.; and Muggleton, S. H. 2020. Complete
Bottom-Up Predicate Invention in Meta-Interpretive Learn-
ing. In Proceedings of the Twenty-Ninth International Joint
Conference on Artiﬁcial Intelligence, IJCAI 2020, 2312–
2318.
Inoue, K.; Doncescu, A.; and Nabeshima, H. 2013. Com-
pleting causal networks by meta-level abduction. Machine
Learning, (2): 239–277.
Kaminski, T.; Eiter, T.; and Inoue, K. 2019. Meta-
Interpretive Learning Using HEX-Programs. In Proceedings
of the Twenty-Eighth International Joint Conference on Ar-
tiﬁcial Intelligence, IJCAI 2019, 6186–6190.
Larson, J.; and Michalski, R. S. 1977. Inductive inference
of VL decision rules. SIGART Newsletter, 38–44.
Law, M.; Russo, A.; and Broda, K. 2014. Inductive Learning
of Answer Set Programs. In Logics in Artiﬁcial Intelligence
- 14th European Conference, JELIA 2014, 311–325.
Lloyd, J. W. 2012. Foundations of logic programming.
Springer Science & Business Media.
Lynce, I.; and Silva, J. P. M. 2004. On Computing Mini-
mum Unsatisﬁable Cores. In SAT 2004 - The Seventh Inter-
national Conference on Theory and Applications of Satisﬁa-
bility Testing.
Mannila, H.; and Räihä, K. 1994. Algorithms for Inferring
Functional Dependencies from Relations. Data Knowl. Eng.,
(1): 83–99.

