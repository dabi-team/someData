Convergence Rates of Smooth Message Passing with Rounding in
Entropy-Regularized MAP Inference

0
2
0
2

r
a

M
1

]

G
L
.
s
c
[

2
v
7
2
1
1
0
.
7
0
9
1
:
v
i
X
r
a

Jonathan N. Lee∗
Stanford University

Aldo Pacchiano∗
UC Berkeley

Michael I. Jordan
UC Berkeley

Abstract

Maximum a posteriori (MAP) inference is
a fundamental computational paradigm for
statistical inference. In the setting of graphi-
cal models, MAP inference entails solving a
combinatorial optimization problem to ﬁnd
the most likely conﬁguration of the discrete-
valued model. Linear programming (LP) re-
laxations in the Sherali-Adams hierarchy are
widely used to attempt to solve this problem,
and smooth message passing algorithms have
been proposed to solve regularized versions
of these LPs with great success. This paper
leverages recent work in entropy-regularized
LPs to analyze convergence rates of a class
of edge-based smooth message passing algo-
rithms to (cid:15)-optimality in the relaxation. With
an appropriately chosen regularization con-
stant, we present a theoretical guarantee on
the number of iterations suﬃcient to recover
the true integral MAP solution when the LP
is tight and the solution is unique.

1 INTRODUCTION

Undirected graphical models are a central modeling for-
malism in machine learning, providing a compact and
powerful way to model dependencies between variables.
Here we focus on the important class of discrete-valued
pairwise models. Inference in discrete-valued graphi-
cal models has applications in many areas including
computer vision, statistical physics, information theory,
and genome research (Antonucci et al., 2014; Mezard
and Montanari, 2009; Wainwright and Jordan, 2008).

We focus on the problem of identifying a conﬁguration
of all variables that has highest probability, termed

∗Equal contribution. Proceedings of the 23rd International
Conference on Artiﬁcial Intelligence and Statistics (AIS-
TATS) 2020, Palermo, Italy. PMLR: Volume 108. Copyright
2020 by the author(s).

maximum a posteriori (MAP) inference. This problem
has an extensive literature across multiple communities,
where it is described by various names, including en-
ergy minimization (Kappes et al., 2013) and constraint
satisfaction (Schiex et al., 1995). In the binary case,
the MAP problem is sometimes described as quadratic-
pseudo Boolean optimization (Hammer et al., 1984) and
it is known to be NP-hard to compute exactly (Cooper,
1990; Kolmogorov and Zabin, 2004) or even to ap-
proximate (Dagum and Luby, 1993). Consequently,
much work has attempted to identify settings where
polynomial-time methods are feasible. We call such
settings “tractable” and the methods “eﬃcient.” A
general framework for obtaining tractable methodology
involves “relaxation”—the MAP problem is formulated
as an integer linear program (ILP) and is then relaxed
to a linear program (LP). If the vertex at which the
LP achieves optimality is integral, then it provides an
exact solution to the original problem. In this case we
say that the LP is tight. If the LP is performed over
the convex hull of all integral assignments, otherwise
known as the marginal polytope M, then it will always
be tight. Inference over the marginal polytope is gener-
ally intractable because it requires exponentially many
constraints to enforce global consistency.

A popular workaround is to relax the marginal poly-
tope to the local polytope L2 (Wainwright and Jordan,
2008). Instead of enforcing global consistency, the lo-
cal polytope enforces consistency only over pairs of
variables, thus yielding pseudo-marginals which are
pairwise consistent but may not correspond to any true
global distribution. The number of constraints needed
to specify the local polytope is linear in the number of
edges. More generally, Sherali and Adams (1990) intro-
duced a series of successively tighter relaxations of the
marginal polytope, or convex hull, while retaining con-
trol on the number of constraints. However, even with
these relaxations, it has been observed that standard
LP solvers do not scale well (Yanover et al., 2006), mo-
tivating the study of solvers that exploit the structure
of the problem, such as message passing algorithms.

Of particular interest to this paper are smooth mes-

 
 
 
 
 
 
Convergence Rates of Smooth Message Passing with Rounding

sage passing algorithms, i.e. algorithms derived from
regularized versions of the relaxed LP (Hazan and
Shashua, 2008; Meshi et al., 2012; Ravikumar et al.,
2010; Savchynskyy et al., 2011, 2012). These regular-
ized LPs conduce to eﬃcient optimization in practice
and have the special property that their ﬁxed points
are unique and optimal; however, this comes at the cost
of solving an approximation of the true MAP problem
and, without rounding, they do not recover integral
solutions in general. Non-asymptotic convergence rates
to the optimal regularized function value have been
studied (Meshi et al., 2012), but guarantees on the
number of iterations suﬃcient to recover the optimal
integral assignment of the true MAP problem have not
been considered to our knowledge.

In this work we provide a sharp analysis of the entropy-
regularized MAP inference problem with Sherali-
Adams relaxations. We ﬁrst characterize the approxi-
mation error of the regularized LP in l1 distance, based
on new results on entropy-regularized LPs (Weed, 2018).
We then analyze an edge-based smooth message passing
algorithm, modiﬁed from the algorithms described in
Werner (2007) and Ravikumar et al. (2010). We prove
a O(1/(cid:15)2) rate of convergence of iterates in l1 distance.
Combining the approximation error and convergence
results, we present a guarantee on the number of iter-
ations suﬃcient to recover of the true integral MAP
assignment using a standard vertex rounding scheme
when the LP relaxation is tight and the solution is
unique.

2 RELATED WORK

The idea of entropy regularization to aid optimization
in inference problems is well studied. It is well known
that solving a scaled and entropy-regularized linear
program over the marginal polytope yields the scaled
Gibbs free energy, intimately related to the log parti-
tion function, when the temperature parameter equals
one (Wainwright and Jordan, 2008). As the temper-
ature parameter is driven to zero, the calculation of
the free energy reduces to the value of the MAP prob-
lem. However, this problem is intractable due to the
diﬃculty of both computing the exact entropy and
characterizing the marginal polytope (Deza and Lau-
rent, 2009). Therefore, there has been much work in
trying to turn this observation into tractable inference
algorithms. The standard Bethe approximation instead
minimizes an approximation of the true entropy (Bethe,
1935). It was show by Yedidia et al. (2003) that ﬁxed
points of the loopy belief propagation correspond to its
stationary points, but still the optimization problem
resulting from this approximation is non-convex and
convergence is not always guaranteed.

To alleviate convergence issues, much work has con-
sidered convexifying the free energy problem leading
to classes of convergent convex belief propagation of-
ten derived directly from convex regularizers (Hazan
and Shashua, 2008; Heskes, 2006; Johnson and Willsky,
2008; Meshi et al., 2009; Savchynskyy et al., 2012). For
instance, Weiss et al. (2007) proposed a general con-
vexiﬁed belief propagation and explored some suﬃcient
conditions that enable heuristically recovering the MAP
solution of the LP via a convex sum-product variant.
However, the approximation error was still unclear and
non-asymptotic convergence rates were not considered.
A number of algorithms have also been proposed to
directly optimize the unregularized LP relaxation often
with only asymptotic convergence guarantees such as
block-coordinate methods (Globerson and Jaakkola,
2008; Kappes et al., 2013; Kovalevsky and Koval, 1975;
Tourani et al., 2018; Werner, 2007) and tree-reweighted
message passing (Kolmogorov, 2006; Wainwright et al.,
2005). The relationship between the regularized and
unregularized problems can equivalently be viewed as
applying a soft-max to the dual objective typically
considered in the latter to recover that of the former
(Nesterov, 2005; Sontag et al., 2011). Many other con-
vergent methods exist such as augmented Lagrangian
(Martins et al., 2011; Meshi and Globerson, 2011), bun-
dle (Kappes et al., 2012), and steepest descent (Schwing
et al., 2012, 2014) approaches, but again they are diﬃ-
cult to compare without rates.

Most closely related to our work is recent work in
convergence analysis of certain smoothed message pass-
ing algorithms that aim to solve the regularized LP
objective. Savchynskyy et al. (2011) proposed an accel-
erated gradient method that achieves O(1/(cid:15)) conver-
gence to the optimal regularized dual objective value.
Convergence of the primal iterates was only shown
asymptotically. Meshi et al. (2012) considered a gen-
eral dual coordinate minimization algorithm based on
the entropy-regularized MAP objective. They proved
upper bounds on the rate of convergence to the optimal
regularized dual objective value; however, closeness to
the true MAP assignment was not formally character-
ized. Furthermore, convergence in the dual objective
value again does not make it easy to determine when
the true MAP assignment can be recovered. Meshi
et al. (2015) later studied the beneﬁts of adding a
quadratic term to the LP objective instead and proved
similar guarantees. Ravikumar et al. (2010) also con-
sidered entropic and quadratic regularization, using a
proximal minimization scheme with inner and outer
loops. They additionally provided rounding guarantees
to recover true primal solutions. However, as noted by
the authors, the inexact calculation of the inner loop
prevents a convergence rate analysis once combined
with the outer loop. Additionally, rates on the inner

Jonathan N. Lee∗, Aldo Pacchiano∗, Michael I. Jordan

loop convergence were not addressed.

The approach of this paper can be understood as
the bridging the gap between Meshi et al. (2012)
and Ravikumar et al. (2010). Our ﬁrst contribution
is a characterization of the approximation error of
the entropy-regularized MAP inference problem. We
then study an edge-based message passing algorithm
that solves the regularized LP, which is essentially a
smoothed max-sum diﬀusion (Werner, 2007) or the
inner loop of the proximal steps of Ravikumar et al.
(2010). For our main contribution, we provide non-
asymptotic guarantees to the integral MAP assignment
for this message passing algorithm when the LP is tight
and the solution is unique. To our knowledge, this is
the ﬁrst analysis with rates guaranteeing recovery of
the true MAP assignment for smooth methods.

3 BACKGROUND

+

+ : (cid:80)

def.= (cid:8)p ∈ Rd

We denote the d-dimensional probability simplex as
i pi = 1(cid:9). The set of joint dis-
Σd
tributions which give rise to p, q ∈ Σd is deﬁned
as Ud(p, q) def.= (cid:8)P ∈ Rd×d
: P 1 = p, P (cid:62)1 = q(cid:9) . For
any two vectors or matrices p and q having the same
number of elements, we use (cid:104)p, q(cid:105) to denote the dot
product, i.e.
elementwise multiplication then sum
over all elements. We use (cid:107)p(cid:107)1 to denote the sum
of absolute values of the elements of p. The Breg-
man divergence between p, q ∈ Rd
+ with respect to a
+ (cid:55)→ R is DΦ(p, q) def.=
strictly convex function Φ : Rd
Φ(p) − Φ(q) − (cid:104)∇Φ(q), p − q(cid:105). We will consider the Breg-
man divergence with respect to the negative entropy
Φ(p) = −H(p) def.= (cid:80)
i pi(log pi − 1), where p need not
be a distribution. When p is a distribution, this corre-
sponds to the Kullback-Leibler (KL) divergence. The
Bregman projection with respect to Φ of q ∈ Rd
+ onto
the set X is deﬁned as PX (q) def.= arg minp∈X DΦ(p, q).
The Hellinger distance between p, q ∈ Σn is deﬁned
√
as h(p, q) def.= 1√
q(cid:107)2, where (cid:107) · (cid:107)2 is the l2-
2
norm. We denote the square of the Hellinger distance
by h2(p, q). We will often deal with marginal vectors
which are ordered collections of joint and marginal
distributions in the form of matrices and vectors, re-
spectively.

√
(cid:107)

p −

3.1 Pairwise Models

For a set of vertices, V = {1, . . . , n}, and edges
E, a pairwise graphical model, G def.= {V, E},
is a
Markov random ﬁeld that represents the joint dis-
def.= (Xi)i∈V , taking on
tribution of variables XV
values from the set of states χ = {0, . . . , d − 1}.
We assume that each vertex has at least one edge.

For pairwise models, the joint distribution can be
written as a function of doubletons and singletons:
i∈V θi(xi) + (cid:80)
pθ(xV ) ∝ exp
. We
wish to ﬁnd maximum a posteriori (MAP) estimates of
this model. That is, we consider the integer program:

(cid:17)
ij∈E θij(xi, xj)

(cid:16)(cid:80)

maxxV ∈χn (cid:80)

i∈V θi(xi) + (cid:80)

ij∈E θij(xi, xj).

(Int)

The maximization in (Int) can be written as a linear
program by deﬁning a marginal vector µ over variable
vertices {µi}i∈V and variable edges {µij}ij∈E . The
vector µi ∈ Rd
+ represents the marginal distribution
probabilities on vertex i while the matrix µij ∈ Rd×d
represents the joint distribution probabilities shared
between vertices i and j. We follow the notation of
Globerson and Jaakkola (2008) and denote indexing
into the vector and matrix variables with parentheses,
e.g. µij(xi, xj) for xi, xj ∈ χ. The set of marginal
vectors that are valid probability distributions is known
as the marginal polytope and is deﬁned as
PXi (xi) = µi(xi), ∀i, xi
PXi,Xj (xi, xj) = µij(xi, xj),

µ : ∃ P,

M def.=

(1)

(cid:41)

(cid:40)

+

∀ij, xi, xj

We can think of M as the set of mean parameters of
the model for which there exists a globally consistent
distribution P. We abuse notation slightly and dually
view θ as a potential “vector.” The edge matrix θij ∈
Rd×d is indexed as θij(xi, xj), indicating the element
at the xith row and xjth column. The vertex vector θi
is indexed as θi(xi), indicating the xith element. The
MAP problem in (Int) can be shown to be equivalent
to the following LP (Wainwright and Jordan, 2008):

max (cid:104)θ, µ(cid:105)

µ ∈ M
(cid:80)
θij(xi, xj)µij(xi, xj).

s.t.
(cid:80)

i∈V

=

xi

where
(cid:80)

ij∈E

(cid:80)

(cid:104)θ, µ(cid:105)

xi,xj

θi(xi)µi(xi) +

3.2 Sherali-Adams Relaxations

The number of constraints in M is unfortunately super-
polynomial (Sontag, 2010). This motivates considering
relaxations of the marginal polytope to outer polytopes
that involve fewer constraints. For example, the local
outer polytope is obtained by enforcing consistency only
on edges and vertices:

(cid:26)

L2

def.=

µ ≥ 0 :

µi ∈ Σd
∀i ∈ V
µij ∈ Ud(µi, µj) ∀ij ∈ E

(cid:27)

(2)

Relaxations of higher orders have also been studied, in
particular by Sherali and Adams (1990) who introduced
a hierarchy of polytopes by enforcing consistency on
joint distributions of increasing order up to n: L2 ⊇
L3 ⊇ . . . ⊇ Ln ≡ M. The corresponding Sherali-
Adams LP relaxation of order m is then

max (cid:104)θ, µ(cid:105)

s.t.

µ ∈ Lm,

(LP)

Convergence Rates of Smooth Message Passing with Rounding

where 1 ≤ m ≤ n. Because Lm is an outer polytope
of M, we no longer have that the solution to (LP)
recovers the true MAP solution of (Int) in general.
However if the solution to (LP) is integral, then xi =
arg maxx µi(x) recovers the optimal solution of the true
MAP problem. In this case, we say Lm is tight.

4 ENTROPY-REGULARIZED MAP

In this section, we present our ﬁrst main technical
contribution, characterizing the approximation error
in the entropy-regularized MAP problem for Sherali-
Adams relaxations. In contrast to solving the exact
(LP), we aim to solve the entropy-regularized LP:

min (cid:104)C, µ(cid:105) −

1
η

H(µ)

s.t.

µ ∈ Lm,

(Reg)

where C def.= −θ and H(µ) = (cid:104)µ, − log µ + 1(cid:105). The
hyperparameter η adjusts the level of regularization.
Denote by µ∗
η the solution of (Reg) where we omit the
reference to m to alleviate notation. In addition to
their extensive history in inference problems, entropy-
regularized LPs have arisen in a number of other ﬁelds
to aid optimization when standard LP solvers are insuf-
ﬁcient. For example, recent work in optimal transport
has relied on entropy regularization to derive alternat-
ing projection algorithms (Benamou et al., 2015; Cuturi,
2013) which admit almost linear time convergence guar-
antees in the size of the cost matrix (Altschuler et al.,
2017). Some of our theoretical results draw inspiration
from these works.

4.1 Approximation Error

When Lm is tight and the solution is unique, we show
that approximate solutions from solving (Reg) are not
necessarily detrimental because we can apply standard
vertex rounding schemes to yield consistent integral
solutions. It was shown by Cominetti and San Mart´ın
(1994), and later reﬁned by Weed (2018), that the ap-
proximation error of general entropy-regularized linear
programs converges to zero at an exponential rate in
η. Furthermore, it is possible to determine how large
η should be chosen in order for rounding to exactly
recover the optimal solution to (Int). The result is
summarized in the following extension of Theorem 1 of
Weed (2018)1.

Theorem 1. Let R1 = maxµ∈Lm (cid:107)µ(cid:107)1, RH =
maxµ,µ(cid:48)∈Lm H(µ) − H(µ(cid:48)), Vm be the set of vertices
of Lm, and V ∗
m ⊆ Vm the set of optimal vertices with
respect to C. Let ∆ = minV1∈Vm\V ∗
(cid:104)C, V1(cid:105) −

m,V2∈V ∗
m

(cid:104)C, V2(cid:105) be the smallest gap in objective value be-
tween an optimal vertex and any suboptimal vertex
of Lm.
Suppose Lm is tight and |V ∗
If
η ≥ 2R1 log 64R1+2R1+2RH
, the following rounded solu-
tion is a MAP assignment:

m| = 1.

∆

(cid:0)round(µ∗

η)(cid:1)

i

:= arg max

x∈χ

(µ∗

η)i(x)

m,V2∈ (cid:101)V ∗
m

Proof. Deﬁne (cid:101)C = C + 1 1
η , where 1 denotes an all-ones
vector with the same dimensions as C. If η ≥ 4R1
∆ then
m, the set of optimal vertices of Lm with respect to (cid:101)C,
(cid:101)V ∗
m = V ∗
satisﬁes (cid:101)V ∗
m and minV1∈Vm\ (cid:101)V ∗
(cid:104)C, V1(cid:105) −
(cid:104)C, V2(cid:105) ≥ ∆
If V ∈ (cid:101)V ∗
m; and V (cid:48) ∈ Vm\(cid:101)V ∗
m, then
2 .
(cid:104) (cid:101)C, V (cid:48)(cid:105) − (cid:104) (cid:101)C, V (cid:105) ≥ ∆ − 1
η (cid:107)V (cid:48) − V (cid:107)1 ≥ ∆
2 . Let (cid:101)∆ =
∆
, and |(cid:101)V ∗
m| = 1 then
2 .
32 . And therefore, by
2R1 exp
η(cid:107)1 ≤ 1
(cid:107)µ − µ∗
Corollary 9 of Weed (2018) minµ∈V ∗
32 .
Since Lm is assumed to be tight and (cid:101)V ∗
m = V ∗
m contains
a single integral vertex µ∗, the last equation implies
round(µ∗

If η ≥ R1 log 64R1+R1+RH

+ R1+RH
R1

−η (cid:101)∆
R1

≤ 1

(cid:17)

(cid:16)

(cid:101)∆

m

η) = µ∗.

(cid:0)n
j

(cid:1)dj and RH ≤

j=1

j=1

(cid:0)n
j

Consequently, since R1 ≤ (cid:80)m
(cid:1) log(dj)2, we have:
(cid:80)m
Corollary 1. If Lm is tight, |V ∗
log(8mnmdm)+2mnmdm
∆
is a MAP assignment.

m| = 1, and η ≥
, the rounded solution round(µ∗
η)

In general the dependence of ∆ on η suggested by The-
orem 1 is not improvable (Weed, 2018). Nevertheless,
when m = 2 and d = 2, since all vertices in V2 have
entries equal to either 0, 1
2 or 1—see Padberg (1989)
or Theorem 3 of Weller et al. (2016)—if the entries
of C are all integral, we have ∆ ≥ 1
2 , thus yielding a
more concrete guarantee. The disadvantage of choos-
ing exorbitantly large η is that eﬃcient computation
of solutions often becomes more diﬃcult in practice
(Altschuler et al., 2017; Benamou et al., 2015; Weed,
2018). Thus, in practice, there exists a trade-oﬀ be-
tween computation time and approximation error that
is controlled by η. We will provide a precise theoretical
characterization of the trade-oﬀ in Section 6. In our
guarantees, multiplying C by a constant a (and there-
fore multiplying ∆ by a) is equivalent to multiplying η
by the same value.

4.2 Equivalent Bregman Projection

The objective (Reg) can be interpreted as a Bregman
projection. This interpretation has been explored by

1The entropy is deﬁned without the linear oﬀset in Weed

2For m = 2 we can get tighter bounds corresponding to

(2018).

the number of edges in the graph G.

Jonathan N. Lee∗, Aldo Pacchiano∗, Michael I. Jordan

Ravikumar et al. (2010) as a basis for proximal up-
dates and also Benamou et al. (2015) for the optimal
transport problem. The objective is equivalent to

min DΦ (µ, exp(−ηC))

s.t.

µ ∈ Lm,

(Proj)

where Φ := −H. The derivation, based on a mirror
descent step can be found in the appendix. The pro-
jection, however, cannot be computed in closed form
in general due to the complex geometry of Lm.

Ravikumar et al. (2010) proposed using the Bregman
method (Bregman, 1966), which has been applied in
many ﬁelds to solve diﬃcult constrained problems (Be-
namou et al., 2015; Goldstein and Osher, 2009; Osher
et al., 2005, 2010), to compute PLm(exp(−ηC)) for
the inner loop calculation of their proximal algorithm.
While the outer loop proximal algorithm can be shown
to converge at least linearly, the inner loop rate was
not analyzed and the constants (possibly dependent
on dimension) were not made clear. Furthermore, the
Bregman method is in general inexact, which makes
the approximation and the eﬀect on the outer loop
unclear (Liu and Ihler, 2013).

5 SMOOTH MESSAGE PASSING

We are interested in analyzing a class of algorithms
closely inspired by max-sum diﬀusion (MSD) as pre-
sented by Werner (2007) and the proximal updates of
Ravikumar et al. (2010) to solve (Proj) over the L2
polytope. We describe it in detail here, with a few
minor modiﬁcations and variations to facilitate theo-
retical analysis. In L2, the constraints occur only over
edges between vertices3. Given an edge ij ∈ E, we
must enforce the constraints prescribed by (2), which
is the intersection of the following sets:

(a) Xij→i = {µ : µij1 = µi}
(b) Xij,i = {µ : µ(cid:62)
i
1 = µj}
(c) Xij→j = {µ : µ(cid:62)
ij
1 = 1, 1(cid:62)µij1 = 1}.
(d) Xij,j = {µ : µ(cid:62)
j

1 = 1, 1(cid:62)µij1 = 1}

The normalization of the joint distribution µij in (b)
and (d) is actually a redundant constraint, but it fa-
cilitates analysis as we demonstrate in Section 6. For
each of these aﬃne constraints, we can compute the
Bregman projections in closed form with simple multi-
plicative updates.

Proposition 1. For a given edge ij ∈ E, the closed-
form solutions of the Bregman projections for each of
the above individual constraints are given below.

Algorithm 1 EMP-cyclic (C, η, (cid:15))
1: µ ← Normalize(exp(−ηC))
2: k ← 1

3: while maxij

(cid:40)

max{(cid:107)µ(k)
ij
(cid:107)(µ(k)

ij )(cid:62)1 − µ(k)

i (cid:107)1,

1 − µ(k)
j (cid:107)1}

(cid:41)

≥ (cid:15) do

µ ← (PXij,j ◦ PXij→j ◦ PXij,i ◦ PXij→i)(µ)

µ ← µ(k)
for ij ∈ E do

4:
5:
6:
7:
8:
9:
10: end while
11: return round(µ(k))

end for
µ(k+1) ← µ
k ← k + 1

Figure 1: The EMP-cyclic algorithm (Ravikumar et al.,
2010) projects on all edges in order until the constraints
are satisﬁed up to (cid:15) in l1 distance. The operator ◦ denotes
the composition of the projection operations.

(a) Left consistency: If µ(cid:48) = PXij→i(µ), then for all

xi, xj ∈ χ, µ(cid:48)

ij(xi, xj) ← µij(xi, xj)

and µ(cid:48)

i(xi) ← µi(xi)

(cid:113) (cid:80)

x µij (xi,x)
µi(xi)

.

(cid:113) µi(xi)

(cid:80)

x µij (xi,x)

(b) Left normalization:
for all xi ∈ χ, µ(cid:48)
µij
µij (xi,xj ) .

(cid:80)

xi,xj

If µ(cid:48) = PXij,i(µ),
x µi(x) and µ(cid:48)

µi

(cid:80)

i ←

then
ij ←

(c) Right consistency: If µ(cid:48) = PXij→j (µ), then for all

xi, xj ∈ χ, µ(cid:48)

and µ(cid:48)

j(xj) ← µj(xj)

ij(xi, xj) ← µij(xi, xj)
(cid:113) (cid:80)
x µij (x,xj )
µj (xj )

.

(cid:113) µj (xj )

(cid:80)

x µij (x,xj )

(d) Right normalization:
for all xj ∈ χ, µ(cid:48)
µij
µij (xi,xj ) .

(cid:80)

xi,xj

If µ(cid:48) = PXij,j (µ), then
x µj (x) and µ(cid:48)
ij ←

µj

(cid:80)

j ←

These update rules are similar to a number of algo-
rithms throughout the literature on LP relaxations.
Notably, they can be viewed as a smoothed version of
MSD (Kovalevsky and Koval, 1975; Werner, 2007) in
that the updates enforce agreement between variables
on the edges and vertices. Nearly identical smoothed
updates were also initially proposed by Ravikumar et al.
(2010). As in MSD, it is common for message passing
schemes derived from LP relaxations to operate on dual
objective instead. We presented the primal view here
as the Bregman projections lend semantic meaning to
the updates and ultimately the stopping conditions in
the algorithms. An equivalent dual view is presented
in Appendix C.1.

3Written explicitly, the constraints actually occur be-
tween any pair of vertices, but these variables play no role
in the objective or constraints.

Based on these update rules, we formally outline the
algorithms we wish to analyze, which we call edge-
based message passing (EMP) for convenience. We

Convergence Rates of Smooth Message Passing with Rounding

Algorithm 2 EMP-greedy (C, η, (cid:15))
1: µ ← Normalize(exp(−ηC))
2: k ← 1

3: while maxij

(cid:40)

max{(cid:107)µ(k)
ij
(cid:107)(µ(k)

ij )(cid:62)1 − µ(k)

i (cid:107)1,

1 − µ(k)
j (cid:107)1}

(cid:41)

≥ (cid:15) do

4:

5:

ij ← GreedyEdge(µ(k))
i (cid:107)1 > (cid:107)(µ(k)
1 − µ(k)
if (cid:107)µ(k)
ij

ij )(cid:62)1 − µ(k)

j (cid:107)1 then

µ(k+1) ← (PXij,i ◦ PXij→i)(µ(k))

µ(k+1) ← (PXij,j ◦ PXij→j )(µ(k))

else

6:
7:
8:
9:
10:
11: end while
12: return round(µ(k))

end if
k ← k + 1

Figure 2: The EMP-greedy algorithm selects the edge and
direction with the greatest constraint violation and projects
until all constraints are satisﬁed up to (cid:15) in l1 distance.

consider two variants: EMP-cyclic (Algorithmic 1),
which cyclically applies the updates to each edge in
each iteration and EMP-greedy (Algorithmic 2), which
applies a single projection update to only the edge with
the greatest constraint violation in each iteration. We
emphasize that these algorithms are not fundamentally
new, but our analysis in the next section is our main
contribution. EMP-cyclic is the Bregman method,
almost exactly the inner loop proposed by Ravikumar
et al. (2010). In both variants, µ(1) is deﬁned as the
normalized value of exp(−ηC). The GreedyEdge
operation in EMP-greedy is deﬁned as

GreedyEdge(µ) = arg max

ij∈E

(cid:26) max{(cid:107)µ(k)
(cid:107)(µ(k)

ij

i (cid:107)1,

1 − µ(k)
j (cid:107)1}

ij )(cid:62)1 − µ(k)

(cid:27)

These procedures are then repeated again until the
stopping criterion is met, which is that µ(k) is (cid:15)-close
to satisfying the constraint that the joint distributions
sum to the marginals for all edges. Both algorithms also
conclude with a rounding operation. Any ﬁxed point of
EMP must correspond to an optimal µ∗
η (see details in
appendix). Computationally, EMP-greedy requires a
search over the edges to identify the greatest constraint
violation, which can be eﬃciently implemented using a
max-heap (Nutini et al., 2015).

6 THEORETICAL ANALYSIS

We now present our main contribution, a theoretical
analysis of EMP-cyclic and EMP-greedy. This result
combines two aspects. First, we present a convergence
guarantee on the number of iterations suﬃcient to
solve (Proj), satisfying the L2 constraints with (cid:15) > 0
error in l1 distance. We note that, in ﬁnite iterations,
the pseudo-marginals of EMP are not primal feasible

in general due to this (cid:15)-error. We then combine this
result with our guarantee on the approximation error in
Theorem 1 to show a bound on the number of iterations
suﬃcient to recover the true integral MAP assignment
by rounding, assuming the LP is tight and the solution
is unique. This holds with suﬃcient iterations and a
suﬃciently large regularization constant even though
the pseudo-marginals may not be primal feasible. We
emphasize that these theorems are a departure from
usual convergence rates in the literature (Meshi et al.,
2012, 2015). Prior work has guaranteed convergence
in objective value to the optimum of the regularized
objective (Proj), making it unclear whether the optimal
MAP assignment can be recovered, e.g. by rounding.
We address this ambiguity in our results.

We begin with the upper bound iterations to obtain
(cid:15)-close solutions, which is the result of two facts which
we show. The ﬁrst is that the updates in Proposition 1
monotonically improve a Lyapunov (potential) function
by an amount proportional to the constraint violation
as measured via the Hellinger distance. The second
is that the diﬀerence between the initial and optimal
values of the Lyapunov function is bounded.

Let deg(G) denote the maximum degree of graph G and
deﬁne:



S def.=

(cid:88)

log

(cid:88)

e−ηCij (xi,xj ) +

ij∈E
(cid:34)

(cid:88)

log

+

i∈V

xi,xj ∈χ

e−ηCi(x) +

(cid:88)

x∈χ

(cid:88)

x∈χ

η
d

Ci(x)

.

η
d2 Cij(xi, xj)





(cid:88)

xi,xj ∈χ

(cid:35)

Theorem 2. For any (cid:15) > 0, EMP is guaranteed to
satisfy (cid:107)µij1 − µi(cid:107)1 < (cid:15) and (cid:107)µ(cid:62)
1 − µj(cid:107)1 < (cid:15) for all
ij
ij ∈ E in (cid:100) 4S0(deg(G)+1)
(cid:101) iterations for EMP-cyclic and
(cid:100) 4S0

(cid:15)2
(cid:15)2 (cid:101) iterations for EMP-greedy.

Here, S0 = min((cid:107)ηC/d + exp(−ηC)(cid:107)1, S). In this the-
orem, we give our guarantee in terms of l1 distance
rather than function value convergence. As we will
see, this is signiﬁcant, allowing us to relate this result
to Theorem 1 in order to derive the main result. The
proof is similar in style to Altschuler et al. (2017). We
leave the full proof for EMP-cyclic for the appendix
due to a need to handle tedious edge cases, but we state
several intermediate results and sketch the proof for
EMP-greedy for intuition as it reveals possibly how sim-
ilar message passing algorithms can be analyzed. We
ﬁrst introduce a Lyapunov function written in terms of
dual variables (λ, ξ), indexed by the edges and vertices
to which they belong in L2. We denote the iteration-
indexed dual variables as (λ(k), ξ(k)). For a given edge
ij ∈ E, constraints enforcing row and column consis-
tency correspond to λij, λji ∈ Rm, respectively. Nor-
malizing constraints correspond to ξi, ξj, ξij ∈ R. The
Lyapunov function, L(λ, ξ), is shown in Figure 3.

Jonathan N. Lee∗, Aldo Pacchiano∗, Michael I. Jordan

L(λ, ξ) = − (cid:80)

ij∈E

(cid:80)

xi,xj ∈χ exp (−ηCij(xi, xj) − λij(xi) − λji(xj) − ξij)

(cid:16)

− (cid:80)
− (cid:80)

(cid:80)

i∈V

x∈χ exp
ij∈E ξij − (cid:80)

−ηCi(x) − ξi + (cid:80)

j∈Nr(i) λij(x) + (cid:80)

(3)

i∈V ξi + (cid:80)

ij∈E

(cid:80)

xi,xj ∈χ exp(−ηCij(xi, xj)) + (cid:80)

i

x∈χ exp(−ηCi(x))

(cid:17)
j∈Nc(i) λji(x)
(cid:80)

Figure 3: The proposed Lyapunov function. Nr(i) denotes the set of neighboring vertices of i where row consistency is
enforced. Nc(i) is the same for column consistency. The Lyapunov function L can be derived from the dual objective
of (Proj). A full derivation is provided in the appendix.

We note that maximizing L over (λ, ξ) satisﬁes all
constraints and yields the solution to (Proj) by ﬁrst-
order optimality conditions. We now present a result
that establishes the monotone improvement in L due
to the updates in Proposition 1.
Lemma 1. For a given edge ij ∈ E, let µ(cid:48) and (λ(cid:48), ξ(cid:48))
denote the updated primal and dual variables after a
projection from one of (a)–(d) in Proposition 1. We
have the following improvements on L. If µ(cid:48) is equal
to:
(a) PXij→i (µ), then L(λ(cid:48), ξ(cid:48)) − L(λ, ξ) = 2h2(µij1, µi)
(b) PXij,i (µ), then L(λ(cid:48), ξ(cid:48)) − L(λ, ξ) ≥ 0

ij1, µj)

(c) PXij→j (µ), then L(λ(cid:48), ξ(cid:48)) − L(λ, ξ) = 2h2(µ(cid:62)
(d) PXij,j (µ), then L(λ(cid:48), ξ(cid:48)) − L(λ, ξ) ≥ 0.
This result shows that L improves monotonically after
each of the four updates in Proposition 1. Furthermore,
at every update, L improves by twice the squared
Hellinger distance of the constraint violation between
the joint and the marginals.
Lemma 2. Let λ∗, ξ∗ denote the maximizers of L.
The diﬀerence in function value between the optimal
value of L and the ﬁrst iteration value is upper bounded
L(λ∗, ξ∗) − L(λ(1), ξ(1)) ≤ S0.

Turning to Theorem 2, the result is obtained by observ-
ing that as long as the constraints are violated by an
amount (cid:15) > 0 (i.e., the algorithm has not terminated),
then the Lyapunov function must improve by a known
positive amount at each iteration. We provide a proof
sketch for EMP-greedy.

Proof Sketch of Theorem 2 for EMP-greedy. We now
show how to combine the results of Lemma 1 and
Lemma 2 to obtain Theorem 2. Let k∗ be the ﬁrst iter-
ation such that the termination condition in Algorithm
2 holds with respect to some (cid:15) > 0. Then, for any k
satisfying 1 ≤ k < k∗, we have that GreedyEdge(µ)
selects ij such that either (cid:107)µij1 − µi(cid:107)1 ≥ (cid:15) or
(cid:107)µ(cid:62)
ij
Without loss of generality, suppose (cid:107)µij1 − µi(cid:107)1 ≥
(cid:107)µ(cid:62)
ij

1 − µj(cid:107)1. Therefore, we have

1 − µj(cid:107)1 ≥ (cid:15).

(cid:15)2
4

≤

1
4

(cid:107)µij1 − µi(cid:107)2

1 ≤ 2h2(µij1, µi),

where again h2(µij1, µi) denotes the squared Hellinger
distance and the last inequality is the Hellinger in-
equality. Since µij and µi are normalized for each
iteration, this inequality is valid. Thus, L improves
by 2h2(µij1, µi) when PXij→i occurs and by a non-
negative amount when PXij,i occurs by Lemma 1.
Therefore, we can guarantee improvement of at least (cid:15)2
4
each iteration. Since the optimality gap is at most S0
by Lemma 2, this means the algorithm must terminate
in (cid:100) 4S0

(cid:15)2 (cid:101) iterations.

We now turn to our main theoretical result. We com-
bine our approximation and iteration convergence guar-
antees to fully characterize the convergence of EMP for
L2 to the optimal MAP assignment when the relaxation
is tight and the solution is unique.
Theorem 3. Let η ≥ 2 log(16n2d2)+16|E|d2
, and (cid:15)−1 >
(25d deg(G)|E|)2 max (η(cid:107)C(cid:107)∞, 68). If L2 is tight and
|V ∗
2 | = 1, the EMP algorithm returns a MAP assign-
ment after (cid:100) 4S0(deg(G)+1)
(cid:101) iterations for EMP-cyclic
and after (cid:100) 4S0

(cid:15)2 (cid:101) iterations for EMP-greedy.

min(∆, 1

128 )

(cid:15)2

When C is integral, ∆ ≥ 1
2 , yielding a bound of all
known parameters. The main technical challenge in
producing this result is to relate the termination con-
dition of EMP to the l1 distance between µ(k) and
µ∗ (the MAP assignment), as this may lie outside
the polytope L2. It does not suﬃce to provide con-
vergence guarantees in function value as the goal of
MAP inference is to produce integral assignments. The
proof proceeds in two steps. First we show that µ(k)
is the entropy-regularized solution to objective C over
a “slack” polytope Lν(k)
. Where the slack vector ν(k)
corresponds to the constraint violations of µ(k). We use
this characterization to “project” µ(k) onto a nearby
L2 feasible point µ(k)(2). Second, we can use the prop-
erties of the primal objective to bound µ(k)(2) and µ∗
η.
The proof is in the appendix.

2

7 NUMERICAL EXPERIMENTS

We illustrate our theoretical results in a practical appli-
cation of the EMP algorithms. Ravikumar et al. (2010)
already gave empirical evidence that the basic EMP-

Convergence Rates of Smooth Message Passing with Rounding

Figure 5: On grids of size n = 2500, convergence rates to
the optimal MAP assignment of greedy and cyclic variants
are shown. The lines on each plot indicate choices of η.

Figure 6: The algorithm variants on Erd˝os-R´enyi random
graphs with n = 400, η = 700.0, and maximum degrees
deg(G) = 5, 10. The higher degree graphs (red and blue)
take longer to converge to the optimal MAP assignment.

illustrates the distance of the rounded solution to the
optimal MAP solution over projection steps on grids
of size n = 2500. EMP-greedy converges sharply and
varying regularization has less of an eﬀect on its conver-
gence rate. Finally, in Figure 6, we look at Erd˝os-R´enyi
random graphs to observe the eﬀect of the graph struc-
ture for both variants. We considered degree-limited
random graphs with deg(G) = 5 and deg(G) = 10.
The ﬁgure shows convergence over projection steps
for graphs of size n = 400. For both variants, the
convergence rate deteriorates for higher degrees.

8 CONCLUSION

Figure 4: A box-plot showing the eﬀect of graph size (x-axis)
and regularization on the quality of rounded solutions for
both algorithm variants after 80 iterations. Thick horizontal
bars indicate the median over 20 trials each. For large η
(cyan and purple), the true MAP is almost always recovered.

cyclic is competitive with standard solvers. Therefore,
the objective of these experiments is to understand
how graph and algorithm properties aﬀect approxima-
tion (Theorem 1) and convergence (Theorem 2). We
consider the family of multi-label Potts models (Wain-
wright et al., 2005) with d = 3 labels on L2. For each
trial, the cost vector is Ci(xi) = αi(xi), ∀i, xi and

Cij(xi, xj) =

(cid:40)

βij xi = xj
0

otherwise

∀ij, xi, xj

√

√

n ×

the parameters are

where
random αi(xi) ∼
Unif(−0.5, 0.5) and βij ∼ Unif{−0.1, 0.1}. The graphs
n grids (Erdogdu
considered are structured as
et al., 2017; Globerson and Jaakkola, 2008; Ravikumar
et al., 2010) and as Erd˝os-R´enyi random graphs with
edge probability p = 1.1 log n
. To evaluate recovery
n
of the optimal MAP assignment, we ﬁrst solved each
graph with the ECOS LP solver (Domahidi et al., 2013)
and selected graphs that were tight. Solving the LP to
ﬁnd the ground-truth was the main computational bot-
tleneck. Further details can be found in Appendix E.

Approximation In Figure 4, we evaluate the eﬀect
of regularization and graph size on the quality of the
nearly converged solution from EMP for over 80 it-
erations on grids. The box-plots indicate that large
choices of η often yield the exact MAP solution (cyan
and purple). Moderate choices still yield competitive
solutions but not optimal for larger graphs (orange and
green). Low choices generally give poor solutions with
high spread for all graph sizes (red and blue).

Convergence We then investigate the eﬀects of reg-
ularization on convergence for both variants. Figure 5

In this paper, we investigated the approximation eﬀects
of entropy regularization on MAP inference objectives.
We combined these approximation guarantees with a
convergence analysis of an edge-based message passing
algorithm that solves the regularized objective to de-
rive guarantees on the number of iterations suﬃcient
to recover the true MAP assignment. We also showed
empirically the eﬀect of regularization and graph prop-
ertise on both the approximation and convergence. In
future work, we wish to extend the analyses and proof
techniques to higher order polytopes and general block-
coordinate minimization algorithms.

1004009002500Graph Size0.0000.0050.0100.0150.0200.0250.030Avg. Hamming Distance to OptimalRecovery of Integral MAP with varying  and nGreedy, =700.0Cyclic, =700.0Greedy, =300.0Cyclic, =300.0Greedy, =100.0Cyclic, =100.00100000200000300000400000Projection Steps0.0000.0050.0100.0150.0200.0250.030Avg. Hamming DistanceEMP-greedy n=2500=700.0=300.0=100.00100000200000300000400000Projection StepsEMP-cyclic n=2500=700.0=300.0=100.00300006000090000Projection Steps0.000.050.100.150.200.250.30Avg. Hamming DistanceGreedy, deg=5Cyclic, deg=5Greedy, deg=10Cyclic, deg=10Jonathan N. Lee∗, Aldo Pacchiano∗, Michael I. Jordan

Acknowledgements We thank the anonymous re-
viewers and Marco Pavone for their invaluable feed-
back.

References

Jason Altschuler, Jonathan Weed, and Philippe Rigol-
let. Near-linear time approximation algorithms for
optimal transport via Sinkhorn iteration.
In Ad-
vances in Neural Information Processing Systems,
pages 1964–1974, 2017.

Alessandro Antonucci, Cassio De Campos, and Marco
Zaﬀalon. Probabilistic graphical models. In Intro-
duction to Imprecise Probabilities. Wiley, 2014.

Jean-David Benamou, Guillaume Carlier, Marco Cu-
turi, Luca Nenna, and Gabriel Peyr´e. Iterative Breg-
man projections for regularized transportation prob-
lems. SIAM Journal on Scientiﬁc Computing, 37(2):
A1111–A1138, 2015.

Hans Bethe. Statistical theory of superlattices. Pro-
ceedings of the Royal Society of London. Series A-
Mathematical and Physical Sciences, 150(871):552–
575, 1935.

Lev M Bregman. A relaxation method of ﬁnding a
common point of convex sets and its application to
problems of optimization. In Soviet Mathematics
Doklady, volume 7, pages 1578–1581, 1966.

S´ebastien Bubeck. Convex optimization: Algorithms
and complexity. Foundations and Trends in Machine
Learning, 8(3-4):231–357, 2015.

Roberto Cominetti and Jaime San Mart´ın. Asymptotic
analysis of the exponential penalty trajectory in lin-
ear programming. Mathematical Programming, 67
(1-3):169–187, 1994.

Gregory Cooper. The computational complexity of
probabilistic inference using Bayesian belief networks.
Artiﬁcial Intelligence, 42(2-3):393–405, 1990.

Marco Cuturi. Sinkhorn distances: Lightspeed compu-
tation of optimal transport. In Advances in Neural
Information Processing Systems, pages 2292–2300,
2013.

Paul Dagum and Michael Luby. Approximating proba-
bilistic inference in Bayesian belief networks is NP-
hard. Artiﬁcial Intelligence, 60(1):141–153, 1993.

Michel Deza and Monique Laurent. Geometry of Cuts

and Metrics, volume 15. Springer, 2009.

Alexander Domahidi, Eric Chu, and Stephen Boyd.
ECOS: An SOCP solver for embedded systems. In
2013 European Control Conference (ECC), pages
3071–3076. IEEE, 2013.

Murat Erdogdu, Yash Deshpande, and Andrea Monta-
nari. Inference in graphical models via semideﬁnite

programming hierarchies. In Advances in Neural In-
formation Processing Systems, pages 417–425, 2017.

Amir Globerson and Tommi Jaakkola. Fixing max-
product: Convergent message passing algorithms for
MAP LP-relaxations. In Advances in Neural Infor-
mation Processing Systems, pages 553–560, 2008.

Tom Goldstein and Stanley Osher. The split Bregman
method for L1-regularized problems. SIAM journal
on Imaging Sciences, 2(2):323–343, 2009.

Peter L Hammer, Pierre Hansen, and Bruno Simeone.
Roof duality, complementation and persistency in
quadratic 0–1 optimization. Mathematical Program-
ming, 28(2):121–155, 1984.

Tamir Hazan and Amnon Shashua. Convergent
message-passing algorithms for inference over gen-
eral graphs with convex free energies. In Proceedings
of the Twenty-Fourth Conference on Uncertainty in
Artiﬁcial Intelligence, pages 264–273, 2008.

Tom Heskes. Convexity arguments for eﬃcient mini-
mization of the bethe and kikuchi free energies. Jour-
nal of Artiﬁcial Intelligence Research, 26:153–190,
2006.

Jason Johnson and Alan Willsky. Convex relaxation
methods for graphical models: Lagrangian and maxi-
mum entropy approaches. PhD thesis, Massachusetts
Institute of Technology, Department of Electrical
Engineering, 2008.

Joerg Kappes, Bjoern Andres, Fred Hamprecht,
Christoph Schnorr, Sebastian Nowozin, Dhruv Batra,
Sungwoong Kim, Bernhard Kausler, Jan Lellmann,
Nikos Komodakis, et al. A comparative study of
modern inference techniques for discrete energy min-
imization problems. In Proceedings of the IEEE con-
ference on computer vision and pattern recognition,
pages 1328–1335, 2013.

J¨org Hendrik Kappes, Bogdan Savchynskyy, and
Christoph Schn¨orr. A bundle approach to eﬃcient
map-inference by lagrangian relaxation.
In 2012
IEEE Conference on Computer Vision and Pattern
Recognition, pages 1688–1695. IEEE, 2012.

Vladimir Kolmogorov. Convergent tree-reweighted mes-
sage passing for energy minimization. IEEE trans-
actions on pattern analysis and machine intelligence,
28(10):1568–1583, 2006.

Vladimir Kolmogorov and Ramin Zabin. What energy
functions can be minimized via graph cuts? IEEE
Transactions on Pattern Analysis and Machine In-
telligence, 26(2):147–159, 2004.

VA Kovalevsky and VK Koval. A diﬀusion algorithm
for decreasing energy of max-sum labeling problem.
Glushkov Institute of Cybernetics, Kiev, USSR, 1975.

Convergence Rates of Smooth Message Passing with Rounding

Qiang Liu and Alexander Ihler. Variational algorithms
for marginal map. The Journal of Machine Learning
Research, 14(1):3165–3200, 2013.

Andr´e Martins, M´ario Figueiredo, Pedro Aguiar, Noah
Smith, and Eric Xing. An augmented Lagrangian
approach to constrained MAP inference. In Interna-
tional Conference on Machine Learning, volume 2,
page 2, 2011.

Ofer Meshi and Amir Globerson. An alternating di-
rection method for dual MAP LP relaxation.
In
Joint European Conference on Machine Learning and
Knowledge Discovery in Databases, pages 470–483.
Springer, 2011.

Ofer Meshi, Ariel Jaimovich, Amir Globerson, and
Nir Friedman. Convexifying the bethe free energy.
In Proceedings of the Twenty-Fifth Conference on
Uncertainty in Artiﬁcial Intelligence, pages 402–410.
AUAI Press, 2009.

Ofer Meshi, Amir Globerson, and Tommi S Jaakkola.
Convergence rate analysis of map coordinate mini-
mization algorithms. In Advances in Neural Infor-
mation Processing Systems, pages 3014–3022, 2012.

Ofer Meshi, Mehrdad Mahdavi, and Alex Schwing.
Smooth and strong: MAP inference with linear con-
vergence. In Advances in Neural Information Pro-
cessing Systems, pages 298–306, 2015.

Marc Mezard and Andrea Montanari. Information,
Physics, and Computation. Oxford University Press,
2009.

Arkadii Nemirovsky and David Yudin. Problem com-
plexity and method eﬃciency in optimization. 1983.

Yu Nesterov. Smooth minimization of non-smooth
functions. Mathematical programming, 103(1):127–
152, 2005.

Julie Nutini, Mark Schmidt, Issam Laradji, Michael
Friedlander, and Hoyt Koepke. Coordinate descent
converges faster with the gauss-southwell rule than
random selection. In International Conference on
Machine Learning, pages 1632–1641, 2015.

Stanley Osher, Martin Burger, Donald Goldfarb, Jinjun
Xu, and Wotao Yin. An iterative regularization
method for total variation-based image restoration.
Multiscale Modeling and Simulation, 4(2):460–489,
2005.

Stanley Osher, Yu Mao, Bin Dong, and Wotao Yin.
Fast linearized bregman iteration for compressive
sensing and sparse denoising. Communications in
Mathematical Sciences, 8(1):93–111, 2010.

Manfred Padberg. The Boolean quadric polytope: some
characteristics, facets and relatives. Mathematical
Programming, 45(1-3):139–172, 1989.

Pradeep Ravikumar, Alekh Agarwal, and Martin J
Wainwright. Message-passing for graph-structured
linear programs: Proximal methods and rounding
schemes. Journal of Machine Learning Research, 11
(Mar):1043–1080, 2010.

Bogdan Savchynskyy, J¨org Kappes, Stefan Schmidt,
and Christoph Schn¨orr. A study of nesterov’s scheme
for lagrangian decomposition and map labeling. In
CVPR 2011, pages 1817–1823. IEEE, 2011.

Bogdan Savchynskyy, Stefan Schmidt, J¨org Kappes,
and Christoph Schn¨orr. Eﬃcient mrf energy min-
imization via adaptive diminishing smoothing. In
Proceedings of the Twenty-Eighth Conference on Un-
certainty in Artiﬁcial Intelligence, pages 746–755,
2012.

Thomas Schiex, Helene Fargier, and Gerard Verfail-
lie. Valued constraint satisfaction problems: hard
and easy problems. In Proceedings of the 14th Inter-
national Joint Conference on Artiﬁcial Intelligence,
pages 631–637. Morgan Kaufmann Publishers Inc.,
1995.

Alex Schwing, Tamir Hazan, Marc Pollefeys, and
Raquel Urtasun. Globally convergent dual MAP
LP relaxation solvers using Fenchel-Young margins.
In Advances in Neural Information Processing Sys-
tems, pages 2384–2392, 2012.

Alexander Schwing, Tamir Hazan, Marc Pollefeys, and
Raquel Urtasun. Globally convergent parallel MAP
LP relaxation solver using the Frank-Wolfe algo-
rithm.
In International Conference on Machine
Learning, pages 487–495, 2014.

Hanif Sherali and Warren Adams. A hierarchy of re-
laxations between the continuous and convex hull
representations for zero-one programming problems.
SIAM Journal on Discrete Mathematics, 3(3):411–
430, 1990.

David Sontag, Amir Globerson, and Tommi Jaakkola.
Introduction to dual composition for inference. In
Optimization for Machine Learning. MIT Press, 2011.

David A. Sontag. Approximate inference in graphi-
cal models using LP relaxations. PhD thesis, Mas-
sachusetts Institute of Technology, 2010.

Siddharth Tourani, Alexander Shekhovtsov, Carsten
Rother, and Bogdan Savchynskyy. Mplp++: Fast,
parallel dual block-coordinate ascent for dense graph-
ical models. In Proceedings of the European Confer-
ence on Computer Vision (ECCV), pages 251–267,
2018.

Martin Wainwright and Michael Jordan. Graphical
models, exponential families, and variational infer-
ence. Foundations and Trends in Machine Learning,
1(1–2):1–305, 2008.

Jonathan N. Lee∗, Aldo Pacchiano∗, Michael I. Jordan

Martin J Wainwright, Tommi S Jaakkola, and Alan S
Willsky. Map estimation via agreement on trees:
message-passing and linear programming.
IEEE
transactions on information theory, 51(11):3697–
3717, 2005.

Jonathan Weed. An explicit analysis of the entropic
penalty in linear programming. In Conference On
Learning Theory, pages 1841–1855, 2018.

Yair Weiss, Chen Yanover, and Talya Meltzer. Map
estimation, linear programming and belief propaga-
tion with convex free energies. In Proceedings of the
Twenty-Third Conference on Uncertainty in Artiﬁ-
cial Intelligence, pages 416–425, 2007.

Adrian Weller, Mark Rowland, and David Sontag.
Tightness of LP relaxations for almost balanced mod-
els. In Artiﬁcial Intelligence and Statistics, pages
47–55, 2016.

Tomas Werner. A linear programming approach to
max-sum problem: A review. IEEE transactions
on pattern analysis and machine intelligence, 29(7):
1165–1179, 2007.

Chen Yanover, Talya Meltzer, and Yair Weiss. Linear
programming relaxations and belief propagation–an
empirical study. Journal of Machine Learning Re-
search, 7(Sep):1887–1907, 2006.

Jonathan Yedidia, William Freeman, and Yair Weiss.
Understanding belief propagation and its generaliza-
tions. Exploring Artiﬁcial Intelligence in the New
Millennium, 8:236–239, 2003.

Convergence Rates of Smooth Message Passing with Rounding

A Bregman Projection Derivation

The objective (Reg) can be equivalently interpreted as a Bregman projection. This interpretation has been
explored by Ravikumar et al. (2010) as a basis for proximal updates and also Benamou et al. (2015) for the optimal
transport problem. Here, we review the transformation because it is central to the algorithm of Ravikumar et al.
(2010), upon which our main theoretical results are based.

By deﬁnition of the Bregman projection with respect to the negative entropy, Φ = −H, we have

DΦ(µ, 1) =+ (cid:104)µ, log µ − 1(cid:105) − (cid:104)log 1, µ − 1(cid:105)

= −H(µ)

where 1 is a vector of ones of the same size as the marginal vector and =+ denotes the two sides are equal up to
a constant. Substituting this into (Reg) and multiplying through by η yields the objective:

min

η(cid:104)C, µ(cid:105) + DΦ (µ, 1)

s.t. µ ∈ Lm.

Note the similarity to a projected mirror descent update over Lm starting from 1 (Bubeck, 2015; Nemirovsky
and Yudin, 1983). Using this insight and performing a single gradient update in the dual, we can transform the
problem into a single Bregman projection of the vector. The unprojected marginal vector µ(cid:48) satisﬁes

∇Φ(µ(cid:48)) = ∇Φ(1) − ηC,

where ∇Φ(µ) = −∇H(µ) = log µ is the dual map and (∇Φ)−1(µ) = ∇Φ∗(µ) = exp(µ) is the inverse dual
map. We have µ(cid:48) = exp(−ηC) and the solution to the mirror descent update is PLm(exp(−ηC)). Therefore it is
suﬃcient to solve the following Bregman projection problem:

min DΦ (µ, exp(−ηC))

s.t.

µ ∈ Lm

The projection, however, cannot be computed in closed form due to the complex geometry of Lm. Sinkhorn-like
algorithms such as those used in Cuturi (2013) are unavailable because the transportation polytopes Ud(µi, µj)
are dependent on variables µi and µj which are also involved in the projection operation.

B Derivation of EMP Update Rules

We present the derivations of the update rules similar to Ravikumar et al. (2010) for a given edge ij ∈ E based
on the Bregman projections onto the individual constraint sets Xij→i, Xij,i, Xij→j, Xij,j. We refer the reader to
Ravikumar et al. (2010) for the original algorithm and derivation. We derive only the ﬁrst two projections; the
last two can be found by exchanging the indices.

(a) For the projection µ(cid:48) = PXij→i(µ), where

Xij→i = {µ : µij1 = µi},

there are no constraints on any edges or vertices other than ij and i. Therefore, ∀k (cid:54)= i, µ(cid:48)
∀k(cid:96) (cid:54)= ij, µ(cid:48)

k(cid:96) = µk(cid:96).

k = µk. Similarly,

The Lagrangian of the projection is given in terms of primal variables µ and dual variables α:

L(µ(cid:48), α) =

=

(cid:88)

xi,xj

(cid:88)

xi,xj

µ(cid:48)

ij(xi, xj)

µ(cid:48)

ij(xi, xj)

(cid:18)

(cid:18)

log

µ(cid:48)
ij(xi, xj)
µij(xi, xj)

(cid:19)

− 1

+

µ(cid:48)

i(xi)

(cid:88)

xi

(cid:18)

log

µ(cid:48)
i(xi)
µi(xi)

(cid:19)

− 1

+ α(cid:62) (cid:0)µ(cid:48)

ij

1 − µ(cid:48)
i

(cid:1)

log

µ(cid:48)
ij(xi, xj)
µij(xi, xj)

(cid:19)

− 1 + α(xi)

+

µ(cid:48)

i(xi)

(cid:88)

xi

(cid:18)

log

µ(cid:48)
i(xi)
µi(xi)

(cid:19)

− 1 − α(xi)

.

By the ﬁrst-order optimality condition, the primal solution in terms of the dual variables is

µ(cid:48)

ij(xi, xj) = µij(xi, xj)e−α(xi)
i(xi) = µi(xi)eα(xi).

µ(cid:48)

Jonathan N. Lee∗, Aldo Pacchiano∗, Michael I. Jordan

Substituting this solution back in to the Lagrangian, we have

L(α) = −

(cid:88)

xi,xj

µij(xi, xj)e−α(xi) −

µi(xi)eα(xi).

(cid:88)

xi

Again, by the ﬁrst-order optimality condition, the dual solution is

α∗(xi) =

(cid:80)

xj

1
2

log

µij(xi, xj)
µi(xi)

.

Substituting this value for α∗ into the primal solution yields the desired result.

(b) Again, for the projection onto

Xij,i = {µ : µ(cid:62)
i

1 = 1, 1(cid:62)µij1 = 1},

only µi and µij are aﬀected. Xij,i enforces that the variables µij and µi each sum to one. It is well known
and easy to show that the Bregman projection with respect to the negative entropy is simply the µij and µi
normalized by their sums. This normalization can also be written as a multiplicative update of the same
form by observing that

where ξ∗

ij = log (cid:80)

xi,xj

µij(xi, xj) and ξ∗

µi(xi). Again, these can be derived via the Lagrangian.

µ(cid:48)

ij(xi, xj) = µ(cid:48)
i(xi) = µ(cid:48)

ij(xi, xj)e−ξ∗
i(xi)e−ξ∗
i ,

ij

µ(cid:48)
i = log (cid:80)

xi

C Extensions of EMP

C.1 Dual EMP

We may also equivalently interpret the multiplicative updates in Algorithm 1 and Algorithm 2 as additive updates
of the dual variables. The dual interpretation is consistent with past work in dual MAP algorithms (Sontag et al.,
2011) and may be more practical to avoid numerical issues in implementation. Instead of tracking the primal
variables µ, we track a sum of the dual variables with ζ for each vertex and edge. Enforcing consistency between
a given joint distribution and its marginals in (a) yields updated dual variable sums

ij(xi, xj) ← ζij(xi, xj) − α∗(xi)
ζ (cid:48)

i(xi) ← ζi(xi) + α∗(xi),
ζ (cid:48)

where again α∗(xi) = 1
normalization step in (b) yields

2 log

xj

(cid:80)

µij (xi,xj )
µi(xi)

. The same is done for the vertex j in (c) with indices exchanged. The

ij = log (cid:80)
where ξ∗
vector is recovered with

xi,xj

ij(xi, xj) ← ζij(xi, xj) − ξ∗
ζ (cid:48)
ij
i = log (cid:80)

µij(xi, xj) and ξ∗

xi

i(xi, xj) ← ζi(xi) − ξ∗
ζ (cid:48)
i ,

µi(xi). Again, the same is done for (d). The primal marginal

We will later make explicit the dual formulation as it will aid in the theoretical analysis.

µ = exp(−ηC + ζ).

C.2 Clique Constraints

The version of EMP presented in the paper is for the L2 local polytope, which enforces only pairwise consistency
among the variables with edges, but this can be fairly easily extended. In this section, we discuss higher order
pseudo-marginals and their constraints. Consider the polytope that enforces consistency on all subsets of V of
size k and below, denoted by C. We use the notation of Meshi et al. (2012). The constraint set is written as

(cid:26)

LC

def.=

µ ≥ 0 :

µi ∈ Σm
µi(xi) = (cid:80)

xc\i

∀i ∈ V
µc ∀xi ∈ χ, i ∈ c, c ∈ C,

(cid:27)

.

(4)

Convergence Rates of Smooth Message Passing with Rounding

where xc\i denotes a marginalization over all variables except i. For convenience, we may also now account for
higher-order interactions in the model itself:

max

(cid:88)

(cid:88)

c∈C

xc∈χk

θc(xc)µc(xc) +

(cid:88)

(cid:88)

i∈V

xi∈χ

θi(xi)µi(xi)

s.t.

µ ∈ LC

The projection operation in (Proj) is the same for C = −θ. Analogous update rules to Proposition 1 can derived
with exactly the same procedure. For a given subset c ∈ C and vertex i, we have that µ(cid:48) = Pij→i(µ) constitutes
the update

(cid:115)

µ(cid:48)

c(xc) = µc(xc)

µi(xi)

(cid:80)

µc(xc)

xc\i

(cid:115) (cid:80)

µ(cid:48)

i(xi) = µc(xc)

µc(xc)

xc\i
µi(xi)

.

The normalization updates are identical as well. As in the presented EMP algorithm, we can design greedy and
cyclic algorithms around these update equations. The theoretical analysis in Section 6 will focus on the case with
edges only. We leave the general analysis of LC for future work.

D Omitted Proofs and Derivations from Section 6

D.1 Derivation of the Lyapunov function (3)

For convenience, L is restated here:

L(λ, ξ) = −

(cid:88)

(cid:88)

ij∈E

xi,xj ∈χ

exp (−ηCij(xi, xj) − λij(xi) − λji(xj) − ξij)





−

−

(cid:88)

(cid:88)

exp

−ηCi(x) − ξi +

(cid:88)

λij(x) +

(cid:88)

λji(x)



i∈V
(cid:88)

x∈χ

ξij −

ij∈E

(cid:88)

i∈V

(cid:88)

(cid:88)

ξi +

ij∈E

xi,xj ∈χ

j∈Nr(i)

j∈Nc(i)

exp(−ηCij(xi, xj)) +

(cid:88)

(cid:88)

i

x∈χ

exp(−ηCi(x)).

(5)

The Lagrangian of (Proj) with primal variables µ and dual variables (λ, ξ) can be written as

L(µ, λ, ξ) = DΦ(µ, exp(−ηC)) +

(cid:88)

(cid:0)λ(cid:62)

ij(µij1 − µi) + λ(cid:62)

ji(µ(cid:62)
ij

1 − µi)(cid:1)

ij
ξij(1(cid:62)µij1 − 1) +

(cid:88)

+

ij

ξi(µ(cid:62)
i

1 − 1),

(cid:88)

i

where

DΦ(µ, exp(−ηC)) =

(cid:88)

(cid:88)

µij(xi, xj) (log µij(xi, xj) + ηCij(xi, xj) − 1)

xi,xj

ij
(cid:88)

+

(cid:88)

µi(x) (log µi(x) + ηCi(x) − 1)

i
(cid:88)

x
(cid:88)

+

ij

xi,xi

exp(−ηCij(xi, xj)) +

(cid:88)

(cid:88)

i

x

exp(−ηCi(x)).

The partial derivatives with respect to µij(xi, xj) and µi(x) are given by

∂L
∂µij(xi, xj)

∂L
∂µi(x)

= log µij(xi, xj) + ηCij(xi, xj) + λij(xi) + λji(xj) + ξij

= log µi(x) + ηCi(x) + ξi −

(cid:88)

λij(xi) +

(cid:88)

λji(xj).

j∈Nr(i)

j∈Nc(i)

Jonathan N. Lee∗, Aldo Pacchiano∗, Michael I. Jordan

Setting the derivatives to zero gives the solution µ in terms of the dual variables:

µij(xi, xj) = exp (−ηCij(xi, xj) − λij(xi) − λji(xj) − ξij)



µi(x) = exp

−ηCi(x) − ξi +

(cid:88)

λij(x) +

(cid:88)

λji(x)

 .

j∈Nr(i)

j∈Nc(i)



By substituting µ in L, we obtain the Lyapunov function L.

D.2 Proof of Lemma 1

In this section we prove Lemma 1. We restate the result for the reader’s convenience.
Lemma 3. For a given edge ij ∈ E, let µ(cid:48) and (λ(cid:48), ξ(cid:48)) denote the updated primal and dual variables after a
projection from one of (a)–(d) in Proposition 1. We have the following improvements on L. If µ(cid:48) is equal to:

(a) PXij→i(µ), then L(λ(cid:48), ξ(cid:48)) − L(λ, ξ) = 2h2(µij1, µi)

(b) PXij,i(µ), then L(λ(cid:48), ξ(cid:48)) − L(λ, ξ) ≥ 0

(c) PXij→j (µ), then L(λ(cid:48), ξ(cid:48)) − L(λ, ξ) = 2h2(µ(cid:62)
ij

1, µj)

(d) PXij,j (µ), then L(λ(cid:48), ξ(cid:48)) − L(λ, ξ) ≥ 0.

Proof. Let L and L(cid:48) denote the values of the Lyapunov function before and after the projection in each case.

(a) Due to the projection µ(cid:48) = PXij→i (µ), only µij and µi change values.

L(cid:48) − L =

(cid:88)

xi,xj

(cid:0)µij(xi, xj) − µ(cid:48)

ij(xi, xj)(cid:1) +

(cid:88)

x

(µi(x) − µ(cid:48)

i(x))

(cid:88)

=

(cid:32)

(cid:115)

µij(xi, xj)

1 −

µi(xi)
x(cid:48) µij(xi, x(cid:48))

(cid:80)

(cid:33)

(cid:88)

+

x

(cid:32)

µi(x)

1 −

(cid:115) (cid:80)

x(cid:48) µij(x, x(cid:48))
µi(xi)

(cid:33)

xi,xj
= (cid:13)
(cid:112)µij1 −
(cid:13)

√

µi

(cid:13)
2
2 = 2h2(µij1, µi).
(cid:13)

(b) Due to the projection µ(cid:48) = PXij→i(µ) change, again only µij and µi, but they are simply normalized.
From the derivation of the updates, we can see that only dual variables ξi and ξij are updated in order for the
normalization to occur. We have, from the update rule in Proposition 1

ξ(cid:48)
ij = ξij − log

(cid:88)

µij(xi, xj)

ξ(cid:48)
i = ξi − log

xi,xj
(cid:88)

µi(x).

x

The improvement on the Lyapunov function can then be written as

L(cid:48) − L =

(cid:88)

µij(xi, xj) (cid:0)1 − exp(ξ(cid:48)

ij − ξij)(cid:1) +

(cid:88)

x

µi(x) (1 − exp(ξ(cid:48)

i − ξi))

xi,xj
+ ξ(cid:48)
(cid:88)

ij − ξij + ξ(cid:48)
µij(xi, xj) − log

i − ξi

=

(cid:88)

xi,xj

µij(xi, xj) − 1

xi,xj

(cid:88)

+

x

µi(x) − log

(cid:88)

x

µi(x) − 1,

where the second equality uses the fact that µ(cid:48)
be non-negative by recognizing the classical inequality x − log x − 1 ≥ 0 for all x > 0.

ij and µi both sum to one. This last expression can be shown to

Convergence Rates of Smooth Message Passing with Rounding

(c) The proof of improvement is identical to (a); however, we replace vertex i with j and all row sums µij1
with column sum µ(cid:62)
ij

1.

(d) The proof of improvement is identical to (b), but we replace i with j for the vertex marginal normalization.

D.3 Fixed points of EMP

We start this section by noting that all ﬁxed points of EMP correspond to valid (constraint satisfying) primal
solutions and therefore must equal global optima of the dual function.

First note that any ﬁxed point of EMP corresponds to a candidate solution all whose constraints are satisﬁed.
Indeed, at optimality λ∗, ξ∗ satisfy:

(cid:1)

(cid:0)µ∗

η

ij

(xi, xj) = exp (cid:0)−ηCij(xi, xj) − λ∗

ij(xi) − λ∗

ji(xj) − ξ∗
ij

(cid:1)

(cid:0)µ∗

η

i

(xi) = exp


−ηCi(xi) − ξ∗

i +

(cid:1)



(cid:88)

λ∗
ij(xi) +

(cid:88)

λ∗
ji(xi)

 ,

j∈Nr(i)

j∈Nc(i)

with µ∗

η ∈ L2. Since all constraints are satisﬁed, for all projection types P in Lemma 1, P(µ∗

η) = µ∗
η.

For the converse, we proceed by contradiction. Let µ be a ﬁxed point of EMP. As such, all the normalization
constraints (ensuring the edge and node distributions each sum to one) must be satisﬁed. Assume then that a
constraint of type (a) or (c) is not satisﬁed. Without loss of generality let ij → i be the unsatisﬁed constraint. As
a consequence of 1, the Lyapunov objective can be strictly increased by performing the corresponding Bregman
projection, and therefore EMP couldn’t have possibly be at a ﬁxed point. We summarize these observations in
the following proposition:

Proposition 2. All maxima of L(λ, ξ) are ﬁxed points of EMP and all ﬁxed points of EMP are maxima of
L(λ, ξ).

D.4 Proof of Lemma 2

In this section we prove Lemma 2, we restate it here for readability:
Lemma 4. Let λ∗, ξ∗ denote the maximizers of L. The diﬀerence in function value between the optimal value of
L and the value at the ﬁrst iteration is upper bounded as

L(λ∗, ξ∗) − L(λ(1), ξ(1)) ≤ min((cid:107)ηC/d + exp(−ηC)(cid:107)1, S).

Proof. We start by showing the upper bound:

L(λ∗, ξ∗) − L(λ(1), ξ(1)) ≤ (cid:107)ηC/d + exp(−ηC)(cid:107)1.

(6)

We have that (λ, ξ) = (0, 0) when µ = e−ηC before any updates to the primal variables. By Lemma 1,
L(0, 0, 0) ≤ L(λ(1), ξ(1)). Then we have

L(λ∗, ξ∗) − L(λ(1), ξ(1)) ≤ L(λ∗, ξ∗) − L(0, 0) ≤ L(λ∗, ξ∗).

We may establish an upper bound on L(λ∗, ξ∗) by ﬁnding a feasible point in the primal objective (Proj). It is
easy to verify that µ is in L2 if ∀ij ∈ E and ∀i ∈ V, µij(xi, xj) = 1
d . With this choice of µ, the
value of (Proj) is

d2 and µi(xi) = 1

DΦ(µ, exp(−ηC)) =

(cid:88)

ij∈E

(ηEU [Cij] − 1 − log d2) +

(ηEU [Ci] − 1 − log d)

(cid:88)

i∈V

(cid:88)

(cid:88)

+

exp(−ηCij(xi, xj)) +

(cid:88)

(cid:88)

i

x∈χ

exp(−ηCi(x))

xi,xj ∈χ

ij∈E
η
d

≤ (cid:107)

C + exp(−ηC)(cid:107)1 − (|V| + |E|)(log d + 1),

Jonathan N. Lee∗, Aldo Pacchiano∗, Michael I. Jordan

where EU denotes the uniform distribution. where the last inequality follows from the fact that Cij(0, 0) =
Ci(0) = 0. Therefore,

L(λ∗, ξ∗) − L(λ(1), ξ(1)) ≤ L(λ∗, ξ∗) ≤ (cid:107)

η
d

C + exp(−ηC)(cid:107)1 − (|V| + |E|)(log d + 1).

We now proceed to show the following (direct) bound on L(λ∗, ξ∗) − L(λ(1), ξ(1)):

L(λ∗, ξ∗) − L(λ(1), ξ(1)) ≤

(cid:88)





log



(cid:88)



exp (−ηCij(xi, xj))

 +

(cid:88)

ij∈E
(cid:34)

(cid:88)

log

xi,xj ∈χ

(cid:32)

(cid:88)

(cid:33)

exp (−ηCi(x))

+

i∈V

x∈χ

xi,xj ∈χ
(cid:35)

Ci(x)

.

(cid:88)

x∈χ

η
2



Cij(xi, xj)

 +

η
4

We work under the assumption that at any time k, all the component distributions of µ(k) are normalized so its
entries sum to 1. Notice that in this case

L(λ∗, ξ∗) − L(λ(1), ξ(1)) =

(cid:88)

ij∈E

ξ(1)
ij − ξ∗

ij +

ξ(1)
i − ξ∗
i .

(cid:88)

i∈V

If we initialize our algorithm to λ(1) = 0, and ξ(1) be the normalization factors corresponding to this choice of λ,
then

(cid:88)

ij∈E

ξ(1)
ij +

ξ(1)
i =

(cid:88)

i∈V

(cid:88)

ij∈E



log



(cid:88)

xi,xj ∈χ



exp (−ηC(xi, xj))

 +

log

(cid:88)

i∈V

(cid:32)

(cid:88)

x∈χ

(cid:33)

exp (−ηC(x))

.

Notice that at optimality λ∗, ξ∗, for all ij ∈ E and, for all xi, xj,

exp (cid:0)−ηCij(xi, xj) − λ∗

ij(xi) − λ∗

ji(xj) − ξ∗
ij

(cid:1) = (cid:0)µ∗

η

(cid:1)

ij

(xi, xj) ∈ [0, 1].

And for all i ∈ V and for all x,


−ηCi(x) − ξ∗

i +

exp

(cid:88)

λ∗
ij(x) +

(cid:88)

λ∗
ji(x)

j∈Nr(i)

j∈Nc(i)


 = (cid:0)µ∗

η

(cid:1)

i

(x) ∈ [0, 1].

Therefore, for all ij ∈ E and for all xi, xj:

− ηCij(xi, xj) − λ∗

ij(xi) − λ∗

ij(xj) − ξ∗

ij ≤ 0

For all i ∈ V and for all x:

− ηCi(x) − ξ∗

i +

(cid:88)

λ∗
ij(x) +

(cid:88)

λ∗
ji(x) ≤ 0

j∈Nr(i)

j∈Nc(i)

Summing Equations (7) and (8) over all ij ∈ E, i ∈ V and xi, xj, x ∈ χ yields:
(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

−

ξ∗
ij −

ξ∗
i ≤

ij∈E

i∈V

ij∈E

xi,xj ∈χ

η
d2 Cij(xi, xj) +

η
d

Ci(x)

And, therefore,

L(λ∗, ξ∗) − L(λ(1), ξ(1)) ≤

(cid:88)





log



(cid:88)

exp (−ηC(xi, xj))

 +

ij∈E
(cid:34)

(cid:88)

log

xi,xj ∈χ

(cid:32)

(cid:88)

(cid:33)

exp (−ηC(x))

+

i∈V

x∈χ

(cid:88)

x∈χ

η
d

i∈V

x∈χ



(cid:88)

xi,xj ∈χ
(cid:35)


η
d2 Cij(xi, xj)

 +

Ci(x)

.

(10)

(7)

(8)

(9)

Convergence Rates of Smooth Message Passing with Rounding

Notice that the RHS of the equation above is positive since: (cid:80)(cid:96)
for
all (cid:96) ∈ N and all a1, · · · , a(cid:96) ∈ R. Combining Equations (6) and (10) and the observation that L(0, 0) ≤ L(λ(1), ξ1)
(by virtue of Lemma 1) we obtain the ﬁnal result.

i=1 exp(ai) ≥ 1
(cid:96)

i=1 exp(ai) ≥ exp

i=1 ai
(cid:96)

(cid:80)(cid:96)

(cid:16) (cid:80)(cid:96)

(cid:17)

In the case when all entries of C are positive it may be the case that S (cid:29) (cid:107) exp (−ηC) (cid:107)1.

D.5 Complete Proof of Theorem 2

In this section, we will complete the proof of Theorem 2 by handling the case of EMP-cyclic. We require two
additional technical lemmas on the l1 distance between updated variables. We will use r(·) and c(·) to denote row
and column sums respectively of joint distribution matrices.
Lemma 5. Let a, b ∈ Σd be two points in the simplex and let p ∈ Rd
1 ≤ i ≤ d. Let c ∈ Σd deﬁned as c = p
(cid:80)

+ s.t. min(ai, bi) ≤ pi ≤ max(ai, bi) for all

. Then:

i pi

Proof. We only need to prove that (cid:107)a − c(cid:107) ≤ (cid:107)a − b(cid:107)1. From min(ai, bi) ≤ pi ≤ max(ai, bi) we obtain:

max((cid:107)a − c(cid:107)1, (cid:107)b − c(cid:107)1) ≤ (cid:107)a − b(cid:107)1

Let t = 1
(cid:80)

i pi

. The following relationships hold:

|ai − pi| + |bi − pi| = |ai − bi|.

(cid:107)a − c(cid:107)1 =

≤

(cid:88)

i
(cid:88)

i

|a − tpi| =

|ai − pi| +

(cid:88)

i
(cid:88)

i

|ai − pi + (1 − t)pi|

|(1 − t)pi|.

Note that

and

Therefore,

The result follows.

(cid:88)

i

|(1 − t)pi| = |1 − t|

pi =

|1 − t|
t

= |

1
t

(cid:88)

i

− 1| = |

(cid:88)

i

pi − 1|,

(cid:88)

i

|bi − pi| ≥ |

(cid:88)

i

bi − pi| = |1 −

(cid:88)

i

pi| = |

(cid:88)

i

pi − 1|.

(cid:107)a − c(cid:107)1 ≤

(cid:88)

i

|ai − pi| +

(cid:88)

i

|bi − pi| =

(cid:88)

i

|ai − bi| = (cid:107)a − b(cid:107)1.

Let A ∈ Σd×d with elements aij be a matrix representing joint distribution probabilities. For p = (cid:2)p1
Σd, deﬁne

. . . pd

(cid:3)(cid:62)

∈

(cid:101)A =

1
z



a11






ad1

r(A)1

(cid:113) p1
...
(cid:113) pd

r(A)d

· · · a1d
. . .
· · · add

r(A)1

(cid:113) p1
...
(cid:113) pd

r(A)d








where z is a normalization term, such that the new probabilities matrix sums to one. The notation r(A)i denotes
the ith element of row sum vector r(A).

Jonathan N. Lee∗, Aldo Pacchiano∗, Michael I. Jordan

Lemma 6. The following inequality holds on the diﬀerence between A and (cid:101)A:

(cid:107)c( (cid:101)A) − c(A)(cid:107)1 ≤ (cid:107)r( (cid:101)A) − r(A)(cid:107)1

Proof.

(cid:107)c( (cid:101)A) − c(A)(cid:107)1 =

≤

=

d
(cid:88)

j=1

(cid:88)

i,j

(cid:88)

i

(cid:88)

=

i

− z

(cid:19)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:18)(cid:114) pi

aij
z
(cid:114) pi

d
(cid:88)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
i=1
(cid:12)
aij
(cid:12)
(cid:12)
z
(cid:12)

r(A)i
z

(cid:12)
(cid:12)
(cid:12)
(cid:12)

r(A)i
(cid:114) pi

r(A)i
(cid:12)
(cid:12)
(cid:12)
(cid:12)

− z

− z

r(A)i

(cid:114)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

r(A)ipi
z

− r(A)i

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= (cid:107)r( (cid:101)A) − r(A)(cid:107)1.

This proof of Theorem 2 relies heavily on the primal and dual variables at given times throughout the algorithm.
As such, it is necessary to deﬁne precise notation for these temporal events. We note that there are two loops in
the algorithm: an outer loop that controls the iterations and an inner one that loops over all edges in E. The
outer loop’s current iteration is given by k ≥ 0, as deﬁned and updated in Algorithm 1. We denote the current
step of the inner loop by t where 1 ≤ t ≤ 4|E|. This is due to the fact that there are four projections for each
edge (Xij→i, Xij,i, Xij→j, and Xij,j) in one full iteration for L2. Thus the algorithm alternates between enforcing
consistency between an edge and vertex and normalizing the local distributions.

The value of µ at iteration k and step t within iteration k is denoted by µ(k,t). For example, at the very start of
the algorithm, we are at iteration k = 1 and step t = 1 with initial value µ(1,1), which is equal to exp(−ηC) with
normalized vertex marginal and edge joint distributions. The constraint set onto which a projection is made at
t in any iteration is denoted by X (t). Note that we drop k in the constraint set notation because the order in
which the projections occur is always the same.

Proof of Theorem 2. Let k∗ be the ﬁrst iteration such that the termination condition in Algorithm 1 with
respect to (cid:15) is met. For k such that 1 ≤ k ≤ k∗, there exists ij ∈ E such that (cid:107)r(µ(k,1)
(cid:107)1 ≥ (cid:15) or
(cid:107)c(µ(k,1)
ij

) − µ(k,1)
i

) − µ(k,1)
j

(cid:107)1 ≥ (cid:15).

ij

can move within the (cid:15)-ball of c(µ(k,t)

First consider the case where (cid:107)c(µ(k,1)
µ(k,t)
j
involving vertex j. However, µ(k,t(cid:48))
X (t−2) = Xij→i. Then, by repeatedly applying the triangle inequality, we have

(cid:107)1 ≥ (cid:15). Let t be chosen such that X (t) = Xij→j. Note that
) between times 1 and t of the kth iteration due to earlier projections
for all t(cid:48) ≤ t − 2 because it is only updated at step t − 2 where

) − µ(k,1)
j

= µ(k,1)
ij

ij

ij

ij

(cid:15) ≤ (cid:107)c(µ(k,1)

ij
≤ (cid:107)c(µ(k,t−2)
ij
≤ (cid:107)c(µ(k,t−2)
ij

) − µ(k,1)
(cid:107)1
j
) − µ(k,1)
j
) − µ(k,t)
j

(cid:107)1

(cid:107)1 +

(cid:88)

(cid:107)µ(k,t(cid:48))

j

− µ(k,t(cid:48)+2)

j

(cid:107)1

≤ (cid:107)c(µ(k,t)
ij
(cid:88)

+

j,r ∪T (t)

j,c

) − µ(k,t)
j

t(cid:48)∈T (t)
(cid:107)1 + (cid:107)c(µ(k,t)
− µ(k,t(cid:48)+2)

ij

j

(cid:107)µ(k,t(cid:48))

j

(cid:107)1,

) − c(µ(k,t−2)
ij

)(cid:107)1

t(cid:48)∈T (t)

j,r ∪T (t)

j,c

Convergence Rates of Smooth Message Passing with Rounding

j,r and T (t)
where T (t)
caused µj to be updated:

j,c are sets of times before t where a projection (for row and column consistency, respectively)

T (t)
j,r
T (t)
j,c

def.= {t(cid:48) < t : ∃(cid:96) ∈ Nr(i) s.t. X (t(cid:48)) = Xj(cid:96)→j}
def.= {t(cid:48) < t : ∃(cid:96) ∈ Nc(i) s.t. X (t(cid:48)) = X(cid:96)j→j}.

Therefore, µ(k,t(cid:48)+2)
denote the edge (incident on j) onto which projections are occurring at step t(cid:48) ∈ T (t)
t(cid:48) ∈ Tj,r(t), then

is the result of enforcing consistency with another edge of i and then normalizing µj. Let et(cid:48)
j,c . From Lemma 5, if

j,r ∪ T (t)

j

(cid:107)µ(k,t(cid:48))

j

− µ(k,t(cid:48)+2)

j

(cid:107)1 ≤ (cid:107)µ(k,t(cid:48))

j

− r(µ(k,t(cid:48))

et(cid:48)

)(cid:107)1.

If t(cid:48) ∈ T (t)

j,c , then

Similarly, by combining Lemma 5 and Lemma 6, we have

(cid:107)µ(k,t(cid:48))

j

− µ(k,t(cid:48)+2)

j

(cid:107)1 ≤ (cid:107)µ(k,t(cid:48))

j

− c(µ(k,t(cid:48))

et(cid:48)

)(cid:107)1.

(cid:107)c(µ(k,t)
ij

) − c(µ(k,t−2)
ij

)(cid:107)1 ≤ (cid:107)r(µ(k,t)

ij

) − r(µ(k,t−2)
ij

)(cid:107)1 ≤ (cid:107)µ(k,t−2)

i

− r(µ(k,t−2)
ij

)(cid:107)1.

Note that since the variables are normalized at every even step, they are individually valid probability distributions,
and so the Hellinger inequality can be applied. For distributions, p and q, the inequality states

Therefore,

1
4

(cid:107)p − q(cid:107)2

1 ≤ 2h2(p, q).

(cid:15)2
4(deg(G) + 1)

≤ 2h2(c(µ(k,t)

ij

), µ(k,t)
j

) + 2h2(r(µ(k,t−2)

ij

), µ(k,t−2)
i

)

(cid:88)

+

t(cid:48)∈T (t)
j,r

2h2(r(µ(k,t(cid:48))

et(cid:48)

), µ(k,t(cid:48))

j

) +

2h2(c(µ(k,t(cid:48))

et(cid:48)

), µ(k,t(cid:48))

j

)

(cid:88)

t(cid:48)∈T (t)
j,c

≤ L(k+1,1) − L(k,1).

The last inequality follows from telescoping over all steps in iteration k due to Lemma 1. This proof was for the
case when (cid:107)c(µ(k,1)
(cid:107)1 ≥ (cid:15), the procedure is identical except
ij
we may ignore the term (cid:107)c(µ(k,t)
)(cid:107)1 since µij is constant within iteration k until the projection
ij
onto Xij→i. Thus, the improvement lower bound still holds.

(cid:107)1 ≥ (cid:15). For the case when (cid:107)r(µ(k,1)

) − c(µ(k,t−2)
ij

) − µ(k,1)
i

) − µ(k,1)
j

ij

Putting these results together with Lemma 2, we see that as long as a single constraint is violated above the (cid:15)
threshold at the start of an iteration, it is possible to show that the value of L increases by at least (cid:15)2/4(deg(G) + 1)
during the iteration. This implies that EMP-cyclic terminates in at most (cid:100) 4S0(deg(G)+1)

(cid:101) iterations.

(cid:15)2

D.6 Proof of Theorem 3

We start by deﬁning a version of L2 with slack vectors. Let ν be a vector indexed in a similar way as µ, where
{νij, νji}ij∈E . We deﬁne the slack ν as νij = µij1 − µi and νji = µ(cid:62)
1 − µj. Then we deﬁne the slack polytope
ij
Lν

2 as

Lν
2

def.=






µ ≥ 0 :

µi ∈ Σd
µij1 = µi + νij
µ(cid:62)
ij
1(cid:62)µij1 = 1

∀i ∈ V
∀ij ∈ E
1 = µj + νji ∀ij ∈ E
∀ij ∈ E






.

(11)

Jonathan N. Lee∗, Aldo Pacchiano∗, Michael I. Jordan

Notice that by deﬁnition the slack vectors ν satisfy that, for all ij ∈ E, ν(cid:62)
ij
between L2 and Lν
slack. Consider the entropy-regularized linear program corresponding to Lν
2:

1 = 0. The main diﬀerence
2 lies in that the joints do not marginalize exactly to the vertex probabilities but do so up to a

1 = ν(cid:62)
ji

min (cid:104)C, µ(cid:105) −

1
η

H(µ)

s.t.

µ ∈ Lν
2,

(Reg-slack)

Introducing the exact same ensemble of dual variables λ, ξ as in the Lyapunov function derivation, its dual
function equals

Lν (λ, ξ) = −

(cid:88)

(cid:88)

exp (−ηCij(xi, xj) − λij(xi) − λji(xj) − ξij)

ij∈E
(cid:88)

xi,xj ∈χ
(cid:88)

(cid:16)

ij∈E

xi,xj ∈χ

λij(xi)νij(xi) + .λji(xj)νji(xj)

(cid:17)





(12)

(cid:88)

(cid:88)

exp

−ηCi(x) − ξi +

(cid:88)

λij(x) +

(cid:88)

λji(x)



i∈V
(cid:88)

x∈χ

ξij −

ij∈E

(cid:88)

i∈V

(cid:88)

(cid:88)

ξi +

ij∈E

xi,xj ∈χ

j∈Nr (i)

j∈Nc(i)

exp(−ηCij(xi, xj)) +

(cid:88)

(cid:88)

i

x∈χ

exp(−ηCi(x)).

−

−

−

Furthermore, if λ∗, ξ∗ were a set of optimal dual variables, the optimal primal µ∗ can be computed via

ij(xi, xj) = exp (cid:0)−ηCij(xi, xj) − λ∗
µ∗

−ηCi(xi) − ξ∗

i (xi) = exp

i +

µ∗

ij(xi) − λ∗

ji(xj) − ξ∗
ij

(cid:1)



(cid:88)

λ∗
ij(xi) +

(cid:88)

λ∗
ji(xi)

 .

(13)

(14)

They satisfy the same formulae as the problem without slack variables. Since dual optimality is equivalent to
primal feasibility, whenever an iterate of EMP satisﬁes slack of ν, its corresponding primal solution is optimal for
(Reg-slack).

j∈Nr(i)

j∈Nc(i)

We start with a useful manipulation lemma:
Lemma 7. Let ν, ν(cid:48) be two slack vectors and let µ ∈ Lν

2. Assume (cid:107)v(cid:48)(cid:107)∞ ≤ 1
2d .

1. If for all ij ∈ E and i ∈ V, µi + ν(cid:48)

ij ∈ Σd, then there exists a vector µ(cid:48) ∈ Lν(cid:48)
(cid:107)µ − µ(cid:48)(cid:107)1 ≤ 2(cid:107)ν − ν(cid:48)(cid:107)1.

2 such that

2. If ν = 04, then there exists a vector µ(cid:48) ∈ Lν(cid:48)

2 such that

(cid:107)µ − µ(cid:48)(cid:107)1 ≤ 6d deg(G)(cid:107)ν(cid:48)(cid:107)1.

(15)

(16)

Proof. First we consider the case when for all ij ∈ E, µi + ν(cid:48)
are in [0, 1] and its values sum to 1). In this case, we can argue for the existence of µ(cid:48) via the following:

ij is a valid distribution (in other words, all its entries

i = µi for all i ∈ V. Let ij ∈ E and observe that µij1 = µi + νij and µ(cid:62)
ij

Let µ(cid:48)
in Altschuler et al. (2017) to claim the existence of µ(cid:48)

ij such that µ(cid:48)
ij

1 = µi + ν(cid:48)

1 = µj + νji. We invoke Lemma 7

ij)(cid:62)1 = µj + ν(cid:48)

ji and

(cid:107)µij − µ(cid:48)

ij(cid:107)1 ≤ 2 (cid:0)(cid:107)µi + νij − µi − ν(cid:48)

ij(cid:107)1 + (cid:107)µj + νji − µj − ν(cid:48)

ji(cid:107)1

= 2 (cid:0)(cid:107)νij − ν(cid:48)

ij(cid:107)1 + (cid:107)νji − ν(cid:48)

ji(cid:107)1

(cid:1) .

Setting µ(cid:48) to be the ensemble with values {µ(cid:48)

i}i∈V and {µ(cid:48)

ij}ij∈E the result follows.

Now we consider the case when there exist ij ∈ E such that µi + v(cid:48)
ij does not lie in the probability simplex. In
this case we will have to deﬁne µ(cid:48)
i diﬀerent from µi. Consider some i ∈ V. Let N (i) be the set of neighbouring
vertices to i and we abuse notation slightly and use νij for j ∈ N (i) to denote the slack on i as of the edge
marginal shared by i and j. We deﬁne µ(cid:48)

i in the following way:

4We do not require that µi + ν(cid:48)

ij ∈ Σd

ij and (µ(cid:48)
(cid:1)

Convergence Rates of Smooth Message Passing with Rounding

1. If µi + ν(cid:48)

ij ∈ Σd for all j ∈ N (i) then let µ(cid:48)

i = µi.

2. Otherwise, let {x1, · · · , xr} ⊆ [d] be the entries of µi such that for all xτ ∈ {x1, · · · , xr} there exists at least

one j ∈ N (i) for which (cid:2)µi + ν(cid:48)

(cid:3) (xτ ) (cid:54)∈ [0, 1]. Therefore, we must deﬁne µ(cid:48)

ij

i such that

(cid:107)ν(cid:48)

max
j

ij(cid:107)∞ ≤ µi(x) ≤ 1 − max

(cid:107)ν(cid:48)

ij(cid:107)∞,

j

which can be done by taking the convex combination of µi with the uniform distribution:

µ(cid:48)

i = (1 − θ)µi +

θ
d

.

Setting θ = d maxj (cid:107)ν(cid:48)
have

ij(cid:107)∞ guarantees this outcome because we are given that (cid:107)ν(cid:107)∞ ≤ 1

2d . Furthermore, we

(cid:107)µi − µ(cid:48)

i(cid:107)1 =

(cid:88)

|µi(x) − µ(cid:48)

i(x)|

x
≤ 2d max

j

(cid:107)ν(cid:48)

ij(cid:107)∞.

This, in turn, implies (cid:80)
to achieve existence of {µ(cid:48)

i∈V (cid:107)µi − µ(cid:48)

i(cid:107)1 ≤ 2d(cid:107)ν(cid:48)(cid:107)1. Then, we apply the result of Altschuler et al. (2017) again

(cid:107)µij − µ(cid:48)

ij}ij∈E such that
ij(cid:107)1 ≤ 2 (cid:0)(cid:107)µ(cid:48)
= 2 (cid:0)(cid:107)ν(cid:48)

i − µi − ν(cid:48)
ij(cid:107)1 + (cid:107)ν(cid:48)

ij(cid:107)1 + (cid:107)µ(cid:48)
ji(cid:107)1 + (cid:107)µi − µ(cid:48)

j − µj − ν(cid:48)

ji(cid:107)1
i(cid:107)1 + (cid:107)µj − µ(cid:48)

(cid:1) .

j(cid:107)1

(cid:1)

Summing over these yields (cid:80)
6d deg(G)(cid:107)ν(cid:48)(cid:107)1

ij∈E (cid:107)µij − µ(cid:48)

ij(cid:107)1 ≤ 2(cid:107)ν(cid:48)(cid:107)1 + 2d deg(G)(cid:107)ν(cid:48)(cid:107)1. Therefore (cid:107)µ − µ(cid:48)(cid:107)1 ≤

We additionally require a similar lemma which allows us to project from one polytope to another while bounding
the probabilities away from zero.
Lemma 8. Fix τ such that 0 < τ ≤ 1
a vector µ(cid:48) ∈ L2 such that

8d2 and a slack vector ν such that (cid:107)ν(cid:107)∞ ≤ 1

2, then there exists

4d . If µ ∈ Lν

µ(cid:48)

∀i ∈ V, xi ∈ χ
i(xi) ≥ τ
µ(cid:48)
∀ij ∈ E, xi, xj ∈ χ
ij(xi, xj) ≥ τ
(cid:107)µ − µ(cid:48)(cid:107)1 ≤ 2(cid:107)ν(cid:107)1 + 2(m + n)d2τ.

If µ ∈ L2, then there exists a vector µ(cid:48) ∈ Lν

2 such that

µ(cid:48)

i(xi) ≥ τ
µ(cid:48)
ij(xi, xj) ≥ τ
(cid:107)µ − µ(cid:48)(cid:107)1 ≤ 6d deg(G)(cid:107)ν(cid:107)1 + 8(|E| + n)d2τ.

∀i ∈ V, xi ∈ χ
∀ij ∈ E, xi, xj ∈ χ

Proof. We address each case individually.

1. We use the ﬁrst result from Lemma 7, which yields (cid:98)µ ∈ L2 such that (cid:107)µ − (cid:98)µ(cid:107)1 ≤ 2(cid:107)ν(cid:107)1. If the probabilities
are already bounded below τ , then we are done; however, we must handle the worst case. As in the proof of
Lemma 7, we compute a convex combination of (cid:98)µ with the uniform distribution to draw the distribution
away from zero values. Deﬁne

µ(cid:48)

i := (1 − θ) (cid:98)µi +

1

θ
d

µ(cid:48)

ij := (1 − θ) (cid:98)µij +

θ
d2

1.

Jonathan N. Lee∗, Aldo Pacchiano∗, Michael I. Jordan

where we set θ = τ d2 which ensures that θ ∈ [0, 1] and µ ≥ τ . Then, note that

(cid:107) (cid:98)µi − µ(cid:48)

i(cid:107)1 =

(cid:107) (cid:98)µij − µ(cid:48)

ij(cid:107)1 =

(cid:88)

|

x
(cid:88)

xi,xj

θ
d

− θ (cid:98)µi(x)| ≤ 2τ d2

|

θ
d

− θ (cid:98)µij(xi, xj)| ≤ 2τ d2.

By the triangle inequality, we have

(cid:107)µ − µ(cid:48)(cid:107)1 ≤ (cid:107)µ − (cid:98)µ(cid:107)1 + (cid:107) (cid:98)µ − µ(cid:48)(cid:107)1 ≤ 2(cid:107)ν(cid:107)1 + 2(n + m)d2τ.

2. In the second case, we start by constructing a distribution δ, which is nearly uniform but lives in the slack

polytope is and bounded away from zero by at least τ .
For each i ∈ V, we take δi ∈ Σd to be the uniform distribution where δi(x) = 1
perturb the uniform distribution with ν for each j ∈ N (i), generating δj
notation slightly by using νij to denote marginalization of edge ij to vertex i. Note that δj
j)(cid:62) ∈ Ud(δj
deﬁne the product distribution δij = δj
full vector δ given by the ensemble {δi}i∈V and {δij}ij∈E is in Lν
bounded below as

d ≥ τ . Since (cid:107)ν(cid:107)∞ ≤ 1
4d , we
i := δi + νij. Again, we are abusing
i ∈ Σd, so we can
j), which, by construction, marginalizes such that the
2. Furthermore, each component can be

i , δi

i (δi

+

δij(xi, xj) =

νji(xi)
d

+ νij(xi)νji(xj)

νij(xi)
d
1
2d2 −

1
d2 +
1
d2 −
1
4d2 .
Now, as before, we know there exists (cid:98)µ ∈ L2
2 such that (cid:107)µ − (cid:98)µ(cid:107)1 ≤ 6d deg(G)(cid:107)ν(cid:107)1 from Lemma 7. Therefore,
we can take the convex combination of µ(cid:48) = (1 − θ)µ + θδ to get µ(cid:48) ∈ Lν
4d2 in all entries.
Taking θ = 4d2τ ∈ [0, 1] ensures that µ(cid:48) ≥ τ . Furthermore, the diﬀerence can be computed as

2 such that µ(cid:48) ≥ θ

1
16d2

≥

≥

(cid:107) (cid:98)µi − µ(cid:48)

i(cid:107)1 =

(cid:107) (cid:98)µij − µ(cid:48)

ij(cid:107)1 =

(cid:88)

|

x
(cid:88)

xi,xj

θ
d

− θ (cid:98)µ(x)| ≤ 8d2τ

|θδij(xi, xj) − θ (cid:98)µij(xi, xj)| ≤ 8d2τ.

Therefore, we have (cid:107) (cid:98)µ − µ(cid:48)(cid:107)1 ≤ 8(|E| + n)d2τ , which by triangle inequality implies

(cid:107)µ − µ(cid:48)(cid:107)1 ≤ (cid:107) (cid:98)µ − µ(cid:107)1 + (cid:107) (cid:98)µ − µ(cid:48)(cid:107)1 ≤ 6d deg(G)(cid:107)ν(cid:107)1 + 8(|E| + n)d2τ.

We have now the necessary ingredients to prove the ﬁrst theorem of this section, which provides a bound on
the l1 distance between the ﬁnal iterate µk of Algorithms 1 and 2 and the solution µ∗
η of (Reg). Crucially we
analyze these iterates under the assumption all their component distributions µ(k)
for ij ∈ E
are normalized.
Theorem 4. Let µ(k) is the kth iterate of EMP and let ν(k) be the slack vector corresponding to µ(k) such that
(cid:107)ν(k)(cid:107)∞ ≤ 1

for i ∈ V and µ(k)
ij

4d . In other words,

i

ij

ij = µ(k)
ν(k)
(cid:16)
µ(k)
ν(k)
ji =
ij

1 − µ(k)
(cid:17)(cid:62)

i

1 − µ(k)

.

j

Fix τ > 0 such that τ ≤ 1
8 when fed with µ(k) and τ . Then,

8d2 . Let µ(k)(2) be the pseudo-marginal vector in L2 produced by the ﬁrst case of Lemma

Convergence Rates of Smooth Message Passing with Rounding

1
2

(cid:88)

i∈V

(cid:17)

(cid:16)

(cid:13)
(cid:13)
(cid:13)

− (cid:0)µ∗

µ(k)(2)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
1
≤ (η(cid:107)C(cid:107)∞ + log 1/τ ) (cid:0)8d deg(G)(cid:107)ν(cid:107)1 + 10(|E| + n)d2τ (cid:1) .

µ(k)(2)

− (cid:0)µ∗

(cid:13)
2
(cid:13)
(cid:13)
1

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:88)

1
2

ij∈E

+

(cid:16)

(cid:17)

(cid:1)

(cid:1)

ij

ij

η

η

i

i

Proof. By deﬁnition µ(k) ∈ Lν(k)

2

. In fact, µ(k) is the optimizer of the following regularized linear program:

min (cid:104)C, µ(cid:105) −

1
η

H(µ)

s.t.

µ ∈ Lν(k)

2

,

This observation follows because µ(k) is in Lν(k)
dual feasibility.

2

and its elements can be written as in (13) and (14), thus satisfying

Recall that after every iteration all the component distributions are normalized. Recall that

(cid:104)ηC, µ(k)(2)(cid:105) − H(µ(k)(2)) = DΦ

(cid:104)ηC, µ∗

η(cid:105) − H(µ∗

η) = DΦ

µ(k)(2), exp(−ηC)
η, exp(−ηC)(cid:1) + (cid:104)1, e−ηC(cid:105),
(cid:0)µ∗

+ (cid:104)1, e−ηC(cid:105)

(cid:16)

(cid:17)

where Φ = −H is the negative entropy. The point µ∗
for points in L2. By the properties of information projections,

η is the optimal point of the information projection exp (−ηC)

(cid:16)

DΦ

µ(k)(2), exp(−ηC)

(cid:17)

(cid:16)

≥ DΦ

µ(k)(2), µ∗
η

(cid:17)

+ DΦ

(cid:0)µ∗

η, exp(−ηC)(cid:1) .

Since for µ(k)(2) and µ∗
component vertex and edge distributions) this in turn implies that

η, the sum of their entries is the same, by Pinsker’s inequality (applied to each of the

(cid:16)

DΦ

µ(k)(2), exp(−ηC)

(cid:17)

− DΦ

(cid:0)µ∗

η, exp(−ηC)(cid:1) ≥ DΦ
(cid:88)

≥

i∈V

(cid:88)

ij∈E

(cid:16)

µ(k)(2), µ∗
η

(cid:17)

1
2

1
2

(cid:16)

(cid:13)
(cid:13)
(cid:13)

µ(k)(2)

(cid:17)

i

− (cid:0)µ∗

η

(cid:1)

(cid:13)
2
(cid:13)
(cid:13)
1

i

+

(cid:16)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:17)

µ(k)(2)

− (cid:0)µ∗

η

(cid:1)

ij

ij

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
1

.

(17)

(18)

Let µ∗
of µ∗

η(ν(k)) in Lν(k)
η(ν(k)) and µ(k)(2) for analysis but we need not actually compute them. Expanding I yields

be the vector produced by Lemma 8 applied to µ∗

η ∈ L2. Note that we utilize the existence

2

(cid:16)

DΦ

µ(k)(2), exp(−ηC)

(cid:17)

− DΦ

(cid:0)µ∗

η, exp(−ηC)(cid:1) = (cid:104)ηC, µ(k)(2) − µ∗

η) − H(µ(k)(2))

η(cid:105) + H(µ∗
= (cid:104)ηC, µ(k)(2) − µ(k)(cid:105) + H(µ(k)) − H(µ(k)(2))
(cid:125)
(cid:123)(cid:122)
A1
η(ν(k))(cid:105) + H(µ∗

+ (cid:104)ηC, µ(k) − µ∗

(cid:124)

(cid:124)

(cid:124)

+ (cid:104)ηC, µ∗

η(ν(k)) − µ∗

η(ν(k))) − H(µ(k))
(cid:125)

η) − H(µ∗

η(ν(k)))
(cid:125)

.

(cid:123)(cid:122)
A2
η(cid:105) + H(µ∗
(cid:123)(cid:122)
A3

Term A2 is negative since µ(k) is the optimal point in the slack polytope. Because µ∗
constructed such that all their probabilities are lower bounded by τ , it holds that the entropies are log 1

η(ν(k)) and µ(k)(2) were
τ -Lipschitz

Jonathan N. Lee∗, Aldo Pacchiano∗, Michael I. Jordan

in (cid:107) · (cid:107)1 Terms A1 and A3 can be then bounded:

A1 ≤ η(cid:107)C(cid:107)∞(cid:107)µ(k)(2) − µ(k)(cid:107)1 + log

≤ (η(cid:107)C(cid:107)∞ + log 1/τ )

(cid:16)

1
τ
2(cid:107)ν(k)(cid:107)1 + 2(|E| + n)d2τ

(cid:107)µ(k)(2) − µ(k)(cid:107)1

(cid:17)

A3 ≤ (cid:107)C(cid:107)∞(cid:107)µ∗

η(ν(k)) − µ∗
η(cid:107)1 + log
(cid:16)

≤ (η(cid:107)C(cid:107)∞ + log 1/τ )

6d deg(G)(cid:107)ν(k)(cid:107)1 + 8(|E| + n)d2τ

(cid:17)

.

1
τ

(cid:107)µ∗

η(ν(k)) − µ∗

η(cid:107)1

The result then follow as

A1 + A3 ≤ (η(cid:107)C(cid:107)∞ + log 1/τ )

(cid:16)

8d deg(G)(cid:107)ν(k)(cid:107)1 + 10(|E| + n)d2τ

(cid:17)

.

Theorem 4, combined with the EMP algorithm’s optimality condition can provide convergence guarantees for the
case when L2 is tight and the solution is unique. We restate the main result, Theorem 3, for readability.
Theorem 5. Let η ≥ 2 log(16n2d2)+16|E|d2
|V ∗
(cid:100) 4S0

2 | = 1, the EMP algorithm returns a MAP assignment after (cid:100) 4S0(deg(G)+1)
(cid:15)2 (cid:101) iterations for EMP-greedy.

, and (cid:15)−1 > (25d deg(G)|E|)2 max (η(cid:107)C(cid:107)∞, 68).

(cid:101) iterations for EMP-cyclic and after

If L2 is tight and

min(∆, 1

128 )

(cid:15)2

Proof. Let µ(k) be the last internal iterate of the EMP algorithm before rounding. Since the stopping condition
has been met, the slack vector ν(k) corresponding to µ(k) must satisfy (cid:107) (cid:0)ν(k)(cid:1)
ij (cid:107)1 ≤ (cid:15) for all ij ∈ E so that
(cid:107)ν(k)(cid:107)1 ≤ 2|E|(cid:15).
Let µ(k)(2) be deﬁned as in Theorem 4 and choose τ =

5. Then, the bound from Theorem 4 becomes

(cid:15)
10(|E|+n)d2

(cid:16)

8d deg(G)(cid:107)ν(k)(cid:107)1 + 10(|E| + n)d2τ
(η(cid:107)C(cid:107)∞ + log 1/τ )
≤ (η(cid:107)C(cid:107)∞ + log 1/τ ) (cid:0)16d deg(G)|E|(cid:15) + 10(|E| + n)d2τ (cid:1)

(cid:17)

(cid:18)

=

η(cid:107)C(cid:107)∞ + log

10(|E| + n)d2
(cid:15)

(cid:19)

17d deg(G)|E|(cid:15)

(cid:18)
η(cid:107)C(cid:107)∞ + log (cid:0)10(|E| + n)d2(cid:1) + log
η(cid:107)C(cid:107)∞ + log (cid:0)10(|E| + n)d2(cid:1) + 2(cid:15)−1/2(cid:17)

1
(cid:15)

(cid:19)

(cid:16)

=

≤

17d deg(G)|E|(cid:15)

17d deg(G)|E|(cid:15),

where the last inequality used the fact that log(x) ≤ n(x1/n − 1) for n > 0. Choosing (cid:15)−1 >
425d2 deg(G)2|E|2 max {η(cid:107)C(cid:107)∞, 68} ensures that

(cid:16)

(cid:13)
(cid:13)
(cid:13)

1
2

(cid:88)

i∈V

(cid:17)

µ(k)(2)

− (cid:0)µ∗

η

(cid:1)

i

(cid:13)
2
(cid:13)
(cid:13)
1

i

(cid:88)

+

ij∈E

1
2

(cid:16)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

µ(k)(2)

(cid:17)

− (cid:0)µ∗

η

(cid:1)

ij

ij

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
1

≤

3
25

.

Consequently for all i ∈ V

and for all ij ∈ E

(cid:17)

µ(k)(2)

(cid:16)

(cid:13)
(cid:13)
(cid:13)

i

− (cid:0)µ∗

η

(cid:1)

(cid:13)
(cid:13)
(cid:13)1

i

≤

2
5

.

(cid:16)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:17)

µ(k)(2)

− (cid:0)µ∗

η

(cid:1)

ij

ij

(cid:13)
(cid:13)
(cid:13)
(cid:13)1

≤

2
5

.

5As long as (cid:15) ≤ 1

4d at least, this guarantees τ ≤ 1

8d2 , so we are free to use Theorem 4

Convergence Rates of Smooth Message Passing with Rounding

We also have

(cid:107)µ(k)(2) − µ(k)(cid:107)1 ≤ 2(cid:107)ν(k)(cid:107)1 + 2(|E| + n)d2τ

(cid:15)
5

≤ 4|E|(cid:15) +

≤ 5|E|(cid:15),

which implies (cid:107)µ(k)(2) − µ(k)(cid:107)1 ≤ 1
these inequalities together by triangle inequality,

24 and (cid:107)µ∗

η − µ∗(cid:107)1 ≤ 1

32 (by the condition on η, see Theorem 1). Putting

µ(k)(cid:17)
(cid:16)

(cid:107)

i

(cid:16)

(cid:17)

µ(k)(2)

(cid:107)1 + (cid:107)

i

(cid:16)

(cid:17)

µ(k)(2)

i

−

i

− (cid:0)µ∗

η

(cid:1)

i

(cid:107)1 + (cid:107) (cid:0)µ∗

η

(cid:1)

i

− (µ∗)i (cid:107)1

µ(k)(cid:17)
(cid:16)
2
5

+

+

1
32

− (µ∗)i (cid:107)1 ≤ (cid:107)
1
24
1
2

≤

<

.

For all i ∈ V. A similar statement holds for all ij ∈ E:

(cid:16)

µ(k)(cid:17)

(cid:107)

ij

(cid:16)

− (µ∗)ij (cid:107)1 ≤ (cid:107)
1
24
1
2

≤

<

.

(cid:16)

(cid:17)

µ(k)(2)

(cid:107)1 + (cid:107)

ij

(cid:16)

(cid:17)

µ(k)(2)

ij

− (cid:0)µ∗

η

(cid:1)

ij

(cid:107)1 + (cid:107) (cid:0)µ∗

η

(cid:1)

ij

− (µ∗)ij (cid:107)1

µ(k)(cid:17)

ij

+

2
5

+

−

1
32

Therefore, assuming µ∗ (the solution of L2) is integral,

(cid:16)

round(µ(k))

(cid:17)

i

= (µ∗)i for all i ∈ V

(cid:16)

round(µ(k))

(cid:17)

ij

= (µ∗)ij for all ij ∈ E.

and

E Experiment Details

In this section, we provide some additional details for the experiments in Section 7. As mentioned, empirical
comparisons between state-of-the-art solvers and EMP-like algorithms have been studied extensively (Kappes
et al., 2013; Meshi et al., 2012; Ravikumar et al., 2010; Werner, 2007). For instance, Meshi et al. (2012) found
that the regularized star-based message passing algorithms greatly outperform standard optimization techniques
such as FISTA and gradient descent, which do not exploit the coordinate structure of the problem.

The primary purpose of these experiments is to understand how the theoretical results in Section 6 manifest in a
practical setting. In particular, we would like to understand how the convergence rates, in terms of the ability
to round to the solution, behave as a function of the parameters of the problem such as graph size, choice of
regularization η, and connectivity of the graph. In all experiments, we ran an LP solver on the graph in order to
obtain the ground-truth MAP assignment. We only considered problems that were tight. The solver speciﬁcally
is the ECOS solver through a CVXPY wrapper.

E.1 Grid Experiments

n grids, totallying n
As mentioned, our ﬁrst set of experiments considered solving the MAP problem on
vertices. The vertices were connected by edges to their vertical and horizontal neighbors in the grid. This setting
is fairly standard in the literature (Erdogdu et al., 2017; Globerson and Jaakkola, 2008; Ravikumar et al., 2010).

n ×

√

√

We considered the MAP problem with d = 3 labels and choose a cost vector C in the family of multi-label Potts
models, another well-studied application (Wainwright and Jordan, 2008). Potts models typically have diagonal

Jonathan N. Lee∗, Aldo Pacchiano∗, Michael I. Jordan

potentials between edges. That is, we only penalize/reward when the labels on two connected vertices agree. We
randomly generated the actual values of the vector. For vertex costs, we chose Ci(xi) ∼ Unif(−0.5, 0.5) and for
the edge costs we chose

Cij(xi, xj) =

(cid:40)

βij xi = xj
0

otherwise

∀ij, xi, xj,

where βij ∼ Unif{−0.1, 0.1}. In the approximation results, we ran the algorithms until they had eﬀectively
converged after 80 iterations, where each iteration consisted of a full pass over the edges. For EMP-cyclic, this
means simply going through all the edges once. For EMP-greedy, one iteration means the opportunity to update
each edge exactly once, (although the algorithm will greedily select them in reality). Thus both algorithms
update the same number of edges, though their choices will be diﬀerent. Regardless, we found that 80 iterations
was reasonably suﬃcient to observe the approximation properties. We measured the results in terms of the
average Hamming distance between the LP’s solution, which is integral, and the rounded solution returned by
the algorithms.

E.2 Random Graph Experiments

While the grid topology oﬀers a consistent platform to evaluate the algorithms, we also considered randomly
generated graphs, speciﬁcally Erd˝os-R´enyi random graphs. These graphs are constructed by iterating through
every pair of the n vertices. Then, an edge is drawn between vertex i and j with probability p. Speciﬁcally, we
chose p = 1.1 log n
, which is just large enough that the graph is almost surely connected. We found these to be
useful hyperparameter because any lower and the graph would largely be disconnected. Any higher and typically
we found the LP was not tight. We chose the same multi-label Potts model for generating the cost vector C.

n

With these experiments, we intended to understand how diverse graph topologies would aﬀect convergence due to
randomness. In particular, we restricted the degrees of the graph to deg(G) = 5, 10 to observe how the algorithms
behave on denser graphs.

