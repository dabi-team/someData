0
2
0
2

t
c
O
5

]
P
A

.
t
a
t
s
[

3
v
6
3
9
1
0
.
9
0
9
1
:
v
i
X
r
a

State Drug Policy Eﬀectiveness: Comparative
Policy Analysis of Drug Overdose Mortality
Jarrod Olson, MPP∗; Po-Hsu Allen Chen, PhD; Marissa White, MPH; Nicole
Brennan, PhD (Battelle Memorial Institute†); and Ning Gong, PhD (Legal
Sciences, LLC‡)

Abstract

Opioid overdose rates have reached an epidemic level and state-level policy innova-
tions have followed suit in an eﬀort to prevent overdose deaths. State-level drug law is a
set of policies that may reinforce or undermine each other, and analysts have a limited
set of tools for handling the policy collinearity using statistical methods. This paper
uses a machine learning method called hierarchical clustering to empirically generate
“policy bundles” by grouping states with similar sets of policies in force at a given time
together for analysis in a 50-state, 10-year interrupted time series regression with drug
overdose deaths as the dependent variable. Policy clusters were generated from 138
binomial variables observed by state and year from the Prescription Drug Abuse Policy
System. Clustering reduced the policies to a set of 10 bundles. The approach allows for
ranking of the relative eﬀect of diﬀerent bundles and is a tool to recommend those most
likely to succeed. This study shows that a set of policies balancing Medication Assisted
Treatment, Naloxone Access, Good Samaritan Laws, Medication Assisted Treatment,
Prescription Drug Monitoring Programs and legalization of medical marijuana leads to
a reduced number of overdose deaths, but not until its second year in force.

Introduction

Between 1999 and 2017, the total number of opioid related deaths in the U.S. increased more
than 509 percent (Centers for Disease Control and Prevention, 2018). In an eﬀort to slow
the “epidemic level” rise in mortality rates, law makers have developed a myriad of policies
targeting prevention, treatment and judicial consequences.

Since 1999, Legal Science (2018) has cataloged state-level drug policies into the Prescription
Drug Abuse Policy System (PDAPS) across 50 states. PDAPS codes speciﬁc laws in force in
a state as a policy and this paper uses this same narrow deﬁnition of policy. Between 2000
and 2016 there has been a 2092 percent increase in state-level drug-related policy changes
(i.e. implementing or repealing a policy). The opioid epidemic has impacted states at varying
times and to varying degrees resulting in segmented policies with variation from state to state.
As of 2016, each state had an average number of 33.25 policies targeting the reduction of
opioid-related deaths. While federal drug policy still reﬂects a heavy focus on criminalization,

∗Corresponding author, olsonjr@battelle.org
†505 King Ave, Columbus, OH 43201
‡WeWork c/o Legal Science 1601 Market Street, Fl. 19 Philadelphia, PA 19103

1

 
 
 
 
 
 
these state-level policies focus on a wide range of topics, from marijuana legalization, to
mandatory sentencing for opioid distribution.

With this much variation in the policy system, decisionmakers are reasonably challenged to
understand which policy, or combination of policies, to implement to minimize drug overdose
deaths. With more than 145 policies nationwide there are 8.0479261 × 10251 unique policy
combinations to select from. The comparative policy analysis (CPA) literature has attempted
to address this complex environment, but existing methods are inadequate to prioritize
policies in such a rapidly changing environment. Qualitative CPA methods are limited in
their ability to generalize, while quantitative CPA studies must limit their investigation to
only one or a small sub-set of policies to allow for statistical testing, eliminating the ability
to prioritize.

This paper identiﬁes and explicitly estimates the relative eﬀect of policy clusters composed
of sets of policies implemented together in states over time. It utilizes an existing data set
(PDAPS), a well-founded methodology drawn from quantitative CPA, and a new algorithm
to assess and prioritize the policy interventions employed in the recent history of state-level
drug policy intervention. We hypothesize that sets of policies, generated empirically using
hierarchical clustering based on the time and place they were implemented together, will
change the drug overdose death rate. We will test this hypothesis using a cross-sectional,
interrupted time-series analytical approach. This approach blends work from the qualitative
CPA discipline with quantitative approaches.

Background

The Centers for Disease Control and Prevention (2018) calls the current opioid overdose crisis
an epidemic. Opioids are the leading cause of death for people under the age of 50, and about
130 Americans die every day from an opioid overdose. The CDC has identiﬁed three “waves”
of drug overdose deaths: increased prescription of opioids in the 1990s with deaths increasing
since at least 1999 at a steady rate, the growth of heroin starting in about 2010, and the
sudden climb in deaths caused by synthetic opioids such as Fentanyl starting around 2013.

Speciﬁc policy approaches have developed to address each wave and state-level innovations
have reacted with rapid growth and massive churn in state-level policy since 2000, as shown
in Figure 1. These innovations include the development of Prescription Drug Monitoring
Programs (PDMP) to address patient-speciﬁc prescribing behavior, and policies to address
the rising death rate attributed to heroin and Fentanyl through Naloxone Access Laws
(NAL) and Good Samaritan Laws (GSL), which both aim to respond to actual overdoses and
prevent deaths. Each policy addresses diﬀerent causal issues associated with drug overdose.
PDMP increases scrutiny on the supply of opiates, typically by creating a registry to track
prescriptions. NAL improves access to medication that reverse active opioid overdoses,
and GSL reduces the risk for persons reporting a drug overdose (who might otherwise be
arrested for engaging in a criminal act like consuming opiates with the person experiencing
an overdose). Haegerich, Paulozzi, Manns, & Jones (2014) found that there is very limited
reliable data about drug policy eﬀectiveness, noting that “the quality of evidence for the
impact of state legislation on provider behavior, patient behavior, and health outcomes is

2

Figure 1: Mean Number of State Drug Laws Changed, by State.

low,” and that without improvements and studies of eﬀectiveness, states, regulatory agencies,
and organizations will be unable to make informed decisions.

In response to this innovation in drug policymaking, a number of studies have been conducted
to understand which policies work to reduce drug overdose deaths, and the context around it.
Several authors have attempted studies that either articulate every minimal diﬀerence in laws
(as passed), often leading to a narrow qualitative case study approach (see Ritter, Livingston,
Chalmers, Berends, & Reuter, 2016 for several). The literature on these qualitative case studies
often does not generalize, but can help answer questions about the policy implementation
and hypothesize the conditions that facilitated or blocked success (Ritter et al., 2016). Other
authors have attempted to ﬁnd more precise and generalizable estimates of overall eﬀect
using quantitative methods, or mixed-methods that utilize qualitatively deﬁned “sets” of
policies (e.g. Blackman, Wistow, & Byrne, 2013; Devers, Lallemand, Burton, Zuckerman,
& Authors, 2016; and Pardo, 2017). Policies that are identiﬁed and used in quantitative
papers often rely on a summative index score, potentially derived from empirical methods,
data-driven policy coding (such as the data set produced by Legal Science), diﬀerences based
on geography (Keele & Titiunik, 2015), or described policy diﬀerences that can be coded for
analysis. These approaches typically rely on a variety of statistical methods (Ritter et al.,
2016).

Each policy implemented in a state has speciﬁc details distinguishing it from other policies
that are critical for comparing eﬀectiveness. These diﬀerences are often ignored or treated
minimally by controlling for the jurisdiction as the intervention, or all of the policies within a
jurisdiction, leading to “a hazy deﬁnition of policy that leads to confusion in the speciﬁcation
and measurement of the phenomena being studied” (Burris, 2017). Burris (2017) propose
“the use of transparent, reliable method to produce detailed observations of the apparent
characteristics of policy that can be used in evaluation research.” An individual policy
does not deﬁne the entire legal environment that might aﬀect outcomes. As an illustration,

3

0.000.030.060.090.122000200520102015YearMean Number of Laws ChangedTable 1: CPA Characteristics as deﬁned by Ritter, 2016

Characteristic
Jurisdiction

Treatment of Time

Purpose

Deﬁnition
Legal entity used as unit of
analysis
How is time used in the
comparison
Study’s purpose

This Study
50 States

Lagged independent variable
with policy shock
Identify highest impact sets
of policies on reducing drug
overdose deaths

Method
Comparative Design How is comparison

Quantitative or Qualitative Quantitative

operationalized

Policy Speciﬁcation How is the policy

operationalized

Comparing concurrent state
policy implementation
Drug-related policies
clustered together as
"bundles"

studying NAL in isolation will miss the critical importance of GSL as an enabler. GSLs
address the problem that individuals can be arrested for illegal possession and use of opioids
if they call 911 for a friend experiencing an overdose, thus disincentivizing a person from
calling for help, where Naloxone might be distributed broadly (i.e. ﬁrst responders).

Finally, in both qualitative and quantitative methods, there is often a lack of theory applied
to analysis. Baptist, Carrie & Befani, Barbara (2015) note that theory is a critical tool
for triangulating ﬁndings, or making theory-based qualitative evaluations, and is a critical
ingredient in so-called set-based methods for classifying data into groups for analysis. In
quantitative methods, a strong theory of change is critical to understand the parameters
of the analysis, as well as identify a spurious ﬁnding. A theory of change also guides the
scientiﬁc questions asked over the course of the study (Burris et al., 2010).

Methods

CPA is a broadly deﬁned discipline for theory-driven comparisons of policy eﬀectiveness. It
has no singular set of methodological tools but utilizes the most appropriate analytical method
for the policy under assessment. In all cases, CPA aims to explain the relationship between
policies and their eﬀects (Ritter et al., 2016). Necessarily, this includes a speciﬁed outcome
and a given policy, studied over two or more jurisdictions. In Table 1 the characteristics of
this study are described using Ritter et al. (2016)’s framework.

Our speciﬁcation follows from Burris et al. (2010), which frames the role of public health law
on health outcomes.Laws, which are “interventional,” “infrastructural,” or “incidental” change
legal practice, which aﬀects both changes in behavior directly, and changes in environment
that indirectly lead to additional changes in behavior. These changes in environment and
behavior yield changes in population health. In this case, viewing drug overdose deaths as a
public health problem suggests that all corresponding changes in legal practice will aﬀect

4

the drug overdose rate, including changes in drug enforcement (interventional), the addition
of new infrastructure to support drug enforcement (infrastructural), or policies that aﬀect
health as a secondary feature (incidental).

Figure 2 shows the theoretical model from Burris et al. (2010) modiﬁed to represent this
study. We are directly modeling sets of laws, changes in environments (through a set of
control variables), and the outcome (drug overdose deaths), i.e. B-C-D-E. We expect laws
that reduce drug overdose deaths through environmental changes that also aﬀect behavioral
changes to reduce drug overdoses the most. However, many environmental changes could
yield a behavior change that has a mitigating eﬀect. For example NALs aim to reduce drug
overdose deaths by access to Naloxone for people experiencing an opioid related drug overdose.
One potential unintended consequence may be that this environmental change could increase
drug use, and overdoses if the population believes an overdose can be easily counteracted.

Figure 2: Public Health Legal Research Framework, Applied to this Analysis.

We specify our policies using categorical classiﬁcations of individual policies that are not
mutually exclusive, and are often implemented within a system of policies that are both
complementary and conﬂicting. Those speciﬁcations are converted into bundles based on the
states that implemented them at the same time. As an example, if policy one and policy two
are implemented in states x and y in the same years, but policy three is only implemented in
state z in a diﬀerent year, then there are two bundles, one for policies one and two, and one
for policy three.

This paper uses a time-series, cross-sectional method with an interrupted time-series design
as described by Bernal, Cummins, & Gasparrini (2017) to estimate the eﬀect of policy
bundles on drug overdose deaths. The intervention (intervention) is conﬁgured as a mutually

5

exclusive dummy variable, with panel data of states (s) over time (t). Using a ﬁxed-eﬀects
regression (segmentation), where time-invariant factors of each observation (s) are controlled
using a dummy for the unit of analysis (i.e. state-years). Correlation and temporal order are
necessary to establish causality, so the policy clusters are lagged by one year. Equation (1)
shows a general interrupted time-series design using panel data and an intervention.

outcomets = β0 + βttime + βsunitOf Analysis + βkcontrolsk(t)+
βiinterventions(t−1) + βdeaths(t−1) + (cid:15)

(1)

In this case, the “intervention” is the policy bundle in force within a given state. Drawing
from Burris et al. (2010), this paper includes a set of sociodemographic and environmental
factors as controls. Because drug overdoses deaths are a count variable, highly dependent on
population, the value is log transformed and normalize by population in a Poisson regression
as shown in Equation (2).

drugOverdoseDeathsP erCapitats = βsState + β1 log(P opulationts) + β2Genderts+
β3P rescribingRatets + β4Ginits + β5Incomets + β6Deathss(t−1)+
βcpolicyClusterst−1) + (cid:15)

(2)

Variables for the equation are drawn from a variety of publicly-available, state-level datasets
and the policyCluster variable is constructed for this analysis from the PDAPS datasets.
Although policy and overdose data are available from 1999 forward, data analysis is limited to
2006 - 2016 when most of the opioid-related policy changes started. Table 2 shows summary
information about each variable.

Table 2: Data characteristics for analysis variables, n observation = 1122.

Variable

Type

Years

drugOverdoseDeaths1 Count
P opulation2
Count
P rescribingRate3
Rate
Gini4
Continuous
Income5
Continuous
policyCluster6
Multinomial
Gender7
Binomial

2006-2016
2006-2016
2006-2016
2006-2016
2006-2016
2006-2016
2006-2016

n

1122
1122
1122
1122
1122
1122
1122

Mean

SD

339.14
3051925.43
80.96
0.46
52.53
NA
NA

408.60
3425227.85
22.98
0.02
8.81
NA
NA

1Centers for Disease Control and Prevention (2017)
2Centers for Disease Control and Prevention (2017)
3Disease Control and Prevention (2019)
4Bureau (2017b)
5Bureau (2017a)
6Generated in this analysis from Legal Science (2018)
7Centers for Disease Control and Prevention (2017)

6

Outcome Data: CDC Wonder Data

Wide-ranging Online Data for Epidemiologic Research (WONDER) (Centers for Disease
Control and Prevention, 2017) is an online database that makes several CDC datasets
available to public health professionals. This paper includes the drug-overdose death rates
and prescribing data. WONDER suppresses the number of deaths if there are fewer than 10
deaths in a query to protect personal privacy. To reduce the amount of censored data, yearly
instead of monthly age-adjusted drug-related overdose underlying cause of death counts are
used for all 50 states and the District of Columbia (DC) by gender between 1999 to 2016
for a total of 1,836 observations, where 15 (0.8 percent) censored data were imputed by ﬁve
(median of 0-10). Yearly state-level population data were also obtained from WONDER.

Figure 3 shows the box plots of drug-related overdose death rates (number of deaths divided
by the population size) reported in WONDER from 1999 to 2016 across 50 states and DC
by gender. On average, the drug-related overdose death rates have increased 513 percent
between 1999 and 2016, and the slope of the trend has become steeper in recent years. During
1999 to 2016, West Virginia (17.3), Kentucky (15.5), and Nevada (14.2) had the highest
average drug overdose death rates, while Maryland (2.2), North Dakota (2.8), and South
Dakota (3.0) had the lowest average death rates. Rates of drug-related overdose death are
signiﬁcantly higher for males than females. The male overdose rate increased from 5.1 per
100,000 population in 1999 to 24.3 while the rate for female increased from 1.9 to 11.3.

PDAPS

PDAPS is a data set to track key state laws related to prescriptions drug abuse, which
provides a source of rigorous legal data to compare policies across time and states (Legal
Science, 2018). The data for this analysis is broken down into 16 topic areas (data sets)
including topics like Expanded Access to Naloxone, Good Samaritan 911 Immunity, Medical
Marijuana, Opioid Related Controls, Prescription Drug Monitoring Program, and others.
Generally, the data in PDAPS are a set of time-varying binary variables (Yes/No questions)
to capture if a law was implemented or not for each state at a speciﬁc period of time. There
are also some variables with multiple values nested to those binary variables for providing
state-speciﬁc details. All binary variables in PDAPS were extracted from 16 data sets
resulting in 145 state-law variables. While PDAPS records nested sub-questions as missing
data if the law in the main question was not implemented, here the missing data is converted
to “No” to represent the truth of fact that those nested-laws were also not implemented.
Figure 4 displays the distribution of starting time of laws to demonstrate that although the
ﬁrst implemented state law for drug abuse can be traced back to 1974, most laws (more than
90 percent) were implemented after 2006. Therefore, even though WONDER provides data
for opioid overdose death from 1999 to 2016, this paper focuses on the eﬀects of drug laws on
opioid overdose death rate from 2006 to 2016.

Figure 5 shows a summary of the policy data for a selection of states. It summarizes the
data into “policy groups” from PDAPS, which are sets of policies addressing a certain policy
area (e.g. NAL). These groups are diﬀerent from the clusters to be used in this analysis. This

7

Figure 3: Death Rate Per 100,000 Population.

8

0204060199920002001200220032004200520062007200820092010201120122013201420152016YearDeath Rate per 100kGenderFemaleMaleFigure 4: Policy Start Years by PDAPS Dataset.

9

2006199520002005201020152020Drugged DrivingDirect DispensingMM DispensariesGood SamaritanMedication−Assisted TreatmentMM CaregiverMM PatientsMM Product SafetyNaloxoneOpioid Prescribing GuidelinesPain ClinicPDMP AccessPDMP AdminPDMP DatesPDMP ReportingRecreational MarijuanaYear* One datapoint was removed from PDMP Dates with start year 1974.        ** MM denotes Medical Marijuana and PDMP denotes Prescription Drug Monitoring Programs.Figure 5: Selected States and Policy Utilization by Policy Group.

shows the range of implementation, comparing a low-population state like Wyoming and
a high-population state like California, or a state struggling with extremely high overdose
death rates like Ohio. Darker colors indicate that the state has implemented closer to 100
percent of the policies within the group.

A common approach to utilize PDAPS data is to select a small-set of binary variables as
explanatory variables for ﬁtting a (Poisson) regression model to determine if the implemented
laws are associated with changes in opioid-related overdose deaths, (e.g. Bachhuber, Saloner,
Cunningham, & Barry, 2014; Patrick, Fry, Jones, & Buntin, 2016; Rees, Sabia, Argys,
Latshaw, & Dave, 2017). However, as noted by Pardo (2017) and Fink et al. (2018), this
approach may face problems of multicollinearity, inadequate adjustment for competing laws,
and subjectivity in variable selection, all of which increase the risk of bias for studies. To avoid
multicollinearity problems, Pardo (2017) created a score function to summarize prescription
drug monitoring programs; however, this approach is still subjective in assigning diﬀerent
weights to administrative laws (Fink et al., 2018) and, perhaps more importantly, it loses the
information of the eﬀects on speciﬁc laws.

Several machine learning techniques were considered for reducing the dimension of PDAPS
data to a readable level without losing much information, but most of them have shortcomings.
Unsupervised learning methods (e.g., Principal Component Analysis (PCA) or Sparse PCA)

10

Direct DispenseDrugged DrivingGSLMATMedical MarijuanaNALPain Mgmt ClinicPDMPPrescribing GuidelinesRec MarijuanaCaliforniaIowaOhioWashingtonWest VirginiaWyomingStatePolicy Group0.000.250.500.751.00Policy GroupUtilizationwere used to create clusters of laws, but the meaning of those clusters was diﬃcult to interpret.
For example, what does it mean for a linear combination of several prescriptions drug abuse
related laws? A regression using a regularization technique, i.e., Lasso regression, was also
tested for selecting a subset of important explanatory variables for opioid overdose death
rate. However, neither ﬁtting a Lasso regression using laws from all 16 data sets in PDAPS
nor ﬁtting several Lasso regressions only using the laws in each data set can eﬃciently reduce
dimensionality. This may indicate that the sparsity assumption in Lasso regression (only a
small number of laws may actually be relevant to the opioid overdose deaths) is violated.

This paper creates policy bundles using hierarchical clustering on state and year direction of
the data. Instead of clustering on laws, this approach clusters the state-years with similar laws
implemented. After a suitable number of feature clusters are extracted, the corresponding
feature cluster for each state and year data can be identiﬁed. Then, those cluster features
will be treated as explanatory variables to estimate the association between laws and opioid-
related overdose deaths. The two main advantages of the proposed approach are as follows:
First, feature clusters were created without sub-setting or combining any laws, increasing the
ability to explain feature clusters. Second, this data-driven approach avoids the subjective
bias seen frequently in the literature for selecting a particular subset of laws or assigning
weights to laws.

To perform hierarchical clustering on PDAPS data, several cleaning steps data were required.
To facilitate eventual combination with overdose death rates (which are reported by year and
state), the PDAPS data needed to be re-structured from the speciﬁc dates that the law was
put into eﬀect and repealed to “years in force”. The eﬀective date and valid through date for
each state-law in PDAPS is used to identify the year for this study. If a particular state-law
was implemented more than six months within a year, the law was treated as “in eﬀect” for
that year. Second, all laws in a binary variable form in PDAPS were selected except four
policies with missing data and three laws without variation across the United States from
2006 to 2016, which results in 138 binary variables in total. Table 3 shows the policies
removed from consideration. Then, the distance matrix was calculated using Gower distance
(Gower, 1971), and the hierarchical clustering was performed with complete linkage (Maechler,
Rousseeuw, Struyf, Hubert, & Hornik, 2018). Finally, 10 feature clusters were selected based
on the result of elbow method. The elbow method recommends thresholds for the number
of clusters based on a decrease in the slope of the explainability of the clustering model
for each threshold (Zambelli, 2016). Figure 6 shows the elbow plot used for the decision.
Because four clusters is the ﬁrst major change in slope, and at 20, there is highly diminishing
marginal change, those cases will be considered as sensitivity cases. All of these algorithms
were executed in R (R Core Team, 2018).

Other Variables

Several time-varying demographic measures (confounding factors) are also considered, includ-
ing Gini index, median household income, and opioid prescribing rate by state and year, and
proportion of adults aged more than 25 years by state, year, and gender, where GINI index
and household income were obtained from American Community Survey (ACS) in United
State Census Bureau, prescribing rate was measured by Legal Science, LLC, and proportion

11

Variable name

DD_PA

DD_PAlimit

Table 3: Policies removed from clustering.

Cause

Description

Missingness Are Physician Assistants authorized to
directly dispense controlled substances

Missingness Are Physician Assistants limited to

dispensing medications to the extent the
supervising physician authorizes

DD_PArur

Missingness Are practitioners regulated diﬀerently

share.dispecheck

Missingness Does the state require dispensers to check

based on the geographic location of their
oﬃce

OPG_.Acute.Penalty

Fixed

OPG_EDPenalty

Fixed

naloxone.crimpossessionprog Fixed

the PDMP before dispensing controlled
substances
Is there a mandatory penalty for failure to
comply with the acute pain guidelines

Is there a mandatory penalty for failure to
comply with the emergency department
guidelines
Is participation in a naloxone
administration program required as a
condition of immunity

12

Figure 6: Elbow Plot for Hierarchical Clustering.

13

468105101520Number of ClustersWithin clusters sum of squares (SS)Table 4: Cluster descriptions and counts.

Cluster

N Description

1

2

3

4
5

6

7

8

298 Represents early stage where a small set of laws was implemented, not
including Medication-Assisted Treatment Laws and PDMP Laws.
39 Similar to Cluster 1, but more PDMP laws were implemented and Pain

Management Clinical laws were implemented.

17 Similar to cluster 2, but more focus on Pain Management Clinical laws

and MAT.

105 Cluster with fewest laws, mostly just MAT.
33 Focused on PDMP, with medical marijuana, MAD, and GSL focus.

9 Similar to cluster 5, but with less focus on PDMP, and adding

recreational marijuana laws.

20 Similar to cluster 6, bit no recreational marijuana laws and generally

fewer laws.

11 Similar to cluster 7, but adding more laws from Medical Marijuana,

prescribing guidelines, and direct dispensing.

9
10

9 Heavily focused on GSL, PDMP, NAL, Medical Marijuana and MAT.
20 Similar to cluster 9, but lower focus on GSL, PDMP, and NAL, with a

heavier focus on Medical Marijuana.

of adults was derived from 1-year ACS data and estimated using table of age and sex in ACS
ﬁve-year Estimates for each year, state, and gender. These variables are often suggested as
relevant variables for opioid overdose death rate in literature (see for example Bachhuber et
al., 2014; Pardo, 2017; Rees et al., 2017).

Results

The clustering into 10 clusters generated a data set that was used in the regression. As
mentioned, each cluster contains several state-year data across 138 law variables. These
policies are grouped in PDAPS by Legal Science (2018) and we call those groups “Policy
Groups” for this analysis. As a summary of the clusters, Figure 7 shows the relative eﬀect of
each policy group on the cluster deﬁnitions. Because of the limited space, the ﬁgure only
shows the corresponding name of topic area for each law. The list of full policy questions in
the ﬁgure can be found in the online appendix8. Using the ﬁgure, the key features of the 10
clusters and the number of observation (state and years) in each cluster are summarized in
Table 4. More detailed plots, showing each policy group’s full set of policies are available in
the online appendix9.

The results shown in table 5 allow us to reject the null hypothesis that the policy cluster
do not aﬀect drug overdose deaths. The ﬁxed eﬀects model (Y ear and State) shows that

8All appendices are available by request from the corresponding author
9All appendices are available by request from the corresponding author

14

Figure 7: Policy Group inﬂuence on Cluster Deﬁnition.

15

Direct DispenseDrugged DrivingGSLMATMedical MarijuanaNALPain Mgmt ClinicPDMPPrescribing GuidelinesRec Marijuana12345678910Cluster NumberPolicy Group0.00.20.40.6Relative ClusterInfluencethere is a statistical eﬀect from including the policy clusters. Speciﬁcally, the log-likelihood of
the model improves and the Aikake Information Criterion (AIC) decreases indicating better
predictiveness without sacriﬁcing eﬃciency. Because of the ﬁxed eﬀects, the table only shows
the relative diﬀerence between clusters two to 10 and cluster one. The results omit the State
and Year coeﬃcients for simplicity. The eﬀect of Gender does not change from model to
model, but the eﬀect of P rescribing.Rate is shown to be ineﬃcient and biased (changing
coeﬃcient direction and becoming insigniﬁcant). Gini is moderated and Income is slightly
moderated (recalling that Income has been scaled to the thousands). Clusters ﬁve, seven,
and 10 all show an increased number of overdose deaths when implemented, compared to
cluster 1.

The impact of a policy is possibly diﬀused or distributed over multiple years. To consider
the sensitivity of the model, diﬀerent time lags are included to show a policy’s impact over
time. In order to save space, Table 5 omits the additional lag values after the causal lag (1
year), depending on the model used. In the model with just a two year lag, the AIC and log
likelihood worsen, suggesting that the immediate eﬀect is important to capture. Model three
shows a ﬁve-year dissipating impact, and has the largest reduction in AIC.

Figure 8 shows the relative impacts of the diﬀerent results visually, allowing for comparison
of the policies as a collection. It is estimated by generating a synthetic data set holding all
factors equal and varying only the cluster. The ﬁgure shows that diﬀerences between clusters
are sometimes minimally consequential. However, the diﬀerence between the best performing
cluster (cluster nine) and the worst performing (cluster 10) is signiﬁcant (conﬁdence intervals
do not overlap) and substantial (approximately a 30% decrease).

The impact of the diﬀerence in eﬀectiveness in policy for a speciﬁc state, like Washington,
is substantial. Assuming a change in the year 2010, Figure 9 shows the potential change
in trajectory for both the single lag and the dissipating models for a world where cluster
nine policies are implemented (“simulated”) vs. not (“real-world”). The simulated results
show an immediate interruption for the one-year lag model and a one-year delayed impact
in the ﬁve-year dissipating model (illustrating the “interrupted time-series design”). The
ﬁgure also shows the complex interactions between environmental factors and policy change
outcomes for the diﬀerent genders. The diﬀerences for men are larger than for women. The
ﬁgure compares the predicted change in Washington of the policies with the multiyear shock
model, and the eﬀect is slightly larger, but also delayed compared to a single lag. with the
multiyear model, but model performance increases substantially, suggesting that this is a
more reliable prediction.

To rule out selection bias from our selection of the number of clusters, Table 6 compares
the eﬀects of diﬀerent numbers of clusters. The 20 cluster model has the highest model
performance, but as discussed above, is somewhat more complicated to explain.

Discussion

This study shows policy is an important variable in the comparative state analysis of drug
overdose deaths and hierarchical clustering can illustrate the relative impact of policies on

16

Table 5: Regression Model Results for overdose deaths.

GenderMale

Prescribing.Rate

Gini

Income

Deaths.lag1

factor(cluster.lag1)2

factor(cluster.lag1)3

factor(cluster.lag1)4

factor(cluster.lag1)5

factor(cluster.lag1)6

factor(cluster.lag1)7

factor(cluster.lag1)8

factor(cluster.lag1)9

factor(cluster.lag1)10

Observations
Log Likelihood
Akaike Inf. Crit.

Note:

Base

(1)

0.669∗∗∗
(0.004)
0.004∗∗∗
(0.0004)
−2.684∗∗∗
(0.516)
−0.003∗∗∗
(0.001)
0.0001∗∗∗
(0.00001)

Dependent variable:

Deaths

10Clust

10Clust-2Yr

10Clust-Dissipate

(3)

0.672∗∗∗
(0.004)
0.001∗∗
(0.0005)
−0.231
(0.541)
−0.002∗∗
(0.001)
0.0001∗∗∗
(0.00001)

(2)

0.670∗∗∗
(0.004)
−0.0002
(0.0005)
−2.131∗∗∗
(0.538)
−0.002∗∗∗
(0.001)
0.0001∗∗∗
(0.00001)
−0.125∗∗∗
(0.009)
−0.102∗∗∗
(0.010)
−0.042∗∗∗
(0.008)
0.029∗∗∗
(0.010)
−0.136∗∗∗
(0.013)
0.077∗∗∗
(0.012)
−0.073∗∗∗
(0.016)
−0.137∗∗∗
(0.011)
0.221∗∗∗
(0.010)

(4)

0.664∗∗∗
(0.004)
−0.001∗∗∗
(0.0005)
−1.283∗∗
(0.551)
−0.004∗∗∗
(0.001)
0.0001∗∗∗
(0.00001)
−0.072∗∗∗
(0.013)
−0.055∗∗∗
(0.015)
−0.010
(0.011)
0.010
(0.013)
−0.038∗∗
(0.015)
0.129∗∗∗
(0.016)
−0.040∗
(0.024)
0.015
(0.017)
0.286∗∗∗
(0.013)

1,121

1,121

−10,448.770 −9,829.777
19,809.550
21,029.540

1,120
−9,957.005
20,064.010

1,117
−9,324.868
18,871.740

∗p<0.1; ∗∗p<0.05; ∗∗∗p<0.01

17

Figure 8: Relative Eﬀects of Policy Clusters with 2 ∗ SE Error Bars.

18

60070080096238415710Cluster (lagged 1 year)Overdose deathsFigure 9: Simulated Impact of Change to Policy 9 in Washington, 2010.

19

FemaleMale200620082010201220142016200620082010201220142016200400600800Cluster (lagged 1 year)Overdose deathsmodeldissipateone−yearscenarioReal−WorldSimulated20Clust

20Clust-dissipate

Table 6: Sensitivity regression model results.

Dependent variable:

Deaths

10Clust

(1)

0.670∗∗∗
(0.004)
−0.0002
(0.0005)
−2.131∗∗∗
(0.538)
−0.002∗∗∗
(0.001)
0.0001∗∗∗
(0.00001)

4Clust

(2)

0.673∗∗∗
(0.004)
0.001∗∗
(0.0005)
−4.021∗∗∗
(0.527)
−0.005∗∗∗
(0.001)
0.0001∗∗∗
(0.00001)

(3)

0.669∗∗∗
(0.004)
−0.0003
(0.0005)
−2.470∗∗∗
(0.547)
−0.002∗∗∗
(0.001)
0.0001∗∗∗
(0.00001)

1,121

1,121
−9,829.777 −10,333.000 −9,677.593
19,525.190
20,803.990
19,809.550

1,121

(4)

0.661∗∗∗
(0.005)
−0.001
(0.001)
−1.187∗∗
(0.578)
−0.004∗∗∗
(0.001)
0.0001∗∗∗
(0.00001)

1,117
−8,756.953
17,835.910

∗p<0.1; ∗∗p<0.05; ∗∗∗p<0.01

GenderMale

Prescribing.Rate

Gini

Income

Deaths.lag1

Observations
Log Likelihood
Akaike Inf. Crit.

Note:

the change in drug overdose deaths. Hierarchical clusters use empirical, and reproducible
methods to segment individual policies that are highly correlated into bundles, and those
policy bundles can have a highly diﬀerentiated eﬀect. The sensitivity analysis suggests there
are major challenges in selecting the “correct” number of clusters, and also that policy has a
changing eﬀect over time.

This changing eﬀect over time ﬁts an assumption where behavior adapts to new policies
and the policy impacts are eventually muted. This learning process necessitates continual
innovation in policy to show continued growth. As an illustration of this learning, Figure
10 shows the relative eﬀect of policy bundle nine from the 10 policy bundle over ﬁve years.
In this case, the initial neutral eﬀect in the ﬁrst year ultimately leads to a reduction in
drug overdoses in years two and 3, with a neutral impact thereafter. Controlling for time
reduces the likelihood that this pattern is simply the long term trend toward increased opioid
overdose deaths.

Based on these results, policy bundle nine has the largest eﬀect. There are 18 state-years
matching that bundle (California and New Mexico, ranging from 2011-2015). Of those
state-years, there are 74 total policies in force, with 30 implemented in all state-years. Table
7 shows the policies that were in place in all states for cluster nine (30 policies). This cluster
is dominated by GSL, PDMP, NAL, MAT, and Medical Marijuana policies. There is balance
in the legalization, treatment, and protection from prosecution, with heavy emphasis on
access to medical marijuana.

20

Figure 10: Attenuation of Policy Impact Over Time for Cluster nine.

21

−0.15−0.10−0.050.000.05factor(cluster.lag1)9factor(cluster.lag2)9factor(cluster.lag3)9factor(cluster.lag4)9factor(cluster.lag5)9ClusterCoefficient of effectTable 7: Policies in cluster nine in force in all state-years.

Description
Does the law allow in-state law enforcement to access PDMP data
Is treatment planning for admitted patients required at OTPs
Is periodic review of the treatment plan required by law
Does the law explicitly provide any aﬃrmative defenses for the use of medical
marijuana
Does the state allow qualifying patients to designate a caregiver for assistance in the
use of medical marijuana
Are caregivers allowed to cultivate marijuana
Does the state have a law authorizing adults to use medical marijuana
Are registered caregivers who comply with the law exempt from arrest
Are caregivers allowed to transport medical marijuana
Does the law explicitly allow cardholders to cultivate medical marijuana plants
Does the state have a law regulating medical marijuana dispensaries
Are dispensaries required to operate as not-for-proﬁt entities
Does the state law provide an explicit procedure for adding additional qualifying
diseases
Are minors authorized to use medical marijuana
Does the state law have explicit privacy provisions related to medical marijuana
cardholders
Does the jurisdiction have a naloxone access law
Do prescribers have immunity from civil liability for prescribing dispensing or
distributing naloxone to a layperson
Do prescribers have immunity from criminal prosecution for prescribing, dispening or
distributing naloxone to a layperson
Is a layperson immune from criminal liability when administering naloxone
Do dispensers have immunity from civil liability for prescribing, dispensing or
distributing naloxone to a layperson
Do dispensers have immunity from criminal prosecution for prescribing, dispensing or
distributing naloxone to a layperson
Are prescribers required to act with reasonable care
Does the law explicitly allow out-of-state law enforcement to access PDMP data
Does this state have legislation authorizing access by professionals to a PDMP system
Does this state have legislation authorizing a PDMP
Does the state have legislation authorizing a PDMP
Is the PDMP permitted or required to identify suspicious or statistically outlying
prescribing dispensing or purchasing activity
Does the law permit or require PDMP to release de-identiﬁed data for research or
education
Does this state have legislation requiring dispensers to report data to the PDMP

These analytical tools can also help understand states that are outperforming (often called

22

“bright spots”) and states that are under performing their expectations. These states (in
a speciﬁc time-frame) can be useful in case studies to help drive new research. Detailed
qualitative CPA can identify potential hypotheses on a policy bundle’s overall impact that
can then feed a virtuous cycle of research. Given the robust documentation of the policy
environments in each state, this could lead to new policy innovations and evaluations. This
also provides an opportunity to identify details about policies as implemented, compared to
policies as stated. The critical importance of this diﬀerence was highlighted by Ritter et al.
(2016). Figure 11 shows a simple analysis showing some of these states.

Limitations

This study and approach produced new insight into the eﬀectiveness of the policy system,
illustrating how policies can be complementary and supportive or contradictory and destructive
at reducing drug overdose deaths. There are limitations that should be addressed for future
research into both the conclusions of the study and the clustering approach used to generate
policy bundles.

Future research should address the speciﬁc cause of death more directly as an outcome and
the eﬀect of policy bundles on those death rates to provide more detailed information to
policymakers. While opioid overdose is the leading cause of drug overdose deaths, other drug
overdose deaths are incorporated in this publicly-available dataset. The policies in this case
are not limited to just opioid overdoses, but primarily focus on those policies. Future research
using more detailed data, some of which might not be publicly available would improve those
results.

This study also fails to directly model an important predictor of drug overdoses as an
independent variable: drug use (a behavior change). NSDUH data would be a useful source
for the relationship between policy and drug use, but handling the aggregation of that data
for state-level analysis is a challenge beyond the scope of this paper.

While hierarchical clustering substantially reduced the complexity of the data set (from 138
policies to four, 10, or 20, depending on the scenario), the explainability of the bundles is
critical to the ﬁnding’s ability to be used in a policymaking context. Future work should
leverage legal analysts and data visualization tools to best understand these trade oﬀs. While
the model with 20 bundles was the most predictive, it also suﬀered from potential over-ﬁtting
and explainability challenges. Selection of the “right” number of clusters should be considered
in future research.

Finally, the quality of data available using publicly available national datasets like CDC
WONDER is diﬃcult to assess. The data is drawn from medical examiner reports on cause of
death, and depend extensively on the quality of that observation and reporting. Additional
research into the reliability of outcome reporting for drug overdose deaths would strengthen
the conclusions that can be drawn when using it as an outcome variable.

23

Figure 11: Bright Spot Analysis for Drug Overdose Deaths.

24

AlabamaAlaskaArizonaArkansasCaliforniaColoradoConnecticutDelawareDistrict of ColumbiaFloridaGeorgiaHawaiiIdahoIllinoisIndianaIowaKansasKentuckyLouisianaMaineMarylandMassachusettsMichiganMinnesotaMississippiMissouriMontanaNebraskaNevadaNew HampshireNew JerseyNew MexicoNew YorkNorth CarolinaNorth DakotaOhioOklahomaOregonPennsylvaniaRhode IslandSouth CarolinaSouth DakotaTennesseeTexasUtahVermontVirginiaWashingtonWest VirginiaWisconsinWyoming−1000−5000500Difference (Expected − Real World Deaths)statusAverageOver−performingUnder−performingConclusion

While drug overdose deaths have skyrocketed to epidemic levels in the U.S. (Centers for
Disease Control and Prevention, 2018) and policy innovation has attempted to keep pace,
the ability of policymakers to identify the core sets of policies that will treat the epidemic
has been limited by the methodologies of CPA. While CPA as a practice is quite diverse and
useful for some policy analysis, qualitative case studies that are diﬃcult to generalize and
quantitative studies that either lack speciﬁcity (by not considering the complexity of policy),
or lack generalizability (by not including the system of policies) have only partially served
those decisionmaking needs.

This study provides information for policymakers about the eﬀectiveness of existing drug
policies using a new method for treating policies as “bundles” empirically and estimating the
relative eﬀect of those policies. In a policymaking environment, we would propose that a
suite of policies based on the most impactful bundles (for example, bundle nine with a heavy
GSL, PDMP, NAL, MAT, and Medical Marijuana focus) would have the largest impact on
addressing the current drug overdose epidemic. Evaluators and researchers can leverage this
approach to control for collinearity in the policy system and provide more detailed results
about the sets of policies that have the most impact.

Acknowledgements

This research was funded by NIH-SBIR Research through grant 2R44DA040340-02. The
authors would like to express appreciation for extensive research assistance by Jordan Vasko
and Steven Watanabe and the support of Dr. Jeremy Bellay and Dr. Heidi Grunwald initiating
the project.

References

Bachhuber, M. A., Saloner, B., Cunningham, C. O., & Barry, C. L. (2014). Medical cannabis
laws and opioid analgesic overdose mortality in the United States, 1999-2010. JAMA Internal
Medicine, 174 (10), 1668–1673. https://doi.org/10.1001/jamainternmed.2014.4005

Baptist, Carrie, & Befani, Barbara.
(2015). Qualitative Comparative Analysis – A
Rigorous Qualitative Method for Assessing Impact Better Evaluation. Retrieved from
https://www.betterevaluation.org/en/resources/guide/qcr_a_rigorous_qualitative_
method_for_assessing_impact

Bernal, J. L., Cummins, S., & Gasparrini, A. (2017). Interrupted time series regression for the
evaluation of public health interventions: A tutorial. International Journal of Epidemiology,
46 (1), 348–355. https://doi.org/10.1093/ije/dyw098

Blackman, T., Wistow, J., & Byrne, D. (2013). Using Qualitative Comparative Analysis to
understand complex policy problems. Evaluation, 19 (2), 126–140. https://doi.org/10.1177/
1356389013484203

25

Bureau, U. S. C. (2017a). Annual Household Income: Households, 1 year Estimates, 2006-
2016.

Bureau, U. S. C. (2017b). GINI INDEX OF INCOME INEQUALITY: Households, 1 year
Estimates, 2006-2016. Retrieved from https://factﬁnder.census.gov/bkmk/table/1.0/en/
ACS/17_1YR/B19083/0100000US.04000

Burris, S. (2017). Theory and methods in comparative drug and alcohol policy research:
Response to a review of the literature. International Journal of Drug Policy, 41 (Supplement
C), 126–131. https://doi.org/10.1016/j.drugpo.2016.11.011

Burris, S., Wagenaar, A. C., Swanson, J., Ibrahim, J. K., Wood, J., & Mello, M. M. (2010).
Making the Case for Laws That Improve Health: A Framework for Public Health Law Research.
Milbank Quarterly, 88 (2), 169–210. https://doi.org/10.1111/j.1468-0009.2010.00595.x

Centers for Disease Control and Prevention, N. C. for H. S. (2017). Underlying Cause of
Death 1999-2016 on CDC WONDER Online Database. Retrieved from http://wonder.cdc.
gov/ucd-icd10.html

Centers for Disease Control and Prevention, N. C. for I. P. and C. (2018). Understanding
the Epidemic Drug Overdose CDC Injury Center. Retrieved from https://www.cdc.gov/
drugoverdose/epidemic/index.html

(2016).

Devers, K. J., Lallemand, N. C., Burton, R. A., Zuckerman, S., & Authors,
to Study Patient-
A.
Centered Medical Homes. Retrieved from https://www.urban.org/research/publication/
using-qualitative-comparative-analysis-qca-study-patient-centered-medical-homes

Using Qualitative Comparative Analysis

(QCA)

Disease Control and Prevention, C. for. (2019). US Opioid Prescribing Rate Maps Drug
Overdose CDC Injury Center. Retrieved from https://www.cdc.gov/drugoverdose/maps/
rxrate-maps.html

Fink, D. S., Schleimer, J. P., Sarvet, A., Grover, K. K., Delcher, C., Castillo-Carniglia, A.,
. . . Cerdá, M. (2018). Association Between Prescription Drug Monitoring Programs and
Nonfatal and Fatal Drug Overdoses: A Systematic Review. Annals of Internal Medicine,
168 (11), 783–790. https://doi.org/10.7326/M17-3074

Gower, J. C. (1971). A general coeﬃcient of similarity and some of its properties. Biometrics,
27 (4), 857–871. Retrieved from http://links.jstor.org/sici?sici=0006-341X%28197112%2927%
3A4%3C857%3AAGCOSA%3E2.0.CO%3B2-3

Haegerich, T. M., Paulozzi, L. J., Manns, B. J., & Jones, C. M. (2014). What we know, and
don’t know, about the impact of state policy and systems-level interventions on prescription
drug overdose. Drug and Alcohol Dependence, 145 (Supplement C), 34–47. https://doi.org/
10.1016/j.drugalcdep.2014.10.001

Keele, L., & Titiunik, R. (2015). Natural Experiments Based on Geography. Political Science
Research and Methods, FirstView, 1–31. https://doi.org/10.1017/psrm.2015.4

Legal Science, L. (2018). Prescription Drug Abuse Policy System - PDAPS. Retrieved from
http://pdaps.org/

26

Maechler, M., Rousseeuw, P., Struyf, A., Hubert, M., & Hornik, K. (2018). Cluster - Cluster
Analysis Basics and Extensions.

Pardo, B. (2017). Do more robust prescription drug monitoring programs reduce prescription
opioid overdose? Addiction, 112 (10), 1773–1783. https://doi.org/10.1111/add.13741

Patrick, S. W., Fry, C. E., Jones, T. F., & Buntin, M. B. (2016).
Implementation Of
Prescription Drug Monitoring Programs Associated With Reductions In Opioid-Related
Death Rates. Health Aﬀairs (Project Hope), 35 (7), 1324–1332. https://doi.org/10.1377/
hlthaﬀ.2015.1496

R Core Team. (2018). R - A Language and Environment for Statistical Computing. Retrieved
from https://www.R-project.org/

Rees, D. I., Sabia, J. J., Argys, L. M., Latshaw, J., & Dave, D. (2017). With a Little Help from
My Friends: The Eﬀects of Naloxone Access and Good Samaritan Laws on Opioid-Related
Deaths (Working Paper No. 23171). https://doi.org/10.3386/w23171

Ritter, A., Livingston, M., Chalmers, J., Berends, L., & Reuter, P. (2016). Comparative
policy analysis for alcohol and drugs: Current state of the ﬁeld. International Journal of
Drug Policy, 31 (Supplement C), 39–50. https://doi.org/10.1016/j.drugpo.2016.02.004

Zambelli, A. E. (2016). A data-driven approach to estimating the number of clusters in
hierarchical clustering. F1000Research, 5. https://doi.org/10.12688/f1000research.10103.1

27

