A Survey for Solving Mixed Integer Programming via Machine Learning

Jiayi Zhang1 , Chang Liu1 , Junchi Yan1∗
Xijun Li2 , Hui-Ling Zhen2 , Mingxuan Yuan2
1Department of CSE, and MoE Key Lab of Artiﬁcial Intelligence, Shanghai Jiao Tong University
2Noah’s Ark Lab, Huawei Ltd.

@sjtu.edu.cn
zhangjiayirr, only-changer, yanjunchi
}
{
@huawei.com
xijun.li,zhenhuiling2,yuan.mingxuan
}
{

2
2
0
2

r
a

M
6

]
I

A
.
s
c
[

1
v
8
7
8
2
0
.
3
0
2
2
:
v
i
X
r
a

Abstract

This paper surveys the trend of leveraging ma-
chine learning to solve mixed integer programming
(MIP) problems. Theoretically, MIP is an NP-
hard problem, and most of the combinatorial op-
timization (CO) problems can be formulated as the
MIP. Like other CO problems, the human-designed
heuristic algorithms for MIP rely on good initial so-
lutions and cost a lot of computational resources.
Therefore, we consider applying machine learn-
ing methods to solve MIP, since ML-enhanced ap-
proaches can provide the solution based on the typ-
ical patterns from the historical data.
In this pa-
per, we ﬁrst introduce the formulation and prelimi-
naries of MIP and several traditional algorithms to
solve MIP. Then, we advocate further promoting
the different integration of machine learning and
MIP and introducing related learning-based meth-
ods, which can be classiﬁed into exact algorithms
and heuristic algorithms. Finally, we propose the
outlook for learning-based MIP solvers, direction
towards more combinatorial optimization problems
beyond MIP, and also the mutual embrace of tradi-
tional solvers and machine learning components.

1 Introduction
Mixed integer programming problems (MIP) are signiﬁcant
parts of combinatorial optimization (CO) problems. Beneﬁt-
ing from the development of academic theory and commer-
cial software, MIP has become a vital capability that powers
a wide range of applications, including planning [Pochet and
Wolsey, 2010; Wu et al., 2013], scheduling [Sawik, 2011;
Keha et al., 2009], routing [Malandraki and Daskin, 1992;
Schouwenaars et al., 2001] and bin packing [Gajda et al.,
2022]. Moreover, [Paulus et al., 2021] manages to integrate
integer programming solvers into neural network architec-
tures as a differentiable layer capable of learning both the cost
terms and the constraints. The resulting end-to-end trainable
architectures are able to simultaneously extract features from
raw data and learn a suitable set of constraints that specify
any combinatorial problem. This architecture can learn to ﬁt

∗Correspondence author is Junchi Yan.

the right NP-hard problem needed to solve the task, which
demonstrate the importance of MIP in the area of combinato-
rial optimization.

When dealing with mathematical modeling problems in in-
dustrial applications mentioned above, decision variables and
integer variables are sometimes inevitable, which are mod-
eled as MIP models. For example: x cars, y packages. x, y
are integer variables here, and decimals are meaningless. One
MIP problem may contain both integer and continuous vari-
ables. If the problem contains an objective function with no
quadratic term, then the problem is termed a Mixed Integer
Linear Programming (MILP). Formally, it is given as:

min cTx

(1)

I

∈

∈

≥

Z,

b,x

j
∀

s.t. Ax

Rn xj ∈
When there is at least a quadratic term in the objec-
tive, the problem terms to a Mixed Integer Quadratic Pro-
gram (MIQP). If the model has any constraint containing a
quadratic term, regardless of the objective function, the prob-
lem is termed as a Mixed Integer Quadratic Constrained Pro-
gram (MIQCP). In this paper, we only focus on the basic
MILP, and the MIP term denotes MILP from now on.

A lower bound for optimum of MILP is provided by solv-
ing the corresponding LP relaxation of the MILP. The LP re-
laxation of is obtained by omitted the integer requirements:

min cTx
b, x

s.t. Ax

≥

∈

Rn

(2)

Exactly solving the MILP is NP-hard, that is, exponential
time solvable. While practitioners have more interested in
getting solutions of good quality as quickly as possible than in
ﬁnding a provably optimal solution. The research on how to
obtain high-quality solutions in a limited time is of practical
great signiﬁcance.

In this survey, we focus on ML-based algorithmic tech-
niques to solve MIP. These basic and well-studied techniques
can be divided into two main categories, the branch and
bound based algorithms for exact solving and the heuristic
algorithms for approximately solving. We will introduce one
by one in the next sections, and discuss other interesting di-
rections later. In modern MIP solvers, most of them are based
on the branch-and-bound method, and the cutting plane tech-
nique is often integrated into the branch-and-bound method

 
 
 
 
 
 
X
{
=

Algorithm 1: Branch-and-Bound (X, f )
1 Set L =
2 while L
3

and
}
do
∅
Select a subproblem S from L to explore
if a solution ˆx(cid:48)
f (x) < f (ˆx)
x
found then

∈ {

∈

S

|

}

Set ˆx = ˆx(cid:48)

can be

if S cannot be pruned then

Partition S into S1, S2, . . . , Sr
Insert S1, S2, . . . , Sr into L

Remove S from L

Output: ˆx

4

5

6

7

8

9

half a century ago [Land and Doig, 1960], B&B is an exact
algorithm that is proved to reach the optimal solution eventu-
ally. In this section, we ﬁrst give an overview of the general
B&B algorithm, and then we divide the existing works into
branching variable selection, node selection, cutting plane se-
lection and discuss these methods combined with machine
learning approaches in detail.

Branch-and-bound is a classic tree search method. By
divide-and-conquer, it partitions the search space by branch-
ing on variables’ values and smartly uses bounds from prob-
lem relaxations to prune unpromising regions from the tree.

∈

∈

∈

P

⊆

Deﬁne an optimization problem as

arg minx∈X f (x). In order to solve

= (X, f ), where
X (called the search space) is a set of valid solutions, and
R is the objective function. The goal is to ﬁnd an
f : X
→
optimal solution x∗
,
P
a search tree T of subsets of the search space is build. Ad-
ditionally, a feasible solution ˆx
X (called the incumbent
solution) is stored globally. At each iteration, the algorithm
X to explore from a list L of un-
selects a new subsets S
explored subsets; if a solution ˆx(cid:48)
S (called a candidate
incumbent) can be found with a better objective value than ˆx
(i.e., f (ˆx(cid:48)) < f (ˆx) ), the incumbent solution is updated. On
the other hand, if it can be proven that no solution in S has
a better objective value than ˆx( i.e. ,
f (ˆx)),
the subset is pruned (or fathomed), and the subset is termi-
nal. Otherwise, child subsets are generated by partitioning
S into an exhaustive (but not necessarily mutually exclusive)
set of subset S1, S2, . . . , Sr, which are then inserted into T .
Once no unexplored subset remain, the best incumbent so-
lution is returned; since the subset is only fathomed if they
contain no solution better than ˆx, it must be the case that
arg minx∈X f (x). Pseudocode for the generic B&B pro-
ˆx
cedure is given in Alg. 1, and an example of solving MIP by
B&B [He et al., 2014] is shown in Fig. 1.

S, f (x)

≥

∈

∈

x

∀

One critical reason why B&B is difﬁcult to formalize re-
sides in its inherent exponential nature: millions of Branch-
ing Variable Selection (BVS) decisions could be needed to
solve a MILP, and a single bad one could result in a doubled
tree size and no improvement in the search. Such a complex
and data-rich setting, paired with often a lack of formal un-
derstanding of the particular problem structure, makes B&B
an appealing ground for machine learning techniques, which
has lately been thriving in discrete optimization. Employing

Figure 1: Use branch-and-bound to solve an integer linear
programming minimization. (Credit to [He et al., 2014])

to increase the efﬁciency of branch-and-bound algorithm.
These two techniques constitute the branch-and-cut frame-
work. The common MIP solvers includes SCIP [Bestuzheva
et al., 2021], CPLEX [Cplex, 2009] and GUROBI [Gurobi
Optimization, 2020]. Due to space limitations, this paper will
not cover classical methods used in commercial solvers for
solving MIP.

There are emerging open-source libraries to facilitate the
research at the intersection of machine learning and mixed
integer programming. MIPLearn1 offers a customized li-
brary for learning-based solver conﬁguration which supports
both GUROBI and CPLEX. It can be framed as a border-
line case of an MDP framework which is the focus of another
emerging library Ecole [Prouvost et al., 2020]. Ecole is de-
signed to cooperate with the state-of-the-art open-source MIP
solver SCIP where Ecole acts as an improvement to existing
solvers. Besides, ORGym [Hubbs et al., 2020] and Open-
GraphGym [Zheng et al., 2020] are Gym-like libraries for
learning heuristics for a collection of combinatorial optimiza-
tion problems including MIP.

Difference to existing surveys. There are excellent sur-
veys in the area of machine learning for combinatorial op-
timization [Bengio et al., 2021], and exactly learning for
solving mixed integer programming [Kleinert et al., 2021;
Lodi and Zarpellon, 2017; Huang et al., 2021a]. Compared
with the previous survey [Lodi and Zarpellon, 2017] which
only covers the topic of learning-supported node selection
techniques due to the limited development ﬁve years ago.
While the other [Kleinert et al., 2021] is focused on bi-level
tailored approaches that exploit MIP techniques to solve bi-
level optimization problems. In this paper, we aim to give a
comprehensive and up-to-date review in the area of learning
for solving MIP, especially seeing the rapid development in
recent years. The recent paper [Huang et al., 2021a] mainly
focuses on the development in recent decades of the branch-
and-bound algorithm instead of MIP, but it does not empha-
size the importance of adapting machine learning in MIP.

2 Branch-and-Bound
In general, mixed integer linear programming problems can
be solved using a linear-programming based branch-and-
bound (B&B) algorithm [Land and Doig, 2010]. Proposed

1https://anl-ceeesa.github.io/MIPLearn

−13/2+∞−13/3+∞−16/3+∞−3−3−4−4–22/5+∞INFINF−3−3x = 5/2#y = 3/2x = 5/3#y = 1x = 5/3#y = 2x = 1#y = 1x = 1#y = 12/5x = 1#y = 2x = 0#y = 3y ≤ 1y ≥ 2x ≤ 1x ≤ 1x ≥ 2x ≥ 2y ≤ 2y ≥ 3ub = +∞#lb = −16/3ub = −3#lb = −22/5ub = −4#lb = −4ub = −3#lb = −16/3node expansion  order    global lower and upper boundoptimal nodefathomed nodemin  −2x − y#s.t.   3x − 5y ≤ 0#        3x + 5y ≤ 15#        x ≥ 0, y ≥ 0#        x, y ∈ Z training examples:−13/3+∞−16/3+∞<prune:−13/3+∞Figure1:Usingbranch-and-boundtosolveanintegerlinearprogrammingminimization.•Easyincorporationofheuristics.Mosthand-designedstrategieshandleonlyafewheuris-tics,andtheysetweightsondifferentheuristicsbydomainknowledgeormanualexperi-mentation.Inourmodel,multipleheuristicscanbesimplypluggedinasstatefeaturesforthepolicy,allowingahybrid“heuristic”tobelearnedeffectively.Weassumethatasmallsetofsolvedproblemsaregivenattrainingtimeandtheproblemstobesolvedattesttimeareofthesametype.Welearnanodeselectionpolicyandanodepruningpolicyfromsolvingthetrainingproblems.Thenodeselectionpolicyrepeatedlypicksanodefromthequeueofallunexplorednodes,andthenodepruningpolicydecidesifthepoppednodeisworthexpanding.WeformulateB&Bsearchasasequentialdecision-makingprocess.Wedesignasimpleoraclethatknowstheoptimalsolutioninadvanceandonlyexpandsnodescontainingtheoptimalsolution.Wethenuseimitationlearningtolearnpoliciesthatmimictheoracle’sbehaviorwithoutperfectinformation;thesepoliciesmustevenmimichowtheoraclewouldactinstatesthattheora-clewouldnotitselfreach,assuchstatesmaybeencounteredattesttime.Weapplyourapproachtolinearprogramming(LP)basedB&Bforsolvingmixedintegerlinearprogramming(MILP)prob-lems,andachievebettersolutionsfasteron4MILPproblemlibrariesthanGurobi,arecentfastcommercialsolvercompetitivewithCplex,andSCIP,oneofthefastestopen-sourcesolvers[8].2TheBranch-and-BoundFramework:AnApplicationinMixedIntegerLinearProgrammingConsideranoptimizationproblemofminimizingfoverafeasiblesetF,whereFisusuallydiscrete.B&Busesadivideandconquerstrategy:FisrecursivelydividedintoitssubsetsF1,F2,...,FpsuchthatF=Spi=1Fi.Therecursiontreeisanenumerationtreeofallfeasiblesolutions,whosenodesaresubproblemsandedgesarethepartitionconditions.Slightlyabusingnotation,wewilluseFitorefertoboththesubsetanditscorrespondingB&Bnodefromnowon.A(convex)relaxationofeachsubproblemissolvedtoprovideanupper/lowerboundforthatnodeanditsdescendants.Wedenotetheupperandlowerboundatnodeiby`ub(Fi)and`lb(Fi)respectivelywhere`uband`lbareboundingfunctions.AcommonsettingwhereB&BisubiquitouslyappliedisMILP.AMILPoptimizationproblemhaslinearobjectiveandconstraints,andalsorequiresspeciﬁedvariablestobeinteger.WeassumeweareminimizingtheobjectivefunctioninMILPfromnowon.Ateachnode,wedroptheintegralityconstraintsandsolveitsLPrelaxation.WepresentaconcreteexampleinFigure1.Theoptimizationproblemisshowninthelowerrightcorner.Atnodei,alocallowerbound(showninlowerhalfofeachcircle)isfoundbytheLPsolver.Alocalupperbound(showninupperpartofthecircle)isavailableifafeasiblesolutionisfoundatthisnode.WeautomaticallygetanupperboundiftheLPsolutionhappenstobeintegerfeasible,orwemayobtainitbyheuristics.B&BmaintainsaqueueLofactivenodes,startingwithasinglerootnodeonit.Ateachstep,wepopanodeFifromLusinganodeselectionstrategy,andcomputeitsbounds.AnodeFi2(cid:54)
Table 1: Summary of methods that combine machine learning with B&B. “Selection” denotes which part involves learning.

Selection
Method
[Gasse et al., 2019]
Variable
[Gupta et al., 2020]
Variable
[Sun et al., 2020]
Variable
[He et al., 2014]
Node
[Yilmaz et al., 2020]
Node
[Khalil et al., 2016]
Variable
[Shen et al., 2021]
Variable
[Huang et al., 2021b]
Cutting
[Zarpellon et al., 2020] Variable
[Tang et al., 2020]
Cutting
[Nair et al., 2021]
Variable
[Ding et al., 2019]
Variable
[Alvarez et al., 2014]
Variable

Network

Representation
Learning
Bipartite graph
Reinforcement GCN
Bipartite graph
GCN
Supervised
Subproblem set
PD policy
Reinforcement
Standalone
Standalone
Reinforcement
Handcraft
MLP
Supervised
Handcraft
SVM
Supervised
Bipartite graph
GCN
Supervised
Handcraft
Supervised
MLP
Reinforcement MLP
Handcraft
Reinforcement Attention & LSTM Handcraft
Reinforcement GCN
GCN
Supervised
ExtraTrees
Supervised

Bipartite graph
Tripartite graph
Handcraft

Remark
Imitate strong branching
Accelerate via dynamic embedding
Evolution strategy for training
Imitate optimal oracle
Prune leaf
Learning to rank
Combined with DFS
Large scale
Imitate strong branching
Evolution strategy for training
Imitate strong branching
Extract connection information
Imitate strong branching

Algorithm 2: Branching Variable Selection
Input: Subproblem of the current node
S
XM ILP
optimal LP solution ˆx /
∈
i

1 Deﬁne branching candidates set C =
2 for each candidate i
3

Calculate its score value si ∈

C do

R

∈

∈

{

I

with its

ˆxi /
∈

|

Z
}

Output: A subscript i = arg mini∈C si of an integer
variable with fractional value ˆxi /
∈

Z

a clever branching rule is critical for MIP solvers.

The majority of works focus on decision in the branch-and-
bound algorithm [Balcan et al., 2018; Khalil et al., 2016].
Two most crucial ones are branching variable selection and
node selection. Recent works explore “learning to branch”,
including learning for branching variable selection [Khalil
et al., 2016; Song et al., 2020b; Liberto et al., 2016;
Gasse et al., 2019; Sun et al., 2020; Zarpellon et al., 2020;
Etheve et al., 2020], node selection [He et al., 2014; Song
et al., 2017; 2020b; Yilmaz et al., 2020], and cutting plane
selection [Huang et al., 2021b; Tang et al., 2020]. In partic-
ular, branching variable selection is the main stream of the
presented articles, since the selection of the next variable is
signiﬁcant in B&B and matters to the total cost of B&B.

2.1 Branching Variable Selection (BVS)
Branch variable selection determines which fractional vari-
ables (also known as candidates) to branch the current node
into two child nodes. To indicate the quality of a candidate
variable, a score of this variable is used to measure its effec-
tiveness, and the candidate with the highest score is picked to
branch on. The pseudocode of BVS is presented in Alg. 2,
which illustrates the basic variable selection idea.

There are various branching rules used to measures vari-
ables in BVS, including strong branching (SB) rule [Apple-
gate et al., 1995], pseudo-cost [B´enichou et al., 1971] and
hybrid branching [Achterberg and Berthold, 2009]. Natu-

Figure 2: Transform an MIP instance to a bipartite graph. The
variables (in green) correspond to one side and the constraints
(in red) refers to the other. (Credit to [Nair et al., 2021])

rally, the idea of adopting an imitation learning [Ho and Er-
mon, 2016] strategy to learn a fast approximation of branch-
ing rules came into being. Imitation learning aims at using
expert experience to conduct the learning of neural networks,
which can acquire the neural networks that can reach the same
or even better performance than the initial expert. [Alvarez
et al., 2014; 2017; Khalil et al., 2016; Gasse et al., 2019;
Gupta et al., 2020] learn branching policies by imitating the
strong branching rule. This kind of approach adopts a high-
quality but expensive heuristic scheme, which is the earliest
and most widely studied method for machine learning.

Speciﬁcally, [Alvarez et al., 2014] is the ﬁrst to use su-
pervised learning to learn a strong branching model. By the
observation of the expert, the neural networks can learn an
approximated function of the variable score, and can further
adapt it to select the suitable variable in B&B. [Khalil et al.,
2016] extends the work of [Alvarez et al., 2014] by design-
ing a novel pipeline that can solve the MIP on the ﬂy.
In
the ﬁrst 500 branches, they use the traditional SB to make
decisions while recording the problem features to train the
neural networks, and the neural networks take control of the
decision-maker from the 501st branch. Both of them imitate
SB successfully, while the spending time is too high due to
the calculation of a large number of features on each node.

To overcome complex feature calculation, [Gasse et al.,

and upper bound ¯J

Algorithm 3: Node Selection
Input: Node list L =

P
{

}

1 Assigns a score to each active node
2 Pop a node P i from L
3 Solve the LP relaxation
4 get solution
5 if J i

xi, yi

and lower bound J i

¯J then
(cid:0)
≥
Prune the node P i
Zp then

(cid:1)

7 else if yi

Improve upper bound ¯J = J i

∈

6

8

9 else
10

Branch node P i and push child nodes to list L

(MDP). They further design a policy net based on primal-dual
iteration over reduced LP relaxation, which utilizes the power
of evolution strategy to update the neural networks.

2.2 Node Selection
As mentioned above, the branch-and-bound algorithm recur-
sively divides the feasible set of a problem into disjoint sub-
sets, organized in a tree structure, where each node represents
a subproblem that searches only the subset at that node. The
main steps of the node selection algorithm are given in Alg. 3.
If computing bounds on a subproblem does not rule out the
possibility that its subset contains the optimal solution, the
subset can be further partitioned (“branched”) as needed. Else
if the lower bound of possible solutions of a node is larger
than the known upper bound, the node can be pruned. A key
question in B&B is how to prioritize which nodes to consider.
An effective node priority decision strategy guides the tree
search to promising areas and improves the chance of quickly
ﬁnding a good incumbent solution, which can be used to de-
cide whether to discard or expand other nodes. Thus, learning
the appropriate node selection policy of a B&B tree is worthy
of being investigated. More precisely, a policy is a function
that maps a state to an action, which in this case is the next
node to be selected.

There is less work in node selection of B&B than in BVS.
[He et al., 2014] uses imitation learning to train a node se-
lection and a node pruning policy to speed up the tree search
in the B&B process. Following the above work, [Yilmaz et
al., 2020] obtains a node selector by imitation learning. The
difference is that [Yilmaz et al., 2020] learns only to choose
a node’s children it should select. This encourages ﬁnding
solutions quickly, as opposed to learning a BFS-like method.

2.3 Cutting Plane
It is known that every MIP can be relaxed to a linear program-
ming (LP) by dropping the integer constraints, and there are
many traditional efﬁcient algorithms for solving LP such as
Simplex [Dantzig, 1990], Interior Point Method (IPM) [Roos
et al., 2005], etc. It means that we can relax MIP to LP and
solve the incident LP instead at an acceptable cost, which
leads to the cutting plane algorithm. As Fig. 4 shows, cutting
plane methods iteratively add cuts to the relaxed LP, which

Figure 3: From MIP to tripartite graph. Three types of ver-
tices represent objective functions, variables, and constraints,
respectively. (Credit to [Ding et al., 2019])

2019] encodes MIP into a graph-convolutional network
(GCN) [Kipf and Welling, 2017], which can extract the fea-
tures on the graph efﬁciently by various message passing
approaches. [Nair et al., 2021] encodes MIP to the graph-
convolutional network (GCN) as a bipartite graph and com-
putes an initial feasible solution (Neural Diving), then trains
a GCN to imitate ADMM-based policy for branching (Neural
Branching). It uses RL to learn a policy that un-assigns one
variable at a time, interleaved with solving a sub-MIP every η
steps to compute a new solution. The authors formulate MIP
as a natural bipartite graph representing variable-constraint
relationships, which is illustrated in Fig. 2. Each MIP has
two sets of nodes, one representing variables and another rep-
resenting constraints. And an edge between a variable i and
a constraint j means variable i appears in constraint j. A lot
of subsequent work has referenced the bipartite graph model
proposed by [Gasse et al., 2019]. Inspired by the utilization
[Gupta et al., 2020] proposes a hybrid
of the GCN model,
architecture that uses a GNN model at only the root node of
the B&B tree and a weak but fast predictor at the remain-
ing nodes, such as a simple Multi-Layer Perception (MLP).
The model combines the superior representation framework
[Gasse et al., 2019] with the computationally cheaper
of
framework of [Khalil et al., 2016] to realize a time-accuracy
trade-off in branching. Besides, [Ding et al., 2019] generates
a tripartite graph from its MIP formulation, as illustrated in
Fig. 3. They train a GCN for variable solution prediction on
the collected features, labels, and tripartite graphs. In [Zarpel-
lon et al., 2020], the authors claim that information contained
in the global branch-and-bound tree state is an important fac-
tor in variable selection, and they use a novel neural network
design that incorporates the branch-and-bound tree state di-
rectly. Furthermore, they are one of the few techniques on
heterogeneous instances.

Different from learning the output of a computationally ex-
pensive heuristic used in B&B, [Etheve et al., 2020] applies
reinforcement learning (RL) for BVS from scratch, free from
any heuristic. The core idea of RL is to learn from the in-
teractions between the agent and the environment, and here
the MIP instance is the environment and the agent is try to
solve it. Experience shows that the RL approach sometimes
works better than the imitation learning we mentioned before.
In [Sun et al., 2020], the authors argue that strong branching
is not a good expert to imitate and utilize RL by modeling
the variable selection process as a Markov Decision Process

Table 2: A brief summary of methods that combine machine learning with heuristic algorithms. The “Focus” column denotes
the combined heuristic algorithm. LNS means large neighborhood search and FP means feasibility pump.

Method
[Song et al., 2020a]
[Sonnerat et al., 2021]
[Wu et al., 2021]
[Liu et al., 2021]
[Qi et al., 2021b]
[Ding et al., 2020]
[Grover et al., 2018]
[Xavier et al., 2021]

Focus
LNS
LNS
LNS
LNS
FP
Pick
Pick
Pick

Learning
Network
Reinforcement
MLP
Reinforcement
GCN
GCN
Reinforcement
Supervised & Reinforcement GNN
Reinforcement
Supervised
Reinforcement
Supervised

Representation
Handcraft
Bipartite graph
Bipartite graph
Bipartite graph

Remark
Combined with GUROBI
Use imitation learning
Outperforms SCIP
Adaptive neighborhood size

MLP & CNN Parameter matrix Combine [A,b] as matrix
GCN
Standalone
KNN

Predict solution value for variables
Pick heuristics in CPLEX
As a warm start

Tripartite graph
Handcraft
Handcraft

proposes a cut ranking method for cut selection in the settings
of multiple instance learning. It uses neural networks to give
scores to different candidate cuts for the next step.

3 Heuristic Algorithms
Though MIP can be solved via B&B exactly, it is time and
resource-consuming due to its NP-hard nature. In many cases
especially large-scale problem instances, B&B becomes in-
tractable. Thus, heuristic-based methods are considered in-
stead. Heuristic algorithms aim to solve MIP approximately,
by the integration of greedy approach and searching. The
common heuristic algorithms for MIP are large neighborhood
search and the feasibility pump. Besides, some works aim at
better utilizing existing MIP solvers by machine learning. We
will discuss these approaches in detail.

3.1 Large Neighborhood Search (LNS)
Large neighborhood search (LNS) is a powerful heuristic for
MIP. Given the problem instance and the initial feasible solu-
tion, LNS searches for better candidate solutions among pre-
deﬁned neighborhoods of current solution in each iteration.
The iteration continues until the search budget (for example
the computing time) is used up. Due to the nature of LNS, it is
important to prevent the search from falling into a poor local
optimum. In general, the size of the neighborhood grows ex-
ponentially as the size of the input problem increase. There-
fore, it is necessary to optimize the LNS algorithm by the
learning techniques to improve its efﬁciency.

There are two critical choices to determine the effective-
ness of LNS: 1) initial solution and 2) search neighborhood
[Song et al., 2020a] learns a neighbor-
at each iteration.
hood selection policy using imitation learning and reinforce-
ment learning (RL). It uses a random neighborhood selec-
tion policy to generate training data for imitation learning.
Following the neural diving idea proposed by [Nair et al.,
2021] mentioned in Section 2.1, [Sonnerat et al., 2021] adapts
neural diving to obtain the initial solution and for select-
ing the search neighborhood at each LNS step. Some re-
searchers [Liu et al., 2021] conduct analysis to LNS, and it
turns out the size of neighbors is important, and the most suit-
able neighbor size varies over iterations. Therefore, they pro-
pose to use machine learning to automatically ﬁnd the suit-
able neighbor size. [Wu et al., 2021] combines RL with LNS,

Figure 4: Cutting planes for MIP.

are linear constraints that can tighten the LP relaxation by
eliminating some part of the feasible region while preserv-
ing the LP optimal solution. Suppose that we add the cut set

(cid:48)

=

C
Then, the optimization formulation of MIP becomes:

|C
i=1 to the original formulation in Eq. (1).

i x

αT

βi

≥

|

(cid:48)

(cid:8)

(cid:9)

min cTx

(3)

xj ∈

Z,

j
∀

I

s.t. Ax

b, x

Rn αT x

β,

∈

∈

≥

≥
As shown by the new formulation, cuts serve as the pur-
pose of reducing the LP solution space, which might lead
to a smaller tree in the branch-and-cut algorithm so that the
number of nodes to be searched is signiﬁcantly reduced. As
mentioned before, the cutting plane can be combined with the
branch and bound algorithm, which constitutes the branch-
and-cut framework. Branch-and-cut is known as one of the
most commonly used algorithms in modern solvers.

Due to the importance of the cutting plane in solving MIP,
many researchers try to utilize machine learning technologies
to improve the traditional cutting plane algorithm. Unlike
B&B, there are relatively few well-designated heuristics in
the cutting plane algorithm, which denotes imitation learn-
ing or supervised learning cannot be directly applied here.
Therefore, researchers begin to think of reinforcement learn-
ing. [Tang et al., 2020] introduces a MDP formulation for
the problem of sequentially selecting cutting planes for MIP,
and training a reinforcement learning (RL) agent using evo-
lutionary strategies. This work shows the ability of RL to
improve the cutting plane algorithm and potentially opens a
new research topic. The following work [Huang et al., 2021b]

Algorithm 4: Feasibility Pump
argmin cT x; x0
Input: x0

←
1 while xi is not feasiable do

xi+1
argmin
xi+1
[xi+1]
if xi+1 == xi then

←
←

||

x

xi

−

||

[x0]; i = 0

←

random perturbation of xi
j,

j
∀

∈

I

2

3

4

5

6

7

else

k

←
Output: xi

k + 1

where the action of RL is to select the variable to be replaced.
They also propose a novel feature extractor for variables and
constraints in MIP.

LNS aims to continuously improve a solution, which is a
common idea in solving CO problems. Therefore, we will
discuss some approaches in the CO ﬁeld that shares similar
ideas with LNS, which we hope could inspire adaptation of
these methods to solve MIP. [Chen and Tian, 2019] proposes
a framework called local rewrite, which tries to improve a
given solution by selecting a part of the solution and modify-
ing it. In their paper, the local rewrite framework is proved
to be a powerful method for the vehicle routing problem and
computing resource allocation. The ECO-DQN [Barrett et
al., 2020] framework re-designs the action space of the rein-
forcement learning agent, which allows revoking the previous
action. In other words, the action of the agent is revocable in
the ECO-DQN framework. There are many other works [Lu
et al., 2020; Fu et al., 2021] following the idea of local rewrite
and ECO-DQN in combinatorial optimization.

3.2 Feasibility Pump
Feasibility pump (FP) is a heuristic algorithm that runs the
following steps: 1) ﬁnd the rounded optimal continuous re-
laxation solution of the MIP (degenerating to LP); 2) search
for the nearest solution in the relaxed feasible region; 3) per-
turb and round the new solution found at each step until the
solution is feasible. If the limit of the maximum number of
steps is reached, the algorithm will halt and return the cur-
rent feasible solution as the output. The basic steps of the FP
algorithm are shown in Algorithm 4.

Though FP is a relatively powerful heuristic, the efﬁciency
and cost-effectiveness are not satisﬁed. Therefore, [Qi et al.,
2021a; 2021b] utilize RL to improve FP. The entry point of
RL is to ﬁnd the next non-integer solution in step 2). Instead
of choosing the nearest solution, the authors let the RL agent
choose the next solution as its action. Besides, two methods
of MLP and CNN are designed on the representation of the
state space, where the CNN is to treat the parameters [A, b]
in MIP as an image and process it. Fig. 4 shows the FP algo-
rithm and the smart FP proposed by [Qi et al., 2021a].

3.3 Predict and Pick
Instead of solving the MIP directly, some works aim to pre-
dict and pick from the existing MIP solvers or methods. It is

Figure 5: The feasibility pump. (Credit to [Qi et al., 2021a])

reasonable to solve MIP based on existing works since exist-
ing MIP solvers have been improved for decades. Some re-
searchers believe that better utilization of existing MIP meth-
ods is a valuable research topic. [Ding et al., 2020] predicts
a solution value for each variable based on historical data
and decides whether to use heuristic algorithms or the ex-
act branching approach to solve it. The authors try to make
the exact branching approach focus on the hard case while
leaving the easy case to the heuristic algorithm. By adopt-
ing reinforcement learning, [Grover et al., 2018] proposes to
select the predeﬁned heuristics in CPLEX by the features of
the given instance, which is an online learning framework.
[Xavier et al., 2021] focuses on solving the MIP instances in
a data-driven manner. Combined with existing MIP solvers,
they train a KNN to predict redundant constraints, good ini-
tial feasible solutions, and afﬁne subspaces where the optimal
solution is likely to lie, which can lead to a signiﬁcant reduc-
tion in the problem size of MIP. They conduct experiments on
the electric grid unit commitment problem, which is an appli-
cation of MIP. Besides, the early stopping technique is widely
adopted in the hyperparameter optimization [Makarova et al.,
2021], which uses machine learning to predict when to stop
the searching process without much loss of quality. It greatly
improves the efﬁciency and saves computing resources. The
early stopping technique might be integrated into the MIP
solvers. Speciﬁcally, one can use machine learning tech-
niques to predict when to early stop the B&B process mean-
while the incumbent primal solution is still acceptable.

4 Conclusion and Outlook
In this survey, a study of the state-of-the-art machine learning
approach for solving MIP is presented, to summarize exist-
ing work and serve as a starting point for future research in
these areas. We ﬁnd that the integration of machine learning
techniques and traditional operational research algorithms is
a raising topic in the research ﬁeld, including combination
with the exact B&B algorithms and heuristic algorithms.

Since MIP is an NP-hard problem, it is very difﬁcult to
obtain an exact solution. Leveraging machine learning tech-
niques to obtain an acceptable solution within limited com-
puting resources is welcomed and reasonable in practical ap-
plications. We can design a model, by instructing learning
models to imitate heuristic algorithms, and make some deci-
sions in the B&B algorithm or make adjustments to the initial
solution.
It can be seen that with the development of ma-
chine learning, especially for deep and reinforcement learn-
ing, more and more models are used in MIP solving, contin-
uously improving the efﬁciency and solution quality.

References
[Achterberg and Berthold, 2009] T.

Achterberg
T. Berthold. Hybrid branching. In CPAIOR, 2009.

and

[Alvarez et al., 2014] A. M. Alvarez, Q. Louveaux, and
L. Wehenkel. A supervised machine learning approach to
variable branching in branch-and-bound. In ECML, 2014.

[Alvarez et al., 2017] A. M. Alvarez, Q. Louveaux, and
L. Wehenkel. A machine learning-based approximation
of strong branching. JOC, 2017.

[Applegate et al., 1995] D. Applegate, R. Bixby, V. Chvatal,
and B. Cook. Finding cuts in the tsp. Technical report,
1995.

[Balcan et al., 2018] M.-F. Balcan, T. Dick, T. Sandholm,
and E. Vitercik. Learning to branch. In ICML, 2018.

[Barrett et al., 2020] T. Barrett, W. Clements, J. Foerster, and
A. Lvovsky. Exploratory combinatorial optimization with
reinforcement learning. In AAAI, 2020.

[Bengio et al., 2021] Y. Bengio, A. Lodi, and A. Prou-
vost. Machine learning for combinatorial optimization: a
methodological tour d’horizon. EJOR, 2021.

[B´enichou et al., 1971] M. B´enichou,

J.-M. Gauthier,
P. Girodet, G. Hentges, G. Ribi`ere, and O. Vincent.
Experiments
linear programming.
Mathematical Programming, 1971.

in mixed-integer

[Bestuzheva et al., 2021] K. Bestuzheva, M. Besanc¸on, W.-
K. Chen, A. Chmiela, T. Donkiewicz, J. van Doorn-
malen, L. Eiﬂer, O. Gaul, G. Gamrath, A. Gleixner,
L. Gottwald, C. Graczyk, K. Halbig, A. Hoen, C. Ho-
jny, R. van der Hulst, T. Koch, M. L¨ubbecke, S. J. Ma-
her, F. Matter, E. M¨uhmer, B. M¨uller, M. E. Pfetsch,
D. Rehfeldt, S. Schlein, F. Schl¨osser, F. Serrano, Y. Shi-
nano, B. Sofranac, M. Turner, S. Vigerske, F. Wegschei-
der, P. Wellner, D. Weninger, and J. Witzig. The SCIP
Optimization Suite 8.0. ZIB-Report 21-41, Zuse Institute
Berlin, December 2021.

[Chen and Tian, 2019] X. Chen and Y. Tian. Learning to per-
form local rewriting for combinatorial optimization.
In
NeurIPS, 2019.

[Cplex, 2009] I. I. Cplex. V12. 1: User’s manual for
International Business Machines Corporation,

cplex.
46(53):157, 2009.

[Dantzig, 1990] G. B. Dantzig. Origins of the simplex
method. In A history of scientiﬁc computing, pages 141–
151. 1990.

[Ding et al., 2019] J. Ding, C. Zhang, L. Shen, S. Li,
B. Wang, Y. Xu, and L. Song. Optimal solution predic-
tions for mixed integer programs. Arxiv, abs/1906.09575,
2019.

[Etheve et al., 2020] M. Etheve, Z. Al`es, C. Bissuel, O. Juan,
and S. Kedad-Sidhoum. Reinforcement learning for vari-
able selection in a branch and bound algorithm. Arxiv,
abs/2005.10026, 2020.

[Fu et al., 2021] Z.-H. Fu, K.-B. Qiu, and H. Zha. Generalize
a small pre-trained model to arbitrarily large tsp instances.
In AAAI, 2021.

[Gajda et al., 2022] M. Gajda, A. Trivella, R. Mansini, and
D. Pisinger. An optimization approach for a complex real-
life container loading problem. Omega, 2022.

[Gasse et al., 2019] M. Gasse, D. Ch´etelat, N. Ferroni,
L. Charlin, and A. Lodi. Exact combinatorial optimiza-
tion with graph convolutional neural networks. Arxiv,
abs/1906.01629, 2019.

[Grover et al., 2018] A. Grover, T. Markov, P. Attia, N. Jin,
N. Perkins, B. Cheong, M. Chen, Z. Yang, S. Harris,
W. Chueh, et al. Best arm identiﬁcation in multi-armed
bandits with delayed feedback. In AISTATS, 2018.

[Gupta et al., 2020] P. Gupta, M. Gasse, E. B. Khalil, M. P.
Kumar, A. Lodi, and Y. Bengio. Hybrid models for learn-
ing to branch. Arxiv, abs/2006.15212, 2020.

[Gurobi Optimization, 2020] Gurobi Optimization. Gurobi

optimizer reference manual. 2020.

[He et al., 2014] H. He, H. Daume III, and J. M. Eisner.
Learning to search in branch and bound algorithms.
In
NeurIPS, 2014.

[Ho and Ermon, 2016] J. Ho and S. Ermon. Generative ad-

versarial imitation learning. In NeurIPS, 2016.

[Huang et al., 2021a] L. Huang, X. Chen, W. Huo, J. Wang,
F. Zhang, B. Bai, and L. Shi. Branch and bound in mixed
integer linear programming problems: A survey of tech-
niques and trends. arXiv preprint arXiv:2111.06257, 2021.
[Huang et al., 2021b] Z. Huang, K. Wang, F. Liu, H. ling
Zhen, W. Zhang, M. Yuan, J. Hao, Y. Yu, and J. Wang.
Learning to select cuts for efﬁcient mixed-integer pro-
gramming. Pattern Recognition, 2021.

[Hubbs et al., 2020] C. D. Hubbs, H. D. Perez, O. Sarwar,
N. V. Sahinidis, I. E. Grossmann, and J. M. Wassick. Or-
gym: A reinforcement learning library for operations re-
search problems. arXiv:2008.06319, 2020.

[Keha et al., 2009] A. B. Keha, K. Khowala, and J. W.
Fowler. Mixed integer programming formulations for sin-
gle machine scheduling problems. Computers & Industrial
Engineering, 2009.

[Khalil et al., 2016] E. B. Khalil, P. L. Bodic, L. Song,
G. Nemhauser, and B. Dilkina. Learning to branch in
mixed integer programming. In AAAI, 2016.

[Kipf and Welling, 2017] T. Kipf and M. Welling. Semi-
supervised classiﬁcation with graph convolutional net-
works. ArXiv, abs/1609.02907, 2017.

[Ding et al., 2020] J.-Y. Ding, C. Zhang, L. Shen, S. Li,
B. Wang, Y. Xu, and L. Song. Accelerating primal solu-
tion ﬁndings for mixed integer programs based on solution
prediction. In AAAI, 2020.

[Kleinert et al., 2021] T. Kleinert, M. Labb´e, I. Ljubi´c, and
M. Schmidt. A survey on mixed-integer programming
techniques in bilevel optimization. EURO Journal on
Computational Optimization, 2021.

[Land and Doig, 1960] A. H. Land and A. G. Doig. An auto-
matic method of solving discrete programming problems.
Econometrica, 28:497, 1960.

[Schouwenaars et al., 2001] T. Schouwenaars, B. De Moor,
E. Feron, and J. How. Mixed integer programming for
multi-vehicle path planning. In ECC, 2001.

[Land and Doig, 2010] A. H. Land and A. G. Doig. An auto-
matic method for solving discrete programming problems.
50 Years of Integer Programming 1958-2008: From the
Early Years to the State-of-the-Art, 2010.

[Liberto et al., 2016] G. D. Liberto, S. Kadioglu, K. Leo,
and Y. Malitsky. Dash: Dynamic approach for switching
heuristics. EJOR, 2016.

[Liu et al., 2021] D. Liu, M. Fischetti, and A. Lodi. Learning

to search in local branching. ArXiv, 2021.

[Lodi and Zarpellon, 2017] A. Lodi and G. Zarpellon. On

learning and branching: a survey. Top, 2017.

[Lu et al., 2020] H. Lu, X. Zhang, and S. Yang. A learning-
based iterative method for solving vehicle routing prob-
lems. In ICLR, 2020.

[Makarova et al., 2021] A. Makarova, H. Shen, V. Perrone,
A. Klein, J. B. Faddoul, A. Krause, M. Seeger, and C. Ar-
chambeau. Overﬁtting in bayesian optimization: an em-
pirical study and early-stopping solution. arXiv preprint
arXiv:2104.08166, 2021.

[Malandraki and Daskin, 1992] C.

and
M. Daskin.
Time dependent vehicle routing prob-
lems: Formulations, properties and heuristic algorithms.
Transportation Science, 1992.

Malandraki

[Nair et al., 2021] V. Nair, S. Bartunov, F. Gimeno, I. von
Glehn, P. Lichocki, I. Lobov, B. O’Donoghue, N. Son-
nerat, C. Tjandraatmadja, P. Wang, R. Addanki, T. Ha-
puarachchi, T. Keck, J. Keeling, P. Kohli, I. Ktena, Y. Li,
O. Vinyals, and Y. Zwols. Solving mixed integer programs
using neural networks. arXiv:2012.13349, 2021.

[Paulus et al., 2021] A. Paulus, M. Rol´ınek, V. Musil,
B. Amos, and G. Martius. Comboptnet: Fit the right
np-hard problem by learning integer programming con-
straints. In ICML, 2021.

[Pochet and Wolsey, 2010] Y. Pochet and L. A. Wolsey.
Production Planning by Mixed Integer Programming.
Springer, 2010.

[Prouvost et al., 2020] A.

J. Dumouchelle,
L. Scavuzzo, M. Gasse, D. Ch´etelat, and A. Lodi. Ecole:
A gym-like library for machine learning in combinatorial
optimization solvers. arXiv:2011.06069, 2020.

Prouvost,

[Qi et al., 2021a] M. Qi, M. Wang, and Z.-J. Shen. Smart
feasibility pump: Reinforcement learning for (mixed) in-
teger programming. arXiv:2102.09663, 2021.

[Qi et al., 2021b] M. Qi, M. Wang, Zuo-jun, and M. Shen.
Reinforcement learning for (mixed) integer programming:
In RL4RealLife Workshop of
Smart feasibility pump.
ICML, 2021.

[Roos et al., 2005] C. Roos, T. Terlaky, and J.-P. Vial. Inte-

rior point methods for linear optimization. 2005.

[Sawik, 2011] T. Sawik. Scheduling in supply chains using
mixed integer programming. John Wiley & Sons, 2011.

[Shen et al., 2021] Y. Shen, Y. Sun, A. Eberhard, and X. Li.
Learning primal heuristics for mixed integer programs. In
IJCNN, 2021.

[Song et al., 2017] J. Song, R. Lanka, A. Zhao, Y. Yue, and
M. Ono. Learning to search via self-imitation with appli-
cation to risk-aware planning. In Proc. Adv. Neural Inform.
Process. Syst. Workshop, 2017.

[Song et al., 2020a] J. Song, R. Lanka, Y. Yue, and B. Dilk-
ina. A general large neighborhood search framework for
solving integer linear programs. arXiv:2004.00422, 2020.
[Song et al., 2020b] J. Song, R. Lanka, Y. Yue, and M. Ono.
Co-training for policy learning. In Uncertainty in Artiﬁcial
Intelligence, pages 1191–1201. PMLR, 2020.
[Sonnerat et al., 2021] N. Sonnerat, P. Wang,

I. Ktena,
S. Bartunov, and V. Nair.
Learning a large neigh-
borhood search algorithm for mixed integer programs.
arXiv:2107.10201, 2021.

[Sun et al., 2020] H. Sun, W. Chen, H. Li, and L. Song.
Improving learning to branch via reinforcement learning.
LMCA, 2020.

[Tang et al., 2020] Y. Tang, S. Agrawal, and Y. Faenza. Re-
inforcement learning for integer programming: Learning
to cut. In ICML, 2020.

[Wu et al., 2013] T. Wu, K. Akartunalı, J. Song, and L. Shi.
Mixed integer programming in production planning with
backlogging and setup carryover: Modeling and algo-
rithms. DEDS, 2013.

[Wu et al., 2021] Y. Wu, W. Song, Z. Cao, and J. Zhang.
Learning large neighborhood search policy for integer pro-
gramming. NeurIPS, 2021.

[Xavier et al., 2021]

´A. S. Xavier, F. Qiu, and S. Ahmed.
Learning to solve large-scale security-constrained unit
commitment problems. INFORMS Journal on Computing,
33(2):739–756, 2021.

[Yilmaz et al., 2020] K. Yilmaz, N. Yorke-Smith, and xxx.
Learning efﬁcient search approximation in mixed integer
branch and bound. Arxiv, abs/2007.03948, 2020.

[Zarpellon et al., 2020] G. Zarpellon, J. Jo, A. Lodi, and
Y. Bengio. Parameterizing branch-and-bound search trees
to learn branching policies. Arxiv, abs/2002.05120, 2020.
[Zheng et al., 2020] W. Zheng, D. Wang, and F. Song. Open-
graphgym: A parallel reinforcement learning framework
for graph optimization problems. In International Confer-
ence on Computational Science, 2020.

