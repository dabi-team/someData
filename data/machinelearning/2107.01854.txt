1
2
0
2

l
u
J

5

]

G
L
.
s
c
[

1
v
4
5
8
1
0
.
7
0
1
2
:
v
i
X
r
a

1

Poisoning Attack against Estimating from
Pairwise Comparisons

Ke Ma, Member, IEEE, Qianqian Xu, Senior Member, IEEE, Jinshan Zeng,
Xiaochun Cao, Senior Member, IEEE, and Qingming Huang, Fellow, IEEE

Abstract—As pairwise ranking becomes broadly employed for elections, sports competitions, recommendation, information retrieval
and so on, attackers have strong motivation and incentives to manipulate or disrupt the ranking list. They could inject malicious
comparisons into the training data to fool the target ranking algorithm. Such a technique is called “poisoning attack” in regression
and classiﬁcation tasks. In this paper, to the best of our knowledge, we initiate the ﬁrst systematic investigation of data poisoning attack
on the pairwise ranking algorithms, which can be generally formalized as the dynamic and static games between the ranker and the
attacker, and can be modeled as certain kinds of integer programming problems mathematically. To break the computational hurdle of
the underlying integer programming problems, we reformulate them into the distributionally robust optimization (DRO) problems, which
are computational tractable. Based on such DRO formulations, we propose two efﬁcient poisoning attack algorithms and establish the
associated theoretical guarantees including the existence of Nash equilibrium and the generalization ability bounds. The effectiveness
of the suggested poisoning attack strategies is demonstrated by a series of toy simulations and several real data experiments. These
experimental results show that the proposed methods can signiﬁcantly reduce the performance of the ranker in the sense that the
correlation between the true ranking list and the aggregated results with toxic data can be decreased dramatically.

Index Terms—Adversarial Learning, Poisoning Attack, Pairwise Comparison, Rank Aggregation, Robust Game, Distributionally
Robust Optimization.

(cid:70)

1 INTRODUCTION

R ANK aggregation, in particular estimating a ranking

based on comparisons between pairs of objects, arises
in a variety of disciplines, including the social choice theory
[3], psychology [16], statistics [34], machine learning [39],
bioinformatics [37] and others. The convenience of these
rank aggregation methods relies on their utilization of the
ordinal data. Without features, the comparisons only contain

• K. Ma is with the School of Computer Science and Technology, University
of Chinese Academy of Sciences, Beijing 100049, China, and with the
Artiﬁcial Intelligence Research Center, Peng Cheng Laboratory, Shenzhen
518055, China. E-mail: make@ucas.ac.cn

• Q. Xu is with the Key Laboratory of Intelligent Information Processing,
Institute of Computing Technology, Chinese Academy of Sciences, Beijing
100190, China. E-mail: qianqian.xu@vipl.ict.ac.cn, xuqianqian@ict.ac.cn.

•

J. Zeng is with the School of Computer and Information Engineering,
Jiangxi Normal University, Nanchang, Jiangxi, 330022, China. E-mail:
jinshanzeng@jxnu.edu.cn, jsh.zeng@gmail.com

• X. Cao is with the State Key Laboratory of Information Security
(SKLOIS), Institute of Information Engineering, Chinese Academy of
Sciences, Beijing, 100093, China, and with the School of Cyber Security,
University of Chinese Academy of Sciences, Beijing 100049, China.
E-mail: caoxiaochun@iie.ac.cn

• Q. Huang is with the Key Laboratory of

Intelligent

Information
Processing, Institute of Computing Technology, Chinese Academy of
Sciences, Beijing 100190, China, and with the School of Computer Science
and Technology, University of Chinese Academy of Sciences, Beijing
100049, China, and with the Key Laboratory of Big Data Mining and
Knowledge Management, the School of Economics and Management,
University of Chinese Academy of Sciences, Beijing 100049, China, and
with the Artiﬁcial Intelligence Research Center, Peng Cheng Laboratory,
Shenzhen 518055, China. E-mail: qmhuang@ucas.ac.cn.

the partial ranking lists generated by human beings. For in-
stance, the voters who participated in an election choose one
over the other candidates, which generate pairwise compar-
isons between the candidates. As another example workers
in a crowdsourcing platform are often asked to identify the
better advertisement of two possible visualization modes.
Competitive sports such as tennis or chess also involve
a serious of competitions between two players. From a
modeling perspective, the rank aggregation approach treats
pairwise comparisons as an access to estimate the under-
lying “scores” or “qualities” of the items being compared
(e.g., preference of candidates, skill levels of tennis players,
and advertisement performance). A vast body of prior work
has made the signiﬁcant progress in studying both statistical
and computational aspects [57], [58], [59], [61], [63], [64],
[65], [76].

However, the existing work ignores the security issue.
Beyond statistical property and computational complexity,
situations become complicated when the pairwise ranking
algorithms are utilized in high-stakes applications, e.g. elec-
tions, sports competitions, and recommendation. In pursuit
of huge economic beneﬁts, the potential attackers have
strong motivations and incentives to manipulate or dis-
rupt the aggregated results. When the victims are ranking
algorithms, a proﬁt-oriented adversary could try his/her
best to manipulate or disrupt the ranking list which will
favor his/her demands-say, the attacker could place the
special object at the top of the recommendation list, help
the particular candidate to win an election or just defeat the
candidate who should have won the election. If the attackers
compromise the integrity of ranking results, the fairness and
rationality will be lost in these high-stakes applications. Un-

 
 
 
 
 
 
fortunately, the security risk and serious threat of pairwise
ranking problem have not been comprehensively examined
yet. Can rank aggregation algorithms with pairwise com-
parisons be easily manipulated or disrupted? How reliable
are their results in the high-stakes applications?

To the best of our knowledge, the adversarial arsenal for
pairwise ranking methods has never been serious studied.
On one hand, the pairwise comparisons are the most simple
data in the literature as just binary variables can represent
them. Due to the absence of features, modifying these binary
data is an easy job. On the other hand, any single compari-
son does not dictate the aggregated result. Even manipulat-
ing a small quantity of binary data could not affect the ﬁnal
global ranking. Such a contradiction inspires us to initiate
an adversarial investigation of pairwise ranking problem.

To execute the attack strategy in the scenario, the ad-
versary must analyze the characteristics of pairwise rank-
ing problems. Unlike the supervised learning tasks (e.g.
regression, classiﬁcation, multi-arm bandit and reinforce-
ment learning), the rank aggregation does not need the
test protocol. This means that the evasion attacks (a.k.a
adversarial examples [24]) are not realistic. Evasion attack
causes the ﬁxed model to misbehave by well-crafted test
data. But there is no test phrase to implement such a kind
of attack. To archive his/her goal, the adversary needs to
inject the manipulated data into the training data. Thus,
rank aggregation in an adversarial setting is inherently
related to the challenging poisoning attacks [10], [31]. Next,
the adversary should consider the discrete property of the
pairwise comparisons. Unlike the data consisting of features
in continuous space, the input of pairwise ranking only con-
sists of binary data. The adversary could only add, delete or
ﬂip pairwise comparisons to execute the poisoning attacks.
Such limitations make the substantial attack operations on
pairwise ranking even harder. How to design efﬁcient algo-
rithms that are able to inject toxic data in a discrete domain?
It is the distinguishable characteristic of our work which is
different with the existing poisoning attack approaches [15],
[31], [33], [42], [43], [47], [48], [49], [79].

Given these challenges, we propose a principle frame-
work for adversarial perturbations of pairwise comparisons
that aims to break the integrity of rank aggregation result.
In particular, we focus on the parametric model solved by
maximum likelihood estimation [34]. We make the follow-
ing contributions:

• We propose two game-theoretic frameworks speciﬁ-
cally designed for adversary with the full or limited
knowledge of the victim algorithm. By introducing the
uncertainty set around the original data, the adversary
aims to ﬁnd a toxic distribution which will maximize
the risk of estimating the ranking parameters. The
dynamic threat model assumes that the adversary is
aware of the original pairwise comparisons, the ranking
algorithm and the ranking parameter learned from the
original data. This model relates to a dynamic distri-
butionally robust game. Besides, we propose a weaker
threat model which assumes that the adversary only
predominates the original data and the ranking algo-
rithm. It induces a static distributionally robust game
where the adversary can only execute the attacks in the
“black-box” attack style.

2

• Different statistical attacks corresponding to the dy-
namic and static threat models are formulated into
the bi-level optimization problem and distributionally
robust optimization problem. In the bi-level optimiza-
tion problem, we adopt χ2 divergence to describe the
uncertainty set around the original data. The optimal
attack strategy can be obtained by the projection onto
a simplex. In the distributionally robust optimization
problem, the uncertainty set is a Wasserstein ball. Based
on the strong duality, the optimal attack behavior is
obtained by a least square problem with a special
regularization.

• We prove the existence of robust optimization equilib-
rium and establish a minimax framework for pairwise
ranking under adversarial setting.
To the best of our knowledge, this is the ﬁrst systematic
study of attacking rank aggregation under different adver-
sarial models. The extensively evaluations are conducted on
several datasets from different high-stake domains, includ-
ing election, crowdsourcing, and recommendation. Our ex-
periments demonstrate that the proposed poisoning attack
could signiﬁcantly decrease the correlation between the true
ranking list and the aggregated result.
Notations

Let V be a ﬁnite set. We will adopt the following nota-

tion from combinatorics:

(cid:33)

(cid:32)

V
k

:= set of all k element subset of V .

(cid:1)

(cid:0)V
2

In particular
would be the set of all unordered pairs
of elements of V . The sets of ordered pair will be denoted
V × V . Ordered and unordered pairs will be delimited by
parentheses (i, j) and braces [i, j] respectively. We will use
positive integers to indicate alternatives and voters. Hence-
forth, V will always be the set [n] = {1, . . . , n} and will
denote a set of alternatives to be ranked. U = {1, . . . , m}
will denote a set of voters. For i, j ∈ V , we write i (cid:31) j to
mean that alternative i is preferred over alternative j. If we
wish to emphasize the preference judgment of a particular
voter u ∈ U , we will write i (cid:31)u j. Suppose that Ω ⊂ Rn
is the data space, we denote (Ω, d(·, ·)) as a metric space
equipped with some metric d : Ω × Ω → R.

2 RANKING WITH PAIRWISE COMPARISONS
Given a collection V of n alternatives, we suppose that each
i ∈ V has a certain numeric quality score θ∗
i . We represent
the quality scores of V as a vector θ∗ ∈ Rn. Suppose that
a comparison of any pair [i, j] ∈ (cid:0)V
is generated via
i , θ∗
the comparison of the corresponding scores θ∗
j in the
presence of noise. Let y∗
ij be the true direction of a pair [i, j]
as

(cid:1)

k

y∗
ij =

(cid:40)

1,
−1,

i > θ∗
θ∗
j ,
i < θ∗
θ∗
j .

(1)

Let C be a collection of N pairwise comparisons

C = {c = [i, j] | yij = 1, i, j ∈ V , i (cid:54)= j},

(2)

and yij is the label of pair [i, j] which could not be consist
with y∗
ij. It is worth noting that C is always a multi-set. For
any pair [i, j], it could be labeled by multiple users. Given a

set of voter U = {u1, . . . , um}, let yu
[i, j] given by voter u ∈ U . We can aggregate yu1
into a weight w0

ij be the judgment of pair
ij , . . . , yum
ij
ij. Deﬁne w(i, j, u) as the indicator of yu
ij:

w(i, j, u) =

(cid:40)

ij = 1, u ∈ U

if yu
1,
0, otherwise

and the weight w0

ij of yij is

w0

ij =

(cid:88)

u ∈ U

w(i, j, u).

(3)

(4)

Moreover, we introduce the comparison matrix A. If there
exists a comparison c ∈ C, it can be described by its label
yij and a row of A as ac = {ac

1, . . . , ac

|C|}:

ac
k =






1, k = i,
−1, k = j,

0, otherwise.

(5)

Then the data of pairwise ranking problem can be repre-
sented by CU = {A, y, w0} where w0 = {w0
ij}, y = {yij}
is a n(n − 1)/2-d binary vector.

In statistical ranking or estimation from pairwise com-
parison, our goal is to obtain a score vector ˆθ to minimize a
loss of a global ranking on the given data CU .

ˆθ ∈ arg min
θ ∈ Rn

(cid:96)(θ; CU ).

In particular, let the estimation of yij be

ˆyij = sgn

(cid:16)

(cid:104)ac, θ(cid:105) + εc

(cid:17)

, ∀ c ∈ C,

(6)

(7)

where sgn(·) is the sign function, εc is the independent
and identically distributed (i.i.d) noise variable and has
a cumulative distribution function (c.d.f ) F . Actually, (6)
minimizes the derivation between the observed label y and
its estimation ˆy = {ˆyij} based on the observing data CU . In
addition, the random variable εc plays the role of a noise
parameter, with a higher magnitude of εc leading to more
uncertainty in the comparisons and the higher probability
of sign inconsistency occurred between yij and θi − θj. The
event that object i dominating object j (yij = 1) is generally
independent of the order of the two items being compared,
thus, the following holds:

Pr(yij = 1) = 1 − Pr(yij = −1)

(8)

and F is a symmetric c.d.f whose continuous inverse is well-
deﬁned. Some typical examples of (7) are the uniform model
[63], the Bradley-Terry- Luce (BTL) model [14], [46], and the
Thurstone model with Gaussian noise (Case V) [67], which
have been extensively studied in literature (e.g., [17], [78]). In
this paper, we focus on the Uniform Model: one can adopt
the symmetric c.d.f F (t) = t+1
2 , and the general set-up (7)
turns to be a linear model. Furthermore, the loss function
in (6) can be specialized as the weighted sum-of-squares
function:

(cid:96) (θ; CU ) =

=

1
2|CU |
1
2|CU |

(cid:107) y − Aθ (cid:107)2

2, w0

(cid:88)

w0

ij ( yij − θi + θj )2.

(9)

(i, j)

3

3 METHODOLOGY
In this section, we systematically introduce the methodology
for poisoning attacks on pairwise ranking. Speciﬁcally, we
ﬁrst start by introducing two game-theoretic threat models
including the full knowledge and the limited knowledge
adversaries. Then we present the corresponding algorithms
to generate the optimal strategies of these threat models
at different uncertainty budgets. Finally, the existence of
equilibrium and the results of generalization analysis are
discussed in the end of this section.

3.1 Poisoning Attack on Pairwise Ranking

We provide here a detailed adversarial framework for poi-
soning attacks against pairwise ranking algorithms. The
framework consists of deﬁning the adversary’s goal, knowl-
edge of the attacked method, and capability of manipulating
the pairwise data, to eventually deﬁne the optimal poison-
ing attack strategies.
The Goal of Adversary. If an adversary executes the poi-
soning attack, he/she will provide the ranker with the toxic
data. This action will mislead its opponent into picking
parameters to generate a different ranking result from ˆθ
obtained by the original data CU in (6). Let ¯θ be the solution
of (6) with the toxic data, it satisﬁes

d(πθ∗ , πˆθ) ≤ d(πθ∗ , π¯θ),
(10)
where θ∗ is the true quality scores of the objects, πθ is
the ranking list decided by θ and d(π1, π2) measures the
similarity of two ordered lists π1 and π2.
The Knowledge of Adversary. We assume two distinct
attack scenarios which are distinguished by the knowledge
of adversary, referred to as dynamic and static attacks in
the following. The adversaries in the two scenarios have
different knowledge of the victims.

• In dynamic attacks, the attacker is assumed to know
the observed data CU , the ranking algorithm, and even
the ranking parameters ˆθ obtained by the original data
CU in (6). If a dictator wants to sabotage the election
which will subvert his/her predominant, he/she would
not need to manipulate the results of the election.
Making the most competitive opponent lose the ad-
vantage in the key districts will achieve the purpose.
The dictator could execute the dynamic strategies as
the aggregation process is a “white-box” to him/her.
This adversarial mechanism can be implemented by
establishing the hierarchical relationship between the
ranker and the attacker. The attacker is assumed to an-
ticipate the reactions of the ranker; this allows him/her
to choose the best—or optimal—strategy accordingly.
Such a hierarchical interaction results in the fact that
the mathematical program related to the ranking pro-
cess is part of the adversary’s constraints. It is also
known as the dynamic or Stackelberg (leader-follower)
game [7] in the literature: the two agents take their
actions in a sequential (or repeated) manner. Moreover,
the hierarchical relationship is the major feature of bi-
level optimization. The bi-level program includes two
mathematical programs within a single instance, one of
these problems being part of the constraints of the other
one.

• In static attacks, the attacker could not grasp ˆθ but is
still aware of the observed data CU and the ranking
algorithm. This scenario comes from the fact that the
ranking aggregation problem does not need the test
protocol. Once the adversary provides the modiﬁed
data, the victim would generate the ranking list im-
mediately. There is no chance to monitor the ranker’s
behavior. In most cases, the adversary can not obtain
ˆθ. There is no feedback for the adversary to update
his/her strategies. A competitor of the e-commerce
platform, who wants to disrupt the recommendation
results and destroy the user experience, would execute
the static strategies. Promoting the rank of speciﬁc
goods is challenging. Disrupting the normal ranking
result is sufﬁcient to archive his/her purpose. The
competitor could only execute the static strategies as
the aggregation process is a “gray-box”. The leading e-
commerce platform is the only one who could access
the ranking parameters. The objective function and the
pairwise comparisons for recommendation can be per-
ceivable to the adversary. This adversarial mechanism
should be modeled as a static game. A static game is
one in which a single decision is made by each player,
and each player has no knowledge of the decision
made by the other players before making their own
decision. In other words, decisions or actions are made
simultaneously (or the order is irrelevant).

k

(cid:1)

The Capability of Adversary. To modify the original data
CU in poisoning attacks, the adversary will inject an ar-
bitrary pair [i, j] ∈ (cid:0)V
with any directions into CU ,
delete the existing comparison c = (i, j) in CU or just
ﬂip the label of c. The three kinds of operations require
some new representations of the observed set. We augment
the observed data CU with the comparisons which are not
labeled by users in U . Let D = V × V be the set of all
ordered pairs, and |D| = N = n(n − 1). The weights of all
0 and there exist 0 entries in w(cid:48)
possible comparisons are w(cid:48)
0.
As D is the complete comparison set, the comparison
matrix B will be ﬁxed and we can adopt a n(n−1)-d single-
value vector to represent the labels, saying that y(cid:48) is a vector
with all entries are 1. Now all attack operations (adding,
deleting and ﬂipping) can be executed by increasing or
decreasing the corresponding weight w(cid:48)
0.

B =



















b1,2
b1,3
...
bn,n−2
bn,n−1

⊂ (cid:8) − 1, 0, 1(cid:9)N ×n

,

y(cid:48) = (cid:8) y1,2, y2,1, . . . , yn−1,n, yn,n−1

(cid:9)(cid:62)

= (cid:8) 1, 1, . . . , 1, 1 (cid:9)(cid:62)

.

Besides injecting the toxic data, the attacker also needs
to disguise himself/herself. It means that the adversary
needs to coordinate a poisoned w = {wij} associated with
w(cid:48)
0. Intuitively, the adversary could not obtain w through
the drastic changes, neither on each wij nor (cid:80)
(i,j) wij.
Such limitations lead to the following constraints for the

4

adversary’s action. First, the total difference between w(cid:48)
0
and w would be smaller than b, namely,
(cid:107) w − w(cid:48)

0 (cid:107)1 ≤ b, b ∈ N+.

(12)

Here the positive integer b bounds the total number of
malicious samples thereby limiting the capabilities of the
attacker. Furthermore, the adversary could not alter the
number of votes on each pairwise comparison c ∈ D
obviously. This constraint on the adversary leads to the
following condition:

(cid:107) w − w(cid:48)

0 (cid:107)∞ ≤ l, l ∈ N+, l ≤ min{max(w(cid:48)
The positive integer l leads the conservative perturbations
on the observed samples. To summarize, the adversary‘s
action set Ω1 is



0), b}.




(13)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

w ∈ NN ,
(cid:107) w − w(cid:48)
(cid:107) w − w(cid:48)

l, b ∈ N,
0 (cid:107)1 ≤ b,
0 (cid:107)∞ ≤ l,

l ≤ min{max(w(cid:48)

0), b}

.



Ω1 =

w

(14)



Furthermore, the attacker must pay for his/her mali-
cious behaviors. Let s : NN × NN → R is a “cost” function
measured the overhead of the perturbation as changing w0
into w. The attacker hopes that the toxic weight w will
represent the lowest cost option. Let Ω2 be the budget set of
the adversary

Ω2 =

(cid:26)

w

(cid:12)
(cid:12) w ∈ arg min s(w, w(cid:48)
(cid:12)
0)

(cid:27)

(15)

Finally, the action set is Ω0 = Ω1 ∩ Ω1 which ﬁgures out the
capability of the adversary.

Poisoning Attack Strategies. Here we specify the different
poisoning strategies for the two attack scenarios.

• Dynamic attack strategy. Consider the goal and knowl-
edge of attacker, we formulate the interaction between
ranker and the adversary with full knowledge as a
dynamic game. In this game, information is assumed
to be complete (i.e., the players’ payoff functions, as
well as the constraint set Ω0 and the ﬂexible set of
ranking parameter Θ, are common knowledge) and
perfect (i.e., the attacker knows the ranker’s decision).
Having received the ranker’s decision ˆθ, the attacker
chooses a feasible decision w ∈ Ω0 that maximizes the
ranker’s loss function to increase the risk of the ranker’s
estimation based on {w, B, y(cid:48)}. Such a dynamic game
can be formulated into the following bi-level optimiza-
tion problem:

(11)

max
w ∈ Ω0

(cid:96)(w; ˆθ, B, y(cid:48)),

subject to ˆθ ∈ arg min
θ ∈ Θ

(cid:96)(θ; w(cid:48)

0, B, y(cid:48)).

(16a)

(16b)

The upper level optimization (16a) amounts to selecting
the toxic data w to maximize the loss function of
the ranker, while the lower level optimization (16b)
corresponds to calculate the ranking parameter ˆθ with
original data {w0, B, y(cid:48)}. Once the adversary gener-
ates w, he/she will deliver the toxic data to the ranker.
Then the poisoned parameter ¯θ will be obtained by

¯θ = arg min
θ ∈ Θ

(cid:96)(θ; w, B, y(cid:48)).

(17)

• Static attack strategy. This strategy is represented such
a type of adversary whose ability is to inﬂict the high-
est possible risk of the ranker when no information
about his/her interests is available. It means that the
two players make decisions simultaneously, and the
attacker does not knows the ranker’s decision. Such a
static game can be formulated into the following min-
max optimization problem:

min
θ ∈ Θ

max
w ∈ Ω0

(cid:96)(θ, w; B, y(cid:48)).

(18)

The poisoned parameter ¯θ will be solved by (17).
However, solving the dynamic and static attack strate-
gies from (16) and (18) are challenging. On one hand, the
bi-level optimization (16) and the min-max problem (18)are
both mixed-integer programming problem as the variable
w is restricted to be positive integers. On the other hand,
the feasible set Ω0 corresponds to a non-linear constraint
as it requires to ﬁnd the perturbation in the neighborhood
of w(cid:48)
0 with the lowest cost. It is well-known that linear
integer programmings are NP-complete problems [36]. Such
a non-linear constraint makes these problems even more
complex. Obviously, adopting the heuristic methods to solve
the optimal attack strategies (16) and (18) is sub-optimal. In
this part, we will develop the other model based on ideas
from distributionally robust optimization [12], [22], [54] that
provides the tractable convex formulations for solving the
optimal strategies in the dynamic and static scenarios.

3.2 Distributional Perspective and Robust Game

In the above formulations (16) and (18), the attacker modi-
ﬁes the number of votes on each pairwise comparison with
constraints Ω0. This formulation leads to the mixed-integer
programming problem. Here we introduce a distributional
perspective to establish the tractable optimization problem.
Generally speaking, the attacker and the ranker both access
the original data D to play the dynamic or static game.
0, B, y(cid:48)} are
The non-toxic pairwise comparisons D = {w(cid:48)
actually drawn from an empirical distribution PN

PN =

1
N

(cid:88)

(cid:48)

δ(w0
ij

c ∈ C

, bi,j, yij

(cid:48)), c = (i, j),

(cid:48), bi,j, yij

(cid:48)) is the Dirac probability measure
where δ(w0
ij
(cid:48), bi,j, yij
(cid:48)). With B and y(cid:48) as (11), the marginal
on (w0
ij
distribution of w(cid:48)
0 plays a vital role in the sequel. With some
abuse of symbol, we treat the marginal distribution of w0 as
the distribution of the original data and
1
N

), c = (i, j).

δ(w0
ij

PN =

(cid:88)

(cid:48)

c ∈ C

The attacker chooses a perturbation function ψ : NN → NN
that changes the weight w(cid:48)
0 to w ∈ Ω0. Such a perturbation
ψ induces a transition from the empirical distribution PN
to a poisoned distribution Q. If the attacker selects Q in a
sufﬁciently small neighborhood of PN , namely, the “distance”
between the poisoned distribution Q and the empirical dis-
tribution P would be sufﬁciently small, the attacker could
obtain a “local” solution and Q is a “good” approximation of
PN in the sense of such a “distance”. Therefore, the poisoned
sample w would satisfy the constraints (12) and (13). Here

5

we directly work with the empirical distribution PN (or
other nominal distribution) and consider Q is close to the
nominal distribution in terms of a certain statistical distance.
There exists some popular choices of the statistical dis-
tance, such as φ-divergences [8], [9], [18], [32], [53], [54], [75],
Prokhorov metric [21], Wasserstein distances [11], [23], [40],
[51], [77] and maximum mean discrepancy [66].

For dynamic attack strategy (16), we adopt

the φ-
divergence [41] as the discrepancy measure between the
empirical distribution Pn and the toxic distribution Q.
Deﬁnition 1 (φ-divergence and χ2-divergence). Let φ :
R+ → R be a convex function with φ(1) = 0. Then the φ-
divergence between distributions Q and P deﬁned on a measurable
space X is

dφ(Q || P) =

(cid:90)

(cid:19)

φ

(cid:18) dQ
dP

dP =

(cid:90)

X

(cid:19)

φ

(cid:18) q(x)
p(x)

p(x)dµ(x),

where µ is a σ-ﬁnite measure on X satisfying Q, P are absolutely
continuous with respect to µ, and q = dQ
dµ are the
Radon–Nikodym derivative with respect to µ. If φ is adopted as
φ(t) = 1

2 (t − 1)2, it is known as the χ2-divergence.

dµ , p = dP

Suppose that X(PN ) is a set of probability distributions
from the empirical distribution with χ2-divergence. This χ2
ball with radius α is given by

Xα(PN ) =

(cid:110)

Q ∈ P(Ω1)

(cid:12)
(cid:12) dχ2(Q || PN ) ≤ α
(cid:12)

(cid:111)

,

(19)

where P(Ω1) denotes the set of all Borel probability mea-
sures on Ω1. With carefully chosen α, the adversary chooses
w from the toxic distribution Q ∈ Xα(PN ). w could satisfy
the neighborhood constraints as (12) and (13). Replacing
the minimal ‘cost’ constraint (15) by the neighborhood con-
straint deﬁned with the χ2 ball, we formulate the following
bi-level optimization to obtain the dynamic attack strategy

(cid:2)(cid:96)(w; ˆθ)(cid:3),

Ew∼Q

max
Q ∈ Xα(PN )
subject to ˆθ = arg min
θ ∈ Θ

(cid:96)(θ; w(cid:48)

0).

(20)

The χ2-divergence and the “local” neighborhood constraint
Q ∈ Xα(PN ) will help us to develop a tractable algorithm
for the dynamic attack strategy.

Different with the dynamic attack strategy, the ranking
parameter ˆθ would be unknown for the adversary in the
static attack strategy. The χ2 divergence will not help to
simplify the min-max problem (18). To sum up, we adopt
the p-Wasserstein distance [22] as the discrepancy measure
between the empirical distribution Pn and the toxic distri-
bution Q for the static attack strategy. The p-Wasserstein
distance will help us to reformulate the min-max problem
(18) into a single regularized problem.

Deﬁnition 2 (p-Wasserstein distance). Let p ∈ [1, ∞]. The
p-Wasserstein distance between distributions P, Q ∈ P(Ω) is
deﬁned as

• 1 ≤ p < ∞

Wp (P, Q)
(cid:32)

min
γ∈Γ(P, Q)

=

(cid:40)(cid:90)

Ω×Ω

(cid:104)

w, w(cid:48)(cid:17)(cid:105)p
(cid:16)

d

(cid:16)

dw, dw(cid:48)(cid:17)

γ

(21)

(cid:41)(cid:33) 1

p

• p = ∞

Wp (P, Q) = inf

γ∈Γ(P, Q)

γ-ess sup
Ω×Ω

(cid:16)

d

w, w(cid:48)(cid:17)

(22)

where Γ(P, Q) denotes the set of all Borel probability distributions
on Ω×Ω with marginal distributions P and Q, d : Ω×Ω → R+
is a nonnegative function, and γ-ess sup expresses the essential
supremum of d(·, ·) with respect to the measure γ.

The Wasserstein distance (21) and (22) arise in the
problem of optimal transport [52], [72]: for any coupling
γ ∈ Γ(P, Q), the conditional distribution γw|w(cid:48) can be
viewed as a randomized overhead for ‘transporting’ a unit
quantity of some material from a random location w ∼ P to
another location w(cid:48) ∼ Q. If the cost of transportation from
w ∈ Ω to w(cid:48) ∈ Ω is given by [d(w, w(cid:48))]p, Wp (P, Q) will
be the minimum expected transport cost [60].

Suppose that Wp(PN ) is a set of probability distributions
constructed from the empirical distribution PN with p-
Wasserstein distance. This Wasserstein ball of radius α is
given by

(cid:110)

Wα

p (PN ) =

Q ∈ P(Ω1)

(cid:12)
(cid:12) Wp (PN , Q) ≤ α
(cid:12)
With local uncertainty set Wα
p (PN ), the min-max optimiza-
tion (18) could be expressed as the following distributionally
robust optimization (DRO) problem:
(cid:104)

(23)

(cid:111)

.

Ew∼Q

(cid:105)
(cid:96)(θ, w)

,

(24)

min
θ ∈ Θ

sup
Q ∈ Wα

p (PN )

where the supremum operation w.r.t. Q means that all play-
ers’ optimal decision is based on the worst expected value
of (cid:96) from the set of distributions Wα
p (PN ). Here we replace
the minimal ‘cost’ constraint in (18) by the neighborhood
constraint on the worst-case expectation. With the local con-
straint Q ∈ Wα
p (PN ), the Wasserstein distance between the
empirical distribution PN and the perturbed distribution Q
must be smaller than a given budget α as Wp (P, Q) ≤ α. It
means that the attacker has a budget α to implement his/her
perturbation on the original data for ranking aggregation.
The robust game formulation (24) would relax the coarse-
grid constraint as (14), and the analysis in the sequel reveals
the central role played by this relaxation.

Actually, the bi-level problem (20) and the DRO problem
(24) relate to a general robust game [1], [44], [45] between
the attacker and the ranker as

min
xr ∈ Xr

sup
Q ∈ U

Eξ∼Q

(cid:104)

(cid:105)
fr(xr, x−r, ξ)

, r = 1, 2

(25)

where r indicates the role of the agent in the robust game,
xr is the decision variable of the special player r, and x−r
denotes the decision variables of its rivals, and Xr is the
action set of player r. The random variable ξ illustrates the
uncertainty or inaccuracy of distributional information to
the players, and U is the uncertainty set of distribution
of random variable ξ for all players (i.e., Xα(PN ) and
Wα
p (PN )). The pay-off function fr could be different for
each player and the corresponding game is a non-zero
sum game. Comparing the general case (25) with (20) and
(24), all players in (24) focus on the same pay-off function
as f1 = f2 = (cid:96). Moreover, the decision variable of the
ranker θ equals to x1. The random variable ξ represents the

6

distribution of pairwise comparison as w. So the decision
variable of the attacker x2 will be the constant (its role
has been replaced by ξ). The robust game problem is ﬁrst
proposed by Bertsimas and Aghassi in [1]. It expands the
boundaries of research of the classical Nash game [55], [56],
[73] and the Bayesian game [26], [27], [28]. Different form
the Nash and the Bayesian game [1], the only common
knowledge of all participants in robust game is that all
players being aware about an uncertainty set like Xα(PN )
and Wα
p (PN ). All possible parameters of payoff function
are related to this set. Here we investigate the existence of
the equilibrium for distributionally robust Nash equilibrium
of the proposed model (25). First, we give the deﬁnition of
the distributionally robust Nash equilibrium.
Deﬁnition 3. A pair of different players’ action {x∗
2} is
called a distributionally robust Nash equilibrium (DRNE) of (25)
if they satisfy the following

1, x∗

x∗

r ∈ arg min
xr ∈ Xr

sup
Q ∈ U

Eξ∼Q

(cid:104)

(cid:105)
fr(xr, x−r, ξ)

, r = 1, 2. (26)

Next, we can prove the existence of DRNE for the general

robust game (25).

Theorem 1. Let the pay-off function fr, r = 1, 2 be the weighted
sum-of-squared loss (cid:96) (9) in (25). If the uncertainty set is Xα(PN )
or Wα
p (PN ), the general robust game (25) has a DRNE.

To prove this existence result, we reformulate the prob-
lem (25) into a single optimization problem and show that
the single problem has an optimal solution. The detailed
proof is provided in the Appendix A.

3.3 Optimization

In this part we show our algorithms for computing the
adversarial strategies. Suppose the total number of pairwise
comparison without perturbation is M 0, and the frequencies
of each type of the observed comparisons are

p =

1
M 0 · w(cid:48)

0, M 0 =

w0
ij

(cid:48)

.

(cid:88)

(i,j)

(27)

Let the maximum toxic dosage be κ. It suggests that the
number of toxic pairwise comparisons M satisﬁes

M =

(cid:88)

(i,j)

wij ≤ (1 + κ) · M 0.

(28)

We replace the toxic weight w with its frequency q =
{qij} ∈ RN
+ when analyzing the equilibrium, studying the
statistical nature of the worst-case estimator and solving the
corresponding optimization problem. We relax the integer
programming problem into a general optimization by such
a variable substitution. Thus, the pay-off function (9) turns
to be

(cid:96)(θ, q) =

1
2N

(cid:88)

(i,j)

qij

(cid:0)yij − θi + θj

(cid:1)2

,

(29)

and we still adopt PN and Q as the distribution of the
empirical data and the toxic data. Furthermore, we can
implement the integer attack with the optimal q and M .
Now we come to solve the bi-level optimization (20) and

the distributionally robust optimization problem (24) with
the variable substitution:

(cid:2)(cid:96)(q; ˆθ)(cid:3),

Eq∼Q

max
Q ∈ Xα(PN )
subject to ˆθ = arg min
θ ∈ Θ

(cid:96)(θ; w(cid:48)

0),

and

min
θ ∈ Θ

sup
Q ∈ Wα

p (PN )

Eq∼Q

(cid:104)

(cid:96)(cid:0)θ; q(cid:1) (cid:105)

(30)

(31)

For the dynamic attack strategy (30), a similar formula-
tion has been studied for archiving a better variance-bias
trade-off in maximum likelihood estimation [54]. Based on
the χ2-divergence, the bi-level problem (30) turns to be a
convex problem. We provide a detailed process of solving
(30) in the supplementary material.

The distributionally robust optimization formulation
(31) involves optimizing over the uncertainty set Wα
2 (PN ),
which contains countless probability measures. However,
recent strong duality results of distributionally robust op-
timization involving Wasserstein uncertainty set [23, Theo-
rem 1] and [12, Theorem 1]) ensure that the inner supremum
in (31) admits an equivalent reformulation which would be
a tractable, univariate optimization problem. In the adver-
sarial scenario of pairwise ranking, we have the following
result. The DRO problem (31) could be reformulated as a
regularized regression problem.
Theorem 2. Let Z = (cid:8)p, B, y(cid:48)(cid:9) be the observed data set,
where B and y(cid:48) are deﬁned as (11), p is the frequency of each
type of pairwise comparison as (27). Consider the loss function
of z, and the distance function between zc, z(cid:48)
c are based on the
(cid:96)2-norm. In other words, we take (cid:96)(θ, z) as (29) and
c) = (cid:13)
(cid:0)pij, bi,j, y(cid:48)
(cid:1) − (cid:0)qij, bi,j, y(cid:48)
(cid:13)
(cid:12)
= (cid:12)
(cid:12).
(cid:12) pij − qij

d(zc, z(cid:48)

(cid:1)(cid:13)
(cid:13)2

(32)

ij

ij

Then, the DRO problem (31) has an equivalent form:
(cid:96)(cid:0)θ; q(cid:1) (cid:105)

Eq∼Q

(cid:104)

min
θ ∈ Θ
= min
θ ∈ Θ

sup
Q ∈ Wα
2 (PN )
L(θ) + R(θ),

where

and

L(θ) =

1
2N

(cid:88)

(i, j)

pij(y(cid:48)

ij − θ(cid:62)bi,j)2,

R(θ) =

(cid:115) α
4N

(cid:88)

(y(cid:48)

ij − θ(cid:62)bi,j)2.

(i, j)

(33)

(34)

(35)

We provide a detailed proof in the Appendix B. The ex-
ample of linear regression with Wasserstein distance based
uncertainty sets has been considered in [11]. The represen-
tation for regularized linear regression in Theorem 2 can
be seen as an extension of [11]. We adopt the weighted
sum-of-squared loss and the “regularization” (35) here is
not the (cid:96)2-norm of θ. (35) can be treated as a “regulariza-
tion” which is the square root of the residual between y(cid:48)
ij
and its estimation. It represents a ‘worst’ case in pairwise
ranking: all possible comparisons appear and they have the
same number of votes. In this case, the pairwise ranking

7

algorithm could not generate a reasonable ranking result.
The uncertainty budget α play the role as the regularization
parameter. As α increase, the ranking scores θ obtained by
(33) would come closer to the solution of (35). The validity
of the analysis above will be illustrated in the empirical
studies.

With Theorem 2, we will have the following corollary
which gives a tractable method to obtain the worst-case
distribution q∗
α. If we have the worst-case solution, we can
solve the corresponding dual variable from the optimal vale
of the original DRO problem.

Corollary 1. For λ ≥ 0 and the weighted least square loss (29),
we deﬁne ψ : RN → R

ψλ, (cid:96)(p; θ)

= sup

z(cid:48)∈Rn+2

1
N

(cid:88)

(cid:110)

(cid:96)(θ; qij) − λ(pij − qij)2(cid:111)

(36)

(i,j)

where

Let

we have

(cid:96)(θ; qij) =

qij
2

(cid:0)y(cid:48)

ij − θi + θj

(cid:1)2

.

Iprimal =

sup
Q ∈ Wα

2 (PN )

Ez(cid:48)∼Q

(cid:104)

(cid:96)(cid:0)θ; z(cid:48)(cid:1)(cid:105)

,

(cid:40)

λα + Ez(cid:48)∼Q

(cid:104)

(cid:105)
ψλ, (cid:96)(p; θ)

(cid:41)
.

Iprimal = inf
λ≥0

(37)

(38)

(39)

Moreover, let θ∗
(33) and the dual variable of θ∗

α be the optimal solution of the right hand side of
α will be a solution of (39):

α is λ∗

λ∗
α =

(cid:118)
(cid:117)
(cid:117)
(cid:116)

1
16N α

·

(cid:88)

(cid:0)y(cid:48)

ij − (θ∗

α)(cid:62)bi,j

(cid:1)2

.

(i,j)

The optimal static attack strategy q∗
corresponding to θ∗

α is a solution of

α and λ∗
α:
(cid:40)

(cid:16)
ij − (θ∗
y(cid:48)

α)(cid:62)ac

qij

(cid:17)2

− λ∗

α|pij − qij|2

(cid:41)
.

q∗
α = arg max
q ∈ RN
+

(cid:88)

(i,j)

Finally, we describe the whole optimization of the static
poisoning attack on pairwise ranking with Algorithm 1.
First, the adversary changes the original weight w(cid:48)
0 into
the frequency p as the initialization (line 1). By Theorem
2, the attacker could obtain the worst-case estimation θ∗
α
through (33) (line 2). But the attacker cannot adopt θ∗
α as the
attack operation. Here we solve the dual variable λ∗
α (line
4) to ﬁnd the toxic distribution. Then the toxic distribution
q∗
α with uncertainty budget α is obtained by Corollary 1
(line 4). With some rounding operation (line 5 & 6), the
α, B, y(cid:48)}. Then
adversary prepares the poisoned data {w∗
the poisoned data is provided to the ranker who solved
the ranking parameter by (17). Then the whole poisoning
process will be completed.

3.4 Theoretical Analysis

In this section, we come back to (31) and give a couple of
inequalities relating the local worst-case (or local minimax)
risks and the usual statistical risks of the pairwise ranking
under adversarial conditions. In the traditional paradigm

(40)

(36)

Algorithm 1: Static Poisoning Attack on Pairwise
Ranking.

Input

: the original data {w(cid:48)
maximum toxic dosage κ, the uncertainty
budget α.

0, B, y(cid:48)}, the

1 Initialize the frequency of weights p by (27)
2 Obtain the worst-case ranking scoring θ∗

α under the

uncertainty budget α
(cid:32)

θ∗

α ∈ arg min
θ∈Θ

(cid:114) α
4N

(cid:80)

(i,j)

(y(cid:48)

ij −θ(cid:62)bi,j )2+ 1
2N

(cid:80)

(i,j)

pij (y(cid:48)

ij −θ(cid:62)bi,j )2

3 Calculate the optimal dual variable through (40)

(cid:115)

λ∗

α =

1
16N α

(cid:80)

(i,j)

(cid:0)y(cid:48)

ij −(θ∗

α)(cid:62)bi,j

(cid:1)2

.

4 Obtain the toxic distribution q∗

α corresponding to θ∗
α

and λ∗
α

q∗

α ∈ arg max
q∈RN
+

(cid:80)

(i,j)

(cid:110)

qij (y(cid:48)

ij −(θ∗

α)(cid:62)bi,j )2−λ∗

α|pij −qij |2

5 Assign the toxic weights with q∗
α

wα = M0(1+κ)·q∗
α.

6 Round wα to obtain the w∗

α as integer vector

w∗

α = rounding(wα).

Output: the poisoned data {w∗

α, B, y(cid:48)}.

of statistical learning [71], we have a class of probability
measures P on a measurable instance space Z and a class F
of measurable functions (cid:96) : Z → R+. Each (cid:96) ∈ F quantiﬁes
the loss of a certain decision rule or a hypothesis. With
a slight abuse of terminology, we will refer to F as the
hypothesis space. The (expected) risk of a hypothesis (cid:96) on
instances generated according to P ∈ P(Z) is given by

and

RP((cid:96)) := Ez∼P

(cid:2)(cid:96)(z)(cid:3) =

(cid:90)

Z

(cid:96)(z) P(dz).

(41)

Given an N -tuple {z1, . . . , zN } of i.i.d. training examples
drawn from an unknown distribution P ∈ P, the objective
is to ﬁnd a hypothesis f ∈ F whose risk R(P, (cid:96)) is close to
the minimum risk

R∗

P(F) := inf
(cid:96) ∈ F

RP((cid:96))

(42)

with high probability. Under some suitable regularity as-
sumptions, this objective can be accomplished via Empirical
Risk Minimization (ERM):

RPN ((cid:96)) :=

1
N

N
(cid:88)

i=1

(cid:96)(zc)

and the minimum empirical risk is
R∗
PN

(F) := min
(cid:96) ∈ F

RPN ((cid:96)),

(43)

(44)

(cid:80)N

where PN = 1
c=1 δzc is the empirical distribution of the
N
training examples. Meanwhile, the minimax risk [40] can be
deﬁned as

8

We assume that the instance space Z is a Polish space
(i.e., a complete separable metric space) with metric dZ . We
denote by P(Z) the space of all Borel probability measures
on Z, and by Pm(Z) with m ≥ 1 the space of all P ∈ P(Z)
with ﬁnite m-th moments. The metric structure of Z can be
used to deﬁne a family of metrics on the spaces Pm(Z). We
then deﬁne the local worst-case risk of (cid:96) at P,

(cid:33)

.

RP,α,p((cid:96)) :=

sup
Q ∈ Wα

p (PN )

RQ((cid:96))

(46)

and the local minimax risk of P,
R∗

P,α,p(F) := inf
(cid:96) ∈ F

RP,α,p((cid:96)).

(47)

Next, we analyze the performance of the local minimax

ERM procedure of the pairwise ranking, namely,
ˆ(cid:96) ∈ arg min

RPN ,α,2((cid:96)).

(48)

(cid:111)
.

(cid:96) ∈ F

Theorem 3. Consider the setting of pairwise ranking problem
with the sum-of-squared loss, for any t > 0, it holds

(cid:16)

Pr

∃ (cid:96) ∈ F : RP,α,2((cid:96)) > ς1

(cid:17)

≤ e−2t2

(cid:16)
∃ (cid:96) ∈ F : RPN ,α,2((cid:96)) > ς2

(cid:17)

Pr

≤ 2e−2t2

(49)

(50)

and

where

(cid:40)

ς1 = min
λ≥0

λα2 + Ez∼Q

(cid:41)

(cid:2) ψλ,(cid:96) (z) (cid:3)

+

24J (F) + t
N

√

.

ς2 = min
λ≥0
(cid:40)

min
λ≥0

(cid:40)

(λ + 1)α2 + Ez∼Q

(cid:2) ψλ,(cid:96) (z) (cid:3)

(cid:112)

log(λ + 1)
N

√

(cid:41)

+

24J (F) + t
N

√

,

+

(51)

(52)

where J (F) is the Dudley’s entropy integral [20], which is served
as the complexity measure of the hypothesis class F .

Theorem 3 is a type of data-dependent generalization
bounds which is proposed for margin cost function class
[38], [40]. By the strong duality results, we can establish this
result from the dual representation of the Wasserstein DRO
problem. The detailed proof is provided in the Appendix D.
Here we note that the hypothesis selected by the minimax
ERM procedure (48) are uniform smoothness with respect
to the underlying metric dZ (·, ·). Further, we have the
following result. Proofs are relegated to the Appendices E.

Theorem 4. Consider the setting of pairwise ranking problem
with the sum-of-squared loss, the following holds with probability
as least 1 − η

RP,α,2(ˆ(cid:96)) − R∗

≤

48J (F)
√
N

+

P,α,2(F)
48L(cid:2)diam(Z)(cid:3)2
√

α

N

(cid:115)

+ 3

log( 2
η )
2N

,

where diam(Z) is the diameter of Z)

(53)

(54)

ˆRPN (F) := min

(cid:96) ∈ F

sup
Q ∈ W(PN )

RQ((cid:96))

(45)

diam(Z) = sup
z,z(cid:48)∈Z

dZ (z, z(cid:48)).

4 EXPERIMENTS

In this section, four examples are exhibited with both sim-
ulated and real-world data to illustrate the validity of the
proposed poisoning attack on pairwise ranking. The ﬁrst
example is with simulated data while the latter three exploit
real-world datasets involved crowdsourcing, election and
recommendation.

4.1 Simulated Study

Settings. We ﬁrst validate our poisoning attack framework
on simulated data. We create a random total ordering on
set V with n candidates as the ground-truth ranking and
generate the comparison matrix B and the labels y(cid:48) as
(11). Next, we generate the ground-truth weight of each
comparisons w0. Notice that the original data {w0, B, y(cid:48)}
consists of some noisy comparisons. In the simulation
study, we can specify the percentage of noisy comparisons,
denoted as (cid:37). We validate the proposed attack framework
when n, w0 and (cid:37) vary. Moreover, the maximum toxic
dosage κ and the uncertainty budget α are the hyper-
parameters of the Algorithm 1. Since the annotations of
pairwise data are usually collected via crowdsourcing
platforms where the attacker could produce hundreds of
zombie accounts easily to inject the poisoned pairwise
comparisons, we also vary κ and α in our experiments. At
last, there exists a rounding operator in the Algorithm 1
and we explore the results of different rounding functions,
e.g. ceiling, ﬂoor, and the nearest integer of each element in
wα.

Competitors. To the best of our knowledge, the proposed
method is the ﬁrst poisoning attack on pairwise ranking. To
see whether our proposed method could provide efﬁcient
perturbation data for misleading the pairwise ranking
algorithm, we implement the random perturbation attack
(referred to as ‘Random’) and the Stackelberg or dynamic
game attack (referred to as ‘Dynamic’) as the competitors.
• The random perturbation attack modiﬁes w0 as wrandom
to manipulate the ranking result. The random perturba-
tion attack generates wrandom and obeys the constraints
(12) and (13) to hide his/her behaviors. We vary b and
l to explore the ability of random attack. The random
perturbation data is noted as Zrandom = {A, y, wrandom}.
We assume this attacker is also lack of prior knowledge on
the true ranking. So the random perturbation attack also
adopts the ﬁxed label set y.

• The Stackelberg (dynamic) game attack comes from (16).
To execute this type of poisoning attack, the adversary
would have the full knowledge of original training data
w0 and the corresponding relative ranking score θoriginal.
With these advantages, the adversary can adjust his/her
strategies to provide the optimal malicious action with
the bi-level optimization like (16). Without a doubt, the
adversary endues with the privilege by such a hierarchical
relation. For the fair competition, we only perform one
round of the leader-follower game as the other competi-
tors. Notice that this kind to attack is also proposed by
this paper. Due to the length limitation, we provide the
details of this attack in the supplementary materials.

9

It is worth noting that the poisoning attack with dynamic
game is not a practical attack method. (16) is a bi-level op-
timization and the maximization process needs the solution
of the minimization problem. In other words, the attacker
must obtain the relative ranking score ˆθ estimated from the
original training data without perturbation. This operation
is much harder than injecting some modiﬁed training sam-
ples into the victim’s training set. Only the so-called “white-
box” setting would satisfy its necessary requirements. As
the ‘Dynamic’ method needs more exorbitant conditions, the
‘Dynamic’ method only reﬂects the vulnerability of ranking
aggregation algorithms but can not show the superiority of
the ‘Static’ method.

Evaluation Metrics. We adopt the following measures for
evaluating the ranking results aggregated by the different
sets of pairwise comparisons.
• Kendall τ Distance (Kendall-τ ). The Kendall rank correla-
tion coefﬁcient evaluates the degree of similarity between
two sets of ranks given the same objects. This coefﬁcient
depends upon the number of inversions of pairs of objects
which would be needed to transform one rank order into
the other. Let V = [n] be a set of n candidates and π1, π2
are two total orders or permutations on V , the Kendall τ
distance is deﬁned to be

dK(π1, π2) =

2
n(n − 1)

· ϑ,

(55)

where

n−1
(cid:88)

n
(cid:88)

ϑ =

i=1

j=i+1

ϑ(π1(i), π1(j), π2(i), π2(j))

(56)

is the number of different pairs between these two ordered
sets π1, π2 as

ϑ(π1(i), π1(j), π2(i), π2(j))



if (π1(i) − π1(j))(π2(i) − π2(j)) > 0,
if (π1(i) − π1(j))(π2(i) − π2(j)) < 0,
otherwise,

1,
−1,
0,

=



(57)

and π1(i) represents the ranking score of the ith object in
ranking list π1. Kendall τ distance counts the number of
pairwise mismatches between two rank orders. Then this
metric considers all candidates of V . However, Kendall-τ
ignores the importance of the top objects in a ranking list.

• Reciprocal Rank (R-Rank). The reciprocal rank is a statis-
tic measure for evaluating any process that produces an
order list of possible responses to a sample of queries,
ordered by the probability of correctness or the ranking
scores. The reciprocal rank of a rank order is the multi-
plicative inverse of the rank of the ﬁrst correct object:

RR =

1
ranki

,

(58)

where ranki refers to the rank position of
candidates of the ground-truth ranking in the other list.

the ﬁrst

• Precision at K (P@K). Precision at K is the proportion
of the top-K objects in the other rank order that are
the
consistent with the true ranking.
precision and recall will be the same. So we do not report

In this case,

(a) α = 10−6

(b) α = 10−3

(c) α = 1

Fig. 1: The amount of changed pairwise comparisons by the
poisoning attack with static game. The x-axis is the index
of pairwise comparisons and the y-axis is the amount of
change. Note that the ranges of y-axis in each sub-ﬁgure are
different.

Fig. 2: The number of correct pairwise comparisons and
comparisons which conﬂict with the ground-truth ranking
in the poisoned training set by ‘Static’ method.

the recall and F score for our poisoning attack method.

• Average Precision at K (AP@K). Average precision at K
is a weighted average of the precision. If the top objects in
the new ranking list are consistent with the true ranking,
they will contribute more than the tail objects in this
metric.

• Normalized Discounted Cumulative Gain

at K
(NDCG@K). Using a graded relevance scale of objects in
ranking result, discounted cumulative gain (DCG) mea-
sures the usefulness, or gain, of the objects based on its
position in the order list when recovering to the true
ranking. The gain is accumulated from the top to the
bottom, with the gain of each result discounted at lower
ranks. Compared to DCG, NDCG will be normalized by
the ideal DCG.

10

Comparative Results. We display the comparative results
of different attack methods in Table 1. There the number
of candidates ranges from 10 to 100 ( n = 10, 20, 50, 100 ).
The percentage of noisy comparisons is (cid:37) = 0 in the four
cases. We let the maximum toxic dosage to be 0 as κ = 0
to verify the effectiveness of the worst-case distribution in
the Wasserstein ball with uncertainty budget α. We show
the attack effect of ‘Static’ and ‘Dynamic’ methods with
different budgets. The performance of ‘Random’ are affected
by two parameters: the percentage of the new comparisons
injected into the original training set, and the percentage of
the existed comparisons deleted from the original training
set. Here we set these two parameters be s1 = s2 = 0.05. We
obtain the following observations from Table 1. The ‘Static’
method can decrease the Kendall-τ when the uncertainty
budget α increases. Looking back on the Algorithm 1, the
uncertainty budget α is the weight of the second term in
(33) and the two parts of (33) have the same monotonic
respect to θ. With the increasing of α, the impact of the
second term (35) to the solution (33) becomes gradually.
The solution of (35) means that the algorithm will adopt all
possible pairwise comparisons with same number of voting
to aggregate the ﬁnal ordered list. There is no doubt that this
case would be far away from the ground-truth ranking. If
α approaches ∞, we would obtain this confusing solution.
This explains the behaviors of the ‘Static’ methods when
the Kendall-τ is larger than 0. In Figure 1, we see that
the ‘Static’ method does two things to perturb the training
set: adding pairwise comparisons which conﬂict with the
ground-truth ranking and removing the pairwise compar-
isons which is consistent with the ground-truth ranking.
The total amount of change enlarge when the uncertainty
budget α increase. If the Kendall-τ is smaller than 0, it
means that the poisoned training dataset would support an
opposite ranking list. In Figure 2, each group corresponds
to a poisoned data set by ‘Static’ method with a certain
uncertainty budget. When the Kendall-τ is smaller than 0
(α ≥ 10−3), we observe that the number of comparisons
which conﬂict with the ground-truth ranking is larger that
the number of comparisons which is consistent with the
ground-truth ranking. Such training data could generate an
arbitrarily ordered list. If it happens, the Kendall-τ could not
monotonically decrease when we increase the uncertainty
budget continuously. Moreover, the uncertainty budget α
plays a totally different role in the ‘Dynamic’ method. The
existing work [18], [54] reveal that such kind of min-max
problem is a new type of regularization. This regularization
also carries out the ‘bias-variance’ trade-off like the classical
approaches like Tikhonov regularization. In this case, the
uncertainty budget α can be explained as a regularization
coefﬁcient. The Kendall-τ of ‘Dynamic’ method presents a
‘U’-type curve in our experiments.

Visualization. We visualize the ranking list in Figure 3.
The visualization shows the same phenomenons as the
numeric results in Table 1. As the target ranking aggregation
algorithm does not emphasize the top-K results and the
adversary has no prior knowledge of the ranking results,
the untrustworthy results of ‘Static’ method only depend on
the original data and the uncertainty budget. So the pro-
posed method is the non-target attack for pairwise ranking

TABLE 1: Comparative results of different attack methods on simulated data.

11

Method

Budget

Kendall-τ

Tendency (ideal)

R-Rank P@3 AP@3 NDCG@3

Method

Budget

Kendall-τ

Tendency (ideal)

R-Rank P@5 AP@5 NDCG@5

Original

-

1.0000

Random

0.05/0.05

0.9556

-

-

1.0000 1.0000 1.0000

1.0000

Original

-

1.0000

1.0000 1.0000 1.0000

1.0000

Random

0.05/0.05

0.9684

-

-

1.0000 1.0000 1.0000

1.0000

1.0000 1.0000 1.0000

1.0000

Static

Dynamic

10−6
10−5
10−4
10−3
10−2
10−1
1

10−6
10−5
10−4
10−3
10−2
10−1
1

1.0000
1.0000 (−)
1.0000 (−)
-0.6889 (↓)
-1.0000 (↓)
-0.8222
-0.9111

-0.7333
-0.7333 (−)
-0.7333 (−)
-0.7333 (−)
0.5111 (↑)
0.3778 (↓)
-0.4222 (↓)

1.0000 1.0000 1.0000
1.0000 1.0000 1.0000
1.0000 1.0000 1.0000
0.1111 0.0000 0.0000
0.1000 0.0000 0.0000
0.1250 0.0000 0.0000
0.1111 0.0000 0.0000

0.1429 0.0000 0.0000
0.1429 0.0000 0.0000
0.1429 0.0000 0.0000
0.1429 0.0000 0.0000
1.0000 0.3333 0.3333
0.5000 0.0000 0.0000
1.0000 0.3333 0.3333

1.0000
1.0000
1.0000
0.0000
0.0000
0.0000
0.0000

0.0000
0.0000
0.0000
0.0000
0.4040
0.0000
0.4040

Static

Dynamic

10−6
10−5
10−4
10−3
10−2
10−1
1

10−6
10−5
10−4
10−3
10−2
10−1
1

1.0000
0.9684 (↓)
-0.4737 (↓)
-1.0000 (↓)
-0.4842
-0.7474
-0.7579

-0.7579
-0.7579 (−)
-0.7279 (−)
-0.6842 (↑)
1.0000 (↓)
0.4526 (↓)
-0.7053 (↓)

1.0000 1.0000 1.0000
1.0000 1.0000 1.0000
0.0588 0.0000 0.0000
0.0500 0.1000 0.0333
0.0526 0.0000 0.0000
0.0500 0.0000 0.0000
0.0500 0.0000 0.0000

0.0556 0.0000 0.0000
0.0556 0.0000 0.0000
0.0556 0.0000 0.0000
0.0556 0.0000 0.0000
1.0000 1.0000 1.0000
0.2500 0.2000 0.0400
1.0000 0.2000 0.2000

1.0000
1.0000
0.0000
0.1127
0.0000
0.0000
0.0000

0.0000
0.0000
0.0000
0.0000
1.0000
0.1546
0.2738

Method

Budget

Kendall-τ

Tendency (ideal) R-Rank P@10 AP@10 NDCG@10

Method

Budget

Kendall-τ

Tendency (ideal) R-Rank P@10 AP@10 NDCG@10

Original

-

1.0000

Random

0.05/0.05

0.9396

-

-

1.0000 1.0000

1.0000

1.0000

Original

-

0.9996

0.5000 0.1000

0.0250

0.1012

Random

0.05/0.05

0.9543

-

-

1.0000 1.0000

1.0000

1.0000

0.5000 0.2000

0.0422

0.1688

Static

Dynamic

10−6
10−5
10−4
10−3
10−2
10−1
1

10−6
10−5
10−4
10−3
10−2
10−1
1

0.9886
0.6327 (↓)
-0.9200 (↓)
-1.0000 (↓)
-0.6637
-0.7224
-0.7741

-0.7486
-0.7486 (−)
-0.6669 (↑)
0.8824 (↑)
1.0000 (↑)
-0.0580 (↓)
-0.8808 (↓)

1.0000 0.8000
1.0000 0.3000
0.0227 0.0000
0.0200 0.0000
0.0294 0.0000
0.0250 0.0000
0.0200 0.0000

0.0238 0.0000
0.0238 0.0000
0.0238 0.0000
0.5000 0.1000
1.0000 1.0000
0.1429 0.0000
0.3333 0.0000

0.6709
0.2333
0.0000
0.0000
0.0000
0.0000
0.0000

0.0000
0.0000
0.0000
0.0200
1.0000
0.0000
0.0000

0.8056
0.3715
0.0000
0.0000
0.0000
0.0000
0.0000

0.0000
0.0000
0.0000
0.0932
1.0000
0.0000
0.0000

Static

Dynamic

10−6
10−5
10−4
10−3
10−2
10−1
1

10−6
10−5
10−4
10−3
10−2
10−1
1

0.9762
-0.8242 (↓)
-0.9996 (↓)
-0.6776
-0.6933
-0.7459
-0.8307

-0.7693
-0.7568 (↑)
-0.7095 (↑)
0.9996 (↑)
0.4853 (↓)
-0.6402 (↓)
-0.9402 (↓)

1.0000 0.2000
0.0119 0.0000
0.0100 0.0000
0.0102 0.0000
0.0133 0.0000
0.0102 0.0000
0.0103 0.0000

0.0120 0.0000
0.0120 0.0000
0.0120 0.0000
1.0000 1.0000
0.0333 0.0000
0.0286 0.0000
0.0222 0.0000

0.1000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000

0.0000
0.0000
0.0000
1.0000
0.0000
0.0000
0.0000

0.2380
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000

0.0000
0.0000
0.0000
1.0000
0.0000
0.0000
0.0000

TABLE 2: Comparative results of different attack methods
on human age data.

Method

Budget

Kendall-τ

Tendency

R-Rank P@10 AP@10 NDCG@10

Original

-

0.6872

Random

0.05/0.05

0.7425

-

-

0.3333 0.0000

0.0000

0.0000

0.3333 0.0000

0.0000

0.0000

Static

Dynamic

10−6
10−5
10−4
10−3
10−2
10−1
1

10−6
10−5
10−4
10−3
10−2
10−1
1

0.7149
0.7793
-0.3655
-0.5402
-0.6552
-0.1724
-0.4851

-0.5494
-0.5494
-0.5494
-0.5448
0.6782
-0.2000
-0.7517

0.3333 0.1000
0.5000 0.3000
0.0500 0.0000
0.0345 0.0000
0.0345 0.0000
0.0385 0.0000
0.0500 0.0000

0.0345 0.0000
0.0345 0.0000
0.0345 0.0000
0.0345 0.0000
0.3333 0.0000
1.0000 0.1000
0.3333 0.0000

0.0500
0.1095
0.0000
0.0000
0.0000
0.0000
0.0000

0.0000
0.0000
0.0000
0.0000
0.0000
0.1000
0.0000

0.1308
0.2842
0.0000
0.0000
0.0000
0.0000
0.0000

0.0000
0.0000
0.0000
0.0000
0.0000
0.1651
0.0000

Fig. 3: The ranking generated from the original data (Orig-
inal), random attack data (Random), static poisoning attack
data (Static) and dynamic poisoning attack data (Dynamic).

algorithm. Manipulating the ranking list with speciﬁc goals,
a.k.a the target attack, is the future work.

4.2 Human Age

Description. 30 images from human age dataset FGNET are
annotated by a group of volunteer users on ChinaCrowds
platform. The ground-truth age ranking is known to us.
The annotator is presented with two images and given a
binary choice of which one is older. Totally, we obtain 8, 017
pairwise comparisons from 94 annotators.

Comparative Results. Notice that the real-world data
has a high percentage of outliers (about 20% comparisons
conﬂict with the correct age ranking). We observe similar
phenomenons as the simulation experiments. When the un-
certainty budget increase, the ‘Static’ method would inject
more comparisons which conﬂict with the true age ranking
and delete the original comparisons which indicate the
true ordered list. Once the ‘wrong’ samples overwhelm the
‘correct’ samples, the ranking aggregation algorithm would
like to generate a reversed list. As there are only the ‘wrong’
samples in the toxic training set by ‘Static’ method, the ﬁnal
result could be arbitrary.

2468101214161820TABLE 3: Comparative results of different attack methods
on Dublin election data.

12

Method

Budget

Kendall-τ

Tendency

R-Rank P@5 AP@5 NDCG@5

Original

-

0.4725

Random

0.05/0.05

0.4736

-

-

0.0769 0.4000 0.2333

0.4038

0.0769 0.4000 0.2333

0.4038

Static

Dynamic

10−6
10−5
10−4
10−3
10−2
10−1
1

10−6
10−5
10−4
10−3
10−2
10−1
1

0.4725
0.4725
0.5824
-0.3846
-0.4725
-0.4725
-0.0330

0.4286
0.5385
0.5385
0.4725
0.5385
0.5385
0.1648

0.0769 0.4000 0.2333
0.0769 0.4000 0.2333
0.0769 0.0000 0.0000
0.1250 0.0000 0.0000
0.1250 0.0000 0.0000
0.1250 0.0000 0.0000
0.1250 0.0000 0.0000

0.0769 0.0000 0.0000
0.0769 0.0000 0.0000
0.0769 0.0000 0.0000
0.0769 0.4000 0.2333
0.0769 0.6000 0.3533
1.0000 0.2000 0.2000
0.3333 0.0000 0.0000

0.4038
0.4038
0.0000
0.0000
0.0000
0.0000
0.0000

0.0000
0.0000
0.0000
0.4038
0.5584
0.2738
0.0000

TABLE 4: Comparative results of different attack methods
on Sushi election data.

Method

Budget

Kendall-τ

Tendency

R-Rank P@3 AP@3 NDCG@3

Original

-

1.0000

Random

0.05/0.05

1.0000

-

-

Static

Dynamic

1e-6
1e-5
1e-4
1e-3
1e-2
1e-1
1

1e-6
1e-5
1e-4
1e-3
1e-2
1e-1
1

1.0000
1.0000
1.0000
-0.9556
-1.0000
-1.0000
-0.7333

0.4222
0.4222
0.4667
0.7333
1.0000
0.7778
0.4222

1.0000 1.0000 1.0000

1.0000

1.0000 1.0000 1.0000

1.0000

1.0000 1.0000 1.0000
1.0000 1.0000 1.0000
1.0000 1.0000 1.0000
0.2500 0.0000 0.0000
0.2500 0.0000 0.0000
0.2500 0.0000 0.0000
0.2500 0.0000 0.0000

0.1000 0.0000 0.0000
0.1000 0.0000 0.0000
0.1000 0.0000 0.0000
0.1250 0.3333 0.1667
1.0000 1.0000 1.0000
0.2500 0.0000 0.0000
0.2500 0.0000 0.0000

1.0000
1.0000
1.0000
0.0000
0.0000
0.0000
0.0000

0.0000
0.0000
0.0000
0.3202
1.0000
0.0000
0.0000

shows positive correlation with the actual election result.
Different from the manipulation or strategic voting setting
in election, the adversary could control the whole votes
but with some constraints. As a consequence, the poisoning
attack could break the barrier of computational complex-
ity [69], [74]. The proposed method focuses on the ‘non-
target’ attack on pairwise ranking aggregation. The ‘Static’
method could perturb the ranking list generated by the
original algorithm with a sufﬁcient uncertainty budget. But
the adversary is not able to manipulate the order with
her/his preference as she/he can not decide the winner of
election. We call the problem as the ‘target’ attack, where the
adversary manipulates the order with her/his preference.
Our future work will study the ‘target’ poisoning attack
on pairwise ranking. Moreover, the ‘Dynamic’ method does
not completely destroy the election result. It indicates that
the inaccurate supervision would mislead the adversary and
the corresponding Nash equilibrium could show partiality
for the ranking aggregation algorithm.

4.4 Sushi Preference

Description. This dataset contains the results of a series
of surveys which involves 5000 individuals for their pref-
erences about various kinds of sushi. The original survey
provides 10 complete strict rank orders of 10 different kinds
of sushi as 1) ebi (shrimp), 2) anago (sea eel), 3) maguro
(tuna), 4) ika (squid), 5) uni (sea urchin), 6) sake (salmon
roe), 7) tamago (egg), 8) toro (fatty tuna), 9) tekka-maki (tuna
roll), and 10) kappa-maki (cucumber roll). The complete

Fig. 4: The ranking generated from the original data (Orig-
inal), random perturbation data (Random), poisoned data
(Static and Dynamic) on Human Age dataset. When the
Kendall-τ is smaller than 0 (α ≥ 10−4), we observe that the
aggregated results would put the younger people at the top
of the lists. Moreover, the same phenomenons in the simu-
lation are still observed. The training data with more than
50% outliers could generate an arbitrarily ordered list. If it
happens, the Kendall-τ could not monotonically decrease
when we increase the uncertainty budget continuously for
the static attack strategies.

4.3 Dublin Election

Description. The Dublin election data set1 contains a com-
plete record of votes for elections held in county Meath,
Dublin, Ireland on 2002. This set contains 64, 081 votes over
14 candidates. These votes could be a complete or partial
list over the candidate set. The ground-truth ranking of
14 candidates are based on their obtained ﬁrst preference
votes2. The ﬁve candidates who receive the most ﬁrst pref-
erence votes will be the winner of the election. We are
interested in the top-5 performance of the pairwise rank
aggregation method. Then these votes are converted into the
pairwise comparisons. The total number of the comparisons
is 652, 817.

Comparative Results. In this experiment, we evaluate the
ability of poisoning attack in election. The election result
is not obtained by pairwise ranking aggregation. However,
the ordered list aggregated from induced comparisons still

1. http://www.preﬂib.org/data/election/irish/
2. https://electionsireland.org/result.cfm?election=2002&cons=

178&sort=ﬁrst

514640393636464051363936TrueRankingOriginalRandom405146393636Static1e-6Static1e-5Static1e-4Static1e-3Static1e-2Static1e-1Static1Dynamic1e-6Dynamic1e-2Dynamic1e-1Dynamic140465136393639514036463615181018177710517112752151011301026252230201917210185181120274640513639365140363639465751101115TABLE 5: Computational complexity (ms) comparisons on
the synthetic dataset. The results are the mean of 100 trials
with different pairwise comparisons.

TABLE 6: Computational complexity (ms) comparisons on
the real-world datasets. The results are the mean of 100 trials
with different initialization.

13

Method

Static

Dynamic

Budget
1e−6
1e−5
1e−4
1e−3
1e−2
1e−1
1
1e−6
1e−5
1e−4
1e−3
1e−2
1e−1
1

10
0.0736
0.0727
0.0692
0.0715
0.0712
0.0662
0.0680
0.0279
0.0238
0.0258
0.0351
0.0243
0.0261
0.0252

No. of Candidates

20
0.2123
0.2274
0.1976
0.2133
0.2124
0.2026
0.2410
0.0764
0.0726
0.0796
0.0758
0.0749
0.0792
0.0730

50
9.7374
9.6190
9.6027
9.5939
9.3595
9.7653
9.9514
2.7743
2.7711
2.7001
2.7028
2.7095
2.7665
2.7860

100
198.7755
200.4348
200.7480
197.5005
196.2806
197.9314
197.4316
55.9370
54.5632
55.5834
57.0046
56.0811
55.8359
55.9948

Method

Static

Dynamic

Budget
1e−6
1e−5
1e−4
1e−3
1e−2
1e−1
1
1e−6
1e−5
1e−4
1e−3
1e−2
1e−1
1

Age
1.2012
1.1174
1.6814
1.3130
1.1457
0.9435
1.0184
0.2664
0.2424
0.3147
0.2779
0.2461
0.2235
0.2382

Dataset
Dublin
0.1018
0.0798
0.0862
0.1256
0.0809
0.0779
0.0811
0.0356
0.0244
0.0277
0.0369
0.0253
0.0247
0.0245

Sushi
0.0548
0.0645
0.0483
0.0455
0.0535
0.0473
0.0403
0.0205
0.0240
0.0190
0.0180
0.0207
0.0182
0.0154

5 CONCLUSION
We initiate the ﬁrst study of data poisoning attacks in
the context of pairwise ranking. We formulate the attack
problem as a robust game between two players, the ranker
and the adversary. The attacker’s strategies are modeled as
the distributionally robust optimization problems and some
theoretical results are established, including the existence of
distributionally robust Nash equilibrium and the general-
ization bounds. Our empirical studies show that our attack
strategies signiﬁcantly break the performance of pairwise
ranking in the sense that the correlation between the true
ranking list and the aggregated result with toxic data can be
decreased dramatically.

There are many avenues for further investigation – such
as, providing the ﬁnite-sample and asymptotic results char-
acterizing the theoretical performance of the estimator with
adversarial learning, extending our attacks to more pairwise
ranking algorithms such as spectral ranking, and trying to
attack the ranking algorithms with defense paradigm. We
believe that a very interesting open question is to expand
our understanding to better understand the role and capa-
bilities of adversaries in pairwise ranking.

strict rank orders are converted into the pairwise graph
by [50]. We adopt the whole 221, 670 comparisons and the
Hodgerank [34] method to aggregate a ranking list as the
ground-truth. Then 20 percent of pairwise comparisons are
chosen to consist of the observation set. The different attack
approaches can manipulate the subset of data and induce
the pairwise ranking algorithm to generate a different order
list.

Comparative Results. This experiment is a classic setting
in recommendation and computational advertisement. With
the selected subset, the ranking aggregation method can
produce a same ranking list as adopting with the whole
preference data. The random attack would not change this
list in this experiment. In addition, the ‘Dynamic’ method
is trapped with the inaccurate supervision and only shows
a moderate destructive effect. The ‘Static’ method could
generate a promise perturbation to mislead the ranking
aggregation method as the Kendall-τ would be −1.

4.5 Computational Complexity Analysis

The computational complexity of the dynamic strategy de-
pends on the number of turns of (20). Given n candidates,
the complexity of the ranker is O(n6) for solving a least
square problem and the complexity of the adversary is
O(n2 log(n2) + log 1
(cid:15) · log(n2)) where (cid:15) is the solution accu-
racy, n2 log(n2) is for sorting and the last part corresponds
to the projection onto the (cid:96)2 ball. The computational com-
plexity of the static strategy depends on the subroutines
of Line 2 and Line 4 in Algorithm 1. We solve the sub-
routine of Line 2 by gradient descent and evaluating the
gradient needs O(n4) each time. The complexity of Line 4
is O(n3 + n2 log(n2) + n2) where n3 is for the closed form,
n2 log(n2) is for the sorting and n2 for the projection onto
the simplex. We also display the computational complexity
comparisons on the synthetic and the real-world datasets
in Table 5 and 6. The results are mean of 100 trials with
different pairwise comparisons or initialization. All compu-
R2016b, on a Laptop PC
tation is done using MATLAB
with MacOS
Core i7 CPU,
and 16GB 2133MHz DDR3 memory.

Big Sur, with 3.1GHz Intel

(cid:114)

(cid:114)

(cid:114)

REFERENCES

[1] Michele Aghassi and Dimitris Bertsimas. Robust game theory.

Mathematical Programming, 107(1):231–273, 2006.

[2] Luigi Ambrosio, Nicola Gigli, and Giuseppe Savar´e. Gradient ﬂows:
in metric spaces and in the space of probability measures. Springer, 2008.
[3] K.J. Arrow and E.S. Maskin. Social Choice and Individual Values:

Third Edition. Yale University Press, 2012.

[5]

[4] Bernd Bank, J ¨urgen Guddat, Diethard Klatte, Bernd Kummer, and
Klaus Tammer. Non-linear Parametric Optimization. Springer, 1982.
Jonathan Bard.
Some properties of the bilevel programming
problem. Journal of Optimization Theory and Applications, 68(2):371–
378, 1991.
Jonathan F Bard. Practical Bilevel Optimization: Algorithms and
Applications, volume 30. Springer, 2013.

[6]

[7] Tamer Basar and Geert J. Olsder. Dynamic Non-Cooperative Game

Theory. SIAM, 1999.

[8] G ¨uzin Bayraksan and David K. Love. Data-Driven Stochastic

Programming Using φ-Divergences, chapter 1, pages 1–19.

[9] Aharon Ben-Tal, Dick den Hertog, Anja De Waegenaere, Bertrand
Melenberg, and Gijs Rennen. Robust solutions of optimization
problems affected by uncertain probabilities. Management Science,
59(2):341–357, 2013.

[10] Battista Biggio, Blaine Nelson, and Pavel Laskov.

Poisoning
attacks against support vector machines. In International Conference
on Machine Learning, pages 1467–1474, 2012.

[11] Jose Blanchet, Yang Kang, and Karthyek Murthy. Robust wasser-
stein proﬁle inference and applications to machine learning. Jour-
nal of Applied Probability, 56(03):830–857, 2019.

[12] Jose Blanchet and Karthyek Murthy. Quantifying distributional
model risk via optimal transport. Mathematics of Operations Re-
search, 44(2):565–600, 2019.

[13] Stephen Boyd and Lieven Vandenberghe. Convex Optimization.

Cambridge University Press, 2004.

[14] Ralph Allan Bradley and Milton E Terry. Rank analysis of
incomplete block designs: I. the method of paired comparisons.
Biometrika, 39(3):324–345, 1952.

[15] Yiding Chen and Xiaojin Zhu. Optimal attack against autoregres-
sive models by manipulating the environment. In AAAI Conference
on Artiﬁcial Intelligence, pages 3545–3552, 2020.

[16] Douglas E Critchlow, Michael A Fligner, and Joseph S Verducci.
Probability models on rankings. Journal of Mathematical Psychology,
35(3):294 – 318, 1991.

[17] Herbert Aron David. The Method of Paired Comparisons, volume 12.

London, 1963.

[18] John C. Duchi and Hongseok Namkoong. Variance-based regular-
ization with convex objectives. Journal of Machine Learning Research,
20(68):1–55, 2019.

[19] John C. Duchi, Shai Shalev-Shwartz, Yoram Singer, and Tushar
Chandra. Efﬁcient projections onto the (cid:96)1-ball for learning in high
dimensions. In International Conference on Machine Learning, pages
272–279, 2008.

[20] R.M Dudley. The sizes of compact subsets of hilbert space and
Journal of Functional Analysis,

continuity of gaussian processes.
1(3):290 – 330, 1967.

[21] E. Erdo ˘gan and G. Iyengar. Ambiguous chance constrained
problems and robust optimization. Mathematical Programming,
107(1):37–61, 2006.

[22] Rui Gao, Xi Chen, and Anton J. Kleywegt. Wasserstein distribu-
tional robustness and regularization in statistical learning. CoRR,
abs/1712.06050, 2017.

[23] Rui Gao and Anton J. Kleywegt. Distributionally robust stochastic
optimization with wasserstein distance. CoRR, abs/1604.02199,
2016.

[24] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Ex-
In International

plaining and harnessing adversarial examples.
Conference on Learning Representations, 2015.

[25] Markus Grasmair, Otmar Scherzer, and Markus Haltmeier. Nec-
essary and sufﬁcient conditions for linear convergence of (cid:96)1-
regularization. Communications on Pure and Applied Mathematics,
64(2):161–182, 2011.

[26] John C. Harsanyi. Games with incomplete information played by
“bayesian” players part i. the basic model. Management Science,
14(3):159–182, 1967.

14

[28] John C. Harsanyi. Games with incomplete information played by
‘bayesian’ players, part iii. the basic probability distribution of the
game. Management Science, 14(7):486–502, 1968.

[29] Jean-Baptiste Hiriart-Urruty and Claude Lemar´echal. Convex
Analysis and Minimization Algorithms I: Fundamentals, volume 305.
Springer, 2013.

[30] Wassily Hoeffding. Probability inequalities for sums of bounded
Journal of the American Statistical Association,

random variables.
58(301):13–30, 1963.

[31] Matthew Jagielski, Alina Oprea, Battista Biggio, Chang Liu,
Cristina Nita-Rotaru, and Bo Li. Manipulating machine learning:
Poisoning attacks and countermeasures for regression learning. In
IEEE Symposium on Security and Privacy, pages 19–35, 2018.
[32] Ruiwei Jiang and Yongpei Guan. Data-driven chance constrained
stochastic program. Mathematical Programming, 158(1):291–327,
2016.

[33] Wenbo Jiang, Hongwei Li, Sen Liu, Yanzhi Ren, and Miao He.
In IEEE

A ﬂexible poisoning attack against machine learning.
International Conference on Communications, pages 1–6, 2019.
[34] Xiaoye Jiang, Lek-Heng Lim, Yuan Yao, and Yinyu Ye. Statistical
ranking and combinatorial hodge theory. Mathematical Program-
ming, 127(1):203–244, 2011.

[35] Shizuo Kakutani. A generalization of brouwer’s ﬁxed point

theorem. Duke Mathematical Journal, 8(3):457–459, 1941.

[36] Richard M. Karp. Reducibility among combinatorial problems.
In Symposium on the Complexity of Computer Computations,, pages
85–103, 1972.

[37] Raivo Kolde, Sven Laur, Priit Adler, and Jaak Vilo. Robust rank
aggregation for gene list integration and meta-analysis. Bioinfor-
matics, 28(4):573–580, 2012.

[38] V. Koltchinskii and D. Panchenko. Empirical margin distributions
and bounding the generalization error of combined classiﬁers. The
Annals of Statistics, 30(1):1–50, 02 2002.

[39] Anna Korba, St´ephan Clemencon, and Eric Sibony. A Learning
In International Conference on

Theory of Ranking Aggregation.
Artiﬁcial Intelligence and Statistics, pages 1001–1010, 2017.

[40] Jaeho Lee and Maxim Raginsky. Minimax statistical learning with
wasserstein distances. In Annual Conference on Neural Information
Processing Systems, pages 2692–2701, 2018.

[41] F. Liese and Igor Vajda. On divergences and informations in
statistics and information theory. IEEE Transactions on Information
Theory, 52(10):4394–4412, 2006.

[42] Fang Liu and Ness B. Shroff. Data poisoning attacks on stochastic
In International Conference on Machine Learning, pages

bandits.
4042–4050, 2019.

[43] Xuanqing Liu, Si Si, Jerry Zhu, Yang Li, and Cho-Jui Hsieh. A
uniﬁed framework for data poisoning attack to graph-based semi-
supervised learning. In Advances in Neural Information Processing
Systems, pages 9777–9787, 2019.

[44] Yongchao Liu, Huifu Xu, Shu-Jung Sunny Yang, and Jin Zhang.
Distributionally robust equilibrium for continuous games: Nash
and stackelberg models. European Journal of Operational Research,
265(2):631–643, 2018.

[45] Nicolas Loizou. Distributionally robust games with risk-averse
In International Conference on Operations Research and

players.
Enterprise Systems, pages 186–196, 2016.

[46] R Duncan Luce. Individual Choice Behavior. John Wiley, 1959.
[47] Yuzhe Ma, Xuezhou Zhang, Wen Sun, and Jerry Zhu. Policy
poisoning in batch reinforcement learning and control. In Advances
in Neural Information Processing Systems, pages 14543–14553, 2019.
[48] Yuzhe Ma, Xiaojin Zhu, and Justin Hsu. Data poisoning against
In Interna-
differentially-private learners: Attacks and defenses.
tional Joint Conference on Artiﬁcial Intelligence, pages 4732–4738,
2019.

[49] Saeed Mahloujifar, Mohammad Mahmoody, and Ameer Mo-
hammed. Data poisoning attacks in multi-party learning. In Inter-
national Conference on Machine Learning, pages 4274–4283, 2019.
[50] Nicholas Mattei and Toby Walsh. Preﬂib: A library of preference
In International Conference on Algorithmic Decision Theory,

data.
pages 7–26, 2013.

[51] Peyman Mohajerin Esfahani and Daniel Kuhn. Data-driven distri-
butionally robust optimization using the wasserstein metric: per-
formance guarantees and tractable reformulations. Mathematical
Programming, 171(1):115–166, 2018.

[27] John C. Harsanyi. Games with incomplete information played by
“bayesian” players part ii. bayesian equilibrium points. Manage-
ment Science, 14(5):320–334, 1968.

[52] Gaspard Monge. M´emoire sur la th´eorie des d´eblais et des
remblais. Histoire de l’Acad´emie Royale des Sciences de Paris, pages
666–704, 1781.

15

IEEE Transactions on Pattern Analysis and Machine Intelligence,
41(4):844–856, 2019.

[79] Xuezhou Zhang, Yuzhe Ma, Adish Singla, and Xiaojin Zhu. Adap-
tive reward-poisoning attacks against reinforcement learning. In
International Conference on Machine Learning, pages 11225–11234,
2020.

[53] Hongseok Namkoong and John C. Duchi.

Stochastic gradi-
ent methods for distributionally robust optimization with f -
divergences. In Annual Conference on Neural Information Processing
Systems, pages 2208–2216, 2016.

[54] Hongseok Namkoong and John C. Duchi. Variance-based regu-
larization with convex objectives. In Annual Conference on Neural
Information Processing Systems, pages 2975–2984, 2017.

[55] John Nash. Non-cooperative games. Annals of Mathematics,

54(2):286–295, 1951.

[56] John F. Nash. Equilibrium points in n-person games. Proceedings

of the National Academy of Sciences, 36(1):48–49, 1950.

[57] Sahand Negahban, Sewoong Oh, and Devavrat Shah. Rank cen-
trality: Ranking from pairwise comparisons. Operation Research,
65(1):266–287, 2017.

[58] Sahand Negahban, Sewoong Oh, Kiran Koshy Thekumparampil,
and Jiaming Xu. Learning from comparisons and choices. Journal
of Machine Learning Research, 19(40):1–95, 2018.

[59] Ashwin Pananjady, Cheng Mao, Vidya Muthukumar, Martin J.
Wainwright, and Thomas A. Courtade. Worst-case vs average-case
design for estimation from ﬁxed pairwise comparisons. Annals of
Statistics, 48(2):1072–1097, 2020.

[60] Gabriel Peyr´e, Marco Cuturi, et al. Computational optimal trans-
port. Foundations and Trends® in Machine Learning, 11(5-6):355–607,
2019.

[61] Arun Rajkumar, Suprovat Ghoshal, Lek-Heng Lim, and Shivani
Agarwal. Ranking from stochastic pairwise preferences: Recover-
ing condorcet winners and tournament solution sets at the top. In
International Conference on Machine Learning, pages 665–673, 2015.
[62] J. B. Rosen. Existence and uniqueness of equilibrium points for
concave n-person games. Econometrica, 33(3):520–534, 1965.
[63] Nihar B. Shah, Sivaraman Balakrishnan, Joseph K. Bradley, Ab-
hay Parekh, Kannan Ramchandran, and Martin J. Wainwright.
Estimation from pairwise comparisons: Sharp minimax bounds
with topology dependence. Journal of Machine Learning Research,
17(58):1–47, 2016.

[64] Nihar B. Shah, Sivaraman Balakrishnan, Aditya Guntuboyina, and
Martin J. Wainwright. Stochastically transitive models for pairwise
comparisons: Statistical and computational issues. In International
Conference on Machine Learning, pages 11–20, 2016.

[65] Nihar B. Shah and Martin J. Wainwright. Simple, robust and
Journal of Machine

optimal ranking from pairwise comparisons.
Learning Research, 18(199):1–38, 2017.

[66] Matthew Staib and Stefanie Jegelka. Distributionally robust
In Annual
optimization and generalization in kernel methods.
Conference on Neural Information Processing Systems, pages 2438–
2446, 2019.

[67] Louis L Thurstone. A law of comparative judgment. Psychological

Review, 34(4):273–286, 1927.

[68] Alexandre B. Tsybakov.

Introduction to Nonparametric Estimation.

Springer, 2008.

[69] Rohit Vaish, Neeldhara Misra, Shivani Agarwal, and Avrim Blum.
On the computational hardness of manipulating pairwise voting
rules. In International Conference on Autonomous Agents & Multia-
gent Systems, pages 358–367, 2016.

[70] Aad W. van der Vaart and Jon A. Wellner. Weak Convergence and
Empirical Processes: With Applications to Statistics. Springer New
York, 1996.

[71] Vladimir N. Vapnik. The Nature of Statistical Learning Theory.

Springer, 1995.

[72] C´edric Villani. Optimal Transport: Old and New. Springer, 2008.
[73] John von Neumann and Oskar Morgenstern. Theory of Games and

Economic Behavior. Princeton University Press, 1947.

[74] Toby Walsh. Is computational complexity a barrier to manipula-
tion? Annals of Mathematics and Artiﬁcial Intelligence, 62(1-2):7–26,
2011.

[75] Zizhuo Wang, Peter W Glynn, and Yinyu Ye. Likelihood robust
optimization for data-driven problems. Computational Management
Science, 13(2):241–261, 2016.

[76] Fabian L. Wauthier, Michael I. Jordan, and Nebojsa Jojic. Efﬁcient
ranking from pairwise comparisons. In International Conference on
Machine Learning, pages 109–117, 2013.

[77] David Wozabal. Robustifying convex risk measures for linear port-
folios: A nonparametric approach. Operations Research, 62(6):1302–
1315, 2014.

[78] Qianqian Xu, Jiechao Xiong, Xiaochun Cao, Qingming Huang,
and Yuan Yao. From social to individuals: A parsimonious path
of multi-level models for crowdsourced preference aggregation.

APPENDIX A
PROOF OF THEOREM 1.
Property 1. Let the pay-off function fr, r = 1, 2 be the weighted sum-of-squared loss (cid:96) (9) in (25). If the uncertainty set is Xα(PN )
or Wα

p (PN ), we have

16

1) fr is a continuous function, and for any ﬁxed {x−r, ξ}, fr(xr, x−r, ξ) is convex over Xr.
2) X = X1 × X2 is a compact set.
3) Eξ∼Q[fr(xr, x−r, ξ)] is ﬁnite-valued, ∀ x ∈ X , Q ∈ U.
4) U is a weakly compact set.

Proposition 1. Let x = {x1, x2}, v = {v1, v2}, we deﬁne φ : X × X → R+ as

φ(v, x) = sup
Q ∈ U

(cid:104)

Eξ∼Q

f1(v1, x2, ξ)

(cid:105)

+ sup
Q ∈ U

(cid:104)

Eξ∼Q

f2(x1, v2, ξ)

(cid:105)

With Property 1, x∗ = {x∗

1, x∗

2} is a distributional robust Nash equilibrium of (26) if and only if

{x∗

1, x∗

2} ∈ arg min

v ∈ X

φ(v, x∗).

(59)

(60)

Proof. The reformulation φ is well known for deterministic Nash equilibrium, see for example [62]. The “if” part follows
from the fact that if {x∗

2} is not an equilibrium of (25), there exists some ¯xr, r = 1, 2, such that

1, x∗

sup
Q ∈ U

(cid:104)

Eξ∼Q

fr(¯xr, x∗

−r, ξ)

(cid:105)

< sup
Q ∈ U

(cid:104)

Eξ∼Q

fr(x∗

r, x∗

−r, ξ)

Let ¯x = {¯xr, x∗

−r}, we have φ(¯x, x∗) < φ(x∗, x∗). This is a contradiction.

The “only if” part is obvious as

sup
Q ∈ U
Summing up each r on both sides, the inequality shows that {x∗

> sup
Q ∈ U
1, x∗

−r, ξ)

fr(xr, x∗

Eξ∼Q

(cid:104)

(cid:105)

Eξ∼Q

(cid:104)

fr(x∗

r, x∗

−r, ξ)

2} is a global minimizer.

(cid:105)

(cid:105)

p (PN ), the general robust game (25) has a DRNE.

Based on the Proposition 1, we have the following existence result for distributional robust Nash equilibrium of 25.
Theorem 1. Let the pay-off function fr, r = 1, 2 be the weighted sum-of-squared loss (cid:96) (9) in (25). If the uncertainty set is Xα(PN )
or Wα
Proof. Based on the Proposition 1, each Eξ∼Q[fr(xr, x−r, ξ)] is continuous and convex for any Q ∈ U. The supremum
preserves the convexity of fr and, under weakly compactness of U, the continuity of fr will hold. Therefore φ(v, x) is
continuous and convex w.r.t. v on X for any ﬁxed x ∈ X .

The existence of an optimal solution to

min
v ∈ X

φ(v, x)

(61)

follows from compactness of X under the third condition in Assumption 1. To complete the proof, we are left to show the
existence of x∗ ∈ X such that

x∗ ∈ arg min

φ(v, x∗).

(62)

Let Φ(x) be the set of optimal solutions to min φ(v, x) for each ﬁxed x ∈ X . Then Φ(x) ⊂ X holds. By the convexity of φ,
Φ(x) is a convex set. Obviously, Φ(x) is closed, namely, there exists a sequence {xk} with limk→∞xk = ¯x and vk ∈ Φ(xk),
if limk→∞vk = ¯v, we have ¯v ∈ Φ(¯x). Further, following by Theorem 4.2.1 in [4], Φ is upper semi-continuous on X . By
Kakutani’s ﬁxed point theorem [35], , there exists x∗ ∈ X such that x∗ ∈ Φ(x∗).

v ∈ X

APPENDIX B
PROOF OF THEOREM 2.

The following proposition shows the strong duality result for Wasserstein DRO [12], which ensures that the inner
supremum in (31) admits a reformulation which is a simple, univariate optimization problem. Note that there exists
the other strong duality result of Wasserstein DRO [23].
Proposition 2. Let d : Rn+2 × Rn+2 → [0, ∞] be a lower semi-continuous cost function satisfying d(z, z(cid:48)) = 0 whenever
z = z(cid:48), z = (p, b, y), z(cid:48) = (p(cid:48), b(cid:48), y(cid:48)). For λ ≥ 0 and loss function (cid:96) (29) that is upper semi-continuous in (p, b, y) for each θ,
deﬁne

ψλ,(cid:96)(z; θ) := sup

z(cid:48)∈Rn+2

(cid:88)

(i,j)

(cid:40)

(cid:96)(θ; z(cid:48)) − λd(z, z(cid:48))

(cid:41)
.

(63)

Then

sup
Q ∈ Wα

p (PN )

Ez(cid:48)∼Q

(cid:104)

(cid:96)(cid:0)θ, z(cid:48)(cid:1) (cid:105)

(cid:40)

= min
λ≥0

λα +

1
N

(cid:88)

z

(cid:41)

ψλ,(cid:96)(z; θ)

17

(64)

Theorem 2. Let Z = (cid:8)p, B, y(cid:48)(cid:9) be the observed data set, where B and y(cid:48) are deﬁned as (11), p is the frequency of each type of
pairwise comparison as (27). Consider the loss function of z, and the distance function between zc, z(cid:48)
c are based on the (cid:96)2-norm. In
other words, we take (cid:96)(θ, z) as (29) and

d(zc, z(cid:48)

c) = (cid:13)
(cid:0)pij, bi,j, y(cid:48)
(cid:13)
= (cid:12)
(cid:12)
(cid:12) pij − qij
(cid:12).

ij

(cid:1) − (cid:0)qij, bi,j, y(cid:48)

ij

(cid:1)(cid:13)
(cid:13)2

Then, the DRO problem (31) has an equivalent form:

where

and

min
θ ∈ Θ
= min
θ ∈ Θ

Eq∼Q

sup
2 (PN )
Q ∈ Wα
L(θ) + R(θ),

(cid:104)

(cid:96)(cid:0)θ; q(cid:1) (cid:105)

L(θ) =

1
2N

(cid:88)

(i, j)

pij(y(cid:48)

ij − θ(cid:62)bi,j)2,

R(θ) =

(cid:115) α
4N

(cid:88)

(y(cid:48)

ij − θ(cid:62)bi,j)2.

(i, j)

Proof. Let ∆ij = qij − pij. The ψλ,(cid:96) function (36) has a new formulation as

ψλ,(cid:96)(θ, p)

= sup
q ∈ RN
+

= sup
q ∈ RN
+

1
N

1
N

(cid:88)

(cid:110)
(cid:96)(θ, qij) − λ(cid:2)d(pij, qij)(cid:3)2(cid:111)

c ∈ C

(cid:88)

(cid:40)

c ∈ C

qij
2

(cid:20)
(−θ(cid:62), 1)

·

(cid:19)(cid:21)2

(cid:18)ac
yij

(cid:41)

− λ(cid:12)

(cid:12)pij − qij

2

(cid:12)
(cid:12)

=

1
N

(cid:88)

c ∈ C

(cid:16)

sup
∆ij ∈ R

∆ijbij − λ∆2

ij + pijbij

(cid:17)

,

(32)

(33)

(34)

(35)

(65)

where bij = (yij − θ(cid:62)ac)2/2, and the third equality holds due to ψλ,(cid:96) is a decomposable function. Expanding (65), we can
simplify ψλ,(cid:96) as below:

ψλ,(cid:96)(θ, p)

(cid:88)

1
N

(cid:104)p, b(cid:105) +

1
N
c ∈ C
(cid:40) (cid:104)p, b(cid:105)/N + (cid:107)b(cid:107)2

=

=

2/(4λN ),

if λ > 0,

if λ = 0.

∞,

(∆ijbij − λ∆2

ij)

sup
∆ij ∈ R

(66)

Next, we investigate the duality of (31) with Proposition 2. As ψλ,(cid:96)(θ, z) = ∞ when λ = 0, the dual formulation of the
supremum in (38) would be

Ez(cid:48)∼Q

sup
Q ∈ Wα

p (PN )
(cid:40)

(cid:104)

(cid:96)(cid:0)θ, z(cid:48)(cid:1) (cid:105)

(cid:41)

By the deﬁnition of b, we know that

= min
λ≥0

= min
λ>0

λα + ψλ,(cid:96)(θ, p)

(cid:26)

λα +

1
N

(cid:104)p, b(cid:105) +

(cid:27)

.

(cid:107)b(cid:107)2
2

1
4λN

(cid:96)(θ, p) =

1
N

(cid:10)p, b(cid:11)

(67)

(68)

Moreover, notice that the right hand side of (67) is a convex function which approaches inﬁnity when λ → ∞, the global
optimal of it can be obtained uniquely via the ﬁrst order optimality condition as

(cid:26)

∂
∂λ

λα +

1
N

(cid:104)p, b(cid:105) +

1
4λN

(cid:107)b(cid:107)2
2

(cid:27)

= 0,

(69)

and the optimal dual variable is

Substituting λ∗

α and b into (67), we have

λ∗
α =

(cid:107)b(cid:107)2
√
αN
2

.

Ez(cid:48)∼Q

(cid:104)

(cid:96)(cid:0)θ, z(cid:48)(cid:1) (cid:105)

p (PN )

sup
Q ∈ Wα
(cid:114) α
N
(cid:115) α
4N

=

=

· (cid:107)b(cid:107)2 +

1
N

· (cid:104)p, b(cid:105)

(cid:88)

c ∈ C

(yij − θ(cid:62)ac)2 +

1
2N

(cid:88)

c ∈ C

pij(yij − θ(cid:62)ac)2.

18

(70)

(71)

APPENDIX C
SOME PROPOSITIONS FOR GENERALIZATION ANALYSIS.
Proposition 3. Suppose that (cid:96) is L-Lipschitz function, i.e., |(cid:96)(z) − (cid:96)(z(cid:48))| ≤ L · dZ (z, z(cid:48)) for all z, z(cid:48) ∈ Z. Then, for any
Q ∈ Wα

p (PN ),

RQ((cid:96)) ≤ RP,α,p((cid:96)) ≤ RQ((cid:96)) + 2Lα.

Proof. For p = 1, the result follows immediately from the Kantorovich dual representation of W1(·, ·) [72]:

W1(P, Q) = sup

(cid:40) (cid:12)
(cid:12)
(cid:12)
(cid:12)

Ez∼P

(cid:2)h(z)(cid:3) − Ez∼Q

(cid:2)h(z)(cid:3)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

sup
z,z(cid:48)∈Z,z(cid:54)=z(cid:48)

(cid:12)
(cid:12) h(z) − h(z(cid:48)) (cid:12)
(cid:12)
dZ (z, z(cid:48))

(cid:41)

≤ 1

with the triangle inequality:

W1(P, Q) ≤ 2α,

∀ P, Q ∈ Wα

1 (PN ).

For p > 1, the result follows from the fact that

W1(P, Q) ≤ Wp(P, Q),

∀ P, Q ∈ Pp(Z).

(72)

(73)

(74)

(75)

Next we consider the case when the function (cid:96) is smooth but not Lipschitz-continuous. Since we are working with
general metric spaces that may lack an obvious differentiable structure, we need to ﬁrst introduce some concepts from
metric geometry [2].
Deﬁnition 4 (Geodesic Space). A metric space (Z, dZ ) is a geodesic space if for every pair of points z, z(cid:48) ∈ Z there exists a
constant-speed geodesic path (cid:37) : (cid:2)0, 1(cid:3) → Z, such that (cid:37)(0) = z, (cid:37)(1) = z(cid:48), and for all 0 ≤ s ≤ t ≤ 1

(cid:104)

(cid:105)
(cid:37)(s), (cid:37)(t)

dZ

= (t − s) · dZ

(cid:104)

(cid:105)
(cid:37)(0), (cid:37)(1)

.

(76)

Deﬁnition 5 (Geodesic convexity). A functional (cid:96) : Z → R is geodesically convex if for any pair of points z, z(cid:48) ∈ Z there is a
constant-speed geodesic (cid:37), so that

(cid:16)
(cid:96)

(cid:37)(t)

(cid:17)

(cid:16)

(cid:17)

≤ (1 − t) · (cid:96)
+ t · (cid:96)
= (1 − t) · (cid:96)(z) + t · (cid:96)(z(cid:48)).

(cid:37)(0)

(cid:16)

(cid:17)

(cid:37)(1)

(77)

Deﬁnition 6 (Upper Gradient). Suppose that (cid:96) : Z → R is a Borel function. The upper gradient of (cid:96) is a functional G(cid:96) : Z → R+
satisﬁes that: for any pair of points z, z(cid:48) ∈ Z, there exist a constant-speed geodesic path (cid:37):

|(cid:96)(z(cid:48)) − (cid:96)(z)| ≤

(cid:90) 1

0

G(cid:96)((cid:37)(t))dt · dZ (z, z(cid:48)).

Proposition 4. Suppose that (cid:96) has a geodesically convex upper gradient G(cid:96), we have

where

and 1/p + 1/q = 1.

RQ((cid:96)) ≤ RP,α,p((cid:96)) ≤ RQ((cid:96)) + 2αµ,

(cid:32)

µ = sup
Q ∈ Wα

p (P)

Ez∼Q

(cid:33) 1

q

(cid:104)(cid:12)
(cid:12)G(cid:96)(z)(cid:12)
(cid:12)

q(cid:105)

(78)

(79)

(80)

19

Proof. With ﬁxed Q, Q(cid:48) ∈ Wα
(z, z(cid:48)) ∼ γ, we have

p (P) and let γ ∈ Γ(Z × Z) achieve the inﬁmum in (21) and (22) for Wp(Q, Q(cid:48)). Then for any

(cid:96)(z(cid:48)) − (cid:96)(z) ≤

(cid:90) 1

G(cid:96)((cid:37)(t))dt · dZ (z, z(cid:48))

0
(cid:16)

1
2

≤

G(cid:96)(z) + G(cid:96)(z(cid:48))

(cid:17)

· dZ (z, z(cid:48)),

(81)

where the ﬁrst inequality is from the deﬁnition of the upper gradient (78) and the second one is by the assumed geodesic
convexity of G(cid:96). Taking expectations of both sides with respect to γ and using H ¨older inequality, we obtain

RQ((cid:96)) − RQ(cid:48)((cid:96)) ≤

=

1
2

1
2

(cid:32)

E(z,z(cid:48))∼γ

(cid:104)(cid:12)
(cid:12)G(cid:96)(z) + G(cid:96)(z(cid:48))(cid:12)
(cid:12)

q(cid:105)

(cid:33) 1

q (cid:32)

E(z,z(cid:48))∼γ

(cid:33) 1

p

(cid:2)dZ (z, z(cid:48))(cid:3)p

(cid:32)

E(z,z(cid:48))∼γ

(cid:104)(cid:12)
(cid:12)G(cid:96)(z) + G(cid:96)(z(cid:48))(cid:12)
(cid:12)

q(cid:105)

(cid:33) 1

q

· Wp(Q, Q(cid:48)),

where we adopt the p-Wasserstein optimality of γ for Q and Q(cid:48). By the triangle inequality, and since z ∼ Q and z(cid:48) ∼ Q,

(cid:32)

E(z,z(cid:48))∼γ

(cid:104)(cid:12)
q(cid:105)
(cid:12)G(cid:96)(z) + G(cid:96)(z(cid:48))(cid:12)
(cid:12)

(cid:33) 1

q

(cid:32)

≤

Ez∼Q

(cid:104)(cid:12)
(cid:12)G(cid:96)(z)(cid:12)
(cid:12)

q(cid:105)

(cid:33) 1

q

(cid:32)

+

Ez(cid:48)∼Q(cid:48)

(cid:33) 1

q

(cid:104)(cid:12)
q(cid:105)
(cid:12)G(cid:96)(z(cid:48))(cid:12)
(cid:12)

(cid:32)

Ez∼Q

q(cid:105)
(cid:104)(cid:12)
(cid:12)G(cid:96)(z)(cid:12)
(cid:12)

(cid:33) 1

q

.

≤ 2

sup
Q ∈ Wα

p (P)

Interchanging the roles of Q and Q(cid:48) and proceeding with the same argument, we obtain the following estimation

sup

Q, Q(cid:48) ∈ Wα

p (P)

(cid:12)
(cid:12)
(cid:12) RQ((cid:96)) − RQ(cid:48)((cid:96))

(cid:12)
(cid:12)
(cid:12) ≤ 2α sup
Q ∈ Wα

p (P)

(cid:32)

Ez∼Q

(cid:104)(cid:12)
(cid:12)G(cid:96)(z)(cid:12)
(cid:12)

q(cid:105)

(cid:33) 1

q

.

Then

RQ((cid:96))
≤ RP,α,p((cid:96))

= 2α

sup
Q(cid:48) ∈ Wα

p (P)

(cid:104)

(cid:105)
RQ(cid:48),α,p((cid:96)) − RQ((cid:96)) + RQ((cid:96))

≤ RQ((cid:96)) + 2α sup
Q ∈ Wα

p (P)

(cid:32)

Ez∼Q

(cid:104)(cid:12)
(cid:12)G(cid:96)(z)(cid:12)
(cid:12)

q(cid:105)

(cid:33) 1

q

(82)

(83)

(84)

Proposition 5. Consider the setting of pairwise ranking problem with the sum-of-squared loss: let A be a convex subset of Rn,
Y = [−1, 1], and equip Z = A × Y with the Euclidean metric

dZ (z, z(cid:48)) =

(cid:113)

(cid:107)a − a(cid:48)(cid:107)2

2 + |y − y(cid:48)|2, z = (a, y).

It means that we do not aggregate the pairwise comparisons into the same type and the weight. Then, it holds that

RQ((cid:96)) ≤ RP,α,2((cid:96)) ≤ RQ((cid:96)) + 4α(1 + C)τ,

where

(cid:32)

τ =

1 + L

sup
Q ∈ Wα

2 (PN )

EQ(cid:107)A(cid:107)2

(cid:33)

, z = (a, y) ∼ Q,

and A = [a(cid:62)

1 , . . . , a(cid:62)
N ].

Proof. As Z ⊆ Rn+1, Z is a geodesic space as

γ(t) = (1 − t) · z + t · z(cid:48), ∀ z, z(cid:48) ∈ Z

is the unique constant-speed geodesic path.

Moreover, the geodesically convex upper gradient of (cid:96) is

G(cid:96)(z) = G(cid:96)(a, y) = 2(B + C)(1 + L(cid:107)∇h(a)(cid:107)2), ∀ z ∈ Z.

(85)

(86)

(87)

(88)

(89)

where (cid:96)(z) = (cid:96)(a, y) = (y − h(a))2. In such a ﬂat Euclidean setting, geodesic convexity coincides with the usual deﬁnition
of convexity, and the map z → G(cid:96)(z) is convex evidently: for all pair z, z(cid:48) ∈ Z

20

With the mean-value theorem

and a simple calculation

G(cid:96)((1 − t) · z + t · z(cid:48)) ≤ (1 − t) · G(cid:96)(z) + t · G(cid:96)(z(cid:48)).

(cid:96)(z) − (cid:96)(z(cid:48))
(cid:90) 1

(cid:10)z − z(cid:48), ∇(cid:96)(cid:0)(1 − t) · z + t · z(cid:48)(cid:1)(cid:11)dt

0
(cid:90) 1

0
(cid:90) 1

0

(cid:13)∇(cid:96)(cid:0)(1 − t) · z + t · z(cid:48)(cid:1)(cid:13)
(cid:13)

(cid:13)2dt · (cid:107)z − z(cid:48)(cid:107)2

(cid:13)∇(cid:96)(cid:0)(1 − t) · z + t · z(cid:48)(cid:1)(cid:13)
(cid:13)

(cid:13)2dt · dZ (z, z(cid:48))

≤

≤

=

(cid:107)∇(cid:96)(z)(cid:107)2

2 = 4(cid:96)(z)(1 + (cid:107)∇h(a)(cid:107)2

2) ≤ 4(B + C)2(1 + L2(cid:107)a(cid:107)2

2),

we have (cid:107)∇(cid:96)(z)(cid:107)2 ≤ G(cid:96)(z) for any z ∈ Z. Thus, by Proposition 3, we have

RQ((cid:96)) ≤ RP,α,2((cid:96))

≤ RQ((cid:96)) + 2α

sup
Q ∈ Wα

2 (PN )
(cid:32)

(cid:32)

Ez∼Q

(cid:104)(cid:12)
(cid:12)G(cid:96)(z)(cid:12)
(cid:12)

2(cid:105)

(cid:33) 1

2

= RQ((cid:96)) + 4α(B + C)

1 + L

sup
Q ∈ Wα

2 (PN )

Ez∼Q(cid:107)A(cid:107)2

(cid:33)
.

(90)

(91)

(92)

(93)

APPENDIX D
PROOF OF THEOREM 3.
Assumption 1. d : Z × Z → R+ in (21) and (22) is a nonnegative lower semi-continuous function satisfying d(w, w(cid:48)) = 0 if and
only if w = w(cid:48).
Assumption 2. The loss function (cid:96) ∈ F ⊆ L1(dQ) are upper semi-continuous, where L1(dQ) denote the collection of Borel
measurable functions (cid:96) : Z → R such that

(cid:90)

|(cid:96)| dQ < ∞, ∀ Q ∈ P(Z).

Assumption 3. The instance space Z is bounded, namely,

diam(Z) = sup
z,z(cid:48)∈Z

dZ (z, z(cid:48)) < ∞.

Assumption 4. (cid:96) ∈ F is uniformly bounded as

0 ≤ (cid:96)(z) ≤ B < ∞, ∀ (cid:96) ∈ F, and z ∈ Z.

Deﬁnition 7. Let (Z, dZ ) be a metric space. For a function (cid:96) : Z → R and a point s ∈ R, the upper contour set deﬁned by s is

and the corresponding lower contour set is

(cid:96)−1(cid:0)[s, ∞)(cid:1) = (cid:8)z ∈ Z : (cid:96)(z) ≥ s(cid:9),

(cid:96)−1(cid:0)(∞, s](cid:1) = (cid:8)z ∈ Z : (cid:96)(z) ≤ s(cid:9).

We call a function (cid:96) : Z → R is upper semi-continuous if and only if for any s ∈ R, (cid:96)−1(cid:0)(∞, s](cid:1) is an open set.
We adopt the Dudley’s entropy integral [20] as the complexity measure of the hypothesis class F ,
(cid:90) ∞

(cid:113)

J (F) =

log N(F, (cid:107) · (cid:107)∞, υ) dυ,

(94)

(95)

(96)

(97)

(98)

0

where N(F, (cid:107) · (cid:107)∞, υ) is υ-covering number of F with respect to the uniform metric (cid:107) · (cid:107)∞, deﬁned as the size of the
smallest υ-cover of F

N(F, (cid:107) · (cid:107)∞, υ)

(cid:40)

= min
m∈N

∃ {(cid:96)1, . . . , (cid:96)m} ⊆ F ⊆

(cid:41)

B(cid:107)·(cid:107)∞
υ

((cid:96)k)

m
(cid:91)

k=1

(99)

and (cid:83)m

k=1 B(cid:107)·(cid:107)∞

υ

(·) is a υ-cover of F with respect to (cid:107) · (cid:107)∞

(cid:107) (cid:96) − (cid:96)(cid:48) (cid:107)∞ = sup
z ∈ Z

| (cid:96)(z) − (cid:96)(cid:48)(z) |.

Theorem 3. Consider the setting of pairwise ranking problem with the sum-of-squared loss, for any t > 0, it holds

and

where

and

(cid:16)

Pr

∃ (cid:96) ∈ F : RP,α,2((cid:96)) > ς1

(cid:17)

≤ e−2t2

(cid:16)
∃ (cid:96) ∈ F : RPN ,α,2((cid:96)) > ς2

(cid:17)

Pr

≤ 2e−2t2

(cid:40)

ς1 = min
λ≥0

λα2 + Ez∼Q

(cid:41)

(cid:2) ψλ,(cid:96) (z) (cid:3)

+

24J (F) + t
N

√

.

ς2 = min
λ≥0
(cid:40)

min
λ≥0

(cid:40)

(λ + 1)α2 + Ez∼Q

(cid:2) ψλ,(cid:96) (z) (cid:3)

(cid:112)

log(λ + 1)
N

√

(cid:41)

+

24J (F) + t
N

√

,

+

21

(100)

(49)

(50)

(51)

(52)

where J (F) is the Dudley’s entropy integral [20], which is served as the complexity measure of the hypothesis class F .

Proof. This proof is a specialization of data-dependent generalization bounds for margin cost function class [38]. From the
deﬁnition of the local minimax risk (47) and its duality form,

where

RP,α,p((cid:96)) = min
λ>0

≤ min
λ>0

(cid:110)

(cid:110)

λαp + Ez∼P

λαp + Ez∼P

(cid:2)ψλ,(cid:96)(z)(cid:3) (cid:111)
(cid:2)ψλ,(cid:96)(z)(cid:3) + V λ

(cid:111)

V λ = sup
(cid:96) ∈ F

(cid:110)

Ez∼P

(cid:2)ψλ,(cid:96)(z)(cid:3) − Ez∼PN

(cid:2)ψλ,(cid:96)(z)(cid:3) (cid:111)

is a data-dependent random variable for any λ ≥ 0. As F and P satisfy the Assumption 3 and 4, we have

Furthermore, known from McDiarmid’s inequality that, for any ﬁxed λ ≥ 0

0 ≤ ψλ,(cid:96)(z) ≤ B, ∀ z ∈ Z.

Using a standard symmetrization argument, we have

(cid:16)

Pr

V λ ≥ EV λ +

√

Bt
N

(cid:17)

≤ 2e−2t2

.

EV λ ≤ 2 · E

(cid:34)

sup
(cid:96) ∈ F

1
N

N
(cid:88)

i=1

(cid:35)

(cid:15)iψλ,(cid:96)(zi)

where (cid:15)1, . . . , (cid:15)N are i.i.d. Rademacher random variables independent of z1, . . . , zN .

To bound (105), we deﬁne the F -indexed process βF = {β(cid:96)}(cid:96)∈F as

This is a zero-mean and sub-Gaussian process [70] with respect to the metric (cid:107) · (cid:107)∞ as

β(cid:96) =

1
N

N
(cid:88)

i=1

(cid:15)iψλ,(cid:96)(zi).

(101)

(102)

(103)

(104)

(105)

(106)

E

(cid:104)

exp(cid:0)t(β(cid:96) − β(cid:96)(cid:48))(cid:1)(cid:105)
(cid:34)

(cid:32)

= E

exp

√

t
N

N
(cid:88)

i=1

(cid:0)ψλ,(cid:96)(zi) − ψλ,(cid:96)(cid:48)(zi)(cid:1)

(cid:33)(cid:35)

(cid:15)i

(cid:40)

(cid:34)

(cid:32)

=

E

exp

√

t
N

(cid:15)i sup
z(cid:48)

inf
z(cid:48)(cid:48)

(cid:96)(z(cid:48)) − λ[dZ (z1, z(cid:48))]p − (cid:96)(cid:48)(z(cid:48)(cid:48)) + λ[dZ (z1, z(cid:48)(cid:48))]p(cid:111)
(cid:110)

(cid:33)(cid:35)(cid:41)N

(107)

(cid:110)

(cid:96)(z(cid:48)) − (cid:96)(cid:48)(z(cid:48))

(cid:111)(cid:19) (cid:35)(cid:41)N

(cid:40)

(cid:34)

≤

E

exp

(cid:18) t
√
N

(cid:15)i sup
z(cid:48)

≤ exp

(cid:18) t2(cid:107)(cid:96) − (cid:96)(cid:48)(cid:107)2
∞

(cid:19)

2

,

where the second equation comes from the independence of {zi}i∈[N ] and the deﬁnition of ψλ,(cid:96)(·). The last inequality
follows the Hoeffding’s lemma [30].

With the F -indexed process βF and invoking Dudley’s entropy integral (98) [20] for the right-hand side of (105), we

22

obtain

and

EV λ ≤ 2 · E

(cid:34)

sup
(cid:96) ∈ F

(cid:35)

β(cid:96)

≤

√

24
N

J (F), ∀ λ ≥ 0

(cid:16)

V λ ≥

Pr

24J (F) + Bt
N

√

(cid:17)

≤ 2e−2t2

.

In addition, the ﬁrst part of the claims holds with ant ﬁxed λ ≥ 0:

where

Pr ( ∃ (cid:96) ∈ F : RP,α,p((cid:96)) > ς1 ) ≤ e−2t2

, ∀ t > 0,

(cid:40)

ς1 = min
λ≥0

λαp + Ez∼Q

(cid:41)

(cid:2) ψλ,(cid:96) (z) (cid:3)

+

24J (F) + Bt
N

√

.

For the second part, we start with two sequences: {λk} and {tk}

λk = k, tk = t +

(cid:113)

log(k), k = 1, 2, . . .

and (49) also holds as

(cid:32)

(cid:40)

Pr

(cid:88)

k
(cid:88)

≤

≤

∃ (cid:96) ∈ F : RP,α,p((cid:96)) > min

k

e−2t2

k

e−2log(k) · e−2t2

λkαp + Ez∼Q

(cid:2) ψλk,(cid:96) (z) (cid:3)

(cid:41)

+

24J (F) + Btk
N

√

(cid:33)

Moreover,

k
≤ 2e−2t2

.

(cid:40)

(cid:40)

(cid:40)

min
k

= min

k

≤ min
λ≥0

λkαp + Ez∼Q

(cid:2) ψλk,(cid:96) (z) (cid:3)

kαp + Ez∼Q

(cid:2) ψλk,(cid:96) (z) (cid:3)

(cid:41)

+

+

(cid:41)

24J (F) + Btk
N

√

24J (F) + Bt
N

√

+

B(cid:112)
√

log(k)
N
B(cid:112)

(λ + 1)αp + Ez∼Q

(cid:41)

(cid:2) ψλ,(cid:96) (z) (cid:3)

+

24J (F) + Bt
N

√

+

log(λ + 1)
√

N

(108)

(109)

(110)

(111)

(112)

where the last inequity holds since, for any λ ≥ 0, there exists k ∈ N+ such that λ ≤ k ≤ λ + 1, and ψλ1,(cid:96) ≤ ψλ2,(cid:96) holds
whenever λ1 ≥ λ2 as (63).

Notice that

where

RPN ,α,p((cid:96)) ≤ min
λ>0

(cid:110)

λαp + Ez∼PN

(cid:2)ψλ,(cid:96)(z)(cid:3) + W λ

(cid:111)

,

W λ = sup
(cid:96)∈F

(cid:110)

Ez∼PN

(cid:2)ψλ,(cid:96)(z)(cid:3) − Ez∼P

(cid:2)ψλ,(cid:96)(z)(cid:3) (cid:111)
.

(113)

(114)

Following the similar analysis of RP,α,p((cid:96)), the second part of the claims holds

Pr ( ∃ (cid:96) ∈ F : RPN ,α,p((cid:96)) > ς2 ) ≤ 2e−2t2

, ∀ t > 0

where

(cid:40)

ς2 = min
λ≥0

(λ + 1)αp + Ez∼Q

(cid:2) ψλ,(cid:96) (z) (cid:3) +

B(cid:112)

log(λ + 1)
√

N

(cid:41)

+

24J (F) + Bt
N

√

.

APPENDIX E
PROOF OF THEOREM 4.
The common choice of the smoothness assumption is Lipschitz smoothness. Next, we explore the behavior of the dual
variable λ in (64) when the (64) archives the minimal. The following lemma enables the control of its upper bound.

Assumption 5. The functions in F are L-Lipschitz, if they satisfy

23

sup
z,z(cid:48)∈Z,z(cid:54)=z(cid:48)

(cid:96)(z(cid:48)) − (cid:96)(z)
dZ (z(cid:48), z)

≤ L, ∀ (cid:96) ∈ F.

Lemma 1. Suppose that Q ∈ Wα

p (Pn) ⊂ Pm(Z) and ˜(cid:96) is the optimal solution of local worst-case risk with distribution Q

˜λ is the inﬁmum-archiving dual variable corresponding to ˜f

˜(cid:96) ∈ arg min

RQ,α,p ((cid:96)),

(cid:96) ∈ F

Then under Assumption 3-5, ˜λ satisﬁes

˜λ ∈ min
λ≥0

(cid:26)

λαp + Ez∼Q

(cid:104)

(cid:105) (cid:27)

ψλ, ˜(cid:96)(z)

.

˜λ ≤ Lα−(p−1).

Proof. With the ﬁxed Q and the estimator ˜f , we have
(cid:34)

˜λαp ≤ ˜λαp + Ez∼Q

sup
z(cid:48)∈Z

(cid:26)

˜f (z(cid:48)) − ˜f (z) − ˜λ

(cid:104)

(cid:105)p(cid:27)(cid:35)

dZ (z, z(cid:48))

(115)

(116)

(117)

(118)

(119)

and the equality holds with z(cid:48) = z. Due to the optimality of ˜λ and the dual formulation of local worst-case risk (64), (119)
can be further bounder as

˜λαp ≤ λαp + Ez∼Q

(cid:34)

(cid:26)

˜f (z(cid:48)) − ˜f (z) − λ

(cid:104)

sup
z(cid:48)∈Z

(cid:105)p(cid:27)(cid:35)

dZ (z, z(cid:48))

≤ λαp + Ez∼Q

L · dZ (z, z(cid:48)) − λ

(cid:104)

dZ (z, z(cid:48))

(cid:105)p(cid:27)(cid:35)

(120)

(cid:34)

(cid:26)

sup
z(cid:48)∈Z
(cid:8)Lv − λvp(cid:9),

≤ λαp + sup
v≥0

where the second line comes from the Lipschitz smoothness of (cid:96) ∈ F and the third line holds by substituting v = dZ (z, z(cid:48)).
When p = 1, the result can be obtained by taking λ = L

If p > 1, we can take the v∗ =

(cid:17) 1

p−1

(cid:16) L
λp

and

˜λα ≤ Lα + sup
z(cid:48)∈Z

(cid:8)Lv − Lv(cid:9) = Lα.

which satisﬁes ﬁrst-order optimal condition for
(cid:8)Lv − λvp(cid:9)

sup
v≥0

˜λαp ≤ λαp + (p − 1)L

p
p−1 p

p
1−p λ

1
1−p .

Treating λ as a variable and minimizing the right-hand side of (123) by choosing λ = L

pαp−1 , the claim holds.

(121)

(122)

(123)

Theorem 4. Consider the setting of pairwise ranking problem with the sum-of-squared loss, the following holds with probability as
least 1 − η

RP,α,2(ˆ(cid:96)) − R∗

P,α,2(F)
48L(cid:2)diam(Z)(cid:3)2
√

α

N

(cid:115)

+ 3

log( 2
η )
2N

,

where diam(Z) is the diameter of Z)

≤

48J (F)
√
N

+

diam(Z) = sup
z,z(cid:48)∈Z
Proof. Suppose that (cid:96)∗ ∈ F can archive the local minimax risk R∗
P,α,p(F) = RP,α,p(ˆ(cid:96)) − R∗

RP,α,p(ˆ(cid:96)) − R∗

dZ (z, z(cid:48)).

P,α,p(F), we decompose the excess risk
P,α,p((cid:96)∗)

≤ RP,α,p(ˆ(cid:96)) − RPN ,α,p(ˆ(cid:96)) + R∗

PN ,α,p((cid:96)∗) − R∗

P,α,p((cid:96)∗),

(53)

(54)

(124)

where the last equality stands by the optimality of ˆ(cid:96).

Next, we introduce ˆλ and λ∗ as the corresponding dual variables of ˆ(cid:96) and (cid:96)∗ as
(cid:105) (cid:27)

(cid:26)

(cid:104)

ˆ(cid:96) ∈ min
λ≥0

λαp + Ez∼PN

ψλ, ˆ(cid:96)(z)

,

and

(cid:96)∗ ∈ min
λ≥0

(cid:26)

λαp + Ez∼P

(cid:104)

(cid:105) (cid:27)

ψλ, (cid:96)∗ (z)

.

By the ﬁrst part of Theorem 2, the right-hand side of (124) can be further bounded by

RP,α,p(ˆ(cid:96)) − RPN ,α,p(ˆ(cid:96)) = min

(cid:26)

λαp +

(cid:90)

Z

ψλ,ˆ(cid:96)(z)P(dz)

(cid:27)

(cid:18)

−

ˆλαp +

(cid:90)

Z

ψˆλ,ˆ(cid:96)(z)PN (dz)

(cid:19)

λ≥0
(cid:90)

≤

ψˆλ,ˆ(cid:96)(z)(P − PN )(dz),

and

Z

R∗

PN ,α,p((cid:96)∗) − R∗

P,α,p((cid:96)∗) ≤

(cid:90)

Z

ψλ∗,(cid:96)∗ (z)(PN − P)(dz).

By Lemma 1, we know

and deﬁne the function class

(127) can be written as

ˆλ ∈ Λ := (cid:2) 0, Lα−(p−1) (cid:3)

(cid:110)

Ψ =

ψλ, (cid:96)

(cid:12)
(cid:12) λ ∈ Λ, (cid:96) ∈ F

(cid:111)
,

RP,α,p(ˆ(cid:96)) − RPN ,α,p(ˆ(cid:96)) ≤ sup

ψ∈Ψ

(cid:26) (cid:90)

Z

ψ d( P − PN )

(cid:27)

.

24

(125)

(126)

(127)

(128)

(129)

(130)

(131)

By Assumption 3, 4 and the deﬁnition of ψλ, (cid:96) as (63), we know that every ψ ∈ Ψ is bounded and take value in [0, B].
Employing symmetrization, we have

RP,α,p(ˆ(cid:96)) − RPN ,α,p(ˆ(cid:96)) ≤ 2RN (Ψ) + B

(cid:115)

log( 2
η )
N

with probability at least 1 − η

2 , where

RN (Ψ) = E

(cid:34)

1
N

N
(cid:88)

i=1

sup
ψ∈Ψ

(cid:35)

(cid:15)iψ(z)

(132)

(133)

is the expected Rademacher average of Ψ, with i.i.d Rademacher random variables {(cid:15)i} which are independent of {zi},
i ∈ [N ]. Moreover, from Hoeffding’s inequality, it follows that

R∗

PN ,α,p((cid:96)∗) − R∗

P,α,p((cid:96)∗) ≤ B

(cid:115)

log( 2
η )
2N

(134)

with probability at least 1 − η
theorem.

2 . Combining (132) and (134), and apply the Lemma from Appendix, we obtain the whole

THE STACKELBERG GAME ATTACK ON PAIRWISE RANKING.
We study the poisoning attack on pairwise ranking, which injects the malicious pairwise comparisons into the training
set of the ranking algorithm. Meanwhile, the robust ranking algorithm could prune the outlier when leaning a consensus
ranking with the noise observation. Such an adversarial interaction between two opponents can is naturally a game. One
player will control the ranking algorithm, and the other player will manipulate the distribution of input data, especially
the pairwise comparisons. The optimal action for each player generally depends on both players’ strategies.

We adopt positive integers to index alternatives and users. Henceforth, V always is the set {1, . . . , n} and denotes a
set of alternatives to be ranked. In our approach to attack pairwise ranking, we represent these candidates as vertices of
a graph. U = {1, . . . , m} denotes a set of voters or users. For i, j ∈ V , we write the pairwise comparison i (cid:31) j or (i, j)
to mean that alternative i is preferred over alternative j. If we hope to emphasize the preference judgment of a particular
user u, we will write i (cid:31)u j or (u, i, j).

For each user u ∈ U , the pairwise ranking matrix of user u is a skew-symmetric matrix
Y u = {yu

ij} ∈ Rn×n, i, j ∈ V , u ∈ U ,

i.e. for any ordered pair (i, j) ∈ V × V , we have

ij = −yu
yu
ji.

(135)

(136)

Informally, yu
we focus on the “binary” case of Y u ∈ {−1, 1}n×n. Here yu
(u, i, j) made by user u.

ij measures the “degree of preference” of the ith alternative over the jth alternative held by the uth voter. Here
ij = 1 means there exist a particular preference judgment

Deﬁne the weight function w : U × V × V → [0, ∞) as the indicator function

wu

ij = w(u, i, j) =

(cid:26)1,

if yu
ij = 1,
0, otherwise.

(137)

25

With the weight function w, we can aggregate all users’ pairwise comparison matrices {Y u}, u ∈ U into a single
comparison matrix Y = {yij} with weights matrix W 0 = {w0

ij}, where
(cid:33)
,

(cid:32)

V
2

yij = 1, ∀ (i, j) ∈

(cid:1)

(cid:0)V
2

is the set of all ordered pairs of elements of V , and

w0

ij =

(cid:88)

u∈U

wu

ij, ∀ (i, j) ∈

(cid:33)
.

(cid:32)

V
2

(138)

(139)

A graph structure arises naturally from ranking data as follows. Let G = (V , E) be a directed graph whose vertex set

is V , the set of candidates to be ranked. The edge set is

(cid:40)

E :=

e = (i, j)

(cid:12)
(cid:12)
(cid:12) (i, j) ∈

(cid:33)(cid:41)

.

(cid:32)

V
2

(140)

We call such G a pairwise comparison graph. One can further associate weights on the edges as (4). Different from the
general pairwise ranking setting, we do not prune the edges whose weights equal to 0. As a consequence, the pairwise
comparison graph G is a complete graph. The cardinality of the edge set is

|E| := N = n(n − 1).

The comparison between i and j will be labeled by different annotators and their answers to the same question could

be inconsistent, i.e.,

ij = yu2
yu1

ji = 1, u1, u2 ∈ U .

To obtain the true direction between vertex i and j, we deﬁne an estimator ˆyij of noise label yij on edge e = (i, j),

ˆye = (cid:104)ze, θ(cid:105) + γe + εe, ∀ e ∈ E,

(141)

(142)

where Z = {ze} ∈ {−1, 0, 1}N ×n, e ∈ E is the incident matrix of G, θ ∈ Rn is some true scaling scores on V ,
εe ∼ N (0, σ2) is the Gaussian noise with zero mean and variance σ, and the outlier indicator variable γe ∈ R is assumed to
have a higher magnitude than σ. Here the outliers are the aggregated edges whose directions conﬂict with the true ranking.
In order to estimate the N + n unknown parameters (N for γ and n for θ), we aim to minimize the discrepancy between
the annotation y and the prediction Zθ + γ, as well as holding the outlier indicator γ sparse. It gives us the following
optimization problem:

where

minimize
θ, γ

(cid:96)w0(θ, γ) + λ · Rw0(γ),

(cid:96)w0 (θ, γ) =

=

1
2
1
2

(cid:107)y − Zθ − γ(cid:107)2

2,w0

w0

ij(yij − γij − θi + θj)2,

(cid:88)

e∈E

y = ver(Y ), w0 = ver(W 0) is the vector form of Y and W 0, and the weighted regularization term Rw0 is

Rw0 (γ) = (cid:107)γ(cid:107)1,w0 =

w0

ij|γe|.

(cid:88)

e∈E

(143)

(144)

(145)

In this situation, the weight w0 and the label y would be treated as the input data of the ranking problem (143). Moreover,
we introduce the variable β = (θ, γ)(cid:62) to deﬁne the action space of the ranking algorithm. We rewrite (143) as

where

minimize
β∈Bλ

(cid:96)w0(β),

(cid:96)w0 (β) =

(cid:20)Z

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

y −

1
2

(cid:21) (cid:32)
1

θ
γ

(cid:33)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

2,w0

(146)

(147)

and

(cid:40)

Bλ =

β

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:42)

(0, w0) ,

(cid:33)(cid:43)

(cid:41)

≤ ε(λ)

(cid:32)

θ
γ

26

(148)

is the feasible set of (143) and the ranker’s action space.

We model poisoning attack as a game between two players, the ranker and an attacker, where the latter wants to
mislead its opponent into picking parameters to generate a difference order against the true ranking. To disguise himself,
the adversary needs to coordinate a poisoned w associate with y. Intuitively, the adversary could not obtain w through
drastic changes, neither on each wij nor (cid:80) wij. Such limitations lead to the following constraints for adversary’s action.
First, the total difference between w0 and w would be smaller than b, namely,

(cid:107)w − w0(cid:107)1 ≤ b, b ∈ Z+.

Furthermore, the adversary could not alter the number of votes on any pairwise comparison e ∈ E obviously,

(cid:107)w − w0(cid:107)∞ ≤ l,

l ∈ Z+,

l ≤ min{max(w0), b},

and the adversary‘s action space Ww0 is

Ww0 =




w



(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

w ∈ ZN

+ , l, b ∈ Z+,
(cid:107)w − w0(cid:107)1 ≤ b,
(cid:107)w − w0(cid:107)∞ ≤ l,
l ≤ min{max(w0), b}






.

(149)

(150)

(151)

The robust ranking algorithm (143) observes the poisoned training set sampling from G, prunes the outlier and learns a
ranking from the remaining data simultaneously. Against the robust ranking algorithm that employs the defense described
above, we can formulate the attacker’s goal as the following bi-level optimization problem:

(cid:96)w(ˆθ, ˆγ) + λ · Rw(ˆγ),

maximize
w
subject to ˆθ, ˆγ ∈ arg min

(cid:96)w(θ, γ) + λ · Rw(γ),

(152)

θ,γ

w ∈ Ww0.

Distributional Perspective
In (14), the (cid:96)1 and (cid:96)∞ distance constraints on w correspond to the attacker only being able to ﬁnd the perturbation in the
neighborhood of w0. The lower problem in (152) corresponds to the robust pairwise ranking algorithm. With input data
{w, y}, the ranker obtain the relative score θ by minimizing the discrepancy between the annotation y and the prediction
Zθ + γ while keeping γ to be sparse. Unfortunately, the bilevel nature of (152) [5], [6]—maximizing the outer loss involves
an inner minimization to ﬁnd the parameters θ, γ—makes it difﬁcult to solve, even less the discrete property of (12) and
(13). Next, we will discuss the poisoning attack on pairwise ranking in a different way. Generally, we can look at the poison
attack (152) from a distributional perspective. The attacker and the ranker both access the weighted comparison graph G
to play a game as (152). Actually, the non-toxic training data {w0, y} are drawn according to a probability distribution P
(cid:88)

(153)

p(w0, y) =

p(w0

ij, yij).

e∈E

The attacker chooses a perturbation function ψ : ZN
+ that change the weight w0 to w. The attacker constructs the
perturbation ψ with the limitation as (14). Such a perturbation ψ induces a transition from empirical distribution P to a
poisoned distribution Q

+ → ZN

q(w, y) = q(ψ(w0), y) =

q(wij, yij).

(154)

(cid:88)

The attacker can only alter b pairwise comparisons at most, increase or decrease the number of vote on any comparison
less than l, and formulate the poisoned training set {w, y}. If the attacker selects Q in a small enough neighborhood of P ,
namely, the “distance” between the poisoned distribution Q and the empirical distribution P would be small, the attacker
could obtain a good approximation of P in the sense of such a “distance” and the poisoned sample {w, y} would be
satisﬁed the constraints (12) and (13).

Let φ : R+ → R be a convex function with φ(1) = 0. Then the φ-divergence between distributions Q and P deﬁned on

e∈E

a space X is

dφ(Q||P ) =

=

(cid:90)

(cid:90)

X

φ

φ

(cid:19)

(cid:18) dQ
dP
(cid:18) q(x)
p(x)

dP

(cid:19)

p(x)dµ(x),

(155)

where µ is a σ-ﬁnite measure with Q, P (cid:28) µ, and q = dQ
action space, the local neighborhood of the empirical distribution P with radius ρ as

dµ , p = dP

dµ . Given φ and sample w0, we reformulate the adversary’s

QP = {distribution Q satisﬁes dφ(Q||P ) ≤ ρ},

(156)

27

where P is the empirical distribution of the pairwise comparisons, and Q is the toxic distribution for poisoning attack.
Throughout this paper, we adopt

1
2
which gives the χ2-divergence [18], [54], [68]. It means that Q consists of discrete distributions supported on the observation
{(w0, y)}. With opportunely chosen ρ, the adversary could obtain w which satisﬁes the neighborhood constraints as (12)
and (13).

(t − 1)2,

φ(t) =

The possible actions of two players a = [βλ, w] constitute the joint action space A = Bλ × QP which is assumed to be
nonempty, compact, and convex. Action spaces A are parameters of the game (152). Then the bi-level integer programming
(152) can be written as a min-max optimization problem:

sup
q∈QP

inf
β∈Bλ

EQ[(cid:96)(β, q(w, y))] = sup

dφ(Q||P )≤ρ

inf
(cid:107)q(w)◦β(cid:107)1≤ε(λ)

EQ[(cid:96)(β, q(w, y))]

where

q(w) ◦ β =

(cid:20)0

(cid:21)

(cid:21) (cid:20)θ
γ

,

q(W )

(157)

W = diag(w) is a diagonal matrix. Due to the (cid:96)1 norm is decomposable, we can deﬁne a new set of loss function
fij : Bλ × Z+ × {−1, 1}N → R+, ∀ e ∈ E

fij(β, q(w, y))
1
2
(cid:20) 1
2

= q(wij) ·

(yij − γij − θi + θj)2 + λ · q(wij)|γij|

= q(wij) ·

(yij − γij − θi + θj)2 + λ · |γij|

(cid:21)

and the ﬁnite sum of {fij}

f (β, q(w, y)) =

(cid:88)

e∈E

fij(β, q(w, y))

(158)

(159)

With ﬁxed λ and some special form of q, (157) could be a convex problem. We swap the order of minimization and
maximization in the min-max optimization problem (157) as

inf
β∈Bλ

sup
q∈QP

EQ[f (β, q(w, y))] = inf
β∈Bλ

sup
q

(cid:26)

EQ[f (β, q(w, y))], s.t. dφ(Q||P ) ≤ ρ

(cid:27)

.

(160)

In fact, the minimization of (157) and (160) correspond to the residual method and the Tikhonov regularization with
discrepancy principle of the LASSO. Indeed, it can be shown that the constrained minimization problem is equivalent to
Tikhonov regularization, when the regularization parameter λ is chosen according to Morozov’s discrepancy principle [25].
Note that the objective function of (160) is a strictly convex function with respect to its arguments, then by [7, Theorem
4.3], at least one Nash equilibrium exists.

Optimization

From a game-theoretic viewpoint, (160) can be seen as a zero-sum game between two agents: the agent ranker (the inﬁmum)
seeks to incur the least possible loss, while the agent adversary (the supremum) seeks to obtain the worst possible objective
function value – both given by f (βλ, w, y).

For the supremum part of (160), the integer characteristic of w obstructs obtaining a probability density function q of
the toxic distribution Q. Thanks to distributionally robust optimization, we reformulate the supremum part of (160) as a
quadratically constrained linear maximization problem. This tractable formulation can be solved by the probability simplex
projection method. Suppose the total number of pairwise comparison without toxic is

and the frequencies of each comparison are

M 0 =

(cid:88)

e∈E

w0
ij,

p =

1
M 0 w0.

Let the maximum toxic dosage be κ. It suggests that the number of toxic pairwise comparisons M satisﬁes
(cid:88)

M =

wij ≤ (1 + κ) · M 0,

e∈E

(161)

(162)

(163)

Furthermore, we replace the toxic weight w with its frequency q = w
general optimization by such a variable substitution. We note

M . We relax the integer programming problem into a

28

ze =

1
2

(yij − γλ

ij − θλ

i + θλ

j )2 + λ · |γλ

ij|, e ∈ E

(164)

and z = [z1, . . . , zN ] ∈ RN
to compute the worst-case linear combination of {zij}, e ∈ E as

+ . The objective function with ﬁxed βλ, maximizing the expectation EQ[f (βλ, q(w, y))] equals

maximize
q

(cid:104)q, z(cid:105) , s.t. dφ(Q||P ) ≤ ρ.

(165)

As Q is a distribution, it requires that the combination coefﬁcients q should satisfy

(cid:88)

e∈E

qe = 1 or (cid:104)1, q(cid:105) = 1.

It means that the distribution of q is a probability simplex. Furthermore, as P and Q are the discrete distributions and we
choose φ(t) = 1

2 (t − 1)2 in (1), the neighborhood constraint dφ(Q||P ) ≤ ρ can be transformed as

1
2

(cid:107)q − p(cid:107)2

2 ≤ ρ(cid:107)p(cid:107)2
2.

(166)

Now we obtain the following quadratically constrained linear maximization problem which could be used to compute the
supremum problem in (160):

maximize
q

(cid:104)q, z(cid:105) s.t. q ∈ Qp

where

Qp =

(cid:26)

q

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
2

(cid:107)q − p(cid:107)2

2 ≤ ρ(cid:107)p(cid:107)2

2, (cid:104)1, q(cid:105) = 1

(cid:27)

.

We reformulate the concave optimization (167) as a minimization problem for simplicity:

minimize
q

(cid:104)q, z(cid:105) s.t. q ∈ Qp,

(167)

(168)

(169)

and take a partial dual problem of this minimization, then maximize this dual problem to ﬁnd the optimal q.

First, we introduce the dual variable µ ≥ 0 for the quadratical constraint (166). Notice that the strong duality exists for

(169) because the Slater condition is satisﬁed by

Performing the standard min-max swap [13], it yields the following problem

q = p and 1(cid:62)p = 1.

inf
q

(cid:110) µ
2

(cid:107)q − p(cid:107)2

minimize
µ≥0
2 − µρ(cid:107)p(cid:107)2

2 + q(cid:62)z | q ∈ RN

(cid:111)
+ , q(cid:62)1 = 1

.

g(µ) =

(170)

Given a collection of concave functions {gq}q∈Qp , if it attains

inf g = inf
q∈Qp

gq

at some q0 ∈ Qp, we know that ∇gq0 is the super-gradient of g [29, Chapter VI.4.4]. Suppose q(µ) is the unique minimizer
of the right hand side of (170), the dual function g will be

g(µ) =

µ
2

(cid:107)q(µ) − p(cid:107)2

2 − µρ(cid:107)p(cid:107)2

2 + q(µ)(cid:62)z

and the derivative with respect to µ (keeping q(µ) ﬁxed) is

g(cid:48)(µ) =

1
2

(cid:107)q(µ) − p(cid:107)2

2 − ρ(cid:107)p(cid:107)2
2.

(172)

(173)

As the constraints q ≥ 0 and q(cid:62)1 = 1 require q is on the probability simplex, we adopt the Euclidean projection of a
vector to the probability simplex [19]. Such a projection provides an efﬁcient solver of the inﬁmum (169). With no loss of
generality, we assume that z is an increasing sequence and the mean of z is zero,

z1 ≤ z2 ≤ · · · ≤ zN ,

(cid:104)z, 1(cid:105) = 0.

Then we use a, σ ∈ RN

+ , the cumulative summation of z and z2 as
(cid:88)

(cid:88)

ai =

zi, σi =

z2
i ,

i ∈ [N ].

j≤i

j≤i

(174)

(175)

Algorithm 2: Poisoning Attack on Pairwise Ranking

Input

: the original data {w0, y}, maximum toxic dosage κ, parameter ρ, solution accuracy ε, and an outlier
pruning rate τ .

1 Initialize the frequency of w0, p by (27),
2 Obtain the ranking parameters on the original data:

βλ ← HodgeRank(w0, y, τ ),

3 Calculate the objective function value z by (164):
4 while w not converged do
5

Update the frequency: q = WorstCase(z, p, ρ, ε),
Assign the weight with q,

6

7

8

w(cid:48) = (cid:2)(1 + κ) · M 0(cid:3) q,

Round w(cid:48) to obtain the w as integer vector

Update the ranking parameters:

w = rounding(w(cid:48)),

βλ ← HodgeRank(w, y, τ ),

29

(171)

Update the objective function value: z via (164),

9
10 end

Output: the poisoned data {w, y}, the ranking parameters βλ = {θλ, γλ}.

The inﬁmum in (170) is equivalent to projecting the vector v(µ) ∈ RN onto the probability simplex,

1
µ
According to [19], q(µ) has the form as qi(µ) = (vi − η)+ for some η ∈ R, where η is selected such that (cid:80) qi(µ) = 1.
Finding such a value η is equivalent to ﬁnding the unique index i such that

vi = pi −

i ∈ [N ]

(176)

zi,

i
(cid:88)

(vj − vi) < 1 and

j=1

i+1
(cid:88)

j=1

(vj − vi+1) > 1.

If no such index exists, we set i = n as the sum (cid:80)i

j=1(vj − vi) is increasing in i and v1 − v1 = 0. Given the index i,

η = pi −

1
i

−

1
iµ

i
(cid:88)

j=1

zi = pi −

1
i

−

1
iµ

ai

(177)

(178)

satisﬁes (cid:80)(vi − η)+ = 1 and vj − η ≥ 0 for any j ≤ i while vj − η ≤ 0 for j > i. Meanwhile, the derivative ∂
q(µ) is ﬁxed) has a explicit form

∂µ g(µ) (where

∂
∂µ
1
2
1
2

i
(cid:88)

j=1

g(cid:48)(µ) =

=

=

=

=

(cid:110) µ
2

(cid:107)q(µ) − p(cid:107)2 − µρ(cid:107)p(cid:107)2

2 + q(cid:62)(µ)z

(cid:111)

(cid:107)q(µ) − p(cid:107)2 − ρ(cid:107)p(cid:107)2

1
2

i
(cid:88)

j=1

(cid:18) zj
µ

(cid:19)2

+ η

+

1
2

N
(cid:88)

j=i+1

j − ρ(cid:107)p(cid:107)2
p2

σi
2µ2 +

η2i
2

+

aiη
µ

+

N
(cid:88)

j=i+1

j − ρ(cid:107)p(cid:107)2
p2

(vj − η − pj)2 +

1
2

N
(cid:88)

j=i+1

j − ρ(cid:107)p(cid:107)2
p2

(179)

The derivative g(cid:48)(µ) only needs O(1) when a and σ are known. Binary search can calculate the optimal index i and q
efﬁciently, which requires O(log 1
ε log N ) to ﬁnd µ with accuracy ε. We can get η through (178) if (177) are satisﬁed. The
solution q(µ) is

qi =

(cid:18)

pi −

zi
µ

− η

(cid:19)

, i ∈ [N ].

+

(180)

Speciﬁcally, the computational complexity to obtain the sorted vector z is O(N log N ), and that of the estimate of the
frequency q is O(log 1

ε log N ). The overall time computational complexity is O(N log N + log 1

ε log N ).

At last, we describe the whole optimization of the poison attack on pairwise ranking with Algorithm 1. We summarize
the complete optimization procedure of the supremum in (160) as Algorithm 3 and Algorithm 3. For the inﬁmum part of
(160), the agent HodgeRank ﬁnds βλ that minimizes the regularized loss on {w, y} where the hyper-parameter λ controls
the regularization strength. We include the solving process of HodgeRank as Algorithm 5 for completeness.

30

Algorithm 3: WorstCase(z, p, ρ, ε)

Input

: the objective function value z ∈ RN , the frequency of true comparisons p ∈ RN
accuracy ε.

+ , parameter ρ, solution

1 Make z have the zero mean: z ← z − ¯z, and sort z.
2 Initialize µmin = 0, ai = (cid:80)
j≤i z2

j≤i zj, and σi = (cid:80)

j for all i ∈ [N ],
(cid:115)

(cid:40)

µmax = µ∞ = max

(cid:107)z(cid:107)∞,

(cid:41)

1
ρ(cid:107)p(cid:107)2
2

(cid:107)z(cid:107)2

3 while |µmax − µmin| > εµ∞ do
2 (µmin + µmax), and
4

Set µ = 1

(η, i) = FindShift(z, p, a, µ),

5

6

7

8

9

Obtain the partial derivative g(cid:48)(µ) by (179)
if g(cid:48)(µ) > 0 then
µmin ← µ

else

µmax ← µ

end

10
11 end
12 Set µ = 1

2 (µmin + µmax), and

(η, i) = FindShift(z, p, a, µ),

Output: q by (180).

Algorithm 4: FindShift(z, p, a, µ)

Input

: the sorted and zero mean vector z ∈ RN , the frequency p, the cumulative sum a, and the dual variable µ.

1 Initialize ilow = 1 and ihigh = N ,
2 if pN − 1
µ zN ≥ 0 then
3

η = 0, i = N ,
Break.

4
5 else
6

while ilow (cid:54)= ihigh do

2 (ilow + ihigh),

i = 1
aleft = (cid:80)i
aright = (cid:80)i+1
if aright ≥ 1 ∧ aleft < 1 then

j=1(vj − vi) = 1
j=1(vj − vi+1) = 1

µ (izi − ai),

µ [(i + 1)zi+1 − ai+1],

7

8

9

10

11

12

13

14

15

16

17

η = pi − 1
Break.

i − 1

iµ ai,

else if aleft ≥ 1 then
ihigh = i − 1

else

ilow = i + 1

end

end

18
19 end

Output: i = ilow, η = pi − 1

i − 1

iµ ai.

31

Algorithm 5: HodgeRank(w, A, y)

Input

: the weight w, the comparison matrix A and the corresponding label y.

1 Calculate the relative ranking score ˆθ

ˆθ = (X (cid:62)X + δI)−1X (cid:62)

√

W y

√

√

√

where X =
W = diag(
Output: the corresponding ranking parameter ˆθ.

W A,

w).

