DeepSun: Machine-Learning-as-a-Service for Solar
Flare Prediction

Yasser Abduallah, Jason T. L. Wang, Yang Nie
Department of Computer Science
New Jersey Institute of Technology
University Heights, Newark, NJ 07102, USA

Chang Liu, Haimin Wang
Institute for Space Weather Sciences
New Jersey Institute of Technology
University Heights, Newark, NJ 07102, USA

0
2
0
2

p
e
S
4

]

M

I
.
h
p
-
o
r
t
s
a
[

1
v
8
3
2
4
0
.
9
0
0
2
:
v
i
X
r
a

Abstract—Solar ﬂare prediction plays an important role in un-
derstanding and forecasting space weather. The main goal of the
Helioseismic and Magnetic Imager (HMI), one of the instruments
on NASA’s Solar Dynamics Observatory, is to study the origin
of solar variability and characterize the Sun’s magnetic activity.
HMI provides continuous full-disk observations of the solar
vector magnetic ﬁeld with high cadence data that lead to reliable
predictive capability; yet, solar ﬂare prediction effort utilizing
these data is still limited. In this paper, we present a machine-
learning-as-a-service (MLaaS) framework, called DeepSun, for
predicting solar ﬂares on the Web based on HMI’s data products.
Speciﬁcally, we construct training data by utilizing the physical
parameters provided by the Space-weather HMI Active Region
Patches (SHARP) and categorize solar ﬂares into four classes,
namely B, C, M, X, according to the X-ray ﬂare catalogs available
at the National Centers for Environmental Information (NCEI).
Thus, the solar ﬂare prediction problem at hand is essentially a
multi-class (i.e., four-class) classiﬁcation problem. The DeepSun
system employs several machine learning algorithms to tackle
this multi-class prediction problem and provides an application
programming interface (API) for remote programming users.
To our knowledge, DeepSun is the ﬁrst MLaaS tool capable of
predicting solar ﬂares through the Internet.

Index Terms—AI tool, machine learning, solar ﬂares

I. INTRODUCTION

Solar ﬂares and the often-associated coronal mass ejections
(CMEs) highly impact the near-Earth space environment [1],
[2]. They have the potential to cause catastrophic damage to
technology infrastructure [3]. According to the U.S. National
Space Weather Strategy, released by the Space Weather Pre-
diction Center, it is a challenging task to correctly predict solar
ﬂares and CMEs. Recent efforts led by the United States and
its partners resulted in substantial progress toward monitoring,
prediction, and mitigation plans, but much more effort is still
needed.

Researches have indicated that the magnetic free energy
stored in the corona, quickly discharged by magnetic recon-
nection, powers solar ﬂares and CMEs [4] . The process of
building the coronal free energy is controlled by the structural
evolution of the magnetic ﬁeld on the photosphere where
plasma dominates the process. Observing and measuring the
structure and evolution of the photospheric magnetic ﬁeld
can provide valuable information and clues to the triggering
mechanisms of ﬂares and CMEs. There are many physical

properties or parameters, as we will discuss later in the paper,
that characterize the static photospheric magnetic ﬁeld, such as
integrated Lorentz force, magnetic helicity injection, unsigned
magnetic ﬂux, vertical electric currents, magnetic shear and
gradient, and magnetic energy dissipation.

Researchers spent signiﬁcant efforts attempting to under-
stand the physical relationship between ﬂare productivity and
non-potentiality of active regions (ARs) as speciﬁed by the
physical parameters. This led researchers to use different
methods to predict ﬂares that are not based on physical models,
but rather based on statistical modeling and machine learning
[5]. Machine learning gives computer programs the ability to
learn from data and progressively improve performance. It uses
input data, also called training data, and learns hidden insights
in the training data to build a predictive model that will be used
later to make predictions on unseen test data.

In our previous work [1], we reported the results of solar
ﬂare prediction using the random forests (RF) algorithm
[6]. We constructed a database of solar ﬂare events using
the physical parameters provided by the Space-weather HMI
Active Region Patches (SHARP), and categorized solar ﬂares
into four different classes, namely B, C, M, X, based on
the X-ray ﬂare catalogs available at the National Centers for
Environmental Information (NCEI). Flares in the B class have
the smallest magnitude while ﬂares in the X class have the
largest magnitude. We used the RF algorithm and the physical
parameters or features to perform multi-class classiﬁcation of
solar ﬂares, predicting the occurrence of a certain class of
ﬂares in a given active region (AR) within 24 hours. Our
experimental results demonstrated the good performance of
the RF algorithm.

In this paper, we extend our previous work in [1] by con-
sidering two additional multi-class classiﬁcation algorithms:
multilayer perceptrons (MLP) and extreme learning machines
these algorithms into a machine-
(ELM). We implement
learning-as-a-service (MLaaS) framework, called DeepSun,
which allows scientists to perform multi-class ﬂare predic-
tion on the Internet. Speciﬁcally, our work here makes two
contributions.

1) We develop an ensemble method for multi-class ﬂare
prediction that performs better than the existing machine

 
 
 
 
 
 
TABLE I: 13 Important SHARP Physical Parameters

Parameter

Description

ABSNJZH
AREA ACR
EPSZ
MEANPOT
R VALUE
SAVNCPP
SHRGT45
TOTBSQ
TOTFZ
TOTPOT
TOTUSJH
TOTUSJZ
USFLUX

Absolute value of the net current helicity
Area of strong ﬁeld pixels in the active region
Sum of z-component of normalized Lorentz force
Mean photospheric magnetic free energy
Sum of ﬂux near polarity inversion line
Sum of the modulus of the net current per polarity
Fraction of area with shear > 45°
Total magnitude of Lorentz force
Sum of z-component of Lorentz force
Total photospheric magnetic free energy density
Total unsigned current helicity
Total unsigned vertical current
Total unsigned ﬂux

learning algorithms including RF, MLP and ELM accord-
ing to our experimental study.

2) We design and implement DeepSun, which is the ﬁrst
MLaaS system of its kind for solar ﬂare prediction.
The rest of this paper is organized as follows. Section II
describes the data and the SHARP predictive parameters
used in this study. Section III describes the machine learning
algorithms employed by DeepSun. Section IV evaluates the
performance of these machine learning algorithms. Section
V details the design and implementation of the DeepSun
framework. Section VI surveys related work and compares
DeepSun with existing services computing systems. Section
VII concludes the paper and points out some directions for
future research.

II. DATA AND PHYSICAL PARAMETERS

In 2012, SHARP data were released. The main goal of the
SHARP data was to facilitate AR (active region) event fore-
casting [7]. These data are available in the Joint Science Op-
erations Center (JSOC) (http://jsoc.stanford.edu/) as hmi.sharp
series which include magnetic measures and parameters for
many ARs. In 2014, another data series, cgem.Lorentz, were
produced based on the SHARP data. This series include
the Lorentz force estimations. The main goal of this series
was to help diagnose the dynamic process of ARs. Bobra
et al. [7] considered 25 physical parameters in the SHARP
datasets that characterize the AR magnetic ﬁeld properties.
The authors used a univariate feature selection method to
score the 25 parameters, and suggested that the top 13 out
of the 25 parameters be used as predictors for ﬂare activity.
Table I summarizes these 13 important parameters and their
descriptions. More details about the 13 physical parameters
can be found in [1].

We constructed a database based on the SHARP parameters
extracted from the solar images that are available at
the
Joint Science Operations Center (JSOC) and the X-ray ﬂare
catalogs provided by the National Centers for Environmental
Information (NCEI) [1]. We considered the period between
May 2010 and December 2016. There are 845 ﬂares in this

TABLE II: Numbers of Flares and Active Regions per Solar
Flare Class

Flare Class

Number of Flares

Number of ARs

B
C
M
X

128
552
142
23

88
281
88
15

period, among which 128 ﬂares are of class B, 552 ﬂares are
of class C, 142 ﬂares are of class M, and 23 ﬂares are of class
X. These 845 ﬂares come from 472 active regions (ARs). The
duration of a ﬂare ranges from several minutes to hours. The
duration of an AR ranges from several minutes to days. Table
II summarizes the ﬂare information.

We created and stored 845 corresponding data samples in
our database, shown in Figure 1 and accessible at https://
nature.njit.edu/spacesoft/Flare-Predict/, where each data sam-
ple contains values of the 13 physical parameters or features
listed in Table I. The two digits following a class label (B,
C, M, X) are ignored in performing ﬂare prediction. The time
point of a data sample is the beginning time (00:00:01 early
morning) of the start date of a ﬂare and the label of the data
sample is the class which the ﬂare belongs to. These labeled
data samples are used to train the DeepSun system.

III. MACHINE LEARNING ALGORITHMS

DeepSun employs three machine learning algorithms for
ﬂare prediction: random forests (RF) [6], multilayer percep-
trons (MLP) [8], [9] and extreme learning machines (ELM)
[10], [11]. RF is a tree-based algorithm comprised of multiple
binary classiﬁcation and regression trees (CART) while both
MLP and ELM are feed-forward artiﬁcial neural networks. All
the three algorithms are well suited for multi-class classiﬁca-
tion. In addition, we develop an ensemble (ENS) algorithm,
which works by taking the majority vote of RF, MLP and
ELM. If there is no majority vote for a test data sample, ENS
outputs “no verdict” for the test data sample.

IV. PERFORMANCE EVALUATION

We conducted a series of experiments to evaluate the
performance of the machine learning algorithms presented in
Section III using the database described in Section II. To
avoid bias and to keep the data as balanced as possible, we
created 100 csv (comma separated values) datasets of which
each dataset included all B, M, and X classes and randomly
selected 142 data samples of class C. We used 10-fold cross
validation in which for each data set, we randomly formed 10-
fold partitions using the KFold function provided by the scikit-
learn library in Python [12]. Each machine learning algorithm
was trained by nine of the 10-folds, and the 10th fold was
used for testing. To overcome errors associated with cross
validation, we repeated the procedure 100 times for each of
the 100 datasets that resulted in 10000 iterations to produce
the ﬁnal result.

Fig. 1: Screenshot showing our online ﬂare database.

We converted the multiple-class classiﬁcation problem at
hand into four binary classiﬁcation problems for the four
classes B, C, M, X respectively. For example, consider the
binary classiﬁcation problem for class B. Here, we say a
data sample is positive if it is in class B, or negative if it
is not in class B, i.e., it is in class C, M or X. We deﬁne
TP (true positive), FP (false positive), TN (true negative),
FN (false negative) as follows. TP is a data sample where
an algorithm predicts the data sample to be positive and the
data sample is indeed positive. FP is a data sample where the
algorithm predicts the data sample to be positive while the
data sample is actually negative. TN is a data sample where
the algorithm predicts the data sample to be negative and the
data sample is indeed negative. FN is a data sample where the
algorithm predicts the data sample to be negative while the
data sample is actually positive. We also use TP (FP, TN,
FN respectively) to represent the number of true positives
(false positives, true negatives, false negatives respectively).
Because we are tackling an imbalanced classiﬁcation problem
(see Table II), we adopt two performance metrics, balanced
accuracy (BACC) and true skill statistics (TSS), where BACC
is deﬁned as follows:
1
2

TN
TN + FP

(cid:18) TP

BACC =

TP + FN

+

(cid:19)

and TSS is deﬁned as follows:

TSS =

TP
TP + FN

−

FP
TN + FP

BACC and TSS are well suited for imbalanced classiﬁcation
of solar eruptions [1], [2], [13]. We obtain BACC and TSS
for each binary classiﬁcation problem. There are four binary
classiﬁcation problems. We then calculate the average of the
BACC and TSS values obtained from the four classiﬁcation
problems, and use the average as the result for the multi-class
classiﬁcation problem.

We implemented the machine learning algorithms in Python
leveraging the scikit-learn packages [12]. Each algorithm has
different optimization parameters to be tuned based on the
training and test datasets. We used random forests (RF)
composed of 500 to 1000 trees and set the number of features
to six to ﬁnd the best node split. For multilayer perceptrons
(MLP) and extreme learning machines (ELM), we set the
number of hidden layers to 200. These parameter values were
chosen to maximize TSS values.

Table III compares the BACC and TSS values of the ma-
chine learning algorithms at hand for each binary classiﬁcation
problem and for the overall multi-class classiﬁcation problem
where the highest performance metric values are highlighted
in boldface. It can be seen from the table that the proposed
ENS algorithm is better than the existing algorithms RF, MLP
and ELM. However, all the four algorithms perform poorly in
predicting X-class ﬂares. This happens probably because the
X class has much fewer ﬂares than the other classes. Overall,
there were approximately less than 2% data samples receiving
“no verdict.”

TABLE III: Flare Prediction Results Using 13 SHARP Param-
eters and Four Machine Learning Algorithms

Class B

Class C

Class M Class X

Average

BACC
ENS
RF
MLP
ELM

TSS
ENS
RF
MLP
ELM

0.871
0.834
0.818
0.791

0.745
0.708
0.661
0.618

0.691
0.663
0.659
0.641

0.380
0.378
0.285
0.296

0.790
0.749
0.757
0.721

0.551
0.537
0.526
0.446

0.670
0.645
0.599
0.608

0.362
0.330
0.010
0.227

0.756
0.723
0.708
0.690

0.507
0.488
0.371
0.397

Fig. 2: Overview of DeepSun.

V. THE DEEPSUN FRAMEWORK

A. System Design

The four machine learning algorithms (ENS, RF, MLP,
ELM) have been implemented into our DeepSun system
where the algorithms are used as a back-end, also known as
the server-side, engine for the machine-learning-as-a-service
(MLaaS) platform. Fig. 2 presents the overall contextual
architecture of the DeepSun framework. The system supports
two different types of users: Web and programming. The Web
user invokes the service by accessing a graphical user interface
(GUI) to perform ﬂare predictions. The programming user can
use any programming language that supports HTTP requests,
such as Java, C++, Python, Node.js, JavaScript modules in
React or other frameworks to perform ﬂare predictions.

MLaaS is a representational state transfer (REST) ap-
plication programming interface (API) that supports JSON
(JavaScript Object Notation) formatted payloads in the request
and response. JSON is a plain-text and lightweight data-
interchange format. It is structured with attributes and values in
an easy way for humans to read and write. JSON is language
independent but it is easy to parse; therefore almost every
programming language supports it. The request transmits the
user’s data from the front-end to the back-end and must include
well deﬁned JSON formatted test data to predict or training
data to create a predictive model. The response transmits the
result from the back-end to the front-end, which is a well
formatted prediction result or the predictive model identiﬁer.
Here, the front-end means the client-side that can be a Web-
designed interface for the Web user or a program for the
programming user.

B. System Implementation

When a user visits DeepSun’s home page, the user sees
three options. Option 1 allows the user to select the pretrained
models provided by DeepSun. Option 2 allows the user to
upload his/her own training data to create his/her own machine

learning models for solar ﬂare prediction. Option 3 allows the
user to perform solar ﬂare prediction using RESTful services.
Fig. 3 shows DeepSun’s home page, which can be accessed
at https://nature.njit.edu/spacesoft/DeepSun/.

Fig. 3: Screenshot showing the home page of DeepSun.

1) Pretrained Models in DeepSun: The pretrained models
are ready-to-use models that were created using the database
described in Section II. With the pretrained models, a user
has multiple options to load test data samples containing
the 13 physical parameters or features listed in Table I: (1)
Manually enter the data samples with values of the 13 physical
parameters one by one in the provided text boxes. (2) Load
sample data provided by the DeepSun engine. (3) Load the
user’s own data in a ﬁle, in which each line contains the
values of the 13 physical parameters. The user may invoke the
services to predict all the loaded, or entered, test data at once
or make predictions one by one. Fig. 4 shows the webpage of
pretrained models on which four predictions were made using
the ENS algorithm.

2) Custom Models in DeepSun: DeepSun allows the user
to load his/her data to train and create his/her custom model

Fig. 4: Screenshot showing the webpage with pretrained models of DeepSun.

to predict solar ﬂares. The training data are saved in a ﬁle
meeting DeepSun’s format requirement. When the user creates
a custom model, a model identiﬁer (id) is assigned to the
current session. If the created model is idle for 24 hours, it
will be deleted. Once the model is ready, the user goes to the
DeepSun’s graphical user interface with the assigned model id
to perform ﬂare predictions as done with the pretrained mod-
els. The model id is used to distinguish between the custom
models and pretrained models. Fig. 5 shows the webpage of
custom models with example training data displayed.

3) RESTful API for DeepSun: The RESTful API is de-
signed to help the programming user perform solar ﬂare
predictions using the pretrained or custom models. The API
supports the POST request to predict solar ﬂare occurrence or
create a custom model, and the GET request to get a random
data sample from our training database. The interface supports
JSON formatted strings for requests’ body and their results.
The interface also supports two different debug levels; they are
(i) INFO which is the default debug mode and (ii) DEBUG
to return additional data with the result.

The return result from the POST request is a JSON object
including the predicted solar ﬂare occurrence and its class.
Each test data sample is associated with a JSON object that
includes two attributes. One attribute is “fcnumber” which is
the numerical representation for the solar ﬂare class where we
use “1” (“2”, “3”, “4” respectively) to represent class B (C,
M, X respectively). The other attribute is ”fcname” which is
the solar ﬂare class name.

In addition, the RESTful API uses the POST request to
create a custom model. The body of the request must be JSON
formatted strings for an array of JSON objects. Each object
must contain the 13 physical parameters and its ﬂare class
label where the label must be one of B, C, M, X. The return
result of this POST request is a JSON object that contains
the custom model identiﬁer (id) which can be used for ﬂare
prediction. The custom model includes all the four algorithms
(ENS, RF, MLP, ELM). Since the API is a RESTful interface,
any programming language that supports HTTP calls, such as
Java, C++, Python, Node.js, JavaScript modules in React or
other frameworks can be used to invoke the API. Fig. 6 shows
the RESTful API page on which the deﬁnitions of the available
methods and client examples are displayed.

VI. RELATED WORK

There are two groups of work that are closely related to ours.
The ﬁrst group is concerned with solar ﬂare forecasting. Many
studies in this group used parameters derived from the line-of-
sight (LOS) component of the photospheric magnetic ﬁeld and
produced probability outputs for the occurrence of a certain
magnitude ﬂare in a time period [1]. Some researchers [14]
used sunspot classiﬁcation and Poisson statistics to provide
probabilities for an active region (AR) to produce ﬂares with
different magnitudes within 24 hours. Song et al. [15] used
three LOS magnetic parameters together with the ordinal
logistic regression (OLR) method to predict the probabilities
of a one-day ﬂare. Bloomﬁeld et al. [16] suggested that the

Fig. 5: Screenshot showing the webpage with custom models of DeepSun.

prediction probabilities should be converted into a binary (i.e.,
yes-or-no) forecast before they can be translated as ﬂare-
imminent or ﬂare-quiet. Following this suggestion, Yuan et
al. [17] employed support vector machines (SVMs) to obtain
a clear true or false ﬂare prediction for different ﬂare classes.

M1.0 class. Nishizuka et al. [21] applied a number of machine
learning algorithms to HMI data and produced prediction
models for ≥M and X-class ﬂares with reasonably high
performance. More recently, we employed a long short-term
memory network for ﬂare prediction [13].

On the other hand, the full vector data provide more infor-
mation about the photospheric magnetic ﬁeld structure com-
pared to the LOS ﬁeld. This type of information may provide
better ﬂare prediction performance, but due to the limitation
imposed by ground-based vector magnetic ﬁeld observations,
the work on ﬂare forecast is limited. For example, Leka and
Barnes [18] used a small sample of vector magnetograms
from the Mees Solar Observatory and applied a discriminant
analysis to differentiate between ﬂare-producing and ﬂare-
quiet ARs within few hours. The authors later extended their
work and used a larger number of samples with a 24-hour
prediction window on producing probabilistic forecasts [19].

Since May 2010, the Helioseismic and Magnetic Imager
(HMI) onboard the Solar Dynamics Observatory (SDO) [20]
has been producing high quality photospheric vector magne-
tograms with high-cadence and full-disk coverage data. Using
these data, Bobra and Couvidat [20] calculated a number of
magnetic parameters for each AR. They selected 13 from
all
the available parameters and achieved good prediction
performance using an SVM method for ﬂares greater than

The second group of related work is concerned with services
computing. Benmerar et al. [22] developed a brain diffusion
MRI (magnetic resonance imaging) application to overcome
the SaaS (software-as-a-service) limitations caused by inten-
sive computation. The application provides APIs that tackle
browser paradigms to reduce the parallel computation rendered
in the client side of the browser.

Wu et al. [23] developed an automated testing technique
to detect cross-browser compatibility issues so that they can
be ﬁxed. These cross-browser issues cause problems for an
organization to create JavaScript web applications. The authors
employed an existing record-and-play technique, Mugshot
[24], to design an incremental cross-browser incompatibility
algorithm. The system starts off by injecting the record library
into the browsers, collects traces and events to be replayed,
and runs the detection algorithm to ﬁnd different types of
incompatibilities among the browsers.

Song et al. [25] presented a machine learning algorithm for
IT support services to automate the problem determination
and classiﬁcation, and also ﬁnd the root cause of a problem.

Fig. 6: Screenshot showing the RESTful API page of DeepSun.

The algorithm is an on-line perceptron that
learns about
the user’s problems from the data that were generated from
logs and monitoring information across different systems. The
algorithm then categorizes the problems by ﬁnding the actual
root cause from what it learned from the data. The algorithm
employs an incremental learning technique and is able to
automatically adjust the classiﬁer parameters.

Li et al. [26] described a new software documentation rec-
ommendation methodology that adopts a learn-to-rank (LTR)
technique. LTR is an application of supervised and semi-
supervised machine learning techniques. Their strategy com-
bines the social context from a questions-and-answers online
system and the content of ofﬁcial software documentation to
build the LTR model to provide accurate and relevant software
documentation recommendations. Their experimental results
showed that this approach outperforms traditional code search
engines including the Google search engine.

Our DeepSun system differs from the above works in two
ways. First, DeepSun provides services dedicated to solar ﬂare
prediction, which has not been addressed by the existing ser-
vices computing systems. Second, in the solar ﬂare forecasting
area, DeepSun is the ﬁrst MLaaS system, to our knowledge,
that allows scientists to perform multi-class ﬂare prediction
through the Internet.

VII. CONCLUSIONS AND FUTURE WORK

We present a machine-learning-as-a-service framework
(DeepSun) for solar ﬂare prediction. This framework provides
two interfaces: a web server where the user enters the in-
formation through a graphical interface and a programmable
interface that can be used by any RESTful client. DeepSun
employs three existing machine learning algorithms, namely
random forests (RF), multilayer perceptrons (MLP), extreme
learning machines (ELM), and an ensemble algorithm (ENS)

[16] D. S. Bloomﬁeld, P. A. Higgins, R. T. J. McAteer, and P. T. Gallagher,
“Toward reliable benchmarking of solar ﬂare forecasting methods,” The
Astrophysical Journal, vol. 747, p. L41, 2012.

[17] Y. Yuan, F. Shih, J. Jing, and H. Wang, “Automated ﬂare forecasting
learning technique,” Research in Astronomy and

using a statistical
Astrophysics, vol. 10, pp. 785–796, 2010.

[18] K. D. Leka and G. Barnes, “Photospheric magnetic ﬁeld properties of
ﬂaring versus ﬂare-quiet active regions. II. Discriminant analysis,” The
Astrophysical Journal, vol. 595, pp. 1296–1306, 2003.

[19] G. Barnes, K. D. Leka, E. A. Schumer, and D. J. Della-Rose, “Proba-
bilistic forecasting of solar ﬂares from vector magnetogram data,” Space
Weather, vol. 5, p. S09002, 2007.

[20] M. G. Bobra and S. Couvidat, “Solar ﬂare prediction using SDO/HMI
vector magnetic ﬁeld data with a machine-learning algorithm,” The
Astrophysical Journal, vol. 798, p. 135, 2015.

[21] N. Nishizuka, K. Sugiura, Y. Kubo, M. Den, S. Watari, and M. Ishii,
“Solar ﬂare prediction model with three machine-learning algorithms us-
ing ultraviolet brightening and vector magnetograms,” The Astrophysical
Journal, vol. 835, p. 156, 2017.

[22] T. Z. Benmerar, T. Megherbi, M. Kachouane, R. Deriche, and F. O.
Boumghar, “Browser-level parallelism and interactive rendering APIs
for scalable computation-intensive SaaS: Application to brain diffusion
MRI,” IEEE Transactions on Services Computing, 2018.

[23] G. Wu, M. He, W. Chen, J. Wei, and H. Zhong, “X-Check: Im-
proving effectiveness and efﬁciency of cross-browser issues detection
for JavaScript-based Web applications,” IEEE Transactions on Services
Computing, 2018.

[24] J. Mickens, J. Elson, and J. Howell, “Mugshot: Deterministic capture
and replay for JavaScript applications,” in 7th USENIX Symposium on
Networked Systems Design and Implementation (NSDI 10). San Jose,
CA: USENIX Association, 2010.

[25] Y. Song, A. Sailer, and H. Shaikh, “Hierarchical online problem
classiﬁcation for IT support services,” IEEE Transactions on Services
Computing, vol. 5, no. 3, pp. 345–357, 2012.

[26] J. Li, Z. Xing, and A. Kabir, “Leveraging ofﬁcial content and social
context to recommend software documentation,” IEEE Transactions on
Services Computing, 2018.

[27] H. Liu, Y. Xu, J. Wang, J. Jing, C. Liu, J. T. L. Wang, and H. Wang,
“Inferring vector magnetic ﬁelds from Stokes proﬁles of GST/NIRIS
using a convolutional neural network,” The Astrophysical Journal, vol.
894, p. 70, 2020.

[28] Z. Hu, T. Turki, N. Phan, and J. T. L. Wang, “A 3D atrous convolutional
long short-term memory network for background subtraction,” IEEE
Access, vol. 6, pp. 43450–43459, 2018.

[29] Z. Hu, T. Turki, and J. T. L. Wang, “Generative adversarial networks
for stochastic video prediction with action control,” IEEE Access, vol. 8,
pp. 63336–63348, 2020.

that combines the three machine learning algorithms. Our
experimental results demonstrated the good performance of the
ensemble algorithm and its superiority over the three existing
machine learning algorithms.

In the current work we focus on data samples composed
of SHARP physical parameters. We collect 845 data samples
belonging to four ﬂare classes: B, C, M, and X across
472 active regions. In addition, the Helioseismic Magnetic
Imager (HMI) aboard the Solar Dynamics Observatory (SDO)
produces continuous full-disk observations (solar images). In
future work we plan to incorporate these HMI images into
our DeepSun framework and extend our previously developed
deep learning techniques [27]–[29] to directly process the
images. We also plan to combine our recently developed deep
learning algorithms using the SHARP parameters [13] with
the image-based techniques and machine learning algorithms
described in this paper for more accurate solar ﬂare prediction.

REFERENCES

[1] C. Liu, N. Deng, J. T. L. Wang, and H. Wang, “Predicting solar ﬂares
using SDO/HMI vector magnetic data products and the random forest
algorithm,” The Astrophysical Journal, vol. 843, p. 104, 2017.

[2] H. Liu, C. Liu, J. T. L. Wang, and H. Wang, “Predicting coronal mass
ejections using SDO/HMI vector magnetic data products and recurrent
neural networks,” The Astrophysical Journal, vol. 890, p. 12, 2020.
[3] I. Daglis, D. Baker, J. Kappenman, M. Panasyuk, and E. Daly, “Effects
of space weather on technology infrastructure,” Space Weather, vol. 2,
p. S02004, 2004.

[4] E. Priest and T. Forbes, “The magnetic nature of solar ﬂares,” The
Astronomy and Astrophysics Review, vol. 10, pp. 313–377, 2002.
[5] G. Barnes, K. D. Leka, C. J. Schrijver, T. Colak, R. Qahwaji, O. W.
Ashamari, Y. Yuan, J. Zhang, R. T. J. McAteer, D. S. Bloomﬁeld, P. A.
Higgins, P. T. Gallagher, D. A. Falconer, M. K. Georgoulis, M. S.
Wheatland, C. Balch, T. Dunn, and E. L. Wagner, “A comparison of
ﬂare forecasting methods. I. Results from the “all-clear” workshop,”
The Astrophysical Journal, vol. 829, p. 89, 2016.

[6] L. Breiman, J. H. Friedman, and R. A. Olshen, Classiﬁcation and

Regression Trees. CA: Wadsworth International Group, 1984.

[7] M. G. Bobra, X. Sun, J. T. Hoeksema, M. Turmon, Y. Liu, K. Hayashi,
G. Barnes, and K. D. Leka, “The Helioseismic and Magnetic Imager
(HMI) vector magnetic ﬁeld pipeline: SHARPs - Space-weather HMI
Active Region Patches,” Solar Physics, vol. 289, pp. 3549–3578, 2014.
[8] F. Rosenblatt, The Perceptron: A Theory of Statistical Separability in
Cognitive Systems. Cornell Aeronautical Laboratory, Inc., Rep. No.
VG-1196-G-1. U.S., 1958.

[9] P. J. Braspenning, F. Thuijsman, and A. J. M. M. Weijters, Eds., Artiﬁcial
Neural Networks: An Introduction to ANN Theory and Practice, Lecture
Notes in Computer Science, vol. 931. Springer, 1995.

[10] G. Huang and L. Chen, “Convex incremental extreme learning machine,”

Neurocomputing, vol. 70, no. 16-18, pp. 3056–3062, 2007.

[11] G.-B. Huang and L. Chen, “Enhanced random search based incremental
extreme learning machine,” Neurocomputing, vol. 71, no. 16-18, pp.
3460–3468, 2008.

[12] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion,
O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vander-
plas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duch-
esnay, “Scikit-learn: Machine learning in Python,” Journal of Machine
Learning Research, vol. 12, pp. 2825–2830, 2011.

[13] H. Liu, C. Liu, J. T. L. Wang, and H. Wang, “Predicting solar ﬂares
using a long short-term memory network,” The Astrophysical Journal,
vol. 877, p. 121, 2019.

[14] P. T. Gallagher, Y.-J. Moon, and H. Wang, “Active-region monitoring
and ﬂare forecasting - I. Data processing and ﬁrst results,” Solar Physics,
vol. 209, pp. 171–183, 2002.

[15] H. Song, C. Tan, J. Jing, H. Wang, V. Yurchyshyn, and V. Abramenko,
“Statistical assessment of photospheric magnetic features in imminent
solar ﬂare predictions,” Solar Physics, vol. 254, pp. 101–125, 2009.

