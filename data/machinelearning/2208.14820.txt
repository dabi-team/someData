2
2
0
2

g
u
A
1
3

]
I

A
.
s
c
[

1
v
0
2
8
4
1
.
8
0
2
2
:
v
i
X
r
a

Learning Automata-Based Complex Event Patterns in
Answer Set Programming

Nikos Katzouris and Georgios Paliouras

Institute of Informatics & Telecommunications, National Center for Scientiﬁc Research (NCSR)
“Demokritos”, Athens, Greece
{nkatz,gpaliourg}@iit.demokritos.gr,

Abstract. Complex Event Recognition and Forecasting (CER/F) techniques at-
tempt to detect, or even forecast ahead of time, event occurrences in streaming
input using predeﬁned event patterns. Such patterns are not always known in ad-
vance, or they frequently change over time, making machine learning techniques,
capable of extracting such patterns from data, highly desirable in CER/F. Since
many CER/F systems use symbolic automata to represent such patterns, we pro-
pose a family of such automata where the transition-enabling conditions are de-
ﬁned by Answer Set Programming (ASP) rules, and which, thanks to the strong
connections of ASP to symbolic learning, are directly learnable from data. We
present such a learning approach in ASP and an incremental version thereof that
trades optimality for efﬁciency and is capable to scale to large datasets. We evalu-
ate our approach on two CER datasets and compare it to state-of-the-art automata
learning techniques, demonstrating empirically a superior performance, both in
terms of predictive accuracy and scalability.

Keywords: Automata Learning · Answer Set Programming · Complex Event
Recognition

1

Introduction

Complex Event Recognition and forecasting (CER/F) systems [8,17,2] detect, or even
forecast ahead of time, occurrences of complex events (CEs) in multivariate streaming
input, deﬁned as temporal combinations of simple events, e.g. sensor data. CE patterns
are typically deﬁned by domain experts in some event speciﬁcation language. However,
such patterns are not always known in advance, or they frequently need to be revised,
as the characteristics of the input data change over time, making machine learning tech-
niques capable of learning such patterns from data highly desirable in CER/F.

Despite the great diversity of existing event speciﬁcation languages, a minimal set
of basic constructs/operators that should be present in every such language have been
identiﬁed [36,3,17,19], in the form of an abstract event algebra. The most important
of these operators are the sequence operator and the closely related iteration opera-
tor (Kleene Closure), implying respectively that some particular events should succeed
one another temporally, or that an event should occur iteratively in a sequence, and the
selection operator, which ﬁlters (selects) events that satisfy a set of predeﬁned predi-
cates. Taken together, these three operators already point to a computational model for

 
 
 
 
 
 
2

Katzouris & Paliouras

CER/F based on symbolic automata [9], and indeed, in most existing CER/F systems
CE patterns are either deﬁned directly as symbolic automata, or are compiled into such
at runtime [35,1,36,12,10,11,30,29,7,2]. In symbolic automata the transition-enabling
conditions are predicates, rather than mere symbols, as in classical automata. In CER/F,
the structure of such an automaton pattern corresponds to the conditions speciﬁed by
the sequence/iteration operators in the CE pattern and their transition guards correspond
to the pattern’s selection predicates.

Learning such symbolic automata-based CE patterns is a challenging task that re-
quires to combine automata structure identiﬁcation techniques with reasoning about
the satisﬁability of the selection predicates. To address this issue we propose a family
of symbolic automata, which we call answer set automata (ASA), where the transition
guards are deﬁned by means of rules in Answer Set Programming (ASP), providing
deﬁnitions for the selection predicates. Importantly, thanks to the strong connections
of ASP with symbolic learning, ASA-based CE patterns are directly learnable from
data. We present an approach that utilizes the power of ASP in declarative learning to
automatically construct such patterns from data and we lift this approach to an incre-
mental version that trades optimality for efﬁciency and allows our learning framework
to scale to large datasets. We evaluate our approach on two CER datasets and compare
it to state-of-the-art automata learning techniques, demonstrating empirically a superior
performance, both in terms of predictive accuracy and scalability.

2 Related Work

Although the ﬁeld of automata learning [20,34] has a long history in the literature
[18,4,28,21,33,5,16,32,15], existing techniques that induce automata from positive &
negative traces have several shortcomings, which limit their applicability in the CER/F
domain. Most such algorithms either attempt to learn a model that perfectly discrimi-
nates between the positive/negative traces [18,4,16,5,15], or they use greedy techniques
for state merging [28,21], a technique that generalizes from a large, tree-like automa-
ton (the Preﬁx Tree Acceptor – PTA), generated from the entire training set. These
approaches tend to learn large, overﬁtted models that generalize poorly. More recent
techniques [31] replace the PTA generalization heuristics with exact, constraint-based
automata identiﬁcation methods, achieving higher generalization capacity. However,
the issue remains that such techniques still need to encode the entire training set into a
PTA, raising memory/scalability issues in large datasets.

All aforementioned algorithms learn classical automata. Although some of these al-
gorithms could, in principle, be applied to the symbolic automata learning setting, e.g.
via propositionalization, that would entail an explosion in alphabet size and the combi-
natorial complexity of the learning task. On the other hand, although some algorithms
for symbolic automata induction do exist [13,26,6,14], they are mostly based on “up-
grading” existing classical automata identiﬁcation techniques to richer alphabets, and
they thus suffer from the limitations outlined above, i.e. poor generalization, intolerance
to noise and limited scalability.

Learning automata and grammars has been an application domain for ILP since its
early days, targeting mostly classical automata expressed as deﬁnite clause grammars.

Learning Automata-Based Complex Event Patterns in Answer Set Programming

3

More recent ILP frameworks, such as meta-interpretative learning (MIL) and learning
from answer sets (ILASP), have also been applied to the task [27,15]. However, both
these approaches learn models that perfectly discriminate between positive and nega-
tive examples, therefore, they cannot deal with noise in the data. Moreover, the MIL
approach of [27] learns classical automata, and although the ILASP-based approach of
[15] does learn a form of symbolic automata, the transition guards therein are restricted
to propositional clauses generated from combinations of the alphabet symbols, which
falls short of the CER/F requirement for arbitrary selection predicates.

In contrast to the above-mentioned approaches, our symbolic automata learning
framework utilizes the full expressive power of ASP in the deﬁnitions of transition
guards and ASP’s declarative learning capabilities to learn highly compressive models
that generalize adequately. Moreover, its incremental learning version is able to scale to
arbitrarily large datasets.

3 ASP Background

} ←

α
{

We assume some familiarity with ASP and refer to [23] for an in-depth account. In
this section we review some basic ASP constructs that will be useful in what follows.
Throughout, we use the Clingo1 syntax for representing ASP expressions. A choice rule
is an expression of the form
δ1, . . . , δn, with the intuitive meaning that when-
ever the body δ1, . . . , δn is satisﬁed by an answer set I of a program that includes the
choice rule, instances of the head α are arbitrarily included in I (satisﬁed) as well.
A weak constraint is an expression of the form :~ δ1, . . . , δn.[w@p, t1, . . . , tk], where
δi’s are literals, called the body of the constraint, w and p are integers, called respec-
tively the weight and the priority level of the constraint and t1, . . . , tk are ASP terms.
A grounding/instance of a weak constraint c is an expression that results from c by re-
placing all variables in δ1, . . . , δn, t1, . . . , tk by constants. Such an instance is satisﬁed
by an answer set IΠ of a program Π that includes c if IΠ satisﬁes c’s ground body,
which incurs a penalty of w on IΠ . IΠ ’s total cost is the sum of penalties resulting from
each instance of c that is satisﬁed by IΠ . Inclusion of weak constraints in an ASP pro-
gram triggers an optimization process that yields answer sets of minimum cost. Priority
levels in weak constraints model the constraints’ relative importance, since the afore-
mentioned optimization process attempts to ﬁrst minimize the total cost due to weak
constraints of higher priority levels.

4 The Problem Setting and a Running Example

We next set the scene for our proposed automata-based CE pattern learning framework.
CER/F applications usually deal with multivariate input, i.e., input that arrives in multi-
ple streams, each representing a “signal” obtained by the evolution of a relevant domain
attribute in time. We illustrate the case using a running example from the domain of pre-
cision medicine, as formulated in the context of the INFORE EU-funded project2.

1 https://potassco.org/
2 https://www.infore-project.eu/

4

Katzouris & Paliouras

Fig. 1: A multi-cellular simulation of tumor evolution from the INFORE project.

Example 1 (Running Example). INFORE’s precision medicine use-case utilizes CER/F
techniques to assist the knowledge discovery process in personalized cancer treatment
development. This process involves running a vast amount of complex, multi-cellular
simulations to study the effects of various drug synergies on tumor growth. Such simu-
lations are extremely demanding computationally and their majority ends-up in a nega-
tive result, signifying that a particular drug combination is not effective. Using CER/F to
detect/forecast non-promising simulations at an early stage may thus speed up research
by allowing to terminate non-interesting simulations early-on and allocate resources
towards the exploration of more promising drug combinations. This calls for learn-
ing patterns of interesting/non-interesting outcomes from labeled, historical simulation
data. Notably, the interpretability of such patterns is crucial in this domain.Therefore,
mainstream black-box time-series classiﬁcation methods, including deep learning tech-
niques, are not an option. Figure 1 presents such a simulation generated by PhysiBoss
[22], a bio-informatics simulation environment that allows to explore the results of sev-
eral environmental and genetic alterations to populations of cells. Figure 1 presents
tumor growth evolution over time, in terms of population sizes of three types of cell:
the tumor’s alive cells, its apoptotic cells, i.e. cells that are “programmed” to die, due
to apoptosis, and the tumor’s necrotic cells, i.e. cells that die due to the effects of an
injected Tumor Necrosis Factor (TNF), i.e. a drug combination.

Multivariate time-series, such as the simulation data from Figure 1, may be converted
into symbolic multivariate sequences (MVSs), e.g. by using the Symbolic Aggregate
Approximation (SAX) algorithm [24,25]. SAX converts time-series into symbolic se-
quences, by mapping numerical values to symbols, drawn from a ﬁxed-length alphabet,
such that each symbol in the converted sequence corresponds to a bin (value range) in
the original time-series.

In the event pattern learning setting that we put forward we assume that the train-
ing data consist of labeled, symbolic MVSs, each representing a training example. For
instance, the symbolic MVS obtained by discretizing the simulation data in Figure 1,
along with a label (e.g. interesting/non-interesting simulation) represents such a training
example. In what follows, by MVS we always mean a symbolic MVS.

Learning Automata-Based Complex Event Patterns in Answer Set Programming

5

(a) A toy training set consisting of two MVSs.
Positive example (id1):
eeeedcbbbb
Alive cells:
Necrotic cells: aabbbcccde
Apoptotic cells: bbbcdghhhh

Negative example (id2):
eecdbbbbbb
Alive cells:
Necrotic cells: aabbbbcccc
Apoptotic cells: bbbcfghhhh

(b) The logical representation of MVS id1:
I id1
1 = {obs(id1, av(alive, e), 1). obs(id1, av(necrotic, a), 1). obs(id1, av(apoptotic, b), 1).}
I id1
2 = {obs(id1, av(alive, e), 2). obs(id1, av(necrotic, a), 2). obs(id1, av(apoptotic, b), 2).}
I id1
3 = {obs(id1, av(alive, e), 3). obs(id1, av(necrotic, b), 3). obs(id1, av(apoptotic, b), 3).}
. . .
I id1
10 = {obs(id1, av(alive, b), 10). obs(id1, av(necrotic, e), 10). obs(id1, av(apoptotic, h), 10).}

Table 1: Multivariate, discrete sequences and their logical representation.

Given an MVS S of maximum length n (i.e. the length of the largest sequence in S)
we use a logical representation of S as a sequence of interpretations I1, . . . , In, where
each It consists of ground facts that describe S’s t-th coordinate. In particular, we as-
sume that each sequence in S corresponds to a domain attribute and consists of symbols
from a ﬁxed alphabet Σ that represent the values of this attribute over time. Then, the
interpretation It that corresponds to S’s t-th coordinate consists of observation facts
of the form obs(SeqId, av(A, V ), T ), meaning that the attribute A of the MVS with
unique id SeqId has value V at time T .

Example 2 (Labeled MVS). Table 1 (a) presents a minimal, toy training set with a sin-
gle positive and a single negative example. Each example is an MVS consisting of three
length-ten sequences regarding the evolution of cell populations for the different types
of cell in our running example (Example 1). These sequences are short excerpts of
longer simulation sequences, which have been discretized using SAX. Each symbol in
a sequence corresponds to a bin of real values.Table 1 (b) presents the logical represen-
tation of the positive example (MVS id1) as a sequence of interpretations I id
1 , . . . , I id
10.

5 Answer Set Automata

We next deﬁne a family of symbolic automata that may be used to express CE patterns
over MVSs. The transition guard predicates, which we shall call transition features and
correspond to selection predicates in a CER/F context, will be deﬁned by ASP rules,
we therefore call the resulting automata answer set automata (ASA). Intuitively, a tran-
sition in an ASA is enabled when the body of the corresponding transition feature rule
is satisﬁed by the input MVS. Note that ASA will be non-deterministic in principle.
This is because to enforce determinism in the case of symbolic automata it must be en-
sured that the conditions that guard all outgoing transitions from some state q to a set of
different states must be mutually exclusive. This is infeasible to guarantee in the ASA
framework, since the transition features may encode arbitrary, domain-speciﬁc condi-
tions that are deemed informative to synthesize automata with. The non-determinism

6

Katzouris & Paliouras

of the ASA framework is in accordance with most event speciﬁcation languages in the
CER domain, where complex event patterns are deﬁned as, or are eventually compiled
into non-deterministic automata.

=

Σ, B, R, Q, q0, F, δ
(cid:104)

Deﬁnition 1 (Answer Set Automaton – ASA). An answer set automaton is a tuple
, where: Σ is the alphabet, represented by a set of ASP facts;
(cid:105)
A
B is some background knowledge represented by an ASP program; R is a set of ASP
rules, called the transition features; Q is a ﬁnite set of states; q0 ∈
Q is a designated
Q is a designated set of accepting states; δ is a non-deterministic
start state and F
state transition function deﬁned by means of a feature mapping δR : Q
Q,
where δR(q, r) = q(cid:48) has the intuitive meaning that the transition from state q to q(cid:48) is
guarded by the transition feature r. Given a feature mapping δR, the transition function
δ : Q

is deﬁned as:

2Q

2Σ

→

×

⊆

R

×

→

∪ {⊥}

δ(q, I) =

(cid:26) Aq =
(cid:3)

δR(q, r)
{
q
∈ {{

{⊥}}

}

,

I
Q
∈
|
, else.

B (cid:15) body(r)
, if Aq
}

∪

=

,
∅

(1)

∪

The “alphabet” Σ in Deﬁnition 1 is deﬁned as the set of ground facts that encode the
simple events in the input, i.e., facts of the form obs(alive, a), as per our running exam-
ple. The transition function δ operates on interpretations, i.e. subsets of Σ, as indicated
by the powerset 2Σ in δ’s signature. Then, given a state q and an interpretation I, the
“if” branch of δ in Eq. (1) maps q to its set of “next states” Aq. Each q(cid:48)
Aq is ob-
tained by the feature mapping δR, therefore, it is of the form q(cid:48) = δR(q, r) and has the
property that I

B satisﬁes the body of the corresponding transition feature r.

∈

If the set of next states is empty (i.e., if no transition feature associated with q is
satisﬁed by I), the “else” branch encodes the different operational semantics that may
be deﬁned to govern the automaton’s behavior in this case. Typical options for such
, or to
semantics is either to self-loop on the current state, in which case δ(q, I) =
q
}
{
reject the input, by moving to an absorbing, “dead” state, which we denote by
. These
⊥
semantics correspond to two different event consumption policies in CER/F, which are
called skip-till-any-match and strict contiguity respectively [17].
The logical representation of an ASA consists of a set of facts of the form
transition(s1, f, s2), meaning that the transition from state s1 to s2 is guarded by condi-
tion f . Figure 2 presents an example of this representation, which is explained in more
detail in Example 3 below. Additionally, the accepting states in the ASA are speciﬁed
via atoms of the form accepting(s).
Reasoning with ASA is performed via an interpreter that deﬁnes the desired ASA be-
havior. Such an interpreter is presented in Figure 2 as part of the background knowledge
B (also to be discussed in Example 3). The ﬁrst rule in the interpreter states that for any
example (input MVS) SeqId an ASA is initially (at time 1) in state q0, i.e. q0 is the
start state. The second rule states that an ASA moves from state S1 to state S2 at time
T , if there is a transition whose feature is satisﬁed by the current example (SeqId) at
time T . This is the meaning of the satisﬁes/3 atom that appears in that rule. Finally,
the third rule in the interpreter deﬁnes the accepting condition for the MVS SeqId, by
demanding the ASA to be in an accepting state at the end of the MVS. Rejection of an
input MVS is deﬁned implicitly via closed-world assumption. Note that this interpreter
implements the strict contiguity operational semantics, i.e. it rejects the input at time T

(cid:54)
Learning Automata-Based Complex Event Patterns in Answer Set Programming

7

Fig. 2: An ASA that discriminates between the positive and negative MVSs of Figure 1.

←

if the set of next states Aq at T is empty. The skip-till-any match semantics may also
be supported by adding to the interpreter an extra rule that allows to self-loop when
Aq =

, e.g. by using count aggregates in ASP:
∅

inState(Id, S, T + 1)

F : satisﬁes(Id, F, T )
}
{

= 0.
inState(Id, S, T ), #count
Transition Features. In this work the transition features are assumed to be deﬁned
beforehand (learning them, along with the corresponding ASA is a direction of future
work) and are assumed to encode simple relations over attributes and values. Given that
the goal is to check if the transition features are satisﬁed or not by the coordinates of an
input MVS, we deﬁne them via the predicate satisﬁes/3 that is used by the interpreter.
The bodies of such satisﬁes/3 rules consist of the conditions that should be satisﬁed in
order for a transition to be triggered. These conditions are deﬁned by means of attribute-
value observation atoms (i.e., obs/3 atoms, as in Table 1) and comparison predicates
that encode relations between such atoms.

Example 3 (Answer set automata & transition features). Figure 2 presents an ASA, its
logical representation and its transition features R, along with some background knowl-
edge B necessary to reason with the ASA. B consists of the ASA interpreter and the
speciﬁcation of attribute-value domain constants. We ﬁrst discuss the transition features
R before going into the details of the ASA and its functionality. The ﬁrst rule in R spec-
iﬁes the conditions under which an MVS SeqId satisﬁes, at time T , a predicate with
signature neg(A, V ), stating that at time T in SeqId (i.e., in SeqId’s T -th coordinate),
the attribute A does not have the value V . The next rule deﬁnes a predicate lt(A1, A2)
stating that at time T the value of attribute A1 is less than (hence, lt) the value of at-

q0startq1neg(alive,b)lt(alive,necrotic)atLeast(necrotic,c)Logicalrepresentation:transition(q0,neg(alive,b),q0).transition(q0,lt(alive,necrotic),q1).transition(q0,lt(alive,necrotic),q1).accepting(q1)BackgroundKnowledgeB:ASAInterpreter:inState(SeqId,q0,1)←example(Id).inState(SeqId,S2,T+1)←inState(ExmplId,S1,T),transition(S1,F,S2),satisﬁes(SeqId,F,T).accepted(SeqId)←inState(SeqId,S,T),accepting(S),seqEnd(SeqId,T).Domain-speciﬁcbackgroundknowledge:att(alive;necrotic;apoptotic).val(a;b;c;d;e;f;g).TransitionFeaturesR:satisﬁes(SeqId,neg(A,V),T)←obs(SeqId,av(A,V1),T),V6=V1,att(A),val(V).satisﬁes(SeqId,lt(A1,A2),T)←obs(SeqId,av(A1,V1),T),obs(Id,av(A2,V2),T),V1<V2.satisﬁes(SeqId,atLeast(A,V),T)←obs(SeqId,av(A,V1),T),val(V1),V<=V1.8

Katzouris & Paliouras

tribute A2. Finally, the third rule in R deﬁnes atLeast(A, V ) stating that at time T the
value of attribute A is at least V .

Given these deﬁnitions, and based on the instances of the transition features that
guard the edges of the ASA in Figure 2, the behavior of the ASA is the following: It
self-loops on q0 for as long as the size of the alive cells population in the input – recall
our running example – is not b; it transitions to the accepting state q1 if an observation
comes in, where the size of the alive cells population is smaller than that of the necrotic
– an indication that a drug is promising; and it expects the necrotic cells population size
to exceed a threshold (c) from that point on, by self-looping on the accepting state.

The ASA in Figure 2 accepts the positive (id1) and rejects the negative example
(id2) in Table 1. To see the former note the ASA self-loops on q0 until time T = 7, when
the value of alive = b, causing B
to no longer satisfy the self-loop condition
on q0. However, at the same time point necrotic = c, which exceeds the value of alive
(recall that the symbols in the running example represent bins of values and they are
ordered by the lexicographic ordering, i.e. letters later in the alphabet represent bins of
(cid:15) lt(alive, necrotic), causing the ASA to transition
larger values). Therefore, B
to the accepting state q1. The values of necrotic in the remaining time steps are at least
c, thus the ASA self-loops on the accepting state for the rest of the input.

I id1
7

I id1
7

∪

∪

To see that the ASA rejects id2 note that at time T = 5 in id2 alive = b, causing the
condition that allows to self-loop on q0 up to that point to fail. Moreover, the condition
that allows to transition from q0 to q1 is also not satisﬁed, since necrotic = b. There-
fore, since the interpreter implements the strict contiguity semantics, the ASA is in no
state at time T = 6 (i.e. it implicitly moves to the dead state) and the input is rejected.

6 Learning Answer Set Automata

We now turn to our approach to Answer Set Automata Learning (ASAL) in ASP. Our
learning objective may be formulated as follows: Given a training set consisting of pos-
itive and negative MVSs S+ and S−, a set of transition features R, a “state budget” N
and potentially, a set of structural and regularization constraints SC and RC respec-
that uses the transition features in R, respects SC, optimizes
tively, learn an ASA
RC, does not
training error, deﬁned as:
(cid:80)
, s), i.e. the number of misclassiﬁed train-
s∈S+ rejects(

A
exceed N and minimizes
, s) + (cid:80)
s∈S− accepts(

the

ing examples.

A

A

Structural constraints may include e.g. requirements for accepting states being ab-
sorbing ones, starting states not being accepting states etc. Regularization constraints
are typically related to learning simpler models, where simplicity in our case is mea-
sured by the total number of states and transitions in an automaton. Several other sim-
plicity criteria may be considered. For instance, an earliness bias would favor automata
that accept/reject their input as early as possible, the intuition being that initial segments
of the input are often enough to learn a good model, while trying to ﬁt the entire input
could yield more complicated automata with inferior generalization capacity.

We cast the automata learning problem as an abductive reasoning task in ASP. In
its simplest form, such a task may be deﬁned as a tuple
, where Π is a
(cid:105)
logic program that represents some background knowledge, IC is a set of constraints

Π, IC, G, A
(cid:104)

Learning Automata-Based Complex Event Patterns in Answer Set Programming

9

Generate ASA:
{transition(S1, F, S2)} ← state(S1), state(S2), feature(F ).
feature(φ) ← type1(var1
{states(S)} ← maxStates(S).
{accepting(S)} ← state(S).
maxStates(1..qN ). start(1).

φ), . . . , typen(varn

φ ).

Minimize the training error:
:~ accepted(SeqId), negative(SeqId). [wf p@2, SeqId]
:~ not accepted(SeqId), positive(SeqId). [wf n@2, SeqId]

Example of regularization constraints:
:~ transition(S1, X, S2). [1@1, S1, S2, X]
:~ accepted(SeqId, T ). [T @1, SeqId, T ]
accepted(SeqId, T ) ← inState(SeqId, S, T ), accepting(S).
accepted(SeqId) ← accepted(SeqId, _).

Example of structural constraints:
← transition(S,, S2), accepting, S2 (cid:54)= S.

Table 2: Abductive ASA learning in ASP.

∪

∪

that must be respected, G is a set of ground constraints, often called “goals” and A is a
set of predicate signatures called abducibles. A solution to an abductive reasoning task
is a set of ground logical facts ∆, such that B

∆ (cid:15) G.

IC

In our case, the background knowledge program Π contains the ASA interpreter,
S− in logical
the deﬁnitions of the transition features R and the training MVSs S+
form; IC are the structural and regularization constraints, G is a set of ground con-
straints related to the acceptance/rejection of each MVS in S+, S− respectively and
A =

∪

.

transition/3, accepting/1
}
{

The abductive task is straightforward to specify and solve in ASP, via its generate-
and-test methodology, according to which we generate automata via choice rules and
test their performance via (weak) constraints. Table 2 presents an example formulation.
The choice rules in the ﬁrst block of rule generate ASA as collections of transition/3
and accepting/3 facts (as in Figure 2). The feature/1 rule is just a “type rule” added
for each transition feature r
R. For instance, for the transition feature lt(A, V ) from
∈
Figure 1, the corresponding type rule is feature(lt(A, V ))

att(A), val(V ).

The next block of rules is a set of weak constraints that minimize the training error.
Note that the accepted/1 predicate is deﬁned in the ASA interpreter in Figure 2 and the
positive/1 and negative/1 predicates are facts that carry the label of each training MVS.
The constraints may be weighted differently, accounting e.g. for imbalances between
positive/negative examples in the training set. The weights are wfp for the ﬁrst rule,
which is the price paid for each false positive, and wfn for the second rule, the price
paid for each false negative. These constraints have a higher priority, relative to the
ones that follow in Table 2, making training error minimization the primary objective.

←

10

Katzouris & Paliouras

The next block of rules presents an example of regularization biases in the form of
weak constraints. The ﬁrst constraint attempts to compress the generated automata as
much as possible, by penalizing transition/3 facts. The second rule attempts to maxi-
mize earliness by minimizing the length of the preﬁxes that an ASA needs to process
before accepting3. The accepted/2 predicate that is used in the earliness constraint sim-
ply monitors the number of steps needed to reach an accepting state, while the next rule
deﬁnes acceptance in terms of such “partial” acceptance. To use the earliness bias con-
straint in ASAL these two rules should replace the third rule in the ASA interpreter in
Figure 2, while accepting states should be treated as absorbing. This essentially forces
ASAL to learn an automaton that accepts from preﬁxes of the input, whose length is to be
minimized by the earliness constraint. The last rule in Table 2 is a structural constraint
ensuring that accepting states are absorbing.

Example 4 (ASAL in Action). Let Π be the program consisting of the rules in Table 2,
B and R from Figure 2 and the logical representation of the two training examples in
Table 1, as the union of the I id1
’s, along with the facts positive(id1) and
t
negative(id2). Running Clingo on Π and ﬁltering the transition/3 and the accepting/1
facts from the generated solutions yields the learnt ASA. One of these ASA is the one
illustrated in Figure 2, which is suboptimal, based on the constraints in Table 2. It can
be seen that optimal ASA consist of two states and two transitions. e.g. the ASA

’s and the I id2

t

transition(q0, at_least(alive, e), q0). transition(q0, at_least(apoptotic, d), q1).
accepting(q1).

In addition to being smaller, it can be seen that this ASA accepts the positive example
id1 at step 6, in contrast to the ASA in Figure 2, which accepts at step 8. If we drop the
earliness constraint in Table 2 we may obtain a single-state ASA:

transition(q0, neg(apoptotic, f), q0).
accepting(q0).

Although this ASA correctly classiﬁes the examples, it is degenerate and has an uncon-
ventional behavior, always starting from an accepting state and failing later on to reject
the negative examples (e.g. it moves to the implicit dead state at step 5 to reject id2).

6.1

Incremental Learning & Automata Revision

ASAL is guaranteed to ﬁnd an optimal, constraint-compliant solution to the abductive
ASA learning task, given enough time and memory. The main drawback, however, is
that the requirements for such resources grow exponentially with the complexity of the
learning task (e.g. alphabet size, number of transition features etc.) and the size of the
input (e.g. number and length of the training examples), making the approach infeasible
for larger datasets. To alleviate this issue we give-up the requirement for optimal ASA
and opt for an incremental learning strategy that simply learns ASA with a good ﬁt
in the training data. Additional strategies for improving ASAL’s scalability, such as
incorporating symmetry-breaking constraints, in order to ignore isomorphic ASA, are
future work directions.

3 Maximizing earliness for input rejection, in addition to acceptance, would also be possible by
modifying the ASA interpreter to not handle rejection via the closed-world assumption, but
via explicit, absorbing dead states, and adding appropriate regularization constraints.

Learning Automata-Based Complex Event Patterns in Answer Set Programming

11

ASAL’s incremental learning version operates on mini-batches of the training data,
sufﬁciently small to allow for fast ASA induction from each batch and, ideally, sufﬁ-
ciently large and diverse to allow for learning relatively good ASA from samples of
the training set. This is paired with an ASA revision technique, which tries to apply
minimal structural modiﬁcations on existing automata, to improve their performance
on new mini-batches. The algorithm – we omit the pseudocode due to space limita-
tions – is a greedy, iterative hill-climbing search that works as follows: At each point
is maintained. At each mini-batch D, if
in time, an initially empty, best-so-far ASA
is
A
revised by running Clingo on a program Π similar to the one described in Example 4,
augmented as follows: For each transition(qi, φi, qj) and each accepting(qi) fact in the
logical speciﬁcation of

’s local classiﬁcation performance on D is lower than a given error threshold,

we add to Π the following:

A

A

A

existing(transition(qi, φi, qj)).
existing(accepting(qi)).
:~ not transition(qi, φi, qj), existing(transition(qi, φi, qj)). [
:~ not accepting(qi), existing(accepting(qi)). [1@1]

wi@1]

−

The ﬁrst two facts simply state which facts already exist in the structural description of
, while the weak constraints penalize their removal, thus fostering minimal revisions.
A
The weight wi in the ﬁrst weak constraint is deﬁned as wi = n
p, where n, p are
respectively the number of negative/positive examples throughout the entire training
set, which are accepted by
and the acceptance paths use the corresponding transition
feature φi. Note the “-” sign in front of wi, which makes wi positive (i.e., a penalty in
the optimization process) if n > p and negative (i.e. a reward) in the opposite case.

A

−

An ASP solver runs on the augmented program Π for a given time t, and the k
best solutions found in that time are preserved, where the time-out t and k are run-
time parameters. Subsequently, these k locally best solutions are evaluated on the entire
training set (updating the aforementioned p, n counts for each transition/3 fact in these
(cid:48) is found after this process has a better global performance than
ASA). If an ASA
A
as the new best ASA. The process is repeated for a given number
, it replaces
A
of iterations, by shufﬂing and re-partitioning the training set into new mini-batches at
the beginning of each iteration. The current best ASA that results from this process is
returned in the output.

A

7 Experimental evaluation

We empirically assess ASAL on two CER datasets from the domains of precision medicine
and maritime monitoring. The former has already been outlined in Section 3. It consists
of 644 time series, each containing three signals related to the alive, necrotic and apop-
totic attributes, of length 49 each. The positive class (interesting simulations) amounts
to the 20% of the data. In addition to this dataset, to which we refer as Bio-small, in
order to test the scalability of the incremental version of ASAL, we also used a signiﬁ-
cantly larger dataset with the same characteristics, but with 50K training simulations.

The maritime dataset contains data from nine vessels that cruised around the port
of Brest, France. There are ﬁve attribute signals for longitude, latitude, speed, heading,

12

Katzouris & Paliouras

Method

F1-score

#States

#Transitions

Time (min)

Bio Small-U

RPNI

EDSM

DISC
ASALbatch
classic
ASALincr

classic

Bio Large-U ASALincr

classic

Bio Small ASALbatch
classic
ASALincr
classic
ASALbatch
symb
ASALincr
symb

Bio Large ASALincr
ASALincr
symb

classic

Maritime ASALincr
ASALincr
symb

classic

0.702

0.722

0.833

0.887

0.882

0.858

0.902

0.889

0.968

0.924

0.852

0.942

0.892

0.952

13

12

10

3

3

3

3

3

3

3

3

3

3

3

Table 3: Experimental results

292

278

13

35

41

57

53

60

5

7

12

8

15

8

0.05

0.05

51

1 (time-out)

0.566

13

5 (time-out)

2.7

5 (time-out)

3.4

25

39

6

18

and course over ground. The positive class is related to whether a vessel eventually en-
ters the port of Brest and there are 2,980 negative and 2,269 positive examples, a total
of 5,249 multivariate examples, each of length 30. The maritime dataset has been pre-
viously used in CER research, we therefore refer to [2] for more details. Both datasets
were discretized using SAX with ten bins.

symb and ASALincr

classic and ASALincr

We compared the following algorithms: (a) ASALbatch

classic, the batch
and incremental version of ASAL that learns ASA that resemble classical automata, by
using no transition feature other that equality, i.e. an attribute having a particular value
found in the data. This is similar to using a symbol for each attribute-value. This version
of ASAL was evaluated to assess the merits of using relational transition features; (b)
ASALbatch
symb, the batch and incremental versions respectively of ASAL,
as described in the previous sections. These were used with ﬁve predeﬁned transition
features, similar to those presented in Figure 2; (c) RPNI [28] and an improved version
thereof, EDSM [21], two widely used algorithms of the state-merging (SM) family,
that compress a PTA (see Section 3) using greedy heuristics. Note that although these
algorithms are quite old, the main ideas behind them are the SoA in SM-style learning
and their LearrnLib4 implementation used in the experiments is extremely efﬁcient and
frequently used by practitioners; (d) DISC [31], a recent algorithm that translates the
PTA compression problem into a Mixed Integer Linear Programming problem, which
it delegates to the off-the-shelf Gurobi solver. DISC is similar to ASAL in the sense that
it is able to learn optimal automata, given enough time and memory.

4 https://learnlib.de/

Learning Automata-Based Complex Event Patterns in Answer Set Programming

13

The experimental setting was a ﬁve-fold cross validation with 80/20 training/testing
set splits. The experiments were carried-out on a 3.6GHz processor (4 cores, 8 threads)
and 16GB of RAM. Whenever ASALbatch
classic was used it was given a timeout (maximum
allowed time), in order to obtain a solution in a feasible amount of time.

The results are presented in Table 3 in the form of average testing set F1-scores,
number of states and transitions, as well as training times for the algorithms compared.
Note that RPNI, EDSM and DISC deal with single strings and cannot handle multivariate
input. To compare to these algorithms we used a univariate version of the bio dataset,
which contains the alive attribute only, as it is informative enough to learn a useful
model. No such attribute has this property in the maritime dataset, we therefore did not
experiment with RPNI, EDSM and DISC on it. Moreover, only the “classic” version of
ASAL was used on the univarate bio dataset, since there are no cross-feature relations
that could be captured by transition features in the symbolic version.

The ﬁrst block in Table 3 concerns the small version of the univariate dataset. It can
be seen that RPNI and EDSM are lightning-fast, learning a model in approx. three secs.
On the other hand, they have signiﬁcantly inferior predictive performance as compared
to all other algorithms and they are signiﬁcantly more complicated, as indicated by their
size. DISC has a better F1-score and learns slightly simpler models, as indicated by its
states number (the reduced number of transitions for DISC is misleading, since DISC
omits self loops). On the other hand, it takes a little less than an hour on average to train.
ASALbatch
classic has the best predictive performance, achieved within 1 min. Its incremental
version closely follows in predictive performance in almost half the time.

In the large version of the univiariate bio dataset (second block in Table 3) ASALincr
classic
was the only usable algorithm, since RPNI, EDSM and DISC terminated with memory
errors, due to the size of the dataset. In contrast, thanks to its incremental learning strat-
egy that never loads the entirety of the training data into memory, ASAL was able to
learn a good model in approx. 13 minutes.

The results from the small version of the full bio dataset (containing all the features)
in the next block in Table 3), highlight the advantages of learning symbolic automata.
Indeed, both the batch and the incremental version of ASAL achieve signiﬁcantly better
results than the classical version of ASAL and learn automata with much fewer tran-
sitions. Note that the F1-scores of the two versions of the batch ASAL version were
achieved with the same time-out value and the incremental versions of ASAL have com-
parative training times. Therefore, the symbolic version learns better models without
signiﬁcantly compromising efﬁciency. The results from the large bio dataset (full, all
features used) and the maritime dataset also seem to conﬁrm this claim.

8 Conclusions and Future Work

We presented a methodology for learning symbolic automata where the transition guards
are deﬁned via ASP rules, and evaluated our approach on two CER datasets, demon-
strating its efﬁcacy. There are several directions for future work, including a more thor-
ough experimental assessement on more datasets and settings, a formal characterization
of the expressive power of ASA in relation to common event algebras used in CER,

14

Katzouris & Paliouras

scalability improvements, e.g. via symmetry breaking, and jointly learning the transi-
tion features deﬁnitions, along with the automaton.

Acknowledgements

This work is supported by the project entitled “ARIADNE - AI Aided D-band Net-
work for 5G Long Term Evolution”, which has received funding from the European
Union’s Horizon 2020 research & innovation programme under grant agreement No
871464, and by the project entitled “INFORE: Interactive Extreme-Scale Analytics and
Forecasting”, which has received funding from the European Union’s Horizon 2020
research & innovation programme under grant agreement No 825070.

References

1. Agrawal, J., Diao, Y., Gyllstrom, D., Immerman, N.: Efﬁcient pattern matching over event
streams. In: Proceedings of the 2008 ACM SIGMOD international conference on Manage-
ment of data. pp. 147–160 (2008)

2. Alevizos, E., Artikis, A., Paliouras, G.: Complex event forecasting with prediction sufﬁx

trees. The VLDB Journal 31(1), 157–180 (2022)

3. Alevizos, E., Skarlatidis, A., Artikis, A., Paliouras, G.: Probabilistic complex event recogni-

tion: A survey. ACM Computing Surveys (CSUR) 50(5), 1–31 (2017)

4. Angluin, D.: Learning regular sets from queries and counterexamples. Information and com-

putation 75(2), 87–106 (1987)

5. Angluin, D., Eisenstat, S., Fisman, D.: Learning regular languages via alternating automata.

In: Twenty-Fourth International Joint Conference on Artiﬁcial Intelligence (2015)

6. Argyros, G., D’Antoni, L.: The learnability of symbolic automata. In: International Confer-

ence on Computer Aided Veriﬁcation. pp. 427–445. Springer (2018)

7. Cugola, G., Margara, A.: Tesla: a formally deﬁned event speciﬁcation language. In: Proceed-
ings of the Fourth ACM International Conference on Distributed Event-Based Systems. pp.
50–61 (2010)

8. Cugola, G., Margara, A.: Processing ﬂows of information: From data stream to complex

event processing. ACM Computing Surveys (CSUR) 44(3), 15 (2012)

9. D’Antoni, L., Veanes, M.: The power of symbolic automata and transducers. In: International

Conference on Computer Aided Veriﬁcation. pp. 47–67. Springer (2017)

10. Demers, A., Gehrke, J., Hong, M., Riedewald, M., White, W.: Towards expressive pub-
lish/subscribe systems. In: International Conference on Extending Database Technology. pp.
627–644. Springer (2006)

11. Demers, A.J., Gehrke, J., Panda, B., Riedewald, M., Sharma, V., White, W.M., et al.: Cayuga:

A general purpose event monitoring system. In: Cidr. vol. 7, pp. 412–422 (2007)

12. Diao, Y., Immerman, N., Gyllstrom, D.: Sase+: An agile language for kleene closure over

event streams. UMass Technical Report (2007)

13. Drews, S., D’Antoni, L.: Learning symbolic automata. In: International Conference on Tools
and Algorithms for the Construction and Analysis of Systems. pp. 173–189. Springer (2017)
Inferring symbolic automata. arXiv preprint

14. Fisman, D., Frenkel, H., Zilles, S.:

arXiv:2112.14252 (2021)

15. Furelos-Blanco, D., Law, M., Jonsson, A., Broda, K., Russo, A.: Induction and exploitation
of subgoal automata for reinforcement learning. Journal of Artiﬁcial Intelligence Research
70, 1031–1116 (2021)

Learning Automata-Based Complex Event Patterns in Answer Set Programming

15

16. Giantamidis, G., Tripakis, S., Basagiannis, S.: Learning moore machines from input–output
traces. International Journal on Software Tools for Technology Transfer 23(1), 1–29 (2021)
17. Giatrakos, N., Alevizos, E., Artikis, A., Deligiannakis, A., Garofalakis, M.N.: Complex event

recognition in the big data era: a survey. VLDB J. 29(1), 313–352 (2020)

18. Gold, E.M.: Language identiﬁcation in the limit. Information and control 10(5), 447–474

(1967)

19. Grez, A., Riveros, C., Ugarte, M.: A formal framework for complex event processing. In:
22nd International Conference on Database Theory (ICDT 2019). Schloss Dagstuhl-Leibniz-
Zentrum fuer Informatik (2019)

20. De la Higuera, C.: Grammatical inference: learning automata and grammars. Cambridge

University Press (2010)

21. Lang, K.J., Pearlmutter, B.A., Price, R.A.: Results of the abbadingo one dfa learning com-
petition and a new evidence-driven state merging algorithm. In: International Colloquium on
Grammatical Inference. pp. 1–12. Springer (1998)

22. Letort, G., Montagud, A., Stoll, G., Heiland, R., Barillot, E., Macklin, P., Zinovyev, A.,
Calzone, L.: Physiboss: a multi-scale agent-based modelling framework integrating physical
dimension and cell signalling. Bioinformatics 35(7), 1188–1196 (2019)

23. Lifschitz, V.: Answer set programming. Springer (2019)
24. Lin, J., Keogh, E., Lonardi, S., Chiu, B.: A symbolic representation of time series, with
implications for streaming algorithms. In: Proceedings of the 8th ACM SIGMOD workshop
on Research issues in data mining and knowledge discovery. pp. 2–11 (2003)

25. Lin, J., Keogh, E., Wei, L., Lonardi, S.: Experiencing sax: a novel symbolic representation

of time series. Data Mining and knowledge discovery 15(2), 107–144 (2007)

26. Maler, O., Mens, I.E.: A generic algorithm for learning symbolic automata from membership

queries. In: Models, Algorithms, Logics and Tools, pp. 146–169. Springer (2017)

27. Muggleton, S.H., Lin, D., Pahlavi, N., Tamaddoni-Nezhad, A.: Meta-interpretive learning:

application to grammatical inference. Machine learning 94(1), 25–49 (2014)

28. Oncina, J., Garcia, P.: Identifying regular languages in polynomial time. In: Advances in

structural and syntactic pattern recognition, pp. 99–108. World Scientiﬁc (1992)

29. Pietzuch, P.R., Shand, B., Bacon, J.: A framework for event composition in distributed sys-
tems. In: ACM/IFIP/USENIX International Conference on Distributed Systems Platforms
and Open Distributed Processing. pp. 62–82. Springer (2003)

30. Schultz-Møller, N.P., Migliavacca, M., Pietzuch, P.: Distributed complex event processing
with query rewriting. In: Proceedings of the Third ACM International Conference on Dis-
tributed Event-Based Systems. pp. 1–12 (2009)

31. Shvo, M., Li, A.C., Icarte, R.T., McIlraith, S.A.: Interpretable sequence classiﬁcation via dis-
crete optimization. In: Proceedings of the 35th AAAI Conference on Artiﬁcial Intelligence
(AAAI). pp. 9647–9656 (2021)

32. Smetsers, R., Fiter˘au-Bro¸stean, P., Vaandrager, F.: Model learning as a satisﬁability mod-
ulo theories problem. In: International Conference on Language and Automata Theory and
Applications. pp. 182–194. Springer (2018)

33. Ulyantsev, V., Zakirzyanov, I., Shalyto, A.: Bfs-based symmetry breaking predicates for dfa
identiﬁcation. In: International Conference on Language and Automata Theory and Appli-
cations. pp. 611–622. Springer (2015)

34. Wieczorek, W.: Grammatical Inference. Springer (2017)
35. Wu, E., Diao, Y., Rizvi, S.: High-performance complex event processing over streams. In:
Proceedings of the 2006 ACM SIGMOD international conference on Management of data.
pp. 407–418 (2006)

36. Zhang, H., Diao, Y., Immerman, N.: On complexity and optimization of expensive queries
in complex event processing. In: Proceedings of the 2014 ACM SIGMOD international con-
ference on Management of data. pp. 217–228 (2014)

