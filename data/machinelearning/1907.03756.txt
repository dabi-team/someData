Neutaint: Efﬁcient Dynamic Taint Analysis
with Neural Networks

Dongdong She, Yizheng Chen, Abhishek Shah, Baishakhi Ray and Suman Jana
Columbia University

Abstract—Dynamic taint analysis (DTA) is widely used by var-
ious applications to track information ﬂow during runtime execu-
tion. Existing DTA techniques use rule-based taint-propagation,
which is neither accurate (i.e., high false positive rate) nor efﬁ-
cient (i.e., large runtime overhead). It is hard to specify taint rules
for each operation while covering all corner cases correctly. More-
over, the overtaint and undertaint errors can accumulate during
the propagation of taint information across multiple operations.
Finally, rule-based propagation requires each operation to be
inspected before applying the appropriate rules resulting in pro-
hibitive performance overhead on large real-world applications.
In this work, we propose NEUTAINT, a novel end-to-end
approach to track information ﬂow using neural program embed-
dings. The neural program embeddings model the target’s pro-
grams computations taking place between taint sources and sinks,
which automatically learns the information ﬂow by observing a
diverse set of execution traces. To perform lightweight and precise
information ﬂow analysis, we utilize saliency maps to reason
about most inﬂuential sources for different sinks. NEUTAINT con-
structs two saliency maps, a popular machine learning approach
to inﬂuence analysis, to summarize both coarse-grained and ﬁne-
grained information ﬂow in the neural program embeddings.

We compare NEUTAINT with 3 state-of-the-art dynamic taint
analysis tools. The evaluation results show that NEUTAINT can
achieve 68% accuracy, on average, which is 10% improvement
while reducing 40× runtime overhead over the second-best taint
tool Libdft on 6 real world programs. NEUTAINT also achieves
61% more edge coverage when used for taint-guided fuzzing
indicating the effectiveness of the identiﬁed inﬂuential bytes. We
also evaluate NEUTAINT’s ability to detect real world software
attacks. The results show that NEUTAINT can successfully detect
different types of vulnerabilities including buffer/heap/integer
overﬂows, division by zero, etc. Lastly, NEUTAINT can detect
98.7% of total ﬂows, the highest among all taint analysis tools.

I. INTRODUCTION

9
1
0
2

p
e
S
3

]

R
C
.
s
c
[

2
v
6
5
7
3
0
.
7
0
9
1
:
v
i
X
r
a

[41]

Dynamic Taint Analysis (DTA)

is a well-known
technique to track information ﬂow between source and
sink variables during a program’s execution. It has been
used in many security-relevant applications including guided
fuzzing, automatic vulnerability discovery, run-time policy
enforcement, information leak detection and malware behavior
analysis. [19] [22] [31] [34] [37] [41] [51] [58] [59] [61] [64].
Most, if not all, applications of DTA require high accuracy
and low run-time overhead. Unfortunately, existing DTA
techniques suffer both from high false positive/negative rates
and incur prohibitive performance overhead especially for
large real-world programs [18].

All existing DTA techniques propagate taint labels from the
taint source to the sinks during the target program’s execution

1

Unfortunately,

based on a set of rules for every executed statement. The ﬁnal
taint results are computed by propagating and composing the
individual per-statement taint rules together. Essentially, the
ﬁnal output indicates whether a taint source inﬂuences a sink.
rule-based
approach
propagation
this
limitations: (i) Specifying accurate
has three fundamental
propagation rules: Even for seemingly simple operations,
accurately specifying propagation rules is often hard as there
can be many different cases to consider. For instance, the
correct propagation rule for s = x*c might vary based on
different values of taint labels of x and constant c—if c is
always 0, s is not inﬂuenced by x. Similarly, if c is very
large and x is small, the inﬂuence of x on the output might
be negligibly small. It is extremely difﬁcult to enumerate all
such possibilities exhaustively. (ii) Accumulating errors: Even
if taint propagation rules for each operation are accurate,
their composition across multiple operations can introduce
large errors. For example, consider two operations s = a
+ b; t = s - b, where the rule-based propagation will
conclude that both s and t are inﬂuenced by b. Although this
is the correct analysis for each operation individually, t is not
affected by b. (iii) Large run-time overhead: The rule-based
propagation introduces prohibitive run-time overhead as each
operation has to be examined to decide which rules to apply.
In this paper, we propose a novel technique, NEUTAINT
that automatically learns the information ﬂow, i.e., taint, in
a program by modeling its source-sink behaviors with neural
program embeddings and gradient analysis. Neural program
learn to
embeddings are essentially neural networks that
predict program behaviors from different representations of a
program (e.g., graph representation, input-output pairs) [60],
[46], [52], [53]. Such embeddings have shown promise in
various tasks including fuzzing, program repair, program
synthesis, vulnerability localization and binary similarity
detection [60], [25], [14], [47], [52]. Leveraging the chain
rule of calculus, gradient analysis is a more precise technique
using automatic gradient computation to accurately track the
inﬂuence of sources over sinks in programs. Our NEUTAINT
ﬁrst learns a neural program embedding of a program’s run-
time behaviors and then performs gradient analysis for light-
weight and accurate end-to-end information ﬂow tracking.

NEUTAINT addresses the aforementioned limitations of
rule-based taint tracking. First, while rule-based DTA applies
the propagation rules based on the program statements
executed along a single ﬂow, neural networks can generalize

 
 
 
 
 
 
and infer new ﬂows based on the past program behaviors.
This allows us to more accurately model different degrees of
inﬂuence from different taint sources. Second, since neural
networks are continuous, the gradient computation provides
an efﬁcient and precise mathematical way of deriving a
source’s inﬂuence on a particular sink, thus avoiding the need
to manually specify propagation rules. This also minimizes
the composition errors
that plague existing rule-based
approaches and signiﬁcantly improves the accuracy of taint
tracking by cutting down the false positive/negative rates.
Lastly, the neural program embeddings can be trained using
program traces generated ofﬂine by adding light-weight
instrumentation and executing the target program with
multiple inputs. Once trained, the neural program embeddings
can be used to perform taint analysis without even examining
the computations performed by the target program in an
highly efﬁcient manner compared to rule-based propagation.
Speciﬁcally, we train dynamic neural program embeddings
using observed execution paths between sources and sinks.
Once we have observed one path reaching the sink from
the source during program execution, we generate a lot of
other program paths in a cheap way (e.g., mutating the
input) to obtain the training data. Note that any form of DTA
(rule-based or learning-based) requires an input triggering a
program execution path from the source to the sink to begin
its analysis. Our key advantage is that we can accurately
infer new information ﬂows without inspecting each executed
statement. Even with simple training data, we can track more
ﬂows than three state-of-the-art DTA tools: Libdift, Triton,
and DFSan. We can potentially further improve the training
data quality by using techniques such as symbolic execution.
We present detailed quantitative results showing the number
of detected and missed ﬂows by NEUTAINT in Section IV-G.
After training the neural program, we use a gradient-based
attribution method on the trained network to create saliency
maps that accurately measure the ﬂow of information from
NN inputs (i.e.,
taint
sinks). Depending on the application domain, NEUTAINT
supports two types of saliency maps to track information
ﬂow: (i) a coarse-grained map that aggregates the inﬂuence of
all sources over all sinks. This map contains the information
ﬂow summarized by all executed inputs over all taken paths.
(ii) a ﬁne-grained map containing separate inﬂuence analysis
for each source-sink pair. Such information is useful for tasks
like zero-day attack detection. A common use case for such
analysis is taint-guided fuzzing where the sources are the input
bytes and the sinks are the variables used in program branches.
Input bytes with high saliency values have large inﬂuences on
the output variables in program branches. Mutating these bytes
can maximally trigger the execution of a diverse set of program
branches. The number of mutations spent on each byte can be
adjusted according to its corresponding aggregate inﬂuence
on all program branches, i.e., the higher the inﬂuence, the
more mutations should be tried on the corresponding byte.

taint sources) to NN outputs (i.e.,

We evaluate NEUTAINT against 3 state-of-the-art dynamic
taint analysis tools: Libdft, Triton, and DFSan. We train neural

i.e., ﬁle format bytes (inﬂuential

network models representing two sets of real-world programs.
For the ﬁrst set of programs, NEUTAINT can successfully ﬁnd
the information ﬂow from source to sink in known CVEs. On
the second set of programs, we compare NEUTAINT against
other tools in regards to accuracy, overhead, and effectiveness
when applied to fuzzing (an important security application).
We utilize the parsing logic of programs to build ground
truth of hot bytes,
taint
sources) that trigger different program behaviors (taint sinks
at branching conditions). The evaluation results show that
NEUTAINT achieves on average 10% higher taint accuracy
than the second-best DTA tool. To compare the runtime
overhead, we measure the total amount of
time needed
to process all
the inputs in the training dataset, and our
NEUTAINT is almost 40× more efﬁcient than the second-
fastest tool, Libdft. We then validate the taint information
obtained from all
tools through taint-guided fuzzing. We
feed the hot bytes produced by the four different tools into
a common fuzzer backend that supports the same mutation
algorithm in which our NEUTAINT achieves 61% more edge
coverage on all the real-world programs in 24 hours.

Our main contributions are as follows:
• We propose a novel information ﬂow tracking technique
based on neural program embedding and gradient
analysis.

• We design and implement our technique as part of
NEUTAINT and evaluate it against 3 state-of-the-art
DTA tools. The evaluation shows that NEUTAINT can
achieve on average 10% higher taint accuracy than the
second-best tool while taking 40× less analysis time.
• We further validate the taint information obtained from
4 different tools by using a real world taint application,
taint-guided fuzzing. The results show that NEUTAINT
achieves 61% more edge coverage than that of the
second-best DTA tool.

• We analyze and identify the key factors that allow
NEUTAINT to outperform traditional DTA tools.
In
addition, we present quantitative results showing NEU-
TAINT’s ability to infer new information ﬂows and discuss
different ways to further improve the training data quality.

II. BACKGROUND

This section ﬁrst gives a brief overview of dynamic taint
analysis. Then, we introduce existing work in program
embeddings, among which dynamic program embeddings can
be used to capture the runtime program behavior. Lastly, we
discuss saliency maps for neural networks, which can be used
to conduct information ﬂow analysis for dynamic program
embeddings.

Dynamic Taint Analysis (DTA). A dynamic taint analysis
pre-deﬁnes taint sources (e.g., untrusted ﬁle, network, etc.) and
as a program executes tracks the effect of them on program
state such as internal variables. In most cases, DTA wants to
determine whether the taint sources affect some predeﬁned
target locations, commonly known as taint sinks. Depending
on the speciﬁc application, taint sources and sinks vary.

2

1 x = input();
2 a = x[0];
3 b = x[1];
4 c = a*a + b;
5 z = c - b;
6 print z

Fig. 1: Simple code snippet demonstrating the workﬂow of NEUTAINT. NEUTAINT uses light-weight instrumentation to collect
a diverse set of sources and sinks from the input program. Then, we train neural program embeddings and use gradient-based
analysis to infer information ﬂow for the programs.

For many security applications, user inputs are often used
as taint sources [41]. For example, during fuzzing [49], [16],
DTA explores diverse program execution behaviors and checks
which input bytes affect the branches (i.e., the taint sinks) of
the target program. In the case of malware analysis [64], DTA
monitors if program instruction registers (i.e., taint sink) are
manipulated by untrusted user input [41]. DTA is also applied
to identifying user information leakage [21] [56], where DTA
monitors a set of sensitive user data as taint source and a set
of sensitive functions (e.g., socket write) that leak that data
to the outside world as taint sinks.

they fail

DTA is typically implemented with taint tags. There are
mainly two types of taint tags used in the literature: binary
tags and multiple tags. The binary tag approach marks all
taint sources with a single binary value: 1 or 0 to represent
tainted or untainted respectively. Binary tags are commonly
found in simple tasks such as privacy leakage and detecting
attacks from user-supplied inputs. However,
to
monitor more ﬁne-grained information ﬂow used in malware
analysis and taint-guided fuzzing because they can only track
the existence of taint rather than the ownership of taint source.
In contrast, multi-tag DTA, which tracks every taint source
independently,
tracks taint at a more detailed granularity
at
the cost of signiﬁcantly large runtime overhead which
grows quadratically with tag size. The large runtime overhead
prohibits practical deployment of online DTA tasks to check
security properties such as policy enforcement and intrusion
detection in Android [21]
time-sensitive
applications such as fuzzing ideally require taint analysis
for a large number of program executions in a short amount
of time for defenders to ﬁnd vulnerabilities before attackers
do [49]. These limitations are further detailed in Appendix D3.

[56]. Moreover,

Fundamental Problems of DTA. There are three fundamental
problems in the design and implementation of taint: under-
taint, over-taint, and large runtime overhead. Even with the
heavy instrumentations that cause large runtime overheads,
manually engineered rules for taint propagation still have poor
accuracy at capturing information ﬂow. These limitations of
taint severely affect its applicability to real-world programs. A
recent work TaintInduce [18] has proposed to learn the taint

3

propagation rules instead of manually specifying them. This
can increase the accuracy of individual rules, but the error
accumulation and large overhead issues still remain, due to
propagation-based design. Therefore, we choose to use end-to-
end program embeddings, and we conduct inﬂuence analysis
directly on the neural program to track information ﬂow.

Program Embeddings. In general, there are two types of
program embeddings, static and dynamic. Static program
embeddings ﬁrst generates a program representation,
then
use neural networks
to encode the representation into
embeddings. Example program representations include token
sequences [25], [14], [47], [20], abstract syntax trees [39], and
control and data ﬂow graphs [63], [13]. Static program embed-
dings have been applied to correcting student code errors, au-
tomatic vulnerability detection, and detecting variable misuse.
Since such program representations cannot capture program
semantics, dynamic program embeddings
learn program
behavior from input-output pairs [60], [46], [53] by executing
the program. Dynamic program embeddings have been used
for fuzzing [52], solving symbolic constraints [53], program
repair [60] and generating feedback on student code [46].
Since information ﬂow analysis reﬂects the runtime behavior
of programs, we use dynamic program embeddings to learn
from program execution traces. Our neural program model
approximates the program logic from taint source to taint
sink. Then, we analyze the ﬂow of information in the model.

Information Flow in Neural Network. A popular technique
to track information ﬂows in a neural network (NN) is a
saliency map, which measures the sensitivity of the NN output
to changes in the input features [54]. For example, in image
classiﬁcation, the saliency map can be viewed as an annotated
representation of the input image, where the annotations at
every pixel correspond to the gradient of the output w.r.t. to
the corresponding original pixel value ( i.e., how the output
category changes as the input image pixels change). Saliency
maps have also been used to construct inputs with minimal per-
turbations as adversarial examples to an image classiﬁer [44].
Since the saliency map indicates the most critical input fea-
tures that affect ﬁnal neural network output,
it guides an
attacker’s construction of the adversarial example by localizing

Input Program+3.21st byte has the largest inﬂuence on ZZ+2.77+0.01-0.02 X[0]X[1]X[2]X[3]Taint sinkGradient analysis Taint sourcesTaint sources & Taint sinks Instrumented Execution NN Training +0.03Neural Program EmbeddingInﬂuence Analysisthe changes needed on features to change the classiﬁer output.
As a gradient-based attribution method, a saliency map
has been widely used in interpreting neural networks.
Compared to other gradient-based methods (e.g., integrated
gradient [57]), saliency maps focus on the sensitivity of neural
output to every feature, i.e., how the NN output changes with
respect to a small change in the input. In contrast, integrated
gradient tries to explain the attribution of neural output to
every feature, i.e., how each feature of input contributes to
the ﬁnal NN output. This implies that saliency values for
speciﬁed input features may differ from their corresponding
integrated gradient value. Since integrated gradient value is
essentially gradient ∗ input and saliency value is gradient,
the disparity between these two values is maximized when
the input value is signiﬁcantly small but the gradient value is
large. In our case, since we want to infer which byte in the
input affects the taint sink, i.e., induce the greatest sensitivity
to the neural network output, we use the saliency map method.

III. METHODOLOGY

A. Overview

In this section, we give a motivating example to show the
workﬂow of NEUTAINT. As shown on the left side of Fig 1,
we assume the taint source is x, taking 6 bytes from the user
input, and the taint sink is variable z. The propagation-based
dynamic taint analysis cannot derive accurate information ﬂow
in this case. Since variable c at line 4 is computed by a and b,
the ﬁrst two bytes of user input, so taint value for c is a and
b. At line 5, z is computed from c and b, thus the taint value
for z is composed from c and b. The analysis is accurate for
both line 4 and line 5, but composing the propagation rules
together ampliﬁes errors. The analysis ignores the fact that
at line 5 z actually equals a*a and is only affected by the
ﬁrst byte of user input. Composition introduces and ampliﬁes
errors and runtime overhead in the dynamic taint analysis.

On the contrary, NEUTAINT uses an end-to-end approach
to build neural program embeddings for information ﬂow
analysis. Based on some training samples (i.e., user input, z),
NEUTAINT learns a neural program from dynamic execution
results which preserve program context–z is only affected by
a. As shown on the right side of Fig 1, given a user input x,
NEUTAINT computes the gradient of variable z with respect to
x and constructs a saliency map which indicates the sensitivity
how each byte of x affects z. From the saliency map, we
ﬁnd that ﬁrst byte is the most critical byte of input affecting
z. Fig 1 presents a high-level overview of our approach.

Training. We ﬁrst

train a neural program to learn the
information ﬂow from taint source to sink. For a given program
and a set of inputs, we mark these inputs and use light-weight
instrumentation to collect values of sink variables. They repre-
sent the dynamic behavior of a program. Next, we train a neu-
ral network model (NN) to learn this dynamic behavior. Our
NN approximates a function that maps sources to sinks. The
training process minimizes the errors of learning this function,
thereby improving the precision of information ﬂow tracking.

Inﬂuence Estimation. We construct two saliency maps to
infer the information ﬂow from taint source to sink. Saliency
maps analyze the sensitivity of input features for NEUTAINT.
The more important a feature is, the more it inﬂuences the
NN output. We ﬁrst deﬁne a saliency map to summarize
coarse-grained information ﬂow for the program behavior,
aggregating gradient information for all inputs and all paths.
Then, we deﬁne the second saliency map to identify the most
important taint sources for speciﬁc sinks, utilizing ﬁrst-order
partial derivatives of the NN output with respect to the input.
Since our end-to-end methodology of collecting program
behavior information,
training, and inﬂuence estimation is
lightweight, the runtime overhead is much smaller than a tradi-
tional taint analysis tool. NEUTAINT directly performs analysis
the program semantic level by learning from dynamic
at
program behaviors rather than on the instruction semantic level
in traditional taint analysis which leads to under-taint and over-
taint. Learning the end-to-end model with NEUTAINT reduces
overall information tracking errors, which mitigates the issues
of over-taint and under-taint. Thus, NEUTAINT achieves more
accurate results than traditional taint analysis tools.

B. Program Embedding

NEUTAINT learns the information ﬂow by observing a
large set of taint source-sink pairs from program execution
traces. The model predicts the values of taint sink variables
given taint sources as model input. We formally deﬁne our
neural network model as follows, with detailed architecture
shown in Appendix A. Given a set of concrete taint sources
x and the corresponding taint sinks y for a speciﬁed program
P , the neural program predicts the taint sinks as ˆy, with the
following equations.

a = φ(W T

1 x + b1)

ˆy = σ(W T

2 a + b2)

(1)

(2)

We denote Wk, bk as trainable parameters for every
layer where k represents the layer index, φ represents the
ReLU function, and σ represents the sigmoid function. In
Equation 1, a represents the output vector of the hidden layer
of neural network. The NN model learns the function f that
takes numerical vector of size m as input and outputs n taint
sink variables. Let θ denote the trainable weight parameters
of f . Given a set of training samples (X, Y ), where X is
a set of taint sources and Y represents the correct taint sink
values, the training task of the parametric function f (x, θ) is
to obtain the parameter ˆθ that minimizes the multi-variable
regression loss, where each variable is a taint sink.

After we train the NN model, we construct two saliency
maps to analyze the ﬂow of information in the neural program.
From the neural program model, the ﬁrst saliency map pro-
vides a global view of coarse-grained information ﬂow when
all sinks are considered as a whole. The second saliency map
can extract the most inﬂuential taint sources for any given sink.
We now explain the details of the information ﬂow analysis.

4

C. Coarse-Grained Information Flow

We discuss the method to extract coarse-grained information
ﬂow from the NN model. We deﬁne the coarse-grained
information ﬂow as the inﬂuence of each source on all sinks.
Since some dynamic taint analysis applications have a set of
taint sink variable, e.g., taint-guided fuzzing, it is important to
consider coarse-grained information ﬂow to all the sinks. The
aggregated information ﬂow to a set of taint sink variables
can highlight which part of the taint source has the most
signiﬁcant effect on them.

To extract coarse-grained information ﬂow, we ﬁrst
compute the partial derivatives of the taint sink with respect
to all sources. Let fi(θ, x) denote the output value for the
i-th taint sink variable during the execution of the targeted
program with taint source x. We compute the derivative with
respect to a given taint source x, deﬁned below, where xj
denotes the j-th byte in the taint source.
(cid:20) ∂fi(θ, x)
∂xj

∂f (θ, x)
∂x

∇xf (θ, x) =

(3)

=

(cid:21)

i∈1...n,j∈1...m

The partial derivatives constitute a Jacobian matrix of the
neural network function. Each element of the matrix represents
the gradient of output neuron fi(θ, x) with respect to taint
source byte xj. Note that the gradient we compute has two
main differences from the gradient used in a neural network
trained by backpropagation. First, the target function is differ-
ent. The gradient used for backpropagation is computed on a
loss function which includes information about the state of the
model parameters and the expected outputs. In contrast, our
method computes the derivative on the output of the neural net-
work, which includes only information about the model param-
eters. Since we aim to interpret how neural networks make the
decision after convergence, our gradient computation does not
need to consider the corresponding ground truth information.
Second, we compute the gradient with respect to the input,
rather than trainable parameters of neural network model. By
computing the gradient directly with respect to the input, we
obtain the sensitivity of NN output to all the bytes in the input.
Then, we construct a saliency map to provide the global
view for coarse-grained information ﬂow, based on partial
derivatives of the neural network model. The saliency map
S(x) is deﬁned as follows.

S(x)[j] =

(cid:88)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

∂fi(θ, x)
∂xj

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(4)

is the sum of all

i
S(x)[j]
the sink sensitivity to the j-th
byte, representing the effect of the j-th byte to the overall
program behavior from the current execution. Summarizing
the sensitivity to all sinks includes information about all
paths to these sinks. In addition, the neural program includes
information about all the input data. Therefore, we can analyze
the coarse-grained information ﬂow using this saliency map.

D. Fine-Grained Information Flow

We deﬁne ﬁne-grained information ﬂow as the inﬂuence of
each source to a single sink. Dynamic taint analysis applica-
tions that are interested in ﬁne-grained information ﬂow often

5

set taint sink at a certain variable such as function pointer,
jump target address and instruction pointer register. We refer
to these applications as ﬁne-grained information ﬂow analysis.
To reason about how information arrives at a given sink, we
follow similar steps from the coarse-grained information ﬂow
analysis as mentioned in Section III-C. First, we compute
the Jacobian matrix to obtain the gradient information using
equation 3. After obtaining the gradient value for every
byte in the taint source, we can construct a saliency map to
infer the ﬁne-grained information ﬂow from taint source to
a particular taint sink. Since we are only interested in the
sensitivity of the taint sink to every byte in the taint source,
we take the absolute value of the gradient to construct the
saliency map S(x) deﬁned as follows.

S(x)[j] =

(cid:12)
(cid:12)
(cid:12)
(cid:12)

∂fi(θ, x)
∂xj

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(5)

The bytes that causes the maximum ﬂuctuations of NN output
are considered taint source bytes that inﬂuence the sink. The
set of source bytes that determines taint sink variables can
be inferred by ﬁnding the top-k bytes with maximum values,
deﬁned below.

(cid:12)
(cid:12)
Hi(k) : arg(top k(
(cid:12)
(cid:12)

∂fi(θ, x)
∂x

(cid:12)
(cid:12)
(cid:12)
(cid:12)

))

(6)

Let Hi(k) denote the set of indices of K source bytes, top k
denotes the function to select k largest elements from a vector
and arg denote the function to return indices of selected
elements. Since our neural network learns a summary of
dynamic program behavior from all
the
inﬂuential source bytes inferred from the neural network
model contains knowledge from a large number of concrete
runs of the program. On the contrary, traditional dynamic taint
analysis tools have information from only the speciﬁc path
taken from one execution.

training samples,

E. Data Collection

In this section, we describe the general method to collect
a set of training samples for our neural program training. To
learn the information ﬂow from taint source to taint sink, it is
crucial to obtain a large, diverse, and representative dataset.
However, unlike traditional machine learning tasks (e.g.,
image classiﬁcation, natural
language processing, speech
recognition), there is no standard dataset for various taint
sources and sinks. There are many options to collect training
datasets. A natural solution to collect such a dataset would
be to randomly sample taint source-sink execution pairs for
a speciﬁed programs. As an example to generate a training
dataset, we can start with a common taint source, randomly
ﬂip the bytes in the taint source, and record the corresponding
taint sink values. Alternatively, we can use a simple fuzzer to
generate a set of taint source which trigger diverse program
states and record the taint sinks values. The training data
coverage affects the amount of information NEUTAINT can
track. We can further improve the information ﬂow coverage
using more sophisticated techniques like coverage-guided

fuzzing, symbolic execution, etc. However, in this paper we
demonstrate that even with training data generated by a simple
fuzzer, NEUTAINT can easily outperform existing DTA tools.
Note that taint sources are normally user input, ﬁles or user
privacy strings that can be represented as byte sequences. So
we can easily convert the byte sequences to bounded numerical
vectors ranged in [0, 255]. However, the taint sink can be
arbitrary variables in the program with unbounded values such
as instruction pointer register, a complex socket structure, or a
user deﬁned variable in the program. These arbitrary variables
are hard to model as uniﬁed representations for NN output
and make it difﬁcult for the NN to converge. To tackle this
problem, we normalize these unbounded variables to bounded
data for different applications. For example, in taint-guided
fuzzing, we set taint sinks at a set of variables used in branch
conditions and normalize the sink variables with binary data
(i.e., 1 represents the branch is taken, 0 represents the branch
is not taken). The binary representation of the NN output can
ensure the fast convergence of the model.

IV. EVALUATION

In this section, we evaluate the effectiveness and efﬁciency
three state-of-the-art dynamic taint
of NEUTAINT against
analysis tools (Libdft [32], Triton [2], and DFSan [5]). We
answer the following research questions about NEUTAINT in
the evaluation.

1) Hot Byte Accuracy: Is NEUTAINT more accurate at
ﬁnding hot bytes (i.e., the most inﬂuential bytes that
determine different program behaviors) in input for 6
real-world programs?

2) Runtime Overhead: What is the runtime overhead of
NEUTAINT compared to state-of-the-art dynamic taint
analysis tools (both with and without GPU)?

3) Exploit Analysis: Can NEUTAINT detect vulnerabilities

in real-world programs?

4) Application on Taint-Guided Fuzzing: Since fuzzing is
one of the most important security applications of taint,
does NEUTAINT help taint-guided fuzzing achieve better
edge coverage compared to other taint analysis tools?
5) Model Choice: How does NEUTAINT perform with
different machine learning models other than neural
networks?

6) Information Loss: What kinds of ﬂows are missed by
NEUTAINT? How does the training data quality affect
such information loss and how to mitigate this loss?
To answer these questions, we will ﬁrst describe our
experiment setup and how we learn the neural program
embeddings for the real-world programs.

A. Experiment Setup

Environment Setup. All our measurements are performed
on a ubuntu 16.04 system with an Intel Xeon E5-2623
v4@2.60GHz CPU , an Nvidia GTX 1080 Ti GPU and 256
GB RAM. We implement the NEUTAINT in Keras-2.1.4 [6]
with Tensorﬂow-1.8.0 [7] as the backend.

Next, we give a brief introduction of the three front-end
tools in our evaluation, how we set up the tools, and our
implementation of NEUTAINT.

1) Libdft: Libdft is a widely-used dynamic taint analysis
engine based on Intel PIN framework [8]. It predeﬁnes taint
propagation rules for every type of instruction via external
functions using the PIN analysis API. Then, it dynamically
instruments the binary code using the PIN instrumentation
API at runtime. For every executed instruction, Libdft calls
a corresponding external function to track the taint ﬂow.
If a particular type of instruction (e.g., pop, ret) lacks any
function will be invoked.
taint
Nevertheless, for real-world applications, most
instructions
contain taint
information, and hence this design incurs a
large runtime overhead due to the sheer number of external
function calls. Another notable drawback of Libdft is that the
current implementation only supports the x86 architecture.

information, no external

Setup. We set up a modiﬁed version libdft with support of
multiple taint tags [1]. The dependency PIN version is 2.13.
2) Triton: Triton is a platform that supports concolic
execution, dynamic taint analysis, and abstract syntax tree
representation. Similar
to Libdft’s approach for dynamic
analysis, it uses Intel PIN to monitor taint ﬂow corresponding
to a set of predeﬁned taint propagation rules. Currently, its
taint analysis engine only supports the x86 architecture. Triton
provides users Python bindings to the underlying PIN API
so that they can write scripts to perform customized analysis
tasks. However, these bindings are limited and fail to capture
the full functionality of PIN. Moreover, the limited Python
bindings cause imprecise dynamic taint analysis results in
addition to the runtime overhead from heavy instrumentation
and monitoring taint propagation in PIN.

Setup. We set up a develop fork Triton to support the multiple
taint tags feature [3]. The dependency PIN version is 2.13.
We write the analysis script with Triton Python binding to
set corresponding taint sources and taint sinks according to
different programs.

3) DFSan: DFSan (DataFlowSanitizer)

is a data ﬂow
analysis framework provided by Clang [4]. It consists of a
compile-time instrumentation module and a runtime dynamic
library to track taint ﬂow for the x86-64 architecture only.
Users only need to deﬁne taint source and taint sink with the
public DFSan API. DFSan relies on predeﬁned taint propaga-
tion rules for LLVM IR instructions rather than architecture-
speciﬁc assembly instructions. This enables DFSan to insert
taint
tracking functions at compile time into a program.
Thus, it has a smaller runtime overhead compared to other
PIN-based tools that use dynamic instrumentation. DFSan,
however, fails to run on programs which depend on external
shared libraries. Since the dynamically shared libraries cannot
be instrumented when compiling a given program, DFSan
cannot insert these taint tracking functions and fails to work on
programs depending on dynamic shared libraries. This along
with the exhaustion and resolution of taint tags (Section IV-C)
limits the applicability of DFSan to real-world applications.

6

DTA Engine

Propagation Level

Dependency

Tag Type

Program

Taint Sources #

Taint Sinks #

Taint Sinks Types

Libdft
Triton
DFSan

assembly instruction
assembly instruction
LLVM instruction

Pin 2.13
Pin 2.13
LLVM-7.0.0

multi-tag
multi-tag
multi-tag

TABLE I: Dynamic Taint Analysis Engines.

Setup. We set up DFSan from the Clang runtime library. The
underlying LLVM version is 7.0.0. We use DFSan’s API to
set taint source and sink for different programs.

4) NEUTAINT: Model Architectures. For each program,
we train a neural program model which learns the program
logic from taint sources to taint sinks. The NN model consists
of 3 fully-connected layers. The hidden layer uses ReLU
as activation functions with 4096 hidden units. The output
layer uses Sigmoid as the activation function to predict the
sink variables. Since each program has different taint sources
and taint sinks,
the corresponding neural program model
has different number of input/output neurons. We describe
taint sources and taint sinks for all programs in Table II. We
use the ﬁrst 6 programs to evaluate the hot byte accuracy
and the taint-guided fuzzing experiments, so we set multiple
taint sinks as branch variables (i.e.,
the variables used in
conditional predicates). The later 5 programs are evaluated
in the exploit analysis experiment, so they only have a single
taint sink at a speciﬁed variable. All 11 programs set each
byte of the program input as a taint source. Thus the total
number of taint sources are the total number of input bytes.

Training Data Collection. To collect the training data, we
ﬁrst run the AFL fuzzer with an initial seed to collect its
mutation corpus. Next, we use a simple LLVM pass to add
light-weight instrumentation for recording the two operands
of CMP instructions during runtime. These operands of
CMP instructions are branch variables (i.e., our taint sinks)
evaluated in conditional predicates. We run the instrumented
program with the generated input and record the taint sink
values. We collect around 2K input-output pairs (each input
has multiple source bytes and reaches multiple sinks) on each
program for training. For hot byte evaluation, we normalize
the taint sink variables into binary, i.e., 1 if a sink value
satisﬁes the conditional predicate and 0 if not. We check
the value of predicates by computing the difference of two
operands of CMP instructions. For exploit analysis, we use the
similar LLVM pass to obtain the speciﬁed taint sink values,
then perform standard min-max normalization to the sink
values (i.e., ynorm = (y − ymin)/(ymax − ymin)). Note that
the data collection and normalization can be easily done by
a simple python script, no manual labeling effort is required.

Training Procedure. We adopt random weight initialization
and cross-entropy loss function or mean-square-error loss
depending on speciﬁc model output data type. The NN model
is trained with an Adam optimizer for 100 epochs with an
initial learning rate 0.01 and decay rate 0.7 per 10 epochs. We
choose a mini-batch size 16. For exploit analysis evaluation,
we use mean-square-error as loss function and metric to
is
evaluate our model performance. Since our NN model

readelf
harfbuzz
mupdf
libxml
libjpeg
zlib

sort
openjpeg2
libsndﬁle
nm
strip

7467
5049
4861
8040
5873
8306

500
298
446
847
1123

2122
2805
1377
1929
997
571

1
1
1
1
1

branch variables
branch variables
branch variables
branch variables
branch variables
branch variables

length variable
denominator
length variable
counter variable
length variable

TABLE II: We set program input bytes as taint sources, and
we use different types of taint sinks. For the ﬁrst 6 programs,
we select sink variables at program branches to evaluate
NEUTAINT’s accuracy, overhead, and application on taint-
guided fuzzing. For the rest 5 programs, we set taint sinks
according to the vulnerability information for exploit analysis.

simple, the training process is very efﬁcient and takes on
average 73s across all tested programs. In Section IV-B, we
test the accuracy and false positive rate of our neural program
models at identifying hot bytes. In addition, we evaluate the
information loss in Section IV-G.

B. Is NEUTAINT more accurate at ﬁnding hot bytes (i.e., the
the most inﬂuential bytes) in input for 6 real-world programs?

is relevant

It is extremely hard to evaluate the accuracy of dynamic
taint analysis. We would like to ﬁnd ground truth for taint
to its applications. DTA is often used to
that
search for important bytes in the inputs to trigger speciﬁed
program behaviors. For example, vulnerability analysis needs
to ﬁnd which part of untrusted input
triggers malicious
behaviors. Taint-guided fuzzing aims to ﬁnd importance bytes
which explore new program behaviors and yield new code
coverage. DTA ﬁnds these important bytes by setting and
propagating taint labels from taint sources (program input)
to taint sinks (various variables that determines program
behaviors). Therefore, we propose to use these hot bytes to
evaluate the accuracy of DTA tools and NEUTAINT.

Hot Bytes Deﬁnition. We deﬁne importance bytes that can
maximally inﬂuence the variables in program branches as hot
bytes.

Then next question is how to obtain the ground truth
hot bytes as baseline to compute the hot byte accuracy.
We observe that a large number of real-world programs are
parsers which take in a speciﬁed ﬁle type and check its
format. Meanwhile, most of the program behaviors of these
parser programs are determined by bytes at
the speciﬁed
locations of input (i.e., the ﬁxed locations where ﬁle format
headers locate), rather than the ﬁle content. Hence, for a
parser program, we can approximate that the hot bytes are
mostly located at the structured format sections. Further, by
analyzing the ﬁxed structured locations of a ﬁle, we can
obtain the estimated ground truth of hot bytes for a particular
parsing program. These ground truth hot bytes can be used as
a metric to evaluate the effectiveness and efﬁcacy of dynamic
taint analysis tools on a particular parsing program.

7

Programs

File
Format

Hot Byte Accuracy

Hot Byte FPR

NEUTAINT

Libdft

DFSan

Triton

NEUTAINT

Libdft

DFSan

Triton

readelf-2.30
harfbuzz-1.7.6
mupdf-1.12.0
libxml2-2.9.7
libjpeg-9c
zlib-1.2.11

ELF
TTF
PDF
XML
JPEG
ZIP

81%
86%
80%
65%
29%
66%

74%
86%
48%
56%
n/a
26%

49%
n/a
57%
n/a
n/a
n/a

44%†
13%†
33%†
14.2%†
n/a
3%†

1.6%
0.8%
2.0%
2.3%
3.9%
1.8%

3.0%
0.8%
2.9%
3.0%
n/a
3.9%

3.5%
n/a
2.6%
n/a
n/a
n/a

3.7%†
5.2%†
3.9%†
5.8%†
n/a
5.1%†

†indicates cases where Triton analyzed partial dataset within 24 hours

NEUTAINT
(GPU/CPU)

6m/25m
5m/18m
3m/9m
6m/29m
3m/5m
3m/4m

Runtime

Libdft

DFSan

Triton

161m
204m
224m
197m
n/a
20m

117m
n/a
532m
n/a
n/a
n/a

>24h
>24h
>24h
>24h
n/a
>24h

TABLE III: For each program, we measure the accuracy and false positive rate of identifying hot bytes, as well as runtime
overhead for different DTA tools and NEUTAINT. NEUTAINT achieves the highest accuracy and lowest false positive rate. On
average, NEUTAINT increases the accuracy by 10% and reduces the false positive rate by 0.44% compared to the second-best
DTA tool Libdft. NEUTAINT is 40× faster on GPU and 10× faster on CPU than the second-best DTA tool Libdft.

Ground Truth. Note that all evaluated real-world programs in
this sections are ﬁle parsing programs. Since these 6 parsing
programs have particular structures in their ﬁle formats, we
can obtain estimated ground truth of hot bytes by analyzing
these ﬁle formats. A saliency map of ELF ﬁle format
is
shown in Appendix B. Fig 2 shows the ground truth of all
6 ﬁle formats. Similar to ELF, other formats also include the
header and trailers. But some ﬁles may have unique format
features. For example, ZIP ﬁle has an additional local ﬁle
header after the ZIP ﬁle header at the beginning. TTF ﬁle
contains unique character tables near the trailers.

Extract Hot Byte. We perform the following step to extract
the hot bytes from our neural program models. 1) For each
to NN model. 2) We
program, we feed the seed input
compute the gradient of taint sinks with respect to the taint
sources (seed input) and construct the saliency map using
Equation 4. The saliency value indicates the extent to which
the byte in taint sources affect the all the taint sink variables.
3) We select the top 5% bytes with highest values from the
input saliency map as possible hot bytes using Equation 6.
The reason we set this threshold is that in practice, only a
small number of hot bytes in the input determine program
behaviors. After analyzing all 6 ﬁle formats, we ﬁnd that the
total number of ground truth hot bytes range from 250 to 500
which takes around 5% of total input bytes.

Compute Hot Byte Accuracy. We compute the hot byte accu-
racy by checking if the hot bytes analyzed from taint tools are
consist with ground truth hot bytes. To be speciﬁc, if a hot byte
identiﬁed by NEUTAINT locate in the estimated ground truth
range, we consider it as a true hot byte identiﬁcation (i.e., true
positive); otherwise, we consider it as false identiﬁcation (i.e.,
false positive). For the 3 other state-of-the-art dynamic taint
analysis tools, we also evaluate their abilities to ﬁnd hot bytes
to compare against NEUTAINT. Since dynamic taint analysis
operates on a single execution trace, we run the dynamic taint
analysis tools on every input in the training data and collect
the tainted bytes for every execution; we then aggregate these
tainted bytes by counting the total number of times a speciﬁed
byte is tainted. In this way, we construct a similar saliency
map as NEUTAINT for these 3 tools. We then select the same
threshold 5% of top tainted bytes as possible hot bytes and
calculate the hot byte accuracy. Lastly, we measure the total

8

runtime to obtain the ﬁnal hot byte accuracy for the 4 tools.
For the 3 dynamic taint analysis tools, we record the total
runtime for tracking all the input samples in the dataset. For
NEUTAINT, we record the total runtime cost for NN training
and gradient computation. Based on the best-effort ground
truth for the 6 ﬁle formats, we compute accuracy and false
positive rate of identifying hot bytes in a standard way.

Results. The results for hot byte accuracy is shown in
Table III. For programs with simple and straightforward
parsing logic such as readelf and harfbuzz, we observe
that all four tools ﬁnd hot bytes with high accuracy. For
programs with complex parsing and transformation logic
such as libjpeg and zlib,
the accuracy drops for all
tools due to large taint ﬂows inside the decompression
algorithm. Nonetheless, NEUTAINT achieves the highest hot
byte accuracy on 5 programs. Even for the remaining program
libjpeg which causes signiﬁcant runtime overhead due to
large taint propagation ﬂows, NEUTAINT is the only one to be
able to ﬁnish the analysis within a reasonable time (minutes
as opposed to hours). Fig 2 shows the detailed visualisation
of hot byte accuracy using a heat map.

Traditional

in signiﬁcant
taint propagation can result
slowdowns for time-sensitive operations in large real-world
applications. libjpeg’s decompression algorithm requires
massive memory read and write operations which carry
taint information. Indeed, all three traditional dynamic taint
analysis tools fail to ﬁnish the analysis of libjpeg on the
dataset within 24 hours. Moreover, the second-best tool Libdft
spends more than 3 minutes on libjpeg to ﬁnish a single
execution (more than 2 days for all 993 inputs in the dataset)
to track all the taint ﬂows inside the decompression algorithms
while a vanilla execution of libjpeg without dynamic taint
analysis takes 0.015s. The runtime overhead for intense taint
tracking could be more than 104X times while NEUTAINT
such heavy instrumentation overhead through a
avoids
lightweight neural network model that identiﬁes the hot bytes.

68%, 58%, 53%, 27%. NEUTAINT

Analysis: Hot Byte Accuracy. The average hot byte
accuracy for all 4 tools across all evaluated programs
10%
are
than second-best dynamic
more accuracy improvement
taint
for hot byte accuracy of every
tool Libdft. As
program, NEUTAINT achieves 7%, 0%, 7%, 23%, 40% more

achieves

(a) ELF

(b) XML

(c) TTF

(d) JPG

(e) ZIP

(f) PDF

Fig. 2: The six heatmaps show how each tool identiﬁes hot bytes for a given ﬁle format. The x-axis is broken into byte
intervals, and an interval’s darkness is proportional to how many hot bytes a tool predicts. Since the ﬁrst row represents the
ground truth, the correctness is deﬁned by how each subsequent row aligns with the ground truth row.

improvement respectively on program readelf, harfbuzz,
mupdf, libxml, zlib. The reason for NEUTAINT’s higher
accuracy is that NEUTAINT is an analysis based on program
semantics by learning dynamic program logic rather than
an analysis based on instruction semantics performed by
traditional dynamic taint analysis tools. NEUTAINT could
ﬂexibly adapt to diverse execution context which cannot be
accurately modeled by dynamic taint analysis tools through
ﬁxed, predeﬁned taint propagation rules.

the

lowest

false positive

Analysis: Hot Byte False Positive Rate. For all programs,
NEUTAINT achieves
at
identifying hot bytes (Table III). On average, NEUTAINT has
2.07% false positive rate, that is less than half of that for
Triton. Compared to the second-best DTA tool Libdft, the hot
byte false positive rate of NEUTAINT is 0.44% lower. The
results show that learning end-to-end program embeddings
can effectively reduce the overtaint issue.

rate

Result 1: NEUTAINT achieves the highest hot byte accuracy
and lowest false positive rate in six popular ﬁle formats
compared to state-of-the-art dynamic taint analysis tools.
On average, NEUTAINT increases the accuracy by 10% and
reduces the false positive rate by 0.44% compared to the
second-best DTA tool Libdft.

C. What is the runtime overhead of NEUTAINT compared to
state-of-the-art dynamic taint analysis tools, with and without
GPU?

We measure the runtime overhead for NEUTAINT and all
three dynamic taint analysis tools. We measure the total time
needed to process all the inputs in our dataset, as the runtime
in Table III. For NEUTAINT, the total runtime of NEUTAINT
is composed of three parts, collecting program behavior data,
training NN and computing the saliency map of NN.

Table III summarizes the result. Overall, NEUTAINT has
the least runtime overhead for all six programs compared to
other tools, since the time cost for training and computing the

9

saliency map is negligible. To collect the training dataset, we
obtain values of the sink variables in the binary through light-
weight instrumentation which introduces negligible overhead.
In addition, computing the saliency map is computationally
efﬁcient. Therefore, NEUTAINT enjoys the fastest runtime
among all four tools evaluated. In particular, on program
mupdf, NEUTAINT can save up to 74× runtime overhead on
GPU and 24× runtime overhead on CPU than the second-best
DTA tool Libdft. The average runtime overhead for the
four tools are 4 mins(GPU)/15min (CPU), 161 mins, 325
mins and > 24 hours. Compared to the second fastest tool
Libdft, NEUTAINT on average achieves 40× and 10× smaller
runtime overhead on GPU and CPU, respectively.

Among the other three tools, Triton achieves the worst result
on hot byte accuracy and runtime overhead, due to PIN dy-
namic instrumentation and inefﬁcient analysis routine. So we
only evaluate the partial inputs from dataset on Triton within
24 hours to compute the hot byte accuracy. As for runtime of
Triton, we use > 24 hours to indicate the signiﬁcantly large
runtime overhead. DFSan achieves the second fastest analysis
on program readelf. Its runtime overhead is smaller than
Libdft because of its efﬁcient instrumentation during compile
time rather than runtime. However, DFSan fails to run on four
programs because it cannot instrument external dynamically
linked libraries at compile time, and it incurs large overhead
for recursive tag resolution. Libdft runs faster than DFSan
and Triton for all programs except readelf. It is also more
accurate at identifying hot bytes than DFSan and Triton, in
all programs except mupdf. However, Libdft is still 43 times
slower than NEUTAINT, due to execution of heavily instru-
mented binary and accumulated overhead through propagation.

Result 2: The runtime overhead of NEUTAINT is 40× faster
on GPU and 10× faster on CPU than the previously fastest
dynamic taint analysis tool Libdft.

Ablation Studies. We break down the total runtime overhead
of NEUTAINT for processing 2,000 inputs into three parts,

Neutaint 81%  DFSan 49%   Triton 44%Ground Truth Libdft 74% Neutaint 65%  DFSan  n/a   Triton 17%Ground Truth Libdft 56% Neutaint 86%  DFSan  n/a   Triton 13%Ground Truth Libdft 86% Neutaint 29%  DFSan  n/a   Triton  n/aGround Truth Libdft  n/a Neutaint 66%  DFSan  n/a   Triton  3%Ground Truth Libdft 26% Neutaint 80%  DFSan 57%   Triton 33%Ground Truth Libdft 48%     100    75    25    50    0  n/a Number of hot bytes predicted by a toolProgram

readelf
harfbuzz
mupdf
libxml
libjpeg
zlib

Data
Collection

All 2,000 Inputs
Training

GPU

CPU

Saliency Map
CPU
GPU

18s
40s
30s
44s
10s
5s

214s
115s
116s
216s
112s
110s

1352s
951s
472s
1652s
251s
202s

98s
119s
64s
93s
36s
26s

119s
130s
82s
109s
37s
30s

Total

GPU

CPU

330s
274s
210s
353s
158s
141s

1471s
1080s
554s
1761s
288s
232s

Programs

readelf-2.30
harfbuzz-1.7.6
mupdf-1.12.0
libxml2-2.9.7
libjpeg-9c
zlib-1.2.11

File
Format

ELF
TTF
PDF
XML
JPEG
ZIP

Edge coverage

NEUTAINT

Libdft

DFSan

Triton

5540
5395
399
918
649
200

4164
3796
248
428
n/a
131

2489
n/a
192
n/a
n/a
n/a

440†
11†
48†
236†
n/a
54†

TABLE IV: Runtime breakdown for NEUTAINT. The table
shows the total runtime of processing 2,000 inputs for data
collection, training, and saliency map computation.

†indicates cases where Triton analyzed partial inputs from dataset.

TABLE VI: Edge coverage comparison of 5 taint-guided
fuzzers for 24 hour time budget

Program

Vulnerability Type

CVE ID

sort
openjpeg2
libsndﬁle
nm
strip

buffer overﬂow
integer division-by-zero
out-of-bound read
heap overﬂow
integer overﬂow

CVE-2013-0221
CVE-2016-9112
CVE-2017-14245
CVE-2018-19931
CVE-2018-19932

TABLE V: NEUTAINT
can successfully identify the
information ﬂow from source to sink in the following exploits.

data collection, training and saliency map on both GPU and
CPU settings. The results are shown in Table IV. The average
runtime of NEUTAINT is 244s across 6 programs, 4× faster
than on CPU (898s). Even on a machine with only CPU
computation, the runtime overhead of NEUTAINT is still 10×
lower than traditional DTA tools. Since our NN model has a
small number of hyperparameters, the model can be efﬁciently
trained with and without GPU. With GPU, the training time
takes around 60%. The construction of saliency map and
data collections takes around 30% and 10%, respectively.
With only CPU, the runtime splits into training, saliency map
computation, and data collection as 88%, 9% and 3%. Using
only CPU causes on average 4.5× and 0.16× slowdown
in training and saliency map construction than with GPU,
respectively. In general, the training time takes up the majority
of total runtime. Whereas, data collection takes up the least
part of runtime because the light-weight instrumentation of
program only records the taint sink values during execution
and introduces minimal overhead than vanilla execution.

Result 3: The total runtime for NEUTAINT to process all
2,000 inputs is 244s on average for each of the six pro-
grams. Training time takes up the most part of total runtime
overhead, around 60% with GPU and 88% without GPU.

D. Can NEUTAINT detect vulnerabilities
programs?

in real-world

We evaluate the effectiveness of NEUTAINT in the
analysis of software attacks. We choose 5 known real-world
vulnerabilities as listed in Table V. These vulnerabilities
are all
from open-sourced programs. Then we perform
light-weight instrumentation on the programs and record the
values for (taint source, taint sink) pairs during runtime. The
5 vulnerabilities covers various exploit types such as buffer
overﬂow, heap overﬂow, integer overﬂow, integer division-by-
zero and out-of-bound read. For each vulnerabilities, we set
the taint sink at the variables which causes the vulnerability

(e.g., length variable used by read/write function, variable used
as denominator). We also set program input as taint source
for every vulnerability. To collect the training samples, we
randomly ﬂip bytes at a speciﬁed program input (the exploit)
and execute the vulnerable programs with the generated input
to record the corresponding taint sink values. For the 5 vulner-
abilities, we generate 2K training samples for each of them.
We train the neural program model which learns the mapping
from taint source to taint sink. Then we feed the exploit as
taint source to the neural program and construct the saliency
map using Equation 5 based on the gradient of taint sink with
respect to taint source. According to the saliency, we can infer
which part of taint source determines the taint sink variables.
The key result is that NEUTAINT successfully locates the
hot bytes which control the taint sink variables, and thus can
reason about the inﬂuence from taint source to taint sink.

Result 4: NEUTAINT can successfully ﬁnd the information
ﬂow from source to sink in known CVEs.

E. Since taint-guided fuzzing is one of the most important
security applications of
taint, does NEUTAINT help taint-
guided fuzzing achieve better edge coverage compared to
other taint analysis tools?

In this section, we compare the performance of all
tools when applied to one of the most important security
applications, taint-guided fuzzing.

Fuzzer Backend Implementation. Dynamic taint analysis
has been used as the front end by many fuzzers to identify hot
bytes for guiding further mutations. [62] [40] [27] [49] [16].
Although these fuzzers leverage dynamic taint analysis tools
to ﬁnd hot bytes, each of them applies different algorithms
to mutate hot bytes. For example, Vuzzer [49] copies the
magic number extracted from binary directly to the locations
of hot bytes; and Angora [16] implements gradient descent
along with other strategies to mutate these hot byte locations.
To eliminate the effects of different searching strategies
and different execution backends of fuzzing modules, we
build a simple and efﬁcient fuzzer backend in C (shown in
Appendix C). For each dynamic taint analysis front end, we
use a common backend that generates new inputs based on
mutations of the hot bytes. Therefore, we have a total of
four fuzzer prototypes using the same mutation algorithm as
shown in Algorithm 1. The metric we use for comparison is
the edge coverage achieved from the different front ends.

10

Edge Coverage Comparison. We run each fuzzer prototype
for 24 hours on the 6 programs shown in Table VI. We
have discussed the evaluation of hot byte accuracy for these
programs in Section IV-B. Each fuzzer is given the same initial
seed corpus for each program and assigned a single CPU.
Each dynamic taint analysis front-end works with the back-end
fuzzer to guide the mutation. Since Triton incurs a signiﬁcantly
large runtime overhead greater the our evaluation time, Triton
has only analyzed partial inputs in 24 hours. The results are
shown in Table VI. NEUTAINT achieves the highest edge
coverage for all 6 program evaluated. On average, NEUTAINT
reaches 61% more edge coverage than the second best analysis
front end Libdft. Triton is the worst analysis front end due
to its extremely large runtime overhead and lowest hot byte
accuracy. DFSan front end could only run on two programs
and achieves intermediate results. To summarize, the taint-
guided fuzzing results further validate that NEUTAINT obtains
the most accurate hot bytes among the four taint analysis tools
in real-world applications. The consistency of taint-guided
fuzzing results and hot byte accuracy evaluation (Section IV-B)
demonstrates the efﬁciency and effectiveness of NEUTAINT.

Result 5: NEUTAINT achieves 61% more edge coverage
than other dynamic taint analysis tools for taint-guided
fuzzing, demonstrating that the taint information obtained
from NEUTAINT is more effective.

F. How does NEUTAINT perform with different machine
learning models other than neural networks?

In this section, we compare other machine learning models
(e.g., logistic regression and support vector machines (SVM))
against neural network for the implementation of NEUTAINT
on the same set of real world programs. We also use the hot
byte accuracy and FPR as mentioned in Section IV-B to eval-
uate the performance of different machine learning models.
Logistic Regression: We implement the logistic regression
using the same NN architecture, but without any non-linear
activation in hidden layers. We use sigmoid as ﬁnal layer and
train with the same setting as mentioned in Section IV-A.
To extract the hot byte information, we perform the gradient
analysis routine as mentioned in Section IV-B.
SVM models: We implement
the SVM models (linear,
polynomial kernel, and RBF Gaussian kernel) using the
scikit-learn library [9]. Our dataset has a large number of
output labels (i.e., up to 2K sink variables for each input).
The runtime overhead is large for SVM model on such dataset
because it uses a simple one-vs-one scheme. Therefore, we
leverage the correlations between labels and encode the large
number labels into a smaller and compact ones. To obtain
the importance of each input feature, we compute the dot
product of all weights associated with each input feature to
the ﬁnal model outputs. Bigger weights mean that the output
is more sensitive to the change of the corresponding feature.
Results: Table VII shows the hot byte accuracy and false
positive rate from the ﬁve different ML models. Neural
network model achieves the best results on all 6 programs,
on average 68% hot byte accuracy. Among the four other

Fig. 3: Total number of ﬂows detected by NEUTAINT when
training dataset coverage increases. Training data with higher
coverage can increase the ﬂow coverage of NEUTAINT.

machine learning models, SVM with polynomial kernel is the
best model, achieving on average 30.5% hot byte accuracy.
Logistic model achieves the second-best results on programs
libjpeg and zlib. SVM with polynomial kernel is the
best-performed SVM model, achieving the second-best results
on programs harfbuzz and readelf. SVM with linear
kernel achieves the second-best result on program libxml
and SVM with RBF Gaussian kernel achieves the second-best
result on program mupdf. The reason for neural network’s
superior performance is that neural network has a large model
it ﬁts diverse datasets well. Moreover,
capacity such that
unlike SVM, neural network can naturally support datasets
with a large number of labels.

Result 6: The neural network model achieves on average
68% hot byte accuracy and 2.07% FPR, the best among
ﬁve machine learning models.

G. What kinds of ﬂows are missed by NEUTAINT? How does
the training data quality affect such information loss and how
to mitigate this loss?

Flow Deﬁnition: Before describing our techniques to measure
the information loss, we formally deﬁne the ﬂows. The goal of
DTA is to detect ﬂows based on dynamic execution. Therefore,
we collect a ground truth dataset that contains the total number
of ﬂows based on unseen test inputs. We deﬁne one ﬂow as a
tuple of (input value, source, sink), and the total ﬂows are col-
lected from all test inputs. To measure the information loss, we
evaluate how many ﬂows NEUTAINT and dynamic taint analy-
sis tools can detect out of the total ﬂows from the ground truth.

Flow Dataset: Since we need the ground truth of exact
number of total ﬂows as baseline, we choose four programs
(including three tiny programs [12], [10], [11], and one small
real world program) where such information can be obtained
reliably through static analysis and manual inspection. For
each program, we choose 50 sink variables in conditional
predicates, such as ﬁle magic bytes, ﬁeld values and offsets.
We obtain these sink values through light-weight instrumen-
tation and normalize them into binary data as mentioned
in Section IV-A. These sink variables are commonly used
to perform conditional checking that determines program
behaviors. If a particular input can reach 20 sinks, we count
20 ﬂows for that input. To collect the dataset, we randomly
ﬂip bytes of a speciﬁed input using a simple fuzzer, generating

11

01020304050Training data coverage (No. of reachable sinks)05000100001500020000Total flow numberszlibtinyxmltinyjpgtinyelfProgram

readelf
harfbuzz
mupdf
libxml
libjpeg
zlib

NN

Logistic

Hot Byte Accuracy
SVM(linear)

SVM(poly)

SVM(rbf)

NN

Logistic

SVM(linear)

SVM(poly)

SVM(rbf)

Hot Byte FPR

81%
86%
80%
65%
29%
66%

38.6%
19.8%
13%
34.8%
7.3%
44%

23.8%
26.3%
14%
47%
5.9%
7.1%

47.4%
56.7%
14.8%
42.3%
7%
15%

27.4%
28.7%
17.4%
5.7%
1.4%
10%

1.6%
0.8%
2%
2.3%
3.9%
1.8%

4.2%
4.8%
5%
4.3%
7.3%
3%

5.2%
4.4%
5%
3.5%
5.1%
4.8%

3.6%
2.6%
4.9%
3.9%
5%
4.4%

4.9%
4.2%
4.8%
6.3%
5%
4.7%

TABLE VII: NEUTAINT performance on different ML models. The neural network model achieves on average 68% hot byte
accuracy and 2.07% FPR, the best among ﬁve machine learning models.

Program

TinyELF
TinyJPG
TinyXML
Zlib

Total Flows
(Ground Truth)

NEUTAINT

Libdft

Triton

DFSan

19,464
17,188
17,036
19,957

19,046
17,160
16,691
19,804

7,227
11,439
15,233
18,043

18,048
17,184
7,671
14,743

5,120
15,510
14,720
14,322

the testing inputs. The result

is shown in Table VIII.
all
On average, NEUTAINT detects 98.7% ﬂows,
the highest
among all tools. Triton, Libdft, and DFSan detect on average
78%, 70.9% and 69% ﬂows, respectively. The 1.3% loss of
NEUTAINT is due to model inaccuracy.

TABLE VIII: Comparison of information ﬂow losses of
different
tracking tools on three tiny programs and
one real world program. We use static analysis and manual
examination to estimate the number of total ﬂows.

taint

6K inputs which cover all the 50 sink variables. Then we
split the dataset into 5K training inputs and 1K testing inputs.
Both training and testing datasets can cover all 50 sink
variables. We achieve on average 99% testing accuracy. After
training the neural program, we perform the gradient analysis
as mentioned in Section IV-B to reason if a sink variable
is tainted or not. If the gradient value for a sink variable is
greater than a speciﬁed threshold, it is considered as tainted.

Information Loss: All dynamic taint analysis tools suffer
from information loss, since they cannot
track all ﬂows
in a program. The information loss of NEUTAINT can be
categorized into two classes.

• Coverage of training dataset. When the training data do
not cover all the sink variables that appear in the testing
data, there could be information loss on NEUTAINT.
• Inaccuracy of machine learning model. No model

is
100% accurate on unseen testing data. The information
loss happens when the neural network model makes
wrong predictions to unseen testing data.

To investigate the information loss caused by training data
coverage (i.e., the number of sink variables covered by training
inputs), we downsample the 5K training inputs into ﬁve subsets
with different coverage threshold. Each subset covers a differ-
ent number of sink variables from 10, 20, 30, 40, to 50. Then
we train NEUTAINT with each subset and evaluate the total
number of ﬂows detected on the 1K unseen test inputs. The
result is shown in Fig 3. The total number of ﬂows detected by
NEUTAINT increases as the training data coverage increases.
When training data covers all the sinks, NEUTAINT can detect
the highest number of ﬂows in the unseen testing dataset.

Furthermore, we evaluate the information loss caused by
the inaccuracy of the neural network model. Speciﬁcally, we
compare the number of ﬂows detected by NEUTAINT against
three state-of-the-art DTA tools on the four programs. We
obtain the ground truth (i.e., total number of ﬂows) from

Advantages of NEUTAINT: The reason for NEUTAINT’s
superior performance is that NEUTAINT can detect information
ﬂows passed through some complex code such as external
library calls strcmp() and strncmp(). It
is hard for DTA
tools to propagate the taint tags through the library calls.
Moreover, NEUTAINT also detects some implicit control
ﬂow dependency which is not supported by common DTA
tools. We will cover more details of these cases in Section V
and Appendix D. NEUTAINT achieves the best result on
(TinyELF, TinyXML, and Zlib) among
3 programs
all four tools and the second best on TinyJPG. For the
program TinyJPG, Triton ﬁnds slightly more ﬂows than
NEUTAINT. TinyJPG does not contain any external library
calls or implicit control dependency in selected taint sinks,
while NEUTAINT could make some minor mistakes when
approximating sink variables in unseen inputs. Lifdft performs
the worst on the program TinyELF, because most functions
in TinyELF pass parameters through a ﬂoat point instruction
MOVSD which is not supported by Libdft. Compared to other
tools, DFSan ﬁnds the least number of ﬂows. The results
show that information loss is common for all tested tools.

How to improve the coverage of
training data for
NEUTAINT? To mitigate the information loss, we can add
more training data to reach more sink variables. Using a
fuzzer to generate data with coverage guidance is more
helpful than only randomly ﬂipping the input without the
guidance. In addition, we can use existing techniques such
as symbolic execution to generate training data with high
quality. Finding a new path in any form of DTA is the hard
problem. Once we ﬁnd one path between source and sink, we
can generate many more paths via input mutation. Though
training the neural program requires at least one path between
a source and a sink, we can achieve lower false positive rate
and higher accuracy than rule-based traditional DTA tools.

Result 7: Training data with higher coverage increases
the ﬂow coverage of NEUTAINT. On average, NEUTAINT
detects 98.7% ﬂows which is 20% more than the second-best
tool Triton.

12

V. UNDERTAINT CASE STUDY

VI. RELATED WORK

In this

section, we present a case to explain why
NEUTAINT is more accurate than traditional dynamic taint
analysis. Speciﬁcally, NEUTAINT tracks implicit information
ﬂows and avoids under taint in real world programs. More
examples can be found in Appendix D.

Example: Implicit Information Flows. Most DTA tools
ignore implicit information ﬂows (i.e., implicit control depen-
dency and complex external library calls) and only support
explicit information ﬂow in data-dependency form. The reason
is that supporting implicit information ﬂows could cause high
runtime overhead and false positive rate [32]. Lack of support
to these implicit information ﬂows often result in under-taint
issue on some real world programs. We discuss the implicit
control dependency in a popular tiny program TinyXML [12].
As shown in List 1, p is a input buffer which stores program
input as taint source. At line 16, ele->ClosingType() is
the sink variable determining the program branching behavior.
At line 6, ele->ClosingType() can be modiﬁed to a
constant value when there is a special character in the input
buffer. Since ele->ClosingType() is control-dependent
but not data-dependent on taint source input buffer p,
DTA tools fail
to track the ﬂows to such sink variables.
In the second example, we consider such implicit control
dependency in complex external function calls. Many sink
variables are the return values of complex external function
calls such as strcmp() and strncmp(). The return values
are state variables which are control-dependent on the taint
source, but not explicit data dependent. Therefore, DTA tools
would lose taint information for such sink variables.

1 // tinyxml2/tinyxml2.cpp:1066
2 while(p){
...
3
if( *p == ’/’ )
{

4

5

6

7

8

/* implicit control flow dependency*/
ele->ClosingType() = CLOSING;
++p;

}

9
10 }
11
12 char* XMLNode::ParseDeep(...)
13 {
14

...
/* under-taint */
if(ele->ClosingType() == XMLElement::CLOSING)
{

15

16

17

18

19

20
21 }

...

}
...

Listing 1: Implicit control dependency in TinyXML

NEUTAINT Solution. NEUTAINT avoids this problem by
directly learning the mapping from taint sources to any taint
sink variables (including both data-dependency and control-
dependency variables). Compared to traditional dynamic taint
analysis tools, NEUTAINT has the advantage of generalizing
to various real-world programs.

13

Recently, many works [14], [47], [24], [46], [50] have used
machine learning for different program analysis tasks such as
program synthesis [45], vulnerability detection [28], [43], [39],
[35], [30], [33], [17], program repair [60], [26], fuzzing [48],
[23], [42], [36], [29], [52], and symbolic execution [53].

Dynamic taint analysis [41] [15] [64] [32] [38] executes
programs with concrete inputs to perform the analysis.
However, it incurs large overhead and suffers from overtaint
and undertaint issues. To address these issues, TaintInduce [18]
proposes to learn platform-speciﬁc taint propagation rules
from (input, output) pairs of instructions. Their approach
learns propagation rules based on a template, and uses an
algorithm to reduce the task to learning different input sets
and pre-conditions for propagating the taint tags. TaintInduce
individual propagation rules,
increases the accuracy for
but
from accumulated errors and large
overhead due to propagation-based design. On the contrary,
NEUTAINT uses machine learning technique to track end-to-
end information ﬂow. We use light-weight instrumentation to
build neural program embeddings, and directly analyze the
ﬂow of information captured by the neural network models.
end-to-end information ﬂow
Our
tracking errors and signiﬁcantly reduces runtime overhead.

technique minimizes

they still suffer

VII. CONCLUSION

We present a novel approach NEUTAINT to perform
taint analysis using neural program embeddings. Our neural
program learns the information ﬂow directly from taint
sources to taint sinks. We use saliency maps to analyze the
information ﬂow in the neural programs. To evaluate the
accuracy, overhead, and application utility of NEUTAINT, we
compare against three state-of-the-art dynamic taint analysis
tools. The results show that NEUTAINT achieves on average
10% increase in accuracy and 40 times less runtime overhead
over the second best dynamic taint analysis tool Libdft.
NEUTAINT can also successfully track the information from
source to sink in exploits. We further evaluate NEUTAINT
through a popular taint application–fuzzing. The taint-guided
fuzzing results demonstrate that NEUTAINT can achieve
on average 61% more edge coverage than state-of-the-art
dynamic taint analysis tools.

ACKNOWLEDGEMENT

We thank Mingshen Sun, our shepherd Mathias Payer and
the anonymous reviewers for their constructive and valuable
feedback. This work is sponsored in part by NSF grants
CNS-18-42456, CNS-18-01426, CNS-16-17670, CNS-16-
18771, CCF-16-19123, CCF-18-22965, CNS-19-46068; ONR
grant N00014-17-1-2010; an ARL Young Investigator (YIP)
award; a NSF CAREER award; a Google Faculty Fellowship;
and a Capital One Research Grant. Any opinions, ﬁndings,
conclusions, or recommendations expressed herein are those
of the authors, and do not necessarily reﬂect those of the US
Government, ONR, ARL, NSF, Google, or Capital One.

REFERENCES

[1] Libdft with support of multiple taint. https://github.com/m000/dtracker.
[2] Triton: A Dynamic Symbolic Execution Framework. SSTIC, 2015.
[3] Triton with support of multiple taint tags. https://github.com/bntejn/

Triton/tree/dev-tagging-taint, 2017.

[4] Clang: a C language family frontend for LLVM. https://clang.llvm.org/,

2018.

[5] DataFlowSanitizer. https://clang.llvm.org/docs/DataFlowSanitizer.html,

2019.

[6] Keras: The python deep learning library. https://keras.io/, 2019.
[7] An

source machine

framework

learning

open

for

everyone.

https://www.tensorﬂow.org/, 2019.

[8] Pin - A Dynamic Binary Instrumentation Tool. https://software.intel.
com/en-us/articles/pin-a-dynamic-binary-instrumentation-tool, 2019.
[9] scikit-learn Machine Learning in Python. https://scikit-learn.org/stable/,

2019.

[10] TinyELF. https://github.com/TheCodeArtist/elf-parser, 2019.
[11] TinyJPG. https://github.com/cdcseacave/TinyEXIF, 2019.
[12] TinyXML2. https://github.com/leethomason/tinyxml2, 2019.
[13] M. Allamanis, M. Brockschmidt, and M. Khademi. Learning to represent
programs with graphs. arXiv preprint arXiv:1711.00740, 2017.
[14] S. Bhatia and R. Singh. Automated correction for syntax errors in
programming assignments using recurrent neural networks. 2016.
[15] E. Bosman, A. Slowinska, and H. Bos. Minemu: The world’s fastest

taint tracker. In RAID, 2011.

[16] P. Chen and H. Chen. Angora: Efﬁcient fuzzing by principled search.
2018 IEEE Symposium on Security and Privacy (S&P), pages 711–725,
2018.

[17] M.-J. Choi, S. Jeong, H. Oh, and J. Choo. End-to-end prediction of
buffer overruns from raw source code via neural memory networks.
In Proceedings of the 26th International Joint Conference on Artiﬁcial
Intelligence, IJCAI’17, 2017.

[18] Z. L. Chua, Y. Wang, T. Blu, P. Saxena, Z. Liang, and P. Su. One engine
to serve’em all: Inferring taint rules without architectural semantics.
In 26th Annual Network and Distributed System Security Symposium,
NDSS 2019, San Diego, California, USA, February 24-27, 2019, 2019.
[19] J. Clause, W. Li, and A. Orso. Dytan: A generic dynamic taint analysis

framework. 2007.

[20] J. Devlin, J. Uesato, S. Bhupatiraju, R. Singh, A.-r. Mohamed,
and P. Kohli. Robustﬁll: Neural program learning under noisy i/o.
In Proceedings of
the 34th International Conference on Machine
Learning-Volume 70, pages 990–998. JMLR. org, 2017.

[21] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel,
and A. N. Sheth. Taintdroid: An information-ﬂow tracking system
In Proceedings
for realtime privacy monitoring on smartphones.
of
the 9th USENIX Conference on Operating Systems Design and
Implementation, OSDI’10, pages 393–407, Berkeley, CA, USA, 2010.
USENIX Association.

[22] V. Ganesh, T. Leek, and M. Rinard. Taint-based directed whitebox
In 2009 IEEE 31st International Conference on Software

fuzzing.
Engineering, May 2009.

[23] P. Godefroid, H. Peleg, and R. Singh. Learn&Fuzz: Machine Learning
for Input Fuzzing. In Proceedings of the 32nd IEEE/ACM International
Conference on Automated Software Engineering, 2017.

[24] A. Graves, G. Wayne, and I. Danihelka. Neural turing machines. 2014.
[25] R. Gupta, S. Pal, A. Kanade, and S. K. Shevade. Deepﬁx: Fixing

common c language errors by deep learning. In AAAI, 2017.

[26] R. Gupta, S. Pal, A. Kanade, and S. K. Shevade. Deepﬁx: Fixing
In Proceedings of the
common C language errors by deep learning.
Thirty-First AAAI Conference on Artiﬁcial Intelligence, February 4-9,
2017, San Francisco, California, USA., 2017.

[27] I. Haller, A. Slowinska, M. Neugschwandtner, and H. Bos. Dowsing
for overﬂows: A guided fuzzer to ﬁnd buffer boundary violations. In
Proceedings of the 22nd USENIX Security Symposium, 2013.

[28] A. Hovsepyan, R. Scandariato, W. Joosen, and J. Walden. Software
vulnerability prediction using text analysis techniques. In Proceedings
the 4th International Workshop on Security Measurements and
of
Metrics, MetriSec ’12, 2012.

[29] Z. Hu, J. Shi, Y. Huang, J. Xiong, and X. Bu. Ganfuzz: A gan-based
industrial network protocol fuzzing framework. In Proceedings of the
15th ACM International Conference on Computing Frontiers, 2018.

[30] X. Huo, M. Li, and Z.-H. Zhou.

Learning uniﬁed features from
natural and programming languages for locating buggy source code.
In Proceedings of the Twenty-Fifth International Joint Conference on
Artiﬁcial Intelligence, 2016.

[31] M. G. Kang, S. McCamant, P. Poosankam, and D. X. Song. Dta++:
Dynamic taint analysis with targeted control-ﬂow propagation.
In
NDSS, 2011.

[32] V. P. Kemerlis, G. Portokalidis, K. Jee, and A. D. Keromytis. Libdft:
In
Practical dynamic data ﬂow tracking for commodity systems.
Proceedings of the 8th ACM SIGPLAN/SIGOPS Conference on Virtual
Execution Environments, VEE ’12, 2012.

[33] A. N. Lam, A. T. Nguyen, H. A. Nguyen, and T. N. Nguyen. Combining
deep learning with information retrieval
to localize buggy ﬁles for
bug reports (n). In 2015 30th IEEE/ACM International Conference on
Automated Software Engineering (ASE), 2015.

[34] S. Lekies, B. Stock, and M. Johns. 25 million ﬂows later: Large-scale
detection of dom-based xss. In Proceedings of the 2013 ACM SIGSAC
conference on Computer & communications security, pages 1193–1204.
ACM, 2013.

[35] Z. Li, D. Zou, S. Xu, X. Ou, H. Jin, S. Wang, Z. Deng, and Y. Zhong.
Vuldeepecker: A deep learning-based system for vulnerability detection.
In 25th Annual Network and Distributed System Security Symposium,
NDSS 2018, San Diego, California, USA, February 18-21, 2018, 2018.
[36] C. Lv, S. Ji, Y. Li, J. Zhou, J. Chen, P. Zhou, and J. Chen.
Smartseed: Smart seed generation for efﬁcient fuzzing. arXiv preprint
arXiv:1807.02606, 2018.

[37] W. Melicher, A. Das, M. Sharif, L. Bauer, and L. Jia. Riding out doms-
day: Towards detecting and preventing dom cross-site scripting. In 2018
Network and Distributed System Security Symposium (NDSS), 2018.

[38] J. Ming, D. Wu, J. Wang, G. Xiao, and P. Liu. Straighttaint: Decoupled
ofﬂine symbolic taint analysis. In Proceedings of the 31st IEEE/ACM
International Conference on Automated Software Engineering, ASE
2016, New York, NY, USA, 2016. ACM.

[39] L. Mou, G. Li, L. Zhang, T. Wang, and Z. Jin. Convolutional neural
networks over tree structures for programming language processing. In
Proceedings of the Thirtieth AAAI Conference on Artiﬁcial Intelligence,
AAAI’16, 2016.

[40] M. Neugschwandtner, P. Milani Comparetti, I. Haller, and H. Bos. The
In Proceedings
BORG: Nanoprobing binaries for buffer overreads.
of the 5th ACM Conference on Data and Application Security and
Privacy, 2015.

[41] J. Newsome and D. Song. Dynamic taint analysis for automatic
detection, analysis, and signature generation of exploits on commodity
software. 2005.

[42] N. Nichols, M. Raugas, R.

Jasper, and N. Hilliard.

Faster
arXiv preprint

fuzzing: Reinitialization with deep neural models.
arXiv:1711.02807, 2017.

[43] Y. Pang, X. Xue, and A. S. Namin. Predicting vulnerable software
components through n-gram analysis and statistical feature selection.
In 2015 IEEE 14th International Conference on Machine Learning and
Applications (ICMLA), 2015.

[44] N. Papernot, P. D. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik, and
A. Swami. The limitations of deep learning in adversarial settings.
2016 IEEE European Symposium on Security and Privacy, 2016.
[45] E. Parisotto, A. rahman Mohamed, R. Singh, L. Li, D. Zhou, and
P. Kohli. Neuro-symbolic program synthesis. CoRR, abs/1611.01855,
2016.

[46] C. Piech, J. Huang, A. Nguyen, M. Phulsuksombati, M. Sahami, and
L. Guibas. Learning program embeddings to propagate feedback on
student code. In Proceedings of the 32nd International Conference on
Machine Learning, pages 1093–1102, 2015.

[47] Y. Pu, K. Narasimhan, A. Solar-Lezama, and R. Barzilay. Sk P: A
In Proceedings of the 2016
Neural Program Corrector for MOOCs.
ACM SIGPLAN International Conference on Systems, Programming,
Languages and Applications: Software for Humanity, 2016.

[48] M. Rajpal, W. Blum, and R. Singh. Not All Bytes Are Equal: Neural
Byte Sieve for Fuzzing. arXiv preprint arXiv:1711.04596, 2017.
[49] S. Rawat, V. Jain, A. Kumar, L. Cojocar, C. Giuffrida, and H. Bos.
In Proceedings of
VUzzer: Application-Aware Evolutionary Fuzzing.
the 2008 Network and Distributed Systems Security Conference, 2017.
In

[50] S. E. Reed and N. de Freitas. Neural programmer-interpreters.
International Conference on Learning Representations, 2015.

[51] U. Shankar, K. Talwar, J. S. Foster, and D. Wagner. Detecting format
In Proceedings of the 10th

string vulnerabilities with type qualiﬁers.

14

Conference on USENIX Security Symposium, SSYM’01, Berkeley, CA,
USA, 2001. USENIX Association.

[52] D. She, K. Pei, D. Epstein, J. Yang, B. Ray, , and S. Jana. NEUZZ:
Efﬁcient Fuzzing with Neural Program Smoothing. In Proceedings of
the 2019 IEEE Symposium on Security and Privacy, 2019.

[53] S. Shen, S. Ramesh, S. Shinde, A. Roychoudhury, and P. Saxena.
Neuro-symbolic execution: The feasibility of an inductive approach to
symbolic execution. 2019.

[54] K. Simonyan, A. Vedaldi, and A. Zisserman. Deep inside convolutional
networks: Visualising image classiﬁcation models and saliency maps.
CoRR, abs/1312.6034, 2013.

[55] A. Slowinska and H. Bos. Pointless tainting?: Evaluating the practicality
of pointer tainting. In Proceedings of the 4th ACM European Conference
on Computer Systems, EuroSys ’09, New York, NY, USA, 2009. ACM.
Taintart: A practical multi-level
information-ﬂow tracking system for android runtime. In Proceedings
of
the 23rd ACM Conference on Computer and Communications
Security, CCS’16, 2016.

[56] M. Sun, T. Wei, and J. C. Lui.

[57] M. Sundararajan, A. Taly, and Q. Yan. Axiomatic attribution for deep

networks. arXiv preprint arXiv:1703.01365, 2017.

[58] O. Tripp, M. Pistoia, S. J. Fink, M. Sridharan, and O. Weisman. Taj:
Effective taint analysis of web applications. In Proceedings of the 30th
ACM SIGPLAN Conference on Programming Language Design and
Implementation, PLDI ’09, New York, NY, USA, 2009. ACM.

[59] P. Vogt, F. Nentwich, N. Jovanovic, E. Kirda, C. Kr¨ugel, and G. Vigna.
Cross site scripting prevention with dynamic data tainting and static
analysis. In NDSS, 2007.

[60] K. Wang, R. Singh, and Z. Su. Dynamic neural program embedding

for program repair, 2017.

[61] T. Wang, T. Wei, G. Gu, and W. Zou. Taintscope: A checksum-aware
directed fuzzing tool for automatic software vulnerability detection. In
Proceedings of the 2010 IEEE Symposium on Security and Privacy, SP
’10, Washington, DC, USA, 2010. IEEE Computer Society.

[62] T. Wang, T. Wei, G. Gu, and W. Zou. TaintScope: A checksum-aware
directed fuzzing tool for automatic software vulnerability detection. In
Proceedings of the IEEE Symposium on Security & Privacy, 2010.
[63] X. Xu, C. Liu, Q. Feng, H. Yin, L. Song, and D. Song. Neural network-
based graph embedding for cross-platform binary code similarity
In Proceedings of the 2017 ACM SIGSAC Conference on
detection.
Computer and Communications Security, pages 363–376. ACM, 2017.
[64] H. Yin, D. Song, M. Egele, C. Kruegel, and E. Kirda. Panorama:
Capturing system-wide information ﬂow for malware detection and
analysis. In In Proceedings of the 14th ACM Conferences on Computer
and Communication Security (CCS). ACM, 2007.

A. NN Architecture

APPENDIX

We use the neural network architecture shown in Figure 4
to learn neural program embeddings. The taint sources are
NN inputs and taint sinks are NN outputs. The network has
one hidden layer with ReLU activations and one output layer
with sigmoid activations.

Fig. 4: The Neural Network architecture we use to generate
dynamic program embeddings.

15

B. Saliency Map for ELF File Format

The ELF ﬁle format can be broken down into four main
regions, as shown in Fig 5. Three of them are header informa-
tion (ELF, Program Header Table, and Section Header Table)
and the other one is for non-header information (e.g.,.text,
.data, .bss). For a common ELF ﬁle parser (readelf), the
main parsing logic focuses on these shaded header regions
and typically ignores the non-header information. Therefore
the hot bytes should locate at the these header regions.

Fig. 5: Saliency Map of user input on program readelf.
The darkness of the color corresponds to the inﬂuence of the
region’s bytes on the taint sinks. The ELF Header ﬁeld has
the largest saliency values.

C. Fuzzing Algorithm

Our fuzzing algorithm is shown in Algorithm 1. The
algorithm takes in hot bytes locations from taint tools and
perform deterministic mutations on these hot bytes. Random
mutations are discarded to ensure that the fuzzer performance
is only affected by the quality of hot bytes identiﬁed by the
different dynamic taint analysis front ends.

Algorithm 1 Our mutation algorithm for taint-guided fuzzing
that focuses on inﬂuential bytes.

Input:

seed ← initial seed
iter ← number of iterations
hot bytes ← hot bytes from taint tools

locations ← top(hot bytes, (2i))
for m = 1 to 255 do

for loc ∈ locations do
v ← seed[loc] + m
v ← clip(v, 0, 255)

1: for i = 1 to iter do
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15: end for

end for

end for
gen mutate(seed, loc, v)
for loc ∈ locations do
v ← seed[loc] − m
v ← clip(v, 0, 255)

end for
gen mutate(seed, loc, v)

,W1b1,W2b2YX_2 taint sinks  ... X_n X_1 relurelurelu... sigmoid... ... taint  sources sigmoidsigmoidy_1 y_2... y_nXD. Case Study

In this section, we present case studies to explain why
NEUTAINT is more accurate and has lower runtime overhead
than traditional dynamic taint analysis tools.

1) Undertaint: When a taint analysis tool fails to track
all the taint labels for a speciﬁed variable, it is considered as
under-taint. Under-taint is a common issue for dynamic taint
analysis. Since the taint propagation rules in dynamic taint
analysis tools are neither sound nor complete, some taint
labels are easily missed during the analysis process [18].

Example: Pointer Taint. In the code example 2, we demon-
strate the classic pointer taint dilemma in a popular XML
parser library libxml, where we track the taint ﬂow from
program input to NXT(len) (line 7 and 8). From the prior
execution context, variables ctxt->cur and len are all
affected by program input taint source and therefore carry the
taint label of the taint source. The example shows a function,
xmlXPathComPathExpr(), that is frequently used by the
library to parse the path expression of a XML element. It uses
len as the index to check the one-character operator of a path
expression at line 7 and 8, through the byte reading macro
NXT(val) deﬁned in line 2. After taking len as the offset
to the current pointer location ctxt->cur, NXT() returns
the byte located at the address ctxt->cur + len. The
propagation rules state that the byte memory is only affected
by a single byte read from the memory content NXT(val),
not by the base address ctxt->cur and len. However,
these addresses determine the byte memory content, which
are missed due to pointer under-taint. In practice, the taint
ﬂow from pointer to memory content is intentionally ignored
by most taint analysis tools as handling them could easily
cause many false positives and even a taint explosion.[55] In
contrast, NEUTAINT can capture such information ﬂow from
pointer to program behavior. Speciﬁcally, NEUTAINT models
the function mapping from program input to branch variables
at line 7 and 8. Then, by learning the differences among
program behavior triggered by various input samples at line 7
and 8, NEUTAINT can infer input bytes that reach line 10. The
advantage of our method over traditional taint analysis is that it
is based on the knowledge learned from a summary of runtime
program semantics rather than ﬁxed taint propagation rules.

1 // libxml2-2.9.7/xpath.c:10736
2 #define NXT(val) ctxt->cur[(val)]
3
4 static void xmlXPathCompPathExpr(...)
5 {
6

...
if((NXT(len) == ’<’) || (NXT(len) == ’>’)
|| (NXT(len) == ’=’))
{

7

8

9

10

11

12

13
14 }

lc = 1;
break;

}
...

Listing 2: Pointer under-taint in libxml

Example: Incomplete Taint Source. Incomplete taint source

identiﬁcation can also cause severe under-taint issue in real-
world applications. Dynamic taint analysis tools identify the
taint source by installing some hooks to system calls open(),
read(), mmap() and setting taint marks on corresponding
memory/registers. These predeﬁned interception procedures
usually rely on developers’ experience to cover some common
cases. However, real-world applications have diverse and
complex IO procedures. The simple system call hooks in
dynamic taint analysis tools may fail
to fully capture all
the taint sources and lose track of taint information at the
beginning of program execution. For example, a popular XML
parser library libxml supports uses compressed IO interface
gzread() by default for both compressed and uncompressed
input, which a lot of tools are not aware of. In this case, a
state-of-the-art dynamic taint tool libdft would lose track of
partial taint source and result in a severe under-taint problem.
To make the matter worse, many different under-taint reasons
can co-occur at different parts of the program.

NEUTAINT Solution. NEUTAINT avoids this problem by not
relying on any human engineered system call hook procedures.
It directly uses a neural network model to learn the mapping
between taint sources and taint sink variables. Compared to
traditional dynamic taint analysis tools, NEUTAINT has the
advantage of generalizing to various real-world programs.
2) Overtaint: Over-taint occurs when dynamic

taint
analysis marks irrelevant taint labels on speciﬁed variables.
Dynamic taint analysis tools deﬁne over-approximated taint
propagation rules for certain types of instructions, making
it hard to track the precise taint ﬂow. Since the taint labels
are propagated at the instruction level and often ignore the
semantic of the program context,
issue is
the over-taint
in a real-world program, a single
inevitable. Furthermore,
over-taint label could instantly propagate to generate many
over-taint labels during a repeating operation (e.g., a loop or
recursive function call). This over-taint issue pollutes further
execution and analysis results.

1 // zlib-1.2.11/inffast.c:50
2 void ZLIB_INTERNAL inflate_fast(strm, start)
3 {
4

...
for(...)
{

hold += (unsigned long)(*in++) << bits;
bits += 8;
hold += (unsigned long)(*in++) << bits;
bits += 8;
...
/* decoding match distance */
if(dodist)
{

dist=(unsigned)hold & ((1U << op) - 1);
if(dist > dmax) {...}

}
...
hold >>= (bits + 16); // over-taint

}
...

Listing 3: Over-taint propagation in zlib

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21
22 }

16

propagation handler,
then the runtime overhead would be
signiﬁcantly large. As shown in code 4, decode_mcu() is
a common function used in JPEG parser library libjpeg,
to DC
where we track taint ﬂow from program input
coefﬁcients block. The function uses a for
loop to
decode Huffman-compressed coefﬁcients, by repeatedly
calling a function macro HUFF_DECODE at line 17. Since
HUFF_DECODE is a time-critical operation, it is implemented
inline-macro for better performance. However, most
as
in HUFF_DECODE involve taint propagation.
operations
Starting from line 5, the macro reads a byte c from input
buffer, then performs a binary OR between get_buffer and
c at line 6. So get_buffer takes the union of taint labels
for c and itself. At line 7, the global variable get_buffer is
used to perform huffman decoding which requires to propagate
label from get_buffer to result. Repeated
the taint
calls to the macro HUFF_DECODE all
label
propagation, causing extreme runtime overhead. These taint
labels ﬁnally propagates into result variable s at line 20, which
would be intensively used during later decoding procedure and
introduce even more runtime overhead. Our experiments show
that a state-of-the-art dynamic taint analysis tool has more than
10,000X runtime overhead than normal execution on libjepg.

involve taint

NEUTAINT Solution. As mentioned in last section, NEUTAINT
is a black-box analysis that does not need to track every
instruction, enabling it to avoid large runtime overheads.

1 // jpeg-9c/jdhuff.c:1197
2 #define HUFF_DECODE(result, ...) \
3 {
4

5

6

7

...
c = read_byte(); \
get_buffer = get_buffer | c; \
result = huff_decode(get_buffer, ...); \
...

8
9 }
10
11 bool decode_mcu(j_decompress_ptr cinfo, ...)
12 {
13

...
for(...)
{

...
HUFF_DECODE(s, br_state, htbl, ...);
...
/* Output the DC coefficient */
(*block)[0] = (JCOEF) s;
...

}
...

14

15

16

17

18

19

20

21

22

23
24 }

Listing 4: Extreme runtime overhead in libjpeg. In
Line 17, macro HUFF_DECODE is repeatedly called,
which involves expensive taint label propagation, causing
extreme runtime overhead.

Example. Error Accumulation. As shown in code 3,
inflate_fast() is a decoding function in a zlib decom-
pression procedure, where we track the taint ﬂow from input
buffer in (line 7 and 9) to the distance variable dist (line
16). The function reads compressed data from input buffer in
and decodes the distance variable dist for further deﬂation.
Going through the for loop, every time two bytes are read
from in buffer (lines 7-10) and stored into the bit accumulator
hold, then the content in hold are dropped at line 19. After
a few iterations, the condition at line 13 is satisﬁed and the
function starts to decode the match distance variable dist.
So dist is only affected by the two new bytes in hold that
are read from the current round. The over-taint occurs at line
19 when hold drops bits from the previous round through
a shift operation, but the taint rules did not drop the labels.
Since no taint propagation rule can be general enough for
different program semantic, dynamic taint analysis tools use a
conservative taint rule to copy all the taint labels from source
(hold) to destination (hold) for shift instructions. For every
round in the loop, hold obtains two byte taint labels while
still keeping the old taint labels from the previous round.
The total taint labels of hold were accumulated through the
loop, then spread to dist that determines the conditional
program behavior at line 16. The over-taint propagation issue
stems from the inaccurate taint propagation rules pre-deﬁned
by experts. It is impossible to design ﬁxed taint propagation
rules to accurately handle all the real-world cases.

NEUTAINT Solution. NEUTAINT directly models the mapping
from program input to conditional program behaviors at line
16. As long as there exist samples that cover different
line 16, NEUTAINT can easily infer the two
branches at
critical bytes of program input that affect dist.

3) Overhead: Traditional dynamic taint analysis tools track
the taint labels by instrumenting the execution of the program.
Speciﬁcally, for every executed instruction, the taint analysis
tool calls a corresponding taint propagation handler to process
the taint labels associated with the operation. Most instructions
trigger calls to these handlers to track the taint ﬂow with very
few exceptions (e.g., push, pop and ret), leading to a large
runtime overhead. The runtime overhead of taint propagation
is also affected by the granularity of the taint tag. Marking taint
tags for each input on the coarse binary taint tag granularity al-
ready incurs signiﬁcant overhead, not to mention the overhead
to mark each input offset. A complex dynamic taint analysis
task such as fuzzing requires more ﬁne-grained taint labels
which represents different offsets of user input. Tracking nu-
merical taint labels incurs more runtime overhead than simple
binary taint labels due to the fact that a basic union operation
over two tainted source tags with respectively m and n offsets
is O(mn) time complexity, rather than O(1) on two binary taint
labels. As a result, adopting ﬁne-grained taint labels drastically
increases the runtime overhead of taint propagation handlers.

Example. Real-world programs can have many time-critical
operations that are frequently executed. If every instruction
of these time-critical procedures needs to call additional taint

17

