2
2
0
2

t
c
O
2
1

]

C
O
.
h
t
a
m

[

2
v
6
0
0
2
1
.
5
0
2
2
:
v
i
X
r
a

Neur2SP: Neural Two-Stage Stochastic Programming

Justin Dumouchelle∗

Rahul Patel∗

Elias B. Khalil† Merve Bodur

Department of Mechanical & Industrial Engineering, University of Toronto

Abstract

Stochastic Programming is a powerful modeling framework for decision-making
under uncertainty. In this work, we tackle two-stage stochastic programs (2SPs),
the most widely used class of stochastic programming models. Solving 2SPs
exactly requires optimizing over an expected value function that is computationally
intractable. Having a mixed-integer linear program (MIP) or a nonlinear program
(NLP) in the second stage further aggravates the intractability, even when special-
ized algorithms that exploit problem structure are employed. Finding high-quality
(ﬁrst-stage) solutions – without leveraging problem structure – can be crucial in
such settings. We develop Neur2SP, a new method that approximates the expected
value function via a neural network to obtain a surrogate model that can be solved
more efﬁciently than the traditional extensive formulation approach. Neur2SP
makes no assumptions about the problem structure, in particular about the second-
stage problem, and can be implemented using an off-the-shelf MIP solver. Our
extensive computational experiments on four benchmark 2SP problem classes with
different structures (containing MIP and NLP second-stage problems) demonstrate
the efﬁciency (time) and efﬁcacy (solution quality) of Neur2SP. In under 1.66 sec-
onds, Neur2SP ﬁnds high-quality solutions across all problems even as the number
of scenarios increases, an ideal property that is difﬁcult to have for traditional 2SP
solution techniques. Namely, the most generic baseline method typically requires
minutes to hours to ﬁnd solutions of comparable quality.

1

Introduction

Mathematical programming consists of a gamut of tools to solve optimization problems. Under
perfect information, i.e., when all the data is deterministic and known, many of these problems can
be solved as a linear program (LP) or mixed-integer linear program (MIP). However, in many cases,
there is a need to deal with problems with partial information. Stochastic programming is one such
framework that allows us to incorporate uncertainty into decision-making.

In this work, we focus our attention on Two-stage Stochastic Programs (2SPs). A 2SP involves two
sets of decisions, namely the ﬁrst-stage and second-stage (recourse) decisions, to be made before
and after the uncertainty is realized, respectively. Given the (joint) probability distribution of the
random parameters of the problem, the most common objective of 2SP is to optimize the expected
value of the decisions. For example, in a two-stage stochastic facility location problem, ﬁrst-stage
decisions consist of which facilities should be built whereas second-stage decisions involve assigning
customers to open facilities to meet their stochastic demand, and the overall objective is to minimize
the sum of the cost of the ﬁrst-stage decisions and the expected cost of the second-stage decisions.

2SPs are usually solved via Sample Average Approximation (SAA), which limits the future un-
certainty to a ﬁnite set of possible realizations (scenarios). The SAA approximation of a 2SP is a

∗These authors contributed equally.
†Corresponding author: khalil@mie.utoronto.ca.

36th Conference on Neural Information Processing Systems (NeurIPS 2022).

 
 
 
 
 
 
Figure 1: Overview of Neur2SP. The leftmost block is the input, namely, a 2SP. From the 2SP,
we follow the data generation procedure from Section 4.3 to obtain a dataset consisting of tuples
of (ﬁrst-stage decision, scenario set, corresponding expected second-stage objective value). We
then train one of the learning models presented in Section 4.1 to predict the expected cost given
a ﬁrst-stage decision and scenario set. The trained model is then embedded into a MIP using the
procedure in Section 4.2 to obtain an approximate MIP (the “MIPify” step). Lastly, the approximate
MIP is solved with an off-the-shelf MIP solver to obtain a ﬁrst-stage 2SP solution.

reduction to an equivalent deterministic problem and can be solved by the so-called extensive form: a
monolithic formulation where scenario copies of the second-stage decision variables are created and
linked to the ﬁrst-stage decisions. However, even for small 2SPs, solving the extensive form may
be intractable as it requires introducing a large number of (possibly integer) variables and (possibly
nonlinear) constraints. As such, specialized algorithms are required. If the second-stage problem
assumes the form of an LP, then algorithms such as Benders’ decomposition (also known as the
L-shaped method) can be leveraged to efﬁciently solve the problem to optimality. Unfortunately, in
many practical applications of 2SP, the second-stage problem assumes the form of a MIP, for which
specialized decomposition algorithms might not be efﬁcient. The existence of continuous ﬁrst-stage
variables linked to the second-stage problem signiﬁcantly increases the difﬁculty of solving such
problems. This is exacerbated when the second-stage problem is nonlinear, for which no general and
structure-agnostic solution strategy exists.

In this work, we propose Neur2SP, a framework for constructing an easier-to-solve surrogate op-
timization problem for 2SP with the use of supervised deep learning. In a nutshell, a Rectiﬁed
Linear Unit (ReLU) neural network is trained to approximate the second-stage objective value for
a set of scenarios. Using MIP-representable activation functions such as the ReLU, the forward
computation of the trained network can be embedded into a MIP. The surrogate problem is then
conﬁned to optimizing only ﬁrst-stage decisions with respect to the ﬁrst-stage objective function and
the neural network approximation of the second-stage objective 3. Assuming a small and accurate
neural network can be used, the surrogate problem is much smaller than the extensive form, and
thus faster to solve. The entire procedure is summarized in Figure 1. Our main contributions are as
follows:

1. Novelty: Neur2SP is the ﬁrst generic machine learning approach for deriving a heuristic
solution for 2SP. We introduce a highly parallelizable data collection procedure and show
two separate neural models which can be used to formulate a deterministic mixed-integer
surrogate problem for 2SP;

2. Generality: Neur2SP can be used out-of-the-box for 2SPs with linear and nonlinear objec-
tives and constraints as well as mixed-integer variables in both the ﬁrst and second stages,
all without using any problem structure, i.e., in a purely data-driven way;

3. Performance: Neur2SP is shown to produce high-quality solutions signiﬁcantly faster than
the solely applicable general baseline method, the extensive form approach, for a variety of
benchmark problems, namely, stochastic facility location problem, an investment problem, a
server location problem, and a pooling problem from chemical engineering.

3For a ﬁxed ﬁrst-stage solution obtained via this surrogate, an optimal second-stage decision can be obtained

relatively quickly for each scenario if desired.

2

2 Preliminaries

We introduce the 2SP setting and describe the MIP formulation for a ReLU activation function which
is central to the surrogate model we propose in this work. Appendix A summarizes the notation used.

2.1 Two-stage Stochastic Programming

A 2SP can be generally expressed as minx{c(cid:124)x + Eξ[Q(x, ξ)] : x ∈ X }, where c ∈ Rn is the
ﬁrst-stage cost vector, x ∈ Rn represents the ﬁrst-stage decisions, X is the ﬁrst-stage feasible set,
and ξ is the vector of random parameters that follow a probability distribution P with support Ξ. The
value function Q : X × Ξ → R returns the cost of optimal second-stage (recourse) decisions under
realization ξ given the ﬁrst-stage decisions of x. In many cases, as the Q(x, ξ) is obtained by solving
a mathematical program, evaluating the expected value function Eξ[Q(x, ξ)] is intractable.
To provide a more tractable formulation, the extensive form (EF) is used. Using a set of K sce-
narios, ξ1, . . . , ξK, sampled from the probability distribution P, EF(ξ1, . . . , ξK) ≡ minx{c(cid:124)x +
(cid:80)K
k=1 pkQ(x, ξk) : x ∈ X }, where pk is the probability of scenario ξk being realized.
If
Q(x, ξ) = miny{F (y, ξ) : y ∈ Y(x, ξ)}, then EF(ξ1, . . . , ξK) can be expressed as

(cid:40)

c(cid:124)x +

min
x,y

K
(cid:88)

k=1

pkF (yk, ξk) : x ∈ X , yk ∈ Y(x, ξk) ∀k = 1, . . . , K

(cid:41)
,

which can be solved through standard deterministic optimization techniques. However, the number
of variables and constraints of the EF grows linearly with the number of scenarios. Furthermore,
if Q(·, ·) is the optimal value of a MIP or an nonlinear program (NLP), the EF model becomes
signiﬁcantly more challenging to solve as compared to the LP case, limiting its applicability even at
small scale.

2.2 Embedding Neural Networks into MIPs

Mathematically, an (cid:96)-layer fully-connected neural network can be expressed as: h1 = σ(W 0α + b0);
hm+1 = σ(W mhm + bm), m = 1, . . . , (cid:96) − 1; β = W (cid:96)h(cid:96) + b(cid:96). Here, α ∈ Rm is the input, β ∈ R
is the prediction, hi ∈ Rdi is the i-th hidden layer, W i ∈ Rdi×di+1 is the matrix of weights from
layer i to i + 1, bi ∈ Rdi is the bias at the i-th layer, and σ is a non-linear activation function, here
the activation function is given by ReLU(a) = max{0, a} for a ∈ R.

Central to Neur2SP is the embedding of a trained neural network into a MIP. Here, we present the
formulation proposed by [Fischetti and Jo, 2018]. For a given hidden layer m, the j-th hidden unit,
hm
j , can be written as



dm−1
(cid:88)



hm
j = ReLU



wm−1
ij

hm−1
i

+ bm−1
j

 ,

(1)

i=1
ij is the element at the j-th row and i-th column of W m−1 and bm−1
where wm
bm−1. To model ReLU in a MIP for the j-th unit in the m-th layer, we use the variables ˆhm
ˆhm−1
i

j , ˇhm
for i = 1, . . . , dm−1. The ReLU activation is then modeled with the following constraints:

is the j-th index of
j and

j

dm−1
(cid:88)

i=1

wm−1
ij

ˆhm−1
i

+ bm−1
j

= ˆhm

j − ˇhm
j ,

(2a)

j = 1 ⇒ ˆhm
zm
j ≤ 0,
j = 0 ⇒ ˇhm
zm
j ≤ 0,
ˆhm
j , ˇhm
j ≥ 0,
zm
j ∈ {0, 1},
where the logical constraints in Equation (2b) and Equation (2c) are translated into big-M constraints
by MIP solvers. To verify the correctness of this formulation, observe that constraints (2b) and (2c)
in conjunction with the fact the binary zm
j are non-zero.

j ensures that at most one of ˆhm

j and ˇhm

(2b)

(2d)

(2c)

(2e)

3

Furthermore, since both ˆhm
follows that ˆhm
j > 0 and ˇhm
left-hand side of (2a) is positive, ˆhm
representation of the ReLU function.

j are non-negative, if (cid:80)dm−1

j and ˇhm
j = 0. If negative, then ˆhm

j = 0 and ˇhm

i=1 wm−1

j will be positive; if it is negative, then ˆhm

ˆhm−1
i

+ bm−1
> 0, then it
ij
j
j > 0. Thus, we have that if the
j = 0; this is an exact

3 Related Work

3.1 Machine Learning for Nested Optimization

Machine learning has recently been employed to solve nested optimization problems; by “nested",
we mean optimization problems whose objective or constraints involve another optimization. For
example, Nair et al. [2018], Shen et al. [2021], Jiang et al. [2021], Xiong and Hsieh [2020], Shao
et al. [2022] directly predict a binary or continuous solution vector. The major limitation with
predicting solutions directly is the inability to handle variable integrality and hard constraints.
In addition, only Nair et al. [2018] consider 2SP, whereas the others focus on bi-level problems
with a single inner optimization, rather than the expectation as in stochastic programming. For
stochastic programming, there has been a signiﬁcant interest in the integration of learning to enhance
prevalent solution techniques. We speciﬁcally discuss three areas of related work: learning-enabled
optimization, learning-based algorithms for stochastic programming, and scenario reduction for
stochastic programming.

The line of work on learning-enabled optimization [Deng and Sen, 2022, Liu et al., 2022, Diao and
Sen, 2020] introduced “predictive stochastic programming" to leverage contextual information when
formulating SP models. This is in contrast to our approach, which leverages predictions to reduce
computing times in a non-contextual 2SP setting. That being said, Neur2SP admits extensions to the
contextual setting by including the context information during training.

In recent years, several studies have explored the use of integrating predictions within stochastic
programming algorithms for computational improvements. Donti et al. [2017] proposed an end-to-
end approach to directly optimize a task-loss for contextual stochastic programming problems by
differentiating through the argmin operator, speciﬁcally for strongly convex problems. Dai et al.
[2022] developed a model to solve multi-stage linear optimization problems by learning the piece-
wise value function of the nested problems. Larsen et al. [2022] leveraged predictions to improve an
exact decomposition-based algorithm for 2SP. Neur2SP differs from these approaches as it can be
applied to problems with both hard constraints and integer/non-linear second-stage problems.

Lastly, another related research direction for learning-based stochastic programming is scenario
reduction, which reduces the complexity of the stochastic programming problem by ﬁnding a smaller
set of “representative scenarios". Many of these approaches [Dupaˇcová et al., 2003, Römisch, 2009,
Beraldi and Bruni, 2014, Prochazka and Wallace, 2020, Keutchayan et al., 2021] perform some form
of clustering to reduce the number of scenarios and then solve a smaller surrogate problem with these
scenarios. Recently, Wu et al. [2022] used a conditional variational autoencoder to learn scenario
embeddings and perform clustering on them for scenario reduction. To ﬁnd representative scenarios,
they use semi-supervised learning with respect to the second-stage cost. However, these predictions
are not leveraged explicitly in the optimization as is done with Neur2SP. Bengio et al. [2020] predicts
a representative scenario for an input scenario set and use it to form a smaller surrogate problem.
They show that using the predicted representative scenario, a near-optimal ﬁrst-stage decision can be
obtained by solving the surrogate. However, their method requires some domain expertise as it relies
on the problem structure to build the representative scenario for training.

3.2 Neural Network Embeddings

Neur2SP can be broadly classiﬁed as both a learning-based scenario reduction approach and a
learning-accelerated heuristic for stochastic programming. The reason for this is that Neur2SP reduces
the computational complexity introduced by the scenarios by computing a compact representation
that is then leveraged to formulate an approximation to the EF. We speciﬁcally leverage the recent
line of work by Cheng et al. [2017], Tjeng et al. [2017], Fischetti and Jo [2018], Serra et al. [2018],
which studies the problem of embedding a trained neural network with ReLU activation into a MIP.
The works of Anderson et al. [2020] and Grimstad and Andersson [2019] present MIP encoding

4

Figure 2: NN-E architecture diagram.

formulations with tighter LP relaxations by appropriately setting the big-M constraints, leading to
reduced solving time. The growing interest in embedding predictive models in MIPs has led to the
development of libraries such as JANOS [Bergman et al., 2022] and OMLT [Ceccon et al., 2022]. Say
et al. [2017], Grimstad and Andersson [2019], Murzakhanov et al. [2020], Katz et al. [2020], Kody
et al. [2022] propose the use of embedded neural networks to formulate surrogate MIPs for intractable
and non-linear constraints in optimization problems. To the best of our knowledge, Neur2SP is
the ﬁrst approach that employs this technique in stochastic programming or more generally for the
simpliﬁcation of nested optimization problems.

4 The Neur2SP Framework

In this section, we present two neural architectures, the corresponding surrogate problems that ap-
proximate a given 2SP, and a data collection strategy. Figure 1 summarizes the Neur2SP framework.

4.1 Neural Network Architectures

k=1

We propose two distinct neural architectures for predicting the second-stage costs: NN-E approximates
the expected value of the second-stage cost of a set of scenarios, whereas NN-P approximates the
per-scenario value of the second-stage cost for a single scenario.
(cid:1) → (cid:80)K
NN-E (Figure 2) learns a mapping from (cid:0)x, {ξk}K
k=1 pkQ(x, ξk). In words, the model
takes in a ﬁrst-stage solution x and any ﬁnite set of scenarios sampled from Ξ, and outputs a prediction
of the expected second-stage objective value. We embed the scenario set {ξk}K
k=1 into a latent space
by passing each scenario, independently, through the same neural network Ψ1, then performing mean-
aggregation over the resulting K embeddings. The aggregated embedding is passed through another
network, Ψ2, to obtain the ﬁnal embedding of the scenario set, ξλ. This embedding, representing
the scenario set à-la-DeepSets [Zaheer et al., 2017], is appended to the input ﬁrst-stage decision
and passed through a ReLU feed-forward network ΦE to predict the expected second-stage value.
Hence, the ﬁnal output is such that ΦE(x, Ψ2(⊕K
k=1 pkQ(x, ξk). Note that
the embedding networks, Ψ1 and Ψ2, can be arbitrarily complex as only the latent representation
is embedded into the approximate MIP. Also, although Ψ1 is trained using K scenarios, once the
networks are trained, they can be used with any (potentially much larger) ﬁnite number of scenarios.
NN-P learns a mapping ΦP from (x, ξ) → Q(x, ξ) for ξ sampled from Ξ. Once the mapping
ΦP is learned, we can approximate the expected second-stage objective value for any ﬁnite set of
scenarios as (cid:80)K
k=1 pkΦP (x, ξk). ΦP is a feed-forward neural network with
input given by the concatenation of x and ξ.

k=1Ψ1(pk, ξk))) ≈ (cid:80)K

k=1 pkQ(x, ξk) ≈ (cid:80)K

4.2 Neural Network Embedding for 2SP

We now describe the surrogate MIP for both the NN-E and NN-P learning models from the preceding
section. Let Λ represent the number of predictions made by the neural network. For the NN-E case,

5

Λ = 1 as we only predict the expected second-stage value for a set of scenarios. In the NN-P case,
Λ = K as we predict the second-stage value for each scenario. In this section, we use [M ] to denote
{1, . . . , M } for M ∈ Z+.
Let ˆhm,λ
represent the ReLU output for the j-th hidden unit in the m-th hidden layer for output λ, for
j
all m ∈ [(cid:96) − 1], j ∈ [dm], and λ ∈ [Λ]. Suppose ˇhm,λ
is a slack variable used to model the ReLU
output for the j-th hidden unit in the m-th hidden layer for scenario k, for all m ∈ [(cid:96) − 1], j ∈ [dm],
and λ ∈ [Λ]. Let zm,λ
are
non-zero. This variable is deﬁned for all m ∈ [(cid:96) − 1], j ∈ [dm], and λ ∈ [Λ]. Suppose βλ is the λ-th
prediction by the neural network, for all λ ∈ [Λ].

be a binary variable used to ensure that at most one of ˆhm,k

and ˇhm,k

j

j

j

j

With the above variables we can deﬁne an approximation to EF as given in Equation (3). The objective
function (3a) minimizes the sum of the cost of the ﬁrst-stage decisions and the approximate cost of
the second-stage value. Constraints (3b)-(3d) propagate a ﬁrst-stage solution x to the output of the
neural network for each scenario. Constraints (3e)-(3h) ensure the prediction of the neural network is
respected. Constraint (3i) ensures the feasibility of the ﬁrst-stage solution.

. In addition, we introduce 2 · Λ · H continuous variables for ˆhm,λ

In this approximation, we introduce a number of additional variables and big-M constraints. Specif-
ically, for a neural network with H hidden units, we introduce Λ · H additional binary variables
for zm,λ
. Lastly, we
j
require an additional Λ variables for the output of the network. Although the number of variables we
introduce in this approximation is quite large, we hypothesize that the resulting MIP will be easier
to solve than the extensive form, in particular, when the second-stage problem is nonlinear. In the
remainder of the paper, we refer to the surrogate MIP given in (3) as MIP-NN.

and ˇhm,λ
j

j

min c(cid:124)x +

Λ
(cid:88)

λ=1

pλβλ

d0(cid:88)

s.t.

w0

ij[x, ξλ]i + b0

j = ˆh1,λ

j − ˇh1,λ

j

= ˆhm,λ

j − ˇhm,λ

j

i=1

dm−1
(cid:88)

i=1

wm−1
ij

ˆhm−1,λ
i

+ bm−1
j

d(cid:96)(cid:88)

w(cid:96)
ij

ˆh(cid:96),λ
i + b(cid:96) ≤ βλ

j = 0
j = 0

i=1
j = 1 ⇒ ˆhm,λ
zm,λ
j = 0 ⇒ ˇhm,λ
zm,λ
zm,λ
∈ {0, 1}
j
, ˇhm,λ
ˆhm,λ
j
x ∈ X

j ≥ 0

(3a)

∀ j ∈ [d1], λ ∈ [Λ],

(3b)

∀ m ∈ [(cid:96) − 1], j ∈ [dm], λ ∈ [Λ],

(3c)

∀λ ∈ [Λ],

(3d)

∀ m ∈ [(cid:96) − 1], j ∈ [dm], λ ∈ [Λ],

(3e)

∀ m ∈ [(cid:96) − 1], j ∈ [dm], λ ∈ [Λ],

(3f)

∀ m ∈ [(cid:96) − 1], j ∈ [dm], λ ∈ [Λ],

(3g)

∀ m ∈ [(cid:96) − 1], j ∈ [dm], λ ∈ [Λ],

(3h)

(3i)

4.3 Data Generation

A diverse dataset of input-output pairs is needed to train Neur2SP’s supervised second-stage value
approximation. To generate such a dataset for a given 2SP problem, we adopt an iterative procedure.
We begin by generating a random feasible ﬁrst-stage decision. For the NN-E case, we sample a
set of scenarios with random cardinality K (cid:48) from the uncertainty distribution. Here, K (cid:48) should be
chosen to balance the trade-off between the time spent to generate a sample of second-stage values
for a given ﬁrst-stage solution and the time to estimate the expected second-stage value for a set of
ﬁrst-stage decisions in a given time budget. Speciﬁcally, if K (cid:48) is large, then on average more time
will be spent in determining the expected value using a large number of scenarios, while for a small
K (cid:48), the ﬁrst-stage decision space will be explored more since expected value estimates would be

6

Problem First stage

Second Stage

Objective Constraints Objective Sense

CFLP
INVP
SSLP
PP

Binary
Binary
Continuous Binary
Binary
Binary
Continuous
Binary

Linear
Linear
Linear
Bilinear

Linear
Linear
Linear
Bilinear

Minimization
Minimization
Minimization
Maximization

Table 1: Problem class characteristics.

obtained faster. For a given input, i.e., a ﬁrst-stage decision and set of scenarios, we then compute a
label by calculating the expected second-stage value (cid:80)K(cid:48)
For the NN-P case, at each iteration of the data generation procedure, we sample a single scenario
from the uncertainty distribution. For a given input of a ﬁrst-stage decision and scenario we generate
a label by calculating its second-stage value Q(·, ·). Last, the input-output pair is added to the dataset.

k(cid:48)=1 pk(cid:48)Qk(cid:48)(·, ξk(cid:48)).

This data generation procedure is fully parallelizable over the second-stage problems to be solved.

4.4 NN-E vs. NN-P Trade-offs

The NN-E and NN-P architectures exhibit trade-offs in terms of the learning task and the resulting
surrogate optimization problem.

Training.
In data collection, both models require solving second-stage problems with a ﬁxed ﬁrst-
stage solution to obtain the label. A sample in for NN-P requires solving only a single optimization
problem, whereas a sample for NN-E requires solving at most K (cid:48) second-stage problems. As this
process is ofﬂine and highly parallelizable, this trade-off is easy to mitigate. As for training, NN-E
operates on a subset of scenarios which makes for an exponentially larger input space. Despite the
large input space, our experiments show that the NN-E model in the training converges quite well
and in many cases the embedded model outperforms the NN-P model.

Surrogate Optimization Problem. As the ultimate goal is embedding the trained model into a
MIP, the trade-off in this regard becomes quite important. Speciﬁcally, for K scenarios, the NN-P
model will have K times more binary and continuous variables than the NN-E model. For problems
with a large number of scenarios, this makes the NN-E model much more appealing, smaller and
likely faster to solve. Furthermore, it allows for much larger networks given that only a single copy
of the network is embedded.

5 Experimental Setup

All experiments were run on a computing cluster with an Intel Xeon CPU E5-2683 and Nvidia Tesla
P100 GPU with 64GB of RAM (for training). Gurobi 9.1.2 [Gurobi Optimization, LLC, 2021] was
used as the MIP solver. Scikit-learn 1.0.1 [Pedregosa et al., 2011] and Pytorch 1.10.0 [Paszke et al.,
2019] were used for supervised learning. The code to reproduce all of the experiments is available at
https://github.com/khalil-research/Neur2SP.

2SP Problems: We evaluate our approach on four 2SP problems that are commonly considered in the
literature: a two-stage stochastic variant of the Capacitated Facility Location Problem (CFLP) [Cor-
nuéjols et al., 1991], an Investment Problem (INVP) [Schultz et al., 1998], the Stochastic Server
Location Problem (SSLP) [Ntaimo and Sen, 2005], and the Pooling Problem (PP) [Audet et al., 2004,
Gupte et al., 2017, Gounaris et al., 2009, Haverly, 1978]. Table 1 summarizes the types of ﬁrst and
second-stage variables for these problems and Appendix B includes their detailed descriptions.

Baselines: We consider two baselines. The ﬁrst is EF, which is perhaps the only generic approach
that can be applied for both integer and nonlinear second-stage problems. We limit the solving time
of EF to 3 hours. Additionally, we compare against an embedded trained linear regressor rather
than a neural network, but defer these results to Appendix D as the solution quality is quite poor in
comparison to the neural network models.

Model & Dataset Selection : As is common in supervised learning, model selection and the size of
the training set can have a signiﬁcant impact on model performance. We present detailed experiments

7

Problem

Data Generation Time

Training Time

Total Time

NN-E

NN-P

NN-E

CFLP_10_10
CFLP_25_25
CFLP_50_50

SSLP_10_50
SSLP_15_45
SSLP_5_25

INVP_B_E
INVP_B_H
INVP_I_E
INVP_I_H

PP

1,823.07
4,148.83
7,697.91

942.10
929.27
860.74

8,951.27
9,207.90
8,759.83
8,944.65

1,202.11

13.59
112.83
135.57

22.95
16.35
13.18

4.17
4.22
4.34
3.32

667.28
2,205.23
463.71

708.86
1,377.21
734.02

344.87
1,214.54
2,115.25
393.82

NN-P

127.12
840.07
128.11

116.17
229.42
147.44

NN-E

NN-P

2,490.35
6,354.06
8,161.62

1,650.96
2,306.48
1,594.75

140.71
952.90
263.68

139.13
245.77
160.62

1,000.14
607.49
680.93
174.26

9,296.13
10,422.43
10,875.08
9,338.47

1,004.31
611.71
685.27
177.58

14.86

576.08

367.25

1,778.19

382.11

Table 2: Computing times (in seconds) for data generation and training. Data was generated in
parallel with 43 processes.

for model selection and dataset sizing in Appendix F. As a brief summary, we use random search over
100 hyperparameter conﬁgurations for model selection, and observe that accuracy on a validation set
is rather insensitive to hyperparameter choices. For the size of the dataset, we observe diminishing
returns when increasing the size beyond 5000 samples.

Data Generation & Supervised training times : As the data generation and training can be done
ofﬂine and are both parallelizable, we report the total times in Table 2 and defer more speciﬁc timing
details to Appendix C. We note that for data generation, a single sample can be obtained in less than
two seconds for all instances, and in many cases much faster. The training times are within the range
of 120 to 2100 seconds. For the NN-E data generation, we choose K (cid:48) = 100, a number of scenarios
which was quick to label while exposing the model to a reasonably large number of scenarios in some
cases. The combined time for data generation and model training is typically less than 3 hours (i.e.,
the time given to EF) and depending on the problem, may be much less.

6 Results & Discussion

In this section, we report the results of Neur2SP across the four problem settings. As is standard in
2SP, we evaluate a single “base” instance across varying scenario sets and sizes. For example, in
CFLP, and for a “base” instance with 10 facilities and 10 customers, one can generate an instance by
sampling any number of scenarios. An important advantage of our approach is that we can apply a
single trained model to an instance with an arbitrary number of scenarios. For example, the same
trained model is used for CFLP_10_10_{100,500,1000}.

Tables 3 through 6 report the gaps between approaches, solving times, and the time which EF takes to
achieve the same solution quality as NN-E and NN-P. In addition, we include supplementary results
with the objective values in Appendix D and non-aggregated results for the SSLP SIPLib instances in
Appendix E. For SSLP and CFLP, each row represents mean statistics across 11 and 10 instances
generated by sampling different scenario sets of a given size, respectively. However, for INVP and
PP, each row represents the statistics across 1 instance. Originally, both these problems have inﬁnite
support as the uncertainty distributions are assumed to be continuous. To manage the complexity,
these distributions are typically transformed to have ﬁnite support by uniformly sampling equidistant
points over the continuous domain. We adopt this same procedure from the literature, leading to a
static set of scenarios for a given scenario set size.

6.1 Discussion

Tables 3–6 show that NN-E is signiﬁcantly faster than other approaches, with a minimum and
maximum solving time of 0.11s and 1.66s respectively, across all problems. This highlights the
scalability of the NN-E in terms of problem size and type, which is expected as the size of the
resulting MIP is independent of the number of scenarios. Also, the objective difference is less than
5% in most cases, with a minimum of -102% and a maximum of 13.78%. These differences are
inversely proportional to the scenario set size, which indicates that the NN-E is able to generalize on
larger scenario sets, even though it was trained with a maximum of 100 scenarios per data point. EF

8

Problem

Obj. Difference (%)

Solving Time

EF time to

EF-NN-E EF-NN-P NN-E

NN-P

EF

NN-E

CFLP_10_10_100
CFLP_10_10_500
CFLP_10_10_1000
CFLP_25_25_100
CFLP_25_25_500
CFLP_25_25_1000
CFLP_50_50_100
CFLP_50_50_500
CFLP_50_50_1000

2.58
2.41
0.94
-0.75
-3.62
-1.32
-0.43
-9.58
-16.62

1.65
0.94
-0.67
-0.75
-3.62
-1.32
-1.29
-10.71
-17.50

0.38
0.60
0.64
0.44
0.54
0.58
1.66
1.25
1.44

8.28
206.30
856.77
4.86
26.41
54.45
21.10
173.63
572.12

4,410.60
10,800.17
10,800.87
10,800.06
10,800.14
10,800.36
10,800.05
10,806.15
10,805.82

8.87
415.89
580.50
-
-
-
5,637.98
-
-

(0)
(0)
(0)
(10)
(10)
(10)
(6)
(10)
(10)

NN-P

12.69
2,034.73
7,551.00
-
-
-
2,334.04
-
-

(0)
(0)
(8)
(10)
(10)
(10)
(9)
(10)
(10)

Table 3: CFLP results: each row represents an average over ten 2SP instances with varying scenario
sets. “Obj. Difference” for method EF-{NN-E, NN-P} is the percent relative objective value of
{NN-E, NN-P} to EF; a negative (positive) value of −g% (g%) indicates that {NN-E, NN-P} ﬁnds a
solution that is g% better (worse) than EF’s for the minimization problem. “Solving Time” is the time
in which {NN-E, NN-P, EF} are solved to optimality. A time of ∼10,800 implies that the solving
limit was reached. “EF time to” is the time in which EF achieves a solution of the same quality as
{NN-E, NN-P}. To the right in parentheses is the number of instances for which EF failed to ﬁnd a
solution that is as good as {NN-E, NN-P}. If EF did not ﬁnd any feasible solution, then the entry is
left as “-”. All times are in seconds.

Problem

Obj. Difference (%)

Solving Time

EF time to

EF-NN-E EF-NN-P NN-E

NN-P

EF

NN-E

SSLP_10_50_50
SSLP_10_50_100
SSLP_10_50_500
SSLP_10_50_1000
SSLP_10_50_2000
SSLP_15_45_5
SSLP_15_45_10
SSLP_15_45_15
SSLP_5_25_50
SSLP_5_25_100

0.00
-0.00
-0.00
-55.21
-102.69
3.10
2.98
2.53
0.12
0.02

0.00
-0.00
-0.00
-55.21
-102.69
18.71
18.47
18.90
1.78
1.60

0.11
0.11
0.14
0.13
0.14
0.32
0.31
0.33
0.20
0.18

5.83
13.09
129.44
466.38
2,182.31
0.34
0.58
0.86
1.14
1.83

10,800.48
10,800.21
10,802.82
10,800.47
10,800.17
2.54
1,976.62
2,052.76
2.24
8.43

228.06
145.35
7,359.85
-
-
0.75
2.72
1.84
1.94
8.04

(0)
(0)
(4)
(11)
(11)
(0)
(0)
(0)
(0)
(0)

NN-P

228.06
145.35
7,359.85
-
-
0.12
0.20
0.34
1.97
7.75

(0)
(0)
(4)
(11)
(11)
(0)
(0)
(0)
(0)
(1)

Table 4: SSLP results: each row represents an average over eleven 2SP instances with varying
scenario sets, one of which being the instance from Ahmed et al. [2015]. Columns are as in Table 3.

takes signiﬁcantly longer to reach a solution quality similar to NN-E, often on the order of minutes to
3 hours. For many larger CFLP and SSLP instances, EF ﬁnds worse solutions than NN-E even after 3
hours. Not only is NN-E as good or better in solution quality, but also orders of magnitude faster.

For the NN-P, we can observe that the solving time is directly proportional to the size of the problem.
However, for the largest INVP instances, it times out without even generating a feasible solution
(Table 5). This is expected as we need to embed the trained neural network once per scenario, limiting
scalability. In terms of objective differences, we can observe that the difference improves with the
increase in instance size for CFLP and SSLP, whereas no clear trend is visible for For INVP. However,
the objective differences do not exceed 5% in most cases. For PP, the objective difference is around
40%, indicating that the NN-P is not able to generalize, whereas NN-E performs very well. One
important advantage for NN-P over NN-E is the fact that the time required for data generation and
training is notably less. In settings with limited parallel computing resources or time NN-P may be a
more appropriate choice.

7 Conclusion

Two-stage stochastic programming is a powerful modeling framework for decision-making under
uncertainty. These problems are hard to solve in practice, especially when the second-stage problem
is a MIP or NLP. Finding good feasible solutions quickly thus becomes extremely important.

To that end, we proposed Neur2SP, a learning-based, general, and structure-agnostic approach which
approximates the second-stage value function to form an easy-to-solve surrogate problem. The four
problem classes we have tackled are (1) widely used in the literature, (2) vary in the types of ﬁrst and
second-stage problems, and (3) span a wide range in terms of number of variables, constraints, and
scenarios. Through our experiments, we show that Neur2SP achieves high-quality solutions quickly,
especially for larger instances. In 1–2 seconds, a model trained in the Neur2SP framework can ﬁnd

9

Problem

Obj. Difference (%)

Solving Time

EF time to

EF-NN-E EF-NN-P NN-E

NN-P

EF NN-E

NN-P

INVP_B_E_4
INVP_B_E_9
INVP_B_E_36
INVP_B_E_121
INVP_B_E_441
INVP_B_E_1681
INVP_B_E_10000
INVP_B_H_4
INVP_B_H_9
INVP_B_H_36
INVP_B_H_121
INVP_B_H_441
INVP_B_H_1681
INVP_B_H_10000
INVP_I_E_4
INVP_I_E_9
INVP_I_E_36
INVP_I_E_121
INVP_I_E_441
INVP_I_E_1681
INVP_I_E_10000
INVP_I_H_4
INVP_I_H_9
INVP_I_H_36
INVP_I_H_121
INVP_I_H_441
INVP_I_H_1681
INVP_I_H_10000

9.54
7.54
2.72
1.37
2.80
1.36
-1.48
8.81
5.04
1.61
1.77
2.13
-0.71
-2.72
12.83
7.40
5.48
5.30
3.00
1.31
-1.35
13.78
9.12
4.97
4.01
3.15
-0.34
-1.60

3.01
2.00
4.96
2.42
2.43
-
-
9.50
5.04
1.61
1.77
5.50
-
-
0.00
2.64
5.17
4.49
0.68
3.08
-
12.16
0.81
3.44
4.99
3.15
0.11
-

0.36
0.31
0.30
0.33
0.37
0.34
0.36
0.46
0.30
0.26
0.33
0.28
0.36
0.36
0.38
0.27
0.27
0.29
0.26
0.26
0.30
0.35
0.37
0.36
0.32
0.32
0.33
0.38

0.34
0.53
9.53
86.42
4,342.19
-
-
0.25
0.57
6.79
45.89
1,870.42
-
-
0.23
0.35
1.39
49.51
2,049.93
10,834.53
-
0.21
0.31
1.99
23.10
1,231.48
10,816.89
-

0.02
0.04
0.08
1.69
117.59
10,800.01
10,803.98
0.01
0.03
1.29
34.69
217.46
10,800.01
10,800.03
0.01
0.06
0.04
1.65
46.92
10,800.00
10,800.10
0.02
0.03
1.27
7.43
10,800.00
10,800.03
10,802.10

0.02
0.03
0.02
0.06
0.78
17.41
-
0.01
0.02
0.01
0.01
2.21
-
-
0.01
0.01
0.01
0.02
0.08
0.41
-
0.01
0.01
0.03
0.07
0.33
-
-

0.02
0.03
0.02
0.02
1.15
0.00
0.00
0.01
0.02
0.01
0.01
0.21
0.00
0.00
0.01
0.02
0.01
0.03
0.10
0.41
0.00
0.01
0.02
0.03
0.07
0.33
252.70
0.00

Table 5: INVP results: each row represents a single instances. Columns are as in Table 3.

Problem

Obj. Difference (%)

Solving Time

EF time to

EF-NN-E EF-NN-P NN-E

NN-P

EF

NN-E

NN-P

PP_125
PP_216
PP_343
PP_512
PP_729
PP_1000

3.25
9.06
0.67
8.69
1.38
5.92

36.64
40.14
40.85
39.77
37.98
41.32

1.51
1.47
1.46
1.60
1.62
1.49

144.08
254.94
570.64
1,200.37
3,440.19
10,853.59

10,800.00
364.98
10,800.00
10,800.01
10,800.01
10,800.00

10,717.05
59.79
1,450.54
167.77
5,867.67
1,596.22

2.48
3.59
9.12
13.80
36.34
210.48

Table 6: PP results: each row represents a single instances. Columns are as in Table 3.

solutions of the same or better quality than the most generic method in the literature, EF, with the
latter taking minutes to hours.

In terms of future work, this methodology can be extended in many directions. Further innovations
in the NN-E model architecture may improve our already positive results. Another direction is the
extension of the general idea of embedding trained models into other complex optimization problems,
such as bilevel optimization or multi-stage stochastic programming.

Another direction for future work is a more comprehensive comparison of Neur2SP with algorithms
that are specialized to a given problem class. However, we note that on SSLP instances, the computing
times of progressive hedging [Rockafellar and Wets, 1991], a widely used heuristic for 2SP, is on the
order of hours [Torres et al., 2022]. These experiments are not directly comparable as they were run
on different hardware. However, this would not meaningfully impact the several order of magnitude
reduction in solving time achieved by our approach.

Lastly, in this work, we propose NN-E and NN-P, however, a natural middle ground between these
models is a clustering approach which embeds a trained model for a subset of scenarios, rather than a
single or the entire scenario set at evaluation time.

Acknowledgments: Bodur would like to acknowledge support from an NSERC Discovery Grant.
Dumouchelle, Patel, and Khalil acknowledge support from the Scale AI Research Chair Program and
an NSERC Discovery Grant.

10

References

Matteo Fischetti and Jason Jo. Deep neural networks and mixed integer linear optimization. Con-

straints, 23(3):296–309, 2018.

Vinod Nair, Dj Dvijotham, Iain Dunning, and Oriol Vinyals. Learning fast optimizers for contextual

stochastic integer programs. In UAI, pages 591–600, 2018.

Jiayi Shen, Xiaohan Chen, Howard Heaton, Tianlong Chen, Jialin Liu, Wotao Yin, and Zhangyang
Wang. Learning a minimax optimizer: A pilot study. In International Conference on Learning
Representations, 2021. URL https://openreview.net/forum?id=nkIDwI6oO4_.

Haoming Jiang, Zhehui Chen, Yuyang Shi, Bo Dai, and Tuo Zhao. Learning to defend by learning to
attack. In Arindam Banerjee and Kenji Fukumizu, editors, Proceedings of The 24th International
Conference on Artiﬁcial Intelligence and Statistics, volume 130 of Proceedings of Machine
Learning Research, pages 577–585. PMLR, 13–15 Apr 2021. URL https://proceedings.mlr.
press/v130/jiang21a.html.

Yuanhao Xiong and Cho-Jui Hsieh. Improved adversarial training via learned optimizer. In Andrea
Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm, editors, Computer Vision – ECCV
2020, pages 85–100, Cham, 2020. Springer International Publishing.

Zhihui Shao, Jianyi Yang, Cong Shen, and Shaolei Ren. Learning for robust combinatorial opti-
mization: Algorithm and application. In IEEE INFOCOM 2022 - IEEE Conference on Computer
Communications, pages 930–939, 2022. doi: 10.1109/INFOCOM48880.2022.9796715.

Yunxiao Deng and Suvrajeet Sen. Predictive stochastic programming. Computational Management

Science, 19(1):65–98, 2022.

Junyi Liu, Guangyu Li, and Suvrajeet Sen. Coupled learning enabled stochastic programming with

endogenous uncertainty. Mathematics of Operations Research, 47(2):1681–1705, 2022.

Shuotao Diao and Suvrajeet Sen. Distribution-free algorithms for learning enabled optimization with

non-parametric estimation. Management Science, 66(3):1025–1044, 2020.

Priya Donti, Brandon Amos, and J Zico Kolter. Task-based end-to-end model learning in stochastic

optimization. Advances in Neural Information Processing Systems, 30, 2017.

Hanjun Dai, Yuan Xue, Zia Syed, Dale Schuurmans, and Bo Dai. Neural stochastic dual dynamic
programming. In International Conference on Learning Representations, 2022. URL https:
//openreview.net/forum?id=aisKPsMM3fg.

Eric Larsen, Emma Frejinger, Bernard Gendron, and Andrea Lodi. Fast continuous and integer

L-shaped heuristics through supervised learning. arXiv preprint arXiv:2205.00897, 2022.

Jitka Dupaˇcová, Nicole Gröwe-Kuska, and Werner Römisch. Scenario reduction in stochastic

programming. Mathematical Programming, 95(3):493–511, 2003.

Werner Römisch. Scenario reduction techniques in stochastic programming.

In International

Symposium on Stochastic Algorithms, pages 1–14. Springer, 2009.

Patrizia Beraldi and Maria Elena Bruni. A clustering approach for scenario tree reduction: an
application to a stochastic programming portfolio optimization problem. Top, 22(3):934–949,
2014.

Vit Prochazka and Stein W Wallace. Scenario tree construction driven by heuristic solutions of the

optimization problem. Computational Management Science, 17(2):277–307, 2020.

Julien Keutchayan, Janosch Ortmann, and Walter Rei. Problem-driven scenario clustering in stochastic

optimization. arXiv preprint arXiv:2106.11717, 2021.

Yaoxin Wu, Wen Song, Zhiguang Cao, and Jie Zhang. Learning scenario representation for solving
two-stage stochastic integer programs. In International Conference on Learning Representations,
2022. URL https://openreview.net/forum?id=06Wy2BtxXrz.

11

Yoshua Bengio, Emma Frejinger, Andrea Lodi, Rahul Patel, and Sriram Sankaranarayanan. A
learning-based algorithm to quickly compute good primal solutions for stochastic integer programs.
In International Conference on Integration of Constraint Programming, Artiﬁcial Intelligence, and
Operations Research, pages 99–111. Springer, 2020.

Chih-Hong Cheng, Georg Nührenberg, and Harald Ruess. Maximum resilience of artiﬁcial neural
networks. In International Symposium on Automated Technology for Veriﬁcation and Analysis,
pages 251–268. Springer, 2017.

Vincent Tjeng, Kai Xiao, and Russ Tedrake. Evaluating robustness of neural networks with mixed

integer programming. arXiv preprint arXiv:1711.07356, 2017.

Thiago Serra, Christian Tjandraatmadja, and Srikumar Ramalingam. Bounding and counting linear
In International Conference on Machine Learning, pages

regions of deep neural networks.
4558–4566. PMLR, 2018.

Ross Anderson, Joey Huchette, Will Ma, Christian Tjandraatmadja, and Juan Pablo Vielma. Strong
mixed-integer programming formulations for trained neural networks. Mathematical Programming,
pages 1–37, 2020.

Bjarne Grimstad and Henrik Andersson. ReLU networks as surrogate models in mixed-integer linear

programs. Computers & Chemical Engineering, 131:106580, 2019.

David Bergman, Teng Huang, Philip Brooks, Andrea Lodi, and Arvind U Raghunathan. JANOS: an
integrated predictive and prescriptive modeling framework. INFORMS Journal on Computing, 34
(2):807–816, 2022.

Francesco Ceccon, Jordan Jalving, Joshua Haddad, Alexander Thebelt, Calvin Tsay, Carl D Laird, and
Ruth Misener. OMLT: Optimization & machine learning toolkit. arXiv preprint arXiv:2202.02414,
2022.

Buser Say, Ga Wu, Yu Qing Zhou, and Scott Sanner. Nonlinear hybrid planning with deep net learned

transition models and mixed-integer linear programming. In IJCAI, pages 750–756, 2017.

Ilgiz Murzakhanov, Andreas Venzke, George S Misyris, and Spyros Chatzivasileiadis. Neu-
ral networks for encoding dynamic security-constrained optimal power ﬂow. arXiv preprint
arXiv:2003.07939, 2020.

Justin Katz, Iosif Pappas, Styliani Avraamidou, and Efstratios N. Pistikopoulos. The integration
of explicit MPC and ReLU based neural networks. IFAC-PapersOnLine, 53(2):11350–11355,
ISSN 2405-8963. doi: https://doi.org/10.1016/j.ifacol.2020.12.544. URL https://
2020.
www.sciencedirect.com/science/article/pii/S2405896320308429. 21st IFAC World
Congress.

Alyssa Kody, Samuel Chevalier, Spyros Chatzivasileiadis, and Daniel Molzahn. Modeling the AC
power ﬂow equations with optimally compact neural networks: Application to unit commitment.
Electric Power Systems Research, 213:108282, 2022. ISSN 0378-7796. doi: https://doi.org/10.
1016/j.epsr.2022.108282. URL https://www.sciencedirect.com/science/article/pii/
S0378779622004771.

Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabás Póczos, Ruslan Salakhutdinov,
and Alexander J. Smola. Deep sets.
In Isabelle Guyon, Ulrike von Luxburg, Samy Ben-
gio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett, edi-
tors, Advances in Neural Information Processing Systems 30: Annual Conference on Neu-
ral Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA,
pages 3391–3401, 2017. URL https://proceedings.neurips.cc/paper/2017/hash/
f22e4747da1aa27e363d86d40ff442fe-Abstract.html.

Gurobi Optimization, LLC. Gurobi Optimizer Reference Manual, 2021. https://www.gurobi.com.

F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Pretten-
hofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and
E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research,
12:2825–2830, 2011.

12

Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward
Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,
Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An imperative style, high-performance
deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and
R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 8024–8035.
Curran Associates, Inc., 2019. http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-
high-performance-deep-learning-library.pdf.

Gérard Cornuéjols, Ranjani Sridharan, and Jean-Michel Thizy. A comparison of heuristics and
relaxations for the capacitated plant location problem. European Journal of Operational Research,
50(3):280–297, 1991.

Rüdiger Schultz, Leen Stougie, and Maarten H Van Der Vlerk. Solving stochastic programs with
integer recourse by enumeration: A framework using Gröbner basis. Mathematical Programming,
83(1):229–252, 1998.

Lewis Ntaimo and Suvrajeet Sen. The million-variable “march” for stochastic combinatorial opti-

mization. Journal of Global Optimization, 32(3):385–400, 2005.

Charles Audet, Jack Brimberg, Pierre Hansen, Sébastien Le Digabel, and Nenad Mladenovi´c. Pooling
problem: Alternate formulations and solution methods. Management Science, 50(6):761–776,
2004.

Akshay Gupte, Shabbir Ahmed, Santanu S Dey, and Myun Seok Cheon. Relaxations and discretiza-

tions for the pooling problem. Journal of Global Optimization, 67(3):631–669, 2017.

Chrysanthos E Gounaris, Ruth Misener, and Christodoulos A Floudas. Computational comparison of

piecewise-linear relaxations for pooling problems. 48(12):5742–5766, 2009.

Co A Haverly. Studies of the behavior of recursion for the pooling problem. Acm sigmap bulletin,

(25):19–28, 1978.

Shabbir Ahmed, R Garcia, N Kong, L Ntaimo, G Parija, F Qiu, and S Sen. SIPLIB: A stochastic inte-
ger programming test problem library. https://www2.isye.gatech.edu/~sahmed/siplib/,
2015.

R Tyrrell Rockafellar and Roger J-B Wets. Scenarios and policy aggregation in optimization under

uncertainty. Mathematics of operations research, 16(1):119–147, 1991.

Juan J Torres, Can Li, Robert M Apap, and Ignacio E Grossmann. A review on the performance of
linear and mixed integer two-stage stochastic programming software. Algorithms, 15(4):103, 2022.

Niels van der Laan and Ward Romeijnders. A loose Benders decomposition algorithm for approxi-
mating two-stage mixed-integer recourse models. Mathematical Programming, 190(1):761–794,
2021.

Xiang Li, Emre Armagan, Asgeir Tomasgard, and Paul I Barton. Stochastic pooling problem for
natural gas production network design and operation under uncertainty. AIChE Journal, 57(8):
2120–2135, 2011.

13

Checklist

The checklist follows the references. Please read the checklist guidelines carefully for information on
how to answer these questions. For each question, change the default [TODO] to [Yes] , [No] , or
[N/A] . You are strongly encouraged to include a justiﬁcation to your answer, either by referencing
the appropriate section of your paper or providing a brief inline description. For example:

• Did you include the license to the code and datasets? [Yes] See Section ??.
• Did you include the license to the code and datasets? [No] The code and the data are

proprietary.

• Did you include the license to the code and datasets? [N/A]

Please do not modify the questions and only use the provided macros for your answers. Note that the
Checklist section does not count towards the page limit. In your paper, please delete this instructions
block and only keep the Checklist section heading above along with the questions/answers below.

1. For all authors...

(a) Do the main claims made in the abstract and introduction accurately reﬂect the paper’s

contributions and scope? [Yes]

(b) Did you describe the limitations of your work? [Yes]
(c) Did you discuss any potential negative societal impacts of your work? [N/A]
(d) Have you read the ethics review guidelines and ensured that your paper conforms to

them? [Yes]

2. If you are including theoretical results...

(a) Did you state the full set of assumptions of all theoretical results? [N/A]
(b) Did you include complete proofs of all theoretical results? [N/A]

3. If you ran experiments...

(a) Did you include the code, data, and instructions needed to reproduce the main experi-
mental results (either in the supplemental material or as a URL)? [Yes] All code to
reproduce the experiments is available at https://anonymous.4open.science/r/
neural_stochastic_programming-437E.

(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they

were chosen)? [Yes]

(c) Did you report error bars (e.g., with respect to the random seed after running experi-
ments multiple times)? [Yes] The both training and evaluation are done over varying
conﬁgurations and realizations of randomness.

(d) Did you include the total amount of compute and the type of resources used (e.g., type
of GPUs, internal cluster, or cloud provider)? [Yes] These are detailed in Section 5 and
the Appendix.

4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
(a) If your work uses existing assets, did you cite the creators? [Yes] All software used in

the development has been cited

(b) Did you mention the license of the assets? [N/A]
(c) Did you include any new assets either in the supplemental material or as a URL? [N/A]

(d) Did you discuss whether and how consent was obtained from people whose data you’re

using/curating? [N/A]

(e) Did you discuss whether the data you are using/curating contains personally identiﬁable

information or offensive content? [N/A]

5. If you used crowdsourcing or conducted research with human subjects...

(a) Did you include the full text of instructions given to participants and screenshots, if

applicable? [N/A]

(b) Did you describe any potential participant risks, with links to Institutional Review

Board (IRB) approvals, if applicable? [N/A]

(c) Did you include the estimated hourly wage paid to participants and the total amount

spent on participant compensation? [N/A]

14

A Symbols

List of symbols used in the paper with their brief description.

Two-stage stochastic program

x
c
K
k
ξk
pk
n
Q(x, ξ)
F (x, ξ)
X
Y(x, ξ)

First-stage decision vector
First-stage objective coefﬁcient vector
EF scenario set size
Scenario index
kth scenario realization
Probability of scenario k
Dimension of x
Second-stage sub-problem for ﬁrst-stage decision x and scenario ξ
Second-stage cost for ﬁrst-stage decision x and scenario ξ
Constraint set exclusively on the ﬁrst-stage decision
Scenario-speciﬁc constraint set for ﬁrst-stage decision x and scenario ξ

(cid:96)
m
d0
dm
α
β
W
b
σ
hm
i
j
Φ1
Φ2
ΨE
ΨP

ˆh
ˇh
z
Λ
[M ]

Neural network

Number of layers in the network
Index over the neural network layers
Dimensionality of input layer
Dimensionality of layer m
Input to the neural network
Output of the neural network
Weight matrix
Bias
Activation function
mth hidden layer
Index over the column of weight matrix
Index over the row of weight matrix
Scenario-encoding network
Post scenario-aggregation network
Scenario-embedding network for NN-E
Scenario-embedding network for NN-P

MIP-NN

Non-negative ReLU input
Negative ReLU input
Indicator variables
Number of predictions used in embedding
The set {1, . . . , M } for an M ∈ Z+

Table 7: Symbols summary

B Stochastic Programming Problems

B.1 Capacitated Facility Location (CFLP)

The CFLP is a decision-making problem in which a set of facility opening decisions must be made
in order to meet the demand of a set of customers. Typically this is formulated as a minimization
problem, where the amount of customer demand satisﬁed by each facility cannot exceed its capacity.
The two-stage stochastic CFLP arises when facility opening decisions must be made prior to knowing
the actual demand. For this problem, we generate instances following the procedure described in
[Cornuéjols et al., 1991] and create a stochastic variant by simply generating the ﬁrst-stage costs and
capacities, then generate scenarios by sampling K demand vectors using the distributions deﬁned in
[Cornuéjols et al., 1991]). To ensure relatively complete recourse, we introduce additional variables
with prohibitively expensive objective costs in the case where customers cannot be served. In the
experiments a CFLP with n facilities, m customers, and s scenarios is denoted by CFLP_n_m_s.

15

B.2 Investment Problem (INVP)

The INVP is a 2SP problem studied in [Schultz et al., 1998]. This 2SP has a set of continuous
ﬁrst-stage decisions which yield an immediate revenue. In the second stage, after a set of random
variables are realized, a set of binary decisions can be made to receive further proﬁt. In this work,
we speciﬁcally consider the instance described in the example 7.3. of [Schultz et al., 1998]. This
problem has 2 continuous variables in the ﬁrst stage with the domain [0, 5], and 4 binary variables in
the second stage. The scenarios are given by two random discrete variables which are deﬁned with
equal probability over the range [5, 15]. Speciﬁcally, for K scenarios, each random variable can take
an equally spaced value in the range. Although the number of variables is quite small, the presence of
continuous ﬁrst-stage decision has made this problem relevant within the context of other recent work
such as the heuristic approach proposed in [van der Laan and Romeijnders, 2021]. As a note, we
reformulate the INVP as an equivalent minimization problem in the remainder of this work. In the
experiments an INVP instance is denoted by INVP_v_t, where v indicates the type of second-stage
variable (B for binary and I for integer) and t indicates the type of technology matrix (E for identity
and H for [[2/3, 1/3], [1/3, 2/3]]).

B.3 Stochastic Server Location Problem (SSLP)

The SSLP is a 2SP, where in the ﬁrst stage a set of decisions are made to decide which servers should
be utilized and a set of second-stage decisions assigning clients to servers. In this case, the random
variables take binary values, which represent a client with a request occurring in the scenario or not.
A more detailed description of the problem can be found in [Ntaimo and Sen, 2005]. In this work, we
directly use the instances provided in SIPLIB [Ahmed et al., 2015]. In the experiments a SSLP with
n servers, m clients, and s scenarios is denoted by SSLP_n_m_s.

B.4 Pooling Problem (PP)

The pooling problem is a well-studied problem in the ﬁeld of mixed-integer nonlinear programming
Audet et al. [2004], Gupte et al. [2017], Gounaris et al. [2009], Haverly [1978]. It can be formulated
as a mixed-integer quadratically constrained quadratic program, making it the hardest problem class
in our experiments.

We are given a directed graph, consisting of three disjoint sets of nodes, called the source, pool and
terminal nodes. We need to produce and send some products from the source to the terminal nodes,
using the given arcs, such that the product demand and quality constraints on the terminal nodes,
along with the arc capacity constraints, are satisﬁed. The pool nodes can be used to mix products
with different qualities in appropriate quantities to generate a desired quality product. The goal is
to decide the amount of product to send on each arc such that the total proﬁt from the operations is
maximized. We consider a stochastic version of the problem as described in the case study of Li
et al. [2011]. Here, in the ﬁrst stage, we need to design the network by selecting nodes and arcs from
the input graph, without knowing the quality of the product produced on source nodes and the exact
demand on the terminal nodes. Once the uncertainty is revealed, in the second stage, we make the
recourse decisions about the amount of product to be sent on each arc, such that demand and quality
constraints on the terminal nodes are satisﬁed. In our case, we have 16 binary variables in the ﬁrst
stage and 11 continuous variables per scenario in the second stage. An instance of this problem is
referred to as PP_s, where s is the number of scenarios.

C Data Generation & Supervised Learning Times

In this section, we report details of the data generation and training times for all problem settings in
Tables 8 and 9, respectively. For training, we split the # samples into an 80%-20% train validation
set, and select the best model on the validation set in the given number of epochs.

D Objective Results

In this section, we report the objective for the ﬁrst-stage solutions obtained by each approximate
MIP and the objective of EF (either optimal or at the end of the solving time). In addition, we

16

Problem

NN-E

NN-P

# samples Time per sample Total time

# samples Time per sample Total time

CFLP_10_10
CFLP_25_25
CFLP_50_50

SSLP_10_50
SSLP_15_45
SSLP_5_25

INVP_B_E
INVP_B_H
INVP_I_E
INVP_I_H

PP

5,000
5,000
5,000

5,000
5,000
5,000

5,000
5,000
5,000
5,000

5,000

0.36
0.83
1.54

0.19
0.19
0.17

1.79
1.84
1.75
1.79

0.24

1,823.07
4,148.83
7,697.91

942.10
929.27
860.74

8,951.27
9,207.90
8,759.83
8,944.65

1,202.11

10,000
10,000
10,000

10,000
10,000
10,000

10,000
10,000
10,000
10,000

10,000

0.00
0.01
0.01

0.00
0.00
0.00

0.00
0.00
0.00
0.00

0.00

13.59
112.83
135.57

22.95
16.35
13.18

4.17
4.22
4.34
3.32

14.86

Table 8: Data generation samples and times. Data was generated in parallel with 43 processes. All
times in seconds.

CFLP_10_10
CFLP_25_25
CFLP_50_50

SSLP_10_50
SSLP_15_45
SSLP_5_25

INVP_B_E
INVP_B_H
INVP_I_E
INVP_I_H

NN-E

667.28
2,205.23
463.71

708.86
1,377.21
734.02

344.87
1,214.54
2,115.25
393.82

NN-P

127.12
840.07
128.11

116.17
229.42
147.44

1,000.14
607.49
680.93
174.26

PP

576.08

367.25

LR

0.53
0.28
0.75

0.63
0.57
0.05

0.02
0.02
0.02
0.02

0.05

Table 9: Training times. All times in seconds.

report the objective of the approximate MIP. See Tables 10 through 13 for results. As mentioned
in the main paper, the results from linear regressor (LR) are quite poor, with a signiﬁcantly worse
objective in almost every instance. This is not surprising as a linear function will not likely have the
capacity to estimate the integer and non-linear second-stage objectives. For both NN-E and NN-P we
can see that the true objective and the approximate-MIP objective are relatively close for all of the
problem settings, further indicating that the neural network embedding is a useful approximation to
the second-stage expected cost.

E SSLP SIPLib Results

In this section we report optimally gaps and solving times on the publicly available SSLP SIPLib
instances in Table 14. From the table, we can see that both NN-E and NN-P do quite well in terms of
ﬁnding solutions, especially in the larger scenario case where they obtain optimal ﬁrst-stage solutions.
Perhaps, the most impressive results here is that NN-E is able to obtain optimal results for many
instances in ∼0.1 seconds.

F Model & Dataset Selection

F.1 Model Selection

For the supervised learning task, we implement linear regression using Scikit-learn 1.0.1 [Pedregosa
et al., 2011]. In this case we use the base estimator with no regularization. The NN-P/NN-E neural
models are all implemented using Pytorch 1.10.0 [Paszke et al., 2019]. For model selection, we use
random search over 100 conﬁgurations for each problem setting. For NN-P and NN-E we sample
conﬁgurations from Table 15. For both cases we limit the ReLU layers to a single layer with a varying
hidden dimension. In the NN-P case the choice of the ReLU hidden dimension is limited since a large

17

Problem

True objective

Approximate-MIP objective

NN-E

NN-P

LR

EF

NN-E

NN-P

LR

CFLP_10_10_100
CFLP_10_10_500
CFLP_10_10_1000
CFLP_25_25_100
CFLP_25_25_500
CFLP_25_25_1000
CFLP_50_50_100
CFLP_50_50_500
CFLP_50_50_1000

7,174.57
7,171.79
7,154.60
11,773.01
11,726.34
11,709.90
25,236.33
25,281.13
25,247.77

7,109.62
7,068.91
7,040.70
11,773.01
11,726.34
11,709.90
25,019.64
24,964.33
24,981.70

10,418.87
10,410.19
10,406.08
23,309.73
23,310.34
23,309.85
45,788.45
45,786.97
45,787.18

6,994.77
7,003.30
7,088.56
11,864.83
12,170.67
11,868.04
25,349.21
28,037.66
30,282.41

7,102.57
7,102.57
7,102.57
11,811.39
11,811.39
11,811.39
26,309.43
26,287.48
26,309.43

7,046.37
7,084.46
7,064.36
12,100.73
12,051.51
12,041.12
26,004.88
25,986.50
26,002.78

5,631.00
5,643.68
5,622.40
10,312.21
10,277.01
10,263.37
18,290.63
18,209.77
18,217.14

Table 10: CFLP detailed objective results: each row represents an average over 10 2SP instance
with varying scenario sets. “True objective" for {NN-E,NN-P,LR} is the cost of the ﬁrst-stage
solution obtained from the approximate MIP evaluated on the second-stage scenarios. For EF it is the
objective at the solving limit. “Approximate-MIP objective" is objective from the approximate MIP
for {NN-E,NN-P,LR}. All times in seconds.

Problem

True objective

Approximate-MIP objective

NN-E

NN-P

LR

EF

NN-E

NN-P

LR

SSLP_10_50_50
SSLP_10_50_100
SSLP_10_50_500
SSLP_10_50_1000
SSLP_10_50_2000
SSLP_15_45_5
SSLP_15_45_10
SSLP_15_45_15
SSLP_5_25_50
SSLP_5_25_100

-354.96
-345.86
-349.54
-350.07
-350.07
-247.27
-249.58
-251.10
-125.22
-120.91

-354.96
-345.86
-349.54
-350.07
-350.07
-206.83
-209.49
-208.86
-123.15
-119.03

-63.00
-49.62
-54.68
-55.45
-54.72
-249.51
-252.89
-254.58
14.50
19.87

-354.96
-345.86
-349.54
-235.22
-172.73
-255.55
-257.41
-257.68
-125.36
-120.94

-350.96
-350.96
-350.96
-350.96
-350.96
-238.44
-238.44
-238.44
-121.64
-121.64

-339.42
-328.54
-332.82
-333.46
-332.87
-259.11
-265.92
-267.01
-110.18
-109.59

-294.69
-283.96
-288.02
-288.55
-288.19
-58.28
-64.01
-66.71
-119.98
-117.79

Table 11: SSLP detailed objective results: each row represents an average over eleven 2SP instance
with varying scenario sets. See Table 10 for a detailed description of the columns.

number of predictions each with a large hidden dimension can lead to MILPs which are prohibitively
expensive to solve. For the NN-E speciﬁc hidden dimensions, we have 3 layers, with Embed hidden
dimension 1 and Embed hidden dimension 2 corresponding to layers before the aggregation and
Embed hidden dimension 3 being a ﬁnal hidden layer after the aggregation.

In Tables 16 and 17 we report the best parameters for each problem setting for the NN-P and NN-E
models, respectively. In addition, we report the validation MSE across all 100 conﬁgurations for each
problem in box plots in Figures 3 to 6. From the box plots we can observe that lower validation MAE
conﬁgurations are quite common as the medians are typically not too far from the lower tails of the
distributions. This indicates that hyperparameter selection can be helpful when attempting to improve
the second-stage cost estimates, however, the gains are marginal in most cases.

F.2 Dataset Size Selection

In this section, we report results for varying dataset sizes. Here, we report only the results for a single
problem setting, namely, CFLP_10_10. We use a validation with 5000 samples and training sets with
100, 500, 1000, 5000, 10000, and 20000 samples. Model selection with random search is done for
each training set size as described in the previous section. Figures 7 and 8 report the results for the
NN-P and NN-E models respectively. In both cases, we can see an improvement in validation MAE
with increases in the dataset sizes, however, diminishing returns start to occur when increasing the
number of samples above 5000 samples. This motivates the choice of dataset sizes which we use
in the remainder of the experiments. Speciﬁcally, we use 10000 samples for the NN-P case as data
generation is quite fast. For the NN-E case we limit the number of samples to 5000 as we only see a
small improvement of %4 in validation MAE at the cost of doubling the compute time.

18

Problem

True objective

Approximate-MIP objective

NN-E

NN-P

LR

EF NN-E

NN-P

INVP_B_E_4
INVP_B_E_9
INVP_B_E_36
INVP_B_E_121
INVP_B_E_441
INVP_B_E_1681
INVP_B_E_10000
INVP_B_H_4
INVP_B_H_9
INVP_B_H_36
INVP_B_H_121
INVP_B_H_441
INVP_B_H_1681
INVP_B_H_10000
INVP_I_E_4
INVP_I_E_9
INVP_I_E_36
INVP_I_E_121
INVP_I_E_441
INVP_I_E_1681
INVP_I_E_10000
INVP_I_H_4
INVP_I_H_9
INVP_I_H_36
INVP_I_H_121
INVP_I_H_441
INVP_I_H_1681
INVP_I_H_10000

-51.56
-54.86
-59.55
-61.44
-59.60
-59.81
-59.85
-51.75
-56.56
-59.31
-59.93
-60.14
-60.47
-60.53
-55.35
-61.63
-66.03
-67.35
-67.55
-67.95
-67.94
-54.75
-59.78
-63.78
-65.03
-65.12
-65.63
-65.66

-55.29
-58.15
-58.19
-60.78
-59.83
-
-
-51.36
-56.56
-59.31
-59.93
-58.07
-
-
-63.50
-64.80
-66.25
-67.92
-69.16
-66.73
-
-55.78
-65.25
-64.80
-64.37
-65.12
-65.34
-

-46.25
-53.11
-58.86
-61.06
-59.91
-59.30
-58.68
-51.75
-56.56
-59.31
-59.93
-60.14
-60.47
-60.53
-52.50
-61.89
-67.08
-69.07
-67.39
-66.52
-65.67
-54.75
-59.78
-63.78
-65.03
-65.12
-65.63
-65.66

-57.00
-59.33
-61.22
-62.29
-61.32
-60.63
-58.98
-56.75
-59.56
-60.28
-61.01
-61.44
-60.04
-58.93
-63.50
-66.56
-69.86
-71.12
-69.64
-68.85
-67.04
-63.50
-65.78
-67.11
-67.75
-67.24
-65.41
-64.63

-58.59
-58.81
-59.38
-59.60
-59.91
-59.94
-59.95
-58.12
-61.78
-59.38
-60.22
-60.23
-60.57
-60.65
-66.79
-66.70
-67.39
-67.39
-67.63
-67.69
-67.82
-65.31
-64.15
-66.79
-65.38
-67.13
-65.87
-66.45

-52.15
-55.33
-57.92
-58.91
-58.51
-
-
-52.41
-56.67
-59.52
-60.54
-58.13
-
-
-58.96
-61.70
-65.18
-66.70
-67.43
-67.62
-
-59.99
-61.08
-63.76
-64.64
-65.16
-65.03
-

LR

-63.67
-63.67
-63.67
-63.67
-63.67
-63.67
-63.67
-61.24
-61.24
-61.24
-61.24
-61.24
-61.24
-61.24
-71.57
-71.57
-71.57
-71.57
-71.57
-71.57
-71.57
-66.07
-66.07
-66.07
-66.07
-66.07
-66.07
-66.07

Table 12: INVP detailed objective results: each row represents single instance. See Table 10 for a
detailed description of the columns.

Problem

True objective

Approximate-MIP objective

NN-E

NN-P

LR

EF NN-E

NN-P

PP_125
PP_216
PP_343
PP_512
PP_729
PP_1000

264.30
200.29
206.38
204.41
219.42
202.50

173.10
131.83
122.90
134.83
137.97
126.30

-10.00
-10.00
-10.00
-10.00
-10.00
-10.00

273.19
220.25
207.77
223.86
222.48
215.25

189.75
189.75
189.75
189.75
189.75
189.75

177.12
168.10
172.17
162.54
167.55
165.59

LR

70.75
70.75
70.75
70.75
70.75
70.75

Table 13: PP detailed objective results: each row represents single instance. See Table 10 for a
detailed description of the columns.

Problem

Gap to Optimal (%)

Solving Time

NN-E NN-P

EF NN-E

NN-P

EF

SSLP_10_50_50
SSLP_10_50_100
SSLP_10_50_500
SSLP_10_50_1000
SSLP_10_50_2000
SSLP_15_45_5
SSLP_15_45_10
SSLP_15_45_15
SSLP_5_25_50
SSLP_5_25_100

0.00
0.00
0.00
0.00
0.00
0.46
1.57
0.53
0.00
0.00

0.00
0.00
0.00
0.00
0.00
19.59
18.23
16.51
2.15
1.40

0.00
0.00
0.00
28.64
51.24
0.00
0.00
0.00
0.00
0.00

0.11
0.11
0.11
0.12
0.13
0.32
0.25
0.41
0.26
0.18

4.83
11.66
107.88
383.51
4,523.19
0.28
0.40
0.72
0.92
1.68

10,801.27
10,800.04
10,818.23
10,800.26
10,800.20
4.17
3.71
4.74
2.35
8.87

Table 14: SSLP SIPLib gap and time comparison among methods. Optimal SIPLib instances values
obtained from Ahmed et al. [2015]. “Gap to Optimal" is the percent gap to the optimal solution.
“Solving Time" is the solving to of the approximate MIP and EF. All times in seconds.

19

Parameter

NN-P

NN-E

Batch size
Learning rate
L1 weight penalty
L2 weight penalty
Optimizer
Dropout
# Epochs
ReLU hidden dimension
Embed hidden dimension 1
Embed hidden dimension 2
Embed hidden dimension 3

{16, 32, 64, 128}
[1e−5, 1e−1]
[1e−5, 1e−1]
[1e−5, 1e−1]
{Adam, Adagrad, RMSprop}
[0, 0.5]
1000
{32, 64}
-
-
-

{16, 32, 64, 128}
[1e−5, 1e−1]
[1e−5, 1e−1]
[1e−5, 1e−1]
{Adam, Adagrad, RMSprop}
[0, 0.5]
2000
{64, 128, 256, 512}
{64, 128, 256, 512}
{16, 32, 64, 128}
{8, 16, 32, 64}

Table 15: Random search parameter space for NN-P and NN-E models. For values in {}, we sample
with equal probability for each discrete choice. For values in [], we sample a uniform distribution
with the given bounds. For single values, we keep it ﬁxed across all conﬁgurations. A value of -
means that parameter is not applicable for the given model type.

Parameter

CFLP_10_10 CFLP_25_25 CFLP_50_50

SSLP_5_25

SSLP_10_50

SSLP_15_45

INVP_B_E INVP_B_H INVP_I_E INVP_I_H

PP

Batch size
Learning rate
L1 weight penalty
L2 weight penalty
Optimizer
Dropout
ReLU hidden dimension

128
0.05029
0.07512
0.08343
Adam
0.02198
64

16
0.05217
0.00551
0.02846
Adam
0.02259
32

128
0.00441
0.08945
0.08602
Adam
0.05565
64

128
0.03385
0.03232
0.0
RMSprop
0.00914
32

128
0.07015
0.07079
0.01792
RMSprop
0.01944
64

64
0.08996
0.09105
0.0
RMSprop
0.02257
32

16
0.00435
0.08321
0.01047
RMSProp
0.17237
64

32
0.00521
0.05754
0.02728
RMSProp
0.13698
64

32
0.06613
0.01683
0
Adam
0.04986
64

128
0.01614
0. 01859
0
Adam
0.0859
32

64
0.0032
0
0.0361
Adam
0.05945
64

Table 16: NN-P best conﬁgurations from random search.

Parameter

CFLP_10_10 CFLP_25_25 CFLP_50_50

SSLP_5_25

SSLP_10_50

SSLP_15_45

INVP_B_E INVP_B_H INVP_I_E INVP_I_H

PP

Batch size
Learning rate
L1 weight penalty
L2 weight penalty
Optimizer
Dropout
ReLU hidden dimension
Embed hidden dimension 1
Embed hidden dimension 2
Embed hidden dimension 3

32
0.0263
0.02272
0.05747
RMSprop
0.01686
128
512
16
16

16
0.06571
0.06841
0.0
Adam
0.0028
256
128
64
16

128
0.02906
0.05792
0.04176
Adam
0.03318
256
256
64
8

64
0.08876
0.0
0.03488
Adam
0.00587
256
64
16
32

64
0.07633
0.04529
0.0
RMSprop
0.00018
64
128
32
64

32
0.03115
0.07182
0.0
Adam
0.0088
256
512
64
16

128
0.01959
0.0
0
Adagrad
0.08692
256
256
16
32

32
0.00846
0.0
0.09007
Adam
0.04096
256
512
16
16

16
0.02841
0.00022
0.02272
Adagrad
0.01854
256
64
32
8

128
0.02867
0
0.01882
Adagrad
0.01422
256
256
32
64

64
0.08039
0
0
Adam
0.0072
512
512
128
16

Table 17: NN-E best conﬁgurations from random search.

Figure 3: CFLP validation MAE over random search conﬁgurations for NN-P and NN-E models.

20

Figure 4: SSLP validation MAE over random search conﬁgurations for NN-P and NN-E models.

Figure 5: INVP validation MAE over random search conﬁgurations for NN-P and NN-E models.

Figure 6: PP validation MAE over random search conﬁgurations for NN-P and NN-E models.

21

Figure 7: NN-P dataset sizing results

Figure 8: NN-E dataset sizing results

22

