Fast semideÔ¨Ånite programming with feedforward neural networks

Tam¬¥as Kriv¬¥achy,1 Yu Cai,1 Joseph Bowles,2 Daniel Cavalcanti,2 and Nicolas Brunner1
1Department of Applied Physics, University of Geneva, CH-1211 Geneva, Switzerland
2ICFO - Institut de Ciencies Fotoniques, The Barcelona Institute
of Science and Technology, E-08860 Castelldefels, Barcelona, Spain
(Dated: November 13, 2020)

SemideÔ¨Ånite programming is an important optimization task, often used in time-sensitive appli-
cations. Though they are solvable in polynomial time, in practice they can be too slow to be used
in online, i.e. real-time applications. Here we propose to solve feasibility semideÔ¨Ånite programs
using artiÔ¨Åcial neural networks. Given the optimization constraints as an input, a neural network
outputs values for the optimization parameters such that the constraints are satisÔ¨Åed, both for the
primal and the dual formulations of the task. We train the network without having to exactly solve
the semideÔ¨Ånite program even once, thus avoiding the possibly time-consuming task of having to
generate many training samples with conventional solvers. The neural network method is only in-
conclusive if both the primal and dual models fail to provide feasible solutions. Otherwise we always
obtain a certiÔ¨Åcate, which guarantees false positives to be excluded. We examine the performance
of the method on a hierarchy of quantum information tasks, the Navascu¬¥es‚ÄìPironio‚ÄìAc¬¥ƒ±n hierarchy
applied to the Bell scenario. We demonstrate that the trained neural network gives decent accuracy,
while showing orders of magnitude increase in speed compared to a traditional solver.

I.

INTRODUCTION

Neural network-based algorithms have produced as-
tounding results for many tasks. A notable example is
that of image inpainting. Given an image with miss-
ing patches in it, properly trained algorithms can Ô¨Åll the
patch in convincingly, matching both local and global ex-
pectations. In many Ô¨Åelds of science and technology we
Ô¨Ånd ourselves facing a similar problem: given some ele-
ments of a matrix, Ô¨Ånd a completion of it, such that the
whole matrix is positive semideÔ¨Ånite. Such a problem is
an instance of a feasibility semideÔ¨Ånite program (SDP),
which is a widely studied class of convex optimization
problems, having a broad range of applications [1, 2].
SDPs can be solved in polynomial time and by duality are
typically able to provide a certiÔ¨Åcate of reaching the opti-
mum. However, in various use-cases solving the problem
exactly becomes impractical due to extensive runtimes,
which can limit its utility in many real-time applications.
This has led to several approaches to reduce the runtime,
even if at the cost of losing accuracy [3‚Äì9].

Here we explore an alternative solver for SDPs using
neural networks. We replace the standard optimization
procedure with a single nonlinear function, a feedforward
artiÔ¨Åcial neural network. We focus on feasibility SDPs,
where, given a description of the problem as an input,
the neural network will guess the optimization parameter
values such that they complete a matrix in a positive
semideÔ¨Ånite way (illustrated in Fig. 1). If the prediction
of the network results in a positive semideÔ¨Ånite matrix
then we obtain a certiÔ¨Åcate of feasibility. If it fails to do
so, then this could be either because there does not exist
a positive semideÔ¨Ånite completion or because the neural
network just didn‚Äôt Ô¨Ånd it. Luckily, the SDP has a dual
formulation, in which the dual task is feasible if and only
if the primal is infeasible. Thus we also check the dual
task with a second neural network in a similar manner as

FIG. 1. General scheme of our machine learning approach.
Given a new instance of a feasibility SDP, described by the
vector v (purple dots), a neural network outputs the missing
elements (yellow triangles) of the constraint matrix Œì. The
neural network‚Äôs parameters are updated in order to make Œì
as positive semideÔ¨Ånite as possible (i.e. maximize the smallest
eigenvalue).

the primal. It is only if both networks fail that we do not
get a deÔ¨Ånite statement of feasibility. In other words, for
the neural network-based method the duality gap is not
guaranteed to be zero, while dedicated SDP solvers can
in principle close this gap.

We pay this price in precision in order to gain a sig-
niÔ¨Åcantly improved runtime. Contrary to traditional
solvers, for each new instance of a problem our neural
network does not have to start from scratch to solve
it, since it learned the structure of the problem previ-
ously, during training, which allows for a strong advan-
tage in runtime. The Ô¨Çexibility of neural networks allow
the user to tune this trade-oÔ¨Ä in accuracy versus run-
time by changing the size and architecture of the neural
network. The technique could be useful for screening
data before running slower, albeit more precise solvers,
when one has many instances of similarly structured op-

0
2
0
2

v
o
N
2
1

]
h
p
-
t
n
a
u
q
[

2
v
5
8
7
5
0
.
1
1
0
2
:
v
i
X
r
a

vLossùö™ 
 
 
 
 
 
2

timization tasks. Additionally, it can be very useful in
scenarios where quick or even real-time solving of SDPs
are required, such as in calculating the safe zones of self-
driving cars, collision avoidance [10, 11], control systems
and robotics tasks [2, 12], black-box quantum random
number generation and quantum protocols [13, 14], an-
alyzing ground state energies in quantum chemistry and
many-body physics tasks [15‚Äì20] or bounding problems
in NP [12, 21].

We examine the performance of the method on a cen-
tral scenario in quantum theory, Bell nonlocality [22, 23].
At a glance, the basic task is to decide what kind of
shared resource is necessary or suÔ¨Écient for creating cor-
In particular, quantum
relations between two parties.
resources, as opposed to classical ones, can lead to so-
called nonlocal behavior. Previous works have used ma-
chine learning in tackling the question of whether classi-
cal resources are suÔ¨Écient [24, 25], in classifying behavior
by learning from many samples [26] or by proposing new
experiments [27]. In the current work we turn towards
another question: is a quantum resource suÔ¨Écient to re-
produce the correlations? A hierarchy of SDPs proposed
by Navascu¬¥es, Pironio and Ac¬¥ƒ±n (NPA) helps in answer-
ing this question [28]. Each step of the hierarchy is a
feasibility SDP which demonstrates whether the corre-
lations under scrutiny fall within a given relaxation of
the set of quantum correlations. For higher levels of the
hierarchy the relaxations become tighter, and eventually
converge to the true quantum set [29, 30]. Each SDP in
the hierarchy is a feasibility SDP in which some elements
of the so-called moment matrix are Ô¨Åxed by physically
observed correlations, and the other elements need to be
completed such that the whole matrix is positive semidef-
inite.

We apply our technique to this problem by training
two neural networks for each level of the hierarchy, one
for the primal and one for the dual problem. For a Ô¨Åxed
level of the hierarchy, the physically observed correlations
deÔ¨Åne the SDP, so this is the input we use for the neural
network. For training, we use only random correlations
as inputs, without having to solve the SDP exactly even
once. Once trained, the neural networks can predict ma-
trix completions orders of magnitude quicker for a new
correlation than conventional solvers, while keeping a de-
cent accuracy.

In the following we introduce our approach to solving
feasibility SDPs in detail. We follow by describing the
Bell scenario and the hierarchy of SDPs which approxi-
mate the quantum set of correlations. Then we present
the performance results and conclude with a discussion.
Finally, we present a more detailed introduction to neu-
ral networks and the details of our implementation in the
Methods section.

II. NEURAL NETWORKS FOR SOLVING SDP

Consider the following family of generic nonlinear op-

timization tasks, parametrized by a vector v.

fv(z),

min
z
s.t. gv(z) ‚â• 0,

(1)

where fv : RN ‚Üí R, gv : RN ‚Üí RM . We focus on a dif-
ferentiable objective fv and constraints gv. The general
spirit of our work is to encode the optimization problem
in the loss function of an artiÔ¨Åcial neural network, such
that it learns to satisfy the constraints and minimize the
objective function, i.e. L(v, z) = fv(z) ‚àí ¬µ min(gv(z), 0),
where ¬µ ‚àà R+ is introduced to balance the objective and
constraints in the loss function. Then we train the neural
network to minimize this loss by inputting random con-
Ô¨Åguration vectors v, and asking the neural network to
output z, a solution which it guesses to be optimal. Af-
ter training on many random conÔ¨Ågurations from within
the family the neural network will learn the structure
of the problem, and when evaluated on a new instance,
it will predict a close-to optimal solution. Within this
family of (Ô¨Åxed-size) optimization problems we thus au-
tomate the solving process, since for a new instance of
an optimization problem (characterized by v), instead of
solving it from scratch, the neural network predicts the
solution almost instantaneously.

In the current work we examine an important subclass
of optimization problems, feasibility SDPs [1]. First, we
do this because SDPs are speciÔ¨Åc instances of conic pro-
gramming and thus have a dual problem, the optimal so-
lution of which approaches the primal‚Äôs from below and
achieves a zero duality gap. With our technique we can
train a neural network also for the dual task, and by eval-
uating both the dual and primal neural networks we can
obtain bounds on how well the two models together man-
age to reduce the duality gap. Second, we only examine
feasibility problems because in these the machine‚Äôs task
is very pronounced and its success is easy to check: pre-
dict a variable z such that gv(z) ‚â• 0. If successful, we
have a certiÔ¨Åcate of feasibility. Finally, note that well-
formulated SDPs with a bounded objective function can
be approximated arbitrarily well with a series of feasibil-
ity SDPs using bisection techniques, with the accuracy
increasing exponentially with the number of feasibility
SDPs solved.

A feasibility SDP can be expressed as

Find Œì,

s.t. Œì ‚â• 0,

‚àÄk : (cid:104)Fk, Œì(cid:105) = vk,

(2)

where Œì is a matrix, (cid:104)¬∑, ¬∑(cid:105) is the Hilbert-Schmidt inner
product, and the matrices Fk and vector v encode the
constraints. The dual task of the primal SDP can be

stated as

Find yk

s.t.

(cid:18)‚àí (cid:80)

k ykFk
0

(cid:19)

(cid:80)

0
k ykvk ‚àí Œ¥

‚â• 0,

(3)

where Œ¥ is an arbitrary positive number, which we intro-
duced in order to be able to state the dual problem also
as a feasibility task. For feasibility problems, either the
primal or the dual task has a solution.

Our main tools for solving these SDPs are artiÔ¨Åcial
neural networks. A feedforward neural network is a
model for a generic multidimensional nonlinear function.
One of its simplest realization, a multilayer perceptron, is
characterized by the number of neurons per layer (width),
the number of layers (depth), and the activation func-
tions used at the neurons, which altogether model an
iterative sequence of parametrized aÔ¨Éne and Ô¨Åxed non-
linear transformations on the input, i.e.

rl+1 = h(Wlrl + bl),

(4)

where the matrix Wl and vector bl parametrize the lin-
ear transformation, h is a Ô¨Åxed diÔ¨Äerentiable nonlinear
function, and rl is the input of layer l, r1 being the input
of the model and rdepth being the output. During train-
ing, the parameters of the model ({Wl, bl}l) are updated
such that they minimize a diÔ¨Äerentiable loss function of
the training set. Once trained, the neural network can be
evaluated on new input instances. For a more detailed
introduction to neural networks we refer the reader to
the Methods section or to Ref. [31].

Our approach to solving SDPs via neural networks is
illustrated in Fig. 1. We examine a family of feasibility
SDP problems, where {Fk}k is Ô¨Åxed and only the val-
ues of v are diÔ¨Äerent. We input the constraints of the
SDP (v) in a feedforward neural network. The neural
network outputs the optimization variables (the free val-
ues of Œì for the primal or y for the dual) and the loss is
taken to be minus one times the smallest eigenvalue of
the constraint matrix. Thus the neural network tries to
push the lowest eigenvalue of the constraint matrix to be
as large as possible. For a test sample, if this smallest
eigenvalue of the primal constraint is positive, then the
machine has found a positive semideÔ¨Ånite completion of
Œì, i.e. we obtain a certiÔ¨Åcate of feasibility. Alternatively
if the dual neural network Ô¨Ånds a positive semideÔ¨Ånite
completion of (3), we obtain a certiÔ¨Åcate of infeasibility
of the primal task. It is only if neither the primal nor the
dual neural network give positive semideÔ¨Ånite solutions
that we are uncertain of the feasibility.

III. CASE STUDY IN QUANTUM
NONLOCALITY

To examine the performance of the method, we con-
sider a hierarchy of feasibility SDPs, where the constraint
matrices naturally have several elements Ô¨Åxed and the

3

others left free. In the Navascu¬¥es‚ÄìPironio‚ÄìAc¬¥ƒ±n (NPA)
hierarchy [28, 29], using such SDPs we can explore the
limitations of correlations coming from shared quantum
resources. The hierarchy can be applied in a variety of
scenarios such as estimating randomness in device inde-
pendent scenarios [32, 33], network nonlocality [34, 35],
sequential Bell tests [36] or bounding ground state en-
ergies [20], but here, for concreteness and easy bench-
marking, we examine the standard bipartite Bell sce-
nario, which is an excellent sandbox for examining the
strength of correlations between two systems [22, 23].

In the Bell scenario a source is distributed to two par-
ties, Alice and Bob, and they each additionally receive
an input (x and y, respectively), and produce an output
(a and b, respectively), as illustrated in Fig. 2(a). For
the current work we will only consider discrete inputs
and outputs of cardinality 2, i.e. x, y, a, b ‚àà {0, 1}. We
say that there is no signaling among the parties if the
statistics of the inputs and outputs obey

p(ab|xy) =

p(ab|xy) =

(cid:88)

b
(cid:88)

a

(cid:88)

b
(cid:88)

a

p(ab|xy(cid:48))

‚àÄa, x, y, y(cid:48),

(5)

p(ab|x(cid:48)y)

‚àÄa, x, x(cid:48), y.

(6)

Any correlation for which these constraints hold are in
the set of no-signaling correlations N S. We enforce no-
signaling and that the inputs are independent from the
source. Then, just by observing the statistics of the in-
puts and the outputs of the two parties, p(ab|xy), one
can in certain cases deduce that stronger than classi-
cal sources were used, e.g. quantum or post-quantum
sources. With any classical source, the obtained statis-
tics can be described by a shared random variable Œõ,
constraining the correlations to be of the form

(cid:90)

p(ab|xy) =

dŒªp(Œª)p(a|x, Œª)p(b|y, Œª),

(7)

for some p(a|x, Œª), p(b|y, Œª) conditional probability dis-
tributions, otherwise known as response functions, and
some probability distribution p(Œª). Any correlation
which can be described by such a model (otherwise
known as a local hidden variable model) is within the
local set L.

The Born rule of quantum theory postulates that for

any quantum source, p(ab|xy) must have the form

p(ab|xy) = Tr(œÅAa

x ‚äó Bb

y),

(8)

where œÅ is a Hermitian positive semideÔ¨Ånite matrix (or
operator, more generally) with unit trace, and can be
thought of as the quantum analogue of a probability
distribution, {Aa
x}a,x are projective matrices such that
‚àÄx : (cid:80)
a Aa
x}a
represents Alice‚Äôs measurement when her input is x and
output is a, and analogously for Bob. Any correlation
having a quantum explanation according to the above
equation is in the set Q.

x = I, and similarly for Bb

y. The set {Aa

4

paper we will examine the relaxations Q1, Q1AB, Q2,
Q3, where the number denotes the maximal degree of
moments used in the relaxation, and for Q1AB only in-
cludes single moments and cross-moments of Alice‚Äôs and
Bob‚Äôs measurement, a commonly used intermediate level
between Q1 and Q2. The set Qn + 1 is a subset of Qn,
and as n approaches inÔ¨Ånity we are guaranteed to recover
the actual quantum set Q [29, 30].

FIG. 2. (a) The Bell scenario. A source (either no-signaling,
quantum or local) is distributed to the two parties, Alice (A)
and Bob (B). Independently from the source they each re-
ceive and input (x and y, resp.) and produce an output (a
and b, resp.). The correlations are characterized by the joint
statistics p(ab|xy). (b) A slice of the set of no-signaling corre-
lations, where the axes are the CHSH expression divided by
four and a relabeling of that (CHSH‚Äô/4). The isotropic line
(dotted red line) runs between the PR-box (top yellow dot)
and the fully mixed state (gray dot). The red dot represents
the Tsirelson bound. The 8 local vertices achieving a CHSH
value of 2 do not appear in this slice, but for illustration are
projected onto 2 points (yellow dots on the border of L).

The no-signaling set and the local set are poly-
topes [23], bounded by convex combinations of a Ô¨Ånite set
of vertices, or equivalently by linear inequalities. For the
local set there are 8 non-trivial inequalities, all of them
equivalent up to relabeling to the same Clauser‚ÄìHorne‚Äì
Shimony‚ÄìHolt (CHSH) inequality, which is a linear ex-
pression bounded by the value 2 for local behaviors [37].
This inequality deÔ¨Ånes a facet, spanned by 8 local ver-
tices. The no-signaling set is bounded by 24 vertices of
which 16 are also local vertices, and 8 are genuinely no-
signaling vertices, all equivalent under relabeling to the
Popescu‚ÄìRohrlich box (PR-box) [38‚Äì41], deÔ¨Åned as

pPR(ab|xy) :=

(cid:40)

1 if a ‚äï b = xy,
otherwise,
0

(9)

which gives a CHSH value of 4, far above the local bound.
The relation between L, Q and N S is visualized on a two-
dimensional slice of the space in Fig. 2(b).

‚àö

Quantum behaviors can at most achieve a CHSH value
2, the Tsirelson bound, thus achieving nonlocal-
of 2
ity [42]. However, the quantum set is not a polytope
and is thus more diÔ¨Écult to characterize than the local
or no-signaling sets. An additional diÔ¨Éculty is that one
can not in general bound the dimension of the density
matrix required. A general technique for approximating
the quantum set is an inÔ¨Ånite hierarchy of relaxations,
known as the NPA hierarchy [28]. Each relaxation is
deÔ¨Åned by a Ô¨Ånite set of strings of moments of the quan-
In this
tum measurement operators of Alice and Bob.

0, A0

1, B0

The basic idea of the relaxations is that if a distribu-
tion has a quantum description according to Eq. (8), then
the so-called moment matrix should be positive semideÔ¨Å-
nite. A moment matrix, Œì, is constructed by taking a set
of strings of moments of measurement operators, e.g. for
Q1 one takes S := {I, A0
1 }. Other single mo-
ments are not needed due to normalization, so for clarity
we leave away the output superscript from now on. One
constructs the moment matrix by taking the expectation
value of the dyadic product of S and its element-wise
adjoint set S‚Ä†, which in the case of single moments is
the same as S since the projectors are self-adjoint. The
moment matrix is the following, where the (cid:104)¬∑(cid:105) is the ex-
pectation value with respect to œÅ, i.e. Tr(œÅ ¬∑). Only the
upper triangle is shown as Œì is symmetric.

0 , B0

I A0
(cid:104)I(cid:105) (cid:104)A0(cid:105)

A1
(cid:104)A1(cid:105)

B0
(cid:104)B0(cid:105)

B1
(cid:104)B1(cid:105)

(cid:104)A1(cid:105)

(cid:104)A0(cid:105) (cid:104)A0A1(cid:105) (cid:104)A0B0(cid:105) (cid:104)A0B1(cid:105)
(cid:104)A1B0(cid:105) (cid:104)A1B1(cid:105)
(cid:104)B0B1(cid:105)
(cid:104)B1(cid:105)

(cid:104)B0(cid:105)

I
A0
A1
B0
B1

(10)

For any behavior derived from some quantum source
œÅ, such a moment matrix must be positive semideÔ¨Ånite.
Notice that even without knowing œÅ, almost all elements
can be identiÔ¨Åed with the observed statistics p(ab|xy) via
the Born rule in Eq. (8). However, a few elements are
unphysical and can not be observed, since they would
require the joint measurement of two of Alice‚Äôs or Bob‚Äôs
operators, which is prohibited for noncommuting mea-
surements. For Q1 there are only two such unknown
elements, denoted by bold text in the matrix (10), how-
ever for higher levels their number grows quickly, namely
there are 8, 22, 52, 92 and 142 unknown elements in the
moment matrices of levels Q1AB, Q2, . . . Q5, while each
of them have the same number of elements Ô¨Åxed by the
statistics p(ab|xy).

The task is now the following: given some statistics
from a Bell scenario, p(ab|xy), and a level of the hierarchy
(say Q1), Ô¨Ånd real numbers for the unknown elements of
the moment matrix such that it is positive semideÔ¨Ånite.
If such a completion is possible then p(ab|xy) ‚àà Q1. We
can see that this problem is of the form (2) by deÔ¨Åning
the matrices {Fk}k to have ones only in the matrix in-
dices where physical elements appear and zero otherwise,
and by identifying the entries of v with the appropriate
elements of p(ab|xy). As such, a dual formulation also
exists, such that is if there is a positive semideÔ¨Ånite com-
pletion of the dual constraint matrix (see Eq. (3)), then
we certify that p(ab|xy) /‚àà Q1. Otherwise, if we do not

ùìõùì†ùìùùì¢PR-boxProjected local vertexFully mixedCHSH/4CHSH‚Äô/41‚âà0.7070.50(b)(a)Source(NS., Q. or L.)xyabABÔ¨Ånd a positive semideÔ¨Ånite for either the primal or dual,
then we are left in uncertainty. In the following we train
neural networks for the primal and dual of this problem
for diÔ¨Äerent levels of the NPA hierarchy and examine
their performance.

We examine two ways to generate input behaviors
p(ab|xy). Since local behaviors can easily be screened
out by checking their CHSH values, we do not need to
train the machine to perform well on those. Thus we
take samples from the nonlocal part of the no-signaling
set, N S\L. We examine only a non-redundant part of
this set by not considering the 8-fold symmetry under
relabeling. As a result the set we consider is spanned by
the 8 extremal local points and the PR-box which maxi-
mize the canonical CHSH inequality (see the yellow dots
in Fig. 2(b) for an illustration). With a slight abuse of
notation we continue to label this set as N S\L.

In the Ô¨Årst sampling technique, we generate random
samples from N S\L using hit and run sampling [43, 44].
In the second, which we will refer to as weighted vertex
sampling we take uniformly randomly weighted mixtures
of the 9 vertices of N S\L, with 8-fold weight on the PR-
box. Formally, if the local vertices are {pL
i=1
and the PR-box is pPR(ab|xy), then a training sample is
generated as

i (ab|xy)}8

5

FIG. 3. The maximum of the smallest eigenvalue of the primal
and dual SDP matrix as predicted by the machine (blue and
red dashed lines, resp.), compared to the true value calculated
by an SDP solver (green and orange solid lines, resp.), as a
function of the mixing parameter q of the isotropic line, for
several diÔ¨Äerent levels of the hierarchy. For the dual methods,
in order to have numerical stability the outputs are restricted
2
to be between ‚àí1 and 1. The Tsirelson bound at q = 1/
is denoted by the solid magenta line.

‚àö

p(ab|xy) =

8w0 pPR(ab|xy) + (cid:80)8
8w0 + (cid:80)8

i=1 wi pL
i=1 wi

i (ab|xy)

, (11)

IV. RESULTS

where the wi ‚àà [0, 1] are uniformly drawn random num-
bers. This sampling technique resulted in a more reliable
training for the dual neural network.

Among other factors, the accuracy of the trained net-
work depends on the architecture of the neural network,
in particular on its size. In the following we will exam-
ine a family of neural networks, one for each level of the
hierarchy. We keep the depth at a constant of 8 layers,
while we vary the width in order to accompany the grow-
ing complexity of higher levels. In particular we take the
width to be three times the number of elements which
need to be predicted. The last layer is diÔ¨Äerent from
the preceding ones, Ô¨Årst oÔ¨Ä, because its width is exactly
the size of the number of elements which need to be pre-
dicted. Second, whereas in other layers we use exponen-
tial linear activations, we use a linear activation for the
Ô¨Ånal layer of the primal network. For the dual network
using linear activation can lead to instability, since the
optimal solution to yk for maximizing the eigenvalue of
the dual matrix in Eq. (3) can tend to inÔ¨Ånity. Thus we
limit the outputs such that ‚àí1 < yk < 1 by using a tan-
gent hyperbolic activation. For a small enough Œ¥ (e.g. we
used 3e‚àí7) this only minimally restricts the generality of
the solver, giving errors well below the standard inaccu-
racy of the machine learning predictions. For additional
details of the training procedure see the Methods section.

The memory usage of the neural network method is
approximately the same as for conventional SDP solvers,
with the construction of the moment matrix being the
primary bottleneck. Hence, in the following we compare
the two approaches from two other aspects, their accu-
racy and runtime.

First let us examine Tsirelson‚Äôs bound in detail by us-
ing both the primal and the dual neural networks for
relaxations Q1, Q1AB, Q2 and Q3 on the isotropic line,
i.e. on distributions

pq(ab|xy) = q pPR(ab|xy) + (1 ‚àí q) pid(ab|xy),

(12)

where pid(ab|xy) is the completely Ô¨Çat distribution and
q ‚àà [0, 1] is the mixing parameter. The edge of the quan-
tum set, Tsirelson‚Äôs bound, is at precisely q‚àó = 1‚àö
. The
2
isotropic line is portrayed in Fig. 2(b). In Fig. 3 we depict
the minimum eigenvalue of the predicted moment matrix
as a function q, and contrast it to the maximum possible
minimum eigenvalue, calculated by an SDP solver. For
the results in Fig. 3 we use hit and run training for the
primal networks and weighted vertex for the duals, since
the dual neural network showed poor convergence and
performance when trained on hit and run sampling.

We further explore the eÔ¨Äect of choosing one train-
ing sampling technique versus the other by evaluating
the accuracy of the Q2 primal neural network solver for
both hit and run and weighted vertex sampling. When

0.150.100.050.000.050.100.15Q1True primalPrimal NNTrue dualDual NN0.040.020.000.020.04Q1AB0.650.700.750.800.040.020.000.020.04Q20.650.700.750.800.030.020.010.000.010.020.03Q36

Tested on

Hit and run
Weighted vertices
Quantum pure
Tsirelson bound
(nonlocal part)

Trained on
Hit and run Weighted
vertices
60%
77%
50%
0.193/0.207
= 93%

81%
77%
80%
0.176/0.207
= 85%

TABLE I. Percent of test samples for which the Q2 primal
neural network found a positive semideÔ¨Ånite completion, for
diÔ¨Äerent training and test sampling techniques. For the test
sets, consisting of 10000 samples each, we used only correla-
tions which have positive semideÔ¨Ånite completions. For the
Tsirelson bound the percentage is calculated only on the non-
local part of the isotropic line, i.e. q = 0.5 is 0% and q = 1‚àö
2
is 100%.

Q1
2

Q1AB
8

Q2
22

Q3
52

98%

79%

81%

60%

99%

97%

85%

77%

17 ¬µs

20 ¬µs

36 ¬µs

210 ¬µs

9 ms

10 ms

13 ms

17ms

SDP
variables
NN
accuracy
NN
Tsirelson
NN time
per sample
MOSEK
time per
sample

TABLE II. Time per sample and accuracy for diÔ¨Äerent levels
of the hierarchy. The neural networks (NN) used all have a
depth of 8 and a width which is 3 times the number of SDP
variables which need to be predicted.

testing the performance we additionally included a set of
correlations coming from random two-qubit pure states
measured in random projective bases (all sampled uni-
formly in the Haar measure) as well as results from the
isotropic line. Results are portrayed in Table I.

Finally, in Table II we compare the time performance
of the primal neural network to standard solving soft-
ware (MOSEK), solved on the same personal computer
at 100% CPU usage. We note that the timing results
depend on the choice of neural network architecture. Re-
call that for diÔ¨Äerent levels of the hierarchy we kept the
depth Ô¨Åxed and increased the width linearly. This was
an arbitrary choice which leads to the accuracy results,
also visible in Table II. If one would like to have higher
accuracy on larger problem sizes, one could use larger
neural networks, at the cost of having somewhat slower
evaluation times. We can see that for the choice we made
the speed of solving is orders of magnitude quicker than
solving with MOSEK, hence there is still much space left
for improving the accuracy if required.

V. DISCUSSION

We have developed a solver for feasibility SDPs of a
Ô¨Åxed structure using feed-forward neural networks. Our
approach is an unsupervised learning one in the sense
that training is done only with random input samples,
and the neural network must learn itself the best output,
which gives ‚Äúthe most positive-semideÔ¨Ånite‚Äù constraint
matrix by constructing it explicitly. This is facilitated
through a loss function which motivates the neural net-
work to maximize the smallest eigenvalue of the gener-
ated constraint matrix. In future work it could be inter-
esting to explore alternative approaches more in line with
supervised learning, where one generates a training set
by taking many random inputs and calculating the solu-
tion using conventional solvers, which input-output pairs
would be training data for a neural network. Though
it could be more precise than the approach explored in
this work, it comes with the disadvantage that generat-
ing training samples is slow. This is a similar bottleneck
as for the training of the method examined in this work,
since we must calculate the eigenvalues of the constraint
matrix for each training sample, which calculation for an
m √ó m matrix typically scales as m3 in practice. We note
that we have tried brieÔ¨Çy to do a supervised learning
approach in which we circumvent these timely training
steps by generating random positive semideÔ¨Ånite matri-
ces and asking a feedforward neural network to predict
the missing element positions given the known element
positions. This gives a quick training procedure, however
it is not as accurate as the technique demonstrated here,
since the learned completions are not trying to push the
matrix to be ‚Äúas positive semideÔ¨Ånite as possible‚Äù.

A direction worth exploring in future work would be
the use of generative methods. Instead of learning the
distribution over outputs given an input (as it is done
in discriminative techniques), generative neural networks
learn the distribution over the inputs, and can generate
new instances. Though we were inspired by such gener-
ative machine learning-based image inpainting, the task
here is to always predict the same unknown elements of
the matrix given the constraints v. Thus it is unnec-
essarily expensive to learn a generative distribution over
all positive semideÔ¨Ånite matrices, when one only needs to
learn the conditional probabilities of some elements given
others. Nonetheless, if suÔ¨Éciently strong generative tech-
niques were used their performance could be comparable
to ours, though the same trade-oÔ¨Ä between training speed
and accuracy is expected to also be present for generative
models.

Examining generative models lead us towards more
general scenarios than the one considered here.
In the
current work we discussed families of feasibility SDP
problems where the structure of the problem is Ô¨Åxed.
This is a common scenario in applications, where {Fk}k
(the structure of the problem) is essentially Ô¨Åxed, and the
task must be solved for diÔ¨Äerent speciÔ¨Åc instances given
by v. If this is not the case then in principle Fk can be

provided next to v to the neural network. For the ex-
ample of matrix completion, a diÔ¨Äerent Fkk would mean
that diÔ¨Äerent elements of the matrix need to be Ô¨Ålled in,
which for example a generative model could tackle, as
previously discussed. In the current work we evaluated
our approach on such tasks, i.e. tasks where the structure
of the problem requires us to Ô¨Åll in a matrix, as shown in
Fig. 1, where the entries of Œì are either completely Ô¨Åxed
by v or are free optimization variables. For more general
settings variable elimination on the constraints can help
reduce the problem to this form, then allowing for our
method to be used with slight modiÔ¨Åcations.

Furthermore, one could examine even more generic
tasks by moving outside the realm of semideÔ¨Ånite pro-
grams to generic nonlinear objective functions and con-
straints, as in Eq. (1), where neural networks could be
trained to minimize a Lagrangian function, incorporating
all constraints and objectives with penalty terms. There
have been many works addressing optimization problems
using machine learning [45], however previous works ad-
dressing SDP speciÔ¨Åcally have been mostly focused on
developing neural networks for specialized hardware. In
principle these are quick, and for speciÔ¨Åc problems, such
as for semideÔ¨Ånite programming, they can guarantee con-
vergence [46, 47]. However, if simulated on a general-
purpose digital computer, these neural network optimiza-
tions are also slow, since they must evaluate the con-
straints many times before converging.

The choice of the training set is important, especially
since we are working in high-dimensional spaces. For
example training on random quantum points for the pri-
mal is very ineÔ¨Écient, as most of them are local points.
Another example is our preference of using the weighted
vertex sampling for the dual neural network. Most sam-
ples generated with hit and run sampling are within Q, so
the dual network focuses on performing well on that re-
gion. However, in order to function well on the isotropic
line, for example, it must also perform well on the region
outside Q, so that it can detect the boundary. We over-
came this diÔ¨Éculty by introducing the weighted vertex
sampling. In general some domain knowledge is useful in
choosing the training set for such neural network-based
SDP solvers.

Finally, an interesting question worth exploring more
in depth is the advantage of neural networks versus con-
In which scenario could such a neu-
ventional solvers.
ral network approach have an advantage compared to
standard solvers? Clearly, in application where many in-
stances of semideÔ¨Ånite programs must be solved quickly,
a neural network-based approach could be useful, for ex-
ample in calculating the safe zones of self-driving cars,
collision avoidance [10, 11], control systems and robotics
tasks [2, 12], black-box quantum random number gen-
eration and quantum protocols [13, 14], testing many
diÔ¨Äerent candidate materials in quantum chemistry and
many-body physics tasks [15‚Äì20] or bounding problems
in NP [12, 21]. Furthermore, we note that there are
additional potential advantages of using neural network

7

solvers for SDPs. One can use standard neural network
analysis tools, such as optimizing over the input to see
which inputs trigger the strongest response of the net-
work. For example in the NPA hierarchy if the distribu-
tion pœï(ab|xy) depends on parameters œï in some nonlin-
ear manner, then SDP solvers could not help us. How-
ever, with a trained neural network we could ask it to
Ô¨Ånd the a œï‚àó for which the maximal smallest eigenvalue
is as negative as possible, thus to Ô¨Ånd ‚Äúvery nonlocal‚Äù
behaviors in a sense.

In conclusion, due to the rich variety of machine learn-
ing architectures, there could be a myriad of ways to
tackle semideÔ¨Ånite programming. Here we demonstrated
a simple feedforward neural network approach to opti-
mization with semideÔ¨Ånite constraints which, by con-
struction, is unable to give false positives. The approach
is also applicable to the dual formulation of the SDP.
Our neural network, once trained, is orders of magni-
tudes quicker than standard SDP solvers when evaluating
multiple instances of the same type of problem. Though
it is less precise, the performance is acceptable for the
archetypal Bell scenario, and by changing network ar-
chitectures, one can tune the trade-oÔ¨Ä of precision and
speed.

VI. METHODS

Here we introduce a simple artiÔ¨Åcial neural network
architecture, the multilayer perceptron, and the details
of our implementation for feasibility SDP solving. For a
more in-depth, pedagogical introduction to modern neu-
ral networks we refer the interested reader to Ref. [31].

A multilayer perceptron is a model for a generic nonlin-
ear multivalued, multivariate function, i.e. HNN : Rs ‚Üí
Rt. It is constructed of a series of layer, each layer con-
sisting of an aÔ¨Éne and a subsequent nonlinear transfor-
mation. The depth of a neural network is the number
of layers used, d. A layer l is characterized by its width
wl and the activation function used in it, hl, though typ-
ically all layers (except the Ô¨Årst and the last) have the
same width w and activation h. The output of layer l is

rl+1 = hl(Wlrl + bl),

(13)

where the weight matrix Wl ‚àà Rwl+1 √ó Rwl and bias vec-
tor bl ‚àà Rwl+1 parametrize the aÔ¨Éne transformation, hl
is the Ô¨Åxed diÔ¨Äerentiable nonlinear ‚Äúactivation‚Äù function,
and is typically an element-wise operation, and rl ‚àà Rw
is the input of layer l, r1 ‚àà Rs being the input of the
model and rd ‚àà Rt being the output. The free, trainable
parameters of the model {Wl, bl}l are often collectively
referred to as the weights and are denoted by Œ∏.

A neural network is trained on the so-called training
data R = {ri
1}i, with the objective of minimizing a loss
function L(R|Œ∏) = (cid:80)
1, ri
d|Œ∏). The most common
algorithm to train a neural network is stochastic gradient
descent, in which a random subset of the training data, a
batch Rj, is taken and evaluated by the neural network.

i L(ri

8

For each batch the loss is evaluated and the weights are
updated according to the gradient of the loss function,

Œ∏(cid:48) = Œ∏ ‚àí Œ∑‚àáŒ∏L(Rj|Œ∏),

(14)

where Œ∑ ‚àà R+ is the learning rate. The process is re-
If the data is
peated with all batches of the data set.
Ô¨Ånite, then the algorithm reiterates over the data for
many epochs. However, in the application analyzed in
this work new training data can be artiÔ¨Åcially generated
on the go, hence we do not use epochs, but use fresh
data for each round. There are many variants of stochas-
tic gradient descent. In the current work we additionally
applied momentum to the updates, i.e. the updater re-
members the update of the previous step, ‚àÜŒ∏, and adds
this with a weight Œ± ‚àà R+, such that

Œ∏(cid:48) = Œ∏ ‚àí Œ∑‚àáŒ∏L(Rj|Œ∏) + Œ±‚àÜŒ∏.

(15)

This is an example of a procedure which helps to avoid
getting stuck in local minima during training. Typically
the learning rate is decayed during training so that we
can Ô¨Åne-tune the model towards the end.

Training is typically done until the loss appears to con-
verge or until a Ô¨Åxed number of steps. Once trained, the
neural network can be evaluated on new input instances,
and is often benchmarked on a test set, which is com-
posed of data that it hasn‚Äôt seen during training.

In the current work we used neural networks of depth
8 and a width is 3 times the number of SDP optimiza-
tion parameters (see Table II for primal task sizes). The
Ô¨Ånal layer width is precisely the number of SDP opti-
mization parameters. The input size is always 8, as this
is the number of parameters needed to characterize the
conditional probability vector p(ab|xy) for binary vari-
ables (i.e. the number of unique, physically observable
elements in (10)). The loss used is

L(r1, rd|Œ∏) = ‚àí min e.v. (Œì(r1, rd|Œ∏)) ,

(16)

where we introduced the function Œì(¬∑), which creates
the constraint matrix from the inputs and outputs (see
Eqs. (2), (10) for the primal and Eq. (3) for the dual), and
the e.v.(¬∑) function which returns the set of eigenvalues
of a matrix. Such an eigenvalue function is implemented
in the TensorFlow machine learning library [48]. Note
that the dependence on the weights Œ∏ is implicitly in the
output rd. Also, recall that the input r1 corresponds to

v in the generic introduction in the maintext, or p(ab|xy)
in the examined quantum case study.

Before feeding any input correlation into the network
(be that training or testing) we permute the labels in
p(ab|xy) such that it maximally violates the canonical
CHSH inequality (see e.g. Ref. [23]), then we apply the
standard preprocessing used with neural networks, that
for each feature the mean is 0 and variance is 1. In each
round of training we generate 10000 random p(ab|xy) vec-
tors either through hit and run sampling of the no signal-
ing polytope or with the weighted vertex sampling (see
Eq. (11)). We perform 800 rounds of training in total
with stochastic gradient descent, of which the Ô¨Årst 200
rounds have a Ô¨Åxed learning rate of 0.005 (0.0001 for the
dual network), while the rest have a decay rate of 0.99
per round, and the momentum is kept at a constant rate
of 0.8.

The neural network used for the dual task (Eq. 3)) is
slightly diÔ¨Äerent from the one used for the primal. We
have to restrict the outputs to be Ô¨Ånite, since the optimal
solution tends to inÔ¨Ånity for points where the dual is fea-
sible; we do this by replacing the linear activation used in
the Ô¨Ånal layer of the primal neural network with a tangent
hyperbolic activation function. All other activations in
the networks are exponential linear functions. Even with
this restriction the dual neural network tries to increase
its weights as much as possible in order to get marginal
improvements in the tangent hyperbolic functions (push-
ing outputs of neurons as close to 1 as possible). This
can lead to exploding gradients, which we counteract by
using the default Keras L2 activity regularizer on each
layer with weight 10‚àí6 [49].

VII. ACKNOWLEDGMENTS

Most of the computations were performed at Univer-
sity of Geneva on the Baobab cluster. TK, YC and
NB acknowledge Ô¨Ånancial support from the Swiss Na-
tional Science Foundation (Starting grant DIAQ, and
QSIT), and the European Research Council (ERC MEC).
JB and DC acknowledge support from Fundaci¬¥o Cellex,
Fundaci¬¥o Mir-Puig, Generalitat de Catalunya (CERCA,
AGAUR SGR 1381). JB additionally acknowledges sup-
port from the Spanish MINECO (Severo Ochoa SEV-
2015-0522) and the AXA Chair in Quantum Informa-
tion Science. DC additionally acknowledges support from
the Government of Spain (Ramon y Cajal fellowship,
FIS2020-TRANQI and Severo Ochoa CEX2019-000910-
S) and ERC AdG CERQUTE.

[1] H. Wolkowicz, R. Saigal, and L. Vandenberghe, Hand-
book of SemideÔ¨Ånite Programming: Theory Algorithms
and Applications (Springer Science & Business Media,
2012).

[2] L. Vandenberghe and S. Boyd, Applications of semidef-
inite programming, Applied Numerical Mathematics 29,
283 (1999).

[3] A. Majumdar, G. Hall, and A. A. Ahmadi, Recent Scal-
ability Improvements for SemideÔ¨Ånite Programming with

Applications in Machine Learning Control and Robotics,
Annual Review of Control, Robotics, and Autonomous
Systems 3, 331 (2020).

[4] S. Arora, E. Hazan, and S. Kale,

in 46th Annual
IEEE Symposium on Foundations of Computer Science
(FOCS‚Äô05) (2005), pp. 339‚Äì348.

[5] R. Jain and P. Yao, in 2011 IEEE 52nd Annual Sym-
posium on Foundations of Computer Science (2011), pp.
463‚Äì471.

[6] E. Hazan and T. Koren, A linear-time algorithm for trust
region problems, Mathematical Programming 158, 363
(2016).

[7] A. S. Bidyarthy, R. Raman, and D. Thomas, in Proceed-
ings of the 7th ACM India Computing Conference (Asso-
ciation for Computing Machinery, New York, NY, USA,
2014), COMPUTE ‚Äô14, pp. 1‚Äì8.

[8] D. A. Mazziotti, Large-Scale SemideÔ¨Ånite Programming
for Many-Electron Quantum Mechanics, Physical Review
Letters 106, 083001 (2011).

[9] S. Shah, A. K. Yadav, C. D. Castillo, D. W. Jacobs,
C. Studer, and T. Goldstein,
in Computer Vision ‚Äì
ECCV 2016, edited by B. Leibe, J. Matas, N. Sebe, and
M. Welling (Springer International Publishing, Cham,
2016), Lecture Notes in Computer Science, pp. 717‚Äì735.
[10] S. Prajna and A. Jadbabaie, in Hybrid Systems: Compu-
tation and Control, edited by R. Alur and G. J. Pappas
(Springer, Berlin, Heidelberg, 2004), Lecture Notes in
Computer Science, pp. 477‚Äì492.

[11] E. Frazzoli, Z.-H. Mao, J.-H. Oh, and E. Feron, Reso-
lution of ConÔ¨Çicts Involving Many Aircraft via Semidef-
inite Programming, Journal of Guidance, Control, and
Dynamics (2012).

[12] S. Boyd and L. Vandenberghe, SemideÔ¨Ånite Program-
ming Relaxations of Non-Convex Problems in Control
and Combinatorial Optimization,
in Communications,
Computation, Control, and Signal Processing: a tribute
to Thomas Kailath, edited by A. Paulraj, V. Roychowd-
hury, and C. D. Schaper (Springer US, Boston, MA,
1997), pp. 279‚Äì287.

[13] S. Pironio, A. Ac¬¥ƒ±n, S. Massar, A. B. de la Giroday, D. N.
Matsukevich, P. Maunz, S. Olmschenk, D. Hayes, L. Luo,
T. A. Manning, et al., Random numbers certiÔ¨Åed by Bell‚Äôs
theorem, Nature 464, 1021 (2010).

[14] J. B. Brask, A. Martin, W. Esposito, R. Houlmann,
J. Bowles, H. Zbinden, and N. Brunner, Megahertz-
Rate Semi-Device-Independent Quantum Random Num-
ber Generators Based on Unambiguous State Discrimi-
nation, Physical Review Applied 7, 054018 (2017).
[15] D. A. Mazziotti, First-order semideÔ¨Ånite programming
for the direct determination of two-electron reduced den-
sity matrices with application to many-electron atoms
and molecules, The Journal of Chemical Physics 121,
10957 (2004).

[16] S. Bravyi, D. Gosset, R. K¬®onig, and K. Temme, Approx-
imation algorithms for quantum many-body problems,
Journal of Mathematical Physics 60, 032203 (2019).
[17] M. Fukuda, B. J. Braams, M. Nakata, M. L. Overton,
J. K. Percus, M. Yamashita, and Z. Zhao, Large-scale
semideÔ¨Ånite programs in electronic structure calculation,
Mathematical Programming 109, 553 (2007).

[18] M. Nakata, H. Nakatsuji, M. Ehara, M. Fukuda,
K. Nakata, and K. Fujisawa, Variational calculations
of
fermion second-order reduced density matrices by
semideÔ¨Ånite programming algorithm, The Journal of

9

Chemical Physics 114, 8282 (2001).

[19] M. Nakata, B. J. Braams, K. Fujisawa, M. Fukuda, J. K.
Percus, M. Yamashita, and Z. Zhao, Variational calcula-
tion of second-order reduced density matrices by strong N-
representability conditions and an accurate semideÔ¨Ånite
programming solver, The Journal of Chemical Physics
128, 164113 (2008).

[20] M. Navascu¬¥es, A. Garc¬¥ƒ±a-S¬¥aez, A. Ac¬¥ƒ±n, S. Pironio, and
M. B. Plenio, A paradox in bosonic energy computations
via semideÔ¨Ånite programming relaxations, New Journal
of Physics 15, 023026 (2013).

[21] M. X. Goemans and D. P. Williamson, Improved approx-
imation algorithms for maximum cut and satisÔ¨Åability
problems using semideÔ¨Ånite programming, Journal of the
ACM 42, 1115 (1995).

[22] J. S. Bell, On the Einstein Podolsky Rosen paradox,

Physics Physique Fizika 1, 195 (1964).

[23] N. Brunner, D. Cavalcanti, S. Pironio, V. Scarani, and
S. Wehner, Bell nonlocality, Reviews of Modern Physics
86, 419 (2014).

[24] T. Kriv¬¥achy, Y. Cai, D. Cavalcanti, A. Tavakoli, N. Gisin,
and N. Brunner, A neural network oracle for quantum
nonlocality problems in networks, npj Quantum Informa-
tion 6, 1 (2020).

[25] K. Bharti, T. Haug, V. Vedral, and L.-C. Kwek, How to
Teach AI to Play Bell Non-Local Games: Reinforcement
Learning, arXiv:1912.10783 [quant-ph] (2019).

[26] A. Canabarro, S. Brito, and R. Chaves, Machine Learn-
ing Nonlocal Correlations, Physical Review Letters 122,
200401 (2019).

[27] A. A. Melnikov, P. Sekatski, and N. Sangouard, Setting
Up Experimental Bell Tests with Reinforcement Learning,
Physical Review Letters 125, 160401 (2020).

[28] M. Navascu¬¥es, S. Pironio, and A. Ac¬¥ƒ±n, Bounding the Set
of Quantum Correlations, Physical Review Letters 98,
010401 (2007).

[29] M. Navascu¬¥es, S. Pironio, and A. Ac¬¥ƒ±n, A convergent hi-
erarchy of semideÔ¨Ånite programs characterizing the set of
quantum correlations, New Journal of Physics 10, 073013
(2008).

[30] A. C. Doherty, Y. Liang, B. Toner, and S. Wehner, in
2008 23rd Annual IEEE Conference on Computational
Complexity (2008), pp. 199‚Äì210.

[31] I. Goodfellow, Y. Bengio, and A. Courville, Deep Learn-

ing (MIT Press, 2016).

[32] O. Nieto-Silleras, S. Pironio, and J. Silman, Us-
ing complete measurement statistics for optimal device-
independent randomness evaluation, New Journal of
Physics 16, 013035 (2014).

[33] J.-D. Bancal, L. Sheridan, and V. Scarani, More ran-
domness from the same data, New Journal of Physics
16, 033011 (2014).

[34] A. Pozas-Kerstjens, R. Rabelo, (cid:32)L. Rudnicki, R. Chaves,
D. Cavalcanti, M. Navascu¬¥es, and A. Ac¬¥ƒ±n, Bounding the
Sets of Classical and Quantum Correlations in Networks,
Physical Review Letters 123, 140503 (2019).

[35] E. Wolfe, A. Pozas-Kerstjens, M. Grinberg, D. Ros-
set, A. Ac¬¥ƒ±n, and M. Navascues, Quantum InÔ¨Çation:
A General Approach to Quantum Causal Compatibility,
arXiv:1909.10519 [quant-ph] (2020).

[36] J. Bowles, F. Baccari, and A. Salavrakos, Bound-
ing sets of sequential quantum correlations and device-
independent randomness certiÔ¨Åcation, Quantum 4, 344
(2020).

10

[37] J. F. Clauser, M. A. Horne, A. Shimony, and R. A. Holt,
Proposed Experiment to Test Local Hidden-Variable The-
ories, Physical Review Letters 23, 880 (1969).

[38] S. Popescu and D. Rohrlich, Quantum nonlocality as an

axiom, Foundations of Physics 24, 379 (1994).

[39] P. Rastall, Locality Bells Theorem and Quantum Mechan-

ics, Foundations of Physics 15, 963 (1985).

[40] L. A. KhalÔ¨Ån and B. Tsirelson, Quantum and quasi-
classical analogs of Bell inequalities., Symposium on the
Foundations of Modern Physics pp. 441‚Äì460 (1985).
[41] J. Barrett, N. Linden, S. Massar, S. Pironio, S. Popescu,
and D. Roberts, Nonlocal correlations as an information-
theoretic resource, Physical Review A 71, 022101 (2005).
[42] B. S. Cirel‚Äôson, Quantum generalizations of Bells inequal-
ity, Letters in Mathematical Physics 4, 93 (1980).
[43] R. L. Smith, EÔ¨Écient Monte Carlo Procedures for Gen-
erating Points Uniformly Distributed Over Bounded Re-
gions, Operations Research 32, 1296 (1984).

[44] C. B¬¥elisle, A. Boneh, and R. Caron, Convergence proper-
ties of Hit-and-Run samplers, Communications in Statis-

tics. Stochastic Models 14 (1998).

[45] Y. Bengio, A. Lodi, and A. Prouvost, Machine learning
for combinatorial optimization: A methodological tour
d‚Äôhorizon, European Journal of Operational Research
(2020).

[46] D. Jiang and J. Wang, A recurrent neural network for
real-time semideÔ¨Ånite programming, IEEE Transactions
on Neural Networks 10, 81 (1999).

[47] J. J. HopÔ¨Åeld and D. W. Tank, ‚ÄúNeural‚Äù computation of
decisions in optimization problems, Biological Cybernet-
ics 52, 141 (1985).

[48] Mart¬¥ƒ±n Abadi, Ashish Agarwal, Paul Barham, Eugene
Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado,
Andy Davis, JeÔ¨Ärey Dean, Matthieu Devin, et al., Ten-
sorFlow: Large-Scale Machine Learning on Heteroge-
neous Systems (2015).

[49] F. Chollet and others, Keras (2015).

