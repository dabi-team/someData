1
2
0
2

p
e
S
5
1

]
E
P
.
o
i
b
-
q
[

3
v
1
2
2
3
1
.
3
0
0
2
:
v
i
X
r
a

PLANNING AS INFERENCE
IN EPIDEMIOLOGICAL DYNAMICS MODELS

A PREPRINT

Frank Wood1,3,4, Andrew Warrington2, Saeid Naderiparizi1, Christian Weilbach1, Vaden Masrani1,
William Harvey1, Adam ´Scibior1, Boyan Beronov1, John Grefenstette5, Duncan Campbell5, and Ali Nasseri1

1Department of Computer Science, University of British Columbia
2Department of Engineering Science, University of Oxford
3MILA
4CIFAR AI Chair
5Epistemix Inc., Pittsburgh
{fwood,awarring,saeidnp,weilbach,vadmas,wsgh,ascibior,beronov}@cs.ubc.ca, ali.nasseri@ubc.ca,
{john.grefenstette,duncan.campbell}@epistemix.com

September 17, 2021

ABSTRACT

In this work we demonstrate how to automate parts of the infectious disease-control policy-making
process via performing inference in existing epidemiological models. The kind of inference tasks
undertaken include computing the posterior distribution over controllable, via direct policy-making
choices, simulation model parameters that give rise to acceptable disease progression outcomes.
Among other things, we illustrate the use of a probabilistic programming language that automates
inference in existing simulators. Neither the full capabilities of this tool for automating inference
nor its utility for planning is widely disseminated at the current time. Timely gains in understanding
about how such simulation-based models and inference automation tools applied in support of policy-
making could lead to less economically damaging policy prescriptions, particularly during the current
COVID-19 pandemic.

Keywords public health preparedness, epidemiological dynamics, inference, probabilistic programming, COVID-19

1

Introduction

Our goal in this paper is to demonstrate how the “planning as inference” methodology at the intersection of Bayesian
statistics and optimal control can directly aid policy-makers in assessing policy options and achieving policy goals,
when implemented using epidemiological simulators and suitable automated software tools for probabilistic inference.
Such software tools can be used to quickly identify the range of values towards which controllable variables should be
driven by means of policy interventions, social pressure, or public messaging, so as to limit the spread and impact of an
infectious disease such as COVID-19.

In this work, we introduce and apply a simple form of planning as inference in epidemiological models to automatically
identify policy decisions that achieve a desired, high-level outcome. As but one example, if our policy aim is to contain
infectious population totals below some threshold at all times in the foreseeable future, we can condition on this putative
future holding and examine the allowable values of controllable behavioural variables at the agent or population level,
which in the framework of planning as inference is formalized in terms of a posterior distribution. As we already know,
to control the spread of COVID-19 and its impact on society, policies must be enacted that reduce disease transmission
probability or lower the frequency and size of social interactions. This is because we might like to, for instance, not
have the number of infected persons requiring hospitalization exceed the number of available hospital beds.

 
 
 
 
 
 
A PREPRINT - SEPTEMBER 17, 2021

Throughout this work, we take a Bayesian approach, or at the very least, a probabilistic consideration of the task.
Especially in the early stages of a new outbreak, the infectious dynamics are not known precisely. Furthermore, the
spread of the disease cannot be treated deterministically, as a result of either fundamental variability in the social
dynamics that drive infections, or of uncertainty over the current infection levels, or of uncertainty over appropriate
models for analyzing the dynamics. Therefore, developing methods capable of handling such uncertainty correctly
will allow for courses of action to be evaluated and compared more effectively, and could lead to “better” policies: a
policy that surpasses the desired objective with 55% probability, but fails with 45% probability, may be considered
“worse” than a policy that simply meets the objective with 90% probability. Bayesian analysis also offers a form of
probabilistic inference in which the contribution of individual variables to the overall uncertainty can be identiﬁed and
quantiﬁed. Beyond simply obtaining “the most effective policy measure,” this may be of interest to analysts trying to
further understand why certain measures are more effective than others.

We ﬁrst show how the problem of policy planning can be formulated as a Bayesian inference task in epidemiological
models. This framing is general and extensible. We then demonstrate how particular existing software tools can be
employed to perform this inference task in preexisting stochastic epidemiological models, without modifying the model
itself or placing restrictions on the models that can be analyzed. This approach is particularly appealing, as it decouples
the speciﬁcation of epidemiological models by domain experts from the computational task of performing inference.
This shift allows for more expressive and interpretable models to be expediently analyzed, and the sophistication of
inference algorithms to be adjusted ﬂexibly.

As a result, the techniques and tools we review in this paper are applicable to simulators ranging from simple
compartmental models to highly expressive agent-based population dynamics models. In the former, the controls
available to policy-makers are blunt – e.g., “reduce social interactions by some fractional amount” – but how best to
achieve this is left as an exercise for policy-makers. In the latter, variables like “probability of individuals adhering to
self-isolation” and “how long should schools be closed if at all” can be considered and evaluated in combination and
comparison to others as potential ﬁne-grained controls that could achieve the same policy objective more efﬁciently.

When governments impose any such controls, both citizens and ﬁnancial markets want to know how draconian these
measures must be and for how long they have to be in effect. Policy analysis based on models that reﬂect variability in
resources such as healthcare facilities in different jurisdictions could hopefully make the answers to these questions
more precise and the controls imposed more optimal in the utility maximizing sense. The same holds for the difference
between models that can or cannot reﬂect variations in population mixing between rural and urban geographic areas. A
person living in a farming county in central Illinois might reasonably wonder if it is as necessary to shelter in place
there as it is in Chicago.

Current approaches to model-based policy-making are likely to be blunt. Simple models, e.g., compartmental models
with few compartments, are rapid to ﬁt to new diseases and easy to compute, but are incapable of evaluating policy
options that are more ﬁne-grained than the binning used, such as regionalized measures. The net effect of being
able to only consider blunt controls arguably has contributed to a collective dragging of feet, even in the face of the
current COVID-19 pandemic. This delayed reaction, combined with brute application of control, has led to devastating
socioeconomic impact, with many sectors such as education, investment markets and small-medium enterprises being
directly impacted.

We can and should be able to do better. We believe, and hope to demonstrate, that models and software automation
focused on planning as inference for policy analysis and recommendation is one path forward that can help us better
react to this and future pandemics, and improve our public health preparedness.

We upfront note that the speciﬁc models that we use in this paper are far from perfect. First, the pre-existing models we
use to demonstrate our points in this paper are only crudely calibrated to present-day population dynamics and speciﬁc
COVID-19 characteristics. We have made some efforts on the latter point, in particular sourcing a COVID-19 adapted
compartmental model [1, 2, 3] and parameters from [4, 5, 6, 7, 8, 9, 10, 11, 12, 13], but we stress this limitation. In
addition, in simple cases, the type of problems for which we discuss solutions in this paper may be solved with more
straightforward implementations involving parameter sweeps and “manual” checking for desired policy effects, albeit at
potentially higher human cost. In this sense, our goal is not to claim fundamental novelty, uniqueness or superiority of
any particular inference technique, but rather to raise awareness for the practical feasibility of the Bayesian formulation
of planning as inference, which offers a higher level of ﬂexibility and automation than appears to be understood widely
in the policy-making arena.

Note also that current automated inference techniques for stochastic simulation-based models [14, 15, 16, 17, 18]
are computationally demanding and are by their very nature approximate. The academic topic at the core of this
paper and the subject of a signiﬁcant fraction of our academic work [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29] deals
with this challenge. Furthermore, the basic structure of simulators currently available may lack important policy-

2

A PREPRINT - SEPTEMBER 17, 2021

inﬂuenceable interaction parameters that one might like to examine. If viewed solely in light of the provided examples,
our contribution could reasonably be seen both as highlighting the utility of inference for planning in this application
setting, and as automating the manual selection of promising policy parameters. The tools we showcase are capable of
signiﬁcantly more; however, for expediency and clarity, we have focused on control as inference, an application that
has seen relatively little speciﬁc coverage in the literature, and the simplest possible inference methods which do not
require familiarity with the technical literature on approximate Bayesian inference. We leave other straightforward
applications of automated inference tools in this application area, like parameter inference from observed outbreak data
[14, 15, 16, 17, 18], to others.

That being said, our hope is to inform ﬁeld epidemiologists and policy-makers about an existing technology that could,
right now, be used to support public policy planning towards more precise, potentially tailored interventions that ensure
safety while also potentially leading to fewer economic ramiﬁcations. Fully probabilistic methods are apparently only
relatively recently being embraced by the epidemiology community [30, 31], while the communities for approximate
Bayesian inference and simulation-based inference have remained mostly focused on the tasks of parameter estimation
and forecasting [14, 15, 16], rather than control as inference. Beyond this demonstration, we hope to encourage timely
and signiﬁcant developments on the modelling side, and, if requested, to actually aid in the ﬁght against COVID-19
by helping arm policy-makers with a new kind of tool and training them how to use it rapidly. Finally, we hope to
engage the machine learning community in the ﬁght against COVID-19 by helping translate between the speciﬁc
epidemiological control problem and the more general control problem formulations on which we work regularly.

2 Assumptions and Findings

We start with the assumption that the effectiveness of policy-making can be signiﬁcantly improved by consulting the
outputs of model-based tools which provide quantitative metrics for the ability of particular policy actions to achieve
speciﬁc formalized goals. In particular, we imagine the following scenario. There exists some current population, and
the health status of its constituents is only partially known. There exists a disease whose transmission properties may be
only partially known, but whose properties cannot themselves be readily controlled. There exists a population dynamic
that can be controlled in some limited ways at the aggregate level. There exists a “policy goal” or target which we will
refer to as the allowable, allowed, or goal set of system trajectories. An example of this could be “the total number of
infectious persons should not ever exceed some percentage of the population” or “the ﬁrst date at which the total number
of infectious persons exceeds some threshold is at least some number of days away.” We ﬁnally assume an implied set
of allowable policy prescriptions, deﬁned in the sense that population dynamics behaving according to such policies
will be exactly the ones to attain the goal with high probability. In general, this set of allowable policies is intractable
to compute exactly, motivating the use of automated tools implementing well established approximate Bayesian
inference methods. We explicitly do not claim “completeness” of the stochastic dynamic models in any realistic sense,
disregarding complications such as potential agent behaviour in strategic response to regionalized policies, and do not
attempt to quantify all costs and beneﬁts of the considered policies, for example economic or cultural impacts. Rather,
formulating the problem described above in terms of Bayesian inference results in a posterior distribution over policies
which have been conditioned on satisfying the formalized policy desiderata within the formalized dynamical model.
Effectively, this is to be understood as “scrutinizing,” “weighting,” “prioritizing,” or “focusing” potential policy actions
for further consideration, rather than as an “optimal” prescription. When selecting a policy based on the posterior
distribution, policy-makers are expected to account for additional, more complex socio-economic phenomena, costs and
beneﬁts using their own judgment.

The only things that may safely be taken away from this paper are the following:

• Existing compartmental models and agent-based simulators can be used as an aid for policy assessment via a

Bayesian planning as inference formulation.

• Existing automated inference tools can be used to perform the required inferential computation.

• Opportunities exist for various ﬁelds to come together to improve both understanding of and availability of

these techniques and tools.

• Further research and development into modelling and inference is recommended to be immediately undertaken
to explore the possibility of more efﬁcient, less economically devastating control of the COVID-19 pandemic.

What should not be taken away from this paper are any other conclusions, including in particular the following:

• Any conclusion or statements that there might exist less aggressive measures that could still be effective in

controlling COVID-19.

3

A PREPRINT - SEPTEMBER 17, 2021

• Any substantial novelty, uniqueness or performance claims about the particular numerical methods and
software implementations for Bayesian inference which were used for the purpose of demonstrating the
ﬁndings above. In particular, on the one hand, similar results could have been obtained using other software
implementation strategies in principle, and on the other hand, more advanced inference methods could have
been applied using the same software tools at the expense of rendering the conceptual exposition less accessible
to audiences outside of the Bayesian inference community.

As scientists attempting to contribute “across the aisle,” we use more qualifying statements than usual throughout this
work in an attempt to reduce the risk of misunderstandings and sensationalism.

3 Approach

In this section we formalize the policy-making task in terms of computing conditional probabilities in a probabilistic
model of the disease spread. While the technical description can get involved at times, we emphasize that in practice the
probabilistic model is already deﬁned by an existing epidemiological simulator and the probabilistic programming tools
we describe in this paper provide the ability to compute the required conditional probabilities automatically, including
automatically introducing required approximations, so the users only need to focus on identifying which variables to
condition on, and feeding real-world data to the system. Readers familiar with framing planning as inference may wish
to skip directly to Section 4.

Being able to perform probabilistic inference is crucial for taking full advantage of available simulators in order to
design good policies. This is because in the real world, many of the variables crucially impacting the dynamics of
simulations are not directly observable, such as the number of infectious but asymptomatic carriers or the actual number
of contacts people make in different regions each day. These variables are called latent, as opposed to observable
variables such as the number of deaths or the number of passengers boarding a plane each day, which can often be
directly measured with high accuracy. It is often absolutely crucial to perform inference over some latent variables to
achieve reliable forecasts. For example, the future course of an epidemic like COVID-19 is driven by the number of
people currently infected, rather than the number of people currently hospitalized, while in many countries in the world
currently only the latter is known.

While performing inference over latent variables is very broadly applicable, the scenario described above being but
one example, in this paper we primarily address the problem of choosing good policies to reduce the impact of an
epidemic which can also be formulated as an inference problem. This choice of problem was driven by the hypothesis
that the search for effective controls may not in fact be particularly well-served by automation at the current time. In the
epidemiological context, the questions we are trying to answer are ones like “when and for how long do we need to
close schools to ensure that we have enough ventilators for everyone who needs them?” While obviously this is overly
simplistic and many different policy decisions need to be enacted in tandem to achieve good outcomes, we use this
example to illustrate tools and techniques that can be applied to problems of realistic complexity.

Our approach is not novel, it has been studied extensively under the name “control via planning as inference” and is
now well understood [32, 33, 34, 35]. What is more, the actual computations that result from following the recipes for
planning as inference can be, in some cases readily, manually replicated. Again, our aim here is to inform or remind a
critically important set of policy-makers and modellers that these methodologies are extremely relevant to the current
crisis. Moreover, at least partial automation of model-informed policy-guidance is achievable using existing tools, and,
may even lead to sufﬁcient computational savings to make their use in current policy-making practical. Again, our
broader hope here is to encourage rapid collaborations leading to more targeted and less-economically-devastating
policy recommendations.

3.1 An Abstract Epidemiological Dynamics Model

In this work we will look at both compartmental and agent-based models. An overview of these speciﬁc types of models
appears later. For the purposes of understanding our approach to planning as inference, it is helpful to describe the
planning as inference problem in a formalism that can express both types of models. The approach of conducting
control via planning as inference follows a general recipe:

1. Deﬁne the latent and control parameters of the model and place a prior distribution over them.
2. Either or both deﬁne a likelihood for the observed disease dynamics data and design constraints that deﬁne

acceptable disease progression outcomes.

3. Do inference to generate a posterior distribution on control values that conditions both on the observed data

and the deﬁned constraints.

4

A PREPRINT - SEPTEMBER 17, 2021

4. Make a policy recommendation by picking from the posterior distribution consisting of effective control values

according to some utility maximizing objective.

We focus on steps 1-3 of this recipe, and in particular do not explore simultaneous conditioning. We ignore the observed
disease dynamics data and focus entirely on inference with future constraints. We explain the rationale behind these
choices near the end of the paper.

Very generally, an epidemiological model consists of a set of global parameters and time dependent variables. Global
parameters are (θ, η), where θ denotes parameters that can be controlled by policy directives (e.g. close schools for
some period of time or decrease the general level of social interactions by some amount), and η denotes parameters
which can not be affected by such measures (e.g. the incubation period or fatality rate of the disease).

The time dependent variables are (Xt, Yt, Zt) and jointly they constitute the full state of the simulator. Xt are the
latent variables we are doing inference over (e.g. the total number of infected people or the spatio-temporal locations
of outbreaks), Yt are the observed variables whose values we obtain by measurements in the real world (e.g. the total
number of deaths or diagnosed cases), and Zt are all the other latent variables whose values we are not interested in
knowing (e.g. the number of contacts between people or hygiene actions of individuals). For simplicity, we assume that
all variables are either observed at all times or never, but this can be relaxed.

The time t can be either discrete or continuous. In the discrete case, we assume the following factorization

p(θ, η, X0:T , Y0:T , Z0:T ) = p(θ)p(η)p(X0, Y0, Z0 |

θ, η)

T

t=1
(cid:89)

p(Xt, Yt, Zt |

X0:t−1, Y0:t−1, Z0:t−1, θ, η).

(1)

Note that we do not assume access to any particular factorization between observed and latent variables. We assume
that a priori the controllable parameters θ are independent of non-controllable parameters η to avoid situations where
milder control measures are associated with better outcomes because they tend to be deployed when the circumstances
are less severe, which would lead to erroneous conclusions when conditioning on good outcomes in Section 3.3.

3.2

Inference

The classical inference task [14, 15, 16, 17, 18] is to compute the following conditional probability

p(η, X0:T |

Y0:T , θ) =

p(η, X0:T , Z0:T |

Y0:T , θ) dZ0:T .

(2)

(cid:90)

In the example given earlier Xt would be the number of infected people at time t and Yt would be the number of
hospitalized people at time t. If the non-controllable parameters η are known they can be plugged into the simulator,
otherwise we can also perform inference over them, like in the equation above. This procedure automatically takes into
account prior information, in the form of a model, and available data, in the form of observations. It produces estimates
with appropriate amount of uncertainty depending on how much conﬁdence can be obtained from the information
available.

The difﬁculty lies in computing this conditional probability, since the simulator does not provide a mechanism to sample
from it directly and for all but the simplest models the integral cannot be computed analytically. The main purpose
of probabilistic programming tools is to provide a mechanism to perform the necessary computation automatically,
freeing the user from having to come up with and implement a suitable algorithm. In this case, approximate Bayasian
computation (ABC) would be a suitable tool. We describe it below, emphasizing again that its implementations are
already provided by existing tools [14, 15, 16, 17, 18].
The main problem in this model is that we do not have access to the likelihood p(Yt |
the standard importance sampling methods. To use ABC, we extend the model with auxiliary variables Y obs
represent the actual observations recorded, and use a suitably chosen synthetic likelihood p(Y obs
Effectively, that means we’re solving the following inference problem,

Xt, θ, η) so we can not apply
0:T , which
Yt), often Gaussian.

|

t

p(X0:T |

p(η, X0:T , Y0:T , Z0:T |
which we can solve by importance sampling from the prior. Algorithmically, this means independently sampling a large
number N of trajectories from the simulator

Y obs
0:T , θ) dY0:T dZ0:T dη,

Y obs
0:T , θ) =

(cid:90) (cid:90) (cid:90)

(3)

(η(i), X (i)

0:T , Y (i)

0:T , Z (i)
0:T )

i.i.d.
∼

p(η, X0:T , Y0:T , Z0:T |

θ)

for i

1, . . . , N

∈ {

,
}

(4)

5

computing their importance weights

wi =

and approximating the posterior distribution

(cid:80)

Y (i)
0:T )

p(Y obs
0:T |
N
j=1 p(Y obs
0:T |

,

Y (j)
0:T )

N

i=1
(cid:88)

p(X0:T |

Y0:T , θ)

ˆp(X0:T |

≈

Y0:T , θ) =

A PREPRINT - SEPTEMBER 17, 2021

(5)

(6)

wiδX (i)

0:T

(X0:T ),

where δ is the Dirac delta putting all the probability mass on the point in its subscript. In more intuitive terms, we are
approximating the posterior distribution with a collection of weighted samples where weights indicate their relative
probabilities.

3.3 Control as Inference: Finding Actions That Achieve Desired Outcomes

In traditional inference tasks we condition on data observed in the real world. In order to do control as inference, we
instead condition on what we want to observe in the real world, which tells us which actions are likely to lead to such
observations. This is accomplished by introducing auxiliary variables that indicate how desirable a future state is or is
, where 1 means that
not. In order to keep things simple, here we restrict ourselves to the binary case where Yt ∈ {
}
the situation at time t is acceptable and 0 means it is not. This indicates which outcomes are acceptable, allowing us
to compute a distribution over those policies, while leaving the choice of which speciﬁc policy likely to produce an
acceptable outcome to policymakers. For example, Yt can be 1 when the number of patients needing hospitalization at a
given time t is smaller than the number of hospital beds available and 0 otherwise.

0, 1

To ﬁnd a policy θ that is likely to lead to acceptable outcomes, we need to compute the posterior distribution

p (θ

| ∀t : Yt = 1) ,

(7)

Once again, probabilistic programming tools provide the functionality to compute this posterior automatically. In this
case, rejection sampling would be a simple and appropriate inference algorithm. The rejection sampling algorithm
repeatedly samples values of θ from the prior p(θ), runs the full simulator using θ, and keeps the sampled θ only if
all Yt are 1. The collection of accepted samples approximates the desired posterior. We use rejection sampling in our
agent-based modeling experiments, but emphasize that other, more complex and potentially more computationally
efﬁcient, approaches to computing this posterior exist.

This tells us which policies are most likely to lead to a desired outcome but not how likely a given policy is to lead to
that outcome. To do that, we can evaluate the conditional probability p(
θ), which is known as the model
evidence, for a particular θ. A more sophisticated approach would be to condition on the policy leading to a desired
outcome with a given probability p0, that is

∀t : Yt = 1

|

|

|

p (

p (θ

θ) > p0) .

∀t : Yt = 1
For example, we could set p0 = 0.95 to ﬁnd a policy that ensures availability of hospital beds for everyone who needs
one with at least 95% probability. The conditional probability in Equation 8 is more difﬁcult to compute than the one in
Equation 7. It can be approximated by methods such as nested Monte Carlo (NMC) [23], which are natively available
in advanced probabilistic programming systems such as Anglican [36] and WebPPL [37] but in speciﬁc cases can also
be implemented on top of other systems, such as PyProb [38], with relatively little effort, although using NMC usually
has enormous computational cost.
p(θ), then draw N samples of
To perform rejection sampling with nested Monte Carlo, we ﬁrst draw a sample θi ∼
Y (j)
θi) and reject θi if fewer than p0N of sampled sequences of Y s are all 1s, otherwise we accept it.
0:T
This procedure is continued until we have a required number K of accepted θs. For sufﬁciently high values of N and
K, this algorithm approximates the posterior distribution (8) arbitrarily well.

p(Y0:T |

i.i.d.
∼

(8)

However we compute the posterior distribution, it contains multiple values of θ that represent different policies that, if
implemented, can achieve the desired result. In this setup it is up to the policymakers to choose a policy θ∗ that has
support under the posterior, i.e. yields the desired outcomes, taking into account some notion of utility.

Crucially, despite their relative simplicity, the rejection sampling algorithms we have discussed evaluate randomly
sampled values of θ. This is a fundamental difference from the commonly used grid search over a deterministic array of
parameter values. In practical terms, this is important because “well distributed” random samples are sufﬁcient for
experts to gauge the quantities of interest, and avoid grid searches that would be prohibitively expensive for θ with
more than a few dimensions.

6

3.4 Stochastic Model Predictive Control: Reacting to What’s Happened

A PREPRINT - SEPTEMBER 17, 2021

During an outbreak governments continuously monitor and assess the situation, adjusting their policies based on newly
available data. A convenient theoretical and general framework to formalize this is that of model predictive control [39].
In this case, Yt consists of variables Y data
that can be measured as the epidemic unfolds (such as the number of deaths)
and the auxiliary variables Y aux
that indicate whether desired goals were achieved, just like in Section 3.3. Say that at
t
time t = 0 the policymakers choose a policy to enact θ∗

t

0 based on the posterior distribution
∀t>0 : Y aux

, Z0,

t

X0, Y data
0

= 1)p(X0, Z0) dX0 dZ0.

(9)

p(θ

| ∀t>0 : Y aux

t

= 1) =

p(θ

|

(cid:90) (cid:90)

Then at time t = 1 they will have gained additional information Y data
, leading to a new belief over the current state
that we denote as ˆp1(X1, Z1), for which we give a formula in the general case in Equation 11. The policymakers then
choose the policy θ∗

1 from the posterior distribution p(θ

= 1).

1

| ∀t>1 : Y aux

t

Generally, at time t we compute the posterior distribution conditioned on the current state and achieving desirable
outcomes in the future

p(θ

| ∀t(cid:48)>t : Y aux

t(cid:48) = 1) =

p(θ

|

Xt, Y data
t

, Zt,

(cid:90) (cid:90)

Policymakers then can use this distribution to choose the policy θ∗
computed by inference

t(cid:48) = 1)ˆpt(Xt, Zt) dXt dZt.

∀t(cid:48)>t : Y aux
t that is actually enacted. The current belief state is

(10)

ˆp(Xt, Zt) =

p(Xt, Zt |

Yt, θ∗

t , η, Xt−1, Yt−1, Zt−1)ˆp(Xt−1, Zt−1) dXt−1 dZt−1.

(11)

(cid:90) (cid:90)

Equation 11 can be computed using methods described in Section 3.2, while Equation 10 can be computed using
methods described in Section 3.3. As such, the policy enacted evolves over time, as a result of re-solving for the optimal
control based on new information.

We note that what we introduce here as MPC may appear to be slightly different from what is commonly referred to as
model predictive control [40]. Firstly, instead of solving a ﬁnite-dimensional optimization problem over controls at each
step, we perform a Bayesian update step and sample from the resulting posterior distribution over controls. Secondly, in
more traditional applications of MPC a receding horizon [41] is considered, where a ﬁnite and ﬁxed-length window is
considered. The controls required to satisfy the constraint over that horizon are then solved for and applied – without
consideration of timesteps beyond this ﬁxed window. At the next time step, the controls are then re-solved for. In this
t time steps, as opposed to allowing a variable policy
work, we rather consider a constant policy for the remaining T
(discussed below) over a ﬁxed window. We note that time-varying controls are fully permissible under the framework
we present, as we demonstrate in Section 3.5. Furthermore, we could easily consider a ﬁxed horizon, just by changing
to be equal to one for t(cid:48) > t + p, where p is the length of the window being considered. Both of
the deﬁnition of Y aux
these extensions are provisioned for under the framework we provide, and could be used to implement what might be
considered as more conventional stochastic MPC, but with all the auxiliary beneﬁts of Bayesian inference.

−

t(cid:48)

t

| ∀t>1 : Y aux

Before we proceed, it is critical to note that the posterior p(θ
= 1) describes the probability, given the
dynamic model and the currently available information, for the parameters θ to achieve the policy goals. As such, our
approach provides a method for “screening” policies such that candidate policies that achieve the required outcomes
are found. What it does not take into account is the relative “cost” of each policy, or, how best to achieve the required
parameter values. For instance, in the SEI3R examples we present later, we learn the reduction in transmission required
to avoid exceeding an infection threshold. The reduction in transmission can be achieved (for instance) by encouraging
hand-washing and social distancing. While the method will identify whether or not a particular level of transmission
will achieve the desired outcome, it does not indicate the optimal trade-off between the cost of a particular policy, the
amount that the policy exceeds the required outcome, and the probability of the outcome. A human must therefore
select, from the set of compliant policies identiﬁed, the policy that maximizes utility while minimizing cost. Therefore,
this method is an important component of a wider policy making toolkit, as opposed to an oracle that can dictate the
optimal policy decisions.

3.5 Time-Varying Control: Long Term Planning

It is also possible to explicitly model changing policy decisions over time, which enables more detailed planning, such
as when to enact certain preventive measures such as closing schools. Notationally, this means instead of a single θ
there is a separate θt for each time t. We can then ﬁnd a good sequence of policy decisions by performing inference just
like in Section 3.3 by conditioning on achieving the desired outcome

p(θ0:T | ∀

t : Yt = 1).

7

(12)

A PREPRINT - SEPTEMBER 17, 2021

The inference problem is now more challenging, since the number of possible control sequences grows exponentially
with the time horizon. Still, the posterior can be efﬁciently approximated with methods such as Sequential Monte Carlo.

It is straightforward to combine this extension with model predictive control from Section 3.4. The only required
modiﬁcation is that in Equation 10 we need to condition on previously enacted policies and compute the posterior over
all future policies.

p(θt+1:T | ∀t(cid:48)>t Y aux

t(cid:48) = 1) =

(cid:90) (cid:90)

p(θt+1:T |

θ∗
0:t, Xt, Y data

t

, Zt,

∀t(cid:48)>t : Y aux

t(cid:48) = 1)ˆpt(Xt, Zt) dXt dZt.

(13)

At each time t the policymakers only choose the current policy θ∗
t , without committing to any future choices. This
combination allows for continuously reevaluating the situation based on available data, while explicitly planning
for enacting certain policies in the future. While here we explicitly consider only open-loop control policies, this
re-planning allows new information to be taken into account, and facilitates reactionary policy decisions to evolving
situations.

In models with per-timestep control variables θt, it is very important that in the model (but not in the real world) the
enacted policies must not depend on anything else. If the model includes feedback loops for changing policies based on
the evolution of the outbreak, it introduces positive correlations between lax policies and low infection rates (or other
measures of severity of the epidemic), which in turn means that conditioning on low infection rates is more likely to
produce lax policies. This is a known phenomenon of reversing causality when correlated observational data is used to
learn how to perform interventions [42].

We note another potential pitfall that may be exacerbated by time-varying control: if the model used does not accurately
reﬂect reality, any form of model-based control is likely to lead to poor results. To some extent, this can be accounted
for with appropriate distributions reﬂecting uncertainty in parameter values. However, given the difﬁculty of modeling
human behavior, and especially of modeling people’s reactions to novel policies, there is likely to be some mismatch
between modeled and real behavior. To give an example of a possible ﬂaw in an agent-based model: if a proposed
ﬁne-grained policy closed one park while keeping open a second, nearby, park, the model may not account for the likely
increase in visitors to the second park. The larger and more ﬁne-grained (in terms of time or location), the space of
considered policies is, the more such deﬁciencies may exist. We therefore recommend that practitioners restrict the
space of considered policies to those which are likely to be reasonably well modeled.

3.6 Automation

We have intentionally not really explained how one might actually computationally characterize any of the conditional
distributions deﬁned in the preceding section. For the compartmental models that follow, we provide code that directly
implements the necessary computations. Alternatively we could have used the automated inference facilities provided
by any number of packages or probabilistic programming systems. Performing inference as described in existing,
complex simulators is much more complex and not nearly as easy to implement from scratch. However, it can now be
automated using the tools of probabilistic programming.

3.6.1 Probabilistic Programming

Probabilistic programming [43] is a growing subﬁeld of machine learning that aims to build an analogous set of tools
for automating inference as automatic differentiation did for continuous optimization. Like the gradient operator of
languages that support automatic differentiation, probabilistic programming languages introduce observe operators that
denote conditioning in the probabilistic or Bayesian sense. In those few languages that natively support nested Monte
Carlo [36, 44], language constructs for deﬁning conditional probability objects are introduced as well. Probabilistic
programming languages (PPLs) have semantics [45] that can be understood in terms of Bayesian inference [46, 47, 48].
The major challenge in designing useful PPL systems is the development of general-purpose inference algorithms
that work for a variety of user-speciﬁed programs. The work in the paper uses only the very simplest, and often least
efﬁcient, general purpose inference algorithms, importance sampling and rejection sampling. Others are covered in
detail in [43].

Of all the various probabilistic programming systems, only one is readily compatible with inference in existing stochastic
simulators: PyProb[49]. Quoting from its website1 “PyProb is a PyTorch-based library for probabilistic programming
and inference compilation. The main focus of PyProb is on coupling existing simulation codebases with probabilistic
inference with minimal intervention.” A textbook, technical description of how PyProb works appears in [43, Chapt. 6].

1https://github.com/pyprob/pyprob

8

A PREPRINT - SEPTEMBER 17, 2021

Recent examples of its use include inference in the standard model of physics conditioning on observed detector outputs
[50, 51], inference about internal composite material cure processes through a composite material cure simulator
conditioned on observed surface temperatures [52], and inference about malaria spread in a malaria simulator [53].

3.6.2 Alternative Approaches

It is important to note upfront that our ultimate objective is to understand the dependence of the policy outcome on the
controllable parameters (for instance, as deﬁned by Equation (7) and (8)). There are a litany of methods to quantify this
dependency. Each method imposes different constraints on the model family that can be analyzed, and the nature of the
solution obtained. For instance, the fully Bayesian approach we take aims to quantify the entire distribution, whereas
traditional optimal control methods may only seek a pointwise maximizer of this probability. Therefore, before we
introduce the models we analyze and examples we use to explore the proposed formulation, we give a brief survey
of alternative approaches one could use to solve this problem, and give the beneﬁts and drawbacks of our proposed
formulation compared to these approaches.

The traditional toolkits used to analyze problems of this nature are optimal control [54, 55, 56, 57] and robust
control [58, 59, 60]. Most generally, optimal control solves for the control inputs (here denoted θ) such that some
outcome is achieved (here denoted Y aux
∀t>0) while minimizing the associated cost of the controls. An example
of this may be successfully maintaining stable ﬂight while minimizing fuel expenditure. However, for the controls to be
optimal, this assumes the model is correct. Alternatively, robust control does not assume that the model is correct, and
instead solves for controls that are maximally robust to the uncertainty in the model, while still achieving the desired
outcome.

= 1

t

Many traditional control approaches can exploit a mathematical model of the system to solve for controls that consider
multiple timesteps, referred to as model-predictive control (MPC) [61, 62, 39]. Alternatively, control methods can be
model-free, where there is no notion of the temporal dynamics of the system being controlled, such as the canonical PID
control. Model-based methods often solve for more effective control measures with lower overall computational costs,
by exploiting the information encoded in the model. However, model-predictive control methods are only applicable
when a (accurate) model is available.

One could re-frame the objective as trying to maximize the reward of some applied controls. Here, reward may be a 0-1
indicator corresponding to whether or not the hospital capacity was exceeded at any point in time. The reward may
also be more sophisticated, such as by reﬂecting the total number of people requiring hospital treatment, weighted by
how critical each patient was. Reward may also internalize some notion of the cost of a particular control. Shutting
workplaces may prevent the spread of infection, but has economic and social implications that (at least partially)
counteract the beneﬁt of reducing the infection rate. This can be implemented as earning progressively more negative
reward for stronger policies.

This type of analysis is formalized through reinforcement learning (RL) [63, 64, 65, 57, 66]. In RL, a policy, here θ, is
solved for that maximizes the expected reward. RL is an incredibly powerful toolkit that can learn highly expressive
policies that vary as a function of time, state, different objectives etc. RL methods can also be described as model-
based [67] and model-free [57] analogously to traditional control methods. While we do not delve into RL in detail here,
it is important to highlight as an alternative approach, and refer the reader to Levine [35] for a more detailed introduction
of RL, [57] for discussion of the relationship between RL and control methods, and Levine [35] for discussion of the
relationship between RL and planning-as-inference.

However, a critical drawback of both control and RL is the strong dependence on the loss functions or speciﬁc models
considered, both in terms of convergence and the optimal solution recovered [68]. This dependence may therefore
mean that the solution recovered is not representative of the “true” optimal solution. Furthermore, RL approaches can
be incredibly expensive to train, especially in high-dimensional time series models, with a large array of controls and
sparse rewards. More traditional control-based methods can be limited in the models that they can analyze, both in
terms of the transition distribution and the range of controls that can be considered. Finally, both RL and control-based
approaches offer limited insight into why certain controls were proposed. This can limit the ability of researchers and
modellers to expediently investigate the emergent properties of complex, simulation-based models. Furthermore, this
lack of transparency may be disadvantageous for policy-makers, who may be required to justify why certain policy
decisions were made, and the conﬁdence with which that policy decision was believed to be optimal.

All of these methods, at least in terms of their core intentions, are very similar. Different methods impose different
In this work, we take
restrictions on the models that can be analyzed, and the nature of the solution obtained.
the approach of framing control and planning as fully Bayesian inference with a binary objective. We choose this
formulation as it places very few restrictions on the model class that can be analyzed, allows uncertainty to be succinctly
handled throughout the inference, a broad range of objectives to be deﬁned under the same framework, and correctly

9

A PREPRINT - SEPTEMBER 17, 2021

calibrated posterior distributions over all random variables in the model to be recovered. Furthermore, this formulation
allows us to access the ever-growing array of powerful inference algorithms to perform the inference. While naive
approaches such as grid-search or random sampling may be performant in low-dimensional applications, they do not
scale to high-dimensions through the curse of dimensionality [69, 70]. Therefore, we focus on methods that can scale to
high-dimensional applications [70]. Finally, Bayesian inference methods are, arguably, the most complete formulation.
Once the full posterior or joint distribution have been recovered, many different methodologies, constraints, objectives
etc can be formulated and evaluated post facto. This ﬂexibility allows for ﬁne-grained analysis to be conducted on the
inferred distributions to provide analysts with a powerful and general tool to further analyze and understand the model.
Less myopically, this analysis and the understanding garnered may be more beneﬁcial to our broader understanding of
outbreaks and the feasibility and efﬁcacy of particular responses.

Finally, we note that while throughout the experiments presented in Section 5.2 we use the PyProb framework, PyProb
is not the only framework available. Any inference methodology could be used to compute the probability in Equation
(7). However, PyProb is a natural choice as it allows for greater ﬂexibility in interfacing between black-box simulator
code, and powerful and efﬁciently implemented inference algorithms, without modifying either simulator or inference
code. This reduces the implementation overhead to the analyst, and reduces the scope for implementation bugs and
oversights to be introduced.

4 Models

Epidemiological dynamics models can be used to describe the spread of a disease such as COVID-19 in society.
Different types span vastly different levels of ﬁdelity. There are classical compartmental models (SIR, SEIR, etc.) [71]
that describe the bulk progression of diseases of different fundamental types. These models break the population down
to a series of compartments (e.g. susceptible (S), infectious (I), exposed (E), and recovered (R)), and treat them as as
continuous quantities that vary smoothly and deterministically over time following dynamics deﬁned by a particular
system of ordinary differential equations. These models are amenable to theoretical analyses and are computationally
efﬁcient to forward simulate owing to their low dimensionality. As policy-making tools, they are rather blunt unless the
number of compartments is made large enough to reﬂect different demographic information (age, socio-economic info,
etc), spatial strata, or combinations of thereof.

At the other end of the spectrum are agent-based models [72, 73, 74, 75] (like the Pitt Public Health Dynamics Labora-
tory’s FRED [76] or the Institute for Disease Modelling’s EMOD [77]) that model populations and epidemiological
dynamics via discrete agent interactions in “realistic” space and time. Imagine a simulation environment like the game
Sim-CityT M , where the towns, populations, infrastructure (roads, airports, trains, etc.), and interactions (go to work,
school, church, etc.) are modelled at a relatively high level of ﬁdelity. These models exist only in the form of stochastic
simulators, i.e. software programs that can be initialized with disease and population characteristics, then run forward
to show in a more ﬁne-grained way the spread of the disease over time and space.

Both types of models are useful for policy-making. Compartmental models are usually more blunt unless the number
of compartments is very high and it is indexed by spatial location, demographics and age categories. Increasing the
number of compartments adds more unknown parameters which must be estimated or marginalized. Agent-based
models are complex by nature, but they may be more statistically efﬁcient to estimate, as they are parameterized more
efﬁciently, often directly in terms of actual individual and group behaviour choices. In many cases, predictions made by
such models are more high ﬁdelity, certainly more than compartmental models with few compartments, and this has
implications for their use as predictive tools for policy analysis. For instance, policies based on simulating a single
county in North Dakota with excellent hospital coverage and a highly dispersed, self-sufﬁcient population could lead to
different intervention recommendations compared to a compartmental model of the whole of the United States with
only a few compartments.

4.1 A Compartmental Model of COVID-19

We begin by introducing a low-dimensional compartmental model to explore our methods in a well-known model family,
before transitioning to a more complex agent-based simulator. The model we use is an example of a classical SEIR
model [1, 2, 3]. In such models, the population is subdivided into a set of compartments, representing the susceptible
(uninfected), exposed (infected but not yet infectious), infectious (able to infect/expose others) and recovered (unable
to be infected). Within each compartment, all individuals are treated identically, and the full state of the simulator
is simply the size of the population of each compartment. Our survey of the literature found a lack of consensus
about the compartmental model and parameters which most faithfully simulate the COVID-19 scenario. Models used
range from standard SEIR [12, 11, 7, 78], SIR [79, 7, 80, 81, 82], SIRD [83, 84, 85], QSEIR [86], and SEAIHRD
[87]. The choice depends on many factors, such as how early or late in the stages of an epidemic one is, what type of

10

A PREPRINT - SEPTEMBER 17, 2021

(1

−

u) 1
Nt

S

3

i=1
(cid:80)

βiIi,t

α

E

I1

R

γ2

I2

γ1

p1

γ3

p2

κ

I3

death

Figure 1: Flow chart of the SEI3R model we employ. A member of the susceptible population S moves to exposed E
after being exposed to an infectious person, where “exposure” is deﬁned as the previous susceptible person contracting
the illness. After some incubation period, a random duration parameterized by α, they develop a mild infection (I1).
They may then either recover, moving to R, or progress to a severe infection (I2). From I2, they again may recover, or
else progress further to a critical infection (I3). From I3, the critically infected person will either recover or die.

measures are being simulated, and the availability of real word data. We opted for the model described in this section,
which seems to acceptably represent the manifestation of the disease in populations. Existing work has investigated
parameter estimation in stochastic SEIR models [88, 89]. Although we will discuss how we set the model parameters,
we emphasize that our contribution is instead in demonstrating how a calibrated model could be used for planning.

{

St, Et, I1,t, I2,t, I3,t, Rt}

Model description We use an SEI3R model [3], a variation on the standard SEIR model which allows additional
modelling freedom. It uses six compartments: susceptible (S), exposed (E), infectious with mild (I1), severe (I2)
or critical infection (I3), and recovered (R). We do not include baseline birth and death rates in the model, although
[0, T ] is
there is a death rate for people in the critically infected compartment. The state of the simulator at time t
with St, Et, I1,t, I2,t, I3,t, and Rt indicating the population sizes (or proportions) at
Xt =
time t. The unknown model parameters are η =
, each with their own associated
α, β1, β2, β3, p1, p2, γ1, γ2, γ3, κ
}
{
prior. To the model we add a free, control parameter, denoted u
[0, 1], that acts to reduce the transmission of
the disease. Since u is the only free parameter, θ = u. An explanation of u is given later in the text. There
are no internal latent random variables (Zt) in this model. In this paper we do not demonstrate inference about θ
given Y obs within this model, and so do not consider Y obs here. We do, however, consider Y aux to perform policy
selection, and discuss the form of Y aux later. Deﬁning the total live population (i.e.
the summed population of
all compartments) at time t to be Nt, the dynamics are given by the following equations, and shown in Figure 1.

∈

∈

d
dt
d
dt
d
dt

St =

(1

−

−

3

i=1

βiIi,tSt

(14)

E = (1

−

u)

βiIi,tSt −

αEt

(15)

i=1

I1,t = αEt −

γ1I1,t

(16)

(cid:88)
3

u)

1
Nt
1
Nt
(cid:88)
p1I1,t −

d
dt
d
dt
d
dt

γ2I2,t

I2,t = p1I1,t −
I3,t = p2I2,t −
Rt = γ1I1,t + γ2I2,t + γ3I3,t.

p2I2,t −
κI3,t −

γ3I3,t

(17)

(18)

(19)

For the purposes of simulations with this model, we initialize the state with 0.01% of the population having been
exposed to the infection, and the remaining 99.99% of the population being susceptible. The population classiﬁed as
infectious and recovered are zero, i.e. X0 =
0.9999, 0.0001, 0, 0, 0, 0
{

and Nt = 1.

}

Example trajectories Before explaining how we set the SEI3R model parameters, or pose inference problems in the
model, we ﬁrst verify that we are able to simulate feasible state evolutions. As we will describe later, we use parameters
that are as reﬂective of current COVID-19 epidemiological data as possible at the time of writing. Figures 2a and
2b show deterministic simulations from the model with differing control values u. Shown in green is the susceptible
population, in blue is the exposed population, in red is the infectious population, and in purple is the recovered
population. The total live population is shown as a black dotted line. All populations are normalized by the initial total
population, N0. The dashed black line represents a threshold under which we wish to keep the number of infected
people under at all times. The following paragraph provides the rationale for this goal.

Policy goal As described in Section 3.4, parameters should be selected to ensure that a desired goal is achieved. In all
scenarios using the SEI3R model, we aim to maintain the maximal infectious population proportion requiring healthcare
below the available number of hospital beds per capita, denoted C. This objective can be formulated as an auxiliary
observation, Y aux

0:T , introduced in Section 3, as:

0:T = I
Y aux

max
t∈0:T

(cid:20)(cid:18)

(I1,t + I2,t + I3,t)

< C

,

(cid:19)

(cid:21)

(20)

11

A PREPRINT - SEPTEMBER 17, 2021

(a) Deterministic trajectory with zero control input (u = 0).

(b) Deterministic trajectory controlled to limit maximum infected population (u = 0.37).

Figure 2: Populations per compartment during deterministic SEI3R simulations, both without intervention (top) and
with intervention (bottom). Plots in the left column show the full state trajectory, and in the right column are cropped
to more clearly show the exposed and infected populations. Without intervention, the infected population requiring
hospitalization (20% of cases) exceeds the threshold for infected population (0.0145, black dashed line), overwhelming
hospital capacities. With intervention (u=0.37) the infected population always remains below this limit. Note that we
re-use the colour scheme from this ﬁgure through the rest of the paper.

where I1,0:T , I2,0:T and I3,0:T are sampled from the model, conditioned on a θ value. This threshold value we use
was selected to be 0.0145, as there are 0.0029 hospital beds per capita in the United States [90], and roughly 20% of
COVID-19 cases require hospitalization. This constraint was chosen to represent the notion that the healthcare system
must have sufﬁcient capacity to care for all those infected who require care, as opposed to just critical patients. However,
this constraint is only intended as a demonstrative example of the nature of constraints and inference questions one can
query using models such as these, and under the formalism used here, implementing and comparing inferences under
different constraints is very straightforward. More complex constraints may account for the number of critical patients
differently to those with mild and severe infections, model existing occupancy or seasonal variations in capacity, or,
target other metrics such as the number of deceased or the duration of the epidemic.

The constraint is not met in Figure 2a, but is in Figure 2b, where a greater control input u has been used to slow the
spread of the infection. This is an example of the widely discussed “ﬂattening of the curve.” As part of this, the infection
lasts longer but the death toll is considerably lower.

Control input As noted before, we assume that only a single “controllable” parameter affects our model, u. This is
the reduction in the “baseline reproductive ratio,” R0, due to policy interventions. Increasing u has the same effect as
reducing the infectiousness parameters β1, β2 and β3 by the same proportion. u can be interpreted as the effectiveness
of policy choices to prevent new infections. Various policies could serve to increase u, since it is a function of both, for
example, reductions in the “number of contacts while infectious” (which could be achieved by social distancing and
isolation policy prescriptions), and the “probability of transmission per contact” (which could be achieved by, e.g., eye,
hand, or mouth protective gear policy prescriptions). It is likely that both of these kinds of reductions are necessary to
maximally reduce u at the lowest cost.

For completeness, the baseline reproductive ratio, R0, is an estimate of the number of people a single infectious person
will in turn infect and can be calculated from other model parameters [3]. R0 is often reported by studies as a measure
of the infectiousness of a disease, however, since R0 can be calculated from other parameters we do not explicitly
parameterize the model using R0, but we will use R0 as a convenient notational shorthand. We compactly denote
the action of u as controlling the baseline reproductive rate to be a “controlled reproductive rate,” denoted ˆR0, and

12

0100200300400500600Days0.00.51.0FractionofpopulationNT0.984Imax0.0970100200300400500600Days0.00.10.2FractionofpopulationImax0.097StEtItRtNtC0100200300400500600Days0.00.51.0FractionofpopulationNT0.993Imax0.0140100200300400500600Days0.00.10.2FractionofpopulationImax0.014A PREPRINT - SEPTEMBER 17, 2021

(a)

(b)

Figure 3: Stochastic simulations from the SEI3R model. Figure 3a shows the full trajectory while Figure 3b is cropped
to the pertinent region. Compared to the deterministic simulations in Figure 2a, stochastic simulations have the capacity
to be much more infectious. Therefore, fully stochastic simulations are required to accurately quantify the true risk in
light of the uncertainty in the model. As a result of this, Bayesian methods, or at least methods that correctly handle
uncertainty, are required for robust analysis. We reuse the colour scheme deﬁned in Figure 2a for trajectories.

calculated as ˆR0 = (1
with the model deﬁnition above.

−

u)R0. This is purely for notational compactness and conceptual ease, and is entirely consistent

Using point estimates of model parameters We now explain how we set the model parameters to determin-
istic estimates of values which roughly match COVID-19. The following section will consider how to include
uncertainty in the parameter values. Speciﬁcally, the parameters are the incubation period α−1; rates of dis-
ease progression p1 and p2; rates of recovery from each level of infection, γ1, γ2, and γ3; infectiousness for
each level of infection, β1, β2, and β3; and a death rate for critical infections, κ. u
[0, 1] is a control
parameter, representing the strength of action taken to prevent new infections [91]. To estimate distributions
over the uncontrollable model parameters, we consider their relationships with various measurable quantities

∈

incubation period = α−1

mild duration

=

severe duration =

critical duration =

1
γ1 + p1
1
γ2 + p2
1
γ3 + κ

(21)

(22)

(23)

(24)

mild fraction =

severe fraction =

γ1
γ1 + p1
γ2
γ2 + p2 ·

mild fraction)

(1

−

critical fraction = 1

severe fraction

mild fraction

−

fatality ratio =

(critical fraction).

−
κ
γ3 + κ ·

(25)

(26)

(27)

(28)

Given the values of the left-hand sides of each of Equations 21-28, (as estimated by various studies) we can calculate
model parameters α, p1, p2, γ1, γ2, γ3 and κ by inverting this system of Equations. These parameters, along with
estimates for β1, β2, and β3, and a control input u, fully specify the model. Reference [3] uses such a procedure to
deterministically ﬁt parameter values. Given the parameter values, the simulation is entirely deterministic. Therefore,
setting parameters in this way enables us to make deterministic simulations of “typical” trajectories, as shown in
2. Specifying parameters in this way and running simulations in this system provides a low overhead and easily
interpretable environment, and hence is an invaluable tool to the modeller.

Dealing with uncertainty about model parameter values Deterministic simulations are easy to interpret on a high
level, but they require strong assumptions as they ﬁx the values of unknown parameters to point estimates. We therefore
describe how we can perform inference and conditioning in a stochastic model requiring less strict assumptions, and
show that we are able to provide meaningful conﬁdence bounds on our inferences that can be used to inform policy
decisions more intelligently than without this stochasticity. As described in Section 3, stochasticity can be introduced to
a model through a distribution over the latent global parameters η. Examples of stochastic simulations are shown in
Figure 3a. Clearly there is more capacity in this model for representing the underlying volatility and unpredictability of
the precise nature of real-world phenomena, especially compared to the deterministic model.

However, this capacity comes with the reality that increased effort must be invested to ensure that the unknown latent
states are correctly accounted for. For more speciﬁc details on dealing with this stochasticity please refer back to

13

0100200300400500600Days0.00.51.0Fractionofpopulation0100200300400500600Days0.000.050.100.150.20FractionofpopulationA PREPRINT - SEPTEMBER 17, 2021

Section 3, but, in short, one must simulate for multiple stochastic values of the unknown parameters, for each value of
the controllable parameters, and agglomerate the many individual simulations appropriately for the inference objective.
When asking questions such as "will this parameter value violate the constraint?" there are feasibly some trajectories
that are slightly above and some slightly below the trajectory generated by the deterministic simulation due to the
inherent stochasticity (aleatoric uncertainty) in the real world. This uncertainty is integrated over in the stochastic
model, and hence we can ask questions such as "what is the probability that this parameter will violate the constraint?"
Using conﬁdence values is this way provides some measure of how certain one can be about the conclusion drawn from
the inference – if the conﬁdence value is very high then there is a measure of “tolerance” in the result, compared to a
result with a much lower conﬁdence.

We deﬁne a joint distribution over model parameters as follows. We consider the 95% conﬁdence intervals of β1, β2,
and β3 and the values in the left hand-sides of Equations (21)-(24), and assume that their true values are uniformly
distributed across these conﬁdence intervals. Then at each time t in a simulation, we sample these values and then
invert the system of Equations 21-28 to obtain a sample of the model parameters. More sophisticated distributions
could easily be introduced once this information becomes available. We now detail the nominal values used for typical
trajectories (and the conﬁdence intervals used for sampling). The nominal values are mostly the same as those used
by [3]. We use: an incubation period of 5.1 days (4.5-5.8) [92]; a mild infection duration of 6 days (5.5-6.5) [93]; a
severe infection duration of 4.5 days (3.5-5.5) [94]; a critical infection duration of 6.7 days (4.2-10.4); fractions of
mild, severe, and critical cases of 81%, 14% and 5% [95]; and a fatality ratio of 2% [95]. We also use β1 = 0.33 / day
(0.23-0.43), and β2 = 0. / day (0.-0.05), and β3 = 0. / day (0.-0.025). Where possible, the conﬁdence intervals are
obtained from the studies which estimated the quantities. Where these are not given, we use a small range centred on
the nominal value to account for possible imprecision.

4.2 Agent-Based Simulation

While compartmental models, such as the SEIR model described in Section 4.1, provide a mathematically well
understood global approximation to disease dynamics, due to their coarse-grained statistical nature they cannot capture
many important aspects and local details of the physical and social dynamics underlying the spread of a disease. These
aspects include geographic information, spatio-temporal human interaction patterns in social hubs such as schools or
workplaces, and the impact of individual beliefs on transmission events. To address these limitations, agent-based
simulators (ABS) have been introduced. Such simulators have practically no restrictions in terms of expressiveness, i.e.,
they can make use of all features of modern Turing-complete programming languages, at the signiﬁcant computational
cost of simulating all details involved.

4.2.1 FRED: Fine-grained simulation of disease spreading

FRED2 [76] is an instance of the class of epidemiological agent-based simulators that are currently available for
use in policy-making. FRED is an agent-based modeling language and execution platform for simulating changes
in a population over time. FRED represents individual persons, along with social contacts and interactions with
the environment. This enables the model to include individual responses and behaviors that vary according to the
individual’s characteristics, including demographics (age, sex, race, etc.), as well as the individual’s interactions with
members of various social interaction groups, such as their neighborhood, school or workplace. The FRED user can
deﬁne and track any dynamic condition for the individuals within the population, including diseases (such as covid-19),
attitudes (such as vaccine acceptance), and behaviors (such as social distancing).

FRED captures demographic and geographic heterogeneities of the population by modelling every individual in a region,
including realistic households, workplaces and social networks. Using census-based models available for every state
and county in the US and selected international locations, FRED simulates interactions within the population in discrete
time steps of one hour. Transmission kernels model the spatial interaction between infectious places and susceptible
agents. These characteristics enable FRED to provide much more ﬁne-grained policy advice at either the regional or
national level, based on socio-economic and political information which cannot be incorporated into compartmental
models.

We chose to use FRED in this work because it has been used to evaluate potential responses to previous infectious
disease epidemics, including vaccination policies [96], school closure [97], and the effects of population structure [98]
and personal health behaviors [99, 100].

2https://fred.publichealth.pitt.edu/

14

A PREPRINT - SEPTEMBER 17, 2021

After 10 years of develoment as an academic project, FRED has been licensed by the University of Pittsburgh to
Epistemix 3, to develop commercial applications of the FRED modeling technology. In turn, Epistemix has developed a
detailed COVID-19 model in FRED, which is used in the experiments described here.

The FRED COVID-19 model includes three interconnected components: (1) The Natural History of COVID-19; (2) The
social dynamics/behavior of individuals; and (3) The Vaccination Program. The COVID-19 model was designed using
the latest scientiﬁc data, survey information from local health authorities, and in consultation with expert epidemiologists.
This model has been used to project COVID-19 cases in universities, K-12 school districts, large cities, and ofﬁces.

The FRED COVID-19 natural history model represents the period of time and trajectory of an individual from infection
or onset to recovery or death. In the current version of the model, when an individual, or an agent, is exposed to
SARS-CoV-2, the virus that causes COVID-19, the individual enters a 2-day latent period before they become infectious.
In the infectious state, individuals can either be asymptomatic, symptomatic, or hospitalized. The probability of entering
any of these infectious states is based on the individual’s age, infection history, and vaccination history. Individuals
have a duration of illness (i.e. number of days they can transmit the virus) which is dependent on infectious state, a
severity of disease (i.e. magnitude of transmissibility), and a disease outcome (recovery or death).

When an agent is exposed to SARS-CoV-2 and becomes symptomatic, the individual chooses whether or not to
isolate themselves from normal activities. Approximately 20% of individuals continue regular daily activities while
symptomatic. Agents who are exposed and develop an asymptomatic infection do not isolate themselves and go about
their regular activities. This introduces both symptomatic and asymptomatic forms of transmission into the model.

Prevalence of mask wearing and adherence to social distancing are unique to each location and change over time. The
level of compliance to these behaviors is set based on the number of active infections that were generated from reported
cases in the previous two weeks. Social distancing is assumed to reduce the number of contacts between agents in each
place the agent attends.

Following the general recipe for framing planning as inference in Section 3.1, the following section deﬁnes what a
prior on controls θ is in terms of of FRED internals, how FRED parameters relate to η, and how to condition FRED on
desirable future outcomes Y aux
0:T . Section 4.2.3 describes results of performing automated inference in this stochastic
simulation-based model using the probabilistic programming system PyProb. The main point of this section is to
illustrate how a stochastic simulator can be seen as a probabilistic model and, when integrated with an appropriate
probabilistic programming system, can be repurposed to perform automatic inference, in this instance for planning as
inference. The FRED-speciﬁc recipe we provide below should be read with the understanding that it is easy to apply
the same recipe to most if not all existing epidemiological simulators as their fundamental computational structure is
regular.

4.2.2 Turning FRED into A Probabilistic Program

The FRED simulator has a parameter ﬁle which stipulates the values of θ and η. In other words both the controllable
and non-controllable parameters live in a parameter ﬁle. FRED, when run given a particular parameter ﬁle, produces a
θ, η). Changing the random seed and re-running FRED will result in a new
sample from the distribution p(X0:T , Z0:T |
sample from this distribution.

The difference between X0:T and Z0:T in FRED is largely in the eye of the beholder. One way of thinking about it is
that X0:T are all the values that are computed in a run and saved in an output ﬁle and Z0:T is everything else.
In order to turn FRED into a probabilistic programming model useful for planning via inference several small but
consequential changes must be made to it. These changes can be directly examined by browsing one of the public
source code repositories accompanying this paper.4 First, the random number generator and all random variable samples
must be identiﬁed so that they can be intercepted and controlled by PyProb. Second, any variables that are determined
to be controllable (i.e. part of θ) need to be identiﬁed and named. Third, in the main stochastic simulation loop, the state
variables required to compute Y aux
t must be extracted. Fourth, these variables must be given either synthetic
ABC likelihoods or given constraints in the form of likelihoods. Finally, a mechanism for identifying, recording,
and or returning X0:T to the probabilistic programming system must be put in place. FRED, like many stochastic
simulators, includes the ability to write-out results of a run of the simulator to the ﬁlesystem. This, provided that the
correspondence between a sample θ(i) and the output ﬁle or ﬁles that correspond to it is established and tracked, is how
X (i)

and Y obs

0:T is implicitly deﬁned.

t

3http://www.epistemix.com/
4https://github.com/plai-group/FRED

15

A PREPRINT - SEPTEMBER 17, 2021

In the interest of time and because we were familiar with the internals of PyProb and knew that we would not be using
inference algorithms that were incompatible with this choice, the demonstration code does not show a full integration
in which all random variables are controlled by the probabilistic programming system, instead, it only controls the
sampling of θ and the observation of Y aux
. Notably this means that inference algorithms like lightweight Metropolis
Hastings [101], which are also included in PyProb, cannot be used with the released integration code.

t

4.2.3 Details of FRED+PyProb Integration

Our integration of PyProb into FRED required only minor modiﬁcations to FRED’s code base, performed in collabora-
tion with the FRED developed at Epistemx. More details about the integration of FRED and PyProb include:

1. The simulator is connected to PyProb through a cross-platform execution protocol (PPX5). This allows PyProb
to control the stochasticity in the simulator, and requires FRED to wait, at the beginning of its execution, for a
handshake with PyProb through a messaging layer.

2. PyProb overwrites the policy parameter values θ with random draws from the user-deﬁned prior. While PyProb
internally keeps tracks of all random samples it generates, we also decided to write out the updated FRED
parameters to a parameter ﬁle in order to make associating θ(i) and X (i)

0:T easy and reproducible.

3. For each daily iteration step in FRED’s simulation, we call PyProb’s observe function with a likelihood

corresponding to the constraint we would like to hold in that day.

With these connections established, we are able to select an inference engine implemented by PyProb to compute the
posterior. We use a particularly simple algorithm, namely rejection sampling, in order to focus our exposition on the
conceptual framework of planning as inference. PyProb implements multiple other, more complex, algorithms, which
may be able to better approximate the posterior with a given computational budget. However for the inference task
we consider, in which we attempt to infer only a small fraction of the random variables in the simulator, we ﬁnd that
rejection sampling is sufﬁciently performant.

We also remind the reader that, like in Section 3.5, more complex controls can be considered, in principle allowing
for complex time-dependent policies to be inferred. We do not examine this here, but note that this extension is
straightforward to implement in the probabilistic programming framework, and that PyProb is particularly well adapted
to coping with the additional complexity. Compared to sampling parameter values for FRED at the beginning of the
simulation, such time-varying policies could be implemented through changing the FRED model source code directly.
This approach will be explored in future research.

5 Experiments

We now demonstrate how inference in epidemiological dynamics models can be used to inform policy-making decisions.
We organize this section according to a reasonable succession of steps of increasing complexity that one might take
when modelling a disease outbreak. We again stress that we are not making COVID-19 speciﬁc analyses here, but
instead highlight how framing the task as in Section 3 allows existing machine learning machinery to be leveraged to
enhance analysis and evaluation of outcomes; and avoid some potential pitfalls.

We begin by showing how a simple, deterministic compartmental SEIR-based model can be used to inform policy-
making decisions, and show how analysis derived from such a deterministic model can fail to achieve stated policy goals
in practice. Next, we demonstrate how using a stochastic model can achieve more reliable outcomes by accounting for
the uncertainty present in real world systems. While these stochastic models address the limitations of the deterministic
model, low-ﬁdelity SEIR models are, in general, not of high enough ﬁdelity to provide localized, region-speciﬁc
policy recommendations. To address this we conclude by performing inference in an existing agent-based simulator of
infectious disease spread and demonstrate automatic determination of necessary controls.

5.1 SEI3R Model

The most straightforward approach to modelling infectious diseases is to use low-dimensional, compartmental models
such as the widely used susceptible-infectious-recovered (SIR) models, or the SEI3R variant introduced in Section 4.1.
These models are fast to simulate and easy to interpret, and hence form a powerful, low-overhead analysis tool.

5https://github.com/pyprob/ppx

16

A PREPRINT - SEPTEMBER 17, 2021

(a)

(b)

Figure 4: Here we demonstrate planning using the deterministic SEI3R model. Figure 4a shows, in red, the probability
that the constraint is met using the deterministic simulator. The probability jumps from zero to one at a value
of approximately u = 0.37. Figure 4b then shows trajectories using three salient parameter values, speciﬁcally,
u = [0.3, 0.37, 0.45]. Each parameter value corresponds to more control than the previous, and is evident as the peak
infection fraction drops from approximately 0.03 with u = 0.3, to 0.014 with u = 0.37 and almost zero with u = 0.45.
These values were selected as values just below, on, and above the threshold seen in Figure 4a. We reuse the colour
scheme deﬁned in Figure 2a.

5.1.1 Deterministic Model

The system of equations deﬁning the SEI3R model form a deterministic system when global parameter values, such
as the mortality rates or incubation periods, are provided. However, the precise values of these parameter values are
unknown, and instead only conﬁdence intervals for these parameters are known, i.e. the incubation period is between
4.5 and 5.8 [92]. This variation may be due to underlying aleatoric uncertainty prevalent in biological systems, or
epistemic uncertainty due to the low-ﬁdelity nature of SIR-like models. We do not discuss them here, but work exists
automatically ﬁtting point-wise estimates of model parameter values directly from observed data [102, 103].

Regardless of whether one obtains a point estimate of the parameter values by averaging conﬁdence intervals, or by
performing parameter optimization, the ﬁrst step is to use these values to perform fully deterministic simulations,
yielding simulations such as those shown in Figure 2a. Simulations such as this are invaluable for understanding the
bulk dynamics of systems, investigating the inﬂuence of variations in global parameter values or investigating how
controls affect the system. However, the ultimate utility in these models is to use them to inform policy decisions to
reduce the impact of outbreaks. As eluded to above, this is the primary thrust of this work, combining epidemiological
simulators with automated machine learning methodologies to model policy outcomes, by considering this problem as
conditioning simulations on outcomes.

To demonstrate such an objective, we consider maintaining the infected population below a critical threshold C at
all times. In a deterministic system there are no stochastic quantities and hence whether the threshold is exceeded is
a deterministic function of the controlled parameters, i.e. the value of p(
θ) (related to (7) via Bayes
rule) is binary in a deterministic system and hence takes a value of either 0 or 1. Therefore, we can simply simulate
the deterministic system for a ﬁnite number of θ values, and select those parameter values that do not violate the
constraint. We vary the free parameter u
[0, 1], where u is a scalar value that reduces the baseline reproduction rate
as ˆR0 = (1
u)R0. We deﬁne u in this way such that u represents an intervention, or change from normal conditions.
The parameter u is the only parameter we have control over, and hence θ = u.
Results for this are shown in Figure 4. It can then be read off that under the deterministic model ˆR0 must be reduced
by at least 37.5% of R0 to satisfy the constraint. Figure 4 shows trajectories simulated using insufﬁcient intervention
with u = 0.3 ( ˆR0 = 70%R0), acceptable intervention of u = 0.375 ( ˆR0 = 62.5%R0), and excessive intervention of
u = 0.45 ( ˆR0 = 55%R0), and show that these parameters behave as expected, violating the constraint, remaining just
under the threshold and remaining well beneath the threshold respectively.

∀t>0Y aux

= 1
|

−

∈

t

5.1.2 Stochastic Simulation

While the above example demonstrates how parameters can be selected by conditioning on desired outcomes, we
implicitly made a critical modelling assumption. While varying the free parameter u, we ﬁxed the other model parameter
values (α−1, γ1, etc) to single values. We therefore found a policy intervention in an unrealistic scenario, namely one in
which we (implicitly) claim to have certainty in all model parameters except u.

17

0%R020%R040%R060%R080%R0100%R0ˆR0:Controlledexposureraterelativetouncontrolledexposurerate.0.00.51.0p(∀t>0Yauxt=1|θ)ˆR0=(1−u)R0Deterministic90%conf.02004006008001000Days0.0000.0250.0500.0750.100FractionofpopulationA PREPRINT - SEPTEMBER 17, 2021

To demonstrate the pitfalls of analyzing deterministic systems and applying the results to an inherently stochastic system
such as an epidemic, we use the permissible value of u solved for in the deterministic system, u = 0.375, and randomly
sample values of the remaining simulation parameters. This “stochastic” simulator is a more realistic scenario than the
deterministic variant, as each randomly sampled η represents a unique, plausible epidemic being rolled out from the
current world state.

The results are shown in Figure 5a. Each line represents a possible epidemic. We can see that using the previously found
value of u results in a large number of epidemics where the infectious population exceeds the constraint, represented
by the red trajectories overshooting the dotted line. Simply put, the control parameter we found previously fails in as
unacceptable number of simulations.

This detail highlights the shortcomings of the deterministic model: in the deterministic model a parameter value was
either accepted or rejected with certainty. There was no notion of the variability in outcomes, and hence we have no
mechanism to concretely evaluate the risk of a particular conﬁguration.

Instead, we can use a stochastic model which at least does account for some aleatoric uncertainty about the world. We
repeat the analysis picking the required value of u, but this time using the stochastic model detailed in Section 4.1.
In practice, this means the (previously deterministic) model parameters detailed in Equations 21 - 28 are randomly
sampled for each simulation according to the procedure outlined following the equations.

t

∀t : Y aux

= 1
|

To estimate the value of p (
θ), for a given u value, we sample M stochastic trajectories from the system.
∀t : Y aux
= 1 holds, and divide this count
We then simply count the number of trajectories for which the condition
by M . Intuitively, this is operation is simple: for a given θ, simulate a number of possible trajectories, and, as the
number of simulations M tends to inﬁnity, the fraction that satisfy the constraint is the desired probability value. We
note that this operation corresponds to an “inner” Monte Carlo expectation, sampling under the distribution of simulator
trajectories conditioned on θ, evaluating the expected number of trajectories that do not violate the threshold. This
value is then passed through a non-linear indicator function extracting those parameters that yield a conﬁdence above a
certain threshold. We are then free to use any method we please for exploring θ space, or, evaluating additional Monte
Carlo expectations under the resulting θ distribution. As such, this system is a nested Monte Carlo sampler [23].

t

The results are shown in Figure 5b. The certainty in the result under the stochastic model is not a binary value like
in the deterministic case, and instead occupies a continuum of values representing the conﬁdence of the results. We
see that the intersection between the red and green curves occurs at approximately 0.5, explaining the observation
that approximately half of the simulations in Figure 5a exceed the threshold. We can now ask questions such as:
"what is the parameter value that results in the the constraint not being violated, with 90% conﬁdence." We can read
off rapidly that we must instead reduce the value of ˆR0 to 50% of its original value to satisfy this conﬁdence based
constraint. Repeating the stochastic simulations using these computed values conﬁrms that very few simulations violate
the constraint (Figure 5c). The ability to tune the outcome based on a required level of conﬁdence is paramount for
safety-critical applications, as it informs how sensitive the system is to the particular parameter choice and is more
resilient to model misspeciﬁcation.

5.1.3 Model predictive control

We have shown how one can select the required parameter values to achieve a desired objective. To conclude this
example, we apply the methodology to iterative planning. The principal idea underlying this is that policies are not static
and can be varied over time conditioned on the current observed state. Under the formalism used here, re-evaluating the
optimal control to be applied, conditioned on the new information, is as simple as re-applying the planning algorithm at
each time step. Note that here we consider constant control. However, more complex, time-varying control policies
can easily be considered under this framework. For instance, instead of recovering a ﬁxed control parameter, the
parameter values of a polynomial function deﬁning time-varying control input could be recovered, or, a scalar value
determining the instantaneous control input at each time-step. This is a beneﬁt of the fully Bayesian and probabilistic
programming-based approach we have taken: the model class that can be analyzed is not ﬁxed and can be determined
(and easily changed and iterated on) by the modeller, and the inference back-end cleanly and efﬁciently handles the
inference.

We show a demonstration of this in Figure 6. In this example, we begin at time t = 200 with non-zero infection rates.
We solve for a policy that satisﬁes the policy with 90% certainty, and show this conﬁdence interval over trajectories
as a shaded region. We then simulate the true evolution of the system for a single step sampling from the conditional
distribution over state under the selected control parameter. We then repeat this process at regular intervals, iteratively
adapting the control to the new world state. We see that the conﬁdence criterion is always satisﬁed and that the infection
is able to be maintained at a reasonable level. We do not discuss this example in more detail, and only include it as an

18

A PREPRINT - SEPTEMBER 17, 2021

(a) ˆR0 = 0.63R0

(b)

(c) ˆR0 = 0.5R0

(d) ˆR0 = 0.4R0

(e) Green = valid, red = invalid.

Figure 5: Comparison of stochastic and deterministic SEI3R models for policy selection. We reuse the colour scheme
deﬁned in Figure 2a for trajectories. Figure 5a shows a stochastic simulation using ˆR0 = 0.63R0, identiﬁed as an
acceptable parameter value under the deterministic model. However, once used in a stochastic system, the parameter
performs poorly, yielding many simulations that violate the constraint. This highlights why analyses in deterministic
systems can yield poor results. Figure 5b repeats the analysis in Figure 4a adding planning in the stochastic simulation,
where the y-coordinate can now be interpreted as the conﬁdence level. Figure 5c shows a simulation using the lowest
valid value of u, representing the “weakest” valid policy. This value, approximately ˆR0 = 0.5R0, renders most of the
trajectories under the threshold, with only a small fraction above, implying that it will satisfy the criteria with high
probability. Figure 5d shows simulations using ˆR0 = 0.4R0 effectively reduces the level of infection to near zero.
Figure 5e illustrates an example of how policy-level variables create model-level parameter values. Shown are the
u)R0.
level-sets of the free parameter u
We suggest that the reduction in the (unknown) reproduction rate is given by the root of the product of two factors
controllable through policy. Green level sets indicate that the value of u was effective and achieved a 90% conﬁdence
that the trajectory does not violate the constraint, whereas red curves do not satisfy this.

[0, 1], which acts to reduce the baseline reproduction rate R0 as ˆR0 = (1

−

∈

example of the utility of framing the problem as we have, insomuch as iterative re-planning based on new information
is a trivial extension under the formulation used.

5.1.4 Policy-based controls

We have illustrated how simulations can be used to answer questions about the suitability of parameter values we can
inﬂuence, while marginalizing over those parameter we do not have control over. However, u is not something that

19

02004006008001000Days0.0000.0250.0500.0750.100Fractionofpopulation0%R020%R040%R060%R080%R0100%R0ˆR0:Controlledexposureraterelativetouncontrolledexposurerate.0.00.51.0p(∀t>0Yauxt=1|θ)ˆR0=(1−u)R0Deterministic90%conf.Stochastic02004006008001000Days0.0000.0250.0500.0750.100Fractionofpopulation02004006008001000Days0.0000.0250.0500.0750.100Fractionofpopulation0.00.20.40.60.81.0ρ:Socialcontactrelativetonormal(at1.0).0.00.20.40.60.81.0τ:Transmissionraterelativetonormal(at1.0).u=p(1−τ)×(1−ρ)A PREPRINT - SEPTEMBER 17, 2021

(a)

(b)

Figure 6: Here we brieﬂy demonstrate the capacity of the SEI3R model in a model predictive control setting. Figure
6a shows the state when we begin controlling the system at t = 200 with some level of infection already present. We
solve for the minimum required control such that the constraint is satisﬁed. We plot the 90% conﬁdence interval over
trajectories conditioned on this control value. We then step through the system, randomly sampling continuations, and
adapting the controls used such that the constraint is always met (Figure 6b). We uncover that stronger controls must be
applied early on to reduce the infected population, but that the amount of control required can then reduce over time as
herd immunity becomes a stronger effect. We reuse the color scheme deﬁned in Figure 2a for plotting trajectories.

is directly within our control. Instead, the value of u is set through changing policy level factors. As an exploratory
example we suggest that the value of u is the square root of the product of two policy-inﬂuenceable factors: the
fractional reduction in social contact, ρ, below its normal level (indicated as a value of 1.0), and the transmission rate
relative to the normal level, τ , where we again denote normal levels as 1.0. This relationship is shown in Figure 5e.

We indicate u level sets that violate the constraint in red, and valid sets in green. We suggest taking the least invasive,
valid policy, being represented by the highest green curve. Once the analysis above has been performed to obtain a
value of u, that satisﬁes the required infection threshold, it deﬁnes the set of achievable policies. Any combination
of τ and η along this curve render the policy valid. Here, additional factors may come into consideration that make
particular settings of τ and η more or less advantageous. For instance, wearing more PPE may be cheaper to implement
and less economically and socially disruptive than social distancing, and so higher values of τ may be selected relative
to η. This reduces to a simple one-dimensional optimization of the cost surface along the level-set.

While we have simply hypothesized this as a potential relationship, it demonstrates how policy level factors inﬂuence
simulations and outcomes. While the SEIR model family is an invaluable tool for analyzing and understanding the bulk
dynamics of outbreaks, it is too coarse-grained for actual, meaningful, localized policy decisions to be made, especially
when those policy decisions are directly inﬂuencing populations. Further, these notions of “policy” are somewhat
abstract here because of the high-level nature of the SEI3R model used. We now go on to resolve these issues by using
the more sophisticated, agent-based simulator, FRED, where simulations are able to represent localized variations, and,
where real policy measures are more easily deﬁned.

5.2 FRED Simulator

In this section, we turn to agent-based simulators. We showcase how control as inference might possibly be used to
inform regional policy decisions through two scenarios presented in Sections 5.2.1,5.2.2. In the ﬁrst scenario, we
consider an inﬂuenza outbreak and in the second a COVID-19 outbreak is simulated. In both scenarios the policy
makers wish to “ﬂatten the curve” by limiting some statistic of the infected population under a certain threshold.

5.2.1 Inﬂuenza simulation

In this section, we consider a scenario where an inﬂuenza (not COVID-19) outbreak has occurred in Allegheny County
(similarly to [76]), and policy makers wish to limit the number of infected to less than 10% of the county’s population.
To achieve this hypothetical goal policy-makers might consider the following ﬁve controls among others (corresponding
to the θ parameter deﬁned in Table 1):

• A “social distancing” policy which mandates all citizens stay home for a ﬁxed period of time. Here, policy

makers must inﬂuence:

1. θ1, a shelter-in-place duration, or the length of time a social distancing policy must be in place.
2. θ2, a shelter-in-place compliance rate, or the percentage of the population to which this policy applies.

20

02004006008001000Days0.000.010.02Fractionofpopulation02004006008001000Days0.000.010.02FractionofpopulationA PREPRINT - SEPTEMBER 17, 2021

(a) Without controls.

(b) With controls.

Figure 7: Aggregated SEIR statistics extracted from 100, 000 FRED simulations of an inﬂuenza (not COVID-19)
outbreak in Allegheny County. The objective in this scenario is to keep the number of infectious people (I in SEIR
terminology, shown here in red) below 10%, indicated by the black dotted line. We plot the median and conﬁdence
intervals between 3rd and 97th percentile, shown by the shaded areas. To avoid clutter and focus on relevant dynamics,
the susceptible statistic (S in SEIR terminology, shown previously in green) and conﬁdence intervals for the Recovered
(R in SEIR terminology, shown here in purple) statistic are omitted. Blue shows the fraction of the population that
has been exposed (E in SEIR terminology). The bottom row shows a zoomed-in version of the top row, where all
conﬁdence intervals have been removed, for ease of visual inspection. Figure 7b shows the evolution of the outbreak
when no controls are applied. Figure 7b shows the evolution of the outbreak when controls, solved for using our
method, are applied. When no controls are applied we see the number of infectious people often exceeds the allowable
threshold, whereas, when optimal controls are applied, the conﬁdence interval for infectious people (red) stays below
our constraint.

Prior
θ1 ∼
θ2 ∼
θ3 ∼
θ4 ∼
θ5 ∼

Uniform(0, 14)
Uniform(0, 1)
Uniform(0, 1)
Uniform(0.01, 0.21)
Uniform(0, 1)
Table 1: Prior over FRED control parameter θ =

Control
shelter in place duration
shelter in place compliance rate
isolation rate
school closure attack rate threshold
hand washing compliance rate
θ1, . . . , θ5}

{

for Inﬂuenza simulations.

• θ3, a symptomatic isolation rate, the fraction of symptomatic individuals that self isolate during an epidemic.
• θ4, a school closure attack rate threshold, a threshold on the total percentage of people infected that automati-

cally triggers a three-week school closure when exceeded.

• θ5, a hand washing compliance, the percentage of the population that washes their hands regularly.

For simplicity of results interpretation we have put uniform priors, appropriately continuous or discrete, on intervals of
interest for these controllable parameters.

Also relative to (7) we choose Yt to be a binary variable indicating if the proportion of the county’s infected population
|∀t : Yt = 1), we characterize which control values will lead to this desired
is below 10% on day t. By inferring p(θ
outcome.

Using the model described in Section 4.2 with parameters as deﬁned in this section, we used PyProb to perform
automated inference over the policy parameters described in Table 1. To reiterate we infer the posterior distribution

21

255075100125150Days0.00.10.2Fractionofpopulation255075100125150Days0.00.51.01.5Fractionofpopulation×10−2255075100125150Days0.00.10.2Fractionofpopulation255075100125150Days0.00.51.01.5Fractionofpopulation×10−4A PREPRINT - SEPTEMBER 17, 2021

Figure 8: Empirically determined marginals of the full joint distribution over controllable policy parameters that lead
to desired outcomes (see Equation (7)) for a simulated inﬂuenza epidemic in Allegheny county. Along the diagonal:
one-dimensional marginals of each control parameter with a uniform prior indicated by the dashed line. We can clearly
see the efﬁcacy of high rates of hand washing and a quick school closure policy, as indicated by the non-uniformity of the
marginal distributions. The remaining array of plots show two-dimensional marginal distributions of any two parameters
where the dark green color indicates higher probability density. For reference, the color corresponding to a uniform
prior on the two-dimensional plots is indicated on the color bar on the right. This illustrates policy-level outcomes such
as there being a strong interaction when jointly enforcing high isolation rate and hand washing compliance. In contrast,
the effectiveness of school closure attack rate threshold is largely independent of the isolation rate (and indeed most
other parameters). Such richly structured information is paramount for making effective and justiﬁable policy decisions,
and is only provided through fully Bayesian analysis, as opposed to simpler reinforcement learning or optimal control
methodologies which may only provide a point estimate of the optimal control to be applied, with no quantiﬁcation of
uncertainty or the joint interaction of parameters.

over control parameters θ which satisfy the goal of limiting the instantaneous number of infected to less than 10% of
the county’s population at all times up to a maximum of 150 days. In conducting our experiments we generated one
million samples, 40% of which satisﬁed the policy goal.

Simulator conﬁguration We simulate Allegheny County, Pennsylvania, using 2010 U.S. Synthetic Population data.
We use an older, publicly available version of FRED6 and its default parameters, which simulates a model of inﬂuenza
“in which infectivity starts 1 day before symptoms and lasts for 7 days. Both symptoms and infectivity ramp up and ramp
down.”7 All simulations begin with 10 random agents seeded with the virus at day zero. Person-to-person contact rates
for various environments (household, ofﬁce, etc) were calibrated to speciﬁcally model Allegheny County. Parameter
ﬁles for the four policies under consideration are available online.8

Results Figure 7 shows the SEIR statistics for both the controlled (left) and uncontrolled (right) simulations. We see
that the conﬁdence interval in red stays beneath our infection rate constraint indicated by the dashed black line, while in
the uncontrolled scenario the conﬁdence band well exceeds the constraint. We also observed the overall number of
exposed and infectious populations is much lower using samples of control variables from the inferred posterior, which
indicates that control variable values draw from this posterior are indeed effective in limiting the spread of the virus.

6https://github.com/PublicHealthDynamicsLab/FRED
7https://github.com/PublicHealthDynamicsLab/FRED/blob/FRED-v2.12.0/input_files/defaults
8https://github.com/plai-group/FRED/tree/FRED-v2.12.0/params

22

0.010.21Schoolclosureattackratethreshold01Isolationrate014Shelterinplacedurationmean01Handwashingcompliance01Shelterinplacecompliance0.010.21Schoolclosureattackratethreshold01Isolationrate014Shelterinplacedurationmean01Shelterinplacecompliance0UniformA PREPRINT - SEPTEMBER 17, 2021

(a) Day 30: controlled = 15,626, uncontrolled = 208,646

(b) Day 60: controlled = 1,567 uncontrolled = 530

(c) Day 90: controlled = 42,133, uncontrolled = 0

(d) Day 120: controlled = 1,783, uncontrolled = 0

Figure 9: Progression of a simulated inﬂuenza epidemic in Allegheny county under controlled (left) and uncontrolled
(right) scenarios. Each red dot represents the household of an infectious person. The count of the number of infected
households in each scenario appears in the captions below each row. The peak number of cases in the uncontrolled
scenario is 215, 799 on day 29, while the peak number of cases in the controlled scenario is 65, 997 on day 83. We see
that the controls we solve for successfully “ﬂatten the curve,” indicated by a much lower density of red dots. There
is also a second spike predicted, visible in Figure 9c, where as controls are removed there is an increase in cases
throughout the susceptible portion of the population. However, this second spike is still below the required threshold.

23

A PREPRINT - SEPTEMBER 17, 2021

While Figure 7 indicates that the inferred controls can achieve the desired aims, it doesn’t indicate which policy to
choose. To answer this, we plot the two-dimensional marginal distributions over controlled policy parameters in
Figure 8. Policy-makers could use a ﬁgure like this, coupled with a utility function, to generate policy recommendations.
Interpreting Figure 8, ﬁrst we see the importance of inﬂuencing hand washing compliance and quick school closures.
This plot indicates that hand washing compliance must be driven above 50% and the school closure attack rate threshold
beneath 7% in order to achieve our stated goal. We also note the correlation between hand washing compliance and
isolation rate. If we can achieve only 70% hand washing compliance the isolation rate must be driven high, however, if
hand washing compliance is very good then a lower isolation rate is tolerable. The importance of hygiene and long-term
school closures has also been noted in the epidemiology literature [104, 105, 106].

A ﬁnal interpretation of the results of Figure 8 can be provided in terms of the outcome of a hypothetical inﬂuenza
policy-making scenario. A recommendation one might extract from this visualization of the posterior inference results
is a conjunction of the following controls:

1. Ensure that all schools close as soon as 2% of the population contracts the virus.

2. Attempt to drive the hand washing compliance to 80%.

3. Attempt to drive the symptomatic isolation rate to 50%.

4. No amount of sheltering in place is required.

Such a recommendation corresponds to what one could imagine would be, in comparison to more draconian options, a
relatively mild, economically speaking, policy response that still attains the objective. Of course, in the presence of
a real inﬂuenza outbreak, vaccination would be among the most critical controls to consider. We have intentionally
excluded it here in order to be in some small way more reﬂective of the COVID-19 pandemic which is emerging at the
time of conducting this experiment.

The results of applying this policy are shown in Figure 9, where we show a single simulation of the spread of inﬂuenza
in Allegheny county over time in both the uncontrolled (left) and controlled (right) cases. Each red dot shows the
household of an infectious person. This policy recommendation can be seen to work as it reduces the maximum number
of infected households from 215,799 on day 29 in the uncontrolled case to 65,997 on day 83 in the the uncontrolled
case. The maximum in the controlled case actually occurs during a second “outbreak” after schools re-open (noticeable
around day 90 in Figure 9c). While the controlled policy results in two “spikes,” our inference procedure accounts for
this and correctly controls the maximum number of infectious persons to remain below 10% of the total at all times.

5.2.2 COVID-19 Simulation

In this section, we consider COVID-19 outbreaks in the Seattle metropolitan area. The controls we consider in these
experiments are the following (corresponding to the θ parameter deﬁned in Table 2):

• θ1, a social distancing, or the fraction of population practising social distancing.
• θ2, a workplace closure, or the fraction of businesses deemed essential and exempt from workplace closure

mandates.

• θ3, a school closure attack rate threshold, a threshold on fraction of population hospitalized per day. Schools

get closed if the daily hospitalization rate exceeds this threshold.

Similar to Section 5.2.1, we have put uniform priors on these controllable parameters, as described in Table 2.

We put thresholds on the number of daily hospitalizations and daily deaths in different experiments. Hence, Yt in (7) is
a binary variable indicating if any of the thresholds are exceeded.

Prior
θ1 ∼
θ2 ∼
θ3 ∼

Uniform(0, 1)
Uniform(0, 1)
Uniform(1, 1.5
Table 2: Prior over FRED control parameter θ =

10−4)

×

Control
social distancing
workplace closure
school closure attack rate threshold

θ1, θ2, θ3}

{

for COVID-19 simulations.

Simulator conﬁguration Our simulations presented here are on a synthetic population of Seattle metropolitan area
incorporated in the FRED simulator (a population size of 3,416,570). The synthetic population closely matches the
2010 census data for the United States with high spatial resolution, differing from the American Community Survey

24

A PREPRINT - SEPTEMBER 17, 2021

(a) March 2020 - September 2020

(b) December 2020 - June 2021

(c) June 2021 - June 2022

Figure 10: Aggregated statistics from 1,000 FRED simulations of a COVID-19 outbreak in the Seattle metropolitan
area. We plot the median and conﬁdence intervals between 3rd and 97th percentiles of the daily cases, hospitalizations,
and deaths. Each row shows a different period of time with different starting conditions and policy goals. The goal in
these simulations is to keep the number of daily hospitalizations and deaths below the thresholds speciﬁed by dashed
lines in matching colors. The left column shows evolution of the outbreak when no control is applied. The right column
shows evolution of the outbreak when controls provided by our method are applied. As expected, without control the
number of hospitalizations and deaths quickly exceeds the thresholds whereas in the controlled simulations it is ensured
that all all the desired conditions are met throughout the simulation period.

25

20/03/0120/04/0120/05/0120/06/0120/07/0120/08/0120/08/31050010001500Population20/03/0120/04/0120/05/0120/06/0120/07/0120/08/0120/08/310100200300400CasesHospitalizationsDeaths20/12/0121/01/0121/02/0121/03/0121/04/0121/05/0121/05/31010002000Population20/12/0121/01/0121/02/0121/03/0121/04/0121/05/0121/05/31010020030040021/06/0121/07/0121/08/0121/09/0121/10/0121/11/0121/12/0122/01/0122/02/0122/03/0122/04/0122/05/0122/05/310100200300400Population21/06/0121/07/0121/08/0121/09/0121/10/0121/11/0121/12/0122/01/0122/02/0122/03/0122/04/0122/05/0122/05/310255075100A PREPRINT - SEPTEMBER 17, 2021

Simulation dates

1 Mar. 2020 - 1 Sep. 2020
1 Dec. 2020 - 1 Jun. 2021
1 Jun. 2021 - 1 Jun. 2022

Active
infections
400
8017
3024

Total
hospitalizations
0
2096
8313

Total
deaths
1
1459
2867

% Vaccinated

0
0
47

Policy goals
Hospitalizations Deaths
409
409
102

100
100
20

Table 3: Initial conditions and policy goals used in the COVID-19 simulations in Seattle metropolitan area.

by less than 1% for large counties. A detailed description of the methodology and further comparisons are provided
in [107]. The parameters of the disease are calibrated to COVID-19, as explained in Section 4.2. We have conducted
simulations in three different time periods and the initial conditions of each simulation (number of active infections,
total hospitalizations, total deaths and vaccinated people) is set according to the numbers reported by U.S. health
ofﬁcials for the chosen dates (see Table 3).

Results Figure 10 shows the number of daily cases, hospitalizations, and deaths (note that this is not the same as
SEIR) for all time periods considered in this experiment. Similar to SEIR plots, it shows results for both the controlled
(left) and uncontrolled (right) simulations.

Figure 11 shows samples from two-dimensional marginals of the distribution over controlled policy parameters.
According to these results, social distancing is the most important control among the three and policy makers should
make sure more than 70% of the population practice it. Although enforcing a more strict school or workplace closure
helps as well and allows a slightly wider range for social distancing compliance, they are far less effective than social
distancing. Adding more relative control parameters (for example, public mask wearing, recommended vaccine booster
shots, restricting large events, imposing travel restrictions, etc.) are planned extensions of future research.

We have conducted COVID-19 simulations for three different scenarios:

• The 6 months following March 1, 2020 when the outbreak is in its early stages with a few cases.

• The 6 months following December 1, 2020 when there is a large number of cases, hospitalizations and deaths.

• The 12 months following June 1, 2021 when the number of hospitalizations is the largest among our simulations
and there are more than 3000 active infections and near 3000 deaths. However, in this case 47% of the
population are vaccinated at the beginning of the simulation.

The goal in the ﬁrst two scenarios is to avoid the number of daily hospitalizations and daily deaths exceeding 409 and
100 people, respectively, while these numbers are 102 and 20 for the third scenario. For the third scenario our results in
Figure 11 show the goals are achieved even with a slightly looser set of controls over the population despite the large
number of active infections and hospitalizations and tighter goals. This is indeed the effect of higher vaccinations rates
in the initial conditions for the third scenario.
Finally, as a part of this project we have created a website9 where users can perform planning as inference in COVID-19
simulations for different locations in the U.S. and Canada. It allows users to choose initial conditions of the simulations,
policy goals and the set of control parameters (or interventions) to explore. The website automatically runs simulations
on the population of the speciﬁed location and produces an interactive version of Figures 10,11. It also provides the
location of infections on the selected location’s map, similar to Figure 9. We are working on expanding the features and
set of controllable parameters on the website as well.

6 Software

In this paper, we have introduced and reviewed control as inference in epidemiological dynamics models and illustrated
how this technique can be used to substantially increase the level of automation and precision of some aspects of
policy-making using models at two extremes of expressivity and ﬁdelity – compartmental and agent-based. We are
releasing accompanying source code for our SEIR-type COVID-19 model along with bespoke inference code that
researchers in the machine learning, control, policy-making, and approximate Bayesian inference communities can use
immediately in their own research. We are also releasing code that demonstrates how a complex, existing, agent-based
epidemiological dynamics model can be quickly interfaced to an existing probabilistic programming system so as to
automate, even in such a complex model, the inference tasks resulting from the problem formulation of control as
inference. Again, we stress that the speciﬁcs of the models we use to illustrate these techniques are not optimally

9https://covid19ideas.cs.ubc.ca/

26

A PREPRINT - SEPTEMBER 17, 2021

(a) March 2020 - September 2020.

(b) December 2020 - June 2021.

(c) June 2021 - June 2022.

Figure 11: Empirically determined marginals of the full joint distribution over controllable policy parameters that give
rise to appropriately controlled outcomes (see Equation (7)) for simulations of COVID-19 in the Seattle metropolitan
area. Similar to Figure 8, the diagonal of each ﬁgure shows one-dimensional marginals for each policy parameter, with
the uniform prior indicated by the dashed line. The remaining array of plots shows kernel density estimation (KDE)
plots ﬁtted to samples from the two-dimensional marginals of the joint posterior distribution. For reference, the color
corresponding to a uniform prior on the two-dimensional plots is indicated on the color bar on the right. Each of the
Subﬁgures 11a, 11b, 11c show the results of simulations for a different time period as indicated. The initial parameters
and policy goals for each plot are reported in Table 3. We see that among the three policy parameters, social distancing
is the most effective in all time periods. Furthermore, putting a more restrictive policy on closing schools of workplaces
leads to a wider range of acceptable social distancing policies. Finally, note that in the June 2021 - June 2022 period,
when the vaccination rates are high, a looser set of policy enforcement are acceptable even though the desired outcomes
for this experiment are much tighter (see Table 3).

27

01Socialdistancing00.015Schoolclosureattackratethreshold01Workplaceclosure01Socialdistancing01Workplaceclosure0Uniform01Socialdistancing00.015Schoolclosureattackratethreshold01Workplaceclosure01Socialdistancing01Workplaceclosure0Uniform01Socialdistancing00.015Schoolclosureattackratethreshold01Workplaceclosure01Socialdistancing01Workplaceclosure0UniformA PREPRINT - SEPTEMBER 17, 2021

calibrated for COVID-19, and that we do not report methodological innovation per se, as there are other ways of
recombining existing inference packages and existing models to approach the control as inference problem. In this
sense, our principal goal is to demonstrate the feasibility of, and raise interdisciplinary awareness for, such approaches,
rather than to champion any speciﬁc implementation.
The ﬁrst part of the software release accompanying this paper is a pure Python implementation of the SEI3R model
adapted to COVID-19 from Section 4.1. It is contained inside an online software version control repository and consists
of the model, “custom” inference code that implements control as inference via approximate nested Monte Carlo
(NMC), and code that shows how to perform stochastic model-predictive control using the model, i.e., the code used to
produce Fig. 6.

The second part of the software release accompanying this paper is the FRED Modeling Language code for the
COVID-19 model executed on the agent-based platform FRED [76], which has been interfaced to the probabilistic
programming system PyProb, designed to perform approximate Bayesian inference in pre-existing simulators. The
experiments here demonstrate how to achieve the systems integration required to interface automated inference with
the FRED simulator. We believe that model-inference combinations such as FRED+PyProb could provide formidable
policy analysis tools with potentially signiﬁcant societal beneﬁts, particularly because they would allow high-ﬁdelity
assessment of region-speciﬁc targeted policies. We expect that the set of effective policy interventions might differ
across the regional characteristics of counties, states or countries, as well as their transient epidemiological situations.
Testing this hypothesis depends upon expanding the number of counties, provinces, and countries with simulation
proﬁles in FRED, or in any other agent-based epidemiological model that can be interfaced with a universal and
language-agnostic probabilistic programming system such as PyProb.

While the current FRED source code is proprietary, we are happy to discuss the process of PyProb+FRED integration
with any interested parties. Furthermore, we have released the PyProb+FRED integration code for our inﬂuenza
experiment, which uses the older, open-source version of FRED. This code is contained in three separate repositories: a
fork of the FRED repository with PyProb integration,10 a fork of the PyProb code with slight additions required for
FRED integration,11 and a repository that contains scripts for orchestrating and plotting artifacts from simulation and
inference.12 This last repository also contains a Singularity container [108] image bundling all of the necessary software
dependencies, including the repositories above. This should dramatically reduce the setup time for interested parties, as
Singularity images are supported at a large number of existing high performance computing facilities.

7 Discussion

Our experience in conducting this research has led us to identify a number of opportunities for improvement in the
ﬁelds of simulation-based inference and control .

7.1 Software Tools

Building a simple SEIR-type model with very few compartments is a project of the scope of graduate homework.
Building and maintaining a simulator like FRED or the US National Large Scale Agent Model [109] is a massive
undertaking, which would be prohibitive to replicate or signiﬁcantly extend in a crisis situation. As far as we could ﬁnd
with limited search effort when conducting this work in March 2020, there was neither a central repository of up-to-date
open-source agent-based epidemiological models, nor an organizing body we could interface to immediately.

7.2 Methodology

There appear to be practically very consequential conceptual gaps between the ﬁelds of control, epidemiology, statistics,
policy-making, and probabilistic programming. To quote Lessler et al. [31], “the historic separation between the
infectious disease dynamics and ‘traditional’ epidemiologic methods is beginning to erode.” We, like them, see
our work as a new opportunity for “cross pollination between ﬁelds.” As discussed earlier, the most closely related
work that we found in the literature is all focused on automatic model parameter estimation from observational data
[14, 15, 16, 17, 18]. These methods and the models to which they have been applied could be repurposed for planning,
as we have demonstrated, simply by changing the random variables they condition on to include safety or utility metrics.
Our emphasis therefore lies on the feasibility of planning as inference using existing software tools for approximate
Bayesian inference.

10https://github.com/plai-group/FRED
11https://github.com/plai-group/pyprob
12https://github.com/plai-group/covid

28

A PREPRINT - SEPTEMBER 17, 2021

Looking closer at the implementation choices, we found at least two existing papers that explore using probabilistic
programming coupled to epidemiological simulators; [30] which used Libbi [110] and [53] which used PyProb. The
latter is an example of work that “hijacks” a malaria simulator in the same way we “hijacked” the FRED simulator in
this paper. Neither explicitly addresses control. [18] uses the probabilistic programming system STAN [111] to address
parameter estimation in SEIR-type models, but it too does not explore control, nor could it be repurposed to control an
agent-based model with non-differentiable joint densities or, more generally, any external simulator not directly deﬁned
in the STAN language.

Like [14, 15, 16, 17, 18] we too could have demonstrated automated parameter estimation in both of the models that we
consider, for instance to automatically adjust uncertainty in disease-speciﬁc parameters by conditioning on observable
quantities such as death counts that are measured online during a breakout. However, as the epidemiological community
already relies upon long-standing methods established for estimating conﬁdence intervals for model parameters during
evolving pandemics, we exclusively restricted ourselves to demonstrating how to achieve control via inference, assuming
that the disease parameter priors have been obtained from established parameter estimation techniques. Combining the
two kinds of observations in a single inference task is technically straightforward but does require care in interpretation.

8 Final Thoughts

At the time of writing all authors, apart from J.G. and D.C. at Epistemix Inc., Pittsburgh, were principally afﬁliated
with the “Programming Languages for Artiﬁcial Intelligence” (PLAI) research group at UBC, Vancouver, which is
primarily involved in developing next-generation probabilistic AI tools and techniques. We felt, however, that the
acute circumstances demanded we lend whatever we could to the global ﬁght against COVID-19. Beyond the speciﬁc
contributions outlined above, our secondary aim in writing this paper was to encourage other researchers to contribute
their expertise to the ﬁght against COVID-19 as well. We believe the world will be in a better place more quickly if
they do.

9 Acknowledgements

We acknowledge the support of the Natural Sciences and Engineering Research Council of Canada (NSERC), the
Canada CIFAR AI Chairs Program, and the Intel Parallel Computing Centers program. This material is based upon work
supported by the United States Air Force Research Laboratory (AFRL) under the Defense Advanced Research Projects
Agency (DARPA) Data Driven Discovery Models (D3M) program (Contract No. FA8750-19-2-0222). Additional
support was provided by UBC’s Composites Research Network (CRN), Data Science Institute (DSI), Support for Teams
to Advance Interdisciplinary Research (STAIR) Grants, the Innovation for Defence Excellence and Security (IDEaS)
program, under its COVID-19 Challenges (CPCA-0397), and a CIFAR AI and COVID-19 Catalyst Grant. This research
was enabled in part by technical support and computational resources provided by WestGrid (https://www.westgrid.ca/)
and Compute Canada (www.computecanada.ca).

29

A PREPRINT - SEPTEMBER 17, 2021

References

[1] W. O. Kermack and A. G. McKendrick. A contribution to the mathematical theory of epidemics. Proceedings of
the royal society of london. Series A, Containing papers of a mathematical and physical character, 115(772):
700–721, 1927.

[2] J. C. Blackwood and L. M. Childs. An introduction to compartmental modeling for the budding infectious

disease modeler. Letters in Biomathematics, 5(1):195–221, 2018.

[3] A. Hill, M. Levy, S. Xie, J. Sheen, J. Shinnick, A. Gheorghe, and C. Rehmann. Modeling COVID-19 spread vs
healthcare capacity, 2020. URL https://alhill.shinyapps.io/COVID19seir/. Accessed: 2020-3-25.

[4] N. M. Ferguson, D. Laydon, G. Nedjati-Gilani, N.

A. Boonyasiri, Z. Cucunubá, G. Cuomo-Dannenburg, et al.
terventions (NPIs)
//www.imperial.ac.uk/media/imperial-college/medicine/sph/ide/gida-fellowships/
Imperial-College-COVID19-NPI-modelling-16-03-2020.pdf.

to reduce COVID-19 mortality and healthcare demand, 2020.

Imai, K. Ainslie, M. Baguelin, S. Bhatia,
in-
URL https:

Impact of non-pharmaceutical

[5] M. Magdon-Ismail. Machine learning the phenomenology of COVID-19 from early infection dynamics. medRxiv

preprint, 2020. doi: 10.1101/2020.03.17.20037309.

[6] J. Riou and C. L. Althaus. Pattern of early human-to-human transmission of Wuhan 2019 novel coronavirus
(2019-nCoV), december 2019 to january 2020. Eurosurveillance, 25(4), 2020. doi: 10.2807/1560-7917.ES.2020.
25.4.2000058.

[7] M. C. Traini, C. Caponi, and G. V. De Socio. Modelling the epidemic 2019-nCoV event in Italy: a preliminary

note. medRxiv preprint, art. medRxiv:2020.03.14.20034884, 2020. doi: 10.1101/2020.03.14.20034884.

[8] L. Russo, C. Anastassopoulou, A. Tsakris, G. N. Bifulco, E. F. Campana, G. Toraldo, and C. Siettos. Tracing
DAY-ZERO and forecasting the fade out of the COVID-19 outbreak in Lombardy, Italy: A compartmental
modelling and numerical optimization approach. medRxiv preprint, art. medRxiv:2020.03.17.20037689, 2020.
doi: 10.1101/2020.03.17.20037689.

[9] B. S. Pujari and S. M. Shekatkar. Multi-city modeling of epidemics using spatial networks: Application to
2019-nCov (COVID-19) coronavirus in India. medRxiv preprint, art. medRxiv:2020.03.13.20035386, 2020. doi:
10.1101/2020.03.13.20035386.

[10] L. Peng, W. Yang, D. Zhang, C. Zhuge, and L. Hong. Epidemic analysis of COVID-19 in China by dynamical

modeling. medRxiv preprint, art. medRxiv:2020.02.16.20023465, 2020. doi: 10.1101/2020.02.16.20023465.

[11] C. Massonnaud, J. Roux, and P. Crépey. COVID-19: Forecasting short term hospital needs in France. medRxiv

preprint, art. medRxiv:2020.03.16.20036939, 2020. doi: 10.1101/2020.03.16.20036939.

[12] A. Rovetta and A. S. Bhagavathula. Modelling the epidemiological trend and behavior of COVID-19 in Italy.

medRxiv preprint, art. medRxiv: 2020.03.19.20038968, 2020. doi: 10.1101/2020.03.19.20038968.

[13] Y. Wen, L. Wei, Y. Li, X. Tang, S. Feng, K. Leung, X. Wu, X.-F. Pan, C. Chen, J. Xia, X. Zou, T. Feng, and
S. Mei. Epidemiological and clinical characteristics of COVID-19 in Shenzhen, the largest migrant city of China.
medRxiv preprint, art. medRxiv:2020.03.22.20035246, 2020. doi: 10.1101/2020.03.22.20035246.

[14] T. Kypraios, P. Neal, and D. Prangle. A tutorial introduction to bayesian inference for stochastic epidemic models

using approximate bayesian computation. Mathematical biosciences, 287:42–53, 2017.

[15] T. J. McKinley, I. Vernon, I. Andrianakis, N. McCreesh, J. E. Oakley, R. N. Nsubuga, M. Goldstein, R. G. White,
et al. Approximate bayesian computation and simulation-based inference for complex stochastic epidemic
models. Statistical science, 33(1):4–18, 2018.

[16] T. Toni, D. Welch, N. Strelkowa, A. Ipsen, and M. P. Stumpf. Approximate Bayesian computation scheme for
parameter inference and model selection in dynamical systems. Journal of the Royal Society Interface, 6(31):
187–202, 2009.

[17] A. Minter and R. Retkute. Approximate bayesian computation for infectious disease modelling. Epidemics, 29:

100368, 2019.

[18] A. Chatzilena, E. van Leeuwen, O. Ratmann, M. Baguelin, and N. Demiris. Contemporary statistical inference

for infectious disease models using stan. Epidemics, 29:100367, 2019.

[19] S. Naderiparizi, A. ´Scibior, A. Munk, M. Ghadiri, A. Baydin, B. Gram-Hansen, C. Schroeder de Witt, R. Zinkov,
P. Torr, T. Rainforth, Y. Whye Teh, and F. Wood. Amortized rejection sampling in universal probabilistic
programming, 2019. URL https://arxiv.org/abs/1910.09056.

30

A PREPRINT - SEPTEMBER 17, 2021

[20] Y. Zhou, B. J. Gram-Hansen, T. Kohn, T. Rainforth, H. Yang, and F. Wood. LF-PPL: A low-level ﬁrst order
probabilistic programming language for non-differentiable models. In Proceedings of the Twentieth International
Conference on Artiﬁcial Intelligence and Statistics (AISTATS), 2019.

[21] T. A. Le, A. G. Baydin, and F. Wood. Inference Compilation and Universal Probabilistic Programming. In 20th
International Conference on Artiﬁcial Intelligence and Statistics, April 20–22, 2017, Fort Lauderdale, FL, USA,
2017.

[22] B. Paige and F. Wood. Inference networks for sequential Monte Carlo in graphical models. In Proceedings of the

33rd International Conference on Machine Learning, volume 48 of JMLR, 2016.

[23] T. Rainforth, R. Cornish, H. Yang, A. Warrington, and F. Wood. On nesting monte carlo estimators. arXiv

preprint arXiv:1709.06181, 2017.

[24] T. Rainforth, C. Naesseth, F. Lindsten, B. Paige, J. van de Meent, A. Doucet, and F. Wood.

Interacting
particle Markov chain Monte Carlo. In Proceedings of the 33rd International Conference on Machine Learning,
volume 48 of JMLR, 2016.

[25] D. Tolpin, J.-W. van de Meent, and F. Paige, Brooks Wood. Output-Sensitive Adaptive Metropolis-Hastings for

Probabilistic Programs. In ECML PKDD 2015, 2015.

[26] J.-W. van de Meent, H. Yang, V. Mansinghka, and F. Wood. Particle Gibbs with Ancestor Sampling for

Probabilistic Programs. In Artiﬁcial Intelligence and Statistics, 2015.

[27] B. Paige, F. Wood, A. Doucet, and Y. Teh. Asynchronous anytime sequential monte carlo. In Advances in Neural

Information Processing Systems, pages 3410–3418, 2014.

[28] F. Wood, J. W. van de Meent, and V. Mansinghka. A new approach to probabilistic programming inference. In

Artiﬁcial Intelligence and Statistics, pages 1024–1032, 2014.

[29] A. Warrington, S. Naderiparizi, and F. Wood. Coping with simulators that don’t always return. In The 23rd

International Conference on Artiﬁcial Intelligence and Statistics (AISTATS 2020), 2020.

[30] S. Funk and A. A. King. Choices and trade-offs in inference with infectious disease models. Epidemics, 30:

100383, 2020.

[31] J. Lessler, A. S. Azman, M. K. Grabowski, H. Salje, and I. Rodriguez-Barraquer. Trends in the mechanistic and

dynamic modeling of infectious diseases. Current Epidemiology Reports, 3(3):212–222, 2016.

[32] E. Todorov. General duality between optimal control and estimation. In 2008 47th IEEE Conference on Decision

and Control, pages 4286–4292. IEEE, 2008.

[33] M. Toussaint. Robot trajectory optimization using approximate inference. In Proceedings of the 26th annual

international conference on machine learning, pages 1049–1056, 2009.

[34] H. J. Kappen, V. Gómez, and M. Opper. Optimal control as a graphical model inference problem. Machine

learning, 87(2):159–182, 2012.

[35] S. Levine. Reinforcement learning and control as probabilistic inference: tutorial and review. arXiv preprint

arXiv:1805.00909, 2018.

[36] D. Tolpin, J.-W. van de Meent, H. Yang, and F. Wood. Design and implementation of probabilistic programming
language anglican. In Proceedings of the 28th Symposium on the Implementation and Application of Functional
programming Languages, pages 1–12, 2016.

[37] N. D. Goodman and A. Stuhlmüller. The Design and Implementation of Probabilistic Programming Languages.

http://dippl.org, 2014. Accessed: 2020-3-26.

[38] T. A. Le, A. G. Baydin, and F. Wood. Inference compilation and universal probabilistic programming. In
Proceedings of the 20th International Conference on Artiﬁcial Intelligence and Statistics (AISTATS), volume 54
of Proceedings of Machine Learning Research, pages 1338–1348, Fort Lauderdale, FL, USA, 2017. PMLR.

[39] E. F. Camacho and C. B. Alba. Model predictive control. Springer science & business media, 2013.

[40] C. E. Garcia, D. M. Prett, and M. Morari. Model predictive control: Theory and practice—a survey. Automatica,

25(3):335–348, 1989.

[41] J. Mattingley, Y. Wang, and S. Boyd. Receding horizon control. IEEE Control Systems Magazine, 31(3):52–65,

2011.

[42] J. Pearl. Causality: Models, Reasoning, and Inference. Cambridge University Press, USA, 2000.

ISBN

0521773628.

31

A PREPRINT - SEPTEMBER 17, 2021

[43] J.-W. van de Meent, B. Paige, H. Yang, and F. Wood. An introduction to probabilistic programming, 2018. URL

https://arxiv.org/abs/1809.10756.

[44] N. D. Goodman and A. Stuhlmüller. The design and implementation of probabilistic programming languages.

http://dippl.org, 2014. Accessed: 2020-3-25.

[45] S. Staton, F. Wood, H. Yang, C. Heunen, and O. Kammar. Semantics for probabilistic programming: higher-order
functions, continuous distributions, and soft constraints. In 2016 31st Annual ACM/IEEE Symposium on Logic in
Computer Science (LICS), pages 1–10. IEEE, 2016.

[46] Z. Ghahramani. Probabilistic machine learning and artiﬁcial intelligence. Nature, 521(7553):452, 2015.

[47] A. Gelman, H. S. Stern, J. B. Carlin, D. B. Dunson, A. Vehtari, and D. B. Rubin. Bayesian data analysis.

Chapman and Hall/CRC, 2013.

[48] C. M. Bishop. Pattern Recognition and Machine Learning. Springer, 2006.

[49] T. A. Le, A. R. Kosiorek, N. Siddharth, Y. W. Teh, and F. Wood. Revisiting reweighted wake-sleep for models
with stochastic control ﬂow. In Proceedings of the conference on Uncertainty in Artiﬁcial Intelligence (UAI),
2019. URL https://arxiv.org/abs/1805.10469.

[50] A. G. Baydin, L. Heinrich, W. Bhimji, B. Gram-Hansen, G. Louppe, L. Shao, K. Cranmer, F. Wood, et al.
Efﬁcient probabilistic inference in the quest for physics beyond the standard model. In Thirty-second Conference
on Neural Information Processing Systems (NeurIPS), 2018.

[51] A. G. Baydin, L. Shao, W. Bhimji, L. Heinrich, L. Meadows, J. Liu, A. Munk, S. Naderiparizi, B. Gram-Hansen,
G. Louppe, et al. Etalumis: bringing probabilistic programming to scientiﬁc simulators at scale. In Proceedings
of the International Conference for High Performance Computing, Networking, Storage and Analysis, pages
1–24, 2019.

[52] A. Munk, A. ´Scibior, A. G. Baydin, A. Stewart, A. Fernlund, A. Poursartip, and F. Wood. Deep probabilistic sur-
rogate networks for universal simulator approximation. In The second International Conference on Probabilistic
Programming (PROBPROG), 2020.

[53] B. Gram-Hansen, C. S. de Witt, T. Rainforth, P. H. Torr, Y. W. Teh, and A. G. Baydin. Hijacking malaria

simulators with probabilistic programming. arXiv preprint arXiv:1905.12432, 2019.

[54] R. B. Vinter and R. Vinter. Optimal control. Springer, 2010.

[55] F. L. Lewis, D. Vrabie, and V. L. Syrmos. Optimal control. John Wiley & Sons, 2012.

[56] O. Sharomi and T. Malik. Optimal control in epidemiology. Annals of Operations Research, 251(1-2):55–71,

2017.

[57] D. P. Bertsekas. Reinforcement learning and optimal control. Athena Scientiﬁc Belmont, MA, 2019.

[58] K. Zhou and J. C. Doyle. Essentials of robust control, volume 104. Prentice hall Upper Saddle River, NJ, 1998.

[59] L. Hansen and T. J. Sargent. Robust control and model uncertainty. American Economic Review, 91(2):60–66,

2001.

[60] M. Green and D. J. Limebeer. Linear robust control. Courier Corporation, 2012.

[61] M. Morari and J. H. Lee. Model predictive control: past, present and future. Computers & Chemical Engineering,

23(4-5):667–682, 1999.

[62] J. B. Rawlings. Tutorial overview of model predictive control. IEEE control systems magazine, 20(3):38–52,

2000.

[63] R. Sutton. Reinforcement Learning. The Springer International Series in Engineering and Computer Science.

Springer US, 1992. ISBN 9780792392347.

[64] L. P. Kaelbling, M. L. Littman, and A. W. Moore. Reinforcement learning: A survey. Journal of artiﬁcial

intelligence research, 4:237–285, 1996.

[65] R. S. Sutton and A. G. Barto. Reinforcement learning: An introduction. MIT press, 2018.

[66] A. Warrington, J. W. Lavington, A. Scibior, M. Schmidt, and F. Wood. Robust asymmetric learning in pomdps.

In International Conference on Machine Learning, pages 11013–11023. PMLR, 2021.

[67] T. M. Moerland, J. Broekens, and C. M. Jonker. Model-based reinforcement learning: A survey, 2021.

[68] A. Laud and G. DeJong. The inﬂuence of reward on the speed of reinforcement learning: An analysis of shaping.

In Proceedings of the 20th International Conference on Machine Learning (ICML-03), pages 440–447, 2003.

32

A PREPRINT - SEPTEMBER 17, 2021

[69] M. Köppen. The curse of dimensionality. In 5th Online World Conference on Soft Computing in Industrial

Applications (WSC5), volume 1, pages 4–8, 2000.

[70] A. B. Owen. Monte Carlo theory, methods and examples. 2013.
[71] J. C. Blackwood and L. M. Childs. An introduction to compartmental modeling for the budding infectious
disease modeler. Letters in Biomathematics, 5(1):195–221, 2018. doi: 10.1080/23737867.2018.1509026.
[72] E. Hunter, B. Mac Namee, and J. Kelleher. An open-data-driven agent-based model to simulate infectious disease

outbreaks. PLOS ONE, 13(12):1–35, 12 2018. doi: 10.1371/journal.pone.0208775.

[73] E. Hunter, B. Mac Namee, and J. D. Kelleher. A taxonomy for agent-based models in human infectious disease
epidemiology. Journal of Artiﬁcial Societies and Social Simulation, 20(3):2, 2017. ISSN 1460-7425. doi:
10.18564/jasss.3414.

[74] M. Tracy, M. Cerdá, and K. M. Keyes. Agent-based modeling in public health: Current applications and future di-
rections. Annual Review of Public Health, 39(1):77–94, 2018. doi: 10.1146/annurev-publhealth-040617-014317.
[75] J. Badham, E. Chattoe-Brown, N. Gilbert, Z. Chalabi, F. Kee, and R. F. Hunter. Developing agent-based models

of complex health behaviour. Health & place, 54:170–177, 2018.

[76] J. J. Grefenstette, S. T. Brown, R. Rosenfeld, J. DePasse, N. T. Stone, P. C. Cooley, W. D. Wheaton, A. Fyshe,
D. D. Galloway, A. Sriram, et al. FRED (A Framework for Reconstructing Epidemic Dynamics): an open-source
software system for modeling infectious diseases and control strategies using census-based populations. BMC
public health, 13(1):940, 2013. doi: 10.1186/1471-2458-13-940.

[77] A. Bershteyn, J. Gerardin, D. Bridenbecker, C. W. Lorton, J. Bloedow, R. S. Baker, G. Chabot-Couture, Y. Chen,
T. Fischle, K. Frey, et al. Implementation and applications of EMOD, an individual-based multi-disease modeling
platform. Pathogens and disease, 76(5):fty059, 2018.

[78] Q. Liu, Z. Liu, J. Zhu, Y. Zhu, D. Li, Z. Gao, L. Zhou, J. Yang, and Q. Wang. Assessing the global tendency of
COVID-19 outbreak. medRxiv preprint, art. medRxiv:2020.03.18.20038224, 2020. doi: 10.1101/2020.03.18.
20038224.

[79] B. S. Pujari and S. M. Shekatkar. Multi-city modeling of epidemics using spatial networks: Application to
2019-nCov (COVID-19) coronavirus in India. medRxiv preprint, art. medRxiv:2020.03.13.20035386, 2020. doi:
10.1101/2020.03.13.20035386.

[80] A. Weber, F. Ianelli, and S. Goncalves. Trend analysis of the COVID-19 pandemic in China and the rest of the

world. arXiv e-prints, art. arXiv:2003.09032, March 2020.

[81] P. Teles. Predicting the evolution of COVID-19 in Portugal using an adapted SIR model previously used
in South Korea for the MERS outbreak. medRxiv preprint, art. medRxiv:2020.03.18.20038612, 2020. doi:
10.1101/2020.03.18.20038612.

[82] W. Jia, K. Han, Y. Song, W. Cao, S. Wang, S. Yang, J. Wang, F. Kou, P. Tai, J. Li, et al. Extended SIR
prediction of the epidemics trend of COVID-19 in Italy and compared with Hunan, China. medRxiv preprint, art.
medRxiv:2020.03.18.20038570, 2020. doi: 10.1101/2020.03.18.20038570.

[83] C. Anastassopoulou, L. Russo, A. Tsakris, and C. Siettos. Data-based analysis, modelling and forecasting of the
novel coronavirus (2019-nCoV) outbreak. medRxiv preprint, art. medRxiv:2020.02.11.20022186, 2020. doi:
10.1101/2020.02.11.20022186.

[84] Z. Liu, P. Magal, O. Seydi, and G. Webb. Predicting the cumulative number of cases for the COVID-19 epidemic

in China from early data. arXiv preprint, art. arXiv:2002.12298, 2020.

[85] D. Caccavo. Chinese and italian COVID-19 outbreaks can be correctly described by a modiﬁed SIRD model.

medRxiv preprint, art. medRxiv:2020.03.19.20039388, 2020. doi: 10.1101/2020.03.19.20039388.

[86] X. Liu, G. J. Hewings, S. Wang, M. Qin, X. Xiang, S. Zheng, and X. Li. Modeling the situation of COVID-19
and effects of different containment strategies in China with dynamic differential equations and parameters
estimation. medRxiv preprint, art. medRxiv:2020.03.09.20033498, 2020. doi: 10.1101/2020.03.09.20033498.
[87] A. Arenas, W. Cota, J. Gomez-Gardenes, S. Gómez, C. Granell, J. T. Matamalas, D. Soriano-Panos, and
B. Steinegger. A mathematical model for the spatiotemporal epidemic spreading of COVID19. medRxiv preprint,
art. medRxiv:2020.03.21.20040022, 2020. doi: 10.1101/2020.03.21.20040022.

[88] P. E. Lekone and B. F. Finkenstädt. Statistical inference in a stochastic epidemic SEIR model with control
intervention: Ebola as a case study. Biometrics, 62(4):1170–1177, 2006. doi: 10.1111/j.1541-0420.2006.00609.x.
[89] M. Roberts, V. Andreasen, A. Lloyd, and L. Pellis. Nine challenges for deterministic epidemic models. Epidemics,
10:49 – 53, 2015. ISSN 1755-4365. doi: 10.1016/j.epidem.2014.09.006. Challenges in Modelling Infectious
Disease Dynamics.

33

A PREPRINT - SEPTEMBER 17, 2021

[90] W. Bank. Hospital beds per capita in the united states. https://data.worldbank.org/indicator/SH.MED.

BEDS.ZS?locations=US, 2020. Accessed: 2020-3-25.

[91] P. Boldog, T. Tekeli, Z. Vizi, A. Dénes, F. A. Bartha, and G. Röst. Risk assessment of novel coronavirus covid-19

outbreaks outside China. Journal of Clinical Medicine, 9(2):571, 2020.

[92] S. A. Lauer, K. H. Grantz, Q. Bi, F. K. Jones, Q. Zheng, H. R. Meredith, A. S. Azman, N. G. Reich, and
J. Lessler. The incubation period of coronavirus disease 2019 (COVID-19) from publicly reported conﬁrmed
cases: estimation and application. Annals of Internal Medicine, 2020.

[93] R. Woelfel, V. M. Corman, W. Guggemos, M. Seilmaier, S. Zange, M. A. Mueller, D. Niemeyer, P. Vollmar,
C. Rothe, M. Hoelscher, et al. Clinical presentation and virological assessment of hospitalized cases of coronavirus
disease 2019 in a travel-associated transmission cluster. medRxiv preprint, art. medRxiv:2020.03.05.20030502,
2020. doi: 10.1101/2020.03.05.20030502.

[94] S. Sanche, Y. T. Lin, C. Xu, E. Romero-Severson, N. W. Hengartner, and R. Ke. The novel coronavirus, 2019-
nCoV, is highly contagious and more infectious than initially estimated. arXiv preprint, art. arXiv:2002.03268,
2020.

[95] Z. Wu and J. M. McGoogan. Characteristics of and important lessons from the coronavirus disease 2019
(COVID-19) outbreak in China: summary of a report of 72 314 cases from the chinese center for disease control
and prevention. Jama, 2020.

[96] B. Y. Lee, S. T. Brown, R. R. Bailey, R. K. Zimmerman, M. A. Potter, S. M. McGlone, P. C. Cooley, J. J.
Grefenstette, S. M. Zimmer, W. D. Wheaton, et al. The beneﬁts to all of ensuring equal and timely access to
inﬂuenza vaccines in poor communities. Health affairs, 30(6):1141–1150, 2011.

[97] M. A. Potter, S. T. Brown, P. C. Cooley, P. M. Sweeney, T. B. Hershey, S. M. Gleason, B. Y. Lee, C. R. Keane,
J. Grefenstette, and D. S. Burke. School closure as an inﬂuenza mitigation strategy: how variations in legal
authority and plan criteria can alter the impact. BMC public health, 12(1):1–11, 2012.

[98] S. Kumar, K. Piper, D. D. Galloway, J. L. Hadler, and J. J. Grefenstette. Is population structure sufﬁcient to
generate area-level inequalities in inﬂuenza rates? an examination using agent-based models. BMC public health,
15(1):1–12, 2015.

[99] S. Kumar, J. J. Grefenstette, D. Galloway, S. M. Albert, and D. S. Burke. Policies to reduce inﬂuenza in
the workplace: impact assessments using an agent-based model. American journal of public health, 103(8):
1406–1411, 2013.

[100] F. Liu, W. T. Enanoria, J. Zipprich, S. Blumberg, K. Harriman, S. F. Ackley, W. D. Wheaton, J. L. Allpress, and
T. C. Porco. The role of vaccination coverage, individual behaviors, and the public health response in the control
of measles epidemics: an agent-based simulation for california. BMC public health, 15(1):1–16, 2015.
[101] D. Wingate, A. Stuhlmüller, and N. Goodman. Lightweight implementations of probabilistic programming
languages via transformational compilation. In Proceedings of the Fourteenth International Conference on
Artiﬁcial Intelligence and Statistics, pages 770–778, 2011.

[102] H. J. Wearing, P. Rohani, and M. J. Keeling. Appropriate models for the management of infectious diseases.

PLoS medicine, 2(7), 2005.

[103] D. K. Mamo and P. R. Koya. Mathematical modeling and simulation study of SEIR disease and data ﬁtting of
Ebola epidemic spreading in West Africa. Journal of Multidisciplinary Engineering Science and Technology, 2
(1):106–114, 2015.

[104] T. C. Germann, H. Gao, M. Gambhir, A. Plummer, M. Biggerstaff, C. Reed, and A. Uzicanin. School dismissal

as a pandemic inﬂuenza response: When, where and for how long? Epidemics, 28:100348, 2019.

[105] P. Saunders-Hastings, J. A. Crispo, L. Sikora, and D. Krewski. Effectiveness of personal protective measures in
reducing pandemic inﬂuenza transmission: a systematic review and meta-analysis. Epidemics, 20:1–20, 2017.
[106] B. Y. Lee, S. T. Brown, P. Cooley, M. A. Potter, W. D. Wheaton, R. E. Voorhees, S. Stebbins, J. J. Grefenstette,
S. M. Zimmer, R. Zimmerman, et al. Simulating school closure strategies to mitigate an inﬂuenza epidemic.
Journal of public health management and practice: JPHMP, 16(3):252, 2010.

[107] W. D. Wheaton, J. C. Cajka, B. M. Chasteen, D. K. Wagener, P. C. Cooley, L. Ganapathi, D. J. Roberts, and J. L.
Allpress. Synthesized population databases: A us geospatial database for agent-based models. Methods report
(RTI Press), 2009(10):905, 2009.

[108] Singularity, 2020. URL https://sylabs.io/. Accessed: 2020-3-25.
[109] J. Parker and J. M. Epstein. A distributed platform for global-scale agent-based models of disease transmission.

ACM Transactions on Modeling and Computer Simulation (TOMACS), 22(1):1–25, 2011.

34

A PREPRINT - SEPTEMBER 17, 2021

[110] L. M. Murray. Bayesian state-space modelling on high-performance hardware using LibBi. arXiv preprint

arXiv:1306.3277, 2013.

[111] B. Carpenter, A. Gelman, M. D. Hoffman, D. Lee, B. Goodrich, M. Betancourt, M. Brubaker, J. Guo, P. Li, and

A. Riddell. Stan: a probabilistic programming language. Journal of statistical software, 76(1), 2017.

35

