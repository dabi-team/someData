Learning programs by combining programs*

Andrew Cropper

University of Oxford
andrew.cropper@cs.ox.ac.uk

2
2
0
2

n
u
J

1

]

G
L
.
s
c
[

1
v
4
1
6
1
0
.
6
0
2
2
:
v
i
X
r
a

Abstract

The goal of inductive logic programming is to induce a set of
rules (a logic program) that generalises examples. Inducing
programs with many rules and literals is a major challenge.
To tackle this challenge, we decompose programs into non-
separable fragments, learn fragments separately, and then
combine them. We implement our approach in a generate, test,
combine, and constrain loop. Our anytime approach can learn
optimal, recursive, and large programs and supports predicate
invention. Our experiments on multiple domains (including
program synthesis and inductive general game playing) show
that our approach can increase predictive accuracies and re-
duce learning times compared to existing approaches.

1 Introduction
Given examples and background knowledge (BK), the goal
of inductive logic programming (ILP) (Muggleton 1991) is
to ﬁnd a set of rules (a logic program ) which with the BK
correctly generalises the examples.

The fundamental challenge is to efﬁciently search a
large hypothesis space (the set of all programs) for a
solution (a program that correctly generalises the exam-
ples). The two main approaches are divide-and-conquer
(D&C) and separate-and-conquer (S&C). D&C approaches
(Blockeel and De Raedt 1998) divide the examples into dis-
joint sets and search for a program for each set. S&C ap-
proaches (Muggleton 1995) search for a program that gen-
eralises a subset of the examples, separate these examples,
and then search for more rules to add to the program to
generalise the remaining examples. These two approaches
support noise and learning programs with many rules and
literals. However, as they only learn from a subset of the
examples, they struggle to learn recursive programs. More-
over, these approaches offer no guarantees about the optimal-
ity of their solutions and can learn overly speciﬁc programs.
Finally, these systems cannot perform predicate invention
(Stahl 1995).

Many modern approaches

(Corapi, Russo, and Lupu
2011; Muggleton, Lin, and Tamaddoni-Nezhad
2015;
Evans and Grefenstette 2018; Kaminski, Eiter, and Inoue
2021; Dai and Muggleton
2019; Cropper and Morel

*This manuscript is an early draft. We will make improvements
before submission. Therefore, any feedback is greatly appreciated.

2021) overcome these limitations
through meta-level
search (Cropper et al. 2022) and can learn optimal and
recursive programs. However, most modern approaches
struggle to learn programs with many literals in a rule,
many rules in a program, or both. For instance, ASPAL
(Corapi, Russo, and Lupu 2011) precomputes every possible
rule in a program and uses an answer set solver to ﬁnd a sub-
set of rules that generalises the examples. However, this pre-
computation rule selection approach does not scale to rules
with more than a few literals (Law, Russo, and Broda 2014;
Kaminski, Eiter, and Inoue 2019; Raghothaman et al. 2020).
Likewise, many modern systems struggle to learn programs
with many rules (Muggleton, Lin, and Tamaddoni-Nezhad
2015; Evans and Grefenstette 2018; Cropper and Morel
2021; Purgał, Cerna, and Kaliszyk 2022).

In this paper, our goal is to overcome the limitations of
modern systems yet maintain the ability to learn recursive
and optimal programs and support predicate invention. The
three key ideas are to (i) decompose programs into non-
separable fragments, (ii) learn fragments separately, and (iii)
combine fragments to learn programs with many rules and
literals.

A non-separable program cannot be decomposed into

smaller parts. For instance, consider this program:

happy(A) ← rich(A)
happy(A) ← friend(A,B), famous(B).
happy(A) ← married(A,B), beautiful(B) )

p1 :

(

This program has three rules that can be evaluated indepen-
dently. In other words, if we learn the three rules separately
and union their individual logical consequences, we have a
program that is logically equivalent to p1. This program is,
therefore, a separable program. By contrast, consider this
program:

p2 :

(cid:26)

happy(A) ← rich(A)
happy(A) ← married(A,B), happy(B)

(cid:27)

This program has two rules that cannot be evaluated indepen-
dently as it has a recursive rule. In other words, if we learn
the two rules separately and union their individual logical
consequences, we have a program that is logically different
to p2. It is, therefore, a non-separable program. By decom-
posing programs into smaller non-separable fragments, we
want to make them easier to learn and thus reduce learning
times.

 
 
 
 
 
 
To explore these ideas, we build on the learning from fail-
ures (LFF) (Cropper and Morel 2021) approach. LFF frames
the ILP problem as a constraint satisfaction problem. The
goal of an LFF learner, such as POPPER, is to accumulate
constraints in a generate, test, and constrain loop. In other
words, POPPER continually generates programs, tests them
on examples, and, if they are not solutions, builds constraints
to explain why they are not solutions to guide future program
generation.

To improve learning performance, we add the three new
previously mentioned ideas to LFF. We describe our ap-
proach with an example.

Motivating example Suppose we have positive and neg-
ative examples of lists of numbers of arbitrary length. We
want to learn a program to say whether an unseen list is good
or bad. We might want to learn a program such as:

f(A) ← head(A,7)
f(A) ← head(A,4), tail(A,B), head(B,4)
f(A) ← head(A,23), tail(A,B), head(B,24)
f(A) ← tail(A,B), f(B)




h0 : 




This program says that a list is good if it contains the se-
quence [7] or [4,4] or [23,24]. The last rule is important. It
is a recursive rule that allows the program to generalise to
lists of arbitrary length.



To ﬁnd a program that generalises the examples, we use a
generate, test, combine, and constrain loop. In the generate
stage, we generate progressively larger programs, i.e. pro-
grams with one literal, two literals, etc. Importantly, in this
step, we only generate non-separable programs. For this ex-
ample, we would start by generating programs such as h1
and h2:

h1 : { f(A) ← head(A,1) }
h2 : { f(A) ← head(A,5) }

In the test stage, we test each program on the examples. If a
program entails a negative example, we build a generalisa-
tion constraint to eliminate more general programs from the
hypothesis space as they will also entail the negative exam-
ple. For instance, if we have the negative example f([5,5,5])
we would eliminate h2 from the hypothesis space and any-
thing more general than it, such as:

h3 :

(cid:26)

f(A) ← head(A,5)
f(A) ← head(A,7)

(cid:27)

If a program entails no negative examples, we build a spe-
cialisation constraint to eliminate more speciﬁc programs
from the hypothesis space, as they will also not cover any
positive example. For instance, if we do not have a positive
example where the ﬁrst element is 5, we prune all specialisa-
tions of h2, such as

h4 : { f(A) ← head(A,5), tail(A,B), head(B,9) }

A key novelty of our approach is the combine stage. If a
program entails at least one positive and none of the nega-
tive examples, we add the program to a set of candidate pro-
grams. Candidate programs are non-separable programs that

we want to combine. For instance, when considering pro-
grams of size 5, we might generate the recursive program:

h5 :

(cid:26)

f(A) ← head(A,7)
f(A) ← tail(A,B),f(B)

(cid:27)

As h5 covers at least one positive example and no negative
examples we deem it a candidate program.

In the combine stage, we search for a combination of can-
didate programs that covers all the positive examples and
that is minimal in size. If we do not ﬁnd a combination, we
go to the constrain stage, where we use the discovered gener-
alisation and specialisation constraints to generate a new pro-
gram. If we ﬁnd a combination, we deem it the best solution
so far. For instance, suppose that after considering programs
of size 7 we see the programs:

f(A) ← head(A,4), tail(A,B), head(B,4)
f(A) ← tail(A,B),f(B)
(cid:27)
f(A) ← head(A,23), tail(A,B), head(B,24)
f(A) ← tail(A,B),f(B)

h6 :

h7 :

(cid:26)

(cid:26)

(cid:27)

Then the combination of h5 ∪ h6 ∪ h7 is h0 (the solution we
want to learn). We have, therefore, learned a program with
4 rules and 13 literals by only considering programs with
2 rules and 7 literals. As we show in our experiments, this
decomposition and recombination of programs allows us to
learn programs much faster than existing approaches.

As this point, we have has not yet proven that the combina-
tion is optimal in terms of program size. In other words, we
have not yet proven that there is no smaller solution. There-
fore, to avoid over-ﬁtting, we continue to the constrain stage
and add a constraint on the maximum program size in the
generate stae (12 literals) for future iterations. We repeat this
loop until we prove the optimality of a solution.

Contributions.

• We introduce a generate, test, combine, and constrain ILP

approach.

• We implement our ideas in POPPER+, a new ILP system.
POPPER+ uses an answer set programming (ASP) solver
(Gebser et al. 2014) to generate programs that do not vio-
late constraints. POPPER+ uses a separate ASP solver to
search for combinations of non-separable programs. To
learn programs with complex data structures and continu-
ous values, POPPER+ uses Prolog to test programs1 POP-
PER+ learns optimal, recursive, and large programs and
supports predicate invention.

• We experimentally show on three domains (classiﬁcation,
inductive general game playing, and program synthesis)
that our approach can substantially outperform other ILP
systems, especially in terms of learning times.

2 Related work
D&C. TILDE (Blockeel and De Raedt 1998) is a D&C ap-
proach. TILDE extends decision tree learning algorithms to

1POPPER+ can also ASP to test programs if the programs only

need Datalog programs.

learn ﬁrst-order, rather than propositional, rules. Although
TILDE can learn large programs and scale to large datasets,
it cannot learn recursive programs and struggles to learn
from small numbers of examples.

Rule

2019;

Si et al.

systems

systems

Evans et al.

S&C. Progol

selection. Many

is a S&C approach that has inspired
many other approaches (Ray 2009; Ahlgren and Yuen 2013;
Sch¨uller and Benz 2018), notably ALEPH (Srinivasan 2001).
Progol employs a set covering algorithm to incrementally
ﬁnd programs that covers an uncovered example, removes
the example from the set, and repeats on the remaining un-
covered examples. Progol struggles to learn recursive and
optimal programs and does not support predicate invention.
Progol variants, such as ALEPH, inherit the same limitations.
formu-
late the ILP problem as a rule selection problem
(Law, Russo, and Broda 2014; Kaminski, Eiter, and Inoue
2019; Evans and Grefenstette 2018; Raghothaman et al.
2020;
2021). ASPAL
(Corapi, Russo, and Lupu 2011) is one of the ﬁrst rule
selection approaches. ASPAL precomputes every possible
rule in the hypothesis space. ASPAL uses an ASP solver to
ﬁnd a subset of the rules that covers all the positive but none
of the negative examples. A major issue with this approach
is scalability in terms of the size of rules. As it involves
pre-computing every possible rule in the hypothesis space,
the approach does not scale to rules with many body
literals, or, more generally, to problems with many rules.
For instance, the coins-goal task in our experiments would
require precomputing at least 1012 rules, which is clearly
intractable. In contrast to these approaches, we do not
precompute every possible rule. In addition, we do not
search for combinations of individual rules. We instead
search for combinations of programs, potentially formed
of multiple rules, including recursive rules and invented
predicates.

POPPER. Rather than precompute every possible rule,
POPPER (Cropper and Morel 2021) lazily generates pro-
grams, potentially with multiple rules. The key idea of POP-
PER is to discover constraints from smaller programs to rule
out larger programs. POPPER searches for a single solution
for all the examples. POPPER struggles to learn solutions
with many rules and many literals. We go beyond POPPER
by (i) only generating non-separable programs in the gener-
ate step, and (ii) adding a combine step. As we experimen-
tally demonstrate, our POPPER+ approach can drastically
outperform POPPER and other systems.

DCC. The most similar work to our approach is the
divide, constrain, and conquer (DCC) approach (Cropper
2022). DCC combines classical D&C search with modern
constraint-driven ILP. Similar to D&C approaches, DCC
learns a program for each example separately. To do so,
DCC calls POPPER with a subset of the examples. As these
programs are likely to be overly speciﬁc, DCC iteratively
tries to learn more general programs. The key idea behind
DCC is to reuse knowledge (constraints) between iterations
to improve learning performance. Our approach is com-
pletely different to DCC. DCC tries to generate a single
program that covers all the examples, including separable
programs and DCC has no combine stage, i.e. does not

search for combinations of programs. By contrast, POPPER+
never generates a separable program. Moreover, it searches
for combinations of programs in the combine stage. As we
experimentally show, POPPER+ can drastically outperform
DCC, especially in terms of learning times.

3 Problem Setting
We use the learning from failures (LFF) (Cropper and Morel
2021) setting. LFF uses hypothesis constraints to re-
strict the hypothesis space. Let L be a language that de-
ﬁnes hypotheses, i.e. a meta-language. For instance, con-
sider a meta-language formed of two literals h lit/3 and
b lit/3 which represent head and body literals respectively.
With this language, we can denote the rule last(A,B) ←
tail(A,C), head(C,B) as the set of literals {h lit(0,last,(0,1)),
b lit(0,tail,(0,2)), b lit(0,head,(2,1))}. The ﬁrst argument of
each literal is the rule index, the second is the predicate
symbol, and the third is the literal variables, where 0 rep-
resents A, 1 represents B, etc. A hypothesis constraint is
a constraint (a headless rule) expressed in L. Let C be a
set of hypothesis constraints written in a language L. A set
of deﬁnite clauses H is consistent with C if, when writ-
ten in L, H does not violate any constraint in C. For in-
stance, the rule last(A,B) ← last(B,A) violates the constraint
← h lit(0,last,(0,1)), b lit(0,last,(1,0)). We denote as HC the
subset of the hypothesis space H which does not violate any
constraint in C.

We deﬁne the LFF problem:

Deﬁnition 1 (LFF input). The LFF input
is a tuple
(E+, E−, B, H, C) where E+ and E− are sets of ground
atoms denoting positive and negative examples respectively;
B is a deﬁnite program denoting background knowledge;
H is a hypothesis space, and C is a set of hypothesis con-
straints.

We deﬁne a LFF solution:
Deﬁnition 2 (LFF solution). Given an input
tuple
(E+, E−, B, H, C), a hypothesis H ∈ HC is a solution
when H is complete (∀e ∈ E+, B ∪ H |= e) and consistent
(∀e ∈ E−, B ∪ H 6|= e).
If a hypothesis is not a solution then it is a failure. A hypoth-
esis is incomplete when ∃e ∈ E+, H ∪B 6|= e. A hypothesis
is inconsistent when ∃e ∈ E−, H ∪ B |= e. A hypothesis is
partially complete when ∃e ∈ E+, H ∪ B |= e. A hypothe-
sis is totally incomplete when ∀e ∈ E+, H ∪ B 6|= e.

Let cost : H 7→ R be an arbitrary cost function that mea-
sures the cost of a hypothesis. We deﬁne an optimal solution:
Deﬁnition 3 (Optimal solution). Given an input tuple
(E+, E−, B, H, C), a hypothesis H ∈ HC is optimal when
(i) H is a solution, and (ii) ∀H ′ ∈ HC , where H ′ is a solu-
tion, cost(H) ≤ cost(H ′).
In this paper, our cost function is the number of literals in
the hypothesis H.

Constraints. The goal of an LFF learner is to learn hypoth-
esis constraints from failed hypotheses. Cropper and Morel
(2021) introduce hypothesis constraints based on subsump-
tion (Plotkin 1971). A clause C1 subsumes a clause C2

(C1 (cid:22) C2) if and only if there exists a substitution θ such
that C1θ ⊆ C2. A clausal theory T1 subsumes a clausal the-
ory T2 (T1 (cid:22) T2) if and only if ∀C2 ∈ T2, ∃C1 ∈ T1 such
that C1 subsumes C2. A clausal theory T1 is a specialisation
of a clausal theory T2 if and only if T2 (cid:22) T1. A clausal the-
ory T1 is a generalisation of a clausal theory T2 if and only
if T1 (cid:22) T2. If a hypothesis H is incomplete, a specialisation
constraint prunes specialisations of H, as they are guaran-
teed to also be incomplete. If a hypothesis H is inconsistent,
a generalisation constraint prunes generalisations of H, as
they are guaranteed to be inconsistent as well.

4 POPPER+
We now describe our POPPER+ algorithm. We ﬁrst brieﬂy
describe POPPER.

4.1 POPPER

Algorithm 1 shows the POPPER algorithm, which solves the
LFF problem (Deﬁnition 1). POPPER takes as input back-
ground knowledge (bk), positive (pos) and negative (neg)
examples, and an upper (max size) bound on hypothesis
sizes. POPPER uses a generate, test, and constrain loop to
ﬁnd an optimal solution.

POPPER starts with a ASP program P (hidden in the gen-
erate function). The models of P correspond to hypotheses
(deﬁnite programs). In the generate stage (line 5), POPPER
uses Clingo (Gebser et al. 2014), an ASP system, to search
for a model of P. If there is no model, POPPER increments
the hypothesis size (line 7) and loops again. If there is a
model, POPPER converts it to a hypothesis (h). In the test
stage (line 9), POPPER tests the hypothesis on the training
examples. If the hypothesis is a solution (is complete and
consistent), POPPER returns it. If the hypothesis fails (is in-
complete or inconsistent), then, in the constrain stage (line
12), POPPER builds hypothesis constraints (represented as
ASP constraints) from the failure. POPPER adds these con-
straints to P to prune models and thus reduce the hypothesis
space. For instance, if a hypothesis is incomplete (does not
entail all the positive examples), POPPER builds a speciali-
sation constraint to prune hypotheses that are logically more
speciﬁc. If a hypothesis is inconsistent, POPPER builds a gen-
eralisation constraint to prune hypotheses that are logically
more general.

POPPER repeats this loop until it (i) ﬁnds an optimal solu-

tion, or (ii) there are no more hypotheses to test.

4.2 POPPER+

Algorithm 2 shows the POPPER+ algorithm. There are two
key differences to POPPER. First, POPPER+ only allows gen-
erates non-separable programs in the generate stage. Sec-
ond, POPPER+ has an additional combine stage that tries to
combine promising programs. We now describe these differ-
ences and the high-level POPPER+ loop.

The generate stage of POPPER+ is identical to POPPER
but only generates non-separable programs. The test stage
is also the same. A key difference is how POPPER+ han-
dles the outcome of testing. If a program is inconsistent,

def popper(bk, pos, neg, max_size):

cons = {}
m = size
while m ≤ max_size:

h = generate(cons, size)
if h == UNSAT:
size += 1
continue

Algorithm 1: POPPER
1
2
3
4
5
6
7
8
9
10
11
12
13

return {}

return h

cons += constrain(h, outcome)

outcome = test(pos, neg, bk, h)
if outcome == (COMPLETE, CONSISTENT)

def popper+(bk, pos, neg, max_size):

Algorithm 2: POPPER
1
2
3
4
5
6
7
8
9
10
11

cons = {}
candidates = {}
size = 1
while size ≤ max_size:

h = generate(cons, size)
if h == UNSAT:
size += 1
continue

test_outcome = test(pos, neg, bk, h)
if test_outcome == (PARTIAL_COMPLETE,

CONSISTENT):
candidates += h
combine_outcome = combine(candidates, bk,

pos, neg)

if combine_outcome != NO_SOLUTION:
solution, solution_size = outcome
max_size = solution_size-1
cons += constrain(h, outcome)

return {}

12
13

14
15
16
17
18

POPPER+ builds a generalisation constraint to prune pro-
grams that are more general, the same as POPPER. Special-
isation constraints are different. If a program is incomplete,
POPPER builds a specialisation constraint to prune anything
more speciﬁc. However, POPPER+ cannot do that because
the partially complete program might still need to be spe-
cialised to form a solution. For instance, consider learning
programs to determine whether someone is happy. Suppose
POPPER+ generates the program:

happy(A) ← rich(A)

This program is incomplete and inconsistent. However, we
do not want to prune specialisations of it as doing so would
eliminate the following program from the hypothesis space:

happy(A) ← rich(A), tall(A)

Therefore, POPPER+ only builds a specialisation constraint
when a program is either (i) totally incomplete, or (ii) con-
sistent.

If a program is partially complete and consistent, POP-
PER+ adds the program to a set of candidate programs (line
12). In the combine stage, POPPER+ searches for combina-
tions of programs that cover the positive examples. If there

is such a combination, POPPER+ updates its maximum pro-
gram size and continues to search to prove optimality. For in-
stance, suppose that the combination of two programs each
with 3 literals is a solution. Then there is no point consider-
ing programs with more than 5 literals, as we already have a
solution with 6 literals. POPPER+ repeats this loop until ei-
ther it (i) ﬁnds an optimal solution, or (ii) there are no more
hypotheses to test.

Combiner. To ﬁnd combinations of programs, we follow
ASPAL and use an ASP encoding. We give each positive
example a unique example id. Unlike ASPAL, which only
assigns ids to individual rules, we assign each candidate pro-
gram (potentially formed of multiple rules) a unique pro-
gram id. We create an ASP choice rule (a decision variable
in standard constraint terminology) that determines whether
a program should be in a solution. We add facts about the
coverage and size of each candidate program. We then ask
the ASP solver to ﬁnd a combination of programs that cov-
ers as many positive examples as possible. We also ask the
ASP solver to ﬁnd the smallest combination, as to learn the
optimal program.

5 Experiments
The evaluate the performance of POPPER+, our experiments
aim to answer the question:

Q1 How does POPPER+ compare against other approaches?

To answer Q1 we compare POPPER+ against POPPER,
DCC, and ALEPH.

A key motivation for introducing POPPER+ is to reduce
learning times, especially the time required to provably learn
optimal programs. Our experiments, therefore, aim to an-
swer the question:

Q2 How well does POPPER+ perform given more learning

time?

To answer Q2, we measure the learning performance of POP-
PER+ and other systems when given progressively longer
timeouts (maximum learning times). In other words, we ask
each system to return the best solution found in the time
given.

Methods. We measure predictive accuracy and learning
time given a maximum learning time. We use two maximum
learning times: 60 seconds and 10 minutes. We repeat all
the experiments 10 times and measure the mean and stan-
dard deviation. We use a 3.8 GHz 8-Core Intel Core i7 with
32GB of ram. All the systems use a single CPU.

Systems. We compare POPPER+ against POPPER, DCC,
and ALEPH2. We use these systems because they can learn

2We also tried to compare POPPER+ against ILASP3. However,
ILASP3 follows ASPAL and pre-computes every possible rule in
a hypothesis space. This approach is infeasible for our datasets.
For instance, on the trains tasks, ILASP3 took 2 seconds to pre-
compute rules with three body literals; 20 seconds for rules with
four body literals; and 12 minutes for rules with ﬁve body literals.
Since the simplest train task requires rules with six body literals,
ILASP3 is unusable.

recursive deﬁnite programs. DCC, POPPER, and POPPER+
use identical biases so the comparison between them is fair.
ALEPH uses a similar bias to POPPER+ but requires addi-
tional settings, such as an upper bound on the nodes to be
explored when searching for a rule. We have tried to make a
fair comparison but there will likely be different parameters
that would improve the performance of ALEPH.

5.1 Experimental Domains
We use the following domains. More details are in the ap-
pendix.

The

Trains.

Michalski

Michalski

trains
(Larson and Michalski 1977) problem is to ﬁnd a hy-
pothesis that distinguishes eastbound trains from westbound
trains. We use this domain because we can easily generate
progressively more difﬁcult tasks to test the scalability of
the approaches as the solution size grows. We consider
four tasks of increasing complexity, where the subscript
denotes the number of rules in the solution. There are
1000 examples but the distribution of positive and negative
examples is different for each task. We randomly sample
the examples and split them into 80/20 train/test partitions

IGGP.

In inductive general game playing (IGGP)
(Cropper, Evans, and Law 2020) agents are given game
traces
from the general game playing competition
to in-
(Genesereth and Bj¨ornsson 2013). The task is
duce a set of rules that could have produced these traces.
We use four IGGP games: minimal decay (md), rock, paper,
scissors (rps), buttons, and coins. We learn the next relation
for each game. We also learn the goal relation for buttons
and coins. These tasks are non-trivial for ILP systems as the
search spaces can be large. We exclude the goal relations
for md and rps and they require trivial two literal solutions.
These tasks are non-trivial for ILP systems as the search
spaces can be large. For instance, the coins-goal problem
has 130 background relations and requires a solution with
multiple rules and many literals.

Program synthesis. Inducing complex recursive pro-
grams has long been considered a difﬁcult problem
(Muggleton et al. 2012) and most ILP systems cannot learn
recursive programs. We use the program synthesis dataset in-
troduced by Cropper and Morel (2021) augmented with two
new tasks contains and reverse.

5.2 Experimental Results
Table 1 shows the predictive accuracies of the solutions re-
turned by the systems when given a maximum learning time
of 60 seconds. The results show that POPPER+ generally
outperforms the other systems in terms of predictive accu-
racy. POPPER+ comfortably outperforms POPPER and DCC,
especially on the trains and IGGP tasks. For instance, for the
buttons task, POPPER+ achieves 100% accuracy on the test
set, whereas POPPER and DCC only achieve 19%. ALEPH
performs reasonably well on the trains and IGGP tasks but
struggles on the program synthesis tasks. This performance
is expected as ALEPH, as with all bottom clause approaches,
struggle to learn recursive programs.

POPPER+, POPPER, and DCC are all guaranteed to learn
optimal programs given sufﬁcient time, assuming one exists.

Therefore, when these systems have low predictive accuracy,
it is because they struggled to ﬁnd a solution in the given
time limit and thus return an empty or partial program – this
explanation does not hold for ALEPH, which always termi-
nates in the given learning time, but tends to learn overly spe-
ciﬁc programs. For instance, the buttons tasks requires learn-
ing a solution with 10 rules and 61 literals, which is beyond
DCC and POPPER. This explanation is clearer when looking
at the predictive accuracies of the solutions returned by the
systems when given a maximum learning time of 10 min-
utes, which are shown in Table 2. With this larger timeout,
all three systems have higher predictive accuracy, as does
ALEPH. However, even with this larger timeout, POPPER+
is still the best performing system.

The systems have large differences in learning times,
which are shown in Table 3. The main difference is that POP-
PER+ provably learns the optimal solution for most tasks in
under 90 seconds. By contrast, for many tasks, DCC and
POPPER do not terminate within 10 minutes. For instance,
DCC and POPPER do not ﬁnd a solution for buttons-goal
given 10 minutes The reasons for this drastic improvement
in learning time are because POPPER+ (i) only generates
non-separable programs, and (ii) then tries to combine them.
The results of the buttons-goal task need explaining. POP-
PER+ is guaranteed to ﬁnd the smallest program that covers
all the positive and none of the negative examples. On the
buttons-goal task, POPPER+ ﬁnds such a program in less
than 60 seconds. However, for this task, ALEPH outperforms
POPPER+ in terms of predictive accuracy (100% vs 74%).
The reason is that ALEPH learns a very speciﬁc program
that includes memorising certain examples. In other words,
ALEPH includes positive examples in the solution. For this
task, memorising the training examples is suitable for high
predictive accuracy on the test examples. POPPER+, by con-
trast, learns a more general solution, i.e. without memoris-
ing the examples, but which does not generalise as well to
the test data.

Overall, the results from this experiment show that POP-
PER+ can outperform existing systems both in terms of pre-
dictive accuracies and learning times.

6 Conclusions and Limitations
We have introduced an ILP approach that employs a gen-
erate, test, combine, and constrain loop. The three key
ideas are to (i) decompose programs into non-separable
fragments, (ii) learn fragments separately, and (iii) com-
bine fragments to learn programs with many rules and lit-
erals. We have implemented our approach in POPPER+, a
new ILP system. POPPER+ can learn optimal, recursive, and
large programs and perform predicate invention. Our ex-
periments on three domains (classiﬁcation, inductive gen-
eral game playing, and program synthesis) show that our
approach can improve predictive accuracies and reduce
learning times compared to other ILP systems. The dras-
tic improvements we have shown in learning performance
should directly transfer to problems in which LFF has al-
ready been applied, such as learning to explain Rubix cubes
(Agostinelli et al. 2022) and learning higher-order programs
(Purgał, Cerna, and Kaliszyk 2022).

Task

trains1
trains2
trains3
trains4

md
buttons
rps
coins
buttons-goal
coins-goal

contains
dropk
droplast
evens
ﬁnddup
last
len
reverse
sorted
sumlist

POPPER+

DCC

POPPER ALEPH

100 ± 0
97 ± 1
99 ± 0
100 ± 0

100 ± 0
100 ± 0
100 ± 0
88 ± 2
76 ± 8
100 ± 0

100 ± 0
100 ± 0
100 ± 0
100 ± 0
100 ± 0
100 ± 0
100 ± 0
90 ± 9
95 ± 4
100 ± 0

100 ± 0
98 ± 1
100 ± 0
100 ± 0

100 ± 0
19 ± 0
100 ± 0
33 ± 16
50 ± 0
50 ± 0

70 ± 12
100 ± 0
100 ± 0
100 ± 0
99 ± 0
100 ± 0
100 ± 0
50 ± 0
85 ± 9
100 ± 0

100 ± 0
98 ± 1
79 ± 0
32 ± 0

11 ± 0
19 ± 0
18 ± 0
17 ± 0
50 ± 0
50 ± 0

60 ± 10
100 ± 0
100 ± 0
100 ± 0
99 ± 0
100 ± 0
100 ± 0
50 ± 0
75 ± 11
100 ± 0

100 ± 0
100 ± 0
100 ± 0
59 ± 16

94 ± 0
87 ± 0
100 ± 0
17 ± 0
100 ± 0
50 ± 0

50 ± 0
59 ± 9
50 ± 0
50 ± 0
50 ± 0
50 ± 0
50 ± 0
50 ± 0
65 ± 4
50 ± 0

Table 1: Predictive accuracies with a 60 seconds learning
timeout. We round accuracies to integer values. The error is
standard deviation.

6.1 Limitations and Future Work
Noise.
In the combine stage, POPPER+ searches for a com-
bination of candidate programs that covers all the positive
and none of the negative examples and that is minimal in
size. To perform this search, we use Clingo’s optimisation
feature. This approach allows us to handle misclassiﬁed pos-
itive examples, i.e. false negatives. In future work, we want
to extend the approach to handle negative examples, which
early work has already explored (Wahlig 2022).

Acknowledgments
This work was supported by the EPSRC fellowship The Au-
tomatic Computer Scientist (EP/V040340/1).

References
Agostinelli, F.; Panta, R.; Khandelwal, V.; Srivastava, B.;
Muppasani, B. C.; Lakkaraju, K.; and Wu, D. 2022. Ex-
plainable Pathﬁnding for Inscrutable Planners with Induc-
tive Logic Programming. In ICAPS 2022 Workshop on Ex-
plainable AI Planning.
Ahlgren, J.; and Yuen, S. Y. 2013. Efﬁcient program synthe-
sis using constraint satisfaction in inductive logic program-
ming. J. Machine Learning Res., (1): 3649–3682.
Blockeel, H.; and De Raedt, L. 1998. Top-Down Induction
of First-Order Logical Decision Trees. Artif. Intell., (1-2):
285–297.
Corapi, D.; Russo, A.; and Lupu, E. 2011. Inductive Logic
In Inductive
Programming in Answer Set Programming.
Logic Programming - 21st International Conference, 91–97.
Cropper, A. 2022. Learning logic programs through divide,
constrain, and conquer. In AAAI 2022.

Task

trains1
trains2
trains3
trains4

md
buttons
rps
coins
buttons-goal
coins-goal

contains
dropk
droplast
evens
ﬁnddup
last
len
reverse
sorted
sumlist

POPPER+

DCC

POPPER ALEPH

100 ± 0
97 ± 1
99 ± 0
100 ± 0

100 ± 0
100 ± 0
100 ± 0
87 ± 1
74 ± 8
100 ± 0

100 ± 0
100 ± 0
100 ± 0
100 ± 0
99 ± 0
100 ± 0
100 ± 0
100 ± 0
95 ± 4
100 ± 0

100 ± 0
98 ± 1
100 ± 0
100 ± 0

100 ± 0
100 ± 0
100 ± 0
57 ± 16
50 ± 0
100 ± 0

100 ± 0
100 ± 0
100 ± 0
100 ± 0
99 ± 0
100 ± 0
100 ± 0
100 ± 0
95 ± 4
100 ± 0

100 ± 0
98 ± 1
79 ± 0
32 ± 0

28 ± 17
19 ± 0
18 ± 0
17 ± 0
50 ± 0
50 ± 0

100 ± 0
100 ± 0
100 ± 0
100 ± 0
98 ± 0
100 ± 0
100 ± 0
100 ± 0
95 ± 4
100 ± 0

100 ± 0
100 ± 0
100 ± 0
100 ± 0

94 ± 0
87 ± 0
100 ± 0
100 ± 0
100 ± 0
93 ± 0

50 ± 0
59 ± 9
50 ± 0
50 ± 0
50 ± 0
50 ± 0
50 ± 0
50 ± 0
65 ± 4
50 ± 0

Table 2: Predictive accuracies with a 10 minute learning
timeout. We round accuracies to integer values. The error
is standard deviation.

Task

trains1
trains2
trains3
trains4

md
buttons
rps
coins
buttons-goal
coins-goal

contains
dropk
droplast
evens
ﬁnddup
last
len
reverse
sorted
sumlist

POPPER+

DCC

POPPER

ALEPH

3 ± 0.2
3 ± 0.3
16 ± 0.6
13 ± 0.5

11 ± 0.8
23 ± 0.7
87 ± 1
50 ± 2
44 ± 0.2
88 ± 0.7

13 ± 0.5
2 ± 0.2
2 ± 0.1
2 ± 0.2
5 ± 0.2
2 ± 0.1
3 ± 0.2
28 ± 5
23 ± 17
4 ± 0.1

4 ± 0.3
7 ± 1
timeout
timeout

timeout
timeout
timeout
timeout
timeout
timeout

85 ± 36
5 ± 0.5
8 ± 0.8
12 ± 0.9
42 ± 2
5 ± 0.5
13 ± 1
302 ± 26
38 ± 1
40 ± 1

3 ± 0.2
26 ± 9
timeout
timeout

586 ± 14
timeout
timeout
timeout
timeout
timeout

88 ± 18
5 ± 0.4
7 ± 0.6
12 ± 1
29 ± 3
4 ± 0.5
13 ± 0.9
258 ± 37
52 ± 7
46 ± 3

2 ± 0.5
1 ± 0.1
13 ± 3
148 ± 50

1 ± 0.1
43 ± 3
4 ± 0.2
342 ± 10
22 ± 0.1
283 ± 2

46 ± 0.4
1 ± 0.3
467 ± 35
0.8 ± 0.1
0.5 ± 0
0.7 ± 0.1
0.8 ± 0
0.8 ± 0
0.5 ± 0.1
0.3 ± 0

Table 3: Termination times given a 10 minute timeout. A
timeout entry means that the system did not terminate in
the given time. We round times over one second to the near-
est second. The error is standard deviation. Although ALEPH
has low learning times in the synthesis tasks is also low pre-
dictive accuracy.

Cropper, A.; Dumancic, S.; Evans, R.; and Muggleton, S. H.
Inductive logic programming at 30. Mach. Learn.,
2022.
111(1): 147–172.

Cropper, A.; Evans, R.; and Law, M. 2020. Inductive general
game playing. Mach. Learn., (7): 1393–1434.
Cropper, A.; and Morel, R. 2021. Learning programs by
learning from failures. Mach. Learn., (4): 801–856.
Dai, W.; and Muggleton, S. H. 2021. Abductive Knowledge
Induction from Raw Data. In IJCAI 2021.
Evans, R.; and Grefenstette, E. 2018. Learning Explanatory
Rules from Noisy Data. J. Artif. Intell. Res., 1–64.
Evans, R.; Hern´andez-Orallo, J.; Welbl, J.; Kohli, P.; and Ser-
got, M. J. 2021. Making sense of sensory input. Artif. Intell.,
103438.
Gebser, M.; Kaminski, R.; Kaufmann, B.; and Schaub, T.
2014. Clingo = ASP + Control: Preliminary Report. CoRR.
Genesereth, M. R.; and Bj¨ornsson, Y. 2013. The Interna-
tional General Game Playing Competition. AI Magazine,
(2): 107–111.
Kaminski, T.; Eiter, T.; and Inoue, K. 2019. Meta-
Interpretive Learning Using HEX-Programs. In Proceedings
of the Twenty-Eighth International Joint Conference on Ar-
tiﬁcial Intelligence, IJCAI 2019, 6186–6190.
Larson, J.; and Michalski, R. S. 1977. Inductive inference
of VL decision rules. SIGART Newsletter, 38–44.
Law, M.; Russo, A.; and Broda, K. 2014. Inductive Learning
of Answer Set Programs. In Logics in Artiﬁcial Intelligence
- 14th European Conference, JELIA 2014, 311–325.
Muggleton, S. 1991. Inductive Logic Programming. New
Generation Computing, (4): 295–318.
Muggleton, S. 1995. Inverse Entailment and Progol. New
Generation Comput., (3&4): 245–286.
Muggleton, S.; De Raedt, L.; Poole, D.; Bratko, I.; Flach,
P. A.; Inoue, K.; and Srinivasan, A. 2012.
ILP turns 20 -
Biography and future challenges. Mach. Learn., (1): 3–23.
Muggleton, S. H.; Lin, D.; and Tamaddoni-Nezhad, A. 2015.
Meta-interpretive learning of higher-order dyadic Datalog:
predicate invention revisited. Mach. Learn., (1): 49–73.
Plotkin, G. 1971. Automatic Methods of Inductive Inference.
Ph.D. thesis, Edinburgh University.
Purgał, S. J.; Cerna, D. M.; and Kaliszyk, C. 2022. Learn-
ing Higher-Order Logic Programs From Failures. In IJCAI
2022.
Raghothaman, M.; Mendelson, J.; Zhao, D.; Naik, M.; and
Scholz, B. 2020. Provenance-guided synthesis of Data-
log programs. Proc. ACM Program. Lang., (POPL): 62:1–
62:27.
Ray, O. 2009. Nonmonotonic abductive inductive learning.
J. Applied Logic, (3): 329–340.
Sch¨uller, P.; and Benz, M. 2018. Best-effort inductive logic
programming via ﬁne-grained cost-based hypothesis genera-
tion - The inspire system at the inductive logic programming
competition. Mach. Learn., (7): 1141–1169.
Si, X.; Raghothaman, M.; Heo, K.; and Naik, M. 2019. Syn-
thesizing Datalog Programs using Numerical Relaxation. In
Proceedings of the Twenty-Eighth International Joint Con-
ference on Artiﬁcial Intelligence, IJCAI 2019, 6117–6124.

Srinivasan, A. 2001. The ALEPH manual. Machine Learn-
ing at the Computing Laboratory, Oxford University.
Stahl, I. 1995. The Appropriateness of Predicate Invention
as Bias Shift Operation in ILP. Mach. Learn., (1-2): 95–117.
Wahlig, J. 2022. Learning Logic Programs From Noisy Fail-
ures. CoRR, abs/2201.03702.

arXiv:2206.01614v1  [cs.LG]  1 Jun 2022

.
.
.

1

