A Scalable Two Stage Approach to Computing Optimal Decision Sets*

Alexey Ignatiev1, Edward Lam1,2, Peter J. Stuckey1, Joao Marques-Silva3
1Monash University, Melbourne, Australia
2CSIRO Data61, Melbourne, Australia
3ANITI, IRIT, CNRS, Toulouse, France

alexey.ignatiev,edward.lam,peter.stuckey
{

@monash.edu, joao.marques-silva@irit.fr
}

1
2
0
2

b
e
F
3

]
I

A
.
s
c
[

1
v
4
0
9
1
0
.
2
0
1
2
:
v
i
X
r
a

Abstract

Machine learning (ML) is ubiquitous in modern life. Since it
is being deployed in technologies that affect our privacy and
safety, it is often crucial to understand the reasoning behind
its decisions, warranting the need for explainable AI. Rule-
based models, such as decision trees, decision lists, and de-
cision sets, are conventionally deemed to be the most inter-
pretable. Recent work uses propositional satisﬁability (SAT)
solving (and its optimization variants) to generate minimum-
size decision sets. Motivated by limited practical scalability
of these earlier methods, this paper proposes a novel approach
to learn minimum-size decision sets by enumerating indi-
vidual rules of the target decision set independently of each
other, and then solving a set cover problem to select a subset
of rules. The approach makes use of modern maximum satis-
ﬁability and integer linear programming technologies. Exper-
iments on a wide range of publicly available datasets demon-
strate the advantage of the new approach over the state of the
art in SAT-based decision set learning.

1

Introduction

Rapid advances in artiﬁcial intelligence and, in particular, in
machine learning (ML), have inﬂuenced all aspects of hu-
man lives. Given the practical achievements and the over-
all success of modern approaches to ML (LeCun, Bengio,
and Hinton 2015; Jordan and Mitchell 2015; Mnih et al.
2015; ACM 2018), one can argue that it will prevail as a
generic computing paradigm and it will ﬁnd an ever grow-
ing range of practical applications. Unfortunately, the most
widely used ML models are opaque, which makes it hard
for a human decision-maker to comprehend the outcomes of
such models. This motivated efforts on validating the oper-
ation of ML models (Ruan, Huang, and Kwiatkowska 2018;
Katz et al. 2017) but also on devising approaches to ex-
plainable artiﬁcial intelligence (XAI) (Ribeiro, Singh, and
Guestrin 2016; Lundberg and Lee 2017; Monroe 2018).

One of the major lines of work in XAI is devoted to train-
ing logic-based models, e.g. decision trees (Bessiere, He-
brard, and O’Sullivan 2009; Narodytska et al. 2018; Hu,

*This work is supported in part by the AI Interdisciplinary In-
stitute ANITI, funded by the French program “Investing for the
Future - PIA3” under Grant agreement no. ANR-19-PI3A-0004.

Rudin, and Seltzer 2019; Aglin, Nijssen, and Schaus 2020),
decision lists (Angelino et al. 2017; Rudin and Ertekin 2018)
or decision sets (Lakkaraju, Bach, and Leskovec 2016; Ig-
natiev et al. 2018; Malioutov and Meel 2018; Ghosh and
Meel 2019; Yu et al. 2020), where concise explanations can
be obtained directly from the model. This paper focuses on
the decision set (DS) model, which comprises an unordered
set of if-then rules.

One of the advantages of decision sets over other rule-
based models is that rule independence makes it straight-
forward to explain a prediction: a user can pick any rule
that “ﬁres” the prediction and the rule itself serves as the
explanation. As a result, generation of minimum-size deci-
sion sets is of great interest. Recent work proposed SAT-
based methods for generating minimum-size decision sets
by solving a sequence of problems that determine whether
a decision set of size K exists, with K being the number of
rules (Ignatiev et al. 2018) or the number of literals (Yu et al.
2020) s.t. the decision set agrees with the training data. Un-
fortunately, scalability of both approaches is limited due to
the large size of the propositional encoding.

Motivated by this limitation, our work proposes a novel
approach that splits the DS generation problem into two
parts: (1) exhaustive rule enumeration and (2) computing a
subset of rules agreeing with the training data. In general,
this novel approach enables a signiﬁcantly more compact
propositional encoding, which makes it scalable for problem
instances that are out of reach for the state of the art. The
proposed approach is inspired by the standard setup used
in two-level logic minimization (Quine 1952, 1955; Mc-
Cluskey 1956). While the ﬁrst part can be done using enu-
meration of maximum satisﬁability (MaxSAT) solutions, the
second part is reduced to the set cover problem, for which
integer linear programming (ILP) is effective. Experiments
on a wide range of datasets indicate that this approach out-
performs the state of the art. The remainder of this paper
presents these developments in detail.

2 Preliminaries
Satisﬁability and Maximum Satisﬁability. We use the
standard deﬁnitions for propositional satisﬁability (SAT)
and maximum satisﬁability (MaxSAT) solving (Biere et al.

 
 
 
 
 
 
¬

¬

∈ {

0, 1
}

x. (Given a constant parameter σ

2009). SAT and MaxSAT admit Boolean variables. A literal
over Boolean variable x is either the variable x itself or its
, we use
negation
notation xσ to represent literal x if σ = 1, and to represent lit-
x if σ = 0.) A clause is a disjunction of literals. A term
eral
is a conjunction of literals. A propositional formula is said to
be in conjunctive normal form (CNF) or disjunctive normal
form (DNF) if it is a conjunction of clauses or disjunction of
terms, respectively. Whenever convenient, clauses and terms
are treated as sets of literals. Formulas written as sets of sets
of literals (either in CNF or DNF) are described as clausal.
We will make use of partial maximum satisﬁability (Par-
tial MaxSAT) (Biere et al. 2009, Chapter 19), which can be
formulated as follows. A partial CNF formula can be seen
as a conjunction of hard clauses
(which must be satis-
ﬁed) and soft clauses
(which represent a preference to sat-
isfy those clauses). The Partial MaxSAT problem consists in
ﬁnding an assignment that satisﬁes all the hard clauses and
maximizes the total number of satisﬁed soft clauses.

H

S

∈

1, . . . , K
{

Classiﬁcation Problems and Decision Sets. We follow
the notation used in earlier work (Bessiere, Hebrard, and
O’Sullivan 2009; Lakkaraju, Bach, and Leskovec 2016; Ig-
natiev et al. 2018; Yu et al. 2020). Consider a set of features
=
. The domain of possible values for feature
}
F
[K] is Dr. The complete space of feature values (or fea-
r
ture space (Han, Kamber, and Pei 2012)) is F (cid:44) ∏K
r=1 Dr.
The vector f = ( f1, . . . , fK) of K variables fr
Dr refers to
a point in F. Concrete (constant) points in F are denoted by
Dr. For simplicity, all the features
v = (v1, . . . , vK), with vr
are assumed to be binary, i.e. Dr =
[K]; categor-
r
∀
ical and ordinal features can be mapped to binary features
using standard techniques (Pedregosa et al. 2011). There-
fore, whenever convenient, a Boolean literal on a feature r
can be represented as fr (or
fr, resp.), denoting that feature
fr takes value 1 (value 0, resp.).

,
0, 1
}
{

∈

¬

∈

∈

E

∈

=

∈ E

∈ C

Consider a standard classiﬁcation scenario with training
is
F is a vector of feature values and
is a class. An example ei can be seen as associating
. This work

. A data instance (or example) ei
e1, . . . , eM
data
}
{
a pair (vi, ci) where vi
ci
a vector of feature values vi with a class ci
∈ C
,
focuses on binary classiﬁcation problems, i.e.
⊕}
C
{(cid:9)
but the proposed ideas are easily extendable to the case of
and the rth
multiple classes. Given example ei = (vi, ci)
∈ E
component vir of vi, literal f 1
is said to discriminate ei
−
r
vir
vir, i.e. f 1
because f 1
(cid:44)
falsiﬁes example ei when
−
−
r
r
it is considered as a conjunction of feature literals. The con-
cept of example discrimination can be extended to terms.

=

¬

vir

vir

∈ E

Examples ei, e j

associating the same set of feature
values with the opposite classes are referred to as over-
lapping. We assume wlog. that the training data
is per-
fectly classiﬁable, i.e.
partially deﬁnes a Boolean function
φ : F
— in other words, there are no overlapping ex-
→ C
. Otherwise, either ei or e j can be removed from
amples in
E
, incurring an error of 1. In general, repeated “col-
dataset
lisions” can be resolved by taking the majority vote, which
results in highest possible accuracy on training data.

E

E

E

The objective of classiﬁcation in ML is to devise a func-

E

E

tion ˆφ that matches the actual function φ on the train-
and generalizes suitably well on unseen test
ing data
data (F¨urnkranz, Gamberger, and Lavrac 2012; Han, Kam-
ber, and Pei 2012; Mitchell 1997; Quinlan 1993). In many
settings, function ˆφ is not required to match φ on the com-
and instead an accuracy measure
plete set of examples
is considered. Furthermore, in classiﬁcation problems one
conventionally has to optimize with respect to (1) the com-
plexity of ˆφ , (2) the accuracy of the learnt function (to make
it match the actual function φ on a maximum number of ex-
amples), or (3) both. As this paper assumes that the training
data does not have overlapping instances, we aim solely at
minimizing the representation size of the target ML models.
This paper focuses on learning representations of ˆφ cor-
responding to decision sets (DS) (Lakkaraju, Bach, and
Leskovec 2016; Ignatiev et al. 2018; Malioutov and Meel
2018; Ghosh and Meel 2019; Yu et al. 2020). A decision
set is an unordered set of rules. Each rule π is from the
, where u represents a don’t care
set
r=1{
}
value. For each example e
c,
, a rule of the form π
∈ E
π
is interpreted as “if the feature values of ex-
ample e agree with π then the rule predicts that example e
has class c”. Hereinafter, we will be dealing with learning
minimum-size decision sets, with the size measure being ei-
ther the number of rules in the decision set or the total num-
ber of literals in it (sometimes referred to as total size). Note
that because rules in decision sets are unordered, some rules
may overlap, i.e. multiple rules πi
may agree with some
instance of the feature space F. It may also happen that none
of the rules of a decision set apply to some instances of F.
Example 1. Consider the following dataset of four data in-
stances representing the “to date or not to date?” example
by Domingos (2015):

= ∏K

∈ R

fr, u

∈ R

∈ C

, c

fr,

⇒

R

¬

#

Day

Venue Weather TV Show Date?

e1 Weekday Dinner
e2 Weekend
Club
e3 Weekend
Club
e4 Weekend
Club

Warm
Warm
Warm
Cold

Bad
Bad
Bad
Good

No
Yes
Yes
No

This data serves to predict whether a friend accepts an invi-
tation to go out for a date given various circumstances. An
example of a valid decision set for this data is the following:

IF TV Show = Good
IF Day = Weekday
IF TV Show = Bad

∧∧∧

THEN Date = No
THEN Date = No
Day = Weekend THEN Date = Yes

This DS has 3 rules and a total size of 7 (1 for each literal
on the left and right, or alternatively, 1 for each literal on the
left and 1 for each rule). It does not exhibit rule overlap for
examples in F while the following decision set does:

IF TV Show = Good
IF Day = Weekday
IF Weather = Warm

∧∧∧

THEN Date = No
THEN Date = No
Day = Weekend THEN Date = Yes

Here, the ﬁrst and third rules overlap for all examples with
feature values Weather = Warm and TV Show = Good.

3 Related Work

Rule-based ML models can be traced back to around the
70s and 80s (Michalski 1969; Shwayder 1975; Hyaﬁl and
Rivest 1976; Breiman et al. 1984; Quinlan 1986; Rivest
1987). To our best knowledge, decision sets ﬁrst appear as
an unordered variant of decision lists (Rivest 1987; Clark
and Niblett 1989) in (Clark and Boswell 1991). The use
of logic and optimization for synthesizing a disjunction of
rules matching a given training dataset was ﬁrst tried in (Ka-
math et al. 1992). Recently, (Lakkaraju, Bach, and Leskovec
2016) argued that decision sets are more interpretable than
decision trees and decision lists.

Our work builds on (Ignatiev et al. 2018; Yu et al. 2020)
where SAT-based models were proposed for training deci-
sion sets of smallest size. The method of (Ignatiev et al.
2018) minimized the number of rules in perfect decision
sets, i.e. those that agree perfectly with the training data,
which is assumed to be consistent; it was also shown to
signiﬁcantly outperform the smooth local search approach
of (Lakkaraju, Bach, and Leskovec 2016). Rule minimiza-
tion was then followed by minimization of the total number
of literals used in the decision set, which resulted in a lexico-
graphic approach to the minimization problem. In contrast,
(Yu et al. 2020) focused on minimizing the total number of
literals in the target DS. This work showed that minimiz-
ing the number of rules is more scalable for solving the per-
fect decision set problem since the optimization measure, i.e.
the number of rules, is more coarse-grained. However, min-
imizing the total number of literals was shown to produce
signiﬁcantly smaller and, thus, more interpretable target de-
cision sets. Furthermore, they showed that sparse decision
sets (minimizing either the number of literals or the num-
ber or rules) provide a user with yet another way to produce
a succinct classiﬁer representation, by trading off its accu-
racy for smaller size. Sparse decision sets were also consid-
ered in (Malioutov and Meel 2018; Ghosh and Meel 2019)
where the authors proposed a MaxSAT model for represent-
ing one target class of the training data. ILP was also applied
to compute a variant of sparse decision sets (Dash, G¨unl¨uk,
and Wei 2018). As was shown in (Yu et al. 2020), sparse
decision sets, although are much easier to compute, achieve
lower test accuracy compared to perfect decision sets. As a
result, the focus of this work is solely on improving scala-
bility of computing perfect decision sets, i.e. sparse models
are excluded from consideration.

4 Decision Sets by Rule Enumeration

Similar to the recent logic-based approaches to learning de-
cision sets (Ignatiev et al. 2018; Malioutov and Meel 2018;
Ghosh and Meel 2019), our approach builds on state-of-the-
art SAT and MaxSAT technology. These prior works con-
sider a SAT or MaxSAT model that determines whether there
exists a decision set of size N given training data
with
= M examples. The problem is solved by iteratively vary-
|E|
ing size N and making either a series of SAT calls or one
MaxSAT call. The main limitation of prior work is the en-
K), where N is the
coding formula size, which is
O
target size of decision set (which is determined either as the

(N

M

×

×

E

number of rules (Ignatiev et al. 2018) or as the total num-
ber of literals (Yu et al. 2020)), M is the number of training
data instances and K is the number of features in the training
data. This limitation signiﬁcantly impairs scalability of these
approaches and hence restricts their practical applicability.

In contrast to the aforementioned works, the approach de-
tailed below does not aim at devising a decision set in one
step and instead consists of two phases. The ﬁrst phase se-
quentially enumerates all individual minimal rules given an
input dataset. The second phase computes a minimum-size
subset of rules (either in terms of the number of rules or
the total number of literals in use) that covers all the training
data instances. This way the approach trades off large encod-
ing size and thus potentially hard SAT oracle calls for com-
puting a complete decision set with a (much) larger number
of simpler oracle calls, each computing an individual rule,
followed by solving the set cover problem. This algorithmic
setup is, in a sense, inspired by the effectiveness of the stan-
dard clausal formula minimization approach (Quine 1952,
1955; McCluskey 1956; Brayton et al. 1984; Espresso).

,

C

E

=

⊕}

and

∈ R

E(cid:9)
= /0.

E⊕ ∪ E(cid:9)

⇒
fr,
¬

E⊕
E⊕ ∩ E(cid:9)

into the sets of examples

4.1 Decision Sets as DNF Formulas
First, recall that we consider binary classiﬁcation, i.e.

=
,
but the ideas of this section can be easily adapted
{(cid:9)
to multi-class problems, e.g. by using one-hot encoding (Pe-
dregosa et al. 2011). Next, let us split the set of training ex-
amples
for the respec-
E
tive classes s.t.

c, each associating a set of literals π
fr, u

and
Recall that a decision set is an unordered set of if-then
=
rules π
∏K
, over the feature-values present in rule π
r=1{
}
with the corresponding class c
,
. Following (Ig-
∈ {(cid:9)
natiev et al. 2018), observe that each set of literals π in the
rule forms a term and so every class ci
in a de-
cision set can be represented logically as a disjunction of
terms, each term representing a conjunction of literals in π.
Example 2. Consider our example dataset shown in Exam-
ple 1. Assume that features Day, Venue, Weather, and TV
Show are represented with Boolean variables f1, f2, f3, and
f4, respectively. Observe that all the features fr, r
[4],
∈
in the example are binary, and thus each value for feature
fr can be represented either as literal fr or literal
fr. Let
¬
us map the original feature values to
such that the
alphabetically-ﬁrst value is mapped to 0 while the other is
mapped to 1. The classes No and Yes are mapped to
and
, respectively. As a result, our dataset becomes

,
∈ {(cid:9)

0, 1
}
{

⊕}

⊕}

R

(cid:9)

⊕

f1
0
1
1
1

f2
1
0
0
0

f3
1
1
1
0

f4
0
0
0
1

c

(cid:9)
⊕
⊕
(cid:9)

Using this binary dataset and the ﬁrst decision set from Ex-
and c =
ample 1 the classes c =
are represented as the
(cid:9)
(cid:44) ( f4)
f4 ∧
(
DNF formulas φ
¬
∨

In this work, we follow (Ignatiev et al. 2018; Yu et al.
2020) and compute minimum-size decision sets in the form
of disjunctive representations φ
and

⊕
f1) and φ

of classes

and φ

(cid:44) (

f1)

¬

⊕

(cid:9)

(cid:9)

⊕

(cid:9)

. Even though it is simpler to construct rules for one class
⊕
when there are only two classes (Malioutov and Meel 2018;
Ghosh and Meel 2019), computing both φ
achieves
better interpretability. Speciﬁcally, if both classes are explic-
itly represented, it is relatively easy to extract explicit and
succinct explanations for any class, but this is not the case
when only one class is computed. This approach also imme-
diately extends to problems with three or more classes.

and φ

⊕

(cid:9)

⊕

for the class c =

Without loss of generality, we focus on computing a dis-
. The same
. The target DNF
must be consistent with the training data, i.e. every term
φ
and
. Furthermore, each
∈ E(cid:9)
must be irreducible, meaning that any subterm

junctive representation φ
reasoning can be applied to compute φ
φ
⊕
π
∈
(2) discriminate all examples e j
term π
π (cid:48) (cid:40) π does not fulﬁll one of the two conditions above.

must (1) agree with at least one example ei

∈ E⊕

⊕

∈

φ

(cid:9)

⊕

⊕

ψ (cid:44)

4.2 Learning Rules
This section describes the ﬁrst phase of the proposed ap-
proach, namely, how a term π satisfying both of the condi-
tions above can be obtained separately of the other terms.
Every term is computed as a MaxSAT solution to a partial
CNF formula

S

∈

and

with

H ∧ S

P
|
[K], deﬁne variables pr

H
Consider two sets of Boolean variables P and N,
= K. For every feature fr, r

(1)
being the hard and soft parts, described below.
=
P
N
|
|
and nr
N. The idea is inspired by the dual-rail encoding
(DRE) of propositional formulas (Bryant et al. 1987), e.g.
studied in the context of logic minimization (Manquinho
et al. 1997; Jabbour et al. 2014). Variables pr and nr are
referred to as dual-rail variables. We assume that pr = 1 iff
fr = 1 while nr = 1 iff fr = 0. Moreover, for every feature
fr, r
to forbid the feature
taking two values at once:

[K], a hard clause is added to

|
∈

H

∈

∈

[K] (
∈

pr
(2)
¬
The other combinations of values for pr and nr encode the
fact that feature r occurs in the target term π positively, neg-
atively, or does not occur at all (when pr = nr = 0).

∨ ¬

nr)

∀r

S

(cid:44)

The set of soft clauses

represents a preference to discard
the features from a target term π and thus contains a pair of
soft unit clauses expressing that preference:
[K]
(
(3)
}
¬
By construction of
and given a MaxSAT solution for (1),
the target term π is composed of all features fr, for which
one of the dual-rail variables (either pr or nr) is assigned
to 1 by the solution, i.e. the corresponding soft clauses are
falsiﬁed.

pr), (

{
S

nr)

¬

∈

S

r

|

Discrimination Constraints. Every example e j = (v j,
)
(cid:9)
must be discriminated. This can be enforced by us-
from
E(cid:9)
ing a clause ((cid:87)
), where constant v jr is the value
r
of the rth feature in example e j. To represent this in the dual-
rail formulation, we add the following hard clauses to

[K] f 1

v jr

−

∈

:

r

∀ j

[
E
|
∈

]
(cid:9)|

(cid:95)

δ jr,

r

[K]

∈

where δ jr is to be replaced by dual-rail variable pr if v jr = 0
and replaced by the opposite dual-rail variable nr if v jr = 1.
Example 3. Consider instance e1 = ( f1 = 0, f2 = 1, f3 =
1, f4 = 0)
of the running example. To discriminate it,
∈ E(cid:9)
p4). Indeed, to satisfy
n2 ∨
we add a hard clause (p1 ∨
this clause, we have to pick one of the literals discriminating
example e1, e.g. if p1 = 1 then literal f1 occurs in term π,
which discriminates instance e1.

n3 ∨

Coverage Constraints. To enforce that every term π cov-
, we can use simi-
ers at least one training instance of
E⊕
lar reasoning. Observe that a term π
covers instance
∈ R
ei = (vi, ci)
iff none of its literals discriminates ei, i.e.
v jr
f 1
r

[K]. For each example ei = (vi, ci)

−
, we introduce an auxiliary variable ti deﬁned by:

∈ E⊕
π for any r

(cid:54)∈

∈

∈

E⊕

ti

K
(cid:95)

(
↔ ¬
r=1

δir),

(5)

where δir is to be replaced by dual-rail variable pr if vir = 0
and replaced by the opposite dual-rail variable nr if vir = 1.
Now, variable ti is true iff term π covers example ei.
Example 4. Consider instance e2 = ( f1 = 1, f2 = 0, f3 =
1, f4 = 0)
of the running example. Introduce variable
p4) as shown above. If t2 = 1, the liter-
n3 ∨
(n1 ∨
t2 ↔ ¬
als in the target term π cannot discriminate example e2.

∈ E⊕
p2 ∨

Once auxiliary variables ti are introduced for each exam-

ple ei

∈ E⊕

, the hard clause
(cid:95)
i
[
E
|
∈

]
⊕|

ti

(6)

can be added
one of the training data instances.

H

to ensure that any term π agrees with at least

(K

The overall partial MaxSAT model (1) comprises hard
clauses (2), (4), (5), (6) and also soft clauses (3). The num-
(K + M) while
ber of variables used in the encoding is
O
M). Recall that earlier
the number of clauses is
O
K) variables and
works proposed encoding with
clauses, which in some situations makes it hard (or infeasi-
ble) to prove optimality of large decision sets.
Example 5. Consider our aim at computing rules for class
⊕
in the running example. By applying the DRE, one obtains
the formula ψ =


where

×
(N



M

O

×

×

H ∧ S
(
¬
(
¬

n1)
n3)

p1 ∨ ¬
p3 ∨ ¬
(p1 ∨
(n1 ∨
[t2 ↔ ¬
[t3 ↔ ¬

∧
∧
n2 ∨
p2 ∨
(n1 ∨
(n1 ∨

(
¬
(
¬
n3 ∨
p3 ∨
p2 ∨
p2 ∨
t3)

(t2 ∨




p2 ∨ ¬
p4 ∨ ¬
p4)
n4)

n3 ∨
n3 ∨

n2)
n4)

∧
∧

∧
∧
p4)]
p4)]

∧
∧




=

H

and

=

S

(cid:26) (
¬
(
¬

p1)
p3)

n1)
n3)

(
¬
(
¬

(
¬
(
¬

∧
∧

∧
∧

p2)
p4)

∧
∧

(cid:27)

n2)
n4)

(
¬
(
¬

∧

H

(4)

H

H

E(cid:9)

E⊕

E(cid:9)

∈ E⊕

∈ E⊕

; soft clauses

T⊕
. The rationale is that if sets

Any assignment satisfying the hard clauses

of the dual-
rail MaxSAT formula (1) constructed above deﬁnes a term π
and covers at least one
that discriminates all examples of
ensure minimality of terms π.
example of
S
More importantly, one can exhaustively enumerate all solu-
tions of (1) to compute the set of all such terms (i.e. one can
use the standard trick of adding a hard clause blocking the
previous solution and ask for a new one until no more solu-
tions can be found). Let us refer to this set of terms as
.
T⊕
Finally, we claim that as soon as exhaustive solution enumer-
covers
ation for formula (1) is ﬁnished, the set of terms
every example ei
and
E⊕
do not overlap then for any example ei
there is a
E(cid:9)
way to cover it by a term π s.t. all examples of
are dis-
criminated by π. This means that, by construction of (1), for
every variable ti, the hard part
of the formula has a sat-
isfying assignment assigning ti = 1. (Recall that we assume
training data to be perfectly classiﬁable.)
Example 6. Consider our running example. Observe that a
valid solution for formula ψ above is
from which
f4) for the target class
we can extract a term π = ( f1 ∧ ¬
c =
. Observe that π covers
. The term π is added to
⊕
T⊕
both examples e2 and e3 and discriminates examples e1 and
e4 from class

.
(cid:9)
4.3 Smallest Rule Cover
of all terms for class c =
Once the set
is obtained, the
next step of the approach is to compute a smallest size cover
φ
. Concretely, the problem is
⊕
to select the smallest size subset φ
that covers all
the training examples. The size can be the either the num-
ber of terms used or the total number of literals used in φ
.
⊕
Therefore, the problem to solve is essentially the set cover
= L and create a
problem (Karp 1972). Assume that
Boolean variable b j for every term π j
, indicating that
rule j is selected. Also, consider L
, Boolean
constant values ai j s.t. ai j = 1 iff term j covers example i.
Then, the problem of computing the cover with the fewest
number of terms can be stated as:

of the training examples

|T⊕|
∈ T⊕
M(cid:48), M(cid:48) =

p1, n4}

|E⊕|

T⊕

T⊕

E⊕

of

×

⊕

{

⊕

minimize

subject to

L
∑
j=1

L
∑
j=1

b j

ai j

b j

·

1,

i
∀

∈

≥

[M(cid:48)]

(7)

(8)

Alternatively, the objective function can be modiﬁed to
minimize the total number of literals. Concretely, create a
constant s j
, π
. The problem is then to
|

Z s.t. s j =

∈ T⊕

∈

π j
|
L
∑
j=1

s j

b j

·

minimize

subject to

L
∑
j=1

ai j

b j

·

1,

i
∀

∈

≥

[M(cid:48)]

Example 7. For our running example,
being:

|T⊕|

= 4, with terms

=

f3), ( f1 ∧ ¬
( f1 ∧
{
The set cover problem for c =

T⊕

f4), (

f3), (

f2 ∧
¬
¬
can be seen as the table:

f4)
}

f2,

¬

⊕

(9)

(10)

π1
1
1

2

π2
1
1

2

π3
1
1

2

π4
1
1

2

ai j

s j

E⊕

This example has trivial solutions because every term covers
, i.e., every ai, j = 1 When minimizing the
all examples of
number of terms using the set cover problem (7) and (8), ev-
ery optimal solution contains exactly one term. When mini-
mizing the number of literals using the set cover problem (9)
and (10), every optimal solution again contains exactly one
term, and this term has size 2.
Now, consider class c =
;
(cid:9)
|T(cid:9)|
f1), ( f2), (

= 4, with terms being:
f3), ( f4)
}

=
¬
Then the set cover problem for c =
following table:

can be seen as the

(
¬

T(cid:9)

(cid:9)

{

π1
1
0

π2
1
0

π3
0
1

π4
0
1

ai j

s j

1

1

1

1
In our case, one valid solution picks columns π1 and π3 as
both of them together cover
. Thus, when minimizing the
E(cid:9)
number of terms, the fewest number of columns to pick, such
that every row has at least one value, is 2, i.e., any optimal
solution has cost 2 (1 + 1).

Breaking Symmetric Rules. Observe in Example 7 that
the two terms π1 and π2 in
cover the same examples from
. In the context of the set cover problem, such terms are
E⊕
described as symmetric. It is straightforward that at most one
term in a set of symmetric terms can appear in a solution
because of the minimization in the set cover problem.

T⊕

Symmetric terms can become an issue if the total number
of terms is exponential on the number of features. This kind
of repetition can be avoided by using the instance coverage
variables ti. Concretely, given a term π
covering a set
of data instances, one can add a clause ((cid:87)
ti)
E (cid:48)
i
E
⊕ ⊂ E⊕
∈
enforcing that any terms discovered later must cover at least
one instance ei uncovered by term π.

∈ T⊕

E(cid:48)
⊕

⊕\

While the terms are symmetric for objective (7), there is a
dominance relation for objective (9). Consider a term π with
π
the same coverage as another term ρ s.t.
— term
|
| ≥ |
π dominates term ρ. Given a set cover solution S
ρ
, we
}
∪ {
can always replace ρ by π to get a no worse solution S
π
.
}
∪{
Therefore, term ρ can be ignored during selection.

ρ
|

Because term enumeration is done with MaxSAT, i.e.
smaller terms come ﬁrst, we can use the same method above
for symmetry to eliminate dominated terms, since a domi-
nating term (a smallest term with the same coverage) will
always be discovered ﬁrst. Clearly, optimality for objec-
tives (7) and (9) is still guaranteed if breaking symmetric
rules is applied.
Example 8. By breaking symmetric terms, the enumeration
and two terms
procedure computes only one term for class
= 4.)
for class
. (Recall that we previously got
Note that all of them are included in the solutions for the
corresponding set cover problems.

⊕
|T⊕|

|T(cid:9)|

(cid:9)

=

(a) Raw performance

(b) Detailed runtime comparison of rulerl

il p vs. opt

Figure 1: Scalability of the competitors.

5 Experimental Results
This section evaluates the proposed rule enumeration based
approach in terms of scalability and compares it with the
state of the art of SAT-based learning of minimum-size deci-
sion sets on a variety of publicly available datasets. The ex-
periments were performed in Debian Linux on an Intel Xeon
Silver-4110 2.10GHz processor with 64GByte of memory.
Following the setup of recent work (Yu et al. 2020), the time
limit was set to 1800s for each individual process to run. The
memory limit was set to 8GByte per process.

Prototype Implementation and Selected Competition.
A prototype1 of our rule enumeration based approach was
developed as a set of Python scripts, in the following re-
ferred to as ruler. The implementation of rule enumeration
was done with the use of the state-of-the-art MaxSAT solver
RC2 (Ignatiev, Morgado, and Marques-Silva 2018, 2019),
which proved to be the most effective in MaxSAT model
enumeration (MaxSAT Evaluation 2020). As a result, the
terms are computed in a sorted fashion, i.e. the smallest
ones come ﬁrst. For the second phase of the approach, i.e.
computing the set cover, we attempted to solve the prob-
lem both (1) with the RC2 MaxSAT solver and (2) with the
Gurobi ILP solver (Gurobi Optimization 2020). The corre-
sponding conﬁgurations of the prototype are called ruler∗rc2
and ruler∗il p, where ‘
’ can either be ‘r’ or ‘l’ meaning that
∗
the solver minimizes either the number of rules or the total
number of literals.2 Conﬁgurations ruler∗
+b apply symme-
∗
try breaking constraints to reduce the number of implicant
rules computed in the ﬁrst phase of the approach. Finally,
all conﬁgurations were set to compute explicit optimal DNF
representations for all classes given a dataset.

The competiting approaches include SAT-based meth-
2 referred to as

ods (Ignatiev et al. 2018) MinDS2 and MinDS(cid:63)

1Available as part of https://github.com/alexeyignatiev/minds.
2We also tried using Gurobi for the ﬁrst phase but it was signif-

icantly outperformed by the MaxSAT-based solution.

mds2 and mds(cid:63)
2. The former tool computes the fewest num-
ber of rules while the latter lexicographically minimizes the
number of rules and then the number of literals. The second
competitor is a recent SAT-based approach that minimizes
the total number of literals in the model (Yu et al. 2020), in
the following referred to as opt. Note that as the main objec-
tive of this experimental assessment is to demonstrate scala-
bility of the proposed approach, the methods for computing
sparse decision sets (Malioutov and Meel 2018; Ghosh and
Meel 2019; Yu et al. 2020) are intentionally excluded due to
the signiﬁcant difference in the problem they tackle.

Benchmarks. All datasets considered in the evaluation
were adopted from (Yu et al. 2020) and used unchanged.
These datasets originated from the UCI Machine Learning
Repository (UCI) and the Penn Machine Learning Bench-
marks (PennML). The total number of datasets is 1065. The
number of one-hot encoded (Pedregosa et al. 2011) fea-
tures (training instances, resp.) per dataset in the benchmark
suite varies from 3 to 384 (from 14 to 67557, resp.). Also,
since ruler can handle only perfectly classiﬁable data, it pro-
cesses each training dataset by keeping the largest consistent
(non-overlapping) set of examples. This technique is applied
in (Ignatiev et al. 2018; Yu et al. 2020) as well, which en-
ables one to achieve the highest possible accuracy on the
training data. Motivated by one of the conclusions of (Yu
et al. 2020) stating that perfectly accurate decision sets, if
successfully computed, are signiﬁcantly more accurate than
sparse and also heuristic models, here we do not compare
test accuracy of the competitors – we assume test accuracy
to be (close to) identical for all the considered approaches.

Raw Performance. Figure 1a shows scalability of all
the selected approaches. Observe that the mixed solution
rulerr
il p+b demonstrates the best performance being able to
train decision sets for 802 datasets. Second best approach is
rulerl
il p+b and copes with 800 benchmarks. Pure MaxSAT-
based rulerr
rc2+b perform worse with 734

rc2+b and rulerl

0100200300400500600700800instances020040060080010001200140016001800CPUtime(s)rulerrilp+brulerlilp+brulerrrc2+brulerlilprulerrilprulerlrc2+brulerrrc2mds2rulerlrc2mds?2opt10−1100101102103104rulerlilp+b10−1100101102103104opt1800sec.timeout1800sec.timeout(a) Literals or rules: rulerl

il p vs. mds2

(b) Literals or lexicographic: rulerl

il p vs. mds(cid:63)
2

Figure 2: Model size comparison.

and 669 instances solved. This is not surprising because the
structure of set cover problems naturally ﬁts the capabilities
of modern ILP solvers.

Disabling symmetry breaking constraints affects the per-
formance of all conﬁgurations of ruler∗
, which drops sig-
∗
niﬁcantly. When it is disabled, the best such conﬁgura-
tion (rulerl
il p) solves 686 benchmarks while the worst one
(rulerl
rc2) tackles 556. Here, we should say that the maxi-
mum and average number of rules enumerated if symme-
try breaking is disabled is 326399 and 19604.4, respectively.
Breaking symmetric rules decreases these numbers to 8865
and 563.7, respectively.

As for the rivals of the proposed approach, the best of
them (mds2) is far behind ruler∗il p+b and successfully trains
578 models even though it targets rule minimization, which
is arguably a much simpler problem. Another competitor
(mds(cid:63)
2) lexicographically minimizes the number of rules and
then the number of literals, which is unsurprisingly harder
to deal with, as it solves 398 benchmarks. Finally, the worst
performance is demonstrated by opt, which learns 351 mod-
els. We reemphasize that both opt and rulerl
il p+b compute
minimum-size decision sets in terms of the number of liter-
als. However, the proposed solution outperforms the compe-
tition by 449 benchmarks. Note that due to the large encod-
ing size, opt (mds2, resp.) is practically limited to optimal
models having a few dozens of literals (rules, resp.). There
is no such limitation in ruler∗
– in our experiments, it could
∗
obtain minimum-size models having thousands of literals in
total within the given time limit. The runtime comparison
for rulerl
il p+b and opt is detailed in Figure 1b – observe that
except for a few outliers, rulerl
il p+b outperforms the rival by
up to four orders of magnitude.

Rules vs. Literals. Here we demonstrate that literal mini-
mization results in smaller and thus more interpretable mod-
els than rule minimization. Figure 2a compares the total
number of literals in the models of mds2 and rulerl
il p+b
while Figure 2b compares the model sizes for mds(cid:63)
2 and

rulerl
il p+b. To make a valid comparison, we used only in-
stances solved by both approaches in each pair. Among the
datasets used in of Figure 2a, the average number of literals
obtained by mds2 and rulerl
il p+b is 116.2 and 62.2, respec-
tively – the advantage of literal minimization is clear. Also,
as shown in Figure 2b, lexicographic optimization results in
models almost identical in size to the models produced by
rulerl
il p+b. This suggests that applying the approach of mds(cid:63)
2
may in general pay off in terms of solution size, by signif-
icantly sacriﬁcing scalability compared to mds2 and, more
importantly, to rulerl
il p+b (398 vs. 578 vs. 800 instances
solved, which represents 37.4%, 54.7%, and 75.1% of all
1065 benchmarks, respectively).

6 Conclusions

This paper has introduced a novel approach to learning
minimum-size decision sets based on individual rule enu-
meration. The proposed approach has been motivated by the
standard twofold methods applied in two-level logic mini-
mization (Quine 1952, 1955; McCluskey 1956) and split the
problem into two parts: (1) exhaustively enumerating indi-
vidual rules followed by (2) solving the set cover problem.
The basic approach has been additionally augmented with
symmetry breaking, enabling us to signiﬁcantly reduce the
number of rules produced. The approach has been applied
to computing minimum-size decision sets both in terms of
the number of rules and in terms of the total number of lit-
erals. The proposed approach has been shown to outperform
the state of the art in logic-based learning of minimum-size
decision sets by a few orders of magnitude.

As the proposed approach targets computing perfectly ac-
curate decision sets, a natural line of future work is to ex-
amine ways of applying it to computing sparse decision sets
that trade off accuracy for size. Another line of work is to
address the issue of potential rule overlap wrt. the proposed
approach. Finally, it is of interest to apply similar rule enu-
meration techniques for devising other kinds of rule-based
ML models, e.g. decision lists and decision trees.

100101102103rulerlilp+b100101102103mds2100101102103rulerlilp+b100101102103mds?2References
ACM. 2018. Fathers of the Deep Learning Revolution Re-
ceive ACM A.M. Turing Award. http://tiny.cc/9plzpz.

Aglin, G.; Nijssen, S.; and Schaus, P. 2020. Learning
Optimal Decision Trees Using Caching Branch-and-Bound
Search. In AAAI, 3146–3153.

Angelino, E.; Larus-Stone, N.; Alabi, D.; Seltzer, M.; and
Rudin, C. 2017. Learning Certiﬁably Optimal Rule Lists. In
KDD, 35–44.

Bessiere, C.; Hebrard, E.; and O’Sullivan, B. 2009. Min-
imising Decision Tree Size as Combinatorial Optimisation.
In CP, 173–187.

Biere, A.; Heule, M.; van Maaren, H.; and Walsh, T., eds.
2009. Handbook of Satisﬁability. IOS Press. ISBN 978-1-
58603-929-5.

Brayton, R. K.; Hachtel, G. D.; McMullen, C.; and
Sangiovanni-Vincentelli, A. 1984. Logic minimization al-
gorithms for VLSI synthesis, volume 2. Springer Science &
Business Media.

Breiman, L.; Friedman, J. H.; Olshen, R. A.; and Stone, C. J.
1984. Classiﬁcation and Regression Trees. Wadsworth.
ISBN 0-534-98053-8.

Bryant, R. E.; Beatty, D. L.; Brace, K. S.; Cho, K.; and Shef-
ﬂer, T. J. 1987. COSMOS: A Compiled Simulator for MOS
Circuits. In DAC, 9–16.

Clark, P.; and Boswell, R. 1991. Rule Induction with CN2:
Some Recent Improvements. In EWSL, 151–163.

Clark, P.; and Niblett, T. 1989. The CN2 Induction Algo-
rithm. Machine Learning 3: 261–283.

Dash, S.; G¨unl¨uk, O.; and Wei, D. 2018. Boolean Decision
Rules via Column Generation. In NeurIPS, 4660–4670.
Domingos, P. 2015. The Master Algorithm: How the Quest
for the Ultimate Learning Machine Will Remake Our World.
Basic Books. ISBN 978-0465065707.

Espresso. 1993. Espresso — Multi-valued PLA minimiza-
tion. http://tiny.cc/txdnsz.
F¨urnkranz, J.; Gamberger, D.; and Lavrac, N. 2012. Founda-
tions of Rule Learning. Springer. ISBN 978-3-540-75196-0.

Ghosh, B.; and Meel, K. S. 2019.
IMLI: An Incremen-
tal Framework for MaxSAT-Based Learning of Interpretable
Classiﬁcation Rules. In AIES, 203–210.

Gurobi Optimization, L. 2020. Gurobi Optimizer Reference
Manual. URL http://www.gurobi.com.
Han, J.; Kamber, M.; and Pei, J. 2012. Data Mining: Con-
cepts and Techniques, 3rd edition. Morgan Kaufmann. ISBN
978-0123814791.

Hu, X.; Rudin, C.; and Seltzer, M. 2019. Optimal Sparse
Decision Trees. In NeurIPS, 7265–7273.

Hyaﬁl, L.; and Rivest, R. L. 1976. Constructing Optimal
Binary Decision Trees is NP-Complete. Inf. Process. Lett.
5(1): 15–17.

Ignatiev, A.; Morgado, A.; and Marques-Silva, J. 2018.
PySAT: A Python Toolkit for Prototyping with SAT Oracles.
In SAT, 428–437.

Ignatiev, A.; Morgado, A.; and Marques-Silva, J. 2019.
RC2: an Efﬁcient MaxSAT Solver. J. Satisf. Boolean Model.
Comput. 11(1): 53–64.

Ignatiev, A.; Pereira, F.; Narodytska, N.; and Marques-Silva,
J. 2018. A SAT-Based Approach to Learn Explainable De-
cision Sets. In IJCAR, 627–645.

Jabbour, S.; Marques-Silva, J.; Sais, L.; and Salhi, Y. 2014.
Enumerating Prime Implicants of Propositional Formulae in
Conjunctive Normal Form. In JELIA, 152–165.

Jordan, M. I.; and Mitchell, T. M. 2015. Machine learn-
ing: Trends, perspectives, and prospects. Science 349(6245):
255–260.

Kamath, A. P.; Karmarkar, N.; Ramakrishnan, K. G.; and
Resende, M. G. C. 1992. A continuous approach to inductive
inference. Math. Program. 57: 215–238.

Karp, R. M. 1972. Reducibility Among Combinatorial Prob-
lems. In Complexity of Computer Computations, 85–103.

Katz, G.; Barrett, C. W.; Dill, D. L.; Julian, K.; and Kochen-
derfer, M. J. 2017. Reluplex: An Efﬁcient SMT Solver for
Verifying Deep Neural Networks. In CAV, 97–117.

Lakkaraju, H.; Bach, S. H.; and Leskovec, J. 2016.
Inter-
pretable Decision Sets: A Joint Framework for Description
and Prediction. In KDD, 1675–1684.

LeCun, Y.; Bengio, Y.; and Hinton, G. 2015. Deep learning.
nature 521(7553): 436.

Lundberg, S. M.; and Lee, S. 2017. A Uniﬁed Approach to
Interpreting Model Predictions. In NIPS, 4765–4774.

Malioutov, D.; and Meel, K. S. 2018. MLIC: A MaxSAT-
Based Framework for Learning Interpretable Classiﬁcation
Rules. In CP, 312–327.

Manquinho, V.; Flores, P.; Marques-Silva, J.; and Oliveira,
A. 1997. Prime Implicant Computation Using Satisﬁability
Algorithms. In ICTAI, 232–239.

MaxSAT Evaluation 2020. 2020. MaxSAT Evaluation 2020.
https://maxsat-evaluations.github.io/2020/.

McCluskey, E. J. 1956. Minimization of Boolean Functions.
Bell system technical Journal 35(6): 1417–1444.

Michalski, R. S. 1969. On the quasi-minimal solution of the
general covering problem. In International Symposium on
Information Processing, 125–128.
Mitchell, T. M. 1997. Machine learning. McGraw-Hill.

Mnih, V.; Kavukcuoglu, K.; Silver, D.; Rusu, A. A.; Ve-
ness, J.; Bellemare, M. G.; Graves, A.; Riedmiller, M.; Fid-
jeland, A. K.; Ostrovski, G.; et al. 2015. Human-level con-
trol through deep reinforcement learning. Nature 518(7540):
529.
Monroe, D. 2018. AI, Explain Yourself. Commun. ACM
61(11): 11–13.

Narodytska, N.; Ignatiev, A.; Pereira, F.; and Marques-Silva,
J. 2018. Learning Optimal Decision Trees with SAT.
In
IJCAI, 1362–1368.
Pedregosa, F.; Varoquaux, G.; Gramfort, A.; Michel, V.;
Thirion, B.; Grisel, O.; Blondel, M.; Prettenhofer, P.; Weiss,
R.; Dubourg, V.; Vanderplas, J.; Passos, A.; Cournapeau, D.;
Brucher, M.; Perrot, M.; and Duchesnay, E. 2011. Scikit-
learn: Machine Learning in Python. Journal of Machine
Learning Research 12: 2825–2830.
PennML. 2020. Penn Machine Learning Benchmarks. https:
//github.com/EpistasisLab/penn-ml-benchmarks.

Quine, W. V. 1952. The problem of simplifying truth func-
tions. American mathematical monthly 521–531.
Quine, W. V. 1955. A way to simplify truth functions. Amer-
ican mathematical monthly 627–631.
Quinlan, J. R. 1986. Induction of Decision Trees. Machine
Learning 1(1): 81–106.
Quinlan, J. R. 1993. C4.5: Programs for machine learning.
Morgan Kauffmann.

Ribeiro, M. T.; Singh, S.; and Guestrin, C. 2016. “Why
Should I Trust You?”: Explaining the Predictions of Any
Classiﬁer. In KDD, 1135–1144.
Rivest, R. L. 1987. Learning Decision Lists. Machine
Learning 2(3): 229–246.
Ruan, W.; Huang, X.; and Kwiatkowska, M. 2018. Reach-
ability Analysis of Deep Neural Networks with Provable
Guarantees. In IJCAI, 2651–2659.
Rudin, C.; and Ertekin, S. 2018. Learning customized and
optimized lists of rules with mathematical programming.
Mathematical Programming Computation 10: 659–702.
Shwayder, K. 1975. Combining Decision Rules in a Deci-
sion Table. Commun. ACM 18(8): 476–480.
UCI. 2020. UCI Machine Learning Repository.
//archive.ics.uci.edu/ml.

https:

Yu, J.; Ignatiev, A.; Stuckey, P. J.; and Le Bodic, P. 2020.
Computing Optimal Decision Sets with SAT. In CP, 952–
970.

