Robustness Certiﬁcation of Generative Models

Matthew Mirman 1 Timon Gehr 1 Martin Vechev 1

0
2
0
2

r
p
A
0
3

]

G
L
.
s
c
[

1
v
6
5
7
4
1
.
4
0
0
2
:
v
i
X
r
a

is highly non-convex,

Abstract
Generative neural networks can be used to specify
continuous transformations between images via
latent-space interpolation. However, certifying
that all images captured by the resulting path
in the image manifold satisfy a given property
can be very challenging. This is because this
set
thwarting existing
scalable robustness analysis methods, which
are often based on convex relaxations. We
present APPROXLINE, a scalable certiﬁcation
method that successfully veriﬁes non-trivial
speciﬁcations involving generative models and
classiﬁers. APPROXLINE can provide both
sound deterministic and probabilistic guarantees,
by capturing either inﬁnite non-convex sets of
neural network activation vectors or distributions
over such sets. We show that APPROXLINE
is practically useful and can verify interesting
interpolations in the networks latent space.

1. Introduction

While neural networks are used across a wide range of
applications, from facial recognition to autonomous driving,
certiﬁcation of their behavior has remained predominantly
focused on uniform classiﬁcation of norm-bounded balls
aiming to capture invisible perturbations (Gehr et al.,
2018; Katz et al., 2017; Wong et al., 2018; Gowal et al.,
2018; Singh et al., 2018; Raghunathan et al., 2018; Tjeng
et al., 2017; Dvijotham et al., 2018b; Salman et al., 2019;
Dvijotham et al., 2018c; Wang et al., 2018).

However, a system’s safety can depend on its behavior on
visible transformations. Consequently, there is increased
interest in investigating techniques able to certify more
complex speciﬁcations (e.g., geometric perturbations)
(Balunovic et al., 2019; Liu et al., 2019; Dvijotham et al.,
2018a; Singh et al., 2019).

Of particular interest is the work of Sotoudeh & Thakur

1Department of Computer Science, ETH Zurich, Zurich,
to: Matthew Mirman

Correspondence

Switzerland.
<matthew.mirman@inf.ethz.ch>.

Figure 1. To prove that a classiﬁer is robust to orientation changes,
we consider a non-convex set of images created by interpolation in
the latent space of a generative model. The bottom-middle image
is the nonsensical pixel-wise average of the endpoints that every
convex relaxation based analysis would have to consider.

(2019), which shows that if inputs of a network are restricted
to a line segment, exact veriﬁcation can sometimes be
efﬁciently performed. This method has been used to certify
properties which are not norm-based (Julian et al., 2018) and
improve Integrated Gradients (Sundararajan et al., 2017).

This Work In this work we build on related ideas
and introduce a powerful veriﬁer based on non-convex
overapproximation of sets of neuron activation vectors,
trading off some exactness for scalability. Further, our
veriﬁer is able to certify probabilistic properties, which
can be used to quantify the fraction of inputs that satisfy the
desired property even if it does not hold for all considered
inputs.
In contrast to sampling-based approaches, our
analyzer computes guaranteed bounds on those quantities.

Main contributions Our key contributions are:

• A veriﬁcation system, APPROXLINE1, which
introduces sound approximations to non-convex
certiﬁcation, scaling to much larger networks (nearly
100k neurons) than exact methods and even sampling.

• The ﬁrst demonstration of veriﬁcation of visible
speciﬁcations based on latent space interpolations of a
generator, such as that a classiﬁer for “is bald” is robust
to different orientations of a head, as in Fig. 1.

• A method to compute tight deterministic guaranteed
bounds on probabilities of outputs given distributions
over inputs, which we believe is the ﬁrst application
of probabilistic abstract interpretation in the context of
neural networks.

Earlier version submitted to ICLR 2020

1 Link to code and model snapshots in dropbox.

 
 
 
 
 
 
Encode

Decode

Classify with nA

Robustness Certiﬁcation of Generative Models

nD

x1,1

x1,2

x1,2

E1

E2

E2

4

3

2

1

e1

λ

=

1

e2

−1

1 2

(a)

nE

nE

n#
D

E1

2 .

4

.

.2

4
.2

2

1

−1

1 2 3

(b)

ReLU#

x1,1

ReLU

ReLU

x2,1

x2,2

x2,2
1
.
.1

4
.2

.1

.1

2

1

.

4

Relax

x2,1

1 2 3

(c)

0 . 5

x2,2

4

3

2

1

0.5

1

−0.25

.

4

.6

MatMul#

x2,1

1 2 3

(d)

x3,1

x3,2

x3,2

4

3

2

1

(e)

.6

.4

3

x3,1

Figure 2. Using APPROXLINE to ﬁnd probability bounds for latent space interpolation of ﬂipped images, as summarized in the pseudocode
in Appendix A. Blue polygonal chains represent activation distributions at each layer exactly. The orange boxes represent the relaxation
that APPROXLINE would create, obviating the need to keep track of the segments it entirely covers. The probabilities associated with each
segment or box are shown in red. While in practice, images are more than two dimensional, and the classiﬁer we use is much larger, the
presented inference presented in the lightly shaded green region is faithful to the weights of the network shown in the top row.

al.

(2018a)

Related work Dvijotham et
verify
probabilistic properties universally over sets of inputs by
bounding the probability that a dual approach veriﬁes
In contrast, our system veriﬁes properties
the property.
that are either universally quantiﬁed or probabilistic.
However, the networks we verify are multiple orders of
magnitude larger. While they only provide upper bounds
on the probability that a speciﬁcation has been violated,
we provide extremely tight bounds on such probabilities
from both sides. PROVEN (Weng et al., 2018) proposes a
technique to infer conﬁdence intervals on the probability
of misclassiﬁcation from prexisting convex relaxation
methods that ﬁnd linear constraints on outputs. We show
how in the case of interpolations for generative models,
convex relaxation methods are unable to prove meaningful
bounds. This implies that the linear lower bound function
used by PROVEN would be bounded above by 0, and
thus because F L
0 (0.5) = 1, the
gt
lower bound, γL, that their system should derive would
be γL = 0. This is because even the most precise convex
relaxation over the generated set of images might include
many nonsensical images. For example, the convex hull
includes the pixel-wise average of the generated endpoint
images, as can be seen in Fig. 1.

0 (0.5) and F L

(0.5) ≥ F L

Another line of work is smoothing, which provides a defense
with statistical robustness guarantees (Cohen et al., 2019;
Lecuyer et al., 2018; Liu et al., 2018; Li et al., 2018;
Cao & Gong, 2017). In contrast, APPROXLINE provides
deterministic guarantees, and is not a defense. The analysis
we use to determine bounds is an instance of probabilistic
abstract interpretation (Cousot & Monerau, 2012).

2. Overview of APPROXLINE

We now use the example in Fig. 2 to demonstrate how
APPROXLINE computes exact and probabilistic bounds for
the robustness of a classiﬁer based on a latent space image
transformation. The goal is to verify that a classiﬁcation
network nA does not change its prediction when presented
with images of a head from different angles, produced by
interpolating encodings in the latent space of an autoencoder.
We ﬁrst use the encoder, nE, to produce encodings e1
and e2 from the original image and that image ﬂipped
horizontally. It is a common technique to use the decoder
nD to get a picture of a head at an intermediate angle, on
an interpolated point e, taken from the segment e1e2 =
{e1 + α · (e2 − e1) | α ∈ [0, 1]}. Decodings for e1 and e2
can be seen in Fig. 2(b). We want to check the property for
all possible encodings on e1e2 (not only points e1 and e2).

To accomplish this, we propagate lists of line segments
and interval (box) constraints through the decoder and
classiﬁer, starting with the segment e1e2. At each layer, we
adaptively relax this list by combining segments into interval
constraints, in order to reduce the number of points that need
to be managed in downstream layers. This relaxation is
key, as without it, the number of tracked points could grow
exponentially with the number of layers. While (Sotoudeh
& Thakur, 2019) demonstrates that this is not a signiﬁcant
concern when propagating through classiﬁers, for generative
models or decoders, the desired output region will be highly
non-convex (with better models producing more segments).
One may think of the number of segments produced by the
model in such a case as the model’s “generative resolution”.

Robustness Certiﬁcation of Generative Models

Example of Inference with Overapproximation Consider
the simple (instructive) two dimensional input classiﬁer
network shown in Fig. 2, with inputs x1,1 and x1,2. The
possible inputs to this network we would like to consider
are the points in the region described by the blue polygonal
chain in Fig. 2(b), whose axes are x1,1 and x1,2. The chain
has coordinates (1, 2), (−1, 3), (−1, 3.5), (1, 4.5), (3.5, 2)
with (1, 2) representing nD(e1) and (3.5, 2) representing
nD(e2). The segments of the chain are annotated with
weights λ = 0.2, 0.2, 0.2, 0.4. These weights are such
that the distribution produced by picking segment j with
probability λ(j) and then picking a point uniformly on that
segment is the same as the distribution of nD(e) given
e ∼ U (e1e2) where U (S) is the uniform distribution on S.

After applying the ReLU layer to this chain (marked with
ReLU#), one can observe in Fig. 2(c) that the ﬁrst and
third segment of this chain are split in half, resulting in 6
segments, which is 50% more than there were originally. As
the segments represented uniform distributions, the weights
of the new segments is the proportional weight of that part
on the pre-ReLU segment. Here, each part of the new
segment obtains half the pre-ReLU segment’s weight.

Since a 50% increase is signiﬁcant, we now decide to
consolidate, moving from exact to approximate (still sound)
inference. Here, we use a heuristic (labeled Relax), to
choose segments to subsume that are small and close
together. As they are clearly quite close together, we pick the
ﬁrst 5 segments, replacing them by the (orange) box that has
smallest corner at (0, 2) and largest corner at (1, 4.5). This
box, introduced in Fig. 2(d), is assigned a weight equivalent
to the sum 0.6, of the weights of all removed segments.
Whereas each segment represents a uniform distribution,
this new box represents a speciﬁc but unknown distribution
with all its mass in the box. As a box is represented by two
points (maximum and minimum or center and radius), only
four points must be maintained, a signiﬁcant reduction.

The last step is to perform matrix multiplication. As this
is a linear transformation, segments can be transformed
by transforming their nodes, without adding new segments.
Box constraints can be transformed using interval arithmetic,
also without adding anything further. The weights of the
regions are preserved, as the probability of selecting each
region has not changed, only the regions themselves.

Computing probabilistic bounds Let A0(j) for j = 1 . . . k
represent the regions (either the box and segment, or all 6
segments) shown in Fig. 2(e), each with weight λ(j). We
want to ﬁnd bounds on the probability of class t = 1 being
selected by classiﬁer nA. We can immediately bound this
probability Pre∈e1e2[arg maxi nD(e)i = t] from below by
[∀x3 ∈ A0(j).x3,1 > x3,2]λ(j)

X

j

where [P ] is the indicator for predicate P . To bound it from
above, we would compute analogously

X

[∃x3 ∈ A0(j).x3,1 > x3,2]λ(j).

j

As an example, we will compute the lower bound for the
example where we used relaxations. Here, it is clear that
the entirety of the orange box lies within the region where
x3,1 > x3,2, so its indicator is evaluated to 1 and we use
its weight. On the other hand, the segment contains a
point where x3,1 = 2.75 and x3,2 = 3 which violates this
condition, so its indicator is evaluated to 0 and its weight is
not used. We can thus show a probabilistic lower bound of
0.6. Of course, because the segment represents a uniform
distribution, we could in fact provide an exact lower bound
in this case by computing the fraction of the segment that
satisﬁes the condition. We will describe this in more detail
later. We now observe that all the regions which would have
been preserved using the exact procedure (in blue) would
have contributed the same amount to the lower bound, as
they all entirely satisfy the constraint. Exact inference would
produce the same lower bound, but uses 50% more points.

3. Certiﬁcation of Deterministic Properties

We review concepts from prior work (Gehr et al., 2018) and
formally deﬁne APPROXLINE for deterministic properties.

Our goal is to automatically show that images x from a
given set X of valid inputs are mapped to desirable outputs
from a set Y. We can write this property as f [X] ⊆ Y. For
example, we can choose f as a decoder, X as a line segment
in its latent space and Y as the set of images for which a
given classiﬁer detects a desired attribute.

Such properties compose naturally: If we want to show
that h[X] ⊆ Z for h(x) = g(f (x)), it sufﬁces to ﬁnd a set
Y for which we can show f [X] ⊆ Y and g[Y] ⊆ Z. For
example, f could be a decoder and g an attribute detector,
where Z describes the set of output activations that lead to
an attribute being detected.

We assume that we can decompose the neural network f
as a sequence of l layers: f = Ll−1 ◦ · · · ◦ L0. To show a
property f [X] ⊆ Y, we ﬁnd a family of sets A0, . . . , Al such
that X ⊆ A0, Li[Ai] ⊆ Ai+1 for 0 ≤ i < l and Al ⊆ Y.
To automate this analysis, we choose A0, . . . , Al such that
they can be represented using a few real parameters. We
pick A0 based on X and Ai+1 based on Ai and Li, such that
they satisfy the properties X ⊆ A0 and Li[Ai] ⊆ Ai+1. At
the end, we check if we indeed have Al ⊆ Y. If this holds,
the veriﬁcation succeeds and we know that the property
holds. Otherwise, the procedure fails to prove the property.

Robustness Certiﬁcation of Generative Models

If we pick A0 as a bounding box of
Interval Arithmetic
X, we can compute sets Ai for 1 ≤ i ≤ l by evaluating the
layers Li using interval arithmetic. The analysis computes
a range of possible values for each activation of the neural
network, i.e., the sets Ai are boxes. At the end, we check
if the bounds of Al are strong enough to place it inside Y.
This analysis is fast but imprecise — it often fails to prove
properties that actually hold.

j=1

A(j)
i

Unions We can also represent a set Ai as a union of sets
Ski
. If we know how to propagate the individual
sets through layer Li, we can (among other possibilities)
independently propagate each set and form the union of the
results to obtain Ai+1. For example, we can cover the set
X with boxes and then propagate them through the network
independently using interval arithmetic for each box. In the
end, we have to show that all resulting boxes are within Y.

3.1. APPROXLINE for Deterministic Properties

i

i

, where each set A(j)

APPROXLINE for deterministic properties represents the sets
Ai as unions of sets A(j)
is either a box
or a line segment. Let ni denote the number of neurons in
layer i. Formally, Ai = Ski
, where for each j either
i = Qni
A(j)
l=1[al, bl] is a box with given lower bounds a and
upper bounds b, or A(j)
i = x1x2 is a segment connecting
given points x1 and x2 in Rni. To automate the analysis,
we can represent Ai as a list of bounds of boxes and a list
of pairs of endpoints of segments.

A(j)
i

j=1

Like EXACTLINE (Sotoudeh & Thakur, 2019), we focus on
the case where the set X of input activations is a segment.
EXACTLINE discusses how to split a given segment into
multiple segments that cover it, such that a given neural
network is an afﬁne function on each of the new segments.
Essentially, EXACTLINE determines the points where the
segment crosses decision boundaries of piecewise-linear
activation functions and splits it at those points. In order
to compute a set Ai+1 such that Li[Ai] ⊆ Ai+1, we ﬁrst
split all segments according to this strategy applied to only
the current layer Li. Then, we map the endpoints of the
resulting segments to the next layer by applying Li to all
of them. This is valid and captures exactly the image
of the segments under Li, because due to the splits, Li,
restricted to any one of the segments, is always an afﬁne
function. Additionally, we propagate the boxes through Li
by applying standard interval arithmetic.

Note that if we propagate a segment x1x2 using this strategy
alone for all layers, this analysis produces the exact image of
X, which is essentially equivalent to performing the analysis
using EXACTLINE exclusively.

i, such that Ai ⊆ A0

Relaxation Therefore, our analysis may, before applying
a layer Li, apply relaxation operators that turn the set Ai
into A0
i. We use two kinds of relaxation
operators: bounding box operators remove a single segment
cd. The removed segment is replaced by its bounding box
Qni
l=1[min(cl, dl), max(cl, dl)]. Merge operators replace

multiple boxes by their common bounding box.

By carefully applying the relaxation operators, we can
explore a rich tradeoff between pure EXACTLINE and pure
interval arithmetic. Our analysis generalizes both: if we
never apply relaxation operators, the analysis reduces to
EXACTLINE, and will be exact but potentially slow. If we
relax the initial segment into its bounding box, the analysis
reduces to interval arithmetic and will be imprecise but fast.

Relaxation Heuristic For our evaluation, we use the
following heuristic, applied before each convolutional layer.
The heuristic is parameterized by a relaxation percentage
p ∈ [0, 1] and a clustering parameter k ∈ N. Each chain
of connected segments with t > 1000 nodes is traversed
in order, and each segment is turned into its bounding
box, until the chain ends, the total number of different
segment endpoints visited exceeds t/k or we ﬁnd a segment
whose length is strictly above the p-th percentile, computed
over all segment lengths in the chain prior to applying the
heuristic. All bounding boxes generated in one such step
(from adjacent segments) are then merged, the next segment
(if any) is skipped, and the traversal is restarted on the
remaining segments of the chain. This way, each chain is
split into some chains and a number of new boxes.

4. Certiﬁcation of Probabilistic Properties

We now extend the analysis to the probabilistic case and
formally deﬁne APPROXLINE for probabilistic properties.

Our goal is to automatically show that images x drawn
from a given input distribution µ map to desirable outputs
D with a probability in some interval [l, u]. We can write
this property as Prx∼µ[d(x) ∈ D] ∈ [l, u]. For example,
we can choose d as a decoder, µ as the uniform distribution
on a line segment in its latent space, D as the set of images
for which a given classiﬁer detects a desired attribute and
[l, u] = [0.95, 1]. The property then states that for at least a
fraction 0.95 of the interpolated points, the given classiﬁer
detects the desired attribute.

in contrast

Note that
to the deterministic setting,
probabilistic properties of this kind do not compose
naturally. We therefore reformulate the property by deﬁning
sets X and Y of probability distributions and a distribution
transformer f ,
in analogy to deterministic properties.
Namely, we let X = {µ}, Y = {ν | Pry∼ν[y ∈ D] ∈ [l, u]}
and f = d∗, where d∗ is the pushforward of d. I.e., f maps

Robustness Certiﬁcation of Generative Models

a distribution of inputs to d to the corresponding distribution
of outputs of d. With those deﬁnitions, our property again
reads f [X] ⊆ Y and can be decomposed into properties
(Li)∗[Ai] ⊆ Ai+1 talking about each individual layer.
Therefore, we again overapproximate X with A0 such that
X ⊆ A0 and push it through each layer of the network,
computing sets A1, . . . , Al. Instead of activation vectors,
the sets Ai now contain distributions over such vectors. It
therefore remains to select a class of sets of distributions
that we can represent using a few real parameters.

Lifting Note that we can reuse any deterministic analysis
directly as a probabilistic analysis, by ignoring probabilities.
I.e., we let the set Ai be the set of all probability distributions
on a corresponding set A0
i of (deterministic) activation
vectors. The analysis then just propagates the deterministic
sets A0
i as it would in the deterministic setting. For example,
if each set A0
i is a box, Ai is the set of all distributions on
this box A0
i, and the analysis propagates the box constraints
using interval arithmetic. Of course, such an analysis is
rather limited, as it can at most prove properties with l = 0
or u = 1. For example, it would be impossible to prove that
a probability is between 0.6 and 0.8 using only this kind
of lifted analysis. However, interval arithmetic, lifted in
this fashion, is a powerful component of APPROXLINE for
probabilistic properties, detailed below.

Convex Combinations We can represent a set Ai as a
pointwise convex combination of sets of distributions A(j)
with weights λ(j)
and weights
i ≥ 0 where Pki
j=1 λ(j)
λ(j)
i = 1, the set Ai contains all
distributions of the form Pki
j=1 λ(j)
· µ(j), where each µ(j)
is some distribution chosen from the corresponding set A(j)

. Formally, for ﬁxed sets A(j)

i

i

i

i

.

i

i

i

i

i

i

is lifted from a box A0(j)

, then A(j)
For example, if A(j)
represents all distributions on the box A0(j)
. If those boxes
are disjoint, the weight λ(j)
is the probability of ﬁnding
the neural network activations in layer i within the box
A0(j)
. In general, we can intuitively think of Ai as making
i
the assertion that there exists a certain random process
producing results distributed like the activations in the i-th
layer. The process ﬁrst randomly selects one of the sets A(j)
according to the probabilities λ(j)
and then samples from a
ﬁxed distribution µ(j) that is known to be in A(j)

.

i

i

i

Similar to unions in the deterministic case, it is valid to
propagate each set A(j)
independently and to form the
convex combination of the results using the same weights
i+1 = λ(j)
λ(j)

to obtain Ai+1.

i

i

4.1. APPROXLINE for Probabilistic Properties

Probabilistic APPROXLINE represents the sets Ai as convex
combinations of sets A(j)
is either a
lifted box or contains a single distribution on a segment.

, where each set A(j)

i

i

Formally, this means
kiX




λ(j)
i

· µ(j)

Ai =



j=1

µ(1) ∈ A(1)

i

, . . . , µ(ki) ∈ A(ki)

i






,

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

i

i

i

where for each j, the set A(j)
is either the set of distributions
on a box Qni
l=1[al, bl] with given lower bounds a and upper
bounds b, or A(j)
i = {ν}, where ν is a distribution on
a segment x1x2 with given endpoints x1 and x2 in Rni.
To automate the analysis, we can represent Ai as a list of
bounds of boxes with associated weights λ(j)
, as well as
a list of segments with associated probability distributions
and weights λ(j)
. If, as in our evaluation, we consider a
restricted case, where probability distributions on segments
are uniform, it sufﬁces to associate a weight to each segment.
The weights should be non-negative and sum up to 1.
The set Ai can be propagated through layer Li to obtain
Ai+1 in a similar fashion to deterministic analysis. However,
when splitting a segment, we now also need to split the
distribution associated to it. For example, if we want to split
the segment L = cd with distribution ν and weight λ into
two segments L0 = ce and L00 = ed with L0 ∪ L00 = L, we
have to form distributions ν0, ν00 and weights λ0, λ00 where
λ0 = λ · Prx∼ν[x ∈ L0], λ00 = λ · Prx∼ν[x ∈ L00 \ L0],
ν0 is ν conditioned on the event L0 and ν00 is ν conditioned
on the event L00. For example, if distributions on segments
are uniform, this would result in the weight being split
according to the relative lengths of the two new segments.
A segment can be split into more than two segments by
applying this procedure the required number of times.
To propagate a lifted box, we apply interval arithmetic,
preserving the box’s weight. In practice, this is the same
computation used for deterministic propagation of a box.

We focus on the case where we want to propagate a
singleton set containing the uniform distribution on a
segment L = x1x2 through the neural network. In this case,
each distribution on a propagated segment will still remain
uniform, and it sufﬁces to store a segment’s weight without
an explicit representation for the corresponding distribution,
as noted above. As in the deterministic setting, if we apply
the analysis to the uniform distribution on a segment without
applying relaxation operators, the analysis will compute
an exact representation of the output distribution.
I.e.,
Al will be a singleton set containing the distribution of
outputs obtained when the neural network is applied to
inputs distributed uniformly at random on L.

Robustness Certiﬁcation of Generative Models

Relaxation As this does not scale, we again apply
relaxation operators. Similar to the deterministic setting,
we can replace a set of distributions Ai by another set of
i with Ai ⊆ A0
distributions A0
i.

Relaxation Heuristic Here, we use the same heuristic
described for the deterministic setting. When replacing a
segment by its bounding box, we preserve its weight. When
merging multiple boxes, their weights are added to give the
weight for the resulting box.

Computing Bounds Given the set Al, describing the
possible output distributions of the neural network, we want
to compute optimal bounds on the robustness probabilities
P = {Pry∼ν[y ∈ D]
| ν ∈ Al}. The part of the
distribution tracked using segments has all its probability
mass in perfectly determined locations, while the probability
mass in each box can be located anywhere inside it.

We can therefore compute bounds as

(l, u) = (min P, max P) =



e +

λ(j)
l

, e +

X

j∈L

X

j∈U



λ(j)
l

 ,

where e is the probability of ﬁnding the output on one of
the segments. If D is described as a set of linear constraints,
we can compute e by splitting the segments such that they
do not cross the constraints and summing up all weights
of resulting segments that are subsets of D. L is the set of
all indices of lifted boxes that are subsets of D, and U is
the set of all indices of lifted boxes that have a non-empty
intersection with D.

5. Evaluation

It is well known that certain generative models appear to
produce interpretable transformations between outputs for
interpolations of encodings in the latent space (Dumoulin
et al., 2016; Mathieu et al., 2016; Bowman et al., 2015;
Radford et al., 2015; Mescheder et al., 2017; Ha & Eck,
2017; Dinh et al., 2016; Larsen et al., 2015; Van den Oord
et al., 2016; Lu et al., 2018; He et al., 2019). That is,
as we move from one latent vector to another, there are
interpretable attributes of the outputs that gradually appear
or disappear. This leads to the following question: given
encodings of two outputs with a number of shared attributes,
what fraction of the line segment between the encodings
generates outputs sharing those same attributes? To answer
this question, we can verify a generator using a trusted
attribute detector, or we can verify an attribute detector
based on a trusted generator. For both tasks, we have
to analyze the outputs of neural networks restricted to
segments. We ﬁrst describe robustness terminology.
Let N : Rm → Rn be a neural network with m inputs and n

outputs which classiﬁes x ∈ Rm to class arg maxi N (x)i.
Speciﬁcation A robustness speciﬁcation is a pair (X, Y)
where X ⊆ Rm is a set of input activations and Y ⊆ Rn is
a set of permissible outputs for those inputs.
Deterministic robustness Given a speciﬁcation (X, Y), a
neural network N is said to be (X, Y)-robust if for all
x ∈ X, we have N (x) ∈ Y. In the adversarial robustness
literature, X is usually an l2- or l∞-ball, and Y is a set
In
of outputs corresponding to a speciﬁc classiﬁcation.
our case, X is a segment connecting two encodings. The
deterministic veriﬁcation problem is to prove (ideally with
100% conﬁdence) that a network is robust for a speciﬁcation.
As deciding robustness is NP-hard (Katz et al., 2017), to
enable scalability, the problem is frequently relaxed so the
veriﬁer may sometimes say the network is not robust when
it is (while still maintaining soundness: if the network is not
robust, it will certainly ﬂag it).

Probabilistic robustness Even if N is not entirely robust, it
may still be useful to quantify its lack of robustness. Given
a distribution µ over X, we are interested in ﬁnding provable
bounds on the robustness probability Prx∼µ[N (x) ∈ Y],
which we call probabilistic [robustness] bounds.

5.1. Experimental Setup

We refer to our veriﬁer as APPROXLINE (both deterministic
and probabilistic versions) where the relaxation heuristic
uses relaxation percentage p and clustering parameter k.
We implement APPROXLINE as in the DiffAI (Mirman
et al., 2018) framework, taking advantage of the GPU
parallelization provided by PyTorch (Paszke et al., 2017).
Additionally, we use our implementation of APPROXLINE
to compute exact results without approximation. To obtain
exact results, it sufﬁces to set the relaxation percentage p to
0 in which case the clustering parameter k can be ignored.
0
We write EXACT to mean veriﬁcation using APPROXLINE
k.
This should produce equivalent (up to ﬂoating point) results
EXACTLINE, but is implemented on the GPU. We run on
a machine with a GeForce GTX 1080 with 12 GB of GPU
memory, and four processors with a total of 64 GB of RAM.

5.2. Generative speciﬁcations

For generative speciﬁcations, we use autoencoders with
either 32 or 64 latent dimensions trained in two different
ways: VAE and CycleAE, described below. We train them to
reconstruct CelebA with image sizes 64×64. We always use
Adam (Kingma & Ba, 2014) with a learning rate of 0.0001
and a batch size of 100. The speciﬁc network architectures
are described in Appendix B. For CelebA, the decoder has
74128 neurons and the attribute detector has 24676.

VAEl is a variational autoencoder (Kingma & Welling,
2013) with l latent dimensions.

Seconds Per Speciﬁcation
60s

54.4

50s

40s

30s

20s

10s

0s

0.01

Robustness Certiﬁcation of Generative Models

Probabilistic Bound Width

36.53

26.06

1

0.89

0.8

1

0.8

0.6

0.4

0.2

0

1.85 · 10−3

HZono

Sampling

EXACT APPROXLINE

HZono

Sampling

EXACT APPROXLINE

(a)

(b)

Figure 3. A comparison of different methods that compute probabilistic bounds for ˆC. APPROXLINE uses p = .02 and k = 100.

CycleAEl is a repurposed CycleGAN (Zhu et al., 2017).
While originally designed for style transfer between
distributions P and Q, we use it as an autoencoder where
the generator behaves like a GAN such that encodings
are ideally distributed well in the latent space. For the
latent space distribution P we use a normal distribution
in l dimensions with a feed forward network DP as its
discriminator. The distribution Q is the ground truth
data distribution. For its discriminator DQ we use the
BEGAN method (Berthelot et al., 2017), which determines
an example’s realism based on an autoencoder with l latent
dimensions, trained to reproduce Q and adaptively to fail to
reproduce the GAN generator’s distribution.

Attribute Detector is trained to recognize the 40 attributes
provided by CelebA. The attribute detector has a linear
output. The attribute i is detected in the image if the
i-th component of the attribute detector’s output is strictly
positive. It is trained using Adam for 300 epochs.

5.3. Speed and precision results

Given a generative model capable of producing data
manifold interpolations between inputs, there are many
different veriﬁcation goals one might pursue. For example,
we can check whether the generative model is correct with
respect to a trusted classiﬁer or whether a classiﬁer is
robust to interpretable interpolations produced by a trusted
generator. Even trusting neither generator nor classiﬁer, we
might wish to verify their mutual consistency.

We address all of these goals by efﬁciently computing the
attribute consistency of a generative model with respect to
an attribute detector: for a point picked uniformly between
the encodings e1 and e2 of ground truth inputs both with or
without matching attributes i, we would like to determine
the probability that its decoding will have (or not) the same
attribute. We deﬁne attribute consistency as

Ci,nA,nD (e1, e2) =

Pr
e∼U (e1e2)

[sign nA(nD(e))i = t],

where t = sign nA(nD(e1))i. We will frequently omit the
attribute detector nA and the decoder nD from C if it is clear
from context which networks are being evaluated.

Here, we demonstrate that probabilistic APPROXLINE is
precise and efﬁcient enough to provide useful bounds
on attribute consistency for interesting generators and
speciﬁcations. Speciﬁcally, we compare APPROXLINE to a
variety of other methods for providing probabilistic bounds.
We do this ﬁrst for CycleAE32 trained for 200 epochs.

Suppose P is a set of unordered pairs {a, b} from the data
with sign aA,i = sign bA,i for every attribute, where aA,i
is label of attribute i for a. Using each method, we ﬁnd
bounds on the true value of average attribute consistency
as ˆCP = meana,b∈P,iCi,nA,nD (nE(a), nE(b)) where nE is
the encoding network. Each method ﬁnds a probabilistic
bound, [l, u], such that l ≤ ˆC ≤ u. We call u − l its width.

We compare probabilistic APPROXLINE against two other
probabilistic analyses: EXACT (APPROXLINE with p = 0),
and HZono (Mirman et al., 2018) lifted probabilistically. We
also compare against probabilistic sampling with binomial
conﬁdence intervals on C.

For probabilistic sampling, we take samples and recalculate
the Clopper-Pearson interval with a conﬁdence of 99.99%
until the interval width is below .002 (chosen to be the same
as our best result with APPROXLINE). To avoid incorrect
calculation, we discard this result, and resample using the
estimated number of samples. Notably, the probabilistic
bound returned by the analyses is guaranteed to be correct
100% of the time, while for sampling it is only guaranteed
to be correct 99.99% of the time.

For all methods, we report a bound of [0, 1]
in the
case of either out-of-memory error, or 60s timeout. For
APPROXLINE, if an out-of-memory error occurs, we reﬁne
the hyperparameters using schedule A in Appendix D and
restart (without resetting the timeout clock). Fig. 3 shows
the results of running these on |P | = 100 pairs of matching

Seconds Per Speciﬁcation

Probabilistic Bound Width

Robustness Certiﬁcation of Generative Models

6.12

2.97

7s

6s

5s

4s

3s

2s

1s

0s

0.36

0.36

1

1

1

0.8

0.6

0.4

0.2

0

0.14

0

Zono

DeepZono

EXACT APPROXLINE

Zono

DeepZono

EXACT APPROXLINE

(a)

(b)

Figure 4. A comparison of speed and accuracy of domains for computing ˆC on MNIST. APPROXLINE uses p = .95 and k = 25.

(a).

(b).

(c).

Figure 5. Examples of interpolated images, with originals at the 1st and 11th positions. Their immediate neighbors are their reconstructions.
(a) is between the same person with the same attributes using CycleAE32 after 200 epochs. (b) is between horizontally ﬂipped images
using CycleAE64 after 20 epochs. (c) is between an image and the addition of the “mustache” feature vector using CycleAE32 again.

celebrities with matching attribute labels, chosen uniformly
at random from CelebA (each method uses the same P ).

While HZono is the fastest method, it is unable to prove any
speciﬁcations. Sampling and EXACT appear to be similar in
speed to APPROXLINE, but the widths of the probabilistic
bounds they produce is much larger. This is because
Sampling frequently times out, and EXACT frequently
exhausts GPU memory. On the other hand, APPROXLINE
provides an average probabilistic bound width of less than
0.002 in under 30s with perfect conﬁdence (compared with
the lower conﬁdence provided by sampling).

Comparing to Precise Convex Abstract Domains Here
we compare to two precise convex relaxation methods:
Zonotope (Gehr et al., 2018) and DeepZono (Singh et al.,
2018). At the expense of memory and speed, these domains
are able to verify more properties. Due to increased
memory requirements, we were unable to use them on
the GPU for the CelebA networks described.
In order
to demonstrate their inadequacy for line speciﬁcations in
generative networks, we adapted the same networks for
MNIST (LeCun et al., 1998) such that it could still be
analyzed on the GPU with the DiffAI implementation of

Zonotope and DeepZono (from Singh et al. (2018)). We
trained a VAE50 for 10 epochs with a learning rate of 0.001
with the networks described in Appendix C. The decoder has
74128 neurons and the attribute detector has 23820 neurons.
Here, the attribute detector works similarly, but attribute i is
considered present for images of the digit i.

We analyzed 100 pairs with Zonotope, DeepZono, and
ApproxLine with p = 0.95 and k = 25, and EXACT. No
timeouts occurred. The results are shown in Fig. 4. Despite
their speed, the precision of Zonotope and DeepZono is not
enough to prove anything. While EXACT is able to perfectly
prove since it no longer runs out of GPU memory, it takes
more than twice as long as APPROXLINE.

5.4. Use cases for APPROXLINE

We now demonstrate how to check the attribute consistency
of a model against an attribute detector. We do this for two
possible generative speciﬁcations: (i) generating rotated
heads using ﬂipped images, and (ii) adding previously
absent attributes to faces. For the results in this section,
we use schedule B described in Appendix D.

Robustness Certiﬁcation of Generative Models

Figure 6. Comparing the different generative models using
probabilistic APPROXLINE with p = 0.02 and k = 200 to
provide lower bounds for meaniCi(nE(a), nE(Flipped(a))),
where a and Flipped(a) are the images shown in Fig. 5b.
The width of the largest probabilistic bound was smaller than
3 × 10−6, so only the lower bounds are shown. Fewer than
50 seconds were necessary to compute each bound, and the
fastest computation was for CycleAE64 at 30 seconds.

Comparing models with turning heads
It is known
that VAEs are capable of generating images with
intermediate poses from ﬂipped images. An example
of this transformation is shown in Fig. 5b. Here, we
show an example of using APPROXLINE to compare the
effectiveness of different autoencoding models for this task.
We trained the 4 models described above for 20 epochs, and
created a speciﬁcation between encodings of the ﬂipped
images shown in Fig. 5b. For a head that is turned in
one direction, ideally the different reconstructions will
correspond to images of different orientations of the head
in 3D space. As none of the CelebA attributes correspond
to pose, the attribute detector should recognize the same set
of attributes for all interpolations. We used deterministic
APPROXLINE with p = 0.02 and k = 200 to demonstrate
which attributes provably remain correct for every possible
interpolation (as visualized in Appendix F). While we are
able to show in the worst case, 32 out of 40 attributes are
entirely robust to ﬂipping, some attributes are not robust
across interpolation. Fig. 6 demonstrates the results of using
probabilistic APPROXLINE to ﬁnd the average lower bound
on the fraction of the input interpolation encodings which do
result in the correct attribute appearing in the output image.

attribute

independence We

Verifying
now use
APPROXLINE() to demonstrate that attribute detection
for one feature is invariant to a transformation of an
independent feature. Speciﬁcally, we verify for a single
image the effect of adding a mustache. This transformation
is shown in Fig. 5c. To do this, we ﬁnd the attribute
vector m for “mustache” (i = 22 in CelebA) using
the 80k training-set images in the manner described by
(Larsen et al., 2015), and compute probabilistic bounds for
Cj(nE(o), nE(o) + 2m, oA,j) for j 6= 22 and the image o.
Using APPROXLINE we are able to prove that 30 out of the
40 attributes are entirely robust through the addition of a
mustache. Among the attributes which can be proven to be
robust are i = 4 for “bald” and i = 39 for “young”. We
are able to ﬁnd that attribute i = 24 for “NoBeard” is not
entirely robust to the addition of the mustache vector. We
ﬁnd a lower bound on the robustness probability of 0.83522
and an upper bound of 0.83528.

Lower Bound on Correctness

1

0.95

0.9

0.85

0.8

0.75

0.82

0.83

0.85

0.9

VAE32

VAE64

CycleAE32

CycleAE64

6. Conclusion

We presented a scalable non-convex relaxation to verify
neural network properties restricted to line segments.
Our method supports both deterministic and probabilistic
certiﬁcation and is able to verify, for the ﬁrst
time,
interesting visual transformation properties based on latent
space interpolation, beyond the reach of prior work.

References

Balunovic, M., Baader, M., Singh, G., Gehr, T., and Vechev,
M. Certifying geometric robustness of neural networks.
In Advances in Neural Information Processing Systems
32. 2019.

Berthelot, D., Schumm, T., and Metz, L. Began: Boundary
arXiv

equilibrium generative adversarial networks.
preprint arXiv:1703.10717, 2017.

Bowman, S. R., Vilnis, L., Vinyals, O., Dai, A. M.,
Jozefowicz, R., and Bengio, S. Generating sentences from
a continuous space. arXiv preprint arXiv:1511.06349,
2015.

Cao, X. and Gong, N. Z. Mitigating evasion attacks to
deep neural networks via region-based classiﬁcation.
In Proceedings of the 33rd Annual Computer Security
Applications Conference, pp. 278–287. ACM, 2017.

Cohen, J. M., Rosenfeld, E., and Kolter, J. Z. Certiﬁed
adversarial robustness via randomized smoothing. arXiv
preprint arXiv:1902.02918, 2019.

Cousot, P. and Monerau, M.

In Seidl, H.

interpretation.
Languages and Systems,
Heidelberg, 2012. Springer Berlin Heidelberg.
978-3-642-28869-2.

Probabilistic abstract
(ed.), Programming
pp. 169–193, Berlin,
ISBN

Dinh, L., Sohl-Dickstein, J., and Bengio, S. Density
preprint

arXiv

nvp.

estimation
real
arXiv:1605.08803, 2016.

using

Robustness Certiﬁcation of Generative Models

Dumoulin, V. and Visin, F. A guide to convolution
arXiv preprint

arithmetic for deep learning.
arXiv:1603.07285, 2016.

LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P.
Gradient-based learning applied to document recognition.
Proceedings of the IEEE, 1998.

Dumoulin, V., Belghazi, I., Poole, B., Mastropietro, O.,
Lamb, A., Arjovsky, M., and Courville, A. Adversarially
learned inference. arXiv preprint arXiv:1606.00704,
2016.

Lecuyer, M., Atlidakis, V., Geambasu, R., Hsu, D., and
Jana, S. Certiﬁed robustness to adversarial examples with
differential privacy. arXiv preprint arXiv:1802.03471,
2018.

Dvijotham, K., Garnelo, M., Fawzi, A., and Kohli, P.
Veriﬁcation of deep probabilistic models. arXiv preprint
arXiv:1812.02795, 2018a.

Dvijotham, K., Gowal, S., Stanforth, R., Arandjelovic, R.,
O’Donoghue, B., Uesato, J., and Kohli, P. Training
veriﬁed learners with learned veriﬁers. arXiv preprint
arXiv:1805.10265, 2018b.

Dvijotham, K., Stanforth, R., Gowal, S., Mann, T. A., and
Kohli, P. A dual approach to scalable veriﬁcation of deep
networks. In UAI, pp. 550–559, 2018c.

Gehr, T., Mirman, M., Tsankov, P., Drachsler Cohen,
D., Vechev, M., and Chaudhuri, S. Ai2: Safety and
robustness certiﬁcation of neural networks with abstract
interpretation. In Symposium on Security and Privacy
(SP), 2018.

Gowal, S., Dvijotham, K., Stanforth, R., Bunel, R., Qin, C.,
Uesato, J., Mann, T., and Kohli, P. On the effectiveness of
interval bound propagation for training veriﬁably robust
models. arXiv preprint arXiv:1810.12715, 2018.

Ha, D. and Eck, D. A neural representation of sketch

drawings. arXiv preprint arXiv:1704.03477, 2017.

He, Z., Zuo, W., Kan, M., Shan, S., and Chen, X. Attgan:
Facial attribute editing by only changing what you want.
IEEE Transactions on Image Processing, 2019.

Julian, K. D., Kochenderfer, M. J., and Owen, M. P.
Deep neural network compression for aircraft collision
avoidance systems. Journal of Guidance, Control, and
Dynamics, 42(3):598–608, 2018.

Katz, G., Barrett, C., Dill, D. L., Julian, K., and
Kochenderfer, M. J. Reluplex: An efﬁcient smt solver
In International
for verifying deep neural networks.
Conference on Computer Aided Veriﬁcation, 2017.

Kingma, D. P. and Ba, J. Adam: A method for stochastic
optimization. arXiv preprint arXiv:1412.6980, 2014.

Kingma, D. P. and Welling, M. Auto-encoding variational

bayes. arXiv preprint arXiv:1312.6114, 2013.

Li, B., Chen, C., Wang, W., and Carin, L. Second-order
arXiv

adversarial attack and certiﬁable robustness.
preprint arXiv:1809.03113, 2018.

Liu, C., Tomioka, R., and Cevher, V. On certifying
non-uniform bound against adversarial attacks. arXiv
preprint arXiv:1903.06603, 2019.

Liu, X., Cheng, M., Zhang, H., and Hsieh, C.-J. Towards
In
robust neural networks via random self-ensemble.
Proceedings of the European Conference on Computer
Vision (ECCV), pp. 369–385, 2018.

Lu, Y., Tai, Y.-W., and Tang, C.-K. Attribute-guided face
generation using conditional cyclegan. In Proceedings of
the European Conference on Computer Vision (ECCV),
pp. 282–297, 2018.

Mathieu, M. F., Zhao, J. J., Zhao, J., Ramesh, A.,
Sprechmann, P., and LeCun, Y. Disentangling factors of
variation in deep representation using adversarial training.
In Advances in Neural Information Processing Systems,
pp. 5040–5048, 2016.

Mescheder, L., Nowozin, S., and Geiger, A. Adversarial
variational bayes: Unifying variational autoencoders
In Proceedings
and generative adversarial networks.
of
the 34th International Conference on Machine
Learning-Volume 70, pp. 2391–2400. JMLR. org, 2017.

Mirman, M., Gehr, T., and Vechev, M. Differentiable
interpretation for provably robust neural
In International Conference on Machine

abstract
networks.
Learning (ICML), 2018.

Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E.,
DeVito, Z., Lin, Z., Desmaison, A., Antiga, L., and Lerer,
A. Automatic differentiation in pytorch. 2017.

Radford, A., Metz, L., and Chintala, S. Unsupervised
convolutional
arXiv preprint

representation learning with deep
generative adversarial networks.
arXiv:1511.06434, 2015.

Larsen, A. B. L., Sønderby, S. K., Larochelle, H., and
Winther, O. Autoencoding beyond pixels using a learned
similarity metric. arXiv preprint arXiv:1512.09300, 2015.

Raghunathan, A., Steinhardt, J., and Liang, P. Certiﬁed
defenses against adversarial examples. arXiv preprint
arXiv:1801.09344, 2018.

Robustness Certiﬁcation of Generative Models

Salman, H., Yang, G., Zhang, H., Hsieh, C.-J., and Zhang, P.
A convex relaxation barrier to tight robust veriﬁcation of
neural networks. arXiv preprint arXiv:1902.08722, 2019.

Singh, G., Gehr, T., Mirman, M., P¨uschel, M., and Vechev,
In
Fast and effective robustness certiﬁcation.
M.
Advances in Neural Information Processing Systems, pp.
10825–10836, 2018.

Singh, G., Gehr, T., P¨uschel, M., and Vechev, M. An abstract
domain for certifying neural networks. Proceedings of the
ACM on Programming Languages, 3(POPL):41, 2019.

Sotoudeh, M. and Thakur, A. V. Computing linear
arXiv preprint

restrictions of neural networks.
arXiv:1908.06214, 2019.

Sundararajan, M., Taly, A., and Yan, Q. Axiomatic
attribution for deep networks. In Proceedings of the 34th
International Conference on Machine Learning-Volume
70, pp. 3319–3328. JMLR. org, 2017.

Tjeng, V., Xiao, K., and Tedrake, R. Evaluating robustness
of neural networks with mixed integer programming.
arXiv preprint arXiv:1711.07356, 2017.

Van den Oord, A., Kalchbrenner, N., Espeholt, L., Vinyals,
O., Graves, A., et al. Conditional image generation with
pixelcnn decoders. In Advances in neural information
processing systems, pp. 4790–4798, 2016.

Wang, S., Pei, K., Whitehouse, J., Yang, J., and Jana, S.
Efﬁcient formal safety analysis of neural networks. In
Advances in Neural Information Processing Systems, pp.
6367–6377, 2018.

Weng, T.-W., Chen, P.-Y., Nguyen, L. M., Squillante,
M. S., Oseledets, I., and Daniel, L. Proven: Certifying
robustness of neural networks with a probabilistic
approach. arXiv preprint arXiv:1812.08329, 2018.

Wong, E., Schmidt, F., Metzen, J. H., and Kolter, J. Z.
Scaling provable adversarial defenses. arXiv preprint
arXiv:1805.12514, 2018.

Zhu, J.-Y., Park, T., Isola, P., and Efros, A. A. Unpaired
translation using cycle-consistent
image-to-image
In Proceedings of the IEEE
adversarial networks.
international conference on computer vision, pp.
2223–2232, 2017.

Robustness Certiﬁcation of Generative Models

A. APPROXLINE Propogation Pseudocode

Algorithm 1. Pseudocode for inference with APPROXLINE

Input: k network layers with weights and biases Mi, Bi,
and a line segment a, b in the input space.
Output: D a list of boxes and line segments describing
possible regions of the output space with associated
probabilities.
D = [(Segment, 1, a, b)].
for l = 1 to k − 1 do

˜D = []
for i = 1 to |D| do

if Di == Segment then
a = Di,3Ml + Bl
b = Di,4Ml + Bl
T = [0, 1]
for d = 1 to |bl| do

if ad < 0 ∧ Bd ≥ 0 then

T.push( −ad

|(a−b)d| )
else if ad ≥ 0 ∧ Bd < 0 then

T.push(1 − −bd

|(a−b)d| )

end if
end for
T .sort()
for t = 1 to |T | do
p = Tt − Tt−1
˜a = (b − a) ∗ Tt−1 + a
˜b = (b − a) ∗ Tt + a
˜D.push((Segment, Di,2 ∗ p, ˜a, ˜b))

end for

else

c = Di,3Ml + bl
r = Di,4|Ml|p
˜c = ReLU (c + r) + ReLU (c − r)
˜r = ReLU (c + r) − ReLU (c − r)
˜D.push((Box, Di,2, 0.5 ∗ ˜c, 0.5 ∗ ˜r))

end if
end for
˜P =Relax( ˜D)
for i = 1 to | ˜D| do

for p = 1 to | ˜P | do

if γ( ˜Di) ⊆ γ( ˜Pp) then
˜Pp,2 = ˜Pp,2 + ˜Di,2
delete Di
break

end if
end for

end for
D = ˜D + ˜P

end for
return D

B. Network Architectures

has 14512 neurons:

Robustness Certiﬁcation of Generative Models

→ ReLU
l → FC 400
→ FC 1568
→ ReLU
→ ConvT2,116 × 3 × 3 → ReLU
→ ConvT1,03 × 3 × 3
→ x.

• Attribute Detector is a convolutional network which

has 4804 neurons:

x → Conv216 × 4 × 4 → ReLU
→ Conv232 × 4 × 4 → ReLU
→ FC 100
→ 10.

D. APPROXLINE Reﬁnement Schedule

While many reﬁnement schemes start with an imprecise
approximation and progressively tighten it, we observe
that being only occasionally memory limited and rarely
time limited, it conserves more time to start with the
most precise approximation we have determined usually
works, and progressively try less precise approximations
as we determine that more precise ones can not ﬁt into
GPU memory. Thus, we start searching for a probabilistic
p
robustness bound with APPROXLINE
N and if we run out of
min(1.5p,1)
max(0.95N,5) for schedule A, and
memory, try APPROXLINE
min(3p,1)
max(0.95N,5) for schedule B. This procedure is

APPROXLINE
repeated until a solution is found, or time has run out.

E. Effect of Approximation Parameters on

Speed and Precision

Here we demonstrate how modifying the approximation
p
parameters, p and N of APPROXLINE
N effect its speed and
precision. Fig. 7 shows the result of varying these on x-axis.
The bottom number, N is the number of clusters that will
be ideally made, and the top number p is the percentage of
nodes which are permitted to be clustered.

F. Comparing the Deterministic Binary

Robustness of Different Models

Fig. 8 uses deterministic APPROXLINE0.02
200 to demonstrate
which attributes provably remain the same and are correct
(in blue) for every possible interpolation.

For both models, we use the same encoders and decoders
(even in the autoencoder descriminator from BEGAN),
and always use the same attribute detectors. Here we use
ConvsC×W ×H to denote a convolution which produces C
channels, with a kernel width of W pixels and height of H,
with a stride of s and padding of 1. FC n is a fully connected
layer which outputs n neurons. ConvTs,pC × W × H is a
transposed convolutional layer (Dumoulin & Visin, 2016)
with a kernel width and height of W and H respectively and
a stride of s and padding of 1 and out-padding of p, which
produces C output channels.

• Latent Descriminator is a fully connected feed forward
network with 5 hidden layers each of 100 dimensions.

• Encoder is a standard convolutional neural network:

x → Conv132 × 3 × 3 → ReLU
→ Conv232 × 4 × 4 → ReLU
→ Conv164 × 3 × 3 → ReLU
→ Conv264 × 4 × 4 → ReLU
→ ReLU
→ FC 512
→ FC 512
→ l.

• Decoder is a transposed convolutional network which

has 74128 neurons:

→ ReLU
l → FC 400
→ FC 2048
→ ReLU
→ ConvT2,116 × 3 × 3 → ReLU
→ ConvT1,03 × 3 × 3
→ x.

• Attribute Detector is a convolutional network which

has 24676 neurons:

x → Conv216 × 4 × 4 → ReLU
→ Conv232 × 4 × 4 → ReLU
→ FC 100
→ 40.

C. MNIST Network Architectures

Here we list the architectures for MNIST models.

• Encoder is a standard convolutional neural network:

x → Conv132 × 3 × 3 → ReLU
→ Conv232 × 4 × 4 → ReLU
→ Conv164 × 3 × 3 → ReLU
→ Conv264 × 4 × 4 → ReLU
→ FC 512
→ ReLU
→ FC 512
→ l.

• Decoder is a transposed convolutional network which

Robustness Certiﬁcation of Generative Models

Prob Bound Width

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

Time
30s

27s

24s

21s

18s

15s

12s

9s

6s

3s

0s

.02
100

.02
75

.02
50

.3467
100

.3467
75

.3467
50

.6733
100

.6733
75

.6733
50

1
100

1
75

1
50

.02
100

.02
75

.02
50

.3467
100

.3467
75

.3467
50

.6733
100

.6733
75

.6733
50

1
100

1
75

1
50

(a)

(b)

Figure 7. A comparison of speed (a) and Probabilistic Bound Widths (b) of APPROXLINE for different approximation hyperparameters,
on CycleAE64 trained for 200 epochs.

Figure 8. Blue means that the interpolative speciﬁcation visualized in Fig. 5b has been deterministically and entirely veriﬁed for the
0.02
200 . Red means that the attribute can not be veriﬁed. In all cases, this is because the speciﬁcation
attribute (horizontal) using APPROXLINE
was not robust for the attribute. One can observe that the most successful autoencoder is CycleAE64.

VAE32
CycleAE32
VAE64
CycleAE64

