Identiﬁcation of Twitter Bots Based on an Explainable Machine Learning
Framework: The US 2020 Elections Case Study

Alexander Shevtsov,1,3 Christos Tzagkarakis, 1 Despoina Antonakaki, 1 Sotiris Ioannidis, 2, 1
1 Institute of Computer Science, Foundation for Research and Technology
2 Technical University of Crete
3 Computer Science Department - University of Crete
{shevtsov,tzagarak,despoina}@ics.forth.gr, sotiris@ece.tuc.gr

1
2
0
2
c
e
D
4
1

]
I
S
.
s
c
[

2
v
3
1
9
4
0
.
2
1
1
2
:
v
i
X
r
a

Abstract

Twitter is one of the most popular social networks attract-
ing millions of users, while a considerable proportion of on-
line discourse is captured. It provides a simple usage frame-
work with short messages and an efﬁcient application pro-
gramming interface (API) enabling the research commu-
nity to study and analyze several aspects of this social net-
work. However, the Twitter usage simplicity can lead to ma-
licious handling by various bots. The malicious handling
phenomenon expands in online discourse, especially dur-
ing the electoral periods, where except the legitimate bots
used for dissemination and communication purposes, the goal
is to manipulate the public opinion and the electorate to-
wards a certain direction, speciﬁc ideology, or political party.
This paper focuses on the design of a novel system for
identifying Twitter bots based on labeled Twitter data. To
this end, a supervised machine learning (ML) framework is
adopted using an Extreme Gradient Boosting (XGBoost) al-
gorithm, where the hyper-parameters are tuned via cross-
validation. Our study also deploys Shapley Additive Expla-
nations (SHAP) for explaining the ML model predictions
by calculating feature importance, using the game theoretic-
based Shapley values. Experimental evaluation on distinct
Twitter datasets demonstrate the superiority of our approach,
in terms of bot detection accuracy, when compared against a
recent state-of-the-art Twitter bot detection method.

Introduction

is considered one of

Twitter
the most popular and
widespread online social networks (OSNs) nowadays. It
is used by millions of users and organizations to quickly
share and discover information about a service, product,
sports/social/political event etc. However, Twitter can be
used as an intermediate system for malicious purposes, such
as spreading fake news (Bovet and Makse 2019; Sharma
et al. 2019) or manipulating public opinion (Badawy, Fer-
rara, and Lerman 2018).

Speciﬁcally, Twitter can be used to circulate propa-
ganda (Neudert, Kollanyi, and Howard 2017; Jones 2019;
Chatﬁeld, Reddick, and Brajawidagda 2015), manipulate the
public opinion (Bolsover and Howard 2019; Seo 2014), and
inﬂuence the electorate towards a particular ideology or po-
litical party (Golovchenko et al. 2020; Howard, Kollanyi,

Copyright © 2021, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

and Woolley 2016). These tasks can be fully automated
through a special organized group of agents, called botnets,
which are groups of sybil accounts that collectively seek to
inﬂuence ordinary users. In particular, a botnet is a group
of bots, i.e., automated programs programmed to run certain
tasks. A sybil account in OSNs is a fake identity, not neces-
sarily representing a real person or created by the real person
it represents (impersonation technique) (Alsaleh et al. 2014).
It has been observed that Twitter bots can also be ex-
ploited to spread fake news, rumors and hate speech (Founta
et al. 2018; Fortuna and Nunes 2018; Burnap and Williams
2015) by instantly republishing low credibility Twitter con-
tent (Shao et al. 2018) via popular users and Twitter men-
tions (Stella, Ferrara, and De Domenico 2018).

In this work, we aim to build a machine learning (ML)
framework over a large collected dataset, to detect bot Twit-
ter accounts. We identify and analyze Twitter bots during
the US 2020 Elections period. The current study provides
answers to the following questions:

• Is it possible to implement and ﬁne-tune a ML-based bot
detection model to efﬁciently apply it to the US 2020
Elections dataset?

• Which types of features can be extracted from the Twitter
application programming interface (API) to promote high
performance?

• Is it possible to examine the ML model’s generalization
capability in terms of bot detection accuracy across sev-
eral well-established datasets?

• Does the proposed ML model act as a black box or could
the ML model’s mechanism be “unlocked” in order to in-
vestigate how it yields its predictions?

Our analysis can help the research community to better un-
derstand the bot detection task and how it can be performed
in different types of datasets, or within diverse domains. The
presented methodology achieves a high bot detection accu-
racy on the US 2020 Elections dataset, while attaining in-
creased generalization performance in terms of bot identiﬁ-
cation when applied on additional, well-established Twitter
datasets. The ML model’s outcome is also explained based
on Shapley Additive Explanations (SHAP) method.

The rest of the paper is organized as follows: Background
explores related past works. A detailed description of the

 
 
 
 
 
 
data collection process and the proposed methodology is
given in Methodology. Experimental Results evaluates the
performance of our method, whilst Conclusions and Future
Work summarizes the main outcomes and provides direc-
tions for future work.

Background
Twitter (social) bots can be used for malicious purposes
spanning from junk news and fake news or rumor spread-
ing (Sharma et al. 2019), to propaganda and astroturﬁng
(Bovet and Makse 2019; Howard et al. 2017a; Neudert, Kol-
lanyi, and Howard 2017; Howard et al. 2017b). Speciﬁcally,
an application is developed in (Hui et al. 2020) to track in-
formation spreading on Twitter and tweets and accounts as-
sociated with suspicious campaigns.

Usually, a legitimate bots’ usage is adopted, to perform
automated communication or administration during the elec-
toral periods (Howard, Woolley, and Calo 2018). How-
ever, Twitter bots have been extensively used for opin-
ion hijacking during the Russian elections (Krebs 2011;
Shane 2017; Lightfoot and Jacobs 2017; Illing 2018), the
2017 French presidential election (Ferrara 2017), the US
elections (Howard, Woolley, and Calo 2018; Byrnes 2016;
Rizoiu et al. 2018),
the Catalan independence referen-
dum (Stella, Ferrara, and De Domenico 2018), as well as in
the Australian (Waugh et al. 2013), the Ukrainian (Hegelich
and Janetzko 2016) and the Brazilian electoral process (Ar-
naudo 2017). In (Luceri et al. 2019), the authors study
245,000 accounts on Twitter during the US 2016 presiden-
tial election and 2018 midterm elections, and they detect
approximately 31,000 bots. Forty-three million elections-
related tweets of ongoing U.S. Congress investigation of
Russian interference in the 2016 U.S. election campaigns are
examined in (Badawy, Ferrara, and Lerman 2018), where it
is estimated that 4.9% and 6.2% of liberal and conservative
users, respectively, were bots, with reported precision and
recall scores above 90%. In (Keller and Klinger 2019), the
authors provide an analysis of the German parties’ posts on
Twitter from before and during the 2017 electoral period,
and they reveal an increased amount of social bots (7.1% to
9.9%). Other studies focusing on Twitter bots analysis in-
clude (Stukal et al. 2017) studying a speciﬁc consequen-
tial period in Russian politics (February 2014 to Decem-
ber 2015) and apply sentiment analysis or attempt to predict
the results of the elections (Ibrahim et al. 2015; Antonakaki
et al. 2017).

The authors in (Garimella and Weber 2017) investigate
the political polarization on Twitter between 2009 and 2016,
with an increased polarization of 10% and 20% being re-
ported. The impact of Twitter bots during the ﬁrst U.S. pres-
idential debate of 2016 is studied in (Rizoiu et al. 2018),
where a novel algorithm for estimating user inﬂuence from
retweet cascades is introduced towards analyzing the role
and user inﬂuence of bots versus humans. Moreover, a
Twitter data analysis has been conducted in (Fraisier et al.
2018) related to the 2017 French presidential campaign.
The authors built a large and complex dataset of 22,853
active Twitter proﬁles during the campaign from Novem-
ber 2016 to May 2017. Analysis of political discourse on

Twitter in elections dataset has been noted during the US
2016 presidential elections (Yaqub et al. 2017). Opinion hi-
jacking has been observed not only in politics, but also in
anti-vaccination promotion movements (Broniatowski et al.
2018). Thus, it is important to quantify the spread of fake
news on Twitter (Waugh et al. 2013) and the inherent vari-
ability (Vosoughi, Roy, and Aral 2018), in order to distin-
guish bots from human agents and legitimate users (Edwards
et al. 2014).

It is evident that Twitter bot detection is a complex task,
often requiring rigorous and solid treatment. Several ML-
based solutions have been proposed. In particular, a real-
time detection system dubbed as BotOrNot using a total
amount of 1200 different features in combination with a
Random Forest classiﬁer is introduced in (Davis et al. 2016).
An updated version of this system is described in (Yang et al.
2019) named as Botometer, which requires Twitter API keys
to collect user information during the real-time computa-
tions, thus it is not efﬁcient to use real-time labeling tools
in the case of big datasets. BotSentinel (Sentinel 2021 (ac-
cessed April 19, 2021) on the other hand, is a non-real-time
labeling tool, capable of processing large amounts of user
accounts and storing the results in a database. BotSentinel’s
ofﬂine labeling methodology is adopted whenever a user ac-
count is being suspended or removed, whereas real-time la-
beling does not provide any suspended account information.
Moreover, the ofﬂine implementation allows us to increase
the query rate limits, since it involves no labeling computa-
tional costs.

Since a fundamental part of the bot detection pipeline
corresponds to the computation of features based on Twit-
ter data, a plethora of different types of features have been
proposed. Various features are based on content (Ahmed
and Abulaish 2013; Gilani, Kochmar, and Crowcroft 2017;
Lee, Caverlee, and Webb 2010; Davis et al. 2016; Varol
et al. 2017), sentiment (Loyola-Gonz´alez et al. 2019; Dick-
erson, Kagan, and Subrahmanian 2014; Ferrara et al. 2016;
Loyola-Gonz´alez et al. 2019), account information (Wald
et al. 2013; Chu et al. 2012; Davis et al. 2016; Lee, Caverlee,
and Webb 2010; Loyola-Gonz´alez et al. 2019), usage (Chu
et al. 2012) and network characteristics (Feng et al. 2020;
Keller et al. 2017; Cresci et al. 2017).

There is a growing number of ML and data (statisti-
cal) analysis-based Twitter bot identiﬁcation tools. The most
popular can be considered the Stweeler tool (Gilani et al.
2016), the Debot system (Chavoshi, Hamooni, and Mueen
2016), which takes into account synchronous bots spreading
content, the TSD Sybil Detector (Alsaleh et al. 2014) that
adopts a ML approach using 17 Twitter data-based features
and the Retweet-Buster (RTbust) (Mazza et al. 2019) which
is an unsupervised learning tool combining feature extrac-
tion and clustering techniques. Moreover, sentiment analysis
has been incorporated into the bot detection pipeline (Dick-
erson, Kagan, and Subrahmanian 2014; Loyola-Gonz´alez
et al. 2019). A set of sentiment features is also exploited
by the BotOrNot tool in (Varol et al. 2017). The promis-
ing direction of ML-based Twitter bot detection can be
reﬂected in DARPA competition, where six different re-
search groups competed in performing bot identiﬁcation, us-

Hashtag

#VOTE
#Trump202
#Vote
#Election2020
#vote
#Biden
#Debate2020
#BidenHarris2020
#VoteBlueToSaveAmerica
#Trump

Tweet Counts
3,064,099
2,403,586
2,200,954
1,906,959
1,838,645
1,063,265
839,717
781,697
746,896
601,516

Table 1: Most popular HTs in our dataset. Tweets may con-
tain multiple HTs so that the sum of tweets is not equal to
the number of tweets in our collection.

ing anti-vaccination campaigns Twitter data (Subrahmanian
et al. 2016).

Methodology

Dataset
In order to capture the US 2020 elections’ Twitter dynam-
ics shortly before the elections day (November 3rd 2020),
we build a dataset where the most popular hashtags (HTs)
related to the US 2020 elections were initially obtained. We
use Twitter API to retrieve all the tweets containing these
HTs, spanning from September 1st, 2020 to November 3rd,
2020, resulting in a dataset of 15.6 million tweets and 3.2
million users. The ten most popular HTs are shown in Ta-
ble 1.

Twitter Users Labeling
The acquired dataset does not contain explicit knowledge
whether a user is a bot or not. Since the goal of the cur-
rent study is to provide a supervised ML-based solution for
Twitter bot detection, it is crucial to obtain a bot vs. normal
users labeled dataset. Unfortunately, in the area of Twitter
bot detection, it is not possible to collect accurate ground
truth labels, without using third-party bot labeling tools. The
classic solution of ground truth generation corresponds to a
manual/crowd-sourcing analysis, which requires a thorough
inspection of Twitter accounts, by human experts to identify
the label of each account (via a majority voting rule). The
manual labeling process is cumbersome when considering
both the size of big datasets that contain millions of users
(in our case the dataset contains 3.2 million users) and the
sophistication level of bot accounts which has risen during
the last years.

As a means of overcoming the inherent restrictions of
manual labeling, we utilize off-the-shelf ML-based tech-
niques, allowing us to scale up the labeling procedure. ML
methods achieve higher accuracy, in terms of ground truth
labeling, as compared with the manual/crowd-sourcing anal-
ysis, since they exploit Twitter data feature representations
not evident to human experts. Here, we use the Botome-
ter (project 2020 (accessed October 21, 2020; Varol et al.
2017) and BotSentinel (Sentinel 2021 (accessed April 19,

Figure 1: The bot vs. normal users labeling pipeline.

2021) online tools to obtain the user labeling information.
To achieve highly conﬁdent results, we combine the set of
labels provided as output by the Botometer and the BotSen-
tinel tool, respectively. In particular, we compute the inter-
section of the two label sets. The intersection contains the
labels that are equal in both label sets. The users identiﬁed
as bots by one of the two tools are marked as unlabeled.

Both bot detection labeling tools yield an output score for
each requested Twitter account. The Botometer score lies
in the interval [0, 5], while the BotSentinel score takes inte-
ger values in {0, . . . , 100}. The higher the output score is,
the higher the probability the requested account is a bot. A
Twitter user is labeled as bot when the Botomoter and Bot-
Sentinel’s output score is greater than 4.0 and 75, respec-
tively. When the Botomoter and BotSentinel’s output score
is less than 1.0 and 25, respectively, the Twitter user is la-
beled as normal. As mentioned above, since none of the two
tools guarantees 100% bot identiﬁcation accuracy, we aim at
combining the scores from both tools and take into consider-
ation the labels that are (mutually) equal. When an account
is already suspended, Botometer cannot query Twitter API,
and thus we perform a Twitter API check to identify whether
an account is suspended or not.

Step
Before labeling
BotSentinel
Botometer
Suspended
Final

Bot Users Normal users

10,324
2,180
2,389
4,569

25,546
7,267
0
7,267

Total
1.3M
35,870
9,447
2,389
11,836

Table 2: The number of users during each phase of the label-
ing of our dataset (the symbol M corresponds to million).

To minimize the time complexity of the labeling process,
we separate our dataset into two parts. The ﬁrst part con-
tains data extracted during September 2020 and is utilized
for user labeling, ML model ﬁne-tuning, training, validation
and testing purposes. The second part incorporates data from
October 1st, 2020 until November 3rd, 2020 and is used to
evaluate the generalization capability of the proposed ML-
based Twitter bot identiﬁcation system on unseen data.

The dataset separation allows us to reduce the label-
ing process (computational) time without signiﬁcant infor-
mation loss, since the accounts remain active throughout
the whole period of September and October. The ﬁrst part
has 1.3 million users and more than 5 million tweets and
retweets, while the second part consists of 2.6 million users

DatasetSuspendedBot SentinelBotometer APITwitter APIBot usersNormal usersBot usersNormal usersFeature
statuses count
entities count
followers count
friends count
favourites count
listed count
name len
geolocation
protected
location
background img
default proﬁle
veriﬁed

Type
count
count
count
count
count
count
count
boolean
boolean
boolean
boolean
boolean
boolean

Feature
screen name len
description len
screen name likelihood
name screen sim
tweet retweet ratio
name digits
screen name digits
tweets by age
followers by age
friends by age
favourites by age
listed by age
followers friends

Type
count
count
real-valued
real-valued
real-valued
real-valued
real-valued
real-valued
real-valued
real-valued
real-valued
real-valued
real-valued

Calculation

likelihood of screen name
name and screen name similarity
statuses count / retweet count score
number of digits in user name
number of digits in user screen name
statuses count / user age
followers count / user age
friends count / user age
favourites count / user age
listed count / user age
followers count / friends count

Table 3: Proﬁle features extracted from Twitter user objects.

and 10.6 million tweets and retweets. A subset of users re-
main active during both periods, therefore it is obvious to
notice the overlap between the two parts.

Figure 1 shows the labeling pipeline. Our dataset has 1.3
million users during the BotSentinel labeling step. Then, the
Botometer tool receives as input 35,870 users, i.e., 10,324
bot users and 25,546 normal users (see Table 2), and out-
puts 9,447 users (2,180 Twitter accounts labeled as bots and
7,267 Twitter accounts marked as normal accounts). As a
parallel step, we query the Twitter API and the response pro-
vides a set of 2,389 users labeled as suspended. Therefore,
the ﬁnal labeled set has 4,569 bot users and 7,267 normal
users. Note that the overall labeling procedure is initialized
with BotSentinel, since it does not impose any daily query
limitations, in contrast with the Botometer. In the case of a
Botomoter-based initialization step, the labeling outcome of
the pipeline depicted in Figure 1 will be the same, but the
processing time will grow dramatically and will require 650
days to terminate, due to the Botometer request limitations.
So, starting with BotSentinel will require only 18 days.

We already mentioned that none of the existing labeling
tools provide 100% accurate ground truth labels. To quantify
the accuracy of our proposed labeling pipeline, we compare
the labeling results of our pipeline against the Twitter bot
detection algorithm after a period of six months. According
to Twitter, the number of bot accounts is 4,569 (with 51%
and 34% of the bot accounts being suspended and removed,
respectively), while 7,267 Twitter accounts are identiﬁed as
normal (with only 1.9% and 6.3% of the normal accounts
being suspended and removed, respectively). Twitter’s label-
ing mechanism incorporates a lag time, and thus it cannot be
efﬁciently used to compute our ground truth labels. Speciﬁ-
cally, we manually conﬁrmed that the lag time corresponds
to about two months in the case of the US 2020 Elections.

Feature Extraction
Twitter API allows the collection of tweets, including infor-
mation such as tweet text, tweet post time, as well as meta-
data such as HTs, URLs, and mentions. In this paper, we also
include the user proﬁle information by retrieving user ob-

jects, where all different types of the retrieved Twitter con-
tent are utilized, leading to a total amount of 335 computed
features. The features can be divided into four categories,
namely, user proﬁle, user context, user time, and user inter-
action.

Proﬁle Features Twitter API retrieves user objects con-
taining critical information to achieve accurate bot identi-
ﬁcation performance. The importance of user proﬁle fea-
tures is analyzed in various works (Chu et al. 2012; Wald
et al. 2013; Gilani, Kochmar, and Crowcroft 2017; Yang
et al. 2020). Typically, a user proﬁle object includes user
description, username, proﬁle picture, and proﬁle statistics
(e.g., number of followers, friends, favourites, and listed).
In this paper, bot vs. normal users distinction is promoted,
by enriching the features set through the extraction of pro-
ﬁle features. For this, the user proﬁle description and the
user/screen name digits are taken into consideration.

The computed user object-based features correspond to
unedited parameters such as the number of followers,
friends, favourites, listed lists, and description length. Flag
type elements like location usage, account description, pro-
tected ﬂag, geolocation usage, and background image usage,
are also estimated. Additional parameters such as the Jac-
card similarity of the user and the account screen name are
pre-computed and included in the overall features set. Ta-
ble 3 shows the list of the extracted feature set, where the
feature names written in italics correspond to the statisti-
cal features described in (Yang et al. 2020), and the feature
names written in bold correspond to our proposed features
leading to a 26-dimensional proﬁle feature space.

Context Features The user proﬁle feature set described in
the previous section reﬂects the statistics of the user’s Twit-
ter account, since the ﬁrst day of the subscription to Twitter.
However, the proﬁle features lack semantic information re-
garding the actual content sent by the user. Thus, it is essen-
tial to incorporate contextual information such as user posts’
content, most important user tweeted/re-tweeted topics, pop-
ular user HTs and number of URLs usage per tweet. Table 4
summarizes the list of the estimated context features.

Feature
N tweet mentioned tﬁdf
N tweet mentioned word
N tweet hashtags tﬁdf
N tweet hashtags word
N retweet mentioned tﬁdf
N retweet mentioned word
N retweet hashtags tﬁdf
N retweet hashtags word
N tweet word
N retweet word
tweet number of urls
retweet number of urls
tweet number of hashtags
retweet number of hashtags
tweet number of mentions
retweet number of mentions

Description
TF-IDF score of the 3 most popular user mentions contained in tweets
The 3 most popular mentions in user tweets as word features
TF-IDF score of the 3 most popular user HTs contained in tweets
The 3 most popular HTs in user tweets as word features
TF-IDF score of the 3 most popular user mentions contained in RTs
The 3 most popular mentions in user RTs as word features
TF-IDF score of the 3 most popular user HTs contained in RTs
The 3 most popular HTs in user RTs as word features
The 3 most popular words used by user in tweets as word features
The 3 most popular words used by user in RTs as word feature
Number of URLs in tweets, computed as average and standard deviation
Number of URLs in RTs, computed as average and standard deviation
Number of HTs in tweets, computed as average and standard deviation
Number of HTs in RTs, computed as average and standard deviation
Number of mentions in tweets, computed as average and standard deviation
Number of mentions in RTs, computed as average and standard deviation

Table 4: Context features based on user tweets and RTs, crawled by Twitter API.

Tweet’s context characteristics provide a diverse range of
uniqueness because each user operates in a different form of
expression. To estimate the most frequent words and enti-
ties, we compute a subset of the context features such as the
three most popular words, mentions and HTs per user (punc-
tuation marks and stop words are removed since they do not
provide important information). For each user, we discover
the most frequent sentences (user mentions, hashtags, up-
per and lower words). User mentions and hashtags may pro-
vide unique information that highlights the characteristics
of a particular user, thus we compute the term frequency-
inverse document frequency (TF-IDF) (Rajaraman and Ull-
man 2011) on the collected dataset. This allows us to iden-
tify the importance level of the user’s hashtags and men-
tions. In particular, we compute the TF-IDF of the overall
user mentions and hashtags and for each particular user, we
identify the three most frequent mentions/hashtags. The ﬁ-
nal step is to compute the TF-IDF based on the overall fre-
quency.

The next step is to use the word2vec algorithm (CHURCH
2017) to learn the word embeddings from the obtained Twit-
ter dataset, allowing us to transform text-based features into
a 10-dimensional space. The most frequent words, mentions
and HTs are transformed with the trained word2vec model.
Note that the text-based features might differ between the
user’s original tweets and RTs, since they are usually written
by a different user. Thus, text-based features are computed
separately for each user’s tweets and RTs.

Time-Based Features The automated bot accounts follow
a non-uniform time distribution activity (Zhang and Paxson
2011), either due to Twitter API time constraints regarding
tweet posts within short time intervals, or as a result of the
job schedulers that invoke tasks at speciﬁc time intervals.
In addition, the automated bots follow a non-uniform activ-
ity pattern whenever scripts are scheduled to start or stop
running at the same timestamps. Thus, the automated bots
behaviour can be detected by recognizing extremely non-

uniform or highly uniform tweet posts time patterns. On the
other hand, normal users’ tweets typically follow a diurnal
pattern, which can be predictable for speciﬁc users. As men-
tioned in (Chu et al. 2010), the human activity follows a spe-
cial pattern on Twitter since humans perform tweet posts at
speciﬁc daily time intervals, while the activity appears to
be lower during the weekends. Nevertheless, bots’ activity
pattern is more unpredictable because it does not follow the
same activity level per day. The automated behaviour of a
bot accounts is constantly evolving, almost mimicking hu-
man users activity, making it a challenging task to detect
bot accounts solely based on time-oriented features. How-
ever, due to the fact that not all automated behaviours are
similar, we aim to compute and use time-based patterns as
additional input to the proposed ML pipeline to enhance the
bot vs. normal users detection accuracy.

In this paper, we extract multiple time-based features such
as the RT time, as well as the hourly and daily activity. Re-
garding the RT times, we compute the difference between
the original tweet and the RT time provided in the tweet
object. We also measure the RT time distribution per user,
where the minimum, maximum, average and standard devi-
ation values of the RT time are included in the feature set.
As an account activity metric, the daily percentage of tweets
and RTs is computed (i.e., we can identify during which days
the users appear to be more active). Similar metrics are es-
timated during the active days and hours, and thus we can
identify the exact hourly intervals of the day in which the
user is vigorously posting tweets or RTs. Table 5 presents
the set of time-based features.

Interaction Features The ﬁnal set of extracted features is
based on the RT network graph which models user inter-
actions. The RT graph is estimated based on the collected
dataset, with the nodes representing users and the directed
edges deﬁning a RT action from user i to user j. The edge
weight indicates the number of RTs between the two users.
The resulted graph represents the network of the RT con-

Figure 2: ML model selection pipeline.

nections in our dataset. Finally, we use Gephi (Bastian, Hey-
mann, and Jacomy 2009) to compute the node statistics such
as in-degree and out-degree of each node.

Experimental Results
In this section, we examine the performance of our proposed
system, with respect to the resulting bot vs. normal users
detection accuracy.

ML Framework
As a main step towards building a robust and accurate ML-
based bot identiﬁcation system, we perform a model se-
lection procedure by examining the bot vs. normal users
classiﬁcation accuracy of several state-of-the-art ML al-
gorithms. In particular, we evaluate the performance of
Random Forest (Breiman 2001), Support Vector Machine
(SVM) (Cortes and Vapnik 1995) and Extreme Gradient
Boosting (XGBoost) (Chen and Guestrin 2016) algorithm.
Each ML method involves a different number of hyper-
parameters, and thus it is of paramount importance to fol-
low a hyper-parameter tuning procedure to identify the best
(trained) version of each ML model and promote a fair mod-
els’ comparison. Figure 2 illustrates the ML model selection
pipeline based on a combination of 80/20 train/test split (us-
ing random shufﬂe) and a 5-fold cross-validation scheme,
i.e., the dataset is randomly shufﬂed, where 80% of the
dataset is used for training/validation and the rest 20% (hold-
out part) of the dataset is exploited for testing purposes.
Each train/test split is performed in a stratiﬁed manner in

Feature
daily rt
daily tw
daily rt tw
daily retweet avg
daily tweet avg

hourly rt
hourly tw
hourly rt tw
retweet time

daily

Description
RT % each week day
tweets % each week day
tweets/RT % each week day
average daily number of RTs
average
of
tweets
RTs % of daily hours
tweets % of daily hours
tweets/RTs % of daily hours
time difference between
original tweet and user RT,
computed as min/max/avg/std

number

Table 5: Time-based features computed on user’s tweet/RT
object. Min, max, avg and std correspond to minimum, max-
imum, average and standard deviation, respectively.

order to have the same ratio of classes in both training and
testing data. During the 5-fold cross-validation process, the
synthetic minority oversampling technique (SMOTE) using
Tomek links (Batista, Prati, and Monard 2004) is applied on
the training folds to balance the two (bot vs. normal) dis-
tributions by oversampling the minority (bot) class distribu-
tion.

Model
XGBoost
Random Forest
SVM

F1
0.919
0.908
0.889

PR-AUC ROC-AUC

0.967
0.955
0.941

0.979
0.973
0.964

Table 6: Testing accuracy during the model selection phase.

Additionally, we employ feature selection based on three
different methods, namely, Lasso (Tibshirani 1994), Ran-
dom Forest feature selection and model feature importance.
Among the three feature selection methods, the model fea-
ture importance1 provided the features having the highest
predictive accuracy.

It is important to mention that some of the context features
are vectors provided by the pre-trained word2vec model.
The word2vec model provides a 10-dimensional space rep-
resentation of the text, but only a few out of the ten di-
mensions are informative for the model. For this, we keep
only the informative dimensions through the feature selec-
tion process. An example is presented in Figure 5, where
the feature “N1 retweet hashtag word 7” represents the ﬁrst
most popular hashtag seen in the user retweets. According to
the feature name, the seventh element of this particular word
(embedding) vector corresponds to the most informative di-
mension.

Table 6 reports the F1 score and the two areas under
the curve (AUC) scores, i.e., the precision-recall (PR) AUC
value and the receiver operating characteristic (ROC) AUC
value, averaged over ten repetitions. It can be seen that the
XGBoost model achieves slightly better results on the test-
ing data than SVM and Random Forest. Thus, we select XG-
Boost as the basic ML model applied in the next experimen-
tal evaluation phase.

General Model Comparison
We evaluate the generalization capability of the XGBoost
model, which is already ﬁne-tuned on the US 2020 Elec-
tions dataset (see in section ML Framework), against a gen-
eral model (Yang et al. 2020) applied to detect bots on var-
ious datasets. To perform this comparison, we collect the
public datasets provided by (Yang et al. 2020) and we per-
form an experimental evaluation with similar speciﬁcations
as described in ML Framework section. The authors in (Yang
et al. 2020) utilize only the statistical features computed on
the user objects, without exploiting any further knowledge
related with user interactions, RT times, or contextual infor-
mation of user tweets. As a result, we extract and use the
same feature set in both XGBoost and general model imple-
mentation to promote a fair comparison.

1Scikit-learn function: SelectFromModel

DatasetShuffleand split 80/20  Testing (Hold-out)Train and validationTrain (oversampled)Validation Store Model scoresDataset
cavarlee
varol-icwsm
cesci-17
pronbots
celebrity
vendor-purchased
botometer-feedback
political-bots
Gilani-17
Cresci-rtbust
cresci-stock
Midterm-18
Botwiki
veriﬁed
Total

# bots
15,483
733
7,049
17,882
0
1,087
139
62
1,090
353
7,102
42,446
698
0
94,124

# normal
14,833
1,495
2,764
0
5,918
0
380
0
1,413
340
6,174
8,092
0
1,987
43,396

Table 7: Publicly available labeled datasets used for bot de-
tection performance evaluation in (Yang et al. 2020).

We follow the experimental strategy described in (Yang
et al. 2020). Our proposed XGBoost model is trained over all
possible combinations of publicly available Twitter datasets
mentioned in Table 7. The dataset combinations that cor-
respond to the best testing performance of each model are
presented in Table 8. The ﬁrst six rows of Table 8 indi-
cate the different dataset combinations (check mark sym-
bols) used as training data by the M196, M195, U1 and U2
models. The next four rows correspond to the identiﬁcation
accuracy of each model using as testing (unseen) data the
Botwiki & veriﬁed, Midterm-18, Gilani-17 and Cresci-rtbust
datasets, respectively. Note that the ROC-AUC scores over
the four datasets correspond to the M196 and M195 dataset
combinations used in (Yang et al. 2020) and to the U1, U2
dataset combinations trained by our model. The inherent in-
formation of the various combined datasets reﬂect the dif-
ferences between bot vs. normal users. This information can
be learned via the XGBoost model, achieving robust gener-
alization capabilities.

The best ROC-AUC scores are achieved by our XGBoost
model when using as training data the dataset combina-
tions U1 (varol-icwsm, pronbots, botometer-feedback) and
U2 (varol-icwsm, pronbots, botometer-feedback, political-
bots). Table 8 also reports the best ROC-AUC scores
achieved by the Random Forest model in (Yang et al.
2020) utilizing as training data the dataset combina-
tions M196 (varol-icwsm, cesci-17, celebrity botometer-
feedback, political-bots) and M195 (varol-icwsm, cesci-17,
celebrity botometer-feedback).

The results clearly indicate that our ﬁne-tuned models (U1
and U2) achieve superior results when compared with the
general models (M195 and M196) in (Yang et al. 2020), as
reﬂected on the average ROC-AUC scores. According to the
best performance (U1 model) across the different datasets,
the ROC-AUC values range from 0.97 to 0.63. In order to
identify how the U1 and U2 trained models will perform on
the US 2020 Elections dataset, we measure the ROC-AUC

Dataset
varol-icwsm
cesci-17
pronbots
celebrity
botometer-feedback
political-bots
Botwiki & veriﬁed
Midterm-18
Gilani-17
Cresci-rtbust
Average ROC-AUC

M196 M195

(cid:88)
(cid:88)

(cid:88)
(cid:88)
(cid:88)

(cid:88)
(cid:88)

(cid:88)
(cid:88)

U1
(cid:88)

(cid:88)

(cid:88)

U2
(cid:88)

(cid:88)

(cid:88)
(cid:88)

0.99
0.99
0.68
0.60
0.815

0.99
0.99
0.69
0.59
0.815

0.978
0.954
0.75
0.63
0.828

0.978
0.951
0.745
0.614
0.822

Table 8: Training dataset combinations and performance re-
sults between our XGBoost model and the method described
in (Yang et al. 2020).

score for these two models. The models U1 and U2 achieved
0.609 and 0.618 ROC-AUC, respectively. For this purpose,
we provide the performance of the model trained directly on
the US 2020 Elections data.

Feature set
Statistical General only
Statistical
Context
Time
Graph
Our model

Number of features
20
26
204
99
6
228

Table 9: Number of features extracted by each feature cate-
gory from the US 2020 Elections dataset.

Statistical vs. Context Features
We compare the proposed XGBoost model with the model
introduced in (Yang et al. 2020) in light of the statistical
features set. The authors in (Yang et al. 2020) exploit only
the statistical features set. To promote a fair models’ com-
parison we use the statistical features alone, including the
number of followers, listed, favorites, and friends, as well
as the computation of the growth rate, based on the user ac-
count age, the number of digits in the screen name and the
account screen name likelihood. The extracted set of fea-
tures do not contain semantic information related with the
posts content. The rest of the feature types described in sec-
tion Feature Extraction are utilized separately in our model,
during the training and validation steps. Each feature cate-
gory, presented in Table 9 is used separately and compared
to each category’s performance against PR and ROC curves
with the features described in (Yang et al. 2020), as well as
the best features that were selected by our model. Figure 3
presents the precision vs. recall performance of those fea-
tures, with separate information of F1-score of the hold-out
dataset portion. Figure 4 illustrates the ROC-AUC curve and
the corresponding AUC score for each feature set. Accord-
ing to the ROC-AUC performance model, utilizing a mixture

Figure 3: Mean PR curves: multiple types of features com-
pared against our selected features.

Figure 4: Mean ROC curves: multiple types of features com-
pared against our selected features.

of multiple features with proper feature selection results in a
better ROC-AUC performance model, since each feature set
contains critical information for the model.

Generalization Performance: US 2020 Elections
Dataset

The combination of multiple feature types provide the best
bot identiﬁcation accuracy as it is experimentally evaluated
in section Statistical vs. Context Features, where the num-
ber of multiple combined features is 228. We use this set
of features to investigate the generalization capability of our
XGBoost model on the US 2020 Elections dataset. In partic-
ular, we divide the US 2020 Elections dataset into two parts
as mentioned in section Twitter Users Labeling, i.e., the ﬁrst
part corresponds to the time interval between September 1st
and September 30th, while the second part corresponds to
the interval between October 1st and November 3rd. The ex-
perimental speciﬁcation is the same as that adopted in sec-
tion ML Framework. The only difference is that the train/test
split now is 70/30, where 70% of the September dataset is
used for train/validation of the XGBoost model, while the
rest 30% is used for testing with the F1 score equal to 0.916
and the ROC-AUC score is 0.98. A difference between these
results and the ones depicted in Figure 3 due to the random
data shufﬂing.

The second dataset (October 1st to November 3rd) is also
used as testing data, to evaluate the bot identiﬁcation perfor-
mance of the already trained (on the 70% data of September)
XGBoost model on unseen data that correspond to an ex-
tended time horizon. The XGBoost model achieves an aver-
age of 0.896 F1 score and 0.977 ROC-AUC. The aforemen-
tioned results, clearly indicate that our proposed ML model
achieves impressive generalization capabilities by identify-
ing bot accounts on future data, based on past training sam-
ples.

Model Explainability
One of the ultimate goals of the current paper is to “unlock”
the proposed ML model mechanism in order to better under-
stand how the model yields its predictions. We use SHapley
Additive exPlanations (SHAP) values proposed in (Lund-
berg and Lee 2017) since they present several advantageous
characteristics. First and most importantly, SHAP values are
model-agnostic, i.e., they are not bound to any particular
type of ML model. Secondly, SHAP values present proper-
ties of local accuracy, consistency, and missingness, which
are not found simultaneously in other methods. Lastly,
SHAP implementation is actively supported by an open-
source community2, it is well documented and straightfor-
ward to use.

Before proceeding to the SHAP values explanation, let us
ﬁrst, provide a description of the concept of Shapley value.
More speciﬁcally, Shapley introduced a game-theoretic ap-
proach for assigning fair payouts to players depending on
their contribution to the total gain (Shapley 1953). Within
a predictive modeling task, this translates to assigning an
importance numerical value to features that depend on their
contribution to a prediction. Thus, in the predictive ML con-
text, a Shapley value can be deﬁned as the average marginal
contribution of a feature value across all possible feature
coalitions. Based on this deﬁnition, a Shapley value for a
given feature can be interpreted as the difference between
the mean prediction for the whole dataset and the actual pre-
diction.

The Shapley values are represented as a linear model of
feature coalitions by the SHAP method (Lundberg and Lee
2017). SHAP values exploit the game theory’s Shapley in-
teraction index, which allows allocating payouts, i.e., impor-
tance, not just to individual players, i.e., features, but also
among all pairs of them. As a result, SHAP values can ex-

2https://shap.readthedocs.io/

users have lower values of “favourites by age” (also known
as likes), which means that bot users tend to ignore the like
button of other users’ posts. This could be explained by the
complexity of bot account implementation. Finally, we no-
tice that bot users have high values of “friends by age” fea-
ture, which means that they tend to connect to more accounts
within a short period of time. This activity is obvious since
bot accounts try to gain high visibility and expand to larger
parts of the Twitter network. Presented explanations conﬁrm
our initial intuitive explanations regarding the difference be-
tween normal and bot accounts activity.

Conclusions and Future Work
This paper introduces a novel methodology based on a su-
pervised machine learning (ML) framework for identifying
bot vs. normal Twitter users using a wide range of extracted
features. Speciﬁcally, the proposed system incorporates the
extraction and labeling of multiple features, with the ground
truth labels estimated through the combination of two on-
line bot detection tools’ output. A thorough ML analysis
involving train/validation/test split, feature selection, over-
sampling and hyper-parameters tuning, establishes the Ex-
treme Gradient Boosting (XGBoost) algorithm as the best
ML model along with a speciﬁc set of features. The selected
XGBoost model when trained on a wide range of combined
features spanning from proﬁle and context features to time-
based and interaction features achieves the highest bot de-
tection accuracy.

The generalization capability of the proposed ML system
is extensively examined through an experimental evaluation
process, and compared with a recently introduced general
model (Yang et al. 2020). Finally, the obtained explanations
revealed meaningful insights from a Twitter data analysis
point of view about the reasoning process behind the XG-
Boost model’s decisions. Future work concerns the exten-
sion of the proposed methodology by performing text anal-
ysis on the tweet corpus posted by the bot users, to identify
the shared type of content during the US 2020 Elections pe-
riod.

The code and the employed datasets are available at the
following link in GitHub repository: (Code repository 2021)

Acknowledgements
We would like to thank the reviewers for their valuable com-
ments. This document is the result of the research projects
CONCORDIA (grant number 830927), CyberSANE (grant
number 833683) and PUZZLE (grant number 883540) co-
funded by the European Commission, with (EUROPEAN
COMMISSION Directorate-General Communications Net-
works, Content and Technology).

References
Ahmed, F.; and Abulaish, M. 2013. A generic statistical ap-
proach for spam detection in online social networks. Com-
puter Communications 36(10-11): 1120–1129.

Alsaleh, M.; Alariﬁ, A.; Al-Salman, A. M.; Alfayez, M.;
and Almuhaysin, A. 2014. Tsd: Detecting sybil accounts in

Figure 5: US 2020 Elections dataset: summary plot for
SHAP values. The top twenty features with the highest im-
pact at the XGBoost model’s output are depicted.

plain the modeling of local interaction effects, and allow the
possibility of providing new insights into the ML model’s
features.

Figure 5 shows the summary plot for SHAP values re-
lated with the features extracted from the US 2020 Elections
dataset. The top twenty features with the highest impact at
the XGBoost model’s output are depicted. For each feature,
one point corresponds to a single Twitter user. A point’s po-
sition along the x-axis (i.e., the actual SHAP value) repre-
sents the impact that feature had on the model’s output for
that speciﬁc Twitter user. Mathematically, this corresponds
to the malicious behaviour risk relative across Twitter users
(i.e., a Twitter user with a higher SHAP value has a higher
risk being malicious relative to a Twitter user with a lower
SHAP value). Features are arranged along the y-axis based
on their importance, which is given by the mean of their ab-
solute Shapley values. The higher the feature is positioned
in the plot, the more important it is for the XGBoost model.
A further analysis of the results in Figure 5 indicates
that the top twenty features with the highest impact on the
XGBoost model’s output correspond to statistical, time and
graph-based features. In particular, features such as Twitter
lists and average number of mentions in user tweets appear
to have a high impact in XGBoost model’s output. We ex-
pect that a combination of features with the highest output
impact could provide the best possible bot identiﬁcation per-
formance. This statement can be conﬁrmed by the results
mentioned in section Generalization Performance: US 2020
Elections Dataset.

Based on the SHAP values summary plot depicted in Fig-
ure 5, it is obvious that “listed count” corresponds to the
feature with the highest impact at XGBoost model’s bot vs.
normal user detection. As shown in Figure 5 bot users tend
to not belong to Twitter lists, whereas normal users could be
members of more than one list. We can also deduce that bot

twitter. In 2014 13th International Conference on Machine
Learning and Applications, 463–469. IEEE.

Antonakaki, D.; Spiliotopoulos, D.; V. Samaras, C.;
Pratikakis, P.; Ioannidis, S.; and Fragopoulou, P. 2017. So-
cial media analysis during political turbulence. PloS one
12(10): e0186836.

Arnaudo, D. 2017. Computational propaganda in Brazil: So-
cial bots during elections .

Badawy, A.; Ferrara, E.; and Lerman, K. 2018. Analyzing
the digital traces of political manipulation: The 2016 Rus-
sian interference Twitter campaign. In 2018 IEEE/ACM in-
ternational conference on advances in social networks anal-
ysis and mining (ASONAM), 258–265. IEEE.

Bastian, M.; Heymann, S.; and Jacomy, M. 2009. Gephi:
An Open Source Software for Exploring and Manipulating
Networks .

Batista, G. E. A. P. A.; Prati, R. C.; and Monard, M. C. 2004.
A Study of the Behavior of Several Methods for Balancing
Machine Learning Training Data. SIGKDD Explor. Newsl.
6(1): 20–29. ISSN 1931-0145.

Bolsover, G.; and Howard, P. 2019. Chinese computational
propaganda: automation, algorithms and the manipulation of
information about Chinese politics on Twitter and Weibo.
Information, communication & society 22(14): 2063–2080.

Bovet, A.; and Makse, H. A. 2019. Inﬂuence of fake news
in Twitter during the 2016 US presidential election. Nature
Communications 10(1): 7.

Breiman, L. 2001. Random Forests. Machine Learning
45(1): 5–32. ISSN 0885-6125.

Broniatowski, D. A.; Jamison, A. M.; Qi, S.; AlKulaib, L.;
Chen, T.; Benton, A.; Quinn, S. C.; and Dredze, M. 2018.
Weaponized health communication: Twitter bots and Rus-
sian trolls amplify the vaccine debate. American journal of
public health 108(10): 1378–1384.

Burnap, P.; and Williams, M. L. 2015. Cyber hate speech
on twitter: An application of machine classiﬁcation and sta-
tistical modeling for policy and decision making. Policy &
Internet 7(2): 223–242.

Byrnes, N. 2016. How the bot-y politic inﬂuenced this elec-
tion. Technology Rev. 100(10).

Chatﬁeld, A. T.; Reddick, C. G.; and Brajawidagda, U.
2015. Tweeting Propaganda, Radicalization and Recruit-
ment: Islamic State Supporters Multi-Sided Twitter Net-
In Proceedings of the 16th Annual International
works.
Conference on Digital Government Research, dg.o ’15,
239–249. New York, NY, USA: Association for Computing
Machinery. ISBN 9781450336000. doi:10.1145/2757401.
2757408. URL https://doi.org/10.1145/2757401.2757408.

Chavoshi, N.; Hamooni, H.; and Mueen, A. 2016. Identify-
ing correlated bots in twitter. In International conference on
social informatics, 14–21. Springer, .: Springer.

Chen, T.; and Guestrin, C. 2016. XGBoost: A Scalable
In Proceedings of the 22nd ACM
Tree Boosting System.

Github.

SIGKDD International Conference on Knowledge Discov-
ery and Data Mining, KDD ’16, 785–794. New York,
ISBN
NY, USA: Association for Computing Machinery.
9781450342322.
Chu, Z.; Gianvecchio, S.; Wang, H.; and Jajodia, S. 2010.
Who is tweeting on Twitter: human, bot, or cyborg? In Pro-
ceedings of the 26th annual computer security applications
conference, 21–30.
Chu, Z.; Gianvecchio, S.; Wang, H.; and Jajodia, S. 2012.
Detecting automation of twitter accounts: Are you a human,
bot, or cyborg? IEEE Transactions on Dependable and Se-
cure Computing 9(6): 811–824.
CHURCH, K. W. 2017. Word2Vec. Natural Language Engi-
neering 23(1): 155–162. doi:10.1017/S1351324916000334.
https://github.com/
Code repository. 2021.
alexdrk14/USBotDetection.
Cortes, C.; and Vapnik, V. 1995. Support-vector networks.
Machine learning 20(3): 273–297.
Cresci, S.; Di Pietro, R.; Petrocchi, M.; Spognardi, A.; and
Tesconi, M. 2017. The paradigm-shift of social spambots:
Evidence, theories, and tools for the arms race. In Proceed-
ings of the 26th international conference on world wide web
companion, 963–972. .: ACM.
Davis, C. A.; Varol, O.; Ferrara, E.; Flammini, A.; and
Menczer, F. 2016. BotOrNot: A System to Evaluate Social
Bots. In Proceedings of the 25th International Conference
Companion on World Wide Web, 273–274.
Dickerson, J. P.; Kagan, V.; and Subrahmanian, V. S. 2014.
Using sentiment to detect bots on Twitter: Are humans more
opinionated than bots? In 2014 IEEE/ACM International
Conference on Advances in Social Networks Analysis and
Mining (ASONAM 2014), 620–627. IEEE/ACM.
Edwards, C.; Edwards, A.; Spence, P. R.; and Shelton, A. K.
2014. Is that a bot running the social media feed? Testing
the differences in perceptions of communication quality for
a human agent and a bot agent on Twitter. Computers in
Human Behavior 33: 372–376.
Feng, Y.; Li, J.; Jiao, L.; and Wu, X. 2020. Towards
Learning-Based, Content-Agnostic Detection of Social Bot
Trafﬁc. IEEE Transactions on Dependable and Secure Com-
puting 7(3): 3.
Ferrara, E. 2017. Disinformation and social bot operations
in the run up to the 2017 French presidential election. First
Monday ISSN 1396-0466.
Ferrara, E.; Varol, O.; Davis, C.; Menczer, F.; and Flammini,
A. 2016. The rise of social bots. Communications of the
ACM 59(7): 96–104.
Fortuna, P.; and Nunes, S. 2018. A survey on automatic
detection of hate speech in text. ACM Computing Surveys
(CSUR) 51(4): 1–30.
Founta, A.; Djouvas, C.; Chatzakou, D.; Leontiadis, I.;
Blackburn, J.; Stringhini, G.; Vakali, A.; Sirivianos, M.;
Large Scale Crowdsourcing
and Kourtellis, N. 2018.
and Characterization of Twitter Abusive Behavior. CoRR
abs/1802.00393: 5. URL http://arxiv.org/abs/1802.00393.

Fraisier, O.; Cabanac, G.; Pitarch, Y.; Besanc¸on, R.; and
Boughanem, M. 2018. # ´Elys´eee2017fr: The 2017 French
In International AAAI
Presidential Campaign on Twitter.
Conference on Web and Social Media (ICWSM ’18).
Garimella, K.; and Weber, I. 2017. A Long-Term Analysis
of Polarization on Twitter.
Gilani, Z.; Kochmar, E.; and Crowcroft, J. 2017. Classiﬁ-
cation of twitter accounts into automated agents and human
users. In Proceedings of the 2017 IEEE/ACM International
Conference on Advances in Social Networks Analysis and
Mining 2017, 489–496. .: IEEE/ACM.
Gilani, Z.; Wang, L.; Crowcroft, J.; Almeida, M.; and Farah-
bakhsh, R. 2016. Stweeler: A Framework for Twitter Bot
Analysis. In Proceedings of the 25th International Confer-
ence Companion on World Wide Web, 37–38.
Golovchenko, Y.; Buntain, C.; Eady, G.; Brown, M. A.;
and Tucker, J. A. 2020. Cross-Platform State Propaganda:
Russian Trolls on Twitter and YouTube During the 2016
The International Journal of
US Presidential Election.
Press/Politics 21(3): 1940161220912682.
Hegelich, S.; and Janetzko, D. 2016. Are social bots on Twit-
ter political actors? Empirical evidence from a Ukrainian so-
cial botnet. In Proceedings of the International AAAI Con-
ference on Web and Social Media, volume 10.
Howard, P. N.; Bolsover, G.; Kollanyi, B.; Bradshaw, S.; and
Neudert, L.-M. 2017a. Junk news and bots during the US
election: What were Michigan voters sharing over Twitter.
CompProp, OII, Data Memo 21(3): 8.
Howard, P. N.; Bradshaw, S.; Kollanyi, B.; and Bolsolver, G.
2017b. Junk News and Bots during the French Presidential
Election: What Are French Voters Sharing Over Twitter In
Round Two? ComProp data memo 21(3): 8.
Howard, P. N.; Kollanyi, B.; and Woolley, S. 2016. Bots and
Automation over Twitter during the US Election. Computa-
tional Propaganda Project: Working Paper Series 21: 8.
Howard, P. N.; Woolley, S.; and Calo, R. 2018. Algo-
rithms, bots, and political communication in the US 2016
election: The challenge of automated political communica-
tion for election law and administration. Journal of informa-
tion technology & politics 15(2): 81–93.
Hui, P.-M.; Yang, K.-C.; Torres-Lugo, C.; and Menczer, F.
2020. BotSlayer: DIY Real-Time Inﬂuence Campaign De-
tection. In Proceedings of the International AAAI Confer-
ence on Web and Social Media, volume 14, 980–982.
Ibrahim, M.; Abdillah, O.; Wicaksono, A. F.; and Adriani,
M. 2015. Buzzer Detection and Sentiment Analysis for Pre-
dicting Presidential Election Results in a Twitter Nation. In
2015 IEEE International Conference on Data Mining Work-
shop (ICDMW), 1348–1353.
doi:10.1109/ICDMW.2015.
113.
Illing, S. 2018.
the shady
data ﬁrm that might be a key Trump-Russia link,
com/policy-
explained.
and-politics/2017/10/16/15657512/mueller-fbi-
cambridgeanalytica-trump-russia. Accessed 13: 1–42.

Cambridge Analytica,

https://www.

Vox.

vox.

Jones, M. O. 2019. The gulf information war— propaganda,
fake news, and fake trends: The weaponization of twitter
International journal of communi-
bots in the gulf crisis.
cation 13: 27.

Keller, F. B.; Schoch, D.; Stier, S.; and Yang, J. 2017. How
to manipulate social media: Analyzing political astroturﬁng
using ground truth data from South Korea. In Eleventh Inter-
national AAAI Conference on Web and Social Media, 811–
824. .: AAAI.

Keller, T. R.; and Klinger, U. 2019. Social Bots in Elec-
tion Campaigns: Theoretical, Empirical, and Methodologi-
cal Implications. Political Communication 36(1): 171–189.

Twitter bots drown out anti-Kremlin
Krebs on Security blog, http://krebsonsecurity.

Krebs, B. 2011.
tweets.
com/2011/12/twitter-botsdrown-out-anti-kremlin-
tweets/,(accessed February 29, 2012) 43(9): 0.

Lee, K.; Caverlee, J.; and Webb, S. 2010. Uncovering social
spammers: social honeypots+ machine learning. In Proceed-
ings of the 33rd international ACM SIGIR conference on Re-
search and development in information retrieval, 435–442.
,: ACM.

Lightfoot, S.; and Jacobs, S. 2017. Political propaganda
spread through social bots. Media, Culture, & Global Poli-
tics 8: 1–22.

Loyola-Gonz´alez, O.; Monroy, R.; Rodr´ıguez, J.; L´opez-
Cuevas, A.; and Mata-S´anchez, J. I. 2019. Contrast pattern-
based classiﬁcation for bot detection on Twitter. IEEE Ac-
cess 7: 45800–45817.

Luceri, L.; Deb, A.; Giordano, S.; and Ferrara, E. 2019. Evo-
lution of bot and human behavior during elections. First
Monday .

Lundberg, S.; and Lee, S.-I. 2017.
A uniﬁed ap-
proach to interpreting model predictions. arXiv preprint
arXiv:1705.07874 .

Mazza, M.; Cresci, S.; Avvenuti, M.; Quattrociocchi, W.;
and Tesconi, M. 2019. Rtbust: Exploiting temporal patterns
for botnet detection on twitter. In Proceedings of the 10th
ACM Conference on Web Science, 183–192. ,: ACM.

Neudert, L.; Kollanyi, B.; and Howard, P. N. 2017. Junk
news and bots during the german parliamentary election:
What are german voters sharing over twitter? Computational
Propaganda - University of Oxford 21(3): 8.

project, O. 2020 (accessed October 21, 2020). Botometer
(formerly BotOrNot) checks the activity of a Twitter account
and gives it a score. Higher scores mean more bot-like ac-
tivity. URL https://botometer.osome.iu.edu/.

Rajaraman, A.; and Ullman, J. D. 2011. Data Mining, 1–17.
Cambridge University Press.

Rizoiu, M.-A.; Graham, T.; Zhang, R.; Zhang, Y.; Ackland,
R.; and Xie, L. 2018. #DebateNight: The Role and Inﬂuence
of Socialbots on Twitter During the 1st 2016 U.S. Presiden-
tial Debate. In International AAAI Conference on Web and
Social Media (ICWSM ’18).

Data Selection. In Proceedings of the AAAI Conference on
Artiﬁcial Intelligence, 1096–1103. .: AAAI.
Yaqub, U.; Chun, S. A.; Atluri, V.; and Vaidya, J. 2017.
Analysis of political discourse on twitter in the context of
the 2016 US presidential elections. Government Informa-
tion Quarterly 34(4): 613–626. ISSN 0740-624X. doi:https:
URL https://www.
//doi.org/10.1016/j.giq.2017.11.001.
sciencedirect.com/science/article/pii/S0740624X17301910.

Zhang, C. M.; and Paxson, V. 2011. Detecting and analyz-
ing automated activity on twitter. In International Confer-
ence on Passive and Active Network Measurement, 102–111.
Springer.

Sentinel, B. 2021 (accessed April 19, 2021). Bot Sentinel.
URL https://botsentinel.com/info/about.
Seo, H. 2014. Visual propaganda in the age of social me-
dia: An empirical analysis of Twitter images during the 2012
Israeli–Hamas conﬂict. Visual Communication Quarterly
21(3): 150–161.
Shane, S. 2017. The fake Americans Russia created to inﬂu-
ence the election. The New York Times 7(09).
Shao, C.; Ciampaglia, G. L.; Varol, O.; Yang, K.-C.; Flam-
mini, A.; and Menczer, F. 2018.
The spread of low-
credibility content by social bots. Nature communications
9(1): 1–9.
Shapley, L. S. 1953. A value for n-person games. Contrib.
Theory Games 2: 307–317.
Sharma, K.; Qian, F.; Jiang, H.; Ruchansky, N.; Zhang, M.;
and Liu, Y. 2019. Combating fake news: A survey on iden-
tiﬁcation and mitigation techniques. ACM Transactions on
Intelligent Systems and Technology (TIST) 10(3): 1–42.
Stella, M.; Ferrara, E.; and De Domenico, M. 2018. Bots
increase exposure to negative and inﬂammatory content in
online social systems. Proceedings of the National Academy
of Sciences 115(49): 12435–12440.
Stukal, D.; Sanovich, S.; Bonneau, R.; and Tucker, J. A.
2017. Detecting bots on Russian political Twitter. Big data
5(4): 310–324.
Subrahmanian, V.; Azaria, A.; Durst, S.; Kagan, V.; Gal-
styan, A.; Lerman, K.; Zhu, L.; Ferrara, E.; Flammini, A.;
and Menczer, F. 2016. The DARPA Twitter Bot Challenge.
Computer 49(6): 38–46. ISSN 0018-9162.
Tibshirani, R. 1994. Regression Shrinkage and Selection
Via the Lasso. JOURNAL OF THE ROYAL STATISTICAL
SOCIETY, SERIES B 58: 267–288.
Varol, O.; Ferrara, E.; Davis, C. A.; Menczer, F.; and Flam-
mini, A. 2017. Online human-bot interactions: Detection,
In International AAAI
estimation, and characterization.
Conference on Web and Social Media (ICWSM ’17), 280–
289.
Vosoughi, S.; Roy, D.; and Aral, S. 2018. The spread of true
and false news online. Science 359(6380): 1146–1151.
Wald, R.; Khoshgoftaar, T. M.; Napolitano, A.; and Sumner,
C. 2013. Predicting susceptibility to social bots on twitter.
In 2013 IEEE 14th International Conference on Information
Reuse & Integration (IRI), 6–13. IEEE.
Waugh, B.; Abdipanah, M.; Hashemi, O.; Rahman, S. A.;
and Cook, D. M. 2013. The Inﬂuence and Deception of
Twitter: the authenticity of the narrative and slacktivism in
In 14th Australian Infor-
the Australian electoral process.
mation Warfare Conference, 28–38.
Yang, K.-C.; Varol, O.; Davis, C. A.; Ferrara, E.; Flammini,
A.; and Menczer, F. 2019. Arming the public with artiﬁcial
intelligence to counter social bots. Human Behavior and
Emerging Technologies 1(1): 48–61.
Yang, K.-C.; Varol, O.; Hui, P.-M.; and Menczer, F. 2020.
Scalable and Generalizable Social Bot Detection through

