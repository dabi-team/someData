Correlation Clustering via Strong Triadic Closure Labeling: Fast
Approximation Algorithms and Practical Lower Bounds

Nate Veldt 1

2
2
0
2

n
u
J

3
2

]
S
D
.
s
c
[

2
v
9
9
6
0
1
.
1
1
1
2
:
v
i
X
r
a

Abstract

Correlation clustering is a widely studied frame-
work for clustering based on pairwise similarity
and dissimilarity scores, but its best approxima-
tion algorithms rely on impractical linear program-
ming relaxations. We present faster approxima-
tion algorithms that avoid these relaxations, for
two well-studied special cases: cluster editing
and cluster deletion. We accomplish this by draw-
ing new connections to edge labeling problems
related to the principle of strong triadic closure.
This leads to faster and more practical linear pro-
gramming algorithms, as well as extremely scal-
able combinatorial techniques, including the ﬁrst
combinatorial approximation algorithm for clus-
ter deletion. In practice, our algorithms produce
approximate solutions that nearly match the best
algorithms in quality, while scaling to problems
that are orders of magnitude larger.

1. Introduction

Correlation clustering is a framework for unsupervised learn-
ing that clusters items in a dataset based on pairwise simi-
larity and dissimilarity scores, rather than based on explicit
representations for data objects. The simplest version of the
problem can be cast as a partitioning objective on a complete
signed graph, where the goal is to form clusters of nodes
in a way that avoids placing negative edges inside clus-
ters or positive edges between clusters. Bansal, Blum, and
Chawla (Bansal et al., 2004) introduced the problem, proved
its NP-hardness, and presented the ﬁrst approximation algo-
rithms. Now, nearly two decades later, developing improved
approximation algorithms and hardness results for different
variants of the problem continues to be a very active area of
research (Jafarov et al., 2020; 2021; Veldt et al., 2020; Bun
et al., 2021; Cohen-Addad et al., 2021; Bonchi et al., 2022).
In addition to extensive theoretical research, the problem

1Department of Computer Science and Engineering, Texas
A&M University, College Station, Texas, USA. Correspondence
to: Nate Veldt <nveldt@tamu.edu>.

has been applied in a wide variety of settings, including to
image segmentation (Kim et al., 2011; Yarkony et al., 2012),
community detection (Wang et al., 2013; Veldt et al., 2018;
Chen et al., 2012), cross-lingual link detection (Van Gael
& Zhu, 2007), cancer mutation analysis (Hou et al., 2016),
and detecting co-regulated genes based on expression pro-
ﬁles (Bhattacharya & De, 2010; 2008; Ben-Dor et al., 1999).
However, despite signiﬁcant previous research on both theo-
retical and applied aspects of correlation clustering, there
still exists a wide gap between the best approximation al-
gorithms and the most practical tools for this task. Many
fast heuristic methods come with no approximation guaran-
tees (Shi et al., 2021; Beier et al., 2015; Bhattacharya & De,
2008; Levinkov et al., 2017), while rigorous approximation
algorithms are often either impractically expensive, or only
apply to the simplest version of the problem.

Linear programming algorithms. The best approximation
factors for correlation clustering, both for the standard un-
weighted objective (Chawla et al., 2015) as well as more
general weighted variants (van Zuylen & Williamson, 2009;
Ailon et al., 2008; Puleo & Milenkovic, 2015; 2018; Veldt
et al., 2018; Gleich et al., 2018; Li et al., 2019; Jafarov et al.,
2020), are obtained by solving an expensive linear program-
ming (LP) relaxation in order to obtain lower bounds for the
objective. These lower bounds can useful for more than just
designing approximation algorithms. In practice, linear pro-
gramming lower bounds are often much closer to optimality
than worst case theoretical results predict. If a good LP
lower bound can be computed, the output of fast heuristic
methods can be compared against the lower bound to obtain
a posteriori approximation guarantees that are often very
good in practice (Swoboda & Andres, 2017; Lange et al.,
2018; Yarkony et al., 2012; Veldt et al., 2018). However,
despite some recent work on specialized solvers (Veldt et al.,
2019; Ruggles et al., 2020; Sonthalia & Gilbert, 2020), these
lower bounds can only be computed for medium-sized in-
stances at best (e.g., graphs with a few thousands nodes),
and even then this can take a long time. There is therefore a
need for faster approximation algorithms, as well as an even
more basic need to efﬁciently compute good lower bounds
for the NP-hard objective in practice.

Pivot algorithms. PIVOT is a combinatorial algorithm that

 
 
 
 
 
 
Correlation Clustering via Strong Triadic Closure Labeling

iteratively selects a random unclustered node and places it
with all of its unclustered positive neighbors. This provides
a randomized 3-approximation for complete unweighted
correlation clustering (Ailon et al., 2008). This approach
can be made very fast (Pan et al., 2015; Chierichetti et al.,
2014; Cohen-Addad et al., 2021), but is not without its lim-
itations. First, the approach is designed for the complete
unweighted case and does not extend as easily as LP-based
techniques to other variants of correlation clustering. As
one example, cluster deletion is a simple variant that strictly
prohibits clustering two nodes together if they share a neg-
ative edge. Although constant-factor linear programming
algorithms have been designed for cluster deletion (Puleo &
Milenkovic, 2015; Veldt et al., 2018; Charikar et al., 2005),
the standard PIVOT technique does not even produce a fea-
sible solution for this problem. Another limitation of PIVOT
is that it only provides an expected approximation guarantee,
and although derandomization techniques have been devel-
oped, these again rely on solving the expensive canonical
LP relaxation (van Zuylen & Williamson, 2009). Finally,
PIVOT does not produce explicit lower bounds for the NP-
hard objective, so it provides no way to compute improved
a posteriori approximation guarantees in practice.

The present work: practical lower bounds and faster al-
gorithms via connections to strong triadic closure. We
provide signiﬁcant steps in bridging the theory-practice gap
in correlation clustering by designing practical techniques
for computing lower bounds, and faster corresponding ap-
proximation algorithms. We achieve our results by high-
lighting and exploiting a relationship between correlation
clustering and edge-labeling problems related to the prin-
ciple of strong triadic closure (Sintos & Tsaparas, 2014;
Easley et al., 2010). Strong triadic closure (STC) posits
that two people will often share at least a weak connection
if they share strong connections to a mutual friend. An
STC-labeling of a graph is a way to label edges as weak or
strong in order to satisfy this principle. Similarities between
clustering and STC-labeling problems have been noted in
previous work (Konstantinidis et al., 2018; Gr¨uttemeier &
Komusiewicz, 2020). Our results signiﬁcantly expand on
these previously observed relationships, and provide new
strategies for rounding lower bounds for STC-labeling prob-
lems into approximate solutions for clustering problems.

One of the central contributions of our paper is to develop
combinatorial approximation algorithms for complete un-
weighted correlation clustering (also called cluster editing)
and cluster deletion, which can also be made deterministic
without LP relaxations. Our strategy works in three basic
steps: matching, ﬂipping, and pivoting. We ﬁrst obtain
lower bounds by computing maximal matchings in either
an auxiliary graph (for cluster deletion) or an auxiliary 3-
uniform hypergraph (for cluster editing). We use the results
of our matching to determine edges to be ﬂipped (i.e., added

or deleted) to create a new graph. Finally we prove that
applying a pivoting procedure on the resulting graph yields
approximation guarantees for the original problem. In sum-
mary, we provide the following algorithms:

• We apply our match-ﬂip-pivot approach to design the ﬁrst
combinatorial approximation algorithm for cluster deletion,
which provides a 4-approximation guarantee.

• We use match-ﬂip-pivot to design a combinatorial 6-
approximation algorithm for complete unweighted cor-
relation clustering. This can be made deterministic using
purely combinatorial techniques, making it the best approx-
imation guarantee achieved by any deterministic algorithm
that does not depend on linear programming.

• We present additional approximation algorithms for both
problems, each with a factor-4 approximation guarantee,
by solving and rounding LPs with signiﬁcantly fewer con-
straints than the canonical LP relaxations.

In proving these results, we show more generally that any α-
approximation algorithm for the minimum weakness strong
triadic closure problem (Sintos & Tsaparas, 2014) can be
used to design a (2α)-approximation for cluster deletion.
We show an analogous result for unweighted complete corre-
lation clustering. Our results imply that an optimal solution
to either of these clustering problems is always within a
factor of 2 of the optimal solution to a corresponding edge
labeling problem. This is especially signiﬁcant for cluster
deletion and minimum weakness strong triadic closure, as
there are known examples where these objectives differ by
up to a factor of 8/7 (Gr¨uttemeier & Komusiewicz, 2020).
Thus, our upper bound on the difference between these two
objectives is not far off of a known lower bound on their dif-
ference. Finally, we show that our algorithms are far more
scalable in practice than algorithms that solve the canonical
LP, producing approximate solutions that are within a small
factor of optimality (factors ≈ 2) on graphs with millions
of nodes, within a matter of seconds. Our fast algorithms
for ﬁnding lower bounds can also be used to provide good
a posteriori approximation guarantees for heuristics that
previously came with no guarantees.

2. Preliminaries and Related Work

We begin with deﬁnitions, terminology, and notation. Al-
though correlation clustering is often presented as a cluster-
ing objective on a signed graph, the variants we primarily
consider can be cast as objectives on an unsigned and un-
weighted graph G = (V, E). All objectives we consider in
this paper are deﬁned on undirected graphs.

Open wedges. The problems we consider rely on the notion
of an open wedge. Given an unsigned graph G = (V, E),
a triplet of nodes (i, j, k) is an open wedge centered at k
if (i, k) ∈ E and (j, k) ∈ E but (i, j) /∈ E. Let W denote

Correlation Clustering via Strong Triadic Closure Labeling

the set of triplets that deﬁne open wedges, and Wk ⊆ W
denote the set of open wedges centered at k.

2.1. Correlation Clustering Objectives

2

ij ∈ W + and an edge weight w−

The most general weighted version of correlation cluster-
ing is deﬁned by a node set V and two sets of nonnegative
weights W + and W − deﬁned on pairs of nodes. Formally,
each pair (i, j) ∈ (cid:0)V
(cid:1) is associated with an edge weight
w+
ij ∈ W −. In some ap-
plications these correspond to edge weights for positive
and negative edges in a signed graph, but this does not
always have to be the case. Broadly speaking, the nonnega-
tive weights (w+
ij) indicate the level of attraction and
repulsion, respectively, between nodes i and j in a cluster-
ing problem. The goal of the general weighted correlation
clustering objective is to partition the nodes in a way that
correlates as much as possible with these weights. This is ac-
complished by solving the following integer linear program
(ILP), know as the MinDisagree objective:

ij, w−

min

(cid:88)

w+

ijxij + w−

ij(1 − xij)

(i,j)∈(V
2 )

such that xjk + xik ≥ xij for triplets i, j, k

xij ∈ {0, 1} for (i, j) ∈ (cid:0)V

(cid:1).

2

et al., 2004; Ben-Dor et al., 1999). Alternatively, this means
clustering G in a way that minimizes the number of mistakes
or disagreements: edges crossing between clusters or non-
adjacent node pairs inside clusters.

Cluster deletion. Cluster deletion (Shamir et al., 2004)
seeks to convert a graph G = (V, E) into a disjoint union
of cliques by deleting the smallest number of edges. This
can be viewed as an instance of general weighted correla-
tion clustering (1) where (w+
ij, w−
ij) = (1, 0) if i and j are
adjacent in G, and (w+
ij, w−
ij) = (0, ∞) if these nodes are
not adjacent. In this special case, the problem permits an
integer programming formulation with fewer constraints,
since xij = 1 when (i, j) /∈ E:

min (cid:80)
s.t.

(i,j)∈E xij
xij ∈ {0, 1}
xjk + xik ≥ 1
xjk + xik ≥ xij
xjk + xij ≥ xik
xik + xij ≥ xjk






for all (i, j) ∈ E
if (i, j, k) ∈ Wk

(2)

if i, j, k is a triangle.

(1)

The best approximation factor for cluster deletion is 2 (Veldt
et al., 2018), which relies on rounding the linear program-
ming relaxation of objective (2).

Here, xij = 0 if nodes i and j are clustered together and
xij = 1 if they are separated. In other words, a penalty of
w+
ij is applied for separating i and j, and a penalty of w−
ij is
applied if they are placed together. Note that there is a trian-
gle inequality constraint xij ≤ xjk + xik for each ordering
of three distinct vertices {i, j, k}. An alternative objective
for correlation clustering is to maximize the weight of agree-
ments, which is the same at optimality but is different from
the perspective of approximations. Throughout this paper,
we focus on the MinDisagree objective (1).

Correlation clustering is NP-hard even for the simple un-
weighted case, but if the binary constraint xij ∈ {0, 1} is
relaxed to linear constraints 0 ≤ xij ≤ 1, the result is the
canonical linear programming relaxation of the problem,
which can be solved in polynomial time. Many approxima-
tion algorithms rely on solving and rounding this LP. An
O(log n) approximation can be obtained for the general case
using LP rounding (Charikar et al., 2005; Demaine et al.,
2006), and improved results exist for special weighted vari-
ants (Veldt et al., 2018; Puleo & Milenkovic, 2015; Jafarov
et al., 2020; Ailon et al., 2008; Veldt et al., 2020).

Cluster editing. Minimizing disagreements in a complete
unweighted signed graph (Bansal et al., 2004) is the widely-
studied special case of objective (1) where (w+
ij) ∈
{(0, 1), (1, 0)} for each node pair (i, j). This is equivalent
to a problem called cluster editing: given a graph G =
(V, E), ﬁnd the minimum number of edges to add or remove
in order to convert G into a disjoint union of cliques (Shamir

ij, w−

2.2. Strong Triadic Closure Labeling Objectives

Strong triadic closure (Easley et al., 2010; Granovetter,
1973) posits that two people are likely to share at least
a weak connection if they both share strong connections to a
mutual friend. This is used as a guiding principle for social
network analysis, and is the foundation for certain edge
labeling problems (Sintos & Tsaparas, 2014; Gr¨uttemeier &
Komusiewicz, 2020; Konstantinidis et al., 2018).

Min-weakness strong triadic closure. If every edge in a
graph G = (V, E) is labeled as either weak or as strong, we
say this is a strong triadic closure labeling if at least one of
the edges in each open wedge is weak. The rationale is that
if both edges in a wedge are strong ties, we would expect the
wedge to be closed because of strong triadic closure. The
minimum weakness strong triadic closure (MINSTC) prob-
lem (Sintos & Tsaparas, 2014) seeks a strong triadic closure
labeling with the minimum number of weak edges. We can
cast this as an integer program where a binary variable zuv
equals 1 if (u, v) ∈ E is labeled as a weak connection:

min (cid:80)
s.t.

(i,j)∈E zij
zjk + zik ≥ 1
zij ∈ {0, 1}

if (i, j, k) ∈ Wk
for all (i, j) ∈ E.

(3)

Strong triadic closure with edge additions. Minimum-
weakness strong triadic closure with edge additions
(MINSTC+) allows one to satisfy strong triadic closure by
also adding weak edges between non-adjacent nodes in the

Correlation Clustering via Strong Triadic Closure Labeling

graph G = (V, E). This is equivalent to viewing certain
non-edges as weak connections that were not observed. The
integer program formulation for this problem is:

min

s.t.

(cid:88)

zij

(i,j)∈(V
2 )
zjk + zik + zij ≥ 1
zij ∈ {0, 1}

(4)

if (i, j, k) ∈ W
(cid:1).
for (i, j) ∈ (cid:0)V

2

If (i, j) ∈ E and zij = 1, this again corresponds to labeling
the edge as weak. If (i, j) /∈ E and zij = 1, this means
we add a new edge between i and j. A feasible solution to
MINSTC+ is therefore a set of new edges E(cid:48) and a subset
of edges EW ⊆ E that we will label as weak. The goal is
to minimize |E(cid:48)| + |EW |. We assume all new edges E(cid:48) are
weak, to ensure we do not introduce new open wedges that
violate strong triadic closure. We refer to a feasible solution
(E(cid:48), EL) for MINSTC+ as an STC+ labeling.

2.3. Correlation Clustering and STC Connections

The cluster deletion (2) integer program can be obtained by
taking the integer program for MINSTC (3) and adding the
constraints zij + zik ≥ zjk for all permutations of nodes
i, j, k when (i, j, k) is a triangle in G. Thus, a feasible
solution for cluster deletion will produce a feasible solu-
tion for MINSTC by labeling all the deleted edges as weak.
Similarly, the constraints in the integer program for MIN-
STC+ (4) can be seen as a subset of the triangle inequal-
ity constraints in the integer program for cluster editing,
once a change of variables is applied. The fact that MIN-
STC lower bounds cluster deletion, and MINSTC+ lower
bounds cluster editing, has already been noted in previous
work (Gr¨uttemeier & Komusiewicz, 2020; Gr¨uttemeier &
Morawietz, 2020; Konstantinidis et al., 2018). The optimal
solutions to cluster deletion and MINSTC are known to coin-
cide for co-graphs (Konstantinidis et al., 2018), though there
exist concrete examples to conﬁrm that in general they are
not the same problem (Gr¨uttemeier & Komusiewicz, 2020).
There also exist approximation algorithms for correlation
clustering that rely on lower bounds from open wedge pack-
ings (also called bad triangle packings) (Ailon et al., 2008;
Bansal et al., 2004). These can also be viewed implicitly
as lower bounds for related STC-labeling problems, though
this connection is not explicitly addressed in these works.
Our paper expands on the known relationship between corre-
lation clustering and STC-labeling problems, and provides
new ways to round lower bounds for labeling problems into
approximate solutions for clustering problems.

3. Faster Linear Programming Algorithms

We ﬁrst show how to round LP relaxations for STC-labeling
problems to develop 4-approximation algorithms for cluster
deletion and cluster editing. While improved guarantees

can be obtained by rounding tighter relaxations (Chawla
et al., 2015; Veldt et al., 2018), our approach provides a
useful tradeoff in runtime and approximation guarantee.
In our experiments, we ﬁnd that these less expensive LP
relaxations are faster, while typically performing just as
well as algorithms based on canonical relaxations. To prove
our results, we ﬁrst review a general pivoting strategy for
correlation clustering, which we build on in our work.

3.1. Algorithmic Pivoting Primitive

PIVOT provides an expected 3-approximation for cluster
editing (Ailon et al., 2008), but applying it directly to a
weighted graph typically yields poor results. For cluster
deletion, it does not even produce a feasible solution. How-
ever, pivoting can be successfully used as a step in more so-
phisticated algorithms for correlation clustering. We extract
a general algorithmic strategy from the work of van Zuylen
and Williamson (van Zuylen & Williamson, 2009). This
method takes in a weighted instance of correlation cluster-
ing (V, W +, W −), a set of “budgets” {bij : (i, j) ∈ (cid:0)V
(cid:1)},
and a derived graph ˆG = (V, ˆE). Theorem 3.1 provides
conditions for bounding the output solution from running
PIVOT on ˆG.
Theorem 3.1. (Thm 3.1, van Zuylen & Williamson (2009).)
Let (V, W +, W −) deﬁne a weighted instance of correla-
tion clustering (1), and bij deﬁne the budget for node pair
(i, j) ∈ (cid:0)V
(cid:1). Assume that for some α > 0, there is a graph
ˆG = (V, ˆE) satisfying the following two properties:

2

2

1. For all (i, j) ∈ ˆE, we have w−
ij ≤ αbij.

(i, j) /∈ ˆE, we have w+

ij ≤ αbij, and for all

2. If (i, j, k) is an open wedge centered at j in ˆG, we have

w+

ij + w+

jk + w−

ik ≤ α (bij + bjk + bik).

Then applying PIVOT to ˆG = (V, ˆE) with uniform random
pivots will return a clustering with expected weight of dis-
agreements bounded by α (cid:80)
i<j bij. There also exists a
deterministic pivoting strategy that returns a clustering with
disagreements bounded above by α (cid:80)

i<j bij.

Appendix B provides details for the deterministic strategy.
By setting budgets bij to be the contribution of a node pair
(i, j) to the LP relaxation of (1), i.e., bij = w+
ij(1−
xij), one can obtain a derandomized 3-approximate PIVOT
method for complete unweighted correlation clustering (van
Zuylen & Williamson, 2009). However, the bottleneck is
solving the LP relaxation.

ijxij +w−

3.2. Faster LP Algorithms for Clustering

We ﬁrst present a new approximation algorithm for cluster
editing by rounding the LP relaxation of MINSTC+ (4),

Correlation Clustering via Strong Triadic Closure Labeling

Algorithm 1 Rounding the MINSTC+ LP relaxation.

Input: Graph G = (V, E)
Output: Clustering of G.
Solve LP (5)
Set ˆE ← {(i, j) ∈ (cid:0)V
5: Return PIVOT( ˆG = (V, ˆE))

2

(cid:1) : xij < 1/2}

Algorithm 2 Rounding the MINSTC LP relaxation.

Input: Graph G = (V, E)
Output: Feasible cluster deletion clustering of G.
Solve LP relaxation of (3)
Set ˆE ← {(i, j) ∈ E : zij < 1/2}

5: Return PIVOT( ˆG = (V, ˆE))

obtained by replacing zij ∈ {0, 1} with linear constraints
0 ≤ zij ≤ 1. We apply a convenient change of variables:
set xij = zij if (i, j) ∈ E, and xij = 1 − zij otherwise.
This leads to a linear program that amounts to the canonical
cluster editing LP relaxation but with fewer constraints:

min (cid:80)
s.t.

(i,j)∈E xij + (cid:80)

(i,j) /∈E(1 − xij)

xij ≤ xjk + xik if (i, j, k) ∈ Wk
(cid:1).
0 ≤ xij ≤ 1 for all (i, j) ∈ (cid:0)V

2

(5)

The number of constraints in this LP is O(|V |2 + |W|).
Assuming a connected graph, this is bounded above by
O(|E||V |) and for many common graph classes will be
smaller than the O(|V |3) constraints required for the canon-
ical relaxation. Algorithm 1 is a 4-approximation for cluster
editing. To prove its approximation guarantee, we show how
to round the output of LP (5) to produce a graph satisfying
the conditions of Theorem 3.1 with α = 4.

Theorem 3.2. Algorithm 1 is a randomized 4-
approximation algorithm for cluster editing.

Algorithm 2 rounds the MINSTC LP relaxation, obtained
by replacing xij ∈ {0, 1} with 0 ≤ xij ≤ 1 in (3).
Theorem 3.3. Algorithm 2 is a randomized 4-
approximation algorithm for cluster deletion.

The appendix provides full proofs for Theorems 3.2 and 3.3,
as well as full details for how to derandomize both al-
gorithms. Charikar, Guruswami, and Wirth (2005) previ-
ously showed that the canonical LP relaxations of cluster
editing and cluster deletion can be rounded to produce 4-
approximation algorithms for both problems. Theorems 3.2
and 3.3 show that the same approximation guarantee is pos-
sible using LP relaxations with only a subset of constraints.
For many natural graph classes (e.g., sparse graphs), the
number of constraints is asymptotically smaller. The best
approximation algorithms known for these problems—a
2.06-approximation for cluster editing (Chawla et al., 2015)

and a 2-approximation for cluster deletion (Veldt et al.,
2018)—still use the canonical LP relaxations. However,
these come as a signiﬁcant increase in computational cost.

4. Match-Flip-Pivot Algorithms

We now present a combinatorial approach for obtaining
lower bounds and approximation algorithms for cluster edit-
ing and cluster deletion. We begin by reviewing combinato-
rial strategies for lower bounding MINSTC and MINSTC+,
which we round in new ways for clustering problems.

4.1. Lower Bounds via Maximal Matchings

The MINSTC problem (3) on a graph G = (V, E) is equiv-
alent to solving vertex cover on the Gallai graph G of G.
The Gallai graph (Le, 1996) has a node vij for each edge
(i, j) ∈ E, and an edge between two nodes vjk and vik if
(i, j, k) is an open wedge centered at k in G. The edges in
G are in one-to-one correspondence with the open wedges
of G. Placing node vij in the cover can be viewed as label-
ing the edge (i, j) ∈ E as weak. Since all edges in G are
adjacent to at least one node in any vertex cover, this means
that all open wedges in G will have at least on weak edge.

The MINSTC+ objective (4) can instead be viewed as a
vertex cover problem in a three-uniform hypergraph H =
(VH, EH). This hypergraph has a node vij ∈ VE for every
pair of distinct nodes (i, j) ∈ (cid:0)V
(cid:1) in the original graph
G = (V, E), and a hyperedge wijk = {vij, vik, vjk} ∈ EH
whenever (i, j, k) is an open wedge in G. We will refer to
H as the open wedge hypergraph.

2

Sintos and Tsaparas (2014) showed that a 2-approximation
for MINSTC can be obtained by applying the 2-
approximation for vertex cover (Vazirani, 2001) to the Gallai
graph. A similar 3-approximation for MINSTC+ is obtained
by approximating vertex cover on H (Gr¨uttemeier & Moraw-
ietz, 2020). These approximate solutions are obtained by
ﬁrst ﬁnding a maximal matching in G or H respectively. For
our purposes, a maximal matching in G corresponds to an
edge-disjoint set of open wedges in G, and lower bounds the
cluster deletion objective. Similarly, a maximal matching
in H is a node-pair disjoint set of open wedges in G, and
lower bounds cluster editing.

4.2. Math-Flip-Pivot Algorithm for Cluster Editing

A vertex cover in the Gallai graph corresponds to a feasi-
ble STC+ labeling, and hence is a feasible solution for the
MINSTC+ integer program (4). We now show how to round
these approximately optimal solutions to MINSTC+ to ap-
proximate cluster editing. We start with a generic approach
that rounds any STC+ labeling (E(cid:48), EW ) into a solution
for cluster editing. This algorithms ﬁrst ﬂips edges in the

Correlation Clustering via Strong Triadic Closure Labeling

Algorithm 3 MATCHFLIPPIVOTCE(G)

Algorithm 4 MATCHFLIPPIVOTCD(G)

Input: Graph G = (V, E)
Output: Clustering of G.
Reduce: Build open wedge hypergraph H = (VH, EH)
Match: Find maximal matching M ⊆ EH

5: Vertex Cover:

C = {vij ∈ VH : vij ∈ w for some w ∈ M}

STC+ Labeling:

E(cid:48) = {(i, j) /∈ E : vij ∈ C}
EW = {(i, j) ∈ E : vij ∈ C}
Construct ˆG = (V, ˆE) where ˆE = E(cid:48) ∪ (E − EW )

10: Return PIVOT( ˆG)

original graph G = (V, E), meaning that we convert some
non-adjacent node pairs into edges E(cid:48), and we delete edges
EW that were previously in E. We then run PIVOT on the
new graph. The number of mistakes made can be bounded
in terms of the number of ﬂipped edges.
Theorem 4.1. Let (E(cid:48), Ew) be an STC+ labeling for graph
G = (V, E). If ˆE = E(cid:48) ∪ (E − EW ), applying PIVOT to
derived graph ˆG = (V, ˆE) returns a cluster editing solution
for G with at most 2(|E(cid:48)| + |EW |) mistakes in expectation.

We prove this result in the appendix and also provide a de-
randomized version. We can then use any approximation
algorithm for MINSTC+ to approximate cluster editing.
Corollary 4.2. If A is an α-approximation algorithm for
MINSTC+, applying the algorithm in Theorem 4.1 on an
STC+ labeling (E(cid:48), EW ) returned by A produces a (2α)-
approximation for cluster editing. If OPT + and OPT CE
are optimal solutions to STC+ and cluster editing, then
OPT + ≤ OPT CE ≤ 2OPT +.

Combining Corollary 4.2 with the 3-approximation for MIN-
STC+ produces a fast algorithm for cluster editing.
Corollary 4.3. Algorithm 3 is a randomized 6-
approximation for cluster editing.

Recall that standard PIVOT produces a better expected ap-
proximation factor of 3 and is also faster, as it requires
neither match nor ﬂip steps. Nevertheless, Algorithm 3
provides new beneﬁts and advantages in both theory and
practice. First of all, this algorithm can be derandomized
using a completely combinatorial approach (Appendix B).
Previous approaches for derandomizing PIVOT require solv-
ing the impractical canonical LP (van Zuylen & Williamson,
2009). Our approximation factor of 6 is therefore the best
approximation guarantee for complete unweighted correla-
tion clustering among methods that are both combinatorial
and deterministic. Furthermore, the match step of our algo-
rithm is extremely useful in practice, as it provides explicit
lower bounds and a posteriori approximation guarantees
that are typically much better than 3. In our experimental

Input: Graph G = (V, E)
Output: Feasible cluster deletion clustering of G.
Reduce: Build Gallai graph G = (VG, EG) (Section 4.1)
Match: Find maximal matching M ⊆ EG

5: Cover: C = {vij ∈ VG : vij ∈ w for some w ∈ M}

STC Labeling: EW = {(i, j) ∈ E : vij ∈ C}
Construct graph ˆG = (V, ˆE) where ˆE = (E − EW )
Return PIVOT( ˆG)

results, we ﬁnd that using our lower bounds in conjunction
with standard PIVOT yields a very fast method that produces
a posteriori approximations that are much better than the
3-approximate a priori guarantee for PIVOT.

4.3. Match-Flip-Pivot Algorithm for Cluster Deletion

We analogously round an approximate feasible solution
to MINSTC to approximate cluster deletion. Recall that
a feasible solution to MINSTC for a graph G = (V, E)
is a set of edges EW to label as weak to ensure all open
wedges in G have at least one weak edge. We prove that
applying PIVOT to G after deleting all of the edges in EW
will produce a feasible cluster deletion solution with a bound
on the number of deleted edges. Proofs and derandomized
algorithms are given in the appendix.
Theorem 4.4. Let EW be an STC label set for graph G =
(V, E). Applying PIVOT to graph ˆG = (V, E −EW ) returns
a cluster deletion solution for G with at most 2|EW | deleted
edges in expectation.

We obtain the following corollary on the relationship be-
tween MINSTC and cluster deletion.

Corollary 4.5. If A is an α-approximation algorithm
for MINSTC, running the algorithm in Theorem 4.4
with an STC label set returned by A produces a (2α)-
If OPT ST C and
approximation for cluster deletion.
OPT CD are optimal solutions to MINSTC and cluster dele-
tion, then OPT ST C ≤ OPT CD ≤ 2OPT ST C.

We can also use Theorem 4.4 to obtain the ﬁrst combinato-
rial approximation algorithm for cluster deletion.

Corollary 4.6. Algorithm 4 is a randomized 4-
approximation algorithm for cluster deletion.

A derandomized (and still combinatorial) version of the
algorithm is provided in Appendix B.

5. Experiments

In practice, our algorithms are far more scalable than the
best LP relaxation algorithms, and can be run on graphs
that are orders of magnitude larger, at a very small loss

Correlation Clustering via Strong Triadic Closure Labeling

in approximation guarantee. We demonstrate this by com-
puting lower bounds and approximate solutions for cluster
deletion and cluster editing problems on a range of dif-
ferent types of public graph datasets from the Suitesparse
matrix collection (Davis & Hu, 2011), the SNAP graph col-
lection (Leskovec & Krevl, 2014), and the Facebook100
collection (Traud et al., 2012). We also run experiments
on the 2021 PACE Challenge benchmark graphs for cluster
editing (Kellerhals et al., 2021). Cluster editing and cluster
deletion were ﬁrst motivated by applications to clustering
biological networks (Ben-Dor et al., 1999; Shamir et al.,
2004). These problems can also be viewed as special cases
of more general frameworks for community detection in un-
signed graphs (Veldt et al., 2018), which is why we consider
solving them on graphs from a range of different applica-
tion domains (e.g., social networks, biological networks,
email networks, collaboration networks). Our experiments
are run on a MacBook Air with 16GB of RAM and an
Apple M1 chip. All of our algorithms are implemented in
the Julia programming language, and we use Gurobi soft-
ware to solve linear programming relaxations. Code for
all of our algorithms and experimental results are available
at github.com/nveldt/FastCC-via-STC.

5.1. Cluster Deletion Approximation Algorithms

For cluster deletion, we run our strong triadic closure LP
rounding algorithm (LP-STC, Algorithm 2), our match-ﬂip-
pivot technique (MFP-CD, Algorithm 4), and compare these
against solving and rounding the canonical LP relaxation
(LP-CD). All previous approximation algorithms for cluster
deletion rely on the canonical LP (Charikar et al., 2005;
Puleo & Milenkovic, 2015; Veldt et al., 2018). We speciﬁ-
cally compare against the rounding procedure that provides
the best-case 2-approximation (Veldt et al., 2018). All the
lower bounds we consider can be rounded with either a
deterministic or randomized pivoting procedure on some
type of derived graph. The bottleneck in all runtimes is
computing the lower bound, so for these experiments we
apply randomized PIVOT 100 times on each derived graph
and take the best result as this is simple, fast, and effective.

Table 1 shows results on 4 of the larger graphs we consider.
In the appendix, we show full results for a wider range of
graphs that vary in size. We ﬁnd overall that LP-STC is
roughly twice as fast as LP-CD, while matching it in so-
lution quality. This method always returns the same lower
bound as LP-CD. In some cases it outputs a solution that is
also feasible for the canonical relaxation. In other cases, the
solution is not feasible for the canonical relaxation but still
has a matching objective score. The differences in rounded
solutions for these methods is negligible (they trade off in
performance) and is likely due to slight variations in the
randomized rounding pivot procedure rather than the lower
bound itself. Meanwhile, MFP-CD is 2-3 orders of magni-

Table 1. Lower bounds (LB), rounded objective scores (UB), ap-
proximation ratios (Ratio) and runtimes (Run) for MFP-CD, LP-
STC, and the existing 2-approximation for cluster deletion (LP-
CD, Veldt et al. (2018)). Larger LB is better; smaller UB is better.
The lower bound for LP-STC is guaranteed to be bounded above
by the bound for LP-CD. In practice, the former is twice as fast,
while outputting a matching lower bound in all cases. MFP-CD is
theoretically guaranteed to produce even looser lower bounds, but
these are still very close in practice and the method is 2-3 orders of
magnitude faster. In many cases, MFP-CD actually produces better
rounded solutions (best shown in bold), even if the approximation
ratio is slightly higher because of a looser lower bound.

Graph

EMAILENRON

n = 36692
m = 183831

CONDMAT05

n = 36458
m = 171734

CAASTROPH

n = 17903
m = 196972

LOC-
BRIGHTKITE
n = 58228
m = 214078

MFP-CD LP-STC

LP-CD

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

84385
169793
2.012
0.398

72428
147826
2.041
0.433

87563
178278
2.036
0.367

101924
204104
2.003
0.632

87861.0
173936.0
1.98
243.0

79287.5
152791.0
1.927
39.5

91188.0
174918.0
1.918
78.4

106429.0
211219.0
1.985
151.0

87861.0
174035.0
1.981
391.0

79287.5
153446.0
1.935
72.5

91188.0
174802.0
1.917
376.0

106429.0
211240.0
1.985
241.0

tude faster than LP-CD, with very minor loss to approx-
imation factor. A posteriori approximation guarantees are
always at or below 2.12, and are usually below 2. The lower
bound is only slightly worse than the bounds from the LP
methods in all cases. In 21 out of 24 cases, MFP-CD in fact
returns a better rounded solution (see appendix).

5.2. Cluster Editing Approximation Algorithms

We run a similar set of experiments for cluster editing (CE),
i.e., complete unweighted correlation clustering, with the
same overall ﬁndings. Table 2 summarizes results for a
few graphs. Our method for rounding the MINSTC+ LP
relaxation (LP-STC+, Algorithm 1), is noticeably faster
than solving and rounding the canonical LP-relaxation (LP-
CE, Chawla et al. (2015)), and produces nearly identical
approximation results. As a bonus, LP-STC+ can be used
as a ﬁrst step of a more efﬁcient approach for solving the
full canonical relaxation for cluster editing. In fact, we are
not even able to solve the canonical relaxation on graphs
with a few hundred nodes without using a “lazy constraints”
method that involves ﬁrst applying LP-STC+ and then it-
eratively updating constraints (see the appendix for further

Correlation Clustering via Strong Triadic Closure Labeling

Table 2. Lower bounds (LB), rounded solution scores (UB),
approximation ratios (Ratio) and runtimes (Run) for MFP-CE,
LP-STC+, and the 2.06 approximation for cluster editing (LP-
CE, Chawla et al. (2015)). To even run LP-CE, we ﬁrst solve
the STC+ relaxation and iteratively add violated constraints. This
often (but not always) makes it possible to run LP-CE almost as
quickly as LP-STC+. MFP-CE obtains good approximations in
under a second for problems that are so large the LP methods run
out of memory (indicated by a dash).

Graph

CAHEPTH

n = 8638
m = 24806

SIMMONS81

n = 1518
m = 32988

CAASTROPH

n = 17903
m = 196972

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
LOC
-BRIGHTKITE UB
n = 58228
m = 214078

Ratio
Run

MFP-CE LP-STC+ LP-CE

10609
29049
2.738
0.049

16402
38856
2.369
0.0645

86369
225943
2.616
0.488

101544
267453
2.634
0.559

11289.8
21625
1.915
62.6

16490.0
32977
2.0
235.8

11290.5
20597
1.824
562.1

16490.0
34391
2.086
236.9

–
–
–
–

–
–
–
–

–
–
–
–

–
–
–
–

details). If we tried forming the entire constraint matrix for
the canonical LP relaxation, LP-CE would not be able to run
on the graphs in Table 2. In comparison with LP-based meth-
ods, our match-ﬂip-pivot method (MFP-CE, Algorithm 3) is
orders of magnitude faster than the LP methods. Even for
problems where LP-based methods run out of memory,
MFP-CE obtains good results in under a second. The
appendix includes results on more graphs, and provides
additional details and results for various alternative round-
ing schemes. For example, we ﬁnd that combining the
lower bounds from MFP-CE with the clusterings obtained
by running standard PIVOT leads to signiﬁcantly improved
a posteriori approximation guarantees, with no increase in
runtime.

5.3. Match-Flip-Pivot on Large Graphs

Next we test the scalability of our match-ﬂip-pivot tech-
niques on graphs with up to millions of nodes and billions
of edges. We run MFP-CE and MFP-CD on all graphs
from the Facebook100 dataset (Traud et al., 2012), and on
a wide range of SNAP graphs (Leskovec & Krevl, 2014).
Figure 1(a) reports our a posteriori approximation guaran-
tees for cluster deletion vs. our approximations for cluster
editing, on graphs from 8 different classes (e.g., Facebook

(a) Cluster deletion approx vs. cluster editing approx

(b) MFP-CD runtimes

(c) MFP-CE runtimes

Figure 1. (a) Our algorithms allow us to observe different patterns
in how easy or hard it is to approximate cluster editing and cluster
deletion in different graph classes. Runtimes for our match-ﬂip-
pivot algorithms for cluster deletion (b) and cluster editing (c) are
extremely fast, and scale roughly linearly in term of |E|.

social networks, other social networks, road networks; see
appendix for more details). For MFP-CE, we report the ap-
proximation factor obtained by combining our lower bounds
with the clusterings obtained by standard PIVOT, as this is
just as fast and tends to produce better results. Our results
allow us to highlight and detect interesting patterns that
arise for different classes of graphs when it comes to solv-
ing these edge modiﬁcation problems. For example, the
three road networks (green) are unique in that cluster edit-
ing approximations for these graphs are signiﬁcantly better
than cluster deletion approximations. Meanwhile, the col-
laboration networks (purple) exhibit worse cluster deletion
approximation results than other graphs in general. Finally,
social networks are characterized by better cluster deletion
approximations, and poorer cluster editing approximations.

These results and observations about graph classes would
not be possible if our algorithms were not extremely scalable.
Figure 1 shows that our methods scale roughly linearly in
terms of the number of edges. For most graphs, our methods
take a few seconds or less, and only take a few minutes for
large graphs with millions of nodes and edges. The largest
graph we consider (soc-Livejournal1) has 4.2 million nodes
and 4.7 billion edges. We ﬁnd a 2.01 approximation for
cluster deletion in 100 seconds, and a 2.56 approximation
for cluster editing in 24 minutes. By comparison, standard
LP solvers run out of memory for problems that take us less

Correlation Clustering via Strong Triadic Closure Labeling

(a) SNAP CE Ratios

(b) FB100 CE Ratios

(c) SNAP CE Runtimes

(d) FB100 CE Runtimes

Figure 2. Approximation ratios and runtimes for MFP-CE, and
for combining lower bounds from MFP-CE with Louvain-based
heuristics (Louv-MFP), on SNAP and Facebook100 graphs. Run-
times for both methods include the time it takes to obtain the MFP
lower bound. We separately show the time it takes to compute this
lower bound (LB time). The time it takes MFP-CE to round this
lower bound in negligible, but the Louvain approach is slower.

than a second. Specialized solvers for correlation clustering
relaxations have also been designed (Ruggles et al., 2020;
Sonthalia & Gilbert, 2020; Veldt et al., 2019). These are
more memory efﬁcient than standard black-box optimiza-
tion methods and can be applied to more general problems,
but can be very slow in practice. We tried these methods as
well but found they were not competitive on the problems
we consider. See appendix for details.

5.4. A Posteriori Guarantees for Fast Heuristics

The lower bounds computed by our match-ﬂip-pivot tech-
niques can be used to provide a posteriori approximation
guarantees for fast heuristic algorithms that come with no
approximation guarantees of their own. To illustrate this,
we run a heuristic method for correlation clustering called
LAMBDALOUVAIN (Veldt et al., 2018) based on the popular
Louvain method for graph clustering (Blondel et al., 2008).
Figure 2 displays the approximation guarantees we obtain
for the cluster editing objective (CE) by combining our MFP
lower bounds with LAMBDALOUVAIN. Overall this leads
to signiﬁcantly improved a posteriori approximation ratios
in comparison with running MFP by itself, at the expense
of slower runtimes. Viewed from another perspective, this
shows that we can obtain lower bounds to certify that heuris-
tic methods provide approximately optimal solutions, in
signiﬁcantly less time than it takes to actually run these
heuristic methods. The appendix provides additional details.

(a) PACE Graphs Ratios

(b) PACE Graphs Runtimes

Figure 3. Comparison against KaPoCE on PACE graphs.

5.5. Comparisons on PACE Graphs

Finally, we illustrate the performance of our methods on
graphs from the 2021 Parameterized Algorithms and Com-
putational Experiments (PACE) challenge on algorithms for
solving the cluster editing objective (Kellerhals et al., 2021).
We compare against the winning method KaPoCE, which
comes with an exact version for ﬁnding optimal solutions
and a heuristic version with no approximation guarantees.
The exact version times out on even on some problems
with under 100 nodes, and even the heuristic approach does
not scale to large graphs. Figure 3 shows results for MFP-
CE, compared with results for combining MFP-CE lower
bounds with LAMBDALOUVAIN and the heuristic KaPoCE
algorithm. KaPoCE ﬁnds high quality solutions on small
graphs, but comes with no approximation guarantees of its
own and is orders of magnitude slower than MFP-CE.

6. Discussion and Open Questions

We have presented new approximation algorithms for clus-
ter editing and cluster deletion, based on new ways to
round lower bounds for related edge labeling problems.
We proved that cluster deletion and MINSTC are always
within a factor of 2; previous work has shown cases where
their objectives differ by a factor of 8/7 (Gr¨uttemeier &
Komusiewicz, 2020). One open question is whether we
can tighten these bounds in either direction, or tighten the
corresponding bounds between MINSTC+ and cluster edit-
ing. Our research also motivates further work on improved
lower bounds and approximation algorithms for correlation
clustering that do not rely on LP relaxations. Is it possible
to obtain even better approximation guarantees using alter-
native rounding schemes or simply alternative analyses?
One particularly compelling open question is to see whether
we can obtain a deterministic combinatorial PIVOT method
that is a 3-approximation, rather than a 6-approximation, or
a combinatorial 2-approximation for cluster deletion. Fi-
nally, perhaps the most interesting and meaningful direction
for future work is to see whether our fast and practical
match-ﬂip-pivot lower bounds can be used to obtain faster
approximation algorithms for weighted variants of correla-
tion clustering whose only approximation algorithms cur-
rently rely on LP relaxations (Jafarov et al., 2020; Veldt
et al., 2018; Puleo & Milenkovic, 2015).

Correlation Clustering via Strong Triadic Closure Labeling

References

Ailon, N., Charikar, M., and Newman, A. Aggregating
inconsistent information: ranking and clustering. Journal
of the ACM (JACM), 55(5):23, 2008.

Bansal, N., Blum, A., and Chawla, S. Correlation clustering.

Machine Learning, 56:89–113, 2004.

Beier, T., Hamprecht, F. A., and Kappes, J. H. Fusion moves
for correlation clustering. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR), June 2015.

Ben-Dor, A., Shamir, R., and Yakhini, Z. Clustering gene
expression patterns. Journal of computational biology, 6
(3-4):281–297, 1999.

Bhattacharya, A. and De, R. K. Divisive correlation clus-
tering algorithm (dcca) for grouping of genes: detecting
varying patterns in expression proﬁles. bioinformatics,
24(11):1359–1366, 2008.

Bhattacharya, A. and De, R. K.

Average corre-
lation clustering algorithm (acca) for grouping of
co-regulated genes with similar pattern of variation
Journal of Biomedi-
in their expression values.
cal Informatics, 43(4):560–568, 2010.
ISSN 1532-
0464.
https://doi.org/10.1016/j.jbi.2010.02.
001. URL https://www.sciencedirect.com/
science/article/pii/S1532046410000158.

doi:

Blondel, V. D., Guillaume, J.-L., Lambiotte, R., and Lefeb-
vre, E. Fast unfolding of communities in large networks.
Journal of statistical mechanics: theory and experiment,
2008(10):P10008, 2008.

Bonchi, F., Garc´ıa-Soriano, D., and Gullo, F. Correlation
Clustering: Morgan & Claypool Publishers. Morgan &
Claypool Publishers, 2022.

Bun, M., Elias, M., and Kulkarni, J. Differentially private
correlation clustering. In Meila, M. and Zhang, T. (eds.),
Proceedings of the 38th International Conference on Ma-
chine Learning, volume 139 of Proceedings of Machine
Learning Research, pp. 1136–1146. PMLR, 18–24 Jul
2021. URL https://proceedings.mlr.press/
v139/bun21a.html.

Charikar, M., Guruswami, V., and Wirth, A. Clustering with
qualitative information. Journal of Computer and System
Sciences, 71(3):360 – 383, 2005.
ISSN 0022-0000.
doi: http://dx.doi.org/10.1016/j.jcss.2004.10.012. URL
http://www.sciencedirect.com/science/
article/pii/S0022000004001424. Learning
Theory 2003.

Chawla, S., Makarychev, K., Schramm, T., and Yaroslavtsev,
G. Near optimal lp rounding algorithm for correlation
clustering on complete and complete k-partite graphs.
In Proceedings of the Forty-Seventh Annual ACM on
Symposium on Theory of Computing, pp. 219–228. ACM,
2015.

Chen, Y., Sanghavi, S., and Xu, H. Clustering sparse graphs.
In Advances in Neural Information Processing Sys-
tems, volume 25 of NIPS ’12. Curran Associates,
URL https://proceedings.
Inc.,
neurips.cc/paper/2012/file/
1e6e0a04d20f50967c64dac2d639a577-Paper.
pdf.

2012.

Chierichetti, F., Dalvi, N., and Kumar, R. Correlation clus-
tering in mapreduce. In Proceedings of the 20th ACM
SIGKDD international conference on Knowledge discov-
ery and data mining, pp. 641–650, 2014.

Cohen-Addad, V., Lattanzi, S., Mitrovi´c, S., Norouzi-Fard,
A., Parotsidis, N., and Tarnawski, J. Correlation cluster-
ing in constant many parallel rounds. In Proceedings of
the 38th International Conference on Machine Learning,
ICML ’21. PMLR, July 2021.

Davis, T. A. and Hu, Y.

The university of ﬂorida
sparse matrix collection. ACM Trans. Math. Softw.,
38(1), dec 2011.
doi: 10.1145/
ISSN 0098-3500.
2049662.2049663. URL https://doi.org/10.
1145/2049662.2049663.

Demaine, E. D., Emanuel, D., Fiat, A., and Im-
Correlation clustering in general
morlica, N.
Theoretical Computer Science,
weighted graphs.
doi:
ISSN 0304-3975.
361(2):172 – 187, 2006.
https://doi.org/10.1016/j.tcs.2006.05.008.
URL
http://www.sciencedirect.com/science/
article/pii/S0304397506003227. Approxi-
mation and Online Algorithms.

Easley, D., Kleinberg, J., et al. Networks, crowds, and mar-
kets, volume 8. Cambridge university press Cambridge,
2010.

Gleich, D. F., Veldt, N., and Wirth, A. Correlation
In 29th International Sym-
Clustering Generalized.
posium on Algorithms and Computation, volume 123
of ISAAC 2018, pp. 44:1–44:13, Dagstuhl, Germany,
2018. Schloss Dagstuhl–Leibniz-Zentrum fuer Infor-
matik. ISBN 978-3-95977-094-1. doi: 10.4230/LIPIcs.
ISAAC.2018.44. URL http://drops.dagstuhl.
de/opus/volltexte/2018/9992.

Granovetter, M. S. The strength of weak ties. American

journal of sociology, 78(6):1360–1380, 1973.

Correlation Clustering via Strong Triadic Closure Labeling

Gr¨uttemeier, N. and Komusiewicz, C. On the relation
of strong triadic closure and cluster deletion. Algorith-
mica, 82(4):853–880, 2020. doi: https://doi.org/10.1007/
s00453-019-00617-1.

Levinkov, E., Kirillov, A., and Andres, B. A comparative
study of local search algorithms for correlation clustering.
In German Conference on Pattern Recognition, pp. 103–
114. Springer, 2017.

Gr¨uttemeier, N. and Morawietz, N. On strong triadic closure

with edge insertion. Technical report, 2020.

Hou, J. P., Emad, A., Puleo, G. J., Ma, J., and Milenkovic,
O. A new correlation clustering method for cancer muta-
tion analysis. Bioinformatics, 32(24):3717–3728, 2016.
doi: 10.1093/bioinformatics/btw546. URL http://dx.
doi.org/10.1093/bioinformatics/btw546.

Jafarov, J., Kalhan, S., Makarychev, K., and Makarychev, Y.
Correlation clustering with asymmetric classiﬁcation er-
rors. In Proceedings of the 37th International Conference
on Machine Learning, ICML ’20, pp. 4641–4650. PMLR,
13–18 Jul 2020. URL https://proceedings.mlr.
press/v119/jafarov20a.html.

Jafarov, J., Kalhan, S., Makarychev, K., and Makarychev,
Y. Local correlation clustering with asymmetric classi-
ﬁcation errors. In Proceedings of the 36th International
Conference on Machine Learning, ICML ’21, pp. 4677–
4686. PMLR, 2021.

Kellerhals, L., Koana, T., Nichterlein, A., and Zschoche, P.
The pace 2021 parameterized algorithms and computa-
tional experiments challenge: Cluster editing. In 16th
International Symposium on Parameterized and Exact
Computation (IPEC 2021). Schloss Dagstuhl-Leibniz-
Zentrum f¨ur Informatik, 2021.

Kim, S., Nowozin, S., Kohli, P., and Yoo, C. D. Higher-
order correlation clustering for image segmentation. In
Shawe-Taylor, J., Zemel, R. S., Bartlett, P. L., Pereira, F.,
and Weinberger, K. Q. (eds.), Advances in Neural Infor-
mation Processing Systems 24, pp. 1530–1538. Curran
Associates, Inc., 2011.

Konstantinidis, A. L., Nikolopoulos, S. D., and Papadopou-
los, C. Strong triadic closure in cographs and graphs of
low maximum degree. Theoretical Computer Science,
740:76–84, 2018.

Lange, J.-H., Karrenbauer, A., and Andres, B. Partial op-
timality and fast lower bounds for weighted correlation
clustering. In Proceedings of the 35th International Con-
ference on Machine Learning, pp. 2892–2901. PMLR,
2018.

Le, V. B. Gallai graphs and anti-gallai graphs. Discrete

Mathematics, 159(1-3):179–189, 1996.

Leskovec, J. and Krevl, A.

SNAP Datasets: Stan-
ford large network dataset collection. http://snap.
stanford.edu/data, June 2014.

Li, P., Puleo, G. J., and Milenkovic, O. Motif and hy-
pergraph correlation clustering. IEEE Transactions on
Information Theory, pp. 1–1, 2019. ISSN 1557-9654. doi:
10.1109/TIT.2019.2940246.

Pan, X., Papailiopoulos, D., Oymak, S., Recht, B., Ramchan-
dran, K., and Jordan, M. I. Parallel correlation clustering
on big graphs. In Proceedings of the 28th International
Conference on Neural Information Processing Systems,
NIPS ’15, pp. 82–90, Cambridge, MA, USA, 2015. MIT
Press.

Puleo, G. and Milenkovic, O. Correlation clustering with
constrained cluster sizes and extended weights bounds.
SIAM Journal on Optimization, 25(3):1857–1872, 2015.
doi: 10.1137/140994198. URL https://doi.org/
10.1137/140994198.

Puleo, G. J. and Milenkovic, O. Correlation clustering and
biclustering with locally bounded errors. IEEE Trans-
actions on Information Theory, 64(6):4105–4119, June
2018. ISSN 0018-9448. doi: 10.1109/TIT.2018.2819696.

Ruggles, C., Veldt, N., and Gleich, D. F. A parallel pro-
jection method for metric constrained optimization. In
Proceedings of the SIAM Workshop on Combinatorial Sci-
entiﬁc Computing (CSC), pp. 43–53, 2020. doi: 10.1137/
1.9781611976229.5. URL https://epubs.siam.
org/doi/abs/10.1137/1.9781611976229.5.

Shamir, R., Sharan, R., and Tsur, D. Cluster graph modi-
ﬁcation problems. Discrete Applied Mathematics, 144:
173–182, 2004.

Shi, J., Dhulipala, L., Eisenstat, D., Ła¸cki, J., and Mirrokni,
V. Scalable community detection via parallel correlation
clustering. In VLDB, 2021.

Sintos, S. and Tsaparas, P. Using strong triadic closure to
characterize ties in social networks. In Proceedings of the
20th ACM SIGKDD international conference on Knowl-
edge discovery and data mining, KDD ’14, pp. 1466–
1475, 2014. URL https://doi.org/10.1145/
2623330.2623664.

Sonthalia, R. and Gilbert, A. C. Project and forget: Solving
large-scale metric constrained problems. arXiv preprint
arXiv:2005.03853, 2020.

Swoboda, P. and Andres, B. A message passing algorithm
for the minimum cost multicut problem. In Proceedings
of the 2017 IEEE Conference on Computer Vision and
Pattern Recognition, CVPR 2017, pp. 1617–1626. IEEE,
2017.

Correlation Clustering via Strong Triadic Closure Labeling

Traud, A. L., Mucha, P. J., and Porter, M. A. Social structure
of Facebook networks. Physica A: Statistical Mechanics
and its Applications, 391(16):4165–4180, 2012.

Van Gael, J. and Zhu, X. Correlation clustering for
In Proceedings of the
crosslingual link detection.
20th International Joint Conference on Artiﬁcal In-
telligence, IJCAI 2007, pp. 1744–1749, San Fran-
cisco, CA, USA, 2007. Morgan Kaufmann Publishers
Inc. URL http://dl.acm.org/citation.cfm?
id=1625275.1625558.

van Zuylen, A. and Williamson, D. P. Deterministic piv-
oting algorithms for constrained ranking and clustering
problems. Mathematics of Operations Research, 34(3):
594–620, 2009.
ISSN 0364765X, 15265471. URL
http://www.jstor.org/stable/40538434.

Vazirani, V. V. Approximation algorithms, volume 1.

Springer, 2001.

Veldt, N., Gleich, D. F., and Wirth, A. A correlation clus-
tering framework for community detection. In Proceed-
ings of the 2018 World Wide Web Conference, WWW
’18, pp. 439–448, Republic and Canton of Geneva,
Switzerland, 2018. International World Wide Web Con-
ferences Steering Committee. ISBN 978-1-4503-5639-
doi: 10.1145/3178876.3186110. URL https:
8.
//doi.org/10.1145/3178876.3186110.

Veldt, N., Gleich, D. F., Wirth, A., and Saunderson, J.
Metric-constrained optimization for graph clustering al-
gorithms. SIAM Journal on Mathematics of Data Science,
1(2):333–355, 2019. doi: 10.1137/18M1217152. URL
https://doi.org/10.1137/18M1217152.

Veldt, N., Wirth, A., and Gleich, D. F. Parameterized cor-
relation clustering in hypergraphs and bipartite graphs.
In Proceedings of the 26th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining, pp.
1868–1876, 2020.

Wang, Y., Xu, L., Chen, Y., and Wang, H. A scalable
approach for general correlation clustering. In Motoda,
H., Wu, Z., Cao, L., Zaiane, O., Yao, M., and Wang, W.
(eds.), Advanced Data Mining and Applications, pp. 13–
24, Berlin, Heidelberg, 2013. Springer Berlin Heidelberg.
ISBN 978-3-642-53917-6.

Yarkony, J., Ihler, A., and Fowlkes, C. C. Fast planar correla-
tion clustering for image segmentation. In European Con-
ference on Computer Vision, ECCV 2012, pp. 568–581,
Berlin, Heidelberg, 2012. Springer Berlin Heidelberg.
ISBN 978-3-642-33783-3.

Correlation Clustering via Strong Triadic Closure Labeling

A. Proofs for Approximation Algorithms

A.1. Proof of Theorem 3.2

Proof. We must prove that Theorem 3.1 is satisﬁed with α = 4 for an appropriate choice of correlation clustering weights
and budgets. For cluster editing, the weights are given by

(w+

ij, w−

ij) =

(cid:40)

(1, 0)
(0, 1)

if (i, j) ∈ E
if (i, j) /∈ E,

and the budgets deﬁned by the LP relaxation are given by

bij =

(cid:40)

xij
1 − xij

if (i, j) ∈ E
if (i, j) /∈ E.

Considering the way ˆG is constructed in Algorithm 1, the conditions in Theorem 3.1 translate to the following:

1. If xij < 1/2, we have w−

ij ≤ 4bij, and if xij ≥ 1/2, then w+

ij ≤ 4bij.

2. If xij < 1/2 and xjk < 1/2 but xik ≥ 1/2, then

w+

ij + w+

jk + w−

ik ≤ 4(bij + bjk + bik).

(6)

(7)

(8)

Condition 1 is straightforward to check by considering the deﬁnitions of edge weights (6) and budgets (7). We can prove the
second condition by case analysis, considering separately whether each node pair (i, j), (i, k), and (j, k) is an edge or not in
original graph G = (V, E). Regardless of the case, we have the following bounds, based on the assumption that (i, j, k) is
an open wedge centered at j in ˆG:

1 − xij > 1/2,

1 − xjk > 1/2,

xik ≥ 1/2.

(9)

We summarize all of the cases in succinct tabular format, where we state whether each edge is in E or not, and then give
lower bounds on the right hand side of inequality (8) to show it is greater than the left hand side in each case. We have
ordered cases so that moving from one row to the next changes the edge status of only one node pair at a time, making it
easy to quickly see changes in the left and right hand sides of the inequality (8) for the corresponding budgets and weights.
Several of the bounds we list for the right hand side of (8) could be tightened further, but this would not lead to an improved
overall approximation guarantee.

Is the edge in E?
(j, k)

(i, k)

(i, j)

Y

Y

Y

Y

N

N

N

N

Y

Y

N

N

N

Y

Y

N

Y

N

N

Y

Y

Y

N

N

Right side of (8)
4(bij + bjk + bik)

4(xij + xjk + xik) ≥ 4xik ≥ 2

Left side of (8)
ij + w+
w+
2 = 1+ 1+ 0

jk + w−

ik

4(xij + xjk + 1 − xik) ≥ 4

3 = 1+ 1+ 1

4(xij + 1 − xjk + 1 − xik) > 2

4(xij + 1 − xjk + xik) ≥ 2

4(1 − xij + 1 − xjk + xik) ≥ 0

4(1 − xij + xjk + xik) ≥ 2

4(1 − xij + xjk + 1 − xik) > 2

2 = 1 + 0 + 1

1 = 1 + 0 + 0

0 = 0 + 0 + 0

1 = 0 + 1 + 0

2 = 0 + 1 + 1

4(1 − xij + 1 − xjk + 1 − xik) > 2

1 = 0 + 0 + 1

Explanation Note

xik ≥ 1/2

xij + xjk − xik ≥ 0
(LP constraint)

1 − xjk > 1/2

xik ≥ 1/2

zero left side

xik ≥ 1/2

1 − xij > 1/2

1 − xij > 1/2

Correlation Clustering via Strong Triadic Closure Labeling

A.2. Proof of Theorem 3.3
Proof. First of all, note that applying PIVOT to the derived graph ˆG = (V, ˆE), using any order of pivot choices, will produce
a feasible instance for cluster deletion. To see why, observe that if k is the pivot node and i and j are two of its neighbors in
ˆG, then zki < 1/2 and zkj < 1/2, which implies that (i, j) ∈ E. If (i, j) were not an edge, then (i, j, k) would be an open
wedge and the LP relaxation would include the constraint zki + zkj ≥ 1. It remains to check that Theorem 3.1 is satisﬁed
with α = 4, for the right choice of budgets and weights. The weights in this case are

(w+

ij, w−

ij) =

(cid:40)

(1, 0)
(0, ∞)

if (i, j) ∈ E
if (i, j) /∈ E,

(10)

since we are solving cluster deletion. We set our budgets to be the contributions to the LP objective: bij = zij if (i, j) ∈ E,
and bij = 0 otherwise. These conditions we need to satisfy are:

1. If (i, j) ∈ ˆE, we have w−

ij ≤ 4bij, and if (i, j) /∈ ˆE, then w+

ij ≤ 4bij.

2. If (i, j) ∈ ˆE and (j, k) ∈ ˆE and (i, k) /∈ ˆE, then

w+

ij + w+

jk + w−

ik ≤ 4(bij + bjk + bik).

(11)

Checking condition 1. Observe that (i, j) ∈ ˆE =⇒ (i, j) ∈ E =⇒ w−
(i, j) /∈ E, then w+

ij = bij = 0. If (i, j) /∈ ˆE but (i, j) ∈ E, then zij = bij ≥ 1/2 and so w+

ij = 0 ≤ 4bij. Similarly, if (i, j) /∈ ˆE and
ij = 1 < 4bij.

Checking condition 2. For condition 2, note that (i, j) ∈ ˆE ⊆ E and (j, k) ∈ ˆE ⊆ E imply that zij + zjk < 1 and therefore
(i, j, k) is not an open wedge in G and so (i, k) ∈ E. Since (i, k) /∈ ˆE, we know bik = zik ≥ 1/2. Overall, we have that

w+

ij + w+

jk + w−

ik = 2 = 4 ·

1
2

≤ 4bik ≤ 4(bij + bjk + bik).

A.3. Proof of Theorem 4.1

Proof. One convenient way to prove Theorem 4.1 is to show that it satisﬁes the conditions of Theorem 3.1 for an appropriate
choice of weights, budgets, and parameter α. For cluster editing, recall that the correlation clustering weights are

(w+

ij, w−

ij) =

(cid:40)

(1, 0)
(0, 1)

if (i, j) ∈ E
if (i, j) /∈ E.

For this theorem, we do not choose budgets to correspond to a lower bound for a labeling or clustering problems. Instead,
the budgets are deﬁned in terms of the set of ﬂipped edges:

bij =

(cid:40)

1
0

if (i, j) ∈ EW ∪ E(cid:48)
otherwise

.

The sum of budgets is exactly (cid:80)
of Theorem 3.1 are satisﬁed with α = 2. We ﬁrst need to check that

i<j bij = |E(cid:48)| + |EW |. Note then that the result holds if we can prove that the conditions

(i, j) ∈ ˆE =⇒ w−
(i, j) /∈ ˆE =⇒ w+

ij ≤ 2bij and
ij ≤ 2bij.

(12)

(13)

Checking (12): If (i, j) ∈ ˆE ∩ E then w−
non-edge (w−

ij = 1) that was ﬂipped (bij = 1).
Checking (13): If (i, j) /∈ ˆE and (i, j) /∈ E then we have w+

ij = 0 = bij, and if (i, j) ∈ ˆE but (i, j) /∈ E, then bij = w−

ij = 1 since (i, j) is a

ij = bij = 0. If (i, j) /∈ ˆE and (i, j) ∈ E, then w+

ij = 1 = bij.

Next we conﬁrm that if (i, j, k) is an open wedge centered at j in ˆG = (V, ˆE), then

Correlation Clustering via Strong Triadic Closure Labeling

w+

ij + w+

jk + w−

ik ≤ 2 (bij + bjk + bik) .

Regardless of the edge structure of (i, j, k) in the original graph G = (V, E), we must have

bij + bjk + bik + w+

ij + w+

jk + w−

ik = 3.

(14)

(15)

To see why, observe ﬁrst of all that (i, j) ∈ ˆE, (j, k) ∈ ˆE, and (i, k) /∈ ˆE, by our assumption that (i, j, k) is an open wedge
centered at j in ˆG . Consider node pair (i, j): either this pair is an edge (i, j) ∈ E (meaning w+
ij = 1) or it was ﬂipped
(meaning bij = 1) but not both. Therefore, bij +w+
jk = bik +w−
ik = 1.
This yields (15).

ij = 1, and by the same argument we can show bjk +w+

A key step in the proof is to realize that

bij + bjk + bik ≥ 1.

(16)

If instead we assume bij + bjk + bik = 0, this means that none of the edges were ﬂipped, so (i, j, k) is also an open wedge
in the original graph G = (V, E). This contradicts the fact that (E(cid:48), EW ) is a strong triadic closure labeling. A strong
triadic closure labeling would either add (i, k) to the new edge set E(cid:48), or label one of the edges as weak, which would
subsequently lead to one node pair being ﬂipped. Combining (16) and (15), we can see that

w+

ij + w+

jk + w−

ik ≤ 2 = 2(1) ≤ 2(bij + bjk + bik).

A.4. Proof of Corollary 4.2

Proof. We have previously established that OPT + ≤ OPT CE. If (E(cid:48), EW ) is the α-approximate STC+ labeling returned
by A and B = |E(cid:48)| + |EW |, then

B ≤ αOPT + ≤ αOPT CE =⇒

B
α

≤ OPT CE,

which provides a lower bound on the optimal cluster editing solution. Using Theorem 4.1, we can ﬁnd a cluster editing
solution that makes at most 2B mistakes, which is within 2α of the lower bound. If we solve MINSTC+ optimally, this
mean α = 1, which shows that OPT + ≤ OPT CE ≤ 2OPT +.

We also observe in passing that an α-approximation algorithm for vertex cover would imply a (2α)-approximation for
cluster editing, since MINSTC+ can be reduced to vertex cover in an approximation preserving way.

A.5. Proof of Corollary 4.3

Proof. By construction, the minimum vertex cover in the 3-uniform hypergraph H = (VH, EH) is equivalent to MINSTC+
on G = (V, E). The algorithm performs the standard steps to obtain a 3-approximation: ﬁnd a maximal matching, and place
all nodes from the matched edges in the vertex cover. This can be converted to an STC+ labeling that is a 3-approximation
for MINSTC+, which can be fed to FLIPPIVOT to produce a 2 · 3 = 6 approximation for cluster editing.

A.6. Proof of Theorem 4.4

Proof. We must ﬁrst conﬁrm that this approach produces a feasible solution to cluster deletion, meaning that all clusters
returned are cliques in the original graph G = (V, E). Consider pivoting on any node j in the derived graph ˆG = (V, ˆE). If
(j, k) ∈ ˆE and (i, j) ∈ ˆE, this means neither of these edges were labeled weak, and so we must have (i, k) ∈ E or else
strong triadic closure would be violated. Thus, pivoting on any node produces cliques.

The rest of the theorem follows by showing that Theorem 3.1 holds with α = 2 if we choose budgets bij = 1 if (i, j) ∈ EW
and bij = 0 otherwise, and use weights (w+
ij) that corresponding to cluster deletion (see (10)). In this case, the sum of
budgets in is (cid:80)

i<j bij = |EW |. The conditions we must check are:

ij, w−

1. For all (i, j) ∈ ˆE, we have w−

ij ≤ 2bij, and for all (i, j) /∈ ˆE, we have w+

ij ≤ 2bij.

Correlation Clustering via Strong Triadic Closure Labeling

Algorithm 5 DETPIVOT(V, W +, W −, {bij}, ˆE)

Input: Correlation clustering instance (V, W +, W −), budgets {bij}, derived graph ˆG = (V, ˆE)
Output: C = DETPIVOT(V, W +, W −, {bij}, ˆE)
for k ∈ V do

5:

k = {(i, j) ∈ ˆE : (j, k) /∈ ˆE, (i, k) ∈ ˆE}
T +
k = {(i, j) /∈ ˆE : (j, k) ∈ ˆE, (i, k) ∈ ˆE}
T −
Pk =

(i,j)∈T
(cid:80)

ij +(cid:80)

w−
ij

w+

−
k

+
k

(cid:80)

(i,j)∈T

∪T

+
k

(i,j)∈T
bij

−
k

end for
p = argmink∈V Pk
S = {v ∈ V : (p, v) ∈ ˆE}

T = {w+
T = {w−

10: T = V \S
W +
W −
ˆET = {(i, j) ∈ ˆE : i ∈ T, j ∈ T }
BT = {bij : i ∈ T, j ∈ T }

ij : i ∈ T, j ∈ T }
ij : i ∈ T, j ∈ T }

15: Return C = {S, DETPIVOT(T, W +

T , W −

T , BT , ˆET )

// select pivot
// form cluster
// update node set
// update remaining weights, edges, and budgets

2. If (i, j, k) is an open wedge centered at j in ˆG, we have w+

ij + w+

jk + w−

ik ≤ 2 (bij + bjk + bik).

Checking condition 1: If (i, j) ∈ ˆE, then (i, j) ∈ E, so w−
ij = 0 ≤ 2bij. If (i, j) /∈ ˆE but (i, j) ∈ E, then (i, j) ∈ EW and so bij = 1, and thus w+
w+

ij = 0 ≤ 2bij. If (i, j) /∈ ˆE and (i, j) /∈ E, then have

ij = 1 = bij.

Checking condition 2: If (i, j) ∈ ˆE and (j, k) ∈ ˆE, then we must have (i, k) ∈ E or else there would be a violation of
strong triadic closure. Since we are assuming in condition 2 that (i, j, k) is an open wedge centered at j in ˆG, the edge
(i, k) ∈ EW , and so bik = 1. Thus, we have

w+

ij + w+

jk + w−

ik = 2 = 2bik.

Therefore, the weight of mistakes (i.e, the number of deleted edges) resulting from running a pivoting procedure on
ˆG = (V, E − EW ) is at most α (cid:80)

i<j bij = 2|EW | in expectation.

We omit proofs for Corollaries 4.5 and 4.6 as they follows the same arguments as Corollaries 4.2 and 4.3.

B. Deterministic Approximation Algorithms

Our main text focused on randomized algorithms with expected approximation guarantees that can be obtained by applying
a standard pivot procedure to a derived graph ˆG = (V, ˆE). All of our algorithms can be made deterministic by applying
the deterministic pivoting procedure of van Zuylen and Williamson (2009). Algorithm 5 provides pseudocode for this
method, whose choice of pivot nodes is guided by the derived graph ˆG, the budgets {bij}, and the weights {w+
ij} that
deﬁne the correlation clustering instance. For completeness, we show how to set all parameters for our algorithms to obtain
deterministic approximation guarantees.

ij, w−

Algorithms 6 and 7 are deterministic versions of Algorithms 1 and 2, and show explicitly how to set budgets and weights to
guide the deterministic pivoting strategy (Algorithm 5). Similarly, Algorithm 8 is a deterministic counterpart to Algorithm 3,
and provides a way to turn an STC+ labeling (E(cid:48), EW ) into a cluster editing solution that is guaranteed to make at most
2(|E(cid:48)| + |EW |) mistakes (i.e., deleted and added edges). Finally, Algorithm 9 is a deterministic version of Algorithm 4, our
combinatorial 4-approximation for cluster deletion.

Correlation Clustering via Strong Triadic Closure Labeling

Algorithm 6 Deterministic Rounding for the MINSTC+ LP relaxation.

Input: Graph G = (V, E)
Output: Clustering of G.
Solve LP-relaxation of (5)
Set ˆE ← {(i, j) ∈ V × V : xij < 1/2}
ij, w−
ij, w−

5: For (i, j) ∈ E, (w+
For (i, j) /∈ E, (w+
Return DETPIVOT(V, {w+

ij) = (1, 0), and bij = xij
ij) = (0, 1), and bij = 1 − xij
ij}, {bij}, ˆE)

ij}, {w−

Algorithm 7 Deterministic Rounding for the MINSTC LP relaxation.

Input: Graph G = (V, E)
Output: Feasible cluster deletion clustering of G.
Solve LP relaxation of (3)
Set ˆE ← {(i, j) ∈ E : zij < 1/2}

5: For (i, j) ∈ E, (w+
For (i, j) /∈ E, (w+
Return DETPIVOT(V, {w+

ij, w−
ij, w−

ij) = (1, 0), and bij = zij
ij) = (0, ∞) and bij = 0

ij}, {w−

ij}, {bij}, ˆE)

Algorithm 8 DETMATCHFLIPPIVOTCE(G, E(cid:48), EW )

Input: G = (V, E)
Output: Clustering of G.
Reduce: Build open wedge hypergraph H = (VH, EH) (Section 4.1)
Match: Find maximal matching M ⊆ EH

5: Vertex Cover: C = {vij ∈ VH : vij ∈ w for some w ∈ M}

STC+ Labeling:

Construct ˆG = (V, ˆE) where ˆE = E(cid:48) ∪ (E − EW )
Set budgets (bij) and weights (w+

ij, w−

ij):

E(cid:48) = {(i, j) /∈ E : vij ∈ C}
EW = {(i, j) ∈ E : vij ∈ C}

bij =

(cid:40)
1
0

if (i, j) ∈ EW ∪ E(cid:48)
otherwise

10: Return DETPIVOT(V, {w+

ij}, {w−

ij}, {bij}, ˆE)

Algorithm 9 DETMATCHFLIPPIVOTCD(G, EW )

Input: Graph G = (V, E) and STC label set EW
Output: Feasible cluster deletion clustering of G.
Reduce: Build Gallai graph G = (VG, EG) (Section 4.1)
Match: Find maximal matching M ⊆ EG

5: Cover: C = {vij ∈ VG : vij ∈ w for some w ∈ M}

STC Labeling: EW = {(i, j) ∈ E : vij ∈ C}
Construct graph ˆG = (V, ˆE) where ˆE = (E − EW )
Set budgets (bij) and weights (w+

ij, w−

ij):

bij =

(cid:40)

1
0

if (i, j) ∈ EW
otherwise

Return DETPIVOT(V, {w+

ij}, {w−

ij}, {bij}, ˆE)

(w+

ij, w−

ij) =

(cid:40)

(1, 0)
(0, 1)

if (i, j) ∈ E
if (i, j) /∈ E

(w+

ij, w−

ij) =

(cid:40)

(1, 0)
(0, ∞)

if (i, j) ∈ E
if (i, j) /∈ E

Correlation Clustering via Strong Triadic Closure Labeling

C. Extended Experimental Results and Details

C.1. Graph details

Aside from PACE challenge graphs, all of the graphs we consider in our experimental results come from either the
Facebook100 dataset (Traud et al., 2012), or are available on the Suitesparse Matrix Collection (Davis & Hu, 2011), or the
SNAP large network repository (Leskovec & Krevl, 2014). These can be categorized into the following classes:

• fb-social: Facebook social networks (all graphs from the Facebook100 dataset)

• loc-social: Location-based social networks (loc-Gowalla, loc-Brightkite)

• o-social: Other social networks (com-LiveJournal, com-Youtube, soc-Epinions1, soc-LiveJournal1, soc-Slashdot0811,

soc-Slashdot0902)

• web: web networks (web-BerkStan, web-Google, web-NotreDame, web-Stanford, wiki-topcats)

• comm: communication networks (email, email-Enron, email-EuAll, wiki-Talk)

• road: road networks (roadNet-CA, roadNet-PA, roadNet-TX)

• prod: product co-purchasing networks (amazon0302, amazon0312, amazon0505, amazon0601, com-Amazon)

• collab: collaboration networks (Erdos991, Netscience, ca-AstroPh, ca-CondMat, ca-GrQc, ca-HepTh, ca-HepPh,

condmat2005, com-DBLP)

• cit: citation networks (SmaGri, cit-HepPh, cit-HepTh, cit-Patents)

• bio: biological networks (celegans-neural, celegans-metabolic)

• other: all other graphs (Harvard500, Roget, polblogs)

Some of these graphs have weights or directions. Before running our experiments, we standardize all graphs by removing
edge directions and weights.

C.2. Results for Cluster Deletion Approximation Algorithms

In Table 4 we show more results for running our approximation algorithms for cluster deletion on various graphs. Overall,
our LP-STC algorithm is twice as fast as the canonical relaxation algorithm (LP-CD), while obtaining similar approximation
results. Our match-ﬂip-pivot technique (MFP-CD) is far more scalable, and comes with a minor loss in approximation
guarantees.

C.3. Extended Results and Details for Cluster Editing Approximation Algorithms

Solving cluster editing on a graph G is equivalent to solving the complete unweighted correlation clustering objective
on the signed graph obtained by treating edges of G as positive edges and non-edges in G as negative edges. Cluster
editing is much more computationally expensive than cluster deletion, as it involves both deleting and adding edges, rather
than just deleting edges. Approximation algorithms and LP-rounding schemes for this problem are more abundant than
approximation algorithms for cluster deletion. Therefore, for this problem we provide additional details on techniques for
scaling LP algorithms as much as possible, and we also provide additional details on different methods for rounding the
lower bounds we consider. Interestingly, we ﬁnd in practice that the best results are obtained by combining the lower bounds
of our algorithms with alternative rounding schemes than the ones we theoretically analyze in the main text. This suggests
that improved approximation results may also be obtained by analyzing other rounding strategies.

Rounding for MFP-CE For MFP-CE, we compare our combinatorial lower bound against three types of pivoting
strategies. The ﬁrst is the standard approach of applying a random PIVOT procedure to the derived graph ˆG in Algorithm 3.
The second is a proof-of-concept implementation of the deterministic version of this algorithm (Algorithm 8), which
signiﬁcantly improves a posteriori approximation guarantees but is slower as our implementation of the deterministic
pivoting procedure is not optimized. An optimized version of this code would be signiﬁcantly faster, though we expect it

Correlation Clustering via Strong Triadic Closure Labeling

to typically still be noticeably slower than randomized pivot node selections. Finally, we ﬁnd that the best results can be
obtained simply by running standard PIVOT on the original graph G multiple times and comparing the best result against the
lower bound from MFP-CE. This last approach is extremely fast while producing results that are comparable to deterministic
pivoting on the derived graph ˆG. In Tables 5 and 6, we show results for each rounding method (when applying randomized
PIVOT, we take the best result from 50 different runs). In Table 2 in the main text, we have displayed results for the standard
MFP-CE algorithm that applies pivoting on the derived graph ˆG, in order to show how the approximation algorithm performs
when it is run exactly according to its theoretical design. In subsequent experiments in the main text, we display results for
applying PIVOT to the original graph G = (V, E), as this perform better typically and is just as fast.

Rounding for LP-STC+ For the canonical LP-relaxation (LP-CE), we use the rounding scheme with a 2.06-approximation
guarantee, due to Chawla, Makarychev, Schramm, and Yaroslavtsev (2015), which we refer to as CMSY rounding. This
involves a more careful randomized construction of a derived graph before running a pivot procedure; we perform this
randomized construction ten times and take the best result. For LP-STC+, we use the more simplistic rounding scheme
that gives us our 4-approximation (Algorithm 1). For our results in the appendix, we additionally apply the same CMSY
rounding procedure, which is cheap in comparison with ﬁnding the lower bound. We ﬁnd in practice that CMSY produces
the best results.

Scalability and LP solvers. Linear programming relaxations for cluster deletion have O(|E|) variables, whereas LPs
for cluster editing involve O(|V |2) variables. Even more signiﬁcantly, the canonical LP for cluster editing has O(|V |3)
constraints. In our experiments, it becomes prohibitively expensive to even form the constraint matrix when |V | equals a few
hundred. In the runtimes listed in Table 2 and in the appendix, the runtimes for LP-STC+ and LP-CE appear very similar,
but this is only because we apply a useful warm-start approach for solving the canonical LP relaxation. This approach ﬁrst
solves the LP relaxation for STC+ and then iteratively adds in constraints from the canonical cluster editing relaxation that
were violated. This process continues adding in violated constraints and re-solving the problem until all of the canonical LP
constraints are satisﬁed, even if they were not included explicitly. Often, the solution for the STC+ relaxation matches the
solution for LP-CE and this procedure terminates quickly, while in many other cases only a few iterations are needed. This
lazy constraints approach has previously been used to help scale up LP solvers for correlation clustering (Veldt et al., 2019),
though without an explicit realization that this method actually begins by solving the STC+ relaxation.

There also exist specialized solvers for approximately solving the correlation clustering LP relaxation by applying memory-
efﬁcient projection methods (Ruggles et al., 2020; Veldt et al., 2019; Sonthalia & Gilbert, 2020). However, although these
methods come with a smaller memory requirement and can be generalized to other weighted variants of the problem, they
are still quite slow and were not competitive for the problems we considered. In Table 3 we show lower bounds and runtimes
for using the projection method of Veldt et al. (2019) on a sample of graphs. When it comes to lower bounding the cluster
editing relaxation, this method is much slower than LP-STC+ and LP-CE, and returns poorer lower bounds.

C.4. Details for Louvain Experiments and Cluster Deletion Results

We used an implementation of the LAMBDALOUVAIN method from the author’s previous work (Veldt et al., 2020)
(available at https://github.com/nveldt/ParamCC/blob/master/src/Graph_Louvain.jl). Running
this method with a parameter λ = 1/2 greedily optimizes the cluster editing objective, while λ close to 1 greedily optimizes
cluster deletion (Veldt et al., 2018).

The performance and runtime of this methods depends on how long the greedy procedure is allowed to run when searching
for improved clusterings. In more detail, the method selects a random ordering of nodes, places all nodes in singleton
clusters to start, and then iteratively visits each node to move it to the adjacent cluster leading to the greatest improvement in
the correlation clustering objective. In theory, this greedy moving can continue until no more improvement is possible, but
usually the number of passes over the nodes is truncated. Once there is no more improvement from visiting nodes, or once
the maximum number of passes over the nodes is reached, the algorithm enters a second phase where nodes in the same
cluster are agglomerated into supernodes and the procedure is run again on a reduced graph. Often, the algorithm is run
multiple times with different random node orderings, and the best result is returned.

Parameter settings and cluster deletion results
In our experiments, we run LAMBDALOUVAIN with the fastest possible
settings. For each graph we ﬁx a single random ordering of the nodes and run the algorithm only for this ordering. When
iteratively visiting nodes to perform greedy moves, we visit each node only once time, and then skipped the second

Correlation Clustering via Strong Triadic Closure Labeling

Table 3. Cluster editing lower bounds (LB) for three convex relaxations, and runtimes (Run). Value n denotes number of nodes, m is the
number of edges. Proj-CE solves a quadratic program that approximates the canonical cluster editing LP. This method is not competitive
with LP-STC+ or LP-CE when applied to cluster editing. Dashed lines indicate that Proj-CE did not converge after half an hour.

Graph

HARVARD500

ROGET

SMAGRI

POLBLOGS

EMAIL

CA-GRQC

CAHEPTH

LP-STC+ LP-CE

Proj-CE

n = 500
m = 2043

n = 994
m = 3640

n = 1024
m = 4916

LB
Run

LB
Run

LB
Run

n = 1222
LB
m = 16714 Run

n = 1133
m = 5451

LB
Run

n = 5242
LB
m = 14484 Run

727.0
0.376

1819.5
0.622

2457.0
2.7

8356.0
61.6

2722.0
1.6

4931.0
16.2

727.0
0.447

1819.5
0.893

2457.0
2.9

8356.0
63.1

2722.0
1.9

4931.0
80.9

n = 8638
LB
m = 24806 Run

11289.8
64.7

11290.5
625.5

696.3
33.4

1736.6
218.8

2345.3
278.5

7976.3
326.4

2598.6
416.0

–
–

–
–

(a) SNAP CD Runtimes

(b) FB100 CD Runtimes

(c) SNAP CD Ratios

(d) FB100 CD Ratios

Figure 4. Approximation ratios and runtimes when solving the cluster deletion objective.

phase where nodes are agglomerated into supernodes. Since we use the fastest settings for LAMBDALOUVAIN, we do
the same for MFP-CE, and only perform one step of the pivot rounding procedure for this comparison. This provides the
most straightforward comparison between the methods, as we are comparing the fastest settings for each method. More
importantly, we run LAMBDALOUVAIN with the fastest settings as this provides most of the improvement in terms of
solution quality (i.e., the a posteriori approximation guarantee), at a fraction of the runtime. Overall this provides the most
favorable comparison for LAMBDALOUVAIN. Even so, this method can be quite a bit slower than MFP-CE. Our plots do
not report results for running LAMBDALOUVAIN on the largest SNAP graph, (soc-Livejournal1), as it took too long even
with the fastest parameter settings.

We also provide approximation ratios and runtimes for MFP-CD and for LAMBDALOUVAIN when λ is slightly less than one,
which greedily optimizes the cluster deletion objective (Figure 4). MFP-CD tends to return solutions with an approximation
guarantee around two for nearly every graph. LAMBDALOUVAIN again returns better solutions. This is often at the expense
of longer runtimes, though for this objective MFP-CD is actually a little slower for some graphs.

Better but slower results with Louvain By visiting nodes more than once and performing the second phase of the Louvain
method, we can obtain better results using LAMBDALOUVAIN, but this signiﬁcantly increases the runtime. Meanwhile, for
MFP-CE, increasing the number of pivot rounding steps has only a small increase in runtime since the main bottleneck for
this method is the matching step for ﬁnding lower bounds. A more detailed comparison (speciﬁcally for the cluster editing
objective) is provided in Figure 5. Subﬁgures (a) and (c) are the same approximation and runtime plots from the main text,
showing results for the fastest settings for each method. Subﬁgures (b) and (d) show results for running LAMBDALOUVAIN
when the number of passes over the nodes is increased to 10, and where we also apply the second phase of the algorithm.
These plots also show results for running MFP-CE with 50 pivot steps for rounding. Running these algorithms longer leads

Correlation Clustering via Strong Triadic Closure Labeling

Table 4. Detailed cluster deletion results (n = |V |, and m = |E|). An asterisk next to the result of LP-STC indicates this LP relaxation
returns an optimal solution for the canonical cluster deletion LP relaxation. Dashed lines indicate the method ran out of memory.

Graph

NETSCIENCE

n = 379
m = 914

ERDOS991

n = 446
m = 1413

CELEGANS-
METABOLIC
n = 453
m = 2025

HARVARD500

n = 500
m = 2043

CELEGANS-
NEURAL
n = 297
m = 2148

ROGET

n = 994
m = 3640

SMAGRI

n = 1024
m = 4916

EMAIL

n = 1133
m = 5451

CA-GRQC

n = 5242
m = 14484

CALTECH36

n = 769
m = 16656

POLBLOGS

n = 1222
m = 16714

REED98

n = 962
m = 18812

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

356.5
605.0
1.697
0.0231

315
669
2.124
0.00365

MFP-CD LP-STC LP-CD
356.5∗
597.0
1.675
0.0117
701.0∗
1372.0
1.957
0.0513

674
1338
1.985
0.000419

701.0
1378.0
1.966
0.101

966
1917
1.984
0.00058

776
1548
1.995
0.00424

1062
2117
1.993
0.000474

1788
3571
1.997
0.00117

2410
4811
1.996
0.0015

2616
5169
1.976
0.00248

4789
10095
2.108
0.0674

8295
16613
2.003
0.101

8336
16660
1.999
0.00441

9369
18676
1.993
0.00434

996.5
1961.0
1.968
0.15
823.0∗
1584.0
1.925
0.092
1074.0∗
2148.0
2.0
0.107
1819.5∗
3623.0
1.991
0.141
2457.0∗
4909.0
1.998
0.435
2722.0∗
5430.0
1.995
0.234

5196.0
8598.0
1.655
0.559
8324.5∗
16648.0
2.0
4.36
8356.0∗
16705.0
1.999
4.64
9405.5∗
18811.0
2.0
4.79

996.5
1963.0
1.97
0.257

823.0
1584.0
1.925
0.252

1074.0
2148.0
2.0
0.196

1819.5
3624.0
1.992
0.143

2457.0
4910.0
1.998
0.58

2722.0
5432.0
1.996
0.478

5196.0
8620.0
1.659
2.2

8324.5
16648.0
2.0
9.56

8356.0
16706.0
1.999
9.48

9405.5
18811.0
2.0
9.24

Graph

CA-HEPTH

n = 8638
m = 24806

SIMMONS

n = 1518
m = 32988

HAVERFORD

n = 1446
m = 59589

SWARTHMORE

n = 1659
m = 61050

BOWDOIN

n = 2252
m = 84387

AMHERST

n = 2235
m = 90954

CONDMAT05

n = 36458
m = 171734

EMAILENRON

n = 36692
m = 183831

RICE31

n = 4087
m = 184828

CA-ASTROPH

n = 17903
m = 196972

LEHIGH96

n = 5075
m = 198347

LOC-
BRIGHTKITE
n = 58228
m = 214078

MFP-CD LP-STC

LP-CD

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

10673
21508
2.015
0.0848

16451
32919
2.001
0.02

29771
59508
1.999
0.0153

30500
61005
2.0
0.0292

42163
84298
1.999
0.0216

45450
90887
2.0
0.0227

72428
147826
2.041
0.433

84385
169793
2.012
0.398

92342
184692
2.0
0.0952

87563
178278
2.036
0.367

99082
198201
2.0
0.102

101924
204104
2.003
0.632

11320.5
21631.0
1.911
1.42
16490.0∗
32976.0
2.0
11.5
29794.5∗
59588.0
2.0
38.0
30524.0∗
61048.0
2.0
36.0
42192.5∗
84382.0
2.0
55.2
45477.0∗
90953.0
2.0
70.0

79287.5
152791.0
1.927
39.5

87861.0
173936.0
1.98
243.0
92410.5∗
184814.0
2.0
227.0

91188.0
174918.0
1.918
78.4
99172.5∗
198345.0
2.0
210.0

106429.0
211219.0
1.985
151.0

11320.5
21712.0
1.918
2.38

16490.0
32976.0
2.0
18.5

29794.5
59588.0
2.0
110.0

30524.0
61048.0
2.0
68.4

42192.5
84382.0
2.0
114.0

45477.0
90953.0
2.0
162.0

79287.5
153446.0
1.935
72.5

87861.0
174035.0
1.981
391.0

–
–
–
–

91188.0
174802.0
1.917
376.0

99172.5
198345.0
2.0
1420.0

106429.0
211240.0
1.985
241.0

Correlation Clustering via Strong Triadic Closure Labeling

Table 5. Cluster editing (complete unweighted correlation clustering) results for smaller graphs. An asterisk next to the result of LP-STC+
indicates this LP relaxation returns an optimal solution for the canonical cluster editing LP relaxation for the given graph. Value n
denotes number of nodes, m is the number of edges, LB is the lower bound returned by the method, UB is the upper bound achieved
by rounding the lower bound, and Ratio = LB/UB is the a posteriori approximation guarantee. Runtime is given is seconds. We apply
three ways to round the lower bound of MFP-CE. The ﬁrst two are our own randomized (+piv ( ˆG)) and deterministic (det., Algorithm 8)
rounding strategies, which apply randomized and deterministic pivoting methods to a derived graph ˆG. The third (+piv (G)) is simply
running PIVOT on the original graph. For LP-STC+, we apply both our own randomized pivoting procedure (+piv ( ˆG)), to a derived
graph ˆG that differs from the derived graph generated by MFP-CE, as well as the rounding procedure that is guaranteed to output a 2.06
approximation (CMSY) if applied to the cluster editing LP (Chawla et al., 2015). The deterministic rounding for MFP-CE is slow as it is a
proof-of-concept implementation, and not optimized.

Graph

HARVARD500

n = 500
m = 2043

CELEGANSNEURAL

n = 297
m = 2148

ROGET

n = 994
m = 3640

SMAGRI

n = 1024
m = 4916

EMAIL

n = 1133
m = 5451

CA-GRQC

n = 5242
m = 14484

CALTECH36

n = 769
m = 16656

POLBLOGS

n = 1222
m = 16714

REED98

n = 962
m = 18812

CAHEPTH

n = 8638
m = 24806

MFP-CE
LP-STC+
+piv ( ˆG) +det. +piv (G) +piv ( ˆG)

LP-CE

+CMSY +CMSY

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

687
1832
2.667
0.00333

1055
2593
2.458
0.012

1786
4654
2.606
0.00663

2403
6084
2.532
0.00845

2606
6729
2.582
0.00997

4551
12414
2.728
0.0239

8239
18835
2.286
0.0277

8309
18869
2.271
0.0299

9338
21805
2.335
0.0311

10609
29049
2.738
0.049

1547
2.252
0.0368

1331
1.937
0.00381

2341
2.219
0.0299

2118
2.008
0.00435

4061
2.274
0.174

5330
2.218
0.282

5692
2.184
0.302

9268
2.036
7.5

17204
2.088
2.2

17312
2.084
4.5

19511
2.089
2.5

23442
2.21
12.0

3873
2.169
0.00949

5166
2.15
0.0103

5859
2.248
0.0105

8610
1.892
0.0358

17166
2.084
0.0167

17664
2.126
0.0182

20386
2.183
0.0186

22214
2.094
0.0582

727.0∗
1395
1.919
0.419
1074.0∗
2148
2.0
0.58
1819.5∗
3621
1.99
0.632
2457.0∗
4905
1.996
2.6
2722.0∗
5429
1.994
1.4

4931.0
8311
1.685
15.4
8324.5∗
16648
2.0
118.9
8356.0∗
16710
2.0
63.9
9405.5∗
18811
2.0
67.3

11289.8
21625
1.915
62.6

1303
1.792
0.426

2092
1.948
0.583

3442
1.892
0.656

4851
1.974
2.6

5269
1.936
1.4

7595
1.54
15.9

17085
2.052
118.9

17212
2.06
64.0

19723
2.097
67.4

20470
1.813
64.1

727.0
1321
1.817
0.451

1074.0
2100
1.955
0.59

1819.5
3413
1.876
0.844

2457.0
4817
1.961
2.8

2722.0
5357
1.968
1.7

4931.0
7741
1.57
73.4

8324.5
16891
2.029
119.1

8356.0
17132
2.05
64.4

9405.5
19385
2.061
67.7

11290.5
20597
1.824
562.1

Correlation Clustering via Strong Triadic Closure Labeling

Table 6. Cluster editing (complete unweighted correlation clustering) results for larger graphs. Dashed lines indicate that the method ran
out of memory. See caption of Table 5 for more information about each column and row meaning.

MFP-CE
+piv ( ˆG) +det.

LP-STC+
+piv (G) +piv ( ˆG)
16490.0∗
32977
2.0
235.8

37919
2.312
0.0263

LP-CE

+CMSY +CMSY

34374
2.085
235.9

16490.0
34391
2.086
236.9

Graph

SIMMONS81

n = 1518
m = 32988

HAVERFORD76

n = 1446
m = 59589

SWARTHMORE42

n = 1659
m = 61050

BOWDOIN47

n = 2252
m = 84387

AMHERST41

n = 2235
m = 90954

CONDMAT2005

n = 36458
m = 171734

EMAILENRON

n = 36692
m = 183831

RICE31

n = 4087
m = 184828

CA-ASTROPH

n = 17903
m = 196972

LEHIGH96

n = 5075
m = 198347

LOC-BRIGHTKITE

n = 58228
m = 214078

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

LB
UB
Ratio
Run

16402
38856
2.369
0.0645

29676
68742
2.316
0.133

30411
70247
2.31
0.125

42077
99161
2.357
0.17

45346
105353
2.323
0.226

71658
200854
2.803
0.36

83991
221420
2.636
0.428

92199
219129
2.377
0.447

86369
225943
2.616
0.488

98929
237145
2.397
0.489

101544
267453
2.634
0.559

34424
2.099
6.8

61494
2.072
14.0

63138
2.076
16.3

87449
2.078
36.6

93857
2.07
39.4

67437
2.272
0.0611

69110
2.273
0.0475

98881
2.35
0.0668

103404
2.28
0.0967

151017
2.107
354.2

161977
2.26
0.308

182653
2.175
828.4

184296
2.194
0.334

189818
2.059
170.9

218071
2.365
0.212

178356
2.065
496.8

186697
2.162
0.302

204838
2.071
203.3

241219
2.438
0.226

221993
2.186
1287.9

239849
2.362
0.493

–
–
–
–

–
–
–
–

–
–
–
–

–
–
–
–

–
–
–
–

–
–
–
–

–
–
–
–

–
–
–
–

–
–
–
–

–
–
–
–

–
–
–

–
–
–

–
–
–

–
–
–

–
–
–

–
–
–

–
–
–

–
–
–

–
–
–

–
–
–

–
–
–
–

–
–
–
–

–
–
–
–

–
–
–
–

–
–
–
–

–
–
–
–

–
–
–
–

–
–
–
–

–
–
–
–

–
–
–
–

Correlation Clustering via Strong Triadic Closure Labeling

(a) Alg Fastest (Runtime)

(b) Alg Better Quality (Runtime)

(c) Alg Fastest (Ratios)

(d) Alg Better Quality (Ratios)

Figure 5. Approximation ratios and runtimes for MFP-CE and Louvain heuristics (Louv-MFP) on Facebook100 graphs. In (a) and (c), we
use the fastest settings for each algorithm. For (b) and (d), we run the algorithms longer to obtain improved guarantees. Running the
greedy Louvain heuristics longer leads to slightly improved guarantees at the expense of a signiﬁcantly increased runtime.

to slight improvements to approximation ratios, though the results are qualitatively very similar. The runtime for MFP-CE is
affected only slightly, but this increases the runtime for LAMBDALOUVAIN by an order of magnitude.

C.5. Additional Details for PACE Challenge Graphs

Details and results from the original PACE challenge are available online at https://pacechallenge.org/2021/
tracks/. The KaPoCE algorithm was the winning method both for the exact and heuristic track of this challenge, so
we focus on comparing against this method (https://github.com/kittobi1992/cluster_editing). The
results displayed in the main text are for a subset of the benchmark graphs used for the heuristic track of the PACE challenge.
In particular, we use odd-instance graphs from 1 to 57 (the even instance graphs were hidden and used as test cases for the
challenge). These correspond to available benchmark graphs with fewer than 500 nodes. We capped the runtime of the
heuristic version of KaPoCE to 10 minutes. Even for these small graphs, there were several cases where the algorithm
reached this maximum runtime. The heuristic KaPoCE algorithm obtains high quality solutions in terms of the cluster
editing objective, but comes with no approximation guarantees of its own and does not scale to large graphs. Overall,
our experiments illustrate that PACE challenge algorithms are simply focused on an alternative task—ﬁnding high quality
solutions for small problems, rather than obtaining approximate solutions at a large scale.

