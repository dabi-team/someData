Recovery of Meteorites Using an Autonomous Drone and Machine
Learning

Robert I. Citron1, Peter Jenniskens2, Christopher Watkins3, Sravanthi Sinha4, Amar Shah5, Chedy
Raissi6, Hadrien Devillepoix7, and Jim Albers2

1Department of Earth and Planetary Sciences, University of California, Davis 95616, USA.
2SETI Institute, Carl Sagan Center, Mountain View, CA 94043, USA; NASA Ames Research Center, Moﬀett
Field, CA 94035, USA.
3Commonwealth Scientiﬁc and Industrial Research Organisation, Scientiﬁc Computing, Clayton, VIC 3800,
Australia.
4Holberton School of Software Engineering, San Francisco, CA 94111, USA.
5Cambridge University, Dep. of Engineering, Computational and Biological Learning, Cambridge, CB2 1PZ, UK.
6Institut National de Recherche en Informatique et en Automatique, France.
7Space Science Technology Centre, School of Earth and Planetary Sciences, Curtin University, GPO Box U1987,
Perth, Western Australia 6845, Australia.

June 11, 2021

Abstract

The recovery of freshly fallen meteorites from tracked and triangulated meteors is critical to deter-
mining their source asteroid families. However, locating meteorite fragments in strewn ﬁelds remains a
challenge with very few meteorites being recovered from the meteors triangulated in past and ongoing
meteor camera networks. We examined if locating meteorites can be automated using machine learning
and an autonomous drone. Drones can be programmed to ﬂy a grid search pattern and take systematic
pictures of the ground over a large survey area. Those images can be analyzed using a machine learning
classiﬁer to identify meteorites in the ﬁeld among many other features. Here, we describe a proof-of-
concept meteorite classiﬁer that deploys oﬀ-line a combination of diﬀerent convolution neural networks
to recognize meteorites from images taken by drones in the ﬁeld. The system was implemented in a
conceptual drone setup and tested in the suspected strewn ﬁeld of a recent meteorite fall near Walker
Lake, Nevada.

1

Introduction

There is an ongoing eﬀort to determine the composition of some 40 asteroid families in the asteroid belt
to understand the early evolution of the solar system. Remote sensing information is complemented with
data gleaned from laboratory studies of meteorites. To put that meteoritic data in context, the approach
orbit of freshly fallen meteorites are measured to determine what asteroid family might have produced the
meteoritic debris from a particular collision event. This is a statistical eﬀort to determine the inclination and
semi-major axis distribution of the approach orbits of meteorites of the same type with the same collision
age. The inclination identiﬁes the inclination of the source region, while the semi-major axis points to the
delivery resonance (Jenniskens, 2013).

If the meteorite can be recovered, a ﬁreball’s lightcurve and deceleration proﬁle also provides information
about how its kinetic energy is deposited in the Earth’s atmosphere, which is a function of density and
internal strength. That information can be used to improve predictions at what altitude asteroids of this
material type fragment that are big enough to cause damaging airbursts (Popova et al., 2013).

So far, in only about 40 cases have meteorites been recovered from observed falls for which the ﬁreball
trajectory in the atmosphere and pre-impact orbit were measured (Boroviˇcka et al., 2015; Jenniskens, 2013).

1

Many of those are cases where the meteorite was found after which the ﬁreball data was obtained from
serendipitous security or dash-cam footage. Until now, various ﬁreball networks have recorded approximately
800 trajectories of meteoroids signiﬁcant enough to have dropped meteorites on the ground, of which only
∼26 cases (3%) resulted in meteorite recovery.

Finding meteorites from an observed fall can be very diﬃcult. Meteorites are scattered over many square
kilometer large strewn ﬁelds and typically are found only through a physical survey, taking ∼ 100 man-hours
to locate one meteorite fragment. The investment of that time is made more often when the falling meteorites
are detected by Doppler weather radar, as it gives conﬁdence that meteorites survived to the ground (e.g.,
Jenniskens et al., 2012).

In order to increase the recovery yield of the more frequent smaller falls, a more eﬃcient method of
searching for freshly fallen meteorites is required. Recent advances in autonomous drone technology and
machine learning image classiﬁcation algorithms have enabled the possibility for autonomous meteorite
fragment localization. Autonomous quadcopter drones can navigate terrain at a ﬁxed height, obtaining a
survey of top-down images. These images can be spliced and fed into a machine learning object detection
classiﬁer, which can determine the likelihood that meteorite fragments are present in the image. Using a
machine learning object detection model coupled with an autonomous drone, it may be possible to reduce
the man-hours needed to locate freshly fallen meteorites, and increase the likelihood of locating meteorites
in strewn ﬁelds.

1.1 Prior work

The use of drones surveys to locate freshly fallen meteorite fragments has gained increasing traction in recent
years (Citron et al., 2017; Zender et al., 2018; AlOwais et al., 2019; Anderson et al., 2020). The general
method of detecting meteorites with a drone survey involves applying a machine learning classiﬁer to images
taken from an autonomous drone that ﬁrst surveys the area at low altitude (Citron et al., 2017). With a
suﬃcient ﬁeld of view and image resolution, each 1-3 cm meteorite fragment should be resolved by >20 pixels
in width, suﬃcient for image classiﬁcation. If a machine learning classiﬁer can be eﬀectively trained to locate
meteorites in drone-acquired images, a survey of aerial photos can be spliced and classiﬁed to determine if
any meteorite fragments are present.

Training a machine learning classiﬁer to detect freshly fallen meteorite fragments presets a challenge.
The main identifying characteristic of a meteorite fragment is that it should appear to not belong in the
surrounding terrain. Although freshly fallen meteorite fragments should appear quite distinct from native
rocks, meteorites are diverse and it is impossible to know the characteristics of the next freshly fallen
meteorite fragments or the surrounding terrain. While meteorites typically are darker than native rocks due
to the fusion crust obtained during atmospheric entry, some meteorite fragments lack a fusion crust because
of subsequent break-up. The challenge is also that meteorite strewn ﬁelds can result in search areas several
square kilometers. In such a search area, there may be only a few meteorite fragments 1-3 cm in size. A
machine learning classiﬁer therefore must be versatile enough to detect meteorites of a variety of types on
completely new terrains, and return suﬃciently low false positive detections to make a square kilometer
survey feasible.

The construction of a machine learning classiﬁer to identify meteorite fragments from native terrain
should be feasible, and several groups have tested the application of machine learning to meteorite detection
in the ﬁeld (Citron et al., 2017; AlOwais et al., 2019; Anderson et al., 2019; Anderson et al., 2020). The
most suitable machine learning classiﬁer for meteorite identiﬁcation might be based on convolutional neural
networks (LeCun et al., 1998), which have achieved state of the art performance in a variety of computer
vision based tasks (Gu et al., 2018). A classiﬁer based on convolution neural networks avoids problems
associated with hand picking features, which would be inadequate for meteorite identiﬁcation because of the
diverse possible properties of meteorite fragments. The key beneﬁt of a neural network based classiﬁer is
that it is trained to learn the features most relevant for its task jointly with the output predictions it makes.
Thus, by applying deep learning algorithms to the task of discriminating between images of patches of land
with and without meteorites, a general classiﬁer can be constructed to identify a freshly fallen meteorite
fragment on most terrains.

There are two main types of machine learning models applied to object recognition: binary image clas-
siﬁers or object detection networks. A binary image classiﬁer utilizes the entire image to determine what

2

object it represents. Binary image classiﬁers are trained on sets of ‘positive’ and ‘negative’ images, and when
a trained binary classiﬁcation network is applied to a new image it determines the likelihood the image falls
in the ‘positive’ or ‘negative’ category (i.e., if the image is of a meteorite or not). For this type of classiﬁer
to work the meteorite must encompass most of the image, therefore the network must be applied to small
image patches. A large image acquired by a drone must therefore be spliced into multiple smaller image
patches before being fed into the classiﬁer (Citron et al., 2017). Alternatively, an object detection network
may be used. Object detection networks are trained on sets of larger images where each class of object is
demarcated (usually by a box) within each training image. Instead of training on separate sets of positive
and negative images, the object detection network learns to recognize classes of objects (or a single class of
objects, e.g.meteorites) marked within each image as ’positives’ and the rest of the image where the object
class is not highlighted is eﬀectively ‘negative’. When a trained object detection network is applied to a new
image it outputs a box around each section of the image where it predicts the object classes are located.
Object detection networks can be fed an image of any size and locate an object within the image. This is
more time eﬃcient because each drone acquired image does not need to be spliced into smaller fragments
that need to be classiﬁed independently.

Several studies have tested the use of a machine learning classiﬁer to ﬁnd freshly fallen meteorite frag-
ments. An earlier version of our system was tested in Creston, California (Citron et al., 2017), however, that
iteration used binary image classiﬁer that required each image to be spliced into ∼64x64 pixel patches before
classiﬁcation. This resulted in long processing times for each full image. Furthermore, many false positives
were detected, depending on the terrain type. Zender et al. (2018) also tested meteorite detection using a
drone mounted camera, but did not use a machine learning classiﬁer and instead applied a simple algorithm
based on reﬂectance characteristics. AlOwais et al. (2019) performed real-time detection of meteorites by
implementing a machine learning algorithm on board a drone. Their algorithm processed images from a
live video feed and achieved an accuracy of ∼ 90%. Anderson et al. (2020) implemented the Keras machine
learning module applied to 200x200 pixel tiles spliced from drone-acquired images. They constructed a
training dataset by pasting meteorite images into drone-acquired images of the local terrain and trained a
binary image classiﬁer to identify meteorite fragments with validation accuracy of ∼97%. In a ﬁeld test,
Anderson et al. (2020) used an RGB camera mounted on a multicopter to survey a searching area, covering
1 km2/day at a resolution of 1.8 mm/pix. Their machine learning approach was able to correctly identify 3
real meteorites (two falls, one ﬁnd) in their native fall locations.

Machine learning is a rapidly advancing ﬁeld and is providing new tools to increase the accuracy of object
detection and classiﬁcation. Of particular interest are residual neural networks, which have achieved excellent
performance in visual recognition tasks (He et al., 2015). Residual learning framework can be used to train
deeper neural networks capable of advanced object detection independent of the image size. Thus, instead
of training a binary image classiﬁer to examine many small patches (<200 pixels in width) (e.g., Citron
et al., 2017; Anderson et al., 2020), an eﬀective object detection network can be trained to recognize small
meteorite fragments in full images. Utilizing these recent advances, we train a residual neural network based
object detection network to recognize meteorite fragments in drone acquired images, and test its accuracy
in the ﬁeld.

Here, as a proof-of-concept, we construct an object detection network using images of meteorite fragments
collected from an autonomous drone. We chose an inexpensive oﬀ-the-shelf drone model (3DR) and camera
(GoPro Hero4) in hope that our algorithm could later be applied on a much bigger scale by owners of such
equipment. We show that classiﬁcation of meteorite fragments in drone images is possible, and test our
model at the location of a recent suspected strewn ﬁeld in Walker Lake, Nevada.

2 Methods

2.1 Constructing the Machine Learning Classiﬁer

2.1.1 Training Dataset

Any machine learning classiﬁer requires a large training data set of thousands of positive and negative images.
Because a future meteorite fall could occur on any type of terrain, and consist of any type of meteorite
fragment, we constructed a dataset containing a variety of meteorite types on a diverse set of terrains. A

3

classiﬁer trained on such a set of images could be readily applied to the classiﬁcation of images from a future
fresh meteorite fall. We used three sources for meteorite images to construct a large training dataset: 1)
placing a limited collection of 8 meteorite fragments in our possession on various local terrains and taking
overhead images of them, 2) placing our collection of 8 meteorite fragments in a recent meteorite strewn
ﬁeld and imaging them from above with a drone, and 3) using overhead shots of freshly fallen meteorite
fragments obtained from an internet search.

For collecting images of meteorite fragments on local terrains, we used our collection 8 meteorite fragments
10-100 g in mass (1-4 cm in diameter) obtained fresh from the 1992 Mbale meteorite fall Jenniskens et al.
(1994). The meteorites were deployed on various local grass, dirt, sand, and rocky terrains, and imaged with
smart phone cameras and a DSLR from above at a similar height as the expected drone images. Each image
was spliced into smaller patches of 1000x600 pixels. Although the object detection network described in
Section 2.2 could work on images of any size, we found that processing was limited by the computer memory
requirements during image classiﬁcation, and 1000x600 pixel image patches resulted in good performance.
Examples of image patches containing meteorites used in training the object detection classiﬁer are shown
in Figure 1a. We used 526 image patches with meteorites placed on various local terrains and imaged from
above.

The second source of test images was from a previous test of an earlier iteration of our machine learning
classiﬁer. During this prior test, we deployed our meteorite fragments in the location of a recent meteorite
fall near Creston, California and imaged the fragments from above with a drone-mounted camera (Citron
et al., 2017). For the updated object detection classiﬁer described in this paper, we used the images from
our previous test as an additional data source to train our new classiﬁer. Because these images were taken
with the same camera and drone system, they are more applicable to future ﬁeld deployments and of high
value to training our updated model. Each image was spliced into smaller 1000x600 pixel image patches
before being added to the training dataset. Example training data from our ﬁeld test are shown in Figure
1b. We used 82 image patches obtained from a drone-mounted camera during our ﬁeld test in Creston, CA.
The third source of training images was obtained from an internet search for pictures of freshly fallen
meteorites. The use of images of meteorites obtained from the web was critical because we did not want to
overtrain our object detection network on the 8 meteorites in our collection. By using images of meteorites
from various falls worldwide, we were able to include in our data a variety of diﬀerent meteorite types and
background terrains, enhancing our ability to deploy our machine learning algorithm at the site of a future
fresh fall. The meteorite images obtained online were re-scaled or cropped so that each image patch was
1000x600 pixels, to construct a training dataset of similar image sizes. Overall, we used 155 image patches
from meteorite images collected from the web. Examples of pictures of meteorites obtained from the web
are shown in Figure 1c.

Overall, our training dataset contained 526 images of our 8 fragments placed on local terrains, 82 images
of our 8 fragments taken during a ﬁeld test, and 154 images of meteorites obtained from an internet web
search. These image sources were combined into a single dataset of 762 images. The training data set was
separated into a training and validation subset. The validation subset was 150 images randomly selected
images (∼ 20% of the full dataset) and the training subset was the remaining 612 images. Because the
number of meteorite images in our dataset was limited, we augmented the training dataset by reﬂecting each
image across the horizontal plane, vertical plane, and both the horizontal and vertical planes, resulting in a
total of 2448 images in the training dataset.

2.2 Training the Object Detection network

For meteorite detection, we use the RetinaNet object detection network (Lin et al., 2017). RetinaNet is
a highly eﬃcient object detection network that is built upon the ResNet deep residual neural network
architecture (He et al., 2015). The implementation of RetinaNet utilizes the Keras (Chollet, 2015), Caﬀe
(Jia et al., 2014), and Tensorﬂow (Abadi et al., 2015) software packages. We use the ResNet-50 backend (He
et al., 2015) which is pre-trained using a dataset of roughly 15 million images called ImageNet (Russakovsky
et al., 2014). This approach means that from initializing our training phase, the object detection network
would already be familiar with objects such as grass, rocks, hay, etc, and would not have to learn their
features from scratch. We took the pre-trained model and trained it on our dataset of meteorite images
for several epochs with RetinaNet in order to obtain a ﬁnal object detection model. We trained the model

4

search area. The user can then scan through the image patches and ﬂag particularly strong candidates for
follow-up.

2.3 Drone hardware and ﬁeld deployment
The drone currently used in our deployment is the 3DR Solo quadcopter drone ﬁtted with a gimbal-mounted
GoPro HERO 4 camera. Because of the hilly terrain in much of California, we upgraded the 3DR Solo
drone with a laser altimeter and the PixHawk GreenCube ﬂight controller capable of running Arducopter
3.4. The use of the Arducopter 3.4 equipped ﬂight controller and the laser altimeter allowed the drone to
use true terrain following to maintain a constant elevation above the ground. We upgraded the GoPro with
a narrow-angle lens oﬀering a 87 degree ﬁeld of view. Flying at a height of 3 m with the 4000x3000 pixel
GoPro camera, this yields a resolution of 0.97 mm/pixel. At 6 m, the resolution is 1.95 mm/pixel. The
desired resolution is ∼ 20 pixels across a meteorite fragment, so the drone was ﬂown at 3 m when searching
for smaller fragments ∼ 2 cm across (10-20 g) and 6 m when searching for larger fragments > 4 cm across
(75-150 g).

Each drone survey was programmed with the Mission Planner software, which allowed us to pre-fetch the
map data prior to ﬁeld deployment. During ﬁeld deployment we programmed the drone to ﬂy a grid-search
pattern and take photos from a constant altitude of 2−6 m. Because of the battery-limited ∼ 25 minute ﬂight
time of the 3DR Solo drone, each grid survey acquired ∼ 130 to 250 images, depending on the ﬂight altitude
and search pattern. Because our object detection classiﬁer identiﬁes many false meteorite candidates, the
user must scan through the processed images to determine which candidates are worth following up with
another ﬁeld visit. Each image is tagged with a timestamp that can be compared to the drone’s GPS log to
determine the approximate location where the image was acquired. Although in principal it is possible to
process the images and scan for candidates in the ﬁeld, we found this was more easily accomplished out of
the ﬁeld. Our system of deployment was to acquire images for a full day and process the images during the
evening, when potential meteorite candidates were ﬂagged for follow-up during a second trip to the ﬁeld site
the next day.

3 Field Test and Results

3.1 Potential meteorite fall at Walker Lake, NV

On July 14, 2019, at 09:36:50 UTC, a bright meteor of 4.1 second duration was captured by four stations of
the NASA Meteorite Tracking and Recovery Network, part of the Global Fireball Observatory. The ﬁreball
track was detected from stations at Lick Observatory, Mt. Umunhum, Sunnyvale, and the Allen Telescope
Array (Figure 2). The images were calibrated and the meteor track extracted (Devillepoix et al., 2020). The
beginning height of the meteor was at 82.054 km and the end height of 27.066 km over the Sierra Nevada
mountains. The approach orbit was asteroidal, with a = 2.358 +/- 0.032 AU and i = 10.72 +/- 0.08 degrees.
The entry speed was relatively high at 21.937 +/- 0.114 km/s, but the surviving mass was calculated to be
as much as 35.3 +/- 3.7 kg (EKS model (Devillepoix et al., 2020)). The meteor had a 41◦ slope with lateral
uncertainty in the trajectory of order 250-m due to a relatively large minimum distance of 275 km between
the meteor and the stations.

Analysis of the wind drift during the dark ﬂight calculations were done using the Oakland Wind sonde
data before and after the time of fall, using the software WIND with an assumed density of 3.2 g/cm3.
This resulted in expected fragments of 1g, 10g, 100g, and 1 kg located near Walker Lake, Nevada within
the Walker River Indian Reservation of the Walker River Paiute Tribe, headquartered at Schurz, NV. The
expected strewn ﬁeld location is shown in Figure 3. Solutions were calculated starting falling from the ﬁnal
ﬂare (white markers and from the ﬁnal observed point of the trajectory (blue). Winds in this case were
such that small meteorites were blown towards the larger ones, shortening the strewn ﬁeld. The area is a
former lake bed of Walker Lake and has sand dunes and stretches of rock-strewn ﬂat areas. The vegetation
is minimal, but increases in density towards the river.

6

Figure 2: NASA Meteorite Tracking and Recovery imaging of the 2019 July 14 bolide from A: Lick Obser-
vatory, B: Mount Umunhum, C: Alan Telescope Array, D: Sunnyvale - early part, E: Sunnyvale -late part of
bolide.

3.2 Field test
We received permission to conducted a ﬁeld test of our meteorite classiﬁcation system in Walker Lake,
Nevada, the site of a meteorite fall on July 14, 2019 (Figure 3). Overall we conducted 10 test ﬂights at
two diﬀerent sites within the expected strewn ﬁeld. Site A was near the 10g marker in Figure 3, where
we expected 1-20g fragments. Site B was near the 100g marker in Figure 3, where we expected 50-150g
fragments. Due to the smaller expected fragment size at Site A, we ﬂew the drown at a lower altitude (2-3
m). At Site A we also deployed our collection of 8 meteorite fragments during each test ﬂight to conﬁrm our
ability to detect the meteorites used to train our classiﬁer on a new terrain type. At Site B we conducted
higher altitude (3-6 m) surveys to cover a larger area and potentially ﬁnd a single large fragment ∼ 100 g.
A summary of the 10 test ﬂights and results is shown in Table 1. Four tests were conducted at Site
A, three at 2 m and one at 3 m. Six tests ﬂights were conducted at Site B, two at 3 m and four at 6 m.
During each test ﬂight the drone acquired images for ∼ 20 minutes, limited by the battery life of the drone.
Each test ﬂight acquired 129-388 full GoPro images. These full 4000x3000 pixel images were spliced into
overlapping image patches 1000x600 pixels. The image patches were analyzed with the trained RetinaNet
model. An image patch was classiﬁed as ‘positive’ if it contained an object classiﬁed as a meteorite with
a score of 0.5 or higher, and all other image patches were classiﬁed as ‘negative’. The number of positive
and negative image patches is listed in Table 1. Each test ﬂight resulted in a large number of image patches
classiﬁed as positive. This was particularly true for the low-altitude ﬂights, where there were on average ∼
2650 positive patches per test ﬂight (∼ 28% of the all patches). This is mostly due to the large number of
other rocks in the survey area, and illustrates the diﬃculty of locating meteorite remotely on rocky terrain.
The higher altitude ﬂights (6 m) resulted in less positive patches, with an average of ∼ 1112 positive patches
per test ﬂight (∼ 12% of the all patches). Test Flight 5 contained around three times as many positive
patches as the other 6 m ﬂights, which was likely due to the more rocky terrain in the Test 5 ﬂight path.

The results illustrated in Table 1 show that RetinaNet returns a large number of false positives for a given
search area. For the 2−3 m Test Flights, the number of positive patches returned was prohibitive, meaning
that the thousands of positive patches ﬂagged for follow-up is too cumbersome to sort through and identify
expected meteorite fragments. For the 6 m test ﬂights, the number of positive patches was suﬃciently low
to allow a user to quickly scan through the positive image patches and identify fragments to follow-up with
an in-ﬁeld visit.

Apart from generally determining the number of positive patches during ﬁeld surveys, we conducted two
critical tests to determine the feasibility of using our system in the ﬁeld. The ﬁrst test was to deploy our
collection of known meteorite fragments in the drone survey path and test the ability of our machine learning

7

Figure 3: Map of the expected Walker Lake strewn ﬁeld. The while line indicates the ﬁnal part of the meteor
trajectory based on NASA Meteorite Tracking and Reocvery imagery. The yellow line is an extension. The
dots mark the anticipated location for meteorites falling from the ﬁnal ﬂare (white markers) and the end
point (blue markers), based on Oakland wind sonde data and the WIND darkﬂight model.

Test
1
2
3
4
5
6
7
8
9
10

Site Altitude (m)
A
A
A
A
B
B
B
B
B
B

2
2
2
3
3
3
6
6
6
6

Table 1: Field test runs

Images Total patches Positives Negatives

256
245
288
145
135
129
214
175
190
225

12240
11232
13824
6960
6480
6192
10272
8400
9120
10800

3553
2322
1328
679
2019
2769
2377
875
399
800

8687
8910
12496
6281
4461
3423
7895
7525
8721
10000

algorithm to correctly identify these fragments on novel terrain. The second test was to scan through the
most likely meteorite candidates ﬂagged by our trained RetinaNet model and attempt to relocate them in
the ﬁeld based on the drone-acquired images and geolocation determined from cross-referencing the image
timestamp and the drone GPS log.

To test the ability of our trained object detection network to correctly identify our collection of known
meteorite fragments on novel terrain, during each test survey at Site A we deployed several of the 8 meteorite
samples in our collection in the drone ﬂight path. An example image from a test survey in which the drone
ﬂew over the deployed meteorites is shown in Figure 4. As described in Section 2, each full GoPro image was
split into smaller 1000x600 pixel image patches that were run through the object detection model. Examples
of image patches containing correctly identiﬁed meteorites and false positives are shown in Figure 5. The two

8

Figure 4: Example image of two meteorites deployed during a ﬁeld test near Walker Lake, Nevada. The
meteorites are marked with orange ﬂags.

meteorites from Figure 4 were correctly identiﬁed in the smaller image patches and given a model score 1.0
by the object detection algorithm (Figure 5a). Several false positives were also identiﬁed with two examples
shown Figure 5b, which were given a score of 0.89 and 0.76. Overall, of the four low-altitude test ﬂights
where we deployed meteorite fragments in the survey path, our object detection model correctly located all
of the deployed meteorite fragments. This is not surprising because the meteorite fragments we deployed in
the ﬁeld were the same meteorite fragments used to train our model. However, we did deploy the meteorites
on completely new terrain than was used during the model training, illustrating the ability of our object
detection network to locate our meteorite samples on a new terrain not used in the training data.

To test our ability to locate candidate meteorite ﬂagged by our object detection algorithm in the ﬁeld, we
scanned through the positive image patches from the higher altitude (6 m) surveys conducted at Site B. We
identiﬁed three meteorite candidates to attempt to locate in the ﬁeld. The three drone images ﬂagged for
follow-up are shown in Figure 6 and Supplementary Figures A.1 and A.2. The GPS coordinates of the three
meteorite candidates were referenced to the drone ﬂight log to determine the expected GPS coordinates
where the images were acquired. During the a second trip to the ﬁeld the day after the ﬂight tests, we
visited the expected GPS coordinates of each of the three candidate meteorites and used the drone images
to locate the meteorites. We successfully located the three meteorite candidates. Close up images of the
three meteorite candidates located in the ﬁeld are shown in Figure 7. Only two of the three stones we had
ﬂagged appeared a good meteorite candidate upon closer in-situ examination (Figure 7 a and b). These two
meteorite were dark rocks, similar in appearance to meteorites. The candidate that was not a good match
to a meteorite fragment (Figure 7 c, corresponding to Supplementary Figure A.2) was on closer examination
a dark brush combined with a shadow. This illustrates that in some cases shadows, poor resolution, and
camera perspective can confuse the identiﬁcation of meteorite candidates. Still, two candidates showed a
good match to what might be expected from a fresh meteorite fall and were able to be located in the ﬁeld
after georeferencing the ﬂagged images. As a proof of concept, this illustrated our ability to locate in the

9

a) Correctly identified meteorites

b) False positives

Figure 5: Example 1000x600 pixel image patches from Figure 4 containing (a) correctly identiﬁed meteorites
(score = 1.0) that we placed in the test area from our collection and (b) false positives (scores = 0.89 and
0.76).

ﬁeld prospective meteorites that were ﬂagged in images acquired from prior ﬁeld surveys.

4 Discussion

Our ﬁeld deployment highlighted several areas of improvement in order to make drone searches for meteorite
fragments fully eﬀective. Our focus and the primary area of improvement is the object detection classiﬁer.
Because our local collection of meteor fragments was limited to 8 samples, with the exception of the training
data acquired from the web our training data was biased towards locating these 8 samples. Expanding
the training dataset to include more meteorite images from the web and more drone acquired images of
meteorites other than the 8 we had in our collection would increase the diversity of meteorites in the training
data. Every time the drone system is deployed in the ﬁeld it generates new data that can later be added to
the training data to create a newly trained object detection model. Bringing new meteorites not previously
in our collection and deploying them during ﬁeld tests would allow for continued improvement of our trained
object detection model, however, this option is limited by the availability of such meteorites. We also noticed
during our tests that the accuracy of the classiﬁer was related to several variables, including the resolution
of the training and test images. It is possible that an improved camera resolution or more stable height
control could decrease the amount of false positives.

In addition to updating the training dataset, the object detection network and method of training the
ﬁnal model could also be improved. For example, we could determine if certain iterations of training data
result in more eﬃcient object detection by training RetinaNet with varied training data sets, adjusting factors
such as the ratio of images acquired from the web to images of our collection of 8 fragments, or changing the
image resolution or size of the training data. We could also test other object detection networks to determine
if certain networks are more eﬃcient when trained on our dataset. Although RetinaNet represents the state
of the art in machine learning and is widely used in computer vision and object detection, machine learning
is a rapidly evolving ﬁeld and it is possible that a newer machine learning approach could be even more

10

 
 
Figure 6: Example image showing a candidate meteorite identiﬁed during the higher altitude ﬁeld test ﬂights.
The large image shows the full 4000x3000 pixel GoPro image obtained from the drone, with the candidate
meteorite circled in blue. The inset shows the enlarged 1000x600 pixel image patch run through the object
detection model with the meteorite outlined in a blue box (model likelihood = 1.0).

(a)

(b)

(c)

Figure 7: Images of meteorite candidates taken close-up with a DSLR camera after being geolocated in the
ﬁeld. Panels (a), (b), and (c) correspond to candidates in the drone imagery identiﬁed in Figure 6 and
Supplementary Figures A.1 and A.2, respectively.

eﬀective. Future work could more directly compare the eﬀectiveness of various types of object detection
networks.

In addition to improvements in the machine learning algorithm, our ﬁeld test identiﬁed some necessary
hardware improvements. We found that surveys at 2 or 3 m covered too small of an area to be particularly
eﬀective. These surveys also located more false positives than the 6 m surveys. However, the GoPro camera
was not at high enough resolution to be fully eﬀective for surveys conducted at 6 m altitude. Camera wobble

11

 
 
also contributed to minor image blur which made object detection more diﬃcult. To improve our system
requires a drone with an upgraded camera that can take higher resolution photos from 6 m. This is not
possible with the 3DR Solo Drone, which can only mount a GoPro camera, so a new drone system is required.
Unfortunately, there is no economical commercial drone that can use a laser altimeter to maintain constant
elevation above the ground, which is necessary to obtain a relatively uniform image resolution. However,
drone technology is continually being improved, so a new hardware solution that is within reach of regular
consumers may present itself in the future.

The original intention of the project was to process the images on-site with the object detection classiﬁer
so ﬂagged positives could be immediately checked during the same trip to the ﬁeld. However, our ﬁeld test
found this to be ineﬀective.
Images were diﬃcult to scan through in the ﬁeld on the laptop due to the
outdoor lighting conditions. The relatively fast image processing time of ∼ 6 s means that in theory images
could be processed at the same rate that they are acquired with drone ﬂights. However this requires a larger
team and more equipment (such as a power source for the laptop) so that one user could run the classiﬁer
on the images while another user conducts the next test ﬂight.

Overall, the object detection network deployed in this work presented a major improvement over the direct
image classiﬁer used in our previous ﬁeld test (Citron et al., 2017). Our results showed that the trained
RetinaNet object detection network was highly eﬀective on our dataset, and could locate meteorites on terrain
not used for training the model. RetinaNet reduced the image processing time and increased the accuracy
of our model. While the amount of false positives were still high, for 6 m ﬂights there was a suﬃciently low
number of positive image patches that a user could scan through the data in a reasonable timeframe and
ﬂag meteorite candidates for follow-up study. The ability to locate ﬂagged meteorites in subsequent ﬁeld
excursions demonstrates the system can be used to locate freshly fallen meteorite fragments.

5 Conclusions

We demonstrated that as a proof of concept, it is possible to identify meteorites in the ﬁeld by applying
an object detection classiﬁer to images acquired with an autonomous drone. As a ﬁrst step at automating
meteorite detection, we constructed a large dataset of meteorite images and trained an object detection
network. We demonstrated the accuracy of our classiﬁer in the ﬁeld over terrain not used in our training
dataset, and were able to locate meteorite candidates identiﬁed by our classiﬁer during subsequent ﬁeld trips.
With a larger training dataset, updated classiﬁcation scheme, and improved imaging hardware, machine
learning coupled to an autonomous drone survey could prove a valuable tool for increasing the number of
meteorite fragments found from fresh falls. This is particularly important for fresh meteorite falls where
only small fragments are expected. These falls are unlikely to draw the attention of meteorite hunters, but
if the fall is imaged with an all-sky survey, locating fragments is essential to augmenting the number of
freshly fallen meteorites with entry orbits computed from imaged ﬁreball trajectories. By constructing a
more eﬃcient classiﬁer for locating meteorites in the ﬁeld, it may be possible to increase the number of
meteorites found that can be associated with imaged ﬁreball trajectories, increasing our understanding of
the composition of meteors and their parent asteroid bodies.

Acknowledgements

This project was completed as part of the 2016 NASA Frontier Development Lab, which was supported by
the NASA Oﬃce of the Chief Technologist. We would like to thank Jason Utas for assistance with our prior
Creston, CA ﬁeld study. We also thank Fabio Teixeira and Brian Lim of Hypercube and Carlos Uranga for
help testing various drone designs. We thank James Parr and Jordan McRae, co-directors of FDL, as well
as Jim Adams, deputy chief technologist for NASA, Bruce Pittman, Chief Systems Engineer at NASA Ames
Research Center, Bill Diamond, CEO of the SETI Institute, Debbie Kolyer, Grants Manager of the SETI
Institute, Jonathan Knowles, explorer in Residence at Autodesk, Alison Lowndes, Deep Learning Solutions
for NVIDIA, Eric Dahlstrom, President of the International Space University, Yarin Gal, University of
Cambridge Research Fellow. The ﬁeld work was coordinated with the tribal leaders of the Walker River
Northern Paiute Tribe. We thank especially Cheri Clenneding and her interns for assisting in the search.

12

The Global Fireball Observatory is supported by the Australian Research Council. RC and PJ are supported
by NASA grant 80NSSC18K08.

References

Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., Davis, A., Dean, J.,
Devin, M., Ghemawat, S., Goodfellow, I., Harp, A., Irving, G., Isard, M., Jia, Y., Jozefowicz, R., Kaiser,
L., Kudlur, M., Levenberg, J., Man´e, D., Monga, R., Moore, S., Murray, D., Olah, C., Schuster, M.,
Shlens, J., Steiner, B., Sutskever, I., Talwar, K., Tucker, P., Vanhoucke, V., Vasudevan, V., Vi´egas, F.,
Vinyals, O., Warden, P., Wattenberg, M., Wicke, M., Yu, Y., Zheng, X., 2015. TensorFlow: Large-scale
machine learning on heterogeneous systems. Software available from tensorﬂow.org.

AlOwais, A., Naseem, S., Dawdi, T., Abdisalam, M., Elkalyoubi, Y., Adwan, A., Hassan, K., Fernini, I.,
2019. Meteorite hunting using deep learning and uavs, in: 2019 2nd International Conference on Signal
Processing and Information Security (ICSPIS), pp. 1–4.

Anderson, S., Towner, M., Bland, P., Haikings, C., Volante, W., Sansom, E., Devillepoix, H., Shober, P.,
Hartig, B., Cupak, M., Jansen-Sturgeon, T., Howie, R., Benedix, G., Deacon, G., 2020. Machine learning
for semi-automated meteorite recovery. arXiv:2009.13852.

Anderson, S.L., Bland, P.A., Towner, M.C., Paxman, J.P., 2019. Utilizing drones and machine learning for

meteorite searching and recovery, in: Lunar and Planetary Science Conference, p. 2426.

Boroviˇcka, J., Spurn`y, P., Brown, P., 2015. Small near-earth asteroids as a source of meteorites. Asteroids

IV 257. doi:10.azu uapress 9780816532131-ch014.

Chollet, F., 2015. Keras: Deep Learning library for Theano and TensorFlow. Github Repository .

Citron, R.I., Shah, A., Sinha, S., Watkins, C., Jenniskens, P., 2017. Meteorite Recovery Using an Autonomous

Drone and Machine Learning, in: Lunar and Planetary Science Conference, p. 2528.

Devillepoix, H., Cup´ak, M., Bland, P., Sansom, E., Towner, M., Howie, R., Hartig, B., Jansen-Sturgeon, T.,
Shober, P., Anderson, S., et al., 2020. A global ﬁreball observatory. Planetary and Space Science 191,
105036. doi:10.1016/j.pss.2020.105036.

Gu, J., Wang, Z., Kuen, J., Ma, L., Shahroudy, A., Shuai, B., Liu, T., Wang, X., Wang, G., Cai, J., et al.,

2018. Recent advances in convolutional neural networks. Pattern Recognition 77, 354–377.

He, K., Zhang, X., Ren, S., Sun, J., 2015. Deep residual learning for image recognition. arXiv:1512.03385.

Jenniskens, P., 2013. Recent documented meteorite falls, a review of meteorite–asteroid links, in: Meteoroids

2013: proceedings of the astronomical conference held at AM University, Poznan, pp. 57–68.

Jenniskens, P., Betlem, H., Betlem, J., Barifaijo, E., Schl¨uter, T., Hampton, C., Laubenstein, M., Kunz,
J., Heusser, G., 1994. The Mbale meteorite shower. Meteoritics 29, 246–254. doi:10.1111/j.1945-
5100.1994.tb00678.x.

Jenniskens, P., Fries, M.D., Yin, Q.Z., Zolensky, M., Krot, A.N., Sandford, S.A., Sears, D., Beauford, R.,
Ebel, D.S., Friedrich, J.M., Nagashima, K., Wimpenny, J., Yamakawa, A., Nishiizumi, K., Ohsumi, K.,
Cahill, T.A., Lawton, J.A., Barnes, D., Steele, A., Rochette, P., Verosub, K.L., Gattacceca, J., Cooper, G.,
Glavin, D.P., Smith, K., Silber, E.A., Brown, P.G., Albers, J., Klotz, D., Hankey, M., Matson, R., Fries,
J.A., Walker, R.J., Puchtel, I., Lee, C.T.A., Erdman, M.E., Eppich, G.R., Roeske, S., Gabelica, Z., Lerche,
M., Nuevo, M., Girten, B., Worden, S.P., 2012. Radar-Enabled Recovery of the Sutter’s Mill Meteorite, a
Carbonaceous Chondrite Regolith Breccia. Science 338, 1583–1587. doi:10.1126/science.1227163.

Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T.,
2014. Caﬀe: Convolutional architecture for fast feature embedding, in: Proceedings of the 22nd ACM
international conference on Multimedia, pp. 675–678.

13

LeCun, Y., Bottou, L., Bengio, Y., Haﬀner, P., 1998. Gradient-based learning applied to document recogni-

tion. Proceedings of the IEEE 86, 2278–2324.

Lin, T.Y., Goyal, P., Girshick, R., He, K., Doll´ar, P., 2017. Focal loss for dense object detection, in:

Proceedings of the IEEE international conference on computer vision, pp. 2980–2988.

Popova, O.P., Jenniskens, P., Emel’yanenko, V., Kartashova, A., Biryukov, E., Khaibrakhmanov, S., Shu-
valov, V., Rybnov, Y., Dudorov, A., Grokhovsky, V.I., et al., 2013. Chelyabinsk airburst, damage assess-
ment, meteorite recovery, and characterization. Science 342, 1069–1073. doi:10.1126/science.1242642.

Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla,
Imagenet large scale visual recognition challenge.

A., Bernstein, M., Berg, A.C., Fei-Fei, L., 2014.
arXiv:1409.0575.

Zender, J., Rudawska, R., Koschny, D., Drolshagen, G., Netjes, G.J., Bosch, M., Bijl, R., Crevecoeur, R.,
Bettonvil, F., 2018. Meteorite detection with airborne support—a study case, in: Proceedings of the
International Meteor Conference, pp. 145–152.

14

A Supplementary Figures

Figure A.1: Example image showing a candidate meteorite identiﬁed during the higher altitude ﬁeld test
ﬂights. The large image shows the full 4000x3000 pixel GoPro image obtained from the drone, with the
candidate meteorite circled in blue. The inset shows the enlarged 1000x600 pixel image patch run through
the object detection model with the meteorite outlined in a blue box (model likelihood = 0.992).

15

 
 
Figure A.2: Example image showing a candidate meteorite identiﬁed during the higher altitude ﬁeld test
ﬂights. The large image shows the full 4000x3000 pixel GoPro image obtained from the drone, with the
candidate meteorite circled in blue. The inset shows the enlarged 1000x600 pixel image patch run through
the object detection model with the meteorite outlined in a blue box (model likelihood = 0.992).

16

 
 
