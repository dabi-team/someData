0
2
0
2

r
a

M
2

]

A
M

.
s
c
[

6
v
1
6
9
0
0
.
5
0
9
1
:
v
i
X
r
a

An Elo-based rating system for TopCoder SRM

Fred Batty and Dmitry Kamenetsky
fbatty@gmail.com, dkamenetsky@gmail.com

March 3, 2020

Abstract

We present an Elo-based rating system for programming contests.
We justify a deﬁnition of performance using the logarithm of a player’s
rank. We apply the deﬁnition to rating TopCoder SRM. We improve the
accuracy, guided by experimental results. We compare results with SRM
ratings.

1

Introduction

SRM (single round matches) are regular programming contests organized
by TopCoder [1] since 2001. TopCoder has developed its own rating
system, which has been used throughout its 19 year history [2]. Various
shortcomings of SRM ratings have been documented on TopCoder forums
and elsewhere. Our purpose here is not to discuss these issues, but to
provide a concrete proposal to remedy them. Players have sometimes
asked: What would SRM ratings be if they were Elo-based? We would
like to obtain a reasonable answer to this question.

There isn’t a standard method for applying Elo ratings to rounds of
more than two players. We could consider a ranking of players as the
set of results between each pair of players. However, such results are
not independent from each others: a ranked result is the product of a
single performance by each player. Instead, we will consider the ranking
as a tournament. From desirable properties, we will deduce a formula for
performance in ranked games.

We then use this formula to speciﬁcally rate SRM. Our goal is to more

accurately predict the players’ performances after each round.

2 Performance

2.1 Rank performance

Let RP (n, r) be the performance of a player ranked r in a round of n
players. We consider the ranking as an elimination tournament, and count
the number of wins.

If the tournament has 2n players, the winner must win n 1-1 rounds,

so we have:

The player ranked 2 has one less win than rank 1:

RP (2n, 1) = n

(1)

1

 
 
 
 
 
 
RP (n, 2) = RP (n, 1) − 1

(2)

Multiplying both r and n by any k > 0 does not change the number

of wins:

RP (n, r) = RP (kn, kr)

With these constraints, we ﬁnd the only solution is:

RP (n, r) = log2 n − log2 r

(3)

(4)

2.2 Expectations

We use the standard Elo formula for expectations [3]. A player with rating
Ri is expected to outperform a player with rating Rj with probability:

WP (Ri, Rj) =

1
1 + 10(Rj −Ri)/400

(5)

As with SRM ratings, the rating of new players is initially 1200.

2.3 Ties

In programming contests like SRM, ties generally reﬂect a limitation of
the problem set or scoring, rather than an unexpected performance of the
tied players. We would like ties to not aﬀect the ratings.

We experimented with several accounting methods. We ﬁnd the most
accurate is to split the ties equally in actual and expected ranks, .5 in
each. Slightly less accurate is to compute expected ranks regardless of
ties, then split the tied ranks as is expected.

We now split the ties equally.

2.4 Relative performance

We have the results of a round, which may include multiple divisions and
ties. We consider the results of each division separately. The result of a
round is a list of scores S, where si is the score obtained by player i.

We compute rank and expected rank for each player i:

rties =

1
2

|{sj ∈ S : j (cid:54)= i, sj = si}|

r = 1 + |{s ∈ S : s > si}| + rties

ˆr = 1 +

(cid:88)

j:sj (cid:54)=si

WP (Rj, Ri) + rties

(6)

The relative performance of a player in the round is the diﬀerence of

actual and expected rank performance:

This can be written as:

P = RP (n, r) − RP (n, ˆr)

P (ˆr, r) = log2 ˆr − log2 r

(7)

(8)

The performance P equals a number of wins above or below expectations

in a tournament of appropriately matched players.

2

2.5 Properties

Figure 1: Rank performance

Rank performance is convex (Figure 1). The sum of performances of a
set of ranks is maximal if the ranks are distinct, and minimal if the ranks
are uncertain or tied. Having split ties equally in actual and expected
ranks, the expected ranks are at least as tied as the actual ranks. This
ensures the sum of performances in a round is positive or zero. We have:

(cid:88)

P ≥ 0

(9)

Figure 2: Relative performance

The rank is expected in logarithm (Figure 2). A player’s performance

may average 0 in several ways:

P (a, b) + P (b, c) + P (c, a) = 0
P (r, rxk) = k.P (r, rx)
P (ˆr, r) = P (kˆr, kr)

(10)

We will compute ∆R ∝ P , preserving these properties.

3

2.6 Accuracy

We deﬁne the prediction error for expected and actual ranks (ˆr, r):

E(ˆr, r) = |P | = | log2 ˆr − log2 r|

(11)

Our primary accuracy metric is the average error for all participants

in all rated rounds.

3 Proposed rating system

We have the performances of each player in a SRM. We would like to
compute rating changes ∆R which better predict future performances.

3.1

Initial factor

With a prior of 1 : 1, a performance P is outperforming expectations by
a factor 1 : 2P . A rating diﬀerence ∆R is expecting a better performance
by a factor 1 : 10∆R/400. We can convert the performances in rating units:

∆R =

P = K0 · P

400
log2 10
K0 ≈ 120

(12)

If we expected the same performances the next round, and had no
other information, this would be a reasonable ∆R. Thus we consider
∆R ∝ P as Elo-based or ’Elo’.

3.2 Fixed K

Figure 3: Fixed K

Here we compute ∆R = K · P , with K minimizing the error. We ﬁnd
the most accurate choice is K = 65 (Figure 3). As we add factors in ∆R,
we automatically adjust K to the most accurate.

3.3 Weight factor

A player’s prior rating should weigh in ∆R according to the player’s
experience. Let W be the weight, such that ∆R ∝ 1/W , and NR the
round number for the player, starting with 1. We experimented with

4

Figure 4: Weight factor

several possibilities, and ﬁnd the best results with W =
shows choices of W = NRα. Thus we choose W =
NR.

√

∆R = K ·

P
W

K = 182, the error is .7562.

3.4 Variance factor

√

NR. Figure 4

(13)

A player’s performance has variance for various reasons, not necessarily
predicting future performance. We compute the derivative of a player’s
expected performance per change in rating:

P = − log2 ˆr

dP
dR

= −

ˆr = 1 +

.

dˆr
dR

1
ln 2.ˆr
(cid:88)

wj

(14)

j(cid:54)=i

wj = WP (Rj, R)

We write the expected rank 1 as the loss:win ratio relative to the

player’s current rating:

ˆr(dR) = 10−dR/400 +

(cid:88)

1
1 + 10(R+dR−Rj )/400
(cid:88)

dˆr
dR

= −

dP
dR

=

ln 10
400
1
K0

.

wj(1 − wj))

(1 +
1 + (cid:80) wj(1 − wj)
1 + (cid:80) wj

In units of performance, we have:

P (cid:48) =

1 + (cid:80) wj(1 − wj)
1 + (cid:80) wj

Extrapolating linearly, we can solve P = 0 with ∆R = K0 · P

P (cid:48) .

• P (cid:48) ≤ 1, so ∆R = K0 · P may be conservative.
• P (cid:48) → 1 when ˆr → 1. No extrapolation is possible.

5

(15)

(16)

• P (cid:48) → 1

n when ˆr → n. Here P (cid:54)= 0 has bits of precision, hence more

likely predicts future performance.

We compute ∆R in a direction accounting for P (cid:48) and a multiplier C:

∆R ∝

P
1 + C · P (cid:48)

(17)

Figure 5: Choice of C

We ﬁnd the most accurate C ≈ 4 (Figure 5). Thus we choose C = 4.
We deﬁne the variance factor V = 1 + C · P (cid:48). We now have:

∆R =

K
V

·

P
W

(18)

K = 415, the error is .7536.

3.5 Maximum factor

An unexpected performance predicts future performance less reliably than
a consistent performance. The ratings gain accuracy if we limit the
magnitude of P to a maximum M using a sigmoid. A sigmoid preserves
symmetry, and exactly linearity of performance around 0. We deﬁne the
adjusted performance PA. We ﬁnd the best results with:

PA =

P
1 + |P |
M

(19)

We ﬁnd the most accurate M ≈ 6.75 (Figure 6). Thus we choose

M = 6.75. The rating change for each player is now:

∆R =

K
V

·

PA
W

(20)

K = 600, the error is .7513.

3.6 Natural inﬂation

We have computed ∆R ∝ P which make the ratings more accurate after
a round. Each player is expected a performance 0, thus has an expected
∆R = 0. The ratings are stable in expectation.

Because performances have a positive sum, more rating is won by the
outperforming players than is lost by the underperforming players. The

6

Figure 6: Choice of M

ratings have net inﬂation. Because the players gain experience during a
round, the players on average have better performances after the round.
Thus inﬂation better predicts future performance than deﬂation. Because
we minimized the prediction error, the average ∆R should approximately
predict the next performances of participants relative to non-participants.
We deﬁne this rate of inﬂation as natural inﬂation.

For comparison with SRM ratings, we consider natural inﬂation as
stable. We refer to this Elo-based implementation as ’Elo’ in our results.

’Elo’: K = 600; C = 4; M = 6.75

3.7 Stability

We have ∆R ∝ P , predicting the players’ relative performances. Now we
would like to estimate the performances over time, such that players with
stable performances have stable ratings. To maintain relative accuracy,
we will not adjust our current parameters.

3.8 Performance bonus

As long as ∆R ∝ P exactly, the expected rating change of any player is
zero. However, the expected performance in a round is a better performance
than not participating. Players having practiced already have better
performances before the round. Thus ∆R = 0 in expectation predicts
future performance less accurately than ∆R > 0.

We adjust the expectation to expect inﬂation, as if the ratings increased.
We choose a parameter B = ∆R, then add the diﬀerence in expected
performance to each player’s performance:

B
K0
We ﬁnd B ≈ 6 (Figure 7), and little accuracy can be gained from this

∆P =

· P (cid:48)

(21)

parameter alone.

3.9 New players

So far we have a constant rating R0 = 1200 for new players. However,
the performance of new players is not constant. As the performance of

7

Figure 7: Choice of B

existing players improves, SRMs become more diﬃcult. This raises the
barrier to entry.

Before participating, potential players have opportunities to practice
on recent rounds. Some may be experienced players coming from other
platforms. Thus the performance of new players improves over time. Thus
we adjust the initial rating for inﬂation.

• We choose a parameter N , the increase in R0 per 100 rounds.
• After each round, adjust R0 by N

100 .

• Simultaneously, adjust B for accuracy.

Figure 8: Choice of N

We ﬁnd most accurately N = 63, B = 27 (Figure 8).
Thus, our parameters estimating a stable performance are:

’Elo2’: N = 63; B = 27

8

4 Results

We ﬁrst compare our ’Elo’ implementation to SRM ratings. Table 1 shows
the average computed ∆R, performances, and prediction error, using our
deﬁnitions.

• The ﬁrst row is our primary metric.

• The players by experience.

• Existing players, in each division.

• In each division, the top and bottom half ranks.

Players
All
First round
2-7 rounds
8-24 rounds
25-74 rounds
75-199 rounds
200+ rounds
Existing
Division 1
Division 2
D1 H1
D1 H2
D2 H1
D2 H2

∆R

perf

err

ratings
790127
77818
202858
217893
195019
84825
11714
712309
388024
324285
194004
194020
162141
162144

Elo
19.5
65.3
32.5
12.2
5.1
0.8
-0.5
14.5
11.7
17.8
34.1
-10.7
58.7
-23.2

SRM Elo
0.224
-20.8
0.391
-186.2
0.285
-25.1
0.239
10.9
0.171
4.5
0.050
-0.7
-0.043
-2.0
0.206
-2.7
0.169
-1.8
0.251
-3.7
0.636
52.1
-0.298
-55.8
0.881
55.3
-0.379
-62.7

SRM
Elo
0.7513
0.298
-0.373 0.8019
0.6649
0.244
0.7454
0.511
0.7671
0.395
0.8701
0.284
0.8965
0.241
0.7458
0.372
0.6930
0.241
0.8090
0.528
0.9705
0.796
0.4155
-0.314
1.1311
1.348
0.4869
-0.291

SRM
0.8301
1.0766
0.7105
0.8204
0.8263
0.9093
0.9347
0.8032
0.7230
0.8992
1.0406
0.4054
1.3831
0.4153

Table 1: Player statistics, Elo : SRM

Because SRM ratings use a diﬀerent deﬁnition of performance, we
include results using independent metrics. Each round, we compute rank
correlation statistics [4]:

• Kendall’s τ

• Spearman’s ρ

For each metric, we compute the fraction of rounds where ’Elo’ better
predicted the result than SRM ratings, splitting ties equally. Table 2
shows the percentages.

Tables 3, 4 and 5 compare our ’Elo2’ and ’Elo’ implementations.

9

Rounds
All
Division 1
Division 2
2-16 players
17-99 players
100-199 players
200-399 players
400-599 players
600-799 players
800+ players

#
1950
1196
754
151
204
337
437
310
268
242

τ
87.4
79.8
99.4
48.3
65.9
86.5
92.7
95.5
98.1
99.2

ρ
87.1
79.6
98.9
48.7
65.4
85.9
92.7
95.5
98.1
97.9

err
89.2
83.1
98.9
54.0
69.1
91.5
94.7
96.1
96.3
98.3

Table 2: Round statistics, % Elo : SRM

Players
All
First round
2-7 rounds
8-24 rounds
25-74 rounds
75-199 rounds
200+ rounds
Existing
Division 1
Division 2
D1 H1
D1 H2
D2 H1
D2 H2

∆R

perf

err

ratings Elo2
25.7
790127
90.6
77818
40.4
202858
15.6
217893
7.3
195019
2.4
84825
11714
0.6
18.6
712309
14.9
388024
22.9
324285
37.0
194004
-7.2
194020
63.2
162141
-17.3
162144

Elo
19.5
65.3
32.5
12.2
5.1
0.8
-0.5
14.5
11.7
17.8
34.1
-10.7
58.7
-23.2

Elo2
0.217
0.426
0.280
0.217
0.156
0.050
-0.033
0.194
0.163
0.232
0.622
-0.297
0.852
-0.388

Elo2
Elo
0.7497
0.224
0.7997
0.391
0.6649
0.285
0.7442
0.239
0.7650
0.171
0.050
0.8662
-0.043 0.8924
0.7443
0.206
0.6915
0.169
0.8074
0.251
0.9668
0.636
0.4163
-0.298
1.1199
0.881
0.4949
-0.379

Elo
0.7513
0.8019
0.6649
0.7454
0.7671
0.8701
0.8965
0.7458
0.6930
0.8090
0.9705
0.4155
1.1311
0.4869

Table 3: Player statistics, Elo2 : Elo

Rounds
All
Division 1
Division 2
2-16 players
17-99 players
100-199 players
200-399 players
400-599 players
600-799 players
800+ players

#
1950
1196
754
151
204
337
437
310
268
242

τ
58.4
59.5
56.6
52.6
56.6
57.7
62.2
61.1
59.0
53.3

ρ
57.3
58.3
55.7
54.0
54.4
56.8
61.1
61.0
57.8
50.4

err
64.6
63.8
65.8
59.3
60.3
58.9
65.7
66.1
69.8
69.8

Table 4: Round statistics, % Elo2 : Elo

10

err

Rating
SRM 0.8301
0.7908
initial
0.7784
K
0.7562
W
0.7536
C
0.7513
Elo
0.7511
B
0.7497
Elo2

µ
-20.8
22.2
14.7
18.5
19.6
19.5
21.5
25.7

∆R
σ
130
142
75
102
103
102
104
105

R
init median max
3923
1043
1200
4663
1301
1200
3955
1258
1200
3734
1327
1200
3684
1341
1200
3709
1369
1200
3801
1384
1200
4468
2095
1970

max
900
1202
642
1762
2417
1548
1581
1591

Table 5: Statistics, each parameter

5 Conclusion

Our ’Elo’ implementation generally better predicts the players’ relative
performances than SRM ratings. The ranks are also better predicted, with
predictions improving with the number of players. Our ’Elo2’ adjustments
improve stability and slightly improve accuracy.

Our primary metric considers all the players’ performances in all SRM.
The predictions are empirically accurate, on average, but not necessarily
precise for any player or at any time.

We include source code and charts in appendix. Other results are

posted on our web site [5].

6 Acknowledgements

We would like to thank Ivan Kazmenko for reviewing this paper and
helpful comments.

References

[1] Topcoder. https://www.topcoder.com/about.

[2] Topcoder:

Algorithm competition rating system.
https://
community.topcoder.com/tc?module=Static&d1=help&d2=ratings.

[3] Wikipedia: Elo rating system. https://en.wikipedia.org/wiki/

Elo_rating_system.

[4] Wikipedia: Rank Correlation.

https://en.wikipedia.org/wiki/

Rank_correlation.

[5] http://tc.eloranked.com.

11

Appendix A

//
// tc.eloranked.com/EloSRM.h
// (c) 2019-2020 Batty, Kamenetsky
//

#include <math.h>
#include <vector>
#include <algorithm>

namespace EloSRM
{

const double EloScale = M_LN10 / 400;
const double K0 = 400 * M_LN2 / M_LN10;

const double R0 = 1200;
double R1 = R0;
const double N = .63;

// initial rating
// adjusted for inflation
// per round

const double K = 600;
const double C = 4;
const double M = 6.75;
const double B = 27 / K0;

// initial K
// coeff P’
// max perf
// perf bonus

struct Player {

int numRatings = 0;
double rating = R1;

};

struct Result {

Player* player;
int div;
double score;
double deltaR;

};

inline double winP(double ri, double rj) {

double s = (rj - ri) * EloScale;
return 1 / (1 + exp(s));

}

void rateDivision(Result* results, int n) {

#pragma omp parallel for

for (int i = 0; i < n; i++) {

Player* pi = results[i].player;
double si = results[i].score;
double ri = pi->rating;
double erank = 1, arank = 1;
double mu = 1, var = 1;
for (int j = 0; j < n; j++) {
if (j == i) continue;
double sj = results[j].score;
double rj = results[j].player->rating;
double wp = winP(rj, ri);
mu += wp;
var += wp * (1 - wp);
if (si == sj) {
erank += .5;
arank += .5;

}
else {

erank += wp;
arank += si < sj;

}

}
double err = log(erank / arank) * M_LOG2E;
double err1 = var / mu;
double perf = err + B * err1;
double pa = perf * M / (M + abs(perf));
double wf = sqrt(1. + pi->numRatings);
double vf = 1 + C * err1;
double w = wf * vf;
results[i].deltaR = K * pa / w;

}

}

void rateRound(std::vector<Result>& results) {

int n = (int)results.size();
std::sort(results.begin(), results.end(), [](auto& r0, auto& r1) { return r0.div < r1.div; });
for (int i = 0, j = 1; j <= n; j++) {

if (j == n || results[j].div != results[i].div) {

rateDivision(&results[i], j - i);
i = j;

}

}
for (int i = 0; i < n; i++) {

Player* pi = results[i].player;
pi->numRatings++;
pi->rating += results[i].deltaR;

}
R1 += N;

}

}

12

Appendix B

Figure 9: Stability

13

