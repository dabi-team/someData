2019 Evolutionary Algorithms Review

Andrew N. Sloss1 and Steven Gustafson2

1Arm Inc., Bellevue
2MAANA Inc., Bellevue

June 24, 2019

Abstract

Evolutionary algorithm research and applications began over 50 years ago. Like other artiﬁcial
intelligence techniques, evolutionary algorithms will likely see increased use and development due to
the increased availability of computation, more robust and available open source software libraries,
and the increasing demand for artiﬁcial intelligence techniques. As these techniques become more
adopted and capable, it is the right time to take a perspective of their ability to integrate into
society and the human processes they intend to augment. In this review, we explore a new taxonomy
of evolutionary algorithms and resulting classiﬁcations that look at ﬁve main areas: the ability to
manage the control of the environment with limiters, the ability to explain and repeat the search
process, the ability to understand input and output causality within a solution, the ability to manage
algorithm bias due to data or user design, and lastly, the ability to add corrective measures. These
areas are motivated by today’s pressures on industry to conform to both societies concerns and new
government regulatory rules. As many reviews of evolutionary algorithms exist, after motivating this
new taxonomy, we brieﬂy classify a broad range of algorithms and identify areas of future research.

9
1
0
2

n
u
J

3

]
E
N
.
s
c
[

1
v
0
7
8
8
0
.
6
0
9
1
:
v
i
X
r
a

1

 
 
 
 
 
 
1 Preface

When attempting to ﬁnd a perfect combination of chemicals for a speciﬁc problem, a chemist will un-
dertake a set of experiments. They know roughly what needs to be achieved but not necessarily how
to achieve it. A chemist will create a number of experiments. Each experiment is a combination of
diﬀerent chemicals. Following some theoretical basis for the experiments. The experiments are played
out and the promising solutions are identiﬁed and gathered together. These new chemical combinations
are then used as the basis for the next round of experiments. This procedure is repeated until hopefully
a satisfactory chemical combination is discovered.

The reason this discovery method is adopted is because the interactions between the various chemicals
is too complicated and potentially unknown. This eﬀectively makes the problem-domain too large to ex-
plore. An Evolutionary Algorithm (EA) replaces the decision making by the chemist, using evolutionary
principles to explore the problem-space. EAs handle situations that are too complex to be solved with
current knowledge or capability using a form of synthetic digital evolution. The exciting part is that
the solutions themselves can be original, taking advantage of eﬀects or attributes previously unknown
to the problem. EAs provide a framework that can be reused across diﬀerent domains, they are mostly
biologically-inspired algorithms that reside as a subbranch of Artiﬁcial Intelligence (AI).

Using Bertrand Russell’s method of deﬁning philosophy [46] i.e.“as soon as deﬁnite knowledge concerning
any subject becomes possible, this subject ceases to be called philosophy, and becomes a separate sci-
ence”. AI research lives in-between philosophy and science. Ideas transition from philosophical thought
to applied science and truth. Within Computer Science, the AI ﬁeld resides at the edge of knowledge
and as such includes a distinct part which is more philosophical and another which is more rooted in
science.
In this review we cover one of the science aspects. AI science incorporates many areas of
research e.g. Neural Networks, Bayesian Networks, Evolutionary Algorithms, Correlation, Game Theory,
It is a dynamically
Planning, Vision recognition, Decision making, Natural Language Processing, etc.
changing list as more discoveries are made or developed. Thirdly, Machine Learning is the engineering
discipline which applies the science to a real world problem.

One of the overriding motivators driving Machine Learning in recent years has been the desire to replace
rigid rule-based systems. A strong candidate has been emerging which is both adaptive and outcome-
based. This technology relies on data-directed inputs. Jeﬀ Bezos, CEO of Amazon, succinctly described
this concept in a letter to shareholders in 2017 [44], ”Over the past decades computers have broadly
automated tasks that programmers could describe with clear rules and algorithms. Modern Machine
Learning techniques now allow us to do the same for tasks where describing the precise rules is much
harder.”. Also Kazuo Yano, Fellow and Corporate Oﬃcer of Hitachi Ltd, said in his keynote at the 2018
Genetic and Evolutionary Computation Conference (GECCO) [31] that the demand for more ﬂexibility
forces us to transition from traditional rule-oriented systems to future outcome-oriented ones.

The adaptability and transition to outcome-oriented systems means, from an end user perspective,
there is more uncertainly surrounding the ﬁnal result. This is construed as being either real or per-
ceived. Rule-based systems are not impervious but tend to be deterministic and understandable e.g.
the most notable being the area of safety-critical systems. This uncertainty creates the notion of User
Control Attributes (UCA). The UCA include the concepts of limiters [65], explainability [26], causality
[3], fairness [27,64] and correction [45]. These attributes have seen a lot of scrutiny in recent years
due to high-proﬁle public errors, as detailed in the AI Now 2018 Report [45]. The report goes into the
details of fairness and highlights the various procedures, transparency and accountability required for

1

Machine Learning systems to be safely applied in real social environments. Also worth mentioning is
the International Standard Organization (ISO), which has formed a study group focusing speciﬁcally
on Trustworthiness [51]. The study will be investigating methods to improve basic trust in Machine
Learning systems by exploring transparency, verify-ability, explainability, and control-ability. The study
will also look at mitigation techniques. The goal is to improve overall robustness, resiliency, reliability,
accuracy, safety, security and privacy; and by doing so hopefully minimize source biases. For this review
we will limit the focus to research, while at the same time being cognizant of the dangers of real world
deployment.

Control imposes a diﬀerent level of thinking, where researchers are not just given a problem to solve but
the solution requires a model justifying the outcome. That model has to provide the answers to the main
questions: Whether the algorithm stays within limits/restrictions? Is the algorithm explainable? Can
the algorithm predict beyond historical data? Does the algorithm avoid system biases or even side-step
replicating human prejudices [83]? And ﬁnally, can the algorithm be corrected? These attributes are
not mutually exclusive and in fact intertwine with each other. We can see a trend where modern Ma-
chine Learning algorithms will be rated not only on the quality of the results but on how well they cope
with the user demanded control attributes. These attributes are to be used as a basis for a new taxonomy.

This is a good point to start discussing the Computer Industry. The industry itself is facing a set of new
challenges and simultaneously adding new capabilities, as summarized below:

• Silicon level: groups are starting to work on the problem of mass silicon production at the
3-nanometer scale and smaller [63]. This involves designing gates and transistors at a scale
unimaginable 10 or even 5-years ago, using enhanced lithographic techniques and grappling with
quantum tunneling issues. These unprecedented improvements have allowed other areas higher
up the software stack to ﬂourish. Unfortunately these advancements are slowing down, as the
current techniques hit both physical and economic limitations. This situation is called the End of
Moore’s Law (EoML) [61,62].

• System level: A number of levels above the silicon lies the system-level which also has seen some
impressive advancements with the world-wide web, network infrastructure and data centers that
connect everyone with everyone. The scale of the system-level advancements has opened up the
possibility of mimicking small parts of the human brain. One such project is called SpiNNaker
[8]. SpiNNaker was upgraded and switched on in November 2018, it now consists of a million
interconnected ARM cores each executing Spiking Neural Networks (SNN) [41]. Even with all the
hardware capability, estimates suggest that it is only equivalent to about 1% of a human brain.

• Software design level: Software design, at the other end of the spectrum, has been constantly
pursuing automation. The hope being that automation leads to the ability to handle more com-
plicated problems, which in turn provides more opportunities. New programming languages, new
software paradigms and higher level data-driven solutions all contribute to improving software
automation.

To handle these new challenges and capabilities requires a continuously changing toolbox of techniques.
EAs are one such tool and like other tools they have intrinsic advantages and disadvantages. Recently
EAs have seen a resurgence of enthusiasm, which comes at an interesting time since other branches of
Machine Learning become mature and crowded. This maturity forces some researchers to explore com-
binations of techniques. As can be seen in this review a lot of the new focus and vigor is centered upon

2

hybrid solutions, especially important is the area of combining evolutionary techniques with Artiﬁcial
Neural Networks (ANNs).

3

2

Introduction

EAs are not a new subject. In fact as we look back at some of the early computing pioneers we see exam-
ples of evolutionary discovery. For example both Alan Turing [39] and John von Neumann [40] formed
ideas around Biological Automation, Biological Mathematics and Machine Learning. These forward
visionaries focused on the fact that exploitative methods could only go so far to solve diﬃcult problems
and more exploratory methods were required. The main diﬀerence between the two techniques is that
exploitative focuses on direct local knowledge to obtain a solution whereas exploratory takes eﬀectively
a more stochastic approach (leaping into the unknown).

Figure 2.1: Hardware capability and algorithmic eﬃciency over an idealized time line

Figure 2.1 shows an idealized view of the changes to hardware capability and algorithmic eﬃciency over
a time period. The ﬁgure shows the relationship between improvements in hardware and the types of
problems that can be addressed. Before 2010, the computing industry mostly focused on exploitative
problems ”getting things to work eﬃciently”. Today, due to hardware improvements, we can look at
exploratory algorithms that ”discover”. At the extremes of the X-Y axis, top-right and bottom-right lies
the respective future potentials of hardware and software i.e. the unknown.

4

Note: End of Dennard Scaling [78] marks the point in time when transistor shrinkage no-longer sustained
a constant power density. In other words, static power consumption dominates the power equation for
silicon. Forcing the industry to use clever frequency and design duplication techniques to mitigate the
problem. Deep Learning [79] represents the software resurgence of Neural Nets, due to hardware im-
provements and the availability of large training data sets.

The Hardware Capability top-right of the graph represents future hardware concepts, and requires subse-
quent manufacturing breakthroughs. These future concepts could include alternative computing models,
Quantum computing, Neuromorphic architectures, new exotic materials, Asynchronous processing, etc..
By contrast the Algorithmic Eﬃciency bottom-right represents future breakthroughs in subjects like
Artiﬁcial Life, Artiﬁcial General Intelligence (AGI), etc.; more philosophical goals than either science or
engineering. Both require signiﬁcant advancements beyond what we have today.

With these future developments, the desire is to set a problem-goal and let the ”system” ﬁnd the correct
answer. This is extremely simple to state but highly complex to implement. And more importantly, next
to impossible to implement without direct insertion of domain speciﬁc knowledge into the algorithm in
question.

No Free Lunch Theorem [74] states that no algorithm exists which outperforms every other algorithm
for every problem. This means to be successful, each problem requires some form of domain speciﬁc
knowledge to be eﬃcient. The more domain speciﬁc knowledge applied to an algorithm the greater the
likelihood of beating a stochastic algorithm. A stochastic algorithm can search every problem, without
the requirement of domain knowledge. EAs are directed population-based stochastic search algorithms.
As hardware capability increases more of these types of problems can be handled. It is the constraints
of time and eﬃciency that forces domain knowledge to be inserted into an algorithm.

This paper provides an up-to-date review of the various EAs, there respective options and how they may
be applied to diﬀerent problem-domains. EAs are a family of biologically-inspired algorithms that take
advantage of synthetic methods, namely management of populations, replication, variability and ﬁnally
selection. All based upon the fundamental theory of Darwinian evolution [5]. As a general rule the
algorithms are often simple at a high-level but become increasingly complex as more domain knowledge
is put into the system.

Another term frequently used to describe these style of algorithms is metaheuristics. Metaheauristics is a
higher-order concept, it is an algorithm that systematically pursues the identiﬁcation of the best solution
within a problem-space. EAs obviously fall under this class of algorithms and a lot of the academic lit-
erature frequently refers to metaheuristics: the main diﬀerentiator being biologically inspired algorithms.

For these algorithms to execute, some form of quantitative goal has to be set. This goal is the metric
for success. The success metric can also be used as a method to exit the algorithm but most often a
function of time is used. The algorithm can also be designed to be continuous i.e. never ending, always
evolving. The goal itself can be made up of a single objective or multi-objectives. For multi-objective the
search and optimization is towards the pareto optimal curve i.e. attempting to satisfy all the objectives
in some degree.

As an important side-note, EAs are mostly derivative-free, in that majority do not require a derivative
function to measure change to determine the optimal result.

5

Lastly, GECCO 2018 [31], in Kyoto, saw a number of trends. Neuroevolution being one of the more
notable ones, Neuroevolution is the method of using EAs to conﬁgure ANNs (see section 5.2). These
new trends will be tracked in more detail in future reviews if they remain popular in the evolutionary
research community.

2.1 Applications

EAs are applied to problems where traditional exploitative or pure stochastic algorithms fail or ﬁnd it dif-
ﬁcult to reach a conclusion. This is normally due to constraints on resources, high number of dimensions
or complex functionality. Solving these problems would require exceeding the available resources.
In
other words, given inﬁnite resources and inﬁnite compute capability it could be possible for a traditional
exploitative or stochastic algorithm to reach a conclusion. By contrast, EAs can be thought of as the
algorithms-of-last-resort. The problems in question are inherently complex, size of the problem-domain
is extreme or the mere number of objectives make the problem impossibly diﬃcult to explore. In these
circumstances the solutions are more likely ”good enough” solutions rather than solutions with high
precision or accuracy (but this does not preclude precision or accuracy being a goal). EAs tend to be
poor candidates for simple problems where standard techniques could easily be used instead.

They can be applied to a broad set of problem types. These types range from variable optimization
problems to creating new conceptual designs. In both instances, novelty can occur which may exceed
human understanding or ability. These problem-domains can be broken-down into optimization, new
design and improvement.

• Variable optimization consists of searching a variable space for a ”good” solution, where the
number of variables being searched is large. Potentially at a magnitude greater than a traditional
programming problem. This is where the goal can be strictly deﬁned.

• New structural design consists of creating a completely new solution, for example like a pro-
gram or a mechanical design. A famous example, of a non-anthropomorphized solution, is the
evolutionary designed NASA antenna [38]. The antenna design was not necessarily something a
human would have created. This is where a particular outcome is desired but it is unknown how
that outcome can be constructed.

• Improvement is where a known working solution is placed into the system and EAs explore
potential better versions. This is where a solution already exists and there is a notion that a
potential better solution can be discovered.

Being more speciﬁc on the applications side, EAs have been applied to a wide range of problems from
leading edge research on self-assembly cellular automata [67] to projecting future city landscapes for
town planners (see section 6.2.3).

6

3 Fundamentals of Digital Evolution

Before diving directly into the fundamentals we should stress that there are two ways to describe evolu-
tion. The ﬁrst is from a pure biology point-of-view dealing the various interactions of biological systems
In this paper we will keep the focus on
and the other is from the Computer Science perspective.
Computer Science with a hint of biology. Other texts may approach the explanation from a diﬀerent
perspective.

Evolution is a dynamic mechanism that includes a population of entities (potential solutions) where
some form of replication, variation and selection occurs on those entities, as shown in ﬁgure 3.1. This
is a stochastic but guided process where the desire is to move towards a ﬁxed goal.

• Replication: Is where new entities are formed, either creating a completely new generation of the

population or altering speciﬁc individuals within the same population (called steady-state).

• Variation: Making the population diverse. There are in eﬀect two forms of variation, namely
recombination and mutation. Recombination, or more commonly called crossover, creates new
entities by combining parts of other entities. By contrast, mutation injects randomness into the
population by stochastic-ally changing speciﬁc features of the entities.

• Selection: Selection is based on Darwin’s natural selection, or Survival Of The Fittest, where
selected entities that show the most promise are carried forward, with variation on the selection
being used to create the children of the next generation.

Figure 3.1: Idealized Darwinian Evolution

As a recap, digital evolution is one which a population of entities goes through generational changes.
Each change starts with a selection from the previous generation. Each entity is evaluated against a
known speciﬁc goal i.e. the ﬁtness is established and used as input to the selection algorithm. Once a
selection is made, replication occurs with diﬀerent degrees of variation. The variation is either by some
form of recombination from the parent selection and/or some stochastic mutation.

7

Figure 3.2: Basic Digital Process

Figure 3.2 shows the basic digital process that is adopted by many EAs. The high level synthetic evolu-
tionary process as-shown is a relatively straightforward and simple procedure. Within the process there
are many complex nuances and variations, which are inﬂuenced by our understanding of evolutionary
biology.

3.1 Population

A population is a set of solution candidates or entities. Each population is created temporally and has
the potential to age with each evolutionary cycle i.e. generation. The initial population is either seeded
randomly or is sampled from a set of known solutions. There are two ways for the population to be
evolved. This ﬁrst way consists of evolving the entire population to create the next generation. The
second way is to evolve individual entities within the population (called Steady-State). Entities can die
or thrive between generations.

The size of the population can be ﬁxed or dynamic throughout the evolutionary process. Fixed is when
the number of entities is kept constant and dynamic is when the population size changes. If dynamic,
a larger initial population may bring some potential advantages. This is especially true when choosing
the ﬁrst strong candidates for further evolution.

A population can also be divided into subgroups, these subgroups are called demes. A deme is a
biological term that describes a group of evolving organisms with the same taxonomy. They can evolve
in isolation within the population [1]. Demes can be made to interact with the other demes. This is often
described using an island and canoe metaphor, where the demes are the islands and the interactions
occur as canoes move between the islands depositing new entities.

8

3.2 Population Entities

The population entities, or more commonly called phenotypes, can be any type provided that type al-
lows recombination and/or mutation to be applied. The main styles are strings and programs. In this
context ”programs” is a loose term. The strings are ﬁxed length and more likely represent variables
or parameters. The programs tend to be more complex. Eﬀectively any structure from a traditional
computer programming language to hardware layout, or even biological descriptions, can be a program.

Metaheuristics operate at a high-level making the process generic, allowing idea or concept can be
used as the evolved substrate.
Including concepts like Deep Learning Neural Network or potentially a
causality equation. EAs are neutral on the subject but when it comes to speciﬁc problems, the problems
themselves, tend to be strictly deﬁned.

There are two important concepts to consider with population entities, namely niching and crowding
[4]. These terms are associated with diversity, which is brieﬂy mentioned in section 3.1. Niching means
individual entities survive generations in distinct areas of the search space. By contrast, crowding means
replacing an individual entity with similar featured individuals.

3.3 Generation

A generation is a speciﬁc step in an evolutionary population, where individuals in the population un-
dergo change via crossover and/or mutation. For EAs with a ﬁxed-run a restriction is imposed on
the number of generations. By contrast, continuous EAs have no upper bounds. EAs can vary from
small populations with high number of generations to large populations with signiﬁcantly lower number
of generations. These trade-oﬀs need to be made in terms of computation time. For example, some
scenarios will have expensive evaluation functions (so fewer generations with larger populations might
be preferred). The number of generations required is both algorithmic and problem-domain speciﬁc.

The children in the next generation can also include the parents from the previous generation. This is
called elitism, where the strongest entities remain in the population.

3.4 Representation and the grammar

Representation, or more commonly called genotype, is what EAs manipulate. There are diﬀerent types
of representations which include strings, tree structures, linear structures and direct-graphs. Each rep-
resentation has advantages and disadvantages, and is dependent on the speciﬁc problem-domain. The
representation determines what actually gets manipulated when recombination occurs, some lend them-
selves more to fractal/recursive like procedures and the others are more sequential and linear.

By contrast, the rules are deﬁned by the grammar. EAs grammar provides the expressive boundaries for
the representation. For example, in a mathematical domain adding a function like sin(x) to the grammar
provides extra richness and complexity to the representation. Similarly, for string based representations
adding or removing a variable to the grammar changes the expressiveness. Other decisions can be
made for structural EAs, such-as including more constructors (e.g. addition) over destructors (e.g.
subtraction), vice-versa or more commonly keeping the grammar entirely balanced i.e. same number of
constructors as destructors.

Possible grammars include a subset of Python or C, assembly instructions or even pure LLVM interme-
diate code [56]. These are all potential outputs of EAs.

9

3.5 Fitness

Fitness is the measure of how close a result is to a desired goal. A ﬁtness function is the algorithm used
to calculate the ﬁtness value. Calculating the ﬁtness value for an entire population is a time consuming
activity. The time taken is related to the complexity of the ﬁtness function and the size of the population
being evaluated. The ﬁtness function is used to select individuals for inclusion in future populations.
The function can be constant throughout the evolutionary process or it can change depending upon the
desired goal or situation. It is the feature of ﬁtness function change that makes EAs highly adaptive.

The ﬁtness can be calculated using diﬀerent methods e.g. Area Under the Curve (AUC) from a test
set, measurement of a robot responding to a set of trials, etc.; each method being problem dependent.
For supervised learning it is calculated as the diﬀerence between the desired goal and the actual result
obtained from the entity. Conversely, for unsupervised learning there are other methods. Once the
ﬁtness has been determined the entities can be ranked/sorted by strength. The stronger candidates are
more likely to be chosen as parents for the next generation.

3.6 Selection

Selection is the method where individuals in the current population are chosen to be the starting par-
In digital evolution, parents are not restricted to two; any number can
ents for the next generations.
be chosen. A simple method is to use the ﬁtness value to order the population, this method is called
ranked selection. A population can be organized from the highest to lowest ﬁtness value. The highest
entities are then used as the starting parents for the next generation and so forth. As mentioned in
section 3.3, elitism is where the chosen parents remain in the next population rather than being discarded.

Diversity [4] is an important concept when it comes to a healthy population. Healthy populations
are important for discovering ”good” solutions.
In other words, a diverse population has a higher ex-
ploratory capability. This tends to be important especially at the start of the search process. Diversity
is directly associated with the amount of variation applied to the entities. It can be argued that local
selection schemes [1,4] (steady-state) are naturally more likely to preserve diversity over global selection
scheme. Local selection means evolution is potentially occurring at diﬀerent rates across the population.

An example of a local selection scheme is called tournament selection. As the name implies, selection
requires running a tournament between a randomly chosen set of individuals. The ”winner” of each
tournament is then selected for further evolution.

Note: there are other selection schemes, which are not covered here.

3.7 Multi-objective

As the name implies multi-objective is the concept of not having a single objective but multiple objectives.
These objectives may act against each other in complex ways i.e. conﬂict. It is this interaction which
makes multi-objective so complex. A typical example in the mobile phone industry is ﬁnding the optimum
position between performance, power consumption (longevity) and cost. These three objectives can
be satisﬁed to diﬀerent degrees, eﬀectively giving the end consumer a choice of options. Too much
performance may sacriﬁce longevity + cost, low cost may sacriﬁce performance + longevity and so-on.
EAs are extremely good at exploring multi-objective problems where the ﬁtness is around a compromise
along the Pareto curve.

10

3.8 Constraints

Constraints are the physical goals, as compared with the objectives which are the logical goals. The
physical goals represent the real world limitations. They take a theoretical problem and make it real-
istic. Constraints are the limitations imposed on the entities. A constraint could be code size, energy
consumption or execution time. EA Researchers have discovered some of the most interesting and
potentially best solutions tend to lie somewhere at the edge of the constraint boundaries.

3.9 Exploitative-exploratory search

EAs use recombination and mutation for exploitative and exploratory search. The more mutation that
occurs the more exploratory the search, and correspondingly the less mutation the more exploitative the
search. EAs can be at either end of the spectrum, with only recombination (more exploitative) or only
mutation (more exploratory). The ratios of recombination and mutation can be ﬁxed or dynamic. By
making the ratios dynamic EAs can adapt to changing circumstances. This shift may occur when the
potential ”good” solution is perceived to be either near or far. Another way to view this is that mutation
is a local search and recombination (or crossover) is a global search. Recombination, despite using only
existing genetic material, often takes much larger jumps in the search space than does mutation.

3.10 Execution environment, modularity and system scale

EAs can execute as a process within an Operating System, as a self-constructed dynamic program feed
into a language interpreter (e.g. Python exec(open(”ea.py”).read())), or within a simulator, where the
simulator can be a physics simulator, biological simulator and/or a processor simulator. EAs are generic
and literally any executing model can be used to explore a desired problem-domain.

To handle larger problems some form of modularity has to be adopted. There are many schemes in-
cluding ones that introduce tree based processing or Byzantine style algorithms i.e. voting systems.
Modularity tends to work best when the problem granularity is relatively small and concise, such as a
function-call. The normal questions asked are (1) whether all the function-calls use the same input data,
(2) whether all information is shared between the functions, or (2) whether a hierarchy of evolution has
to be adopted i.e. from function call to full solution or from local to global parameter conﬁguration.

EAs can scale from one process to many processes running on several server clusters [42,70,75,76].
These compute clusters are called islands. They operate in either a parallel and/or distributed fashion.
A parallel system is a set of evolving islands working together towards a common goal. Genetic material
or solutions can be shared. We should highlight that there are a few options when it comes to parallel
topologies. By comparison, the distributed approach, which can include parallel islands, is about the
physical aspect of running on various hardware systems. With both approaches, scale-out co-ordination
becomes an important issue i.e. the management of the islands becomes part of the performance equa-
tion.

Lastly, it is important to mention co-evolution in the context of scaling. Co-evolution is where two or
more evolving populations (eﬀectively species) start interfering/cooperating with each other. This is
particular important when digital evolution is being used to build much larger systems. Both modu-
larity and system scale add an extra layer of complexity. Scale is a required necessity to answer more
complicated problems.

11

3.11 Code bloat and clean-up

The EAs which play with structures can quite easily have to deal with the problem of bloat [84]. Bloat
is a byproduct of exploring a problem-domain. Historically this was a major issue with the earlier algo-
rithms due to hardware limitations. Today, modern systems have an abundance of compute and storage.
This does not mean the limitation has gone away but it is mitigated to a certain extent. Bloat may
be critically important to the evolutionary process.
In nature the more that is discovered the more it
seems that very little is actually wasted. Non-coding regions are not bloat, they are crucial parts to the
process of molecular mechanisms.

There are structures or code sequences that have no value, as-in the result is circumvented by other
code or structures. These neutral or noneﬀective structures are called introns. Intron is a biological term
referring to the noneﬀective fragments found in DNA. For software programs, introns are code sequences
that are noneﬀective or neutral; these sequences can be identiﬁed and cleaned-up, i.e. eliminated. The
elimination can occur either during the evolutionary process itself or at a ﬁnal stage. Note, introns can
be critically important to the process, so early removal can be detrimental.

3.12 Non-convergence, or early local optima

There has been a lot of research focusing on the problems of non-convergence and early-local-optima
solutions. Non-convergence means that the evolving entities are not making enough progress towards
a solution. Early-local-optima means a sub-optimal solution has been found at the beginning of the
evolutionary process. This sub-optimal solution has caused the algorithm to limit further exploration,
reducing the chance of ﬁnding a better solution.

Non-convergence is caused by many factors including the possibility of not having the right data. EAs
rely on stochastic processes to move toward, which means that the paths taken are unique, unrepeat-
able and non-deterministic; unique in the sense that the paths taken are always diﬀerent, unrepeatable
as-in randomness is used to determine the next direction, non-deterministic as-in the length of time to
solution is variable. To get to a potential solution may require reruns of the algorithm. Each rerun
In the end,
potentially requiring some form of ﬁne adjustment to help narrow into a good solution.
when everything else fails, more domain speciﬁc knowledge may have to be inserted before convergence
eventually occurs.
It is important to stress that the ﬁnal solution may very well be deterministic and
repeatable, it is the evolutionary process to create the solution which may not be.

Similar to non-convergence is the problem of reaching a local extrema too early, and then EAs iterate
persistently around a point not discovering a better solution. Again, the techniques used for non-
convergence tend to be used to avoid the local optima scenario. Identiﬁcation of a local optima can be
diﬃcult since the global optima is unknown. After multiple readjustments hopefully the global optima
can be discovered.

3.13 Other useful terms

There are other terms which are worthy of a mention and brief descriptions. The ﬁrst terms are the
Baldwin Eﬀect [12] and Lamarckian Evolution [13] both important concepts for digital evolution. The
Baldwin Eﬀect is about how learned behavior eﬀects evolution. This is important for EAs that improve
towards a solution under techniques such as elitism (as brieﬂy mentioned in section 3.3). And Lamar-
ckian Evolution which theorizes that children can inherit characteristics from the experiences gained by

12

their parents. Again, an important concept with direct implications for digital evolution.

By contrast, the term overﬁtting [18] describes a situation that should be avoided.
It is when the
data noise containing irrelevant information and what is actually being discovered combine into a result
(conﬁguration parameters). EAs overﬁt when the discovered parameters satisﬁes the complete data-set
and not the data for the speciﬁc exploration, making it eﬀectively useless for any future prediction using
other input data sources. The potential concern is the increased risk of a false-positive outcome.

Lastly, Genetic Drift [68,69] is a basic evolutionary mechanism found in nature, where some genotype
entries between generations leave more descendants or parts than others. These descendants are in the
population by random chance. They are neither in the next generation because of a strong attribute nor
higher ﬁtness value. In nature this happens to all populations and there is little chance for avoidance.
EAs genetic drift can be as a result of a combination of factors, primarily related to selection, ﬁtness
function and representation. It happens by unintentional loss of genotypes. For example, random chance
that a good genotype solution never gets selected for reproduction. Or, if there is a “lifespan” to a
solution and it dies before it can reproduce. Normally such a genotype only resides in the population
for a limited number of generations.

13

4 Traditional techniques

In this section we brieﬂy cover the traditional and well known EAs. These EAs tend to be older and
more mature techniques. The techniques covered are frequently used by industry and research. There
are numerous support frameworks available to experiment with [72,6,29,71]. Assume for each technique
discussed that there are many more variations available.

Figure 4.1: Relationships between traditional EA techniques

Figure 4.1 shows the relationships between the various traditional techniques. For this review we have
decided to focus more on Genetic Programming and the various sub-categories. In future reviews this
emphasis will likely change.

4.1 Evolutionary Strategy, ES

Evolutionary Strategy, ES [4,42,48] is one of the oldest EAs, developed in the 1960s at the Technical
University of Berlin; it usually only involves mutation and selection. Entities are selected using trunca-
tion selection. After the entities are evaluated, the entries below the truncation point are systematically
removed from the population. The remaining parents are mutated to buildup a new population.

Modern implementations include Co-variance Matrix Adaptation - Evolutionary Strategy CMA-ES [15]
and an alternative Co-variance Matrix Self Adaptation - Evolutionary Strategy CMSA-ES. CMA-ES is
thought to be complicated to implement, and CMSA-ES is a newer alternative and is believed to be
easier to implement [73].

What problems do ESs solve? An ES is used to solve continuous parameter optimization. A parameter
is deﬁned by its type and interval range (upper and lower bounds). A continuous parameter can take
any value within the interval range. The precision determines the minimum change value.

14

4.2 Genetic Algorithms, GA

Genetic Algorithms, GA [4,24,42] is the most common and popular among the EAs. GA applies evolution
to ﬁxed length strings. The length of the string represents the dimensionality of the problem. These
strings represent variables or parameters and are useful when exploring a large number problem-domain
space. This space is normally beyond human or traditional methods. As well as being popular, GAs are
also the most commonly taught algorithm within the various EAs. Variables or parameters are converted
to ﬁxed length strings, the strings are entities in the population and are evolved using crossover windows
and mutation. Crossover is ubiquitous but explicit crossover windows are not. By comparison to an ES
(section 4.1), a GA tends to be more generic.

It should be noted that a recent trend has emerged, in both GAs and ESs, where crossover is dropped
and mutation is the sole mechanism for evolution (this diﬀers to the earlier thinking expressed in the
classical literature).

What problems do GAs solve? GAs handle optimization and conﬁguration problems where there are
too many variables or parameters for a traditional method to succeed. The variables or parameters may
interact making a potential solution much harder to identify.

4.3 Genetic Programming, GP

Genetic Programming, GP [20,21,22,23] in contrast to GAs, manipulate structures and in-particular
executable programs or mathematical equations. Early GPs were based on tree representations and used
the LISP programming language as the grammar. LISP was chosen for its operator richness and was rel-
atively easily to manipulate. More recently there have been other representations introduced and newer
languages such as Python have become popular as the main target. The recombination carries out the
global search, whereas the mutation covers the local search. It is frequently common for mutation to be
limited to 5-10% of the population [20]. There are always exceptions, especially if the % mechanisms
are dynamically altered between generations [4].

What problems do GPs solve? GPs apply evolutionary techniques to code or functions. GPs handle
the manipulation of programs, so that problems that are linear, tree or direct-graph based can be
explored. GPs can produce original source code, and in fact ﬁnd new novel solutions to any structural
style problem. In industry, GP are mostly used to discover best ﬁt mathematical equations.

4.4 Genetic Improvement, GI

Genetic Improvement, GI [17] is a subclass of GP (section 4.3), where instead of a random initial seeded
population, a working program is inserted as the starting point to spawn entities of the ﬁrst population.
This is a powerful concept since it does not only search for a better optimized solution but also has the
potential to discover and correct faults in the original ”working” code.

What problems do GIs solve? Solves an interesting problem, where either the working code is
potentially un-optimized and a more optimized version is required or bringing legacy code up to current
standards.

15

4.5 Grammatical Evolution, GE

Grammatical Evolution, GE [6] is a powerful technique. It is yet another subclass of GP (section 4.3)
but instead of using a ﬁxed grammar to evolve-able solutions, the grammar itself is select-able. A good
It takes a standard Backus-Naur Form
example of GE is the PonyGE2 [6] tool, written in Python.
(BNF) grammar [16] as an input and uses it to evolves solutions. This is a powerful method especially
when dealing with more obscure programming languages. GE can also carry out GI (see section 4.4).
Note the PonyGE2 source code is available on GitHub.

What problems does GEs solve? GE solves the problem of evolving multiple programming languages
using the same tool. As long as the language has a BNF-style deﬁnition, it can be evolved. This
makes GE ﬂexible across a number of problem-domains, and especially ones which require a speciﬁc
programming language.

4.6 Linear Genetic Programming, LGP

Linear Genetic Programming, LGP [1] is a subclass of GP (section 4.3) and as the name implies uses
a linear structure representation. The linear structure has some advantages over the more complicated
tree or directed-graph structures. LGP is particularly useful for problems which are more sequential.
For example, optimizing low level assembly output. It also makes the problem of manipulating complex
structures easier since it is a linear ﬂow that is being evolved. Constructs like if-style control ﬂow or
loops are superimposed onto the linear structure. The linear aspect of this technique introduces an
ordering constraint, which potentially has Turing Machine and/or Turing complete ramiﬁcations.

What problems do LPGs solve? LPG solves problems that are sequential. This is particular useful for
optimizing programs and low level assembly style output. Or any problem-domain where the problem
being explored is about sequential ordering.

4.7 Cartesian Genetic Programming, CGP

Rather than linear or tree based, Cartesian Genetic Programming CGP [2] is based on Cartesian co-
ordinates and directed-graphs. One basic characteristic is that the population is small (e.g. population
size around 5). The small population goes through a large number of generations. CGP is uniquely
qualiﬁed to handle speciﬁc problems extremely well. EAs themselves can be temporal by default. CGP
introduces the concept of spatial awareness into EAs.

What problems do CGPs solve? CGP has been shown to be useful at circuit layout design since the
logic components require some form of spatial awareness. Interestingly since CGP is spatial it can also
be used to produce artistic designs/patterns. Recent research shows that CGP can achieve competitive
results on the Atari benchmark set [28]. CGP can also encode ANNs by adding weights to the links in
the graph, allowing them to do neuroevolution (see section 5.2).

4.8 Diﬀerential Evolution, DE

Diﬀerential Evolution, DE [4,42] is an example of a non-biologically inspired algorithm but falls under
the metaheuristic category. It is based on iterating a population towards a quality goal. The iteration
involves recombination, evaluation and selection. It avoids the need for gradient descent. A new candi-
date is based on a weighted diﬀerence between random candidates to create a third candidate, shifting

16

the population to a higher quality level. Each new population eﬀectively self-organizes.

What problems do DEs solves? Works best on Boolean, Integer spaces and Reals. DE was developed
speciﬁcally to ﬁnd the Chebyshev polynomial coeﬃcients and the optimization of digital ﬁlter coeﬃcients.

4.9 Gene Expression Programming, GEP

Gene Expression Programming, GEP [43,50] is a subclass of both GA (section 4.2) and GP (section 4.3).
This method borrows from both techniques, as-in it uses ﬁxed length strings which encode expression
trees. The expression trees can be of varied size. Evolution occurs on the simple linear, ﬁxed length
strings.

What problems do GEPs solve? It oﬀers a powerful linear encoding which is guaranteed to pro-
duce valid programs, since GEP follows the syntactic rules of the speciﬁc programming language being
targeted. This makes it easy to implement powerful genetic operators.

17

5 Specialized techniques and concepts

In this section we cover some of the more exotic EAs and extended tools. These EAs are new, hybrids
or just miscellaneous concepts. This is not an exhaustive list but a more holistic subset of ideas that
do not follow the traditional evolutionary methods. A few of the techniques covered in this section are
not technically based on biological or synthetic evolution but play an important role in the process or
are placed here due to taxonomy convenience.

Figure 5.1: Relationships between specialized techniques and concepts

Figure 5.1 shows the relationships between the specialized techniques and concepts. These relationships
are more tenuous than the relationships found between the various traditional EA techniques.

5.1 Auto-constructive Evolution

Auto-constructive Evolution [25] is where instead of having an overarching algorithm orchestrating the
artiﬁcial evolution process, entities themselves are given the ability to undergo evolution. This means
that children are constructed by their own parents. Parents have an ability to produce children, without
the need of a master synthetic algorithm. This is in contrast to the more traditional EAs where the
artiﬁcial replication occurs at a higher level.

What problems does auto-constructive evolution solve? Provides a method to carry out micro-
evolution. This type of evolution is more inline with the goal of building Artiﬁcial Life. Potentially has
an advantage to scale since it requires no centralized coordination.

5.2 Neuroevolution, or Deep Neuroevolution

It has become more popular in recent
Neuroevolution [53,30,47,59] is classed as a hybrid solution.
years. It was a noticeably hot topic in GECCO 2018 [31]. Neuroevolution is the concept of using some
form of GA to discover the optimal way to setup a Deep Neural Network (DNN). The entities being

18

optimized are artiﬁcial neural networks (ANNs). Or, it can be used in combination with supervised
learning and reinforcement learning (RL) techniques. The family of neuroevolution algorithms can be
further classiﬁed based on how the candidate solutions are encoded and how much they can vary. As
mentioned previously, CGP (section 4.7) can also be an eﬀective way to evolve ANNs by adding weights
to the links.

• Direct encoding: parameters of every artiﬁcial neuron and connection are part of the solution

encoding.

• Indirect encoding:

is a ”recipe” for generating ANNs. The topology can be either ﬁxed or
evolving. Fixed means that only the connection weights are optimized, whereas evolving means
both the connection weights and the topology of the ANN are modiﬁed. This latter class of
algorithms is commonly called Topology and Weight Evolving Artiﬁcial Neural Network algorithms
(TWEANNs).

Notable examples of TWEANNs are Neuroevolution of Augmenting Topologies (NEAT) [9] and its suc-
cessor HyperNEAT [10]. The former uses a direct encoding while the latter uses an indirect encoding
called ”Compositional Pattern Producing Networks” (CPPN) [57]. Another example of a TWEANN
approach using an indirect encoding is ”Evolutionary Acquisition of Neural Topologies” (EANT2) [58].

What problems does Neuroevolution solve? Neuroevolution combines ideas from Genetic Algorithms
and Artiﬁcial Neural Networks. It can evolve both ANN weights and topologies making it an attractive
alternative to ML hyper-parameter hand-crafting. By contrast with backpropagation, neuroevolution is
not limited to diﬀerentiable domains [59].

5.3 Self-replicating Neural Networks

Self-replicating Neural Networks [7] is a relatively new idea where the ANNs themselves re-conﬁgure.
Currently the idea is to have the network learn by producing their own weights as output also to have
regeneration. Regeneration is the concept of training an ANN by inserting predictions of its own pa-
rameters. This technique is still being researched and is at a very early stage. Vigorous exploration is
still required but this idea has potential to be become more important. Expect to see forward progress
in this area.

What problems do Self-replicating Neural Networks solve? Self-replication is still a new idea. Early
research shows some promise in the area of continual ANN improvement using natural selection.

5.4 Markov Brains

Markov Brains [32] is in an early stage. Markov Brains belong to the same hybrid group as neuroevolu-
tion. Based on ANNs with some signiﬁcant diﬀerences. Normal ANNs are designed with layers built-up
from nodes with the same functional characteristic. Markov Brains are networks built from nodes with
diﬀerent computational characteristics. The components interact with each other, and can connect with
external sensors (physical inputs) and actuators (physical outputs).

What problems do Markov Brains solve? This is still relatively early days for Markov Brains but they
are showing some early promise especially in unsupervised learning. By being a more ﬂexible substrate
than ANNs, they could also lead to a more general understanding of the role recurrence plays in learning.
Looking forward to see the next papers on this subject.

19

5.5 PushGP

PushGP [29] is a family of programming languages which have been speciﬁcally designed for evolution
to be applied-to i.e. an evolution target. It is based on a stack execution model. Each datatype has a
separate stack. Code is treated as a manipulated datatype. It has been subjected to continuous research
over a number of years and so there are many iterations and implementations. These variations include
ones that allow for auto-constructive evolution (see section 5.1).

What problems does PushGP solve? PushGP is designed to be an evolutionary target language
rather than forcing a standard programming language to evolve.
In other words, instead of using an
existing programming language which is not evolutionary friendly, PushGP goes the other way by making
it evolutionary friendly.

5.6 Simulated Annealing

Simulated Annealing [4] is not an evolutionary algorithm in itself but is frequently used in-conjunction
It is where a problems starts being exploratory and as it gets nearer to a possible solution
with EAs.
moves more to being exploitative. Meaning that more of a stochastic approach is adopted at the be-
ginning and as a good enough solution becomes nearer a more combinational approach is adopted (see
section 3.9).

What problems does Simulated Annealing solve? Simulated Annealing is most useful when the
problem-domain requires more of an exploratory approach at the beginning but as the solution becomes
more in view a more exploitative approach is adopted.

5.7 Tangled Program Graph, TPG

Tangled Program Graph (TPG) [52] is another relatively new technique. A method of managing pro-
grams to scale. The scale is used to handle more complicated tasks such as game playing. Provides
a method to manage continuous evolution of independent and co-evolved populations. Shown to have
some promising results when compared with equivalent deep learning methods. And requires signiﬁ-
cantly lower computation requirement.

What problems does TPG solve? TGP is both eﬃcient and proven to handle complex dynamic
problems such as the traditional game playing benchmarks. This is still an early research area and as
such should be monitored.

5.8 Tabu search

Tabu search [66] is similar to Simulated Annealing (see section 5.6) in that it is often used in con-
junction with EAs. Tabu search relaxes the local search method by allowing a not-so-good solution to
progress-forward over solutions which have already been visited.

What problems does Tabu search solve? Tabu search solves the problem of getting oﬀ a local
maxima by placing solutions which have already been visited onto a tabu list. The list is used as a
method to avoid going down known previously explored search paths.

20

5.9 Animal inspired algorithms

The Animal Inspired Algorithms [4] are biology inspired algorithms. Never-the-less they deserve a refer-
ence within the context of EAs. There are a surprisingly large number of animal inspired algorithms. The
more famous are swarm, ant and frog algorithms but the actual list is considerably longer. Each animal
inspired algorithm provides some unique quality like ﬂying, jumping or walking. They are important
algorithms; swarm algorithm, for instance, can be used to control a collection of drones. Ant algorithms
can be used to explore an unknown terrain for searching useful resources.

What problems do Animal Inspired Algorithms solve? This is a broad group of specialized algorithms
which solve very speciﬁc problems.

21

6 Problem-domain mapping

The most important part of any algorithm is what can it accomplish. In this section we attempt to map
speciﬁc problem-domains to potential techniques. We must stress that this is not exhaustive and may
change dramatically between reviews. It will act as an important baseline for any future reports.

6.1 Speciﬁc problem-domain mappings

Here we map the general problem-domains and the speciﬁc technique or techniques. These problem-
domains are traditional problems found in industry.

6.1.1 Variable and parameter optimization

Parameter and variable optimization is a process of ﬁnding the best set of parameter values for a prob-
lem. The problems in themselves are complicated or the number of parameters is extremely large.
If
neither is true then a more traditional method of optimization may be a better route to a solution.

ES or GA are the normal solutions for this type of problem-domain. It has been shown that a GA can
handle up to a million variables, as discussed in the Tutorial on Next Generation Genetic Algorithms
GECCO 2018 [31,80]. This makes the search space diﬃcult or impossible for traditional methods and
the only remaining true competitor is a pure stochastic method.

See sections,

• 4.1 Evolutionary Strategy, ES

• 4.2 Genetic Algorithms, GA

6.1.2 Symbolic and polynomial regression

This is the problem when given a data-set ﬁnding the equivalent mathematical equation. This is a
particularly popular and important activity in many industries. The requirement is to ﬁnd a matching
equation for the data. EAs are adopted when traditional regression methods fail. The automotive in-
dustry are actively involved in this area since they frequently need to conﬁrm theoretical equations with
practical data. The techniques help ﬁnd the equation that matches the real data independent of theory.

GP and all subclasses can handle symbolic and polynomial regression.

See sections,

• 4.3 Genetic Programming, GP

• 4.6 Linear Genetic Programming, LGP

• 4.7 Cartesian Genetic Programming, CGP

• 4.5 Grammatical Evolution, GE

• 5.5 PushGP

22

6.1.3 Automated code production

The goal is to produce new code without human involvement. Once the programming language, repre-
sentation and goal have all been chosen, EAs can explore the problem-domain in search of an optimal
solution. If a ﬁnal code solution is found then it will fall into one of three criteria i.e. precise/accurate,
”good enough” or a multi-objective compromise (along the pareto curve).

Historically, EAs have mostly targeted programming languages such as LISP and low-level assembly
language. Both have strict input-output formats which can simplify mutation and the joining of code
segments. This avoids introducing syntax errors due to interface inconsistencies. Today the popular
programming languages are Python (as a replacement for LISP) and Intermediate Representation (as a
replacement for assembler instructions). Both oﬀer new opportunities and challenges.

GP, LGP, GE, CGP, and PushGP are all techniques that produce code. Due to the fact that the code
is automatically generated it is likely that the end result is diﬃcult or unreadable by humans.

See sections,

• 4.3 Genetic Programming, GP

• 4.6 Linear Genetic Programming, LGP

• 4.5 Grammatical Evolution, GE

• 4.7 Cartesian Genetic Programming, CGP

• 5.5 PushGP

6.1.4 Regular expression

Automated generation of regular expression. This can be achieved using Genetic Programming [60].
Where EAs are used to explore expression strings.

See section,

• 4.3 Genetic Programming

6.1.5 Circuit design

Circuit design is similar to low-level assembly instructions (see section 6.1.3) in that it has been suc-
cessfully explored using EAs. The rules for circuit design is relatively simple and so EAs can explore the
problem space relatively easily. This area was explored intensely in the 1990’s but has potential to see
a revival as system complexity increases.

CGP is particularly good at exploring circuit design since it handles spatial problems using Cartesian
co-ordinates.

See sections,

• 4.3 Genetic Programming, GP

• 4.7 Cartesian Genetic Programming, CGP

23

6.1.6 Code improvement and optimization

This is an up and coming area. The evolutionary process starts from a working code base, as compared
with an initial random seed population. The existing working code is optimized towards a set of new
objectives or is transitioned to ﬁt within a new set of constraints. The new objectives could include
speciﬁc performance features or any other similar attributes. The constraints could include new code
size restrictions or power consumption limitations. The working code is basically used as a seed for the
ﬁrst initial population. Standard evolutionary operators are then applied to search the problem space
for a potentially better solution.

As a subtopic, legacy code improvement is about taking older existing code and ﬁnding a better alter-
native. This better alternative can either be a metric improvement (e.g. faster, smaller code) or higher
quality (hidden or existing anomalies are removed).

EAs in this problem-domain act as extra engineers on the project, where they might or might not produce
a better answer from the original. Similar to many parts of engineering, this technique relies heavily on
the quality of the goal and the associated test suites.

GP, GI and GE are all referenced to handle code improvement and optimization.

See sections,

• 4.3 Genetic Programming, GP

• 4.4 Genetic Improvement, GI

• 4.5 Grammatical Evolution, GE

6.1.7 Simulator testing

Simulation testing is an indirect/byproduct of using EAs.
It turns out EAs can be extremely good at
ﬁnding simulator inconsistencies. This is because EAs explore the simulator in a diﬀerent way than an
engineer or scientist would explore a simulator. In fact, there are a number of historical examples where
EAs are annoyingly good at discovering faults.

All the EAs are capable of pushing the limits of a simulator.

6.1.8 Walking robot

Robots learning to walk has been a traditionally hard problem. EAs have been involved in learning
how to walk for decades. EAs have two attributes which make them particularly useful in handling
these types of problems. First, EAs can learn how to improve with each evolutionary cycle (incremental
improvements) and second they can adapt to changes in the environment. For example, if a physical
component changes or malfunctions EAs can adapt to that change and can continue walking.

GAs are used extensively in Robot Walking Algorithms, for both soft and hard robots.

See section,

• 4.2 Genetic Algorithms, GA

24

6.1.9 Automated machine learning

EAs are starting to be used in the new subject of Automated Machine Learning (or more commonly
known as AutoML) [47,53]. AutoML is the automation of machine learning to real problem-domains.
The goal is to avoid the labor intensive conﬁguration required to setup a Deep Neural Network (DNN).
This method also potentially bypasses the requirement for domain experts. Google have shown that Au-
toML can successfully improve existing ML systems. Google has also shown how Evolutionary AutoML
can be used to improve Image Classiﬁers that were originally designed by humans.

This is becoming an increasingly popular subject, especially as DNNs become more complicated and
larger. DNNs are more and more being adopted to solve interesting, real problems but the complexity of
setup is causing a slow down in application. The quest today is applying and conﬁguring DNN to more
problems quicker and easier. EAs are increasingly being used in this area to discover novel solutions
which are more eﬃcient.

In research, GAs are an alternative way to conﬁgure a DNN. The GAs provide some form of novelty. For
example, in a Google Brain paper [53] aging the weaker entities from the population was introduced
to DNN conﬁguration. They found that GAs achieved better results, as compared with other methods,
when there is limited hardware resources.

One of the more famous public tools in EAs to carry this is out is TPOT [33], source code available
on GitHub. It is designed to be a Data Science Assistant, written in Python. The goal is to optimize
machine learning pipelines using GP.

See sections,

• 4.2 Genetic Algorithms, GA

• 4.3 Genetic Programming, GP

• 5.2 Neuroevolution, or Deep Neuroevolution

6.2 Unusual and interesting problem-domain mappings

Here we highlight some of the more unusual problem-domain mappings that have appeared in recent
articles. It is expected that these mappings will change the most between reviews.

6.2.1 Conﬁguring neuromorphic computers

Conﬁguration of a Neuromorphic Computer [34] is a more unusual problem. Current techniques map
Convolutional Neural Networks (CNNs) to Spiking Neural Networks (SNN). These techniques avoid the
dynamic nature and complexity of SNNs. A suggestion is to use an EA to perform these mappings. EAs
are used to design simple ANNs to conﬁgure the platform. This technique allows the full utilization of a
complex SNN to create small networks to solve speciﬁc problems. EAs can explore the entire parameter
space of the speciﬁc hardware.

6.2.2 Forecasting ﬁnancial markets

GA are used by institutional quantitative traders and other areas of the ﬁnancial world [36]. Traders use
software packages to set parameters that are optimized using both historical data and a GA. Depending

25

upon the problem, the optimization can vary from which parameters are being used and the associated
values to only optimizing the values. Trading comes with some risk but identifying the right parameters
that relate to major market turns can be critical.

6.2.3 Predicting future city landscapes

The Spanish Foundation For Science and Technology [37] have used EAs to predicts the upward growth
of cities. They discovered that increases in build height follows similar development as some living
systems. A GA takes historical and economic data and uses it to predict the skyline of the future. The
GA predicts how the skyscrapers and other buildings increase in height.

6.2.4 Designing an optimized ﬂoor-plan

Using EAs to design internal building ﬂoor plans. Floor plan can be complex due to building irregularities.
A GA has been applied to optimize complex ﬂoor-plans [49]. The GA successfully designed oﬃce ﬂoor
plans that optimized walk times and hallways.

6.2.5 Antenna design

Antennas are complicated and are mostly designed by hand. This is both time-consuming and requires
many resources. EAs have been ”used to search the design space and automatically ﬁnd novel antenna
designs”. In the paper entitled Automated Antenna Design with Evolutionary Algorithm [38], a group of
NASA scientist successfully achieve designing an antenna using digital evolution. The antenna turned
out to be eﬃcient for a variety of applications. It was unique since the ﬁnal design would not have been
created by a human.

6.2.6 Defect identiﬁcation of electron microscopy images

The US Department of Energy has been using a system called Multinode Evolutionary Neural Networks
for Deep Learning (MENNDL) [54] to identify defects in electron microscopy images. MENNDL uses
NNs to ﬁnd defects out of changing data. The system runs on the Oakridge Summit supercomputer [55].
Fully utilizing all the available compute-nodes i.e. 18,000 GPUs on 3000 nodes. It analyzes millions of
networks using a ”scalable, parallel, asynchronous genetic algorithm augmented with a support vector
machine to automatically ﬁnd a superior deep learning network topology and hyper-parameter set.” [54].
The scale of this system makes this an impressive hybrid implementation.

26

7 Challenges

Challenges include some personal opinions from the experience we have had navigating the subject of
EAs. The points laid out below are opinions so should be debated and discussed. They are not end
points.

• It is our observation that the community is relatively small compared with other Machine Learning
communities. The size of the community determines the level of vigor that can be applied to
In other words, there is not enough experts in the subject to
validate a new idea or concept.
vigorously prove or disprove a concept. Many ideas, even extremely clever and good ones, go
unveriﬁed and unchecked by the community. This is a problem since good ideas can go missing
due to a lack of support.

• EAs have an inherent diﬃculty proving they are the best solution to a speciﬁc ”real-world” problem.
There is no automatic methods to compare algorithms that is without any bias. In other words
how do we prove, without doubt, that an EA performs better at achieving a time-to-solution than
a random search. This has been a consistent issue since it is extremely diﬃcult to prove the results
from an EA experiment that is obviously without bias. What compounds the diﬃculty is that the
problem-domains targeted are in themselves inherently complex, that is why an EAs is being used
in the ﬁrst place.

• Recently a lot of work has gone into creating synthetic problem benchmarks but there is concern
less work has been applied to ”real world” problems with ”real world” constraints. Where bench
marking and consistency is undoubtedly important, especially when comparing techniques, the
most important activity is always applying algorithms to real problems.

• The community is an old community within Machine Learning, with ideas dating back to the early
1950’s but many of the original drawbacks of using evolutionary techniques have been removed
since modern hardware is both abundant and high performing. This means experiments which
were constrained by the hardware resources at the time can now be feasible. Population size and
maximum number of generations can be made considerably larger.

• Biology plays important an role but EAs are not organisms. This makes crossing terms between
biology and Computer Science diﬃcult. Computer Scientists will use the biological terms loosely
for their own purposes whereas the real biological meaning is much more complicated.

• EAs have been proven good at tackling some hard problems but they suﬀer from a diﬃculty-of-
scale.
In complex systems it is important to divide-and-conquer (break the problem down into
smaller elements) before attempting to produce a solution. EAs at the bottom level make a lot
of sense but they become more problematic as we scale-up the problem. Research work at bigger
scale problems is still immature and is also limited, for the most part, with the capabilities of the
current hardware available.

• Similar to many other AI disciplines, there is a constant struggle between make verses buy. There
is a tendency for Researchers to re-invent the technology wheel, this is in part due to the required
learning curve to attain usefulness. The amount of eﬀort to learn a new framework can be as
challenging and time consuming as creating a propriety framework from ﬁrst principles. This is
detrimental to the discipline, as a whole, since the re-invention slows down forward progress. The
caveat is that over time frameworks become overly speciﬁc to a given problem domain, so applying
the same framework to a diﬀerent problem can be cumbersome.

27

• Modularity is a method to handle more complex problems by breaking the problem into more man-
ageable components. This falls under the divide-and-conquer strategy or scientiﬁc method. EAs
solve problems using a bottom-up design and as-such are inherently more diﬃcult to modularize.

• EAs may be deterministic and provable, the process by how the solution was arrived at is non-
determinant and if the algorithm is run again there is no guarantee the same result will be found
or any result will be found. This is the opposite of some other techniques in Machine Learning.

• EAs are provable. Proof and explainability is becoming increasingly more important. Governments
are also stepping in with new regulations, for example the General Data Protection Regulation
(GDPR) [26]. GDPR is a European regulation which has direct implications on Machine Learning
algorithms in general.
In Article 22 [27], of the regulation, calls for algorithmic fairness and
explainability. In other words, explain how the algorithm is correct, fair and unbiased.

• Being an old subject EAs inherently suﬀers from the reinvention and rediscovery of already known
concepts. Keeping everyone current with what has been published is always a challenge, especially
as the amount of scientiﬁc information accelerates.

• Even-though EAs could potentially be the next big direction for Machine Learning, the general
low funding of the subject may hold back development. This is concerning since EAs are not as
well-known as other Machine Learning techniques. This situation makes obtaining core funding
for EA related research diﬃcult and very much a secondary focus. The outcome is that only a few
full-time researchers worldwide focus solely on these techniques. Also, the broad interdisciplinary
knowledge base required is diﬃcult to attain.

28

8 Predictions

In this section we look into the future. What may happen in the next few years with EAs. Again since
these are predictions they should be treated with more questions.

• It is likely that in the near future we will see more cross-pollination and collaboration between
Machine Learning researchers and molecular biologists, neuroscientists and evolutionary biologists.
People are held back by their specializations and generally dangerous in other areas. The philoso-
pher Paul Feyerabend argued that the most progress is made on the boundaries between subjects
[81]. It is at the boundary of biology and computer science where most advancements are likely
to occur.

• Pure research on DNNs will slow down and the DNN focus will shift to engineering and the
application side for the near-term. There is a strong likelihood that Machine Learning research will
diversify and be more challenging. Research problems will become hybrid, involving the merging of
many techniques. A potential end goal for hybrid systems is Artiﬁcial General Intelligence (AGI).

• Artiﬁcial General Intelligence is a philosophical goal, or concern depending upon whom you ask.
This will potentially take decades and many stages before is can be reached, if at all. One stage
is the much smaller attainable goal of producing what we call Domain Speciﬁc Artiﬁcial Life
(DSAL). Bringing together many disciplines in the desire to create solutions to a speciﬁc problem.
The term is a fun play on Domain Speciﬁc Architectures as advocated by some of the hardware
architecture community: small artiﬁcial lifeforms to solve speciﬁc problems.

• New Artiﬁcial Neurons (AN) will be explored and developed. There is potential for the ANs
themselves to be re-examined either by vastly increasing the number of interconnects or adding
interesting attributes like co-ordinates to the model. Today’s ANs have limited interconnects,
whereas the biological neurons have substantially more interconnects. Then evolving these models
as required. These are ideas that people like Julian Miller have put forward. Whatever future
direction is taken, the AN model will most likely change over the next few years. In all likelihood
we will end up with many AN models to choose from. This change will occur as our understanding
of Neuroscience and biological mechanisms increases.

• As James Shapiro points out, there are many genetic mechanisms that could be incorporated into
existing and new EAs [82]. One such concept is Horizontal Gene Transfer (HGT) [11]. HGT
becomes important to the community, as more advanced complex systems are attempted. HGT is
the ability for useful genes (or code segments) to quickly transfer across species (islands). There
are Computer Science implications for such ideas. As with Richard Feynman’s ”There’s plenty
of room at the bottom”, when referring to molecular chemistry, there is plenty of room with
evolutionary biology and its application to EAs.

• EAs can potentially be used to explore causality. Judea Pearl [3] has given the industry a challenge
to explain Machine Learning outcomes and identify the causes of the outcomes. In particular ideas
like counterfactual, where forward predictions about the future can be made by inserting a change
or deciding not to insert a change. This involves not just providing data correlation but creating
a model on how the data was created.

• Obfuscation may allow EAs to get involved in security, privacy and data cloaking.

• EAs are already being used in the ﬁeld of Quantum Computing (QC), and we can expect more
activity in this area. Either to conﬁgure or to handle the complicated data output. 2017 saw the
Humies Award [19] go to an Australian Team [35] using EAs applied to Quantum Computing.

29

9 Final discussion and conclusion

The 2019 Evolutionary Algorithms Review is a baseline for future reports. We are cognizant that there
are many areas which were not covered or were only covered brieﬂy. These areas may become more
important as we consider the 2020 review. Traditional EAs continue to provide useful solutions to hard
problems. They are mature algorithms. They are becoming particularly useful when placed on modern
hardware. The newer trends appear to indicate that hybrid solution may provide the next future capa-
bility i.e. combining evolutionary techniques with other techniques. Where EAs are used either to bring
knowledge-forwarding or optimizing complex Machine Learning conﬁgurations.

We dedicated most of the review to the landscaping of the various techniques. This was planned to act
as a baseline for future review development. For problem-domains that aﬀect society, and subsequently
industry, we introduced UCA (User Control Attributes) criteria. There are ﬁve deﬁned attributes i.e. lim-
iters, explainability, causality, fairness and correction. They impose an extra level of required thinking,
where the algorithms have to be both community friendly and adhere to new government regulations.
The UCA will be used as a basis for a new taxonomy for EAs. Future algorithms will not only be rated
on their ability to produce an outcome but on the ability to satisfy the UCA criteria in some form or
other. More generally this taxonomy could be applied to other forms of Machine Learning.

Current thoughts on applying the UCA to EAs are as follows:

• Limiters is the concept of restricting the capability. It is still early days but as EAs handle more
problems that either aﬀect the physical environment (i.e. control actuators), or are involved in
some privacy aspect, then methods of limiting the capability or cloaking the outcomes become
more important. This may require signiﬁcant external technology and thought.

• Explainability revolves around explaining how an algorithm produces an answer. The output
solution from EAs are inherently provable since they solve a speciﬁc problem but as with all
algorithms of this class, explaining how the solution came about is problematic and diﬃcult to
repeat.

• Causality is about moving to a higher order answer which adds the ”Why” component to the
answer being searched. The challenge has been set and causality will become more important as
we move forward with implementing real world EAs, driven by the desire for the EAs to do more
and to understand why a conclusion has been reached.

• Fairness is about producing an answer which is balanced and without human prejudice. This may
come down to the actual input data selected and the ﬁtness function being used. Algorithmic
fairness [45] has to be capable of detecting biases, contesting a decision and ﬁnally instigating
a potential remedy. A critical method of achieving fairness is making sure that the outcome is
vigorously tested. There is potential for a mathematical element of fairness to be incorporated into
the evolutionary frameworks. Whereas the society aspects will remain in the human domain for the
foreseeable future and may well require careful deliberate biasing to produce a fair outcome. Two
features related to fairness, not covered in this review, are the broader subjects of accountability
and transparency. A method of algorithmic fairness can be complicated. This is an area that
requires future monitoring. Fairness may also involve studying the initial starting states, checking
that the biases are not injected right at the start of the process.

• Correction is about correcting a problem once it has been identiﬁed. When an error is identi-
ﬁed/detected/contested, EAs can be assessed on how easily a remedy can be applied. EAs by

30

deﬁnition are adaptive, and so correction can occur as part of a continuous evolutionary process
(i.e. via environmental-changes) or more manually through a direct change to the ﬁtness function
and/or constraints.

Now that we have described the basics of the UCA, we will attempt in the 2020 review to apply them
to the various EAs outlined in this review. This provides the new taxonomy.

There is a long way to go with-respect-to EAs. We are just forming a common language by which we
can communicate with the biologists. This is an exciting time since the discoveries in biochemistry and
synthetic biology are occurring at unprecedented rates and the capabilities of digital hardware are com-
ing to levels that can mimic parts of the biological system. Likewise, biology can also take advantage
of some of the newly gained insights from the Computer Science ﬁeld.

This means that the research runway is long but at the same time we have to realize that the hardware
gap in both ”eﬀective” processing and interconnects between biology and digital systems is still vast.
We may have the vision to achieve biological equivalence but the current state of the hardware is both
diﬀerent and non-optimal for many types of problems. This is particularly interesting as we hit the End
of Moore’s Law and the possibility of diﬀerent compute-models being introduced and forced on the
industry.

10 Acknowledgements

We would like to acknowledge the following people for their encouragement and feedback during the
writing of this review, namely Mbou Eyole, Casey Axe, Paul Gleichauf, Gary Carpenter, Andy Loats,
Rene De Jong, Charlotte Christopherson, Leonard Mosescu, Vasileios Laganakos, Julian Miller, David
Ha, Bill Worzel, William B. Langdon, Daniel Simon, Emre Ozer, Arthur Kordon, Hannah Peeler and
Stuart W. Card.

11 Feedback

If you have any feedback or suggestions on this review please send them to andrew.sloss@arm.com with
the subject line of ”2019 Review Feedback” and we will consider the enhancements.

31

12 References

1. W. Banzhaf, M. Brameier, ’Linear Genetic Programming Published’ by Springer, 2007

2. J Miller, ’Cartesian Genetic Programming’, Published by Springer, 2011

3. J. Pearl, D. Mackenzie, ’The Book Of Why : The New Science Of Cause and Eﬀect’, Published

by Basic Books, 2018

4. D. Simon, ’Evolutionary Optimization Algorithms : Biologically Inspired and Population-Based

Approaches to Computer Intelligence’, Published by Wiley, 2013

5. C. Darwin, ’Origin of the Species’, published November 24 1859

6. M. Fenton, J. McDermott, D. Fagan, S. Forstenlechner, E. Hemberg, M. O’Neill, April 26 2017,
’PonyGE2: Grammatical Evolution in Python’, <https://arxiv.org/abs/1703.08535>, [ac-
cessed December 28 2018]

7. O. Chang, H. Lipson, ’Neural Network Quine’, arXiv.org, May 24 2018, <https://arxiv.org/

abs/1803.05859>, [accessed November 11 2018]

8. S. Furber ’SpiNNaker’, Manchester University, UK, <http://apt.cs.manchester.ac.uk/proj

ects/SpiNNaker/project/>, [accessed November 11 2018]

9. K. O. Stanley, R. Miikkulainen, ’Evolving Neural Networks through Augmenting Topologies’ Sum-

mer 2002, <https://dl.acm.org/citation.cfm?id=638554 [accessed April 29 2019]

10. K. O. Stanley, D. B. D’Ambrosio, J. Gauci, ’A Hypercube-Based Encoding for Evolving Large-
Scale Neural Networks’, April 2009, <https://ieeexplore.ieee.org/document/6792316,
[accessed April 29 2019]

11. R. Jain, M. C. Rivera, J. A. Lake, ’Horizontal gene transfer among genomes: The complex-
ity hypothesis’, March 1999, <https://www.pnas.org/content/pnas/96/7/3801.full.pdf
[accessed April 29 2019]

12. T. J. H. Morgan, T. L. Griﬃths, ’What the Baldwin Eﬀect aﬀects’, 2005, <http://cocosci.pr

inceton.edu/papers/BaldwinEffectAffects.pdf>, [accessed April 29 2019]

13. R. W. Burkhardt, ’Lamarck, Evolution, and the Inheritance of Acquired Characters’, August 2013,
<https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3730912/>, [accessed April 29 2019]

14. E. Ozcan, B. Bilgin, E. E. Korkmaz,

’A comprehensive analysis of hyper-heuristics’, Febru-
ary 2008, <https://www.researchgate.net/publication/220571729_A_comprehensive_
analysis_of_hyper-heuristics>, [accessed April 29 2019]

15. N. Hansen, ’The CMA Evolution Strategy: A Tutorial’, April 4 2016, <https://arxiv.org/pd

f/1604.00772.pdf>, [accessed April 29 2019]

16. J. W. Backus, ’The Syntax and Semantics of the Proposed International Algebraic Language
of the Zurich ACM-GAMM Conference’, 1959, <http://www.softwarepreservation.org/p
rojects/ALGOL/paper/Backus-Syntax_and_Semantics_of_Proposed_IAL.pdf>, [accessed
April 29 2019]

32

17. J. Petke, S. O. Haraldsson, M. Harman, W. B. Langdon, D. R. White, J. R. Woodward, ’Genetic
Improvement of Software: A Comprehensive Survey’, April 25 2017, >https://ieeexplore.i
eee.org/abstract/document/7911210<, [access April 29 2019]

18. J. Brownlee, ’Overﬁtting and Underﬁtting With Machine Learning Algorithms’, March 21 2016,
<https://machinelearningmastery.com/overfitting-and-underfitting-with-machine
-learning-algorithms/>, [accessed April 29 2019]

19. GECCO, ’Annual ”Humies” Awards For Human-Competitive Results’, <http://www.human-com

petitive.org>, [accessed November 12 2018]

20. W. B. Langdon, N. F. McFree, ’A Field Guide to Geentic Programming’, <http://www.gp-fie

ld-guide.org.uk>, [accessed December 28 2018]

21. J.R. Koza, ’Genetic Programming: On the Programming of Computers by Means of Natural
Selection (Complex Adaptive Systems)’, Published by A Bradford Book, December 11 1992,

22. J.R. Koza, ’Genetic Programming: On the Programming of Computers by Means of Natural

Selection (Complex Adaptive Systems)’, Published by A Bradford Book, May 17 1994

23. J.R. Koza, ’Genetic Programming III: Darwinian Invention and Problem Solving (Vol 3)’, Published

by Morgan Kaufmann, May 14 1999

24. D.E. Goldberg, ’Genetic Algorithms in Search, Optimization, and Machine Learning’, Published

by Addison-Wesley Professional, January 11 1989,

25. L. Spector, N. F. McPhee, T. Helmuth, M. M. Casale, J. Oks, ’Evolution Evolves with Auto-
construction’, July 2016, <http://faculty.hampshire.edu/lspector/pubs/wk1202-spect
orA.pdf>, [accessed December 28 2018]

26. Intersoft Consulting, ’General Data Protection Regulation GDPR’, <https://gdpr-info.eu>,

[accessed November 22, 2018]

27. Intersoft Consulting, ’Art. 22 GDPR Automated individual decision-making, including proﬁling’,

<https://gdpr-info.eu/art-22-gdpr/>, [accessed November 22, 2018]

28. D. G Wilson, S. Cussat-Blanc, H. Luga, J. F. Miller, ’Evolving simple programs for playing Atari
games’, June 14 2018, <https://arxiv.org/abs/1806.05695>, [accessed December 28 2018]

29. L. Spector, ’Push, PushGP and Pushpop’, <http://faculty.hampshire.edu/lspector/pus

h.html>, [accessed December 28 2018]

30. Uber Engineering, ’Welcoming the Era Deep Neuroevolution’, <https://eng.uber.com/dee

p-neuroevolution/>, [accessed December 28 2018]

31. ACM, ’GECCO 2018’, <http://gecco-2018.sigevo.org/index.html/tiki-index.php?p

age=HomePage>,July 2018, [accessed December 2 2018]

32. A. Hintze, J. A. Edlund, R. S. Olson, D. B. Knoester, J. Schossau, L. Albantakis, A. Tehrani-
Saleh, P. Kvam, L. Sheneman, H. Goldsby, C. Bohm, C. Adami, ’Markov Brains: A Technical
Introduction’, September 17 2017,<https://arxiv.org/abs/1709.05601 [accessed December
28 2018]

33

33. EpistasisLab, ’TPOT’, Last changed August 30 2018, <https://github.com/EpistasisLab/

tpot>, [accessed December 28 2018]

34. S. Buckley, A. N. McCaughan, J. Chiles, R. P. Mirin, S. W. Nam, J. M. Shainline, G. Bruer, J.
S. Plank, C. D. Schuman, ’Design of superconducting optoelectronic networks for neuromorphic
computing’, November 2018, <http://neuromorphic.eecs.utk.edu/raw/files/publicat
ions/2018-Buckley.pdf>, [accessed December 28 2018]

35. R. Harper, R. J. Chapman, C. Ferrie, C. Granade, R. Kueng, D. Naoumenko, S. T. Flammia, A.
Peruzzo, ’Explaining quantum correlations through evolution of causal models’, July 2017, <ht
tp://www.human-competitive.org/sites/default/files/harper-02-slides.pdf>, [ac-
cessed December 28 2018]

36. J. Kuepper, ’Using Genetic Algorithms to Forecast Financial Market’, April 24 2018, <https://ww

w.investopedia.com/articles/financial-theory/11/using-genetic-algorithms-forec
ast-financial-markets.asp>, [accessed November 17 2018]

37. Spain Foundation for Science and Technology, ’A genetic algorithm predicts the vertical growth
of cities’, May 25 2018, <https://www.eurekalert.org/pub_releases/2018-05/f-sf-aga
052518.php>, [accessed November 17, 2018]

38. G. S. Hornby, A. Globus, D. S. Linden, J. D. Lohn, ’Automated Antenna Design with Evolution-
ary Algorithms’, <http://alglobus.net/NASAwork/papers/Space2006Antenna.pdf>, [ac-
cessed December 2018]

39. A. M. Turing, ’The Chemical Basis of Morphogenesis’, August 14 1952, <https://www.jstor.

org/stable/92463?seq=1#page_scan_tab_contents>, [access April 29 2019]

40. J. V. Neumann, A. W. Burks, ’Theory of Self-Reproducing Automata’, Published by University of

Illinois Press; First Edition edition 1966

41. W. Maass, ’Networks of Spiking Neurons: The Third Generation of Neural Network Models’,
March 27 1996, <https://igi-web.tugraz.at/PDF/85a.pdf>, [accessed April 29 2019]

42. S. Luke, ’Essentials of Metaheuristics’, Lulu 2nd Edition, 2013, <https://cs.gmu.edu/˜sean/

book/metaheuristics/>[accessed December 28 2018]

43. C. Ferreira, ’Gene Expression Programming: Mathematical Modeling by an Artiﬁcial Intelligence’,

Publishing by Springer; 2nd edition (July 11, 2006)

44. K. Leswing, ’Jeﬀ Bezos just perfectly summed up what you need to know about artiﬁcial in-
telligence’, <https://www.businessinsider.com/jeff-bezos-shareholder-letter-on-a
i-and-machine-learning-2017-4>, [accessed December 20 2018]

45. M. Whittaker, K. Crawford, R. Dobbe, G. Fried, E. Kaziunas, V. Mathur, S. M. West, R. Richard-
son, J. Schultz, ’AI Now 2018 Report’, <https://ainowinstitute.org/AI_Now_2018_Repo
rt.pdf>, [accessed December 20 2018]

46. B. Russell, ’Value of Philosophy’, <https://web.ics.purdue.edu/˜drkelly/RussellValueP

hilosophy1912.pdf>, [accessed December 20 2018]

47. E. Real, ’Using Evolutionary AutoML to Discover Neural Network Architectures’, Published March
15 2018, <https://ai.googleblog.com/2018/03/using-evolutionary-automl-to-disco
ver.html>, [accessed December 22 2018]

34

48. N. Maheswaranathan, L. Metz, G. Tucker, D. Choi, J. Sohl-Dickstein, ’Guided evolutionary strate-
gies: escaping the curse of dimensionality in random search’, Published December 19 2018,
<https://arxiv.org/abs/1806.10230>, [accessed December 22 2018]

49. A. Tokmakova, ’Optimizing ﬂoorplans via experimental algorithms’, December 21 2018, <https:

//archinect.com/news/article/150108746/optimizing-floorplans-via-experimental-a
lgorithms>, [accessed December 22 2018]

50. C. Ferreira, ’Gene Expression Programming: A New Adaptive Algorithm for Solving Problems’,
Published 2001, ’https://arxiv.org/pdf/cs/0102027.pdf’, [accessed 22 December 2018]

51. W. Diab, ’About JTC 1/SC 42 Artiﬁcial intelligence’, Published May 30, 2018, <https://jt
c1info.org/jtc1-press-committee-info-about-jtc-1-sc-42/>, [accessed December 22
2018]

52. S. Kelly, M. I. Heywood,

’Emergent Tangled Graph Representations for Atari Game Playing
Agents’, <https://www.researchgate.net/publication/315066110_Emergent_Tangled_G
raph_Representations_for_Atari_Game_Playing_Agents>, [accessed December 23 2018]

53. E. Real, A. Aggarwal, Y. Huang, Quoc V. Le, ’Regularized Evolution for Image Classiﬁer Architec-
ture Search’, October 26 2018, <https://arxiv.org/abs/1802.01548>, [accessed December
28 2018]

54. US Department of Energy, ’Deep learning for electron microscopy’, <https://m.phys.org/new

s/2018-12-deep-electron-microscopy.html>, [accessed December 2018]

55. U.S. Department of Energy, ’ORNL Launches Summit Supercomputer’, June 8 2018, <https:
//www.ornl.gov/news/ornl-launches-summit-supercomputer>, [accessed April 29 2019]

56. ’The LLVM Compiler Infrastructure Project’, <https://llvm.org/>, [accessed January 2 2019]

57. K. O. Stanley, ’Compositional Pattern Producing Networks: A Novel Abstraction of Development’,
Springer 2007, <https://eplex.cs.ucf.edu/papers/stanley_gpem07.pdf>, [accessed Jan-
uary 2 2019]

58. N. T. Siebel, ’Evolutionary Reinforcement Learning’, <http://www.siebel-research.de/evo

lutionary_learning/>, [accessed Jnuary 2 2019]

59. F. P. Such, V. Madhavan, E. Conti, J. Lehman, K. O. Stanley, J. Clune, ’Deep Neuroevolution:
Genetic Algorithms are a Competitive Alternative for Training Deep Neural Networks for Rein-
forcement Learning’, April 20 2018, <https://arxiv.org/pdf/1712.06567.pdf>, [accessed
January 2 2019]

60. M. Gibbs, ’Genetic programming meets regular expressions’, August 2 2015, <https://www.netw
orkworld.com/article/2955126/software/genetic-programming-meets-regular-expre
ssions.html>, [accessed January 2 2019]

61. T. Simonite, ’Moore’s Law Is Dead. Now What?’, May 13 2016, <https://www.technologyre

view.com/s/601441/moores-law-is-dead-now-what/, [accessed January 7 2019]

62. B. Bailey, ’The Impact Of Moore’s Law Ending’, October 29 2018, <https://cacm.acm.org/n
ews/232532-the-impact-of-moores-law-ending/fulltext>, [accessed April 29 2019]

35

63. N. Dahad, ’Imec, ASML Team on Post-3nm Lithography’, October 24 2018, <https://www.ee

times.com/document.asp?doc_id=1333896>, [accessed January 7 2019]

64. A. Zaldivar, ’Introduction to Fairness in Machine Learning’, November 27 2018, <https://deve

lopers.googleblog.com/2018/11/introduction-to-fairness-in-machine.html>, [accessed
January 8 2019]

65. Y. Sverdlik, ’Google is Switching to a Self-Driving Data Center Management System’, August 02
2018, <https://www.datacenterknowledge.com/google-alphabet/google-switching-s
elf-driving-data-center-management-system>, [accessed January 8 2019]

66. J. Brownlee, ’Tabu Search’, 2015, <http://www.cleveralgorithms.com/nature-inspired/

stochastic/tabu_search.html>, [accessed January 10 2019]

67. N. Krasnogor, S. Gustafson, D. A. Pelta, J. L. Verdegay,’Systems Self-Assembly, Volume 5: Mul-
tidisciplinary Snapshots (Studies in Multidisciplinarity) 1st Edition’, Published by Elsevier Science,
May 12th 2008

68. J. Arnold, ’Genetic Drift’, 2001 <https://www.sciencedirect.com/topics/neuroscience/

genetic-drift>, [accessed April 29 2019]

69. Understanding Evolution, ’Genetic drift’, unknown date, <https://evolution.berkeley.edu

/evolibrary/article/evo_24>, [accessed February 4 2019]

70. M. Ammi, S. Chikhi, ’A Generalized Island Model Based on Parallel and Cooperating Metaheuris-
tics for Eﬀective Large Capacitated Vehicle Routing Problem Solving’, 2015, <https://pdfs.sem
anticscholar.org/9a62/be35edffa02ae2170319d002e93b5c1d9cf7.pdf?_ga=2.104627072.
1852817033.1549303865-1734504371.1549303865>, Published in the Journal of Computing
and Information Technology

71. L. Mosescu, ’Darwin Neuroevolution Framework’, 2018, <https://github.com/tlemo/darwi

n>, [accessed February 4 2019]

72. M. Wall, ’GAlib: Matthew’s C++ Genetic Algorithms Library’, March 23 1996, <http://lanc

et.mit.edu/galib-2.4/>, [accessed February 4 2019]

73. H. Beyer, B. Sendhoﬀ, ’Covariance Matrix Adaptation Revisited – The CMSA Evolution Strategy’,
September 2008, <https://www.researchgate.net/publication/220701715_Covariance
_Matrix_Adaptation_Revisited_-_The_CMSA_Evolution_Strategy_->, [accessed February
6 2019]

74. D. H. Wolpert, W. G. Macready, ’No Free Lunch Theorems for Optimization’, April 1997, <https:

//ieeexplore.ieee.org/document/585893>, [accessed April 29 2019]

75. Ivan, ’Parallel and distributed genetic algorithms’, Mar 15 2018, <https://towardsdatascien

ce.com/parallel-and-distributed-genetic-algorithms-1ed2e76866e3>, [accessed Febru-
ary 7 2019]

76. D. Izzo, M. Ruci´nski, F. Biscani, ’The Generalized Island Model’, January 2012 <https://www.
researchgate.net/publication/285622237_The_Generalized_Island_Model>, [accessed
February 7 2019]

36

77. A. N. Sloss, ’Book Review: “The Book of Why: The New Science of Cause and Eﬀect” By Judea
Pearl and Dana Mackenzie’, September 27 2019, <https://www.linkedin.com/pulse/book-r
eview-why-new-science-cause-effect-judea-pearl-dana-sloss/>, [accessed February
11 2019]

78. R. H. Dennard, F. Gaensslen, H. N.Yu, L. Rideout, E. Bassous, A. LeBlanc, ’Design of Ion-
Implanted MOSFET’s with Very Small Physical Dimensions’, October 1974, <https://www.ece.
ucsb.edu/courses/ECE225/225_W07Banerjee/reference/Dennard.pdf>, [accessed March
29 2019]

79. Y. LeCun, Y. Bengio, G. Hinton, ’Deep Learning’, May 15 2015, <https://www.nature.com/a

rticles/nature14539>, [accessed March 29]

80. D. Whitley, ’Next Generation Genetic Algorithms’, July 2018, <http://gecco-2018.sigevo.o

rg/index.html/tiki-index.php?page=Tutorials>, [accessed March 2019]

81. W. J. Broad, ’Paul Feyerabend: Science and the Anarchist’, November 2 1979, <https://www.
jstor.org/stable/1749231?seq=1#page_scan_tab_contents>, [accessed April 4 2019]

82. J. A. Shapiro, ’21st century view of evolution: genome system architecture, repetitive DNA, and
natural genetic engineering’, January 4 2005, <http://shapiro.bsd.uchicago.edu/Shapiro
.2005.Gene.pdf>, [accessed April 4 2019]

83. D. Cossins, ’Discriminating algorithms: 5 times AI showed prejudice’, April 27 2018 <https://ww
w.newscientist.com/article/2166207-discriminating-algorithms-5-times-ai-showe
d-prejudice/>, [accessed April 26 2019]

84. A. Purohit, N. S. Choudhari, ArunaTiwari, ’Code Bloat Problem in Genetic Programming’, April
2013, <http://www.ijsrp.org/research-paper-0413/ijsrp-p1612.pdf>[accessed May 26
2019]

37

