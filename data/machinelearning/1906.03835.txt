9
1
0
2

n
u
J

0
1

]

G
L
.
s
c
[

1
v
5
3
8
3
0
.
6
0
9
1
:
v
i
X
r
a

SAR: Learning Cross-Language API Mappings with Little
Knowledge

Nghi D. Q. Bui
School of Information Systems
Singapore Management University
dqnbui.2016@phdis.smu.edu.sg

Yijun Yu
Department of Computing &
Communications
The Open University
y.yu@open.ac.uk

Lingxiao Jiang
School of Information Systems
Singapore Management University
lxjiang@smu.edu.sg

ABSTRACT
To save effort, developers often translate programs from one pro-
gramming language to another, instead of implementing it from
scratch. Translating application program interfaces (APIs) used in
one language to functionally equivalent ones available in another
language is an important aspect of program translation. Existing
approaches facilitate the translation by automatically identifying
the API mappings across programming languages. However, these
approaches still require large amount of parallel corpora, ranging
from pairs of APIs or code fragments that are functionally equiva-
lent, to similar code comments.

To minimize the need of parallel corpora, this paper aims at an
automated approach that can map APIs across languages with much
less a priori knowledge than other approaches. The approach is
based on an realization of the notion of domain adaption, combined
with code embedding, to better align two vector spaces. Taking as
input large sets of programs, our approach first generates numeric
vector representations of the programs (including the APIs used
in each language), and it adapts generative adversarial networks
(GAN) to align the vectors in different spaces of two languages. For
a better alignment, we initialize the GAN with parameters derived
from API mapping seeds that can be identified accurately with a sim-
ple automatic signature-based matching heuristic. Then the cross-
language API mappings can be identified via nearest-neighbors
queries in the aligned vector spaces. We have implemented the
approach (SAR, named after three main technical components in
the approach) in a prototype for mapping APIs across Java and
C# programs. Our evaluation on about 2 million Java files and 1
million C# files shows that the approach can achieve 54% and 82%
mapping accuracy in its top-1 and top-10 API mapping results with
only 257 automatically identified seeds, more accurate than other
approaches using the same or much more mapping seeds.

KEYWORDS: software maintenance, language mapping, word2vec,
syntactic structure, program translation

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
ICSE-NIER’18, May 27-June 3 2018, Gothenburg, Sweden
© 2018 Copyright held by the owner/author(s). Publication rights licensed to the
Association for Computing Machinery.
ACM ISBN 978-1-4503-5662-6/18/05. . . $15.00
https://doi.org/10.1145/3183399.3183427

1 INTRODUCTION
Migrating software projects from one language to another is a com-
mon and important task in software engineering. To support the
process, various migration tools have been proposed. A fundamen-
tal challenge faced by such tools is to translate the library APIs of
one language to functionally equivalent counterparts of another. Of-
ten, much manual effort is required to define the mappings between
the respective APIs of two languages.

Several studies have addressed this API mapping problem, such
as MAM [35], StaMiner [19], DeepAM [11], and Api2Api [24].
MAM [35] and StaMiner [19] require as input a large body of par-
allel program corpora, which contain functionally equivalent code
that use APIs in both languages, in order to mine the mappings.
Thus, they rely heavily on the availability of bilingual projects
that implement the same functionality in two or more languages,
which is not easy to find for any pair of languages. Although they
rely on similar function names to reduce manual effort needed to
identify parallel data, many functions with similar names may be ac-
tually functionally different, degrading the quality of training data
and final mapping results. DeepAM [11] maps API sequences to
sequences based on the text descriptions for the sequences. Its intu-
ition is that two API sequences across languages may be mapped to
each other if their text descriptions are similar. This approach does
not need API mapping seeds, but requires many similar text descrip-
tions across programs written in different programming languages
whose availability can affect the mapping results. Api2Api [24]
uses a vector space transformation method inspired by Mikolov
et al. [15], but it still requires many API mapping seeds from an
external source (Java2CSharp [3])) to map APIs across languages.
In this paper, we propose an approach that can map APIs across
languages while alleviating the shortcoming of existing approaches.
We realize that the underlying goal of state-of-the-art techniques
is essentially to find a transformation that can align two different
domains (in our context, the two vector spaces for APIs in two
different languages). Api2Api [24] is also an instance of this idea to
learn an optimal transformation matrix between two vector spaces
while requiring much parallel training data. However, empirical
evidence of existing approaches suggest that collecting the training
data is an expensive process that requires either availability of
manual inspection or high-quality documentations. This has led
to the following research question we aim to answer in this paper:
"Can a model be built to minimize the need of parallel data to map
APIs across languages?".

We realize that the API mapping problem may be addressed by
techniques based on generative adversarial training [8] with the
assistance of a pre-trained model. Given large code bases in two

 
 
 
 
 
 
ICSE-NIER’18, May 27-June 3 2018, Gothenburg, Sweden

Nghi et al.

languages, it is likely that certain similarities between the code
bases can be exploited to discover APIs of similar functionality
across languages, without manually specifying parallel corpora.
Such knowledge of similar functionalities may not be big enough
for a complete mapping model, but it is small enough to afford
human validation. Once validated, the knowledge can be transferred
through adversarial training techniques to maximize the alignment
between the two languages which results in better API mappings.
Our approach for API mapping works in the following way: (1)
it takes in a large number of programs in two languages, and gen-
erates a vector space representing code and APIs in each language
via a word embedding technique adapted from previous studies [2,
11, 19, 24, 35]; (2) it adapts domain adaption techniques [5, 7, 8] to
transform and align the two vector spaces for the two languages,
with mainly three technical components: Seeding, Adversarial train-
ing, and Refinement; and (3) it utilizes nearest-neighbors queries
in the aligned vector spaces to identify the mapping result of each
API. We name our approach SAR, after the three main technical
components in the domain adaption step.

We have implemented the approach in a prototype tailored for
Java and C#, and evaluated and compared it with the state-of-the-
art techniques, such as StaMiner, DeepAM and Api2Api [24]. We
have evaluated the prototype on a dataset of more than 14,800 Java
projects containing approximately 2.1 million files and 7,800 C#
projects containing approximately 958,000 files. Our evaluation re-
sults indicate that the approach can achieve 54% and 82% accuracy
in its top-1 and top-10 API mapping results with only 257 auto-
matically identified seeds, more accurate than other approaches
using the same or much more mapping seeds. In addition, we also
identify about 400 more API mappings between the Java and C#
SDKs than other approaches.

The main contributions of this paper are as follows:

• We propose SAR, a new approach based on domain adaption
techniques to transform and align different vector spaces across
languages with the assistance of a seeding, adversarial learning,
and refinement method. To the best of our knowledge, we are
the first to apply the adversarial training techniques for the API
mapping task.

• We adapt the adversarial training techniques in a number of ways
to improve its alignment of the vector spaces: (1) we use nearest-
neighbor queries to identify possible mapping candidates for
better alignment; (2) we use a similarity-based model selection
criteria and reduce the need of known API mappings during the
training of our model; and (3) we use the Procrustes algorithm
to find the exact solution of the mapping matrix.

• We have implemented the approach and evaluated it with a
corpus containing millions of Java and C# source files; via an
extensive empirical evaluation on different components of our
approach, we demonstrate its advantages against other API map-
ping approaches in producing more accurate mappings with
much fewer seeds that can be automatically identified.
The rest of the paper is organized as follows. Section 2 discusses
studies in the literature closely related to this paper; Section 3
presents the background about vector space mapping and adver-
sarial learning; Section 4 presents our approach in detail; Section 5
evaluates our approach to demonstrate its effectiveness and discuss
its limitations; and Section 7 concludes with possible future work.

2 RELATED WORK
This section briefly reviews related work on cross-language pro-
gram translation and relevant techniques.

Cross-Language Program Translation. For the problem of cross-
language program translation, much work has utilized various
statistical language models for tokens [21], phrases [13, 22, 23], or
APIs [19, 20, 26, 34, 35]. A few studies also used word embedding for
API mapping and migration (e.g., [10, 11, 24, 26]), but our work does
not need large number of manually specified parallel corpora or
mapping seeds. Tools for translating code among specific languages
in practice (e.g., Java2CSharp [3]) also often dependent on manually
defined rules specific to the grammars of individual languages,
while our approach alleviates the need of language-specific rules.
MAM [35] and StaMiner [19] rely on the availability of bilingual
projects that implement the same functionality in two or more
languages. DeepAM [11] requires many similar text descriptions
across programs written in different programming languages whose
availability can affect the mapping results. Api2Api [24] requires
many API mapping seeds from Java2CSharp [3]) to map APIs across
languages. The idea of our approach is most similar to Api2Api,
while we combine seed-based and unsupervised domain adaptation
techniques to reduce the need of mapping seeds.

Relevant Techniques. For the techniques used to represent, model,
learn source code, many studies exist for building various statistical
language models of code for various purposes in recent years [1].
When it comes to what models to use for code, there is still much
room for improvement. Hellendoorn et al. [12] showed that simpler
code learning models (e.g., n-gram) with caches of code locality and
hierarchy may outperform complex deep neural network models.
While other studies (e.g., [11, 13, 20]) demonstrate that more gram-
matical and semantic code features at various levels of abstraction
can be useful for more accurate models. These studies provoke us
to perform code embedding with structural information, and in
future to explore more semantic information for code embedding.
However, existing studies using domain adaption techniques for
API mapping and translation still require the creation of mapping
seeds [24, 26].

To transform vector spaces, studies in NLP on sentence compari-
son and translation involve variants of bilateral models to align the
contents [31], but they require parallel corpora in two languages.
Recent progresses in domain adaption alleviate the need of paral-
lel corpora [5, 7, 8]. In an application to image learning, domain
adaptation through GAN has shown benefit to transfer the models
from other dataset as pre-training models when training on smaller
dataset [30], which provides the technical foundation for our work.

3 BACKGROUND
The goal of domain adaptation is to produce a mapping matrix as an
approximation of the similarities between vectors in the two spaces.
This section gives a brief overview of two methods for domain
adaptation: seed-based or unsupervised. Apart from the two input
vector spaces, the seed-based method also requires a set of seeds as
the parallel training data to learn the matrix, while unsupervised
method does not: the mapping matrix can be obtained through
adversarial learning assuming that similarity exists between the
distributions of vectors in the two spaces.

SAR: Learning Cross-Language API Mappings with Little Knowledge

ICSE-NIER’18, May 27-June 3 2018, Gothenburg, Sweden

3.1 Seed-based Domain Adaptation
Given two sets of embeddings have been trained independently
on monolingual data, seed-based domain adaptation is to learn a
mapping using the seeds s.t. their translations are close in a shared
vector space. Such an idea has been explored for word translation
in NLP [15], and Api2Api [24] adapts it to learn API mappings.

Formally, given two vector spaces, X = {x1, . . . , xn } and Y =
{y1, . . . , ym }, containing n and m embeddings for two languages L1
and L2, and a set S of seeds of API embedding pairs {(xsi , ysi )}si ∈ {1, |S | },
we want to learn a linear mapping W between the source and the
target space, such that W xsi approximates ysi . In theory, W can be
learned by solving the following objective function:
W ∗ ≜ arдmin

||W XS − YS ||

(1)

W ∈M ⊂Rd ×d

where d is the dimension of the embeddings; M ⊂ Rd ×d is the
space of d × d matrices of real numbers; XS ≜ {xsi } ⊂ X and
YS ≜ {ysi } ⊂ Y contain the embeddings of the APIs in the seeds,
which are matrices of size d × |S |.

Instead of approximating a solution using traditional stochastic
gradient descent method used in Api2Api [24], there exists an
analytical Procrustes problem [28] solved by Xing et al. [32], which
has a closed form solution of the mapping matrix derived from the
singular value decomposition (SVD) of Y XT :

W ∗ = arдminW ||W Xs − Ys || = UV T , with U ΣV T = SV D(Ys XT
s )
The advantage of a closed form solution is that one can get the
exact solution which is better than the approximate solution of
gradient descent, and is faster in computation.

(2)

With the mapping matrix W , one can use yx = W x to map a
query vector x. The vector yx is the mapping, or adaptation, of x
in the target space.

3.2 Unsupervised Domain Adaptation
Adversarial learning has been successfully used for domain adap-
tation in an unsupervised manner. In particular, the Generative
Adversarial Network [8] achieves this goal by a model which com-
prises a generator and a discriminator as two inter-playing compo-
nents. A generator network that aims to learn real data distribution
and produce fake data to fool the other component, so-called the
discriminator; the discriminator network that acts as a classifier,
which aims to distinguish the generated fake data from the real
data. The two components are trained in a minimax fashion and
would converge when the generator has maximized its ability to
generate fake data so similar to the real data that the probability
for the discriminator to make a mistake would be 1
2 .

Conneau et al. [5] use this idea as a variant for the machine
translation task, which achieves significantly better results than
other baselines of machine translation, which would require no
parallel data to train the networks. The generator, in this case, is a
mapping matrix W , which can simply be seen as a set of parameters
that need to be learned, and the discriminator is a feed-forward
neural network. We want to find a matrix W as an approximation
of the mapping between the two vector spaces X and Y . In the
adversarial learning setting, we aim to optimize two parameters:
one is the discriminator’s parameters, denoted as θD , the other is
the mapping matrix W . Our goal is to find the optimal value of

Figure 1: Approach Overview

two sets of parameters, which results that we have two objective
functions in the adversarial learning setting.

Discriminator objective. Given the mapping W , the discriminator

(parameterized as θD ) is optimized by this objective function:

LD (θD |W ) = −

n
(cid:213)

i =1

loдPθD (sour ce = 1|W xi ) −

m
(cid:213)

i =1

loдPθD (sour ce = 0 |yi )

(3)

(cid:0)source = 1(cid:12)

(cid:12)v(cid:1) is the probability that a vector v originates
where PθD
from the source embedding space (as opposed to an embedding
from the target space).

Mapping objective. Given the discriminator θD , the mapping W
aims to fool the discriminator’s ability of predicting the original
domain of an embedding by minimizing this objective function:

LW (W |θD ) = −

n
(cid:213)

i =1

loдPθD (sour ce = 0|W xi ) −

m
(cid:213)

i =1

loдPθD (sour ce = 1 |yi )

(4)

Learning Algorithm. The discriminator θD and the mapping W
are optimized iteratively to minimize LD and LW , respectively by
following the training procedure of adversarial networks proposed
by Goodfellow et al. [8]

4 OUR APPROACH
Combining the virtues of seed-based and unsupervised adversarial
methods described in the background, our domain adaptation ap-
proach can approximate two spaces of vectors with minimal parallel
corpora. Although unsupervised adversarial learning method does
not require any seed as parallel data, the distributions of vectors
(i.e. embeddings) in the two spaces may not be similar. Therefore,
it is our hypothesis that the performance could be improved by
initializing the unsupervised adversarial learning method with a
small set of seeds taken from the seed-based domain adaptation,
and by generating the rest of API mappings in the following two
steps:

• From large code corpora in two different languages, we cre-
ate two vector spaces for APIs by adapting word embedding
technique for code. From such corpora,we derive a small set
of mappings based on a simple text similarity heuristic (see

ICSE-NIER’18, May 27-June 3 2018, Gothenburg, Sweden

Nghi et al.

Code Embedding in Figure 1);

• The two vector spaces, along with the mapping seeds, are
transformed by a mapping matrix to get aligned with each
other. This step comprises three sub-steps: Seeding, Adver-
sarial Learning, and Refinement (see Domain Adaptation in
Figure 1).

For any given API a in the source language and its continuous
vector representation x, we can map it to the other domain space
by computing yx = W x. Then, one can find the top-k nearest
neighbors of yx in the target vector space, using cosine similarity
as the distance metric, and finally can retrieve the list of APIs in
the target language that have the same embeddings as the top-k
nearest neighbors. The list of APIs can then be used as the mapping
results for a (see Cross-Space Near-Neighbor Query in Figure 1).

The following subsections detail these sub-steps.

4.1 Code Embedding via Word Embedding
We first parse source code files into Abstract Syntax Trees (AST)
using srcML [4] for both Java and C# projects. Then we extract from
individual functions the code sequences and perform a normaliza-
tion. The normalization enriches the code sequence with structural
semantic information extracted from parsing, which constitutes
two steps:

Filtering out noisy tokens. Tokens are considered noisy if they
are not API tokens. To leverage as much structural information as
possible, language keywords and AST node types are still kept for
code embedding.

Converting raw API tokens into signatures. This step reduces the
variance of vocabulary existing in the source code. For example,
one may extract the ‘List.add’ method from the ‘java.util.List’ class,
or from the ‘com.google.common.collect.List’ in an external third-
party library. Even though these two APIs have the same class
and method names, their usages and semantics are different. To
handle such cases, we propose this additional step to convert a
raw API token to its signature in qualified name format ‘<Pack-
age>.<Class>.<Method>’.

Below shows an example of the normalization for the code token

sequence:

List.add List.add if List.addAll else HashMap.put return

==> java.util.List.add java.util.List.add if

java.List.addAll

else java.util.HashMap.put return

From the corpora of code sequences, we use the skip-gram
word2vec [14] model to train the embedding of each token. Given a
large corpus as the training data, the tokens appearing in the same
context would usually have their embeddings close by distance in
the vector space.

4.2 Domain Adaptation
Our domain adaptation comprises three steps: seeding, adversarial
training, and refinement (hence the abbreviation SAR of our ap-
proach). Seeing SAR from outside as a black-box, it receives two
vector spaces and a set of seeds as input and generates a mapping

Figure 2: Domain adaptation steps to align two vector spaces

matrix W as output. Internally, each step of SAR is a different way
to improve the mapping matrix, which receives the matrix out-
put from the previous step as input and produces the improved
version of it as output. We assign W1, W2 and W3 as the output
matrix for the three steps, respectively. Figure 2 summaries the
domain adaptation procedure as a whole. The rationale for each
step is described as follows: (1) The Seeding step to initialize a
mapping matrix between the two vectors spaces based on some
prior knowledge (i.e., seeds) (2) The Adversarial Learning step
to re-use the knowledge learned from the Seeding step as an ini-
tializer for adversarial training in order to maximize the similarity
between the two vector spaces (or two distributions); and (3) The
Refinement step to make the mapping matrix better and reach its
optimal state.

4.2.1

Seeding. After Code Embedding, two vector spaces are
obtained to produce a mapping matrix that approximates the two
vector spaces by using the knowledge from mapping seeds in a
dictionary. Notice that by a simple signature-based comparison to
identify APIs having the same signature name, one can identify
many high-quality mapping candidates to be used as the seeds
without any human effort to verify because developers often use
the same name for the same functionality even when they are in
different languages.

Having the dictionary D obtained, in addition to the two vector
spaces X and Y , the initial mapping matrix produced is W1 by
solving the Equation 1 in Section 3 (also see Seeding in Figure 2).
This seeding step can be seen as a function A, which will receive
these three inputs and produces a transforming matrix W1 such
that W1 = A(X , Y , D). Internally, A solves the optimization problem

SAR: Learning Cross-Language API Mappings with Little Knowledge

ICSE-NIER’18, May 27-June 3 2018, Gothenburg, Sweden

described in Section 3 given the three inputs.

4.2.2 Adversarial Learning. The quality of the matrixW1 learned
in previous step is limited by the number of seeds one can provide,
which results in an approximation between the source and target
domains. In this case, the knowledge learned for W1 can be seen as
a pre-trained model and can be reused for the other model.

Formally, given the two original vector spaces, X = {x1, . . . , xn }
and Y = {y1, . . . , ym },containing n and m API embeddings obtained
from the Code Embedding step, we want to find the matrix W2
to maximize the approximation of the mapping between the two
vector spaces. We use the adversarial learning to achieve this goal.
We build the adversarial learning network comprises of two steps:
the mapping matrix W2 and a discriminator network as described
in Section 3.2. Our goal is to find the optimal value of W2 and θD
(discriminator parameters) We achieve this by training the adver-
sarial network with the objective functions as described in Section
3.2 to find W2 and θD .

The key difference with the general adversarial setting described
Section 3.2 is that we do not initialize W2 randomly as one usually
does when training a neural network. Instead, we use W1 as a pre-
trained model to initialize for the W2 so that W2 is initialized with
some good knowledge, even if it is small (see Adversarial Learning
in Figure 2). This step is essential to improve the performance of
the API mapping results.

Model Selection Criteria. To train the adversarial networks, like
any other neural network architecture, we need a validation set
to select the best model for the prediction step. The validation set
is used to minimize overfitting when training the neural network.
Concretely, for each training epoch, one needs to evaluate against
the validation dataset to pick the model that has the highest valida-
tion accuracy through training. Our goal is to use as little parallel
data as possible to build the model. In practice, one only has a very
small number of seeds inferred from the signature-based matching,
or in the worst case, one cannot infer any seed to have data for
validation. As such, it is impractical to use a parallel dataset as a
validation set to train neural networks in the adversarial learning
step, i.e., involving additional prior knowledge.

To address this issue, we propose to use a model selection using
an unsupervised criteria that quantifies the closeness of the source
and target embedding spaces. Specifically, we consider them a set of
K most frequent source APIs and multiply them with the mapping
matrix W to generate a target API mapping for each of them. We
then compute the average cosine similarity between these deemed
mapping and use their average as a validation metric.

4.2.3 Refinement for Better Alignment. The adversarial approach
tries to align all words irrespective of their frequencies. However,
rare tokens have embeddings that are less updated and are more
likely to appear in different contexts in each corpus, which makes
them harder to align [5]. To address this problem, we use the method
proposed in [5] to infer a list of mapping candidates using only the
most frequent tokens. Moreover, other heuristics are introduced to
infer another candidate set of mapping based on the threshold of
cosine similarity, which can be used as another synthetic dictionary
that can combine with the top-K frequency mapping candidates.

mapping candidates using W2 just learned with adversarial training.
Assume that one can induce a combined set of mapping candidates
from different heuristics above, and the quality of the combined set
is good, then this set of candidates should be used to learn a better
mapping and, consequently, an even better set of candidates for the
next iteration. The process can repeat iteratively to obtain a hope-
fully better mapping and candidates set each iteration until some
convergence criteria are met. Formally, the refinement step receives
W2 from the previous adversarial learning step, along with the two
original embeddings X and Y to produce the next W3 iteratively
(see Refinement in Figure 2).

Specifically, we produce the mapping candidates for refinement

based on two heuristics:

Top-K Frequency: Conneau et al. [5] shows that by taking the
top-k frequent words and their nearest neighbors in the trans-
formed vector spaces, it can provide high-quality mapping candi-
dates because the most frequently used words are likely to be the
same across languages. Therefore, we can use the top-k frequent
API names to induce the seeds for the refinement.
Cosine Similarity Threshold: Since finding API mappings in
the aligned vector space is essential to finding APIs close enough
in the vector space, all API pairs “similar enough” in the vector
space aligned by Adversarial Learning can be good candidates for
the refinement step. In this work, we use the cosine similarity as
the metric to measure how similar two vectors are. We note that
not all APIs in a language can have a mapping in another language.
In the empirical case study, we show how a good threshold is
found in Section 5.3.2.

Therefore, we can infer two sets of synthetic mapping candidates
from the above heuristics. In fact, there are different ways to merge
them into one single set as they can overlap as, e.g., (1) the union
of the two sets, (2) the intersection of the two sets.

The matrix W3 in this step is the final output of the domain
adaptation process. When it comes to the step to produce the map-
ping from the source query, the embeddings of the query will be
multiplied with W3 in order to obtain corresponding mappings in
the target language.

5 EMPIRICAL EVALUATION
We have conducted extensive empirical evaluations on our approach
in various settings to answer the following research questions:

RQ1 Compared to related methods, is our approach more effective

in identifying API mappings?

RQ2 How well do different combinations of refinement heuristics

improve the performance?

RQ3 How do the seeds overlapping effect on the performance?
RQ4 What is the impact of each component in our approach on

the performance?

5.1 Dataset
We use the Java Giga corpus data described by Allamanis et al. [36].
It involves approximately 14,807 Java projects from Github and
contains approximately 2.1 millions of files. For C#, we clone the
projects on Github that have at least 1 star and collect 7,841 C#
projects with about 958,000 files.

Following the step shown in [5], it is possible to build a set of

As the main advantage of our approach, there is no need to

ICSE-NIER’18, May 27-June 3 2018, Gothenburg, Sweden

Nghi et al.

Table 1: Example of Seeds from the Signature-based Match-
ing Heuristic

Java

C#

java.lang.String.equals
java.util.List.remove
java.util.Random.nextDouble
java.lang.Math.round
java.io.File.Exists

System.String.Equals
System.Collections.Generic.List.Remove
System.Random.NextDouble
System.Math.Round
System.IO.File.Exists

specify which code in Java is functionally equivalent to which
code in C#. For each function in a file, we traverse the AST of the
function to extract the API call sequences. For Java, we get a corpus
containing 6.7 million code sequences; for C#, we get a corpus
containing 5.1 million code sequences.

For evaluation, we take 860 method API mappings and 430 class
API mappings defined in Java2CSharp [3] as the ground truth for
evaluating our approach against the baselines.

5.2 Implementation
We adapt Gensim [27] in NLP to produce the embeddings of tokens
for the Java and C# corpora. We use the same settings used by
Mikolov et al. [16] during the training: stochastic gradient descent
with a default learning rate of 0.025, negative sampling with 30
samples, skip-gram with a context window of size 10, and a sub-
sampling rate of value 1e−4.

Evaluation Metrics. We define the top-k accuracy as the evalu-
ation metric throughout the experiments. The top-k accuracy is
defined as follow: For a test JDK API j, SAR produces a resulting list.
If the true mapping API in C# .NET for j is in the top-k resulting
list, we count it a hit. If not, we count it a miss. Top-k accuracy is
computed as the ratio between the number of hits and the total
of hits and misses for a given ground-truth test set. We use this
simplified metric for easier comparison with other approaches. In
real-world uses, one may retrieve a list of API mapping results
given a query, and better use other information retrieval metrics,
such as Mean Average Precision (MAP) or Mean Reciprocal Rank
(MRR) as the evaluation metrics.

Code Embedding. From the two code corpora, we scan through
all pairs of APIs in the two corpora to produce a set of seeds using
the signature-based matching heuristic. We got 257 seeds for this
step. Table 1 shows examples of the seeds. Among these 257 seeds,
we found that 83 seeds overlap in 860 mappings of the ground truth.
Then, we apply the Code Embedding step on the corpora get the
source embedding and target embedding, we use them, along with
the seeds as the input for the domain adaptation process.

Domain Adaptation. For the seeding step, we find W1 by using
the Procrustes solution in Equation 2 with the three inputs: source
embedding X (Java), target embedding Y (C#) and 257 seeds. This
step gives us the mapping matrix W1. We implement the adversarial
learning by using PyTorch [25]. We use Momentum Gradient De-
scent method [29] to search for the optimal transformation matrix.
We use the unsupervised model selection criteria proposed in
Section 4.2.2 to select the best model by choosing the top 1000
frequent API token pairs, e.g top-1 frequent token in the source is
aligned with top-1 frequent token in the target as the validation
set, then we extract the W2 from the model. Figure 3 shows three

Figure 3: Unsupervised Model Selection Criteria

Table 2: API Mappings - Baselines

Index
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24

Baselines

Random seeds: Api2Api

Random seeds: SAR

K-Fold: Api2Api

K-Fold: SAR

Signature-based: Api2Api

Signature-based: SAR

K-folds
-
-
-
-
-
-
-
-
1-fold
2-folds
3-folds
4-folds
1-fold
2-folds
3-folds
4-folds
-
-
-
-
-
-
-
-

Seeds
0
10
50
100
0
10
50
100
172
344
516
688
172
344
516
688
25
50
100
257
25
50
100
257

Top-1
0.03
0.09
0.14
0.19
0.25
0.28
0.26
0.44
0.24
0.34
0.37
0.43
0.36
0.45
0.54
0.59
0.12
0.20
0.27
0.35
0.30
0.37
0.43
0.54

Top-5
0.05
0.12
0.19
0.24
0.30
0.35
0.43
0.50
0.35
0.45
0.51
0.64
0.39
0.50
0.66
0.77
0.16
0.23
0.32
0.41
0.35
0.41
0.50
0.75

Top-10
0.1
0.14
0.22
0.32
0.35
0.40
0.47
0.69
0.41
0.55
0.67
0.72
0.48
0.61
0.71
0.84
0.18
0.29
0.38
0.55
0.40
0.48
0.67
0.82

different lines: (1) the discriminator accuracy, which is the accuracy
in classifying the samples from the source and target embeddings
(2) the API mapping accuracy, which is the accuracy when using
the model to evaluate against the 1000 pairs validation set; and (3)
the average cosine similarity of all the pairs. As shown, the criteria
correlate well to the mapping accuracy.

From W2 resulting from the adversarial training, we obtain the
final W3 by performing the refinement step on the basis of two
heuristics in Section 4.2.3. For the top-N frequency heuristics, we
choose top-500 frequent tokens for the synthetic dictionary, as
suggested in [5]. For the second similarity threshold rule, we use
0.7 as the threshold as shown in Section 5.3.2, we found that this
number balances coverage and precision of API mappings well.

Our source code and experimental results can be accessed at the

anonymous repository1.

5.3 Evaluation

5.3.1 RQ1. Effectiveness of SAR in Mining API Mapping. The
first question we want to answer is how effective our approach in
identifying API mappings from the two vector spaces. We compare
SAR with Api2Api, StaMiner, and DeepAM.

1https://github.com/djxvii/fse2019

SAR: Learning Cross-Language API Mappings with Little Knowledge

ICSE-NIER’18, May 27-June 3 2018, Gothenburg, Sweden

Result Summary. Index 24 in Table 2 uses 257 API mappings
automatically selected by the signature-based matching heuristic
and test against the 860 ground truth mappings. Index 16 uses 688
mappings selected randomly from the 860 ground truth set and test
against the rest. The performance of SAR in term of top-k accuracy
is shown. As one can see in both cases, the top-1 accuracies are
above 50%, and the top-10 accuracies are above 80%.

Compare to Api2Api. The method used in Api2Api is correspond-
ing to the seeding step in our domain adaptation process, which
finds a mapping matrix by solving the Equation 1 given a large set
of seeds. We use the top-k accuracy as the evaluation metric.

Table 2 shows the top-k accuracy of our approach when com-
paring to Api2Api in various settings. First, we compare Api2Api
with SAR using the seeds coming from two different sources: the
860 mappings defined by Java2CSharp and the 257 mappings in-
ferred from the signature-based matching. Here we described the
variances as results shown in Table 2, indicating that our approach
can use much fewer number of seeds compared to Api2Api but still
achieve better results.
• Select randomly: we select a subset of mappings r randomly from
860 mappings in the ground truth, and test against the rest 860−r
mappings. Concretely, r = 0, 10, 50, and 100;

• k-fold: we divide the 860 mappings into k = 1, 2, 3, 4 folds and
perform the variants of five-fold cross-validation: while k folds
are used as training data, the other 5 − k folds are used as testing
data;

• Select by signature: we use 257 mappings inferred by method
signature, and select randomly a varying number of them as the
training data and test against the remaining mappings in the
ground truth.

The process repeats for using different folds as the training data
for both Api2Api and we take the average accuracy are some ob-
servations from the results:
• Using the same number of seeds, either using the seeds from
Random, K-fold or Signature-based, we get significantly better
results than Api2Api for every setting.

• Our approach only needs 100 signature-based seeds to get a
comparable result (43% for Top-1) or better results (Top-5 and
Top-10) with Api2Api that uses 688 manually crafted seeds.
• When using all of the 257 signature-based seeds, our approach
gets significantly better results than Api2Api: top-1 improves
19%, top-5 improves 34%, and top-10 improves 27%.

Compare to StaMiner and DeepAM. We follow the details de-
scribed in StaMiner and DeepAM to measure how well SAR per-
forms in mining API mappings for Class API and Method API. In
Java, an API element, by definition, can be a class, a method or a
field in the class; and it must belong to a package (or the names-
pace in case of C#). As such, the goal in this task is to measure
the performance the Class and Method API mapping task one by
one for each API of each package, i.e., to see which package has
the best performance for API mappings, so-called 1-to-1 mappings.
For the method API mapping, we use the 860 method ground truth
mapping described in Section 5.1 for evaluation. For the class API
mapping, we use the 430 class ground truth mapping described
in Section 5.1 for evaluation. We follow the details described in

DeepAM to choose only the APIs under the packages as shown
in Table 3, column ’Package’, so that the total number of method
API mapping left is 289 (remaining from 860 ground truth method
API mappings), and the total number of class API Mapping 283
(remaining from 430 ground truth class API mappings).

Adapting SAR for class-level API mapping is relatively easy: one
can remove the method part of a qualified API signature token so
that only the package and class parts of the token are retained in
the code sequences. Then code embedding for the API sequence
can be derived as the embedding of the class-level API, along with
other keywords from the ASTs. We do this for both languages. To
select mapping seeds by API signatures, we first infer the mappings
from signatures at the class level, then follow a similar domain
adaptation process from APIs at the method-level.

One could not run StaMiner and DeepAM directly because they
require parallel data (aligned function body for StaMiner, and aligned
code and text description for DeepAM) for training. Therefore, we
had to compare to them by extracting the reported performance
numbers from their papers. This is also how DeepAM compared
itself to StaMiner.

We use the F-score as the performance metric to measure accu-
racy in this evaluation. It is defined as F = (2PR)/(P + R), where
Precision P = T P/(T P + F P) and Recall R = T P/(T P + F N ). TP
refers to the number of true positives, which is the number of API
mappings that are in both result datasets and the groundatasets;
TN refers to the number of true negatives, which is the number of
API mappings that are neither in the returned results nor in the
ground truth datasets; FP refers to the number of false positives
which represents the number of result mappings that are not in the
ground truth set; FN refers to the number of false negatives, which
represents the number of mappings in the ground truth set but not
in the results.

Table 3 shows the comparison results of our mined API map-
pings with StaMiner (Sta) and DeepAM (DeepA). Columns “Class
Mapping" and “Method Mapping" list results of comparing API
classes and methods, respectively. As one can see for the F-score,
our approach has better results than those of DeepAM and StaMiner
at the level of both classes and methods with much fewer seeds,
while DeepAM needs to use millions of similar API sequence de-
scriptions and StaMiner needs to use ten of thousands of pairs of
parallel data.

Newly found API mappings. More interestingly, we found a lot
more new API mappings than other studies in our actual code
corpora. For each of the API in Java, we query the top-10 nearest
neighbors in C# and manually verify the mappings. We enforce
the threshold = 0.7 as mentioned in Section 5.3.2 for this task. We
found 420 new SDK API mappings that can complement the tool
Java2CSharp. Comparing to MAM (25 new mappings), StaMiner
(125 new mappings), Api2Api (52 new mappings), we found a suffi-
ciently larger number of mappings and our newly found APIs also
overlap with the APIs in these baselines. In Table 4, we show some
interesting examples of such newly found API mappings whose
name do not match exactly using traditional approaches. Our list
of newly found Java/C# APIs mappings can be accessed at this
anonymous Github repository: 2.

2https://github.com/djxvii/fse2019/blob/master/new_found/new_found_apis.csv

ICSE-NIER’18, May 27-June 3 2018, Gothenburg, Sweden

Nghi et al.

Table 3: Accuracy of 1-1 Mapping when compares with StaMiner and MAM

Package

java.io
java.lang
java.math
java.net
java.sql
java.util
All

Sta
70.0%
82.5%
50.0%
100.0%
100.0%
64.7%
77.9%

Precision
DeepA
80.0%
80.0%
66.7%
100.0%
100.0%
69.6%
82.7%

SAR
80.0%
85.0%
66.7%
89.0%
100.0%
83.6%
84.0%

Class Mapping
Recall
DeepA
75.0%
81.3%
66.7%
100.0%
100.0%
72.7%
82.6%

Sta
63.6%
76.7%
50.0%
50.0%
50.0%
71.0%
60.2%

SAR
75.0%
80.2%
66.7%
100.0%
90.0%
75.7%
81.3%

Sta
66.6%
79.5%
50.0%
66.7%
66.7%
67.7%
66.2%

F-Score
DeepA
72.7%
80.7%
66.7%
100.0%
100.0%
71.1%
81.9%

SAR
77.5%
82.6%
66.7%
94.5%
95.0%
79.7%
82.7%

Sta
70.0%
86.7%
66.7%
100.0%
100.0%
63.0%
81.1%

Precision
DeepA
66.7%
83.3%
66.7%
100.0%
50.0%
64.3%
71.9%

SAR
75.0%
81.5%
66.7%
100%
75.0%
64.8%
76.1%

Method Mapping
Recall
DeepA
87.5%
87.2%
66.7%
100.0%
66.7%
85.7%
82.3%

SAR
82.9%
78.4%
66.7%
83.3%
70.0%
89.0%
78.38%

Sta
64.0%
76.5%
66.7%
33.3%
50.0%
54.8%
57.6%

Sta
66.9%
81.3%
66.7%
50.0%
66.7%
58.6%
65.0%

F-score
DeepA
75.2%
85.4%
66.7%
100.0%
57.2%
73.5%
76.3%

SAR
78.7%
79.9%
66.7%
81.7%
72.4%
76.9%
77.2%

Table 4: Examples of newly found APIs in Java and C#

Table 6: Different ways to combine refinement heuristics

Java

C#

Refine Method

Top-1

Top-5

Top-10

java.io.DataInputStream.readInt
java.awt.Graphics2d.fillRect
javax.swing.Text.JtextComponent.setCaretPosition
java.lang.Byte.parseByte
java.lang.Double.longBitsToDouble
java.net.Datagramsocket.isConnected
java.awt.geom.AffineTransform.inverseTransform
java.io.DataInputStream.readDouble
java.net.Serversocket.accept

System.Io.BinaryReader.ReadUInt16
System.Drawing.Graphics.FillRectangle
System.Windows.Controls.RichTextbox.CaretPosition
System.sbyte.Parse
System.BitConverter.Int64BitsToDouble
System.Net.Sockets.Socket.Connect
System.Drawing.Drawing2d.Graphicspath.Transform
System.Io.BinaryReader.ReadDouble
System.Net.Sockets.Socket.AcceptAsync

Table 5: Accuracy using various similarity thresholds

Threshold

Coverage

Accuracy

Top-1

Top-5

Top-1

Top-5

0.6
0.7
0.8
0.9

0.76
0.34
0.10
0.04

0.94
0.56
0.19
0.09

0.42
0.51
0.65
0.73

0.59
0.63
0.80
0.89

5.3.2 RQ2. Effect of Different Refinement Approaches.

Effects of Cosine Similarity Threshold. In this section, we measure
the effect of different ways to combine the seeds for the refinement
step. We want to measure the effects of cosine similarity thresh-
old in order to choose a good one for the second heuristic in the
refinement step. Since threshold is a part of the refinement, the
domain adaptation step only comprises of two steps: Seeding and
Adversarial Learning. Once the threshold is found, we use it for the
Refinement in the other experiments.

Then we produce the mapping for each source query in the 860
ground truth mappings. For each mapping produce, we obtain the
cosine similarity between the query and the result mapping. We
choose a threshold to filter out the mapping that has the cosine
similarity lower than the threshold, then we measure the accuracy
of the left mappings.

In Table 5, the column "Coverage" means the percentage of
ground truth APIs that have mappings in the candidate selection
results when choosing a specific cosine similarity threshold. The
column “Accuracy“ means the top-k accuracy in identifying the
mapping given a cosine similarity threshold as a condition to iden-
tify. The results show that our approach in these experiments has
higher mapping accuracy, but lower coverage with respect to the
ground truth set when the similarity threshold increases. It is, there-
fore, a trade-off to have higher accuracy in the expense of coverage.
For the other experiments that involve the cosine similarity thresh-
old in the refinement, we choose 0.7 as the threshold as this number
is balanced between the coverage and the accuracy.

Effects of Different Combinations of Refinement Heuristics. Ob-
tained 0.7 as a good threshold to identify correct mappings, we
use this number for the "Cosine Similarity Threshold " heuristic

Top-K
Cosine
Union Top-K + Cosine
Intersection Top-K + Cosine

0.53
0.24
0.36
0.54

0.70
0.29
0.42
0.75

0.78
0.36
0.50
0.82

Table 7: Effect of overlapping seeds

Baselines

Seeds

Top-1

Top-5

Top-10

Ours: Removed overlapping seeds
Ours: All seeds

174
257

0.51
0.54

0.69
0.75

0.76
0.82

in the Refinement step. What we measure is the impact of the two
refinement heuristics on the performance, either using only one of
them or combine them together. The domain adaptation also com-
prises of only Seeding and Adversarial Learning. After Adversarial
Learning, we use different combinations of refinement heuristics to
measure the effect of each heuristic. We use the 860 ground truth
mappings from Java2CSsharp as the test set.

The results in Table 6 show that taking the Intersection between
the Top-K Frequency and the Cosine Threshold heuristic results in
the best performance. This implies that the Cosine Threshold has
an effect to filter out poor Top-K Frequency synthetic seeds, thus
making the refinement better in overall.

5.3.3 RQ3: Effect of Overlapping Seeds. As mentioned in Sec-
tion 5.2, we found 257 seeds from the signature-based matching
heuristic as the training data; however, 83 of them overlap with
the ground truth set. These 83 overlapping seeds could affect the
final performance even though these 257 seeds are part of our end-
to-end approach. To analyze the effect of these overlapping seeds,
we also remove them from the training data, using the remaining
174 seeds to evaluate. Comparing the results to those using all 257
seeds as the training data, Table 7 shows that accuracy suffers a
few percents, but the overall score is still fairly good.

5.3.4 RQ4: Effect of Each Component. We performed an abla-
tion study of domain adaptation to measure the performance of
individual components as well as their combinations (Table 8). Note
that for the Refinement component, since Section 5.3.2 shows that
using the intersection of Top-K and cosine threshold leads to better
results than union, we refer Refinement to those of “Intersection of
Top-K and Cosine" performance.

Here are some observations from the results:

• Seeding is the most important step for the domain adaptation to
works well, e.g even with a small set of seeds (25), which is a very
small knowledge, it sets up a basis for the adversarial learning to
improve the performance significantly.

SAR: Learning Cross-Language API Mappings with Little Knowledge

ICSE-NIER’18, May 27-June 3 2018, Gothenburg, Sweden

Table 8: Ablation Study – effects of each component

Table 9: Effect of Refinement on Frequent vs. Rare Tokens

Baselines

Seeds

Top-1

Top-5

Top-10

Seeding+Adv

Seeding+Refine

Seeding

Refine
Adv+Refine
Adv

25
50
100
257
25
50
100
257
25
50
100
257
-
-
-

0.30
0.32
0.40
0.51
0.13
0.20
0.25
0.33
0.12
0.20
0.23
0.32
0.01
0.29
0.25

0.39
0.40
0.53
0.73
0.15
0.23
0.29
0.40
0.15
0.19
0.27
0.39
0.01
0.34
0.30

0.45
0.54
0.71
0.82
0.20
0.29
0.43
0.53
0.18
0.28
0.36
0.42
0.01
0.40
0.35

• Adversarial Learning is essential in improving the performance,
e.g comparing Seeding with Seeding-Adv, the top-1 accuracy is
improved by 19% on average.

• Without the Adversarial Learning, either the Seeding or the Re-
finement step alone, or combine these two together does not
achieve good performance.

• Refinement alone does not achieve any good result because the
initial input matrix was completely random that cannot be refined
to anything better;

• Using the Adversarial Learning alone achieves some reasonable
results, e.g top-1 = 24%, top-10 = 35%. Further with the Refinement
step, top-1 improves to 29%, top-10 becomes 40%. These can be
seen as the results of unsupervised domain adaptation without
any initial seeds.

5.4 Explainability Analysis of the Results
We performed various explainability analyses of our model in vary-
ing configurations to obtain some insights about our method. From
the results, we show that our approach performs significantly better
than Api2Api in every perspective. An interesting question one
may ask is "why does this approach perform better than Api2Api?".
Although theoretically, Adversarial Learning maximizes the sim-
ilarity between two distributions, it is still useful to explain this
phenomenon using analysis of the results.

5.4.1 Effect of Refinement on Frequent vs Rare tokens. We note
that the frequency of an API token could affect the quality of the
mapping result, i.e more frequent tokens could affect performance
more than the less frequent ones. With this assumption, the Re-
finement of the mapping matrix tries to improve the mapping by
using frequent tokens as the anchor. To measure the effect of the
refinement on the frequent tokens and rare tokens, we ranked the
860 ground truth mappings in Java2CSharp by the frequency of
the source APIs, i.e. the Java JDK APIs. Then we use our model to
produce the mapping results against the top 10%, which is a subset
of frequent tokens; and bottom 10%, which is a subset of rare tokens.
To ensure a fair comparison, we use the 174 non-overlapping seeds
in Section 5.3.3 to train the domain adaptation procedure.
The results in Table 9 show the following observations:

• Mapping accuracy decreases while increasing top-k frequent
tokens in the evaluation set, in either setting. This implies that
token frequency does affect on the mapping result;

Baselines

% Ground truth

Eval size

With Refine

Without Refine

Top 10%
Bottom 10%
Top 10%
Bottom 10%

86
86
86
86

Accuracy
Top-5

Top-10

Top-1

0.65
0.32
0.54
0.30

0.78
0.35
0.65
0.34

0.85
0.47
0.72
0.45

• The refinement step can improve the result of both the frequent
tokens and rare tokens, although the impact is bigger on fre-
quent tokens, e.g., improved by 10% for top-10% , and only 2%
for bottom-10%.

5.4.2 Retrieved Results Comparison. To evaluate our ap-
proach qualitatively, we retrieved C# API methods from sample
queries in Java SDK. Table 10 shows the resulting top-5 C# APIs
java.io.File.exists
java.util .Collection.add,
for four queries:
javax .swinд.T ext .JT extComponent .setCaretPosition,
and
java.util .concurrent .atomic.AtomicInteдer .дetAndDecrement.
They are ordered by increasing difficulty in finding a mapping.

For the first query, we can see that both Api2Api and our ap-
proach can successfully select the correct top-1 mapping, the other
results are also related. This case can be considered as easy for both
approaches to performing well.

For the second query, both approaches can achieve a good exact
mapping, but for the other results, our approach can generalize
all of the results under the ‘System.IO.File’ class, while there are
some less related results in the top-5 produced by Api2Api, e.g
‘System.W eb.Error Formatter .ResolveHttpFileN ame’.

The third query token ranks the 11,204th in the embedding
table3. As discussed earlier, embedding quality of rare tokens is
not as good as those of frequent tokens. Therefore, it is more
difficult to find an exact mapping for such a query. Even so,
our approach can still rank a correct mapping at the third place
(‘System.W indows.Controls.RichT extBox .CaretPosition’), while
Api2Api produce totally unrelated results.

For the last query, even though there has no mapping in C# by
the ground truth, the retrieved results are still reasonably close.
The query, in this case, is an API for an atomic operation, which is
related to thread handling. Our approach can generalize the result
mappings to the ‘System.Threadinд’ APIs in C#, while the results
from Api2Api are totally unrelated.

This experiment shows that Adversarial Learning can maximize
the similarity between the two distributions so that similar APIs
are clustered together.

5.4.3 API Clustering Ability. We perform an additional analysis
at the package level to show the ability of Adversarial Learning to
cluster similar APIs under the same package, e.g., ‘java.io’ APIs
in Java should be close to ‘System.IO’ APIs in C#. To define the
ground truth of the aligned packages, we refer to the 860 ground
truth mappings from Java2CSharp datasets: when more than 50% of
APIs in a package in one language have the corresponding of APIs
in another language, we say that these two packages are aligned.
For example, we say that the package ‘java.io’ and ‘System.IO’ are
aligned because 83% of ‘java.io’ APIs in Java is aligned with some
‘System.IO’ APIs in C#. In total, we can derive 5 pairs of aligned

3The order of the token embedding provided by word2vec is proportional to the
frequency of the token [16]

ICSE-NIER’18, May 27-June 3 2018, Gothenburg, Sweden

Nghi et al.

Table 10: Retrieved API mapping results from sample queries produced by SAR and Api2Api.

SAR

Api2Api

(1) java.util.Collection.add

System.Collections.Objectmodel.Collection.Add
System.Collections.Generic.List.Add
System.Collections.ObjectModel.Collection.Clear
System.Collections.Generic.List.Contains
System.Collections.Generic.Dictionary.Add

System.Collections.Generic.List.Add
System.Collections.Generic.List.Get
System.Collections.Generic.List.Remove
System.Collections.Objectmodel.Collection.Add
System.Collections.IDictionary.GetEnumerator

(2) javax.swing.Text.JtextComponent.setCaretPosition

System.Windows.Controls.RichTextBox.Clip
System.Web.Ui.Webcontrols.DataGrid.PageSize
System.Windows.Controls.RichTextBox.CaretPosition
System.Windows.Forms.ContextMenuStrip.SuspendLayout
System.Windows.Controls.RichTextBox.CaretBrush

System.Drawing.Image.GetframeCount
System.Media.SoundPlayer.PlaySync
System.Web.Ui.Webcontrols.Calendar.WeekendDayStyle
System.Configuration.Xmlutil.StrictSkipToNextElement
System.Media.SoundPlayer.PlayLooping

(3) java.io.File.exists

System.Io.File.Exists
System.Io.File.AppendText
System.Io.File.Delete
System.Io.Fileinfo.LastWriteTime
System.Io.File.GetAttributes

System.Io.File.Exists
System.Web.Errorformatter.ResolveHttpFileName
System.Io.File.OpenRead
System.Io.Compression.Zipfile.OpenRead
System.Io.Compression.ZipFile.ExtractToDirectory

(4) java.util.concurrent.atomic.AtomicInteger.getAndDecrement

System.Threading.Interlocked.Decrement
System.Threading.ReaderWriterLockSlim.EnterWriteLock
System.Threading.Interlocked.Increment
System.Threading.EventWaitHandle.OpenExisting

System.Directoryservices.SearchResultCollection.GetEnumerator
System.Directoryservices.SearchResultCollection.Dispose
System.Runtime.Serialization.ObjectIdGenerator.HasId
System.Collections.Generic.Queue.CopyTo

Table 11: Average Cosine Similarity Comparison

Baselines

Api2Api
SAR

java.io
0.23
0.39

Average Score Per Package
java.sql
java.net
0.31
0.27
0.48
0.58

java.math
0.66
0.73

java.util
0.17
0.41

packages: (1) java.io – System.IO, (2) java.math – System.Math,
(3) java.net – System.N et, (4) java.sql – System.Data.SqlClient, and
(5) java.util – System.Collections.Generic.

Using these data, we first compute the pairwise cosine similarity
scores of all pairs of APIs under each pair aligned packages, then
take the average of the scores. We do this for both Api2Api and
our approach. Table 11 shows that the average scores produced by
our approach are significantly better than those of Api2Api, which
implies that our approach has the ability to cluster the similar group
of APIs together.

6 THREATS TO VALIDITY AND LIMITATIONS
The goal of domain adaptation is to use as little knowledge as
possible for any pair of languages. However, we only perform the
experiments on Java and C# in this paper because it is not easy to
find a good and large enough evaluation dataset for other pairs of
languages. We leave this task in the future.

While unsupervised adversarial learning method does not re-
quire any seed as parallel data, there is a risk that the distributions of
vectors (embeddings) in the two spaces are not so similar. Through
our experiments, it is confirmed that the performance could be im-
proved further by initializing the unsupervised adversarial learning
method with a small set of seeds taken from the seed-based domain
adaptation, and by generating the rest of API mappings.

One limitation of our approach is that we can only generate
single API mapping instead of an API sequence mapping. Both
Api2Api and ours share such a limitation. In Api2Api, they use the
new mappings mined from the tool as the input for an external

machine translation tool, Phrasal [9], to generate the mapping for
API sequences. In the future, we can also feed the newly found
mapping APIs from our tool to Phrasal as inputs.

We mainly use a simplified top-k accuracy metric to measure our
performance against the Api2Api. In real-world use cases, other
information retrieval based metrics, such as MAP and MRR, may
have less bias in evaluating the list of API mappings. We leave this
for the future.

7 CONCLUSION & FUTURE WORK
We have proposed a domain adaptation approach, named SAR,
to automatically transform and align the vector spaces used to
represent two different languages and APIs used therein. We adapt
code embedding and adversarial learning techniques with a seeding
and refinement method to implement our approach. The approach
can identify API mappings across different programming languages.
Our evaluation shows that the mappings between Java and C#
APIs identified by our approach can be more accurate than other
approaches with just 257 mapping seeds that can be easily identified
by an automatic, simple signature-based heuristic, and it helps to
identify hundreds of more API mappings between Java and C#
SDKs.

Domain adaptation methods are useful for other software en-
gineering tasks that involve two different domains targeted by
transferred learning [17, 18, 33], such as cross-language program
classification, code summarization, cross-language/project bug pre-
diction. These tasks may benefit from the proposed approach when
little curated data is available. Other SE tasks that are challenging
due to lack of data, such as the out-of-vocabulary (OOV) prob-
lem [1, 6, 12] for learning and modeling fast-evolving software code,
may also benefit from our domain adaptation approach, because
the embeddings of OOV words may be approximated on-the-fly
by adapting the known embeddings of their contextual or similar
words in different languages. In the future, we will explore these

SAR: Learning Cross-Language API Mappings with Little Knowledge

ICSE-NIER’18, May 27-June 3 2018, Gothenburg, Sweden

variants of applications.

REFERENCES
[1] Miltiadis Allamanis, Earl T. Barr, Premkumar Devanbu, and Charles Sutton.
2018. A Survey of Machine Learning for Big Code and Naturalness. ACM
Computing Surveys (CSUR) 51, 4, Article 81 (July 2018), 37 pages. https://doi.
org/10.1145/3212695

[2] Nghi D. Q. Bui and Lingxiao Jiang. 2018. Hierarchical learning of cross-
language mappings through distributed vector representations for code. In
Proceedings of the 40th International Conference on Software Engineering: New
Ideas and Emerging Results, ICSE (NIER) 2018, Gothenburg, Sweden, May 27 -
June 03, 2018. 33–36. https://doi.org/10.1145/3183399.3183427

[3] codejuicer. 2017.

Java2CSharp: a maven plugin to convert java classes to
(2017). https://github.com/codejuicer/java2csharp Last commit in Sep

c#.
19, 2017.

[4] Michael L. Collard, Michael John Decker, and Jonathan I. Maletic. 2013. srcML:
An Infrastructure for the Exploration, Analysis, and Manipulation of Source
Code: A Tool Demonstration. In 2013 IEEE International Conference on Software
Maintenance (ICSM). 516–519. https://doi.org/10.1109/ICSM.2013.85

[5] Alexis Conneau, Guillaume Lample, Marc’Aurelio Ranzato, Ludovic Denoyer,
and Hervé Jégou. 2017. Word Translation Without Parallel Data. CoRR
abs/1710.04087 (2017). arXiv:1710.04087 http://arxiv.org/abs/1710.04087
[6] Milan Cvitkovic, Badal Singh, and Anima Anandkumar. 2018. Deep Learning
On Code with an Unbounded Vocabulary. In Machine Learning for Program-
ming (ML4P) Workshop at Federated Logic Conference (FLoC).

[7] Yaroslav Ganin and Victor S. Lempitsky. 2015. Unsupervised Domain Adapta-
tion by Backpropagation. In Proceedings of the 32nd International Conference
on Machine Learning (ICML). 1180–1189. http://jmlr.org/proceedings/papers/
v37/ganin15.html

[8] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-
Farley, Sherjil Ozair, Aaron C. Courville, and Yoshua Bengio. 2014. Generative
Adversarial Networks. CoRR abs/1406.2661 (2014). arXiv:1406.2661 http://
arxiv.org/abs/1406.2661

[9] Spence Green, Daniel M. Cer, and Christopher D. Manning. 2014. Phrasal: A
Toolkit for New Directions in Statistical Machine Translation. In Proceedings of
the Ninth Workshop on Statistical Machine Translation, WMT@ACL 2014, June
26-27, 2014, Baltimore, Maryland, USA. 114–121. http://aclweb.org/anthology/
W/W14/W14-3311.pdf

[10] Xiaodong Gu, Hongyu Zhang, Dongmei Zhang, and Sunghun Kim. 2016. Deep
API learning. In Proceedings of the 24th ACM SIGSOFT International Symposium
on Foundations of Software Engineering (FSE). 631–642.

[11] Xiaodong Gu, Hongyu Zhang, Dongmei Zhang, and Sunghun Kim. 2017.
DeepAM: Migrate APIs with Multi-modal Sequence to Sequence Learning. In
26th International Joint Conference on Artificial Intelligence (IJCAI). 3675–3681.
[12] Vincent J. Hellendoorn and Premkumar Devanbu. 2017. Are Deep Neural
Networks the Best Choice for Modeling Source Code?. In 11th Joint Meeting
on Foundations of Software Engineering (ESEC/FSE 2017). ACM, New York, NY,
USA, 763–773. https://doi.org/10.1145/3106237.3106290

[13] Svetoslav Karaivanov, Veselin Raychev, and Martin Vechev. 2014. Phrase-
Based Statistical Translation of Programming Languages. In Proceedings of the
2014 ACM International Symposium on New Ideas, New Paradigms, and Reflec-
tions on Programming & Software (Onward! 2014). ACM, New York, NY, USA,
173–184. https://doi.org/10.1145/2661136.2661148

[14] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient Esti-
mation of Word Representations in Vector Space. CoRR abs/1301.3781 (2013).
[15] Tomas Mikolov, Quoc V. Le, and Ilya Sutskever. 2013. Exploiting Similari-
ties among Languages for Machine Translation. CoRR abs/1309.4168 (2013).
arXiv:1309.4168 http://arxiv.org/abs/1309.4168

[16] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013.
Distributed representations of words and phrases and their compositionality.
In Advances in neural information processing systems (NIPS). 3111–3119.
[17] J. Nam, W. Fu, S. Kim, T. Menzies, and L. Tan. 2018. Heterogeneous Defect
Prediction. IEEE Transactions on Software Engineering 44, 9 (Sep. 2018), 874–
896. https://doi.org/10.1109/TSE.2017.2720603

[18] Jaechang Nam, Sinno Jialin Pan, and Sunghun Kim. 2013. Transfer Defect
Learning. In Proceedings of the 2013 International Conference on Software Engi-
neering. 382–391.

[19] Anh Tuan Nguyen, Hoan Anh Nguyen, Tung Thanh Nguyen, and Tien N.
Nguyen. 2014. Statistical learning approach for mining API usage mappings
for code migration. In ACM/IEEE International Conference on Automated Soft-

ware Engineering (ASE). 457–468.

[20] Anh Tuan Nguyen, Hoan Anh Nguyen, Tung Thanh Nguyen, and Tien N.
Nguyen. 2014. Statistical learning of API mappings for language migration.
In 36th International Conference on Software Engineering - Companion (ICSE).
618–619.

[21] Anh Tuan Nguyen, Tung Thanh Nguyen, and Tien N. Nguyen. 2013. Lexical
statistical machine translation for language migration. In Joint Meeting of the
European Software Engineering Conference and the ACM SIGSOFT Symposium
on the Foundations of Software Engineering (ESEC/FSE). 651–654.

[22] Anh Tuan Nguyen, Tung Thanh Nguyen, and Tien N. Nguyen. 2015. Divide-
and-Conquer Approach for Multi-phase Statistical Migration for Source Code
(T). In 30th IEEE/ACM International Conference on Automated Software Engi-
neering (ASE). 585–596.

[23] Anh Tuan Nguyen, Zhaopeng Tu, and Tien N. Nguyen. 2016. Do Contexts
Help in Phrase-Based, Statistical Source Code Migration?. In IEEE Interna-
tional Conference on Software Maintenance and Evolution (ICSME). 155–165.

[24] Trong Duc Nguyen, Anh Tuan Nguyen, Hung Dang Phan, and Tien N. Nguyen.
2017. Exploring API embedding for API usages and applications. In 39th Inter-
national Conference on Software Engineering (ICSE). 438–449. https://doi.org/
10.1109/ICSE.2017.47

[25] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang,
Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
2017. Automatic differentiation in PyTorch. In NIPS-W.

[26] Hung Dang Phan, Anh Tuan Nguyen, Trong Duc Nguyen, and Tien N. Nguyen.
2017. Statistical migration of API usages. In 39th International Conference on
Software Engineering - Companion Volume (ICSE). 47–50.

[27] Radim Řehůřek and Petr Sojka. 2010. Software Framework for Topic Mod-
elling with Large Corpora. In Proceedings of the LREC 2010 Workshop on
New Challenges for NLP Frameworks. ELRA, Valletta, Malta, 45–50.
http:
//is.muni.cz/publication/884893/en.

[28] Peter H. Schönemann. 1966. A generalized solution of the orthogonal pro-
crustes problem. Psychometrika 31, 1 (01 Mar 1966), 1–10. https://doi.org/10.
1007/BF02289451

[29] Ilya Sutskever, James Martens, George E. Dahl, and Geoffrey E. Hinton. 2013.
On the importance of initialization and momentum in deep learning. In Pro-
ceedings of the 30th International Conference on Machine Learning, ICML 2013,
Atlanta, GA, USA, 16-21 June 2013. 1139–1147. http://jmlr.org/proceedings/
papers/v28/sutskever13.html

[30] Yaxing Wang, Chenshen Wu, Luis Herranz, Joost van de Weijer, Abel
Gonzalez-Garcia, and Bogdan Raducanu. 2018. Transferring GANs: Gener-
ating Images from Limited Data. In Computer Vision - ECCV 2018 - 15th Eu-
ropean Conference, Munich, Germany, September 8-14, 2018, Proceedings, Part
VI (Lecture Notes in Computer Science), Vittorio Ferrari, Martial Hebert, Cris-
tian Sminchisescu, and Yair Weiss (Eds.), Vol. 11210. Springer, 220–236. https:
//doi.org/10.1007/978-3-030-01231-1_14

[31] Zhiguo Wang, Wael Hamza, and Radu Florian. 2017.

Bilateral Multi-
Perspective Matching for Natural Language Sentences. In 26th International
Joint Conference on Artificial Intelligence (IJCAI). 4144–4150.

[32] Chao Xing, Dong Wang, Chao Liu, and Yiye Lin. 2015. Normalized Word Em-
bedding and Orthogonal Transform for Bilingual Word Translation. In NAACL
HLT 2015, The 2015 Conference of the North American Chapter of the Associa-
tion for Computational Linguistics: Human Language Technologies, Denver, Col-
orado, USA, May 31 - June 5, 2015. 1006–1011. http://aclweb.org/anthology/N/
N15/N15-1104.pdf

[33] S. Yan, B. Shen, W. Mo, and N. Li. 2017. Transfer Learning for Cross-Platform
Software Crowdsourcing Recommendation. In 24th Asia-Pacific Software Engi-
neering Conference (APSEC). 269–278. https://doi.org/10.1109/APSEC.2017.33
[34] Hao Zhong, Suresh Thummalapenta, and Tao Xie. 2013. Exposing Behavioral
Differences in Cross-Language API Mapping Relations. In Proceedings of 16th
International Conference on Fundamental Approaches to Software Engineering
(FASE), Held as Part of the European Joint Conferences on Theory and Practice
of Software (ETAPS). 130–145.

[35] Hao Zhong, Suresh Thummalapenta, Tao Xie, Lu Zhang, and Qing Wang.
2010. Mining API mapping for language migration. In Proceedings of the 32nd
ACM/IEEE International Conference on Software Engineering - Volume 1 (ICSE).
195–204.

[36] Thomas Zimmermann, Massimiliano Di Penta, and Sunghun Kim (Eds.). 2013.
Proceedings of the 10th Working Conference on Mining Software Repositories,
MSR ’13, San Francisco, CA, USA, May 18-19, 2013. IEEE Computer Society. http:
//ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6597024

