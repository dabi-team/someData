IEEE TRANSACTIONS ON NUCLEAR SCIENCE, VOL. XX, NO. XX, XXXX 2020

1

Study of using machine learning for level 1 trigger
decision in JUNO experiment

Barbara Clerbaux1, Pierre-Alexandre Petitjean1, Yu Xu2,3, Yifan Yang1

0
2
0
2

v
o
N
7
1

]
t
e
d
-
s
n
i
.
s
c
i
s
y
h
p
[

1
v
7
4
8
8
0
.
1
1
0
2
:
v
i
X
r
a

Abstract—A study on the use of a machine learning algorithm
for the level 1 trigger decision in the JUNO experiment is
presented. JUNO is a medium baseline neutrino experiment
in construction in China, with the main goal of determining
the neutrino mass hierarchy. A large liquid scintillator (LS)
volume will detect the electron antineutrinos issued from nuclear
reactors. The LS detector is instrumented by around 20000 large
photomultiplier tubes. The hit information from each PMT will
be collected into a center trigger unit for the level 1 trigger
decision. The current trigger algorithm used to select a neutrino
signal event is based on a fast vertex reconstruction. We propose
to study an alternative level 1 (L1) trigger in order to achieve
a similar performance as the vertex ﬁtting trigger but with less
logic resources by using ﬁrmware implemented machine learning
model at the L1 trigger level. We treat the trigger decision as a
classiﬁcation problem and train a Multi-Layer Perceptron (MLP)
model to distinguish the signal events with an energy higher than
a certain threshold from noise events. We use JUNO software
to generate datasets which include 100K physics events with
noise and 100K pure noise events coming from PMT dark noise.
For events with energy higher than 100 keV, the L1 trigger
bosed on the converged MLP model can achieve an efﬁciency
higher than 99%. After the training performed on simulations,
we successfully implemented the trained model into a Kintex 7
FPGA. We present the technical details of the neural network
development and training, as well as its implementation in the
hardware with the FPGA programming. Finally the performance
of the L1 trigger MLP implementation is discussed.

Index Terms—JUNO, ML, Machine Learning, MLP, Multi-

Layer Perceptron, FPGA

I. THE JUNO EXPERIMENT

The Jiangmen Underground Neutrino observatory (JUNO)
experiment [1] uses a large liquid scintillator detector aiming at
measuring electron antineutrinos issued from nuclear reactors
at a distance of 53 km. The main goal to determine the neutrino
mass hierarchy, after 6 years of data taking [2]. The detector
will be located at 700 m underground and will consists of
20 ktons of liquid scintillator contained in a 35 m diameter
acrylic sphere, instrumented by 18000 20-inch photomultiplier
tubes (PMT) and 25600 3-inch PMTs. Two vetoes are foreseen
to reduce the different backgrounds. A 20 ktons ultrapure
water Cerenkov pool around the central detector instrumented
by 2000 20-inch PMTs will tag events coming from outside
the neutrino target. It will also act as a passive shielding for
neutrons and gammas. In addition, a muon tracker will be
installed on top of the detector (top muon veto) in order to

Submitted for review on October 31, 2020

1Inter-university Institute for High Energies, Universit´e libre de Bruxelles
(ULB)
2 Forschungszentrum J¨ulich IKP
3 III. Physikalisches Institut B, RWTH Aachen University

Fig. 1. The JUNO detector with the central acrylic sphere, the two veto
systems and the calibration part.

tag cosmic muons and validate the muon track reconstruction.
A schematic view of the detector is presented in ﬁgure 1.

II. ELECTRONICS READOUT SYSTEM

The JUNO electronics system will have to cope with
signals from 18000 large (20-inch) PMTs and 25600 small
(3-inch) PMTs of the central detector as well as 2000 PMTs
installed in the surrounding water pool. One of the innovative
aspects of JUNO is its electronics and readout concept [1].
With JUNO, a ﬂexible approach is chosen: every 3 PMTs will
have their own “intelligence” as self-monitoring (currents,
voltages,
temperatures) and it will have the possibility to
implement various data processing algorithms (for example,
trigger request generation and data compression). The JUNO
electronics system can be separated into mainly two parts:
(i) the front-end electronics system, performing the analog
signal processing (the underwater electronics) and after about
100 m cables, (ii) the back-end electronics system, sitting
outside water, consisting of the data acquisition (DAQ) and
the trigger. The main challenge of the whole electronics
system is the very strict criteria on reliability: a maximum
of 0.5% failure over 6 years for the PMT full readout chain,
as well as the large data transfer of 1.25 Gb/s that needs to
be delivered over 2 times 100 m Ethernet cables. A detailed
description of the full electronics chain of JUNO, from the
PMTs front-end to the trigger and DAQ is presented in [3].

 
 
 
 
 
 
IEEE TRANSACTIONS ON NUCLEAR SCIENCE, VOL. XX, NO. XX, XXXX 2020

2

Fig. 2. The electronics readout system of the JUNO experiment. The
underwater electronics (PMT, Global Control Unit ) is presented in the left
(green) box, and the dry electronics (Back-End Card , Reorganize & multiplex
Unit and the Central Trigger Unit ) in the right (blue) box.

For the front-end electronics, the global control unit (GCU)
[4] will digitize the incoming analog signals with custom
designed high speed ADU (analog to digital converter unit).
The GCU will store the signals in a large local memory under
the control of the FPGA (Field-Programmable Gate Array)
waiting for the trigger decision and sending out possible event
data as well as trigger requests to the outside-water system. A
back-end card will be used as a concentrator and each of the
incoming trigger request signals will pass through an equalizer
for compensating the attenuation due to the long cables [5].
An FPGA mezzanine card (called TTIM, for trigger timing
interface mezzanine) will collect all differential trigger request
signals, aligning them with certain trigger count. Then it will
make a sum, and send the result to the next stage (RMU,
for Reorganize & Multiplex Unit) and ﬁnally to the Center
Trigger Unit (CTU) over optical ﬁbers. A schematic view of
the electronics readout system is presented in ﬁgure 2.

III. TRIGGER ALGORITHMS

Two possible trigger algorithms have been discussed in
JUNO and are detailed in reference [6]. The ﬁrst and simpler
one, called the ”multiplicity trigger”, counts the number of
ﬁred PMTs in a 300 ns timing window. Figure 3 presents the
dark noise event rate as a function of the number of ﬁred
PMTs for two different dark noise frequencies (30 KHz and
50 kHz) and for 2 different time windows (80 ns and 300 ns).
It can be observed that a high trigger threshold on the number
of PMTs ﬁred has to be set in order to reject the coincidences
originated from the PMT dark noise, which will sacriﬁce the
recognition of low energy events.

In order to reduce the impact from the PMT dark noise, a
sophisticated trigger scheme called vertex ﬁtting is proposed
in references [6] and [7]. Unlike the ”multiplicity trigger”,
the vertex ﬁtting method tests the PMT information with
all possible positions and ﬁnds the most likely one among
them. In order to estimate the vertex position, it is needed
to extract the charge information form each hit. The whole
detector volume is divided into a certain number of blocks.

Fig. 3. Dark noise event rate as a function of the number of ﬁred PMTs.
The full (dotted) lines use a time window of 80 ns (300 ns). Two dark noise
frequencies (30 KHz and 50 KHz) are also considered [7].

Fig. 4. Vertex ﬁtting concept in JUNO. On the left side, an example of an
event happening in the upper part of the central detector, and ﬁring several
PMTs. On the right side, the schematic view of the vertex ﬁt logic, with a
correction of the various times of ﬂight for each PMT, before the sum is
performed and send to the trigger bloc.

By correcting the time of ﬂight for each PMT, it is possible to
decrease the timing window to 80 ns while reducing the effect
from the PMT dark noise even for 0.1 MeV physical events.
The schematic view of the vertex ﬁtting concept is shown in
ﬁgure 4. The candidate hardware for implementing the vertex
ﬁtting is a Virtex 7 FPGA.

The goal of the study presented in this article is to ﬁnd an
alternative way, using a machine learning model, to distinguish
between signal events at low energy (as low as 100 keV)
and background events from dark noise, while keeping the
algorithm lightweight enough to be implemented in a Kintex
7 FPGA.

We describe our study in the following 3 chapters. We start
with a description of the signal and noise event simulations,
followed by the MLP model training. Finally we present the
ﬁrmware implementation.

IV. SIMULATION OF SIGNAL AND NOISE EVENTS

In the JUNO experiment, when a signal event happens, the
kinetic energy of the ﬁnal state particles can be transferred to
photons that are detected by the PMTs. The initial information
of the events is thus the observed hits distributed in a time
window. In JUNO, the signal events include neutrino events,
radioactive decay events, and cosmic ray events, and the hits

IEEE TRANSACTIONS ON NUCLEAR SCIENCE, VOL. XX, NO. XX, XXXX 2020

3

are always distributed in the shape of events’ time proﬁle in
the LS as shown in ﬁgure 5.

Fig. 5. The time proﬁle of one signal event. Here we use alpha particles as
an example of signal event.

However, we cannot collect only the ”pure” number of hits
from signal events, since these hits are always contained in the
dark noise coming from the PMT electronics. Although the
dark noise hits are distributed uniformly in the time window,
the number of dark hits in one time window follows a Poisson
distribution, and we cannot know the accurate number of
dark hits in the time window. Therefore, when the number
of detected hits is close to the average level of dark noise, it
is hard to say whether the time window contains a real signal
event. This is specially the case for the low energy signal
events. In that case, it is a challenging topic to identify signal
event hits from pure dark noise hits.

In this study, we want to identify two kinds of data: the
pure dark noise events and the signal events with dark noise.
For the signal events, we prepared simulated samples using
the SNiPER (Software for Non-collider Physics ExpeRiments)
software [8]. SNiPER is a uniﬁed software platform based
on common requirements from both nuclear reactor neutrino
experiments and cosmic ray experiments. It is used by the
JUNO and LHAASO (Large High Altitude Air Shower Ob-
servatory) experiments [9]. The SNiPER framework consists
of physics generators, detector simulation and electronics
simulation modules. The JUNO detector simulation software is
based on Geant4, while the management of the geometry and
the user actions are simpliﬁed by introducing several interface
classes. The software has excellent efﬁciency and ﬂexibility
with an open structure. An overview of SNiPER structure in
3 layers is shown in ﬁgure 6.

In the present study, we generate electron events at ﬁxed
energy as the signal events. The electron energy chosen is 100
keV. We generate 100k signal events in total, with positions
uniformly distributed in the detector. Then, the dark noise is
added to the signal events. For the dark noise simulation,
we generate some hits uniformly distributed in the time
window. For the training, we use 100 keV electron events
with dark noise as signal events, and pure dark noise events

Fig. 6. An overview of SNiPER structure with three layers : the Python UI
layer, the core software layer and the user’s application layer [9].

as background events. In JUNO, the light yield is around
1200 p.e./MeV, so there will be in average 120 hits for 100
keV events. We set the number of hits for dark noise in
the range of 100 to 240. Figure 7 shows the distribution of
ﬁred PMT amount in one clock cycle for both background
events and signal events,it’s easy to tell from the plot that
two distributions are different while having partly overlap, it’s
difﬁcult to express the difference with an explicit function.

Fig. 7. Distribution of ﬁred PMT amount in 16ns for both background events
and signal events.

The data generated by the simulation contains two parts:
the label and the inputs for the CTU. The label tells if the
event is either a signal event or a dark noise event. The inputs
for CTU are the numbers of ﬁred PMTs in a continuously
20 clock cycles, therefore, they are 1×20 arrays, and each
element in the array describes the number of ﬁred PMTs in
the corresponding clock cycle. The time window is 320 ns for a
62.5 MHz clock, it is long enough to cover any event occurring
at any position of the JUNO detector. For the labels we assign
1 to signal events, and 0 to background events. Since a trigger
decision can be treated as a binary classiﬁcation problem, what
we hope is that the model can assign the correct label from the
different inputs given. The inputs are the information which
is received by the CTU, and the label is the trigger decision
result, either 1 (for a signal event) or 0 (for a dark noise event).
Training the machine learning model requires a big amount

IEEE TRANSACTIONS ON NUCLEAR SCIENCE, VOL. XX, NO. XX, XXXX 2020

4

Fig. 8. Neural network architecture with the input layer, a hidden layer and
the output layer.

Fig. 9. Representation of the two activation functions used in the study: the
Relu function (left plot) and the Sof tmax function (right plot).

of labeled data which we do not have. We thus use MC
simulations to simulate speciﬁc behaviors of the detector such
as the CTU inputs for different events, the combination of
events type. The labeled data are used to train the machine
learning model.

V. MULTILAYER PERCEPTRON NEURAL NETWORK (MLP)

The structure of the artiﬁcial neural network used in the
present study is shown in ﬁgure 8. Each disk represents a
neuron and the blue lines correspond to the forward link
between the neurons.

The forward link of a neuron is computed following this

formula [10]:

Yk = f

(cid:32) N
(cid:88)

i=0

(cid:33)

wi × Xi + b

where Yk is the value of a neuron number k in the layer number
j , we do the sum of the over all the neuron of the previous
layers (layer number j − 1) : N is the number of neurons
of previous layer, Xi is the value of the neuron number i of
previous layer, wi is the weight associated to the link between
Xi → Yk, b is the bias of the neuron k in the layer j and f
is the activation function applied on the sum. The activation
functions used in this paper are the two following one where
z is the argument of the function:

• Relu function : σ(z) = max(0, z)
eβzk
i eβzi

• Sof tmax function : σ(z) =

(cid:80)

Figure 9 shows shows these two functions changing with z.
In the present study, a 20×20×2 neural network architecture
is considered, as shown in ﬁgure 8. We have to ﬁnd 440
weights and 22 biases by training the model with the labeled
data set generated using MC simulation. A converged model
will be able to infer the correct label with real inputs, which
is to decide the type of event according to the hit information
for 20 clock cycles.

A. Building and training the neural network

To build this MLP model, we use the Python library called
Pytorch [11]. The activation function used for the hidden layer
is the Relu function and the one for the output layer is the
Sof tmax function. The speciﬁc back-propagation algorithm

used is a method based on the Adam algorithm [12]. Pytorch
gives already a function using this algorithm. The ﬁnal pa-
rameters are the learning rate = 0.0001, β = [0.9, 0.999],
(cid:15) = 1 × 10−8 , and the decay weight = 0.

Fig. 10. Prediction precision on the 20 000 events data set. After 100 epochs
the precision on the prediction is equal to 99%.

The loss function used here is the cross-entropy loss func-
tion [10]. We use 180k data for the training and 20k data
events for the testing sample. Figure 10 shows the result of the
test on a data sample of 20 000 events after each epoch. The

Fig. 11. ROC curves for the signal event class in blue and the background
event class in red. The left plot shows a global view of the ROC curve. It
means the classiﬁer have good performances. The right plot is a zoom of the
left plot. We have added the threshold of several point. From this, we can
conclude that a threshold of 0.5 is good enough for our case.

Receiver operating characteristic (ROC) is a effective method
to evaluate the performance of a classiﬁer [13]. In ROC curves,

IEEE TRANSACTIONS ON NUCLEAR SCIENCE, VOL. XX, NO. XX, XXXX 2020

5

the True positive rate (T P R) is considered as a function of
the False positive rate (F P R). The F P R is deﬁned as:

F P R =

F alse P ositive
F alse P ositive + T rue P ositive

The T P R rate is deﬁned as:

T P R =

T rue P ositive
F alse P ositive + T rue P ositive

(1)

(2)

Figure 11 shows the ROC curves for the signal event class (in
blue) and the background event class (in red). The left plot
shows a global view of the ROC curve. The right plot is a
zoom of the left plot. We have added the threshold of several
point. From this , we can conclude that a threshold of 0.5 is
good enough for our case.

B. Neural network architecture study

Three other neural network architectures have been studied
in addition to the 20×20×2 one : the 20×10×2, the 20×30×2
and the 20 × 20 × 20 × 2 structures. Their performances are
shown in ﬁgure 12. Each curve represents the learning process
of the neural network. All the 4 models are trained with the
same data set generated with MC simulations as described
in the previous chapter. The main difference between the four
different curves is coming from the learning speed. We see that
the more complex is the architecture of the neural network,
faster it learns. Note also that the 20 × 10 × 2 architecture
has a lower prediction precision after 50 epochs of 98% in
comparison to the 99% of the three other architectures. The
models 20 × 30 × 2 and 20 × 20 × 20 × 2 achieved a precision
of 99 % faster than the 20 × 20 × 2 model. We decided to
implement the 20 × 20 × 2 model because of its better ratio
cost in logic resources versus performance.

Fig. 12. Prediction precision on 20 000 events data set. The blue curve is for
the neural network 20 × 20 × 2, the orange curve is for the case 20 × 10 × 2,
the green curve for 20 × 10 × 2 and the red curve for 20 × 20 × 20 × 2.

C. Accuracy scan

In order to guide the ﬁrmware implementation, we need
to ﬁrst determine the data width, since Two’s complement is

used in FPGA as a method of signed number representation
[14]. We thus convert all the parameters into different bit
widths of the Two’s complement and verify their accuracy.
The results are shown in ﬁgure 13. The ﬁgure shows that with
6 bits, we have the same precision as the model using ﬂoats
as parameters.

Fig. 13. Comparison of the neural network output as a function of the number
of bits. The none value corresponds to unmodiﬁed model results. The results
shows that with a encoding of the parameters on 6 bits we achieve the same
precision as a neural network using parameter in double precision.

VI. FIRMWARE IMPLEMENTATION

A. Requirements

The basic and most important timing requirements for the
level 1 trigger decision of the JUNO experiment are listed as
below:

• Trigger decision latency less than 600 ns
• Trigger decision running synchronized with the system

clock

These requirements deﬁned the implementation target, which
is that the MLP should be able to give a trigger decision no
later than 600 ns after receiving the hit information, and it
should be able to give a decision every 16 ns if a 62.5 MHz
system clock is used.

There are mainly 3 important steps for implementing the
MLP model: the parameter and hit loading, the calculation
and the veriﬁcation. We use Verilog and vivado codes [15] to
implement the ﬁrmware in order to get full control at every
step.

B. Parameter and hit loading

As explained in the previous sections, the target MLP model
topology is 20 × 20 × 2, it has 22 neurons, each of which
contains 20 weights and 1 bias; in total it includes 440 weights
and 22 biases. According to MLP accuracy scan study, the use
of 6 bits is accurate enough to represent all the parameters.
We thus chose 12 bits Two’s complement as the method of
signed number representation to represent each parameter. It
not only guaranties the accuracy but also facilitates the future
calculation (as it will be explained in the calculation section).
A 5544 bits constant is used to keep all the parameters, the
ﬁrst 5040*(12*21*20) bits represent the 420 parameters for

IEEE TRANSACTIONS ON NUCLEAR SCIENCE, VOL. XX, NO. XX, XXXX 2020

6

the 20 neurons in the hidden layer and the last 504*(12*21*2)
bits represent the 42 parameters for the 2 neurons in the output
layer. Looking at the distribution of the hit information from
the simulated MC data, we can see that for pure dark noise
coincidences, the number of ﬁred PMTs in the 16 ns window
will never exceed 20, so 8 bits Two’s complement is more
than enough to represent the hit information for each system
clock cycle.

In principle, we need 20 clock cycles to collect the 20 inputs
for the MLP, since the latency only counts from the ending of
loading input until the appearing of the ﬁrst trigger decision.
We use a 160*500 bits BRAM to store 500 events. Each event
contains 20 8-bits-wide inputs as the hit information for 20
clock cycles.

C. Calculation

From the deﬁnition of the MLP, there are mainly 3 op-
erations that need to be implemented: multiply, accumulate,
and Relu. Each neuron contains 20 weights and 1 bias, which
correspond to 20 multiplies of of each hit and weight, and one
accumulation of 20 results and 1 bias. In order to get the best
performance, all the multipliers are implemented with DSP48
core inside Kintex 7 FPGA, with pipeline stages set to 3. The
multiplier can operate at a speed higher than 200 MHz [16],
with a ﬁxed latency of 3 clock cycles.

A two number adder is the basic function module for the
accumulation, 32 numbers are separated into 2 groups: 16
adders in ﬁrst level get 16 sums as the input to the 8 adders
in the second level, then 8 sums as the input to another 4
adders in the third level, until the ﬁfth level gets the ﬁnal
result. Each level operates synchronized to the system clock.
This implementation has the highest operation frequency while
keeping the latency ﬁxed to 5 clock cycles. The structure of
the accumulation is presented in ﬁgure 14.

Since all the data are signed numbers, Relu is very easy to
implement by checking the highest bit. If it’s 1, it means that
the value is negative and all outputs are 0. If it’s 0, the value

Fig. 14. Structure of the implementation of the accumulation operation for
32 numbers. They are ﬁrst separated into 2 groups, and the 16 adders in the
ﬁrst level get 16 sums as the input to the 8 adders in the second level. This
continues to operate until the ﬁfth level where we get the ﬁnal result.

will be transfered without any change. There is a Sof tmax
function for the output in the MLP model. Since it’s a binary
classiﬁcation, by setting a cut at 0.5, we can simply output the
level 1 trigger accept by checking the value of two neurons. If
the neuron which represents the signal event is larger than the
one which represents the dark noise event, the level 1 trigger
accept is one, which means it is a signal event. Otherwise it
is a dark noise event.

The overview of the top level and one of the neuron is

represented in ﬁgure 15.

Fig. 15. The left ﬁgure represents the top level structure of the ﬁrmware:
it includes two BRAM for parameters loading and 20 neurons in the hidden
layer as well as the two neurons in the output layer, it also shows the output
operation and the link to two SMA for hardware performance evaluation. The
right picture shows the detail structure of one neuron, it includes 20 multiplier
implemented by DSP48 IPcore, as well as the accumulator described in ﬁgure
12

D. Veriﬁcation

It is important to verify the correctness of MLP operation.
Two methods are used to verify the calculation procedure.
The ﬁrst one is performed using simulations, with both post-
implementation timing simulation and post-synthesis function
simulation. We can check all
the intermediate results by
comparing with the software results. The second method uses
chipscope [15], due to the limitation of logic resources, we are
able to check all the 22 neuron’s outputs with 22 ILA probes.
These methods allow us to check that the ﬁrmware calculation
is indeed correct.

E. Performance

Besides the correctness of the operation, the timing per-
formance is also critical. We use two spare IOs of the TTI:
one is used as the enable signal which enable the operation
periodically, the other one is used as the level 1 trigger accept
output. During each enable cycle, there are 500 trigger deci-
sions happening. The hardware setup is shown in ﬁgure 16. On
the right side we can see the BEC and the TTIM, powered with
redundancy power supply. Two SMA cables transfer the two
TTIM signals to a DPO7000 oscilloscope. On the left side. The
oscilloscope is triggered with enable signal and it is running at
inﬁnite persistence mode. A screenshot of the oscilloscope is
shown in ﬁgure 17. From the inﬁnite persistence mode picture,
the sharp edges show that the operations have few jitters.

IEEE TRANSACTIONS ON NUCLEAR SCIENCE, VOL. XX, NO. XX, XXXX 2020

7

TABLE I
COMPARISON BETWEEN THE RESULTS OBTAINED IN THE WORK OF
REFERENCE [17] (LEFT COLUMN) AND THE RESULTS OF THIS WORK
(RIGHT COLUMN).

MLP topology
FPGA model
Data width
Latency
Power consumption
BRAM
DSP
LUT

Reference [17]
7 × 6 × 5
Artix 7 35T
16
270 ns
241 mW
0
81
3466

This work
20 × 20 × 2
Kintex 7 325T
12
128 ns
350 mW
0
440
16563

data as a labeled dataset links machine learning with physics.
The implementation of the MLP model in FPGA makes the
trigger decision algorithm ﬂexible and easy to maintain: by
simply changing the parameter constants in the ﬁrmware it is
very easy and efﬁcient to upgrade the model for future needs.
The design takes full advantage of the parallelism of FPGA
and the high speed operation of the embedded DSP hardcore.
The model has been implemented in a Kintex 7 FPGA, with a
trigger latency of 128 ns at a clock frequency of 125 MHz. It
fulﬁls the timing requirements from the level 1 trigger decision
and indicates the feasibility of using MLP for level 1 trigger
decision in the JUNO experiment. It also gives the limitation
from the FPGA to the model, which is the amount of DSP48.
Once a model has been trained, it is easy to ﬁnd the most
suitable FPGA according to the number of layers and the
number of neurons in each layer.

In the future, we will make a more realistic signal simula-
tion. We will generate signal events in a spectrum of energy
range, and we will generate a bigger dataset to optimize the
MLP model. Following the development procedure presented
here, a better performance is foreseen. Since the current trigger
algorithm based on vertex ﬁtting does not require any use of
DSP48, it would be very interesting to put the MLP model
into the current CTU hardware, and to verify the efﬁciency of
the new proposed trigger during real data taking.

REFERENCES

[1] Zelimir Djurcic et al.
arXiv:1508.07166.

JUNO Conceptual Design Report.

2015.

[2] Fengpeng An et al. Neutrino physics with JUNO. Journal of Physics

G: Nuclear and Particle Physics, 43(3):030401, February 2016.

[3] M. Bellato et al. Embedded readout electronics R&D for the large
PMTs in the JUNO experiment. Nuclear Instruments and Methods in
Physics Research Section A: Accelerators, Spectrometers, Detectors and
Associated Equipment, 985:164600, January 2021.

[4] D. Pedretti et al. The global control unit for the JUNO front-end
electronics. Proceedings of International Conference on Technology and
Instrumentation in Particle Physics 2017:186–189, 2018.

[5] Yifan Yang and Barbara Clerbaux. Design of a common veriﬁcation
board for different back-end electronics options of the JUNO experi-
ment, 2018. arXiv:1806.09698.

[6] X. Fang, Y. Zhang, G.H. Gong, G.F. Cao, T. Lin, C.W. Yang, and W.D.
Li. Capability of detecting low energy events in juno central detector.
Journal of Instrumentation, 15(03):P03020–P03020, March 2020.
[7] Guanghua Gong, Hui Gong, Hongming Li, and Tao Xue. The global
trigger with online vertex ﬁtting for low energy neutrino research. Pro-
ceedings of the 15th Int. Conf. on Accelerator and Large Experimental
Physics Control Systems, ICALEPCS2015:Australia, 2015.

Fig. 16. This picture shows the hardware performance evaluation platform,
on the right is the BEC with TTIM powered by redundant power supply, on
the left side one can see the DPO7000 oscilloscope displaying the waveform
of the two signals transferred through two SMA cables to the TTIM.

Fig. 17. Waveform of two SMA from the FPGA. The blue waveform is an
enable signal to enable 500 inferences. The pink waveform is the results of
the inferences. The oscilloscope is running at inﬁnite persistence mode. The
sharp edge of the pink signal shows that the operations are always at ﬁxed
latency. The minimum width of the pink pulse of 8 ns shows that the hardware
is able to refresh the inference at a speed of 125 MHz. The 16 clock cycles
difference between the enable and the ﬁrst valid inference result shows that
the latency is 128 ns.

The minimum pulse width represents the current operation
frequency, which is 125 MHz. The 16 clock distance between
the beginning of enable signal and the ﬁrst result shows that
the processing latency is ﬁxed to 128 ns.

A comparison between the performance of our implemen-
tation and the results of reference [17] is presented in table
I. The work of reference [17] implements a 7 × 6 × 5 MLP
architecture in a Artix 7 35T FPGA, it uses less logic resource
mainly because the MLP model is smaller, and partly because
the model has been implemented by Xilinx system generator
design toolbox, not all the neurons are implemented by DSP48
hardcore. On the other hand, our implementation have shorter
latency which is critical for level 1 trigger decision.

VII. CONCLUSIONS

This study shows an efﬁcient cooperation between 3 differ-
ent specialized subjects, and deﬁnes a smooth working ﬂow.
Each stage is implementation oriented. The use of simulated

IEEE TRANSACTIONS ON NUCLEAR SCIENCE, VOL. XX, NO. XX, XXXX 2020

8

[8] Tao Lin, Jiaheng Zou, Weidong Li, Ziyan Deng, Xiao Fang, Guofu Cao,
Xingtao Huang, and Zhengyun You. The application of SNiPER to the
juno simulation. Journal of Physics: Conference Series, 898:042029,
oct 2017.

[9] J. H. Zou, X. T. Huang, W. D. Li, T. Lin, T. Li, K. Zhang, Z. Y.
Deng, and G. F. Cao. SNiPER: an ofﬂine software framework for non-
collider physics experiments. Journal of Physics: Conference Series,
664(7):072053, dec 2015.

[10] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning.

MIT Press, 2016. http://www.deeplearningbook.org.

[11] A. Paszke et al.

Pytorch: An imperative style, high-performance
deep learning library.
In H. Wallach, H. Larochelle, A. Beygelzimer,
F. d'Alch´e-Buc, E. Fox, and R. Garnett, editors, Advances in Neural In-
formation Processing Systems 32, pages 8024–8035. Curran Associates,
Inc., 2019. http://papers.neurips.cc/paper/9015-pytorch-an-imperative-
style-high-performance-deep-learning-library.pdf.

[12] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic

optimization. arXiv:1412.6980, 2016.

[13] Andrew P. Bradley. The use of the area under the ROC curve in
the evaluation of machine learning algorithms. Pattern Recognition,
30(7):1145–1159, July 1997.

[14] User guide Xilinx.

”7 series dsp48e1 slice”, March 2018.
http : //www.xilinx.com/support/documentation/user guides/
ug479 7Series DSP48E1.pdf.

user

guide

[15] Vivado
suite
2018.
tutorial:
https : //www.xilinx.com/support/documentation/sw manuals
xilinx2012 2/ug936-vivado-tutorial-programming-debugging.pdf.

Xilinx.
and

design
June

Programming

debugging”,

”vivado

Product
sheet:dc

Speciﬁcation Xilinx.

FPGA’s
[16] User
data
2018.
https : //www.xilinx.com/support/documentation/data sheets/
ds182 Kintex 7 DataSheet.pdf.

characteristics”,

switching

”kintex-7

June

and

ac

[17] Nikhil B. Gaikwad, Varun Tiwari, Avinash Keskar, and N. C. Shiv-
aprakash. Efﬁcient FPGA implementation of multilayer perceptron for
IEEE Access, 7:26696–26706,
real-time human activity classiﬁcation.
2019.

