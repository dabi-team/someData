1
2
0
2

p
e
S
8
2

]
E
M

.
t
a
t
s
[

1
v
1
7
4
3
1
.
9
0
1
2
:
v
i
X
r
a

An Automated Approach to
Causal Inference in Discrete Settings∗

Guilherme Duarte
gjduarte@upenn.edu

Noam Finkelstein
noam@jhu.edu

Dean Knox
dcknox@upenn.edu

Jonathan Mummolo
jmummolo@princeton.edu

Ilya Shpitser
ilyas@cs.jhu.edu

First draft: February 10, 2021
This draft: September 29, 2021

Abstract

When causal quantities cannot be point identiﬁed, researchers often pursue partial
identiﬁcation to quantify the range of possible values. However, the peculiarities of
applied research conditions can make this analytically intractable. We present a gen-
eral and automated approach to causal inference in discrete settings. We show causal
questions with discrete data reduce to polynomial programming problems, and we
present an algorithm to automatically bound causal eﬀects using eﬃcient dual relax-
ation and spatial branch-and-bound techniques. The user declares an estimand, states
assumptions, and provides data (however incomplete or mismeasured). The algorithm
then searches over admissible data-generating processes and outputs the most precise
possible range consistent with available information—i.e., sharp bounds—including
a point-identiﬁed solution if one exists. Because this search can be computationally
intensive, our procedure reports and continually reﬁnes non-sharp ranges that are
guaranteed to contain the truth at all times, even when the algorithm is not run to
completion. Moreover, it oﬀers an additional guarantee we refer to as ε-sharpness,
characterizing the worst-case looseness of the incomplete bounds. Analytically vali-
dated simulations show the algorithm accommodates classic obstacles, including con-
founding, selection, measurement error, noncompliance, and nonresponse.

Keywords: causal inference, partial identiﬁcation, constrained optimization, linear pro-
gramming, polynomial programming

∗

Guilherme Jardim Duarte is a Ph.D. student in the Operations, Information and Decisions Department, the Wharton
School of the University of Pennsylvania. Noam Finkelstein is a Ph.D. student in the Department of Computer Science, Johns
Hopkins University. Dean Knox is an Andrew Carnegie Fellow and an assistant professor in the Operations, Information and
Decisions Department, the Wharton School of the University of Pennsylvania. Jonathan Mummolo is an assistant professor of
Politics and Public Aﬀairs, Princeton University. Ilya Shpitser is the John C. Malone Assistant Professor in the Department
of Computer Science, Whiting School of Engineering at the Johns Hopkins University. Authors listed in alphabetical order.
For helpful feedback, we thank Peter Aronow, Justin Grimmer, Kosuke Imai, Luke Keele, Gary King, Christopher Lucas,
Fredrik S¨avje, Brandon Stewart, Eric Tchetgen Tchetgen, and participants in the Harvard Applied Statistics Workshop, the
New York University Data Science Seminar, University of Pennsylvania Causal Inference Seminar, PolMeth 2021, and the
Yale Quantitative Research Methods Workshop. We gratefully acknowledge ﬁnancial support from AI for Business and the
Analytics at Wharton Data Science and Business Analytics Fund. This research was made possible in part by a grant from
the Carnegie Corporation of New York. The statements made and views expressed are solely the responsibility of the authors.

 
 
 
 
 
 
Contents

1 Introduction

2 Related Literature

3 Preliminaries

3.1 Canonical DAGs
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Potential Outcomes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3 Principal Stratiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4 Formulating the Polynomial Program

5 Simplifying the Polynomial Program

5.1 Eliminating Blocked Disturbances . . . . . . . . . . . . . . . . . . . . . . .
5.2 Exploiting the Nested Markov Parameterization . . . . . . . . . . . . . . .
5.3 Eliminating Additional Constraints and Parameters . . . . . . . . . . . . .

6 Computing ε-sharp Bounds in Polynomial Programs

7 Statistical Inference

8 Simulated Examples

Instrumental Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8.1
8.2 Coverage of Conﬁdence Bounds . . . . . . . . . . . . . . . . . . . . . . . .
8.3 More Complex Bounding Problems . . . . . . . . . . . . . . . . . . . . . .

9 Potential Critiques of the Approach

10 Future Work with Automated Bounding

A Examples, Algorithms, and Detailed Discussion

A.1 Canonicalization of DAGs
. . . . . . . . . . . . . . . . . . . . . . . . . . .
A.2 Functional Models in the Context of Determinism . . . . . . . . . . . . . .
A.3 DAG Parameterization for Non-geared Graphs . . . . . . . . . . . . . . . .
A.4 Example of Program Simpliﬁcation . . . . . . . . . . . . . . . . . . . . . .
A.5 Constructing the Polynomial Program . . . . . . . . . . . . . . . . . . . .
A.6 Optimizing the Polynomial Program . . . . . . . . . . . . . . . . . . . . .

B Proofs

C Uncertainty

D Details of Simulated Models

D.1 Noncompliance Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . .
D.2 Outcome-Based Selection Simulation . . . . . . . . . . . . . . . . . . . . .
D.3 Measurement Error Simulation . . . . . . . . . . . . . . . . . . . . . . . .
D.4 Outcome Missingness Simulation . . . . . . . . . . . . . . . . . . . . . . .
D.5 Joint Missingness Simulation . . . . . . . . . . . . . . . . . . . . . . . . . .

1

3

4
5
6
6

9

12
12
12
14

15

16

18
18
20
21

24

25

30
30
30
31
32
35
36

39

41

44
47
47
48
49
50

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.

Tukey (1986, pp. 74–75)

1

Introduction

When causal quantities cannot be point identiﬁed, researchers often pursue partial identi-
ﬁcation to quantify the range of possible answers. These solutions are tailored to speciﬁc
scenarios (e.g. Lee, 2009; Gabriel et al., 2020; Kennedy et al., 2019; Knox et al., 2020; Li and
Pearl, 2021; Sj¨olander et al., 2014), but the idiosyncrasies of applied research can render
prior results unusable if identifying assumptions fail or slightly diﬀering causal structures
are encountered. This case-by-case approach to deriving causal bounds presents a major
obstacle to scientiﬁc progress. To increase the pace of discovery, researchers need a general
approach that is robust to context-speciﬁc peculiarities.

In this paper, we present an automated approach to causal inference in discrete set-
tings which can be applied to all graphical causal models, as well as all observed quantities
and domain assumptions in standard use. With our algorithm, users declare an estimand,
state assumptions, and provide available data—however incomplete or mismeasured. The
algorithm then outputs sharp bounds, the most precise possible answer to the causal query
given these inputs, including a point estimate if the solution is identiﬁed. This approach
can accommodate scenarios involving any classic threat to inference, including but not lim-
ited to missing data, selection, measurement error, and noncompliance. Our algorithm also
has the desirable property of alerting users when assumptions conﬂict with observed data,
indicating a faulty causal theory. Finally, we develop techniques for drawing statistical in-
ferences about estimated bounds. We demonstrate our method using a host of simulations,
validating results wherever existing analytic solutions are available.

Our work advances a rich literature on partial identiﬁcation in causal inference (Robins,
1989; Manski, 1990; Heckman and Vytlacil, 2001; Zhang and Rubin, 2003; Cai et al., 2008;
Swanson et al., 2018; Gabriel et al., 2020; Molinari, 2020), outlined in Section 2, which
has sometimes cast the task as a constrained optimization problem that can be solved
computationally.
In pioneering work, Balke and Pearl (1994, 1997) provided a method
for calculating sharp bounds when causal queries can be expressed as linear programming
problems. However, a wide range of estimands and empirical obstacles result in causal
queries that are not reducible to linear programs, and a complete computational solution
has remained elusive.

When feasible, sharp-bounding approaches oﬀer a principled and transparent approach
to causal inference that makes maximum use of available information while acknowledg-
ing its limitations. Claims outside the bounds can be immediately rejected, and claims
inside the bounds must be explicitly justiﬁed by additional assumptions or data that en-
able tightening. But several obstacles still preclude widespread use of these techniques.

1

For one, analytic derivation remains intractable for many problems. Within the subclass
of linear problems, Balke and Pearl’s (1994) simplex method oﬀers a highly eﬃcient an-
alytic solution, but one that fails to generalize to the many partially observed settings
where nonlinearity arises. Analytic nonlinear solutions remain limited to speciﬁc results,
painstakingly derived case by case (e.g. Knox et al., 2020; Gabriel et al., 2020; Li and
Pearl, 2021). Though general sharp bounds can in theory be obtained by various nonlin-
ear optimization techniques (Geiger and Meek, 1999; Zhang and Bareinboim, 2021), such
approaches are often computationally infeasible. This is because without exhaustively ex-
ploring a vast model space, analysts can obtain local optima that correspond to potentially
invalid bounds—i.e., ranges that may fail to contain the truth.

To address these limitations, we ﬁrst show in Sections 3 and 4 that essentially all com-
mon causal queries involving discrete variables can be reduced to polynomial programs—a
well-studied class of optimization tasks that nest linear programming as a special case—
building on prior results from Geiger and Meek (1999) and Wolfe et al. (2019).1 While
mature techniques have been developed for such tasks (Belotti et al., 2009; Vigerske and
Gleixner, 2018; Gamrath et al., 2020), it is well known that solving polynomial programs
to global optimality is in general NP-hard. The diﬃculty of the problem thus highlights
the need for eﬃcient algorithms and bounding techniques that remain valid even when
analysts are faced with time constraints. In Sections 5–6, we develop a procedure, based
on dual relaxation and spatial branch-and-bound relaxation techniques, that provides valid
bounds of arbitrary sharpness, for all causal structures, under virtually any information
environments and domain assumptions. We show this procedure is guaranteed to achieve
complete sharpness with suﬃcient computation time; in smaller problems, this can oc-
cur in a matter of seconds. However, in cases where the time needed to discover sharp
bounds is prohibitive—which can occur even in moderately sized problems with severe
information fragmentation—our algorithm is anytime (Dean and Boddy, 1988), meaning
it can be interrupted to obtain non-sharp bounds that are nonetheless guaranteed to be
valid. Our technique also oﬀers an additional guarantee we term “ε-sharpness,” indicating
the worst-case looseness factor of the relaxed bounds relative to the unknown, completely
sharp bounds. In Section 7, we provide two approaches for characterizing uncertainty in the
estimated bounds, and we demonstrate our technique in a series of simulations in Section 8.
Our simulations, validated against previously derived analytically results where possible,
show the ﬂexibility of our approach and the ease with which assumptions can be modularly
imposed or relaxed. Moreover, we demonstrate how the algorithm can uncover counterin-
tuitive results: in one case, we show a scenario that appears to be partially identiﬁed is in
fact point identiﬁed, improving over widely used bounds (Manski, 1990) and recovering a
recent advance in the literature on nonrandom missingness (Miao et al., 2015).

1Speciﬁcally, our results apply to elementary arithmetic functionals or monotonic transformations
thereof—a broad set that essentially includes all causal assumptions, observed quantities, and estimands
in standard use. For example, the average treatment eﬀect and the log odds ratio can be sharply bounded
with our approach, but non-analytic functionals (which are rarely if ever encountered) cannot. Functionals
that do not meet these conditions can be approximated to arbitrary precision, if they have convergent
power series.

2

Our approach oﬀers a complete and computationally feasible approach to causal infer-
ence in discrete settings. Given a well-deﬁned causal query, valid assumptions, and data,
researchers now have a general and automated process to draw causal inferences that are
guaranteed to be valid and, with suﬃcient computation time, provably optimal. As we
discuss in Sections 9–10, our approach’s modular nature also allows analysts to conduct
principled robustness tests and sensitivity analyses that can identify the most promising
avenues for future research, promote research transparency, and accelerate scientiﬁc dis-
covery.

2 Related Literature

Researchers have long sought to automate causal identiﬁcation by recasting causal queries
as constrained optimization problems that can be solved computationally. Our work is most
closely related to Balke and Pearl (1994, 1997), which showed that certain bounding prob-
lems in discrete settings—generally corresponding to causal systems in which outcomes
and manipulated variables are fully observed—could be formulated as the minimization
and maximization of a linear objective function subject to linear equality and inequality
constraints. In these cases, causal bounding problems can be reformulated as linear pro-
gramming problems, which admit both symbolic solutions and highly eﬃcient numerical
solutions. Subsequent studies have proven that in particular settings, the bounds pro-
duced by this technique are sharp (Ramsahai, 2012; Bonet, 2001; Heckman and Vytlacil,
2001), and Sachs et al. (2020) shows this approach produces sharp bounds for any such
linear problem. These results were extended by Geiger and Meek (1999), which showed
that a much broader class of discrete problems can be formulated in terms of polynomial
relations—at least, when analysts have precise information about the kinds of disturbances
or confounders that may exist, expressed in terms of latent variable cardinalities. These dis-
crete problems include not only the bounds studied in this paper, but the related problem of
determining what constraints on the main variables are implied by a causal graph. In addi-
tion to the well-known conditional independence constraints implied by d-separation, these
can include generalized equality constraints (or Verma constraints; Verma and Pearl, 1990;
Tian and Pearl, 2002). Beyond these equalities, the main variables are also constrained by
generalizations of the instrumental inequalities (Pearl, 1995; Bonet, 2001).

Geiger and Meek (1999) note that in theory, algorithms for quantiﬁer elimination can
provide symbolic solutions for these questions. However, the time complexity of quantiﬁer
elimination is doubly exponential, rendering it infeasible for all but the simplest cases. At
the core of this issue is that symbolic methods provide a general solution, meaning that
they must explore the space of all possible inputs. In contrast, numerical methods such
as our approach can often eliminate portions of the space that are irrelevant, accelerating
computation.

Even so, computation can be time-consuming; polynomial programming is in general
NP-hard.
In practice, many optimizers are able to rapidly ﬁnd reasonably good values
but cannot guarantee optimality without exhaustively searching the space of candidates.

3

This approach poses a challenge for obtaining causal bounds, which represent minimal and
maximal values of the estimand under all models that are admissible, or consistent with
observed data and modeling assumptions.
If a local optimizer operates on the original
problem (the primal ), proceeding from the interior and widening bounds as more extreme
models are discovered, then failing to reach global optimality will result in invalid bounds—
ranges narrower than the optimal sharp bounds which do not contain all possible solutions.
In this paper, we detail an approach that resolves this obstacle by allowing analysts to
obtain valid bounds in limited time. At a high level, our approach is to reexpress causal
inference problems in terms of principal strata (Frangakis and Rubin, 2002). To do so, we
ﬁrst present new results on lossless reductions for latent variables of unknown cardinality.
We then show that causal estimands, modeling assumptions, and observed information
can all be expressed in terms of polynomial expressions, equalities, and inequalities with
no loss of information. We show how these systems can be simpliﬁed for computational
eﬃciency, then develop an iterative primal-dual algorithm that searches for admissible
models from the interior of the bounds (the primal problem) while simultaneously reﬁning
a guaranteed-valid outer envelope for the sharp bounds (the dual problem). Even when
exhaustive search is computationally infeasible, suboptimal primal and dual values can still
be found and improved over time. We show suboptimal dual points allow analysts to report
valid loose bounds—those that are wider than the unknown sharp bounds. Our method also
utilizes the suboptimal primal points, allowing analysts to assess the worst-case looseness
factor of the reported valid bounds, relative to the unknown sharp bounds.

3 Preliminaries

In this section, we deﬁne notation and discuss concepts necessary to derive our key results.
We ﬁrst review how arbitrary directed acyclic graphs (DAGs) can be “canonicalized” with-
out loss of information, resulting in an equivalent form with properties amenable to analysis
(Evans, 2018). We then describe how graphs in this form give rise to potential outcomes
and principal strata (Frangakis and Rubin, 2002), two key building blocks in our analytic
strategy.

Suppose that for each i.i.d. unit i ∈ {1, . . . , N }, the main variables of interest are
contained in Vi = {Vi,1, . . . , Vi,J }, indexed by j. We will suppose that the sample space of
each main variable, S(Vi,j), has ﬁnite cardinality. These variables may be either observed or
unobserved—as we will show, it is often useful to reason about unobserved elements of Vi in
the context of missing data and measurement error. We will also consider unobserved causal
ancestors of Vi, collectively denoted Ui = {Ui,1, . . . , Ui,K} and indexed by k, that represent
random disturbances or confounders. Without loss of generality, these disturbances—
which have unknown, possibly inﬁnite cardinality—are assumed to subsume all phenomena
that are causally relevant to Vi.2 As we show in Section 3.3, this assumption is without

2We note that traditionally, variables in Vi are permitted to be aﬀected by exogenous causal noise not
represented in the graph. By incorporating all causally relevant factors into Ui, we take each variable in
Vi to be a deterministic function of its parents in the graph, discussed in more detail below.

4

consequence, because even a continuous and inﬁnite dimensional Ui must still map down
to the same ﬁnite canonical partitions that we describe there. In addition, we will make
use of counterfactual random variables, which represent hypothetical versions of random
variables in Vi that would have occurred had, contrary to fact, treatment variables been
exogenously set to a speciﬁed value. (A more rigorous deﬁnition is given in Section 3.2.)
By convention, bold letters denote collections of variables; uppercase and lowercase letters
respectively denote random variables and their realizations. We will consider population
distributions until discussing inference in Section 7.

3.1 Canonical DAGs

We now discuss how DAGs can be canonicalized, or distilled to minimal form, to clarify
which aspects of the structural model can be ignored, greatly simplifying the bounding task.
Suppose that causal relationships between all variables in Vi and Ui are represented by a
directed acyclic graph (DAG) G. The nonparametric structural equations model (NPSEM)
of a DAG states that each main variable Vi,j ∈ Vi is a deterministic function of its parents
in the graph G, denoted pa(Vi,j). That is, all factors determining Vi,j are contained in
pa(Vi,j), a subset of Ui and Vi. We denote the function mapping from pa(Vi,j) to Vi,j as
(cid:0)pa(Vi,j)(cid:1); we use F = {f1, . . . , fJ } to denote the collection of these structural
Vi,j = fj
equations, or the structural causal model model of V (Pearl, 2009; Richardson and Robins,
2013). Note that each main variable may be inﬂuenced by multiple disturbances, and a
single disturbance may inﬂuence multiple main variables.

i, such that Ui inﬂuences a subset of the variables inﬂuenced by U (cid:48)

A DAG is said to be in canonical form if (i) all disturbances are exogeneous, i.e. no
variable in Ui has any parents in G; and (ii) there exists no pair of disturbances, Ui and
U (cid:48)
i. Evans (2018) showed
that for any DAG G(cid:48) not in canonical form; there exists a canonical form DAG G with
an identical distribution over all factual and counterfactual versions of all variables in Vi.
We can therefore without loss of generality limit our consideration to DAGs in canonical
form. An example of a DAG not in canonical form is given in panel Figure 1(a). Panel
Figure 1(b) illustrates the canonicalized version of this graph. For convenience, we will
refer to the joint distribution over all factual and counterfactual versions of Vi as the full
data law. Moreover, any DAG over Ui, Vi, and unobserved ancillary variables Wi with
unknown cardinality (e.g., confounders or mediators not of direct interest) also has an
equivalent canonical DAG with respect to this full data law. A guide for canonicalizing
arbitrary DAGs is given in Appendix A.1.

In short, representing the causal graph in canonical form distills the data-generating pro-
cess (DGP) to its simplest form, eliminating potentially complex networks of disturbances.
Removing variables that are irrelevant to the causal goal further simpliﬁes the structure.
Without these simpliﬁcations, it would be exceedingly diﬃcult, if not intractable, to con-
vert causal problems into polynomial programs that can be readily optimized—the essence
of the approach we develop below.

5

Figure 1: Canonicalization of a mediation model. Mediation DAG in non-canonical
form (panel a) and canonical form (panel b) that are fully equivalent with respect to
their full data law. Unit indices, i, are suppressed. Canonicalization proceeds as follows:
(i) the dependent disturbance U3 is absorbed into its parent U23; (ii) the superﬂuous U2
is eliminated as it inﬂuences a subset of U23’s children; and (iii) the irrelevant W13 is
absorbed into the V1 → V3 path as it is neither observed nor of interest. A complete guide
to canonicalization is given in Appendix A.1.

U1

V1

(a)

U2

U23

U3

V2

W13

V3

U1

V1

(b)

U23

V2

V3

3.2 Potential Outcomes

The notation of potential outcome functions allows us to compactly express the eﬀects of
manipulating a variable’s parents or other ancestors. Let A ⊂ V be a subset of variables
that will be intervened upon, ﬁxing them to A = a. When A = ∅, so that no intervention
occurs, then deﬁne Vi,j(a) = Vi,j, the natural value. When A ⊆ pa(Vi,j), so that only
immediate parents are manipulated, then unit i’s potential outcome function is given by
(cid:0)A = a, pa(Vi,j) \ A(cid:1). We will now deﬁne more gen-
its response function, Vi,j(a) = fj
eral potential outcome functions by recursive substitution (Richardson and Robins, 2013;
(cid:0){a(cid:96) : A(cid:96) ∈
Shpitser, 2018). For arbitrary interventions on A ⊂ V , let Vi,j(a) = Vi,j
pa(Vi,j)} ∪ {Vi,j(cid:48)(a) : Vi,j(cid:48) ∈ pa(Vi,j) \ A}(cid:1); here, (cid:96) is a generic index that sweeps over main
variables in the graph. This means that if a parent of Vi,j is directly manipulated, it is set
to the corresponding value in a. Otherwise, the parent takes on its potential value after
intervention on any causally prior variables, or its natural value otherwise. To obtain the
parent’s potential value, we follow the same deﬁnition recursively. When deﬁning potential
outcomes, intervention on Vi,j itself is ignored. To illustrate, consider the mediation graph
of Figure 1(b). Possible potential outcomes for Vi,3 are (i) Vi,3(∅) = Vi,3(Vi,1, Vi,2), the
observed distribution; (ii) Vi,3(vi,1) = Vi,3(vi,1, Vi,2(vi,1)), relating to total eﬀects; and (iii)
Vi,3(vi,1, vi,2), relating to controlled eﬀects.

3.3 Principal Stratiﬁcation

Analysts have little information about the disturbances Ui, which may take on an inﬁnite
number of values. This poses an analytic challenge, as it is diﬃcult to reason about inﬁnite
spaces. Here, we review a result that makes the general partial identiﬁcation problem
tractable despite this issue: broadly, when Vi are discrete, the model that a DAG encodes
can be represented by a ﬁnite number of parameters without loss of generality, as long as
the reduced space is suﬃciently large. We then introduce the functional parameterization
used for this task, discuss its relationship to principal strata, and review how any marginal

6

of the full data law can be represented in terms of these parameters.

Finkelstein et al. (2021) show that there are ﬁnite state spaces for Ui that do not restrict
the NPSEM of a DAG for Pr(Vi = v), i.e. the model over the factual main variables. In the
following proposition, we extend this result to show that there are ﬁnite state spaces for Ui
that do not restrict the NPSEM of a DAG for the full data law—i.e., the full distribution
over all factual and counterfactual versions of the main variables.

Proposition 1. Suppose G is a canonical DAG over discrete main variables Vi and dis-
turbances Ui with inﬁnite cardinality. Then the model over the full data law implied by
G is unchanged by assuming that the disturbances have ﬁnite cardinalities, provided those
cardinalities are suﬃciently large.

A proof can be found in Appendix B, along with details on how to obtain a lower bound
on non-restrictive cardinalities for the disturbances.

Further, Evans (2018) showed that for a large class of graphs called geared graphs, it is
possible to develop a functional model that does not alter the causal model of a DAG. In
the functional model of a graph, each main variable Vi is associated with a disturbance Ui
that fully determines how Vi responds to the values of its remaining parents.3

Proposition 1 enables us to develop functional models for graphs that are not geared
as well. Finkelstein et al. (2021) presents an algorithm for constructing a concise func-
tional model for non-geared graphs, taking as input a disturbance cardinality that is
non-restrictive of the model over factual random variables. By instead substituting the
Proposition 1 disturbance cardinality, which may be larger and restricts neither the fac-
tual nor the counterfactual random variables, we obtain a functional model that is likewise
Intuitively, functional models are closely related to
non-restrictive of the full data law.
principal stratiﬁcation (Greenland and Robins, 1986; Frangakis and Rubin, 2002). For
example, consider the simple DAG,

Ui,1 → Vi,1 → Vi,2 ← Ui,2

(1)

in which Vi,1 and Vi,2 are binary. This relationship is governed by the structural equations
Vi,1 = f1(Ui,1) and Vi,2 = f2(Vi,1, Ui,2), where the functions f1 : S(Ui,1) → S(Vi,1) and
f2 : S(Vi,1) × S(Ui,2) → S(Vi,2) are deterministic and shared across all units. Thus, the
only source of randomness is in the disturbances, Ui = {Ui,1, Ui,2}.

Analysts generally do not have direct information about these disturbances. For exam-
ple, Ui,1 could potentially take on any value in (−∞, ∞). However, Proposition 1 states
that this variation is irrelevant, because Vi,1 can only take on two possible values: 0 and 1.
The space of Ui,1 can therefore be divided into two canonical partitions (Balke and Pearl,
1997)—those that deterministically lead to Vi,1 = 0 and those that lead to Vi,1 = 1—and
thus there is no loss of generality in treating Ui,1 as if it were binary.4

3Note that if any main variable Vi has multiple parents in Ui, there may be multiple valid functional
parameterizations, depending on which disturbance is chosen to determine which main variable. If each
main variable has only a single parent in Ui, there is only a single functional parameterization.

4See Section 8.2 of Pearl (2009) for a related discussion.

7

2

2

The situation with Vi,2 is similar but more involved. After the random Ui,2 is realized,
it induces the partially applied response function Vi,2 = f2(Vi,1, Ui,2 = u2) = f (Ui,2=u2)
(Vi,1),
which deterministically governs how Vi,2 counterfactually responds to Vi,1. Regardless of
how many values the disturbance can take on, this response function must fall into one
of only four possible groups, or principal strata, each corresponding to a possible func-
tion of the form f (Ui,2=u2)
: S(Vi,1) → S(Vi,2) (Angrist et al., 1996). These groups are (i)
Vi,2 = 1 regardless of Vi,1, “always takers”; (ii) Vi,2 = 0 regardless of Vi,1, “never takers”;
(iii) Vi,2 = Vi,1, “compliers”; and (iv) Vi,2 = 1 − Vi,1, “deﬁers”. Thus, from the perspective
of Vi,2, any ﬁner-grained variation in S(Ui,2) beyond the canonical partitions is irrelevant.
These partitions of U are in one-to-one correspondence with principal strata, allowing
causal quantities to be expressed in simple algebraic expressions; e.g., the average treat-
ment eﬀect (ATE) in (1) is equal to the proportion of compliers minus the proportion of
deﬁers.5 By writing down all information in terms of (possibly unknown) strata sizes, we
can convert causal inference problems into tractable polynomial programming problems
over these variables.

The functional parameterization of this graph has four free parameters: one for the
binary Ui,1 (or its reduced representation) and three for the quaternary Ui,2.6 Because the
distributions of disturbances are independent in canonical DAGs by virtue of their exo-
geneity, only their marginal distributions need be parameterized. Each of Ui,1 and Ui,2
encode full information about how Vi,1 and Vi,2 respectively respond to their remaining
parents. In other words, each setting of Ui provides full information not only about each
variable Vi, but also about each of its potential outcomes. This means that we can rep-
resent “cross-world” distributions such as Pr (cid:0)Vi,2(Vi,1 = 0) = 0, Vi,2(Vi,1 = 1) = 1(cid:1)—the
“complier” proportion—in terms of parameters of the marginal distributions of Ui,2 alone.
As we will see below, this fact will be useful in encoding cross-world type assumptions like
monotonicity, as well as for bounding cross-world targets like the natural direct eﬀect or
the probability of causation. More generally, any marginal of the full data law may be
expressed in terms of the functional parameters.

Finally, consider a more complex example, the mediation DAG of Figure 1(b). The
In contrast, Vi,3 is caused by
response functions for Vi,1 and Vi,2 remain unchanged.
pa(Vi,3) = {Vi,1, Vi,2} via the structural equation Vi,3 = f3(Vi,1, Vi,2, Ui,23). Substituting in
a realization of the disturbance, Ui,23 = ui,23, will produce one of sixteen response functions
of the form f (Ui,23=u23)
: S(Vi,1) × S(Vi,2) → S(Vi,3). More generally, the number of unique
response functions grows with (i) the cardinality of the variable, (ii) the number of causal
parents it has, and (iii) the parents’ cardinalities. Speciﬁcally, Vi,j has |S(Vi,j)||S(pa(Vi,j ))|
possible response functions: given a particular input from Vi,j’s parents, the number of
possible outputs for Vi,j is |S(Vi,j)|; the number of possible inputs from Vi,j’s parents is

3

5To see this, note that the ATE is given by E[Vi,2(Vi,1 = 1) − Vi,2(Vi,1 = 0)] = (cid:80)

E[Vi,2(Vi,1 = 1) −
Vi,2(Vi,1 = 0) | strata]·Pr(strata) = 0·Pr(always taker)+0·Pr(never taker)+1·Pr(complier)−1·Pr(deﬁer).
6These can be thought of as the probabilities of encountering a unit of the “control” type with Vi,1 = 0
(for Ui,1) and of encountering units of the “always-taker,” “never-taker,” and “complier” types (for Ui,2).
These parameters determine the probabilities of the remaining types (the “treatment” type for Ui,1 and
the “deﬁer” type for Ui,2), as principal strata probabilities must sum to unity.

strata

8

|S(pa(Vi,j))| = (cid:81)

Vi,j(cid:48) ∈pa(Vi,j ) |S(Vi,j(cid:48))|, the product of the parents’ cardinalities.

In turn, this determines the minimal cardinality of U in a reduced but non-restrictive
functional model—roughly speaking, the number of principal strata combinations that
exist, if we think of U as principal strata. Here, “non-restrictive” means that the simpliﬁed
model is fully expressive, or that it can represent any possible full data law. For example,
to capture the joint response patterns that a unit may have on Vi,2 and Vi,3, a reduced
version of Ui,23 will be capable of expressing any full data law if it has a cardinality of
|S(U23)| = 4 × 16, because Vi,2 has four possible response functions and Vi,3 has sixteen.

4 Formulating the Polynomial Program

We now turn to the central problem of this paper: sharply bounding causal quantities
with missing data. Our approach is to (i) rewrite the causal query into a polynomial
expression, (ii) rewrite modeling assumptions and empirical information into polynomial
constraints, and (iii) thereby transform the task into a constrained optimization problem
that can be solved computationally. Sharp bounds are the narrowest range that contain all
admissible values for a target quantity, i.e., all values that are consistent with information
available to the analyst: structural causal knowledge in the form of a canonical DAG, G;
as well as empirical evidence, E, and modeling assumptions, A, formalized below. We also
suppose that the main variables take on values in a known, discrete set, S = S(V ). In
this section, we will demonstrate (i) that {G, E, A, S} restricts the admissible values of
the target quantity, and (ii) this range of observationally indistinguishable values can be
recovered by polynomial programming.

The causal graph and sample space, G and S, together imply a set of possible functional
models, each fully characterizing the main variables. By Proposition 1, without loss of gen-
erality, we can consider a simple functional model in which (i) each counterfactual main
variable is a deterministic function of exogeneous, discrete disturbances; (ii) there are a
relatively small number of such disturbances; and (iii) disturbances take on a ﬁnite number
of possible values, corresponding to principal strata of the main variables. When repeat-
edly sampling units (along with each unit’s random disturbances, Ui), the k-th disturbance
thus follows the categorical distribution with parameters PUk = {Pr(Ui,k = ui,k) : ui,k}. By
the properties of canonical DAGs, these disturbances are independent. It follows that the
parameters PU of the joint disturbance distribution Pr(Ui = ui) = (cid:81)
k Pr(Ui,k = ui,k) not
only fully determine the distribution of each factual main variable—i.e. the potential out-
come under no intervention, Vi,j(∅)—they also determine the counterfactual distribution
of Vi,j(a) under any intervention a, and its joint distribution with other counterfactual
variables Vi,j(cid:48)(a(cid:48)) under possibly diﬀerent interventions a(cid:48). This leads to the following
proposition.

Proposition 2. Suppose G is a canonical DAG and C = {Vi,(cid:96)(a(cid:96)) = v(cid:96)} is a set of counter-
factual statements, indexed by (cid:96), that variable Vi,(cid:96) will take on value v(cid:96) under manipulation
a(cid:96). Let U ⊂ S(U ) indicate the subset of disturbance realizations that lead deterministically

9

to every statement in C being satisﬁed. Then under the structural equation model G,

(cid:32)

(cid:94)

(cid:33)

C(cid:96)

=

Pr

(cid:88)

(cid:89)

(cid:96)

u∈U

uk∈u

Pr(Ui,k = uk),

(2)

which is a polynomial equation in PUi, the parameters of Pr(U = u).

For example, in the mediation setting of Figure 1(b), Proposition 2 implies that the

joint distribution of the factual variables—Vi,1(∅), Vi,2(∅), and Vi,3(∅)—is given by

Pr (cid:0)Vi,1(∅) = v1, Vi,2(∅) = v2, Vi,3(∅) = v3

(cid:1) =

(cid:88)

Pr(U1 = u1) Pr(U23 = u23),

(3)

{u1,u23}∈U

(Vi,1 = 0, Vi,2 = 0) = 0

(cid:111)
.

(cid:111)

(cid:110)

2

1

{u1, u23} : f (U1=u1)

(∅) = v1, f (U23=u23)

(v1) = v2, f (U23=u23)

where U =
is the
set of all disturbances that are consistent with a particular Vi = {v1, v2, v3}. Alternatively,
analysts may be interested in the probability that a randomly drawn unit i has a positive
controlled direct eﬀect when ﬁxing the mediator to Vi,2 = 0. This is given by Pr (cid:0)Vi,3(Vi,1 =
0, Vi,2 = 0) = 0, Vi,3(Vi,1 = 1, Vi,2 = 0) = 1(cid:1) and is similarly expressed in terms of the distur-
bances as (cid:80)
{u1,u23}∈U (cid:48) Pr(Ui,1 = u1) Pr(Ui,23 = u23), summing over a diﬀerent subset of the
disturbance space, U (cid:48) =

(Vi,1 = 1, Vi,2 = 0) = 1, f (Ui,23=u23)

{u1, u23} : f (Ui,23=u23)

(v1, v2) = v3

(cid:110)

3

3

3

We now expand this result to include a large class of functionals of marginal probabilities

and logical statements about these functionals.

Corollary 1. Suppose G is a canonical DAG. Let PV denote the full data law and g(PV )
denote a functional of PV involving elementary arithmetic operations on constants and
marginal probabilities of PV . Then g(PV ) can be expressed as a polynomial fraction in
the parameters of PU , h(PU ), by replacing each marginal probability with its Proposition 2
polynomialization.

We say functionals of the full data law that fulﬁll these properties are polynomial-
fractionalizable, or simply polynomializable if the result contains no fractions. The corollary
has a number of implications, which we brieﬂy discuss here. First, it demonstrates that
a wide array of single-world and cross-world functionals can be expressed as polynomial
fractions. These include traditional targets such as the ATE, as well as more complex tar-
gets such as the pure direct eﬀect and the probability of causal suﬃciency. It also suggests
that any non-elementary functional of PV can be approximated to arbitrary precision by
a polynomial fraction, provided the functional has a convergent power series.7

Next, observe that when (i) g(PV ) is a polynomial-fractionalizable expression; (ii)
(cid:56) ∈ {<, ≤, =, >, ≥, (cid:54)=} is a binary comparison operator; and (iii) α is a constant, then

7We note that non-elementary functionals rarely arise in practice, with the exception of target quantities
on logarithmic or exponential scales. In such cases, bounds on monotonic transformations of polynomials
can be straightforwardly obtained by bounding the underlying polynomial, then applying the transforma-
tion. An example of a functional that our approach cannot handle is the non-analytic 1(ATE is rational).

10

statements of the form g(PV ) (cid:56) α can be equivalently expressed as non-fractional polyno-
mial relations h(PU ) (cid:56) 0. Finally, by the same token, any polynomial-fractional expression
h(PU ) in the parameters of PU can be reexpressed with (i) a non-fractional polynomial in
an expanded parameter space and (ii) a polynomial equation in the same expanded space.8
We will make extensive use of these properties to convert causal queries to polynomial
programs.

In Appendix A, Algorithm 1 provides a step-by-step procedure for obtaining sharp
bounds. We begin by transforming a factual or counterfactual target of inference T into
polynomial form, possibly with the use of additional auxiliary variables to eliminate frac-
tions. To accomplish this task, the procedure utilizes the possibly non-canonical DAG G
and the possible main-variable outcomes S(V ) to reexpress T in terms of functional param-
eters that correspond to principal strata proportions. The result is the objective function
of the polynomial program. The procedure then polynomializes the sets of constraints on
polynomializable functionals resulting from empirical evidence and by modeling assump-
tions, respectively E and A. For example, in the binary mediation setting of Figure 1, G
may be the graph depicted in either panel (a) or (b). If only observational data is available,
then E consists of eight pieces of evidence, each represented as a statement corresponding
to a cell of the factual distribution Pr (cid:0)Vi,1(∅) = v1, Vi,2(∅) = v2, Vi,3(∅) = v3
(cid:1) = Pr(Vi,1 =
v1, Vi,2 = v2, Vi,3 = v3) for observable values in {0, 1}3. Modeling assumptions include all
other information, such as monotonicity or dose-response assumptions; these can be ex-
pressed in terms of principal strata. For example, the assumed unit-level monotonicity of
the V1 → V2 relationship (e.g., the “no deﬁers” assumption of Angrist et al., 1996) can
be written as the statement that Pr (cid:0)Vi,2(Vi,1 = 0) = 1, Vi,2(Vi,1 = 1) = 0(cid:1) = 0. Assumed
population-level monotonicity is typically written E[Vi,2(Vi,1 = 1) − Vi,2(Vi,1 = 0)] ≥ 0,
but can equivalently be reformulated in terms of principal strata as Pr (cid:0)Vi,2(Vi,1 = 1) =
1, Vi,2(Vi,1 = 0) = 0(cid:1) − Pr (cid:0)Vi,2(Vi,1 = 0) = 1, Vi,2(Vi,1 = 1) = 0(cid:1) ≥ 0. Finally, the statement
that each disturbance k follows a categorical probability distribution is reexpressed as the
polynomial relations Pr(Uk = uk) ≥ 0 : uk and (cid:80)

Pr(Uk = uk) = 1.

uk

Algorithm 1 produces an optimization problem with a polynomial objective subject to
polynomial constraints. This polynomial programming problem is equivalent to the original
causal bounding problem. This leads directly to the following theorem.

Theorem 1. Minimization (maximization) of the polynomial program produced by Algo-
rithm 1 produces sharp lower (upper) bounds on T under the sample space S(V ), structural
equation model G, additional modeling assumptions A, and empirical evidence E.

Once the causal problem is expressed in polynomial form, a variety of computational
solvers can in principle be used to optimize (e.g. IPOPT; W¨achter and Biegler, 2006).
However, local solvers cannot guarantee valid bounds without exhaustively searching the

8To see this, let s be a scalar auxiliary variable and set h(PU ) = s, which can be manipulated to
obtain a non-fractional polynomial equation, per (ii). The original expression can now be rewritten simply
as s, which is a monomial and hence a polynomial, per (i). Thus, the original polynomial-fractional
expression has been reexpressed in terms of (i) a non-fractional polynomial expression and (ii) a non-
fractional polynomial equation.

11

space; when time is limited, these often fail to discover global extrema for the causal es-
timand, resulting in intervals that may fail to contain the quantity of interest. Moreover,
such approaches often become computationally intractable as causal problems grow com-
plex. In the next section, we show how the polynomial program can be simpliﬁed to speed
computation.

5 Simplifying the Polynomial Program

Because solving polynomial programs is in general NP-hard, eﬃcient computation requires
us to fully exploit our knowledge of the problem structure. This knowledge allows ana-
lysts to reduce the complexity of the program in ways that algebraic presolvers may not
necessarily detect. In this section, we discuss several ways to do this.

5.1 Eliminating Blocked Disturbances

We begin by using the following observation to limit the number of disturbance distribution
parameters involved in the target and constraints.

, where C =
Proposition 3. Consider the polynomialization of a probability Pr
{Vi,(cid:96)(a(cid:96)) = v(cid:96) : (cid:96)}. We say that for intervention a(cid:96), a disturbance Ui,k is blocked from
the corresponding counterfactual Vi,(cid:96) if there are no paths from Ui,k to Vi,(cid:96) that do not go
through the causally prior members of the intervention a(cid:96). When Ui,k is blocked from Vi,(cid:96)
for every (cid:96), the corresponding parameters PUk can be eliminated from the polynomialization.

(cid:96) C(cid:96)

(cid:16) (cid:86)

(cid:17)

In other words, Proposition 3 states that each main variable Vi,j is only a function of its
ancestors in U that aﬀect it through a variable not under intervention. For each marginal
probability of an event, the disturbances that do not aﬀect any variable in the event are
irrelevant. This allows us to amend the polynomialization of Proposition 2 so that the outer
sum ranges only over all possible settings of relevant disturbances, reducing the degree of
each term in the polynomial. For example, in the mediation graph of Figure 1(b), consider
the total eﬀect of the treatment Vi,1 on the outcome Vi,3. Here, all probabilities are of the
form Vi,3(vi,1 = a1) = v3.9 The disturbance Ui,1 is therefore blocked from the outcome Vi,3,
because the sole path from Ui,1 to Vi,3 goes through the intervention set Vi,1. This means
that whenever Pr(U1 = u1) appears in the polynomial, it does so in a way that ensures
(cid:80)

Pr(U1 = u1) = 1 can be factored out and eliminated.

u1

5.2 Exploiting the Nested Markov Parameterization

We now consider the common case when the empirical evidence E includes single-world
marginal distributions. This occurs when (i) a factual or counterfactual event (cid:86)
(cid:96){Vi,(cid:96)(a) =
v(cid:96)} involves the same intervention, a, for every variable of interest; and (ii) the probability
9The total eﬀect is given by Pr (cid:0)Vi,3(Vi,1 = 1) = 1(cid:1) − Pr (cid:0)Vi,3(Vi,1 = 0) = 1(cid:1), which can equivalently be

written Pr (cid:0)Vi,3(Vi,1 = 1, Vi,2 = Vi,2(Vi,1 = 1)) = 1(cid:1) − Pr (cid:0)Vi,3(Vi,1 = 0, Vi,2 = Vi,2(Vi,1 = 0)) = 1(cid:1).

12

(cid:16) (cid:86)

(cid:17)
(cid:96){Vi,(cid:96)(a) = v(cid:96)}

is observed for every event in that state space, {v(cid:96) : (cid:96)} ∈ (cid:81)

Pr
(cid:96) S(Vi,(cid:96)).
For example, in the binary mediation setting of Figure 1(b), an observational study might
obtain information about Pr (cid:0)Vi,1(∅) = v1, Vi,2(∅) = v2, Vi,3(∅) = v3
(cid:1) for every combi-
nation of v1, v2, and v3. Similarly, an experiment that randomly manipulated Vi,1 would
(cid:1)
obtain two such distributions: (i) by observing Pr (cid:0)Vi,2(Vi,1 = 0) = v2, Vi,3(Vi,1 = 0) = v3
for all v2 and v3; and similarly, (ii) by observing Pr (cid:0)Vi,2(Vi,1 = 1) = v2, Vi,3(Vi,1 = 1) = v3
(cid:1)
for all v2 and v3.

A na¨ıve parameterization might use one parameter for the probability of each principal
strata (e.g., four parameters for the proportion of “always takers,” “never takers,” “com-
pliers,” and “deﬁers”). It is immediately apparent that one na¨ıve parameter is redundant,
as its value is already implied by the fact that all distributions must marginalize to unity.
Hidden-variable DAG models imply additional equality constraints, each of which can like-
wise be used to reduce the number of parameters needed to describe the model, thereby
reducing the number of polynomial constraints in the program.

These additional equality constraints, which are implied by the structural equations
model of G, are well understood. In particular, G imposes certain conditional independence
and generalized equality constraints (or Verma constraints, Verma and Pearl, 1990; Tian and
Pearl, 2002) on these distributions. Each equality constraint can be used to eliminate one
parameter of the single-world distribution. The parameterization that takes full advantage
of these structural equality constraints to reduce the number of parameters is called the
nested Markov parameterization (Evans et al., 2019). This parameterization achieves the
minimal number of parameters, equal to the dimension of the model of G.

(cid:16) (cid:86)

of a single-world event, Pr

(cid:17)
(cid:96)(cid:48){Vi,(cid:96)(cid:48)(a(cid:48)) = v(cid:96)(cid:48)}

Each nested Markov parameter is exactly equal to an identiﬁed marginal probability
. Because each of the nested Markov
(cid:17)
(cid:16) (cid:86)
,
parameters is identiﬁed from the initial single-world distribution, Pr
whether indirectly or directly, it can be calculated directly from the empirical evidence E.
By Proposition 2, this probability remains polynomializable in the parameters PU . This
allows us to add one equality constraint to the program per nested Markov parameter,
based on its polynomialization, rather than one equality constraint per outcome in the state
space. For hidden variable DAGs that imply a large number of equality constraints, this
can substantially reduce the number of constraints. Evans et al. (2019) oﬀers a a complete
guide to obtaining nested Markov formulations of arbitrary single-world distributions.

(cid:96){Vi,(cid:96)(a) = v(cid:96)}

Each parameter in the nested Markov formulation is the probability of a single-world
event that involves fewer main variables and more interventions, compared to any event
used by the na¨ıve parameterization. As a result, the corresponding polynomialization will
have fewer terms, of lower degree, than the polynomialization of na¨ıve parameters. An
example is provided in Appendix A.4. Using this technique, we modify Algorithm 1 by
partitioning the empirical evidence into all single-world marginal distributions EM and
the remaining evidence ER. The constraints in EM can then be reduced into their nested
Markov form before polynomialization. Because the nested Markov parameterization allows
for fewer, simpler polynomial constraints in the program, it is important to use it whenever

13

the empirical evidence permits.

We note that when certain deterministic relationships exist between variables in Vi,
as in the missing-data setting of Figure 5(c–d),10 these relationships may imply equality
constraints not exploited by the nested Markov parameterization. In such cases, it may be
possible to further reduce the number of constraints; we do not explore that option here.

5.3 Eliminating Additional Constraints and Parameters

Finally, we describe when constraints and parameters can be safely eliminated from a
program. We say that parameters x and y co-occur in a polynomial system if they appear
in the same constraint; they interact if there exists a sequence of parameters from x to y
such that every adjacent pair co-occurs.11 If a constraint’s parameters do not interact with
the objective’s parameters, that constraint may be dropped. If a parameter exists only
in constraints that have been eliminated, then the parameter has also been eliminated,
simplifying the system.

This may be used in conjunction with the structure of G to help simplify the program,
because diﬀerent districts—components in G connected by bidirected arcs (Tian and Pearl,
2002; Richardson, 2003)—do typically do not interact. That is, likelihoods on marginal
distributions of G have a representation that is decomposable by districts. For example, in
Figure 1(b), Vi,1 lies in one district; in contrast, Vi,2 and Vi,3 lie in another district, because
they are connected by Ui,23. Because each nested Markov parameter is the probability of
a single-world event involving main variables within a single district, its polynomialization
will at most involve disturbance parameters in that district. This leads to the following
proposition.

Proposition 4. The degree of each polynomial in the nested Markov constraints is bounded
from above by the number of latent variables in the corresponding district. Moreover, if two
disturbances Ui,k and Ui,k(cid:48) appear in diﬀerent districts, their parameters PUk and PUk(cid:48) will
not interact in any nested Markov constraint.

To illustrate, consider the common scenario where an analyst observes the full joint
distribution over factual variables, Pr (cid:0)Vi,1(∅) = v1, . . . , Vi,J (∅) = vJ
(cid:1), and seeks to bound
a functional relating a treatment a to an outcome Vi,j(a) in the same district. As an
example, in Figure 1(b), the eﬀect of the mediator Vi,2 on the outcome Vi,3 is wholly
contained within a single district. We can therefore drop all constraints related to nested
Markov parameters involving other districts, and thus all disturbance parameters in other
districts.

10In this graph, a latent variable Y has an observed version Y ∗ that deterministically inherits Y ∗ = Y

when a reporting variable R = 1, but takes on the missing-value indicator Y ∗ = NA otherwise.

11For example, consider the constraints x + y = a, y + z = b. Here, x and y co-occur; x and z interact.

14

6 Computing ε-sharp Bounds in Polynomial Programs

We now turn to the practical optimization of the polynomial program deﬁned by Algo-
rithm 1. Theorem 1 states minimization and maximization of this original primal program
is equivalent to the initial bounding problem. However, obtaining globally optimal solu-
tions in polynomial programming can be computationally intensive. Worryingly, methods
that iteratively improve suboptimal values for the primal problem may fail to produce
valid bounds (i.e., bounds containing all possible values of the estimand, including global
extrema) without searching the full parameter space, P. To address this challenge, we
use dual methods that construct and iteratively reﬁne an outer envelope around the pri-
mal function (i.e. the objective function, or causal quantity of interest). Speciﬁcally, we
employ a variation of the spatial branch-and-bound method, combined with a piecewise lin-
ear envelope, implemented using a variety of optimization frameworks that include SCIP
and Couenne (Vigerske and Gleixner, 2018; Gamrath et al., 2020; Belotti et al., 2009).
Throughout the optimization process, current suboptimal values for dual minimization
and maximization problems are guaranteed to produce valid but loose outer bounds; cur-
rent suboptimal values for the primal problem produce possibly invalid inner bounds; and
the lower (upper) endpoint of the unknown sharp bounds is guaranteed to lie between
the current suboptimal primal and dual minimization (maximization) values. Through si-
multaneous primal-dual optimization, we use these suboptimal inner bounds to precisely
quantify worst-case looseness, ε, of the suboptimal but valid outer bounds. This allows
researchers to assess how more computation may lead to tightened conclusions.

A step-by-step description of our optimization procedure, which we term ε-sharp bound-
ing, is given in Algorithm 2 of Appendix A. At a high level, it proceeds as follows. Our
procedure takes as inputs the polynomialized objective function T (p) and constraint set
C(p), obtained from Algorithm 1. It then evaluates a range of models, or points p in the
model space P for which C(p) is satisﬁed. It seeks to identify extreme values of T (p) within
this subspace. It also accepts two parameters: (cid:15)thresh, a stopping threshold for the looseness
factor stopping, and θthresh, a stopping threshold for width of the bounds. The algorithm
returns two types of information: the bounds for the causal program, and the worst-case
looseness factor ε.

Primal bounds are denoted P and P , adopting the convention that underlines refer to
objects used for minimization and overlines for maximization. These indicate the extreme
values of the target estimand in any admissible model—that is, satisfying C(p)—that has
been located so far. These are initialized at +∞ and −∞, respectively, indicating that
no admissible models have been found yet. As optimization proceeds, the primal bounds
improve as new, more extreme admissible models are found. We refer to [P , P ] as the inner
bounds: the unknown sharp bounds must at least contain these points, which correspond
to models that are observationally indistinguishable from the true DGP.

Dual optimization begins by partitioning the parameter space into branches, proceeding
separately for the lower and upper bound and respectively producing partitions Bb and Bb.
At initialization, these consist of a single branch spanning the entire parameter space; each

15

branch is then recursively divided. The lower and upper parts of the dual envelope, or
outer envelope, are denoted D and D. These are piecewise linear functions, with pieces
corresponding to the branching partitions, that are relaxations of the true objective func-
tion, T (p), from below and above. These relaxations are made to ensure they will always
contain the entire objective function at all points in the parameter space. Within branch
b, the value min{Db(p) : p ∈ Bb} indicates the lowest value attained by the lower envelope;
(cid:8)min{Db(p) : p ∈ Bb}(cid:9) represents the lowest value attained by the lower
thus, T = minb
(cid:8)max{Db(p) : p ∈ Bb}(cid:9)
envelope anywhere in the parameter space. Conversely, T = maxb
represents the highest value of the upper envelope. These extreme points on the dual
envelope, [T , T ], deﬁne the dual (outer) bounds. These are the reported causal bounds;
whatever the true sharp bounds, they must lie inside the dual bounds, even if the algorithm
has not run to completion. We let θ equal the bound width, or the diﬀerence between the
upper and lower dual bounds, and we deﬁne the worst-case looseness factor ε as the slack
(the diﬀerence in dual and primal bound widths) divided by the primal bound width.

The algorithm heuristically selects branches in the model space that appear promising,
and reﬁnes primal and dual bounds in turn.
It ﬁrst searches within the branch for an
admissible model; if found, and if the associated causal estimand is more extreme than
those previously encountered, it is stored as a new primal bound. Whatever the true
nonparametric sharp bounds, they must lie outside the primal bounds because the true
bounds must contain the extreme models that deﬁne the primal bounds. Then, it divides
the branch into sub-branches and reﬁnes the dual envelope by tightening the piecewise
linear outer-approximation. The algorithm continuously prunes branches of Bb and Bb
that wholly violate constraints; it also continuously branches and reﬁnes the bounds while
θ and ε exceed speciﬁed thresholds.

7 Statistical Inference

We now turn to statistical inference for the bounds developed above. We say that the results
of Algorithm 2 when applied to E, the population empirical constraints—i.e., margins of the
full data law that are observed without sampling error—are population bounds. In practice,
the empirical quantities used in these constraints are estimated from ﬁnite samples. Our
goal in this section is to account for variation in ˆE, the estimated constraints, that arises
over repeated sampling. The results of Algorithm 2 when substituting ˆE for E are referred
to as the estimated bounds. In this section, we describe how to construct conﬁdence bounds
that (i) contain the estimated bounds and (ii) contain the population bounds at a rate of
at least the conﬁdence level α over repeated samples.

Recall that each element of empirical evidence E is a relation between (i) some popu-
lation quantity that is an observable functional of the main variables’ distribution, g(PV ),
reexpressed in terms of the disturbance distribution PU ; and (ii) the population value of
that observable quantity. In ˆE, we plug in for (ii) the estimated value of the quantity in
ﬁnite data. For example, in the mediation graph of Figure 1(b), an analyst with access to
a sample of observational data would have

16

(cid:26)

polynomialize

ˆE =

(cid:18) Pr (cid:0)Vi,1(∅) = v1, Vi,2(∅) = v2, Vi,3(∅) = v3

(cid:1)
1 {Vi,1 = v1, Vi,2 = v2, Vi,3 = v3}

(cid:80)N

= 1
N

i=1

(cid:19)

(cid:27)

: v1, v2, v3

(4)

i=1

(cid:80)N

We will refer to the vector of estimated quantities on the right-hand side of ˆE elements—in
1 (Vi,1 = v1, Vi,2 = v2, Vi,3 = v3)—as ˆE.
the above example, quantities of the form 1
N
We denote the corresponding population quantities as E, the right-hand side values in E.
To construct conﬁdence bounds we consider the sampling variability of these estimated
quantities. We construct regions, CRα( ˆE), containing ˆE and guaranteed to contain the
population quantities E with at least probability α over repeated samples. These regions
correspond to population distributions over observed parameters that cannot be rejected at
level α. In Algorithm 2, we then replace the ˆE constraints with a set of loosened conﬁdence
constraints CRα( ˆE). In other words, if the population bounds are obtained by optimizing
subject to a equality constraint {g(cid:96)(PV ) = E(cid:96)} ∈ E, and the estimated bounds are obtained
(cid:110)
g(cid:96)(PV ) = ˆE(cid:96)
∈ ˆE, then the conﬁdence bounds will incorporate
with the plug-in version
(cid:110)
g(cid:96)(PV ) ∈ CRα( ˆE(cid:96))

the interval constraint

∈ CRα( ˆE).

(cid:111)

(cid:111)

Because loosening ˆE to CRα( ˆE) can only decrease (increase) the minimum (maximum)
value obtained by the polynomial program, conﬁdence bounds always contain the estimated
bounds. Similarly, when the conﬁdence region for estimated quantities fully contains their
population analogues, then the conﬁdence constraint CRα( ˆE) is looser than the population
constraint E, and resulting conﬁdence bounds also contain the population bounds. However,
when the conﬁdence region does not fully contain population quantities due to sampling
error, conﬁdence bounds may still contain population bounds. This can occur if the non-
covered quantity corresponds to a constraint that is irrelevant to the bounds. Therefore,
if the conﬁdence region on the observed quantities has coverage of exactly α, conﬁdence
bounds will contain the population bounds in at least α of repeated samples.

(cid:16)

In discrete settings, the task of obtaining conﬁdence bounds thus reduces to the problem
(cid:17)
of constructing regions CRα( ˆE) for the multinomial proportion, such that Pr
E ∈ CRα( ˆE)
≥ α. We focus on two methods for doing so. Drawing on Malloy et al. (2020), we ﬁrst
consider a “Bernoulli-KL” approach that constructs separate conﬁdence regions for each
observable atomic event, Pr(Vi = v), treating it as a “success” in a Bernoulli distribution.
The approach rotates through all possible v and combines the event-speciﬁc regions using
a result on the Kullback-Leibler divergence of sampling distributions to the underlying
population distribution. The Bernoulli-KL method produces a conﬁdence region for single-
world distributions that is guaranteed to have conservative coverage for the multinomial
proportion in ﬁnite samples. The region can be represented as a system of linear inequality
constraints, then incorporated into the polynomial program. Our second approach uses
an asymptotically valid conﬁdence region based on the multivariate Gaussian limiting dis-
tribution of the Dirichlet (Bienaym´e, 1838), which can be represented as a single convex
quadratic inequality constraint. Figure 2 visualizes these regions for a simple two-node

17

(cid:80)N

Figure 2: Polynomial conﬁdence regions in a binary graph. Panel (a) presents a
causal graph in which binary X causes binary Y , but both are confounded by an unobserved
U . N = 1, 000 observations are drawn from this DGP, producing an empirical distribution
1(Xi = x, Yi = y). Panels (b–c) depict conﬁdence regions for
with proportions 1
N
Pr(Xi = 0, Yi = 0), Pr(Xi = 0, Yi = 1), and Pr(Xi = 1, Yi = 0); the ﬁnal category,
Pr(Xi = 1, Yi = 1) (not depicted), must sum to unity. Panel (b) shows the Bernoulli-
KL conﬁdence region, which is conservative in ﬁnite samples and can be polynomialized
as a set of linear inequalities. Panel (c) shows the Gaussian conﬁdence region, which is
asymptotically valid and can be polynomialized as a single convex quadratic inequality.

i=1

U

X

Y

(a)

(b)

(c)

graph. Simulations reported in Section 8.2 evaluate coverage of the methods for various
sample sizes. Appendix C provides details on the implementation of these methods. We
also provide a method for polynomializing arbitrary conﬁdence regions, allowing analysts
to exploit tighter ﬁnite-sample conﬁdence regions.

8 Simulated Examples

We now demonstrate our algorithm’s performance via simulations. Several examples corre-
spond to known analytic solutions, oﬀering further validation of our approach. Section 8.1
illustrates how Algorithms 1–2 allow analysts to iteratively state possible assumptions, test
their observable implications, and use them to narrow causal bounds under noncompliance.
Section 8.2 evaluates our proposals for statistical inference with estimated bounds. Sec-
tion 8.3 examines several challenges—selection, mismeasurement, and missingness—that
pose more complex threats to statistical inference. For clarity of exposition, all simulations
use binary variables; our method adapts automatically to categorical variables.

8.1 Instrumental Variables

Noncompliance, or deviation between assigned (Zi) and realized (Xi) treatment status, is a
common obstacle to causal inference in randomized trials. Balke and Pearl (1997) showed
that the task of bounding the ATE on an outcome Yi in the presence of noncompliance

18

can be formulated as a linear programming problem, admitting a computational solution
to partial identiﬁcation. However, this approach cannot be extended to bound the local
average treatment eﬀect (LATE) among “compliers” that accept the assigned treatment—a
principal eﬀect that has received considerable attention—because this estimand corresponds
to a nonlinear objective function. Angrist et al. (1996) shows the LATE can be point
identiﬁed, but only if a number of conditions hold. These conditions include (i) ignorability
of Zi; (ii) a non-null eﬀect of Zi on Xi; (iii) an exclusion restriction, or the absence of a
direct eﬀect of Zi on Yi; and (iv) monotonicity, or the absence of “deﬁers” that behave
inversely to instructions. In this section, we estimate both the ATE and LATE in settings
where assumptions i–ii are satisﬁed, then probe the implications of assumptions iii–iv. Our
results show that while extant methods oﬀer solutions for speciﬁc scenarios and estimands,
even minor deviations from ideal conditions can render them inapplicable or inaccurate.
Below, we show how our algorithm easily accommodates these variations and complications.

Figure 3: DGPs with noncompliance. The ﬁgure displays three possible causal models
corresponding to scenarios in which an encouragement Z causes treatment X. Panel (b)
corresponds to the true DAG in our simulated dataset, in which the monotonicity assump-
tion is violated (indicated here by the absence of a + symbol) but other key identifying
assumptions are satisﬁed. Panel (a) depicts a DAG assumed by an overcautious analyst
that allows for violations of the exclusion restriction. Panel (c) depicts a model assumed
by an overconﬁdent analyst in which monotonicity of Z → X is incorrectly invoked.

Omitted assumption
(overcautious)

Justiﬁed assumptions
(true DGP)

Erroneous assumption
(overconﬁdent)

U

U

U

Z

(a)

X

Y

Z

(b)

X

Y

Z

(c)

X

+

Y

Figure 3 displays three possible DGPs that analysts might assume in a scenario involving
noncompliance. We simulate data from the true DGP, shown in panel (b), in which all
assumptions in Angrist et al. (1996) are satisﬁed except monotonicity of Z → X. In this
simulation, the true values of the ATE and LATE are −0.25 and −0.36, respectively. In
practice, analysts may proceed with an abundance of caution and make the conservative
causal assumptions depicted in panel (a)—a challenging scenario in which a direct eﬀect
of the instrument on the outcome cannot be excluded and monotonicity is not assumed.
Assuming model (a) and applying our algorithm yields sharp bounds of [−0.63, 0.37] and
[−1, 1] for the ATE and LATE, respectively. While these bounds are relatively wide—the
ATE cannot be signed, and the bounds for LATE are entirely uninformative—the resulting
intervals do contain the true estimand values, and they represent the most precise statement
possible under assumptions the analyst is willing to defend.

If the analyst was willing to assume the exclusion restriction, per model (b)—perhaps
due to domain expertise or an experimental design that ruled out direct eﬀects—our al-

19

gorithm would bound the ATE at [−0.55, −0.15], revealing a negative eﬀect and correctly
containing the true value of −0.25. However, under these circumstances, the bounds on the
LATE remain entirely uninformative at [−1, 1]. This reﬂects the fact that without strong
assumptions, it is diﬃcult to learn about cross-world quantities such as principal eﬀects.

Finally, panel (c) shows a DGP imagined by an overconﬁdent analyst, in which all four
identifying assumptions in Angrist et al. (1996) are embraced. Unbeknownst to the analyst,
the monotonicity assumption is in fact violated. Helpfully, when asked to estimate bounds,
our Algorithm 2 reports that the causal query is infeasible. Recall that the true DGP
corresponds to model (b), in which deﬁers are present; because the algorithm fails to locate
any DGPs in which the observed information is consistent with the absence of deﬁers, it
provides a clear warning to users that the assumption cannot be defended. However, if
the analyst na¨ıvely applied the traditional instrumental variables two-stage least squares
estimator, they would not be alerted to this fact. Rather, they would obtain a point
estimate of −0.74, roughly twice the true LATE. Put diﬀerently, the standard IV approach
ignores observable implications of underlying assumptions. In contrast, our algorithm ﬂags
faulty theory by identifying infeasible scenarios, forestalling fruitless inquiry.

8.2 Coverage of Conﬁdence Bounds

In applied settings, the bounds estimated by our algorithm will be subject to sampling error.
We now evaluate the performance of conﬁdence bounds that characterize this uncertainty,
constructed according to Section 7, using the instrumental variable model of Figure 3(b).
Speciﬁcally, we draw samples of N = 1, 000, N = 10, 000, or N = 100, 000 observations from
this DGP. For each sample, we then compute estimates of eight quantities: Pr(Zi = z, Xi =
x, Yi = y) for all x, y, z ∈ {0, 1}. These quantities form the basis of estimated bounds, by
the plug-in principle. To quantify uncertainty, we compute 95% conﬁdence regions on
the same observed quantities, then convert them to polynomial constraints for inclusion
in Algorithm 2. Optimizing subject to these conﬁdence constraints produces conﬁdence
bounds, depicted in Figure 4. For each combination of sample size and uncertainty method,
we draw 1,000 simulated datasets and run Algorithm 2 once.

Table 1 reports average values of estimated lower (upper) conﬁdence bounds obtained
by Algorithm 2 over 1,000 simulated datasets, for varying N . At all sample sizes, estimated
bounds are centered on population bounds. Figure 2 shows conﬁdence bounds obtained
across methods and sample sizes. The Bernoulli-KL method produces wider conﬁdence
intervals at all N ; at N = 1, 000, it is generally unable to reject zero, whereas the asymptotic
method does so occasionally. Diﬀerences in interval width persist but shrink rapidly as
sample size grows and both methods collapse on population bounds. As discussed in
Section 7, we ﬁnd more conservative coverage for conﬁdence bounds on the ATE (100%
coverage of population bounds), compared to coverage of the underlying conﬁdence regions
on the observed quantities (95% joint coverage of observed population quantities for the
asymptotic method).

20

Table 1: Bias of estimated bounds. Average lower (upper) estimated bounds simu-
lated datasets of varying size. Average estimated bounds correspond closely to population
bounds.

Quantity
Lower bound
Upper bound

N = 1, 000 N = 10, 000 N = 100, 000 Population
−0.550
−0.146

−0.549
−0.144

−0.551
−0.146

−0.551
−0.146

Figure 4: Coverage of conﬁdence bounds. Each of 1,000 simulations is depicted with
a horizontal line. For each simulation, a horizontal error bar represents a 95% conﬁdence
bound obtained per Section 7. All conﬁdence bounds fully contain the population bounds,
indicating 100% coverage. The upper (lower) row of panels reﬂect conﬁdence bounds ob-
tained with the Bernoulli-KL (asymptotic) method. Columns of panels report conﬁdence
bounds obtained using samples of various sizes. Vertical dotted white lines show true pop-
ulation lower and upper bounds, which contain the true ATE of −0.25; vertical dashed
black lines indicate zero.

8.3 More Complex Bounding Problems

We now examine four hypothetical DGPs, shown in Figure 5, featuring various threats to
inference. Throughout, we target the ATE of X on Y . Panel (a) illustrates outcome-based
selection: we observe unit i only if Si = 1, where Si may be aﬀected by Yi. Selection
severity, Pr(Si = 0), is known, but no information about Pr(Xi = x, Yi = y|Si = 0) is
available. Xi and Yi are also confounded by unobserved Ui. Bounding in this setting is
a nonlinear program, with an analytic solution recently derived in Gabriel et al. (2020).
Panel (b) illustrates measurement error: an unobserved confounder Ui jointly causes Yi and
its proxy Y ∗
i , but only treatment and the proxy outcome are observed. Bounding in this
setting is a linear problem. A number of results for linear measurement error were recently
presented in Finkelstein et al. (2020); here, we examine the monotonic errors case, where
i (Yi = 1) ≥ Y ∗
Y ∗
i (Yi = 0). Panel (c) depicts missingness in outcomes, i.e. nonresponse

21

i = Yi, but if Ri = 0, then Y ∗
i

or attrition. Here, Xi aﬀects both the partially observed Yi and response indicator Ri;
if Ri = 1, then Y ∗
takes on the missing value indicator
NA. Nonresponse on Yi is diﬀerentially aﬀected by both Xi and the value of Yi itself (i.e.
“missingness not at random,” MNAR); Manski (1990) provides analytic bounds. Finally,
panel (d) depicts joint missingness in both treatment and outcome—sometimes a challenge
in longitudinal studies with dropout—with MNAR on Yi.

Figure 6(a–c) illustrates how Algorithm 2 recovers sharp bounds. Each panel shows
progress in time, converging on known analytic results depicted at the right of each plot.
Primal bounds (blue) widen over time as more extreme, observationally equivalent models
are found. Dual bounds (red) narrow as the outer envelope is tightened. When a region
cannot possibly produce a more extreme value than a previously discovered primal point,
it is eliminated from consideration. Optimization proceeds by simultaneously searching for
more extreme primal points and narrowing the dual envelope. Analysts can terminate the
process at any time, reporting guaranteed-valid dual bounds along with their worst-case
suboptimality factor, ε—or await complete sharpness, ε = 0.

22

Figure 5: Various threats to inference. Panels depict (a) outcome-based selection, (b)
measurement error, (c) nonresponse and (d) joint missingness. In each graph, X and Y are
treatment and outcome, respectively. Dotted red regions represent observed information.
In (a), the box around S indicates selection: other variables are only observed conditional
on S = 1. In (b), Y ∗ represents a mismeasured version of the unobserved true Y . In (c),
RY indicates reporting, so that Y ∗ = Y if R = 1 and is missing otherwise. In (d), both
treatment and outcome can be missing; and missingness on X can aﬀect missingness on Y .

U

X

Y

S

Y

RY

Y ∗

(a)

X

(c)

Y

Y ∗

U

RY

Y ∗

X

Y

X

RX

X ∗

(b)

(d)

Figure 6: Computation of ATE bounds. Progress of Algorithm 2 in simulated Fig-
ure 5(a–d) DGPs. Black error bars are known analytic bounds, y-axes are ATE values,
and x-axes are runtimes of Algorithm 2. Prior analytic bounds are sharp for settings (a–c).
In setting (d), Algorithm 2 achieves point identiﬁcation, but Manski (1990) bounds do
not. Red regions are dual bounds, which always contain sharp bounds and the unknown
true causal eﬀect; these can only narrow over time, converging on optimality. Blue regions
are primal bounds, which can only widen over time as more extreme models are found.
Optimization stops when primal and dual bounds meet, indicating bounds are sharp.

(a) Outcome-based selection

(b) Measurement error

(c) Nonresponse

(d) Joint missingness

23

−1.0−0.50.00.51.00.00.20.40.6SecondsATE−1.0−0.50.00.51.00.0000.0250.0500.0750.100SecondsATE−1.0−0.50.00.51.00.00.20.4SecondsATE−1.0−0.50.00.51.001234SecondsATEIn Figure 6(a–c), the algorithm converges on known analytic results. Ultimately, in the
selection simulation (a), Algorithm 2 achieves bounds of [−0.37, 0.68], correctly recovering
Gabriel et al.’s (2020) bounds; in (b), measurement error bounds are [−0.57, 1.00], matching
Finkelstein et al. (2020); and in (c), outcome missingness bounds are [−0.25, 0.75], equal-
ing Manski (1990) bounds. Somewhat counterintuitively, Figure 6(d) shows dual bounds
collapsing to a point, correctly point-identifying the ATE at −0.25 despite severe missing-
ness. This surprising result turns out to be a special case of an approach using “shadow
variables” recently developed by Miao et al. (2015).12 This example illustrates that the
algorithm is general enough to recover results even when they are not widely known in
a particular model; note that the commonly used approach of Manski (1990) produces
far looser bounds of [−0.72, 0.40], failing to exploit causal structure given in Figure 5(d).
This result suggests our approach enables an empirical investigation of complex models
where general identiﬁcation results are not yet available. Situations where bounds con-
verge suggest models where point identiﬁcation via an explicit functional may be possible,
potentially enabling new identiﬁcation theory.

9 Potential Critiques of the Approach

Below, we brieﬂy discuss several potential critiques of our method.

“The user must know the true causal model.”
Our algorithm requires users specify a causal graph and assumptions, but in many applica-
tions, the true DGP is unknown. This is precisely the obstacle that motivates our approach,
which allows for valid inferences in the absence of complete information. Rather than as-
sert a faulty “complete” model, the user need only input what they know or believe. The
algorithm then outputs the most precise possible solution given that information; key as-
sumptions can be relaxed further using easily incorporated sensitivity analyses, as needed.
We note the diﬃculty of declaring a causal theory, even a partial one, is universal: any
attempt to draw causal inferences from data—even in experimental settings—is premised
(often implicitly) on underlying causal theory. Making assumptions explicit is not a trade-
oﬀ relative to other methods, but a boon for research transparency.

“The bounds may be too wide to be informative.”
Yes.

When a point-identiﬁed solution exists, our algorithm will discover it. As Section 8.3
shows, this can occur in surprising scenarios and may help reveal new identiﬁcation theory.
However, when point-identiﬁcation is impossible, our approach produces sharp bounds.
These bounds may be insuﬃcient for an analyst to achieve a goal such as discerning the
sign of a causal eﬀect. This is simply a fact about the limitations of the research design—
as we prove, it is impossible to narrow the bounds further without additional information.
Again, there is no tradeoﬀ: incorrect point estimates based on faulty assumptions are also

12Speciﬁcally, it can be shown the ATE is identiﬁed for the Figure 5(d) graph only among faithful

distributions where X → Y is non-null—i.e. almost everywhere in the model space.

24

uninformative. When sharp bounds incorporating all defensible assumptions are wide, it
means progress will require collecting more data or justifying additional assumptions.

“What about continuous variables?”
Our approach applies to discrete data, but analysis of continuous variables can often still
proceed with some adjustments. Discrete approximations often suﬃce in applied work.
(Indeed, “all data as observed are discrete,” Rubin, 1981, p. 133). When continuous treat-
ments (e.g. birth date, vehicle speed) often aﬀect discrete outcomes (school admittance,
police stops) only when exceeding a threshold, discretization is lossless. Moreover, when
analyzing discrete treatments and continuous outcomes, much of our theory generalizes to
estimands involving expectations of the outcome. Future work may study our method’s
applicability to bounded continuous variables with smooth eﬀects.

“The bounds will take too long to compute.”
Computation time for sharp bounds may sometimes be prohibitive, but our approach is
likely still faster than manual derivation. Notably, the algorithm recovers several recently
published analytic results in mere seconds (Gabriel et al., 2020; Miao et al., 2015; Knox
et al., 2020). Second, when computation time is long, our algorithm’s “anytime” guarantee
ensures premature termination will still produce valid bounds and report a worst-case
looseness factor for the resulting non-sharp bounds.

10 Future Work with Automated Bounding

Causal inference is a central goal of science, and several established techniques can estimate
causal quantities under ideal conditions. But in many applications, these conditions are
simply not satisﬁed, and developing new analytic solutions is often intractable. For knowl-
edge accumulation to proceed in the messy world of applied statistics, a general solution
is needed. We present a tool to automatically produce sharp bounds on causal quantities
in settings involving discrete data. Our approach involves a reduction of all such causal
queries to polynomial programming problems, enables eﬃcient search over observationally
indistinguishable DGPs, and produces sharp bounds on arbitrary causal estimands. This
approach is suﬃciently general to accommodate a range of classic inferential obstacles.

Beyond providing a general tool for causal inference, our approach aligns closely with
recent calls to improve research transparency by requiring the explicit declaration of esti-
mands, identifying assumptions, and theory (Miguel et al., 2014; Lundberg et al., 2021).
With a common understanding of goals and premises, scholars can have meaningful debates
over the credibility of research. When aspects of a theory are contested, our approach allows
for a fully modular exploration of how assumptions shape empirical conclusions. Scholars
can learn whether a particular assumption is empirically consequential, and if so, craft a
targeted line of inquiry to probe its validity. Our approach can also act as a safeguard
for analysts, ﬂagging assumptions as infeasible when they conﬂict with observed informa-
tion. This means hopeless research projects can be abandoned before wasting eﬀort or
disseminating untruths.

25

Future work should seek to reduce computation time for sharp bounds, especially when
incorporating point-identiﬁed subquantities or additional semi-parametric modeling ap-
proaches. Causal inference scholars may also use this method as an exploratory tool to
aid in the discovery of new identiﬁcation theory. These lines of inquiry now represent the
major open questions in discrete causal inference.

References

Angrist, J. D., G. W. Imbens, and D. B. Rubin (1996).

Identiﬁcation of causal eﬀects
using instrumental variables. Journal of the American Statistical Association 91 (434),
444–455.

Balke, A. and J. Pearl (1994). Counterfactual probabilities: Computational methods,

bounds and applications. In Uncertainty Proceedings 1994, pp. 46–54. Elsevier.

Balke, A. and J. Pearl (1997). Bounds on treatment eﬀects from studies with imperfect

compliance. Journal of the American Statistical Association 92 (439), 1171–1176.

Belotti, P., J. Lee, L. Liberti, F. Margot, and A. W¨achter (2009). Branching and bounds
tightening techniques for non-convex MINLP. Optimization Methods and Software 24 (4-
5), 597–634.

Bienaym´e, I. J. (1838). M´emoire sur la probabilit´e des r´esultats moyens des observations:

d´emonstration directe de la r`egle de Laplace. Imprimerie Royale.

Bonet, B. (2001). Instrumentality tests revisited. In J. S. Breese and D. Koller (Eds.),
UAI ’01: Proceedings of the 17th Conference in Uncertainty in Artiﬁcial Intelligence,
pp. 48–55. Morgan Kaufmann.

Cai, Z., M. Kuroki, J. Pearl, and J. Tian (2008). Bounds on direct eﬀects in the presence

of confounded intermediate variables. Biometrics 64 (3), 695–701.

Carath´eodory, C. (1907, March). ¨Uber den variabilit¨atsbereich der koeﬃzienten von poten-
zreihen, die gegebene werte nicht annehmen. Mathematische Annalen 64 (1), 95–115.

Dean, T. L. and M. Boddy (1988). An analysis of time-dependent planning. pp. 49–54.

American Association for Artiﬁcial Intelligence.

Evans, R. (2018). Margins of discrete bayesian networks. Annals of Statistics 46 (6A),

2623–2656.

Evans, R. J. (2016). Graphs for margins of bayesian networks. Scandinavian Journal of

Statistics 43 (3), 625–648.

Evans, R. J., T. S. Richardson, et al. (2019). Smooth, identiﬁable supermodels of discrete

dag models with latent variables. Bernoulli 25 (2), 848–876.

Finkelstein, N., R. Adams, S. Saria, and I. Shpitser (2020). Partial identiﬁability in discrete

data with measurement error. arXiv preprint arXiv:2012.12449 .

26

Finkelstein, N., E. Wolfe, and I. Shpitser (2021). Non-restrictive cardinalities and functional

models for discrete latent variable dags. Working Paper .

Frangakis, C. E. and D. B. Rubin (2002). Principal stratiﬁcation in causal inference.

Biometrics 58 (1), 21–29.

Gabriel, E. E., M. C. Sachs, and A. Sj¨olander (2020). Causal bounds for outcome-dependent
sampling in observational studies. Journal of the American Statistical Association. DOI:
10.1080/01621459.2020.1832502.

Gamrath, G., D. Anderson, K. Bestuzheva, W.-K. Chen, L. Eiﬂer, M. Gasse, P. Gemander,
A. Gleixner, L. Gottwald, K. Halbig, et al. (2020). The scip optimization suite 7.0.

Geiger, D. and C. Meek (1999, August). Quantiﬁer elimination for statistical problems. In
Proceedings of Fifteenth Conference on Uncertainty in Artiﬁcial Intelligence, Stockholm,
Sweden (Proceedings of Fifteenth Conference on Uncertainty in Artiﬁcial Intelligence,
Stockholm, Sweden ed.)., pp. 226–235.

Greenland, S. and J. Robins (1986). Identiﬁability, exchangeability, and epidemiological

confounding. International Journal of Epidemiology 15, 413–419.

Heckman, J. and E. Vytlacil (2001). Instrumental variables, selection models, and tight

bounds on the average treatment eﬀect, pp. 1–15. Physica.

Kennedy, E. H., S. Harris, and L. J. Keele (2019). Survivor-complier eﬀects in the presence
of selection on treatment, with application to a study of prompt icu admission. Journal
of the American Statistical Association 114 (525), 93–104.

Knox, D., W. Lowe, and J. Mummolo (2020). Administrative records mask racially biased

policing. American Political Science Review 114, 619–637.

Kuchibhotla, A. K., S. Balakrishnan, and L. Wasserman (2021). The hulc: Conﬁdence

regions from convex hulls.

Lee, D. (2009). Training, wages, and sample selection: Estimating sharp bounds on treat-

ment eﬀects. The Review of Economic Studies 76 (3), 1071–1102.

Li, A. and J. Pearl (2021). Bounds on causal eﬀects and application to high dimensional

data. arXiv preprint arXiv:2106.12121.

Lundberg, I., R. Johnson, and B. M. Stewart (2021). What is your estimand? deﬁn-
ing the target quantity connects statistical evidence to theory. American Sociological
Review 86 (3), 532–565.

Malloy, M. L., A. Tripathy, and R. D. Nowak (2020). Optimal conﬁdence regions for the

multinomial parameter. arXiv preprint arXiv:2002.01044 .

Manski, C. (1990). Nonparametric bounds on treatment eﬀects. The American Economic

Review 80 (2), 319–323.

27

Miao, W., L. Liu, E. T. Tchetgen, and Z. Geng (2015).

Identiﬁcation, doubly robust
estimation, and semiparametric eﬃciency theory of nonignorable missing data with a
shadow variable. arXiv preprint arXiv:1509.02556 .

Miguel, E., C. Camerer, K. Casey, J. Cohen, K. Esterling, A. Gerber, R. Glennerster,
D. Green, M. Humphreys, G. Imbens, and D. Laitin (2014). Promoting transparency in
social science research. Science 343 (6166), 30–31.

Molinari, F. (2020). Microeconometrics with partial identiﬁcation. arXiv:2004.11751.

Ottmann, T., S. Schuierer, and S. Soundaralakshmi (1995). Enumerating extreme points in
higher dimensions. In Annual Symposium on Theoretical Aspects of Computer Science,
pp. 562–570. Springer.

Pearl, J. (1995). On the testability of causal modelswith latent and instrumental vari-
ables. Uncertainty in Artiﬁcial Intelligence II. San Francisco, CA: Morgan Kaufmann
Publishers.

Pearl, J. (2009). Causality. New York: Cambridge University Press.

Ramsahai, R. R. (2012). Causal bounds and observable constraints for non-deterministic

models. Journal of Machine Learning Research 13 (3), 829–848.

Richardson, T. (2003). Markov properties for acyclic directed mixed graphs. Scandinavian

Journal of Statistics 30 (1), 145–157.

Richardson, T. S., R. J. Evans, J. M. Robins, and I. Shpitser (2017). Nested Markov

properties for acyclic directed mixed graphs. Working paper.

Richardson, T. S. and J. M. Robins (2013). Single world intervention graphs (swigs) : A
uniﬁcation of the counterfactual and graphical approaches to causality. Working Paper,
Center for Stat. & Soc. Sci., U. Washington 128 (30).

Robins, J. (1989). The analysis of randomized and non-randomized aids treatment trials
using a new approach to causal inference in longitudinal studies. Health service research
methodology: a focus on AIDS , 113—-159.

Rubin, D. B. (1981). The Bayesian Bootstrap. The Annals of Statistics 9 (1), 130 – 134.

Sachs, M., E. Gabriel, and A. Sj¨olander (2020). Symbolic computation of tight causal

bounds.

Shpitser, I. (2018). Identiﬁcation in graphical causal models. In M. Maathuis, M. Drton,
S. Lauritzen, and M. Wainwright (Eds.), Handbook of Graphical Models. CRC Press.

Sj¨olander, A., W. Lee, H. K¨allberg, and Y. Pawitan (2014). Bounds on causal interactions

for binary outcomes. Biometrics 70 (3), 500–505.

Swanson, S. A., M. A. Hern´an, M. Miller, J. M. Robins, and T. S. Richardson (2018).
Partial identiﬁcation of the average treatment eﬀect using instrumental variables: Review
of methods for binary instruments, treatments, and outcomes. Journal of the American
Statistical Association 113 (522), 933–947. DOI: 10.1080/01621459.2018.1434530.

28

Tian, J. and J. Pearl (2002). On the testable implications of causal models with hidden
variables. In UAI ’02: Proceedings of the 18th Conference in Uncertainty in Artiﬁcial
Intelligence, pp. 519–527.

Tukey, J. (1986). Sunset salvo. The American Statistician 40 (1), 72–76.

Verma, T. and J. Pearl (1990). Equivalence and synthesis of causal models.

In P. P.
Bonissone, M. Henrion, L. N. Kanal, and J. F. Lemmer (Eds.), Proc. of the Conf. on
Uncertainty in Artiﬁcial Intelligence, pp. 255–268. Morgan Kaufmann.

Vigerske, S. and A. Gleixner (2018). Scip: Global optimization of mixed-integer nonlinear
programs in a branch-and-cut framework. Optimization Methods and Software 33 (3),
563–593.

W¨achter, A. and L. T. Biegler (2006). On the implementation of an interior-point ﬁl-
ter line-search algorithm for large-scale nonlinear programming. Mathematical program-
ming 106 (1), 25–57.

Wolfe, E., R. W. Spekkens, and T. Fritz (2019). The inﬂation technique for causal inference

with latent variables. Journal of Causal Inference 7 (2).

Zhang, J. and E. Bareinboim (2021, Feb). Non-parametric methods for partial identiﬁcation
of causal eﬀects. Technical Report R-72, Causal Artiﬁcial Intelligence Lab, Columbia
University.

Zhang, J. L. and D. B. Rubin (2003). Estimation of causal eﬀects via principal stratiﬁcation
when some outcomes are truncated by “death”. Journal of Educational and Behavioral
Statistics 28 (4), 353–368.

29

A Examples, Algorithms, and Detailed Discussion

A.1 Canonicalization of DAGs

In this appendix, we summarize the process for obtaining a canonical hidden variable DAG,

presented as Deﬁnition 4.6 in Evans (2016). Theorem 4.13 in Evans (2016) shows that the

marginal model of any hidden variable DAG is the same as that of its canonical hidden

variable DAG, and Proposition 7.4 of the same work shows that the same holds for the

model for post-intervention distributions, when interventions are restricted to the main

variables.

Given a hidden variable DAG G, the canonical form of the DAG is constructed by the

following procedure:

1. Add an edge Xj → Xj(cid:48) for any pair of variables Xj, Xj(cid:48) such that there is a path

from Xj to Xj(cid:48) along which all variables between Xj and Xj(cid:48) are hidden. Xj and Xj(cid:48)

can each be hidden or observed.

2. Remove incoming edges to hidden variables.

3. Remove hidden variables whose children are a subset of the children of another hidden

variable.

By construction, all latent variables in the canonical DAG will be exogenous.

A.2 Functional Models in the Context of Determinism

The general approach for obtaining functional models for discrete hidden variable DAGs

(Evans, 2018; Finkelstein et al., 2021) does not take account of the kind of determinism

introduced into the model by missingness indicators, and as such may yield a functional

model that is over-parameterized. Due to the complexity of polynomial programming, it is

beneﬁcial to avoid excess parameters where possible. We now brieﬂy explore this issue.

30

Figure 7: A graph with determinism.

A

RA

A∗

B

Consider the scenario depicted in Figure 7. In this graph, A∗ is a proxy for the unob-

served variable A, which is observed with missingness as indicated by RA. When RA = 0,

then A∗ is deterministically equal to a special value indicating missingness (usually denoted

with the special value such as “?” or “NA”). In addition, A∗ is aﬀected by B. This scenario

might arise if A is measured with missingness and measurement error, and the nature of

the error is aﬀected by B. Of note, A∗ is not a fully deterministic function of A and

RA, and cannot simply be removed from the functional parameterization, as in traditional

missingness without measurement error. However, we can use the fact that it is a partially

deterministic function of RA to reduce the number of parameters needed in the functional

model for this graph.

In general, the functional model for this graph would allocate one value of (cid:15)A∗—the

exogenous noise that determines A∗ in terms of its parents—for every combination of pos-

sible responses of A∗ to its parents. Suppose A∗ takes values in {0, 1, ?}, and A, RA and

B take values in {0, 1}. This would correspond to 38 = 6561 possible values of (cid:15)A∗. How-

ever, any such value that maps RA = 0 to A∗ ∈ {0, 1} or RA = 1 to A∗ =? is ruled out

by the deterministic relationship. As a result, (cid:15)A∗ need only specify the response of A∗

in {0, 1} to A and B when RA = 1. This yields only 24 = 16 possible values for (cid:15)A∗.

This example demonstrates that incorporating known deterministic relationships can yield

a non-restrictive functional parameterization with fewer parameters.

A.3 DAG Parameterization for Non-geared Graphs

Most graphs we encounter in practice are geared (Evans, 2018), which means they have no

non-trivial bi-directed cycles Finkelstein et al. (2021). When graphs are not geared, and the

target estimand as well as all empirical evidence involves only single world probabilities,

31

it is possible to improve the complexity of the system. Under these circumstances, it is

preferable to obtain non-restrictive bounds on the cardinalities of latent variables according

to Finkelstein et al. (2021). All single world probabilities can be expressed in terms of the

usual DAG parameters according to the g-formula, and therefore all functionals of such

probabilities described in Corollary 1 can be polynomialized as well. If the target or any of

the empirical evidence involve cross-world probabilities, we must revert to the functional

model approach.

A.4 Example of Program Simpliﬁcation

Figure 8: A graph with conditional independence and Verma constraints.

A

B

U2

E

U1

C

F

D

U3

Consider the graph presented in Figure 8. We will use this graph to illustrate a number

of points raised in the main body of the paper. Suppose we are interested in the ATE of E

on C. First, we will explicitly construct the functional model of this graph, then use it to

generate a simple polynomial program that bounds a causal target. Next, we will employ

several of the strategies described in Section 5 to simplify the program, demonstrating the

importance of these strategies in obtaining tractable program formulations. Finally, we will

observe that a broader class of partial identiﬁcation problems than previously recognized

can be formulated as linear programs.

Suppose all observed variables in the graph above are binary. In constructing a func-

tional model, we ﬁrst note that U2 is responsible for determining the values of A, C and E

in response to their parents. A has no parents, E has one parent, and C has two parents.

Therefore U2 takes values in a state space of size 21 × 22 × 24 = 128. Next, we suppose

32

U1 is responsible for determining the value of B in response to A, and therefore has size

22 = 4. U3 is left to determine the value of F in response to D, and of D in response to U1

and C. It therefore takes values in space of size 28 × 22 = 1024.13

To construct the polynomial program, we begin with the non-negativity and linear

marginalization constraints on the parameters of the distributions of the disturbances (for

simplicity, we abstain from eliminating one parameter per distribution using the sum-to-

unity constraint):

Pr(Ui = u) ≥ 0

Pr(Ui = u) = 1

(cid:88)

u∈ΩUi

∀i, ∀u ∈ ΩUi

∀i.

We then add constraints encoding the empirical evidence E. For simplicity, we assume

that we observe the full joint distribution Pr(A = a, B = b, C = c, D = d, E = e, F = f ),

which is a vector of size 26 = 64, corresponding to 64 equality constraints in the program.

There are 3 disturbance variables in this graph, including (cid:15)E, leading to polynomials in these

equality constraints with terms of degree 3. Given the cardinalities of the disturbances,

there are 24 × 27 × 210 = 2, 097, 152 possible combinations of disturbance assignments. By

a simple exchangeability argument, the same number of possible combinations lead to each

outcome in the state space. As there are 26 outcomes, each of the 64 polynomial equality

constraints for E will have 221

26 = 215 terms, again each of degree 3. This is a very large

program.

Pr(A = a, B = b, C = c, D = d, E = e, F = f ) =

(cid:88)

(cid:89)

u∈ΩU

i

Pr(Ui = u)1(u =⇒ a, b, c, d, e, f )

(1)

We now consider the strategies described in Section 5. First, observe that there are

13It is also possible to construct a functional model by ﬁrst taking U3 to be responsible for determining F
in response to D, and then U1 to be responsible for determining B in response to A and D in response to C
and U3. By a simple symmetry argument, the two functional models yield the same number of parameters.

33

only 31 nested Markov parameters for this graph, corresponding to 31 polynomial equality

constraints encoding E: a substantial savings over the 64 parameters of the na¨ıve parameter-

ization. This reduced parameterization is possible because it encodes standard conditional

independences, such as F ⊥ A | D.

In addition, it encodes Verma constraints, which

emerge either (i) from independences in post-intervention distributions or (ii) from the ir-

relevance of an intervention to a particular distribution. In this case, A ⊥ {D, F } | do(C).

As discussed in the main text, each equality constraint can be used to reduce the num-

ber of parameters needed in a non-restrictive reduction that can express every possible

distribution in the model.

Recall that each nested Markov parameter corresponds to the identiﬁed probability of a

single world event, where the event is speciﬁed in terms of variables in a single district, and

the intervention is on all parents of the district relevant to those variables. For example,
in this case, one of the nested Markov parameters is Pr (cid:0)b = 1, f = 1|d = 1, do(a =
1, c = 1)(cid:1). We can now make use of Proposition 3 to reason that each of these polynomial

constraints must involve only disturbances from a single district. Therefore in the equations

corresponding to nested Markov parameters for the district corresponding to U2, parameters

of the distributions of U1 and U3 will all sum out, and we will be left with equations

that are linear in the parameters of U2. Likewise, in equations corresponding to nested

Markov parameters for the district containing descendants of U1 and U3, parameters for

the distribution of U2 will factor out, and we will be left with a quadratic equation.

Finally, we can make use of Proposition 4 to note that constraints involving nested

Markov parameters corresponding to the {U1, U3} district can be dropped from the pro-

gram. This is because they only involve parameters for the distributions of U1 and U3,

which do not appear in any constraint involving parameters for the distribution of U2. The

target, by contrast, involves only parameters for the distribution of U2.

As a result of taking the three steps described in Section 5, we have taken this problem

from a polynomial program involving 1156 parameters to a linear program involving only

27 = 128 parameters and fewer constraints. This example also motivates the following

34

corollary, which expands the class of partial identiﬁcation problems that can be formulated

as linear programs relative to known results (Balke and Pearl, 1997; Finkelstein et al., 2020;

Wolfe et al., 2019).

Corollary 2. Suppose G is a hidden variable DAG with observed variables V , C = {V(cid:96)(a(cid:96)) =

v(cid:96) | (cid:96) ∈ L} is a set of counterfactual statements, and Pr(C) is the target of interest. Further

suppose that the full joint distribution Pr(V = v) is observed. Then Pr(C) can be sharply

bounded given the observed data by optimizing a linear program if all {V(cid:96)|(cid:96) ∈ L} are in the

same single-latent-variable district.

Proof. Because the common district of C contains only a single latent variable, by Propo-

sition 3 the objective will be linear in the parameters of the distribution of that latent

variable. By Proposition 4, the constraints will not involved parameters corresponding

to other districts. By Algorithm 1, no single term in a constraint will involve multiple

parameters for the same latent distribution, meaning that all constraints involving only

parameters corresponding to a single-variable district will be linear. The non-negativity

and sum-to-unity constraints on the parameters of the latent-variable distribution are also

linear. It follows that the objective and all constraints are linear.

A.5 Constructing the Polynomial Program

Algorithm 1 constructs a polynomial program to sharply bound any factual or counter-

factual target of inference, T , that is a polynomial fraction or monotonic transformation

thereof. In addition to T , the algorithm takes as input a possibly non-canonical DAG G;

empirical evidence E, modeling assumptions A, and sample space of possible outcomes for

the main variables, S(V ). It produces an optimization problem with a polynomial objective

subject to polynomial constraints. This polynomial programming problem is equivalent to

the original causal bounding problem.

35

Algorithm 1 Constructing a Polynomial Program

Input:
Output: polynomial program in parameters PU or PU ∪ s

graph G, evidence E, assumptions A, sample space S(V ), target T

Initialization

1: initialize empty constraint set C ← ∅
2: G ← canonicalize G
3: PU ← parameters of functional model for G

Polynomialize objective function
4: T ← polynomial-fractionalize(T )
5: if T contains fractions then
6:
7:
8: end if

polynomialize(T = s) and append to C
T ← s

polynomialize(cid:0)g(PV ) (cid:56) α(cid:1) and append to C

Polynomialize constraints
9: for (cid:0)g(PV ) (cid:56) α(cid:1) ∈ (cid:0)E ∪ A(cid:1) do
10:
11: end for
12: for Ui,k ∈ Ui do
13:
14: end for

append (cid:0)PUk is a distribution(cid:1) to C

Optimize

15: return optimize T subject to C

A.6 Optimizing the Polynomial Program

Algorithm 2 provides a step-by-step description of the ε-sharp bounding procedure. For ease

of reference, we duplicate the Section 6 discussion of the algorithm’s various components

here.

Algorithm 2 takes as inputs the polynomialized objective function T (p) and constraint

set C(p), obtained from Algorithm 1. It then evaluates a range of models, or points p in

the model space P for which C(p) is satisﬁed. It seeks to identify extreme values of T (p)

within this subspace. It also accepts two parameters: (cid:15)thresh, a stopping threshold for the

looseness factor stopping, and θthresh, a stopping threshold for width of the bounds. The

algorithm returns two types of information: the upper and lower bounds for the causal

program, and the worst-case looseness factor ε.

Primal bounds are denoted P and P , adopting the convention that underlines refer to

objects used for minimization and overlines for maximization. These indicate the extreme

36

values of the target estimand in any admissible model—that is, satisfying C(p)—that has

been located so far. These are initialized at +∞ and −∞, respectively, indicating that

no admissible models have been found yet. As optimization proceeds, the primal bounds

improve as new, more extreme admissible models are found. We refer to [P , P ] as the inner

bounds: the unknown sharp bounds must at least contain these points, which correspond

to models that are observationally indistinguishable from the true DGP.

Dual optimization begins by partitioning the parameter space into branches, proceeding

separately for the lower and upper bound and respectively producing partitions Bb and Bb.

At initialization, these consist of a single branch spanning the entire parameter space; each

branch is then recursively divided. The lower and upper parts of the dual envelope, or

outer envelope, are denoted D and D. These are piecewise linear functions, with pieces

corresponding to the branching partitions, that are relaxations of the true objective func-

tion, T (p), from below and above. These relaxations are made to ensure they will always

contain the entire objective function at all points in the parameter space. Within branch

b, the value min{Db(p) : p ∈ Bb} indicates the lowest value attained by the lower envelope;
(cid:8)min{Db(p) : p ∈ Bb}(cid:9) represents the lowest value attained by the lower
(cid:8)max{Db(p) : p ∈ Bb}(cid:9)

envelope anywhere in the parameter space. Conversely, T = maxb

thus, T = minb

represents the highest value of the upper envelope. These extreme points on the dual

envelope, [T , T ], deﬁne the dual (outer) bounds. These are the reported causal bounds;

whatever the true sharp bounds, they must lie inside the dual bounds, even if the algorithm

has not run to completion. We let θ equal the bound width, or the diﬀerence between the

upper and lower dual bounds, and we deﬁne the worst-case looseness factor ε as the slack

(the diﬀerence in dual and primal bound widths) divided by the primal bound width.

The algorithm heuristically selects branches in the model space that appear promising,

and reﬁnes primal and dual bounds in turn.

It ﬁrst searches within the branch for an

admissible model; if found, and if the associated causal estimand is more extreme than

those previously encountered, it is stored as a new primal bound. Whatever the true

nonparametric sharp bounds, they must lie outside the primal bounds because the true

37

bounds must contain the extreme models that deﬁne the primal bounds. Then, it divides

the branch into sub-branches and reﬁnes the dual envelope by tightening the piecewise

linear outer-approximation. The algorithm continuously prunes branches of Bb and Bb

that are inconsistent with speciﬁed constraints; it also continuously branches and reﬁnes

the bounds while θ and ε exceed speciﬁed thresholds.

Algorithm 2 Computing ε-sharp Bounds

Input:

Output:

target T (p) and constraint relations C(p) in parameters p,
stopping thresholds εthresh and θthresh
lower bound T , upper bound T , maximum looseness factor ε

Initialization

1: branches of parameter space: indexed partitions B ←

[0, 1]#{p}(cid:111)
(cid:110)
2: dual (outer) bounds: indexed families of functions D ← {p (cid:55)→ −∞}, D ← {p (cid:55)→ +∞}
3: primal (inner) bounds: P = +∞ and P = −∞
4: bounds width: θ = +∞
5: bounds looseness factor ε = +∞

[0, 1]#{p}(cid:111)
(cid:110)

, B ←

Spatial branch and bound

6: while ε > εthresh and θ > θthresh do
7:

for extremum in min, max do

8:
9:
10:
11:
12:

13:
14:
15:
16:

17:
18:
19:
20:
21:
22:
23:

24:
25:
26:
27:
28:

29:

30:
31:

Select direction
if extremum is min then

set ∗ ← and (cid:56) ← ≤
else if extremum is max then
set ∗ ← and (cid:56) ← ≥

end if
Primal reﬁnement
continue search for local extremum of T (p) s.t. C(p) is satisﬁed
if feasible point is found and T (p) (cid:56) P ∗ then

update primal bound P ∗ ← T (p)

end if
Dual reﬁnement
select outermost branch b = arg extremumb(cid:48)
b from B∗ and subpartition it, pop D∗
pop B∗
for each subpartition B∗
push new branch B∗
ﬁnd linear function D∗
push linear programming relaxation D∗

b(cid:48) in B∗
b(cid:48) into B∗

b(cid:48) s.t. D∗

b do

end for
Prune branches that cannot widen bounds
for each b in 1, . . . , |B∗| do
if P ∗ (cid:56) extremum{D∗

b (p) : p ∈ B∗

pop B∗

b from B∗, pop D∗

b from D∗

end if

end for

(cid:8)extremum{D∗
b (p) from D∗

b(cid:48)(p) : p ∈ B∗

b(cid:48)}(cid:9)

b(cid:48)(p) (cid:56) T (p) for all p ∈ B∗
b(cid:48)
b(cid:48) into D

b } or C(p) = False for all p ∈ B∗

b then

end for
Check progress
T ← minb {min{Db(p) : p ∈ Bb}}, T ← maxb
θ ← T − T

(cid:8)max{Db(p) : p ∈ Bb}(cid:9)

38

ε ← θ/(P − P ) − 1

32:
33: end while
34: return T , T , ε

B Proofs

Proof of Proposition 1.

Proof. We adapt the proof of Finkelstein et al. (2021) to account for counterfactuals as
(cid:0)pa(Vi,j) = a(cid:1), to be those

follows. First, we deﬁne one-step-ahead counterfactuals, Vi,j

where all main parents of a variable are subject to intervention pa(Vi,j) = a. Next, we note

that all other counterfactuals and factuals in the full data law are deterministic functions

of one-step-ahead variables, after ﬁxing Ui. Therefore it is suﬃcient to reason about only

one-step-ahead variables; intervention on other variables is irrelevant to the full data law.

Because the likelihoods of multi-district graphs factorize as the likelihoods of the dis-

tricts after intervention on their parents (Richardson et al., 2017), we can consider single-

district graphs without loss of generality.

In multi-district graphs, the bound obtained

below can be applied within each district.

Each main variable Vi,j has |S(pa(Vi,j))| one-step-ahead counterfactuals, corresponding
(cid:0)pa(Vi,j) =
to possible manipulations of its parents. Each one-step-ahead counterfactual Vi,j
a(cid:1) has a cardinality equal to those of the corresponding main variable |S(Vi,j)|. Therefore,
the collection of a single variable’s one-step-ahead counterfactuals (cid:8)Vi,j
can take on |S(Vi,j)||S(pa(Vi,j ))| possible values, and there are d ≡ (cid:81)

(cid:0)pa(Vi,j) = a(cid:1), Vi,j

|S(Vi,j)||S(pa(Vi,j ))|

Vi,j ∈Vi

(cid:0)pa(Vi,j) = a(cid:48)(cid:1), . . .(cid:9)

values that the full collection of all one-step-ahead variables can take. Any model over
this full collection must be a subset of the d − 1 simplex. We let V (cid:0)pa(V )(cid:1) denote the

collection of one-step-ahead variables.

Suppose the disturbances Ui are enumerated as {Ui,1, . . . , Ui,K}. We will now show
that each Ui,k can be assumed to be discrete without altering the model for V (cid:0)pa(V )(cid:1)

and therefore the full data law. First, for each value uk in the domain of Ui,k, we deﬁne the

distribution Puk

(cid:16)

V (cid:0)pa(V )(cid:1)(cid:17)

= (cid:82)

u\k

(cid:16)

P

V (cid:0)pa(V )(cid:1) | u\k, uk

(cid:17)

P (u\k), where u\k denotes

39

all disturbances other than uk. This ﬁxes Ui,k at the value uk, modifying the distribution
over V (cid:0)pa(V )(cid:1).

We now make two observations. First, the model for V (cid:0)pa(V )(cid:1) contains Puk for any

uk, because Ui,k is not restricted by the model and is therefore permitted to have a point-

mass distribution at uk. Second, the expected value of Puk with respect to Ui,k recovers
V (cid:0)pa(V )(cid:1)(cid:17)

, which is therefore in the convex hull of

the original marginal distribution P

(cid:16)

the set of distributions S(Puk) ≡ {Puk | uk ∈ S(Ui,k)}.

Carath´eodory’s Theorem (1907) states that for any point P in the convex hull of a set S

in a space of dimension d−1, there exists a set of d−1 points {Puk1
{w1, . . . , wd−1} such that P = (cid:80)d−1
. It then follows directly that any distribution in
the marginal model over V (cid:0)pa(V )(cid:1) when latent variables have unrestricted cardinality is
also in the marginal model over V (cid:0)pa(V )(cid:1) when latent variables have cardinality restricted
to (cid:81)

|S(Vi,j)||S(pa(Vi,j ))| − 1 or higher.

, . . . , Pukd−1

} and weights

(cid:96)=1 w(cid:96)Pui(cid:96)

Vi,j ∈Vi

Proof of Proposition 2

Proof. Using the approach developed in Evans (2018) and generalized to arbitrary graphs

in Finkelstein et al. (2021), we can obtain a functional model that is non-restrictive of the

causal model of G over observed variables. In such a model, each Vi,(cid:96)(a(cid:96)) is determined by

by values of the disturbances Ui. By assumption, G is in canonical form, rendering all dis-

turbances marginally independent. The proposition then follows from standard probability

calculus.

Proof of Proposition 3

Proof. Under the conditions speciﬁed, no element in C involves a function of Ui,k. It follows

that whether the disturbances lead to C is not a function of the value of Ui,k. As a result,

a sum over all parameters of the distribution of Ui,k can be factored out of the product

in Equation 2. By the deﬁnition of probability distributions, this sum will be equal to 1,

rendering the parameters irrelevant to the polynomial.

40

Proof of Proposition 4

Proof. Each of the nested Markov parameters corresponds to the probability that ran-

dom variables in a single district take certain values after an intervention on parents of

the district. It follows from Proposition 3 that no disturbances outside the district cor-

responding to the nested Markov parameter will appear in the polynomialization of that

parameter. From this, it then follows that no disturbances in diﬀerent districts will interact

in constraints corresponding to nested Markov parameters. By Proposition 2, the degree

of a polynomialization of the probability of the event is at most the number of relevant

disturbances.

C Uncertainty

In this appendix, we provide details on our approach to quantifying the uncertainty of

bounds based on estimated empirical inputs, ˆE =

(cid:105)

(cid:104) ˆE(cid:96)

. Recall that the estimated bounds

are obtained from a polynomial program using equality constraints of the form
polynomialize(cid:0)g(cid:96)(PV ) = ˆE(cid:96)
(cid:1), which is equivalent to polynomial-fractionalize(cid:0)g(cid:96)(PV )(cid:1) =
ˆE(cid:96). Here, ˆE(cid:96) is the noisily estimated empirical quantity and polynomial-fractionalize(cid:0)g(cid:96)(PV )(cid:1)

is the reexpression of that same quantity in terms of principal strata sizes. At a high level,

we will proceed by constructing conﬁdence regions CRα( ˆE) such that Pr

(cid:16)

(cid:17)
E ∈ CRα( ˆE)

≥

α. To obtain conﬁdence bounds, we then replace empirical equality constraints with a looser
version that accounts for sampling variation, of the form polynomial-fractionalize(cid:0)g(cid:96)(PV )(cid:1) ∈
CRα( ˆE).

Observe that because the main variables are discrete, ˆE is a realization of a multino-

mial proportion.

In what follows, we will assume that empirical evidence arises from a

single multinomial distribution, such as a single-world marginal distribution; if multiple in-

dependent sets of empirical evidence about diﬀering quantities are available, the procedure

generalizes straightforwardly by repeating the procedure within each set and combining the

results appropriately.

41

Based on this idea, we examine two methods for constructing CRα( ˆE). Drawing on

Malloy et al. (2020), we ﬁrst consider a “Bernoulli-KL” approach that constructs separate

conﬁdence regions for each observable atomic event, Pr(Vi = v), treating it as a “success”

in a Bernoulli distribution. The approach rotates through all possible v and combines

the event-speciﬁc regions using a result on the Kullback-Leibler divergence of sampling

distributions to the underlying population distribution. The Bernoulli-KL method produces

a conﬁdence region for single-world distributions that is guaranteed to have conservative

coverage for the multinomial proportion in ﬁnite samples.

Let k ∈ {1, . . . , K} index possible atomic events, and denote the probability of the k-th

event as pk = Pr(Vi = vk). Empirical frequencies are denoted ˆpk. For the Bernoulli-KL
method, we will develop a conﬁdence region of the form CRα( ˆE) = (cid:84)K

(cid:105)
, noting

p

(cid:104)

k=1

, pk

k

that each pk can be polynomialized. A visualization of the resulting region is given in

Figure 2(b).

We now describe how p

k

and pk can be calculated to ensure that Pr(E ∈ CRα( ˆE)) ≥ α.

At a high level, we will do so by analyzing each of the K observable events as a Bernoulli

distribution. Taking each ˆpk estimate as given, we identify regions of the unknown pk from

which the observed ˆpk diverge substantially. Equation 11 of Malloy et al. (2020) provides

bounds on the sampling probability of observing KL ([1 − ˆpk, ˆpk], [1 − pk, pk]) in excess of
some threshold, where KL(cid:0)[1 − ˆpk, ˆpk], [1 − pk, pk](cid:1) = ˆpk log ˆpk
pk

+ (1 − ˆpk) log 1−ˆpk
1−pk

.

In turn, these bounds imply regions of pk that can be conservatively rejected. Let p

k

be given by the solution to KL(cid:0)[1 − ˆpk, ˆpk], [1 − p
](cid:1) = 1
Similarly, let pk be given by KL(cid:0)[1 − ˆpk, ˆpk], [1 − pk, pk](cid:1) = 1

, p
k

k

N log 2K
N log 2K

1−α subject to p

∈ [0, ˆpk].

k

1−α subject to pk ∈ [ˆpk, 1].

It can be seen from Malloy et al. (2020) that when constructing p

Pr

(cid:16)(cid:84)K

k=1 pk ∈ [p

(cid:17)

, pk]

k

≥ α over repeated samples.

and pk in this way,

k

Our second approach uses an asymptotic conﬁdence region based on the multivariate
Gaussian limiting distribution of the multinomial proportion, N (cid:0)p, diag(p) − pp(cid:62)(cid:1) (Bien-

aym´e, 1838). Because the multinomial proportion must sum to unity, this distribution is de-

generate, and it is often more convenient to work with its ﬁrst K −1 elements, p\K. We con-

42

(cid:80)N

Figure 9: Polynomial conﬁdence regions in a binary graph. Panel (a) presents a
causal graph in which binary X causes binary Y , but both are confounded by an unobserved
U . N = 1, 000 observations are drawn from this DGP, producing an empirical distribution
1(Xi = x, Yi = y). Panels (b–c) depict conﬁdence regions for
with proportions 1
N
Pr(Xi = 0, Yi = 0), Pr(Xi = 0, Yi = 1), and Pr(Xi = 1, Yi = 0); the ﬁnal category,
Pr(Xi = 1, Yi = 1) (not depicted), must sum to unity. Panel (b) shows the Bernoulli-
KL conﬁdence region, which is conservative in ﬁnite samples and can be polynomialized
as a set of linear inequalities. Panel (c) shows the Gaussian conﬁdence region, which is
asymptotically valid and can be polynomialized as a single convex quadratic inequality.

i=1

U

X

Y

(a)

(b)

(c)

struct the asymptotic conﬁdence region as ( ˆp\K − p\K)(cid:62) (cid:16)
p\K) ≤ z, where z is an appropriate critical value of the χ2 distribution. A visualization of

diag( ˆp\K) − ˆp\K ˆp(cid:62)
\K

( ˆp\K −

(cid:17)−1

the resulting region is given in Figure 2(c). As before, each element in p is polynomializ-

able, leading to a single conﬁdence constraint that can be straightforwardly incorporated

into the optimization routine.

For ease of reference, we duplicate Figure 2 in Figure 9, below. This ﬁgure depicts

these regions visually for a simple two-node graph, shown in Figure 9(a). The resulting

Bernoulli-KL and Gaussian conﬁdence regions are depicted in Figure 9(b–c).

Finally, we describe how arbitrary conﬁdence regions, such as the optimal level-set re-

gions of Malloy et al. (2020) or the exact ﬁnite-sample regions of Kuchibhotla et al. (2021),

can be polynomialized. At a high level, the proposed method uses a circumscribing poly-

tope, adding faces along the region’s principal axes until the desired tightness is achieved.

One possible approach to doing so is to enumerate candidate p along a ﬁne grid, assess

each candidate for membership in the conﬁdence region, and compute the convex hull of

43

the non-rejected points. This procedure produces a system of linear inequalities describing

the hull facets. However, it is infeasible for even moderately sized problems, as the time

complexity of hull construction can grow exponentially in the dimension of the space, K

(Ottmann et al., 1995). Our approach builds on this basic intuition of circumscribing a

complex conﬁdence region with a larger, more tractable polytope. We compute the principal

components of the non-rejected points, then identify the two extreme non-rejected points

along each axis. Each principal axis is the normal vector for two boundary planes, and each

extreme point along that axis deﬁnes an boundary plane oﬀset. By repeating this procedure

along each principal axis, we obtain a circumscribing conﬁdence region, a parallelepiped

that contains the KL conﬁdence region. The gap between the two conﬁdence regions can be

rapidly approximated by using number of grid points that lie in the inscribing region but

not the original conﬁdence region. By slicing the simplex along additional directions, such

as convex combinations of principal axes, this gap can be tightened to arbitrary precision.

The resulting polytope deﬁnes a system of linear inequalities that can then be incorporated

into the polynomial program.

D Details of Simulated Models

In this section, we detail all models presented in Section 8. For simplicity, all main variables

in these models are binary. Simulation parameters are described in terms of principal strata.

Principal strata can take one of three forms, depending on the number of parents of the

relevant variable. Below, we provide compact notation for referring to these principal

strata. Subsequent sections report strata probabilities for each simulation, including joint

distributions over strata for multiple variables where confounding exists.

1. Variables with no parents, which have two strata. Consider a hypothetical

variable Xi with no parents, as in Figure 5(a). We use x0 to denote units with

Xi(∅) = 0 and x1 to denote Xi(∅) = 1.

2. Variables with a single parent, which have four strata. Consider a hypotheti-

44

cal variable Yi inﬂuenced by parent Xi, also depicted in Figure 5(a). For compactness,

we adopt the convention that counterfactual manipulations of parent variables are

presented in the form yYi(Xi=0),Yi(Xi=1). For example, (i) we use y00 to denote “never

takers” with example, Yi(Xi = 0) = 0 and Yi(Xi = 1) = 0. Similarly, (ii) y01 denotes

“compliers” with Yi(Xi = 0) = 0 and Yi(Xi = 1) = 1, (iii) y10 denotes “deﬁers”

with Yi(Xi = 0) = 1 and Yi(Xi = 1) = 0, and y11 denotes “always takers” with

Yi(Xi = 0) = 1 and Yi(Xi = 1) = 1.

3. Variables with two parents, which have sixteen strata. Consider a hypothet-

ical variable Yi inﬂuenced by parents Zi and Xi, as in Figure 3(a). Extending the

convention described above, we denote these in compact forms ranging from y0000 to

y1111. Speciﬁc deﬁnitions are provided in Table 2.

45

Table 2: Principal strata for a variable Yi with two parents, Zi and Xi. Each row
corresponds to a strata, with compact names given in the ﬁrst column. For each strata,
counterfactual values of Yi are given in subsequent columns.

Yi(Zi = 0, Xi = 0) Yi(Zi = 0, Xi = 1) Yi(Zi = 1, Xi = 0) Yi(Zi = 1, Xi = 1))
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1

0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1

0
0
0
0
1
1
1
1
0
0
0
0
1
1
1
1

0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1

y0000
y1000
y0100
y1100
y0010
y1010
y0110
y1110
y0001
y1001
y0101
y1101
y0011
y1011
y0111
y1111

46

D.1 Noncompliance Simulation

In this section, we describe the DGP for our noncompliance simulation analyzed in Sec-

tion 8.1. The DGP follows the model of Figure 3(b), reproduced below for ease of reference.

Simulation parameters are reported in terms of the joint distribution over principal strata.

Figure 10: DGP with noncompliance.

U

Z

X

Y

Strata for Z:

z0

z1

0.649335

0.350665

Strata for X and Y :

y00

y10

y01

y11

x00

x10

x01

x11

0.000757

0.013034

0.006125

0.002606

0.004541

0.074105

0.034526

0.014387

0.026040

0.418847

0.195419

0.082264

0.004534

0.073950

0.034123

0.014742

D.2 Outcome-Based Selection Simulation

In this section, we describe the DGP for our outcome-based selection simulation, analyzed

in Section 8.3 and Figure 6(a). The DGP follows the model of Figure 5(a), reproduced below

for ease of reference. Simulation parameters are reported in terms of the joint distribution

over principal strata.

47

U

X

Y

S

Strata for X and Y

y00

y10

y01

y11

x0

x1

0.124855

0.125375

0

0

0.249647

0.124847

0.249851

0.125425

Strata for S

S10

S01

0.50052

0.49948

D.3 Measurement Error Simulation

In this section, we describe the DGP for our measurement error simulation, analyzed in

Section 8.3 and Figure 6(b). The DGP follows the model of Figure 5(b), reproduced below

for ease of reference. Simulation parameters are reported in terms of the joint distribution

over principal strata.

Y

Y ∗

X

U

Strata for X

x0

x1

0.499442

0.500558

48

Strata for Y and Y ∗

Y ∗
00

Y ∗
10

01 Y ∗
Y ∗
11

y00

y10

y01

y11

0

0

0

0

0.167269

0

0

0

0.165838

0.500388

0.166505

0

0

0

0

0

D.4 Outcome Missingness Simulation

In this section, we describe the DGP for our outcome missingness simulation, analyzed in

Section 8.3 and Figure 6(c). The DGP follows the model of Figure 5(c), reproduced below

for ease of reference. Simulation parameters are reported in terms of the joint distribution

over principal strata.

Y

RY

Y ∗

X

Strata for X

x0

x1

0.499159

0.500841

Strata for Y

y00

y10

y01

y11

0.166371

0

0.666851

0.166778

49

Strata for R

r0000

r1000

0

0

r0100

0.250368

r1100

0.249910

r0010

r1010

r0110

r1110

r0001

r1001

0

0

0

0

0

0

r0101

0.250154

r1101

r0011

r1011

r0111

0

0

0

0

r1111

0.249568

D.5 Joint Missingness Simulation

In this section, we describe the DGP for our joint missingness simulation, analyzed in

Section 8.3 and Figure 6(d). The DGP follows the model of Figure 5(d), reproduced below

for ease of reference. Simulation parameters are reported in terms of the joint distribution

over principal strata.

Y

RY

Y ∗

X

RX

X ∗

50

Strata for X

x0

x1

0.43464

0.56536

Strata for Y

y00

y10

y01

y11

0.485336

0.253616

0.003768

0.257279

Strata for Rx

rx,0

rx,1

0.470201

0.529798

Strata for Ry

ry,0000

ry,1000

0

0

ry,0100

0.162045

ry,1100

0

ry,0110

0.177470

ry,0001

0.107010

ry,1001

0.120311

ry,0101

0.255778

ry,1101

0.081733

ry,0011

ry,1011

0

0

ry,0111

0.095652

ry,1111

0

51

