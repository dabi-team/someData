9
1
0
2

v
o
N
2
1

]

O
C

.
t
a
t
s
[

2
v
4
2
2
4
0
.
1
1
9
1
:
v
i
X
r
a

APPROXIMATE UNCERTAIN PROGRAM

A PREPRINT

Xun Shen
Department of Statistical Sciences
The Graduate University for Advanced Studies
Tokyo, Japan 106-8569
shenxun@ism.ac.jp

Jiancang Zhuang
Institute of Statistical Mathematics
Research Organization of Information and Systems
Tokyo, Japan 190-8562
zhuangjc@ism.ac.jp

Xingguo Zhang
Department of Mechanical Systems Engineering
Tokyo University of Agriculture and Technology
Tokyo, Japan, 184-8588
xgzhang@go.tuat.ac.jp

November 13, 2019

ABSTRACT

Chance constrained program where one seeks to minimize an objective over decisions which satisfy
randomly disturbed constraints with a given probability is computationally intractable. This paper
proposes an approximate approach to address chance constrained program. Firstly, a single layer
neural-network is used to approximate the function from decision domain to violation probability
domain. The algorithm for updating parameters in single layer neural-network adopts sequential
extreme learning machine. Based on the neural violation probability approximate model, a random-
ized algorithm is then proposed to approach the optimizer in the probabilistic feasible domain of
decision. In the randomized algorithm, samples are extracted from decision domain uniformly at
ﬁrst. Then, violation probabilities of all samples are calculated according to neural violation prob-
ability approximate model. The ones with violation probability higher than the required level are
discarded. The minimizer in the remained feasible decision samples is used to update sampling pol-
icy. The policy converges to the optimal feasible decision. Numerical simulations are implemented
to validate the proposed method for non-convex problems comparing with scenario approach and
parallel randomized algorithm. The result shows that proposed method have improved performance.

Keywords Chance constrained program, extreme learning machine, randomized optimization.

1 Introduction

Uncertain programs are optimization problems involved uncertainties in constraints or objectives[1]. Uncertain pro-
gram involves chance constraints or probabilistic constraints is identiﬁed as chance constrained program[2]. Chance
constraints are constraints within uncertain parameters which are required to hold with speciﬁed probability levles[3].
In recent 30 years, chance constrained program has been applied from economics and management ﬁleds to various
problems, such as model predictive control[4], automotive control[5, 6] , machine learning[7], system identiﬁcation
and prediction[8].

However, chance constrained program is NP-hard due to the chance constraints. The challenge of solving chance
constrained program directly motivates the development of approximation approach to solve it. In recent 20 years,
the main stream has converged to scenario approach[9, 10] in which deterministic constraints imposed for ﬁnte sets
of independently extracted samples of uncertain parameters are used to replace the chance constraints. Scenario
approach preserves that the solution of the newly formulated deterministic program satisﬁes chance constraints with a
determined bounds of probability[9]. Afterwards, scenario approach with tight conﬁdence bounds has been developed,

 
 
 
 
 
 
A PREPRINT - NOVEMBER 13, 2019

in which a set of sampled constraints with tight conﬁdence on violation probability is determined for approximating
chance constraints. For instance, a certain proportion of parameter samples to deﬁne a set of sampled constraints
and discard the rest can be used to approximate chance constraints with tight violation probabilities for ﬁxed sample
number [11]. A repetitive scenario approach that utilizes both priori and posteriori knowledge of probabilities can
provide tighter bounds than approaches without prior information[12]. However, scenario approach still has fatal
drawbacks. It cannot ensure that the obtained solution is the optimal one in the probabilistic feasible domain. when
the sample number becomes larger, the obtained solution becomes more conservative and ﬁnally converges to the
totally robust solution which is feasible for all uncertainty realizations. Moreover, the solution depends highly on the
chosen samples of uncertain parameters, which might be guided to the wrong directions due to the bad choices of
samples.

Sample average approach has been proposed in [13] as a development of scenario approach. A sample average program
is used as approximation of the chance constrained program in which the chance constraints are replaced by a meaure
to indicates the violation probability. [14] extends sample average approach to an inner-outer approximate approach.
However, sample average approach still needs too many assumptions on the program such as convexity of the function
from decision to violation probability.

Bayesian optimization framework has been applied to optimization under unknown constraints recently[15, 17], which
is essentially a data-driven approach for approximating the optimizer of the program. Statistical approach based on
Gaussian processes and Bayesian learning to both approximate the unknown function and estimate the probability of
meeting the constraints is developed to approximate the optimizer in unknown feasible domain. While, this can only
be applied to expected constraints. Also, Gaussian process model is still not precise enough for approximating the
feasible domain described by chance constraints.

Stimulated by [13, 15], [16] proposed a parallel randomized algorithm for chance constrained program in which
randomized optimization and sample-discard method is applied to search the probabilistic feasible optimizer. As a
development of [16], this paper addresses chance constrained program with a single neural networks-based approxi-
mate framework. The map from decision domain to violation probability domain is approximately modelled by Single
Layer Feedforward Neural-networks (SLFNs). Based on the approximate violation probability map, randomized opti-
mization algorithm is used to approach the optimizer in the probabilistic feasible domain of decision. The algorithm
for updating parameters in single layer neural-network adopts sequential Extreme Learning Machine (ELM). Firstly,
samples are extracted from both decision domain and random disturbance space. According to the chosen samples,
violation probability map is updated. Then, in the second phase, the feasible decision samples are extracted uniformly
but discarded with a portion according to the violation probability map. The remained feasible decision samples are
used to calculated the corresponding objective values. These pairs are used to update sampling policy of the second
layer. The policy converges to the optimal feasible decision.

The rest of the paper is organised as follows. Section 2 gives brief background of chance constrained program formerly
and then present the problem description. The preliminaries for understanding the proposed method is given in Section
3. In Section 4, sampling algorithms for violation probability map approximation and optimizer exploration is intro-
duced. The numerical simulation for validating the sampling algorithm is presented in Section 5, using a non-convex
program with chance constraints as targeted problem. Finally, Section 6 concludes the whole study.

2 Background and Problem Description

Chance constrained program can be generally expressed as:

J(u)

min
u∈U
s.t. Pr{h(u, δ) ≤ 0} ≥ 1 − α, δ ∈ ∆, α ∈ (0, 1)

(1)

where u ∈ U ⊂ Rnu is the decision variable, the decision variable domain U is supposed to be bounded, δ ∈
∆ ⊂ Rnδ is an uncertain parameter vector, the set ∆ is the sample space of δ on which a probability measure Pr
is deﬁned, α is a given probability level for violation of chance constraints. Moreover, J(u) : U × ∆ → R and
∀δ ∈ ∆, h(u, δ) : U × ∆ → R are continuous and differentiable in u. Chance constraints appearing in Eq. (1)
emerge in various applications and can be regarded as a compromise of hard constraints which require to be satisﬁed
for all values δ ∈ ∆. Exploring optimizer under hard constraints could be too costly and even impossible.
The feasible decision domain can be denoted as Uf . However, it is difﬁcult to obtain the exact expression of Uf . Fig.
1 gives illustration on the formulation of probabilistic feasible domain in a 2-dimension space. Denoting ∆s ⊂ ∆ and
the probability measure of ∆s satisﬁes

Pr{∆s} ≥ 1 − α.

2

(2)

A PREPRINT - NOVEMBER 13, 2019

Figure 1: Formulation of probabilistic feasible domain.

The feasible domain for δt ∈ ∆s is deﬁned as

Then, the feasible domain for ∆s is intersection of Uδt for all δt ∈ ∆s, which is written as

Uδt = {u ∈ U |h(u, δt) ≤ 0}.

Considering a family of ∆s denoted as

U∆s =

Uδt .

\δt∈∆s

F = {∆s ⊂ ∆|Pr{∆s} ≥ 1 − α},

the feasible decision domain for Eq. (1) can be deﬁned as:

Uf =

U∆s =

Uδt .

[∆s∈F

[∆s∈F \δt∈∆s

(3)

(4)

(5)

(6)

Obviously, even if Uδt is known, it is impossible to obtain explicit expression or domain of Uf due to inﬁnite times’
operation of intersection and union. Thus, program (1) is NP hard due to the chance constraint. To address program
(1), the following issues should be considered:

• How to approximate chance constraints, namely approximate the probabilistic feasible domain of decision

variable;

• How to approximate the optimizer in the probabilistic feasible domain.

3 Preliminaries

In this section, the preliminaries for understanding the proposed method is introduced. Firstly, a brief introduction on
ELM algorithm is presented. Then, randomized optimization is introduced.

3.1 Extreme Learning Machine

ELM is essentially an algorithm to train the parameters in SLFNs. SLFNs is with a number of hidden nodes and
with almost any nonlinear activation function, as an approximation of standard multilayer feedforward neural net-
works. For N arbitrary distinct samples (xi, yi), where xi = [xi,1, ..., xi,m]T ∈ Rn denotes the plant input and
yi = [yi,1, ..., yi,m]T ∈ Rm the plant output, standard SLFNs with ¯N hidden nodes and activation function g(x)
models the input-to-output relationship as

ˆti =

¯N

Xj=1

βjgj(xi) =

¯N

Xj=1

βjg(ωT

j xi + bj),

(7)

where i = 1, ..., N is the sample index, ωj = [ωj,1, ..., ωj,n]T represent the weight vector connecting the j-th hidden
node and the input nodes, βj = [βj,1, ..., βj,m]T denotes the weight vector connecting the j-th hidden node and the

3

A PREPRINT - NOVEMBER 13, 2019

output nodes, and bj is the threshold of the j-th hidden node. ωT
nodes are linear in this SLFNs.
The standard SLFNs with ¯N hidden nodes with activation function g(x) is able to approximate these N samples with
zero error means express as

j xi denotes the inner product of ωj and xi. The output

i.e., according to the result in [18], there exit ¯N ≤ N, βj, ωj and bj such that

N

Xi=1

N

keik =

ti − ˆti

= 0,

Xi=1 (cid:13)
(cid:13)

(cid:13)
(cid:13)

where j = 1, ..., N is sample index. More generally, by deﬁning

ti =

¯N

Xj=1

βjg(ωT

j xi + bj),

g(ωT

1 x1 + b1)
...
¯N xN + b1)

g(ωT

...

...
...

H = 



g(ωT

g(ωT

¯N x1 + b ¯N )
...
¯N xN + b ¯N )






and

the above N equations can be written compactly as

βT
1
...
βT
¯N



,




β = 



tT
1
...
tT
¯N

T = 





,




T = Hβ.

,

(8)

(9)

(10)

(11)

(12)

(13)

As introduced in [19], H is called the hidden layer output matrix of the neural network; the i-th column of H is the
i-th hidden node output with respect to inputs x1, x2, ..., xN . The gradient-based algorithm can be used to train the
value of β, ω1, ..., ω ¯N , b1, ..., b ¯N [20]. Compare to the gradient-based algorithm, ELM algorithm, proposed in [21], is
more simple and efﬁcient. Regarding X = [x1, x2, ..., xN ] as input, and T as output, the Batch ELM algorithm for
training the SLFNs models can be summarized as in algorithm 1:

Algorithm 1 Batch ELM for training the SLFNs models
Input: X, T, ¯N
Output: β, ωj, bj, j = 1, 2, ..., ¯N
1: Step 1: Randomly assign ωj and bj, j = 1, ..., ¯N
2: Step 2: Calculate the hidden layer output matrix H
3: Step 3: Calculate the β as β = H M T .

In algorithm 1, H M is the Moore-Penrose generalized inverse of matrix H [22], which can be derived by

Then, the estimation of β can be calculated as

H M = (H T H)−1H T .

β = (H T H)−1H T T.

(14)

(15)

The basis of algorithm 1 is the results presented in [20], if the activation function g is inﬁnitely differentiable the
hidden layer output matrix H is invertibel and kHβ − T k = 0. The sequential implementation of Eq. (15) can be
derived and referred as the recursive least squares (RLS) algorithm. The proof of the RLS algorithm can be found in
[23]. The sequential ELM for training the SLFNs models is derived based on RLS algorithm and summarized as in
algorithm 2:

4

A PREPRINT - NOVEMBER 13, 2019

Algorithm 2 Sequential ELM for training the SLFNs models
1: Step 1: Give β0 according to algorithm 1
2: Step 2: Calculate the hidden layer output matrix hk+1 based on further coming observation (xk+1, tk+1) according
to Eq.(10), k = 0, 1, 2, ..., i, ...
3: Step 3: Calculate the βk+1 as

βk+1 = βk + Mk+1hk+1(tT

k+1 − hT

k+1βk)

where Mk+1 is calculated as

4: Step 4: Set k = k + 1

Mk+1 = Mk −

Mkhk+1hT
1 + hT

k+1Mk
k+1Mkhk+1

.

(16)

(17)

3.2 Randomized Optimization Algorithm

Randomized optimization algorithm is numerical optimization algorithm which is free from the gradient of the ob-
jective function[24]. It can therefore be used for problems with objective functions that are not continuous or dif-
ferentiable. Furthermore, even if the problem is under non-convex constraints, randomized optimization algorithm
still ensures the convergence to the optimizer [25]. In random optimization, sample of decision is extracted from the
feasible domain, the start point can be randomly chosen. Then, the next sample is extracted near the current position
according to normal distribution or uniform distribution. The optimizer will be replaced if better sample which has
lower cost or better reward is extracted. It is ensured that the sample moves to better positions iteratively and stops at
global optimizer[26].
Let F : V ⊂ Rn → R be the cost function to be minimized in the feasible domain V . Let v ∈ V denote a position
or candidate optimizer in the feasible domain. The basic randomized optimization algorithm is denoted as algorithm
3 and expressed as following[27]:

Algorithm 3 Typical randomized optimization algorithm
1: Step 1: Initialize v ∈ V randomly
2: Step 2: Extract new sample v′ ∈ Vv obeying uniform distribution or normal distribution. Here, Vv is a neighbour
of v, for instance, as Vv = {vf ∈ V | kvf − vk2 < ǫv}
3: Step 3: If F (v′) < F (v), set v = v′
4: Step 4: Examine whether the termination criterion is met(e.g. number of iterations), if termination criterion is met,
go to Step 5, otherwise, go to Step 2 and repeat
5: Step 5: Set v as optimizer

4 Proposed Method

This section discusses the two-phase optimizer exploration approach for chance constrained program. Firstly, the
structure of the proposed method is presented. Then, approximate algorithm for violate probability is introduced.
Finally, the exploration algorithm is introduced in details.

4.1 Overview

Randomized optimization can be used to solve program (1). The ﬂow diagram of randomized optimization applied
for chance constrained program is illustrated in Fig. 2. Firstly, decision samples are randomly extracted from U
which might not satisfy the chance constraints. Thus, in the next step, violation probability of extracted samples are
veriﬁed and the unqualiﬁed samples are discarded. The optimizer are chosen from the qualiﬁed samples. The process
is repeated until termination criterion is satisﬁed and optimizer is outputted ﬁnally. The ﬁrst key of the optimization
algorithm is to have a map from decision to violation probability. The ELM-based approximate approach for violation
probability is proposed in this study and introduced in the next part. The details of optimizer exploration algorithm is
also presented in the later part of this section.

5

A PREPRINT - NOVEMBER 13, 2019

Sampling from 
decision domain

Violation probability 
verification

Discarding unqualified 
samples

Choosing optimizer from 
qualified samples

No

Termination 
Criterion

Yes

Output optimizer

Figure 2: Flow diagram of randomized optimization for chance constrained program.

Figure 3: Brief structure of approximate algorithm.

6

A PREPRINT - NOVEMBER 13, 2019

Figure 4: Brief structure of optimizer exploring algorithm.

4.2 Violation Probability Map Approximation

Violation probability of decision u is denoted as

V (u) = Pr{h(u, δ) > 0}, δ ∈ ∆.
Obviously, V (u) is a function of u since the ﬁxed u have only one violation probability value when probability measure
of ∆ is identical. Then, if V (u) is continuous, it can be approximated by SLFNs model.

(18)

For given decision u and disturbance δ, a boolean function can be denoted as

B(uc, δ) =

1, if h(u, δ) > 0
0, if h(u, δ) ≤ 0

(cid:26)

(19)

If Ns samples, {δ1, ..., δNs}, are extracted from ∆ independently, the estimate violation probability can be written as
Ns
i=1 B(u, δi)
Ns

ˆV (u) =

P

(20)

.

According to law of larger numbers, as Ns → ∞, ˆV (u) converges to V (u) with probability one[28].
For Nu samples in decision domain, denoted as u1, ..., uNu ∈ U , can be regarded as input of a SLFNs model.
The corresponding violation probability values, V (u1), ..., V (uNu) can be regarded as output of the SLFNs model.
Although the real values of violation probability are not known, it can be iteratively approximated by Eq. (19). Thus,
for every decision sample ui, i ∈ {1, ..., Nu}, it has an boolean output B(ui, δk), k ∈ {1, ..., Nδ} for determined
disturbance sample which can also be used as the output when updating the violation probability map. The approximate
algorithm is summarized in Algorithm 4, which is essentially a two-layer sample algorithm. Also, brief structure of
approximate algorithm is illustrated in Fig. 3. If Nu, Nδ → ∞, the algorithm converges to the violation probability
map.

Algorithm 4 Algorithm for approximating violation probability map
1: Step 1: Initialize parameters, β, ωj, bj, j = 1, ..., ˆN randomly
2: Step 2: Extract decision samples u1, ...uNu ∈ U obeying uniform distribution, the decision samples are ﬁxed from
the following steps
3: Step 3: Extract sample δk+1 ∈ ∆ obeying the distribution deﬁned by probability measure Pr{·}
4: Step 4: Calculate B(ui, δk+1), ∀i ∈ {1, ..., Nu} according to Eq. (19)
5: Step 5: Regard ui, B(ui, δk+1) as xk+1, tk+1 in algorithm 2, then, update β for violation probability map according
to algorithm 2 for all i ∈ {1, ..., Nu}
6: Step 6: Set k = k + 1

4.3 Optimizer Exploration Algorithm

The proposed optimizer exploration algorithm ﬁrstly extracts n samples, {u1, ..., un} ∈ U , from the decision domain.
However, not all the samples satisfy the chance constraints. Based on the trained violation probability model, V (ui) =

7

A PREPRINT - NOVEMBER 13, 2019

Figure 5: Approximation of violation probability map.

P r{h(ui, δ) > 0}, ∀i ∈ {1, ..., n} can be calculated and the ones with violation probability larger than α − αǫ are
discarded. αǫ ∈ (0, α) is chosen for technical consideration since the violation probability map may have errors due to
that Nδ, Nu cannot be ∞. Thus, more conservative boundary than the required one should be chosen. The remained
feasible samples are used to calculate the corresponding cost function values. The one with minimal cost value is
chosen to be the optimizer. The above steps are repeated until termination criterion is met, for instance, number of
iterations. The algorithm is summarized in Algorithm 5 and brieﬂy illustrated in Fig. 4.

f ∈ U randomly

Algorithm 5 Algorithm for exploring the feasible optimizer
1: Step 1: Initialize optimizer u∗
2: Step 2: Extract {u1, ..., un} ∈ U randomly
3: Step 3: Calculate P r{h(ui, δ) > 0}, ∀i ∈ {1, ..., n}, discard all ui that V (ui) = P r{h(ui, δ) > 0} > α, and the
remained solution set is Uf
4: Step 4: If Uf = ∅, return to Step 1, else if Uf 6= ∅, go to Step 5
5: Step 5: Set optimizer as u∗ = argmin
u∈Uf

f ); Return to Step 2 directly if J(u∗) ≥ J(u∗
6: Step 6: Replace optimizer u∗
f )
7: Step 7: Examine whether the termination criterion is met (e.g. number of iterations), if termination criterion is met,
go to Step 8, otherwise, go to Step 2 and repeat
8: Step 8: Set u∗
f as optimizer.

f = u∗ and go to Step 7 if J(u∗) < J(u∗

J(u)

5 Numerical Validation

This section presents numerical simulation for verifying the proposed method, comparing with scenario approach
and parallel randomized algorithm. The targeted problem is brieﬂy introduced ﬁrstly. Also, the basic concepts of
scenario approach and parallel randomized algorithm are introduced shortly which is enough for helping understand
the comparison result. Furthermore, the results of both probabilistic feasible domain approximation and optimizer
exploration are presented.

8

A PREPRINT - NOVEMBER 13, 2019

Figure 6: Boundaries of 5% violation with different δ-sample numbers.

5.1 Targeted Problem

The targeted problem in the numerical simulation is a non-convex program with chance constraints. The decision
domain is U = [−6, 5]2. The cost function is

The constrained function is

2
i=1(ui + 0.5)4 − 30u2

i − 20ui

100

.

J(u) =

P

2

h(u, δ) = (

0.075 ∗ (ui − 2δ)4 − 3.5 ∗ (ui − 2δ)2) − (8 − 0.1δ)2,

Xi=1

(21)

(22)

where δ is random variable which obeys normal distribution N (0, 1). Moreover, the violation probability level is
α = 0.05. The proposed method is applied to solve the targeted problem, comparing with scenario approach presented
in [11] and parallel algorithm proposed in [16].

In scenario approach, independent samples δ(i), i = 1, ..., N is identically extracted from ∆ randomly, a deterministic
convex optimization problem can be formed as

J(u)

min
u∈U
s.t. h(u, δ(i)) ≤ 0, i = 1, ..., N
which is a standard ﬁnitely constrained optimization problem. The optimal solution ˆuN of the program Eq. (23) is
called as the scenario solution for program Eq. (1) generally. Moreover, since the extractions δ(i), i = 1, ..., N is
randomly chosen, the optimal solution ˆuN is random variable. If ˆuN is expected to satisfy
PrN {(δ(1), ..., δ(N ) ∈ ∆N : V (ˆuN ) ≤ α} ≥ 1 − β, β ∈ (0, 1),

(24)

(23)

then, N should have a lower limitation Nl

N ≥

2
α

ln

1
β

+ 2nu +

2nu
α

ln

2
α

.

(25)

Note that β is an important factor and choosing β = 0 makes Nl = ∞. Namely, if the number of chosen samples
gets larger, the probability of satisfying the original chance constraints approaches 1. Actually, when chosen samples
becomes inﬁnity and cover the whole sample space, not only the chance constraints, it becomes totally robust.

9

A PREPRINT - NOVEMBER 13, 2019

Figure 7: Mean evolutions of the solution during computation process for proposed method (simulation of 400 times).

Parallel randomized algorithm is under the same framework of the proposed method. Differently, the discard process
of parallel randomized algorithm also adopts sampling approach. Parallel randomized algorithm is summarized in
algorithm 6.

f ∈ U randomly

Algorithm 6 Paralle randomized algorithm
1: Step 1: Initialize optimizer u∗
2: Step 1: Extract {u1, , ..., ui, ..., uNu} ∈ U
3: Step 2: Extract {δ1, ..., δNδ } ∈ ∆ randomly
4: Step 3: Calculate approximately V (ui), ∀i ∈ {1, ..., Nu} according to Eq.
V (ud) > α, and the remained solution set is Uf
5: Step 5: If Uf = ∅, return to Step 1, else if Uf 6= ∅, go to Step 6
6: Step 6: Set optimizer as u∗ = argmin
u∈Uf

J(u)

(19) and (20), discard all ud that

f ); Return to Step 2 directly if J(u∗) ≥ J(u∗
7: Step 7: Replace optimizer u∗
f )
8: Step 8: Examine whether the termination criterion is met (e.g. number of iterations), if termination criterion is met,
go to Step 9, otherwise, go to Step 1 and repeat
9: Step 9: Set u∗ as optimizer.

f = u∗ and go to Step 8 if J(u∗) < J(u∗

5.2 Probabilistic Feasible Domain

Firstly, the results of probabilistic feasible domain estimation by proposed method is presented. The violation prob-
ability maps, comparison between real one and approximations, are shown in Fig. 5. Actually, the real one is also
the approximate one. 3136 points, (u1,i, u1,i) are chosen from [−6, 5]2. For every point, 10000 samples of δ are
extracted according to N (0, 1) for calculating the corresponding violation probability. Fig. 5(a) shows the results.
Fig. 5 (b-d) shows the results of approximation maps based on Algorithm 4 with N (δ) = 200, N (δ) = 1000 and
N (δ) = 2000 where N (δ) denotes the sample numbers. Since the boundary of 5% violation probability is concerned,
the comparisons of boundaries are plotted in Fig. 6. Obviously, Algorithm 4 converges to the real boundary when
N (δ) ≥ 1000.

5.3 Optimizer Exploration

The results of optimizer exploration are presented here.
In this numerical simulation, proposed method, parallel
randomized algorithm and scenario approach are used to solve the targeted problem. The numerical simulation adopts

10

A PREPRINT - NOVEMBER 13, 2019

Figure 8: Solution distribution (Nδ = 2000,simulation of 400 times).

Figure 9: Results of the cost values and violation probabilities (mean values of simulation of 400 times).

11

A PREPRINT - NOVEMBER 13, 2019

Monte Carlo methodology, namely, the procedure of exploring the optimizers is repeated for a large number of times
and the samples of u and δ are extracted obeying the identical distribution in every simulation time. 400 times of
simulation were done in this validation. Moreover, αǫ is chosen as 0.005 here.

In Fig. 7, mean evolutions of the solution during computation process for proposed method are plotted, for both
cases N (δ) = 1000 and N (δ) = 2000. In every simulation, the solutions converge to the small intervals for both
u1 and u2. The ﬁnal converged values of decision are plotted in Fig. 8. Blue points are solutions from proposed
method using 2000 disturbance samples, magenta squares are solutions from parallel randomized algorithm using
2000 disturbance samples and red circles present the solutions from scenario approach using 2000 disturbance samples.
Apparently, proposed method can converges to the 5% boundary where the cost is minimal in the probabilistic domain.
Parallel randomized algorithm exhibits worse performance than proposed method while roughly near the boundary
with randomness. However, for scenario approach, the solution cannot converge to the boundary. In every simulation,
the sampled δ are different, the constraints of problem expressed by Eq. (23) are different, the solution are therefore
different and distributed in a larger area.

Furthermore, Fig. 9 shows the plotted mean results of cost values and violation probabilities in all simulations. From
these results, obviously, the proposed method achieves the trade-off between violation probability and optimization
in a more stable way because SLFN-based violation probability map is accurate. While, scenario approach achieves
the chance constraints but get poor performance on cost value since it is too conservative. Parallel randomized algo-
rithm achieves good performance on cost value but has poor performance on satisfying violation probability since its
estimation on violation probability has variance and have poor accuracy than the SLFN-based map.

6 Conclusion

This paper has introduced a neural network-based approximate approach to chance constrained optimization. The
novel idea is to approximate the feasible domain constrained by chance constraints by SLFNs. The parameters of
SLFNs can be obtained by ELM algorithm with historical data. Then, a two-layer randomized optimization algorithm
is proposed to approximate the optimizer of chance constrained program based on the trained probabilistic feasible
domain map. The proposed method is validated by numerical simulation compared with scenario approach and parallel
randomized algorithm. The proposed method exhibits better robustness on both exploring optimizer and satisfying
violation probability. while, there still remains future works to be done for improving the proposed method. The
current randomized optimization algorithm is totally a random one which can be improved to converge to the optimizer
in less iterations. Moreover, the accuracy of probability map is related to the sample number of random disturbance.
The quantitative analysis should be implemented to investigate the relationship between accuracy and sample number.
Especially, the principle of choosing parameter αǫ should be investigated in theory.

References

[1] A. Ben-Tal, and A. Nemirovski “Robust solutions of uncertain linear programs,” Operations Research Letters, vol.

25, no. 1, pp. 1-13, Aug. 1999.

[2] A. Prekopa, “On probabilistic constrained programming,” in Proceedings of the Princeton Symposium on Mathe-

matical Programming, Princeton University Press, Princeton, NJ, pp. 113-138, 1970.

[3] A. Charnes, and W. W. Cooper, “Chance constrained programming,” Management Science, vol. 6, no. 1, pp. 73-79,

Oct. 1959.

[4] G. Schildbach, L. Fagiano, C. Frei, and M. Morari, “The scenario approach for stochastic model predictive con-
trol with bounds on closed-loop constraint violations,” Automatica, vol. 50, no. 12, pp. 3009-3018, Dec. 2014,
doi.org/10.1016/j.automatica.2014.10.035.

[5] D. Moser, R. Schmied, H. Waschl, and L. del Re, “Flexible Spacing Adaptive Cruise Control Using Stochastic
Model Predictive Control,” IEEE Trans. Control Systems Technology, vol. 26, no. 1, pp. 274-281, Jan. 2018,
10.1109/TCST.2017.2658193.

[6] X. Shen, and T. Shen, “Chance-Constrained Optimization for Torque Tracking Control with Improving Fuel Econ-
omy in Spark-Ignition Engines,” SICE Journal of Control, Measurement, and System Integration, vol. 11, no. 4,
pp. 365-371, July 2018, doi.org/10.9746/jcmsi.11.365.

[7] M. C. Campi, "Classiﬁcation with guaranteed probability of error," Machine Learning, vol. 80, no. 1, pp. 63-84,

July 2010, 10.1007/s10994-010-5183-x.

[8] M. C. Campi, and S. Garatti, Introduction to the scenario approach, MOS-SIAM Series on Optimization, Philadel-

phia, 2019, pp. 1-20.

12

A PREPRINT - NOVEMBER 13, 2019

[9] G. Calariore, and M. C. Campi, “The scenario approach torobust control design,” IEEE Trans. Automatic Control,

vol. 51, no. 5, pp. 742-753, May 2006, 10.1109/TAC.2006.875041.

[10] J. Luedtke, and S. Ahmed, “A Sample Approximation Approach for Optimization with Probabilistic Constraints,”

SIAM Journal on Optimization, vol. 19, no. 2, pp. 674-699, July 2008, doi.org/10.1137/070702928.

[11] M. C. Campi, and S. Garatti, “A sampling-and-discarding approach to chance-constrained optimization: feasibil-
ity and optimality,” Journal of Optimization Theory and Applications , vol. 148, no. 2, pp. 257–280, Feb. 2011,
10.1007/s10957-010-9754-6.

[12] M. Cannon, “Chance-constrained optimization with tight conﬁdence bounds,” arXiv:1711.03747 [math.OC],

May 2018, arXiv:1711.03747.

[13] B. K. Pagnoncelli, S. Ahamed, and A. Shapiro, “Sample average approximation method for chance constrained
programming: theory and applications,” Journal of Optimal Theory and Application, vol. 142, pp. 399-416, 2009,
10.1007/s10957-009-9523-6.

[14] A. Geletu, A. Hoffmann, M. Kloppel and P. Li, “An inner-outer approximation approach to chance constrained

optimization,” SIAM J. Optim., vol. 27, no. 3, pp. 1834-1857, 2017, 10.1137/15M1049750.

[15] R. B. Gramacy, and H. K. H. Lee, “Optimization Under Unknown Constraints,” arXiv:1004.4027 [stat.ME], Jul.

2010, arXiv:1004.4027.

[16] X. Shen, J. Zhuang and X. Zhang, “Parallel Randomized Algorithm for Chance Constrained Program,”

arXiv:1911.00192v1 [math.OC], Nov. 2019, arXiv:1911.00192v1.

[17] V. Picheny, R. B. Gramacy, S. M. Wild, and S. Le Digabel, “Bayesian optimization under mixed constraints with

a slack-variable augmented Lagrangian,” arXiv:1605.09466 [stat.CO], May 2016, arXiv:1605.09466.

[18] G. B. Huang, “Learning capability and storage capacity of two-hidden-layer feedforward networks,” IEEE Trans.

Neural Networks, vol. 14, no. 2, pp. 274-281, Mar. 2003, 10.1109/TNN.2003.809401.

[19] G. B. Huang, and H. A. Babri, “Upper bounds on the number of hidden neurons in feedforward networks with
arbitrary bounded nonlinear activation functions,” IEEE Trans. Neural Networks, vol. 9, no. 1, pp. 224-229, Jan.
1998, 10.1109/72.655045.

[20] S. Tamura, and M. Tateishi, “Capabilities of a four-layered feedforward neural network: four layers versus three,”

IEEE Trans. Neural Networks, vol. 8, no. 2, pp. 251-255, Mar. 1997, 10.1109/72.557662.

[21] G. B. Huang, Q.Y. Zhu, and C. K. Siew “Extreme learning machine: theory and applications,” Neurocomputing,

vol. 70, pp. 489-501, Dec. 2006, doi.org/10.1016/j.neucom.2005.12.126.

[22] C. R. Rao, and S. K. Mitra, Generalized inverse of matrices and its application, Wiley, New York, 1972.
[23] E. K. P. Chong, and S. H. Zak, An introduction to optimization, New York: John Wiley, 2001, pp. 227-231.
[24] J. Matyas, “Random Optimization,” Automation and Remote Control, vol. 26, no. 2, pp. 246-253, 1965.
[25] N. Baba, “Convergence of a random optimization method for constrained optimization problems,” Journal of

Optimization Theory and Applications, vol. 33, no. 4, pp. 451-461, April 1981, 10.1007/bf00935752.

[26] C. C. Y. Dorea, “Expected number of steps of a random optimization method,” Journal of Optimization Theory

and Applications, vol. 39, no. 2, pp. 165-171, Feb. 1983, 10.1007/bf00934526.

[27] F. J. Solis, and R. J. B. Wets, “Minimization by Random Search Techniques,” Mathematics of operations research,

vol. 6, no. 1, pp. 19-30, Feb. 1981, 10.1287/moor.6.1.19.

[28] W. Feller, An introduction to probability theory and its applications, John Wiley and Sons, Inc., Jan. 1968, pp.

243-263.

13

