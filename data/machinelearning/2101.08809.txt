1
2
0
2

n
a
J

1
2

]

G
L
.
s
c
[

1
v
9
0
8
8
0
.
1
0
1
2
:
v
i
X
r
a

PyGlove: Symbolic Programming
for Automated Machine Learning

Daiyi Peng, Xuanyi Dong, Esteban Real, Mingxing Tan, Yifeng Lu
Hanxiao Liu, Gabriel Bender, Adam Kraft, Chen Liang, Quoc V. Le
Google Research, Brain Team
{daiyip, ereal, tanmingxing, yifenglu,
hanxiaol, gbender, adamkraft, crazydonkey, qvl}@google.com
xuanyi.dxy@gmail.com ∗

Abstract

Neural networks are sensitive to hyper-parameter and architecture choices. Auto-
mated Machine Learning (AutoML) is a promising paradigm for automating these
choices. Current ML software libraries, however, are quite limited in handling the
dynamic interactions among the components of AutoML. For example, efﬁcient
NAS algorithms, such as ENAS [1] and DARTS [2], typically require an imple-
mentation coupling between the search space and search algorithm, the two key
components in AutoML. Furthermore, implementing a complex search ﬂow, such
as searching architectures within a loop of searching hardware conﬁgurations, is
difﬁcult. To summarize, changing the search space, search algorithm, or search ﬂow
in current ML libraries usually requires a signiﬁcant change in the program logic.
In this paper, we introduce a new way of programming AutoML based on symbolic
programming. Under this paradigm, ML programs are mutable, thus can be
manipulated easily by another program. As a result, AutoML can be reformulated
as an automated process of symbolic manipulation. With this formulation, we
decouple the triangle of the search algorithm, the search space and the child
program. This decoupling makes it easy to change the search space and search
algorithm (without and with weight sharing), as well as to add search capabilities
to existing code and implement complex search ﬂows. We then introduce PyGlove,
a new Python library that implements this paradigm. Through case studies on
ImageNet and NAS-Bench-101, we show that with PyGlove users can easily
convert a static program into a search space, quickly iterate on the search spaces
and search algorithms, and craft complex search ﬂows to achieve better results.

1

Introduction

Neural networks are sensitive to architecture and hyper-parameter choices [3, 4]. For example,
on the ImageNet dataset [5], we have observed a large increase in accuracy thanks to changes in
architectures, hyper-parameters, and training algorithms, from the seminal work of AlexNet [5]
to recent state-of-the-art models such as EfﬁcientNet [6]. However, as neural networks become
increasingly complex, the potential number of architecture and hyper-parameter choices becomes
numerous. Hand-crafting neural network architectures and selecting the right hyper-parameters is,
therefore, increasingly difﬁcult and often take months of experimentation.

Automated Machine Learning (AutoML) is a promising paradigm for tackling this difﬁculty. In
AutoML, selecting architectures and hyper-parameters is formulated as a search problem, where a
search space is deﬁned to represent all possible choices and a search algorithm is used to ﬁnd the

∗Work done as a research intern at Google.

34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.

 
 
 
 
 
 
best choices. For hyper-parameter search, the search space would specify the range of values to try.
For architecture search, the search space would specify the architectural conﬁgurations to try. The
search space plays a critical role in the success of neural architecture search (NAS) [7, 8], and can be
signiﬁcantly different from one application to another [8–11]. In addition, there are also many different
search algorithms, such as random search [12], Bayesian optimization [13], RL-based methods [1,
9, 14, 15], evolutionary methods [16], gradient-based methods [2, 10, 17] and neural predictors [18].

This proliferation of search spaces and search algorithms in AutoML makes it difﬁcult to program with
existing software libraries. In particular, a common problem of current libraries is that search spaces
and search algorithms are tightly coupled, making it hard to modify search space or search algorithm
alone. A practical scenario that arises is the need to upgrade a search algorithm while keeping the rest
of the infrastructure the same. For example, recent years have seen a transition from AutoML algo-
rithms that train each model from scratch [8, 9] to those that employ weight-sharing to attain massive
efﬁciency gains, such as ENAS and DARTS [1, 2, 14, 15, 19]. Yet, upgrading an existing search space
by introducing weight-sharing requires signiﬁcant changes to both the search algorithm and the model
building logic, as we will see in Section 2.2. Such coupling between search spaces and search algo-
rithms, and the resulting inﬂexibility, impose a heavy burden on AutoML researchers and practitioners.
We believe that the main challenge lies in the programming paradigm mismatch between existing
software libraries and AutoML. Most existing libraries are built on the premise of immutable
programs, where a ﬁxed program is used to process different data. On the contrary, AutoML requires
programs (i.e. model architectures) to be mutable, as they must be dynamically modiﬁed by another
program (i.e. the search algorithm) whose job is to explore the search space. Due to this mismatch,
predeﬁned interfaces for search spaces and search algorithms struggle to accommodate unanticipated
interactions, making it difﬁcult to try new AutoML approaches. Symbolic programming, which
originated from LISP [20], provides a potential solution to this problem, by allowing a program to
manipulate its own components as if they were plain data [21]. However, despite its long history,
symbolic programming has not yet been widely explored in the ML community.
In this paper, we reformulate AutoML as an automated process of manipulating ML programs
symbolically. Under this formulation, programs are mutable objects which can be cloned and
modiﬁed after their creation. These mutable objects can express standard machine learning concepts,
from a convolutional unit to a complex user-deﬁned training procedure. As a result, all parts of a ML
program are mutable. Moreover, through symbolic programming, programs can modify programs.
Therefore the interactions between the child program, search space, and search algorithm are no
longer static. We can mediate them or change them via meta-programs. For example, we can map
the search space into an abstract view which is understood by the search algorithm, translating an
architectural search space into a super-network that can be optimized by efﬁcient NAS algorithms.
Further, we propose PyGlove, a library that enables general symbolic programming in Python, as an
implementation of our method tested on real-world AutoML scenarios. With PyGlove, Python classes
and functions can be made mutable through brief Python annotations, which makes it much easier to
write AutoML programs. PyGlove allows AutoML techniques to be easily dropped into preexisting
ML pipelines, while also beneﬁting open-ended research which requires extreme ﬂexibility.
To summarize, our contributions are the following:

• We reformulate AutoML under the symbolic programming paradigm, greatly simplifying the
programming interface for AutoML by accommodating unanticipated interactions among
the child programs, search spaces and search algorithms via a mutable object model.

• We introduce PyGlove, a general symbolic programming library for Python which im-
plements our symbolic formulation of AutoML. With PyGlove, AutoML can be easily
dropped into preexisting ML programs, with all program parts searchable, permitting rapid
exploration on different dimensions of AutoML.

• Through case studies, we demonstrate the expressiveness of PyGlove in real-world search
spaces. We demonstrate how PyGlove allows AutoML researchers and practitioners to
change search spaces, search algorithms and search ﬂows with only a few lines of code.

2 Symbolic Programming for AutoML

Many AutoML approaches (e.g., [2, 9, 22]) can be formulated as three interacting components: the
child program, the search space, and the search algorithm. AutoML’s goal is to discover a performant
child program (e.g., a neural network architecture or a data augmentation policy) out of a large set

2

of possibilities deﬁned by the search space. The search algorithm accomplishes the said goal by
iteratively sampling child programs from the search space. Each sampled child program is then
evaluated, resulting in a numeric measure of its quality. This measure is called the reward2. The
reward is then fed back to the search algorithm to improve future sampling of child programs.

In typical AutoML libraries [23–31], these three components are usually tightly coupled. The cou-
pling between these components means that we cannot change the interactions between them unless
non-trivial modiﬁcations are made. This limits the ﬂexibility of the libraries. Some successful at-
tempts have been made to break these couplings. For example, Vizier [26] decouples the search space
and the search algorithm by using a dictionary as the search space contract between the child program
and the search algorithm, resulting in modular black-box search algorithms. Another example is the
NNI library [27], which tries to unify search algorithms with and without weight sharing by carefully
designed APIs. This paper, however, solves the coupling problem in a different and more general way:
with symbolic programming, programs are allowed to be modiﬁed by other programs. Therefore, in-
stead of solving ﬁxed couplings, we allow dynamic couplings through a mutable object model. In this
section, we will explain our method and show how this makes AutoML programming more ﬂexible.

2.1 AutoML as an Automated Symbolic Manipulation Process

AutoML can be interpreted as an automated process of searching for a child program from a search
space to maximize a reward. We decompose this process into a sequence of symbolic operations. A
(regular) child program (Figure 1-a) is symbolized into a symbolic child program (Figure 1-b), which
can be then cloned and modiﬁed. The symbolic program is further hyperiﬁed into a search space
(Figure 1-c) by replacing some of the ﬁxed parts with to-be-determined speciﬁcations. During the
search, the search space is materialized into different child programs (Figure 1-d) based on search
algorithm decisions, or can be rewritten into a super-program (Figure 1-e) to apply complex search
algorithms such as efﬁcient NAS.

Figure 1: AutoML as an automated symbolic manipulation process.

An analogy to this process is to have a robot build a house with LEGO [32] bricks to meet a human
being’s taste: symbolizing a regular program is like converting molded plastic parts into LEGO
bricks; hyperifying a symbolic program into a search space is like providing a blueprint of the house
with variations. With the help of the search algorithm, the search space is materialized into different
child programs whose rewards are fed back to the search algorithm to improve future sampling, like a
robot trying different ways to build the house and gradually learning what humans prefer.

Symbolization. A (regular) child program can be
described as a complex object, which is a composi-
tion of its sub-objects. A symbolic child program is
such a composition whose sub-objects are no longer
tied together forever, but are detachable from each
other hence can be replaced by other sub-objects.
The symbolic object can be hierarchical, forming
a symbolic tree which can be manipulated or
executed. A symbolic object is manipulated through
its hyper-parameters, which are like the studs
of a LEGO brick, interfacing connections with
other bricks. However, symbolic objects, unlike
LEGO bricks, can have internal states which are
automatically recomputed upon modiﬁcations. For

Figure 2: Symbolizing classes into mutable sym-
bolic trees. Their hyper-parameters are like the studs
of LEGO bricks, while their implementations are
less interesting while we manipulate the trees.

2While we use RL concepts to illustrate the core idea of our method, as will be shown later, the proposed

paradigm is applicable to other types of AutoML methods as well.

3

symbolizehyperifypyqzmaterialize / rewriteqpzxy(a)(b) (c)(d)(e)orqpzxyoneof@symbolizeclass Trainer(object):    def __init__(self,           optimizer, model):        …@symbolizeclass Conv(Layer):    def __init__(self, filters, kernel):        …    def call(self, input):        ...qponeof ([    p: Adam(2e-4),     q: RMSProp(floatv(1e-6, 1e-3))])Adam(2e-4)xzyoneof ([    x: Identity(),    y: Dense(8),    z: Conv(oneof([4, 8]), (3, 3))])Conv(4, (3, 3))qpxzyqpzxyTrainerOneshotTraineroneof ([    x: Identity(),    y: Dense(8),    z: Conv(        oneof([4, 8]), (3, 3))])Switch([    Identity(),    Dense(8),    MaskedConv2D(       [4, 8], (3, 3))])rewriteqfz48qpxzySearch Algorithmpz(a)(b)(c)(d)mapmaterializexyzqp4qpxzySearch Algorithm 2(a)Search Algorithm 1pz(b)(d)map with 𝜃1map with 𝜃2qpxyz413e-420[[(a)(b)@symbolizeclass Trainer(object):    def __init__(self, model, optimizer):        …@symbolizeclass Conv(Layer):    def __init__(self, filters, kernel):        …    def call(self, input):        ...example, when we change the dataset of a trainer, the train steps will be recomputed from the
number of examples in the dataset if the training is based on the number of epochs. With such a
mutable object model, we no longer need to create objects from scratch repeatedly, or modify the
producers up-stream, but can clone existing objects and modify them into new ones. The symbolic
tree representation puts an emphasis on manipulating the object deﬁnitions, while leaving the
implementation details behind. Figure 2 illustrates the symbolization process.

2.2 Disentangling AutoML through Symbolic Programming

Disentangling search spaces from child programs. The
search space can be disentangled from the child program
in that 1) the classes and functions of the child program
can be implemented without depending on any AutoML
library (Appendix B.1.1), which applies to most preexisting
ML projects whose programs were started without taking
AutoML in mind; 2) a child program can be manipulated
into a search space without modifying its implementation.
Figure 3 shows that a child program is turned into a search
space by replacing a ﬁxed Conv with a choice of Identity,
MaxPool and Conv with searchable ﬁlter size. Meanwhile,
it swaps a ﬁxed Adam optimizer with a choice between the
Adam and an RMSProp with a searchable learning rate.

Figure 3: Hyperifying a child program
into a search space by replacing ﬁxed parts
with to-be-determined speciﬁcations.

Disentangling search spaces from search algorithms.
Symbolic programming breaks the coupling between the
search space and the search algorithm by preventing the
algorithm from seeing the full search space speciﬁcation.
Instead, the algorithm only sees what it needs to see for
the purposes of searching. We refer to the algorithm’s view
of the search space as the abstract search space. The full
speciﬁcation, in contrast, will be called the concrete search
space (or just the “search space” outside this section). The
distinction between the concrete and abstract search space
is illustrated in Figure 4: the concrete search space acts as
a boilerplate for producing concrete child programs, which
holds all the program details (e.g., the ﬁxed parts). How-
ever, the abstract search space only sees the parts that need
decisions, along with their numeric ranges. Based on the
abstract search space, an abstract child program is proposed, which can be static numeric values
or variables. The static form is for obtaining a concrete child program, shown in Figure 4, while
the variable form is used for making a super-program used in efﬁcient NAS – the variables can be
either discrete for RL-based use cases or real-valued vectors for gradient-based methods. Mediated
by the abstract search space and the abstract child program, the search algorithm can be thoroughly
decoupled from the child program. Figure 5 gives a more detailed illustration of Figure 4.

Figure 4: Materializing a (concrete) child
program (d) from the search space (a) with
an abstract child program (c) proposed
from the search algorithm, which holds an
abstract search space (b) as the algorithm’s
view for the (concrete) search space.

Figure 5: The path from a (concrete) search space to a (concrete) child program. The disentanglement between
the search space and the search algorithm is achieved by (1) abstracting the search space, (2) proposing an
abstract child program, and (3) materializing the abstract child program into a concrete one.

4

@symbolizeclass Trainer(object):    def __init__(self,           optimizer, model):        …@symbolizeclass Conv(Layer):    def __init__(self, filters, kernel):        …    def call(self, input):        ...qponeof ([    p: Adam(2e-4),     q: RMSProp(floatv(1e-6, 1e-3))])Adam(2e-4)xzyoneof ([    x: Identity(),    y: MaxPool((3, 3)),    z: Conv(oneof([4, 8]), (3, 3))])Conv(4, (3, 3))qpxzyqpzxyTrainerOneshotTraineroneof ([    x: Identity(),    y: MaxPool((3, 3)),    z: Conv(        oneof([4, 8]), (3, 3))])Switch([    Identity(),    MaxPool((3, 3)),    MaskedConv2D(       [4, 8], (3, 3))])rewriteqfz48qpxzySearch Algorithmpz(a)(b)(c)(d)mapmaterializexyzqp4qpxzySearch Algorithm 2(a)Search Algorithm 1pz(b)(d)map with 𝜃1map with 𝜃2qpxyz413e-420[[(a)(b)@symbolizeclass Trainer(object):    def __init__(self, model, optimizer):        …@symbolizeclass Conv(Layer):    def __init__(self, filters, kernel):        …    def call(self, input):        ...@symbolizeclass Trainer(object):    def __init__(self,           optimizer, model):        …@symbolizeclass Conv(Layer):    def __init__(self, filters, kernel):        …    def call(self, input):        ...qponeof ([    p: Adam(2e-4),     q: RMSProp(floatv(1e-6, 1e-3))])Adam(2e-4)xzyoneof ([    x: Identity()    y: Dense(8)    z: Conv(oneof([4, 8]), (3, 3))])Conv(4, (3, 3))qpxzyqpzxyTrainerOneshotTraineroneof ([    x: Identity()    y: Dense(8)    z: Conv(        oneof([4, 8]), (3, 3)])Switch([    Identity()    Dense(8)    MaskedConv2D(       [4, 8], (3, 3))])rewriteqfz48qpxzySearch Algorithmpz(a)(b)(c)(d)mapmaterializexyzqp4qpxzySearch Algorithm 2(a)Search Algorithm 1pz(b)(d)map with 𝜃1map with 𝜃2qpxyz413e-420[[(a)(b)@symbolizeclass Trainer(object):    def __init__(self, model, optimizer):        …@symbolizeclass Conv(Layer):    def __init__(self, filters, kernel):        …    def call(self, input):        ...Trainer(   model=Stacked(op=oneof([    Identity(),    MaxPool((3, 3)),    Conv(oneof([4, 8]), (3, 3))  ]), repeats=3)),  optimizer=oneof([    Adam(2e-2),    RMSProp(floatv(1e-6, 1e-3))  ]))    xyzqpChoice ∈ {0, 1}Float ∈ [1e-6, 1e-3]  Choice ∈ {0, 1, 2} 13e-42 Choice ∈ {0, 1} 0(())[]Trainer(  model=Stacked(    op=Conv(4, (3, 3)),     repeats=3)),  optimizer=RMSProp(3e-4))Search SpaceAbstract Search SpaceAbstract Child ProgramChild ProgramDisentangling search algorithms from child programs.
While many search algorithms can be implemented by
rewriting symbolic objects, complex algorithms such as
ENAS [1], DARTS [2] and TuNAS [15] can be decom-
posed into 1) a child-program-agnostic algorithm, plus 2) a
meta-program (e.g. a Python function) which rewrites the
search space into a representation required by the search al-
gorithm. The meta-program only manipulates the symbols
which are interesting to the search algorithm and ignores
the rest. In this way, we can decouple the search algorithm
from the child program.

Figure 6: Rewriting a search space (a) into
a super-program (b) required by TuNAS.

For example, the TuNAS [15] algorithm can be decomposed into 1) an implementation of RE-
INFORCE [33] and 2) a rewrite function which transforms the architecture search space into a
super-network, and replaces the regular trainer with a trainer that samples and trains the super-
network, illustrated in Figure 6. If we want to switch the search algorithm to DARTS [2], we use a
different rewrite function that generates a super-network with soft choices, and replace the trainer
with a super-network trainer that updates the choice weights based on the gradients.

2.3 Search space partitioning and complex search ﬂows

Early work [19, 34, 35] shows that factorized search can help partition the computation for optimizing
different parts of the program. Yet, complex search ﬂows have been less explored, possibly due
in part to their implementation complexity. The effort involved in partitioning a search space and
coordinating the search algorithms is usually non-trivial. However, the symbolic tree representation
makes search space partitioning a much easier task: with a partition function, we can divide those
to-be-determined parts into different groups and optimize each group separately. As a result, each
optimization process sees only a portion of the search space – a sub-space – and they work together
to optimize the complete search space. Section 3.4 discusses common patterns of such collaboration
and how we express complex search ﬂows.

3 AutoML with PyGlove

In this section, we introduce PyGlove, a general symbolic programming library on Python, which
also implements our method for AutoML. With examples, we demonstrate how a regular program
is made symbolically programmable, then turned into search spaces, searched with different search
algorithms and ﬂows in a dozen lines of code.

Figure 7: A regular Python class made symbolically programmable via the symbolize decorator (left), whose
object is a symbolic tree (middle), in which all nodes can be symbolically operated (right). For example, we
can (i) retrieve all the Layer objects in the tree via query, (ii) clone the object and (iii) modify the copy by
swapping all Conv layers with MaxPool layers of the same kernel size using rebind.

3.1 Symbolize a Python program

Table 1: The development cost of dropping PyGlove
into existing projects on different ML frameworks. The
source code of MNIST is included in Appendix B.5.
Modiﬁed
lines of code

In PyGlove, preexisting Python programs can be
made symbolically programmable with a sym-
bolize decorator. Besides classes, functions
can be symbolized too, as discussed in Ap-
pendix B.1.2. To facilitate manipulation, Py-
Glove provides a wide range of symbolic opera-
tions. Among them, query, clone and rebind are of special importance as they are foundational to

Original
lines of code

TensorFlow MNIST [37]

PyTorch ResNet [36]

Projects

353

120

15

24

5

@symbolizeclass Trainer(object):    def __init__(self,           optimizer, model):        …@symbolizeclass Conv(Layer):    def __init__(self, filters, kernel):        …    def call(self, input):        ...qponeof ([    p: Adam(2e-4),     q: RMSProp(floatv(1e-6, 1e-3))])Adam(2e-4)xzyoneof ([    x: Identity(),    y: MaxPool((3, 3)),    z: Conv(oneof([4, 8]), (3, 3))])Conv(4, (3, 3))qpxzyqpzxyTrainerSuper-networkTraineroneof ([    x: Identity(),    y: MaxPool((3, 3)),    z: Conv(        oneof([4, 8]), (3, 3))])Switch([    Identity(),    MaxPool((3, 3)),    MaskedConv2D(       [4, 8], (3, 3))])rewriteqfz48qpxzySearch Algorithmpz(a)(b)(c)(d)mapmaterializexyzqp4qpxzySearch Algorithm 2(a)Search Algorithm 1pz(b)(d)map with 𝜃1map with 𝜃2qpxyz413e-420[[(a)(b)@symbolizeclass Trainer(object):    def __init__(self, model, optimizer):        …@symbolizeclass Conv(Layer):    def __init__(self, filters, kernel):        …    def call(self, input):        ...def swap(k, v, Conv):  if isinstance(v, Conv):    return MaxPool(v.kernel)  return vprint(trainer.query(  lambda v: isinstance(v, Layer)))trainer.clone().rebind(swap)Trainer(  model=ResNetLike(    block=Sequential(      permutate([        Conv(          filters=oneof([4, 8]),           kernel=(3, 3)),        BatchNormalization(),        ReLU()      ])),    num_blocks=intv(6, 12)),  optimizer=oneof([    Adam(2e-4),    RMSProp(floatv(1e-6, 1e-3))  ]))    @symbolizeclass Trainer(object):  def __init__(    self, model, optimizer):    ...  def train(self):    return trainer_impl(      self.optimizer,       self.model)Trainer(  model=ResNetLike(    block=Sequential([      Conv(4, (3, 3)),      BatchNormalization(),      ReLU(),    num_blocks=12),  optimizer=Adam(2e-4))    Symbolic classSymbolic tree of objectSymbolic operationsfor trainer, feedback in sample(    search_space=hyper_trainer,     algorithm=PPO(),    partition_fn=None):  reward = trainer.train()  feedback(reward)def relax_filters(k, v, parent):  if isinstance(parent, Conv):    if k == 'filters':      return oneof([v//2, v, v*2])  return vhyper_trainer = trainer.clone()  .rebind(relax_filters)@symbolizeclass Block(object):  def __init__(self, filters):    self.filters = filters  def __call__(self):    return Sequential([      Conv(self.filters, (3, 3)),       Conv(self.filters*2), (3, 3))])other symbolic operations. Examples of these operations can be found in Appendix B.2. Figure 7
shows (1) a symbolic Python class, (2) an instance of the class as a symbolic tree, and (3) key
symbolic operations which are applicable to a symbolic object. To convey the amount of work
required to drop PyGlove into real-life projects, we show the number of lines of code in making a
PyTorch [36] and a TensorFlow [37] projects searchable in Table 1.

3.2 From a symbolic program to a search space

With a child program being a symbolic tree, any node in the
tree can be replaced with a to-be-determined speciﬁcation,
which we call hyper value (in correspondence to hyperify,
a verb introduced in Section 2.1 in making search spaces).
A search space is naturally represented as a symbolic tree
with hyper values. In PyGlove, there are three classes of
hyper values: 1) a continuous value declared by floatv;
2) a discrete value declared by intv; and 3) a categorical
value declared by oneof, manyof or permutate. Table 2
summarizes different hyper value classes with their semantics.
Figure 8 shows a search space that jointly optimizes a model
and an optimizer. The model space is a number of blocks
whose structure is a sequence of permutation from [Conv,
BatchNormalization, ReLU] with searchable ﬁlter size.

Dependent hyper-parameters can be achieved by using higher-
order symbolic objects. For example, if we want to search
for the ﬁlters of a Conv, which follows another Conv whose
ﬁlters are twice the input ﬁlters, we can create a symbolic
Block class, which takes only one ﬁlter size – the output
ﬁlters of the ﬁrst Conv – as its hyper-parameters. When it’s
called, it returns a sequence of 2 Conv units based on its
ﬁlters, as shown in Figure 9. The ﬁlters of the block can be
a hyper value at construction time, appearing as a node in the
symbolic tree, but will be materialized when it’s called.

3.3 Search algorithms

Figure 8: The child program from Fig-
ure 7-2 is turned into a search space.

Figure 9: Expressing dependent hyper-
parameters by introducing a higher-order
symbolic Block class.

Without interacting with the child program and the search space directly, the search algorithm in
PyGlove repeatedly 1) proposes an abstract child program based on the abstract search space and
2) receives measured qualities for the abstract child program to improve future proposals. PyGlove
implements many search algorithms, including Random Search, PPO and Regularized Evolution.

Table 2: Hyper value classes and their semantics.

Strategy

Hyper-parameter annotation

Continuous

floatv(min, max)

Discrete

intv(min, max)

Categorical

oneof(candidates)

manyof(K, candidates, θ)

permutate(candidates)

Search space semantics
A ﬂoat value from R[min,max]

An int value from Z[min,max]

Choose 1 out of N candidates
Choose K out of N candidates
with optional constraints θ on the
uniqueness and order of chosen candidates
A special case of manyof which
searches for a permutation of all candidates

Hierarchical

(when a categorical hyper value
contains child hyper values)

Conditional search space

3.4 Expressing search ﬂows

With a search space, a search algorithm, and an optional search space partition function, a search ﬂow
can be expressed as a for-loop, illustrated in Figure 10-left. Search space partitioning enables various
ways in optimizing the divided sub-spaces, resulting in three basic search types: 1) optimize the sub-

6

def swap(k, v, Conv):  if isinstance(v, Conv):    return Dense(v.filters)  return vprint(trainer.query(  lambda v: isinstance(v, Layer)))trainer.clone().rebind(swap)Trainer(  model=ResNetLike(    block=Sequential(      permutate([        Conv(          filters=oneof([4, 8]),           kernel=(3, 3)),        BatchNormalization(),        ReLU()      ])),    num_blocks=intv(6, 12)),  optimizer=oneof([    Adam(2e-4),    RMSProp(floatv(1e-6, 1e-3))  ]))    @symbolizeclass Trainer(object):  def __init__(    self, model, optimizer):    ...  def train(self):    return trainer_impl(      self.optimizer,       self.model)Trainer(  model=ResNetLike(    block=Sequential([      Identity(),      Dense(8),      Conv(4,(3, 3))]),    num_blocks=12),  optimizer=Adam(2e-4))    Symbolic classSymbolic tree of objectSymbolic operationsfor trainer, feedback in sample(    search_space=hyper_trainer,     algorithm=PPO(),    partition_fn=None):  reward = trainer.train()  feedback(reward)def relax_filters(k, v, parent):  if isinstance(parent, Conv):    if k == 'filters':      return oneof([v//2, v, v*2])  return vhyper_trainer = trainer.clone()  .rebind(relax_filters)@symbolizeclass Block(object):  def __init__(self, filters):    self.filters = filters  def __call__(self):    return Sequential([      Conv(self.filters, (3, 3)),       Conv(self.filters*2), (3, 3)])def swap(k, v, Conv):  if isinstance(v, Conv):    return MaxPool(v.kernel)  return vprint(trainer.query(  lambda v: isinstance(v, Layer)))trainer.clone().rebind(swap)Trainer(  model=ResNetLike(    block=Sequential(      permutate([        Conv(          filters=oneof([4, 8]),           kernel=(3, 3)),        BatchNormalization(),        ReLU()      ])),    num_blocks=intv(6, 12)),  optimizer=oneof([    Adam(2e-4),    RMSProp(floatv(1e-6, 1e-3))  ]))    @symbolizeclass Trainer(object):  def __init__(    self, model, optimizer):    ...  def train(self):    return trainer_impl(      self.optimizer,       self.model)Trainer(  model=ResNetLike(    block=Sequential([      Conv(4, (3, 3)),      BatchNormalization(),      ReLU(),    num_blocks=12),  optimizer=Adam(2e-4))    Symbolic classSymbolic tree of objectSymbolic operationsfor trainer, feedback in sample(    search_space=hyper_trainer,     algorithm=PPO(),    partition_fn=None):  reward = trainer.train()  feedback(reward)def relax_filters(k, v, parent):  if isinstance(parent, Conv):    if k == 'filters':      return oneof([v//2, v, v*2])  return vhyper_trainer = trainer.clone()  .rebind(relax_filters)@symbolizeclass Block(object):  def __init__(self, filters):    self.filters = filters  def __call__(self):    return Sequential([      Conv(self.filters, (3, 3)),       Conv(self.filters*2, (3, 3))])Search type

Joint

Separate

for-loop pattern
for(x, fx) : ...

for(x1, fx1) : ...
for(x2, fx2) : ...

Factorized

for(x1, fx1) :

for(x2, fx2) : ...

Figure 10: PyGlove expresses search as a for-loop (left). Complex search ﬂows can be expressed as
compositions of for-loops (right).

spaces jointly; 2) optimize the sub-spaces separately; or 3) factorize the optimization. Figure 10-right
maps the three search types into different compositions of for-loop.

Let’s take the search space deﬁned in Figure 8 as an example, which has a hyper-parameter sub-
space (the hyper optimizer) and an architectural sub-space (the hyper model). Towards the two
sub-spaces, we can 1) jointly optimize them without specifying a partition function, as is shown in
Figure 10-left; 2) separately optimize them, by searching the hyper optimizer ﬁrst with a ﬁxed
model, then use the best optimizer found to optimize the hyper model; or 3) factorize the optimization,
by searching the hyper optimizer with a partition function in the outer loop. Each example in the
loop is a trainer with a ﬁxed optimizer and a hyper model; the latter will be optimized in the inner
loop. The combination of these basic patterns can express very complex search ﬂows, which will be
further studied through our NAS-Bench-101 experiments discussed in Section 4.3.

3.5 Switching between search spaces

Making changes to the search space is a daily routine for Au-
toML practitioners, who may move from one search space to
another, or to combine orthogonal search spaces into more
complex ones. For example, we may start by searching for
different operations at each layer, then try the idea of search-
ing for different output ﬁlters (Figure 11), and eventually
end up with searching for both. We showcase such search
space exploration in Section 4.2.

3.6 Switching between search algorithms

Figure 11: Manipulating the model in a
trainer into a search space by relaxing the
ﬁxed ﬁlters of the Conv as a set of options.

The search algorithm is another dimension to experiment with. We can easily switch between search
algorithms by passing a different algorithm to the sample function shown in Figure 10-1. When
applying efﬁcient NAS algorithms, the hyper_trainer will be rewritten into a trainer that samples
and trains the super-network transformed from the architectural search space.

4 Case Study

In this section, we demonstrate that with PyGlove how users
can deﬁne complex search spaces, explore new search spaces,
search algorithms, and search ﬂows with simplicity.

4.1 Expressing complex search spaces

The composition of hyper values can represent complex search
spaces. We have reproduced popular NAS papers, including
NAS-Bench-101 [38], MNASNet [8], NAS-FPN [39], Prox-
ylessNAS [14], TuNAS [15], and NATS-Bench [40]. Here we
use the search spaces from NAS-Bench-101, NAS-FPN, and
TuNAS to demonstrate the expressiveness of PyGlove.

In the NAS-Bench-101 search space (Figure 12-top), there are
N different positions in the network and (cid:0)N
edge
positions that can be independently turned on or off. Each
node independently selects one of K possible operations.

(cid:1) = N (N −1)

2

2

Figure 12: Partial search space deﬁ-
nition for NAS-Bench-101 (top), NAS-
FPN (middle) and TuNAS (bottom).

7

@symbolizeclass Trainer(object)  def __init__(    Self, model, optimizer):    ...  def train(self):    return trainer_impl(      self.optimizer,       self.model)Trainer(  model=ResNetLike(    block=Sequential([      Identity(),      Dense(8),      Conv(4,(3, 3))]),    num_blocks=12),  optimizer=Adam(2e-4))    def swap(k, v, Conv):  if isinstance(v, Conv):    return Dense(v.filters)  return vprint(trainer.query(  lambda v: isinstance(v, Layer))trainer.clone().rebind(swap)Symbolic classSymbolic tree of objectSymbolic operationsTrainer(  model=ResNetLike(    block=Sequential(      permutate([        Conv(          filters=oneof([4, 8]),           kernel=(3, 3))        BatchNormalization(),        ReLU()      ])),    num_blocks=intv(6, 12)),  optimizer=oneof([    Adam(2e-4),    RMSProp(floatv(1e-6, 1e-3)  ]))    for trainer, feedback in sample(    search_space=hyper_trainer,     algorithm=PPO(),    partition_fn=None):  reward = trainer.train()  feedback(reward)def relax_filters(k, v, parent):  if isinstance(parent, Conv):    if k == ‘filters’:      return oneof([v//2, v, v*2])  return vhyper_trainer = trainer.clone()  .rebind(relax_filters)@symbolizedef block(filters):  return Sequential([    Conv(filters, (3, 3)),     Conv(filters*2), (3, 3)])def swap(k, v, Conv):  if isinstance(v, Conv):    return Dense(v.filters)  return vprint(trainer.query(  lambda v: isinstance(v, Layer)))trainer.clone().rebind(swap)Trainer(  model=ResNetLike(    block=Sequential(      permutate([        Conv(          filters=oneof([4, 8]),           kernel=(3, 3)),        BatchNormalization(),        ReLU()      ])),    num_blocks=intv(6, 12)),  optimizer=oneof([    Adam(2e-4),    RMSProp(floatv(1e-6, 1e-3))  ]))    @symbolizeclass Trainer(object):  def __init__(    self, model, optimizer):    ...  def train(self):    return trainer_impl(      self.optimizer,       self.model)Trainer(  model=ResNetLike(    block=Sequential([      Identity(),      Dense(8),      Conv(4,(3, 3))]),    num_blocks=12),  optimizer=Adam(2e-4))    Symbolic classSymbolic tree of objectSymbolic operationsfor trainer, feedback in sample(    search_space=hyper_trainer,     algorithm=PPO(),    partition_fn=None):  reward = trainer.train()  feedback(reward)def relax_filters(k, v, parent):  if isinstance(parent, Conv):    if k == 'filters':      return oneof([v//2, v, v*2])  return vhyper_trainer = trainer.clone()  .rebind(relax_filters)@symbolizeclass Block(object):  def __init__(self, filters):    self.filters = filters  def __call__(self):    return Sequential([      Conv(self.filters, (3, 3)),       Conv(self.filters*2), (3, 3)])# NAS-Bench-101ModelSpec(  nodes=[oneof(range(K))]*N,   edges=[oneof([0, 1])]*N*(N-1)/2)# NAS-FPNFpnNode(  type=oneof(['sum', 'attention']),  level=3,  input_offsets=manyof(      2, range(NUM_PRE_NODES),      distinct=True,      sorted=True))# TuNASResidual(oneof([  InvertedBottleneck(    filters=oneof([32, 48, 64]),    kernel=oneof([3, 5, 7]),    expansion=oneof([3, 6])),  Zero()]))The NAS-FPN search space is a repeated FPN cell, each of whose nodes (Figure 12-middle) ag-
gregates two outputs of previous nodes. The aggregation is either sum or global attention. We use
manyof with the constraints distinct and sorted to select input nodes without duplication.

The TuNAS search space is a stack of blocks, each containing a number of residual layers (Figure
12-bottom) of inverted bottleneck units, whose ﬁlter size, kernel size and expansion factor will be
tuned. To search the number of layers in a block, we put Zeros as a candidate in the Residual layer
so the residual layer may downgrade into an identity mapping.

4.2 Exploring search spaces and search algorithms

We use MobileNetV2 [41] as an example to demonstrate how to explore new search spaces and
search algorithms. For a fair comparison, we ﬁrst retrain the MobileNetV2 model on ImageNet to
obtain a baseline. With our training setup, it achieves a validation accuracy of 73.1% (Table 3, row 1)
compared with 72.0% in the original MobileNetV2 paper. Details about our experiment setup, search
space deﬁnitions, and the code for creating search spaces can be found in Appendix C.1.

Search space exploration: Similar to previous AutoML works [8, 14], we explore 3 search spaces
derived from MobileNetV2 that tune the hyper-parameters of the inverted bottleneck units [41]: (1)
Search space S1 tunes the kernel size and expansion ratio. (2) Search space S2 tunes the output ﬁlters
(3) Search space S3 combines S1 and S2 to tune the kernel size, expansion ratio and output ﬁlters.

From Table 3, we can see that with PyGlove we were able to convert MobileNetV2 into S1 with 23
lines of code (row 2) and S2 with 10 lines of code (row 5). From S1 and S2, we obtain S3 in just a
single line of code (row 6) using rebind with chaining the transform functions from S1 and S2.
Search algorithm exploration: On the search algorithm dimension, we start by exploring different
search algorithms on S1 using black-box search algorithms (Random Search [12], Bayesian [26]) and
then efﬁcient NAS (TuNAS [15]). To make model sizes comparable, we constrain the search to 300M
multiply-adds3 using TuNAS’s absolute reward function [15]. To switch between these algorithms,
we only had to change 1 line of code.

Table 3: Programming cost of switching between three search spaces and three AutoML algorithms based
on PyGlove. Lines of code in red is the cost in creating new search spaces, while the lines of code in black is
the cost for switching algorithms. The unit cost for search and training is deﬁned as the TPU hours to train a
MobileNetV2 model on ImageNet for 360 epochs. The test accuracies and MAdds are based on 3 runs.
Lines
of codes

Search
algorithm

# of
MAdds

Search
cost

Search space

Train
cost

#

1

2
3
4

5

6

(static)

N/A

(static) → S1
S1
S1

(static) → S2

S1, S2 → S3

RS
RS → Bayesian
Bayesian → TuNAS

TuNAS

TuNAS

N/A

+23
+1
+1

+10

+1

N/A

25
25
1

1

2

1

1
1
1

1

1

300M

73.7 ± 0.3 (↑ 0.6)
73.9 ± 0.3 (↑ 0.8)
74.2 ± 0.1 (↑ 1.1)

300 ± 3 M
301 ± 5 M
301 ± 5 M

73.3 ± 0.1 (↑ 0.2)

302 ± 7M

73.8 ± 0.1 (↑ 0.7)

302 ± 6M

Test
accuracy
73.1 ± 0.1

4.3 Exploring complex search ﬂows on NAS-Bench-101

PyGlove can greatly reduce the engineering cost when ex-
ploring complex search ﬂows. In this section, we explore
various ways to optimize the NAS-Bench-101 search space.
NAS-Bench-101 is a NAS benchmark where the goal is to
ﬁnd high-performing image classiﬁers in a search space of
neural network architectures. This search space requires op-
timizing both the types of neural network layers used in the
model (e.g., 3x3 Conv) and how the layers are connected.

We experiment with three search ﬂows in this exploration:
1) we reproduce the original paper to establish a baseline,
which uses the search space deﬁned in Figure 12-top to
jointly optimize the nodes and edges. 2) we try a factorized search, which optimizes the nodes in the

Figure 13: Mean and standard deviation of
search performances with different search
ﬂows on NAS-Bench-101 (500 runs), using
Regularized Evolution [16] .

3For RS and Bayesian, we use rejection sampling to ensure sampled architectures have around 300M MAdds.

8

012345Total Search Time (seconds)1e60.9370.9380.9390.9400.9410.9420.9430.944CIFAR-10 Test Accuracystandardfactorized searchhybrid searchouter loop and the edges in the inner loop – the reward for a node setting is computed as the average
of top 5 rewards from the architectures sampled in the inner loop. While its performance is not as
good as the baseline under the same search budget, we suspect that under each ﬁxed node setting,
the edge space is not explored enough. 3) To alleviate this problem, we come out a hybrid solution,
which uses the ﬁrst half of the budget to optimize the nodes as in search ﬂow 2, while using the
other half to optimize the edges, based on the best node setting found in the ﬁrst phase. Interestingly,
the search trajectory crosses over the baseline in the second phase, ended with a noticeable margin
(Figure 13). We used Regularized Evolution [16] for all these searches, each with 500 runs. It takes
only 15 lines of code to implement the factorized search and 26 lines of code to implement the hybrid
search. Source codes are included in Appendix C.2.

5 Related Work

Software frameworks have greatly inﬂuenced and fueled the advancement of machine learning.
The need for computing gradients has made auto-gradient based frameworks [36, 37, 42–45] ﬂourish.
To support modular machine learning programs with the ﬂexibility to modify them, frameworks were
introduced with an emphasis on hyper-parameter management [46, 47]. The sensitivity of machine
learning to hyper-parameters and model architecture has led to the advent of AutoML libraries [23–31].
Some (e.g., [23–25]) formulate AutoML as a problem of jointly optimizing architectures and hyper-
parameters. Others (e.g., [26–28]) focus on providing interfaces for black-box optimization. In
particular, Google’s Vizier library [26] provides tools for optimizing a user-speciﬁed search space
using black-box algorithms [12, 48], but makes the end user responsible for translating a point in the
search space into a user program. DeepArchitect [29] proposes a language to create a search space as a
program that connects user components. Keras-tuner [30] employs a different way to annotate a model
into a search space, though this annotation is limited to a list of supported components. Optuna [49]
embraces eager evaluation of tunable parameters, making it easy to declare a search space on the go
(Appendix B.4). Meanwhile, efﬁcient NAS algorithms [1, 2, 14] brought new challenges to AutoML
frameworks, which require coupling between the controller and child program. AutoGluon [28]
and NNI [27] partially solve this problem by building predeﬁned modules that work in both general
search mode and weight-sharing mode, however, supporting different efﬁcient NAS algorithms are
still non-trivial. Among the existing AutoML systems we are aware of, complex search ﬂows are less
explored. Compared to existing systems, PyGlove employs a mutable programming model to solve
these problems, making AutoML easily accessible to preexisting ML programs. It also accommodates
the dynamic interactions among the child programs, search spaces, search algorithms, and search
ﬂows to provide the ﬂexibility needed for future AutoML research.

Symbolic programming , where a program manipulates symbolic representations, has a long history
dating back to LISP [20]. The symbolic representation can be programs as in meta-programming,
rules as in logic programming [50] and math expressions as in symbolic computation [51, 52]. In this
work, we introduce the symbolic programming paradigm to AutoML by manipulating a symbolic tree-
based representation that encodes the key elements of a machine learning program. Such program
manipulation is also reminiscent of program synthesis [53–55], which searches for programs to
solve different tasks like string and number manipulation [56–59], question answering [60, 61], and
learning tasks [62, 63]. Our method also shares similarities with prior works in non-deterministic
programming [64–66], which deﬁne non-deterministic operators like choice in the programming
environment that can be connected to optimization algorithms. Last but not least, our work echos the
idea of building robust software systems that can cope with unanticipated requirements via advanced
symbolic programming [67].

6 Conclusion

In this paper, we reformulate AutoML as an automated process of manipulating a ML program
through symbolic programming. Under this formulation, the complex interactions between the child
program, the search space, and the search algorithm are elegantly disentangled. Complex search ﬂows
can be expressed as compositions of for-loops, greatly simplifying the programming interface of
AutoML without sacriﬁcing ﬂexibility. This is achieved by resolving the conﬂict between AutoML’s
intrinsic requirement in modifying programs and the immutable-program premise of existing software
libraries. We then introduce PyGlove, a general-purpose symbolic programming library for Python
which implements our method and is tested on real-world AutoML scenarios. With PyGlove, AutoML

9

can be easily dropped into preexisting ML programs, with all program parts searchable, permitting
rapid exploration of different dimensions of AutoML.

Broader Impact

Symbolic programming/PyGlove makes AutoML more accessible to machine learning practitioners,
which means manual trial-and-error of many categories can be replaced by machines. This can
also greatly increase the productivity of AutoML research, at the cost of increasing demand for
computation, and – a result – increasing CO2 emissions.

We see a big potential in symbolic programming/PyGlove in making machine learning researchers
more productive. On a new ground of mutable programs, experiments can be reproduced more easily,
modiﬁed with lower cost, and shared like data. A large variety of experiments can co-exist in a shared
code base that makes combining and comparing different techniques more convenient.

Symbolic programming/PyGlove makes it much easier to develop search-based programs which can
be used in a broad spectrum of research and product areas. Some potential areas, such as medicine
design, have a clear societal beneﬁt, while others potential applications, such as video surveillance,
could improve security while raising new privacy concerns.

Acknowledgments and Disclosure of Funding

We would like to thank Pieter-Jan Kindermans and David Dohan for their help in preparing the case
study section of this paper; Jiquan Ngiam, Rishabh Singh for their feedback to the early versions
of the paper; Ruoming Pang, Vijay Vasudevan, Da Huang, Ming Cheng, Yanping Huang, Jie Yang,
Jinsong Mu for their feedback at early stage of PyGlove; Adams Yu, Daniel Park, Golnaz Ghiasi,
Azade Nazi, Thang Luong, Barret Zoph, David So, Daniel De Freitas Adiwardana, Junyang Shen,
Lav Rai, Guanhang Wu, Vishy Tirumalashetty, Pengchong Jin, Xianzhi Du, Yeqing Li, Xiaodan
Song, Abhanshu Sharma, Cong Li, Mei Chen, Aleksandra Faust, Yingjie Miao, JD Co-Reyes, Kevin
Wu, Yanqi Zhang, Berkin Akin, Amir Yazdanbakhsh, Shuyang Cheng, HyoukJoong Lee, Peisheng Li
and Barbara Wang for being early adopters of PyGlove and their invaluable feedback.

Funding disclosure: This work was done as a part of the authors’ full-time job in Google.

References

[1] Hieu Pham, Melody Y Guan, Barret Zoph, Quoc V Le, and Jeff Dean. Efﬁcient neural architecture search
via parameter sharing. In The International Conference on Machine Learning (ICML), pages 4092–4101,
2018.

[2] Hanxiao Liu, Karen Simonyan, and Yiming Yang. DARTS: Differentiable architecture search.

In

International Conference on Learning Representations (ICLR), 2019.

[3] Gábor Melis, Chris Dyer, and Phil Blunsom. On the state of the art of evaluation in neural language models.

In International Conference on Learning Representations (ICLR), 2018.

[4] Alfredo Canziani, Adam Paszke, and Eugenio Culurciello. An analysis of deep neural network models for

practical applications. arXiv preprint arXiv:1605.07678, 2016.

[5] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classiﬁcation with deep convolutional
neural networks. In The Conference on Neural Information Processing Systems (NeurIPS), pages 1097–
1105, 2012.

[6] Mingxing Tan and Quoc Le. EfﬁcientNet: Rethinking model scaling for convolutional neural networks. In

The International Conference on Machine Learning (ICML), pages 6105–6114, 2019.

[7] Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V Le. Learning transferable architectures for
scalable image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), pages 8697–8710, 2018.

[8] Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew Howard, and Quoc V Le.
MNASNet: Platform-aware neural architecture search for mobile. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition (CVPR), pages 2820–2828, 2019.

[9] Barret Zoph and Quoc V Le. Neural architecture search with reinforcement learning. In International

Conference on Learning Representations (ICLR), 2017.

10

[10] Bichen Wu, Xiaoliang Dai, Peizhao Zhang, Yanghan Wang, Fei Sun, Yiming Wu, Yuandong Tian, Peter
Vajda, Yangqing Jia, and Kurt Keutzer. FbNet: Hardware-aware efﬁcient convnet design via differentiable
neural architecture search. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), pages 10734–10742, 2019.

[11] Xiaoliang Dai, Peizhao Zhang, Bichen Wu, Hongxu Yin, Fei Sun, Yanghan Wang, Marat Dukhan, Yunqing
Hu, Yiming Wu, Yangqing Jia, et al. ChamNet: Towards efﬁcient network design through platform-aware
model adaptation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
pages 11398–11407, 2019.

[12] James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. The Journal of

Machine Learning Research (JMLR), 13(Feb):281–305, 2012.

[13] Jasper Snoek, Hugo Larochelle, and Ryan P Adams. Practical bayesian optimization of machine learning
algorithms. In The Conference on Neural Information Processing Systems (NeurIPS), pages 2951–2959,
2012.

[14] Han Cai, Ligeng Zhu, and Song Han. ProxylessNAS: Direct neural architecture search on target task and

hardware. In International Conference on Learning Representations (ICLR), 2019.

[15] Gabriel Bender, Hanxiao Liu, Bo Chen, Grace Chu, Shuyang Cheng, Pieter-Jan Kindermans, and Quoc Le.
Can weight sharing outperform random architecture search? an investigation with TuNAS. In The IEEE
Conference on Computer Vision and Pattern Recognition, 2020.

[16] Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V Le. Regularized evolution for image classiﬁer
architecture search. In AAAI Conference on Artiﬁcial Intelligence (AAAI), pages 4780–4789, 2019.

[17] Sirui Xie, Hehui Zheng, Chunxiao Liu, and Liang Lin. Snas: Stochastic neural architecture search, 2020.

[18] Wei Wen, Hanxiao Liu, Hai Li, Yiran Chen, Gabriel Bender, and Pieter-Jan Kindermans. Neural predictor
for neural architecture search. In Proceedings of the European Conference on Computer Vision (ECCV),
2020.

[19] Xuanyi Dong, Mingxing Tan, Adams Wei Yu, Daiyi Peng, Bogdan Gabrys, and Quoc V Le. AutoHAS:

Efﬁcient hyperparameter and architecture search. arXiv preprint arXiv:2006.03656, 2020.

[20] John McCarthy. Recursive functions of symbolic expressions and their computation by machine, part i.

Communications of the ACM, 3(4):184–195, 1960.

[21] Symbolic programming. https://en.wikipedia.org/wiki/Symbolic_programming.

[22] Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Jie Tan, Quoc V
Le, and Alexey Kurakin. Large-scale evolution of image classiﬁers. In The International Conference on
Machine Learning (ICML), pages 2902–2911, 2017.

[23] Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Springenberg, Manuel Blum, and Frank Hutter.
Efﬁcient and robust automated machine learning. In The Conference on Neural Information Processing
Systems (NeurIPS), pages 2962–2970, 2015.

[24] Lars Kotthoff, Chris Thornton, Holger H Hoos, Frank Hutter, and Kevin Leyton-Brown. Auto-weka 2.0:
Automatic model selection and hyperparameter optimization in weka. The Journal of Machine Learning
Research (JMLR), 18(1):826–830, 2017.

[25] Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Tobias Springenberg, Manuel Blum, and Frank
Hutter. Auto-sklearn: efﬁcient and robust automated machine learning. In Automated Machine Learning,
pages 113–134. Springer, 2019.

[26] Daniel Golovin, Benjamin Solnik, Subhodeep Moitra, Greg Kochanski, John Karro, and D Sculley. Google
vizier: A service for black-box optimization. In The SIGKDD International Conference on Knowledge
Discovery and Data Mining, pages 1487–1495, 2017.

[27] Neural network intelligence. https://github.com/microsoft/nni.

[28] Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang Zhang, Pedro Larroy, Mu Li, and Alexander Smola.
Autogluon-tabular: Robust and accurate automl for structured data. arXiv preprint arXiv:2003.06505,
2020.

[29] Renato Negrinho, Darshan Patil, Nghia Le, Daniel Ferreira, Matthew Gormley, and Geoffrey Gordon.
In The Conference on Neural Information

Towards modular and programmable architecture search.
Processing Systems (NeurIPS), pages 13715–13725, 2019.

[30] Keras tuner. https://github.com/keras-team/keras-tuner.

[31] Haifeng Jin, Qingquan Song, and Xia Hu. Auto-keras: An efﬁcient neural architecture search system. In
The SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1946–1956,
2019.

[32] The Lego Group. Lego. https://en.wikipedia.org/wiki/Lego.

11

[33] Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement

learning. Machine learning, 8(3-4):229–256, 1992.

[34] Jeshua Bratman, Satinder Singh, Jonathan Sorg, and Richard Lewis. Strong mitigation: Nesting search
for good policies within search for good reward. In Proceedings of the 11th International Conference
on Autonomous Agents and Multiagent Systems-Volume 1, pages 407–414. International Foundation for
Autonomous Agents and Multiagent Systems, 2012.

[35] Arber Zela, Aaron Klein, Stefan Falkner, and Frank Hutter. Towards automated deep learning: Efﬁcient

joint neural architecture and hyperparameter search. CoRR, abs/1807.06906, 2018.

[36] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. PyTorch: An imperative style, high-performance
deep learning library. In The Conference on Neural Information Processing Systems (NeurIPS), pages
8024–8035, 2019.

[37] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin,
Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. Tensorﬂow: A system for large-scale machine
learning. In The {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 16),
pages 265–283, 2016.

[38] Chris Ying, Aaron Klein, Eric Christiansen, Esteban Real, Kevin Murphy, and Frank Hutter. Nas-bench-
In The International Conference on Machine

101: Towards reproducible neural architecture search.
Learning (ICML), pages 7105–7114, 2019.

[39] Golnaz Ghiasi, Tsung-Yi Lin, Ruoming Pang, and Quoc V. Le. NAS-FPN: learning scalable feature

pyramid architecture for object detection. CoRR, abs/1904.07392, 2019.

[40] Xuanyi Dong, Lu Liu, Katarzyna Musial, and Bogdan Gabrys. NATS-Bench: Benchmarking nas algorithms

for architecture topology and size. arXiv preprint arXiv:2009.00437, 2020.

[41] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. Mobilenetv2:
Inverted residuals and linear bottlenecks. In Proceedings of the IEEE conference on computer vision and
pattern recognition, pages 4510–4520, 2018.

[42] James Bergstra, Olivier Breuleux, Frédéric Bastien, Pascal Lamblin, Razvan Pascanu, Guillaume Des-
jardins, Joseph Turian, David Warde-Farley, and Yoshua Bengio. Theano: a cpu and gpu math expression
compiler. In Proceedings of the Python for scientiﬁc computing conference (SciPy), pages 18–24, 2010.

[43] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio
Guadarrama, and Trevor Darrell. Caffe: Convolutional architecture for fast feature embedding. In The
ACM International Conference on Multimedia (ACM MM), pages 675–678, 2014.

[44] Seiya Tokui. Chainer: A powerful, ﬂexible and intuitive framework of neural networks, 2018.

[45] Roy Frostig, Matthew Johnson, and Chris Leary. Compiling machine learning programs via high-level

tracing. In Conference on Machine Learning and Systems (MLSys), 2018.

[46] Jonathan Shen, Patrick Nguyen, Yonghui Wu, Zhifeng Chen, Mia X Chen, Ye Jia, Anjuli Kannan, Tara
Sainath, Yuan Cao, Chung-Cheng Chiu, et al. Lingvo: a modular and scalable framework for sequence-to-
sequence modeling. arXiv preprint arXiv:1902.08295, 2019.

[47] Gin-conﬁg. https://github.com/google/gin-conﬁg.

[48] Max Jaderberg, Valentin Dalibard, Simon Osindero, Wojciech M Czarnecki, Jeff Donahue, Ali Razavi,
Oriol Vinyals, Tim Green, Iain Dunning, Karen Simonyan, et al. Population based training of neural
networks. arXiv preprint arXiv:1711.09846, 2017.

[49] Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. Optuna: A
next-generation hyperparameter optimization framework. In Proceedings of the 25rd ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining, 2019.

[50] Alain Colmerauer and Philippe Roussel. The birth of prolog. In History of programming languages—II,

pages 331–367, 1996.

[51] Wolfram Research, Inc. Mathematica, Version 12.1. Champaign, IL, 2020.

[52] Bruno Buchberger et al. Symbolic computation (an editorial). J. Symbolic Comput, 1(1):1–6, 1985.

[53] Harold Abelson and Gerald Jay Sussman. Structure and interpretation of computer programs. The MIT

Press, 1996.

[54] Sumit Gulwani, Susmit Jha, Ashish Tiwari, and Ramarathnam Venkatesan. Synthesis of loop-free programs.

ACM SIGPLAN Notices, 46(6):62–73, 2011.

[55] Sumit Gulwani, Oleksandr Polozov, and Rishabh Singh. Program synthesis. Foundations and Trends® in

Programming Languages, 4(1-2):1–119, 2017.

12

[56] Oleksandr Polozov and Sumit Gulwani. Flashmeta: a framework for inductive program synthesis. In
Proceedings of the ACM SIGPLAN International Conference on Object-Oriented Programming, Systems,
Languages, and Applications (OOPSLA), pages 107–126, 2015.

[57] Emilio Parisotto, Abdel rahman Mohamed, Rishabh Singh, Lihong Li, Dengyong Zhou, and Pushmeet
Kohli. Neuro-symbolic program synthesis. In International Conference on Learning Representations
(ICLR), 2017.

[58] Jacob Devlin, Jonathan Uesato, Surya Bhupatiraju, Rishabh Singh, Abdel rahman Mohamed, and Pushmeet
Kohli. Robustﬁll: Neural program learning under noisy i/o. In The International Conference on Machine
Learning (ICML), pages 990–998, 2017.

[59] Matej Balog, Alexander L Gaunt, Marc Brockschmidt, Sebastian Nowozin, and Daniel Tarlow. DeepCoder:
Learning to write programs. In International Conference on Learning Representations (ICLR), 2017.

[60] Chen Liang, Mohammad Norouzi, Jonathan Berant, Quoc V. Le, and Ni Lao. Memory augmented policy
optimization for program synthesis and semantic parsing. In The Conference on Neural Information
Processing Systems (NeurIPS), pages 9994–10006, 2018.

[61] Arvind Neelakantan, Quoc V. Le, and Ilya Sutskever. Neural programmer: Inducing latent programs with

gradient descent. In International Conference on Learning Representations (ICLR), 2016.

[62] Esteban Real, Chen Liang, David R So, and Quoc V Le. Automl-zero: Evolving machine learning

algorithms from scratch. In The International Conference on Machine Learning (ICML), 2020.

[63] Lazar Valkov, Dipak Chaudhari, Akash Srivastava, Charles Sutton, and Swarat Chaudhuri. Houdini:
Lifelong learning as program synthesis. In The Conference on Neural Information Processing Systems
(NeurIPS), pages 8687–8698, 2018.

[64] D. Andre and S. Russell. State abstraction in programmable reinforcement learning. In AAAI Conference

on Artiﬁcial Intelligence (AAAI), 2002.

[65] Harald Søndergaard and Peter Sestoft. Non-determinism in functional languages. The Computer Journal,

35(5):514–523, 1992.

[66] Armando Solar-Lezama. The sketching approach to program synthesis. In Asian Symposium on Program-

ming Languages and Systems, pages 4–13. Springer, 2009.

[67] G. Sussman. Building robust systems an essay. In Massachusetts Institute of Technology, 2007.

13

Appendix

The appendix provides a formal deﬁnition of symbolic programs in our method, including symbolic
counterparts of different program constructs, supported operations, and the description of algorithms
used in the materialization process. Appendix B gives a more detailed introduction to PyGlove –
our implementation of the method – with an example of dropping neural architecture search (NAS)
into an existing Tensorﬂow program (MNIST [37]). Appendix C provides additional information for
experiments used in our case studies, including experiment setup, source code for creating search
spaces and complex search ﬂows.

A More on Symbolic Programming for AutoML

A.1 Formal deﬁnition of a symbolic program

Give a program construct type t, let the hyper-parameters (which deﬁnes the uniqueness of an instance
of t) be noted as P (t) = (cid:104)p0, ..., pn(cid:105). The symbolic type of t can then be deﬁned as the output
of the symbolization function S applied on t, which returns a tuple of t’s type information and its
hyper-parameter deﬁnitions:

s = S(t) = (cid:104)t, P (t)(cid:105)

(1)

A hyper-parameter pi of s is either a primitive type or a symbolic type. Therefore an instance x of s –
a symbolic object – is a tree node, whose sub-nodes are its hyper-parameters. For convenience, x is
called a symbolic t, e.g: symbolic Dataset, symbolic Conv, etc. A symbolic program is a symbolic
object that can be executed, for example, a symbolic Trainer that trains and evaluates a ResNet (as
a sub-node) on ImageNet.

Two tree nodes are equal if and only if their type and hyper-parameters are equal. For example,
consider a symbolic Conv class which takes filters, kernel_size as its hyper-parameters. Two
Conv instances are equal if and only if their filters and kernel_size are equal.

We can clone a tree by copying its type information and hyper-parameters. Similarly, we can replace
a hyper-parameter value with a new value, which is the foundation for symbolic manipulation. For
example, a symbolic Conv’s kernel_size can be changed from (3, 3) to (5, 5) by another program.

Symbolic constraints can be speciﬁed on the hyper-parameters. These constraints deﬁne the hyper-
parameters’ value types and ranges. When a value is assigned as a hyper-parameter of another
symbolic object, it will be validated based on the symbolic constraint on that hyper-parameter. Since
the sub-nodes of a symbolic object can be manipulated, the constraints are helpful in catching
mistakes during symbolic manipulation.

A.2 Symbolic types

The basic elements of a computer program are classes and functions, plus a few built-in data structure
that works with the classes and functions for composition. To symbolize a computer program, we
need to map these basic program constructs to their symbolic counterparts. Based on Equation 1, the
symbolic type of t is deﬁned by t’s type information and hyper-parameters, illustrated in Table 4

Table 4: Hyper-parameters of basic program constructs

Program construct type
class
function
list
dict

Hyper-parameters
Constructor arguments.
Function arguments.
Indices in the list.
Keys in the dict.

Though a regular function takes arguments, the function itself doesn’t hold its hyper-parameter values.
Therefore, in order to manipulate the hyper-parameters of a function, a symbolic function – functor –

14

behaves like an object: an function with bound arguments. As a result, a functor is no different from
a class object with a call method, whose arguments could be bound either at construction time or call
time. Therefore, a functor can be a node in the symbolic tree.

A.3 Operations on symbolic types

Symbolic objects can be manipulated via a set of operations. Table 5 lists the basic operations
applicable to all symbolic types. Particularly, rebind in the modiﬁcation category is of special
importance, as it’s the foundation for implementing complex program transforms.

Category
Modiﬁcation

Inference

Inquiry

Table 5: Basic operations applicable to symbolic types.

Operation
rebind(x, dict)
rebind(x, λ)

Description
Replace each node in x whose path is a key in dict
Recursively apply the function λ to each node in x

isinstance(x, t)
has(x, p)
equal(x, x(cid:48))

Returns true if x is an instance of t, false otherwise
Returns true if p is a property of x, false otherwise
Returns true if x equals x(cid:48), false otherwise

parent(x)
path(x)
get(x, l)

query(x, θ)

Returns the parent node of x
Returns the path from the tree root to x
Returns the sub-node of x which has path l
Returns a dict of (cid:104)path, value(cid:105) pairs which
contains all sub-nodes of x satisfying predicate θ

Replication

clone(x)

Returns a symbolic copy of x

A.4 Materializing a child program from an abstract child program

As we decouple the search algorithm from the search space and child program by introducing the
abstract search space and abstract child program, we need to materialize the abstract child program
into a concrete child program based on the search space. Algorithm 1 illustrates this process, which
recursively merges the hyper values from the search space and the numeric choices from the abstract
child program. For a continuous or discrete hyper value, the value of choice is the ﬁnal value to be
assigned to its target node in the tree, while for a categorical hyper value, the value of choice is the
index of the selected candidate.

Algorithm 1: materialize
Input: search_space, abstract_child_program
Output: child_program

if isinstance(search_space, Choice) then

xcs ← ()
forall c ∈ child_space(search_space) do

dc ← child_value(abstract_child_program, path(c))
xc ← materialize(c, dc)
append(xcs, xc)

child_program ← xcs[value_of(abstract_child_program)]

else

child_program ← value_of(abstract_child_program)

return child_program

A.5 Sampling child programs from a search space

Sampling a child program from a search space can be described as a process in which 1) the search
algorithm proposes an abstract child program, and 2) the search space materializes the abstract child

15

program into a concrete program. Before the process starts, an abstract search space will be obtained
from the search space for setting up the search algorithm. This process is described by Algorithm 2.

Algorithm 2: sample
Input: search_space, search_algorithm
Output: Iterator((cid:104)child_program, f eedback_f or_child(cid:105))

setup(search_algorithm, abstract_search_space(search_space))
while true do

abstract_child_program ← propose(search_algorithm)
child_program ← materialize(search_space, abstract_child_program)
f eedback_f or_child ←
partial_bind(feedback, search_algorithm, abstract_child_program)

yield (cid:104)child_program, f eedback_f or_child(cid:105)

16

B More on PyGlove

In this section, we will map the concepts from our method into PyGlove programs, to illustrate how
a regular Python program is made symbolic programmable, turned into a search space, and then
optimized in a search ﬂow. At the end of this section, we provide an example of enabling NAS for an
existing Tensorﬂow-based MNIST program.

B.1 Symbolize a child program

B.1.1 Symbolize classes

A symbolic class can be converted from a regular Python class using the @symbolize decorator, or
can be created on-the-ﬂy without modifying the original class. The symbolize decorator creates a
class on-the-ﬂy by multi-inheriting the symbolic Object base class and the user class. The resulting
class therefore possesses the capabilities of both parents. Figure 14 shows an code example of
symbolizing existing/new classes.

import pyglove as pg
import tensorflow as tf

# Symbolizing preexisting keras layers into symbolic
# classes without modifying original classes .
Conv2D = pg . symbolize ( tf . keras . layers . Conv2D )
Dense = pg . symbolize ( tf . keras . layers . Dense )
Sequential = pg . symbolize ( tf . keras . Sequential )

# Symbolizing a newly created class with constraints .
@pg . symbolize ([

( ’ learning_rate ’ , pg . typing . Float ( min_value =0)) ,
( ’ steps ’ , pg . typing . Int ( min_value =1))

])
class CosineDecay ( object ):

def __init__ ( self , learning_rate , steps ):

self . learning_rate = learning_rate
self . steps = steps

def __call__ ( self , current_step ):

return ( tf . cos ( np . pi * current_step / self . steps )

* self . learning_rate )

Figure 14: Symbolizing existing classes and new classes.

Using symbolic constraints Constraints which validate new values during object construction or
upon modiﬁcation can be optionally provided when using the @symbolize decorator. Symbolic
constraints can greatly reduce human mistakes when a program is manipulated by other programs.
It also make the program implementation more crisp: user can program against an argument as it
claims to be without additional check.

Recomputing internal states Symbolic objects may have internal states. The mutable program-
ming model will only work when the internal states are consistent upon modiﬁcation. When one or
more hyper-parameters are modiﬁed through rebind, the object’s state will be reset, and the object’s
constructor will be invoked (again) on the same instance. Moreover, the change propagates back from
the current node to the root of the symbolic tree, allowing all impacted nodes to recompute states
upon modiﬁcation.

B.1.2 Symbolize functions

From function to functor Making functions symbolic programmable is trickier than for classes,
for the following reasons: First: functions don’t explicitly hold their parameters as member variables,

17

although functions’ bound arguments are analogous to member variables in classes. Second: functions
don’t have the concept of inheritance, which is necessary to get access to the capabilities provided by
the symbolic Object base class. To address these two issues, we introduce the concept of functor,
which is a symbolic class with a __call__ method; all the function arguments becoming the
functor’s hyper-parameters. Under the functor concept, we unify the representation and operations
of classes and functions. Figure 15 shows that functions can be symbolized in the same way as we
symbolize classes. Figure 16 shows how functors can be used with great ﬂexibility in binding their
hyper-parameters.

@pg . symbolize
def random_augment ( image , magnitude ):

return rand om_a ugme nt _ impl ( data , magnitude )

@pg . symbolize ([

( ’ model ’ , pg . typing . Instance ( Layer )) ,
( ’ augment_policy ’ , pg . typing . Callable (
[ pg . typing . Instance ( tf . Tensor )] ,
returns = pg . typing . Instance ( tf . Tensor ))) ,

( ’ learning _schedule ’ , pg . typing . Callable ([

pg . typing . Instance ( tf . Tensor )]))

])
def train_model ( model ,

augment_policy ,
lear ning_schedule ):

return train_model_impl (

model , augment_policy , learni ng_sched ule )

Figure 15: Decorator symbolize converts functions into functors.
Since properties for functors are automatically added from function
signature, constraints are optional. Nevertheless, users are encouraged
to add constraints for functor properties for safety and productivity.

model = Sequential ( children =[

Conv2D ( filters =8 , kernel_size =(3 , 3)) ,
Dense ( units =10)

])

# Partial parameter binding , in which ‘ model ‘ is missing .
trainer = train_model (

augment_policy = random_augment (

magnitude =8))

# Incremental parameter binding via assignment .
trainer . learn ing_schedule = CosineDecay (1 e -5 , 5000)

# Incremental parameter binding at call time .
accuracy1 = trainer ( model = model )

# Call with overriding previously bound parameters .
accuracy2 = trainer (

model = model ,
learn ing_schedule = CosineDecay (2 e -4 , 5000) ,
override_args = True )

Figure 16: Functors can be used as objects, with a rich set of argument
binding features.

Partial and incremental argument binding Functor comes with a capability that allows argu-
ments to be partially bound at construction time, incrementally bound via property assignment and at
call time. We can even override a previously bound argument during the call to the functor.

18

B.2 Operating symbolic values

Symbolic values can be operated as if they were plain data, including inference, inquiry, modiﬁcation
and replication. Figure 17 gives some examples to these operations.

model = Sequential ( children =[

Conv2D ( filters =8 , kernel_size =(3 , 3)) ,
Dense ( units =10)

])

# Partial parameter binding , in which ‘ model ‘ is missing .
trainer = train_model (

augment_policy = random_augment (

magnitude =8))

# Inference .
assert isinstance ( trainer , train_model )
assert isinstance ( trainer . model , Layer )
assert trainer . model . children [1] == Dense (10)
assert trainer . model != Conv2D (16 , (3 , 3))

# Inquiry .
assert trainer . query ( ’ .* filters ’) == {
’ model . children [0]. filters ’: 8

}

assert trainer . query ( where =(

lambda v : isinstance (v , Dense ))) == {

’ model . children [1] ’: Dense ( units =10)

}

# Modification .
assert trainer . rebind ({

’ model . children [0]. filters ’: 16 ,
’ model . children [1] ’: insert ( Dense (20))

}). model == Sequential ([

Conv2D (16 , (3 , 3)) , Dense (20) , Dense (10)

])

def conv_to_dense (k , v ):

return Dense ( v . filters ) if isinstance ( v . Conv2D ) else v

assert trainer . rebind ( conv_to_dense ) == (

Sequential ([ Dense (16) , Dense (20) , Dense (10)])

# Replication .
assert trainer . clone () == trainer
assert trainer . clone ( deep = True ) == trainer
trainer . save ( ’ trainer . json ’)
assert pg . load ( ’ trainer . json ’) == trainer

Figure 17: Example code for symbolic operations on inference, comparison,
inquiry, modiﬁcation, replication and serialization.

B.3 Using PyGlove for search

B.3.1 Creating search spaces

With the deﬁnition of functors train_model and random_augment, as well as the layer classes, we
can create a search space by replacing concrete values with hyper values, illustrated in Figure 18.

19

hyper_trainer = train_model (

model = Sequential (

pg . manyof ( k =3 , candidates =[

Conv2D ( filters = pg . oneof ([8 , 16]) ,

kernel_size = pg . oneof ([(3 , 3) , (5 , 5)])) ,

Dense ( units = pg . oneof ([10 , 20]))

] , choices_distinct = False )) ,
augment_policy = random_augment (

magnitude = pg . oneof ([3 , 6 , 9])) ,

lear ning_schedule = CosineDecay ( pg . floatv (1 e -5 , 1e -4) , 5000))

Figure 18: An example of conditional search space for jointly searching the
model architecture, data augment policy, and learning rate.

B.3.2 Search: putting things together

With hyper_trainer as the search space, we can start a search by sampling concrete trainers from
the search space with a search algorithm (e.g. RegularizedEvolution [16]). The trainer is
a concrete instance of train_model, which can be invoked to return the validation accuracy on
ImageNet. We use the validation accuracy as a reward to feedback to the search algorithm, illustrated
in Figure 19.

for trainer , feedback in pg . sample (

hyper_trainer , pg . generators . RegularizedEvolution () ,
partition_fn = None ):

reward = trainer ()
feedback ( reward )

Figure 19: Creating a search ﬂow from a search space and a search algorithm.
We pass None to the search space partition function here as to optimize the whole
search space.

B.4 More on materialization of hyper values

Materialization of hyper values can take place either eagerly or in a late-bound fashion. In the former
case, the hyper value evaluates to a concrete value within its range upon creation, and register the
search space into a global context for the ﬁrst run, which can be picked up by the search algorithm
later to propose values for future runs. This conditional evaluation makes it possible to support the
deﬁne-by-run style search space deﬁnition advocated by Optuna [49]. In the latter case, the search
space will be inspected from the symbolic tree and the tree can be manipulated freely by the search
algorithm before the program is executed.

def oneof ( candidates , hints = None ):

""" Oneof with optional eager execution . """
choice = Choice ( candidates , hints )
if is_eager_mode ():

if is_apply_decisi ons ():

# Apply next decision from the global context .
chosen_index = n ex t_ gl obal_deci sion ()

else :

# Collect the decision points when running
# the program for the first time .
a d d _ g lo b a l _ d e c i s io n _ p o i n t ( choice )
chosen_index = 0

choice = candidates [ chosen_index ]

return choice

Figure 20: Eagerly evaluation of hyper values.

20

The advantage of eager evaluation is that one can drop AutoML into a new ML program with minimal
code changes. Users do not need to explicitly deﬁne the hyper-parameters to search. Instead, we can
automatically identify them by executing the user’s code before the start of the search. On the other
hand, scattered searchable hyper-parameters makes it hard or error-prone to modify search space over
many ﬁles, especially when we want to explore multiple search spaces.

Meanwhile, conditional search spaces require special handling. Deﬁne-by-run semantics typically do
not provide enough information for us to recognize hierarchical search spaces. For instance, it is dif-
ﬁcult to distinguish between oneof([oneof([1, 2]), 1]) and oneof([1, 2]) + oneof([3,
4]). In PyGlove, we solve this problem by using a lambda function with zero-argument which
returns the candidate: oneof([lambda:oneof([1, 2]), 1]). In this case, the outer oneof will
instantiate the inner oneof, making it possible to capture the hierarchy of the hyper value structure.

While eagerly evaluation of hyper values seems to override the mechanism of symbolic manipulation,
it is not so for PyGlove: Under eager mode, PyGlove runs the user program once to collect the
symbolic objects (like the hyper values) along the program ﬂow, so we can access these objects,
manipulate them and inject them back into the program for future runs. As a result, eagerly evaluation
can be regarded as an interface for PyGlove to inspect and manipulate the implicit symbolic objects
created during program execution.

B.5 Example: Neural Architecture Search on MNIST

This section shows a complete example of dropping PyGlove into an existing ML program as to
enable NAS. Added code is highlighted with a light-yellow background.

""" NAS on MNIST .

This is a basic working ML program which does NAS on MNIST .
The code is modified from the tf . keras tutorial here :
https :// www . tensorflow . org / tutorials / keras / classification

( The tutorial uses Fashion - MNIST ,
but we just use " regular " MNIST for these tutorials .)

"""

from absl import app
from absl import flags
import numpy as np
import pyglove as pg
import tensorflow as tf

flags . DEFINE_integer (

’ max_trials ’ , 10 , ’ Number of max trials for tuning . ’)

flags . DEFINE_integer (

’ num_epochs ’ , 10 , ’ Number of epochs to train for each trail . ’)

FLAGS = flags . FLAGS

def d ow nl o ad _ an d _p r e p_ d at a ():

""" Download dataset and scale to [0 , 1].

Returns :

tr_x : Training data .
tr_y : Training labels .
te_x : Testing data .
te_y : Testing labels .

"""
mnist_dataset = tf . keras . datasets . mnist
( tr_x , tr_y ) , ( te_x , te_y ) = mnist_dataset . load_data ()
tr_x = tr_x / 255.0
te_x = te_x / 255.0

21

return tr_x , tr_y , te_x , te_y

# Create symbolized Keras layers classes .}
Conv2D = pg.symbolize(tf.keras.layers.Conv2D)

Dense = pg.symbolize(tf.keras.layers.Dense)

Sequential = pg.symbolize(tf.keras.Sequential)

def model_builder ():

""" Model search space . """
return Sequential(pg.oneof([

# Model family 1: only dense layers .
[

tf.keras.layers.Flatten() ,

Dense(pg.oneof([64, 128]), pg.oneof([’relu’, ’sigmoid’]))

] ,
# Model family 2: conv net .
[

tf.keras.layers.Lambda(lambda x:

tf.reshape(x, (-1, 28, 28, 1))) ,

Conv2D(pg.oneof([64, 128]), pg.oneof([(3, 3), (5, 5)]) ,

activation=pg.oneof([’relu’, ’sigmoid’])) ,

tf.keras.layers.Flatten()

]]) + [tf.keras.layers.Dense(10, activation=’softmax’)])

def train_and_eval ( model , input_data , num_epochs =10):

""" Returns model accuracy after train and evaluation .

Args :

model : A Keras model .
input_data : A tuple of ( training features , training_labels ,

test features , test labels ) as input data .
num_epochs : Number of epochs to train model .

Returns :

Accuracy on test split .

"""
tr_x , tr_y , te_x , te_y = input_data
model . compile ( optimizer = ’ adam ’ ,

loss = ’ s p a r s e _ c a t e g o r i c a l _ c r o s s e n t r o p y ’ ,
metrics =[ ’ accuracy ’ ])

model . fit ( tr_x , tr_y , epochs = num_epochs )
_ , test_acc = model . evaluate ( te_x , te_y , verbose =2)
return test_acc

def search ( max_trials , num_epochs ):
""" Search MNIST model via PPO .

Args :

max_trials : Max trials to search .
num_epochs : Number of epochs to train individual trial .

"""
results = []
input_data = d ow n lo a d_ a nd _p rep _da ta ()
for i, (model, feedback) in enumerate(pg.sample(

model_builder(), pg.generators.PPO(), max_trials)):

22

test_acc = train_and_eval(model, input_data, num_epochs)

results.append((i, test_acc))

feedback(test_acc)

# Print best results .
top_results = sorted(results, key=lambda x:

x[2], reverse=True)

for i, (trial_id, test_acc) in enumerate(top_results[:10]):

print(’{0:2d} - trial {1:2d} ({2:.3f})’.format(i + 1, trial_id, test_acc))

def main ( argv ):

""" Program entrypoint . """
if len ( argv ) > 1:

raise app . UsageError ( ’ Too many command - line arguments . ’)

search(FLAGS.max_trials, FLAGS.num_epochs)

if __name__ == ’ __main__ ’:

app . run ( main )

23

C More on case studies

This section describes the experiment details for our case studies in the paper.

C.1 Search spaces and search algorithms exploration

C.1.1 Experiment setup

Table 6: Hyper-parameters for training MobileNetV2 and searched models.

Name
Image size
Pre-processing

Training epochs
Batch size
Optimizer

Learning schedule

L2

Value
224 * 224
ResNet preprocessing

360
4096
RMSProp: momentum 0.9, decay 0.9, epsilon 1.0
Cosine decay with peak learning rate 2.64,
with 5 epochs linear warmup at the beginning.
2e-5

Dropout rate
Batch normalization

0.15
momentum 0.99, epsilon 0.001

Search space
S1

Table 7: Deﬁnition of search spaces for exploration.

Hyper-parameters
Search the kernel sizes with candidates [(3, 3), (5, 5), (7, 7)]
and expansion ratios with candidates [3, 6] for the inverted bottleneck units
in MobileNetV2; can remove layers from each block.

S2

S3

Search output ﬁlters of MobileNetV2
with multipliers [0.5, 0.625, 0.75, 1.0, 1.25, 1.5, 2.0]

Combine S1 and S2

Table 8: Search algorithm setup. We uses TuNAS absolute reward function with exponent=-0.1.

Search algorithm
Random Search [12]

Bayesian Optimization [26]

Conﬁguration
100 trials, each trial trains for 90 epochs,
rejection threshold for MAdds: ± 6M

100 trials, each trial trains for 90 epochs
rejection threshold for MAdds: ± 30M
(We use a larger rejection ratio for Bayesian
to limit the rejection rate, since our infra
will take the rewards from rejected trials)

TuNAS [15]

Search for 90 epochs, with RL learning rate set to 0 for ﬁrst 1/4 of training.
The search cost for S1 and S2 is about 4x of static model training,
and the cost for S3 about 8x of static model training.

24

C.1.2 Creating search spaces

In the Result section, we demonstrated 3 search spaces created from MobileNetV2 [41]. Figure 21-23
show the code for converting the static model into search spaces S1, S2 and S3.

import pyglove as pg

# Get the first inverted bottleneck .
r = model . query ( lambda x : isinstance (x , Inv er tedBottleneck ))
r = next ( iter ( r . values ()))

def h y p e r _i n v e r t e d _ b o t t l e n e c k (

kernel_size_list , expansion_ratio_list , add_zeros = False ):

return pg . oneof ([

r . clone (). rebind ( kernel_size =k , expansion_ratio = e )
for k in kernel_size_list
for e in ex pa ns io n_ ra tio _list

] + ([ Zeros ()] if add_zeros else []))

def relax_ops (k , v , p ):

if not k or k . key != ’ op ’:

return v

# Check if the layer of current operation is the
# first layer of current block .
if k . parent . key == 0:

if k == ’ blocks [0]. layers [0]. op ’:

return hy p e r _ i n v e r te d _ b o t t l e n e ck (
[(3 , 3) , (5 , 5) , (7 , 7)] , [1])

else :

return h y p e r _ i n v e r t e d _ b o t t l e n e ck (

[(3 , 3) , (5 , 5) , (7 , 7)] , [3 , 6])

else :

return hy p e r _ i n v e r te d _ b o t t l e n e ck (

[(3 , 3) , (5 , 5) , (7 , 7)] , [3 , 6] , True )

mobile_s2 = mobilenet_v2 . clone (). rebind ( relax_ops )

Figure 21: Added code for converting MobileNetV2 into a search space (S1) that tunes the
kernel size and expansion ratio in all inverted bottleneck units.

def relax_filters (k , v , p ):

if isinstance (p , I nv er ted Bo tt leN ec k ) and k == ’ filters ’:

scaled_values = sorted ( set ([

layers . scale_filters (v , x )()
for x in [0.5 , 0.625 , 0.75 , 1.0 , 1.25 , 1.5 , 2.0]]))

if len ( scaled_values ) == 1:
return scaled_values [0]

return pg . oneof ( scaled_values )

return v

mobile_s1 = mobilenet_v2 . clone (). rebind ( relax_filters )

Figure 22: Added code for converting MobileNetV2 into a search space (S2) that tunes the
channel size in all inverted bottleneck units.

mobile_s3 = mobilenet_v2 . clone (). rebind ([ relax_filters ,

relax_ops ])

Figure 23: Applying transform functions from S1 and S2 to create S3.

25

C.2 Search ﬂow exploration

In the case study, we explored 3 search ﬂows for optimizing NAS-Bench-101. Here we include
the code for the factorized and hybrid search since the standard search is already discussed in
Section B.3.2.

C.2.1 Factorized search

For the factorized search, we optimize the nodes in the outer loop and the edges in the inner loop.
Each example in the outer loop is a search space of edges with a ﬁxed node setting. Each example in
the inner loop is a ﬁxed model architecture. The reward for the outer loop is computed as the average
of top 5 rewards from the inner loop.

def factorized_s earch ( search_space ):

# Optimize the ops in the outer loop .
# Each example in the outer loop is an edge sub - space with fixed
# ops . ‘ partition_fn ‘ is used to create a sub - space by selecting
# op hyper values only .
best_example , best_reward = None , None
for edge_space , ops_feedback in pg . sample (

search_space , Re gu la ri zedEvolu tion () ,
trials =300 , partition_fn = lambda v : v . hints == OP_HINT ):

# Optimize the edges in the inner loop .
# Each reward computed in the inner loop
# is for an edge setting relative to
# the node setting decided in the outer loop .
rewards = []
for example , edges_feedback in pg . sample (

edge_space , Re gu la rize dEvolution () , trials =20):

reward = nasbench . get_reward ( example )
edges_feedback ( reward )
rewards . append ( reward )
if best_reward is None or best_reward < reward :
best_example , best_reward = example , reward

ops_feedback ( top5_average ( rewards ))

return best_example

Figure 24: A factorized search that optimizes the nodes in the outer loop and the edges in the inner
loop.

26

C.2.2 Hybrid search

For the hybrid search, we use the ﬁrst half of the budget to optimize the nodes using the same search
ﬂow illustrated in Section C.2.1 , then we use the other half of the budget to further optimize the
edges with the best nodes found in the prior phase.

def hybrid_search ( search_space ):

# Phase 1: search for the best ops with sampled edges .
# Each example in the outer loop is an edge sub - space with fixed
# ops . ‘ partition_fn ‘ is used to create a sub - space by selecting
# op hyper values only .
ops_attempts = []
for edge_space , ops_feedback in pg . sample (

search_space , Re gu la ri zedEvolu tion () ,
trials =150 , partition_fn = lambda v : v . hints == OP_HINT ):

rewards = []
algo = Re gul ar iz ed Ev ol ut ion ()
for example , edges_feedback in pg . sample ( edge_space ,

algo , trials =20):

reward = nasbench . get_reward ( example )
edges_feedback ( reward )
rewards . append ( reward )

ops_reward = top5_average ( rewards )
ops_attempts . append (( edge_space , ops_reward , algo ))
ops_feedback ( ops_reward )

# Phase 2: Continue search the best edge sub - space
# with best ops found .
edge_space , _ , edge_algo = sorted (

ops_attempts , key = lambda x : x [1] , reverse = True )[0]

best_example , best_reward = None , None
for example , edges_feedback in pg . sample ( edge_space ,

reward = nasbench . get_reward ( example )
edges_feedback ( reward )
if best_reward is None or best_reward < reward :
best_example , best_example = example , reward

return best_example

edge_algo , 150 * 20):

Figure 25: A hybrid search that optimizes the nodes with a factorized search in the ﬁrst phase, and
optimize the edges based on the best nodes found in the second phase.

27

