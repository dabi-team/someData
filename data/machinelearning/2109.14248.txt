1
2
0
2

p
e
S
9
2

]

G
L
.
s
c
[

1
v
8
4
2
4
1
.
9
0
1
2
:
v
i
X
r
a

EBSD Grain Knowledge Graph Representation
Learning for Material Structure-Property
Prediction

Chao Shu, Zhuoran Xin, and Cheng Xie∗

Yunnan University, School of Software, Kunming 650504, China
xiecheng@ynu.edu.cn

Abstract. The microstructure is an essential part of materials, stor-
ing the genes of materials and having a decisive inﬂuence on materi-
als’ physical and chemical properties. The material genetic engineering
program aims to establish the relationship between material composi-
tion/process, organization, and performance to realize the reverse de-
sign of materials, thereby accelerating the research and development of
new materials. However, tissue analysis methods of materials science,
such as metallographic analysis, XRD analysis, and EBSD analysis, can-
not directly establish a complete quantitative relationship between tissue
structure and performance. Therefore, this paper proposes a novel data-
knowledge-driven organization representation and performance predic-
tion method to obtain a quantitative structure-performance relationship.
First, a knowledge graph based on EBSD is constructed to describe the
material’s mesoscopic microstructure. Then a graph representation learn-
ing network based on graph attention is constructed, and the EBSD or-
ganizational knowledge graph is input into the network to obtain graph-
level feature embedding. Finally, the graph-level feature embedding is
input to a graph feature mapping network to obtain the material’s me-
chanical properties. The experimental results show that our method is
superior to traditional machine learning and machine vision methods.

Keywords: Knowledge Graph · EBSD · Graph Neural Network · Rep-
resentation Learning · Materials Genome · Structure-Property.

1

Introduction

Material science research is a continuous understanding of the organization’s evo-
lution, and it is also a process of exploring the quantitative relationship between
organizational structure and performance. In the past, the idea of material re-
search was to adjust the composition and process to obtain target materials with
ideal microstructure and performance matching. However, this method relies
on a lot of experimentation and trial-error experience and is ineﬃcient. There-
fore, to speed up the research and development(R&D) of materials, the Material
Genome Project [5] has been proposed in various countries. The idea of the

 
 
 
 
 
 
2

C. Shu et al.

Material Genome Project is to establish the internal connections between ingre-
dients, processes, microstructures, and properties, and then design microstruc-
tures that meet the material performance requirements [5,9]. According to this
connection, the composition and process of the material are designed and op-
timized. Therefore, establishing the quantitative relationship between material
composition/process, organizational structure, and performance is the core issue
of designing and optimizing materials.

At present, most tissue structure analysis is based on image analysis technol-
ogy to extract speciﬁc geometric forms and optical density data [12]. However,
the data obtained by this method is generally limited to the quantitative in-
formation about one-dimensional or two-dimensional images, and it is not easy
to directly establish a quantitative relationship between tissue structure and
material properties. The method has obvious limitations. In addition, current
material microstructure analysis (e.g., metallographic analysis, XRD analysis,
EBSD analysis) is often qualitative or partially quantitative and relies on man-
ual experience [12]. It is still impossible to directly calculate material properties
based on the overall organizational structure.

In response to the above problems, this paper proposes a novel data-driven [18]
material performance prediction method based on the EBSD [4]. EBSD is cur-
rently one of the most eﬀective material characterization methods. This char-
acterization data not only contains structural information but is also easier for
computers to understand. Therefore, we construct a digital knowledge graph [14]
representation based on EBSD, then design a representation learning network
to embed graph features. Finally, we use neural network [11] to predict material
performance with graph embedding. We conducted experiments on magnesium
metal and compared our method with traditional machine learning methods and
computer vision methods. The results show the scientiﬁc validity of our proposed
method and the feasibility of property calculation. The contribution of this page
include:

1. We design an EBSD grain knowledge graph that can digitally represent the

mesoscopic structural organization of materials.

2. We propose an EBSD representation learning method that can predict ma-

terial’s performance based on the EBSD organization representation.

3. We establish a database of structural performance calculations that expand

the material gene database.

2 Related work

2.1 Data-driven material structure-performance prediction

Machine learning algorithms can obtain abstract features of data and mine the
association rules behind the data. Machine learning algorithms have accelerated
the transformation of materials R&D to the fourth paradigm(i.e., Data-driven
R&D model). Machine learning is applied to material-aided design.

Ruho Kondo et al. used a lightweight VGG16 networks to predict the ionic
conductivity in ceramics based on the microstructure picture [7]. Zhi-Lei Wang

EBSD Grain Knowledge Graph Representation Learning

3

et al. developed a new machine learning tool, Material Genome Integrated Sys-
tem Phase and Property Analysis (MIPHA) [16]. They use neural networks to
predict the stress-strain curves and mechanical properties based on constructed
quantitative structural features. Pokuri et al. used deep convolutional neural net-
works to map microstructures to photovoltaic performance, and learn structure-
attribute relationships of the data [10]. They designed a CNN-based model to
extract the active layer morphology feature of thin-ﬁlm OPVs and predict pho-
tovoltaic performance.

Machine learning methods based on numerical and visual features can de-
tect the relationship between organization and performance. However, the mi-
crostructure of materials contains essential structural information and connec-
tion relationships, and learning methods based on descriptors and images will
ignore this information.

2.2 Knowledge graph representation learning

Knowledge Graph is an important data storage form in artiﬁcial intelligence tech-
nology. It forms a large amount of information into a form of graph structure
close to human reasoning habits and provides a way for machines to under-
stand the world better. Graph representation learning[3] gradually shows great
potential.

In medicine, knowledge graphs are commonly used for embedding represen-
tations of drugs. The knowledge graph embedding method is used to learn the
embedding representation of nodes directly and construct the relationship be-
tween drug entities. The constructed knowledge graphs can be used for down-
stream prediction tasks. Lin Xuan et al. propose a graph neural network based
on knowledge graphs(KGNN) to solve the problem of predicting interactions in
drug knowledge graphs [8].

Similarly, in the molecular ﬁeld, knowledge graphs are used to characterize
the structure of molecules/crystals [17,2,6]. Nodes can describe atoms, and edges
can describe chemical bonds between atoms. The molecular or crystal structure
is seen as an individual ”graph”. By constructing a molecular network map and
applying graph representation learning methods, the properties of molecules can
be predicted.

In the biological ﬁeld, graphs are used for the structural characterization of
proteins. The Partha Talukdar research group of the Indian Institute of Science
did work on the quality assessment of protein models [13]. In this work, they used
nodes to represent various non-hydrogen atoms in proteins. Edges connect the K
nearest neighbors of each node atom. Edge distance, edge coordinates, and edge
attributes are used as edge characteristics. After generating the protein map,
they used GCN to learn atomic embedding. Finally, the non-linear network is
used to predict the quality scores of atomic embedding and protein embedding.
Compared with the representation of descriptors and visual features, knowl-
edge graphs can represent structural information and related information. The
EBSD microstructure of the material contains important grain structure infor-
mation and connection relationships. Therefore, this paper proposes the rep-

4

C. Shu et al.

resentation method of the knowledge graph and uses it for the prediction of
organizational performance.

3 Representation of the EBSD Grain Knowledge Graph

In this part of the work, we construct a knowledge graph representation of the
micro-organization structure. As shown in the Figure 1, the left image is the
scanning crystallographic data onto the sample, and the right is the Inverse Pole
Figure map of the microstructure. The small squares in the Figure 1(b) repre-
sents the grains. Based on this grain map data, we construct a grain knowledge
graph representation. Because the size, grain boundary, and orientation of the
crystal grains aﬀect the macroscopic properties of the material, such as yield
strength, tensile strength, melting point, and thermal conductivity [1]. There-
fore, in this article, we choose the grain as the primary node in the map, and at
the same time, we discretize the main common attributes of the grain size and
orientation as the attribute node. Then, according to the grain boundaries of
the crystal grains, we divided the two adjacent relationships between the crystal
grains, namely, strong correlation and weak correlation. Finally, aﬃliation with
grains and attribute nodes is established.

(a) Raw scan data

(b) Grain organization map

Fig. 1. EBSD scan organization information.

3.1 Nodes Representation

Grain node. We segment each grain in the grain organization map and map
it to the knowledge graph as a grain node. First, we use Atex software to count
and segment all the grains in a grain organization map. Then We individually
number each grain so that all the grains are uniquely identiﬁed, and ﬁnally, we
build the corresponding nodes in the graph. As shown in the Figure 2, the left
side corresponds to the grains of the Figure 1(b), and the right side are the node
we want to build. The original grain corresponds to the grain node one-to-one.

EBSD Grain Knowledge Graph Representation Learning

5

The grain node is the main node entity in the graph, reﬂecting the existence and
distribution of the grain.

Fig. 2. The grain node corresponds to the original grain.

Grain size attribute node. Next, we construct grain size attribute nodes used
to discretize and identify the grain size. First, we discretize the size of the crystal
grains. As shown in the Figure 3, the color represents the diﬀerence in the size
of the grains, SIZEmax represents the largest-scale grain size, and SIZEmin
represents the smallest-scale grain size. The grain size levels are divided into
NSIZE, and the interval size of each level is (SIZEmax − SIZmin)/NSIZE. We
regard each interval as a category, as shown in the equation 1, for each grain, we
divide it into corresponding category according to its size. We use the discretiza-
tion category to represent the grain size instead of the original value. Then we
construct a size attribute node for each size category, as shown in Figure 3. Fi-
nally, we use the one-hot method to encode these NSIZE categories and use the
one-hot encoding as the feature of the size attribute node.

L Snode = (cid:100)Grain.size/(cid:100)(SIZEmax − SIZEmin)/NSIZE(cid:101)(cid:101)

(1)

where L Snode represents the size category of the grain. Grain.size is the circle
equivalent diameter of the grain, (cid:100)(cid:101) means rounding up.

Grain orientation attribute node. In this work, Euler angles are used to
identify the orientation of grains. Similarly, we also discretize the Euler angles,
as shown in Figure 4. The orientation of the grains is determined by the euler
angles in three directions, so we discretize the euler angles in the three direc-
tions and combine them. The obtained three Euler angle interval combinations
are the discretized types of orientation. Speciﬁcally as shown in the equation
2, we ﬁrst calculate the maximum and minimum values of the three Euler an-
gles φ(φ1, φ, φ2) for all grains, namely φmax = {φ1max, φmax, φ2max}, φmin =
{φ1min, φmin, φ2min}. Then each Euler angle φ(φ1, φ, φ2) is divided into Nφ
equal parts, the length of each part is (φmax − φmin)/Nφ. Finally, the Nφ equal
parts of each Euler angle are cross-combined to obtain N 3
φ combinations. We

12341GrainsGrain Nodes2346

C. Shu et al.

Fig. 3. Grain size discretization and corresponding size attribute nodes. The size of
the grains is marked with diﬀerent colors. From left to right, the grains are getting
bigger and bigger. Then the size interval [SIZEmin, SIZEmax] of the grains is found,
and this interval is divided into NSIZE parts. Finally, a size node is constructed for
regard each combination as a kind of orientation, i.e., there are N 3
each divided interval.
φ orientation
categories. For each grain, we can map it to one of N 3
φ categories according to
its three Euler angles φ(φ1, φ, φ2), As shown in the equation 2. In this way, all
crystal grains are divided into a certain type of orientation. We construct an
orientation attribute node for each type of orientation to represent orientation
information. Similarly, we use the one-hot method to encode these N 3
φ categories
individually. Each orientation category will be represented by a N 3
φ-dimensional
one-hot vector used as the feature of the corresponding orientation attribute
node.

L Onode = {(cid:100)Grain.φ1/(cid:100)(φ1max − φ1min)/Nφ(cid:101)(cid:101),

(cid:100)Grain.φ/(cid:100)(φmax − φmin)/Nφ(cid:101)(cid:101),
(cid:100)Grain.φ2/(cid:100)(φ2max − φ2min)/Nφ(cid:101)(cid:101)}

(2)

where Grain.φ1, Grain.φ and Grain.φ2 are the euler angles in the three di-
rections. L Onode represents the orientation category to which the grains are
classiﬁed. (cid:100)(cid:101) refers to rounding up.

Fig. 4. Grain orientation discretization and corresponding orientation attribute nodes.
On the left are three directions Euler angles, whose angles are represented by the RGB
color. Each Euler angle is divided into Nφ parts, and then each equal part of each Euler
angle is combined with one equal part of the remaining Euler angle. Each combination
is regarded as an orientation category, and a node is constructed for this.

Size 1Size 3Size 4Size n-4Size n-2Size n….SIZEminSIZEmax  μm…Grain Size increase ↑divideSize NodeNumber of Size Nodes:  NSIZESize LeverNo.NN3 combinations……No.NNo.1No.2No.NNo.1No.2No.1No.21Original Eular angleOrientation NodeCombine three angles2Ori 1 . . .     . . . Ori 2Ori 3Ori 4Ori 6Ori N3 Ori 5…EBSD Grain Knowledge Graph Representation Learning

7

3.2 Edges Representation

After the construction of the node, the edges between the nodes need to be
constructed. The nodes reﬂect the entities in the graph, and the edges contain
the structural information of the graph. We build edges in the grain knowledge
graph based on crystallographic knowledge. The constructed edge represents
the association between nodes, including position association and property as-
sociation. The edges between grain nodes reﬂect position information and grain
boundaries; the edges between grain nodes and grain attribute nodes describe
the properties of the grains.

Edge between grain nodes. The contact interface between the grains is called
the grain boundary, representing the transition of the atomic arrangement from
one orientation to another. Generally speaking, grain boundaries have a signif-
icant impact on the various properties of the metal. In order to describe the
boundary information of grains, we construct edges between grain nodes. First,
we obtain the neighboring grains of each grain and construct the connection be-
tween the neighbor grain nodes. In order to further restore more complex grain
spatial relationships, we set up a knowledge of neighboring rules. As shown in
the equation 3, we use lp to represent the ratio of the bordering edge length
of the grain to the total perimeter of the grain. Then we set a threshold λ, as
shown in the equation 4, when the lp of grain A and grain B is greater than or
equal to λ, we set the relationship between the A node and the B node to be
a strong correlation; otherwise, it is set to weak correlation. Figure 5 shows the
edge between grain nodes.

lp = bound length/perimeter

Rel G G(lp) =

(cid:40)

Strong association,
Weak association,

lp < λ
lp ≥ λ

(3)

(4)

Fig. 5. Adjacent grains and the edges between them

1234StrongBoundRelationStrongBoundRelationStrongBoundRelationStrongBoundRelationStrongBoundRelationStrongBoundRelationWeakBoundRelationStrongBoundRelationStrongBoundRelationStrongBoundRelationOriginal GrainGrain Knowledge Graph8

C. Shu et al.

Edge between grain node and size attribute node. In section 3.1, we
construct two types of attribute nodes. Here we associate the grain node with the
attribute node to identify the property of the grain. First, we calculate the grain
size category according to the equation 1, and then associate the corresponding
grain node with the corresponding size attribute node to form the edge. As
shown in the Figure 6, we calculate the size categories {m, m, n, r} of the four
grains {1, 2, 3, 4}, and then associate the corresponding grain node with the size
attribute nodes to form the belonging relationship.

Fig. 6. Edge between grain node and size attribute node.

Edge between grain node and orientation attribute node. Similarly,
we identify the orientation category for the grain node by associating it with
the orientation attribute node. As shown in the Figure 7, ﬁrst we split the
grains in the map, the bottom left of the picture shows the three Euler angles of
the grains. Then we calculate the orientation category {i, j, k, l} of the grains
{1, 2, 3, 4} according to equation 3. Finally, we associate the corresponding
orientation attribute node with the corresponding grain node. Figure 7 shows
the edges between the grain nodes and the orientation attribute nodes, reﬂecting
the discrete orientation characteristics and orientation distribution of the grains.

Fig. 7. Edge between grain node and orientation attribute node.

Size mSize nSize rOriginal GrainSize LeverSize division1234StrongBoundRelationStrongBoundRelationStrongBoundRelationStrongBoundRelationStrongBoundRelationStrongBoundRelationWeakBoundRelationStrongBoundRelationStrongBoundRelationStrongBoundRelationrnSize isSize ofSize ofmSize ofSize isSize isSize isSize ofGrain Knowledge GraphSize mSize rSize nOriginal GrainOri  lOri  kOri  jOri  iEuler: 176.07, 140.89, 51.91Euler: 16.56, 155.44, 38.22Euler: 51.11, 159.22, 32.37Euler: 2.98, 100.55, 16.79Orientation information(Euler angles)123StrongBoundRelationStrongBoundRelationStrongBoundRelationStrongBoundRelationStrongBoundRelationStrongBoundRelationWeakBoundRelationStrongBoundRelationStrongBoundRelationStrongBoundRelationrnSize isSize ofSize ofmSize ofSize isSize isSize isSize ofGrain Knowledge GraphOri  jjOri  kkOri ofOri isOri isOri isOri isOri of  Ori ofOri ofiOri  iOri  ll4Orientation CategoryeulareulareulareularEBSD Grain Knowledge Graph Representation Learning

9

3.3 Grain graph convolutional prediction model

The structured grain knowledge graph can describe the microstructure of the
material. Next, we build a graph feature convolution network(grain graph convo-
lutional network) to embed the grain knowledge graph and realize graph feature
extraction. Then, a feature mapping network based on a neural network is built
to predict material properties with the graph feature. The complete model we
built is shown in Figure 8.

Fig. 8. Grain graph convolutional prediction model. The model is divided into graph
feature extraction part and performance prediction part. The graph feature extraction
network is composed of multiple node-level graph attention networks(gat) and a path-
level attention aggregation network. The prediction network is a multilayer neural
network. The graph feature network extracts graph-level features, and the prediction
network maps graph-level features to material properties.

Grain graph convolutional network. The graph features convolution net-
work is a heterogeneous graph convolution network [15]. First, the heterogeneous
grain knowledge graph is divided into multiple bipartite graphs and isomorphic
graphs according to the type of edges. Next, the features of the nodes in the
meta-path of subgraph are transferred and aggregated. Then the features of
the same nodes of the subgraphs are fused, and ﬁnally, the graph-level char-
acterization nodes are obtained through multiple convolutions. The process of
graph convolution is shown at the bottom of Figure 8. Speciﬁcally, the node
aggregation process includes node-level feature aggregation and path-level fea-
ture aggregation. In node message transmission, we use node-level attention to
learn the attention value of adjacent nodes on the meta-path. After complet-
ing the message transmission of all meta-paths, we use path-level attention to
learn the attention value of the same nodes on diﬀerent meta-paths. With the
double-layer attention, the model can capture the inﬂuence factors of nodes and

`α101Graph Feature ExtractionBipartite GraphPerformance PredictionGrain Orientation NodeGrain Size NodeGrain Nodea[1]1a[1]2a[1]3a[1]na[2]1a[2]2a[2]3a[2]na[3]1a[3]2a[3]3a[3]nAttrTS EC…Graph Lever Nodes2h43110h12115h897Grain <> OriGrain <> GrainGrain <> Sizeα11α21α31α41α61α51α91α71α81α111α121Path   Attention…Path   Attention6h……Path   Attentionβ11β21β31……βp-11βp1Layer 1Layer 2Layer kNode Attention (gat)Graph Feature ExtractionNetwork LayerPath Attentiongatgatgatgatgatgatgatgatgat10

C. Shu et al.

obtain the optimal combination of multiple meta-paths. Moreover, the nodes
in the graph can better learn complex heterogeneous graphical and rich infor-
mation. The equation 5 shows the feature aggregation transformation under the
node-level attention. ι represents diﬀerent paths/edges, and there are a total of p
edges. αij represents the attention score between node i and node j. LeakyReLU
and Sof tmax are activation functions, W is a learnable weight matrix, and (cid:126)a
is a learnable weight vector. (cid:107) represents concatenation, and N (i) refers to all
neighbor nodes of node i. hk+1
represents the (k + 1) layers embedding of node
i.

i

· (cid:126)hk(ι)
i

(cid:126)zk(ι)
i = W k(ι)
ek(ι)
ij = LeakyReLU ((cid:126)ak(ι)
ij = Sof tmaxj(ek(ι)
αk(ι)
ij )
(cid:88)
(cid:126)hk+1(ι)
αk(ι)
ij
i

= σ(

· (cid:126)zk(ι)
i

)

· [(cid:126)zk(ι)
i

(cid:107) (cid:126)zk(ι)
j

])

(5)

j∈N (i)(ι)

The equation 6 shows the change of node characteristics at the path level,
βk
(ι) is the important coeﬃcient of each meta-path. We ﬁrst perform a nonlinear
transformation on the output (cid:126)hk+1(ι)
of the node-level attention network, and
then perform a similarity measurement with a learnable attention vector q. Next,
we input the result of the similarity measurement into the Softmax function to
obtain important coeﬃcients, and ﬁnally perform weighted summation on the
node embeddings on each meta-path. After completing multiple graph feature
convolutions, we obtain graph-level node embeddings.

i

βk
(ι) = Sof tmax(

1
N (i)

(cid:88)

ι∈N (i)

(cid:126)hk+1

i =

p
(cid:88)

ι=1

(ι) · (cid:126)hk+1(ι)
βk

i

(cid:126)q · tanh(W k · (cid:126)hk+1(ι)

i

+ (cid:126)b))

(6)

Feature mapping network. The microstructure-performance relationship is
usually qualitatively studied through statistical methods (e.g., statistics of grain
size, orientation, and grain boundaries). The relationship between the microstruc-
ture and properties is diﬃcult to obtain through comparative observation or
direct calculation. However, Artiﬁcial neural networks can mine more essential
characteristics of data and establish complex relationships between data [11].
Here, we have used the graph features convolution network to extract the fea-
tures of the grain knowledge graph, so we use a feature mapping network based
on a neural network to implement machine learning tasks. As shown in equation
7, (cid:126)hi is the ﬁnal graph-level node vector, f c is the mapping network. The net-
work comprises a data normalization layer, a fully connected layer, an activation
layer, and a random deactivation layer. Through this network, the feature of the

EBSD Grain Knowledge Graph Representation Learning

11

grain knowledge graph can be mapped to the property of material.

prop =

1
n

n
(cid:88)

i=1

f c((cid:126)hi)

(7)

4 Experiment

4.1 Dataset

The experimental data comes from the EBSD experimental data of 19 Mg metals
and also includes the yield strength(ys), tensile strength(ts), and elongation(el)
of the sample. The EBSD scan data contains a total of 4.46 million scan points.
As a result, the number of nodes in all the constructed knowledge graphs is
40,265, and the number of edges reaches 389,210. We use EBSD knowledge graph
representation as model input and mechanical properties as label.

4.2 Comparison methods and Results

We design two diﬀerent methods to compare with ours. They are traditional
machine learning methods based on statistics, image feature extraction meth-
ods based on computer vision. We use traditional machine learning methods to
directly calculate the attribute characteristics of all grains to obtain material
properties. These methods include Ridge, SVR, KNN, ExtraTree. In addition,
we use the pre-trained CNN model to directly learn visual features from the
microstructure map and predict performance. The model is Resnet-50.

The model performance evaluation results are shown in Table 1. It can be seen
that our method is superior to other methods. Our method obtained an R2 value
of 0.74. This shows that our method can extract more eﬀective features. Tra-
ditional machine learning methods and machine vision methods have obtained
acceptable R2 values, which shows that both methods can obtain microstructure
characteristics to a certain extent. However, compared with traditional machine
learning, the method of machine vision does not show much superiority. It is
because CNN training requires a larger amount of data, and our current data
set is small.

Table 1. Results of model for ys prediction

Model
Ridge
SVR
KNN
ExtraTree
Resnet50
Hetero GAT(Our)

MSE MAE
112.5
102.7
97.6
105.9
94.8
73.1

6.9
4.8
3.6
5.6
3.1
5.9

R2
0.590
0.626
0.651
0.610
0.667
0.74

12

C. Shu et al.

5 Conclusion

This paper proposes a novel material organization representation and perfor-
mance calculation method. First, we use the knowledge graph to construct the
EBSD representation. Then, we designed a representation learning network to
abstract the EBSD representation as graph-level features. Finally, we built a
neural network prediction model to predict the corresponding attributes. The
experimental results prove the eﬀectiveness of our method. Compared with tra-
ditional machine learning methods and machine vision methods, our method is
more reasonable and practical.

References
1. Carneiro, ´I., Sim˜oes, S.: Recent advances in ebsd characterization of metals. Metals

10(8), 1097 (2020)

2. Chen, C., Ye, W., Zuo, Y., Zheng, C., Ong, S.P.: Graph networks as a universal
machine learning framework for molecules and crystals. Chemistry of Materials
31(9), 3564–3572 (2019)

3. Hamilton, W.L.: Graph representation learning. Synthesis Lectures on Artiﬁcal

Intelligence and Machine Learning 14(3), 1–159 (2020)

4. Humphreys, F.: Characterisation of ﬁne-scale microstructures by electron backscat-

ter diﬀraction (ebsd). Scripta materialia 51(8), 771–776 (2004)

5. Jain, A., Ong, S.P., Hautier, G., Chen, W., Persson, K.A.: Commentary: The ma-
terials project: A materials genome approach to accelerating materials innovation.
APL Materials 1(1), 011002 (2013)

6. Jang, J., Gu, G.H., Noh, J., Kim, J., Jung, Y.: Structure-based synthesizability
prediction of crystals using partially supervised learning. Journal of the American
Chemical Society 142(44), 18836–18843 (2020)

7. Kondo, R., Yamakawa, S., Masuoka, Y., Tajima, S., Asahi, R.: Microstructure
recognition using convolutional neural networks for prediction of ionic conductivity
in ceramics. Acta Materialia 141, 29–38 (2017)

8. Lin, X., Quan, Z., Wang, Z.J., Ma, T., Zeng, X.: Kgnn: Knowledge graph neural
network for drug-drug interaction prediction. In: Proceedings of the Twenty-Ninth
International Joint Conference on Artiﬁcial Intelligence, IJCAI-20 (International
Joint Conferences on Artiﬁcial Intelligence Organization). pp. 2739–2745 (2020)
9. Pablo, J.D., Jackson, N.E., Webb, M.A., Chen, L.Q., Moore, J.E., Morgan, D.,
Jacobs, R., Pollock, T., Schlom, D.G., Toberer, E.S.: New frontiers for the materials
genome initiative. Npj Computational Materials 5(1) (2019)

10. Pokuri, B.S.S., Ghosal, S., Kokate, A., Sarkar, S., Ganapathysubramanian, B.: In-
terpretable deep learning for guided microstructure-property explorations in pho-
tovoltaics. npj Computational Materials 5(1), 1–11 (2019)

11. Priddy, K.L., Keller, P.E.: Artiﬁcial neural networks: an introduction, vol. 68. SPIE

press (2005)

12. Rekha, S., Raja, V.B.: Review on microstructure analysis of metals and alloys
using image analysis techniques. IOP Conference Series: Materials Science and
Engineering 197, 012010 (may 2017)

13. Sanyal, S., Anishchenko, I., Dagar, A., Baker, D., Talukdar, P.: Proteingcn: Protein
model quality assessment using graph convolutional networks. bioRxiv (2020)
14. Wang, Q., Mao, Z., Wang, B., Guo, L.: Knowledge graph embedding: A survey
of approaches and applications. IEEE Transactions on Knowledge and Data Engi-
neering 29(12), 2724–2743 (2017)

EBSD Grain Knowledge Graph Representation Learning

13

15. Wang, X., Ji, H., Shi, C., Wang, B., Ye, Y., Cui, P., Yu, P.S.: Heterogeneous graph
attention network. In: The World Wide Web Conference. pp. 2022–2032 (2019)
16. Wang, Z.L., Adachi, Y.: Property prediction and properties-to-microstructure in-
verse analysis of steels by a machine-learning approach. Materials Science and
Engineering: A 744, 661–670 (2019)

17. Wieder, O., Kohlbacher, S., Kuenemann, M., Garon, A., Ducrot, P., Seidel, T.,
Langer, T.: A compact review of molecular property prediction with graph neural
networks. Drug Discovery Today: Technologies (2020)

18. Zhou, Q., Lu, S., Wu, Y., Wang, J.: Property-oriented material design based on a
data-driven machine learning technique. The journal of physical chemistry letters
11(10), 3920–3927 (2020)

