1
2
0
2

v
o
N
4
2

]
L
P
.
s
c
[

1
v
0
2
4
2
1
.
1
1
1
2
:
v
i
X
r
a

CircuitFlow: A Domain Speciﬁc Language for
Dataﬂow Programming*

Riley Evans, Samantha Frohlich[0000−0002−4423−6918], and Meng
Wang[0000−0001−7780−630X]

University of Bristol, Bristol, United Kingdom

Abstract. Dataﬂow applications, such as machine learning algorithms,
can run for days, making it desirable to have assurances that they will
work correctly. Current tools are not good enough: too often the in-
teractions between tasks are not type-safe, leading to undesirable run-
time errors. This paper presents a new declarative Haskell Embedded
DSL (eDSL) for dataﬂow programming: CircuitFlow. Deﬁned as a Sym-
metric Monoidal Preorder (SMP) on data that models dependencies in
the workﬂow, it has a strong mathematical basis, refocusing on how
data ﬂows through an application, resulting in a more expressive solu-
tion that not only catches errors statically, but also achieves competitive
run-time performance. In our preliminary evaluation, CircuitFlow outper-
forms the industry-leading Luigi library of Spotify by scaling better with
the number of inputs. The innovative creation of CircuitFlow is also of
note, exemplifying how to create a modular eDSL whose semantics neces-
sitates eﬀects, and where storing complex type information for program
correctness is paramount.

Keywords: eDSL, domain-speciﬁc languages, Haskell, Dataﬂow pro-
gramming

1

Introduction

CircuitFlow’s domain is dataﬂow programming [8], which deals with processing
data through transformations with interlinking dependencies. Inputs are trans-
formed into outputs by tasks, organised into workﬂows taking the form of Di-
rected Acyclic Graphs (DAGs) encoding dependencies, where the directionality
indicates the direction the data is ﬂowing, and the acyclicity ensures that the
data doesn’t go round in circles. Dataﬂow programming is highly applicable with
numerous uses spanning from scientiﬁc data analysis [11, 20] to machine learn-
ing [1, 41]. Examples include Data Pipelines, CI Systems, Quartz Composer [17]
and Spreadsheets. It also has the following beneﬁts:

Declarative Describing the shape of the DAG instead of just indicating the
connections, provides a more user-friendly and declarative experience.

*Published in proceedings of PADL 2022. This version includes appendices.

 
 
 
 
 
 
2

R. Evans et al.

Implicit Parallelism Since each node in a dataﬂow is a pure function, it is possible
to parallelise implicitly. The purity of the nodes means that outside of data
dependencies encoded in the dataﬂow graph, no node can interact with another.
Thus eliminating the ability for a deadlock to occur.

Visual The dataﬂow paradigm uses graphs. This provides the programs with
a visual interpretation, allowing end-user programmer to reason visually about
how data passes through the program, much easier than in an imperative ap-
proach [15].

Existing dataﬂow libraries such as Spotify’s Luigi [33] or Apache’s Airﬂow [2]
have no mechanism to ensure the dependencies are valid. There is no static
checking that the connections in the graph match up, which could cause runtime
crashes, or even worse, the bug could go unnoticed and cause havoc in later tasks.
Consider an example shown in the docs for Luigi [34] that is made up of two tasks:
the ﬁrst, GenerateWords, generates a list of words and saves it to a ﬁle; and the
second, CountLetters, counts the number of letters in each of those words. An
implementation of this in Luigi could have a very subtle bug! GenerateWords
could write the words to a ﬁle separated by new lines, while CountLetters
expects a comma-separated list. This shows a key ﬂaw in this system, as it is up
to the programmer to ensure that they write the outputs correctly, and then that
they read that same ﬁle in the same way. This error, would not even cause a run-
time error, instead, it will just produce the incorrect result. For a developer, this
is extremely unhelpful: it means more time is used writing tests — something
that no one enjoys. With good development practices, the risk is reduced, but as
functional programmers, we know a better way: abstraction and static typing.

Why not eliminate all of this with an abstraction of the reading and writing of
many diﬀerent sources and types? The abstraction will help to ensure correctness
of passing data via ﬁles by eliminating any possible duplicated code. Instead, just
having a uniform interface to test. Then the abstract interface can be combined
with the type system so that in each program, it is enforced that the types align.
This promotes the need for a new solution with such features that can safely
compose tasks and make use of types to perform static analysis to ensure that
dependencies are valid.

We present CircuitFlow, which takes a diﬀerent line of attack from its prede-
cessing plumbers like Luigi: rather than focus on how to compose tasks together,
it deﬁnes a declarative language that describes how data ﬂows through a work-
ﬂow. In CircuitFlow, it would not be possible to feed the output of one task, with
the type FileStore [String] into a task that expects a CommaSepFile [String]. The
same example, written in CircuitFlow, is deﬁned as:

generateWords :: Circuit (cid:48)[Var] (cid:48)[()] (cid:48)[FileStore] (cid:48)[[String]] N1
generateWords = functionTask (const ["apple", "banana", "grapefruit"])
countLetters :: Circuit (cid:48)[CommaSepFile] (cid:48)[[String]] (cid:48)[FileStore] (cid:48)[[String]] N1
countLetters = functionTask (map f)

where

f word = (concat [word, ":", show (length word)])

CircuitFlow

3

circuit :: Circuit (cid:48)[Var] (cid:48)[()] (cid:48)[FileStore] (cid:48)[[String]] N1
circuit = generateWords <−> countLetters

In this example, it will fail to compile, giving the error:

> Couldn’t match type ‘CommaSepFile’ with ‘FileStore’

Beneﬁting the user since the feedback loop of knowing if the program will succeed
is reduced. Previously, the whole data pipeline had to be run, whereas now this
information is available at compile-time.

Due to the type heft required for such a language, which includes DataKinds [39],

Singletons [10], Type Families [32], Heterogeneous lists [19], Phantom Types (a
brief introduction of which can be found in Appendix A), it will be embedded.
CircuitFlow draws its origins from monoidal resource theory [7], details of
which can be found in Appendix C. It is then compiled down to a Kahn Process
Network (KPN) that executes the workﬂow in parallel, to provide the speed
beneﬁts of multi-core processors. The KPN used by CircuitFlow is capable of
handling an exception in a task, without causing the full network to crash,
allowing computation to continue after for successive inputs.

Contributions: A declarative eDSL for creating dataﬂow programs that:

– employs state of the art DSL design techniques, including indexed data types
`a la carte and principled recursion to provide interpretations for the AST.
– uses state of the art Haskell methods to produce a type-safe implementation.
– makes use of indexed functors, extended to support multiple indicies, to con-
struct a type-indexed AST in conjunction with an indexed monadic catamor-
phism to provide a type-safe translation to a KPN.

– has a strong mathematical grounding in monadic resource theories providing

conﬁdence that the language can represent all dataﬂow diagrams.

– has appealing preliminary benchmark performance against another compet-
ing library — outperforming Luigi by almost 4x on large numbers of inputs.

– exempliﬁes how to create such a language in a modular manner.
– uses the ﬁrst known implementation of a Kahn Process Network in Haskell.

Examples that demonstrate the language’s applicability:

– Machine learning: preprocessing of real world song data in comparison to

Spotify’s Luigi.

– Build systems: the thesis this paper is based on was compiled using CircuitFlow

(details in Appendix B).

2 CircuitFlow Language

A use case for CircuitFlow is building data pipelines for machine learning. Con-
sider the example where an audio streaming service would like to create a playlist
full of new songs to listen to. This could require a machine learning model that

4

R. Evans et al.

Month 1

Month 2

Month 3

AggSongs

Top10

T10 Songs

AggArtists

Top10

T10 Artists

Fig. 1: A dataﬂow diagram for pre-processing the song data

can predict songs based on the top ten artists and songs that the user has lis-
tened to over the last three months. However, each of the months’ data is stored
in diﬀerent ﬁles that need aggregating together before they can be input into the
model. This problem can be drawn up as a dataﬂow diagram like Figure 1. To
achieve this preprocessing, a software developer at said audio streaming service
would need to use the following key features of the CircuitFlow language.

2.1 DataStores

Dataﬂow programming revolves around transforming inputs into outputs. Thus
the ﬁrst thing the language needs is a way of getting inputs and writing outputs.
For the preprocessing example, this corresponds to a way of interfacing with
the diﬀerent months of song data; a way to pass on the aggregated songs and
artists to the top ten calculators; and ﬁnally somewhere to store the preprocessed
output ready for the machine learning model. In CircuitFlow, DataStores are used
to pass values between diﬀerent tasks, in a closely controlled manner. To abstract
over the diﬀerent ways of storing data, they are deﬁned as a type class:

class DataStore f a where

fetch :: f a → IO a
save
empty :: TaskUUID → JobUUID → IO (f a)

:: f a → a → IO ()

The type class provides a way of extracting a value from a DataStore (fetch), a
way to write to one (save), and a way of creating an empty one for a speciﬁc
task. Although the user can deﬁne their own, the library comes with predeﬁned
DataStores, the simplest is a Var, based on MVars (mutable locations).

newtype Var a = Var {unVar :: MVar a} deriving (Eq)
instance DataStore Var a where

fetch = readMVar · unVar
save = putMVar · unVar
empty

= Var <$> newEmptyMVar

Var doesn’t use its id arguments in empty, however, other predeﬁned stores, such
as FileStore and CSVStore, use them to decide where to place the ﬁles created.

Combined DataStores A special case of a DataStore, they allow the interfacing
with typed lists, not just a single type. The typed list is a variation on HLists:

IHList (deﬁned below). Combined data stores are automatically derived from
existing DataStore instances, making it easier for tasks to fetch from multiple
inputs by supplying fetch’. (Since tasks can only have one output, there is no
need for a save’ function.)

CircuitFlow

5

data IHList (fs :: [∗ → ∗]) (as :: [∗]) where

HCons’ :: f a → IHList fs as → IHList (f (cid:48): fs) (a (cid:48): as)
HNil’

:: IHList (cid:48)[ ] (cid:48)[ ]

class DataStore(cid:48) (fs :: [∗ → ∗]) (as :: [∗]) where
:: IHList fs as → IO (HList as)

fetch’
empty’ :: TaskUUID → JobUUID → IO (IHList fs as)

2.2 Circuit Type

A Circuit represents some computation that has some number of inputs and
outputs. In order to statically check dependencies, the Circuit type needs to
store a lot of information.

Circuit (insContainerTypes

:: [∗ → ∗]) (insTypes
(outsContainerTypes :: [∗ → ∗]) (outsTypes :: [∗]) (nIns :: Nat)

:: [∗])

It has ﬁve type parameters: insContainerTypes, a type-list of storage types, for
example (cid:48)[VariableStore, CSVStore]; insTypes, a type-list of the types stored in
the storage, for example (cid:48)[Int, [(String, Float)]]; outsContainerTypes and outsTypes
mirror that the examples above, but for the outputs instead. The container and
value types are separate, due to the need for them to be “unapplied” for the
DataStore typeclass. Unfortunately, GHC requires a little more information to
perform this match check, such as the seemingly superﬂuous nIns, a type-level
Nat that is the length of the input lists.

2.3 Circuit Constructors

...

c1

...

c2

...

...

c2

...

...

c2

...

...

f

(a) id

(b) replicate

(c) c1 <−> c2

(d) c1 <> c2

(e) task f

Above shows the core constructors of the language along with their dia-
grammatic representation. Here the relation to resource theories is apparent,
the constructors in this library make up a SMP, establishing them as a resource
theory able to represent any DAG. More details can be found in appendices C
and D. The diagrammatic interpretation also makes translation from dataﬂow
diagrams, such as Figure 1, to CircuitFlow code easy.

6

R. Evans et al.

In the language, there are two types of constructors: those that create ba-
sic circuits and those that compose them. The behaviour of the constructor is
recorded within the types. Here are the types of some basic circuits:

:: DataStore(cid:48) (cid:48)[f] (cid:48)[a] ⇒ Circuit (cid:48)[f] (cid:48)[a] (cid:48)[f]
(cid:48)[a] N1
id
replicate :: DataStore(cid:48) (cid:48)[f] (cid:48)[a] ⇒ Circuit (cid:48)[f] (cid:48)[a] (cid:48)[f, f] (cid:48)[a, a] N1

Consider the id constructor, for convenience the nins parameter is shorted with
type synonyms, e.g. N1∼(cid:48)Succ (cid:48)Zero. It can be seen how the type information
for this constructor states that it has 1 input value of type f a and it returns
that same value. Each type parameter in id is a phantom type, since there are
no values stored in the data type that use the type parameters. The replicate
constructor states that a single input value of type f a should be input, and that
value should then be duplicated and output. There is also a swap constructor that
takes two values as input and swaps their order, and dropL / dropR constructors
that will take two inputs and drop the left or the right one respectively.

To use these basic circuits, CircuitFlow provides two constructors named ‘be-
side’ and ‘then’ to compose circuits. The deﬁnition of these constructors will
require type level calculations. This is where closed type families [9] come in,
allowing for type level versions of (+) and (++) [19] (requiring PolyKinds [39]).

The ‘Then’ Constructor , denoted by <−>, is used run one circuit, then an-
other, encapsulating the idea of dependencies. Through types, it enforces that
the output of the ﬁrst circuit is the same as the input to the second circuit.

(<−>) :: (DataStore(cid:48) fs as, DataStore(cid:48) gs bs, DataStore(cid:48) hs cs)

⇒ Circuit fs as gs bs nfs → Circuit gs bs hs cs ngs → Circuit fs as hs cs nfs

It employs a similar logic to function composition (·) :: (a → b) → (b → c) →
(a → c). The resulting type from this constructor uses the input types from the
ﬁrst argument fs as, and the output types from the second argument hs cs. It
then forces the constraint that the output type of the ﬁrst argument and the
input type of the second are the same — gs bs.

The ‘Beside’ Constructor , denoted by <> is used to run two circuits at the same
time. The resulting Circuit has the types of the two circuits appended together.
(<>) :: (DataStore(cid:48) fs as, DataStore(cid:48) gs bs, DataStore(cid:48) hs cs, DataStore(cid:48) is ds)

⇒ Circuit fs as gs bs nfs → Circuit hs cs is ds nhs
→ Circuit (fs :++ hs) (as :++ cs) (gs :++ is) (bs :++ ds) (nfs :+nhs)

This constructor works by making use of the :++ type family to append the input
and output type list of the left constructor to those of the right constructor. It
also makes use of the :+ type family to sum the number of inputs.

Tasks are made using a smart constructor task, which requires a type level
Length. To save boiler-plate, CircuitFlow also provides more handy task smart
constructors such as functionTask. This particular smart constructor allows a
simple a → b function to be promoted to a task. It comes in useful returning
to the music preprocessing example as it simpliﬁes the deﬁnition of a task that
ﬁnds the top ten songs or artists: functionTask (take 10).

CircuitFlow

7

2.4 CircuitFlow in Action

preProcPipeline = organiseIns <−> (

(aggSongs <−> top10 "t10s.csv")
<> (aggArtists <−> top10 "t10a.csv"))

The above CircuitFlow circuit solves the music processing example. organiseIns
replicates the input values so that they are passed into both aggSongs and
aggArtists. Again, it can be seen how this structure of tasks directly correlates
with the dataﬂow diagram previously seen in Figure 1. This helps to make it
easier when designing circuits as it can be constructed visually level by level.

2.5 mapC operator

Currently a circuit has a static design: once created it cannot change. There are
times when this could be a ﬂaw in the language. For example, when there is a
dynamic number of inputs. CircuitFlow’s mapC allows for dynamic circuits. This
constructor maps a circuit on an input containing a list of items. The input is
fed one at a time into the inner circuit, accumulated back into a list, and then
output.

mapC :: (DataStore(cid:48) (cid:48)[f] (cid:48)[[a]], DataStore g [b])

⇒ Circuit (cid:48)[Var] (cid:48)[a] (cid:48)[Var] (cid:48)[b] N1 → Circuit (cid:48)[f] (cid:48)[[a]] (cid:48)[g] (cid:48)[[b]] N1

3 CircuitFlow Under the Hood

This section explores the embedding of the CircuitFlow language into Haskell and
how it is translated down to be executed.

3.1 Circuit API

The constructors for the language are actually smart constructors [35], providing
a more elegant way to build the AST that represents the circuit. They bring the
beneﬁts of extensibility and modularity usually found in a shallow embedding,
while still having a ﬁxed core AST that can be used for interpretation.

IFunctor The ﬁxed core AST is implemented via a jacked up version of the
traditional capturing of an abstract datatype as a ﬁxed Functor story [13]. Instead
of Functor, a type class called IFunctor [26] (also known as HFunctor [18]) is used
as it is able to maintain the type indices, which in the case of CircuitFlow, are the
all important dependency phantom type parameters. IFunctor can be thought of
as a Functor transformer: it is able to change the structure of a Functor, whilst
preserving the values inside it. IFunctors can also be used to mark recursive
points of data types, as long as they are paired with a matching IFix to tie the
recursive knot. As Circuit has ﬁve type parameters, it needs IFunctor5 and IFix5.

8

R. Evans et al.

type ((cid:32)) f g = ∀a.f a → g a
class IFunctor iF where

imap :: (f (cid:32) g) → iF f (cid:32) iF g

newtype IFix iF a

= IIn (iF (IFix iF) a)

class IFunctor5 iF where

imap5

:: (∀a ... e.f a ... e → g a ... e)
→ iF f a ... e → iF g a ... e

newtype IFix5 iF a ... e

= IIn5 (iF (IFix5 iF) a ... e)

Indexed Data types `a la carte When building an eDSL one problem that becomes
quickly prevalent is the so called Expression Problem [37]. A popular solution is
Data types `a la carte [36]: it combines constructors using the co-product of their
signatures. This technique makes use of standard functors, however, an approach
using IFunctors is described in Compositional data types [3]. This approach is
upgraded further to add support for ﬁve type indices:

data (iF :+: iG) (f’ :: i → j → k → l → m → ∗) (a :: i) ... (e :: m)

= L :: iF f’ a ... e → (iF :+: iG) f’ a ... e | R :: iG f’ a ... e → (iF :+: iG) f’ a ... e

Using the :+: operator comes with problem of many L’s and R’s, when creat-
ing the AST. The solution, extended from [36] to also accommodate ﬁve type
parameters, is to introduce a type class :≺: that injects them automatically.

Data types for each constructor can now be deﬁned individually. The Then
(<−>) constructor is used as an example, however, the process can be applied to
all constructors in the language.

data Then (iF :: [∗ → ∗] → [∗] → [∗ → ∗] → [∗] → Nat → ∗)

(insS :: [∗ → ∗]) (insT :: [∗])
(outsS :: [∗ → ∗]) (outsT :: [∗]) (nins :: Nat) where
Then :: (DataStore(cid:48) fs as, DataStore(cid:48) gs bs, DataStore(cid:48) hs cs)

⇒ iF fs as gs bs nfs → iF gs bs hs cs ngs → Then iF fs as hs cs nfs

Each iF denotes the recursive points in the data type, with the subsequent type
arguments mirroring those seen in Section 2.3. A corresponding IFunctor5 in-
stance formalises the points of recursion, by describing how to transform the
structure inside it. The smart constructor, that injects the L’s and R’s automat-
ically can be deﬁned for Then adding one extra constraint, to the constructor
deﬁned in Section 2.3 (Then :≺: iF), allowing the smart constructor to produce
a node in the AST for any sum of data types, that includes the Then data type.

Representing a Circuit Once each constructor has been deﬁned, they can be
combined together to form the CircuitF type to represent a circuit. IFix5 then
ties the recursive knot to deﬁne the Circuit type.

type CircuitF = Id :+: Replicate :+: Then :+: ... :+: Task :+: Map
type Circuit = IFix5 CircuitF

Now that it is possible to build a Circuit, which can be considered a speciﬁcation
for how to execute a set of tasks, there needs to be a mechanism in place to
execute the speciﬁcation.

CircuitFlow

9

3.2 Network Typeclass

A Network represents a mechanism for executing the computation described by a
Circuit. To allow for multiple execution mechanisms, a Network type class deﬁnes
the key features each network requires:

class Network n where

startNetwork :: Circuit insS insT outsS outsT nIns

→ IO (n insS insT outsS outsT)

stopNetwork :: n insS insT outsS outsT → IO ()
:: IHList insS insT
write
:: n insS insT outsS outsT → IO (IHList outsS outsT)
read

→ n insS insT outsS outsT → IO ()

This type class requires that a network has 4 diﬀerent functions: startNetwork
is responsible for converting the circuit into the underlying representation for a
process network: it will be discussed in more detail in Section 3.4; stopNetwork is
for cleaning up the network after it is no longer needed. For example, stopping
any threads running. This could be particularly important if embedding a circuit
into a larger program, where unused threads could be left hanging; write should
take some input values and add them into the network, so that they can be
processed; read should retrieve some output values from the network. nIns is
required for the translation of Circuit to Network, therefore it is not inluded in
the type of a network.

3.3 The Basic Network Representation

A BasicNetwork is an implementation of a Network that uses a Kahn Process
Network (KPN). This means that each task in a circuit will run on its own
separate thread, with inputs being passed between them on unbounded channels
(from Control.Concurrent). A BasicNetwork stores the multiple input and output
channels, to do so it leverages a special case of IHList.

data PipeList (fs :: [∗ → ∗]) (as :: [∗]) where

PipeCons :: Chan (f a) → PipeList fs as → PipeList (f (cid:48): fs) (a (cid:48): as)
PipeNil

:: PipeList (cid:48)[ ] (cid:48)[ ]

Using these PipeLists, BasicNetwork is deﬁned using record syntax allowing for
named ﬁelds, with accessors automatically generated.

data BasicNetwork (insS :: [∗ → ∗]) (insT :: [∗])

(outsS :: [∗ → ∗]) (outsT :: [∗]) where

BasicNetwork :: {

threads :: Map TaskUUID ThreadId,
:: Map JobUUID JobStatus,
jobs
:: PipeList inpS inpT,
ins
:: PipeList outsS outsT
outs

-- allows threads to be managed
-- avoids duplicate job UUIDs
-- to feed in inputs
-- to retrieve outputs

} → BasicNetwork inS insT outsS outsT

10

R. Evans et al.

The Network type instance for a BasicNetwork is relatively trivial to implement
using Control.Monad’s forM if given a function to transform a Circuit to it.

instance Network BasicNetwork where
startNetwork = buildBasicNetwork
stopNetwork n = forM (threads n) killThread
write uuid xs n = writePipes xs (ins n)
read n

= readPipes (outs n)

-- Deﬁned soon...

The writePipes function will input a list of values into each of the respective
pipes. The readPipes function will make a blocking call to each channel to read
an output from it. This function will block till an output is read from every
output channel.

3.4 Translation to a BasicNetwork

There is now a representation for a Circuit that the user will build, and a repre-
sentation used to execute the Circuit. However, there is no mechanism to convert
between them. This can be achieved by folding the circuit data type into a net-
work. This fold, however, will need to create threads and channels, both of which
are IO actions, and of course it will also need to deal with the numerous type
parameters of Circuit. Such requirements lead to an exciting take on the cata-
morphism method for performing generalised folding of an abstract datatype.

Indexed Monadic Catamorphism The use of a catamorphism removes the
recursion from any folding of the datatype. This means that the algebra can
focus on one layer at a time. This also ensures that there is no re-computation
of recursive calls, as this is all handled by the catamorphism. icata is able to
fold an IFix iF a and produce an item of type f a. It uses the algebra argument
as a speciﬁcation of how to transform a single layer of the datatype. Normal
catamorphisms can use monadic computations if deﬁned as follows:

cataM :: (Traversable f, Monad m) ⇒ (∀a.f a → m a) → Fix f → m a
cataM algM (In x) = algM =<< mapM (cataM algM) x

This monadic catamorphism [12] follows a similar pattern to a standard catamor-
phism, but instead uses functions such as a monadic map — mapM :: Monad m ⇒
(a → m b) → f a → m (f b). This allows the monadic catamorphism to be applied
recursively on the data type being folded.

A similar technique can also be applied to indexed catamorphisms to gain
a monadic version [3], however, to do so an indexed monadic map has to be
introduced. imapM is the indexed equivalent of mapM, it performs a natural
transformation, but is capable of also using monadic computation. This is in-
cluded in the IFunctor type class, and facilitates the deﬁnition of icataM.

For Circuit, there is one ﬁnal step that needs to be done: accommodating the
ﬁve type parameters. To do this, IFunctor’s imapM gets gifted the type parameters
to complete the IFunctor5 class and allow the deﬁnition of icataM5.

CircuitFlow

11

BuildNetworkAlg The ﬁnal piece of the translation puzzle is an algebra for
the fold. However, a standard algebra will not be able to complete this trans-
formation. Consider an example Circuit with two tasks executed in sequence:
task1 <−> task2. In a standard algebra, both sides of the Then constructor would
be evaluated independently. In this case it would produce two disjoint networks,
both with their own input and output channels. The algebra for Then, would
then need to join the output channels of task1 with the input channels of task2.
However, it is not possible to join channels together. Instead, the output chan-
nels from task1 need to be accessible when creating task2. This is referred to as
a context-sensitive or accumulating fold. An accumulating fold forms series of
nested functions, that collapse to give a ﬁnal value once the base case has been
applied. A simple example of an accumulating fold could be, implementing foldl
in terms of foldr.

To be able to have an accumulating fold inside an indexed catamorphism a
carrier data type is required to wrap up this function. This carrier, which shall
be named AccuN, contains a function that when given a network that has been
accumulated up to that point, then it is able to produce a network including the
next layer in a circuit. This can be likened to the lambda function given to foldr,
when deﬁning foldl. The type of the layer being folded will be Circuit a b c d e.

newtype AccuN n asS asT a b c d e = AccuN

{unAccuN :: n asS asT a b → IO (n asS asT c d)}

This newtype has two additional type parameters at the beginning, namely:
asS and asT. They represent the input types to the initial circuit. Since the
accumulating fold will work layer by layer from the top downwards, these types
will remain constant and never change throughout the fold.

Classy Algebra To ensure that the approach remains modular, the algebra takes
the form of a type class: the interpretation of a new constructor is just a new
type class instance.

class (Network n, IFunctor5 iF) ⇒ BuildNetworkAlg n iF where

buildNetworkAlg :: iF ( AccuN n asS asT) bsS bsT csS csT nbs
→ IO ((AccuN n asS asT) bsS bsT csS csT nbs)

This algebra type class takes two parameters: n and iF. The n is constrained
to have a Network instance, this allows the same algebra to be used for deﬁning
folds for multiple network types. The iF is the IFunctor that this instance is being
deﬁned for, an example is Then or Id. This algebra uses the AccuN data type to
perform an accumulating fold. The input to the algebra is an IFunctor with the
inner elements containing values of type AccuN. The function can be retrieved
from inside AccuN to perform steps that are dependent on the previous, for
example, in the Then constructor.

The Initial Network Given the use of an accumulating fold, one important ques-
tion needs to be answered: what happens on the ﬁrst layer? The fold needs an
initialNetwork that has matching input and output types:

12

R. Evans et al.

initialNetwork

:: ∀insS insT.(InitialPipes insS insT) ⇒ IO (BasicNetwork insS insT insS insT)

initialNetwork = do

ps ← initialPipes :: IO (PipeList insS insT)
return (BasicNetwork empty empty ps ps)

The InitialPipes type class constructs an initialPipes based on the type required
in the initial network.

The Translation Now that the algebra type class, and the initial input to the
accumulating fold is deﬁned, each instance of the type class can be deﬁned.

Basic Constructors There are several constructors that just manipulate the out-
put PipeList, these constructors are Id, Replicate, Swap, DropL, and DropR. The
Swap constructor takes two inputs and then swaps them over:

instance BuildNetworkAlg BasicNetwork Swap where
buildNetworkAlg Swap = return $ AccuN (λn → do
let PipeCons c1 (PipeCons c2 PipeNil) = outs n
return $ BasicNetwork

(threads n) (jobs n) (ins n)
(PipeCons c2 (PipeCons c1 PipeNil)))

The instance for Swap, deﬁnes a function wrapped by AccuN, that takes the
current accumulated network, up to this point. It then transforms the outputs by
swapping c1 and c2, and building a new BasicNetwork. All other leaf constructors
will follow this pattern.

Task In a BasicNetwork, a task will run as a separate thread, to do this forkIO ::
IO () → IO ThreadId will be used. Using this function requires some IO () com-
putation to run, this will be deﬁned by taskExecutor, which will read a value
from each of input channels, execute the task with those inputs, and then write
the output to the output channels. This computation is then repeated forever.
Making use of the taskExecutor, the algebra instance for Task is as:

instance BuildNetworkAlg BasicNetwork Task where

buildNetworkAlg (Task t) = return $ AccuN (λn → do

← PipeCons <$> newChan <∗> return PipeNil

out
taskUUID ← genUnusedTaskUUID (threads n)
threadId ← forkIO (taskExecuter (Task t) taskUUID (outputs n) output)
return $ BasicNetwork

(M.insert taskUUID threadId (threads n)) (jobs n) (inputs n) output

This instance ﬁrst creates a new output channel, this will be given to the task to
send its outputs on. It then forks a new thread with the computation generated
by taskExecutor. The executor is given the output values of the accumulated
network and the output channel, just created. The resulting network has the
same inputs, but now adds a new thread id to the list and the outputs set to be
the output channels from the task.

CircuitFlow

13

Then The Then constructor is responsible for connecting circuits in sequence.
When converting this to a network, this will involve making use of the accumu-
lated network value to generate the next layer. The instance is deﬁned as:

instance BuildNetworkAlg BasicNetwork Then where

buildNetworkAlg (Then (AccuN fx) (AccuN fy))

= return $ AccuN (fx >=> fy)

This instance has an interesting deﬁnition: ﬁrstly it takes the accumulated net-
work n as input. It then uses the function fx, with the input n to generate a
network for the top half of the Then constructor. Finally, it takes the returned
network, from the top half of the constructor, and generates a network using the
function fy representing the bottom half of the constructor.

Beside The Beside (<>) constructor places two circuits side by side. This is the
most tedious algebra to deﬁne as the accumulated network needs to be split in
half to pass to the two recursive sides of Beside. Details of its translation can be
found in Appendix E.

CircuitFlow also uses the ExceptT monad transformer to fail gracefully.

4 Benchmarks

We use the audio streaming example from Section 2 to perform the benchmark-
ing. It is also the main application domain of Luigi which we will compare with.
Haskell benchmarks were taken using criterion [29]; Python 3.8.5 benchmarks
with pytest − benchmark [23]. Each benchmark is tested on thirteen diﬀerent
numbers of inputs: 1, 10, 100, 200, then at intervals of 200 until 2000, with
measurements repeated and summarised as a mean average.

Three months of one of the author’s own audio history is used, to ensure that
the data closely aligns with the real world. This allows for the evaluation of how
each implementation scales with more inputs. All benchmarks take place on an
Intel(R) Core(TM) i5-4690 CPU at 3.50GHz (4 cores and no hyper-threading),
with 8GB of RAM booting Ubuntu 20.04.

Multi-Core Haskell By default the Haskell runtime does not enable multi-core
processing. Considering the aim of this project partly involves making CircuitFlow
run in parallel, multi-core processing is crucial. To enable this the -threaded
ﬂag is set when building the binary. Then, using the runtime options, the number
of threads can be set by adding +RTS -N ﬂags when running the binary. The -N
allows the runtime to select the optimal number of threads for the program.

Parallel vs Serial The ﬁrst test will ensure that CircuitFlow’s parallelisation
has a positive eﬀect on run-times. To ensure that the test is fair, the serial
implementation will make use of the same tasks in the pre-processing pipeline.
The inputs and outputs will just be manually fed into each task, in a sequential

14

R. Evans et al.

way. The results show that CircuitFlow does indeed provide a performance gain,
with a mean speedup of 1.53x.

Proﬁling the circuit shows that a signiﬁcant proportion of time is spend
reading CSV ﬁles. Optimising speed of CSV parsing and how often a CSV is read
via caching would improve runtime. Another area for improvement is that there
is an expectation on the user to know where is best to split up the workﬂow into
tasks. It would be beneﬁcial if a circuit could automatically fuse tasks together,
then it would have a positive eﬀect on the runtime.

Single-core CircuitFlow
Serial

CircuitFlow
Luigi

)
s
(

e
m

i
t
n
u
R

600

400

200

0

500

1,000
Number of inputs

1,500

2,000

0

500

1,000
Number of inputs

1,500

2,000

200

100

)
s
(

e
m

i
t
n
u
R

0

0

(a) Linear

(b) Vs Luigi

Fig. 3: CircuitFlow benchmarks

1 Core Circuit vs Serial Another interesting scenario to test is checking if
the network structure adds additional overhead, in a situation where there is
only 1 core. To test this, the multi-core support of the Haskell runtime will
not be enabled: this will then simulate multiple cores with context switching.
Figure 3a, shows the results of this benchmark. It shows that both the linear and
single core implementation scale together in a linear fashion. Most importantly,
CircuitFlow only adds a minor overhead over a linear implementation. This will
be particularly helpful for a user which needs to run code on multiple types
of devices. There is no need for them to create a diﬀerent implementation for
devices where parallelisation may not be possible.

CircuitFlow vs Luigi The ﬁnal benchmark on CircuitFlow is comparing it to
widely used library: Luigi by Spotify [33]. Since Luigi uses a Data Process Net-
work (DPN), it can use any number of threads: in this test it is set to 4 — the
same as CircuitFlow. Figure 3b, shows the results of the benchmark.

This shows that CircuitFlow performs better than Luigi on larger numbers
of inputs. CircuitFlow scales linearly with the number of inputs, whereas Luigi’s
runtime appears to grow at a quicker rate than linear.

Why is CircuitFlow so good? Luigi and CircuitFlow have their diﬀerences,
which will likely explain why there is a diﬀerence in run times, especially with
larger numbers of inputs.

CircuitFlow

15

More Lightweight Luigi is a far more complex library with advanced features,
not included in CircuitFlow, that may slow Luigi down — one such feature is back
ﬁlling. This allows Luigi to avoid running tasks that have already been run. This
feature means that before executing a task the Luigi scheduler has to check if a
task has already been executed. This adds additional overhead to the scheduler
that CircuitFlow does not have. Although this feature does have its beneﬁts, after
the ﬁrst run of Luigi all run times after are very quick as no tasks will need to be
executed. If CircuitFlow were to implement this feature any overhead it adds will
be partially mitigated by the checks being distributed across multiple threads,
instead of in one central scheduler.

Computation Models The two libraries use variants of the same computation
model: CircuitFlow uses a KPN and Luigi uses a DPN [22]. This diﬀerence is
the main reason why CircuitFlow scales linearly when it needs to process more
input values. CircuitFlow makes use of buﬀered channels to keep a queue of all
inputs that need to be processed. However, Luigi does not rely on this design,
instead it has a pool of workers with a scheduler controlling what is executed
on each worker. It is this scheduler that causes Luigi to scale non-linearly. As
the number of inputs grow, the scheduler will have to schedule more and more
tasks: this process is not O(n).

Multi-processing in Python CircuitFlow makes use of a static number of threads
deﬁned by the number of tasks in a circuit. Luigi on the other hand can support
any number of workers, however, Luigi suﬀers from a downfall of Python: threads
cannot run in parallel due to the Global Interpreter Lock. To avoid this Luigi
uses processes not threads, which adds extra overhead. Luigi also creates a new
process for each invocation of a task, which CircuitFlow does not do. This means
that Luigi will start 8000 processes vs CircuitFlow’s 4 threads for the 2000 inputs
benchmark. CircuitFlow’s static number of threads could also be considered a
downside due to the lack of ﬂexibility depending on run-time values. To combat
this more combinators can be introduced that allow for branching or other similar
operations, in fact, mapC is a combinator of this type.

5 Discussion and Related Work

In this section, we cover the embedding techniques that we build upon and how
our process can be replicated. We also discuss other popular workﬂow libraries
including imperative and functional ones, comparing them to CircuitFlow.

Summary of Embedding Techniques and their General Use. CircuitFlow, which
can be more generally be seen as an eDSL whose semantics needs to use ef-
fects and has rich types to verify program correctness, has been created in a
modular manner that doesn’t compromise on performance. The pivotal parts
of CircuitFlow’s creation can be replicated to produce such other eDSLs. The
process is one of three parts. The ﬁrst is the curation of the type information. In

16

R. Evans et al.

the case of CircuitFlow, this was dependency information, and was achieved using
Haskell’s approximation of dependant types (DataKinds [39] and Singletons [10]
for value promotion/demotion to/from the type level; Type Families [32] for
type information manipulation; and Heterogeneous lists [19] for, well, storing
more than one type in a list). The second act follows the same beats as the clas-
sic embedding story [13]: each construct is created as a separate ﬁxed functor,
where all constructs can be composed together with the beloved Data types `a la
carte, and semantics provided through a “classy” algebra. The story just needs
to be jacked up to accommodate the type information and eﬀects, with the trick
being the switch to indexed functors [26, 18] and a monadic catamorphism [12].
Finally, the choice of underlying semantics is key for speed as that is ultimately
what will be running. Our choice of KPNs assisted us greatly with CircuitFlow’s
competitive run-time.

Applicative Functors An example of capturing parallelism in Haskell is to use
applicative functors [27] — a technique employed by the Haxl library [24]. This
approach can leverage the applicative combinators to group together compu-
tation that can be performed simultaneously. There is even the ApplicativeDo
language extension [25], which desugars do notation down to applicative combi-
nators. However, this approach suﬀers from some forced sequentiality at points.
Take the previously mentioned example Figure 1, both top ten tasks would be
grouped together. Leading to neither task being able to begin until both aggre-
gations have been completed.

Arrows Another method is arrows [16], used by Funﬂow based on Composing
Eﬀects into Tasks and Workﬂows [30]. Arrows similarly are often used through
with the notation obtained from the language extension [31], which introduces
a do style notation. They also fall victim to the same problems as applicative
functors. Due to the constructor arr consuming a function, it is not possible to
inspect inside and fully exploit all cases of parallelisation.

The Funﬂow library that makes use of arrows, does so by noticing that tasks
in workﬂows are similar to eﬀects in the functional community. It draws from
existing work on combining and analysing eﬀects, with categories and arrows,
and applies this to constructing workﬂows.

Symmetric Monoidal Categories (SMCs) Linear Haskell is put to excellent use
in Evaluating Linear Functions to Symmetric Monoidal Categories [4] to address
the problem of over sequentialisation found in applicative functors and arrows. It
introduces a new SMC type class that allows for all parallelism to be exposed and
exploited in a workﬂow. The type class adds new combinators for linear Haskell
functions, that can be composed in a style that aligns with do notation. It uses
atomic types to detail the synchronisation points, and where synchronisation
can be discovered by a scheduler. However, it comes with the caveat that it can
only compose linear functions.

CircuitFlow

17

Pipes [14]
focuses on supporting steaming data, which is beneﬁcial as there
is no need to wait for jobs to ﬁnish before moving on. This is something that
CircuitFlow is also designed to support without any modiﬁcations: a network can
be started and inputs can be streamed in when they are available.

Luigi [33] Industry-favourite Luigi, used to orchestrate tasks in a data work-
ﬂow, is a library that, as we have seen, falls into the trap of un-typed task
dependencies. It makes use of a central scheduler and workers, allowing work to
be distributed across multiple machines. It also comes with built-in support for
many diﬀerent output formats, such as ﬁles in a Hadoop ﬁle system.

SciPipe [21] An approach for orchestrating external jobs is taken by SciPipe, a
workﬂow library for agile development of complex and dynamic bioinformatics
pipelines. Unlike CircuitFlow and many other libraries, instead of deﬁning tasks
as functions within the embedding language, SciPipe uses Bash commands to
easily interact with pre-existing binaries. This allows task to be written in the
language most suited for its requirements, however, comes with the downside
of the additional infrastructure required to create all these binaries for each
task. Due to the separation of tasks into bash scripts, type checking interactions
between tasks is signiﬁcantly harder.

Other Typed Dataﬂow Libraries DryadLINQ [40] allows for developers to cre-
ate parallel programs in SQL-like LINQ expressions. Similarly to CircuitFlow,
these can be inspected to ﬁnd any data-parallel sections and then automatically
translated into a distributed execution plan that can run on Dryad — although
CircuitFlow currently lacks a distributed network implementation. FlumeJava [5],
uses lazy evaluation of operations on parallel data structures, to build a dataﬂow
graph of the steps required. When the value is required the graph is optimised
to evaluate the operations in an optimal way. Unlike CircuitFlow, Naiad [28] can
execute cyclic dataﬂow programs. It does so on a distributed system, to help
with streaming data analysis or iterative machine learning training.

Staged Selective Parser Combinators [38] Indexed functors [26], are a new tech-
nique for building typed eDSL. This paper makes use of this new tool to have a
type index representing the type of a parser. This allows it to make optimisations
and translations while ensuring that the value parsed never changes.

6 Conclusion

This paper introduced a new eDSL to declaratively construct data workﬂows,
which are type-safe and competitive in run-time performance. The design of
CircuitFlow draws its origins from a strong mathematical background, with each
constructor directly representing an axiom in a SMP. This demonstrates the lan-
guage’s completeness at being able to represent any DAG, that a data workﬂow
may need. The battle for type-safety without compromising run-time or modu-
lar design was a tough one, but one that can be replicated to great avail when
creating languages with a similar requirements.

18

R. Evans et al.

Acknowledgements. The authors would like to thank Jamie Willis for his
insights while creating CircuitFlow and the anonymous reviewers for their con-
structive and helpful comments.

The work is partly supported by EPSRC Grant EXHIBIT: Expressive High-
Level Languages for Bidirectional Transformations (EP/T008911/1) and Royal
Society Grant Bidirectional Compiler for Software Evolution (IESR3170104).

References

1. Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghe-
mawat, S., Irving, G., Isard, M., Kudlur, M., Levenberg, J., Monga, R., Moore,
S., Murray, D.G., Steiner, B., Tucker, P., Vasudevan, V., Warden, P., Wicke, M.,
Yu, Y., Zheng, X.: Tensorﬂow: A system for large-scale machine learning. In: 12th
USENIX Symposium on Operating Systems Design and Implementation (OSDI
16). pp. 265–283. USENIX Association, Savannah, GA (Nov 2016)

2. Apache: Airﬂow, http://airﬂow.apache.org
3. Bahr, P., Hvitved, T.: Compositional data types. In: Proceedings of the Seventh
ACM SIGPLAN Workshop on Generic Programming. p. 83–94. WGP ’11, Associ-
ation for Computing Machinery, New York, NY, USA (2011)

4. Bernardy, J.P., Spiwack, A.: Evaluating linear functions to symmetric monoidal
categories. In: Proceedings of the 14th ACM SIGPLAN International Symposium
on Haskell. p. 14–26. Haskell 2021, Association for Computing Machinery, New
York, NY, USA (2021)

5. Chambers, C., Raniwala, A., Perry, F., Adams, S., Henry, R., Bradshaw, R.,
Nathan: Flumejava: Easy, eﬃcient data-parallel pipelines. In: ACM SIGPLAN
Conference on Programming Language Design and Implementation (PLDI). pp.
363–375. 2 Penn Plaza, Suite 701 New York, NY 10121-0701 (2010)

6. Cheney, J., Hinze, R.: First-class phantom types (Jan 2003)
7. Coecke, B., Fritz, T., Spekkens, R.W.: A mathematical theory of resources. Infor-

mation and Computation 250, 59–86 (Oct 2016)

8. Dennis, J.B., Misunas, D.P.: A preliminary architecture for a basic data-ﬂow pro-
cessor. In: Proceedings of the 2nd Annual Symposium on Computer Architecture.
p. 126–132. ISCA ’75, Association for Computing Machinery, New York, NY, USA
(1974)

9. Eisenberg, R.A., Vytiniotis, D., Peyton Jones, S., Weirich, S.: Closed type families
with overlapping equations. In: Proceedings of the 41st ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages. p. 671–683. POPL ’14, As-
sociation for Computing Machinery, New York, NY, USA (2014)

10. Eisenberg, R.A., Weirich, S.: Dependently typed programming with singletons. In:
Proceedings of the 2012 Haskell Symposium. p. 117–130. Haskell ’12, Association
for Computing Machinery, New York, NY, USA (2012)

11. Erdmann, M., Fischer, B., Fischer, R., Rieger, M.: Design and execution of make-
like, distributed analyses based on spotify’s pipelining package luigi. Journal of
Physics: Conference Series 898, 072047 (Oct 2017)

12. Fokkinga, M.: Monadic maps and folds for arbitrary datatypes. Memoranda
imported from EWI/DB PMS [db-

– (Jun 1994),

informatica (94-28),
utwente:tech:0000003538]

CircuitFlow

19

13. Gibbons, J., Wu, N.: Folding domain-speciﬁc languages: Deep and shallow embed-
dings (functional pearl). Proceedings of the ACM SIGPLAN International Confer-
ence on Functional Programming, ICFP 49 (Aug 2014)

14. Gonzalez, G.: pipes, https://hackage.haskell.org/package/pipes
15. Hils, D.D.: Visual languages and computing survey: Data ﬂow visual programming

languages. J. Vis. Lang. Comput. 3, 69–101 (1992)

16. Hughes, J.: Generalising monads to arrows. Science of Computer Programming

37(1), 67–111 (2000)

17. Inc, A.: Quartz composer user guide (Jul 2007)
18. Johann, P., Ghani, N.: Foundations for structured programming with gadts. In:
Proceedings of the 35th Annual ACM SIGPLAN-SIGACT Symposium on Princi-
ples of Programming Languages. p. 297–308. POPL ’08, Association for Computing
Machinery, New York, NY, USA (2008)

19. Kiselyov, O., L¨ammel, R., Schupke, K.: Strongly typed heterogeneous collections.
In: Proceedings of the 2004 ACM SIGPLAN Workshop on Haskell. p. 96–107.
Haskell ’04, Association for Computing Machinery, New York, NY, USA (2004)
20. Kotliar, M., Kartashov, A.V., Barski, A.: CWL-Airﬂow: a lightweight pipeline
manager supporting Common Workﬂow Language. GigaScience 8(7) (Jul 2019),
giz084

21. Lampa, S., Dahl¨o, M., Alvarsson, J., Spjuth, O.: SciPipe: A workﬂow library for
agile development of complex and dynamic bioinformatics pipelines. GigaScience
8(5) (Apr 2019), giz044

22. Lee, E.A., Parks, T.M.: Dataﬂow process networks. Proceedings of the IEEE 83(5),

773–801 (1995)

23. Maries, I.C.: time, https://pypi.org/project/pytest-benchmark/
24. Marlow, S., Brandy, L., Coens, J., Purdy, J.: There is no fork: An abstraction for ef-
ﬁcient, concurrent, and concise data access. In: Proceedings of the 19th ACM SIG-
PLAN International Conference on Functional Programming. p. 325–337. ICFP
’14, Association for Computing Machinery, New York, NY, USA (2014)

25. Marlow, S., Peyton Jones, S., Kmett, E., Mokhov, A.: Desugaring haskell’s do-
notation into applicative operations. SIGPLAN Not. 51(12), 92–104 (Sep 2016)
26. McBride, C.: Functional pearl: Kleisli arrows of outrageous fortune. Journal of

Functional Programming (accepted for publication) (2011)

27. Mcbride, C., Paterson, R.: Applicative programming with eﬀects. J. Funct. Pro-

gram. 18(1), 1–13 (Jan 2008)

28. Murray, D., McSherry, F., Isaacs, R., Isard, M., Barham, P., Abadi, M.: Naiad: A
timely dataﬂow system. In: Proceedings of the 24th ACM Symposium on Operating
Systems Principles (SOSP). p. 439–455. ACM (Nov 2013)
29. O’Sullivan, B.: criterion, http://www.serpentine.com/criterion/
30. Par`es, Y., Bernardy, J.P., Eisenberg, R.A.: Composing eﬀects into tasks and work-
ﬂows. In: Proceedings of the 13th ACM SIGPLAN International Symposium on
Haskell. p. 80–94. Haskell 2020, Association for Computing Machinery, New York,
NY, USA (2020)

31. Paterson, R.: A new notation for arrows. In: International Conference on Functional

Programming. pp. 229–240. ACM Press (Sep 2001)

32. Schrijvers, T., Peyton Jones, S., Chakravarty, M., Sulzmann, M.: Type checking
with open type functions. In: Proceedings of the 13th ACM SIGPLAN Interna-
tional Conference on Functional Programming. p. 51–62. ICFP ’08, Association
for Computing Machinery, New York, NY, USA (2008)

33. Spotify: Spotify: Luigi, https://github.com/spotify/luigi

20

R. Evans et al.

34. Spotify: Tasks (Apr 2020), https://luigi.readthedocs.io/en/stable/tasks.html
35. Svenningsson, J., Axelsson, E.: Combining deep and shallow embedding of domain-
speciﬁc languages. Computer Languages, Systems & Structures 44, 143–165 (2015),
sI: TFP 2011/12

36. Swierstra, W.: Data types `a la carte. Journal of Functional Programming 18(4),

423–436 (2008)

37. Wadler, P.: The expression problem (Nov 1998)
38. Willis, J., Wu, N., Pickering, M.: Staged selective parser combinators. Proc. ACM

Program. Lang. 4(ICFP), 1–30 (Aug 2020)

39. Yorgey, B.A., Weirich, S., Cretin, J., Peyton Jones, S., Vytiniotis, D., Magalh˜aes,
J.P.: Giving haskell a promotion. In: Proceedings of the 8th ACM SIGPLAN Work-
shop on Types in Language Design and Implementation. p. 53–66. TLDI ’12, As-
sociation for Computing Machinery, New York, NY, USA (2012)

40. Yu, Y., Isard, M., Fetterly, D., Budiu, M., Erlingsson, U., Gunda, P.K., Currey, J.:
Dryadlinq: A system for general-purpose distributed data-parallel computing using
a high-level language. In: Proceedings of the 8th USENIX Conference on Operating
Systems Design and Implementation. p. 1–14. OSDI’08, USENIX Association, USA
(2008)

41. Zaharia, M., Chowdhury, M., Franklin, M.J., Shenker, S., Stoica, I.: Spark: Cluster
computing with working sets. In: Proceedings of the 2nd USENIX Conference on
Hot Topics in Cloud Computing. p. 10. HotCloud’10, USENIX Association, USA
(2010)

Appendices

A Type Heft

CircuitFlow is crafted using a good proportion of the type heft that Haskell can
muster. Herein lies the reason that creating a standalone language was simply
out of the question.

This section provides a quick rundown of the Haskell type magic used to

create CircuitFlow.

A.1 Dependently Typed Programming

Although Haskell does not oﬃcially support dependently typed programming,
there are techniques available that together can be used to replicate some of the
experience.

– DataKinds [39] allows for values to be promoted to types. When constructors
are promoted to type constructors, they are preﬁxed with a (cid:48) . This allows
for more interesting and restrictive types such as vectors that store their
length at the type level.

– Singletons [10] allow types to be demoted to values. They are called sin-
gletons because they only have one inhabitant - one possible value for each
type. This way the constructed type can reﬂect its type back to the value
level. An example usage is recovering the length of a vector as a singleton
SNat value.

– Type Families [32] can be used to deﬁne functions that manipulate types.
Type level functions are deﬁned just like normal Haskell functions: by pattern
matching on the constructors, they just have slightly diﬀerent syntax.

– Heterogeneous lists [19] leverage the promotion of values to the type level to
allow for lists of multiple types. Rather than be parameterised by a single
type, they instead make use of a type list, which is the list type promoted
through DataKinds to be a kind, with its elements being types. Each element
in the type list aligns with the value at that position in the list, giving its
type. A heterogeneous list is deﬁned as:

data HList (xs :: [Type]) where

:: HList (cid:48)[ ]

HNil
HCons :: x → HList xs → HList (x (cid:48): xs)

A.2 Phantom Types

Phantom type parameters [6] are when a type variable only appears on the
left hand side of the equals. The most basic example is Const, it has two type

22

R. Evans et al.

arguments, but only a is used on the right hand side. Phantom type parameters
can be used to store information in the types, which can act as further static
constraints on the types.

B Build System (lhs2TeX)

Another use case for a task based dependency system is a build system. For
example, a Makeﬁle is a way of specifying the target ﬁles from some source ﬁles,
with a command that can be used to generate the target ﬁle. CircuitFlow: could
also be used to model such a system.

Consider this paper, which is made using LATEX. This project is made up of
multiple subﬁles, each written in a literate Haskell format. Each of these ﬁles
needs to be pre-processed by the lhs2TeX command to produce the .tex source
ﬁle. Once each of these ﬁles has been generated, then the LATEXproject can be
built into a PDF ﬁle.

B.1 Building the Circuit

The Circuit deﬁned here makes use of the mapC operator. To do so a Circuit is
deﬁned that is able to build a single .tex ﬁle from a .lhs. This has to make use
of the standard task constructor:

lhs2TexTask :: Circuit (cid:48)[Var] (cid:48)[String] (cid:48)[Var] (cid:48)[String] N1
lhs2TexTask = task f
where

f :: IHList (cid:48)[Var] (cid:48)[String] → Var String → ExceptT SomeException IO ()
f input output = lift (do

HCons fInName HNil ← fetch’ input
let fOutName = fInName−<.> "tex"
callCommand

("lhs2tex -o " ++ fOutName ++ " " ++ fInName ++ " > lhs2tex.log")

save output fOutName)

This Circuit makes use of the callCommand function from the System.Process
library. This allows the task to execute external commands, that may not nec-
essarily be deﬁned in Haskell. A similar Circuit can be deﬁned that will compile
the .tex ﬁles and produce a PDF.

CircuitFlow

23

buildTexTask :: String → String → Circuit (cid:48)[Var] (cid:48)[[String]] (cid:48)[Var] (cid:48)[String] N1
buildTexTask outputFileName mainFileName = task f
where

f :: IHList (cid:48)[Var] (cid:48)[[String]] → Var String → ExceptT SomeException IO ()
f

output = lift (do
callCommand

("texfot --no-stderr latexmk -interaction=nonstopmode "
++ "-pdf -no-shell-escape -bibtex -jobname="
++ outputFileName
++ " "
++ mainFileName
)

save output (outputFileName <.> "pdf"))

The buildTexTask also demonstrates how it is possible to pass a global pa-
rameter into a task. This can allow tasks to be made in a more reusable way.
Saving a user from deﬁning multiple variations of the same task.

These two tasks can now be combined into a Circuit. This Circuit can be
interpreted as inputting a list of .lhs ﬁles, which are sequentially compiled to
.tex ﬁles by the mapC operator. These ﬁles are then built by the buildTexTask
to produce a PDF ﬁle as output.

buildPipeline :: String → String → Circuit (cid:48)[Var] (cid:48)[[String]] (cid:48)[Var] (cid:48)[String] N1
buildPipeline outputFileName mainFileName =

mapC lhs2TexTask
<−>
buildTexTask outputFileName mainFileName

B.2 Using the Circuit

To use this Circuit, a Conﬁg data type is used to store the information needed
within the system to build the project:

data Conﬁg = Conﬁg

:: FilePath

{mainFile
, outputName :: String
, lhsFiles
}
deriving (Generic, FromJSON, Show)

:: [FilePath]

This data type uses record syntax to have name ﬁelds:

– mainFile is the name of the root ﬁle that should be used for compilation.
– outputName is the desired name for the output PDF ﬁle.
– lhsFiles are all the literate haskell ﬁles required to build the LATEXdocument.

24

R. Evans et al.

The Conﬁg data type also derives the Generic and FromJSON instance. This
allows it to be used in conjunction with a YAML ﬁle to specify these parameters.
The conﬁg can be loaded with:

loadConﬁg :: IO Conﬁg
loadConﬁg = loadYamlSettings ["dissertation.tex-build"] [ ] ignoreEnv

An example conﬁg ﬁle can be seen in Figure 4.

m a i n F i l e : d i s s e r t a t i o n . l h s
outputName : d i s s e r t a t i o n
l h s F i l e s :

[ d i s s e r t a t i o n . l h s

, c h a p t e r s / i n t r o d u c t i o n . l h s
, c h a p t e r s / background . l h s
, c h a p t e r s / the−l a n g u a g e . l h s
, c h a p t e r s / i m p l e m e n t a t i o n . l h s
, c h a p t e r s / e v a l u a t i o n . l h s
, c h a p t e r s / examples . l h s ]

Fig. 4: An example conﬁg ﬁle for the lhs2TeX build system

To be able to use the system a main function is deﬁned, which will serve as

the entry point to the executable:

main :: IO ()
main = do

conﬁg ← loadConﬁg
n ← startNetwork (buildPipeline (outputName conﬁg) (mainFile conﬁg)) :: IO

(BasicNetwork (cid:48)[Var] (cid:48)[[String]] (cid:48)[Var] (cid:48)[String])

inputJobUUID ← genJobUUID
inputTaskUUID ← genTaskUUID
(inputVar :: Var [FilePath]) ← empty inputTaskUUID inputJobUUID
save inputVar (lhsFiles conﬁg)
write inputJobUUID (HCons’ inputVar HNil’) n

← read n
stopNetwork n

The main function in the build system has 5 steps:

1. The conﬁg ﬁle is loaded.
2. A network is started based on the buildDiss circuit. The type of network to be
started has to be annotated, so that the type system knows which Network
instance to use.

3. The build job is input into the network, with the input values being a list of

.lhs ﬁles to compile.

CircuitFlow

25

4. A call is made to the blocking function read, although the outputs are not
needed, the call to read is. This prevents the program ending before the
network has complete processing values.

5. Finally, the network is destroyed.

The thesis this paper is based on makes use of this build system to be able

include literate Haskell ﬁles.

C Monoidal Resource Theories

Resource theories [7] are a branch of mathematics that allow for the reasoning
of questions surrounding resources, for example: If I have some resources, can I
make something? If I have some resources, how can I get what I want? Questions
that are eerily familiar to the questions addressed by dataﬂow: If I have some
inputs, can I make an output? If I have some inputs, how can I get the output
I want? Resource theories provide a way to answer these questions, making
them an excellent source of inspiration for our dataﬂow language. They combine
preorders and symmetric monoids together to describe collections of resources
(or inputs) and dependencies between them.

Symmetric Monoids are monoids with the following additional axiom:

∀x, y ∈ X, x ⊗ y = y ⊗ x (Symmetry).

SMPs A symmetric monoidal structure (X, I, ⊗) on a preorder (X, ≤) encap-
sulates this respect of the preorder as an additional axiom: ∀x1, x2, y1, y2 ∈ X,
if x1 ≤ y1 and x2 ≤ y2, then x1 ⊗ x2 ≤ y1 ⊗ y2 (Monotonicity). One example
is where X is a collection of resources, ⊗ combines resources together, and ≤
deﬁnes dependencies between resources.

Wiring Diagrams: A graphical representation of SMPs is a wiring diagram,
similar to DAGs. A wiring diagram is made up of boxes that can have multiple
inputs and outputs. The boxes can be arranged in series or in parallel. Figure 5a,
shows an example wiring diagram.

a

b

≤

≤

c

d

f

≤

e

x

x

x

(a) Example diagram

(b) Discard diagram

(c) Copy diagram

A wiring diagram formalises a SMP, with each element x ∈ X existing as the
label on a wire. Two wires, x and y, drawn in parallel are considered to be the
monoidal product x ⊗ y. The monodial unit is deﬁned as a wire with the label
I or no wire.

26

R. Evans et al.

x

y

A box connects parallel wires on the left to parallel wires on the right. A
wiring diagram is considered valid if the monoidal product of the left is less than
the right.

x1
x2
x3

≤

y1

y2

This example wiring diagram corresponds to the inequality x1 ⊗ x2 ⊗ x3 ≤
y1 ⊗ y2, which corresponds to the idea that x1, x2, and x3 are required to get
y1, and y2.

Each axiom in a SMP has a corresponding graphical form, using wiring dia-

grams.

Reﬂexivity The reﬂexivity law states that x ≤ x, this states that a diagram of
one wire is valid.

x

This law corresponds to the idea that a resource is preserved.

Transitivity The transitivity law says that if x ≤ y and y ≤ z then x ≤ z.
This corresponds to connecting two diagrams together in sequence. If both of
the diagrams

x

≤

y

and

y

≤

z

are valid, then they can be joined together to obtain another valid diagram.

x

≤

y

≤

z

If a box is considered a task that can transform values, then this law corre-
sponds to the idea that two tasks can be composed in sequence, with the output
of one being the input to the next.

Unitality The unitality law states that I ⊗ x = x and x ⊗ I = x, this means that
a blank space can be ignored and that diagrams such as

Nothing

x

x

x

Nothing

are valid.

Associativity The associativity law says that (x ⊗ y) ⊗ z = x ⊗ (y ⊗ z), this states
that diagrams can be built from either the top or bottom. This means that the
order of grouping resources does not matter. In reality it is trivial to see how
this is true with wires:

CircuitFlow

27

x

y
z

=

x
y

z

Symmetry The symmetry law states that x ⊗ y = y ⊗ x, this encodes the
notion that a diagram is still valid even if the wires cross.

x
y

y
x

Monotonicity Monotonicity states that, if x1 ≤ y1 and x2 ≤ y2, then x1 ⊗ x2 ≤
y1 ⊗ y2. This can be thought of as stacking two boxes on top of each other:

x2

x1

≤

≤

y2

y1

(cid:32)

x1

x2

≤

y1

y2

This law conceptualises the idea that when resources are combined, the de-

pendencies are respected.

Resource theories can level up to include additional axioms that encode de-

sirable things to do with data, such as deleting it, or duplicating it.

Discard Axiom There are times when there is no longer need to keep a value,
it would be beneﬁcial if it could be discarded. In a wiring diagram this is repre-
sented as a wire that ends (Figure 5b). It corresponds to the idea that resources
can be destroyed when they are no longer needed.

Copy Axiom The ﬁnal axiom to add is the notion of copying a value: ∀x ∈
X, x ≤ x + x. This can be represented in wiring diagram as a split wire (Figure
5c). This embodies the idea that it is possible to duplicate a resource.

D Circuit Forms a Symmetric Monoidal Preorder

For simplicity only the insApplied and outsApplied type parameters will be used
to formalise a Circuit — all other type parameters are only required to aid GHC
in compilation.

A preorder is deﬁned over tasks and DataStores. The preorder relation ≤,
can be used to describe the dependencies in the DataStores, with a task being
able to transform DataStores into new DataStores. The relation is deﬁned over
the set X, which describes the set of all possible DataStores.

28

R. Evans et al.

The monoidal product ⊗ can be thought of as the concatenation of multiple
DataStores into type-lists. For example the monoidal product of (f a) ⊗ (g b) =
(cid:48)[f a] :++(cid:48) [g b]∼(cid:48)[f a, g b]. The monoidal unit, is tricky to deﬁne as it has no real
meaning within a Circuit, however it could be considered the empty DataStore:
(cid:48)[ ].

The axioms are then satisﬁed as follows:

1. Reﬂexivity — this is the id :: Circuit (cid:48)[f a] (cid:48)[f a] constructor, it represents a

straight line with the same input and output.

2. Transitivity — this is the <−> ::Circuit x y → Circuit y z → Circuit x z con-

structor, it allows for circuits to be placed in sequence.

3. Monotonicity — this is the <> :: Circuit x1 y1 → Circuit x2 y2 → Circuit (x1 :
++ x2) (y1 :++ y2) constructor. This can place circuits next to each other.
4. Unitality — given the monoidal unit (cid:48)[ ] and a DataStore xs, then the rules

hold true: (cid:48)[ ] :++ xs∼xs and xs :++(cid:48) [ ]∼xs.

5. Associativity — given three DataStores: xs, ys, zs. Since concatenation of
lists is associative then this rule holds: (xs :++ ys) :++ zs∼xs :++ (ys :++ zs).
6. Symmetry — this is the swap :: Circuit (cid:48)[f a, g b] (cid:48)[g b, f a] constructor, it allows

for values to swap over.

7. Delete Axiom — this is satisﬁed by the dropL :: Circuit (cid:48)[f a, g b] (cid:48)[g b] and
dropR :: Circuit (cid:48)[f a, g b] (cid:48)[f a]. Although this does not directly ﬁt with the
axiom, it also has to ensure the constraint on a circuit that there must always
be 1 output value.

8. Copy Axiom — this is the replicate :: Circuit (cid:48)[f a] (cid:48)[f a, f a] constructor. It

allows for a DataStore to be duplicated.

By satisfying all the axioms a Circuit is a SMP.

E Beside Algebra

An instance of the algebra is deﬁned as:

instance BuildNetworkAlg BasicNetwork Beside where

buildNetworkAlg = beside

This requires a beside function, however to deﬁne this function some extra tools
are required. The ﬁrst is takeP, which will take the ﬁrst n elements from a
PipeList:

takeP :: SNat n → PipeList fs as → PipeList (Take n fs) (Take n as)
takeP SZero
takeP (SSucc ) PipeNil
takeP (SSucc n) (PipeCons x xs) = PipeCons x (takeP n xs)

= PipeNil
= PipeNil

This makes use of the Take type family to take n elements from each of the type
lists: fs, as, and xs. It follows the same structure as the take :: Int → [a] → [a]
deﬁned in the Prelude.

CircuitFlow

29

The next function is dropP, it drops n elements from a PipeList:

dropP :: SNat n → PipeList fs as → PipeList (Drop n fs) (Drop n as)
= l
dropP SZero
= PipeNil
dropP (SSucc ) PipeNil
xs) = dropP n xs
dropP (SSucc n) (PipeCons

l

This function again follows the same structure as drop :: Int → [a] → [a] deﬁned
in the Prelude. Both takeP and dropP are used to split the outputs of a network
after n elements. This requires the knowledge of what n is at the value level,
however n is only stored at the type level as the argument nins. To be able to
recover this value the IsNat type class is used. The recoverNIns function is able to
direct the IsNat type class to the correct type argument, and produces an SNat
with the same value as that stored in the type.

recoverNIns :: (Length bsS∼Length bsT, nins∼Length bsS, IsNat nins, Network n)

⇒ (N n asS asT) bsS bsT csS csT (nins :: Nat) → SNat (Length bsS)

recoverNIns = nat

After splitting a network and generating two new networks, the outputs will need
to be joined together again: this will require the appending of two PipeLists. To
do this an AppendP type class is deﬁned:

class AppendP fs as gs bs where

appendP :: PipeList fs as → PipeList gs bs → PipeList (fs :++ gs) (as :++ bs)

This type class has one function appendP, it is able to append two PipeLists
together. It makes use of the :++ type family to append the type lists together.
The instances for this type class are made up of two cases: the base case and a
recursive case.

instance AppendP (cid:48)[ ] (cid:48)[ ] gs bs where

appendP PipeNil ys = ys

instance (AppendP fs as gs bs) ⇒ AppendP (f (cid:48): fs) (a (cid:48): as) gs bs where

appendP (PipeCons x xs) ys = PipeCons x (appendP xs ys)

The base case corresponds to having an empty list on the left, with some other
list on the right. Here the list on the right is returned. The recursive case, simply
takes 1 element from the left hand side and conses it onto the from of a recursive
call, with the rest of the left hand side.

It is now possible to deﬁne the beside function. The result is calculated in 4

steps, with helper functions for each step:

1. Get the number of inputs (nins) on the left hand side of the Beside construc-
tor. This will give the information needed to split the inputted accumulated
network n.

30

R. Evans et al.

2. Split the network into a left and right hand side. This will retain the same
input type to the network, as there is no information on how to split that.
Only the output PipeList will be split into two parts.

3. Translate the both the left and right network. This will perform the recursive
step and generate two new networks with the networks from the left and right
added to the accumulated network n.

4. Join the networks back together. Now that the left and right hand side of
this layer has been added to the accumulated network, the two sides need to
be joined back together to get a single network that can be returned.

beside :: ∀asS asT bsS bsT csS csT (nbs :: Nat)

. Beside (AccuN BasicNetwork asS asT) bsS bsT csS csT nbs
→ IO

((AccuN BasicNetwork asS asT) bsS bsT csS csT nbs)

beside (Beside l r) = return $ AccuN (λn → do

let nins = circuitIns l
(nL, nR) ← splitNetwork nins n
(newL, newR) ← translate nins (nL, nR) (l, r)
joinNetwork (newL, newR)

)
where

splitNetwork :: SNat nbsL → BasicNetwork asS asT bsS bsT

→ IO (BasicNetwork asS asT (Take nbsL bsS) (Take nbsL bsT),
BasicNetwork asS asT (Drop nbsL bsS) (Drop nbsL bsT))

splitNetwork nbs n = return

(BasicNetwork (threads n) (ins n) (takeP nbs (outs n)),
BasicNetwork (threads n) (ins n) (dropP nbs (outs n)))

translate :: SNat nbsL

→ (BasicNetwork asS asT (Take nbsL bsS) (Take nbsL bsT),
BasicNetwork asS asT (Drop nbsL bsS) (Drop nbsL bsT))

→ ((AccuN BasicNetwork asS asT) (Take nbsL bsS)

(Take nbsL bsT) csLS csLT nbsL,

(AccuN BasicNetwork asS asT) (Drop nbsL bsS)

(Drop nbsL bsT) csRS csRT nbsR)
→ IO (BasicNetwork asS asT csLS csLT,
BasicNetwork asS asT csRS csRT)
(nL, nR) (N cL, N cR) = do

translate

nL’ ← cL nL
nR’ ← cR nR
return (nL’, nR’)

joinNetwork :: (AppendP csLS csLT csRS csRT)

⇒ (BasicNetwork asS asT csLS csLT

, BasicNetwork asS asT csRS csRT)

→ IO (BasicNetwork asS asT (csLS :++ csRS) (csLT :++ csRT))

joinNetwork (nL, nR) = return $ BasicNetwork
(nub (threads nL ++ threads nR))

CircuitFlow

31

(ins nL)
(outs nL `appendP` outs nR)

The splitNetwork function creates two new BasicNetworks. To split the output
values, takeP, and dropP are used. translate performs the recursive step in the
accumulating fold, which produces two new networks that include this layer.
joinNetwork takes the two new networks and appends the outputs with appendP.
It also has to append the thread ids from both sides, however, this will now
include duplicates as threads were not split in splitNetwork. To combat this nub
is used, which returns a list containing all the unique values in the original.

Using the algebra in conjunction with icataM5,

buildBasicNetwork is now deﬁned:

buildBasicNetwork :: InitialPipes a b

⇒ Circuit a b c d e → IO (BasicNetwork a b c d)

buildBasicNetwork x = do

n ← icataM5 buildNetworkAlg x
n’ ← initialNetwork
unAccuN n n’

icataM5 builds a value of type AccuN, which is unpacked and applied with the
initialNetwork. The application step, causes the nest of accumulator functions to
collapse and generate a new network, creating the channels and threads.

