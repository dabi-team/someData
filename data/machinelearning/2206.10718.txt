2
2
0
2

n
u
J

1
2

]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[

1
v
8
1
7
0
1
.
6
0
2
2
:
v
i
X
r
a

Physics-informed machine learning with
differentiable programming for heterogeneous
underground reservoir pressure management

Aleksandra Pachalieva1,2,*, Daniel O’Malley2, Dylan Robert Harp2, and Hari Viswanathan2

1Center for Non-Linear Studies, Los Alamos National Laboratory, Los Alamos, 87545 NM, USA
2Earth and Environmental Sciences Division, Los Alamos National Laboratory, Los Alamos, 87545 NM, USA
*apachalieva@lanl.gov

ABSTRACT

Avoiding over-pressurization in subsurface reservoirs is critical for applications like CO2 sequestration and wastewater injection.
Managing the pressures by controlling injection/extraction are challenging because of complex heterogeneity in the subsurface.
The heterogeneity typically requires high-ﬁdelity physics-based models to make predictions on CO2 fate. Furthermore,
characterizing the heterogeneity accurately is fraught with parametric uncertainty. Accounting for both, heterogeneity and
uncertainty, makes this a computationally-intensive problem challenging for current reservoir simulators. To tackle this, we use
differentiable programming with a full-physics model and machine learning to determine the ﬂuid extraction rates that prevent
over-pressurization at critical reservoir locations. We use DPFEHM framework, which has trustworthy physics based on the
standard two-point ﬂux ﬁnite volume discretization and is also automatically differentiable like machine learning models. Our
physics-informed machine learning framework uses convolutional neural networks to learn an appropriate extraction rate based
on the permeability ﬁeld. We also perform a hyperparameter search to improve the model’s accuracy. Training and testing
scenarios are executed to evaluate the feasibility of using physics-informed machine learning to manage reservoir pressures.
We constructed and tested a sufﬁciently accurate simulator that is 400 000 times faster than the underlying physics-based
simulator, allowing for near real-time analysis and robust uncertainty quantiﬁcation.

Introduction

Reservoir pressure management is essential for injection/extraction operations in the subsurface for resource extraction, carbon
sequestration, climate change mitigation, and renewable energy. However, when mishandled, the pressure management strategy
can cause induced seismicity, examples of which are the seismic events due to large-scale wastewater re-injection in central
Oklahoma1–3. Another example of a failed pressure management strategy is the seismic events that followed the injection of
large quantities of water at high pressure at the geothermal reservoir in Basel, Switzerland4–6. The incident led to public distrust
and, ﬁnally, the cancellation of the enhanced geothermal systems (EGS) project altogether7, which was just one out of multiple
EGS projects canceled due to induced seismicity concerns8.

Another application that can beneﬁt from a better understanding of pressure management is Geologic CO2 sequestration
(GCS). GCS at a large scale is necessary to reduce anthropogenic CO2 emissions enough to combat global warming and climate
change. To do this efﬁciently, it is crucial to choose a well-suited reservoir in which 99% of the geologically sequestered
carbon will remain sequestered for over 1000 years9. This requires a pressure management strategy that minimizes the risk
of leakage and potential induced seismicity through wells, faults, and fractures10–12. This requires solving complex physics
models with sufﬁcient ﬁdelity and enough realizations to understand and forecast the system behavior. This is only feasible if
we use methods to speed up the process while keeping the results accurate.

An overwhelming amount of research is focused on using machine learning (ML) to improve the efﬁciency and accuracy
of subsurface energy-related ﬂuid-ﬂow applications13. Machine learning has been used to create reduced order models for
geologic CO2 sequestration14–17, CO2 enhanced oil recovery, geothermal energy18–21, geothermal energy22–25, and oil and
gas extraction26, 27. For each of these applications, an effective pressure management strategy is required to mitigate the risks
associated with injection/extraction operations1, 10–12, 28, 29. However, the use of machine learning to manage the pressures in a
subsurface injection scenario has not been investigated in depth.

Modeling reservoir pressure management is challenging considering the complex heterogeneity of the reservoirs and the
uncertainties of the systems’ input parameters. This complex heterogeneity typically requires high-ﬁdelity physics-based models
to make CO2 predictions. Furthermore, characterizing the heterogeneity accurately is fraught with parametric uncertainty.
Accounting for both heterogeneity (which contributes to the complexity and high computational cost of the physics model) and

 
 
 
 
 
 
uncertainty demands many realizations. Performing many realizations makes this a computationally-intensive problem that is
challenging for current reservoir simulation workﬂows. For some applications, such as the oil and gas industry, tens of thousands
of wells have been drilled, resulting in large amounts of data and the development and usage of data-driven machine learning
models30–32. However, this is not the case for applications such as GCS, where few wells are in use, data is scarce, expensive,
and time-consuming to obtain33, 34. For such data-limited applications, physics constraints are often introduced into the machine
learning algorithms to regularize the neural networks training and thus augment the lack of data35, 36. This approach is called
physics-informed neural networks (PINN)37. A limitation of the PINN approach is that if the physics are not trustworthy –
there are no guarantees that the computation will quickly (or at all) converge to the correct solution. An incorrect solution
could misguide the pressure management machine learning model. A major limitation of most traditional numerical models is
the calculation of parameter gradients from high-ﬁdelity physics reservoir simulations. Most ﬂuid and transport simulators,
which can simulate subsurface ﬂuid injection/extraction rely on ﬁnite-difference gradients to evaluate many physics-based
parameters38–42. This is why such simulators are built without the use of differentiable programming (DP) and automatic
differentiation (AD) techniques which are standard in machine learning approaches such as PINNs. Computing ﬁnite-difference
gradients for highly-dimensionalized models (e.g., those with heterogeneous permeability ﬁelds) is computationally inefﬁcient
and often prevents the traditional physical models from being included in machine learning workﬂows. A solution to this
problem is using DP and AD that takes advantage of the chain rule to evaluate complex derivatives more efﬁciently43, including
for implementing trustworthy numerical models based on traditional methods such as ﬁnite difference/element/volume.

We developed a physics-informed machine learning (PIML) framework that determines the ﬂuid extraction rates for
dedicated wells to maintain the pressure at a critical location during water injection. We consider a complex physics model
that accounts for the permeability ﬁeld’s heterogeneity, which was overlooked or deemed too expensive by previous studies44.
Instead of using an analytical single-phase model as previously done by Harp et al.44, we solved a full-physics model using the
DPFEHM framework45 that accounts for heterogeneity. Our physics model is differentiable, which in alternative approaches,
such as PINNs, do not rigorously guarantee that the physical constraints will be satisﬁed. We use a steady-state equation that
looks at the long-term impact of the injection/extraction. Harp et al.44 considered only a ﬁxed time in the future, which limited
the ability to evaluate the sustainability of the injection process. DPFEHM allows us to combine a rigorous, trustworthy physics
model with Convolutional Neural Networks (CNN) that have built-in AD. In addition, DPFEHM minimizes the time for code
development by automatically creating the execution code from a short description of the equations of interest.

One way to develop a full-physics model for pressure management in the context of CO2 sequestration would require the
completion of the following steps: (1) development of a simple pressure management PIML framework solving the analytical
Theis model46 as shown by Harp et al.44; (2) development of a pressure management PIML framework using a full-physics
model with heterogeneous permeability ﬁeld, which we demonstrate in the current study; and (3) adding a multi-phase model.
Our single-phase pressure management model is more relevant to wastewater injection. However, including a full-physics model
in the ML workﬂow and accounting for heterogeneity are essential steps towards pressure management for multi-phase injection
scenarios such as CO2 sequestration. Furthermore, without this PIML framework, we would be unable to do uncertainty
quantiﬁcation (UQ) in real-time since thousands (or more) partial differential equation-constrained optimization problems
would be required.

1 Methods

Operators at underground reservoir sites require pressure management systems to make informed decisions for the injec-
tion/extraction rates to minimize the risk of leakage and induced seismicity and maximize the reservoir’s performance (e.g.,
maximize the net ﬂuid injected). The traditional approach to constructing pressure management systems uses full-order physics
models that do not allow for UQ in real-time. Existing alternatives, such as the work of Harp et al.44, used a highly simpliﬁed
homogeneous model which neglects heterogeneity. In reality, the subsurface is highly heterogeneous, so for the model to be
trustworthy, heterogeneity must be accounted for. Our PIML framework uses a full-physics model and ML combined with DP,
making this approach computationally and practically feasible.

A schematic representation of the proposed PIML framework is shown in Figure 1. We use this framework to determine the
ﬂuid extraction rates at an extraction well to maintain the pressure at a critical location in a reservoir with a heterogeneous
permeability ﬁeld. We achieve this by using a neural network model (NNM) trained on a set of permeability ﬁelds that,
along with the NNM-predicted extraction rate, act as an input to the full-physics DPFEHM model. The NNM is trained to
determine the extraction rates for a heterogeneous permeability ﬁeld. The physics constraints needed for the training process
are incorporated through the DPFEHM framework, which provides the physics information in our PIML framework. Our
framework has similarities to the works of Harp et al. and Srinivasan et al.44, 47, that use physics-informed neural networks
with physical constraints used during the NNM training. A signiﬁcant difference in our approach is that instead of using a
differentiable, simple analytical solution, we use a differentiable numerical physics model. Alternative approaches such as
PINNs do not have rigorous guarantees that the physical constraints will be satisﬁed.

2/12

Figure 1. (Color online) Workﬂow diagram of physics-informed machine learning framework for managing reservoir
pressures at a critical location during subsurface ﬂuid injection. The key innovation of the surrogate model is the
automatically-differentiable full-order model that allows for heterogeneity.

We executed a suite of training scenarios using a single-phase model with heterogeneous permeability ﬁelds randomly
generated using a Gaussian distribution function. Since the model has many parameters, computing ﬁnite-difference gradients
become infeasible, and the only efﬁcient approach to solve the problem is by using reverse-mode automatic differentiation.
We perform a hyperparameter search by varying the batch size (i.e., the number of training samples included in each gradient
calculation) and the learning rate (i.e., the step size controlling the rate at which each iteration moves towards the minimum of
the loss function).

Physics model
We consider the pressure change during injection/extraction of a single-phase ﬂuid ﬂow in a heterogeneous permeability ﬁeld.
Such subsurface reservoirs are modeled using the following equation

∇ · (cid:0)k(x) · ∇h(cid:1) = f ,

(1)

where k(x) are heterogeneous permeability ﬁelds depending on the position x, h is the pressure head and f is the injection/ex-
traction. This is a steady-state equation which allows us to evaluate the long-term impact of the injection and the extraction on
the pressure head.

The equation is solved using DPFEHM45. DPFEHM uses the standard two-point ﬂux ﬁnite volume approximation, which
results in a trustworthy solution to the physics model. In addition, DPFEHM has built-in AD that makes the transition between
the physics model and the machine learning model seamless.

PIML framework
As shown in Figure 1, our PIML framework trains an NNM to estimate the extraction rates at dedicated extraction wells
to maintain predeﬁned pressures at critical locations during ﬂuid injection. This is necessary near faults with high induced
seismicity risk or at abandoned wellbores with leakage potential. To make the model more realistic, we randomly initialized
heterogeneous permeability ﬁelds using a Gaussian distribution function. The PIML framework is part of the DPFEHM
package, which is available at https://github.com/OrchardLANL/DPFEHM.jl.

The PIML workﬂow consists of the following steps:

1. Generate a training dataset that consists of Nb batches and Ns samples per batch. We use heterogeneous permeability

samples, randomly initialized using a Gaussian distribution function.

2. Construct a CNN with an input layer that accepts a permeability ﬁeld and an output layer that estimates the ﬂuid extraction

rates at the extraction well.

3. Calculate a loss function that quantiﬁes the error between the model’s overpressure and the target overpressure at a

critical location.

4. Train the CNN to determine the extraction rates that minimize the error between the model’s overpressure and the target
overpressure at a critical location by adjusting the CNN model parameters based on the loss-function parameter gradients.

3/12

Backpropagation loopHeterogeneous permeability samplesConvolutional Neural NetworkPressure errors at critical locationsAutomatically-differentiable full order modelOperational control parametersLoss FunctionExtraction ratesVariable or uncertain propertiesCritical locationExtractionInjectionIn step 2, the PIML framework trains a CNN based on LeNet-548 to determine the extraction rates at an extraction well
to maintain pressure at critical locations, such as faults with induced seismicity risk or abandoned wellbores with leakage
potential, during ﬂuid injection at dedicated injection wells with heterogeneous permeability ﬁelds. LeNet-5’s architecture
consists of a convolutional encoder with two convolutional layers and a dense block with three fully-connected layers. For this
work, we use a slightly modiﬁed LeNet-5 CNN with the following architecture:

model = C h a i n ( Conv ( ( 5 , 5 ) , 1= >6 ,

r e l u ) ,

r e l u ) ,

MaxPool ( ( 2 , 2 ) ) ,
Conv ( ( 5 , 5 ) , 6= >16 ,
MaxPool ( ( 2 , 2 ) ) ,
f l a t t e n ,
Dense ( 1 2 9 6 , 1 2 0 ,
Dense ( 1 2 0 , 8 4 ,
Dense ( 8 4 , 1 ) )

| > f 6 4

r e l u ) ,

r e l u ) ,

We use two convolutional layers, two subsampling layers, a ﬂattening operation, and a fully connected dense block. Each
convolutional layer uses a 5x5 kernel and a max pooling subsampling layer which calculates the maximum of the values present
in each kernel. The ﬁrst convolutional layer has 6 output channels, and the second one has 16. The activation function with a
stride of 2 reduces the dimensionality through downsampling by a factor of 4. We ﬂatten the output of the convolutional block
by taking the four-dimensional input and transforming it into two-dimensional input to be compatible with the fully-connected
dense block. The dense block has three fully-connected layers, with 120, 84, and 1 outputs, respectively. Relu activation
functions are used for all hidden layers as σ (x) = max(0, x), with x being the input and σ (x) being the output of the neuron.
The last dense layer outputs a single value associated with the extraction rate, Qext.

During preliminary investigations, we explored the use of more complex deep neural networks (such as the VGG16,49)
with a larger number of neurons and/or more hidden layers; however, they did not improve the convergence speed and thus
the performance of the PIML framework. On the contrary, in some cases, they led to slower convergence and worse overall
results. The reason for this is most likely that larger networks are more prone to complex response surfaces, which increases the
chance for the training to become trapped in local minima. By contrast, our empirical results suggest that LeNet-5 provides a
good balance between strong performance and ease of training. As we transition to more complex physics models, the ease of
training becomes more critical when the data sets become smaller. Nonetheless, the optimal architecture for these problems
remains an exciting area for research.

In step 3, the loss function is deﬁned as the sum of the squared errors between the simulated and the target overpressures at

a critical location as

L (θ ) =

Nb
∑
i

Ns
∑
j

(cid:104)
∆h (cid:0)QNN

(cid:0)θ , k j(x)(cid:1), k j(x)(cid:1) − ∆htarget(cid:105)2

,

(2)

with Nb being the number of batches, Ns the number of samples per batch, and ∆htarget the target overpressure. The predicted
overpressure ∆h is a function of the injection rate QNN and the permeability k j(x) at a speciﬁc position. QNN is calculated using
the LeNet-5 CNN model and takes two parameter, θ being the model parameters and k j(x) permeability. From the loss function
we calculate the root-mean-square error (RMSE) as

RMSE(θ ) =

(cid:115)

L (θ )
NbNs

.

In step 4, the NNM is trained to minimize the loss function L (θ ) as

= L (θ ).

min
θ

(3)

(4)

using an Adam optimizer from the Julia Flux package50. We use the DPFEHM package to solve the full-physics model as shown
in Eq.1. Within the DPFEHM framework, we automatically differentiate the physics model using Julia’s Zygote package51.

Differentiable programming
Traditional physics models are rarely automatically differentiable and require the usage of ﬁnite difference methods to compute
parameter gradients38–42. This is computationally inefﬁcient and makes incorporating these models in a machine learning
workﬂow infeasible when the number of parameters is large. When looking at a large number of physics-model parameters in a

4/12

PIML framework, choosing the most efﬁcient way to calculate gradients is essential for the algorithm’s success. This is because
computing the gradient of the loss function is central to training machine learning models.

In computational ﬂuid dynamics, ﬁnite-differences or numerical differentiation are often used to compute gradients, but
that could be computationally expensive, especially when the number of input parameters grows. The number of model runs
required to compute the gradient is proportional to the number of input parameters. When using ﬁnite difference (FD), the
quality of the solution is also greatly inﬂuenced by the truncation and round-off errors associated with different ﬁnite difference
formulas. An alternative is using differentiable programming (DP), and in particular, reverse-mode AD, which utilizes the
chain rule to calculate complex derivatives. It breaks a computer program down into elementary operations, which allows
the derivatives to be evaluated accurately to working precision. Reverse-mode AD becomes more efﬁcient when the number
of model inputs is large (e.g., the parameters of a neural network) and the number of model outputs is small (e.g., the loss),
which can be demonstrated with the following example: The LeNet-5 model uses approximately 1 million model parameters,
which gradients can be obtained using AD in a single forward and backward model pass regardless of the number of model
parameters; in comparison, using a central ﬁnite-difference model, we would have to calculate two forward simulations per
model parameter which results in 2 million forward calls. In AD, the advantage of using reverse-mode AD (akin to adjoint
methods) comes from its computational cost being independent of the number of design variables. By contrast, the cost of
the forward sensitivity analysis increases linearly with the number of design variables52. Depending on the simulator and the
application, the AD adjoint simulations can be more expensive than the forward simulations; however, the discrepancies in
execution time have been decreasing with the development of DP43, 53. For a physics simulator, which typically involves a
solution of a system of equations, the backward pass requires only the solution of a linear system of equations (even if the
underlying equations are nonlinear). So in this setting, the backward pass is rarely more expensive than the forward pass.

Results

The physics model includes an injection well, an extraction well, and a critical location. The injection well injects water at a rate
of 1.0 MMT/y (million metric tons per year), which is equivalent to 0.031688 m3/s. The extraction well protects the critical
location where a target overpressure (change in pressure from pre-injection conditions) is set to 0.0 MPa. The permeability ﬁeld
is randomly initialized using a multivariate Gaussian distribution function with a correlation length of 50 m and log standard
deviation equal to 1. A schematic representation of the simulation conﬁguration is shown in Figure 2, where we indicate the
positions of the injection, extraction, and critical location. The permeability ﬁeld is illustrated using a color map, where blue
and red denote low and high permeability, respectively. The size of the simulated domain is 400 meters on each side. Our PIML
framework trains the neural network to achieve the target overpressure at the critical location for a given permeability ﬁeld. We
solve a steady-state equation that captures the long-term impact of the injection/extraction. The background reservoir pressure
in our simulation is equal to 19.0 MPa, which is in line with MPC 26-5 well located in Kemper County, Mississippi. MPC 26-5
well is part of the ECO2S project and its depth is 1791 meters54, 55.

The PIML algorithm uses 512, 1024, 2048, or 4096 training and disjoint testing samples per epoch depending on the
batch size, where the batch size ranges from 32 to 256. The testing data is sampled only once from a multivariate Gaussian
distribution, while the training data is sampled in every epoch. That is, the model never sees the same data point twice, so there
is little risk of overﬁtting, a unique characteristic of the DP that allows for data to be generated on the ﬂy compared to other ML
models that use just a ﬁxed set of data. This is possible because our DP approach has the physics model in the training loop.
Therefore, generating the training data and running the model is unnecessary before the training begins. The total number of
executed epochs is 10,000, but similar results could be obtained using a much smaller number of epochs on the order of 4,000.
The training samples are randomly initialized before training each epoch, making the total number of unique training samples
for the batch size of 256 equal to 40,960,000 throughout the ML training. The test samples are initialized only once before
starting the ﬁrst epoch. We ran the training on a central processing unit (CPU) with an AMD EPYC 7702P 64-Core processor
without parallelization paradigms.

We perform a hyperparameter search in which we test the RMSE for a variety of batch sizes (bsize ∈ [32, 64, 128, 256]), and
learning rates (lr ∈ [1e−3, 3e−4, 1e−4]) as shown in Table 1. The hyperparameter search shows that by decreasing the learning
rate from lr = 1e−3 to lr = 1e−4, the RMSE decreases three to four times for each batch size. The best results are achieved
using a batch size and learning rate equal to 256 and 1e−4, respectively. The results can be potentially improved by further
decreasing the learning rate. However, we did not expand the search since the model was producing results that were within
acceptable limits.

Figure 3 illustrates the rate at which the RMSE decreases with the number of epochs. The results are for the best
hyperparameters we tested during PIML training, which uses a batch size of 256 and a learning rate equal to 1e−4. The ﬁgure
shows the training RMSE error in blue and the testing RMSE in red. We observe a rapid decrease in the RMSE at the beginning
of the training. In later epochs (after approximately 4000 epochs), the RMSE starts to decrease much slower, reaching a
plateau around 8000 epochs with an overall error reduction of 99%. The minimum RMSE reached using the testing data

5/12

Figure 2. (Color online) Diagram of a single-phase pressure management with heterogeneous permeability ﬁeld including one
injection and one extraction wells, and a critical location.

Figure 3. (Color online) RMSE for the best training set from the hyperparameter search (bsize = 256, and lr = 1e−4). The
minimum RMSE is equal to 0.002786 MPa overpressure at the critical location.

6/12

Northing [m]Critical locationExtractionInjectionEasting [m]Permeabilitylr = 1e−3
lr = 3e−4
lr = 1e−4

bsize = 32
0.018658
0.005779
0.005332

bsize = 64
0.013856
0.015159
0.003719

bsize = 128
0.010190
0.005228
0.002852

bsize = 256
0.009823
0.006147
0.002786

Table 1. Hyperparameter search to determine the optimal ML parameters. Minimum testing RMSE for a variety of batch sizes,
bsize ∈ [32, 64, 128, 256]; and learning rates, lr ∈ [1e−3, 3e−4, 1e−4]. The results are given in pressure units [MPa].

(a)

(b)

Figure 4. (Color online) (a) Resulting pressure distribution within the reservoir. The positions of the injection/extraction and
critical locations are indicated; (b) Overpressure values within the prescribed domain extracted from the PIML framework. The
blue and red triangles denote respectively the position of the extraction and the injection wells, respectively, while the circle
depicts the critical location at which a target pressure is set.

samples is 0.002786 MPa, which is small in comparison to the overpressure caused by the injection and makes the model
sufﬁciently accurate to be used in practice. That is, other factors beyond errors in the injection rate, such as uncertainty about
the heterogeneity, will impact the decision-making process for the extraction rate, and this model could be used to help ﬁnd an
appropriate extraction rate given uncertainty by predicting an ensemble of extraction rates for a variety of permeability ﬁelds.
After training the PIML frameworks, we can use them to generate extraction rates and overpressures at the critical location
given a heterogeneous permeability ﬁeld. In Figure 4, we illustrate the resulting pressures and overpressures for a random
permeability ﬁeld within the domain. We used the same permeability ﬁeld as shown in Figure 2, and the PIML framework for
which we achieved the lowest RMSE (bsize = 256 and lr = 1e−4). The background pressure of the MPC 26-5 well is 19.0 MPa,
which is reﬂected in the total pressure of the well depicted in Figure 4a. Figure 4b shows that the prescribed pressure at the
critical location, 0.0 MPa, is obtained by the PIML framework with good accuracy and, despite the small deviation, still falls
into an acceptable range. As expected, the overpressure rates at the injection well are considerably larger, up to 6 MPa. At the
same time, at the extraction well, we achieve negative overpressure, which protects the critical location from exceeding the
prescribed 0.0 MPa.

Next, we look at the distribution of extraction rates and overpressures at the critical location after running 10,000
random heterogeneous ﬁeld samples through our PIML framework as shown in Figure 5. The distribution function of the
extraction rate, depicted in Figure 5a, is skewed and shows that most of the samples require an extraction rate in the range of
−0.009 m3/s to −0.001 m3/s in 90% of the time. Compared to our injection rate of 1.0 MMT/year, the extraction rate is equal
to −0.283824 MMT/year, and −0.031536 MMT/year, respectively. Figure 5b illustrates that the overpressure at the critical
location deviates very slightly from the prescribed overpressure, speciﬁcally in the range of −0.003 MPa to 0.006 MPa in
90% of the time. These results conﬁrm that the PIML framework can provide useful information for the operators of pressure
management systems.

7/12

Critical locationExtractionInjectionNorthing [m]Easting [m]Pressure [MPa]Northing [m]Easting [m]Overpressure [MPa](a)

(b)

Figure 5. (Color online) (a) Extraction rates in cubic meters per second [m3/s]; (b) Overpressure at the critical location in
pressure units [MPa].

Overall, solving the physics model on a CPU (AMD EPYC 7702P 64-Core) takes 5.9e−3 seconds, and obtaining the
extraction rates using the trained PIML model on a GPU (NVIDIA RTX A6000) takes only 1.4e−8 seconds (equivalent to
14 nanoseconds) per sample. Our framework solves the constrained optimization model more than 400 000 times faster than
solving the physics model allowing for near real-time analysis and robust uncertainty quantiﬁcation. We obtained these results
using a total number of 50 000 to fully utilize the GPU.

Discussion

We have demonstrated that the PIML framework can successfully manage subsurface pressures by controlling ﬂuid extraction
in heterogeneous permeability ﬁelds. Such operations are relevant for resource extraction (oil and gas), climate mitigation (CO2
sequestration), and production of renewable energy (geothermal energy). A similar PIML approach has already been evaluated
by44 using homogeneous permeability. We have added a signiﬁcantly more complex physics model using the DPFEHM
framework to ensure a seamless transition between the execution of the physics model and the machine learning model. We
show that a PIML framework with built-in AD can train an NNM to determine the ﬂuid extraction needed to achieve pressure
management goals while injecting large amounts of ﬂuid into the subsurface. This has the potential to help operators at sites
effectively manage reservoir pressures and can be coupled with decision-making strategies to attain operational efﬁciencies56–60.
The computational cost is modest enough that it can be run on a single CPU with AMD EPYC7702P 64-Core processor
without parallelization. However, the full-physics model and the heterogeneity add complexity to the model that is only feasible
because of the DPFEHM framework and its built-in AD. The number of training epochs can be reduced depending on the
accuracy demands, which can be a helpful strategy when considering a more complex physics model. Our results showed
that, though we trained for 10,000 epochs, a much smaller number could be used to obtain accuracy consistent with realistic
operational goals. This could be important when using more complex physics models (such as multi-phase ﬂow) to keep the
computational cost manageable. Parallelization could also be exploited in these cases.

We tested different convolutional neural networks, one of them was the VGG Net, a very deep CNN often used for image
recognition49. To execute the VGG Net more efﬁciently, we used a hybrid approach, in which the ML model was executed
on the GPU while the physics model was executed on the CPU. Even though the VGG Net is signiﬁcantly deeper, it did not
improve the RMSE of the training and sometimes performed worse. However, such a neural network could be more efﬁcient
when training on even more complex physics models such as multi-phase models needed for investigating climate mitigation
and, in particular CO2 sequestration. These models might require a more complex network to deal with the more complex
physics present in these cases, but this is a topic for future research.

In addition, we batch-parallelized the model using Julia’s parallel map operation implemented as a pmap-function. Since
our physics model is only modestly expensive, the communication between processes was longer than the time needed for the

8/12

0.02000.01750.01500.01250.01000.00750.00500.00250.0000Extraction Rate [m3/s]050100150200250300350Number of Samples0.0150.0100.0050.0000.0050.0100.0150.020Overpressure at the Critical Location [MPa]0100200300400500600700Number of Samplescomputation. Therefore, the pmap did not improve the performance. However, this technique could be used more effectively
when investigating more complex physics models, such as multi-phase ﬂow. Again, this is a topic for future research.

Conclusions

We applied a PIML framework to a subsurface pressure management problem that considers the pressure change during
injection/extraction. We considered a single-phase steady-state ﬂuid ﬂow with heterogeneity that looks at the long-term
impact of the injection/extraction on the reservoir. In our PIML framework, a convolutional NNM is trained to determine
ﬂuid extraction rates at a dedicated critical reservoir location during the injection. We performed a hyperparameter search,
which showed that decreasing the learning rate while increasing the batch size improves the results. In conclusion, we would
emphasize the following observations:

• A PIML framework can train a convolutional NNM to manage reservoir pressures with heterogeneous permeability
ﬁelds resulting in small deviations from the target overpressure. We accomplished this by combining a differentiable
full-physics simulator with a convolutional neural network.

• This problem is only feasible because of the DPFEHM framework, which has a built-in AD. To solve the physics model,

we use the DPFEHM framework as part of the PIML framework.

• DPFEHM allows us to bridge the gap between numerical models and machine learning techniques because both are

compatible with the same AD frameworks

• The hyperparameter search shows that decreasing the learning rate and increasing the batch size is beneﬁcial for bringing
down the RMSE of the ML training. Our results can be potentially improved by further decreasing the learning rate.

• We tested a hybrid implementation of the PIML framework using a deeper convolutional neural network (VGG Net).
In that case, the physics model is solved on a CPU, while the machine learning model is solved on a GPU. The results
showed no improvement in the ML training, concluding that the relatively simple LeNet network sufﬁces for this problem.

• We also batch-parallelized the combined NNM and physics model using Julia’s parallel map operation (pmap). However,
for the single-phase steady-state ﬂow problem with heterogeneity, the added communication costs outweigh the beneﬁts
of parallelization. This is because the physical model, in this case, is relatively inexpensive. We anticipate that for more
complex physics models, such as introducing a multi-phase ﬂow, will beneﬁt from such parallelization.

• A natural next step in this line of research is to study this problem in the context of multi-phase ﬂows, which are essential

for CO2 sequestration, among other applications.

References

1. Zoback, M. D. Managing the seismic risk posed by wastewater disposal. Earth 57, 38 – 43 (2012).

2. Keranen, K. M., Weingarten, M., Abers, G. A., Bekins, B. A. & Ge, S. Sharp increase in central Oklahoma seismicity

since 2008 induced by massive wastewater injection. Science 345, 448–451 (2014).

3. McNamara, D. E. et al. Earthquake hypocenters and focal mechanisms in central Oklahoma reveal a complex system of

reactivated subsurface strike-slip faulting. Geophys. Res. Lett. 42, 2742–2749 (2015).

4. Baer, M. et al. Earthquakes in Switzerland and surrounding regions during 2006. Swiss J. Geosci. 100, 517–528 (2007).

5. Deichmann, N. et al. Earthquakes in switzerland and surrounding regions during 2007. Swiss J. Geosci. 101, 659–667

(2008).

6. Dyer, B., Schanz, U., Ladner, F., Haring, M. & Spillman, T. Microseismic imaging of a geothermal reservoir stimulation.

The Lead. Edge 27, 856–869 (2008).

7. Deichmann, N. & Giardini, D. Earthquakes induced by the stimulation of an enhanced geothermal system below Basel

(Switzerland). Seismol. Res. Lett. 80, 784–798 (2009).

8. Majer, E. L. et al. Induced seismicity associated with enhanced geothermal systems. Geothermics 36, 185–222 (2007).

9. Metz, B., Davidson, O., De Coninck, H., Loos, M. & Meyer, L. IPCC special report on carbon dioxide capture and storage

(Cambridge: Cambridge University Press, 2005).

9/12

10. Buscheck, T. A. et al. Combining brine extraction, desalination, and residual-brine reinjection with CO2 storage in saline
formations: Implications for pressure management, capacity, and risk mitigation. Energy Procedia 4, 4283–4290 (2011).

11. Cihan, A., Birkholzer, J. T. & Bianchi, M. Optimal well placement and brine extraction for pressure management during

CO2 sequestration. Int. J. Greenh. Gas Control. 42, 175–187 (2015).

12. Harp, D. R. et al. Development of robust pressure management strategies for geologic CO2 sequestration. Int. J. Greenh.

Gas Control. 64, 43–59 (2017).

13. Viswanathan, H. S. et al. From ﬂuid ﬂow to coupled processes in fractured rock: recent advances and new frontiers. Rev.

Geophys. 60, e2021RG000744 (2022).

14. Chen, B., Harp, D. R., Lin, Y., Keating, E. H. & Pawar, R. J. Geologic CO2 sequestration monitoring design: A machine

learning and uncertainty quantiﬁcation based approach. Appl. energy 225, 332–345 (2018).

15. Menad, N. A., Hemmati-Sarapardeh, A., Varamesh, A. & Shamshirband, S. Predicting solubility of CO2 in brine by
advanced machine learning systems: Application to carbon capture and sequestration. J. CO2 Util. 33, 83–95 (2019).

16. Wang, Z., Dilmore, R. M. & Harbert, W. Inferring CO2 saturation from synthetic surface seismic and downhole monitoring
data using machine learning for leakage detection at CO2 sequestration sites. Int. J. Greenh. Gas Control. 100, 103115
(2020).

17. Amar, M. N. & Ghahfarokhi, A. J. Prediction of CO2 diffusivity in brine using white-box machine learning. J. Petroleum

Sci. Eng. 190, 107037 (2020).

18. Krasnov, F., Glavnov, N. & Sitnikov, A. A machine learning approach to enhanced oil recovery prediction. In International

Conference on Analysis of Images, Social Networks and Texts, 164–171 (Springer, 2017).

19. Chen, B. & Pawar, R. J. Characterization of co2 storage and enhanced oil recovery in residual oil zones. Energy 183,

291–304 (2019).

20. You, J., Ampomah, W. & Sun, Q. Development and application of a machine learning based multi-objective optimization

workﬂow for co2-eor projects. Fuel 264, 116758 (2020).

21. You, J. et al. Machine learning based co-optimization of carbon dioxide sequestration and oil recovery in co2-eor project.

J. Clean. Prod. 260, 120866 (2020).

22. Li, Y., Júlíusson, E., Pálsson, H., Stefánsson, H. & Valfells, A. Machine learning for creation of generalized lumped

parameter tank models of low temperature geothermal reservoir systems. Geothermics 70, 62–84 (2017).

23. Rezvanbehbahani, S., Stearns, L. A., Kadivar, A., Walker, J. D. & van der Veen, C. J. Predicting the geothermal heat ﬂux

in greenland: A machine learning approach. Geophys. Res. Lett. 44, 12–271 (2017).

24. Holtzman, B. K., Paté, A., Paisley, J., Waldhauser, F. & Repetto, D. Machine learning reveals cyclic changes in seismic

source spectra in geysers geothermal ﬁeld. Sci. advances 4, eaao2929 (2018).

25. Tut Haklidir, F. S. & Haklidir, M. Prediction of reservoir temperatures using hydrogeochemical data, western anatolia

geothermal systems (turkey): a machine learning approach. Nat. Resour. Res. 29, 2333–2346 (2020).

26. Hegde, C. & Gray, K. Use of machine learning and data analytics to increase drilling efﬁciency for nearby wells. J. Nat.

Gas Sci. Eng. 40, 327–335 (2017).

27. Hanga, K. M. & Kovalchuk, Y. Machine learning and multi-agent systems in oil and gas industry applications: A survey.

Comput. Sci. Rev. 34, 100191 (2019).

28. Axelsson, G., Stefánsson, V., Björnsson, G. & Liu, J. Sustainable management of geothermal resources and utilization for

100–300 years. In Proceedings World Geothermal Congress, vol. 8 (2005).

29. Weingarten, M., Ge, S., Godt, J. W., Bekins, B. A. & Rubinstein, J. L. High-rate injection is associated with the increase in

us mid-continent seismicity. Science 348, 1336–1340 (2015).

30. Cao, Q. et al. Data driven production forecasting using machine learning. In SPE Argentina Exploration and Production of

unconventional resources symposium (OnePetro, 2016).

31. Mohaghegh, S. D. Data-driven reservoir modeling (SPE, 2017).

32. Hajizadeh, Y. Machine learning in oil and gas; a SWOT analysis approach. J. Petroleum Sci. Eng. 176, 661–663 (2019).

33. Claprood, M. et al. Workﬂow using sparse vintage data for building a ﬁrst geological and reservoir model for CO2
geological storage in deep saline aquifer. A case study in the St. Lawrence Platform, Canada. Greenh. Gases: Sci. Technol.
2, 260–278 (2012).

10/12

34. Mishra, S. et al. Maximizing the value of pressure monitoring data from co2 sequestration projects. Energy Procedia 37,

4155–4165 (2013).

35. Yang, Y. & Perdikaris, P. Adversarial uncertainty quantiﬁcation in physics-informed neural networks. J. Comput. Phys.

394, 136–152 (2019).

36. Meng, X., Li, Z., Zhang, D. & Karniadakis, G. E. Ppinn: Parareal physics-informed neural network for time-dependent

pdes. Comput. Methods Appl. Mech. Eng. 370, 113250 (2020).

37. Raissi, M., Perdikaris, P. & Karniadakis, G. E. Physics-informed neural networks: A deep learning framework for solving
forward and inverse problems involving nonlinear partial differential equations. J. Comput. physics 378, 686–707 (2019).
38. Pruess, K. TOUGH2-A general-purpose numerical simulator for multiphase ﬂuid and heat ﬂow. Lawrence Berkeley Natl.

Lab. LBNL Rep. Number LBL-29400 (1991).

39. White, M. & Oostrom, M. STOMP subsurface transport over multiple phases: Users guide. Tech. Rep., Paciﬁc Northwest

National Lab.(PNNL), Richland, WA (United States) (1997).

40. Harbaugh, A. W. MODFLOW-2005, the US Geological Survey modular ground-water model: The ground-water ﬂow

process (US Department of the Interior, US Geological Survey Reston, VA, USA, 2005).

41. Zyvoloski, G. FEHM: A control volume ﬁnite element code for simulating subsurface multi-phase multi-ﬂuid heat and

mass transfer May 18, 2007 LAUR-07-3359 (2007).

42. CMG, G. Advanced compositional and unconventional reservoir simulator Version 2018. CMG Ltd., CM Group, Ed.

(2018).

43. Baydin, A. G., Pearlmutter, B. A., Radul, A. A. & Siskind, J. M. Automatic differentiation in machine learning: a survey.

J. Marchine Learn. Res. 18, 1–43 (2018).

44. Harp, D. R., O’Malley, D., Yan, B. & Pawar, R. On the feasibility of using physics-informed machine learning for

underground reservoir pressure management. Expert. Syst. with Appl. 178, 115006 (2021).

45. O’Malley, D., Harp, D. R. & Vesselinov, V. V. DPFEHM.jl. accessed from https://github.com/Orchard LANL/DPFEHM.jl

(2022).

46. Theis, C. V. The relation between the lowering of the piezometric surface and the rate and duration of discharge of a well

using ground-water storage. Eos, Transactions Am. Geophys. Union 16, 519–524 (1935).

47. Srinivasan, S. et al. A machine learning framework for rapid forecasting and history matching in unconventional reservoirs.

Sci. Reports 11, 1–15 (2021).

48. LeCun, Y. et al. Backpropagation applied to handwritten zip code recognition. Neural Comput. 1, 541–551 (1989).
49. Simonyan, K. & Zisserman, A. Very deep convolutional networks for large-scale image recognition. arXiv preprint

arXiv:1409.1556 (2014).

50. Innes, M. Flux: Elegant machine learning with Julia. J. Open Source Softw. 3, 602 (2018).
51. Innes, M. Don’t unroll adjoint: Differentiating SSA-form programs. arXiv preprint arXiv:1810.07951 (2018).
52. Giles, M., Ghate, D. & Duta, M. Using automatic diﬁerentiation for adjoint CFD code development. Comput. Fluid Dyn. J.

16 (2008).

53. Innes, M. et al. A differentiable programming system to bridge machine learning and scientiﬁc computing. arXiv preprint

arXiv:1907.07587 (2019).

54. Duguid, A. et al. Co2 well construction: Lessons learned from united states department of energy sponsored projects. In

14th Greenhouse Gas Control Technologies Conference Melbourne, 21–26 (2018).

55. Riestenberg, D. Survey of existing wellbores in and around kemper county, mississippi (deliverable 4.1). Tech. Rep.,

Southern States Energy Board, Peachtree Corners, GA (United States) (2018).

56. Martin, J. J. Bayesian decision problems and Markov chains (Wiley, 1967).
57. Charnes, A., Cooper, W. W. & Rhodes, E. Measuring the efﬁciency of decision making units. Eur. journal operational

research 2, 429–444 (1978).

58. Geng, L., Chen, Z., Chan, C. W. & Huang, G. H. An intelligent decision support system for management of petroleum-

contaminated sites. Expert. systems with applications 20, 251–260 (2001).

59. Ben-Haim, Y. Info-gap decision theory: Decisions under severe uncertainty (Elsevier, 2006).
60. Zhang, L., Wu, X., Ding, L., Skibniewski, M. J. & Yan, Y. Decision support analysis for safety control in complex project

environments based on Bayesian Networks. Expert. Syst. with Appl. 40, 4273–4282 (2013).

11/12

Acknowledgements

AP acknowledges funding from Center for Nonlinear Studies (CNLS) at Los Alamos National Laboratory. DO acknowl-
edges support from Los Alamos National Laboratory’s Laboratory Directed Research and Development Early Career Award
(20200575ECR). The authors acknowledge support from the US Department of Energy’s Science-informed Machine-learning
for Accelerating Real-Time decisions (SMART) initiative.

Author contributions statement

Aleksandra Pachalieva: Data curation, Formal analysis, Investigation, Methodology, Software, Validation, Visualization, Writing
- original draft, Writing - review & editing. Daniel O’Malley: Conceptualization, Formal analysis, Software, Methodology,
Writing - review & editing. Dylan Robert Harp: Software, Writing - review & editing. Hari Viswanathan: Funding acquisition,
Writing - review & editing.

Competing interests

The author(s) declare no competing interests.

12/12

