2
2
0
2

y
a
M
1
1

]

G
L
.
s
c
[

2
v
7
0
2
1
1
.
1
1
1
2
:
v
i
X
r
a

Improved Sample Complexity Bounds for Branch-and-Cut

Maria-Florina Balcan∗

Siddharth Prasad†

Tuomas Sandholm‡

Ellen Vitercik§

May 13, 2022

Abstract

Branch-and-cut is the most widely used algorithm for solving integer programs, employed
by commercial solvers like CPLEX and Gurobi. Branch-and-cut has a wide variety of tunable
parameters that have a huge impact on the size of the search tree that it builds, but are
challenging to tune by hand. An increasingly popular approach is to use machine learning to
tune these parameters: using a training set of integer programs from the application domain at
hand, the goal is to ﬁnd a conﬁguration with strong predicted performance on future, unseen
integer programs from the same domain. If the training set is too small, a conﬁguration may
have good performance over the training set but poor performance on future integer programs.
In this paper, we prove sample complexity guarantees for this procedure, which bound how large
the training set should be to ensure that for any conﬁguration, its average performance over the
training set is close to its expected future performance. Our guarantees apply to parameters
that control the most important aspects of branch-and-cut: node selection, branching constraint
selection, and cutting plane selection, and are sharper and more general than those found in
prior research [7, 9].

1

Introduction

Branch-and-cut (B&C) is a powerful algorithmic paradigm that is the backbone of all modern
integer programming (IP) solvers. The main components of B&C can be tuned and tweaked in
a myriad of ways. The fastest commercial IP solvers like CPLEX and Gurobi employ an array
of heuristics to make decisions at every stage of B&C to reduce the solving time as much as
possible, and give the user freedom to tune the multitude of parameters inﬂuencing the search
through the space of feasible solutions. However, tuning the parameters that control B&C in a
principled way is an inexact science with little to no formal mathematical guidelines. A rapidly
growing line of work studies machine-learning approaches to speeding up the various aspects of
B&C—in particular investigating whether high-performing B&C parameter conﬁgurations can be
learned from a training set of typical IPs from the particular application at hand [2, 22, 24, 27,
29, 32, 37, 42, 43]. Complementing the substantial number of experimental approaches using
machine learning for B&C, a recent generalization theory has developed in parallel that aims to
provide a rigorous theoretical foundation for how well any B&C conﬁguration learned from training
IP data will perform on new unseen IPs [7, 9].
In particular, this line of theoretical research
provides sample complexity guarantees that bound how large the training set should be to ensure

∗School of Computer Science, Carnegie Mellon University. ninamf@cs.cmu.edu
†Computer Science Department, Carnegie Mellon University. sprasad2@cs.cmu.edu
‡Computer Science Department, Carnegie Mellon University, Optimized Markets, Inc., Strategic Machine, Inc.,

Strategy Robot, Inc. sandholm@cs.cmu.edu

§Department of Electrical Engineering and Computer Sciences, UC Berkeley. vitercik@berkeley.edu

1

 
 
 
 
 
 
that no matter how the parameters are conﬁgured (i.e., using any approach from prior research),
the average performance of branch-and-cut over the training set is close to its expected future
performance. Sample complexity bounds are important because with too small a training set,
learning is impossible: a conﬁguration may have strong average performance over the training set
but terrible expected performance on future IPs. If the training set is too small, then no matter
how the parameters are tuned, the resulting conﬁguration will not have reliably better performance
than any default conﬁguration. State-of-the-art parameter tuning methods have historically come
without any provable guarantees, and our results ﬁll in that gap for a wide array of tunable B&C
parameters. In this paper, we expand and improve upon the existing theory to develop a wider
and sharper handle on the learnability of the key components of B&C.

1.1 Summary of main contributions

Our main contribution is a formalization of a general model of tree search, presented in Section 2.1,
that allows us to improve and generalize prior results on the sample complexity of tuning B&C.
In this model, the algorithm repeatedly chooses a leaf node of the search tree, performs a series of
actions (for example, a cutting plane to apply and a constraint to branch on), and adds children
to that leaf in the search tree. The algorithm will also fathom nodes when applicable. The node
and action selection are governed by scoring rules, which assign a real-valued score to each node
and possible action. For example, a node-selection scoring rule might equal the objective value of
the node’s LP relaxation. We focus on general tree search with path-wise scoring rules. At a high
level, a score of a node or action is path-wise if its value only depends on information contained
along the path between the root and that node, as is often the case in B&C. Many commonly
used scoring rules are path-wise including the eﬃcacy [4], objective parallelism [1], directed cutoﬀ
distance [15], and integral support [41] scoring rules, all used for cut selection by the leading open-
souce solver SCIP [15]; the best-bound scoring rule for node selection; and the linear, product, and
most-fractional scoring rules for variable selection using strong branching [1]. In Section 4, we show
how this general model of tree search captures a wide array of B&C components, including node
selection, general branching constraint selection, and cutting plane selection, simultaneously. We
also provide experimental evidence that, in the case of cutting plane selection, the data-dependent
tuning suggested by our model can lead to dramatic reductions in the number of nodes expanded
by B&C.

In Section 3, we prove our main structural result: for any IP, the tree search parameter space can
be partitioned into a ﬁnite number of regions such that in any one region, the resulting search tree is
ﬁxed. This is in spite of the fact that the B&C search tree can be an extremely unstable function of
its parameters, with minuscule changes leading to exponentially better or worse performance [7, 9].
By analyzing the complexity of this partition, we prove our sample complexity bound. In particular,
we relate the complexity of the partition to the pseudo-dimension of the set of functions that
measure the performance of B&C as a function of the input IP. Pseudo-dimension (deﬁned in
Section 3) is a combinatorial notion from machine learning theory that measures the intrinsic
complexity of a set of functions. At a high level, it measures how well a set of functions are
able match complex patterns. Classic results from learning theory then allow us to translate our
pseudo-dimension bound into a sample complexity guarantee [3], capturing the intuition that the
more complex patterns one can ﬁt (i.e., the larger the pseudo-dimension is), the more samples
needed to generalize. The sample complexity bound grows linearly with the pseudo-dimension, so
ideally, the pseudo-dimension will be polynomial in the size of the problem.

We show that the pseudo-dimension is only polynomial in the depth of the tree (which is, for
example, at most the number of variables in the case of binary integer programming). By contrast,

2

we might na¨ıvely expect the pseudo-dimension to grow linearly with the number of arithmetic
operations required to compute the B&C tree (as in Theorem 8.4 by Anthony and Bartlett [3]),
which is exponential in the depth of the tree. In fact, our bound is exponentially smaller than the
pseudo-dimension bound of prior research by Balcan et al. [9], which grows linearly with the total
number of nodes in the tree. Their results apply to any type of scoring rule, path-wise or otherwise.
By taking advantage of the path-wise structure, we are able to reason inductively over the depth of
the tree, leading to our exponentially improved bound. Our results recover those of Balcan et al. [7],
who only studied path-wise scoring rules for single-variable selection for branching. In contrast,
we are able to handle many more of the critical components of tree search: node selection, general
branching constraint selection, and cutting plane selection.

1.2 Additional related research

A growing body of research has studied how machine learning can be used to speed up the time
it takes to solve integer programs, primarily from an empirical perspective, whereas we study
this problem from a theoretical perspective. This line of research has included general parameter
tuning procedures [24, 25, 27, 37], which are not restricted to any one aspect of B&C. Researchers
have also honed in on speciﬁc aspects of tree search and worked towards improving those using
machine learning. These include variable selection [2, 7, 13, 16, 19, 29], general branching constraint
selection [44], cut selection [9, 23, 37, 39], node selection [21, 36], and heuristic scheduling [10, 30].
Machine learning approaches to large neighborhood search have also been used to speed up solver
runtimes [38].

This paper contributes to a line of research that provides sample complexity guarantees for
algorithm conﬁguration, often by using structure exhibited by the algorithm’s performance as a
function of its parameters [5–9, 20]. This line of research has studied algorithms for clustering [6],
computational biology [8], and integer programming [7, 9], among other computational problems.
The main contribution of this paper is to provide a sharp yet general analysis of the performance
of tree search as a function of its parameters.

A related line of research provides algorithm conﬁguration procedures with provable guarantees
that are agnostic to the speciﬁc algorithm that is being conﬁgured [31, 40] and are particularly well-
suited for algorithms with a ﬁnite number of possible conﬁgurations (though they can be applied
to algorithms with inﬁnite parameter spaces by randomly sampling a ﬁnite set of conﬁgurations).

2 Main tree search model

In this section we present our general tree search model and situate it within the framework of
sample complexity. Balcan et al. [9] studied the sample complexity of a much more general formu-
lation of a tunable search algorithm without any inherent tree structure. Our formulation explicitly
builds a tree.

2.1 General model of tree search

Tree search starts with a root node. In each round of tree search, a leaf node Q is selected. At
this node, one of three things may occur: (1) Q is fathomed, meaning it is never visited again,
(2) some action is taken at Q, and then it is fathomed, or (3) some action is taken at Q, and
then some number of children nodes of Q are added to the tree. (For example, an action might
represent a decision about which variable to branch on.) This process repeats until the tree has no
unfathomed leaves. More formally, there are functions actions, children, and fathom prescribing

3

Algorithm 1 Tree search
Input: Root node Q, depth limit ∆

1: Initialize T = Q.
2: while T contains an unfathomed leaf do
3:

Select a leaf Q of T that maximizes nscore(T , Q).
if depth(Q) = ∆ or fathom(T , Q, None) then

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

Fathom Q.

else

Select an action A ∈ actions(T , Q) that maximizes ascore(T , Q, A).
if fathom(T , Q, A) then

Fathom Q.

else if children(T , Q, A) = ∅ then

Fathom Q.

else

Add all nodes in children(T , Q, A) to T as children of Q.

how the search proceeds. Given a partial tree T and a leaf Q of T , actions(T , Q) outputs a set
of actions available at Q. Given a partial tree T , a leaf Q of T , and an action A ∈ actions(T , Q),
fathom(T , Q, A) ∈ {true, false} is a Boolean function used to determine when to fathom a leaf
Q of T given that action A ∈ actions(T , Q) ∪ {None} was taken at Q, and children(T , Q, A)
outputs a (potentially empty) list of nodes representing the children of Q to be added to the search
tree given that action A was taken at Q. Finally, nscore(T , Q) is a node-selection score that
outputs a real-valued score for each leaf of T , and ascore(T , Q, A) is an action-selection score that
outputs a real-valued score for each action A ∈ actions(T , Q). These scores are heuristics that
are meant to indicate the quality of exploring a node or performing an action.

Many aspects of B&C are governed by scoring rules [1]. For example, commonly used scoring
rules for cutting plance selection include eﬃcacy [4], which is the perpendicular distance from
the current LP solution to the cutting plane; parallelism [1], which measures the angle between
the objective and the normal vector to the cutting plane; and directed cutoﬀ [15], which is the
distance from the current LP solution to the cutting plane along the direction of the line segment
connecting the LP solution to the current best incumbent integer solution For node selection, under
the commonly used best-ﬁrst node selection policy, nscore(T , Q) equals the objective value of the
LP relaxation of the IP represented by the node Q. Finally, for variable selection, popular scoring
rules include a maximum change in LP objective value after branching on the variable (where the
maximum is taken over the two resulting children), the minimum change in the LP objective value,
linear combinations of these two values, and the product of these two values [1]. Algorithm 1 is a
formal description of tree search using these functions.

The key condition that enables us to derive stronger sample complexity bounds compared to
prior research is the notion of a path-wise function, which was also used in prior research but only
in the context of variable selection [7].

Deﬁnition 2.1 (Path-wise functions). A function f on tree-leaf pairs is path-wise if for all T and
Q ∈ T , f (T , Q) = f (TQ, Q), where TQ is the path from the root of T to Q. A function g on
tree-leaf-action triples is path-wise if for all A, fA(T , Q) := g(T , Q, A) is path-wise.

We assume that actions, ascore, nscore and children are path-wise, though fathom is not

necessarily path-wise.

4

Many commonly-used scoring rules are path-wise. For example, scoring rules are often functions
of the LP relaxation of the IP represented by a given node, and these scoring rules are path-wise.
Speciﬁc examples include the eﬃcacy, objective parallelism, directed cutoﬀ distance, and integral
support scoring rules used for cut selection; the best-bound scoring rule for node selection; and the
linear, product, and most-fractional scoring rules for variable selection using strong branching. A
point of clariﬁcation: the pathwise assumption is with respect to the numerical scores assigned to
actions/nodes. The actual act of, for example, node selection, can depend on the entire tree. For
example, consider the best-bound node selection rule in branch-and-cut, which chooses the node
with the best LP estimate. Here, the scoring rule, which is the LP objective value itself, is pathwise,
but ultimately the node that is selected depends on the LP bounds at every unexplored node of
the tree. This is ﬁne for our analysis. Similarly, the decision to fathom a node based on LP bounds
is a decision that depends on the entire tree built so far, which is also captured by our analysis.

No one scoring rule is optimal across all application domains, and prior research on variable
selection has shown that it can be advantageous to adapt the scoring rule to the application domain
at hand [7]. To this end, Algorithm 1 can be tuned by two parameters µ ∈ [0, 1] and λ ∈ [0, 1] that
control action selection and node selection, respectively. Given two ﬁxed path-wise action-selection
scores ascore1 and ascore2, we deﬁne a new score by

ascoreµ(T , Q) = µ · ascore1(T , Q) + (1 − µ) · ascore2(T , Q).

Similarly, given two path-wise node-selection scores nscore1 and nscore2, we deﬁne

nscoreλ(T , Q, A) = λ · nscore1(T , Q, A) + (1 − λ) · nscore2(T , Q, A).

Then, if nscoreλ and ascoreµ are used as the scores in Algorithm 1, we can view the behavior
of tree search as a function of µ and λ. The choice to use a convex combination of scores is not
new: prior research has shown that this idea can lead to dramatic improvements in the case of
single-variable branching [7]. Furthermore, the leading open source solver SCIP uses a hard-coded
weighted sum of scoring rules to select cutting planes. More broadly, interpolating between two
scores is a commonly-studied modeling choice in other machine learning topics such as clustering [6].
Finally, we assume there exists b, k ∈ N such that |actions(T , Q)| ≤ b for any Q ∈ T , and

|children(T , Q, A)| ≤ k for all Q, A.

2.2 Problem formulation

We now deﬁne the notion of a sample complexity bound more formally. Let Q denote the domain of
possible input root nodes Q to Algorithm 1 (for example, the set of all IPs with n variables and m
constraints). As is common in prior research on algorithm conﬁguration [22, 24, 27, 32, 37, 42, 43],
we assume there is some unknown distribution D over Q. In the IP setting, D could represent, for
example, typical scheduling IP instances solved by an airline company. The sample complexity of
a class of real valued functions F = {f : Q → R} is the minimum number of independent samples
required from D so that with high probability over the samples, the empirical value of f on the
samples is a good approximation of the expected value of f over D, uniformly over all f ∈ F .
Formally, given an error parameter ε and conﬁdence parameter δ, the sample complexity NF (ε, δ)
is the minimum N0 ∈ N such that for any N ≥ N0,

(cid:32)

Pr
Q1,...,QN ∼D

sup
f ∈F

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
N

N
(cid:88)

i=1

f (Qi) − E
Q∼D

(cid:12)
(cid:12)
(cid:12)
[f (Q)]
(cid:12)
(cid:12)

(cid:33)

≤ ε

≥ 1 − δ

5

for all distributions D supported on Q. Equivalently, our results bound the error εF (N, δ) between
the empirical value of any f ∈ F and its true expected value in terms of the number of training
samples N and the conﬁdence parameter δ. NF (ε, δ) is the number of samples required to achieve
a prescribed error bound ε, while εF (N, δ) provides an error bound for any number N of samples
at hand. We provide bounds on NF (ε, δ) and εF (N, δ) in terms of a common learning-theoretic
measure of intrinsic complexity of F called pseudo-dimension, which is detailed in Section 3.

In the context of Algorithm 1, we study families of tree-constant cost functions. A cost function
cost : Q → R is tree constant if cost(Q) only depends on the tree built by Algorithm 1 on input Q
(an example is tree size). Let costµ,λ(Q) denote this cost when Algorithm 1 is run using the scores
ascoreµ = µ · ascore1 + (1 − µ) · ascore2 and nscoreλ = λ · nscore1 + (1 − λ) · nscore2. We study
the sample complexity of F = {costµ,λ : µ, λ ∈ [0, 1]}. We emphasize that we primarily interpret
tree-constant functions as proxies for run-time. In the context of integer programming, tree size is
one such measure. A strength of these guarantees is that they apply no matter how the parameters
are tuned: optimally or suboptimally, manually or automatically. For any conﬁguration, these
guarantees bound the diﬀerence between average performance over the training set and expected
future performance on unseen IPs.

3 Generalization guarantees for tree search

In order to derive our sample complexity guarantees, we ﬁrst prove a key structural property: the
behavior of Algorithm 1 is piecewise constant as a function of the node-selection score parameter
λ and the action-selection score parameter µ. We give a high-level outline of our approach. We
ﬁrst assume that the conditional checks fathom(T , Q, ·) = true (lines 4 and 8) are suppressed. Let
A(cid:48) denote Algorithm 1 without these checks (so A(cid:48) fathoms a node if and only if the depth limit
is reached or if the node has no children). The behavior of A(cid:48) as a function of µ and λ can be
shown to be piecewise constant using the same argument as in Claim 3.4 of Balcan et al. [7]. Given
this, our ﬁrst main technical contribution (Lemma 3.1) is a generalization of Claim 3.5 of Balcan et
al. [7] that relates the behavior of A(cid:48) to Algorithm 1. The argument in Balcan et al. [7] is speciﬁc
to branching, but we are able to prove our result in a much more general setting. Our second main
technical contribution (Lemma 3.3) is to establish piecewise structure when the node-selection score
is controlled by λ ∈ [0, 1]. The main reason for this auxiliary step of analyzing A(cid:48) is due to the fact
that fathom is not necessarily a path-wise function, and can depend on the state of the entire tree.

Lemma 3.1. Fix µ ∈ [0, 1]. Let T and T (cid:48) be the trees built by Algorithm 1 and A(cid:48), respectively,
using the action-selection score µ · ascore1 + (1 − µ) · ascore2. Let Q be any node in T , and let
TQ be the path from the root of T to Q. Then, TQ is a rooted subtree of T (cid:48), no matter what node
selection policy is used.

Proof. Let t denote the length of the path TQ. Let TQ be comprised of the sequence of nodes
(Q1, . . . , Qt) such that Q1 is the root of T , Qt = Q, and for each τ , Qτ +1 ∈ children(TQτ , Qτ , Aτ )
where Aτ ∈ actions(TQτ , Qτ ) is the action selected by Algorithm 1 at node Qτ . We show that
(Q1, . . . , Qt) is a rooted path in T (cid:48) as well.

Suppose for the sake of contradiction that this is not the case. Let τ ∈ {2, . . . , t} be the minimal
index such that (Q1, . . . , Qτ −1) is a rooted path in T (cid:48), but there is no edge in T (cid:48) from Qτ −1 to
node Qτ . There are two possible cases:

Case 1. Qτ −1 was fathomed by A(cid:48). This case is trivially not possible since whenever A(cid:48)
fathoms a node, so does Algorithm 1 (recall A(cid:48) was deﬁned by suppressing fathoming conditions
of Algorithm 1).

6

τ −1) where A(cid:48)

Case 2. Qτ /∈ children(T (cid:48), Qτ −1, A(cid:48)

τ −1 is the action taken by A(cid:48) at node Qτ −1.
τ −1) = ∅, then Qτ −1 would be fathomed by A(cid:48), which cannot
In this case, if children(T (cid:48), Qτ −1, A(cid:48)
happen by the ﬁrst case. Otherwise, if children(T (cid:48), Qτ −1, A(cid:48)
τ −1) (cid:54)= ∅, we show that we arrive at
a contradiction due to the fact that the scoring rules, action-set functions, and children functions
τ −1 denote the action taken by A(cid:48) at Qτ −1, and let Aτ −1 denote the action
are all path-wise. Let A(cid:48)
taken by Algorithm 1 at Qτ −1. Since actions is path-wise,

actions(T , Qτ −1) = actions(TQτ −1, Qτ −1) = actions(T (cid:48), Qτ −1).

Since ascore1 and ascore2 are path-wise, we have

µ · ascore1(T ,Qτ −1, A) + (1 − µ) · ascore2(T , Qτ −1, A)

= µ · ascore1(TQτ −1, Qτ −1, A) + (1 − µ) · ascore2(TQτ −1, Qτ −1, A)
= µ · ascore1(T (cid:48), Qτ −1, A) + (1 − µ) · ascore2(T (cid:48), Qτ −1, A).

for all actions A ∈ actions(TQτ −1, Qτ −1). Therefore Algorithm 1 and A(cid:48) choose the same action
at node Qt−1, that is, Aτ −1 = A(cid:48)

τ −1. Finally, since children is path-wise, we have

children(T , Qτ −1, Aτ −1) = children(TQτ −1, Qτ −1, Aτ −1) = children(T (cid:48), Qτ −1, Aτ −1).

Since Qτ ∈ children(T , Qτ −1, Aτ −1), this is a contradiction, which completes the proof.

We use the following generalization of Claim 3.4 of Balcan et al. [7] that shows the behavior
of A(cid:48) is piecewise constant. While their argument only applies to single-variable branching, our
key insight is that the same reasoning can be readily adapted to handle any actions (including
general branching constraints and cutting planes). The structure of our proof (which we defer to
the appendix) is identical, but is modiﬁed to work in our more general setting. This style of analysis
is similar in spirit to [34].

Lemma 3.2. Let ascore1 and ascore2 be two path-wise action-selection scores. Fix the input
root node Q. There are T ≤ k∆(∆−1)/2b∆ subintervals I1, . . . , IT partitioning [0, 1] where for any
subinterval It, the action-selection score µ · ascore1 + (1 − µ) · ascore2 results in the same tree built
by A(cid:48) for all µ ∈ It, no matter what node selection policy is used.

We now prove our main structural result for Algorithm 1.

Lemma 3.3. Let ascore1 and ascore2 be path-wise action-selection scores and let nscore1 and
nscore2 be path-wise node-selection scores. Fix the input root node Q. There are T ≤ k∆(9+∆)b∆
rectangles partitioning [0, 1]2 such that for any rectangle Rt, the node-selection score λ · nscore1 +
(1 − λ) · nscore2 and the action-selection score µ · ascore1 + (1 − µ) · ascore2 result in the same
tree built by Algorithm 1 for all (µ, λ) ∈ Rt.

Proof. By Lemma 3.2, there is a partition of [0, 1] into subintervals I1 ∪ · · · ∪ IT such that for all
µ within a given subinterval, the tree built by A(cid:48) is invariant (independent of the node-selection
score). Fix a subinterval It of this partition. Let T denote the tree built by Algorithm 1. For each
node Q ∈ T , let TQ denote the path from the root to Q in T . Since nscore1 is path-wise, for any
tree T (cid:48) containing TQ as a rooted path, nscore1(T (cid:48), Q) = nscore1(TQ, Q). The same holds for
nscore2. For every pair of nodes Q1, Q2 ∈ T , let λ(Q1, Q2) ∈ [0, 1] denote the unique solution to

λ · nscore1(TQ1, Q1) + (1 − λ) · nscore2(TQ1, Q1)

= λ · nscore1(TQ2, Q2) + (1 − λ) · nscore2(TQ2, Q2),

7

if it exists (if there are either (1) no solutions or (2) inﬁnitely many solutions, set λ(Q1, Q2) = 0).
The thresholds λ(Q1, Q2) for every pair of nodes Q1, Q2 ∈ T partition [0, 1] into subintervals such
that for all λ within a given subinterval, the total order over the nodes of T induced by nscoreλ
is invariant. In particular, this means that the node selected by each iteration of Algorithm 1 is
invariant. Let J1 ∪ · · · ∪ JS denote these subintervals induced by the thresholds over all subinterval
It ∈ {I1, . . . , IT } established in Lemma 3.2.

We now show that this implies that the tree built by Algorithm 1 is invariant over all (µ, λ)
within a given rectangle It × Js. Fix some rectangle It × Js. We proceed by induction on the
iterations (of the while loop) of Algorithm 1. For the base case (iteration 0, before entering the
while loop), the tree consists of only the root, so the hypothesis trivially holds. Now, suppose the
statement holds up until the jth iteration, for some j. We analyze each line of Algorithm 1 to
show that the behavior of the j + 1st iteration is independent of (µ, λ) ∈ It × Js. First, since Js
determines the node selected at each iteration (as argued above), the node selected on the j + 1st
iteration (line 3) is ﬁxed, independent of (µ, λ) ∈ It × Js. Denote this node by Q. Thus, whether
depth(Q) = ∆ is independent of (µ, λ) ∈ It × Js, and similarly whether fathom(T , Q, None) = true
is independent of (µ, λ) ∈ It × Js (line 4). This implies that whether or not Q is fathomed at this
stage is independent of (µ, λ) ∈ It × Js. If Q was fathomed, we are done. Otherwise, we argue that
the action selected at line 7 is invariant over (µ, λ) ∈ It × Js. By Lemma 3.2, A(cid:48) builds the same
tree for all µ ∈ It. Let TQ denote the path from the root to Q in this tree. By Lemma 3.1, TQ is the
path from the root to Q in the tree built by Algorithm 1 as well. The action selected at Q by A(cid:48) is
invariant over µ ∈ It (by Lemma 3.2). Therefore, since actions, ascore1, and ascore2 are path-
wise, the action A selected by Algorithm 1 at Q is invariant over µ ∈ It. Finally, fathom(T , Q, A)
and children(T , Q, A) are completely determined, so the execution of the remaining conditional
statement (line 8 to line 13) is invariant over (µ, λ) ∈ It × Js. Thus, the entire iteration of
Algorithm 1 is invariant over (µ, λ) ∈ It × Js, which completes the induction.

Finally, we count the total number of rectangles in our partition of [0, 1]2. For each interval
It in the partition established in Lemma 3.2, we obtained a partition of It × [0, 1] into rectangles
induced by at most (cid:0)|T |
2

(cid:1) thresholds, which consists of at most at most

1 +

(cid:18)(k∆+1 − 1)/(k − 1)
2

(cid:19)

≤ 1 +

(cid:19)2

(cid:18) k∆+1 − 1
k − 1

≤ k5∆

subintervals. Accounting for every interval It ∈ {I1, . . . , IT } in the partition from Lemma 3.2, we
get a total of T k5∆ ≤ k∆(9+∆)/2b∆ rectangles, as desired.

We now derive generalization guarantees for the collection F = {costµ,λ : (µ, λ) ∈ [0, 1]2} where
cost is any tree-constant function, such as tree size. We do this by bounding the pseudo-dimension
of F , which is a combinatorial measure of intrinsic complexity of a class of real valued functions.
The pseudo-dimension of F , denoted by Pdim(F ), is the largest positive integer N such that
there exist N nodes Q1, . . . , QN ∈ Q and N thresholds r1, . . . , rN ∈ R such that |{(sign(f (Q1) −
r1), . . . , sign(f (QN ) − rN )) : f ∈ F }| = 2N . A well-known result in learning theory [3] states that
if functions in F have bounded range [−H, H], then

NF (ε, δ) = O

(cid:18) H 2

(cid:19)
ε2 (Pdim(F ) + ln(1/δ))

(cid:32)

(cid:114)

and εF (N, δ) = O

H

Pdim(F ) + ln(1/δ)
N

(cid:33)

.

When each function in F maps to {0, 1}, the pseudo-dimension is more commonly referred to as
the VC dimension.

8

Bounding the pseudo-dimension is a simple instantiation of the general framework provided by
Balcan et al. [8] with the piecewise structure established in Lemma 3.3. Balcan et al.’s [8] main
result gives pseudo-dimension bounds for families of piecewise structured functions in terms of the
VC dimension of the class of 0/1 classiﬁers deﬁning the boundaries of the functions, the number
of classiﬁers deﬁning the boundaries, and the pseudo-dimension of the family of functions when
restricted to each piece. (Strictly, this result is in terms of the dual classes of the boundary and piece
functions. However, since the dual class of all linear separators is the set of all linear separators,
we omit this detail for simplicity.)

Theorem 3.4. Let cost(Q) be any tree-constant cost function, and let costµ,λ(Q) be the cost of
the tree built by Algorithm 1 on input root node Q using action-selection score parameterized by µ
and node-selection score parameterized by λ. Then, Pdim({costµ,λ}) = O(∆2 log k + ∆ log b).

Proof. By Lemma 3.3, there are at most T = k∆(9+∆)b∆ rectangles partitioning [0, 1]2 such that
for a ﬁxed input node Q, costµ,λ(Q) is constant over each rectangle as a function of µ, λ. These
T rectangles can be deﬁned by T thresholds on [0, 1] corresponding to µ and T thresholds on [0, 1]
corresponding to λ. Thus, the T rectangles can be identiﬁed by T 2 = k2∆(9+∆)b2∆ linear separators
in R2. The VC dimension of linear separators in R2 is O(1). The pseudo-dimension of the set of
constant functions is also O(1). Plugging these quantities into the main theorem of Balcan et al. [8]
yields the theorem statement.

3.1 Multiple actions

Theorem 3.4 can be easily generalized to the case where there are multiple actions of diﬀerent types
taken at each node of Algorithm 1. Speciﬁcally, there are now d path-wise action-set functions
actions1, . . . , actionsd, and at line 7 of Algorithm 1 we take one action of each type, that is, we
select action A1 ∈ actions1(T , Q), A2 ∈ actions2(T , Q), and so on. The functions fathom and
children then depend on all d actions taken at node Q. We assume that there are two scoring rules
ascorei
2 for each action type i = 1, . . . , d. Algorithm 1 can then be parameterized
by (µ, λ), where µ ∈ Rd is a vector of parameters controlling each action, so the ith action is
selected to maximize µi · ascorei
2. Then, as long as d = O(1), we get the same
pseudo-dimension bound. We assume b is a uniform upper bound on the size of actionsi for any
i. The proof is nearly identical, and we defer it to the appendix (which also contains more details
on the multiple-action setup).

1 + (1 − µi) · ascorei

1 and ascorei

Theorem 3.5. Let cost(Q) be any tree-constant cost function, and let costµ,λ(Q) be the cost of
the tree built by Algorithm 1 on input root node Q using action-selection scores parameterized by
µ ∈ Rd, where d = O(1), and node-selection score parameterized by λ. Then, Pdim({costµ,λ}) =
O(∆2 log k + ∆ log b).

4 Branch-and-cut for integer programming

We now instantiate our main results with the three main components of the B&C algorithm:
branching, cutting planes, and node selection, used to solve IPs max{cT x : Ax ≤ b, x ≥ 0, x ∈ Zn}
where c ∈ Rn, A ∈ Zm×n, b ∈ Zm. The function fathom(T , Q, A) outputs true if after having
taken action A the LP relaxation at Q is integral, infeasible, or worse than the best integral solution
found so far in T . The function children(T , Q, A) outputs the two subproblems generated by the
branching procedure on the IP at Q after having taken action A. For simplicity we refer only to
IPs, but everything in our discussion applies to mixed IPs as well. In our model of tree search,

9

node selection is controlled by λ. Cutting planes and branching are types of actions and controlled
by µ.

4.1 Branching

In this section, we provide guarantees for branching. Throughout this section we assume ∆ = O(n),
as is the case with single-variable branching.

4.1.1 Multivariable branching constraints

It is well known that allowing for more general generation of branching constraints can result
in smaller B&C trees. Gilpin and Sandholm [17] studied multivariable branches of the form
LP[i](cid:7) where S is a subset of the integer vari-
i∈S x[i] ≤ (cid:4)(cid:80)
(cid:80)
i∈S x∗
ables such that (cid:80)
LP[i] /∈ Z. Here, actions(T , Q) = 2[n], so, Pdim({costµ,λ}) = O(n2).
So our sample complexity bound for multivariable branching constraints is, surprisingly, only a
constant factor worse than the bound for single-variable branching constraints.

i∈S x[i] ≥ (cid:6)(cid:80)

LP[i](cid:5), (cid:80)

i∈S x∗

i∈S x∗

We give a simple example where B&C using only single variable branches builds a tree of
exponential size, while a single branch on the entire set of variables at the root yields two infeasible
subproblems (and a B&C tree of size 3).

Theorem 4.1. For any n, there is an IP with two constraints and n variables such that with
only single variable branches, B&C builds a tree of size 2(n−1)/2, while with a suitable multivariable
branch, B&C builds a tree of size three.

Proof. Let n be an odd positive integer. Consider the infeasible IP max{(cid:80)n
i=1 x[i] =
n, x ∈ {0, 1}n}. Jeroslow [26] proved that with only single-variable branches, B&C builds a tree
with 2(n−1)/2 nodes to determine infeasibility. However, with a suitable multivariable branch, B&C
will build a tree of constant size. The optimal solution to the LP relaxation of the IP is attained
when all variables are set to 1/2. A multivariable branch on all n variables produces the two
subproblems with constraints (cid:80)n
i=1 x[i] ≥ (cid:100)n/2(cid:101), respectively. Since n is
odd, (cid:98)n/2(cid:99) < n/2 and (cid:100)n/2(cid:101) > n/2, so the LP relaxations of both subproblems are infeasible.
Thus, B&C builds a tree with three nodes.

i=1 x[i] ≤ (cid:98)n/2(cid:99) and (cid:80)n

i=1 x[i] : 2 (cid:80)n

Yang et al. [45] provide more examples of situations where multivariable branching yields dra-
matic improvements in tree size over single variable branching. They also perform a computational
evaluation of a few diﬀerent strategies for generating multivariable branching constraints. Yang et
al. [44] explore gradient-boosting for learning to mimic strong branching for multiple variables.

4.1.2 Branching on general disjunctions

Branching constraints can be even more general than multivariable branches. Given any integer
vector π ∈ Zn and any integer π0 ∈ Z (jointly referred to as a disjunction), the constraints πT x ≤ π0
or πT x ≥ π0 + 1 represent a valid partition of the feasible region into subproblems. Owen and
Mehrotra [35] ran the ﬁrst experiments demonstrating that branching on general disjunctions can
lead to signiﬁcantly smaller tree sizes. Subsequent works have posed diﬀerent heuristics to select
disjunctions to branch on [14, 33].

In practice it is known that additional IP constraints should not have coeﬃcients that are too
large. If C is a bound on the magnitude of the coeﬃcient of any disjunction, then actions(T , Q) =
{−C, . . . , C}n+1, so Pdim({costµ,λ}) = O(n2 log C). Karamanov and Cornu´ejols [28] conduct a
computational evaluation of disjunctions derived from Gomory mixed-integer cuts. In this setting,

10

actions(T , Q) is the set of m or fewer disjunctions corresponding to the m or fewer Gomory
mixed-integer cuts derived from the simplex tableau from solving the LP relaxation of Q. In this
case, Pdim({costµ,λ}) = O(n2 + n log m).

4.2 Cutting planes

The action set can also correspond to cutting planes used to reﬁne the feasible region of the IP
at any stage of B&C. Here, actions(T , Q) is any set of cutting planes derived solely using the
path from the root to the IP at Q. Examples include the set of Chv´atal-Gomory (CG) derived
from the simplex tableau [18], and various combinatorial families of cutting planes such as clique
cuts, odd-hole cuts, and cover cuts. The set actions(T , Q) can also consist of sequences of cutting
planes, representing adding several cutting planes to the IP in waves. For example, the set of
all sequences of w CG cuts generated from the simplex tableau for an IP with m constraints has
size at most mw (regardless of whether the LP is resolved after each cut). The number of such
cutting planes provided by the LP tableau at any node in the tree is at most O(m + nw) (the
original IP has m constraints, and after at most n branches there are an additional n branching
constraints and at most nw cutting planes), which means that |actions(T , Q)| ≤ O(m + nw)w.
Thus, Pdim({costµ,λ}) = O(n2 + nw log(m + nw)).

We can also handle arbitrary CG cuts (not just ones from the LP tableau). Balcan et al. [9]
proved that given an IP with feasible region {x ∈ Zn : Ax ≤ b, x ≥ 0}, even though there are
inﬁnitely many CG cut parameters, there are eﬀectively only O(w2w (cid:107)A(cid:107)1,1 + 2w (cid:107)b(cid:107)1 + nw)1+mw
distinct sequences of cutting planes that w CG cut parameters can produce. At any node in the B&C
tree, the number of constraints is at most O(m + nw). So, on the domain of IPs with (cid:107)A(cid:107)1,1 ≤ α
and (cid:107)b(cid:107)1 ≤ β, |actions(T , Q)| ≤ O(w2wα + 2wβ + nw)1+w·O(m+nw). Thus, Pdim({costµ,λ}) =
O(n2w3m log(α + β + n)).

4.2.1 Experiments on cover cuts for the multiple knapsack problem

In this section, we demonstrate via experiments that tuning a convex combination of scoring rules
to select cuts can lead to dramatically smaller branch-and-cut trees when done in a data-dependent
manner. We study the classical NP-hard multiple knapsack problem: given a set N of items where
each item i ∈ N has a value pi ≥ 0 and a weight wi ≥ 0, and a set K of knapsacks where each
knapsack k ∈ K has a capacity Wk ≥ 0, the goal is to ﬁnd a feasible packing of the items into the
knapsacks of maximum value. We assume, without loss of generality, that the items are labeled in
descending order of weight, that is, w1 ≥ w2 ≥ · · · ≥ w|N |. This problem can be formulated as the
following binary IP:

maximize (cid:80)
subject to (cid:80)
(cid:80)

(cid:80)

k∈K pixk,i
i∈N
i∈N wixk,i ≤ Wk
k∈K xk,i ≤ 1

xk,i ∈ {0, 1}

∀ k ∈ K
∀ i ∈ N
∀ i ∈ N, k ∈ K

A subset C ⊆ N of items is called a cover for knapsack k ∈ K if (cid:80)
i∈C wi > Wk. If C is a cover, no
feasible solution can have xk,i = 1 for all i ∈ C, so (cid:80)
i∈C xk,i ≤ |C| − 1 is a valid constraint—called
a cover cut. When C is minimal (that is, C \ {i} is not a cover for every i ∈ C), such cover
cuts help tighten the knapsack IP by cutting oﬀ fractional LP solutions. We generate (a subset
of all) cover cuts for each knapsack k as follows: for each i ∈ N , let j > i be minimal such that
C = {i, i + 1, . . . , j} is a cover for k (if such a j exists). Since wi ≥ wj for j > i, C is a minimal
cover, and moreover the extended cover cut (cid:80)j
i=1 xi ≤ |C| − 1 is valid and dominates the minimal

11

(a) µ · E + (1 − µ) · P

(b) µ · E + (1 − µ) · D

(c) µ · D + (1 − µ) · P

Figure 1: Chv´atal distribution with 35 items and 2 knapsacks.

(a) µ · E + (1 − µ) · P

(b) µ · E + (1 − µ) · D

(c) µ · D + (1 − µ) · P

Figure 2: Chv´atal distribution with 35 items and 3 knapsacks.

cover cut (cid:80)
facet deﬁning for the integer hull under certain natural conditions [12].

i∈C xi ≤ |C| − 1. Extended cover cuts generated from minimal covers are known to be

We investigate the relationship between three scoring rules for cutting planes. The ﬁrst is
eﬃcacy (E), which is the perpendicular distance from the current LP solution to the cutting plane.
The second is parallelism (P), which measures the angle between the objective and the normal
vector to the cutting plane. The third is directed cutoﬀ (D), which is the distance from the current
LP solution to the cutting plane along the direction of the line segment connecting the LP solution
to the current best incumbent integer solution. More details, including explicit formulas, can be
found in [9] and references therein.

We consider two speciﬁc instances of the multiple knapsack problem, which are loosely based on
a class of knapsack problems introduced by Chv´atal that are diﬃcult to solve with vanilla branch-
and-bound [11, 45]. In the ﬁrst, pi = wi for all i ∈ N , and Wk = (cid:98)((cid:80)
i∈N wi)/2|K|(cid:99) + (k − 1) for
each k = 1, . . . , |K|. In the second, pi = w|N |−i+1, so the most valuable item is the lightest and the
least valuable item is the heaviest, and Wk is deﬁned as in the ﬁrst type. We call the ﬁrst class
of problems Chv´atal instances and the second class reverse Chv´atal instances. For a given N, K,
we generate (reverse) Chv´atal instances by drawing each weight independently as wi = (cid:98)zi(cid:99), where
zi ∼ N (50, 2), and sorting the items by weight in descending order.

In our experiments, we add (whenever possible) two extended cover cuts obtained in the afore-
mentioned manner at every node of the B&C tree. The two cuts chosen are the two with the
highest score µ · ascore1 + (1 − µ) · ascore2 among all extended cover cuts that are violated by
the current LP optimum, where ascore1, ascore2 ∈ {E, D, P}. Figures 1-4 display the average tree
size over 1000 samples for diﬀerent Chv´atal and reverse Chv´atal distributions as a function of µ,
where the domain [0, 1] of µ is discretized in increments of 0.01. We ran our experiments using the
Python API of CPLEX 12.10 with default cut generation turned oﬀ. All other aspects of B&C (e.g.

12

(a) µ · E + (1 − µ) · P

(b) µ · E + (1 − µ) · D

(c) µ · D + (1 − µ) · P

Figure 3: Reverse Chv´atal distribution with 100 items and 10 knapsacks.

(a) µ · E + (1 − µ) · P

(b) µ · E + (1 − µ) · D

(c) µ · D + (1 − µ) · P

Figure 4: Reverse Chv´atal distribution with 100 items and 15 knapsacks.

variable and node selection) are controlled by the default settings of CPLEX. The key takeaway of
our plots is that tuning a convex combination of scoring rules can lead to signiﬁcant savings in B&C
tree size, and that this tuning must be done with the IP distribution in mind. No single parameter
produces small trees for all the distributions we considered, and in fact a µ that minimizes tree
size for one distribution can result in the largest trees for another (as in Figures 2b and 4b, for
example). Furthermore, many of the plots display discernible trends (and in some cases are quite
smooth), suggesting that the number of samples required to avoid overﬁtting in practice can be
signiﬁcantly smaller than our theoretical bounds.

4.3 Improved bounds for branch-and-cut

To allow node selection, branching, and cutting-plane selection to be tuned simultaneously, we apply
Theorem 3.5. This allows us to bound the pseudo-dimension of the family of functions {costµ1,µ2,λ},
where µ1 controls branching, µ2 controls cutting-plane selection, and λ controls node selection. Let
actions1(T , Q) denote the set of branching actions available at Q, and let actions2(T , Q) denote
the set of cutting planes available at Q. Let b1, b2 ∈ N be such that actions1(T , Q) ≤ b1 and
actions2(T , Q) ≤ b2 for all T and all Q ∈ T . Fix two branching scores ascore1
2, ﬁx two
1, ascore2
cutting-plane selection scores ascore2
2, and ﬁx two node-selection scores nscore1, nscore2.

1, ascore1

Theorem 4.2. Let cost(Q) be any tree-constant cost function, and let costµ1,µ2,λ be the cost of
the tree built by B&C using branching score µ1 · ascore1
2, cutting-plane selection
score µ2 · ascore2
1 + (1 − µ2) · ascore2
2, and node-selection score λ · nscore1 + (1 − λ) · nscore2.
Then, with ∆ = O(n), Pdim({costµ1,µ2,λ}) = O(n2 + n log(b1 + b2)).

1 + (1 − µ1) · ascore1

13

4.3.1 Comparison to existing bounds

Balcan et al. [9] give a pseudo-dimension bound for tree search with a linear dependence on a cap
κ on the number of nodes allowed in any tree. Their pseudo-dimension bound in our setting is
Pdim({costµ1,µ2,λ}) = O(κ log κ + κ log b1 + κ log b2). While κ is treated as a constant, it can be
a prohibitively large quantity. In fact, without explicitly enforcing a limit on the number of nodes
expanded by B&C, Balcan et al. [9] obtain a pseudo-dimension bound of O(2n(log b1 + log b2)).
Balcan et al. [7] use the path-wise property to prove that Pdim({costµ}) = O(n2) for single-
variable branching, but for the case where branching is the only tunable component of B&C (and
node selection is ﬁxed).

5 Conclusions and future research

We presented a general model of tree search and proved sample complexity guarantees for this model
that improve and generalize upon the recent sample complexity theory for conﬁguring branch-and-
cut. There are many interesting and open directions for future research. One compelling open
question is to obtain pseudo-dimension bounds when action sets are inﬁnite. Balcan et al. [9]
alluded to this question in the case of cutting planes, and neither the techniques of their work nor
the techniques of the present work can handle, for example, important inﬁnite cutting-plane families
such as the class of Gomory mixed-integer cuts, or the inﬁnitely many valid disjunctions that could
be branched on. Beyond integer programming, our model of tree search could potentially be applied
to completely diﬀerent problem domains that exhibit tree structure. Another direction is to extend
our results to convex combinations of (cid:96) > 2 scoring rules µ1score1 + . . . µ(cid:96)score(cid:96), as Balcan et
al. [7] do in the special case of single-variable branching. However, their pseudo-dimension bound
grows exponentially in the number of variables n in that special case; developing techniques that
lead to a polynomial dependence on n remains a challenging open question.

Acknowledgements

This material is based on work supported by the National Science Foundation under grants CCF-
1733556, CCF-1910321, IIS-1901403, and SES-1919453, the ARO under award W911NF2010081,
the Defense Advanced Research Projects Agency under cooperative agreement HR00112020003,
a Simons Investigator Award, an AWS Machine Learning Research Award, an Amazon Research
Award, a Bloomberg Research Grant, and a Microsoft Research Faculty Fellowship.

References

[1] Tobias Achterberg. Constraint Integer Programming. PhD thesis, Technische Universit¨at

Berlin, 2007.

[2] Alejandro Marcos Alvarez, Quentin Louveaux, and Louis Wehenkel. A machine learning-based
approximation of strong branching. INFORMS Journal on Computing, 29(1):185–195, 2017.

[3] Martin Anthony and Peter Bartlett. Neural Network Learning: Theoretical Foundations. Cam-

bridge University Press, 2009.

[4] Egon Balas, Sebasti´an Ceria, and G´erard Cornu´ejols. Mixed 0-1 programming by lift-and-

project in a branch-and-cut framework. Management Science, 42(9):1229–1246, 1996.

14

[5] Maria-Florina Balcan. Data-driven algorithm design. In Tim Roughgarden, editor, Beyond

Worst Case Analysis of Algorithms. Cambridge University Press, 2020.

[6] Maria-Florina Balcan, Vaishnavh Nagarajan, Ellen Vitercik, and Colin White. Learning-
theoretic foundations of algorithm conﬁguration for combinatorial partitioning problems. In
Conference on Learning Theory (COLT), 2017.

[7] Maria-Florina Balcan, Travis Dick, Tuomas Sandholm, and Ellen Vitercik. Learning to branch.

In International Conference on Machine Learning (ICML), 2018.

[8] Maria-Florina Balcan, Dan DeBlasio, Travis Dick, Carl Kingsford, Tuomas Sandholm, and
Ellen Vitercik. How much data is suﬃcient to learn high-performing algorithms? Gener-
In Annual Symposium on Theory of
alization guarantees for data-driven algorithm design.
Computing (STOC), 2021.

[9] Maria-Florina Balcan, Siddharth Prasad, Tuomas Sandholm, and Ellen Vitercik. Sample
complexity of tree search conﬁguration: Cutting planes and beyond. In Annual Conference on
Neural Information Processing Systems (NeurIPS), 2021.

[10] Antonia Chmiela, Elias B Khalil, Ambros Gleixner, Andrea Lodi, and Sebastian Pokutta.
Learning to schedule heuristics in branch-and-bound. In Annual Conference on Neural Infor-
mation Processing Systems (NeurIPS), 2021.

[11] Vasek Chv´atal. Hard knapsack problems. Operations Research, 28(6):1402–1411, 1980.

[12] Michele Conforti, G´erard Cornu´ejols, Giacomo Zambelli, et al. Integer programming, volume

271. Springer, 2014.

[13] Giovanni Di Liberto, Serdar Kadioglu, Kevin Leo, and Yuri Malitsky. Dash: Dynamic approach
for switching heuristics. European Journal of Operational Research, 248(3):943–953, 2016.

[14] Matteo Fischetti and Andrea Lodi. Local branching. Mathematical Programming, 98:23–47,

2002.

[15] Gerald Gamrath, Daniel Anderson, Ksenia Bestuzheva, Wei-Kun Chen, Leon Eiﬂer, Maxime
Gasse, Patrick Gemander, Ambros Gleixner, Leona Gottwald, Katrin Halbig, Gregor Hendel,
Christopher Hojny, Thorsten Koch, Pierre Le Bodic, Stephen J. Maher, Frederic Matter,
Matthias Miltenberger, Erik M¨uhmer, Benjamin M¨uller, Marc E. Pfetsch, Franziska Schl¨osser,
Felipe Serrano, Yuji Shinano, Christine Tawﬁk, Stefan Vigerske, Fabian Wegscheider, Dieter
Weninger, and Jakob Witzig. The SCIP Optimization Suite 7.0. Technical report, Optimization
Online, March 2020. URL http://www.optimization-online.org/DB_HTML/2020/03/7705.
html.

[16] Maxime Gasse, Didier Ch´etelat, Nicola Ferroni, Laurent Charlin, and Andrea Lodi. Exact
combinatorial optimization with graph convolutional neural networks. In Annual Conference
on Neural Information Processing Systems (NeurIPS), pages 15554–15566, 2019.

[17] Andrew Gilpin and Tuomas Sandholm.

Information-theoretic approaches to branching in

search. Discrete Optimization, 8(2):147–159, 2011. Early version in IJCAI-07.

[18] Ralph E. Gomory. Outline of an algorithm for integer solutions to linear programs. Bulletin

of the American Mathematical Society, 64(5):275 – 278, 1958.

15

[19] Prateek Gupta, Maxime Gasse, Elias B Khalil, M Pawan Kumar, Andrea Lodi, and Yoshua
Bengio. Hybrid models for learning to branch. In Annual Conference on Neural Information
Processing Systems (NeurIPS), 2020.

[20] Rishi Gupta and Tim Roughgarden. A PAC approach to application-speciﬁc algorithm selec-

tion. SIAM Journal on Computing, 46(3):992–1017, 2017.

[21] He He, Hal Daume III, and Jason M Eisner. Learning to search in branch and bound algo-

rithms. In Annual Conference on Neural Information Processing Systems (NeurIPS), 2014.

[22] Eric Horvitz, Yongshao Ruan, Carla Gomez, Henry Kautz, Bart Selman, and Max Chicker-
In Proceedings of the

ing. A Bayesian approach to tackling hard computational problems.
Conference on Uncertainty in Artiﬁcial Intelligence (UAI), 2001.

[23] Zeren Huang, Kerong Wang, Furui Liu, Hui-ling Zhen, Weinan Zhang, Mingxuan Yuan, Jianye
Hao, Yong Yu, and Jun Wang. Learning to select cuts for eﬃcient mixed-integer programming.
arXiv preprint arXiv:2105.13645, 2021.

[24] Frank Hutter, Holger H Hoos, Kevin Leyton-Brown, and Thomas St¨utzle. ParamILS: An
automatic algorithm conﬁguration framework. Journal of Artiﬁcial Intelligence Research, 36
(1):267–306, 2009. ISSN 1076-9757.

[25] Frank Hutter, Holger Hoos, and Kevin Leyton-Brown. Sequential model-based optimization
for general algorithm conﬁguration. In International Conference on Learning and Intelligent
Optimization (LION), pages 507–523, 2011.

[26] Robert G Jeroslow. Trivial integer programs unsolvable by branch-and-bound. Mathematical

Programming, 6(1):105–109, 1974.

[27] Serdar Kadioglu, Yuri Malitsky, Meinolf Sellmann, and Kevin Tierney. ISAC—instance-speciﬁc
algorithm conﬁguration. In European Conference on Artiﬁcial Intelligence (ECAI), 2010.

[28] Miroslav Karamanov and G´erard Cornu´ejols. Branching on general disjunctions. Mathematical

Programming, 128(1-2):403–436, 2011.

[29] Elias Khalil, Pierre Le Bodic, Le Song, George Nemhauser, and Bistra Dilkina. Learning to

branch in mixed integer programming. In AAAI Conference on Artiﬁcial Intelligence, 2016.

[30] Elias Khalil, Bistra Dilkina, George Nemhauser, Shabbir Ahmed, and Yufen Shao. Learning
to run heuristics in tree search. In International Joint Conference on Artiﬁcial Intelligence
(IJCAI), 2017.

[31] Robert Kleinberg, Kevin Leyton-Brown, and Brendan Lucier. Eﬃciency through procrasti-
nation: Approximately optimal algorithm conﬁguration with runtime guarantees. In Interna-
tional Joint Conference on Artiﬁcial Intelligence (IJCAI), 2017.

[32] Kevin Leyton-Brown, Eugene Nudelman, and Yoav Shoham. Empirical hardness models:
Methodology and a case study on combinatorial auctions. Journal of the ACM, 56(4):1–52,
2009. ISSN 0004-5411.

[33] Ashutosh Mahajan and Theodore K Ralphs. Experiments with branching using general dis-

junctions. In Operations Research and Cyber-Infrastructure, pages 101–118. Springer, 2009.

16

[34] Nimrod Megiddo. Combinatorial optimization with rational objective functions. Mathematics

of Operations Research, pages 414–424, 1979.

[35] Jonathan H. Owen and Sanjay Mehrotra. Experimental results on using general disjunctions
in branch-and-bound for general-integer linear programs. Computational Optimization and
Applications, 20(2):159–170, November 2001.

[36] Ashish Sabharwal, Horst Samulowitz, and Chandra Reddy. Guiding combinatorial optimiza-
tion with UCT. In International Conference on AI and OR Techniques in Constraint Pro-
gramming for Combinatorial Optimization Problems. Springer, 2012.

[37] Tuomas Sandholm. Very-large-scale generalized combinatorial multi-attribute auctions:
In Zvika Neeman, Alvin Roth, and Nir

Lessons from conducting $60 billion of sourcing.
Vulkan, editors, Handbook of Market Design. Oxford University Press, 2013.

[38] Jialin Song, Ravi Lanka, Yisong Yue, and Bistra Dilkina. A general large neighborhood
search framework for solving integer programs. In Annual Conference on Neural Information
Processing Systems (NeurIPS), 2020.

[39] Yunhao Tang, Shipra Agrawal, and Yuri Faenza. Reinforcement learning for integer program-

ming: Learning to cut. International Conference on Machine Learning (ICML), 2020.

[40] Gell´ert Weisz, Andr´as Gy¨orgy, and Csaba Szepesv´ari. LeapsAndBounds: A method for ap-
proximately optimal algorithm conﬁguration. In International Conference on Machine Learn-
ing (ICML), 2018.

[41] Franz Wesselmann and Uwe Suhl.

Implementing cutting plane management and selection

techniques. Technical report, University of Paderborn, 2012.

[42] Lin Xu, Frank Hutter, Holger H Hoos, and Kevin Leyton-Brown. Satzilla: portfolio-based
algorithm selection for SAT. Journal of Artiﬁcial Intelligence Research, 32(1):565–606, 2008.

[43] Lin Xu, Frank Hutter, Holger H Hoos, and Kevin Leyton-Brown. Hydra-MIP: Automated
algorithm conﬁguration and selection for mixed integer programming. In RCRA workshop on
Experimental Evaluation of Algorithms for Solving Problems with Combinatorial Explosion at
the International Joint Conference on Artiﬁcial Intelligence (IJCAI), 2011.

[44] Yu Yang, Natashia Boland, Bistra Dilkina, and Martin Savelsbergh. Learning generalized
strong branching for set covering, set packing, and 0-1 knapsack problems. Technical report,
Technical Report, 2020., 2020.

[45] Yu Yang, Natashia Boland, and Martin Savelsbergh. Multivariable branching: A 0-1 knapsack

problem case study. INFORMS Journal on Computing, 2021.

A Analysis of A(cid:48)

Proof of Lemma 3.2. Let T denote the tree built by A(cid:48). For i ∈ [∆], let T [i] denote the restriction
of T to nodes of depth at most i. Let ascoreµ = µ · ascore1 + (1 − µ) · ascore2. We prove
the lemma by induction on i. In particular, we show that for each i ∈ [∆], there are ki(i−1)/2bi
subintervals partitioning [0, 1] such that T [i] is invariant over all µ within any given subinterval.

17

Since T [∆] = T , this implies the lemma statement. The base case of i = 1 is trivial since T [1]
consists of only the root.

Now, suppose the statement holds for some i ∈ {1, . . . , ∆ − 1}. That is, there are T ≤ ki(i−1)/2bi
disjoint intervals I1∪· · ·∪IT = [0, 1] such that T [i] is invariant over all µ within any given subinterval
(our inductive hypothesis). Fix one of these subintervals It. We subdivide It into subintervals such
that T [i + 1] is invariant within each one of these smaller subintervals. Let Q be any leaf of T [i],
and for µ ∈ It let Tµ denote the state of the tree using ascoreµ at the point that Q is selected.
Since i < ∆, Q is not fathomed at line 4, regardless of µ. Next, since actions is path-wise, the
actions available at Q depend only on the path TQ from the root of T to Q, which, by the inductive
hypothesis, is invariant over all µ ∈ It. That is, actions(Tµ, Q) = actions(TQ, Q) for all µ ∈ It.
Then, ascoreµ with parameter µ will select action A ∈ actions(TQ, Q) if and only if

A =

argmax
A0∈actions(TQ,Q)

=

argmax
A0∈actions(TQ,Q)

µ · ascore1(Tµ, Q, A0) + (1 − µ) · ascore2(Tµ, Q, A0)

µ · ascore1(TQ, Q, A0) + (1 − µ) · ascore2(TQ, Q, A0),

where the second equality follows from the fact that ascore1 and ascore2 are path-wise. Thus,
for a ﬁxed A0, ascoreµ is linear in µ, so for each A0 there is at most one subinterval of [0, 1]
such that for all µ in that subinterval, A0 maximizes ascoreµ. Thus, each leaf of T [i] contributes
at most b subintervals such that for µ within a given subinterval, the action selected at each leaf
of T [i] is invariant. T [i] consists of at most ki leaves, so this is a total of at most kib subin-
tervals. Now, since the action A selected at each leaf Q of T [i] is invariant, the set of children
children(Tµ, Q, A) = children(TQ, Q, A) of Q added to the tree is also invariant, using the fact
that children is path-wise. This shows that within every subinterval, T [i + 1] is invariant. The
total number of subintervals is, by the induction hypothesis, at most ki(i−1)/2bi · kib = k(i+1)i/2bi+1,
as desired.

B Multiple actions

Let actions1, . . . , actionsd be path-wise. The multi-action version of Algorithm 1 is given by
Algorithm 2. There are two scoring rules ascorei
2 for each action type i ∈ [d].
Algorithm 2 can then be parameterized by (µ, λ), where µ ∈ Rd is a vector of parameters controlling
each action: the ith action is selected to maximize µi · ascorei
2. As before,
we assume there are b, k ∈ N such that |actionsi(T , Q)| ≤ b for any i and any Q ∈ T , and
|children(T , Q, A1, . . . , Ad)| ≤ k for all Q, A1, . . . , Ad.

1 + (1 − µi) · ascorei

1 and ascorei

Let A(cid:48), as in the single-action setting, be Algorithm 2 with the evaluations of fathom on line 4

and line 8 suppressed. Then, we may prove a slight generalization of lemma 3.2.

Lemma B.1. Let ascorei
2 be two path-wise action-selection scores, for each i ∈
{1, . . . , d}. Fix the input root node Q. There are T ≤ kd∆(∆−1)/2bd∆ boxes of the form Rt = I1×· · ·×
1+(1−µi)·ascorei
Id partitioning [0, 1]d where for any box Rt, the action-selection scores µi·ascorei
2
results in the same tree built by A(cid:48) for all µ ∈ Rt, no matter what node selection policy is used.

1 and ascorei

Proof. Let T denote the tree built by A(cid:48). For i ∈ [∆], let T [i] denote the restriction of T to nodes
of depth at most i. Let ascorei
2. We prove the lemma by
induction on i. In particular, we show that for each i ∈ [∆], there are kdi(i−1)/2bdi boxes partitioning
[0, 1]d such that T [i] is invariant over all µ within any given box. Since T [∆] = T , this implies the

1 + (1 − µi) · ascorei

µi = µi · ascorei

18

Algorithm 2 Tree search with multiple actions
Input: Root node Q, depth limit ∆

1: Initialize T = Q.
2: while T contains an unfathomed leaf do
3:

Select a leaf Q of T that maximizes nscore(T , Q).
if depth(Q) = ∆ or fathom(T , Q, None, . . . , None) then

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

Fathom Q.

else

For i = 1, . . . , d, select Ai ∈ actionsi(T , Q) that maximizes ascorei(T , Q, Ai).
if fathom(T , Q, A1, . . . , Ad) then

Fathom Q.

else if children(T , Q, A1, . . . , Ad) = ∅ then

Fathom Q.

else

Add all nodes in children(T , Q, A1, . . . , Ad) to T as children of Q.

lemma statement. The base case of i = 1 is trivial since T [1] consists of only the root, regardless
of µ ∈ [0, 1]d.

Now, suppose the statement holds for some i ∈ {1, . . . , ∆ − 1}. That is, there are T ≤
kdi(i−1)/2bdi disjoint boxes R1 ∪ · · · ∪ IR = [0, 1]d such that T [i] is invariant over all µ within
any given boxes (our inductive hypothesis). Fix one of these boxes Rt. We subdivide Rt into
sub-boxes such that T [i + 1] is invariant within each one of these smaller boxes. Let Q be any
leaf of T [i], and for µ ∈ Rt let Tµ denote the state of the tree using ascorei
µi for each i at the
point that Q is selected. Since i < ∆, Q is not fathomed at line 4, regardless of µ. Next, since
actionsi is path-wise for each i, the actions available at Q depend only on the path TQ from
the root of T to Q, which, by the inductive hypothesis, is invariant over all µ ∈ Rt. That is,
for all i actionsi(Tµ, Q) = actionsi(TQ, Q) for all µ ∈ Rt. Then, ascorei
µi will select action
Ai ∈ actionsi(TQ, Q) if and only if

Ai =

argmax
A0∈actionsi(TQ,Q)

=

argmax
A0∈actionsi(TQ,Q)

µ · ascorei

1(Tµ, Q, A0) + (1 − µi) · ascorei

2(Tµ, Q, A0)

µi · ascorei

1(TQ, Q, A0) + (1 − µi) · ascorei

2(TQ, Q, A0),

1 and ascorei

where the second equality follows from the fact that ascorei
2 are path-wise. Thus,
for a ﬁxed A0, ascorei
µi is linear in µi, so for each A0 there is at most one subinterval of [0, 1]
such that for all µi in that subinterval, A0 maximizes ascorei
µi. Thus, each leaf of T [i] contributes
at most b subintervals such that for µi within a given subinterval, the action of type i selected
at each leaf of T [i] is invariant. T [i] consists of at most ki leaves, so this is a total of at most
kib subintervals. Writing Rt = I1 × · · · Id, we have established that for each i, there are kib
subintervals partitioning Ii into subintervals such that as µi varies over each subinterval, the action
of type i selected at every leaf of T [i] is invariant. These subintervals partition Rt into at most
(kib)d boxes. As before, since the actions selected at each leaf Q of T [i] are invariant, the set of
children children(Tµ, Q, A1, . . . , Ad) = children(TQ, Q, A1, . . . , Ad) of Q added to the tree is also
invariant, using the fact that children is path-wise. Therefore, within every sub-box of Rt, T [i+1]
is invariant. The total number of boxes over each possible Rt is, by the induction hypothesis, at
most kdi(i−1)/2bdi · kdibd = kd(i+1)i/2bd(i+1).

19

The proof of Lemma 3.1 is identical in the multi-action setting. The proof of Lemma 3.3 is
also identical: here, we ﬁx a box R in the partition established in Lemma B.1, and get an identical
partition of R×[0, 1] such that the behavior of Algorithm 2 is invariant as λ varies in each subinterval
of [0, 1]. The number of boxes in the ﬁnal partition of [0, 1]d+1 is kd∆(∆−1)/2bd∆ ·k5∆ ≤ kd∆(9+∆)bd∆.
Our main pseudo-dimension bound for the multi-action setting follows from the same argument
that exploits the framework of Balcan et al. [8].

Theorem B.2. Let cost(Q) be any tree-constant cost function, and let costµ,λ(Q) be the cost of
the tree built by Algorithm 1 on input root node Q using action-selection scores parameterized by
µ ∈ Rd, where d = O(1), and node-selection score parameterized by λ. Then, Pdim({costµ,λ}) =
O(d∆2 log k + d∆ log b).

When d = O(1) we get the same pseudo-dimension bound as in the single-action setting:

Pdim({costµ,λ}) = O(∆2 log k + ∆ log b), which is the statement of Theorem 3.5.

20

