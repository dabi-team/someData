1
2
0
2

y
a
M
8
2

]

G
L
.
s
c
[

1
v
6
4
1
4
1
.
5
0
1
2
:
v
i
X
r
a

Deep Fair Discriminative Clustering

Hongjing Zhang
Department of Computer Science
University of California - Davis
hjzzhang@ucdavis.edu

Ian Davidson
Department of Computer Science
University of California - Davis
davidson@cs.ucdavis.edu

Abstract

Deep clustering has the potential to learn a strong representation and hence better
clustering performance compared to traditional clustering methods such as k-means
and spectral clustering. However, this strong representation learning ability may
make the clustering unfair by discovering surrogates for protected information
which we empirically show in our experiments. In this work, we study a general
notion of group-level fairness for both binary and multi-state protected status vari-
ables (PSVs). We begin by formulating the group-level fairness problem as an
integer linear programming formulation whose totally unimodular constraint matrix
means it can be efﬁciently solved via linear programming. We then show how to
inject this solver into a discriminative deep clustering backbone and hence propose
a reﬁnement learning algorithm to combine the clustering goal with the fairness ob-
jective to learn fair clusters adaptively. Experimental results on real-world datasets
demonstrate that our model consistently outperforms state-of-the-art fair clustering
algorithms. Our framework shows promising results for novel clustering tasks
including ﬂexible fairness constraints, multi-state PSVs and predictive clustering.

1

Introduction

Clustering is essential as it is the basis of many AI tools and has been widely used in real-world
applications [14] such as market research, social network analysis, and crime analysis. However,
as AI tools augment and even replace humans in decision making, particularly on other humans,
the need to ensure clustering is fair becomes paramount. Here fairness is measured using protected
status variables (PSVs) such as gender, race, or education level. Fairness takes two primary forms: i)
group-level fairness and ii) individual-level fairness. In this paper, we study the former which ensures
that no one cluster contains a disproportionately small number of individuals with protected status.
Motivated by this goal, our work aims to add fairness rules to deep clustering to generate fair clusters.

Recent work [8, 21, 22, 16, 2, 3] has been proposed on fair clustering algorithms. To ensure group-
level fairness, many of these works use the notion of the disparate impact doctrine [8], that instances
from different protected groups must have approximately (within a tolerance) equal representation in
a cluster compared to the population. Different geographic regions place this tolerance at different
levels. These existing fair clustering algorithms optimize the clustering quality by minimizing some
well-known clustering objectives while satisfying the group-level fairness constraints. Previous
examples of adding fairness to clustering algorithms include k-median based approaches [8, 2, 3]
and spectral clustering based algorithm [16]. However, most of these algorithms evaluate their
performance on low-dimensional tabular data and mainly study the problems with binary PSV.

Deep clustering [31, 13, 10, 30] has the ability to simultaneously cluster and learn a representation for
problems with large amounts of complex data (i.e., images, texts, graphs). However, the representation
learning ability sometimes makes the learner suffer from bias hidden in the data which can lead to
unfair clustering results. For example, clustering of portraits may create clusters based on features
which are surrogates for racial and other protected status information. One way to overcome this is

Preprint.

 
 
 
 
 
 
by adding group-level fairness to deep clustering which is a challenging and understudied problem. A
signiﬁcant challenge is it is hard to translate the current fair clustering algorithms into an end-to-end
deep clustering setting. For example, geometric pre-processing steps such as computing fairlets [8]
to ensure fairness will not work as the end-to-end learning of deep learners means the underlying
features that clustering is performed on are unknown apriori. Similarly, another line of work that
adds constraints into deep learning models such as [32] and [36] are not appropriate either as these
constraints are at the instance level, whereas we require to apply fairness rules at a cluster level.

The work on fair deep clustering is relatively new. The ﬁrst work on fair deep clustering [29] studies
deep fair clustering problem from a geometric perspective which aims to learn a fair representation
with multi-state PSV. The most recent work (and only other work) [18] proposes a deep fair visual
clustering model with adversarial learning to encourage the clustering partition to be statistically
independent of each sensitive attribute. Although these deep clustering approaches demonstrate better
clustering performance compared to the traditional fair clustering algorithms (Table 1), their fairness
results are relatively poor compared to those fair clusterings with fairness guarantees [8, 2]. Our
work can be seen to combine the beneﬁts of deep representation learning and discrete optimization
by producing an intermediate clustering assignments that are guaranteed to be fair.

In this paper, we propose a novel deep fair clustering framework to address the above issues. We
adopt a probabilistic discriminative clustering network and learn a representation that naturally yields
compact clusters. To incorporate the group-level fairness rules in the deep learner, we ﬁrst formulate
our fairness objective as an integer linear programming (ILP) problem that guarantees group-level
fairness. This ILP is efﬁcient to solve as its constraint matrix is totally unimodular. Further, we
propose a reﬁnement learning algorithm to combine the solved fair assignments, clustering objective
and self-supervised contrastive learning. Finally, we connect all these components and train the
network in an end-to-end fashion. Experimental results on real-world datasets demonstrate that our
model achieves near-optimal fairness with competitive clustering results. We also examine the novel
uses of our framework in predictive clustering, ﬂexible fair clustering, and challenging tasks with
multi-state PSVs. The major contributions of this paper are summarized as follows:

• Our work optimizes a general notion of fairness for multi-state PSVs which we prove
(Theorem 3.2) is equivalent to optimizing the balance measure for disparate impact [8].
• We formulate our fairness objective as an ILP and show the constraint matrix is totally
unimodular, (Theorem 4.2) so it can be efﬁciently solved by an LP solver (but still generate
integer solutions). This allows scaling of our work.

• We propose an end-to-end reﬁnement learning algorithm that combines deep learning and

discrete optimization that can generate meaningful and fair clusters.

• Extensive experimental results show that our work can achieve near-optimal fairness with
competitive clustering performance. We demonstrate our novel extensions for fair clustering
tasks in predictive clustering, multi-state PSVs and ﬂexible fairness rules.

In the next section we discuss the related work. Then we outline our measure of fairness and how
it relates to classic measures of disparate impact. Next we introduce our clustering framework and
encode our fairness objective as an ILP which can be efﬁciently solved by LP solver. A reﬁnement
learning algorithm and contrastive learning are adopted for end-to-end fair clustering. Finally we
validate the effectiveness of our approach on image and tabular data.

2 Related Work

Fair clustering has received much attention recently [22, 15, 1, 7, 9, 19, 4]. Chierichetti et al [8] ﬁrst
addressed the disparate impact for clustering problems in the presence of binary PSVs. Their work
apriori groups instances into many fairlets which are used as input into standard k-medians style
algorithms. Their work is guaranteed to produce a speciﬁed level of fairness and achieve a constant
factor approximation with respect to cluster quality. Other work [2] improves the fair decomposition
algorithm to linear run-time. Rösner and Schmidt [21] generalizes the fairness notion to allow for
more than two protected groups. Later on, Bera et al. [3] propose a general fair clustering algorithm
that allows human-speciﬁed upper and lower bounds on any protected group in any cluster. Their
work can be applied to any clustering problems under (cid:96)p norms such as k-median, k-means, and
k-center. Kleindessner et al. [16] extends the fairness notion to graph spectral clustering problems.

2

Previous fair clustering approaches mainly focus on adding fairness constraints into traditional
clustering algorithms. In our work, we aim to study the fairness problem for recently proposed deep
clustering algorithms [31, 34, 13, 5, 25, 26, 24]. Deep clustering algorithms connect representation
learning and clustering together and have demonstrated their advantages over the two-phase clustering
algorithms which use feature transformation ﬁrst and then clustering. However, limited work has
been done to study the fairness of those algorithms. One of the earliest works [29] to address the deep
fair clustering problem learns a latent representation such that the cluster centroids are equidistant
from every “fairoid” (the centroid of all the data belonging to the same protected group). Recently,
[18] encodes the fairness constraints as an adversarial loss and concatenates the fairness loss to
a centroid-based deep clustering objective as a uniﬁed model. Their goal of adding fairness via
adversarial loss is to make the clustering assignments to be statistically independent of the PSVs.

Different from previous deep fair clustering work, we translate the fairness requirements into an ILP
problem and our formulation allows for a general notion of fairness that supports ﬂexible fairness
constraints and multi-state PSVs. Moreover, we propose a novel learning framework to train fair
clustering models via simultaneous clustering and ﬁtting the self-generated fairness signals. Empirical
studies show that our model can achieve near-optimal fairness and competitive clustering results.

3 Deﬁnitions of Group-level Fairness

We begin this section by overviewing the seminal deﬁnition of group-level fairness in clustering (see
equation 1) and then its extension to multi-state PSVs (see equation 2). We then go onto show a new
measure that our deep clustering framework will optimize (see equation 3) and equation 2 have the
same optimal condition as shown in Theorem 3.2.

3.1 Notion of Fairness

Let X ∈ RN ×D denote N data points with D dimension features. The prediction function φ assigns
each instance to one unique cluster, φ : x → {1, ...K}, which forms K disjoint clusters {C1, ...CK}.
Given the protected status variable (denoted as PSV) A with T states, X can be partitioned into T
demographic groups as {G1, G2, ...GT }.
Deﬁnition 1. The seminal proposed measure of fairness for clustering with binary PSV [8] encoded
disparate impact as follows:

k and N 2

balance(Ck) = min(

N 2
k
N 1
k
Here N 1
k represent the populations of the ﬁrst and second demographic groups in clus-
ter Ck. Such a measure of fairness only works for binary PSV. To allow for multi-state PSVs,
let N min
k ) denotes the smallest (in size) protected group in cluster k and
k
N max
k ) denotes the largest group. We extend the balance measure for multi-
k
state PSV as:

= min(N 1

= max(N 1

k . . . N T

k . . . N T

) ∈ [0, 1]

N 1
k
N 2
k

(1)

,

balance(Ck) =

∈ [0, 1]

(2)

N min
k
N max
k

Recent works [21, 3] also propose a new fairness measure to allow for fair clustering problems with
multi-state PSVs.
Deﬁnition 2. Let ρi be the representation of group Gi in the dataset as ρi = |Gi|/N , and ρi(k) be
the representation of group Gi in the cluster Ck: ρi(k) = |Ck ∩ Gi|/|Ck|. Using these two values,
the fairness value for cluster Ck is:

f airness(Ck) = min(

ρi
ρi(k)

,

ρi(k)
ρi

) ∈ [0, 1] ∀i ∈ {1, . . . T }

(3)

The overall fairness of a clustering is deﬁned as the minimum fairness value over all the clusters.
Similarly the overall balance is the minimum balance value of all the clusters.

3.2 Equivalence of Optimizing Fairness and Balance Measures

Here we show that optimizing equation 3 is equivalent to optimizing our extended deﬁnition of balance
in equation 2. We see that equation 3 achieves maximal fairness when P (x ∈ Gt|x ∈ Ck) = ρt.

3

Our balance measure in equation 2 achieves optimal balance when P (x ∈ Gt|x ∈ Ck) = 1
T for
any protected group Gt in cluster Ck. However, this is an ideal case as protected groups may be
imbalanced. Denote the size of each protected group as |Gi| and the size of the data set as N , we
now show that the optimal balance is achieved if and only if P (x ∈ Gt|x ∈ Ck) = ρt. This result
indicates the equivalence of optimizing fairness (equation 3) and generalized balance (equation 2).

Lemma 3.1. The optimal balance can be achieved only when all the clusters have the same balance.
Formally, ∀i, j ∈ {1, 2, ..., K}: balance(Ci) = balance(Cj).

Theorem 3.2. To achieve optimal balance value for multi-state protected variables, we must satisfy
the condition: P (x ∈ Gt|x ∈ Ck) = ρt which is precisely the optimal fairness value for equation 2.

4 Deep Fair Clustering Algorithm

We introduce our deep fair clustering framework in this section. We can view our algorithm as
learning a good fair clustering under three objectives: a clustering loss function, self-generated
fairness signals and a contrastive learning objective.

4.1 Deep Clustering Model

We learn a neural network fθ as a discriminative function to predict the clustering assignments
Y = σ(fθ(X)) ∈ RN ×K based on input X ∈ RN ×D and softmax function σ. Based on previous
work [17, 13] we represent the mutual information I(X; Y ) between X and clustering labels Y as
the difference between marginal entropy H(Y ) and conditional entropy H(Y |X):

I(X; Y ) = H(Y ) − H(Y |X) = h(

1
N

N
(cid:88)

i=1

σ(fθ(xi))) −

1
N

N
(cid:88)

i=1

h(σ(fθ(xi)))

(4)

where h is the entropy function. We add a regularization term to our network and the clustering
objective is (cid:96)C:

N
(cid:88)

N
(cid:88)

L
(cid:88)

i=1

1
N

(cid:96)C =

h(σ(fθ(xi))) − h(

1
N
where α denotes the hyper-parameter for network parameters {θ1 . . . θL}. Maximizing H(Y ) will
punish imbalanced cluster size and prevent trivial solutions where all the instances are clustered into
one cluster whilst minimizing H(Y |X) will map similar instances x to have similar labels y. Note
we favor this probabilistic discriminative clustering model since it has fewer assumptions about the
natures of categories are made [17] and ﬁts our fairness objective which requires fractional clustering
assignments as inputs to indicate the degree of cluster assignment belief.

σ(fθ(xi))) + α

(cid:107)θl(cid:107)

(5)

i=1

l=1

2

4.2 Generating Fair Assignments Under Group-level Fairness Constraints

Let the fractional clustering assignments from the current learned model be Y = {y1, . . . yN } ∈
RN ×K. To use these to form fair clustering assignments, we solve a fairer assignment matrix
ˆY = {ˆy1, . . . ˆyN } ∈ ZN ×K that satisfy our optimal fairness condition: P (x ∈ Gt|x ∈ Ck) = ρt. To
address the fair assignment problem we formulate our fairer assignment problem as an integer linear
programming problem where we aim to minimize the changes to the current assignment Y to obtain
a fairer assignment ˆY as follows:

Objective: arg min

[1 − yi ∗ ˆyi

T ]

(6)

N
(cid:88)

ˆY

i=1

Recall that yi is a probability distribution over the cluster assignments for instance i and ˆyi chooses
exactly one cluster to assign instance i to. Naturally the objective is maximized when yi is assigned
to its most probable cluster but this may cause an unfair clustering.

We denote ρi = |Gi|/N as the fraction of the protected group Gi in the data set and our aim is for
each cluster to have the same density. Let M ∈ ZN ×T encode the sensitive attributes for the entire
population such that Mit ∈ {0, 1} indicates whether an instance xi belongs to a protected group Gt.

4

To satisfy optimal fair condition P (x ∈ Gt|x ∈ Ck) = ρt we have the following constraints:

N
(cid:88)

i=1

Mit ˆyij =

N
(cid:88)

i=1

ˆyijρt ∀j ∈ {1 . . . K}, t ∈ {1 . . . T }

(7)

Now we relax the problem by ﬁxing the size of each new cluster to make the constraint matrix totally
unimodular. Let the rounded version of current assignment Y as Y
then the size of cluster Cj is
|Cj| = (cid:80)N

ij. The constraints for new clusters’ size are:

i=1 y

(cid:48)

(cid:48)

N
(cid:88)

i=1

ˆyij = |Cj| ∀j ∈ {1 . . . K}

Lastly we add constraints for ˆY to ensure each instance is assigned to one cluster:

(cid:88)

j

ˆyij = 1 ∀i ∈ {1 . . . N }

(8)

(9)

Note this ILP formulation also supports user-deﬁned ρt which can be seen as a ﬂexible fairness
rule. Next we show the constraint matrix of our ILP problem is totally unimodular so that we can
efﬁciently solve it with a LP solver and still return integral solutions.

Proof of Total Unimodularity of Constraint Matrix: We know that if a constraint matrix of an
ILP is totally unimodular (TU) then we can solve the problem using an LP (linear program) solver
and the solution will still be integral [23]. Using an LP solver will largely reduce the running time
and [27] has shown that the running time for LP is polynomial in the input size.

In the above proposed constraints, there are N K unique regular variables (N instances and K
categories). To construct the constraint matrix C which encodes constraint 7, 8 and 9, we will
use 2N K regular variables. Matrix C has T + 1 rows (the ﬁrst T rows correspond to the fairness
constraints in equation 7 and last row corresponds to constraints in equation 9) and N + K columns.
Note the ﬁrst K columns of the last row are set to 0 and the last N columns of ﬁrst T rows are set to
0. In matrix C, each entry of C is from {−1, 0, 1}. Moreover, each column only has one non-zero
element. This is because: (1) for constraints set in equation 7, each instance only belongs to one
protected group, (2) for constraints set in equation 9, there is only one row vector with K elements as
1 to ensure the valid assignment.
Lemma 4.1. TU Identity [23]. Let C be a matrix such that all its entries are from {0, 1, −1}. Then
C is totally unimodular, i.e., each square submatrix of C has determinant 0, 1, or −1 if every subset
of rows of C can be split into two parts A and B so that the sum of the rows in A minus the sum of
the rows in B produces a vector all of whose entries are from {0, 1, −1}.
Theorem 4.2. The matrix C formed by the coefﬁcients of the constraints used to encode our proposed
constraints from equation 7, 8 and equation 9 is totally unimodular.

4.3 Learning to Be Fairer with Contrastive Learning

To learn a fair clustering model we aim to exploit the fairness assignments ˆY to reshape the features
learned via clustering networks fθ. We treat ˆY as “pseudo-labels” to optimize the following cross
entropy loss (cid:96)F air for fairer results:
N
(cid:88)

K
(cid:88)

N
(cid:88)

ˆyijlogyij =

ˆyilog(σ(fθ(xi)))

(10)

(cid:96)F air =

1
N

i=1

j=1

1
N

i=1

Simply optimizing the fairness loss (cid:96)F air will dramatically change the current clustering represen-
tations to ﬁt an approximated fair assignment ˆY which harms the clustering properties. Instead,
we propose to learn a fairer and clustering-friendly representation simultaneously by combining
the clustering loss (cid:96)C with fairness loss (cid:96)F air. Note the fair assignments ˆY are updated after each
training epoch as the “nearest" fair assignments for current clustering predictions.

Inspired by the recent use of contrastive learning [12, 6] which leads to state-of-the-art performance
in the unsupervised training. Here we consider a general augmentation strategy beyond classic
augmentation techniques within vision domain: we propose to add a small local perturbation of
= x + t and hope to maximize the perturbation t subject to the constraint
instance x such that x

(cid:48)

5

Algorithm 1 Main learning algorithm for deep fair discriminative clustering.

k=1, sensitive attributes M , cluster size K, network structure f , hyper-parameters α, β, γ.

(cid:80)n

i=1 σ(fθ(xi))) + α (cid:80)L

l=1 (cid:107)θl(cid:107)

2

n

(cid:80)n

k=1 .

end for

k=1 do

i=1 h(σ(fθ(xi)))− h( 1

for sampled mini-batch {xk}n

Calculate (cid:96)C = 1
n
(cid:48)
k = xk + t via solving t from eq 11.
Generate x
Calculate (cid:96)Aug = (cid:80)n
i=1 KL(σ(fθ(xi)), σ(fθ(x
Update network fθ via minimizing (cid:96)C + γ(cid:96)Aug.

Input: Input {xk}N
Output: Clustering network fθ, predictions {yk}N
1: for each pre-trained epoch do
2:
3:
4:
5:
6:
7:
8: end for
9: repeat
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21: until {yk}N

Calculate (cid:96)F air = 1
n
(cid:80)n
Calculate (cid:96)C = 1
n
Generate x
Calculate (cid:96)Aug = (cid:80)n
Calculate (cid:96) = (cid:96)C + β(cid:96)F air + γ(cid:96)Aug
Update network fθ via minimizing (cid:96).

k = xk + t via solving t from eq 11.
i=1 KL(σ(fθ(xi)), σ(fθ(x

i=1 ˆyilog(σ(fθ(xi)))
i=1 h(σ(fθ(xi)))− h( 1

k=1 via LP solver.
k=1 do

k=1 satisfy optimal fairness rules

k=1 based on fθ.

end for

(cid:80)n

n

(cid:48)

(cid:48)

i)))

(cid:48)

i)))

Generate predictions {yk}N
Construct a fair assignment problem via objective 6 and constraints deﬁned in eq 7, 8 and 9.
Solve fair assignments {ˆyk}N
for sampled mini-batch {xk}n

(cid:80)n

i=1 σ(fθ(xi))) + α (cid:80)L

l=1 (cid:107)θl(cid:107)

2

that the clustering assignments for x and x
are the same. To achieve this goal we apply the virtual
adversarial training [20] work to generate adversarial direction for perturbation t. Denote the current
model’s parameters θ to help estimate the true clustering indicator vector for instance x as σ(fθ(x)),
the formulation to compute the adversarial perturbation tadv is as follows:
KL(σ(fθ(x)), σ(fθ(x + t)))

(11)

(cid:48)

tadv = arg max
t;||t||2≤(cid:15)

Note that (cid:15) is a scalar-valued hyper-parameter with constraint that (cid:15) > 0. [20] has shown that solving
tadv can be approximated efﬁciently via few gradient steps. With the generated tadv we propose
the augmentation loss (cid:96)Aug which minimizes the Kullback–Leibler divergence between clustering
assignment σ(fθ(xi)) and its augmented version’s assignment σ(fθ(xi

)):

(cid:48)

(cid:96)Aug =

N
(cid:88)

i=1

KL(σ(fθ(xi)), σ(fθ(xi

(cid:48)

)))

(12)

To train our proposed framework, we start with the training on clustering network f (θ) via optimizing
the clustering loss (cid:96)C and augmentation loss (cid:96)Aug to ensure the data are separated into different
meaningful clusters; as clustering model converges we generate fair assignments after each training
epoch based on the objective in eq 6 and optimize the overall loss function (cid:96) by concatenating the
fairness loss (cid:96)F air to augmentation and clustering objectives as (cid:96) = (cid:96)C + β(cid:96)F air + γ(cid:96)Aug where
β, γ are positive weight hyper-parameters. Algorithm 1 summarizes the proposed method.

5 Experiments

In this section, we conduct experiments1 to evaluate our approach empirically. Based on our
experiments, we report the following key results:

• In typical fair clustering settings our approach achieves better clustering performance and

near-optimal fairness results compared against existing baselines.

• Our approach is effective in novel fair clustering settings such as ﬂexible fairness constraints,

clustering with multi-state PSVs, and predictive clustering.

1In our experimental work we use the fair clustering data sets used by earlier work for comparison.

6

• We show our learned embedding converges to a space useful for fairness clustering quickly
and also provides insights on tuning hyper-parameter β to achieve our fairness goal with a
minimum loss on clustering performance.

5.1 Experimental Setup

Deep Clustering Data Sets. We ﬁrst evaluate our work on two visual data sets with binary PSV
that has been used in recent work [18]: 1) MNIST-USPS consists of 67291 training images of
hand-written digits. We use the image source (MNIST or USPS) as a binary PSV and cluster the
data into 10 classes representing 10 digits. 2) Reverse-MNIST takes the 60000 training images from
MNIST and creates an inverted duplicate to build this dataset. The binary PSV is then original or
inverted and the total number of classes is 10. Moreover, we evaluate one challenging fair clustering
task with multi-state PSV on the HAR dataset used in [29]: 3) HAR contains 10299 instances in total
with captured action features for 30 participants. There are 6 actions in total which serve as labels for
clustering. The identity of each person is used as the PSV value.

Classic Data Sets. Following traditional fair clustering work [3] we choose three tabular datasets
for complete comparison: 1) Census data with 5 attributes (“age”, “fnlwgt”, ‘education-num”,
“capitalgain”, “hours-per-week”) and binary PSV gender, we set whether income exceeds 50K as the
clustering label; 2) Bank data with 3 attributes (“age”, “balance”, “duration-of-account”) and binary
PSV marital, we set whether a client will subscribe a term deposit as the label; 3) Credit data with 14
features and binary PSV marital, we set whether the cardholder will make a payment as the label.

Measurements. To measure the clustering quality for deep fair clustering and other baselines, we
use both clustering accuracy (Acc) [33, 35] and normalized mutual information (NMI) metrics for a
comprehensive study. To evaluate the fairness, we use the balance measure deﬁned in equation 2. For
all those three measures, higher values indicate better performance.

Algorithms. For the deep clustering baselines, we use DEC [31] as a representative method for
centroid-based clustering and IMSAT [13] for discriminative clustering approach. For fair clustering
algorithms, we choose the scalable fair clustering algorithm [2] and the fair algorithms for clustering
[3]. For deep fair clustering baselines, we compare our work with the latest work [18] and the
geometric-based fair clustering [29]. For our own approach, we set parameters α = 10−4, γ = 1 and
β = 4. For the structure of fθ, we use two convolutional layers followed by batch normalization
and pooling for visual data and fully connected layers for non-visual data. For a fair comparison
with non-deep clustering baselines, we use pre-trained auto-encoder’s features like [18]. For the ILP
objective we use the Gurobi [11] optimizer. More details are included in the supplementary material.

5.2 Evaluation

Table 1: Comparison of clustering and fairness performance on MNIST-USPS, Reverse-MNIST and
HAR. HAR consists of multi-state PSV that baselines with dashes are not applicable. Bold results are
the best results among all the baselines except the ground-truth and the guaranteed fairness results
which are marked with blue. Note we report our average performance results after 10 trials and the
term optimal refers to the clustering giving the optimal accuracy and the corresponding balance.

Category

Non-Fair Deep
Clustering
Fair Non-Deep
Clustering

Fair Deep
Clustering

Methods
Ground Truth (Optimal)
DEC [31]
IMSAT [13]
ScFC [2]
FAlg [3]
[29]
DFCV [18]
Initial ILP Results (Ours)
Ours Result

MNIST-USPS
NMI
1.000
0.686
0.787
0.053
0.496
0.716
0.789
0.746
0.876

Balance
0.120
0.000
0.000
0.120
0.093
0.039
0.067
0.120
0.119

Acc
1.000
0.586
0.804
0.176
0.621
0.725
0.825
0.779
0.936

Reverse-MNIST
NMI
1.000
0.480
0.630
0.105
0.206
0.506
0.679
0.577
0.690

Balance
1.000
0.000
0.000
1.000
0.667
0.430
0.763
1.000
0.946

Acc
1.000
0.401
0.525
0.268
0.295
0.425
0.577
0.485
0.589

Acc
1.000
0.571
0.812
–
0.642
0.607
–
0.789
0.862

HAR
NMI
1.000
0.662
0.803
–
0.618
0.661
–
0.702
0.845

Balance
0.458
0.000
0.000
–
0.420
0.166
–
0.653
0.468

High Dimensional Data. As shown in the Table 1, traditional fair clustering algorithms achieve
good fairness results especially ScFC which returns guaranteed fair clusters. However the clustering

7

Table 2: Measuring our work’s ability to obtain optimum fairness on Bank, Census and Credit data
sets. Ours w/o fairness denotes the results from our proposed model without the fairness objective.

k-Means

Acc
0.647
0.656
0.694

Balance
0.406
0.144
0.835

Census
Bank
Credit

Ours w/o fairness Ours with fairness Optimal
Balance
Acc
0.492
0.649
0.189
0.664
0.856
0.697

Balance
0.489
0.186
0.855

Balance
0.401
0.144
0.828

Acc
0.620
0.645
0.690

Table 3: Our clustering results on the test sets of high-dimensional data without the sensitive attributes
information. The optimal balance denotes the test set’s optimal results.

Acc

NMI

train
MNIST-USPS
0.936
Reverse-MNIST 0.589
0.862

HAR

test
0.930
0.562
0.831

train
0.876
0.690
0.845

test
0.865
0.645
0.795

train
0.119
0.946
0.468

Balance
test
0.164
0.890
0.167

optimal
0.200
1.000
1.000

performance is not good as deep clustering methods due to the lack of representation learning Both
DEC and IMSAT achieve reasonable clustering results but poor fairness results, this shows the
unfairness of existing deep clustering methods which motivates our adding fairness rules. Comparing
our results with the recent deep fair clustering works [29, 18] we can see that our approach consistently
outperforms these two baselines in terms of both clustering performance and fairness. Observing
the ground truth results in Table 1 we can see the fairness rules can be seen as positive guidance to
improve the clustering performance, our approach is shown to be able to learn from this guidance and
improve fairness as well as accuracy. Comparing our ﬁnal results with initial fair ILP assignments,
we demonstrate the success of iteratively learning fairer and clustering-favored features.

Classic Tabular Datasets. We evaluate our approach on tabular data sets used by classic fair
clustering algorithms and present the results in Table 2. We ﬁnd that our model achieves similar
results as k-Means on tabular data with human-deﬁned semantic features. Meanwhile, both k-Means
and our deep clustering model achieve good balance results when the number of clusters is correctly
set as the ground truth number of classes. Even when the initial balance is high, our model can still
largely improve it and achieve near-optimal balance with a slight loss in terms of clustering accuracy.

Predictive Clustering Results. Here we evaluate our method’s ability to make predictions on test
data without PSV information which is a new setting in the fair clustering literature. That is we have
already clustered a data set with PSV values and are now making predictions using the model learnt.
This is particularly important for practitioners who are, for instance, deploying models on the web
(where individuals are reluctant to share PSV information) and we see our results in Table 3. Our
approach performs well in both train and test sets. One exception is that the test balance in HAR is
much lower than the training balance, we hypothesize this is due to different distributions between
training and test set, the optimal test balance is 1 while the optimal training balance is 0.653.

5.3 Further Analysis on Our Model

Here we explore our model’s ﬂexibility in satisfying fairness requirements and better understand its
performance by feature space visualization and empirical convergence.

Table 4: Results on ﬂexible fair constraints for MNIST-USPS data.
Acc
0.903
0.892
0.869
0.847

NMI Balance
0.847
0.835
0.818
0.798

Relax Degree
(cid:15) = 0.01
(cid:15) = 0.02
(cid:15) = 0.03
(cid:15) = 0.04

0.103
0.095
0.081
0.069

Results on Flexible Fairness Constraints. Here we explore how relaxing the optimal fair condition
deﬁned as ρt in equation 7 produces ﬂexible constraints. We now require the fairness requirement
to be in the interval [ρt − (cid:15), ρt + (cid:15)]. In Table 4, we can see a larger relaxation (cid:15) leads to a lower
balance which is expected; since the fairness signals can serve as positive guidance for clustering in
MNIST-USPS, we observe the Acc and NMI are decreasing with larger relaxation. Allowing ﬂexible
constraints are important from a practitioner’s perspective as the fairness rules vary across regions.

8

(a) epoch 0

(b) epoch 15

(c) epoch 30

(d) epoch 45

(e) epoch 60

Figure 1: t-SNE visualization of learned embedding, color red and blue indicate different PSV values.

(a) MNIST-USPS (Balance)

(b) MNIST-USPS (Acc)

(c) HAR (Balance)

(d) HAR (Acc)

Figure 2: Sensitivity analysis of fairness hyper-parameter β.

Feature Space Visualizing. To understand how our model learns a fair representation, we have
applied t-SNE [28] to visualize the feature space of MNIST-USPS during different training epochs in
Figure 1. The initial model is trained with deep clustering objectives which yield unfair results, once
we introduce fairness objectives the red instances start to move to different clusters. Meanwhile we
can ﬁnd our learned representations still maintain good clustering performance.

Tuning the Weight of Fairness Objective. We experiment on the choices of hyper-parameter β
which controls the weight of the fairness objective and report the clustering results in Figure 2. It is
straightforward to see from (a) and (c) that as β increases, the training balance increases. Meanwhile,
based on (b) and (d) we can ﬁnd the Acc goes up and down as β increases. Our previous result shows
that the fairness constraints can serve as positive guidance for both MNIST-USPS and HAR. That is
why the clustering accuracy goes up when we increase β from 0. But we also observe that with a
very large β the clustering accuracy will drop. We hypothesize this is because the fairness objective
dominates the overall objective so that the impact of clustering objective is hindered. As balance can
be tracked during the training process for free, our insight for selecting hyper-parameter β is to pick
the smallest β that achieves satisfying balance results.

Empirical Convergence Analysis. To investi-
gate the smoothness of learning with clustering
and fairness objectives together, we present the
learning curves of overall training loss and the
balance results in Figure 3 and 4. We can see
from the plots that the train loss drops quickly
and converges after 50 epochs. Our model’s bal-
ance result also converges after 50 epochs.

6 Conclusion

Figure 3: Train Loss

Figure 4: Train Balance

In this paper, we explore the novel direction of adding fairness into deep clustering. This is a challeng-
ing problem given the end-to-end deep learning setting which does not facilitate pre-processing into
fairlets and the need for scalability to large data sets. We formulate a group level measure of fairness
as an integer linear programming problem and show the problem can be solved efﬁciently due to total
unimodularity (Theorem 3.2). We then add this solver into a discriminative deep learner and show
that our formulation works with multi-state sensitive attributes as well as ﬂexible fairness constraints
that can occur in real-life applications. Extensive experiments demonstrate the strong performance of
our approach and an in-depth analysis including feature space visualization, hyper-parameter tuning,
model convergence analysis, and investigating ﬂexible fair constraints shows its versatility.

9

0246810β0.000.020.040.060.080.100.12Balance0246810β0.780.800.820.840.860.880.900.920.94Clustering Acc0246810β0.00.10.20.30.40.5Balance0246810β0.800.810.820.830.840.850.860.87Clustering Acc01020304050Training Epochs4.004.254.504.755.005.255.505.756.00Overall LossHARMNIST-USPS01020304050Training Epochs0.00.10.20.30.4BalanceHARMNIST-USPSReferences

[1] S. Ahmadian, A. Epasto, R. Kumar, and M. Mahdian. Clustering without over-representation.
In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery
& Data Mining, pages 267–275, 2019.

[2] A. Backurs, P. Indyk, K. Onak, B. Schieber, A. Vakilian, and T. Wagner. Scalable fair clustering.

In International Conference on Machine Learning, pages 405–413, 2019.

[3] S. Bera, D. Chakrabarty, N. Flores, and M. Negahbani. Fair algorithms for clustering. In

Advances in Neural Information Processing Systems, pages 4955–4966, 2019.

[4] B. Brubach, D. Chakrabarti, J. Dickerson, S. Khuller, A. Srinivasan, and L. Tsepenekas. A
In International

pairwise fair and community-preserving approach to k-center clustering.
Conference on Machine Learning, pages 1178–1189. PMLR, 2020.

[5] M. Caron, P. Bojanowski, A. Joulin, and M. Douze. Deep clustering for unsupervised learning
of visual features. In Proceedings of the European Conference on Computer Vision (ECCV),
pages 132–149, 2018.

[6] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton. A simple framework for contrastive learning
of visual representations. In International conference on machine learning, pages 1597–1607.
PMLR, 2020.

[7] X. Chen, B. Fain, L. Lyu, and K. Munagala. Proportionally fair clustering. In International

Conference on Machine Learning, pages 1032–1041. PMLR, 2019.

[8] F. Chierichetti, R. Kumar, S. Lattanzi, and S. Vassilvitskii. Fair clustering through fairlets. In

Advances in Neural Information Processing Systems, pages 5029–5037, 2017.

[9] I. Davidson and S. Ravi. Making existing clusterings fairer: Algorithms, complexity results and

insights. In Thirty-Fourth AAAI Conference on Artiﬁcial Intelligence, 2020.

[10] X. Guo, L. Gao, X. Liu, and J. Yin. Improved deep embedded clustering with local structure
preservation. In Proceedings of the 26th International Joint Conference on Artiﬁcial Intelligence,
pages 1753–1759, 2017.

[11] L. Gurobi Optimization. Gurobi optimizer reference manual, 2021.

[12] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick. Momentum contrast for unsupervised visual
representation learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, pages 9729–9738, 2020.

[13] W. Hu, T. Miyato, S. Tokui, E. Matsumoto, and M. Sugiyama. Learning discrete representations
via information maximizing self-augmented training. In International Conference on Machine
Learning, pages 1558–1567, 2017.

[14] A. K. Jain, M. N. Murty, and P. J. Flynn. Data clustering: a review. ACM computing surveys

(CSUR), 31(3):264–323, 1999.

[15] M. Kleindessner, P. Awasthi, and J. Morgenstern. Fair k-center clustering for data summarization.

In International Conference on Machine Learning, pages 3448–3457, 2019.

[16] M. Kleindessner, S. Samadi, P. Awasthi, and J. Morgenstern. Guarantees for spectral clustering
with fairness constraints. In International Conference on Machine Learning, pages 3458–3467,
2019.

[17] A. Krause, P. Perona, and R. G. Gomes. Discriminative clustering by regularized information

maximization. In Advances in neural information processing systems, pages 775–783, 2010.

[18] P. Li, H. Zhao, and H. Liu. Deep fair clustering for visual learning. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9070–9079, 2020.

[19] S. Mahabadi and A. Vakilian. Individual fairness for k-clustering. In International Conference

on Machine Learning, pages 6586–6596. PMLR, 2020.

10

[20] T. Miyato, S.-i. Maeda, M. Koyama, and S. Ishii. Virtual adversarial training: a regularization
method for supervised and semi-supervised learning. IEEE transactions on pattern analysis
and machine intelligence, 41(8):1979–1993, 2018.

[21] C. Rösner and M. Schmidt. Privacy preserving clustering with constraints. In 45th International
Colloquium on Automata, Languages, and Programming (ICALP 2018). Schloss Dagstuhl-
Leibniz-Zentrum fuer Informatik, 2018.

[22] M. Schmidt, C. Schwiegelshohn, and C. Sohler. Fair coresets and streaming algorithms for fair
k-means. In International Workshop on Approximation and Online Algorithms, pages 232–251.
Springer, 2019.

[23] A. Schrijver. Theory of linear and integer programming. John Wiley & Sons, 1998.

[24] S. A. Shah and V. Koltun. Deep continuous clustering. arXiv preprint arXiv:1803.01449, 2018.

[25] U. Shaham, K. Stanton, H. Li, B. Nadler, R. Basri, and Y. Kluger. Spectralnet: Spectral
clustering using deep neural networks. International Conference on Learning Representations,
2018.

[26] E. Tzoreff, O. Kogan, and Y. Choukroun. Deep discriminative latent space for clustering. arXiv

preprint arXiv:1805.10795, 2018.

[27] P. M. Vaidya. Speeding-up linear programming using fast matrix multiplication. In 30th annual

symposium on foundations of computer science, pages 332–337. IEEE, 1989.

[28] L. Van der Maaten and G. Hinton. Visualizing data using t-sne. Journal of machine learning

research, 9(11), 2008.

[29] B. Wang and I. Davidson. Towards fair deep clustering with multi-state protected variables.

arXiv preprint arXiv:1901.10053, 2019.

[30] C. Wang, S. Pan, R. Hu, G. Long, J. Jiang, and C. Zhang. Attributed graph clustering: A
deep attentional embedding approach. In Proceedings of the Twenty-Eighth International Joint
Conference on Artiﬁcial Intelligence, IJCAI-19, pages 3670–3676, 2019.

[31] J. Xie, R. Girshick, and A. Farhadi. Unsupervised deep embedding for clustering analysis. In

International conference on machine learning, pages 478–487, 2016.

[32] J. Xu, Z. Zhang, T. Friedman, Y. Liang, and G. Broeck. A semantic loss function for deep
learning with symbolic knowledge. In International Conference on Machine Learning, pages
5502–5511, 2018.

[33] W. Xu, X. Liu, and Y. Gong. Document clustering based on non-negative matrix factorization.
In Proceedings of the 26th annual international ACM SIGIR conference on Research and
development in informaion retrieval, pages 267–273, 2003.

[34] B. Yang, X. Fu, N. D. Sidiropoulos, and M. Hong. Towards k-means-friendly spaces: Simulta-
neous deep learning and clustering. In Proceedings of the 34th International Conference on
Machine Learning-Volume 70, pages 3861–3870. JMLR. org, 2017.

[35] Y. Yang, D. Xu, F. Nie, S. Yan, and Y. Zhuang. Image clustering using local discriminant
models and global integration. IEEE Transactions on Image Processing, 19(10):2761–2773,
2010.

[36] H. Zhang, S. Basu, and I. Davidson. Deep constrained clustering-algorithms and advances.
In Joint European Conference on Machine Learning and Knowledge Discovery in Databases,
pages 57–72, 2019.

11

