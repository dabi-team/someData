Robust Graph Learning Under
Wasserstein Uncertainty

Xiang Zhang, Student Member, IEEE, Yinfei Xu, Member, IEEE, Qinghe Liu,
Zhicheng Liu, Student Member, IEEE, Jian Lu, Member, IEEE, and Qiao Wang, Senior Member, IEEE

1

1
2
0
2

y
a
M
3
1

]

G
L
.
s
c
[

2
v
0
1
2
4
0
.
5
0
1
2
:
v
i
X
r
a

Abstract

Graphs are playing a crucial role in different ﬁelds since they are powerful tools to unveil intrinsic relationships among
signals. In many scenarios, an accurate graph structure representing signals is not available at all and that motivates people to
learn a reliable graph structure directly from observed signals. However, in real life, it is inevitable that there exists uncertainty
in the observed signals due to noise measurements or limited observability, which causes a reduction in reliability of the learned
graph. To this end, we propose a graph learning framework using Wasserstein distributionally robust optimization (WDRO) which
handles uncertainty in data by deﬁning an uncertainty set on distributions of the observed data. Speciﬁcally, two models are
developed, one of which assumes all distributions in uncertainty set are Gaussian distributions and the other one has no prior
distributional assumption. Instead of using interior point method directly, we propose two algorithms to solve the corresponding
models and show that our algorithms are more time-saving. In addition, we also reformulate both two models into Semi-Deﬁnite
Programming (SDP), and illustrate that they are intractable in the scenario of large-scale graph. Experiments on both synthetic
and real world data are carried out to validate the proposed framework, which show that our scheme can learn a reliable graph
in the context of uncertainty.

Distributionally robust optimization (DRO), graph learning, graph signal processing, graph Laplacian, Wasserstein distance.

Index Terms

I. INTRODUCTION

Graphs are widely employed to characterize structured data in signal processing, machine learning and statistics since
intrinsic information of structured data residing on topologically complicated domain can be ﬂexibly represented by graph
[1]. Speciﬁcally, vertices in graph represent data entities and edges represent afﬁnity relations between these entities [2]. A
variety of ﬁelds witness the applications of graph-structured data, including urban science, social networks and meteorology,
etc. Among these applications, many models ﬁrst deﬁne graphs using prior knowledge which, however, is often unavailable.
Furthermore, prior graphs might not accurately capture the intrinsic relationships among vertices. Therefore, it is essential to
learn an underlying graph topology directly from data on hand and then the learned graph can be used in numerous pipeline
tasks.

Historically, graph learning has been a research ﬁeld of concern for a long time. Abundant of researches, such as [3]–[5], are
committed to learning a graph from statistical view. On the other hand, graph signal processing (GSP), an emerging research
ﬁeld [6], [7], is employed to handle graph learning problems from perspective of signal processing. The main characteristic
of GSP based models is learning a graph with some tools generalizing classical signal processing concepts, such as sampling
theorem, time-frequency analysis and ﬁltering on graphs [2]. One of the most notable GSP based model is built on stationarity
assumption [8]–[11]. These models hold the opinion that the observed signals are stationary over the graph to be learned and
the eigenvalues of graph operators, such as Laplacian matrices, can be estimated by using sample covariance matrices of the
observed data [2]. In parallel with stationarity based models, smoothness assumption also occupies an important position in
GSP based graph learning models. The smoothness of graph signals means that signal values of two connected vertices in
the corresponding graph with large weights tend to be similar [12]. Smoothness based models endeavor to learn a graph over
which observation graph signals are the smoothest [12]–[16]. Here we should mention that smoothness assumption is the one
we take in this paper.

While a wealth of researches are carried out on graph learning, limited to our understanding, few of them focuses on how
to learn a graph when there exists uncertainty in signals. Uncertainty arises from, for example, noise measurements or limited
observability of data and may cause the learned graph deviate from ground-truth, which brings troubles to pipeline tasks [17].
To better illustrate the impact of uncertainty, we might learn a graph under uncertainty using method in [12] and apply Louvain
algorithm [18] to detect clusters in the learned graph. To increase uncertainty, we only generate 50 signals for a 45 vertices
graph and add noise to the generated signals. As displayed in Fig.1, for the learned graph, 6 clusters are detected while the
groundtruth graph only contains 3 clusters. This vividly illustrates the impact of uncertainty on graph learning tasks and this
motivates us to surmount uncertainty in signals.

The authors are with the School of Information Science and Engineering, Southeast University, Nanjing 210096, China. (e-mail: {xiangzhang369, yinfeixu,

liuqinghe, zhichengliu, lujian1980, qiaowang}@seu.edu.cn). (Corresponding authors: Yinfei Xu; Qiao Wang.)

Part of this work will be submitted to NeurIPS 2021.

 
 
 
 
 
 
2

Fig. 1: Community detection results using the learned graph. (a) The ground truth graph. (b) The learned graph under uncertainty

(a)

(b)

From perspective of optimization, if we regard signals with uncertainty as unknown parameters, graph learning under
uncertainty amounts to an optimization problems with unknown parameters. Typically, robust optimization [19], [20] and
stochastic optimization [21], [22] are two common tools to cope with optimization problems with unknown parameters.
While robust optimization limits unknown parameters in an uncertainty set, stochastic optimization assumes that unknown
parameters subject to a certain distribution. Recently, distributionally robust optimization (DRO) has been a popular tool to
handle optimization problems with unknown parameters and can be viewed as a unifying framework for robust optimization and
stochastic optimization [17]. Instead of directly constructing uncertainty sets with respect to the value of unknown parameters,
DRO assumes that uncertainty is built on the distributions of unknown parameters [17], [23]. To be speciﬁc, in the context of
graph learning, we have no knowledge of the true distribution of graph signals because of noise corruption or limited number
of data. To this end, we construct an uncertainty set containing the true distribution with high possibility. With this uncertainty
set, we expect to ﬁnd the graph that minimize the risk of the worst case of all possible distribution in uncertainty set. Since
DRO takes the worst case into consideration, results of DRO are conservative and robust. It is worth noting that uncertainty
sets in DRO is crucial and deﬁned on distributions, hence some distance metrics between probabilities need to be employed
to construct uncertainty sets. In addition to Φ divergence [24], [25] and maximum mean discrepancy [26] based metrics,
Wasserstein distance is another emerging one to measure the discrepancy between probabilities [27]. Recall that Wasserstein
distance is originated from optimal transport theory [28] and takes into account the geometry of the space on which the
distributions are deﬁned [29]. In fact, Wasserstein distance based distributionally robust optimization, which is abbreviated as
WDRO [30]–[32], has gained success in numerous ﬁelds [33]–[35]. However, to the best of our knowledge, this paper is the
ﬁrst work that handles uncertainty from distributional perspective exploiting WDRO in graph learning.

Our contributions in this paper may be summarized as follows:
• We ﬁrst propose a graph learning framework under uncertainty using WDRO by deﬁning uncertainty set from distribu-
tionally perspective. Speciﬁcally, two models are developed, one of which assumes all distributions in uncertainty sets
are of Gaussian and the another one has no prior assumption about distributions in uncertainty set. For the second model,
we prove that robustness is obtained by a regularizer whose weight equals to the radius of uncertainty set, which can be
interpreted as the level of robustness. This provides interpretability for robustness under our framework.

• To exploit the algorithms for solving the above models, we reformulate the above models into Semi-Deﬁnite Programming
(SDP) problems. Then we demonstrate that it is actually impractical to solve such SDP problems in reality, which suggests
us to give up the SDP reformulations. To this end, we develop two novel algorithms respectively for Gaussian and general
scenario. Instead of using convex optimization package, such as CVX exploiting interior methods, we introduce a linear
operator to get rid of constraints of graph structure and use gradient descendent method to ﬁnd the optimal result. The
proposed algorithms are illustrated to be more time-saving.

• Experiments with synthetic data and real data are carried out to validate the proposed framework. These results conﬁrm

that the proposed framework is effective at learning a reliable graph in the context of uncertainty.

Organization: The rest of the paper is organized as follows. Section II states the problem which we focus on and gives the
basic formulation of our framework. Section III and section IV are the models and algorithms of our framework in Gaussian
and general scenario respectively. In section V, we reformulate these two models of section III and IV into SDP problems
and show the infeasibility of solving procedures. Synthetic and real data experiments are carried out to validate our models in

3

TABLE I: List of symbols and their meaning

Symbols

L, L, lij
W, D, I
x, x, X
d, N
Tr(·) , vec(·)
E(·) , Cov(·)
W (·), α
p, (cid:15)
γ, Θ
Sd
Sd
+
Rd
Rd
+
P, Q
P,Q
µ, Σ
µn, Σn
1, 0

Meaning

graph Laplacian matrix, set of graph Laplacian matrices, element of L
adjancy matrix, degree matrix, identity matrix
signal element, signal vector, signal matrix,
number of vertices, number of signals
trace operator, vectorization operator
expectation operator, covariance operator
Wasserstein distance, Wasserstein distance type
norm type, uncertainty set radius
dual variable, equivalent variable of xxT
d × d symmetric matrix
d × d positive semideﬁnite matrix
d-dimensional real vector
d-dimensional non-negative real vector
distribution of variable x, distribution of variable Θ
set of distribution P, set of distribution Q
mean vector of x, covariance matrix of x
empirical mean vector, empirical covariance matrix
vector with entries of 1, vector with entries of 0

section VI. Finally, some concluding remarks are presented in Section VII.

Notations: Some important notations used throughout this paper are listed in Table I. Other minutiae notations will be given

in detail in the corresponding sections.

II. PROBLEM FORMULATION

In this section, the smoothness based graph learning framework is ﬁrstly revisited. When there exists uncertainty in observed
graph signals, the distributionally robust graph learning problem is then proposed. To measure the discrepancy of distributions
in uncertainty sets, we select Wasserstein distance in this paper. Therefore, we introduce the deﬁnition on Wasserstein distance
in the last part of this section.

A. Smoothness Based Graph Learning

In this paper, we only focus on undirected graphs with nonnegative weights and no self-loops. Formally, deﬁne a graph
G = {V, E, f } with d vertices, where V = {v1, ..., vd} denotes vertex set and E is edge set. Mapping f : E → R allocates
every edge e in E a nonnegative real value as weight. Give a graph G, its adjacency matrix W is an d × d symmetric matrix
and we denote it as W ∈ Sd. Clearly, wij = wji = f ((vi, vj)) for i (cid:54)= j and wij = 0 if i = j, where (vi, vj) denotes the edge
whose corresponding vertices are vi and vj. Furthermore, the degree matrix D of G is deﬁned as a d × d diagonal matrix with
dii = (cid:80)d

j=1 Wij. Based on the above deﬁnitions, Laplacian matrix can then be deﬁned as

Note that L is a positive semi-deﬁnite matrix and the set of all Laplacian matrices can be written as

L (cid:44) {L : L ∈ Sd

+, L1 = 0, lij ≤ 0 for i (cid:54)= j}.

L = D − W.

(1)

(2)

In section III and IV, a normalized constraint Tr(L) = d is added to avoid trivial solution. Under this circumstance, the set of
all feasible Laplacian matrices is deﬁned as

Lc (cid:44) {L : L ∈ Sd

+, L1 = 0 , Tr(L) = d, lij ≤ 0 for i (cid:54)= j}.

(3)

A signal x = [x1, x2, ...xd]T deﬁned on graphs, which is named as graph signals, means that every dimension of this signals
represents a vertex in the graph. The existence of edges between two vertices can be understood as that the corresponding
two dimensions of the signals are related, and the weights quantify the relationships. Given N observations X = [x1, ...xN ]
generated from graph G, graph learning tasks are designed to infer the topology of G with d × N observation matrix X using
some prior assumptions. Recall that smoothness is the metric we adopt in this paper, it is crucial to appropriately deﬁne the
smoothness of signals over graphs. Several deﬁnitions of smoothness are proposed, such as [13], [16], [36], and in this paper
we employ the following form.

Deﬁnition 1: (Smoothness). Given an observed signal x and the Laplacian matrix L of graph G, the smoothness of x over

G is deﬁned as

xTLx =

1
2

(cid:88)

i,j

wij(xi − xj)2

(4)

4

In fact, the smaller value of (4) is, the smoother the signal over the graph. And (4) explicitly indicates that if an edge weight
wij is large, the values of the corresponding vertices of this edge are supposed to be close under smoothness assumption.
This can be explained as that, under smoothness assumption, edge weights of the learned graph represent the similarity of the
connected vertices. Based on the above deﬁnition, graph learning based on smoothness assumption can be formulated as

N
(cid:88)

i LxT
xT

i + η (cid:107) L (cid:107)2
F

i=1
Tr(XTLX) + η (cid:107) L (cid:107)2
F ,

inf
L∈L

= inf
L∈L

(5)

(6)

where X is the d × N observation matrix. The Frobenius norm term (cid:107) L (cid:107)2
F with constant η is used to control the edge weights
of the learned graph [12]. Note that the Laplacian L is learned from (6) and it can represent the topology of a graph because
of one-to-one relationship. We emphasize that (4) has some variant forms displayed in [13].

B. Distributionally Robust Graph Learning Formulation

We then turn our attention to how to learn a graph under smoothness assumption when there exists uncertainty in observed
signals. Given N d−dimensional observed signals x1, x2, ...xN with uncertainty caused by limited observability or noise
corruption, we are purposed to learn a robust graph taking uncertainty into consideration. As indicated in (6), classic formulation
ignores the uncertainty in signals. If the observed signals deviate from the true ones signiﬁcantly, unreliability will be brought
to the learned graph.

Since the observed signals x1, x2, ...xN are not reliable due to uncertainty, we can take signals generated from graphs as
unknown parameters. What we need to do is learning a robust graph with these unknown parameters. One natural idea is that
if the distribution of x is available, we can minimize the expectation of (4) to eliminate the impact of unknown parameters.
To be speciﬁc, we can learn a graph by the following formulation,

where Preal is the real distribution of x. This formulation is called stochastic optimization (SO) [17]. In SO, we learn a Laplacian
matrix with unknown parameters from the perspective of probability instead of only from the observed signals.

Unfortunately, in most situations of practical interest, Preal is hard to obtain precisely. Hence, empirical distributions,

EPreal

(cid:2)xTLx + η (cid:107) L (cid:107)2

F

(cid:3) ,

inf
L∈L

(7)

Pn = 1/N

N
(cid:88)

i=1

δ(xi),

are used as an alternative in many applications, where δ(xi) denotes the Dirac point mass at the ith training sample xi. Using
empirical distribution, (7) is converted into

inf
L∈L

= inf
L∈L

EPn

(cid:2)xTLx + η (cid:107) L (cid:107)2

F

(cid:3)

1
N

N
(cid:88)

i=1

i Lxi + η (cid:107) L (cid:107)2
xT
F ,

(8)

(9)

and this is called sample average approximation (SAA) [27]. The formulation is similar to the model named SigRep of [12] but
SAA is derived from probability perspective. However, when the number of observations is limited, empirical distributions may
be far from true distributions, which also bring uncertainty to sample distributions. As a result, SAA tends to display a poor
out-of-sample performance [27]. To address this issue, inspired by the idea of robust optimization, we deﬁne an uncertainty
set on sample distributions

P = {P| dist(P, Pn) ≤ (cid:15)} ,

(10)

where dist(·) measures the distance between two distributions. The uncertainty set contains all distributions whose distance
from empirical distribution Pn is less than (cid:15). For all distributions in uncertainty set, we deﬁne the worst case risk as
EP

(cid:2)xTLx + η (cid:107) L (cid:107)2

(cid:3) .

(11)

F

R(L) = sup
P∈P

Under the viewpoint of robust optimization, we may learn a robust graph L by minimizing the worst case, i.e.,

inf
L∈L

R(L) = inf
L∈L

sup
P∈P

EP

(cid:2)xTLx + η (cid:107) L (cid:107)2

F

(cid:3) .

(12)

The philosophy under minimizing the worst case is that we can push down the risk under all distributions in uncertainty
set, which of course includes the true distribution Preal [32]. For the learned L∗, the risks of all distributions in uncertainty
set are smaller than R(L∗). Hence, L∗ is not sensible to the change of P leading to a robust result. It should be pointed out

5

that, different from robust optimization whose uncertainty set is deﬁned on unknown parameters directly, the uncertainty set of
our formulation is deﬁned on the unknown distributions and this is the origin of the name distributionally robust optimization
(DRO). Furthermore, as shown in (10), (cid:15) determines the size of uncertainty sets. Clearly, larger (cid:15) implies more nuisance
distributions in uncertainty set, causing L∗ to be less sensitive to changes of P. From this point of view, larger (cid:15) means the
more robustness consideration. However, large (cid:15) may lead to over conservative L∗ since uncertainty sets can contain more
”bad” distributions which may not be encountered at all in real life. Therefore, (cid:15) actually controls the level of robustness and
an appropriate (cid:15) needs to be determined in advance.

C. Wasserstein Distance

In the deﬁnition of uncertainty set (10), many tools can be selected as dist(·), such as KL divergence, total variation metric,
etc. In this paper, we select Wasserstein distance to measure the discrepancy between two distributions due to its great properties
[17]. Before going into efﬁcient algorithms to solve the Wasserstein robust optimization problem in details, we ﬁrst introduce
the necessary deﬁnition on type-α Wassertein distance formally.

Deﬁnition 2: ( [30], Deﬁnition 2 ). For any α ∈ [1, ∞), type-α Wasserstein distance between two probability distributions

P1 and P2 on Rd is deﬁned as

Wα(P1, P2) =

(cid:18)

inf
π∈Π(P1,P2)

(cid:90)

Rd×Rd

C(z1, z2)απ(dz1, dz2)

(cid:19) 1

α

,

(13)

where C(·) denotes a cost function. In this paper, p-type norm is taken as cost functions, i.e., C(z1, z2) = (cid:107)z1 − z2(cid:107)p. In
addition, Π(P1, P2) represents the set of all probability distributions of z1 ∈ Rd and z2 ∈ Rd with marginal distribution P1
and P2.

Especially, when P1 and P2 are normal distributions, type-2 Wasserstein distance of P1 and P2 can be calculated with only

the ﬁrst two order moments.

Proposition 1: ( [37], Proposition 7 ). If p = 2 and α = 2, the type-2 Wasserstein distance of two normal distribution
+ are covariance matrices, then

P1 = N (µ1, Σ1) and P2 = N (µ2, Σ2), where µ1, µ2 ∈ Rd are mean vectors and Σ1, Σ2 ∈ Sd

(cid:115)

W2(P1, P2) =

(cid:107) µ1 − µ2 (cid:107)2

2 +Tr

(cid:20)

Σ1 + Σ2 − 2

(cid:16)

1
2

Σ

2 Σ1Σ

(cid:17) 1

2 (cid:21)
.

1
2
2

(14)

III. WASSERSTEIN ROBUST GRAPH LEARNING WITH GAUSSIAN PRIOR ASSUMPTIONS

A. Reformulation as Convex Optimization

In this section, we assume that all distributions in uncertainty set P are normal distributions. It is known that smooth signals
over a graph are governed by normal distribution, one case of which is mentioned in [13]. Thanks to the nice properties of
normal distributions, if we choose cost function as type-2 norm function and α = 2, the Wasserstein distance of two normal
distributions has closed form as displayed in (14). One advantage of equation (14) is that the type-2 Wasserstein distance is
explicitly available while ﬁrst two order moments of Gaussian distribution are provided. Based on (14), the uncertainty sets
containing only normal distribution can then be constructed as follows.

Suppose P ∼ N (µ, Σ) and empirical distribution Pn ∼ N (µn, Σn), then uncertainty set centered at nominal distribution

P = {P : W (P, Pn) ≤ (cid:15)} is equivalent to
(cid:115)

(cid:26)

PG =

(µ, Σ) :

(cid:107) µn − µ (cid:107)2

2 +Tr

(cid:20)
Σ + Σn − 2

(cid:16)

1
2

1
n ΣΣ
2
n

Σ

2 (cid:21)

(cid:17) 1

≤ (cid:15), Σ ∈ Sd
+

(cid:27)

.

Therefore, if p = 2 and α = 2, (12) can be written as

inf
L∈L

R(L) = inf
L∈L

sup
P∈PG

EP

(cid:2)xTLx + η (cid:107) L (cid:107)2

F

(cid:3)

At a ﬁrst glance, it is not tractable to solve the worst case R(L) of (16) because of the expectation operator. For this reason,
we move to the dual form of worst case risk R(L) such that we may get rid of the expectation operator.

Lemma 1: If α = 2, p = 2, for any γ ≥ 0, we have

R(L) = inf
γ≥0

h(γ, L) + γ (cid:2)(cid:15)2 − Tr(Σn)(cid:3) + η (cid:107) L (cid:107)2
F ,

where

(cid:26)

h(γ, L) = sup

µ,Σ(cid:23)0

Tr(cid:0)Σ(L − γI)(cid:1) + Tr(LµµT) − γ (cid:107) µ − µn (cid:107)2

2 +2γTr

(cid:18)(cid:113)

(17)

(18)

(cid:19) (cid:27)
.

1
2

1
n ΣΣ
2
n

Σ

(15)

(16)

Proof: The proof of Lemma 1 is straightforward. Firstly notice that

R(L) = sup
P∈PG
= sup
P∈PG
= sup

EP

(cid:2)xTLx + η (cid:107) L (cid:107)2

F

(cid:3)

Tr(LEP[xxT]) + η (cid:107) L (cid:107)2
F

Tr(L(Σ + µµT)) + η (cid:107) L (cid:107)2

F .

The worst case risk can then be expressed as:

µ,Σ(cid:23)0

Tr(L(Σ + µµT)) + η (cid:107) L (cid:107)2
F

sup
µ,Σ(cid:23)0
(cid:115)

s.t.

(cid:107) µn − µ (cid:107)2 +Tr

(cid:20)
Σ + Σn − 2

(cid:16)

1
2

1
n ΣΣ
2
n

Σ

2 (cid:21)

(cid:17) 1

≤ (cid:15)

By dualizing the constraint of (22), we can obtain

R(L) = sup

µ,Σ(cid:23)0

inf
γ≥0

Tr(L(Σ + µµT)) + η (cid:107) L (cid:107)2

F +γ

(cid:18)

(cid:15)2− (cid:107) µn − µ (cid:107)2 −Tr

(cid:18)
Σ + Σn − 2(cid:0)Σ

1
2

1
n ΣΣ
2
n

6

(19)

(20)

(21)

(22)

(cid:19)(cid:19)

(cid:1) 1

2

= inf
γ≥0

= inf
γ≥0

γ (cid:2)(cid:15)2 − Tr(Σn)(cid:3) + η (cid:107) L (cid:107)2

F + sup
µ,Σ(cid:23)0

Tr(cid:0)Σ(L − γI)(cid:1) + Tr(LµµT) − γ (cid:107) µ − µn (cid:107)2

2 +2γTr

h(γ, L) + γ (cid:2)(cid:15)2 − Tr(Σn)(cid:3) + η (cid:107) L (cid:107)2

F .

(cid:18)(cid:113)

Σ

(cid:19)

1
2

1
n ΣΣ
2
n

(23)

The second equality holds because of strong duality [38]. With (23), we can reach the conclusion of Lemma 1.

Although the expectation operation is avoided by using duality, the above problem (17) is still hard to handle due to the
inner supreme problem. Therefore, we further calculate the closed form of the inner supreme problem and then convert the
original problem into a tractable convex optimization form.

Theorem 1: If α = 2, p = 2, we have

inf
L∈L

R(L) = inf

L∈L,γI(cid:31)L

γ((cid:15)2 − Tr(Σx)) + γ2Tr((γI − L)−1Σx) + η (cid:107) L (cid:107)2
F ,

(24)

where Σx (cid:44) Σn + µnµT
n.

The proof of Theorem 1 is placed in Appendix A. With Theorem 1, we may get rid of expectation operator and the inf-sup

problem. Then it is feasible to solve (24) to obtain a desired graph.

B. Solving the Convex Optimization

For convenience, we deﬁne

g(γ, L) (cid:44) γ((cid:15)2 − Tr(Σx)) + γ2Tr((γI − L)−1Σx) + η (cid:107) L (cid:107)2
F ,

(γ > λmax).

(25)

where λmax is the largest eigenvalue of L. We add this constraint because of the constraint γI (cid:31) L in (24). In order to solve
(24), we propose that g(γ, L) is convex as the following theorem 2 states.

Theorem 2: For γ > λmax and L ∈ L, problem (24) is convex with γ and L.
Before we prove Theorem 2, some important facts, which is essential to our proof, are provided
Lemma 2: (Facts 7.4.8 in [39]) For any A, B ∈ Rd×d and C ∈ Sd, then

Tr(ACBC) = vec(C)T(B ⊗ AT)vec(C)

Lemma 3: (Proposition 7.1.7 in [39]) If A, B ∈ Sd

+, then

(A ⊗ B)−1 = A−1 ⊗ B−1

(26)

(27)

Proof: The proof is similar with Proposition 4.3 in [38]. Since g(γ, L) is a multivariable function with γ and L jointly,
we calculate the Hessian matrix of g(γ, L) and prove the positive deﬁnite of it. Through basic calculation, the Hessian matrix
of g(γ, L) is shown as follows.

7

(cid:21)

(28)

Fig. 2: Trend of g(γ, ·) with γ for a given L





∂2g(γ,L)
∂γ∂vec(L)
∂2g(γ,L)
∂γ2

(cid:17)T

H =





∂2g(γ,L)
∂vec(L)2
(cid:16) ∂2g(γ,L)
∂γ∂vec(L)

=

(cid:20)2γ2 (cid:0)((γI − L)−1Σx(γI − L)−1) ⊗ (γI − L)−1(cid:1) + 2ηId2
2γvec((γI − L)−1(I − γ(γI − L)−1)Σx(γI − L)−1)T

2γvec((γI − L)−1(I − γ(γI − L)−1)Σx(γI − L)−1)
2Tr (cid:0)Σx(I − γ(γI − L)−1)2(γI − L)−1(cid:1)

where ⊗ is Kronecker product and Id2 means identity matrix with d2 dimensions.

Next, we are aimed to prove the positive deﬁnite of H. Firstly, since γ > λmax and Σx (cid:31) 0, then ∂2g(γ,L)
∂vec(L)2 in H

we need to calculate the Schur complement of ∂2g(γ,L)

∂vec(L)2 (cid:31) 0. secondly,

S =

>

=

=

∂2g(γ, L)
∂γ2
∂2g(γ, L)
∂γ2
∂2g(γ, L)
∂γ2
∂2g(γ, L)
∂γ2

−

−

−

−

= 0

(cid:18) ∂2g(γ, L)
∂γ∂vec(L)
(cid:18) ∂2g(γ, L)
∂γ∂vec(L)

(cid:19)T (cid:18)

(cid:19)T (cid:18)

2γ2 (cid:0)((γI − L)−1Σx(γI − L)−1) ⊗ (γI − L)−1(cid:1) + 2ηId2

(cid:19)−1 ∂2g(γ, L)
∂γ∂vec(L)

2γ2 (cid:0)((γI − L)−1Σx(γI − L)−1) ⊗ (γI − L)−1(cid:1)

(cid:19)−1 ∂2g(γ, L)
∂γ∂vec(L)

(cid:18) ∂2g(γ, L)
∂γ∂vec(L)
(cid:18)

(γI − L)

1
2γ2
1
2γ2 Tr

(cid:19)T

(cid:0)(γI − L)Σ−1

x (γI − L) ⊗ (γI − L)(cid:1) ∂2g(γ, L)
∂γ∂vec(L)

∂2g(γ, L)
∂γ∂L

(γI − L)Σ−1

x (γI − L)

(cid:19)

∂2g(γ, L)
∂γ∂L

(29)

The inequality holds because 2ηId2 (cid:31) 0. The second and the third equality holds due to lemma 3 and lemma 2 respectively.
We can observe from (29) that the Schur complement of ∂2g(γ,L)
∂vec(L)2 in H is greater than 0. Thus, H is a positive deﬁnite matrix.
Finally, the constraints for the domain of the function g(γ, L), i.e., γ > λmax and L ∈ L do not affect the convexity of the
function g(γ, L). Thus we reach the conclusion of theorem 2.

Theorem 2 implies that there exists an unique solution (γ∗, L∗) for problem (24). Thus it is natural to solve (24) by using
a Newton-type method. Albeit feasible, we give up this method owing to the complexity and numerical stability. Instead, we
adopt a block coordinate descent method to solve (24). First of all, we ﬁx L and update γ. The corresponding function g(γ, ·)
is nonlinear and convex. To better illustrate the characteristics of the function g(γ, ·), for a given L, Figure 2 plots the trend
of g(γ, ·) with γ. It is clear that g(γ, ·) is a convex function, and will explode to inﬁnity quickly when γ approaches λmax.
On the other hand, g(γ, ·) will also asymptotically linearly toward inﬁnity when γ toward inﬁnity.

In order to ﬁnd the minimizer γ∗ of g(γ, ·), we calculate the ﬁrst-order partial derivative of g(γ, L) on γ,

gγ(γ, L) =

∂g(γ, L)
∂γ

= (cid:15)2 − Tr(Σx) + 2γTr((γI − L)−1Σx) − γ2Tr((γI − L)−1Σx(γI − L)−1)
= (cid:15)2 − Tr (cid:0)(I − γ(γI − L)−1)2Σx

(cid:1) .

(30)

8

Algorithm 1 Update γ using bisection search

Input:

Tolerance error;
Uncertainty set size (cid:15)
Parameters of search area a, b
Empirical mean vector µn;
Empirical covariance matrix Σn
Graph Laplacian of last iteration L;

Output:

The minimizer γ∗;
1: Calculate λmax of L;

Set initial upper bound ub = a × λmax;
Set initial lower bound lb = λmax + b;

2: Calculate initial middle value mid = (ub + lb)/2;
3: Calulate gγ(lb, L), gγ(ub, L) and gγ(mid, L) using (30);
4: If gγ(lb, L)gγ(mid, L) < 0:
Update ub, ub = mid;
If gγ(ub, L)gγ(mid, L) < 0:
Update lb, lb = mid;

5: If ub − lb > error:

Go back to step 2;

Else:

γ∗ = (ub + lb)/2

6: return γ∗

What we need to do right now is to ﬁnd γ∗ such that gγ(γ∗, L) = 0. Usually one might apply Newton method to directly
calculate γ∗. However, experiments show that if the initial value is not selected properly, the numerical results will diverge
frequently. To address this issue, we resort bisection method to ﬁnd γ∗. Actually, it locates between the biggest eigenvalue
λmax of graph Laplacian operator and the inﬁnity as Figure 2 depicts, henceforth it is feasible to use bisection method to ﬁnd
γ∗. The ﬂow of bisection method is shown in Algorithm 1.

Remark 1: We may represent (25) as

g(γ, L) (cid:44) γ((cid:15)2 − Tr(Σx)) + γ2 ·

Qd−1(γ)
γ · Pd−1(γ)

+ η (cid:107) L (cid:107)2
F ,

(γ > λmax),

in which both Pd−1(γ) and Qd−1(γ) are polynomials of order d − 1 and

Pd−1(γ) = (γ − λ2)(γ − λ3) · · · (γ − λmax),

(31)

(32)

which leads to the asymptotically linear behavior while γ → +∞. Notice that 0 = λ1 <= λ2 ≤ λmax are eigenvalues of
Laplacian L.

Secondly, we ﬁx γ and update L, and (24) boils down to the following problem.

inf
L
s.t.

γ2Tr(Σx(γI − L)−1) + η (cid:107) L (cid:107)2
F ,

lij = lji ≤ 0, i (cid:54)= j,
L1 = 0,
Tr(L) = d.

(33)

Note that, except L ∈ L, we add an extra constraint Tr(L) = d, which is meant to avoid trivial solutions [12]. As lemma 2
states, it is a convex optimization problem. We can apply interior point method to solve it and a variety of convex optimization
package, such as CVX in MATLAB, can be adpoted. However, in interior point method, we need to solve a Newton type
equation to obtain update directions, which is time consuming especially for order d2 variables. Inspired by [40], we exploit
a projection gradient descent (PGD) method to solve this problem. Since the symmetry of L and the L1 = 0 constraint, the
degrees of freedom of L is d(d−1)
. Hence, we introduce a linear operator T , which is deﬁned in detail in Appendix C, that
can convert a non-negative vector v ∈ Rd(d−1)/2

into a Laplacian matrix. With T , we can rewrite (33) as

2

+

inf
v≥0

r(v) = inf
v≥0

γ2Tr(Σx(γI − T v)−1) + η (cid:107) T v (cid:107)2

F +β(Tr(T v) − d)2.

(34)

9

Algorithm 2 Update L using PGD

Input:

Σx, η, β, γ∗ of last iteration, tolerance error,
max iteration maxIter;

Output:

The learned graph L∗;
1: Initialize iter = 0, v > 0;
2: Calculate update direction using (35);
3: Calculate step size s using line search method;
4: Update viter+1 using (36);
5: iter = iter + 1;
6: If (cid:107) viter − viter−1 (cid:107)2≥ error and iter < maxIter:

Go back to Step 2;

Else:

Go to return Step;

7: return L∗ = T v

Algorithm 3 Graph learning in gaussian scenario

Input:

Tolerance error;
Uncertainty set size (cid:15);
Max iteration maxIter;
Empirical mean vector µn;
Empirical covariance matrix Σn;

Output:

The learned graph L∗;

1: Initialize iter = 0;

Initialize any L0 ∈ Lc;
Set Σx = Σn + µnµT
n;
2: Update γiter+1 using Algorithm 1 with Liter;
3: Update Liter+1 by solving (33) with γiter+1;
4: iter = iter + 1;
5: If (cid:107) Liter − Liter−1 (cid:107)F≥ error and iter < maxIter:

Go back to Step 2;

Else:

Go to return Step;

6: return Liter

The last term of (34) is a relaxation of the constraint Tr(T v) = d. With this relaxation, solving a convex problem with equality
constraint is avoided. Indeed, (34) is a convex problem of v without structural constraints, and hence we can apply projection
gradient descent (PGD) method to solve it. Notice that the derivative of r(v) is

∇r(v) = γ2T ∗((γI − T v)−2Σx) + 2ηT ∗T v + 2β(Tr(T v) − d)T ∗I.

(35)

Then we may update v by using (35),

vk+1 = (vk − s∇r(vk))+,
(36)
where (·)+ (cid:44) max(·, 0), and s is the step size that is determined using backtrack line search method [41]. Finally, we can
reach the complete ﬂow of our proposed block coordinate descent algorithm, which is shown in Algorithm 3.

Note that g(γ, L) is jointly convex with γ and L, hence there exists a unique global minimum (γ∗, L∗). Speciﬁcally, in
the domain of g(γ, L), all terms are actually differentiable, and we can reach the conclusion that g(γ, L) is regular at each
coordination-wise minimum point γ∗ and L∗ based on Lemma 3.1 in [42]. Therefore, the minimum point γ∗ and L∗ for each
coordinate are the stationary points of g(γ, L), which is also the global minimum point for a convex function. Based on this,
the results obtained by iteratively updating γ and L will converge monotonically to the global minimum γ∗, L∗ ﬁnally.

C. Computation Complexity

In the step of updating γ, one of the time-consuming step is calculating λmax. The common method to calculate eigenvalue
is Cholesky decomposition, which requires order O(d3/3) ﬂops. For large-scale graph, we can apply Lanczos [43] to calculate

10

the λmax of a symmetric matrix, such as L. Moreover, we do not need to calculate λmax at each iteration. As the number
of iterations increases, the difference between each λmax will be small, hence the previously calculated λmax can be used as
the lower bound of bisection. On the other hand, when we calculate (30), the most time consuming is inverse operator whose
complexity is O(d3). We can also apply spectral perturbation method to avoid inverse operation at each iteration. Based on
above analysis, in updating γ step, the costs is p1d3, p1 is the number of iterations of bisection method to converge.

In the step of updating L, the cost of both T and T ∗ is order O(d2). When calculating derivative, the complexity is O(d3).

Then updating L costs order O(p2d3) ﬂops, where p2 is the number of iterations of PGD method to converge.

Based on the above analysis, the overall procedure costs order p3max{p1d3, p2d3} ﬂops, and p3 is the number of iterations

of Algorithm 3.

A. Reformulation as Convex Optimization

IV. WASSERSTEIN ROBUST GRAPH LEARNING WITHOUT PRIOR ASSUMPTION

In this section, we consider the case when prior information of the distribution of signals is not assumed, i.e., uncertainty set
might contain any distribution whose Wasserstein distance from empirical distribution smaller than (cid:15). Furthermore, distributions
are not required to be the same type of Wasserstein distance. In this setting, the uncertainty set can be deﬁned as

Revisit problem (12), the general formulation can then be speciﬁed as

P = {P : Wα(P, Pn) ≤ (cid:15), for all distributions P}

inf
L∈L

R(L) = inf
L∈L

sup
P∈P

EP

(cid:2)xTLx + η (cid:107) L (cid:107)2

F

(cid:3)

(37)

(38)

We ﬁrstly focus on the worst case risk R(L). Since no assumption is made on distributions, it is not feasible to use the ﬁrst
two order moments to replace expectation operator just as the previous section does. Obviously, expectation operator in (11)
is deﬁned on the probability of inﬁnite dimensions, and it is difﬁcult to solve such an optimization problems directly. For the
same reason as we present in Lemma 1, the following dual form of (38) is obtained by using the deﬁnition of Wα(P, Pn),

Lemma 4: For any γ > 0, the dual form of the worst case risk in (38) can be written as:

R(L) = sup
P∈P

EP

(cid:2)xTLx + η (cid:107) L (cid:107)2

F

(cid:3)

(cid:26)

= inf
γ≥0

γ(cid:15)α + η (cid:107) L (cid:107)2

F +

1
N

N
(cid:88)

i=1

sup
x∈Rd

(cid:8)Tr(xTLx) − γ (cid:107) x − xi (cid:107)α

p

(cid:9)

(cid:27)

,

(39)

The proof of lemma 4 is derived from Corollary 2 in [30], and the minor change is that cost function is chosen as p-type norm
in our formulation. With the dual form, we can easily reach corollary 1.

Corollary 1: The dual form of (38) can be further reformulated into the following form

R(L) = sup
Q∈Q

EQ[Tr(LΘ) + η (cid:107) L (cid:107)2
F]

(cid:26)

= inf
γ≥0

γ(cid:15)α + η (cid:107) L (cid:107)2

F +

1
N

N
(cid:88)

i=1

sup
U∈Sd

(cid:8)Tr(LU) − γ (cid:107) vec(U) − vec(Θi) (cid:107)α

p

(cid:9)

(cid:27)

,

where Θ (cid:44) xxT, Θi = xixT
Here the ﬁrst equality holds because

i . Q is the distribution of Θ and Q is the set of Q induced by P.

R(L) = sup
P∈P
= sup
P∈P
= sup
Q∈Q

EP[xTLx + η (cid:107) L (cid:107)2
F]

EP[Tr(LxxT) + η (cid:107) L (cid:107)2
F]

EQ[Tr(LΘ) + η (cid:107) L (cid:107)2
F],

(40)

(41)

and the second equality of (40) holds due to the duality presented in lemma 4. In (40), we replace the origin variable x with
Θ because a closed form of the inner supreme problem of (40) can be calculated with variable Θ. Speciﬁcally, with variable
Θ, we can prove that (12) in general scenario is equivalent to a convex problem using its dual form.

Theorem 3: The solution of (12) in general scenario is equivalent to the following problem.

inf
L∈L

= inf
L∈L

EP[xTLx + η (cid:107) L (cid:107)2
F]

sup
P∈P
Tr(LΘn) + η (cid:107) L (cid:107)2

F +(cid:15) (cid:107) vec(L) (cid:107)q

(42)

where Θn = Θ1+Θ2+....ΘN

N

= x1xT

2+...+xN xT
1+x2xT
N
N

, and 1

p + 1

q = 1.

11

Algorithm 4 Graph learning in general scenario

Input:

Θn, η, β, uncertainty set size (cid:15), tolerance error,
max iteration maxIter;

Output:

The learned graph L∗;
1: Initialize iter = 0, v > 0;
2: Calculate update direction using (45);
3: Calculate step size s using line search method;
4: Update viter+1 using (46);
5: iter = iter + 1;
6: If (cid:107) viter − viter−1 (cid:107)2≥ error and iter < maxIter:

Go back to Step 2;

Else:

Go to return Step;

7: return L∗ = T v

The detailed proof of Theorem 3 is illustrated in Appendix B. Note that the right side of (42) is actually an SAA problem
plus a regularization term. It is an interesting conclusion because robustness can be seen as a regularization term and the
size of uncertainty set (cid:15) controls the weight of regularization term as well as the level of robustness. Therefore, our proposed
framework provides an interpretation for the relationship between the size (radius) of uncertainty sets and robustness level.

B. Solving the Convex Optimization

To solve (42), we also add an extra constraint Tr(L) = d as the previous section does for the same reason and the complete

problem is shown as follows.

inf
L
s.t.

Tr(LΘn) + η (cid:107) L (cid:107)2

F +(cid:15) (cid:107) vec(L) (cid:107)q

lij = lji ≤ 0, i (cid:54)= j
L1 = 0
Tr(L) = d

(43)

If q ≥ 1, which is tantamount to p ≥ 1, the object function and constraints are all convex. We can solve this convex problem
by using projection gradient descent just as above-mentioned. With the linear operator T , the origin problem (43) can be
rewritten as:

inf
v≥0

m(v) = Tr(ΘnT v) + η (cid:107) T v (cid:107)2

F +(cid:15) (cid:107) vec(T v) (cid:107)q +β(Tr(T v) − d)2

The derivative of m(v) is

∇m(v) =T ∗Θn + 2ηT ∗T v + 2β(Tr(T v) − d)T ∗I + (cid:15) (cid:107) vec(T v) (cid:107)1−q

q

T ∗(T w).(q−1),

where (·).(q−1) means an element-wise operation. We can then update v using PGD

vk+1 = (vk − s∇m(vk))+,

where (·)+ (cid:44) max(·, 0), and s is the step size that is determined using backtrack line search method [41]. The complete
algorithm ﬂow is shown in Algorithm 4. The convergence of our algorithms can be guaranteed since it is a convex problem.

C. Computation Complexity

In Algorithm 4, both T and T ∗ cost order O(d2) ﬂops. In addition, since (·).(q−1) is a elementwise operator, the cost
is O(d2). Therefore, the overall procedure costs order p4d2 ﬂops, where p4 is the number of iterations of PGD method to
converge. When the scale of graph is large, which implies d is a large value, the speed of PGD will be superior to that of
interior point method.

(44)

(45)

(46)

V. REFORMULATION AS SEMI-DEFINITE PROGRAMMING (SDP)

In both Gaussian and general scenario, we convert the intractable (12) into a problem that can be solved easily. In this
section, we will prove that, if α = 2 and p = 2 for both scenarios, (12) is equivalent to a SDP problem. However, we will
also illustrate that it is impractical to solve such SDP problems and that is why we do not learn a robust graph in this way.

We ﬁrst display the SDP form of Gaussian scenario, which is shown in proposition 2
Proposition 2: If α = 2, p = 2, in Gaussian scenario, the following SDP problem and problem (12) have the same optimal

value.

inf
L∈L,γI(cid:31)L,z>=0,Z∈Sd
+

γ((cid:15)2 − Tr(Σx)) + η (cid:107) L (cid:107)2

F +z + Tr(Z)

12

(cid:21)

(cid:23) 0,

(47)

s.t.

(cid:20)γI − L γµn
z

γµT
n

(cid:34)

1
γI − L γΣ
2
n

1
γΣ
2
n

Z

(cid:35)

(cid:23) 0

Proof: From Theorem 1, the origin inf-sup problem has been proven to be tantamount to an inf-problem (24). The
remaining proof is similar with Corollary 2.9 in [38]. Speciﬁcally, in (24), we focus our attention on the nonlinear term
φ(γ, L) (cid:44) γ2Tr((γI − L)−1Σx) = γ2Tr((γI − L)−1Σn) + γ2Tr((γI − L)−1µnµT
n). The domain of φ(γ, L) is {(γ, L) : γI (cid:31)
L, L ∈ L}.In fact, φ(γ, L) is a matrix fractional function described in [44] and has the following reformulation [38]:
(cid:8)t : γI (cid:31) L, γ2Tr((γI − L)−1Σn) + γ2Tr((γI − L)−1µnµT
(cid:110)

φ(γ, L) = inf
t

n) ≤ t(cid:9)

(cid:111)

= inf
t,Z,z

t : γI (cid:31) L, Z (cid:23) γ2Σ

n (γI − L)−1Σ

1
2

n(γI − L)−1µn, Tr(Z) + z ≤ t

(48)

1
2

n , z ≥ γ2µT
(cid:34)

(cid:40)

= inf
Z,z

Tr(Z) + z : γI (cid:31) L,

(cid:20)γI − L γµn
z

γµT
n

(cid:21)

(cid:23) 0,

1
γI − L γΣ
2
n

1
γΣ
2
n

Z

(cid:35)

(cid:41)

(cid:23) 0

Bring (48) back to (24), we can ﬁnally reach the conclusion in proposition 2.

On the other hand, the SDP problem of general scenario is described in proposition 3
Proposition 3: If α = 2, p = 2, in general scenario, the following SDP problem and problem (12) have the same optimal

value.

inf
γ>0,zi>0,L∈L
(cid:20)γI − L
γxT
i

s.t.

γ(cid:15)2 + η (cid:107) L (cid:107)2

F +

(cid:21)

γxi
zi + γ (cid:107) xi (cid:107)2
2

1
N

N
(cid:88)

i=1

zi,

(49)

(cid:23) 0,

for i = 1, ..., N

Proof: From proposition (4), we can obtain the dual form of (12). By introducing auxiliary variables zi, the dual form of

worst case equals to:

R(L) = inf

γ>0,zi>0

γ(cid:15)2 + η (cid:107) L (cid:107)2

1
N
xTLx − γ (cid:107) x − xi (cid:107)2

F +

i=1
2 ≤ zi

N
(cid:88)

zi,

for i = 1, ..., N

s.t. sup
x∈Rd

= inf

γ>0,zi>0
(cid:20)−x
1

s.t. sup
x∈Rd

γ(cid:15)2 + η (cid:107) L (cid:107)2

F +

N
(cid:88)

zi,

1
N

i=1
−γxi

1
N

N
(cid:88)

i=1

zi,

= inf

γ(cid:15)2 + η (cid:107) L (cid:107)2

F +

γ>0,zi>0
(cid:20)γI − L
γxT
i

s.t.

(cid:21)

γxi
zi + γ (cid:107) xi (cid:107)2
2

(cid:23) 0,

for i = 1, ..., N

(cid:21)T (cid:20)L − γI
−γxT

i −zi − γ (cid:107) xi (cid:107)2
2

(cid:21)

(cid:21) (cid:20)−x
1

≤ 0,

for i = 1, ..., N

(50)

We then insert (50) into (12), and ﬁnally reach (49). It seems feasible to solve (47) and (49) to obtain the desired graph L
because we can resort state-of-art interior point solvers for such SDP problems. However, we should mention that reformulating
(12) to an SDP problem brings extra variables such as z and Z in (47) and zi in (49). Another point is that more constraints
are incurred in SDP problems. Therefore, the scale of SDP problems is signiﬁcantly larger than our formulation in section III

13

and IV. The impact of extra variables and constraints will be more intolerant if we use interior point method, which is the most
common method exploited by existing optimization packages, to solve SDP problems. In fact, according to our experiments
in the running environment shown in section VI, if we use interior point to solve an SDP problem with scale exceeding 150
vertices, out of memory error will appear anyway. Therefore, just as [38] states, when the number of vertices becomes large,
it is no longer practical to solve an SDP problem even for moderate values d. In addition, observe that, in (49), the number
of constraints is actually equal to that of samples. To reduce uncertainty, a large number of samples may be collected leading
to a huge problem scale of (49). Under this circumstance, it is impractical to solve such an SDP problem. In section VI, we
will compare the runtime of our proposed formulation with SDP formulation of Gaussian scenario (SDP of general scenario
is not practical to solve) to validate our analysis.

In this section, we evaluate our proposed graph learning framework with both synthetic data and real world data. First of

VI. EXPERIMENTS

all, experimental settings are presented.

A. Main Settings

On the top of to-do list is generating groundtruth graphs for synthetic data. We ﬁrst generate a similarity graph where edge
weights represent the similarity of corresponding vertices. The similarity is calculated using Gaussian radial basis function
(RBF), namely exp(−dist(i, j)2/2σ2), where dist(i, j) represents the distance between vertex i and vertex j and σ is the kernel
function width. Edges will be retained only when the similarity between two vertices is greater than a certain threshold τ .
In addition, for pipeline task, we detect communities in an SBM graph, which is a stochastic graph consist of some clusters,
because it is suitable for cluster tasks [45]. Four parameters of SBM graphs are required to be determined, namely the number
of clusters, the number of nodes in each cluster, the probability of node connection between clusters and within clusters.

Graph signals are generated from distribution N (0, L†), and † represents pseudo inverse. We generate graph signals in this
way because it is one of the model generating smooth signals in [13] and the smooth signals can be explained as a result of
graph ﬁltering. After obtaining the learned graph, we eliminate some unimportant edges, whose weights are less than 10−4,
in order to make the learned graph more reasonable.

All algorithms are implemented by MATLAB and run on an Intel(R) CPU with 3.80GHz clock speed and 16GB of RAM.

B. Synthetic data

For constructing groundtruth graph, we randomly generate coordinates of 20 vertices in a unit square and calculate the
similarity between these vertices using method above with parameter σ = 0.5 and τ = 0.7. Laplacian matrix of the groundtruth
graph are then calculated and we generate graph signals using above-mentioned method. For all experiments, white noises
w ∼ N (0, σ2

w), σw = 0.1 are added to the generated data directly.

Two metrics are adopted to evaluate the performance of the learned graph, which are Matthews correlation coefﬁcient (MCC)

[46] and difference of graphs (DOG) respectively. MCC is deﬁned as:

MCC =

TP · TN − FP · FN
(cid:112)(TP+FP)(TP+FN)(TN+TP)(TN+TN)

,

(51)

where T P (true positives) is the number of nonzero off-diagonal entries of groundtruth graph correctly identiﬁed in the learned
graph while F N (false negatives) is the number of those that are falsely identiﬁed as zeros. On the other hand, T N (true
negatives) is the number of zero off-diagonal entries that are correctly identiﬁed in the learned graph while F P is the number
of those misidentiﬁed as non-zeros. MCC is one of the most informative metrics for tasks of binary classiﬁcation because it
fuses all information of T N, T P, F N and F P . In the context of graph learning, binary classiﬁcation can be understood as
whether one edge are learned or not. The value of MCC belongs to [−1, +1], and +1 means that the learned graph exactly
learns the existence of all edges in groundtruth graph while −1 can be interpreted as a total misidentiﬁcation.

The other metric, DOG, is used to evaluate the difference between groundtruth and the learned graph, which is deﬁned as

DOG =

(cid:107) L∗ − Lgt (cid:107)F
(cid:107) Lgt (cid:107)F

,

(52)

where L∗ is the learned Laplacian matrix and Lgt is the groundtruth one.

The method of SAA model are taken as a baseline which is almost the same as [12] in section II. Parameter (cid:15) is selected
according to metric MCC, that is, the (cid:15) corresponding to the largest MCC will be selected from a candidate set. To improve
the reliability of the learning results, we run each experiment 20 times independently, and the ﬁnal result is the average of all
trials.

14

(a)

(b)

Fig. 3: Performance of the learned graph with different sample size (a) MCC; (b) DOG

1) Impact of sample size N : We ﬁrst study the uncertainty induced by sample size. Fig.3 (a) depicts the relationship between
MCC and the number of samples. When the number of samples are small, this indicates there is a large gap between nominal
distribution and true distribution, which brings more uncertainty to samples. Therefore, the learned graph of SAA performs
poorly in the case of small N . However, the performance of WDRO (both Gaussian and General scenario) is superior to that of
SAA. As the number of samples increases, nominal distribution starts to approach the true distribution, leading to a decrease in
sample uncertainty. This explains the fact that the performance of SAA increase as sample size. Additionally, the performance
improvement of WDRO is small when the sample size is large due to the same reason mentioned before. Fig.3 (b) shows the
relationship between DOG and the number of samples and the result displays a similar trend with that of MCC and both of
them illustrate the superiority of our framework.

2) Impact of uncertainty set size (cid:15): We then check the impact of uncertainty set (cid:15) on the learned graph. We can see from
4 (a) that, as (cid:15) increases, the value of MCC ﬁrst increases and then drops down. This is due to that (cid:15) represents the size
of uncertainty set and larger uncertainty set contains more distributions, which brings more robustness. For a certain level of
uncertainty, when (cid:15) increases from 0, the level of robustness will start to approach to the one ”best matching” the uncertainty
level. However, if (cid:15) is too large, the result is not ideal because the uncertainty set may contain too many nuisance distributions
far from the real one, causing the worst case risk is too conservative. The results vividly demonstrate the role of (cid:15) in our
framework, and we need to make a trade-off between robustness levels. Furthermore, the best (cid:15), which is corresponding to the
largest MCC or DOG value decreases as the number of sample increases. The reason for this trend is that increases in sample
size reduces the uncertainty of sample distributions because the gap between nominal and real distributions is getting small as
sample size increases. Therefore, it is suitable to set a lower robustness level for the case of large number of samples. Fig.4
(b) interprets the same trend from the perspective of DOG.

3) Reliability: To better understand the impact of (cid:15), we deﬁne a metric called certiﬁcate reliability as

Reliability = P{R(xt, L∗) < R∗},

(53)

where R(xt, L∗) is the risk with respect to testing samples xt and L∗ and can be calculated as xT
F. Additionally,
R∗ is the optimal value of (12) and is equivalent to the worst case R(L∗). Give some testing samples xt and L∗, reliability is
tantamount to the empirical probability of that the risks of testing samples are smaller than R∗. On the other hand, reliability
also represents the probability of whether uncertainty set contains the true distribution of signals. This can be explained that if
uncertainty set is large enough to contain Preal, the worst case risk R(L∗) of all distributions in uncertainty set must be larger
than the risk of testing samples because testing samples and training samples are from the same distribution, that is, Preal.

t L∗xt+η (cid:107) L∗ (cid:107)2

As shown is Fig.5, for both general and Gaussian scenario, as (cid:15) increases, reliability approaches to 1. This trend makes
sense since that for a larger (cid:15), uncertainty sets are more likely to contain Preal. Reliability reveals how (cid:15) controls robustness.
Furthermore, from Fig.5, we can conclude the fact that Gaussian scenario tends to need smaller (cid:15) for reliability reaching 1.

4) Impact of noise level σw: In addition to the uncertainty caused by sample size, we also take noise-induced uncertainty
into consideration. To this end, we ﬁx the number of signals to 100 and change σw from 0.1 to 1. As depicted in 6 (a),
when noise level is low (lower than 0.5), it has little impact on MCC of the graph learned by WDRO framework while the
performance of SAA drops signiﬁcantly. When the noise level increases further, MCC of our framework also decreases but is
still better than that of SAA. For another side, as shown in 6 (b), the impact of noise level on DOG is not as great as that of

102103104N0.50.60.70.80.9MCCWDRO-GeneralWDRO-GaussianSAA102103104N0.20.250.30.350.40.450.50.55DOGWDRO-GeneralWDRO-GaussianSAA15

(a)

(b)

Fig. 4: Performance of the learned graph with different uncertainty sizes (a) MCC; (b) DOG

Fig. 5: Reliability values of different uncertainty set sizes

MCC. This may caused by that the misidentiﬁed edges, which can affect MCC considerably, have small weight. Hence, they
have less impact on DOG than MCC.

5) Impact of norm type p: We then show the impact of norm type in cost function of Wasserstein distance. Since we assume
p = 2 in Gaussian scenario, we only take the general scenario into consideration. Additionally, for the reason that MCC and
DOG show similar trend, we only list the results of MCC.

As illustrated in Table II, the performance of larger p values is superior to those of small p values except p = ∞. However,

the superiority is not signiﬁcant, and if take convenience into consideration, p = 2 will be a suitable choice.

6) Performance of pipeline tasks: Next we check the performance of the learned graph on pipeline tasks. We apply Louvain
algorithm [18] to detect communities in the learned graph. For this purpose, we generate a SBM graph with 3 clusters and
each cluster contains 15 vertices. The probabilities of node connections between clusters and within clusters are 0.02 and 0.3
respectively. To evaluate the performance of detection results, we adopt normalized mutual information (NMI) to measure the
dependence between the cluster results of ground-truth and those of the learned graph. The results are shown in Table III, from
which we can see that in the case of small sample size, the performances of WDRO framework outperform those of SAA,
illustrating that the detection results of our framework are more similar to the groundtruth. However, when the sample is large,
the superiority of our framework is not as obvious as that of small size case because uncertainty decreases as sample size.

7) Efﬁciency of algorithms: The last part of synthetic data experiments is testing the efﬁciency of the proposed algorithm.
We compare our algorithm with classic interior point (IP) method . For Gaussian scenario, we use the use interior point to
solve the SDP form of the origin problem. As depicted in 7, the runtime of four algorithms all increases as the number of
vertices in graph. However, as stated in complexity analysis part, the runtime of IP increases more drastically than that of

10-110010100.20.40.60.81MCCN=50N=100N=200N=1000GeneralN=50N=100N=200N=1000Gaussian10-11001010.10.20.30.40.5DOGN=50N=100N=200N=1000GeneralN=50N=100N=200N=1000Gaussian10-210-11001011020.30.40.50.60.70.80.9ReliabilityN=50N=100N=200N=1000GeneralN=50N=100N=200N=1000Gaussian16

(a)

(b)

Fig. 6: Performance of the learned graph with different levels of noise (a) MCC; (b) DOG

TABLE II: MCC values of the learned graph using different norm type p under general scenario

Samp

1

4/3

3/2

2

3

4

N = 50
N = 100
N = 200
N = 1000

0.629
0.706
0.755
0.820

0.640
0.723
0.753
0.822

0.656
0.742
0.755
0.824

0.704
0.771
0.786
0.832

0.736
0.796
0.812
0.844

0.740
0.805
0.814
0.851

∞

0.627
0.722
0.752
0.820

our algorithm in both Gaussian and general scenarios. On the other hand, we can observe that Gaussian scenario is more
time-consuming than general scenario since in Gaussian the algorithm costs order O(d3) ﬂops. Therefore, to reduce runtime,
we can adopt some tricks to avoid these time-consuming operators. The details can be found in complexity analysis section.
Another important fact is that the most time consuming scenario is SDP reformulation solved by interior point method. This
is due to the fact that SDP problem bring extra variables and constraints just as analyzed in section V. Actually, the reason
we set the maximum of d in Figure 7 120 is that out-of-memory errors will occur if d > 150 for the experiments of SDP
problems. Therefore, it is not practical to reformulate (12) as a SDP problem.

C. Real data

We ﬁrst apply our framework to the temperature data of 31 provincial capitals in Mainland China to learn a climate correlation
graph between these cities. We collect temperature information from 2017 to 2019 1 and average the data of the ﬁrst and second
half month. Finally, 72 signals are obtain,the number of which is small for a 31-vertices graph, which brings large uncertainty
in the collected data. Since no groundtruth graph is available, we only discuss the rationality of the learned graph.

From Fig.8 (a) and (b), we can see that edges almost lie in latitude direction. It is reasonable because the temperatures in the
same latitude area tend to be similar. If the latitude difference between two regions is large, then temperature difference between
them will also be large, meaning a weaker temperature connection. Visually, these connections divide Chinese mainland into 4
regions from north to south. These 4 regions roughly correspond to cold-temperate/medium-temperate regions, warm-temperate
regions, subtropical regions and tropical regions. It is also worth noting that there are four isolated points on the graph of
general scenario, which are Xining, Lhasa, Kunming and Haikou. The ﬁrst three cities are all in plateau, which means that
their altitudes are much higher than other cities. High altitude makes them completely different from other regions climatically.
The last isolated city is Haikou, which lies in a island in tropical region. It is reasonable to differ from other cities on land.
We also apply our framework to temperature data of states of the mainland of USA except Alaska and Hawaii. Temperature
data of 48 states are collected and for each states, we collected the weekly average temperature for 2020 and part of 2019 2.
Hence, a total of 60 signals for each state are collected. Note that 60 signals for a 48 vertices means high level of uncertainty.
Same as the case above, we discuss the rationality of the learned graph. The results is shown in Fig.9. Same as the learned
graph of China, edges in Fig.9 almost lie in latitude direction. The isolated points are in high altitude or in low latitude, i.e.,
Florida. Another interesting trend is that edges in the east are much more those in the west. This may be caused by the fact

1The data is available at website http://www.weather.com.cn/
2The data is available at website https://data.iimedia.cn/

00.20.40.60.81Noise level0.50.550.60.650.70.750.80.85MCCWDRO-GeneralWDRO-GaussianSAA00.20.40.60.81Noise level0.250.30.350.40.450.50.550.6DOGWDRO-GeneralWDRO-GaussianSAATABLE III: Performance of community detection results using the learned graph

N

80

100

150

200

500

1000

General
Gaussian
SAA

0.727
0.737
0.700

0.756
0.7734
0.699

0.762
0.745
0.725

0.814
0.814
0.774

0.787
0.776
0.779

0.785
0.799
0.781

17

Fig. 7: Running time of different graph scales

plains are the most common terrain in the east of the USA while the terrains in the west are more complex. Furthermore, the
distances between states in the west are also greater, which may cause greater climatic differences. The learned graphs in both
general scenario and Gaussian scenario are reasonable, unveiling the power of our framework.

VII. CONCLUSION

In this paper, we are committed to the problem of learning a graph directly from data in the context of uncertainty. To
this end, we propose a graph learning framework based on Wasserstein distributionally robust optimization, which handles
uncertainty from the perspective of data distribution. Speciﬁcally, we develop two graph learning models based on Gaussian
distribution assumption and a more general circumstance without any prior distribution assumption. Two algorithms are also
put forward to solve these models, which is proven to be more efﬁcient than classic interior point method. Experimental results
show that our framework can learn a reliable graph under uncertainty.

Future research directions include applying distributionally robust optimization framework to other prior assumptions except

smoothness, as well as a more efﬁcient algorithm accommodate large-scale graphs.

APPENDIX A
PROOF OF THEOREM 1
By the dual form of R(L) in Lemma 1, we notice the maximization h(γ, L) can be decoupled with Σ and µ separately.

Let’s deﬁne

l1(Σ) (cid:44) Tr[Σ(L − γI)] + 2γTr(
Σ
n ΣΣ
l2(µ) (cid:44) Tr(LµµT) − γ (cid:107) µ − µn (cid:107)2
2 .

(cid:113)

1
2

1
2

n ),

Then h(γ, L) can be written as

h(γ, L) = sup
Σ(cid:23)0

l1(Σ) + sup
µ

l2(µ).

Therefore, we can calculate the maximum value of l(Σ, µ) with respect to Σ and µ separately.
n ΣΣ1/2

Firstly, we focus on l1(Σ), and deﬁne Σ1/2

n (cid:44) M2, it can be found that

sup
Σ(cid:23)0

l1(Σ) = sup
M(cid:23)0

Tr

(cid:16)

M2Σ− 1

n (L − γI)Σ− 1

n

2

2

(cid:17)

+ 2γTr(M).

(54)

(55)

(56)

(57)

Since the r.h.s of (57) is a quadratic form of positive semi-deﬁnite matrix M, the maximum exists only when γI (cid:23) L and the
maximizer is

M∗ = −γΣ

n (L − γI)−1Σ

1
2

1
2

n .

(58)

204060801001200100200300400500600700Runtime(sec)General-PGDGeneral-IPGaussian-PGDGaussian-SDP18

Fig. 8: The learned temperature relationship graph of the mainland of China (a) general scenario; (b) Gaussian scenario

(a)

(b)

Fig. 9: The learned temperature relationship graph of the mainland of the USA (a) general scenario; (b) Gaussian scenario

(a)

(b)

Bring M∗ to (57), we can get

l1(Σ) = −γ2Tr

(cid:16)

sup
Σ(cid:23)0

1
2

1
n (L − γI)−1Σ
2
n

Σ

(cid:17)

.

(59)

Next, we turn our attention on l2(µ). Calculate the derivative of l2(µ) and we assume γI (cid:31) L, the maximizer µ∗ equals to

γ(γI − L)−1µn. Bring it back to l2(µ), it is easy to obtain

Combining (59) and (60), we reach the maximization h(γ, L), that is,

l2(µ) = −γµT

nµn + γ2(γI − L)−1µT

nµn.

sup
µ

h(γ, L) = −γ2Tr

(cid:16)

1
2

Σ

n (L − γI)−1Σ

− γµT
nµn + γ2Tr((γI − L)−1Σx).

(cid:17)

1
2
n

= −γµT

nµn + γ2(γI − L)−1µT

nµn

Finally, bring h(γ, L) back to (17) in Lemma 1, the worst case risk R(L) is equivalent to

R(L) = inf
γI(cid:31)L
= inf
γI(cid:31)L

γ[(cid:15)2 − Tr(Σn)] − γµT

nµn + γ2Tr((γI − L)−1Σx) + η (cid:107) L (cid:107)2
F

γ[(cid:15)2 − Tr(Σx)] + γ2Tr((γI − L)−1Σx) + η (cid:107) L (cid:107)2

F .

With (63), we can reach the conclusion of Theorem 1.

(60)

(61)

(62)

(63)

The outline of this proof is similar with Theorem 2.1 in [47]. According to corollary 1, we can rewrite (12) as:

APPENDIX B
PROOF OF THEOREM 3

inf
L∈L

sup
P∈P

EP[xTLx + η (cid:107) L (cid:107)2
F]

= inf

L∈L,γ≥0

(cid:40)

(cid:40)

γ(cid:15)α + η (cid:107) L (cid:107)2

F +

(cid:44) inf

L∈L,γ≥0

γ(cid:15)α + η (cid:107) L (cid:107)2

F +

1
N

1
N

N
(cid:88)

i=1
N
(cid:88)

i=1

Tr(LU) − γ (cid:107) vec(U) − vec(Θi) (cid:107)α
p

(cid:27)(cid:41)

(cid:26)

sup
U∈Sd

(cid:41)

ϕi(L)

19

(64)

We ﬁrst focus our attention on the inner sup of the dual form (64) and calculate the close form of ϕi(L). Deﬁne ∆ (cid:44) U − Θi,
and then

ϕi(L) = sup
∆∈Sd
= sup
∆∈Sd

(cid:8)Tr(L(∆ + Θi)) − γ (cid:107) vec(∆) (cid:107)α
(cid:8)Tr(L∆) − γ (cid:107) vec(∆) (cid:107)α

p

p +Tr(LΘi)(cid:9)

(cid:9)

Since Tr(L∆) = vec(L)vec(∆), apply H¨older inequality and we get Tr(L∆) ≤(cid:107) vec(L) (cid:107)q(cid:107) vec(∆) (cid:107)p, where the equality
holds only when Tr(L∆) > 0 and there exists constant λ so that |∆ij|p = λ|Lij|q with 1
q = 1. For convenience, we
deﬁne a set S containing all ∆ making the equation hold, that is, S = {∆ : Tr(L∆) > 0, |∆ij|p = λ|Lij|q, ∆ ∈ Sd}. Based
on this setting, (65) can written as:

p + 1

ϕi(L) = sup
∆∈S

{(cid:107) vec(L) (cid:107)q(cid:107) vec(∆) (cid:107)p −γ (cid:107) vec(∆) (cid:107)α

p +Tr(LΘi)}

(cid:44) Tr(LΘi) + sup
∆∈S

h(∆)

(66)

What we need to do is to calculate the maximum of h(∆), and we will calculate in two different situations, that is, α = 1
and α ≥ 1.

When α = 1, h(∆) is actually a linear function with (cid:107) vec(∆) (cid:107)p and the maximum of h(∆), which is equals to 0, exists

only when γ ≥(cid:107) vec(L) (cid:107)q. In this scenario, ϕi(L) equals to Tr(LΘi). Replace it back to (64), we can reach:
EP[xTLx + η (cid:107) L (cid:107)2
F]

inf
L∈L

sup
P∈P

(cid:40)

= inf
L∈L

inf
γ≥(cid:107)vec(L)(cid:107)q

γ(cid:15)α + η (cid:107) L (cid:107)2

F +

(cid:41)

Tr(LΘi)

1
N

N
(cid:88)

i=1

N
(cid:88)

(cid:15) (cid:107) vec(L) (cid:107)q +

1
N
Tr(LΘn) + (cid:15) (cid:107) vec(L) (cid:107)q +η (cid:107) L (cid:107)2
F

i=1

Tr(LΘi) + η (cid:107) L (cid:107)2
F

= inf
L∈L

= inf
L∈L

(67)

When α > 1, we need to calculate the derivate of h(∆) to get the maximum. After the ﬁrst and second derivative test, we

, h(∆) reaches its maximum. Bring the maximizer to (66) to calculate the

obtain that when (cid:107) vec(∆) (cid:107)p =
maximum and we get:

(cid:16) (cid:107)vec(L)(cid:107)q
γα

(cid:17) 1

α−1

α
α−1
ϕi(L) =(cid:107) vec(L) (cid:107)
q

In the same way, put the maximum into (64):

(cid:32)

1

(γα)

1
α−1

−

γ
(γα)

α
α−1

(cid:33)

+ Tr(LΘi)

inf
L∈L

sup
P∈P

EP[xTLx + η (cid:107) L (cid:107)2
F]

(cid:26)

= inf
L∈L

inf
γ≥0

γ(cid:15)α + η (cid:107) L (cid:107)2

F + (cid:107) vec(L) (cid:107)

(cid:32)

α
α−1
q

1

(γα)

1
α−1

−

γ
(γα)

α
α−1

(cid:33)

(cid:27)

+ Tr(LΘn)

(65)

(68)

(69)

Similarly, we need to calculate the inner minimum with γ of (69). After the ﬁrst and second derivative test, we can obtain the
minimizer γ∗ = (cid:107)vec(L)(cid:107)q
α(cid:15)α−1

. Bring γ∗ to (69), we ﬁnally obtain:

inf
L∈L

= inf
L∈L

EP[xTLx + η (cid:107) L (cid:107)2
F]

sup
P∈P
Tr(LΘn) + (cid:15) (cid:107) vec(L) (cid:107)q +η (cid:107) L (cid:107)2
F

(70)

In both α = 1 and α > 1, we can reach the conclusion of Theorem 3, and ﬁnally we complete the proof.

APPENDIX C
DEFINITION OF OPERATOR T

20

Given a vector v ∈ Rd(d−1)/2

, linear operator T is used to convert v to a Laplacian matrix, that is, v (cid:55)→ T v ∈ Rd×d,
where T v satisﬁes Laplacian constraints([T v]ij = [T v]ji ≤ 0, for i ≤ j and [T v] · 1 = 0). Based on this, the linear operator
can be deﬁned as [40]:

+

[T v]ij =






−vi+bj
[T v]ji
− (cid:80)

i(cid:54)=j[T v]ij

i > j,
i < j,
i = j,

(71)

where bj = −j + j−1

2 (2d − j)

The adjoint operator T ∗ of T can then be derived , that is, (cid:104)T v, V(cid:105) = (cid:104)v, T ∗V(cid:105). Speciﬁcally, for a matrix V, the adjoint

operator T ∗ : V (cid:55)→ T ∗v is deﬁned as

[T ∗V]k = Vii − Vij − Vji + Vjj,

(72)

where i, j ∈ Z+ and k = i − j + j−1

2 (2p − j) with i > j.

REFERENCES

[1] D. Thanou, X. Dong, D. Kressner, and P. Frossard, “Learning heat diffusion graphs,” IEEE Transactions on Signal and Information Processing over

Networks, vol. 3, no. 3, pp. 484–499, 2017.

[2] X. Dong, D. Thanou, M. Rabbat, and P. Frossard, “Learning graphs from data: A signal representation perspective,” IEEE Signal Processing Magazine,

vol. 36, no. 3, pp. 44–63, 2019.

[3] J. Friedman, T. Hastie, and R. Tibshirani, “Sparse inverse covariance estimation with the graphical lasso,” Biostatistics, vol. 9, no. 3, pp. 432–441, 2008.
[4] M. Yuan and Y. Lin, “Model selection and estimation in the gaussian graphical model,” Biometrika, vol. 94, no. 1, pp. 19–35, 2007.
[5] P. Ravikumar, G. Raskutti, M. J. Wainwright, and B. Yu, “Model selection in gaussian graphical models: High-dimensional consistency of l1-regularized

mle.,” in NIPS, pp. 1329–1336, 2008.

[6] D. I. Shuman, S. K. Narang, P. Frossard, A. Ortega, and P. Vandergheynst, “The emerging ﬁeld of signal processing on graphs: Extending high-dimensional

data analysis to networks and other irregular domains,” IEEE signal processing magazine, vol. 30, no. 3, pp. 83–98, 2013.

[7] A. Ortega, P. Frossard, J. Kovaˇcevi´c, J. M. Moura, and P. Vandergheynst, “Graph signal processing: Overview, challenges, and applications,” Proceedings

of the IEEE, vol. 106, no. 5, pp. 808–828, 2018.

[8] G. Mateos, S. Segarra, A. G. Marques, and A. Ribeiro, “Connecting the dots: Identifying network structure via graph signal processing,” IEEE Signal

Processing Magazine, vol. 36, no. 3, pp. 16–43, 2019.

[9] B. Pasdeloup, V. Gripon, G. Mercier, D. Pastor, and M. G. Rabbat, “Characterization and inference of graph diffusion processes from observations of

stationary signals,” IEEE transactions on Signal and Information Processing over Networks, vol. 4, no. 3, pp. 481–496, 2017.

[10] S. Segarra, A. G. Marques, G. Mateos, and A. Ribeiro, “Network topology inference from spectral templates,” IEEE Transactions on Signal and

Information Processing over Networks, vol. 3, no. 3, pp. 467–483, 2017.

[11] H. E. Egilmez, E. Pavez, and A. Ortega, “Graph learning from ﬁltered signals: Graph system and diffusion kernel identiﬁcation,” IEEE Transactions on

Signal and Information Processing over Networks, vol. 5, no. 2, pp. 360–374, 2018.

[12] X. Dong, D. Thanou, P. Frossard, and P. Vandergheynst, “Learning laplacian matrix in smooth graph signal representations,” IEEE Transactions on

Signal Processing, vol. 64, no. 23, pp. 6160–6173, 2016.

[13] V. Kalofolias, “How to learn a graph from smooth signals,” in Artiﬁcial Intelligence and Statistics, pp. 920–929, PMLR, 2016.
[14] S. P. Chepuri, S. Liu, G. Leus, and A. O. Hero, “Learning sparse graphs under smoothness prior,” in 2017 IEEE International Conference on Acoustics,

Speech and Signal Processing (ICASSP), pp. 6508–6512, IEEE, 2017.

[15] W. Huang, A. G. Marques, and A. R. Ribeiro, “Rating prediction via graph signal processing,” IEEE Transactions on Signal Processing, vol. 66, no. 19,

pp. 5066–5081, 2018.

[16] P. Berger, G. Hannak, and G. Matz, “Efﬁcient graph learning from noisy and incomplete data,” IEEE Transactions on Signal and Information Processing

over Networks, vol. 6, pp. 105–119, 2020.

[17] H. Rahimian and S. Mehrotra, “Distributionally robust optimization: A review,” arXiv preprint arXiv:1908.05659, 2019.
[18] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre, “Fast unfolding of communities in large networks,” Journal of statistical mechanics:

theory and experiment, vol. 2008, no. 10, p. P10008, 2008.

[19] H.-G. Beyer and B. Sendhoff, “Robust optimization–a comprehensive survey,” Computer methods in applied mechanics and engineering, vol. 196,

no. 33-34, pp. 3190–3218, 2007.

[20] A. Ben-Tal, L. El Ghaoui, and A. Nemirovski, Robust optimization. Princeton university press, 2009.
[21] D. Fouskakis and D. Draper, “Stochastic optimization: a review,” International Statistical Review, vol. 70, no. 3, pp. 315–349, 2002.
[22] A. Nemirovski, A. Juditsky, G. Lan, and A. Shapiro, “Robust stochastic approximation approach to stochastic programming,” SIAM Journal on

optimization, vol. 19, no. 4, pp. 1574–1609, 2009.

[23] J. Goh and M. Sim, “Distributionally robust optimization and its tractable approximations,” Operations research, vol. 58, no. 4-part-1, pp. 902–917,

2010.

[24] A. Ben-Tal, D. Den Hertog, A. De Waegenaere, B. Melenberg, and G. Rennen, “Robust solutions of optimization problems affected by uncertain

probabilities,” Management Science, vol. 59, no. 2, pp. 341–357, 2013.

[25] J. Duchi and H. Namkoong, “Variance-based regularization with convex objectives,” arXiv preprint arXiv:1610.02581, 2016.
[26] M. Staib and S. Jegelka, “Distributionally robust optimization and generalization in kernel methods,” arXiv preprint arXiv:1905.10943, 2019.
[27] P. M. Esfahani and D. Kuhn, “Data-driven distributionally robust optimization using the wasserstein metric: Performance guarantees and tractable

reformulations,” Mathematical Programming, vol. 171, no. 1, pp. 115–166, 2018.

[28] C. Villani, Optimal transport: old and new, vol. 338. Springer Science & Business Media, 2008.
[29] E. Simou, D. Thanou, and P. Frossard, “node2coords: Graph representation learning with wasserstein barycenters,” IEEE Transactions on Signal and

Information Processing over Networks, 2020.

[30] R. Gao and A. J. Kleywegt, “Distributionally robust stochastic optimization with wasserstein distance,” arXiv preprint arXiv:1604.02199, 2016.
[31] J. Blanchet, K. Murthy, and F. Zhang, “Optimal transport based distributionally robust optimization: Structural properties and iterative schemes,” arXiv

preprint arXiv:1810.02403, 2018.

[32] D. Kuhn, P. M. Esfahani, V. A. Nguyen, and S. Shaﬁeezadeh-Abadeh, “Wasserstein distributionally robust optimization: Theory and applications in

machine learning,” in Operations Research & Management Science in the Age of Analytics, pp. 130–166, INFORMS, 2019.

21

[33] M. Staib and S. Jegelka, “Distributionally robust deep learning as a generalization of adversarial training,” in NIPS workshop on Machine Learning and

Computer Security, 2017.

[34] S. Shaﬁeezadeh-Abadeh, P. M. Esfahani, and D. Kuhn, “Distributionally robust logistic regression,” arXiv preprint arXiv:1509.09259, 2015.
[35] R. Gao, L. Xie, Y. Xie, and H. Xu, “Robust hypothesis testing using wasserstein uncertainty sets.,” in NeurIPS, pp. 7913–7923, 2018.
[36] D. Zhou and B. Sch¨olkopf, “A regularization framework for learning from graph data,” in ICML 2004 Workshop on Statistical Relational Learning and

Its Connections to Other Fields (SRL 2004), pp. 132–137, 2004.

[37] C. R. Givens, R. M. Shortt, et al., “A class of wasserstein metrics for probability distributions.,” The Michigan Mathematical Journal, vol. 31, no. 2,

pp. 231–240, 1984.

[38] V. A. Nguyen, D. Kuhn, and P. M. Esfahani, “Distributionally robust inverse covariance estimation: The wasserstein shrinkage estimator,” arXiv preprint

arXiv:1805.07194, 2018.

[39] D. S. Bernstein, Matrix mathematics: theory, facts, and formulas. Princeton university press, 2009.
[40] S. Kumar, J. Ying, J. V. de Miranda Cardoso, and D. P. Palomar, “A uniﬁed framework for structured graph learning via spectral constraints.,” Journal

of Machine Learning Research, vol. 21, no. 22, pp. 1–60, 2020.

[41] J. Nocedal and S. Wright, Numerical optimization. Springer Science & Business Media, 2006.
[42] P. Tseng, “Convergence of a block coordinate descent method for nondifferentiable minimization,” Journal of optimization theory and applications,

vol. 109, no. 3, pp. 475–494, 2001.

[43] C. Lanczos, “An iteration method for the solution of the eigenvalue problem of linear differential and integral operators,” Journal of research of the

National Bureau of Standards, vol. 45, pp. 255–282, 1950.

[44] S. Boyd, S. P. Boyd, and L. Vandenberghe, Convex optimization. Cambridge university press, 2004.
[45] P. W. Holland, K. B. Laskey, and S. Leinhardt, “Stochastic blockmodels: First steps,” Social networks, vol. 5, no. 2, pp. 109–137, 1983.
[46] D. M. Powers, “Evaluation: from precision, recall and f-measure to roc, informedness, markedness and correlation,” arXiv preprint arXiv:2010.16061,

2020.

[47] P. Cisneros-Velarde, A. Petersen, and S.-Y. Oh, “Distributionally robust formulation and model selection for the graphical lasso,” in International

Conference on Artiﬁcial Intelligence and Statistics, pp. 756–765, PMLR, 2020.

