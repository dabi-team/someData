Learning Active Constraints to Efﬁciently Solve
Linear Bilevel Problems: Application to the
Generator Strategic Bidding Problem

El´ea Prat and Spyros Chatzivasileiadis, Senior Member, IEEE

1

2
2
0
2

l
u
J

8

]

C
O
.
h
t
a
m

[

3
v
4
4
3
6
0
.
0
1
0
2
:
v
i
X
r
a

Abstract—Bilevel programming can be used to formulate
many problems in the ﬁeld of power systems, such as strategic
bidding. However, common reformulations of bilevel problems
to mixed-integer linear programs make solving such problems
hard, which impedes their implementation in real-life. In this
paper, we signiﬁcantly improve solution speed and tractability
by introducing decision trees to learn the active constraints of
the lower-level problem, while avoiding to introduce binaries and
big-M constants. The application of machine learning reduces the
online solving time, by moving the selection of active constraints
to an ofﬂine process, and becomes particularly beneﬁcial when
the same problem has to be solved multiple times. We apply
our approach to the strategic bidding of generators in electricity
markets, where generators solve the same problem many times
for varying load demand or renewable production. Three meth-
ods are developed and applied to the problem of a strategic
generator, with a DCOPF in the lower-level. These methods are
heuristic and as so, do not provide guarantees of optimality or
solution quality. Yet, we show that for networks of varying sizes,
the computational burden is signiﬁcantly reduced, while we also
manage to ﬁnd solutions for strategic bidding problems that were
previously intractable.

Index Terms—Bilevel programming, Stackelberg games, clas-
siﬁer, active set, mixed-integer linear programming (MILP),
strategic bidding

I. INTRODUCTION

Bilevel problems were formulated for the ﬁrst time in 1934
by H.v. Stackelberg [1]. Since then, they have been widely
used in economics and game theory, in particular to model
strategic behaviors. One issue is that these problems are NP-
hard to solve [1], [2]. Linear bilevel problems can easily be
reformulated as one-level problems, but the introduction of
binary variables renders these reformulations intractable for
large systems [3]. In power systems, bilevel problems can
be used to model the behavior of a price-maker in electric-
ity markets, to evaluate investment in production facilities,
to model the best transmission network investments [4], to
evaluate the vulnerability of power systems to deliberate [5]
or unintentional [6] outages, and more recently for demand
response management by tariff design in a smart grid setup [7].
Due to the size of the networks, the tractability of bilevel
problems is critical for these applications.

The approach used here derives from the active-set strat-
egy [8]. The lower-level problem is replaced with its active
constraints in a one-level reformulation, avoiding the use of

E. Prat and S. Chatzivasileiadis are with the Department of Electrical
Engineering, Technical University of Denmark, 2800 Kgs. Lyngby, Denmark
e-mail: {emapr, spchatz}@elektro.dtu.dk.

This work is supported by the H2020 European Project FLEXGRID, Grant
Agreement No. 863876 and by the ERC Starting Grant VeriPhIED, Grant
Agreement No. 949899

binary variables and thus obtaining a more tractable version of
the bilevel problem. However, there can be multiple possible
sets of active constraints to consider, depending on the value
of the variables of the upper-level problem. To avoid having
to identify the possible active sets at every run of a model,
machine learning techniques can be used. This is particularly
interesting for power systems applications in which similar
calculations have to be carried out very often with only a few
parameters changing, especially in problems related to bidding
in the electricity markets.

In this paper, we study the problem of a strategic generator
optimizing its bids on the day-ahead market, with the market
modelled by a DC Optimal Power Flow (DCOPF). This
problem has been largely studied. It has been formulated for
different types of generators, including virtual power plants [9]
or a retailer considering demand response [10]. Different set-
ups have been considered, such as stochastic ones [11], multi-
period, with non-convex operating constraints [12] or incom-
plete information [13]. The problem of strategic bidding in
different markets at once has also been studied [14]. However
the size of the test cases remains small due to the complexity
of solving bilevel problems.

Machine learning has already been used to learn the active
constraints of a DCOPF problem with promising results [15]–
[17]. In [18], a similar approach is considered, except that the
active constraints are not learned directly. Instead, they are
derived from the gradient of the cost with respect to the loads;
the gradient is itself the output of a Neural Network classiﬁer.
In [19], machine learning is used to identify redundant con-
straints and simplify the security-constrained unit commitment
problem. Contrary to these problems, the bilevel problems we
consider in this paper have two distinct characteristics. Besides
being effectively formulated as MILPs – and not LPs as most
of the problems considered above – their main challenge is
that the decision variables of the upper-level problem shall not
intervene with the active set classiﬁcation process of the lower
level problem, although the upper-level decision variables are
indeed parameters of the lower-level problem. To the best of
our knowledge, this is the ﬁrst paper that introduces machine
learning techniques to boost the runtime and solution quality
of problems with such features.

Looking at the literature for approaches related to a more
efﬁcient solving of linear bilevel problems, several directions
have been explored, such as genetic algorithms [20] and
evolutionary algorithms [21], [22]. In [23], regularization
approaches are combined with mixed-integer reformulation, by
ﬁrst ﬁnding a local optimal solution to provide initial values of
the binary variables, which reduces the computational burden.
In [24], the problem is reformulated as a one-level problem,

 
 
 
 
 
 
using the dual of the lower-level problem, and decomposition
is used for solving it. In these regards, and as shown by
the results obtained in this paper, the application of machine
learning techniques is a most promising new approach.

This paper has the following contributions:
• We introduce three methods, with some of them being
highly parallelizable, that boost the runtime and solution
quality of bilevel problems.

• Using Decision Trees, we move the selection of the active
set of the lower-level problem to an ofﬂine process. We
eliminate the binary variables, and solve instead a single
or a small number of LPs.

• We apply our methods to the problem of the strategic
bidding of a generator in the electricity market, and
demonstrate their performance to power systems of vary-
ing size and complexity, up to 2’869 buses.

• We compare our methods with the most promising ex-
isting techniques for solving bilevel programs, such as
the Big-M method and the penalty alternating direction
method (PADM) introduced in [24]. We show that our
methods are 6-24 times faster while achieving good
solution quality, comparable with existing methods, even
though our methods do not provide guarantees in these
regards, similar to other existing heuristic to solve these
non-convex problems. More importantly, our methods are
shown to retrieve good solutions to problems that existing
methods ﬁnd intractable.

The rest of this paper is organized as follows: Section II
introduces bilevel problems as well as the example considered
in the rest of the paper with its reformulation as a mixed-
integer linear problem (MILP). Section III describes the meth-
ods proposed. The application of the methods to test systems
is given in Section IV, and Section V concludes the paper.

II. SOLVING BILEVEL PROBLEMS

A. Formulation of KKTs and linearization

Bilevel problems are optimization problems in which con-
straints are in part deﬁned by another optimization problem.
One common example in the ﬁelds of economics and game
theory is Stackelberg games, in which one player, the leader,
anticipates the decision of the other agents, or followers, and
decides on its strategy accordingly. They can be formulated
as:

min
x,y,λ,µ

F (x, y, λ, µ)

s.t. H(x, y, λ, µ) = 0
G(x, y, λ, µ) ≤ 0
min
y
s.t.

f (x, y)

h(x, y) = 0 (λ)
g(x, y) ≤ 0 (µ)

(1a)

(1b)
(1c)
(1d)

(1e)
(1f)

where x ∈ Rn and y ∈ Rm. Equations (1d) to (1f) describe
the embedded problem, referred to as lower-level or follower
problem. The lower-level objective function is f (x, y), and
h(x, y) and g(x, y) are the lower-level constraints. The dual
variables associated with these equality and inequality con-
straints respectively are λ and µ. F (x, y) is the objective
function of the global problem, called upper-level or leader

2

problem. H(x, y) and G(x, y) are the upper-level constraints.
The variables collected in x are decision variables to the upper-
level problem and parameters in the lower-level problem. On
the other hand, y stands for the decision variables of the lower-
level problem.

The problem is non-linear and intractable, due to Equa-
tion (1d). In order to be solved, it can be reformulated as
a one-level problem. The most common approach, under the
condition that the lower-level problem is convex and regular, is
to replace it with its Karush–Kuhn–Tucker conditions (KKTs).
The following problem is obtained:

min
x,y,λ,µ

F (x, y, λ, µ)

s.t. H(x, y, λ, µ) = 0
G(x, y, λ, µ) ≤ 0
∇yL(x, y, λ, µ) = ∇yf (x, y) + λT ∇yh(x, y)
+µT ∇yg(x, y) = 0

h(x, y) = 0
0 ≤ µ ⊥ −g(x, y) ≥ 0

(2a)

(2b)
(2c)

(2d)

(2e)
(2f)

where ∇yL(x, y, λ, µ) represents the Lagrangian derivatives
with regard to the components of the vector y.

The complementarity constraints associated with the in-
equality constraints of the lower-level problem (Equation (2f))
are non-linear but several techniques exist to linearize them,
such as the Fortuny-Amat–McCarl linearization, which will
be detailed here. It introduces binary variables, thus trans-
forming the problem into a Mixed Integer Problem (MIP).
Equation (2f) can be replaced by:

0 ≤ −g(x, y) ≤ M u
0 ≤ µ ≤ M (1 − u)

(3a)
(3b)

where M is a large enough constant and u is a binary variable.
The selection of M is an important issue, which will be
discussed in the case studies, in Section IV.

If the lower-level problem is linear and the objective func-
tion and constraints of the upper-level problem are linear too,
the reformulated problem is a MILP and can generally be
solved. However, when the number of inequality constraints
in the lower-level problem is large, the number of binaries
introduced by this reformulation will be high and the problem
often becomes intractable. The focus of this paper is, thus,
to eliminate these binary variables in order to signiﬁcantly
decrease the solving time and to enable solving problems that
were intractable before.

B. Strategic Generator as a MILP

In the rest of this paper, the methods proposed will be
applied to one particular instance of bilevel problem which
formulates the decision-making of a strategic producer aiming
at determining its bids on the day-ahead market, in order to
maximize its proﬁt. The lower-level problem is the day-ahead
market clearing formulated as a DCOPF:

min
P g,θ

cSP g

i=1 +

ciP g
i

(cid:88)

i(cid:54)=1

s.t. P g

i − P d

i −

(cid:88)

l,i∈l

Bl∆θl = 0,

∀i

(αi)

(4a)

(4b)

≤ P g

i ≤ P g,max
l ≤ Bl∆θl ≤ f max

P g,min
i
− f max
θi=ref = 0 (γ)

,

i

l

,

∀i

(φmin
i
∀l

, φmax
i
(ρmin
l

)
, ρmax
l

)

(4c)

(4d)
(4e)

the generators in the system P g
i

where i ∈ I, represents the bus of the system studied
and l ∈ L,
the lines connecting the bus of this system.
The decision variables of the DCOPF are the power output
(i ∈ I) and the
of all
voltage angles at the bus θi (i ∈ I). ∆θl is a notation to
represent the voltage angle difference between the origin bus
(i = froml) and the destination bus (i = tol) of line l, namely,
∆θl = θi=froml −θi=tol . Without loss of generality, we consider
that there is only one generator per bus and that the strategic
generator is placed in bus i = 1. The slack bus is identiﬁed as
i = ref. It might or might not be the bus where the strategic
generator is located. The price bid of the strategic generator
cS is an upper-level decision and a parameter to the DCOPF.
The objective is to minimize the total cost of the system. The
actual production cost of generator i is given by ci. Apart from
the strategic generator which bids at the cost cS, all the other
generators are assumed to bid their true cost. Equation (4b) is
the power balance at bus i, Bl being the susceptance of line l
and P d
i the demand at bus i. Equation (4c) gives the operating
limits for the generator at bus i in terms of minimum P g,min
and maximum P g,max
. Equation (4d) gives the limits of the
power ﬂow in line l, bounded by the line constraint f max
.
Finally, the angle of the slack bus θi=ref is set to 0. The dual
variables of Equations (4b) to (4e) are given in parentheses
next to each equation, and will be used to formulate the KKTs
of the lower-level problem.

i

i

l

The bilevel problem for the strategic generator can be

formulated as:

min
cS,P g,θ,αi=1
s.t.

ci=1P g

i=1 − αi=1P g

i=1

ci=1 ≤ cS ≤ cS,max
(4a) − (4e)

(5a)

(5b)
(5c)

The upper-level problem objective (5a) is the maximization
of proﬁt for the strategic generator, as the difference between
its operating cost ci=1 and the price received, given by the
dual variable of the power balance in bus 1, αi=1. The proﬁt
is here expressed in the minimization form (standard form).
Equation (5b) belongs to the upper-level problem and sets
limits to the cost of the strategic generator to ensure that the
problem is bounded. The minimum is equal to the real cost
of production ci=1 and the maximum is cS,max.

The objective function in Equation (5a) is not linear because
of the term αi=1P g
i=1. However it can be linearized, as shown
in [4]. This together with the KKTs and Fortuny-Amat–
McCarl linearization gives the following MILP:

ci − αi − φmin

i + φmax

i = 0 ∀i (cid:54)= 1

(cid:88)

Bl(αi − αi=tol − ρmin

l + ρmax

l

3

(6f)

)

l,i=froml
(cid:88)

+

l,i=tol

(cid:88)

Bl(αi − αi=froml + ρmin

l − ρmax

l

) = 0, ∀i (cid:54)= ref

Bl(αi=ref − αi=tol − ρmin

l + ρmax

l

(6g)

)

l,ref=froml
(cid:88)

+

l,ref=tol

Bl(αi=ref − αi=tol + ρmin

l − ρmax

l

, ∀i

, ∀i

i

≤ M umin

i
i ≤ M umax
i

0 ≤ P g
i − P g,min
i
0 ≤ φmin
i ≤ M (1 − umin
), ∀i
0 ≤ P g,max
− P g
i
i
i ≤ M (1 − umax
0 ≤ φmax
), ∀i
l + Bl∆θl ≤ M ymin
0 ≤ f max
l
l ≤ M (1 − ymin
0 ≤ ρmin
), ∀l
l − Bl∆θl ≤ M ymax
0 ≤ f max
0 ≤ ρmax
l ≤ M (1 − ymax
, umax
umin
i
i

), ∀l
l ∈ {0, 1}

, ymin
l

, ymax

l

l

l

, ∀l

, ∀l

) + γ = 0 (6h)

(6i)

(6j)

(6k)
(6l)

(6m)

(6n)
(6o)
(6p)

(6q)

l

i

, ymin
l

, umax
i

(i ∈ I,

where umin

and ymax
l ∈ L) are
the binary variables introduced by Fortuny-Amat McCarl
linearization, and M is a large enough constant. Equa-
tions (6c) and (6d) are the equalities of the lower-level
problem. Equations (6e) to (6h) are obtained by setting to zero
the derivatives of the Lagragian of the lower-level problem
with regard to all the variables. Equations (6i) to (6q) are
the linearized complementarity constraints. They contain and
replace the inequality constraints in Equations (4c) and (4d).
Solving Equations (6a) to (6q) directly will be used as a

baseline for the case studies in Section IV.

III. METHODS
The reformulation proposed here is based on the model
given in II-B, and aims at only keeping the constraints that
are active at the optimal point. In the case of a linear problem,
those are sufﬁcient to describe the system at optimality. We
have established three methods to achieve this. The process
for each of these methods is illustrated in Figure 1. They
follow the same general structure. First, as part of an ofﬂine
process, a database is built, mapping the variables of the lower-
level problem to the corresponding active constraints. This is
described in Section III-A2. This database is used to train
a decision tree (DT), as explained in Section III-A3. For a
given value of the parameters, this DT allows to retrieve sets
of active constraints, in order to build and solve a reduced
bilevel problem. This process is detailed in Section III-B. A
summary of the learning process for the three methods is given
in Table I. Finally, a preliminary discussion is available in
Section III-C.

min
cS,P g,θ,α,
ρ,φ,γ,u,y

(cid:88)

i(cid:54)=1

(ciP g

i + φmax

i P g,max

i

− φmin

i P g,min

i

− αiP d
i )

+ ci=1P g

i=1 +

(cid:88)

f max
l

(ρmin

l + ρmax

l

s.t.

l
ci=1 ≤ cS ≤ cS, max
P g
i − P d
i −

(cid:88)

Bl∆θl = 0, ∀i

l,i∈l

θi=ref = 0
cS − αi=1 − φmin

i=1 + φmax

i=1 = 0

)

TABLE I
COMPARISON OF THE THREE METHODS INTRODUCED, IN TERMS OF
DATABASE, DT AND REDUCED BILEVEL PROBLEM

Method

VarLower

AllSets

BestSet

Database
Features
Load and cS

Load

Load

Target
Set of active
constraints
Set of sets of
active constraints
Set of active
constraints

Final DT(s)
DT(s)

Features

nV

1

1

Load

Load

Load

Target
Set of active
constraints
Set of nA sets of
active constraints
Set of active
constraints

Online
LP(s)

nV

nA

1

(6a)

(6b)

(6c)

(6d)

(6e)

4

For many values of load and cS

Varying
parameters:
load

Upper-level
variables:
cS

Lower-level:
DCOPF

Set of active
constraints

DT training:
(load, cS) →
active constraints

Database

Critical
values of cS

DTs training:
(load) → active
constraints

DT 1:
(load) → active
constraints

DT 2:
(load) → active
constraints

...

DT nV:
(load) → active
constraints

(a) VarLower

DT 1

Active
set 1

Reduced
bilevel 1

Actual value
of the
parameters:
Load

DT 2

Active
set 2

Reduced
bilevel 2

...

...

...

Optimal
solution
cS*

DT nV

Active
set nV

Reduced
bilevel nV

For many values of load

Varying
parameters:
load

cS
1

cS
2
...

cS
n

Lower-level:
DCOPF

Lower-level:
DCOPF
...

Lower-level:
DCOPF

Set of sets
Set of active
constraints 1

Set of active
constraints 2
...

Set of active
constraints nA

For many values of load

Varying
parameters:
load

cS
1

cS
2
...

cS
n

Lower-level:
DCOPF

Lower-level:
DCOPF
...

Lower-level:
DCOPF

Selection of
the best
value of cS

Set of active
constraints

Database

DT training:
(load) →
set of sets

DT:
(load) →
set of sets

Actual value
of the
parameters:
Load

DT

(b) AllSets

Active
set 1

Reduced
bilevel 1

Active
set 2
...

Active
set nA

Reduced
bilevel 2
...

Reduced
bilevel nA

Optimal
solution
cS*

Database

DT training:
(load) → active
constraints

DT:
(load) → active
constraints

Actual value
of the
parameters:
Load

DT

Set of active
constraints

Reduced
bilevel

Optimal
solution
cS*

Fig. 1. Description of the three methods introduced in this paper. The grayed area on the left contains the ofﬂine part of the method, while the online part
is represented in the right part. The step “DT training” also includes testing of the decision tree.

(c) BestSet

A. Database Generation and Learning

The general idea is to reduce the lower-level problem to its
active constraints, which will eliminate the binaries introduced
by the linearization of the complementarity constraints. The
optimal solution will be different for different values of the
input parameters (such as the loads in the case of the strategic
generator problem) and so will the active constraints. As a
consequence, the identiﬁcation of these active constraints must
be carried out for each new value of the input parameters. This
can be tedious as the variables of the upper-level problem are
also parameters to the lower-level problem. So, in order to
consider all possible reductions of the lower-level problem,
multiple setups would have to be tested, even when the
parameters are known. In the context of power systems, this
is particularly critical as decisions have to be made very
often and the parameters vary and are uncertain, especially
demand and renewable energy generation. To avoid a long
decision process, the idea is to move the selection of the
active constraints to an ofﬂine process, using machine learn-
ing classiﬁcation techniques. In this paper, DTs are used to
perform this classiﬁcation. Our approach can also be adapted
to other machine learning classiﬁcation approaches, such as
Neural Networks or Random Forests (see e.g. [25] about how
we can use an exact transformation of Neural Networks to a
MILP for power system problems). Here, we focus on DTs
because they are easier to interpret [26]. For this reason, they

have a larger acceptance in the industry, which we think is
crucial for the deployment of those methods in actual practice.
The challenge is to remove the decision variables of the upper-
level problem from the classiﬁer, unless the DT is included
in the optimization problem as in [27]. This option has been
considered but discarded as it would introduce unnecessary
binary variables and additional constraints, while preventing
the removal of constraints. The three methods detailed in the
following offer three different ways to exclude the decision
variables of the upper-level problem from the classiﬁcation.
Solving the MILP reformulation for each possible active set
of lower-level problem could be a way of proceeding. But
while this works well for a small number of active sets, it
becomes highly inefﬁcient when there are too many. On the
other hand, for a system that has few active sets in the lower-
level, it will be more suitable to directly solve the MILP for
each of the sets than to use the DT approach.

1) Identiﬁcation of the Active Constraints: The focus here
is on the lower-level optimization problem. In optimization
problems, if the feasible set is convex and variables are contin-
uous, the optimal solution lies at the boundaries of the feasible
space. In particular, this is the case for a linear problem (LP),
as considered here. The corresponding constraints are binding,
and the other constraints are inactive. The active set
that
corresponds to the optimal solution regroups the constraints
that are satisﬁed with equality at the optimal point. If the

problem is reformulated following this set, by replacing the
active inequality constraints with equalities and removing the
other constraints, it will recover the optimal solution. This
reduced problem is easier to solve since some constraints are
dropped.

The active constraints of an LP can partially be identiﬁed
by looking at the value of the dual variables associated with
the inequalities of the problem, at the optimal point (equality
constraints are always binding). All dual variables that are non-
zero indicate an active constraint. However, a dual variable
equal to zero might also indicate an active constraint. It is
then necessary to check the activation by looking at the value
of the constraint at the optimal point.

2) Database Building Process: In order to train the DT
classiﬁer, a database of points has to be built. The way this
database is generated is different in each method we propose
but the general idea is the same: the DT should take the load
at every bus as input and return one or several active sets.
We need to ensure that the database generated gives a good
representation of the possible active sets. To achieve this, the
algorithm DiscoverMass, as presented in [16], is applied as a
stopping criterion. The idea is to keep generating points from a
given distribution, until a sufﬁcient share of the possible active
sets have been recovered; that is, until the probability mass of
the discovered sets reaches a chosen threshold. A safety limit
to the number of steps of the algorithm is also deﬁned, in case
it would not converge fast enough. The interested reader can
refer to [16] for details on the algorithms and the theorems
and proofs associated, in particular regarding termination.

a) Method VarLower:

In this method, shown in Fig-
ure 1a, the generated point consists of the varying parameters
of the lower-level and the variables of the upper-level problem
that are parameters to the lower-level problem. In the selected
example, that would be the all the bus loads, collected in a
load vector, along with the cost bid of the strategic generator.
For the randomly generated point, the lower-level problem
(DCOPF) is run and the set of active constraints at the optimal
point is retrieved.

b) Method AllSets: As illustrated in Figure 1b,
the
database in this method associates for a given load vector all
observed sets of active constraints obtained by varying the cost
bid of the strategic generator. For each randomly created load
vector, multiple instances of the DCOPF are solved for a range
of cS values. For each value of cS, an active set is retrieved.
All these active sets are gathered in a set of active sets to be
associated with this load in the database.

c) Method BestSet: This works similarly to the previous
method, as shown in Figure 1c: for a given load vector, the
DCOPF is solved for a range of cS values. In this case,
however, only the active set corresponding to the value of cS
that returns the best value of the upper-level objective function
is kept to be part of the database. The intention here is to
keep only the active sets corresponding to optimal points of
the bilevel problem.

3) Decision Tree Training: Once the database is created,
a DT is trained in order to later predict, for any given value
of the parameters of the lower-level problem, the set of active
constraints to apply. A decision tree is a classiﬁer that keeps
splitting the data according to one of the features of the input
until reaching a separation per class. It consists of nodes,
which represent decisions made based on a given feature,

5

branches, and leaves, which are the ﬁnal nodes, in which
the class is selected. Figure 2 shows representations of such
decision trees.

a) Method VarLower:

In this method, a ﬁrst DT is
generated from the database, that is from samples consisting
of load vector and cS values. However, cS should not be an
input parameter to the ﬁnal DT, which will be applied outside
and before the bilevel problem is solved. As a consequence,
all the nodes in which the feature is cS are retrieved and the
corresponding critical values of cS are extracted, as shown
in Figure 2. The database is then split following the identiﬁed
intervals of cS. Then, for each of these intervals, a DT is built,
taking as input the load vector and returning an active set.
Online, each of these sub-decision trees will be applied, thus
returning as many active sets as there are sub-decision trees.
This whole process is illustrated in Figure 2.

b) Method AllSets: For the method AllSets, the database
is already built for the load vector only, so a single DT is built,
taking as input the load vector and returning a set of active
sets.

c) Method BestSet: Similarly to the previous method,
one DT is built with the load vector as input, but this time
only one active set is returned: the one corresponding to the
optimal solution of the bilevel problem.

B. Reduced Bilevel

Once one or more (for method VarLower) DTs have been
trained ofﬂine, they can be applied online to predict the active
set corresponding to a given load vector. The lower-level
problem is then reduced to keep the active constraints only,
replacing them with equalities. This reformulation is applied
to the inequalities (3a) and (3b) in the MILP formulation. For
each inequality of the original lower-level problem:

• If it is considered as active, it is replaced with equality
and the corresponding complementarity constraint is dis-
carded, as well as the constraints on the dual variables,
since they are inactive. In the general formulation of
the bilevel program, for g active, we would replace
Equations (3a) and (3b) with:

g(x, y) = 0

(7)

• If it is considered as inactive, the inequality is dropped
and the corresponding dual variable is set to be equal to
0. In the general formulation of the bilevel program, for g
inactive, we would replace Equations (3a) and (3b) with:

µ = 0

(8)

As a consequence, the binary variables are completely re-
moved from the formulation and the bilevel problem is now
an LP. Inequality constraints are also removed.

Note that we still have the equalities (6e) to (6h) associated
with the Lagrangian derivatives in the new formulation. In gen-
eral, for a nondegenerated LP it is possible to simply replace
the lower-level problem with its active constraints, without
having to formulate any Lagrangian, as in [18]. However, the
chosen problem could be degenerated, and moreover, as the
duals of the lower-level problem intervene in the objective
function (6a), this cannot be applied here.

In the cases where several active sets are returned by the
DT(s), several LPs are solved and compared in terms of value
of the objective function, to keep the best one only.

6

Is P d

1 ≤ 7.8 ?

yes

no

For cS ≤ 10

For 10 < cS ≤ 18

Is cS ≤ 10 ?

Is P d

2 ≤ 15 ?

Is P d

1 ≤ 7.8 ?

Is P d

1 ≤ 7.8 ?

For cS > 18

Is P d

1 ≤ 7.8 ?

Set 1

Is P d

1 ≤ 5 ?

Is cS ≤ 18 ?

Set 2

Set 1

Is P d

2 ≤ 15 ?

Is P d

1 ≤ 5 ?

Is P d

2 ≤ 15 ?

Is P d

1 ≤ 5 ?

Is P d

2 ≤ 15 ?

Set 5

Set 6

Set 3

Set 4

Set 3

Set 2

Set 5

Set 6

Set 3

Set 2

Set 5

Set 6

Set 4

Set 2

Fig. 2. Decision tree building process for the method VarLower. A ﬁrst DT is built including load and cS, in order to identify the critical values of cS. This
helps building intervals of cS to split the database and build new decision trees on the load only, one for each interval identiﬁed.

a) Method VarLower:

In the method VarLower, there
are nV decision trees to be applied, one per interval of cS
as illustrated in the online part of Figure 1a. As a result, nV
sets of active constraints are returned. The bilevel problem, re-
formulated as an LP with the corresponding active constraints
only, is solved nV times.

b) Method AllSets: With AllSets, one DT is applied, and
the output is a set of nA active sets. nA different versions of
the reduced bilevel are solved and the best result is identiﬁed.
This is shown in the online part of Figure 1b.

c) Method BestSet: In the method BestSet, one DT is
applied, returning one active set. Only one reduced bilevel
problem is solved in this case.

C. Short Discussion

The methods introduced are based on the constraints of
the problem at hand. In case of network reconﬁguration, the
learning process has to be applied again. An evolution of these
methods would introduce a more ﬂexible setup, similarly to
the Graph Neural Network approach followed in [28].

In bilevel problems, it is possible that multiple values of
the upper-level variable could be optimal. In this case, one
must decide between following an optimistic or a pessimistic
approach [2]. Here, we consider an optimistic setup:
the
cost chosen by the generator in the set of possible optimal
values does not have an impact on the outcome. However,
it could be the case that
the strategic generator wants to
reduce the risk by bidding the smallest cost in that interval, to
ensure being dispatched. In this case, the pessimistic modeling
approach would be applied. As the pessimistic approach is not
compatible with the KKTs reformulation, our methods could
not be used directly. Further research would be necessary on
this topic.

In general, the methods introduced can easily be applied
to other linear bilevel problems with a unique upper-level
decision variable, in an optimistic setup.

IV. CASE STUDIES
In this section, the three methods will be applied to 5
different test cases, and will be compared with solving the
bilevel problem with the KKTs and big-M reformulation as
well as with the penalty alternating direction method (PADM)
introduced in [24]. The systems are based on Matpower
cases [29]. The details of the cases are given in Table II. The
exact data ﬁles used are available online [30]. All simulations
were carried out in Python using Gurobi to solve the opti-
mization problems and Python library scikit-learn to build and
apply the decision trees. The code accompanying this paper is
also available online [31].

A. Baseline Methods

1) KKTs and Big-M: As mentioned in Section II, the ﬁrst
baseline method used for comparison is obtained by directly
solving the MILP in Equations (6a) to (6q). Two versions of
this method are implemented. In the ﬁrst one, later referred as
BigM Long, the method is left running as long as necessary
for it to complete the calculations, within the limit of 15
minutes. This limit needs to be set because the method is
tested for 5’000 scenarios and in the situation where we have
many intractable instances, it would not be possible to obtain
results in a reasonable amount of time. Moreover, in the case
of a strategic generator preparing its bids for the day-ahead
market, obtaining an output for each hourly bid within 15
minutes or less would probably be a requirement. In the cases
where the runtime limit is reached, the latest feasible solution
obtained by the MILP solver is returned, if it is available. The
second version of this method will be called BigM Short. In
this version, the ﬁrst feasible solution obtained by the MILP
solver is returned and the execution stops.

The choice of M is an important factor to take into
consideration [32], [33]. Too small, it can interfere with the
physics of the model, too big it can lead to numerical ill-
conditioning. Here we take advantage of the database gener-
ation to set M . First, two constants are deﬁned: Mp for the
primal constraints and Md for the dual variables. The choice of
Mp is straightforward as it is linked with the existing bounds
on the primal variables. However, the choice of Md is not
straightforward as it is complicated to evaluate and bound
the dual variables. When solving the DCOPF in the database
creation process, the maximum values of the dual variables are
retrieved and stored to be later assigned to Md in the solving
process. In order to have some safety margin, we used 10
times these maximum values both for Mp and Md.

2) PADM: A promising method from the literature, the
PADM introduced in [24], is also used to compare with our
method. As the problem of the strategic generator is not of the
form used in this work, we had to adjust the PADM method
in order to use it for our problem, as we detail in [34]. Here

TABLE II
CHARACTERISTICS OF THE TEST CASES CHOSEN

Test case

9-bus
39-bus
89-bus
1354-bus
2869-bus

Load interval
around default
value
[50%, 150%]
[75%, 125%]
[90%, 110%]
[75%, 100%]
[75%, 100%]

VarLower

AllSets

Best Set

DB

Sets

DB

Sets

DB

Sets

13263
13896
17133
19011
29649

4
18
42
82
282

13273
13277
18030
21190
29703

2
13
52
166
367

13265
13350
13565
14204
18889

3
11
19
36
81

7

well. Figure 3 illustrates this. The DTs performance improves
signiﬁcantly with this addition as shown in Table III. It has,
however, almost no effect on the big 2869-bus system. To build
and evaluate the DTs, the database is randomly separated into
training and testing sets, with 70% of the samples kept for
training. The performance is evaluated by the achieved DT
accuracy on the test set, which measures the percentage of
the test samples that are correctly classiﬁed. A randomized
search is performed in order to select the hyperparameters that
maximize the DT accuracy while avoiding overﬁtting.

Note that in Table III, we see that even with total load as a
feature, the accuracy of the DT can be low for the largest test
cases. This will be further explained below in Section IV-C4
along with a way to overcome this. Moreover, we see in this
table that the accuracy of the DTs for the 1354-bus system is
worse than for the 2869-bus system. To understand why, we
must look at the representation of each class in the database.
In the case of the method AllSets, for the 2869-bus system,
the most represented class covers 64% of the points in the
database and the 3 most represented classes cover 90% of the
points in the database. For the 1354-bus system, these numbers
drop to 12% and 32% respectively. So not only is it harder
for the DT to classify the data, but it is also more likely to be
wrong for the 1354-bus system than for the 2869-bus system.

again, two versions are implemented. In the ﬁrst one, PADM
Long, the method runs until convergence, within the same
limit of 15 minutes. In PADM Short, the method runs for the
same duration as the method AllSets, completing the ongoing
iteration when the time limit is reached, and the latest values
for the variables is kept.

With the PADM too, there are parameters to be determined,
which impact the solution efﬁciency. Those are the initial value
of the penalty η0 and the penalty increment ηstep. We observed
that if η0 is too small, the method can converge to a solution
that is not feasible for the original problem. The value of ηstep
can have a big impact on the number of iterations and if chosen
too big, it can impede convergence. The values ﬁnally chosen
were determined by trial-and-error. These are η0 = 1 and
ηstep = 0.1 for 9, 39 and 89-bus systems and ηstep = 1 for
1354 and 2869-bus systems.

B. Modeling Parameters

a) Databases generation: The parameters used in Dis-
coverMass algorithm for the database generation are the ones
suggested in [16]. The resulting number of points in the
databases is given in Table II. As the number of active sets
varies depending on the method (one with BestSet, nA with
AllSets and nV with VarLower in Figure 1), so does the number
of points for a given system. The loads applied are selected
randomly with equal probability, and independently for each
bus, in an interval [(1 − xm)P d
is
the default load (from the test case data) and xm and xp are
the percentages of sample range under and above the default
load, respectively. All the points which are infeasible for the
DCOPF are not included the database. The maximum value
of cS, as deﬁned in Section II, is chosen as:

i ], where P d
i

i ,(1 + xp)P d

cS,max = 10 × max{ci, i ∈ I}

(9)

where max{ci, i ∈ I} is the cost of the most expensive
generator in the system. This way we avoid the situation where
cS is unbounded, while ensuring that the chosen bound will not
impact the resulting dispatch. For methods AllSets and BestSet,
each sample of load was tested with 10 values of cS, between
c1 and cS,max. Note that the choice of values for cS can be
crucial because of the inﬂuence they have on which constraints
are active. Here, we take a simpliﬁed approach and divide the
interval of cost in ten. It could be reﬁned by selecting the
cS values equal to the costs of the other generators, as we
observe that those are values for which the active constraints
can change. However, a trade-off must be made between the
selection of critical values and the size of the database. The
generation of the database is something to be improved in
future work. Such a study should also focus on the balance of
the database and on the representation of each class, both in
the training and testing sets. Here, the scenarios are generated
artiﬁcially because there is no existing database of operating
points. For a real system, it would be possible to learn from
observed data.

b) Decision Trees building: When building a classiﬁer,
the features of the data used for the training are of great
importance. Here,
the main features are the load at each
bus and the cost bid by the strategic generator (for Method
VarLower only). It was found that adding the total
load
of the system as a feature is very valuable information as

Fig. 3. Importance of the different features in the resulting DT. Example with
39-bus system and VarLower general DT.

c) Models evaluation: In order to assess the performance
of our methods, 5’000 scenarios of feasible load vectors are
randomly generated with a uniform distribution within the
same intervals of values that were used for the database
generation. The reduced LPs are run in parallel. To ensure
feasibility of the solution, we check that the solution of each
reduced LP does not violate any constraint of the initial
problem. The solution maximizing the proﬁt of the strategic
generator is chosen among all feasible solutions.

C. Results

The different methods are compared in terms of runtime

and quality of the solution returned.

1) Runtime: For the analysis of the temporal component,
the performance graph shown in Figure 4 on the left, is built
as described in [35]. This graph shows, for each method,
the cumulative distribution function for the performance ratio
of method s over all instances p. The performance ratio is
denoted by rp,s, and calculated with:

rp,s =

tp,s
min{tp,s : s ∈ S}

(10)

load n3load n4load n7load n8load n15load n16load n20load n21load n23load n24load n25load n27load n28load n29load n39total loadcs0.00.10.20.30.4Features importanceWithout total loadIncluding total loadTABLE III
DECISION TREE TRAINING TIME AND ACCURACY DEPENDING ON THE FEATURES

8

Training duration (min)
AllSets
0.01
0.04
0.10
2.48
16.46

VarLower
0.35
3.74
6.77
43.17
277.46

BestSet
0.01
0.03
0.07
1.56
8.75

Accuracy without total load
AllSets
97.5%
70.3%
72.7%
15.8%
43.5%

VarLower
95.0%
86.0%
87.0%
66.0%
52.6%

BestSet
97.0%
82.0%
78.1%
21.7%
79.0%

With total load as a feature

VarLower

AllSets
BestSet
100.0% 100.0% 100.0%
92.6%
96.0%
96.8%
91.0%
86.4%
91.6%
29.3%
25.6%
75.2%
79.2%
43.7%
52.6%

9-bus
39-bus
89-bus
1354-bus
2869-bus

where S represents all the methods that are considered here. In
case the method hits the runtime limit, the performance ratio
is set to a maximum, rM = 1000 in our case.

From this ﬁgure, we can see that the methods introduced
in this paper manage to return a solution much faster than
all the methods that have been used for comparison. More
information about the running times per method and per test
case is given in Table IV.

Except for the smaller 9-bus system, for which the big-
M method already solves fast, our proposed methods achieve
a computation speedup of 6 to 24 times faster than the
conventional Big-M method on the tractable instances. For the
2869-bus system, the Big-M method often fails to complete
calculation within 15 minutes (which corresponds to a median
around 900s) which gives a considerable advantage to our
methods for such a large system. Note that for PADM Long,
the high mean and low median for the running time indicates
that some instances do not converge in the selected time limit
of 15 minutes.

2) Solution quality: The performance of the different meth-
ods in terms of solution quality has been evaluated by compar-
ing the value of the proﬁt for the strategic generator. Instead of
directly using the value of the upper-level objective function
obtained with the different methods, the proﬁt is calculated
with the nodal price returned when solving the DCOPF with
the ﬁnal value of cS. This is indeed the most accurate way to
estimate this proﬁt. The relative gaps gp,s are then calculated
with:

gp,s =

q∗
p − qp,s
q∗
p

(11)

where qp,s is the proﬁt of the strategic generator for instance
p, with method s, and q∗
p is the lower bound on the MILP
optimal objective function, which is obtained by relaxing the
binary constraints in Problem (6). We check the value of the
now integer but originally binary variables. If they are all close
enough to 0 or 1, we can conclude that the optimal solution
of the relaxed MILP is the solution of the MILP, which is
never the case here. In other words, the solution of the relaxed
MILP is never in the feasible space of the MILP here. For
this reason, we include one more result as an upper bound
on the optimal value of the objective function of the MILP,
which is obtained by solving the DCOPF with the optimal
value of cS in the relaxed MILP. Those two supplementary
comparisons are included with the names Relax MILP and
Relax MILP-DCOPF respectively. The resulting cumulative
distribution function is shown on the right part of Figure 4.
It can be observed that the performance of the three methods
we propose in this paper, in terms of solution value, is close
to the lower-bound obtained with Relax MILP. In particular,
the methods perform much better than BigM Short and PADM

Short. Details on the relative gaps per method and per test
case are given in Table V. This conﬁrms that, when infeasible
instances are disregarded, the solution quality is good with our
methods.

i

− φmax

i + φmin

i P g,min

3) Duality Gap of the Lower-Level Problem: For given
values of the strategic cost cS and of the lower-level primal
and dual optimization variables, the duality gap is calculated
as the difference between the primal and dual objective func-
tions. The value of the dual objective function is given by:
(cid:80)
i P g,max
i(αiP d
).
i
The three methods introduced here are designed in a way
that if a feasible solution is found, the duality gap of the lower-
level problem will always be zero. In other words, if these
methods return a feasible point, it is the optimal solution. The
same applies to the big-M methods, and to the PADM if it
converges. The Relax MILP, on the other hand, can have a
duality gap. For example, for the 1354-bus system, the relative
duality gap is on average 4.0% with Relax MILP and 3.6%
with PADM Short.

l + ρmax

) − (cid:80)

l f max
l

(ρmin

l

4) Limits of the Methods and Improvements: In Table VI,
the number of instances that reach the time limit and the
number of instances that do not return a feasible solution are
given. This conﬁrms that the methods introduced in this paper
have the advantage of avoiding intractability. However, the
reformulation introduced might be infeasible and unable to
return a value for the bidding cost of the strategic generator.
The PADM always yields a value, as, even in the case it is not
converging, an estimation of the strategic cost is made at each
iteration. For the 1354-bus system in particular, PADM Long
fails to converge for most instances but still gives a value for
cS, which appears to be far from the optimal value as show in
Table V.

that

For the complex systems studied (1354-bus and 2869-
bus) the incidence of infeasible occurrences is high. This
derives from the fact
the DTs have a low accuracy.
Figure 5 presents t-SNE plots for the databases with the
method VarLower. The t-SNE technique allows to represent a
high-dimensional set of data in 2 dimensions. It shows points
that are related by clustering them. Ideally, there is a cluster
for each class of the data represented. Further information on
t-SNE can be found in [36]. Here, each class corresponds to a
set of active constraints. However, we cannot identify proper
clusters, which means that the classes of our problem are
very similar. It is then difﬁcult for the classiﬁer to distinguish
how to best separate the data, while avoiding over-ﬁtting.
But similar classes will be classiﬁed in the same area of
the created decision tree. This idea is applied to extract
extra information from the DT and signiﬁcantly increase the
accuracy for these systems. When applying the DT to a given
load, the corresponding leaf is extracted and its parent is
identiﬁed. Then, the classes of all training data samples that

9

(a) Performance proﬁle for the running times. x-axis
represents Eq. (10), and is expressed in logarithmic
scale.

(b) Cumulative distribution function for the relative
gaps. x-axis represents Eq. (11).

Fig. 4. Comparison of the performance of the different methods in terms of running time and relative gap. y-axis represents the share of instances tested.

TABLE IV
RESULTS ON THE RUNNING TIMES PER METHOD AND TEST CASE

PADM Long
PADM Short
BigM Long
BigM Short
VarLower
AllSets
BestSet

9-bus

39-bus

89-bus
Mean (s) Median (s) Mean (s) Median (s) Mean (s) Median (s) Mean (s) Median (s) Mean (s) Median (s)
26.938
8.421
904.743
904.624
4.499
4.934
4.259

52.266
8.422
671.892
666.819
4.494
4.897
4.258

900.541
2.352
24.009
23.112
1.174
1.298
1.184

809.249
2.307
28.687
26.996
1.175
1.3
1.186

3.155
0.088
0.325
0.3
0.046
0.051
0.043

5.814
0.037
0.128
0.097
0.02
0.019
0.018

0.069
0.037
0.13
0.096
0.02
0.019
0.018

0.645
0.088
0.329
0.34
0.046
0.052
0.043

0.019
0.009
0.011
0.011
0.007
0.007
0.006

0.017
0.009
0.011
0.011
0.007
0.007
0.006

2869-bus

1354-bus

TABLE V
RESULTS ON THE RELATIVE GAPS, COMPARING TO THE LOWER BOUND AND EXCLUDING INFEASIBLE INSTANCES

PADM Long
PADM Short
BigM Long
BigM Short
VarLower
AllSets
BestSet

9-bus
Mean Median
11.0%
80.0%
11.0%
11.0%
11.0%
11.0%
11.0%

0.0% 28.7%
83.1% 38.1%
0.0% 28.7%
0.0% 36.2%
0.0% 29.1%
0.0% 30.7%
0.0% 30.1%

89-bus
39-bus
Mean Median
Mean Median
3.2%
3.7%
5.7%
4.6% 65.4%
5.7%
3.2%
11.9% 35.9%
7.3%
8.8%
5.2%

2869-bus
1354-bus
Mean Median
Mean Median
8.4%
8.4%
89.9% 100.0%
89.3%
65.6% 101.2% 100.0% 88.1%
7.4%
9.3%
3.5%
7.6%
4.1% 13.8%
9.3%
14.9% 18.6%
8.4%
48.9% 11.4%
8.4%
8.5%

5.6%
8.7%
29.5%
43.9%
5.7%

3.7%
32.8%
3.7%
3.8%
3.7%

4.3%
6.3%
4.9%

2.9%

would be classiﬁed to the parent node of this leaf are retrieved.
As a result, more LPs are formulated but a good performance
is recovered. The three last rows of Table VI indicate that the
number of infeasible instances decreases signiﬁcantly when
this technique is applied.

For the 2869-bus system, from 64% of intractable cases
with the Big-M method, we manage to reduce them to about
20% of infeasible cases with our methods applied directly and
as low as 0.3% when we extract more information from the
learning process of the DT with our augmented method.

5) Comparison of the three Methods: We have seen that
the three methods introduced have similar performance but
there are some differences that we will develop here. With
the method BestSet, less active sets are identiﬁed, as shown
in Table II. As a consequence, the database is smaller (and
thus faster to build) and it is faster to train the DT, as we
see in Table III. This method gives the best results in terms
of distance to optimality. However, it results more often to an

infeasible model, which is coherent with the fact that only one
LP is solved in that case. With the method VarLower, more
DTs need to be trained, which takes more time. This method
results less often than the others in infeasible instances.
However, it cannot be applied to bilevel problems where there
is more than one decision variable passed on to the lower-level
problem. Finally, with the method AllSets, a lot of sets of sets
of active constraints can be identiﬁed and it is complicated to
ensure that they are all properly represented in the database.
However, since multiple LPs are run, it gives better results
than BestSet in terms of infeasibility.

The choice of one method over another thus depends
on one’s focus. If more interested in retrieving the optimal
solution, BestSet should be prefered. On the other hand, if the
focus is to ﬁnd a feasible solution, VarLower will perform
better. Alternatively, AllSets can be used, especially for other
bilevel problems in which more than one decision variable are
passed on to the lower-level problem.

11010010000.00.20.40.60.81.0VarLowerAllSetsBestSetPADM LongPADM ShortBigM LongBigM Short0.00.20.40.60.81.00.00.20.40.60.81.0VarLowerAllSetsBestSetPADM LongPADM ShortBigM LongBigM ShortRelax MILPRelax MILP - DCOPF10

TABLE VI
RESULTS ON INTRACTABILITY AND INFEASIBILITY

PADM Long
PADM Short
BigM Long
BigM Short
VarLower
AllSets
BestSet
VarLower (augmented)
AllSets (augmented)
BestSet (augmented)

9-bus

39-bus

89-bus

1354-bus

2869-bus

Time limit
0
0
0
0
0
0
0
-
-
-

Infeasible
0
0
0
0
0
0
0
-
-
-

Time limit
31 (0.6%)
0
0
0
0
0
0
-
-
-

Infeasible
0
0
0
0
0
0
239 (4.8%)
-
-
-

Time limit
13 (0.3%)
0
0
0
0
0
0
-
-
-

Infeasible
0
0
0
0
48 (1.0%)
132 (2.6%)
418 (8.4%)
-
-
-

Time limit
4472 (89%)
0
0
0
0
0
0
0
0
0

Infeasible
0
0
0
0
318 (6.4%)
682 (13.6%)
3544 (70.9%)
22 (0.4%)
5 (0.1%)
48 (1.0%)

Time limit
44 (0.9%)
0
3186 (63.7%)
0
0
0
0
0
0
0

Infeasible
0
0
3186 (63.7%)
0
442 (8.8%)
926 (18.5%)
1089 (21.8%)
284 (5.7%)
63 (1.3%)
13 (0.3%)

Fig. 5.

t-SNE plots for the complex cases, on the databases generated for VarLower. Each color corresponds to a possible set of active constraints.

(a) 1354 bus

(b) 2869 bus

V. CONCLUSION

This paper uses machine learning to introduce efﬁcient
approaches that solve linear bilevel problems, boosting their
runtime and solution quality. We propose three methods, some
of them highly parallelizable, that use decision trees to learn
the active sets of the lower-level problem and apply them
to the problem of a strategic generator optimizing its bids
for the electricity market. Linear bilevel problems are most
often converted to Mixed Integer Linear Programs (MILP)
by replacing the lower-level problem with its Karush–Kuhn–
Tucker conditions (KKTs), in order to solve them. Our goal
in this paper is to completely eliminate the use of the binary
variables by learning the active sets and solve a single or a
small number of Linear Programs (LPs) instead.

Contrary to existing machine learning methods for optimiza-
tion, to the best of our knowledge, this is the ﬁrst paper that
considers optimization problems with two distinct characteris-
tics: besides effectively treating MILPs – and not LPs as most
machine learning methods applied on optimization problems
so far – the main challenge is that the decision variables of
the upper-level problem shall not intervene with the active
set classiﬁcation process of the lower-level problem, although
the upper-level decision variables are indeed parameters of the
lower-level problem.

We apply our methods to systems with up to 2’869 buses,
and we compare them with the most promising existing
approaches to solve bilevel problems: the big M reformulation,
which is the most common approach to treat the non-linear
complementarity constraints, and the Penalty Alternating Di-
rection Method (PADM), recently introduced in [24]. Our

methods are shown to be 6 to 24 times faster, while they
maintain very good solution quality, comparable with existing
methods. More importantly, although we observe a trade-
off between the decision tree prediction accuracy and the
computational complexity of the problem (the number of
LPs solved), our methods have been shown to retrieve good
solutions to problems where existing methods, such as the
PADM, fail to converge. At the same time, they also appear to
perform well in large test cases. As a matter of fact, we obtain
the most encouraging results for very large systems, such as
the 2869-bus system, where existing methods fail to return a
solution within 15 minutes for 64% of the test cases. Finally,
an additional considerable advantage of the methods proposed
in this paper is that they do not introduce any parameters in
the online stage, that would have to be appropriately tuned for
a good performance.

As far as power system problems are concerned, considering
that we already use training data that include a wide range
of possible load and generation realizations,
the methods
proposed in this paper can easily accommodate uncertainty
from various sources, and especially renewable generation,
while they can also be extended to a bilevel program with
a stochastic lower-level problem. Future work should focus
on providing guarantees for the accuracy of the Decision
Trees, when it comes to the classiﬁcation of the active sets;
this shall enhance the performance of the proposed methods.
Research is also required to investigate the desirable properties
of the database and how to achieve them, and to extend
the application of such approaches to more complex bilevel
problems.

−75−50−250255075tsne-2d-one−100−75−50−250255075100tsne-2d-two−75−50−250255075100tsne-2d-one−75−50−250255075tsne-2d-twoREFERENCES

[1] S. Dempe, Foundations of Bilevel Programming, ser. Nonconvex Opti-

mization and Its Applications. Springer US, 2006.

[2] B. Colson, P. Marcotte, and G. Savard, “Bilevel programming: A survey,”

4OR, vol. 3, pp. 87–107, 06 2005.

[3] D. Pozo, E. Sauma, and J. Contreras, “Basic theoretical foundations
and insights on bilevel models and their applications to power systems,”
Annals of Operations Research, vol. 254, 07 2017.

[4] S. Gabriel, A. Conejo, J. Fuller, B. Hobbs, and C. Ruiz, Complementarity
Modeling in Energy Markets, ser. International Series in Operations
Research & Management Science. Springer New York, 2012.

[5] J. M. Arroyo and F. D. Galiana, “On the solution of the bilevel program-
ming formulation of the terrorist threat problem,” IEEE Transactions on
Power Systems, vol. 20, no. 2, pp. 789–797, 2005.

[6] J. M. Arroyo, “Bilevel programming applied to power system vulner-
ability analysis under multiple contingencies,” IET Generation, Trans-
mission Distribution, vol. 4, no. 2, pp. 178–190, 2010.

[7] A. Kov´acs, “Bilevel programming approach to demand response man-
agement with day-ahead tariff,” Journal of Modern Power Systems and
Clean Energy, vol. 7, no. 6, pp. 1632–1643, 2019.

[8] M. Fukushima and P. Tseng, “An implementable active-set algorithm
for computing a b-stationary point of a mathematical program with
linear complementarity constraints,” SIAM Journal on Optimization,
vol. 12, no. 3, pp. 724–739, 2002.
[Online]. Available: https:
//doi.org/10.1137/S1052623499363232

[9] M. Shaﬁekhani, A. Badri, M. Shaﬁe-Khah, and J. P. Catal˜ao, “Strategic
bidding of virtual power plant in energy markets: A bi-level multi-
objective approach,” International Journal of Electrical Power & Energy
Systems, vol. 113, pp. 208–219, 2019.

[10] R. Shariﬁ, A. Anvari-Moghaddam, S. H. Fathi, and V. Vahidinasab,
“A bi-level model for strategic bidding of a price-maker retailer with
ﬂexible demands in day-ahead electricity market,” International Journal
of Electrical Power & Energy Systems, vol. 121, p. 106065, 2020.
[11] C. Ruiz and A. J. Conejo, “Pool strategy of a producer with endogenous
formation of locational marginal prices,” IEEE Transactions on Power
Systems, vol. 24, no. 4, pp. 1855–1866, 2009.

[12] Y. Ye, D. Papadaskalopoulos, J. Kazempour, and G. Strbac, “Incorporat-
ing non-convex operating characteristics into bi-level optimization elec-
tricity market models,” IEEE Transactions on Power Systems, vol. 35,
no. 1, pp. 163–176, 2019.

[13] T. Li and M. Shahidehpour, “Strategic bidding of

transmission-
constrained gencos with incomplete information,” IEEE Transactions
on power Systems, vol. 20, no. 1, pp. 437–447, 2005.

[14] T. Rintam¨aki, A. S. Siddiqui, and A. Salo, “Strategic offering of a
ﬂexible producer in day-ahead and intraday power markets,” European
Journal of Operational Research, vol. 284, no. 3, pp. 1136–1153, 2020.
[15] Y. Ng, S. Misra, L. A. Roald, and S. Backhaus, “Statistical learning for
dc optimal power ﬂow,” in 2018 Power Systems Computation Conference
(PSCC).

IEEE, 2018, pp. 1–7.

[16] S. Misra, L. Roald, and Y. Ng, “Learning for constrained opti-
mization: Identifying optimal active constraint sets,” arXiv preprint
arXiv:1802.09639, 2018.

[17] D. Deka and S. Misra, “Learning for dc-opf: Classifying active sets
IEEE, 2019, pp.

using neural nets,” in 2019 IEEE Milan PowerTech.
1–6.

[18] Y. Chen and B. Zhang, “Learning to solve network ﬂow problems via

[19]

neural decoding,” arXiv preprint arXiv:2002.04091, 2020.
´A. S. Xavier, F. Qiu, and S. Ahmed, “Learning to solve large-scale
security-constrained unit commitment problems,” INFORMS Journal on
Computing, 2020.

[20] H. I. Calvete, C. Gal´e, and P. M. Mateo, “A new approach for
solving linear bilevel problems using genetic algorithms,” European
Journal of Operational Research, vol. 188, no. 1, pp. 14 – 28,
2008. [Online]. Available: http://www.sciencedirect.com/science/article/
pii/S0377221707003773

[21] H. Li and L. Fang, “An evolutionary algorithm for solving bilevel pro-
gramming problems using duality conditions,” Mathematical Problems
in Engineering, vol. 2012, 01 2012.

[22] A. Sinha, P. Malo, and K. Deb, “Efﬁcient evolutionary algorithm for

single-objective bilevel optimization,” 2013.

[23] S. Pineda, H. Bylling, and J. Morales, “Efﬁciently solving linear bilevel
programming problems using off-the-shelf optimization software,” Op-
timization and Engineering, vol. 19, no. 1, pp. 187–211, 2018.

[24] T. Kleinert and M. Schmidt, “Computing feasible points of bilevel prob-
lems with a penalty alternating direction method,” INFORMS Journal
on Computing, vol. 33, no. 1, pp. 198–215, 2021.

[25] I. Murzakhanov, A. Venzke, G. S. Misyris, and S. Chatzivasileiadis,
“Neural networks for encoding dynamic security-constrained optimal
power ﬂow,” 2021.

11

[26] E. Carrizosa, B. Mart´ın-Barrag´an, and D. R. Morales, “Detecting rel-
evant variables and interactions in supervised classiﬁcation,” European
Journal of Operational Research, vol. 213, no. 1, pp. 260–269, 2011.

[27] L. Halilbasic, F. Thams, A. Venzke, S. Chatzivasileiadis, and P. Pinson,
“Data-driven security-constrained ac-opf for operations and markets,” in
Proceedings of 20th Power Systems Computation Conference. United
States: IEEE, 2018, 20th Power Systems Computation Conference,
PSCC 2018 ; Conference date: 11-06-2018 Through 15-06-2018.
[Online]. Available: http://www.pscc2018.net/index.html

[28] B. Donon, B. Donnot, I. Guyon, and A. Marot, “Graph neural solver
for power systems,” in 2019 International Joint Conference on Neural
Networks (IJCNN), 2019, pp. 1–8.

[29] R. D. Zimmerman, C. E. Murillo-S´anchez, and R. J. Thomas, “Mat-
power: Steady-state operations, planning, and analysis tools for power
systems research and education,” IEEE Transactions on Power Systems,
vol. 26, no. 1, pp. 12–19, Feb 2011.

[30] “Online

appendix

(datasets),”

https://zenodo.org/record/4081513#

.X4SIvdAzZnI.

[31] “Online

appendix

(code),”

https://github.com/eleaprat/

Bilevel---Active-Constraints.

[32] T. Kleinert, M. Labb´e, F. Plein, and M. Schmidt, “There’s No
Free Lunch: On the Hardness of Choosing a Correct Big-M in
Bilevel Optimization,” Jun. 2019, working paper or preprint. [Online].
Available: https://hal.inria.fr/hal-02106642

[33] S. Pineda and J. M. Morales, “Solving linear bilevel problems using big-
ms: Not all that glitters is gold,” IEEE Transactions on Power Systems,
vol. 34, no. 3, pp. 2469–2471, 2019.

[34] E. Prat and S. Chatzivasileiadis, “Learning active constraints to efﬁ-
ciently solve linear bilevel problems,” arXiv preprint arXiv:2010.06344,
2020.

[35] E. D. Dolan and J. J. Mor´e, “Benchmarking optimization software with
performance proﬁles,” Mathematical programming, vol. 91, no. 2, pp.
201–213, 2002.

[36] L. van der Maaten and G. Hinton, “Visualizing data using t-sne,” Journal
of Machine Learning Research, vol. 9, pp. 2579–2605, 11 2008.

El´ea Prat received her M.S. in sustainable energy
from the Technical University of Denmark (DTU)
in 2017. She worked as a research assistant in the
electrical engineering department of DTU (2019-
2021). She is now doing her Ph.D. in the manage-
ment department of DTU, in operations research.
Her research interests include optimization, elec-
tricity markets, multi-scale decision making, bilevel
programming.

Spyros Chatzivasileiadis (S’04, M’14, SM’18) is
the Head of Section Power Systems and an Associate
Professor at the Technical University of Denmark
(DTU). Before that he was a postdoctoral researcher
at the Massachusetts Institute of Technology (MIT),
USA and at Lawrence Berkeley National Labora-
tory, USA. Spyros holds a PhD from ETH Zurich,
Switzerland (2013) and a Diploma in Electrical and
Computer Engineering from the National Technical
University of Athens (NTUA), Greece (2007). He is
currently working on machine learning applications
for power systems, and on power system optimization, dynamics, and control
of AC and HVDC grids. Spyros is the recipient of an ERC Starting Grant in
2020.

APPENDIX

A. PADM Formulation for the Strategic Generator Problem

1) Dual of Lower-Level Problem: The dual of the lower-

level problem given in Equations (4a) to (4e) is:

3) Penalty Problem: In the previous formulation, the com-

plicating constraint (13m) is relaxed, using the penalty η:
i=1 − αi=1P g

i=1 + η[cSP g

ci=1P g

i=1

min
cS,P g,θ,α,φ,ρ,γ

(cid:88)

+

ciP g

i −

(cid:88)

(P d

i αi + P g,min

i

φmin
i

i(cid:54)=1
− P g,max
i

i

φmax
i

) +

(cid:88)

f max
l

l

s.t.

(13b) − (13l)

(ρmin

l + ρmax

l

)]

(14a)

(14b)

12

)

(12a)

(12b)

(12c)

4) Subproblems: From the penalty problem, subproblems
are formulated and solved alternatively. The ﬁrst is obtained
by ﬁxing the primal variables of lower-level problem:

min
α,φ,ρ,γ

s.t.

(φmax

i P g,max

i

(cid:88)

i

− φmin

i P g,min

i

(cid:88)

) +

f max
l

l

(ρmin

l + ρmax

l

cS − αi=1 − φmin
ci − αi − φmin

i=1 + φmax

1 = 0

i + φmax

i = 0, ∀i (cid:54)= 1
l + ρmax

Bl(αi − αi=tol − ρmin

l

(cid:88)

l,i=froml
(cid:88)

+

l,i=tol

(cid:88)

l,ref=froml
(cid:88)

+

)

min
cS,α,φ,ρ,γ

Bl(αi − αi=froml + ρmin

l − ρmax

l

) = 0, ∀i (cid:54)= ref

Bl(αi=ref − αi=tol − ρmin

l + ρmax

l

(12d)

s.t.

)

Bl(αi=ref − αi=froml + ρmin

l − ρmax

l

) + γ = 0 (12e)

(cid:88)

− α1

i=1 + η[cS ¯Pg
¯Pg

i=1 −

(cid:88)

(P d

i αi + P g,min

i

− P g,max
i

φmax
i

) +

(cid:88)

f max
l

i
l + ρmax
(ρmin

l

)]

l

c1 ≤ cS ≤ cS,max
cS − α1 − φmin
ci − αi − φmin

1 + φmax
i + φmax

1 = 0
i = 0, ∀i (cid:54)= 1
l + ρmax

l

)

Bl(αi − αi=tol − ρmin

φmin
i

(15a)

(15b)

(15c)

(15d)

l,i=froml
(cid:88)

+

l,i=tol

Bl(αi − αi=froml + ρmin

l − ρmax

l

) = 0, ∀i (cid:54)= ref

(15e)

(cid:88)

l,ref=froml
(cid:88)

+

Bl(αref − αi=tol − ρmin

l + ρmax

l

)

Bl(αref − αi=froml + ρmin

l − ρmax

l

l,ref=tol
, φmax
, ρmax

φmin
i
ρmin
l

i ≥ 0, ∀i
l ≥ 0, ∀l

) + γ = 0 (15f)

(15g)

(15h)

The second subproblem is obtained by ﬁxing the variables of
upper-level and the dual variables of lower-level:

min
P g,θ

ci=1P g

i=1 − ¯α1P g

i=1 + η[ ¯cSP g

i=1 +

P g
i − P d

i −

(cid:88)

l,i∈l

Bl∆θl = 0, ∀i

≤ P g

i ≤ P g,max
l ≤ Bl∆θl ≤ f max

i

l

, ∀i

, ∀l

P g,min
i
− f max
θref = 0

ciP g
i ]

(cid:88)

i(cid:54)=1

(16a)

(16b)

(16c)
(16d)
(16e)

l,ref=tol
, φmax
, ρmax

φmin
i
ρmin
l

i ≥ 0, ∀i
l ≥ 0, ∀l

(12f)

(12g)
(12h)

2) Reformulation as one-level problem: Using the dual of
the lower-level problem and the strong-duality theorem, the
bilevel problem in Equations (5a) to (5c) can be reformulated
as a single-level problem:

min
cS,P g,θ,α,φ,ρ,γ

s.t.

ci=1P g

i=1 − αi=1P g

i=1

ci=1 ≤ cS ≤ cS,max
P g
i − P d
i −

(cid:88)

Bl∆θl = 0, ∀i

l,i∈l

, ∀i

i

i ≤ P g,max
l ≤ Bl∆θl ≤ f max

≤ P g

P g,min
i
− f max
θref = 0
cS − αi=1 − φmin
ci − αi − φmin

i + φmax

i=1 + φmax

l

, ∀l

(cid:88)

Bl(αi − αi=tol − ρmin

i=1 = 0
i = 0, ∀i (cid:54)= 1
l + ρmax

l

(13a)

(13b)

(13c)

(13d)
(13e)
(13f)

(13g)

(13h)

)

l,i=froml
(cid:88)

+

l,i=tol

(cid:88)

Bl(αi − αi=froml + ρmin

l − ρmax

l

) = 0, ∀i (cid:54)= ref

Bl(αi=ref − αi=tol − ρmin

l + ρmax

l

(13i)

)

l,ref=froml
(cid:88)

+

l,ref=tol

Bl(αi=ref − αi=froml + ρmin

l − ρmax

l

, φmax
, ρmax

φmin
i
ρmin
l
− cSP g

i ≥ 0, ∀i
l ≥ 0, ∀l
i=1 −

(cid:88)

ciP g

i +

(cid:88)

(P d

i αi + P g,min

i

φmin
i

i(cid:54)=1

− P g,max
i

φmax
i

) −

(cid:88)

f max
l

l

i
(ρmin

l + ρmax

l

) ≥ 0

(13m)

) + γ = 0

(13j)

(13k)

(13l)

