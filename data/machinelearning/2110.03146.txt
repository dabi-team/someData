2
2
0
2

p
e
S
8

]

C
O
.
h
t
a
m

[

2
v
6
4
1
3
0
.
0
1
1
2
:
v
i
X
r
a

Solving Multistage Stochastic Linear Programming via Regularized
Linear Decision Rules: An Application to Hydrothermal Dispatch
Planning

Felipe Nazare and Alexandre Street*

LAMPS PUC-Rio,
Electrical Engineering Department

Pontiﬁcal Catholic University of Rio de Janeiro1

Abstract

The solution of multistage stochastic linear problems (MSLP) represents a challenge for many

applications. Long-term hydrothermal dispatch planning (LHDP) materializes this challenge in a

real-world problem that aﬀects electricity markets, economies, and natural resources worldwide.

No closed-form solutions are available for MSLP and the deﬁnition of non-anticipative policies

with high-quality out-of-sample performance of is crucial. Linear decision rules (LDR) provide an

interesting simulation-based framework for ﬁnding high-quality policies to MSLP through two-stage

stochastic models. In practical applications, however, the number of parameters to be estimated

when using an LDR may be close or higher than the number of scenarios of the sample average

approximation problem, thereby generating an in-sample overﬁt and poor performances in out-of-

sample simulations. In this paper, we propose a novel regularized LDR to solve MSLP based on

the AdaLASSO (adaptive least absolute shrinkage and selection operator). The goal is to use the

parsimony principle as largely studied in high-dimensional linear regression models to obtain better

out-of-sample performance for a LDR applied to MSLP. Computational experiments show that the

overﬁt threat is non-negligible when using the classical non-regularized LDR to solve the LHDP,

one of the most studied MSLP with relevant applications in industry. Our analysis highlights the

following beneﬁts of the proposed framework in comparison to the non-regularized benchmark: 1)

signiﬁcant reductions in the number of non-zero coeﬃcients (model parsimony), 2) substantial cost

reductions in out-of-sample evaluations, and 3) improved spot-price proﬁles.

Keywords: OR in energy, AdaLASSO, long-term hydrothermal dispatch planning, multistage

stochastic programming, regularized linear decision rules.

1. Introduction

Whenever a decision process of one period aﬀects the optimal decisions of the subsequent

ones, it gives rise to a dynamic problem, which in the optimization ﬁeld is known as a multistage

problem. When this process is aﬀected by uncertainty that is gradually observed and decisions can

∗Corresponding author: Alexandre Street
Email address: street@puc-rio.br (Pontiﬁcal Catholic University of Rio de Janeiro)
1Felipe Nazare and Alexandre Street are with the electrical engineering Department at the Pontiﬁcal Catholic
University of Rio de Janeiro (PUC-Rio). Alexandre Street is also the co-founder and research director at the
Laboratory of Applied Mathematical Programming and Statistics (LAMPS) PUC-Rio.

Preprint submitted to Journal of LATEX Templates

September 12, 2022

 
 
 
 
 
 
also be dynamically adapted to the uncertainty process through a linear programming problem, a

multistage stochastic linear problem (MSLP) can be deﬁned.

The solution of a MSLP relies on the estimation of a decision policy, i.e., a rule deﬁning the

vector of decision variables to be implemented throughout the stages (periods) as a function of

the history of the uncertain parameters representing the state of the system. For the general

MSLP, there is no closed-form available. Furthermore, the combination of high number of stages

and high dimension of state and uncertainty vectors results in an enormous range of possible

paths, preventing the use of scenario-tree approaches (see [1]). Thus, the predominant literature

exploring MSLP as a simulation-based tool for practical decision making under uncertainty widely

focus on simulation-based or sample average approximation (SAA) techniques (see [2] and [3]).

This phenomenon has been named in the literature as the curse of dimensionality. If we consider a

stage-wise independent uncertainty aﬀecting the right-hand-side of a linear problem, the so-called

stochastic dual dynamic programming (SDDP) method provides us with the optimal policy for a

given sample of scenarios. This concept was proposed in [4] applied to long-term hydrothermal

dispatch planning (LHDP), and its convergence was proved in [5]. Just to mention a few, more

recently, SDDP was applied in [6] to consider security criteria in the dispatch problem through a

hybridization with robust optimization and in [7] to address the short-term dispatch with storage

in a system aﬀected by wind uncertainty.

Alternatively, a decision policy for a MSLP can also be deﬁned through a function of observed

data, say, ξ[1:t], where t refers to the stage, aﬀecting the problem until the moment each vector

of decisions, xt, must be deﬁned, i.e., xt = Ψ(ξ[1:t]). Approximation approaches consider the

subset of policies deﬁned as a linear combination of functions applied to the uncertainty data.

This subset of decision rules is also known as linear decision rules (LDRs), oftentimes referred

to as aﬃne rules or aﬃne policies in cases where an aﬃne functional space is used. We refer to

[8] and references therein for a recent work. This method ﬁrst appeared in [9], applying it in an

employment workforce and factory production. However, due to its ﬂexibility in solving diﬀerent

stochastic problems, the approach was easily accommodated to other linear problems, being widely

used in reservoir management in a large set of publications such as [10, 11, 12, 13, 14, 15].

The subject of LDR in decision-making under uncertainty is still under development, as ob-

served in [16]. In this work, the authors aim to minimize worst-case scenarios of reservoir limits

violations through a robust approach, approximating the total outﬂow curve to aﬃne functions

of the uncertainty data. Besides reservoir management problems, the simple adaptation of this

method allowed its application in many other studies, varying from solution of ﬁnancial assets

allocation problem [17] to management of heat and power generation [18], power system operation

[19], power generation capacity planning [20] among other relevant works. In terms of hydropower

scheduling, the application of LDR in [21] aims the deﬁnition of a feasible hydropower dispatch for

a price and inﬂow uncertainty set, allowing to reduce the computational eﬀort to solve the problem

while obtaining gains in expected proﬁts. It is relevant to mention that LDR has been playing a

relevant role in addressing two-stage and multi-stage robust models in the recent literature (see [22]

and references therein). This is because the LDR allows for a simpliﬁed representation of recourse

actions, avoiding the complexity of multi-level optimization that robust models generally impose.

2

So, while SDDP-based approaches limit the uncertainty model, the type of variables that can

be considered, and require convexity, the use of LDR limits the format of the functional used to

deﬁne the decision rule. However, it is worth mentioning that the framework of LDR is not limited

to linear or aﬃne functions of the uncertainties. Rather, any convenient linear functional space of

interest mapping the set of uncertainty vectors onto the set of states can be considered and the

problem linearity would still be preserved2. Additionally, as shown in [8], the adoption of a LDR

approach allows writing the MSLP as a two-stage stochastic model (with multiple periods). In

this case, we would be inheriting all properties and convergence results (e.g., SAA results [2, 23]),

and the methods and algorithms (such as Benders decomposition [24] and Progressive Hedging

[25]) for this widely studied class of models. Regarding its ﬂexibility, this class of models allows

us to address MSLP based on uncertainty processes with any kind of non-linear time-dependency

structure and non-Gaussian distributions (such as those typically aﬀecting power systems – see [26]

and [27]) through completely exogenously-generated scenarios, to consider the more broader class

of mixed-integer linear problems, and to consider data-driven methods (see [28]). In this context,

it is worth emphasizing that both approaches have pros and cons and deserve further studies, as

recently demonstrated in the comparisons provided in [8].

In this work, we work concentrate on providing a new empirical and practical contribution to

the application of LDRs to solve MSLPs. Within this context, the deﬁnition of a policy requires

the estimation of many coeﬃcients under limited amount of data. This is especially critical in the

LHDP problem, where a huge number of coeﬃcients would be needed to account for each stage,

individual reservoirs, diﬀerent components of a functional basis, and lags of observed data in the

decision rule. Hence, in practical applications, we oftentimes need to handle more coeﬃcients than

the number of scenarios to keep the model tractable.

In this situation, we should expect from

LDRs a certain degree of in-sample overﬁt and, consequently, poor out-of-sample performances,

i.e., under unseen scenarios. This is a well-known fact from high-dimensional statistics and machine

learning problems (we refer to [29, 30, 31, 32] and [33] as a relevant and updated literature on the

subject).

Interestingly, when applied to a MSLP, the two-stage LDR identiﬁcation problem resembles

the estimation of a linear regression model, Y = X (cid:48)θ + ε, based on a more general loss function,

l(X, Y ; θ), related to the speciﬁc objective function of the problem. In this context, the overﬁtting

issue and the related poor out-of-sample performance of non-parsimonious regression models (with

the number of coeﬃcients approaching or exceeding the number of in-sample observations) have

been addressed by the use of regularization procedures ([33]).

In particular, the adaptive least

absolute shrinkage and selection operator (AdaLASSO) has been playing a key role in the statistical

and machine learning literature [29, 31, 34, 33]. The interested reader is referred to [29] and [30]

for further details. More recently, in [32], the capacity to hedge against unseen data (out-of-

sample) of regularized regression models, such as those based on the LASSO, was connected to

data-driven distributionally robust optimization problems with Wasserstein metric. In [35] (see

2Note that deﬁning a LDR within a given linear space of nonlinear functions (trigonometric, polynomial, etc.)

is equivalent to the problem of ﬁnding the best coeﬃcients of a basis for this space, which is a linear problem.

3

chapter 2), linear regression with LASSO and other regularization metrics were also connected to

robust regression models. Although such theoretical results cannot be generalized for a general

loss function, previously reported (empirical and theoretical) results regarding the improved out-

of-sample performance of regularized regression models provide us with strong and insightful

evidence that MSLP addressed via LDR would also beneﬁt from regularization schemes.

1.1. Hypothesis, objectives, and contributions

The main hypothesis tested in this work is the following: non-regularized LDR overﬁts in-

sample data and more parsimonious LDR-based policies estimated with AdaLASSO-regularization

can provide relevant cost savings under unseen out-of-sample data. Thus, the objectives of this

paper are: 1) to propose a novel regularized LDR for MSLP based on the AdaLASSO, and 2) to

test the aforementioned hypothesis and study the regularization eﬀects using the LHDP problem.

The goal of the approach is to improve the out-of-sample performance of a LDR estimated with

a given sample of size N . In this sense, as our approach provides an out-of-sample cost lower or

equal to the out-of-sample cost of the non-regularized LDR, we improve the SAA method (see [2])

by oﬀering a lower or equal upper bound and an associated improved implementable solution.

To achieve the proposed objective, this paper provides the following contributions to the state-

of-the-art literature:

• Raise awareness of the in-sample overﬁt threat for which LDRs are subject to when applied

to solve MSLP. We test the aforementioned hypothesis and show strong evidence that regu-

larization is an interesting avenue to improve LDR-based policies quality in out-of-sample.

• A novel regularized LDR to solve MSLP based on the AdaLASSO. We exemplify the beneﬁts

of the proposed AdaLASSO-regularized LDR studying one of the most relevant MSLP found

in the related literature, the LHDP, using a polynomial basis of functions.

To quantify the beneﬁts of our proposed regularization scheme, we use a two-step estimation-

simulation procedure. In the ﬁrst step, the LDR coeﬃcients are estimated by a two-stage linear

programming problem, in which an AdaLASSO-regularization term imposes the trade-oﬀ between

parsimony and cost reduction for the in-sample scenarios.

In the second step, the state-target

tracking problem proposed in [8] is used to ﬁnd implementable decisions that follows as much as

possible the estimated LDR for a large set of out-of-sample scenarios. Computational experiments

showcase that the parsimony induced by the regularization procedure signiﬁcantly reduces the

number of coeﬃcients diﬀerent from zero, shrinks the remaining nonzero coeﬃcients, and provides

signiﬁcant out-of-sample economic and operational gains for the identiﬁed policy solving the LHDP

problem.

Finally, it is worth mentioning that our simple yet novel idea of regularized LDRs provides

us with an eﬀective machine-learning-based approach to improve the out-of-sample performance

of two-stage LDRs proposed in [8] that does not increase the complexity of the original problem.

Indeed, according to [36] and [37], the general Wasserstein-based data-driven distributionally robust

counterpart of a polynomial-time solvable linear optimization problem with RHS uncertainty is an

4

NP-hard problem. And based on the results of [38], it is actually a “practically hard NP-hard”

problem3. Therefore, our proposed approach can also be seen as a tractable heuristic to the task of

robustiﬁcation against unseen data that do not add an NP-hard bilevel layer on top of the already

diﬃcult original LHDP problem.

The rest of this paper is structured as follows: Section 2 presents the LDR-based policy estima-

tion and evaluation procedures applied to the long-term hydrothermal dispatch planning problem.

Section 3 describes the new estimation model with AdaLASSO regularization and the calibration

scheme for the regularization parameter. Section 4 depicts the case study data and the main

results. Finally, Section 5 presents the main conclusions of this work and future research avenues.

2. Hydrothermal Dispatch Problem with Linear Decision Rules

Uncertainty is an inherent feature of any planning activity. The impact of such uncertainties

in the certain decision processes requires well structured and robust planning processes. This is

specially evident in the operation of hydrothermal power systems, as a poor management of the

water resources may impose long and severe economic and social losses. The LHDP problem is one

of the most studied MSLP. Its representative mathematical structure (MSLP with long horizons

and high-dimensional state space and uncertainty) and real-world economic and social relevance

(management of one of the most relevant natural resources used to generate energy) motivated a

myriad of academic papers (see the literature review in [39]) and industry applications in the last

three decades.4

In the LHDP problem, independent system operators (ISOs) must manage the water stored in

hydro reservoirs through the time to dispatch the best mix of generators to supply demand at every

stage while minimizing the long-run expected operating cost. To do that, ISOs must consider the

cascades topology (considering that upstream water discharges can be used to generate energy in

downstream hydros), network transmission constraints (considering that the energy produced by

generators must ﬂow through the network to supply demand), thermoelectric generation capacity

and fuel costs, and the inﬂow uncertainty5.

In this setting, a dispatch policy or rule must be

estimated and then evaluated through an out-of-sample implementation scheme. In this section,

we show both the estimation and evaluation procedures of LDRs applied to LHDP, which is a

relevant, representative, and didactic case of a MSLP.

3We call a practically hard NP-hard problem a problem that is not only hard for the worst-case instance, but

for practical medium-sized instances of interest in realistic applications.

4Interestingly, the development of the stochastic programming area was signiﬁcantly aﬀected by the relevance

and challenge of this problem. We refer the interested reader to [3].

5Many other uncertainties can be considered, but for the sake of simplicity and didactic purposes we concentrate

on the main format with which this problem is generally studied.

5

2.1. General formulation for the MSLP and linear decision rules

The general form of the MSLP we will approach in this paper follows the one used in [8] and

can be written as follows:

min Eω

(cid:34)

(cid:88)

(cid:16)

t∈T

t(ξt(ω))xt(ξ[t](ω)) + q(cid:48)
c(cid:48)

t(ξt(ω))yt(ξ[t](ω))

(cid:35)

(cid:17)

s.t.: (cid:2)xt(ξ[t](ω)), yt(ξ[t](ω))(cid:3) ∈ Ft

(cid:0)xt−1(ξ[t−1](ω)), ξt(ω)(cid:1),

∀t, ω.

(1)

(2)

In this general model, c(cid:48)

t and q(cid:48)

t stand for the transpose of vectors ct and qt, t represents the

time steps or decision stages assumed to belong to T and ω represents a scenario (or point) of

the sample space Ω. The uncertainty is accounted for by random vectors ξt : Ω −→ Ξt for all

t ∈ T , whose history until t is represented by vector ξ[t] = [ξ1, ..., ξt]. We assume that the support
set of ξt, namely, Ξt, is a subset of Rdξt and Ξ[t] = ×t
In this context, Eω means the
mathematical expectation, where ω is used to clearly show where the expectation is iterating.
Then, for instance, the expected value of ξt is deﬁned as µt = Eω[ξt(ω)] = (cid:82)
ω∈Ω ξtdP. We consider
random variables with ﬁnite ﬁrst and second moments. Regarding the decisions, xt : Ξ[t] −→ Rdxt

k=1 Ξk.

is part of the decision vector that stands for the state of the system at the end of stage t, whereas
yt : Ξ[t] −→ Rdyt represents the current stage vector of control actions. Regarding the problem

structure, Ft represents a polyhedral set parameterized on the value of the state vector at the end

of t − 1, or initial state of t, and on the history of the uncertainty until t. Therefore, expression

(2) means a general aﬃne relation among vectors xt, yt, xt−1, and ξ[t].

Note that, in the general formulation (1)–(2), both the state and the control vectors of a

given stage t are general functions of ξ[t](ω), the history of the stochastic process until t. As per

[8], the LDR approach assumes both the state and the control to belong to a set of functional

space that can be expanded by a set of basis of nonlinear functions. Alternatively, the two-stage

LDR approach assumes that only state variables follow the LDR. In this case, control actions

are afterward obtained by a state-target tracking implementation procedure. Finally, it is worth

mentioning that although the proposed approach applies to the more general model (1)–(2), in this

work, we showcase our contributions based on a particularized version of this problem. We use the

LHDP as an application to derive experiments and test the hypothesis that AdaLASSO-regularized

LDRs provide improved out-of-sample results in comparison to their non-regularized version.

2.2. Linear decision rule applied to the LHDP

In this work, we focus on the two-stage LDR approach [8] to generate a hydrothermal scheduling

policy considering uncertainty in water inﬂow. Although many variants of this problem can be used,

we keep the model simple (following previously reported works) to study the main properties of

an applied LDR in a didactic yet meaningful problem. Therefore, we use the following operational

6

model to estimate the LDR:

(cid:34)

(cid:88)

α−t(cid:16)

min Eω

t∈T

tgt(ω) + c(cid:48)
c(cid:48)

dδt(ω)

(cid:35)

(cid:17)

s.t.: T gt(ω) + Hρ(ut(ω)) + Aft(ω) + δt(ω) = dt,

∀t, ω

vt(ω) − vt−1(ω) + M (ut(ω) + st(ω)) = ξt(ω),

∀t, ω

v1(ω) = v0,

∀ω

vT (ω) ≥ vf ,

∀ω

{vt(ω), ut(ω), st(ω)} ∈ Ht,

∀t, ω

{gt(ω), ft(ω)} ∈ Nt,
(cid:88)

vt(ω) −

∀t, ω

Ψk(ξ[t−τ :t](ω))Θt,k = 0,

∀t, ω.

(3)

(4)

(5)

(6)

(7)

(8)

(9)

(10)

k∈K

First, it is important to mention that throughout this work, decision variables are all on the

left-hand-side of constraints as well as constants are all on the right-hand-side. Thus, in model

(3)–(10), the objective function, (3), represents the expected value of the net-present value at a

discount factor α of operating costs within the set of periods T . For the sake of simplicity, the

operating cost is represented as a linear function of the thermoelectric generation vector, gt(ω).

Therefore, ct represents the vector of unitary costs of each thermoelectric unit. Additionally, the

objective function is also composed by a second term representing the cost of the energy not

supplied, δt(ω), where a unitary cost for the deﬁcit of supply, cd, is assumed.

The nodal energy balance is presented in (4). In this expression, total supply, composed of

thermoelectric generation, hydro generation, transmission ﬂows, and ﬁctitious generation repre-

senting deﬁcit, respectively, should be equal to demand in every node. Thus, T and H allocate

thermoelectric and hydro generation to respective buses (nodes of the network) and the incidence

matrix A, which deﬁnes the network topology, associates transmission-line ﬂows to the correspond-

ing nodal equations. Finally, ρ(·) deﬁnes the vector of hydro production functions, transforming

the amount of water discharged into hydros’ turbines into actual power generation. Expression (5)

represents the water balance equation (state transition function) for each hydroelectric reservoir,

scenario ω, and stage t. In this expression, vt(ω) and vt−1(ω) represent the vector of water stored

at the end of period t and t − 1 for scenario ω, respectively; ξt(ω) represents the vector of incoming

water (inﬂows) in each reservoir for scenario ω; ut(ω) and st(ω) represents the water discharged

into the turbines that eﬀectively produce energy and water spillage, respectively, for period t and

scenario ω. Finally, M is a matrix that deﬁnes rivers topology in the water balance, accounting for

upstream and downstream water release in each reservoir balance equation. The initial condition

of the stored water in each reservoir is stated in (6). In order to avoid the end of horizon eﬀect,

Equation (7) is used to maintain the ﬁnal reservoir levels greater than or equal to a user-deﬁned

limit. Constraint (8) allows deﬁning operative limits for hydro power plants, e.g., minimum and

maximum reservoir’s storage capacity, minimum water discharge, etc. Similarly, Expression (9)

represents the set of technical operational constraints for the generation or transmission assets, e.g.,

considering minimum and maximum generation, transmission line limits and the Second Kirchhoﬀ

7

Law [40] for each period.

Finally, expression (10) deﬁnes a general LDR rule driving the state of the system (vt(ω)) at each

stage and scenario, where {Ψk}k∈K represents a basis of nonlinear functions. This basis is applied

to the inﬂow vector, ξ[t−τ :t](ω), which stacks on ξt(ω) the vectors of τ -previous observed reservoirs’

inﬂows for each ω. The vector of coeﬃcients Θt,k is one of the decisions of our model, which is co-

optimized with the rest of the dispatch decisions. It accounts for a limited set of lags, L = {0, ..., τ },

and elements, k ∈ K, in the functional basis. In this work, we use a set of polynomial functions

(considering the intercept, i.e., 0 ∈ K) for each reservoir. For the sake of simplicity, we disregard

cross-terms eﬀects. Notwithstanding, to consider the inﬂuence of other reservoirs h(cid:48) ∈ H\{h} in
the LDR of reservoir h, we also consider the sum of their inﬂows (ξ(−h)

h(cid:48)∈H\{h} ξt−l+1,h(cid:48))
in each LDR expression. It is important to highlight that the consideration of cross-terms, such

t−l+1 := (cid:80)

as ξt−l+1,h · ξt−l(cid:48)+1,h(cid:48) for diﬀerent l, l(cid:48), h and h(cid:48), would still be valid under the proposed LDR

scheme. Note that although nonlinear, cross-terms accounting for products between the inﬂow

data of diﬀerent lags and reservoirs can be exogenously pre-calculated and transformed into new
variables, e.g., ξ(l,l(cid:48),h,h(cid:48))

= ξt−l+1,h · ξt−l(cid:48)+1,h(cid:48), to be considered in the LDR as customary in linear

t

regression.

Therefore, model (3)–(10) deﬁnes the optimal LDR for the hydro reservoir h, period t, and

scenario ω under the following functional form:

vt,h(ω) =

(cid:88)

(cid:88)

k∈K

l∈Lk

θ(h)
t,h,k,l ·

(cid:18) ξt−l+1,h(ω) − µt−l+1,h
σt−l+1,h

(cid:19)k

(cid:88)

(cid:88)

+

θ(−h)
t,h,k,l ·

k∈K0

l∈L

(cid:32)

t−l+1(ω) − µ(−h)
ξ(−h)
σ(−h)
t−l+1

t−l+1

(cid:33)k

∀t, h, ω.

(11)

Where, µt−l+1,h and σt−l+1,h are the expected value and standard deviation of the inﬂow of hydro
t−l+1 and σ(−h)
reservoir h at stage t − l + 1, respectively, µ(−h)
t−l+1 represent the same statistics for
t−l+1, and θ(h)
ξ(−h)
t,h,k,l are the components of the coeﬃcient vector Θt,k. By considering the intercept,
k = 0, seasonal levels are automatically addressed. Thus, we can use the deseasonalized series

to determine the policy based on standardized shocks above or below average. Additionally, we

avoid degenerated models (with multiple coeﬃcients playing the role of intercept) by disregarding

multiple lags when k = 0 in the ﬁrst term, i.e., by making Lk := L ∀k > 0 and L0 := {0}, and

disregarding k = 0 in the second term, i.e., by making K0 := K\{0}.

2.3. Linear decision rule estimation

In practice, according to [8], the so-called SAA version of problem (3)–(10) is used to estimate
the vector of coeﬃcients ˆΘ for the LDR. To do that, we randomly generate (based on a Monte

Carlo procedure) a ﬁnite sample space ΩN from Ω with N scenarios, each of which associated with
a probability equal to 1/N .6 We denote as {ξt,s}s∈ΩN ,t∈T the associated inﬂow values for each

6Notwithstanding, scenario reduction techniques, clusterization methods, and variants of Monte Carlo approaches
can also be used to generate the aforementioned set of scenarios used to estimate LDRs. Depending on the method,
one just need to consider an individual probability diﬀerent than 1/N for each scenario. Henceforth, however, for
the sake of simplicity, we will consider equally distributed scenarios as per the SAA approach.

8

sampled scenario. Thus, we can estimate the LDR coeﬃcients by solving the following two-stage

linear optimization problem:

min

1
N

(cid:88)

(cid:88)

α−t(cid:16)

tgt,s + c(cid:48)
c(cid:48)

dδt,s

(cid:17)

s∈ΩN

t∈T

s.t.: T gt,s + Hρ(ut,s) + Aft,s + δt,s = dt,

∀t, s

vt,s − vt−1,s + M (ut,s + st,s) = ξt,s,

∀t, s

v1,s = v0,

∀s

vT,s ≥ vf ,

∀s

{vt,s, ut,s, st,s} ∈ Ht,

∀t, s

{gt,s, ft,s} ∈ Nt,
(cid:88)

vt,s −

∀t, s

Ψk(ξ[t−τ :t],s)Θt,k = 0,

∀t, s.

(12)

(13)

(14)

(15)

(16)

(17)

(18)

(19)

k∈K

It is relevant to note that the number of coeﬃcients in the decision rule depends on the number

of periods (|T |), water reservoirs (|H|), time-lags of the historical data (|L|), and on the degree of

the polynomial basis (|K|). Although it provides great ﬂexibility for obtaining reasonable dispatch

policies, the large number of coeﬃcients easily approaches the typical number of scenarios that

can be handled in practical applications.7 For instance, if we consider a 24 months (2 years

horizon in monthly basis), 5 reservoirs, 12 lags, and 6 degrees in the polynomial basis, the total

number of coeﬃcients for estimating the LDR is approximately equal to 8.6 thousands. This

number (approximately) doubles if we account for the second term of expression (11) (in this case,

approximately equals to 16.8 thousands) and can get much larger if we consider cross-terms. As

a result, in practical applications where a SAA of the model is used with, say, hundreds to few

thousands of sampled scenarios, it is very likely spurious coeﬃcients will be found due to overﬁt.

The consequence, in general, is a poor performance when implementing the policy in out-of-sample

scenarios as largely reported in regression and machine learning literature.

2.4. Linear decision rule implementation and out-of-sample evaluation

The implementation of a two-stage LDR can follow a state-target tracking (STT) procedure

described in [8]. In this procedure, the operation of the system is implemented by a STT optimiza-

tion problem, which aims to follow the targeted storage deﬁned by the estimated LDR as much

as possible for a given initial state and observed data. The estimated LDR is represented by the
optimal coeﬃcient vector ˆΘ, which can be obtained as the solution of problem (12)–(19). Thus,
given the estimated LDR coeﬃcient vector ˆΘ, the vector of initial storage vt−1,s, and observed

scenario of inﬂows ξ[t−τ :t],s, the operation of the system for stage t can be deﬁned by the solution

7For instance, [8], and more recently [41], apply LDRs with relatively few scenarios in-sample. For instance, in
[41], “we approximated this problem with just 25 scenarios due to computational limitations.” and in [8], authors
use only “250 scenarios to construct an SAA”.

9

of the following deterministic and single-period STT problem:

min c(cid:48)gt,s + c(cid:48)

dδt,s + γ(cid:48)(e+

t,s + e−

t,s)

s.t.: T gt,s + Hρ(ut,s) + Aft,s + δt,s = dt

vt,s + M (ut,s + st,s) = vt−1,s + ξt,s

{vt,s, ut,s, st,s} ∈ Ht

{gt,s, ft,s} ∈ Nt

e+
t,s, e−

t,s ≥ 0

vt,s + e+

t,s − e−

t,s =

Ψk(ξ[t−τ :t,s]) ˆΘt,k.

(cid:88)

k∈K

(20)

(21)

(22)

(23)

(24)

(25)

(26)

Problem (20)–(26) delivers as output optimal implemented operational decisions (g∗

t,s, u∗

t,s, f ∗

t,s, δ∗

t,s)

and the new state of the system v∗

t,s. It is worth highlighting that v∗

t,s can diﬀer from the targeted

state deﬁned by the LDR in right-hand-side of expression (26). However, aiming to enforce the

objective function to penalize the absolute value of the state-target deviation errors e+

LDR as much as possible in the implementation step, a high penalty vector γ is considered in the
t,s + e−
t,s.
Low penalties for spillages can also be considered for practical purposes albeit omitted in this

model. It is relevant to emphasize at this point that the above procedure represents the actual

two-stage decision rule. In other words, it provides the system operator with a process that, given
ˆΘ, the initial state, and the observed data until stage t, recommend what to do in this stage in a

nonanticipative fashion.

Thus, based on the STT problem (20)–(26), we can evaluate out of sample the performances of

any LDR for a larger and new set of randomly generated scenarios ΩM (generated from the same

underlying process), where M >> N . To do that, we initialize v∗

0,s with a known initial storage

vector v0 and successively solve the STT problem for all t ∈ T and s ∈ ΩM . In each step, i.e.,
for each t, s, we consider as input (vt−1,s, ξ[t−τ ]:t],s, ˆΘ) and as output (g∗
that the storage output of a given period is used as input for the next period. At the end of this

t,s). Note

t,s, f ∗

t,s, u∗

t,s, v∗

t,s, δ∗

chronological simulation process, we can evaluate the out-of-sample operational cost due to the
implementation of a LDR deﬁned by ˆΘ as follows:

M ( ˆΘ) =
z∗

1
M

(cid:88)

(cid:88)

α−t(cid:16)

s∈ΩM

t∈T

c(cid:48)g∗

t,s + c(cid:48)

dδ∗
t,s

(cid:17)

.

(27)

Because the STT is always limited for any value of ˆΘ, due to the uniform law of large number, under
(cid:105)

mild conditions on the distribution of ξ, we have that z∗

t∈T α−t(c(cid:48)g∗

t (ω)+c(cid:48)

dδ∗

t (ω))

M ( ˆΘ) −→ Eω

(cid:104) (cid:80)

when M → ∞, in which g∗

t (ω), δ∗

t (ω), and v∗

t (ω) are the optimal solutions of the STT problem for

ξt(ω) ([2]).

3. The Proposed Regularized Linear Decision Rule via AdaLASSO

The AdaLASSO is a regularization operator that has the oracle property [29]. Roughly, it

means that such a regularization scheme is capable of selecting only the few coeﬃcients truly

10

relevant for explaining the data. This concept is proposed for the ﬁrst time in the present work

to improve the quality of LDR applied to solve MSLP problem. The proposed regularized LDR

estimation model considers an additional term in the objective function penalizing the scaled (cid:96)1-

norm of the coeﬃcient vector. Then, the new objective function accounts for the trade-oﬀ between

the in-sample cost minimization and the number of parameters (parsimony) used in the LDR to

minimize it. The goal of the regularization is to obtain a better generalization of the LDR for

unseen scenarios, thereby reducing the out-of-sample cost.

If Θ stacks all the coeﬃcients θt,h,k,l,r=1 = θ(h)

t,h,k,l and θt,h,k,l,r=2 = θ(−h)

t,h,k,l for all t ∈ T , h ∈ H,

k ∈ K, and l ∈ L, the AdaLASSO regularization function Fλ,Θ(0)(Θ) can be deﬁned as follows:

Fλ,Θ(0)(Θ) = λ

(cid:88)

(cid:88)

(cid:88)

(cid:88)

2
(cid:88)

t∈T

h∈H

k∈K0

l∈L

r=1

|θt,h,k,l,r|
|θ(0)
t,h,k,l,r|

.

(28)

Function (28) receives a vector of parameters Θ and returns a scaled sum of the absolute values

of its components, disregarding the intercept coeﬃcient (k = 0). It has two parameters, namely:

1) λ, which is a scalar reﬂecting the overall penalization level to all coeﬃcients, and 2) Θ(0),
which is the vector that stacks the non-regularized LDR coeﬃcients θ(0)

t,h,k,l,r estimated with the
original SAA problem (12)–(19), where zero elements are replaced with 1. It is important to notice

that from one period to another, the value of Θ(0) should not dramatically change. Therefore, in

practical applications one might not need to solve the two problems all the time. Additionally, it is

important to highlight that other interesting regularization metrics can also be used as alternatives

to the AdaLASSO in cases the extra computational burden to estimate Θ(0) becomes an issue.8

Nevertheless, as we are in a planning context, the computational time to solve both models might

not constitute an issue.

Thus, the (AdaLASSO) regularized LDR for the MSLP can be estimated by the solution of the

following two-stage linear programming model:

min

1
N

(cid:88)

(cid:88)

α−t(cid:16)

c(cid:48)gt,s + c(cid:48)

dδt,s

(cid:17)

+ λ

s∈ΩN

t∈T

(cid:88)

(cid:88)

(cid:88)

(cid:88)

2
(cid:88)

t∈T

h∈H

k∈K0

l∈L

r=1

φt,h,k,l,r
|θ(0)
t,h,k,l,r|

s.t.: Constraints (13) to (19)

φt,h,k,l,r − θt,h,k,l,r ≥ 0,

∀t, h, k, l, r

φt,h,k,l,r + θt,h,k,l,r ≥ 0,

∀t, h, k, l, r

(29)

(30)

(31)

(32)

In (29)–(32), the regularization term deﬁned in (28) is added to the original objective function,

(12). Additionally, the nonlinear absolute-value terms, |θt,h,k,l,r|, in (28) are replaced with auxil-

iary variables, φt,h,k,l,r, and epigraph constraints, (31)–(32), following the standard linearization
procedure in linear programming. Note that the output of (29)–(32) is a vector of coeﬃcients ˆΘλ

8Note that many other regularization penalties could be used, each of which with their pros and cons as widely
reported in the related literature. For instance, a combination between absolute and quadratic norms (Elastic Net)
is a salient example that could be used as an alternative. Notwithstanding, it is beyond the scope of this paper to
analyze all of them. Instead, we focus on the more general (cid:96)1-norm form of the AdaLASSO, which is widely used
and recognized as a relevant tool for variable selection [33] and to improve the model performance in out-of-sample
tests.

11

representing a regularized LDR, which can be evaluated out of sample through (27) for diﬀerent

values of λ. In this context, a grid search based on the out-of-sample cost metric can be used to

obtain the best regularized LDR within all policies induced by the inspected values of λ. Finally,

it is important to highlight that although we have used the LHDP problem to derive our ideas,

the results of this section are very general and can be easily applied to other MSLP instances

particularized from (1)–(2).

4. Computational Experiments

For analysing the proposed method, two diﬀerent case studies are performed. The aim of the

ﬁrst case study are twofold: 1) to study the quality of the regularized LDR in out-of-sample tests,

and 2) to study the properties of regularized coeﬃcients. To address the former, we benchmark

the regularized LDR with the classical non-regularized LDR [8] and evaluate the out-of-sample

costs. Finally, the latter is addressed based on comparisons between the coeﬃcients obtained with

the non-regularized and regularized LDRs. The second case study shows statistical analysis of

the out-of-sample results of the regularized LDR based on a more complex cascade topology for

a stochastic process with nonlinear temporal dependencies [26]. It focuses on the eﬀects of the

regularization process over the total cost distribution, for which we show further beneﬁts obtained

from the proposed regularization beyond cost reduction.

All computational experiments were conducted using the Julia programming language (version

v1.2) and solved with Gurobi v0.9.13, on an Intel Core i7-10510U processor at 1.80 GHz with 8

GB of RAM.

4.1. Case Study 1 – a simple test system

To evaluate the proposed regularized policy based on LDR and its performance in reducing

the overﬁt issue, we consider a comparison between the proposed method and the standard non-

regularized LDR approach. For the sake of simplicity and to easy the comparison, in this case

study, we use a stagewise-independent stochastic process with periodic mean and variance based

on historical data to generate inﬂow scenarios. Thus, in this particular case, the standard SDDP

approach provides the optimal policy, thereby serving as reference for the proposed LDR approach.

To this end, we implement the same operational model used to deﬁne each stage of model (3)–(10)

in [42] and used the same in-sample scenarios.

In this ﬁrst simulation a simple system conﬁguration , with only one reservoir (one state vari-

able), is chosen to ensure we can explore and study operational results obtained with the regularized

LDR. The Table 1 presents the main characteristics of the simulation.

Table 1: Case Study 1 - System Conﬁguration

Number of Stages
Number of Hydros
Number of Thermals
In-sample Scenarios
Out-of-sample Scenarios
Discount Rate

36
1
6
100
1000
0.5%

12

The main characteristics of the hydro power plant considered in this case study is presented in

Table 2, while thermal projects are presented in Table 3.

Table 2: Case Study 1 - Hydro Power Plants Characteristics

Max Reservoir Storage (units)
Min Reservoir Storage (units)
Max Turbine Capacity (units)
Eﬃciency (MW/unit)

894
356
700
0.414

Capacity (MW) Variable Cost ($/MWh)

Table 3: Case Study 1 - Thermal Power Plants Characteristics
Thermal
Thermal 1
Thermal 2
Thermal 3
Thermal 4
Thermal 5
Thermal 6

100
100
100
50
50
50

500
113
153
116
58
86

In this case, where only one hydro unit is considered, the second term in (11) is not applicable.

Thus, the parameters of the LDR will be selected considering the maximum order in the polynomial

basis equal to six (i.e., max{K} = 6) and the maximum value of lag is 11 (i.e., max{L} = 11).

4.1.1. Policy quality

To measure the quality of the policies generated with the regularized LDR, we use the opti-

mization model proposed in (29)–(32) for diﬀerent values of λ. The cost of each policy is evaluated

considering out-of-sample scenarios according to the STT procedure described in Section 2.4. The

best regularized LDR is selected according to the minimum out-of-sample cost metric (27) by vary-

ing the value of λ within a user-deﬁned grid. Table 4 shows the computational times required in

the estimation and out-of-sample evaluation processes as well as the respective expected costs.

Table 4: Computational Time - Case Study 1

Comp. Time

Exp. Total Cost

Estimation Evaluation Estimation Evaluation

λ = 0
λ = 103

(s)
9.73
4.60

(s)
5.75
8.02

(M$)
1.56
1.59

(M$)
2.00
1.63

Figure 1 shows the in-sample (estimation) and out-of-sample (evaluation) system operating

cost for diﬀerent values of λ. Noticeably, the in-sample operational cost does not signiﬁcantly

vary with values of λ as the out-of-sample does. Additionally, the AdaLASSO penalization, albeit

shrinking parameters, do not signiﬁcantly aﬀect the in-sample cost until a determined threshold. In

turn, as the value of λ increases, the out-of-sample operating cost signiﬁcantly decreases, revealing

the existence of many regularized policies that can signiﬁcantly outperform the traditional non-

regularized LDR. These facts show us evidence of overﬁt and the potential threat of non-regularized

LDR in ﬁnite samples. Furthermore, it also shows that, in ﬁnite sample, better policies, with

improved out-of-samples results, may be found based on the proposed regularization scheme.

13

Figure 1: Total in-sample and out-of-sample system cost per λ

The increase of the regularization penalty shrinks a great amount of parameters associated with

explanatory variables (using the terminology of regression analysis in statistics) that are not indeed

relevant to generalize the LDR model to other samples. For the deﬁned system conﬁguration

(classiﬁed loosely restricted case – we will further show a more restricted case) and stage-wise

independent scenarios, the lower out-of-sample cost is found at λ = 103, however the out-of-sample

results for λ > 103 do not vary signiﬁcantly until the maximum λ (which would mean that the

LDR considers only the intercepts). In this case, the proposed regularization scheme provides a

18.5% gain, in terms of out-of-sample cost reduction, compared to the policy obtained with the

traditional non-regularized LDR approach. This gain grows up to 25% for the 95-percentile of the

cost distribution.

Regarding the benchmark with the SDDP reference, we use the same in-sample scenarios used

to train the LDRs as the set of backward scenarios in the SDDP. Forward steps are calculated using

random samples also from the set of in-sample scenarios. After the SDDP algorithm converged

(within a computational time of 99.9 seconds), we use the same 1000 out-of-sample scenarios used

to evaluate the LDR approaches and obtained the a reference cost of 1.57 M$. While the in-sample

cost obtained with the non-regularized LDR falls within the in-sample GAP of the SDDP, the out-

of-sample cost of the non-regularized LDR is 27.39 % higher than the out-of-sample of the SDDP.

On the other hand, the best regularized LDR exhibits an improved out-of-sample performance,

only 3.8% higher than the SDDP reference (which is 7.16 times smaller than the gap obtained with

the non-regularized LDR).

4.1.2. Operational results

In this subsection we compare operative results simulated with the non-regularized (lines and

shadows in blue) and regularized (lines and shadows in orange) LDR. Hereinafter, whenever we

use the therm regularized LDR, we mean the best regularized LDR, i.e., with the best value of λ

previously selected (in this case, λ = 103). Figures 2, 3, and 4 show the total thermal generation,

hydro generation, and hydro reservoir storage levels, respectively, for the out-of-sample scenarios.

Lines represent expected values, whereas shadows account for the 2% to 98% quantile range.

14

Results obtained from both policies exhibit similar average levels, trends, and seasonalities.

Nevertheless, moderate deviations in the average amplitude of the seasonal pattern reveal dif-

ferences in the overall storage strategy, whereas prominent spikes in some stages highlight the

instability that non-regularized coeﬃcients may bring under ﬁnite sample sizes. Our tests indi-

cate that small regularization penalties can mitigate such cases, suggesting that they are mostly

caused by overﬁt under degenerated solutions. In addition to the aforementioned deviations, the

most prominent diﬀerence between the two policies lies in their variability. Noticeably, the non-

regularized policy exhibits a much more uncertain proﬁle (see blue shadows in Figures 2, 3, and

4) if compared with the proposed regularized policy.

In some stages, where the storage levels

approach the maximum and minimum bounds, only the intercept of the LDR is selected, thereby

resulting in a deterministic policy in which storage targets are deﬁned regardless of the inﬂow.

On the other hand, the non-regularized dependency of inﬂows under unseen scenarios can produce

expensive thermal generation. For instance, in Figure 2, the activation of the most expensive

thermal resource induced by the non-regularized LDR imposes a cost many times higher than the

cost savings obtained with lower generation scenarios (see the generation costs at Table 3).

Figure 2: Thermal power generation in avgMW

Figure 3: Hydro power generation in avgMW

4.1.3. Regularized coeﬃcients

Finally, we provide an analysis of the selection and shrinkage of the decision variables (LDR

parameter). Figure 5 illustrates the percentage of non-zero coeﬃcients deﬁned for each (policy)

value of λ per lag of the water inﬂow. Noticeably, the non-regularized policy (λ = 0) contains

a relatively large number of coeﬃcients diﬀerent than zero, e.g., 45.0% of the total number of

15

Figure 4: Hydropower plant initial level of the reservoirs at each stage in percentage of the maximum

coeﬃcients. Increasing the penalty value however, the number of non-zero coeﬃcients signiﬁcantly

diminishes, even though the in-sample total cost remains approximately the same (as can be

observed in Figure 1). This reduction in the number of LDR coeﬃcients clearly indicates the

existence of degenerated solutions – solutions with the same in-sample operational cost.

Additionally, the existence of diﬀerent solutions with the same in-sample cost but with a reduced

number of parameters and cheaper out-of-sample costs strongly corroborates the main hypotheses

of this work9. At the best penalty λ = 103 (highlighted in red in Figure 5), only 5.1% coeﬃcients

are diﬀerent than zero, which represents a relevant reduction in comparison to the 45.0% obtained

with λ = 0 (i.e., a 88.6% reduction in the non-zero coeﬃcients).

Figure 5: Coeﬃcient selection in percentage of the total available coeﬃcients

Figure 6 depicts the shrinkage process in the LDR coeﬃcients. It is interesting to see that the

(cid:96)1-norm of vector Θ(λ=103) is 95.57% lower than the same norm calculated with λ = 0.

9As per the introduction section, the main hypothesis is: non-regularized LDR overﬁts in-sample data and more
parsimonious LDR-based policies estimated with AdaLASSO-regularization can provide relevant cost savings under
unseen out-of-sample data.

16

Figure 6: Coeﬃcient (cid:96)1-norm shrinkage in percentage of the (cid:96)1-norm for λ = 0

4.2. Case Study 2

For the sake of evaluating the performance of the regularized LDR in a more realistic problem,

the Case Study 2 is carried out considering the operation of interconnected cascades. The water

inﬂows into the reservoirs are modelled via generalized autoregressive with score model (GAS),

a non-Gaussian stochastic processes with nonlinear score-driven autoregression dependence. This

processes allows modeling, estimating, and simulating inﬂow time series within a coherent frame-

work that, e.g., recognizes the boundaries and speciﬁc family of conditional distributions of the

underlying stochastic process. We refer the interested reader to [43] for an example of application in

wind power generation in Brazil and to [26] for the open-source tool used to generate the scenarios

used in this case study. The consideration of realistic processes with typical nonlinear dependen-

cies and non-Gaussian distributions constitute a relevant and timely avenue for approximating the

mathematical model and the true underlying problem. It is worth mentioning that the usage of a

stochastic process with non-linear (non-convex) time dependencies prevents the application of the

traditional SDDP technique. Interestingly, the LDR considers the stochastic processes driving the

uncertainties as a completely exogenous model. In this case, all sort of spatial-temporal dependen-

cies can be considered through simulated scenarios and used to estimate and evaluate the LDR as

per previous Sections.

In this case study, we further study the economic beneﬁts of the proposed idea of regularizing

LDRs. Therefore, we extend the analysis previously carried out for the expected cost to analyze

the cost distribution. Finally, we also analyze speciﬁc operational and market performance indices

to exemplify other economic beneﬁts of regularizing LDRs.

4.2.1. System Conﬁguration

In this Case Study, the system conﬁguration is composed of ﬁve reservoirs (ﬁve state variables)

in two diﬀerent cascades as shown in Figure 7. The main hydro power plants’ data are depicted

in Table 5.

The demand is set as 1000M W in every stage, preventing any extra eﬀect on the results besides

the inﬂow scenarios and decisions on the power system scheduling. The load shedding cost is set

to $2611/M W h. Moreover, the system conﬁguration of this example contains six thermal power

units whose data are shown in Table 6.

Finally, Table 7 depicts other relevant parameters used in this case study.

17

Figure 7: Hydropower plants cascade topology

Hydro
Max. Storage (hm3)
Min. Storage (hm3)
Max. Turb. (m3/s)
Prod. Factor (MW/month.m3.s)
Downstream Plant

Table 5: Hydropower plants conﬁguration
3
291
17
77
1.10
4

1
394
36
80
0.81
None

2
319
78
103
1.12
4

4
197
21
227
1.10
5

5
166
8
277
1.19
None

Table 6: Thermal power plants conﬁguration

Name

Max. Gen. Capacity Variable Cost

Thermal 1
Thermal 2
Thermal 3
Thermal 4
Thermal 5
Thermal 6

(MW)
250
50
250
50
50
50

($/MWh)
159
113
153
116
58
86

Table 7: Case study main conﬁgurations.

Stages
24

In-Sample Series Out-of-Sample Series Max. Lag

100

10000

12

4.2.2. Regularization Process

As proposed, the regularized LDR method requires the deﬁnition of an optimal penalty for the

AdaLASSO, therefore the regularization process was carried out. A similar sequential process of

changing the penalty level in the estimation step and evaluating the LDR policy for out-of-sample

scenarios was performed. Table 8 depicts the computational times required in the estimation and

out-of-sample evaluation processes for both the non-regularized and best regularized LDRs.

Table 8: Computational Time - Case Study 2

Estimation Time (s) Evaluation Time (s)

λ = 0
λ = 104

138.11
29.77

113.12
79.82

As depicted in Figure 8, the estimation time exhibits an interesting pattern. For instance,

higher and more volatile computational times are observed for small values of λ, whereas a more

regular and smoother pattern takes place when the value of λ reaches the scale of generating units’

18

costs (greater of equal to 10 $/MWh). The evaluation time exhibits a much more constant pattern

as it does not directly depends on the value of λ.

Figure 8: Computational time for each λ

In this case study, however, we present the out-of-sample results for the expected value, ﬁfth

percentile (P5), and ninety-ﬁfth percentile (P95) of the total operation cost. Figure 9 presents

these three indices (vertical axis) for diﬀerent values of λ (horizontal axis). The lower and upper

dashed curves show the P5 and P95 values, respectively, while the continuous curve depicts the

expected value.

In this case, the best value of λ is equal to 10000. Note that the P95 metric

and the average costs do not agree in which should be the best value of λ. However, this is not

necessarily true for all percentiles.

Figure 9: Expected Value of Total Operation Cost for diﬀerent values of λ

The best regularization produces a reduction of 13.0% on the total cost in comparison to the

non-regularized benchmark. After this penalty level, the performance of the out-of-sample tests

reaches worse results. The selection of coeﬃcients resulted in 60.2% of non-zero coeﬃcients in non-

regularized LDR against 2.0% for λ = 10000. The shrinkage also resulted in a relevant reduction,

reaching 97.6% of reduction of the (cid:96)1-norm of the coeﬃcient vector.

In addition to the previously presented results, by comparing the accumulated probability

distribution of both regularized and non-regularized LDRs, we can see in Figure 10 that the

regularized policy dominates (in the stochastic sense) the non-regularized one. In this ﬁgure, it is

19

also highlighted the expected value, P5 and P95, also numerically presented in Tables 9 and 10.

From the last column of Table 10, we can also observe a 50% reduction in the dispersion of the

cost distribution (assessed through the diﬀerence between P95 and P5) for the regularized LDR

case in comparison to the benchmark. Thus, the regularized LDR provides a stochastic dominant

and less uncertain operational cost distribution. The previously highlighted ﬁndings showcase the

prominent superiority of the regularized LDR over the non-regularized benchmark.

Figure 10: Distributed Probability Function, Expected Value, P5 and P95 of Operation Cost of Out-of-Sample
Simulations

Interestingly, by contrasting values presented in Tables 9 and 10 we can see that: the small

increments (of 1.5%, 0.6%, and 0.6%) on the in-sample metrics due to the regularization approach

enables higher reductions (of 15.6%, 13.5%, and 18.7%) on the same indices in out-of-sample

scenarios. This provides us with a measure of the in-sample sub-optimality imposed by the best

regularization scheme.

Table 9: Cost metrics for in-sample scenarios.
λ

P5
($ · 106)
1.34
1.36
1.5%

Expected value
($ · 106)
1.58
1.59
0.6%

P95
($ · 106)
1.77
1.78
0.6%

0
104
Diﬀerence

λ

0
104
Diﬀerence

Table 10: Cost metrics for out-of-sample scenarios.
Expected value
($ · 106)
1.78
1.54
-13.5%

P95
($ · 106)
2.14
1.74
-18.7%

P5
($ · 106)
1.60
1.35
-15.6%

P95−P5
($ · 106)
0.54
0.39
-27.7%

In view of evaluating economic eﬀects of the regularization, Table 11 presents some additional

important marked-oriented metrics that exploits the economic impact of the regularization process

in spot prices (calculated in this work as the marginal operating costs).

20

Table 11: Annual-average spot price metrics for out-of-sample scenarios.

λ

P5

E[.]

P95

Average

Time

($/MWh)
340
148

($/MWh)
622
195

($/MWh)
1058
314

0
104

Uncertainty Variability
($/MWh)
719
166

(%)
199
27

Besides the usual metrics as percentiles and expected value for the average-annual spot prices

(all extracted from the twelve central months of operation – steady state), the average uncertainty

level, calculated as the diﬀerence between the monthly P95 and P5, and the time variability, deﬁned

according to expression (33), are also presented.

T imeV ariability =

1
T − 1

T
(cid:88)

(cid:88)

pω

ω

t=2

(cid:12)
(cid:12)
(cid:12)

πt,ω − πt−1,ω
πt−1,ω

(cid:12)
(cid:12)
(cid:12).

(33)

Noticeably, the regularization policy also promotes a remarkable stability on spot prices. Such

eﬀect is characterized by the signiﬁcant drop on the average uncertainty level and time variability

indices when compared to the non-regularized policy. Additionally, the average of the annual

spot-price and its P95 also exhibit relevant reductions, which are desirable characteristic generally

associated with eﬃciency signals for market players.

4.2.3. Sensitivity Analysis

Finally, we present in Figure 11 a sensitivity analysis on the out-of-sample gain obtained with

the regularized LDR (with the best value of λ) with respect to the number of scenarios N used in

the estimation process. It is possible to see that, although it is well known that the gain should

decay to zero as N (and M ) grows to inﬁnity, in practice, the size of tractable instances does not

comport large sample sizes in the estimation step (see [8] and other applications).

In our case

study, for N ≥ 500, the model could not be solved and the computer run out of memory.

Figure 11: Sensitivity analysis of the regularization beneﬁt in the out-of-sample with the estimation sample size N .
Left axis (bars) – out-of-sample gains obtained with the regularization procedure. Right axis (line) – computational
time took for the estimation process.

Although more powerful computers or decomposition algorithms could be implemented, in prac-

tical applications, SAA instances are in general constrained to ﬁnite (small) sample sizes. This

is especially true in real industry applications, where we need to consider very detailed models

21

to avoid unrealistic (and even infeasible) solutions.10 Notwithstanding, previously reported work

on two-stage LDR also rely on small sample sizes (see [8] and [41]). In this context, we can see

in Figure 11 that for all tractable instances analyzed in this case study, the proposed regularized

LDR improved the SAA result by more than 10%11, which is a considerable amount for practical

applications. Therefore, the above results, although empirical and problem based, provide large evi-

dences in favor to corroborate the initial hypothesis, namely, that LDR-based policies estimated with

AdaLASSO-regularization can provide relevant cost savings under out-of-sample (unseen) data.

5. Conclusion

This work raised awareness of the in-sample overﬁt threat featured by linear decision rules

(LDRs) applied to solve multistage stochastic linear problems (MSLP). In this context, we pro-

posed a new regularized LDR-based policy considering the AdaLASSO, which takes into account

the tradeoﬀ between a better in-sample ﬁt and the over parameterization of the LDR. Thus,

we tested the following hypothesis: non-regularized LDR overﬁts in-sample data and more par-

simonious LDR-based policies estimated with AdaLASSO-regularization can provide relevant cost

savings under unseen out-of-sample data. We found strong evidences that this hypothesis is true

based on our computational results.

To study the proposed framework and test the aforementioned hypothesis, we used the well-

known and representative long-term hydrothermal dispatch planning problem (see [4]) considering

a basis of nonlinear functions in the two-stage LDR (see [8]). Within the limitations of our case

study (selected problem and data), results show that, in the out-of-sample test, the regularized LDR

achieved relevant cost savings in comparison to the classical non-regularized LDR approach (18.5%

on average and 25.0% for the 95-percentile in a single-reservoir case study and 13.5% on average

and 18.7% for the 95-percentile of the costs in a multi-reservoir case study). The AdaLASSO

regularization resulted in a reduction greater or equal to 82.9% of the total number of selected

coeﬃcients in both case studies. This fact highlights the importance of the regularization scheme

to ﬁnd the subset of parameters that performs best in out-of-sample. Interestingly, our case study

also revealed a relevant eﬀect of the best regularization on dual variables. The uncertainty level

and time variability metrics of spot prices (marginal operating costs extracted from a steady state

year) are signiﬁcantly reduced when compared to the non-regularized policy. The expected value

and the 95-percentile of the annual–average spot prices also show a relevant reduction under the

best regularization penalty. These facts provide strong evidences that the proposed regularization

approach constitutes an important step, worth analysing, when using LDRs to solve MSLP.

Notwithstanding, relevant and interesting challenges arise from the utilization of LASSO-based

regularization terms to address the overﬁt issue when using LDRs to address MSLP. For instance,

the identiﬁcation of the best penalty parameter, λ, requires a line search procedure running the

10For instance, the oﬃcial dispatch planning models used in Brazil use very few scenarios (less than 40). Planners
also rely on models with very few scenarios due to the huge number of constraints to model physical aspects needed
to considered to ensure feasible solutions (see [44] for a realistic planning study based on a new decomposition
algorithm and detailed comments on the subject).

11All reported gains are statistically signiﬁcant at a signiﬁcance level lower than 0.01.

22

MSLP for each point inspected. Interestingly, results suggest that the best parameter is stable

across instances, which is a merit of this approach as one might not need to calibrate the parameter

every time. Additionally, the use of sensitivity analysis can help to identify regions for which the

LDR remains unchanged and thereby a recalculation is not necessary.

We highlight four possible avenues for future research in this topic: 1) the study of theoretic

results based on convergence results for two-stage sample average approximation such as [45]

and [46]; 2) the study of diﬀerent applications in which traditional methods’ hypothesis, such

as convexity in the case of the SDDP, fail to comply with the problem at hand, e.g., non-convex

(nonlinear) hydro production curves, unit-commitment (binary) constraints, revenue maximization

with spot-price uncertainty, just to mention a few; 3) the study of diﬀerent basis of functions

and regularization methods, e.g., (cid:96)2-norm and combinations between (cid:96)1 and (cid:96)2-norm (which are

associated with ridge regression and Elastic Net) with interesting and complementary properties

to AdaLASSO; ﬁnally 4) the study of interactions between scenario reduction techniques and

regularization.

References

[1] J. R. Birge, F. Louveaux, Introduction to stochastic programming, Springer Science & Busi-

ness Media, 2011.

[2] W.-K. Mak, D. P. Morton, R. K. Wood, Monte carlo bounding techniques for determining

solution quality in stochastic programs, Operations research letters 24 (1-2) (1999) 47–56.

[3] A. Street, D. Vallad˜ao, Real-world impact of stochastic programming: The electricity sector

case, The Newsletter of the Stochastic Programming Society 2 (1) (2021) 14–17.

URL https://stoprog.org/sites/default/files/sps_newsletter_2.pdf

[4] M. V. F. Pereira, L. M. V. G. Pinto, Multi-stage stochastic optimization applied to energy

planning, Mathematical Programming 52 (1) (1991) 359–375. doi:10.1007/BF01582895.

URL https://doi.org/10.1007/BF01582895

[5] A. B. Philpott, Z. Guan, On the convergence of stochastic dual dynamic programming and

related methods, Oper. Res. Lett. 36 (4) (2008) 450–455. doi:10.1016/j.orl.2008.01.013.

URL http://dx.doi.org/10.1016/j.orl.2008.01.013

[6] A. Street, A. Brigatto, D. M. Vallad˜ao, Co-optimization of energy and ancillary services for

hydrothermal operation planning under a general security criterion, IEEE Transactions on

Power Systems 32 (6) (2017) 4914–4923. doi:10.1109/TPWRS.2017.2672555.

[7] A. Papavasiliou, Y. Mou, L. Cambier, D. Scieur, Application of stochastic dual dynamic

programming to the real-time dispatch of storage under renewable supply uncertainty, IEEE

Transactions on Sustainable Energy 9 (2) (2018) 547–558. doi:10.1109/TSTE.2017.2748463.

[8] M. Bodur, J. R. Luedtke, Two-stage linear decision rules for multi-stage stochastic program-

ming, Mathematical Programming (2018) 1–34.

23

[9] C. C. Holt, F. Modigliani, H. A. Simon, A Linear Decision Rule for Production and Employ-

ment Scheduling, Management Science 2 (1) (1955) 1–30.

[10] C. Revelle, E. Joeres, W. Kirby, The Linear Decision Rule in Reservoir Management and

Design: 1, Development of the Stochastic Model, Water Resources Research 5 (4) (1969)

767–777. doi:10.1029/WR005i004p00767.

[11] C. Revelle, W. Kirby, Linear Decision Rule in Reservoir Management and Design: 2. Per-

formance Optimization, Water Resources Research 6 (4) (1970) 1033–1044. doi:10.1029/

WR006i004p01033.

[12] D. P. Loucks, Some Comments on Linear Decision Rules and Chance Constraints, Water

Resources Research 6 (2) (1970) 668–671.

[13] J. Eastman, C. ReVelle, Linear decision rule in reservoir management and design: 3. Direct

capacity determination and intraseasonal constraints, Water Resources Research 9 (1) (1973)

29–42. doi:10.1029/WR009i001p00029.

[14] J. Gundelach, C. ReVelle, Linear decision rule in reservoir management and design: 5.

A general algorithm, Water Resources Research 11 (2) (1975) 204–207.

doi:10.1029/

WR011i002p00204.

[15] C. Revelle, J. Gundelach, Linear Decision Rule in Reservoir Management and Design 4. A

Rule That Minimizes Output Variance, Water Resources Research 11 (2).

[16] C. Gauvin, E. Delage, M. Gendreau, Decision rule approximations for the risk averse reservoir

management problem, European Journal of Operational Research 261 (1) (2017) 317–336.

[17] G. C. Calaﬁore, Multi-period portfolio optimization with linear control policies, Automatica

44 (10) (2008) 2463–2473.

[18] M. Zugno, J. M. Morales, H. Madsen, Robust management of Combined Heat and Power

systems via linear decision rules, ENERGYCON 2014 - IEEE International Energy Conference

(2014) 479–486doi:10.1109/ENERGYCON.2014.6850470.

[19] S. V. Braaten, O. Gjønnes, K. Hjertvik, S. E. Fleten, Linear Decision Rules for Seasonal

Hydropower Planning: Modelling Considerations, Energy Procedia 87 (1876) (2016) 28–35.

doi:10.1016/j.egypro.2015.12.354.

URL http://dx.doi.org/10.1016/j.egypro.2015.12.354

[20] R. Dominguez, A. J. Conejo, M. Carrion, Investing in Generation Capacity: A Multi-Stage

Linear-Decision-Rule Approach, IEEE Transactions on Power Systems 31 (6) (2016) 4784–

4794. doi:10.1109/TPWRS.2016.2522505.

[21] R. Egging, S. E. Fleten, I. Gronvik, A. Hadziomerovic, N. Ingvoldstad, Linear Decision Rules

for Hydropower Scheduling under Uncertainty, IEEE Transactions on Power Systems 32 (1)

(2017) 103–113. doi:10.1109/TPWRS.2016.2555360.

24

[22] A. Lorca, X. A. Sun, Multistage robust unit commitment with dynamic uncertainty sets and

energy storage, IEEE Transactions on Power Systems 32 (3) (2017) 1678–1688.

[23] A. Shapiro, D. Dentcheva, A. Ruszczynski, Lectures on stochastic programming: modeling

and theory, SIAM, 2021.

[24] C. G. S. Sikora, Benders’ decomposition for the balancing of assembly lines with stochastic

demand, European Journal of Operational Research 292 (1) (2021) 108–124.

[25] E. Nikzad, M. Bashiri, B. Abbasi, A matheuristic algorithm for stochastic home health care

planning, European Journal of Operational Research 288 (3) (2021) 753–774.

[26] H. Hoeltgebaum, C. Fernandes, A. Street, Generating joint scenarios for renewable generation:

The case for non-gaussian models with time-varying parameters, IEEE Transactions on Power

Systems 33 (6) (2018) 7011–7019. doi:10.1109/TPWRS.2018.2838050.

[27] G. Bodin, R. Saavedra, C. Fernandes, A. Street, Scoredrivenmodels. jl: a julia package for

generalized autoregressive score models, arXiv preprint arXiv:2008.05506.

[28] A. Velloso, A. Street, D. Pozo, J. M. Arroyo, N. G. Cobos, Two-stage robust unit commitment

for co-optimized electricity markets: An adaptive data-driven approach for scenario-based

uncertainty sets, IEEE Transactions on Sustainable Energy 11 (2) (2019) 958–969.

[29] H. Zou, The adaptive lasso and its oracle properties, Journal of the American statistical

association 101 (476) (2006) 1418–1429.

[30] C. Giraud, Introduction to high-dimensional statistics, Chapman and Hall/CRC, 2014.

[31] G. Ciuperca, Adaptive LASSO model selection in a multiphase quantile regression, Statistics

50 (5) (2016) 1100–1131. doi:10.1080/02331888.2016.1151427.

URL http://dx.doi.org/10.1080/02331888.2016.1151427

[32] J. Blanchet, Y. Kang, K. Murthy, Robust wasserstein proﬁle inference and applications to

machine learning, Journal of Applied Probability 56 (3) (2019) 830–857.

[33] R. P. Masini, M. C. Medeiros, E. F. Mendes, Machine learning advances for time series fore-

casting, arXiv preprint arXiv:2012.12802.

[34] R. Tibshirani, Regression shrinkage and selection via the lasso, Journal of the Royal Statistical

Society. Series B (Methodological) 58 (1) (1996) 267–288.

URL http://www.jstor.org/stable/2346178

[35] D. Bertsimas, J. Dunn, Machine learning under a modern optimization lens, Dynamic Ideas

LLC, 2019.

[36] P. Mohajerin Esfahani, D. Kuhn, Data-driven distributionally robust optimization using the

wasserstein metric: Performance guarantees and tractable reformulations, Mathematical Pro-

gramming 171 (1) (2018) 115–166.

25

[37] D. Bertsimas, S. Shtern, B. Sturt, Two-stage sample robust optimization, Operations Research

70 (1) (2022) 624–640.

[38] C. A. Gamboa, D. M. Vallad˜ao, A. Street, T. Homem-de Mello, Decomposition methods for

wasserstein-based data-driven distributionally robust problems, Operations Research Letters

49 (5) (2021) 696–702.

[39] A. Street, D. Vallad˜ao, A. Lawson, A. Velloso, Assessing the cost of the hazard-decision

simpliﬁcation in multistage stochastic hydrothermal scheduling, Applied Energy 280 (2020)

115939.

[40] A. Brigatto, A. Street, D. Valladao, Assessing the Cost of Time-Inconsistent Operation Policies

in Hydrothermal Power Systems, IEEE Trans. Power Syst PP (99) 1–9. doi:10.1109/TPWRS.

2017.2672204.

[41] M. Daryalal, M. Bodur, J. R. Luedtke, Lagrangian dual decision rules for multistage stochastic

mixed integer programming, arXiv preprint arXiv:2001.00761.

[42] O. Dowson, L. Kapelevich, SDDP.jl: a Julia package for stochastic dual dynamic program-

ming, INFORMS Journal on ComputingArticles in Advance. doi:https://doi.org/10.

1287/ijoc.2020.0987.

[43] H. Hoeltgebaum, C. Fernandes, A. Street, Generating joint scenarios for renewable generation:

The case for non-gaussian models with time-varying parameters, IEEE Transactions on Power

Systems 33 (6) (2018) 7011–7019.

[44] A. Soares, A. Street, T. Andrade, J. D. Garcia, An integrated progressive hedging and

benders decomposition with multiple master method to solve the brazilian generation ex-

pansion problem, IEEE Transactions on Power Systems 37 (5) (2022) 4017–4027. doi:

10.1109/TPWRS.2022.3141993.

[45] S. Ahmed, A. Shapiro, E. Shapiro, The sample average approximation method for stochastic

programs with integer recourse, Submitted for publication (2002) 1–24.

[46] A. J. Kleywegt, A. Shapiro, T. Homem-de Mello, The sample average approximation method

for stochastic discrete optimization, SIAM Journal on Optimization 12 (2) (2002) 479–502.

26

