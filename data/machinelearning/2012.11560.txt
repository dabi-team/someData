Application of Quantum Machine Learning using the
Quantum Variational Classiﬁer Method to High
Energy Physics Analysis at the LHC on IBM
Quantum Computer Simulator and Hardware with
10 qubits

Sau Lan Wu1*, Jay Chan1, Wen Guan1, Shaojun Sun1, Alex Wang1, Chen Zhou1
Miron Livny2
Federico Carminati3, Alberto Di Meglio3
Andy C. Y. Li4, Joseph Lykken4, Panagiotis Spentzouris4
Samuel Yen-Chi Chen5, Shinjae Yoo5
Tzu-Chieh Wei6

1Department of Physics, University of Wisconsin, Madison WI, USA
2Department of Computer Sciences, University of Wisconsin, Madison WI, USA
3CERN Quantum Technology Initiative, IT Department, CERN, Geneva, Switzerland
4Quantum Institute, Fermi National Accelerator Laboratory, Batavia, IL, USA
5Computational Science Initiative, Brookhaven National Laboratory, Upton, NY, USA
6C.N. Yang Institute for Theoretical Physics, State University of New York at Stony Brook,
Stony Brook, NY, USA

1
2
0
2

g
u
A
1
2

]
h
p
-
t
n
a
u
q
[

2
v
0
6
5
1
1
.
2
1
0
2
:
v
i
X
r
a

 
 
 
 
 
 
Page 2

Abstract. One of the major objectives of the experimental programs at the LHC is
the discovery of new physics. This requires the identiﬁcation of rare signals in immense
backgrounds. Using machine learning algorithms greatly enhances our ability to achieve
this objective. With the progress of quantum technologies, quantum machine learning could
become a powerful tool for data analysis in high energy physics. In this study, using IBM gate-
model quantum computing systems, we employ the quantum variational classiﬁer method in
two recent LHC ﬂagship physics analyses: t¯tH (Higgs boson production in association with a
top quark pair, probing the Higgs boson couplings to the top quark) and H → µ+µ− (Higgs
boson decays to two muons, probing the Higgs boson couplings to second-generation fermions).
We have obtained early results with 10 qubits on the IBM quantum simulator and the IBM
quantum hardware. With small training samples of 100 events on the quantum simulator, the
quantum variational classiﬁer method performs similarly to classical algorithms such as SVM
(support vector machine) and BDT (boosted decision tree), which are often employed in LHC
physics analyses. On the quantum hardware, the quantum variational classiﬁer method has
shown promising discrimination power, comparable to that on the quantum simulator. This
study demonstrates that quantum machine learning has the ability to diﬀerentiate between
signal and background in realistic physics datasets. We foresee the usage of quantum machine
learning in future high-luminosity LHC physics analyses, including measurements of the Higgs
boson self-couplings and searches for dark matter.

Page 3

The discovery of the Higgs boson by the ATLAS and CMS experiments at the Large Hadron
Collider (LHC) in 2012 [1, 2] was a major milestone for high energy physics. Since then,
LHC experiments have been using the Higgs boson as a tool to pursue the discovery of new
physics. The discovery of new physics requires the identiﬁcation of rare signals against immense
backgrounds. Using machine learning greatly enhances our ability to achieve this objective.

The intersection between machine learning and quantum computing has been referred
to as quantum machine learning, and can possibly oﬀer a valuable alternative to classical
machine learning by providing more eﬃcient solutions [3].
In 2018, a quantum variational
classiﬁer method was experimentally implemented with a quantum circuit of 2 qubits on a
superconducting processor and successfully tested on synthetic datasets [4]. This method
provides “tools for exploring the applications of noisy intermediate-scale quantum computers to
machine learning” [4]. With the progress of quantum technologies, quantum machine learning
could possibly become a powerful tool for data analysis on real-world datasets such as those
seen in high energy physics.

In this study, we employ the quantum variational classiﬁer method in a t¯tH (H → 2 photons)
physics analysis and a H → µ+µ− physics analysis, two recent ﬂagship physics analyses at the
LHC, using IBM gate-model quantum computers. Our goal is to explore and to demonstrate, in
a proof of principle experiment, the potential of quantum computers can be a new computational
paradigm for big data analysis in high energy physics. An earlier study in a ggH (H → 2 photons)
physics analysis using D-wave quantum annealers was performed by A. Mott et al. [5].

Two recent LHC ﬂagship physics analyses: The observation of t¯tH production (Higgs
boson production in association with a top quark pair) in 2018 by the ATLAS and CMS
experiments [6, 7] was a signiﬁcant milestone for the understanding of fundamental particles
It conﬁrmed the interactions between the Higgs boson and the top quark,
and interactions.
which is the heaviest known fundamental particle. The measurement of the Higgs-top coupling
strength could reﬁne our understanding of the Higgs mechanism and provide important handles
to new physics. As t¯tH only accounts for about 1% of the total Higgs boson production at the
LHC, its observation was extremely challenging. Here we address a channel where the Higgs
boson decays into two photons (H → γγ ) and the two top quarks decay into jets. To ensure the
results are as realistic as possible, we closely follow an analysis strategy similar to that employed
by ATLAS [6]. Starting from reconstructed events with two photons and at least three jets, we
train classiﬁers to separate the t¯tH (H → γγ ) signal from the dominant background of this
analysis, the non-resonant two-photon production. See Figure 1 for representative Feynman
diagrams for t¯tH production (a), H → γγ decay (b), and non-resonant two-photon production
(c). The training is using 23 kinematic variables similar to those in [6]: the transverse momentum
pT , pseudo-rapidity η and b-tagging status of up to 6 leading jets, the magnitude of the missing
transverse momentum, as well as the pT /mγγ (mγγ denotes invariant mass of the photon pair)
and η of the two photons.

The searches for H → µ+µ− decay (Higgs boson decay into two muons) at the ATLAS and
CMS experiments [8, 9] have become one of the most important topics in the LHC physics
program. Although the coupling between the Higgs boson and third-generation fermions (e.g.
top quark) has been observed, currently there exist only ﬁrst indications of the coupling between
the Higgs boson and second-generation fermions. H → µ+µ− decay is the most promising
process by which to observe such a coupling at the LHC. The strength of the Higgs-muon
coupling could be signiﬁcantly modiﬁed by new physics. With more data in the future, the LHC
experiments could establish the Higgs couplings to muons, or exclude the Higgs-muon coupling:
both will be an exciting discovery. In searches for H → µ+µ− decay, the challenge is mainly
due to the small H → µ+µ− decay branching ratio of about 0.02%. Again following an analysis
strategy similar to that used by ATLAS [8], we divide reconstructed two-muon events into several

Page 4

nj (jet multiplicity) channels, and focus on the nj ≥ 2 channel to target vector boson fusion
(VBF) Higgs production, whose signature is two forward jets. We train classiﬁers to distinguish
between the H → µ+µ− signal and the dominant background of this analysis, production of a
pair of muons through the exchange of a Z boson or a virtual photon (Z/γ∗ → µµ). See Figure 1
for representative Feynman diagrams for VBF Higgs production (d), H → µ+µ− decay (e), and
Z/γ∗ → µµ production (f). The training is based on 13 kinematic variables similar to those
in [8]: the pT and rapidity Y of the two-muon system, the absolute value of the cosine of the
lepton decay angle cos θ∗ in the Collins-Soper frame, the pT and η of the two leading jets, the
relative azimuthal angle of each jet with respect to the di-muon system, the pT , Y and invariant
mass of the two-jet system, as well as the relative azimuthal angle between the two-jet system
and the two-muon system.

(a)

(d)

(b)

(e)

(c)

(f)

Figure 1. Representative Feynman diagrams for (a) t¯tH production, (b) H → γγ decay, (c)
non-resonant two-photon production, (d) VBF Higgs production, (e) H → µ+µ− decay, and
(f) Z/γ∗ → µµ production. In these diagrams, H denotes a Higgs boson, g denotes a gluon, q
denotes a quark, t denotes a top quark, b denotes a bottom quark, µ denotes a muon, W denotes
a W boson, Z denotes a Z boson, V denotes a W boson or Z boson, and γ denotes a photon.

In both the t¯tH and H → µ+µ− cases, we generate the signal and background events using
Madgraph5 aMC@NLO [10] plus Pythia6 [11]. The center-of-mass energy of the proton-proton
collisions of the generated events is set to 13 TeV (same as the ATLAS publications). For each
generated event, we simulate the detector response using Delphes [12]. A Principal Component
Analysis (PCA) method [13, 14] is employed for data compression, converting the kinematic
variables to a smaller number of PCA variables so that the number of encoded variables matches
the number of available qubits (which is 10 in this study). After PCA, the data is transformed
using MinMaxScaler in the scikit-learn package [15] so that it ranges from −π to π. The events
are then passed to the machine learning algorithms, whether classical or quantum.

Page 5

Quantum variational classiﬁer algorithm and workﬂow: Following [4], we use the
quantum variational classiﬁer algorithm to classify physics events of interest from background
events. This quantum approach exploits the mapping of classical input data to an exponentially
large quantum feature space, which is based on quantum circuits that are hard to simulate
classically. It can be summarized in four main steps:

(i) Apply a feature map circuit UΦ((cid:126)x) to encode the input data (cid:126)x (containing 10 PCA variables)
into a quantum state |Φ((cid:126)x)(cid:105), as shown in Figure 2(a). In our study the feature map encodes
N classical variables to the quantum state space of a N-qubit system.

(ii) Apply a quantum variational circuit W ((cid:126)θ) parameterized by gate angles (cid:126)θ, as shown in

Figure 2(b). Here the variational circuit takes the form

W ((cid:126)θ) = Urot(θ) Uent . . . Urot(θ) Uent

(1)

where Urot(θ) refers to a variational circuit consisting of rotations on diﬀerent qubits and
Uent refers to entanglement unitary operations [4].

(iii) Measure the qubit state in the computational basis. The qubit measurement error is one
of the largest error sources on the quantum hardware and results in imprecision on the
classiﬁcation result. To reduce this imprecision, we entangle every two qubits and then
measure half of the N qubits, as shown in Figure 2(c). Additionally, a measurement error
mitigation method implemented by the Qiskit framework [16] is applied when measuring
qubits. This error mitigation method derives a relation matrix between the ideal results
and the noisy results, which is later used to correct the noisy results.

(iv) Classify the state through the action of a diagonal operator f in computational basis with
the eigenvalue being either +1 or −1. A discriminant is evaluated for the input data (cid:126)x
according to

(cid:104)Φ((cid:126)x)|W †((cid:126)θ)2−1(1 + f )W ((cid:126)θ)|Φ((cid:126)x)(cid:105)

(2)

and used to assign an output label y ∈ {1, 0} denoting either a signal or background
process [4].

During the training phase, a set of input data (cid:126)x and corresponding outputs y are used to
train the circuit W((cid:126)θ) to reproduce the correct classiﬁcation. The set of optimized parameters
(cid:126)θ is then kept ﬁxed for all future classiﬁcations of the physical data.

Page 6

(a)

(b)

(c)

Figure 2.
Quantum circuits used in our quantum variational classiﬁer studies. (a) The
quantum feature map. First, Hadamard gates H initialize every qubit to an equal superposition
of all basis states. Then the feature map circuit UΦ((cid:126)x) encodes classical variables to quantum
states by applying a phase rotation RZ of an angle xi. The parameterization of xi with the
corresponding PCA variable is slightly diﬀerent between the t¯tH and the H → µ+µ− cases. The
feature map circuits can be duplicated multiple times with a depth parameter. (b) The quantum
variational circuits W ((cid:126)θ). The variational rotation circuit Urot(θ) is parameterized by θ and is
followed by the entanglement circuit Uent. Urot(θ) consists of two rotations, RY and RZ, on
every qubit with parameterized θ. For the entanglement step Uent, we use the controlled phase
gate CZ to entangle adjacent qubits. In order to parallelize the qubit operations, we optimized
the Uent circuit to reduce execution dependency by at ﬁrst only entangling each even qubit to
its following odd qubit and then only entangling each odd qubit to its following even qubit.
Multiple copies of the variational and entanglement circuits with another depth parameter can
be applied to increase the number of degrees of freedom in a machine learning model [4]. (c) The
measurement circuit M(half ). To measure half of the qubits, a controlled phase gate operation
CZ is applied on every two qubits and only one of the two entangled qubits is measured.

Page 7

Result from the IBM Quantum Computer Simulator with 10 qubits: We employ
quantum machine learning with 10 qubits on the ibmq QasmSimulator [16] to classify signal
and background processes for the t¯tH analysis and the H → µ+µ− analysis. The ibmq
QasmSimulator simulates executions and measurements on quantum circuits of the IBM
quantum computer hardware. The simulation incorporates a noise model generated from the
properties of real hardware device. In each analysis, we apply the quantum variational classiﬁer
algorithm to ten independent datasets, each consisting of 100 events for training and 100 events
for testing. The quantum circuits are optimized to best ﬁt the constraints imposed by the
hardware (e.g., qubit connectivity, gate set availability, and hardware noise), as well as the
nature of the data. In the optimized conﬁguration, the feature map depth is 1 and the variational
circuit depth is 1. With the present status of our accessed hardware, the limited circuit depths
are adopted to overcome the hardware noise when utilizing 10 qubits. The circuit implementation
uses linear qubit connectivity. The Spall’s simultaneous perturbation stochastic approximation
(SPSA) algorithm [17, 18] is used as the optimizer for the variational circuit parameters (cid:126)θ in
the training process. With the same ten datasets and the same 10 variables processed with the
PCA method, we also train a classical SVM [19] classiﬁer using the scikit-learn package [15]
and a BDT [20, 21] classiﬁer using the XGBoost package [22]. The classical SVM and the BDT
serve as benchmarks for classical machine learning algorithms. Hyper-parameter tuning was
performed on these classical algorithms.

To study the discrimination power of each algorithm for both t¯tH and H → µ+µ− , the test-
ing events of the ten datasets are combined to make Receiver Operating Characteristic (ROC)
curves as a benchmark in the plane of background rejection versus signal eﬃciency, as shown in
Figure 3. We observe that in both the t¯tH analysis and the H → µ+µ− analysis, the quantum
variational classiﬁer method on the ibmq QasmSimulator (blue) performs similarly to the classi-
cal SVM (yellow) and the BDT (green). We quantify the discrimination power of each classiﬁer
by the AUC (area under the ROC curve). In the t¯tH analysis, the AUC for the quantum varia-
tional classiﬁer method reaches 0.81±0.04 on the ibmq QasmSimulator, compared to 0.83±0.04
for the classical SVM and 0.83±0.06 for the BDT. Similarly, in the H → µ+µ− analysis, the
AUC for the quantum variational classiﬁer method reaches 0.83±0.05 on the ibmq QasmSimula-
tor, compared to 0.82±0.03 for the classical SVM and 0.80±0.06 for the BDT. The quoted errors
are the standard deviations for the AUC values of the ten datasets. This demonstrates the quan-
tum algorithm can accurately distinguish signal from background on realistic physics datasets;
the performance is comparable to (within the margin of error) state-of-the-art classical methods.

Ultimately, we can select events based on the classiﬁer discriminant to maximize the quantity
S/(cid:112)(B), where S is the number of signal events and B is the number of background events
remaining after the selection. S/(cid:112)(B) is an approximation of the signal signiﬁcance and is
typically correlated with the classiﬁer AUC, as both indicate the degree of separation between
signal and background. In the t¯tH analysis, a selection on the variational quantum classiﬁer
discriminant with a signal acceptance of 0.70 is associated with a background rejection of
0.78 (see the ROC curve in Figure 3 (a)), and hence improves S/(cid:112)(B) by approximately
0.70/(cid:112)(0.22) − 1 = 50% with respect to no selection. Similarly, in the H → µ+µ− analysis,
a selection on the variational quantum classiﬁer discriminant with a signal acceptance of 0.70
is associated with a background rejection of 0.84 (see the ROC curve in Figure 3 (b)), hence
improving S/(cid:112)(B) by approximately 0.70/(cid:112)(0.16) − 1 = 75%.

Page 8

(a)

(b)

Figure 3. The Receiver Operating Characteristic (ROC) curves (as a benchmark in the plane
of background rejection versus signal eﬃciency) of the quantum variational classiﬁer method on
the ibmq QasmSimulator (blue), the classical SVM (yellow), and the BDT (green) for (a) the
t¯tH analysis and (b) the H → µ+µ− analysis. In each analysis, the classiﬁers are constructed
using ten independent datasets, each consisting of 100 events for training and 100 events for
testing. All classiﬁers are trained with the same 10 variables processed with the PCA method.
In this study, 10 qubits are employed on the quantum computer simulator. To visualize the
discrimination power of each algorithm, the testing events of the ten datasets are combined to
make the ROC curves. We observe that the quantum variational classiﬁer method on the ibmq
QasmSimulator performs similarly to the classical SVM and the BDT for both the t¯tH analysis
and the H → µ+µ− analysis.

Page 9

Result from the IBM Quantum Computer Hardware with 10 qubits: At this point,
it is interesting to assess the potential of quantum hardware calculations on the classiﬁcation
of the data presented in the previous section, and quantify the eﬀect of the device noise.
For the t¯tH analysis and the H → µ+µ− analysis, we employ the quantum variational
classiﬁer algorithm with 10 qubits on the “ibmq boeblingen” and “ibmq paris” quantum computer
hardware. “ibmq boeblingen” is a 20-qubit quantum processor and “ibmq paris” is a 27-qubit
quantum processor. Both are based on superconducting electronic circuits. Due to current
limitation of the access time to the quantum processors, the quantum variational classiﬁer
algorithm is only applied to one of the ten datasets for each physics analysis. We pick the
dataset whose simulator AUC is closest to the average simulator AUC of the ten datasets. The
circuit, optimizer, and error mitigation conﬁguration on the hardware is kept the same as for
the simulator jobs.

The ROC curves of the quantum variational classiﬁer algorithm on the ‘ibmq boeblingen”
quantum hardware (for t¯tH ) and “ibmq paris” quantum hardware (for H → µ+µ− ) are shown
in red in Figure 4. The ROC curves for the ibmq QasmSimulator with the same datasets are
overlaid in blue. We observe that for the quantum variational classiﬁer method, the quantum
simulator and quantum hardware results appear to be in good agreement. In the t¯tH analysis,
the quantum hardware AUC is 0.82, while the quantum simulator AUC is 0.83. Similarly, in the
H → µ+µ− analysis, the quantum hardware AUC is 0.81, while the quantum simulator AUC
is 0.83. In each analysis, the diﬀerence between the hardware AUC and the simulator AUC is
found to be compatible with the test sample statistical error evaluated using a Bootstrapping
re-sampling method. With the circuit conﬁguration optimized for 10 qubits, the gate-model
quantum computers have achieved reasonable performance in exploiting a quantum state space
with 210 dimensions to distinguish signal from background at the LHC.

Figure 5 shows the evolution of the loss function versus the number of iterations during
the training process of the quantum variational classiﬁer on the hardware (red) and simulator
(blue) for the t¯tH analysis and the H → µ+µ− analysis. The number of iterations indicates
the number of times the variational circuit parameters are updated in the training process. The
empirical loss function is deﬁned by the error probability of incorrect assignment compared to
the exact solutions available for the training set. During the training process, the loss function
is minimized to penalize misassignment and to optimize classiﬁer parameters. The loss function
improves and converges as the number of iterations increases, indicating that the quantum
algorithm on hardware is indeed learning the diﬀerence between signal and background in a
realistic high energy physics analysis at the LHC.

In our study, 200 hours are required to run 500 training iterations on 100 events of the
t¯tH or H → µ+µ− analyses on quantum hardware. This is longer than that of the classical
algorithms because today’s quantum hardware is not yet fully mature. However, with the present
rapid developments in quantum hardware, we expect in the future to see speed ups in quantum
machine learning applications to high energy physics.

Page 10

(a)

(b)

Figure 4. The Receiver Operating Characteristic (ROC) curves of the quantum variational
classiﬁer method with the “ibmq boeblingen” and “ibmq paris” quantum computer hardware
(red) and with the ibmq QasmSimulator (blue) for (a) the t¯tH analysis (using “ibmq boeblingen”)
and (b) the H → µ+µ− analysis (using “ibmq paris”). For each physics analysis, one dataset
consisting of 100 events for training and 100 events for testing is utilized to construct the
classiﬁers. This dataset is one of the ten datasets used in Figure 3. All classiﬁers are trained with
the same 10 variables processed with the PCA method. In this study, 10 qubits are employed
on the quantum computer hardware and the quantum computer simulator. To visualize the
discrimination power of both the quantum simulator and quantum hardware, the testing events
of the dataset are used to make the ROC curves. We observe that, for the quantum variational
classiﬁer method, the quantum simulator and quantum hardware results appear to be in good
agreement.

Page 11

(a)

(b)

Figure 5. The evolution of the loss function versus the number of iterations during the training
process of the quantum variational classiﬁer on the quantum computer hardware (red) and
quantum computer simulator (blue) for (a) the t¯tH analysis and (b) the H → µ+µ− analysis.
The number of iterations indicates the number of times the variational circuit parameters are
updated in the training process. The empirical loss function is deﬁned by the error probability
of incorrect assignment compared to the exact solutions available for the training set. The
loss function improves and converges as the number of iterations increases, indicating that the
quantum algorithm on hardware is indeed learning the diﬀerence between signal and background.

Page 12

Conclusion: In this study, we have obtained early results in the application of quantum
machine learning with 10 qubits on the imbq QasmSimulator and the “ibmq boeblingen” and
t¯tH and
“ibmq paris” quantum hardware to two recent LHC ﬂagship physics analyses:
H → µ+µ− . t¯tH , Higgs boson production in association with a top quark pair, probes the Higgs
boson couplings to the top quark, while H → µ+µ− , Higgs boson decays to two muons, probes
the Higgs boson couplings to second-generation fermions. In this study we do not attempt to
do a complete analysis of t¯tH and H → µ+µ− . Rather our goal is to perform proof of principle
in using quantum machine learning compared with popular classical machine learning methods,
BDT for example. With small training samples of 100 events, the quantum variational classiﬁer
method on the ibmq QasmSimulator performs similarly to the classical SVM algorithm and
the BDT algorithm. The quantum variational classiﬁer method on the quantum hardware has
shown promising discrimination power comparable to that on the quantum simulation.

To study the discrimination power of quantum machine learning classiﬁers, we make use
of Receiver Operating Characteristic (ROC) curves in the plane of background rejection versus
signal eﬃciency as a standard metric in machine learning application for the high energy physics.
We further quantify the discrimination power of the classiﬁers by the AUC (area under the ROC
curve). The use of ROC curves and AUCs to be the metric of discrimination power compared
with classical machine learning methods is inspired by Ref [5]. A diﬀerence is that Ref [5] uses
quantum annealers while our work uses gate-based quantum computers. In the t¯tH analysis,
the quantum hardware AUC is 0.82, while the quantum simulator AUC is 0.83. Similarly, in the
H → µ+µ− analysis, the quantum hardware AUC is 0.81, while the quantum simulator AUC is
0.83. These results demonstrate that quantum machine learning on the hardware of the gate-
model quantum computers has the ability to diﬀerentiate between signal and background in a
realistic high energy physics analysis at the LHC. Furthermore, although we have demonstrated
that the quantum and classical machine learning algorithms perform similarly, with the rapid
advance of the quantum computing technology, the use of quantum machine learning may oﬀer
a “speed up” advantage [3], which can be critical for the future of the high energy physics
community.

In the future, by exploiting the high dimensional feature space deﬁned by a larger number
of qubits and by mitigating the impact of quantum hardware noise, quantum machine learning
classiﬁers could possibly outperform classical classiﬁers. We plan to explore quantum algorithms
to extend our analysis to more qubits and larger sample sizes. Moreover, we plan to apply the
quantum kernel classiﬁer method proposed in [4] to our LHC ﬂagship physics analyses. We
foresee the usage of quantum machine learning in future high-luminosity LHC physics analyses,
including measurements of the Higgs boson self-couplings and searches for dark matter.

Page 13

[1] ATLAS Collaboration, Aad, G. et al. Observation of a new particle in the search for the standard model

Higgs boson with the ATLAS detector at the LHC. Phys. Lett. B 716, 1–29 (2012).

[2] CMS Collaboration, Chatrchyan, S. et al. Observation of a new boson at a mass of 125 GeV with the CMS

experiment at the LHC. Phys. Lett. B 716, 30–61 (2012).

[3] Biamonte, J., Wittek, P., Pancotti, N., Rebentrost, P., Wiebe N., and Lloyd., S. Quantum machine learning.

Nature 549, 195–202 (2017).

[4] Havl´ıˇcek, V., C´orcoles, A. D., Temme, K., Harrow, A. W., Kandala, A., Chow, J. M. and Gambetta, J. M.

Supervised learning with quantum-enhanced feature spaces. Nature 567, 209-212 (2019).

[5] Mott, A., Job, J., Vlimant, J., Lidar D., and Spiropulu, M., Solving a Higgs optimization problem with

quantum annealing for machine learning. Nature 550, 375-379 (2017).

[6] ATLAS Collaboration, Aaboud, M. et al. Observation of Higgs boson production in association with a top

quark pair at the LHC with the ATLAS detector. Phys. Lett. B 784, 173-191 (2018).

[7] CMS Collaboration, Sirunyan, A. M. et al. Observation of ttH Production. Phys. Rev. Lett. 120, 231801

(2018).

[8] ATLAS Collaboration, Aad, G. et al. A Search for the Dimuon Decay of the Standard Model Higgs Boson

with the ATLAS Detector. Phys. Lett. B 812, 135980 (2021).

[9] CMS Collaboration, Sirunyan, A. M. et al. Evidence for Higgs boson decay to a pair of muons. JHEP 01,

148 (2021).

[10] Alwall, J., Frederix, R., Frixione, S., Hirschi, V., Maltoni, F., Mattelaer, O., Shao, H. -S., Stelzer, T.,
Torrielli, P. and Zaro, M. The automated computation of tree-level and next-to-leading order diﬀerential
cross sections, and their matching to parton shower simulations. JHEP 07, 079 (2014).

[11] Sjostrand, T., Mrenna, S. and Skands, P. Z. PYTHIA 6.4 physics and manual. JHEP 05, 026 (2006).
[12] de Favereau, J., Delaere, C., Demin, P., Giammanco, A., Lemaˆıtre, V., Mertens, A. and Selvaggi, M.
DELPHES 3, a modular framework for fast simulation of a generic collider experiment. JHEP 02, 057
(2014).

[13] Pearson, K. On lines and planes of closest ﬁt to systems of points in space. The London, Edinburgh, and

Dublin Philosophical Magazine and Journal of Science, 2, 559-572 (1901).

[14] Jolliﬀe, I. T. Principal component analysis, second edition. Springer Science+Business Media, (2002).
[15] Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P.,
Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay,
E. Scikit-learn: machine learning in python. Journal of Machine Learning Research 12, 2825-2830 (2011).
[16] Aleksandrowicz, G. et al. Qiskit: An Open-source Framework for Quantum Computing. https://qiskit.org

(2019).

[17] Spall, J. C. A one-measurement form of simultaneous perturbation stochastic approximation. Automatica

33, 109–112 (1997).

[18] Spall, J. C. Adaptive stochastic approximation by the simultaneous perturbation method. IEEE Trans.

Automat. Contr. 45, 1839-1853 (2000).

[19] Boser, B. E., Guyon, I. M., Vapnik, V. N. A training algorithm for optimal margin classiﬁers. Proceedings of

the 5th Annual ACM Workshop on Computational Learning Theory, 144-152 (1992).

[20] Friedman, J. H. Stochastic gradient boosting. Computational Statistics & Data Analysis 38, 367-378 (2002).
[21] Hastie, T., Tibshirani, R., Friedman, J. The elements of statistical learning: data mining, inference, and

prediction, second edition. Springer Science+Business Media, (2009).

[22] Chen, T. and Guestrin, C. XGBoost: a scalable tree boosting system. Proceedings of the 22nd ACM SIGKDD

International Conference on Knowledge Discovery and Data Mining, 785-794 (2016).

Page 14

Acknowledgements This project is supported in part by the United States Department of
Energy, Oﬃce of Science, HEP-QIS Research Program, under Award Number DE-SC0020416.
This project is supported in part by the United States Department of Energy, Oﬃce of
Science, Oﬃce of High Energy Physics program under Award Number DE-SC-0012704 and
the Brookhaven National Laboratory LDRD #20-024. This research used resources of the Oak
Ridge Leadership Computing Facility, which is a United States Department of Energy Oﬃce of
Science User Facility supported under Contract DE-AC05-00OR22725. The Wisconsin group
would like to thank the ATLAS Collaboration for the inspiration of the two LHC ﬂagship
analyses used in this publication.

Correspondence and requests

for materials should be addressed to S.L.W.

(Sau.Lan.Wu@cern.ch).

