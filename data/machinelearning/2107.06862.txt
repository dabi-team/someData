Differentiable Programming of Reaction-Diffusion Patterns

Alexander Mordvintsev1, Ettore Randazzo1 and Eyvind Niklasson1

1Google
moralex@google.com

1
2
0
2

n
u
J

2
2

]
E
N
.
s
c
[

1
v
2
6
8
6
0
.
7
0
1
2
:
v
i
X
r
a

Abstract

Reaction-Diffusion (RD) systems provide a computational
framework that governs many pattern formation processes in
nature. Current RD system design practices boil down to
trial-and-error parameter search. We propose a differentiable
optimization method for learning the RD system parameters
to perform example-based texture synthesis on a 2D plane.
We do this by representing the RD system as a variant of
Neural Cellular Automata and using task-speciﬁc differen-
tiable loss functions. RD systems generated by our method
exhibit robust, non-trivial “life-like” behavior.

Introduction

Multicellular organisms build and maintain their body struc-
tures through the distributed process of local interactions
among tiny cells working toward a common global goal.
This approach, often called self-organisation, is drastically
different from the way most human technologies work. We
are just beginning to scratch the surface of integrating some
of nature’s “best practices” into technology.

In 1952, Alan Turin wrote his seminal work, “The Chem-
ical Basis of Morphogenesis” (Turing, 1952), in which he
proposed that pattern formation in living organisms can be
controlled by systems of chemical substances called mor-
phogens. Simultaneous processes of chemical Reactions-
Diffusion (RD) of these substances provide the sufﬁcient
biocomputation platform to execute distributed algorithms
of pattern formation (Kondo and Miura, 2010; Landge et al.,
2019).

Even a system of just two interacting substances (e.g.
Gray-Scott) can produce a great diversity of patterns and in-
teresting behaviours (Pearson, 1993). As is often the case
with complex emergent behaviours of simple systems, it is
very difﬁcult ﬁnd model parameters that produce a particu-
lar, predeﬁned behaviour. Most of the time researchers use
hand-tuned reaction rules, random and grid search over the
parameter space for the combinations with the desired prop-
erties. Procedural texture synthesis is one of the best known
applications for this type of parameter tuning (Witkin and
Kass, 1991; Turk, 1991). In this paper, we propose to use

differentiable optimization as an alternative to such a trial-
and-error process.

The task of determining the sets of parameters that lead
to desired behaviors becomes even more important as we
enter the realm of artiﬁcial life and synthetic biology. The
work of Scalise and Schulman (2014) is a remarkable exam-
ple of an attempt to design a ﬂexible modular framework for
RD-based spatial programming. The authors demonstrate
(at least in simulation) a way to combine a set of basic com-
putational primitives, implemented as RD systems of DNA
strands, into multistage programs that generate non-trivial
spatial structures. We argue that these programs cannot yet
be called “self-organizing systems” due to two important
limitations. First, they rely on a predeﬁned initial state that
deﬁnes the global coordinate system on which the program
operates through chemical gradients or precise locations of
chemical “seeds”. Second, program execution is a feed-
forward process that does not imply homeostatic feedback
loops that make the patterns robust to external perturbations
or a changed initial state.

Another very related line of research in artiﬁcial life is
Lenia (Chan, 2020), which aims to ﬁnd rules and conﬁg-
urations for space-time-state-continuous cellular automata
that demonstrate life-like homeostatic and replicating be-
haviours.

Figures in video form and a reference implementation is

available here1.

Differentiable Reaction-Diffusion Model
We study a computational model that can be deﬁned by the
following system of PDEs:

∂xi
∂t

= ci∇2xi + fθ(x0, . . . , xn−1)

x0, . . . , xn−1 are scalar ﬁelds representing the “concentra-
tions” n “chemicals” on a 2D plane. ci are per-”chemical”
diffusion coefﬁcients, and fθ : Rn → Rn is a function deﬁn-
ing the rate of change of “chemical concentrations” due to

1https://selforglive.github.io/alife_rd_

textures/

 
 
 
 
 
 
local “reactions”. Chemical terms are used here in quotes
because, in the current version of our model, the function fθ
need not obey any actual physical laws, such as the law of
conservation of mass or the law of mass action. “Concentra-
tions” can also become negative.

Reaction-Diffusion as a Neural CA
The objective of this paper is to train a model that can be rep-
resented by a space-time continuous PDE system. Yet, we
have to discretize the model to run it on a digital computer.
The discretized model can be treated as a case of Neural
Cellular Automata (NCA) model (Mordvintsev et al., 2020;
Randazzo et al., 2020).

Our model and the training procedure are heavily inspired
by the texture-synthesizing Neural CA described by Niklas-
son et al. (2021). Similarly, we discretize space into cells
and time into steps, use explicit Euler integration of the
system dynamics and backpropagation-through-time to op-
timize the model parameters. Our model differs from the
previous texture-synthesizing NCA:

• CA iteration does not have the perception phase. The “re-
action” part of cell update (modelled by fθ) depends on
the current state of the cell only.

• There is an isotropic diffusion process that runs in paral-
lel with “reaction” and is modelled by channelwise con-
volution with a Laplacian kernel. This is the only method
of communication between cells. Thus, the Neural RD
model is completely isotropic: in addition to translation,
the system behaviour is invariant to rotational and mirror-
ing transformations.

• We do not use stochastic updates, all cells are updated at

every step.

Thus, the system described here can be seen as a stripped
version of the Neural CA model. These restrictions are moti-
vated by a number of practical and philosophical arguments
described below.

Model simplicity and prospects of physical implementa-
tion The discussion section of “Growing NCA” article by
Mordvintsev et al. (2020) contains speculations about poten-
tial of physical implementation of the Neural CA as a grid
of tiny independent computers (microcontrollers). Neural
CA consists of a grid of discrete cells that are sophisticated
enough to persist and update individual state vectors, and
communicate within the neighborhood in a way that differ-
entiates between neighbours, adjacent to different sides of
the cell. This implies the existence of global alignment be-
tween cells, so that they agree where up and left are, and
separate communication channels to send the information
in different directions.
In contrast, diffusion based com-
munication doesn’t require any dedicated structures, and

“just happends” in nature due to the Brownian motion of
molecules.

Furthermore, states of Neural CA cells are only modiﬁed
by their learned update rules and are not affected by any en-
vironmental processes. Cells have clear separation between
what’s inside and outside of them, and can control which
signals should be let through. However, many natural phe-
nomena of self-organisation can be effectively described as
a PDE system on a continuous domain. Individual elements
that constitute the domain are considered negligibly small,
and the notion of their individual updates is meaningless.

In the experiments section we cover some practical ad-
vantages of the proposed RD model with respect to Neural
CA. In particular we demonstrate the generalization into ar-
bitrary mesh surfaces and even volumes.

Reaction-Diffusion CA update rule The discrete update
rule can be written as follows:

xt+1
i = xt

i + ciKlap ∗ xt
d = ∆t/∆2

i d + fθ(xt
h, r = ∆t

0, . . . , xt

n−1) r

(1)

Klap is a 3x3 Laplacian convolution kernel, ci and θ are
parameters that control the CA behaviour, and the coefﬁ-
cients r and d control the rates of reaction and diffusion,
encapsulating temporal and spatial discretization step sizes
∆t and ∆h. By varying these coefﬁcients we can validate
if the learned discrete CA rule approximates the continuous
PDE and does not over-feat to the particular discretization.
During training we use r = d = 1.0.

The function fθ(x) = act(xW0 + b0)W1 is a small
two layer neural network with parameters θ : (W0 ∈
Rn×h, W1 ∈ Rh×n, b0 ∈ Rh) and a non-linear element-
wise activation function act (see the experiments section).
In our experiments we use n = 32, h = 128, so the system
models the dynamics of 32 “chemicals”, and the total num-
ber of network parameters equals to 8320. Per-“chemical”
diffusion coefﬁcients ci can be learned (in this case we set
ci = sigmoid(ˆci) to make sure that diffusion rate stays in
0..1 range), or ﬁxed to speciﬁc values.

Texture synthesis
Reaction-Diffusion models are a well-known tool for tex-
ture synthesis. Typically, manual parameter tuning has been
used to design RD systems that generate desired visual pat-
terns (Witkin and Kass, 1991; Turk, 1991). We propose an
example-based training procedure to learn a RD rule for a
given example texture image. This procedure closely fol-
lows the work “Self-Organising Textures” (SOT) (Niklasson
et al., 2021), with a few important modiﬁcations. Our goal
is to learn a RD update function whose continuous applica-
tion from a starting state would produce a pattern similar to
the provided texture sample. The procedure is summarised
in algorithm 1.

Algorithm 1: Texture RD system training
pool ← Npool randomly sampled seed states ;
for step ← 1 to Ntrain do

batch ← sample Nbatch random pool indices ;
x ← pool[batch];
if step mod Rseed = 0 then
x[0] ← random seed state

end
for i ← 1 to U nif orm(Imin, Imax) do

x ← RDθ(x) ;

end
loss ← calcLoss(x) ;
update θ using the gradient of loss ;
pool[batch] ←x;

end

Ntrain
Rseed

20000
32

Imin
Imax

32 Npool
96 Nbatch

1024
4

Seed states SOT uses seed states ﬁlled with zero values.
Stochastic cell updates provide the sufﬁcient variance to
break the symmetry between cells. We use synchronous ex-
plicit Euler integration scheme that updates all cells simulta-
neously, so the non-uniformity of the seed states is required
to break the symmetry. We initialize the grid with a number
of sparsely scattered Gaussian blobs (ﬁg.1).

Figure 1: Random seed states.

Periodic injection of seed states into training batches is
crucial to prevent the model from forgetting how to develop
the pattern from the seed, rather then improving already ex-
isting one. We observed that it is sufﬁcient to inject the seed
much less often than in SOT. We use Rseed = 32 in this
experiment.

Rotation-invariant texture loss Similar to SOT, we in-
terpret the ﬁrst 3 “chemicals” as RGB colors and use them
to calculate texture loss. Our texture loss is also based on
matching Gram matrices of pre-trained VGG network ac-
tivations (Gatys et al., 2015), but has an important modiﬁ-
cation to account for the rotational invariance of isotropic
RD. Consider the texture lined 0118 from the ﬁgure 2.
The target pattern is anisotropic, but RD, unlike NCA, has
no directional information and cannot produce a texture that
exactly matches the target orientation. We construct the
rotation-invariant texture loss by uniformly sampling Nrot

target images rotated by angles 0◦...360◦ and computing the
corresponding texture descriptions. This computation only
occurs in the initialization phase and does not slow down
the training. At each loss evaluation, the texture descriptors
from RD are matched with all target orientations and the best
match is taken for each sample in the batch.

Per-“chemical” diffusion coefﬁcients in Eq. (1) are set to
c0..7 = 1/8, c8..15 = 1/4, c16..23 = 1/2, c24..31 = 1, so that
the “substances” are split into 4 groups of varying diffusiv-
ity. Therefore, RGB colors correspond to slowly diffusing
channels x0..2. We experimented with learned diffusion co-
efﬁcients, but it did not seem to bring substantial improve-
ment, so we kept ﬁxed values for the simplicity. In all of the
texture synthesis experiments we use wrap-around (torus)
grid boundary conditions.

RD network uses a variant of Swish (Ramachandran et al.,
2017) elementwise activation function: act(x) = xσ(5.0 ∗
x), where σ is a sigmoid function.

We trained seven texture-synthesizing RD models (ﬁg.2).
Six were using 128x128 images from DTD dataset (Cimpoi
et al., 2014), and the last was using a 48x48 lizard emoji
image, replicated four times. Models were trained for 20000
steps using the Adam optimiser (Kingma and Ba, 2015) with
learning rate 1e-3 decayed by 0.2 at steps 1000 and 10000.
We also used the gradient normalization trick from SOT to
improve training stability. Training a single RD model took
about 1 hour on the NVIDIA P100 GPU.

Results
In spite of the constrained computational model, trained RD
systems were capable of reproducing (although imperfectly)
distinctive features of the target textures. All models except
chequered 0121 seemed to be isotropic, which mani-
fested in the random orientation of the resulting patterns, de-
pending on the randomized seed state. chequered 0121
always produced diamond-oriented squares, which suggests
overﬁtting to the particular discrete grid. Below we investi-
gate this behaviour more carefully.

Witkin and Kass (1991) proposed using anisotropic diffu-
sion for anisotropic texture generation with RD. In our ex-
periments, we demonstrated the capability of fully isotropic
RD systems to produce locally anisotropic textures through
the process of iterative alignment, that looks surprisingly
“life-like”. Figure 3 shows snapshots of grid states at dif-
ferent stages of pattern evolution. We recommend watching
supplementary videos to get a better intuition of RD system
behaviours.

Do we really learn a PDE? We decided to validate that
the discrete Neural CA that we use to simulate RD system
is robust enough to be used with different grid resolution
than used during training. This would conﬁrm that the sys-
tem we trained really approximates a space-time continuous

Figure 3: Stages of texture development at time steps 50,
100, 1000 and 10000. Anisotropic textures form by local
symmetry breaking and reﬁnement. Resulting patterns look
consistent over long time periods, but never reach full sta-
bility. For example, dots in the middle row asynchronously
change colors.

Figure 4: Running RD system on a non-uniform r grid. All
models except the rightmost seem to be capable of oper-
ating on a modiﬁed grid, preserving the key pattern char-
acteristics. chequered 0121 overﬁtted to the particular
grid resolution and is unable to produce right corners at
larger scales. Sometimes it even develops instabilities and
explodes.

PDE without overﬁtting to the particular grid discretization.
One way to execute the RD on a ﬁner grid is to decrease the
∆h coefﬁcient in (1). This leads to the quick growth of the
diffusion term, making the simulation unstable. We can mit-
igate this by reducing the ∆t as well. In practice we keep
d = 1.0, but decrease r, so that ∆h =
r. Thus, setting
r = 1/4 corresponds to running on a twice ﬁner grid, and
should produce patterns magniﬁed two times. Decrease of r
may also be interpreted as reaction speed slowdown or dif-
fusion acceleration.

√

Fig. 4 shows results of RD system evaluation on a grid
having non-uniform r: in the center r = 1, slowly decreas-
ing to r ≈ 1/9 at the boundary. Most of the trained models
were capable of preserving their behaviour independent of
the grid resolution. chequered 0121 model was the only

sample texture images; other
Figure 2: Left column:
columns: different 5000-step runs of the learned RD mod-
els. Almost all models replicate features of the target tex-
ture in rotation-invariant fashion. Only chequered 0121
overﬁtted to exploit the underlying raster grid structure to
always produce diamond-oriented checker squares.

Figure 5: RD texture models can easily be applied to mesh
surfaces. We treat each vertex of the Stanford Bunny model
as a cell, and allow the associated state vectors to diffuse
along the mesh edges. This enables consistent texturing of
dense meshes without constructing UV-maps or tangent co-
ordinate frames. Please see the supplementary videos for the
system dynamics and more views.

exception. The grid-overﬁtting hypothesis was conﬁrmed by
the fact that the model could not form right angles at the grid
corners, and even developed instabilities in the ﬁne resolu-
tion grid areas.

Generalization beyond 2D plane RD-system can be ap-
plied to any manifold that has a diffusion operation deﬁned
on it. This enables much more extreme out-of-training gen-
eralization scenarios, than those possible for Neural CA. For
example, applying texture synthesis method by Niklasson
et al. (2021) to a 3d mesh surface would require deﬁning
smooth local tangent coordinate systems for all surface cells
(for example, located at mesh vertices). This is necessary
to compute partial derivatives of cell states with some vari-
ant of generalized of Sobel ﬁlters. In contrast, Neural RD
doesn’t require tangents, and can be applied to an arbitrary
mesh by state diffusion over the edges of the mesh graph
(see ﬁg. 5). Even more surprisingly, RD models that were
trained to produce patterns on a 2d plane, can be applied to
spaces of higher dimensionality by just replacing the diffu-
sion operator with a 3d equivalent. Figure 6 shows examples
of volumetric texture synthesis by 2d models.

Discussion
Reaction-Diffusion is known to be an important mechanism
controlling many developmental processes in nature (Kondo
and Miura, 2010; Landge et al., 2019). We think that master-
ing RD-system engineering is an important prerequisite for

Figure 6: 2D to 3D generalization of Reaction-Diffusion
models. The models that were trained on 2D plane with
2D image loss and executed on a 3D space. For some
patterns, individual slices though the volume have textures
similar to the target images, while for others (e.g.
the
last row) the similarity is less convincing. We treat white
color as transparent to visualize the structure of lizards
and polka-dotted patterns. Please see supplementary
videos for model dynamics.

making human technology more life-like: robust, ﬂexible,
and sustainable. This work demonstrates the applicability of
Differentiable Programming to the design of RD-systems.
We think this is an important stepping stone to transform
RD into a practical engineering tool.

To achieve this, some limitations should be addressed in
future work. First, it is crucial to ﬁnd such optimization
problem formulations that would produce physically plau-
sible RD systems. Second, further research in the area of
differentiable objective formulations is needed to make this
approach applicable to a broader range of design problems
for self-organizing systems.

References

Chan, B. (2020).

Lenia and expanded universe.

ArXiv,

abs/2005.03742.

Cimpoi, M., Maji, S., Kokkinos, I., Mohamed, S., and Vedaldi, A.
(2014). Describing textures in the wild. 2014 IEEE Con-
ference on Computer Vision and Pattern Recognition, pages
3606–3613.

Gatys, L. A., Ecker, A. S., and Bethge, M. (2015). Texture synthe-

sis using convolutional neural networks. In NIPS.

Kingma, D. P. and Ba, J. (2015). Adam: A method for stochastic

optimization. CoRR, abs/1412.6980.

Kondo, S. and Miura, T. (2010). Reaction-diffusion model as a
framework for understanding biological pattern formation.
Science, 329:1616 – 1620.

Landge, A. N., Jordan, B. M., Diego, X., and M¨uller, P. (2019).
Pattern formation mechanisms of self-organizing reaction-
diffusion systems. Developmental Biology, 460:2 – 11.

Mordvintsev, A., Randazzo, E., Niklasson, E., and Levin,
M. (2020). Growing neural cellular automata. Distill.
https://distill.pub/2020/growing-ca.

Niklasson,

E., Mordvintsev, A., Randazzo,

Levin, M. (2021).
https://distill.pub/selforg/2021/textures.

Self-organising textures.

E.,

and
Distill.

Pearson, J. E. (1993). Complex patterns in a simple system. Sci-

ence, 261(5118):189–192.

Ramachandran, P., Zoph, B., and Le, Q. V. (2017). Swish: a self-
gated activation function. arXiv: Neural and Evolutionary
Computing.

Randazzo, E., Mordvintsev, A., Niklasson, E., Levin, M., and
Greydanus, S. (2020). Self-classifying mnist digits. Distill.
https://distill.pub/2020/selforg/mnist.

Scalise, D. and Schulman, R. (2014). Designing modular reaction-

diffusion programs for complex pattern formation.

Turing, A. M. (1952). The chemical basis of morphogenesis. Philo-
sophical transactions of the Royal Society of London. Series
B, Biological sciences, 237(641):37–72.

Turk, G. (1991). Generating textures on arbitrary surfaces using
reaction-diffusion. Proceedings of the 18th annual confer-
ence on Computer graphics and interactive techniques.

Witkin, A. and Kass, M. (1991). Reaction-diffusion textures. Pro-
ceedings of the 18th annual conference on Computer graph-
ics and interactive techniques.

