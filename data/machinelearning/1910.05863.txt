GLOBAL-LOCAL METAMODEL ASSISTED TWO-STAGE
OPTIMIZATION VIA SIMULATION

9
1
0
2

t
c
O
3
1

]

C
O
.
h
t
a
m

[

1
v
3
6
8
5
0
.
0
1
9
1
:
v
i
X
r
a

Wei Xie∗1, Yuan Yi2, and Hua Zheng1

1Northeastern University, Boston, MA 02115
2Rensselaer Polytechnic Institute, Troy, NY 12180

ABSTRACT

To integrate strategic, tactical and operational decisions, the two-stage optimization has been widely
used to guide dynamic decision making. In this paper, we study the two-stage stochastic programming
for complex systems with unknown response estimated by simulation. We introduce the global-local
metamodel assisted two-stage optimization via simulation that can efﬁciently employ the simulation
resource to iteratively solve for the optimal ﬁrst- and second-stage decisions. Speciﬁcally, at each
visited ﬁrst-stage decision, we develop a local metamodel to simultaneously solve a set of scenario-
based second-stage optimization problems, which also allows us to estimate the optimality gap. Then,
we construct a global metamodel accounting for the errors induced by: (1) using a ﬁnite number of
scenarios to approximate the expected future cost occurring in the planning horizon, (2) second-stage
optimality gap, and (3) ﬁnite visited ﬁrst-stage decisions. Assisted by the global-local metamodel, we
propose a new simulation optimization approach that can efﬁciently and iteratively search for the
optimal ﬁrst- and second-stage decisions. Our framework can guarantee the convergence of optimal
solution for the discrete two-stage optimization with unknown objective, and the empirical study
indicates that it achieves substantial efﬁciency and accuracy.

Keywords Simulation optimization, two-stage stochastic programming, Gaussian process metamodel, dynamic
decision making

1

Introduction

In many applications, such as high-tech manufacturing, bio-pharmaceutical supply chains, and smart power grids
with renewable energy, we often need to integrate the strategic, tactical and operational decisions. For example, in
the semiconductor manufacturing, the managers need to consider the facility planning and the ensuing production
scheduling. The planning decision is made “here and now", and the production scheduling is a “wait and see" decision,
which depends on the investment decision and also the realization of demand. To guide the dynamic decisions making,
in this paper, we consider the two-stage stochastic programming,

min
x∈X

G(x) ≡ c0(x) + Eξξξ

(cid:20)

min
y∈Y(x)

(cid:21)

q(x, y, ξξξ)

(1)

where x denotes the ﬁrst-stage action, e.g., the investment decision, y denotes the second-stage decision, e.g., production
scheduling, ξξξ denotes the random inputs, e.g., demands, X and Y(x) represent the feasible decision sets. The overall
cost includes the investment cost and the expected production cost occurring in the planning horizon.

The existing two-stage optimization approaches often assume that the response function q(x, y, ξξξ) is known [1, 2, 3, 4].
For example, it can be a linear or mixed-integer function. However, for many complex real systems, the response
function could be unknown. For example, in the semiconductor manufacturing, the production processes can involve
thousands of steps and the production cost function is unknown [5]. We resort to simulation for the unknown response
under different scenarios ξξξ and decisions (x, y). Thus, in this paper, we consider the two-stage optimization via
simulation (OvS).

∗Corresponding author: w.xie@northeastern.edu

 
 
 
 
 
 
Compared to the classical two-stage optimization with the known response function, such as two-stage stochastic linear
programming problems, there exist additional challenges to solve the two-stage OvS listed as follows.

1. When the response function is known, various algorithms exploiting the structural information haven been
developed in the optimization community to search for the optimal solution, including Benders decomposition
algorithm and stochastic decomposition [6, 7, 8, 9]. However, they cannot be employed and extended to the
two-stage OvS of interest.

2. It is computationally demanding to solve the two-stage OvS. For complex stochastic systems, each simulation
run could be computationally expensive. In addition, there could exist high prediction uncertainty and the
number of scenarios used by the Sample Average Approximation (SAA) to approximate the expected future
cost needs to be large [10, 4]. Hence, there exists tremendous computational burden.

3. It is challenging to search for the optimal ﬁrst-stage solution. Given limited computational resource, we often
cannot ﬁnd the true optimal second-stage decisions, which leads to the optimality gap. Thus, besides the ﬁnite
sampling error introduced by SAA, this optimality gap can further lead to a biased estimate of the expected
future cost.

Hence, in this paper, we introduce a new simulation optimization approach that allows us to efﬁciently solve the
complex two-stage OvS problems.

Notice that the problem of interest is different with the existing black-box OvS problems studied in the simulation
literature [11, 12, 13, 14, 15]. Existing studies tend to focus on the stochastic one-stage OvS,

min
x∈X

Eξξξ [f (x, ξξξ)] .

(2)

Given a feasible decision x, the system unknown mean response, denoted by Eξξξ [f (x, ξξξ)], can be assessed by simulation.
Various simulation optimization algorithms are proposed to solve one-stage OvS; see Henderson and Nelson [16] for
a review. In particular, metamodel-assisted optimization approaches can efﬁciently employ the simulation resource
for the search of optimal solution [16, 17]. When there is no strong prior information on the mean response surface,
the Gaussian process (GP) can be used to characterize the remaining metamodel estimation uncertainty. To balance
exploration and exploitation, Sun et al. [15] proposed a GP based search (GPS) algorithm for discrete optimization
problems, and it can efﬁciently use the simulation resource and guarantee global convergence.

Inspired by those one-stage metamodel assisted approaches, in this paper, we propose a global-local metamodel-
assisted two-stage OvS. Speciﬁcally, at each visited ﬁrst-stage action x, we construct a local GP metamodel for
qx(y, ξξξ) ≡ q(x, y, ξξξ) so that we can simultaneously solve a large set of second-stage optimization problems sharing
the same ﬁrst-stage decision x. Then, built on the search results from the second-stage optimization problems, we
further develop a global metamodel accounting for various sources of errors. Assisted by the global-local metamodel,
we introduce a two-stage optimization via simulation approach that can efﬁciently employ the limited simulation budget
to iteratively search for the optimal ﬁrst- and second-stage decisions. Here, suppose each simulation run could be
computationally expensive, say taking about a few days.

Therefore, the main contributions of this paper are as follows.

• We propose a global-local metamodel accounting for the ﬁnite sampling error introduced by using a ﬁnite
number of scenarios to approximate the expected future cost and also the bias introduced by the optimality gap
from the second-stage optimization.

• Assisted by the global-local metamodel, we develop a two-stage optimization via simulation approach that can
simultaneously control the impact from various sources of error and efﬁciently employ the simulation budget
to search for the optimal ﬁrst- and second-stage decisions.

• Our approach can guarantee global convergence as the simulation budget increases. The empirical study also

demonstrates that it has good and stable ﬁnite-sample performance.

The rest of the paper is organized as follows. Section 2 gives the literature review of relevant studies on two-stage
stochastic programming and metamodel-assisted simulation optimization. We formally state the problem of interest in
Section 3. We develop a global-local metamodel-assisted two-stage OvS approach for complex stochastic systems in
Section 4. We study the ﬁnite sample performance of our approach in Section 5, and conclude the paper in Section 6.

2 Background

To integrate strategic, tactical and operational decisions, the classical two-stage stochastic optimization was introduced
[1, 2]. Since the introduction, it has been applied to a wide range of areas, including electricity marketing [18, 19, 20]

2

and the capacity expansion problem [21, 22, 23]. In the classical two-stage stochastic optimization, the second-stage
response function is assumed to be known, e.g., a linear function [1, 2] or a mixed integer one [18, 19, 20]. Various
algorithms have been proposed in the stochastic optimization community to solve it, such as two-stage linear program
and two-stage mixed-integer program. To obtain the optimal solution, they typically exploit the structural information.
For example, the L-shaped algorithm was proposed by Van Slyke and Wets [24], and further developed in [25, 26, 7].
The Stochastic Decomposition (SD) algorithm was proposed in Higle and Sen [8, 9].

However, for many real-world complex systems, e.g., semiconductor production systems and global bio-pharma supply
chains, the second-stage response function is often unknown and the system outputs can be predicted through simulation.
Therefore, the problem becomes a two-stage stochastic optimization via Simulation (OvS). In these situations, the
classical algorithms cannot be easily extended.

In the simulation community, OvS is an active research area. With recent technology advances, OvS offers a convenient
way to support the decision making for a variety of complex stochastic systems and it has gained ever increasing
importance [27, 28]. The existing OvS studies extensively focus on the one-stage OvS problems, including the ranking
and selection [16], the random search algorithm [29], the COMPASS algorithm [13, 30], the simultaneous perturbation
stochastic approximation (SPSA) algorithm [11]; see Fu [17] for a comprehensive review.

However, existing simulation-based optimization algorithms are typically developed for one-stage OvS problems in
(2). To the best of our knowledge, there is no rigorous algorithm proposed for two-stage stochastic OvS in the general
situations. Different from the one-stage optimization, two-stage stochastic programming exhibits some unique features:
the ﬁrst-stage optimization problem is stochastic and it depends on the results from second-stage optimization, while
the second-stage optimization problems are conditional on the realizations of random events and they are deterministic.

For the two-stage OvS, the estimation of expected cost is required. In many situations, the possible scenarios representing
the second-stage uncertainty are too many or even inﬁnite. Then, the sampling approach, SAA, uses a set of scenarios
to approximate the expected future cost [31]; see more discussion about SAA in [32, 33, 34]. However, the SAA often
introduces the ﬁnite sampling error. To accurately estimate the second-stage expected cost and control the impact
of ﬁnite sampling error, a large scenario size is required [4]. In addition, the expected objective in (1) relies on the
second-stage optimal solutions. Without strong prior information on the second-stage response function, such as
linearity, given a tight computational resource, there exists the optimality gap.

For real-world complex stochastic systems, each simulation run could be computationally expensive. Thus, it is
important to efﬁciently employ the tight simulation budget to search for promising ﬁrst-stage decisions, while controlling
the ﬁnite sampling error introduced by SAA and the optimality gap induced in the second-stage black-box optimization.
In this paper, we propose a metamodel-assisted framework for two-stage optimization in (1). When there is no strong
prior information on the system response function, the Gaussian process metamodel is often used to provide a global
prediction. In the past decades, it has received great attention in both deterministic and one-stage stochastic simulation
optimization; see for example [12, 14, 35, 15]. Jones et al. [12] introduced Kriging for deterministic OvS problems.
Sun et al. [15] developed the GPS algorithm that employs Stochastic Kriging models introduced by Ankenman et
al. [36] for stochastic discrete optimization via simulation (DOvS). It can guarantee the global convergence, and also
demonstrates good ﬁnite sample performances.

Notice that this paper is fundamentally different with our previous study in [37]. Here, we propose a simulation
optimization approach that can efﬁciently solve the discrete two-stage optimization for complex stochastic systems
with unknown second-stage response function. The study in [37] focused on a generalized two-stage dynamic decision
model with nested risk measures, such as the conditional value-at-risk (CVaR). For a given decision policy, a metamodel-
assisted approach was introduced to efﬁciently assess the nested system risk, and further delivered a credible interval
(CrI) quantifying the simulation estimation error.

3 Problem Description

In this section, we describe the problem of interest. To guide the dynamic decision making for complex stochastic
systems, we consider the two-stage stochastic programming with unknown response estimated by simulation,

min
x∈X

G(x) ≡ c0(x) + Eξξξ

(cid:20)

min
y∈Y(x)

(cid:21)

q(x, y, ξξξ)

(3)

where x represents the ﬁrst-stage decision with the feasible set, denoted by X , and y represents the second-stage
decision with the feasible set Y(x) depending on x. Suppose that both c0(x) and q(x, y, ξξξ) are continuous, and the
sets X and Y(x) are discrete and ﬁnite. The random input variate ξξξ follows the probability model, denoted by F (ξξξ),
characterizing the prediction uncertainty. The ﬁrst-stage decision x is made prior to the realization of ξξξ and the

3

second-stage decision y is made after the uncertainty is revealed. That means given any feasible ﬁrst-stage decision x
and a scenario ξξξ, we need to solve a second-stage optimization problem,
q(x, y, ξξξ),

Q(x, ξξξ) ≡ min

y∈Y(x)
which leads to the optimal decision, denoted by y(cid:63)(x, ξξξ). For simpliﬁcation, suppose that there is a unique optimal
ﬁrst-stage decision, denoted by x(cid:63) = arg minx∈X G(x), with the objective G(x(cid:63)).
For complex stochastic systems, such as global biopharma supply chains and semiconductor manufacturing, both cost
functions G(x) and qxi(y, ξξξ) ≡ q(xi, y, ξξξ) at any xi ∈ X are often unknown, which can be estimated by simulation.
Here, we use a semiconductor production facility investment as an illustrative example. We consider the planning
horizon with T time periods, say T quarters. Given the ﬁrst-stage decision xi, i.e., the capacity of production facility
investment, and the realization of demands ξξξ = (ξ1, ξ2, . . . , ξT ) in the planning horizon, we want to ﬁnd the production
scheduling decision y = (y1, y2, . . . , yT ) minimizing the operational cost qxi(y, ξξξ) = (cid:80)T
t=1 ct(xi, yt, ξt), where ξt
and ct(·) for t = 1, 2, . . . , T represent the accumulated demand and the cost occurring in the t-th time period. The
optimal second-stage decision depends on the investment decision xi and also the realized demands ξξξ. Since the
semiconductor production could involve thousands of processing steps, each simulation run for qxi(y, ξξξ) could be
computationally expensive. Notice that the scenario aggregation and decision discretization could be used to reduce the
complexity of second-stage optimization; see the similar strategies recommended for approximate look-ahead models
in [38].

(4)

For some xi ∈ X , the second-stage program could be infeasible, i.e., Y(xi) is empty [3]. To avoid this issue, we
assume that the problem of interest has relatively complete recourse, i.e., for every xi ∈ X and every scenario ξξξ ∈ Ξ,
the second-stage recourse problem is always feasible, where Ξ denotes the scenario set.

If the scenario set Ξ only contains J scenarios {ξξξ1, . . . , ξξξJ } with known probabilities {p1, . . . , pJ }, then the expectation
in Objective (3) becomes Eξξξ[Q(xi, ξξξ)] = (cid:80)J
j=1 pjQ(xi, ξξξj), where J is a ﬁnite integer. In this case, for each ﬁrst-stage
decision xi, only J second-stage optimization problems in (4) need to be solved.
However, in many situations, ξξξ is continuous or the number of possible scenarios is astronomical. At any visited xi ∈ X ,
the SAA with N (xi) number of scenarios can be used to approximate the expected future cost in (3),

¯Gc(xi) ≡ c0(xi) +

1
N (xi)

N (xi)
(cid:88)

j=1

qxi(y(cid:63)

ij, ξξξij)

(5)

i.i.d.∼ F (ξξξ) for j = 1, 2, . . . , N (xi); see the introduction of SAA in [10, 33, 39]. The superscript c in (5)
with ξξξij
indicates that the objective is estimated based on the “correct" optimal second-stage decisions y(cid:63)
ij ≡ y(cid:63)(xi, ξξξij).
Differing with the existing two-stage optimization studies in the literature that assume the response qxi(y, ξξξ) known
[21, 22, 23, 10], for each ﬁrst-stage decision xi and scenario ξξξij, the second-stage optimization in our study is a
black-box scenario-based deterministic optimization problem. Given ﬁnite computational assignment, there often exists
an optimality gap introduced by using the estimated optimal solution, denoted by (cid:98)y(cid:63)
ij,

δ(xi, ξξξij) ≡ qxi((cid:98)y(cid:63)

ij, ξξξij) − qxi(y(cid:63)

ij, ξξξij).

(6)

In addition, the forecast uncertainty of ξξξ occurring in the planning horizon could be large. For example, in the
semiconductor and biopharma manufacturing, we frequently introduce new products and it is challenging to precisely
predict their demands [5, 40, 41, 42]. For the power grids with high renewable energy penetration, it is challenging to
provide an accurate forecast of the wind and solar power generation when we make the unit commitment scheduling
decision for the day-ahead market [18, 19, 20]. Thus, it could require a large number of scenarios, N (xi), to accurately
estimate the expected future cost. It is computationally prohibitive to solve a large number of black-box second-stage
optimization problems, minyij ∈Y(xi) qxi(yij, ξξξij) for j = 1, 2, . . . , N (xi).
When we solve the two-stage optimization in (3) for complex stochastic systems via simulation, there are some important
observations described as follows.

Observation (1): The objective function values G(x) and G(x(cid:48)) tend to be similar when the ﬁrst-stage
decisions x and x(cid:48) are close to each other.
Observation (2): For each ﬁrst-stage action xi, when we use SAA to approximate the expected cost, there
are N (xi) second-stage optimization problems needed to be solved. Under situations with high prediction
uncertainty, N (xi) is required to be large so that we can accurately estimate the expected cost. Each scenario-
based second-stage optimization is a black-box deterministic optimization problem and it is time-consuming
to solve them separately. Also each simulation run could be computationally expensive.

4

Observation (3): When we search for the optimal ﬁrst-stage decision, we need to consider errors induced
by: (a) the ﬁnite sampling error introduced by SAA, (b) the second-stage optimality gap, and (c) ﬁnite visited
ﬁrst-stage decisions.

4 Global-Local Metamodel-Assisted Two-Stage Optimization

Considering the unique properties of stochastic programming with unknown response, in this section, we introduce
a global-local metamodel-assisted two-stage optimization via simulation. It can efﬁciently employ the simulation
budget, denoted by C, to solve the two-stage optimization problem in (3) for complex stochastic systems. We ﬁrst
present the local metamodel assisted second-stage optimization in Section 4.1. At each visited ﬁrst-stage decision
xi ∈ X , we construct a GP metamodel for qxi(y, ξξξ). The metamodel uncertainty is characterized by the GP posterior
distribution, denoted by GP xi and let (cid:101)qxi(·, ·) ∼ GP xi. In the paper, the notation (cid:101)· denotes the posterior sample
or random function/variable. To overcome the challenges stated in Observation (2), we utilize the local metamodel
GP xi to simultaneously solve the N (xi) second-stage optimization problems, minyij ∈Y(xi) qxi(yij, ξξξij) for j =
1, 2, . . . , N (xi). The local metamodel also allows us to estimate the optimality gap from the second-stage optimization.

Then, in Section 4.2, based on the search results for the second-stage optimization, we develop a global GP metamodel
(cid:2)miny∈Y(x) q(x, y, ξξξ)(cid:3). It accounts for: (1) ﬁnite sampling error induced by SAA, (2) the bias
for G(x) = c0(x) + Eξξξ
caused by the second-stage optimality gap, and (3) prediction error induced by only ﬁnite decision points visited. It can
capture the spatial dependence of the response surface G(·) stated in Observation (1).

Assisted by the global-local metamodel developed in Sections 4.1 and 4.2, we propose the two-stage optimization via
simulation in Section 4.3 that can balance exploration and exploitation through simultaneously controlling all sources
of errors. It can efﬁciently employ the computational resource to iteratively solve for the optimal ﬁrst- and second-stage
decisions. As the simulation budget goes to inﬁnity, in Section 4.4, we can show that the proposed optimization
procedure can guarantee the global convergence to G(x(cid:63)).

4.1 Local Metamodel Assisted Second-Stage Optimization

At any visited design point xi, in this section, we introduce a local metamodel assisted algorithm for solving the second-
stage simulation optimization problems. Speciﬁcally, we ﬁrst construct a GP metamodel for qxi (·, ·) in Section 4.1.1.
Then, for each scenario ξξξij, we plug it into the local metamodel and the posterior sample path (cid:101)qxi(y, ξξξij) is utilized
to predict the response at any y ∈ Y(xi). Thus, we solve the scenario-based second-stage optimization problems,
minyij ∈Y(xi) qxi(yij, ξξξij) and further estimate the optimality gap δ(xi, ξξξij) for j = 1, 2, . . . , N (xi) in Section 4.1.2.
Since the local metamodel qxi(·, ·) can leverage the information collected from all scenarios at xi, it can efﬁciently
solve the second-stage optimization problems.

4.1.1 Local Metamodel Construction

For notational simplicity, let z ≡ (y, ξξξ). The cost occurring in the planning horizon can be modeled as a realization of
GP,

qxi(z) = β0 + M (z).
It consists of two parts: a global trend β0 (note that β0 can be replaced by a more general trend term f (z)(cid:62)βββ without
affecting our method) and a zero-mean GP, denoted by M (z), modeling the spatial dependence of the response function
qxi(z). The covariance function of the GP is Cov(M (z), M (z(cid:48))) = σ2R(z, z(cid:48)), where σ2 is the variance and R(·) is
the correlation function. Our previous study [43] demonstrates that the product-form Gaussian correlation function has
the good performance and also easy to implement. Thus, it is used in the empirical study

R(z − z(cid:48)|φφφ) = exp



−

d
(cid:88)

j=1



φj(zj − z(cid:48)

j)2



(7)

where d is the dimension of z and the parameters φφφ = (φ1, . . . , φd) control the spatial dependence.
Denote K1 design points at xi by Pxi ≡ {mz1, mz2, . . . , mzK1 }, and the corresponding simulation outputs by
= (qxi(mz1), qxi(mz2), . . . , qxi(mzK1))(cid:48). Deﬁne mZ as the matrix of Kp prediction points. Let R(mZ, ·)
QPxi
represent the K1 × Kp spatial correlation matrix between K1 design points and Kp prediction points mZ. Let R be the
K1 × K1 correlation matrix across all K1 design points and let R(mZ, mZ) represent the Kp × Kp spatial correlation
matrix between Kp prediction points . Then, given the simulation outputs QPxi
, the remaining uncertainty of the local

5

metamodel at mZ is characterized by the updated Gaussian process, denoted by GP xi((cid:98)qxi (mZ), s2
mean
(cid:98)qxi(mZ) = (cid:98)β0 · 1Kp×1 + R(mZ, ·)(cid:48)R−1(QPxi

− 1K1×1 (cid:98)β0),

xi

and variance-covariance matrix

s2
xi

(mZ, mZ) = σ2{R(mZ, mZ) − R(mZ, ·)(cid:48)R−1R(mZ, ·)

(mZ)), with

(8)

(9)

+[11×Kp − 1(cid:48)

K1×1R−1R(mZ, ·)](cid:48)[1(cid:48)
K1×1R−1QPxi

where (cid:98)β0 = (1(cid:48)
likelihood approach; see Sacks et al. [44] and Jones et al. [12].

K1×1R−11K1×1)−11(cid:48)

K1×1R−11K1×1]−1[11×Kp − 1(cid:48)

K1×1R−1R(mZ, ·)]},

. The unknown parameters σ and φφφ are estimated by the maximum

4.1.2 Second-Stage Optimization and Optimality Gap Estimation

At any visited ﬁrst-stage candidate xi ∈ X , when SAA is used to estimate the expected future cost, it could be
computationally expensive to solve N (xi) black-box second-stage optimization problems separately. Assisted by the
local metamodel built for qxi(·, ·) in Section 4.1.1, we can simultaneously solve all N (xi) second-stage optimization
problems: y(cid:63)
ij = arg miny∈Y(xi) qxi(y, ξξξij) with j = 1, 2, . . . , N (xi). Speciﬁcally, by plugging in each scenario
ξξξij, the metamodel GP xi((cid:98)qxi(·, ξξξij), s2
(·, ξξξij)) provides the posterior prediction of the system response for any
untried decision y ∈ Y(xi), which is used to guide the search for y(cid:63)
ij. Given the current estimated optimal solution,
denoted by (cid:98)y(cid:63)
ij, we want to efﬁciently employ the simulation resource to reduce the optimality gap, δ(xi, ξξξij) =
qxi((cid:98)y(cid:63)
ij, ξξξij). Thus, in the next search iteration, we want to ﬁnd the promising point yij ∈ Y(xi) that
can reduce the optimal gap the most and run simulation there.

ij, ξξξij) − qxi(y(cid:63)

xi

Since the response surface qxi(·, ξξξij) is unknown, motivated by the Efﬁcient Global Optimization (EGO) algorithm
[12], the criteria used to guide the sequential search for the optimal solution y(cid:63)
ij is based on minimizing the expected
optimality gap or maximizing the expected improvement (EI). The unknown second-stage response surface is modeled
by the posterior sample path (cid:101)qxi(·, ·) ∼ GP xi((cid:98)qxi (·, ·), s2
(·, ·)). Following [12], given the current optimal solution
(cid:98)y(cid:63)
ij, the EI at any untried point yij ∈ Y(xi) can be deﬁned as

xi

E

(cid:101)qxi (yij ,ξξξij ) [I(yij, ξξξij)] ≡ E
(cid:101)qxi (yij ,ξξξij )
(cid:18)
(cid:19)

(cid:2)max (cid:0)qxi((cid:98)y(cid:63)

ij, ξξξij) − (cid:101)qxi(yij, ξξξij), 0(cid:1)(cid:3)
(cid:19)

(cid:18)

= ∆ · Φ

∆
sxi(yij, ξξξij)

+ sxi(yij, ξξξij) · ϕ

∆
sxi(yij, ξξξij)

(10)

where E
(cid:101)qxi(yij, ξξξij) ∼ N ((cid:98)qxi(yij, ξξξij), s2
PDF, CDF of standard normal distribution with ϕ(·), Φ(·) respectively. The greater E
more promising the untried point yij could be. Hence, to efﬁciently search for the true optimal y(cid:63)
which gives the maximum EI,

(cid:101)qxi (yij ,ξξξij ) [·] denotes the expectation over the remaining metamodel uncertainty at (yij, ξξξij) with
ij, ξξξij) − (cid:98)qxi(yij, ξξξij), and represent the
(cid:101)qxi (yij ,ξξξij ) [I(yij, ξξξij)] is, the
ij, we ﬁnd the point

(yij, ξξξij)). Here, we set ∆ ≡ qxi ((cid:98)y(cid:63)

xi

(cid:101)qxi (yij ,ξξξij ) [I(yij, ξξξij)]

yEI
ij = arg maxyij ∈Y(xi)E
and then run simulation there; see the second-stage optimization search procedure in Section 4.3.
In addition, the local metamodel can be used to esimate the second-stage optimality gap, δ(xi, ξξξij) = qxi((cid:98)y(cid:63)
ij, ξξξij) −
qxi(y(cid:63)
ij, ξξξij) for j = 1, 2, . . . , N (xi). Speciﬁcally, the unknown response surface qxi(·, ·) is modeled by a sample path
of Gaussian Process GP xi . For each scenario ξξξij, the local metamodel GP xi can be used to estimate the expected
optimality gap E[δ(xi, ξξξij)|ξξξij], where the conditional expectation is over the metmodel uncertainty. Basically, as
the metamodel uncertainty increases especially at the promising area, the expected optimality gap also increases.
To estimate E[δ(xi, ξξξij)|ξξξij], we ﬁrst generate a posterior sample path (cid:101)q(b)
(·, ·)) for b =
1, . . . , B, where (cid:98)qxi and s2
xi (y, ξξξij) to predict the response for any
y ∈ Y(xi), and calculate the b-th realization of the optimality gap,
δ(b)(xi, ξξξij) = max (cid:0)0, qxi((cid:98)y(cid:63)

xi are speciﬁed by (8) and (9). Then, we can use (cid:101)q(b)

xi (·, ·) ∼ GP xi ((cid:98)qxi(·, ·), s2

ij, ξξξij) − (cid:98)q(cid:63)

(cid:1) with (cid:98)q(cid:63)

ijb = min

(y, ξξξij).

(11)

ijb

xi

y∈Y(xi) (cid:101)q(b)

xi

Thus, we can estimate E[δ(xi, ξξξij)|ξξξij] with

(cid:98)E[δ(xi, ξξξij)|ξξξij] =

1
B

B
(cid:88)

b=1

δ(b)(xi, ξξξij).

(12)

6

4.2 Global Metamodel Development

Based on Observation (1) described in Section 3, suppose that the unknown response surface G(x) = c0(x) +
(cid:2)miny∈Y(x) qx(y, ξξξ)(cid:3) is a realization of GP. Given the results from the second-stage optimization, we develop a
Eξξξ
global GP metamodel for G(x), which will be used to guide the search for the optimal decision x(cid:63) in Section 4.3.
For any xi ∈ X , the optimal response from the j-th scenario Gj(xi) ≡ c0(xi) + minyij ∈Y(xi) qxi (yij, ξξξij) can be
written as,

Gj(xi) = G(x) + (cid:15)(xi, ξξξij),
(13)
where the mean zero random error (cid:15)(xi, ξξξij) represents the deviation of Gj(xi) from the expected cost G(xi) =
E[Gj(xi)]. However, the optimal solution for the second-stage optimization, y(cid:63)
ij = arg minyij ∈Y(xi) qxi(yij, ξξξij), is
unknown. Since only the current optimal estimate (cid:98)y(cid:63)
ij, ξξξij).
Thus, we rewrite the optimal response from the j-th scenario as Gj(xi) = ˘Gj(xi) − δ(xi, ξξξij) with the optimality gap,
δ(xi, ξξξij) = qxi((cid:98)y(cid:63)

ij is available, we can observe ˘Gj(xi) ≡ c0(xi) + qxi((cid:98)y(cid:63)

ij, ξξξij). Combining with (13), we have

ij, ξξξij) − qxi (y(cid:63)

˘Gj(xi) − δ(xi, ξξξij) = G(xi) + (cid:15)(xi, ξξξij).

(14)

As noted in Section 4.1.2, given any scenario ξξξij, since qxi(·, ·) has the remaining metamodel uncertainty, our belief on
unknown optimality gap δ(xi, ξξξij) is treated as a random variable with conditional expectation E[δ(xi, ξξξij)|ξξξij]. Thus,
δ(xi, ξξξij) can be expressed as

δ(xi, ξξξij) = E[δ(xi, ξξξij)|ξξξij] + (cid:15)(cid:48)(xi, ξξξij),
(15)
where (cid:15)(cid:48)(xi, ξξξij) is deﬁned as a zero-mean random variable characterizing the variability of δ(xi, ξξξij) given ξξξij and it
is induced by the local metamodel uncertainty of qxi(·, ξξξij). By plugging (15) into (14) and then rearranging terms, we
obtain

˘Gj(xi) − E[δ(xi, ξξξij)|ξξξij] = G(xi) + (cid:15)(xi, ξξξij) + (cid:15)(cid:48)(xi, ξξξij).

(16)

At each xi, given N (xi) scenario results from solving the second-stage optimization problems, we obtain the expected
optimality gap adjusted SAA estimate for G(xi),

¯G(xi) =

1
N (xi)

N (xi)
(cid:88)

j=1

{ ˘Gj(x) − E[δ(xi, ξξξij)|ξξξij]}

= c0(xi) + 1

N (xi)

(cid:80)N (xi)
j=1

(cid:8)q(xi, (cid:98)y(cid:63)

ij, ξξξij) − E[δ(xi, ξξξij)|ξξξij](cid:9)

(17)

N (xi)

(cid:80)N (xi)

i.i.d.∼ F (ξξξ) for i = 1, 2, . . . , K and j = 1, 2, . . . , N (xi). Let ¯e(xi, Di) = 1

j=1 [(cid:15)(x, ξξξij)+(cid:15)(cid:48)(xi, ξξξij)],
with ξξξij
where Di = {ξξξij : j = 1, . . . , N (xi)} represents the ﬁnite scenarios set at xi. Then, from Equation (16), we get
¯G(xi) = G(xi) + ¯e(xi, Di).
Suppose the unknown response surface G(x) is a random sample path of a GP, denoted by W(x) = µ0 + W (x),
characterizing the uncertainty of our belief on the underlying G(x). Thus, at any xi ∈ X , we can model the summary
simulation output ¯G(xi) with

¯G(xi) = [µ0 + W (xi)] + ¯e(xi, Di).
(18)
Since the mean zero error ¯e(xi, Di) considers the aggregated impact from many factors or results from the N (xi)
scenarios, we can assume that it follows the normal distribution by applying the general central limit theory (CLT).
Note that µ0 in (18) can be replaced by a more general trend term, i.e., f (xi)(cid:62)µµµ.
Denote the design points with Po ≡ {x1, x2, . . . , xK}. Let ¯GPo = ( ¯G(x1), ¯G(x2), . . . , ¯G(xK))(cid:48). The bootstrap can
be used to quantify the estimation variance of ¯G(xi) for i = 1, . . . , K. Speciﬁcally, in each t-th iteration, we draw with
replacement N (xi) outputs from { ˘Gj(x) − E[δ(xi, ξξξij)|ξξξij] with j = 1, . . . , N (xi)} and calculate the sample mean,
denoted by ¯G(t)(xi). Repeat this procedure for T times. We can estimate the variance of ¯G(xi), denoted by Vii, by
using the sample variance from these T bootstrap samples ¯G(1), . . . , ¯G(T ). For unknown E[δ(xi, ξξξij)|ξξξij], we plug
in the estimate (cid:98)E[δ(xi, ξξξij)|ξξξij] obtained from (12). Then, without CRN, the covariance matrix of ¯GPo is a diagonal
matrix V with the i-th diagonal term equal to Vii. Given ¯GPo and V , we can construct the global metmaodel to guide
the search for x(cid:63).
Represent the spatial covariance function as Cov(W (x), W (x(cid:48))) = τ 2r(x, x(cid:48)), where τ 2 denotes the variance and
r(x − x(cid:48); φφφ) denotes the correlation function with parameters φφφ. The Gaussian correlation function is used in our
empirical study. For any prediction point mX(cid:63) ∈ X , denote the spatial covariance vector between mX(cid:63) and

7

design points by Σ(mX(cid:63), ·), and denote the variance-covariance matrix between design points by Σ. Given the
simulation outputs, the remaining uncertainty of the cost function G(mX(cid:63)) can be characterized by a GP, denoted by
(cid:101)G(mX(cid:63)) ∼ GP o( (cid:98)G(mX(cid:63)), s2(mX(cid:63))), with mean

(cid:98)G(mX(cid:63)) = (cid:98)µ0 + Σ(mX(cid:63), ·)(cid:48)[Σ + V ]−1( ¯GPo − (cid:98)µ0 · 1)

(19)

and variance

s2(mX(cid:63)) = τ 2 − Σ(mX(cid:63), ·)(cid:48)[Σ + V ]−1Σ(mX(cid:63), ·) + η(cid:48)[1(cid:48)(Σ + V )−11]−1η
(20)
where (cid:98)µ0 = [1(cid:48)(Σ + V )−11]−11(cid:48)(Σ + V )−1 ¯GPo and η = 1 − 1(cid:48)(Σ + V )−1Σ(mX(cid:63), ·); see the detailed information
about the stochastic kriging in Ankenman et al. [36]. The maximum likelihood estimates (MLEs) for τ 2 and φφφ are used
for prediction.

4.3 Global-Local Metamodel Assisted Two-Stage Optimization via Simulation

Built on the global-local metamodel developed in Sections 4.1 and 4.2, we propose a two-stage optimization via
simulation. Notice that before using either local or global metamodel for the optimal search, we need to verify the
GP assumption; See Jones et al. [12] and Huang et al. [14] for the detailed discussion. The procedure of proposed
global-local metamodel assisted two-stage OvS includes the main steps described in Algorithm 1. In Step (1), we
specify the simulation budget C, the initial relative EI threshold α0, the growth factor g, the number of replications
n0, and set the iteration index k = 1. Denote D(k)
x as the set of ﬁrst-stage design points visited at the k-th iteration
x = (cid:83)k
and denote S (k)
x . We generate
the initial set of design points for the global GP metamodel D(k)
x with k = 1 by using the maximin Latin Hypercube
Design (LHD) [12, 14]. In the empirical study, we use the “10d" rule for the number of initial design points [14]. For
each xi ∈ D(k)
x , we allocate n0 scenarios. Following Kim and Nelson [45] and Tsai et al. [46], we set n0 = 10 in the
empirical study.

as all design points that have been visited until the k-th iteration, S (k)

s=1 D(s)

x

ij = arg miny∈Y(xi) qxi(y, ξξξij) with j = 1, 2, . . . , N (k)(xi) for each xi ∈ D(k)

Then, we iteratively solve the second- and ﬁrst-stage optimization. At the k-th iteration, we solve the second-stage
optimization problems y(cid:63)
x in Step (2).
Here, α(k)(xi) is the relative EI threshold which controls the stopping criteria for second-stage optimal search. For
any design point that is visited for the ﬁrst-time, xi ∈ D(k)
, we set α(k)(xi) = α0 and generate
x
N (k)(xi) = n0 scenarios. Since too large α0 could lead to unreliable optimization results and too small α0 could
cause wasting the effort on unpromising candidates, we set α0 = 0.1 in the empirical study. Then, we use LHD to
generate the design points of (y, ξξξ) evenly covering the space Y(xi) × Ξ, run simulations, and construct the initial local
x ∩ S (k−1)
metamodel GP xi((cid:98)qxi(·, ·), s2
},
x
we increase the number of scenarios N (k)(xi) and reduce the threshold α(k)(x) to simultaneously control the impact
from ﬁnite sampling error and second-stage optimality gap. Inspired by Lesnevski et al. [47, 48], for the t-th visited
ﬁrst-stage action x ∈ X with t > 1, the relative EI threshold for second-stage optimization is set to be α0g− t−1
2 and
the accumulated number of scenarios is set to be (cid:100)n0gt−1(cid:101). Thus, for the design point x revisited in the k-th iteration,
we add N (k−1)(x)(g − 1) additional scenarios. Following Lesnevski et al. [47], we set g = 1.5.

(·, ·)) by using (8) and (9). For each revisited design point, i.e., xi ∈ {D(k)

and xi /∈ S (k−1)

xi

x

In Step (2.2), we search the optimal solutions for those new generated scenarios ξξξij by using the local metamodel,

In Step (2.3), we ﬁrst check the stopping criteria for each scenario ξξξij with j = 1, . . . , N (k)(xi),

(cid:98)y(cid:63)
ij = arg minyij ∈Y(xi)(cid:98)qxi (yij, ξξξij).

maxyij ∈Y(xi) E

(cid:101)qxi (yij ,ξξξij ) [I(yij, ξξξij)]

|qxi((cid:98)y(cid:63)

ij, ξξξij)|

≤ α(k)(xi)

(21)

(22)

(cid:101)qxi (yij ,ξξξij ) [I(yij, ξξξij)] obtained by (10). We move those scenarios satisfying the stopping criteria (22) to the
with E
set Uxi that inlcudes all terminated scenarios. For the remaining scenario ξξξij with ξξξij /∈ Uxi, to efﬁciently reduce the
optimality gap, we ﬁnd the point yEI

ij giving the maximum EI,

yEI

ij = arg max

yij ∈Y(xi)

(cid:101)qxi (yij ,ξξξij ) [I(yij, ξξξij)] .
E

(23)

We add the point (yEI
simulation there. Then, we update the metamodel by using (8)–(9) and also update (cid:98)y(cid:63)

ij , ξξξij) to the set Pxi that includes all design points for the local metamodel GP xi and run
ij. We repeat this procedure

8

ALGORITHM 1: The Procedure for Global-Local Metamodel-Assisted Two-Stage OvS.
Step (1): Initialization.
Step (1.1) Specify the simulation budget C and the growth factor g. Initialize the iteration index k = 1, the EI threshold α0 and the

number of replications n0.
Step (1.2) Use the maximin LHD to generate the initial ﬁrst-stage design point set D(k)
set S (k)

x . Let N (k)(xi) = n0 for xi ∈ D(k)
x .

x = D(k)

x evenly covering the decision space X and

Step (2): Solve the second-stage optimization problems for design points visited at the k-th iteration, xi ∈ D(k)
collection of ﬁnished second-stage scenarios, Uxi = ∅.
Step (2.1): Update the relative EI threshold α(k)(xi) and the number of scenarios N (k)(xi) for xi ∈ D(k)
x .
if xi /∈ S (k−1)

(ﬁrst visited design points) then

x

x . Reset the

Set α(k)(xi) = α0 and N (k)(xi) = n0. Generate new scenarios {ξξξij}N (xi)
point set Pxi evenly covering the space of (y, ξξξ), denoted by Y(xi) × Ξ, and run simulations there. Construct the initial local
metamodel GP xi ((cid:98)qxi (·, ·), s2

. Use LHD to generate the second-stage design

xi (·, ·)) by using (8) and (9).

j=1

Set α(k)(xi) = α(k−1)(xi) · g− 1

2 . Generate N (k−1)(xi)(g − 1) new scenarios and let N (k)(xi) = N (k−1)(xi) · g.

else

end
Step (2.2): For each new generated scenario ξξξij, use the local metamodel GP xi to search (cid:98)y(cid:63)
Step (2.3): Check the stopping criteria (22) for each scenario ξξξij with j = 1, . . . , N (k)(xi) and move the terminated ones to the set
Uxi . If |Uxi | = N (k)(xi), stop the second-stage optimization for xi. Otherwise, continue the optimal search for each remaining
scenario ξξξij /∈ Uxi .
while |Uxi | < N (k)(xi) do

ij by using (21).

for 1 ≤ j ≤ N (k)(xi) and ξξξij /∈ Uxi do

(cid:101)qxi

(a) Find yEI
E

ij by using (23).
(yij ,ξξξij )[I(yEI
|qxi ((cid:98)y(cid:63)
ij ,ξξξij )|

ij ,ξξξij )]

(b) If
Otherwise, run simulation at (yEI
(8)–(9) and update ((cid:98)y(cid:63)

ij, ξξξij).

end

≤ α(k)(xi), then terminate the optimal search for scenario ξξξij and set Uxi = Uxi

(cid:83){ξξξij}.
ij , ξξξij) and add it to Pxi . Update the local metamodel for qxi (·, ·) based on Pxi by using

end
(c) Estimate E[δ(xi, ξξξij)|ξξξij] by (12).

Step (3): Solve the ﬁrst-stage optimization.
Step (3.1): Construct/Update the global metamodel GP o( (cid:98)G(·), s2(·)) by using (19) and (20). Find the current optimal decision,
(cid:98)x(cid:63)(k) = arg min
Step (3.2): If the simulation budget C is exhausted, stop the search procedure and report (cid:98)x(cid:63)(k). Otherwise, construct the sampling
distribution f (k+1)(x) for x ∈ X by (24) and use it to generate a new set of design points D(k+1)
| = s. Update
the set of design points S (k+1)

. Set the iteration index k = k + 1 and return to Step (2)

with size |D(k+1)

(cid:83) D(k+1)

¯G(x).

= S (k)
x

(k)
x

x∈S

x

x

x

x

for all scenarios ξξξij that have not been terminated. If all N (xi) optimization problems meet the stopping criteria,
|Uxi| = N (xi), we terminate the second-stage optimal search for xi in the k-th iteration and estimate E[δ(xi, ξξξij)|ξξξij]
by using (12).

In Step (3), we solve the ﬁrst-stage optimization. Given the results from second-stage optimization, we construct/update
¯G(x).
the global GP metamodel GP o by using (19)–(20) and ﬁnd the current optimal decision, (cid:98)x(cid:63)(k) = arg minx∈S (k)
The optimal search terminates when the simulation budget C is exhausted. Otherwise, we generate a new set of design
points D(k+1)
, set the number of iteration k = k + 1 and then loop back to Step (2) for solving the second-stage
optimization problems at any xi ∈ D(k+1)
. The EI criterion used in the second-stage optimization was originally
introduced for the deterministic simulation and it is appropriate for the stochastic cases; see Huang et al. [14] and Quan
et al. [35]. Thus, following Sun et al. [15], we construct a sampling distribution,

x

x

x

f (k+1)(x) =

Pr{ (cid:101)G(x) < ¯G((cid:98)x(cid:63)(k))}
xi∈X Pr{ (cid:101)G(xi) < ¯G((cid:98)x(cid:63)(k))}

(cid:80)

,

(24)

where (cid:101)G(·) ∼ GP o( (cid:98)G(·), s2(·)). Since Pr{ (cid:101)G(x) < ¯G((cid:98)x(cid:63)(k))} is the posterior possibility that the point x ∈ X achieves
a better objective value than the current optimal, the normalized probability mass function f (k+1)(x) reﬂects the
potential of point x. The sampling distribution f (k+1)(x) is used for generating a new set of ﬁrst-stage design points

9

for the next (k + 1)-th iteration with the size |D(k+1)

D(k+1)
| = s. Following Sun et al. [15], we set s = 5 in the
x
x
empirical study. Notice that if the ﬁrst-stage solutions x drawn in the early iterations are promising, they are more
likely to be selected again and we invest more simulation budget there to get more accurate estimation on G(x). On
the other hand, if such ﬁrst-stage candidate solutions are inferior, they are less likely to be selected again. Thus, the
proposed algorithm can efﬁciently utilize the simulation budget to search for the optimal solution x(cid:63).

4.4 Convergence of Global-Local Metamodel Assisted Two-Stage OvS

In this section, we provide the theoretical guarantee of the convergence for the proposed global-local metamodel assisted
two-stage OvS. The results are given under following assumptions:

1. The response θ(x, y, ξξξ) ≡ c0(x) + q(x, y, ξξξ) is bounded for any x ∈ X , y ∈ Y(x) and ξξξ ∼ F (ξξξ). There
exists a bound M such that (cid:107)q(cid:107)Hφ(X ) ≤ M , where Hφφφ(X ) denotes the reproducing kernel Hilbert space
(RKHS) of correlation function Rφφφ(z, z(cid:48)) (z ≡ (y, ξξξ)) on (Y(x), Ξ).

2. The ﬁrst- and second-stage feasible sets are ﬁnite, i.e., |X | < ∞ and |Y(x)| < ∞ for any x ∈ X .
3. The spatial variance for ﬁrst- and second-stage GP is strictly positive, i.e., σ2 > 0 and τ 2 > 0.
4. The MLEs for σ2 and τ 2 and φ are consistent under some regularity conditions [49].

The main result is shown in Theorem 1 and detailed proofs are provided in the appendix.

We start with Lemma 1 showing that the number scenarios allocated to any x ∈ X goes to inﬁnity as the number of
iterations or the simulation budget goes to inﬁnity, N (k)(x) → ∞ w.p.1 as k → ∞. Then, the ﬁnite sampling error
reduces to zero.
Lemma 1. Suppose that the metamodel-assisted optimization approach proposed in Algorithm 1 is used to solve the
two-stage optimization problem (3) and Assumptions 1–4 holds. Then N (k)(x) → ∞ w.p.1 k → ∞ ∀x ∈ X .

Furthermore, since the second-stage optimization search is based on the expected improvement. In the proposed
algorithm, we gradually reduce the second-stage optimality gap through controlling the threshold of relative expected
improvement. Then, in Lemma 2, we can show that the expected improvement for any unobserved second-stage
decision y is positive and bounded. By letting the threshold α(k)(x) gradually decreasing to zero as k → ∞, all untried
points will eventually be simulated. It implies that we eventually visit all possible solutions in Y(x) when k is large and
the optimality gap becomes zero.
Lemma 2. Suppose that the metamodel-assisted optimization approach proposed in Algorithm 1 is used to solve the
two-stage optimization problem (3) and Assumptions 1–4 holds. Then δ(x, ξξξj) → 0 w.p.1 as k → ∞ ∀x ∈ X .

Theorem 1 shows that our two-stage optimization approach can guarantee the global convergence as the simulation
budget C goes to inﬁnity. Since it simultaneously reduces the ﬁnite sampling error introduced by SAA and the error
induced by the second-stage optimality gap to zero, we have a consistent performance estimator as the simulation
budget goes to inﬁnite, ¯G(x) → G(x) as N (x) → ∞ for any x ∈ X . Then, following the proof in Sun et al. [15], we
can show that ¯G((cid:98)x(cid:63))→G(x(cid:63)) w.p.1 as the budget C → ∞ or the number of iteration k → ∞.
Theorem 1. Suppose that Assumptions 1–4 holds and the metamodel-assisted optimization approach proposed in
Algorithm 1 is used to solve the two-stage optimization problem (3). Denote x(cid:63) as the true optimal solution, i.e.,
G(x(cid:63)) = arg minx∈X G(x). Let (cid:98)x(cid:63)(k) be the optimal decision obtained in the k-th iteration with the objective estimate
¯G((cid:98)x(cid:63)(k)). Then, ¯G((cid:98)x(cid:63)(k))→G(x(cid:63)) w.p.1 as the simulation budget C → ∞ or the iteration k → ∞.

5 Empirical Study

In this paper, we consider two-stage stochastic programming for complex systems with unknown second-stage response
surface. The existing simulation optimization approaches typically consider one-stage optimization. In addition, to
the best of our knowledge, the two-stage stochastic programming approaches typically assume the response surface
qx(y, ξξξ) known; see the literature review in Section 2. Thus, in this section, we compare the ﬁnite sample performance
of proposed global-local metamodel assisted two-stage OvS with two methods, including a random sampling SAA
approach and the deterministic look-ahead (DLH) policy model solved by using the state-of-art simulation optimization
approach, called Gaussian process-based search approach (GPS) proposed in [15].

For the random sampling SAA approach, without any prior information about the optimal ﬁrst- and second-stage
decisions, suppose that all ﬁrst-stage solutions have equal probability to be optimal. Also at any given ﬁrst-stage

10

decision, all second-stage solutions have equal probabilities to be the best. Thus, in this approach, we randomly
generate N1 ﬁrst-stage candidate solutions, {x1, x2, . . . , xN1 }. At each solution xi with i = 1, 2, . . . , N1, we generate
N2 scenarios {ξξξi1, ξξξi2, . . . , ξξξiN2}. For each scenario ξξξij with j = 1, 2, . . . , N2, we randomly generate C/(N1N2)
second-stage solutions and select the best one as the optimal (cid:98)y(cid:63)
ij. Then, for each visited ﬁrst-stage solution xi with
i = 1, 2, . . . , N1, we aggregate the results from all N2 second-stage optimization problems, and obtain an estimate
of the objective value, ¯G(xi) = c0(xi) + (cid:80)N2
ij, ξξξij)/N2. The ﬁrst-stage solution giving the best objective is
¯G(xi).
selected, (cid:98)x(cid:63) = arg minxi∈{x1,x2,...,xN1 }
For the deterministic look-ahead policy model (see the description in [38]), we consider

j=1 qxi((cid:98)y(cid:63)

min
x∈X ,y∈Y(x)

GD(x, y) ≡ c0(x) + Eξξξ [q(x, y, ξξξ)] ,

(25)

which can be used for stochastic control [50]. Then, the Gaussian process-based search approach (GPS) proposed in [15]
is used to efﬁciently solve the optimization problem in (25). Speciﬁcally, we model the unknown mean response surface
GD(·) with a GP metamodel having the spatial variance denoted as σ2
GP S. Then, following the simulation optimization
proposed in [15], we develop a sampling distribution to efﬁciently guide the search for the optimal decisions of (x, y).
In each iteration, the sampling distribution is used to generate m promising decisions of (x, y). At each selected (x, y),
we assign r independent scenarios of ξξξ. We repeat this search procedure until reaching to the computational budget.

To study the ﬁnite sample performance of proposed framework and compare it with the random sampling SAA and
the deterministic look-ahead approach with GPS, we consider two examples, including a simple two-stage linear
optimization problem and a supply chain management example.

5.1 A Two-Stage Linear Optimization Problem

We ﬁrst consider a two-stage linear stochastic optimization example from Ekin et al. [6],

min
0≤x≤3

G(x) = −3x + E[Q(x, ξ)] with Q(x, ξ) = min
y≥0

{ξy : 0.5x + y ≤ 5}

(26)

where ξ follows the lognormal distribution with mean 0 and variance 1. It is easy to see that the ﬁrst-stage optimal
solution is x(cid:63) = 3. Notice that the objective function in (26) is monotonic in x, which means that the closer a solution
x is to the true optimal x(cid:63) = 3, the better quality it has. Thus, we can examine the algorithm’s performance by directly
checking the value of optimal ﬁrst-stage decision (cid:98)x(cid:63). To study the performance of our approach, we pretend that the
objective function is unknown, and it is estimated by simulation. We discretize the solution spaces of x and y with an
increment 0.01. In our optimization procedure, we set the initial threshold for the second-stage relative optimality gap
α0 = 0.1 and set the initial number of scenarios n0 = 10.

We study the performance of proposed global-local metamodel assisted two-stage OvS, random sampling SAA approach,
and deterministic look-ahead policy with GPS (DLH-GPS) under different simulation budget C = 600, 1000, 2000.
For the random sampling SAA approach, we consider two representative settings for N1 and N2: N1 = 10, N2 = 10
and N1 = 10, N2 = 20. For the GPS, we set m = 10, r = 10 when the budget C = 600, 1000 and set m = 13, r = 10
when C = 2000. Following the setting of Section (5.1) in [15], we set the spatial variance of the GP to be σGP S = 5.
Table 1 records mean and standard deviation (SD) of (cid:98)x(cid:63) obtained by using these approaches. The results are estimated
based on 100 macro-replications. Given the same simulation budget, our method and deterministic look-ahead with
GPS provide much higher quality solutions in terms of means and standard deviations of (cid:98)x(cid:63). They deliver (cid:98)x(cid:63) very
close to x(cid:63) = 3 with all three budget levels. By contrast, the optimal decision obtained by the random sampling SAA
approach has low quality and high estimation uncertainty, and it shows only a small improvement as C increases.

Table 1: Mean and SD of (cid:98)x(cid:63) obtained by three candidate approaches

Our approach

DLH-GPS

Random sampling SAA
(N1 = 10, N2 = 10)

Random sampling SAA
(N1 = 10, N2 = 20)

C = 600
C = 1000
C = 2000

mean
2.91
2.92
2.94

SD
0.07
0.05
0.04

mean
2.91
2.92
2.93

SD mean
2.69
0.07
2.68
0.06
2.73
0.05

SD
0.28
0.29
0.22

mean
2.67
2.67
2.73

SD
0.27
0.31
0.22

We also examine the estimation accuracy of ¯G((cid:98)x(cid:63)), the estimator of corresponding objective G((cid:98)x(cid:63)) of the obtained
optimal solution (cid:98)x(cid:63). Since for each (cid:98)x(cid:63) with G((cid:98)x(cid:63)) = −3(cid:98)x(cid:63), we can calculate the relative estimation error rE ≡
| ¯G((cid:98)x(cid:63))−G((cid:98)x(cid:63))|
· 100%. Table 2 documents mean and SD of rE in % obtained by using these three approaches. Our
G((cid:98)x(cid:63))

11

Table 2: Mean and SD of relative estimation error rE ≡ | ¯G((cid:98)x(cid:63)) − G((cid:98)x(cid:63))|/G((cid:98)x(cid:63)) · 100% (in %).
Random sampling SAA
(N1 = 10, N2 = 20)

Random sampling SAA
(N1 = 10, N2 = 10)

Our approach DLH-GPS

C = 600
C = 1000
C = 2000

mean
5.4
5.0
4.0

SD
3.0
2.9
3.0

mean
5.5
5.2
4.0

SD mean
24.2
3.2
24.1
2.8
22.1
3.0

SD
5.0
6.0
4.0

mean
23.1
21.7
22.0

SD
5.6
6.2
6.0

method can provide reliable estimates of G((cid:98)x(cid:63)). The random sampling SAA method shows its deﬁciency in the
objective value estimation accuracy and it has only a small improvement as C increases.

In addition, we further study the two-stage linear optimization problem in (26) and note that ξy is monotonically
increasing in y for ξ > 0. Since ξ follows the lognormal distribution, it means that the optimal value y(cid:63) doesn’t
depend on ξ. That explains why the proposed global-local metamodel assisted two-stage OvS demonstrates the similar
performance with the deterministic look-ahead approach with GPS.

5.2 A Supply Chain Management Example

In this section, we use a supply chain management example to study the performance of our approach. It is inspired
by our research collaboration with a bio-pharmaceutical manufacturing company. The company produces various
commercial and clinical products, which requires some common vital raw materials, including soy and other chemical
raw materials. For simpliﬁcation, we only consider the soy raw material and one type of raw chemical material used
for producing the key clinical product. The company orders soy and chemical raw material from outside vendors.
While the chemical raw material can be fast-delivered, due to the regulations and long testing cycles, soy has long lead
time. Since the clinical demand has high prediction uncertainty [42], the company faces high ﬂuctuations in the total
cost. Thus, the company is interested in ﬁnding the ﬁrst-stage soy ordering decision x and the second-stage decisions
y = (u, s, S), including production scheduling u and inventory control for the raw chemical material (speciﬁed by
(s, S) review policy), to minimize the expected overall cost.

Considering the long lead time of soy delivery, the company ﬁrst forecasts the clinical demand and places the soy order
x in advance. Suppose that x is within the range [0, 5000] with an increment 20. Then, after the clinical demand is the
realized, the company needs to make two types of decisions: the inventory control for the chemical material and the
daily production decision u. Due to the fast-delivery nature, the company excises the daily review (s, S) policy for the
chemical raw material satisfying 100 ≤ s < 400, 200 ≤ S < 500 and s < S. Here, we consider a variety of choices:
(s, S) = (100, 200), (100, 300), (100, 400),(100, 500), (200, 300),(200, 400),(200, 500),(300, 400), (300, 500), and
(400, 500). For simpliﬁcation, suppose that the chemical raw material orders have zero lead time.

The production planning horizon has four weeks, and each week has ﬁve work days. Let D = (d1, d2, d3, d4), where
di denotes the aggregated clinical demand occurring in the i-th week with i = 1, 2, . . . , 4. If the production can not
fully meet the demand di, the unmet demand will be subcontracted at a much higher price Pc per unit. If the company
produces more than needed, the additional products will be stored with the holding cost as Pe per unit. The goal is to
minimize the expected total cost,

min
x∈X

G(x) ≡ Psx + ED

(cid:104)

min(s,S,u)

(cid:16)

(cid:80)4

i=1

Pr · (cid:80)5

j=1 oij + Pc · h−

i + Pe · h+

i

(cid:17)(cid:105)

S.t.

i = max(di − h+
h−
i = max(h+
h+
Iij = max(Ii,j−1 − u + oij, 0)

i−1 − 5u, 0) ∀i
i−1 + 5u − di, 0) ∀i

(cid:26)S − Iij,

oij =

0,

0 ≤ u ≤ x/20,

Iij ≤ s,
Iij > s.
u is an integer,

where Ps and Pr are the unit ordering costs for soy and chemical raw material, h+
i denotes the inventory left at week
i, h−
i denotes the unmet demand for week i, oij and Iij denote the raw chemical material ordering decision and the
inventory in the j-th day of i-th week. Let starting chemical raw material inventory I10 = 100. Thus, the second-stage
production cost at the i-th week consists of the ordering cost for the fast-delivery chemical, the subcontract and inventory
costs. Let the soy ordering price Ps = 10, the chemical ordering price Pr = 5, the inventory cost Pe = 5 and the

12

Table 3: Maximum absolute relative difference for G(x) estimation.

NB
relativeError

102
9.1%

5 × 102
3.5%

103
3.2%

5 × 103
0.6%

104
0.3%

5 × 104
0.2%

penalty Pc = 100. For the deterministic look-ahead policy, we solve the optimization problem,

min
x,s,S,u

GD(x, s, S, u) ≡ Psx + ED

(cid:104)(cid:80)4

i=1

(cid:16)

Pr · (cid:80)5

j=1 oij + Pc · h−

i + Pe · h+

i

(cid:17)(cid:105)

.

We apply Gaussian process-based search approach (GPS) with same setting as 5.1 except the standard deviation of the
Gaussian process σGP S = 15 following Section (5.2) in [15].

Given any x, since there is no closed-form of G(x), we use SAA with NB scenarios to correctly estimate the mean
response, which will be used to assess the performance of optimal solutions obtained by the different candidate
approaches. To determine the proper sample size NB so that we can accurately estimate the objective G(x), we did
a side experiment by running 10 macro-replications. In each macro-replication, we randomly generate a ﬁrst-stage
action x (with equal probability at each solution). Then, we generate NB second-stage problems. For each second-stage
problem, we exhaustively go through every combination of y and thus ﬁnd the corresponding second-stage optimal
decisions. For various choices of NB, we record the relative difference error | ¯G(x) − G(x)|/G(x), where G(x) denotes
the objective value by 105 second-stage samples. Suppose 105 is large enough and the ﬁnite sample estimation error is
negligible. The maximum relative error for different choices of NB obtained from 10 macro-replications is recorded in
Table 3. We observe that NB = 5000 has the maximum relative error not exceeding 1%. Balancing the computational
cost and the accuracy, we use NB = 5000 to evaluate the objective value for x.

Moreover, by conducting the side experiment, we obtain the true response surface G(x) against soy order x for
cases with σ = 10, 20, 30. We get the optimal cost: G(x(cid:63)) = 9912 for σ = 10, G(x(cid:63)) = 10625 for σ = 20, and
G(x(cid:63)) = 11484 for σ = 30.

√

g) ≡ SD(G(cid:63)

n) and SE(G(cid:63)

g) and SE(G(cid:63)
g)/

g), respectively. Let nm represent the number macro-replications, E(G(cid:63)

Then, given the same simulation budget, we compare the results obtained from proposed global-local metamodel assisted
two-stage OvS, the random sampling SAA approach, and DLH-GPS. Denote mean and SE of G((cid:98)x(cid:63)) obtained by our
g) ≡ E[G((cid:98)x(cid:63))]
approach as E(G(cid:63)
and SE(G(cid:63)
nm, where SD represents the standard deviation (SD) of optimal objective estimate obtained
from each macro-replication. Denote mean and SE of G((cid:98)x(cid:63)) obtained by the random sampling SAA approach as
E(G(cid:63)
s). In Tables 4–6, we
record the results obtained from these approaches when C = 600, 1000, 2000 and d ∼ N (150, 102), N (150, 202) and
N (150, 302). They are based on nm = 100 macro-replications. The mean of G((cid:98)x(cid:63)) tends to decrease as the budget
C increases. The results in Tables 4–6 show that our approach signiﬁcantly outperforms the DLH-GPS and random
sampling SAA approaches. It leads to much smaller expected cost and SE. Moreover, we also see the mean of G((cid:98)x(cid:63))
increases as the variance of demand increases for all approaches. It agrees with the real-world fact that the higher
prediction uncertainty of demand results in higher cost of production scheduling and inventory control.

n). Denote those obtained by the DLH-GPS approach as E(G(cid:63)

s) and SE(G(cid:63)

Table 4: Performance statistics of G((cid:98)x(cid:63)) when di ∼ N (150, 102)

Our approach
SE(G(cid:63)
g)
151
148
104

E(G(cid:63)
g)
12004
11836
11290

DLH-GPS

E(G(cid:63)
s)
13087
12217
11906

SE(G(cid:63)
s)
224
227
295

Random Sampling SAA
(N1 = 10, N2 = 10)
E(G(cid:63)
n)
16083
15789
15380

SE(G(cid:63)
n)
428
369
405

Random Sampling SAA
(N1 = 10, N2 = 20)
E(G(cid:63)
n)
15917
15408
14605

SE(G(cid:63)
n)
428
368
313

C = 600
C = 1000
C = 2000

Table 5: Performance statistics of G((cid:98)x(cid:63)) when di ∼ N (150, 202)

Our approach
SE(G(cid:63)
g)
173
97
82

E(G(cid:63)
g)
12135
11905
11771

DLH-GPS

E(G(cid:63)
s)
13066
12965
12272

SE(G(cid:63)
s)
217
163
199

Random Sampling SAA
(N1 = 10, N2 = 10)
E(G(cid:63)
n)
16462
16342
16316

SE(G(cid:63)
n)
427
371
416

Random Sampling SAA
(N1 = 10, N2 = 20)
E(G(cid:63)
n)
16188
15753
15391

SE(G(cid:63)
n)
421
371
324

C = 600
C = 1000
C = 2000

In addition, we deﬁne the relative estimation error as r∆Gγ ≡ {E[G((cid:98)x(cid:63)
γ)−G(x(cid:63))]/G(x(cid:63))
with γ = g, s, n representing the results obtained by proposed global-local metamodel assisted two-stage OvS,

γ)]−G(x(cid:63))}/G(x(cid:63)) = [E(G(cid:63)

13

Table 6: Performance statistics of G((cid:98)x(cid:63)) when di ∼ N (150, 302)

Our approach
SE(G(cid:63)
g)
97
125
66

E(G(cid:63)
g)
12601
12522
12236

DLH-GPS

E(G(cid:63)
s)
13507
13378
12929

SE(G(cid:63)
s)
217
155
189

Random Sampling SAA
(N1 = 10, N2 = 10)
E(G(cid:63)
n)
17103
16684
16815

SE(G(cid:63)
n)
438
368
415

Random Sampling SAA
(N1 = 10, N2 = 20)
E(G(cid:63)
n)
16657
16063
15995

SE(G(cid:63)
n)
423
357
322

C = 600
C = 1000
C = 2000

DLH-GPS and random sampling SAA approach respectively. The true optimal solution x(cid:63) is obtained by the side
experiments. For the case with d ∼ N (150, 202), even with a very tight budget C = 600, our approach can identify the
promising solutions. The average objective value obtained by our approach is 12, 135 and we have r∆Gg = 14.2%,
r∆Gs = 23.0% and r∆Gn = 54.9%, 52.4% for two random sampling SAA settings respectively. It shows our
approach outperform DLH-GPS by 9% and random sampling SAA by about 40%. As C grows, the performance of our
approach signiﬁcantly improves. When C = 1000, our method delivers the optimal solution with the objective value
equal to 11, 905. We get r∆Gg = 12.0%, r∆Gs = 22.0% and r∆Gn = 53.8%, 48.3% for two random sampling SAA
settings. The results suggest that our approach outperforms the deterministic look-ahead approach with GPS by 10%
and the random sampling SAA method by about 40%. The similar performance is also observed when d ∼ N (150, 102)
and N (150, 302). When the variability of the demand increases, it requires a larger simulation budget to search for the
optimal solution. According to Tables 4–6, we see the estimate E(G(cid:63)
g) obtained by our algorithm converges to the true
optimum faster than the other competitors.

Furthermore, in order to better understand the convergence behavior obtained from the proposed approach, we plot
G((cid:98)x(cid:63)(k)) with respect to the number of iterations k. We record the results from 10 representative runs in Figure 1. They
indicate that our algorithm can quickly search for the optimal solutions. In addition, the average overhead computational
cost from our approach is 0.8 seconds per simulation run when C = 600, 1000, and 2 seconds when C = 2000. Since
we consider the situations where each simulation run could be computationally expensive, the overhead is negligible.

Figure 1: Ten representative sample path plots of G((cid:98)x(cid:63)(k)) versus the index of iteration k for the supply chain
management example with σ = 20

In addition, we study the performance of proposed approach as the dimension of second-stage decisions y increases.
Speciﬁcally, we modify the supply chain management example by allowing more ﬂexible production and inventory
decision making. Let u1, u2 and (s1, S1), (s2, S2) represent the daily production and inventory control decisions made

14

in the ﬁrst and second two weeks. Then we replace the constraint 0 ≤ u ≤ x/20 in (27) with

0 ≤ u1 + u2 ≤ x/10.

We consider the daily inventory review policy (si, Si) for the chemical raw material satisfying 100 ≤ si < 400,
200 ≤ Si < 500 and si < Si with i = 1, 2. Thus, as we change from y = (u, s, S) to y = (u1, u2, s1, S1, s2, S2), the
dimension and complexity of second-stage optimization problem also increase. Under the same parameter setting as
Section 5.2, the results obtained from our algorithm, DLH-GPS and random sampling SAA approaches are summarized
in Table 7. We can see that the proposed global-local metamodel assisted two-stage OvS still delivers the optimal
solution with smaller expected cost in all budget levels than the other two algorithms.

Table 7: Performance statistics of G((cid:98)x(cid:63)) with the increased size of second stage when di ∼ N (150, 202)
Random Sampling SAA
(N1 = 10, N2 = 20)

Random Sampling SAA
(N1 = 10, N2 = 10)

Our approach
SE(G(cid:63)
221
292
193

E(G(cid:63)
g)
12948
12621
12606

DLH-GPS
g) E(G(cid:63)
s)
13532
13339
13282

SE(G(cid:63)
362
353
297

s) E(G(cid:63)
n)
17007
16687
16510

C = 600
C = 1000
C = 2000

SE(G(cid:63)
n)
443
405
385

E(G(cid:63)
n)
16730
16184
16160

SE(G(cid:63)
n)
440
408
439

5.3 The effect of α0 and n0

Comparing with one-stage optimization studied in the simulation literature, in two-stage stochastic programming, the
optimality gap from the second-stage optimization impacts the search performance. Thus, we study the effect of α0 in
this section. The relative EI threshold α0 impacts the exploitation and exploration trade-off. When α0 is large, our
proposed algorithm turns to put less effort for second-stage optimization for each scenario. When α0 is small, we could
spend more efforts to search for the second-stage optimal solution for each scenario.

Here, we empirically study the effect of α0. Tables 8 and 9 provide the results for the examples in Sections 5.1 and
5.2 when α0 = 0.05, 0.1, 0.2. Table 8 indicates the choice of α0 has relative less impact on the optimization for the
two-stage linear optimization problem. Table 9 provides mean and SE of G((cid:98)x(cid:63)) for the supply chain management
example when di ∼ N (150, 202). All three settings can deliver near-optimal (cid:98)x(cid:63) while the SD of (cid:98)x(cid:63) obtained from
α0 = 0.1 is slightly smaller than the other two settings.

Table 8: For the two-stage linear optimization problem, mean and SD of (cid:98)x(cid:63) when α0 = 0.05, 0.1, 0.2.

α0 = 0.05

α0 = 0.1

α0 = 0.2

C = 600
C = 1000
C = 2000

mean
2.90
2.91
2.93

SD mean
2.91
0.07
2.92
0.07
2.94
0.06

SD mean
2.90
0.07
2.93
0.05
2.93
0.04

SD
0.07
0.06
0.07

We also conduct the experiments studying the impact of n0 by using both examples. Tables 10 and 11 provide the
corresponding results when n0 = 10, 20 under the same parameter setting. Table 10 doesn’t show signiﬁcant difference
between n0 = 10 and 20 in all three budget levels for the two-stage linear optimization problem. In the supply chain
management example, however, we see better result for n0 = 20 according to Table 11. In general, n0 plays an
important role in the trade-off between exploitation and exploration. When ξξξ has higher uncertainty and the complexity
of the response surface G(x) is lower, we could require a larger number of initial scenarios, n0. Without strong prior
information, we would recommend starting with n0 = 10.

6 Conclusion

In this paper, we propose a global-local metamodel assisted two-stage OvS that can efﬁciently employ the tight
simulation budget to solve the stochastic programming for complex systems. In particular, for each visited ﬁrst-stage
decision, we construct a local metamodel which allows us to simultaneously solve all second-stage optimization
problems sharing the same ﬁrst-stage decision. Then, based on the second-stage optimization results, we construct a
global metamodel accounting for the ﬁnite sampling error from SAA and the second-stage optimality gap. Assisted by
the global-local metamodel, we develop a two-stage optimization approach that can efﬁciently employ the simulation

15

Table 9: For the supply chain management example, mean and SE of (cid:98)x(cid:63) for α0 = 0.05, 0.1, 0.2 when nm = 100,
n0 = 10 and di ∼ N (150, 202)

α0 = 0.05

α0 = 0.1

α0 = 0.2

C = 600
C = 1000
C = 2000

E(G(cid:63)
g)
13230
13040
12093

SE(G(cid:63)
269
133
153

g) E(G(cid:63)
g)
12135
11905
11771

SE(G(cid:63)
173
97
82

g) E(G(cid:63)
g)
12343
12063
11724

SE(G(cid:63)
g)
180
158
137

Table 10: For the two-stage linear optimization problem, Mean and SD of (cid:98)x(cid:63) when n0 = 10, 20
n0 = 10

n0 = 20

C = 600
C = 1000
C = 2000

mean
2.91
2.92
2.94

SD mean
2.91
0.07
2.94
0.05
2.94
0.04

SD
0.07
0.07
0.08

Table 11: For the supply chain management example, Mean and SD of (cid:98)x(cid:63) for n0 = 10, 20 when nm = 100, α0 = 0.1
and di ∼ N (150, 202).

n0 = 10
E(G(cid:63)
g)
12135
11905
11771

SE(G(cid:63)
173
97
82

n0 = 20
g) E(G(cid:63)
g)
11711
11666
11192

SE(G(cid:63)
g)
83
132
66

C = 600
C = 1000
C = 2000

budget to iteratively solve for the optimal ﬁrst- and second-stage decisions. The empirical studies demonstrate that our
algorithm delivers superior and stable optimal decisions. The proposed methodology may lay the groundwork for future
research on two-stage risk-averse stochastic simulation optimization.

Acknowledgments

The authors acknowledge helpful discussion with Barry L. Nelson.

A Nomenclature

List of Symbols

Empirical Study
(s, S)
E(G(cid:63)
E(G(cid:63)
E(G(cid:63)
SE(G(cid:63)
SE(G(cid:63)
SE(G(cid:63)
σGP S
C
di
h+
i
h−
i

the daily review (s, S) policy for the raw chemical material.

g) mean of G((cid:98)x(cid:63)) obtained by the proposed global-local metamodel assisted two-stage OvS algorithm.
n) mean of G((cid:98)x(cid:63)) obtained by the random sampling SAA approach.
s) mean of G((cid:98)x(cid:63)) obtained by the DLH-GPS.
g) standard error of G((cid:98)x(cid:63)) obtained by the proposed global-local metamodel assisted two-stage OvS algorithm.
n) standard error of G((cid:98)x(cid:63)) obtained by the random sampling SAA approach.
s) standard error of G((cid:98)x(cid:63)) obtained by the DLH-GPS.

spatial standard deviation of the Gaussian process metamodel in the DLH-GPS algorithm.
simulation budget.
the aggregated clinical demand occurring in the i-th week with i = 1, 2, 3, 4.
the inventory left at week i.

unmet demand for the i-th week.

16

the raw chemical material inventory in the j-th day of i-th week.
number of observed ﬁrst-stage solutions for the random sampling SAA approach.
number of scenarios generated at each visited ﬁrst-stage decision for the random sampling SAA approach.
number of scenarios used to accurately estimate the objective G(x) at any x.
number of macro replications.
raw chemical material ordering decision in the j-th day of i-th week.
unit penalty cost for unmet demand.
unit inventory holding cost.
unit ordering costs for chemical raw material.
unit ordering costs for soy.

Iij
N1
N2
NB
nm
oij
Pc
Pe
Pr
Ps
r∆G the relative error between estimated optimal cost and and true optimum.
Functions
¯Gc(x) SAA estimator for any visited x with N (x) number of scenarios.
δ(xi, ξξξij) optimality gap δ(xi, ξξξij) ≡ qxi((cid:98)y(cid:63)
GP o( (cid:98)G(mX(cid:63)), s2(mX(cid:63))) the global Gaussian process metamodel at prediction points mX(cid:63) with mean (cid:98)G(mX(cid:63))

ij, ξξξij) − qxi(y(cid:63)

ij, ξξξij)

and variance s2(mX(cid:63)).

xi

(mZ)) the local Gaussian process metamodel at the prediction points Z.

GP xi((cid:98)qxi(mZ), s2
W(·)
(cid:101)qxi (yij ,ξξξij ) [I(yij, ξξξij)] the expected improvement (EI) for any untried point yij ∈ Y(xi) given the current optimum
E

the global GP metamodel, deﬁned as W(·) ≡ µ0 + W (·)

(cid:98)y(cid:63)
ij.
CDF of standard normal distribution
PDF of standard normal distribution
probability distribution function of ξξξ, characterizing the prediction uncertainty.

Φ
ϕ
F (ξξξ)
f (k+1)(x) sampling distribution used for generating a new set of ﬁrst-stage design points for the next (k + 1)-th

iteration.
objective function of the two-stage stochastic programming.

the set of ﬁrst-stage design points.
the set of second-stage design points at xi.
the set of ﬁnished second-stage scenarios at xi.
feasible set of ﬁrst-stage decisions
feasible set of second-stage decisions depending on x
the scenario set containing all possible ξξξ.

G(x)
M (z) GP model with mean zero.
q(x, y, ξξξ) second-stage response function
Sets
Po
Pxi
Uxi
X
Y(x)
Ξ
D(k)
x
S(k)
x
Variables
α(k)(xi) the relative EI threshold for any xi controlling the stopping criteria for second-stage optimization. For the
t-th visited ﬁrst-stage action x ∈ X with t > 1, the relative EI threshold for second-stage optimization is set to
be α0g− t−1
2 .
the initial relative EI threshold.
the global trend in local metamodel.
random input/scenarios

new ﬁrst-stage design point set generated at k-th iteration.
ﬁrst-stage design point set accumulated until the k-th iteration, i.e., S (k)

x = S (k−1)

(cid:83) D(k)
x .

α0
β0
ξξξ

x

17

the corresponding simulation outputs at given design points Pxi.
optimal ﬁrst-stage decision
ﬁrst-stage decision
optimal second-stage decision
second-stage decision
the global trend in global metamodel.
parameter of correlation function controlling the spatial dependence.
the spatial variance of correlation function of global metamodel.
the spatial variance of correlation function of local metamodel.

QPxi
x(cid:63)
x
y(cid:63)
y
µ0
φφφ
σ2
τ 2
(cid:101)qxi(·, ·) the posterior sample from the estimated GP, i.e. (cid:101)qxi(·, ·) ∼ GP xi((cid:98)qxi(·), s2
N (x)
n0
V

(·)).

xi

number of scenarios assigned to design point at x
initial number of scenarios allocated to each visited design point.
K × K diagonal covariance matrix of ¯GPo = ( ¯G(x1), ¯G(x2), . . . , ¯G(xK))(cid:48), where Po ≡ {x1, x2, . . . , xK}
denotes the global metamodel design points.

B Proof of Proposition 1

Proposition 1. Let d(x) ≡ minx(cid:48)∈X {|x − x(cid:48)|}. Then, we have the prediction variance s2(x) ≥ τ 2[1 − r(d(x))]2 and
the lower bound is zero if d(x) = 0.

Proof. Let ωωω = (Σ + V )−1 (cid:104)
V )−1Σ(x, ·). We ﬁrst show that ωωω has nice property (cid:80)K
scalars, we have

(cid:16) 1−1(cid:48)(Σ+V )−1Σ(x,·)
1(cid:48)(Σ+V )−11

Σ(x, ·) + 1

(cid:17)(cid:105)

, λ = 1−1(cid:48)(Σ+V )−1Σ(x,·)

and η = 1 − 1(cid:48)(Σ +
i ωi = 1. Since Σ(x, ·)(cid:48)(Σ + V )−11 and 1(cid:48)(Σ + V )−11 are

1(cid:48)(Σ+V )−11

ωωω(cid:48)1 =

(cid:20)
Σ(x, ·)(cid:48) + 1(cid:48)

(cid:18) 1 − 1(cid:48)(Σ + V )−1Σ(x, ·)
1(cid:48)(Σ + V )−11

(cid:19)(cid:21)

(Σ + V )−11

= Σ(x, ·)(cid:48)(Σ + V )−11 +

(cid:18) 1 − 1(cid:48)(Σ + V )−1Σ(x, ·)
1(cid:48)(Σ + V )−11

(cid:19)

1(cid:48)(Σ + V )−11

= 1.

Let ωi denote i-th element of ωωω. Then, for the prediction variance, we derive the lower bound as follows,

s2(x) = τ 2 − Σ(x, ·)(cid:48)[Σ + V ]−1Σ(x, ·) + η(cid:48)[1(cid:48)(Σ + V )−11]−1η

= τ 2 − Σ(x, ·)(cid:48)(Σ + V )−1Σ(x, ·) − λ (cid:2)1 − 1(cid:48)(Σ + V )−1Σ(x, ·)(cid:3)
= τ 2 + λ − Σ(mx, ·)(cid:48)(Σ + V )−1Σ(x, ·) − λ1(cid:48)(Σ + V )−1Σ(mx, ·)
= τ 2 + λ − ωωω(cid:48)Σ(x, ·)
= τ 2 + [Σ(x, ·)(cid:48) + λ1(cid:48)] ωωω − 2ωωω(cid:48)Σ(x, ·)
= τ 2 + ωωω(cid:48)(Σ + V )ωωω − 2ωωω(cid:48)Σ(x, ·)
≥ τ 2 + ωωω(cid:48)Σωωω − 2ωωω(cid:48)Σ(x, ·)



= τ 2

1 +



≥ τ 2

1 +

K
(cid:88)

K
(cid:88)

i=1

j=1

K
(cid:88)

K
(cid:88)

i=1

j=1

ωiωjr(xi, xj) − 2



ωir(x, xi)



K
(cid:88)

i=1

ωiωjr(x, xi)r(x, xj) − 2



ωir(x, xi)



K
(cid:88)

i=1

(cid:34)

≥ τ 2

1 −

K
(cid:88)

i=1

(cid:35)2

ωir(x, xi)

18

(27)

≥ τ 2[1 − r(d(x))]2.

(28)

Step (27) follows because the correlation function r(·) satisﬁes r(x1 −x2) ≥ r(x−x1)r(x−x2) for any x, x1, x2 ∈ X .
Step (28) follows by applying (cid:80)K
i ωi = 1. Notice that τ 2[1 − r(d(x))]2 = 0 if x is one of design points, i.e.,
d(x) = minx(cid:48)∈X {|x − x(cid:48)|} = 0.

C Proof of Lemmas 3, 4 and 5

Lemma 3, 4 and 5 will facilitate the following proofs of convergence.
Lemma 3. Suppose that the global-local metamodel-assisted OvS approach proposed in Algorithm 1 is used to solve
the two-stage optimization problem (3). For any x ∈ X , if f (k)(x) ≥ c inﬁnitely often (i.o.) for some constant c > 0,
then N (k)(x) → ∞ w.p.1 as k → ∞.

Proof. The proof follows by applying Lemma (1) in [15].

Lemma 4. Suppose that the global-local metamodel-assisted OvS approach proposed in Algorithm 1 is used to solve
the two-stage optimization problem (3). Then N (k)((cid:98)x(cid:63)(k)) → ∞ w.p.1 as k → ∞.

Proof. The proof follows by applying Lemma (2) in [15].

Lemma 5. Suppose that the global-local metamodel-assisted OvS approach proposed in Algorithm 1 is used to solve the
two-stage optimization problem (3) with ﬁnite ﬁrst- and second-stage decision spaces, i.e., |X | < ∞ and |Y(x)| < ∞
for any x ∈ X . Then we have lim inf k→∞ ¯G((cid:98)x(cid:63)(k)) > G(x(cid:63)) − ν for any ν > 0 w.p.1. It’s equivalent to show

Pr{ ¯G((cid:98)x(cid:63)(k)) < G(x(cid:63)) − ν

i.o.} = 0.

Proof. Following the proof of Lemma (3) in [15], at the end of each iteration, for any x ∈ X , we add additional scenarios
(cid:0)N (k)((cid:98)x(cid:63)(k)), N (k)(x)(cid:1)
to x such that the number of scenarios at x is at least N (k)((cid:98)x(cid:63)(k)). Let n(k)(x) = maxx∈X
and denote ¯G with additional scenarios as ¯Ga(x) = 1

{ ˘Gj(x) − E[δ(x, ξξξj)|ξξξj]}.

(cid:80)n(k)(x)
j=1

n(k)(x)

Given ﬁnite decision space |X | < ∞, when we use the Stochastic kriging global metamodel searching for the optimal
ﬁrst-stage decision, Lemma 4 states that n(k)(x) → ∞ as the iteration k → ∞ or the simulation budget C → ∞. Since
n(k)(x) = (cid:100)n0gt(x)−1(cid:101), the number of revisits t(x) → ∞ as k → ∞, which further implies α(k)(x) → 0 as k → ∞.
By applying Lemma 2, we can show δ(k)(x, ξξξj) a.s.→ 0 as k → ∞.

Let ¯Gc(x) ≡
¯Gc(x) are all ﬁnite, by applying the triangle inequality, we have

1
n(k)(x)

(cid:80)n(k)(x)

j=1 Gj(x) with Gj(x) = c0(x) + q(x, y(cid:63), ξξξj). For any ν > 0, since ¯Ga(x), G(x) and

| ¯Ga(x) − G(x)| = | ¯Ga(x) − ¯Gc(x) + ¯Gc(x) − G(x)|

< | ¯Ga(x) − ¯Gc(x)| + | ¯Gc(x) − G(x)|
< ν, as k → ∞.

(29)
The inequality in (29) follows because: (1) | ¯Gc(x) − G(x)| < ν/2 holds by applying n(k)(x) → ∞ and the strong
law of large numbers; and (2) | ¯Ga(x) − ¯Gc(x)| < ν/2 holds by applying δ(k)(x, ξξξ) → 0. That means ¯Ga(x) → G(x)
w.p.1 as k → ∞. Since G(x(cid:63)) = minx∈X G(x) ≤ G(x), we have
Pr{ ¯Ga(x) < G(x(cid:63)) − ν

i.o.} = 0

as k → ∞. Hence, with |X | < ∞ and minx∈X ¯Ga(x) ≤ Pr{ ¯G((cid:98)x(cid:63)(k)), we have
i.o.} ≤ Pr{min
x∈X

Pr{ ¯G((cid:98)x(cid:63)(k)) < G(x(cid:63)) − ν

¯Ga(x) < G(x(cid:63)) − ν

i.o.}

≤

(cid:88)

x∈X

Pr{ ¯Ga(x) < G(x(cid:63)) − ν

i.o.} = 0.

19

D Proof of Lemmas 1 and 2

Proof. (Lemma 1) It sufﬁces to prove Pr{limk→∞ N (k)(x) < N } = 0 ∀x ∈ X , ∀N > 0. By Lemma 5, for all x ∈ X ,

Pr{ lim
k→∞

N (k)(x) < N } = Pr{ lim
k→∞

N (k)(x) < N, lim inf
k→∞

¯G((cid:98)x(cid:63)(k)) > G(x(cid:63)) − ν}

for any ν > 0. Let Ω(x) = {limk→∞ N (k)(x) < N, lim inf k→∞ ¯G((cid:98)x(cid:63)(k)) > G(x(cid:63)) − ν}. It sufﬁces to show that
Pr{Ω(x)} = 0 for all x ∈ X .

Without loss of generality, we can follow Sun et al. [15] to set a predetermined large positive constant M such that
| ¯G(x)| < M . Thus, we have |(cid:98)µ0| = [1(cid:48)(Σ + V )−11]−11(cid:48)(Σ + V )−1| ¯GPo| ≤ M . Since Σ is symmetric positive
deﬁnite and V is diagonal positive deﬁnite, we can apply eigendecomposition to Σ such that Σ = QΛQ(cid:48), Q−1 = Q(cid:48).
Furthermore, by Woodbury identity [51], [Λ + Q−1V Q]−1 = Λ−1 − Λ−1Q(cid:48)(V −1 + QΛ−1Q−1)−1QΛ−1 holds. Then,
we have the following inequality,

1(cid:48)[Σ + V ]−11 = 1(cid:48)[QΛQ(cid:48) + V ]−11

= 1(cid:48)Q[Λ + Q−1V Q]−1Q(cid:48)1
= 1(cid:48)Q (cid:2)Λ−1 − Λ−1Q(cid:48)(V −1 + QΛ−1Q−1)−1QΛ−1(cid:3) Q(cid:48)1
= 1(cid:48)QΛ−1Q(cid:48)1 − 1(cid:48)QΛ−1Q(cid:48)(V −1 + QΛ−1Q−1)−1QΛ−1Q(cid:48)1
≤ 1(cid:48)QΛ−1Q(cid:48)1
≤ 1(cid:48)[QΛQ(cid:48)]−11
≤ 1(cid:48)Σ−11.

(30)

(31)

(32)
Step (30) follows by applying Woodbury identity. Step (31) follows because (V −1 + QΛ−1Q−1)−1 is symmetric
positive deﬁnite. Thus we also have

(cid:98)G(x) = (cid:98)µ0 + Σ(x, ·)(cid:48)[Σ + V ]−1( ¯GPo − (cid:98)µ0 · 1)
≤ M + 2 · Σ(x, ·)(cid:48)[Σ + V ]−11 · M
≤ M (1 + 2τ 21(cid:48)Σ−11).

The last step follows by applying (32). Notice that τ 2Σ−1 is correlation matrix deﬁned by the set of ﬁrst-stage design
points Po with |Po| = K. Denote this correlation matrix as

RPo⊆X ≡







r(x1, x1)
r(x2, x1)
...
r(xK, x1)

r(x1, x2)
r(x2, x2)
...
r(xK, x2)

. . .
. . .
...
. . .

r(x1, xK)
r(x2, xK)
. . .
r(xK, xK)







.

By |X | < ∞ from Assumption 2, there is only ﬁnite number (2|X | − 1) of those correlation matrices. Then, let
dmax = minPo⊆X {1 + 21(cid:48)RPo1}, we have (cid:98)G(x) ≤ M dmax for any x ∈ X and k > 0.
For any ﬁrst-stage design point x that has been observed, without loss of generality, we can follow Sun et al. [15]
to assign a small positive variance, say σ2
min to guarantee the
exploration for those design points. For any ﬁrst-stage design point x that has not been observed, since the feasible
set X is discrete, by applying Proposition 1, we get s2(x) ≥ (cid:98)τ 2[1 − r(d)], where d = minx,x(cid:48)∈X {|x − x(cid:48)|}. By
Assumptions 3 and 4, (cid:98)τ 2 is the ML estimate of τ 2 > 0 and it is consistent. Thus, when k is large, there is (cid:15) > 0 such
that (cid:98)τ 2 ≥ τ 2 − (cid:15) > 0. Let s2 = (τ 2 − (cid:15))[1 − r(d)] and σ ≡ min(σmin, s). Then, we have s(x) ≥ σ, depending only
on X , φφφ, correlation function r.
Therefore, for any x ∈ X and ω ∈ Ω(x), there exists K(ω) such that ∀k > K(ω), ¯G((cid:98)x(cid:63)(k)) > G(x(cid:63)) − ν. For any
k > K(ω), let c = G(x(cid:63))−ν−M dmax

min, to bound the prediction uncertainty, s2(x) ≥ σ2

. Since c <

¯G((cid:98)x(cid:63))− (cid:98)G(x)
s(x)

σ

Pr{ (cid:101)G(x) < ¯G((cid:98)x(cid:63))} = Pr

(cid:40)

(cid:101)G(x) − (cid:98)G(x)
s(x)

<

¯G((cid:98)x(cid:63)) − (cid:98)G(x)
s(x)

(cid:40)

≥ Pr

(cid:101)G(x) − (cid:98)G(x)
s(x)

(cid:41)

< c

= Φ(c) > 0

, we have
(cid:41)

where Φ(·) is the CDF of a standard normal random variable. Then we have

f (k)(x) ≥

1
|X |

Φ(c) > 0.

By applying Lemma 3, we can get Pr{Ω(x)} = 0 for all x ∈ X .

20

Proof. (Lemma 2)
Lemma (1) states that N (k)(x) → ∞ for all x ∈ X as the iteration k → ∞ or the simulation budget C → ∞. Notice
that N (k)(x) = (cid:100)n0gt(x)−1(cid:101), the number of revisits t(x) → ∞ as k → ∞. That means α(k)(x) → 0 as k → ∞.
Let Θ(k)
search for j-th scenario ξξξj in k-th iteration. For any yj ∈ Y(x) if yj /∈ Θ(k)
positive,

(x) ≡ {yj ∈ Y(x) | yj has been visited at iteration k} denote a set including all visited points in the local
(x), the expected improvement is strictly

j

j

(cid:101)qx(yj ,ξξξj ) [I(yj, ξξξj)] ≡ E
E

(cid:101)qx(yj ,ξξξj )

(cid:2)max (cid:0)qx((cid:98)y(cid:63)

j , ξξξj) − (cid:101)qx(yj, ξξξj), 0(cid:1)(cid:3) > 0,

(cid:101)qx(yj ,ξξξj ) [I(yj, ξξξj)] = 0. Notice that 0 < qx(yj, ξξξj) ≤ qmax < ∞ for any x and yj (qmax exists since
otherwise E
q(x, y, ξξξ) is ﬁnite continuous function). From Assumption 1, we have (cid:107)q(cid:107)Hφ(X ) ≤ M . Let κ(x) ≡ xΦ(x) + ϕ(x).
By applying Assumption 2 and Proposition 1, we have s2
(x), where
d = minx∈X ;y,y(cid:48)∈Y(x){|y − y(cid:48)|} is the smallest distance between two second stage decision points. By Assumption 4,
under some regularity conditions, MLE (cid:98)τ 2 is consistent. Thus when k is large enough, there is (cid:15) such that (cid:98)σ2 ≥
σ2 − (cid:15) > 0 by Assumption 3. Then we have s2 = (σ2 − (cid:15))[1 − R(d)] depending only on ξξξj, R, X and Y(x). By
applying Lemma 8 in [52], we have

x(yj, ξξξj) ≥ σ2[1 − R(d)] > 0 for yj /∈ Θ(k)

j

(cid:101)qx(yj ,ξξξj ) [I(yj, ξξξj)] ≥ σκ(−M /σ)sx(yj, ξξξj) ≥ σκ(−M /σ)s > 0.
E

Thus, since α(k)(x) → 0 as k → ∞, ∃k0 > 0 such that for any yj ∈ Y(x)/Θ(k)

j

(x) and k > k0 we have

(cid:101)qx(yj ,ξξξj ) [I(yj, ξξξj)] ≡ E
E

(cid:101)qx(yj ,ξξξj )

(cid:2)max (cid:0)qx((cid:98)y(cid:63)

j , ξξξj) − (cid:101)qx(yj, ξξξj), 0(cid:1)(cid:3) > α(k)(x)qmax.

According to the stopping criteria for second-stage optimization (22), we eventually run simulations at all yj ∈
Y(x)/Θ(k)
(x) as α(k)(x) → 0. Then by the deﬁnition of second-stage optimality gap, for k > k0, we have zero
optimality gap for any ξξξj,

j

δ(k)(x, ξξξj) = qx((cid:98)y(cid:63)

j , ξξξj) − qx(y(cid:63)

j , ξξξj) = min
y∈Θ(k)

(x)

j

qx(y, ξξξj) − min
y∈Y(x)

qx(y, ξξξj) = 0

for j = 1, 2, . . . , N (x). It also implies δ((cid:98)x, ξξξj) a.s.→ 0 as k → ∞ because
δ((cid:98)x, ξξξj) = 0} = 1.

Pr{ lim
k→∞

E Proof of Theorem 1

Proof. Recall G(·) is the objective function, G(xi) = c0(xi) + Eξξξ [q(xi, y(cid:63)(xi, ξξξ), ξξξ)]; ¯Gc(xi) is the SAA of G(x)
(cid:80)N (xi)
q(xi, y(cid:63)(xi, ξξξij), ξξξij); and ¯G(xi) is the SAA of G(x)
without the optimality gap, ¯Gc(xi) = c0(xi) + 1
j=1
with the optimality gap, ¯G(xi) = c0(xi) + 1
j=1 {q(xi, (cid:98)y(cid:63)(xi, ξξξij), ξξξij) − E[δ(x, ξξξij)]}. For any ν > 0, since
¯G(x), G(x) and ¯Gc(x) are all ﬁnite, by applying the triangle inequality, we have

N (xi)
(cid:80)N (xi)

N (xi)

| ¯G(x) − G(x)| = | ¯G(x) − ¯Gc(x) + ¯Gc(x) − G(x)|

< | ¯G(x) − ¯Gc(x)| + | ¯Gc(x) − G(x)|
< ν

(33)
as k → ∞. For the last inequality in (33), as k → ∞, | ¯Gc(x) − G(x)| < ν/2 holds by applying Lemma 1, i.e.
N (k)(x) → ∞ and the strong law of large numbers, while | ¯G(x) − ¯Gc(x)| < ν/2 holds by applying Lemma 2. Thus,
for any x ∈ X w.p.1., we have

Pr{| ¯G(x) − G(x)| > ν

i.o.} = 0

(34)

as k → ∞.
After that, we want to bound | ¯G((cid:98)x(cid:63)(k)) − G(x(cid:63))|. Two cases can happen: either ¯G((cid:98)x(cid:63)(k)) ≤ G(x(cid:63)) or ¯G((cid:98)x(cid:63)(k)) >
G(x(cid:63)). When ¯G((cid:98)x(cid:63)(k)) ≤ G(x(cid:63)), notice G(x(cid:63)) ≤ G((cid:98)x(cid:63)(k)) since G(x(cid:63)) is the optimal objective value. Then, we
have
¯G((cid:98)x(cid:63)(k)) ≤ G(x(cid:63)) ≤ G((cid:98)x(cid:63)(k))

21

which leads to

| ¯G((cid:98)x(cid:63)(k)) − G(x(cid:63))| ≤ | ¯G((cid:98)x(cid:63)(k)) − G((cid:98)x(cid:63)(k))| ≤ max

x∈X

| ¯G(x) − G(x)|

(35)

When ¯G((cid:98)x(cid:63)(k)) > G(x(cid:63)), notice ¯G(x(cid:63)) ≥ ¯G((cid:98)x(cid:63)(k)) since ¯G((cid:98)x(cid:63)(k)) is the current optimal estimate. Then, we have
G(x(cid:63)) < ¯G((cid:98)x(cid:63)(k)) ≤ ¯G(x(cid:63))

which leads to

Hence, we have

| ¯G((cid:98)x(cid:63)(k)) − G(x(cid:63))| ≤ | ¯G(x(cid:63)) − G(x(cid:63))| ≤ max

x∈X

| ¯G(x) − G(x)|

| ¯G((cid:98)x(cid:63)(k)) − G(x(cid:63))| ≤ max

x∈X

| ¯G(x) − G(x)|

By applying (35) and (36), for any ν > 0, we have

Pr{| ¯G((cid:98)x(cid:63)(k)) − G(x(cid:63))| > ν

i.o.} ≤ Pr{max
x∈X
Pr{| ¯G(x) − G(x)| > ν

| ¯G(x) − G(x)| > ν

(cid:88)

≤

x∈X

= 0

i.o.}

i.o.}

(36)

(37)

as k → ∞. By Assumption 2, the inequality (37) holds by applying Equation (34). Thus, the convergence follows,
¯G((cid:98)x(cid:63)(k))→G(x(cid:63)) w.p.1 as the budget C → ∞ or the iteration k → ∞.

References

[1] E. M. L. Beale. On minimizing a convex function subject to linear inequalities. Journal of the Royal Statistical

Society. Series B (Methodological), 17(2):173–184, 1955.

[2] George B. Dantzig. Linear programming under uncertainty. Management Science, 1(3/4):197–206, 1955.
[3] Alexander Shapiro and Andy Philpott. A tutorial on stochastic programming, 2007.
[4] Alexander Shapiro, Darinka Dentcheva, and Andrzej Ruszczynski. Lectures on Stochastic Programming: Modeling

and Theory. SIAM, Philadelphia, 2009.

[5] Jingang Liu, Chihui Li, Feng Yang, Hong Wan, and Reha Uzsoy. Production planning in semiconductor
manufacturing via simulation optimization. In S. Jain, R. R. Creasey, J. Himmelspach, K. P. White, and M. Fu,
editors, Proceedings of the 2011 Winter Simulation Conference, pages 3617 – 3627, Piscataway, New Jersey, 2011.
Institute of Electrical and Electronics Engineers, Inc.

[6] Tahir Ekin, Nicholas G. Polson, and Reﬁk Soyer. Augmented markov chain monte carlo simulation for two-stage

stochastic programs with recourse. Decision Analysis, 11(4):250–264, 2014.

[7] Karl Frauendorfer. Solving slp recourse problems with arbitrary multivariate distributions: The dependent case.

Mathematics of Operations Research, 13(3):377–394, 1988.

[8] Julia L. Higle and Suvrajeet Sen. Stochastic decomposition: An algorithm for two-stage linear programs with

recourse. Mathematics of Operations Research, 16(3):650–669, 1991.

[9] Julia L. Higle and Suvrajeet Sen. Finite master programs in regularized stochastic decomposition. Mathematical

Programming, 67(1):143–168, 1994.

[10] Shabbir Ahmed, Alexander Shapiro, and Er Shapiro. The sample average approximation method for stochastic

programs with integer recourse. SIAM J. Optim., 12:479–502, 2002.

[11] James C. Spall. Multivariate stochastic approximation using simultaneous perturbation gradient approximation.

IEEE Trans. Autom. Control, 37(3):332–341, 1992.

[12] Donald R. Jones, Matthias Schonlau, and William J. Welch. Efﬁcient global optimization of expensive black-box

functions. J. Glob. Optim., 13(4):455–492, 1998.

[13] L. Jeff Hong and Barry L. Nelson. Discrete optimization via simulation using compass. Operations Research,

54(1):115–129, 2006.

[14] D. Huang, T. T. Allen, W. I. Notz, and N. Zeng. Global optimization of stochastic black-box systems via sequential

kriging meta-models. J. Glob. Optim., 34(3):441–466, 2006.

22

[15] Lihua Sun, L. Jeff Hong, and Zhaolin Hu. Balancing exploitation and exploration in discrete optimization via

simulation through a gaussian process-based approach. Operations Research, 62(6):1416–1438, 2014.

[16] Shane G. Henderson and Barry L. Nelson. Handbooks in Operations Research and Management Science,

volume 13. Elsevier, 2006.

[17] Michael C. Fu, editor. Handbook of Simulation Optimization. Springer, New York, NY, 2014.
[18] Samer Takriti, John R. Birge, and Erik Long. A stochastic model for the unit commitment problem. IEEE Trans.

Power Syst., 11(3):1497–1508, 1996.

[19] Pablo A. Ruiz, C. Russ Philbrick, and Peter W. Sauer. Wind power day-ahead uncertainty management through
stochastic unit commitment policies. In 2009 IEEE/PES Power Systems Conference and Exposition, pages 1–9,
2009.

[20] Aidan Tuohy, Peter Meibom, Eleanor Denny, and Mark O’Malley. Unit commitment for systems with signiﬁcant

wind penetration. IEEE Trans. Power Syst., 24(2):592 – 601, 2009.

[21] M. A. H. Dempster, M. F. Fisher, L. Jansen, and A. H. G. Rinnooy Kan. Analytical evaluation of hierarchical

planning systems. Operations Research, 29(4):707–716, 1981.

[22] John R. Birge and M. A. H. Dempster. Stochastic programming approaches to stochastic scheduling. J. Glob.

Optim., 9(3):417–451, 1996.

[23] T. Glenn Bailey, Paul A. Jensen, and David P. Morton. Response surface analysis of two-stage stochastic linear

programming with recourse. Naval Research Logistics, 46(7):753–776, 1999.

[24] R. M. Van Slyke and Roger Wets. L-shaped linear programs with applications to optimal control and stochastic

programming. SIAM Journal on Applied Mathematics, 17(4):638–663, 1969.

[25] François V. Louveaux. A solution method for multistage stochastic programs with recourse with application to an

energy investment problem. Operations Research, 28(4):889–902, 1980.

[26] John R. Birge and François V. Louveaux. A multicut algorithm for two-stage stochastic linear programs. European

Journal of Operational Research, 34(3):384–392, 1988.

[27] Satyajith Amaran, Nikolaos V. Sahinidis, Bikram Sharda, and Scott J. Bury. Simulation optimization: A review of

algorithms and applications. Annals of Operations Research, 240(1):351–380, 2016.

[28] Barry L. Nelson. ‘some tactical problems in digital simulation’ for the next 10 years. Journal of Simulation,

10(1):2–11, 2016.

[29] Zelda B. Zabinsky. Random Search Algorithms. Wiley, 2009.
[30] Jie Xu, Barry L. Nelson, and L. Jeff Hong. Industrial strength compass: A comprehensive algorithm and software

for optimization via simulation. ACM Trans. Model. Comput. Simul., 20(1):3:1–3:29, 2010.

[31] George B. Dantzig and Peter W. Glynn. Parallel processors for planning under uncertainty. Annals of Operations

Research, 22(1):1–21, 1990.

[32] Alexander Shapiro and Tito Homem-de Mello. A simulation-based approach to two-stage stochastic programming

with recourse. Mathematical Programming, 81(3):301–325, 1998.

[33] Alexander Shapiro and Tito Homem-de Mello. On the rate of convergence of optimal solutions of monte carlo

approximations of stochastic programs. SIAM J. Optim., 11(1):70–86, 2000.

[34] Alexander Shapiro and Arkadi Nemirovski. Continuous Optimization, volume 99 of Applied Optimization.

Springer, Boston, MA, 2005.

[35] Ning Quan, Jun Yin, Szu Hui Ng, and Loo Hay Lee. Simulation optimization via kriging: A sequential search
using expected improvement with computing budget constraints. IIE Transactions, 45(7):763–780, 2013.
[36] Bruce Ankenman, Barry L. Nelson, and Jeremy Staum. Stochastic kriging for simulation metamodeling. Opera-

tions Research, 58(2):371–382, 2010.

[37] Wei Xie and Yuan Yi. A simulation-based prediction framework for two-stage dynamic decision making. In
T. M. K. Roeder, P. I. Frazier, R. Szechtman, E. Zhou, T. Huschka, and S. E. Chick, editors, Proceedings of the
2016 Winter Simulation Conference, pages 2304–2315, Piscataway, New Jersey, 2016. Institute of Electrical and
Electronics Engineers, Inc.

[38] Warren Powell. Clearing the jungle of stochastic optimization. INFORMS Tutorials in Operations Research,

pages 109–137, 2014.

[39] Alexander Shapiro. Stochastic programming approach to optimization under uncertainty. Mathematical Program-

ming, 112(1):183–220, 2008.

23

[40] Chen Fu Chien, Stéphane Dauzère-Pérès, Hans Ehm, John W. Fowler, Zhibin Jiang, Shekar Krishnaswamy, Tae
Eog Lee, Lars Mönch, and Reha Uzsoy. Modelling and analysis of semiconductor manufacturing in a shrinking
world: Challenges and successes. European Journal of Industrial Engineering, 5(3):254–271, 2011.

[41] Yao Ma. Risk Management in Biopharmaceutical Supply Chains. PhD thesis, University of California, Berkeley,

2011.

[42] Philip Kaminsky and Yang Wang. Analytical models for biopharmaceutical operations and supply chain manage-

ment: A survey of research literature. Pharmaceutical Bioprocessing, 3(1):61–73, 2015.

[43] Wei Xie, Barry L. Nelson, and Jeremy Staum. The inﬂuence of correlation functions on stochastic kriging
metamodels. In B. Johansson, S. Jain, J. Montoya-Torres, J. Hugan, and E. Yucesan, editor, Proceedings of the
2010 Winter Simulation Conference, pages 1067–1078, Piscataway, New Jersey, 2010. Institute of Electrical and
Electronics Engineers, Inc.

[44] Jerome Sacks, William J. Welch, Toby J. Mitchell, and Henry P. Wynn. Design and analysis of computer

experiments. Statistical Science, 4(4):409–423, 1989.

[45] Seong-Hee Kim and Barry L. Nelson. Recent advances in ranking and selection. In Proceedings of the 2007 Winter
Simulation Conference, pages 162–172, Piscataway, New Jersey, 2007. Institute of Electrical and Electronics
Engineers, Inc.

[46] Shing Chih Tsai, Barry L. Nelson, and Jeremy Staum. Combined screening and selection of the best with control
variates, volume 133 of International Series in Operations Research & Management Science. Springer, New
York, 2009.

[47] Vadim Lesnevski, Barry L. Nelson, and Jeremy Staum. Simulation of coherent risk measures based on generalized

scenarios. Management Science, 53(11):1756–1769, 2007.

[48] Vadim Lesnevski, Barry L. Nelson, and Jeremy Staum. An adaptive procedure for estimating coherent risk

measures based on generalized scenarios. Journal of Computational Finance, 11(4):1–31, 2008.
[49] Abraham Wald. Note on the consistency of the maximum likelihood estimate. 20(4):595–601, 1949.
[50] John R. Birge and Franois Louveaux. Introduction to Stochastic Programming. Springer Publishing Company,

Incorporated, 2nd edition, 2011.

[51] Gene H. Golub and Charles F. Van Loan. Matrix Computations. The Johns Hopkins University Press, third edition,

1996.

[52] Adam D. Bull. Convergence rates of efﬁcient global optimization algorithms. J. Mach. Learn. Res., 12:2879–2904,

November 2011.

24

