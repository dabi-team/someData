9
1
0
2

v
o
N
6

]

O
L
.
s
c
[

2
v
8
6
7
3
1
.
9
0
9
1
:
v
i
X
r
a

Backpropagation in the Simply Typed Lambda-Calculus with Linear Negation

ALO¨IS BRUNEL, Deepomatic
DAMIANO MAZZA, CNRS, UMR 7030, LIPN, Universit´e Sorbonne Paris Nord
MICHELE PAGANI, IRIF UMR 8243, Universit´e de Paris, CNRS

Backpropagation is a classic automatic diﬀerentiation algorithm computing the gradient of functions speciﬁed by a certain class

of simple, ﬁrst-order programs, called computational graphs. It is a fundamental tool in several ﬁelds, most notably machine learning,

where it is the key for eﬃciently training (deep) neural networks. Recent years have witnessed the quick growth of a research

ﬁeld called diﬀerentiable programming, the aim of which is to express computational graphs more synthetically and modularly by

resorting to actual programming languages endowed with control ﬂow operators and higher-order combinators, such as map and

fold.

In this paper, we extend the backpropagation algorithm to a paradigmatic example of such a programming language: we

deﬁne a compositional program transformation from the simply-typed lambda-calculus to itself augmented with a notion of linear

negation, and prove that this computes the gradient of the source program with the same eﬃciency as ﬁrst-order backpropagation.

The transformation is completely eﬀect-free and thus provides a purely logical understanding of the dynamics of backpropagation.

CCS Concepts: •Theory of computation → Program semantics; Theory and algorithms for application domains;

Additional Key Words and Phrases: Diﬀerentiable Programming, Lambda-calculus, Linear Logic

1 INTRODUCTION

In the past decade there has been a surge of interest in so-called deep learning, a class of machine learning methods

based on multi-layer neural networks. The term “deep” has no formal meaning, it is essentially a synonym of “multi-

layer”, which refers to the fact that the networks have, together with their input and output layers, at least one internal

(or “hidden”) layer of artiﬁcial neurons. These are the basic building blocks of neural networks: technically, they are
just functions Rm → R of the form (x1, . . . , xm ) → σ
, where σ : R → R is some activation function and
w1, . . . , wm ∈ R are the weights of the neuron. A layer consists of several unconnected artiﬁcial neurons, in parallel.
The simplest way of arranging layers is to connect them in cascade, every output of each layer feeding into every

m
i =1 wi · xi

(cid:0)Í

(cid:1)

neuron of the next layer, forming a so-called feed-forward architecture. Feed-forward, multi-layer neural networks are
known to be universal approximators: any continuous function f : K → R with K ⊆ Rk compact may be approximated
to an arbitrary degree of precision by a feed-forward neural network with one hidden layer, as long as the weights are

set properly (Cybenko 1989; Hornik 1991). This leads us to the question of how to eﬃciently train a neural network, i.e.,

how to ﬁnd the right weights as quickly as possible.

Albeit in theory the simplest architecture suﬃces for all purposes, in practice more complex architectures may

perform better, and diﬀerent architectures may be better suited for diﬀerent purposes. We thus get to another basic

question of deep learning: how to select and, if necessary, modify or design network architectures adapted to a given task.

Since the quality of an architecture is also judged in terms of training eﬃciency, this problem is actually interlaced

with the previous one.

Manuscript submitted to ACM

1

 
 
 
 
 
 
x1

x2

−

z1

·

z2

sin

y

let z1 = x1 - x2 in let z2 = z1 · z1 in sin z2

Fig. 1. A computational graph with inputs x1, x2 and output y, and its corresponding term. Nodes are drawn as circles, hyperedges
as triangles. The output y does not appear in the term: it corresponds to its root.

The ﬁrst question is generally answered in terms of the gradient descent algorithm (or some variant thereof). This
ﬁnds local minima of a function G : Rn → R using its gradient ∇G, i.e., the vector of the partial derivatives of G
(Equation 1). The algorithm starts by choosing a point w0 ∈ Rn. Under certain assumptions, if ∇G(w0) is close to zero
then w0 is within a suﬃciently small neighborhood of a local minimum. Otherwise, we know that G decreases most
sharply in the opposite direction of ∇G(w0), and so the algorithm sets w1 := w0 − ρ∇G(w0) for a suitable step rate
ρ > 0, and repeats the procedure from w1. In the case of deep learning, a neural network (with one output) induces
a function h(w, x) : Rn+k → R, where k is the number of inputs and n the number of weights of all the neurons in
the network. By ﬁxing w ∈ Rn and making x vary over a set of training inputs, we may measure how much h diﬀers
from the target function f : Rk → R when the weights are set to w. This deﬁnes an error function G : Rn → R, the
minimization of which gives a way of ﬁnding the desired value for the weights. The training process thus becomes the
iteration, over and over, of a gradient computation, starting from some initial set of weights w0.

So, regardless of the architecture, eﬃciently training a neural network involves eﬃciently computing gradients.

The interest of gradient descent, however, goes well beyond deep learning, into ﬁelds such as physical modeling and

engineering design optimization, each with numerous applications. It is thus no wonder that a whole research ﬁeld,

known as automatic diﬀerentiation (AD for short), developed around the computation of gradients and, more generally,
Jacobians1 (Baydin et al. 2017). In AD, the setting of neural networks is generalized to computational graphs, which
are arbitrarily complex compositions of nodes computing basic functions and in which the output of a node may be

shared as the input of an unbounded number of nodes. Fig. 1 gives a pictorial representation of a simple computational
graph made of only three basic functions (subtraction, multiplication and sine), with inputs x1 and x2. Notice that
the computation of x1 − x2 is shared by the two factors of the multiplication. Neural networks are special cases of
computational graphs.

The key idea of AD is to compute the gradient of a computational graph by accumulating in a suitable way the

partial derivatives of the basic functions composing the graph. This rests on the mathematical principle known as
chain rule, giving the derivative of a composition f ◦ д from the derivatives of its components f and д (Equation 3).

There are two main “modes” of applying this rule in AD, either forward, propagating derivatives from inputs to outputs,

or backwards, propagating derivatives from outputs to inputs. As will be explained in Sect. 2, if G is a computational
graph with n inputs and m outputs invoking |G| operations (i.e., nodes), forward mode computes the Jacobian of G
in O(n |G|) operations, while reverse mode requires O(m |G|) operations. In deep learning, as the number of layers
increases, n becomes astronomical (millions, or even billions) while m = 1, hence the reverse mode is the method
of choice and specializes in what is called the backpropagation algorithm (Sect. 2.4), which has been a staple of deep

1The generalization of the gradient to the case of functions Rn → Rm with m > 1.

2

learning for decades (LeCun et al. 1989). Today, AD techniques are routinely used in the industry through deep learning

frameworks such as TensorFlow (Abadi et al. 2016) and PyTorch (Paszke et al. 2017).

The interest of the programming languages (PL) community in AD stems from the second deep learning question

mentioned above, namely the design and manipulation of (complex) neural network architectures. As it turns out,

these are being expressed more and more commonly in terms of actual programs, with branching, recursive calls or
even higher-order primitives, like list combinators such as map or fold, to the point of yielding what some call a
generalization of deep learning, branded diﬀerentiable programming (LeCun 2018). Although these programs always

reduce, in the end, to computational graphs, these latter are inherently static and therefore inadequate to properly

describe something which is, in reality, a dynamically-generated neural network. Similarly, traditional AD falls short

of providing a fully general foundation for diﬀerentiable programming because, in order to compute the gradient of

an a priori arbitrary (higher order) program, it forces us to reduce it to a computational graph ﬁrst. In PL-theoretic

terms, this amounts to ﬁxing a reduction strategy, which cannot always be optimal in terms of eﬃciency. There is also

a question of modularity: if gradients may only be computed by running programs, then we are implicitly rejecting the

possibility of computing gradients modularly, because a minor change in the code might result in having to recompute

everything from scratch, which is clearly unsatisfactory.

This paper is a contribution to the theoretical foundations of diﬀerentiable programming. We deﬁne a compositional

program transformation

←−
D (Table 3) extending the backpropagation algorithm from computational graphs to general

simply typed λ-terms. Our framework is purely logical and therefore oﬀers the possibility of importing tools from

semantics, type systems and rewriting theory. The beneﬁt is at least twofold, in the form of

(1) a soundness proof (Theorem 5.6 and Corollary 5.7), which relies on the logical/compositional deﬁnition of

←−
D

and the semantics;

(2) a complexity analysis, which hinges on rewriting in the form of the linear substitution calculus (Accattoli 2012)

and which guarantees that generalized backpropagation is at least as eﬃcient as the standard algorithm on

computational graphs.

Although the soundness proof is based on a ﬁxed strategy (reducing to a computational graph ﬁrst and then computing

the gradient), the conﬂuence of our calculus guarantees us that the gradient may be computed using any other reduc-

tion strategy, thus allowing arbitrary evaluation mechanisms for executing backpropagation in a purely functional

setting, without necessarily passing through computational graphs. Sect. 6 discusses the beneﬁts of this in terms of

eﬃciency.

On a similar note, compositionality ensures modularity: for instance, if p = tu, i.e., program p is composed of
←−
D (p) = ←−
←−
D (t)
D (u) may be computed independently, so that if p is
←−
D (t) may be reused. Modularity also opens the way to parallelization, another

←−
D (u) and

←−
D (t) and

subprograms t and u, then
modiﬁed into tu ′, the computation of
potential avenue to eﬃciency.

Finally, let us stress that the transformation

←−
D is remarkably simple: on “pure” λ-terms, i.e., not containing any

function symbol corresponding to the basic nodes of computational graphs,

←−
D is the identity, modulo a change in
←−
D maps a datatype constructor/destructor (cons, head, tail, etc.) or a typical higher order
the types. In particular,
combinator (map, fold, etc.) to itself, which makes the transformation particularly easy to compute and analyze. We
see this as a theoretical counterpart to the use of operator overloading in implementations of AD.

From a more abstract perspective, all these properties (including compositionality) may be succinctly summarized

←−
D is a cartesian closed 2-functor or, better, a morphism of cartesian 2-multicategories, obtained by freely

in the fact that

3

lifting to λ-terms a morphism deﬁned on computational graphs. However, such a viewpoint will not be developed in this

paper.

Related work. Our main source of inspiration is (Wang et al. 2019), where a program transformation

←−
D is proposed

as a compositional extension of symbolic backpropagation to functional programs. We summarize their approach in

Sect. 3, let us concentrate on the main diﬀerences here:

(1) the transformation

←−
D uses references and delimited continuations, while our transformation

←−
D is purely

functional and only relies on a linear negation primitive on the ground type. Albeit (Wang et al. 2019) do

mention that a purely functional version of their transformation may be obtained by encoding the memory

inside the type of the continuation, this encoding adds a sequentialization (introduced by the order of the

memory updates) which is absent in

←−
D and which makes our transformation more amenable to parallelization.
←−
D applies to a Turing-complete programming language, while we focus on the much more
←−
D is given, only testing on examples.

restrictive simply-typed λ-calculus. However, no soundness proof for

(2) The transformation

This brings to light a diﬀerence in the general spirit of the two approaches: the paper (Wang et al. 2019) is

mainly experimental, it comes with a deep learning framework (Lantern) and with a case study showing the

relevance of this line of research. Our approach is complementary because it is mainly theoretical: we focus on

proving the soundness and complexity bound of a non-trivial diﬀerentiable programming framework, “non-

trivial” in the sense that it is the simplest exhibiting the diﬃculty of the task at hand. To the best of our

knowledge, such foundational questions have been completely neglected, even for “toy” languages, and our

paper is the ﬁrst to address them.

The earliest work performing AD in a functional setting is (Pearlmutter and Siskind 2008). Their motivations are

To this end, they endow Scheme with a combinator

broader than ours: they want to deﬁne a programming language with the ability to perform AD on its own programs.
←−
J computing the Jacobian of its argument, and whose execution
←−
J must reﬂectively access, at runtime, the program in which it is

implements reverse mode AD. In order to do this,

contained, and it must also be possible to apply it to itself. While this oﬀers the possibility of computing higher-order

derivatives (in the sense of derivative of the derivative, which we do not consider), it lacks a type-theoretic treatment:
←−
J is deﬁned in an untyped language. Although (Pearlmutter and Siskind 2008) do mention, for ﬁrst-

the combinator

order code, a transformation essentially identical to our

backpropagators may be typed linearly and that

←−
D (using so-called backpropagators), the observations that

←−
D may be directly lifted to higher-order code (as we do in Tab. 3)
←−
J is not illustrated by a

are original to our work. Finally, let us mention that in this case as well the correctness of
mathematical proof of soundness, but by testing an implementation of it (Stalin∇).

At a more theoretical level, (Elliott 2018) gives a Haskell implementation of backpropagation extracted from a functor
D over cartesian categories, with the beneﬁt of disclosing the compositional nature of the algorithm. However, Elliot’s
approach is still restricted to ﬁrst-order programs (i.e., computational graphs): as far as we understand, the functor D

is cartesian but not cartesian closed, so the higher-order primitives (λ-abstraction and application) lack a satisfactory

treatment. This is implicit in Sect. 4.4 of (Elliott 2018), where the author states that he only uses biproduct categories:
it is well-known that non-trivial cartesian closed biproduct categories do not exist.2

We already mentioned TensorFlow and PyTorch. It is diﬃcult at present to make a fair comparison with such large-

scale diﬀerentiable programming frameworks since we are still focused on the conceptual level. Nevertheless, in the

2If a category C has biproducts, then 1 (cid:27) 0 (the terminal object is also initial). If C is cartesian closed, then its product × is a left adjoint and therefore
preserves colimits (initial objects in particular), so A (cid:27) A × 1 (cid:27) A × 0 (cid:27) 0 for every object A of C.

4

perspective of a future implementation, our work is interesting because it would oﬀer a way of combining the beneﬁts

of hitherto diverging approaches: the ability to generate modular, optimizable code (TensorFlow) with the possibility

of using an expressive language for dynamically-generated computational graphs (PyTorch).

Contents of the paper. Sect. 2 gives a (very subjective) introduction to the notions of AD used in this paper. Sect. 3

informally introduces our main contributions, which will then be detailed in the more technical Sect. 5. Sect. 4 formally

speciﬁes the programming language we work with, introducing a simply-typed λ-calculus and a rewriting reduction

(Tab. 2) necessary to deﬁne and to evaluate our backpropagation transformation

←−
D . Sect. 6 applies

←−
D to a couple of

examples, in particular to a (very simple) recurrent neural network. Sect. 7 concludes with some perspectives.

2 A CRASH COURSE IN AUTOMATIC DIFFERENTIATION

What follows is an introduction to automatic diﬀerentiation for those who are not familiar with the topic. It is extremely

partial (the ﬁeld is too vast to be summarized here) and heavily biased not just towards programming languages

but towards the very subject of our work. It will hopefully facilitate the reader in understanding the context and

achievements of the paper.

2.1 What is automatic diﬀerentiation?

Automatic diﬀerentiation (or AD) is the science of eﬃciently computing the derivative of (a restricted class of) pro-

grams (Baydin et al. 2017). Such programs may be represented as directed acyclic hypergraphs, called computational
graphs, whose nodes are variables of type R (the set of real numbers) and whose hyperedges are labelled by functions
drawn from some ﬁnite set of interest (for example, in the context of neural networks, sum, product and some activa-

tion function), with the restriction that hyperedges have exactly one target node and that each node is the target of at

most one hyperedge. The basic idea is that nodes that are not target of any hyperedge represent input variables, nodes

which are not source of any hyperedge represent outputs, and a hyperedge

x1, . . . , xk

f
−→ y

represents an assignment y := f (x1, . . . , xk ), so that a computational graph with n inputs and m outputs represents a
function of type Rn → Rm . An example is depicted in Fig. 1; it represents the function (x1, x2) 7→ sin((x1 − x2)2).

In terms of programming languages, we may deﬁne computational graphs as generated by

F , G ::= x | f (x1,. . .,xk ) | let x = G in F | (F ,G)

where x ranges over ground variables and f over a set of real function symbols. The let binders are necessary to rep-
resent sharing, a fundamental feature of hypergraphs: e.g., in Fig. 1, node z1 is shared. The set of real function symbols
consists of one nullary symbol for every real number plus ﬁnitely many non-nullary symbols for actual functions. We
may write f (G1,. . .,Gn ) as syntactic sugar for let x1 = G1 in. . . let xn = Gn in f (x1,. . .,xn ). Within this intro-
duction (Sect. 2 and 3) we adopt the same notation for a function and the symbol associated with it in the language,
so for example r may refer to both a real number and its associated numeral. Also, we use an OCaml-like syntax in the
hope that it will help the unacquainted reader parse the examples. From Sect. 4 onward we will adopt a more succinct

syntax.

5

Typing is as expected: types are of the form Rk and every computational graph in context x1:R,. . .,xn :R ⊢ G : Rm
: Rn → Rm (this will be deﬁned formally in Sect. 5.1). Restricting for simplicity to the one-

denotes a function

G

K

J

G
output case, we may say that, as far as we are concerned, the central question of AD is computing the gradient of
at any point r ∈ Rn, as eﬃciently as possible. We remind that the gradient of a diﬀerentiable function f : Rn → R is
K
deﬁned to be the function ∇f : Rn → Rn such that, for all r ∈ R,

J

∇f (r) = (∂1 f (r), . . . , ∂n f (r)) ,

(1)

where by ∂i f we denote the partial derivative of f with respect to its i-th argument. Of course, the above question
is diﬀerentiable, which is the case if every function symbol represents a diﬀerentiable function.
makes sense only if

G

In practice this is not always guaranteed (notoriously, modern neural networks use activation functions which are not

J

K

diﬀerentiable) but this is not actually an issue, as it will be explained momentarily.

Before delving into the main AD algorithms, let us pause a moment on the question of evaluating a computational
graph. In terms of hypergraphs, we are given a computational graph G with input nodes x1, . . . , xn together with an
assignment xi := ri with ri ∈ R for all 1 ≤ i ≤ n. The value
(r1, . . . , rn) is found by progressively computing the
G
f
K
J
assignments w := f (s1, . . . , sm ) for each hyperedge z1, . . . , zm
−→ w such that the values of all zi are already known.
This is known as forward evaluation and has cost |G| (the number of nodes of G).

In terms of programming languages, forward evaluation corresponds to a standard call-by-value strategy, with

values being deﬁned as tuples of numbers. For instance, for G in Fig. 1

let x1 = 5 in
let x2 = 2 in

−→∗

G

let x1 = 5 in
let x2 = 2 in
let x1 = 3 in
let z2 = z1 · z1 in

sin z2

−→∗

let x1 = 5 in
let x2 = 2 in
let x1 = 3 in
let z2 = 9 in
sin z2

−→∗

let x1 = 5 in
let x2 = 2 in
let x1 = 3 in
let z2 = 9 in

0.412

The operational semantics realizing the above computation will be introduced later. For now, let us mention that the
value of a closed computational graph G may be found in O(|G|) reduction steps, where |G| is the size of G as a term,

consistently with the cost of forward evaluation.

2.2 Forward mode AD

The simplest AD algorithm is known as forward mode diﬀerentiation. Suppose that we are given a computational
graph (in the sense of a hypergraph) G with input nodes x1, . . . , xn and one output node y, and suppose that we want
to compute its j-th partial derivative in r = (r1, . . . , rn ) ∈ Rn. The algorithm maintains a memory consisting of a set
of assignments of the form x := (s, t ), where x is a node of G and s, t ∈ R (know as primal and tangent), and proceeds
as follows:

• we initialize the memory with xi := (ri , 0) for all 0 ≤ i ≤ n, i , j, and xj := (rj , 1).
• At each step, we look for a node z1, . . . , zk

f
−→ w such that zi = (si , ti ) is in memory for all 1 ≤ i ≤ k (there

is at least one by acyclicity) and w is unknown, and we add to memory

w :=

f (s) ,

k

Õi =1

6

∂i f (s) · ti

!

(2)

 
where we used the abbreviation s := s1, . . . , sm .

This procedure terminates in a number of steps equal to |G| and one may show, using the chain rule for derivatives
(which we will recall in a moment), that at the end the memory will contain the assignment y := (

(r)).

G

G

(r), ∂j

Since the arity k of function symbols is bounded, the cost of computing one partial derivative is O(|G|). Computing
the gradient requires computing all n partial derivatives, giving of a total cost of O(n |G|), which is not very eﬃcient

K

J

K

J

since n may be huge (typically, it is the number of weights of a deep neural network, which may well be in the millions).
For example, if G is the computational graph of Fig. 1 and we start with x1 := (5, 1), x2 := (2, 0), we obtain z1 :=
(x1 −x2, 1·1−1·0) = (3, 1), then z2 := (z1 ·z1 , z1 ·1+z1 ·1) = (9, 6) and ﬁnally y := (sin(z2), cos(z2)·6) = (0.412, −5.467),
which is what we expect since ∂1

(x1, x2) = cos((x1 − x2)2) · 2(x1 − x2).

G

2.3 Symbolic AD

J

K

The AD algorithm presented above is purely numerical, but there is also a symbolic approach. The basic idea of (forward

mode) symbolic AD is to generate, starting from a computational graph G with n input nodes and 1 output node, a
−→
D (G) corresponds
−→
D (G)(r1, 0, . . . , rj , 1, . . . , rn, 0) is

computational graph
to executing forward mode AD on G, i.e., for all r = r1, . . . , rn ∈ R, the output of
(

−→
D (G) with 2n input nodes and 2 output nodes such that forward evaluation of

(r)).

G

G

(r), ∂j

J

K
From the programming languages standpoint, symbolic AD is interesting because:

J

K

(1) it allows one to perform optimizations on

−→
D (G) which would be inaccessible when simply running the algo-

rithm on G (a typical beneﬁt of frameworks like TensorFlow);

(2) it opens the way to compositionality, with the advantages mentioned in the introduction;

(3) being a (compositional) program transformation rather than an algorithm, it oﬀers a viewpoint from which

AD may possibly be extended beyond computational graphs.

Recently, (Elliott 2018) pointed out how symbolic forward mode AD may be understood in terms of compositionality,

thus intrinsically addressing point (2) above. The very same fundamental remark is implicitly used also by (Wang et al.
2019). Recall that the derivative of a diﬀerentiable function f : R → R is the (continuous) function f ′ : R → R such
that, for all r ∈ R, the map a 7→ f ′(r ) · a is the best linear approximation of f around r . Now, diﬀerentiable (resp.
continuous) functions are closed under composition, so one may wonder whether the operation (−)′ is compositional,
i.e., whether (д ◦ f )′ = д′ ◦ f ′. This is notoriously not the case: the so-called chain rule states that

∀r ∈ R,

(д ◦ f )′(r ) = д′(f (r )) · f ′(r ).

(3)

Nevertheless, there is a slightly more complex construction from which the derivative may be recovered and which

has the good taste of being compositional. Namely, deﬁne, for f as above,

Df : R × R −→
(r, a)

7→ (f (r ), f ′(r ) · a)).

R × R

We obviously have π2Df (x, 1) = f ′(x) for all x ∈ R (where π2 is projection on the second component) and we invite
the reader to check, using the chain rule itself, that D(д ◦ f ) = Dд ◦ Df .

The similarity with forward mode AD is not accidental. Indeed, as observed by (Elliott 2018), forward mode symbolic

AD may be understood as a compositional implementation of partial derivatives, along the lines illustrated above.
Formally, we may consider two term calculi for computational graphs, let us call them C and C′, deﬁned just as above
7

but based on two diﬀerent sets of function symbols F ⊆ F ′, respectively, with F ′ containing at least sum and product,
and equipped with partial functions

∂i : F −→ F ′
for each positive integer i such that, for all f ∈ F of arity k and for all 1 ≤ i ≤ k, ∂i f is deﬁned and its arity is equal
to k. Then, we deﬁne a program transformation

−→
D from C to C′ which, on types, is given by

−→
D (R) := R × R

D (A × B) := −→
−→

D (A) ×

−→
D (B),

and, on computational graphs,

−→
D(x) := x

−→
D(let x = G in F ) := let x =

−→
D(G) in

−→
D(F )

−→
D((F ,G)) := (

−→
D(F ),

−→
D(G))

−→
D (f (x)) := let x = (z, a) in (f (z),

k
i=1 ∂i f (z) · ai )

In the last case, f is of arity k and let x = (z, a) in . . . stands for let x1 = (z1,a1) in . . . let xk = (zk ,ak ) in
−→
D (f (x)) is the deﬁnition of the operator D mutatis mutandis, considering that now the arity
. . .. Notice how the case

Í

k is arbitrary. More importantly, we invite the reader to compare it to the assignment (2) in the description of the

forward mode AD algorithm: they are essentially identical. The following is therefore not so surprising:

Proposition 2.1. Suppose that every f ∈ F of arity k corresponds to a diﬀerentiable function f : Rk → R and that,
for all 1 ≤ i ≤ k, ∂i f is the symbol corresponding to its partial derivative with respect to the i-th input. Then, for every
computational graph x : R ⊢ G : R with n inputs, for all 1 ≤ j ≤ n and for all r = r1, . . . , rn ∈ R, we have the call-by-value
evaluation

let x1 = (r1,0) in. . . let xj = (r j ,1) in. . . let xn = (rn ,0) in

−→
D (G) −→∗ (JGK (r),∂j JGK (r))

−→
D (G) in call-by-value is the same as executing the forward mode AD
So we obtained what we wanted: evaluating
−→
D is fully compositional.3 Indeed, we merely reformulated the transfor-

algorithm on G. Moreover, the deﬁnition of

mation

−−→
Dx introduced in (Wang et al. 2019): the computation of the proposition corresponds to that of

−−−→
Dx j (G).

Symbolic AD also provides us with an alternative analysis of the complexity of the forward mode AD algorithm.

Recall that the length of call-by-value evaluation of computational graphs is linear in the size, so the computation of
Proposition 2.1 takes O(

−→
D, it is immediate to see that every syntactic

) steps. Now, by inspecting the deﬁnition of

−→
D (G)

construct of G is mapped to a term of bounded size (remember that the arity k is bounded). Therefore,

= O(|G|),
which is exactly the cost of computing one partial derivative in forward mode. In other words, the cost becomes simply

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

−→
D (G)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

the size of the output of the program transformation.

Notice how Proposition 2.1 rests on a diﬀerentiability hypothesis. As mentioned above, this is not truly fundamental.
−→
D (G) is always deﬁned, independently of whether the function symbols it uses are diﬀerentiable.
Indeed, observe that
: F → F ′ are arbitrary and the symbol ∂i f may have nothing to do with
This is because, in principle, the maps ∂i
the i-th partial derivative of the function that the symbol f represents! Less unreasonably, we may consider “mildly”

non-diﬀerentiable symbols and associate with them “approximate” derivatives: for example, the rectiﬁed linear unit
ReLU(x) deﬁned as if x<0 then 0 else x may be mapped by ∂1 to Step(x) deﬁned as if x<0 then 0 else 1, even
though technically the latter is not its derivative because the former is not diﬀerentiable in 0. Formally, Step is called

3Technically, one may consider the calculi C and C′ as cartesian 2-multicategories: types are objects, computational graphs with n inputs and one
−→
output are n-ary multimorphisms and evaluation paths are 2-arrows. Then,
D is readily seen to be a morphism of cartesian 2-multicategories. We will
not develop such categorical considerations in this paper, we will content ourselves with mentioning them in footnotes.

8

a subderivative of ReLU. Proposition 2.1 easily extends to subderivatives and, therefore, AD works just as well on non-

diﬀerentiable functions, computing subgradients instead of gradients, which is perfectly acceptable in practice. This

remark applies also to backpropagation and to all the results of our paper, although for simplicity we prefer to stick to

the more conventional notion of gradient, and thus work under a diﬀerentiability hypothesis.

2.4 Reverse mode AD, or backpropagation

A more eﬃcient way of computing gradients in the many inputs/one output case is provided by reverse mode automatic

diﬀerentiation, from which the backpropagation (often abbreviated as backprop) algorithm derives. As usual, we are
given a computational graph (seen as a hypergraph) G with input nodes x1, . . . , xn and output node y, as well as
r = r1, . . . , rn ∈ R, which is the point where we wish to compute the gradient. The backprop algorithm maintains a
memory consisting of assignments of the form x := (r, α ), where x is a node of G and r, α ∈ R (the primal and the
adjoint), plus a boolean ﬂag with values “marked/unmarked” for each hyperedge of G, and proceeds thus:

initialization: the memory is initialized with xi := (ri , 0) for all 1 ≤ i ≤ n, and the forward phase starts;
forward phase: at each step, a new assignment z := (s, 0) is produced, with s being computed exactly as during
forward evaluation, ignoring the second component of pairs in memory (i.e., s is the value of node z); once
every node of G has a corresponding assignment in memory, the assignment y := (t, 0) is updated to y := (t, 1),
every hyperedge is ﬂagged as unmarked and the backward phase begins (we actually know that t =
(r),
but this is unimportant);

G

K

J

backward phase: at each step, we look for an unmarked hyperedge z1, . . . , zk

f

−→ w such that all hyperedges

having w among their sources are marked. If no such hyperedge exists, we terminate. Otherwise, assuming
:= (si , βi ) for all 1 ≤ i ≤ k, we update the memory with the
that the memory contains w := (u, α) and zi
:= (si , βi + ∂i f (s) · α ) (where s := s1, . . . , sk ) for all 1 ≤ i ≤ k and ﬂag the hyperedge as
assignments zi
marked.

K

J

G

(r)) for all 1 ≤ i ≤ n, i.e., the value of each partial derivative of

One may prove that, when the backprop algorithm terminates, the memory contains assignments of the form xi :=
in r is computed at the corresponding input

(ri , ∂i
node, and thus the gradient may be obtained by just collecting such values. Let us test it on an example. Let G be the
computational graph of Fig. 1 and let r1 = 5, r2 = 2. The forward phase terminates with x1 := (5, 0), x2 := (2, 0), z1 :=
(3, 0), z2 := (9, 0), y := (0.412, 1). From here, the backward phase updates z2 := (9, cos(z2) · 1) = (9, −0.911), then
z1 := (3, z1 · −0.911 + z1 · −0.911) = (3, −5.467) and ﬁnally x1 := (5, 1 · −5.467) = (5, −5.467) and x2 := (2, −1 · −5.467) =
(2, 5.467), as expected since ∂2

= −∂1

G

G

G

K

J

.

Compared to forward mode AD, the backprop algorithm may seem a bit contrived (it is certainly harder to under-

J

K

K

J

stand why it works) but the gain in terms of complexity is considerable: the forward phase is just a forward evaluation;

and, by construction, the backward phase scans each hyperedge exactly once performing each time a constant number
of operations. So both phases are linear in |G|, giving a total cost of O(|G|), like forward mode. Except that, unlike

forward mode, a single evaluation now already gives us the whole gradient, independently of the number of inputs!

2.5 Symbolic backpropagation and the compositionality issue

The symbolic methodology we saw for forward mode AD may be applied to the reverse mode too: given a computa-
tional graph G with n inputs and one output, one may produce a computational graph bp(G) with n + 1 inputs and
9

·

b

·

·

c ′

c ′′

+

1

c

−1

·

·

x ′
1

x ′
2

a

v

y

cos

−

z1

·

z2

sin

x1

x2

let z1=x1-x2 in let z2=z1 ·z1 in let b=(cos z2)·a in let c=z1 ·b+z1 ·b in (sin z2,(1·c,-1·c))

Fig. 2. The computational graph bpx1,x2,a (G) where G is in Fig. 1, and its corresponding term.

1 + n outputs such that, for all r = r1, . . . , rn ∈ R, the forward evaluation of bp(G)(r, 1) has output (
Moreover,

= O(|G|).

bp(G)

G

(r), ∇

G

(r)).

J

K

J

K

(cid:12)
(cid:12)

(cid:12)
(cid:12)

A formal deﬁnition of the bp transformation will be given in Sect. 5.1. Let us look at an example, shown in Fig. 2.
First of all, observe that bpx1, x2, a(G) contains a copy of G, marked in blue. This corresponds to the forward phase.
The nodes marked in red correspond to the backward phase. Indeed, we invite to reader to check that the forward
evaluation of bpx1, x2, a(G) with x1 := 5, x2 := 2 and a := 1 matches exactly the steps of the backprop algorithm as
exempliﬁed in Sect. 2.4, with node b (resp. c, x ′
2) corresponding to the second component of the value of node z2
(resp. z1, x1, x2). (The nodes v, c ′ and c ′′ are just intermediate steps in the computation of b and c which are implicit
in the numerical description of the algorithm and are hidden in syntactic sugar).

1, x ′

Rather than examining the details of the deﬁnition of bp, let us observe at once that, from the standpoint of pro-

−→
gramming languages, it suﬀers from a serious defect: unlike
D, it is not compositional. Indeed, in order to deﬁne
bp(let x = G in F ), we need to know and exploit the inner structure of bp(F ) and bp(G), whereas from the deﬁni-
−→
D (G) are treated as

−→
D given above it is clear that no such knowledge is required in that case, i.e.,

−→
D (F ) and

tion of

“black boxes”. Our way of understanding previous work on the subject (Elliott 2018; Wang et al. 2019) is that it was all

about making symbolic backprop compositional. This is the topic of the next Section.

3 OUR APPROACH TO COMPOSITIONAL BACKPROPAGATION

As mentioned above, the key to modular and eﬃcient diﬀerentiable programming is making symbolic backprop (the

bp transformation) compositional. We will show that this may be achieved by considering a programming language

with a notion of linear negation. The goal of this section is to explain why negation and why linear.

Let us start with by looking at an extremely simple example, which is just the composition of two unary functions:

G := let z = f x in д z

(4)

As a hypergraph, G has three nodes x, y, z, of which x is the input and y the output (corresponding to the root of

G) and two edges x

f

−→ z and z

д
−→ y. Note that, since G has only one input, its gradient is equal to its derivative

and forward and reverse mode AD have the same complexity. This is why the example is interesting: it shows the

10

diﬀerence between the two algorithms by putting them in a context where they must perform essentially the same
operations. In the sequel, we set h :=

and we denote by f ′, д′ and h′ the derivatives of f , д and h, respectively.

G

For what concerns forward mode, we invite the reader to check that

K

J

−→
D (G) = let z = let (v,a)= x in (f v, (f ′ v) · a) in let (w, b) = z in (д w, (д′ w) · b)

We may simplify this a bit by observing that (renaming w as z)

−→
D (G){(x,a)/x} −→∗ let z = f x in let b = (f ′ x)·a in (д z, (д′ z)·b)

On the other hand, applying the deﬁnition of Sect. 5.1, we get

bpx,a(G) = let z = f x in let b = (д′ z)·a in (д z,(f ′ x)·b)
Note that, if we substitute r ∈ R for x and 1 for a, in both cases we obtain (h(r ), h′(r )) in the same number of steps, as
expected. However, the order in which the derivatives are computed relative to the order of the composition д ◦ f is

diﬀerent: it is covariant in forward mode, contravariant in reverse mode. This corresponds precisely to the behavior

of the two algorithms:

• in forward mode, we start with x := (r, 1), from which we infer z := (f (r ), f ′(r )), from which we infer

y := (д(f (r )), д′(f (r )) · f ′(r ));

• in reverse mode, the forward phase leaves us with x := (r, 0), z := (f (r ), 0), y := (д(f (r )), 1), at which point
the backward phase proceeds back from the output towards the input, inferring ﬁrst z := (f (r ), д′(f (r ))) and
then x := (r, f ′(r ) · д′(f (r ))).

A lesson we learn from this example, in the perspective of compositionality, is that both algorithms may be seen as
←−
f and ←−д )

mapping the subprograms f and д, which have one input and one output, to two subprograms

−→
f and −→д (or

having two inputs and two outputs, but then assembling them rather diﬀerently:

forward mode

−→
f

−→д

h(r )

h′(r )

r

1

r

h′(r )

reverse mode

←−
f

←−д

h(r )

1

The picture on the right suggested to (Wang et al. 2019) the idea of solving the compositionality issue via continu-
←−
f and ←−д are seen
as function calls in the CPS transform of G, so that the forward phase takes place along the call path, while the back-

ations: drawing inspiration from “There and Back Again” (Danvy and Goldberg 2005), the blocks

ward phase takes place along the return path. However, in order for their approach to work, (Wang et al. 2019) must

use references, i.e., the memory maintained by the backprop algorithm is explicitly present and is manipulated as

described in Sect. 2.4. Moreover, since the memory is updated after the return from each function call, they must

actually resort to delimited continuations. On the whole, although they do succeed in presenting reverse mode AD as a

compositional program transformation, the work of (Wang et al. 2019) is closer to an (elegant!) implementation of the

backprop algorithm in a functional language with references than to an abstract, purely compositional description of

its dynamics.

Let us focus, instead, on the idea of contravariance. The archetypal contravariant operation is negation. For a (real)
vector space A, negation corresponds to the dual space A ⊸ R, which may be generalized to A⊥E := A ⊸ E for an
arbitrary space E, although in fact we will always take E = Rd for some d ∈ N. For brevity, let us keep E implicit and
simply write A⊥. There is a canonical way, resembling CPS, of transforming a diﬀerentiable function f : R → R with
derivative f ′ into a function Dr f : R × R⊥ → R × R⊥ from which the derivative of f may be extracted. Namely, let,

11

for all x ∈ R and x∗ ∈ R⊥,

Dr f (x, x∗) :=

f (x), λa.x∗(f ′(x) · a)

,

(5)

where we are using λ-notation with the standard meaning. We let the reader verify that, if we suppose E = R, then
for all x ∈ R, (π2Dr f (x, I ))1 = f ′(x), where π2 is projection of the second component and I : R → R is the identity
function (which is obviously linear). More importantly, Dr is compositional: for all x ∈ R and x∗ ∈ R ⊸ R, we have4

(cid:1)

(cid:0)

Drд(Dr f (x, x∗)) = Drд(f (x), λa.x∗(f ′(x) · a)) = (д(f (x)), λb.(λa.x∗(f ′(x) · a))(д′(f (x)) · b))

= (д(f (x)), λb.x∗(f ′(x) · (д′(f (x)) · b)) = (д(f (x)), λb.x∗((д′(f (x)) · f ′(x)) · b))
= ((д ◦ f )(x), λb.x∗((д ◦ f )′(x) · b)) = Dr(д ◦ f )(x, x∗).

This observation may be generalized to maps f : Rn → R: for all x ∈ Rn and x∗ = x∗
1

, . . . , x∗

n ∈ R⊥,

←−
D(f )(x; x∗) :=

f (x), λa.

n

Õi =1

x∗
i (∂i f (x) · a)

.

!

In the AD literature, the x∗
R × R⊥ and we invite the reader to check that, if we take E = Rn, we have

i are called backpropagators (Pearlmutter and Siskind 2008). Obviously

←−
D(f )(x; ι1, . . . , ιn ))1 = ∇f (x),

(π2

←−
D(f ) : (R × R⊥)n →

where, for all 1 ≤ i ≤ n, ιi
zeros everywhere except at position i, which is a linear function. Moreover,

: R → Rn is the injection into the i-th component, i.e., ιi (x) = (0, . . . , x, . . . , 0) with
←−
D is compositional.5 This leads to the
←−
D(R) = R × R⊥ and which, applied to

deﬁnition of a compositional program transformation

←−
D (Tab. 3) which veriﬁes

our example (4), gives

let z =

←−
D(G) =

let (v,v∗) = x in
(f v, fun b -> v∗ ((f ′ v) · b)) in

let (w, w∗) = z in
(д w, fun a -> w∗ (д′(w) · a))

where w∗, v∗ : R⊥ so that both fun b -> v∗ ((f ′ v) · b)) and fun a -> w∗ ((д′ w) · a) have also type R⊥. Notice the
−→
D(G): this is not an accident, both are deﬁned in a purely compositional way (in particular,
resemblance of
←−
D(let x = H in F ) = let x =

←−
D(F )), abiding by the “black box” principle) and the only non trivial case is

←−
D(G) and

←−
D(H ) in

when they are applied to function symbols. Moreover, we have

←−
D(G){(x,x∗)/x} −→∗ let z = f x in (д z, fun a -> let b = (д′ z)·a in x∗((f ′ x)·b))
which, albeit of diﬀerent type, is essentially identical to bpx, a(G). More precisely, if we write let b = (д′ z)·a in
(f ′ x)·b as F , then we have

4The equation in the second line uses both commutativity and associativity of product, but only the latter is really necessary: by replacing f ′(x ) · a
with a · f ′(x ) in Eq. 5 one can check that commutativity is not needed. The former notation reﬂects that this is actually a linear application: in general,
: A → B, then f ′(x ) : A ⊸ B and a : A. When A = B = k with k a ring (commutative or not), k ⊸ k (cid:27) k and linear application
if f
becomes the product of k, so the notation a · f ′(x ) makes sense and backprop has in fact been applied to non-commutative rings (Isokawa et al. 2003;
Pearson and Bisset 1992). In the general case, it makes no sense to swap function and argument and it is unclear how backprop would extend.
←−
5Technically, functions of type Rn → R for varying n form what is known as a cartesian operad, or clone, and
D is a morphism of such structures. A
bit more explicitly, one may compose f : Rn → R with д : Rm+1 → R by “plugging” f into the i -th coordinate of д, forming д ◦i f : Rn+m → R, for
any 1 ≤ i ≤ m + 1; the operation

←−
D preserves such compositions.

12

 
bpx, a(G) =let z=f x in (д z,F ) and

←−
D(G) {(x,x∗)/x} −→∗ let z=f x in (д z, fun a -> x∗ F )

Let us now explain why negation must be linear. The above example is too simple for illustrating this point, so from

now on let G be the computational graph of Fig. 1. Applying the deﬁnition of Tab. 3 and simplifying, we obtain that
←−
D (G) is equal to:

let z2 =

let z1 =

let (v2, v∗
2) = x2 in
let (v1, v∗
1) = x1 in
(v1-v2, fun c -> v∗

1(1·c)+v∗

2(−1·c)) in

−→∗

let (w1,w∗
1) = z1 in
(w1 ·w1, fun b -> w∗

1(w1 ·b)+w∗

1(w1 ·b)) in

let (w2, w∗
2) = z2 in
(sin w2, fun a -> w∗

2 ((cos w2)·a))

let (v2, v∗
let (v1, v∗
let (z1,z∗

2) = x2 in
1) = x1 in
1) =
(v1-v2, fun c -> v∗
2) =
(z1 ·z1, fun b -> z∗

let (z2, z∗

(sin z2, fun a -> z∗

1(1·c)+v∗

2(−1·c)) in

1(z1 ·b)+z∗
2 ((cos z2)·a))

1(z1 ·b)) in

1t +z∗

1 and v∗

There is a potential issue here, due to the presence of two occurrences of z∗

1 (highlighted in brown) which are
matched against the function corresponding to the derivative of x1-x2 (also highlighted in brown, let us denote it by
F ). Notice that such a derivative is present only once in bpx1, x2, a(G): it corresponds to the rightmost nodes of Fig. 2
(more precisely, the abstracted variable c corresponds to node c itself, whereas v∗
1 and
x ′
2, respectively). Therefore, duplicating F would be a mistake in terms of eﬃciency.
The key observation here is that z∗

1 is of type R⊥ , i.e., it is a linear function (and indeed, F is linear: by distributivity of
product over sum, c morally appears only once in its body). This means that, for all t, u : R, we have z∗
1(t +u).
In the λ-calculus we consider (Sect. 4), this becomes an evaluation step oriented from left to right, called linear factoring
←−
D (G) with the same eﬃciency as bpx1, x2, a(G). The linear factoring f t + f u −→ f (t + u)
(18), allowing us to evaluate
would be semantically unsound in general if f : ¬R = R → R, which is why we must explicitly track the linearity of
negations.

2 correspond to nodes x ′

So we have a compositional transformation
returns a program x1 : R × R⊥, . . . , xn : R × R⊥ ⊢
negation, such that

←−
D which takes a computational graph G with n inputs x1, . . . , xn and
←−
D (G) : R × R⊥ in the simply-typed λ-calculus augmented with linear
←−
D (G) evaluates to (essentially) bpx1, ..., xn, a(G). Actually, thanks to another nice observation of
←−
D for free to the whole simply-typed λ-calculus, just letting
←−
D (t)

(Wang et al. 2019), we can do much more: we can extend
←−
←−
D (fun x ->t) := fun x ->
D (t) and
still computes ∇
that if t −→∗ u in p steps, then
ground free variables, eliminating all higher-order redexes gives t −→∗ G for some computational graph G, hence
evaluates to (essentially) bp(G). So
(remember that the semantics is invariant
under evaluation) with a cost equal to O(|G|) plus the cost of the evaluation t −→∗ G, which is the best we can expect
in general.

←−
D immediately gives us
D (u) in O(p) steps (point 2 of Lemma 5.4).6 But since t has ground type and
←−
D (t)

←−
D (u), and, whenever x1 : R, . . . , xn : R ⊢ t : R, we have that

with the same eﬃciency as the evaluation of t! Indeed, the deﬁnition of

←−
D (t) computes the gradient of

D (tu) := ←−
←−

←−
D (t) −→∗ ←−

1u = z∗

D (t)

G

=

K

J

K

K

J

J

t

t

To conclude, we should add that in the technical development we actually use Accattoli’s linear substitution calculus

(Accattoli 2012), which is a bit more sophisticated than the standard simply-typed λ-calculus. This is due to the presence

6Morally, the simply-typed λ-calculus augmented with a set F of function symbols is the free cartesian semi-closed 2-multicategory on F (semi-closed
←−
D is deﬁned on F, it automatically extends to a morphism of such structures. In particular, it functorially
in the sense of (Hyland 2017)). Therefore, once
maps evaluations (which are 2-arrows) to evaluations.

13

of linear negation, but it is also motivated by eﬃciency, which is the whole point of backpropagation. To be taken

seriously, a proposal of using functional programming as the foundation of (generalized) AD ought to come with a

thorough complexity analysis ensuring that we are not losing eﬃciency in moving from computational graphs to

λ-terms. Thanks to its tight connection with abstract machines and reasonable cost models (Accattoli et al. 2014),

ultimately owed to its relationship with Girard’s proof nets (Accattoli 2018) (a graphical representation of linear logic

proofs which may be seen as a higher order version of computational graphs), the linear substitution calculus is an

ideal compromise between the abstractness of the standard λ-calculus and the concreteness of implementations, and

provides a solid basis for such an analysis.

4 THE LINEAR SUBSTITUTION CALCULUS

Terms and Types. Since the linear factoring rule (18) is type-sensitive (as mentioned above, it is unsound in general),

it is convenient to adopt a Church-style presentation of our calculus, i.e., with explicit type annotations on variables.

The set of types is generated by the following grammar:

A, B, C ::= R | A × B | A → B | R⊥d

(simple types)

where R is the ground type of real numbers. The negation R⊥d corresponds to the linear implication (in the sense of
linear logic (Girard 1987)) R ⊸ Rd . However, in order to keep the calculus as simple as possible, we avoid introducing
a fully-ﬂedged bilinear application (as for example in the bang-calculus (Ehrhard and Guerrieri 2016)) and opt instead
for just a negation operator and dedicated typing rules. We may omit the subscript d in R⊥d if clear from the context
or unimportant.

An annotated variable is either x!A (called exponential variable) with A any type, or xR (called linear variable): the
writing x(!)A stands for one of the two annotations (in the linear case A = R). The grammar of values and terms is given
by mutual induction as follows, with x(!)A varying over the set of annotated variables, r over the set of real numbers R
and f over a ﬁnite set F of function symbols over real numbers containing at least multiplication (noted in inﬁx form
t · u):

v ::= x(!)A | r | λx(!)A.t | hv1,v2i

t, u ::= v | tu | ht, ui | t[

x!A, y!B
D

E

:= u] | t[x(!)A := u] | t + u | f (t1, . . . , tk )

(values)

(terms)

(6)

(7)

Since binders contain type annotations, bound variables will never be annotated in the sequel. In fact, we will entirely
omit type annotations if irrelevant or clear from the context. Terms of the form r are called numerals. The term t[x := u]
(and its binary version t[hx, yi := u]) may be understood as the more familiar let x = u in t used in the previous
informal sections.

We denote by Λ⊥(F ) the set of terms generated by the above grammar. We consider also the subset Λ(F ) of terms

obtained by discarding linear negation and linear variables.

We denote by |t | the size of a term t, i.e., the number of symbols appearing in t. We denote by fv(t) the set of

free variables of t, abstractions and explicit substitutions being the binding operators. As usual, α-equivalent terms
are treated as equal. A term t is closed if fv(t) = ∅. In the following, we will use boldface metavariables to denote
sequences: x will stand for a sequence of variables x1, . . . , xn , t for a sequence of terms t1, . . . , tn, etc. The length of
the sequences will be left implicit, because either clear from the context or irrelevant.

14

Γ ⊢z z : R

Γ, x !A ⊢ x : A

Γ ⊢(z) t : A Γ ⊢(z) u : B
Γ ⊢(z) ht, u i : A × B

Γ ⊢ u : A × B Γ, x !A, y !B ⊢(z) t : C
x !A, y !B

:= u] : C

Γ ⊢(z) t [

Γ, x !A ⊢ t : B
Γ ⊢ λx !A .t : A → B

Γ ⊢ t : A → B Γ ⊢ u : A
Γ ⊢ tu : B

Γ ⊢z t : Rd
Γ ⊢ λzR .t : R⊥d

(cid:11)
(cid:10)
Γ ⊢ t : R⊥d

Γ ⊢(z) u : R

Γ ⊢(z) tu : Rd

Γ ⊢ u : A Γ, x !A ⊢(z) t : C
Γ ⊢(z) t [x !A := u] : C

Γ ⊢(z′) u : R Γ ⊢z t : Rd
Γ ⊢(z′) t [zR := u] : Rd

Γ ⊢ t1 : R . . .

Γ ⊢ tk : R

Γ ⊢ f (t1, . . . , tk ) : R

r ∈ R
Γ ⊢ r : R

Γ ⊢(z) t : R Γ ⊢ u : R
Γ ⊢(z) t · u : R

Γ ⊢ t : R Γ ⊢(z) u : R
Γ ⊢(z) t · u : R

Γ ⊢(z) t : Rd

Γ ⊢(z) u : Rd

Γ ⊢z 0 : Rd

Γ ⊢(z) t + u : Rd

Table 1. The typing rules. In the pairing and sum rules, either all three sequents have z, or none does.

We use n-ary products ht1, . . . , tn−1, tni as syntactic sugar for ht1, . . . htn−1, tni . . . i, and we deﬁne Euclidean types
by Rd := R × (. . . R × R . . .). It will be useful to denote a bunch of sums without specifying the way these sums are
associated. The notation

ti ,

Õi ∈I
will denote such a bunch for I a ﬁnite set. In case I is a singleton, the sum denotes its unique element. An empty
sum of type Rd stands for
, which we denote by 0. Of course this notation would denote a unique term
modulo associativity and commutativity of + and neutrality of 0, but we do not need to introduce these equations in
the calculus.

0, . . . , 0

(cid:11)

(cid:10)

The typing rules are in Tab. 1. The meta-variables Γ, ∆ vary over the set of typing contexts, which are ﬁnite sequences
of exponential type annotated variables without repetitions. There are two kind of sequents: Γ ⊢ t : A and Γ ⊢z t : Rd .
In this latter d ∈ N and z is linear type annotated variable which occurs free linearly in t. The typing rules deﬁne what
“occurring linearly” means, following the standard rules of linear logic.7 The writing Γ ⊢(z) t : A stands for either
Γ ⊢ t : A or Γ ⊢z t : A, and in the latter case A = Rd for some d.

Contexts. We consider one-hole contexts, or simply contexts, which are deﬁned by the above grammar (6) restricted
to the terms having exactly one occurrence of a speciﬁc variable {·}, called the hole. Meta-variables C, D will range
over the set of one-hole contexts. Given a context C and a term t we denote by C{t }the substitution of the hole in C by

t allowing the possible capture of free variables of t. A particular class of contexts are the substitution contexts which
have the form of a hole followed by a stack (possibly empty) of explicit substitutions: {·}[p1 := t1] . . . [pn := tn ] with
each pi a variable or a pair of variables. Meta-variables α, β will range over substitution contexts. If α is a substitution
context, we will use the notation tα instead of α {t }.

7In this paper we focus on exactly what is required to express the backpropagation algorithm in the λ-calculus, avoiding a full linear logic typing
assignment and just tracking the linearity of a single variable of type R in judgments typing a term with a Euclidean type Rd .

15

(λx.t)αu −→ t[x := u]α
s[hx, yi := ht, ui α] −→ s[x := t][y := u]α
C{x }[x!A := vα] −→ C{v }[x!A := v]α

t[x!A := vα] −→ tα
t[xR := vα] −→ t {v/x } α
rα + qβ −→ r + qα β
ht1, t2i α + hu1, u2i β −→ ht1 + u1, t2 + u2i α β
rα · qβ −→ rqα β

if x < fv(t)

(8)

(9)

(10)

(11)

(12)

(13)

(14)

(15)

(a) β -rules. In (10), (11) and (12), v is a value. In (10), C is an arbitrary context not binding x . We write (10)
of (10) in which v is a numeral.

n

to refer to the instance

t[x :=

u,u ′

t −→ λy.ty
] −→ t[x :=

y, y′

][

y, y′

:=

u, u ′

]

(b) η-rules. In (16) t has an arrow type or R⊥ . The new variables on the right-hand side of both rules are fresh.
(cid:10)

(cid:11)

(cid:10)

(cid:11)

(cid:10)

(cid:11)

(cid:11)

(cid:10)

α ′t ′)β ′ −→ xR⊥
(c) linear factoring (ℓ-rule for short), where we suppose that none of α, β, α ′, β ′ binds x .

(t + t ′)α βα ′β ′

αt)β + (xR⊥

(xR⊥

t[x := u][y := w] ≡ t[y := w][x := u]
t[x := u][y := w] ≡ t[x := u[y := w]]

t[x!A := u] ≡ t {y/x }[x!A := u][y!A := u]

(s(cid:3)t)[x := u] ≡ s[x := u](cid:3)t
(s(cid:3)t)[x := u] ≡ s(cid:3)(t[x := u])

if y < fv(u) and x < fv(w)
if y < fv(t)

if x < fv(t)
if x < fv(s)

(16)

(17)

(18)

(19)

(20)

(21)

(22)

(23)

(d) Structural equivalence. In (21), t{y/x } denotes t in which some (possibly none) occurrences of x are renamed to a fresh variable
y. In (22), (23) the writing s(cid:3)t stands for either st or s + t or s · t or hs, t i.

Table 2. The reduction and the structural equivalence relations, where we suppose the usual convention that no free variable in one
term can be captured in the other term of a relation.

Rewriting rules. The reduction relation is given in Tab. 2 divided in three sub-groups:

β := {(8), (9), (10), (11), (12), (13), (14), (15)}

η := {(16), (17)}

ℓ := {(18)}

evaluation rules,

extensional rules,

linear factoring.

In case one wants to consider numeric computations (other than sum and products), then of course one must also

include suitable reduction rules associated with the function symbols:

f (r 1α1, . . . , r nαn) −→

f

(r1, . . . , rn)α1 . . . αn

(24)

J
16

K

The rule (8) transforms a λ-calculus application into an explicit substitution. The diﬀerence between the two is that

the latter commutes over terms by the structural equivalence deﬁned in Tab. 2d, while the former does not. Rule (9)

deconstructs a pair, while rule (10) implements a “micro-step” substitution, closer to abstract machines (Accattoli et al.

n
2014). The special case in which v is a numeral is referred to as (10)

. Rule (11) implements garbage collection, and

rule (12) linear substitution. The rules (16) and (17) are standard instances of η-expansion rules. They are useful in the

proof of Theorem 5.6. Rule (18) has already been discussed.

Notice that Λ(F ) is a standard linear explicit substitution calculus encompassing both call-by-need and call-by-
value (Accattoli et al. 2014). For instance, the usual by-value β-rule (λx.t)v −→ t {v/x } is derivable. In this respect,
the reader may think of Λ(F ) as nothing but the plain simply-typed λ-calculus, and consider explicit substitutions as
needed merely to represent computational graphs (which are obtained by restricting to the ground type R only). The
situation is diﬀerent in Λ⊥(F ), in which linearity plays a key role for expressing backpropagation.

Given any X ⊆ β ∪ η ∪ ℓ, we denote by

X
−−→ the context closure of the union of the reduction relations in X , for any

context C:

C{t }

X
−−→ C{u}, whenever t

X
−−→ u.

This means that we do not consider a speciﬁc evaluation strategy (call-by-value, call-by-name etc. . . ), in order to be as

general as possible and to allow a future analysis concerning a more eﬃcient operational semantics.

A term t is a X -normal form if there is no term u with t

X = β ∪ η ∪ ℓ, we write just −→. If k ∈ N,
X
−−→∗ is the reﬂexive-transitive closure of

arbitrary length (including null), i.e.,

X
−−→ u. If the set X is a singleton {ι}, we simply write

ι
−→. If
X
X
−−→∗ denotes a sequence
−−→k denotes a sequence of length k of
X
−−→. Juxtaposition of labels means their

X
−−→, whereas

union, so that, for example,

βη
−−→ denotes the context closure of all reduction relations except (18).

Structural equivalence ≡ is the smallest equivalence relation containing the context closure of the rules (19)–(23) in

Tab. 2d. Morally, structural equivalence relates terms which would correspond to the same state of an abstract machine

implementing the calculus, in which explicit substitutions represent pointers to memory. We refer to (Accattoli et al.
2014; Accattoli and Barras 2017) for more details. The crucial property of ≡ is that it is a (strong) bisimulation with
respect to −→, which means in particular that it may always be postponed to the end of an evaluation (Proposition 4.3).

The following properties are standard and we give them without proof.

Proposition 4.1 (Subject reduction). If t −→ u or t ≡ u and Γ ⊢(z) t : A, then Γ ⊢(z) u : A.

Lemma 4.2 (≡ is a strong bisimulation). Let ι be any reduction rule and let t ′ ≡ t

ι
−→ u, then there exists t ′

ι
−→ u ′

such that u ′ ≡ u.

Proposition 4.3 (postponement of ≡). Let X be any subset of the reduction rules in Tab. 2 (including the variant
n
(10)

X
−−→ ∪ ≡)∗ u with k X -steps, then there exists u ′ such that t

X
−−→k u ′ ≡ u.

) and let t (

Proposition 4.4 (values). Given a closed term t of type A, if t is a β-normal form, then it is a value.

Proposition 4.5 (Weak normalization). For every term t, and every set X ⊆ βℓ, there exists a X -normal form u

such that t

X
−−→∗ u.

The βℓ-rewriting enjoys also strong normalization, even modulo ≡, but the proof is more involved and uninteresting
for our purposes, so we omit it. The strong normalization is however immediate if we restrict the contraction rule (10)

to numerals, a property which will be useful in the sequel.

17

Lemma 4.6. For any t

n
(10)
−−−−−−−−−−−−−−−−→∗ u, the number of steps in the sequence is O(|t |).

(11)(14)(13)(15)

Denotational semantics. The cartesian closed category of sets and functions gives a denotational model for this

calculus. Types are interpreted as sets, as follows:

R

:= R

K

:=

A

×

B

J
A × B
J

A → B
J

R⊥d

q

K
y

:= set of functions from

A

to

B

J
:= set of linear maps from R to Rd

K

J

K

Γ

J

K

K

J

R⊥d
from the cartesian product

K
Notice that the restriction to linear functions in
Γ ⊢ t : A is a function
t
. The interpretation
of a judgment Γ ⊢z t : Rd , is given as a function
a linear map from R to Rd . The
K
deﬁnition is by induction on t and completely standard (explicit substitution is functional composition). We omit the
superscript Γ (or Γ; z) if irrelevant. This interpretation supposes to have associated each function symbol in F with a
suitable map over real numbers. By a standard reasoning, one can prove that:

is such that rule (18) is sound. The interpretation of a judgment
y
Γ

of the denotations of the types in Γ to

Γ;z associating with every g ∈
J

A

q

Γ

J

K

K

J

K

J

J

K

t

Proposition 4.7 (Semantic soundness). Let Γ ⊢(z) t : A, then t −→ u or t ≡ u, gives

t

=

u

.

K
The semantic soundness gives as a by-product a light form of conﬂuence on Euclidean types8.

J

J

K

Corollary 4.8. Let ⊢ t : Rd and v and v ′ be β-normal forms s.t. t −→∗ v and t −→∗ v ′. Then v = v ′.

Proof. It is not hard to show that the interpretation is injective on tuples of numerals, i.e., for v,v ′ : Rd values,
=
(cid:3)

implies v = v ′. The statement then follows from Props. 4.4 and 4.7.

v

J

v ′
J

K
From now on, we will suppose that:

K

(⋆)

all function symbols in F are associated by

−

with diﬀerentiable maps on real numbers.

J
As mentioned at the end of Sect. 2.3, this hypothesis is essentially cosmetic, in that it allows us to use actual gradients

K

and to avoid the more technical notion of subgradient (see also Sect. 7).

Any term x!R
1
(⋆) implies that
in order to β-reduce t into a β-normal form u containing only variables of type R. Then by Prop. 4.7

over R. Since diﬀerentiable functions compose, then
is also diﬀerentiable, if t contains only variables of type R. In the general case, one can use Prop. 4.5

n ⊢ t : R is denoted by an n-ary map

, . . . , x!R
t

J

K

K

J

t

t

is diﬀerentiable. This justiﬁes the following notation, given x!R
1

, . . . , x!R

J

K

∇t(r) :=

∂1

t

(r), . . . , ∂n

t

(r)

.

Section 5 gives an eﬃcient way of computing ∇t(r) based on the syntactic structure of t.

D

J

K

J

K

E

t
n ⊢ t : R and a vector r ∈ Rn:
J

=

u

and so

K

J

K

(25)

5 THE BACKPROPAGATION TRANSFORMATION

Let us ﬁx two sets of function symbols F , F ′ such that F ⊆ F ′, together with partial functions ∂i : F −→ F ′, for
each positive integer i such that, for all f ∈ F of arity k and for all 1 ≤ i ≤ k, ∂i f is deﬁned and its arity is equal to k.
In addition to the hypothesis (⋆) in Sect. 4, we also suppose:

(⋆⋆)

∂i f

:= ∂i

f

8More sophisticated notions of conﬂuence modulo an extension of ≡ hold for the reductions in Tab. 2, but we avoid to discuss this point here because
inessential for our purposes.

J

K

J

K

18

←−
Dd (R) := R × R⊥d

Dd (A → B) := ←−
←−

Dd (A) →

←−
Dd (B)

Dd (A × B) := ←−
←−

Dd (A) ×

←−
Dd (B)

(a) The action of the transformation on types.

←−
Dd (A)

←−
Dd (x!A) := x!
←−
Dd (λx!A.t) := λx!
Dd (tu) := ←−
←−
Dd (t)
←−
Dd (t),

←−
Dd (ht, ui) :=

←−
Dd (t[

D
:= u]) := ←−
Dd (t)[

x!A, y!B
D
E
Dd (t[x!A := u]) := ←−
←−
←−
Dd (r ) :=

←−
Dd (t + u) :=

←−
Dd (f (t)) :=

←−
Dd (t)

←−
Dd (A).
←−
Dd (u)
←−
Dd (u)
E
←−
D d (A), y!

←−
Dd (B)

(cid:29)
Dd (u)]

←−

D d (A) := ←−

x!
(cid:28)
Dd (t)[x!
r, λaR.0
D
x + y, λaR.(x∗a + y∗a)
D

E

k

f (x) , λaR.

*

Õi =1

:= ←−

Dd (u)]

[

x!R, x∗!R⊥d
D

E
x∗
i (∂i f (x) · a)

E
x!R, x∗!R⊥d

:= ←−

Dd (t)][

y!R, y∗!R⊥d
D
:= ←−
Dd (t)]

:= ←−

Dd (u)]

E

[

+

D

E

D

(b) The action of the transformation on terms. In the definition of
1 , x ∗
x !R
of f and the notation [
1
Sect. 3, the variables with superscript ∗ correspond to backpropagators in AD terminology (Pearlmutter and Siskind 2008).

←−
D (f (t)), the sequences t, x, x∗ have all length k equal to the arity
!R⊥d
!R⊥d
D (tk )]. As mentioned in

D (t)] stands for [

x!R, x∗!R⊥d

D (t1)] · · · [

:= ←−

:= ←−

:= ←−

, x ∗
k

x !R
k

D

E

D

E

E

Table 3. The reverse gradient

←−
Dd relative to Rd , for an arbitrary natural number d.

For any d ∈ N, Tab. 3 deﬁnes a program transformation

←−
Dd from Λ(F ) to Λ⊥(F ′), called the reverse gradient relative
←−
Dd (t) computes the gradient of t in at most O(m + |G|) steps, where
to Rd . Given a term x!R ⊢ t : R, Cor. 5.7 proves that
m is the cost of evaluating t to a computational graph G. Moreover, Cor. 5.7 is a consequence of Th. 5.6, proving that
←−
Dd (t) to a term expressing the backpropagation algorithm applied to any computational graph
G β-equivalent to t (indeed, to a single λ-term t one can associate diﬀerent computational graphs, with diﬀerent sizes

actually one can reduce

and with diﬀerent degrees of sharing). Sect. 5.1 sets the framework needed to state and prove our results. Grammar

(26) deﬁnes the notion of ground term corresponding to a computational graph and Def. 5.1 gives the computational

graph associated with the backpropagation applied to ground terms. Prop. 5.3 formally proves the soundness of this

algorithm. Sect. 5.2 then moves to the more general case of λ-terms, giving the soundness of our reverse gradient

transformation

←−
Dd .

←−
Dd is totally independent from the arity k of the
Let us underline that, in the last line of Tab. 3b, the index d of
←−
function symbol f and from the indexes i ≤ k of the variables x∗
Dd . The fact that d
may be arbitrary (it plays a role only in the last remark of Sect. 5.2) is a crucial feature allowing its compositionality,
in contrast with the deﬁnition of bpx, a(G) which has to refer to x containing the free variables in G (see the case
bpx, a(f (y)) in Def. 5.1). This being said, we henceforth omit the index d.

i tagging the sum introduced by

19

5.1 Backpropagation on Computational Graphs

We restrict Λ(F ) to terms of type R not containing higher types, deemed ground terms, as follows:

F , G ::= x!R | F [x!R := G] | f (x!R

1 , . . . , x!R

k ) | r | F + G

(26)

A term f (G1, . . . , Gk ) is considered as syntactic sugar for f (x1, . . . , xk )[x1 := G1] . . . [xk := Gk ]. Fig. 1 and 2 give
examples of ground terms with the associated computational graph. Notice that the type system of Tab. 1 assigns to
any ground term G a type judgment x!R
n ⊢ G : R for a suitable set of variables, so ∇G(r) is deﬁned by (25) and
1
the hypothesis (⋆) and (⋆⋆).

, . . . , x!R

We now deﬁne the transformation bp implementing symbolic backpropagation, as described on hypergraphs e.g. in

(Van Iwaarden 1993, Sect. 3). We ﬁrst introduce the following notation, evaluating some trivial sums on the ﬂy: given
two ground terms F0, F1,

F0 ⊕ F1 :=

Fi
F0 + F1

if Fi −1 = 0,

otherwise





, . . . , x!R

n . Given a ground term of type Γ ⊢ G : R and a fresh variable aR, we deﬁne the

Deﬁnition 5.1. Let Γ = x!R
1

term

by induction on G, as follows. The deﬁnition is based on the inductive invariant that

Γ, a!R ⊢ bpx, a(G) : R × Rn

where α and β are substitution contexts and a does not appear free in G0 or in β.

bpx, a(G) = hG0, hG1, . . . , Gni αi β

• bpx, a(xi ) :=
• bpx, a(r ) :=
• Let f be of arity k and y a subsequence of length k of x. Then,

0, . . . , a, . . . , 0
.

xi ,
r,
(cid:10)

0, . . . , 0
(cid:10)

(cid:11)(cid:11)

, where a appears at the i-th position in the tuple.

(cid:10)

(cid:11)(cid:11)

(cid:10)
bpx, a(f (y)) :=

f (y),

0, . . . , 0, ∂1 f (y) · a, 0, . . . , 0, ∂k f (y) · a, 0, . . . , 0

,

(cid:11)(cid:11)
where the non-zero terms in the tuple are at the positions determined by y within x.

(cid:10)

(cid:10)

• Let G = F ′[z!R := F ′′] and suppose that (with b!R a new variable distinct from a!R)

bpx,z, a(F ′) =

F ′
0,

1, . . . , F ′
F ′

n, H

α ′

β ′,

bpx,b (F ′′) =

F ′′
0 ,

1 , . . . , F ′′
F ′′
n

α ′′

β ′′.

(cid:10)

(cid:11)
(cid:10)
Notice that for every i ≤ n we can suppose by renaming that the set of variables of F ′
disjoint from the set of variables of F ′′
0 has type x!R ⊢ F ′′
can deﬁne:

i bound by α ′′, β ′′. Also, notice that F ′′

i bound by α ′, β ′ is
0 : R. So we

(cid:10)

(cid:11)

(cid:11)

(cid:10)

(cid:11)

bpx, a(F ′[z!R := F ′′]) :=

F ′
0
F ′
0
• Let G = F ′ + F ′′ and suppose that

(cid:10)

(cid:10)

,

,

(cid:10)

(cid:10)

F ′
, . . . , F ′
β ′[z!R := F ′′
α ′
n
1
F ′
1 ⊕ F ′′
n ⊕ F ′′
, . . . , F ′
(cid:11)
(cid:11)
n
1

0 ]β ′′
α ′′[b!R := H ]α ′

if H = 0,

β ′[z!R := F ′′

0 ]β ′′

otherwise.

(cid:11)

(cid:11)

α ′

β ′,

bpx, a(F ′′) =

F ′′
0 ,

1 , . . . , F ′′
F ′′
n

α ′′

β ′′,




1, . . . , F ′
F ′
n

bpx, a(F ′) =

F ′
0,

(cid:10)

(cid:10)

(cid:11)

(cid:11)

20

(cid:10)

(cid:10)

(cid:11)

(cid:11)

then, bpx, a(F ′ + F ′′) :=

F ′
0

+ F ′′
0

,

F ′
1 ⊕ F ′′
1

, . . . , F ′

n ⊕ F ′′
n

α ′α ′′

β ′β ′′.

Lemma 5.2. Let G be a ground term with fv(G) = x, then

(cid:10)

(cid:10)

(cid:11)
bpx, a(G)

(cid:11)
= O(|G|).

(cid:12)
(cid:12)
Proposition 5.3 (Soundness of bp). Let G be a ground term whose free variables are given by a sequence x of length

(cid:12)
(cid:12)

n. Then for every r ∈ Rn, we have:

bpx, a(G)[a := 1][x := r]

n

(11)(13)(15)

(10)
−−−−−−−−−−−−−→O (|G |)≡

G

(r), ∇G(r)

.

DJ

K

E

n
Proof. Let R = {(10)

(11)(13)(15)}. By induction on G we prove that, supposing bpx, a(G) = hG0, hG1, . . . , Gn i αi β,
(r); (ii) for all 1 ≤ i ≤ n, for all real number q,

R
−→∗≡

G

for every vector of real numbers r, we have: (i) G0β[x := r]
Gi α β[a := q][x := r]

(r) · q. From (i) and (ii):

R
−→∗≡ ∂xi

G

J

K

bpx, a(G)[a := 1][x := r ] ≡

J

K

G0β[x := r],

G1α β[a := 1][x := r], . . . , Gnα β[a := 1][x := r]

R
−→∗ ≡

G

(r), ∇r

G

.

Prop. 4.3 allows to postpone all structural equivalences at the end. From Lem. 4.6 and
the length of the reduction is O(|G|).

(cid:10)

(cid:10)

K

DJ
J
= O(|G|) (Lem. 5.2)

KE

(cid:11)(cid:11)
bpx, a(G)
(cid:12)
(cid:12)

(cid:12)
(cid:12)

We give only the proof of (ii) for G = F ′[z := F ′′], the other cases being similar or trivial. Using the notations from
Def. 5.1 we have that the i-th component of the gradient tuple of bpx, a(G) together with the associated substitutions
is equal to (we suppose F ′
i , the other cases being simpler):

+ F ′′

i ⊕ F ′′
i

= F ′
i
i )α ′′[b := H ]α ′β ′[z := F ′′
+ F ′′

+ F ′′

(F ′
i
≡ (F ′
i

0 ]β ′′[a := q][x := r]

i )α ′′[b := H ]α ′β ′β ′′[a := q][x := r][z := F ′′
i )α ′′[b := H ]α ′β ′β ′′[a := q][x := r][z :=
+ F ′′
i )α ′′α ′β ′β ′′[a := q][x := r][z :=

F ′′

J

R
−→∗ (F ′
i
+ F ′′
≡ (F ′
i

0 β ′′[x := r]]

F ′′

(r)]

(r)][b := Hα ′β ′β ′′[a := q][x := r][z :=

K

K
i )α ′′α ′β ′β ′′[a := q][x := r][z :=
F ′′

(r)] + F ′′

J

F ′′

(r)][b := ∂z
F ′

J
i α ′′β ′′[b := ∂z

K

F ′

(r) · q]

K
(r) · q][x := r]

J

R
−→O (|F ′ |) (F ′
i
≡ F ′

+ F ′′
i α ′β ′[a := q][x := r][z :=
F ′′

(r) · q + ∂xi

F ′

R
−→∗ ∂xi
(13)
−−−→

J
∂xi

J
K
(r) ·

∂z

F ′

(r) · q

J

K

K
F ′

(r) + ∂z

J
F ′

K
(r) · ∂xi

(cid:0)

J
F ′′

K
(r)

(cid:1)
· q = ∂xi

G

(r) · q

F ′′

(r)]]

J

K

by (i)

by IH

by IH

(cid:0)

K

J

J

K

J
Notice that in order to move to the last line we use the associativity, commutativity and distributivity of + and ·
over real numbers, not on the corresponding syntactic symbols. In the base cases (variables, functional symbols and
numerals), one performs linear substitutions (10) as well as garbage collection (11). In the case of bpx, a(f (xi1 , . . . , xik ))
(cid:3)
one instance of rule (15) is needed.

K

K

J

(cid:1)

Notice that the result of the evaluation of bpx, a(G)[a := 1][x := r] is independent from the chosen reduction

sequence by Corollary 4.8.

21

5.2 Backpropagation on Higher-Order Programs

Let us now consider the soundness of our transformation

proof uses two essential ingredients: ﬁrst, we remark that the transformation

(Lem. 5.4); second, we prove that
of bpx, a(G) (Lem. 5.5). Notice that Lem. 5.5 introduces fresh variables x ′
components of the gradient of G in a sum. We can then conclude with Th. 5.6 and its Cor. 5.7.

←−
D applied to a computational graph G encodes actually all the relevant information
i (i ≤ n) annotated !R⊥ , tagging the diﬀerent

←−
D (t) applied to any λ-term of type x!R
n ⊢ t : R. The
1
←−
D (t) commutes with any reduction step

, . . . , x!R

Lemma 5.4. Let t be a term of Λ(F ). Then:
←−
D (t) ≡

←−
(1) if t ≡ t ′, then
D (t ′),
ι
−→ t ′, for ι any reduction step in Tab. 2, then

(2) if t

←−
D (t)

these latter cases X = {ι, (8), (10), (11)}.

X

−−→O (1) ←−

D (t ′), where X = {ι} for any ι but (13), (15), in

Lemma 5.5. Let G be a ground term with fv(G) = x = x!R
1

, . . . , x!R

n and suppose that bpx, a(G) = hG0, hG1, . . . , Gn i αi β.

Then, there exists J ⊆ {1, . . . , n} such that i < J implies Gi = 0 and such that

←−
D (G)[x!

←−
D (R) :=

x!R, λaR.x∗!R⊥

a

] −→O (|G |)≡

D

E

G0, λa.(
*

Õj ∈J

x∗
j Gj )α

β .

+

Proof. By induction on G. We only consider G = F [z := F ′], the other cases being simpler. Let bpx,z, a (F ) =
β ′. Let us also consider H , 0 (the other case being
α ′

,

hF0, hF1, . . . , Fn, H i αi β and bpx,b (F ′) =
F ′
0
←−
D (G)[x := hx, λa.x∗ai] is structural equivalent to:
simpler). The term
(cid:10)
(cid:10)
←−
D (F ′)[x :=

(cid:11)
(cid:11)
x, λb.x∗b

←−
D (F )[x :=

x, λa.x∗a

, . . . , F ′
n

])[z := (

F ′
1

])]

(

(cid:10)
(cid:11)
←−
−→O (|F ′ |)≡ (
D (F )[x :=

x, λa.x∗a

])[z :=

(cid:10)
F ′
0, λb.(

(cid:11)

*

j F ′
x∗

j )α ′

β ′]

+

by IH

←−
D (F )[x :=

≡ (

(cid:10)
x, λa.x∗a

])[z :=

(cid:11)

*

(17)
−−−→

(9)
−−→ (

(cid:10)
←−
D (F )[x :=

(cid:11)

x, λa.x∗a

][z :=

Õj ∈J ′
z, z∗

F ′
0, λb.(

j F ′
x∗

Õj ∈J ′
j )α ′

]β ′

+

(16)
−−−→ (

←−
D (F )[x :=

(cid:10)
x, λa.x∗a

(cid:11)
][z :=

(cid:11)
(cid:10)
z, λa.z∗a

])[z := F ′

0][z∗ := λb.(

j F ′
x∗

j )α ′]β ′

Õj ∈J ′

])[z := F ′

0][z∗ := λb.(

j F ′
x∗

j )α ′]β ′

−→O (|F |)≡

(10)
−−−→

(11)
−−−→

(cid:10)

F0, λa.(

*

Õj ∈J

F0, λa.(

*

Õj ∈J

(8)
−−→

*

F0, λa.(

x∗
j Fj + (

Õj ∈J

Õj ∈J ′

(cid:11)
(cid:10)
j Fj + z∗H )α
x∗

+

(cid:11)
β[z := F ′

0][z∗ := λb.(

Õj ∈J ′

Õj ∈J ′
j )α ′]β ′

j F ′
x∗

x∗
j Fj + (λb.(

j F ′
x∗

j )α ′)H )α

β[z := F ′

0]β ′

+

Õj ∈J ′
j )α ′[b := H ])α

j F ′
x∗

β[z := F ′

0]β ′

+

(18)
−−−→#J ∩#J ′

F0, λa.(

*

Õj ∈J ∪J ′

j (Fj ⊕ F ′
x∗

j ))α ′[b := H ]α

β[z := F ′

0]β ′

+

22

by IH

(cid:3)

By composing the reductions in Lemma 5.4 and Lemma 5.5, we get:

Theorem 5.6. Let t be a term of Λ(F ) of type R with fv(t) = x = x!R
1
β
−→ ∪ ≡)∗ G in m β-steps, we have, for a suitable J ⊆ {1, . . . , n}:

t (

, . . . , x!R

n . For any ground term G such that

←−
D (t)[x!

←−
D (R) :=

x!R, λaR.x∗!R⊥

a

] −→O (m+ |G |) ≡

where bpx, a(G) = hG0, hG1, . . . , Gn i αi β and ∀i < J , Gi = 0.

D

E

G0, λa.(
*

Õj ∈J

x∗
j Gj )α

β

+

Corollary 5.7. Let t be a term of Λ(F ) of type x!R ⊢ t : R, with x = x!R
1

, . . . , x!R

number of β-steps needed to reduce t to a ground term G. For any vector r ∈ Rn , let ∇t(r) =
suitable J ⊆ {1, . . . , n}, with i < J , дi = 0, we have:

n the free variables of t. Let m be the
д1, . . . , дn
. Then, for a
D

E

z∗1[

z, z∗

:= ←−

D (t)[x :=

x, λa.x∗a

]][x := r] −→O (m+ |G |) ≡

x∗
j дj .

Õj ∈J

(cid:10)

(cid:11)

(cid:10)

(cid:11)

One can go further and obtain the tuple of numerals ∇t(r) from

←−
Dd (t) with
d = n (here is the only point where we require a speciﬁc choice of d); (ii) replacing each x∗
i (i ≤ n), morally of type
R ⊸ Rn , with the corresponding injection λa. h0 . . . , 0, a, 0, . . . , 0i; (iii) adding all tuples resulting from the reductions
(8),(10),(11):
. However, this last reduction is quadratic in n, as it performs
#J = O(n) sums of vectors of size n without considering that these latter are null but on one coordinate. It would then
be preferable to add an ad hoc read-back operation allowing to decode the tuple ∇t(r) out of the tagged sum
j дj

j дj just by: (i) considering

0, . . . , 0, дj , 0 . . . , 0

j ∈J x∗

j ∈J x∗

, . . . , д

−→∗

j ∈J

Í

Í

д

D

D

E

E

n

1

more parsimoniously.

Í

Notice that the proof of Cor. 5.7 considers a speciﬁc reduction sequence for getting ∇t(r). However, Cor. 4.8 guar-
antees that the result is independent from the chosen sequence.9 This suggests considering more eﬃcient strategies
than that of Cor. 5.7, or even more modular by decomposing the computation along the diﬀerent components of t. We

discuss this last point in the next Section.

6 AN EXAMPLE: RECURRENT NEURAL NETWORKS

6.1 Derivative of a dynamically generated polynomial

Let Nat := (R → R) → R → R be the type of Church natural numbers and consider

G := w · y + x

t := λn!Nat.λx.n(λy.G)x.

We have x!R, y!R, w!R ⊢ G : R and w!R ⊢ t : Nat → R → R. If n encodes n ∈ N, the term t n dynamically generates the
function λx.fn(w, x) with fn (w, x) := (wn + wn−1 + · · · + w + 1) · x (we take some liberty in simplifying arithmetic
expressions for the sake of readability). Notice that the free variable x of λy.G, a term to be iterated at will, is captured
later in t. We have

←−
D (λy.G) −→∗ λ

y,y∗

.

G, λa.w∗(y · a) + y∗(w · a) + x∗a

=: G ′,

where we used the shorthand λhy, y∗i.u := λp.u[hy, y∗i := p]. Hence, when e.g. n = 2,
(cid:11)
(cid:10)

(cid:10)

(cid:11)

←−
D (t 2) = (λn.λx.n
x, x∗

−→ λ

←−
D(λy.G)x) 2 −→∗ (λn.λx.n G ′ x) 2 −→ λx.2 G ′ x −→ λx.G ′(G ′x)
.G ′(G ′

.G ′ hwx + x, H i ,

) −→∗ λ

x, x∗

x, x∗

(cid:11)
9This is in fact the case if one admits the injections λa. h0 . . . , 0, a, 0, . . . , 0i of type R⊥ , as discussed in the previous note.

(cid:10)

(cid:11)

(cid:10)

(cid:10)

(cid:11)

23

where H := λa.w∗(x · a) + x∗(w · a) + x∗a. The computation continues with

x, x∗
−→∗ λ
x, x∗
−→∗ λ
(cid:10)
x, x∗
−→∗ λ
(cid:10)

.

(cid:11)

.

(cid:10)

(cid:11)

.

(cid:10)

(w2 + w + 1)x, λa.w∗((wx + x) · a) + H (w · a) + x∗a
(w2 + w + 1)x, λa.w∗((wx + x) · a) + w∗(wx · a) + x∗(w2 · a) + x∗(w · a) + x∗a
(w2 + w + 1)x, λa.w∗((2wx + x) · a) + x∗((w2 + w + 1) · a)

(cid:11)

(cid:11)

(cid:10)

(cid:11)

(cid:10)

We see that the argument of w∗ (resp. x∗) is the derivative of f2 with respect to w (resp. x). This shows how locally free
variables are handled correctly. Also observe that G ′, which is trivial here but could in principle be a very complex
function, may be pre-computed independently of n.

(cid:11)

6.2 Recurrent neural networks

Recurrent neural networks (RNNs) are meant to process inputs that are arbitrary sequences of vectors in Rd . They are
heavily used for natural language processing: sequences could for instance stand for a word or a sentence, where each

vector is a representation of a letter. Such networks iterate over the input to recursively build a desired output. One
example is encoding recurrent neural networks, which are used to encode a sequence of vectors xi ∈ Rd into an output
vector h ∈ Rm . For instance, in sentiment analysis (dos Santos and Gatti 2014; Glorot et al. 2011; Severyn and Moschitti
2015), it is used to predict if the expressed opinion in a sentence is positive, negative or neutral.

Given a sequence x1, ..., xn ∈ Rd , the encoding RNN produces intermediate outputs h1, ..., hn ∈ Rm recursively, by

applying a single layer L : Rd × Rm → Rm to both the last output value hi and the next input vector xi +1:

hi +1 = L(xi +1, hi )

L(x, h) = σ (E · x + R · h)

where σ is the sigmoid activation function, E is a d × m-matrix called the token embedding matrix, and R is a m × m
matrix whose coeﬃcients are called the recurrent weights. h0 can be initialized to 0. In practice, a RNN ends with a
loss function that we are looking to minimize (and which models the problem we want to solve). To keep the example
simple, we will not consider it. For the same reason, we suppose that d = m = 1, the general encoding being a direct
generalization.

Lists. We represent lists in our language using the Church encoding, which deﬁnes a list by its right fold function.

Given A and X be types, the type of lists List(A, X ) is deﬁned as follows:

List(A, X ) := (A → X → X ) → (X → X )

Given a1 : A, . . . , an : A, we deﬁne the list [a1; ...; an]X of type List(A, X ) as:

[a1; ...; an]X := λ f !(A→X →X ).λx!X .f a1(f a2 . . . (f anx) . . . )

In what follows we will omit the X annotation if it is clear from context or if it does not matter. Finally, it can be noted

that the reverse gradient of the list datatype is given by:

←−
D (List(A, X )) = List(

←−
D (A),

←−
D (X ))

←−
D ([a1; ...; an]X ) = [

←−
D (a1), . . . ,

←−
D (an)]←−

D (X )

Encoding a RNN. Let σ be the function symbol corresponding to the sigmoid function R → R. In dimension 1,
the token embedding matrix and the recurrent matrix may be represented as two terms λx!R.(ϵ · x) and λh!R.(ρ · h)
respectively, where ϵ!R and ρ!R are two variables. The recurring layer L and the recurring network N is then deﬁned
24

and typed as follows:

L := λx!R.λh!R.σ (ϵ · x + ρ · h)
N := λl !List (R, R).lL0

ϵ!R, ρ!R ⊢ L : R → R → R

ϵ!R, ρ!R ⊢ N : List(R, R) → R

The free variables ϵ and ρ are the parameters that we wish to learn via gradient descent.

Backpropagation. For RNNs, the gradient is usually computed using a technique called backpropagation through

time (Pearlmutter 1995; Rumelhart et al. 1987). The method consists in unfolding the RNN (by applying it to an input

sequence) and then applying the usual backpropagation over plain vanilla feedforward neural networks. We will now

apply our reverse gradient transformation to an example of RNN, and show that backpropagation through time is

naturally implemented by the reduction strategy of Theorem 5.6.

Given l = [a1; . . . ; an]R, we compute the gradient of N l with respect to ϵ and ρ. The following proposition ex-
poses the recursive equations expressing the gradient computed thanks to our transformation. They are similar to the

equations of backpropagation through time.

Proposition 6.1. We have ∇(N l)(e,r ) =

ϵ and дn

ρ are given by the following recurrent equations:

σ ′
i +1 := ∂1σ (e · ai +1 + r · ui )

= 0

д0
ϵ
д0
= 0
ρ
u0 = 0

where дn

ϵ , дn
дn
ρ
D
E
дi +1
i +1 · (ai +1 + r · дi
ϵ )
ϵ
дi +1
i +1 · (ui +1 + r · дi
ρ )
ρ
ui +1 = σ (e · ai +1 + r · ui )

= σ ′
= σ ′

Proof. By Corollary 5.7, this amounts to computing D = ϵ∗дϵ + ρ∗дρ such that

z∗1[

z, z∗

:= ←−

D (N l)[ϵ :=

ϵ, λa.ϵ∗a

][ρ :=

ρ, λa.ρ∗a

]][ϵ := e][ρ := r ] −→∗ D

(cid:10)
This is done by induction over the size of the list l.

(cid:10)

(cid:11)

(cid:11)

(cid:10)

(cid:11)

(cid:3)

The strategy from Theorem 5.6 ﬁrst computes

←−
D (N l), then reduces it to

←−
D (G) such that N l −→∗ G, with G a ground

term, i.e., only containing subterms of ground type. Here:

G = F (a1, F (a2, . . . , F (an, 0) . . . ))

where L = λx.λh.F with F = ϵ · x + ρ · h. Notice that G is exactly the unfolding of the RNN, which should convince
the reader that this strategy implements the backpropagation through time.

We now turn our attention to the eﬀectiveness of the reduction strategy. During the reduction of N l to G, the

λ-abstractions of L must be eliminated. Each of these λ is applied exactly to n diﬀerent arguments, requiring L to be

duplicated n times. In other words, we satisfy the following reduction:

By point 2 of Lemma 5.4, the exact same reasoning may be applied to

←−
D (N l), in which

←−
D (L) must be duplicated n

N l −→∗ La1(La2 . . . (Lan0) . . . ) −→∗ G

times:

A simple observation shows that

D (N l) −→∗ ←−
←−

←−
D (L)

←−
D (a1)(

←−
D (a2) . . . (

←−
D (L)

D (L)
←−
D (L) is not in β-normal form:

←−
D (an)

D (0)) . . . ) −→∗ ←−
←−

D (G)

←−
D (L) = λx.λh.

σ (µ), λa.µ∗(∂1σ (µ) · a)

[

µ, µ∗

:= ←−

D (ϵ · x + ρ · h)]

(cid:10)

25

(cid:11)

(cid:10)

(cid:11)

←−
D (L)

←−
D (ϵ · x + ρ · h) being a pair, we have
dimensions d and m are > 1, k = O((d +m)×m). In our case, we see that each component of the sum in
be responsible for at least one substitution. Finally, since

β
−→k u for some β-normal M. Moreover, it can be shown that when the
←−
D (ϵ ·x +ρ ·h) will
←−
D (L) is duplicated n times in the original backpropagation
←−
D (L) is reduced to M before being substituted, we obtain a gain of
through time strategy, by using the strategy where
O((d +m)mn) reduction steps. This is signiﬁcant as the number of learning parameters (here (d +m)m) can be very large
in typical neural networks. For instance, a recent model called GPT-2 (Radford et al. 2019) has 1.5 billion parameters.

7 CONCLUSION AND PERSPECTIVES

On expressiveness. The simply-typed λ-calculus is certainly too restrictive as a programming language, but it does

present the main obstacle in deﬁning higher-order backpropagation, namely the native use of higher-order without

necessarily going through computational graphs. It also has a minimum of expressiveness for interesting examples to
exist, such as inductive types with very basic operations on them (map, fold), as shown in Sect. 6. In fact, our results
apply seamlessly to any total language with set-theoretic semantics (e.g. G¨odel’s System T with arbitrary inductive

types), with no need of additional technical ideas. This is already quite broad: no state-of-the-art deep learning archi-

tecture we are aware of (convolutional NNs, RNNs, Tree-RNNs, attention-based NNs, transformers. . . ) requires going

beyond System T in order to be expressed.

We wish to stress that our current proof does support, unchanged, non-diﬀerentiable functions like ReLU. As men-
tioned at the end of Sect. 2.3, the diﬀerentiability hypothesis (⋆) (end of Sect. 4) is essentially cosmetic, in that it allows
us to use actual gradients and to avoid the more technical notion of subgradient. In the absence of (⋆), Corollary 5.7
holds for all vectors in the domain of deﬁnition of Eq. 25, i.e., wherever the gradient makes sense.

2019)), by adding the deﬁnition

Still in relation with partiality, we argue that our framework can accommodate full recursion (like (Wang et al.
to Tab. 3, where YA : (A → A) → A is the ﬁxpoint operator. As
for denotational semantics, one has to consider the cartesian closed category of pointed complete partial order sets

←−
D (YA) := Y←−

D (A)

and Scott-continuous functions. The type R is interpreted as the ﬂat domain having a bottom element (representing

non-termination) and all real numbers as maximal elements. Corollary 5.7 then holds for all vectors on which the

program converges and is diﬀerentiable. However, this still falls short of being a full programming language like PCF

because it lacks conditionals (on R). The issues related to the presence of branchings are mentioned in (Plotkin 2018),

where a proposal is suggested for ﬁrst-order languages.

On complexity. In computational graphs, complexity analysis assumes that computing the value of a single node

from its local inputs has unitary cost. In terms of low-level complexity models (e.g. random access machines), this

rests on the assumption that searching for the next node to evaluate is a constant-time operation, which is fair because

we may suppose the nodes to be linearly ordered compatibly with the dependencies of the graph.

Our analysis shows that, as soon as the programming language is suitably ﬁne-grained, it is consistent to attribute a

unitary cost to a single evaluation step (i.e., a rewriting rule from Tab. 2). However, in general programming languages,

it is unclear whether the search for the next redex has constant cost. Albeit recent work (Accattoli and Barras 2017,

Corollary 9.2) shows that this is the case in call-by-name evaluation of closed programs, a detailed analysis for our

language is currently missing and we defer it to future work.

On higher-type derivatives. A major endeavor relating functional primitives with diﬀerential operators is diﬀerential

linear logic (Ehrhard 2018) and its associated diﬀerential λ-calculus (Ehrhard and Regnier 2003). Indeed, the initial

26

motivation of our work was to express the backpropagation algorithm in the diﬀerential λ-calculus. Although this

is possible, we realized that it required discarding the most important programming primitive of the diﬀerential λ-

calculus, namely the derivative operator D on higher-order types. This is probably a good place to point out a crucial
←−
D . Take a term λx.t(ux) of type R → R and such that ⊢ t : A → R and
feature of our program transformation
⊢ u : R → A. We have two diﬀerent ways of computing the derivative of t(ux) with respect to xR: either by our
←−
D (λx.t(ux)) or by Ehrhard’s derivative operator D(λx.t(ux)). Both ways are purely functional, but
transformation
←−
←−
D (λx.t(ux)) =
D (u) hx, ai), while Ehrhard’s follows the chain rule (see
β λ hx, ai .D(t) hux, D(u) hx, aii.10 It is clear that this latter expression is ineﬃcient with

our operator decomposes as
Sect. 2.3), giving D(λx.t(ux)) =
respect to backpropagation because of the duplication of the term u (see also Sect. 2).

←−
D and the operator D of the diﬀerential λ-calculus are extensionally diﬀerent. This is immediately seen on
“pure” λ-terms (with no function symbols): when A is higher order, there are pure terms t : A → R with non-trivial
←−
D (t) = t (modulo a type change), which cannot compute the
derivative, which is always computed by D(t), whereas
derivative.11 Indeed, observe that our soundness statements (Theorem 5.6, Corollary 5.7) only hold for terms of ground
type. At present, we seem to have no use for the extra generality provided by the diﬀerential λ-calculus, but it is a

β λ hx, ai .

←−
D (t)(

So our

natural and intriguing question to understand whether the ability to compute derivatives at higher types (rather than

just over R) can play a role in developing new machine learning models.

ACKNOWLEDGMENTS

We would like to thank T. Ehrhard, C. Fouquer´e, M. Gaboardi, B.A. Pearlmutter, Y. Regis-Gianas, J.M. Siskind, C. Tasson

and the anonymous reviewers for useful comments and discussions.

REFERENCES

Mart´ın Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeﬀrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoﬀrey Irving, Michael
Isard, Manjunath Kudlur, Josh Levenberg, Rajat Monga, Sherry Moore, Derek Gordon Murray, Benoit Steiner, Paul A. Tucker, Vijay Vasudevan, Pete
Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. 2016. TensorFlow: A System for Large-Scale Machine Learning. In Proceedings of OSDI.
USENIX Association, 265–283.

Beniamino Accattoli. 2012. An Abstract Factorization Theorem for Explicit Substitutions. In Proceedings of RTA (LIPIcs), Vol. 15. 6–21.
Beniamino Accattoli. 2018. Proof Nets and the Linear Substitution Calculus. In Proceedings of ICTAC (Lecture Notes in Computer Science), Vol. 11187.

Springer, 37–61.

Beniamino Accattoli, Pablo Barenbaum, and Damiano Mazza. 2014. Distilling Abstract Machines. In Proceedings of ICFP. ACM, 363–376.
Beniamino Accattoli and Bruno Barras. 2017. Environments and the complexity of abstract machines. In In Proceedings of PPDP. ACM, 4–16.
Atılım G¨unes¸ Baydin, Barak A. Pearlmutter, Alexey Andreyevich Radul, and Jeﬀrey Mark Siskind. 2017. Automatic Diﬀerentiation in Machine Learning:

a Survey. Journal of Machine Learning Research 18 (2017), 153:1–153:43.

George Cybenko. 1989. Approximation by superpositions of a sigmoidal function. MCSS 2, 4 (1989), 303–314.
Olivier Danvy and Mayer Goldberg. 2005. There and Back Again. Fundam. Inform. 66, 4 (2005), 397–413.
Cicero dos Santos and Maira Gatti. 2014. Deep convolutional neural networks for sentiment analysis of short texts. In Proceedings of COLING: Technical

Papers. 69–78.

Thomas Ehrhard. 2018. An introduction to diﬀerential linear logic: proof-nets, models and antiderivatives. Mathematical Structures in Computer Science

28, 7 (2018), 995–1060.

Thomas Ehrhard and Giulio Guerrieri. 2016. The Bang Calculus: an untyped lambda-calculus generalizing call-by-name and call-by-value. In Proceedings

PPDP. ACM, 174–187.

Thomas Ehrhard and Laurent Regnier. 2003. The diﬀerential lambda-calculus. Theor. Comput. Sci. 309, 1-3 (2003), 1–41.
Conal Elliott. 2018. The simple essence of automatic diﬀerentiation. PACMPL 2, ICFP (2018), 70:1–70:29.
Jean-Yves Girard. 1987. Linear Logic. Theor. Comput. Sci. 50, 1 (Jan. 1987), 1–102.

10Here we use some syntactic sugar in order to avoid notational bureaucracy. For example, λ hx, a i . . . stands for λy . . . . [hx, a i := y] in our
language. Also, the diﬀerential λ-calculus of (Ehrhard and Regnier 2003) does not have pairs and so λ hx, a i is curried into λx .λa.
11This does not contradict Corollary 5.7 because, when A is of order zero (i.e., A = Rn ), any pure t must be a projection and the above equality is correct.

27

Xavier Glorot, Antoine Bordes, and Yoshua Bengio. 2011. Domain adaptation for large-scale sentiment classiﬁcation: A deep learning approach. In

Proceedings of ICML. 513–520.

Kurt Hornik. 1991. Approximation capabilities of multilayer feedforward networks. Neural Networks 4, 2 (1991), 251–257.
J. M. E. Hyland. 2017. Classical lambda calculus in modern dress. Math. Structures Comput. Sci. 27, 5 (2017), 762–781.
Teijiro Isokawa, Tomoaki Kusakabe, Nobuyuki Matsui, and Ferdinand Peper. 2003. Quaternion Neural Network and Its Application. In Proceedings of

KES, Part II. 318–324.

Yann LeCun. 2018. Deep Learning est mort. Vive Diﬀerentiable Programming! (2018).
Yann LeCun, Bernhard E. Boser, John S. Denker, Donnie Henderson, Richard E. Howard, Wayne E. Hubbard, and Lawrence D. Jackel. 1989. Backpropa-

gation Applied to Handwritten Zip Code Recognition. Neural Computation 1, 4 (1989), 541–551.

Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam

Lerer. 2017. Automatic diﬀerentiation in PyTorch. (2017).

Barak A. Pearlmutter. 1995. Gradient calculations for dynamic recurrent neural networks: a survey. IEEE Trans. Neural Networks 6, 5 (1995), 1212–1228.
Barak A. Pearlmutter and Jeﬀrey Mark Siskind. 2008. Reverse-mode AD in a Functional Framework: Lambda the Ultimate Backpropagator. ACM Trans.

Program. Lang. Syst. 30, 2, Article 7 (March 2008), 36 pages.

J.K. Pearson and David L. Bisset. 1992. Back Propagation in a Cliﬀord Algebra. In Proceedings of ICANN, Vol. 2. 413–416.
Gordon Plotkin. 2018. Some Principles of Diﬀerential Programming Languages. (2018). https://popl18.sigplan.org/details/POPL-2018-papers/76/Some-Principles-of-Diﬀerential-Programming-Languages

Invited talk at POPL 2018.

Alec Radford, Jeﬀrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners.

OpenAI Blog 1, 8 (2019).

David E. Rumelhart, James L. McClelland, and PDP Research Group. 1987. Parallel Distributed Processing, Volumes 1 and 2. MIT Press.
Aliaksei Severyn and Alessandro Moschitti. 2015. Twitter sentiment analysis with deep convolutional neural networks. In Proceedings of the 38th

International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, 959–962.

Ronald Van Iwaarden. 1993. Automatic Diﬀerentiation Applied to Unconstrained Nonlinear Optimization with Result Veriﬁcation. Interval Computations

3 (1993), 41–60.

Fei Wang, Daniel Zheng, James M. Decker, Xilun Wu, Gr´egory M. Essertel, and Tiark Rompf. 2019. Demystifying diﬀerentiable programming: shift/reset

the penultimate backpropagator. PACMPL 3, ICFP (2019), 96:1–96:31.

28

A APPENDIX

A.1 Proofs of Section 4

Proposition 4.1 If t −→ u or t ≡ u and Γ ⊢ t : A, then Γ ⊢ u : A.

Proof (Sketch). Let C{t } −→ C{u} (resp. C{t } ≡ C{u}), where t −→ u (resp. t ≡ u) is a reduction step (resp. a

structural equivalence) in Tab. 2. The proof is a standard induction on the evaluation context C. The base case is by

inspection of all cases in Tab. 2, using the following properties:

• (substitution) if Γ, xA ⊢ t : B and Γ ⊢ u : A then Γ ⊢ t {u/x } : B;
• (splitting) if Γ, xA ⊢ t : B then for any term t {y/x } obtained from t by renaming some (possibly none) occur-

rences of x to a fresh variable y, we have Γ, xA, yA ⊢ t {y/x } : B.

The two properties are achieved by induction on t. Notice that the splitting property implies the so-called “weakening”
(cid:3)
lemma: Γ ⊢ t : B implies Γ, xA ⊢ t : B for a fresh variable x.

Lemma 4.2 Let ι be any reduction rule and let t ′ ≡ t

ι
−→ u, then there exists t ′

ι
−→ u ′ such that u ′ ≡ u.

Proof (Sketch). The proof goes along the same lines as (Accattoli et al. 2014). We denote by ≡1 the symmetric and
context closure of the relation induced by the rules (19)–(23), i.e., ≡ is the reﬂexive-transitive closure of ≡1. We then
prove the following lemmata.

(1) If v ≡1 t and v is a value, then t is also a value.

(Remark that no structural equivalence rule allows for commuting an explicit substitution with a λ-abstraction.

In the case v = hv1, v2i, then the only possibility is u = hu1, u2i α (rules (22), (23)), but in this case we would
have vi = uiα, for i = 1 or i = 2, contradicting the hypothesis of vi to be a value).

(2) If C{x } ≡1 u, then u = C′{xα }, for some context C′ and explicit substitution α.

(By induction on C and case inspection).

(3) If t ≡1 t ′ and t

ι
−→ u, for some reduction step applied to the root of t, then there exists u ′ ≡ u such that t ′ ι

−→ u ′.
(11)
−−−→ t and t[x := v] ≡1 t[x := u], with v ≡1 u, one should

(By case inspection. Notice that in case t[x := v]

use (1) to assure that u is a value, in particular no explicit substitution has been lifted from inside v).

(4) If t ≡1 t ′ and t
(By 2 and 3).

ι
−→ u, then there exists u ′ ≡ u such that t ′

ι
−→ u ′.

The general statement then follows by induction on the length of a sequence t ≡1 · · · ≡1 t ′ giving t ≡ t ′, using (4)
(cid:3)

for the induction step.

Proposition 4.3 Let X be any subset of the reduction rules in Tab. 2 (including the variant (10)
X
−−→k u ′ ≡ u.
with k X -steps, then there exists u ′ such that t

n

) and let t (

X
−−→ ∪ ≡)∗ u

Proof. By induction on k, using Lemma 4.2.

(cid:3)

Proposition 4.4. Given a closed term t of type A, if t is a β-normal form, then it is a value.

Proof. By induction on a derivation ⊢ t : A. If the last rule is an → introduction, then t is a value. If it is an →
elimination, then t = u1u2 and ⊢ u1 : B → A or ⊢ u1 : R⊥ . By IH u1 is then a value, hence of the form λx.u ′ and
therefore u1u2 is a redex (8). If the last rule is a × introduction, we apply trivially the IH. If it is a × elimination, then
t = t ′[hx, yi := u] and ⊢ u : A × B. By IH u is a value, and hence it is of the form u = hv1, v2i, therefore t is a (9) redex.

29

The explicit substitution rule is similar to the previous one, using (10) or (11). If t = f (t1, . . . , tn ), then we have by IH
that each ti is a closed value, so a numeral, so we can apply the numerical rule associated with f . If t is a numeral,
(cid:3)
then it is a value. If t = t1 + t2, then by IH each ti is a value so we may apply either (14) or (13).

Proposition 4.5 For every term t, and every set X ⊆ βℓ, there exists a X -normal form u such that t

X
−−→∗ u.

Proof (Sketch). In case (10) < X , it is trivial to ﬁnd a notion of weight w(t) ∈ N such that t

X
−−→ t ′ implies w(t) >
w(t ′). Otherwise, let k be the greatest size of the type of a subterm of t, and let W (t) be the sequence (n1, . . . , nk , nk+1)
= w(t) and for every 1 ≤ i ≤ k, ni is the number of redexes of type (8), (9), (10) in t such that the term in
where nk+1
the explicit substitution has a type of size k + 1 −i (so that, as i grows bigger, ni accounts for smaller and smaller types).
X
−−→ t ′ for some t ′ such that W (t) > W (t ′) in the lexicographical
It is not hard to show that, if t is not X -normal, then t
(cid:3)

order.

Lemma 4.6 For any t

n
(10)
−−−−−−−−−−−−−→∗ u, the number of reduction steps in the sequence is O(|t |).

(11)(13)(15)

Proof. Let kt k be the number of symbols in t where each variable is counted twice. The claim then follows by
remarking that any rule (11), (13), (15) makes kt k strictly decrease, and the same for (10) whenever the substituted
(cid:3)

term is a numeral.

Table 4 recalls the denotational model induced by the cartesian closed structure of the category of sets and functions.

The proof of the soundness property is completely standard.

A.2 Proofs of Section 5

Lemma 5.2. Let G be a ground term whose free variables are given by a sequence x of length n. Then,

bpx, a(G)

= O(|G|).

(cid:12)
(cid:12)

(cid:12)
(cid:12)

Proof. We actually prove a slight stronger claim: let G be a ground term whose free variables are in a sequence x

of length n. Then,

bpx, a(G)
Notice that then whenever x contains exactly the free variables of G, n ≤ |G| and so O(n + |G|) = O(|G|).
(cid:12)
(cid:12)

By induction on the deﬁnition of bpx, a(G) = hG0, hG1, . . . , Gn i αi β, one proves that:

(cid:12)
(cid:12)

= O(n + |G|).

|G0β | = O(|G|);

(i)
(ii) for all 0 < i ≤ n, |Gi | = O(k(#xiG + 1)), with #xi G is the number of occurrences of xi in G;
(iii) for all 0 < i ≤ n, |Gi α | = O(|G|).

Notice that the items (i)-(iii) give that

n
i =1 |Gi | + |G0β | + |α | = O(#x1G + · · · + #xnG) + 2 |G|) = O(|G|)).
We detail only the case G = F [z := F ′], taking the notation of the deﬁnition of bp( ). Item (i) follows trivially from the
induction hypothesis. Item (ii) is a consequence of the induction hypothesis and the fact that #xi (G) = #xi (F ) + #xi (F ′).
Concerning item (iii), we have that:

+ 1 + |H | = O(|F | + |F ′|) = O(|G|).

bpx, a(G)
(cid:12)
(cid:12)

Í

=

(cid:12)
(cid:12)

= |Fiα | +

F ′
i α ′

i )α ′[b := H ]α
The factor k in (ii) is due to the case G = f (xi1 , . . . , xi ′

(Fi ⊕ F ′

(cid:3)

(cid:12)
(cid:12)

k

).
(cid:12)
(cid:12)
30

(cid:12)
(cid:12)

(cid:12)
(cid:12)

R

J
A × B
J
A → B
J

K

K

J

K

J

×

:= R
:=
B
A
:= set of functions from
K
B
K
:= set of linear maps from R to rRd
An
J

A1
J

× · · · ×

to

A

J

K

K

J

K
(a) interpretation of types

z

R⊥d
q
, . . . , x!An

K
y
n z :=

rx!A1

1

Γ ⊢ t : A
K

J

: function from

Γ

to

A

Γ ⊢z t : Rd

r

z : function from

Γ

to

R⊥d
q

y

J
K
Γ ⊢ x : A
Γ ⊢z z : R
J
K
Γ ⊢ f (t) : R
J
Γ ⊢ r : R
Γ ⊢ λx!A.t : A → Bz (g) := d 7→ r

J
K
(g) := дx
(g) := r 7→ r
(g) := f (
(g) := r

K

K

J

K

J

J

r

r

Γ

Γ

J

r

r

Γ ⊢ tu : B

Γ ⊢z tu : Rd

r
Γ ⊢z ht, ui : Rd × Rd ′

(g) :=
K
J
Γ ⊢ λzR.t : R⊥d
z (g) :=
r
z (g) := a 7→ r
(g) := a 7→ (r
z
Γ ⊢z t[x!A := u] : Rd
z (g) := a 7→ r
z (g) := a 7→ r
z (g) := a 7→ r
(g) := a 7→
(g) := a 7→ 0
J
K
z (g) := a 7→ r

2 := u] : Rd
:= u] : Rd
Γ ⊢z t · u : R
E
Γ ⊢z 0 : R
Γ ⊢z t + u : Rd

x!A, y!B
D

Γ ⊢z1 t[zR

r

J

J

K

r
Γ ⊢z t[

r

J

K

(g))

Γ ⊢ t : R

(g))

K

Γ, x!A ⊢ t : Bz (g, d)
(g)(

Γ ⊢ t : A → B

Γ ⊢ u : A
K

J

Γ ⊢z t : Rd

K
z (g)
Γ ⊢ t : Rd

z (g)(

Γ ⊢z u : R

(g)(a))

Γ ⊢z t : Rd

Γ, x!A ⊢ t : Rd

J
z (g)(a),
z (g,

K
Γ ⊢z u : Rd ′

r
Γ ⊢ u :: R

(g))(a)

z (g)(a))

Γ ⊢z2 t : Rd

z (g)(

J
Γ ⊢z2 u : R

K
(g)(a))

J
Γ, x!A, y!B ⊢z t : Rd
Γ ⊢z t : R

(g)(a) ·

z (g,
Γ ⊢ u : R

J

K

Γ ⊢ u : A × B

(g))(a)

K

K

J

(g)

K

Γ ⊢z t : Rd

z (g)(a) +

r

Γ ⊢z u : Rd

z (g)(a)

(27)

(28)

(29)

(30)

(31)

(32)

(33)

(34)

(35)

(36)

(37)

(38)

(39)

(40)

(41)

(b) interpretation of terms. In the cases admitting two version (with or without linear variables), we considered only the case with
linear variables, the other being simpler. The reader may check that the linearity (i.e. commutation with sums and scalar products)
of the parameter a associated with a linear variable is respected.

Table 4. The denotational model induced by the category of sets and functions.

Notice that the above lemma would fail if we replace the meta-operator ⊕ with the sum constructor + in the deﬁni-
tion of bpx, a(G). In that case we would have the size of bpx, a(x1+· · ·+xn ) to be quadratic in n because bpx, a(x1+· · ·+xn )
copies the n − 1 sums for every component of the gradient tuple.

31

Proposition 5.3. Let G be a ground term whose free variables are given by a sequence x of length n. Then for every r ∈ Rn,
we have:

bpx, a(G)[a := 1][x := r]

n

(11)(13)(15)

(10)
−−−−−−−−−−−−−→O (|G |)≡

G

(r), ∇G(r)

.

DJ

K

E

Proof. By induction on G we prove that, if bpx, a(G) = hG0, hG1, . . . , Gn i αi β, then, for every vector of real num-

bers r, we have:

(i) G0β[x := r]

n
(10)
(11)(13)(15)
−−−−−−−−−−−−−→∗≡

G

(r);

(ii) for all 1 ≤ i ≤ n, for all real number q, Gi α β[a := q][x := r]

J

K

From (i) and (ii) then follows:

bpx, a(G)[a := 1][x := r ] ≡

n
(10)
(11)(13)(15)
−−−−−−−−−−−−−→∗≡ ∂xi

G

(r) · q;

J

K

G0β[x := r],

G1α β[a := 1][x := r], . . . , Gnα β[a := 1][x := r]

n
(10)
(11)(13)(15)
−−−−−−−−−−−−−→∗≡

G

(r), ∇G(r)

.

(cid:10)

(cid:10)

Proposition 4.3 allows to postpone all structural equivalences at the end. From Lemma 4.6 and the fact that
O(|G|) (Lemma 5.2) the length of the reduction is O(|G|)

(cid:11)(cid:11)

DJ

K

The non-trivial case for (i) and (ii) is G = F ′[z := F ′′]. Using the notations from the deﬁnition:

G0β[x := r] = F ′
≡ F ′

0 ]β ′′[x := r]

0β ′[z := F ′′
0β ′[x := r][z := F ′′
n
(10)
(11)(13)(15)
−−−−−−−−−−−−−→∗ F ′

0 β ′′[x := r]]

0β ′[x := r][z :=

F ′′

(r)]

n
(10)
(11)(13)(15)
−−−−−−−−−−−−−→∗

F ′

(r,

F ′′

J
(r)) =

K
G

(r)

by IH

by IH

E
bpx, a(G)

=

(cid:12)
(cid:12)

(cid:12)
(cid:12)

K
As for (ii), we have that the i-th component of the gradient tuple of bpx, a(G) together with the associated substitu-

J

K

J

J

K

tions is equal to (we suppose F ′

= F ′
i

+ F ′′

i , the other cases being simpler):

0 ]β ′′[a := q][x := r]

i )α ′′[b := H ]α ′β ′β ′′[a := q][x := r][z := F ′′

0 β ′′[x := r]]

i )α ′′[b := H ]α ′β ′β ′′[a := q][x := r][z :=
F ′′

F ′′
(r)][b := Hα ′β ′β ′′[a := q][x := r][z :=

(r)]

K

J

i )α ′′α ′β ′β ′′[a := q][x := r][z :=

F ′′

(r)]]

K

J
i )α ′′α ′β ′β ′′[a := q][x := r][z :=
J
F ′

i α ′′β ′′[b := ∂z

(r)] + F ′′

F ′′

F ′′

(r)][b := ∂z
(r) · q][x := r]

K

J
(r) · q]

K

F ′

J

K

by (i)

by IH

by IH

+ F ′′

+ F ′′

i ⊕ F ′′
i
i )α ′′[b := H ]α ′β ′[z := F ′′
+ F ′′

(F ′
i
≡ (F ′
i
n
(10)
(11)(13)(15)
−−−−−−−−−−−−−→∗ (F ′
i
+ F ′′
≡ (F ′
i
n
(10)
−−−−−−−−−−−−−→O (|F |) (F ′
i
≡ F ′

+ F ′′
i α ′β ′[a := q][x := r][z :=
n
(10)
(11)(13)(15)
−−−−−−−−−−−−−→∗ ∂xi
(13)
−−−→ ∂xi
=

J
K
(r) · q + ∂xi

(11)(13)(15)

F ′′

F ′

F ′

K
(r) + ∂z

J
K
(r) · ∂xi

∂xi

J
F ′

F ′

J

K

(cid:0)

J

K

J
K
(r) · q + ∂xi

F ′′

(r) ·

∂z

F ′

K

J
(r) · q

J
∂z

K
F ′

(cid:0)
(r) · q

J

K

(r) ·

(cid:1)

F ′′
(cid:0)
J

K

J
(r)

K
· q = ∂xi
(cid:1)

G

(r) · q

(cid:1)

J

K
32

Notice that in order to move to the last line we use the associativity, commutativity and distributivity of + and · over
real numbers, not on the corresponding syntactic symbols.

Let us consider also the case G = hF ′, F ′′i. Using the notations from the deﬁnition:

G0β[x := r] =

β ′β ′′[x := r]

≡

F ′
0, F ′′
0
0β ′[x := r], F ′′
F ′
(cid:11)
n
(10)
(11)(13)(15)
(cid:10)
−−−−−−−−−−−−−→∗ ≡

(cid:10)

0 β ′′[x := r]

F ′

(r),

(cid:11)
F ′′

(r)

by IH

The case (ii) is similar (just a sum instead of a pair).

J

K

=

G

(r)

DJ

K

J

K

E

In the base cases (variables, functional symbols and numerals), one performs linear substitutions (10) as well as
(cid:3)

garbage collection (11). In the case of bpx, a(f (xi1, . . . , xik )) one instance of the rule (15) is needed.
←−
D (t)

Lemma A.1. Let t be a term of Λ(F ). We have:

= O(|t |).

Proof. By just inspecting the deﬁnition in Table 3.

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

Lemma 5.4. Let t be a term of Λ(F ). Then:

(cid:3)

←−
(1) if t ≡ t ′, then
D (t ′),
ι
−→ t ′, for ι any reduction step in Tab. 2, then

←−
D (t) ≡

(2) if t

←−
D (t)

X

−−→O (1) ←−

D (t ′), where X = {ι} for any ι but (13), (15), in

these latter cases X = {ι, (8), (10), (11)}.

Proof. Item 1 is immediate by case inspection. Concerning item 2, one proves by induction on t that:

(•) for every term u of Λ(F ),

D (t {u/x }) = ←−
←−

D (t)

←−
D (u)/x

.

ι
−→ t ′, notice that ι , (18) since t has no R⊥ -variable. If ι = (10), then the statement follows from (•).
Then, suppose t
All other cases are immediate. We detail just the case of an instance of a numerical rule (13), (15), e.g. r + q −→ r + q.

o

n

We have that

←−
D (r + q) is:

x + y, λa.(x ′a + y′a)

[

x, x ′

:=

r, λa.0

][

y, y′

:=

q, λa.0

]

(cid:10)

(cid:11)

(cid:10)

(cid:11)

(cid:10)

(cid:11)

(cid:10)

(cid:11)

D

E

(8)(10)(11)
−−−−−−−−→O (1)

r + q, λa.(0 + 0)
D

E

(13)
−−−→2

r + q, λa.0
D

E (cid:3)

Lemma 5.5. Let G be a ground term of type x!R ⊢ G : R with x = x!R
1
hG0, hG1, . . . , Gn i αi β. For a suitable J ⊆ {1, . . . , n}, such that if i < J , then Gi = 0, we have:

, . . . , x!R

n the free variables of G and let bpx, a(G) =

←−
D (G)[x!

←−
D (R) :=

x!R, λaR.x′!R⊥

a

] −→O (|G |)≡

D

E

G0, λa.(
*

Õj ∈J

x ′
jGj )α

β .

+

Proof. By induction on G. We will freely use structural equivalence where necessary, knowing that Proposition 4.3

allows us to postpone all structural equivalences to the end without aﬀecting the number of reduction steps. The non-
trivial cases are detailed below. Remark that the length of each reduction is O(
) which is equal to O(|G|) by

←−
D (G)

Lemma A.1.

33

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

Let G = F [z := F ′] and suppose that

bpx,z, a(F ) = hF0, hF1, . . . , Fn, H i αi β,
←−
D (G)[x := hx, λa.x′ai] is structural equivalent to :

We have that

bpx,b (F ′) =

F ′
0,

1, . . . , F ′
F ′
n

α ′

β ′.

(cid:10)

(cid:10)

(cid:11)

(cid:11)

←−
D (F )[x :=

(

x, λa.x′a

])[z := (

←−
D (F ′)[x :=

x, λb.x′b

])]

j F ′
x ′

j )α ′

β ′]

+

by IH

(cid:10)
F ′
0, λb.(

(cid:11)

*

Õj ∈J ′
j )α ′

j F ′
x ′

]β ′

+

(cid:11)

*

F ′
0, λb.(

(cid:10)
(cid:11)
←−
−→O (|F ′ |)≡ (
D (F )[x :=

x, λa.x′a

])[z :=

←−
D (F )[x :=

≡ (

(cid:10)
x, λa.x′a

])[z :=

(17)
−−−→

(9)
−−→ (

(cid:10)
←−
D (F )[x :=

(cid:11)

x, λa.x′a

][z :=

Õj ∈J ′
z, z ′

(16)
−−−→ (

←−
D (F )[x :=

(cid:10)
x, λa.x′a

(cid:11)
][z :=

(cid:10)
(cid:11)
z, λa.z ′a

])[z := F ′

0][z ′ := λb.(

j F ′
x ′

j )α ′]β ′

Õj ∈J ′

])[z := F ′

0][z ′ := λb.(

j F ′
x ′

j )α ′]β ′

Õj ∈J ′

Now we can apply the induction hypothesis on

z ′ appears in the tuple associated with

←−
D (F ) and we split in two sub-cases, depending whether the variable

←−
D (F ) or not. In the ﬁrst case, we have that the above term reduces by IH to:

(cid:10)

(cid:11)

(cid:10)

(cid:11)

−→O (|F |)≡

(10)
−−−→

(11)
−−−→

F0, λa.(

*

Õj ∈J

F0, λa.(

*

Õj ∈J

j Fj + z ′H )α
x ′

+

β[z := F ′

0][z ′ := λb.(

j F ′
x ′

j )α ′]β ′

Õj ∈J ′

by IH

x ′
j Fj + (λb.(

Õj ∈J ′

j F ′
x ′

j )α ′)H )α

+

β[z := F ′

0]β ′

(8)
−−→

*

F0, λa.(

x ′
j Fj + (

Õj ∈J

Õj ∈J ′

j F ′
x ′

j )α ′[b := H ])α

β[z := F ′

0]β ′

+

(18)
−−−→#J ∩#J ′

F0, λa.(

*

Õj ∈J ∪J ′

j (Fj ⊕ F ′
x ′

j ))α ′[b := H ]α

β[z := F ′

0]β ′

+

Notice that the above instance of (10) replaces exactly one occurrence of z ′. The last term satisﬁes the statement of
the lemma.

In the case the variable z ′ does not appear in the tuple associated with

←−
D (F ), this means that H = 0. We then have:

βηℓ
−−−→O (|F |)≡

F0, λa.(

*

Õj ∈J

x ′
j Fj )α

+

β[z := F ′

0][z ′ := λb.(

j F ′
x ′

j )α ′]β ′

Õj ∈J ′

F0, λa.(

−→

*

Õj ∈J

x ′
j Fj )α

+

β[z := F ′

0]β ′

The last term satisﬁes the statement of the lemma.

by IH

by (11)

34

Let G = f (xi1, . . . , xik ) for a suitable subset xi1 , . . . , xik ⊆ x. In this case we have:

←−
D (G)[x :=

x, λa.x′a

] =

f (y) , λa.

(cid:10)

(cid:11)

*

k

Õj=1

(cid:0)

(9)(10)
−−−−−→O (n)

f (y) , λa.

*

≡

f (y) , λa.

*

Let G = F + F ′ and suppose that

y′
j

∂j f (y) · a

[

y, y′

:= x][x :=

x, λa.x′a

]

+

(cid:1)

(cid:10)

(cid:11)

k

Õj=1

y′
j

∂j f (y) · a

(cid:0)

+

(cid:1)

(cid:10)
[y := x][y′ := λa.x′a]

(cid:11)

[y := x][y := x][y′ := λa.x′a]

k

y′
j

∂j f (y) · a

+

Õj=1
(cid:0)
−−−−−→O (k) (11)
(8)(10)

(cid:1)
−−−→O (n)

f (xi1, . . . , xik ) , λa.

*

x ′
i j

k

Õj=1

(cid:0)

∂j f (xi1, . . . , xik ) · a

+

(cid:1)

bpx, a(F ) = hF0, hF1, . . . , Fni αi β,

bpx, a(F ′) =

F ′
0,

1, . . . , F ′
F ′
n

α ′

β ′.

We have that

←−
D (G)[x := hx, λa.x′ai] is equal to:
:= ←−

1a + y′

y1, y′
1

2a)

[

D (F )][

(cid:10)

(cid:10)

(cid:11)

(cid:11)

y2, y′
2

:= ←−

D (F ′)][x :=

x, λa.x′a

]

y1 + y2, λa.(y′
βηℓ
(cid:10)
−−−→O (|G |)≡

F0 + F ′

(cid:11)
(cid:10)
0, λa.(y′

(cid:11)
1a + y′

2a)

[y′

(cid:10)
1 := λa.(

(cid:11)

j Fj )α]β[y′
x ′

(cid:10)
2 := λa.(

(cid:11)
x ′
j′ F ′

j′)α ′]β ′

by IH

Õj′ ∈J ′

(cid:10)
(10)(8)(11)
−−−−−−−−→O (1)

F0 + F ′

0, λa.((

*

Õj ∈J

(cid:11)
x ′
j Fj )α + (

Õj′ ∈J ′

Õj ∈J
j′ F ′
x ′

j′ )α ′)

β β ′

+

≡

*

F0 + F ′

0, λa.((

x ′
j Fj ) + (

Õj ∈J

j′ F ′
x ′

j′ ))αα ′

β β ′

+

Õj′ ∈J ′

(18)
−−−→#J ∩#J ′

F0 + F ′

0, λa.(

*

j Fj ⊕ F ′
x ′

j′)αα ′

β β ′

+

Õj ∈J ∪J ′

Notice that all the above instances of (10) replaces exactly one occurrence of a variable. The last term satisﬁes the
(cid:3)

statement of the lemma.

Theorem 5.6. Let t be a term of Λ(F ) of type x!R ⊢ t : R, with x = x!R
1

, . . . , x!R

n the free variables of t. For any ground

term G such that t (

β
−→ ∪ ≡)∗ G in m β-steps, we have, for a suitable J ⊆ {1, . . . , n}:

←−
D (t)[x :=

x, λa.x′a

] −→O (m+ |G |) ≡

where bpx, a(G) = hG0, hG1, . . . , Gn i αi β and ∀i < J , Gi = 0.

(cid:10)

(cid:11)

G0, λa.(
*

Õj ∈J

x ′
jGj )α

β

+

Proof. Let us suppose t (

β
−→ ∪ ≡)∗ G in m steps. By Lemma 5.4, we have that:

←−
D (t)[x :=

x, λa.x′a

] (

β

−→ ∪ ≡)∗ ←−

D (G)[x :=

(cid:10)

(cid:11)

35

x, λa.x′a

]

(cid:10)

(cid:11)

in O(m) steps. By Lemma 5.5, we have that:

←−
D (G)[x :=

x, λa.x′a

] −→O (|G |))≡

(cid:10)

(cid:11)

G0, λa.(
*

Õj ∈J

x ′
jGj )α

β

+

this latter term satisfying the statement of the theorem. We compose the reductions and apply Proposition 4.3 to
(cid:3)

conclude.

Corollary 5.7. Let t be a term of Λ(F ) of type x!R ⊢ t : R, with x = x!R
1
number of β-steps needed to reduce t to a ground term G. For any vector r ∈ Rn , let ∇t(r) =
suitable J ⊆ {1, . . . , n}, with i < J , дi = 0, we have:

n the free variables of t. Let m be the
д1, . . . , дn
. Then, for a
D

, . . . , x!R

E

z ′1[

z, z ′

:= ←−

D (t)[x :=

x, λa.x′a

]][x := r] −→O (m+ |G |) ≡

(cid:10)

(cid:11)

(cid:10)

(cid:11)

x ′
jдj .

Õj ∈J

Proof. Apply Theorem 5.6 to

←−
D (t)[x := hx, λa.x′ai] and then Proposition 5.3.

A.3 Proofs of Section 6

Lemma A.2. Let r ∈ R and u,u ′ ∈ Λ(F ).

←−
D (L)

←−
D (r ) hu, u ′i reduces to

σ (z1.r + z2.u), λa.(z ′

1(r .σ ′.a) + z ′

2(u.σ ′.a) + u ′(z2.σ ′.a))

where σ ′ = ∂1σ (z1.r + z2.u).

(cid:10)

Proof. The proof follows from the following observations:

[

z1, z ′
1

:= ϵ][

z2, z ′
2

:= ρ]

(cid:11)

(cid:10)

(cid:11)

(cid:10)

(cid:11)

←−
D (ϵ.x) =
←−
D (ρ.h) =

z1.e, λa(z ′

z2.e, λa(z ′
(cid:10)

←−
D (ϵ.x + ρ.h) =
←−
D (L) = λx.λh.
(cid:10)

γ1 + γ2, λa.(γ ′
(cid:10)

:= ϵ][

e, e ′

:= x]

e, e ′
(cid:11)

:= h]

[

[

z1, z ′
1
z2, z ′
(cid:10)
2

1(e.a) + e ′(z1.a))
2(e.a) + e ′(z2.a))
1a + γ ′
σ (µ), λa.µ ′(∂1σ (µ).a)

2a)

(cid:11)

(cid:10)

(cid:11)

[

γ1,γ ′
(cid:11)
(cid:10)
1

:= ρ][
(cid:10)

(cid:11)
:= ←−
(cid:10)
(cid:11)
D (ϵ.x)][
:= ←−
µ, µ ′
(cid:11)

[

D (ϵ.x + ρ.h)]

(cid:10)

(cid:11)

γ2, γ ′
(cid:11)
2

:= ←−

D (ρ.h)]

(cid:10)

(cid:11)

(cid:10)

(cid:11)

Lemma A.3. Let a1, . . . , an : R, e, r ∈ R and 1 ≤ i ≤ n. We pose

α = [ϵ :=
l0 := []

e, λa.ϵ ′a

][ρ :=

r, λρ′a

]

(cid:10)

(cid:11)

(cid:10)

(cid:11)

li +1 := [an−i, . . . , an]

Then

←−
D (N li )α reduces to

ui , u ′
i

where:

u0, u ′
(cid:10)
0

=

(cid:11)

0, λa.0

ui +1, u ′
(cid:10)

i +1

(cid:11)

=

with σ ′

i +1

= ∂1σ (e.ai +1 + r .ui ).

(cid:10)

(cid:11)

(cid:11)

σ (e.ai +1 + r .ui ), λa.(ϵ ′(ai +1.σ ′
(cid:10)
D

i +1.a) + ρ′(ui .σ ′

i +1.a) + u ′

i (r .σ ′

i +1.a))

E

36

(cid:3)

(cid:3)

Proof. We have:

D (N [an−i ; . . . ; an]) −→∗ ←−
←−

D (L)

←−
D (an−i )(

←−
D (L)

←−
D (an−i +1)(. . . (

←−
D (L)

←−
D (an)

0, λa.0

) . . . ))

Then the result follows by applying recursively Lemma A.2.

(cid:10)

(cid:11)

(cid:3)

Proposition 6.1. We have ∇(N l)(e,r ) =

ϵ and дn

ρ are given by the following recurrent equations:

σ ′
i +1 := ∂1σ (e.ai +1 + r .ui )

= 0

д0
ϵ
д0
ρ
u0 = 0

= 0

E

where дn

ϵ , дn
дn
ρ
D
дi +1
i +1.(ai +1 + r .дi
ϵ )
ϵ
дi +1
i +1.(ui +1 + r .дi
ρ )
ρ
ui +1 = σ (e.ai +1 + r .ui )

= σ ′
= σ ′

Proof. By Corollary 5.7, this amounts to computing D = ϵ ′.дϵ + ρ′.дρ such that

z ′1[

z, z ′

:= ←−

D (N l)[ϵ :=

ϵ, λa.ϵ ′a

][ρ :=

ρ, λa.ρ′a

]][ϵ := e][ρ := r ] −→∗ D

We get the result by direct application of Lemma A.3.

(cid:10)

(cid:11)

(cid:10)

(cid:11)

(cid:10)

(cid:11)

(cid:3)

37

