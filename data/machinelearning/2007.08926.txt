1
2
0
2

g
u
A
7
1

]

O
L
.
s
c
[

6
v
6
2
9
8
0
.
7
0
0
2
:
v
i
X
r
a

Smart Choices and the Selection Monad

Mart´ın Abadi and Gordon Plotkin
Google Research

Abstract

Describing systems in terms of choices and their resulting costs and rewards oﬀers
the promise of freeing algorithm designers and programmers from specifying how those
choices should be made; in implementations, the choices can be realized by optimization
techniques and, increasingly, by machine-learning methods. We study this approach
from a programming-language perspective. We deﬁne two small languages that support
decision-making abstractions: one with choices and rewards, and the other additionally
with probabilities. We give both operational and denotational semantics.

In the case of the second language we consider three denotational semantics, with
varying degrees of correlation between possible program values and expected rewards.
The operational semantics combine the usual semantics of standard constructs with
optimization over spaces of possible execution strategies. The denotational semantics,
which are compositional, rely on the selection monad, to handle choice, augmented
with an auxiliary monad to handle other eﬀects, such as rewards or probability.

We establish adequacy theorems that the two semantics coincide in all cases. We
also prove full abstraction at base types, with varying notions of observation in the
probabilistic case corresponding to the various degrees of correlation. We present
axioms for choice combined with rewards and probability, establishing completeness at
base types for the case of rewards without probability.

Contents

1 Introduction

2 The selection monad and algebraic operations

2.1 The selection monad . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . .
2.2 Generic eﬀects and algebraic operations

3 A general language with algebraic operations

3.1 Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Operational semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3 Denotational semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4 Adequacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.5 Program equivalences and purity . . . . . . . . . . . . . . . . . . . . . . . .

1

2

6
7
10

22
22
23
27
29
30

 
 
 
 
 
 
4 A language of choices and rewards

4.1 Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . .
4.2 Rewards and additional eﬀects
4.3 Operational semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.4 Denotational semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.5 Adequacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.6 Full abstraction, program equivalences, and purity . . . . . . . . . . . . . .

5 Adding probabilities

5.1 Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . .
5.2 Rewards and additional eﬀects
5.3 Operational semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.4 Denotational semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.5 Adequacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.6 Full abstraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.7 Program equivalences and purity . . . . . . . . . . . . . . . . . . . . . . . .

6 Conclusion

Acknowledgements

1

Introduction

31
31
32
32
37
37
39

47
47
48
50
54
60
63
68

74

76

Models and techniques for decision-making, such as Markov Decision Processes (MDPs)
and Reinforcement Learning (RL), enable the description of systems in terms of choices
and of the resulting costs and rewards. For example, an agent that plays a board game may
be deﬁned by its choices in moving pieces and by how many points these yield in the game.
An implementation of such a system may aim to make the choices following a strategy
that results in attractive costs and rewards, perhaps the best ones. For this purpose it
may rely on classic optimization techniques or, increasingly, on forms of machine-learning
(ML). Deep RL has been particularly prominent in the last decade, but contextual bandits
and ordinary supervised learning can also be useful.

In a programming context, several languages and libraries support choices, rewards,
costs, and related notions in a general way (not speciﬁc to any application, such as a
particular board game). McCarthy’s amb operator [43] may be seen as an early exam-
ple of a construct for making choices. More recent work includes many libraries for RL
(e.g., [10]), languages for planning such as DTGolog [8] and some descendants (e.g., [49]) of
the Planning Domain Deﬁnition Language [44], a “credit-assignment” compiler for learn-
ing to search built on the Vowpal-Rabbit learning library [13], and Dyna [53], a pro-
It also includes
gramming language for machine-learning applications based on MDPs.
SmartChoices [12], an “approach to making machine-learning (ML) a ﬁrst class citizen in

2

programming languages”, one of the main inspirations for our work. SmartChoices and
several other recent industry projects in this space (such as Spiral [11]) extend mainstream
programming languages and systems with the ability to make data-driven decisions by
coding in terms of choices (or predictions) and feedback (in other words, perceived costs
or rewards), and thus aim to have widespread impact on programming practice.

The use of decision-making abstractions has the potential to free algorithm designers
and programmers from taking care of many details. For example, in an ordinary program-
ming system, a programmer that implements quicksort should consider how to pick pivot
elements and when to fall back to a simpler sorting algorithm for short inputs. Heuristic
solutions to such questions abound, but they are not always optimal, and they require
coding and sometimes maintenance when the characteristics of the input data or the im-
plementation platform change. In contrast, SmartChoices enables the programmer to code
in terms of choices and costs—or, equivalently, rewards, which we deﬁne as the opposite of
costs—, and to let the implementation of decision-making take care of the details [12, Sec-
tion 4.3]. As another example, consider the program in Figure 1 that does binary search in
a sorted array. This pseudocode is a simpliﬁed version of the one in [12, Section 4.2], which

let binsearch(x : Int, a : Array[Int], l : Int, r : Int) =

if l > r then None //the special value None represents failure

else choose m:[l,r] in //choose an integer in [l,r]

if a[m] = x then m
else cost(1); //pay to recurse

if a[m] < x then binsearch(x, a, m+1, r)
else binsearch(x, a, l, m-1)

Figure 1: Smart binary search

also includes a way of recording observations of the context of choices (in this example, x,
a[l], and a[r]) that facilitate machine-learning. Here, a choice determines the index m
where the array is split. Behind the scenes, a clever implementation can take into account
the distribution of the data in order to decide exactly how to select m. For example, if x
is half way between a[l] and a[r] but the distribution of the values in the array favors
smaller values, then the selected m may be closer to r than to l. In order to inform the
implementation, the programmer calls cost: each call to cost adds to the total cost of
an execution, for the notion of cost that the programmer would wish to minimize. In this
example, the total cost is the number of recursive calls. In other examples, the total cost
could correspond, for instance, to memory requirements or to some application-speciﬁc
metric such as the number of points in a game.

In this paper, we study decision-making abstractions from a programming-language
perspective. We deﬁne two small languages that support such abstractions, one with
In the spirit of
choices and rewards, and the other one additionally with probabilities.

3

SmartChoices (and in contrast with DTGolog and Dyna, for instance), the languages are
mostly mainstream: only the decision-making abstractions are special. We give them both
In the case of the language with probabilities
operational and denotational semantics.
we provide three denotational semantics, modeling varying degrees of correlation between
possible program values and expected rewards.

Their operational semantics combine the usual semantics of standard constructs with
optimization over possible strategies (thinking of programs as providing one-person games).
Despite the global character of optimization, our results include a tractable, more local for-
mulation of their operational semantics (Theorems 5 and 10). Their denotational semantics
are based on the selection monad [21, 23, 19, 22, 18, 29, 20, 6], which we explain below.

We establish that operational and denotational semantics coincide, proving adequacy
results for both languages (Theorems 6 and 11). We also investigate questions of full
abstraction (at base types) and program equivalences. Our full abstraction results (partic-
ularly Theorems 7 and 12, and Corollary 4) provide further evidence of the match between
denotational and operational semantics. We prove full abstraction results at base types
for each of our denotational semantics, in each case with respect to appropriate notions of
observation. Program equivalences can justify program transformations, and we develop
proof systems for them. For example, one of our axioms concerns the commutation of
choices and rewards. In particular, in the case of the language for rewards we establish
(Theorem 7) the soundness and completeness of our proof system with respect to concepts
of observational equivalence and semantic equivalence (at base types). In the case of the
language with probabilities, ﬁnding such completeness results is an open problem. How-
ever, we show that our proof systems are complete with respect to proving eﬀect-freeness.
For the language without probabilities this holds in all circumstances (Corollary 2); for the
language with probability it holds under reasonable assumptions (Theorem 14).

A brief, informal discussion of the semantics of binsearch may provide some intuition

on the two semantics and on the role of the selection monad.

• If we are given the sequence of values picked by the choice construct in an execu-
tion of binsearch, a standard operational semantics straightforwardly allows us to
construct the rest of the execution. We call this semantics the ordinary operational
semantics. For each such sequence of values, the ordinary operational semantics
implies a resulting total cost, and thus a resulting total reward. We deﬁne the selec-
tion operational semantics by requiring that the sequence of values be the one that
maximizes this total reward.

Although they are rather elementary, these operational semantics are not always a
convenient basis for reasoning, because (as usual for operational semantics) they are
not compositional, and in addition the selection operational semantics is deﬁned in
terms of sequences of choices and accumulated rewards in multiple executions. On
the other hand, the chosen values are simply plain integers.

• In contrast, in the denotational semantics, we look at each choice of binsearch as

4

being made locally, without implicit reference to the rest of the execution or other
executions, by a higher-order function of type (Int → R) → Int (where Int is a
ﬁnite set of machine integers), whose expected argument is a reward function f that
maps each possible value of the choice to the corresponding reward of type R of the
rest of the program. We may view f as a reward continuation. One possible such
higher-order function is the function argmax that picks a value for the argument x
for f that yields the largest reward f (x). (There are diﬀerent versions of argmax,
in particular with diﬀerent ways of breaking ties, but informally one often identiﬁes
them all.)

The type (Int → R) → Int of this example is a simple instance of the selection
monad, S(X) = (X → R) → X, where X is any type, and argmax is an example
of a selection function. More generally, we use S(X) = (X → R) → T(X), where
T is another, auxiliary, monad, which can be used to model other computational
eﬀects, for example, as we do here, rewards and probabilities. For our language with
rewards, we employ the writer monad T(X) = R × X. For our language with rewards
and probabilities we employ three auxiliary monads modeling the various correlations
between ﬁnal values and rewards. Of these, the simplest is T(X) = Df (R × X), the
combination of the ﬁnite probability distribution monad with the writer monad.

The monadic approach leads to a denotational semantics that is entirely composi-
tional, and therefore facilitates proofs of program equivalences of the kind mentioned
above. The denotational semantics may be viewed as an implementation by transla-
tion to a language in which there are no primitives for decision-making, and instead
one may program with selection functions.

Sections 2 and 3 concern supporting theory for our two decision-making languages.
In Section 2, we review the selection monad, with and without an auxiliary monad, and
investigate its algebraic operations. We show how algebraic operations for the selection
monad augmented with an auxiliary monad can be obtained from algebraic operations of
the auxiliary monad (Equation 8); we give a general notion of selection algebraic opera-
tions and characterize such operations in terms of generic eﬀects for the selection monad
S(X) (Theorem 1); and we investigate the equations obeyed by binary selection operations
(Theorems 2 and 3). In Section 3, we present a general language with algebraic operations,
give a general adequacy theorem (Theorem 4), and brieﬂy discuss a calculus for program
equivalences. This section is an adaptation of prior work (see [46]). While useful for our
project, it is not speciﬁc to it.

In Section 4, we deﬁne and study our ﬁrst language with decision-making abstractions;
it is a simply typed, higher-order λ-calculus, extended with a binary choice operation
− or − and a construct for adding rewards. Full abstraction for this language is deﬁned in
terms of observing both ﬁnal values and the corresponding rewards obtained. Theorem 9
in contrast
shows that this notion does not change if we observe only the ﬁnal value;
Corollary 3 shows that it does change if we observe only the ﬁnal reward: in that case we

5

cannot distinguish programs with diﬀerent ﬁnal values but the same optimal ﬁnal reward.
In Section 5, we proceed to our second language, which adds a probabilistic choice
operator to the ﬁrst. Regarding full abstraction, Theorem 13 (an analogue of Theorem 9)
shows that this notion does not change from that associated to the third of our semantics
for probability and rewards if we observe only the distribution of ﬁnal values. Probabilis-
tic choices are not subject to optimization, but in combination with binary choice, they
enable us to imitate the choice capabilities of MDPs. Unlike MDPs, the language does not
support inﬁnite computations. We conjecture they can be treated via a metric approach
to semantics; at any rate, there is no diﬃculty in adding a primitive recursion operator to
the language, permitting MDP runs of arbitrary prescribed lengths, and making no change
to the selection monads employed.

In sum, we regard the main contributions of this paper as being (1): the connection be-
tween programming languages with decision-making abstractions and the selection monad,
and (2): the deﬁnition and study of operational and denotational semantics for those lan-
guages, and the establishment of adequacy and full abstraction theorems for them. The
adequacy theorems show that global operationally-deﬁned optimizations can be character-
ized compositionally using a semantics based on the selection monad.

As described above, the selection operational semantics and the denotational semantics
with the argmax selection function both rely on maximizing rewards.
In many cases,
optimal solutions are expensive. Even in the case of binsearch, an optimal solution that
immediately picks m such that a[m] equals x (without ever recursing) seems unrealistic.
For eﬃciency, the optimization may be approximate and data-driven.
In particular, as
an alternative to the use of maximization in the selection operational semantics, we may
sometimes be able to make the choices with contextual-bandit techniques, as in [12, Section
4.2]. In the denotational semantics, assuming that R is the type of real numbers, we may
use other selection functions instead of argmax. (The use of argmax is convenient, but
our approach does not require it.) For example, instead of computing argmax(f ), we may
approximate f by a diﬀerentiable function over the real numbers, represented by a neural
network with learned parameters, and then ﬁnd a local maximum of this approximation by
gradient ascent. We have explored such approximations only informally so far; Section 6
brieﬂy mentions aspects of this and other subjects for further work. This paper is a full
version of [1].

2 The selection monad and algebraic operations

In this section we present material on the basic selection monad, on the selection monad
augmented with an auxiliary monad, and on generic eﬀects and algebraic operations for
general monads. This material includes a discussion of generic eﬀects and algebraic oper-
ations for the selection monad (whether basic or augmented) and of the equations these
operations satisfy. Such algebraic operations are either so-called selection operations aris-

6

ing from the basic selection monad or operations arising from the auxiliary monads and
then lifted to the augmented selection monad. For a ﬁrst reading, it suﬃces to read the def-
initions of the selection monads and of generic eﬀects and algebraic operations for general
monads. (We repeat the deﬁnitions of the speciﬁc generic eﬀects and algebraic operations
for our two languages when discussing their denotational semantics in Sections 4.4 and 5.4.)

2.1 The selection monad

The selection monad

S(X) = (X → R) → X

introduced in [21], is a strong monad available in any cartesian closed category, for simplic-
ity discussed here only in the category of sets. One can think of the F ∈ S(X) as selection
functions which, viewing R as a reward type, choose an element x ∈ X, given a reward
function γ : X → R. In a typical example, the choice x optimizes, perhaps maximizing,
the reward γ(x). Computationally, we may understand F ∈ S(X) as producing x given a
reward continuation γ, a function giving the reward of the remainder of the computation.
The selection monad has strong connections to logic, similar to those of the continu-
ation monad K(X) = (X → R) → R. For example, as explained in [22], whereas logic
translations using K, taking R to be ⊥, verify the double-negation law ¬¬P ⊃ P , transla-
tions using S verify the instance ((P ⊃ R) ⊃ P ) ⊃ P of Peirce’s law. Again, with R the
truth values, elements of K(X) correspond to quantiﬁers, and elements of S(X) correspond
to selection operators, such as Hilbert’s ε-operator.

The selection monad has unit (ηS)X : X → S(X), where ηS(x) = λγ ∈ X → R. x.
(Here, and below, we may drop suﬃces when they are evident from the context.) The
Kleisli extension is a little involved, so we explain it in stages. First, for any F ∈ S(X)
and reward continuation γ : Y → R we write R(F |γ) for the reward given by the (possibly
optimal) x ∈ X chosen by F , i.e.:

R(F |γ) =def γ(F γ)

For the Kleisli extension, given f : X → S(Y ) we need a function f †S : S(X) → S(Y ).
Equivalently, using f , we need to pick an element of Y , given a computation F ∈ S(X)
and a reward continuation γ : Y → R. We do so as follows:

• For a given x ∈ X, the reward associated to the possibly optimal element of Y picked

by f (x) is R(f (x)|γ).

• Thus we have a reward function from X, viz. rew = λx ∈ X. R(f (x)|γ).

• Using this reward function as the reward continuation of F , we can use F to choose

the (possibly optimal) element of X for it, viz. opt = F (rew ).

7

• Now that we know the best choice of x, we use it to get the desired element of Y ,

viz. f (opt )(γ).

Intuitively, F chooses the x ∈ X which gives the optimal y ∈ Y , and then f uses that x.

Writing all this out, we ﬁnd:

f †SF γ = f (opt)(γ)

= f (F (r ew))(γ)
= f F (λx ∈ X. R(f (x)|γ)))γ

The selection monad has strength (stS)X,Y : X × S(Y ) → S(X × Y ) where:

(stS)X,Y (x, F ) = λγ ∈ X × Y → R. hx, F (λy ∈ Y. γ(x, y))i

There is a generalization of this basic selection monad obtained by augmenting it with a
strong auxiliary monad T. This generalization proves useful when combining additional
eﬀects with selection. Suppose that R is a T-algebra with algebra map αT : T(R) → R.
Then, as essentially proved in [20] for any cartesian closed category, we can deﬁne a strong
monad ST (which may just be written S, when T is understood) by setting:

ST(X) = (X → R) → T(X)

It has unit (ηST)X : X → ST(X) where (ηST )X(x) = λγ ∈ X → R. (ηT)(x). The Kleisli
extension f †ST : ST(X) → ST(Y ) of a function f : X → ST(Y ) is given, analogously to the
above. First, for F ∈ ST(X) and γ : X → R, generalizing that for S, we deﬁne the reward
associated to the T-computation selected by F using γ by:

R(F |γ) = (αT ◦ T(γ))(F (γ))

(1)

Then the Kleisli extension function f †ST : ST(X) → ST(Y ) of a given f : X → ST(Y ) is:

f †ST F γ =def

(λx ∈ X. f (x)(γ))†T (F (λx ∈ X. R(f x|γ)))

(F ∈ ST(X), γ : Y → R)

So for (µT)X = id

†ST
ST(X) we get:

(µT)X F γ = (λd ∈ ST(X). dγ)†T (F (λd ∈ ST(X). R(d|γ)))

The selection monad has strength (stST)X,Y : X × ST(Y ) → ST(X × Y ) where:

(stST)X,Y (x, F ) = λγ ∈ X × Y → R. (stT)X,Y (x, F (λy ∈ Y. γ(x, y)))

(2)

(3)

We remark that if T is the free algebra monad for an equational theory Th, the categories
of T-algebras and of models of Th (i.e., algebras satisfying the equations) are equivalent. In
particular the T algebra αA : T(A) → A corresponding to a model A is the homomorphism

8

id†T
A , and h : A → B is a homomorphism between models of the theory iﬀ it is a T-algebra
morphism (from αA to αB). Note that the Kleisli extension of a map f : X → A to a
model A is the same as the Kleisli extension of f regarded as a map to a T-algebra.

We can deﬁne reward functions for general monads M equipped with an M-algebra

αM : M(R) → R. For u ∈ M(X) and γ : X → R, set:

RMX (u|γ) = (αM ◦ M(γ))(u)

(= γ†M (u))

(4)

Note that, for x ∈ X, RM(ηM(x)|γ) = γ(x) and that RM(−|γ) is an M-algebra morphism.
Further, in case M is the free algebra monad for an equational theory, and αM is the
M-algebra corresponding to a model on R, RM(−|γ) is a homomorphism.

We remark (see [38, 39, 32]) that, using the reward function, one can deﬁne a morphism

θM from M to the continuation monad, by setting

θM(u) = λγ ∈ (X → R). RM(u|γ)

for any set X and u ∈ M(X).

In the case of the selection monad, deﬁne αST : ST(R) → R by:

Fact 1. αST : ST(R) → R is an ST-algebra.

αST(F ) = αT(F (idR))

Proof. We write S for ST. We have to show that αS satisﬁes the unit and multiplication
requirements to be an ST-algebra, i.e., that αS ◦ (ηS)R = idR and αS ◦ (µS)R = αS ◦ S(αS).

For the ﬁrst requirement we have:

αST((ηS)R(r)) = αT((ηS)R(r)(idR)) = αT((ηT)R(r)) = r

For the second requirement, for F ∈ S(S(R)) we calculate, ﬁrst, that:

αS((µT)RF ) = αS(λγ : R → R. (λd ∈ S(R). dγ)†T (F (λd ∈ S(R). R(d|γ))))

= αT((λd ∈ S(R). d idR)†T (F (λd ∈ S(R). R(d|idR))))
= αT((λd ∈ S(R). d idR)†T (F (λd ∈ S(R). αT(d idR))))
= (λd ∈ S(R). αT(d idR))†T (F (αS))
= α†T

S (F (αS))

(where the fourth equality uses the fact that for any M-algebra α : M(X) → X and any
f : Y → M(X) we have α ◦ f †M = (α ◦ f )†M) and, second, that:

αS(S(αS)(F )) = αS(λγ : R → R. T(αS)(F (γ ◦ αS)))
= αT(T(αS)(F (αS )))
= α†T
S (F (αS))

(where the last equality uses the fact that for any M-algebra α : M(X) → X, and any
f : Y → X we have α ◦ M(f ) = f †M). This concludes the proof.

9

Using the general formula for the reward function for monads equipped with an algebra

on R, we then calculate for F ∈ ST(X) = (X → R) → T(X) and γ : X → R that:

RST (F |γ) = αST(ST(γ)(F ))

= αST(λγ′ : R → R. T(γ)(F (γ′ ◦ γ)))
= αT(T(γ)(F γ))

As desired, this is the reward function of Deﬁnition 1. Note that RST(F |γ) = RT(F γ|γ).

2.2 Generic eﬀects and algebraic operations

In order to be able to give semantics to eﬀectual operations such as probabilistic choice, we
use the apparatus of generic eﬀects and algebraic operations in the category of sets discussed
in [47] (in a much more general setting). Suppose that M is a (necessarily strong) monad
on the category of sets. A generic eﬀect g with arity (I, O) (written g : (I, O)) for M is
just a Kleisli map:

g : O → M(I)

An algebraic operation op with arity (I, O) (written op : (I, O)) for M (or M-algebraic
operation) is a family of functions

opX : O × M(X)I → M(X)

natural with respect to Kleisli maps in the sense that the following diagram commutes for
all e : X → M(Y ):

O × M(X)I opX✲ M(X)

O × (e†M )I

e†M

❄
O × M(Y )I

❄
opY✲ M(Y )

There is a 1-1 correspondence between (I, O)-ary generic eﬀects and (I, O)-ary algebraic

operations. In one direction, given g, one sets

opX(o, a) = a†M(g(o))

In the other direction, given such a family op, one sets

g(o) = opI(o, (ηM)I )

(5)

(6)

Naturality implies a weaker but useful property, that the above diagram commutes for
In other words, such maps are homomorphisms
maps M(f ), for any f : X → Y .

10

M(f ) : M(X) → M(X), if we regard M(X) and M(Y ) as algebras equipped with (any)
corresponding algebraic operation components. Naturality also implies that, as monad
mutltiplications (µT)X are Kleisli extensions, they too act homomorphically on algebraic
operations.

We generally obtain the algebraic operations we need via their generic eﬀects. When

O is a product O1 × . . . × Om, we obtain semantically useful functions

op†

X : (M(O1) × . . . × M(Om)) × M(X)I → M(X)

from an algebraic operation

opX : (O1 × . . . × Om) × M(X)I → M(X)

This can be done by applying iterated Kleisli extension to the curried version

op′

X : O1 → . . . Om → M(X)I → M(X)

of op, or, equivalently, using Kleisli extension and the monoidal structure

(mT)X,Y : M(X) × M(Y ) → M(X × Y )

induced by the monadic strength (see [40]).

When O = 1, we generally ignore it and equivalently write g : I and g ∈ M(I) for
generics and op : I and opX : M(X)I → M(X) for algebraic operations. We adopt similar
conventions below for related occurrences of 1. Note that (I, O)-ary algebraic operations
op are in an evident correspondence with indexed families opo (o ∈ O) of I-ary algebraic
in particular, when I = [n] (as usual, [n] = {i | i < n}), the opo can be
operations;
considered to be families (opo)X : M(X)n → M(X) of n-ary functions. (Here, and below,
it is convenient to confuse [n] with n.)

The [n]-ary algebraic operations include the (componentwise) projections πn,i, for
i = 0, n − 1 and are closed under composition, meaning that if op is an [n]-ary alge-
braic operation, and opi are [m]-ary algebraic operations, then so is op ◦ hop0, . . . , opn−1i
where:

(op ◦ hop0, . . . , opn−1i)X (u0, . . . , um−1) = opX((op0)X (u0), . . . , (opm−1)X(um−1))

There are natural corresponding generic eﬀects and operations on them. This is part
of a much larger picture. The generic eﬀects of a monad M form its Kleisli category,
with objects all sets. This category has all small sums, and so its opposite, termed the
large Lawvere theory of M (see [17, 33]), has all small products. The algebraic operations
also form a category, again with objects all sets, and with morphisms from I to O the
(I, O)-ary algebraic operations (identity and composition are deﬁned componentwise). The
correspondence between generic eﬀects and algebraic operations forms an isomorphism
between these two categories.

11

We say that algebraic operations op1 : [n1], . . . , opk : [nk] satisfy equations over function
symbols f1 : n1, . . . , fk : nk iﬀ for any X, (op1)X , . . . , (opk)X do, in the usual sense, i.e., if
the equations hold with the fi interpreted as (opi)X for i = 1, k. In the case where M is
the free-algebra monad for an equational theory Th with function symbols op : n of given
arity, the opX : M(X)n → M(X) form [n]-ary algebraic operations (indeed, in this case
all algebraic operations occur as compositions of these ones and the projection algebraic
operations). These algebraic operations satisfy all the equations of Th.

Given an M-algebra, α : M(X) → X, and an M-algebraic operation op : (I, O) we can

induce a corresponding map opα : O × X I → X, by setting

opα(o, u) = α(opX (o, ηX ◦ u))

and α is then a homomorphism between opM(X) and the induced map. Given a collection
of operations op1 : [n1], . . . , opk : [nk], the corresponding induced maps satisfy the same
equations the operations do. So, in particular, if M is the free-algebra monad for an
equational theory Th with function symbols opi : ni, X becomes a model of the theory via
the (opi)M(X). Conversely, if X is a model of the theory then we can deﬁne a corresponding
M-algebra by setting α = id†M
X . These two correspondences yield an isomorphism between
the categories of M-algebras and models of the theory (the isomorphism is the identity on
morphisms).

Given a monad morphism θ : M → M′, any generic eﬀect g : O → M(I) yields a generic
eﬀect g′ = θI ◦g for M′. Then, see [34], θ is a homomorphism of the corresponding algebraic
operations, opX : O × M(X)I → M(X) and op′
X : O × M′(X)I → M′(X) in the sense that,
for all sets X, the following diagram commutes:

O × M(X)I opX✲ M(X)

O × (θX )I

θX

❄
O × M′(X)I

op′

❄
X✲ M′(X)

We next consider algebraic operations for the selection monad ST. Modulo currying,
(I, O × RI)-ary generic eﬀects g : (O × RI ) → T(I) for T are in bijective correspondence
for ST. There is therefore a corresponding
with (I, O)-ary generic eﬀects
bijective correspondence between (I, O × RI )-ary T-algebraic operations op and (I, O)-ary
ST-algebraic operations
op. This correspondence has a pleasing component-wise expression
going from T to ST. An intermediate function family notion is useful. We deﬁne the
auxiliary function family auxX : O × RX × T(X)I → T(X) associated to a (I, O × RI )-ary
T-algebraic operation op by:

g : O → T(I)RI

e

e

auxX(o, γ, u) = opX (ho, λi ∈ I. RT(ui|γ)i, u)

(7)

Below we write auxX,o,γ for the function auxX (o, γ, −).

12

Proposition 1. Let op be an (I, O × RI )-ary T-algebraic operation. In terms of its as-
sociated auxiliary function family aux, the corresponding (I, O)-ary ST-algebraic operation
op is given by:

opX (o, a) = λγ ∈ RX. auxX,o,γ(λi ∈ I. aiγ)

e
Conversely, we have:

e

auxX,o,γ(u) =

opX(o, λi ∈ I.λγ ∈ X → R. ui)γ

Proof. The generic eﬀect g : O × RI → T(I) corresponding to op is given by Equation 6:

e

g(o, γ) = opI (ho, γi, (ηT)I )

Currying, we obtain

g : O → S(I) where:

g(o) = λγ ∈ RI . opI (ho, γi, (ηT)I )

e

and then, using Equation 5, we have:

e

opX (o, a) = a†ST (

g(o))

We next choose a reward continuation γ ∈ RX and examine a†ST (
ﬁrst obtain a reward continuation in RI from a and γ, namely:

e

e

g(o))γ. To this end we

γ =def λi ∈ I. RT(ai|γ)

e

u =def (λi ∈ I. aiγ) ∈ I → T(X)

and, setting

we have:

a†ST (

g(o))γ = u†T(

g(o)(γ))
= u†T(opI (ho, γi, (ηT)I ))
= opX(ho, γi, u†T (ηT)I )

e

e

(by the Kleisli naturality
of algebraic operations)

= opX(ho, γi, u)

Putting these facts together, we have:

op)X(o, a)γ = a†ST (gST (o))
(
= opX (ho, γi, u)
= opX (ho, λi ∈ I. RT(ai|γ)i, λi ∈ I. aiγ))
= auxX,o,γ(λi ∈ I. aiγ)

e

as required. That

auxX,o,γ(u) =

opX(o, λi ∈ I.λγ ∈ X → R. ui)γ

e

13

is an immediate consequence, for, setting a = λi ∈ I. λγ ∈ X → R. u(i), we ﬁnd:

auxX,o,γ(u) = auxX,o,γ(λi ∈ I. aiγ)

= (
= (

op)X(o, a)γ
op)X(o, λi ∈ I. λγ ∈ X → R. u(i))γ
e
e

Note that, as is natural, the proposition expresses that (opST)X uses the reward function

in RI which assigns to i ∈ I the reward obtained by following the ith branch.

The correspondences between the two kinds of algebraic operations and auxiliary func-
tions ﬁt well with ﬁxing parameters. Given an (I, O × RI)-ary T-algebraic operation
op, we obtain an (I, RI )-ary ST-algebraic operation op′ by ﬁxing an o ∈ O. The corre-
sponding auxiliary function family aux′
X : RX × T(X)I → T(X) is, as one would expect,
λγ, a. auxX(a, γ, a); the corresponding I-ary algebraic operation for ST is

opo.

Using Proposition 1, we can reduce questions of equational satisfaction by ST-algebraic
operations to corresponding questions about their auxiliary functions, so reducing questions
about ST to questions about T. We ﬁrst need a lemma.

e

Lemma 1.

1. The auxiliary function family auxX,γ corresponding to an [n]-ary projection ST-
algebraic operation πn,i is the family (πn,i)T(X) : T(X)n → T(X) of projections.

2. Let op be an [n]-ary ST-algebraic operation, and, for i = 0, n − 1, let opi be [m]-ary
ST-algebraic operations for ST, and let their corresponding auxiliary function families
be auxX and (auxi)X , respectively. Then the auxiliary function family aux′
X corre-
sponding to the composition op′ of op with the opi is the corresponding composition
of auxiliary functions:

aux′

X,γ(u0, . . . , um−1)

= auxX,γ((aux0)X,γ(u0, . . . , um−1), . . . , (auxn−1)X,γ(u0, . . . , um−1))

Proof.

1. This is immediate from the second part of Proposition 1.

2. Making use of both parts of Proposition 1 we calculate:

aux′

X,γ(u0, . . . , um−1)

X(λγ.u0, . . . , λγ.um−1)γ

= op′
= opX((op0)X (λγ.u0, . . . , λγ.um−1), . . . , (opn−1)X (λγ.u0, . . . , λγ.um−1))γ
= auxX,γ((op0)X(λγ.u0, . . . , λγ.um−1)γ, . . . , (opn−1)X (λγ.u0, . . . , λγ.um−1)γ)
= auxX,γ((aux0)X,γ(u0, . . . , um−1), . . . , (auxn−1)X,γ(u0, . . . , um−1))

14

Proposition 2. Let opi be ([ni], Oi × R[ni])-ary T-algebraic operations, for i = 1, k, and
opk)ok , if, for all
choose oi ∈ Oi (i = 1, k). Then an equation is satisﬁed by (
sets X and γ : X → R, it is satisﬁed by (aux1)X,o1,γ, . . . , (auxk)X,ok,γ, where, for i = 1, k,
auxi is the auxiliary function family obtained from opi.

op1)o1, . . . , (

e

e

Proof. We can assume without loss of generality that the Oi are all 1 and so can be ignored.
The interpretation of an algebraic term t with m free variables built from function symbols
f1 : n1, . . . , fk : nk can be considered as an m-ary function, and an equation t = u. over m
free variables holds in the interpretation if the two such interpretations are equal.

Fixing a term t with m free variables, for any set X, using the (

opi)X to interpret the
fi, we obtain functions O[[t]]X : ST(X)m → ST(X), say, and for any set X and γ : X → R,
using the (auxi)X,γ we obtain functions A[[t]]X,γ : T(X)m → T(X), say. As the projec-
tions are algebraic operations and as algebraic operations are closed under composition,
a straightforward structural induction shows that the family O[[t]] is an m-ary algebraic
operation for ST. Using Lemma 1, a further straightforward structural induction shows
that A[[t]]X,− is the corresponding auxiliary function family.

e

Now suppose an equation t = u over m variables is satisﬁed by (aux1)X,γ, . . . , (auxk)X,γ
for all sets X and γ : X → R, that is, suppose that A[[t]]X,γ = A[[u]]X,γ, for all such X and
γ. Then, using Proposition 1, we see that:

O[[t]]X (F0, . . . , Fm−1)γ = A[[t]]X,γ(F0γ, . . . , Fm−1γ)
= A[[u]]X,γ(F0γ, . . . , Fm−1γ)
= O[[u]]X (F0, . . . , Fm−1)γ

holds for all sets X and γ : X → R, concluding the proof.

We next see that, as one would expect, we can use algebraic operations for T-eﬀects to
obtain corresponding ones for ST-eﬀects. If op is an (I, O)-ary T-algebraic operation, it can
be considered to be an (I ×RI , O)-ary algebraic operation which ignores its reward function
argument. The auxiliary functions auxX,o,γ are the same as the (opo)X and Proposition 1
then yields a (I, O)-ary ST-algebraic operation

op, where:

opX(o, a) = λγ ∈ RX. opX (o, λi ∈ I. aiγ)

e

(8)

which is the natural pointwise deﬁnition. In the case where I = [n] this can be written as:

e

opX(o, F1, . . . , Fn) = λγ ∈ RX . opX(o, F1γ, . . . , Fnγ)

(9)

From Proposition 2 we further have (as is, in any case, evident from a pointwise argument):

e

Corollary 1. Let opi be [ni]-ary T-algebraic operations, for i = 1, k. Then an equation is
satisﬁed by

opk, if it is satisﬁed by op1, . . . , opk.

op1, . . . ,

e

e

15

Another way to obtain algebraic operations is to start from the basic selection monad
S. Consider an (I, O × RI)-ary generic eﬀect g : O × RI → I for the identity monad
(equivalent via currying to an (I, O)-ary generic eﬀect for S). Viewed as a T-generic eﬀect
ηI ◦ g, via the unit for T and using Equation 5, we obtain an (I, O × RI )-ary T-algebraic
operation opg where, for o ∈ O, γ ∈ RI , u ∈ T(X)I :

(opg)X (ho, γi, u) = u†

T(ηI ((g(o, γ))) = u(g(o, γ))

Then the corresponding auxiliary functions (auxg)X : O × RX × T(X)I → T(X) are given
by:

(auxg)X,o,γ(u) = (opg)X (ho, λi ∈ I. RT(ui|γ)i, u) = u(g(o, λi ∈ I. RT(ui|γ)))

using Deﬁnition 7.

Finally, via Proposition 1, we obtain the (I, O)-ary ST-algebraic operation

sponding to opg. For for o ∈ O, a ∈ ST(X)I , γ ∈ RX, we have:

opg corre-

e

opg)X(o, a)γ = (auxg)X,o,γ(λi ∈ I. aiγ) = a(g(o, λi ∈ I. RST (ai|γ)))γ
(

(10)

Say that a family of functions

e

fX : O × ST(X)I → ST(X)

is an (I, O)-ary-selection operation if: for every o ∈ O, and every γ ∈ RI there is an i0 ∈ I
such that for all sets X, a ∈ ST(X)I , and γ ∈ RX,

λi ∈ I. RST(ai|γ) = γ =⇒ fX(o, a)γ = ai0γ

that is, each component opX of the family selects a ﬁxed argument, depending only on
the parameter o ∈ P and the reward associated to each branch ai of f ’s argument a. For
opg, as given by Equation 10, is such a selection operation, where the argument
example,
selected is the g(o, γ)-th.

e

Theorem 1. Every selection operation has the form
generic eﬀect g : O → S(I).

opg for some basic selection monad

Proof. Let f be an (I, O)-ary-selection operation.This means that for every o ∈ O and
γ ∈ RI , there is an i0 ∈ I such that for all sets X, a ∈ ST(X)I , and γ ∈ RX:

e

λi ∈ I. RST (ai|γ) = γ =⇒ fX(o, a)γ = aiγ

Fix o ∈ O and γ ∈ RI, choose such an i0, and take X = I and a = (ηST)I . For all i ∈ I

we have:

RST (ai|γ) = RST ((ηST)I (i)|γ) = RT((ηT)I (i)|γ) = γ(i)

16

So γ = λi ∈ I. RST (ai|γ), and we therefore have:

fI (o, a)γ = ai0γ = (ηT)I (i0)

As monad units are always monos, we see there is only one such i0, and so there is a
function g : O × RI → I such that for all o ∈ O, γ ∈ RI , sets X, a ∈ ST(X)I , and γ ∈ RX :

λi ∈ I. RST (ai|γ) = γ =⇒ fX(o, a)γ = ag(o, γ)γ

Substituting, we see that for all o ∈ O, sets X, a ∈ ST(X)I , and γ ∈ RX:

fX(o, a)γ = ag(o, λi ∈ I. RST (ai|γ))γ

We then see from Equation 10 that this identiﬁes f as the algebraic operation
from opg, concluding the proof.

opg arising

We next consider a particular case: binary selection algebraic operations. Here O = 1
and I = [2]. Such operations arise from [2]-ary generics g : R[2] → [2] for the basic selection
monad. Viewed as a binary algebraic operation on ST, Equation 10 becomes:

e

opg)X(G0, G1)γ =
(

G0γ (g(λi ∈ I. RST (Gi|γ))) = 0)
G1γ (g(λi ∈ I. RST (Gi|γ))) = 1)

(cid:26)

Note that [2]-ary generics g : R[2] → [2] for the basic selection monad are in bijection with
binary relations B on R, with relations B corresponding to generics gB, where:

e

gB(γ) = 0 ≡def γ(0)Bγ(1)

(read rBs as “r beats s”). Deﬁning (
we have:

opB) to be the binary ST-algebraic operation

opB)X (G0, G1)γ =
(

G0γ (RST (G0|γ) B RST (G1|γ))
e
G1γ (RST (G0|γ) BRST (G1|γ))

(cid:26)

opgB ,

e

For optimization purposes it is natural to assume B is a total order ≥. We deﬁne or
to be the resulting binary algebraic operation on ST; it is this operation that we use for
the semantics of decision-making in our two languages. Explicitly we have:

e

G0γ (if RST(G0|γ) ≥ RST (G1|γ))
G1γ (otherwise)
This can be usefully rewritten. For γ : X → R deﬁne maxX,γ : X 2 → X (written inﬁx) by:

orX(G0, G1)(γ) =

(cid:26)

x maxX,γ y =

x (if γ(x) ≥ γ(y))
(otherwise)
y

(cid:26)

Then:

orX (G0, G1)(γ) = G0γ maxX,RT(−|γ) G1γ

(11)

17

Taking B to be a total order is equivalent to using a version of argmax as a generic
eﬀect. First, for ﬁnite totally ordered sets I, assuming a total order ≥ on R, we deﬁne
argmaxI ∈ S(I) = (I → R), by taking argmaxγ to be the least i ∈ I among those
maximizing γ(i). Then B corresponds to argmax[2], with [2] ordered by setting 0 < 1.
We could as well have used generics picking from ﬁnite totally ordered sets, with resulting
choice functions of corresponding arity.

We next investigate the equations that the algebraic operations

opB obey and their
relation to properties of the relations B. Deﬁne (auxB)X : RX × T(X)2 → T(X) to be
(auxgB )X. So:

e

(auxB)X,γ(u0, u1) =def (auxg)X,γ(λi ∈ [2]. ui) = ug(λi∈[2]. RT(ui|γ))

and we have:

(auxB)X,γ(u0, u1) =

u0
u1

(if RT(u0|γ) B RT(u1|γ))
(otherwise)

(cid:26)

In particular, for x0, x1 ∈ X we have:

(auxB)X,γ(ηT(x0), ηT(x1))(γ) =

ηT(x0)
ηT(x1)

(if γ(x0)Bγ(x1))
(otherwise)

(cid:26)

(12)

We see from Proposition 2 that
for every X and γ : X → R.

opB satisﬁes an equation if, and only if, (auxB)X,γ does

Say that a binary function f is left-biased if the following equation holds:

e

f (x, f (y, x)) = f (x, y)

and is right-biased if the following equation holds:

f (f (x, y), x) = f (y, x)

and say a relation R is connex iﬀ, for all x, y, either xRy or yRx.

Theorem 2. For every binary relation B on R we have:

1.

opB is idempotent.

2.

3.

4.

5.

opB is associative iﬀ B and its complement is transitive.
e
opB is left-biased iﬀ B is connex.
e
opB is right-biased iﬀ the complement of B is connex.
e
opB is not commutative (assuming R non-empty).
e

Proof. Throughout the proof, we use the fact that, like any monad unit, all components of
e
ηST are 1-1.

18

1. This is evident.

2.

(a) Suppose

e

opB is associative, and choose r0, r1, r2 ∈ R. Deﬁne γ : [3] → R by:
γ(i) = ri, for i = 0, 1, 2, and set f = (auxB)γ,[3] and xi = (ηT)[3](i), for i = 0,1,2.
Note that the xi are all diﬀerent. By Proposition 2 f is associative as
Suppose ﬁrst that r0Br1 and r1Br2. Using Equation 12 we see that, as r0Br1
and r1Br2, f (x0, f (x1, x2)) = f (x0, x1) = x0, and f (f (x0, x1), x2) = f (x0, x2).
So, as f is associative f (x0, x2) = x0. As x0 6= x2, we have x0Bx2, as required.
Suppose next that ¬ r0Br1 and ¬ r1Br2. Then, using Equation 12 again, we
see that f (x0, f (x1, x2)) = f (x0, x2) and f (f (x0, x1), x2) = f (x1, x2) = x2, and,
similarly to before, we conclude that ¬ r0Br2.

opB is.

e

(b) For the converse, suppose that B and its complement is transitive. It suﬃces
to prove that every f = (auxB)X,γ : T(X)2 → T(X) is associative. Choose
ui ∈ T(X) (i = 0, 2) and set ri = R(ui|γ). The proof divides into cases according
as each of r0Br1 and r1Br2 does or does not hold:

i. Suppose that r0Br1 and r1Br2 (and so r0Br2). By the deﬁnition of auxB,

we then have:

f (u0, f (u1, u2)) = f (u0, u1) = u0 = f (u0, u2) = f (f (u0, u1), u2)

ii. Suppose that r0Br1 and ¬ r1Br2. Then:

f (u0, f (u1, u2)) = f (u0, u2) = f (f (u0, u1), u2)

iii. Suppose that ¬ r0Br1 and r1Br2. Then:

f (u0, f (u1, u2)) = f (u0, u1) = u1 = f (u1, u2) = f (f (u0, u1), u2)

iv. Suppose that ¬ r0Br1 and ¬ r1Br2.Then ¬r0Br2, and we have:

f (u0, f (u1, u2)) = f (u0, u2) = u2 = f (u1, u2) = f (f (u0, u1), u2)

So in all cases we have

f (u0, f (u1, u2)) = f (f (u0, u1), u2)

and so

opB is associative, as required.

3.

e

(a) Suppose opB is left-biased and choose r0, r1 ∈ R. Deﬁne γ : [2] → R by:
γ(i) = ri, for i = 0, 1, and set f = (auxB)γ,[2] and xi = (ηT)[2](i), for i = 0,1.
Note that x0 6= x1. By Proposition 2 f is left-biased as opB is.
Suppose that ¬r1Br0. Then we have:

f (x0, x1) = f (x0, f (x1, x0)) = f (x0, x0) = x0

and so, as x0 6= x1, r0Br1.

19

(b) For the converse, suppose the relation B is connex.

It suﬃces to prove that
every f = (auxB)X,γ : T(X)2 → T(X) is left-biased. Choose ui ∈ T(X)
(i = 0, 1) and set ri = RT(ui|γ). Suppose ﬁrst that r1Br0 holds. Then
f (u0, f (u1, u0)) = f (u0, u1). Otherwise, as B is connex, we have ¬ r1Br0 and
r0Br1, and so, f (u0, f (u1, u0)) = f (u0, u0) = u0 = f (u0, u1). So in either case
we have f (u0, f (u1, u0)) = f (u0, u1) as required.

4.

(a) Suppose opB is right-biased and choose r0, r1 ∈ R. Deﬁne γ : [2] → R by:
γ(i) = ri, for i = 0, 1, and set f = (auxB)γ,[2] and xi = (ηT)[2](i), for i = 0,1.
Note that x0 6= x1. By Proposition 2 f is right-biased as opB is.
Suppose that ¬(¬r0Br1), i.e., that r0Br1. Then we have:

f (f (x, y), x) = f (y, x)

f (x1, x0) = f (f (x0, x1), x0) = f (x0, x0) = x0

and so, as x0 6= x1, ¬r1Br0.

(b) For the converse, suppose that ¬B is connex.

It suﬃces to prove that every
f = (auxB)X,γ : T(X)2 → T(X) is right-biased. Choose ui ∈ T(X) (i = 0, 1)
and set ri = RT(ui|γ). Suppose ﬁrst that ¬r0Br1 holds. Then we have that
f (f (x0, x1), x0) = f (x1, x0). Otherwise, as B is connex, we have r0Br1 and
¬ r1Br0, and so, f (u0, f (u1, u0)) = f (u0, u0) = u0 = f (u0, u1). So in either case
we have f (u0, f (u1, u0)) = f (u0, u1) as required.

5. Choose r ∈ R. Deﬁne γ : [2] → R by: γ(0) = γ(1) = r, and set f = (auxB)γ,[2] and
xi = (ηST )(i), for i = 0, 1. Note that x0 6= x1. By Proposition 2 it suﬃces to prove
that f is not commutative.

In case rBr holds, we have:

f (x0, x1) = x0 6= x1 = f (x1, x0)

In case rBr does not hold, we have:

f (x0, x1) = x1 6= x0 = f (x1, x0)

In either case (opB)[2] is not commutative.

Given a binary relation B on R and an ST-algebraic operation op : [n], we say that op
opB iﬀ for all X, i ∈ [n], Fj ∈ ST(X) (j ∈ [n], j 6= i), and G0, G1 ∈ ST(X),

distributes over
we have:

e
opX(F0, . . . , Fi−1,

opB(G0, G1), Fi+1, . . . , Fn−1) =

opB(opX (F0, . . . , Fi−1, G0, Fi+1, . . . , Fn−1), opX (F0, . . . , Fi−1, G1, Fi+1, . . . , Fn−1))

e

e

20

Also, given a binary relation B on R and a function f : Rn we say that f distributes over
B iﬀ for all 0 ≤ i < n, rj ∈ R (0 ≤ j < n, j 6= i), and s0, s1 ∈ R we have:

s B t ⇐⇒ f (r0, . . . , ri−1, s0, ri+1, . . . , rn−1) B f (r0, . . . , ri−1, s1, ri+1, . . . , rn−1)

We say that an n-ary function f : Rn → R, where n ≥ 1, distributes over a binary
relation B on R iﬀ it preserves and reﬂects B in each argument, i.e., iﬀ for 1 ≤ i ≤ n and
x1, . . . , xi−1, y0, y1, xi+1, . . . , xn ∈ R we have:

B(f (x1, . . . , xi−1, y0, xi+1, . . . , xn), f (x1, . . . , xi−1, y1, xi+1, . . . , xn)) ⇐⇒ B(y0, y1)

Theorem 3. Let op : [n] be a T-algebraic operation, and let B be a binary relation on R.
If opR distributes over B then

op distributes over

opB.

Proof. To keep notation simple we suppose that
in its second argument. That is, we prove, for any X, that:

e

op is binary and establish distributivity
e

op(F,

opB(G, H)) =

opB(

op(F, G),

e
op(F, H)))

(F, G, H ∈ ST(X))

To do so we use Proposition 2 and establish the corresponding equation for the auxiliary
functions of these operations. The auxiliary function auxX,γ : T(X)2 → T(X) of
op is opX.
So we need to show for any γ : X → R that

e

e

e

e

e

op(u, (auxB)X,γ(v0, v1)) = (auxB)X,γ(op(u, v0), op(u, v1)))

(u, v0, v1 ∈ T(X))

e

From the deﬁnition of the auxiliary function of
is either op(u, v0) or op(u, v1), and that the LHS is op(u, v0) iﬀ

opB we see that each side of this equation

RT(v0|γ) B RT(v1|γ)

e

(∗)

and that the RHS is op(u, v0) iﬀ

RT(op(u, v0)|γ) B RT(op(u, v1)|γ)

(∗∗)

As both T(γ) and αT are homomorphisms, so is RT(−|γ) = αT ◦ T(γ), and so this last
condition is equivalent to:

opR(RT(u|γ), RT(v0|γ)) B opR(RT(u|γ), RT(v1|γ))

and we see, using the fact that opR distributes over B, that the conditions (∗) and (∗∗) are
equivalent.

21

3 A general language with algebraic operations

The goal of this section is to give some deﬁnitions and results—in particular an adequacy
theorem—for a general language with algebraic operations. We treat our two languages of
later sections as instances of this language via such algebraic operations.

3.1 Syntax

We make use of a standard call-by-value λ-calculus equipped with algebraic operations. Our
language is a convenient variant of the one in [46] (itself building on Moggi’s computational
λ-calculus [45]). The somewhat minor diﬀerences from [46] are that we allow a variety of
base types, our algebraic operations may have parameters, and we make use of general
big-step transition relations as well as small-step ones.

Speciﬁcally, the types σ, τ, . . . of the language are given by:

σ ::= b | Unit | σ × σ | σ → σ

and the terms L, M, N, . . . are given by:

M ::= x | c | f (M1, . . . , Mm) | if L then M else N |

op(N1, . . . , Nn; M1, . . . , Mm) |
∗ | hM, N i | fst(M ) | snd(M ) | λx : σ. M | M N

The types and terms are built from:

- a basic vocabulary, consisting of:

1. base types, b (including Bool);

2. constants, c : b of given base types b (including tt, ff : Bool); and

3. ﬁrst-order function symbols, f : b1 . . . bm → b, of given arity b1 . . . bm and co-arity

b (including equality symbols =b: b × b → Bool),

together with

- algebraic operation symbols op : b1 . . . bn; m, with given parameter base types b1, . . . , bn

and arity m ∈ N.

The languages considered in the next two sections provide examples of this general setup.
We write BTypes for the set of base types and Conb for the set of constants of type b. We
deﬁne the order (or rank ) of types by:

o(b) = o(Unit) = 0

o(σ × τ ) = max(o(σ), o(τ ))

o(σ → τ ) = max(o(σ) + 1, o(τ ))

22

We work up to α-equivalence, as usual, and free variables and substitution are also
deﬁned as usual. The typing rules are standard, and omitted, except for that for the
algebraic operation symbols, which, aside from their parameters, are polymorphic:

Γ ⊢ N1 : b1, . . . , Γ ⊢ Nn : bn Γ ⊢ M1 : σ, . . . , Γ ⊢ Mm : σ
Γ ⊢ op(N1, . . . , Nn; M1, . . . , Mm) : σ

(op : b1 . . . bn; m)

where Γ = x1 : σ1, . . . , xn : σn is an environment. We write M : σ for ⊢ M : σ and say
then that the (closed) term M is well-typed; such terms are the programs of our language.
We employ standard notation, for example for local deﬁnitions writing let x : σ be M in N
for (λx : σ. N )M . We also use a cases form

cases M1 ⇒ N1 | . . . | Mn ⇒ Nn else Nn+1 (for n ≥ 0)

deﬁned by iterated conditionals (where the Mi are boolean).

Moggi’s language has local deﬁnitions and computational types T σ (with associated
term syntax) as primitives; these can be viewed as abbreviations in our language, in par-
ticular setting T σ = 1 → σ.

3.2 Operational semantics

The operational semantics of programs is given in three parts: a small-step semantics,
a big-step semantics, and an evaluation function. We make use of evaluation contexts,
following [24]. The set of values V, W, . . . is given by:

V ::= c | ∗ | hV, W i | λx : σ. M

where we restrict λx : σ. M to be closed. We write Valσ for the set of values of type σ, i.e.,
the V such that V : σ.

The evaluation contexts are given by:

E ::= [ ]

| f (c1, . . . , ck−1, E, Mk+1, . . . , Mm) | if E then M else N |

op(c1, . . . , ck−1, E, Nk+1, . . . , Nn; M1, . . . , Mm)
hE, N i | hV, Ei | fst(E) | snd(E) | EN | (λx : σ. M )E

and are restricted to be closed. The redexes are deﬁned by:

R ::= f (c1, . . . , cm) | if tt then M else N | if ff then M else N |

op(c1, . . . , cn; M1, . . . , Mm)
fst(hV, W i) | snd(hV, W i) | (λx : σ. M )V

and are restricted to be closed. Any program is of one of two mutually exclusive forms: it
is either a value V or else has the form E[R] for a unique evaluation context E and redex R.

23

We deﬁne two small-step transition relations on redexes, ordinary transition relations

and algebraic operation symbol transition relations:

R → N

and

R

c1,...,cn
−−−−→
opi

N (op : b1 . . . bn; m and i = 1, m)

The idea of the algebraic operation symbol transitions is to indicate with which parameters
an operation is being executed, and which of its arguments is then being followed. The
deﬁnition of the ﬁrst kind of transition is standard; we just mention that for each function
symbol f : b1 . . . bm → b and constants c1 : b1, . . . , cm : bn, we assume given a constant
valf (c1, . . . , cm) : b, where, in the case of equality, we have:

val=b(c1, c2) =

tt (if c1 = c2)
ff (otherwise)

(cid:26)

We then have the ordinary transitions:

f (c1, . . . , cm) → c

(valf (c1, . . . , cm) = c)

The algebraic operation symbol transition relations are given by the following rule:

op(c1, . . . , cn; M1, . . . , Mm)

c1,...,cn
−−−−→
opi

Mi

We next extend these transition relations to corresponding ordinary and algebraic operation
symbol transition relations on programs

M → M ′

and M

c1,...,cn
−−−−→
opi

M ′

To do so, we use evaluation contexts in a standard way by means of the following rules:

R → M ′
E[R] → E[M ′]

R

E[R]

c1,...,cn
−−−−→
opi
c1,...,cn
−−−−→
opi

M ′

E[M ′]

These transition relations are all deterministic.

For any program M which is not a value, exactly one of two mutually exclusive possi-

bilities holds:

- For some program M ′

In this case M ′ is determined and of the same type as M .

- For some op : b1 . . . bn; m and c1 : b1, . . . , cn : bn

M → M ′

M

c1,...,cn
−−−−→
opi

Mi

for all i = 1, n and some Mi.
determined and the Mi have the same type as M .

In this case op, the cj and the Mi are uniquely

24

We say a program M is terminating if there is no inﬁnite chain of (small-step) transitions
from M .

Lemma 2. Every program is terminating.

Proof. This is a standard computability argument; see the proof of Theorem 1 in [46] for
some detail. One deﬁnes a computability predicate on values by induction on types, and
then extends it to well-typed terms by taking such a term M to be computable if there
is no inﬁnite chain of (small-step) transitions from M , and every terminating sequence of
small-step transitions from M ends in a computable value.

Using the small-step relations one deﬁnes big-step ordinary and algebraic operation

symbol transition relations by:

M →∗ V
M ⇒ V

M →∗ M ′ M ′ c1,...,cn
−−−−→
opi
M ′′

M

c1,...,cn
=====⇒
opi

M ′′

For any program M which is not a value, similarly to the case of the small-step relations,
exactly one of two mutually exclusive possibilities holds:

- For some value V

M ⇒ V

In this case V is determined and of the same type as M .

- For some op : b1 . . . bn; m and c1 : b1, . . . , cn : bn

M

c1,...,cn
=====⇒
opi

Mi

for all i = 1, n and some Mi.
determined and the Mi have the same type as M .

In this case op, the cj and the Mi are uniquely

The big-step transition relations from a given program M form a ﬁnite tree with values at
the leafs, with all transitions, except for those leading to values being algebraic operation
symbol transitions, and with transitions of algebraic operation symbols of type (w; n)
branching n-fold. We write ||M || for the height of this tree.

Rather than use trees, we follow [46] and use eﬀect values E. These give the same
information and, conveniently, form a subset of our programs. They are deﬁned as follows:

E ::= V | op(c1, . . . , cn; E1, . . . , Em)

(Our eﬀect values are a ﬁnitary version of the interaction trees of [54]). Every program
M : σ can be given an eﬀect value Op(M ) : σ deﬁned as follows using the big-step transition
relations:

Op(M ) =

(

V
op(c1, . . . , cn; Op(M1), . . . , Op(Mm))

(if M ⇒ V )
c1,...,cn
(if M
=====⇒
opi

Mi for i = 1, m)

25

This deﬁnition can be justiﬁed by induction on ||M ||. Note that Op(E) = E, for any eﬀect
value E : σ. Note too that the transitions of programs and their evaluations closely parallel
each other, indeed we have:

M ⇒ V ⇐⇒ Op(M ) = V

and

M

opi=====⇒
c1,...,cn

Mi ⇐⇒ Op(M )

opi=====⇒
c1,...,cn

Op(Mi)

(13)

(14)

We next give a proof-theoretic account of the evaluation function Op to help us prove
our general adequacy theorem. There is a natural equational theory for the operational
semantics, with evident rules, which establishes judgments of the form ⊢o M = N : σ,
taken to be well-formed in case M : σ and N : σ. The axioms are the small-step reductions
for the redexes together with a commutation schema that algebraic operations commute
with evaluation contexts; they are given (omitting type information) in Figure 2.

f (c1, . . . , cm) = c

(valf (c1, . . . , cm) = c)

if tt then M else N = M

if ff then M else N = N

fst(hV, W i) = V

snd(hV, W i) = W

(λx : σ. M )V = M [V /x]

E[op(c1, . . . , cn; M1, . . . , Mm)] = op(c1, . . . , cn; E[M1], . . . , E[Mm])

Figure 2: Axioms

We then have:

Lemma 3. For any well-typed term M : σ we have:

1.

2.

3.

4.

M → M ′ =⇒ ⊢o M = M ′ : σ

M

c1,...,cn
−−−−→
opi

Mi, for i = 1, m =⇒ ⊢o M = op(c1, . . . , cn; M1, . . . , Mm) : σ

M ⇒ V =⇒ ⊢o M = V : σ

M

c1,...,cn
=====⇒
opi

Mi, for i = 1, m =⇒ ⊢o M = op(c1, . . . , cn; M1, . . . , Mm) : σ

26

The following proposition is an immediate consequence of this lemma:

Proposition 3. For any program M : σ we have:

⊢o M = Op(M ) : σ

There is a useful substitution lemma. Given any eﬀect value E : b, a nonempty ﬁnite set
u ⊆ Conb that includes all the constants of type b in E, and a function g from u to programs
of type b′, deﬁne E[g] : b′, the substitution g of programs for constants, homomorphically
by:

=
op(c1, . . . , cn; E1, . . . , Em)[g] = op(c1, . . . , cn; E1[g], . . . , Em[g])

g(c)

c[g]

Let c1, . . . , cn enumerate u (the order does not matter) and deﬁne Fg : b → b′ to be

λx : b. cases x = c1 ⇒ g(c1) | . . . | x = cn−1 ⇒ g(cn−1) else g(cn)

With this notation we have:

Lemma 4.

Op(FgE) = Op(E[g])

Proof. The proof is a structural induction on E. For E a constant c we have:

Op(FgE) = Op(cases c = c1 ⇒ g(c1) | . . . | c = cn−1 ⇒ g(cn−1) else g(cn))

= Op(g(c))
= Op(c[g])

and for E of the form op(c1, . . . , cn; E1, . . . , Em) we have:

Op(FgE) = op(c1, . . . , cn; Op(FgE1), . . . , Op(FgEm))
= op(c1, . . . , cn; Op(E1[g]), . . . , Op(Em[g]))
= Op(op(c1, . . . , cn; E1[g], . . . , Em[g])
= Op(op(c1, . . . , cn; E1, . . . , Em)[g])
= Op(E[g])

3.3 Denotational semantics

The semantics of our language makes use of a given strong monad, following that of Moggi’s
computational λ-calculus [45]. In order to be able to give semantics to eﬀectual operations
we use the apparatus of generic eﬀects and algebraic operations as discussed above. For
the sake of simplicity we work in the category of sets, although the results go through much
more generally, for example in any cartesian closed category with binary sums.

27

To give the semantics of our language a number of ingredients are needed. We assume

given:

- a (necessarily) strong monad M on the category of sets,

- nonempty sets [[b]] for the base types b (with [[Bool]] = B =def {0, 1}),

- elements [[c]] of [[b]] for constants c : b (with [[tt]] = 1 and [[ff]] = 0),

- functions [[f ]] : [[b1]] × . . . × [[bm]] → [[b]] for function symbols f : b1 . . . bm → b, and

- generic eﬀects

for algebraic operation symbols op : b1 . . . bn; m.

gop : [[b1]] × . . . × [[bn]] → M([n])

We further assume that diﬀerent constants of the same type receive diﬀerent denotations,
i.e., the [[-]] : Valb → [[b]] are 1-1 (so we can think of constants as just names for their
denotations, just as one thinks of numerals), and that the given denotations of function
symbols are consistent with their operational semantics in that:

valf (c1, . . . , cm) = c =⇒ [[f ]]([[c1]], . . . , [[cm]]) = [[c]]

(15)

With these ingredients, we can give our language its semantics. Types are interpreted

by putting:

To every term

we associate a function

M[[b]]
= [[b]]
M[[σ × τ ]] = M[[σ]] × M[[τ ]]
M[[σ → τ ]] = M[[σ]] → M(M[[τ ]])

Γ ⊢ N : σ

M[[Γ ⊢ N : σ]] : M[[Γ]] → M(M[[σ]])

where M[[x1 : σ1, . . . , xn : σn]] =def M[[σ1]] × . . . × M[[σn]]. When the typing Γ ⊢ N : σ is
understood, we generally write M[[N ]] rather than M[[Γ ⊢ N : σ]].

The semantic clauses for conditionals and the product and function space terms are

standard, and we omit them. For constants c : b we put:

M[[c]](ρ) = (ηM)[[b]]([[c]])

For function symbol applications f (M1, . . . , Mm), where f : b1 . . . bm → b, we put:

M[[f (M1, . . . , Mm)]](ρ) = [[f ]]∼([[M]](M1)(ρ), . . . , [[M]](Mm)(ρ))

28

where

[[f ]]∼ : M([[b1]]) × . . . × M([[bm]]) → M([[b]])
is obtained from [[f ]] in a standard way e.g., via iterated Kleisli extension. For terms
Γ ⊢ op(N1, . . . , Nn; M1, . . . , Mm) : σ, where op : b1 . . . bn; m, we make use of the algebraic
operation

opX : ([[b1]] × . . . × [[bn]]) × M(X)[m] → M(X)

corresponding to the generic eﬀects gop and put:

M[[op(N1, . . . , Nn; M1, . . . , Mm)]](ρ) =

op†

[[σ]](hM[[N1]](ρ), . . . , M[[Nn]](ρ)i, hM[[M1]](ρ), . . . , M[[Mm]](ρ))i

where op†

[[σ]] is again deﬁned in a standard way, as discussed in Section 2.2.
We further give values V : σ an eﬀect-free (or pure) semantics Mp[[V ]] ∈M[[σ]]:

= [[c]]
Mp[[c]]
Mp[[hV, V ′i]]
= hMp[[V ]], Mp[[V ′]]i
Mp[[λx : τ. N ]] = M[[x : τ ⊢ N : τ ′]]

This eﬀect-free semantics of values V : σ determines their denotational semantics:

Below, we regard the eﬀect-free semantics as providing functions:

M[[V ]](ρ) = (ηM)M[[σ]](Mp[[V ]])

Mp : Valσ → M[[σ]]

3.4 Adequacy

Our proof system is consistent relative to our denotational semantics:

Lemma 5. If ⊢o M = N : σ then M[[M ]] = M[[N ]].

The proof of this lemma uses naturality condition with respect to Kleisli morphisms on

algebraic operations is used here to establish the soundness of the commutation schema.

Our general adequacy theorem is an immediate consequence of Proposition 3 and

Lemma 5:

Theorem 4. For any program N we have: M[[N ]] = M[[Op(N )]].

This adequacy theorem diﬀers somewhat from the usual ones where the denotational
semantics determines termination and the denotation of any ﬁnal result; further, for base
types they generally determine the value produced by the operational semantics. In our case
the ﬁrst part is not relevant as terms always terminate. We do have that the denotational
semantics determines the denotation of any ﬁnal result. For base types (as at any type)
it determines the eﬀect values produced up to their denotation, though the extent of that
determination depends on the choice of the generic eﬀects.

29

3.5 Program equivalences and purity

The equational system of Section 3.2, helps prove adequacy, but is too weak for our purposes
which are to establish completeness results for programs of base type. Moggi gave a
suitable consistent and complete system for his computational λ-calculus in [45]. His
system has equational assertions Γ ⊢ M = N : σ and purity (meaning eﬀect-free) assertions
Γ ⊢ M ↓σ; we always assume that the terms are appropriately typed, and may omit types
or environments when the context makes them clear. One can substitute a term M for a
variable in Moggi’s system only if one can prove M ↓σ.

Our λ-calculus is an extension of Moggi’s and we extend his logic correspondingly; an
alternate approach, well worth pursuing, would be to use instead the purely equational
ﬁne-grained variant of the computational λ-calculus: see [41]. We keep Moggi’s axioms
and rules, other than those for computational types T σ, but extended to our language. (If
we set T σ = 1 → σ, then the rules for computational types, extended to our language, are
derived.)

For conditionals we add:

if tt then M else N = M

if ff then M else N = N

For the algebraic operations we add two equations, one:

u(x) = if x then u(tt) else u(ff)

u(op(y1, . . . , yn; M1, . . . , Mn)) = op(y1, . . . , yn; u(M1), . . . , u(Mn))

(16)

expressing their naturality (and generalizing the commutation schema of Figure 2), and
the other:

op(N1, . . . , Nn; M1, . . . , Mm) =

let y1 : b1, . . . , yn : bn be N1, . . . , Nn
in op(y1, . . . , yn; M1, . . . , Mm)

(no yj in any FV(Mi))

(17)
expressing the order of evaluation of the parameter arguments of op. For function symbols
and constants we add the purity axiom c ↓ and the equation in Figure 2. This equation
enables us to evaluate function symbol applications to constants within our proof system.
One could certainly add further useful axioms and rules (e.g., that some function on base
types is commutative or a form of induction if the natural numbers were a base type);
indeed it would be natural to extend to a predicate logic. However, such extensions are
not needed for our purposes.

We write

Γ ⊢Ax M = N : σ and Γ ⊢Ax M ↓σ

to mean M = N (resp. M ↓σ) is provable from a set of equational or purity axioms
In particular all the axioms of Figure 2 are
Ax (where Γ ⊢ M : σ and Γ ⊢ N : σ).
provable. An equational assertion is true (or holds) in M, written Γ |=M M = N : σ if

30

M[[M ]] = M[[N ]]; similarly, a purity assertion is true (or holds) in M, written Γ |=M M ↓σ,
if ∃a ∈ M[[σ]]. M[[M ]](ρ) = ηM (a). A theory, i.e., a set of axioms, Ax is valid in M if all
the assertions in Ax are true in M.

Equational consistency holds, meaning that, if a theory Ax is valid in M then:

Γ ⊢Ax M = N : σ =⇒ Γ |=M M = N : σ

as does the analogous purity consistency.

We can use Ax to give axioms for particular algebraic operations. For example, we con-
sider languages with a binary decision algebraic operation symbol or : ε; 2 with semantics
given by the algebraic operation family orX of Deﬁnition 11. Here the associative axioms

(L or M ) or N = L or (M or N )

hold at all types as, by Theorem 2, every component orX is associative. We will do this
extensively for our two languages, as in Figures 3 and 4, below.

4 A language of choices and rewards

Building on the framework of Section 3, in this section we deﬁne and study a language
with constructs for choices and rewards.

4.1 Syntax

For the basic vocabulary of our language, in addition to the boolean primitives of Sec-
tion 3.1, we assume available: a base type Rew; a constant 0 : Rew; and function symbols
+ : Rew Rew → Rew and ≤: RewRew → Bool. There are exactly two algebraic operation
symbols: a choice operation or : ε; 2 to make binary choices, and a reward operation
reward : Rew; 1, to prescribe rewards. We leave any other base type symbols, constants, or
function symbols unspeciﬁed.

We may use inﬁx for + and ≤. Similarly, we may use inﬁx notations M0 or M1 or N ·M
for the algebraic operation terms or(; M0, M1) and reward(N ; M ). The signature or : ε; 2
means that M0 and M1 must have the same type and that is then the type of M0 orM1;
the signature reward : Rew; 1 means N · M has the same type as M and that N must be
of type Rew. For example, assuming that 5 and 6 are two constants of type Rew, we may
write the tiny program:

(5 · tt)or(6 · ff) : Bool

Intuitively, this program could potentially return either tt or ff, with respective rewards
5 and 6. In the intended semantics that maximizes rewards, then, the program returns ff
with reward 6.

When designing our language, we could as well have used choice functions of any ﬁnite
arity, as in the example in Figure 1. However we felt that binary choice was suﬃciently
illustrative.

31

4.2 Rewards and additional eﬀects

For both the operational and denotational semantics of our language we need a set of
rewards R with appropriate structure and a monad employing it. So, we assume such a
set R is available, and that it is equipped with:

• a commutative monoid structure, written additively, and

• a total order with addition preserving and reﬂecting the order in its ﬁrst argument

(and so, too, in its second), in that, for all r, s, t ∈ R:

r ≤ s ⇐⇒ r + t ≤ s + t

For example, R could be the reals (or the nonnegative reals) with addition, or the positive
reals with multiplication, in all cases with the usual order. We further assume that there is
an element [[c]] of R for each c : Rew (with, in particular, [[0]] = 0), and that R is expressively
non-trivial in that there is a c : Rew with [[c]] 6= 0.

Our monad is the so-called writer monad W(X) = R × X, deﬁned using the commuta-
tive monoid structure on R. The operational semantics deﬁned below evaluates programs
M of type σ to pairs hr, V i, with r ∈ R and V : σ, that is to elements of W(Valσ). The
denotational semantics uses the selection monad augmented with the writer monad, as
described in Section 2.

The writer monad is the free-algebra monad for R-actions, i.e., the algebras with an
R-indexed family of unary operations, which we write as reward(r, −) or r · −, satisfying
the equations

0 · x = x

r · s · x = (r + s) · x

(18)

The resulting algebraic operation (rewardW )X : R × W(X) → W(X) is given by:

(rewardW )X (r, hs, xi) = hr + s, xi

and is induced by the generic eﬀect (gW)reward : R → W([1]), where (gW)reward(r) =def
hr, ∗i. We generally write applications of (rewardW)X using an inﬁx operator, (·W)X , and,
in either case, may drop subscripts when they can be understood from the context. As
R is itself an R-action (setting r · s = r + s), we obtain a W-algebra αW : W(R) → R as
described in Section 2.2, ﬁnding that αW = +.

4.3 Operational semantics

While the operational semantics of Section 3 is ordinary and does not address optimization,
the selection operational semantics selects an optimal choice strategy, as suggested in the
Introduction. Below we prove an adequacy result relative to a denotational semantics using
the selection monad SW. We thereby give a compositional account of a global quantity:
the optimal reward of a program.

32

For the ordinary operational semantics, we assume available functions valf for the func-
tion symbols f of the basic vocabulary, as discussed in Section 3.2. The global operational
semantics selects strategies maximizing the reward they obtain. To deﬁne such strategies
we employ the version of argmax deﬁned in Section 2: given a ﬁnite totally-ordered set S
and a reward function γ : S → R, argmaxX(γ) selects the least s ∈ S maximizing γ(s). So,
totally ordering S by:

s (cid:22)γ s′ ⇐⇒ γ(s) > γ(s′) ∨ (γ(s) = γ(s′) ∧ s ≤ s′)

the selection is of the least element in this total order. It is convenient to use the notation
argmax s : S. e for argmax(λs ∈ S. e).

We next deﬁne our strategies. The idea is to view an eﬀect value E : σ as a one-player

game for Player. The subterms E′ of E are the positions of the game. In particular:

- if E′ is a value, then E is a ﬁnal position and the reward is 0;

- if E′ = E′
position E′

0 or E′
1; and

1 then Player can choose whether to move to the position E′

0 or the

- if E′ = c · E′′ : σ then Player moves to E′′ and [[c]] is added to the ﬁnal reward.

The ﬁnite set Str(E) of strategies of an eﬀect value E is deﬁned by the following rules,

writing s : E for s ∈ Str(E):

∗ : V

s : E1
1s : E1 or E2

s : E2
2s : E1 or E2

s : E
s : c · E

These strategies can be reformulated as boolean functions on choice subterms; though
standard, this is less convenient. Equivalently, one could work with boolean functions on
choice nodes (terms) of the tree naturally associated to a term by the big-step reduction
relation, noting that this tree is isomorphic to eﬀect values considered as trees (as we see
from equivalences 13,14). In this way we would obtain an equivalent optimizing operational
semantics which makes no use of eﬀect values. We preferred to work with eﬀect values as
they provide a convenient way to work directly with trees formulated as terms. There are
also probabilistic strategies, although, as is generally true for MDPs [5], they would not
change the optimal expected reward.

For any eﬀect value E : σ, the outcome Out(s, E) ∈ R × Valσ = W(Valσ) of a strategy

s : E is deﬁned by:

= h0, V i

Out(∗, V )
Out(1s, E1 or E2) = Out(s, E1)
Out(2s, E1 or E2) = Out(s, E2)
Out(s, c · E)

(= ηW(V ))

= rewardW ([[c]], Out(s, E))

33

We can then deﬁne the reward of such a strategy by:

Rew(s, E) = π1(Out(s, E))

Note that π1 : R × X → R can be written as RW(−|0) = αW ◦ W(0X ), with 0X : X → R
the constantly 0 reward function.

As there can be several strategies maximizing the reward of a game, we need a way of
choosing between them. We therefore deﬁne a total order ≤E on the strategies of a given
game E : σ:

• Game is V :

• Game is E1 + E2:

∗ ≤V ∗

(i, s) ≤E1+E2 (j, s′) ⇐⇒

i < j ∨
i = j = 1 ∧ s ≤E1 s′ ∨
i = j = 2 ∧ s ≤E2 s′

• Game is c · E:

s ≤c·E s′ ⇐⇒ s ≤E s′

We can now give our selection operational semantics Ops(M ) ∈ R × Valσ = W(Valσ)
for programs M : σ. We ﬁrst ﬁnd the Op(M )-strategy sopt maximizing the reward; if there
is more than one such strategy, we take the least, according to the Op(M )-strategy total
order ≤Op(M ). So we set:

sopt =def argmax s : Op(M ). Rew(s, Op(M ))

deﬁne and then we use that strategy to deﬁne Ops(M ):

Ops(M ) =def Out(sopt, Op(M ))

In other words we set

Ops(M ) = Out(argmax s : Op(M ). Rew(s, Op(M )), Op(M ))

Note that Ops(M ) = Ops(Op(M )). (This follows from the form of the deﬁnition of the
optimizing operational semantics and the fact that Op2(M ) = Op(M ).)

While the operational semantics is deﬁned by a global optimization over all strategies,
it can be equivalently given locally without reference to any strategies. We ﬁrst need two
lemmas, whose straightforward proofs we omit:

Lemma 6. Given functions X

g
−→ Y

γ
−→ R, for all u, v ∈ X we have

g(u maxγ◦gv) = g(u) maxγ g(v)

34

Lemma 7. (First argmax lemma) Let S1 ∪ S2 split a ﬁnite total order hS, ≤i into two with
S1 < S2 (the latter in the sense that s1 < s2 for all s1 ∈ S1 and s2 ∈ S2). Then, for all
γ : S → R, we have:

argmax γ = argmax (γ|S1) maxγ argmax (γ|S2)

We now have our local characterization of the operational semantics:

Theorem 5. For well-typed eﬀect values we have:

1. Ops(V ) = h0, V i (= ηW(V ))

2. Ops(E1 or E2) = Ops(E1) maxπ1 Ops(E2) (= Ops(E1) maxRW(−|0) Ops(E2)) .

3. Ops(c · E) = rewardW([[c]], Ops(E))

Proof. For Part 1 we calculate:

Ops(V ) = Out(argmax s : V. Rew(s, V ), V )

= Out(∗, V )
= h0, V i

The ﬁrst equality is as Op(V ) = V ; the second is as values V have only one strategy, ∗.

For part 2, we calculate:

Ops(E1 or E2) = Out(argmax s : E1 or E2. Rew(s, E1 or E2), E1 or E2)

= Out

= Out

















argmax 1s : E1 or E2. Rew(1s, E1 or E2)
maxRew(−,E1 or E2)
argmax 2s : E1 or E2. Rew(2s, E1 or E2)



(by the ﬁrst argmax lemma (Lemma 7))



, E1 or E2


argmax 1s : E1 or E2. Rew(s, E1)
maxπ1◦Out(−,E1 or E2)
argmax 2s : E1 or E2. Rew(s, E2)

, E1 or E2






=

=

Out(argmax 1s : E1 or E2. Rew(s, E1), E1 or E2)
maxπ1
Out(argmax 2s : E1 or E2. Rew(s, E2), E1 or E2)

(by Lemma 6)

Out(argmax s : E1. Rew(s, E1), E1)
maxπ1
Out(argmax s : E2. Rew(s, E2), E2)

= Ops(E1) maxπ1 Ops(E2)

35

And for part 3 we calculate:

Ops(c · E) = Out(argmax s : c · E. Rew(s, c · E), c · E)

= rewardW([[c]], Out(argmax s : c · E. [[c]] + Rew(s, E), E))
= rewardW([[c]], Out(argmax s : c · E. Rew(s, E), E))
= rewardW([[c]], Out(argmax s : E. Rew(s, E), E))
= rewardW([[c]], Ops(E))

where the third equality holds as the monoid preserves and reﬂects the ordering of R.

Using this theorem we can show that substitutions of constants for constants can equiv-
alently be done via W. This will prove useful for our investigations of observational equiv-
alence in Section 4.6.

Lemma 8. Suppose E : b is an eﬀect value, and that f : Valb → Valb′. Let g : u ⊆ Conb
be the restriction of f to a ﬁnite set that includes all the constants of type b in E. Then:

Ops(E[g]) = W(f )(Ops(E))

Proof. The proof is by structural induction. In case E is a constant we have:

W(f )(Ops(c)) = W(f )(h0, ci) = h0, f (c)i = Ops(c[g])

In case E has the form E1 or E2 we have:

W(f )(Ops(E1 or E2))

= W(f )(Ops(E1) maxπ1 Ops(E2))
= W(f )(Ops(E1) maxπ1◦W(f ) Ops(E2))
= W(f )(Ops(E1)) maxπ1 W(f )(Ops(E2)))
= Ops(E1[g]) maxπ1 Ops(E2[g])
= SOp(E1[g] or E2[g])
= Ops((E1 or E2)[g])

(by Theorem 5.2)
(as π1 ◦ W(f ) = π1)
(by Lemma 6)

(by Theorem 5.2)

In case E has the form c · E1 we have:

W(f )(Ops(c · E1)) = W(f )([[c]] · Ops(E1))
= [[c]] · (W(f )(Ops(E1))
= [[c]] · Ops(E1[g])
= Ops(c · (E1[g]))
= Ops((c · E1)[g])

(by Theorem 5.3)
(as W(f ) is homomorphic)

(by Theorem 5.3)

36

4.4 Denotational semantics

For the denotational semantics, as discussed in Section 2.1, we need an auxiliary monad
T, here to handle the reward eﬀect. and we take T to be W = R × –, the writer monad,
and we have the W-algebra αW : W(R) → R where αW(hr, si) = r + s as discussed in
Section 4.2. We therefore have a strong monad

and use this monad to give the denotational semantics

S(X) = (X → R) → R × X

ST[[M ]] : ST[[Γ]] → S(ST[[σ]])

(for Γ ⊢ M : σ)

of our language, following the pattern explained in the previous section. (We often drop
the subscript on ST below.)

We assume available semantics of base types, constants, and function symbols, as dis-
[[Rew]] = R; [[c]] as in Section 4.2, for c : Rew;
cussed in Section 3.3 with, in particular:
and [[+]] and [[≤]] the monoid operation and ordering on R. Recall that diﬀerent constants
of the same type are required to receive diﬀerent denotations and that the consistency
condition 15 is required to be satisﬁed.

Turning to the algebraic operation symbols, for or we use the algebraic operation family

orX given by Equation 11, so:

(or)X (G0, G1)(γ) = G0γ maxX,RW(−|γ) G1γ

(19)

where, for any γ : X → R, maxX,γ : X 2 → X is deﬁned by:

x maxX,γ y =

x (if γ(x) ≥ γ(y))
(otherwise)
y

(cid:26)

For reward we take the algebraic operation family (rewardS)X induced by the (rewardW)X ,
so, using Equation 9:

(rewardS)X (r, G)(γ) = (rewardW)X (r, Gγ) = hr + π1(Gγ), π2(Gγ)i

(20)

4.5 Adequacy

We next aim to prove that the selection operational semantics essentially coincides with
its denotational semantics. This coincidence is our selection adequacy theorem.

We need some notation to connect the operational semantics of programs with their
denotations. We set ([[-]]W)σ = W(Sp) : W(Valσ) → W(S[[σ]]). So for u = hr, V i in
R × Valσ = W(Valσ) we have

([[hr, V i]]W)σ = hr, Sp[[V ]]i

37

Lemma 9. For any eﬀect value E : σ we have:

SW[[E]](0) = [[Ops(E)]]W

Proof. We proceed by structural induction on E, and cases according to its form.

1. Suppose E is a value V . Using Theorem 5.1, we calculate:

[[Ops(V )]]W = [[h0, V i]]W = h0, Sp[[V ]]i = ηW(Sp[[V ]]) = ηS(Sp[[V ]])(0) = S[[V ]](0)

2. Suppose next that E = E1 or E2. Then:

[[Ops(E1 or E2))]]W

= [[Ops(E1) maxRW(−|0) Ops(E2)]]W
= [[Ops(E1) maxαW◦W(0) Ops(E2)]]W
= [[Ops(E1) maxαW◦W(0)◦W([[ ]]σ) Ops(E2)]]W
= [[Ops(E1)]]W maxαW◦W(0) [[Ops(E2)]]W
= S[[E1]](0) maxαW◦W(0) S[[E2]](0)
= or[[σ]](S[[E1]], S[[E2]])(0)
= S[[E1or E2)]](0)

(by Theorem 5.2)

(using Lemma 6)
(by induction hypothesis)
(by Equation 19)

3. Suppose instead that E = c · E′. Then:

[[Ops(c · E′)]]W = W(Sp)(Ops(c · E′))

= W(Sp)([[c]] ·W Ops(E′))
= [[c]] ·W W(Sp)(Ops(E′))
= [[c]] ·W S[[E′]](0)
= ([[c]] ·S S[[E′]])(0)
= S[[c · E′]](0)

(by Theorem 5.3)
(as W(Sp) is a homomorphism)
(by induction hypothesis)
(by Equation 20)

Theorem 6 (Selection adequacy). For any program M : σ we have:

SW[[M ]](0) = [[Ops(M )]]W

Proof. We have:

SW[[M ]](0) = SW[[Op(M )]](0)

(by Theorem 4)

= [[Ops(Op(M ))]]W (by Lemma 9)
= [[Ops(M )]]W

38

This theorem relates the compositional denotational semantics to the globally optimiz-
ing operational semantics. In particular, the latter determines the former at the zero-reward
continuation. Whereas the denotational semantics optimizes only locally, as witnessed by
the semantics of or, the latter optimizes over all possible Player strategies. The use of
the zero-reward continuation is reasonable as the operational semantics of a program does
not consider any continuation, and so, as rewards mount up additively, the zero-reward
continuation is appropriate at the top level.

In more detail, setting hr, V i = Ops(M ), the theorem states that ST[[M ]](0) = hr, Sp[[V ]]i.
So the rewards according to both semantics agree, and the denotation of the value returned
by the globally optimizing operational semantics is given by the denotational semantics. In
the case of base types (or, more generally, products of base types) the globally optimizing
operational semantics is determined by the denotational semantics as the denotations of
values of base types determine the values (see Section 3.4), and so, in that case, there is
complete agreement between the operational semantics and the denotational semantics at
the zero-reward continuation.

4.6 Full abstraction, program equivalences, and purity

Given a notion of observations Ob(M ) of programs M : b of a base type b, one can deﬁne a
notion of observational or behavioural equivalence in a standard contextual manner; such
notions are usually syntactical, being derived from operational semantics, though that
is not necessary. Observational equivalence is generally robust against variations in the
notion of observation, and we explore such variations in the context of our decision-making
languages.

So, for such a notion of observations Ob(M ) of programs of base type b, for programs

M, N : σ, deﬁne operational equivalence M (≈b,Ob)σN between them by:

M (≈b,Ob)σN ⇐⇒ ∀C[ ] : σ → b. Ob(C[M ]) = Ob(C[N ])

] ranges over contexts with a single hole, deﬁned in a standard way, and by
(Here C[
C[
] : σ → τ we mean that for any L : σ we have C[L] : τ .) We generally drop the type
subscript σ below. Observational equivalence is an equivalence relation at any type, and
it is closed under contexts, in the sense that for all programs M : σ, N : σ and contexts
C[ ] : σ → τ we have:

M ≈b,Ob N =⇒ C[M ] ≈b,Ob C[N ]

Operational adequacy generally yields the implication:

|=M M = N : b =⇒ Ob(M ) = Ob(N )

and it then follows that

|=M M = N : σ =⇒ M ≈b,Ob N

(21)

(22)

39

As a particular case of this implication we have M ≈b,Ob Op(M ) for programs M : σ. The
converse of the implication 22 is full abstraction (of M with respect to ≈b,Ob) at type σ.
In the case of our language of choice and rewards, we work with observational equiv-
alence at boolean type, and take the notion of observation to be simply the optimizing
operational semantics Ops, and write ≈b for ≈b,Ops, and ≈ for ≈Bool. Note that the se-
lection adequacy theorem (Theorem 6) immediately yields the implication 21 (and so also
implication 22) for SW and Ops, as expected, and we then also have M ≈b Op(M ) for base
types b and programs M : σ.

We next see that, with this notion of observation, observational equivalence is robust
against changes in choice of base type (Proposition 4). We investigate the robustness of
observational equivalence against weakenings of the notion of observation later, observing
either only values (Theorem 8) or only rewards (Corollary 3).

Lemma 10. Suppose that b is a base type with at least two constants. Then for any base
type b′ and programs M1, M2 : b′ we have:

M1 ≈b M2 =⇒ Ops(M1) = Ops(M2)

Proof. Let Ei be Op(Mi) for i = 1, 2. Then E1 ≈b E2 (as Mi ≈b Op(Mi) for i = 1, 2) and
it suﬃces to prove that Ops(E1) = Ops(E2). Suppose that Ops(Ei) = hri, cii for i = 1, 2.
Let f : Valb′ → Valb be such that f (c1) and f (c2) are distinct, in case c1 and c2 are, and
let g be its restriction to the constants of the Ei of type b′. For i = 1, 2, we have:

Ops(FgEi) = Ops(Ei[g])

= W(f )(Ops(Ei))
= hri, f (ci)i

(by Lemma 4)
(by Lemma 8)

As E1 ≈b E2, we have FgE1 ≈b FgE2 and so Ops(FgE1) = Ops(FgE2) and so, from the
above equations for the Ops(FgEi), that hr1, f (c1)i = hr2, f (c2)i. So, as f is 1-1 on {c1, c2},
hr1, c1i = hr2, c2i as required.

As an immediate consequence of this lemma we have the following proposition that

change of non-trivial base type does not aﬀect observational equivalence:

Proposition 4. For all base types b and programs M, N : σ, we have

M ≈ N =⇒ M ≈b N

with the converse holding if there are at least two constants of type b.

Because the denotational semantics is compositional, it facilitates proofs of program
equivalences, including ones that justify program transformations, and more broadly can
be convenient for certain arguments about programs. For this purpose, we rely on the
equivalence relation Γ ⊢Ax M = N : σ described in Section 3.5. As remarked there, our

40

general semantics is equationally consistent. We interest ourselves in a limited converse,
where σ is a base type and M and N are programs; we call this program completeness for
base types.

Our system of axioms, Ax, is given in Figure 3. As shown in Theorem 2, the choice op-
eration is associative and idempotent; from Corollary 1 we have that the reward operation
is an R-action on the S(X) since it is on the W(X); and we see from Theorem 3 that the
reward operation commutes with the choice operation as the monoid addition preserves
and reﬂects the order. This justiﬁes the ﬁrst ﬁve of our axioms. A pointwise argument
then shows that the following equality holds for r, s ∈ R and F, G ∈ S(X), for any set X:

r·F or s·F = t·F (t = max(r, s))

(23)

Using this equality, the left-bias of the choice operation (shown in Theorem 2), and asso-
ciativity, we have:

and another pointwise argument establishes the equation:

(r·F or G) or s·F = r·F or G (r ≥ s)

(r·F or G) or s·F = G or s·F (r < s)

These remarks justify our last two axioms.

(L or M ) or N = L or (M or N )

M or M = M

0 · N = N

x · (y · N ) = (x + y) · N

x · (M or N ) = (x · M ) or (x · N )

if x ≥ y then x · M else y · M = x · M or y · M

if x ≥ z then (x · M or N ) else (N or z · M ) = (x · M or N ) or z · M

Figure 3: Equations for choices and rewards

Some useful consequences of these equations, mirroring the equalities 23–25, are:

c · M or c′ · M = c′′ · M (where [[c′′]] = max([[c]], [[c′]]))

(c · M or N ) or c′ · M = c · M or N (if [[c]] ≥ [[c′]])

(c · M or N ) or c′ · M = N or c′ · M (if [[c]] < [[c′]])

(24)

(25)

(R1)

(R2)

(R3)

Our equational system allows us to put programs into a canonical form. We say that
such a term is in canonical form if (ignoring bracketing of or) it is an eﬀect value of the
form

(c1 · V1) or . . . or (cn · Vn)

41

with n > 0 and no Vi occurring twice.

Lemma 11. Every program M is provably equal to a canonical form CF(M ).

Proof. By the ordinary adequacy theorem (Theorem 4), M can be proved equal to an eﬀect
value E. Using the associativity equations, the fact that reward and or commute, and the
R-action equations, E can be proved equal to a term of the form c1 · V1 or . . . or Vn · dn,
possibly with some V ’s occurring more than once. Such duplications can be removed using
equations R1, R2, and R3 and associativity.

The next theorem shows that, for programs of base type, four equivalence relations
coincide, and thereby simultaneously establishes for them: a normal form for provable
equality; completeness of our proof system for equations between such programs; and full
abstraction.

Theorem 7. For any two programs M and N of base type b, the following equivalences
hold:

CF(M ) = CF(N ) ⇐⇒ ⊢Ax M = N : b ⇐⇒ |=S M = N : b ⇐⇒ M ≈ N

Proof. We already know the implications from left-to-right hold. So it suﬃces to show
that:

CF(M ) 6= CF(N ) =⇒ M 6≈ N

First ﬁx l, r : Rew with l < r (possible as R is expressively non-trivial). We remark that, in
general, to prove A 6≈ B for A, B : σ it suﬃces to to prove A′ 6≈ B′ if we have ⊢Ax A = A′ : σ
and ⊢Ax B = B′ : σ. We use this fact freely below. We also ﬁnd it convenient to confuse
sums of Rew constants with their denotations.
Let the canonical forms of M and N be

A = (c1 · d1) or . . . or (cn · dn)

and B = (c′

1 · d′

1) or . . . or (c′

n′ · d′

n′)

and suppose they are diﬀerent. It suﬃces to prove that A 6≈ B. Suppose, ﬁrst, that for
some i0, di0 is no d′
j. Choose c to be the maximum of the ci and the c′
j, other than ci0.
Consider the context:

C1[−] =def if [−] = di0 then (c + r) · tt else (ci0 + l) · tt

As ci+(ci0 +l) < ci0 +(c+r), we have π1(Ops(C1[A])) = ci0 +c+r. Further π1(Ops(C1[B])))
is the maximum of the c′
j + ci0 + l and so < ci0 + c + r = Ops(C1[A])). So we see that
A 6≈ B in this case.

Suppose, instead, that for some i0, di0 is d′

j0. Then we
ﬁnd that π1(Ops(C1[A])) = ci0 + c + r, as before, and that π1(Ops(C1[B])) is the maximum
j0 + (c + r), which is c′
of the c′
j0 + (c + r), and so we have again
distinguished A and B.

j0 for some j0 but that ci0 < c′

j + (ci0 + l), for j 6= j0 and c′

42

So, we may assume that for every 1 ≤ i ≤ n there is a 1 ≤ j ≤ n′ such that di = d′

j and
j. Arguing symmetrically, and recalling that none of the di are repeated, and neither
j, we see that we may assume that n = n′ and that (c1 · d1), . . . , (cn · dn)

ci ≥ c′
are any of the d′
1 · d′
and (c′

1), . . . , (c′

n · d′

n) are permutations of each other.

For the last case, suppose there is a ﬁrst point i0 at which A and B diﬀer. We can then

write them as:

and

A = A0 or ci0 · di0 or A1 or ci1 · di1 or A2

i0 or B1 or c′
i2 · d′
with di0 6= d′
i2 = ci0 · di0, and where we allow any of
A0, A1, A2, B1 or B2 to be either a canonical form or the empty sequence, and, continuing
to ignore parentheses, interpret A or B and B or A as B when A is empty and B is not.

B = A0 or c′
i0 · d′

i0 · d′
i0, and c′

i0, ci1 · di1 = c′

i2 or B2

i2 · d′

Let c be the maximum of the ci and the c′

i, except for ci0 and c′

i0, and consider the

context

C2[−] =def

let x : b be [−] in
if x = di0 then (c + c′
i0 + r) · tt else
if x = d′
then (c + ci0 + r) · ff else
i0
(ci0 + c′
i0 + l) · ff

Then C2[A] is provably equal to

(c1 · d1) or . . . or (cn · dn)

where

ci0 · di0 = (ci0 + c + c′
ci1 · di1 = (c′
ci · di

= (ci + ci0 + c′

i0 + r) · tt
i0 + c + ci0 + r) · ff

i0 + l) · ff (i 6= i0, i1)

and we see that Ops(C2[A]) = hci0 + c + c′
Further, C2[B] is provably equal to

i0 + r, tti.

(c′

1 · d

′
1) or . . . or (c′

′
n · d
n)

where

′
c′
i0 = (c′
i0 · d
′
c′
i2 = (ci0 + c + c′
i2 · d
′
i + ci0 + c′
c′
i · d
i

i0 + c + ci0 + r) · ff
i0 + r) · tt
i0 + l) · ff (i 6= i0, i2)

= (c′

and we see that Ops(C2[B]) = hc′
concluding this ﬁnal case.

i0 + c + ci0 + r, ffi. So C2[−] distinguishes A and B,

43

Theorem 7 is in the spirit of [42] in giving axiomatic and denotational accounts of
observational equivalence at base types, though here at the level of terms rather than, as
there, only eﬀect values. (A natural axiomatic account of the observational equivalence
of eﬀect values at base types can be given by specializing the above axioms to them,
including R1, R2, and R3, but deleting the last two in Figure 3.)

Theorem 7 holds a little more generally: for products of base types. The proof remains
the same, using the fact that equality at any product of base types can be programmed
using equality at base types. It follows that we have full abstraction at products of base
types, i.e., for all programs of types of order 0. A standard argument then shows that full
abstraction holds for values of types of order 1; whether or not it holds for programs of
types of order 1 is, however, open.

As a corollary of Theorem 7 we have completeness for purity (i.e., eﬀect-freeness) as-

sertions at base types. Indeed we have it in a strong form:

Corollary 2. For any program M : b, we have:

|=S M ↓ b =⇒ ∃ c : b ⊢Ax M = c

Proof. Suppose |=S M ↓ b. That is, for some x ∈ [[b]], S[[M ]] = ηSW (x) = λγ. h0, xi. For
some r ∈ R and c : b, Ops(M ) = hr, ci. So, by adequacy we have:

S[[M ]](0) = [[Ops(M )]]W = [[hr, ci]]W = hr, [[c]]i

As S[[M ]] = λγ. h0, xi we therefore have r = 0 and [[c]] = x and so |=W M = c. It then
follows from Theorem 7 that ⊢Ax M = c.

As may be expected, more generally we have strong purity completeness for products

of base types, i.e., for any M : σ where σ is a product of base types we have:

|=S M ↓ σ =⇒ ∃ V : σ ⊢Ax M = V

and, indeed, this is a straightforward consequence of the corollary.

A natural question is whether, instead of using the selection monad ST, we can treat
the choice operator at the same level as the reward one, say using a suitable free-algebra
monad. This can be done, to some extent, by making use of Theorem 7 and the equations
we have established for these operations at the term level. Consider an equational system
with a binary (inﬁx) operation symbol − or − and an R-indexed family of unary operation
symbols r·− (r ∈ R), and impose Equations 18, associativity and commutativity equations:

x or (y or z) = (x or y) or z

r · (x or y) = r · x or r · y

and equations corresponding to Equations R1, R2, and R3:
= max(r, r′) · x
r · x or r′ · x
(if r ≥ r′′)
(r · x or r′ · y) or r′′ · x = r · x or r′ · y
(r · x or r′ · y) or r′′ · x = r′ · y or r′′ · x (if r < r′′)

44

Let C be the resulting free-algebra monad, and let C be the corresponding denotational
semantics. One can show that for for all eﬀect values E, E′ : b of a base type b we have:

|=C E = E′ ⇐⇒ ⊢Ax E = E′ : b

Using Theorems 4 and 7 we then obtain a version of Theorem 7 for C, that, for any two
programs M and N of base type b:

⊢Ax M = N : b ⇐⇒ |=C M = N : b ⇐⇒ M ≈ N

However we do not obtain an adequacy theorem analogous to the adequacy theorem
(Theorem 6) which relates the operational semantics to the selection monad semantics at
the zero-reward continuation. Consider, for example, the two boolean eﬀect values tt and
tt or ff. Operationally they both evaluate to tt. But they have diﬀerent S-semantics as
the second value is sensitive to the choice of reward continuation. They therefore have
diﬀerent C-semantics, i.e., in this sense the C-semantics is not sound. An alternative would
be to extend the operational semantics of programs to take a reward continuation into
account, as done in [42]; however such an extension would be in tension with the idea that
programs should be executable without additional information.

Turning to weakening the notion of observation, we may observe either just the reward
or just the ﬁnal value, giving two weakened notions of observation Obr = π1 ◦ Ops, for the
ﬁrst, and Obv = π2 ◦ Ops, for the second. We begin by investigating observing only values.

Lemma 12. For programs M, N : Bool we have:

M1 ≈Obv M2 =⇒ Ops(M1) = Ops(M2)

Proof. As Obv is weaker than Ops the implication 21 holds for SW and it. We can therefore
assume without loss of generality that M1 and M2 are eﬀect values, E1 and E2, say. Suppose
Ops(Ei) = hri, cii (i = 1, 2).

Assume E1 ≈Obv E2. We then have c1 = c2 = tt, say. Suppose, for the sake of
contradiction, that r1 6= r2, and then, without loss of generality, that r1 < r2. Deﬁne
f : ValBool → ValBool to be constantly ff. Then we have

Obv(E1 or Ff E2) = π2(Ops(E1 or Ff E2))

= π2(Ops(E1) maxπ1 Ops(Ff E2))
= π2(hr1, tti maxπ1 Ops(E2[f ]))
= π2(hr1, tti maxπ1 W(f )(Ops(E2)))
= π2(hr1, tti maxπ1 hr2, ffi)
= ff

(by Theorem 5.2)
(by Lemma 4)
(by Lemma 8)

and, similarly,

Obv(E2 or Ff E2) = π2(hr2, tti maxπ1 hr2, ffi)

= tt

yielding the required contradiction, as E1 ≈Obv E2.

45

It immediately follows that observing only values does not weaken the notion of obser-

vational equivalence.

Theorem 8. For programs M, N : Bool we have:

M ≈ N ⇐⇒ M ≈Obv N

To investigate observing only rewards, we consider another free algebra monad, Mr.
It is the free algebra monad for the equational system with a binary (inﬁx) associative,
commutative, absorptive binary operation − or − which forms a module relative to the
max-plus structure of R, meaning that there is an R-indexed family of unary operation
symbols r · − (r ∈ R) forming an R-action and with the following two equations holding:

r · (x or y) = r · x or r · y

r · x or r′ · x = max(r, r′) · x

We write Mr for the associated denotational semantics of our language with rewards.

Lemma 13. For any programs M1, M2 : b of base type, we have:

Mr(M1) = Mr(M2) =⇒ Obr(M1) = Obr(M2)

Proof. Assume Mr(M1) = Mr(M2). We can assume M1 and M2 are eﬀect values, say E1
and E2. These eﬀect values take their denotations in the free algebra Mr([[b]]). They can be
considered as algebra terms if we add the constants c : b in E1 and E2 to the signature and
identify the constants c : Rew occurring in subterms of the form c·E with their denotations.
With that, their denotations are the same as their denotations in the free algebra extended
so that the two denotations of the constants agree. So, as their denotations are equal, they
can be proved equal in equational logic using closed instances of the axioms. We show by
induction on the size of proof that if E = E′ is so provable, then Obr(E) = Obr(E′).

Other than commutativity, all closed instances E = E′ of the axioms hold in S and
so Ops(E) = Ops(E′) for such instances. By Theorem 5.2, for any eﬀect values E, E′ : b
we have Obr(E or E′) = Obr(E) max Obr(E′), and so Obr(E or E′) = Obr(E or E′) for all
closed instances E or E′ = E or E′ of commutativity. The only remaining non-trivial cases
are the congruence rules. For that for choice we again use Theorem 5.2; for that for rewards
we use Theorem 5.3, which implies Obr(r · E) = r + Obr(E), for any eﬀect value E : b.

Theorem 9. For any programs M1, M2 : b of base type, we have:

Mr(M1) = Mr(M2) ⇐⇒ M1 ≈Obr M2

Proof. The implication from left to right follows immediately from Lemma 13. For the
converse, suppose that M1 ≈Obr M2. We can assume M1 and M2 are eﬀect values, say
E1 and E2. Let A1 = (c1 · d1) or . . . or (cn · dn) and A2 = (c′
n′) be
their normal forms. As the program equivalences used to put eﬀect values of base type in

1) or . . . or (c′

n′ · d′

1 · d′

46

normal form follow from those true in Mr, we have Mr(Ei) = Mr(Ai) (i = 1, 2). So, as
E1 ≈Obr E2 we have A1 ≈Obr A2, using the implication from left to right. The ﬁrst part
of the proof of Theorem 7 that the two normal forms considered there are identical up to
a permutation only uses the reward part of the observation notion Ops. So, reasoning as
there, but now with Obr replacing Ops, we see that (c1 · d1), . . . , (cn · dn) is a permutation
of (c′
n′). As the commutativity program equivalence holds in Mr, we
therefore have Mr(A1) = Mr(A2) and so Mr(E1) = Mr(E2), concluding the proof.

1), . . . , (c′

n′ · d′

1 · d′

Corollary 3. The selection monad semantics augmented with auxiliary monad the writer
monad W is not fully abstract at base types for ≈Obr (and so ≈Obr is strictly weaker than
≈). Indeed for programs M, N : σ of any type we have:

So, if we only care about optimizing rewards, we may even assume that or is commu-

M or N ≈Obr N or M

tative.

5 Adding probabilities

We next extend the language of choices and rewards by probabilistic nondeterminism.
Thus, we have the three main ingredients of MDPs, though in the setting of a higher-
order λ-calculus rather than the more usual state machines. We proceed as in the previous
section, often reusing notation.

5.1 Syntax

For the syntax of our language, in addition to the basic vocabulary and algebraic oper-
ations of the language of Section 4.1, we assume available algebraic operation symbols
+p : ε, 2 (p ∈ [0, 1]) and function symbols ⊕p : Rew Rew → Rew (p ∈ [0, 1]). We use inﬁx
notation for both the +p and the ⊕p. The former are for binary probabilistic choice. The
latter are for the convex combination of rewards; they prove useful for the equational logics
given in Section 5.7. (For example, see Equations 33 and 34.) As before, we leave any other
base type symbols, constants, or function symbols unspeciﬁed.

For example (continuing an example from Section 4.1), we may write the tiny program:

(5 · tt) or ((5 · tt) +.5 (6 · ff))

Intuitively, like the program of Section 4.1, this program could return either tt or ff, with
respective rewards 5 and 6. Both outcomes are possible on the right branch of its choice,
each with probability .5. The intended semantics aims to maximize expected rewards, so
that branch is selected.

This example illustrates how the language can express MDP-like transitions. In MDPs,
at each time step, the decision-maker chooses an action, and the process randomly moves

47

to a new state and yields rewards; the distribution over the new states depends on the
current state and the action. In our language, all decisions are binary, but bigger decisions
can be programmed from them. Moreover, the decisions are separate from the probabilistic
choices and the rewards, but as in this example it is a simple matter of programming to
combine them. A more complete encoding of MDPs can be done by adding primitive
recursion to the language, as suggested in the Introduction.

5.2 Rewards and additional eﬀects

As in Section 4.2 for both the operational and denotational semantics of our language we
need a set of rewards R with appropriate structure and a monad employing it. To specify
the structure we require on R, we employ the notion of a barycentric commutative monoid.
Barycentric algebras (also called convex algebras) are equipped with binary probabilistic
choice functions +p : R2 → R (p ∈ [0, 1]) such that the following four equations hold:

x +1 y
x +p x
x +p y
(x +p y) +q z = x +pq (y + (1−p)q
1−pq

= x
= x
= y +1−p x

z)

(p, q < 1)

Barycentric commutative monoids are barycentric algebras further equipped with a com-
mutative monoid structure such that the monoid operation distributes over probabilistic
choice, i.e., writing additively:

r + (s +p s′) = (r + s) +p (r + s′)

Barycentric algebras, introduced by Stone in [51], provide a suitable algebraic structure
for probability. They are equivalent to convex spaces (also called convex algebras), which
n
are algebras equipped with operations
i=1 pi = 1), sub-
ject to natural axioms [48]; we use the two notations interchangeably. Any mathematical
expression built up using the operations of convex spaces from mathematical expressions
n
i=1 piei using the axioms of convex spaces
ei (n > 0, i = 1, n) can be rewritten in the form
(and uniquely so if the ei do not involve the operations of convex spaces). For information
on the extensive history of these concepts see [50, 37].

n
i=1 pixi (where pi ∈ [0, 1] and

P

P

P

Barycentric commutative monoids appear in the semantics of programming languages
with probabilistic choice and nondeterminism and in categorical treatments of probability
(for example, see [52, 37, 16, 35, 15]).

Turning to our assumptions on rewards, we assume a set R of rewards is available, and

that it is equipped with:

• a barycentric commutative monoid structure, and

48

• a total order with probabilistic choice and addition preserving and reﬂecting the order

in their ﬁrst argument (and so too in their second), in that, for all r, s, t ∈ R:

r ≤ s ⇐⇒ r +p t ≤ s +p t

(p ∈ (0, 1))

and

r ≤ s ⇐⇒ r + t ≤ s + t

(Note the restriction on p in the above condition on probabilistic choice.) In the three
examples of Section 4.2 (where the domain of R is the set of reals, nonnegative reals,
or positive reals, respectively), probabilistic choice can be deﬁned using the usual convex
combination of real numbers: r +p s = pr + (1 − p)s. As in Section 4.2 we further assume
that there is an element [[c]] of R for each c : Rew (with, in particular, [[0]] = 0), and that
R is expressively non-trivial.

Our monad is the combination

DW(X) =def Df (R × X)

of the ﬁnite probability distribution monad with the writer monad for both operational
and denotational semantics. Our selection operational semantics, deﬁned below, evaluates
programs M of type σ to ﬁnite distributions of pairs hr, V i, with r ∈ R and V : σ, that is
to elements of DW(Valσ). The monad is the free-algebra monad for barycentric R-modules.
These are algebras with: an R-indexed family of unary operations, written as reward(r, −)
or r · −, forming an R-action (Equation 18); and a [0, 1]-indexed family − +p − of binary
operations forming a barycentric algebra over which the R-action distributes, i.e., with the
following equation holding:

r · (x +p y) = r · x +p r · y

(26)

The resulting monad has unit (ηDW)X(x) = δh0,xi; the extension to DW(X) of a map
f : X → A to an algebra A is given by

n

f †DW (

Xi=1

n

pihri, xii) =

pi(ri · f (xi))

Xi=1

(We used the Dirac distribution δz here; below, as is common, we just write z.) With the
assumptions made on R, it forms a barycentric R-module. Viewing R as a DW-algebra,
αDW : DW(R) → R, we have αDW = (idR)†DW ; explicitly:

n

n

αDW(

pihri, sii) =

pi(ri + si)

Xi=1

Xi=1

The two DW-algebraic operations are:

n

n

(rewardDW)X (r,

pi(ri, xi)) =

pi(r + ri, xi)

(+pDW)X (µ, ν) = pµ + (1 − p)ν

Xi=1

Xi=1

49

They are induced by the generic eﬀects

(gDW)reward : R → DW([1])

(gDW)+ : [0, 1] → DW([2])

where (gDW)reward(r) = hr, ∗i and (gDW)+(p) = ph0, 0i + (1 − p)h0, 1i. We generally write
(rewardDW)X using an inﬁx operator (·DW)X, as in Section 4.2.

5.3 Operational semantics

For the ordinary operational semantics, as in Section 4.3 we assume available functions
valf for the function symbols f of the basic vocabulary, as discussed in Section 3.2. For
the selection operational semantics, we again take a game-theoretic point of view, with
Player now playing a game against Nature, assumed to make probabilistic choices. Player
therefore seeks to optimize their expected rewards. Eﬀect values E : σ are regarded as
games as before, but with one additional clause:

- if E = E1 +p E2, it is Nature’s turn to move. Nature picks E1 with probability p,

and E2 with probability 1 − p.

To account for probabilistic choice we add a rule to the deﬁnition of strategies:

s1 : E1
s2 : E2
(s1, s2) : E1 +p E2

(Player will need a strategy for whichever move Nature chooses) and a case to the deﬁnition
of the total orders on strategies:

• Game is E1 +p E2:

(s1, s2) ≤E1 +p E2 (s′

1, s′

2) ⇐⇒ s1 <E1 s′

1 ∨ (s1 = s′

1 ∧ s2 ≤E2 s′
2)

For any eﬀect value E : σ, the outcome Out(s, E) of a strategy s : E is a ﬁnite
probability distribution over R × Valσ, i.e., an element of Df (R × Valσ). It is deﬁned by:

Out(∗, V )
Out(1s, E1 or E2)
Out(2s, E1 or E2)
Out(s, c · E)
Out((s1, s2), E1 +p E2) = p Out(s1, E1) + (1 − p) Out(s2, E2)

= h0, V i
= Out(s, E1)
= Out(s, E2)
= [[c]] ·Valσ Out(s, E)

The expected reward of a ﬁnite probability distribution on R × X, for a set X, is

EX

n

Xi=1

pi(ri, xi)

!

n

=def

piri

Xi=1

50

 
Note that E : Df (R × X) → R can be written as RDW(−|0) (= αDW ◦ DW(0)), similarly
to how π1 : R × X → R could be in Section 4.3. The expected reward of a strategy is:

Rew(s, E) =def E(Out(s, E))

Our selection operational semantics, Ops(M ) ∈ R × Valσ for M : σ, is deﬁned as before

by:

Ops(M ) = Out(argmax s : Op(M ). Rew(s, Op(M )), Op(M ))

where we are now, as anticipated, maximizing expected rewards.

We remark that, now that probabilistic choice is available, we could change our strate-
gies to make a probabilistic choice for eﬀect values E1 or E2. However, as with Markov
decision processes [25], that would make no change to the optimal expected reward. It
would, however, make a diﬀerence to the equational logic of choice if we chose with equal
probability between eﬀect values with equal expected reward: choice would then be com-
mutative, but not associative.

Much as in Section 4, we now develop a local characterization of the globally optimizing
selection operational semantics. We give this characterization in Theorem 10, below; it is
analogous to Theorem 5 in Section 4. Some auxiliary lemmas are required. The ﬁrst of
them is another argmax lemma enabling us to deal with strategies for probabilistic choice.

Lemma 14. (Second argmax lemma) Let P and Q be ﬁnite total orders, let P × Q be given
the lexicographic ordering, and suppose γ : P × Q → R. Deﬁne g : P → Q, u ∈ P and
v ∈ Q by:

Then:

g(u) = argmax v : Q. γ(u, v)
u
v

= argmax u : P. γ(u, g(u))
= g(u)

(u, v) = argmax (u, v) : P × Q. γ(u, v)

Proof. Consider any pair (u0, v0). By the deﬁnition of g we have g(u0) (cid:22) v0 in the sense
that:

(γ(u0, g(u0)) > γ(u0, v0) ∨ (γ(u0, g(u0)) = γ(u0, v0) ∧ g(u0) ≤ v0)

and it follows that (u0, g(u0)) (cid:22)γ (u0, v0).

Next, by the deﬁnition of u we have u (cid:22) u0 in the sense that:

(γ(u, g(u)) > γ(u0, g(u0)) ∨ (γ(u, g(u)) = γ(u0, g(u0)) ∧ u ≤ u0)

and it follows that (u, g(u)) (cid:22)γ (u0, g(u0)).
(The only non-obvious point may be that
in the case where γ(u, g(u)) = γ(u0, g(u0)), we have u ≤ u0, so either u < u0, when
(u, g(u)) <γ (u0, g(u0)) or else u = u0, when (u, g(u)) = (u0, g(u0)).)

51

So, as v = g(u), we have

(u, v) = (u, g(u)) (cid:22)γ (u0, g(u0)) (cid:22)γ (u0, v0)

establishing the required minimality of (u, v).

The next lemma concerns expectations for probability distributions constructed by the

reward and convex combination operations.

Lemma 15. We have:

1. Rew(s, c · E) = [[c]] + Rew(s, E)

2. Rew(isi, E1 or E2) = Rew(si, Ei)

(i = 1, 2)

3. Rew((s1, s2), E1 +p E2) = pRew(s1, E1) + (1 − p)Rew(s2, E2)

Proof. The second part is evident. For the other two, using the fact that E is a homomor-
phism, we calculate:

Rew(s, c · E) = E(Out(s, c · E))

= E([[c]] · Out(s, ·E))
= [[c]] + E(Out(s, ·E))
= [[c]] + Rew(s, E)

and

Rew((s1, s2), E1 +p E2) = E(Out((s1, s2), E1 +p E2))

= E(p Out(s1, E1) + (1 − p) Out(s2, E2))
= pE(Out(s1, E1)) + (1 − p)E(Out(s2, E2))
= pRew(s1, E1) + (1 − p)Rew(s2, E2)

Theorem 10. The following hold for well-typed eﬀect values:

1. Ops(V ) = h0, V i (= ηDW(V ))

2. Ops(E1 or E2) = Ops(E1) maxE Ops(E2) (= Ops(E1) maxRDW(−|0) Ops(E2))

3. Ops(c · E) = [[c]] · Ops(E)

4. Ops(E1 +p E2) = pOps(E1) + (1 − p)Ops(E2)

Proof.

1. The proof here is the same as the corresponding case of Theorem 5.

2. The proof here is the same as that of the corresponding case of Theorem 5, except

that π1 is replaced by E.

52

3. The proof here is again the same as that of the corresponding case of Theorem 5,

except that we use Lemma 15 to show that Rew(s, c · E) = [[c]] + Rew(s, E).

4. We just consider the fourth case. We have:

Ops(E1 +p E2) =

Out(argmax (s1, s2) : E1 +p E2. Rew((s1, s2), E1 +p E2), E1 +p E2)

So, following the second argmax lemma (Lemma 14), we ﬁrst consider the function

f (s1, s2) =def Rew((s1, s2), E1 +p E2) = pRew(s1, E1) + (1 − p)Rew(s2, E2)

where the second equality holds by Lemma 15. We then consider the function:

g(s1) =def argmax s2 : E2. f (s1, s2)

= argmax s2 : E2. pRew(s1, E1) + (1 − p)Rew(s2, E2)
= argmax s2 : E2. Rew(s2, E2)

where the second equality holds as convex combinations are order-preserving and
reﬂecting in their second argument. Finally we consider

s1 =def argmax s1 : E1. f (s1, g(s1))

= argmax s1 : E1. pRew(s1, E1) + (1 − p)Rew(g(s1), E2)
= argmax s1 : E1. Rew(s1, E1)

where the last equality holds as convex combinations are order-preserving and re-
ﬂecting in their ﬁrst argument, and as g(s1) is independent of s1.

So setting

s2 = g(s1) = argmax s2 : E2. Rew(s2, E2)

by the second argmax lemma (Lemma 14) we have:

(s1, s2) = argmax (s1, s2) : E1 +p E2. Rew((s1, s2), E1 +p E2)

so we ﬁnally have:

Ops(E1 +p E2) = Out((s1, s2), E1 +p E2)

= pOut(s1, E1) + (1 − p)Out(s2, E2)
= pOut(argmax s1 : E1. Rew(s1, E1), E1)

+(1 − p)Out(argmax s2 : E2. Rew(s2, E2), E2)

= pOps(E1) + (1 − p)Ops(E2)

There is an analogous lemma to Lemma 8, that substitutions of constants for constants

can equivalently be done via DW.

53

Lemma 16. Suppose E : b is an eﬀect value, and that f : Valb → Valb′.

1. EValb′ = EValb ◦ DW(f )

2. Let g : u ⊆ Conb be the restriction of f to a ﬁnite set that includes all the constants

of type b in E. Then:

Ops(E[g]) = DW(f )(Ops(E))

Proof. The ﬁrst part is a straightforward calculation. The proof of the second part is by
structural induction on E. The only non-trivial case is where E = E1 or E2. We calculate:

Ops((E1 or E2)[g]) = Ops(E1[g] or E2[g])

= Ops(E1[g]) maxEValb′ Ops(E2[g])

(By Theorem 10.2)
= DW(f )(Ops(E1)) maxEValb′ DW(f )(Ops(E2))

(by induction hypothesis)

= DW(f )(Ops(E1) maxEValb′ ◦DW(f ) Ops(E2))
= DW(f )(Ops(E1) maxEValb

Ops(E2))
(by Lemma 6)

= DW(f )(Ops(E1 or E2))

(By Theorem 10.2)

5.4 Denotational semantics

For the denotational semantics we consider three auxiliary monads T1, T2, and T3, cor-
responding to three notions of observation with varying degrees of correlation between
possible program values and expected rewards. Consider, for example, the eﬀect value
1 · tt +0.5 (2 · ff +0.4 3 · tt). With probability 0.5 this returns tt with reward 1, with proba-
bility 0.2 it returns ff with reward 2, and with probability 0.3 it returns tt with reward 3.
This level of detail is recorded using DW as our ﬁrst monad. At a much coarser grain, we
may simply record that tt and ff are returned with respective probabilities 0.8 and 0.2,
and that the overall expected reward is 1.8. This level of detail is recorded using our third
monad T3. At an intermediate level we may record the same outcome distribution and
the expected reward given a particular outcome (in the example, the expected reward is
1.4, given outcome tt, and 2, given outcome ff). This level of detail is recorded using our
second monad T2.

We work with a general auxiliary monad, and then specialize our results to the Ti.
Speciﬁcally, we assume we have: a monad T; T-generic eﬀects (gT)reward : R → T([1]) and
(gT)+p ∈ T([2]), with corresponding algebraic operations

(rewardT)X : R × T(X) → T(X)

(+pT)X : T(X)2 → T(X)

54

together with a T-algebra αT : T(R) → R, such that, using evident inﬁx notations:

A1 For any set X, (rewardT)X : R × T(X) → T(X) and (+pT)X : T(X)2 → T(X) form

a barycentric R-module.

A2 The algebra map αT : T(R) → R is a barycentric R-module homomorphism, i.e., for

x, y ∈ T(R) we have:

αT(r · x) = r + αT(x)

αT(x +p y) = αT(x) +p αT(y)

So we have the anticipated strong monad

S(X) = (X → R) → T(X)

We assume available semantics of base types, constants, and function symbols, as discussed
for the language without probability in Section 4.4 with, additionally, the function symbols
⊕p denoting the corresponding convex combination operations on R. As before, diﬀerent
constants of the same type are required to receive diﬀerent denotations and the consistency
condition 15 is required to be satisﬁed.

As regards the algebraic operation symbols, for or we use the algebraic operation or

given by Equation 11, so

(or)X (G0, G1)(γ) = G0γ maxX,RT(−|γ) G1γ

(27)

For reward and +p we take the algebraic operations (rewardS)X and (+pS)X induced by
the (rewardT)X and (+pT)X , so:

and

(rewardS)X (r, G)(γ) = (rewardT)X (r, Gγ)

(+pS)X (F, G)(γ) = (+pT)X (F (γ), G(γ))

As mentioned above, our ﬁrst monad is T1 =def DW. With its associated generics for
reward and probabilistic choice and T-algebra it evidently satisﬁes the two assumptions
A1 and A2.

Writing supp(ν) for the support of a probability distribution ν, our second monad is

T2(X) = {hµ, ρi | µ ∈ Df (X), ρ : supp(µ) → R}

It is the free-algebra monad for algebras with an R-indexed family of unary operations,
written as reward(r, −) or r · −, and a [0, 1]-indexed family − +p − of binary operations
satisfying the equations for DW together with the equation:

r · x +p s · x = (r +p s) · x

(28)

55

The two T2(X)-algebraic operations are:

and

where:

(rewardT2)X(r, hµ, ρi) = hµ, x 7→ r + ρ(x)i

(+pT2

)X(hµ, ρi, hµ′, ρ′i) = hpµ + (1 − p)ν, ρ′′i

ρ′′(x) =




ρ(x) +q ρ′(x)
ρ(x)
ρ′(x)

(x ∈ supp(µ) ∩ supp(µ′))
(x ∈ supp(µ)\supp(µ′))
(x ∈ supp(µ′)\supp(µ))

where q = pµ(x)/(µ(x) +p µ′(x)). One can then show that:



n

pihµi, ρii = hµ, ρi

(29)

where µ =

P

n
i=1 piµi and, for x ∈ supp(µ):

Xi=1

ρ(x) =

Xsupp(µi) ∋ x

piµi(x)
µ(x)

ρi(x)

The resulting monad has unit (ηT2)X (x) = hx, x 7→ 0}i; the extension to T2(X) of a

map f : X → A to an algebra A is given by

f †T2 (µ, ρ) =

µ(x)(ρ(x) · f (x))

Xx∈supp(µ)

and for any f : X → Y we have:

where

T2(f )(µ, ρ) = hDf (µ), ρ′i

ρ′(y) =

f (x)=y µ(x)ρ(x)
Df (µ)(y)

P

(y ∈ supp(Df (µ)))

Equation 28 holds for R, using commutativity and homogeneity, so we can take the

algebra map αT2 to be id

†T2
R ; explicitly we ﬁnd:

αT2

n

Xi=1

piri, ρ

!

n

=

pi(ρ(ri) + ri)

Xi=1

Our third monad T3(X) = Df (X) × R is the free-algebra monad for algebras with an
R-indexed family of unary operations, written as reward(r, −) or r · −, and a [0, 1]-indexed
family − +p − of binary operations satisfying the equations for DW and the equation:

r · x +p s · y = (r +p s) · x +p (r +p s) · y

(30)

56

 
The two T3(X)-algebraic operations are:

(rewardT3)X (r, hµ, si) = hµ, r + si

and

(+pT3
One can then show that:

)X (hµ, ri, hν, si) = hpµ + (1 − p)ν, pr + (1 − p)si

n

n

n

pihµi, rii = h

pi,

µi, rii

(31)

Xi=1
The resulting monad has unit

Xi=1

Xi=1

(ηT3 )X(x) = hx, 0i

the extension to T3(X) of a map f : X → A to an algebra A is given by

and

f †T3 (

pixi, r) = r ·

pif (xi)

X

X

T3(f )(h

pixi, ri) = h

pif (xi), ri

X

X

Unfortunately Equation 30 need not hold for R with the assumptions made on it so far;
indeed, while it does hold for the two examples with the reals and addition, it does not
hold for the example of the positive reals and multiplication. When dealing with T3 we
therefore assume additionally that R satisﬁes Equation 30, and so we can take αT3 to be
id

†T3
R ; explicitly we ﬁnd:

αT3

n

Xi=1

piri, r

!

= r +

n

Xi=1

piri

!

Deﬁne comparison maps:

(θDW,T)X : DW(X) → T(X) =def (ηT)†DW

X

These functions are useful when discussing adequacy and full abstraction. Explicitly we
have:

n

n

(θDW,T)X (

pihri, xii) =

pi(ri(·T)T(X)ηT(xi))

(32)

Lemma 17. θDW,T is a monad morphism.

Xi=1

Xi=1

57

 
 
Proof. We have to show that θ is natural and preserves the unit and multiplication maps.
We make use of Equation 32 throughout the proof.

For naturality we need to show that for f : X → Y we have T(f ) ◦ θX = θY ◦ DW(f ).

Choosing

P

n
i=1 pihri, xii ∈ DW(X) we have:
n
i=1 pihri, xii)) = T(f )(

T(f )(θX(

P

=
=

n
i=1 pi(ri ·T ηT(xi)))
n
i=1 pi(ri ·T T(f )(ηT(xi)))
n
i=1 pi(ri ·T ηT(f (xi)))

P

P
P

using the fact that maps of the form T(f ) act homomorphically on algebraic operations,
and:

θY (DW(f )(

n
n
i=1 pihri, f (xi)i))
i=1 pihri, xii)) = θY (
n
i=1 pi(ri ·T ηT(f (xi)))
P

=

P

For preservation of the unit we have to show that (ηT )X = θX ◦ ηDW. This is immediate

P

from the deﬁnition of θ.

For preservation of multiplication we have to show that

θX ◦ (µDW)X = (µT)X ◦ θT(X) ◦ DW(θX)
n
mi
To this end, choose
j=1 qijhsi,j, xi,ji, for
i=1 pihri, uii ∈ DW(DW(X)) where ui =
i = 1, n. Then, using the fact that monad multiplications act homomorphically on algebraic
operations, we have:

P

P

θX((µDW)X (

P

n
i=1 pihri, uii)) = θX(
n
i=1 pi
P

n
mi
i=1 pi
j=1 qijhri + si,j, xi,ji)
mi
j=1 qij(ri + si,j) ·T ηT(xi,j)
P

=

and:

(µT)X(θT(X)(DW(θX)(

P

P

P

P

P

n
i=1 pihri, uii)))
n
i=1 pihri, θX(ui)i))

n
i=1 pi(ri(·T )T(T(X))(ηT )T(X)θX(ui)))

= (µT)X (θT(X)(
= (µT)X (
n
=
i=1 pi(ri(·T )T(X)(µT)X ((ηT )T(X)θX(ui)))
n
i=1 pi(ri(·T )T(X)θX(ui))
=
P
mi
n
i=1 pi(ri(·T )T(X)θX(
=
j=1 qijhsi,j, xi,ji))
P
n
mi
i=1 pi(ri ·T
=
j=1 qij(si,j ·T ηT(xi,j)))
P
mi
n
j=1 qij(si,j · ri ·T ·TηT(xi,j)))
i=1 pi(
=
P
mi
n
j=1 qij((si,j + ri) ·T ·TηT(xi,j)))
i=1 pi(
=
P
P

P
P

P

P

In the case of T1, θT1 is the identity.

In the case of T2, ﬁrst, given a distribution
n
i=1 pihri, xii ∈ T1(X), deﬁne its value distribution VDis(µ) in Df (X), and its value

µ =
support vsupp(µ) ⊆ X by:

P

n

VDis(µ) =

pixi

vsupp(µ) = {xi}

Xi=1

58

and then deﬁne the conditional expected reward of µ given x ∈ vsupp(µ) by:

We then have:

Rew(µ|x) =

xi=x piri
xi=x pi

P
P

(θT2)X µ) = hVDis(µ), Rew(µ|−)i

as, using Equation 29, we can calculate:

θDW,T2(

P

n
i=1 pihri, xii) =
=
P
= hµ, ρi
P

n
i=1 pi(ri ·T2 ηT2(xi))
n
i=1 pihxi, xi 7→ rii

where µ =

n
i=1 pixi and, for x ∈ supp(µ):

P

ρ(x) =

pi
µ(x)

ri

xi=x
X

In the case of T3 we have:

as, using Equation 31, we can calculate:

(θT3)X (µ) = hVDis(µ), E(µ)i

n

Xi=1

pi(ri ·T3 ηT3(xi)) =

pihxi, ri = h

pi,

xi, ri

n

n

n

Xi=1

Xi=1

Xi=1

Two properties of the Ti are useful when we consider full abstraction below. For the
ﬁrst property, say that B is characteristic for T if, for any set X and any two u, v ∈ T(X)
we have:

u 6= v =⇒ ∃f : X → B. T(f )(u) 6= T(f )(v)

Lemma 18. B is characteristic for each of the Ti.

Proof. Fix X, and, for any x ∈ X let fx : X → B be the map that sends x to 0 and
everything else in X to 1.

For the case of T1 suppose we have distinct elements of T1(X), viz. µ =

m
i=1 pihri, xii
n
j=1 qjhsj, yji. Then there is an hri, xii in the support of (say) µ that is either
and ν =
not in the support of ν or has diﬀerent probability there. Then hri, 0i is in the support of
T1(fxi)(µ) but is either not in the support of T1(fxi)(ν) or has diﬀerent probability there.
m
i=1 pixi, ρ0i
n
j=1 qjyj are distinct we proceed as in the case
1 be the

and b = h
of T1. Otherwise there is an xi, say x1, such that ρ0(x1) 6= ρ1(x1). Let ρ′

In the case of T2 suppose we have distinct elements of T2(X), viz. a = h

n
j=1 qjyj, ρ1i. If

m
i=1 pixi and

P
0 and ρ′

P

P

P

P

P

59

second components of T2(fx1)(a) and T2(fx1)(b). Then ρ′
and these are diﬀerent.

0(0) = ρ0(xi) and ρ′

1(0) = ρ1(xi)

In the case of T3 suppose we have distinct elements of T3(X), viz. a = h

m
i=1 pixi, ri
n
j=1 qjyj are distinct we proceed as in the case

P

n
j=1 qjyj, si. If

and b = h
of T1. Otherwise, r 6= s, and T(f ) distinguishes a and b.
P

m
i=1 pixi and

P

P

For the second property, for any X and γ : X → R, deﬁne the reward addition function

kγ : T(X) → T(X)

to be f †T, where f (x) =def γ(x) ·T ηT(x). Then we say that reward addition is injective for
T if such functions are always injective.

Lemma 19. Reward addition is injective for each of the Ti.

Proof. Fix X and γ : X → R. Beginning with T1 for any µ =
hri, xii repeated, we have

m

P

m
i=1 pihri, xii, with no

kγ(µ) =

pihγ(xi) + ri, xii

Xi=1

m
i=1 pihri, xii and ν =

with no repeated hγ(xi) + ri, xii (since the monoid addition on R reﬂects the order).
n
So, for any such µ =
j=1 qjhsj, yji, if kγ(µ) = kγ(ν), i.e., if
n
m
j=1 qjhsj, yji, then m = n and, for some permutation π of the in-
i=1 pihri, xii =
dices, we have pihγ(xi) + ri, xii = qπ(j)hγ(yπ(j)) + sπ(j), yπ(j)i. So then xi = yπ(j), and
P
γ(xi) = γ(yπ(j)) follows, and we see that pihri, xii = qπ(j)hsπ(j), yπ(j)i. So µ = ν, as
required.

P

P

P

The proofs for T2 and T3 are similar, using the respective formulas

m

m

kγ(h

pixi, ρi) = h

pixi, xi 7→ ρ(xi) + γ(xi)i

and

Xi=1

m

Xi=1

m

kγ(h

pixi, ri) = h

pixi, r +

piγ(xi)i

Xi=1

Xi=1

Xi

5.5 Adequacy

As in Section 4.5, we aim to prove a selection adequacy theorem connecting the globally
deﬁned selection operational semantics with the denotational semantics. We again need
some notation. Using assumption A1 of Section 5.4, we set

([[-]]T)σ = ((ηT)S[[σ]] ◦ Sp)†DW : DW(Valσ) → T(S[[σ]])

60

So, for µ =

n
i=1 pihri, Vii ∈ DW(Valσ) we have:

P

n

[[µ]]T =

pi(ri ·T ηT(Sp[[Vi]]))

Xi=1

Lemma 20. For any µ ∈ DW(Valσ) we have: αT(T(0[[σ]])([[µ]]T)) = αDW(DW(0Valσ )(µ))

Proof. Suppose µ =

n
i=1 pihri, Vii. We calculate:

αT(T(0)([[

n
P
i=1 pihri, Vii]]T))

P

n
i=1 pi(ri ·T ηT(Sp[[Vi]]))))
= αT(T(0)(
P
n
i=1 pi(ri ·T T(0)(ηT(Sp[[Vi]]))))
= αT(
n
i=1 pi(ri ·T ηT(0)))
= αT(
P
n
=
i=1 pi(ri + αT(ηT(0)))
P
n
i=1 piri
=
= αDW(DW(0)(

n
i=1 pihri, Vii))

P
P

(by assumption A2 of Section 5.4)

P

Lemma 21. For any eﬀect value E : σ we have: S[[E]](0) = [[Ops(E)]]T

Proof. We proceed by structural induction on E:

1. Suppose that E is a value V . We calculate:

[[Ops(V )]]T = [[h0, V i]]T = ηT(Sp[[V ]]) = ηS(Sp[[V ]])(0) = S[[V ]](0)

2. Suppose that E has the form E1 or E2. We calculate:

[[Ops(E1 or E2)]]T

(by Theorem 10.2)

= [[Ops(E1) maxRDW(−|0) Ops(E2)]]T
= [[Ops(E1) maxαDW◦DW(0) Ops(E2)]]T
= [[Ops(E1) maxαT◦T(0)◦T([[ ]]σ) Ops(E2)]]T (by Lemma 20)
= [[Ops(E1)]]T maxαT◦T(0) [[Ops(E2)]]T
= S[[E1]](0) maxαT◦T(0) S[[E2]](0)
= or[[σ]](S[[E1]], S[[E2]])(0)
= S[[E1or E2)]](0)

(using Lemma 6)
(by induction hypothesis)
(by Equation 27)

3. Suppose that E has the form c · E′. We calculate:

[[Ops(c · E′)]]T = [[[[c]] ·T Ops(E′)]]T (by Theorem 10.3)

= [[c]] ·T [[Ops(E′)]]T (as [[-]]T is a homomorphism)
= [[c]] ·T S[[E′]](0)
= ([[c]] ·S S[[E′]])(0)
= S[[c · E′]](0)

(by induction hypothesis)
(by Equation 20)

61

4. Suppose that E has the form E1 +p E2. We calculate:

[[Ops(E1 +p E2)]]T = [[Ops(E1) +p Ops(E2)]]T

(by Theorem 10.4)

= [[Ops(E1)]]T +p [[Ops(E2)]]T (as [[-]]σ is a homomorphism)
= S[[E1]](0) +p S[[E2]](0)
= (+pS)[[σ]](S[[E1]], S[[E2]])(0)
= S[[E1 +p E2]](0)

(by induction hypothesis)

We then have selection adequacy for our language with probabilities:

Theorem 11 (Selection adequacy). For any program M : σ we have:

S[[M ]](0) = [[Ops(M )]]T

The proof of this theorem is the same as that of Theorem 6. As before, the ade-
quacy theorem implies that the globally optimizing operational semantics determines the
denotational semantics at the zero-reward continuation.

For the converse direction, noting that

([[-]]T)σ = ((ηT)S[[σ]] ◦ Sp)†DW

= (T(Sp) ◦ (ηT)Valσ )†DW (η is natural)
= T(Sp) ◦ ((ηT)Valσ )†DW
= T(Sp) ◦ (θDW,T)Valσ

we see from the adequacy theorem that, for M : σ, the denotational semantics determines
(θDW,T)Valσ (Ops(M )) ∈ T(Valσ) up to T(Sp). We view (θDW,T)Valσ (Ops(M )) as an ob-
servation of the selection operational semantics of M , and so, for M : σ we adopt the
notation:

Obσ,T(M ) = (θDW,T)Valσ (Ops(M )) ∈ T(Valσ)

Using this notation, we see that the adequacy theorem determines observations Obσ,T(M )
up to T(Sp). With the aid of the above discussion of the monad morphism θDW,T we ﬁnd
for M : σ that:

Obσ,T1(M ) = Ops(M )
Obσ,T2(M ) = hVDis(Ops(M )), Rew(Ops(M )|−)i
Obσ,T3(M ) = hVDis(Ops(M )), E(Ops(M ))i

In the case where σ is a product of base types, T(Sp) is an injection. (For Sp is then an
injection and T preserves injections with nonempty domain, as do all functors on sets.)
So in this case the denotational semantics determines T-observations Obσ,T(M ) of the
selection operational semantics of terms M : σ.

62

5.6 Full abstraction

We continue to proceed generally, as above, in terms of an auxiliary monad T and al-
gebra αT : T(R) → R. Having a general notion of observation Obb,T at base types, we
have corresponding general observational equivalence relations ≈b,T, and so, instantiating,
observational equivalence relations ≈b,Ti for the Ti. We write ObT and ≈T for ObBool,T
and ≈Bool,T, respectively, and similarly for the Ti. From the discussion of the selection
adequacy theorem (Theorem 11) at base types, we see that the implications 21 and 22 hold
for ST and all Obb,T and ≈b,T; we then also have M ≈b,T Op(M ) for base types b and
programs M : σ.

We next consider, as we did for our ﬁrst language, whether observing at diﬀerent base

types makes a diﬀerence to contextual equivalence.

Lemma 22. Suppose that B is characteristic for T and that b is a base type with at least
two constants. Then for any base type b′ and programs M1, M2 : b′ we have:

M1 ≈b,T M2 =⇒ Obb′,T(M1) = Obb′,T(M2)

Proof. We can assume without loss of generality that the Mi are eﬀect values, and write
Ei for them. We assume E1 ≈b,T E2, and suppose, for the sake of contradiction, that
Obb′,T(E1) 6= Obb′,T(E2). As B is characteristic for T, there is a map f:Valb′֒→ValBool such
that T(f )(Obb′,T(E1)) 6= T(f )(Obb′,T(E2)). As b has at least two constants, there is an
injection ι : ValBool → Valb. Set f ′ = f ◦ ι : Valb′ → Valb. As T preserves injections with
nonempty domain we have T(f ′)(Obb′,T(E1)) 6= T(f ′)(Obb′,T(E2)). Let g be the restriction
of f ′ to g : u → Valb, where u is the set of constants of type b occurring in E1 or E2.

As E1 ≈b,T E2 we have FgE1 ≈b,T FgE2, so Obb,T(FgE1) = Obb,T(FgE2), and so, by

adequacy, S[[FgE1]](0) = S[[FgE2]](0). For i = 1, 2, we calculate:

S[[FgEi]](0) = S[[Ei[g]]](0)

= [[Ops(Ei[g])]]T
= [[DW(f ′)Ops(Ei)]]T
= T([[-]])((θDW,T)Valb(DW(f ′)(Ops(Ei))))
= T([[-]])(T(f ′)(θValb′ (Ops(Ei))))

= T([[-]])(T(f ′)(Obb′,T(Ei)))

(by Lemma 4)
(by adequacy)
(by Lemma 16.2)

(as θDW,T is natural
by Lemma 17)

So, as T([[-]]) is injective, T(f ′)(Obb,T(E1)) = T(f ′)(Obb,T(E2)), yielding the required con-
tradiction.

We then have the following analogue of Proposition 4:

Proposition 5. Suppose that B is characteristic for T. Then, for all base types b and
programs M, N : σ, we have

M ≈T N =⇒ M ≈b,T N

63

with the converse holding if there are at least two constants of type b.

As B is characteristic for the Ti (Lemma 18), we have invariance of the observational

equivalences ≈b,Ti under changes of base type with at least two constants.

Modulo a reasonable deﬁnability assumption, each of our three semantics is fully ab-
stract at base types with respect to their corresponding notion of observational equivalence.
We establish this via general results for T and αT : T(R) → R, as above.

We ﬁrst need a general result on reward continuations. Suppose u ⊆ Conb and suppose
too that γ : [[b]] → R is deﬁnable on u in the sense that there is a (necessarily unique)
g : Conb → ConRew such that γ([[c]]) = [[g(c)]], for c ∈ u. Set Ku,γ = Fh : b → b where
h(c) = g(c) · c (c ∈ u). We have:

S[[Ku,γc]](0) = γ([[c]]) ·T ηT([[c]])

(c ∈ u)

This program Ku,γ can be used to reduce calling deﬁnable reward continuations to calling
the zero-reward continuation, modulo reward addition:

Lemma 23. Suppose E : b is an eﬀect value, u a ﬁnite set of constants of type b including
all those occurring in E, and γ : [[b]] → R is a reward function deﬁnable on u. Then we
have:

kγ(S[[E]](γ)) = S[[Ku,γE]](0)

Proof. The proof is by structural induction on E. If E is a constant c, than

kγ(S[[c]](γ)) = kγ(ηT([[c]])) = γ([[c]]) ·T ηT([[c]]) = S[[Ku,γc]](0)

Suppose next that E has the form E1 or E2. We ﬁrst show that

αT ◦ T(γ) = αT ◦ T(0) ◦ kγ

(∗)

We have kγ = f †T : T([[b]]) → T([[b]]), where f (x) =def γ(x) ·T ηT(x), for x ∈ [[b]]. Setting
g(x) =def T(0)(γ(x) ·T ηT(x)) (= γ(x) ·T T(0)(ηT(x))), for x ∈ [[b]], we then see that
T(0) ◦ kγ = g†T : T([[b]]) → T(R). Making use of assumption A2 of Section 5.4, we next
see that αT(g(x)) = αT(γ(x) ·T T(0)(ηT(x))) = αT(γ(x) ·T ηT(0)) = γ(x) + 0 = γ(x). This,
in turn, yields αT ◦ T(0) ◦ kγ = αT ◦ g†T = αT ◦ T(αT ◦ g) = αT ◦ T(γ) as required. (The
second equation in this chain holds generally for monad algebras.)

64

We then calculate:

kγ(S[[E1 or E2]](γ))

= kγ(S[[E1]](γ) maxRT(−|γ) S[[E2]](γ))

= kγ(S[[E1]](γ) maxαT◦T(γ) S[[E2]](γ))

=

=

=

=

(cid:26)

(cid:26)

(cid:26)

(cid:26)

kγ(S[[E1]](γ))
kγ(S[[E2]](γ))

(if (αT ◦ T(γ))S[[E1]](γ) ≥ (αT ◦ T(γ))S[[E2]](γ))
(otherwise)

S[[Ku,γ(E1)]](0)
S[[Ku,γ(E2)]](0)

(if (αT ◦ T(0) ◦ kγ)S[[E1]](γ) ≥ (αT ◦ T(0) ◦ kγ)S[[E2]](γ))
(otherwise)

(by induction hypothesis and (∗))

S[[Ku,γ(E1)]](0)
S[[Ku,γ(E2)]](0)

(if (αT ◦ T(0))kγ (S[[E1]](γ)) ≥ (αT ◦ T(0))kγ (S[[E2]](γ)))
(otherwise)

S[[Ku,γ(E1)]](0)
S[[Ku,γ(E2)]](0)

(if (αT ◦ T(0))S[[Ku,γ(E1)]](0) ≥ (αT ◦ T(0))S[[Ku,γ(E2)]](0))
(otherwise)

(by Lemma 23)

= S[[(Ku,γE1) or (Ku,γE2)]](0)

= S[[Ku,γ(E1 or E2)]](0)

(using Equation 16)

Suppose next that E has the form E1 +p E2. Then we calculate:

kγ(S[[E1 +p E2]](γ)) = kγ(S[[E1]](γ) +p S[[E2]](γ))

= kγ(S[[E1]](γ)) +p kγ(S[[E2]](γ))
= S[[Ku,γE1]](0) +p S[[Ku,γE2]](0)
= S[[Ku,γE1 +p Ku,γE2]](0)
= S[[Ku,γ(E1 +p E2)]](0)

Finally, suppose that E has the form c·E′. This case is handled similarly to the previous

65

one:

kγ(S[[c · E′]](γ)) = kγ([[c]] · S[[E′]](γ))
= [[c]] · kγ(S[[E′]](γ))
= [[c]] · S[[Ku,γE′]](0)
= S[[c · Ku,γE′]](0)
= S[[Ku,γ(c · E′)]](0)

We can now demonstrate full abstraction for general T, subject to three assumptions,

Say that a type b is numerable if all elements of [[b]] are deﬁnable by a constant.

Theorem 12. Suppose B is characteristic for T, reward addition is injective for T, and
Rew is numerable. Then S is fully abstract with respect to ≈T at b.

Proof. Suppose M1(≈T)bM2. We wish to show that S[[M1]] = S[[M2]]. By the ordinary
adequacy theorem there are eﬀect values E1, E2 with S[[M1]] = S[[E1]] and S[[M2]] = S[[E2]].
Let u be the set of constants of type b appearing in any one of these eﬀect values. Let
γ : [[b]] → R be a reward function. It is deﬁnable on u by the numerability assumption.
Using Lemma 23 we see that

kγ(S[[Mi]](γ)) = kγ(S[[Ei]](γ)) = S[[Ku,γEi]](0)

(∗)

As M1(≈T)bM2, we have E1(≈T)bE2 so Ku,γE1(≈T)bKu,γE2. As B is characteristic
for T, we can then apply Lemma 22, ﬁnding that ObT(Ku,γE1) = ObT(Ku,γE2). So, by
adequacy, S[[Ku,γE1]](0) = S[[Ku,γE2]](0).

With this, we see, using (∗), that kγ(S[[M1]](γ)) = kγ(S[[M2]](γ)), so, as reward addition
is injective for T, that S[[M1]](γ) = S[[M2]](γ). As γ is an arbitrary reward function, we
ﬁnally have S[[M1]] = S[[M2]] as required.

As, by Lemmas 18 and 19, B is characteristic for all of three Ti and reward addition is

injective for all of them, we immediately obtain:

Corollary 4. Suppose that Rew is numerable. Then STi is fully abstract with respect to
≈Ti at base types, for i = 1, 3.

Regarding full abstraction at other types, full abstraction for general T at products of
base types and so, too, at values of types of order 1 is a consequence of Theorem 12 (under
the same assumptions as those of the theorem). We then obtain full abstraction for the Ti
at products of base types and at values of types of order 1 (assuming Rew numerable). As
in the case of the language of Section 4, the question of full abstraction at other types is
open.

There is a “cheap” version of the free-algebra monad C discussed in Section 4.6 for
general auxiliary monads T. Take Axc to be the set of equations between eﬀect values that

66

hold in ST, and take D to be the corresponding free algebra monad, yielding a corresponding
denotational semantics D. Then we have:

|=D E = E′ : b ⇐⇒ ⊢Axc E = E′ : b ⇐⇒ |=ST E = E′ : b
Assuming B characteristic for T and reward addition injective for T, using Theorems 4
and 12 we then obtain a version of Theorem 7 for D for numerable b:

⊢Axc M = N : b ⇐⇒ |=C M = N : b ⇐⇒ M ≈b N

Turning to weakening the notion of observation, analogously to Section 4 we could
forget all reward information. We do this by taking our notion of observation ObVDis to
be VDis ◦ Ops, i.e., the distribution of ﬁnal values. As we next show, the observational
equivalence ≈ObVDis resulting from this notion coincides with ≈T3.
Lemma 24. For programs M, N : Bool we have

M1 ≈ObVDis M2 =⇒ ObT3(M1) = ObT3(M2)

Proof. Set Ei = Op(Mi), for i = 1, 2. We have Mi ≈T3 Ei and so, as ObVDis is weaker
than ObT3, we also have Mi ≈ObVDis Ei . It therefore suﬃces to prove that:

E1 ≈ObVDis E2 =⇒ ObT3(E1) = ObT3(E2)

So suppose that E1 ≈ObVDis E2 and, for the sake of contradiction, that, for example,
E(Ops(E1)) < E(Ops(E2)).

Since E1 ≈ObVDis E2, they return the same probability distribution tt +p ff on boolean
values. Suppose, without loss of generality, that this distribution is not ff. (If it is, we can
work with tt instead.) Deﬁne f : ValBool → ValBool to be constantly ff. Then we have

ObVDis(E1 or Ff E2) = VDis(Ops(E1 or Ff E2))

= VDis(Ops(E1) maxE Ops(Ff E2))
= VDis(Ops(E1) maxE Ops(E2[f ]))
= VDis(Ops(E1) maxE W(f )(Ops(E2)))
= VDis(W(f )(Ops(E2)))
= ff

(by Theorem 10.2)
(by Lemma 4)
(by Lemma 16.2)

where the next to last equality holds as, using Lemma 16.1, we have:

E(Ops(E1)) < E(Ops(E2)) = E(W(f )(Ops(E1)))

Similarly,

ObVDis(E2 or Ff E2) = VDis(Ops(E2) maxE W(f )(Ops(E2)))
= VDis(Ops(E2))
= tt +p ff

yielding the required contradiction.

67

We then have the following analogue to Theorem 8:

Theorem 13. For any programs M, N : σ, we have

M ≈T3 N ⇐⇒ M ≈ObVDis N

5.7 Program equivalences and purity

We begin by considering the equations holding in ST for a general T as above. We need
some terminology and notation. Say that a term M : σ is in expectation PR-form over
terms L1, . . . , Ln if it has the form

m

ni

pi

qij(Mij · Li)

Xi=1

Xj=1

where the Mij are either variables or constants (and we say M is an expectation PR-value
if the Mij and Li are all constants). For such a term we write Es(M ) : Rew for the term:

m

ni

pi

qijMij

Mi=1

Mj=1

(We write
+p.) In case the Mij are constants dij, we set:

Mi for iterated uses of the ⊕p to avoid confusion with iterated uses of the

L

m

ni

pi

Mi=1

Mj=1







qijdij




m

ni

=

pi

qij[[dij]]

Xi=1

Xj=1

Our system Ax1 of equations is given in Figure 4 (where we omit type information). In
the last two equations it is assumed that M and N are in expectation PR-form over the
same L1, . . . , Ln. The equations express at the term level, that: choice is idempotent and
associative; rewards form an action for the commutative monoid structure on R; probabilis-
tic choice forms a convex algebra; the R-action acts on both forms of choice; probabilistic
choice distributes over choice; and, where this can be seen from the syntax, that choice is
made according to the highest reward, with priority to the left for ties.

Below, for u ∈ T(X) and γ : X → R, we set

E(u|γ) =def RT(u|γ) (= αT(T(γ)(u)))

This is the expected reward of u, given γ.

68

M or M = M

(L or M ) or N = L or (M or N )

0 · N = N

x · (y · N ) = (x + y) · N

M +1 N = M

M +p N = N +1−p M

(M +p N ) +q P = M +pq (N + r−pq
1−pq

P )

(p, q < 1)

x · (M +p N ) = x · M +p x · N
x · (M or N ) = (x · M ) or (x · N )
L +p (M or N ) = (L +p M ) or (L +p N )
if Es(M ) ≥ Es(N ) then M else N = M or N
if Es(M ) ≥ Es(N ) then (M or P ) else (P or N ) = (M or P ) or N

Figure 4: Equations for choices, probability, and rewards

Proposition 6. The axioms hold for general ST.

Proof. Other than the last two axiom schemas, this follows from Theorem 2, Corollary 1,
and Theorem 3. The last two cases are straightforward pointwise arguments, although we
ni
need an observation. We calculate that for a PR-term M =
j=1 qij(dij · Li)
of type σ and a reward function γ : [[σ]] → R we have:
(cid:17)

m
i=1 pi

P

(cid:16)P

E(S[[

m
i=1 pi

P

P

ni
j=1 qij(dij · Li)]]γ | γ) =
=

=

m
i=1 pi(
m
i=1 pi(
P
m
i=1 pi(
P

m
i=1 pi(
P

P
P

ni
j=1 qij([[dij ]] + E(S[[Li]]γ | γ))
ni
j=1 qij[[dij]])+

ni
j=1 qijE(S[[Li]]γ | γ))

ni
j=1 qij([[dij ]]) +
P

m
i=1 piE(S[[Li]]γ | γ)

and we further have:

P

P

P

m

ni

pi

Mi=1

Mj=1

S







qijdij




γ = ηT 


m

ni

pi

Xi=1

Xj=1

qij[[dij]]





So if M : σ and N : σ are in expectation PR-form over the same L1, . . . , Ln then, for
γ : [[σ]] → R, we have:

E(S[[M ]]γ | γ) ≥ E(S[[N ]]γ | γ) ⇐⇒ S[[Es(M ) ≥ Es(N )]]γ = ηT(0)

(recall that [[tt]] = 0). With this observation, the pointwise argument for the last two
equation schemas goes through.

In the case of ST2 we inherit Equation 28 from T2 so we additionally have:

x · M +p y · M = (x ⊕p y) · M

(33)

69

Let Ax2 be Ax1 extended with this equation. In the case of ST3 we inherit Equation 30
from T3 so we have the stronger:

x · M +p y · N = (x ⊕p y) · M +p (x ⊕p y) · N

(34)

Let Ax3 be Ax1 extended with this equation.

Unfortunately, we do not have any results analogous to Theorem 7 for any of the above
three axiom systems for the probabilistic case—further axioms may well be needed to obtain
completeness for program equivalence at base types. We do, however have a completeness
result for purity at base types.

First, some useful consequences of these equations, are the following, where M and N

are expectation PR-values over the same L1, . . . , Ln:

M or N = M (if Es(M ) ≥ Es(N ))

M or N = N (if Es(M ) < Es(N ))

(M or L) or N = M or L (if Es(M ) ≥ Es(N ))

(M or L) or N = L or N (if Es(M ) < Es(N ))

(PR1)

(PR2)

(PR3)

(PR4)

Next, our equational system Ax1 allows us to put programs of base type into a weak
canonical form. First consider programs which are PR-eﬀect values, i.e., programs obtained
by probabilistic and reward combinations of constants. Every such term is provably equiv-
m
j=1 pj(dj · cj) where m > 0, the dj and the cj are constants and
alent to one of the form
no dj · cj is repeated. We call such terms canonical PR-eﬀect values, and do not distinguish
any two such if they are identical apart from the ordering of the dj · cj.

P

We say that an eﬀect value of base type is in weak canonical form if (ignoring bracketing

of or) it is an eﬀect value of the form

E1 or . . . or En

where n > 0, the Ei are canonical PR-eﬀect values, and no Ei occurs twice. (We could
have simpliﬁed canonical forms further by applying the PRi, obtaining a stronger canonical
form, but did not do so as, in any case, we do not have an equational completeness result.)

Lemma 25. Every program M of base type is provably equal to a weak canonical form
CF(M ).

Proof. By Proposition 3, M can be proved equal to an eﬀect value E. Using the associativ-
ity equation and the fact that reward and +p distribute over or, the eﬀect value E can be
proved equal to a term of the form E1 or . . . or En where each Ei is a PR-eﬀect term.

70

Say that a theory Ax, valid in ST, is strongly purity complete for basic PR-eﬀect values,

if for all PR-eﬀect values E : b we have:

|=ST E ↓b =⇒ ∃c : b. ⊢Ax E = c : b

Lemma 26. Axi is strongly purity complete for basic PR-eﬀect values, for i = 1, 3.

Proof. For T1 we have already noted that every PR-eﬀect value is provably equal using
m
Ax1 to a term E : b of the form
j=1 pj(dj · cj) with no dj · cj repeated. For such a term
E ↓b holds iﬀ there is an x ∈ [[b]] such that ST1[[E]]γ = ηT1(b) for all γ : [[b]] → R.
|=ST1
m
j=1 pj([[dj ]] · [[cj]]) = ηT1(b). As no dj · cj is
Taking γ = 0, for example, we then see that
repeated, neither is any [[dj]] · [[cj]]. It follows that m = 1 and d1 = 0. In that case the term
is provably equal, using Ax1, to c1. The other two cases are similar: for T2 we note that
m
every PR-eﬀect value is provably equal using Ax2 to a term of the form
j=1 pi(dj · cj)
with no ci repeated, and for T3 we note that every PR-eﬀect value is provably equal using
m
j=1 pi(d · cj) with no cj repeated.
Ax3 to a term of the form

P

P

P

P

In order to establish purity completeness we need a condition (C) on R. This is that
for all p ∈ (0, 1) and s < 0 in R, there are l, r ∈ R such that s + (r +p l) > l. Condition (C)
evidently holds when there are no negative elements as in our example of the nonnegative
reals [0, ∞) with the addition monoid. It also holds for our other examples of the reals,
(−∞, ∞), and the positive reals, (0, ∞), the former with the addition monoid and the
latter with the multiplication monoid. Two further examples satisfying the condition are
the real intervals (−∞, 0] and (0, 1], both with the usual ordering, the ﬁrst with the sum
monoid, and the second with the multiplication monoid. In all these examples we employ
the usual convex combination, and the veriﬁcation of Condition (C) is straightforward. We
give a counterexample to the condition below.

There are natural conditions that imply Condition (C), and which, together, account

for these examples. Consider the equation:

x +1/2 (y + z) = (x + y) +1/2 z

(35)

and say that condition (D) holds if, for all p ∈ (0, 1), there is an l ∈ R such that for all
s ∈ R there is an r ∈ R such that r +p s > l. Condition (C) is satisﬁed if Equation 35 holds
or Condition (D) does. All our examples with the addition monoid satisfy the equation,
and all our examples other than the nonpositive reals satisfy Condition (D).

Theorem 14 (General purity completeness). Suppose that R satisﬁes condition (C). Let
Ax be a theory extending Ax1 that is valid in ST. If Ax is strongly purity complete for basic
PR-eﬀect values, then it is strongly purity complete at base types, i.e., for all programs M : b
we have:

|=ST M ↓b =⇒ ∃c : b. ⊢Ax M = c : b

71

Proof. We remark ﬁrst that, in general, for any term N : b and any PR-eﬀect value E : b,
if |=ST N ↓b and ST[[N ]](γ) = ST[[E]](γ) for some γ, then ST[[N ]](γ) = ST[[E]](γ) for any γ,
and so, also, |=ST E ↓b and then ⊢Ax E = c, for some c : b (this last using the strong purity
completeness assumption).

It suﬃces to prove the claim for terms M in weak canonical form, i.e., of the form

E1 or . . . or En

where n > 0, and the Ei are canonical PR-eﬀect values. We proceed by induction on n.

So suppose that |=ST M ↓b. For some Ei0 we have ST[[M ]](0) = ST[[Ei0 ]](0), and so, by
the above remark, we see that ST[[N ]] = ST[[Ei0]] and also that there is a c : b such that
⊢Ax Ei0 = c.

In case n = 1 we have shown that ⊢Ax M = c for some c : b, as required. Otherwise
n
j=1 pj(dj · cj) for an i1 6= i0. If every cj is c then both Ei0 and Ei1 are
consider Ei1 =
in expectation PR-value form over c, and so one of the equations PR1–PR4 can be used to
reduce the size of M , and the induction hypothesis can be applied.

P

Otherwise, some cj is not c, and we show next that, for some γ we have

E(ST[[Ei1]]γ | γ) > E(ST[[Ei0 ]]γ | γ)

(∗)

In the ﬁrst case no cj1 is c. Then choose l < r ∈ R and deﬁne
There are two cases.
γ : [[b]] → R by setting γ(x) = r for x 6= [[c]], and γ([[c]]) = r0 + l, where r0 is the least of
the [[dj]]. Then we have:

n
j=1 pj([[dj]] + γ(cj))
n
j=1 pj(r0 + γ(cj))
n
j=1 pj(r0 + r)

E(ST[[Ei1]]γ | γ) =
≥
P
=
P
= r0 + r
P
> r0 + l
= γ(c)
= E(ST[[Ei0 ]]γ | γ)

In the second case cj0 = c for some unique j0. Setting p =

pj, note that p ∈ (0, 1);
then, setting p′
p′
j = 1. Taking r0 to be the least of the
[[dj]] as before, there are l and r in R such that r0 + (r +p l) > l. For if r0 < 0, condition (C)
P
applies, and otherwise r0 ≥ 0 and we can choose any l, r with l < r. Deﬁne γ : [[b]] → R by

j = pj/p for j 6= j0, note that

j6=j0

j6=j0

P

72

setting γ(x) = r for x 6= [[c]], and γ([[c]]) = l. Then we have:

n
j=1 pj([[dj]] + γ(cj))
n
j=1 pj(r0 + γ(cj))
j6=j0

E(ST[[Ei1]]γ | γ) =
≥
p′
j(r0 + γ(cj))) +p (r0 + γ(c))
= (
p′
= (
j(r0 + r)) +p (r0 + l)
= (r0 + r) +p (r0 + l)
= r0 + (r +p l)
> l
= γ(c)
= E(ST[[Ei0 ]]γ | γ)

P
P
P
P

j6=j0

This establishes (∗). It follows that, for some Ei2, with i2 6= i0, ST[[M ]](γ) = ST[[Ei2 ]](γ),
and so ST[[M ]] = ST[[Ei2]] and there is a ci2 : b such that ⊢Ax Ei2 = ci2. As Ax is valid
in ST we have ST[[c]] = ST[[ci2]] and so c = ci2. (Monad units are always injective and so
is [[-]] : Valb → [[b]].) We can therefore replace Ei0 and Ei2 by c, and apply one of PR1–
PR4, obtaining a shorter canonical form, and then apply the induction hypothesis. This
concludes the proof.

So, using Lemma 26, we see that strong purity completeness at base types holds for
Ti with respect to the Axi (assuming R satisﬁes condition (C))1. Regarding products of
base types, strong purity completeness for general T at products of base types follows from
Theorem 14 (under the same assumptions as those of the theorem), and so, then, for the
Ti (assuming R satisﬁes condition (C)).

While Condition (C) is not attractive, it is necessary:

Theorem 15. Suppose R does not satisfy condition (C). Then Ax1 is not purity complete
for T1. That is, there is a term M such that |=ST M ↓b holds but ⊢Ax1 M ↓b does not.

Proof. As the condition fails, we can choose p ∈ (0, 1) and s < 0 such that, for all l and r
we have s + (r +p l) ≤ l. Take M to be the term ff or c · (tt +p ff) where [[c]] = s. Then for
all γ : [[Bool]] → R we have E(ST[[c · (tt +p ff)]]γ | γ) ≤ E(ST[[ff]]γ | γ) and so |=ST M ↓b.
However, switching to any R satisfying condition (C), we see that if ⊢Ax1 M ↓b then, by
consistency, we would have |=ST M ↓b. But this is impossible as, using condition (C), we
can ﬁnd a γ : [[Bool]] → R such that E(ST[[c · (tt +p ff)]]γ | γ) > E(ST[[ff]]γ | γ) and so
ST[[M )]]γ = ST[[c · (tt +p ff)]]γ and this contradicts |=ST M ↓b as ST[[c · (tt +p ff)]]γ 6= ηT1(b)
for any b ∈ Bool.

To conclude our discussion of purity we construct a counterexample to Condition (C).
We make use of the free barycentric commutative algebra RM over a commutative monoid

1In [1] this was claimed without any assumption on R; however there was an error in the proof.

73

(M, +, 0). This is the set of ﬁnite probability distributions over M , with the usual convex
combination operations, with convolution as the monoid operation, deﬁned by:

(
Xi

pixi) + (

qjyj) =

piqj(xi + yj)

Xj

Xij

and with 0 the Dirac distribution δ0.

Consider the case where the monoid M is totally ordered, with the monoid operation
preserving and reﬂecting the order. Every ﬁnite distribution over M can then be written
n
i=1 pixi with x1 > . . . > xn (and no pi zero). Set m(µ) = xn,
uniquely in the form µ =
w(µ) = pn, and, if n > 1, p(µ) =
xi. Note that m(x + µ) = x + m(µ), for x ∈ M ,
P
and that m(µ +p ν) = min(m(µ), m(ν)), for p ∈ (0, 1).
Let ≤ be the least relation on RM such that:

pi
1−pn

n−1
i=1

P

m(µ) < m(ν)
µ ≤ ν

m(µ) = m(ν), w(µ) > w(ν)
µ ≤ ν

m(µ) = m(ν), w(µ) = w(ν) = 1
µ ≤ ν

m(µ) = m(ν), w(µ) = w(ν) 6= 1, p(µ) ≤ p(ν)
µ ≤ ν

Intuitively, one decides whether µ ≤ ν or ν ≤ µ by comparing m(µ) and m(ν), and, if
they are equal, comparing their corresponding probabilities, and then if they are equal,
but not 1, proceeding recursively to the rest of µ and ν. It can be shown that ≤ is a total
order, preserved and reﬂected by probabilistic choice and addition. Note that if µ ≤ ν then
m(µ) ≤ m(ν).

Suppose now that M contains an element s < 0 (so M could, for example, be the
nonpositive integers with the usual addition and order). Then we claim that RM does not
satisfy Condition (C). For, suppose there are l, r such that s + (r +p l) > l. We have:

m(s + (r +p l)) = s + m(r +p l)

= s + min(m(r), m(l))
≤ s + m(l)
< m(l)

However, this contradicts s + (r +p l) > l as that implies that m(s + (r +p l)) ≥ m(l).

6 Conclusion

This paper studies decision-making abstractions in the context of simple higher-order pro-
gramming languages, focusing on their semantics, treating them operationally and deno-
tationally. The denotational semantics are compositional. They are based on the selection
monad, which has rich connections with logic and game theory. Unlike other programming-
language research (e.g., [3, 31]), the treatment of games in this paper is extensional, focusing

74

on choices but ignoring other aspects of computation, such as function calls and returns.
Moreover, the games are one-player games. Going further, we have started to explore
extensions of our languages with multiple players, where each choice and each reward is
associated with one player. For example, writing A and E for the players, we can program
a version of the classic prisoners’s dilemma:

let silentA, silentE : Bool be (tt orA ff), (tt orE ff) in
if silentA and silentE then − 1 ·A −1 ·E ∗
else if silentA then − 3 ·A ∗
else if silentE then − 3 ·E ∗
else − 2 ·A −2 ·E ∗

Here, silentA and silentE indicate whether the players remain silent, and the rewards,
which are negative, correspond to years of prison. Semantically it would be natural to use
the selection monad with R2 as the set of rewards, and with the writer monad as auxiliary
monad. (One could envisage going further and treating probabilistic games via a combi-
nation of the writer monad and a monad for probability.) Many of our techniques carry
over to languages with multiple players, which give rise to interesting semantic questions
(e.g., should we favor some players over others? require Nash equilibria?) and may also be
useful in practice.

Multi-objective optimization provides another area of interest. One could take R to be
a product, with one component for each objective, and use the selection monad augmented
with auxiliary monad the combination Pﬁn(R × −) of the ﬁnite powerset monad and a
version of the writer monad enabling writing to diﬀerent components. One would aim for
a semantics returning Pareto optimal choices.

In describing Software 2.0, Karpathy suggested specifying some goal on the behavior of
a desirable program, writing a “rough skeleton” of the code, and using the computational
resources at our disposal to search for a program that works [36]. While this vision may be
attractive, realizing it requires developing not only search techniques but also the linguistic
constructs to express goals and code skeletons. In the variant of this vision embodied in
SmartChoices, the skeleton is actually a complete program, albeit in an extended language
with decision-making abstractions. Thus, in the brave new world of Software 2.0 and its
relatives, programming languages still have an important role to play, and their study
should be part of their development. Our paper aims to contribute to one aspect of this
project; much work remains.

In comparison with recent theoretical work on languages with diﬀerentiation (e.g,. [27,
2, 4, 9, 14, 30]), our languages are higher-level: they focus on how optimization or machine-
learning may be made available to a programmer rather than on how they would be imple-
mented. However, a convergence of these research lines is possible, and perhaps desirable.
One thought is to extend our languages with diﬀerentiation primitives to construct selection
functions that use gradient descent. These would be alternatives to argmax as discussed
in the Introduction. Monadic reﬂection and reiﬁcation, in the sense of Filinski [26], could

75

support the use of such alternatives, and more generally enhance programming ﬂexibility.
Similarly, it would be attractive to deepen the connections between our languages and
It may also be interesting to connect our semantics with
probabilistic ones (e.g., [28]).
particular techniques from the literature on MDPs and RL, and further to explore whether
monadic ideas can contribute to implementations that include such techniques. Finally, at
the type level, the monadic approach distinguishes “selected” values and “ordinary” ones;
the “selected” values are reminiscent of the “uncertain” values of type Uncertain < T > [7],
and the distinction may be useful as in that setting.

Acknowledgements

We are grateful to Craig Boutilier, Eugene Brevdo, Daniel Golovin, Michael Isard, Eugene
Kirpichov, Ohad Kammar, Matt Johnson, Dougal Maclaurin, Martin Mladenov, Adam
Paszke, Sam Staton, Dimitrios Vytiniotis, and Jay Yagnik for discussions.

References

[1] Mart´ın Abadi and Gordon Plotkin. Smart choices and the selection monad. In 36th
Annual ACM/IEEE Symposium on Logic in Computer Science, LICS 2019. IEEE,
2021.

[2] Mart´ın Abadi and Gordon D. Plotkin. A simple diﬀerentiable programming language.

Proc. ACM Program. Lang., 4(POPL):38:1–38:28, 2020.

[3] Samson Abramsky, Radha Jagadeesan, and Pasquale Malacaria. Full abstraction for

PCF. Inf. Comput., 163(2):409–470, 2000.

[4] Gilles Barthe, Rapha¨elle Crubill´e, Ugo Dal Lago, and Francesco Gavazzo. On the
versatility of open logical relations - continuity, automatic diﬀerentiation, and a con-
tainment theorem. In Peter M¨uller, editor, Programming Languages and Systems -
29th European Symposium on Programming, ESOP 2020, volume 12075 of Lecture
Notes in Computer Science, pages 56–83. Springer, 2020.

[5] Richard Bellman. Dynamic Programming. Princeton University Press, Princeton,

1957.

[6] Joe Bolt, Jules Hedges, and Philipp Zahn. Sequential games and nondeterministic

selection functions. CoRR, abs/1811.06810, 2018.

[7] James Bornholt, Todd Mytkowicz, and Kathryn S. McKinley. Uncertain< T >: a ﬁrst-
order type for uncertain data. In Rajeev Balasubramonian, Al Davis, and Sarita V.
Adve, editors, Architectural Support for Programming Languages and Operating Sys-
tems, ASPLOS ’14, pages 51–66. ACM, 2014.

76

[8] C. Boutilier, R. Reiter, M. Soutchanski, and S. Thrun. Decision-theoretic, high-level
robot programming in the situation calculus. In Proceedings of the AAAI National
Conference on Artiﬁcial Intelligence. AAAI, 2000.

[9] Alo¨ıs Brunel, Damiano Mazza, and Michele Pagani. Backpropagation in the sim-
Proc. ACM Program. Lang.,

ply typed lambda-calculus with linear negation.
4(POPL):64:1–64:27, 2020.

[10] David Budden, Matteo Hessel, John Quan, and Steven Kapturowski. RLax: Rein-

forcement Learning in JAX, 2020.

[11] Vladimir Bychkovsky. Spiral: Self-tuning services via real-time machine learning,

2018. Blog post here.

[12] Victor Carbune, Thierry Coppey, Alexander N. Daryin, Thomas Deselaers, Nikhil
Sarda, and Jay Yagnik. Predicted variables in programming. CoRR, abs/1810.00619,
2018.

[13] Kai-Wei Chang, He He, St´ephane Ross, Hal Daum´e III, and John Langford. A credit
assignment compiler for joint prediction. In Daniel D. Lee, Masashi Sugiyama, Ulrike
von Luxburg, Isabelle Guyon, and Roman Garnett, editors, Advances in Neural Infor-
mation Processing Systems 29: Annual Conference on Neural Information Processing
Systems 2016, pages 1705–1713, 2016.

[14] Geoﬀ Cruttwell, Jonathan Gallagher, and Ben MacAdam. Towards formalizing and
extending diﬀerential programming using tangent categories. Proc. ACT, 2019.

[15] Fredrik Dahlqvist, Louis Parlant, and Alexandra Silva. Layer by layer–combining
In International Colloquium on Theoretical Aspects of Computing, pages

monads.
153–172. Springer, 2018.

[16] Swaraj Dash and Sam Staton. A monad for probabilistic point processes. arXiv

preprint arXiv:2101.10479, 2021.

[17] Eduardo J. Dubuc. Kan extensions in enriched category theory, volume 145. Springer,

2006.

[18] Mart´ın Escard´o. Constructive decidability of classical continuity. Math. Struct. Com-

put. Sci., 25(7):1578–1589, 2015.

[19] Martin Escard´o and Paulo Oliva. Sequential games and optimal strategies. Pro-
ceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences,
467(2130):1519–1545, 2011.

[20] Mart´ın Escard´o and Paulo Oliva. The Herbrand functional interpretation of the double

negation shift. J. Symb. Log., 82(2):590–607, 2017.

77

[21] Mart´ın H¨otzel Escard´o and Paulo Oliva. Selection functions, bar recursion and back-

ward induction. Math. Struct. Comput. Sci., 20(2):127–168, 2010.

[22] Mart´ın H¨otzel Escard´o and Paulo Oliva. The Peirce translation. Ann. Pure Appl.

Log., 163(6):681–692, 2012.

[23] Mart´ın H¨otzel Escard´o, Paulo Oliva, and Thomas Powell. System T and the product
of selection functions. In Marc Bezem, editor, Computer Science Logic, 25th Interna-
tional Workshop / 20th Annual Conference of the EACSL, CSL 2011, volume 12 of
LIPIcs, pages 233–247. Schloss Dagstuhl - Leibniz-Zentrum f¨ur Informatik, 2011.

[24] Matthias Felleisen and Daniel P. Friedman. Control operators, the secd-machine,
and the λ-calculus. In Martin Wirsing, editor, Formal Description of Programming
Concepts - III: Proceedings of the IFIP TC 2/WG 2.2 Working Conference on Formal
Description of Programming Concepts - III, pages 193–222. North-Holland, 1987.

[25] Willliam Feller. An introduction to probability theory and its applications, vol 2. John

Wiley & Sons, 2008.

[26] Andrzej Filinski. Representing monads. In Proceedings of the 21st ACM SIGPLAN-
SIGACT Symposium on Principles of Programming Languages, POPL ’94, page
446–457. ACM, 1994.

[27] Brendan Fong, David I. Spivak, and R´emy Tuy´eras. Backprop as functor: A compo-
sitional perspective on supervised learning. In 34th Annual ACM/IEEE Symposium
on Logic in Computer Science, LICS 2019, pages 1–13. IEEE, 2019.

[28] Noah D. Goodman, Vikash K. Mansinghka, Daniel M. Roy, Keith Bonawitz,
and Joshua B. Tenenbaum. Church: a language for generative models. CoRR,
abs/1206.3255, 2012.

[29] Jules Hedges. The selection monad as a CPS transformation. CoRR, abs/1503.06061,

2015.

[30] Mathieu Huot, Sam Staton, and Matthijs V´ak´ar. Correctness of automatic diﬀerenti-
ation via diﬀeologies and categorical gluing. In Jean Goubault-Larrecq and Barbara
K¨onig, editors, Foundations of Software Science and Computation Structures - 23rd
International Conference, FOSSACS 2020, volume 12077 of Lecture Notes in Com-
puter Science, pages 319–338. Springer, 2020.

[31] J. M. E. Hyland and C.-H. Luke Ong. On full abstraction for PCF: i, ii, and III. Inf.

Comput., 163(2):285–408, 2000.

[32] Martin Hyland, Paul Blain Levy, Gordon Plotkin, and John Power. Combining alge-
braic eﬀects with continuations. Theoretical Computer Science, 375(1-3):20–40, 2007.

78

[33] Martin Hyland, Paul Blain Levy, Gordon D. Plotkin, and John Power. Combining
algebraic eﬀects with continuations. Theor. Comput. Sci., 375(1-3):20–40, 2007.

[34] Martin Hyland, Gordon D. Plotkin, and John Power. Combining eﬀects: Sum and

tensor. Theor. Comput. Sci., 357(1-3):70–99, 2006.

[35] Bart Jacobs. From multisets over distributions to distributions over multisets. arXiv

preprint arXiv:2105.06908, 2021.

[36] Andrej Karpathy. Software 2.0, 2017. Blog post here.

[37] Klaus Keimel and Gordon D. Plotkin. Mixed powerdomains for probability and non-

determinism. Log. Methods Comput. Sci., 13(1), 2017.

[38] G. Max Kelly. A uniﬁed treatment of transﬁnite constructions for free algebras, free
monoids, colimits, associated sheaves, and so on. Bulletin of the Australian Mathe-
matical Society, 22(1):1–83, 1980.

[39] G. Maxwell Kelly and A. John Power. Adjunctions whose counits are coequalizers,
and presentations of ﬁnitary enriched monads. Journal of pure and applied algebra,
89(1-2):163–179, 1993.

[40] Anders Kock.

Strong functors and monoidal monads. Archiv der Mathematik,

23(1):113–120, 1972.

[41] Paul Blain Levy, John Power, and Hayo Thielecke. Modelling environments in call-

by-value programming languages. Inf. Comput., 185(2):182–210, 2003.

[42] Aliaume Lopez and Alex Simpson. Basic operational preorders for algebraic eﬀects in
general, and for combined probability and nondeterminism in particular. In Dan R.
Ghica and Achim Jung, editors, 27th EACSL Annual Conference on Computer Science
Logic, CSL 2018, volume 119 of LIPIcs, pages 29:1–29:17. Schloss Dagstuhl - Leibniz-
Zentrum f¨ur Informatik, 2018.

[43] John McCarthy. A basis for a mathematical theory of computation. In P. Braﬀort
and D. Hirschberg, editors, Computer Programming and Formal Systems, volume 35
of Studies in Logic and the Foundations of Mathematics, pages 33 – 70. Elsevier, 1963.

[44] D. McDermott, M. Ghallab, A. Howe, C. Knoblock, A. Ram, M. Veloso, D. Weld,
and D. Wilkins. PDDL - the planning domain deﬁnition language. Technical Report
TR-98-003, Yale Center for Computational Vision and Control,, 1998.

[45] Eugenio Moggi. Computational lambda-calculus and monads. In Proceedings of the
Fourth Annual Symposium on Logic in Computer Science (LICS ’89), pages 14–23.
IEEE Computer Society, 1989.

79

[46] Gordon Plotkin and John Power. Adequacy for algebraic eﬀects. In Furio Honsell and
Marino Miculan, editors, Foundations of Software Science and Computation Struc-
tures, pages 1–24. Springer Berlin Heidelberg, 2001.

[47] Gordon D. Plotkin and John Power. Algebraic operations and generic eﬀects. Applied

Categorical Structures, 11(1):69–94, 2003.

[48] Dieter Pumpl¨un and Helmut R¨ohrl. Convexity theories iv. Klein-Hilbert parts in

convex modules. Applied Categorical Structures, 3(2):173–200, 1995.

[49] Scott Sanner. Relational dynamic inﬂuence diagram language (rddl): Language de-
scription, 2011. Oﬃcial language of the uncertainty track of the Seventh International
Planning Competition.

[50] Ana Sokolova and Harald Woracek. Congruences of convex algebras. Journal of Pure

and Applied Algebra, 219(8):3110–3148, 2015.

[51] Marshall Harvey Stone. Postulates for the barycentric calculus. Annali di Matematica

Pura ed Applicata, 29(1):25–30, 1949.

[52] Daniele Varacca and Glynn Winskel. Distributing probability over non-determinism.

Mathematical Structures in Computer Science, 16(1):87–113, 2006.

[53] Tim Vieira, Matthew Francis-Landau, Nathaniel Wesley Filardo, Farzad Khorasani,
and Jason Eisner. Dyna: Toward a self-optimizing declarative language for machine
learning applications. In Proceedings of the 1st ACM SIGPLAN International Work-
shop on Machine Learning and Programming Languages, MAPL 2017, page 8–17.
ACM, 2017.

[54] Li-yao Xia, Yannick Zakowski, Paul He, Chung-Kil Hur, Gregory Malecha, Ben-
jamin C. Pierce, and Steve Zdancewic. Interaction trees: representing recursive and
impure programs in coq. Proc. ACM Program. Lang., 4(POPL):51:1–51:32, 2020.

80

