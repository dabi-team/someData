2
2
0
2

l
u
J

7
2

]

G
L
.
s
c
[

1
v
7
6
6
3
1
.
7
0
2
2
:
v
i
X
r
a

Unsupervised Training for Neural TSP Solver(cid:63)

El¯ıza Gaile1,(cid:63)(cid:63), Andis Draguns2, Em¯ıls Ozoli¸nˇs3, and K¯arlis Freivalds4

1 Faculty of Computing, University of Latvia, Riga, Latvia
eliiza.gaile@gmail.com
2 Institute of Mathematics and Computer Science at University of Latvia, Riga, Latvia
andis.draguns@lumii.lv
3 ozolinsemils@gmail.com
4 Institute of Electronics and Computer Science, Riga, Latvia
karlis.freivalds@edi.lv

Abstract. There has been a growing number of machine learning meth-
ods for approximately solving the travelling salesman problem. However,
these methods often require solved instances for training or use complex
reinforcement learning approaches that need a large amount of tuning.
To avoid these problems, we introduce a novel unsupervised learning
approach. We use a relaxation of an integer linear program for TSP to
construct a loss function that does not require correct instance labels.
With variable discretization, its minimum coincides with the optimal or
near-optimal solution. Furthermore, this loss function is diﬀerentiable
and thus can be used to train neural networks directly. We use our loss
function with a Graph Neural Network and design controlled experiments
on both Euclidean and asymmetric TSP. Our approach has the advan-
tage over supervised learning of not requiring large labelled datasets.
In addition, the performance of our approach surpasses reinforcement
learning for asymmetric TSP and is comparable to reinforcement learning
for Euclidean instances. Our approach is also more stable and easier to
train than reinforcement learning.

1

Introduction

Traveling salesman problem (TSP) is a well-known combinatorial optimization
problem that searches for the optimal way to traverse a graph while visiting each
node exactly once. TSP and its variants have broad practical applications, e.g. in
electronics and logistics [16]. Considering that TSP is an NP-hard problem, many
analytical methods and heuristics have been handcrafted to solve this problem
as optimally and eﬃciently as possible.

Neural networks have become powerful tools to solve various tasks and
have shown encouraging results also for TSP. Training neural networks to solve
combinatorial optimization tasks such as TSP presents distinct challenges for
all learning paradigms – supervised (SL), unsupervised (UL), and reinforcement

(cid:63) This research is funded by the Latvian Council of Science, project lzp-2021/1-0479.
(cid:63)(cid:63) Corresponding author.

 
 
 
 
 
 
2

El¯ıza Gaile, Andis Draguns, Em¯ıls Ozoli¸nˇs, and K¯arlis Freivalds

learning (RL). Recently, both supervised and reinforcement learning has been
widely used to solve TSP, however, both of them have disadvantages.

While SL can perform better than other learning paradigms on ﬁxed-size
graphs (e.g. [11]), supervised learning requires optimally labeled TSP examples
that are time consuming to produce even for moderately sized instances; besides
that supervised learning cannot process multiple correct solutions. Although
reinforcement learning does not have these problems, RL systems are often
complex, unstable, and less sample eﬃcient than other learning paradigms. Besides
that, RL models are not well-suited for non-autoregressive models since that would
require a vast action space with O(n2) continuous values. But autoregressive
RL models rely on decoders that use node embeddings instead of adjacency
matrix embeddings. This means that to solve asymmetric TSP using RL, the full
adjacency matrix representation must be encoded in node embeddings. It can be
done but requires powerful and complex encoders [14].

We propose to train Neural models for TSP in an unsupervised way through
minimization of a diﬀerentiable loss. By exchanging supervised loss function with
this unsupervised loss, it is possible to eliminate the need for labeled training data
without using RL and hence avoid RL disadvantages as well. The loss function is
constructed so that its global minimum corresponds to the optimal solution of
relaxed TSP; we use variable discretization to obtain integer solutions. Since loss
function is non-convex, direct minimization for a given TSP instance usually ends
up a sub-optimal local minimum, but when used for training a neural network,
the trained network manages to ﬁnd close-to-optimal solutions.

The proposed loss function does not rely on labels so it can be applied on
large instances while relieving us from the need to create a pre-solved dataset and
does not have problems with multiple solutions. In addition, our unsupervised
approach performs similarly to reinforcement learning when solving Euclidean
instances and our approach works on asymmetric TSP which reinforcement
learning struggles with.

2 Related Work

Over the last few years, many new machine learning approaches for solving
TSP have been proposed. These approaches can be divided into two directions –
hybrid methods where machine learning assists established classical heuristics
and end-to-end neural solvers where ML model outputs solutions directly from
the input.

Most of the notable end-to-end advances in TSP are based on sequence-
to-sequence models [2,18], attention models [4,13,17] or graph neural networks
[11,12,14]. Earlier works focused more on supervised learning (mostly based on
Pointer Networks [18]), however after that more and more RL approaches emerged
(e.g. [2,11,13,14]) and it was noted that reinforcement learning is generally more
suitable for TSP than SL [9,10].

To our knowledge, there are no notable works on neural end-to-end TSP
solvers with unsupervised learning despite UL also having the advantage of not

Unsupervised Training for Neural TSP Solver

3

requiring labeled data. There is also very little work on non-Euclidean TSP
variants; most of the models used for solving TSP use only node coordinates
without adjacency matrices as input and are only applied to planar TSP variants
(e.g. [4,11,13,18]).

3 Unsupervised TSP

To train a neural network in an unsupervised manner, an unsupervised loss
function is needed. We construct a diﬀerentiable function L : ([0, 1]n×n, Rn×n) →
R, where n – number of nodes in a TSP instance. The input of this function
is two matrices – matrix X which tells if each edge is a part of the proposed
optimal tour (0 – not a part of the tour, 1 – part of the tour) and matrix C
which is the adjacency matrix of the instance and contains weights of each edge.
The output of L is an abstract numerical evaluation of how close the proposed
tour is to the optimal solution; the smaller the output, the better.

3.1 Unsupervised Loss

Our approach to obtain such a loss function is based on a relaxation of an integer
program for TSP that was ﬁrst used by Dantzig, Fulkerson, and Johnson [1]. If
the vertices are numbered from 1 to n, the TSP problem can be formulated as
follows:

n
(cid:88)

n
(cid:88)

min

i=1

j(cid:54)=i,j=1

cij · xij :

0 ≤ xij ≤ 1
n
(cid:88)

xij = 1

j = 1, . . . , n;

(1)

i=1,i(cid:54)=j
n
(cid:88)

j=1,j(cid:54)=i
(cid:88)

(cid:88)

i∈Q

j(cid:54)=i,j∈Q

xij = 1

i = 1, . . . , n;

xij ≤ |Q| − 1

∀Q (cid:40) {1, . . . , n}, |Q| ≥ 2

The last constraint guarantees that the solution has no tours smaller than
the whole graph and therefore is called the subtour constraint. The subtour
constraint checks O(2n) node subsets. To avoid this exponential growth, the
subtour constraint can be replaced by a heuristic algorithm that looks only at a
part of subsets (the ones which are more likely to violate the constraint) and can
therefore run in polynomial time. If the chosen heuristic is re-applied many times
and each time the found constraint violations are corrected, a solution with no
violations will be achieved.

4

El¯ıza Gaile, Andis Draguns, Em¯ıls Ozoli¸nˇs, and K¯arlis Freivalds

For the heuristic, the parametric connectivity [1] is used. First, this heuristic

replaces the previous subtour contraint with

cut(Q, V − Q) ≥ 1

∀Q ⊂ {1, . . . , n}, |Q| ≥ 2,

(2)

i∈S

(cid:80)

where V - the set of all vertices and cut(S, T ) = (cid:80)
j∈T xij. Similarly to
DFJ, this constraint also ensures that there are no subtours in the TSP solution.
Second, the heuristic imagines the proposed solution X as a separate graph
with edge weights corresponding to xij values (these are values that determine
whether edge is is the solution). The heuristic calculates and then orders this
graph’s subsets by a parameter (cid:15), which is the maximum edge weight such that
for any two vertices in the subset, they are connected by a path in with all
edges of weight at least (cid:15). Assuming that the ﬁrst three constraints of DFJ are
satisﬁed, subsets of the graph with the largest (cid:15) have the smallest cuts (and the
largest expected values to violate subtour constraint), therefore n subsets with
the largest (cid:15) parameters are chosen to be checked.

By combining the relaxation of the integer program and the parametric
connectivity heuristic, the loss function for TSP with solution matrix X and
adjacency matrix C is obtained. We evaluate the length of the tour and how much
each of the DFJ constraints are violated (0 corresponds to satisﬁed constraints):

n
(cid:88)

n
(cid:88)

L = α ·

cij · xij+

(3)

i=1


j=1,j(cid:54)=i


n
(cid:88)

1 −

+ β ·




j=1

i=1,i(cid:54)=j

n
(cid:88)


2

xij



+



1 −

n
(cid:88)

i=1

n
(cid:88)

j=1,j(cid:54)=i

2



xij




 +

+ γ ·

(cid:88)

Q∈S

(1 − cut(Q, V − Q))2

where S - node subsets chosen by the parametric connectivity heuristic that

violate the subtour constraint; α, β, γ – scalars for scaling.

When the summands of the loss function are scaled appropriately, the global
minimum of the function thus created satisﬁes all constraints and has the shortest
tour, and can therefore express the quality of a proposed TSP solution without
optimal labels. For this paper, we experimentally found that values α = 5, β = 1,
γ = 1 work well.

Additionally, the proposed loss function L is diﬀerentiable w. r. t. solution X
and can therefore be used to train a neural network directly. It is not diﬀerentiable
w. r. t. to the choice of node subsets S and if we wanted to perfectly evaluate the
proposed solution, we should look at all its subsets. However, the use of a neural
network helps to get closer results without checking all subsets of a particular
instance and avoids exponential count of such subsets.

Unsupervised Training for Neural TSP Solver

5

3.2 Variable Discretization

To achieve a diﬀerentiable loss function, a relaxed TSP problem is used, and
the optimal solution of such a relaxation does not always correspond to integer
solutions [7]. To ensure that the solutions provided by minimization of the
unsupervised loss function are integer or can be easily converted to integer
solutions we use the Gumbel-Softmax technique [8,15]. We add Gumbel noise of
a certain magnitude to logits and then apply softmax to get xij. To understand
why adding noise helps to obtain integer solutions, consider how noise aﬀects the
xij. When logits are near zero (xij = 0.5) the addition of noise will produce large
ﬂuctuations in xij and consequently large and random loss. But when logits are
large (xij close to integer points) softmax is saturated and the impact of noise
becomes negligible. Therefore to minimize the expected loss, the network will be
encouraged to produce integer or near-integer solutions. This principle has been
described in more detail in other works [5].

Since we use greedy search to read out the obtained solution we are not
required to fully discretize the solution and noise addition is performed only to
improve the solution quality. We experimentally found out that in Euclidean
TSP case the best results are obtained without noise but in Asymmetric TSP
noise of magnitude 0.1 works well.

3.3 Implementation

Implementation of the ﬁrst three summands of L is straightforward. Our approach
to eﬃciently implement the last summand and the parametric connectivity
heuristic is based on a known method [1]. To ﬁnd the n subsets with the largest
(cid:15) parameters and therefore the smallest expected cuts, we start with an empty
graph X0 = ({1, ..., n}, ∅). By adding edges of the proposed solution X to X0 in
a descending edge weight order, components of X0 are subsets of X whose (cid:15) is at
least the value of the last edge added. Hence every time the addition of an edge
changes components of X0, the new component corresponds to the subset with
the next largest (cid:15). This way we can bypass the explicit calculation of (cid:15).

For the implementation of this algorithm, only the list of components of X0 is
needed. At ﬁrst, each vertex is in its own component. If the endpoints of the edge
with the next largest weight belong to diﬀerent components, they are merged
together by changing the component list; then the cut of the vertex subset of
the new component is checked. If the cut sum value in either direction is smaller
than one, this new component is insuﬃciently connected to the rest of the graph
and forms a subtour. This is repeated until there are only two components left.
To make our method easily usable for both symmetric and asymmetric graphs,
all graphs are implemented as directed; when ordering edge weights and adding
edges to X0, a sum of both direction weights is used. However, when observing
cuts, each direction is checked separately as this can provide more information.
It has been shown that parametric connectivity heuristic can be implemented
with complexity O(n2α(n2)) [1], α - the inverse of the Ackermann function.
However, since the parametric connectivity heuristic is used only when training

6

El¯ıza Gaile, Andis Draguns, Em¯ıls Ozoli¸nˇs, and K¯arlis Freivalds

Algorithm 1 Parametric connectivity
Input: Adjacency matrix X, where weight of each edge describes if that edge is in the
optimal tour; number of vertices n

1: Initialize empty set of cuts that violate subtour constraint S
2: Initialize array of component indexes for each vertex comp; comp ← [1..n]
3: Initialize counter i; i ← 0

4: Add all edges to Edecr
5: Sort Edecr in decreasing order of edge weight

6: for edge in Edecr do

(cid:46) Find components of both edge endpoints

7:
8:

9:
10:
11:
12:
13:

14:
15:
16:
17:

18:
19:
20:
21:
22:
23:

24:
25:
26:
27:
28:
29:
30:
31:

c ← comp[edge.endpoint1]
c0 ← comp[edge.endpoint2]

if c != c0 then
i ← i + 1
for v ← 1 to n do

if comp[v] is c0 then
comp[v] ← c

(cid:46) Merge components together

Initialize cut values for each direction cutin, cutout
cutin, cutout ← 0
for v1 ← 1 to n do

for v2 ← 1 to n do

(cid:46) Find values of cuts in both directions

c1 ← comp[v1]
c2 ← comp[v2]
if c1 == c and c2 != c then
cutin ← cutin + X[v1, v2]
if c2 == c and c1 != c then

cutout ← cutout + X[v2, v1]

(cid:46) Add a subset of vertices (cut) for each violated constraint

for sum in [cin, cout] do
if sum < 1 then

Initialize empty set Q
for v ← 1 to n do

if comp[v] == c then
Q ← Q ∪ {v}

S ← S ∪ {Q}
if i = n − 2 then return S

the model, a more advanced implementation is not necessarily needed. Our
implementation of this algorithm is simpler and the complexity of our approach
is O(n3) (see Algorithm 1).

Unsupervised Training for Neural TSP Solver

7

4 Neural Model

Our model is based on Joshi et al. [9] and follows the same pipeline: the input
is a graph represented by its adjacency matrix C and we train our model to
output matrix X ∈ [0, 1]n×n. This matrix shows which edges belong to the
optimal tour and its values can be viewed as probabilities. We use a graph neural
network that uses both edges and nodes, and each edge and node of the graph is
embedded as d-dimensional vector. Lastly, we use our diﬀerentiable loss function
L to train the network.

To get the full predicted tours from X (e.g. to use for evaluation), we use
greedy search. Greedy search ﬁnds the complete tour by starting from a random
node and traversing along the heaviest edge which is available until a Hamiltonian
cycle is formed.

We also need neural models with supervised learning and reinforcement
learning to compare our approach to diﬀerent learning paradigms. To ensure
fairness, we use the same SL and RL models as Joshi et al. [9] used in his work.

4.1 Graph Neural Network

Our graph neural network (GNN) consists of several layers and each layer (cid:96)
consists of message passing and updating of node and edge embeddings. For
initial node embeddings h(cid:96)=0
ij we use d-dimensional
linear projections of node coordinates and normalized edge weights respectively:

and edge embeddings e(cid:96)=0

ij

h(cid:96)=0
ij = nodeij · W1 + b1
cij
(cid:80)n

norm cij =

(cid:113)

1
n

(cid:80)n
k

l (ckl)2

e(cid:96)=0
ij = norm cij · W2 + b2

(4)

(5)

(6)

To update edge and node features message passing is used. Two types of
messages are computed from each edge (outgoing from vertex and incoming to
vertex) using simple MLP networks, after that vertices gather and process all
messages from their adjacent edges and the vertex itself:

out stateij =

(cid:80)n

k=1(MLP1(e(cid:96)
√
n

ik))

in stateij =

(cid:80)n

k=1(MLP2(e(cid:96)
√
n

kj))

vertex stateij = [in state, out state, h(cid:96)

ij]

(7)

(8)

(9)

Next a new edge embedding candidate for each edge is obtained from the
processed messages of adjacent vertices, and the embedding of each edge is
updated by combining the old embedding with the new candidate (tileij is used

8

El¯ıza Gaile, Andis Draguns, Em¯ıls Ozoli¸nˇs, and K¯arlis Freivalds

for ease of implementation):

tileij =






vertexij
...
vertexij








n times

candidateij = MLP3([e(cid:96)
e(cid:96)+1
ij = e(cid:96)

ij, tileij, tileT
ij])
ij · σ(a · A(cid:96)) + B(cid:96) · candidate

(10)

(11)

(12)

Lastly, the updating of node embeddings h(cid:96)

ij is done by using MLP network

on information available to vertices:

h(cid:96)+1
ij = MLP4(h(cid:96)

ij)

(13)

Each layer contains multilayer perceptrons MLP1, MLP2, MLP3, MLP4, each
with 3 layers (including input and output layer); learnable parameters W1, W2, A,
B ∈ Rd and b1, b2 ∈ R as well as a scalar value a (we experimentally determined
a = 10 to work well).

To decode edge embeddings from the last layer of GNN and get probabilities
for each edge to belong to optimal tour, we ﬁrst use two layer MLP to get logits
from embeddings; after that we get probability matrix X from logits via softmax
over each edge.

If a symmetrical TSP variant is being tackled (e.g. Euclidean TSP), we make
logits symmetrical before softmax by taking the mean of logits in each edge
direction.

5 Evaluation

We carry out several experiments to compare our unsupervised approach to both
supervised and reinforcement approaches.

All datasets are generated randomly. For symmetric graphs, we choose points
in a unit square and get adjacency matrices as Euclidean distances between
those points. For asymmetric graphs, random adjacency matrices are generated
with each edge weight ranging from 0 to 1. Correct solution tours (required for
evaluation and supervised learning) are computed using Concorde solver [3] and
Gurobi optimizer [6] for symmetric and asymmetric cases respectively.

We explore all methods on ﬁxed-size graphs of 20 and 50 vertices on Euclidean
TSP and on asymmetric TSP. For unsupervised and reinforcement learning
training 128000 examples are randomly generated in each of the 100 epochs;
for supervised learning, a larger set of 1280000 samples and their solutions
are generated beforehand. For evaluation, 1280 samples and their solutions are
generated of each type, i.e. TSP and ATSP on respective graph sizes.

To fairly compare between diﬀerent paradigms, supervised and unsupervised
models diﬀer only in the loss function. Comparison with reinforcement learning
is not as straightforward considering that the RL model is auto-regressive and

Unsupervised Training for Neural TSP Solver

9

builds the solution step by step as opposed to SL and UL models, which are non-
autoregressive and produce the solution in one shot. To ensure the comparison is
as fair as possible, for RL we use the corresponding encoder described in Joshi et
al. [9]. Unfortunately, this means that for asymmetric TSP this encoder has to
embed the adjacency matrix into node embeddings. Nonetheless, Table 1 contains
a summary of the main hyperparameters used for comparing SL, RL, and our
UL method. We also follow the experimental setup of Joshi et al. [9], but some
parameters have been adjusted for hardware limitations.

Table 1: Training parametrs for SL, UL and RL models.

Parameter

SL

UL

RL

Epochs
Epoch size
Batch size (n = 20, 50)
Encoder layers (n = 20, 50)
Number of parameters
Learning rate
Embedding and hidden dimensions

1
12800000
128, 32
16, 8
354562
10−4
64

100
128000
128, 32
16, 8
354562
10−4
64

100
128000
128, 32
16, 8
379072
10−4
64

The output of the model is the probabilities of edges to belong to the correct
tour; hence, the greedy search method is used to get a valid tour prediction.
Results are compared using optimality gap, i.e. the average percentage ratio
between the predicted tour and the correct one. We also look at inference time
(1280 samples) and inspect the consistency of validation results throughout
training to observe any unstable behaviours.

Tables 2 and 3 shows results of solving Euclidean and asymmetric TSP using
diﬀerent learning paradigms. We evaluate all methods on ﬁxed-size graphs of 20
and 50 vertices.

Table 2: Optimality gap and inference time of TSP using SL, RL and UL

Method

TSP20

Opt. Gap

SL
RL
UL

0.219
2.752
1.289

Time

2.914
3.163
2.852

TSP50

Opt. Gap

4.870
7.954
11.419

Time

8.141
8.881
8.468

In all of the experiments supervised learning shows superior results to other
learning paradigms, which we explain by our experiments being of ﬁxed-sized
graphs and supervised learning having all the information of training instances.
This also coincides with the current literature [10].

When comparing unsupervised learning with reinforcement learning, we can
observe that results on Euclidean instances are ambiguous, as UL performs better

10

El¯ıza Gaile, Andis Draguns, Em¯ıls Ozoli¸nˇs, and K¯arlis Freivalds

Table 3: Optimality gap and inference time of ATSP using SL, RL and UL

Method

ATSP20

Opt. Gap

SL
RL
UL

17.640
534.820
20.560

ATSP50

Time

3.225
3.488
3.446

Opt. Gap

83.377
1439.005
32.699

Time

9.598
9.208
9.392

on 20 vertices, but RL surpasses UL when looking at instances with 50 vertices.
However, results on asymmetric TSP are much more certain, where RL behaves
very poorly. This suggests that the encoder used is not powerful enough to
eﬃciently embed the adjacency matrix into node embeddings.

When comparing results between TSP and ATSP, we can see that performance
for asymmetric instances is noticeably worse as it is a generally harder problem.
However, UL achieves similar results to SL for asymmetric TSP, which may
indicate the adaptiveness of the unsupervised approach.

Inference time results between learning paradigms are very similar and no

noteworthy diﬀerences can be seen.

Figure 1 shows training behaviors of each of the learning paradigms in all
experiments carried out (validation done with greedy search). It can be seen in
Euclidean experiments (Figure 1a, Figure 1b) that reinforcement learning has
several big ﬂuctuations in the training process; we do not experience this with
other learning paradigms. This type of unstable behaviour is a relatively more
common behaviour for RL in general and leads to large amount of steps to train
the neural network properly. The asymmetric training graphs (Figure 1c, Figure
1d) show small or no improvement in RL training over time, indicating that the
encoder used is not suitable for asymmetric TSP.

To better see how unsupervised loss work with neural networks, we carried
out an experiment to compare straightforward minimization of the loss function
and its usage in our model. The minimization of the function was done using
Adam optimizer (learning rate = 0.01) and we let it run on each instance of
the evaluation datasets for 15000 steps which were empirically determined to
be enough for most edges to be almost discrete. To get proper tours from the
output, we use greedy search.

Results in this experiments for Euclidean TSP and asymmetric TSP can be
seen in in Table 4 and Table 5. We tracked both the optimality gap for each
method as well as inference time for 1280 instances. It should be noted that
time spent on loss minimization directly depends on optimization steps and
could be reduced by possibly sacriﬁcing the quality of the solution. For better
comprehension of the experiment, we added average results of a random tour
and also of a tour found with greedy search on the adjacency matrix.

As expected, we can see that the minimization of the loss function returns
better results than just greedy search. When the loss function is used together
with a neural network, the results are even better. This can be explained by

Unsupervised Training for Neural TSP Solver

11

(a) TSP20

(b) TSP50

(c) ATSP20

(d) ATSP50

Fig. 1: Comparison of optimality gap throughout training when using RL, SL
and UL

the fact that the loss function has many local minimums in which the optimizer
can get trapped, but a neural network helps to overcome this. If we look at the
inference times, we can see that individual optimization is very slow and is not
practical for widespread use.

Table 4: Comparison of minimization of loss function and loss function used in
neural network for TSP

Method

Random
Greedy search
Loss function
Neural network

TSP20

TSP50

Opt. Gap

Time

Opt. Gap

Time

186.959
17.620
6.736
1.289

0.007
0.169
25181.865
2.852

371.908
22.801
16.560
11.419

0.011
1.220
54313.828
8.468

12

El¯ıza Gaile, Andis Draguns, Em¯ıls Ozoli¸nˇs, and K¯arlis Freivalds

Table 5: Comparison of minimization of loss function and loss function used in
neural network for ATSP

Method

Random
Greedy search
Loss function
Neural network

ATSP20

ATSP50

Opt. Gap

Time

Opt. Gap

Time

556.233
91.194
26.413
20.560

0.007
0.169
24448.681
3.446

1492.072
145.298
47.762
32.699

0.0011
1.220
54002.372
9.392

6 Conclusions

We introduce a novel unsupervised learning approach for solving the TSP problem
with neural networks. The basis of our unsupervised method is a new diﬀerentiable
loss function that works on both Euclidean and asymmetric TSP. Unsupervised
learning has the advantage over supervised learning of not needing large correctly
labeled datasets. Our method performs similarly to reinforcement learning for
Euclidean graphs with 20 and 50 vertices and outperforms reinforcement learning
when looking at the stability of training or asymmetric graphs.

The loss function is constructed in a way to be easily modiﬁed with extra
constraints. The addition of constraints can be done by expressing the constraint
as a diﬀerentiable polynomial and adding it to the loss function. Considering
that routing problems are very widespread and often have unique limitations,
the addition of constraints is very relevant and may be very useful. This work
does not explore this possibility further but in the future, we want to examine
our work on TSP variants with additional constraints.

References

1. Applegate, D., Bixby, R., Chv´atal, V., Cook, W.: Implementing the dantzig-
fulkerson-johnson algorithm for large traveling salesman problems. Mathematical
Programming 97, 91–153 (2003)

2. Bello, I., Pham, H., Le, Q.V., Norouzi, M., Bengio, S.: Neural combinatorial

optimization with reinforcement learning. ArXiv abs/1611.09940 (2017)
3. Concorde TSP Solver: http://www.math.uwaterloo.ca/tsp/concorde/ (2003)
4. Deudon, M., Cournut, P., Lacoste, A., Adulyasak, Y., Rousseau, L.M.: Learning

heuristics for the tsp by policy gradient. In: CPAIOR (2018)

5. Frey, B.: Continuous sigmoidal belief networks trained using slice sampling. In:

NIPS (1996)

6. Gurobi Optimization: https://www.gurobi.com (2021)
7. Hougardy, S.: On the integrality ratio of the subtour lp for euclidean tsp. Operations

Research Letters 42(8), 495–499 (2014)

8. Jang, E., Gu, S., Poole, B.: Categorical reparameterization with gumbel-softmax.
In: 5th International Conference on Learning Representations, ICLR 2017, Toulon,
France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net (2017),
https://openreview.net/forum?id=rkE3y85ee

Unsupervised Training for Neural TSP Solver

13

9. Joshi, C.K., Cappart, Q., Rousseau, L.M., Laurent, T., Bresson, X.: Learning tsp

requires rethinking generalization. arXiv preprint arXiv:2006.07054 (2020)

10. Joshi, C.K., Laurent, T., Bresson, X.: On learning paradigms for the travelling

salesman problem. ArXiv abs/1910.07210 (2019)

11. Joshi, C.K., Laurent, T., Bresson, X.: An eﬃcient graph convolutional network
technique for the travelling salesman problem. arXiv preprint arXiv:1906.01227
(2019)

12. Khalil, E.B., Dai, H., Zhang, Y., Dilkina, B., Song, L.: Learning combinatorial

optimization algorithms over graphs. In: NIPS (2017)

13. Kool, W., Hoof, H.V., Welling, M.: Attention, learn to solve routing problems! In:

ICLR (2019)

14. Kwon, Y.D., Choo, J., Yoon, I., Park, M., Park, D., Gwon, Y.: Matrix encoding

networks for neural combinatorial optimization. ArXiv abs/2106.11113 (2021)

15. Maddison, C.J., Mnih, A., Teh, Y.W.: The concrete distribution: A continuous
relaxation of discrete random variables. In: 5th International Conference on Learning
Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track
Proceedings. OpenReview.net (2017), https://openreview.net/forum?id=S1jE5L5gl
16. Matai, R., Singh, S., Mittal, M.L.: Traveling salesman problem: an overview of

applications, formulations, and solution approaches (2010)

17. Nazari, M., Oroojlooy, A., Snyder, L., Tak´ac, M.: Reinforcement learning for solving

the vehicle routing problem. In: NeurIPS (2018)

18. Vinyals, O., Fortunato, M., Jaitly, N.: Pointer networks. In: NIPS (2015)

