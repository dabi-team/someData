Deployable Probabilistic Programming

David Tolpin
PUB+
Israel
david.tolpin@gmail.com

9
1
0
2

n
u
J

0
2

]
L
P
.
s
c
[

1
v
9
9
1
1
1
.
6
0
9
1
:
v
i
X
r
a

Abstract
We propose design guidelines for a probabilistic program-
ming facility suitable for deployment as a part of a produc-
tion software system. As a reference implementation, we in-
troduce Infergo, a probabilistic programming facility for Go,
a modern programming language of choice for server-side
software development. We argue that a similar probabilistic
programming facility can be added to most modern general-
purpose programming languages.

Probabilistic programming enables automatic tuning of
program parameters and algorithmic decision making through
probabilistic inference based on the data. To facilitate addi-
tion of probabilistic programming capabilities to other pro-
gramming languages, we share implementation choices and
techniques employed in development of Infergo. We illus-
trate applicability of Infergo to various use cases on case
studies, and evaluate Infergo’s performance on several bench-
marks, comparing Infergo to dedicated inference-centric prob-
abilistic programming frameworks.

ACM Reference Format:
David Tolpin. 2019. Deployable Probabilistic Programming. In Pro-
ceedings of SPLASH Onward! 2019 (Onward! 2019). ACM, New York,
NY, USA, 16 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn

1 Introduction
Probabilistic programming [13, 14, 26, 62] represents statis-
tical models as programs written in an otherwise general
programming language that provides syntax for the deﬁni-
tion and conditioning of random variables. Inference can
be performed on probabilistic programs to obtain the pos-
terior distribution or point estimates of the variables. In-
ference algorithms are provided by the probabilistic pro-
gramming framework, and each algorithm is usually appli-
cable to a wide class of probabilistic programs in a black-box
manner. The algorithms include Metropolis-Hastings[26, 59,
63], Hamiltonian Monte Carlo [10], expectation propaga-
tion [29], extensions of Sequential Monte Carlo [33, 38, 55,
62], variational inference [23, 60], gradient-based optimiza-
tion [7, 10], and others.

Onward! 2019, October 20-25, 2019, Athens, Greece
2019. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn

There are two polar views on the role of probabilistic pro-
gramming. One view is that probabilistic programming is
a ﬂexible framework for speciﬁcation and analysis of sta-
tistical models [11, 51, 59]. Proponents of this view per-
ceive probabilistic programming as a tool for data science
practitioners. A typical workﬂow consists of data acquisi-
tion and pre-processing, followed by several iterations of ex-
ploratory model design and testing of inference algorithms.
Once a suﬃciently robust statistical model is obtained, anal-
ysis results are post-processed, visualized, and occasionally
integrated into algorithms of a production software system.
The other, emerging, view is that probabilistic program-
ming is an extension of a regular programming toolbox
allowing algorithms implemented in general-purpose pro-
gramming languages to have learnable parameters. In this
view, statistical models are integrated into the software sys-
tem, and inference and optimization take place during data
processing, prediction, and algorithmic decision making
in production. Probabilistic programming code runs unat-
tended, and inference results are an integral part of the algo-
rithms. Natural applications arise whenever the algorithm is
a generative model of a mental or physical process, in par-
ticular when latent variables of the algorithm are used for
decision making [15, 61]; for example, inference about user
behavior in social networks, ongoing health monitoring, or
online motion planning of autonomous robotic devices.

In this work we are concerned with the later view on prob-
abilistic programming. Our objective is to pave a path to de-
ployment of probabilistic programs in production systems,
promoting a wider adoption of probabilistic programming
as a ﬂexible tool for ubiquitous statistical inference. Most
probabilistic programming frameworks are suited, to a cer-
tain extent, to be used in either the exploratory or the pro-
duction scenario. However, the proliferation of probabilis-
tic programming languages and frameworks 1 on one hand,
and scarcity of success stories about production use of prob-
abilistic programming on the other hand, suggest that there
is a need for new ideas and approaches to make probabilistic
programming models available for production use.

are

45 probabilistic programming

1There
on
Wikipedia [58]. 18 probabilistic programming languages were pre-
sented during the developer meetup at PROBPROG’2018, the inaugural
conference on probabilistic programming, http://probprog.cc/, half of
which are not on the Wikipedia list.

languages

listed

 
 
 
 
 
 
Onward! 2019, October 20-25, 2019, Athens, Greece

David Tolpin

Our attitude diﬀers from the established approach in that
instead of proposing yet another probabilistic programming
language, either genuinely diﬀerent [10, 28] or derived from
an existing general-purpose programming language by ex-
tending the syntax or changing the semantics [11, 13, 51],
we advocate enabling probabilistic inference on models
written in a general-purpose probabilistic programming lan-
guage, the same one as the language used to program the
bulk of the system. We formulate guidelines for such imple-
mentation, and, based on the guidelines, introduce a prob-
abilistic programming facility for the Go programming lan-
guage [50]. By explaining our implementation choices and
techniques, we argue that a similar facility can be added
to any modern general-purpose purpose programming lan-
guage, giving a production system modeling and inference
capabilities which do not fall short from and sometimes
exceed those of probabilistic programming-centric frame-
works with custom languages and runtimes. Availability of
such facilities in major general-purpose programming lan-
guages would free probabilistic programming researchers
and practitioners alike from language wars [48] and foster
practical applications of probabilistic programming.

Contributions

This work brings the following major contributions:

• Guidelines for design and implementation of a proba-
bilistic programming facility deployable as a part of a
production software system.

• A reference implementation of deployable probabilis-
tic programming facility for the Go programming lan-
guage.

outlining

• Implementation highlights

important
choices we made in implementation of the proba-
bilistic programming facility, and providing a basis
for implementation of a similar facility for other
general-purpose programming languages.

2 Related Work
Our work is related to three interconnected areas of re-
search:

1. Design and implementation of probabilistic program-

ming languages.

2. Integration and interoperability between probabilistic
programming models and the surrounding software
systems.

3. Diﬀerentiable programming for machine learning.

Probabilistic programming is traditionally associated
with design and implementation of probabilistic program-
ming languages. An apparent justiﬁcation for a new pro-
gramming language is that a probabilistic program has a

diﬀerent semantics [16, 46] than a ‘regular’ program of sim-
ilar structure. Goodman and Stuhlmüller [14] oﬀer a sys-
tematic approach to design and implementation of proba-
bilistic programming languages based on extension of the
syntax of a (subset of) general-purpose programming lan-
guage and transformational compilation to continuation-
passing style [2, 3]. van de Meent et al. [54] give a com-
prehensive overview of available choices of design and im-
plementation of ﬁrst-order and higher-order probabilistic
programming languages. Stan [10] is built around an im-
perative probabilistic programming language with program
structure tuned for most eﬃcient execution of inference on
the model. SlicStan [17] is built on top of Stan as a source-
to-source compiler, providing the model developer with a
more intuitive language while retaining performance ben-
eﬁts of Stan. Our work diﬀers from existing approaches in
that we advocate enabling probabilistic programming in a
general-purpose programming language by leveraging ex-
isting capabilities of the language, rather than building a
new language on top or besides an existing one.

The need for integration between probabilistic programs
and the surrounding software environment is well under-
stood in the literature [7, 51]. Probabilistic programming
languages are often implemented as embedded domain-
speciﬁc languages [11, 42, 51] and include a mechanism of
calling functions from libraries of the host languages. Our
work goes a step further in this direction: since the language
of implementation of probabilistic models coincides with
the host language, any library or user-deﬁned function of
the host language can be directly called from the probabilis-
tic model, and model methods can be directly called from
the host language.

Automatic diﬀerentiation is widely employed in machine
learning [5, 56] where it is also known as ‘diﬀerentiable
programming’, and is responsible for enabling eﬃcient in-
ference in many probabilistic programming frameworks [7,
10, 11, 21, 52]. Diﬀerent automatic diﬀerentiation tech-
niques [18] allow diﬀerent compromises between ﬂexibil-
ity, eﬃciency, and feature-richness [21, 34, 44]. Automatic
diﬀerentiation is usually implemented through either op-
erator overloading [10, 11, 34] or source code transforma-
tion [21, 57]. Our work, too, relies on automatic diﬀerentia-
tion, implemented as source code transformation. However,
a novelty of our approach is that instead of using explicit
calls or directives to denote parts of code which need to be
diﬀerentiated, we rely on the type system of Go to selec-
tively diﬀerentiate the code relevant for inference, thus com-
bining advantages of both operator overloading and source
code transformation.

Deployable Probabilistic Programming

Onward! 2019, October 20-25, 2019, Athens, Greece

3 Challenges
Incorporating a probabilistic program, or rather a proba-
bilistic procedure, within a larger code body appears to be
rather straightforward: one implements the model in the
probabilistic programming language, fetches and prepro-
cesses the data in the host programming language, passes
the data and the model to an inference algorithm, and post-
processes the results in the host programming language
again to make algorithmic decisions based on inference out-
comes. To choose the best option for each particular applica-
tion, probabilistic programming languages and frameworks
are customarily compared by the expressive power (classes
of probabilistic models that can be represented), concise-
ness (e.g. the number of lines of code to describe a partic-
ular model), and time and space eﬃciency of inference al-
gorithms [11, 35, 37, 62]. However, complex software sys-
tems make integration of probabilistic inference challeng-
ing, and considerations beyond expressiveness and perfor-
mance come into play.

Simulation vs. inference Probabilistic models often fol-
low the design pattern of simulation-inference: a signiﬁcant
part of the model is a simulator running an algorithm with
given parameters; the optimal parameters, or their distribu-
tion, are to be inferred. The inferred parameters are then
used by the software system to execute the simulation inde-
pendently of inference for prediction and decision making.
This pattern suggests re-use of the simulator: instead
of implementing the simulator twice, in the probabilistic
model and in the host environment, one can invoke the
same code for both purposes. However to achieve this, the
host language must coincide with the implementation lan-
guage of the probabilistic model, on one hand, and allow a
computationally eﬃcient implementation of the simulation,
on the other hand. Some probabilistic programming frame-
works (Figaro [36], Anglican [51], Turing [11]) are built with
tight integration with the host environment in mind; more
often than not though the probabilistic code is not trivial to
re-use.

Data interface The data for inference may come from a
variety of sources: network, databases, distributed ﬁle sys-
tems, and in many diﬀerent formats. Eﬃcient inference de-
pends on fast data access and updating. Libraries for data
access and manipulation are available in the host environ-
ment. While the host environment can be used as a proxy
retrieving and transforming the data, such as in the case
of Stan [10] integrations, sometimes direct access from the
probabilistic code is the preferred option, for example when
the data is streamed or retrieved conditionally, as in active
learning [49].

A ﬂexible data interface is also beneﬁcial for support
of mini-batch optimization [24]. Mini-batch optimization is
used when the data set is too big to ﬁt in memory, and the ob-
jective function gradient is estimated based on mini-batches
— small portions of data. Diﬀerent models and inference ob-
jectives may require diﬀerent mini-batch loading schemes.
For best performance of mini-batch optimization, it should
be possible to program loading of mini-batches on case-by-
case basis.

Integration and deployment Deployment of software
systems is a delicate process involving automatic builds
and maintenance of dependencies. Adding a component,
which possibly introduces additional software dependen-
cies or even a separate runtime, complicates deployment.
Minimizing the burden of probabilistic programming on the
integration and deployment process should be a major con-
sideration in design or selection of probabilistic program-
ming tools. Probabilistic programming frameworks that are
implemented or provide an interface in a popular program-
ming language, e.g. Python (Edward [52], Pyro [7]) are eas-
ier to integrate and deploy, however the smaller the foot-
print of a probabilistic programming framework, the easier
is the adoption. An obstacle in integration of probabilistic
programming lies also in adoption of the probabilistic pro-
gramming language [27], if the latter diﬀers from the imple-
mentation language of the rest of the system.

4 Guidelines
Based on the experience of developing and deploying so-
lutions using diﬀerent probabilistic programming environ-
ments, we came up with guidelines to implementation of
a probabilistic programming facility for server-side applica-
tions. We believe that these guidelines, when followed, help
easier integration of probabilistic programming inference
into large-scale software systems.

1. A probabilistic model should be programmed in the
host programming language. The facility may im-
pose a discipline on model implementation, such as
through interface constraints, but otherwise support-
ing unrestricted use of the host language for imple-
mentation of the model.

2. Built-in and user-deﬁned data structures and libraries
should be accessible in the probabilistic programming
model. Inference techniques relying on the code struc-
ture, such as those based on automatic diﬀerentiation,
should support the use of common data structures of
the host language.

3. The model code should be reusable between inference
and simulation. The code which is not required solely

Onward! 2019, October 20-25, 2019, Athens, Greece

David Tolpin

for inference should be written once for both infer-
ence of parameters and use of the parameters in the
host environment. It should be possible to run simula-
tion outside the probabilistic model without runtime
or memory overhead imposed by inference needs.

5 Probabilistic Programming in Go
In line with the guidelines, we have implemented a proba-
bilistic programming facility for the Go programming lan-
guage, Infergo. We have chosen Go because Go is a small
but expressive programming language with eﬃcient im-
plementation that has recently become quite popular for
computation-intensive server-side programming. Infergo is
used in production environment for inference of mission-
critical algorithm parameters.

5.1 An Overview of Infergo

Infergo comprises a command-line tool that augments the
source code of a model to facilitate inference, a collection of
basic models (distributions) serving as building blocks for
other models, and a library of inference algorithms.

A probabilistic model in Infergo is an implementation
of an interface requiring a single method Observe2 ac-
cepts a vector (a Go slice) of ﬂoats, the parameters to infer,
and returns a single ﬂoat, interpreted as unnormalized log-
likelihood of the posterior distribution. The model object
usually encapsulates the observations, either as a data ﬁeld
or as a reference to a data source. Implementation of model
methods can be written in virtually unrestricted Go and use
any Go libraries.

For inference, Infergo relies on automatic diﬀerentiation.
The source code of the model is translated by the command-
line tool into an equivalent model with reverse-mode auto-
matic diﬀerentiation of the log-likelihood with respect to
the parameters applied. The diﬀerentiation operates on the
built-in ﬂoating-point type and incurs only a small compu-
tational overhead. However, even this overhead is avoided
when the model code is executed outside inference algo-
rithms: both the original and the diﬀerentiated model are
simultaneously available to the rest of the program code, so
the methods can be called on the diﬀerentiated model for
inference, and on the original model for the most eﬃcient
execution with the inferred parameters.

5.2 A Basic Example

Let us illustrate the use of Infergo on a basic example serv-
ing as a probabilistic programming equivalent of the "Hello,

World!" program — inferring parameters of a unidimen-
sional Normal distribution. In this example, the model ob-
ject holds the set of observations from which the distribu-
tion parameters are to be inferred:

type ExampleModel struct {

Data []float64

}

The Observe method computes the log-likelihood of the
distribution parameters. The Normal distribution has two
parameters: mean µ and standard deviation σ . To ease the in-
ference, positive σ is transformed to unrestricted log σ , and
the parameter vector x is [µ, log σ ]. Observe ﬁrst imposes a
prior on the parameters, and then conditions the posterior
distribution on the observations:

// x[0] is the mean,
// x[1] is the log stddev of the distribution
func (m *ExampleModel)

Observe(x []float64) float64 {
// Our prior is a unit normal ...
ll := Normal.Logps(0, 1, x...)
// ... but the posterior is based
// on data observations.
ll += Normal.Logps(x[0], math.Exp(x[1]),

m.Data...)

return ll

}

For inference, we supply the data and optionally initial-
ize the parameter vector. Here the data is hard-coded, but in
general can be read from a ﬁle, a database, a network con-
nection, or dynamically generated by another part of the
program:

// Data
m := &ExampleModel{[]float64{

-0.854, 1.067, -1.220, 0.818, -0.749,
0.805, 1.443, 1.069, 1.426, 0.308}}

// Parameters
x := []float64{}

The fastest and most straightforward inference is the
maximum a posteriori (MAP) estimation, which can be done
using a gradient descent algorithm (Adam [22] in this case):

opt := &infer.Adam{

Rate: 0.01,

}
for iter := 0; iter != 1000; iter++ {

opt.Step(m, x)

}

To recover the full posterior distribution of the parame-

ters we use Hamiltonian Monte Carlo [30]:

2The method name follows Venture [26], Anglican [51], and other proba-
bilistic programming languages in which observe is the language construct
for conditioning of the model on observations.

hmc := &infer.HMC{

Eps: 0.1,

}

Deployable Probabilistic Programming

Onward! 2019, October 20-25, 2019, Athens, Greece

samples := make(chan []float64)
hmc.Sample(m, x, samples)
for i := 0; i != 5000; i++ {

x = <-samples

}
hmc.Stop()

Models are of course not restricted to linear code, and
may comprise multiple methods containing loops, condi-
tional statements, function and method calls, and recursion.
Case studies (Section 7) provide more model examples.

5.3 Model Syntax and Rules of Diﬀerentiation

In Infergo, the inference is performed on a model. Just like in
Stan [10] models, latent random variables in Infergo models
are continuous. Additionally, Infergo can express and per-
form inference on non-deterministic models by including
stochastic choices in the model code.

An Infergo model is a data type and methods deﬁned on
the data type. Inference algorithms accept a model object as
an argument. A model object usually encapsulates observa-
tions — the data to which the parameter values are adapted.
A model is implemented in Go, virtually unrestricted3. Be-
cause of this, the rules of model speciﬁcation and diﬀeren-
tiation are quite straightforward. Nonetheless, the diﬀeren-
tiation rules ensure that provided that the model’s Observe
method (including calls to other model methods) is diﬀeren-
tiable, the gradient is properly computed [18].

A model

is deﬁned in its own package. The model
must implement interface Model containing a single method
Observe. Observe accepts a slice of ﬂoat64 — the model
parameters — and returns a ﬂoat64 scalar. For probabilis-
tic inference, the returned value is interpreted as the log-
likelihood of the model parameters. Inference models rely
on computing the gradient of the returned value with re-
spect to the model parameters through automatic diﬀeren-
tiation. In the model’s source code:

1. Methods on the type implementing Model returning a

single ﬂoat64 or nothing are diﬀerentiated.

2. Within the methods, the following is diﬀerentiated:

• assignments to ﬂoat64 (including parallel assign-

ments if all values are of type ﬂoat64);

• returns of ﬂoat64;
• standalone calls to methods on the type implement-
ing Model (apparently called for side eﬀects on the
model).

Functions for which the gradient is provided rather than
derived through automatic diﬀerentiation are called elemen-
tals [18]. Derivatives do not propagate through a function
that is not an elemental or a call to a model method. If a

derivative is not registered for an elemental, calling the ele-
mental in a diﬀerentiated context will cause a run-time er-
ror.

if

Functions are considered elementals (and must have
their signature is of kind
a registered derivative)
func (ﬂoat64, ﬂoat64*) ﬂoat64; that is, one or more non-
variadic ﬂoat64 arguments and ﬂoat64 return value. For ex-
ample, function func (ﬂoat64, ﬂoat64, ﬂoat64) ﬂoat64
is considered elemental, while functions

• func (...ﬂoat64) ﬂoat64
• func ([]ﬂoat64) ﬂoat64
• func (int, ﬂoat64) ﬂoat64

are not. Gradients for selected functions from the math pack-
age are pre-deﬁned (Sqrt, Exp, Log, Pow, Sin, Cos, Tan). Aux-
iliary elemental functions with pre-deﬁned gradients are
provided in a separate package.

Any user-deﬁned function of appropriate kind can be
used as an elemental inside model methods. The gradient
must be registered for the function using a call to

func RegisterElemental(

f interface{},
g func(value float64,

params ...float64) []float64)

For example, the call

RegisterElemental(Sigm,
func(value float64,

_ ...float64) []float64 {

return []float64{value*(1-value)}

})

registers the gradient for function Sigm(x) ≔ (1 + e−x )−1.

5.4 Inference

Out of the box, Infergo oﬀers

• maximum a posteriori (MAP) estimation by stochastic

gradient descent [40];

• full posterior
Carlo [19, 30].

inference by Hamiltonian Monte

When only a point estimate of the model parameters is re-
quired, as, for example, in the simulation-inference case, sto-
chastic gradient descent is a fast and robust inference family.
Infergo oﬀers stochastic gradient descent with momentum
and Adam [22]. The inference is performed by calling the
Step method of the optimizer until a termination condition
is met:

for !<termination condition> {

optimizer.Step(model, parameters)

}

3There are insigniﬁcant implementation limitations which are gradually
lifted as Infergo is being developed.

When the full posterior must be recovered for integra-
tion, Hamiltonian Monte Carlo (HMC) can be used instead.

Onward! 2019, October 20-25, 2019, Athens, Greece

David Tolpin

Vanilla HMC as well as the No-U-Turn sampler (NUTS) [19]
are provided. To support lazy any-time computation, the in-
ference runs in a separate goroutine, connected by a channel
to the caller, and asynchronously writes samples to the chan-
nel. The caller reads as many samples from the channel as
needed, and further postprocesses them:

samples := make(chan []float64)
hmc.Sample(model, parameters, samples)
for !<termination condition> {

sample = <-samples
// postprocess the sample

}
hmc.Stop()

Other inference schemes, most notably automatic diﬀer-
entiation variational inference [23], are planned for addition
in future versions of Infergo. However, an inference algo-
rithm does not have to be a part of Infergo to work with
Infergo models. Since Infergo models operate on a built-in
Go ﬂoating point type, ﬂoat64, any third-party inference or
optimization library can be used as well.

As an example, the Gonum [4] library for numerical com-
putations contains an optimization package oﬀering several
algorithms for gradient-based optimization. A Gonum op-
timization algorithm requires the function to optimize, as
well as the function’s gradient, as parameters. An Infergo
model can be trivially wrapped for use with Gonum, and
Infergo provides a convenience function

func FuncGrad(m Model) (

Func func(x []float64) float64,
Grad func(grad []float64, x []float64))

which accepts a model and returns the model’s Observe
method and its gradient suitable for passing to Gonum op-
timization algorithms. Among available algorithms are ad-
vanced versions of stochastic gradient descent, as well as
algorithms of BFGS family, in particular L-BFGS [25], pro-
viding for a more eﬃcient MAP estimation than stochastic
gradient descent at the cost of higher memory consumption:

function, gradient := FuncGrad(model)
problem := gonum.Problem{Func: function,
Grad: gradient}

result, err := gonum.Minimize(problem, parameters)

Other third-party implementations of optimization algo-
rithms can be used just as easily, thanks to Infergo models
being pure Go code operating on built-in Go data types.

6 Implementation Highlights
In our journey towards implementation and deployment of
Infergo, we considered options and made implementation

decisions which we believe to have been crucial for address-
ing the challenges and following the guidelines we formu-
lated for implementation of a deployable probabilistic pro-
gramming facility. While diﬀerent choices may be as well
suited for the purpose as the ones we made, we feel it is im-
portant to share our contemplations and justify decisions,
to which the rest of this section is dedicated, from choosing
the implementation language, through details of automatic
diﬀerentiation, to support for inference on streaming and
stochastic observations.

6.1 Choice of Programming Language

Python [39], Scala [31], and Julia [6] have been popular
choices for development of probabilistic programming lan-
guages and frameworks integrated with general-purpose
programming languages [7, 9, 11, 21, 36, 41, 57]. Each of
these languages has advantages for implementing a prob-
abilistic programming facility. However, for a reference im-
plementation of a facility best suited for probabilistic infer-
ence in a production software system, we were looking for
a language that

• compiles into fast and compact code;
• does not incur dependency on a heavy runtime; and
• is a popular choice for building server-side software.

In addition, since we were going to automatically diﬀerenti-
ate the language’s source code, we were looking for a rela-
tively small language, preferably one for which parsing and
program analysis tools are readily available.

We chose Go [50]. Go is a small but expressive
programming language widely used for implementing
computationally-intensive server-side software systems.
The standard libraries and development environment oﬀer
capabilities which made implementation of Infergo aﬀord-
able and streamlined:

• The Go parser and abstract syntax tree serializer are
a part of the standard library. Parsing, transforming,
and generating Go source code is straightforward and
eﬀortless.

• Type inference (or type checking as it is called in the
Go ecosystem), also provided in the standard library,
augments parsing, and allows to selectively apply
transformation-based automatic diﬀerentiation based
on static expression types.

• Go provides reﬂection capabilities for almost any as-
pect of the running program, without compromising
eﬃciency. Reﬂection gives the ﬂexibility highly desir-
able to implement features such as calling Go library
functions from the model code.

• Go compiles and runs fast. Fast compilation and exe-
cution speeds allow to use the same facility for both

Deployable Probabilistic Programming

Onward! 2019, October 20-25, 2019, Athens, Greece

exploratory design of probabilistic models and for in-
ference in production environment.

• Go is available on many platforms and for a wide
range of operating systems and environments, from
portable devices to supercomputers. Go programs
can be cross-compiled and reliably developed and de-
ployed in heterogeneous environments.

• Go oﬀers eﬃcient parallel execution as a ﬁrst-class
feature, via so-called goroutines. Goroutines stream-
line implementation of sampling-based inference al-
gorithms. Sample generators and consumers are run
in parallel, communicating through channels. Infer-
ence is easy to parallelize in order to exploit hardware
multi-processing, and samples are retrieved lazily for
postprocessing.

Considering and choosing Go for development of what
later became Infergo also aﬀected the shape of the soft-
ware system in which Infergo was deployed ﬁrst. Formerly
implemented mostly in Python, and both enjoying a wide
choice of libraries for machine learning and data processing
and suﬀering from limitations of Python as a language for
implementation of computation-intensive algorithms, the
system has been gradually drifting towards adopting Go,
with performance-critical parts re-implemented and run-
ning faster due to better hardware and network utilization,
and simpler and more maintainable code for data process-
ing, analysis, and decision making.

6.2 Automatic Diﬀerentiation

Infergo employs reverse-mode automatic diﬀerentiation via
source code transformation [18]. The reverse mode is the
default choice in machine learning applications, because it
works best with diﬀerentiating a scalar return value with
respect to multiple parameters. Automatic diﬀerentiation is
usually implemented using either operator overloading or
source code transformation. Operator overloading is often
the method of choice [10, 11, 34] due to relative simplicity,
but the diﬀerentiated code must use a special type (on which
the operators are overloaded) for representing ﬂoating point
numbers. Regardless of the issue of computational overhead,
this restricts the language used to specify the model to op-
erations on that special type and impairs interoperability:
library functions cannot be directly called but have to use
an adaptor, or a ‘lifted’ version of the standard library must
be supplied. Similarly, the data must be cast into the special
type before it is passed to the model for inference.

Reverse mode source code transformation Source code
transformation allows to automatically diﬀerentiate pro-
gram code operating on the built-in ﬂoating point type.

This method involves generation of new code, for the func-
tion gradient or for the function itself, ahead of time or on
the ﬂy. To achieve the best performance, some implementa-
tions generate static code for computing the function gradi-
ent [20, 57]. This requires a rather elaborated source code
analysis, and although a signiﬁcant progress has been made
in this direction, not all language constructs are supported.
Alternatively, the code of the function itself can be trans-
formed by augmenting arithmetics and function calls on the
ﬂoating point type by function calls that record the compu-
tations on the tape, just like in the case of operator overload-
ing. Then, the backward pass is identical to that of operator
overloading. This method allows the use of the built-in ﬂoat-
ing point type along with virtually unrestricted language for
model speciﬁcation, at the cost of slight performance loss.
This latter method is used in Infergo: the model is written
in Go and is placed in a separate Go package. A command-
line tool is run on the package to generate a sub-package
containing a diﬀerentiated version of the model. Both the
original and the diﬀerentiated model are available simulta-
neously in the calling code, so that model methods that do
not require computation of gradients can be invoked with-
out the overhead of automatic diﬀerentiation. However, the
performance loss is rarely a major issue — diﬀerentiated ver-
sions of model methods are only 2–4 times slower on mod-
els from the case studies (Section 7), and the backward pass,
which computes the gradient, is roughly as fast as the orig-
inal, undiﬀerentiated version. At least partially, fast back-
ward pass is due to careful implementation and thorough
proﬁling of the tape.

Automatic diﬀerentiation of models
It may seem de-
sirable to implement or use an automatic diﬀerentiation
library that is more general than needed for probabilistic
programming. However the use of such library, in particu-
lar with source code transformation, may make implemen-
tation restricted and less eﬃcient: ﬁrst, if a model com-
prises several functions, all functions must have a signa-
ture suitable for diﬀerentiation (that is, accept and return
ﬂoating point scalars or vectors); second, the gradient of
every nested call must be fully computed ﬁrst and then
used to compute the gradient of the caller. In Infergo, only
the gradient of Observe is needed, and any other diﬀerenti-
ated model method can only be called from Observe or an-
other diﬀerentiated method. Consequently, only the gradi-
ent of Observe is computed explicitly, and other diﬀerenti-
ated methods may have arbitrary arguments. In particular,
derivatives may propagate through ﬁelds of the model ob-
ject and structured arguments.

Onward! 2019, October 20-25, 2019, Athens, Greece

David Tolpin

...

1 type A struct {Data []float64}
2 func (model A) Observe(x []float64) {
3
4 }
5
6 type B struct {Data []float64}
7 func (model B) Observe(x []float64) {
8
9 }
10
11 type AB struct {Data []float64}
12 func (model AB) Observe(x []float64) float64 {
13
14
15 }

return A{model.Data}.Observe(x[:1]) +

B{model.Data}.Observe(x[1:])

...

Figure 1. Model composition. Model AB is the product of A
and B.

6.3 Model Composition

Just like it is possible to compose library and user-deﬁned
functions into more complex functions, it should be possi-
ble to compose models to build other models [43, 52]. In-
fergo supports model composition organically: a diﬀerenti-
ated model method can be called from another diﬀerentiated
method, not necessarily a method of the same model object
or type. Derivatives can propagate through methods of dif-
ferent models without restriction. Each model is a building
block for another model. For example, if there are two in-
dependent single-parameter models A and B describing the
data, then the product model AB can be obtained by compo-
sition of A and B (Figure 1). Combinators such as product,
mixture, or hierarchy can be realized as functions operating
on Infergo models.

programming

Distributions A probabilistic
facility
should provide a library of distributions for deﬁnition and
conditioning of random variables. To use a distribution
in a diﬀerentiable model, the distribution’s log probabil-
ity density function must be diﬀerentiable by both the
distribution’s parameters and by the value of the random
variable. Distributions are usually supplied as a part of the
probabilistic programming framework [10, 11, 51], and, if
at all possible, adding a user-deﬁned distribution requires
programming at a lower level of abstraction than while
specifying a probabilistic model [1, 41, 51].

In Infergo, distributions are just models, and adding and
using a custom distribution is indistinguishable from adding
a model and calling the model’s method from another model.
By convention, library distributions, in addition to Observe,
also have methods Logp and Logps for the scalar and vec-
tor version of log probability density functions, for conve-
nience of use in models. The distribution library in Infergo

}

} else {

return dist.Logp(lambda, y[0])

return dist.Logps(lambda, y...)

float64 {
lambda, y := x[0], x[1:]
if len(y) == 1 {

1 // Exponential distribution.
2 type expon struct{}
3
4 // Exponential distribution, singleton instance.
5 var Expon expon
6
7 // Observe implements the Model interface. The
8 // parameter vector is lambda, observations.
9 func (dist expon) Observe(x []float64)
10
11
12
13
14
15
16
17 }
18
19 // Logp computes the log pdf of a single
20 // observation.
21 func (_ expon) Logp(lambda float64, y float64)
22
23
24
25 }
26
27 // Logps computes the log pdf of a vector
28 // of observations.
29 func (_ expon) Logps(lambda float64, y ...float64)
30
31
32
33
34
35
36
37 }

float64 {
ll := 0.
logl := math.Log(lambda)
for i := range y {

float64 {
logl := math.Log(lambda)
return logl - lambda*y

ll += logl - lambda*y[i]

}
return ll

Figure 2. The exponential distribution in Infergo.

is just a model package which is automatically diﬀerenti-
ated like any other model. New distributions can be added
in any package. Figure 2 shows the Infergo deﬁnition of the
exponential distribution.

6.4 Stochasticity and Streaming

Perhaps somewhat surprisingly, most probabilistic pro-
grams are semantically deterministic [47] — probabilistic
programs deﬁne distributions, and although they manipu-
late random variables, there is no randomization or non-
determinism per se. Randomization arises in certain infer-
ence algorithms (notably of the Monte Carlo family) for
tractable approximate inference, but this does not intro-
duce non-determinism into the programs themselves. Non-
deterministic probabilistic programs arise in applications.

Deployable Probabilistic Programming

Onward! 2019, October 20-25, 2019, Athens, Greece

Data chan float64 // data is a channel
N

// batch size

int

1 type StreamingModel struct {
2
3
4 }
5
6 func (m *StreamingModel)
7
8
9
10
11
12
13
14
15 }

}
return ll

Observe(x []float64) float64 {

ll := Normal.Logps(0, 1, x...)
// observe a batch of data from the channel
for i := 0; i != m.N; i++ {

ll += Normal.Logp(x[0], math.Exp(x[1]),

<- m.Data)

Figure 3. The basic example with the data read from a chan-
nel.

For example, van de Meent et al. [53] explored using proba-
bilistic programming for policy search in non-deterministic
domains. To represent non-determinism, appropriate con-
structs had to be added to the probabilistic programming
language used in the study.

In Infergo, non-determinism can be easily introduced
through data. In the basic example if Section 5.2, the data
is encapsulated in the model as a vector, populated before
inference. However, this is not at all required by Infergo. In-
stead of being stored in a Go slice, the data can be read from
a Go channel or network connection and generated by an-
other goroutine or process. Figure 3 shows a modiﬁed model
from the basic example with the data gradually read from a
channel rather than passed as a whole in a ﬁeld of the model
object.

A similar approach can be applied to streaming data: the
model may read the data gradually as it arrives, and the in-
ference algorithm will emit samples from the time process
inferred from the data. Work is still underway on algorithms
ensuring robust and sound inference on streams, but Infergo
models connected to data sources via channels are already
used in practice.

7 Case Studies
In this section, we present three case studies of probabilis-
tic programs, each addressing a diﬀerent aspect of Infergo.
Eight schools (Section 7.1) is a popular example we use to
compare model speciﬁcation in Stan and Infergo. Linear re-
gression (Session 7.2) formulated as a probabilistic program
lets us explore a model comprising multiple methods and il-
lustrate the simulation-inference pattern. Gaussian mixture
(Section 7.3) is the most complex model of the three, featur-
ing nested loops and conditionals.

By no means do the models presented in this section re-
ﬂect the complexity or the size of real-world Infergo applica-
tions, the latter reaching hundreds of lines of code in length
and performing inference on tens of thousands of data en-
tries. Rather, their purpose is to provide a general picture of
probabilistic programming with Infergo.

7.1 Eight Schools

The eight schools problem [12] is an application of the hi-
erarchical normal model that often serves as an introduc-
tory example of Bayesian statistical modeling. Without go-
ing into details, in this problem the eﬀect of coaching pro-
grams on test outcomes is compared among eight schools.
Figure 4 shows speciﬁcations of the same model in Stan and
Infergo, side-by-side.

Stan models are written in a probabilistic programming
language tailored to statistical modeling. Infergo models
are implemented in Go. One can see that the models have
roughly the same length and structure. The deﬁnition of
the model type in Go (lines 1–5) corresponds to the data
section in Stan (lines 1–5). Destructuring of the parame-
ters of Observe in Go (lines 9–11) names the parameters
just like the parameters section in Stan (lines 8–10). In-
troduction of theta in Go (line 16) corresponds to the
transformed parameters section in Stan (lines 13–16). The
only essential diﬀerence is the explicit loop over the data
in Go (lines 15–18) versus vectorized computations in Stan
(lines 15 and 20). However, vectorized computations are
used in Stan to speed-up execution more than to improve
readability. If repeated calls to Normal.Logp (line 17) become
the bottleneck, an optimized vectorized version can be im-
plemented in Go in the same package. While subjective, our
feeling is that the Go version is as readable as the Stan one.
In addition, a Go programmer is less likely to resist adoption
of statistical modeling if the models are implemented in Go.

7.2 Linear Regression

The model in Figure 5 speciﬁes linear regression on unidi-
mensional data: an improper uniform prior is placed on the
parameters α, β, and log σ (lines 9–10), which are then con-
ditioned on observations x, y such that

y ∼ Normal(α + βx, σ )

(1)

(lines 12–17). If only the maximum a posteriori is estimated,
the parameter values will maximize their likelihood given
the observations:

(α, β, σ )MAP = arg max Ö

i

pdf Normal(α + βxi , σ )

(2)

Once the values of α and β are estimated, they are used to
predict y for unseen values of x. Hence, the linear transfor-
mation α + βx is computed in two diﬀerent contexts: ﬁrst,

Onward! 2019, October 20-25, 2019, Athens, Greece

David Tolpin

int<lower=0> J;
vector[J] y;
vector<lower=0>[J] sigma;

1 data {
2
3
4
5 }
6
7 parameters {
real mu;
8
real<lower=0> tau;
9
vector[J] eta;
10
11 }
12
13 transformed parameters {
vector[J] theta;
14
theta = mu + tau * eta;
15
16 }
17
18 model {
19
20
21 }

eta ~ normal(0, 1);
y ~ normal(theta, sigma);

J
Y
Sigma

int
[]float64
[]float64

mu := x[0]
tau := math.Exp(x[1])
eta := x[2:]

1 type SchoolsModel struct {
2
3
4
5 }
6
7
8 func (m *SchoolsModel) Observe(x []float64) float64 {
9
10
11
12
13
14
15
16
17
18
19
20
21 }

theta := mu + tau*eta[i]
ll += Normal.Logp(theta, m.Sigma[i], y)

ll := Normal.Logp(0, 1, eta)

for i, y := range m.Y {

return ll

}

a. Stan

b. Infergo

Figure 4. Eight schools: Stan vs. Infergo. The Go implementation has a similar length and structure to the Stan model.

ll := 0.

float64 {

for i := range m.Data {
ll += Normal.Logp(

alpha, beta := x[0], x[1]
sigma := math.Exp(x[2])

1 type LRModel struct {
Data [][]float64
2
3 }
4
5 func (m *LRModel) Observe(x []float64)
6
7
8
9
10
11
12
13
14
15
16
17
18
19 }
20
21 // Simulate simulates y based on x and
22 // regression parameters.
23 func (m *LRModel) Simulate(x, alpha, beta float64)
24
25
26
27 }

m.Simulate(m.Data[i][0], alpha, beta),
sigma,
m.Data[i][1])

y := alpha + beta*x
return y

}
return ll

float64 {

Figure 5. Linear regression: the simulator is re-used in both
inference and prediction.

to compute the likelihood of the parameter values; then,
to predict y based on a given x. This is an example of the
simulation-inference pattern (Section 3): method Simulate
simulates y based on x and is invoked both from Observe
and then directly for prediction. Since both original and dif-
ferentiated model are simultaneously available in the source
code, Simulate can be called for prediction on the original
model, without any diﬀerentiation overhead.

In this greatly simpliﬁed case study, the simulator is a
one-line function. In a real-world scenario though, the sim-
ulator can be laborious to re-implement correctly and eﬃ-
ciently; for example, a simulator that executes a parameter-
ized policy in an uncertain or dynamic domain, and depends
on both parameter values and observations [53]. The ability
to re-use a single implementation both as a part of the prob-
abilistic program, where the simulator must be augmented
for inference (e.g. by automatic diﬀerentiation), and for pre-
diction or decision making, where the simulator may be ex-
ecuted repeatedly and under time pressure, saves the eﬀort
otherwise wasted on rewriting the simulator and removes
the need to maintain consistency between diﬀerent imple-
mentations.

7.3 Gaussian Mixture Model

The Gaussian mixture model is a probabilistic model of a
mixture of components, where each component comes from
a Gaussian distribution. The model variant in Figure 6 ac-
cepts a vector of single-dimensional observations and the

Deployable Probabilistic Programming

Onward! 2019, October 20-25, 2019, Athens, Greece

number of components, and infers the distribution of pa-
rameters of each component in the mixture. Following Stan
User’s Guide [45], component memberships are summed
out to make the model diﬀerentiable. The model contains
most of the steps commonly found in Infergo models. First, a
prior on the model parameters is imposed (lines 8–9). Then,
the parameter vector is destructured into a form convenient
for formulation of conditioning (lines 11–17). Finally, the pa-
rameters are conditioned on the observations (lines 19–34).
The conditioning of parameters involves a nested loop
over all observations and over all mixture components for
each observation. Computing log-likelihood of the model
parameters implies summing up likelihoods over compo-
nents for each observation. In the log-domain, a trick called
‘log-sum-exp’ is required to avoid loss of precision. The trick
is implemented as function logSumExp and called for each
observation and component (line 28).

logSumExp could have been implemented as a model
method and diﬀerentiated automatically. However, this
function is called on each iteration of the inner loop. Hence,
eﬃciency of inference in general is aﬀected by an eﬃcient
implementation of logSumExp (this can also be conﬁrmed
by proﬁling). To save on the cost of a diﬀerentiated call and
speed up gradient computation, logSumExp is implemented
as an elemental (lines 36–43). The hand-coded gradient is
supplied for logSumExp (lines 45–54) to make automatic dif-
ferentiation work.

While still a very simple model compared to real-world In-
fergo models, this case study illustrates common parts and
coding patterns of an elaborated model. The model code
may be quite complicated algorithmically and manipulate
Go data structures freely. When eﬃciency becomes an is-
sue, parts of the model can be implemented at a lower level
of abstraction, but nonetheless in the same programming
language as the rest of the model.

8 Performance
It is customary to include performance evaluation on bench-
mark problems in publications on new probabilistic pro-
gramming frameworks [11, 32, 51, 62]. We provide here
a comparison of running times of Infergo and two other
probabilistic programming frameworks: Turing [11] and
Stan [10]. Turing is a Julia [6] library and DSL oﬀering
exploratory statistical modeling and inference composition.
Stan is a compiled language and a library optimized for high
performance.

We use three models of diﬀerent size and structure for the
comparison: two of the models, Eight schools and Gaussian
mixture model, were introduced as a part of the case stud-
ies (Section 7); the code for the third model, Latent Dirichlet
allocation [8], is included in Appendix A. The code and data

}

m.Data[i])

// number of components

lj := Normal.Logp(mu[j], sigma[j],

if j == 0 {
l = lj
} else {

mu[j] = x[2*j]
sigma[j] = math.Exp(x[2*j+1])

var l float64
for j := 0; j != m.NComp; j++ {

Data []float64 // observations
NComp int

// Compute log likelihood of the mixture
for i := 0; i != len(m.Data); i++ {

ll := 0.0
// Impose a prior on component parameters
ll += Normal.Logps(0, 1, x...)

// Fetch the parameters
mu := make([]float64, m.NComp)
sigma := make([]float64, m.NComp)
for j := 0; j != m.NComp; j++ {

1 type GMModel struct {
2
3
4 }
5
6 func (m *GMModel) Observe(x []float64) float64 {
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34 }
35
36 // logSumExp computes log(exp(x)+exp(y)) robustly.
37 func LogSumExp(x, y float64) float64 {
38
39
40
41
42
43 }
44
45 // logSumExp gradient must be supplied.
46 func init() {
47
48
49
50
51
52
53
54 }

[]float64 {
z := math.Exp(params[1] - params[0])
t := 1 / (1 + z)
return []float64{t, t * z}

}
return z + math.Log(math.Exp(x-z)+math.Exp(y-z))

z := x
if y > z {
z = y

func(_ float64, params ...float64)

ad.RegisterElemental(logSumExp,

}
return ll

l = logSumExp(l, lj)

}
ll += l

})

}

Figure 6. Gaussian mixture model: an Infergo model with
dynamic control structure and a user-deﬁned elemental.

Onward! 2019, October 20-25, 2019, Athens, Greece

David Tolpin

model

time, seconds

compilation

execution

Eight schools
Gaussian mixture model
Latent Dirichlet allocation

Infergo Turing Stan Infergo Turing Stan
0.12
4.9
3.7

0.50
0.50
0.50

0.60
32
8.9

2.8
14
12

50
54
54

-
-
-

Table 1. Compilation and execution times for 1000 iterations of HMC with 10 leapfrog steps.

for all models were originally included in Stan examples and
translated for use with Turing and Infergo. Eight schools is
the smallest model. One may expect that most of the time
execution time is spent in executing the boilerplate code
rather than the model. Gaussian mixture model is a more
elaborated model which beneﬁts greatly from vectorization.
The greater the number of observations (1000 data points
were used in the evaluation), the more signiﬁcant is the ben-
eﬁt of vectorized computations. Latent Dirichlet allocation is,
again, a relatively elaborated model, which is, however, not
as easy to vectorize.

We report both compilation time (for Stan and Infergo)
and execution time. Compilation time is an important char-
acteristic of a probabilistic programming framework — sta-
tistical modeling often involves many cycles of model mod-
iﬁcations and numerical experiments on subsampled data.
The ability to modify and instantly re-run a model is crucial
for exploratory data analysis and model design. Turing is
based on Julia, which is a dynamic language with JIT com-
piler, and there is no separate compilation time. For Stan, the
compilation time includes compiling the Stan model to C++,
and then compiling the C++ source into executable code
for inference. For Infergo, the compilation time consists of
automatic diﬀerentiation of the model, and then building a
command-line executable that calls an inference algorithm
on the model.

Table 1 shows running time measurements on the mod-
els. The measurements were obtained on a 1.25GHz Intel(R)
Core(TM) i5 CPU with 8GB of memory for 1000 iterations of
Hamiltonian Monte Carlo with 10 leapfrog steps and aver-
aged over 10 runs. In execution, Infergo is slower than Stan,
which comes as little surprise — Stan is a mature highly opti-
mized inference and optimization library. However, Infergo
and Turing show similar execution times, despite Turing re-
lying on Julia’s numerical libraries. The slowest relative ex-
ecution time is on the Gaussian mixture model, where Stan
is 6–7 times faster, apparently because Infergo model is not
vectorized; the model could be made more eﬃcient at the
cost of verbosity and poorer readability, but we opted to use
idiomatic Infergo models for the comparison. On the Latent
Dirichlet allocation model, run on Stan example data with
25 documents and 262 word instances, Infergo is only 2.5

times slower than Stan, and faster than Turing, an illustra-
tion of the beneﬁts of transformation-based diﬀerentiation
and eﬃciency of Go.

Infergo programs compile very fast, in particular in com-
parison to Stan models. Both automatic diﬀerentiation and
code generation combined take a fraction of a second. Com-
pilation time of Stan models is dominated by compilation
of the generated C++ code which takes close to a minute
on our hardware. The ability to modify a model and then
re-run inference almost instantly, and with reasonable per-
formance, helps in exploratory model development with In-
fergo, which was conceived with server-side, unattended ex-
ecution in mind, but ﬁts the exploration and development
stage just as well.

9 Conclusion
Building a production software system which employs prob-
abilistic inference as an integral part of prediction and deci-
sion making algorithms is challenging. To address the chal-
lenges, we proposed guidelines for implementation of a de-
ployable probabilistic programming facility. Based on the
guidelines, we introduced Infergo, a probabilistic program-
ming facility in Go, as a reference implementation in accor-
dance with the guidelines. Infergo allows to program infer-
ence models in virtually unrestricted Go, and to perform in-
ference on the model using either supplied or third-party
algorithms. We demonstrated on case studies how Infergo
overcomes the challenges by following the guidelines.

A probabilistic programming facility similar to Infergo
can be added to most modern general-purpose program-
ming languages, in particular those used for implemen-
tation of large-scale software systems, making probabilis-
tic programming inference more accessible in large scale
server-side applications. We described Infergo implementa-
tion choices and techniques in intent to encourage broader
adoption of probabilistic programming in production soft-
ware systems and ease implementation of similar facilities
in other languages and software environments.

Infergo is an ongoing project. Development of Infergo is
inﬂuenced both by feedback from the open-source Go com-
munity and by the needs of the software system in which
Infergo was initially deployed, and which still supplies the

Deployable Probabilistic Programming

Onward! 2019, October 20-25, 2019, Athens, Greece

most demanding use cases in terms of ﬂexibility, scalability,
and ease of integration and maintenance. Deploying proba-
bilistic programming as a part of production software sys-
tem has a mutual beneﬁt of both improving the core algo-
rithms of the system and of helping to shape and improve
probabilistic modeling and inference, thus further advanc-
ing the ﬁeld of probabilistic programming.

Onward! 2019, October 20-25, 2019, Athens, Greece

David Tolpin

References
[1] Jeﬀrey Annis, Brent J. Miller, and Thomas J. Palmeri. 2017. Bayesian
inference with Stan: A tutorial on adding custom distributions. Be-
havior Research Methods 49, 3 (01 Jun 2017), 863–886.

[2] Andrew W. Appel. 2007. Compiling with Continuations. Cambridge

University Press, New York, NY, USA.

[3] A. W. Appel and T. Jim. 1989. Continuation-passing, Closure-passing
Style. In Proceedings of the 16th ACM SIGPLAN-SIGACT Symposium
on Principles of Programming Languages (POPL ’89). ACM, New York,
NY, USA, 293–302.
[4] Gonum authors.
http://gonum.org/.

Gonum numerical

packages.

2017.

[5] Atılım Günes Baydin, Barak A. Pearlmutter, Alexey Andreyevich
Radul, and Jeﬀrey Mark Siskind. 2017. Automatic Diﬀerentiation in
Machine Learning: A Survey. J. Mach. Learn. Res. 18, 1 (Jan. 2017),
5595–5637.

[6] Jeﬀ Bezanson, Alan Edelman, Stefan Karpinski, and Viral B. Shah.
Julia: A Fresh Approach to Numerical Computing. CoRR

2014.
abs/1411.1607 (2014). arXiv:1411.1607

[7] Eli Bingham, Jonathan P. Chen, Martin Jankowiak, Fritz Obermeyer,
Neeraj Pradhan, Theofanis Karaletsos, Rohit Singh, Paul Szerlip, Paul
Horsfall, and Noah D. Goodman. 2019. Pyro: Deep Universal Prob-
abilistic Programming. Journal of Machine Learning Research 20, 28
(2019), 1–6.

[8] David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2002. Latent
Dirichlet Allocation. Journal of Machine Learning Research 3 (2002),
2003.

[9] Avi Bryant. 2018. Rainier. https://github.com/stripe/rainier.
[10] Bob Carpenter, Andrew Gelman, Matthew Hoﬀman, Daniel Lee, Ben
Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter
Li, and Allen Riddell. 2017. Stan: A Probabilistic Programming Lan-
guage. Journal of Statistical Software, Articles 76, 1 (2017), 1–32.
[11] Hong Ge, Kai Xu, and Zoubin Ghahramani. 2018. Turing: Composable
inference for probabilistic programming. In International Conference
on Artiﬁcial Intelligence and Statistics, AISTATS 2018, 9-11 April 2018,
Playa Blanca, Lanzarote, Canary Islands, Spain. 1682–1690.

[12] A. Gelman, J.B. Carlin, H.S. Stern, and D.B. Rubin. 2013. Bayesian Data

Analysis, Third Edition. Taylor & Francis.

[13] Noah D. Goodman, Vikash K. Mansinghka, Daniel M. Roy, Keith
Bonawitz, and Joshua B. Tenenbaum. 2008. Church: a language for
generative models. In Proceedings of Uncertainty in Artiﬁcial Intelli-
gence.

[14] N. D. Goodman and A. Stuhlmüller. 2014. The Design and Implemen-
tation of Probabilistic Programming Languages. http://dippl.org/ elec-
tronic; retrieved 2019/3/29.

[15] Noah D Goodman,

Joshua B. Tenenbaum, and The Prob-
Probabilistic Models of Cognition.

Mods Contributors. 2016.
http://probmods.org/v2. Accessed: 2019-4-29.

[16] Andrew D. Gordon, Thomas A. Henzinger, Aditya V. Nori, and Sri-
ram K. Rajamani. 2014. Probabilistic Programming. In International
Conference on Software Engineering (ICSE, FOSE track).

[17] Maria I. Gorinova, Andrew D. Gordon, and Charles Sutton. 2019. Prob-
abilistic Programming with Densities in SlicStan: Eﬃcient, Flexible,
and Deterministic. Proceedings of the ACM on Programming Lan-
guages 3, POPL, Article 35 (Jan. 2019), 30 pages.

[18] Andreas Griewank and Andrea Walther. 2008. Evaluating Deriva-
tives: Principles and Techniques of Algorithmic Diﬀerentiation (second
ed.). Society for Industrial and Applied Mathematics, Philadelphia,
PA, USA.

[19] Matthew D. Hoﬀman and Andrew Gelman. 2011. The No-U-Turn Sam-
pler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo.

arXiv:1111.4246

[20] Michael Innes. 2018. Don’t Unroll Adjoint: Diﬀerentiating SSA-Form

Programs. arXiv:1810.07951

[21] Michael Innes, Elliot Saba, Keno Fischer, Dhairya Gandhi, Marco Con-
cetto Rudilosso, Neethu Mariya Joy, Tejan Karmali, Avik Pal, and Viral
Shah. 2018. Fashionable Modelling with Flux. arXiv:1811.01457
[22] Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Sto-
chastic Optimization. In 3rd International Conference for Learning Rep-
resentations, San Diego. arXiv:1412.6980

[23] Alp Kucukelbir, Dustin Tran, Rajesh Ranganath, Andrew Gelman, and
David M. Blei. 2017. Automatic Diﬀerentiation Variational Inference.
J. Mach. Learn. Res. 18, 1 (Jan. 2017), 430–474.

[24] Mu Li, Tong Zhang, Yuqiang Chen, and Alexander J. Smola. 2014. Eﬃ-
cient Mini-batch Training for Stochastic Optimization. In Proceedings
of the 20th ACM SIGKDD International Conference on Knowledge Dis-
covery and Data Mining (KDD ’14). ACM, New York, NY, USA, 661–
670.

[25] Dong C. Liu and Jorge Nocedal. 1989. On the limited memory BFGS
method for large scale optimization. Mathematical Programming 45,
1 (01 Aug 1989), 503–528.

[26] Vikash K. Mansinghka, Daniel Selsam, and Yura N. Perov. 2014. Ven-
ture: a higher-order probabilistic programming platform with pro-
grammable inference. arXiv:1404.0099

[27] Leo A. Meyerovich and Ariel S. Rabkin. 2012. Socio-PLT: Principles
for Programming Language Adoption. In Proceedings of the ACM In-
ternational Symposium on New Ideas, New Paradigms, and Reﬂections
on Programming and Software (Onward! 2012). ACM, New York, NY,
USA, 39–54.

[28] Brian Milch, Bhaskara Marthi, Stuart Russell, David Sontag, Daniel L.
Ong, and Andrey Kolobov. 2007. BLOG: Probabilistic Models with
Unknown Objects. In Statistical Relational Learning, Lise Getoor and
Ben Taskar (Eds.). MIT Press.

[29] T Minka, J Winn, J Guiver, and D Knowles. 2010. Infer .NET 2.4, Mi-

crosoft Research Cambridge.

[30] Radford M. Neal. 2012. MCMC using Hamiltonian dynamics. Pub-
lished as Chapter 5 of the Handbook of Markov Chain Monte Carlo,
2011. arXiv:1206.1901

[31] Martin Odersky. 2006. The Scala Experiment: Can We Provide Better
Language Support for Component Systems?. In Conference Record of
the 33rd ACM SIGPLAN-SIGACT Symposium on Principles of Program-
ming Languages (POPL ’06). ACM, New York, NY, USA, 166–167.
[32] Brooks Paige and Frank Wood. 2014. A compilation target for prob-
abilistic programming languages. In Proceedings of The 31st Interna-
tional Conference on Machine Learning. 1935–1943.

[33] B. Paige, F. Wood, A. Doucet, and Y.W. Teh. 2014. Asynchronous Any-
time Sequential Monte Carlo. In Advances in Neural Information Pro-
cessing Systems.

[34] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Ed-
ward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca
Antiga, and Adam Lerer. 2017. Automatic diﬀerentiation in PyTorch.
In NIPS Autodiﬀ Workshop.

[35] Yura N. Perov. 2016. Applications of Probabilistic Programming (Mas-

ter’s thesis, 2015). CoRR abs/1606.00075 (2016).

[36] Avi Pfeﬀer. 2009. Figaro: An object-oriented probabilistic program-
ming language. Charles River Analytics Technical Report 137 (2009),
96.

[37] Tom Rainforth. 2017. Automating Inference, Learning, and Design us-

ing Probabilistic Programming. Ph.D. Dissertation.

[38] Tom Rainforth, Christian A Naesseth, Fredrik Lindsten, Brooks Paige,
Jan-Willem van de Meent, Arnaud Doucet, and Frank Wood. 2016. In-
teracting Particle Markov Chain Monte Carlo. In Proceedings of the

Deployable Probabilistic Programming

Onward! 2019, October 20-25, 2019, Athens, Greece

33rd International Conference on Machine Learning (JMLR: W&CP),
Vol. 48.

[39] Guido Rossum. 1995. Python Reference Manual. Technical Report.

Amsterdam, The Netherlands, The Netherlands.

[40] Sebastian Ruder. 2016. An overview of gradient descent optimization

algorithms. arXiv:1609.04747

[41] John Salvatier, Thomas V. Wiecki, and Christopher Fonnesbeck. 2016.
Probabilistic programming in Python using PyMC3. PeerJ Computer
Science 2 (apr 2016), e55.

[42] Adam Scibior, Zoubin Ghahramani, and Andrew D. Gordon. 2015.
Practical probabilistic programming with monads. In Proceedings of
the 8th ACM SIGPLAN Symposium on Haskell, Haskell 2015, Vancou-
ver, BC, Canada, September 3-4, 2015. 165–176.

[43] Eli Sennesh, Adam Scibior, Hao Wu, and Jan-Willem van de
Meent. 2018. Composing Modeling and Inference Operations with
Probabilistic Program Combinators. CoRR abs/1811.05965 (2018).
arXiv:1811.05965 http://arxiv.org/abs/1811.05965

[44] Stan Development Team. 2014. Stan: A C++ Library for Probability

and Sampling, Version 2.4. (2014).

[56] Bart van Merrienboer, Olivier Breuleux, Arnaud Bergeron, and Pas-
cal Lamblin. 2018. Automatic diﬀerentiation in ML: Where we are
and where we should be going.
In Advances in Neural Information
Processing Systems 31, S. Bengio, H. Wallach, H. Larochelle, K. Grau-
man, N. Cesa-Bianchi, and R. Garnett (Eds.). Curran Associates, Inc.,
8757–8767.

[57] Bart van Merrienboer, Dan Moldovan, and Alexander Wiltschko. 2018.
Tangent: Automatic diﬀerentiation using source-code transformation
for dynamically typed array programming. In Advances in Neural In-
formation Processing Systems 31, S. Bengio, H. Wallach, H. Larochelle,
K. Grauman, N. Cesa-Bianchi, and R. Garnett (Eds.). Curran Asso-
ciates, Inc., 6256–6265.

[58] Wikipedia. 2019. Probabilistic programming language — Wikipedia,

The Free Encyclopedia. [Online; accessed 16-April-2019].

[59] David Wingate, Andreas Stuhlmüller, and Noah D. Goodman. 2011.
Lightweight Implementations of Probabilistic Programming Lan-
guages Via Transformational Compilation. In Proceedings of the 14th
Artiﬁcial Intelligence and Statistics.

[60] David Wingate and Theophane Weber. 2013. Automated variational

[45] Stan Development Team. 2018. Stan Modeling Language User’s Guide

inference in probabilistic programming. arXiv:1301.1299

and Reference Manual, Version 2.18.0. http://mc-stan.org/

[46] S. Staton, H. Yang, C. Heunen, O. Kammar, and F. Wood. 2016. Se-
mantics for probabilistic programming: higher-order functions, con-
tinuous distributions, and soft constraints. In Thirty-First Annual
ACM/IEEE Symposium on Logic In Computer Science.

[47] Sam Staton, Hongseok Yang, Frank Wood, Chris Heunen, and Ohad
Kammar. 2016. Semantics for Probabilistic Programming: Higher-
order Functions, Continuous Distributions, and Soft Constraints. In
Proceedings of the 31st Annual ACM/IEEE Symposium on Logic in
Computer Science (LICS ’16). ACM, New York, NY, USA, 525–534.
https://doi.org/10.1145/2933575.2935313

[61] John Winn, Christopher M. Bishop, Thomas Diethe, and Yordan Za-
ykov. 2019. Model Based Machine Learning. http://mbmlbook.com/
electronic; retrieved 2019/4/21.

[62] Frank Wood, Jan-Willem van de Meent, and Vikash Mansinghka. 2014.
A New Approach to Probabilistic Programming Inference. In Artiﬁcial
Intelligence and Statistics.

[63] Lingfeng Yang, Pat Hanrahan, and Noah D Goodman. 2014. Gener-
ating Eﬃcient MCMC Kernels from Probabilistic Programs. In Pro-
ceedings of the Seventeenth International Conference on Artiﬁcial Intel-
ligence and Statistics. 1068–1076.

[48] Andreas Steﬁk and Stefan Hanenberg. 2014. The Programming Lan-
guage Wars: Questions and Responsibilities for the Programming Lan-
guage Community. In Proceedings of the 2014 ACM International Sym-
posium on New Ideas, New Paradigms, and Reﬂections on Programming
& Software (Onward! 2014). ACM, New York, NY, USA, 283–299.
[49] Q. Sun, A. Laddha, and D. Batra. 2015. Active learning for structured
probabilistic models with histogram approximation. In IEEE Confer-
ence on Computer Vision and Pattern Recognition (CVPR). 3612–3621.
language.

The Go programming

2009.

[50] The Go team.
http://golang.org/.

[51] David Tolpin, Jan-Willem van de Meent, Hongseok Yang, and Frank
Wood. 2016. Design and Implementation of Probabilistic Program-
ming Language Anglican. In Proceedings of the 28th Symposium on
the Implementation and Application of Functional Programming Lan-
guages (IFL 2016). ACM, New York, NY, USA, Article 6, 12 pages.
[52] Dustin Tran, Matthew D. Hoﬀman, Rif A. Saurous, Eugene Brevdo,
Kevin Murphy, and David M. Blei. 2017. Deep probabilistic program-
ming. In International Conference on Learning Representations.
[53] Jan-Willem van de Meent, Brooks Paige, David Tolpin, and Frank
Wood. 2016. Black-Box Policy Search with Probabilistic Programs.
In Proceedings of the 19th International Conference on Artiﬁcial Intelli-
gence and Statistics, AISTATS 2016, Cadiz, Spain, May 9-11, 2016. 1195–
1204.

[54] Jan-Willem van de Meent, Brooks Paige, Hongseok Yang, and
Frank Wood. 2018. An Introduction to Probabilistic Programming.
arXiv:1809.10756

[55] Jan-Willem van de Meent, Hongseok Yang, Vikash Mansinghka,
Particle Gibbs with Ancestor Sampling
and Frank Wood. 2015.
for Probabilistic Programs. In Artiﬁcial Intelligence and Statistics.
arXiv:1501.06769

Onward! 2019, October 20-25, 2019, Athens, Greece

David Tolpin

A Latent Dirichlet Allocation Model

Infergo

Stan

data {

// num topics
// num words
// num docs

int<lower=2> K;
int<lower=2> V;
int<lower=1> M;
int<lower=1> N;
int<lower=1,upper=V> w[N];
int<lower=1,upper=M> doc[N]; // doc for word n
vector<lower=0>[K] alpha;
vector<lower=0>[V] beta;

// topic prior
// word prior

// word n

// total word instances

}

parameters {

simplex[K] theta[M]; // topic dist for doc m
simplex[V] phi[K];

// word dist for topic k

}

model {

for (m in 1:M)

theta[m] ~ dirichlet(alpha); // prior

for (k in 1:K)

phi[k] ~ dirichlet(beta);

// prior

for (n in 1:N) {
real gamma[K];
for (k in 1:K)

gamma[k] <- log(theta[doc[n],k])

+ log(phi[k,w[n]]);

increment_log_prob(log_sum_exp(gamma));

}

}

ll := 0.0

// Impose priors
ll += Dirichlet{m.K}.Logps(m.Alpha, theta...)
ll += Dirichlet{m.V}.Logps(m.Beta, phi...)

// num topics
// num words
// num docs
// total word instances
// word n
// doc for word n

// Regularize the parameter vector
ll += Normal.Logps(0, 1, x...)
// Destructure parameters
theta := make([][]float64, m.M)
m.FetchSimplices(&x, m.K, theta)
phi := make([][]float64, m.K)
m.FetchSimplices(&x, m.V, phi)

K
V
M
N
Word []int
Doc
[]int
Alpha []float64 // topic prior
Beta []float64 // word prior

1 type LDAModel struct {
int
2
int
3
int
4
int
5
6
7
8
9
10 }
11
12 func (m *LDAModel) Observe(x []float64) float64 {
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37 }
38
39 func (m *Model) FetchSimplices(
40
41
42
43 ) {
44
45
46
47
48 }

// Condition on observations
gamma := make([]float64, m.K)
for in := 0; in != m.N; in++ {

px *[]float64,
k int,
simplices [][]float64,

}
ll += D.LogSumExp(gamma)

math.Log(phi[ik][m.Word[in]-1])

for ik := 0; ik != m.K; ik++ {

for i := range simplices {

}
return ll

}

simplices[i] = make([]float64, k)
D.SoftMax(model.Shift(px, k), simplices[i])

gamma[ik] = math.Log(theta[m.Doc[in]-1][ik]) +

