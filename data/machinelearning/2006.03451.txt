Sparsiﬁed Linear Programming for Zero-Sum Equilibrium Finding

Brian Hu Zhang 1 Tuomas Sandholm 1 2 3 4

0
2
0
2

n
u
J

9
2

]
T
G
.
s
c
[

2
v
1
5
4
3
0
.
6
0
0
2
:
v
i
X
r
a

Abstract

Computational equilibrium ﬁnding in large zero-
sum extensive-form imperfect-information games
has led to signiﬁcant recent AI breakthroughs.
The fastest algorithms for the problem are
new forms of counterfactual regret minimiza-
tion (Brown & Sandholm, 2019). In this paper we
present a totally different approach to the problem,
which is competitive and often orders of magni-
tude better than the prior state of the art. The
equilibrium-ﬁnding problem can be formulated
as a linear program (LP) (Koller et al., 1994), but
solving it as an LP has not been scalable due to the
memory requirements of LP solvers, which can
often be quadratically worse than CFR-based al-
gorithms. We give an efﬁcient practical algorithm
that factors a large payoff matrix into a product
of two matrices that are typically dramatically
sparser. This allows us to express the equilibrium-
ﬁnding problem as a linear program with size only
a logarithmic factor worse than CFR, and thus al-
lows linear program solvers to run on such games.
With experiments on poker endgames, we demon-
strate in practice, for the ﬁrst time, that modern
linear program solvers are competitive against
even game-speciﬁc modern variants of CFR in
solving large extensive-form games, and can be
used to compute exact solutions unlike iterative
algorithms like CFR.

1. Introduction

Imperfect-information games model strategic interactions
between agents that do not have perfect knowledge of their
current situation, such as auctions, negotiations, and recre-
ational games such as poker and battleship. Linear pro-

1Department of Computer Science, Carnegie Mellon Univer-
sity, Pittsburgh, PA, USA 2Strategic Machine, Inc.
3Strategy
Robot, Inc. 4Optimized Markets, Inc.. Correspondence to: Brian
Hu Zhang <bhzhang@cs.cmu.edu>, Tuomas Sandholm <sand-
holm@cs.cmu.edu>.

Proceedings of the 37 th International Conference on Machine
Learning, Vienna, Austria, PMLR 119, 2020. Copyright 2020 by
the author(s).

gramming (LP) can be used to solve—that is, to ﬁnd a Nash
equilibrium in—imperfect-information two-player zero-sum
perfect-recall games (Koller et al., 1994). However, due
mostly to memory usage (see e.g., Zinkevich et al., 2007
or Brown & Sandholm, 2019), it has generally been thought
of as impractical for solving large games. Thus, a series of
other techniques has been developed for solving such games.
Most prominent among these is the counterfactual regret
minimization (CFR) family of algorithms (Zinkevich et al.,
2007). These algorithms work by iteratively improving both
player’s strategies until their time averages converge to an
equilibrium. They have a worst-case bound of O(1/ε2)
iterations needed to reach accuracy ε, and more recent im-
provements, most notably CFR+ (Tammelin, 2014) and
discounted CFR (DCFR) (Brown & Sandholm, 2019) mean
that algorithms from the CFR family remain the state of
the art in practice for solving large games, and have been
used as an important part of the computational pipelines to
achieve superhuman performance in benchmark cases such
as heads-up limit (Bowling et al., 2015) and no-limit (Brown
& Sandholm, 2017) Texas hold’em.

Several families of algorithms have theoretically faster con-
vergence rates than those of the CFR family. First-order
methods (Hoda et al., 2010; Kroer et al., 2015) have a theo-
retically better convergence guarantee of O(1/ε) (or even
log(1/ε) with a condition number (Gilpin et al., 2012)), but
in practice perform worse than the newest algorithms in
the CFR family (Kroer et al., 2018; Brown & Sandholm,
2019). Standard algorithms for LP are known that converge
at rate O(log(1/ε)), but for the most part, these algorithms
require storage of the whole payoff matrix explicitly, which
the CFR family does not, and often require superlinear time
per iteration (with respect to the number of nonzero entries
of the LP constraint matrix), which is prohibitive when the
game is extremely large.

In this paper we investigate how to reduce the space require-
ments of LP solvers by factoring the possibly dense payoff
matrix of an extensive-form game. A long body of work
investigates the problem of decomposing, or factoring, a
given matrix A as the product of other matrices, with some
objective in mind. Studied objectives include the speedup of
certain operations, as in the LU or Cholesky factorizations,
and approximation of the matrix A in a certain norm, as in
the singular value decomposition (SVD). Our objective in

 
 
 
 
 
 
Sparsiﬁed Linear Programming for Zero-Sum Equilibrium Finding

this work is sparsity: we investigate the problem of factoring
a matrix A into the product of two matrices U and V that are
much sparser than A. This differs from the usual low-rank
approximation in that the optimization objective is different
(0-norm, that is, number of non-zero entries, instead of the
2-norm, that is, the square root of sum of squares), and that
the matrices U and V might not be low rank (and in fact
in poker they will high rank that is linear in the number of
sequences in the game).

We are not aware of any prior application-independent work
that addresses this problem. The SVD approximates A in
the wrong norm for this purpose: 2-norm approximations
will in the general case have fully dense residual, which is
not desirable. The body of work on sparse PCA (e.g., Zou
& Xue, 2018) focuses on low-rank sparse factorizations.
That still mostly focuses on 2-norm approximations, and
the runtime of the algorithm usually scales with the rank
of the factorization as well as the size of A. In our cases,
an optimal factorization may have high or even full rank
(and yet be sparse), and our matrices are large enough that
quadratic (or worse) dependence on (cid:107)A(cid:107)0, which is often
seen in these algorithms, is unacceptable. Our goal is to
ﬁnd such a factorization efﬁciently. Neyshabur & Panigrahy
(2013) address the same problem, but restrict their attention
to matrices that are known a priori to be the product of
sparse matrices with entries drawn independently from a
nice distribution. This is not the case in our setting. Richard
et al. (2014) attack a related but still substantially different
problem, of ﬁnding a sparse factorization when we know a
priori a good bound on the sparsity of each row or column
of the factors. This, too, is not true in our setting: no such
bound may even exist, much less be known.

Our main technical contribution is a novel practical matrix
factorization algorithm that greatly reduces the size of the
game payoff matrix in many cases. This matrix factorization
allows LP algorithms to run in far less memory and time
than previously known, bringing the memory requirement
close to that of CFR. We demonstrate in practice that this
method can reduce the size of a payoff matrix by multiple
orders of magnitude, yielding improvements in both the time
and space efﬁciency of solving the resulting LP. This makes
our approach—automated matrix sparsiﬁcation followed
by LP—superior to domain-independent versions of the
fastest CFR variant. If high accuracy is desired, our domain-
independent approach in many cases outperforms even a
highly customized poker-speciﬁc implementation of the
fastest CFR variant (Brown & Sandholm, 2019).

We show experiments with the primal simplex, dual simplex,
and the barrier method as the LP solver. The barrier method
runs in polynomial time but each iteration is heavy in terms
of memory and time. For that reason, we present techniques
that signiﬁcantly speed up a recent O(log2(1/ε)) LP algo-

rithm (Yen et al., 2015) that has iteration time and memory
linear in the number of nonzero entries in the constraint
matrix, and show experiments with that as well. Our experi-
ments show interesting performance differences among the
LP solvers as well.

2. Preliminaries

Extensive-form games. We study the standard represen-
tation of games which can include sequential and simulta-
neous moves, as well as imperfect information, called an
extensive-form game. It consists of the following. (1) A
set of players P, usually identiﬁed with positive integers.
Random chance, or “nature” is also considered a player,
and will be referred to as player 0. (2) A ﬁnite tree H of
histories or nodes, rooted at some initial state ∅ ∈ H. Each
node is labeled with the player (possibly nature) who acts
at that node. The set of leaves, or terminal states, in H will
be denoted Z. The edges connecting any node h ∈ H to
its children are labeled with actions. (3) For each player
i ∈ P, a utility function ui : Z → R. (4) For each player
i ∈ P, a partition of the nodes at which player i acts into
a collection Ii of information sets. In each information set
I ∈ Ii, every pair of nodes h, h(cid:48) ∈ I must have the same
set of actions. (5) For each node h at which nature acts, a
distribution σ0(h) over the actions available that node.

For any history h ∈ H and any player i ∈ P, the sequence
h[i] of player i at node h is the sequence of information sets
reached and actions played by player i on the path from the
root node to h. The set of sequences for player i is denoted
Si. A player i has perfect recall if h[i] = h(cid:48)[i] whenever h
and h(cid:48) are in the same information set I ∈ Ii. In this work,
we will focus our attention on two-player zero-sum games
of perfect recall; i.e., games in which P = {1, 2}, u1 =
−u2, and both players have perfect recall. For simplicity of
notation, the opponent of player i will be denoted −i.

A behavior strategy (hereafter simply strategy) σi for player
i is, for each information set I ∈ Ji at which player i
acts, a distribution σi(I) over the actions available at that
infoset. When an agent reaches information set I, it chooses
an action according to σi(I). A pair (σ1, σ2) of behavior
strategies, one for each player, is a strategy proﬁle. The
reach probability πσ
i (h) is the probability that node h will be
reached, assuming that player i plays according to strategy
σi, and all other players (including nature) always choose
actions leading to h when possible. This deﬁnition extends
to sets of nodes or to sequences by summing the reach
probabilities.

The best response value BRV(σ−i) for player i against an
opponent strategy σ−i is the largest achievable value; i.e.,
in a two-player game, BRV(σ−i) = maxσi ui(σi, σ−i). A
strategy σi is an ε-best response to opponent strategy σ−i if

Sparsiﬁed Linear Programming for Zero-Sum Equilibrium Finding

ui(σi, σ−i) ≥ BRV(σ−i) − ε. A strategy proﬁle σ is an ε-
Nash equilibrium if its Nash gap BRV(σ2) + BRV(σ1) is at
most ε. Best responses and Nash equilibria are respectively
0-best responses and 0-Nash equilibria. The exploitability
exp(σi) of a strategy is how far away σi is away from a Nash
equilibrium: exp(σi) = BRV(σi) − BRV(σ∗
i is
a Nash equilibrium strategy for the player. In a zero-sum
game, the Nash value BRV(σ∗
i ) is the same for every Nash
equilibrium strategy, so the exploitability is well-deﬁned.

i ) where σ∗

Equilibrium ﬁnding via linear programming. Nash equi-
librium ﬁnding in an extensive-form game can be cast as an
LP in the following fashion (von Stengel, 1996). Consider
mapping behavior strategies σi to vectors x ∈ RSi by set-
ting x(s) = πσ
i (s) for every sequence s. We will refer to
vector x as a strategy. Under this framework, equilibrium
ﬁnding can be cast as a bilinear saddle point problem

max
x≥0

min
y≥0

xT Ay

s.t. Bx = b, Cy = c,

x, y ≥ 0

where the matrices B and C satisfy (cid:107)B(cid:107)0 = O(|S1|),
(cid:107)C(cid:107)0 = O(|S2|), and encode the constraints on the be-
havior strategies x and y. A is the payoff matrix whose
(i, j) entry is the expected payoff for Player 1 when Player
1 plays to reach sequence i and Player 2 plays to reach se-
quence j: A = (cid:80)
z[2] where
ei is the ith unit vector. The number of entries (cid:107)A(cid:107)0 ≤ |Z|.
Now taking the dual of the inner minimization yields the LP

z∈Z π0(z)u1(z[1], z[2])ez[1]eT

max
x≥0,z

cT z

s.t.

Bx = b, C T z ≤ AT x.

(1)

η > 0. The dual of this subproblem is

min
x,z

cT
LPxLP +

η
2

(cid:13)
(cid:13)
(cid:13)
(cid:13)

ALPxLP − bLP + zLP +

s.t. xLP ≥ 0, zLP ≥ 0

1
η

ˆy

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
2
(3)

The approach is shown in Algorithm 1.
In Line 2, the
solution to Problem (3) is computed via either a random-
ized coordinate descent (RC) or a projected Newton-CG
(PG) algorithm; the details are not important here. The
breakthrough of Yen et al. (2015) is an implementation of
these inner loops in O((cid:107)ALP(cid:107)0) time, rather than O(mn)
or worse. At each iteration, x∗ is infeasible in the origi-
nal problem since the quadratic regularization term in (3)
does not punish slightly infeasible solutions much at all. y∗
is infeasible since (x∗, z∗) is a suboptimal solution to (3).
Thus, Algorithm 1 works with infeasible solutions to the LP,
which must be projected back into the feasible space.

Algorithm 1 Augmented Lagrangian algorithm for solving
linear programs (Yen et al., 2015)
Input: initial dual solution guess ˆy ∈ Rm, parameter η > 0
Output: primal-dual solution pair (x∗, ˆy)
1: loop
2:

let (x∗, z∗) be an approximate solution to
Problem (3) given the current ˆy and η.

3:
4:

set ˆy ← ˆy + η(ALPx∗ − bLP + z∗)
if necessary (as detailed by Yen et al. (2015)),

increase η by a constant factor

Expressed in any LP standard form, the constraint matrix
has O(|S1| + |S2| + |Z|) nonzero entries in its constraint
matrix. The LP can be solved with any standard solver.

Sparse linear programming. Yen et al. (2015) give a
generic algorithm for solving LPs in the standard form1

Theorem 1 (Theorem 3 in Yen et al., 2015). After
O(log(1/ε)) outer iterations of Algorithm 1, each of which
is run for O(log(1/ε)) inner iterations, we have d(ˆy, S) ≤
ε where S ⊆ Rm is the set of dual-optimal solutions and d
is Euclidean distance.

min
xLP≥0

cT
LPxLP s.t. ALPxLP ≤ bLP

(2)

We ﬁrst give a brief overview of the algorithm. We are
interested in LPs of the standard form (2) and their duals

min
yLP≥0

LPyLP s.t. −AT
bT

LPyLP ≤ cLP

where A ∈ Rm×n. Consider the convex subproblem

min
yLP≥0

bT
LPyLP +

1
2η

(cid:107)yLP − ˆy(cid:107)2
2

s.t. −AT

LPyLP ≤ cLP

The O in the above theorem hides problem-dependent con-
stants such as condition numbers. This theoretical guarantee
applies to the dual solution, and not the primal. Thus, to
ﬁnd a primal-dual solution pair, in theory we must run Al-
gorithm 1 twice: on the primal (to ﬁnd a dual solution) and
then the dual (to ﬁnd a primal solution). In practice, the
primal solution from the ﬁrst run already has extremely low
exploitability, so the second run would be unnecessary.

The rest of the paper covers our new contributions.

3. Adapting the O(log2(1/ε)) Sparse LP

for some given initial solution ˆy ∈ Rm and real number

Solver

1 We use the subscript LP everywhere due to the clash of vari-
able naming conventions between LP (where ALP is the constraint
matrix) and equilibrium ﬁnding (where A is the payoff matrix).

In order to make the above LP algorithm fast for game
solving, we had to make a modiﬁcation and also deal with
the caveat of eternally infeasible solutions xLP and yLP.

Sparsiﬁed Linear Programming for Zero-Sum Equilibrium Finding

3.1. Limiting the Number of Inner Iterations

Yen et al. (2015) give an implementation of their algorithm,
which they call LPsparse. In it, the inner loop runs until
either (1) it converges to a sufﬁciently small error tolerance,
or (2) some prescribed iteration limit is hit. The iteration
limit is set to increase exponentially every time it is hit. In
practice, we found this to be far too aggressive, leading to
inner loops that take prohibitively long (an hour or more
on two-player no-limit Texas hold’em endgames). Thus,
we instead we only allow the number of inner iterations to
grow linearly with respect to the number of outer iterations.
Since both the outer and inner loop lengths are bounded
by O(log(1/ε)) in Theorem 1, this does not change the
theoretical performance guarantee of the algorithm, and it
leads to a signiﬁcant speedup in practice.

3.2. Normalizing Infeasible Solutions

Algorithm 1 will output an infeasible solution pair. To re-
trieve a valid behavior strategy (feasible solution), we ﬁrst
project into the positive orthant (i.e., zero out any negative
entries), and then normalize each information set in topolog-
ical order, starting with the root. This results in a strategy
pair whose Nash gap we can evaluate. This normalization
step roughly maintains the guarantee of Theorem 1:

Theorem 2. Suppose xLP = (x, z) is an infeasible solution
to (1) such that d((x, z), S) ≤ ε, where S is the set of opti-
mal solutions to (1). Then the above normalization yields
a (feasible) strategy with exploitability at most εn4(cid:107)A(cid:107)∞,
where n is the total number of sequences between the two
players.

A proof is in the appendix. The above bound is loose, but
it is unnecessary to improve it for the theoretical punch-
line: combining Theorems 1 and 2, we see that the LP
algorithm converges to a strategy with exploitability ε in
O(log2(1/ε)) inner iterations (where the O possibly hides
problem-dependent constants), assuming A is normalized
(i.e., (cid:107)A(cid:107)∞ is ﬁxed to, say, 1).

4. Sparse Factorization

In many games, the payoff matrix A is somewhat dense.
This occurs when the number of terminal game tree nodes,
|Z|, is large compared to the total number of sequences
|S1| + |S2|, that is, when a signiﬁcant fraction of the se-
quence pairs represent valid terminal nodes. In most normal-
form (a.k.a. matrix-form) games, A is fully dense, whereas
in extensive-form games of perfect information, A is ex-
tremely sparse (because the number of terminal nodes equals
the total number of terminal sequences between the players).
In most real games, the value of each entry Aij can be com-
puted in constant time from the indices i and j alone based
on the rules of the game, with a minimal amount of auxiliary

memory, so A can be stored implicitly. In these cases, the
sparse LP solver is at a disadvantage compared to the CFR
family of algorithms. CFR can run with only implicit access
to A. Its memory usage is thus O(|S1| + |S2|). LP solvers,
on the other hand, require a full description of A, which
here will have size O(|Z|). Our idea here is to make LP
solvers practical by carefully compressing A in a way that
standard LP solvers can still handle.

This leads to our main idea. If we can write A approximately
as the product of two matrices; that is, A = ˆA + U V T , such
that (cid:107)U (cid:107)0+(cid:107)V (cid:107)0+(cid:107) ˆA(cid:107)0 (cid:28) (cid:107)A(cid:107)0, then we can reformulate
the LP (1) as

max
x≥0,z,w

cT z

s.t.

Bx = b, C T z ≤ V w + ˆAT x, U T x = w

which, in standard form, has O((cid:107)B(cid:107)0 + (cid:107)C(cid:107)0 + (cid:107)U (cid:107)0 +
(cid:107)V (cid:107)0 + (cid:107) ˆA(cid:107)0) nonzero constraint matrix entries. In this
formulation, we demand that not only U and V but also the
residual ˆA be sparse. Depending on the density of A and the
quality of the factorization ˆA + U V T , a good factorization
could yield a quadratic improvement in both the time and
space used by the LP solver.

When A is low-rank, SVD would provide such a factor-
ization. However, in many cases, A is not sparse and not
well approximated by a low-rank factorization. Further,
even when A is low-rank, it is possible that, for example,
A − uvT is a dense matrix (where uvT is the best rank-1
approximation to A), which means that the algorithm would
take Ω(mn) time and memory per iteration starting from the
second outer iteration. We now give examples of matrices
A for which ﬁnding a sparse factorization in our style is
superior to ﬁnding a standard low-rank factorization (SVD),
both in speed and resulting sparsity. An additional example
can be found in the appendix.
Example 1. Let A1 = uvT be a rank-one matrix, and let A
be A1, except its lower-triangular half has been zeroed out.
In general, A will now be full-rank, and the SVD of A will
not be sparse. However, we can express A = U V T with
(cid:107)U (cid:107)0 = (cid:107)V (cid:107)0 = O(n log n) as follows. Set u0 = u except
with its right half zeroed out, and set v0 = v except with
its left half zeroed out. Then u0vT
0 matches the upper-right
quadrant of the matrix A, as shown in Figure 1. Moreover,
A − u0vT
0 is block diagonal, where the two blocks have size
(n/2) × (n/2) and have the same structure as A itself. Thus,
we may recursively factor the two blocks. The vectors u0
and v0 both have n/2 nonzero entries, so the total number
of nonzero entries in the factorization is expressed by the
recurrence S(n) = n + 2S(n/2), which solves to S(n) =
O(n log n). The matrices U and V will both have Θ(n)
columns. This example shows up in practice; the payoff
matrix of poker endgames is block diagonal, where the
blocks have essentially this form.

Sparsiﬁed Linear Programming for Zero-Sum Equilibrium Finding

We thus resort to an algorithm that may not yield the optimal
solution but works extremely well in practice. Algorithm 3
reduces (4) to solving the subproblem

argmin
v

(cid:107)A − uvT (cid:107)

(5)

for a given matrix A and now a ﬁxed vector u (the other
subproblem is analogous by transposing A and ﬂipping the
roles of u and v). Again, when (cid:107)·(cid:107) is the 2-norm, and the
optimizer of (5) is just v∗ = Au, so that the full algorithm
is just standard power iteration algorithm for SVD.

Algorithm 3 Approximating argminu,v(cid:107)A − uvT (cid:107)
Input: matrix A ∈ Rm×n
Output: vectors u, v.
1: make an initial guess for u
2: loop
3:
4:

v ← argminv(cid:107)A − uvT (cid:107)
u ← argminu(cid:107)A − uvT (cid:107)

When (cid:107)·(cid:107) is instead the 0-norm, as seen in Algorithm 4,
the optimizer of (5) is the vector v whose jth element is
the mode of Aij/ui over all i for which ui (cid:54)= 0. Since
the objective function (4) cannot increase during the alter-
nating minimization, and the objective values are integral,
Algorithm 3 terminates in ﬁnitely many iterations at a local
optimum. Algorithm 2 is an anytime algorithm. In practice,
we terminate it when the number of unsuccessful iterations
(the number of iterations in which the condition on line 4 is
false) exceeds the number of successful iterations.

for each nonzero entry Aij in row i of A do

Algorithm 4 Sparse matrix factorization subproblem
Input: matrix A ∈ Rm×n, vector u ∈ Rm
Output: vector v minimizing (cid:107)A − uvT (cid:107)0
1: q ← map from indices to lists of real numbers
2: for each i for which ui (cid:54)= 0 do
3:
4:
5: v ← 0
6: for each j for which q[j] is nonempty do
7: M ← mode(q[j])
8:
9:

count ← number of times M appears in q[j]
if count > (cid:107)u(cid:107)0 − len(q[j]) then vj ← M

append Aij/ui to q[j]

Figure 1. Illustration of factorization in Example 1. The box repre-
sents the matrix A. The upper right shaded regions represents its
nonzero entries. The ﬁrst iteration of the factorization zeros out
the orange shaded box.

Example 2. Let A0 = ˆA + U V T be a sparsely-factorable
matrix, and A = A0 + ˆA0 where the residual ˆA0 may be
high-rank, but is sparse. For example, perhaps A is A0 with
some entries around its diagonal zeroed out. Then A itself
is also sparsely factorable as A = ( ˆA + ˆA0) + U V T . This
example may seem trivial, but the SVD does not share a
similar property. For example, if ˆA0 is the matrix from
Example 1, and A0 is a general sparsely-factorable matrix
(even the zero matrix), then the SVD of A = A0 + ˆA0 will
be dense, but A will still have a sparse factorization.

5. Factorization Algorithm

In this section, we develop a general algorithm for factoring
an arbitrary sparse matrix A into the product of two possibly
sparser—and never denser—matrices. For this section, we
let m = |S1| and n = |S2| so that A ∈ Rm×n. We follow
the general strategy used by the power iteration SVD algo-
rithm (e.g., Golub & Van Loan, 1996). Algorithm 2 reduces
the factorization problem to solving, for a given matrix A,
the subproblem

argmin
u,v

(cid:107)A − uvT (cid:107).

(4)

Algorithm 2 Matrix factorization
Input: matrix A ∈ Rm×n, norm (cid:107)·(cid:107) on matrices
Output: matrices U ∈ Rm×r and V ∈ Rn×r
1: set U and V to be empty matrices
2: loop
3:
4:
5:
6:
7:

u, v ← argminu,v(cid:107)A − uvT (cid:107)
if (cid:107)u(cid:107)0 > 1 and (cid:107)v(cid:107)0 > 1 then

U ← [U, u]
V ← [V, v]
A ← A − uvT

When (cid:107)·(cid:107) is the 2-norm, this problem can be solved using
the standard power iteration algorithm. However, when (cid:107)·(cid:107)
is the 0-norm, the problem is not so easy, and even using the
1-norm as a convex substitute for the 0-norm does not help:
Theorem 3 (Gillis & Vavasis, 2018). When (cid:107)·(cid:107) is the 1-
norm or 0-norm, the optimization problem (4) is NP-hard.

Algorithms 2-4 constitute an approximate algorithm for
sparse matrix factorization. It is not exact for two reasons.
First, Algorithm 2 is greedy: at each step of the loop, it
chooses the immediate best rank-1 matrix and greedily ap-
pends it to U and V . This is not always optimal, and in
fact in the worst case can already doom the algorithm to
have a trivial approximation factor Θ(n). Second, Algo-
rithm 3 is not exact when (cid:107)·(cid:107) is the 0-norm or 1-norm, as

Sparsiﬁed Linear Programming for Zero-Sum Equilibrium Finding

expected from our Theorem 3. Nevertheless, the method
works remarkably well as we will show experimentally.2

5.1. Initialization

For the SVD, the initial guess for u in Algorithm 3 is usually
chosen to point in a random direction (i.e., ui ∼ N (0, 1) are
drawn i.i.d). In our case, this does not work: if we draw u
that way, then as long as each column of A has at least two
nonzero entries, the mode computation in Algorithm 4 will
return v = 0 with probability 1, since Aij/ui will be differ-
ent for each i with probability 1. This causes the subroutine
of Algorithm 2 to degenerate, leading to a trivial output.
This is troubling for us, since in basically all extensive-form
games, A is much sparser than this. Fortunately, one small
change yields an initialization that works well. Instead of
initializing u to a random unit vector, we initialize u to a ran-
dom basis vector ei. This circumvents the above problem,
and leads to remarkably strong performance in practice.

5.2. Implementation with Implicit Matrices

A major problem with the above algorithm is that a straight-
forward implementation of it would store and modify the
matrix A in order to factor it. In the setting we are consider-
ing, A is often too big to store in memory: the number of
nonzero entries in A may be several orders of magnitude
greater than the number of rows or columns. In these set-
tings, we would like to be able to implement the algorithm
with only implicit access to A. Formally, we assume access
to A via only an immutable oracle that, given an index i,
retrieves the list of nonzero entries, and their indices, in the
ith row or ith column of A.

The immutability of A is the biggest roadblock here. Sev-
eral changes need to be made to Algorithms 2-4 to acco-
modate this. First, Line 7 of Algorithm 2 is no longer
possible.. Thus, Line 3 of Algorithm 2, must be revised to
read argminu,v(cid:107)A − U V T − uvT (cid:107), and the matrices U and
V must be passed through to Algorithms 3 and 4. On Line 3
of Algorithm 4, querying the ith row of A − U V T requires
a matrix multiplication UiV T , where Ui is the ith row of U .

5.3. Run-time Analysis

The run time of the algorithm depends heavily on the struc-
ture of A. The worst case run time is O((cid:107)A(cid:107)0n2), since
every inner iteration runs in at most quadratic time and re-
moves at least one nonzero entry from A. In practice it
runs dramatically faster than that, and we will now present
a rough analysis, valid in most typical cases. For simplic-

2We also experimented with using the 1-norm as a convex
relaxation of the 0-norm. Here, the exact solution to (5) is given
by Meng & Xu (2012). This seemed to make no difference in
practice, so in the experiments we use the 0-norm.

ity, assume A ∈ Rn×n is square. This doesn’t change the
analysis in any meaningful way, and makes for easier expo-
sition since we do not need to distinguish when A has been
transposed in Algorithm 4.

As stated above, the run time of the algorithm is domi-
nated by the matrix multiplication UiV T , which must be
performed for every i where ui (cid:54)= 0 on the current iteration.
On the rth outer iteration of the algorithm, U and V will
have r columns each; therefore, V T ∈ Rr×n, so the ma-
trix multiplication takes time O(rn). We need to perform
(cid:107)u(cid:107)0 of these per inner iteration. Thus, if the algorithm runs
for a total of R outer loop iterations each of which takes t
inner-loop iterations, it will take time

(cid:32)
t

O

R
(cid:88)

r=1

((cid:107)ur(cid:107)0 + (cid:107)vr(cid:107)0)rn

(cid:33)
.

In practice, the number of inner iterations t per outer iter-
ation is usually very small, say, 3. As an example, if the
algorithm correctly factors a matrix of the structure in Ex-
ample 1, the rth outer loop iteration will ﬁnd a block of size
O(1/r) × O(1/r). Thus each inner loop iteration just takes
time O(n), and there will be O(n) iterations, so that the
whole algorithm runs in time O(n2) = O((cid:107)A(cid:107)0).
In most extensive-form games, the payoff matrix A is block
diagonal. In this case, running the factorization algorithm
on A is equivalent to running it on each of the blocks indi-
vidually, and has the same run time as running the algorithm
on each block separately. Indeed, if u is initialized to a
random basis vector ei, the algorithm’s entire run, and all
its operations—including the critical matrix multiplication
UiV T —will not escape the block to which row i of matrix
A belongs. Thus, for example, running the algorithm on
a matrix with blocks of size k × k, each of which has the
structure of Example 1, will still take time O((cid:107)A(cid:107)0).

6. Experiments

implementa-
We compared state-of-the-art commercial
tions (Gurobi Optimization, 2019) of the common LP solv-
ing algorithms (simplex, dual simplex, and barrier) and
our modiﬁed version of the O(log2(1/ε)) LPsparse algo-
rithm (Yen et al., 2015) (which we call LPsparse’), com-
bined with our factorization algorithm, to the newest, fastest
variants of CFR (Brown & Sandholm, 2019).

6.1. Experiments with All Solvers

In the ﬁrst set of experiments, we studied the setting where
the payoff matrix A is given explicitly. In this setting, the
factorization algorithm can be allowed to modify A, and
CFR variants must load the whole matrix A into memory.
In this experiment, we use the game-independent CFR im-
plementation built in the Rust programming language for

Sparsiﬁed Linear Programming for Zero-Sum Equilibrium Finding

Table 1. Experiments on explicitly speciﬁed games. Gap is the target Nash gap to which LPsparse’ and CFR were run. fnnz is the total
number of nonzero elements that resulted from running our matrix factorization algorithm, reported only when the factorization algorithm
had nontrivial effect. Simplex, Barrier, LPsparse’, and CFR are the wall-clock times, in seconds, that those four algorithms took to achieve
the desired Nash gap. All times greater than 2 hours (7200 seconds) are estimated via linear regression on the log-log convergence plot.
Gurobi was time-limited to half an hour (1800 seconds) because each game had at least one method that solved the game well within this
limit. Since it is difﬁcult to estimate the convergence rate of Gurobi’s solver, Gurobi timeouts are simply indicated with a (T).

Game

Gap

|S1| + |S2|

9-card Leduc poker
13-card Leduc poker
5x2 battleship m=2 n=1
4x3 battleship m=2 n=1
3x2 battleship m=4 n=1
3x2 battleship m=3 n=2
sheriff N=10000 B=100
sheriff N=1000 B=1000
sheriff N=100 B=10000
4-rank goofspiel
5-rank goofspiel
NLH river endgame A
NLH river endgame B

.0001
.0001
.0001
.0001
.0001
.0001
.0001
.0001
.0001
.0001
1.74
.00684
.00178

5,798
12,014
230,778
639,984
3,236,158
1,658,904
1,020,306
1,005,006
1,030,206
42,478
5,332,052
129,222
61,062

(cid:107)A(cid:107)0
30,924
95,056
33,124
82,076
1,201,284
3,345,408
2,020,101
2,003,501
2,020,151
11,136
1,574,400
53,585,621
25,240,149

fnnz

Simplex

Barrier

LPsparse’

CFR

13,712
31,522
—
—
—
—
—
—
—
—
—
481,967
229,454

.5
2.4
8.7
81.0
(T)
(T)
3.0
2.8
5.2
.7
(T)
294.9
54.4

.08
.24
.44
1.47
16.90
20.22
52.56
208.35
66.71
.39
267.46
(T)
(T)

7
14
5
14
659
202
12
9
19
42
7,200
7,200
7,200

901
1,823
2,451
4,059
86,284
55,040
7,912
1,728
287
51,857
1,081
11,893
3,350

speed. In each game, the largest entry of the payoff matrix
in absolute value, that is, (cid:107)A(cid:107)∞, was normalized to be 1.
We ran LPsparse’ four times on each game; in particular,
for each combination of (i) which player is chosen to be
player x in (1), in other words, whether (1) is solved via
the primal or dual; and (ii) choice of inner iteration algo-
rithm (RC or PG). We tested four different variants of CFR:
DCFR[∞, −∞, 1] (“CFR+”), DCFR[∞, −∞, 2] (“CFR+
with quadratic averaging”), DCFR[1.5, 0, 2] (“DCFR”),
DCFR[1, 1, 1] (“LCFR”). These variants are introduced and
analyzed in depth by Brown & Sandholm (2019) and repre-
sent the current state of the art in large-scale game solving.
The best of those variants for each game is shown in Table 1.
We ran LPsparse’ and CFR to target precision (Nash gap)
10−4, or for 2 hours, whichever threshold was hit ﬁrst. We
ran primal and dual simplex to optimality (machine pre-
cision), and barrier with default settings except crossover
off. We ran all solvers on a single core. The games that we
tested on are standard benchmarks; they are described in the
appendix.

On most games, all LP solvers outperformed CFR. This
marks, to our knowledge, the ﬁrst time that LP (or, indeed,
any fundamentally different algorithm) has been shown to
be competitive against leading CFR variants on large games.

The matrix factorization algorithm performs remarkably
well in practice when it needed to. On 9-card and 13-
card Leduc poker, it led to a compression ratio of 2-3.
More impressively, the algorithm compresses both no-limit
endgames by a factor of more than 100. This brings savings
of nearly the same factor in convergence rate in both games,
and enables the LP algorithms to be competitive against the
CFR variants in these large games. On payoff matrices that
are already sparse, the factorization algorithm fails to ﬁnd a
sparse factorization, and terminates immediately.

On a few games, the choice of which player to make the
x player in LP (1); that is, the choice between primal and
dual solves, made a signiﬁcant difference. For example, in
the sheriff family of games, setting x to be the smuggler
yields much better results. This is because the optimal
strategy in the sheriff games is very sparse for the smuggler.
Indeed, Yen et al. (2015) make note of the fact that their
algorithm performs signiﬁcantly better when the optimal
primal solution is sparse, since in this case the inner loop
does not need to loop over the entire constraint matrix A.

6.2. Experiments on No-limit Texas Hold’em

Endgames

In the experiment described above, Gurobi’s LP solvers
consistently outperformed LPsparse’ despite the theoretical
guarantees of the latter. Thus, in the second set of experi-
ments, we focus on Gurobi and DCFR.

The implicit implementation of our factorization algorithm
(Section 5.2) allows us to scale our method to larger games
than previously possible. We hence ran experiments testing
this implementation on heads-up no-limit Texas Hold’em
poker endgames encountered by the superhuman agent Li-
bratus (Brown & Sandholm, 2017). To align with Brown
& Sandholm (2019), we used a simple action abstraction:
the bets are half-pot, full-pot, and all-in, and the raises are
full-pot and all-in. All results are expressed in terms of
the standard metric, namely big blinds (bb). The starting
stacks are 200 big blinds per player as in the Libratus match
against humans. We tested on eight real river endgames (i.e.,
endgames that start on the fourth betting round) and a single
manually-generated small turn endgame (i.e., endgames that
start on the third betting round) where the pot already has
half of the players’ wealth, so only a single additional bet
or raise is possible.

Sparsiﬁed Linear Programming for Zero-Sum Equilibrium Finding

Table 2. Experiments on poker endgames. pot is the current pot size in big blinds. |S1| + |S2| is the total number of sequences across
both players. nnz is the number of nonzero entries of the payoff matrix before (ﬁrst row) and after (second row) the our factorization
algorithm is run. The timeout was set to 3600 seconds (1 hour).

Endgame

Starting pot (bb)

|S1| + |S2|

River 1
factor nnz: 58,707,847 → 740,218
factor time 145s, memory 52MB

5.0

River 2
factor nnz: 40,817,801 → 662,219
factor time 125s, memory 43MB

21.0

River 3
factor nnz: 60,831,748 → 888,608
factor time 181s, memory 58MB

5.0

River 4
factor nnz: 51,332,645 → 781,400
factor time 158s, memory 52MB

10.0

River 5
factor nnz: 61,078,916 → 816,401
factor time 156s, memory 55MB

5.0

River 6
factor nnz: 27,859,761 → 454,203
factor time 71s, memory 32MB

36.0

River 7
factor nnz: 23,087,696 → 445,810
factor time 68s, memory 31MB

37.5

River 8
factor nnz: 30,197,553 → 488,937
factor time 84s, memory 34MB

25.0

95,220

68,102

96,232

82,440

96,922

51,632

47,152

53,536

Small Turn
factor nnz: 96,450,855 → 2,680,527
factor time 244s, memory 193MB

200.0

352,800

Factored

Simplex

Barrier

Poker-Speciﬁc
DCFR

Unfactored
Simplex

time (s)
memory (MB)
Nash gap (bb)

time (s)
memory (MB)
Nash gap (bb)

time (s)
memory (MB)
Nash gap (bb)

time (s)
memory (MB)
Nash gap (bb)

time (s)
memory (MB)
Nash gap (bb)

time (s)
memory (MB)
Nash gap (bb)

time (s)
memory (MB)
Nash gap (bb)

time (s)
memory (MB)
Nash gap (bb)

time (s)
memory (MB)
Nash gap (bb)

364
259
6.8 × 10−8

113
208
8.1 × 10−8

410
272
5.8 × 10−8

231
249
1.0 × 10−7

210
269
6.6 × 10−8

38
164
1.1 × 10−7

21
159
1.8 × 10−7

51
167
1.0 × 10−7

3,241
887
2.3 × 10−8

2,116
1,645
2.8 × 10−5

951
1,126
8.5 × 10−7

1,584
1,730
6.3 × 10−7

1,242
1,433
1.7 × 10−6

1,631
1,735
1.7 × 10−5

516
848
1.4 × 10−5

708
770
8.0 × 10−6

644
792
9.3 × 10−9

482
1,545
3.3 × 10−6

509
572
2.1 × 10−4

238
450
2.4 × 10−4

591
572
2.6 × 10−4

389
511
2.7 × 10−4

366
572
3.3 × 10−4

109
390
7.9 × 10−4

89
389
4.9 × 10−4

135
389
2.6 × 10−4

726
133
1.0 × 10−6

2904
5569
6.9 × 10−8

830
3700
1.0 × 10−7

timeout
na
na

1936
4740
1.2 × 10−7

2120
5748
5.9 × 10−8

142
2292
4.8 × 10−8

81
2086
1.7 × 10−7

167
2702
6.8 × 10−8

timeout
na
na

In this experiment we used an optimized poker-speciﬁc C++
implementation of DCFR. This implementation includes
optimizations such as those of Johanson et al. (2011), which
shave an O(k) factor off the runtime of CFR, where in the
case of Texas hold’em poker, k = 1326 is the number of
possible hands a player may have, and Brown & Sandholm
(2015), which prune game lines that are dynamically deter-
mined not to be part of the optimal solution. For the LP
solver, we use Gurobi’s simplex and barrier methods. Both
primal and dual simplex were run, and only the better of
the two results is shown in Table 2. We also tested Gurobi
without the factorization algorithm. In this case, we do not
include results for the barrier method, because it timed out
or ran out of memory in all the cases. All algorithms were
again restricted to a single core. DCFR was run for the
amount of time taken by the fastest LP variant that used
factoring. For example, if Gurobi took 200 seconds to solve
a game, and the factorization algorithm took 100 seconds,
CFR was run for 300 seconds. The results are in Table 2
and representative convergence plots showing anytime per-
formance are in the appendix.

The factorization algorithm reduced the size of the game
by a factor of 52–80 and the resulting payoff matrix had

density (i.e., nonzeros divided by rows plus columns) 7.8–
9.5. This is expected: poker payoff matrices are block
diagonal, where the blocks are k × k and rank one with the
lower-triangular half negated. Thus, they basically have the
structure of Example 1, in which we saw a compression
from density k ≈ 210 to density log k ≈ 10, which is
exactly the compression we are seeing here.

The DCFR implementation we tested against is especially
optimized to solve no-limit turn endgames. It thus may have
some inefﬁciencies when handling river endgames. We esti-
mate that these inefﬁciencies lose a factor of approximately
20 in time and space on river endgames relative to a river-
optimized implementation. However, importantly, these
inefﬁciencies pale in comparison to the speedups gained by
game-speciﬁc poker speedups (e.g., Johanson et al., 2011),
which save a factor of approximately k = 1326 in time
(but not space). This strongly suggests that our method
would be signiﬁcantly faster than any non-game-speciﬁc im-
plementation of CFR or any modern variant. Furthermore,
the memory usage of simplex, after factorization, is only
a factor of log k ≈ 10 worse than the game-speciﬁc CFR
(which stores the constraint matrix implicitly) in the case of
all these endgames, which means it is often practical to use

Sparsiﬁed Linear Programming for Zero-Sum Equilibrium Finding

Figure 2. Convergence plots on representative endgames. DCFR is plotted against the best-performing LP algorithm. The blue dot
represents the time taken by the factorization algorithm, and the space between the blue dot and the start of the blue line is the time taken
for the algorithm to initialize the algorithm, and then ﬁnd a feasible solution (simplex) or run one iteration (barrier). The drop below zero
of the simplex plot is due to a quirk of Gurobi’s objective value reporting, and can most likely be safely ignored. The drop below zero of
the poker-speciﬁc DCFR in the small turn endgame is due to machine precision issues, and once again can be ignored.

LP solvers even on extremely large games with dense payoff
matrices, as long as the constraint matrix is factorable.

Since primal simplex and dual simplex give respectively
only primal-feasible and dual-feasible solutions, anytime
performance of simplex is measured by running both simul-
taneously, and measuring the Nash gap between the current
primal and dual solutions at each time checkpoint, using
Gurobi’s reported objective values. While Gurobi does not
allow retrieval of these anytime solutions when its presolver
is turned on, in principle they can be retrieved easily using
the presolver’s mapping, which unfortunately Gurobi does
not expose to the end user. The convergence plots in Fig-
ure 2 show roughly what we would expect. CFR has a very
stable convergence curve (until it hits too high precision,
at which point numerical stability issues start kicking in,
and the convergence plot looks weird). The LP solvers start
out slow (especially due to the sometimes nontrivial time
requirements of the factorization algorithm) but catch up
with and often eventually exceed the performance of DCFR,
before again very often stopping due to numerical issues.
Even on turn endgames, LP algorithms consistently out-

perform a hypothetical non-game-speciﬁc implementation
of DCFR—which we deﬁne to be 500 times slower than
the poker-speciﬁc DCFR—due to the additional factor of
k ≈ 1326 in the density of the payoff matrix, and hence the
additional cost of the gradient computation in DCFR.

7. Conclusion and Future Research

We presented a matrix factorization algorithm that yields sig-
niﬁcant reduction in sparsity. We showed how the factored
matrix can be used in an LP to solve zero-sum games. This
reduces both the time and space needed by LP solvers. On
explicitly represented games, this signiﬁcantly outperforms
the prior state-of-the-art algorithm, DCFR. It also made LP
solvers competitive on large games that are implicitly de-
ﬁned by a compact set of rules—even against an optimized
game-speciﬁc DCFR implementation. There are many in-
teresting directions for future research, such as (1) further
improving the factorization algorithm, (2) investigating the
explicit form of an optimal factorization in special cases,
and (3) parallelizing the factorization algorithm.

Sparsiﬁed Linear Programming for Zero-Sum Equilibrium Finding

Acknowledgements

This material is based on work supported by the National
Science Foundation under grants IIS-1718457, IIS-1617590,
IIS-1901403, and CCF-1733556, and the ARO under awards
W911NF1710082 and W911NF2010081.

References

Bowling, M., Burch, N., Johanson, M., and Tammelin, O.
Heads-up limit hold’em poker is solved. Science, 347
(6218), January 2015.

Brown, N. and Sandholm, T. Regret-based pruning in
In Proceedings of the Annual
extensive-form games.
Conference on Neural Information Processing Systems
(NeurIPS), 2015.

Brown, N. and Sandholm, T. Superhuman AI for heads-up
no-limit poker: Libratus beats top professionals. Science,
pp. eaao1733, Dec. 2017. Print version 359(6374):418–
424, 2018.

Brown, N. and Sandholm, T. Solving imperfect-information
games via discounted regret minimization. In AAAI Con-
ference on Artiﬁcial Intelligence (AAAI), 2019.

Farina, G., Ling, C. K., Fang, F., and Sandholm, T. Cor-
relation in extensive-form games: Saddle-point formu-
lation and benchmarks. In Proceedings of the Annual
Conference on Neural Information Processing Systems
(NeurIPS), 2019.

Gillis, N. and Vavasis, S. A. On the complexity of robust
PCA and (cid:96)1-norm low-rank matrix approximation. Math-
ematics of Operations Research, 43(4):1072–1084, 2018.

Gilpin, A., Pe˜na, J., and Sandholm, T. First-order algorithm
with O(ln(1/(cid:15))) convergence for (cid:15)-equilibrium in two-
person zero-sum games. Mathematical Programming,
133(1–2):279–298, 2012. Conference version appeared
in AAAI-08.

Golub, G. H. and Van Loan, C. F. Matrix Computations.

Johns Hopkins University Press, 1996.

Gurobi Optimization, L. Gurobi optimizer reference manual,

2019.

Hoda, S., Gilpin, A., Pe˜na, J., and Sandholm, T. Smooth-
ing techniques for computing Nash equilibria of sequen-
tial games. Mathematics of Operations Research, 35(2),
2010.

Johanson, M., Waugh, K., Bowling, M., and Zinkevich,
M. Accelerating best response calculation in large ex-
tensive games. In Proceedings of the International Joint
Conference on Artiﬁcial Intelligence (IJCAI), 2011.

Koller, D., Megiddo, N., and von Stengel, B. Fast algo-
rithms for ﬁnding randomized strategies in game trees. In
Proceedings of the 26th ACM Symposium on Theory of
Computing (STOC), 1994.

Kroer, C., Waugh, K., Kılınc¸-Karzan, F., and Sandholm,
T. Faster ﬁrst-order methods for extensive-form game
solving. In Proceedings of the ACM Conference on Eco-
nomics and Computation (EC), 2015.

Kroer, C., Farina, G., and Sandholm, T. Solving large
sequential games with the excessive gap technique. In
Conference on Neural Information Processing Systems
(NIPS), 2018.

Meng, D. and Xu, Z. Divide-and-conquer method for L1
norm matrix factorization in the presence of outliers and
missing data. arXiv, abs/1202.5844, 2012.

Neyshabur, B. and Panigrahy, R. Sparse matrix factorization.

arXiv, abs/1311.3315, 2013.

Richard, E., Obozinski, G., and Vert, J. Tight convex relax-
ations for sparse matrix factorization. In Proceedings of
the Annual Conference on Neural Information Processing
Systems (NeurIPS), 2014.

Southey, F., Bowling, M., Larson, B., Piccione, C., Burch,
N., Billings, D., and Rayner, C. Bayes’ bluff: Opponent
modelling in poker. In Proceedings of the 21st Annual
Conference on Uncertainty in Artiﬁcial Intelligence (UAI),
July 2005.

Tammelin, O. Solving large imperfect information games

using CFR+. CoRR, abs/1407.5042, 2014.

von Stengel, B. Efﬁcient computation of behavior strategies.
Games and Economic Behavior, 14(2):220–246, 1996.

Yen, I. E., Zhong, K., Hsieh, C., Ravikumar, P., and Dhillon,
I. S. Sparse linear programming via primal and dual
In Proceedings of the
augmented coordinate descent.
Annual Conference on Neural Information Processing
Systems (NeurIPS), pp. 2368–2376, 2015.

Zinkevich, M., Bowling, M., Johanson, M., and Piccione, C.
Regret minimization in games with incomplete informa-
tion. In Proceedings of the Annual Conference on Neural
Information Processing Systems (NeurIPS), 2007.

Zou, H. and Xue, L. A selective overview of sparse principal
component analysis. Proceedings of the IEEE, 106(8):
1311–1320, 2018.

Sparsiﬁed Linear Programming for Zero-Sum Equilibrium Finding

A. Proof of Theorem 2

The key to the proof is to bound how much this naive normalization changes the point x. Let (x∗, z∗) be the result of
projecting (x, z) into the optimal set S.
Lemma. Let x(cid:48) be the result of normalizing x according to the given scheme, and i be an information set at depth d (with
the root deﬁned to be at depth 0. Then we have |x(cid:48)

n.

√

i − x∗

i | ≤ εd

Proof. By induction on the sequence-form strategy tree for player x, starting at the root. At the root node i = 0, the claim
is clearly true because x0 = 1 in any feasible solution x. Now consider any information set with parent xi0 and children
xi := (xi1 , . . . , xik ) at depth d. From the theorem statement, we have (cid:107)xi − x∗
i (cid:107)2 ≤ ε, and since x∗ is feasible, we have
(cid:80)k

j=1 x∗
ik

= x∗

i0. It follows that

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

k
(cid:88)

j=1

xik − x(cid:48)
i0

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤

k
(cid:88)

j=1

(cid:12)
(cid:12)xik − x∗
ik

(cid:12) + (cid:12)
(cid:12)

(cid:12)x(cid:48)
i0

− x∗
i0

(cid:12)
(cid:12) ≤ ε

√

k + ε(d − 1)

√

√

n ≤ εd

n

by triangle inequality and inductive hypothesis, and noting that k ≤ n. But the normalization acts by picking x(cid:48)
(cid:80)k
i0, and it moves all the xik s in the same direction; thus, each one can move by at most εd

i so that
n, completing the

= x(cid:48)

√

j=1 x(cid:48)
ik
induction.

With this lemma in hand, we now prove the theorem.

Proof of Theorem. Since d ≤ n (each depth must have at least one information set), it follows from the lemma that
(cid:107)x(cid:48) − x∗(cid:107)2 ≤ εn2. But the best response function miny xT Ay (with feasibility constraints on y) is a pointwise minimum of
Lipschitz functions xT v for each v = Ay and y feasible, hence itself Lipschitz, with Lipschitz constant

max
y

(cid:107)Ay(cid:107)2 ≤ max

y

(cid:107)Ay(cid:107)1 ≤ (cid:107)A(cid:107)1 max

(cid:107)y(cid:107)∞ = (cid:107)A(cid:107)1 ≤ n2(cid:107)A(cid:107)∞.

y

where (cid:107)A(cid:107)1 is the sum of the magnitudes of the nonzero entries of A. The desired theorem follows.

B. Another Example of the Utility of Sparse Factorization
Example 3. Let A be the n × (n + 1) matrix given by A = (cid:2)In
0(cid:3) + (cid:2)0
(cid:3), where In is the n × n identity, and 0 is a
column vector of zeros. So, A is the matrix whose (i, j) entry is 1 exactly when j = i or j = i + 1. By direct computation,
the SVD of this matrix is A = U ΣV T where U and V are fully dense, and the SVD is unique (in the usual sense, that is, up
to signs and permutations) since all the singular values are. Thus, taking an SVD would have the result of increasing the
number of nonzeros from 2n to Θ(n2), which is the opposite of what we want. Thus, although in this case there will not be
a good sparse factorization, using SVD make the problem worse.

In

C. Benchmark Games in Experiment 1

We tested on the following benchmark games from the literature:

• Leduc poker (Southey et al., 2005) is a small variant of poker, played with one hole card and three community cards.

• Battleship (Farina et al., 2019) is the classic targeting game, with two parameters: m is the number of moves (shots) a
player may take, and n is the number of ships on the board. All ships have length 2. A player scores a point only for
sinking a full ship.

Sparsiﬁed Linear Programming for Zero-Sum Equilibrium Finding

• Sheriff (Farina et al., 2019) is a simpliﬁed Sheriff of Nottingham game, modiﬁed to be zero-sum, played between a
smuggler and a sheriff. The smuggler selects a bribe amount b ∈ [0, B] and a number of illegal items n ∈ [0, N ] to try
to smuggle past the sheriff. The sheriff then decides whether to inspect. If the sheriff does not inspect the cargo, then
the smuggler scores n − b. If the sheriff inspects and ﬁnds no illegal items (n = 0), then the smuggler scores 3. If the
sheriff inspects, and n > 0, then the smuggler scores −2n. The smuggler has far more sequences than the sheriff in
this game.

• No-limit hold-em (NLH) river endgames are endgames encountered by the poker-playing agent Libratus (Brown &
Sandholm, 2017), using the action abstraction used by Libratus. They both begin on the last betting round, when all
ﬁve community cards are known. The normalization of (cid:107)A(cid:107)∞ = 1 means that in these endgames, a Nash gap of 1
corresponds to 0.075 big blinds. Due to the explicit storage of the payoff matrix in this experiment, only extremely
small no-limit endgames can be tested. In particular, endgame A here is the same as endgame 7 in the next experiment
(with a ﬁner abstraction), and endgame B is the same as endgame A except with the starting pot size doubled to make
the game smaller.

