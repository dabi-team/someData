HIR: An MLIR-based Intermediate Representation for
Hardware Accelerator Description

Kingshuk Majumder
Computer Science and Automation
Indian Institute of Science
Bangalore, India
kingshukm@iisc.ac.in

Uday Bondhugula
Computer Science and Automation
Indian Institute of Science
Bangalore, India
udayb@iisc.ac.in

1
2
0
2

b
e
F
7
2

]

R
A
.
s
c
[

1
v
4
9
1
0
0
.
3
0
1
2
:
v
i
X
r
a

Abstract
The emergence of machine learning, image and audio pro-
cessing on edge devices has motivated research towards
power efficient custom hardware accelerators. Though FP-
GAs are an ideal target for energy efficient custom accelera-
tors, the difficulty of hardware design and the lack of vendor
agnostic, standardized hardware compilation infrastructure
has hindered their adoption.

This paper introduces HIR, an MLIR-based intermediate
representation (IR) to describe hardware accelerator designs.
HIR combines high level language features, such as loops
and multidimensional tensors, with programmer defined ex-
plicit scheduling, to provide a high-level IR suitable for DSL
compiler pipelines without compromising control over the
micro-architecture of the accelerator. HIR’s explicit sched-
ules allow it to express fine-grained, synchronization-free
parallelism and optimizations such as retiming and pipelin-
ing. Built as a dialect in MLIR, it draws from best IR practices
learnt from communities like those of LLVM. While offering
rich optimization opportunities and a high level abstraction,
HIR enables sharing of optimizations, utilities and passes
with software compiler infrastructure.

Our implementation shows that the code generation time
of the HIR code generator is on average 1112× lower than
that of Xilinx Vivado HLS on a range of kernels without a
compromise on the quality of the generated hardware. We be-
lieve that these are significant steps forward in the design of
IRs for hardware synthesis and in equipping domain-specific
languages with a productive and performing compilation
path to custom hardware acceleration.

Keywords: HDL, HLS, MLIR, Verilog, accelerator, FPGA

1 Introduction
The growing compute demands of machine learning and
other high performance computing (HPC) domains coupled
with the need for power efficiency on edge computing de-
vices has motivated the increased use of specialized hard-
ware accelerators. In the last decade, GPUs have become
a de-facto standard for data parallel HPC workloads. One
of the enabling forces behind the mass adoption of GPUs
in mainstream computing is the steady improvements in its
programmability. Both CUDA and OpenCL enabled GPUs for

Predictable performance

Predictable hardware

Blackbox modules

Sequential execution

Deterministic parallelism

HDLs HLS HIR
✗

✓

✓

✓✓

✓

✗

✓

✗

✗

✓

✗

✓

✓

✓

✓

Table 1. Comparison of HIR with HLS and HDLs as a target
language for DSLs.

more general purpose programming. DSLs such as Tensor-
Flow have helped further in improving the programmability
while simultaneously allowing new kinds of optimizations
across multiple kernels. In short, the continuous improve-
ments in programming abstractions and growing ecosystem
of libraries and DSLs have helped GPUs cater to the ever
growing demands of the HPC community.

Although custom accelerators on reconfigurable comput-
ing platforms such as FPGAs are able to achieve high power
efficiency [33] and performance, the difficulty of hardware
design is seen as a major roadblock for FPGAs. High level
synthesis [7] offers a promising approach towards making
custom accelerator design more approachable. DSLs can offer
an even higher level of abstraction to the algorithm develop-
ers and benefit from being able to employ the right high-level
synthesis (HLS) pipelines.

MLIR [20, 21], (multi-level intermediate representation) is
a new compiler infrastructure designed to serve the needs
of high-level domain-specific as well as general purpose pro-
gramming languages and models at one end, and hardware
including custom accelerators at the other. Early promis-
ing results have been reported on software code genera-
tion as well as on building or migrating compiler stacks to
MLIR [5, 8, 18, 23].

Numerous domains-specific as well as general-purpose
languages and tools supporting HLS have been built over the
past two decades by the academia and industry [2, 9, 12, 14–
16, 22, 24, 29]. Nearly all electronic design automation ven-
dors now provide suites supporting HLS, examples of which
include Xilinx Vivado, Cadence C-to-silicon, Synopsys Syn-
phony, and Mentor Graphics Catapult HLS. A comprehensive

1

 
 
 
 
 
 
survey of various HLS approaches was conducted by Bacon
et al. [4]. All of these HLS efforts devised their own inter-
mediate representations for their purposes, thus duplicating
and re-implementing a lot of the representation and transfor-
mation infrastructure that could otherwise have been shared.
The problem here is thus worse than that faced by the soft-
ware compiler community including that faced by domains
like deep learning programming systems. The availability of
an open IR standard that is modular and reusable, the same
way as LLVM [19], would bring similar benefits to the HLS
compilation community, and avoid re-engineering core IR
infrastructure. Interestingly, CIRCT [10] is an LLVM sub-
project and an ongoing umbrella initiative to use and adapt
MLIR and its methodology for HLS: it brings a compiler style
approach to a field where programming and debuggability
experience is vastly different. Our work here shares the same
motivation and end goals, and is complementary to existing
work in CIRCT.

Existing intermediate representations (IRs) for high-level
synthesis have not been built in a rigorous manner the
same way as standard compiler IRs such as LLVM [19] and
MLIR [20, 21]. The latter draw from best practices learnt
from over a decade, and aim to improve compiler developers’
productivity at the expense of significant initial investment
in engineering IR infrastructure. Such engineering and in-
vestment purely into IR infrastructure is made even much
before a compiler is built out of it. Our work in this paper
is also along these lines: it focuses on the representation
and the convenience it brings to a hardware developer as
opposed to reporting a specific end-to-end compiler built
from the proposed representation.

Our contributions in this paper can be summarized as

follows:

• We design an intermediate representation, HIR, based
on the MLIR infrastructure, that allows high level spec-
ification of a hardware design.

• We introduce support for explicitly specifying the
schedule of operations in HIR. This makes it easy to
exploit fine grained parallelism available in the hard-
ware.

• We build a code generator that translates HIR into
synthesizable Verilog. The code generator automati-
cally generates the controller to realize the schedule
specified in HIR.

• We implement a schedule verification pass in order to

automatically detect scheduling errors.

• We implement various optimization passes in the com-

piler to improve the generated hardware design.

The rest of this paper is organized as follows. Section 2
describes our motivation in greater detail. Section 3 provides
an overview of FPGAs and hardware design. Section 4 de-
scribes the HIR representation we propose followed by its

2

Kingshuk Majumder and Uday Bondhugula

advantages in Section 5, and its verification and optimiza-
tion infrastructure in Section 6 and Section 7. Related work
is discussed in Section 9, and an evaluation is presented in
Section 8.

2 Motivation
Traditionally, domain-specific languages have targeted either
high level synthesis (HLS) or hardware description languages
(HDLs) as the output. With HLS, the DSL designer is able to
generate code in a high level language such as C/C++. This
makes it easy to implement the code generator. HLS com-
pilers also provide various mechanisms (such as pragmas)
to tune the generated hardware for different performance
and area tradeoffs. In contrast, HDLs are low level but of-
fer complete control over the generated hardware. The DSL
designer is able to manually optimize the design’s critical
sections and timing errors are easier to debug than with HLS.
Another advantage of HDLs is that they are standardized
and most tools understand Verilog or VHDL.

An IR for hardware description has the following desirable

properties:

• Quality of Result (QoR): A description of a hardware
design should have a guaranteed minimum QoR (la-
tency, throughput and area). Verilog, being a low level
language provides this guarantee but HLS languages
heavily depend on the compiler to achieve a certain
performance. Compared to HDLs, HLS designs have
lower performance portability across different compil-
ers.

• Ease of optimization: It should be easy for the compiler
to find optimization opportunities in the design. HIR
designs define the schedule explicitly, which helps in
optimization. For example, if an distributed RAM is
defined as simple dual port but the read and write
operation’s schedules do not overlap, we can replace
it with a single port RAM to save resources. HDLs
make it difficult to extract the schedule from a given
design which makes these kind of optimizations much
harder. Traditionally, HLS compilers perform these
kind of higher level optimizations since the compiler
itself schedules the HLS design.

• Interfacing with external modules: The IR should be
able to interface with external IPs without much over-
head. This is essential to leverage existing libraries.
HLS languages require various handshake protocols
to be implemented for using outside blackbox IPs in
the HLS design.

• Predictable design: The output hardware should be
predictable from the description written in the IR. As
HLS compilers perform different kinds of optimiza-
tions during the binding and scheduling phase, it is
harder to predict the resource usage of an HLS design.

HIR: An MLIR-based Intermediate Representation for Hardware Accelerator Description

• Smaller abstraction gap: Many DSLs target HLS lan-
guages because it is much more difficult to describe
the design in HDLs. An IR that can be used by DSLs
needs to be high level. It is desirable to have basic
programming constructs such as loops. Most software
algorithms contain a mix of sequential and parallel re-
gions. Thus, while translating the algorithm to a hard-
ware implementation, the IR should provide language
constructs to easily express both sequential and paral-
lel algorithms. The abstraction of HDLs is very close
to hardware and hence, like hardware, all operations
in HDLs are parallel. Running dependent operations
sequentially requires additional effort from the devel-
opers’ side such as creation of state machines. HLS
languages often can only express non-deterministic
parallelism. As a result, parallel operations may need
extra synchronization logic.

3 Overview of FPGAs
In this section, we discuss about accelerator design and the
different kinds of hardware resources available in FPGAs. We
will use the nomenclature of Xilinx FPGAs, but the concepts
generalize to other FPGAs as well.

FPGAs are a fundamentally different kind of hardware
from CPUs and GPUs. An FPGA is a grid of simple building
blocks such as small lookup tables, SRAMs, registers and
ALUs (DSP slices). FPGAs do not execute instructions and
thus, do not have an ISA. Instead, FPGAs can implement
arbitrary digital circuits by connecting the hardware blocks
using a programmable on-chip routing matrix.

FPGAs offer multiple types of on-chip memory. For exam-
ple, Xilinx FPGAs contain registers, distributed RAMs and
block RAMs. These memories vary in their size and power
consumption. Registers hold just one bit of data. Smaller
buffers are implemented using distributed RAMs, and block
RAMs offer larger capacity at the expense of greater power
consumption. Each RAM has a fixed number of read/write
ports. These ports can be used independently for parallel
memory accesses. FPGAs lack any kind of caches. Accel-
erators implement custom memory hierarchy to cache the
frequently accessed data in the on-chip memory buffers for
fast, energy efficient access.

FPGA vendors usually provide custom synthesis tools to
target their FPGAs. These tools can take a hardware design
as input and perform optimizations, placement and routing
to output a configuration file that can be used to program
the FPGA. Any external compiler must communicate with
the synthesis tools to target the FPGA. This often means that
the external compiler must output the design in a hardware
description language (HDL) that is supported by the synthe-
sis tool. The two most widely supported HDLs are Verilog
and VHDL.

3

A hardware design is usually synchronized using a clock,
i.e., all state changes happen only at discrete clock ticks.
Unlike CPUs and GPUs, FPGAs provide deterministic fine-
grained parallelism. All operations in the hardware design
execute every cycle unless explicitly constrained. Hardware
designs often use finite state machines (FSMs) to choose
which operations are enabled at each clock cycle. Thus, in
contrast to software development, a design must use extra
logic to ensure sequential execution while parallel execution
is the default.

An accelerator design in a hardware description language,
such as Verilog or VHDL, is usually broken into data paths
and FSMs. The data paths implement the computation and
the FSMs control when each operation in the data path exe-
cutes.

4 HIR
The HIR intermediate representation is implemented as a
dialect in the MLIR [20] compiler infrastructure. As such,
it inherits all the usual benefits provided by the core MLIR
infrastructure. This includes having a round-trippable and
human readable textual representation that could be parsed,
printed, and verified [21]. All our HIR operations have a
custom pretty-printed form for readability and for the con-
venience of compiler developers. Listing 1 shows a sample
design in HIR dialect to transpose a matrix. HIR borrows its
syntax from software programming languages. Like LLVM,
all variables in HIR are SSA variables.

The hardware implementation of any algorithm can be

broken down into three orthogonal components :

• The high level algorithm: this can be captured by any

software programming language.

• The schedule of each constituent operation, i.e., the

clock cycle at each an operation is executed.

• Binding operations and states (variable/arrays) to avail-
able hardware resources such as multipliers, lookup
tables, registers and different kinds of on-chip SRAMs.

Hardware description languages require the developer to
bind operations and manually schedule them using state
machines. High level synthesis takes the other extreme ap-
proach where the developer only specifies the algorithm and
the compiler performs binding and scheduling. The devel-
oper can influence the scheduling and binding via annota-
tions but does not have direct control over it. For example,
in Vivado HLS [16], the programmer can add loop pipelining
annotations with specific initiation interval but compiler can
reject it if it can’t statically prove that pipelining will not
violate loop carried dependencies.

HIR provides complete control over the schedule of the
design while still providing high level abstraction. HIR’s pri-
mary insight is that the complexity of hardware description
in HDLs partly come from manually implementing the sched-
ule using state machines. In HIR dialect, the programmer

Category

Data types

Control flow ops

Examples

i32, i1, f32, hir.memref

hir.func,
hir.for,
hir.return, hir.yield

Compute ops

hir.add, hir.mult

hir.unroll_for,

Memory access ops hir.mem_read, hir.mem_write

Table 2. Data types and different types of operations in HIR.

only describes the schedule and the compiler automatically
generates the control logic. Thus the abstraction of HIR is
in between HDLs and HLS (where there is no scheduling
information in the design and the compiler tries to determine
an optimal schedule).

4.1 Operations
An ‘operation’ is the building block of all MLIR programs.
Each operation can have multiple inputs, outputs, regions
and constant attributes. A region defines a new lexical scope
enclosed in curly braces. Control flow operations such as
functions, conditionals and loops require region arguments.
Attributes associate constant metadata with an operation.
The HIR dialect defines three types of operations.

Control flow operations help in expressing accelera-
tor designs at a high level of abstraction. Most HDLs and
hardware IRs support conditional statements and generate
loops (equivalent to an unroll-for loop in HIR) in their syn-
thesizable subset. In addition to these, HIR also adds for
loop in the language. The compiler automatically generates
state-machines to implement the control flow in hardware.

hir.func @transpose at %t(

%Ai :!hir.memref<16*16*i32, r>,
%Co : !hir.memref<16*16*i32, w>) {

%0 = hir.constant 0
%1 = hir.constant 1
%16 = hir.constant 16

hir.for %i : i32 = %0 : !hir.const to %16 : !hir.const
step %1:!hir.const iter_time(%ti = %t offset %1 ){

%tf = hir.for %j : i32 = %0 : !hir.const to %16 : !hir.const

step %1:!hir.const iter_time(%tj = %ti offset %1){

%v = hir.mem_read %Ai[%i, %j] at %tj

: !hir.memref<16*16*i32, r>[i32, i32] -> i32

%j1 = hir.delay %j by %1 at %tj: i32 -> i32
hir.mem_write %v to %Co[%j1, %i] at %tj offset %1
: (i32,!hir.memref<16*16*i32, w>[i32, i32])

hir.yield at %tj offset %1

}

hir.yield at %tf offset %1

}
hir.return

}

Listing 1. HIR code for matrix transpose.

4

Kingshuk Majumder and Uday Bondhugula

Listing 1 shows the syntax of the for loop. The loop takes a
lower bound, an upper bound, a step, and start time as its
inputs. It also defines two SSA variables that are accessible
inside the loop body: the loop induction variable and a time
variable to represent the start of an iteration. These two
variables have different values for each iteration of the loop.
Operations inside the loop do not have access to any time
variable other than the iteration start time. This ensures that
each operation inside the body can only be scheduled after
the loop guard is checked.

Compute operations calculate output values given the
inputs. This includes arithmetic and logical operations, bit
slicing ops and function calls. The ‘call’ operation can be
used to execute another HIR function or to communicate
with an external Verilog module.

Memory access operations such as hir.mem_read are
used to access memref types. Memory access operations
are constant delay operations. All memory writes take one
cycle. Memory reads may take zero or one cycle depending
on whether the memref is implemented using registers or
on-chip buffers.

4.2 Time variable and schedules
A key contribution of the HIR dialect is the concept of time
variables and schedules. A time variable represents a spe-
cific time instant within its lexical scope. This time instant
is either related to some event, such as a function call, or
represents a constant delay from another time variable.

In HIR, the keyword ‘at’ is used to express that an oper-
ation starts at the time instant represented by a given time
variable. For example, in Listing 1, the time variable %𝑡 rep-
resents the time at which the transpose function is called.
The schedule for all operations within the function’s body
are described with respect to this time variable. The caller
would schedule the function call with respect to its own start
time. This recursively defines the concrete schedule of all
operations in all functions in the call graph starting from the
top-level function.

The start of each iteration of a for loop is also associated
with a time variable. The 𝑖-loop in Listing 1 defines the time
variable %𝑡𝑖 to represent the start of an iteration. This time
variable is local to the loop body, and for each loop iteration,
the time variable represents a different time instant. At the
first iteration, %𝑡𝑖 = %𝑡 + 1, i.e., the loop starts its execution
at time %𝑡 +1 (represented as ‘%𝑡 offset %1’). The hir.yield
operation decides the time at which the next iteration starts.
The 𝑖-loop is sequential and the next iteration starts after
the inner 𝑗-loop completes.

The yield operation is used for loop pipelining. The j-loop
body in Listing 1 yields one cycle after an iteration starts, i.e.,
if the first iteration is at %𝑡 𝑗 = %𝑡𝑖 + 1, the second iteration
starts at %𝑡 𝑗 = %𝑡𝑖 + 2 and so on. The yield operation
does not end the current iteration. Each iteration of the j-
loop takes two cycles to complete (the mem_write operation

HIR: An MLIR-based Intermediate Representation for Hardware Accelerator Description

starts at %𝑡 𝑗 + 1 and takes one cycle to complete). Thus, the
execution of different iterations of the j-loop overlap, i.e., the
j-loop is pipelined. Although multiple iterations can execute
at the same time, the loop iteration time variable will still
hold the correct iteration.

As the schedule of each operation is explicitly specified
using time variables, the textual order of operations does not
have any effect on the functionality. For example, if the yield
operation in the j-loop of the matrix transpose example is
moved to the beginning of the loop body, it will still not
change the behavior of the circuit. The only constraint on
the textual order of the operations is that the definition of
an SSA variable must dominate all its uses.

4.3 Primitive types and HIR constants
HIR supports primitive data types such as arbitrary bit-width
integers and floats. Each SSA variable of primitive type is
defined only at a specific time instant within its lexical scope.
For example, the %𝑣 variable in Listing 1 contains a valid
value only at time %𝑡 𝑗 + 1 (since mem_read takes one cycle).
Constant type (hir.const in the dialect) represents a constant
integer in HIR.

4.4 Memref data type in HIR
All the available memory resources in hardware are rep-
resented via the hir.memref data type. A memref can be
viewed as a pointer or reference to a multidimensional ten-
sor. The tensor may be placed in an array of buffers (such
as distributed or block RAM) or registers. The memref type
abstracts its implementation details away and provides a
uniform interface for memory access.

A memref defines the dimensions of the tensor, the data
type of its elements, and its access permission. Memref types
can have either a read-only, write-only or a read-write access
permission. A single tensor may be associated with multiple
memrefs pointing to it. Each memref pointing to the tensor
represents a memory port. The maximum number of mem-
refs that can simultaneously point to a tensor is fixed by
the available number of ports. For example, block RAMs in
Xilinx FPGAs are dual ported. Thus, a tensor that is held in
the block RAM can have two memrefs pointing to it.

Each dimension of a memref is either a packed dimension
or a distributed dimension. The tensor elements that have
the same indices for the distributed dimensions go to the
same buffer. Elements whose address differs in a distributed
dimension go to different buffers. Distributed dimensions can
only be indexed using compile time constants (i.e., hir.const
type). Multiple parallel read/write operations on the same
memref is valid only if either the address is same for all the
conflicting operations or each access is to a different buffer,
i.e., the addresses differ in at least one distributed dimension.
For unrestricted parallel access, a design may use multiple
memrefs pointing to the same tensor.

5

4.5 Undefined behavior
HIR also borrows the concept of undefined behavior from
software programming languages. The HIR compiler makes
the following assumptions:

• Memory accesses remain within bounds.
• Lower bound of a for-loop is never greater than the

upper bound.

• There will never be multiple accesses to a memref in
the same clock cycle unless they occur at the same
address or at least one distributed dimension index is
different. This is because each memref corresponds to
one port of an on-chip buffer.

• A new instance of a for-loop is not scheduled unless
the previous instance has completed all iterations. For
this reason, the inner loop in listing 1 is pipelined but
the outer loop is sequential.

• All mem_read operations happen on initialized mem-
ory, i.e., the memory must be written-to before reading
a value from it. Each call to a function resets all mem-
ory elements (such as registers and RAMs) instantiated
in the function to uninitialized state. The HIR language
does not support persistent state (equivalent to static
scope in C) across function calls.

Violation of any of the above assumptions is treated as un-
defined behavior. This assists the HIR compiler in two ways.
First, it allows the code generator to automatically insert as-
sertion statements in the generated Verilog to guard against
violation of the above assumptions. These assertions can
then be used to verify that the circuit is not malfunctioning
via simulation or formal verification techniques. Traditional
HDLs describe hardware at a lower level of abstraction and
thus can not describe these types of undefined behaviors.
For example, in Verilog, the programmer would manually
implement an if-else statement (which synthesizes to a multi-
plexer), to select between multiple addresses and read enable
signals, when there are multiple readers. If these readers
attempt to read at different addresses from the same memory
port in the same clock cycle, then it is very likely that the
design is malfunctioning. But to the Verilog compiler, it is
perfectly valid for multiple branches of the if-else statement
to be true – only the first branch is selected. There is not
enough information for the HDL compiler to understand
the programmer’s intent in such situations. Thus, often, the
programmer would have to manually insert these assertions.
Due to HIR’s higher level abstraction, it is possible to au-
tomatically add assertions to check that only one of the
memory operations is to be executed at a given cycle.

The second usual advantage of undefined behaviors is
that the optimizer can exploit this information in order to
improve the circuit. For instance, if a variable is used to index
into an array, the compiler can assume that the variable will
never contain a value greater than the size of the array. This
enables precision reducing optimizations.

HIR

Verilog

Functions

Verilog modules

Primitive types

Wires

memrefs

Block RAMs, distributed RAMs
and registers.

Integer arithmetic Non-pipelined arithmetic in
Verilog

Delay

For loops

Schedules

Shift registers

State machines

State machines

Table 3. Hardware mapping for each HIR language construct.

4.6 Lowering to hardware
HIR is a thin abstraction on top of hardware. This is in-
tentional in order to support low overhead and predictable
hardware generation. HIR’s code generator outputs Verilog
which is understood by nearly every hardware toolchain.
Table 3 shows the hardware that is instantiated by our code
generator for each HIR language construct.

Functions in HIR map to modules in Verilog. Basic integer
arithmetic operations such as integer addition, subtraction
and multiplication map to the corresponding operations in
Verilog. Note that all these operations are combinatorial, i.e.,
they are not pipelined. Delay operations are mapped to shift
registers.

Variables of primitive types such as i32 and f32 map to
wires in Verilog. The hir.memref type is implemented as a
combination of address, ‘read enable’, ‘write enable’ and data
buses depending on whether it is a read-only, write-only or a
read-write port. The multi-dimensional array that a memref
refers to is implemented using either registers or on-chip
memory buffers such as block RAMs. The order of packed
dimensions decides the layout of data within each RAM. The
distributed dimensions produce a banked RAM design. The
code generator adds circuitry to calculate the linear address
and the signals to select the RAM within the bank based on
the input addresses.

The schedule is implemented in hardware as state ma-
chines that generate control signals for other operations.
The state machine also generates clock enable signals for
all pipeline registers. All Verilog modules generated from
HIR functions contain a start signal that the caller’s state
machine uses to signal a function call.

5 Advantages of HIR
In this section, we discuss the advantages of using HIR as an
intermediate language for DSL compilers.

6

Kingshuk Majumder and Uday Bondhugula

5.1 Explicit scheduling
We can broadly group existing languages (and their IRs)
for hardware description into two categories: languages that
precisely describe the schedule of operations in the hardware
design, and languages that rely on the compiler to generate a
schedule. HDLs such as Verilog or VHDL, Chisel [3] and IRs
such as LLHD [30], FIRRTL [17] fall under the first category,
while high-level synthesis tools such as Vivado HLS [16],
Bluespec-Verilog [26] belong to the second category.

Languages that precisely capture the schedule usually
require the programmer to manually implement state ma-
chines. These state machines then generate the control sig-
nals that determine the order of execution of operations.
Without these control signals, every operation in the hard-
ware will execute every cycle. The problem with this ap-
proach is that the scheduling information is hidden inside
the controller, and an optimization requiring the schedule
needs to rediscover this information from the controller de-
scription. Also, any change in the schedule requires reim-
plementing the controller. In HIR, the programmer specifies
the relative time of execution of each operation and the com-
piler automatically generates the required controllers. This
allows HIR to do optimizations that require the scheduling
information. For example, loop pipelining requires control
over the schedule of execution of each iteration of the loop.
Similarly, retiming and operator chaining are a few other
optimizations that modify the schedule.

An explicitly defined schedule makes it easy to modify
the schedule to optimize the design. A similar modification
in HDL would require updating the controllers as well. An
added advantage of this approach is that the compiler can
automatically detect many scheduling errors (see section 6.1).

5.2 High level design
HIR borrows control flow constructs such as loops, function
calls and conditional statements directly from imperative
programming languages. The explicit schedules make it easy
to enforce sequential execution when there is a dependence
between operations. These features make it easy to convert
software algorithms into hardware designs. An HIR design
can be optimized using HLS optimization techniques such
as loop pipelining and overlapped execution. In addition,
HIR offers more control over the generated hardware when
compared to HLS. For instance, an HIR design completely
controls the pipelining and scheduling of individual opera-
tions. This additional control can be used for optimizations
such as adding pipeline registers and retiming to improve
the frequency of operation.

5.3 Deterministic parallelism
Unlike HDLs, HLS languages cannot express deterministic
parallelism. This is primarily because they do not explicitly
schedule operations, and the languages used by HLS tools are

HIR: An MLIR-based Intermediate Representation for Hardware Accelerator Description

usually software programming languages with constructs
for non-deterministic coarse-grained parallelism. This kind
of parallelism often requires some kind of a synchronization
mechanism. For example, in Vivado HLS a producer and a
consumer task can execute in parallel if the producer is trans-
ferring its outputs to the consumer via streams (implemented
as FIFOs in hardware). The consumer task waits for the next
data to be available on the stream in order to continue its
execution. This type of synchronization adds overhead in
the hardware design. The producer task need to assume that
the FIFO may be full and thus the generated circuit needs a
way to pause (referred to as back-pressure). Similarly, the
consumer needs to provision for the situation when the FIFO
is empty. If the two tasks are working in lock-step, i.e., every
fixed number of cycles with the producer task generating
one output and the consumer task consuming it, then there
is no need for synchronization between the two tasks. Both
HIR and HDL languages can express this kind of determin-
istic, synchronization-free, task level parallelism. Section 7
shows an example of task level parallelism in a 1-d stencil
expressed in HIR.

5.4 External hardware modules
The ability to use externally defined hardware circuits is es-
sential in order to specialize a design for the given hardware
platform. This is because FPGA vendors provide their own
custom libraries for many common circuits. For instance,
Xilinx offers optimized libraries for floating-point arithmetic,
multi-ported RAMs, etc. for their FPGAs. Often these library
implementations do not have their source code available.
Thus, porting these libraries to the IR is not an option. Addi-
tionally, there are several third party libraries that may need
to be reused or inter-operated with.

HIR’s ability to capture scheduling information in the func-
tion signature makes it easier to integrate external Verilog
modules with HIR’s design. In languages where the schedule
is determined by the compiler, external modules usually re-
quire handshake signals. Since HIR allows the programmer
to precisely specify when data is read from or written to a
wire or memory, handshake signals are not required unless
the external hardware module does not have a fixed latency.

5.5 Timing closure
Often, hardware designs have a target frequency require-
ment. Timing closure is the process of iterating over the
design to meet the required frequency of operation. The
peak frequency of operation for a design is limited by the
delay in the critical path (longest timing path) of the cir-
cuit. This delay is a sum of the wire delays (time for signals
to propagate through wire) and delay introduced by the
logic in the critical path. Improving the frequency of the de-
sign involves breaking down the critical path by introducing
pipeline stages. All HDLs and IRs that control the schedul-
ing of operations can introduce additional pipeline stages

7

to meet timing requirements. HIR allows pipelining using
delay operations and modifying the schedule. HIR has an
additional advantage that the compiler can detect pipeline
imbalance errors (discussed in section 6.1).

We also use MLIR’s ability to track location information in
order to generate a mapping between the operations in HIR
and the corresponding Verilog code. The code generation
pass prints the location information of the HIR operation
as comments in the generated Verilog output. This helps us
in identifying the critical paths in an HIR design in case of
timing failures in the generated Verilog design.

5.6 Predictable QoR
A predictable quality of result (QoR) is essential for a hard-
ware intermediate representation. This allows DSLs to gen-
erate hardware with a predictable performance and resource
usage. Control over resource usage is also important when
the generated accelerator has to share the FPGA with other
hardware designs. For example, the generated accelerator
may be deployed as a part of a larger design containing PCIe
controllers, DRAM controllers and soft CPU cores (CPU im-
plemented on an FPGA).

The performance of a hardware accelerator is determined
by the amount of parallelism exploited by the accelerator, the
memory bandwidth and the frequency of operation. Among
these, the latter two are dependent on the target FPGA. An
HIR design contains a description of the schedule of all op-
erations. This schedule precisely specifies the amount of
parallelism in the design. In HIR, all resources are explicitly
instantiated in the design. No extra hardware resources are
required to meet the performance specified in the design.
In contrast, HLS compilers can add extra hardware such as
ping-pong buffers and extra memory ports in order to meet
the desired performance.

6 Automatic Verification and Optimization
In this section, we discuss various passes that we imple-
mented in the HIR compiler for optimizing IR and to detect
anomalies in a design.

6.1 Verifying the schedule of computation.
Additional verification of IR helps language front-ends catch
errors early in the development cycle. It also helps library im-
plementors and DSL designers write hand-optimized kernels
directly in HIR.

HDLs do not have any inherent notion of logically valid
data in the language. For example, a wire in Verilog always
contains some data. The compiler cannot determine when
this data is valid. The SSA variables of primitive types (int
and float) in HIR specify the time instant (relative to a time
variable) at which they will have a valid value. The schedule
verification pass exploits this validity information, and the
explicitly specified schedule of operations, to detect errors

hir.func @Array_Add at %t (%A:!hir.memref<128*i32, r>,

hir.func @mac at %t (%a :i32, %b :i32, %c :i32) -> (i32 delay 3){

Kingshuk Majumder and Uday Bondhugula

%B : !hir.memref<128*i32, r>,
%C : !hir.memref<128*i32, w>){

%0 = hir.constant 0
%1 = hir.constant 1
%128 = hir.constant 128

hir.for %i :i8 = %0 :!hir.const to %128 :!hir.const
step %1 :!hir.const iter_time(%ti = %t offset %1){

hir.yield at %ti offset %1

%a = hir.mem_read %A[%i] at %ti

: !hir.memref<128*i32,r>[i8] -> i32

%b = hir.mem_read %B[%i] at %ti

: !hir.memref<128*i32, r>[i8] -> i32

%c = hir.add (%a, %b) : (i32, i32) -> (i32)

hir.mem_write %c to %C[%i] at %ti offset %1
: (i32, !hir.memref<128*i32, w>[i8])

}
hir.return

}

(a) HIR design to add two arrays.

%1 = hir.constant 1
%2 = hir.constant 2

// Pipelined multiplier.
%m = hir.call @mult_3stage (%a,%b) at %t
: (i32, i32) -> (i32 delay 3)

%c2= hir.delay %c by %2 at %t : i32 -> i32

%res = hir.add (%m,%c2) : (i32, i32) -> (i32)
%res1 = hir.delay %res by %1 at %t offset %2 : i32 -> i32

hir.return (%res1) : (i32)

}

(a) HIR design for multiply-accumulate operation.

(b) Diagnostic error reported by HIR’s schedule verifier.

Figure 1. Example of an HIR design containing a scheduling
error.

at compile time that cannot be automatically detected in an
design specified in an HDL.

Figure 1 shows an example of a wrong schedule. The de-
sign in Figure 1a adds two arrays and writes the output into a
third array. Figure 1b shows the error reported by our sched-
ule verification pass. The for loop has an initiation interval of
1 as specified by the yield operation inside the body of the
loop. The mem_write operation takes %𝑖 as an operand at
time %𝑡𝑖 + 1 but the state machine of the for loop generates
%𝑖 at time %𝑡𝑖. Since the for loop has an initiation interval
of one cycle, when the mem_write occurs at %𝑡𝑖 + 1, the %𝑖
variable would have incremented already.

In hardware design, it is common to add extra pipeline
stages to a circuit in order to achieve the desired target fre-
quency. But this may introduce new errors in the final design.
Figure 2 illustrates this with an example design of a multiply-
accumulate operation in which a two stage integer multiplier
is replaced with a multiplier that has three pipeline stages.
For the adder to work properly, both its inputs must arrive
at the same clock cycle. The added pipeline stage in the mul-
tiplier delays %𝑚 by one cycle leading to a malfunctioning
design. Since, function signatures in HIR embed the delays
of each input and output value, we can analyze the source

(b) Diagnostic error reported by HIR’s schedule verifier.

Figure 2. Example of a pipeline imbalance.

Vivado HLS

Vivado HLS (manual opt)

HIR (no opt)

HIR (auto opt)

LUT FF

41

7

32

8

92

51

72

18

Table 4. Resource usage of a Matrix Transpose.

code to find these pipeline mismatches at compile time as
shown in Figure 2b.

6.2 Constant propagation, CSE, and strength

reduction

The HIR compiler performs the standard optimizations well-
known in the software compiler domain like constant prop-
agation and common sub-expression elimination. These op-
timizations enable subsequent optimizations and help re-
duce resource usage. The optimizer replaces multiplication
between loop induction variables and constants with incre-
ments. This reduces the hardware usage since integer type
multiplication consumes more hardware resources than ad-
dition.

6.3 Precision optimization
Compared to software, where the minimum precision of the
compute unit is determined by the underlying architecture,
hardware designs can greatly benefit from reducing the preci-
sion of arithmetic to arbitrarily low levels. The HIR compiler

8

HIR: An MLIR-based Intermediate Representation for Hardware Accelerator Description

automatically analyzes the source code to reduce the pre-
cision of the arithmetic operations in certain simple cases
and thereby improves resource usage. Here, we benefit from
the higher level description of HIR. For example, constant
loop bounds help in determining the minimum precision
required to calculate the loop induction variable. To do the
equivalent optimization, the HDL optimizer would have to
analyze a state machine. Table 4 compares the resource uti-
lization of the matrix transpose. We manually optimized the
HLS design because Vivado HLS was not able to perform the
optimization automatically. The results show that precision
optimization significantly improves resource utilization both
in Vivado HLS (with manual precision reduction) and HIR
(with automatic precision reduction).

6.4 Delay elimination
An HIR design may contain several hir.delay operations
in order to maintain the validity of the schedule. Each delay
operation is implemented using shift registers. In order to
reduce the use of registers, the compiler reuses shift registers
across hir.delay operations. The compiler first applies a
de-duplication pass on the design to remove unnecessary
time variables. Then delay operations using the same time
variable and with same inputs can share the shift registers.

7 Manual optimizations
DSL compilers are expected to exploit domain knowledge
to find potential optimization opportunities [14]. The inter-
mediate language should allow the DSL compiler to express
these optimizations in the accelerator design so that the
compiler backend can generate the desired circuit. In this
section, we discuss different ways in which an HIR design
can be optimized for improved frequency and parallelization.
These optimizations may be manually employed for hand-
optimized kernels or could be used by auto-parallelization
frameworks to emit efficient hardware designs. Automatic
parallelization of HIR designs is itself beyond the scope of
this work. Although an intermediate representation is not
meant to be a programming model or a language, the high-
level nature of abstractions and operations provided by HIR
make manual optimization by a designer a useful feature.

7.1 Loop pipelining
Loop pipelining is a key optimization in high level synthesis.
In loop pipelining, the next iteration of the for loop starts
before the previous iteration completes. This allows multiple
loop iterations to execute in parallel. Loop pipelining does
not add extra hardware overhead. Listing 2 shows an example
of a pipelined loop. Each iteration of the i-loop in the function
"stencilA", takes 3 cycles to complete. The time to schedule
the next iteration of the loop is determined by the hir.yield
operation. In this case the i-loop starts every cycle. The yield

9

operation allows an HIR design to express a constant or a
variable initiation interval.

7.2 Task level parallelism
In addition to exploiting parallelism in loops, multiple tasks
can be executed in parallel to further improve performance.
The "task_parallel" function in listing 3 shows an example of

hir.func @stencil_1d at %t(

%Ai :!hir.memref<64*i32, r>,
%Bw : !hir.memref<64*i32, w>

) {

%0 = hir.constant 0
%1 = hir.constant 1
%2 = hir.constant 2
%3 = hir.constant 3
%64 = hir.constant 64
%W1r, %W1w = hir.alloc() : !hir.memref<2*i32, packing=[], r>,

!hir.memref<2*i32, packing=[], w>

%valA = hir.mem_read %Ai[%0] at %t

: !hir.memref<64*i32, r>[!hir.const] -> i32

%valA1 = hir.delay %valA by %1 at %t offset %1: i32 -> i32
%valB = hir.mem_read %Ai[%1] at %t offset %1

: !hir.memref<64*i32, r>[!hir.const] -> i32

hir.mem_write %valA1 to %W1w[%0] at %t offset %2

: (i32,!hir.memref<2*i32, packing=[],w>[!hir.const])

hir.mem_write %valB to %W1w[%1] at %t offset %2

: (i32,!hir.memref<2*i32, packing=[],w>[!hir.const])

// Pipelined for loop.
hir.for %i : i32 = %1 : !hir.const to %64 : !hir.const
step %1:!hir.const iter_time(%ti = %t offset %3) {

// Yield instruction starts next iteration after one cycle.
hir.yield at %ti offset %1
%v0 = hir.mem_read %W1r[%0] at %ti offset %1

: !hir.memref<2*i32,packing=[], r>[!hir.const] -> i32

%v1 = hir.mem_read %W1r[%1] at %ti offset %1

: !hir.memref<2*i32,packing=[], r>[!hir.const] -> i32

%iPlus1 = hir.add (%i,%1) : (i32,!hir.const) -> (i32)
%v = hir.mem_read %Ai[%iPlus1] at %ti

: !hir.memref<64*i32, r>[i32] -> i32

hir.mem_write %v1 to %W1w[%0] at %ti offset %1

: (i32,!hir.memref<2*i32,packing=[], w>[!hir.const])

hir.mem_write %v to %W1w[%1] at %ti offset %1

: (i32,!hir.memref<2*i32,packing=[], w>[!hir.const])

%r = hir.call @stencil_opA(%v0, %v1) at %ti offset %1

: (i32, i32) -> (i32 delay 1)

%i2 = hir.delay %i by %2 at %ti: i32 -> i32
hir.mem_write %r to %Bw[%i2] at %ti offset %2

: (i32,!hir.memref<64*i32, w>[i32])

}
hir.return

}

Listing 2. One-dimensional stencil with a pipelined loop.

hir.func @task_parallel at %t(
%Ai :!hir.memref<64*i32, r>,
%Co : !hir.memref<64*i32, w>) {
%Br, %Bw = hir.alloc() : !hir.memref<64*i32, r>,

!hir.memref<64*i32, w>

%8 = hir.constant 8
%64 = hir.constant 64

// Execution of stencilB is overlapped with stencilA.
hir.call @stencil_A(%Ai, %Bw) at %t

: (!hir.memref<64*i32, r>, !hir.memref<64*i32, w>)

hir.call @stencil_B(%Br, %Co) at %t offset %8

: (!hir.memref<64*i32, r>, !hir.memref<64*i32, w>)

hir.return

}

Listing 3. Overlapped execution of tasks.

hir.unroll_for %j = 0 to 16 step 1 iter_time(%tj = %t){
// Start all iterations at the same time instant %t.
hir.yield at %tj
// Only unrolled for loops can start all iterations simultaneously.

// Body.
...

}

Listing 4. ‘Unroll loop’ in HIR.

task level parallelism expressed in the HIR dialect. Since, the
stencils read the input array and write to the output sequen-
tially, the second stencil does not have to wait for the first
stencil to complete. It can start its operation as soon as there
is enough data to calculate its first output. After that both the
stencil run in lock-steps i.e. in each cycle stencilA produces
one value and stencilB consumes one value. Overlapping the
execution of the tasks reduces the overall latency of the top
level function. Like loop pipelining, overlapped execution of
multiple tasks does not add any hardware overhead either.

7.3 Loop unrolling
Listing 4 shows an unroll for loop that starts all its itera-
tions in parallel (since the yield operation happens without
any delay). Unrolling replicates the loop body in hardware.
This allows an HIR design to scale with available hardware
resources if there is enough loop parallelism to exploit. Un-
rolling can often be combined with pipelining to further
improve parallelism.

HIR does not support partial unrolling of loops. All un-
roll_for loops are fully unrolled. Partial unrolling can be
represented by stripmining the for loop and completely un-
rolling the resultant inner loop. This is very similar to loop
vectorization in software compilation. A major difference
is that in software, the vectorizable operations are limited
by the CPU, whereas in a hardware design, arbitrary logic
could be replicated to form parallel lanes of execution.

Both, normal for loops and unrolled for loops can be ar-
bitrarily nested within each other. For example, the GEMM
benchmark discussed in Section 8 uses nested loop unrolling
to describe a fully pipelined, two-dimensional systolic array.

7.4 Operation chaining, pipelining and retiming
Operation chaining is the process of scheduling multiple
dependent operations in the same clock cycle. It reduces
latency by completing a chain of dependent operations in
the same cycle, which would otherwise span multiple cycles.
The overall performance of the hardware design depends
on the maximum frequency at which the design can reliably
operate. Pipelining and retiming help in reducing delay in
the critical path to improve frequency of operation.

Pipelining in hardware design is the process of adding ex-
tra registers between operations in order to break a critical
timing path into smaller paths with less delay. Pipelining a

Kingshuk Majumder and Uday Bondhugula

Figure 3. Memory banking in a memref type.

design involves two steps - adding registers between compu-
tations to break them into pipeline stages, and changing the
schedule of the affected operations. Retiming is another tim-
ing closure technique where, instead of adding new pipeline
stages, operations are moved from one pipeline stage to an-
other. The motivation is to reduce the delay in the critical
path at the expense of non-critical paths. Since, the maximum
achievable frequency depends on the delay of the critical
path, this optimization improves the frequency.

An HIR design uses hir.delay operation to add pipeline
registers. All the above optimizations require adding (pipelin-
ing), removing(operator chaining) or moving the delay oper-
ation around. The schedule verifier offers an additional layer
of checks for the validity of these transformations.

7.5 Memory banking and multi-port RAMs
Hardware accelerators use on-chip buffers to reduce DRAM
accesses. In order to execute operations in parallel, these de-
signs may need multiple reads and writes to the buffers every
cycle. FPGAs offer multi-ported on-chip RAMs to support
parallel access. The number of parallel ports and the type of
port depends on the the FPGA. An HIR design can instantiate
a multi-ported RAM in order to parallelize memory accesses.
Usually the number of ports is limited since adding multiple
ports to a memory requires extra resources in the FPGA. For
workloads where the parallel memory accesses are usually
guaranteed to be separated by a fixed stride, an HIR design
may employ memory banking instead. In this approach, the
data is distributed evenly among multiple buffers in such a
way that parallel accesses occur on distinct buffers. HIR sup-
ports memory banking in the memref type. The distributed
dimensions of a memref are spread across multiple buffers
whereas addresses that only differ in packed dimensions fall
into the same buffer. Figure 3 shows how elements of a mem-
ref with distributed dimensions are spread across multiple
buffers.

8 Evaluation
We implemented HIR as an MLIR dialect using mainline
MLIR infrastructure. We then implemented a translator from
the MLIR HIR dialect to Verilog. Our code is available [1]. In
order to evaluate the quality of hardware generated by the
HIR compiler, we compared its resource utilization against
Vivado HLS [16], a proprietary high-level synthesis compiler.

10

A[0,0]A[1,0]A[2,0]A[0,1]A[1,1]A[2,1]Buffer 0Buffer 1A is of type hir.memref< 3 * 2 * i32, packing = [ 1 ], r >HIR: An MLIR-based Intermediate Representation for Hardware Accelerator Description

Benchmark

Vivado HLS/Verilog

HIR

DSP BRAM LUT

DSP BRAM

Matrix transpose

Stencil-1d

Histogram

GEMM

LUT

7

152

130

FF

51

237

107

0

6

0

14495

24538

768

Convolution

1517

2490

FIFO (Verilog)

34

36

0

0

FF

18

147

146

0

6

0

8

114

101

12645

29062

768

289

43

661

140

0

0

0

0

1

0

0

1

0

0

1

0

0

1

Table 5. FPGA resource usage and comparison with Vivado HLS/Verilog.

Benchmark

Compile times (sec)

Speedup

HIR Vivado HLS

Matrix transpose

0.006

Stencil_1d

Histogram

GEMM

Convolution

0.007

0.007

0.099

0.013

13

8

13

33

14

2166×

1142×

1857×

333×

1076×

Table 6. Compile times (in seconds) and comparison with
Vivado HLS.

Vivado HLS is the standard for implementing accelerator de-
signs using high-level synthesis on Xilinx FPGAs. All results
were synthesized for the Xilinx VC709 FPGA evaluation plat-
form. The generated Verilog from both HIR and Vivado HLS
were given to Vivado synthesis tool to obtain the resource
usage data. All results reported are obtained using Vivado
and Vivado HLS version 2019.1.

The compile time results reported in Table 6 were mea-
sured on a system with 2 x 8-core Intel Xeon Silver 4110
CPUs and 256 GB of DDR4 RAM. Both the Vivado HLS and
HIR designs were synthesized for 200MHz and used the same
amount of loop pipelining and unrolling to match perfor-
mance.

We compare the quality of generated hardware on four
benchmarks. The matrix transpose benchmark implements
a hardware circuit to read a matrix from an input memory
interface and write the transpose on an output memory inter-
face. The stencil benchmark takes a one-dimensional array
and a set of weights as input and calculates an output ar-
ray where each output value is the weighted average of the
inputs within a window. Signal processing operations such
as FIR filter can be classified as a stencil computation. The
histogram benchmark calculates a histogram of an image
using a local buffer and writes back the final histogram to

an output memory interface. This benchmark shows data
dependent memory accesses. Matrix multiplication is a fun-
damental operation in many machine learning algorithms.
We implemented a generalized matrix-matrix multiplication
kernel that reads two 16x16 matrices into buffers, multiplies
them using a systolic array design, and writes back the out-
put. We use distributed RAM to implement the local buffers
for the matrices. All benchmarks operate on 32 bit integer
data.

Table 5 shows the resource utilization of all the designs
implemented in Vivado HLS and in HIR. The HIR compiler
generates designs which have a comparable resource utiliza-
tion to Vivado HLS, which is a mature high level synthesis
compiler. Our resource usage of DSP blocks is always the
same as Vivado HLS. The results differ only in the utiliza-
tion of lookup tables and the number of registers. For matrix
transpose, our register usage is much lower than that of the
HLS compiler. We believe this is because the HLS compiler
more aggressively pipelines the design than what is neces-
sary to achieve the desired 200 MHz frequency target. On the
GEMM benchmark, the HIR design consumes less lookup
tables but more registers than the HLS design. In stencil-
1d HIR performs better than Vivado HLS in both LUT and
register usage by a substantial margin. In convolution the
HIR implementation consumes fewer resources compared to
the HLS implementation for an equivalent design. The FIFO
baseline is implemented in Verilog. The HIR implementation
consumes comparable lookup tables but substantially more
registers compared to a Verilog implementation of the FIFO.
Overall, the results in Table 5 show that the HIR compiler
can generate Verilog designs that are comparable to Vivado
HLS in resource usage when both designs have been equally
optimized and for the same target frequency.

9 Related Work
Static Single Assignment (SSA) [11] based intermediate rep-
resentations are a standard in software compilation pipelines.
Both LLVM [19] and GCC [27] use SSA based IRs for their

11

compilation pipeline. Some HLS compilers [7, 28] also reuse
these software IRs for high level synthesis.

9.1 Hardware intermediate representations
Like HIR, LLHD [30] is another intermediate representation
for hardware description that was later migrated to MLIR
and is hosted as part of CIRCT [10], an LLVM sub-project
and a umbrella initiative to adapt and use MLIR for high-level
synthesis. LLHD attempts to cover all stages of hardware
synthesis. It provides IR constructs to describe behavioral
and structural circuits as well as netlists. LLHD is a low-level
IR with similar abstraction level as HDLs (Verilog/VHDL). It
does not have for loops and it expects that loop unrolling to
be done by the language frontend. While LLHD is suitable
for targeting HDLs, we believe that HIR, due to its high level
abstraction, is a better target for HLS and DSL frontends.
Currently, HIR lowers to Verilog, but LLHD could serve as an
alternative code generation target. We intend to contribute
HIR to the CIRCT project, and develop it further within its
community.

The FIRRTL [17] IR is designed along with the Chisel [3]
hardware construction language. FIRRTL designs are repre-
sented as an abstract syntax tree. FIRRTL offers features like
type and width inference for easier Chisel interoperability.
Similar to LLHD and in contrast to HIR, FIRRTL is also a low
level IR which can be a suitable target for HDLs.

𝜇IR [31] decouples the micro-architectural representation
of the accelerator from its behavioral specification. Mircroar-
chitectural optimizations like pipelining and retiming are im-
plemented as transformations of structural graph. Futil [32]
represents an accelerator using a structural sub-language and
a control sub-language. The control sub-language describes
a coarse grained schedule via a happens-before relation. On
the other hand, HIR captures the complete accelerator de-
scription through a unified representation. One of the use
cases of HIR is to allow expert developers to hand optimize
kernels. We believe that a unified representation is easier to
understand, optimize and debug. Unlike Futil, HIR’s sched-
ules are exact (cycle accurate). This helps in interfacing with
external Verilog modules without the overhead of handshak-
ing. The HIR compiler also helps in detecting errors like
pipeline imbalance after microarchitectural optimizations.

9.2 HIR for HLS compilation
In this section, we briefly discuss high-level synthesis lan-
guages and how HIR could fit in as an IR in their compilation
flow. Bluespec-Verilog [26] represents a circuit as a set of
atomic rules. A recent work [6] attempts to enhance the lan-
guage for user-level control over the schedule and predictable
performance. We believe that HIR’s ability to express a de-
sign at a higher level of abstraction than RTL or structural
level while providing complete control over the schedule to
allow fine grained task level parallelism would be a good fit
as a target intermediate language for the BSV compiler. The

12

Kingshuk Majumder and Uday Bondhugula

Dahlia[25] language is inspired from the observation that
HLS languages generate unpredictable designs due to their
excessive flexibility. A small change in the design can affect
the performance by a large factor. Dahlia and its affine type
system enforces the high level design to respect the limita-
tions of hardware. For example, a valid design is guaranteed
to never have multiple reads and writes on the same memory
in the same cycle. Many of Dahlia’s language features such as
memory banking, for loops and unroll-for loops have a direct
equivalent in HIR. This would make it very easy to use HIR
as the intermediate representation in its compiler. Also, a
valid Dahlia design does not introduce undefined behaviour
in HIR. For an IR to use static analysis to prove the absence
of undefined behaviour would be too conservative since it
may be targeted by a variety of frontend languages. Thus,
the ideal situation is when the language is conservative in
accepting a design and the IR is flexible to cater to the need
of multiple languages. Aetherling [13] is another interest-
ing work on high level synthesis. It introduces space-time
types that can be used to describe dataflow pipelines with
exact throughput and latency requirements. The language
attempts to remove the need for synchronization overhead
between different stages of the pipeline. HIR is an ideal fit for
such a language. The explicit deterministic scheduling com-
pletely removes the need for extra synchronization stages.
HIR can represent designs where the producer and consumer
operate in lock steps and there is no back-pressure between
the stages and Aetherling’s type system ensures that this
would always be the case.

We believe that the combination of high level language
constructs such as for and unroll-for loops, the ability to spec-
ify exact schedules of operations and the ability to represent
both high level optimizations (such as loop pipelining and
task overlapping) as well as low level optimizations such as
retiming, allows HLS compilers to use HIR during the whole
compilation pipeline.

10 Conclusion
We introduced HIR, an intermediate representation to de-
scribe FPGA based hardware accelerator designs. HIR has
been implemented as a dialect in the MLIR compiler infras-
tructure. It captures the hardware design at a higher level
of abstraction than today’s hardware description languages
like Verilog or VHDL. This makes it easier for DSL frontends
to target HIR for code generation. HIR is built in a rigorous
manner drawing from best practices learnt from compiler IR
design in the open-source communities of LLVM and MLIR.
The HIR language simplifies the process of hardware opti-
mization and unifies the hardware compilation pipeline with
general-purpose software compiler infrastructure to share
core infrastructure, utilities and passes maximally. Prelimi-
nary results demonstrate the effectiveness of the approach
in terms of hardware designers’ productivity, efficiency of

HIR: An MLIR-based Intermediate Representation for Hardware Accelerator Description

the code generated, and code generation time improvements
of over 1000× over Xilinx Vivado HLS.

References
[1] Anonymized. 2020. HIR source code.

link removed for double blind

review; provided as part of the HotCRP submission.

[2] Joshua Auerbach, David F. Bacon, Ioana Burcea, Perry Cheng,
Stephen J. Fink, Rodric Rabbah, and Sunil Shukla. 2012. A Compiler
and Runtime for Heterogeneous Computing. In Design Automation
Conference. 271–276.

[3] Jonathan Bachrach, Huy Vo, Brian Richards, Yunsup Lee, Andrew
Waterman, Rimas Avižienis, John Wawrzynek, and Krste Asanović.
2012. Chisel: Constructing Hardware in a Scala Embedded Language.
In Proceedings of the 49th Annual Design Automation Conference (San
Francisco, California) (DAC ’12). Association for Computing Machin-
ery, New York, NY, USA, 1216–1225. https://doi.org/10.1145/2228360.
2228584

[4] David F. Bacon, Rodric M. Rabbah, and Sunil Shukla. 2013. FPGA
programming for the masses. Commun. ACM 56, 4 (2013), 56–63.
[5] Uday Bondhugula. 2020. High Performance Code Generation in MLIR:

An Early Case Study with GEMM. arXiv:2003.00532 [cs.PF]

[6] Thomas Bourgeat, Clément Pit-Claudel, Adam Chlipala, and Arvind.
2020. The Essence of Bluespec: A Core Language for Rule-Based
Hardware Design. In Proceedings of the 41st ACM SIGPLAN Conference
on Programming Language Design and Implementation (London, UK)
(PLDI 2020). Association for Computing Machinery, New York, NY,
USA, 243–257. https://doi.org/10.1145/3385412.3385965

[7] Andrew Canis, Jongsok Choi, Mark Aldham, Victor Zhang, Ahmed
Kammoona, Jason H. Anderson, Stephen Brown, and Tomasz Cza-
jkowski. 2011. LegUp: High-Level Synthesis for FPGA-Based Pro-
cessor/Accelerator Systems. In Proceedings of the 19th ACM/SIGDA
International Symposium on Field Programmable Gate Arrays (Mon-
terey, CA, USA) (FPGA ’11). Association for Computing Machinery,
New York, NY, USA, 33–36. https://doi.org/10.1145/1950413.1950423
[8] Lorenzo Chelini, Andi Drebes, Oleksandr Zinenko, Albert Cohen, Henk
Corporaal, Tobias Grosser, and Nicolas Vasilache. 2021. Progressive
Raising in Multi-Level IR. In International Symposium on Code Genera-
tion and Optimization (CGO). ACM. to appear.

[9] Nitin Chugh, Vinay Vasista, Suresh Purini, and Uday Bondhugula.
2016. A DSL Compiler for Accelerating Image Processing Pipelines
on FPGAs. In International Conference on Parallel Architectures and
Compilation (PACT) (Haifa, Israel). 327–338.

[10] The CIRCT community. 2020. CIRCT: Circuit IR Compilers and Tools.

https://github.com/llvm/circt.

[11] Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and
F. Kenneth Zadeck. 1991. Efficiently Computing Static Single Assign-
ment Form and the Control Dependence Graph. ACM Trans. Program.
Lang. Syst. 13, 4 (Oct. 1991), 451–490.

[12] C. Dase, J.S. Falcon, and B. MacCleery. 2006. Motorcycle control
prototyping using an FPGA-based embedded control system. Control
Systems, IEEE 26, 5 (2006), 17–21.

[13] David Durst, Matthew Feldman, Dillon Huff, David Akeley, Ross Daly,
Gilbert Louis Bernstein, Marco Patrignani, Kayvon Fatahalian, and Pat
Hanrahan. 2020. Type-Directed Scheduling of Streaming Accelerators.
In Proceedings of the 41st ACM SIGPLAN Conference on Programming
Language Design and Implementation (London, UK) (PLDI 2020). As-
sociation for Computing Machinery, New York, NY, USA, 408–422.
https://doi.org/10.1145/3385412.3385983

[14] James Hegarty, John Brunhaver, Zachary DeVito, Jonathan Ragan-
Kelley, Noy Cohen, Steven Bell, Artem Vasilyev, Mark Horowitz, and
Pat Hanrahan. 2014. Darkroom: Compiling High-Level Image Process-
ing Code into Hardware Pipelines. ACM Trans. Graph. 33, 4, Article
144 (July 2014), 11 pages. https://doi.org/10.1145/2601097.2601174

13

[15] James Hegarty, Ross Daly, Zachary DeVito, Jonathan Ragan-Kelley,
Mark Horowitz, and Pat Hanrahan. 2016. Rigel: Flexible Multi-rate
Image Processing Hardware. ACM Trans. Graph. 35, 4, Article 85 (July
2016), 11 pages.

Inc.

[16] Xilinx
tehsis.
tools/vivado/integration/esl-design.html.

[n.d.].

Syn-
https://www.xilinx.com/products/design-

High-Level

Vivado

[17] A. Izraelevitz, J. Koenig, P. Li, R. Lin, A. Wang, A. Magyar, D. Kim,
C. Schmidt, C. Markley, J. Lawson, and J. Bachrach. 2017. Reusabil-
ity is FIRRTL ground: Hardware construction languages, compiler
frameworks, and transformations. In 2017 IEEE/ACM International
Conference on Computer-Aided Design (ICCAD). 209–216.
https:
//doi.org/10.1109/ICCAD.2017.8203780

[18] Tian Jin, Gheorghe-Teodor Bercea, Tung D. Le, Tong Chen, Gong
Su, Haruki Imai, Yasushi Negishi, Anh Leu, Kevin O’Brien, Kiyokuni
Kawachiya, and Alexandre E. Eichenberger. 2020. Compiling ONNX
Neural Network Models Using MLIR. arXiv:2008.08272 [cs.PL]
[19] Chris Lattner and Vikram Adve. 2004. LLVM: A Compilation Frame-
work for Lifelong Program Analysis and Transformation. In Proceed-
ings of the International Symposium on Code Generation and Optimiza-
tion: Feedback-Directed and Runtime Optimization (Palo Alto, Califor-
nia) (CGO ’04). IEEE Computer Society, USA, 75.

[20] Chris Lattner, Mehdi Amini, Uday Bondhugula, Albert Cohen, Andy
Davis, Jacques Pienaar, River Riddle, Tatiana Shpeisman, Nicolas Vasi-
lache, , and Oleksandr Zinenko. 2021. MLIR: Scaling Compiler Infras-
tructure for Domain-Specific Computation. In International symposium
on Code Generation and Optimization (CGO). to appear.

[21] Chris Lattner, Mehdi Amini, Uday Bondhugula, Albert Cohen, Andy
Davis, Jacques Pienaar, River Riddle, Tatiana Shpeisman, Nicolas Vasi-
lache, and Oleksandr Zinenko. 2020. MLIR: A Compiler Infrastructure
for the End of Moore’s Law. arXiv:2002.11054 [cs.PL]

[22] matlab-hdl-coder [n.d.]. MATLAB HDL Coder. The MathWorks Inc.

http://in.mathworks.com/products/hdl-coder//.

[23] MLIR.

2020.

MLIR: Talks

and

related

publications.

https://mlir.llvm.org/talks/.

[24] Walid A. Najjar, Wim Böhm, Bruce A. Draper, Jeff Hammes, Robert
Rinker, J. Ross Beveridge, Monica Chawathe, and Charles Ross. 2003.
High-Level Language Abstraction for Reconfigurable Computing.
Computer 36, 8 (Aug. 2003), 63–69.

[25] Rachit Nigam, Sachille Atapattu, Samuel Thomas, Zhijing Li, Theodore
Bauer, Yuwei Ye, Apurva Koti, Adrian Sampson, and Zhiru Zhang. 2020.
Predictable Accelerator Design with Time-Sensitive Affine Types. In
Proceedings of the 41st ACM SIGPLAN Conference on Programming
Language Design and Implementation (London, UK) (PLDI 2020). As-
sociation for Computing Machinery, New York, NY, USA, 393–407.
https://doi.org/10.1145/3385412.3385974

[26] R. Nikhil. 2004. Bluespec System Verilog: efficient, correct RTL from
high level specifications. In Proceedings. Second ACM and IEEE In-
ternational Conference on Formal Methods and Models for Co-Design,
2004. MEMOCODE ’04. 69–70. https://doi.org/10.1109/MEMCOD.2004.
1459818

[27] Diego Novillo. 2003. Tree SSA—a new high-level optimization frame-

work for the gnu compiler collection. (01 2003).

[28] Christian Pilato and Fabrizio Ferrandi. 2013. Bambu: A modular frame-
work for the high level synthesis of memory-intensive applications.
In 23rd International Conference on Field programmable Logic and Ap-
plications, FPL 2013, Porto, Portugal, September 2-4, 2013. IEEE, 1–4.
https://doi.org/10.1109/FPL.2013.6645550

[29] Oliver Reiche, Moritz Schmid, Frank Hannig, Richard Membarth, and
Jürgen Teich. 2014. Code Generation from a Domain-specific Language
for C-based HLS of Hardware Accelerators. In 2014 International Con-
ference on Hardware/Software Codesign and System Synthesis. Article
17, 17:1–17:10 pages.

Kingshuk Majumder and Uday Bondhugula

[30] Fabian Schuiki, Andreas Kurth, Tobias Grosser, and Luca Benini. 2020.
LLHD: A Multi-level Intermediate Representation for Hardware De-
scription Languages. arXiv:2004.03494 [cs.PL]

[31] Amirali Sharifian, Reza Hojabr, Navid Rahimi, Sihao Liu, Apala Guha,
Tony Nowatzki, and Arrvindh Shriraman. 2019. 𝜇IR -An Intermediate
Representation for Transforming and Optimizing the Microarchitec-
ture of Application Accelerators. In Proceedings of the 52nd Annual
IEEE/ACM International Symposium on Microarchitecture (Columbus,

OH, USA) (MICRO ’52). Association for Computing Machinery, New
York, NY, USA, 940–953. https://doi.org/10.1145/3352460.3358292
[32] Sam Thomas. 2020. A Flexible Intermediate Language for High-Level

Synthesis. https://sgtpeacock.com/papers/futil.pdf.

[33] C. Zhang, Zhenman Fang, Peipei Zhou, Peichen Pan, and Jason Cong.
2016. Caffeine: Towards uniformed representation and acceleration
for deep convolutional neural networks. In IEEE/ACM International
Conference on Computer-Aided Design (ICCAD). 1–8.

14

