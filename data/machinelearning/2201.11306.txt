2
2
0
2

n
a
J

7
2

]
L
M

.
t
a
t
s
[

1
v
6
0
3
1
1
.
1
0
2
2
:
v
i
X
r
a

Multi-view learning with privileged weighted twin
support vector machine

Ruxin Xua, Huiru Wanga,∗

aDepartment of Mathematics, College of Science, Beijing Forestry University, No.35
Qinghua East Road, 100083 Haidian, Beijing, China

Abstract

Weighted twin support vector machines (WLTSVM) mines as much potential
similarity information in samples as possible to improve the common short-
coming of non-parallel plane classiﬁers. Compared with twin support vector
machines (TWSVM), it reduces the time complexity by deleting the superﬂu-
ous constraints using the inter-class K-Nearest Neighbor (KNN). Multi-view
learning (MVL) is a newly developing direction of machine learning, which
focuses on learning acquiring information from the data indicated by multiple
feature sets. In this paper, we propose multi-view learning with privileged
weighted twin support vector machines (MPWTSVM). It not only inherits
the advantages of WLTSVM but also has its characteristics. Firstly, it en-
hances generalization ability by mining intra-class information from the same
perspective. Secondly, it reduces the redundancy constraints with the help
of inter-class information, thus improving the running speed. Most impor-
tantly, it can follow both the consensus and the complementarity principle
simultaneously as a multi-view classiﬁcation model. The consensus principle
is realized by minimizing the coupling items of the two views in the original
objective function. The complementary principle is achieved by establishing
privileged information paradigms and MVL. A standard quadratic program-
ming solver is used to solve the problem. Compared with multi-view clas-
siﬁcation models such as SVM-2K, MVTSVM, MCPK, and PSVM-2V, our
model has better accuracy and classiﬁcation eﬃciency. Experimental results
on 45 binary data sets prove the eﬀectiveness of our method.

∗Corresponding author
Email address: whr2019@bjfu.edu.cn (Huiru Wang )

Preprint submitted to Applied Soft Computing

January 28, 2022

 
 
 
 
 
 
Keywords: Multi-view learning, Weighted-TWSVM, Privileged
information, Consensus principle, Complementarity principle

1. Introduction

Support vector machines (SVMs) [1, 2] are supervised learning models
with relevant learning algorithms which is used to analyze data for classiﬁ-
cation and regression analysis. Till now, many improvements to SVM have
been proposed. The multi-surface proximal SVM via generalized eigenvalues
(GEPSVM) [3] makes each plane the closest to the samples of its category and
the farthest away from the samples of other categories. Compared with SVM,
the GEPSVM possesses better XOR performance and lower computational
complexity. GEPSVM has been developed into a series of new non-parallel
plane classiﬁers. The twin support vector machines (TWSVM) [4] has gained
wide attention due to its good generalization capacity and short calculation
time [5] as a kind of GEPSVM. TWSVM obtains two non-parallel planes by
working out two quadratic programming problems (QPPs), and every QPP
has a smaller size than the standard SVM.

To further improve the solving speed of TWSVM, Ye et al. proposed a
non-parallel plane classiﬁer called weighted TWSVM with local information
(WLTSVM) [6], which digs as much potential similarity information in the
samples as possible. It can discover the geometric and discriminative struc-
tures of data manifolds by constructing intra-class and inter-class graphs.
By weighting the samples [7], the model discovers information about the in-
trinsic similarity of samples in the same class and derives as many support
vectors that reside in the other class as possible. Based on WLTSVM, a
KNN(K-Nearest Neighbor)-based weighted rough ν-TSVM [8], least-squares
KNN-based weighted multiclass TSVM [9], enhanced regularized KNN-based
TSVM (RKNN-TSVM) [10] were proposed so that redundant samples can
be deleted and the running speed can be improved. This idea further reduces
the eﬀect of outliers on the model.

Multi-view data are feature data of the same object obtained from diﬀer-
ent ways or levels, with polymorphism characteristics, multi-source, multi-
descriptive, and high-dimensional heterogeneity, etc [11]. For example, SIFT
features, color histogram features, texture features, and text descriptions con-
stitute a multi-view of the image in the image recognition problem. Multi-
view data use features distributed in diﬀerent feature spaces from diﬀerent

2

perspectives to describe an object. These various features disclose diﬀerent
attributes of objects from distinct perspectives, thus enabling a more compre-
hensive and accurate description of objects compared to a single perspective.
Multi-view learning (MVL), also considered data integration of multiple fea-
ture sets, is a rising direction in machine learning. Nowadays, MVL has been
widely used in various ﬁelds and researches [12, 13, 14, 15]. In addition, a
multi-view canonical correlation analysis method based on variational graph
neural network is proposed [16]. This method is an advanced model based
on multi-view data and adopts multi-view representation learning techniques.
MVL has proven eﬀective in diﬀerent application scenarios, such as improv-
ing image classiﬁcation, annotation, and retrieval performance [17], ﬁnancial
distress prediction [18], predicting the multiple stages of AD progression [19]
and mining product adoption intentions from social media [20]. MVL meth-
ods can be deduced in following three major classes [21]: co-regularization
style algorithms, co-training style algorithms, and margin consistency style
algorithms [22, 23].

To better mine the information, MVL generally needs to follow two prin-
ciples: the principle of consistency and the principle of complementarity
[24, 25]. The consistency principle aims to maximize the consistency of mul-
tiple views. The principle of complementarity indicates that complementary
information from multiple views ought to be used to provide a more com-
prehensive and accurate description of the object. Under these two princi-
ples, MVL algorithms can be sorted into co-regularization algorithms and
co-training algorithms. The co-regularization algorithm fuses the regular-
ization term of the discriminant function into the objective function to in-
sure consensus information between diﬀerent views. SVM-2K [26], multi-
view twin SVMs (MVTSVM) [27], regularized multi-view least squares SVM
(RMVLSSSVM) [28] and multi-view maximum margin of twin spheres SVM
[29] are representative multi-view co-regularization learning algorithms. The
co-training algorithm maximizes the mutual consistency of multiple views by
iterations and exchanges complementary information to generate a classiﬁer
on each view [30]. Algorithms that satisfy these two principles tend to have
better generalization capability and performance. Most existing classiﬁcation
models either satisfy the complementarity principle or the consistency prin-
ciple, but fewer models satisfy both principles like multi-view least squares
SVM [31].

Inspired by the above-mentioned theories and conclusions, we propose a
novel classiﬁcation algorithm for MVL called multi-view learning with priv-

3

ileged weighted twin support vector machines (MPWTSVM). It is achieved
by solving two QPPs which makes MPWTSVM work faster. The model we
propose mines the potential similarity information between diﬀerent perspec-
tives and categories by using two graphs (intra-class and inter-class graph)
to represent intra-class compactness and inter-class separability. Intuitively,
support vectors exist in the closest relationship between samples that shar-
ing diﬀerent labels. Therefore, by considering possible support vectors, the
time complexity can be signiﬁcantly reduced. We ensure the consistency
principle by minimizing the coupling terms of the two views in the objective
function. Through the establishment of a privileged information paradigm
and MVL, the principle of complementarity is realized. Consequently, the
proposed model coordinates all views’ information abundantly during the
learning procedure and preserves diﬀerent views’ characteristics and inher-
ent similarity information. We use a standard quadratic programming solver
in order to seek the solution of MPWTSVM. In addition, numerical experi-
ments are conducted to verify the performance.

In summary, our contributions can be outlined as follows.

1) MPWTSVM uses the weighted idea of WLTSVM and incorporates this

ideology into multiple views. It is worth noting that in the two-classiﬁcation
process, we weigh the samples separately under two perspectives and ob-
tain the weights of diﬀerent types and the same type at each view. With
the help of KNN, redundant samples are deleted. Therefore, the operation
eﬃciency is greatly improved.

2) Our model can satisfy both the two principles of MVL, namely, the con-
sensus principle and the complementarity principle. The consensus prin-
ciple is realized by minimizing the coupling items of the two views in the
objective function. The complementary principle is achieved by estab-
lishing privileged information paradigms from diﬀerent perspectives and
MVL. Therefore, the proposed MPWTSVM has a better classiﬁcation
ability.

3) We compare our method with ﬁve state-of-the-art algorithms and per-
formed numerical experiments on 45 binary multi-view classiﬁcation data
sets. The results demonstrate that MPWTSVM has better accuracy and
eﬃciency than other similar algorithms.

The remainder of this paper is presented below. Section 2 retrospects
related work about WLTSVM and PSVM-2V. Section 3 provides a detailed

4

description of our proposed MPWTSVM, where we derive the method’s dual
optimization problem and kernel trick. In Section 4, we compare our algo-
rithm with four state-of-the-art algorithms. Section 5 gives the experimental
results, and we provide conclusions and future work in Section 6.

2. Related Works

In this section, we give a brief review on a single view learning algorithm

WLTSVM and a multi-view learning algorithm PSVM-2V.

2.1. WLTSVM

In [6], a TSVM-based model WLTSVM with local information was pro-
posed. The WLTSVM uses two graphs, i.e., intra-class and inter-class graph,
to describe the tightness within a class and the separability between classes,
so as to dig out as much basic similarity information as possible in the sam-
ples. WLTSVM ﬁnds two nonparallel hyperplanes f (x), one for positive
class, and the other for negative class:

f1(x) = w(cid:62)

1 x1 + b1, f2(x) = w(cid:62)

2 x2 + b2,

where w1 and w2 are two nonparallel hyperplanes’ weights, b1 and b2 are
the biases. The model classiﬁes the samples according to the hyperplane to
which the given sample is close.

Suppose that we have N1 positive training samples {xi, yi}, i = 1, 2, ..., N1,
and N2 negative training samples {xi, yi}, i = 1, 2, ..., N2, where xi ∈ R and
yi is the class label. For any pair of points (xi, xj), (i = 1, 2, ..., N1, j =
1, 2, ..., N1) in positive samples and an arbitrary point xl(l = 1, 2, ..., N2)
in negative samples, we deﬁne the weight matrices of within-class graph
Gs (W 1
j ) of positive samples as below:

s,ij) and between-class graph Gd (f 1

W 1

s,ij =






1,

if xi is the k-nearest neighbors of xj
or xj is the k-nearest neighbors of xi

0, otherwise,

f 1
j =

(cid:40)

1, ∃j, W 1
0, otherwise,

d,ij (cid:54)= 0

5

(1)

(2)

where

W 1

d,ij =

(cid:40)

if xl is the k-nearest neighbors of xi

1,
0, otherwise.

(3)

Similarly, we can get the weight matrices of negative samples and name

them W 2

s,ij and f 2
j .
Let dj = (cid:80)l1
j=1 W 1

j=1 W 2
the formulation of WLTSVM can be written as follows:

s,ij, j = 1, 2, ..., N1; qj = (cid:80)l2

s,ij, j = 1, 2, ..., N2,then

1
2

1
2

min

i=1
s.t. − f 1

l1(cid:88)

dj(ω(cid:62)

1 x+

j + b1)2 + C

l2(cid:88)

ξj,

j (ω(cid:62)

1 x−

j + b1) + ξj ≥ f 1

j=1
j · 1,

and

min

l2(cid:88)

qj(ω(cid:62)

2 x+

j + b2)2 + C

l1(cid:88)

ξj,

i=1
s.t. − f 2

j (ω(cid:62)

2 x+

j + b2) + ξj ≥ f 2

j=1
j · 1,

ξj ≥ 0,

ξj ≥ 0,

(4)

(5)

where (wi, bi) ∈ (Rn × R)(i = 1, 2), C is the penalty coeﬃcient, and ξ is the
nonnegative slack variable.

2.2. PSVM-2V

Suppose there is a dataset with two perspectives of l labeled augmented
samples {(XA, XB, Y )} = {(xA
i , yi)}l
i=1, where
XA and XB are two views’ feature spaces. The ith sample of two views
are represented by the superscripts A and B of xi. PSVM-2V ﬁnds two
hyperplanes, one for view A, another for view B:

i=1 = {(xA

i ; 1), yi)}l

i ; 1), (xB

i , xB

w∗
A

(cid:62)φA(xA) = 0, w∗
B

(cid:62)φB(xB) = 0,

with the optima w∗

A and w∗

B from problem (6).

6

The optimization problem of PSVM-2V [32] can be written as follows,

1
2

min

s.t.

(cid:0)||ωA||2 + γ||ωB||2(cid:1) + C A

l
(cid:88)

ξA∗
i + C B

i=1
i )) − (wB · φB(xB
i ))| ≤ (cid:15) + ηi
i )) ≥ 1 − ξA∗
i )) ≥ 1 − ξB∗
i )),
i )),

|(wA · φA(xA
yi(wA · φA(xA
yi(wB · φB(xB
ξA∗
i ≥ yi(wB · φB(xB
ξB∗
i ≥ yi(wA · φA(xA
i = 1, ..., l,
ηi ≥ 0,

ξA∗
i ≥ 0
ξB∗
i ≥ 0

i

i

l
(cid:88)

i=1

ξB∗
i + C

l
(cid:88)

i=1

ηi

(6)

where wA, wB are weight vectors for views A and B respectively and φA, φB
are mappings from inputs to high-dimensional feature spaces. The princi-
ple of complementary is realized by limiting the non-negative slack variables
l )(cid:62) by the non-negative correc-
1 , ξB
ξA = (ξA
tion function. C A, C B, C are non-negative penalty parameters, γ is a non-
negative trade-oﬀ parameter and η is the nonnegative slack variable.

l )(cid:62) and ξB = (ξB

2 , ...ξB

2 , ...ξA

1 , ξA

3. The multi-view learning with priviledged weighted twin support

vector machines

In this paper, we propose a novel MVL method called multi-view learning
with priviledged weighted TSVM (MPWTSVM) which realizes the consen-
sus and complementarity principle at the same time.
It not only inherits
the weighting idea of WLTSVM, but also combines MVL to produce better
performance. The linear and nonlinear cases of MPWTSVM and the dual
formulations are presented in the following sections. Major notations used
in this paper are summerized in Table 1.

Table 1
List of notations

i , yi)

Notation
i , xB
(xA
l
(xi · xj)
ωA, ωB

Description
ith training point
number of training points
inner product between xi and xj as x(cid:62)
weight vectors for view A and view B

i xj

7

Table 1
List of notations

Description
mappings from inputs to high-dimensional feature spaces
kernel function (φ(xi) · φ(xj))

Notation
φ(·)
K(xi, xj)
CA, CB, C, CA2, CB2, C2 non-negative penalty parameter
non-negative trade-oﬀ parameter
γ
W A, W B
intra-class weight matrix of view A and view B
i , f B
f A
inter-class weight matrix of view A and view B

i , f A

j , f B
j

3.1. Linear MPWTSVM

To make full use of similarity information in data aﬃnity we deﬁne the
intra-class weight matrix of view A’s positive and negative samples respec-
tively.

W A

s,ij =






1,

if xA
i
or xA
j
0, otherwise,

is the k-nearest neighbors of xA
j
is the k-nearest neighbors of xA
i

(7)

pairs of points (xA
j ) are in view A’s positive and negative samples respec-
tively. Similarly, we can acquire intra-class weight matrix of view B’s positive
samples and negative samples respectively.

i , xA

The inter-class weight matrix can be deﬁned as below:

f A
j =

(cid:40)

1, ∃j, W A
0, otherwise,

d,ij (cid:54)= 0

where W A

d,ij =

(cid:40)

if xA
1,
l
0, otherwise,

is the k-nearest neighbors of xA
i

(8)

(9)

i , xA

j ) are in view A’s positive samples, xA
l

and pairs of points (xA
is an arbi-
trary point in view A’s negative samples. In the same way, the inter-class
weight matrix of view A and view B can be well deﬁned. We can use the
weighted thought of WLTSVM and incorporate this idea into multiple views.
By this means, we can obtain the intra-class and inter-class weight matrix
weight in the corresponding view.

8

Fig.1 displays the model construction of MPWTSVM. Multi-view data
are gathered from diﬀerent ﬁelds or gained from diﬀerent feature extrac-
tors for eﬀective learning. By weighting the data from diﬀerent perspec-
tives, MPWTSVM makes full use of the similarity information in data aﬃn-
ity. Combining with privilege information and introducing coupling items,
MPWTSVM meets the two principles of multi-view classiﬁcation.

MPWTSVM ﬁnds four hyperplanes, two for view A, two for view B:

f A
1 (xA) = wA
1 (xB) = wB
f B

1 xA
1 xB

1 + bA
1 ,
1 + bB
1 ,

2 (xA) = wA
f A
2 (xB) = wB
f B

2 xA
2 xB

2 + bA
2 ,
2 + bB
2 ,

1 (xA) and f A

2 (xA) are two nonparallel hyperplanes for positive class
where f A
2 (xB) are two non-
and negative class of view A separately, f B
parallel hyperplanes for positive class and negative class of view B. wt
1 and
wt
2 are the biases
of view t (t=A,B). The view t’s model of MPWTSVM classiﬁes the samples
relying on which hyperplane (from f t
2(x)) the given view t’s sample
is close to.

2 are the weights of two nonparallel hyperplanes, bt

1 (xB) and f B

1(x) and f t

1 and bt

Formally, MPWTSVM can be established as follows:

min

1
2

l1(cid:88)

l1(cid:88)

i=1

j=1

W A

s,ij(ωA(cid:62)

+ xA,+

j + bA

+)2 +

1
2

γ

l1(cid:88)

l1(cid:88)

i=1

j=1

W B

s,ij(ωB(cid:62)

+ xB,+

j + bB

+)2

+ CA

l2(cid:88)

j=1

ξA
j + CB

l2(cid:88)

ξB
j + C

l2(cid:88)

j ξB
ξA
j

+ xA,−
+ xB,−

j (ωA(cid:62)
s.t. − f A
j (ωB(cid:62)
− f B
j ≥ −f B
ξA
j ≥ −f A
ξB

j=1
j=1
j ≥ f A
+) + ξA
j
j ≥ f B
+) + ξB
j
ξA
j + bB
j ≥ 0,
+),
ξB
j + bA
j ≥ 0,
+),

j + bA
j + bB
j (ωB(cid:62)
j (ωA(cid:62)

+ xB,−
+ xA,−

· 1,

· 1,

(j ∈ I −)

(10)

9

and

min

1
2

l2(cid:88)

l2(cid:88)

i=1

j=1

W A

s,ij(ωA(cid:62)

− xA,−

j + bA

−)2 +

1
2

γ

l2(cid:88)

l2(cid:88)

i=1

j=1

W B

s,ij(ωB(cid:62)

− xB,−

j + bB

−)2

s.t.

+ CA2

l1(cid:88)

i=1

ξA
i + CB2

l1(cid:88)

ξB
i + C2

l1(cid:88)

i ξB
ξA
i

i=1

i (ωA(cid:62)
f A
i (ωB(cid:62)
f B
ξA
i ≥ f B
ξB
i ≥ f A

− xA,+
− xB,+
i (ωB(cid:62)
i (ωA(cid:62)

i + bA
i + bB
− xB,+
− xA,+

i=1
i ≥ f A
−) + ξA
i
i ≥ f B
−) + ξB
i
i + bB
ξA
i ≥ 0,
−),
i + bA
ξB
−),
i ≥ 0,

· 1,

· 1,

(i ∈ I +)

(11)

where CA, CB, C, CA2, CB2, C2 are non-negative parameters and γ is a non-
negative trade-oﬀ parameter.

Figure 1: Schematic diagram of MPWTSVM model construction.

Under the supposition that both perspectives are equally important, the
MPWTSVM targets on seeking four hyperplanes, which are explained in
detail below:

10

View AView BWeighed View AWeighed View BweighweighPrivileged informationPrivileged informationCoupling TermComplementarityConsensusThe SIFT featureColor histogram featureTexture featureText description of the imageMulti-view DataMPWTSVM(1) The variables to be worked out in problem (10) are wA

+, wB

+, bA

+, bB

+, ξA

and ξB. Problem (11) is similar.

(2) A larger W A

s,ij indicates a larger weight within the positive class of view A,
which can make full use of the structural information. The introduction
of this term can make a more compact structure and thus have a better
generalization performance. View B is the same. These matrices fully
exploit the intra-class information of view A and B.

(3) Minimizing ξA

i , ξB

i ξB
i

i=1 ξA

i demonstrates the product of error variables of A and
B should be as small as possible. Besides, minimizing the coupling term
C (cid:80)l
indicates that the high amount of error in one perspective
can be recompensed by the low amount of error in the other perspective.
It means that a bigger error variable can be allowed in one perspective. In
this way, the classiﬁcation results of the models constructed in diﬀerent
views can converge, and the principle of consensus is realized.

(4) If the inter-class weight f A or f B is 0, it means that the sample con-
straint is redundant and can be deleted, as a consequence the algorithm
eﬃciency is greatly improved.

(5) Our model uses each view separately as privileged information to refor-
mulate the slack variables. By limiting the non-negative slack variables
ξA and ξB through the unknown non-negative correcting functions de-
termined by view A and B, therefore, MPWTSVM realizes the comple-
mentary principle.

3.2. The dual problem

For simplicity, we let dA/B

i

l1(cid:80)

=

W A/B
s,ij

, wA/B

± =

i=1
(xA/B, 1). Aiming at getting the solution of (10), the corresponding La-

(cid:18) ωA/B
±
b±

(cid:19)

, xA/B =

11

grangian function can be constructed as

L(wA

+, wB

+, ξA

j , ξB

j ) =

1
2

l1(cid:88)

i=1

+ CA

i (wAT
dA

+ xA,+

i

)2 +

l2(cid:88)

j=1

ξA
j + CB

l2(cid:88)

j=1

1
2

γ

l1(cid:88)

i=1

ξB
j + C

i (wBT
dB

+ xB,+

j

)2

l2(cid:88)

j=1

j ξB
ξA
j

−

−

−

−

−

l2(cid:88)

j=1

l2(cid:88)

j=1

l2(cid:88)

j=1

l2(cid:88)

j=1

l2(cid:88)

j=1

(cid:104)
−f A

j (wAT

+ xA,−

j

) + ξA

j − f A
j

(cid:105)

(cid:104)
−f B

j (wBT

+ xB,−

j

) + ξB

j − f B
j

(cid:105)

αA
j

αB
j

(cid:104)

λA
j

ξA
j + f B

j (wBT

+ xB,−

j

(cid:104)
ξB
j + f B

j (wAT

+ xA,−

j

λB
j

(cid:105)
)

(cid:105)
)

j ξA
βA

j −

l2(cid:88)

j=1

j ξB
βB
j ,

(12)

where αA = (αA
(λB
Lagrange multipliers vectors.

1 , ..., αA
l2
)(cid:62), βA = (βA

1 , ..., λB
l2

)(cid:62), αB = (αB
1 , ..., βA
l2

1 , ..., αB
l2
)(cid:62), βB = (βB

)(cid:62), λA = (λA
1 , ..., βB
l2

)(cid:62), λB =
1 , ..., λA
l2
)(cid:62) are the non-negative

Diﬀerentiating the Lagrangian function L with respect to variables wA

+, wB
+,

12

j , ξB
ξA

j yields the following Karush-Kuhn-Tucker (KKT) conditions:

∂L
∂wA
+

=

l1(cid:88)

i=1

i xA,+
dA

i xA,+

i

(cid:62)

wA

+ +

l2(cid:88)

j=1

j f A
αA

j xA,−

j −

l2(cid:88)

j=1

j f A
αB

j xA,−

j = 0,

∂L
∂wB
+

= γ

l1(cid:88)

i=1

i xB,+
dB

i xB,+

i

(cid:62)

wB

+ +

l2(cid:88)

j=1

j f B
αB

j xB,−

j −

l2(cid:88)

j=1

j f B
αA

j xB,−

j = 0,

(13)

∂L
∂ξA
j
∂L
∂ξB
j

= CA + C · ξB

j − αA

j − λA

j − βA

j = 0,

= CB + C · ξA

j − αB

j − λB

j − βB

j = 0,

A,− − f A

j + ξA
j

(cid:17)

= 0,

j + ξB
j

(cid:17)

= 0,

αA
j

αB
j

λA
j

(cid:16)

+ xj

−f A
(cid:16)

−f B

j wA(cid:62)
j wB(cid:62)

+ xj
j wB(cid:62)
j wA(cid:62)

(cid:16)

j + f B
ξA
(cid:16)

ξB
j + f A

+ xj

+ xj

B,− − f B
B,−(cid:17)

= 0,

A,−(cid:17)

= 0,

λB
j
βA
j ξA
j ξB
βB

j = 0,
j = 0.

Expressing (13) and (14) in matrix form, we get:

(cid:62)

(cid:62)

(cid:62)

DA
(cid:62)

X A
+wA
+X A
+
+ wB
γX B
+X B
DB
+
+ = diag(dA
1 , f A

+ + X A
−
+ + X B
−
1 , dA
2 , ..., dA
l1
) and F B
2 , ..., f A
l2

− αA
F A
− − X A
−
(cid:62)
− − X B
− αB
F B
−
), DB
− = diag(f B

− λB
F A
− = 0,
(cid:62)
− λA
F B
+ = diag(dB
1 , f B

− = 0,
1 , dB
2 , ..., dB
l1
2 , ..., f B
).
l2

where DA
− = diag(f A
F A

),

Thereupon we can obtain the optimal solutions wA

+ and wB

+ of (10):

wA

+ = −

(cid:16)

(cid:62)

X A
+

DA

+X A
+

(cid:17)−1 (cid:16)

(cid:62)

X A
−

− (αA
F A

− − λB
−)

(cid:17)

,

(cid:16)

wB

+ = −

(cid:62)

γX B
+

DB

+X B
+

(cid:17)−1 (cid:16)

(cid:62)

X B
−

− (αB
F B

− − λA
−)

(cid:17)

.

13

(14)

(15)

(16)

(17)

(18)

(19)

(20)

(21)

(22)

(23)

(24)

(25)

(26)

If the matrix X A
+

+ or γX B
+
a regularization term (cid:15)I, (cid:15) > 0, then (25) and (26) can be written as

+ is irreversible, we can introduce

+X B

+X A

(cid:62)DB

(cid:62)DA

wA

+ = −

(cid:16)

(cid:62)

X A
+

DA

+X A

+ + (cid:15)I

(cid:17)−1 (cid:16)

(cid:62)

X A
−

− (αA
F A

− − λB
−)

(cid:17)

,

(cid:16)

wB

+ = −

(cid:62)

γX B
+

DB

+X B

+ + (cid:15)I

(cid:17)−1 (cid:16)

(cid:62)

X B
−

− (αB
F B

− − λA
−)

(cid:17)

.

(27)

(28)

The same method is used if we encounter the problem of matrix integrability
in the later part.

By substituting the above equation into (12), we can derive the dual

formulation as follows,

max −

(cid:16)

(cid:62)

−

(cid:1)(cid:62)

DA

X A
+

(cid:0)αB

− X A
F A
−

− − λB
−

1
(cid:0)αA
2
1
2γ
+ αA
F A
− e− + αB
F B
− e− − CξA
−
−
−
−, βB
−, βA
−, λB
−, λA
−, αB
− ≥ 0,

− − λA
−

− X B
F B
−

X B
+

(cid:1)(cid:62)

(cid:16)

(cid:62)

(cid:62)

(cid:62)

s.t. αA

+X A
+

(cid:17)−1

(cid:62)

X A
−

− (αA
F A

− − λB
−)

DB

+X B
+

(cid:17)−1

(cid:62)

X B
−

− (αB
F B

− − λA
−)

(cid:62)

ξB
−

(29)

− + βB

where ξA

(cid:0)αB
− = 1
C
j , βB
Due to βA
j − C · ξA

(cid:0)αA
− = 1
− + λB
− − CB · e−
− − CA · e−
C
j + λA
j ≥ 0 in (15) and (16), we have αA
j ≤ CA,
αB
j + λB
j ≤ CB. Owing to the complexity of objective function (29),
we can work out the following unanimous dual problem as a substitute for
simpliﬁcation,

− + βA
j − C · ξB

(cid:1) and ξB

− + λA

(cid:1).

(cid:1)(cid:62)

F A
− X A
−

(cid:16)

(cid:17)−1

DA

+X A
+

F A
− (αA

− − λB
−)

(cid:62)

X A
+
(cid:16)

(cid:62)

X A
−
(cid:17)−1

min

1
2

+

(cid:0)αB

(cid:0)αA
− − λB
−
1
2γ
− αA
−
− + λA
s.t. αA
αB
− + λB
−, αB
αA

−, λA

(cid:62)

− − λA
−

(cid:1)(cid:62)

− X B
F B
−

(cid:62)

X B
+

DB

+X B
+

(cid:62)

ξB
−

(cid:62)

− e− − αB
F A
−
− − C · ξB
− − C · ξA
−, βA
−, λB

− e− + CξA
F B
−
− ≤ CA · e−
− ≤ CB · e−
−, βB

− ≥ 0 · e−.

(cid:62)

X B
−

− (αB
F B

− − λA
−)

(30)

Next, we deﬁne π+ = (αA
−

(cid:62), αB
−

(cid:62), λA
−

(cid:62), λB
−

(cid:62), ξA
−

(cid:62), ξB
−

(cid:62))(cid:62). Concisely, (30)

14

can be further reformulated as

1
2

+H+π+ + p(cid:62)
π(cid:62)

min
π+
s.t. A+π+ ≤ b+,

+π+

π+ ≥ 0,

where





















H+ =

H +
1

0l2

0l2

0l2 −H +
1

H +

2 −H +
2

0l2 −H +

2 H +
2

−H +
1

0l2

0l2

0l2

0l2

0l2

0l2

0l2

0l2

H +

1 =

(cid:18)

− X A
F A
−

(cid:16)

T

X A
+

DA

+X A
+

(cid:17)−1

T

X A
−

(31)

0l2

0l2

0l2

0l2

0l2

0l2

0l2

0l2

0l2

C · El2





















,

0l2

6l2×6l2

C · El2
(cid:19)

F A
−

,

0l2

0l2

H +
1

0l2

0l2

(cid:18) 1
H +
2 =
γ
+ = (cid:0)−eT
−F A
pT

F B
− X B
−

(cid:16)

T

X B
+

DB

+X B
+

(cid:17)−1

T

X B
−

F B
−

(cid:19)

,

− − eT

−F B
−

01×l2

01×l2

(cid:1)

01×l2

,

1×6l2



El2

A+ =



0l2 El2

0l2

0l2

−C · El2

0l2 El2

0l2 El2 −C · El2

0l2

+ = (cid:0)CA · eT
bT

− CB · eT
−

(cid:1)

,

1×2l2





,

2l2×6l2

El2 is the l2 × l2 identity matrix, 0l2 is the l2 × l2 matrix with all entries be
0 and e− is a column vector with the proper dimension with element 1.

Using a similar process, the second optimization problem (11) can be

15

written as:

1
2

−H−π− + p(cid:62)
π(cid:62)

min
π−
s.t. A−π− ≤ b−,

−π−

π− ≥ 0,

where π− = (αA
+
H −
1



(cid:62), αB
+

(cid:62), λA
+

0l1

(cid:62), ξB
(cid:62), ξA
(cid:62), λB
+
+
+
0l1 −H −
1

H− =



















0l1

H −

2 −H −
2

0l1 −H −

2 H −
2

−H −
1

0l1

0l1

0l1

0l1

0l1

0l1

0l1

0l1

0l1

0l1

H −
1

0l1

0l1

(32)

(cid:62))(cid:62),

0l1

0l1

0l1

0l1

0l1

0l1

0l1

0l1

0l1

C2 · El1





















,

C2 · El1

0l1

6l1×6l1

H −

1 =

(cid:18)

F A
+ X A
+

(cid:16)

(cid:62)

X A
−

DA

−X A
−

(cid:17)−1

X A
+

(cid:62)

F A
+

(cid:19)

,

(cid:18) 1
H −
2 =
γ2
− = (cid:0)−e(cid:62)
p(cid:62)
+F A

El1

A− =



0l1 El1
− = (cid:0)CA2 · e(cid:62)
b(cid:62)

+ X B
F B
+

(cid:16)

(cid:62)

X B
−

DB

−X B
−

(cid:17)−1

X B
+

(cid:62)

F B
+

(cid:19)

,

+ − e(cid:62)
0l1 El1

+F B
+
0l1

01×l1

01×l1

0l1

(cid:1)

01×l1
−C2 · El1

1×6l1


,

0l1 El1 −C2 · El1

0l1

+ CB2 · e(cid:62)
+

(cid:1)

,

1×2l1



,

2l1×6l1

El1 is the l1 × l1 identity matrix, 0l1 is the l1 × l1 matrix with all entries be
0 and e+ is a column vector with the proper dimension with element 1.

A new data point x ∈ Rn is assigned to class r (r=1,2), depending on
which plane it is nearer to. We ﬁrst have the decision function of view A and
view B respectively:

classA(xA) = arg
r=1,2

min

(cid:18) |xA

(cid:62)wA
||wA

r + bA
r |
r ||

(cid:19)

(xA)

(33)

16

and

classB(xB) = arg
r=1,2

min

(cid:18) |xB

(cid:62)wB
||wB

r + bB
r |
r ||

(cid:19)

(xB)

.

(34)

Then the decision function combining two views can be given below:

class(x) = arg
r=1,2

min (dr(x)) ,

(35)

where

dr(x) =

1
2

(cid:18)|xA

(cid:62)wA
||wA

r + bA
r |
r ||

|xB

+

(cid:62)wB
||wB

r + bB
r |
r ||

(cid:19)

.

For the sake of perspicuity, we explicitly express the MPWTSVM algo-

rithm in Algorithm 1.

Algorithm 1 QP Algorithm for MPWTSVM.
i , yi)}l
Input: Training datasets S = {(xA

i , xB

i=1 = {((xA

i ; 1), (xB

i ; 1), yi)}l

i=1,

where label yi ∈ {−1, 1} and the testing sample, x;
Initial parameters γ, CA, CB, C, D ≥ 0.

i , xA

i , xB

j ), KB(xB

j ) and initialize

Output: Decision function as in (33),(34),and(35).
1. Choose two appropriate kernels KA(xA
the kernel parameters.
2. Establish and solve QPPs of (31) and (32) by using 5-fold cross-
validation and choose the best parameters.
3. Construct the separating hyperplanes wA
+
wA
−
0.5(wA
+
4. For a new testing point x, predict its label according to the decision
functions (33) or (34) respectively and (35) collectively.

(cid:62)φA(xA) = 0,
(cid:62)φB(xB) = 0, and
(cid:62)φA(xB) + wB

(cid:62)φB(xB) = 0, wB
(cid:62)φA(xA)) + 0.5(wB

(cid:62)φA(xA) = 0, wB
(cid:62)φA(xA) + wA

(cid:62)φA(xB)) = 0.

+

−

−

+

−

3.3. Nonlinear MPWTSVM

In this section, we extend linear MPWTSVM to the nonlinear case. The

kernel-generated hyperplanes are:

K(xA
K(xB

+, C A)wA
+, C B)wB

+ + bA
+ + bB

+ = 0; K(xA
+ = 0; K(xB

−, C A)wA
−, C B)wB

− + bA
− + bB

− = 0;
− = 0;

(36)

(37)

17

where K is a chosen kernel function deﬁned by K(xi, xj) = (φ(xi) · φ(xj)).
φ(·) is a nonlinear mapping that maps the low-dimensional feature space
to the high-dimensional feature space in a non-linear manner. C denotes
training examples from view A and view B respectively. C A = [X A
2 ] and
C B = [X B
2 ], so that positive examples from view t (t=A,B) are denoted
as Ωt

+ and negative examples from view t are denoted as Ωt
−.
We can deﬁne:

1 ; X B

1 ; X A

Ωt

+ = K(xt
(cid:18) ωt
+
bt
+

+ =

wt

+, C t), Ωt

−, C t),

− = K(xt
(cid:18) ωt
−
bt
−

− =

(cid:19)

.

(cid:19)

, wt

In order to simplify the calculation, we update the matrices above:

+ = (cid:0)K(xt
Ωt

+, C t), e+

(cid:1) ; Ωt

− = (cid:0)K(xt

−, C t), e−

(cid:1) .

Then the optimization problems for non-linear MPWTSVM can be for-

mulated as

min

1
2

M
(cid:88)

M
(cid:88)

i=1

j=1

W A1

s,ij(wA(cid:62)

+ ΩA,+

i

)2 +

1
2

γ

M
(cid:88)

M
(cid:88)

i=1

j=1

W B1

s,ij(wB(cid:62)

+ ΩB,+

i

)2

+ CA

N
(cid:88)

j=1

ξA
j + CB

N
(cid:88)

ξB
j + C

N
(cid:88)

j ξB
ξA
j

j

+ ΩA,−
+ ΩB,−

j (wA(cid:62)
s.t. − f A
j (wB(cid:62)
− f B
ξA
j ≥ −f B
j ≥ −f A
ξB

j (wB(cid:62)
j (wA(cid:62)

j

j=1

· 1,

j=1
j ≥ f A
) + ξA
j
j ≥ f B
) + ξB
j
+ ΩB,−
ξA
j ≥ 0,
),
+ ΩA,−
ξB
j ≥ 0,
),

· 1,

j

j

(j ∈ I −);

(38)

18

and

min

1
2

N
(cid:88)

N
(cid:88)

i=1

j=1

W A2

s,ij(wA(cid:62)

− ΩA,−

j

)2 +

1
2

γ

N
(cid:88)

N
(cid:88)

i=1

j=1

W B2

s,ij(wB(cid:62)

− ΩB,−

j

)2

s.t.

+ CA2

M
(cid:88)

i=1

ξA
i + CB2

M
(cid:88)

ξB
i + C2

i

i (wA(cid:62)
f A
i (wB(cid:62)
f B
i ≥ f B
ξA
i ≥ f A
ξB

− ΩA,+
− ΩB,+
i (wB(cid:62)
i (wA(cid:62)

) + ξA
) + ξB
− ΩB,+
− ΩA,+
),

i

i

i

· 1,

i=1
i ≥ f A
i
i ≥ f B
i
ξA
i ≥ 0,
),
ξB
i ≥ 0,

· 1,

M
(cid:88)

i=1

i ξB
ξA
i

(i ∈ I +).

(39)

4. Comparison with other algorithms

In this section, we compare our MPWTSVM with SVM-2K [26], MVTSVM
[27], MCPK [33] and PSVM-2V [32]. The complexity analysis is also in-
cluded in the following comparisons. For simplicity, we suppose the number
of samples of each class are equal, namely l1 = l2 = l/2, where l repre-
sents the number of training samples. Problem (31) and (32) involve two
convex QPPs. Both of them can be worked out by the classical QP solver
with a time complexity less than 2O((3l)3) for the reason that the inter-class
weight matrix can remove redundant samples and greatly reduce the time
complexity.

4.1. MPWTSVM vs. SVM-2K

SVM-2K solves a QPP, which combines two-stage learning and SVM into
a single optimization. Moreover, it only satisﬁes the consistency principle of
multi-view training by using Kernel Canonical Correlation Analysis (KCCA)
theory [34] and does not satisfy the principle of complementarity. The time
complexity of SVM-2K is O((4l)3). Our model has better eﬃciency compared
to SVM-2K. Our MPWTSVM solves two QPPs which makes it work faster
than SVM-2K. Besides, the introduction of KNN makes it more eﬃcient
to identify the potential support vector. Based on satisfying the principle
of consistency, we met the principle of complementarity with the help of
privileged information.

19

4.2. MPWTSVM vs. MVTSVM

Similar to MVTSVM, our model solves two QPPs. The time complex-
ity of MVTSVM is about 2 × O((2l)3). MVTSVM combines two views by
bringing in the similarity constraint between the two-dimensional projections
of two diﬀerent TSVMs from the two feature spaces. It is only applied to
the classiﬁcation of the two views, which cannot solve the general multi-view
problem. The supplementary information between diﬀerent views cannot
be eﬀectively used so that the model does not satisfy the principle of com-
plementarity. Our model makes full use of each perspective as privileged
information to redeﬁne slack variables, thereby satisfying the principle of
complementarity.

4.3. MPWTSVM vs. MCPK

Compared with MCPK, our model shares with it that they both sat-
isfy both consistency and complementarity principles. The diﬀerence is that
MCPK solves one QPP, while MPWTSVM solves two problems. The time
complexity of MCPK is O((6l)3). Our model has better eﬃciency compared
to MCPK. In addition, our model extends the weighting idea of WLTSVM
to diﬀerent perspectives to measure as much similarity information between
samples as possible and obtain higher accuracy.

4.4. MPWTSVM vs. PSVM-2V

Both PSVM-2V and our model satisfy the complementarity and the con-
sistency principle simultaneously. PSVM-2V solves a QPP. The time com-
plexity of PSVM-2V is O((6l)3). Our model has better eﬃciency compared
to PSVM-2V. PSVM-2V uses regularization terms to limit the diﬀerences
of prediction results from diﬀerent perspectives to achieve the consistency
principle, which is achieved by the coupling terms in the objective function
of our model. PSVM-2V and our model realize the principle of complemen-
tarity both with the help of privileged information. However, compared to
PSVM-2V, our model also draws on the idea of weighting, which enables bet-
ter preservation of the inter and intra connections and diﬀerences of diﬀerent
views in the data.

5. Experiments

In this section, we make comparisons between our MPWTSVM and ﬁve
benchmark methods, SVM+, SVM-2K, MVTSVM, PSVM-2V, and MCPK.

20

We verify the performance of MPWTSVM for binary classiﬁcation on 45
datasets obtained from Animals with Attributes (AwA)1[35].
In order to
eliminate the inﬂuence of size and simplify the numerical calculation, we
scale all the features to the range of [0, 1] in the data preprocessing. The
experiments are conducted in Matlab R2015a on Windows 7 running on a
PC with system conﬁguration Inter(R) Core(TM) i7-6700 CPU (3.40GHz)
with 8.00 GB of RAM.

5.1. Experimental setup

Dataset. The AwA dataset consists of 30,475 images in 50 animal cate-
gories, each image has six pre-extracted features re-represented. The detailed
characteristics of the data set are demonstrated in Table 2. Similar to the
study[36], we use the ten classes in AwA dataset, i.e. antelope, grizzly bear,
killer whale, beaver, dalmatian, Persian cat, horse, German shepherd, blue
whale and Siamese cat. Through the one-to-one strategy, we randomly select
200 samples in each class for training and train 45 binary classiﬁers for each
class pair combination.

Table 2
Comprehensive information of datasets we use in the experiments.

Data set #Data #Classes

#Features
(View A)

#Features
(View B)

AwA

6249

10

252

2000

#Binary data sets

45
(one-versus-one)

Kernels. In these experiments, we choose the Gaussian radial basis function
(RBF) K (xi, xj) = exp(−||xi −xj||2/σ2) for all the algorithms since the RBF
is most widely used in the classiﬁcation problem [31, 37, 33, 38, 39].
Measures. We assess the performance of the classiﬁer by the test accu-
racy. We perform the grid search strategy and 5-fold cross-validation for all
datasets to select the optimal parameters. For methods other than SVM+,
we ponder on the mixed prediction function sign(0.5(fA(xA) + fB(xB))) in
addition to two views’ prediction functions sign(fA(xA)) and sign(fB(xB)),
and choose the one who has the highest precision.
Benchmark method. We make comparisons between the proposed method
and ﬁve of the most recent methods:

1Available at https://cvml.ist.ac.at/AwA2/.

21

1) SVM+ : The SVM+ algorithm [40] replaces the standard SVM’s slack
variable by using the non-negative correction function determined by the
privilege information. During the training process, we separately use the
two views as privileged information for each other.

2) SVM-2K: SVM-2K combines two-stage learning—KCCA followed by SVM,

into a single optimization [26].

3) MVTSVM: MVTSVM merges two perspectives by introducing similarity
constraints between two one-dimensional projections [27]. The model
learns two hyperplanes and solves a pair of QPPs rather than one.

4) PSVM-2V: PSVM-2V extends LUPI (learning using privileged informa-

tion) to MVL [32].

5) MCPK: MCPK is a simple and eﬀective approach to MVL coupling priv-

ilege kernels and satisﬁes two principles for MVL [33].

Parameters. For all algorithms, the optimal parameters are decided by
ﬁve-fold cross validation. The parameter C in SVM+ is selected from the
set {10−3, 10−2, 10−1, 1, 101, 102, 103}. Penalty parameters CA, CB and C of
SVM-2K and PSVM-2V are selected from {10−3, 10−2, 10−1, 1, 101, 102, 103}.
For MVTSVM, we let C1 = C2 = C3 = C4 and D = H, and both of them
are turned over the set {10−3, 10−2, 10−1, 1, 101, 102, 103}. For MCPK, we
set CA = CB = D varying in the set {10−3, 10−2, 10−1, 1, 101, 102, 103}. For
MPWTSVM, we set CA = CB = C = D from {10−3, 10−2, 10−1, 1, 101, 102, 103}.
The neighborhood size k is searched within {3, 5, 7, 9, 11}. Moreover, the
trade-oﬀ parameter γ in SVM+, PSVM-2V, MCPK and MPWTSVM is cho-
sen from the set {10−3, 10−2, 10−1, 1, 101, 102, 103}. The kernel parameter σ
for RBF kernel function is chosen from {10−3, 10−2, 10−1, 1, 101, 102, 103}. For
the sake of simplicity, in the multi-view model, the kernel parameters of the
two views are set to be the same.

5.2. Parameter analysis

To study the inﬂuence of parameters, we examine the parameter sen-
sitivity of MPWTSVM on nine datasets of AwA. The ranges of variation
parameters C, γ, σ are the same as that given in Section 5.1, and we calcu-
late the test data’s accuracy.

22

The consequences are shown in Fig.2. It depicts the values of the main
parameter k for each combination of parameters C and the kernel parameter
corresponding to the highest accuracy rate, in which we control the remaining
parameters to be consistent with C to simplify the calculation and graphing.
These graphs show that the accuracy of MPWTSVM has something to do
with the parameters k, C, σ(ker) on all datasets and is sensitive to them all.
Therefore, these parameters should be carefully adjusted.

(a) gb. vs bea.

(b) gb. vs dal.

(c) bea. vs sc.

(d) bea. vs dal.

(e) bea. vs pt.

(f) bea. vs ho.

(g) bea. vs Gs.

(h) bea. vs bw.

(i) dal. vs sc.

Figure 2: The ﬁgure indicates the highest accuracy k value corresponding to each combi-
nation of C and ker on the datasets from AwA. The colors indicate the degree of accuracy.

5.3. Experimental results

Below, we make the capability of MPWTSVM and all benchmark algo-
rithms under the case of nonlinearity in comparison. Table 3 gives a summary

23

01000210041000610k1008ker11010C1120.10.10.010.010.0010.0015560657075808590Accuracy(%)01000210041000610k1008ker11010C1120.10.10.010.010.0010.0015055606570Accuracy(%)01000210041000610k1008ker11010C1120.10.10.010.010.0010.0015055606570758085Accuracy(%)01000210041000610k1008ker11010C1120.10.10.010.010.0010.001505560657075808590Accuracy(%)01000210041000610k1008ker11010C1120.10.10.010.010.0010.0015055606570758085Accuracy(%)01000210041000610k1008ker11010C1120.10.10.010.010.0010.00155606570758085Accuracy(%)01000210041000610k1008ker11010C1120.10.10.010.010.0010.00150556065707580859095Accuracy(%)01000210041000610k1008ker11010C1120.10.10.010.010.0010.00155606570758085Accuracy(%)01000210041000610k1008ker11010C1120.10.10.010.010.0010.0015860626466687072Accuracy(%)of the detailed information of the overall experimental results on 45 multi-
view datasets, including the accuracy, time, and average rank.
‘Accuracy’
represents the average of ﬁve test results, plus or minus the standard devia-
tion. ‘Time’ means the average training time of ﬁve experiments. The bold
values in Table 3 demonstrate the best accuracy.

Table 3
Performance on AwA dataset (average accuracy ± standard deviation of accuracy(%)).

SVM+A

SVM+B

SVM-2K MVTSVM MCPK

PSVM-2V MPWTSVM

10 gb. vs. sc.

14 gb. vs. pt.

11 gb. vs. kw.

13 gb. vs. dal.

12 gb. vs. bea.

83.50±3.791
92.00±2.739

84.50±4.108 86.00±6.021
85.00±2.500 85.50±4.108
88.00±1.118 91.50±3.791

87.00±2.092 90.00±5.590
82.00±5.123
91.50±4.183
82.00±8.178 84.50±6.471
84.50±4.472 88.50±2.850
83.00±5.420 85.50±2.092

1 ante. vs. sc. 58.50±3.791 84.50±3.710
2 ante. vs. gb. 67.00±3.260 82.50±7.071
3 ante. vs. kw. 79.00±8.023 88.50±5.477
4 ante. vs. bea. 88.50±5.477 98.00±2.092
5 ante. vs. dal. 73.50±6.982 80.50±6.708
72.50±4.677 88.50±8.023

68.00±11.374 63.50±4.183 82.50±6.374
75.00±3.062 72.50±6.847 82.00±4.472
83.50±5.184 77.00±12.550 89.00±3.791
98.00±1.118
92.00±5.420 91.00±2.850 98.50±2.236 96.50±4.183
73.00±4.809 72.50±8.839 84.00±7.416 84.00±3.354 81.00±7.624
75.50±5.701 76.00±4.873 88.00±3.708
6 ante.vs. pt.
7 ante. vs. ho. 68.00±8.551 84.00±7.416 76.00±8.023 69.50±7.786 83.50±4.183
8 ante. vs. Gs. 73.00±9.747 92.50±3.953 78.50±17.375 74.50±2.739 89.00±1.369
75.50±5.969 73.00±5.420 83.50±5.184
9 ante. vs. bw. 75.50±4.809 84.50±9.585
79.50±7.159 75.00±6.124 86.50±2.850
71.00±10.548 87.00±6.225
77.00±4.809 80.50±7.583 84.50±4.809
74.00±9.117 82.00±9.906
84.00±5.755 87.50±6.374 92.50±2.500 91.50±4.541
86.50±4.183 91.50±5.755
77.00±6.471 79.50±7.159
73.00±5.420 74.00±7.202 76.00±5.184
68.00±8.551 76.00±6.755
81.00±8.944 83.50±4.873 86.50±8.768
73.50±8.944 85.00±7.071
87.50±4.677 90.50±5.969
62.50±15.910 62.50±7.500 65.00±10.155 73.50±6.519 76.50±6.755
59.00±8.944 70.00±8.292
84.50±6.937 87.50±5.000
67.50±8.478 76.00±5.755 83.50±6.021
76.00±2.236 83.00±4.108
81.50±6.755 88.50±3.354
77.50±3.062 77.00±4.809 81.50±6.021
68.00±7.374 81.00±3.791
83.00±6.471 81.00±7.202 86.00±1.369
89.00±3.354 89.50±4.108
80.50±4.809 87.00±2.739
18 kw. vs. sc.
90.50±2.092 92.00±2.092
86.50±6.519 85.00±5.590 89.00±4.183
19 kw. vs. bea. 81.50±6.519 87.00±4.809
70.50±4.108 72.00±2.092 72.00±13.393 74.00±3.354 75.50±2.739
68.00±6.708 70.50±6.708
77.00±4.472 71.50±8.944 86.00±2.850 86.50±4.183 86.00±3.354
74.00±6.275 83.50±2.850
82.50±8.101 76.50±6.021 86.00±6.275
70.50±7.159 83.50±3.791
84.50±7.159 88.00±2.739
69.00±5.184 87.50±5.863 74.50±5.701 73.00±3.26
84.50±5.420
85.50±3.260
78.00±6.225 77.00±5.701 83.00±8.178
75.50±3.708 84.00±6.755
82.00±4.809 86.50±2.236
88.50±2.236 93.00±2.092 96.50±1.369
89.50±4.108 95.00±4.330
95.00±3.536 97.00±1.118
25 bea. vs. sc.
95.50±2.092 97.50±3.062
95.50±3.708 93.00±3.260 96.50±2.236
26 bea. vs. dal. 91.50±5.184 96.00±2.850
92.50±3.953 90.00±3.062 95.50±3.260 93.50±3.791 95.50±3.260
88.50±3.354 93.50±2.850
97.50±2.500 98.50±1.369
91.00±5.755 91.00±2.236 98.00±2.092
88.50±5.184 98.00±2.092

28 bea. vs. ho.

20 kw. vs. dal.

24 kw. vs. bw.

27 bea. vs. pt.

87.00±5.701

92.50±3.536

23 kw. vs. Gs.

17 gb. vs. bw.

22 kw. vs. ho.

16 gb. vs. Gs.

21 kw. vs. pt.

15 gb. vs. ho.

24

continued table 3

36 pt. vs. sc.

31 dal. vs. sc.

32 dal. vs. pt.

33 dal. vs. ho.

34 dal. vs. Gs.

35 dal. vs. bw.

96.50±1.369 97.00±2.092
96.00±2.85
98.50±2.236
85.50±4.809 89.00±2.236
89.00±6.275 89.50±4.809

94.00±3.354 93.00±3.708 95.50±3.260
89.00±2.236 92.00±2.739 97.00±1.118
74.50±5.969 73.50±5.477 87.50±6.374
79.50±9.906 77.00±4.108 88.00±2.092
76.00±6.755 68.00±7.984 82.00±4.472 78.50±6.519
69.50±8.178 71.00±6.982 81.50±3.791
73.50±16.919 69.50±11.646 84.50±7.159 84.50±3.26 82.00±3.260
78.00±5.701
91.50±5.755

29 bea. vs. Gs. 92.00±5.701 94.00±6.755
30 bea. vs. bw. 90.50±2.092 95.00±4.677
76.00±6.275 85.50±7.583
74.00±4.183 86.50±3.354
67.00±11.096 76.00±5.184
66.50±5.477 84.00±5.755
65.00±5.303 78.50±6.021
60.00±4.677 78.50±3.354 65.00±1.768 65.00±5.303 77.00±7.583
70.50±4.809 92.50±3.062 87.50±0.000 76.50±5.755 89.50±4.472
81.00±10.093 72.00±7.583 84.00±4.183
68.00±2.739 85.00±6.374
75.50±3.708 72.00±7.374 88.00±3.708
71.50±3.791 84.00±7.416
67.00±3.260 83.50±4.541
76.00±7.202 67.50±5.590 83.00±3.260
64.00±6.275 85.00±3.953 70.50±8.551 71.00±6.755 84.50±9.906 85.00±3.953 84.50±5.969
68.00±4.108 69.00±8.944 75.50±8.178
66.50±3.791 73.50±7.202
71.00±5.477 74.00±6.755 90.50±3.260
75.00±8.292 90.50±3.708
68.00±7.786 70.50±7.159 83.50±4.873
65.00±5.303 85.50±9.253
70.50±7.374 72.50±6.124 77.00±9.083 73.50±5.477
64.50±8.178 73.00±6.225

76.50±4.541
92.00±2.739
82.50±6.124 87.50±5.303
87.00±8.551 89.00±4.183
80.50±4.472 86.00±4.873

75.00±5.000 76.00±4.183
90.50±3.260 93.00±2.092
83.00±4.472 87.50±4.677

81.50±5.755 85.00±3.953

78.50±6.519

73.50±4.873

44 Gs. vs. bw.

42 ho. vs. bw.

41 ho. vs. Gs.

39 pt. vs. bw.

38 pt. vs. Gs.

45 bw. vs. sc.

43 Gs. vs. sc.

37 pt. vs. ho.

40 ho. vs. sc.

Avg.Acc.

73.59

Avg.Time.

0.111

Avg.Rank. 6.678

85.22

0.138

3.011

77.94

0.347

5.500

76.50

0.067

5.756

85.72

0.088

2.678

85.64

0.858

2.911

87.57

0.042

1.467

*W/D/L

45/0/0

37/2/6

45/0/0

45/0/0

35/5/5

38/2/5

0/45/0

*W/D/L is short for Win/Draw/Loss.

The average accuracy of 45 datasets of MPWTSVM is 87.57%, which is
the highest among the seven algorithms followed by MCPK (85.72%), PSVM-
2V (85.64%), SVM+A (85.22%), SVM-2K (77.94%), MVTSVM (76.50%)
and SVM+B (73.59%). MPWTSVM, MCPK and PSVM-2V can follow both
the consensus principle and the complementarity principle. Therefore, the
three algorithms perform better than the other four. It is worth noting that
our model has better generalization performance compared to MCPK and
PSVM-2V. The reason is that it utilizes the weighting idea to better exploit
the intrinsic connections and diﬀerences within and between diﬀerent per-
spectives. SVM-2K and MVTSVM only satisfy the principle of consensus, so
the generalization ability is slightly insuﬃcient compared with MPWTSVM,
PSVM-2V and MCPK. Among the several algorithms, the one with the low-
est accuracy is SVM+, since the model considers only one perspective and

25

uses the other perspective as its privileged information.

The average time of MPWTSVM is 0.042s which is the shortest one com-
pared to MVTSVM (0.067s), MCPK (0.088s), SVM+A (0.111s), SVM+B
(0.138s), SVM-2K (0.347s), and PSVM-2V (0.858s). The reason is that the
proposed MPWTSVM not only solves two small-scale QPPs, but also uses
inter-class weights to remove redundant samples. Therefore, the time com-
plexity can be greatly reduced.

For the same dataset, the accuracy of seven algorithms is ranked and
the optimal one is assigned as 1, the sub optimal algorithm is designated
as 2, and so on. From this, the average rank of each algorithm in 45
datasets is obtained. Our model has an lowest average rank of 1.467 fol-
lowed by MCPK(2.678) and PSVM-2V(2.911) among the seven algorithms,
which shows its good classiﬁcation performance.

In addition, Table 3 shows the wins and losses of our algorithm compared
to other algorithms. If the accuracy of our MPWTSVM is higher than the
other algorithm, it is marked as ‘Win’; if it is equal to the other one, it
is marked as ‘Draw’; and if it is lower than the other one, it is marked as
‘Loss’. After comparing our algorithm with other algorithms in 45 data sets,
we can count the win-loss situation of each algorithm. It can be seen that
compared with SVM+A, SVM-2K, and MVTSVM, our algorithm wins 45
times in 45 data sets; compared with SVM+B, MPWTSVM wins 37 times,
loses six times, and draws twice; compared with MCPK, MPWTSVM wins
35 times, loses ﬁve times and draws ﬁve times; compared with PSVM-2V,
MPWTSVM wins 38 times, loses ﬁve times and draws twice. It denotes that
our algorithm has more prominent advantages compared with other parallel
algorithms.

Fig.3 describes the diﬀerences separating the winning algorithm’s accu-
racy and the remaining algorithms’ average accuracy. The length of each
bar reﬂects the generalization performance of the algorithm, and diﬀerent
colors correspond to diﬀerent algorithms. We can see that MPWTSVM has
a better accuracy among these models.

Fig.4 depicts the comparison between the training time of the winning
algorithm and the remaining algorithms. The value of the ordinate repre-
sents each method’s training time. The numbers on the abscissa indicate the
number of data sets. It is due to the deletion of redundant samples with the
help of the KNN idea, which reduces the running time and improves the com-
putational eﬃciency. It shows the superior eﬃciency of MPWTSVM. These
results strengthen the fact that MPWTSVM itself can make full use of intra-

26

Figure 3: The plot denotes the diﬀerences separating the winning method MPWTSVM’s
(dark red) classiﬁcation accuracy and the remaining algorithms’ average accuracy.

class and inter-class information to obtain better classiﬁcation performance,
which means that MPWTSVM has good generalization ability.

Figure 4: The plot denotes the training time of the following algorithms: SVM+A,
SVM+B, SVM-2K, MVTSVM, MCPK, PSVM-2V, and MPWTSVM.

5.4. Friedman test

We use Friedman test [41] for further analysis since the averaged accuracy
of our MPWTSVM in Table 3 is not always optimal. For each dataset, the

27

00.20.40.60.811.2123456789101112131415161718192021222324252627282930313233343536373839404142434445AccurarcyAwAdata setSVM+ASVM+BSVM-2KMVTSVMMCPKPSVM-2VMPWTSVM00.20.40.60.811.21.4051015202530354045Time(second)AwA data setSVM+ASVM+BSVM-2KMVTSVMMCPKPSVM-2VMPWTSVMhighest accuracy ranking is 1, followed by 2, and so on. Table 3 also shows the
average ranking of the six comparison algorithms. As can be seen from the
Avg.Rank line in Table 3, the average ranking of MPWTSVM is 1.467, which
ranks the bottom of the six methods. The outcome shows that MPWTSVM
proposed by us has the best performance among the six comparison methods.
The following null hypothesis is made: the 7 methods are identical. Fried-

man statistics can be computed using the following formula:

χ2

F =

12N
k(k + 1)

(cid:34)

(cid:88)

j

(cid:35)

R2

j −

k(k + 1)2
4

(40)

where Rj = 1
N

(cid:80)
i

i and rj
rj

i is the jth of k algorithms on the ith of N datasets.

From (40) and with the help of R language, we can get χ2
F is 222.11 and the
P-value of the hypothesis test is 2.2 × 10−16. If α = 0.05, P-value is much
less than α. This means that it denies the null hypothesis above. In other
words, the diﬀerences between these seven methods are obvious.

Since the null hypothesis is rejected, Nemenyi test [42] can be further
conducted. The hollow circle represents the average ranking of the seven al-
gorithms, and the critical diﬀerence CD is shown in the straight lines centered
on ”◦” in Fig.5, where

CD = qα

(cid:114)

k(k + 1)
6N

.

(41)

We can get qα = 2.949 and CD = 1.343 under the signiﬁcance level α =
0.05 by calculation. The consequence in Fig.5 shows that the proposed
MPWTSVM has remarkably better performance than the other models at
the conﬁdence level of 95% .

6. Conclusions

In this paper, we propose a weighted MVL kernel method based on priv-
ileged information termed MPWTSVM, which satisﬁes the principle of con-
sensus and complementarity at the same time. The consensus principle is en-
sured by minimizing the coupling items of the two views in the original goal.
We implement the principle of complementarity by establishing a privileged
information paradigm and by drawing on multi-view learning. In the two-
classiﬁcation process, we weigh the samples from two perspectives to obtain

28

Figure 5: Friedman test.

the weights of diﬀerent types and the same type in each view. The internal
similarity information of samples of the same category is captured. During
the learning process, our model entirely integrates the information of diverse
views and maintains the characteristics of diverse views to a certain extent.
Therefore, the proposed MPWTSVM has better classiﬁcation accuracy and
faster solving speed. We use the standard QP solver to solve MPWTSVM
and compare it with the other ﬁve algorithms. Through numerical experi-
ments on 45 sets of multi-view binary datasets demonstrate the validity and
eﬃciency of our MPWTSVM. In the future, we will extend MPWTSVM to
the case of multiple (more than two) views under the guideline of two prin-
ciples. Other eﬀective optimization algorithms like the alternating direction
methods of multipliers(ADMM) and other solution ways can also be put into
consideration before long.

Acknowledgments

This work was supported in part by the Fundamental Research Funds for

the Central Universities (No. BLX201928).

References

[1] V. N. Vapnik, The nature of statistical learning theory, Springer, Berlin,

1995.

29

6.683.015.505.762.682.911.470.01.02.03.04.05.06.07.08.0SVM+ASVM+BSVM-2KMVTSVMMCPKPSVM-2VMPWTSVM[2] V. Cherkassky, The nature of statistical learning theory , IEEE Trans-

actions on Neural Networks 8 (6) (1997) 1564–1564.

[3] O. Mangasarian, E. Wild, Multisurface proximal support vector machine
classiﬁcation via generalized eigenvalues, IEEE transactions on pattern
analysis and machine intelligence 28 (2006) 69–74.

[4] Jayadeva, R. Khemchandani, S. Chandra, Twin support vector machines
for pattern classiﬁcation, IEEE Trans. Pattern Anal. Mach. Intell. 29 (5)
(2007) 905–910.

[5] S. Ghorai, A. Mukherjee, P. K. Dutta, Nonparallel plane proximal clas-

siﬁer, Signal Processing 89 (4) (2009) 510–522.

[6] Q. Ye, C. Zhao, S. Gao, H. Zheng, Weighted twin support vector ma-
chines with local information and its application, Neural Networks 35
(2012) 31–39.

[7] Q. Ye, C. Zhao, N. Ye, X. Chen, Localized twin svm via convex mini-

mization, Neurocomputing 74 (4) (2011) 580–587.

[8] Y. Xu, J. Yu, Y. Zhang, Knn-based weighted rough ν-twin support

vector machine, Knowledge-Based Systems 71 (2014) 303–313.

[9] M. Tanveer, A. Sharma, P. N. Suganthan, Least squares knn-based
weighted multiclass twin svm, Neurocomputing 459 (2021) 454–464.

[10] J. A. Nasiri, A. M. Mir, An enhanced knn-based twin support vector
machine with stable learning rules, Neural Computing and Applications
32 (16) (2020) 12949–12969.

[11] X. Zhang, L. Zhao, L. Zong, X. Liu, H. Yu, Multi-view clustering via
multi-manifold regularized nonnegative matrix factorization, in: 2014
IEEE International Conference on Data Mining, 2014, pp. 1103–1108.

[12] X. Liu, L. Wang, J. Zhang, J. Yin, Sample-adaptive multiple kernel
learning, Proceedings of the National Conference on Artiﬁcial Intelli-
gence 3 (2014) 1975–1981.

[13] J. Chen, G.-B. Huang, Dual distance adaptive multiview clustering,

Neurocomputing 441 (2021) 311–322.

30

[14] J. Ma, Y. Zhang, L. Zhang, Discriminative subspace matrix factorization
for multiview data clustering, Pattern Recognition 111 (2021) 107676.

[15] J. Xu, J. Han, F. Nie, X. Li, Multi-view scaling support vector machines
for classiﬁcation and feature selection, IEEE Transactions on Knowledge
and Data Engineering 32 (7) (2020) 1419–1430.

[16] Y. Kaloga, P. Borgnat, S. P. Chepuri, P. Abry, A. Habrard, Variational
graph autoencoders for multiview canonical correlation analysis, Signal
Processing 188 (2021) 108182.

[17] N. Chen, J. Zhu, E. Xing, Predictive subspace learning for multi-view

data: a large margin approach, 2010, pp. 361–369.

[18] J. Sun, H. Fujita, Y. Zheng, W. Ai, Multi-class ﬁnancial distress predic-
tion based on support vector machines integrated with the decomposi-
tion and fusion methods, Information Sciences 559 (2021) 153–170.

[19] X. Zhang, Y. Yang, T. Li, Y. Zhang, H. Wang, H. Fujita, Cmc: A
consensus multi-view clustering model for predicting alzheimer’s dis-
ease progression, Computer Methods and Programs in Biomedicine 199
(2021) 105895.

[20] Z. Zhang, X. Wei, X. Zheng, D. D. Zeng, Predicting product adoption
intentions: An integrated behavioral model-inspired multiview learning
approach, Information & Management 58 (7) (2021) 103484.

[21] J. Zhao, X. Xie, X. Xu, S. Sun, Multi-view learning overview: Recent
progress and new challenges, Information Fusion 38 (2017) 43–54.

[22] S. Sun, G. Chao, Multi-view maximum entropy discrimination, 2013,

pp. 1706–1712.

[23] G. Chao, S. Sun, Consensus and complementarity based maximum en-
tropy discrimination for multi-view classiﬁcation, Information Sciences
367-368 (2016) 296–310.

[24] S. Sun, A survey of multi-view machine learning, Neural Computing and

Applications 23 (2013) 2031–2038.

31

[25] C. Xu, D. Tao, Large-margin multi-viewinformation bottleneck, Pat-
tern Analysis and Machine Intelligence, IEEE Transactions on 36 (2014)
1559–1572.

[26] J. D. R. Farquhar, H. Meng, S. Szedmak, D. R. Hardoon, J. Shawe-
taylor, Two view learning: Svm-2k, theory and practice, in: Advances
in Neural Information Processing Systems, MIT Press, 2006.

[27] X. Xie, S. Sun, Multi-view twin support vector machines, Intelligent

Data Analysis 19 (4) (2015) 701–712.

[28] X. Xie, Regularized multi-view least squares twin support vector ma-

chines, Applied Intelligence 48 (9) (2018) 3108–3115.

[29] H. Wang, Z. Zhou, Multi-view learning based on maximum margin of
twin spheres support vector machine, Journal of Intelligent and Fuzzy
Systems 40 (6) (2021) 11273–11286.

[30] A. Blum, T. Mitchell, Combining labeled and unlabeled data with co-
training, in: Proceedings of the Eleventh Annual Conference on Com-
putational Learning Theory, COLT’ 98, Association for Computing Ma-
chinery, New York, NY, USA, 1998, p. 92–100.

[31] L. Houthuys, R. Langone, J. A. Suykens, Multi-view least squares sup-
port vector machines classiﬁcation, Neurocomputing 282 (2018) 78–88.

[32] J. Tang, Y. Tian, P. Zhang, X. Liu, Multiview privileged support vector
machines, IEEE Transactions on Neural Networks and Learning Systems
29 (8) (2018) 3463–3477.

[33] J. Tang, Y. Tian, D. Liu, G. Kou, Coupling privileged kernel method
for multi-view learning, Information Sciences 481 (2019) 110–127.

[34] D. R. Hardoon, S. Szedmak, J. Shawe-Taylor, Canonical correlation
analysis: An overview with application to learning methods, Neural
Computation 16 (12) (2004) 2639–2664.

[35] Y. Xian, C. H. Lampert, B. Schiele, Z. Akata, Zero-shot learning—a
comprehensive evaluation of the good, the bad and the ugly, IEEE
Transactions on Pattern Analysis and Machine Intelligence 41 (9) (2019)
2251–2265.

32

[36] S. Motiian, M. Piccirilli, D. A. Adjeroh, G. Doretto, Information bot-
tleneck learning using privileged information for visual recognition, in:
2016 IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), 2016, pp. 1496–1505.

[37] L. Yang, H. Dong, Support vector machine with truncated pinball loss
and its application in pattern recognition, Chemometrics and Intelligent
Laboratory Systems 177 (2018) 89–99.

[38] P. Zhu, W. Zhu, Q. Hu, C. Zhang, W. Zuo, Subspace clustering guided
unsupervised feature selection, Pattern Recognition 66 (2017) 364–374.

[39] L. Houthuys, R. Langone, J. A. Suykens, Multi-view kernel spectral

clustering, Information Fusion 44 (2018) 46–56.

[40] V. Vapnik, A. Vashist, A new learning paradigm: Learning using privi-
leged information, Neural Networks 22 (5) (2009) 544–557, advances in
Neural Networks Research: IJCNN2009.

[41] J. Demˇsar, Statistical comparisons of classiﬁers over multiple data sets,

J. Mach. Learn. Res. 7 (2006) 1–30.

[42] P. B. Nemenyi, Distribution-free multiple comparisons., Princeton Uni-

versity, 1963.

33

