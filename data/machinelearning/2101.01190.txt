1
2
0
2

r
p
A
3
2

]
h
p
-
t
n
a
u
q
[

2
v
0
9
1
1
0
.
1
0
1
2
:
v
i
X
r
a

Control of Stochastic Quantum Dynamics by
Diﬀerentiable Programming

Frank Sch¨afer1, Pavel Sekatski1,2, Martin Koppenh¨ofer1,3,
Christoph Bruder1, and Michal Kloc1
1 Department of Physics, University of Basel, Klingelbergstrasse 82, CH-4056 Basel,
Switzerland
2 Department of Applied Physics, University of Geneva, CH-1211 Geneva,
Switzerland
3 Pritzker School of Molecular Engineering, University of Chicago, Chicago, Illinois
60637, USA

E-mail: frank.schaefer@unibas.ch, michal.kloc@unibas.ch

26 April 2021

Abstract. Control of the stochastic dynamics of a quantum system is indispensable
in ﬁelds such as quantum information processing and metrology. However, there is
no general ready-made approach to the design of eﬃcient control strategies. Here,
we propose a framework for the automated design of control schemes based on
diﬀerentiable programming (∂P). We apply this approach to the state preparation and
stabilization of a qubit subjected to homodyne detection. To this end, we formulate
the control task as an optimization problem where the loss function quantiﬁes the
distance from the target state, and we employ neural networks (NNs) as controllers.
The system’s time evolution is governed by a stochastic diﬀerential equation (SDE). To
implement eﬃcient training, we backpropagate the gradient information from the loss
function through the SDE solver using adjoint sensitivity methods. As a ﬁrst example,
we feed the quantum state to the controller and focus on diﬀerent methods of obtaining
gradients. As a second example, we directly feed the homodyne detection signal to
the controller. The instantaneous value of the homodyne current contains only very
limited information on the actual state of the system, masked by unavoidable photon-
number ﬂuctuations. Despite the resulting poor signal-to-noise ratio, we can train our
controller to prepare and stabilize the qubit to a target state with a mean ﬁdelity of
around 85%. We also compare the solutions found by the NN to a hand-crafted control
strategy.

1. Introduction

The ability to precisely prepare and manipulate quantum degrees of freedom is a
prerequisite of most applications of quantum mechanics in sensing, computation,
simulation and general information processing. Many relevant tasks in this area can
be formulated as optimal control problems, and therefore, quantum control is a rich and

 
 
 
 
 
 
2

very active research ﬁeld, see [1, 2] for two recent textbooks that provide theoretical
background and [3] for a recent review of important issues.

A typical goal of quantum control

is to ﬁnd a sequence of operations or
parameter values (e.g. external ﬁeld amplitudes) such that the quantum system under
consideration is maintained in a certain target state or evolves in a desired fashion
subject to additional boundary conditions (e.g. most rapid evolution for a prescribed
maximal strength of the control ﬁelds).
In the case of feedback control the control
sequence is determined based on a signal coming from the system [3, 4]. The control
task and its boundary conditions are typically speciﬁed by a loss function. To cast the
optimal control problem into an optimization task, one then introduces a parametric
ansatz for feedback schemes, also known as controllers, and explores the parameter space
to minimize the loss function.

Reinforcement learning (RL) [5, 6] has been proposed as a suitable framework to
develop control strategies. In this framework, the controller (or agent), optimizes its
strategy (the policy) based on the loss function (the rewards) obtained from repetitive
interactions with the system to be controlled. In the context of quantum physics, RL
has proven useful, e.g.
for reducing the error rate in quantum gate synthesis [7], for
autonomous preparation of Floquet-engineered states [8], and for optimal manipulation
i.e. the agent has no prior
of many-qubit systems [9]. RL is a black-box setting,
knowledge on the structure of the system it interacts with, and has to develop its policy
(explore the space of control parameters) only relying on its past interactions with the
system. This makes RL very versatile but requires a large number of training episodes
to ﬁnd a good strategy.

Optimal control design is rarely done on an (unknown) system in situ.

Instead
one trains the controller on a physical model of the real system. This means that
rather than learning how to interact with an unknown environment, one actually starts
with a lot of prior scientiﬁc knowledge about the system, namely its precise dynamical
In the simplest cases, one can even solve the optimal control problem for
model.
this model analytically. Generally, using prior information leads to more data-eﬃcient
training [10, 11]. In the context of the present paper, we use the physical model of the
system to eﬃciently compute the loss function’s gradients with respect to the parameters
of the controller ansatz. Naturally, having access to the gradients of the loss function
can streamline the optimal control design tremendously.

In the case of quantum control the model consist of a quantum state space and
a parametric equation of motion. The dynamics of the system can be solved for ﬁxed
values of the parameters of the model and of the controller. Usually, this is done
numerically. Then, the most naive way to obtain the loss function’s gradients is to
solve the dynamics for a set of parameter values in the neighborhood of each point
and use ﬁnite diﬀerence quotients. Yet, this method is unfeasible if the number of
parameters is large, it suﬀers from ﬂoating-point errors, and it may be numerically
unstable. To circumvent these issues, automatic diﬀerentiation (AD) has been proposed
as another approach to calculate gradients numerically [12, 13], a paradigm also known

3

as diﬀerentiable programming (∂P) [14, 15]. By backpropagating the loss function’s
sensitivity through the numerical simulation, one can compute the gradients with similar
time complexity as solving the system’s dynamics [16]. Recently, these techniques have
been merged with deep neural networks (NNs) as ansatz for the controllers [10, 17, 18].
This is possible because the training of deep NNs is based on stochastic gradient descent
through a large parameter space and becomes eﬃcient when used in conjunction with
∂P-compatible solvers for the system’s dynamics.

In this work, we develop such a physics-informed reinforcement learning framework
based on ∂P and NNs to control the stochastic dynamics of a quantum system under
continuous monitoring [2, 19]. Continuous measurements, such as photon counting
and homodyne detection, allow one to gain information on the random evolution of a
dissipative quantum system [2]. This information can be used to estimate the state of
the quantum system [20, 21, 22], to implement feedback protocols [23, 24, 25, 26, 27],
to generate nonclassical states [28, 29, 30, 31], and to implement teleportation protocols
[32, 33]. Continuous homodyne detection can be realized experimentally in the
microwave [34, 35] and optical regime [20, 36]. The time evolution of a monitored
quantum system is described by quantum trajectories, which are solutions of diﬀerential
equations driven by a L´evy process.

To illustrate our framework, we focus on a qubit subjected to continuous homodyne
detection [34, 37] described by a stochastic Schr¨odinger equation. We engineer a
controller which provides a control scheme to fulﬁl a given state preparation task based
on the measured homodyne current. This situation extends an earlier study [10], where
it has been demonstrated that ∂P can be eﬃciently used for quantum control in the
context of (unitary) closed-system dynamics, i.e. when the dynamics follows an ordinary
diﬀerential equation. The stochastic nature of the problem analyzed here renders the
control task more challenging because the controller must adapt to the random evolution
of the quantum state in each trajectory. Moreover, the instantaneous value of the
It is correlated
homodyne current does not determine the actual state of the qubit.
only to the projection of the state onto the x-axis and this signal is hidden in the
noise which dominates the measured homodyne current [38, 39]. Thus, the information
about the state of the qubit at a given time must be ﬁltered out from the time series of
measurement results.

This paper is organized as follows: In Section 2, we describe the proposed setup
of a qubit in a leaky cavity subjected to homodyne detection and derive the stochastic
Schr¨odinger equation that describes its dynamics. We then discuss two ways to use the
record of the homodyne detection signal in a feedback scheme to engineer a drive that
can be applied to the qubit to perform a desired control task, e.g. state preparation
or stabilization. We also introduce the concept of adjoint sensitivity methods that
we use to eﬃciently compute gradients with respect to solutions of SDEs. Section 3
describes the ﬁrst feedback scheme in detail: Here, we assume that the controller has
through an appropriate ﬁltering procedure
direct access to the quantum state, e.g.
applied to the measurement records. We compare three strategies, viz. a hand-crafted

4

control scheme, one in which a neural network continuously updates the control drive
based on the knowledge of the state, and a numerically less demanding one with a
piecewise-constant control drive. Section 4 presents the second feedback scheme where
directly the measurement record of the homodyne current is fed to the NN representing
the controller. In this setup, the NN must ﬁrst learn how to ﬁlter the data to obtain
information on the state of the system. Only after that it can propose an eﬃcient control
strategy. We conclude in Section 5 and discuss potential future applications.

2. Theoretical background

2.1. A qubit under homodyne detection

(a) Sketch of the considered setup. A qubit coupled to a leaky cavity is
Figure 1:
continuously monitored by a homodyne detection measurement. The radiation emitted
by the qubit is mixed with a local oscillator laser with complex amplitude β at a
beamsplitter. The signal J(t), which is the diﬀerence of the photocurrents of the two
detectors, is fed into a control agent, which applies a drive Ω(t) to the qubit to generate
and stabilize a target state. (b) Diﬀerent structures of the controller considered in Secs. 3
and 4, respectively. (c) Example of a typical signal J(t) of the homodyne detection
measurement. (d) The homodyne detection signal is proportional to the quadrature
, which is hidden in the noise of the measurement [note the diﬀerent axis scaling in
σx
(cid:104)
(cid:105)
(c) and (d)]. The data has been integrated over a measurement interval δt = 10−3κ−1.
The parameters of the physical model are ∆ = 20κ, Ω = 2κ.

We consider a driven two-level system with states

g
|

(cid:105)

and

e
(cid:105)
|

. In a rotating frame,

-controlfiltercontrollercontrollerits Hamiltonian reads

H =

∆
2

σz +

Ω(t)
2

σx ,

5

(1)

where σx, σz are Pauli matrices, Ω(t) is the Rabi frequency of the drive laser, and
∆ = ωeg
ωlaser is the detuning between the qubit and the laser. The qubit can
spontaneously decay into a photon ﬁeld a(t) via the interaction Hamiltonian

−

Hint = i√κ

σ+a(t)

σ−a†(t)

,

−

(2)

(cid:104)

(cid:2)

a†(t)a(t(cid:48))
(cid:105)

(cid:3)
where κ is the decay rate. The ﬁeld operators a(t) and a†(t) satisfy the commutation
relation [a(t), a†(t(cid:48))] = δ(t
t(cid:48)). We assume that the ﬁeld is initially in the vacuum
state,
= 0. Physical examples of such a system are a two-level atom inside
a leaky single-mode cavity that can be adiabatically eliminated, or an artiﬁcial atom,
e.g. a superconducting qubit, coupled to a waveguide. The radiation emitted from the
two-level system is monitored with a continuous homodyne measurement, as depicted
in Fig. 1(a).

−

We show in Appendix A (see also [2, 19]) that the evolution of the qubit is governed

by a stochastic Schr¨odinger equation

d ˜
ψ
|

(cid:105)

= dt

iH

κ
2

−

σ+σ− + J(t)σ−

−

˜
ψ
|

(cid:105)

,

(3)

where ˜
ψ
|
homodyne current J(t) is a random variable satisfying

(cid:105)

denotes an unnormalized qubit state. The instantaneous value of the measured

(cid:110)

(cid:111)

σx
(cid:104)

σx
(cid:104)

J(t) = κ

(cid:105)ψ(t) + √κ ξ(t) .
(cid:105)ψ(t) is the expectation value of σx at time t, and ξ(t) is a stochastic white-
Here,
noise term satisfying E[ξ(t)ξ(t(cid:48))]
t(cid:48)), which stems from the shot noise of the local
oscillator. Heuristically, ξ(t) can be considered as the derivative of a stochastic Wiener
increment, ξ(t) = dW (t)/dt, such that the contribution of the noise to the current
integrated over a short time interval dt is described by a Wiener process,

(4)

δ(t

−

∝

J(t)dt = κ

σx
(cid:104)

(cid:105)ψ(t) dt + √κ dW (t) .

(5)

The ensemble averages of the stochastic Wiener increment dW satisfy E[dW (t)] = 0
and E[dW (t)2] = dt. Several remarks are in order to better understand the dynamics
of the system.

First, Eq. (5) implies that the value of the current over a short interval J(t)dt
of the qubit. This can be

contains only very little information about the state
seen from the (heuristically stated) vanishing signal-to-noise ratio

ψ(t)
(cid:105)
|

κ
(cid:105)ψ(t) dt
σx
(cid:104)
E[κ dW (t)2]

=

κ

σx
(cid:105)ψ(t) dt
(cid:104)
√κdt

=

σx
(cid:104)

(cid:105)ψ(t)

√κdt.

(6)

σx
(cid:104)

If
(cid:105)ψ(t) was a constant signal, one could simply integrate the current J(t) over a
time interval longer than 1/κ to increase the signal-to-noise ratio. However, this is not

(cid:112)

6

possible because relaxation will change the state of the two-level system on the time
scale 1/κ. Thus, the low signal-to-noise ratio is an intrinsic feature of this homodyne
detection scheme. This is illustrated in Figs. 1(c) and (d), where we show a simulation
of the homodyne current J(t) together with the respective value
(cid:105)ψ(t) for a single
quantum trajectory.

σx
(cid:104)

Second, Eq. (3) shows that the inﬁnitesimal time evolution and thus the quantum
trajectory is fully determined by the record of the measured homodyne current Jt and
the values of the applied drive Ωt, which are vectors containing the respective values of
J(t) and Ω(t) from the start time t0 = 0 until the time t. In Appendix A.4, we derive a
closed-form expression of the operator Dt = Dt[Jt, Ωt], which gives the mapping

ρt =

Dtρ0D†
t
tr[Dtρ0D†
t ]

,

(7)

between the states of the qubit at times t0 = 0 and t. The operator Dt[Jt, Ωt] can be
interpreted as a ﬁlter determining the state of the qubit at time t from the values of the
measured homodyne current and the applied drive.

Finally, Eq. (3) does not preserve the norm of the state

, as indicated by the tilde.
(cid:105)
This is no problem if one integrates Eq. (3) numerically, since one can renormalize the
state after each time step. For analytical calculations, it is useful to add some correction
terms (see Appendix A.5 or [2, 19]) such that the norm of the state is preserved up to
second order in dt,

ψ
|

(8)

(9)

(10)

Here, the nonlinear drift and diﬀusion terms are

ψ
d
|

(cid:105)

= Kψ(t)dt + Mψ(t)dW (t) .

Kψ(t) =

iH +

κ
2

−

(cid:18)

σx
(cid:104)

(cid:105)ψ(t) σ−

−

σ+σ−

1
4 (cid:104)

σx

2
ψ(t)
(cid:105)

−

,

ψ
|

(cid:105)

(cid:27)(cid:19)

Mψ(t) = √κ

σ−

(cid:26)
1
2 (cid:104)

−

σx

(cid:105)ψ(t)

.

ψ
|

(cid:105)

(cid:27)
Note that Eq. (8) is a stochastic Schr¨odinger equation in the Itˆo form with multiplicative
scalar noise.

(cid:26)

2.2. Feedback control overview

In our control protocol, the results of the homodyne detection measurement determine
the drive Ω(t) to be applied to the qubit. We will consider two diﬀerent schemes which
are sketched in Fig. 1(b).

In the ﬁrst scheme, discussed in Section 3, we ﬁlter the homodyne signal to extract
the system’s exact state
at time t. Subsequently, the controller receives this state
as an input and determines the drive Ω(t) to be applied next. Equations (7) and (A.33)
give an explicit ﬁltering procedure Dt[Jt, Ωt] to determine the state of the qubit at time
t from the records of homodyne measurements Jt and the drive Ωt, which are known

ψ(t)
|

(cid:105)

7

in the experiment. Since we train the agent on simulated trajectories, we know the
system’s state at each time step. Therefore, we can skip the ﬁlter in Fig. 1(b) and
directly feed back the solution of the SDE solver at each time step to our controller. In
other words we assume a perfect ﬁltering at any time. Thus, this situation corresponds
to the feedback used in Ref. [10] but the deterministic evolution is replaced by an SDE.
We will use this control scheme in Section 3 to test diﬀerent backpropagation methods
and to compare diﬀerent control strategies.

In the second scheme, discussed in Section 4, the controller obtains at time t the
τ, t]. Now, the NN
homodyne current record Jτ (t) measured over some time interval [t
forming the controller must simultaneously learn how to ﬁlter the signal from the noise
and to predict the next action Ω(t). Such an implementation of the control protocol
based only on J(t) is a challenging task because the signal of the system quadrature
σx
(cid:104)

(cid:105)ψ(t) is hidden in the noise as discussed in Section 2.1.

−

2.3. Workﬂow

ψ(t)
(cid:105)
|

Figure 2: Workﬂow of the learning scheme discussed in Section 2.3 to train the
controller. In the forward pass, a controller, which is in this work implemented by a
(see Section 3) or a measurement
neural network, maps the present quantum state
of the homodyne current J(t) (see Section 4) to a drive Ω(t). Then, an SDE is solved to
determine the subsequent state and homodyne detection current J(t). A loss function L
modeling the state preparation objective and possible constraints is evaluated based on
a quantum trajectory, i.e. a sequence of states. In the backward pass, the gradient of the
loss function with respect to the parameters θ of the controller is evaluated by (adjoint)
sensitivity methods (see Section 2.4). This step incorporates physical knowledge of the
system into the training process and is numerically more eﬃcient than a model-blind
gradient estimation. The gradient of the loss function with respect to the parameters
of the controller is used to update the control strategy in a series of training epochs.

The learning scheme to control the stochastic dynamics of the continuously

controllerSDE solverloss functionC<latexit sha1_base64="xzeBtCX6FK/UxeEYmc5IEBb6/xI=">AAADP3ichVFNb9QwEJ2kfHTD11KOXCJWK20PrBKEBMeKUsQBqiKxbaWmWjlZb9Zax4kcb6WS5sfxM+gf4Ia4InHg2U2RoKA6cmb85s2bsSetpKhNFH3x/LUbN2/dXu8Fd+7eu/+g/3Bjvy5XOuOTrJSlPkxZzaVQfGKEkfyw0pwVqeQH6XLbxg9OuK5FqT6a04ofFyxXYi4yZgBN+yYpmFlkTDbbbTA8S6pajMy0EU/jdjPRTOWSB8MmcYUazWdtolgqmcuaa7Zs3rXtPwlmwQ1DaDTbtHFdhLu77fQCnvYH0ThyK7zqxJ0zoG7tlf1zSmhGJWW0ooI4KTLwJTGq8R1RTBFVwI6pAabhCRfn1FKA3BVYHAwGdIl/jtNRhyqcrWbtsjNUkdgamSENsd84xRRsW5XDr2F/Yn9yWP7fCo1Tth2ewqZQ7DnF98ANLcC4LrPomJe9XJ9pb2VoTi/dbQT6qxxi75n91nmNiAa2dJGQdhwzh0bqzid4AQU7QQf2lS8VQnfjGSxzljsV1Sky6GlY+/roB2OO/x7qVWf/2TiOxvGH54OtV93A1+kxPaERpvqCtugt7aGPjM498npe4H/2v/rf/O8XVN/rch7RH8v/8QtAo7tQ</latexit><latexit sha1_base64="xzeBtCX6FK/UxeEYmc5IEBb6/xI=">AAADP3ichVFNb9QwEJ2kfHTD11KOXCJWK20PrBKEBMeKUsQBqiKxbaWmWjlZb9Zax4kcb6WS5sfxM+gf4Ia4InHg2U2RoKA6cmb85s2bsSetpKhNFH3x/LUbN2/dXu8Fd+7eu/+g/3Bjvy5XOuOTrJSlPkxZzaVQfGKEkfyw0pwVqeQH6XLbxg9OuK5FqT6a04ofFyxXYi4yZgBN+yYpmFlkTDbbbTA8S6pajMy0EU/jdjPRTOWSB8MmcYUazWdtolgqmcuaa7Zs3rXtPwlmwQ1DaDTbtHFdhLu77fQCnvYH0ThyK7zqxJ0zoG7tlf1zSmhGJWW0ooI4KTLwJTGq8R1RTBFVwI6pAabhCRfn1FKA3BVYHAwGdIl/jtNRhyqcrWbtsjNUkdgamSENsd84xRRsW5XDr2F/Yn9yWP7fCo1Tth2ewqZQ7DnF98ANLcC4LrPomJe9XJ9pb2VoTi/dbQT6qxxi75n91nmNiAa2dJGQdhwzh0bqzid4AQU7QQf2lS8VQnfjGSxzljsV1Sky6GlY+/roB2OO/x7qVWf/2TiOxvGH54OtV93A1+kxPaERpvqCtugt7aGPjM498npe4H/2v/rf/O8XVN/rch7RH8v/8QtAo7tQ</latexit><latexit sha1_base64="xzeBtCX6FK/UxeEYmc5IEBb6/xI=">AAADP3ichVFNb9QwEJ2kfHTD11KOXCJWK20PrBKEBMeKUsQBqiKxbaWmWjlZb9Zax4kcb6WS5sfxM+gf4Ia4InHg2U2RoKA6cmb85s2bsSetpKhNFH3x/LUbN2/dXu8Fd+7eu/+g/3Bjvy5XOuOTrJSlPkxZzaVQfGKEkfyw0pwVqeQH6XLbxg9OuK5FqT6a04ofFyxXYi4yZgBN+yYpmFlkTDbbbTA8S6pajMy0EU/jdjPRTOWSB8MmcYUazWdtolgqmcuaa7Zs3rXtPwlmwQ1DaDTbtHFdhLu77fQCnvYH0ThyK7zqxJ0zoG7tlf1zSmhGJWW0ooI4KTLwJTGq8R1RTBFVwI6pAabhCRfn1FKA3BVYHAwGdIl/jtNRhyqcrWbtsjNUkdgamSENsd84xRRsW5XDr2F/Yn9yWP7fCo1Tth2ewqZQ7DnF98ANLcC4LrPomJe9XJ9pb2VoTi/dbQT6qxxi75n91nmNiAa2dJGQdhwzh0bqzid4AQU7QQf2lS8VQnfjGSxzljsV1Sky6GlY+/roB2OO/x7qVWf/2TiOxvGH54OtV93A1+kxPaERpvqCtugt7aGPjM498npe4H/2v/rf/O8XVN/rch7RH8v/8QtAo7tQ</latexit><latexit sha1_base64="xzeBtCX6FK/UxeEYmc5IEBb6/xI=">AAADP3ichVFNb9QwEJ2kfHTD11KOXCJWK20PrBKEBMeKUsQBqiKxbaWmWjlZb9Zax4kcb6WS5sfxM+gf4Ia4InHg2U2RoKA6cmb85s2bsSetpKhNFH3x/LUbN2/dXu8Fd+7eu/+g/3Bjvy5XOuOTrJSlPkxZzaVQfGKEkfyw0pwVqeQH6XLbxg9OuK5FqT6a04ofFyxXYi4yZgBN+yYpmFlkTDbbbTA8S6pajMy0EU/jdjPRTOWSB8MmcYUazWdtolgqmcuaa7Zs3rXtPwlmwQ1DaDTbtHFdhLu77fQCnvYH0ThyK7zqxJ0zoG7tlf1zSmhGJWW0ooI4KTLwJTGq8R1RTBFVwI6pAabhCRfn1FKA3BVYHAwGdIl/jtNRhyqcrWbtsjNUkdgamSENsd84xRRsW5XDr2F/Yn9yWP7fCo1Tth2ewqZQ7DnF98ANLcC4LrPomJe9XJ9pb2VoTi/dbQT6qxxi75n91nmNiAa2dJGQdhwzh0bqzid4AQU7QQf2lS8VQnfjGSxzljsV1Sky6GlY+/roB2OO/x7qVWf/2TiOxvGH54OtV93A1+kxPaERpvqCtugt7aGPjM498npe4H/2v/rf/O8XVN/rch7RH8v/8QtAo7tQ</latexit>score-function estimator (model-blind)⇢@L@| (ti)i <latexit sha1_base64="KqHVAYDvEOl1IpgUDawwkZKwP10=">AAADTnichVJLb9QwEJ6kPLbLowtcQFwsVkhFQqukooJjBQVxAKlIbFuprlZO1sla6zzkeCstISf+YK/wD/oHegLBF5NWQIXqyJ7xNzPfzHgSlVpVNgi+ev7KlavXrvdW+zdu3rq9Nrhzd7cqFiaW47jQhdmPRCW1yuXYKqvlfmmkyCIt96L5q9a+dyRNpYr8o12W8jATaa4SFQsLaDL4wqcyQaxjqrOlkdOmNmnU1MFoc/MpC0ahO4OmX/M/nbiWiWW8ZjwxIq55KYxVQjOeCTsDNK/fNc05/JmXlVq3E/WEG5GnWjbcqHQGgoY1k8EQCdxiF5WwU4bUrZ1i8I04TamgmBaUkaScLHRNgip8BxRSQCWwQ6qBGWjK2SU11EfsAl4SHgLoHGeK20GH5ri3nJWLjpFFYxtEMnqM/cYxRvBus0roFeR37E8OS/+boXbMbYVLyAiMq47xPXBLM3hcFpl1nme1XB7ZdmUpoReuG4X6Soe0fcbnPNuwGGBzZ2H02nmm4Ijc/QgvkEOOUUH7ymcMzHU8hRROSseSd4wCfAayfX3UgzGH/w71orK7MQrx0314Ntx62Q28Rw/pEa1jqs9pi97SDuqI6cRb8+57D/xj/9T/4f/87ep7Xcw9+mut9H4BxjbBCw==</latexit><latexit sha1_base64="KqHVAYDvEOl1IpgUDawwkZKwP10=">AAADTnichVJLb9QwEJ6kPLbLowtcQFwsVkhFQqukooJjBQVxAKlIbFuprlZO1sla6zzkeCstISf+YK/wD/oHegLBF5NWQIXqyJ7xNzPfzHgSlVpVNgi+ev7KlavXrvdW+zdu3rq9Nrhzd7cqFiaW47jQhdmPRCW1yuXYKqvlfmmkyCIt96L5q9a+dyRNpYr8o12W8jATaa4SFQsLaDL4wqcyQaxjqrOlkdOmNmnU1MFoc/MpC0ahO4OmX/M/nbiWiWW8ZjwxIq55KYxVQjOeCTsDNK/fNc05/JmXlVq3E/WEG5GnWjbcqHQGgoY1k8EQCdxiF5WwU4bUrZ1i8I04TamgmBaUkaScLHRNgip8BxRSQCWwQ6qBGWjK2SU11EfsAl4SHgLoHGeK20GH5ri3nJWLjpFFYxtEMnqM/cYxRvBus0roFeR37E8OS/+boXbMbYVLyAiMq47xPXBLM3hcFpl1nme1XB7ZdmUpoReuG4X6Soe0fcbnPNuwGGBzZ2H02nmm4Ijc/QgvkEOOUUH7ymcMzHU8hRROSseSd4wCfAayfX3UgzGH/w71orK7MQrx0314Ntx62Q28Rw/pEa1jqs9pi97SDuqI6cRb8+57D/xj/9T/4f/87ep7Xcw9+mut9H4BxjbBCw==</latexit><latexit sha1_base64="KqHVAYDvEOl1IpgUDawwkZKwP10=">AAADTnichVJLb9QwEJ6kPLbLowtcQFwsVkhFQqukooJjBQVxAKlIbFuprlZO1sla6zzkeCstISf+YK/wD/oHegLBF5NWQIXqyJ7xNzPfzHgSlVpVNgi+ev7KlavXrvdW+zdu3rq9Nrhzd7cqFiaW47jQhdmPRCW1yuXYKqvlfmmkyCIt96L5q9a+dyRNpYr8o12W8jATaa4SFQsLaDL4wqcyQaxjqrOlkdOmNmnU1MFoc/MpC0ahO4OmX/M/nbiWiWW8ZjwxIq55KYxVQjOeCTsDNK/fNc05/JmXlVq3E/WEG5GnWjbcqHQGgoY1k8EQCdxiF5WwU4bUrZ1i8I04TamgmBaUkaScLHRNgip8BxRSQCWwQ6qBGWjK2SU11EfsAl4SHgLoHGeK20GH5ri3nJWLjpFFYxtEMnqM/cYxRvBus0roFeR37E8OS/+boXbMbYVLyAiMq47xPXBLM3hcFpl1nme1XB7ZdmUpoReuG4X6Soe0fcbnPNuwGGBzZ2H02nmm4Ijc/QgvkEOOUUH7ymcMzHU8hRROSseSd4wCfAayfX3UgzGH/w71orK7MQrx0314Ntx62Q28Rw/pEa1jqs9pi97SDuqI6cRb8+57D/xj/9T/4f/87ep7Xcw9+mut9H4BxjbBCw==</latexit><latexit sha1_base64="KqHVAYDvEOl1IpgUDawwkZKwP10=">AAADTnichVJLb9QwEJ6kPLbLowtcQFwsVkhFQqukooJjBQVxAKlIbFuprlZO1sla6zzkeCstISf+YK/wD/oHegLBF5NWQIXqyJ7xNzPfzHgSlVpVNgi+ev7KlavXrvdW+zdu3rq9Nrhzd7cqFiaW47jQhdmPRCW1yuXYKqvlfmmkyCIt96L5q9a+dyRNpYr8o12W8jATaa4SFQsLaDL4wqcyQaxjqrOlkdOmNmnU1MFoc/MpC0ahO4OmX/M/nbiWiWW8ZjwxIq55KYxVQjOeCTsDNK/fNc05/JmXlVq3E/WEG5GnWjbcqHQGgoY1k8EQCdxiF5WwU4bUrZ1i8I04TamgmBaUkaScLHRNgip8BxRSQCWwQ6qBGWjK2SU11EfsAl4SHgLoHGeK20GH5ri3nJWLjpFFYxtEMnqM/cYxRvBus0roFeR37E8OS/+boXbMbYVLyAiMq47xPXBLM3hcFpl1nme1XB7ZdmUpoReuG4X6Soe0fcbnPNuwGGBzZ2H02nmm4Ijc/QgvkEOOUUH7ymcMzHU8hRROSseSd4wCfAayfX3UgzGH/w71orK7MQrx0314Ntx62Q28Rw/pEa1jqs9pi97SDuqI6cRb8+57D/xj/9T/4f/87ep7Xcw9+mut9H4BxjbBCw==</latexit>{| (ti)i}<latexit sha1_base64="WbU9GjqgdP37tK5BGrrYgiY1vxY=">AAADrXichVJbb9MwFD5ZuGzlVuCRl4hq0pBQSRAVPE7ctAeQhkS3SfOonNRJrToXOe6gBP9QeOR38MAXkxW2Cs2RfY6/853P59iJKyVrE4bfvQ3/ytVr1ze3ejdu3rp9p3/33kFdLnQixkmpSn0U81ooWYixkUaJo0oLnsdKHMbzV2388FToWpbFR7OsxEnOs0KmMuEG0KT/k01Filyn1ORLLaa20Vlsm3A4Gj0OwmHk1tD2LjBjtRAraug47TKyvYad4zAlUhOwJvjGqlrumIl8xDQvMiWYltkMIRvY3vbfrLaGVRJLNU8aVnFtJFcBy7mZAZo376xdwWvK9h/pSX+A2twI1p2ocwbUjf2y/4MYTamkhBaUk6CCDHxFnGp8xxRRSBWwE2qAaXjSxQVZ6iF3AZYAgwOdY82wO+7QAvtWs3bZCU5RmBqZAW1jvnWKMdjtqQJ+DfsL86vDsv+e0DjltsIlbAzFLaf4HrihGRiXZeYd86yWyzPbrgyl9MJ1I1Ff5ZC2z2Sl8xoRDWzuIgG9ccwMGrHbn+IGCtgxKmhv+UwhcB1PYbmzwqkUnSKHnoZtbx/14Jmji4+67hw8HUb4pz88G+y+7B58kx7QQ9rBqz6nXdqjfdSReHte4X32vvhP/LHP/E9/qBtel3Ofzg0/+w1WBOIN</latexit><latexit sha1_base64="WbU9GjqgdP37tK5BGrrYgiY1vxY=">AAADrXichVJbb9MwFD5ZuGzlVuCRl4hq0pBQSRAVPE7ctAeQhkS3SfOonNRJrToXOe6gBP9QeOR38MAXkxW2Cs2RfY6/853P59iJKyVrE4bfvQ3/ytVr1ze3ejdu3rp9p3/33kFdLnQixkmpSn0U81ooWYixkUaJo0oLnsdKHMbzV2388FToWpbFR7OsxEnOs0KmMuEG0KT/k01Filyn1ORLLaa20Vlsm3A4Gj0OwmHk1tD2LjBjtRAraug47TKyvYad4zAlUhOwJvjGqlrumIl8xDQvMiWYltkMIRvY3vbfrLaGVRJLNU8aVnFtJFcBy7mZAZo376xdwWvK9h/pSX+A2twI1p2ocwbUjf2y/4MYTamkhBaUk6CCDHxFnGp8xxRRSBWwE2qAaXjSxQVZ6iF3AZYAgwOdY82wO+7QAvtWs3bZCU5RmBqZAW1jvnWKMdjtqQJ+DfsL86vDsv+e0DjltsIlbAzFLaf4HrihGRiXZeYd86yWyzPbrgyl9MJ1I1Ff5ZC2z2Sl8xoRDWzuIgG9ccwMGrHbn+IGCtgxKmhv+UwhcB1PYbmzwqkUnSKHnoZtbx/14Jmji4+67hw8HUb4pz88G+y+7B58kx7QQ9rBqz6nXdqjfdSReHte4X32vvhP/LHP/E9/qBtel3Ofzg0/+w1WBOIN</latexit><latexit sha1_base64="WbU9GjqgdP37tK5BGrrYgiY1vxY=">AAADrXichVJbb9MwFD5ZuGzlVuCRl4hq0pBQSRAVPE7ctAeQhkS3SfOonNRJrToXOe6gBP9QeOR38MAXkxW2Cs2RfY6/853P59iJKyVrE4bfvQ3/ytVr1ze3ejdu3rp9p3/33kFdLnQixkmpSn0U81ooWYixkUaJo0oLnsdKHMbzV2388FToWpbFR7OsxEnOs0KmMuEG0KT/k01Filyn1ORLLaa20Vlsm3A4Gj0OwmHk1tD2LjBjtRAraug47TKyvYad4zAlUhOwJvjGqlrumIl8xDQvMiWYltkMIRvY3vbfrLaGVRJLNU8aVnFtJFcBy7mZAZo376xdwWvK9h/pSX+A2twI1p2ocwbUjf2y/4MYTamkhBaUk6CCDHxFnGp8xxRRSBWwE2qAaXjSxQVZ6iF3AZYAgwOdY82wO+7QAvtWs3bZCU5RmBqZAW1jvnWKMdjtqQJ+DfsL86vDsv+e0DjltsIlbAzFLaf4HrihGRiXZeYd86yWyzPbrgyl9MJ1I1Ff5ZC2z2Sl8xoRDWzuIgG9ccwMGrHbn+IGCtgxKmhv+UwhcB1PYbmzwqkUnSKHnoZtbx/14Jmji4+67hw8HUb4pz88G+y+7B58kx7QQ9rBqz6nXdqjfdSReHte4X32vvhP/LHP/E9/qBtel3Ofzg0/+w1WBOIN</latexit><latexit sha1_base64="WbU9GjqgdP37tK5BGrrYgiY1vxY=">AAADrXichVJbb9MwFD5ZuGzlVuCRl4hq0pBQSRAVPE7ctAeQhkS3SfOonNRJrToXOe6gBP9QeOR38MAXkxW2Cs2RfY6/853P59iJKyVrE4bfvQ3/ytVr1ze3ejdu3rp9p3/33kFdLnQixkmpSn0U81ooWYixkUaJo0oLnsdKHMbzV2388FToWpbFR7OsxEnOs0KmMuEG0KT/k01Filyn1ORLLaa20Vlsm3A4Gj0OwmHk1tD2LjBjtRAraug47TKyvYad4zAlUhOwJvjGqlrumIl8xDQvMiWYltkMIRvY3vbfrLaGVRJLNU8aVnFtJFcBy7mZAZo376xdwWvK9h/pSX+A2twI1p2ocwbUjf2y/4MYTamkhBaUk6CCDHxFnGp8xxRRSBWwE2qAaXjSxQVZ6iF3AZYAgwOdY82wO+7QAvtWs3bZCU5RmBqZAW1jvnWKMdjtqQJ+DfsL86vDsv+e0DjltsIlbAzFLaf4HrihGRiXZeYd86yWyzPbrgyl9MJ1I1Ff5ZC2z2Sl8xoRDWzuIgG9ccwMGrHbn+IGCtgxKmhv+UwhcB1PYbmzwqkUnSKHnoZtbx/14Jmji4+67hw8HUb4pz88G+y+7B58kx7QQ9rBqz6nXdqjfdSReHte4X32vvhP/LHP/E9/qBtel3Ofzg0/+w1WBOIN</latexit>| (t0)i<latexit sha1_base64="d3ycXtzXzHTTTae1uLhuapwnqlo=">AAAD0nichVJNb9NAEB3XUFrzlcKRi0VUqUgocioieqzKhziAVKSmrdStorWzcVZZf2i9qZQaHxBXblzhh8Fv4cDz4kQkEepauzP75s3bmV2HuZKFCYKfzoZ76/bmna1t7+69+w8etnYenRbZVEeiH2Uq0+chL4SSqegbaZQ4z7XgSajEWTh5VcfProQuZJaemFkuLhMep3IkI24ADXacTTYUIyRbqTKZaTGsSh2HVRl0er3nftDp2jWovBVmqKZiQQ0sp156lVeyJc4nlhdyzwyCZ0zzNFbCr7zdFQ5TYmR8VvpzspyTmZbxGKFqOauuc5HERppHJcu5NpIrnyXcjAFNyvdVtYDXlKt/pAetNuq3w193uo3TpmYcZ61fxGhIGUU0pYQEpWTgK+JU4LugLgWUA7ukEpiGJ21cUEUecqdgCTA40AnWGLuLBk2xrzULmx3hFIWpkenTLuZbqxiCXZ8q4BewvzGvLRb/94TSKtcVzmBDKG5bxQ/ADY3BuCkzaZjzWm7OrLsyNKID241EfblF6j6jhc5rRDSwiY349MYyY2iEdn+FG0hh+6igvuW5gm87HsJya4VVSRtFDj0NW98+6sEzd1cfdd053e908d9/fNE+PGoefIue0FPaw6u+pEN6R8eoI3IS55vz3fnhnrjX7mf3y1/qhtPkPKal4X79A8Rh8BU=</latexit><latexit sha1_base64="d3ycXtzXzHTTTae1uLhuapwnqlo=">AAAD0nichVJNb9NAEB3XUFrzlcKRi0VUqUgocioieqzKhziAVKSmrdStorWzcVZZf2i9qZQaHxBXblzhh8Fv4cDz4kQkEepauzP75s3bmV2HuZKFCYKfzoZ76/bmna1t7+69+w8etnYenRbZVEeiH2Uq0+chL4SSqegbaZQ4z7XgSajEWTh5VcfProQuZJaemFkuLhMep3IkI24ADXacTTYUIyRbqTKZaTGsSh2HVRl0er3nftDp2jWovBVmqKZiQQ0sp156lVeyJc4nlhdyzwyCZ0zzNFbCr7zdFQ5TYmR8VvpzspyTmZbxGKFqOauuc5HERppHJcu5NpIrnyXcjAFNyvdVtYDXlKt/pAetNuq3w193uo3TpmYcZ61fxGhIGUU0pYQEpWTgK+JU4LugLgWUA7ukEpiGJ21cUEUecqdgCTA40AnWGLuLBk2xrzULmx3hFIWpkenTLuZbqxiCXZ8q4BewvzGvLRb/94TSKtcVzmBDKG5bxQ/ADY3BuCkzaZjzWm7OrLsyNKID241EfblF6j6jhc5rRDSwiY349MYyY2iEdn+FG0hh+6igvuW5gm87HsJya4VVSRtFDj0NW98+6sEzd1cfdd053e908d9/fNE+PGoefIue0FPaw6u+pEN6R8eoI3IS55vz3fnhnrjX7mf3y1/qhtPkPKal4X79A8Rh8BU=</latexit><latexit sha1_base64="d3ycXtzXzHTTTae1uLhuapwnqlo=">AAAD0nichVJNb9NAEB3XUFrzlcKRi0VUqUgocioieqzKhziAVKSmrdStorWzcVZZf2i9qZQaHxBXblzhh8Fv4cDz4kQkEepauzP75s3bmV2HuZKFCYKfzoZ76/bmna1t7+69+w8etnYenRbZVEeiH2Uq0+chL4SSqegbaZQ4z7XgSajEWTh5VcfProQuZJaemFkuLhMep3IkI24ADXacTTYUIyRbqTKZaTGsSh2HVRl0er3nftDp2jWovBVmqKZiQQ0sp156lVeyJc4nlhdyzwyCZ0zzNFbCr7zdFQ5TYmR8VvpzspyTmZbxGKFqOauuc5HERppHJcu5NpIrnyXcjAFNyvdVtYDXlKt/pAetNuq3w193uo3TpmYcZ61fxGhIGUU0pYQEpWTgK+JU4LugLgWUA7ukEpiGJ21cUEUecqdgCTA40AnWGLuLBk2xrzULmx3hFIWpkenTLuZbqxiCXZ8q4BewvzGvLRb/94TSKtcVzmBDKG5bxQ/ADY3BuCkzaZjzWm7OrLsyNKID241EfblF6j6jhc5rRDSwiY349MYyY2iEdn+FG0hh+6igvuW5gm87HsJya4VVSRtFDj0NW98+6sEzd1cfdd053e908d9/fNE+PGoefIue0FPaw6u+pEN6R8eoI3IS55vz3fnhnrjX7mf3y1/qhtPkPKal4X79A8Rh8BU=</latexit><latexit sha1_base64="d3ycXtzXzHTTTae1uLhuapwnqlo=">AAAD0nichVJNb9NAEB3XUFrzlcKRi0VUqUgocioieqzKhziAVKSmrdStorWzcVZZf2i9qZQaHxBXblzhh8Fv4cDz4kQkEepauzP75s3bmV2HuZKFCYKfzoZ76/bmna1t7+69+w8etnYenRbZVEeiH2Uq0+chL4SSqegbaZQ4z7XgSajEWTh5VcfProQuZJaemFkuLhMep3IkI24ADXacTTYUIyRbqTKZaTGsSh2HVRl0er3nftDp2jWovBVmqKZiQQ0sp156lVeyJc4nlhdyzwyCZ0zzNFbCr7zdFQ5TYmR8VvpzspyTmZbxGKFqOauuc5HERppHJcu5NpIrnyXcjAFNyvdVtYDXlKt/pAetNuq3w193uo3TpmYcZ61fxGhIGUU0pYQEpWTgK+JU4LugLgWUA7ukEpiGJ21cUEUecqdgCTA40AnWGLuLBk2xrzULmx3hFIWpkenTLuZbqxiCXZ8q4BewvzGvLRb/94TSKtcVzmBDKG5bxQ/ADY3BuCkzaZjzWm7OrLsyNKID241EfblF6j6jhc5rRDSwiY349MYyY2iEdn+FG0hh+6igvuW5gm87HsJya4VVSRtFDj0NW98+6sEzd1cfdd053e908d9/fNE+PGoefIue0FPaw6u+pEN6R8eoI3IS55vz3fnhnrjX7mf3y1/qhtPkPKal4X79A8Rh8BU=</latexit>¯L<latexit sha1_base64="wPTsA2YtqwATMeGdu1rKdyXOaZw=">AAAEHHichVNbaxNBFD7b9dLGW6qPviyGQgoSNsWgj8UbPihEMG2hU8LsZrIZMnthdlKI6/4V/4Z/wDfxVVDwVf+ED347bmLaKJ1l5pz5zne+OTOHDTIlc+P7X50N99LlK1c3txrXrt+4eau5ffsgT2c6FIMwVak+CngulEzEwEijxFGmBY8DJQ6D6ZMqfngqdC7T5I2ZZ+Ik5lEixzLkBtBw2+mzkRgj2UoV8VyLUVnoKCgLv9Pr3ff8Tteuftk4xwzUTCypvuVUS69sFGxVjQVcFyzmZjLWfFq8LMuysfOXYmVWw21mJsLwXW+d9o5luWybob/LNE8iJf7BYUqMjccKb0GWCzLTMpogVJ7NsjUukhiKCAuWcW0kV96ZspfwmnK5Ij1stvASdnjrTrd2WlSPftr8RoxGlFJIM4pJUEIGviJOOb5j6pJPGbATKoBpeNLGBZXUQO4MLAEGBzrFGmF3XKMJ9pVmbrNDnKIwNTI92sF8bhUDsKtTBfwc9hfmW4tF/z2hsMpVhXPYAIpbVvEVcEMTMC7KjGvmopaLM6tbGRrTI3sbifoyi1T3DJc6TxHRwKY24tEzy4ygEdj9KV4ggR2gguqVFwqevfEIllsrrEpSK3Loadjq9VEP2tw939R152Cv08Uf9PpBa/9x3fBNukv3qI2uPqR9ekF91BE6H5zvzg/np/ve/eh+cj//oW44dc4dOjPcL78B30gQMw==</latexit><latexit sha1_base64="wPTsA2YtqwATMeGdu1rKdyXOaZw=">AAAEHHichVNbaxNBFD7b9dLGW6qPviyGQgoSNsWgj8UbPihEMG2hU8LsZrIZMnthdlKI6/4V/4Z/wDfxVVDwVf+ED347bmLaKJ1l5pz5zne+OTOHDTIlc+P7X50N99LlK1c3txrXrt+4eau5ffsgT2c6FIMwVak+CngulEzEwEijxFGmBY8DJQ6D6ZMqfngqdC7T5I2ZZ+Ik5lEixzLkBtBw2+mzkRgj2UoV8VyLUVnoKCgLv9Pr3ff8Tteuftk4xwzUTCypvuVUS69sFGxVjQVcFyzmZjLWfFq8LMuysfOXYmVWw21mJsLwXW+d9o5luWybob/LNE8iJf7BYUqMjccKb0GWCzLTMpogVJ7NsjUukhiKCAuWcW0kV96ZspfwmnK5Ij1stvASdnjrTrd2WlSPftr8RoxGlFJIM4pJUEIGviJOOb5j6pJPGbATKoBpeNLGBZXUQO4MLAEGBzrFGmF3XKMJ9pVmbrNDnKIwNTI92sF8bhUDsKtTBfwc9hfmW4tF/z2hsMpVhXPYAIpbVvEVcEMTMC7KjGvmopaLM6tbGRrTI3sbifoyi1T3DJc6TxHRwKY24tEzy4ygEdj9KV4ggR2gguqVFwqevfEIllsrrEpSK3Loadjq9VEP2tw939R152Cv08Uf9PpBa/9x3fBNukv3qI2uPqR9ekF91BE6H5zvzg/np/ve/eh+cj//oW44dc4dOjPcL78B30gQMw==</latexit><latexit sha1_base64="wPTsA2YtqwATMeGdu1rKdyXOaZw=">AAAEHHichVNbaxNBFD7b9dLGW6qPviyGQgoSNsWgj8UbPihEMG2hU8LsZrIZMnthdlKI6/4V/4Z/wDfxVVDwVf+ED347bmLaKJ1l5pz5zne+OTOHDTIlc+P7X50N99LlK1c3txrXrt+4eau5ffsgT2c6FIMwVak+CngulEzEwEijxFGmBY8DJQ6D6ZMqfngqdC7T5I2ZZ+Ik5lEixzLkBtBw2+mzkRgj2UoV8VyLUVnoKCgLv9Pr3ff8Tteuftk4xwzUTCypvuVUS69sFGxVjQVcFyzmZjLWfFq8LMuysfOXYmVWw21mJsLwXW+d9o5luWybob/LNE8iJf7BYUqMjccKb0GWCzLTMpogVJ7NsjUukhiKCAuWcW0kV96ZspfwmnK5Ij1stvASdnjrTrd2WlSPftr8RoxGlFJIM4pJUEIGviJOOb5j6pJPGbATKoBpeNLGBZXUQO4MLAEGBzrFGmF3XKMJ9pVmbrNDnKIwNTI92sF8bhUDsKtTBfwc9hfmW4tF/z2hsMpVhXPYAIpbVvEVcEMTMC7KjGvmopaLM6tbGRrTI3sbifoyi1T3DJc6TxHRwKY24tEzy4ygEdj9KV4ggR2gguqVFwqevfEIllsrrEpSK3Loadjq9VEP2tw939R152Cv08Uf9PpBa/9x3fBNukv3qI2uPqR9ekF91BE6H5zvzg/np/ve/eh+cj//oW44dc4dOjPcL78B30gQMw==</latexit><latexit sha1_base64="wPTsA2YtqwATMeGdu1rKdyXOaZw=">AAAEHHichVNbaxNBFD7b9dLGW6qPviyGQgoSNsWgj8UbPihEMG2hU8LsZrIZMnthdlKI6/4V/4Z/wDfxVVDwVf+ED347bmLaKJ1l5pz5zne+OTOHDTIlc+P7X50N99LlK1c3txrXrt+4eau5ffsgT2c6FIMwVak+CngulEzEwEijxFGmBY8DJQ6D6ZMqfngqdC7T5I2ZZ+Ik5lEixzLkBtBw2+mzkRgj2UoV8VyLUVnoKCgLv9Pr3ff8Tteuftk4xwzUTCypvuVUS69sFGxVjQVcFyzmZjLWfFq8LMuysfOXYmVWw21mJsLwXW+d9o5luWybob/LNE8iJf7BYUqMjccKb0GWCzLTMpogVJ7NsjUukhiKCAuWcW0kV96ZspfwmnK5Ij1stvASdnjrTrd2WlSPftr8RoxGlFJIM4pJUEIGviJOOb5j6pJPGbATKoBpeNLGBZXUQO4MLAEGBzrFGmF3XKMJ9pVmbrNDnKIwNTI92sF8bhUDsKtTBfwc9hfmW4tF/z2hsMpVhXPYAIpbVvEVcEMTMC7KjGvmopaLM6tbGRrTI3sbifoyi1T3DJc6TxHRwKY24tEzy4ygEdj9KV4ggR2gguqVFwqevfEIllsrrEpSK3Loadjq9VEP2tw939R152Cv08Uf9PpBa/9x3fBNukv3qI2uPqR9ekF91BE6H5zvzg/np/ve/eh+cj//oW44dc4dOjPcL78B30gQMw==</latexit>⌦(t)<latexit sha1_base64="L6NL/JO9HFwnRKt/Oaf/WKLrhx0=">AAAEMHichVPLbtNAFL2uebThlcKSjUVUKZFQ5SAiWFa8xAJEkUhbqVNFY2fijDJ+aDypFIx/it/gB4ANYsuOLbDgeOpESQPqWDP3zrnnnrkzVw4yJXPj+1+cDffS5StXN7ca167fuHmruX37IE+nOhT9MFWpPgp4LpRMRN9Io8RRpgWPAyUOg8nTKn54KnQu0+SdmWXiJOZRIkcy5AbQYNsZsqEYIdlKFfFMi2FZ6CgoC3+317vv+btdu/pl4xwzUFOxoPqWUy29srFTsGU5lvBA8QEzY2F4wWJuxiPNJ8WrslzhWsHlcPsspeOt0z6wLJdtM/A7TPMkUuIfHKbEyHis8OZkOSczLaMxQqW3Xuw8iaGIsGAZ10Zy5a2UvYDXlMtlafYmFhFvm86g2cLr2OGtO93aaVE99tPmV2I0pJRCmlJMghIy8BVxyvEdU5d8yoCdUAFMw5M2LqikBnKnYAkwONAJ1gi74xpNsK80c5sd4hSFqZHp0Q7mC6sYgF2dKuDnsH8w31ss+u8JhVWuKpzBBlDcsoqvgRsag3FRZlwz57VcnFndytCIHtvbSNSXWaS6Z7jQeYaIBjaxEY+eW2YEjcDuT/ECCWwfFVSvPFfw7I2HsNxaYVWSWpFDT8NWr4960Obu+aauOwcPdrv4q94+bO09qRu+SXfpHrXR1Ue0Ry9pH3WEzifnp/PL+e1+dD+739zvZ9QNp865QyvD/fEXVT4Xzg==</latexit><latexit sha1_base64="L6NL/JO9HFwnRKt/Oaf/WKLrhx0=">AAAEMHichVPLbtNAFL2uebThlcKSjUVUKZFQ5SAiWFa8xAJEkUhbqVNFY2fijDJ+aDypFIx/it/gB4ANYsuOLbDgeOpESQPqWDP3zrnnnrkzVw4yJXPj+1+cDffS5StXN7ca167fuHmruX37IE+nOhT9MFWpPgp4LpRMRN9Io8RRpgWPAyUOg8nTKn54KnQu0+SdmWXiJOZRIkcy5AbQYNsZsqEYIdlKFfFMi2FZ6CgoC3+317vv+btdu/pl4xwzUFOxoPqWUy29srFTsGU5lvBA8QEzY2F4wWJuxiPNJ8WrslzhWsHlcPsspeOt0z6wLJdtM/A7TPMkUuIfHKbEyHis8OZkOSczLaMxQqW3Xuw8iaGIsGAZ10Zy5a2UvYDXlMtlafYmFhFvm86g2cLr2OGtO93aaVE99tPmV2I0pJRCmlJMghIy8BVxyvEdU5d8yoCdUAFMw5M2LqikBnKnYAkwONAJ1gi74xpNsK80c5sd4hSFqZHp0Q7mC6sYgF2dKuDnsH8w31ss+u8JhVWuKpzBBlDcsoqvgRsag3FRZlwz57VcnFndytCIHtvbSNSXWaS6Z7jQeYaIBjaxEY+eW2YEjcDuT/ECCWwfFVSvPFfw7I2HsNxaYVWSWpFDT8NWr4960Obu+aauOwcPdrv4q94+bO09qRu+SXfpHrXR1Ue0Ry9pH3WEzifnp/PL+e1+dD+739zvZ9QNp865QyvD/fEXVT4Xzg==</latexit><latexit sha1_base64="L6NL/JO9HFwnRKt/Oaf/WKLrhx0=">AAAEMHichVPLbtNAFL2uebThlcKSjUVUKZFQ5SAiWFa8xAJEkUhbqVNFY2fijDJ+aDypFIx/it/gB4ANYsuOLbDgeOpESQPqWDP3zrnnnrkzVw4yJXPj+1+cDffS5StXN7ca167fuHmruX37IE+nOhT9MFWpPgp4LpRMRN9Io8RRpgWPAyUOg8nTKn54KnQu0+SdmWXiJOZRIkcy5AbQYNsZsqEYIdlKFfFMi2FZ6CgoC3+317vv+btdu/pl4xwzUFOxoPqWUy29srFTsGU5lvBA8QEzY2F4wWJuxiPNJ8WrslzhWsHlcPsspeOt0z6wLJdtM/A7TPMkUuIfHKbEyHis8OZkOSczLaMxQqW3Xuw8iaGIsGAZ10Zy5a2UvYDXlMtlafYmFhFvm86g2cLr2OGtO93aaVE99tPmV2I0pJRCmlJMghIy8BVxyvEdU5d8yoCdUAFMw5M2LqikBnKnYAkwONAJ1gi74xpNsK80c5sd4hSFqZHp0Q7mC6sYgF2dKuDnsH8w31ss+u8JhVWuKpzBBlDcsoqvgRsag3FRZlwz57VcnFndytCIHtvbSNSXWaS6Z7jQeYaIBjaxEY+eW2YEjcDuT/ECCWwfFVSvPFfw7I2HsNxaYVWSWpFDT8NWr4960Obu+aauOwcPdrv4q94+bO09qRu+SXfpHrXR1Ue0Ry9pH3WEzifnp/PL+e1+dD+739zvZ9QNp865QyvD/fEXVT4Xzg==</latexit><latexit sha1_base64="L6NL/JO9HFwnRKt/Oaf/WKLrhx0=">AAAEMHichVPLbtNAFL2uebThlcKSjUVUKZFQ5SAiWFa8xAJEkUhbqVNFY2fijDJ+aDypFIx/it/gB4ANYsuOLbDgeOpESQPqWDP3zrnnnrkzVw4yJXPj+1+cDffS5StXN7ca167fuHmruX37IE+nOhT9MFWpPgp4LpRMRN9Io8RRpgWPAyUOg8nTKn54KnQu0+SdmWXiJOZRIkcy5AbQYNsZsqEYIdlKFfFMi2FZ6CgoC3+317vv+btdu/pl4xwzUFOxoPqWUy29srFTsGU5lvBA8QEzY2F4wWJuxiPNJ8WrslzhWsHlcPsspeOt0z6wLJdtM/A7TPMkUuIfHKbEyHis8OZkOSczLaMxQqW3Xuw8iaGIsGAZ10Zy5a2UvYDXlMtlafYmFhFvm86g2cLr2OGtO93aaVE99tPmV2I0pJRCmlJMghIy8BVxyvEdU5d8yoCdUAFMw5M2LqikBnKnYAkwONAJ1gi74xpNsK80c5sd4hSFqZHp0Q7mC6sYgF2dKuDnsH8w31ss+u8JhVWuKpzBBlDcsoqvgRsag3FRZlwz57VcnFndytCIHtvbSNSXWaS6Z7jQeYaIBjaxEY+eW2YEjcDuT/ECCWwfFVSvPFfw7I2HsNxaYVWSWpFDT8NWr4960Obu+aauOwcPdrv4q94+bO09qRu+SXfpHrXR1Ue0Ry9pH3WEzifnp/PL+e1+dD+739zvZ9QNp865QyvD/fEXVT4Xzg==</latexit>| (t)i,J(t)<latexit sha1_base64="Q4cdODXp4qg0v7UqtRhWwWkrktA=">AAAEPHichVNbaxNBFD7Jai/xluqjL4uhkEIJm2LQx+INEYUKpi10SpjdTDZDZi/MTgpx3b/m3xB99k189UnBb6ebkDRKZ5k5Z77znW/OzGH9VMnMeN7XWt25cXNjc2u7cev2nbv3mjv3j7NkqgPRDxKV6FOfZ0LJWPSNNEqcplrwyFfixJ88L+MnF0JnMok/mFkqziMexnIkA24ADXZqKRuKEZKtVB7NtBgWuQ79Ivc6vd6+63W6dvWKxhWmr6ZiQfUsp1x6RWM3Z8tyLOa+4gNmxsLwnEXcjEeaT/K3RbHCtYLL4fZlyp67TvvE0ky2zcDbY5rHoRL/4DAlRsZluTsnyzmZaRmOESrc9WLnSQxFBDlLuTaSK3el7AW8plwsS1fReWzffYPNoNnCS9nhrjvdymlRNY6S5jdiNKSEAppSRIJiMvAVccrwnVGXPEqBnVMOTMOTNi6ooAZyp2AJMDjQCdYQu7MKjbEvNTObHeAUhamR6dIu5iur6INdnirgZ7C/MT9aLPzvCblVLiucwfpQ3LaK74AbGoNxXWZUMee1XJ9Z3srQiJ7a20jUl1qkvGew0HmBiAY2sRGXXlpmCA3f7i/wAjFsHxWUrzxXcO2Nh7DcWmFV4kqRQ0/Dlq+PetDm7tWmrjvHB50u/rD3j1uHz6qGb9FDekRtdPUJHdJrOkIdQe1L7U99o77pfHa+Oz+cn5fUeq3KeUArw/n1F/PoGlc=</latexit><latexit sha1_base64="Q4cdODXp4qg0v7UqtRhWwWkrktA=">AAAEPHichVNbaxNBFD7Jai/xluqjL4uhkEIJm2LQx+INEYUKpi10SpjdTDZDZi/MTgpx3b/m3xB99k189UnBb6ebkDRKZ5k5Z77znW/OzGH9VMnMeN7XWt25cXNjc2u7cev2nbv3mjv3j7NkqgPRDxKV6FOfZ0LJWPSNNEqcplrwyFfixJ88L+MnF0JnMok/mFkqziMexnIkA24ADXZqKRuKEZKtVB7NtBgWuQ79Ivc6vd6+63W6dvWKxhWmr6ZiQfUsp1x6RWM3Z8tyLOa+4gNmxsLwnEXcjEeaT/K3RbHCtYLL4fZlyp67TvvE0ky2zcDbY5rHoRL/4DAlRsZluTsnyzmZaRmOESrc9WLnSQxFBDlLuTaSK3el7AW8plwsS1fReWzffYPNoNnCS9nhrjvdymlRNY6S5jdiNKSEAppSRIJiMvAVccrwnVGXPEqBnVMOTMOTNi6ooAZyp2AJMDjQCdYQu7MKjbEvNTObHeAUhamR6dIu5iur6INdnirgZ7C/MT9aLPzvCblVLiucwfpQ3LaK74AbGoNxXWZUMee1XJ9Z3srQiJ7a20jUl1qkvGew0HmBiAY2sRGXXlpmCA3f7i/wAjFsHxWUrzxXcO2Nh7DcWmFV4kqRQ0/Dlq+PetDm7tWmrjvHB50u/rD3j1uHz6qGb9FDekRtdPUJHdJrOkIdQe1L7U99o77pfHa+Oz+cn5fUeq3KeUArw/n1F/PoGlc=</latexit><latexit sha1_base64="Q4cdODXp4qg0v7UqtRhWwWkrktA=">AAAEPHichVNbaxNBFD7Jai/xluqjL4uhkEIJm2LQx+INEYUKpi10SpjdTDZDZi/MTgpx3b/m3xB99k189UnBb6ebkDRKZ5k5Z77znW/OzGH9VMnMeN7XWt25cXNjc2u7cev2nbv3mjv3j7NkqgPRDxKV6FOfZ0LJWPSNNEqcplrwyFfixJ88L+MnF0JnMok/mFkqziMexnIkA24ADXZqKRuKEZKtVB7NtBgWuQ79Ivc6vd6+63W6dvWKxhWmr6ZiQfUsp1x6RWM3Z8tyLOa+4gNmxsLwnEXcjEeaT/K3RbHCtYLL4fZlyp67TvvE0ky2zcDbY5rHoRL/4DAlRsZluTsnyzmZaRmOESrc9WLnSQxFBDlLuTaSK3el7AW8plwsS1fReWzffYPNoNnCS9nhrjvdymlRNY6S5jdiNKSEAppSRIJiMvAVccrwnVGXPEqBnVMOTMOTNi6ooAZyp2AJMDjQCdYQu7MKjbEvNTObHeAUhamR6dIu5iur6INdnirgZ7C/MT9aLPzvCblVLiucwfpQ3LaK74AbGoNxXWZUMee1XJ9Z3srQiJ7a20jUl1qkvGew0HmBiAY2sRGXXlpmCA3f7i/wAjFsHxWUrzxXcO2Nh7DcWmFV4kqRQ0/Dlq+PetDm7tWmrjvHB50u/rD3j1uHz6qGb9FDekRtdPUJHdJrOkIdQe1L7U99o77pfHa+Oz+cn5fUeq3KeUArw/n1F/PoGlc=</latexit><latexit sha1_base64="Q4cdODXp4qg0v7UqtRhWwWkrktA=">AAAEPHichVNbaxNBFD7Jai/xluqjL4uhkEIJm2LQx+INEYUKpi10SpjdTDZDZi/MTgpx3b/m3xB99k189UnBb6ebkDRKZ5k5Z77znW/OzGH9VMnMeN7XWt25cXNjc2u7cev2nbv3mjv3j7NkqgPRDxKV6FOfZ0LJWPSNNEqcplrwyFfixJ88L+MnF0JnMok/mFkqziMexnIkA24ADXZqKRuKEZKtVB7NtBgWuQ79Ivc6vd6+63W6dvWKxhWmr6ZiQfUsp1x6RWM3Z8tyLOa+4gNmxsLwnEXcjEeaT/K3RbHCtYLL4fZlyp67TvvE0ky2zcDbY5rHoRL/4DAlRsZluTsnyzmZaRmOESrc9WLnSQxFBDlLuTaSK3el7AW8plwsS1fReWzffYPNoNnCS9nhrjvdymlRNY6S5jdiNKSEAppSRIJiMvAVccrwnVGXPEqBnVMOTMOTNi6ooAZyp2AJMDjQCdYQu7MKjbEvNTObHeAUhamR6dIu5iur6INdnirgZ7C/MT9aLPzvCblVLiucwfpQ3LaK74AbGoNxXWZUMee1XJ9Z3srQiJ7a20jUl1qkvGew0HmBiAY2sRGXXlpmCA3f7i/wAjFsHxWUrzxXcO2Nh7DcWmFV4kqRQ0/Dlq+PetDm7tWmrjvHB50u/rD3j1uHz6qGb9FDekRtdPUJHdJrOkIdQe1L7U99o77pfHa+Oz+cn5fUeq3KeUArw/n1F/PoGlc=</latexit>@L@⌦(t)<latexit sha1_base64="oSpnAEgzgYVyEh8xfFAE6ioFLvI=">AAAEfnicjVNdb9MwFL0NAbby1cET4sWiGuqk0aWIir0x8aWBQAyJbpPmqXJSN42aLznupBLyp/g38Ft44MRLqnUFDUf2vb73nHOvbcVNwyDTjvOzYV2zr9+4ubbevHX7zt17rY37h1kyU54ceEmYqGNXZDIMYjnQgQ7lcaqkiNxQHrnT12X+6EyqLEjir3qeytNI+HEwDjyhERpuNH7wkRyDbKTyaK7kqMiV7xa50+33t5nT7ZnVKZqXkG44kwuoYzDl0i+amzm/KMdj4YZiyPVEapHzSOjJWIlp/rEolrBG8GK6c07ZYquw7zzNgo4eOltcidgP5V8wPJRjzXjOanBQg7kK/AlSBVtttiZxNOHlPBVKByJkS20vwivKxZJ0la6T2+wDNs3lgv9XiPHPkfQF6EUxbLVx12awVadXOW2qxkHS+kWcRpSQRzOKSFJMGn5IgjJ8J9Qjh1LETilHTMELTF5SQU1wZ0BJIASiU6w+didVNMa+1MwM20OVEFOByWgT851RdIEuq0r4GexvzG8m5v+zQm6Uyw7nsC4U143iJ8Q1TYC4ihlVyLqXq5nlqTSNadecJkB/qYmU5/QWOm+QUYhNTYbRW4P0oeGa/RluIIYdoIPylmsFZk48ghXGSqMSV4oCegq2vH30g2fuXX7UVefwWbeHf/TL8/beq+rB1+gRPaYOXvUF7dE+HaAPz3povbT2rfc22U/sp/bOOdRqVJwHtDTs3T85Oi9/</latexit><latexit sha1_base64="oSpnAEgzgYVyEh8xfFAE6ioFLvI=">AAAEfnicjVNdb9MwFL0NAbby1cET4sWiGuqk0aWIir0x8aWBQAyJbpPmqXJSN42aLznupBLyp/g38Ft44MRLqnUFDUf2vb73nHOvbcVNwyDTjvOzYV2zr9+4ubbevHX7zt17rY37h1kyU54ceEmYqGNXZDIMYjnQgQ7lcaqkiNxQHrnT12X+6EyqLEjir3qeytNI+HEwDjyhERpuNH7wkRyDbKTyaK7kqMiV7xa50+33t5nT7ZnVKZqXkG44kwuoYzDl0i+amzm/KMdj4YZiyPVEapHzSOjJWIlp/rEolrBG8GK6c07ZYquw7zzNgo4eOltcidgP5V8wPJRjzXjOanBQg7kK/AlSBVtttiZxNOHlPBVKByJkS20vwivKxZJ0la6T2+wDNs3lgv9XiPHPkfQF6EUxbLVx12awVadXOW2qxkHS+kWcRpSQRzOKSFJMGn5IgjJ8J9Qjh1LETilHTMELTF5SQU1wZ0BJIASiU6w+didVNMa+1MwM20OVEFOByWgT851RdIEuq0r4GexvzG8m5v+zQm6Uyw7nsC4U143iJ8Q1TYC4ihlVyLqXq5nlqTSNadecJkB/qYmU5/QWOm+QUYhNTYbRW4P0oeGa/RluIIYdoIPylmsFZk48ghXGSqMSV4oCegq2vH30g2fuXX7UVefwWbeHf/TL8/beq+rB1+gRPaYOXvUF7dE+HaAPz3povbT2rfc22U/sp/bOOdRqVJwHtDTs3T85Oi9/</latexit><latexit sha1_base64="oSpnAEgzgYVyEh8xfFAE6ioFLvI=">AAAEfnicjVNdb9MwFL0NAbby1cET4sWiGuqk0aWIir0x8aWBQAyJbpPmqXJSN42aLznupBLyp/g38Ft44MRLqnUFDUf2vb73nHOvbcVNwyDTjvOzYV2zr9+4ubbevHX7zt17rY37h1kyU54ceEmYqGNXZDIMYjnQgQ7lcaqkiNxQHrnT12X+6EyqLEjir3qeytNI+HEwDjyhERpuNH7wkRyDbKTyaK7kqMiV7xa50+33t5nT7ZnVKZqXkG44kwuoYzDl0i+amzm/KMdj4YZiyPVEapHzSOjJWIlp/rEolrBG8GK6c07ZYquw7zzNgo4eOltcidgP5V8wPJRjzXjOanBQg7kK/AlSBVtttiZxNOHlPBVKByJkS20vwivKxZJ0la6T2+wDNs3lgv9XiPHPkfQF6EUxbLVx12awVadXOW2qxkHS+kWcRpSQRzOKSFJMGn5IgjJ8J9Qjh1LETilHTMELTF5SQU1wZ0BJIASiU6w+didVNMa+1MwM20OVEFOByWgT851RdIEuq0r4GexvzG8m5v+zQm6Uyw7nsC4U143iJ8Q1TYC4ihlVyLqXq5nlqTSNadecJkB/qYmU5/QWOm+QUYhNTYbRW4P0oeGa/RluIIYdoIPylmsFZk48ghXGSqMSV4oCegq2vH30g2fuXX7UVefwWbeHf/TL8/beq+rB1+gRPaYOXvUF7dE+HaAPz3povbT2rfc22U/sp/bOOdRqVJwHtDTs3T85Oi9/</latexit><latexit sha1_base64="oSpnAEgzgYVyEh8xfFAE6ioFLvI=">AAAEfnicjVNdb9MwFL0NAbby1cET4sWiGuqk0aWIir0x8aWBQAyJbpPmqXJSN42aLznupBLyp/g38Ft44MRLqnUFDUf2vb73nHOvbcVNwyDTjvOzYV2zr9+4ubbevHX7zt17rY37h1kyU54ceEmYqGNXZDIMYjnQgQ7lcaqkiNxQHrnT12X+6EyqLEjir3qeytNI+HEwDjyhERpuNH7wkRyDbKTyaK7kqMiV7xa50+33t5nT7ZnVKZqXkG44kwuoYzDl0i+amzm/KMdj4YZiyPVEapHzSOjJWIlp/rEolrBG8GK6c07ZYquw7zzNgo4eOltcidgP5V8wPJRjzXjOanBQg7kK/AlSBVtttiZxNOHlPBVKByJkS20vwivKxZJ0la6T2+wDNs3lgv9XiPHPkfQF6EUxbLVx12awVadXOW2qxkHS+kWcRpSQRzOKSFJMGn5IgjJ8J9Qjh1LETilHTMELTF5SQU1wZ0BJIASiU6w+didVNMa+1MwM20OVEFOByWgT851RdIEuq0r4GexvzG8m5v+zQm6Uyw7nsC4U143iJ8Q1TYC4ihlVyLqXq5nlqTSNadecJkB/qYmU5/QWOm+QUYhNTYbRW4P0oeGa/RluIIYdoIPylmsFZk48ghXGSqMSV4oCegq2vH30g2fuXX7UVefwWbeHf/TL8/beq+rB1+gRPaYOXvUF7dE+HaAPz3povbT2rfc22U/sp/bOOdRqVJwHtDTs3T85Oi9/</latexit>forward passreverse pass| (t0)i<latexit sha1_base64="d3ycXtzXzHTTTae1uLhuapwnqlo=">AAAD0nichVJNb9NAEB3XUFrzlcKRi0VUqUgocioieqzKhziAVKSmrdStorWzcVZZf2i9qZQaHxBXblzhh8Fv4cDz4kQkEepauzP75s3bmV2HuZKFCYKfzoZ76/bmna1t7+69+w8etnYenRbZVEeiH2Uq0+chL4SSqegbaZQ4z7XgSajEWTh5VcfProQuZJaemFkuLhMep3IkI24ADXacTTYUIyRbqTKZaTGsSh2HVRl0er3nftDp2jWovBVmqKZiQQ0sp156lVeyJc4nlhdyzwyCZ0zzNFbCr7zdFQ5TYmR8VvpzspyTmZbxGKFqOauuc5HERppHJcu5NpIrnyXcjAFNyvdVtYDXlKt/pAetNuq3w193uo3TpmYcZ61fxGhIGUU0pYQEpWTgK+JU4LugLgWUA7ukEpiGJ21cUEUecqdgCTA40AnWGLuLBk2xrzULmx3hFIWpkenTLuZbqxiCXZ8q4BewvzGvLRb/94TSKtcVzmBDKG5bxQ/ADY3BuCkzaZjzWm7OrLsyNKID241EfblF6j6jhc5rRDSwiY349MYyY2iEdn+FG0hh+6igvuW5gm87HsJya4VVSRtFDj0NW98+6sEzd1cfdd053e908d9/fNE+PGoefIue0FPaw6u+pEN6R8eoI3IS55vz3fnhnrjX7mf3y1/qhtPkPKal4X79A8Rh8BU=</latexit><latexit sha1_base64="d3ycXtzXzHTTTae1uLhuapwnqlo=">AAAD0nichVJNb9NAEB3XUFrzlcKRi0VUqUgocioieqzKhziAVKSmrdStorWzcVZZf2i9qZQaHxBXblzhh8Fv4cDz4kQkEepauzP75s3bmV2HuZKFCYKfzoZ76/bmna1t7+69+w8etnYenRbZVEeiH2Uq0+chL4SSqegbaZQ4z7XgSajEWTh5VcfProQuZJaemFkuLhMep3IkI24ADXacTTYUIyRbqTKZaTGsSh2HVRl0er3nftDp2jWovBVmqKZiQQ0sp156lVeyJc4nlhdyzwyCZ0zzNFbCr7zdFQ5TYmR8VvpzspyTmZbxGKFqOauuc5HERppHJcu5NpIrnyXcjAFNyvdVtYDXlKt/pAetNuq3w193uo3TpmYcZ61fxGhIGUU0pYQEpWTgK+JU4LugLgWUA7ukEpiGJ21cUEUecqdgCTA40AnWGLuLBk2xrzULmx3hFIWpkenTLuZbqxiCXZ8q4BewvzGvLRb/94TSKtcVzmBDKG5bxQ/ADY3BuCkzaZjzWm7OrLsyNKID241EfblF6j6jhc5rRDSwiY349MYyY2iEdn+FG0hh+6igvuW5gm87HsJya4VVSRtFDj0NW98+6sEzd1cfdd053e908d9/fNE+PGoefIue0FPaw6u+pEN6R8eoI3IS55vz3fnhnrjX7mf3y1/qhtPkPKal4X79A8Rh8BU=</latexit><latexit sha1_base64="d3ycXtzXzHTTTae1uLhuapwnqlo=">AAAD0nichVJNb9NAEB3XUFrzlcKRi0VUqUgocioieqzKhziAVKSmrdStorWzcVZZf2i9qZQaHxBXblzhh8Fv4cDz4kQkEepauzP75s3bmV2HuZKFCYKfzoZ76/bmna1t7+69+w8etnYenRbZVEeiH2Uq0+chL4SSqegbaZQ4z7XgSajEWTh5VcfProQuZJaemFkuLhMep3IkI24ADXacTTYUIyRbqTKZaTGsSh2HVRl0er3nftDp2jWovBVmqKZiQQ0sp156lVeyJc4nlhdyzwyCZ0zzNFbCr7zdFQ5TYmR8VvpzspyTmZbxGKFqOauuc5HERppHJcu5NpIrnyXcjAFNyvdVtYDXlKt/pAetNuq3w193uo3TpmYcZ61fxGhIGUU0pYQEpWTgK+JU4LugLgWUA7ukEpiGJ21cUEUecqdgCTA40AnWGLuLBk2xrzULmx3hFIWpkenTLuZbqxiCXZ8q4BewvzGvLRb/94TSKtcVzmBDKG5bxQ/ADY3BuCkzaZjzWm7OrLsyNKID241EfblF6j6jhc5rRDSwiY349MYyY2iEdn+FG0hh+6igvuW5gm87HsJya4VVSRtFDj0NW98+6sEzd1cfdd053e908d9/fNE+PGoefIue0FPaw6u+pEN6R8eoI3IS55vz3fnhnrjX7mf3y1/qhtPkPKal4X79A8Rh8BU=</latexit><latexit sha1_base64="d3ycXtzXzHTTTae1uLhuapwnqlo=">AAAD0nichVJNb9NAEB3XUFrzlcKRi0VUqUgocioieqzKhziAVKSmrdStorWzcVZZf2i9qZQaHxBXblzhh8Fv4cDz4kQkEepauzP75s3bmV2HuZKFCYKfzoZ76/bmna1t7+69+w8etnYenRbZVEeiH2Uq0+chL4SSqegbaZQ4z7XgSajEWTh5VcfProQuZJaemFkuLhMep3IkI24ADXacTTYUIyRbqTKZaTGsSh2HVRl0er3nftDp2jWovBVmqKZiQQ0sp156lVeyJc4nlhdyzwyCZ0zzNFbCr7zdFQ5TYmR8VvpzspyTmZbxGKFqOauuc5HERppHJcu5NpIrnyXcjAFNyvdVtYDXlKt/pAetNuq3w193uo3TpmYcZ61fxGhIGUU0pYQEpWTgK+JU4LugLgWUA7ukEpiGJ21cUEUecqdgCTA40AnWGLuLBk2xrzULmx3hFIWpkenTLuZbqxiCXZ8q4BewvzGvLRb/94TSKtcVzmBDKG5bxQ/ADY3BuCkzaZjzWm7OrLsyNKID241EfblF6j6jhc5rRDSwiY349MYyY2iEdn+FG0hh+6igvuW5gm87HsJya4VVSRtFDj0NW98+6sEzd1cfdd053e908d9/fNE+PGoefIue0FPaw6u+pEN6R8eoI3IS55vz3fnhnrjX7mf3y1/qhtPkPKal4X79A8Rh8BU=</latexit>L(✓)<latexit sha1_base64="wOMP9/PDTWdXhH5P8P7K6+DC718=">AAADbnichVLbahRBEK3d8ZKsl2wi+iLi4iKsEJYZUeJjiBd8UIjgJoFMCN2T3tlh50ZPz8LazE/4NXnVv/Av/AAfPF1OxBg0PdRU9emq01XVJcs0qYzvf+t0vStXr11fWe3duHnr9lp/fWOvKmodqUlUpIU+kKJSaZKriUlMqg5KrUQmU7Uv5y/d+f5C6Sop8o9mWaqjTMR5Mk0iYQAd9zd7NmQWm4vFUqa1asJMmNlUi7l914xCmdnQzJQRzZPmuD/0xz6vwUUjaI0htWu3WO/cpZBOqKCIaspIUU4GdkqCKnyHFJBPJbAjssA0rITPFTXUQ2wNLwUPAXSOf4zdYYvm2DvOiqMj3JJCNCIH9BjyhhklvN2tCnYF/QPyibH4nzdYZnYZLqElGFeZ8T1wQzN4XBaZtZ5nuVwe6aoyNKUXXE2C/EpGXJ3Rb55XONHA5nwyoNfsGYND8n6BDuTQE2TgunzGMOCKT6AFa8UsecsowKehXfddPj1+NYVsHLv6o7eWu75AXySQmt/JAo+5SxavOYZsgve89fw/72kRm5GbruDvWbpo7D0dB/44+PBsuL3TztkK3adHNMIsbdE2vaVdVB/RZzqlL/S1+9275z3wHv5y7XbamDt0bnmjn5pEtLk=</latexit><latexit sha1_base64="wOMP9/PDTWdXhH5P8P7K6+DC718=">AAADbnichVLbahRBEK3d8ZKsl2wi+iLi4iKsEJYZUeJjiBd8UIjgJoFMCN2T3tlh50ZPz8LazE/4NXnVv/Av/AAfPF1OxBg0PdRU9emq01XVJcs0qYzvf+t0vStXr11fWe3duHnr9lp/fWOvKmodqUlUpIU+kKJSaZKriUlMqg5KrUQmU7Uv5y/d+f5C6Sop8o9mWaqjTMR5Mk0iYQAd9zd7NmQWm4vFUqa1asJMmNlUi7l914xCmdnQzJQRzZPmuD/0xz6vwUUjaI0htWu3WO/cpZBOqKCIaspIUU4GdkqCKnyHFJBPJbAjssA0rITPFTXUQ2wNLwUPAXSOf4zdYYvm2DvOiqMj3JJCNCIH9BjyhhklvN2tCnYF/QPyibH4nzdYZnYZLqElGFeZ8T1wQzN4XBaZtZ5nuVwe6aoyNKUXXE2C/EpGXJ3Rb55XONHA5nwyoNfsGYND8n6BDuTQE2TgunzGMOCKT6AFa8UsecsowKehXfddPj1+NYVsHLv6o7eWu75AXySQmt/JAo+5SxavOYZsgve89fw/72kRm5GbruDvWbpo7D0dB/44+PBsuL3TztkK3adHNMIsbdE2vaVdVB/RZzqlL/S1+9275z3wHv5y7XbamDt0bnmjn5pEtLk=</latexit><latexit sha1_base64="wOMP9/PDTWdXhH5P8P7K6+DC718=">AAADbnichVLbahRBEK3d8ZKsl2wi+iLi4iKsEJYZUeJjiBd8UIjgJoFMCN2T3tlh50ZPz8LazE/4NXnVv/Av/AAfPF1OxBg0PdRU9emq01XVJcs0qYzvf+t0vStXr11fWe3duHnr9lp/fWOvKmodqUlUpIU+kKJSaZKriUlMqg5KrUQmU7Uv5y/d+f5C6Sop8o9mWaqjTMR5Mk0iYQAd9zd7NmQWm4vFUqa1asJMmNlUi7l914xCmdnQzJQRzZPmuD/0xz6vwUUjaI0htWu3WO/cpZBOqKCIaspIUU4GdkqCKnyHFJBPJbAjssA0rITPFTXUQ2wNLwUPAXSOf4zdYYvm2DvOiqMj3JJCNCIH9BjyhhklvN2tCnYF/QPyibH4nzdYZnYZLqElGFeZ8T1wQzN4XBaZtZ5nuVwe6aoyNKUXXE2C/EpGXJ3Rb55XONHA5nwyoNfsGYND8n6BDuTQE2TgunzGMOCKT6AFa8UsecsowKehXfddPj1+NYVsHLv6o7eWu75AXySQmt/JAo+5SxavOYZsgve89fw/72kRm5GbruDvWbpo7D0dB/44+PBsuL3TztkK3adHNMIsbdE2vaVdVB/RZzqlL/S1+9275z3wHv5y7XbamDt0bnmjn5pEtLk=</latexit><latexit sha1_base64="wOMP9/PDTWdXhH5P8P7K6+DC718=">AAADbnichVLbahRBEK3d8ZKsl2wi+iLi4iKsEJYZUeJjiBd8UIjgJoFMCN2T3tlh50ZPz8LazE/4NXnVv/Av/AAfPF1OxBg0PdRU9emq01XVJcs0qYzvf+t0vStXr11fWe3duHnr9lp/fWOvKmodqUlUpIU+kKJSaZKriUlMqg5KrUQmU7Uv5y/d+f5C6Sop8o9mWaqjTMR5Mk0iYQAd9zd7NmQWm4vFUqa1asJMmNlUi7l914xCmdnQzJQRzZPmuD/0xz6vwUUjaI0htWu3WO/cpZBOqKCIaspIUU4GdkqCKnyHFJBPJbAjssA0rITPFTXUQ2wNLwUPAXSOf4zdYYvm2DvOiqMj3JJCNCIH9BjyhhklvN2tCnYF/QPyibH4nzdYZnYZLqElGFeZ8T1wQzN4XBaZtZ5nuVwe6aoyNKUXXE2C/EpGXJ3Rb55XONHA5nwyoNfsGYND8n6BDuTQE2TgunzGMOCKT6AFa8UsecsowKehXfddPj1+NYVsHLv6o7eWu75AXySQmt/JAo+5SxavOYZsgve89fw/72kRm5GbruDvWbpo7D0dB/44+PBsuL3TztkK3adHNMIsbdE2vaVdVB/RZzqlL/S1+9275z3wHv5y7XbamDt0bnmjn5pEtLk=</latexit>r✓L<latexit sha1_base64="uLu6e46Lw2gxZ+3ngtyLj3jYjTQ=">AAAD1nichVLLbhMxFL3p8GjDoyks2YyIkFigaAalwLKCgliAVCTSRupUkT1xJqPMI/I4kYo17BBbPoCvYQs/wL+w4Ph2glpKqS37Xh/fe3wflvMsrUwQ/GyteVeuXru+vtG+cfPW7c3O1p39qlzoWA3iMiv1UIpKZWmhBiY1mRrOtRK5zNSBnL1w9wdLpau0LN6b47k6ykVSpJM0FgbQqPPERkxiSy2KRGk17td+VAiZiZGNZG4jM1VG1ABzYaYTLWb2TV2POt2gF/Dwzytho3SpGXvlVmuXIhpTSTEtKCdFBRnoGQmqMA8ppIDmwI7IAtPQUr5XVFMbvgtYKVgIoDPsCU6HDVrg7Dgr9o7xSoal4enTA6xXzChh7V5V0CvIX1gfGEsufMEys4vwGFKCcYMZ3wI3NIXFZZ55Y7mK5XJPl5WhCT3jbFLEN2fE5Rn/4dnFjQY24xufXrJlAg7J5yUqUEAOEIGr8orB54zHkIKlYpaiYRTg05Cu+i6eNndNIRrHrk7V1nLVl6iLBLLgPlngCVfJops9rEfgPattN/28iNXtgjM5iWxM/X8wb2OuGMNTevCf32Lhn5P7u+HfP/W8sv+4Fwa98F2/u/O8+cXrdI/u00O895R26DXtobYxfaVv9J1+eEPvo/fJ+3xiutZqfO7SmeF9+Q29wcnu</latexit><latexit sha1_base64="uLu6e46Lw2gxZ+3ngtyLj3jYjTQ=">AAAD1nichVLLbhMxFL3p8GjDoyks2YyIkFigaAalwLKCgliAVCTSRupUkT1xJqPMI/I4kYo17BBbPoCvYQs/wL+w4Ph2glpKqS37Xh/fe3wflvMsrUwQ/GyteVeuXru+vtG+cfPW7c3O1p39qlzoWA3iMiv1UIpKZWmhBiY1mRrOtRK5zNSBnL1w9wdLpau0LN6b47k6ykVSpJM0FgbQqPPERkxiSy2KRGk17td+VAiZiZGNZG4jM1VG1ABzYaYTLWb2TV2POt2gF/Dwzytho3SpGXvlVmuXIhpTSTEtKCdFBRnoGQmqMA8ppIDmwI7IAtPQUr5XVFMbvgtYKVgIoDPsCU6HDVrg7Dgr9o7xSoal4enTA6xXzChh7V5V0CvIX1gfGEsufMEys4vwGFKCcYMZ3wI3NIXFZZ55Y7mK5XJPl5WhCT3jbFLEN2fE5Rn/4dnFjQY24xufXrJlAg7J5yUqUEAOEIGr8orB54zHkIKlYpaiYRTg05Cu+i6eNndNIRrHrk7V1nLVl6iLBLLgPlngCVfJops9rEfgPattN/28iNXtgjM5iWxM/X8wb2OuGMNTevCf32Lhn5P7u+HfP/W8sv+4Fwa98F2/u/O8+cXrdI/u00O895R26DXtobYxfaVv9J1+eEPvo/fJ+3xiutZqfO7SmeF9+Q29wcnu</latexit><latexit sha1_base64="uLu6e46Lw2gxZ+3ngtyLj3jYjTQ=">AAAD1nichVLLbhMxFL3p8GjDoyks2YyIkFigaAalwLKCgliAVCTSRupUkT1xJqPMI/I4kYo17BBbPoCvYQs/wL+w4Ph2glpKqS37Xh/fe3wflvMsrUwQ/GyteVeuXru+vtG+cfPW7c3O1p39qlzoWA3iMiv1UIpKZWmhBiY1mRrOtRK5zNSBnL1w9wdLpau0LN6b47k6ykVSpJM0FgbQqPPERkxiSy2KRGk17td+VAiZiZGNZG4jM1VG1ABzYaYTLWb2TV2POt2gF/Dwzytho3SpGXvlVmuXIhpTSTEtKCdFBRnoGQmqMA8ppIDmwI7IAtPQUr5XVFMbvgtYKVgIoDPsCU6HDVrg7Dgr9o7xSoal4enTA6xXzChh7V5V0CvIX1gfGEsufMEys4vwGFKCcYMZ3wI3NIXFZZ55Y7mK5XJPl5WhCT3jbFLEN2fE5Rn/4dnFjQY24xufXrJlAg7J5yUqUEAOEIGr8orB54zHkIKlYpaiYRTg05Cu+i6eNndNIRrHrk7V1nLVl6iLBLLgPlngCVfJops9rEfgPattN/28iNXtgjM5iWxM/X8wb2OuGMNTevCf32Lhn5P7u+HfP/W8sv+4Fwa98F2/u/O8+cXrdI/u00O895R26DXtobYxfaVv9J1+eEPvo/fJ+3xiutZqfO7SmeF9+Q29wcnu</latexit><latexit sha1_base64="uLu6e46Lw2gxZ+3ngtyLj3jYjTQ=">AAAD1nichVLLbhMxFL3p8GjDoyks2YyIkFigaAalwLKCgliAVCTSRupUkT1xJqPMI/I4kYo17BBbPoCvYQs/wL+w4Ph2glpKqS37Xh/fe3wflvMsrUwQ/GyteVeuXru+vtG+cfPW7c3O1p39qlzoWA3iMiv1UIpKZWmhBiY1mRrOtRK5zNSBnL1w9wdLpau0LN6b47k6ykVSpJM0FgbQqPPERkxiSy2KRGk17td+VAiZiZGNZG4jM1VG1ABzYaYTLWb2TV2POt2gF/Dwzytho3SpGXvlVmuXIhpTSTEtKCdFBRnoGQmqMA8ppIDmwI7IAtPQUr5XVFMbvgtYKVgIoDPsCU6HDVrg7Dgr9o7xSoal4enTA6xXzChh7V5V0CvIX1gfGEsufMEys4vwGFKCcYMZ3wI3NIXFZZ55Y7mK5XJPl5WhCT3jbFLEN2fE5Rn/4dnFjQY24xufXrJlAg7J5yUqUEAOEIGr8orB54zHkIKlYpaiYRTg05Cu+i6eNndNIRrHrk7V1nLVl6iLBLLgPlngCVfJops9rEfgPattN/28iNXtgjM5iWxM/X8wb2OuGMNTevCf32Lhn5P7u+HfP/W8sv+4Fwa98F2/u/O8+cXrdI/u00O895R26DXtobYxfaVv9J1+eEPvo/fJ+3xiutZqfO7SmeF9+Q29wcnu</latexit>✓<latexit sha1_base64="Td7IeC7jhamJWpupvlu+T4+ANE0=">AAADvnichVJLbxMxEJ50ebThlcIRCa2IkDigaLdqBccICuKCVCTSVmqqyt5MtqvsS7veiGDlxq/hCn+G/8KBz9MNaimltuwZf575PA/rMk1qEwQ/O2vejZu3bq9vdO/cvXf/QW/z4X5dNFXEo6hIi+pQq5rTJOeRSUzKh2XFKtMpH+jZG3d/MOeqTor8k1mUfJypOE+mSaQMoJPeEzsWEpur+UKnDS/9sc7s2JyyUcvlSa8fDAIZ/mUlbJU+tWOv2Ozs0pgmVFBEDWXElJOBnpKiGvOIQgqoBHZMFlgFLZF7piV14dvAimGhgM6wxzgdtWiOs+OsxTvCKylWBU+fnmG9E0YNa/cqQ68hf2F9ESy+8gUrzC7CBaQG44YwfgBu6BQW13lmreUqlus9XVaGpvRKskkQXymIyzP6w7OLmwrYTG58eiuWMTi0nOeoQA45QgSuyisGXzKeQCqRLCx5y6jAV0G66rt4utI1RjSOnc/V1krV56iLBtJInyzwWKpk0c0B1gvwXtR22n5exep2JZmcRTah7X8w72CuGMNzevCf32Lhn5H7u+HfP/Wysr81CINB+HG7P3zd/uJ1ekxP6Tnee0lDek97qG1EX+kbfacf3tCbeplXnJmudVqfR3RheJ9/A5kav7o=</latexit><latexit sha1_base64="Td7IeC7jhamJWpupvlu+T4+ANE0=">AAADvnichVJLbxMxEJ50ebThlcIRCa2IkDigaLdqBccICuKCVCTSVmqqyt5MtqvsS7veiGDlxq/hCn+G/8KBz9MNaimltuwZf575PA/rMk1qEwQ/O2vejZu3bq9vdO/cvXf/QW/z4X5dNFXEo6hIi+pQq5rTJOeRSUzKh2XFKtMpH+jZG3d/MOeqTor8k1mUfJypOE+mSaQMoJPeEzsWEpur+UKnDS/9sc7s2JyyUcvlSa8fDAIZ/mUlbJU+tWOv2Ozs0pgmVFBEDWXElJOBnpKiGvOIQgqoBHZMFlgFLZF7piV14dvAimGhgM6wxzgdtWiOs+OsxTvCKylWBU+fnmG9E0YNa/cqQ68hf2F9ESy+8gUrzC7CBaQG44YwfgBu6BQW13lmreUqlus9XVaGpvRKskkQXymIyzP6w7OLmwrYTG58eiuWMTi0nOeoQA45QgSuyisGXzKeQCqRLCx5y6jAV0G66rt4utI1RjSOnc/V1krV56iLBtJInyzwWKpk0c0B1gvwXtR22n5exep2JZmcRTah7X8w72CuGMNzevCf32Lhn5H7u+HfP/Wysr81CINB+HG7P3zd/uJ1ekxP6Tnee0lDek97qG1EX+kbfacf3tCbeplXnJmudVqfR3RheJ9/A5kav7o=</latexit><latexit sha1_base64="Td7IeC7jhamJWpupvlu+T4+ANE0=">AAADvnichVJLbxMxEJ50ebThlcIRCa2IkDigaLdqBccICuKCVCTSVmqqyt5MtqvsS7veiGDlxq/hCn+G/8KBz9MNaimltuwZf575PA/rMk1qEwQ/O2vejZu3bq9vdO/cvXf/QW/z4X5dNFXEo6hIi+pQq5rTJOeRSUzKh2XFKtMpH+jZG3d/MOeqTor8k1mUfJypOE+mSaQMoJPeEzsWEpur+UKnDS/9sc7s2JyyUcvlSa8fDAIZ/mUlbJU+tWOv2Ozs0pgmVFBEDWXElJOBnpKiGvOIQgqoBHZMFlgFLZF7piV14dvAimGhgM6wxzgdtWiOs+OsxTvCKylWBU+fnmG9E0YNa/cqQ68hf2F9ESy+8gUrzC7CBaQG44YwfgBu6BQW13lmreUqlus9XVaGpvRKskkQXymIyzP6w7OLmwrYTG58eiuWMTi0nOeoQA45QgSuyisGXzKeQCqRLCx5y6jAV0G66rt4utI1RjSOnc/V1krV56iLBtJInyzwWKpk0c0B1gvwXtR22n5exep2JZmcRTah7X8w72CuGMNzevCf32Lhn5H7u+HfP/Wysr81CINB+HG7P3zd/uJ1ekxP6Tnee0lDek97qG1EX+kbfacf3tCbeplXnJmudVqfR3RheJ9/A5kav7o=</latexit><latexit sha1_base64="Td7IeC7jhamJWpupvlu+T4+ANE0=">AAADvnichVJLbxMxEJ50ebThlcIRCa2IkDigaLdqBccICuKCVCTSVmqqyt5MtqvsS7veiGDlxq/hCn+G/8KBz9MNaimltuwZf575PA/rMk1qEwQ/O2vejZu3bq9vdO/cvXf/QW/z4X5dNFXEo6hIi+pQq5rTJOeRSUzKh2XFKtMpH+jZG3d/MOeqTor8k1mUfJypOE+mSaQMoJPeEzsWEpur+UKnDS/9sc7s2JyyUcvlSa8fDAIZ/mUlbJU+tWOv2Ozs0pgmVFBEDWXElJOBnpKiGvOIQgqoBHZMFlgFLZF7piV14dvAimGhgM6wxzgdtWiOs+OsxTvCKylWBU+fnmG9E0YNa/cqQ68hf2F9ESy+8gUrzC7CBaQG44YwfgBu6BQW13lmreUqlus9XVaGpvRKskkQXymIyzP6w7OLmwrYTG58eiuWMTi0nOeoQA45QgSuyisGXzKeQCqRLCx5y6jAV0G66rt4utI1RjSOnc/V1krV56iLBtJInyzwWKpk0c0B1gvwXtR22n5exep2JZmcRTah7X8w72CuGMNzevCf32Lhn5H7u+HfP/Wysr81CINB+HG7P3zd/uJ1ekxP6Tnee0lDek97qG1EX+kbfacf3tCbeplXnJmudVqfR3RheJ9/A5kav7o=</latexit>monitored qubit based on ∂P consists of three building blocks as sketched in Fig. 2:
a parametrized controller
, which will be formed by a NN, a model of the dynamics,
expressed as an SDE, and a loss function.

C

At the beginning of each run, we initialize the system in an arbitrary state on the

8

Bloch sphere,

,

)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

e
|

e
|

g
|

g
|

ϑ
2

and

)eiφ

+ sin(

= cos(

ψ(t0)
|

ϑ
2
where
are the excited and ground states of the qubit in the z-basis,
respectively. To ensure that the controller will perform optimally for any initial state, we
sample the angles ϑ and φ uniformly from their intervals [0, π] and [0, 2π), respectively.
Depending on the chosen control scheme, cf. Fig. 1(b), the controller receives as
an input either the quantum state
(Section 3) or the last homodyne detection
τ, t] (Section 4).
record in form of a vector Jτ (t) gathered over some time interval [t
Moreover, in Section 4 the controller also receives a vector Ωm(t) of the m last control
actions applied prior to the time t.

ψ(t)
(cid:105)
|

(11)

−

The controller then maps this input to the next value of the drive, Ω(t). Given
and Ω(t), we use the Runge-Kutta Milstein solver from the StochasticDiﬀEq.jl
ψ(t)
|
(cid:105)
package [40, 41, 42] to calculate the next state
according to the SDE (8).
This loop between control agent and SDE solver is iterated for all time steps. We store
and the drive values Ω(ti) at N uniformly spaced time steps
the quantum states
is
ti
{
called checkpoints.

N
i=1 to be able to evaluate the loss function. Hereafter, the set

ψ(t + dt)
|

, Ω(ti)
}

ψ(ti)
(cid:105)
|

ψ(ti)

{|

}

(cid:105)

(cid:105)

We minimize a loss function of the form [10, 12, 13, 43]

L =

cµLµ ,

(12)

µ
(cid:88)
where the terms Lµ encode case-speciﬁc objectives of the optimization process, see, e.g.
Ref. [12]. Their relative importance can be controlled by the weights cµ. We choose
the weights cµ empirically but, if necessary, they could also be tuned by means of
hyperparameter optimization techniques [10]. To enforce a large ﬁdelity with respect
to the target state over the whole control interval, we include into the loss function the
average inﬁdelity of the checkpoints

with respect to the target state

ψtar
|

,
(cid:105)

ψ(ti)
|
N

(cid:105)

LF =

1
N

1

i=0
(cid:88)

(cid:0)

ψ(ti)

ψtar
|

2
(cid:105)|

.

− |(cid:104)

(cid:1)

(13)

This form of the loss function also leads to a time-optimal performance of the controller.
To focus on speciﬁc time intervals, like the last few steps for example, the sum in Eq. (13)
can be straightforwardly adjusted. We will consider the target state
in the
following. In addition to LF , we include the term

ψtar
|

e
(cid:105)
|

=

(cid:105)

LΩ =

1
N

N

Ω(ti)

i=0 |
(cid:88)

2
|

(14)

9

in the loss function to favor smaller amplitudes of the drive Ω(ti). In Section 4, we will
ﬁnd that this term is important to suppress the collapse of the NN towards a strategy
where constant maximal pulses are applied during the training.

At this stage, we have calculated a quantum trajectory and evaluated its value of
the loss function. In the next step, we must update the control strategy to decrease
the value of the loss function. The derivative of the loss function L with respect to the
parameters of the neural network provides a meaningful update rule towards a better
control strategy. Thus, we need to calculate the gradient
θL. This can be computed
∇
eﬃciently using sensitivity methods for SDEs discussed next.

2.4. Adjoint sensitivity methods

ψ(ti)
(cid:105)

), deﬁned in Eq. (12), is a scalar function
The loss function L = L(
which explicitly depends on the checkpoints and implicitly on the parameters θ of the
controller. In contrast to score-function estimators [44, 45, 46], such as the REINFORCE
algorithm [47], we will incorporate the physical model into the gradient computation as
sketched in Fig. 2.

, Ω(ti)
}

{|

Automatic diﬀerentiation (AD) is a powerful tool to evaluate gradients of numeric
functions at machine precision [48]. A key concept to AD is the computational
graph [49], also known as Wengert trace, which is a directed acyclic graph that represents
the sequence of elementary operations that a computer program applies to its input
values to calculate its output values. The nodes of the computational graph are the
elementary computational steps of the program called primitives. The outcome of each
primitive operation, called an intermediate variable, is evaluated in the forward pass
through the graph.

In forward-mode AD, one associates with each intermediate variable vj the value

of the derivative

˙vji =

∂vj
∂θi

(15)

θi
{

.
}

with respect to a parameter θi of interest. The derivatives ˙vji are calculated together
with the associated intermediate values vj in the forward pass, i.e. the gradient is pushed
forward through the graph. This procedure must be repeated for each parameter θi,
therefore, forward-mode AD scales poorly in computation time with increasing number
of parameters

In contrast, reverse-mode AD traverses the computation graph backwards from the

loss function to the parameters θi by deﬁning an adjoint process:

¯vi =

∂L
∂vi

,

(16)

which is the sensitivity of the loss function L with respect to changes in the intermediate
variable vi. Reverse-mode AD is very eﬃcient in terms of the number of input parameters
because one needs just a single backward pass after the forward pass to obtain the

10

{

gradient with respect to all parameters
. Thus, we always implement the AD of
θi
}
the NN in reverse mode. However, reverse-mode AD might be very memory expensive
because all intermediate variables vi from the forward pass need to be stored for the
backward pass. Therefore, reverse-mode AD scales poorly in memory if the number of
steps and parameters of the SDE solver increases. Whether forward-mode or reverse-
mode AD is more eﬃcient to calculate gradients of the loss function depends on the
speciﬁc details of the control loop shown in Fig. 2.

In fact, it is possible to combine diﬀerent AD methods on diﬀerent parts of the
computational graph as we illustrate now. In Secs. 3.3 and 4, we will use Algorithm 1,
where the drive Ω(t) is piecewise constant, i.e. a constant value of Ω is applied over Nsub
successive time steps between two checkpoints. In this case, the memory consumption
Ω(ti)
of the reverse-mode AD of the NN is moderate since the number of parameters
}
{
grows only with the number of checkpoints rather than with the number of time steps. In
contrast, in the SDE solver the evaluation of the time evolution between two checkpoints
only depends on the single parameter Ω(ti),
{|
which makes forward-mode AD very eﬃcient [50]. Therefore, we nest both methods
and use an inner forward-mode AD through the SDE solver and an outer reverse-mode
AD for the remaining parts, i.e. the NN and the computation of the loss function.

, Ω(ti)
}

, Ω(ti+1)

ψ(ti+1)

ψ(ti)

and

{|

}

(cid:105)

(cid:105)

Algorithm 1 Piecewise constant
Input: ψ(t0), t0, Ω(t0) = 0
Result: L
for i = 0 : N

1 do
compute and store checkpoints:
Ω(ti+1)
←
ψ(ti+1)
←
SDE (8) in [ti, ti+1]

NNθ(ψ(ti))

−

solve(ψ(ti),Ω(ti+1)) for

Algorithm 2 Continuously updated
Input: ψ(t0), t0, Ω(t0) = 0
Result: L
compute and store checkpoints:

ψ(ti), Ω(ti)
{
SDE (8) in [t0, tN ]

} ←

solve(ψ(t0),NNθ) for

end
L

←

loss(

ψ(ti), Ω(ti)
}

)

{

L

loss(

ψ(ti), Ω(ti)
}

)

{

←

Restricting oneself to a piecewise-constant control drive, however, prevents the
controller from reacting instantaneously to changes of the state. To implement a fast
control loop, the controller has to be placed in the drift term of the SDE (8). Thus,
the parameters entering the solver will be the NN parameters θ, see Algorithm 2. The
continuous adjoint sensitivity method [51, 52, 53] circumvents the resulting memory
issues by introducing a new primitive for the whole SDE in the backward pass of the
code. This new primitive is determined by the solution of another SDE problem, the
adjoint SDE. Formally, deﬁning the adjoint process as

the adjoint SDE problem in the Itˆo sense satisﬁes the diﬀerential equation

aψ(t) =

ψ(t)L(

{|

ψ(ti)

) ,

(cid:105)}

∇

(17)

daψ(t) =

a†

ψ(t)

ψ(t)

· ∇

−

(cid:16)

(cid:17) (cid:0)

Kψ(t)

−

2C IS

ψ(t)

dt

(cid:1)

a†

ψ(t)

−

(cid:16)

ψ(t)

· ∇

(cid:17)

Mψ(t)dW (t) ,

(18)

with the initial condition

aψ(tN ) =

ψ(tN )L(

{|

ψ(ti)

(cid:105)}

) ,

∇

11

(19)

where the standard conversion factor C IS
in Eq. (18) accounts for the required
ψ(t)
transformation from the Itˆo to the Stratonovich sense and vice versa [54]. The gradients
θL with respect to θ are then determined by the
of the loss function aθ(t0) =
integration of

∇

daθ(t) =

−

a†

ψ(t)

θ

· ∇

Kψ(t)

−

2C IS

ψ(t)

dt

−

a†

ψ(t)

θ

· ∇

Mψ(t)dW (t) ,

(20)

(cid:16)

(cid:17) (cid:0)

(cid:1)

(cid:16)

(cid:17)

with the initial condition aθ(tN ) = 0Dim[θ]. This continuous adjoint sensitivity method
will be used in Section 3.2. Further details regarding the adjoint method and our
Julia implementation [55, 56] within the SciML ecosystem [11, 16, 40] are discussed in
Appendix C.2.

3. SDE control based on full knowledge of the state

[

:

C

∈

−

Ω(t)

(cid:105) (cid:55)→

ψ(t)
|

ψ(t)
(cid:105)
|

We ﬁrst investigate the scenario in which the controller maps the quantum state
ψ(t)
(cid:105)
|
Ωmax, Ωmax]. From a learning
to a new control parameter,
perspective, this is a major simpliﬁcation because the NN does not need to learn how
to ﬁlter the homodyne current J(t) to determine the state
. From a practical
perspective of controller design, this approach assumes that there is already a ﬁlter
module, which allows one to predict the state of the system from the measurement
record and past control actions. We discuss in Section 2.1 and Appendix A.4 the
implementation of such a ﬁlter in our case of a qubit subjected to homodyne detection.
Note that if the initial state of the qubit is unknown, only a mixed state ρt can be
obtained if the detection record is too short. Nevertheless, it is always possible to obtain
and recover our scenario, e.g. by projecting ρt onto
a pure state estimate ρt
the surface of the Bloch sphere. Alternatively, one can straightforwardly generalize our
approach to the case of a stochastic quantum master equation describing the evolution
of the system’s density matrix in the presence of homodyne detection, cf. Appendix A.5.
For all numerical experiments we ﬁx the parameters of the physical model as
∆ = 20κ and Ωmax = 10κ. We discuss the variation of these parameters and their
impact on the reached ﬁdelity in Appendix D.

ψ(t)

(cid:55)→ |

(cid:105)

3.1. Hand-crafted strategy

The control operator σx in Eq. (1) induces a rotation about the x-axis. Therefore,
a simple but very intuitive strategy to move the state upwards in each time step is to
compute the expectation value
(cid:105)ψ(t) and to choose the direction of rotation depending
< 0), the controller should rotate (counter-)
σy
on its sign. Speciﬁcally, if
(cid:105)
(cid:104)
clockwise about the x-axis, as summarized in Algorithm 3.

σy
(cid:104)
> 0 (or

σy

(cid:104)

(cid:105)

12

e
(cid:105)
|

Figure 3: Preparation of the state
for the continuously monitored qubit described
by the SDE (8). (a) Mean ﬁdelity (blue solid line) and corresponding standard deviation
(shaded) for the hand-crafted strategy summarized in Algorithm 3 as a function of the
time steps i at which checkpoints are stored. (b) Corresponding drive amplitudes. The
black lines in (a,b) visualize the time evolution of the initial state
. Stereographic
(cid:105)
of the southern
projection, Eq. (21), of the applied drive Ω with respect to states
(cid:105)
hemisphere of the Bloch sphere for (c) the hand-crafted strategy and (d) the optimized
NN described in Section 3.2. Note that panel (d) is the stereographic projection of the
Bloch sphere of the inset of Fig. 4(a).

g
|
ψ
|

Algorithm 3 Hand-crafted controller
Input: ψ(t)
Result: Ω(t)
if

ψ(t) > 0 then
σy
(cid:105)
(cid:104)
Ωmax
Ω(t)

←

else

Ω(t)

end

Ωmax

← −

Figure 3(a,b) shows the ﬁdelity and the associated drive Ω for this control scheme.
Though conceptually straightforward, this hand-crafted control function is very eﬃcient.
The mean ﬁdelity over the whole control interval is Fhc = 0.90
0.13. We visualize the
control strategy in Fig. 3(c), where we show the applied drive Ω as a function of the
state on the Bloch sphere. The Bloch sphere [with spherical coordinates ϑ, φ, see also
Eq. (11)] is mapped onto the tangential plane at z = 0, described by polar coordinates
(R, Φ), using a stereographic projection

±

(R, Φ) = (cot

ϑ
2

, φ) .

(21)

Apparently, the stereographic projection maps the south pole to R = 0 and the north
. Throughout this paper we truncate the value of R to an interval
pole to R =

∞

(b)(c)(d)(a)00[0, 1], so we plot the applied drive values on the states of the southern hemisphere, cf.
Fig. 3(c,d).

13

3.2. Continuously updated control drive

e
(cid:105)
|

Figure 4: Preparation of the state
for the continuously monitored qubit described
by the SDE (8), based on (a-c) continuously updated control parameters and (d-f)
piecewise-constant control parameters. We compute the gradients of the loss function
with respect to the parameters of the NN using the continuous adjoint sensitivity method
in (a-c) and the nested discrete AD method in (d-f), see Section 2.4. (a,d) Smooth
evolution of the loss as a function of training epochs. (b-f) Performance of the trained
NN when it is applied to a set of 256 randomly sampled initial states on the Bloch
sphere. The solid blue [red] line in (b,e) [(c,f)] shows the mean ﬁdelity F (ti) [control
drive Ω(ti)] as a function of the time steps ti at which checkpoints are stored. The
shaded regions represent the corresponding standard deviation which is large in panels
(c) and (f) because the controller will choose a diﬀerent sequence of controls for each
quantum state. The black lines in (b-f) visualize the results for an initial state
. Inset
in Panel (a): Visualization of the control parameters Ω (in color code) as a function
of the current state
on the Bloch sphere. The color palette indicates rotation
clockwise (blue) or anti-clockwise (red) about the x-axis. The yellow points indicate the
where the ﬁrst 50 points are connected by a
trajectory starting at the initial state
line. The hyperparameters are listed in Tab. B1.

ψ(t)
|

g
|

g
|

(cid:105)

(cid:105)

(cid:105)

(b)(c)(a)xzyNow we apply a NN as the controller. We use a controller which changes Ω(t)
in every time step of the solver based on the current state
. This implements
a high-frequency feedback loop but renders discrete AD methods very ineﬃcient since
all parameters of the NN contribute to the feedback loop. Consequently, we use the
continuous adjoint sensitivity methods described in Section 2.4 to calculate gradients of
the loss function.

ψ(t)
(cid:105)
|

14

Figure 4(a) shows the smooth evolution of the loss function throughout the training
of the (fully-connected) neural network, which converges to a conﬁguration able to
reach quickly ﬁdelities with mean value of about 0.9 with modest standard deviation,
see Fig. 4(b). The mean ﬁdelity over the whole control interval is Fc = 0.90
0.13.
Figure 4(c) illustrates the applied drive Ω during this time evolution. The inset of
Fig. 4(a) visualizes the control strategy on the Bloch sphere. The same is depicted in
Fig. 3(d) using the stereographic projection, see Eq. (21). The controlled evolution of
the initial state
, corresponding to the black lines in Fig. 4(b,c), is marked
by the yellow points. These points show how the controller ﬁrst transfers the state from
the south pole to the north pole region and then stabilizes it in vicinity of the target
state

ψ(t0)
(cid:105)
|

g
|

±

=

(cid:105)

.
e
(cid:105)
|

3.3. Piecewise-constant control drive

Now we reduce the control frequency and assume that the controller changes the action
Ω(t) only every Nsub time steps. This case is crucial in many physical situations, where
the control loop is not fast enough to follow high-frequency changes in the physical
system. In practice this means that we evolve the state for Nsub substeps between the
with ﬁxed value of Ω(ti). The resulting piecewise-constant
checkpoints
control scheme allows us to use the discrete forward-mode adjoint sensitivity method
through the SDE solver combined with an outer reverse-mode AD through the rest of
the control loop, as described in Section 2.4. Although we restricted the rate at which
Ω(t) can change, we ﬁnd that the NN converges to a similar learning behavior with
similarly large ﬁdelities F (t) as in Section 3.2, see Fig. 4(e). The mean ﬁdelity over the
whole control interval is Fpw = 0.89

ψ(ti)
(cid:105)

, Ω(ti)

0.10.

{|

}

±

3.4. Comparison of the control strategies

Based on the results from a set of 256 trajectories, all three control strategies perform
nearly equally well in terms of their average ﬁdelities F
0.9. The piecewise-constant
controller slightly outperforms the other two approaches by having the smallest relative
dispersion of the mean ﬁdelity Fpw, which we attribute to the larger number of training
epochs and the larger NN, see Table B1.

≈

The hand-crafted strategy achieves a large average ﬁdelity, but generates sudden
jumps in the drive Ω(t), as shown in Fig. 3(b). Such a drive is experimentally hardly
feasible. We ﬁnd that NNs with moderate depths provide a smooth mapping between
the input states and the drive, see Figs. 3(c) vs. 3(d), while keeping high ﬁdelity in

15

the control interval. The signals generated by these protocols are experimentally more
accessible, see Figs. 4(d) and (f). When necessary, speciﬁc terms can be added to L
in Eq. (12) to strengthen various requirements on the controller’s performance (e.g. the
smoothness of the drive or bounds on the power input) as discussed in Section 2.2. This
is not the case for the hand-crafted strategies where an eﬃcient implementation of these
constraints might be impossible. Furthermore, in some cases, e.g. the mountain car
problem, it is not straightforward to come up with any hand-crafted strategy to start
with.
In contrast, the RL and ∂P approach is easily adjustable to diﬀerent physical
systems.

(cid:29)

There are two principal reasons why the ﬁdelity F only reaches 0.9 in our setup.
First, F is a time-average and the controller needs some time to align the qubit to
a target state (starting from an arbitrary state). Second, the controlled qubit rotates
about an axis in the x-z-plane whose direction depends on the ratio ∆/Ω. Hence, even in
the case Ω
∆ when the qubit rotates solely about the x-axis, the drive can only bring
the qubit all the way up to the north pole of the Bloch sphere if the current state lies
on a great circle perpendicular to this axis. Therefore, the ratio ∆/κ and the maximum
value of Ω set a limit on how close the qubit can come to the target state on average.
In Appendix D, we study scenarios with lower κ and observe that the average ﬁdelity
0.9 is not a limit
can increase and approach unity. We can thus conclude that F
of our design but rather originates from the restricted capability of control operations
considered here.

≈

4. SDE control based on homodyne current

Algorithm 4 Homodyne current
Input: ψ(t0), t0, Ω(t0) = 0
Result: L
for i = 0 : N

−

1 do
compute and store checkpoints
Jτ (t), Ωm(t)
NNθ(
Ω(ti+1)
}
{
ψ(ti+1)
solve(ψ(ti),Ω(ti+1)) for SDE
(8) in [ti, ti+1]

←
←

)

end
L

←

loss(

ψ(ti), Ω(ti)
}

)

{

In this section, we will construct a controller which directly obtains the (noisy)
measurement record of the homodyne current and determines the optimal control ﬁeld
Ω(ti) in each time interval [ti, ti+1]. We consider a controller formed by a slightly
augmented NN architecture with fully connected layers (see Fig. B1). The acquisition
of input data for the NN consists of the following steps:

16

∇

e
(cid:105)
|

using the piecewise-constant control scheme with
Figure 5: Preparation of the state
the discrete AD method to compute the gradients
θL, see Section 2.4, where only the
homodyne current J(t) is used as an input to the controller. (a) Sketch of the acquisition
process of the input data for the NN controller, see Section 4. (b) Evolution of the loss
function L as a function of the training epochs. (c) and (d) Performance of the NN after
400 training epochs [in the ﬁrst plateau of L in panel (b)] for a set 256 trajectories: (c)
Mean ﬁdelity (blue solid lines) and corresponding standard deviation (shaded area), (d)
Corresponding drive amplitudes. (e) and (f) Same quantities as in panels (c) and (d),
but for the fully trained NN, i.e. after 14000 training epochs. Black lines in panels (c-f)
show the results for an initial state
. The hyperparameters are listed in Tab. B1 in
(cid:105)
Appendix B.

g
|

(i) The controller generates a piecewise-constant drive Ω(ti) between two checkpoints
at times ti and ti+1, as described in Section 3.3. In the time window [ti, ti+1], we
integrate the SDE (8) using Nsub substeps of length δt as sketched in Fig. 5(a).
We label these substeps with k. The input for the NN to predict the next Ω(ti+1)
is a vector Jτ (ti) = [δJi1, . . . , δJiNsub]T where τ = Nsubδt is the length of the time
interval over which we gather the data. Experimentally, δt can be interpreted as
the detection time window of the photodetectors. According to Eqs. (4) and (5),
the homodyne measurement in the kth substep is

σx
(cid:104)

δJik = κ

(cid:105)ik δt + √κ δWik .
The ﬁrst term corresponds to the quadrature signal
(cid:105)ik measured over the
detection window δt, which we assume to be approximately constant on time scales
of the order of δt. The second term δWik
Wik is the Wiener increment
during the kth substep. Note that the quantity δJik is dimensionless and solely

Wi(k+1)

(22)

σx

≡

−

(cid:104)

17

represents the number of measured detected photons, as discussed in Appendix A.

(ii) In addition, we provide the NN with the information on the m last control
parameters Ωm(ti) = [Ω(ti−1), . . . , Ω(ti−m)]T . This equips the NN with a “memory”
of its own actions, such that it can take into account how a sequence of the last
control drive amplitudes aﬀected the performance. We empirically choose m such
that the length of the input vector Ωm(ti) corresponds to 1/10 of the length of
Jτ (ti).

[

:

{

∈

−

±

} (cid:55)→

Ω(t)

Given these inputs, the task for the controller is to provide an optimal mapping
Ωmax, Ωmax]. Figure 5(b) shows the evolution of the loss
Jτ (t), Ωm(t)
C
function L during the learning phase as a function of the training epochs. Note that
there are two distinct plateaus. First, after a couple of hundred epochs, the NN develops
a general strategy consisting of the application of a periodic drive to prevent the qubit
from decaying to the ground state. Figures 5(c,d) show examples of the performance
of the NN at epoch 400 to illustrate this phase of the training. This strategy is state-
independent, yet it manages to keep the mean ﬁdelity of the simulated trajectories
around 0.5 over the whole control interval. Around epoch 2500, after some transition
phase where L oscillates substantially, the NN starts to provide state-sensitive control
ﬁelds. The ﬁnal performance of the controller in Fig. 5(e,f) reaches the mean ﬁdelity
FJ = 0.79
0.17 over the whole control interval. During the last 50 time steps in the
control interval, which we speciﬁcally focus on during the training using the adjusted loss
function term of the type (13) for these steps, the average ﬁdelity is F 50
0.12.
At this stage, we infer that the NN has learnt how to extract the signal from the
noisy data before it attains a similar learning strategy as seen in Section 3. In contrast to
the ﬁlter mentioned in Section 2.1 and Appendix A.4, this universal approach based on
∂P will also work if some parameters of the model were a priori unknown. For example,
if the detuning ∆ was unknown, one could train the controller on an ensemble of M
M
randomly chosen parameters
k=1, such that it learns how to deal with the general
situation of arbitrary detuning. In this case a straightforward ﬁltering of the signals to
obtain the state is unfeasible, as this would require to solve the ﬁlter for all possible
values of model parameters, cf. Eq. (A.33). Other options for signal ﬁltering would be
(recursive) backward ﬁltering methods [57, 58] or recurrent neural networks because
their structure allows them to capture temporal correlations in the data [39]. Note
that such ﬁlter methods are compatible with the two-step control approach described
in Section 3.

J = 0.86

∆k

±

}

{

5. Discussion

In this work we proposed a framework based on diﬀerentiable programming (∂P) to
automatically design feedback control protocols for stochastic quantum dynamics. As a
test bed, we used a qubit subjected to homodyne detection, whose dynamics is given by a
stochastic Schr¨odinger equation. Note, however, that our method can straightforwardly

18

be applied to diﬀerent physical systems and that it can be generalized to the case of
stochastic quantum master equations.

In Section 3, we demonstrated that a controller, formed by a NN, can be trained
to prepare and stabilize a target state starting from an arbitrary initial state of the
system when the NN obtains the full knowledge of the instantaneous state at any time.
The method generates a smooth drive Ω(t) while maintaining a high ﬁdelity with the
target state over the whole control interval. Additional constraints on the performance
of the controller can be implemented by adding further terms to the loss function. This
makes the ∂P approach more versatile than tailoring control functions manually, which
requires a unique approach for every new system and can even be infeasible for large
quantum systems.

The key feature of our ∂P framework is to include an explicit model of the system’s
dynamics into the computation of the gradients of the loss function with respect to the
parameters of the NN, i.e. the controller. Speciﬁcally, in Section 3.2, we employed the
recently developed continuous adjoint sensitivity method for the gradient estimation
through an SDE solver, which is memory eﬃcient and, thus, allows us to study a high-
frequency controller. F.S. implemented these new continuous adjoint sensitivity methods
in the DiﬀEqSensitivity.jl package within the open-source SciML ecosystem [55].

In Section 4, we showed that the feedback control scheme can be based directly on
providing the NN with a record of homodyne current measurements without the need
to ﬁlter the information on the actual state beforehand. Therefore, the NN must ﬁrst
learn how to ﬁlter the input data (with poor signal-to-noise ratio) before it can predict
optimal state-dependent values of the control drive. Ultimately, the trained NN was
able to reach ﬁdelities above 85% in a target time interval for random initial states.

In future studies, the optimization of the loss function based on stochastic
trajectories using adjoint sensitivity methods could be compared to alternative
approaches. First, the solution to the stochastic optimal control problem in the
speciﬁc case of Markovian feedback (as in Section 3) is a Hamilton-Jacobi-Bellman
equation [11, 54]. The solution of this partial diﬀerential equation, with same dimension
as the original SDE, may directly give the optimal drive [59]. However, solving this
partial diﬀerential equation with a mesh-based technique is computationally demanding
and mesh-free methods, e.g. based on NNs also require a (potentially costly) training
procedure [60]. Second, the expected values of the loss functions could be optimized
by leveraging the Koopman expectation for direct computation of expected values from
stochastic and uncertain models [61]. Additionally, one could approach this control
problem by using an SDE moment expansion to generate ordinary diﬀerential equations
for the moments and apply a closure relationship [62]. Additional research is required
to ascertain the eﬃciency of these approaches in comparison to our method.

The results reported in this paper imply that ∂P is a powerful tool for the
automated design of quantum control protocols. Further experimental needs, e.g. ﬁnite
time lag between the measurement and the applied drive, ﬁnite-temperature eﬀects, or
imperfect homodyne detection, can be incorporated straightforwardly into this method.

19

Thus, our work introduces a new perspective on how prior physical knowledge can be
encoded into machine learning tools to construct a universal control framework. Besides
the control application demonstrated here, the ∂P paradigm can be also adopted to
solve other inverse problems such as estimating model parameters from experimental
data [63, 64, 65]. An interesting perspective for future work is to extend our framework
to control-assisted quantum sensing and metrology.

Acknowledgment

We would like to thank Niels L¨orch, Eliska Greplova, Moritz Schauer, and Chris
Rackauckas for helpful discussions. We acknowledge ﬁnancial support from the Swiss
National Science Foundation (SNSF) and the NCCR Quantum Science and Technology.
Parts of the computations were performed at sciCORE (scicore.unibas.ch) scientiﬁc
computing core facility at University of Basel.

Data availability statement

The codes that support the ﬁndings of this study are openly available [66].

Appendix A. Continuous homodyne detection

Appendix A.1. Quantum trajectories: monitoring the spontaneous emission of a qubit

Consider a two-level atom interacting with a free photon. In the case of discrete photon
modes, the interaction is given by the usual Hamiltonian ¯Hint = ig(ˆσ+ˆa
ˆσ−ˆa†) with
ˆa† and ˆa being the bosonic creation and annihilation operators, respectively, fulﬁlling
the commutation relation [ˆa, ˆa†] = 1, and g being a coupling constant with dimension of
energy. In contrast to the notation used in the main text, in this appendix, we will mark
operators by a hat to distinguish them from scalars. This Hamiltonian results from the
dipole interaction written in the form ¯Hint
(ˆa + ˆa†)ˆσy and application of the rotating
∝
wave approximation. However, when addressing a decay to the continuum, the photons
are represented by quantum ﬁeld operators with commutation relation [ˆat , ˆa†
s),
thus having units of square root of energy (or, equivalently, inverse square root of time).
The interaction Hamiltonian takes the form

s] = δ(t

−

−

where κ is the decay rate, again, with dimension of energy like g.

ˆHint = i√κ(ˆσ+ˆat

ˆσ−ˆa†

t ) ,

−

(A.1)

The ﬁeld propagator in the interaction picture can be formally written as ˆUτ =
e−i (cid:82) t+τ
is the time-ordering operator. Expanding ˆUδt for short
(cid:104)

, where

ˆHint(s)ds

T

(cid:105)

t

T

times δt, we ﬁnd

ˆUδt =1 + √κ

t+δt

t
(cid:90)
t+δt

(ˆσ+ˆas

−

ˆσ−ˆa†

s)ds

(ˆσ−ˆσ+ˆa†

sˆas(cid:48) + ˆσ+ˆσ−ˆasˆa†

s(cid:48))dsds(cid:48).

20

(A.2)

κ
2

−

t
(cid:90)

0
(cid:105)
|

Here, the second-order terms give an important O(δt) contribution. Higher-order terms
only contribute as O(δt3/2) and can be safely neglected, and we also assume that δt is
short on the timescale of internal qubit dynamics. Assuming the free ﬁeld is originally
in the vacuum state

we can write

1

=

ˆUδt

0
(cid:105)
|

κδt
e
2 |
(cid:105)(cid:104)
is a properly normalized state of the ﬁeld, and

(cid:105)t , where
1
|
e
(cid:105)
|
The simplest way to monitor the qubit state

+ √κ δt ˆσ−

0
(cid:105)
|

−

(cid:17)

(cid:16)

e

|

t+δt

(cid:105)t =
1
|

1
√δt

ˆa†
sds

0
(cid:105)
|

(A.3)

t
(cid:90)
denotes the excited qubit state.
ψ
|

(cid:105)

is then to continuously measure
the intensity of the outgoing ﬁeld. This deﬁnes a Poissonian process, as the probability
to detect a photon in a time interval δt reads

p1 = trqubit

= κδt tr

1
(cid:104)
|
(cid:110)
ˆσ−
{

ˆUδt

ψ
|

(cid:105)(cid:104)

ψ

ψ

0
| ⊗ |

0
(cid:105)(cid:104)
|
ˆσ+
ψ

(cid:105)(cid:104)
= κδt

|

|

}

ˆU †

1
δt |
(cid:105)
(cid:111)
2 ,
ψ
|

(cid:105)|

e
|(cid:104)

(A.4)

p1 respectively. Thus, we obtain the

and the probability of no detection is p0 = 1
standard unraveling for the spontaneous decay process
√κδtˆσ−
ψ
(cid:105)
|
κδt
e
2 |

one photon emitted :

no photons emitted :

−

−

1

,

(cid:105)(cid:104)

(A.5)

.

ψ
|

(cid:105)

e
|

(cid:17)

(cid:16)

Appendix A.2. Weak homodyning

An alternative to photon-counting detection is to mix the outgoing light with coherent
light from a local-oscillator laser on a beamsplitter, and to measure the intensities at
both output ports of the beamsplitter. As a warm-up we ﬁrst consider the situation
where the intensity of the local-oscillator ﬁeld is comparable to the emitted light. It is
given by the expansion of a coherent state using only vacuum and single-photon states
2
β
|
|
2
where the single-photon state of the ˆb-mode is deﬁned identically to the mode ˆa. Mixing
the two states on a 50:50 beamsplitter gives

+ β√δt

√δtβ

(A.6)

1
(cid:105)
|

0
(cid:105)
|

δt

−

=

(cid:19)

(cid:18)

(cid:12)
(cid:12)
(cid:12)

(cid:69)

1

,

ˆUBS

ˆUδt

0
(cid:105)
|

√δtβ

=

1

(cid:69)

(cid:12)
(cid:12)
(cid:12)

(cid:18)

+

+

κδt
e
2 |
(cid:105)(cid:104)

e
| −

β
|

2δt
|
2

−

0, 0
(cid:105)
|

(cid:19)

δt
2
δt
2

(cid:114)

(cid:114)

(cid:0)

(cid:0)

(A.7)

β + √κˆσ−

√κˆσ−

β

−

1, 0
(cid:105)
|

.

0, 1
(cid:105)
|

(cid:1)

(cid:1)

m, which measures the intensity diﬀerence
Introducing the photocurrent variable q = n
of the two outputs, we see that there are three possibilities, q =
1, 0, 1. The respective
probabilities of the three outcomes are given by the norms of the three diﬀerent terms
in Eq. (A.7),

−

−

21

pq=±1 =

δt
2
pq=0 = 1

(cid:10)
−

β2

±
δtβ2

β√κˆσx + κ

δtκ

e
(cid:104)|

(cid:105)(cid:104)

−

ψ ,
e
|
(cid:11)

e
|
(cid:105)(cid:104)
|(cid:105)ψ .
e

(A.8)

The three possible states of the system after the measurement are proportional to

q =

1 :

±
q = 0 :

β

(cid:0)

1
(cid:18)

±

−

,

√κˆσ−
κδt
(cid:1)
e
2 |
(cid:105)(cid:104)

(cid:105)

ψ
|
e
| −

β
|

2δt
|
2

.

ψ
|

(cid:105)

(cid:19)

(A.9)

By setting β = 0 (i.e. no mixing with a local-oscillator ﬁeld), we recover the previous
case where the qubit simply has a chance to decay

q =

1 :

±

√κˆσ−

,

ψ
|

(cid:105)

(A.10)

and pq=1 + pq=−1 = p1. The only diﬀerence is that the emitted photon is randomly split
between the two detectors, with no information about the state of the qubit contained
in the sign of q.

Appendix A.3. Strong homodyning

Finally, we consider the situation treated in the main text. The standard homodyne
measurement requires mixing the signal with a strong coherent local-oscillator ﬁeld
β
|

| (cid:29)

1

∞

=

cn(β)

β
|

(cid:105)

, cn(β) = e−β2/2 βn
√n!

n
|

(cid:105)

.

(A.11)

n=0
(cid:88)
Recall that here the Fock states
ˆb† = 1√
ˆb†
s ds, describing the ﬁeld impinging on the lower port of the beamsplitter
δt
during the interval δt, see Fig. 1(a). For the modes ˆa and ˆb to match, the local-oscillator
laser β has to be in resonance with the drive laser Ω because, in the lab frame, the ﬁeld
at picks up the phase of ˆσ− rotating at the frequency of the drive laser.

are deﬁned with the creation operator

0
n! |
(cid:105)

= ˆb†n
√

t+δt
t

n
(cid:105)
|

(cid:82)

When the modes match, the 50:50 beamsplitter transformation takes the form

ˆUBS

ˆa†
ˆb†

(cid:18)

=

(cid:19)

(cid:18)

ˆa†−ˆb†
√
2
ˆa†+ˆb†
√

.
2 (cid:19)

(A.12)

In particular, this implies ˆUBS
, β√
β√
of the mode
2
2
b is split into two coherent states of half the intensity when mixed with the vacuum
(cid:69)
of the mode a on a 50:50 beamsplitter. Using the last two expressions, we can
state

, i.e. a coherent state

0, β
|

β
|

=

(cid:105)

(cid:105)

(cid:12)
(cid:12)
(cid:12)

0
(cid:105)
|

write down the overall state of the qubit, the spontaneously emitted radiation and the
homodyne laser ﬁeld after the beamsplitter. To do so, let us compute

22

˜Uδt = (ˆ1qubit

ˆUBS)( ˆUδt

⊗
ˆ1qubit)

⊗

⊗

ˆ1laser)
κδt
e
2 |

(cid:105)(cid:104)

(cid:105)

β

0
(cid:105) |
|
+ √κδtˆa†ˆσ−
e
|

0, β
|

(cid:105)

(cid:19)

(A.13)

1
(cid:18)

−

= ( ˆUBS

=

1
(cid:32)

−

κδt
e
2 |
(cid:105)(cid:104)

e

|

+

(cid:114)

κδt
2

(ˆa†

−

ˆb†)ˆσ−

β
√2

,

β
√2

,

(cid:29)

(cid:33) (cid:12)
(cid:12)
(cid:12)
(cid:12)

which is the operator mapping the state of the qubit at time t to the state of the qubit
and the two detected modes at time t + δt. We can further simplify this expression by
noting that

= e−β2/2

ˆa†

β
|

(cid:105)

= e−β2/2

n=0
(cid:88)

n=0
(cid:88)
,

=

ˆn
β |

β

(cid:105)

βn
√n!

(cid:105)

ˆa†

n
|
βn+1
(n + 1)!

(cid:112)

βn
√n!

√n + 1

n + 1
|

(cid:105)

= e−β2/2

n=0
(cid:88)
= e−β2/2

n + 1
β

βn
√n!

n
β |

n

(cid:105)

n=0
(cid:88)

(A.14)

where ˆn = ˆa†ˆa is the photon number operator. Labeling the photon number operator
for the ˆb mode as ˆm = ˆb†ˆb, we can then rewrite Eq. (A.13) in a very intuitive form

˜Uδt =

(cid:18)

κδt
e
2 |
(cid:105)(cid:104)

e
|

1

−

+ √κδt

ˆn

−
β

ˆm

ˆσ−

β
√2

,

β
√2

.

(cid:29)

(A.15)

directly gives us the state of the qubit and the detected modes, while

(cid:19) (cid:12)
(cid:12)
(cid:12)
(cid:12)

Again, ˜Uδt

ψt
|

(cid:105)

n, m
|
(cid:104)

˜Uδt

ψt
|

(cid:105)

= √pn,m

ψt+δt
|

n,m
|

(cid:105)

(A.16)

gives the conditional state of the qubit together with the probability to detect n and m
photons respectively. In the measurement process, superpositions of states with diﬀerent
photon numbers collapse such that the state after the post-measurement is a classical
statistical mixture of the possible outcomes,

∞

pn,m

ψt+δt
|

n,m
|

(cid:105)(cid:104)

ψt+δt

n,m
|

| ⊗ |

n, m

(cid:105)(cid:104)

n, m
|

.

(A.17)

n,m=0
(cid:88)
One easily sees from Eq. (A.15) that

only the
n,m
|
m) of the photon counts reveals information on the state of the qubit,
diﬀerence (n
while the sum (n + m) only describes the shot noise of the local oscillator. It is therefore
m and discard the sum, which deﬁnes the state
suﬃcient to keep the diﬀerence q = n

ψt+δt
|

ψt+δt
|

n−m
|

i.e.

−

=

(cid:105)

(cid:105)

,

−

∞

q=−∞
(cid:88)

pq

ψt+δt
|

q
|

(cid:105)(cid:104)

ψt+δt

q
|

| ⊗ |

,

q

q

|

(cid:105)(cid:104)

where

pq =

pn,n+q.

(A.18)

∞

(cid:88)n=max(0,−q)

In a slight abuse of notation we can formally introduce the joint quantum state of the
qubit and the count diﬀerence q as ˆUδt

with

ψt
|

(cid:105)

23

ˆUδt =

1
(cid:18)

−

κδt
e
2 |

e
|

(cid:105)(cid:104)

+ √κδt

ˆq
β

ˆσ−

˜Φβ

(cid:69)

(cid:19) (cid:12)
(cid:12)
(cid:12)

where

˜Φβ

=

µj(β)

∞

(cid:69)

q=−∞ (cid:113)
(cid:88)

(cid:12)
(cid:12)
(cid:12)

,

q
|
(cid:105)
(A.19)

ˆq

q
|

(cid:105)

= q

q
|

, which gives rise to the same post-measurement state. Here,
(cid:105)

∞

µq(β) =

n(β/√2)c2
c2

n+q(β/√2) = e−β2Iq(β2),

(A.20)

(cid:88)n=max(0,−q)
where In(z) is the modiﬁed Bessel function of the ﬁrst kind.

Next, we use that the distribution of q on the right-hand side of Eq. (A.20) is well
1. Therefore, we

(0, β2) in the limit β

approximated by the normal distribution
can replace the state

(cid:29)
of an integer-valued q in Eq. (A.19) with

N

˜Φβ

(cid:12)
(cid:12)
(cid:12)

(cid:69)

=

Φβ
|

(cid:105)

∞

−∞ (cid:20)
(cid:90)

1
√2πβ

exp(

−

q2
2β2 )

1/2

(cid:21)

dq

q
|

(cid:105)

(A.21)

of a continuously valued and normally distributed q, and we also introduce a
continuously valued operator ˆq.
1 the actual value of
β does not play a role. To get rid of it, recall that β2 = Iδt is the intensity of the
local-oscillator laser in the time window δt, so it is more convenient to work with the
laser power I, which is independent of the choice of the time window δt. Then, we can
rescale the photon count diﬀerence to

In the regime of interest β

(cid:29)

j =

κ
I

q

(cid:114)

to get rid of the laser intensity. Equation (A.19) now reads

Uδt =

(cid:18)

κδt
e
2 |
(cid:105)(cid:104)

e

|

1

−

+ ˆj ˆσ−

,

Φ
|

(cid:105)

(cid:19)

(A.22)

(A.23)

where the initial state

Φ
|

(cid:105)

of the rescaled j can be obtained form Eq. (A.21) and satisﬁes

P0(j) =

j

|(cid:104)

Φ
|

(cid:105)|

2 =

1
√2πκδt

exp

j2
2κδt

.

(cid:19)

−

(cid:18)

(A.24)

This also allows us to deﬁne the homodyne current of the main text J = j/δt, as the
photon count diﬀerence per time. At this point note that Eq. (A.23) already implies
Eq. (3). Let us now show how the measured value of j is distributed. The marginal

distribution of j after the measurement reads

j
(cid:104)

1

−

|

(cid:18)

κδt
e
2 |
(cid:105)(cid:104)

e
|
2

+ ˆj ˆσ−

(cid:19)

ψt

Φ
|

(cid:105) |

2

=

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
κδt
(cid:12)
(cid:12)
(cid:12)
e
(cid:12)
(cid:12)
2 |
(cid:105)(cid:104)

e

|

P (j) =

ˆUδt

j

(cid:104)

|

ψt
|

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
= P0(j)

= P0(j)

= P0(j)

(cid:105)
(cid:12)
(cid:12)
(cid:12)
−

1

1
(cid:12)
(cid:12)
(cid:18)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
ψt
(cid:12)
(cid:12)
(cid:104)

|

(cid:16)

−
(cid:18)
1 + (j2

+ j ˆσ−

ψt
|

(cid:19)
+ j ˆσ+

(cid:105)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
1
(cid:12)
(cid:12)
(cid:19) (cid:18)
(cid:105)ψ + j

ˆσx
(cid:104)

κδt
e
2 |
(cid:105)(cid:104)

e

|

κδt)

ˆσ+ˆσ−
(cid:104)

−

.

(cid:105)ψ

(cid:17)

κδt
e
2 |
(cid:105)(cid:104)

e

|

−

+ j ˆσ−

ψt
|

(cid:105)

(cid:19)

From P (j) one easily deduces the expected value and the variance of j

24

(A.25)

2

(cid:105)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

E(j) = κδt

ˆσx
(cid:104)

(cid:105)ψ

Var(j) = κδt.

(A.26)

Clearly, it has the form of a Wiener process with drift

j = κ

ˆσx
(cid:104)

(cid:105)ψ δt + √κ δW,

(A.27)

where δW is the increment of a Wiener process for an interval δt (a normally distributed
random variable with zero mean and variance δt). The last step is to include the
Hamiltonian of the qubit ˆH = 1
κ−1, ∆−1, Ω−1 in order to get

2 (∆ˆσz + Ω(t)ˆσx) and set dt = δt such that I −1

(cid:28)

(cid:28)

dt

ˆUdt =

1
(cid:18)
with

−

i∆ˆσz + iΩ(t)ˆσx + κ ˆσ+ˆσ−)

(cid:0)
Φ
(cid:105)
|

=

∞

−∞

(cid:90)

P0(j)

dj.

j
|

(cid:105)

(cid:112)

dt
2

+ ˆj ˆσ−

,

Φ
|

(cid:105)

(cid:19)

(A.28)

Appendix A.4. Formal solution of the stochastic dynamics as a ﬁlter

The expression of the inﬁnitesimal time evolution ˆUdt we just derived can be composed
for all time intervals to deﬁne the evolution over a long period [0, t]

ˆUt = ˆUdt(t

−

dt) . . . ˆUdt(dt) ˆUdt(0),

(A.29)

where each time step introduces a new quantum system for the photon detection
diﬀerence measured during the corresponding inﬁnitesimal interval. The joint state
of the qubit and all values of the observed homodyne current for s
[0, t] at the ﬁnal
time t reads

∈

ˆUt

=

ψ0
|

(cid:105)

T

exp

(cid:20)

0
(cid:18)(cid:90)

t

∆
2

i
(
−

ˆσz

i

Ω(s)
2

ˆσx

−

−

κ
2

ˆσ+ˆσ− + J(s)ˆσ−)ds

(cid:19)(cid:21) (cid:79)

s

Φs
|

ψ0

(cid:105) |

.

(cid:105)

(A.30)

Hence, for any ﬁxed values of the measured current J(s) = js/ds we can ﬁnd the
(unnormalized) state of the qubit conditioned on these outcomes

25

ˆUt

js

|

ψ0
|

(cid:105)

= cJ

ˆDt

ψ0
|

(cid:105)

, where

s (cid:104)
(cid:79)
ˆDt =

(cid:81)

T

(cid:20)
Φs
|

exp

t

∆
2

i

(
−

ˆσz

i

Ω(s)
2

ˆσx

−

−

κ
2

0
(cid:18)(cid:90)

ˆσ+ˆσ− + J(s)ˆσ−)ds

(cid:19)(cid:21)

(A.31)

and cJ =
the qubit at time t conditioned on the homodyne detection record reads

is a scalar independent of the input state

ψ0
|

. Thus, the state of
(cid:105)

s(cid:104)

js

(cid:105)

and for mixed initial states ˆρt

ψt
|
ˆDt ˆρ0

ˆDt

,

ψ0
|

(cid:105)

(cid:105) ∝
t . The expression of the operator

ˆD†

t

0 (cid:32)

(cid:90)

i∆
−
iΩ(s)

−

−

iΩ(s) + 2J(s)

i∆

κ

−

ds

(cid:33)

(cid:35)

(A.32)

(A.33)

∝
1
2

ˆDt =

exp

T (cid:34)

can be thought of as a ﬁlter relating the record of the drive ﬁelds Ωt and the values of
the measured homodyne current Jt to the map between the states of the qubit at times
0 and t, represented here by a two-by-two complex matrix. In a real experiment ˆDt can
be computed by, e.g. discretizing the integral.

Notably, even if the initial state of the qubit is unknown, e.g. ˆρ0 = 1
2

ˆ1, after a

certain characteristic time the state

ˆρt =

ˆDt ˆρ0
ˆDt ˆρ0

ˆD†
t
ˆD†
t

tr

(A.34)

(cid:104)
becomes pure. This is because the stochastic dynamics essentially decouples the state of
the system at time t from its state in a far-away past. On the other hand the measured
homodyne current Jt reveals information about the unknown initial state and we have
just shown how to ﬁlter this information, as

(cid:105)

for any two initial states

and

ψ0
|

(cid:105)

P (Jt
P (Jt

|ψ0(cid:105))
|
|φ0(cid:105))
|
φ0
|

.
(cid:105)

ˆDt
ˆDt

= (cid:107)
(cid:107)

ψ0
|
φ0
|

2
(cid:105) (cid:107)
2
(cid:105) (cid:107)

(A.35)

Appendix A.5. Derivation of the norm-preserving stochastic Schr¨odinger equation

We start with the stochastic Schr¨odinger equation (3) which does not preserve the norm
of the state

ψ(t)
|

. Using
(cid:105)

˜
d ˜ψ
ψ
(cid:104)
(cid:105)
|
we can derive the corresponding stochastic quantum master equation

d ˜ψ
(cid:105)(cid:104)
|

+ ˜
ψ
|

d ˜ψ
|

d ˜ψ
|

d˜ρ =

+

(cid:105)(cid:104)

|

,

(A.36)

d˜ρ =

i[ ˆH, ˜ρ]dt + κ

−

D

[ˆσ−]˜ρdt + √κJ(t)

ˆσ− ˜ρ + ˜ρˆσ†
−

dt

(A.37)

(cid:16)

(cid:17)

which does not preserve the norm of the density matrix. Note that the last term in
Eq. (A.36) contains a contribution of order dt since dW 2 = dt. The last term in
Eq. (A.37) shows that the state ˜ρ depends on the homodyne signal J(t), but it does not
preserve the norm of ˜ρ during the time evolution. This can be compensated by adding
a correction term

26

√κ (J(t)dt

−

−

dW )

ˆσ− ˜ρ + ˜ρˆσ†
−

√κ

(cid:104)

−

ˆσ− + ˆσ+

(cid:105)

˜ρdW ,

(A.38)

which cancels the last term in Eq. (A.37) without introducing any new norm-
nonconserving terms. On the level of the stochastic Schr¨odinger equation, this term
can be generated by adding a contribution

(cid:16)

(cid:17)

κ
2 (cid:104)

−

(cid:20)

ˆσ− + ˆσ+

ˆσ−dt

(cid:105)

−

κ
8 (cid:104)

ˆσ− + ˆσ+

2 dt

(cid:105)

−

√κ
2 (cid:104)

ˆσ− + ˆσ+

dW

(cid:105)

(cid:21)

,

ψ
|

(cid:105)

(A.39)

which gives rise to Eq. (8) of the main text.

Appendix B. Neural network architectures and hyperparameters

The hyperparameters used in the control tasks are summarized in Tab. B1. The
In all NNs, we use
architecture of the NN used in Section 4 is shown in Fig. B1.
ReLUs as activation functions for hidden layers and the softsign activation function for
the last layer. Modiﬁcations of this simple architecture, e.g. through the application of
recurrent neural networks to capture temporal correlations in the homodyne current for
the SDE control in Section 4, might be essential for the control of complex many-body
quantum systems.

In this work, we used NNs as universal function approximators. While this approach
is very general, other choices of a controller, e.g. Chebychev polynomials or Fourier basis
expansions, could boost the performance for low-dimensional inputs as in the case of a
qubit, because they can be optimized to the problem at hand. The use of the sparse
identiﬁcation for dynamical system method [67, 68, 69] or symbolic regression tools [70]
could further allow one to replace the trained NNs by a symbolic description based on
a pre-deﬁned library of operators.

Appendix C. Continuous adjoint sensitivity method for ODEs and SDEs

In this appendix, we discuss the continuous adjoint sensitivity method for ordinary
diﬀerential equations (ODEs) and its generalization to SDEs used in the main text.
In Appendix C.1, the continuous adjoint sensitivity method for ODEs is used to compare
the stochastic control scenario discussed in Section 3.2 with the associated unitary
control scenario in the case of a closed system. In Appendix C.2, we provide an intuitive
understanding for the stochastic adjoint process and discuss technical details regarding
In
the continuous adjoint sensitivity method for SDEs and its implementation [55].
all implementations, we use an isomorphism to map the complex amplitudes of the
quantum state to real numbers, as required by the AD backend [71].

ψ(t)
|

(SDE)

(cid:105)
Section 3.2 Section 3.3

27

J(t) (SDE)

Section 4

(ODE)

ψ(t)
|
(cid:105)
Appendix C.1

solver

scheme EulerHeun
200
10−4κ−1

Nsub
dt

RKMil
20
10−3κ−1

loss function

cF
cF 50
cΩ

Adam optimizer

learning rate
batchsize b
epochs

NN

1
0
0

0.8
1.8N/50
10−3

0.0015
64
1000

0.0001
64
3000

(4, 256)
(256, 64)
(64, 1)

(4, 256)
(256, 128)
(128,64)
(64, 1)

LLS 1
LLS 2
LLS 3
LLS 4
LLA 1
LLA 2
LLC 1
LLC 2
LLC 3

2.5

·

RKMil
80
10−4κ−1

1.2
0.8N/50
10−3

0.0001
64
14000

(Nsub, 256)
(256, 256)
(256, 128)

(Nsub/10, 128)
(128, 128)
(256, 64)
(64, 32)
(32, 1)

Tsit5

adaptive

1
0
0

0.0015
256
400

(4, 256)
(256, 64)
(64, 1)

Table B1: Hyperparameters employed to train the neural networks in the case of
continuously updated control parameters (Section 3.2), piecewise-constant control
parameters with knowledge of the state
(Section 3.3), piecewise-constant control
ψ
(cid:105)
|
parameters with knowledge of the homodyne current (Section 4), and the closed-system
dynamics described by the Schr¨odinger equation (Appendix C.1). The number of
checkpoints is N = 150 for all simulations. The value of Nsub gives the number the
solver substeps between the checkpoints. The coeﬃcient cF 50 refers to the modiﬁcation
of the loss function (13) which is limited to the last 50 steps of the control interval.
Speciﬁcations of the solvers are provided in the SciML documentation [40].
‘LLS n’,
‘LLA n’ and ‘LLC n’ denotes the nth linear-layer state-aware, action-aware, and
combination-aware network, respectively. The numbers of input and output channels of
the layers are speciﬁed in the brackets.

28

over the time interval [ti

Figure B1: Scheme of the NN used in Section 4 which consists of three segments of fully
connected networks. The ﬁrst one, the state-aware NNsa, obtains the vector Jτ (ti) which
bears the information on the state of the controlled system in form of its quadrature
τ, ti]. Similarly, the action-aware NNaa takes as an input
σx
(cid:104)
a vector Ωm(ti) of the last m actions taken prior to the time ti. The output of NNsa
and NNaa is concatenated into a vector and enters the last segment, which we refer to as
combination-aware NNca. The ﬁnal output is the next drive value Ω(ti+1) to be applied.
The parameters of the network can be found in Tab. B1.

−

(cid:105)

Appendix C.1. Quantum control of a qubit in a closed system

In this section, we aim at controlling the closed-system dynamics of a qubit given by
the Schr¨odinger equation

with Hamiltonian

d

ψ(t)
|

(cid:105)

=

−

iH CS

ψ(t)
(cid:105)
|

dt =: K CS

ψ(t)dt ,

H CS =

∆
2

σz +

Ω(t)
2

σx ,

(C.1)

(C.2)

where ∆ is the qubit transition frequency [10]. As in Section 3.2, we choose a NN
with parameters θ as the controller ansatz and we allow the NN to change the control
drive Ω(t) in every time step based on the state
. The initial states are uniformly
ψ(t)
(cid:105)
|
distributed on the Bloch sphere, see Eq. (11). We compute the forward pass, Eq. (C.1),
with the adaptive Tsitouras 5/4 embedded Runge-Kutta (Tsit5) scheme as implemented
in the DiﬀerentialEquations.jl package [40]. Given this solution, we use the loss
function (12) with weights cF = 1, cΩ = 0. As discussed in Section 2.3, it depends
on the checkpoints at times

).

N
i=1, L = L(

ψ(ti)

As discussed in Section 2.4, the continuous adjoint sensitivity method circumvents
the memory issues of discrete reverse-mode AD and scales better with the number of
parameters than forward-mode AD. To derive this adjoint method, one ﬁrst adds a zero
to the loss function, Eq. (12), and rewrites it as a time integral

{|

(cid:105)}

ti

{

}

I(θ) =

tN

t0 (cid:34)

(cid:90)

1
N

N

1

i=0
(cid:88)

(cid:0)

ψtar
ψ(ti)
|

2
(cid:105)|

− |(cid:104)

δ(t

ti)

−

−

λ†(t)

(cid:1)

˙
ψ
|

(cid:105) −

(cid:16)

K CS

ψ(t)(θ)

(cid:17)

dt , (C.3)

(cid:35)

where we inserted LF deﬁned in Eq. (13) and introduced the Lagrange multiplier λ,
θL(θ). After an integration by parts and re-
such that I(θ) = L(θ) and
θL requires
arrangement of terms for

∇
θI(θ), one ﬁnds that computing the gradients

θI(θ) =

∇

∇

∇

state-awareaction-awarecombination-awareto evaluate the time evolution of the quantity aψ(t) = λ†(t). This leads to the gradients
for all times t and is called

ψ(t)L of the loss function with respect to the state

ψ(t)
(cid:105)
|

∇
the adjoint process:

The associated adjoint ODE problem satisﬁes the diﬀerential equation [11, 51, 72, 73, 74]

aψ(t) =

ψ(t)L .

∇

(C.4)

29

daψ(t) =

a†

ψ(t)

−

(cid:16)

aψ(t0) = aψ(tN ) +

with the initial condition

ψ(t)

· ∇
t0

tN (cid:34)

(cid:90)

K CS

ψ(t)dt ,

(cid:17)
daψ(t)

dt −

i(cid:54)=N
(cid:88)

δ(t

ti)

∇

−

ψ(ti)L

(cid:35)

dt ,

aψ(tN ) =

ψ(tN )L(

{|

ψ(ti)

(cid:105)}

) .

∇

(C.5)

(C.6)

This adjoint ODE is deﬁned backwards in time from tN to t0. To compute the
vector-Jacobian products in Eq. (C.5), one needs to know the value of the state
ψ(t)
(cid:105)
|
along its entire trajectory, which has been computed in the forward pass. Thus, we must
store these states or recompute them by solving the ODE backwards in time starting
from the ﬁnal value

ψ(tN )
|

,
(cid:105)

ψ(t)
(cid:105)
|

=

ψ(tN )
(cid:105)
|

+

K CS

ψ(t(cid:48))dt(cid:48)

t

tN

(cid:90)

(C.7)

together with the adjoint process. This does not introduce a signiﬁcant memory
overhead. Computing the gradients
θL requires yet another integral, which depends
∇
and aψ(t), respectively. With the initial
on the original and the adjoint process,
condition

ψ(t)
(cid:105)
|

aθ(tN ) = 0Dim[θ] ,

the gradients

∇

θL = aθ(t0) are determined by

daθ(t) =

−

a†

ψ(t)

θ

· ∇
t0

(cid:16)

aθ(t0) = aθ(tN ) +

K CS

ψ(t)dt ,

(cid:17)
daθ(t)
dt

dt ,

(cid:90)
Therefore, the gradients of the loss function

tN

θL with respect to the neural network
parameters θ can be obtained by a single (adjoint) ODE with an augmented state given
by

, aψ(t), and aθ(t).
ψ(t)
(cid:105)
|
Because of the reversion of the ODE, Eq. (C.7) may be numerically unstable.
Therefore, we use an interpolating adjoint algorithm to increase stability [11]. When
solving the augmented state backwards in time, we recompute the forward pass
sequentially for all time intervals [ti, ti+1] between two checkpoints. Then, fourth-order

∇

(C.8)

(C.9)

interpolations of the recomputed forward pass are used to compute the vector-Jacobian
products for the reverse pass.

30

The results of the closed-system control task are shown in Fig. C1. We observe a
very fast and smooth learning process with our physics-informed RL framework. The
is an eigenstate of the Hamiltonian (C.2) for Ω = 0, therefore, the control
target state
is reached. Figures C1(d) and (e) show
drive Ω is switched oﬀ once the target state
that the control strategy, illustrated on the Bloch sphere and with a stereographic
projection, resembles the stochastic case discussed in the main text.

e
(cid:105)
|

e
|

(cid:105)

e
(cid:105)
|

Figure C1: Preparation of the state
in a closed system described by the Hamiltonian,
Eq. (C.2), based on RL and ∂P. (a) Loss function, Eq. (12), as a function of training
epochs. Means (blue/red) and standard deviations (shaded) for (b) ﬁdelity and (c)
control parameters, respectively, as a function of the steps i at which checkpoints are
stored. The black line in (c,d) as well as the yellow dots in (d) highlight the special case
of the initial state
. (d) Bloch sphere with color coding representing Ω and vector ﬁeld
(cid:105)
at that position. (e) Stereographic
showing the inﬁnitesimal evolution of the state
projection of the southern hemisphere of the Bloch sphere according to Eq. (21). The
employed hyperparameters can be found in Tab. B1 in Appendix B.

ψ
|

g
|

(cid:105)

Appendix C.2. Technical details of the continuous adjoint sensitivity method for SDEs

To generalize the continuous adjoint sensitivity method for ODEs to Itˆo SDEs, one ﬁrst
needs to ﬁgure out how the sample path of an SDE can be reversed, i.e. how one can

(b)(c)(a)xz(d)(e)0y31

reconstruct the forward pass of the state
evolution from tN to t0 launched at

from time t0 to tN by a reversed time

ψ(t)
|
(cid:105)
. The reversion of an SDE
ψ(tN )
(cid:105)
|

= ˜Kψ(t)dt + Mψ(t)

ψ
d
|

(cid:105)

dW (t) ,

◦

deﬁned in the Stratonovich sense, is given by [52, 53]

ψ(t)
(cid:105)
|

=

ψ(tN )
(cid:105)
|

+

t

tN

(cid:90)

˜Kψ(t(cid:48))dt(cid:48) +

t

tN

(cid:90)

Mψ(t(cid:48))

◦

dW (t(cid:48)) ,

(C.10)

(C.11)

with noise values W (t) identical to those sampled in the forward pass. This closely
resembles the reversion in case of an ODE shown in Eq. (C.7). To restore the noise, we
use a dense noise grid of the noise values used in the forward pass. The memory overhead
caused by using a noise grid could be traded against speed by using a virtual Brownian
tree [52] or a Brownian interval [53], which enable the reconstruction of W (t) by storing
only very little information such as the seed of the employed pseudo-random number
generator. Despite the allocation of the noise values, the continuous stochastic adjoint
sensitivity method is still much more memory eﬃcient than a discrete reverse-mode AD
backpropagation through the solver operations.

From the reverse Stratonovich SDE, Eq. (C.11), we can straightforwardly obtain

the reverse Itˆo SDE

t

ψ(t)
|

(cid:105)

=

ψ(tN )
|

(cid:105)

+

Kψ(t(cid:48))

−

2C IS

ψ(t)

dt(cid:48) +

tN

(cid:90)

tN

(cid:90)

(cid:0)
of the monitored qubit, Eq. (8), where the standard conversion rule

(cid:1)

t

Mψ(t(cid:48))dW (t(cid:48))

(C.12)

C IS

ψ(t) =

1
2

Mψ(t)

· ∇

ψ(t)

Mψ(t)

(C.13)

in Eq. (C.12) accounts for the required transformation from Itˆo to the Stratonovich
sense and vice versa [54].

(cid:0)

(cid:1)

Analogously to the ODE case, taking the scalar loss function L, Eq. (12), the adjoint

process

to compute the gradients of L with respect to the state
of the adjoint Itˆo SDE

aψ(t) =

ψ(t)L(

{|

∇

ψ(ti)

)

(C.14)

is now a strong solution [54]

(cid:105)}
ψ(t)
(cid:105)
|

daψ(t) =

−

a†

ψ(t)

ψ(t)

· ∇

with the initial condition

(cid:16)

Kψ(t)

−

2C IS

ψ(t)

dt

(cid:1)

(cid:17) (cid:0)

a†

ψ(t)

−

(cid:16)

ψ(t)

· ∇

(cid:17)

Mψ(t)dW (t)

(C.15)

aψ(tN ) =

ψ(tN )L(

{|

ψ(ti)

(cid:105)}

) .

∇

(C.16)

Again, the value of the state
of the forward pass is seen to be embedded in the
vector-Jacobian products within the backward pass and, therefore, the knowledge of the

ψ(t)
|

(cid:105)

32

state
the state

ψ(t)
(cid:105)
|
ψ(t)
(cid:105)
|

along its trajectory is necessary. Using Equation (C.12), we can recompute

without having to store the full trajectory of the forward pass.

This SDE can be augmented by the additional quantity aθ(t) to compute the

gradients aθ(t0) =

θL. It is the solution of the stochastic diﬀerential equation

daθ(t) =

−

∇
a†

ψ(t)

(cid:16)

θ

· ∇

with the initial condition

Kψ(t)

−

2C IS

ψ(t)

dt

(cid:1)

(cid:17) (cid:0)

a†

ψ(t)

−

(cid:16)

θ

· ∇

(cid:17)

Mψ(t)dW (t)

(C.17)

aθ(tN ) = 0Dim[θ] .

(C.18)

As a consequence of the scalar noise character of the forward SDE, Eq. (8), the
adjoint SDE with an augmented state according to Eqs. (C.12), (C.15), and (C.17) also
has scalar noise. Similar to the ODE setting, solving SDEs backwards is not guaranteed
to be stable. Thus, to improve the stability, we modify this approach by resetting the
reverse integration using the checkpoints

.

ψ(ti

{|

(cid:105)}

Appendix D. The eﬀect of the decay rate κ on the ﬁdelity F

≈

In the main text, we report mean ﬁdelities of about F
0.9 averaged over the whole
control interval including the very low ﬁdelities due to the transient initial dynamics.
This value of the ﬁdelity is determined by the physical parameters of the quantum system
(∆, κ) as well as by the experimental limitations of the control scheme (e.g. Ωmax and
the feedback control frequency). We note that these parameters are setup-speciﬁc and
do not represent a hard ﬁdelity limit for our proposed control scheme. In Figure D1,
we demonstrate that the mean ﬁdelity over the full time interval as well as the ﬁnal
state inﬁdelity can easily be improved by decreasing the decay rate κ with respect to
the detuning ∆. In the limit κ/∆
0, one recovers a ﬁdelity close to unity comparable
to the closed-system case, see Appendix C.1. We further see that the diﬀerence between
the trained NN and the hand-crafted strategy gets more pronounced as κ is decreased.

→

References

[1] D. D’Alessandro, Introduction to quantum control and dynamics. Chapman & Hall/CRC, 2008.
[2] H. M. Wiseman and G. J. Milburn, Quantum measurement and control. Cambridge University

Press, 2009.

[3] S. J. Glaser, U. Boscain, T. Calarco, C. P. Koch, W. K¨ockenberger, R. Kosloﬀ, I. Kuprov, B. Luy,
S. Schirmer, T. Schulte-Herbr¨uggen, et al., “Training Schr¨odinger’s cat: quantum optimal
control,” The European Physical Journal D, vol. 69, no. 12, pp. 1–24, 2015.

[4] J. Zhang, Y. xi Liu, R.-B. Wu, K. Jacobs, and F. Nori, “Quantum feedback: Theory, experiments,

and applications,” Physics Reports, vol. 679, pp. 1 – 60, 2017.

[5] R. S. Sutton and A. G. Barto, Reinforcement Learning: An Introduction. The MIT Press,

second ed., 2018.

[6] T. P. Lillicrap, J. J. Hunt, A. Pritzel, N. Heess, T. Erez, Y. Tassa, D. Silver, and D. Wierstra,
“Continuous control with deep reinforcement learning,” in International Conference on Learning
Representations (Poster), 2016.

33

e
(cid:105)
|

Comparison of the preparation of the state

Figure D1:
for the continuously
monitored qubit described by the SDE (8), based on continuously updated control
(a) The solid red line shows the mean
parameters for diﬀerent values of κ/∆.
ﬁdelity F (ti) as a function of the time steps ti at which checkpoints are stored in
the case of κ/∆ = 0.001 and the neural network trained using the continuous adjoint
sensitivity method with κ/∆ = 0.05 of Sec. 3.2 (red). The shaded region represents the
corresponding standard deviation. (b) Average ﬁdelity over all time steps i as a function
of κ/∆ for the neural network from (a) (red) and the hand-crafted control strategy of
Sec. 3.1 (blue). (c) Average ﬁnal-state inﬁdelity (solid lines) and corresponding standard
deviation (shaded regions) as a function of κ/∆ for the neural network from (a) (red)
and the hand-crafted control strategy of Sec. 3.1 (blue). The mean values and standard
deviations are computed for a set of 512 randomly sampled initial states on the Bloch
sphere. The hyperparameters are listed in Tab. B1.

[7] M. Y. Niu, S. Boixo, V. N. Smelyanskiy, and H. Neven, “Universal quantum control through deep

reinforcement learning,” npj Quantum Information, vol. 5, no. 1, p. 33, 2019.

[8] M. Bukov, “Reinforcement learning for autonomous preparation of Floquet-engineered states:

Inverting the quantum Kapitza oscillator,” Physical Review B, vol. 98, p. 224305, Dec 2018.

[9] M. Bukov, A. G. R. Day, D. Sels, P. Weinberg, A. Polkovnikov, and P. Mehta, “Reinforcement
learning in diﬀerent phases of quantum control,” Physical Review X, vol. 8, p. 031086, Sep 2018.
[10] F. Sch¨afer, M. Kloc, C. Bruder, and N. L¨orch, “A diﬀerentiable programming method for quantum

control,” Machine Learning: Science and Technology, vol. 1, p. 035009, 2020.

[11] C. Rackauckas, Y. Ma, J. Martensen, C. Warner, K. Zubov, R. Supekar, D. Skinner, and
A. Ramadhan, “Universal diﬀerential equations for scientiﬁc machine learning,” arXiv preprint
arXiv:2001.04385, 2020.

[12] N. Leung, M. Abdelhafez, J. Koch, and D. Schuster, “Speedup for quantum optimal control
from automatic diﬀerentiation based on graphics processing units,” Physical Review A, vol. 95,
p. 042318, Apr 2017.

[13] M. Abdelhafez, D. I. Schuster, and J. Koch, “Gradient-based optimal control of open quantum
systems using quantum trajectories and automatic diﬀerentiation,” Physical Review A, vol. 99,
p. 052327, May 2019.

[14] C. Rackauckas, A. Edelman, K. Fischer, M. Innes, E. Saba, V. B. Shah, and W. Tebbutt,
“Generalized physics-informed learning through language-wide diﬀerentiable programming.,”
in AAAI Spring Symposium: MLPS, 2020.

[15] H.-J. Liao, J.-G. Liu, L. Wang, and T. Xiang, “Diﬀerentiable programming tensor networks,”

34

Physical Review X, vol. 9, p. 031041, 2019.

[16] C. Rackauckas, M. Innes, Y. Ma, J. Bettencourt, L. White, and V. Dixit, “Diﬀeqﬂux.jl – a Julia

library for neural diﬀerential equations,” arXiv preprint arXiv:1902.02376, 2019.

[17] R.-B. Wu, H. Ding, D. Dong, and X. Wang, “Learning robust and high-precision quantum

controls,” Physical Review A, vol. 99, p. 042327, Apr 2019.

[18] L. Coopmans, D. Luo, G. Kells, B. K. Clark, and J. Carrasquilla, “Protocol Discovery for the
Quantum Control of Majoranas by Diﬀerential Programming and Natural Evolution Strategies,”
arXiv preprint arXiv:2008.09128, 2020.

[19] H.-P. Breuer and F. Petruccione, The theory of open quantum systems. Oxford University Press,

2002.

[20] T. Briant, P. Cohadon, M. Pinard, and A. Heidmann, “Optical phase-space reconstruction of
mirror motion at the attometer level,” The European Physical Journal D - Atomic, Molecular,
Optical and Plasma Physics, vol. 22, pp. 131–140, Jan 2003.

[21] K. Iwasawa, K. Makino, H. Yonezawa, M. Tsang, A. Davidovic, E. Huntington, and A. Furusawa,
“Quantum-limited mirror-motion estimation,” Phys. Rev. Lett., vol. 111, p. 163602, Oct 2013.
[22] W. Wieczorek, S. G. Hofer, J. Hoelscher-Obermaier, R. Riedinger, K. Hammerer, and
M. Aspelmeyer, “Optimal state estimation for cavity optomechanical systems,” Phys. Rev. Lett.,
vol. 114, p. 223601, Jun 2015.

[23] H. M. Wiseman and G. J. Milburn, “Quantum theory of optical feedback via homodyne detection,”

Phys. Rev. Lett., vol. 70, pp. 548–551, Feb 1993.

[24] S. Mancini, D. Vitali, and P. Tombesi, “Optomechanical cooling of a macroscopic oscillator by

homodyne feedback,” Phys. Rev. Lett., vol. 80, pp. 688–691, Jan 1998.

[25] H. F. Hofmann, G. Mahler, and O. Hess, “Quantum control of atomic systems by homodyne

detection and feedback,” Phys. Rev. A, vol. 57, pp. 4877–4888, Jun 1998.

[26] A. C. Doherty and K. Jacobs, “Feedback control of quantum systems using continuous state

estimation,” Phys. Rev. A, vol. 60, pp. 2700–2711, Oct 1999.

[27] D. J. Wilson, V. Sudhir, N. Piro, R. Schilling, A. Ghadimi, and T. J. Kippenberg, “Measurement-
based control of a mechanical oscillator at its themal decoherence rate,” Nature, vol. 524, p. 325,
2015.

[28] H. Nha and H. J. Carmichael, “Entanglement within the quantum trajectory description of open

quantum systems,” Phys. Rev. Lett., vol. 93, p. 120408, Sep 2004.

[29] C. Viviescas, I. Guevara, A. R. R. Carvalho, M. Busse, and A. Buchleitner, “Entanglement
dynamics in open two-qubit systems via diﬀusive quantum trajectories,” Phys. Rev. Lett.,
vol. 105, p. 210502, Nov 2010.

[30] M. Koppenh¨ofer, C. Bruder, and N. L¨orch, “Unraveling nonclassicality in the optomechanical

instability,” Phys. Rev. A, vol. 97, p. 063812, Jun 2018.

[31] M. Koppenh¨ofer, C. Bruder, and N. L¨orch, “Heralded dissipative preparation of nonclassical states

in a Kerr oscillator,” Phys. Rev. Research, vol. 2, p. 013071, Jan 2020.

[32] S. Bose, P. L. Knight, M. B. Plenio, and V. Vedral, “Proposal for teleportation of an atomic state

via cavity decay,” Phys. Rev. Lett., vol. 83, pp. 5158–5161, Dec 1999.

[33] E. Greplova, K. Mølmer, and C. K. Andersen, “Quantum teleportation with continuous

measurements,” Phys. Rev. A, vol. 94, p. 042334, Oct 2016.

[34] Q. Ficheux, S. Jezouin, Z. Leghtas, and B. Huard, “Dynamics of a qubit while simultaneously
monitoring its relaxation and dephasing,” Nature communications, vol. 9, no. 1, p. 1926, 2018.
[35] R. Vijay, C. Macklin, D. Slichter, S. Weber, K. Murch, R. Naik, A. N. Korotkov, and I. Siddiqi,
“Stabilizing Rabi oscillations in a superconducting qubit using quantum feedback,” Nature,
vol. 490, no. 7418, pp. 77–80, 2012.

[36] M. A. Armen, J. K. Au, J. K. Stockton, A. C. Doherty, and H. Mabuchi, “Adaptive homodyne

measurement of optical phase,” Phys. Rev. Lett., vol. 89, p. 133602, Sep 2002.

[37] M. Naghiloo, N. Foroozani, D. Tan, A. Jadbabaie, and K. Murch, “Mapping quantum state
dynamics in spontaneous emission,” Nature communications, vol. 7, no. 1, pp. 1–7, 2016.

35

[38] L. Bouten, R. Van Handel, and M. R. James, “An introduction to quantum ﬁltering,” SIAM

Journal on Control and Optimization, vol. 46, no. 6, pp. 2199–2241, 2007.

[39] E. Flurin, L. S. Martin, S. Hacohen-Gourgy, and I. Siddiqi, “Using a recurrent neural network to
reconstruct quantum dynamics of a superconducting qubit from physical observations,” Phys.
Rev. X, vol. 10, p. 011006, Jan 2020.

[40] C. Rackauckas and Q. Nie, “Diﬀerentialequations.jl–a performant and feature-rich ecosystem for
solving diﬀerential equations in julia,” Journal of Open Research Software, vol. 5, no. 1, 2017.
[41] C. Rackauckas and Q. Nie, “Adaptive methods for stochastic diﬀerential equations via natural
embeddings and rejection sampling with memory,” Discrete and continuous dynamical systems.
Series B, vol. 22, no. 7, p. 2731, 2017.

[42] C. Rackauckas and Q. Nie, “Stability-optimized high order methods and stiﬀness detection for
pathwise stiﬀ stochastic diﬀerential equations,” in 2020 IEEE High Performance Extreme
Computing Conference (HPEC), pp. 1–8, IEEE, 2020.

[43] T. Caneva, T. Calarco, and S. Montangero, “Chopped random-basis quantum optimization,”

Physical Review A, vol. 84, no. 2, p. 022326, 2011.

[44] P. W. Glynn, “Likelihood ratio gradient estimation for stochastic systems,” Communications of

the ACM, vol. 33, no. 10, pp. 75–84, 1990.

[45] J. Yang and H. J. Kushner, “A Monte Carlo method for sensitivity analysis and parametric
optimization of nonlinear stochastic systems,” SIAM journal on control and optimization, vol. 29,
no. 5, pp. 1216–1249, 1991.

[46] J. P. Kleijnen and R. Y. Rubinstein, “Optimization and sensitivity analysis of computer simulation
models by the score function method,” European Journal of Operational Research, vol. 88, no. 3,
pp. 413–427, 1996.

[47] R. J. Williams, “Simple statistical gradient-following algorithms for connectionist reinforcement

learning,” Machine learning, vol. 8, no. 3-4, pp. 229–256, 1992.

[48] A. G. Baydin, B. A. Pearlmutter, A. A. Radul, and J. M. Siskind, “Automatic diﬀerentiation
in machine learning: a survey,” The Journal of Machine Learning Research, vol. 18, no. 1,
pp. 5595–5637, 2017.

[49] R. E. Wengert, “A simple automatic derivative evaluation program,” Communications of the ACM,

vol. 7, no. 8, pp. 463–464, 1964.

[50] C. Rackauckas, Y. Ma, V. Dixit, X. Guo, M. Innes, J. Revels, J. Nyberg, and V. Ivaturi, “A
comparison of automatic diﬀerentiation and continuous sensitivity analysis for derivatives of
diﬀerential equation solutions,” arXiv preprint arXiv:1812.01892, 2018.

[51] L. S. Pontryagin, Mathematical theory of optimal processes. Routledge, 2018.
[52] X. Li, T.-K. L. Wong, R. T. Chen, and D. Duvenaud, “Scalable gradients for stochastic diﬀerential

equations,” arXiv:2001.01328, 2020.

[53] Anonymous, “Neural SDEs made easy: SDEs are inﬁnite-dimensional GANs,” in Submitted to

International Conference on Learning Representations, 2021. under review.

[54] P. E. Kloeden and E. Platen, Numerical solution of stochastic diﬀerential equations. Springer

Science & Business Media, 2013.
“High weak order

[55] F. Sch¨afer,

stochastic
diﬀerential equations.” https://summerofcode.withgoogle.com/archive/2020/projects/
5076877036748800/, 2020.
[Online; accessed 15-February-2021].

solvers and adjoint

sensitivity analysis

for

[56] J. Bezanson, S. Karpinski, V. B. Shah, and A. Edelman, “Julia: A fast dynamic language for

technical computing,” arXiv preprint arXiv:1209.5145, 2012.

[57] F. van der Meulen and M. Schauer, “Continuous-discrete smoothing of diﬀusions,” arXiv preprint

arXiv:1712.03807, 2017.

[58] F. van der Meulen and M. Schauer, “Automatic backward ﬁltering forward guiding for markov

processes and graphical models,” arXiv preprint arXiv:2010.03509, 2020.

[59] J. Gough, V. P. Belavkin, and O. G. Smolyanov, “Hamilton–Jacobi–Bellman equations for
quantum optimal feedback control,” Journal of Optics B: Quantum and Semiclassical Optics,

36

vol. 7, no. 10, pp. S237–S244, 2005.

[60] J. Sirignano and K. Spiliopoulos, “DGM: A deep learning algorithm for solving partial diﬀerential

equations,” Journal of computational physics, vol. 375, pp. 1339–1364, 2018.

[61] A. R. Gerlach, A. Leonard, J. Rogers, and C. Rackauckas, “The Koopman expectation: An
operator theoretic method for eﬃcient analysis and optimization of uncertain hybrid dynamical
systems,” arXiv preprint arXiv:2008.08737, 2020.

[62] A. Lamperski, K. R. Ghusinga, and A. Singh, “Analysis and control of stochastic systems using
semideﬁnite programming over moments,” IEEE Transactions on Automatic Control, vol. 64,
no. 4, pp. 1726–1731, 2018.

[63] E. Greplova, C. K. Andersen, and K. Mølmer, “Quantum parameter estimation with a neural

network,” arXiv preprint arXiv:1711.05238, 2017.

[64] A. Valenti, E. van Nieuwenburg, S. Huber, and E. Greplova, “Hamiltonian learning for quantum

error correction,” Physical Review Research, vol. 1, no. 3, p. 033092, 2019.

[65] S. Krastanov, S. Zhou, S. T. Flammia, and L. Jiang, “Stochastic estimation of dynamical

variables,” Quantum Science and Technology, vol. 4, no. 3, p. 035003, 2019.

[66] F. Sch¨afer, P. Sekatski, M. Koppenh¨ofer, C. Bruder, and M. Kloc, “Control of Stochastic
Quantum Dynamics with Diﬀerentiable Programming.” https://github.com/frankschae/
Control-of-Stochastic-Quantum-Dynamics-with-Differentiable-Programming,
2021.
[Online; accessed 15-February-2021].

[67] S. L. Brunton, J. L. Proctor, and J. N. Kutz, “Discovering governing equations from data by
sparse identiﬁcation of nonlinear dynamical systems,” Proceedings of the National Academy of
Sciences, vol. 113, no. 15, pp. 3932–3937, 2016.

[68] L. Boninsegna, F. N¨uske, and C. Clementi, “Sparse learning of stochastic dynamical equations,”

The Journal of chemical physics, vol. 148, no. 24, p. 241723, 2018.

[69] E. Kaiser, J. N. Kutz, and S. L. Brunton, “Sparse identiﬁcation of nonlinear dynamics for model
predictive control in the low-data limit,” Proceedings of the Royal Society A, vol. 474, no. 2219,
p. 20180335, 2018.

[70] M. Cranmer, A. Sanchez-Gonzalez, P. Battaglia, R. Xu, K. Cranmer, D. Spergel, and S. Ho,
“Discovering symbolic models from deep learning with inductive biases,” NeurIPS 2020, 2020.
[71] M. Innes, A. Edelman, K. Fischer, C. Rackauckus, E. Saba, V. B. Shah, and W. Tebbutt, “Zygote:
A diﬀerentiable programming system to bridge machine learning and scientiﬁc computing.”
arXiv preprint arXiv:1907.07587, 2019.

[72] R. T. Chen, Y. Rubanova, J. Bettencourt, and D. K. Duvenaud, “Neural ordinary diﬀerential
equations,” in Advances in neural information processing systems, pp. 6571–6583, 2018.

[73] S. G. Johnson, “Notes on adjoint methods for 18.336,” 2007.
[74] J. Jia and A. R. Benson, “Neural jump stochastic diﬀerential equations,” in Advances in Neural

Information Processing Systems, pp. 9847–9858, 2019.

