1
2
0
2

c
e
D
6
1

]

C
O
.
h
t
a
m

[

2
v
0
3
5
5
0
.
1
1
1
2
:
v
i
X
r
a

Nearly Optimal Linear Convergence of Stochastic Primal-Dual
Methods for Linear Programming

Haihao Lu∗

Jinwen Yang†

December 17, 2021

Abstract

There is a recent interest on ﬁrst-order methods for linear programming (LP). In this pa-
per,we propose a stochastic algorithm using variance reduction and restarts for solving sharp
primal-dual problems such as LP. We show that the proposed stochastic method exhibits a linear
convergence rate for solving sharp instances with a high probability. In addition, we propose
an eﬃcient coordinate-based stochastic oracle for unconstrained bilinear problems, which has
(1) per iteration cost and improves the complexity of the existing deterministic and stochastic
O
algorithms. Finally, we show that the obtained linear convergence rate is nearly optimal (upto
log terms) for a wide class of stochastic primal dual methods.

1

Introduction

Linear programming (LP), as one of the most fundamental tools in operations research and com-
puter science, has been extensively studied in both academia and industry since 1940s. The ap-
plications of LP span various ﬁelds, including pricing and revenue management, transportation,
network ﬂow, scheduling, and many others [13, 25, 8, 39, 3, 37].

The dominant solvers of LP are essentially based on either the simplex method or interior-point
method, which are very mature nowadays and can usually provide reliable solutions to LP. However,
the success of both methods heavily relies on eﬃcient solving linear systems using factorization,
which has the following major drawbacks:
(i) the factorization may run out of memory even
though the original LP can ﬁt in memory; (ii) it is highly challenging to take advantage of modern
computing resources, such as distributed system and GPUs when solving linear systems. These
drawbacks make it highly challenging to further scale up LP.

Recently, it was shown that ﬁrst-order methods (FOMs) with proper enhancements can also identify
high-quality solutions to LP problem quickly [4], which provides an alternative to the traditional
simplex and barrier methods for LP. FOMs utilize only the gradient information of the objective
function to update the iterates (in contrast to second-order methods where Hessian is used). The
basic operation in FOMs is matrix-vector multiplication, which can avoid the two major drawbacks
of traditional methods mentioned above, thus it is suitable for solving larger LP.

∗The University of Chicago, Booth School of Business (haihao.lu@chicagobooth.edu). Financial support from the

University of Chicago Booth School of Business is gratefully acknowledged.

†The University of Chicago, Department of Statistics (jinweny@uchicago.edu)

1

 
 
 
 
 
 
In this work, we further push this line of research and study stochastic FOMs for LP. In contrast
to deterministic ﬁrst-order methods [4], the basic operation per iteration in stochastic FOMs is a
vector operation. Such operation is very cheap in general and is a common practice for modern
machine learning applications. As a drawback, the number of iterations of stochastic algorithms to
obtain an approximate solution is typically higher than its deterministic counterpart.

Due to such a fundamental distinction, Nesterov [42] formally deﬁnes methods that require matrix
factorization (or matrix inversion) as handling medium-scale problems, methods that require matrix
vector multiplication as handling large-scale problems, and methods that require vector operations
as handling huge-scale problems. Based on this deﬁnition, in the context of LP, the simplex method
and interior point method are classiﬁed as handling medium-scale problems (this deﬁnition perhaps
belie the practical eﬃciency of the two methods, but it is a fact that it is challenging to further
scale up them as mentioned above), deterministic FOMs [4, 36] are classiﬁed as handling large-scale
problems, and in the paper we instead look at huge-scale problems.

While our motivation is LP, we here consider a more general class of primal-dual problems with
the form

min
Rn
x
∈

max
y
∈

Rm L

(x, y) := Φ(x, y) + g1(x)

g2(y),

−

(1)

L

where
(x, y) is convex in x and concave in y, g1(x) is a simple convex function in x and g2(y)
is a simple convex function in y. In particular, the primal-dual formulation of standard form LP
is

and a highly related problem is the unconstrained bilinear problem

min
0
x
≥

max
Rm
y
∈

yT Ax + cT x

bT y ,

−

min
Rn
x
∈

max
Rm
y
∈

yT Ax + cT x

bT y .

−

(2)

(3)

For notational convenience, we deﬁne z = (x, y), F (z) = [
−∇yΦ(x, y)] and g(z) =
g1(x)+g2(y) . We here assume there is an unbiased stochastic oracle Fξ(z) such that E[Fξ(z)] = F (z)
(see Section 5 for examples on how to construct the stochastic oracles). To eﬃciently solve (2), our
key ideas are variance reduction and restarts:

∇xΦ(x, y),

Variance reduction is a successful technique for ﬁnite sum stochastic minimization problems [28,
17, 49]. The basic idea is to reduce the variance in the stochastic gradient estimation by comparing
it with the snapshots of the true gradient. Variance reduction can usually improve the convergence
property of stochastic minimization algorithms [28, 17, 49]. Recently, [2] extends the variance
reduction scheme to EGM for solving monotonic variational inequality (with some ambiguity, we
call this algorithm sEGM), which was shown to have O(1/ǫ) convergence rate.

Restart is another standard technique for minimization problems, which is used to speed up the
convergence of multiple deterministic and stochastic algorithms [43, 22, 52, 45, 53]. Recently, [6]
introduces the sharpness of primal-dual problems, and presents a simple restart scheme to accelerate
the linear convergence rate of primal-dual algorithms for solving sharp problems.

This paper extends the restarted algorithm in [6] to stochastic algorithms (in particular sEGM [2])
for solving sharp primal-dual problems, such as LP. We further show that the obtained linear
convergence rate is nearly optimal (upto log terms) for a wild class of stochastic algorithms. It turns

2

Algorithm

Deterministic
[30]
Deterministic
Restart [6]
SPDHG
[11]
SPDHG2
[1]
Conceptual
Proximal [9]
sEGM
[2]
RsEGM
Oracle II
(This Paper)
RsEGM
Oracle IV
(This Paper)

Per-iteration
Cost

Number of Iteration to
ﬁnd an ǫ solution

(nnz(A))

(nnz(A))

O

O

(m + n)

(m + n)

(m + n)

(m + n)

(m + n)

O

O

O

O

O

(1)

O

kAk2
ǫ

(cid:17)
(cid:16)
κ2 log 1
ǫ

O

O

(cid:1)
(cid:0)
Pi kAi·k2
ǫ

(cid:16)

(cid:17)

F log 1
κ2
ǫ

O

O

O

O

(cid:0)
nnz(A)
m+n

(cid:1)
kAkF
ǫ

(cid:18)q

(cid:19)

nnz(A)
m+n

kAkF
ǫ

(cid:19)
(cid:18)q
nnz(A)
m+n κF polylog( 1
ǫ )

(cid:18)q

(cid:19)

nnz(A)κF polylog( 1
ǫ )
(cid:17)

(cid:16)p

˜
O

˜
O

˜
O

Total Cost1

nnz(A) kAk2

ǫ

(cid:17)
(cid:16)
nnz(A)κ2 log 1
ǫ

O

O

(cid:0)

O

nnz(A) + (m + n) Pi kAi·k2
(cid:16)

ǫ

(cid:17)

(cid:1)

O

(m + n)κ2

F log 1
ǫ
√nnz(A)(m+n)kAkF
ǫ

(cid:1)

(cid:0)
nnz(A) +

(cid:18)

nnz(A) +

(cid:18)

O

O

√nnz(A)(m+n)kAkF
ǫ

(cid:19)

(cid:19)

nnz(A) log 1

ǫ +

nnz(A)(m + n)κF polylog( 1
ǫ )
(cid:17)

p

nnz(A) log 1

ǫ +

nnz(A)κF polylog( 1
ǫ )

p

(cid:17)

(cid:16)

˜
O

(cid:16)

Table 1: Comparison on Unconstrained Bilinear Problem (3), where κ2 = k

A
A
2
α .
α , κF = k
k
k

F

out that while LP is sharp on any bounded region [6], LP is not globally sharp (see Appendix A.1 and
Appendix A.2 for a counter example). A fundamental diﬃculty of restarted stochastic algorithm is
that, unlike deterministic algorithms, the iterates may escape from any bounded region, thus there
is no guarantee that local sharpness can be helpful for the convergence of stochastic algorithms.
We overcome this issue by presenting a high-probability argument and show the linear convergence
of the proposed restarted algorithms with high probability.

The performance of randomized algorithms depends on the realization of stochasticity. The tradi-
tional convergence analysis of these algorithms usually measures the expected performance, namely,
running the algorithm multiple times and looking at the average performance.
In contrast, we
present high probability results, namely, running the algorithm multiple times, and study the per-
formance of all trajectories with a certain probability. In particular, when choosing the probability
as 1/2, we obtain the convergence guarantee of the median trajectory, which can be viewed as an
alternative to the expected performance studied in the related literature.

Table 1 and Table 2 present the per iteration cost, complexity of the algorithm, and the total
ﬂop counts for our proposed algorithm, Restarted sEGM (RsEGM), and compare it with multiple
deterministic and stochastic algorithms for solving unconstrained bilinear problem (3) and LP (2),
respectively. For unconstrained bilinear problems (3), deterministic algorithms require to compute
the gradient of the objective, thus the per iteration cost is O(nnz(A)). Standard stochastic algo-

1The total cost is sometimes more than the product of the per-iteration cost and the number of iterations due to

the snapshot step in variance reduction.

2The complexity of SPDHG [2] involves complicated terms. In the table, we present a lower bound on the number
of iterations and the total cost, i.e., they need at least this number of iterations (or total cost) to ﬁnd an ǫ-accuracy
solution based on their analysis (see Appendix A.4 for more details).

3

Algorithm

Deterministic
[30]
Deterministic
Restart [6]
sEGM
[2]
RsEGM
(This Paper)

Per-iteration
Cost

(nnz(A))

(nnz(A))

O

O

(m + n)

(m + n)

O

O

Number of Iteration

Total Cost

kAk2
ǫ

(cid:17)
(cid:16)
κ2 log 1
ǫ

O

O

(cid:0)
nnz(A)
m+n

(cid:1)
kAkF
ǫ

(cid:19)
(cid:18)q
nnz(A)
m+n κF polylog( 1
ǫ )

(cid:19)

O

˜
O

(cid:18)q

˜
O

(cid:16)

ǫ

nnz(A) kAk2
(cid:17)
(cid:16)
nnz(A)κ2 log 1
ǫ

O

O

(cid:0)

nnz(A) +

√nnz(A)(m+n)kAkF
ǫ

(cid:1)

O
nnz(A) log 1

(cid:18)

ǫ +

nnz(A)(m + n)κF polylog( 1
ǫ )

(cid:19)

p

(cid:17)

A
F
+R0)] ,
Table 2: Comparison on standard LP (2), where κ2 =
k
k
z0,0
1/[H(1+
k
k
and H is the Hoﬀman constant of the KKT system of the LP (see Example 2.3 for details).

+R0)] , κF =
k

A
2
k
k
z0,0
1/[H(1+
k

rithms are usually based on row/column sampling, and the iteration cost is O(m + n). We also
present a stochastic coordinate scheme (oracle IV) where the per-iteration cost is O(1). While
stochastic algorithms have low per-iteration cost, it usually requires more iterations to identify an
ǫ-close solution compared to its deterministic counterparts. As we see in Table 1, compared with
the optimal deterministic algorithms [6], the total ﬂop count of RsEGM with stochastic Oracle II is
better when the matrix A is dense and of low rank. With the coordinate gradient estimator Oracle
IV, the total cost of RsEGM is even lower and improves optimal deterministic algorithms by at
least a factor of √n when A is dense. For standard LP, as seen in Table 2, stochastic algorithms
require more iterations to achieve ǫ-accuracy than the unconstrained bilinear problem due to the
existence of inequality constrains. Similar to the unconstrained bilinear setting, when matrix A is
low-rank and dense, the total ﬂop cost of RsEGM improves the optimal deterministic algorithm.
On the other hand, most of the previous works on stochastic algorithms have sublinear rate. The
only exception is [2], where the authors show the linear convergence of SPDHG for solving problems
satisfying global metric sub-regularity. Indeed, unconstrained bilinear problems satisfy the global
metric sub-regularity, while LP does not satisfy it globally. The complexity of SPDHG involves
more complicated notations and we present a more detailed comparison in Appendix A.2 and Ap-
pendix A.4, but our proposed algorithms are at least better than SPDHG by a factor of condition
number κF .

1.1 Summary of Contributions

The contributions of the paper can be summarized as follow:

(i) We propose a restarted stochastic extragradient method with variance reduction for solving
sharp primal-dual problems. We show that the proposed algorithm exhibit linear convergence rate
with high probability, in particular,

• For unconstrained bilinear problems, our restarted scheme improves the complexity of existing
linear convergence of stochastic algorithms [2] by a factor of the condition number. The
improvement comes from restarts.

• To the best of our knowledge, this is the ﬁrst stochastic algorithm with linear rate for the
general standard-form LP problems (2). To prove this result, we introduce a high-probability

4

analysis to upper-bound distance between the iterates and the optimal solution set.

(ii) We present the complexity lower bound of a class of stochastic ﬁrst-order methods for solving
sharp primal-dual problems, which matches the upper bound we obtained for RsEGM (upto log
terms). This showcases RsEGM achieves a nearly optimal linear convergence rate for sharp primal-
dual problems.

1.2 Assumptions

Throughout the paper, we have two assumptions on the problem and the stochastic oracle. The
ﬁrst one is on the primal-dual problem:

Assumption 1. The problem (1) satisﬁes:
(i)
(x, y) is convex in x and concave in y.
L
(ii) g :
∪
(iii) The stationary solution set

Z →

∞

+

R

is proper convex lower semi-continuous.
0
|

F (z) + ∂g(z)

Z ∗ =

z
{

} 6

= ∅.

∈
As a stochastic ﬁrst-order method, we assume there exists a stochastic gradient oracle:
Assumption 2. We assume there exists a stochastic oracle Fξ : Rm+n
(i) it is unbiased: E[Fξ(z)] = F (z);
(ii) it is L-Lipschitz (in expectation): E[
Fξ(u)
k

2]
Fξ(v)
k

2.
k

u
k

L2

→

≤

−

−

v

Rm+n such that

1.3 Related Literature

Convex-concave primal-dual problems. There has been a long history of convex-concave
primal-dual problems, and many of the early works study a more general problem, monotone
variational inequalities. Rockafellar proposed a proximal point method (PPM) [47] for solving
monotone variational inequalities. Around the same time, Korpelevich proposed the extragradient
method (EGM) [30] for convex-concave primal-dual problems. After that, there have been numerous
results on the convergence analysis of these methods. In particular, Tseng [51] shows that PPM
and EGM have linear convergence for strongly-convex-strongly-concave primal-dual problems or for
unconstrained bilinear problems. Nemirovski proposes Mirror Prox algorithm in the seminal work
( 1
ǫ ) sublinear convergence
[41], which is a more general form of EGM, and shows that EGM has
rate for solving general convex-concave primal-dual problems over a bounded and compact set. [41]
also build up the connection between EGM and PPM: EGM is an approximation to PPM.

O

Another line of research is to study a special case of (1) where Φ(x, y) = yT Ax is a bilinear
term. Two well-known algorithms are Douglas-Rachford splitting [18, 19] (Alternating Direc-
tion Method of Multiplier (ADMM) as a special case) and Primal-dual Hybrid Gradient Method
(PDHG) [12].

Very recently, there is a renewed interest on primal-dual methods, motivated by machine learning
(x, y) = yT Ax with full rank matrix A, [15] shows that
applications. For bilinear problems
the Optimistic Gradient Descent Ascent (OGDA) converges linearly and later on [40] shows that
OGDA , EGM and PPM all enjoy a linear convergence rate.
[40] also presents an interesting
observation that OGDA approximates PPM on bilinear problems. Lu [38] analyzes the dynamics

L

5

of unconstrained primal-dual algorithms under an ODE framework and yields tight conditions under
which diﬀerent algorithms exhibit linear convergence. However, an important caveat is that not
all linear convergence rates are equal. [6] shows that a simple restarted variant of these algorithms
can improve the dependence of complexity on condition number in their linear convergence rate,
as well as the empirical performance of the algorithms.

Linear programming. Linear programming is a fundamental tool in operations research. Two
dominating methods to solve LP problems are simplex method [14] and interior-point method
[29], and the commercial LP solvers based on these methods can provide reliable solutions even
for fairly large instances. While the two methods are quite diﬀerent, both require solving linear
systems using factorization. As a result, it becomes very challenging to further scale up these two
methods, in particular to take advantage of distributed computing. Recently, there is a recent trend
on developing ﬁrst-order methods for LP only utilizing matrix-vector multiplication [7, 23, 36, 4, 5].
In general, these methods are easy to be parallelized and do not need to store the factorization in
memory.

The traditional results of ﬁrst-order methods for LP usually have sublinear rate, due to the lack of
strong convexity, which prevents them to identify high-accuracy solutions. To deal with this issue,
[20] presents a variant of ADMM and shows the linear convergence of the proposed method for
LP. More recently [33, 34] show that many primal-dual algorithms under a mild non-degeneracy
condition have eventual linear convergence, but it may take a long time before reaching the linear
convergence regime.
[6] propose a restarted scheme for LP in the primal-dual formulation. They
introduce a sharpness condition for primal-dual problems based on the normalized duality gap and
show that the primal-dual formulation of LP is sharp on any bounded region. Then they provide
restarted schemes for sharp primal-dual problems and show that their proposed algorithms have the
optimal linear convergence rate (in a class of deterministic ﬁrst-order methods) when solving sharp
problems. A concurrent work [?] studies stochastic algorithms for generalized linear programming,
but the focus is on sublinear rate, while our focus is on the linear rate.

Sharpness conditions and restart schemes. The concept of sharpness was ﬁrst proposed by
Polyak [46] on minimization problem. Recently, there is a trend of work on developing ﬁrst-order
method with faster convergence rates using sharpness. For example, [52] shows linear convergence
of restarted subgradient descent on sharp non-smooth functions and there are other works on sharp
non-convex minimization [16]. Sharpness can also be viewed as a certain error bound condition [48].
Recently [6] introduces sharpness condition for primal-dual problems. A highly related concept is
the metric subregularity for variational inequalities, which is a weaker condition than the sharpness
condition proposed in [6] (see Appendix A.1 for a discussion). Under such conditions, [1, 21] present
the linear convergence for stochastic PDHG and deterministic PDHG, respectively.

Restarting is a powerful technique in optimization. It can improve the practical and theoretical
convergence of a base algorithm without modiﬁcation to the base algorithm [45]. Recently, there
have been extensive works on this technique in smooth convex optimization [43, 48], non-smooth
convex optimization [22, 52] and stochastic convex optimization [28, 35, 50]. For sharp primal-dual
problems, [6] propose ﬁxed-frequency and adaptive restart on a large class of base primal-dual
algorithms including PDHG, ADMM and EGM.

Variance reduction and primal-dual problem. Variance reduction technique [17, 28] is devel-
oped to improve the convergence rate for stochastic algorithms upon pure SGD for minimization

6

problems. There are extensive works on variants of stochastic variance reduction for minimization
problems under various settings (see [24] for a recent overview).

Compared with the extensive works on minimization problem, the research of variance-reduced
methods on primal-dual problems is fairly limited. [44] studies stochastic forward-backward algo-
rithm with variance reduction for primal-dual problems and, more generally, monotone inclusions.
Under strong monotonicity, they prove a linear convergence rate and improve the complexity of
deterministic methods for bilinear problems.
[9] proposes a randomized variant of Mirror Prox
algorithm. They focus on matrix games and improve complexity over deterministic methods in
several settings. However, beyond matrix games, their method requires extra assumptions such
as bounded domain and involves a three-loop algorithm. More recently, [2] proposes a stochastic
extragradient method with variance reduction for solving variational inequalities. Under Euclidean
setting, their method is based on a loopless variant of variance-reduced method [27, 31]. Their
algorithm oﬀers a similar convergence guarantee as [9] but does not require assumptions such as
bounded region.

1.4 Notations

Let log(
) refer to the natural log and exponential function, respectively. Let σmin(A)
) and exp(
·
·
and σ+
min(A) denote the minimum singular value and minimum nonzero singular value of a matrix
kF denote the 2-norm and
A
j be the l2 norm of vector z. Let
A. Let
k
Frobenius norm of a matrix A. Let ei be the i-th standard unit vector. Let f (x) =
(g(x)) denote
O
Cg(x) and f (x) = Ω(g(x)) denote
for suﬃciently large x, there exists constant C such that f (x)
cg(x). f (x) = Θ(g(x)) if f (x) =
for suﬃciently large x, there exists constant c such that f (x)

k2 and
A
k

k2 =

qP

j z2

z
k

(g(x)) and f (x) = Ω(g(x)). Denote ˜
O

O
to a polynomial in log(g(x)). For set
at z with radius r
S.

(0,

∞

∈

O
, denote Wr(z) =

(cid:18)

Z
) intersected with the set

ˆz

the ball centered
k ≤
. ιS is the indicator function of convex set

∈ Z

ˆz

r

Z

(cid:8)

(cid:9)

(cid:19)
z
−
k
(cid:12)
(cid:12)

(g(x)) =

g(x)polylog(g(x))

, where polylog(g(x)) refers

≤
≥

2 Preliminaries

In this section, we present two results in the recent literature (i) the sharpness condition for primal-
dual problems based on the normalized duality gap introduced in [6], and (ii) the stochastic EGM
with variance reduction that was introduced in [2]. We will utilize these results to develop our main
theory in later sections.

2.1 Sharpness Condition for Primal-Dual Problems

Sharpness is a central property of the objective in minimization problems that can speed up the
convergence of optimization methods. Recently, [6] introduces a new sharpness condition of primal-
dual problems based on a normalized duality gap. They show that linear programming (among
other examples) in the primal-dual formulation is sharp. Furthermore, [6] proposes a restarted
algorithm that can accelerate the convergence of primal-dual algorithms such as EGM, PDHG and
ADMM, and achieve the optimal linear convergence rate on sharp primal-dual problems.

7

More formally, the sharpness of a primal-dual problem is deﬁned as:

Deﬁnition 1. We say a primal-dual problem is α-sharp on the set S
for all r, i.e. it holds for all z

S that

∈

if ρr(z) is α-sharp on S

⊂ Z

αdist(z,

∗)

Z

≤

ρr(z) = maxˆz
Wr(z) L
∈

(x, ˆy)

(ˆx, y)

,

− L
r

where Wr(z) =

ˆz

∈ Z

ˆz

k ≤

−

r

is a ball centered at z with radius r intersected with the set

.

Z

In particular, the following examples are shown to be sharp instances [6]:
(cid:9)

(cid:8)

z
k
(cid:12)
(cid:12)

Example 2.1. Consider a primal-dual problem with a bounded feasible region, i.e., g1 and g2 encode
(x, y) is α1-sharp in x
a bounded feasible region of x and y, respectively. Suppose P (x) = maxy L
(x, y) is α2-sharp in y. Then problem (1) is α-sharp in the feasible region,
and D(y) = maxx
where α = min
and R is the diameter of the region.

∈X L
}

α1,α2
{
R

Example 2.2. Consider an unconstrained bilinear problem with
problem (1) is α-sharp in Rm+n, where α = σ+

min(A).

L

(x, y) = yT Ax + cT x

bT y, then

−

Example 2.3. Consider the primal-dual form of standard LP:

min
Rn
x
∈

max
y
∈

Rm L

(x, y) = yT Ax + cT x + ιx

bT y .

0 −

≥

Then for any z, the normalized duality gap ρr(z) = maxˆz
∈

Wr(z) L

(x,ˆy)

−L
r

(ˆx,y)

satisﬁes

ρr(z)

1

≥

H

z
1 + 4
k

2
k

dist(z,

∗) ,

Z

where H is the Hoﬀman constant of the KKT system of LP [6, 26].

p

2.2 Stochastic EGM with Variance Reduction

In this subsection, we present the stochastic EGM with variance reduction introduced in [2], and
restate their two major convergence results.

Algorithm 1 presents the stochastic EGM with variance reduction (sEGM). The algorithm keeps
. wk can be viewed as a snapshot, which is updated rarely
track of two sequences
and we evaluate the full gradient F (wk). Then we calculate ¯zk as a weighted average of zk and
wk. Similar to deterministic EGM, the algorithm computes an intermediate solution zk+1/2. We
then use the full gradient of the snapshot F (wk) to compute zk+1/2, and use the variance reduced
stochastic gradient F (wk) + Fξk (zk+1/2)

Fξk (wk) to compute zk+1.

wk}
{

zk}
{

and

−

We here restate the descent lemma of Algorithm 1 ([2, Lemma 2.2]), which is the key component
in the sublinear convergence rate proof of sEGM:

wk −
k

z

2. Let τ = √p
k

2L . Then for (zk) generated by

Lemma 1. Let φk(z) = (1
Algorithm 1 and any z

z

−

2 +
p)
zk −
k
k
∗ ∈ Z ∗, it holds that
1
2

φk(z
∗

)]

−

≤

p

)

Ek[φk+1(z
∗

zk+1/2 −
k

wkk

2 + Ek[
zk+1 −
k

2]
zk+1k

.

(cid:1)

(cid:0)

8

Algorithm 1 Stochastic EGM with variance reduction: zK = sEGM (p, Q, τ, z0, K)
Input: Probability p
(0, 1), sample oracle Q, step size τ , number of iteration K. Let w0 = z0.
∈
1
k
Output: zK = 1
l=0 zl+1/2.
−
K
1 do
1: for k = 0, 1, ...K
−
P
¯zk = (1
p)zk + pwk
2:
−
zk+1/2 = proxτ g(¯zk −
zk+1 = proxτ g(¯zk −
wk+1 =

3:
4: Draw an index ξk according to Q
5:

τ [F (wk) + Fξk (zk+1/2)

Fξk (wk)])

τ F (wk))

−

6:

zk+1, with prob. p
with prob. 1
wk

(

p

−

7: end for

Moreover, it holds that

∞

Xk=0

(cid:0)

pE[
zk+1/2 −
k

wkk

2] + E[
zk+1/2 −
k

2]
zk+1k

2φ0(z
∗

≤

) = 2(2

z0 −
p)
k

−

2 .

z
∗k

(cid:1)

Next, we restate the sublinear convergence of Algorithm 1 in terms of the duality gap. The theorem
and its proof can be obtained by a simple modiﬁcation of [2, Theorem 2.5].

Theorem 1. Let Assumptions hold, p
Θk+1/2(z) =

F (zk+1/2), zk+1/2 −
h

z

i

∈
+ g(zk+1/2)

(0, 1) and τ = √p

2L . Let zk = 1

k

g(z). Then for any compact set
P

C

−

1

k
l=0 zl+1/2. Let
−
,

2τ E

max
z
∈C

"

k

1

−

Xl=0

Θl+1/2(z)

# ≤

7
2

max
z
∈C

z0 −
k

z

2 + 14
z0 −
k
k

2 .

z
∗k

3 Restarted Stochastic EGM with Variance Reduction

In this section, we ﬁrst present our main algorithm, the nested-loop restarted stochastic EGM
algorithm (RsEGM, Algorithm 2), in section 3.1. Then we show that with high probability, the
restarted algorithm exhibits linear convergence to an optimal solution for sharp primal-dual prob-
lems both with and without bounded region. This linear convergence result accelerates the linear
convergence of stochastic algorithms without restart.

3.1 Algorithm

Algorithm 2 presents the nested-loop restarted stochastic EGM algorithm (RsEGM). We initialize
the algorithm with probability parameter p
(0, 1], a stochastic sample oracle Q, step size τ
for sEGM, length of inner loop K and outer iteration T . In each outer loop, we run sEGM for
K iterations and restart the next outer loop using the output of sEGM from the previous outer
loop.

∈

9

Algorithm 2 Restarted stochastic EGM: zT,0 = RsEGM (p, Q, τ, z0,0, T, K)

Input: Probability p

(0, 1], probability distribution Q, step size τ , number of restart T , number

of iteration for sEGM K.

∈

Output: zT,0.
1: for t = 0, 1, ..., T
2:
3: end for

1 do

−

Call subroutine sEGM to obtain zt+1,0 = sEGM (p, Q, τ, zt,0, K)

3.2 Convergence Guarantees for Problems with Global Sharpness

Theorem 2 presents the high probability linear convergence rate of Algorithm 2 for solving primal-
dual problem (1) with global sharpness conditions. Recall that the global sharpness holds for
unconstrained bilinear problems and bilinear problems with bounded region (an economic exam-
ple is two-player matrix game), this implies the linear convergence of Algorithm 2 for these two
cases.

Theorem 2. Consider RsEGM (Algorithm 2) for solving a sharp primal-dual problem (1). Suppose
Assumption 1 and Assumption 2 hold. Let α be the global sharpness constant of the primal-dual
problem and L be the Lipschitz parameter of the stochastic oracle. Denote the initial distance to
optimal set as R0 = dist(z0,0,
(0, 1) and ǫ > 0, if
the outer loop count T and the inner loop count K of RsEGM satisfy

Z ∗), and choose step-size τ = √p

2L . For any δ

∈

then it holds with probability at least 1

T

≥

max

log2

, 0

, K

R0
ǫ

(cid:26)

˜
O

≥

(cid:18)

1
√p

L
α

1
δ2 T 2

,

(cid:19)

(cid:27)
δ that
−
dist(zT,0,

∗)

Z

≤

ǫ .

Furthermore, the total number of iteration to get ǫ accuracy with probability at least 1

1
√p

L
α

1
δ2

˜
O  

log

R0
ǫ

(cid:18)

3

.

!

(cid:19)

δ is of order

−

Remark 1. The performance of stochastic algorithms depends on the realization of stochasticity.
The traditional convergence analysis of these algorithms usually measures the expected performance,
namely, running the algorithm multiple times and looking at the average performance. In contrast,
when choosing δ = 1
2 , Theorem 2 provides the complexity of the median performance of the algo-
rithm.

Remark 2. In this remark, we consider the ﬁnite-sum model where
i=1 Li(x, y).
Suppose the stochastic oracle computes Fξ(z) = [
−∇yLi(x, y)] for i that is uniformly
random in set [1, ..., N ]. Then evaluating Fξ(z) needs one stochastic oracle and evaluating the
true gradient F (z) need N stochastic oracles. With a careful calculation, we obtain that one outer
iteration of RsEGM requires (N + 2)+ ˜
stochastic oracle calls. Thus,
O
δ becomes
the average total oracle cost of RsEGM to reach ǫ-accuracy with probability at least 1

∇xLi(x, y),

(N p + 2) 1
√p

log R0
ǫ

P

1
δ2

L
α

L

2

(x, y) = 1
N

N

(cid:16)

(N + 2) log

˜
O  

R0
ǫ

+ (N p + 2)

1
√p

L
α

10

(cid:0)
1
δ2

(cid:17)

(cid:1)

R0
ǫ

log

(cid:18)

3

.

!

(cid:19)

−

(4)

Choosing p = Θ
achieve ǫ accuracy becomes

1
N

(cid:0)

(cid:1)

and δ = 0.5, the number of stochastic oracle calls for the median trajectory to

(N + 2) log

˜
O  

R0
ǫ

+ √N

log

R0
ǫ

L
α

(cid:18)

3

.

!

(cid:19)

In contrast, the total oracle cost of deterministic restarted methods solving primal-dual problem with
global sharpness [6] (which is the optimal deterministic algorithm) is

N

LF
α

log

R0
ǫ

O

,

(cid:18)
where LF is the Lipschitz constant for
(x, y). In the context of ﬁnite-sum model, LF is generally
of the same order of L (upto a variance term that is independent of N ). This shows that RsEGM in
general needs O(√N ) less stochastic oracles to ﬁnd an ǫ-solution than its deterministic counterpart
after ignoring the log terms.

(cid:19)

L

We know from Example 2.1 and Example 2.2 that bilinear problems with bounded region and un-
constrained bilinear problem are both globally sharp. A direct application of Theorem 2 gives:

Corollary 1. For bilinear problems with bounded region and for unconstrained bilinear problem,
the total number of iteration to get ǫ accuracy with probability at least 1

δ is of order

−

1
√p

L
α

1
δ2

˜
O  

log

R0
ǫ

(cid:18)

3

.

!

(cid:19)

To prove Theorem 2, we ﬁrst introduce two properties of sEGM. The next lemma bounds the
expected distance between the iterates of sEGM and initial point by the distance between initial
point and optimal solution.

Lemma 2. Consider sEGM (Algorithm 1) for solving (1). Suppose Assumption 1 and Assumption
2 holds, then

E[
zk+1/2 −
k

]
z0k

≤

3 +

(cid:18)

2

1

r

p

(cid:19)

−

z0 −
k

z
∗k

.

(5)

Proof. It follows from Lemma 1

E[
zk+1/2 −
k

2]
zk+1k

2φ0(z
∗

)

z0 −
4
k

≤

≤

2 ,

z
∗k

thus

E[
E[
zk+1/2 −
zk+1/2 −
k
k
We can also derive from the monotonicity of E[φk(z
∗
E[φ0(z∗)] =

E[φk+1(z∗)] ≤ · · · ≤

E[kzk+1 − z∗k2] ≤

]
zk+1k

2]
zk+1k
)] that

≤

(cid:0)

(cid:1)

1
1 − p

1/2

z0 −
2
k

z
∗k

.

≤

1
1 − p

1
1 − p

(2 − p)kz0 − z∗k2 ≤

2
1 − p

kz0 − z∗k2

thus

E[
zk+1 −
k

]
z
∗k

≤

E[
zk+1 −
k

2]

z
∗k

(cid:0)

11

2

−

≤

1

r

1/2

(cid:1)

z0 −

p k

.

z
∗k

By triangle inequality we have

E[
zk+1/2 −
k

]
z
∗k

E[
zk+1/2 −
k

zk+1k

] + E[
zk+1 −
k

]
z
∗k

≤

≤

2 +

(cid:18)

2

1

r

p

(cid:19)

−

z0 −
k

z
∗k

,

E[
zk+1/2 −
k

]
z0k

E[
zk+1/2 −
k

≤

] +

z
∗k

z
∗ −
k

z0k ≤

3 +

(cid:18)

2

1

r

p

(cid:19)

−

z0 −
k

z
∗k

.

Next, we present the sublinear rate of sEGM on localized duality gap:

Lemma 3. Consider sEGM (Algorithm 1) for solving (1). Suppose Assumption 1 and Assumption
2 holds, then

E

max
z
∈C∩Z

(cid:20)

L

(xK, y)

− L

(x, yK)
(cid:21)

≤

1
2τ K

7
2

(cid:18)

max
z
∈C

z0 −
k

z

2 + 14
z0 −
k
k

2
z
∗k

.

(cid:19)

Proof. Notice that

max
z∈C∩Z L

(xK , y)

E

(cid:20)

K−1

max
z∈C∩Z

"

Xk=0
K−1

E

E

1
k

1
k

≤

≤

K−1

1
k

(x, yK)
(cid:21)

≤

E

max
z∈C∩Z

"

Xk=0
(xk+1/2, yk+1/2)(xk+1/2 −

− L

∇xL

(xk+1/2, y)

L
(cid:0)

− L

(x, yk+1/2)

#
(cid:1)

x)

− ∇yL

(xk+1/2, yk+1/2)(yk+1/2 −

y)

#

max
z∈C

"

Xk=0

Θk+1/2(z)

# ≤

1
2τ K

7
2

(cid:18)

max
z∈C k

z0 −

z

k

2 + 14

2

z0 −

k

z∗k

.

(cid:19)

where the ﬁrst two inequalities are from the convexity-concavity of L(x, y) and the last inequality is due to
Theorem 1.

Now we are ready to prove Theorem 2.

Proof of Theorem 2. Consider the t-th outer iteration, and deﬁne Rt = dist(zt,0,
RT ≤
(cid:26)

Z ∗). To prove the
is a high probability event and the key is to use

theorem, we’ll show that the event

the global sharpness on a carefully controlled region.

R0
2T

(cid:27)

Suppose K

2000

≥

≥

exp(e2). It follows from Markov inequality that for any inner iteration k

P

zt,k
k
(cid:16)
Furthermore, it follows from Lemma 2 that

zt,k
k
(cid:16)

zt,0

k ≤

= 1

r0

−

−

(cid:17)

P

zt,0

k

−

> r0

1

−

≥

(cid:17)

zt,0

E

zt,k
k
(cid:2)

−
r0

.

k
(cid:3)

P

zt,k
k
(cid:16)

zt,0

r0

k ≤

−

(cid:17)

1

−

≥

E[
zt,k
k

−
r0

zt,0

]
k

3 +

1

≥

−

(cid:18)

2

1

r

p

(cid:19)

−

zt,0
k

−
r0

z
∗k

.

(6)

12

Thus, if r0 is chosen to be suﬃciently large, the probability P
zt,k
k
zt,0
ily close to 1 . Given the high probability event
(cid:0)
k ≤
normalized duality gap as

zt,k
k
(cid:8)
max
Wr+r0(zt,0)
∈
By α-sharpness and the fact that Wr+r0(zt,0) is deterministic given zt,0, we have for any constant
C > 0 and function g(k) > 0 that

zt,0
can be arbitrar-
, we can upper bound the

(cid:9)
(xt,k, y)

max
Wr(zt,k)

(xt,k, y)

(x, yt,k)

(x, yt,k)

−
r0

− L

− L

k ≤

(7)

r0

≤

−

L

L

n

n

o

o

(cid:1)

∈

.

z

z

P

(cid:18)

αRt+1 ≤

CRt
g(k)

P

1
r

z

(cid:18)

≥

(cid:19)

∈

max

Wr(zt+1,0) L

(xt+1,0, y)

(x, yt+1,0)

− L

= P

max
Wr(zt,k) L

∈

z
(cid:18)

(xt,k, y)

(x, yt,k)

− L

CrRt
g(k)

≤

CRt
g(k)

(cid:19)

.

≤

(cid:19)

Thus, it holds for any r0 ≥
≥ P
αRt+1 ≤

P

0 that

CRt
g(k)

(cid:19)

max
z∈Wr (zt,k)

(cid:18)

L(xt,k, y) − L(x, yt,k) ≤

CrRt
g(k)

, kzt,k − zt,0k ≤ r0

(cid:19)

(cid:18)

≥ P

max
z∈Wr+r0 (zt,0)

L(xt,k, y) − L(x, yt,k) ≤

CrRt
g(k)

, kzt,k − zt,0k ≤ r0

!

= P

kzt,k − zt,0k ≤ r0
(cid:16)
− P

max
z∈Wr+r0 (zt,0)

(cid:17)
L(xt,k, y) − L(x, yt,k) >

CrRt
g(k)

, kzt,k − zt,0k ≤ r0

!

≥ P

kzt,k − zt,0k ≤ r0
(cid:16)

(cid:17)

− P

max
z∈Wr+r0 (zt,0)

L(xt,k, y) − L(x, yt,k) >

CrRt
g(k) !

where the second inequality utilizes Equation (7).

The next step is to upper bound the last term in the right hand side of (8). Denote C1 = 3 +

(8)

2

p

1

−

and choose r0 = r = 2C1Rt

T
δ , then we have z

Wr+r0(zt,0) because r + r0 ≥

Rt, thus

q

P

max
z∈Wr+r0 (zt,0)

L(xt,k, y) − L(x, yt,k) >

≤

g(k)
CrRt

1
2τ k

7
2

(cid:18)

+ 14

(cid:19)

max
z∈Wr+r0 (zt,0)

kzt,0 − zk2 ≤

35
4τ C

max
z∈Wr+r0 (zt,0)
(r + r0)2
rRt

"
g(k)
k

L(xt,k, y) − L(x, yt,k)

#

(9)

,

where the ﬁrst inequality follows from Markov inequality, the second one utilizes Lemma 3 and
z
∗ ∈

Wr+r0(zt,0). Combine Equation (8) with (9), we obtain

∗ ∈
CrRt
g(k) !

≤

g(k)
CrRt

E

P

αRt+1 ≤
(cid:18)

CRt
g(k)

≥

(cid:19)

zt,k
k
(cid:16)

zt,0

−

P

1

3 +

≥

−

k ≤
2

1

p

r0

−

(cid:17)
Rt
r0 −

35
4τ C

g(k)
k

35
4τ C

g(k)
k

(r + r0)2
rRt
(r + r0)2
rRt

,

r
where the last inequality uses Equation (6). Thus, we obtain by substituting the value of r0, r and
τ that

−

(cid:19)

(cid:18)

P

αRt+1 ≤
(cid:18)

CRt
g(k)

(cid:19)

1

≥

−

δ
2T −

35
4τ C

g(k)
k

8C1T
δ

= 1

δ
2T −

L
C

g(k)
k

T
δ

140C1
√p

.

−

13

 
 
 
 
Let C2 = 140C1, C = α and function g(k) = log log k, then we have

P

(cid:18)

Rt+1 ≤

Rt
log log k

(cid:19)

1

−

≥

δ
2T −

C2
√p

L
α

T
δ

log log k
k

.

(10)

When k
¯
P
Et
·|
(cid:0)

(cid:1)

2000 > exp (e2), we have

≥
be the probability conditioned on

n

Rt ≤

Rt ≤

⊆
, then
n

Rt−1
2

o

. Let

Et =

Rt ≤

Rt−1
2

and

o

n

Rt−1
log log k

{E1, ...,

o
Et}

T

P

RT ≤

(cid:18)

R0
2T

≥

(cid:19)

P

T
t=1Et

∩

= P(

E1)

P(

¯
Et
−

Et|

1)

(cid:0)
1

(cid:1)

δ
2T −

−

C2
√p

L
α

T
δ

t=2
Y
log log k
k

≥

(cid:18)

T

(cid:19)

1

−

≥

δ
2 −

C2
√p

L
α

T 2
δ

log log k
k

,

(11)

where the second inequality is from Equation (10) and the third one uses Bernoulli inequality.
Thus, if k

we obtain

2C2
√p

L
α

T 2
δ2 log

2C2
√p

L
α

T 2
δ2

≥

(cid:16)

(cid:17)

C2
√p

L
α

T 2
δ

log log k
k

δ
2 ·

≤

log log

2C2
√p

L
α

(cid:16)

log

T 2
δ2 log
2C2
L
α
√p

(cid:16)
T 2
δ2

2C2
√p

L
α

T 2
δ2

(cid:17)(cid:17)

log

log

(cid:16)
2C2
L
α
√p

T 2
δ2

(cid:17)

+ log log

2C2
√p

L
α

T 2
δ2

δ
2 ·

≤

(cid:16)

(cid:16)

(12)

δ
2

,

(cid:17)(cid:17)

≤

log

(cid:17)
2C2
√p

L
α

T 2
δ2

(cid:16)

(cid:16)

(cid:17)

where the last inequality is from log (x+log x)

x

≤

1. Combine (11) and (12) we arrive at

P

RT ≤

(cid:18)

R0
2T

(cid:19)

1

−

≥

δ
2 −

C2
√p

L
α

T 2
δ

log log k
k

1

−

≥

δ .

L
Finally, by choosing T =
α
iteration to get ǫ accuracy with probability at least 1
(cid:6)

log2

max

, K

2C2
√p

R0
ǫ

≥

n

(cid:7)

T 2
δ2 log

2C2
√p

L
α

T 2
δ2

, 2000

, the total number of

1
√p

L
α

1
δ2

˜
O  

log

(cid:18)

−

R0
ǫ

δ is T K which is of order
(cid:17)

o

(cid:16)

3

.

!

(cid:19)

3.3 Convergence Guarantees for Standard-Form LP

In this subsection, we establish the high probability convergence rate of RsEGM for LP (2). Un-
fortunately, LP is not globally sharp (see Appendix A.2), thus the result in Section 3.2 cannot be
directly applied to LP. Instead, [6] shows that LP is sharp on any bounded region. Unlike deter-
ministic methods as studied in [6], where the iterates of a primal dual algorithm always stay in a
bounded region, the iterates of stochastic methods may escape from any bounded region. Theorem
3 overcomes this diﬃculty by presenting a high probability argument.

14

Theorem 3. Consider RsEGM (Algorithm 2) for solving LP (2). Suppose Assumption 1 and
Assumption 2 hold. Let L be the Lipschitz parameter of the stochastic oracle and H be the Hoﬀman
constant of the KKT system of LP (see Example 2.3). Denote the initial distance to optimal set
as R0 = dist(z0,0,
(0, 1) and ǫ > 0, if the outer loop
count T and the inner loop count K of RsEGM satisfy

Z ∗), and choose step-size τ = √p

2L . For any δ

∈

T

≥

max

log2

(cid:26)

R0
ǫ

, 0

, K

(cid:27)

˜
O

≥

1
√p

(cid:18)

1/ [H(1 +

L
z0,0
k

k

+ R0)]

1
δ3 T 4

,

(cid:19)

then it holds with probability at least 1

δ that

−

dist(zT,0,

∗)

Z

≤

ǫ.

Furthermore, the total number of iteration to get ǫ accuracy with probability at least 1

δ is of order

−

1
√p

˜
O  

1/[H(1 +

L
z0,0
k

k

+ R0)]

1
δ3

(cid:18)

log

R0
ǫ

5

.

!

(cid:19)

Remark 3. Similar to Remark 1, we can obtain the complexity of the median trajectory of the
algorithm by choosing δ = 1
2 .

Remark 4. As shown in [6, Lemma 5], LP is sharp with α =
R
}
with any radius R > 0. Notice that for deterministic primal-dual methods, the iterates usually stay
+R0 (see Section 2 in [6]), thus the eﬀective sharpness
in a ball centered at 0 with radius R =
+R0) . Theorem 3 shows that
constant on deterministic algorithms for LP is given by α =
k
the complexity of RsEGM is ˜
O

H√1+4R2 in the ball

z0,0
k

log R0
ǫ

1
z0,0
k

k2 ≤

z
|k

L
1/α

z
{

1
√p

H(1+

1
δ3

k

5

.

(cid:1)
In the following we prove Theorem 3. The key is to show that the iterates stay in a bounded region
with a high probability, thus we can utilize the sharpness condition of LP.

(cid:0)

(cid:16)

(cid:17)

1

2000
zt

−

≥
1,0

exp(e2). Denote Rt = dist(zt,0,

Z ∗) and consider event
, where we determine the value of B later.

Rt

1B

Proof of Theorem 3. Suppose K
1
Rt ≤
Et =
log log K Rt
−
By deﬁnition:
n

1 and

≥
zt,0
k

−

k ≤

−

o
1 < ... < R0 and

Rt < Rt

t
l=1El ⊆ {
∩
k ≤
¯
, then P(
Et) is the probability conditioned on
·|

Let ¯
t
Et =
l=1El}
{∩
¯
E0) = P(
denote, P(
). It follows from Lemma 2.3 and the sharpness of LP that
·|
·
¯
Et

z0,0
k
{E1, ...,

tR0B +

zt,0
k

Et}

k}

P

−

. For convenience, we

Et+1|
(cid:0)

H

= P

1
(cid:1)
1 + 4

k

zt+1,0

Rt+1 ≤

2

H

k
(xt+1,0, ˆy)

1
1 + 4

k
(ˆx, yt+1,0)

p

zt+1,0

2

k

P

≥

p
max
ˆz∈Wr (zt+1,0)

L

− L
r

Rt
log log K

,

k

zt+1,0

zt,0

−

k ≤

RtB

¯
Et

!

zt+1,0

,

2

k

(cid:12)
(cid:12)

−

Rt
1 + 4

p

zt+1,0

k

k

zt,0

k ≤

RtB

¯
Et
(cid:12)
(cid:12)

.

!
(13)

≤

H log log K

15

 
 
Note that given the event

zt+1,0

{k

RtB

, we have for any r > 0 that
}

zt,0

−
k ≤
(ˆx, yt+1,0)

(xt+1,0, ˆy)

L

max
Wr(zt+1,0)

ˆz

∈

− L
r

max
Wr+RtB(zt,0)

≤

ˆz

∈

(xt+1,0, ˆy)

L

− L
r

(ˆx, yt+1,0)

.

(14)

Furthermore, we have conditioned on ¯

Et that

zt,0
k

k ≤

tR0B +

z0,0
k

, thus
k

H log log K

Rt
zt,0
1 + 4(
k

k

+ RtB)2 ≥

H log log K

Combining Equation (13), (14) and (15), we arrive at

p

Rt
z0,0
1 + 4(
k

k

p

+ tR0B + R0B)2

.

(15)

¯
Et

Et+1|
(cid:0)

(cid:1)
max
ˆz∈Wr+RtB (zt,0)
zt,K

zt,0

−

k ≤

max
ˆz∈Wr+RtB (zt,0)

k
(cid:0)

P

P

≥
=P

P

−

P

≥

RtB

¯
Et
(xt,K , ˆy)
(cid:12)
(cid:12)

(cid:1)

L

(ˆx, yt,K)

− L
r

>

H

zt,K

zt,0

−

k ≤

RtB

P

−

max
ˆz∈Wr+Rt B (zt,0)

(cid:1)

k
(cid:0)

L

(xt,K , ˆy)

L

(ˆx, yt,K)

− L
r

Rt/ log log K

≤

H

1 + 4(
k

z0,0

k

+ (t + 1)R0B)2

zt,K

,

k

−

zt,0

k ≤

RtB

p

Rt/ log log K

z0,0

+ (t + 1)R0B)2

1 + 4(
k
(xt,K , ˆy)
p

k
(ˆx, yt,K)

− L
r

>

H

zt,K

,

k

−

zt,0

k ≤

RtB

Rt/ log log K

1 + 4(
k

z0,0

k

p

+ (t + 1)R0B)2

.

!

¯
Et
(cid:12)
(16)
(cid:12)

¯
Et

!

¯
Et

!

(cid:12)
(cid:12)

(cid:12)
(cid:12)

Next, we set C1 = 3 +
solution z
∗
the second term in the right hand side of (16) by Markov inequality:

and r = RtB, then we know there exists an optimal
1
Wr+RtB(zt,0), because r + RtB = 2RtB > Rt. Then we can upper bound
q

such that z

∗ ∈

−

δ

p , B = 2T C1

2

P

max
ˆz∈Wr+RtB (zt,0)

(xt,K , ˆy)

L

(ˆx, yt,K)

− L
r

>

H

+ (t + 1)R0B)2

+ (t + 1)R0B)2

z0,0

+ (t + 1)R0B)2

H log log K

H log log K

z0,0

1 + 4(
k
rRt

p

z0,0

1 + 4(
k
rRt

p

H log log K

1 + 4(
k
rRt
z0,0
H log log K(1 + 2(
k
rRt

p

k

k

k

≤

≤

≤

≤

p

E

(cid:20)
35
4τ K

35
4τ K
35
4τ K

+ (t + 1)R0B))

k

(r + RtB)2 ,

Rt/ log log K

1 + 4(
k

z0,0

k

+ (t + 1)R0B)2

¯
Et

!

max
ˆz∈Wr+Rt B (zt,0) L

(xt,K, ˆy)

− L

(cid:12)
(cid:12)
(ˆx, yt,K)
(cid:21)

maxz∈Wr+Rt B (zt,0)k

zt,0

2

z

k

−

(17)

(r + RtB)2

where the second inequality follows from Lemma 3, by noticing z
inequality uses √1 + x

1 + √x. Combining Equation (6), (16) and (17), we obtain

∗ ∈

Wr+RtB(zt,0), and the last

≤

P(

Et+1|

¯
Et)

1

−

≥

3 +

(cid:18)

2

1

r

p

(cid:19)

−

1
B −

35H
4τ

log log K
K

(r + RtB)2
rRt

1 + 2(
k

z0,0

k

+ (t + 1)R0B)

(cid:0)

(cid:1)

16

 
 
 
 
Furthermore, by recalling r = RtB, we obtain

P

RT ≤
(cid:18)

R0
2T

P(

∩

≥

T

T

(cid:19)
t=1Et) = P(
E1)
2

3 +

1

≥

−

(cid:18)

1

r

−

p

(cid:19)

t=2
Y
T
B −

P(

¯
Et
−

Et|

1)

P

RT ≤
(cid:18)

R0
2T

(cid:19)

1

−

≥

3 +

(cid:18)

1

r

Q
2
p

−

(cid:19)

Recall τ = √p

2L and B = 2T C1

δ

, thus

where the last inequality comes from

i(1

xi)

1

i xi for xi > 0. Thus we have

35H
4τ

log log K
K

(B + B)2
B

T + 2T

z0,0
k

k

+ T (T + 1)R0B

(cid:0)

−
T
B −

≥
35HB
τ

−
P
log log K
K

T + 2T

z0,0

k

k

+ T (T + 1)R0B

(cid:0)

(cid:1)

(cid:1)

P

RT ≤

(cid:18)

R0
2T

≥

(cid:19)

≥

≥

δ
2 −

δ
2 −
δ
2 −

1

1

1

−

−

−

140HL
√p
140HL
√p

log log K
K

log log K
K

T
δ

T
δ

(cid:18)
T 3
δ

T + 2T

z0,0
k

k

+ T (T + 1)R0

2T C1
δ

(cid:19)

z0,0
(1 + 2
k

k

+ 4C1R0)

HL

log log K
K

T 4
δ2

140
√p

z0,0
(1 + 2
k

k

+ 4C1R0) .

z0,0
Denote C2 = C2(z0,0) = 140(1 + 2
k

+ 4C1R0). Then if

k
2C2
√p

K

≥

HL

T 4
δ3 log

2C2
√p

(cid:18)

HL

T 4
δ3

,

(cid:19)

we have

HL

log log K
K

T 4
δ2

140
√p

z0,0
(1 + 2
k

k

+ 4C1R0)

δ
2

,

≤

for the same reason as Equation (12). Thus, we obtain

P

RT ≤
(cid:18)

R0
2T

(cid:19)

1

−

≥

δ
2 −

HL

log log K
K

T 4
δ2

140
√p

z0,0
(1 + 2
k

k

+ 4C1R0)

1

−

≥

δ .

√p HL T 4
In summary, choosing T =
log2
ber of iteration to get ǫ accuracy with probability at least 1

max

, K

R0
ǫ

2C2

≥

δ3 log

n

(cid:6)

(cid:7)

2C2

√p HL T 4

δ3

, 2000

, the total num-

δ is T K which is of order
(cid:16)
(cid:17)

o

−

1
√p

˜
O  

1/[H(1 +

L
z0,0
k

k

+ R0)]

1
δ3

(cid:18)

log

R0
ǫ

5

.

!

(cid:19)

17

4 Lower Bound

In this section, we establish the complexity lower bound of stochastic ﬁrst-order algorithms (with
variance reduction) for solving sharp primal-dual problems. Together with the results shown in
Section 3 , we demonstrate that RsEGM has nearly optimal convergence rate (upto log terms)
among a large class of stochastic primal-dual methods.

Since we study the lower bound in this section, we can assume

is diﬀerentiable everywhere, thus
is well deﬁned. Recall that in deterministic ﬁrst-order primal-dual methods, we utilize the
∇L
gradient information to update the iterates. Thus, the iterates of ﬁrst-order methods always stay
in the subspace spanned by the gradient, and we call this behavior ﬁrst-order span-respecting (see
for example [6] ) deﬁned as below:

L

Deﬁnition 2. A deterministic primal dual algorithm is called ﬁrst-order span-respecting if its
iterates satisfy

x0 + Span
y0 + Span

xt
yt

∈

∈

(xi, yj) :
(xi, yj) :

i, j

1, ..., t

∈ {
1, ..., t

−
j

,
}

∀

∈ {

∀
i

∀

1
}
1, ..., t
(cid:9)
∈ {

−

∇xL
(cid:8)
∇yL
(cid:8)

1
}
(cid:9)

Many classic primal dual ﬁrst-order methods, such as GDA, AGDA and EGM, are ﬁrst-order
span-respecting when applying unconstrained problems.

In this paper, we study stochastic algorithms with variance reduction. As a result, we consider
a general class of stochastic algorithms where the span includes both the deterministic gradient
(for variance reduction sake) and the stochastic oracle Fξ. More formally, we introduce stochastic
span-respecting algorithms, deﬁned as below:

Deﬁnition 3. A randomized primal dual algorithm is called ﬁrst-order stochastic span-respecting
with respect to a stochastic oracle ξ if the iterates in Rm satisfy:

x0 + Span

xt

∈

yt

y0 + Span

∇xL

n
∇yL

∈
ξi,j are random variables.

n

(xi, yj),

(xi, yj) :

i, j

1, ..., t

∇

ξi,j
x L
ξi,j
y L

(xi, yj),

∇

(xi, yj) :

∀
i

∀

∈ {
1, ..., t

∈ {

−

1
}
o
j

∀

−
,
1
}

1, ..., t

∈ {

}
o

Remark 5. The above deﬁnition consists of both deterministic gradient together with the stochastic
gradient estimator. The reason is to include the variance reduction method into the algorithm class.
Obviously the above algorithm class is larger than the one only with deterministic or stochastic
gradient. As a result, the lower bound is generally higher than a pure stochastic algorithm.

Remark 6. If
ﬁrst-order stochastic span-respecting.

L

is bilinear, then with appropriate indexing of iterates, sEGM and RsEGM are

N and parameter value L > √2α > 0. There exists
Theorem 4. Consider any iteration t
an α-sharp primal-dual problem that satisﬁes Assumption 1 and an L-Lipschitz (in expectation)
stochastic oracle Fξ that satisﬁes Assumption 2, such that the iterates zt of any stochastic span-
respecting algorithm satisﬁes that

∈

dist(zt,

∗)

Z

≥

t

1
1
√2  

−

α√2
L !

dist(z0,

∗) .

Z

18

Remark 7. Theorem 4 implies the following lower complexity bound for a stochastic ﬁrst-order
method to achieve an ǫ-accuracy solution:

Ω

L
α

(cid:18)

log

R0
ǫ

(cid:19)

.

Proof of Theorem 4. Set m = 2t. We consider a primal-dual problem of the form

min
R2m
x
∈

max
y
∈

R2m L

(x, y) = yT Ax

bT y ,

−

(18)

The matrix A

∈

R2m

×

2m and vector b

∈

R2m have the structure

A0

A =

(cid:18)

, b =

A0(cid:19)

b0
b0(cid:19)

(cid:18)

,

Rm
m and b0 ∈
where A0 ∈
and y = (y1, y2), we obtain:

×

Rm are determined later. Rewriting the problem using x = (x1, x2)

min
R2m
x
∈
bT
0 y1,

(x, y) =

max
y
∈

R2m L
L2(x, y) = yT

L1(x, y) +
bT
0 y2 .

L2(x, y) ,

where

L1(x, y) = yT

2 A0x2 −
For any given Lipschitz parameter L and sharpness parameter α such that L > √2α, we denote
Q = L2

1 A0x1 −

2α2 , κ = √Q+3

√Q+1 , and

G0 =

1
−
2
1

−

1
−
2
. . .

1
−
. . .
1

−

2
1

−












−
4I. Denote

G0 (cid:22)
G0 + α2I, h0 =

(cid:22)
α2

. . .
2
1

.






1


−

κ



α2

L2/2
−
4

e1 ,

Note that it holds for any κ

≤

3 that 0

H0 =

L2/2
−
4

where e1 is the ﬁrst standard unit vector. One can check that the solution of the linear system
H0u = h0 is unique and given by

Rm such that u∗i = qi, i = 1, 2, ..., m ,

u∗

∈

with q = √Q
−

1

√Q+1 . Furthermore, it holds that

α2I

H0 (cid:22)

(cid:22)

L2
2

I .

Choose A0 = H 1/2
Ax = b, AT y = 0 , which is equivalent to

, b0 = H −
0

1/2

0

h0 and consider (18). The optimal solution to (18) is given by

A0x1 = b0, AT

0 y1 = 0, A0x2 = b0, AT

0 y2 = 0 ,

19

and thus

H0x1 = h0, y1 = 0, H0x2 = h0, y2 = 0 .
The optimal solution to (18) is given by z∗ = (x∗1, x∗2, y∗1, y∗2) = (u∗, u∗, 0, 0). Moreover, the primal-
dual problem (18) is α-sharp, because

αIm (cid:22)

A0 = H 1/2

0

, αI2m (cid:22)

A =

A0

(cid:18)

.

A0(cid:19)

Without loss of generality we assume x0 = y0 = 0. Consider the stochastic oracle

Fξ(z) = 2(

−∇yLξ(x, y)),

∇xLξ(x, y),
2(AT
2(0, AT

0 y1, 0, A0x1 −

b, 0), with probability 1
2
b), with probability 1
2

=

.

(19)

2]
Fξ(v)
k

−

≤

L2

u
k

−

v

2, thus the stochastic
k

0 y2, 0, A0x2 −
Then we know that Fξ(z) is unbliased and E[
Fξ(u)
k
gradient oracle satisﬁes Assumption 2.

(

By deﬁnition of span-respecting for randomized algorithms with the above oracle:

xt
1 ∈
xt
2 ∈
yt
1 ∈
yt
2 ∈

x0
1 + Span
x0
2 + Span
y0
1 + Span
y0
2 + Span

1

1

AT
0 y0
0 y0
AT
(cid:8)
A0x0
(cid:8)
A0x0
(cid:8)

1, ..., AT
2, ..., AT

0 yt
−
1
0 yt
(cid:9)
−
2
b0, ..., A0xt
1
(cid:9)
−
1 −
1
b0, ..., A0xt
−
2 −

1 −
2 −

thus it holds that

(cid:8)

b0
b0

(cid:9)

(cid:9)

xt
1 ∈
xt
2 ∈

Span nAT
Span nAT

0 (A0x0

b), ..., AT

0 (A0x0

b), ..., AT

1 −

2 −

0 (A0xt−1
0 (A0xt−1

1 −

2 −

b)o = Span nH0x0
b)o = Span nH0x0

1 −

2 −

h0, ..., H0xt−1

1 −

h0, ..., H0xt−1

2 −

h0o ⊆ {
h0o ⊆ {

e1, ..., et

e1, ..., et

}

}

Therefore, we have when m is suﬃciently large that

where the last inequality uses m = 2t, 0 < q < 1 and the fact that q4t

2

xt
1 −
k
x0
1 −
k

u∗k
u∗k

2 ≥ P
P

m
k=t+1 q2k
k=1 q2k = q2t 1
m

q2m

2t

−
q2m ≥

q2t ,

1
2

−
1

−

2q2t + 1 = (q2t

1)2

0.

≥

−

−

Similar result holds for x2:

To sum up, for any t

∈

2

xt
2 −
k
x0
1 −
k

u∗k
u∗k
N there exists an integer m
dist(zt,

∗)2

2 ≥

Z

q2t .

1
2
2t such that
2, u∗)2
q2tdist(x0

2, u∗)2

≥
1, u∗)2 + dist(xt
1
1, u∗)2 +
2
x0, (u∗, u∗)

dist(xt
1
2
1
2

q2tdist

q2tdist(x0

2

≥

≥

=

=

1
2  

1

−

(cid:0)
α√2
L !

2t

(cid:1)
dist(z0,

∗)2 ,

Z

20

(20)

(21)

where second inequality is from Equation (21). Last equality uses y∗1 = y∗2 = y0
square root we ﬁnally reach

1 = y0

2 = 0. Taking

dist(zt,

∗)

Z

≥

t

1
√2  

1

−

α√2
L !

dist(z0,

∗) .

Z

(22)

Remark 8. RsEGM with the stochastic gradient oracle Fξ given in the proof (see (19)) has upper
bound equal to ˜
. Compared with the above lower bound for unconstrained
O

3

(cid:16)
bilinear problem, Ω

(cid:17)
, we conclude that RsEGM is tight up to logarithmic factors.

A
2
k
k
σ+
min(A)
A
(cid:0)
2
k
k
σ+
min(A)

log R0
ǫ
log R0
ǫ

(cid:1)

(cid:17)

(cid:16)

5 Stochastic Oracles

In this section, we propose four stochastic oracles and apply the main results to compute their
total ﬂop counts to obtain an approximate solution to the unconstrained bilinear problems and
standard-form LP.

5.1 Unconstrained Bilinear Problems

We consider unconstrained bilinear problems

min
Rn
x
∈

max
Rm
y
∈

yT Ax + cT x

bT y .

−

Without loss of generality, we drop the linear terms cT x
shifting the origin. Now we consider the unconstrained bilinear problems of the form

bT y because this can be achieved by

−

where A

Rm

×

∈

n. For comparison sake, we assume nnz(A)

m + n.

≥

Converting to (1) and calculating F (z), we have

min
Rn
x
∈

max
Rm
y
∈

yT Ax ,

F (z) = F (x, y) =

AT y
Ax

−

(cid:18)

(cid:19)

, g1(x) = g2(y) = 0 .

First, we restate the total ﬂop count of the optimal deterministic ﬁrst-order primal dual method
(it is achieved by restart primal-dual algorithms [6]). In order to obtain ǫ accuracy solution, the
, thus the total ﬂop counts is (by noticing the
number of primal-dual iterations is
ﬂop count of one primal-dual iteration is O(nnz(A)))
(cid:17)

α log R0

O

2
k

(cid:16)

A

k

ǫ

nnz(A) k

A
k2
α

log

R0
ǫ

.

(cid:19)

O

(cid:18)

To ease the comparison of the ﬂop counts, we state the following simple fact ([44]):

max {kAi·k2, kA·j k2} ≤ kAk2 ≤ kAkF ≤

max {m, n} · max {kAi·k2, kA·jk2} ≤

max {m, n} · kAk2

(23)

p

21

p

Next, we describe four diﬀerent stochastic oracles that satisﬁes Assumption 2. We will discuss their
ﬂop counts and how they improve deterministic restarted methods in diﬀerent regimes.

The ﬁrst two oracles are based row/column sampling, i.e. the stochastic oracle is constructed using
one row and one column. The stochastic oracle is given by the following

Fξ(z) =

1
Ai
ri
·
1
A
cj
·

−

yi
jxj !

, P(ξ = (i, j)) = ricj ,

where cj ≥
n
j=1 cj =

0 for j = 1, ..n and ri ≥
n
i=1 ri = 1. Notice that

0 for i = 1, ...m are parameters of the sampling scheme with

P

P

E

2
Fξ(z)
k
k

(cid:2)

(cid:3)

=

=

≤

m

Xi=1
m

Xi=1
max
i,j

n

1
ri

rik

Ai

·

2 +

yik

cjk −

1
cj

A
·

2

jxjk

1
ri

y2
i k

Ai

·k

2 +

2
Ai
k
·k
ri

(cid:26)

, k

Xj=1
n
1
cj

Xj=1
2
A
jk
·
cj (cid:27)

x2
j k

A
·

2
jk

z
k

2 .
k

Thus the Lipschitz constant of stochastic oracle Fξ is bounded by

L

max
i,j

≤ s

2
Ai
k
·k
ri

, k

2
A
jk
·
cj (cid:27)

.

(cid:26)

(24)

Oracle I: Uniform row-column sampling. In the ﬁrst oracle, we uniformly randomly choose
row and columns, i.e.,

Fξ(z) =

1
Ai
ri
·
1
A
cj
·

−

yi
jxj !

, P(ξ = (i, j)) = ricj, ri =

1
m

, cj =

1
n

.

Plugging in the choice of ri and cj into Equation (24), the Lipschitz constant of Fξ is upper bounded
by

L1 ≤

max

m
{

Ai
k

2
2, n
·k

A
k
·

2
jk
2} ≤

max

m, n
{

} ·

max

Ai

{k

·k2,

A
k
·

jk2}

.

(25)

q

p

Combine Equation (4) together with (25) and set p = m+n
ﬁnd an ǫ-optimal solution using Oracle I is upper bounded by

nnz(A) . The total ﬂop count of RsEGM to

nnz(A) log

˜
O  

R0
ǫ

+

nnz(A)(m + n)

p

max

m, n

{

p

}

max
α

Ai·k2,

A·jk2}

k

{k

log

R0
ǫ

(cid:18)

3

!

(cid:19)

Up to logarithmic factors, the RsEGM with uniformly sampled stochastic oracle is no worse than
the deterministic method when A is dense according to Equation (23). And it improves the deter-
·k2,
ministic method when A is dense and max

jk2} ≪ k

k2.
A

A
k
·

Ai

{k

22

 
 
Oracle II: Importance row-column sampling. In the second oracle, we use importance sam-
pling to set the probability to select rows and columns:

Fξ(z) =

1
Ai
ri
·
1
A
cj
·

−

yi
jxj !

2
Ai
, P(ξ = (i, j)) = ricj, ri = k
2
·k
2
A
F
k
k

2
A
jk
2
, cj = k
·
2
A
F
k
k

.

Plugging in the choice of ri and cj into Equation (24), the Lipschitz constant of Fξ is upper bounded
by

kF .
A
L2 ≤ k

(26)

Combining equation (4) with (26) and setting p = m+n
Oracle II to ﬁnd an ǫ-optimal solution is

nnz(A) , the total ﬂop count of RsEGM with

nnz(A) log

˜
O  

R0
ǫ

+

p

nnz(A)(m + n) k

A
kF
α

log

R0
ǫ

(cid:18)

3

.

!

(cid:19)

It follows from (23) that if A is dense, RsEGM with importance sampled stochastic oracle is no
worse than the optimal deterministic method up to a logarithmic factor. Furthermore, it improves
2
A
nnz(A)
F
m+n , which is the case for low-rank dense
the deterministic method when the stable rank k
k
2
A
2 ≪
k
k
matrix A.

In the above two oracles, the ﬂop cost of computing the stochastic oracle is
(m + n). This
can be further improved by using coordinate based sampling, where the ﬂop cost per iteration is

O

(1).

O
Oracle III: Coordinate gradient estimator [10].
The third oracle only updates a primal
coordinate and a dual coordinate, thus the cost per iteration can be as low as O(1). The idea
follows from [10]. More formally, we set

Fξ(z) =

(cid:18)

Aixjxyix
pixjx

ejx,

Aiyjy xjy
qiyjy

−

eiy

T

,

(cid:19)

(27)

where ix, iy ∈ {

1, ..., n

, jx, jy ∈ {
}

1, ..., m

, and
}

P((ix, jx) = (i, j)) = pij = k

2
1

Ai·k
Ai·k
i k

2
1

, P((iy, jy) = (i, j)) = qij = k

2
1

A·jk
A·jk
j k

Aij |
|
A·jk1
k

2
1

It is easy to check that Aixjx yix
Ax
respectively. Furthermore, one can show the Lipschitz constant of the Oracle III (in expectation)
is (see [10] for more details):

eiy are unbiased estimators for AT y and

P
pixjx ejx and

P

−

−

Aij |
|
Ai·k1
k
Aiy jy xjy
qiy jy

L3 = max




sXi

Ai
k

2
1,
·k

A
k
·

2
jk
1


≤

sXj

√m + n

A

2 ,

(28)

(cid:13)
(cid:13)

(cid:12)
(cid:12)

(cid:12)
(cid:13)
(cid:13)
(cid:12)

is the matrix with entry-wise absolute value of A. Thus Oracle III satisﬁes Assumption



A

where
2 with Lipschitz constant L3.



(cid:12)
(cid:12)

(cid:12)
(cid:12)

23

 
Combine Equation (4) together with (28) and set p = 1
III equals

nnz(A) . The total cost of RsEGM with Oracle

nnz(A) log

˜
O 



R0
ǫ

+

nnz(A)

p

max

Ai

i k

2
1,
·k
α

{
qP

qP

A
·

j k

2
jk
1}

log

R0
ǫ

3

(cid:19)

(cid:18)






For entry-wise non-negative dense matrix A, RsEGM with Oracle III improve deterministic methods
by a factor of
. Unfortunately, there is no guaranteed improvement for a general
matrix A that involves negative value due to the deﬁnition of Lipschitz constant L3.

m, n
{

max

}

p

Oracle IV: Coordinate gradient estimator with a new probability distribution. Inspired
by Oracle III, we propose Oracle IV, where we utilize the same gradient estimation (27) but with
diﬀerent probability values pij and qij:

P((ix, jx) = (i, j)) = pij =

, P((iy, jy) = (i, j)) = qij =

A2
ij
2
A
F
k
k
eiy are unbiased estimators for AT y and

A2
ij
2
A
F
k
k

.

Similarly, we know Aixjx yix
tively. Furthermore, the Lipschitz constant of Oracle IV can be computed by:

pixjx ejx and

Aiy jy xjy
qiy jy

−

Ax respec-

−

E

2
Fξ(z)
k
k

(cid:2)

(cid:3)

=

=

Xix,jx

pixjx(

Aixjxyix
pixjx

)2 +

qiyjy (

−

Aiyjy xjy
qiyjy

)2

(Aixjx)2
pixjx

(yix)2 +

(Aiyjy )2
qiyjy

(xjy )2

Xiy,jy

Xiy,jy

Xix,jx
2
z
A
F k
k
k
kF . Combine Equation (4) with L4 =
A
k

2 .
k

=

kF and set p = 1
Thus, L4 =
A
k
of RsEGM with Oracle IV to ﬁnd an ǫ-solution becomes

nnz(A) . The total ﬂop cost

nnz(A) log

˜
O  

R0
ǫ

+

nnz(A) k

A
kF
α

p

log

R0
ǫ

(cid:18)

3

.

!

(cid:19)

Note that when the matrix A in the unconstrained bilinear problem is dense, RsEGM improves
the total ﬂop counts of deterministic primal-dual method (upto log terms) by at least a factor of
. The improvement does NOT require extra assumptions on the spectral property of

max

m, n
{

}

A (such as Oracle II) nor non-negativity of entries of A (such as Oracle III).
p

5.2 Linear programming

Consider the primal-dual formulation of standard form LP (2). For the ease of comparison, we
assume nnz(A)

m + n. Furthermore, we set

≥

F (z) =

AT y
Ax

−

(cid:19)

(cid:18)

, g1(x) = cT x + ι
{

x

0

}

≥

, g2(y) = bT y.

(29)

24

Recall that R0 = dist(z0,0,
for details)

Z ∗). The total ﬂop count of restarted primal-dual algorithms is (see [6]

O

nnz(A)

(cid:18)

A
k2
k
z0,0
1/[H(1 +
k

k

+ R0)]

log

R0
ǫ

(cid:19)

Consider RsEGM with stochastic Oracle II (importance sampling)

Fξ(z) =

1
Ai
ri
·
1
A
cj
·

−

yi
jxj !

2
Ai
, P(ξ = (i, j)) = ricj, ri = k
2
·k
2
A
F
k
k

2
A
jk
2
, cj = k
·
2
A
F
k
k

.

Similar to the unconstrained bilinear case (Section 5.1), we can obtain the ﬂop count

nnz(A) log

˜
O  

R0
ǫ

+

nnz(A)(m + n)

p

A
kF
k
z0,0
1/[H(1 +
k

k

+ R0)]

(cid:18)

log

R0
ǫ

5

!

(cid:19)

Next, we consider RsEGM with Oracle IV, i.e.,

Fξ(z) =

(cid:18)

Aixjxyix
pixjx

ejx,

Aiyjy xjy
qiyjy

−

T

eiy

, pij =

(cid:19)

A2
ij
2
A
F
k
k

, qij =

A2
ij
2
A
F
k
k

.

With a similar calculation, we can obtain the ﬂop count:

nnz(A) log

˜
O  

R0
ǫ

+

nnz(A)(m + n)

p

A
kF
k
z0,0
1/[H(1 +
k

k

+ R0)]

(cid:18)

log

R0
ǫ

5

!

(cid:19)

Finally, we comment that unlike unconstrained bilinear problem, RsEGM with Oracle II and Oracle
IV for LP has the same order of total cost. This is because the projection onto non-negative orthant
in LP requires

(1) as in unconstrained cases.

(m + n) ﬂops rather than

O

O

6 Conclusions

In this work, we introduce a stochastic algorithm for sharp primal-dual problems, such as linear
programming and bilinear games, using variance reduction and restart. We show that our proposed
stochastic methods enjoy a linear convergence rate, which improves the complexity of the existing
algorithms in the literature. We also show that our proposed algorithm achieves the optimal
convergence rate (upto a log term) in a wide class of stochastic algorithms.

References

[1] Ahmet Alacaoglu, Olivier Fercoq, and Volkan Cevher, On the convergence of stochastic primal-

dual hybrid gradient, arXiv preprint arXiv:1911.00799 (2019).

[2] Ahmet Alacaoglu and Yura Malitsky, Stochastic variance reduction for variational inequality

methods, arXiv preprint arXiv:2102.08352 (2021).

[3] Randy I Anderson, Robert Fok, and John Scott, Hotel industry eﬃciency: An advanced linear

programming examination, American Business Review 18 (2000), no. 1, 40.

25

 
[4] David Applegate, Mateo D´ıaz, Oliver Hinder, Haihao Lu, Miles Lubin, Brendan O’Donoghue,
and Warren Schudy, Practical large-scale linear programming using primal-dual hybrid gradient,
arXiv preprint arXiv:2106.04756 (2021).

[5] David Applegate, Mateo D´ıaz, Haihao Lu, and Miles Lubin, Infeasibility detection with primal-
dual hybrid gradient for large-scale linear programming, arXiv preprint arXiv:2102.04592
(2021).

[6] David Applegate, Oliver Hinder, Haihao Lu, and Miles Lubin, Faster ﬁrst-order primal-dual
methods for linear programming using restarts and sharpness, arXiv preprint arXiv:2105.12715
(2021).

[7] Kinjal Basu, Amol Ghoting, Rahul Mazumder, and Yao Pan, ECLIPSE: An extreme-scale
linear program solver for web-applications, Proceedings of the 37th International Conference
on Machine Learning (Virtual) (Hal Daum´e III and Aarti Singh, eds.), Proceedings of Machine
Learning Research, vol. 119, PMLR, 13–18 Jul 2020, pp. 704–714.

[8] Edward H Bowman, Production scheduling by the transportation method of linear programming,

Operations Research 4 (1956), no. 1, 100–103.

[9] Yair Carmon, Yujia Jin, Aaron Sidford, and Kevin Tian, Variance reduction for matrix games,

arXiv preprint arXiv:1907.02056 (2019).

[10]

, Coordinate methods for matrix games, 2020 IEEE 61st Annual Symposium on Foun-

dations of Computer Science (FOCS), IEEE, 2020, pp. 283–293.

[11] Antonin Chambolle, Matthias J Ehrhardt, Peter Richt´arik, and Carola-Bibiane Schonlieb,
Stochastic primal-dual hybrid gradient algorithm with arbitrary sampling and imaging applica-
tions, SIAM Journal on Optimization 28 (2018), no. 4, 2783–2808.

[12] Antonin Chambolle and Thomas Pock, A ﬁrst-order primal-dual algorithm for convex problems
with applications to imaging, Journal of mathematical imaging and vision 40 (2011), no. 1,
120–145.

[13] Abraham Charnes and William W Cooper, The stepping stone method of explaining linear
programming calculations in transportation problems, Management science 1 (1954), no. 1,
49–69.

[14] George Bernard Dantzig, Linear programming and extensions, vol. 48, Princeton university

press, 1998.

[15] Constantinos Daskalakis, Andrew Ilyas, Vasilis Syrgkanis, and Haoyang Zeng, Training GANs

with optimism, International Conference on Learning Representations, 2018.

[16] Damek Davis, Dmitriy Drusvyatskiy, Kellie J MacPhee, and Courtney Paquette, Subgradient
methods for sharp weakly convex functions, Journal of Optimization Theory and Applications
179 (2018), no. 3, 962–982.

[17] Aaron Defazio, Francis Bach, and Simon Lacoste-Julien, Saga: A fast incremental gradient
method with support for non-strongly convex composite objectives, Advances in neural infor-
mation processing systems, 2014, pp. 1646–1654.

26

[18] Jim Douglas and Henry H Rachford, On the numerical solution of heat conduction problems in
two and three space variables, Transactions of the American mathematical Society 82 (1956),
no. 2, 421–439.

[19] Jonathan Eckstein and Dimitri P Bertsekas, On the Douglas—Rachford splitting method and
the proximal point algorithm for maximal monotone operators, Mathematical Programming 55
(1992), no. 1-3, 293–318.

[20] Jonathan Eckstein, Dimitri P Bertsekas, et al., An alternating direction method for linear

programming, (1990).

[21] Olivier Fercoq, Quadratic error bound of the smoothed gap and the restarted averaged primal-

dual hybrid gradient, (2021).

[22] Robert M Freund and Haihao Lu, New computational guarantees for solving convex optimiza-
tion problems with ﬁrst order methods, via a function growth condition measure, Mathematical
Programming 170 (2018), no. 2, 445–477.

[23] Jacek Gondzio, Interior point methods 25 years later, European Journal of Operational Re-

search 218 (2012), no. 3, 587–601.

[24] Robert M Gower, Mark Schmidt, Francis Bach, and Peter Richt´arik, Variance-reduced methods

for machine learning, Proceedings of the IEEE 108 (2020), no. 11, 1968–1983.

[25] Fred Hanssmann and Sidney W Hess, A linear programming approach to production and em-

ployment scheduling, Management science (1960), no. 1, 46–51.

[26] Alan J Hoﬀman, On approximate solutions of systems of linear inequalities, Journal of Research

of the National Bureau of Standards 49 (1952), 263–265.

[27] Thomas Hofmann, Aurelien Lucchi, Simon Lacoste-Julien, and Brian McWilliams, Variance

reduced stochastic gradient descent with neighbors, arXiv preprint arXiv:1506.03662 (2015).

[28] Rie Johnson and Tong Zhang, Accelerating stochastic gradient descent using predictive variance

reduction, Advances in neural information processing systems 26 (2013), 315–323.

[29] Narendra Karmarkar, A new polynomial-time algorithm for linear programming, Proceedings

of the sixteenth annual ACM symposium on Theory of computing, 1984, pp. 302–311.

[30] Galina M Korpelevich, The extragradient method for ﬁnding saddle points and other problems,

Matecon 12 (1976), 747–756.

[31] Dmitry Kovalev, Samuel Horv´ath, and Peter Richt´arik, Don’t jump through hoops and remove
those loops: Svrg and katyusha are better without the outer loop, Algorithmic Learning Theory,
PMLR, 2020, pp. 451–467.

[32] Puya Latafat, Nikolaos M Freris, and Panagiotis Patrinos, A new randomized block-coordinate
primal-dual proximal algorithm for distributed optimization, IEEE Transactions on Automatic
Control 64 (2019), no. 10, 4050–4065.

[33] Adrian S Lewis and Jingwei Liang, Partial smoothness and constant rank, arXiv preprint

arXiv:1807.03134 (2018).

27

[34] Jingwei Liang, Jalal Fadili, and Gabriel Peyr´e, Local linear convergence analysis of primal–dual

splitting methods, Optimization 67 (2018), no. 6, 821–853.

[35] Hongzhou Lin, Julien Mairal, and Zaid Harchaoui, A universal catalyst for ﬁrst-order opti-

mization, Advances in neural information processing systems, 2015, pp. 3384–3392.

[36] Tianyi Lin, Shiqian Ma, Yinyu Ye, and Shuzhong Zhang, An admm-based interior-point method
for large-scale linear programming, Optimization Methods and Software 36 (2021), no. 2-3,
389–424.

[37] Qian Liu and Garrett Van Ryzin, On the choice-based linear programming model for network
revenue management, Manufacturing & Service Operations Management 10 (2008), no. 2,
288–310.

[38] Haihao Lu, An O(sr)-resolution ODE framework for discrete-time optimization algorithms and
applications to convex-concave saddle-point problems, arXiv preprint arXiv:2001.08826 (2020).

[39] Alan S Manne, Linear programming and sequential decisions, Management Science 6 (1960),

no. 3, 259–267.

[40] Aryan Mokhtari, Asuman Ozdaglar, and Sarath Pattathil, A uniﬁed analysis of extra-gradient
and optimistic gradient methods for saddle point problems: Proximal point approach, Interna-
tional Conference on Artiﬁcial Intelligence and Statistics, 2020.

[41] Arkadi Nemirovski, Prox-method with rate of convergence O(1/t) for variational inequalities
with lipschitz continuous monotone operators and smooth convex-concave saddle point prob-
lems, SIAM Journal on Optimization 15 (2004), no. 1, 229–251.

[42] Yurii Nesterov, Gradient methods for minimizing composite functions, Mathematical Program-

ming 140 (2013), no. 1, 125–161.

[43] Brendan O’Donoghue and Emmanuel Candes, Adaptive restart

for accelerated gradient

schemes, Foundations of computational mathematics 15 (2015), no. 3, 715–732.

[44] Balamurugan Palaniappan and Francis Bach, Stochastic variance reduction methods for saddle-
point problems, Advances in Neural Information Processing Systems, 2016, pp. 1416–1424.

[45] Sebastian Pokutta, Restarting algorithms: Sometimes there is free lunch, International Con-
ference on Integration of Constraint Programming, Artiﬁcial Intelligence, and Operations Re-
search, Springer, 2020, pp. 22–38.

[46] Boris Polyak, Sharp minima, Proceedings of the IIASA Workshop on Generalized Lagrangians
and Their Applications, Laxenburg, Austria. Institute of Control Sciences Lecture Notes,
Moscow, 1979.

[47] R. Tyrrell Rockafellar, Monotone operators and the proximal point algorithm, SIAM Journal

on Control and Optimization 14 (1976), no. 5, 877–898.

[48] Vincent Roulet and Alexandre d’Aspremont, Sharpness, restart, and acceleration, SIAM Jour-

nal on Optimization 30 (2020), no. 1, 262–289.

[49] Mark Schmidt, Nicolas Le Roux, and Francis Bach, Minimizing ﬁnite sums with the stochastic

average gradient, Mathematical Programming 162 (2017), no. 1-2, 83–112.

28

[50] Junqi Tang, Mohammad Golbabaee, Francis Bach, et al., Rest-katyusha: exploiting the so-
lution’s structure via scheduled restart schemes, Advances in Neural Information Processing
Systems, 2018, pp. 429–440.

[51] Paul Tseng, On linear convergence of iterative methods for the variational inequality problem,

Journal of Computational and Applied Mathematics 60 (1995), no. 1-2, 237–252.

[52] Tianbao Yang and Qihang Lin, RSG: Beating subgradient method without smoothness and
strong convexity, The Journal of Machine Learning Research 19 (2018), no. 1, 236–268.

[53] Renbo Zhao, Optimal stochastic algorithms for convex-concave saddle-point problems, arXiv

preprint arXiv:1903.01687 (2020).

29

A Appendix

A.1 Sharpness and metric sub-regularity

In this subsection we establish a connection between sharpness based on the normalized duality
gap [6] and metric sub-regularity [32]. The result is summarized in the following proposition.

Proposition 1. Consider primal-dual problem minx
primal-dual problem is sharp with constant α, i.e. αdist(z,
metric sub-regularity at z∗ for 0, i.e. αdist(z,

∈X

maxy
Z ∗)
dist(0, ∂
L

(x, y). If for any z

∈Y L
≤
(z)) = inf(u,

(z∗) the
ρr(z) for all r > 0, then it satisﬁes
(z) k

,
v)
k

∈ U

(u,

−

∈

∀

v)

z

−

L

∈

∂

Z ∗)

≤

(z∗).

U
Proof. For any (u,

v)

(z)

∂

L

∈

−

αdist(z,

∗)

Z

≤

ρr(z) =

1
r

max
Wr(z) L
∈

ˆz

(x, ˆy)

− L

(ˆx, y)

1
r
1
r
1
r
1
r
1
r

≤

=

≤

=

=

max
Br(z) L
∈

ˆz

max
Br(z) L
∈

ˆz

(x, ˆy)

(ˆx, y)

− L

(x, ˆy)

(x, y) +

(x, y)

L

− L

(ˆx, y)

− L

max
Br(z)
∈

ˆz

vT (ˆy

y) + (

−

−

u)T (ˆx

x)

−

max
Br(z) −
∈

ˆz

(u,

−

v)T (ˆz

z)

−

r

(u,
k

v)
k

−

=

(u,
k

v)
k

−

,

where the ﬁrst inequality utilizes the deﬁnition of sharpness, the third one is due to the convexity-
concavity of

(x, y).

L

Take inﬁmum over ∂

(z) we have

L

αdist(z,

∗)

Z

≤

(u,

inf
∂
v)
∈

L

−

(u,

(z) k

v)
k

−

= dist(0, ∂

(z))

L

A.2 LP does not satisfy metric sub-regularity globally

In this subsection, we present a counter-example to show that the Lagrangian’s generalized gradient
of LP does not satisfy metric sub-regularity globally.

Consider an LP

where A = (0 1)
form is

∈

R1

×

1T x,

s.t. Ax

b, x

0

min
R2
x
∈

≥
2 and b = 1. The optimal solution is unique x∗ = (0, 0). The primal dual

≤

(x, y) = 1T x + yT (Ax

L

b) + ι
{

x

−

0
} −

≥

ι
{

y

0

}

≥

,

30

and the optimal primal-dual solution z∗ = (02, 0). Notice that

∂L(z) =

(p, q)

(cid:26)

∈

R2+1

p

1 + AT y + ∂ι
{

x

0

}

≥

, q

∈

Ax + b + ∂ι
{

y

0

}

≥

∈ −

(cid:27)

thus

dist(0, ∂

(z))2 =

L

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(p,q)

p
∂L(z) k

inf
∈

2 + q2
k

≤

1 + (1 + y)2 + (1

x2)2

−

If the Lagrangian’s generalized gradient of LP satisﬁes global metric sub-regularity, i.e., there exists
(z)),
a constant η such that ηdist(z,

, then

z

≤

dist(0, ∂

Z ∗)
1
η2 (1 + (1 + y)2 + (1

L

≤

∀

∈ Z

x2)2),

−

∀

(x1, x2, y)

R3

+ .

∈

1 + x2
x2

2 + y2

However, this is impossible by ﬁxing x2, y and letting x1 → ∞
Therefore LP does not satisfy the global metric sub-regularity. Although we use Euclidean norm
for illustration, due to the equivalence of norms on Rn, LP does not satisfy the global metric sub-
regularity under any norm. Notice that metric subregularity is a weaker condition than sharpness
(see Appendix A.1). A direct consequence is that LP is not globally sharp.

. This leads to a contradiction.

A.3 Eﬃcient update for coordinate sampling

In Section 5.1, we propose two coordinate gradient estimators, Oracle III and Oracle IV. It turns
(1). The key is to
out with an eﬃcient computation, the cost per iteration for these oracles is
O
guarantee that the steps when wk is not updated have
(1) cost. In this subsection, we show how
this can be accomplished for unconstrained bilinear problems.

O

Consider a generic coordinate stochastic oracle

Fξ(z) = (cxex, dyey) ,

where ex, ey are standard unit vectors in Rm and Rn, respectively, and cx, dy are two arbitrary
scalars. Algorithm 3 rewrites Algorithm 1 so that it updates the iterates with

(1) cost.

O

Algorithm 3 sEGM for Unconstrained Bilinear Porblem: zk = sEGM (p, Q, τ, z0, K)

Input: Probability p

(0, 1], probability distribution Q, step size τ , number of iteration K. Let

∈

1

w0 = z0.
k
Output: zk = 1
l=0 zl+1/2.
−
k
1 do
1: for k = 0, 1, ..., K
−
P
p)zk + [pwk −
zk+1/2 = (1
2:
−
3: Draw an index ξk according to Q
p)zk + [pwk −
4:
−
zk+1, with prob. p
with prob. 1
wk

zk+1 = (1

wk+1 =

5:

p

(

τ F (wk)]

τ F (wk)]

−

6: end for

τ [Fξk (zk+1/2)

Fξk (wk)]

−

−

31

Suppose wk and wk+t+1 are two consecutive updates of w. The terms wk and u = p(wk)
stay the same from k to k + t. Note the update formula of zk+1/2 and zk+1+1/2

−

τ F (wk)

zk+1/2 = (1
zk+1+1/2 = (1
= (1

= (1

−

−

−

−

p)zk + u
p)zk+1 + u
p)[(1
−
p)2zk + [(1

−

p)zk + u

−
p) + 1]u

τ (Fξk (zk+1/2)
τ (1

−

Fξk (wk))] + u

−

−

p)(Fξk (zk+1/2)

Fξk (wk)) .

−

We suggest the following procedure for the period between two consecutive updates of wk:

(a) Maintain count of iterations from last update of wk.

(b) Maintain coordinate stochastic oracles. Fξk+i(zk+i+1/2) and Fξk+i(wk) can be computed
by extracting corresponding coordinates from zk, u, wk and previous Fξ’s. There is no need to
formulate zk+i+1/2 explicitly. The cost is

(1).

O

(c) Steps when updating snapshot. At time k + t + 1 we need to update w. There are several
τ G(p, t, ξ), where a(p, t)
steps to be done. First to compute
and b(p, t) are functions of parameter p and time t. G(p, t, ξ) is a linear combination of coordinate
stochastic oracles during this period. Due to (b) the cost of computing G(p, t, ξ) is
(t). Recall
p = 1
(nnz(A)) in expectation. Thus the cost
of computing

nnz(A) and notice that period length t equals

(nnz(A)). Next we compute zk+t+1 in the following way.

t
i=0 zk+i+1/2 = a(p, t)zk + b(p, t)u

( 1
p ) =

t
i=0 zk+i+1/2 is

P

O

O

O

−

O
τ [Fξk+t (zk+t+1/2)

P

zk+t+1 = zk+t+1/2 −
= (1

p)t+1zk + s(p, t)u

Fξk+t(wk)]

−
τ H(p, t, ξ)

−

−

τ [Fξk+t (zk+t+1/2)

Fξk+t(wk)] ,

−

−

where s(p, t) is a function of parameter p and time t. H(p, t, ξ) is also a linear combination of
(m + n).
coordinate stochastic oracles during this period. The cost to compute zk+t+1 is also
And to prepare for following iterations, we need to update u = pw
τ F (w) as well. The cost of
computing u = p(wk+t+1)

(nnz(A)) which is the dominating cost.

τ F (wk+t+1) is

O

−

−

O

Therefore the total cost when updating the snapshot wk+t+1 is
period between two consecutive updates of w is

(1).

O

(nnz(A)) and the cost during the

O

A.4 Comparison with SPDHG

[1, Theorem 4.6] shows the linear convergence of SPDHG for problems with global metric sub-
regularity, such as the unconstrained bilinear problem. However, the obtained linear convergence
rate may involve parameters that are not easy to interpret. We here apply their results to uncon-
strained bilinear problems with more transparent parameters so that we make a comparison with
our Theorem 2.

Using the notation in [1], they obtained

C1
2 k

xk

E

(cid:20)

2
xk
τ −1 +
∗k

−

1
2 k

yk+1

yk+1
∗

2
D(σ)−1P −1
k

−

ρ)k2Φ0 ,

(1

−

≤

(cid:21)

C1p
2ζ , p = mini pi, C1 = 1

where ρ =
sampling scheme with pi = 1

γ, ζ = 2+ 2
2. For simplicity, we consider the uniform
N
k
n , and thus p = mini pi = 1
n (the other schemes follow with a similar

α2 k

H

−

−

32

arguments). The total number of iterations for SPDHG to achieve ǫ-accuracy is of order

1
ρ

log

=

1
ǫ

(cid:19)

O

(cid:18)

ζ
p

log

1
ǫ

(cid:19)

O

(cid:18)

=

O

(nζ log

1
ǫ

) =

O

H

(n k

2
k

N

−
α2

log

1
ǫ

) .

where the deﬁnitions of H and N are deﬁned in [1, Lemma 4.4]. The operators H and N are
indeed a bit complicated so that the upper bound is hard to derive. Now we lower bound the term
H
k

2.
k

N

−

−

≥

N

2
2
k

2
k

H
k

τ −
k

(H
k

N )q
2
2
k

2
2
1x(1)
2 +
Ax(1)
2
k
k
k
2
x(1)
2
k
k
where the ﬁrst inequality is due to the deﬁnition of operator norm, the second inequality follows
from the choice of q = (x(1), 0, ..., 0) and the last equality is from the choice of x(1) such that
x(1) = argmaxu k
k

2
Ax(1)
2
k
k
2
x(1)
2
k
k

2 ,
A
k
k

2
2
k
2
2
k

−
q
k

Au
u

≥

≥

=

.

Thus we have the complexity of SPDHG is at least

1
ρ

log

1
ǫ

(cid:19)

O

(cid:18)

(n k

=

O

H

N

−
α2

2

k

log

1
ǫ

)

(n k

2

A
k
α2

log

1
ǫ

)

( k

2
F

A
k
α2

log

1
ǫ

) =

O

≥ O

≥ O

(κ2

F log

1
ǫ

) .

3

(κF

In contrast, the complexity of RsEGM is ˜
). This showcase RsEGM has an improved
O
linear convergence rate for solving unconstrained bilinear problems compared to SPDHG in terms
(cid:0)
of the condition number (after ignoring the log terms). Such an improvement comes from the
restarted scheme, similar to the deterministic case [6]. Lastly, we would like to mention that
SPDHG is a semi-stochastic algorithm, where the primal is a full gradient update and the dual is a
stochastic gradient update, while RsEGM takes stochastic gradient steps in both primal and dual
space (except the snapshot steps).

log 1
ǫ

(cid:1)

33

