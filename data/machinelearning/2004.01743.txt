TensorFI: A Flexible Fault Injection Framework for
TensorFlow Applications

Zitao Chen∗1, Niranjhana Narayanan∗1, Bo Fang1, Guanpeng Li2, Karthik Pattabiraman1, and Nathan DeBardeleben3

1University of British Columbia
2University of Illinois
3Los Alamos National Laboratory

0
2
0
2

r
p
A
3

]

C
D
.
s
c
[

1
v
3
4
7
1
0
.
4
0
0
2
:
v
i
X
r
a

Abstract—As machine learning (ML) has seen increasing
adoption in safety-critical domains (e.g., autonomous vehicles),
the reliability of ML systems has also grown in importance.
While prior studies have proposed techniques to enable efﬁcient
error-resilience techniques (e.g., selective instruction duplication),
a fundamental requirement for realizing these techniques is a
detailed understanding of the application’s resilience. In this
work, we present TensorFI, a high-level fault injection (FI) frame-
work for TensorFlow-based applications. TensorFI is able to
inject both hardware and software faults in general TensorFlow
programs. TensorFI is a conﬁgurable FI tool that is ﬂexible,
easy to use, and portable. It can be integrated into existing
TensorFlow programs to assess their resilience for different fault
types (e.g., faults in particular operators). We use TensorFI to
evaluate the resilience of 12 ML programs, including DNNs used
in the autonomous vehicle domain. Our tool is publicly available
https://github.com/DependableSystemsLab/TensorFI .
at

I. INTRODUCTION

In the past decade, Machine Learning (ML) has become
ubiquitous in many applications. ML is also being increasingly
deployed in safety-critical applications such as Autonomous
Vehicles (AVs) [2] and aircraft control [3]. In these domains,
it is critical to ensure the reliability of the ML algorithm and its
implementation as faults can lead to loss of life and property.
Moreover, there are often safety standards in these domains
that prescribe the allowable failure rate. For example, in the
AV domain, the ISO 26262 standard mandates that the FIT
rate (Failures in Time) of the system be no more than 10,
i.e., at most 10 failures in a billion hours of operation [4],
in order to achieve ASIL-D levels of certiﬁcation. Therefore,
there is a compelling need to build efﬁcient tools to (1) test
and improve the reliability of ML systems, and (2) evaluate
their failure rates in the presence of different fault types.

The traditional way to experimentally assess the reliability
of a system is fault injection (FI). FI can be implemented
at the hardware or software level. Software-Implemented FI
(also known as SWiFI) has lower costs, is more controllable,
and easier for developers to deploy [5]. Therefore, SWiFI has
become the dominant method to assess a system’s resilience
to both hardware and software faults.

*Equal contributions
A preliminary version of this work was published in a workshop [1].

There has been a plethora of SWiFI tools such as NF-
Tape [6], Xception [7], GOOFI [8], LFI [9], LLFI [10],
PINFI [11]. These tools operate at different
levels of the
system stack, from the assembly code level to the application’s
source code level. In general, the higher the level of abstraction
of the FI tool, the easier it is for developers to work with, and
use the results from the FI experiments [5].

Due to the increase in popularity of ML applications, there
have been many frameworks developed for writing them.
One of the most popular frameworks is TensorFlow [12],
which was released by Google in 2017. Other examples are
PyTorch [13] and Keras [14]. Unlike traditional applications,
these frameworks allow the developer to “compose” their
application as a sequence of operations, which are connected
together in the form of a graph. The connections represent
the data-ﬂow and control dependencies among the operations.
While the underlying implementation of these frameworks is in
C++ or assembly code for performance reasons, the developer
writes their code using high-level languages (e.g., Python).

In this paper, we introduce a SWiFI tool called TensorFI
which injects faults into the data-ﬂow graph used in Tensor-
Flow applications. TensorFI performs interface-level FI [15],
is the most popular
[16]. We focus on TensorFlow as it
framework used today for ML applications [17], though our
technique is not restricted to TensorFlow. TensorFI can be used
to inject both hardware and software faults in the outputs of
TensorFlow operators, and study the effects of the faults on
the ML application. The main advantage of TensorFI over
traditional SWiFI frameworks is that it directly operates on
the TensorFlow operators and graph, and hence its results are
readily accessible to developers.

Building a FI tool for TensorFlow applications is challeng-
ing due to three reasons. First, because TensorFlow operators
are implemented in C++ or assembly code and optimized for
different platforms (i.e., different processors and operating
systems), it is not practical to modify the implementation
of these operators as doing so will hurt both portability and
performance. However, in order to inject faults at the level of
TensorFlow operators and the graph, one needs to intercept
the operators at runtime to modify their execution results.
Unfortunately, TensorFlow does not expose the operators once
the graph has been constructed, and most of the execution

 
 
 
 
 
 
occurs “behind the scenes” in the low-level code. Therefore,
it is not possible to intercept these operators. Secondly, the
speed of execution of the TensorFlow graph should not be
adversely affected when no faults are injected, as otherwise
developers will avoid using the framework. Finally, there are
many external libraries that are used by TensorFlow develop-
ers. These often rely on the structure and semantics of the
TensorFlow graph, and hence these should not be modiﬁed.

TensorFI addresses the above challenges by ﬁrst duplicating
the TensorFlow graph and creating a FI graph that parallels
the original one. The operators in the FI graph mirror the func-
tionality of the original TensorFlow operators, except that they
have the capability to inject faults based on the conﬁguration
parameters speciﬁed. These operators are implemented by us
in Python, thereby ensuring their portability. Moreover, the FI
graph is only invoked during fault injection, and hence the
performance of the original TensorFlow graph is not affected
(when faults are not injected). Finally, because we do not
modify the TensorFlow graph other than to add the FI graph,
external libraries that depend on the graph’s structure and
semantics can continue to work.

We make the following contributions in this paper.

• Propose a generic FI technique to inject faults at the level
of the TensorFlow graph, without hurting portability and
performance,

• Implement the FI technique in TensorFI, a ﬂexible tool,

which allows easy conﬁguration of FI parameters.

• Evaluate TensorFI on 12 ML applications in TensorFlow,
including deep neural network (DNN) applications used
in AVs, across a wide range of FI conﬁgurations (e.g.,
fault types, error rates). We ﬁnd that there are signiﬁcant
differences due to both individual ML applications, as well
as due to different conﬁgurations. We also evaluate the
performance of TensorFI.

II. BACKGROUND AND FAULT MODEL

We start by explaining the general structure of ML applica-
tions, followed by related work in the area of ML reliability.
We then introduce the fault model we assume in this paper.

A. Machine Learning Applications

An ML model takes an input that contains speciﬁc features
to make a prediction. Prediction tasks can be divided into
classiﬁcation and regression. The former is used to classify the
input into categorical outputs (e.g., image classiﬁcation). The
latter is used to predict dependent variable values based on the
input. ML models can be either supervised or unsupervised. In
the supervised setting, the training samples are assigned with
known labels (e.g., linear regression, neural network), while
in an unsupervised setting there are no known labels for the
training data (e.g., k-means, kernel density estimation).

An ML model typically goes through two phases: 1) training
phase where the model is trained to learn a particular task;
2) inference phase where the model
is used for making
predictions on test data. The parameters of the ML model are
learned from the training data, and the trained model will be

evaluated on the test data, which represents the unseen data
and will not be used in the training phase.

B. Related Work

Several studies have attempted to evaluate the error re-
silience of ML applications through fault
injections [18],
[19]. However, such FI techniques are limited to the speciﬁc
application being studied, unlike TensorFI that
is able to
perform FI on generic ML applications.

More recent studies investigate the resilience of deep neural
networks (DNN) by building fault injectors [20]–[23]. Li et al.
build a fault injector by using the tiny-CNN framework [20].
Reagen et al design a generic framework for quantifying the
error resilience of ML applications [21]. Sabbagh et. al develop
a framework to study the fault resilience of compressed
DNNs [23]. However, their study focuses only on DNNs and
hardware faults, and hence is not applicable to other ML
algorithms. Chen et al. introduce a technique to efﬁciently
prune the hardware FI space by analyzing the underlying
property of ML models [22]. In contrast to the above studies,
TensorFI targets a broad range of ML applications, and can
be used to inject both software and hardware faults.

C. TensorFlow

TensorFlow is an open-source framework for modeling large
data-ﬂow graphs and widely used for building ML programs.
TensorFlow allows programmers to represent the program in
the form of a TensorFlow graph (see below). TensorFlow is
ﬂexible and can be better optimized as it exposes the underly-
ing graph to the developer. Thus, TensorFlow is considered a
low level framework. Many high level frameworks like Keras
use TensorFlow as their backend for implementation.

To use TensorFlow, programmers use the built-in operators
to construct the data-ﬂow graph of the ML algorithm during
the training phase. Once the graph is built, it is not allowed to
be modiﬁed. During the inference phase, data is fed into the
graph through the use of placeholder operators, and the outputs
of the graph correspond to the outputs of the ML algorithm.
In this phase, the graph is typically executed directly in the
optimized form on the target platform using custom libraries.
TensorFlow also provides a convenient Python language in-
terface for programmers to construct and manipulate the data-
ﬂow graphs. Though other languages are also supported, the
dominant use of TensorFlow is through its Python interface.
Note however that the majority of the ML operators and algo-
rithms are implemented as C/C++ code, and have optimized
versions for different platforms. The Python interface simply
provides a wrapper around these C/C++ implementations.

D. Fault Model

In this work, we consider two types of faults, hardware
faults and software faults that occur during the execution of
the TensorFlow program. As TensorFI operates at the level of
TensorFlow operators, we abstract the faults to the operators’
interfaces. Thus, we assume that a hardware or software
fault that arises within the TensorFlow operators, ends up

corrupting (only) the outputs of the operators. We do not
make assumptions on the nature of the output’s corruption.
For example, we consider that the output corruption could
be manifested as a random value replacement (e.g., mutation
testing [24]) or a single bit-ﬂip [20]–[23]. We also assume that
the faults do not modify the structure of the TensorFlow graph,
and that the inputs provided into the program are correct,
because such faults are extraneous to TensorFlow and are
outside our scope. Finally, we assume that the faults occur
neither in the ML algorithms, nor in the parameters of the ML
model. This assumption is needed for us to compare the output
of the FI runs with the golden runs, in order to determine if
a Silent Data Corruption (SDC) has occurred.

We only consider faults during the inference phase of the
ML program. Because training is usually a one-time process
and the results of the trained model can be checked. Inference,
however, is executed repeatedly with different inputs, and is
hence likely to experience faults. This fault model is in line
with other work in this area [20]–[23].

III. METHODOLOGY

We start this section by articulating the design constraints of
TensorFI. We then present the design of TensorFI, and an ex-
ample of its operation. Finally, we present its implementation
and explain how to conﬁgure it.

A. Design Constraints

We follow 3 constraints in the design of TensorFI.

• Ease of Use and Compatibility: The injector should be
easy-to-use and require minimal modiﬁcations to the ap-
plication code. We also need to ensure compatibility with
third-party libraries that may construct the TensorFlow graph
using custom APIs.

• Portability: Because TensorFlow may be pre-installed on
the system, and each individual system may have its own
installation of TensorFlow, we should not assume the pro-
grammer is able to make any modiﬁcations to TensorFlow
or its libraries.

• Minimal Interference: First, the injection process should
not interfere with the normal execution of the TensorFlow
graph when no faults are injected. Further, it should not
make the main graph incapable of being executed on GPUs
or parallelized due to the modiﬁcations it makes. Finally,
the fault injection process should be reasonably fast, when
faults are injected.
We also make two assumptions in TensorFI. First, we
assume that faults occur only during the execution of the
in
TensorFlow operators, and that
nature. In other words, if we reexecute the same operator, the
fault will not reappear. This is because studies have shown that
the kinds of faults that are prevalent in mature software are
often transient faults [25]. Second, we assume that the effect of
a fault propagates to the outputs of the TensorFlow operators
only, and not to any other state. In other words, there is no
error propagation to the permanent state, which is not visible

the faults are transient

at TensorFlow graph level. Again, this is due to the structure
of TensorFlow graphs, and our fault model (Section II).

B. Design of TensorFI

To satisfy the design constraints outlined earlier, TensorFI
operates directly on TensorFlow graphs. The main idea is to
create a replica of the original TensorFlow graph but with
new operators. The new operators are capable of injecting
faults during the execution of the operators and can be
controlled by an external conﬁguration ﬁle. Further, when no
faults are being injected, the operators emulate the behavior
of the original TensorFlow operators they replace. Because
TensorFlow does not allow the dataﬂow graph to be modiﬁed
once it is constructed, we need to create a copy of the entire
graph, and not just the operators we aim to inject faults into.
The new graph mirrors the original one, and takes the same
inputs as it. However, it does not directly modify any of the
nodes or edges of the original graph and hence does not affect
its operation. At runtime, a decision is made as to whether to
invoke the original TensorFlow graph or the duplicated one
for each invocation of the ML algorithm. Once the graph is
chosen, it is executed to completion at runtime.

TensorFI works in two phases. The ﬁrst phase instruments
the graph, and creates a duplicate of each node for fault
injection purposes. The second phase executes the graph to
inject faults at runtime, and returns the corresponding output.
Note that the ﬁrst phase is performed only once for the entire
graph, while the second phase is performed each time the
graph is executed (and faults are injected). We explain below
how this satisﬁes the design constraints.

• Ease of Use and Compatibility: To use TensorFI, the
programmer changec a single line in the Python code.
Everything else is automatic, namely the graph copying and
duplication. Because we duplicate the TensorFlow graph,
our method is compatible with external libraries.

• Portability: We do not make any modiﬁcations to the
TensorFlow code or the internal C++ implementation of the
TensorFlow operators, which are platform speciﬁc. There-
fore our implementation is portable. We do however require
the interfaces of the TensorFlow operators are consistent
across TensorFlow versions.

• Minimal Interference: TensorFI does not interfere with
the operation of the main TensorFlow graph. Further, the
original TensorFlow operators are not modiﬁed in any way,
and hence they can be optimized or parallelized for speciﬁc
platforms. The only overhead introduced by TensorFI is the
check at runtime on whether to call the original graph or
the duplicated graph, but this incurs minimal overhead.

C. Example of TensorFI’s Operation

We consider an example of TensorFI’s operation on a small
TensorFlow program. Because our goal is to illustrate the op-
eration of TensorFI, we consider a simple computation rather
than an ML algorithm. The example is shown in Figure 1.
The nodes in blue represent the original TensorFlow graph,

Fig. 1: Example of TensorFlow graph and how TensorFI modiﬁes it. The
nodes in blue represent the original nodes in the graph, while the nodes in
red are those added by TensorFI for fault injection purposes.

Fig. 2: Example conﬁguration ﬁle in YAML format

TABLE I: List of fault types supported by TensorFI

while those in red represent the duplicated nodes created by
TensorFI.

In the original TensorFlow graph, there are two operators,
an ADD operator which adds two constant node “a” and “b”,
and a MUL operator, which multiplies the resulting value
with that from a place-holder node. A place-holder node is
used to feed data from an external source such as a ﬁle into
a TensorFlow graph, and as such represents an input to the
system. A constant node represents a constant value. TensorFI
duplicates both the ADD and MUL operators in parallel to the
main TensorFlow graph, and feeds them with the values of the
constant nodes as well as the place-holder node. Note however
that there is no ﬂow of values back from the duplicated graph
to the original graph, and hence the fault injection nodes do
not interfere with the original computation performed by the
graph. The outputs orig and faulty represent the original and
fault-injected values respectively. The graph is created before
the fault injection process is launched after the training phase.
At runtime, a dynamic decision is made as to whether we
want to compute the orig output or the faulty output. If the
orig output is demanded, then the graph nodes corresponding
to the original TensorFlow graph are executed. Otherwise, the
nodes inserted by TensorFI are executed and these emulate the
behavior of the original nodes, except that they inject faults.
For example, assume that we want to inject a fault into the
ADD operator. Every other node inserted by TensorFI would
behave exactly like the original nodes in the TensorFlow graph,
with the exception of the ADD operator which would inject
faults as per the conﬁguration (Section III-E).

D. Implementation

TensorFI supports the following features:

• Comparing each FI result with the golden run
• Launching multiple FI runs in parallel (multi-threading)
• Support for visualizing the modiﬁed TensorFlow graphs
• Ability to specify fault type etc. in a conﬁguration ﬁle
• Automated logging of fault injection runs
• Support for statistics collection and analysis

Our

implementation

consists

heavily

of
into

commented
5 modules. We
under

lines
split
publicly
( https://github.com/DependableSystemsLab/TensorFI ),
along with extensive documentation.

a MIT license

available

code,

about

of
Python
have made

2500
and
is
TensorFI
on Github

Type
None
Zero
Rand

Rand-element

bitFlip-element

bitFlip-tensor

Explanation
Do not inject a fault
Change output of the target operator into all zeros
Shufﬂe all data items in the output of the target
operator into random values
Shufﬂe one data item in the output of the target
operator into a random value
Single bit-ﬂip in one data item in the output of the
target operator
Single bit-ﬂip in all data items in the output of the
target operator

E. Conﬁgurations

TensorFI allows the user to conﬁgure it through a YAML in-
terface. Figure 2 shows a sample ﬁle for conﬁguring TensorFI
in YAML format. This is loaded at program initialization, and
is ﬁxed for the entire fault injection campaign. The conﬁg ﬁle
consists of the following ﬁelds:
• Seed: The random seed used in the fault injection experi-

ments, for reproducibility purposes (this is optional).

• ScalarFaultType: The fault type to inject for scalar values
(full list of types in Table I). We set this to bitﬂip-Element.
• TensorFaultType: The fault type to inject for tensor values
(full list of types in Table I). We set this to bitﬂip-Element.
• InjectMode: The mode of injection (list of modes in Ta-

ble II). We set this to errorRate.

• Ops: This is a list of the TensorFlow operators that need to
be injected, and the probability for injecting a fault into each
operator when the mode is errorRate. Probability values can
range from 0 (never inject) to 1 (always inject). We choose
ALL, which represents all operators.

• SkipCount: This is an optional parameter for skipping the
ﬁrst ‘n’ invocations of an operator before injection, where
‘n’ can be any integer value, greater than 0.

IV. EVALUATION

Our goal is to study how resilient are different ML ap-
plications (and datasets) to different fault conﬁgurations of
TensorFI, thereby demonstrating its utility. We ﬁrst describe

TABLE II: List of injection modes supported by TensorFI

Mode
errorRate
dynamicInstance

oneFaultPerRun

Meaning
Specify the error rate for different operator instances
Perform random injection on a randomly chosen
instance of each operation
Choose a single instance among all the operators at
random so that only one fault is injected in the entire
execution

our experimental setup, followed by the research questions we
ask in this study. We then present our results.

A. Experimental Setup

ML applications: We choose a total of 12 ML applications,
12 of which are supervised learning applications (e.g., and
deep neural networks like ResNet, VGGNet) that are com-
monly used in existing studies. In addition, we also choose an
ML application used in the AV domain, i.e., comma.ai driving
model. Table III lists the applications.

In addition to supervised models, TensorFI can be used
to inject faults into unsupervised models that use clustering,
decision trees etc. We use one such application Generative Ad-
versarial Networks (GAN) to show the effects of the injected
faults visually. Because GANs do not have an expected output
label, we do not consider it as part of the other experiments.
ML datasets: We use 4 public ML datasets that are
commonly used in ML studies. MNIST dataset is a hand-
written digits dataset (with 10 different digits). GTSRB dataset
is a dataset consisting of 43 different types of trafﬁc signs.
ImageNet is a large image dataset with more than 14 million
images in 1000 classes. In addition, we use a real-world
driving dataset that is labeled with steering angles [26].

For models that use the ImageNet dataset (ResNet-18 and
SqueezeNet), we use the pre-trained model from since it is
time-consuming to train the model from scratch. For the other
models, we train them using the corresponding datasets. The
datasets are summarized in Table III. The baseline accuracy of
each model (without faults) is also provided for comparison.
Metrics: We consider SDC rate as the metric for evaluating
the resilience of ML applications. An SDC is a wrong output
that deviates from the expected output of the program. SDC
rate is the fraction of the injected faults that result in SDCs.
For classiﬁer applications, an SDC is any misclassiﬁcation.
However, the steering model comma.ai produces a continuous
value as output. For this model, we use different threshold
values for the deviations of steering angles to identify SDCs:
15, 30, 60 and 120 degrees [22]. For the steering model, we
use RMSE (root mean square error) and average deviation per
frame as metrics to evaluate the model’s accuracy - these are
commonly used in ML studies int he AV domain [27].

Experiments: For each benchmark, we perform 1000 ran-
dom FI experiments per fault conﬁguration and input. We
choose 10 inputs for each application, and hence perform a
total of 10, 000 fault injections per conﬁguration and we use
14 different fault conﬁgurations. We also calculate the error
bars at the 95% conﬁdence interval for each experiment.

Fig. 3 shows examples of some of the SDCs observed in
our experiments for both the steering model and classiﬁcation
applications. These may result in safety violations in AVs if
they are not mitigated. With that said, we do not speciﬁcally
distinguish safety-critical outcomes in SDCs.

B. Research Questions

We use different conﬁgurations of TensorFI (shown in
Table I and Table II) for answering the following Research
Questions (RQs):

Fig. 3: Example of SDCs observed in different ML applications. Left box -
Steering Model. Right box - Image Misclassiﬁcations.

TABLE III: ML applications and datasets used for evaluation.
The baseline accuracy without faults is also provided.

ML model
Neural Net
Fully Connected Net
LeNet
AlexNet
CNN
Highway CNN
Recurrent NN
VGG11
ResNet-18

Dataset
MNIST
MNIST
MNIST
MNIST
MNIST
MNIST
MNIST
GTSRB
ImageNet

Dataset Description
Hand-written digits
Hand-written digits
Hand-written digits
Hand-written digits
Hand-written digits
Hand-written digits
Hand-written digits
Real-world trafﬁc sign
General images

SqueezeNet

ImageNet

General images

Comma.ai model [28]

Driving

Real-world
driving frame

Accuracy
85.42%
97.54%
99%
94%
95.74%
97.92%
98.40%
99.74%
62.66% (top-1)
84.61% (top-5)
52.936% (top-1)
74.150% (top-5)
24.12 (RMSE)
12.64 (Avg. Dev.)

RQ1: What are the SDC rates of different applications
under the oneFaultPerRun and dynamicInstance error modes?
RQ2: For the errorRate mode, how do the SDC rates vary

for different error rates?

RQ3: How do the SDC rates vary for faults in different

TensorFlow operations in the same ML application?

RQ4: What is the performance overhead of TensorFI?

C. Results

We organize the results for the 11 ML models listed in
Table III by each RQ, and then show the results of the FI
experiments for GANs. For RQ1 and RQ2, we choose all the
operations in the data-ﬂow graph during the inference phase,
which is a subset of operations in the TensorFlow graph. This
is because many of the operations in the TensorFlow graph are
for training, and are not executed during the inference phase
(thus we do not inject faults into these operations). We also
do not inject faults into those operations that are related to
the input (e.g., reading the input, data preprocessing), as we
assume that the inputs are correct as per our fault model.

1) RQ1: Error resilience for different error modes: In this
RQ, we study the effects of two different error modes, namely
oneFaultPerRun and dynamicInstance. We choose single bit
ﬂip faults as the fault type for this experiment. Fig. 4 show
the SDC rates obtained across applications. We can see that
different ML applications exhibit different SDC rates, and
there is considerable variation.

We can also observe that there are differences between the
two fault modes. For the dynamic instance injection mode,
the SDC rates for all the applications are higher than those in
the one fault per run mode. This is because in the dynamic
instance mode, each type of operation will be injected at least

InputOutput (by fault)Correct angleAngle (by fault)Fig. 4: SDC rates of different ML applications under bit-ﬂip faults (from
oneFaultPerRun and dynamicInstance injection modes). Error bars range from
±0.19% to ±2.45% at the 95% conﬁdence interval

once, while in the one fault per run mode, only one operator is
injected in the entire application. Thus the applications present
higher SDC rates for the former.

We also observe signiﬁcant differences between applications
within the one fault per run mode. For example, the comma.ai
driving model has a higher SDC rate than the classiﬁer appli-
cations. This is because the output of the classiﬁer applications
are not dependent on the absolute values (instead classiﬁcation
probability is used). Thus, the applications are still able to
generate correct output despite the fault occurrence, and hence
have higher resilience. However, the comma.ai model predicts
the steering angle, which is more sensitive to value deviations.
For example, a deviation of 30 due to fault in the classiﬁcation
model will not cause an SDC as long as the predicted label
is correct; whereas the deviation would constitute an SDC in
the comma.ai model if we use the threshold=15 or 30.

In the one fault per run mode, we ﬁnd that RNN exhibits
the highest resilience (less than 1% SDC rate). This is because
unlike feed-forward neural networks, RNN calculates the
output not only using the input from the previous layer, but
also the internal states from other cells. Under the single fault
mode, the other internal states remain intact when the fault
occurs at the output of the previous layer. Therefore, faults that
occur in the feed-forward NNs are more likely to cause SDCs
in this mode. However, under the dynamic instance injection
mode, more than one fault will be injected. As a result, some
of the internal states are also corrupted, thus making the results
prone to SDCs (e.g., RNN has around 38% SDC rate).

We also ﬁnd that AlexNet exhibits high resilience in the
one-fault-per-run and dynamic instance injection modes. This
is because AlexNet has many operations such as ADD, MUL,
which are more resilient to faults (see Fig. 7). Therefore, the
proportion of operations that are more prone to SDCs (e.g.,
convolution operations, activation function) is not as high as
that in other models such as VGG11.

2) RQ2: Error resilience under different error rates:
In
this RQ, we explore the resilience of different models for
the errorRate injection mode. This mode allows us to vary
the probability of error injection on a per-operator basis. We
choose 2 different fault types for studying the effects of the
error rate, namely bitFlip-element and Rand-element.

Fig. 5 and Fig. 6 show the variation SDC rates with error
rates under both fault types. As expected, we can observe
that
larger error rates results in higher SDC rates in all
the applications, as more operations are injected. However,

Fig. 5: SDC rates of different ML applications for various error rates (under
bit ﬂip element FI).

Fig. 6: SDC rates of different ML applications for various error rates (under
random value replacement FI).

compared with the results from the bit-ﬂip FI, random value
replacement results in lower SDC rates. This is likely because
the random value causes lesser value deviation than the bit-ﬂip
fault type (in our implementation, we use the random number
generator function from numpy library). Thus, a lower value
deviation in this mode leads to lower SDC rates [20], [22].

Fig. 5 shows the variations of SDC rates of different ML ap-
plications with error rate under the bit-ﬂip fault type. While we
note that the SDC rates of all the applications grow along with
the increase of error rates, we observe different applications
have different rates of growth of SDCs. In particular, we ﬁnd
that there are four outliers in the results for the bit-ﬂip fault
model (Fig. 5), RNN, HCNN, ResNet and FCN, which exhibit
signiﬁcantly higher SDC rates than their counterparts. We ﬁnd
that the main reason is that these models have a signiﬁcantly
higher number of operations, thereby increasing the number
of injected operators and resulting in higher SDC rates.

Likewise, in the case of the random replacement we ﬁnd that
the SqueezeNet applications exhibit nearly ﬂat growth in SDC
rates with error rates, and that the SDC rates are consistently
low. This is because faults need to cause large deviation in
order to cause SDCs, which rarely occurs with the random
replacement fault type.

3) RQ3: SDC rates across different operations: In this RQ,
we study the SDC rates on different operations in the CNN
model. The SDC rates are shown in Fig. 7. It can be seen that
faults in the convolution layer usually have higher SDC rates,
compared with other operations (e.g., Sub).

Moreover, we can see that operations such as SoftMax,
ArgMax, Equal exhibit the highest SDC rates. In fact, the
SDC rates on the ArgMax and Equal operations are nearly
100%. This is because these operations are directly associated
with the output, and thus faults in these operations are more

00.10.20.30.40.50.60.70.80.91RNNComma(15)Comma(30)Comma(60)Comma(120)Vgg11SqNet(top5)SqNet(top1)ResNet(top5)ResNet(top1)NNCNNLeNetAlexNetFCNHCNNSDC rateOne fault per runDynamic instanceTABLE IV: Overheads for the program (baseline); with in-
strumentation, without FI (disable FI); with FI (enable FI)

ML model

Baseline Disable

NN
FCN
LeNet
AlexNet
CNN
HCNN
RNN
VGG11
SqueezeNet
ResNet
Comma.ai
Average

(in s)
0.06
0.13
0.105
0.51
0.23
0.44
0.097
0.19
0.85
2.72
0.3
0.59

FI
(in s)
0.16
1.03
0.22
0.58
0.23
1.02
2.39
0.82
1
3.76
0.47
1.06

Enable
FI
(in s)
13.50
86.53
17.44
45.24
25.94
134.56
145
29.1
22
300
46
78.66

Overheads

Inst.
1.6x
6.9x
1.1x
0.1x
0.1x
1.3x
1.5x
3.3x
0.2x
0.4x
0.6x
1.5x

FI
83.34x
83x
78.27x
77x
107x
131x
59.66x
34.5x
21x
78.78x
96.87x
77.3x

Fig. 8: Generated images of the digit 8 in the MNIST data-set under different
conﬁgurations for GANs. Top row represents the Rand-element model, while
bottom row represents the single bit-ﬂip model. Left center is with no faults.

5) GAN FI results: As mentioned, we show the GAN
results separately as generated images do not have a labelled
reference output, and we choose to not measure their SDC
rates with another level of indirection from the discriminator.

The set of images in the top row, (ii) to (vi), are generated
from setting the fault type to Rand-element. (ii) and (iii) are
for one fault per run, and dynamic instance respectively. (iv) to
(vi) are generated from the errorRate mode. (iv) is from setting
the error rate to 25%. We can see the fault progression clearly
as the image becomes more difﬁcult to decipher as the error
rate increases. The second row shows images obtained from
similar conﬁgurations as the ﬁrst row, with the only difference
being that the fault type chosen is single bit ﬂip. We observe
that with bit ﬂip in the operators, the resulting faults in images
(vii) to (xi) tend to be more bipolar (i.e., have more black and
white pixels than shades of grey). This is likely because with
bit ﬂips, the tensor values that store the image data are toggled
between being present (1) at a pixel or being absent (0). As
this error propagates into more operators, the computations
performed amplify this effect and the resultant end images
have strong activated regions of black or white. In the random
replacement mode, the injected operations are replaced with
random values and consequently the generated pixels to also
exhibit any values within the range.

Fig. 7: SDC rates of different operations under bit-ﬂip FI in the CNN model).
Error bars range from ±0.3077% to ±0.9592% at 95% conﬁdence interval.

likely to cause SDCs. On the other hand, operators such as
Sub, MatMul have low SDC rates because faults in these
operations are unlikely to propagate much. For example, faults
at the convolution layer are likely to propagate through the
complex convolution operations, in which faults can quickly
propagate and amplify.However, faults at operations such as
add and multiply might be masked before propagating to
the convolution layer; or occur after the convolution layer.
Therefore, due to the limited fault ampliﬁcation effect, faults
in these operations are less likely to cause SDCs.

4) RQ4: Overhead.:

In this question, we measure the
execution time for the TensorFlow programs as a baseline
for 50 predictions. Then we measure the time taken for 50
predictions after the TensorFI instrumentation phase, but with
fault injections disabled. These measurements are detailed in
the Disable FI column of the Table IV. We then measure the
time taken for 50 predictions with a single bit ﬂip fault injected
per run, and report this time in the Enable FI column. The
ﬁrst subcolumn ‘Inst.’ in Overheads, is the instrumentation
overhead (difference between Disable FI and Baseline over the
Baseline) and the second subcolumn ‘FI’ gives the overhead
incurred by fault injection alone (difference between Enable
and Disable FI over Disable FI).

As can be observed, the instrumentation overheads are rela-
tively small, and range from 0.1x to 6.9x across applications.
The fault injection overheads are much higher, ranging from
21x to 131x. This is because we are emulating the TensorFlow
operators during fault injections in Python, and cannot beneﬁt
from the optimizations and low-level implementation of Ten-
sorFlow. However, the instrumentation phase itself incurs only
modest overheads, with an average of 1.5x, when faults are
not injected, in keeping with our minimal interference goal -
this overhead is due to the runtime check for choosing which
version of the operator to invoke (Section III-D).

While the overheads may seem high, we report the actual
this number in
time taken by the FI experiments to put
time-consuming
perspective. In our experiments,
the most
is on the ResNet and Highway CNN models,
experiment
which took less than 16 hours to complete. However, on
average, most of our experiments took 3-4 hours to complete
for injecting 10, 000 faults, which is reasonable.

[18] C. Alippi, V. Piuri, and M. Sami, “Sensitivity to errors in artiﬁcial neural
networks: A behavioral approach,” IEEE Transactions on Circuits and
Systems, vol. 42, no. 6, 1995.

[19] S. Bettola and V. Piuri, “High performance fault-tolerant digital neural

networks,” IEEE transactions on computers, no. 3, 1998.

[20] G. Li, S. K. S. Hari, M. Sullivan, T. Tsai, K. Pattabiraman, J. Emer, and
S. W. Keckler, “Understanding error propagation in deep learning neural
network (dnn) accelerators and applications,” in Proceedings of the
International Conference for High Performance Computing, Networking,
Storage and Analysis, 2017.

[21] B. Reagen, U. Gupta, L. Pentecost, P. Whatmough, S. K. Lee, N. Mulhol-
land, D. Brooks, and G.-Y. Wei, “Ares: a framework for quantifying the
resilience of deep neural networks,” in 55th Annual Design Automation
Conference, 2018.

[22] Z. Chen et al., “Binﬁ: An efﬁcient fault injector for safety-critical ma-
chine learning systems,” in Proceedings of the International Conference
for High Performance Computing, Networking, Storage and Analysis.
ACM, 2019.

[23] M. Sabbagh, C. Gongye, Y. Fei, and Y. Wang, “Evaluating fault
resiliency of compressed deep neural networks,” in 2019 IEEE Interna-
tional Conference on Embedded Software and Systems (ICESS).
IEEE,
2019, pp. 1–7.

[24] L. Ma, F. Zhang, J. Sun, M. Xue, B. Li, F. Juefei-Xu, C. Xie, L. Li,
Y. Liu, J. Zhao et al., “Deepmutation: Mutation testing of deep learning
systems,” in 2018 IEEE 29th International Symposium on Software
Reliability Engineering (ISSRE).

IEEE, 2018, pp. 100–111.

[25] R. Iyer, D. Tang et al., “Experimental analysis of computer system

dependability,” 1993.

[26] “Driving dataset.” [Online]. Available: https://github.com/SullyChen/

driving-datasets

[27] S. Du, et al., “Self-driving car steering angle prediction based on image
recognition,” Department of Computer Science, Stanford University,
Tech. Rep. CS231-626, 2017.

[28] “comma.ai’s steering model.” [Online]. Available: https://github.com/

commaai/research

V. CONCLUSION

We present TensorFI, a generic fault

injection tool for
ML applications written using the TensorFlow framework.
TensorFI is a conﬁgurable tool that can be easily integrated
into existing ML applications. TensorFI is portable, conﬁg-
urable, and fast. Further, it is also compatible with third party
libraries that use TensorFlow. We use TensorFI to study the
resilience of 12 TensorFlow ML applications under different
fault conﬁgurations, including one used in AVs. Our evalu-
ation demonstrates the utility of TensorFI in evaluating ML
applications’ resilience.

REFERENCES

[1] G. Li et al., “Tensorﬁ: A conﬁgurable fault injector for tensorﬂow
applications,” in IEEE International Symposium on Software Reliability
Engineering Workshops (ISSREW).

IEEE, 2018.

[2] S. S. Banerjee et al., “Hands off the wheel in autonomous vehicles?:
A systems perspective on over a million miles of ﬁeld data,” in 48th
Annual IEEE/IFIP International Conference on Dependable Systems and
Networks (DSN).

IEEE, 2018.

[3] K. D. Julian et al., “Policy compression for aircraft collision avoidance
systems,” in 2016 IEEE/AIAA 35th Digital Avionics Systems Conference
(DASC), 2016.

[4] “Functional safety methodologies for automotive applications.” [Online].
Available: https://www.cadence.com/content/dam/cadence-www/global/
en US/documents/solutions/automotive-functional-safety-wp.pdf

[5] M.-C. Hsueh, T. K. Tsai, and R. K. Iyer, “Fault injection techniques and

tools,” Computer, vol. 30, no. 4, pp. 75–82, 1997.

[6] D. T. Stott, B. Floering, D. Burke, Z. Kalbarczpk, and R. K. Iyer,
“Nftape: a framework for assessing dependability in distributed systems
with lightweight fault injectors,” in Proceedings IEEE International
Computer Performance and Dependability Symposium. IPDS 2000.
IEEE, 2000, pp. 91–100.

[7] J. Carreira, H. Madeira, J. G. Silva et al., “Xception: Software fault
injection and monitoring in processor functional units,” Dependable
Computing and Fault Tolerant Systems, vol. 10, pp. 245–266, 1998.
[8] J. Aidemark, J. Vinter, P. Folkesson, and J. Karlsson, “Gooﬁ: Generic
object-oriented fault injection tool,” in 2001 International Conference
on Dependable Systems and Networks.

IEEE, 2001, pp. 83–88.

[9] P. D. Marinescu and G. Candea, “Lﬁ: A practical and general library-
level fault injector,” in 2009 IEEE/IFIP International Conference on
Dependable Systems & Networks.

IEEE, 2009, pp. 379–388.

[10] A. Thomas and K. Pattabiraman, “Llﬁ: An intermediate code level fault
injector for soft computing applications,” in Workshop on Silicon Errors
in Logic System Effects (SELSE), 2013.

[11] J. Wei, A. Thomas, G. Li, and K. Pattabiraman, “Quantifying the
accuracy of high-level fault injection techniques for hardware faults,” in
2014 44th Annual IEEE/IFIP International Conference on Dependable
Systems and Networks.

IEEE, 2014, pp. 375–382.

[12] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin,
S. Ghemawat, G. Irving, M. Isard et al., “Tensorﬂow: A system for large-
scale machine learning,” in 12th {USENIX} Symposium on Operating
Systems Design and Implementation ({OSDI} 16), 2016, pp. 265–283.
[13] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,
T. Killeen, Z. Lin, N. Gimelshein, L. Antiga et al., “Pytorch: An
imperative style, high-performance deep learning library,” in Advances
in Neural Information Processing Systems, 2019, pp. 8024–8035.

[14] “Keras.” [Online]. Available: https://keras.io/
[15] N. P. Kropp, P. J. Koopman, and D. P. Siewiorek, “Automated robustness
testing of off-the-shelf software components,” in Digest of Papers.
Twenty-Eighth Annual International Symposium on Fault-Tolerant Com-
puting (Cat. No. 98CB36224).

IEEE, 1998, pp. 230–239.

[16] A. Lanzaro, R. Natella, S. Winter, D. Cotroneo, and N. Suri, “An
empirical study of injected versus actual interface errors,” in Proceedings
of the 2014 International Symposium on Software Testing and Analysis.
ACM, 2014, pp. 397–408.

[17] “Tensorﬂow popularity.” [Online]. Available: https://towardsdatascience.
com/deep-learning-framework-power-scores-2018-23607ddf297a

