0
2
0
2

v
o
N
3

]

G
L
.
s
c
[

2
v
5
4
6
1
1
.
0
1
0
2
:
v
i
X
r
a

Enabling certiﬁcation of veriﬁcation-agnostic networks
via memory-efﬁcient semideﬁnite programming

Sumanth Dathathri˚1, Krishnamurthy (Dj) Dvijotham˚1, Alex Kurakin˚2,
Aditi Raghunathan˚3, Jonathan Uesato˚1, Rudy Bunel1, Shreya Shankar3,
Jacob Steinhardt4, Ian Goodfellow5, Percy Liang3, Pushmeet Kohli1
1DeepMind 2Google Brain 3Stanford 4UC Berkeley 5Work done at Google
{dathathri,dvij,kurakin,juesato}@google.com, aditir@stanford.edu

Abstract

Convex relaxations have emerged as a promising approach for verifying desirable
properties of neural networks like robustness to adversarial perturbations. Widely
used Linear Programming (LP) relaxations only work well when networks are
trained to facilitate veriﬁcation. This precludes applications that involve veriﬁcation-
agnostic networks, i.e., networks not specially trained for veriﬁcation. On the other
hand, semideﬁnite programming (SDP) relaxations have successfully be applied to
veriﬁcation-agnostic networks, but do not currently scale beyond small networks due
to poor time and space asymptotics. In this work, we propose a ﬁrst-order dual SDP
algorithm that (1) requires memory only linear in the total number of network activa-
tions, (2) only requires a ﬁxed number of forward/backward passes through the net-
work per iteration. By exploiting iterative eigenvector methods, we express all solver
operations in terms of forward and backward passes through the network, enabling
efﬁcient use of hardware like GPUs/TPUs. For two veriﬁcation-agnostic networks
on MNIST and CIFAR-10, we signiﬁcantly improve (cid:96)8 veriﬁed robust accuracy
from 1% Ñ 88% and 6% Ñ 40% respectively. We also demonstrate tight veriﬁcation
of a quadratic stability speciﬁcation for the decoder of a variational autoencoder.

1

Introduction

Applications of neural networks to safety-critical domains requires ensuring that they behave as
expected under all circumstances [32]. One way to achieve this is to ensure that neural networks
conform with a list of speciﬁcations, i.e., relationships between the inputs and outputs of a neural
network that ought to be satisﬁed. Speciﬁcations can come from safety constraints (a robot should
never enter certain unsafe states [40, 29, 12]), prior knowledge (a learned physical dynamics model
should be consistent with the laws of physics [49]), or stability considerations (certain transformations
of the network inputs should not signiﬁcantly change its outputs [57, 7]).

Evaluating whether a network satisﬁes a given speciﬁcation is a challenging task, due to the difﬁculty
of searching for violations over the high dimensional input spaces. Due to this, several techniques
that claimed to enhance neural network robustness were later shown to break under stronger attacks
[61, 5]. This has motivated the search for veriﬁcation algorithms that can provide provable guarantees
on neural networks satisfying input-output speciﬁcations.

Popular approaches based on linear programming (LP) relaxations of neural networks are compu-
tationally efﬁcient and have enabled successful veriﬁcation for many speciﬁcations [37, 18, 30, 21].
LP relaxations are sound (they would never incorrectly conclude that a speciﬁcation is satisﬁed) but

˚ Equal contribution. Alphabetical order.
: Code available at https://github.com/deepmind/jax_verify.

34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.

 
 
 
 
 
 
incomplete (they may fail to verify a speciﬁcation even if it is actually satisﬁed). Consequently, these
approaches tend to give poor or vacuous results when used in isolation, though can achieve strong
results when combined with speciﬁc training approaches to aid veriﬁcation [22, 51, 67, 21, 54, 6].

In contrast, we focus on veriﬁcation-agnostic models, which are trained in a manner agnostic to
the veriﬁcation algorithm. This would enable applying veriﬁcation to all neural networks, and not
just those trained to be veriﬁable. First, this means training procedures need not be constrained
by the need to verify, thus allowing techniques which produce empirically robust networks, which
may not be easily veriﬁed [38]. Second, ML training algorithms are often not easily modiﬁable, e.g.
production-scale ML models with highly speciﬁc pipelines. Third, for many tasks, deﬁning formal
speciﬁcations is difﬁcult, thus motivating the need to learn speciﬁcations from data. In particular, in
recent work [24, 50, 66], natural perturbations to images like changes in lighting conditions or changes
in the skin tone of a person, have been modeled using perturbations in the latent space of a generative
model. In these cases, the speciﬁcation itself is a veriﬁcation-agnostic network which the veriﬁcation
must handle even if the prediction network is trained with the veriﬁcation in mind.

In contrast to LP-based approaches, the semideﬁnite programming (SDP) relaxation [52] has enabled
robustness certiﬁcation of veriﬁcation-agnostic networks. However, the interior point methods
commonly used for SDP solving are computationally expensive with Opn6q runtime and Opn4q
memory requirements, where n is the number of neurons in the network [41, 60]. This limits
applicability of SDPs to small fully connected neural networks.

Within the SDP literature, a natural approach is to turn to ﬁrst-order methods, exchanging precision for
scalability [63, 53]. Because veriﬁcation only needs a bound on the optimal value of the relaxation (and
not the optimal solution), we need not design a general-purpose SDP solver, and can instead operate
directly in the dual. A key beneﬁt is that the dual problem can be cast as minimizing the maximum
eigenvalue of an afﬁne function, subject only to non-negativity constraints. This is a standard technique
used in the SDP literature [25, 42] and removes the need for an expensive projection operation onto
the positive semideﬁnite cone. Further, since any set of feasible dual variables provides a valid upper
bound, we do not need to solve the SDP to optimality as done previously [52], and can instead stop
once a sufﬁciently tight upper bound is attained.

In this paper, we show that applying these ideas to neural network veriﬁcation results in an efﬁcient
implementation both in theory and practice. Our solver requires Opnq memory rather than Opn4q
for interior point methods, and each iteration involves a constant number of forward and backward
passes through the network.

Our contributions. The key contributions of our paper are as follows:

1. By adapting ideas from the ﬁrst-order SDP literature [25, 42], we observe that the dual of the SDP
formulation for neural network veriﬁcation can be expressed as a maximum eigenvalue problem
with only interval bound constraints. This formulation generalizes [52] without loss of tightness,
and applies to any quadratically-constrained quadratic program (QCQP), including the standard
adversarial robustness speciﬁcation and a variety of network architectures.

Crucially, when applied to neural networks, we show that subgradient computations are expressible
purely in terms of forward or backward passes through layers of the neural network. Consequently,
applying a subgradient algorithm to this formulation achieves per-iteration complexity comparable
to a constant number of forward and backward passes through the neural network.

2. We demonstrate the applicability of ﬁrst-order SDP techniques to neural network veriﬁcation. We
ﬁrst evaluate our solver by verifying (cid:96)8 robustness of a variety of veriﬁcation-agnostic networks on
MNIST and CIFAR-10. We show that our approach can verify large networks beyond the scope of
existing techniques. For these veriﬁcation-agnostic networks, we obtain bounds an order of magni-
tude tighter than previous approaches (Figure 1). For an adversarially trained convolutional neural
network (CNN) with no additional regularization on MNIST ((cid:15) “ 0.1), compared to LP relaxations,
we improve the veriﬁed robust accuracy from 1% to 88%. For the same training and architecture
on CIFAR-10 ((cid:15) “ 2{255), the corresponding improvement is from 6% to 40% (Table 1).

3. To demonstrate the generality of our approach, we verify a different quadratic speciﬁcation on
the stability of the output of the decoder for a variational autoencoder (VAE). The upper bound
on speciﬁcation violation computed by our solver closely matches the lower bound on speciﬁcation
violation (from PGD attacks) across a wide range of inputs (Section 6.2).

2

2 Related work

Neural network veriﬁcation. There is a large literature on veriﬁcation methods for neural networks.
Broadly, the literature can be grouped into complete veriﬁcation using mixed-integer programming
[26, 18, 59, 10, 2], bound propagation [56, 70, 65, 21], convex relaxation [30, 17, 67, 51], and
randomized smoothing [35, 11]. Veriﬁed training approaches when combined with convex relaxations
have led to promising results [30, 51, 23, 6]. Randomized smoothing and veriﬁed training approaches
requires special modiﬁcations to the predictor (smoothing the predictions by adding noise) and/or the
training algorithm (training with additional noise or regularizers) and hence are not applicable to the
veriﬁcation-agnostic setting. Bound propagation approaches have been shown to be special instances
of LP relaxations [37]. Hence we focus on describing the convex relaxations and complete solvers, as
the areas most closely related to this paper.

Complete veriﬁcation approaches. These methods rely on exhaustive search to ﬁnd counter-examples
to the speciﬁcation, using smart propagation or bounding methods to rule out parts of the search
space that are determined to be free of counter-examples. The dominant paradigms in this space are
Satisﬁability Modulo Theory (SMT) [26, 18] and Mixed Integer Programming (MIP) [59, 10, 2]. The
two main issues with these solvers are that: 1) They can take exponential time in the network size and
2) They typically cannot run on accelerators for deep learning (GPUs, TPUs).

Convex relaxation based methods. Much work has relied on linear programming (LP) or similar
relaxations for neural-network veriﬁcation [30, 17]. Bound propagation approaches can also be viewed
as a special case of LP relaxations [37]. Recent work [54] put all these approaches on a uniform footing
and demonstrated using extensive experiments that there are fundamental barriers in the tightness of
these LP based relaxations and that obtaining tight veriﬁcation procedures requires better relaxations. A
similar argument in [52] demonstrated a large gap between LP and SDP relaxations even for networks
with randomly chosen weights. Fazlyab et al. [19, 20] generalized the SDP relaxations to arbitrary
network structures and activiation functions. However, these papers use off-the-shelf interior point
solvers to solve the resulting relaxations, preventing them from scaling to large CNNs. In this paper, we
focus on SDP relaxations but develop customized solvers that can run on accelerators for deep learning
(GPUs/TPUs) enabling their application to large CNNs.

First-order SDP solvers. While interior-point methods are theoretically compelling, the demands of
large-scale SDPs motivate ﬁrst-order solvers. Common themes within this literature include smoothing
of nonsmooth objectives [42, 33, 14] and spectral bundle or proximal methods [25, 36, 45]. Conditional
gradient methods use a sum of rank-one updates, and when combined with sketching techniques,
can represent the primal solution variable using linear space [68, 69]. Many primal-dual algorithms
[64, 63, 41, 4, 15] exploit computational advantages of operating in the dual – in fact, our approach to
veriﬁcation operates exclusively in the dual, thus sidestepping space and computational challenges
associated with the primal matrix variable. Our formulation in Section 5.1 closely follows the eigenvalue
optimization formulation from Section 3 of Helmberg and Rendl [25]. While in this work, we show that
vanilla subgradient methods are sufﬁcient to achieve practical performance for many problems, many
ideas from the ﬁrst-order SDP literature are promising candidates for future work, and could potentially
allow faster or more reliable convergence. A full survey is beyond scope here, but we refer interested
readers to Tu and Wang [60] and the related work of Yurtsever et al. [69] for excellent surveys.

3 Veriﬁcation setup

Notation. For vectors a,b, we use a ď b and a ě b to represent element-wise inequalities. We use
(cid:15)pxq
to denote the (cid:96)8 ball of size (cid:15) around input x. For symmetric matrices X,Y , we use X ľ Y to denote
that X ´Y is positive semideﬁnite (i.e. X ´Y is a symmetric matrix with non-negative eigenvalues)
We use rxs` to denote maxpx,0q and rxs´ for minpx,0q. 1 represents a vector of all ones.

B

Neural networks. We are interested in veriﬁying properties of neural network with L hidden layers
and N neurons that takes input x0. xi denotes the activations at layer i and the concantenated vector
x “ rx0,x1,x2,¨¨¨ ,xLs represents all the activations of the network. Let Li denote an afﬁne map
corresponding to a forward pass through layer i, for e.g., linear, convolutional and average pooling
layers. Let σi is an element-wise activation function, for e.g., ReLU, sigmoid, tanh. In this work, we
focus on feedforward networks where xi`1 “ σi

˘
Lipxiq

`

.

3

Veriﬁcation. We study veriﬁcation problems that involve determining whether φpxq ď 0 for network
inputs x0 satisfying (cid:96)0 ď x0 ď u0 where speciﬁcation φ is a function of the network activations x.

opt “: max

x

φpxq subject to xi`1 “ σi

˘
`
Lipxiq
looooooooomooooooooon

, (cid:96)0 ď x0 ď u0
looooomooooon

.

(1)

Neural net constraints

Input constraints

The property is veriﬁed if opt ď 0. In this work, we focus on φ which are quadratic functions. This
includes several interesting properties like veriﬁcation of adversarial robustness (where φ is linear),
conservation of an energy in dynamical systems [49]), or stability of VAE decoders (Section 6.2). Note
that while we assume (cid:96)8-norm input constraints for ease of presentation, our approach is applicable to
any quadratic input constraint.

4 Lagrangian relaxation of QCQPs for veriﬁcation

A starting point for our approach is the following observation from prior work—the neural network
constraints in the veriﬁcation problem (1) can be replaced with quadratic constraints for ReLUs [52]
and other common activations [19], yielding a Quadratically Constrained Quadratic Program (QCQP).
We bound the solution to the resulting QCQP via a Lagrangian relaxation. Following [52], we assume
access to lower and upper bounds (cid:96)i,ui on activations xi such that (cid:96)i ď xi ď ui. They can be obtained
via existing bound propagation techniques [65, 30, 70]. We use (cid:96) ď x ď u to denote the collection of
activations and bounds at all the layers taken together.

We ﬁrst describe the terms in the Lagrangian corresponding to the constraints encoding layer i in
a ReLU network: xi`1 “ ReLUpLipxiqq. Let (cid:96)i,ui denote the bounds such that (cid:96)i ď xi ď ui. We
associate Lagrange multipliers λi “ rλa
i s corresponding to each of the constraints as follows.

i;λb

`

i ;λc
xi`1 ě 0 rλa
ď 0 rλc

i;λd
is, xi`1 ě Lipxiq rλb
i s
is, xi dxi ´p(cid:96)i `uiqdxi `(cid:96)i dui ď 0 rλd
i s.

˘

xi`1 ´Lipxiq

xi`1 d

(2)
The linear constraints imply that xi`1 is greater than both 0 and Lipxiq. The ﬁrst quadratic constraint
together with the linear constraint makes xi`1 equal to the larger of the two, i.e. xi`1 “ maxpLipxiq,0q.
The second quadratic constraint directly follows from the bounds on the activations. The Lagrangian
pxi,xi`1,λiq corresponding to the constraints and Lagrange multipliers described above is as follows.

pxi,xi`1,λiq “ p´xi`1qJλa

i `pLipxiq´xi`1qJλb
i

`

˘

`

xi`1 dpxi`1 ´Lipxiqq
i `pxi dxi ´p(cid:96)i `uiqdxi `(cid:96)i duiqJλd
i
˘
i`1λa
“ p(cid:96)i duiqJλd
p(cid:96)i `uiqdλd
looooomooooon
loooooooooooooooooooooooooooooooomoooooooooooooooooooooooooooooooon
i
i

Jλc
i `pLipxiqqJλb

i ´xJ
i

i ´xJ

i`1λb

´xJ

`

independent of xi,xi`1
i`1diagpλc
i`1diagpλc
`xJ
.
i qxi
looooooooooooooooooooooooooooooooooomooooooooooooooooooooooooooooooooooon
Quadratic in xi,xi`1

iqLipxiq`xJ

iqxi`1 ´xJ

i diagpλd

linear in xi,xi`1

(3)

L

L

L

px,λq is the sum of

pxi,xi`1,λiq across all layers together with the objective
The overall Lagrangian
L
px,λq is
φpxq, and consists of terms that are either independent of x, linear in x or quadratic in x. Thus,
L
2 xJHpλqx. Each
a quadratic polynomial in x and can be written in the form
of the coefﬁcients cpλq, gpλq, and Hpλq are afﬁne as a function of λ. We will describe our approach in
terms of cpλq, gpλq, and Hpλq, which need not be derived by hand, and can instead be directly obtained
px,λq via automatic differentiation as we discuss in Section 5.2. We observe that
from the Lagrangian
px,λq is itself composed entirely of forward passes Lipxiq and element-wise operations. This makes
px,λq both convenient to implement and efﬁcient to compute in deep learning frameworks.

px,λq “ cpλq`xJgpλq` 1

L
computing

L

L

L

Via standard Lagrangian duality, the Lagrangian provides a bound on opt:
1
2

px,λq “ min
λě0

cpλq`xJgpλq`

opt ď min
λě0

max
(cid:96)ďxďu

max
(cid:96)ďxďu L

xJHpλqx.

(4)

We now describe our dual problem formulation starting from this Lagrangian (4).

5 Scalable and Efﬁcient SDP-relaxation Solver

Our goal is to develop a custom solver for large-scale neural network veriﬁcation with the following
desiderata: (1) compute anytime upper bounds valid after each iteration, (2) rely on elementary

4

computations with efﬁcient implementations that can exploit hardware like GPUs and TPUs, and (3)
have per-iteration memory and computational cost that scales linearly in the number of neurons.

In order to satisfy these desiderata, we employ ﬁrst order methods to solve the Langrange dual
problem (4). We derive a reformulation of the Lagrange dual with only non-negativity constraints
on the decision variables (Section 5.1). We then show how to efﬁciently and conveniently compute
subgradients of the objective function in Section 5.2 and derive our ﬁnal solver in Algorithm 1.

5.1 Reformulation to a problem with only non-negativity constraints

Several algorithms in the ﬁrst-order SDP literature rely on reformulating the semideﬁnite programming
problem as an eigenvalue minimization problem [25, 42]. Applying this idea, we obtain a Lagrange
dual problem which only has non-negativity constraints and whose subgradients can be computed
efﬁciently, enabling efﬁcient projected subgradient methods to be applied.

Recall that (cid:96)i,ui denote precomputed lower and upper bounds on activations xi. For simplicity in
presentation, we assume (cid:96)i “ ´1 and ui “ 1 respectively for all i. This is without loss of generality,
since we can always center and rescale the activations based on precomputed bounds to obtain
normalized activations ¯x P r´1,1s and express the Lagrangian in terms of the normalized activations ¯x.
Proposition 1. The optimal value opt of the veriﬁcation problem (1) is bounded above by the Lagrange
dual problem corresponding to the Lagrangian in (4) which can be written as follows:

cpλq`
loooooooooooooooooooooooooomoooooooooooooooooooooooooon

ı
`
minpdiagpκq´M pλqq1

”
κ´λ´

1J

1
2

, M pλq “

ˆ

˙

0

gpλqJ
gpλq Hpλq

,

(5)

optrelax “: min

λě0,κě0

f pλ,κq

and λ´

minpZq “ minpλminpZq,0q is the negative portion of the smallest eigenvalue of Z and κ P R1`N .

Proof Sketch. Instead of directly optimizing over the primal variables x in the Lagrangian of the
veriﬁcation problem (4), we explicitly add the redundant constraint x2 ď 1 with associated dual variables
κ, and then optimize over x in closed form. This does not change the the primal (or dual) optimum,
but makes the constraints in the dual problem simpler. In the corresponding Lagrange dual problem
(now over λ,κ), there is a PSD constraint of the form diagpκq ľ M pλq. Projecting onto this constraint
directly is expensive and difﬁcult. However, for any pλ,κq ľ 0, we can construct a dual feasible
solution pλ,ˆκq by simply subtracting the smallest eigenvalue of diagpκq´M pλq, if negative. For any
non-negative λ,κ, the ﬁnal objective f pλ,κq is the objective of the corresponding dual feasible solution
and the bound follows from standard Lagrangian duality. The full proof appears in Appendix A.3.

Remark 1. Raghunathan et al. [52] present an SDP relaxation to the QCQP for the veriﬁcation
of (cid:96)8 adversarial robustness. The solution to their SDP is equal to optrelax in our formulation (5)
(Appendix A.4). Raghunathan et al. [52] solve the SDP via interior-point methods using off-the-shelf
solvers which simply cannot scale to larger networks due to memory requirement that is quartic in
the number of activations. In contrast, our algorithm (Algorithm 1) has memory requirements that
scale linearly in the number of activations.
Remark 2. Our proof is similar to the standard maximum eigenvalue transformulation for the SDP
dual, as used in Helmberg and Rendl [25] or Nesterov [42] (see Appendix A.6 for details). Crucially
for scalable implementation, our formulation avoids explicitly computing or storing the matrices for
either the primal or dual SDPs. Instead, we will rely on automatic differentiation of the Lagrangian and
matrix-vector products to represent these matrices implicitly, and achieve linear memory and runtime
requirements. We discuss this approach now.

5.2 Efﬁcient computation of subgradients

Our formulation in (5) is amenable to ﬁrst-order methods. Projections onto the feasible set are simple
and we now show how to efﬁciently compute the subgradient of the objective f pλ,κq. By Danskin’s
theorem [13],

´

Bλ,κ

cpλq`

“

”
κ´

1
2

where v‹ “ argmin
}v}“1

`

˘
diagpκq´M pλq
˘
diagpκq´M pλq

v‹J
`

vJ

‰

v‹

ı
`J
1

¯

1

P Bλ,κf pλ,κq,

v “ eigminpdiagpκq´M pλqq,

(6a)

(6b)

5

and Bλ,κ denotes the subdifﬁrential with respect to λ,κ. In other words, given any eigenvector v‹ corre-
sponding to the minimum eigenvalue of the matrix diagpκq´M pλq, we can obtain a valid subgradient
by applying autodiff to the left-hand side of (6a) while treating v‹ as ﬁxed. 1 The main computational
difﬁculty is computing v‹. While our ﬁnal certiﬁcate will use an exact eigendecomposition for v‹, for
our subgradient steps, we can approximate v‹ using an iterative method such as Lanczos [34]. Lanczos
only requires repeated applications of the linear map A “: v ÞÑ
v. This linear map
can be easily represented via derivatives and Hessian-vector products of the Lagrangian.

˘
diagpκq´M pλq

`

Implementing implicit matrix-vector products via autodiff. Recall from Section 4 that the
Lagrangian is expressible via forward passes through afﬁne layers and element-wise operations
involving adjacent network layers. Since M pλq is composed of the gradient and Hessian of the
Lagrangian, we will show computing the map M pλqv is computationally roughly equal to a
forwards+backwards pass through the network. Furthermore, implementing this map is extremely
convenient in ML frameworks supporting autodiff like TensorFlow [1], PyTorch [47], or JAX [8].
From the Lagrangian (4), we note that

gpλq “

L

xp0,λq “

B

L

px,λq
Bx

and Hpλqv “

v
xxp0,λ,vq “
L

ˇ
ˇ
ˇ
ˇ
0,λ

ˆ

px,λq

B2
L
BxBxT

˙ˇ
ˇ
ˇ
ˇ
0,λ

v “

BvJ

xp0,λq
L
Bx

ˇ
ˇ
ˇ
ˇ

.

0,λ

Thus, gpλq involves a single gradient, and by using a standard trick for Hessian-vector products [48], the
Hessian-vector product Hpλqv requires roughly double the cost of a standard forward-backwards pass,
with linear memory overhead. From the deﬁnition of M pλq in (5), we can use the quantities above to get
pgpλqqJv1:N
gpλqv0 `Hpλqv1:N

p
L
xp0,λqv0 `

diagpκq´M pλq

v “ ´κdv`

“ κdv´

Arvs “

˙

ˆ

ˆ

˘

`

xp0,λqqJv1:N
v
xxp0,λ,v1:N q
L

where v0 is the ﬁrst coordinate of v and v1:N is the subvector of v formed by remaining coordinates.

L

˙

,

5.3 Practical tricks for faster convergence

The Lagrange dual problem is a convex optimization problem, and a projected subgradient method with
appropriately decaying step-sizes converges to an optimal solution [43]. However, we can achieve faster
convergence in practice through careful choices for initialization, regularization, and learning rates.

Initialization. Let κoptpλq denote the value of κ that optimizes the bound (5), for a ﬁxed λ. We initialize
with λ “ 0, and the corresponding κoptp0q using the following proposition.
Proposition 2. For any choice of λ satisfying Hpλq “ 0, the optimal choice κoptpλq is given by

nÿ

κ˚

0 “

|gpλq|i

; κ˚

1:n “ |gpλq|

i“1

where κ “ rκ0;κ1:ns is divided into a leading scalar κ0 and vector κ1:n, and |gpλq| is elementwise.

See Appendix A.7 for a proof. Note that when φpxq is linear, Hpλq “ 0 is equivalent to removing the
quadratic constraints on the activations and retaining the linear constraints in the Lagrangian (4).

Regularization. Next, we note that there always exists an optimal dual solution satisfying κ1:n “ 0,
because they are the Lagrange multipliers of a redundant constraint; full proof appears in Appendix A.5.
However, κ has an empirical beneﬁt of smoothing the optimization by preventing negative eigenvalues
of A. This is mostly noticeable in the early optimization steps. Thus, we can regularize κ through either
κ1:n, or by ﬁxing κ1:n to zero midway through optimization. In practice, we
an additional loss term
found that both options occasionally improve ﬁnal performance.

ř

Learning rates. Empirically, we observed that the optimization landscape varies signiﬁcantly for dual
variables associated with different constraints (such as linear vs. quadratic). In practice, we found
that using adaptive optimizers [16] such as Adam [27] or RMSProp [58] was necessary to stabilize
optimization. Additional learning rate adjustment for κ0 and the dual variables corresponding to the
quadratic ReLU constraints provided an improvement on some network architectures (see Appendix B).

5.4 Algorithm for verifying network speciﬁcations

1 The subgradient is a singleton except when the multiplicity of the minimum eigenvalue is greater than one,

in which case any minimal eigenvector yields a valid subgradient.

6

Algorithm 1 Veriﬁcation via SDP-FO

Input: Speciﬁcation φ and bounds on the inputs (cid:96)0 ď x0 ď u0
Output: Upper bound on the optimal value of (1)
Bound computation: Obtain layer-wise bounds (cid:96),u “ BoundPropp(cid:96)0,u0q using approaches such as [39, 70]
Lagrangian: Deﬁne Lagrangian Lpx,λq from (4)
Initialization: Initialize λ,κ (Section 5.3)
for t “ 1,...,T do

ˆ

˙

pLxp0,λqqJv1:

Lxp0,λqv0 `Lv

xxp0,λ,v1:q

(see section 5.2)

Deﬁne the linear operator At as Atrvs “ κdv´
v‹ Ð eigminpAtq using the Lanczos algorithm [34].

”
κ´

“

ı
‰
`J
v‹JAtrv‹s
1

˘

`
λt,κt

Deﬁne the function ftpλ,κq “ Lp0,λq`
¯ft Ð ft
Update λt,κt using any gradient based method to obtain ˜λ,˜κ with the gradients: B
Project λt`1 Ð

,κt`1 Ð r˜κs`.

1 (see (6))

”
˜λ

ı
`

Bλ ftpλt,κtq, B

Bκ ftpλt,κtq

end for
return mint ¯ft

We refer to our algorithm (summarized in Algorithm 1) as SDP-FO since it relies on a ﬁrst-order
method to solve the SDP relaxation. Although the full algorithm involves several components, the
implementation is simple (~100 lines for the core logic when implemented in JAX[9]) and easily
applicable to general architectures and speciﬁcations. 2 SDP-FO uses memory linear in the total number
of network activations, with per-iteration runtime linear in the cost of a forwards-backwards pass.

Computing valid certiﬁcates. Because Lanczos is an approximate method, we always report ﬁnal
bounds by computing v‹ using a non-iterative exact eigen-decomposition method from SciPy [44]. In
practice, the estimates from Lanczos are very close to the exact values, while using 0.2s/iteration on
large convolutional network, compared to 5 minutes for exact eigendecomposition (see Appendix C).

6 Experiments

In this section, we evaluate our SDP-FO veriﬁcation algorithm on two speciﬁcations: robustness to
adversarial perturbations for image classiﬁers (Sec. 6.1), and robustness to latent space perturbations
for a generative model (Sec. 6.2). In both cases, we focus on veriﬁcation-agnostic networks.

6.1 Veriﬁcation of adversarial robustness

Metrics and baselines We ﬁrst study veriﬁcation of (cid:96)8 robustness for networks trained on MNIST
and CIFAR-10. For this speciﬁcation, the objective φpxq in (1) is given by pxLqy1 ´pxLqy, where xL
denotes the the ﬁnal network activations, i.e. logits, y is the index of the true image label, and y1 is a
target label. For each image and target label, we obtain a lower bound on the optimal φpxq ď φ˚pxq by
running projected gradient descent (PGD) [38] on the objective φpxq subject to (cid:96)8 input constraints.
A veriﬁcation technique provides upper bounds φpxq ě φ˚pxq. An example is said to be veriﬁed
when the worst-case upper bound across all possible labels, denoted φx, is below 0. We ﬁrst compare
(SDP-FO, Algorithm 1 to the LP relaxation from [18], as this is a widely used approach for verifying
large networks, and is shown by [55] to encompass other relaxations including [30, 17, 65, 70, 39, 23].
We further compare to the SDP relaxation from [51] solved using MOSEK [3], a commercial interior
point SDP (SDP-IP) solver, and the MIP approach from [59].

Models Our main experiments on CNNs use two architectures: CNN-A from [67] and CNN-B from
[6]. These contain roughly 200K parameters + 10K activations, and 2M parameters + 20K activations,
respectively. All the networks we study are veriﬁcation-agnostic: trained only with nominal and/or
adversarial training [38], without any regularization to promote veriﬁability.

While these networks are much smaller than modern deep neural networks, they are an order of
magnitude larger than previously possible for veriﬁcation-agnostic networks. To compare with prior

2 Core solver implementation at https://github.com/deepmind/jax_verify/blob/master/src/

sdp_verify/sdp_verify.py

7

(a) MNIST, CNN-Adv

(b) CIFAR-10, CNN-Mix

Figure 1: Enabling certiﬁcation of veriﬁcation-agnostic networks. For 100 random examples on MNIST
and CIFAR-10, we plot the veriﬁed upper bound on φx against the adversarial lower bound (taking the
worst-case over target labels for each). Recall, an example is veriﬁed when the veriﬁed upper bound
φx ă 0. Our key result is that SDP-FO achieves tight veriﬁcation across all examples, with all points
lying close to the line y “ x. In contrast, LP or CROWN bounds produce much looser gaps between the
lower and upper bounds. We note that many CROWN bounds exceed the plotted y-axis limits.

work, we also evaluate a variety of fully-connected MLP networks, using trained parameters from
[51, 55]. These each contain roughly 1K activations. Complete training and hyperparameter details
are included in Appendix B.1.

Scalable veriﬁcation of veriﬁcation-agnostic networks Our central result is that, for veriﬁcation-
agnostic networks, SDP-FO allows us to tractably provide signiﬁcantly stronger robustness guarantees
in comparison with existing approaches. In Figure 1, we show that SDP-FO reliably achieves tight
veriﬁcation, despite using loose initial lower and upper bounds obtained from CROWN [70] in
Algorithm 1. Table 1 summarizes results. On all networks we study, we signiﬁcantly improve on the
baseline veriﬁed accuracies. For example, we improve veriﬁed robustness accuracy for CNN-A-Adv
on MNIST from 0.4% to 87.8% and for CNN-A-Mix on CIFAR-10 from 5.8% to 39.6%.

Dataset

Epsilon Model

MNIST

(cid:15) “ 0.1

MLP-SDP [52]
MLP-LP [52]
MLP-Adv [52]
MLP-Adv-B [55]
CNN-A-Adv

CIFAR-10

(cid:15) “ 0.05 MLP-Nor [55]
CNN-A-Mix-4
CNN-B-Adv-4
CNN-A-Mix
CNN-B-Adv

(cid:15) “ 2
255

Accuracy

Nominal
97.6%
92.8%
98.4%
96.8%
99.1%
98.0%
67.8%
72.0%
74.2%
80.3%

PGD
86.4%
81.2%
93.4%
84.0%
95.2%
46.6%
55.6%
62.0%
53.0%
64.0%

SDP-FO (Ours)
85.2%
80.2%
91.0%
79.2%
87.8%
28.0%
47.8%
46.0%
39.6%
32.8%

Veriﬁed Accuracy
SDP-IP:
80%
80%
82%
-
-
-
˚

˚

˚

˚

-
-

LP

MIP:
39.5% 69.2%
79.4%
26.6%
33.2% 34.4%
0.4%
1.8%
26.8%
20.4%
5.8%
2.2%

-
6.0%
-
-
-
-

: Using numbers from [52] for SDP-IP and [54] using approach of [59] for MIP. Dashes indicate previously reported numbers are unavailable.
˚ Computationally infeasible due to quartic memory requirement.

Table 1: Comparison of veriﬁed accuracy across veriﬁcation algorithms. Highlighted rows indicate
models trained in a veriﬁcation-agnostic manner. All numbers computed across the same 500 test set
examples, except when using previously reported values. For all networks, SDP-FO outperforms
previous approaches. The improvement is largest for veriﬁcation-agnostic models.

Comparisons on small-scale problems We empirically compare SDP-FO against SDP-IP using
MOSEK, a commercial interior-point solver. Since the two formulations are equivalent (see Appendix
A.4), solving them to optimality should result in the same objective. This lets us carefully isolate the
effectiveness of the optimization procedure relative to the SDP relaxation gap. However, we note that
for interior-point methods, the memory requirements are quadratic in the size of M pλq, which becomes
quickly intractable e.g. « 10 petabytes for a network with 10K activations. This restricts our comparison
to the small MLP networks from [52], while SDP-FO can scale to signiﬁcantly larger networks.

In Figure 4 of Appendix C.1, we conﬁrm that on a small random subset of matching veriﬁcation
instances, SDP-FO bounds are only slightly worse than SDP-IP bounds. This suggests that optimization
is typically not an issue for SDP-FO, and the main challenge is instead tightening the SDP relaxation.
Indeed, we can tighten the relaxation by using CROWN precomputed bounds [70] rather than interval

8

−10−50φx(Adversariallowerbound)−1001020φx(Veriﬁedupperbound)y=x(lowerboundonveriﬁcationobjective)Veriﬁedboundsacross100examplesSDP-FOLPCROWN−5−4−3−2−10123φx(Adversariallowerbound)−5051015φx(Veriﬁedupperbound)y=x(lowerboundonveriﬁcationobjective)Veriﬁedboundsacross100examplesSDP-FOLPCROWNarithmetic bounds [39, 22], which almost entirely closes the gap between SDP-FO and PGD for the
ﬁrst three rows of Table 1, including the veriﬁcation-agnostic MLP-Adv. Finally, compared to numbers
reported in [55], SDP-FO outperforms the MIP approach using progressive LP bound tightening [59].

Computational resources We cap the number of projected gradient iterations for SDP-FO. Using
a P100 GPU, maximum runtime is roughly 15 minutes per MLP instances, and 3 hours per CNN
instances, though most instances are veriﬁed sooner. For reference, SDP-IP uses 25 minutes on a
4-core CPU per MLP instance [52], and is intractable for CNN instances due to quartic memory usage.

Limitations. In principle, our solver’s linear asymptotics allow scaling to extremely large networks.
However, in practice, we observe loose bounds with large networks. In Table 1, there is already a
signiﬁcantly larger gap between the PGD and SDP-FO bounds for the larger CNN-B models compared
to their CNN-A counterparts, and in preliminary experiments, this gap increases further with network
size. Thus, while our results demonstrate that the SDP relaxation remains tight on signiﬁcantly larger
networks than those studied in Raghunathan et al. [52], additional innovations in either the formulation
or optimization process are necessary to enable further scaling.

6.2 Verifying variational auto-encoders (VAEs)

Figure 2: Comparison of different approaches for verify-
ing the robustness of the decoder of a VAE on MNIST,
measured across 100 samples. The lower-bound on the
robust accuracy computed with SDP-FO closely matches
the upper bound based on a PGD adversarial attack upto
perturbations of 0.1 σz, while the lower bound based on
IBP begins to diverge from the PGD upper bound at much
smaller perturbations.

N

pµs;z

sq “
|

Setup To test the generality of our approach, we consider a different speciﬁcation of verifying the
validity of constructions from deep generative models, speciﬁcally variational auto-encoders (VAEs)
E ,σz;s
pµz;s
E q denote the distribution of the latent representation z corresponding
[28]. Let qEpz
D ,I q denote the decoder. Our aim is to certify robustness of the
zq “
to input s, and let qDps
N
|
decoder to perturbations in the VAE latent space. Formally, the VAE decoder is robust to (cid:96)8 latent
perturbations for input s and perturbation radius α P R`` if:
@z1 s.t
D q :“

(7)
where εrecon is the reconstruction error. Note that unlike the adversarial robustness setting where the
objective was linear, the objective function εrecon is quadratic. Quadratic objectives are not directly
amenable to LP or MIP solvers without further relaxing the quadratic objective to a linear one. For
varying perturbation radii α, we measure the test set fraction with veriﬁed reconstruction error below
τ “ 40.97, which is the median squared Euclidean distance between a point s and the closest point
with a different label (over MNIST).

s´µs;z
2
2 ď τ
D (cid:107)
(cid:107)

E (cid:107)8 ď ασz;s
E ,

εreconps,µs;z

z1 ´µz;s

(cid:107)

Results We verify a VAE on MNIST with a convolutional decoder containing « 10K total activations.
Figure 2 shows the results. To visualize the improvements resulting from our solver, we include a
comparison with guarantees based on interval arithmetic bound propagation (IBP) [23, 39], which
we use to generate the bounds used in Algorithm 1. Compared to IBP, SDP-FO can successfully verify
at perturbation radii roughly 50x as large. For example, IBP successfully veriﬁes 50% at roughly
(cid:15) “ 0.01 compared to (cid:15) “ 0.5 for SDP-FO. We note that besides the IBP bounds being themselves
loose compared to the SDP relaxations, they further suffer from a similar drawback as LP/MIP methods
in that they bound εrecon via (cid:96)8-bounds, which further results in looser bounds on εrecon. Further
details and visualizations are included in Appendix B.2.

7 Conclusion

We have developed a promising approach to scalable tight veriﬁcation and demonstrated good
performance on larger scale than was possible previously. While in principle, this solver is applicable
to arbitrarily large networks, further innovations (in either the formulation or solving process) are
necessary to get meaningful veriﬁed guarantees on larger networks.

9

103102101100101Perturbation Radius:  (no. of std. dev.)020406080% of verified samplesSDP-FOIBPPGD upper boundAcknowledgements

We are grateful to Yair Carmon, Ollie Hinder, M Pawan Kumar, Christian Tjandraatmadja, Vincent
Tjeng, and Rahul Trivedi for helpful discussions and suggestions. This work was supported by NSF
Award Grant no. 1805310. AR was supported by a Google PhD Fellowship and Open Philanthropy
Project AI Fellowship.

Broader Impact

Our work enables verifying properties of veriﬁcation-agnostic neural networks trained using
procedures agnostic to any speciﬁcation veriﬁcation algorithm. While the present scalability of the
algorithm does not allow it to be applied to SOTA deep learning models, in many applications it is
vital to verify properties of smaller models running safety-critical systems (learned controllers running
on embedded systems, for example). The work we have presented here does not address data related
issues directly, and would be susceptible to any biases inherent in the data that the model was trained
on. However, as a veriﬁcation technique, it does not enhance biases present in any pre-trained model,
and is only used as a post-hoc check. We do not envisage any signiﬁcant harmful applications of our
work, although it may be possible for adversarial actors to use this approach to verify properties of
models designed to induce harm (for example, learning based bots designed to break spam ﬁlters or
induce harmful behavior in a conversational AI system).

10

References

[1] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu
Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. Tensorﬂow: A system for
large-scale machine learning. In 12th tUSENIXu Symposium on Operating Systems Design and
Implementation (tOSDIu 16), pages 265–283, 2016.

[2] Ross Anderson, Joey Huchette, Will Ma, Christian Tjandraatmadja, and Juan Pablo Vielma.
Strong mixed-integer programming formulations for trained neural networks. Mathematical
Programming, pages 1–37, 2020.

[3] MOSEK ApS. The MOSEK optimization toolbox for MATLAB manual. Version 9.0., 2019. URL

http://docs.mosek.com/9.0/toolbox/index.html.

[4] Sanjeev Arora and Satyen Kale. A combinatorial, primal-dual approach to semideﬁnite
ISSN 0004-5411. doi: 10.1145/2837020. URL

programs. J. ACM, 63(2), May 2016.
https://doi.org/10.1145/2837020.

[5] Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of se-
curity: Circumventing defenses to adversarial examples. arXiv preprint arXiv:1802.00420, 2018.

[6] Mislav Balunovic and Martin Vechev. Adversarial training and provable defenses: Bridg-
In International Conference on Learning Representations, 2020. URL

ing the gap.
https://openreview.net/forum?id=SJxSDxrKDr.

[7] Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim Šrndi´c, Pavel Laskov,
Giorgio Giacinto, and Fabio Roli. Evasion attacks against machine learning at test time. In
Joint European conference on machine learning and knowledge discovery in databases, pages
387–402. Springer, 2013.

[8] James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal
Maclaurin, and Skye Wanderman-Milne. Jax: composable transformations of python+ numpy
programs, 2018. URL http://github. com/google/jax, page 18.

[9] James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal
Maclaurin, and Skye Wanderman-Milne. JAX: composable transformations of Python+NumPy
programs, 2018. URL http://github.com/google/jax.

[10] Rudy R Bunel, Ilker Turkaslan, Philip Torr, Pushmeet Kohli, and Pawan K Mudigonda. A
uniﬁed view of piecewise linear neural network veriﬁcation. In Advances in Neural Information
Processing Systems, pages 4790–4799, 2018.

[11] Jeremy M Cohen, Elan Rosenfeld, and J Zico Kolter. Certiﬁed adversarial robustness via

randomized smoothing. arXiv preprint arXiv:1902.02918, 2019.

[12] Gal Dalal, Krishnamurthy Dvijotham, Matej Vecerik, Todd Hester, Cosmin Paduraru, and Yuval

Tassa. Safe exploration in continuous action spaces. arXiv preprint arXiv:1801.08757, 2018.

[13] John M Danskin. The theory of max-min with applications. Siam J. Appl. Math, 1966.

[14] Alexandre d’Aspremont and Noureddine El Karoui. A stochastic smoothing algorithm for

semideﬁnite programming. SIAM Journal on Optimization, 24(3):1138–1177, 2014.

[15] Lijun Ding, Alp Yurtsever, Volkan Cevher, Joel A Tropp, and Madeleine Udell. An optimal-
storage approach to semideﬁnite programming using approximate complementarity. arXiv
preprint arXiv:1902.03373, 2019.

[16] John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning

and stochastic optimization. Journal of machine learning research, 12(Jul):2121–2159, 2011.

[17] Krishnamurthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy Mann, and Pushmeet Kohli.
A dual approach to scalable veriﬁcation of deep networks. arXiv preprint arXiv:1803.06567,
104, 2018.

11

[18] Rüdiger Ehlers. Formal veriﬁcation of piece-wise linear feed-forward neural networks. In Deepak
D’Souza and K. Narayan Kumar, editors, Automated Technology for Veriﬁcation and Analysis,
pages 269–286, Cham, 2017. Springer International Publishing. ISBN 978-3-319-68167-2.

[19] Mahyar Fazlyab, Manfred Morari, and George J Pappas. Safety veriﬁcation and robustness
analysis of neural networks via quadratic constraints and semideﬁnite programming. arXiv
preprint arXiv:1903.01287, 2019.

[20] Mahyar Fazlyab, Alexander Robey, Hamed Hassani, Manfred Morari, and George Pappas.
Efﬁcient and accurate estimation of lipschitz constants for deep neural networks. In Advances
in Neural Information Processing Systems, pages 11423–11434, 2019.

[21] Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat Chaudhuri,
and Martin Vechev. Ai 2: Safety and robustness certiﬁcation of neural networks with abstract
interpretation. In Security and Privacy (SP), 2018 IEEE Symposium on, 2018.

[22] Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan
Uesato, Timothy Mann, and Pushmeet Kohli. On the effectiveness of interval bound propagation
for training veriﬁably robust models. arXiv preprint arXiv:1810.12715, 2018.

[23] Sven Gowal, Krishnamurthy Dj Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin,
Jonathan Uesato, Relja Arandjelovic, Timothy Mann, and Pushmeet Kohli. Scalable veriﬁed
training for provably robust image classiﬁcation. In Proceedings of the IEEE International
Conference on Computer Vision, pages 4842–4851, 2019.

[24] Sven Gowal, Chongli Qin, Po-Sen Huang, Taylan Cemgil, Krishnamurthy Dvijotham, Timothy
Mann, and Pushmeet Kohli. Achieving robustness in the wild via adversarial mixing with
disentangled representations. In Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pages 1211–1220, 2020.

[25] Christoph Helmberg and Franz Rendl. A spectral bundle method for semideﬁnite programming.

SIAM Journal on Optimization, 10(3):673–696, 2000.

[26] Guy Katz, Clark Barrett, David L Dill, Kyle Julian, and Mykel J Kochenderfer. Reluplex: An
efﬁcient smt solver for verifying deep neural networks. In International Conference on Computer
Aided Veriﬁcation, pages 97–117. Springer, 2017.

[27] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint

arXiv:1412.6980, 2014.

[28] Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. In Yoshua Bengio
and Yann LeCun, editors, 2nd International Conference on Learning Representations, ICLR
2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings, 2014. URL
http://arxiv.org/abs/1312.6114.

[29] Torsten Koller, Felix Berkenkamp, Matteo Turchetta, and Andreas Krause. Learning-based
model predictive control for safe exploration. In 2018 IEEE Conference on Decision and Control
(CDC), pages 6059–6066. IEEE, 2018.

[30] J Zico Kolter and Eric Wong. Provable defenses against adversarial examples via the convex

outer adversarial polytope. arXiv preprint arXiv:1711.00851, 2017.

[31] Jacek Kuczy´nski and Henryk Wo´zniakowski. Estimating the largest eigenvalue by the power
and lanczos algorithms with a random start. SIAM journal on matrix analysis and applications,
13(4):1094–1122, 1992.

[32] Lindsey Kuper, Guy Katz, Justin Gottschlich, Kyle Julian, Clark Barrett, and Mykel Kochenderfer.
Toward scalable veriﬁcation for safety-critical deep networks. arXiv preprint arXiv:1801.05950,
2018.

[33] Guanghui Lan, Zhaosong Lu, and Renato DC Monteiro. Primal-dual ﬁrst-order methods with
Op1{(cid:15)) iteration-complexity for cone programming. Mathematical Programming, 126(1):1–29,
2011.

12

[34] Cornelius Lanczos. An iteration method for the solution of the eigenvalue problem of linear
differential and integral operators. United States Governm. Press Ofﬁce Los Angeles, CA, 1950.

[35] Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman Jana. Certiﬁed
robustness to adversarial examples with differential privacy. arXiv preprint arXiv:1802.03471,
2018.

[36] Claude Lemaréchal and François Oustry. Nonsmooth algorithms to solve semideﬁnite programs.

In Advances in linear matrix inequality methods in control, pages 57–77. SIAM, 2000.

[37] Changliu Liu, Tomer Arnon, Christopher Lazarus, Clark Barrett, and Mykel J Kochenderfer.
Algorithms for verifying deep neural networks. arXiv preprint arXiv:1903.06758, 2019.

[38] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083,
2017.

[39] Matthew Mirman, Timon Gehr, and Martin Vechev. Differentiable abstract interpretation for
provably robust neural networks. In International Conference on Machine Learning, pages
3575–3583, 2018.

[40] Teodor Mihai Moldovan and Pieter Abbeel. Safe exploration in markov decision processes.

arXiv preprint arXiv:1205.4810, 2012.

[41] Renato DC Monteiro.

First-and second-order methods for semideﬁnite programming.

Mathematical Programming, 97(1-2):209–244, 2003.

[42] Yurii Nesterov.

Smoothing technique and its applications in semideﬁnite optimization.

Mathematical Programming, 110(2):245–259, 2007.

[43] Yurii Nesterov. Lectures on convex optimization, volume 137. Springer, 2018.

[44] T. E. Oliphant. Python for scientiﬁc computing. Computing in Science Engineering, 9(3):10–20,

2007.

[45] Neal Parikh and Stephen Boyd. Proximal algorithms. Foundations and Trends in optimization,

1(3):127–239, 2014.

[46] Beresford N Parlett. The symmetric eigenvalue problem, volume 20. siam, 1998.

[47] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,
Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative
style, high-performance deep learning library. In Advances in Neural Information Processing
Systems, pages 8024–8035, 2019.

[48] Barak A Pearlmutter. Fast exact multiplication by the hessian. Neural computation, 6(1):

147–160, 1994.

[49] Chongli Qin, Krishnamurthy (Dj) Dvijotham, Brendan O’Donoghue, Rudy Bunel, Robert
Stanforth, Sven Gowal, Jonathan Uesato, Grzegorz Swirszcz, and Pushmeet Kohli. Veriﬁcation
In International Conference on Learning
of non-linear speciﬁcations for neural networks.
Representations, 2019. URL https://openreview.net/forum?id=HyeFAsRctQ.

[50] Haonan Qiu, Chaowei Xiao, Lei Yang, Xinchen Yan, Honglak Lee, and Bo Li. Semanticadv:
arXiv preprint

Generating adversarial examples via attribute-conditional image editing.
arXiv:1906.07927, 2019.

[51] Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. Certiﬁed defenses against adver-
In International Conference on Learning Representations, 2018. URL

sarial examples.
https://openreview.net/forum?id=Bys4ob-Rb.

[52] Aditi Raghunathan, Jacob Steinhardt, and Percy S Liang. Semideﬁnite relaxations for certifying
robustness to adversarial examples. In Advances in Neural Information Processing Systems,
pages 10877–10887, 2018.

13

[53] James Renegar. Efﬁcient ﬁrst-order methods for linear programming and semideﬁnite

programming. arXiv preprint arXiv:1409.5832, 2014.

[54] Hadi Salman, Greg Yang, Huan Zhang, Cho-Jui Hsieh, and Pengchuan Zhang. A convex relaxation
barrier to tight robust veriﬁcation of neural networks. arXiv preprint arXiv:1902.08722, 2019.

[55] Hadi Salman, Greg Yang, Huan Zhang, Cho-Jui Hsieh, and Pengchuan Zhang. A convex
relaxation barrier to tight robustness veriﬁcation of neural networks. CoRR, abs/1902.08722,
2019. URL http://arxiv.org/abs/1902.08722.

[56] Gagandeep Singh, Timon Gehr, Matthew Mirman, Markus Püschel, and Martin Vechev. Fast
and effective robustness certiﬁcation. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman,
N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems 31,
pages 10802–10813. Curran Associates, Inc., 2018. URL http://papers.nips.cc/paper/
8278-fast-and-effective-robustness-certification.pdf.

[57] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian
Intriguing properties of neural networks. arXiv preprint

Goodfellow, and Rob Fergus.
arXiv:1312.6199, 2013.

[58] Tijmen Tieleman and Geoffery Hinton. Rmsprop gradient optimization. URL http://www. cs.

toronto. edu/tijmen/csc321/slides/lecture_slides_lec6. pdf, 2014.

[59] Vincent Tjeng, Kai Y. Xiao, and Russ Tedrake. Evaluating robustness of neural networks with
mixed integer programming. In International Conference on Learning Representations, 2019.
URL https://openreview.net/forum?id=HyGIdiRqtm.

[60] Stephen Tu and Jingyan Wang. Practical ﬁrst order methods for large scale semideﬁnite
programming. Technical report, Technical report, University of California, Berkeley, 2014.

[61] Jonathan Uesato, Brendan O’Donoghue, Aaron van den Oord, and Pushmeet Kohli. Adversarial
risk and the dangers of evaluating against weak attacks. arXiv preprint arXiv:1802.05666, 2018.

[62] Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David
Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, Stéfan J.
van der Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J.
Nelson, Eric Jones, Robert Kern, Eric Larson, CJ Carey, ˙Ilhan Polat, Yu Feng, Eric W. Moore,
Jake Vand erPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A. Quintero,
Charles R Harris, Anne M. Archibald, Antônio H. Ribeiro, Fabian Pedregosa, Paul van Mulbregt,
and SciPy 1. 0 Contributors. SciPy 1.0: Fundamental Algorithms for Scientiﬁc Computing in
Python. Nature Methods, 17:261–272, 2020. doi: https://doi.org/10.1038/s41592-019-0686-2.

[63] Zaiwen Wen. First-order methods for semideﬁnite programming. Columbia University, 2009.

[64] Zaiwen Wen, Donald Goldfarb, and Wotao Yin. Alternating direction augmented lagrangian
methods for semideﬁnite programming. Mathematical Programming Computation, 2(3-4):
203–230, 2010.

[65] Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Duane Boning,
Inderjit S Dhillon, and Luca Daniel. Towards fast computation of certiﬁed robustness for relu
networks. arXiv preprint arXiv:1804.09699, 2018.

[66] Eric Wong and J Zico Kolter. Learning perturbation sets for robust machine learning. arXiv

preprint arXiv:2007.08450, 2020.

[67] Eric Wong, Frank Schmidt, Jan Hendrik Metzen, and J Zico Kolter. Scaling provable adversarial
defenses. In Advances in Neural Information Processing Systems, pages 8400–8409, 2018.

[68] Alp Yurtsever, Madeleine Udell, Joel A Tropp, and Volkan Cevher. Sketchy decisions: Convex
low-rank matrix optimization with optimal storage. arXiv preprint arXiv:1702.06838, 2017.

[69] Alp Yurtsever, Joel A Tropp, Olivier Fercoq, Madeleine Udell, and Volkan Cevher. Scalable

semideﬁnite programming. arXiv preprint arXiv:1912.02949, 2019.

[70] Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel. Efﬁcient neural
In Advances in neural

network robustness certiﬁcation with general activation functions.
information processing systems, pages 4939–4948, 2018.

14

A Omitted proofs

A.1 Adversarial robustness as quadratic speciﬁcation

Consider certifying robustness: For input x0 P Rd with true label i, the network does not misclassify
any adversarial example within (cid:96)8 distance of (cid:15) from x0. This property holds if the score of any
incorrect class j is always lower than that of i for all perturbations. Thus φpxq “ cJxL with cj “ 1
and ci “ ´1. The input constraints are also linear: ´(cid:15) ď xi ´x0i ď (cid:15), for i “ 1,2,...d.

A.2 Linear and quadratic constraints for ReLU networks

ReLU as quadratic constraints: For the case of ReLU networks, we can do this exactly, as described
in [52]. Consider a single activation xpost “ maxpxpre, 0q. This can be equivalently written as
xpost ě 0,xpost ě xpre, stating that xpost is greater than 0 and xpre. Additionally, the quadratic constraint
xpostpxpost ´ xpreq “ 0, enforces that xpost is atleast one of the two. This can be extended to all units
in the network allowing us to replace ReLU constraints with quadratic constraints.

A.3 Formulation of bound constrained dual problem

Proposition 1. The optimal value opt of the quadratic veriﬁcation problem (1) is bounded above by

optrelax “: min

λě0,κě0

cpλq`
loooooooooooooooooooooooooomoooooooooooooooooooooooooon

ı
`
minpdiagpκq´M pλqq1

”
κ´λ´

1J

1
2

, M pλq “

ˆ

˙

0

gpλqJ
gpλq Hpλq

,

(8)

and λ´

minpZq is the negative portion of the smallest eigen value of Z, i.e. rλminpZqs´ and κ P R1`N .

f pλ,κq

Proof. We start with the Lagrangian in (4) with rescaled activations such that (cid:96) “ ´1 and u “ 1, where
(cid:96) and u are lower and upper bounds on the activations x P Rn respectively. This normalization is
achieved by using pre-computed bounds via bound propagation, which are used to write the quadratic
constraints, as in [52].

´

¯

xJHpλqx

.

(9)

Deﬁne

opt ď min
λľ0

max
´1ĺxĺ1

cpλq`gpλqJx`

˙

ˆ

˜X “

xJ
1
x xxJ.

1
2

In terms of the above matrix, the above Lagrangian relaxation (9) can be equivalently written as:

opt ď“: min
λľ0
ˆ

cpλq`
max
diagp ˜Xqď1
˙
gpλqJ
gpλq Hpλq

0

M pλq “

1
2

xM pλq, ˜Xy, where

(10)

(11)

Note that ˜X is always a PSD matrix with diagonal entries bounded above by 1. This yields the
following relaxation of (9)

opt ď optsdp “: min
λľ0

max
diagpXqĺ1,Xľ0

cpλq`

1
2

xM pλq,Xy.

(12)

We introduce a Lagrange multiplier 1
convex, by strong duality, we have

2 κ P Rn`1 for the constraint diagpXq ĺ 13. Since optsdp is

optsdp “ min
λ,κľ0

max
Xľ0

cpλq`

1
2

´

¯

xM pλq,Xy`κJ1´xdiagpκq,Xy

,

(13)

(14)

“ min
λ,κľ0

cpλq`

1
2

κJ1 s.t. diagpκq´M pλq ľ 0,

3The factor of 1

2 is introduced for convenience

15

where the last equality follows from the facts that (i) when diagpκq ´ M pλq is not PSD,
xM pλq ´ diagpκq,Xy would be unbounded when maximizing over PSD matrices X and (ii) when
diagpκq´M pλq ľ 0, the maximum value of inner maximization over PSD matrices X is 0.

Projecting onto the PSD constraint diagpκq´M pλq ľ 0 directly is still expensive. Instead, we take
the following approach. For any non-negative pκ,λq, we generate a feasible pˆκ,ˆλq as follows.

”
κ´λ´
min

“

‰

diagpκq´M pλq

ı
`
1

ˆκ “

, ˆλ “ λ

(15)

In other words, λ remains unchanged with ˆλ “ λ. To obtain ˆκ, we ﬁrst compute the minimum
eigenvalue λmin of the matrix diagpκq´M pλq. If this is positive, pκ,λq are feasible, and ˆκ “ κ,ˆλ “ λ.
However, if this is negative, we then add the negative portion of λ´
min “ rλmins´ to the diagonal matrix
to make diagpˆκq ľ M pλq, and subsequently project onto the non-negativity constraint. The subsequent
projection never decreases the value of ˆκ and hence diagpˆκq´M pλq ľ 0.
Plugging ˆκ,ˆλ in the objective above, and removing the PSD constraint gives us the following ﬁnal
formulation.

optsdp “ optrelax “: min
λ,κľ0

cpλq`

1
2

”
κ´λ´

ı
`J
minpdiagpκq´M pλqq1

1.

(16)

Note that feasible κ,λ remain unchanged and hence the equality.

A.4 Relaxation comparison to Raghunathan et al. [52]

Our solver (Algorithm 1) uses the formulation described in (5), replicated above in (16). In this section,
we show that the above formulation is equivalent to the SDP formulation in [52] when we use quadratic
constraints to replace the ReLU constraints, as done in [52] and presented above in Appendix A.2. We
show this by showing equivalence with an intermediate SDP formulation below. From Appendix A.3,
the solution to this intermediate fomulation matches that of relaxation we optimize (16).

optsdp “: min
λľ0

max
diagpXqď1,Xľ0

cpλq`

1
2

xM pλq,Xy.

To mirror the block structure in M pλq, we write X ľ 0 as follows.

ˆ

X “

˙

X11 X J
x
Xx Xxx

,Xxx ľ

1
X11

XxX J
x ,

(17)

(18)

where the last condition follows by Schur complements.

The objective then takes the form

2 xHpλq,Xxxy. Note that the feasible
set (over Xxx,Xx) for X11 “ 1 contains the feasible sets for any smaller X11, by the Schur complement
condition above. Since X11 does not appear in the objective, we can set X11 “ 1 to obtain the following
equality.

max
diagpXxxqĺ1,X11ď1

gpλqJXx ` 1

optsdp “ min
λľ0

max
diagpXqĺ1,X11“1,Xľ0

cpλq`gpλqJXx `

1
2

xHpλq,Xxxy,

(19)

where X11 is the ﬁrst entry, and Xx,Xxx are the blocks as described in (18).

Prior SDP. Now we start with the SDP formulation in [52]. Recall that we have a QCQP that
represents the original veriﬁcation problem with quadratic constraints on activations. The relaxation
in [52] involves intoducing a new matrix variable P as follows.
˙

ˆ

P “

P r1s
P rxs
P rxs P rxxs.

(20)

The quadratic constraints are now written in terms of P where P rxs replaces the linear terms and
P rxxs replaces the quadratic terms. Raghunathan et al. [52] optimize this primal SDP formulation
to obtain optprior-sdp. By strong duality, optprior-sdp matches the optimum of the dual problem obtained

16

via the Lagrangian relaxation of the SDP. In terms of the quantities g,H that we deﬁned in this work
((3) and (4)), we have

optprior-sdp “ min
λľ0

max
diagpP qĺ1,P r1s“1,P ľ0L

prior-sdppP,λq

“ min
λľ0

max
diagpP qĺ1,P r1s“1,P ľ0

cpλq`gpλqJP rxs`

1
2

xHpλq,P rxxsy.

(21)

(22)

By redeﬁning matrix P as X, from (19) and (21), we have optsdp “ optprior-sdp. From (16), we have
optsdp “ optrelax and hence proved that the optimal solution of our formulation matches that of prior
work [52] when using the same quadratic constraints as used in [52]. In other words, our reformulation
that allows for a subgradient based memory efﬁcient solver does not introduce additional looseness
over the original formulation that uses a memory inefﬁcient interior point solver.

A.5 Regularization of κ via alternate dual formulation

In Section 5.3, we describe that it can be helpful to regularize κ1:n towards 0. This is motivated by
the following proposition:
Proposition 3. The optimal value opt is upper-bounded by the alternate dual problem

opt ď min
λ,κľ0

cpλq`
κ0
loooomoooon

1
2

s.t.

ˆf pλ,κ0q

ˆ

˙

κ0

´gpλqJ
´gpλq ´Hpλq

ľ 0

(23)

Further, for any feasible solution λ,κ0 for this dual problem, we can obtain a corresponding solution
to optrelax with λ,κ0,κ1:n “ 0,κ “ pκ0;κ1:nq, such that f pλ,κq “ ˆf pλ,κ0q.

Proof. We begin with the Lagrangian dual

opt ď optlagAlt “: min
λľ0

max
x

cpλq`xJgpλq`

1
2

xJHpλqx.

(24)

Note that this is exactly the dual from Equation (4), without the bound constraints on x in the inner
maximization. In other words, whereas Equation (4) encodes the bound constraints into both the
Lagrangian and the inner maximization constraints, in Equation 24, the bound constraints are encoded
in the Lagrangian only.
The inner maximization can be solved in closed form, and is maximized for x “ ´Hpλq´1gpλq, yielding

optlagAlt “ min
λľ0

cpλq´

1
2

gpλqJHpλqgpλq.

We can then reformulate using Schur complements:

optlagAlt “ min
λľ0,κ0

cpλq`

κ0 s.t. κ0 ě ´gpλqHpλq´1gpλq

“ min
λľ0,κ0

cpλq`
ˆ

κ0 s.t. ˆM pλq ľ 0 where
˙

ˆM pλq “

κ0

´gpλqJ
´gpλq ´Hpλq

.

1
2
1
2

(25)

(26a)

(26b)

(26c)

To see that this provides a corresponding solution to optrelax, we note that when ˆM ľ 0, the choice
κ “ pκ0;κ1:nq,κ1:n “ 0 makes diagpκq´M pλq “ ˆM pλq, and so λ´
“ 0. Thus, for
min
any solution λ,κ0, we have f pλ,κq “ ˆf pλ,κ0q “ cpλq` 1

‰
“
diagpκq´M pλq

2 κ0.

Remark. Proposition 3 indicates that regularizing κ1:n towards 0 corresponds to solving the alternate
dual formulation optdualAlt, which does not use bound constraints for the inner maximization. In
this case, the role of κ1:n and ˆκ is slightly different: even in the case when κ1:n is clamped to 0, the
bound-constrained formulation allows an efﬁcient projection operator, which in turn provide efﬁcient
any-time bounds.

17

A.6

Informal comparison to standard maximum eigenvalue formulation

Our derivation for Proposition 1 is similar to maximum eigenvalue formulations for dual SDPs – our
main emphasis is that when applied to neural networks, we can use autodiff and implicit matrix-vector
products to efﬁciently compute subgradients.

We also mention here a minor difference in derivations for convenience of readers. The common
derivation for these maximum eigenvalue formulations starts with an SDP primal under the assumption
that all feasible solutions for the matrix variable X have ﬁxed trace. This trace assumption plays an
analogous role to our interval constraints in the QCQP (12). These interval constraints also imply
a trace constraint (since diagpXq ď 1 implies trpXq ď N `1), but the interval constraints also allow
us to use κ to smooth the optimization. Without κ, any positive eigenvalues of M pλq cause large spikes
in the objective – simplifying the objective f pλ,κq in (5) reveals the term pN `1qλ`
maxpM pλqq which
grows linearly with N . As expected, this term also appears in these other formulations [25, 42].

A.7 Proof of Proposition 2

Proposition 2. For any choice of λ satisfying Hpλq “ 0, the optimal choice κoptpλq is given by

nÿ

κ˚

0 “

|gpλq|i

; κ˚

1:n “ |gpλq|

i“1

where we have divided κ “ rκ0;κ1:ns into a leading scalar κ0 and a vector κ1:n.

Proof. We use the dual expression from Equation (14):

optsdp “ min
λ,κľ0

cpλq`

1
2

κJ1 s.t. diagpκq´M pλq ľ 0.

Notice that by splitting κ into its leading component κ0 (a scalar) and the subvector κ1:n “ rκ1,...,κns
(a vector of the same dimension as x), the constraint between κ,λ evaluates to

diagpκq´M pλq “

ˆ

˙

κ0
gpλq diagpκ1:nq

gpλqJ

ľ 0

Using Schur complements, we can rewrite the PSD constraint as

´

¯

diagpκq´M pλq

ľ 0 ô κ0 ě

ÿ

iě1

κ´1
i

pgpλqq2
i

Since the objective is monotonically increasing in κ0, the optimal choice for κ0 is the lower bound
above κ0 ě

i . Given this choice, the objective in terms of κ1:n becomes

pgpλqq2

iě1κ´1

ř

i

ÿ

κi `

iě1

pgpλqq2
i
κi

By the AM-GM inequality, the optimal choice for the remaining terms κ1:n is then κ1:n “ |gpλq|.

B Experimental details

B.1 Verifying Adversarial Robustness: Training and Hyperparameter Details

Optimization details. We perform subgradient descent using the Adam [27] update rule for MLP
experiments, and RMSProp for CNN experiments. We use an initial learning rate of 1e ´ 3, which
we anneal twice by 10. We use 15K optimization steps for all MLP experiments, 60K for CNN
experiments on MNIST, and 150K on CIFAR-10. All experiments run on a single P100 GPU.

18

˘

`

xi`1 ´ Lipxiq

Adaptive learning rates For MLP experiments, we use an adaptive learning rate for dual variables
associated with the constraint xi`1 d
ĺ 0, as mentioned in Section 5.3. In early
experiments for MLP-Adv, we observed very sharp curvature in the dual objective with respect to
these variables – the gradient has values on the order « 1e3 while the solution at convergence has
values on the order of « 1e´2. Thus, for all MLP experiments, we decrease learning rates associated
with these variables by a 10ˆ factor. While SDP-FO produced meaningful bounds even without this
adjustment, we observed that this makes optimization signiﬁcantly more stable for MLP experiments.
This adjustment was not necessary for CNN experiments.

Training Modes We conduct experiments on networks trained in three different modes. Nor
indicates the network was trained only on unperturbed examples, with the standard cross-entropy loss.
Adv networks use adversarial training [38]. Mix networks average the adversarial and normal losses,
with equal weights on each. We ﬁnd that Mix training, while providing a signiﬁcant improvement
in test-accuracy, renders the model less veriﬁable (across veriﬁcation methods) than training only
with adversarial examples.

The sufﬁx -4 in the network name (e.g. CNN-A-Mix-4) indicates networks trained with the large
perturbation radius (cid:15)train “ 4.4{255. We ﬁnd that using larger (cid:15)train implicitly facilitates veriﬁcation
at smaller (cid:15) (across veriﬁcation methods), but is accompanied by a signiﬁcant drop in clean accuracy.
For all other networks, we choose (cid:15)train to match the evaluation (cid:15): i.e. generally (cid:15) “ 0.1 on MNIST
and (cid:15) “ 2.2{255 on CIFAR-10 (which slightly improves adversarial robustness relative to (cid:15) “ 2{255
as reported in [22]).

Pre-trained networks For the networks MLP-LP, MLP-SDP, MLP-Adv, we use the trained
parameters from [52], and for the networks MLP-Nor, MLP-Adv-B we use the trained parameters
from [55].

Model Architectures Each model architecture is associated with a preﬁx for the network name.
Table 2 summarizes the CNN model architectures. The MLP models are taken directly from [52, 55] and
use fully-connected layers with ReLU activations. The number of neurons per layer is as follows: MLP-
Adv 784-200-100-50-10, MLP-LP/MLP-SDP 784-500-10, MLP-B/MLP-Nor 784-100-100-10.

Model

Architecture

CNN-A
CONV 16 4×4+2
CONV 32 4×4+1
FC 100
FC 10

CNN-B
CONV 32 5×5+2
CONV 128 4×4+2
FC 250
FC 10

Table 2: Architecture of CNN models used on MNIST and CIFAR-10. Each layer (except the last fully
connected layer) is followed by ReLU activations. CONV T W×H+S corresponds to a convolutional
layer with T ﬁlters of size W×H with stride of S in both dimensions. FC T corresponds to a fully
connected layer with T output neurons.

B.2 Verifying VAEs

Architecture Details We train a VAE on the MNIST dataset with the architecture detailed in Table 3.

Encoder
FC 512
FC 512
FC 512
FC 16

Decoder
FC 1568
CONV-T 32 3×3+2
CONV-T 3×3+1

Table 3: The VAE consists of an encoder and a decoder, and the architecture details for both the encoder
and the decoder are provided here. CONV-T T W×H+S corresponds to a transpose convolutional layer
with T ﬁlters of size W×H with stride of S in both dimensions.

19

(a) Original and Perturbed Digit ‘9’

(b) Original and Perturbed Digit ‘0’

Figure 3: Two digits from the MNIST data set, and the corresponding images when perturbed with
Gaussian noise, whose squared (cid:96)2-norm is equal to the threshold (τ “ 40.97). τ corresponds to
threshold on the reconstruction error used in equation (7).

Optimization details. We perform subgradient descent using RMSProp with an initial learning
rate of 1e ´ 3, which we anneal twice by 10. All experiments run on a single P100 GPU, and each
veriﬁcation instance takes under 7 hours to run.

Computing bounds on the reconstruction loss based on interval bound propagation Interval
bound propagation lets us compute bounds on the activations of the decoder, given bounded l8
perturbations in the latent space of the VAE. Given a lower bound lb and an upper bound ub on the
s ´ ˆs
output of the decoder, we can compute an upper bound on the reconstruction error
2 over
(cid:107)
(cid:107)
2
2, where max represents the element-wise
s ´ lb
,
ub ´ s
all valid latent perturbations as
|
|
|
|
(cid:107)
maximum between the two vectors. We visualize images perturbed by noise corresponding to the
threshold τ on the reconstruction error in Section 6.2 in Figure 3.

maxt

u
(cid:107)

C Additional results

C.1 Detailed comparison to off-the-shelf solver

Setup We isolate the impact of optimization by comparing performance to an off-the-shelf solver
with the same SDP relaxation. For this experiment, we use the MLP-Adv network from [51], selecting
quadratic constraints to attain an equivalent relaxation to [51]. We compare across 10 random
examples, using the target label with the highest loss under a PGD attack, i.e. the target label closest
to being misclassiﬁed. For each example, we measure ΦPGD, ΦSDP-IP, and ΦSDP-FO, where Φ and
Φ are as deﬁned in Section 6.1. Since the interior point method used by MOSEK can solve SDPs
exactly for small-scale problems, this allows analyzing looseness incurred due to the relaxation vs.
optimization. In particular, ΦSDP-IP ´ ΦPGD is the relaxation gap, plus any suboptimality for PGD,
while ΦSDP-IP ´ΦSDP-FO is the optimization gap due to inexactness in the SDP-FO dual solution.

Results We observe that SDP-FO converges to a near-optimal dual solution in all 10 examples. This
is shown in Figure 4. Quantitatively, the relaxation gap ΦSDP-IP ´ΦPGD has a mean of 0.80 (standard
deviation 0.22) over the 10 examples, while the optimization gap ΦSDP-IP ´ΦSDP-FO has a mean of
0.10 (standard deviation 0.07), roughly 8ˆ smaller. Thus, SDP-FO presents a signiﬁcantly more
scalable approach, while sacriﬁcing little in precision for this network.

Remark. While small-scale problems can be solved exactly with second-order interior point methods,
these approaches have poor asymptotic scaling factors. In particular, both the SDP primal and dual
problems involve matrix variables with number of elements quadratic in the number of network
activations N . Solving for the KKT stationarity conditions (e.g. via computing the Cholesky
decomposition) then requires memory OpN 4q. At a high-level, SDP-FO uses a ﬁrst-order method
to save a quadratic factor, and saves another quadratic factor through use of iterative algorithms to
avoid materializing the M pλq matrix. SDP-FO achieves OpN kq memory usage, where k is the number
of Lanczos iterations, and in our experiments, we have found k ! N sufﬁces for Lanczos convergence.

20

OriginalPerturbedOriginalPerturbed(a) MNIST, MLP-Adv

Figure 4: Comparison to off-the-shelf solver. For 10 examples on MNIST, we plot the veriﬁed upper
bound on φx against the adversarial lower bound (using a single target label for each), comparing
SDP-FO to the optimal SDP bound found with SDP-IP (using MOSEK). In all cases, the SDP-FO
bound is very close to the SDP-IP bound, demonstrating that SDP-FO converges to a near-optimal dual
solution. Note that in many cases, the scatter points for SDP-FO and SDP-IP are directly overlapping
due to the small gap.

C.2

Investigation of relaxation tightness for MLP-Adv

Setup The discussion above in Appendix C.1 suggests that SDP-FO is a sufﬁciently reliable
optimizer so that the main remaining obstacle to tight veriﬁcation is tight relaxations. In our main
experiments, we use simple interval arithmetic [39, 23] for bound propagation, to match the relaxation
in [51]. However, by using CROWN [70] for bound propagation, we can achieve a tighter relaxation.

Results Using CROWN bounds in place of interval arithmetic bounds improves the overall veriﬁed
accuracy from 83.0% to 91.2%. This closes most of the gap to the PGD upper bound of 93.4%. For
this model, while the SDP relaxation still yields meaningful bounds when provided very loose initial
bounds, the SDP relaxation still beneﬁts signiﬁcantly from tighter initial bounds. More broadly, this
suggests that SDP-FO provides a reliable optimizer, which combines naturally with development of
tighter SDP relaxations.

C.3 Verifying Adversarial Robustness: Additional Results

Table 4 provides additional results on verifying adversarial robustness for different perturbation radii
and training modes. Here, we consider perturbations and training-modes not included in Table 1. We
ﬁnd that across settings, SDP-FO outperforms the LP-relaxation.

Dataset
MNIST

CIFAR-10

Epsilon Model
(cid:15) “ 0.3

(cid:15) “ 2
255

(cid:15) “ 8
255

CNN-A-Adv
CNN-A-Adv
CNN-A-Adv-4
CNN-A-Adv
CNN-A-Mix

Training
Epsilon
(cid:15)train “ 0.3
(cid:15)train “ 2.2
255
(cid:15)train “ 4.4
255
(cid:15)train “ 8.8
255
(cid:15)train “ 8.8
255

Accuracy

Veriﬁed Accuracy

Nominal
98.6%
68.7%
56.4%
46.9%
56.7%

PGD
80.0%
53.8%
49.4%
30.6%
26.4%

SDP-FO (Ours)
43.4%
39.6%
40.0%
18.0%
9.0%

LP
0.2%
5.8%
38.9%
3.8%
0.1%

Table 4: Comparison of veriﬁed accuracy across various networks and perturbation radii. All SDP-FO
numbers computed on the ﬁrst 100 test set examples, and numbers for LP on the ﬁrst 1000 test set
examples. The perturbations and training-modes considered here differ from those in Table 1. For all
networks, SDP-FO outperforms the LP-relaxation baseline.

C.4 Comparison between Lanczos and exact eigendecomposition

All ﬁnal numbers we report use the minimum eigenvalue from an exact eigendecomposition (we use
the eigh routine available in SciPy [62]). However, the exact decomposition is far too expensive to

21

−8−40φx(Adversariallowerbound)−8−40φx(Veriﬁedupperbound)y=x(lowerboundonveriﬁcationobjective)Veriﬁedboundsacross10examplesSDP-FOSDP-IPuse during optimization. On all networks we studied, Lanczos provides a reliable surrogate, while
using dramatically less computation. For example, for CNN-A-Mix, the average gap between the
exact and Lanczos dual bounds – the values of Equation (5) using the true λmin compared to the
Lanczos approximation of λmin) – is 0.14 with standard deviation 0.07. This gap is small compared
to the overall gap between the veriﬁed upper and adversarial lower bounds, which has mean 0.60 with
standard deviation 0.22. We observed similarly reliable Lanczos performance across models, for both
image classiﬁer and VAE models in Sections 6.1 and 6.2.

At the same time, Lanczos is dramatically faster than the exact eigendecomposition: roughly 0.1
seconds (using 200 Lanczos iterations) compared to 5 minutes. For the VAE model, this gap is
even larger: roughly 0.2 seconds compared to 2 hours. For even larger models, it may be infeasible
to compute the exact eigendecomposition even once. Although unnecessary in our current work,
high-conﬁdence approximation bounds for eigenvectors and associated eigenvalues from Lanczos
can be applied in such cases [31, 46].

22

