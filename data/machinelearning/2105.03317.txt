Toward Code Generation: A Survey and Lessons from
Semantic Parsing

Celine Lee
Intel Labs, University of Pennsylvania
celine.lee@intel.com

Justin Gottschlich
Intel Labs, University of Pennsylvania
justin.gottschlich@intel.com

Dan Roth
University of Pennsylvania
danroth@seas.upenn.edu

1
2
0
2

r
p
A
6
2

]
E
S
.
s
c
[

1
v
7
1
3
3
0
.
5
0
1
2
:
v
i
X
r
a

Abstract
With the growth of natural language processing techniques
and demand for improved software engineering efficiency,
there is an emerging interest in translating intention from
human languages to programming languages. In this survey
paper, we attempt to provide an overview of the growing
body of research in this space. We begin by reviewing natu-
ral language semantic parsing techniques and draw parallels
with program synthesis efforts. We then consider seman-
tic parsing works from an evolutionary perspective, with
specific analyses on neuro-symbolic methods, architecture,
and supervision. We then analyze advancements in frame-
works for semantic parsing for code generation. In closing,
we present what we believe are some of the emerging open
challenges in this domain.

1 Introduction
Machine programming (MP) is the field concerned with the
automation of all aspects of software development [28]. Ac-
cording to Gottschlich et al. [28], the field can be reasoned
about across three pillars: intention, invention, and adaptation
(Figure 1). Intention is concerned with capturing user intent,
whether by natural language, visual diagram, software code,
or other techniques. Invention explores ways to construct
higher-order programs through the composition of exist-
ing – or novel creation of – algorithms and data structures.
Adaptation focuses on transforming higher-order program
representations or legacy software programs to achieve cer-
tain characteristics (e.g., performance, security, correctness,
etc.) for the desired software and hardware ecosystem.

In this paper, we discuss (i) semantic parsing and (ii) code
generation, which chiefly fall within the boundaries of the
intention and invention pillars, respectively. In the context
of natural language (NL), semantic parsing is generally con-
cerned with converting NL utterances (i.e., the smallest unit
of speech) to structured logical forms. Once done, these logi-
cal forms can then be utilized to perform various tasks such
as question answering [41, 42, 47, 80, 86], machine transla-
tion [5, 81], or code generation [38, 49, 73, 87], amongst other
things. For semantic parsing for code generation, the end
logical form will usually be some form of software code. This
may be the direct output program [41, 49, 90, 94] or an inter-
mediate representation of code [21, 42, 68, 87, 88], which can
subsequently be fed into a program synthesis component to
generate syntactically sound and functionally correct code.

Figure 1. The Three Pillars of Machine Programming (credit:
Gottschlich et al. [28]).

In this survey paper, we first provide an overview of the
processes of NL semantic parsing and of code generation in
Sections 2 and 3, respectively. In Section 4, we summarize
the evolution of techniques in NL and code semantic parsing
from the 1970s onward. Section 5 explores the question of
supervision for semantic parsing tasks, while Section 6 dis-
cusses modern advances in neural semantic parsing for code
generation. To conclude, we consider some possible future
directions of semantic parsing for code generation.

2 Natural Language Semantic Parsing
Natural language analysis can be segmented into at least two
fundamental categories: syntax and semantics. In general,
syntax is the way a natural language phrase is structured;
the order and arrangement of words and punctuation. The se-
mantics is the meaning that can be derived from such syntax.
For example, the two sentences “the boy cannot go” and “it
is not possible for the boy to go”, are semantically equivalent
even though they are syntactically different. By lifting seman-
tics from syntax, NL semantic parsers can map semantically
equivalent sentences to the same logical form, even when
they have different syntaxes. An example of this is shown
in Figure 2, where two syntactically different sentences are
shown to be semantically equivalent using an abstract mean-
ing representation (AMR) as its logical form (more details
in Section 2.4). For the remainder of this section, we dis-
cuss how NL semantic parsers extract meaning from natural
language utterances into various machine-understandable
representations.

 
 
 
 
 
 
Figure 2. Abstract meaning representation (AMR) of two
semantically equivalent, but syntactically different sentences
(credit: Banarescu et al. [12]).

2.1 Purpose of Natural Language Semantic Parsing
The general purpose of structured logical forms for natural
language is to have a representation that enables natural
language understanding (NLU) and automated reasoning,
amongst other things. Historically, NL semantic parsers have
enabled computers to query databases [89], play card games
[27], and even act as conversational agents such as Apple’s
Siri and Amazon’s Alexa. Semantic parsing has taken on
many forms. Early hand-crafted rules made way for super-
vised learning techniques. Then, due to the labor-intensive
and error-prone process of hand-labeling data for paired nat-
ural language and logical form datasets, researchers turned
their attention toward weakly supervised [9, 20] and other
learning techniques that tend to require less labeled data.

2.2 Components of a Semantic Parsing System
Given an NL input, a NL semantic parsing system gener-
ates its semantic representation as a structured logical form.
These logical forms are also known as meaning represen-
tations or programs. To generate these outputs, semantic
parsing pipelines usually trained by some learning algorithm
to produce a distribution over the output search space and
then search for a best scoring logical form in that distribu-
tion. This logical form can then be executed against some
environment to carry out an intended task (e.g. to query a
database). Because these logical forms are generally designed
to be machine-understandable representations, they tend to
have a structured nature, following an underlying formalism
by which some grammar can be used to derive valid logical
forms. Insight into the grammar of a set of logical forms
can be leveraged by different semantic parsing methods to
improve performance. For example, semantic parsing for
code generation should have a meaning representation that
can deterministically be transformed into valid code. There-
fore, the output space can be constrained by the underlying
grammar formalisms that define syntactically sound code.

2.3 Grammars
Grammar in the context of natural language processing is
a set of rules that govern the formation of some structure
(parsing of NL utterances) to ensure well-formedness. A fa-
miliar example is English grammar: number, tense, gender
and other features must be consistent in an English sentence.

Figure 3. An example of a CCG category. Syntax (the ADJ
represents an adjective part of speech) is paired with seman-
tics (the lambda term expression) (credit: Artzi et al. [7]).

Figure 4. Sample SQL query for a flight reservation
(credit: Iyer et al. [37]).

The sentence “he eat apples” is grammatically incorrect be-
cause a single noun acts with a verb that must end in ‘s.’
Likewise, in semantic parsing, a logical form can be gram-
matically constrained to ensure well-formedness. A set of
grammatical rules constrains the search space of possible
outputs. Combinatory categorical grammar (CCG) [76, 77]
is one such example of a popular grammar formalism. It has
historically made frequent appearances in semantic parsing
models [45, 91, 92] due to its ability to jointly capture syn-
tactic and semantic information of the constituents which it
label. Consider the example in Figure 3. By pairing syntactic
and semantic information, CCGs can describe textual input
for a machine to understand the semantics with the syntax.

2.4 Meaning Representations
Meaning representations are the end product of NL semantic
parsing. The output logical formula, or meaning represen-
tation, grounds the semantics of the natural language input
in the target machine-understandable domain. A simple ex-
ample of logical forms is a database query. Popular datasets
explored in semantic parsing include Geo880, Jobs640, ATIS,
and SQL itself [20, 37, 89]. An example of a SQL query is
shown in Figure 4. Another class of semantic parsing outputs
is NL instructions to actions, such as the model in Figure 5 for
learning Freecell card game moves. Note that in these cases,
the semantic parser is specific to a particular domain, and
may not generalize to out-of-domain inquiries or differing
data structures.

NL semantic parsing efforts have also translated natural
language input semantics into lambda calculus expressions.
The expressive power of lambda calculus allows the incorpo-
ration of constants, logical connectors, quantifications, and
lambda expressions to represent functions [92].
what countries border France

Sentence:
Logical Form: 𝜆𝑥 .𝑐𝑜𝑢𝑛𝑡𝑟𝑦 (𝑥) ∧ 𝑏𝑜𝑟𝑑𝑒𝑟𝑠 (𝑥, 𝐹𝑟𝑎𝑛𝑐𝑒)

2

Figure 5. A natural language sentence (denoted x), a logical
formula corresponding to the sentence (denoted y), and a
lexical alignment between the two (denoted h) (credit: Gold-
wasser and Roth [27]).

Meaning representations can also take on graph-based
forms. Graph-based formalisms are advantageous because
they are easier for humans to read and they are abstracted
from the syntax of the input natural language sentences. Pop-
ular graphical representations are the Abstract Meaning Rep-
resentation [12], Semantic Dependency Parsing [17, 59], Uni-
versal Conceptual Cognitive Annotation [1], Dependency-
based Compositional Semantics [47], and CCGBank [34].

While most general purpose programming languages are
not necessarily abstract in their representations of intention
(source code often involves details about variables, memory
allocation, class structure, etc.), code can serve as one of the
more fundamental machine-understandable logical forms.
To lift semantics from the code’s syntax, recent works have
gone into developing and using meaning representations of
code, such as the abstract syntax tree (AST) [2–4, 67, 71, 72],
sketching [74], simplified parse tree (SPT) [51], contextual
flow graph (XFG) [13], context-aware semantic structure
(CASS) [85], and program-derived semantics graph (PSG)
[35]. While none of these representation structures are identi-
cal, they somewhat share the common goal of being a vehicle
of machine-understandable meaning of the code, abstracted
to some extent from the syntax of code. We discuss the ap-
plication of some of these structures in Section 3.

3 Program Synthesis / Code Generation
In this section, we review a subset of existing efforts for
program synthesis and code generation. Program synthe-
sis is the task of generating software from some high-level
program specification [54]. The purpose of this section is
to highlight parallels between this process of using a high-
level program specification to generate code, and semantic
parsing’s translation of natural language into meaning repre-
sentations. Insights from the fields of program synthesis and
machine programming can guide semantic parsing efforts,
and vice versa.

Code has many different dimensions. Despite what could
be construed as a strict syntax for compile-ability, source
code can be reasoned about on many different levels: se-
mantics, runtime, memory footprint, and compiler details, to
name a few. As a result, design and selection of a code rep-
resentation structure, and the subsequent reasoning about
said structure is an interesting and nuanced task.

3

Many code recommendation systems use code similarity
to retrieve different implementations of the same intention.
Semantic code representations can provide a foundation on
which to extract code similarity. Facebook et al.’s Aroma
system for code recommendation [51] represents a program
by a simplified parse tree (SPT): the parse tree is defined as
a recursive structure of keyword and non-keyword tokens,
agnostic to implementation programming language. Intel
et al.’s MISIM system for code similarity [85] defines the
context-aware semantic structure (CASS), which leverages
the structural advantages of the SPT, but also carries the
advantage of incorporating customizable parameters for a
wider variety of code context scenarios. The CASS enables
configuration at different levels of granularity, allowing it
to be more flexible for general, rather than domain-specific,
usage. Iyer et al. [35] present the program-derived semantics
graph (PSG) to capture semantics of code at multiple levels
of abstraction. Additionally, it offers one layer of concrete
syntactic abstraction that is programming language specific,
which allows it to be converted into source code.

Program synthesis has also come in the flavor of machine
translation [18, 67, 81], pseudocode-to-code transformation
[44], and inductive program synthesis by input-output exam-
ples [11, 31, 57]. While machine translation found its infancy
in translation between human languages, a series of works
has gone into translating from natural language to program-
ming languages. Wong and Mooney [81] integrate machine
translation techniques with semantic parsing to create a
syntax-based WASP: word alignment-based semantic pars-
ing. Quirk et al. [67] further combine machine translation
to extract ASTs consistent with a constructed grammar for
If-This-Then-That (IFTTT) recipes. Chen et al. [18] tackle
program translation by employing tree-to-tree deep neural
networks to migrate code from one language into an ecosys-
tem built in a different language. Kulal et al. [44] perform
the task of mapping line-to-line pseudocode to code for pro-
gram synthesis. Inductive program synthesis allows us to
produce a program consistent with a set of input-output
examples [11, 24, 30, 31, 48, 57, 63, 66]. In these approaches,
the program synthesis problem can be framed as the follow-
ing: first, encode input-output examples as constraints; then,
search over the space of possible programs with a constraint
solver. A key challenge in this technique is scalability. Pu
et al. [66] demonstrate that inductive program synthesis can
be made a scalable task by having a model iteratively se-
lect a small subset of representative examples, then train on
each small subset at a time. Another aspect to consider is
evaluation. A fitness function determines how well a given
candidate program satisfies some set of requirements. Given
these requirements as a set of input-output examples, such
as in inductive program synthesis, the fitness function can be
learned [53], resulting in more efficient program synthesis
because it is biased to search likely programs.

The task of program synthesis tends to be more tractable
if the output programming language is less complex and thus
the output space is more compact. Declarative programming
languages such as SQL [15], Halide [69], and GraphIT [93]
express the intention of a computation without detailing
its execution. For this reason, these types of languages are
also called intentional programming languages in the field
of machine programming. As a function of the syntax and
semantics being closely related, programs written in inten-
tional programming languages tend to be easier to reason
about in a semantic space. A byproduct of this phenomenon
is that intentional programming languages can also be eas-
ier to optimize. Neo [56] and Bao [55] are learned neural
models that optimize SQL queries. Verified lifting [40] also
demonstrates an ability to optimize Halide code.

As we discuss the evolution of semantic parsing in the next
few sections, we identify parallels between these techniques
used for program synthesis techniques and the techniques
used in semantic parsing.

4 Evolution of Semantic Parsing
This section will review the evolution of NL semantic parsing
techniques from early hand crafted rules in the 1970s to the
rise of learned grammars via statistical learning methods in
the late 1990s and early 2000s, to modern neural semantic
parsing efforts.

4.1 Rules-based Techniques for Semantic Parsing
Many early approaches to NL semantic parsing used hand-
crafted syntactic pattern and phrase matching to parse the
meaning from a given natural language input [39, 82]. These
rules were then augmented by grammars that incorporate
knowledge of semantic categories [33, 50, 80] so that similar
words can be generalized to sets of defined categories and
then constrain the output space of the logical forms. How-
ever, as a function of being based off of pattern-matching
rules, these systems are brittle, and as a function of relying
on defined semantic categories, these grammar-constrained
systems are domain-specific.

4.2 Grammar and Rule Induction for Semantic

Parsing

Statistical methods for the induction of NL semantic pars-
ing grammars rose in the late 1990s and early 2000s. Zelle
and Mooney [90] present a system that learns rules for lan-
guage parsing instead of relying on hand-crafting them. The
system employs inductive logic programming methods to
learn shift-reduce parsers that map sentences into database
queries. Kate et al. [41] also induce transformation rules that
map natural language to logical form. By learning and recur-
sively applying these rules, Kate et al.’s system maps natural
language inputs (or their corresponding syntactic parse trees)
to a parse tree in the target representation language.

Figure 6. Encoder-decoder model for mapping NL to logical
forms (Credit: Dong and Lapata [21]).

Other supervised learning approaches have induced gram-
mars to represent the underlying semantics of a knowledge
base. In the literature, CCGs have been a popular and power-
ful tool to capture textual semantics by mapping sentences to
their logical forms [8, 9, 91, 92]. Artzi and Zettlemoyer [10]
outline a CCG-based NL semantic parsing framework that
maps sentences to lambda-calculus representations of their
meaning. They induce a grammar and estimate the parame-
ters of the compositional and non-compositional semantics
of the space [7]. Artzi’s approach uses corpus-level statistics
at each lexicon update during learning to prune the induced
CCG lexicons. Performance improvements in this system
indicate an advantage to maintaining compact CCG lexicons.
However, these model are typically unable to learn entities
not presented to the model during training. [6, 91].

A challenge in semantic parsing has been how to scale a
semantic parsing model for different domains. Kwiatkowski
et al. [45] present a learned ontology matching model that
adapts the output logical form of the semantic parser for
each target domain. The parser uses a probabilistic CCG
to construct a domain-independent meaning representation
from the NL input, then uses the ontology matching model
to transform that representation into the target domain.

4.3 Neural Models for NL Semantic Parsing
The modern rise in neural models has been marked by the
increase in papers exploring encoder-decoder sequence-to-
sequence (seq2seq) frameworks for semantic parsing. These
encoders and decoders are often built with recurrent architec-
tures such as LSTM cells (see Figure 6) in an effort to better
capture the dynamic and sequential nature of both natu-
ral and programming languages. Neural models can enable
systems to automatically induce grammars, templates, and
features instead of relying on humans to manually annotate
them. This provides the model with flexibility to generalize
across languages and representations [42]. These encoder-
decoder models can bear a resemblance to machine transla-
tion systems [81] except that NL semantic parsing systems
produce a structured logical form, while machine transla-
tion systems traditionally translate a natural language input
into another unstructured natural language output [5]. The
formal output structure of semantic parsing enables neural

4

decoders to lean on the logic of the induced grammars, while
retaining the simplicity of neural translation without latent
syntactic variables[42, 68, 87]. Thus, this type of modeling
can generalize to different environments while reducing de-
mand for custom-annotated datasets. It should be noted,
however, that these neural models tend to have a weakened
ability to leverage the logical compositionality of traditional
rules-based approaches.

Dong and Lapata [21] present a NL semantic parsing
model that employs an attention-enhanced encoder-decoder.
In a nod to the hierarchical structure of their system’s logical
forms, they design a top-down tree decoder to more faithfully
decode well-formed meaning representations. Decoding of
each token is augmented by: (i) soft alignments from atten-
tion computed by the encoder and (ii) parent-feeding con-
nections to provide contextual information from prior time
steps. The resulting model has competitive performance and
increased flexibility without need for any human-engineered
features, making it more scalable to different domains. This
work marks the advent of growing attention to neural models
for semantic parsing.

A more in-depth discussion of modern techniques in neu-
ral semantic parsing models is presented in Section 6, where
we focus on semantic parsing models for code generation.

5 Supervision in Semantic Parsing
Parallel to the evolution of NL semantic parsing techniques
is the evolution of supervision for semantic parsing. Fully-
supervised learning customarily mandates a corpus of paired
natural language utterances and their corresponding logi-
cal forms. However, this can be expensive to generate and
difficult to scale.

Supervision by Denotation. Supervision by denotation
is proposed as an alternative, more scalable approach to
NL semantic parsing. Instead of directly evaluating the suc-
cess of a semantic parser by comparing the output to a gold
standard “correct” logical form as done in fully-supervised
learning, NL semantic parsing can be driven by the response
of the context or environment. Clarke et al. [19] present a
learning algorithm that relies only on a binary feedback sig-
nal for validation. The resulting parser is competitive with
fully supervised systems in the Geoquery domain, demon-
strating the feasibility of supervision by denotation. Liang
et al. [47] also elide the need for labeled logical forms by in-
ducing a NL semantic parsing model from question-answer
pairs. They introduce a new semantic representation, the
dependency-based compositional semantics (DCS) to represent
formal semantics as a tree. The model maps a NL utterance
to DCS trees, aligns predicates within each tree to the span
in the utterance that triggered it, and beam search for the
best candidates.

However, at least two primary challenges arise with super-
vision by denotation. (1) The space of potential denotations

may be large. This can increase computational tractability
challenges in the search problem for intermediate latent rep-
resentations. (2) A weaker response signal has the potential
for spurious logical forms: semantic parsing outputs that
happen to produce the correct response, but do not actually
carry the correct semantics. Modifications to supervision by
denotation have been proposed to address these challenges.
Goldwasser and Roth [27] present a method of learning from
natural language instructions and a binary feedback signal
to address these issues.By capturing alignments between NL
instruction textual fragments and meaning representation
logical fragments, the model can more closely interpret NL
instructions and hopefully reduce the potential for spurious
forms. Pasupat and Liang [62] propose a system that per-
forms dynamic programming on denotations to address the
issue of exploding latent search space and spurious results.
By observing that the space of possible denotations grows
more slowly than the space of logical forms, this dynamic
programming approach can find all consistent logical forms
up to some bounded size. Then, because spurious logical
forms will generally give a wrong answer once the context
changes, they generate a slightly modified context and exam-
ine whether the logical form produces the correct denotation
in this alternate context. If it does not, this spurious logical
form can be discarded. The combination of limited search
space and pruning of spurious forms allows them to use
denotation as a stronger supervision signal.

Weakly Supervised Learning. Artzi and Zettlemoyer [8]
use conversational feedback from un-annotated conversation
logs as a form of weak supervision to induce a NL semantic
parser. In this approach, Artzi and Zettlemoyer model the
meaning of user statements in the conversational log with
latent variables, and define loss as a rough measure of how
well a candidate meaning representation matches the expec-
tations about the conversation context and dialog domain.
Artzi and Zettlemoyer [9] demonstrate the viability of weak
supervision for mapping natural language instructions to
actions in the robotics domain. They run the output of a
parsing component through an execution component and
observe the result relative to a binary-feedback validation
function in the environment. 1

Self-supervised Learning. Poon and Domingos [65] present

a self-supervised system for NL semantic parsing by recur-
sively clustering semantically equivalent logical forms to ab-
stract away syntactical implementation details. This method,
however, does not ground the induced clusters in an ontology.
Poon [64] subsequently proposes a grounded unsupervised
learning approach that takes a set of natural language ques-
tions and a database, learns a probabilistic semantic grammar
over it, then constrains the search space using the database

1We discuss other emerging works of weak supervision, such as Snorkel [70],
in Section 7.

5

schema. For a given input sentence, this system annotates
the sentence’s dependency tree with latent semantic states
derived from the database. The dependency-based logical
form is additionally augmented with a state space to account
for semantic relationships not represented explicitly in the
dependency tree. This semantically-annotated tree can then
be deterministically converted into the logical form, without
ever needing pre-labeled data. Goldwasser et al. [26] suggest
a confidence-driven self-supervised protocol for NL seman-
tic parsing. The model compensates for the lack of training
data by employing a self-training protocol driven by confi-
dence estimation to iteratively re-train on high-confidence
predicted datapoints.

Open vocabulary NL semantic parsing replaces a formal
knowledge base with a probabilistic base learned from a text
corpus. In this framework, language is mapped onto queries
with predicates (parts of the structure that make claims about
the actions or characteristics of the subject) derived directly
from the domain text instead of provided through a grammar.
The model must also learn the execution models for these
induced predicates [43, 46]. Gardner and Krishnamurthy [25]
address the challenge of generalizing NL semantic parsing
models to out-of-domain and open-vocabulary applications.
Instead of mapping language to a single knowledge base
query like traditional NL semantic parsers, this approach
maps language to a weighted combination of queries plus a
distributional component to represent a much broader class
of concepts. This approach can expand the applicability of
semantic parsing techniques to more complex domains.

6 Modern Advances in Neural Semantic

Parsing for Code Generation

Recent semantic parsing efforts have largely centered around
neural models, especially encoder-decoder networks. In this
section, we discuss modern advances in neural models for
semantic parsing for code generation.

6.1 Context and Variable Copying
Information to generate a NL semantic parse is not always
encapsulated entirely in a single input sentence. Surrounding
context can provide valuable information for disambiguation
in NL semantic parsing [8]. Context can be fed into the
encoder to incorporate context to encoder-decoder models.
Iyer et al. [38] develop an architecture that leverages pro-
grammatic context to write contextually-relevant code. This
encoder-decoder system feeds the encoder the input utter-
ance along with featurized representations of environment
identifiers, such as type and name of each variable and
method. The decoding process attends first to the natural lan-
guage, then to the variables and methods of the environment.
Performing this attention in two steps can help the model
match words in the natural language to the environment
identifier representations. Additionally, a supervised copy

6

mechanism [29] based on attention weights is presented to
copy an environment token to the output. This allows the
model to copy in variable names not seen in the training
data or in the input utterance.

6.2 Grammar in Neural Semantic Parsing Models
Grammar also can guide and constrain the decoding pro-
cess of neural encoder-decoder models. Xiao et al. [83] pro-
pose a sequence-based approach to generate a knowledge
base query: they sequentialize the target logical forms, then
demonstrate the advantage of incorporating grammatical
constraints into the derivation sequence. Further, when query-
ing information from semi-structured tables, Krishnamurthy
et al. [42] demonstrate the benefits of enforcing type con-
straints during query generation. They show that including
explicit entity linking during encoding can bolster accuracy
because it ensures the generation of well-typed logical forms.
As discussed in Section 3, code is dynamic in its represen-
tation and semantics, making grammar especially interest-
ing for generating source code. Unlike prior works which
focus on domain-specific languages, which may have lim-
ited scope and complexity, Yin and Neubig [87] and Ling
et al. [49] present methods for generating high-level general-
purpose programming language code such as Python. Ling
et al. [49] present a data-driven sequence-to-sequence code
generation method that implements multiple predictors: a
generative model for code generation, and multiple pointer
models to copy keywords from the input. Building off of
Ling et al. [49], Yin and Neubig [87] point out that general
purpose languages are generally more complex in schema
and syntax than other domain-specific semantic parsing chal-
lenges. Therefore, code generation models could benefit from
a grammar that explicitly captures the target programming
language syntax as prior knowledge. Yin and Neubig [87] use
abstract syntax trees (ASTs) to constrain the search space by
exclusively allowing well-formed outputs: the model gener-
ates a series of actions that produce a valid AST. The actions
themselves are derived from the underlying syntax of the
programming language. This approach demonstrates im-
proved Python code generation, but Yin and Neubig point
out a decline in performance as the AST becomes more com-
plex, noting that there may be space for improvement in
scalability.

Code idioms are bits of code that occur frequently across a
code repository and tend to have a specific semantic purpose.
They can be used to enhance grammars in semantic parsing.
Iyer et al. [36] apply idiom-based decoding to reduce the
burden on training data in grammar-constrained semantic
parsing systems. The top-K most frequently seen idioms in
the training set are used to collapse the grammar for decod-
ing. This compact set of rules helps supervise the learning of
the semantic parser. However, there is a limit to how much
idioms help with performance. The paper notes that adding

too many idioms may cause the model to over-fit and be-
come less generalizable. Shin et al. [73] mine code idioms
with the objective of helping models reason about high-level
and low-level reasoning at the same time. The mined code
idioms are incorporated into the grammar as new named
operators, allowing the model to emit entire idioms at once.
Incorporating the code idioms into the vocabulary of the
neural synthesizer enables it to generate high-level and low-
level program constructs interchangeably at each step, which
is more like how human programmers write code.

6.3 Sketching
Solar-Lezama et al. [75] present the concept of sketching to
generate programs from a high-level description. Through
sketching, developers communicate insight through a partial
program, i.e. the sketch, that describes the high-level struc-
ture of an implementation. Then, synthesis procedures can
generate the full implementation of this sketch in program-
ming language.

Dong and Lapata [22] present a semantic parsing decoder
that operates at varying levels of abstraction for encoder-
decoder semantic parsing. By operating as a representation
of the basic meaning, the sketch can provide a basic idea of
the meaning of the utterance while abstracting away from
the syntactic details of the actual implementation. The de-
coder presented in this paper operates in two stages: (1)
generating a coarse sketch of the meaning representation
that omits low-level details, and (2) filling in those missing
details of arguments and variable names. This coarse-to-
fine decoding has the advantage of disentangling high and
low-level semantic information so that the program can be
modeled at different granularities. An attention-enhanced
RNN serves as the fine meaning decoder, using the coarse
sketch to constrain the decoding output. This approach does
not utilize syntax or grammatical information because the
sketch naturally constrains the output space.

Nye et al. [58] present a method to dynamically integrate
natural language instructions and examples to infer program
sketches. Previous systems have mostly used static, hand-
designed intermediate sketch grammars, which tend to be
rigid in how much a system relies on pattern recognition
vs. symbolic search. When given an easy or familiar task,
Nye et al. [58]’s neuro-symbolic synthesis system can rely
on learned pattern recognition to produce a more complete
output. When given a hard task, the system can produce
a less complete sketch and spend more time filling in that
sketch using search techniques. By learning how complete
to make the sketch for different applications, this model can
employ sketching in a more fitting and customized manner.

6.4 Conversational Semantic Parsing
A remaining challenge in neural semantic parsers is inter-
pretability. Dong et al. [23] outline a confidence modeling

7

framework that characterizes three uncertainties: model un-
certainty, data uncertainty, and input uncertainty. By com-
puting these confidence metrics for a given prediction and
using them as features in a regression model, they obtain a
confidence score which can be used to identify which part of
the input or model contributes to uncertain predictions. This
uncertainty modeling allows models to better understand
what it does and does not know. The ability to target weak
parts of a model leads us to conversational programming
approaches, where the model can query the user for missing
or uncertain information.

When performing NL semantic parsing to extract some
logical flow, conversational AI allows models to remedy in-
complete or invalid requests. By engaging in a back-and-
forth dialogue between the program and the human user,
gaps and errors in logical forms can be filled and remedied, re-
spectively. Additionally, clarifications can reduce the search
space to promise a more accurate output [8, 16, 52].

7 Future Directions
The task of connecting human communication with machine
data and capabilities, as in the intention pillar of machine
programming, has seen considerable headway over the past
few decades. Moving forward in semantic parsing, we iden-
tify four areas of consideration for the next steps of semantic
parsing for code generation:

Evaluation. Current methods of evaluation for seman-
tic parsing correctness use strict matches to gold standards,
denotation, hand-wavy heuristics, or some other imperfect
form of measuring understanding of semantic meaning. Ex-
act match evaluation may incorrectly penalize mismatching
logical forms that actually produce the same semantic mean-
ing. Supervision by denotation can incorrectly reward spuri-
ous logical forms. Hand-wavy heuristics such as Bleu score
[61], which evaluates the "quality" of machine translation
outputs via a modified n-gram precision metric, have been
shown to not reliably capture semantic equivalence for natu-
ral language [14] or for code [79]. Efforts to resolve the weak-
nesses of each of these evaluation methods [20, 27, 62, 64, 65]
have not been ineffective, but do not seem to fully address
the key issue, which is that an evaluator for semantic pars-
ing should have an understanding of semantic reasoning. We
propose that an important next step may be to research ei-
ther or both of: (i) an evaluator that can identify matching
core semantics of different logical forms, and (ii) a meaning
representation that has one unique representation for any
given semantic intention.

Evaluation of a model’s actual understanding could be
another open challenge in semantic parsing. Rules- and
grammar-based systems [10, 33, 39, 41, 50, 80, 90] are gen-
erally more transparent and thus more interpretable than
neural models because the rules on which they are built

can be examined as the logic of the model. However, neu-
ral models tend to function more as "black boxes," where
induced logic is mostly evaluated by examining the outputs.
We recommend research moving forward to consider how to
design this neural learning to better capture the complex na-
ture of both natural language and source code in translating
natural language into source code. Compositional general-
ization is one way to evaluate how well a model understands
natural language. Oren et al. [60] investigate compositional
generalization in semantic parsing. They find that while
well-known and novel extensions to the seq2seq model im-
prove generalization, performance on in-distribution data
is still significantly higher than on out-of-distribution data.
This suggests a need to make more drastic changes to the
neural encoder-decoder approach in order to inject funda-
mental "understanding." Neural Module Networks (NMNs)
can also provide interpretability, compositionality, and im-
proved generalizability to semantic parsers [32, 78]. Gupta
et al. [32] investigate how multiple task-specialized NMNs
can be composed together to perform complex reasoning
over unstructured knowledge such as natural language text.
However, the advanced interpretability of NMNs comes at
the cost of restricted expressivity because each NMN needs
to be individually defined. Gupta et al. [32] reflect that this
tradeoff suggests future further research to bridge these rea-
soning gaps.

Code Semantics Representation. We perceive that an
ongoing challenge in semantic reasoning about language
and code may be the lack of a unified code representation
that can capture semantics and details enough to resolve am-
biguity but remain agnostic of programming language. The
graph-based meaning representations discussed in Section
2.4 are promising avenues to explore. They have shown to be
effective in code retrieval, so we propose they be deployed
in a semantic parsing framework to evaluate their viability
for semantic parsing and code generation.

Big picture, developing this language-agnostic meaning
representation is a promising direction to facilitate a full
machine programming pipeline. If the meaning representa-
tion is transformable in all the directions between natural
language, meaning representation, and code, this unified in-
termediate representation enables a sort of "programming
by conversation." Not only could software be generated from
language, as discussed in this paper, it could also then be
translated from source code into natural language. Then
once in natural language form, intention could be iterated
upon via an interactive conversational agent. The iterated
representation could then be used to translate this refined
intention back into software.

Scope. Most current semantic parsing models reduce the
scope of the problem (and thus, often, output space) to make
the problem more feasible. This can be done either by work-
ing with DSLs, using a selected subset of APIs, or by working

8

only with code snippets of a limited length and complexity.
However, actual functional programs tend to be longer and
more complex than the code snippet outputs in current se-
mantic parsing models. Generation of programs in a GPL
[49] is generally a more complex task than in a DSL due to
the wide variety of domains and the high-dimensional code
reasoning space. Eventually, we want to be able to work dy-
namically with larger programs. Steps toward incorporating
context to and using conversational AI in neural semantic
parsing models have shown promising results, and should
continue to be pursued.

As the field moves into working with larger programs,
existing datasets that match natural language utterances
to code snippets will likely not be enough. To obtain more
data for neural deep learning, we recommend using data
generation models such as Snorkel [70]. Snorkel employs
weak supervision to create training data without any need
for hand-labeled data. We also suggest that new datasets
be developed that account for longer chunks of code. This
can be done by factoring in context variables and functions,
or by mining larger chunks of code with periodic natural
language annotations in the form of comments.

User Interfacing. Future work could also consider the
actual impact of code generation on programmer productiv-
ity. Xu et al. [84] conducted a study that found no impact on
code correctness or generation efficiency when the subjects
were asked to work in a programming environment IDE with
a code generation plug-in. This begs the question of how to
develop future models to be not just user-friendly, but user
aiding. Additionally, user interfaces for code generation may
not share the same vocabulary between trained program-
mers and non-technical developers. There may be room for
natural language understanding research advances for mod-
els to intuit programming concepts from plain English, free
of such jargon as “list,” “graph,” and “iterate.”

8 Broader Impact
The objective of this paper is to compile information and
synthesize ideas about the fields of semantic parsing for
natural language and for code. Since the basis of this paper is
primarily educational, we see its broader impacts to largely
be positive.

Semantic parsing for code generation will likely grant
more people a greater capacity to create programs. How-
ever, this enhanced capability also carries potential negative
impacts. One possible misuse is the creation of malicious
code. The models outlined in this paper could be trained to
learn to write computer viruses, identify security breaches
in other peoples’ networks, or any of a number of dangerous
behaviors. Aside from continuing to make this malicious
code illegal, it may be worthwhile to embed safety features
into the prior knowledge of these models, to discourage de-
structive code. On the flip side, models for code generation

could also in the worst case generate programs with egre-
giously poor performance. If deployed, these programs will
consume excessive computation and energy, thus negatively
impacting the environment. One way to mitigate this harm
is to encourage code reviews for generated code, just as code
reviews exist now for human-created code. Another poten-
tial misuse of this technology that we would be concerned
about is computer science students using this technology
to complete their programming assignments, rather than
learning how to write them themselves. This will be difficult
to discourage from the model development side, but devel-
opment and usage of a technology to identify coding style
could help instructors detect whether students are writing
their own code. Overall, researchers, as designers of these
semantic parsing systems, should consider the safety and
impact of their work on the many different realms of society.

References
[1] Omri Abend and Ari Rappoport. 2013. Universal Conceptual Cogni-
tive Annotation (UCCA). In Proceedings of the 51st Annual Meeting of
the Association for Computational Linguistics (Volume 1: Long Papers).
Association for Computational Linguistics, Sofia, Bulgaria, 228–238.
https://www.aclweb.org/anthology/P13-1023

[2] Miltiadis Allamanis, Marc Brockschmidt, and Mahmoud Khademi.
2018. Learning to Represent Programs with Graphs. In International
Conference on Learning Representations.

[3] Uri Alon, Omer Levy, and Eran Yahav. 2019. code2seq: Generating
Sequences from Structured Representations of Code. In International
Conference on Learning Representations.

[4] Uri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. 2019.
Code2vec: Learning Distributed Representations of Code. Proc. ACM
Program. Lang. 3, POPL, Article 40 (Jan. 2019), 29 pages.
https:
//doi.org/10.1145/3290353

[5] Jacob Andreas, Andreas Vlachos, and Stephen Clark. 2013. Semantic
Parsing as Machine Translation. In Proceedings of the 51st Annual Meet-
ing of the Association for Computational Linguistics (Volume 2: Short
Papers). Association for Computational Linguistics, Sofia, Bulgaria,
47–52. https://www.aclweb.org/anthology/P13-2009

[6] Yoav Artzi, Dipanjan Das, and Slav Petrov. 2014. Learning Compact
Lexicons for CCG Semantic Parsing. In Proceedings of the 2014 Confer-
ence on Empirical Methods in Natural Language Processing (EMNLP).
Association for Computational Linguistics, Doha, Qatar, 1273–1283.
https://doi.org/10.3115/v1/D14-1134

[7] Yoav Artzi, Nicholas Fitzgerald, and Luke Zettlemoyer. 2014. Semantic
Parsing with Combinatory Categorial Grammars. In Proceedings of the
2014 Conference on Empirical Methods in Natural Language Processing:
Tutorial Abstracts. Association for Computational Linguistics, Doha,
Qatar. https://www.aclweb.org/anthology/D14-2003

[8] Yoav Artzi and Luke Zettlemoyer. 2011. Bootstrapping Semantic
Parsers from Conversations. In Proceedings of the 2011 Conference
on Empirical Methods in Natural Language Processing. Association
for Computational Linguistics, Edinburgh, Scotland, UK., 421–432.
https://www.aclweb.org/anthology/D11-1039

[9] Yoav Artzi and Luke Zettlemoyer. 2013. Weakly Supervised Learning
of Semantic Parsers for Mapping Instructions to Actions. Transactions
of the Association for Computational Linguistics 1 (2013), 49–62. https:
//doi.org/10.1162/tacl_a_00209

[10] Yoav Artzi and Luke S. Zettlemoyer. 2015. Situated understanding and

learning of natural language. Ph.D. Dissertation.

[11] Matej Balog, Alexander L. Gaunt, Marc Brockschmidt, Sebastian
Nowozin, and Daniel Tarlow. 2017. DeepCoder: Learning to Write

9

Programs. In 5th International Conference on Learning Representations,
ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceed-
ings.

[12] Laura Banarescu, Claire Bonial, Shu Cai, Madalina Georgescu, Kira
Griffitt, Ulf Hermjakob, Kevin Knight, Philipp Koehn, Martha Palmer,
and Nathan Schneider. 2013. Abstract Meaning Representation for
Sembanking. In Proceedings of the 7th Linguistic Annotation Workshop
and Interoperability with Discourse. Association for Computational Lin-
guistics, Sofia, Bulgaria, 178–186. https://www.aclweb.org/anthology/
W13-2322

[13] Tal Ben-Nun, Alice Shoshana Jakobovits, and Torsten Hoefler. 2018.
Neural Code Comprehension: A Learnable Representation of Code
Semantics. In Proceedings of the 32nd International Conference on Neural
Information Processing Systems (Montréal, Canada) (NIPS’18). Curran
Associates Inc., Red Hook, NY, USA, 3589–3601.

[14] Chris Callison-Burch, Miles Osborne, and Philipp Koehn. 2006. Re-
evaluating the Role of Bleu in Machine Translation Research. In 11th
Conference of the European Chapter of the Association for Computational
Linguistics. Association for Computational Linguistics, Trento, Italy.
https://www.aclweb.org/anthology/E06-1032

[15] Donald D. Chamberlin and Raymond F. Boyce. 1974. SEQUEL: A
Structured English Query Language. In Proceedings of the 1974 ACM
SIGFIDET (Now SIGMOD) Workshop on Data Description, Access and
Control (Ann Arbor, Michigan) (SIGFIDET ’74). Association for Com-
puting Machinery, New York, NY, USA, 249–264. https://doi.org/10.
1145/800296.811515

[16] Shobhit Chaurasia and Raymond J. Mooney. 2017. Dialog for Language
to Code. In Proceedings of the Eighth International Joint Conference on
Natural Language Processing (Volume 2: Short Papers). Asian Federation
of Natural Language Processing, Taipei, Taiwan, 175–180.
https:
//www.aclweb.org/anthology/I17-2030

[17] Wanxiang Che, Yanqiu Shao, Ting Liu, and Yu Ding. 2016. SemEval-
2016 Task 9: Chinese Semantic Dependency Parsing. In Proceedings
of the 10th International Workshop on Semantic Evaluation (SemEval-
2016). Association for Computational Linguistics, San Diego, California,
1074–1080. https://doi.org/10.18653/v1/S16-1167

[18] Xinyun Chen, Chang Liu, and Dawn Song. 2018. Tree-to-Tree Neural
Networks for Program Translation. In Proceedings of the 32nd Inter-
national Conference on Neural Information Processing Systems (Mon-
tréal, Canada) (NIPS’18). Curran Associates Inc., Red Hook, NY, USA,
2552–2562.

[19] James Clarke, Dan Goldwasser, Ming-Wei Chang, and Dan Roth. 2010.
Driving Semantic Parsing from the World’s Response. In Proceedings of
the Fourteenth Conference on Computational Natural Language Learning.
Association for Computational Linguistics, Uppsala, Sweden, 18–27.
https://www.aclweb.org/anthology/W10-2903

[20] Pradeep Dasigi, Matt Gardner, Shikhar Murty, Luke Zettlemoyer, and
Eduard Hovy. 2019. Iterative Search for Weakly Supervised Semantic
Parsing. In Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Lan-
guage Technologies, Volume 1 (Long and Short Papers). Association
for Computational Linguistics, Minneapolis, Minnesota, 2669–2680.
https://doi.org/10.18653/v1/N19-1273

[21] Li Dong and Mirella Lapata. 2016. Language to Logical Form with
Neural Attention. In Proceedings of the 54th Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers).
Association for Computational Linguistics, Berlin, Germany, 33–43.
https://doi.org/10.18653/v1/P16-1004

[22] Li Dong and Mirella Lapata. 2018. Coarse-to-Fine Decoding for Neu-
ral Semantic Parsing. In Proceedings of the 56th Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers). Asso-
ciation for Computational Linguistics, Melbourne, Australia, 731–742.
https://doi.org/10.18653/v1/P18-1068

[23] Li Dong, Chris Quirk, and Mirella Lapata. 2018. Confidence Modeling
for Neural Semantic Parsing. In Proceedings of the 56th Annual Meeting
of the Association for Computational Linguistics (Volume 1: Long Papers).
Association for Computational Linguistics, Melbourne, Australia, 743–
753. https://doi.org/10.18653/v1/P18-1069

[24] John K. Feser, Swarat Chaudhuri, and Isil Dillig. 2015. Synthesizing
Data Structure Transformations from Input-Output Examples. SIG-
PLAN Not. 50, 6 (June 2015), 229–239. https://doi.org/10.1145/2813885.
2737977

[25] Matt Gardner and J. Krishnamurthy. 2017. Open-Vocabulary Semantic
Parsing with both Distributional Statistics and Formal Knowledge. In
AAAI.

[26] Dan Goldwasser, Roi Reichart, James Clarke, and Dan Roth. 2011. Con-
fidence Driven Unsupervised Semantic Parsing. In Proceedings of the
49th Annual Meeting of the Association for Computational Linguistics:
Human Language Technologies. Association for Computational Lin-
guistics, Portland, Oregon, USA, 1486–1495. https://www.aclweb.org/
anthology/P11-1149

[27] Dan Goldwasser and Dan Roth. 2014. Learning from natural in-
structions. Machine Learning 94, 2 (1 Feb. 2014), 205–232. https:
//doi.org/10.1007/s10994-013-5407-y

[28] Justin Gottschlich, Armando Solar-Lezama, Nesime Tatbul, Michael
Carbin, Martin Rinard, Regina Barzilay, Saman Amarasinghe, Joshua B
Tenenbaum, and Tim Mattson. 2018. The Three Pillars of Machine
Programming. arXiv:1803.07244 [cs.AI]

[29] Jiatao Gu, Zhengdong Lu, Hang Li, and Victor O.K. Li. 2016. Incorpo-
rating Copying Mechanism in Sequence-to-Sequence Learning. In Pro-
ceedings of the 54th Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers). Association for Computational Lin-
guistics, Berlin, Germany, 1631–1640. https://doi.org/10.18653/v1/P16-
1154

[30] Sumit Gulwani. 2011. Automating String Processing in Spreadsheets
Using Input-Output Examples. SIGPLAN Not. 46, 1 (Jan. 2011), 317–330.
https://doi.org/10.1145/1925844.1926423

[31] Sumit Gulwani and Prateek Jain. 2017. Programming by Examples: PL
Meets ML. In Programming Languages and Systems - 15th Asian Sym-
posium, APLAS 2017, Suzhou, China, November 27-29, 2017, Proceedings
(Lecture Notes in Computer Science, Vol. 10695), Bor-Yuh Evan Chang
(Ed.). Springer, 3–20. https://doi.org/10.1007/978-3-319-71237-6_1

[32] Nitish Gupta, Kevin Lin, Dan Roth, Sameer Singh, and Matt Gardner.
2020. Neural Module Networks for Reasoning over Text. In Interna-
tional Conference on Learning Representations.

[33] Gary G. Hendrix, Earl D. Sacerdoti, Daniel Sagalowicz, and Jonathan
Slocum. 1978. Developing a Natural Language Interface to Complex
Data. ACM Trans. Database Syst. 3, 2 (June 1978), 105–147. https:
//doi.org/10.1145/320251.320253

[34] Julia Hockenmaier and Mark Steedman. 2007. CCGbank: A Corpus
of CCG Derivations and Dependency Structures Extracted from the
Penn Treebank. Computational Linguistics 33, 3 (2007), 355–396. https:
//doi.org/10.1162/coli.2007.33.3.355

[35] Roshni G. Iyer, Yizhou Sun, Wei Wang, and Justin Gottschlich. 2020.
Software Language Comprehension using a Program-Derived Seman-
tics Graph. arXiv:2004.00768 [cs.AI]

[36] Srinivasan Iyer, Alvin Cheung, and Luke Zettlemoyer. 2019. Learn-
ing Programmatic Idioms for Scalable Semantic Parsing. In Proceed-
ings of the 2019 Conference on Empirical Methods in Natural Lan-
guage Processing and the 9th International Joint Conference on Nat-
ural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China,
November 3-7, 2019, Kentaro Inui, Jing Jiang, Vincent Ng, and Xiao-
jun Wan (Eds.). Association for Computational Linguistics, 5425–5434.
https://doi.org/10.18653/v1/D19-1545

[37] Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, Jayant Krishnamurthy,
and Luke Zettlemoyer. 2017. Learning a Neural Semantic Parser from

User Feedback. In Proceedings of the 55th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1: Long Papers). Asso-
ciation for Computational Linguistics, Vancouver, Canada, 963–973.
https://doi.org/10.18653/v1/P17-1089

[38] Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer.
2018. Mapping Language to Code in Programmatic Context. In Proceed-
ings of the 2018 Conference on Empirical Methods in Natural Language
Processing. Association for Computational Linguistics, Brussels, Bel-
gium, 1643–1652. https://doi.org/10.18653/v1/D18-1192

[39] Tim Johnson. 1984. Natural Language Computing: The Commercial
Applications. The Knowledge Engineering Review 1, 3 (1984), 11–23.
https://doi.org/10.1017/S0269888900000588

[40] Shoaib Kamil, Alvin Cheung, Shachar Itzhaky, and Armando Solar-
Lezama. 2016. Verified Lifting of Stencil Computations. SIGPLAN Not.
51, 6 (June 2016), 711–726. https://doi.org/10.1145/2980983.2908117
[41] Rohit J. Kate, Yuk Wah Wong, and Raymond J. Mooney. 2005. Learning
to Transform Natural to Formal Languages. In Proceedings of the 20th
National Conference on Artificial Intelligence - Volume 3 (Pittsburgh,
Pennsylvania) (AAAI’05). AAAI Press, 1062–1068.

[42] Jayant Krishnamurthy, Pradeep Dasigi, and Matt Gardner. 2017. Neural
Semantic Parsing with Type Constraints for Semi-Structured Tables. In
Proceedings of the 2017 Conference on Empirical Methods in Natural Lan-
guage Processing. Association for Computational Linguistics, Copen-
hagen, Denmark, 1516–1526. https://doi.org/10.18653/v1/D17-1160

[43] Jayant Krishnamurthy and Tom M. Mitchell. 2015. Learning a Compo-
sitional Semantics for Freebase with an Open Predicate Vocabulary.
Transactions of the Association for Computational Linguistics 3 (2015),
257–270. https://doi.org/10.1162/tacl_a_00137

[44] S. Kulal, Panupong Pasupat, K. Chandra, Mina Lee, Oded Padon, A.
Aiken, and Percy Liang. 2019. SPoC: Search-based Pseudocode to Code.
In NeurIPS.

[45] Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and Luke Zettlemoyer.
2013. Scaling Semantic Parsers with On-the-Fly Ontology Matching.
In Proceedings of the 2013 Conference on Empirical Methods in Natural
Language Processing. Association for Computational Linguistics, Seat-
tle, Washington, USA, 1545–1556. https://www.aclweb.org/anthology/
D13-1161

[46] Mike Lewis and Mark Steedman. 2013. Combined Distributional and
Logical Semantics. Transactions of the Association for Computational
Linguistics 1 (2013), 179–192. https://doi.org/10.1162/tacl_a_00219

[47] Percy Liang, Michael Jordan, and Dan Klein. 2011.

Learning
Dependency-Based Compositional Semantics. In Proceedings of the
49th Annual Meeting of the Association for Computational Linguistics:
Human Language Technologies. Association for Computational Lin-
guistics, Portland, Oregon, USA, 590–599. https://www.aclweb.org/
anthology/P11-1060

[48] H. Lieberman. 2001. Your wish is my command: Programming by

example. (01 2001).

[49] Wang Ling, Phil Blunsom, Edward Grefenstette, Karl Moritz Hermann,
Tomáš Kočiský, Fumin Wang, and Andrew Senior. 2016. Latent Predic-
tor Networks for Code Generation. In Proceedings of the 54th Annual
Meeting of the Association for Computational Linguistics (Volume 1: Long
Papers). Association for Computational Linguistics, Berlin, Germany,
599–609. https://doi.org/10.18653/v1/P16-1057

[50] Peter C. Lockemann and Frederick B. Thompson. 1969. A Rapidly Ex-
tensible Language System (The REL Language Processor). In Interna-
tional Conference on Computational Linguistics COLING 1969: Preprint
No. 34. Sånga Säby, Sweden. https://www.aclweb.org/anthology/C69-
3401

[51] Sifei Luan, Di Yang, Celeste Barnaby, Koushik Sen, and Satish Chandra.
2019. Aroma: Code Recommendation via Structural Code Search. Proc.
ACM Program. Lang. 3, OOPSLA, Article 152 (Oct. 2019), 28 pages.
https://doi.org/10.1145/3360578

10

[52] Semantic Machines, Jacob Andreas, John Bufe, David Burkett, Charles
Chen, Josh Clausman, Jean Crawford, Kate Crim, Jordan DeLoach,
Leah Dorner, Jason Eisner, Hao Fang, Alan Guo, David Hall, Kristin
Hayes, Kellie Hill, Diana Ho, Wendy Iwaszuk, Smriti Jha, Dan
Klein, Jayant Krishnamurthy, Theo Lanman, Percy Liang, Christo-
pher H Lin, Ilya Lintsbakh, Andy McGovern, Aleksandr Nisnevich,
Adam Pauls, Dmitrij Petters, Brent Read, Dan Roth, Subhro Roy,
Jesse Rusak, Beth Short, Div Slomin, Ben Snyder, Stephon Striplin,
Yu Su, Zachary Tellman, Sam Thomson, Andrei Vorobev, Izabela
Witoszko, Jason Wolfe, Abby Wray, Yuchen Zhang, and Alexander
Zotov. 2020. Task-Oriented Dialogue as Dataflow Synthesis. Trans-
actions of the Association for Computational Linguistics 8 (September
2020). https://www.microsoft.com/en-us/research/publication/task-
oriented-dialogue-as-dataflow-synthesis/

[53] Shantanu Mandal, T. Anderson, Javier Turek, Justin Emile Gottschlich,
Sheng-Tian Zhou, and A. Muzahid. 2020. Learning Fitness Functions
for Machine Programming. arXiv: Neural and Evolutionary Computing
(2020).

[54] Zohar Manna and Richard Waldinger. 1980. A Deductive Approach to
Program Synthesis. ACM Trans. Program. Lang. Syst. 2, 1 (Jan. 1980),
90–121. https://doi.org/10.1145/357084.357090

[55] Ryan Marcus, Parimarjan Negi, Hongzi Mao, Nesime Tatbul, Moham-
mad Alizadeh, and Tim Kraska. 2020. Bao: Learning to Steer Query
Optimizers. arXiv:2004.03814 [cs.DB]

[56] Ryan Marcus, Parimarjan Negi, Hongzi Mao, Chi Zhang, Mohammad
Alizadeh, Tim Kraska, Olga Papaemmanouil, and Nesime Tatbul. 2019.
Neo: A Learned Query Optimizer. Proc. VLDB Endow. 12, 11 (July 2019),
1705–1718. https://doi.org/10.14778/3342263.3342644

[57] Aditya Menon, Omer Tamuz, Sumit Gulwani, Butler Lampson, and
Adam Kalai. 2013. A Machine Learning Framework for Programming
by Example. In Proceedings of the 30th International Conference on
Machine Learning (Proceedings of Machine Learning Research, Vol. 28),
Sanjoy Dasgupta and David McAllester (Eds.). PMLR, Atlanta, Georgia,
USA, 187–195. http://proceedings.mlr.press/v28/menon13.html
[58] Maxwell Nye, Luke Hewitt, Joshua Tenenbaum, and Armando Solar-
Lezama. 2019. Learning to Infer Program Sketches. , 4861–4870 pages.
http://proceedings.mlr.press/v97/nye19a.html

[59] Stephan Oepen, Marco Kuhlmann, Yusuke Miyao, Daniel Zeman, Dan
Flickinger, Jan Hajič, Angelina Ivanova, and Yi Zhang. 2014. SemEval
2014 Task 8: Broad-Coverage Semantic Dependency Parsing. In Pro-
ceedings of the 8th International Workshop on Semantic Evaluation
(SemEval 2014). Association for Computational Linguistics, Dublin,
Ireland, 63–72. https://doi.org/10.3115/v1/S14-2008

[60] Inbar Oren, Jonathan Herzig, Nitish Gupta, Matt Gardner, and Jonathan
Berant. 2020. Improving Compositional Generalization in Semantic
Parsing. In Findings of the Association for Computational Linguistics:
EMNLP 2020. Association for Computational Linguistics, Online, 2482–
2495. https://doi.org/10.18653/v1/2020.findings-emnlp.225

[61] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.
Bleu: a Method for Automatic Evaluation of Machine Translation. In
Proceedings of the 40th Annual Meeting of the Association for Computa-
tional Linguistics. Association for Computational Linguistics, Philadel-
phia, Pennsylvania, USA, 311–318. https://doi.org/10.3115/1073083.
1073135

[62] Panupong Pasupat and Percy Liang. 2016. Inferring Logical Forms
From Denotations. In Proceedings of the 54th Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers).
Association for Computational Linguistics, Berlin, Germany, 23–32.
https://doi.org/10.18653/v1/P16-1003

[63] Daniel Perelman, Sumit Gulwani, Dan Grossman, and Peter Provost.
2014. Test-Driven Synthesis. SIGPLAN Not. 49, 6 (June 2014), 408–418.
https://doi.org/10.1145/2666356.2594297

[64] Hoifung Poon. 2013. Grounded Unsupervised Semantic Parsing. In Pro-
ceedings of the 51st Annual Meeting of the Association for Computational

11

Linguistics (Volume 1: Long Papers). Association for Computational Lin-
guistics, Sofia, Bulgaria, 933–943. https://www.aclweb.org/anthology/
P13-1092

[65] Hoifung Poon and Pedro Domingos. 2009. Unsupervised Semantic
Parsing. In Proceedings of the 2009 Conference on Empirical Methods in
Natural Language Processing: Volume 1 - Volume 1 (Singapore) (EMNLP
’09). Association for Computational Linguistics, USA, 1–10.

[66] Yewen Pu, Zachery Miranda, Armando Solar-Lezama, and Leslie Kael-
bling. 2018. Selecting Representative Examples for Program Syn-
thesis. In Proceedings of the 35th International Conference on Ma-
chine Learning (Proceedings of Machine Learning Research, Vol. 80),
Jennifer Dy and Andreas Krause (Eds.). PMLR, 4161–4170.
http:
//proceedings.mlr.press/v80/pu18b.html

[67] Chris Quirk, Raymond Mooney, and Michel Galley. 2015.

Lan-
guage to Code: Learning Semantic Parsers for If-This-Then-That
Recipes. In Proceedings of the 53rd Annual Meeting of the Associ-
ation for Computational Linguistics and the 7th International Joint
Conference on Natural Language Processing (Volume 1: Long Papers).
Association for Computational Linguistics, Beijing, China, 878–888.
https://doi.org/10.3115/v1/P15-1085

[68] Maxim Rabinovich, Mitchell Stern, and Dan Klein. 2017. Abstract
Syntax Networks for Code Generation and Semantic Parsing. In Pro-
ceedings of the 55th Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers). Association for Computational
Linguistics, Vancouver, Canada, 1139–1149. https://doi.org/10.18653/
v1/P17-1105

[69] Jonathan Ragan-Kelley, Connelly Barnes, Andrew Adams, Sylvain
Paris, Frédo Durand, and Saman Amarasinghe. 2013. Halide: A Lan-
guage and Compiler for Optimizing Parallelism, Locality, and Recom-
putation in Image Processing Pipelines. SIGPLAN Not. 48, 6 (June
2013), 519–530. https://doi.org/10.1145/2499370.2462176

[70] Alexander J. Ratner, Stephen H. Bach, Henry R. Ehrenberg, Jason Alan
Fries, Sen Wu, and C. Ré. 2019. Snorkel: rapid training data creation
with weak supervision. The Vldb Journal 29 (2019), 709 – 730.
[71] Veselin Raychev, Pavol Bielik, and Martin Vechev. 2016. Probabilistic
Model for Code with Decision Trees. In Proceedings of the 2016 ACM
SIGPLAN International Conference on Object-Oriented Programming,
Systems, Languages, and Applications (Amsterdam, Netherlands) (OOP-
SLA 2016). Association for Computing Machinery, New York, NY, USA,
731–747. https://doi.org/10.1145/2983990.2984041

[72] Veselin Raychev, Martin Vechev, and Andreas Krause. 2015. Predicting
Program Properties from "Big Code". In Proceedings of the 42nd An-
nual ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages (Mumbai, India) (POPL ’15). Association for Computing
Machinery, New York, NY, USA, 111–124. https://doi.org/10.1145/
2676726.2677009

[73] Eui Chul Richard Shin, Miltiadis Allamanis, Marc Brockschmidt,
and Alex Polozov. 2019. Program Synthesis and Semantic Pars-
ing with Learned Code Idioms. In Advances in Neural Informa-
tion Processing Systems 32: Annual Conference on Neural Informa-
tion Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Van-
couver, BC, Canada, Hanna M. Wallach, Hugo Larochelle, Alina
Beygelzimer, Florence d’Alché-Buc, Emily B. Fox, and Roman Gar-
nett (Eds.). 10824–10834. https://proceedings.neurips.cc/paper/2019/
hash/cff34ad343b069ea6920464ad17d4bcf-Abstract.html

[74] Armando Solar-Lezama. 2008. Program Synthesis by Sketching. Ph.D.

Dissertation. USA. Advisor(s) Bodik, Rastislav.

[75] Armando Solar-Lezama, Liviu Tancau, Rastislav Bodik, Sanjit Seshia,
and Vijay Saraswat. 2006. Combinatorial Sketching for Finite Programs.
SIGARCH Comput. Archit. News 34, 5 (Oct. 2006), 404–415. https:
//doi.org/10.1145/1168919.1168907

[76] Mark Steedman. 1987. Combinatory grammars and parasitic gaps.

Natural Language & Linguistic Theory 5 (1987), 403–439.

Republic, 678–687. https://www.aclweb.org/anthology/D07-1071
[92] Luke S. Zettlemoyer and Michael Collins. 2005. Learning to Map
Sentences to Logical Form: Structured Classification with Probabilistic
Categorial Grammars. In Proceedings of the Twenty-First Conference
on Uncertainty in Artificial Intelligence (Edinburgh, Scotland) (UAI’05).
AUAI Press, Arlington, Virginia, USA, 658–666.

[93] Yunming Zhang, Mengjiao Yang, Riyadh Baghdadi, Shoaib Kamil,
Julian Shun, and Saman Amarasinghe. 2018. GraphIt: A High-
Performance Graph DSL. Proc. ACM Program. Lang. 2, OOPSLA, Article
121 (Oct. 2018), 30 pages. https://doi.org/10.1145/3276491

[94] Victor Zhong, Caiming Xiong, and Richard Socher. 2017. Seq2SQL:
Generating Structured Queries From Natural Language Using Rein-
forcement Learning. arXiv:1709.00103 [cs.CL]

[77] Mark Steedman and Jason Baldridge. 2007. Combinatory Categorical

Grammar.

[78] Sanjay Subramanian, Ben Bogin, Nitish Gupta, Tomer Wolfson, Sameer
Singh, Jonathan Berant, and Matt Gardner. 2020. Obtaining Faithful
Interpretations from Compositional Neural Networks. In ACL.
[79] Ngoc Tran, Hieu Tran, Son Nguyen, Hoan Nguyen, and Tien Nguyen.
2019. Does BLEU Score Work for Code Migration? 2019 IEEE/ACM
27th International Conference on Program Comprehension (ICPC) (May
2019). https://doi.org/10.1109/icpc.2019.00034

[80] David L. Waltz. 1978. An English Language Question Answering
System for a Large Relational Database. Commun. ACM 21, 7 (July
1978), 526–539. https://doi.org/10.1145/359545.359550

[81] Yuk Wah Wong and Raymond Mooney. 2006. Learning for Semantic
Parsing with Statistical Machine Translation. In Proceedings of the
Human Language Technology Conference of the NAACL, Main Confer-
ence. Association for Computational Linguistics, New York City, USA,
439–446. https://www.aclweb.org/anthology/N06-1056

[82] W. A. Woods. 1973. Progress in Natural Language Understanding:
An Application to Lunar Geology. In Proceedings of the June 4-8, 1973,
National Computer Conference and Exposition (New York, New York)
(AFIPS ’73). Association for Computing Machinery, New York, NY,
USA, 441–450. https://doi.org/10.1145/1499586.1499695

[83] Chunyang Xiao, Marc Dymetman, and Claire Gardent. 2016. Sequence-
based Structured Prediction for Semantic Parsing. In Proceedings of the
54th Annual Meeting of the Association for Computational Linguistics
(Volume 1: Long Papers). Association for Computational Linguistics,
Berlin, Germany, 1341–1350. https://doi.org/10.18653/v1/P16-1127

[84] Frank F. Xu, Bogdan Vasilescu, and Graham Neubig. 2021.

In-IDE
Code Generation from Natural Language: Promise and Challenges.
arXiv:2101.11149 [cs.SE]

[85] Fangke Ye, Shengtian Zhou, Anand Venkat, Ryan Marcus, Nes-
ime Tatbul, Jesmin Jahan Tithi, Niranjan Hasabnis, Paul Petersen,
Timothy Mattson, Tim Kraska, Pradeep Dubey, Vivek Sarkar, and
Justin Gottschlich. 2020. MISIM: A Novel Code Similarity System.
arXiv:2006.05265 [cs.LG]

[86] Wen-tau Yih, Xiaodong He, and Christopher Meek. 2014. Semantic
Parsing for Single-Relation Question Answering. In Proceedings of the
52nd Annual Meeting of the Association for Computational Linguistics
(Volume 2: Short Papers). Association for Computational Linguistics,
Baltimore, Maryland, 643–648. https://doi.org/10.3115/v1/P14-2105
[87] Pengcheng Yin and Graham Neubig. 2017. A Syntactic Neural Model
for General-Purpose Code Generation. In Proceedings of the 55th An-
nual Meeting of the Association for Computational Linguistics (Volume
1: Long Papers). Association for Computational Linguistics, Vancouver,
Canada, 440–450. https://doi.org/10.18653/v1/P17-1041

[88] Pengcheng Yin and Graham Neubig. 2018. TRANX: A Transition-
based Neural Abstract Syntax Parser for Semantic Parsing and Code
Generation. In EMNLP.

[89] Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan
Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, Zilin Zhang, and
Dragomir Radev. 2018. Spider: A Large-Scale Human-Labeled Dataset
for Complex and Cross-Domain Semantic Parsing and Text-to-SQL
Task. In Proceedings of the 2018 Conference on Empirical Methods in Nat-
ural Language Processing. Association for Computational Linguistics,
Brussels, Belgium, 3911–3921. https://doi.org/10.18653/v1/D18-1425
[90] John M. Zelle and Raymond J. Mooney. 1996. Learning to Parse Data-
base Queries Using Inductive Logic Programming. In Proceedings of
the Thirteenth National Conference on Artificial Intelligence - Volume 2
(Portland, Oregon) (AAAI’96). AAAI Press, 1050–1055.

[91] Luke Zettlemoyer and Michael Collins. 2007. Online Learning of
Relaxed CCG Grammars for Parsing to Logical Form. In Proceedings of
the 2007 Joint Conference on Empirical Methods in Natural Language
Processing and Computational Natural Language Learning (EMNLP-
CoNLL). Association for Computational Linguistics, Prague, Czech

12

