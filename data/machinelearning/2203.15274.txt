Published at the ICLR 2022 workshop on Objects, Structure and Causality

FINDING STRUCTURE AND CAUSALITY
IN LINEAR PROGRAMS

Matej Zeˇcevi´c1,†
1Computer Science Department, TU Darmstadt, 2Centre for Cognitive Science, TU Darmstadt,
3Hessian Center for AI (hessian.AI), †correspondence: matej.zecevic@tu-darmstadt.de

Florian Peter Busch1 Devendra Singh Dhami1, 3 Kristian Kersting1,2,3

ABSTRACT

Linear Programs (LP) are celebrated widely, particularly so in machine learning
where they have allowed for effectively solving probabilistic inference tasks or
imposing structure on end-to-end learning systems. Their potential might seem
depleted but we propose a foundational, causal perspective that reveals intriguing
intra- and inter-structure relations for LP components. We conduct a systematic,
empirical investigation on general-, shortest path- and energy system LPs.

1 OPTIMIZATION PROBLEMS, THEIR STRUCTURE AND CAUSALITY

Linear Programs (LP) stand as the entry ticket to the literature around mathematical optimization.
Their simplicity is characterized by linear cost and constraint vectors that provide the problem of
study with an inherent structure. Both, the LPs simplicity and its structure have leveraged its suc-
cess across many applications—also in machine learning. While classical examples involve the diet
problem (Dantzig, 1990), the assignment problem (Kuhn, 1955), or the shortest path (SP) problem
(Bellman, 1958), more modern applications of LPs involve probabilistic reasoning as in MAP infer-
ence (Weiss et al., 2007). The classical problems are special instances of LPs that assume a certain
structure within their constraints A and decision variable x. For instance in SP the decision x con-
sists of indicators to path segments (i, j) to be chosen for the ﬁnal path a → . . . i → j → . . . b
while A will dictate what constitutes a “legal” path. As another example, in the highly non-trivial
MAP inference case we will act on a polytope of rather abstract objects while inducing no special
structure on the problem itself. While MAP inference is a concrete example of an important machine
learning (ML) task that we might be interested in and lends itself to an LP description, the recent
times have shown an increased interest by the ML community in general for combinatorial prob-
lems. In research around adversarial examples, LPs and its integral variants were used to evaluate
robustness of trained classiﬁer in a defensive (Tjeng et al., 2019) and active setting (Wu et al., 2020).
In research around end-to-end learning systems, LPs have been made differentiable through the use
of perturbations in the Gumbel-Max sense (Berthet et al., 2020). More recently, both adversarials
and the differentiable LPs were combined to deﬁne a new notion of adversarial attack which directly
applies to LPs (and not arbitrary classiﬁers) by bridging the gap to Pearlian causality and its hidden
confounders (Zeˇcevi´c et al., 2021). Furthermore, a magnitude of efforts has been concerned with
allowing learned agents to incorporate structured knowledge, in the constraint-sense that LPs but
more general cone programs (like quadratic or semi-deﬁnite programs), to leverage performance on
downstream tasks (Agrawal et al., 2019; Mandi & Guns, 2020; Paulus et al., 2021).

While it might seem that research around LPs has depleted all which LPs could possibly offer,
we believe to show in this work that there is a side to LPs that has remained hidden and is yet to
be discovered. We have seen that LPs provide an inherent structure through their constraints but
also through the way the semantics of the variables is decided (e.g. the meaning of the decision
variable x). But what about the intra- and inter-structure of the LP, that is, the relations between
say different (xi, xj) or even between (xk, Al,:)? Can we identify a notion of causality within
LPs using the formal, counterfactual theory provided by (Pearl, 2009)? While pure curiosity and
the success of LPs on a wide variety of seemingly different tasks (involving ML) might not allow
for a proper justiﬁcation of the aforementioned research questions, an intuition lies in the inherent
structure provided by LPs in that their constraints commonly carry meaning just as the variables of
interest do—they are governed by certain rules, which one might equate to structural equations in
a Structural Causal Model (SCM). An important case in support of this anticipation is omnipresent
in research around sustainable energy modelling. Energy systems researcher might model certain

1

2
2
0
2

r
a

M
9
2

]
I

A
.
s
c
[

1
v
4
7
2
5
1
.
3
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
Published at the ICLR 2022 workshop on Objects, Structure and Causality

Figure 1: Causal Perspective onto LPs. Left, a causal graph for the constraints φφφ, the cost c, the
decision x and the optimal solution s. The “structural equation” s = f (x; φφφ, c) is well-known as the
solver. But what about intra- and inter-structure (green)? Right, shows such sub-structures where
classical discovery involves x only and LP-related causality φφφ or (φφφ, s). (Best viewed in color.)

physical laws like the law of conservation of energy with constraints in an LP where the decisions xi
will now involve the capacity of the photo-voltaic system or the market bought electricity for a single
household, and then the question arises on how these xi are causally related to each other but also
to the laws and constraints that govern them (Schaber et al., 2012). While this example corroborates
our previous justiﬁcation, the example itself does not come to a surprise since causality (as a concept
not just a speciﬁc formal notion) stands at the core of human cognition and transitively at the core
of science, engineering, business, and law (Penn & Povinelli, 2007). Developmental psychology
has shown children to act in the “manner of a scientist” (Gopnik, 2012), while artiﬁcial intelligence
research dreams of automating said manner (McCarthy & Hayes, 1981). Recent strides in cognitive
science have pursued a computational model of the broad term causality (Gerstenberg et al., 2021),
whereas Pearlian causality speciﬁcally has pressured forward into ML research (Bareinboim et al.,
2020). Various works in ML take inspiration from the latter approach leveraging causal notions and
invariances to drive performance (Lopez-Paz et al., 2017; Kipf et al., 2018).

2 BEYOND CLASSICAL CAUSAL DISCOVERY

Since its core formalization, Pearlian causality has seen many iterations (Pearl, 2009; Peters et al.,
2017; Bongers et al., 2021) and so have methods for identifying the causal structure given data (for
an overview see Eberhardt (2017)). Typically, for an SCM M := (cid:104)U, V, F, P (U)(cid:105) with exogenous
“nature” terms U, its joint distribution P (U), the endogenous nodes of interest V and structural
equations of the form vi ← fi(pai, ui) ∈ F, we are classically interested in relations on V and
sometimes also with regards to relations arising from U that might include hidden confounder as
in non-Markovian SCM. As we motivated in the previous section, if we know that our data stems
from an LP, then we can further partition V into sub-categories such as decision or input variable
x, parameter variables like the constraints φφφ (includes A, b) and the cost c, but also the optimal
solution s. The last might be expressed as a structural equation where the former act as causes
and typically we know how to compute this equation since it corresponds to the solver. Fig.1 (left)
illustrates such a graph. Now, we might go a step further and use this prior knowledge (or bias) on
the role of certain elements in V to ask questions about the relations of parameter to parameter or
parameter to the solution1, see Fig.1 (right).

To investigate these LP-speciﬁc relations we just described, we propose a data-driven approach.
For this, we do not need to assume any speciﬁc knowledge on the actual LP—we simply observe
data stemming from the LP. For interpretation we will assume to know what certain dimensions
should refer to (e.g. feature k corresponding to constraint entry Ai,j). Consider the following ex-
ample which is a simple instance of the diet problem where we try to ﬁnd a cost-efﬁcient plan for
consuming pizza (x1) and salad (x2) subject to what deﬁnes a diet to be “healthy”, for instance

Ax ≤ b := (−1)

(cid:18) 5

1000

(cid:19)

20
250

(cid:19) (cid:18)x1
x2

≥ (−1)

(cid:19)

(cid:18) 30
1800

,

where A1,: denotes the amount of ﬁber in g (per 100 g) and A2,: denotes the calories in kcal (per
100 g), respectively per dish, and b1, b2 denote the minimal requirements in ﬁber and calories (the
−1 assures the lower bound). We can now deﬁne an indicator function φ(x) which is 1 if Ax ≤

1Note that the classical causal discovery setting is neatly captured by input to input in this case.

2

Published at the ICLR 2022 workshop on Objects, Structure and Causality

Figure 2: Schematic View on Problem Setting. Left, the possibly unobserved underlying LP which
is being encoded into a data set. Middle, this data might consist of diets paired with “healthy-ness”.
Right, performing an induction reveals reconstructive properties of the original LP implicit in the
data, e.g. pizza (x1) has greater inﬂuence on whether diet is healthy or not y. (Best viewed in color.)

b and 0 otherwise. Now, we might encounter our data situation where we are given a data set
D := {(xi, yi)}n
i of size n where yi = φ(x) and we can assume to know that x refers to pizza
and salad consumption whereas y denotes whether the consumption is healthy or not. Given only
the data and the knowledge on what it represents, what can we infer from it? Can we discover a
structural relationship, perhaps causal? It turns out, applying an induction approach f to the data
can reveal information implicit in this special type of data. For our concrete example, one such
wi→ y where G = f (D) and ∀i, wi < 0 and |w1| > |w2|. In words,
resulting structure is G : xi
we can infer 3 statements: (a) we can choose whether we consume pizza or salad independently,
(b) our pizza and salad consumption will dictate whether our diet is healthy or not, and (c) pizza is
worse for a healthy diet. Especially, statement (c) is interesting and highly non-trivial since it is the
information about the constraints A, b that we don’t know about but that are captured implicitly by
y. Fig.2 captures the general idea alongside this concrete example schematically.

3 CASE-BY-CASE EMPIRICAL INVESTIGATION

Upon establishing an intuition for strucural (causal) perspective on LPs (Sec.1) and illustrating our
approach on a concrete example (Sec.2), we are now going to study the different discovery settings
empirically (also including special types of LPs such as shortest path). In the following, we choose as
induction method the score-based approach from (Zheng et al. (2018); abbreviated, NT) which ﬁnds
the best linear ﬁt of the data (under optional regularization) while satisfying an acyclicity constraint.
Therefore, NT itself is an optimization problem2, one that aims at ﬁnding the best weighted, directed
acyclic graph (DAG) given the data. NT makes no claims on causality but it ﬁnds correlation (the
best linear ﬁt). This observation was recently pointed out by (Reisach et al., 2021) who showed
that NT might only sort variances. Nonetheless, we choose NT for two reasons (a) correlation
being an arguably appropriate proxy for an LP with its linear cost/constraints and thus pre-requisite
for causation3 at least up to confounder, and (b) NT being a simple, controllable formulation for
effective experimentation. Therefore, we can expect to reveal structure in LPs as previously pointed
out. Still, for future iterations of this work direction it would be sensible to consider the vast zoo
of methods (which also provide guarantees on the causal side) and whether its majority vote keeps
consistent with the subsequent results. Minor technical details can be read up in the appendix.

3.1 GENERAL LINEAR PROGRAMS

Case: D = {(xi, yi)}n
i . If y = 1 for Ax ≤ b , then G = f (D) suggests the linear relationship
y = (cid:80)
i wixi where wi < 0 (red values). Accordingly, ﬂipping the encoding to y = 0 indicating
feasibility we observe an expected ﬂip in weights as well, wi > 0. The xi are reported mutually in-
dependent which reﬂects in the data-generation where we choose x at random. We generally provide
f with 1, 000 data points for our experiments. Furthermore, we observe some effects being more
important to y than others, e.g. increasing x3 would make y = 0 (infeasible) the “quickest”. This

2Ironically, there is a certain elegance to ﬁnding structure in an optimization problem (in the Fig.1 sense)

by applying another optimization problem on top of it.

3This does not hold for non-linear settings. Absence of correlation does not imply absence of causation,

while statistical dependence usually does imply the presence of causation.

3

Published at the ICLR 2022 workshop on Objects, Structure and Causality

observation corroborates once more the fact that G captures implicit information about constraints
A, b only from D. The diagonals are marked out, as are any cyclic relations, since f converged
thus guaranteeing a DAG. The result also reﬂects the actual computation of y although f does not
impose any guarantee regarding the direction of the ﬁt since we could have ﬁtted each xi via y.

Case: (b, y). In this setting we consider a family of LPs parameterized by b while A, c are kept
constant and y is as before. We observe the same overall message as in the ﬁrst case, in that y will
“control” the magnitude of the b which dictate the placement of the polytope faces.

the actual optimal

(b, s). Again, b is parametric but now
Case:
solution s =
we consider
arg maxx LP(x; A, b, c) instead of the feasibility of
an arbitrary solution. The ﬁrst interesting observation
(red, dotted rectangles) is (b1, s1) > 0 which suggests
that b1 is more restrictive for obtaining a solution in that
speciﬁc dimension of decision, looking at column A:,1
supports this intuition (blue denotes entry aij>0). The
second interesting observation is the “competition” be-
tween the dimensions of s since exploiting one si usually comes with a decrease in another sj, i (cid:54)= j.

(c, s). We consider
Case:
two different data sets sam-
pled under different random
seeds. We observe match-
ing tendencies for pairs on the
main diagonal (ci, si) > 0
suggesting that a decrease in
cost comes with an increase of selecting that dimension for the ﬁnal decision. Again, conﬁrmation
for the competition between si. More interestingly, on the right data set we observe a pattern which
requires some detailled inspection. Inspecting the row (c1, s) and (c2, s) they show a negative im-
pact on the latter element of s shifted relative to each other. Inspecting the columns of A reveals the
same patterns suggesting that for e.g. (c1, s1) the constraints were already “exhausted” such that s3
is being negatively impacted—and the same holds for the relations between c2, s2, s4.

Case: (c, A, b, s). Finally, we inspect
the general LP case with all deﬁning el-
ements being parametric. The ﬁrst key
observation is that all the detected re-
lations are exclusive to parameter and
solution. Generally, the extracted pat-
terns conﬁrm the results from the previ-
ous cases. A new scenario is revealed
by the rows in A and their relation to
s which form repeating, negative diago-
nals that suggest a shrinking of the LP polytope, thus the smaller Ai,: the smaller si, ∀i.

3.2 SHORTEST PATH LINEAR PROGRAMS

In the previous section we considered general LPs, but now we move onto the shortest path (SP)
problem which is an integral variant of the LP—one of the classical guises we discussed at the
beginning in Sec.1. Speciﬁcally, we consider two cases of SP much in the same fashion as before.

4

Published at the ICLR 2022 workshop on Objects, Structure and Causality

Case: (x, y). In this setting the graph to the corresponding SP problem is ﬁxed. As before, we
observe a linear relationship between the selected edges (or path segments) xi and the validity of
a path (or collection of such edges) on the route from the left most node to the right most node, y.
More interestingly, we observe a maximal activation in x5 which suggests that this speciﬁc segment
imposes the strongest inﬂuence on what deﬁnes a valid path. Indeed, looking at the graph we observe
that if a path p is valid, then x5 ∈ p.

Case: (A, s). We extend the ﬁxed graph setting with additional, dynamically generated edges. Our
ﬁrst observation is the pattern within A which simply reﬂects the “laws” that are characteristic of
the SP problem formulation, aspects like “a visited node has exactly one incoming and at most one
outgoing edge.” The second observation concerns s where we observe that certain path segments
tend to occur together in the sense that they usually belong to a valid, if not optimal, path.

3.3 ENERGY SYSTEM LP OF A SINGLE FAMILY HOUSEHOLD

To conclude our empirical
section, we consider one ﬁ-
nal LP setting in which we
take inspiration from (Sch-
aber et al., 2012) for a sim-
ple, yet large energy system
modelling the yearly energy
consumption of single family
household per hour (365 ∗ 24 = 8, 760 hours multiplied by the number of constraints that are time-
dependent resulting in an LP with more than 35, 000 constraints). The constraints of the LP model
aspects such as energy balance, photo-voltaics production limit or battery equalities (the speciﬁc LP
is listed in the appendix). Input denotes aspects of the energy system (c), whereas output denotes the
resulting optimal decisions (s). Therefore, the investigated case corresponds to (c, x) from before.
We observe Demand to correlate with all output dimensions, which seems appropriate. However,
we also miss out on relations we’d expect to observe like for instance CapP V onto CapBat.

4 CONCLUSIONS AND FUTURE WORK

Starting our discussion from the success of LPs in various applications ranging from classic ones
(like diet-, assignment-, or shortest path problems) to machine learning tasks (like MAP inference
or adversarial examples), we took a causal perspective and devised a new paradigm for structural
induction from data originated in a (usually hidden) LP to reconstruct insights. Opposed to classical
discovery, we can now reason about parameter to parameter or parameter to solution relations. We
followed this perspective with a thorough empirical investigation on a case-by-case basis.

As pointed out in Sec.1, causality stands at the core of cognition, and transitively at the core of
artiﬁcial intelligence. A counterfactual theory like the Pearlian notion to causality suggests to be an
appropriate formal candidate for this endeavour. In this short work, we investigated a causal per-
spective but only correlations empirically, therefore, we propose that future research shall consider
to investigate an SCM-type of perspective on LPs theoretically. Furthermore, raising the potential
for a more general integration and feed-back between concepts from causality and mathematical op-
timization through an extension of the proposed setting to greater, real-world based examples might
suggest to be fruitful.

5

xcPVcBatcBuyDemandCapPVCapBatOwn-GenTotexCapexcPVcBatcBuyDemandCapPVCapBatOwn-GenTotexCapex=0.1, =0.3cPVcBatcBuyDemandCapPVCapBatOwn-GenTotexCapexCapBatOwn-GenTotexCapexcPVcBatcBuyDemandCapPVCapBatOwn-GenTotexCapexcPVcBatcBuyDemandCapPVCapBatOwn-GenTotexCapex=0.1, =0.3Published at the ICLR 2022 workshop on Objects, Structure and Causality

ACKNOWLEDGMENTS

The authors thank the anonymous reviewers for their valuable feedback. This work was supported
by the ICT-48 Network of AI Research Excellence Center “TAILOR” (EU Horizon 2020, GA No
952215), the Nexplore Collaboration Lab “AI in Construction” (AICO) and by the Federal Ministry
of Education and Research (BMBF; project “PlexPlain”, FKZ 01IS19081). It beneﬁted from the
Hessian research priority programme LOEWE within the project WhiteBox and the HMWK cluster
project “The Third Wave of AI” (3AI).

REFERENCES

Akshay Agrawal, Brandon Amos, Shane Barratt, Stephen Boyd, Steven Diamond, and J Zico Kolter.
Differentiable convex optimization layers. Advances in neural information processing systems,
32, 2019.

Elias Bareinboim, Juan D Correa, Duligur Ibeling, and Thomas Icard. On pearl’s hierarchy and.

2020.

Richard Bellman. On a routing problem. Quarterly of applied mathematics, 16(1):87–90, 1958.

Quentin Berthet, Mathieu Blondel, Olivier Teboul, Marco Cuturi, Jean-Philippe Vert, and Francis

Bach. Learning with differentiable perturbed optimizers. In NeurIPS, 2020.

Stephan Bongers, Patrick Forr´e, Jonas Peters, and Joris M Mooij. Foundations of structural causal

models with cycles and latent variables. The Annals of Statistics, 49(5):2885–2915, 2021.

George B Dantzig. The diet problem. Interfaces, 20(4):43–47, 1990.

Frederick Eberhardt. Introduction to the foundations of causal discovery. International Journal of

Data Science and Analytics, 3(2):81–91, 2017.

Tobias Gerstenberg, Noah D Goodman, David A Lagnado, and Joshua B Tenenbaum. A counter-
factual simulation model of causal judgments for physical events. Psychological review, 128(5):
936, 2021.

Alison Gopnik. Scientiﬁc thinking in young children: Theoretical advances, empirical research, and

policy implications. Science, 2012.

Thomas Kipf, Ethan Fetaya, Kuan-Chieh Wang, Max Welling, and Richard Zemel. Neural relational
inference for interacting systems. In International Conference on Machine Learning, pp. 2688–
2697. PMLR, 2018.

Harold W Kuhn. The hungarian method for the assignment problem. Naval research logistics

quarterly, 2(1-2):83–97, 1955.

David Lopez-Paz, Robert Nishihara, Soumith Chintala, Bernhard Scholkopf, and L´eon Bottou. Dis-
covering causal signals in images. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pp. 6979–6987, 2017.

Jayanta Mandi and Tias Guns. Interior point solving for lp-based prediction+ optimisation. NeurIPS,

2020.

John McCarthy and Patrick J Hayes. Some philosophical problems from the standpoint of artiﬁcial

intelligence. In Readings in artiﬁcial intelligence. 1981.

Anselm Paulus, Michal Rol´ınek, V´ıt Musil, Brandon Amos, and Georg Martius. Comboptnet:
arXiv preprint

Fit the right np-hard problem by learning integer programming constraints.
arXiv:2105.02343, 2021.

Judea Pearl. Causality. Cambridge university press, 2009.

Derek C Penn and Daniel J Povinelli. Causal cognition in human and nonhuman animals: A com-

parative, critical review. Annu. Rev. Psychol., 2007.

6

Published at the ICLR 2022 workshop on Objects, Structure and Causality

Jonas Peters, Dominik Janzing, and Bernhard Sch¨olkopf. Elements of causal inference. The MIT

Press, 2017.

Alexander G Reisach, Christof Seiler, and Sebastian Weichwald. Beware of the simulated dag!

varsortability in additive noise models. arXiv preprint arXiv:2102.13647, 2021.

Katrin Schaber, Florian Steinke, and Thomas Hamacher. Transmission grid extensions for the inte-
gration of variable renewable energies in europe: Who beneﬁts where? Energy Policy, 2012.

Vincent Tjeng, Kai Xiao, and Russ Tedrake. Evaluating robustness of neural networks with mixed

integer programming. ICLR, 2019.

Yair Weiss, Chen Yanover, and Talya Meltzer. Map estimation, linear programming and belief

propagation with convex free energies. UAI, 2007.

Kaiwen Wu, Allen Wang, and Yaoliang Yu. Stronger and faster wasserstein adversarial attacks. In

ICML, 2020.

Matej Zeˇcevi´c, Devendra Singh Dhami, and Kristian Kersting. Intriguing parameters of structural

causal models. arXiv preprint arXiv:2105.12697, 2021.

Xun Zheng, Bryon Aragam, Pradeep K Ravikumar, and Eric P Xing. Dags with no tears: Continuous
optimization for structure learning. Advances in Neural Information Processing Systems, 31,
2018.

7

Published at the ICLR 2022 workshop on Objects, Structure and Causality

A APPENDIX TO “FINDING STRUCTURE AND CAUSALITY IN LINEAR PROGRAMS”

We provide our code for public access and reproduction at: https://github.com/
zecevic-matej/Finding-Structure-and-Causality-in-Linear-Programs.

The hyperparameters of the induction method are explained in Fig.3.

Figure 3: Hyperparameters of Induction Method. We deploy NT (Zheng et al., 2018) which
allows for two hyperparameters λ and w. While λ controls the L1-regularization terms, w is a
threshold for discarding low activations. Therefore, an increase in w will delete signal, whereas an
increase in λ will generally reduce the absolute value of activations and through this also lead to an
increase of activations a to be discarded, a < w.

All experiments were conducted on a MacBook Pro (13-inch, 2020, Four Thunderbolt 3 ports) laptop
running a 2,3 GHz Quad-Core Intel Core i7 CPU with a 16 GB 3733 MHz LPDDR4X RAM on time
scales ranging from a few seconds (small LPs) to up to a few hours (large LPs).

The energy system LP for the single family household is shown in Tab.1.

min
Cap,p

cP V × CapP V + cBat × CapS

Bat +

(cid:88)

cEle × pEle(t) +

(cid:88)

cGas × pGas(t)

t

t
Bat(t) + pGas(t) = D(t), ∀t
Bat(t), t ∈ 2, . . . , T

s.t. pEle(t) + pP V (t) + pout

Bat(t) − pin

Bat(t) − pin

Bat(t − 1) + pout

Bat(t) = pS
pS
0 ≤ pP V (t) ≤ CapP V × availP V (t) × δt, ∀t
0 ≤ pin
Bat(t), pout
0 ≤ pGas(t) ≤ UGas, ∀t
pS
Bat(0) = 0
0 ≤ pEle

Bat(t) ≤ CapBat, ∀t

Table 1: Energy Systems LP for Single Family Household. A large LP that unrolls for 8760 time
steps (8760 hours = 1 year). Model based on (Schaber et al., 2012), the quantities represent: Cost
for Photovoltaics cP V ( C/kW), Battery cBat ( C/kWh), Market Electricity cEle ( C/kWh), Gas cGas
(C/kWh), and the total Demand D (kWh/Year).

8

