Provably Safe Tolerance Estimation for Robot Arms
via Sum-of-Squares Programming

Weiye Zhao, Suqin He, and Changliu Liu

1
2
0
2

r
p
A
8
1

]

O
R
.
s
c
[

1
v
6
9
8
8
0
.
4
0
1
2
:
v
i
X
r
a

Abstract—Tolerance estimation problems are prevailing in
engineering applications. For example, in modern robotics, it
remains challenging to efﬁciently estimate joint tolerance, i.e., the
maximal allowable deviation from a reference robot state such
that safety constraints are still satisﬁed. This paper presented an
efﬁcient algorithm to estimate the joint tolerance using sum-
of-squares programming. It
the
algorithm provides a tight lower bound of the joint tolerance. Ex-
tensive numerical studies demonstrate that the proposed method
is computationally efﬁcient and near optimal. The algorithm is
implemented in the JTE toolbox and is available at https://github.
com/intelligent-control-lab/Sum-of-Square-Safety-Optimization.

is theoretically proved that

I. INTRODUCTION

Tolerance estimation problems are prevailing in engineering
applications. The problem is to ﬁnd a mapping from a con-
straint f (x) ≥ 0, a feasible point for that constraint xr, and a
distance metric (e.g., lp), to the maximum allowable deviation
λ to that feasible point
in the distance metric such that
the constraint is still satisﬁed. Mathematically, the problem
(f, xr, p) (cid:55)→ λ can be written as the following optimization:

max λ s.t. ∀(cid:107)x − xr(cid:107)p ≤ λ, f (x) ≥ 0.

(1)

The problem arises when computing the convex feasible set
for a collision avoidance constraint [1]; when computing the
error tolerance for a given trajectory [2]; when verifying
the adversarial bound for a given constraint [3]; and when
verifying regions of attraction for nonlinear systems [4]. We
call the constraint in (1) a local positiveness constraint, which
requires f to be positive in a bounded neighbourhood of xr.
The solution strategies for (1) differ signiﬁcantly for dif-
ferent types of constraints f . This paper focuses on ﬁnding
tolerance bounds in the joint space of robot arms with respect
to collision avoidance constraints in the Cartesian space. We
call this problem as a joint tolerance estimation problem.
Hence the function f contains the forward kinematics of the
robot arm and the distance computation in the Cartesian space,
which is continuous but highly nonlinear and nonconvex. The
goal is to ﬁnd a non-conservative lower bound of (1), which
can then be used to guide the design of subsequent controllers
to safely stabilize the robot arm within the bound.

While there is limited work on solving (1) that speciﬁcally
leverages the features of f for robot arms, there are many

* This work is in part supported by ARM Institute and Amazon Research

Award.

W. Zhao

and C. Liu

Emails:
with Tsinghua University
hesq16@mails.tsinghua.edu.cn.

weiyezha, cliu6@andrew.cmu.edu.
(work

are with Carnegie Mellon University.
is
at CMU). Email:

done while

He

S.

generic methods that solve (1) in general. The two major
types of solutions are through adversarial optimization and
reachability analysis. Adversarial optimization [5] solves an
equivalent form of (1):

inf (cid:107)x − xr(cid:107)p s.t. f (x) < 0.

(2)

the
which ﬁnds the smallest possible deviation such that
constraint is about to be violated. Numerically, this equivalent
form (2) is easy to solve since it can be directly fed to existing
optimization solvers, while (1) cannot since it essentially
contains inﬁnitely many constraints (i.e., every x corresponds
to a constraint and there are inﬁnitely many x that satisﬁes
(cid:107)x − xr(cid:107)p). However, due to local optimality induced by the
complexity of the constraint f , it is challenging to ﬁnd a
lower bound for (2) [6]. On the other hand, reachability based
methods [7] solves the problem by proposing different λ, com-
puting the reachable set R(λ) := {f (x) | (cid:107)x − xr(cid:107)p ≤ λ},
and then performing binary search to ﬁnd the maximal λ
such that all points in R(λ) satisﬁes f (x) ≥ 0. However,
exact reachable sets are expensive to compute, while under-
approximated reachable sets will not provide a lower bound
of (1) and over-approximated reachable sets may render the
problem overly conservative.

This paper proposes to directly deal with the inﬁnite car-
dinality of constraints by leveraging techniques from sum-
of-squares programming (SOSP) [8]. Although SOSP is able
to deal with inﬁnitely many constraints, the standard SOSP
formulation only deals with global positiveness constraints
instead of local positiveness constraints [9]. A global posi-
tiveness constraint can be written as ∀x, f (x) ≥ 0, which
is more restrictive than a local positiveness constraint. To
derive a non conservative solution of (1), we then resort to
the Positivstellensatz condition, i.e., the theory behind SOSP,
to turn the problem with local positiveness constraints into
an ordinary nonlinear program. The nonlinear program can
then be easily solved by off-the-shelf nonlinear programming
solvers. It
the nonlinear program
provides a lower bound of (1).

is formally proved that

The contributions of this paper include:
• We formulate the joint

tolerance estimation problem
with local positiveness constraints into a sum-of-squares
program and then an ordinary nonlinear program by using
the Positivstellensatz condition.

• We develop an efﬁcient algorithm for joint
is

estimation which
bounds of
is

able
(1) when p = ∞. The
JTE toolbox

implemented

ﬁnd

the

to

in

tolerance
lower
algorithm
is

and

tight

 
 
 
 
 
 
programming solvers. To deal with this issue, we leverage
tools for SOSP (to be reviewed in the following section)
to repose the problem as a nonlinear program. Nonetheless,
using these tools requires f to be a polynomial in x. We
can turn f into a polynomial through local Taylor expansion.
To control
is
desired to constrain the free variable (e.g., x) in a ﬁxed range
instead of a varying range deﬁned by λ. Hence we deﬁne an
auxiliary variable y = [y1, y2, . . . , yn] ∈ Rn and rewrite (3)
as following:

the quality of the Taylor approximation,

it

max λ

s.t. ∀y2

i ≤ 1, i = 1, 2, . . . , n, f (xr + yλ) ≥ 0.

(4)

In the following discussion, we review the tools from SOSP
and show how to use these tools to turn (4) into an ordinary
nonlinear program.

III. SUM OF SQUARES RELATED WORK

Optimization problems with global positiveness constraints
are widely studied and have been successfully applied to
many problems, such as synthesizing Lyapunov functions [11].
These problems can be solved by leveraging SOSP [9]. Math-
ematically, a polynomial p(x) of degree 2d is SOS (denoted
as p(x) ∈ SOS) if and only if there exists polynomials
e1(x), . . . , ek(x) of degree d such that p(x) = (cid:80)k
i=1 ek(x)2.
In particular, SOSTOOLS [9] implements SOSP to solve the
problems with global positiveness constraints. However, our
problem has local positiveness constraints, which cannot be
directly written into the form that SOSTOOLS accepts. We
need to dig into the theory behind SOSP.

To ensure global positiveness of a condition, the easiest
approach is to show that there does not exist any solution that
the condition is violated. The set such that the condition is
violated is called a refute set. For example, the refute set of
∀x, f (x) ≥ 0 is {x | f (x) < 0}. Constructing the refute
set and showing it is empty to ensure global positiveness is
the the core idea behind SOSP [12]. To show that the refute
set is empty, we need to invoke the equivalence conditions in
Positivstellensatz [12]. Before introducing Positivstellensatz,
let us ﬁrst review the deﬁnitions of a key concept: ring-
theoretic cone [13].
Deﬁnition 1 (Cone). Given a set S ⊆ R[x1, . . . , xn], where
R[x1, . . . , xn] is a set of polynomials with [x1, . . . , xn] as
variables. The general cone Γ∗ of S is deﬁned as a subset
of R[x1, . . . , xn] satisfying the following properties:

• a, b ∈ Γ∗ ⇒ a + b ∈ Γ∗
• a, b ∈ Γ∗ ⇒ a · b ∈ Γ∗
• a ∈ R[x1, . . . , xn] ⇒ a2 ∈ Γ∗

Deﬁnition 2 (Ring-theoretic cone). For a polynomial set S =
γ1, . . . , γs ⊆ R[x1, . . . , xn], the associated ring-theoretic cone
can be expressed as:

Γ = {p0 + p1γ1 + . . . + psγs + p12γ1γ2 + . . . + p12...sγ1 . . . γs}
(5)

where Γ ⊆ Γ∗ and p0, . . . , p12...s ∈ SOS.

Fig. 1: Illustration of joint tolerance estimation for a 2-link robot arm.
The actual position of the robot arm may deviate from its reference.
We need to compute the maximum allowable deviation such that the
robot does not collide with the obstacle.

available
Sum-of-Square-Safety-Optimization.

at

https://github.com/intelligent-control-lab/

II. PROBLEM FORMULATION

For an n degree-of-freedom (DOF) robot manipulator, de-
ﬁne xi as the angle of joint i. The state of the robot is
deﬁned as x = [x1; x2; . . . ; xn]. Deﬁne a distance function
f (x) to compute the closest distance between the robot at
conﬁguration x and the environmental obstacles O ⊂ R3 in
Cartesian space, i.e., f (x) = minp∈C(x),o∈O d(p, o) where
d measures the distance between two Cartesian points. The
notation C(x) refers to the area occupied by the robot in
the Cartesian space at conﬁguration x, which needs to be
computed using forward kinematics [10]. Forward kinematics
involve trigonometric terms, i.e., sin(·), cos(·). Hence, f (x) is
highly nonlinear and is not polynomial.

Suppose these is a feasible reference xr, we want to ﬁnd the
maximum tolerance bound λ such that if the deviation from
the actual robot state x to xr does not exceed λ, the robot is
still safe. The problem can be formulated into (1). This paper
focuses on p = ∞ case. Hence the joint tolerance estimation
problem can be posed as

max λ, s.t. ∀(cid:107)x − xr(cid:107)∞ ≤ λ, f (x) ≥ 0.

(3)

Here we provide an example on a 2-link planar robot
arm shown in Fig. 1. The problem is to ﬁnd the maximum
allowable deviation from the reference pose such that the
robot does not collide with the wall at xwall. In this example,
since the ﬁrst link of the robot cannot reach the wall, we
only need to ensure that the end-effector of the robot does
not hit the wall. Suppose the length of the two links are
both 1 and xi is the i-th joint angle for the robot in world
frame, then the collision avoidance constraint can be written
as f (x) = xwall − cos x1 − cos x2. The constraint f (x) and
the reference xr are also illustrated in the conﬁguration (state)
space. The tolerance is illustrated as the green square in the
conﬁguration space.

As mentioned earlier, (3) contains inﬁnitely many con-
straints since every feasible x poses an inequality constraint,
hence cannot be directly solved by off-the-shelf nonlinear

Based on the ring-theoretic cone, Positivstellensatz is spec-

iﬁed in the following theorem.

Theorem 1 (Positivstellensatz). Let (γj)j=1,...,s, (ψk)k=1,...,t,
(φl)l=1,...,u be ﬁnite families of polynomials in R[x1, . . . , xn].
Denote by Γ the cone generated by (γj)j=1,...,s, Ξ the mul-
tiplicative monoid [13] generated by (ψk)k=1,....,t, and Φ
the ideal [13] generated by (φl)l=1,...,u. Then, the following
properties are equivalent:

1) The following set is empty






x ∈ Rn

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

γj(x) ≥ 0, j = 1, .., s
ψk(x) (cid:54)= 0, k = 1, . . . , t
φl(x) = 0, l = 1, . . . , u

.

(6)

2) There exist γ ∈ Γ, ψ ∈ Ξ, φ ∈ Φ such that

γ + ψ2 + φ = 0,

(7)

where ψ = 1 if ψk(x) are empty, and φ = 0 if φl is empty.

In summary, Positivstellensatz shows that

the refute set
being empty is equivalent to a feasibility problem in (7).
The feasibility problem is easier to solve than the original
problem with global positiveness constraints. Nonetheless,
Positivstellensatz does not necessarily require the problem
to be globally positive. We can follow the same procedure
as mentioned above to construct a refute set for the locally
positive problem (1) and then use Positivstellensatz to turn the
problem into a feasibility problem similar to (7), which can
then be formed into an ordinary nonlinear program.

IV. METHODOLOGY

In this section, we introduce the proposed optimization al-
gorithm to efﬁciently solve problem (4) leveraging theorem 1.
The overall procedure of the algorithm contains four main
steps:

• To leverage techniques from SOSP, we construct lower
bound polynomial functions to replace the constraints of
(4).

• To apply Positivstellensatz to efﬁciently solve the lower
bound problem, we construct its corresponding refute
problem and try to show it is empty.

• To efﬁciently ﬁnd solutions for refute problem, we con-
struct the corresponding sufﬁcient problem with reduced
decision variable search space, and further transform it to
a nonlinear programming problem that is easy to solve.
• Solve sufﬁcient nonlinear programming problem using

off-the-shelf nonlinear programming solver.

In the following subsections, we will introduce the details

of three critical problems in prescribed four steps.

A. Lower Bound Problem

g(xr + yλ). It has been shown that the relative error of small
angle approximation is less than 1% when x < 0.244 rad.
In section VI, we empirically demonstrate that g(xr + yλ)
is the lower bound of f (xr + yλ), and the rigorous proof is
left for future work. For the 2-dimensional example shown
in Fig. 1, we have f (xr + yλ) = xwall − cos(xr
1 + y1λ) −
cos(xr
the corresponding
2 λ2
g(xr + yλ) = cos(xr
2 ) −
sin(xr
1)y1λ − sin(xr

2 + y2λ). Then we can construct

1 λ2
2 ) + cos(xr

2)(1 − y2

1)(1 − y2

2)y2λ.

Now suppose the g(xr + yλ) is the lower bound of f (xr +
yλ), such that f (xr + yλ) ≥ g(xr + yλ) ≥ 0. The lower
bound problem of (4) is deﬁned as:

min − λ
s.t. ∀y2

i ≤ 1, i = 1, 2, . . . , n,

g(xr + yλ) ≥ 0.

(8)

B. Refute Certiﬁcation Problem

We can show that the local positiveness constraint in (8) is
satisﬁed by showing its refute set is empty. The refute set is
constructed as:
(cid:40)

γ∗
0 = −g(xr + yλ) ≥ 0
i = 1 − y2
γ∗

i ≥ 0, i = 1, 2, . . . , n

(9)

Then we can use theorem 1 to turn the emptiness problem for
(9) to a feasibility problem similar to (7). Finally, the problem
(8) can be turned into the following optimization problem:

min − λ,

s.t. ∃pi ∈ SOS, i = 0, 1, 2, . . . , such that p0 + p1γ∗

0 + . . . +

psγ∗

n + p01γ∗

0 γ∗

1 + . . . + p012...nγ∗

0 . . . γ∗

n + 1 = 0.

(10)

(10) is equivalent to (8), which will be proved in lemma 3.

Here we highlight that problem (10) inherently differentiates
from the state-of-the-art SOSP due to the fact that set of
inequalities in (9) contain an additional decision variable λ to
be optimized, which is not the free variable x in theorem 1.

C. Sufﬁcient Nonlinear Programming Problem

To efﬁciently search for the existence of SOS polynomials
{pi} while maximizing the desired tolerance bound λ, we
set pi to be a positive scalar αi for all i ≥ 1. By deﬁning
(cid:3) and
a decision vector c∗ = (cid:2)λ α1 α2
corresponding weight vector w∗ = (cid:2)−1
0(cid:3). A
simpliﬁed problem of (10) can be deﬁned:

. . . α012...n
0

. . .

0

min w∗T c∗,
s.t. p0 = −α1γ∗
0 . . . − αsγ∗
0 . . . γ∗
− α012...nγ∗
αi ≥ 0, i = 1, 2, . . .

n − α01γ∗
n − 1 ∈ SOS,

0 γ∗

1 − . . .

(11)

Since Theorem 1 only applies to polynomials in x, we
ﬁrst need to bound f (xr + yλ) below using a polynomial.
Speciﬁcally, we replace the trigonometric terms in f (xr +yλ)
using small angle approximation, where sin(x) ≈ x and
cos(x) ≈ 1 − x2
2 , which results in a multi-variate polynomial

It will be shown in lemma 4 that the solution for (11) is
sufﬁcient to satisfy the constraints (10), hence provides a lower
bound to λ in (10).

To solve for (11), suppose the degree of p0 is 2d, we ﬁrst
do a sum-of-squares decomposition of p0 such that p0 =

y2

. . .

. . .

y1y2

Y (cid:62)Q∗(λ, α1, α2, . . . , α012...n)Y , where Q∗ is symmetric and
Y = (cid:2)1
(cid:3). Speciﬁcally,
y1
yn
ij as the element of Q∗ at i-th row
for off-diagonal terms Q∗
and j-th column (i (cid:54)= j), assuming the the coefﬁcient of the
term YiYj in p0 is wij, we set Q∗
2 . Note that multiple
(i, j) combinations may result in same YiYj. We recommend
to select one (i, j) combination to be wij
2 while setting the
rest to be zero.

ij = wij

yd
n

With the decomposed Q∗, we can formulate the equivalent
nonlinear programming problem of (11) according to lemma 5:

min w∗T c∗,

s.t. det(Q∗(λ, α1, α2, . . . , α012...n)k) ≥ 0, k = 1, 2, . . .

αi ≥ 0, i = 1, 2, . . .

(12)

where Q∗(λ, α1, α2, . . . , α012...s)k denotes the k × k sub-
the ﬁrst k rows and columns of
matrix consisting of
Q∗(λ, α1, α2, . . . , α012...n). Note that (12) is a standard non-
linear programming problem. It can be solved efﬁciently
by off-the-shelf nonlinear programming solvers, such as
fmincon in MATLAB.

Algorithm 1 Joint Tolerance Estimation

1: procedure JTE(xr, f (·))
2:
3:

Construct lower bound problem (8).
Construct refute certiﬁcation problem (10).
Construct sufﬁcient nonlinear programming problem

(12)

Solve (12) using nonlinear programming solver.

4:

5:

(11). Finally, lemma 5 shows (11) is equivalent to the nonlinear
program (12).

Lemma 1 (Transformation). Supposing the solution of (3) is
λ1 and the solution of (4) is λ2. Then we have λ1 = λ2.

Lemma 2 (Lower Bound). Supposing the solution of (4) is
λ2 and the solution of (8) is λ3. If g(x) ≤ f (x) for all x,
then we have λ2 ≥ λ3.

Lemma 3 (Refute Equivalency). If λ4 is the solution of (10),
and λ3 is the solution of (8), then λ4 = λ3 .

Proof. Based on theorem 1 and the fact that we do not have
inequation constraints ((cid:54)=) or equality constraints (=),
the
Positivstellensatz conditions can be reduced to the following
equivalence statement:
(cid:12)
(cid:12)
(cid:12)
(cid:12)

γj(x) ≥ 0, j = 1, .., s

is empty.

x ∈ Rn

The set

(cid:27)

(cid:26)

⇐⇒ There exists γ ∈ Γ such that γ + 1 = 0.

(13)

For the constraint ∀(cid:107)x − xr(cid:107)∞ ≤ λ, f (x) ≤ 0, its refute
certiﬁcation is ∀(cid:107)x − xr(cid:107)∞ ≤ λ, f (x) > 0. By change of
variables, we refute certiﬁcations of the constraints in (8) can
be written as (9). By applying (13) and deﬁnition 2 for Γ, we
know (9) is equivalent to the following statement:

∃pi ∈ SOS, i = 0, 1, 2, . . . , such that γ + 1 = 0 and
γ = p0 + p1γ∗

1 + . . . + p012...nγ∗

0 + . . . + p01γ∗

0 γ∗

0 . . . γ∗
n.
(14)

Therefore, problem (8) is equivalent to problem (10).

The integrated algorithm for joint tolerance estimation is
summarized in algorithm 1, which efﬁciently ﬁnds the lower
bound solution of (3).

Lemma 4 (Sufﬁciency). Supposing λ5 is the solution of (11),
and λ4 is the solution of (10), then λ5 ≤ λ4.

V. PROPERTIES OF JTE

In this section, we will prove that the solution from Algo-
rithm 1 is the lower bound of the optimal solution of (3). The
main result is summarized in the following theorem.

Theorem 2 (Feasibility of Algorithm 1). Under Algorithm 1,
the solution of problem (12) provides the lower bound of
problem (3), i.e., denoting the solution of problem (12) as
λ∗, the optimal solution for (3) as λ, then 0 ≤ λ∗ ≤ λ.

A. Preliminary Results.

Before proving theorem 2, we present preliminary results
that are useful toward proving the theorem. By change of vari-
ables, (4) is equivalent to (3) as summarized in lemma 1. By
using a conservative constraint g instead of f , (8) provides a
lower bound of (4) as summarized in lemma 2. lemma 3 shows
problem with local positiveness constraints can be transformed
into a problem that searches for SOS polynomials, i.e., (10), by
constructing the corresponding refute certiﬁcations. lemma 4
shows that we can solve a sufﬁcient problem of (10), which
only searches for one type of SOS polynomials as shown in

0

it

. . .

. . . α012...n

Proof. It has been shown that
is impossible to check
every instance of the possible sum-of-squares polynomial [12].
Nonetheless, the simplest SOS is a positive constant scalar,
i.e., α ≥ 0 ∈ SOS. By substituting pi with αi ≥
0 for i = 1, 2, . . . and deﬁning a new decision vector
c∗ = (cid:2)λ α1 α2
(cid:3) and weight vector w∗ =
(cid:2)−1
0(cid:3), (10) can be rewrote as (11). Denote the
0
searching space for SOS polynomials pj, j = 1, 2, . . . in (10)
as Ω = [ω1, ω2, . . .], where ωi ∈ R is the coefﬁcient of i-th
term of pj. The search space for SOS polynomials in (11) is
1 ∈ R+ is the scalar term. Therefore, we
Ω∗ = [ω∗
have Ω∗ ⊆ Ω, and λ5 that solves for Ω∗ also solves for Ω, not
vice versa. Since 0 is the common solution for both Ω∗ and
Ω, and their common solution sets evolve continuously, Thus
we have λ5 ≤ λ4.

1], where ω∗

Lemma 5 (Semi-Deﬁnite Cone Equivalency). Supposing λ6
is the solution of (12), and λ5 is the solution of (11) , then
λ5 = λ6.

Proof. Whether a polynomial is SOS can be efﬁciently veriﬁed
through sum-of-squares decomposition [12]. Mathematically,

given polynomial h(x) whose degree is 2d, the sum-of-squares
decomposition decomposes h(x) as:

z = (cid:2)1 x1

h(x) = zT Qz,

. . . xn x1x2

. . . xd
n
(15)
where Q is a constant matrix. If Q is positive semideﬁnite,
then h(x) ∈ SOS. The condition that Q (cid:23) 0 can be encoded
in a semideﬁnite program [12]. In (11), we directly enforce that
the determinant of all submatrices of are positive. By linear
algebra, we know that

(cid:3)

Q (cid:23) 0 ⇐⇒ det(Qk) ≥ 0 for all k = 1, 2, . . .

(16)

where Qk is the k × k submatrix consisting of the ﬁrst k
rows and columns of Q and det(Qk) denotes the determinant
of submatrix Qk. Therefore, the optimization problem (11) is
equivalent to (12).

B. Proof of the Main Result
Proof. If λ∗ is the solution of (12) and λ5 is the solution of
(11). By lemma 5, we have λ∗ = λ5. If λ4 is the solution of
(10), by lemma 4, we have λ5 ≤ λ4. If λ3 is the solution of (8),
then by lemma 3, we have λ3 = λ4. If λ2 is the solution of (4),
by lemma 2, we have λ2 ≥ λ3. Then, if λ is the solution of (3).
By lemma 1 we have λ = λ2. From the above deduction, we
have the main result 0 ≤ λ∗ = λ5 ≤ λ4 = λ3 ≤ λ2 = λ.

C. Additional Results

Theorem 3 (Scalability). If there exists multiple constraints
fi(x) ≥ 0, i = 1, 2, . . . , n and the solution for these con-
i.e., ∀(cid:107)x − xr(cid:107)p ≤ λi, fi(x) ≥ 0, i =
straints are λi,
1, 2, . . . , n. Then λmin = min
λi is a lower bound of the
i
optimization min λ s.t. ∀(cid:107)x − xr(cid:107)p ≤ λ, ∀i, fi(x) ≥ 0. In
other words, ∀(cid:107)x − xr(cid:107)p ≤ λmin, fi(x) ≥ 0, i = 1, 2, . . . , n.

Proof. A straightforward proof is that, suppose λi ≤ λj, i (cid:54)= j,
we have {x | (cid:107)x − xr(cid:107)p ≤ λi} ⊆ {x | (cid:107)x − xr(cid:107)p ≤ λj},
then ∀(cid:107)x − xr(cid:107)p ≤ λi, fi(x) ≥ 0 and fj(x) ≥ 0. For the
minimum λmin, we have the intersection {x | (cid:107)x − xr(cid:107)p ≤
λmin} = (cid:84)
{x | (cid:107)x − xr(cid:107)p ≤ λi}. Hence, ∀(cid:107)x − xr(cid:107)p ≤
λmin, fi(x) ≥ 0 for all i = 1, 2, . . . , n.

i

Theorem 3 implies that the computation complexity grows
linearly with the number of constraints if we solve each
constraint independently and then minimize over all λi.

VI. EXPERIMENTS AND RESULTS

A. Experimental Setup

To demonstrate the effectiveness of the proposed JTE Tool-
box for joint tolerance estimation of robot arms, we design
two sets of experiments. In these experiments, the obstacle is
always taken as a half plane. It is not an over simpliﬁcation
by taking half planes. As shown in the convex feasible set
algorithm [14] [15], all obstacles can be bounded by a set of
half planes and we only need to stay away from these half
planes. Moreover, by theorem 3, we can solve the bound for
each half plane independently and then take the minumum.

Fig. 2: Validation of the algorithm for joint tolerance estimation on
2D problem and 3D problem. The blue points are sampled x in the
hypercube (cid:107)x − xr(cid:107) ≤ λ where λ is the result returned by (1). The
horizontal axis is the sample ID. The vertical axis is the distance
from the robot to the obstacle at that sample. These plots correspond
to different constraints: (a) 2D - x axis half plane, ξx = 1.456. (b)
2D - y axis half plane, ξy = 1.416. (c) 2D - general half plane,
−x − y + 2.8 ≥ 0. (d) 3d - x axis half plane, ξ∗
x = 1.8. (e) 3D -
y axis half plane, ξ∗
z = 1.35.
(g) 3D - general half plane, −0.4758x − 0.0135y − z + 1.7601 ≥ 0.
The red line indicates the boundary of safety constraint.

y = 0.45. (f) 3D - z axis half plane, ξ∗

We design two sets of joint tolerance estimation problems:
one is a 2DOF robot working in 2-dimensional space; the other
is a 6DOF YASKAWA GP50 robot working in 3-dimensional
Cartesian space. For all problem sets, we only enforce the
constraint on the end effector since the other parts of the robot
cannot reach the obstacle. The algorithm is generalizable to
any other critical body point. Denote the end-effector position
as F K(x) where F K(·) computes forward kinematics. For
each problem set, we randomly pick the reference robot
conﬁguration, and specify the following half plane constraints:

• For 2-dimensional plane

– half plane on x axis, such that F k(x)x ≤ ξx;
– half plane on y axis, such that F k(x)y ≤ ξy;
– general half plane O, such that d(F K(x), O) ≥ 0.

• For 3-dimensional Cartesian space

– half plane on x axis, such that F k(x)x ≤ ξ∗
x;
– half plane on y axis, such that F k(x)y ≤ ξ∗
y ;
– half plane on z axis, such that F k(x)z ≤ ξ∗
z ;
– general half plane O∗, such that d(F K(x), O∗) ≥ 0.
y , ξ∗
x, ξ∗
scalars, F K(x)x,
The parameters
z
F K(x)y, F K(x)z denote the x, y, z coordinates of the end ef-
fector, and d(·) denotes a signed distance function to compute
the distance between a point and a half plane. The experiment
platforms for both settings are illustrated in Fig. 3.

ξx, ξy, ξ∗

are

B. Results

For the 2D problem, the lengths of both links of the robot
are 1m. The reference conﬁguration is xr = [ π
6 ]. The
parameters in the safety constraints are 1) ξx = 1.4560m,
2) ξy = 1.4160m, and 3) the general half plane O represented
by −x − y + 2.8 ≥ 0.

3 , π

TABLE I: JTE Toolbox safe joint tolerance bound optimization performance summary cross two sets of experiments in terms of computation
time, the safety constraints violation percentage, and the closest distance (safe distance) from sampled end-effector position to safety boundary.

2-dimensional experiments

3-dimensional experiments

x-axis plane

y-axis plane

general plane

x-axis plane

y-axis plane

z-axis plane

general plane

time (s)
safety violation
smallest f (x) (m)
λ (rad)

0.5953
0%
0.0035
0.0670

0.8105
0%
0.0012
0.0372

0.5940
0%
0.0021
0.1145

6.804
0%
0.0111
0.0346

5.028
0%
0.0067
0.0265

1.5844
0%
0.0014
0.035

3.9198
0%
0.0043
0.0302

VII. CONCLUSIONS

This paper presented a sum-of-squares programming
method that can efﬁciently solve for the joint tolerance of
robot arms with respect to safety constraints. The proposed
method is proved to provide a tight lower bound of the joint
tolerance. Numerous numerical studies are conducted and the
results demonstrate the effectiveness of our proposed method
in terms of computational efﬁciency and optimality. In the
future, we will investigate more complex situations with non
differentiable safety constraints.

REFERENCES

[1] C. Liu, C.-Y. Lin, and M. Tomizuka, “The convex feasible set algorithm
for real time optimization in motion planning,” SIAM Journal on Control
and optimization, vol. 56, no. 4, pp. 2712–2733, 2018.

[2] W. Wu and S. Rao, “Uncertainty analysis and allocation of joint
tolerances in robot manipulators based on interval analysis,” Reliability
Engineering and System Safety, vol. 92, no. 1, pp. 54–64, 2007.
[3] C. Liu, T. Arnon, C. Lazarus, C. Strong, C. Barrett, and M. J.
Kochenderfer, “Algorithms
for verifying deep neural networks,”
Foundations and Trends® in Optimization, vol. 4, no. 3-4, pp. 244–404,
2021. [Online]. Available: http://dx.doi.org/10.1561/2400000035

[4] R. Tedrake, I. R. Manchester, M. Tobenkin, and J. W. Roberts, “Lqr-
trees: Feedback motion planning via sums-of-squares veriﬁcation,” The
International Journal of Robotics Research, vol. 29, no. 8, 2010.
[5] Y. Dong, Q. A. Fu, X. Yang, T. Pang, H. Su, Z. Xiao, and J. Zhu,
“Benchmarking adversarial robustness on image classiﬁcation,” in 2020
IEEE/CVF CVPR, 2020, pp. 318–328.

[6] M. S. Bazaraa, H. D. Sherali, and C. M. Shetty, Nonlinear programming:

theory and algorithms.

John Wiley & Sons, 2013.

[7] A. Bhatia and E. Frazzoli, “Incremental search methods for reachability
analysis of continuous and hybrid systems,” in Hybrid Systems: Compu-
tation and Control, R. Alur and G. J. Pappas, Eds. Berlin, Heidelberg:
Springer Berlin Heidelberg, 2004, pp. 142–156.

[8] S. Prajna, A. Papachristodoulou, and P. A. Parrilo, “Introducing sostools:
A general purpose sum of squares programming solver,” in Proceedings
of the 41st IEEE Conference on Decision and Control, 2002., vol. 1.
IEEE, 2002, pp. 741–746.

[9] A. Papachristodoulou, J. Anderson, G. Valmorbida, S. Prajna, P. Seiler,
and P. Parrilo, “Sostools version 3.00 sum of squares optimization
toolbox for matlab,” arXiv preprint arXiv:1310.4716, 2013.

[10] J.-P. Merlet, “Solving the forward kinematics of a gough-type parallel
manipulator with interval analysis,” The International Journal of robotics
research, vol. 23, no. 3, pp. 221–235, 2004.

[11] W. Tan and A. Packard, “Searching for control lyapunov functions using

sums of squares programming,” sibi, vol. 1, no. 1, 2004.

[12] P. A. Parrilo, “Semideﬁnite programming relaxations for semialgebraic
problems,” Mathematical programming, vol. 96, no. 2, pp. 293–320,
2003.

[13] J. Bochnak, M. Coste, and M.-F. Roy, Real algebraic geometry.

Springer Science & Business Media, 2013, vol. 36.

[14] C. Liu, C.-Y. Lin, Y. Wang, and M. To˚amizuka, “Convex feasible
set algorithm for constrained trajectory smoothing,” in 2017 American
Control Conference (ACC).

IEEE, 2017, pp. 4177–4182.

[15] W. Zhao, S. He, C. Wen, and C. Liu, “Contact-rich trajectory generation
in conﬁned environments using iterative convex optimization,” arXiv
preprint arXiv:2008.03826, 2020.

(a) 2-dimensional plane space ex-
periment platform

3-dimensional Cartesian

(b)
space experiment platform

Fig. 3: Experimental platforms.

20 , − π

For the 3D problem, the physical properties of the robot fol-
low the standard YASKAWA GP50 deﬁnition1. The reference
conﬁguration is xr = [ π
2 , π
20 ]. The parameters
in the safety constraints are 1) ξ∗
y = 0.45m,
z = 1.35m, 4) the general half plane O∗ represented by
3) ξ∗
−0.4758x − 0.0135y − z + 1.7601 ≥ 0. All the experiments
are performed on the MATLAB 2020 platform with a 2.3GHz
Intel Core i5 Processor.

20 , π
20 , π
x = 1.8m, 2) ξ∗

20 , π

To evaluate the optimality of the computed joint tolerance
λ, we randomly sample 10000 conﬁgurations x inside the
hypercube (cid:107)x − xr(cid:107)∞ ≤ λ, then check their distance to
the obstacle, e.g., f (x). The samples for the 2D problem
and the 3D problem are plotted in Fig. 2. We can observe
that the computed joint tolerance bound is maximized in the
sense that the minimum distance from sampled points in the
tolerance bound to the obstacle is very close to 0. Nonetheless,
there is no safety violation across all the experiments, which
aligns with theorem 2. The computation time, percentage of
safety violation, the smallest distance value f (x) are reported
in Table I, as well as the optimized tolerance bound λ. Note
that smaller positive safe distance means smaller gap between
the computed λ and the ground truth λ, thus indicating better
solution optimality. Statistical results indicate that JTE can ﬁnd
maximum joint tolerance bound with great optimality in real
time where the safe distance is bounded at millimeter scale.
At the same time, the great joint tolerance bound optimality
does not compromise safety where zero safety violation can
be observed across all sets of experiments. Note that λ of
all experiments are less than 0.244 rad, which satisfy the
requirement of small angle approximation.

1https://www.motoman.com/en-us/products/robots/industrial/assembly-

handling/gp-series/gp50

00.511.522.5300.511.522.5