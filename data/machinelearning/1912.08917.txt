2
2
0
2

n
a
J

2
2

]

G
L
.
s
c
[

4
v
7
1
9
8
0
.
2
1
9
1
:
v
i
X
r
a

Logarithmic Regret in Multisecretary and

Online Linear Programming Problems with Continuous Valuations

Robert L. Bray

Kellogg School of Management, Northwestern University

January 25, 2022

Abstract

∈ R+ and decreases your inventory holdings by At

I study a general revenue management problem in which n customers arrive sequentially over
n periods, and you must dynamically decide which to satisfy. Satisfying the period-t customer
M
yields utility ut
+ . The customer vec-
t)′, are i.i.d., with ut drawn from a ﬁnite-mean continuous distribution and At drawn
tors, (ut, A′
from a bounded discrete or continuous distribution. I study this system’s regret, which is the
additional utility you could get if you didn’t have to make decisions on the ﬂy. I show that if
your initial inventory endowment scales linearly with n then your expected regret is Θ(log(n))
. I provide a simple policy that achieves this Θ(log(n)) regret rate. Finally, I extend
as n
this result to Arlotto and Gurvich’s (2019) multisecretary problem with uniformly distributed
secretary valuations.

→ ∞

∈ R

Keywords: Online linear programming; multisecretary problem; revenue management; regret
bounds; empirical processes

1

Introduction

Caley (1875) introduced the secretary problem in the nineteenth century.1 The problem is to hire

a man to serve as your secretary (a man because most secretaries were men back then). There

are n applicants for the position, whom you interview sequentially. But there’s a hitch: once you

1See Freeman (1983) for a review of the secretary problem up to 1982. And see Ferguson (1989) for a more precise
deﬁnition of the classical secretary problem and its historical background. Brieﬂy, Lindley (1961) solved the ﬁrst
version of the problem, which sought to maximize the probability of hiring the best candidate, and Bruss’s (2000)
sum-the-odds algorithm generalizes and simpliﬁes his result. Mucci (1973) generalized the objective to maximizing
the expected utility from the man you hire. And Arlotto and Gurvich (2019) considers the problem of maximizing
the expected utility of k ≤ n men you hire. They suppose all secretary valuations. This paper is is devoted to the
extension to continuous secretary valuations.

1

 
 
 
 
 
 
interview a man, you must decide whether or not to hire him before interviewing the next man. So

you face an optimal stopping problem, with the objective being to maximize the expected capability

of the man you hire or, equivalently, to minimize the expectation of your regret, which is deﬁned

as the capability diﬀerence between the most competent man and the man you hire.

Arlotto and Gurvich (2019) studied the multisecretary problem, which is the same as above

except with nbn posts to ﬁll, for some bn ∈
is the expected capability diﬀerence between the nbn most capable men and the nbn men you

In this version of the problem, your regret

[0, 1].

hire. Arlotto and Gurvich made a striking discovery:

If secretary valuations are i.i.d. random
∈ N and
In other words, you’re never expected to make more than some ﬁnite number of

variables with ﬁnite support, then your expected regret is uniformly bounded across n
bn ∈
hiring mistakes, regardless of the number of positions you must ﬁll. For this breakthrough result,

[0, 1].

Arlotto and Gurvich (2019) won the 2021 Applied Probability Society Best Publication Award.

Citing an example by Robert Kleinberg, however, Arlotto and Gurvich (2019, p. 234, 251)

showed that the regret could be large if one valuation had a small probability mass, which suggests

that “one cannot generally expect a bound that does not depend on the minimal mass.” Neverthe-

less, they concluded their article by explaining that “At this point, it is not clear whether bounded

regret is achievable also with continuous [valuation] distributions.”

I show that bounded regret is not achievable with continuous valuation distributions. Specif-

ically, in section 3 I show that the regret is Θ(log(n)) as n

when secretary valuations are

→ ∞

i.i.d. uniform random variables. That is, I show that there exist C1, C2 > 0 such that the expected

regret is between C1 log(n) and C2 log(n) for all n > 1. Moreover, I show that the most obvious

heuristic garners this Θ(log(n)) regret rate.

Switching from ﬁnite to continuous valuations completely changes the mechanics of the model.

With ﬁnite valuations the probability of making a period-t hiring mistake decreases exponentially

in t, whereas expected cost of such a mistake remains constant. Hence the total regret grows with

n like

n
t=1 exp(

−

t). With continuous valuations, however, the probability of making a period-t

hiring mistake and the expected cost of such a mistake both decrease like 1/√t. Hence the total

P

cost grows with n like

n
t=1(1/√t)

·

(1/√t).

In section 4, I extend this logic and the Θ(log(n)) regret rate to the more general “online

P

linear programming” (OLP) problem sketched out in the abstract. In this problem, you start with
M
inventory vector nBn ∈ R
+ for utility ut if you fulﬁll the
period-t customer’s demand. Of course, none of your stocks can become negative, so you must

+ , and you exchange inventory At ∈ R

M

carefully husband each of your M resources. This model is general: ut can’t have point masses or

2

an inﬁnite mean, but it can have inﬁnite variance, and At must reside in a bounded region, but can

have a general measure otherwise. I also impose a few assumptions that ensure the smoothness of

the shadow prices, but they apply only in an arbitrarily small neighborhood of the limiting resource

endowment B

limn

→∞

Bn.

∞ ≡

Overall, I make ﬁve contributions.

1. I tighten the best-known upper bound for the OLP problem from O(log(n) log(log(n))) to

O(log(n)).

2. I provide the ﬁrst lower bound for revenue management problems with continuous valuations.

My Ω(log(n)) bound conﬁrms that problems with continuous valuations fundamentally diﬀer

from those with discrete valuations (which yield constant regret).

3. I establish the asymptotic normality of the OLP’s shadow prices with an empirical processes

technique. This basic result should be useful in other dynamic linear programming problems.

4. I develop a general method for lower-bounding regrets in stochastic resource allocation prob-

lems. Speciﬁcally, I bound the probability of the resource vector spiraling out of control with

the cost of splitting the oﬄine linear program into two separate linear programs.

5. I shows that the O(log(n) regret rate does not require ut to be bounded (as previous authors

have assumed).

I will now discuss each of these contributions in the context of the literature.

2 Related Works

The work of Li and Ye (2019) inspired me to branch out from the multisecretary problem to the

more general OLP problem. An anonymous reviewer directed me toward their paper after I sub-
mitted a previous version of this article.2 The problem Li and Ye outlined—quantifying the regret

in the canonical revenue management problem with continuous valuations—was so basic that I was

surprised it was still open. A problem as fundamental as this one deserves a clean and deﬁnitive

resolution. However, while Li and Ye made tremendous progress, they did not establish the sharp

bounds this problem merits. I build on Li and Ye’s work in ﬁve ways.

First, I eliminate the log(log(n)) fudge factor from Li and Ye’s O(log(n) log(log(n))) upper

bound. From a practical perspective, the diﬀerence between O(log(n) log(log(n))) and O(log(n)) is

2The previous draft of this article was titled “Does the Multisecretary Problem Always Have Bounded Regret?”

3

essentially zero. But from a philosophical perspective, the diﬀerence between O(log(n) log(log(n)))

and O(log(n)) is the diﬀerence between the almost right answer and the right answer, which is

meaningful.

Second, and more importantly, I provide a corresponding regret lower bound. Li and Ye did not

lower bound the expected regret under the optimal policy. Instead, they cited my multisecretary

lower bound (from the previous version of this article), and they also showed that no “dual-based

policy” can do better than Ω(log(n)). But the optimal policy is not dual-based, so this latter result

is of limited use. Now let me be clear:

lower bounding the regret is much harder than upper

bounding it. For the upper bound, we can explicitly tailor the policy to be tractable. For example,

I wanted to use a martingale convergence theorem for my upper bound, so I designed the policy

to burn resources to make the inventory levels were driftless. Of course, my martingale policy

behaves nothing like the optimal policy, but that doesn’t matter, because the asymptotics are very

forgiving—any policy that’s reasonable to the ﬁrst order of approximation will achieve the O(log(n))

regret. Hence, we have many degrees of freedom to simplify the problem when proving the upper

bound. But we lose this advantage for the lower bound, in which case we must contend with the

optimal policy as it is. And not only does this optimal policy have no simplifying properties—it has

no closed-form characterization. So establishing a lower bound requires analyzing a policy that’s

intrinsically indescribable.

Third, I fully characterize the limiting distribution of the shadow prices. Li and Ye proved that

the ﬁnite-horizon shadow prices converge to the inﬁnite-horizon shadow prices at roughly a 1/√n

rate. This was a major result of their article, referenced in its title. But while this convergence result

is suﬃcient for an upper bound—which requires the ﬁnite-horizon and inﬁnite-horizon shadow prices

to be suﬃciently close—it is insuﬃcient for the lower bound—which requires the ﬁnite-horizon and

inﬁnite-horizon shadow prices to be suﬃciently far. So I go a step farther and show that √n times

the diﬀerence of the ﬁnite-horizon and inﬁnite-horizon shadow prices converges to a multivariate

normal. I establish this limiting distribution with an empirical processes result.

Fourth, I create a new methodology to lower bound a revenue management problem’s expected

regret. I begin with Vera and Banerjee’s (2019) compensated coupling regret decomposition, which

expresses the total regret as a sum of period-t regrets, for t

1,

∈ {

, n

. This decomposition
}

· · ·

depends on the random walk taken by the inventories under the optimal policy. I then use the

limiting distribution of the shadow prices to lower-bound the expected regret of the period-t deci-

sion, conditional on the period-t inventory level residing in a given “zone of sanity.” (This is where

I used the asymptotic normality of the ﬁnite-horizon shadow prices.) Finally, I lower bound the

4

probability that the random walk positions the period-t inventory level in the “zone of sanity.” If

the period-t inventory level isn’t in the zone of sanity then the regret must be at least as large

as the diﬀerence between utility achieved by the oﬄine linear program and the utility achieved by

the oﬄine linear program with an extra constraint that excludes the period-t resource vector from

the zone of sanity. So, skipping over a lot of technical details, I basically show that there’s a high

probability that this extra constraint is costly.

Fifth, I generalize the distribution of utility ut. Li and Ye required this variable to be bounded,

which rules out essentially every useful distribution: exponential, log-normal, half-normal, Weibull,

gamma, inverse-gamma, Student’s t—none of these work with their framework. In contrast, all

of these distributions work with my framework, which can accommodate any positive, absolutely

continuous distribution with bounded mean and density. Extending the support of ut from ﬁnite to

inﬁnite extends the support of the shadow prices from ﬁnite to inﬁnite, which completely changes

the problem.

The ﬁve contributions above distinguish my work from Li and Ye’s work. And three contri-

butions distinguish Li and Ye’s work from the work that came before. First, they deﬁned the

problem and outlined the high-level approach to its solution. Speciﬁcally, they had the ingenious

idea of controlling the inﬁnite-horizon shadow prices with their assumptions and then controlling

the ﬁnite-horizon shadow prices by binding them to the inﬁnite-horizon shadow prices with several

convergence results. Second, they developed the convergence results that bind the ﬁnite-horizon

and inﬁnite-horizon shadow prices. And third, they discovered that this problem’s regret is no

more than O(log(n) log(log(n))), as opposed to the O(√n) rate that is more commonly found in

the online learning literature. Moreover, Li and Ye’s model boasts two important features that

mine does not. First, I restrict At to be positive, whereas they allow this vector’s elements to take

either sign. Accordingly, whereas I study a classic retailer, they study a general market maker, who

buys and sells dynamically. Second, I take the joint distribution of ut and At to be given, while

Li and Ye suppose that this information must be estimated over time. Hence, their framework has

an entire learning-v.s.-earning dimension that mine does not.

This last point is crucial because Kleinberg (2005) showed that the regret of the multisecretary

problem is Θ(√n) when the rewards follow a general unknown distribution. Accordingly, Li and Ye

showed that replacing the unconstrained, unknown distribution to moderately constrained, un-

known distribution dramatically reduces the regret.

Arlotto and Xie (2020) wrote the article that’s next most similar to mine. They analyze the

classic knapsack problem, which is the mirror image of the multisecretary problem I study in

5

section 3. Whereas the applicants in my problem have continuous valuations and ﬁxed resource

requirements—each ﬁlling exactly one position—the “applicants” in their problem have ﬁxed valua-

tions and continuous resource requirements. Arlotto and Xie develop a threshold policy that yields

a O(log(n)) regret upper bound, but like Li and Ye they do not develop a corresponding lower

bound. Arlotto and Xie (2020, p. 190) conjecture a Ω(log(n)) lower bound in their conclusion,

but they explain that “it is well known that the optimal policy often lacks desirable structural

properties, so proving [this lower bound] is unlikely to be easy.” As I’ve said, the lower bound is

the harder bound.

Jiang and Zhang (2020) extend Arlotto and Xie’s (2020) model to allow multiple servers. Specif-

ically, they suppose that you must allocate each customer to one of m servers. They provide an

O(log(n)) upper bound, but like Li and Ye (2019) and Arlotto and Xie (2020) do not provide

a corresponding lower bound. Neither Jiang and Zhang’s multi-server problem nor Li and Ye’s

OLP problem (which I study) generalize the other. Jiang and Zhang’s framework incorporates

an additional decision—which server to route a customer to—but Li and Ye’s framework incor-

porates a richer set of restrictions—constraining sales with a general linear program. Moreover,

Jiang and Zhang do not make the initial resource endowment scale linear with n, as Li and Ye

(2019) and I do.

Jiang and Zhang (2020) also considered the case in which there are a ﬁnite number of customer

types. Thus, their article links us to the wave of papers that followed in Arlotto and Gurvich’s

(2019) wake that generalize the multisecretary uniform regret bound to other revenue manage-

ment settings. These articles include Bumpensanti and Wang (2018), Vera and Banerjee (2019),

Vera et al. (2019), Sun et al. (2021), and Chen et al. (2021). These works all exploit the same

phenomenon: a concentration of measure in the distribution of the marginal customer. Since

this concentration of measure does not arise when customer valuations are continuous, the mech-

anism driving their results diﬀers completely from the mechanism driving my results. That said,

Vera and Banerjee (2019, p. 6) developed compensated coupling regret decomposition that under-

pins both my lower and upper bounds. (I actually got the idea for this regret decomposition from

Arcidiacono and Miller (2011), which did a similar thing in a diﬀerent context.)

6

3 Multisecretary Problem

3.1 Setup

You aim to hire bnn
fraction”—i.e., ratio of open positions to applicants—is bn ∈
sequentially, starting with nth man and ending with the 1st man (so that the applicant number

∈ N candidates. Thus, your initial “hiring
(0, 1). You interview the candidates

∈ N secretaries from a pool of n

corresponds with the size of the remaining candidate pool). Hiring the tth man yields utility ut,

which is drawn from a standard uniform distribution, independent of the other candidates’ utilities.

You observe ut when you interview the tth man. After interviewing this candidate, you must either

hire him on the spot or reject him for good. You seek to maximize the expected total utility from

your hires.

The optimal hiring policy yields total expected utility qbn

n , where

max
0,1
∈{

}

xt

xtut + qψt(b,xt)
t
−

1

s. t.

xt ≤

tb

,

(cid:17)

(1)

qb
t ≡

E

qb
0 ≡

0,

(cid:16)

and ψt(b, x)

(tb

≡

−

x)/(t

1).

−

Note that ψt derives the hiring fraction of period t

−

1 from the hiring decision and hiring fraction

of period t.

Bellman equation (1) speciﬁes the following optimal action:

πb
t ≡

arg max
xt

0,1

∈{

}

utxt + qψt(b,xt)
t
−

1

s. t.

xt ≤

tb.

The corresponding realized value is vbn

n , where

vb
t ≡

and vb

0 ≡

t ut + vψt(b,πb
t )
πb
0.

t
−

1

Note that E(vb

t ) = qb

t , by deﬁnition.

If you could interview every applicant before making any job oﬀers then your team of secretaries

7

would yield utility wbn

n ≥

vbn
n , where for tb

∈ N we have

t

t

usxs

s. t.

s=1
X
utxt + wψt(b,xt)
t
−

1

wb

t ≡

max
t
0,1
}
∈{

x

= max
0,1
xt
∈{
tb

}

=

hs
t .

s=1
X

xs ≤

tb

s=1
X
s. t.

xt ≤

tb

(2)

(3)

In the expression above, hs
follow standard uniforms, order statistic hs

· · ·
t follows a beta(t
The diﬀerence in the utilities received in the “oﬄine problem” of hiring after interviewing all

, ut}
s + 1, s) distribution.
−

. Since the applicants’ capabilities

t is the sth highest value in

u1,
{

candidates and the “online problem” of hiring as you go is regret Rn ≡
the expected regret is Θ(log(n)) as n

vbn
n . I will show that
, provided that bn converges to an interior limit point.

n −

wbn

→ ∞

3.2 Upper Bound

I will ﬁrst show that E(Rn) is O(log(n)) as n

.

→ ∞

The oﬄine problem has a simple solution: When there are t remaining applicants and tb re-

maining positions, hire the tth man if and only if his utility exceeds the (tb)th highest utility out

of the ﬁnal t

1. Modifying this solution
yields a hiring heuristic for the online problem: Hire the tth man if and only if his utility exceeds

1 men. That is, make a job oﬀer in period t if ut > htb
t
−

−

the expected value of the (tb)th highest utility out of the ﬁnal t
in period t if ut > E(htb
t
−

1) = 1

−

b.

This policy yields period-t utility ut1{

ut > 1

−

¯bt}

1 men. That is, make a job oﬀer

−

and period-t hiring fraction ¯bt, where

¯bn ≡
1 ≡

−

bn
ψs(¯bs, 1{

us > 1

¯bs}
).

−

and ¯bs

(4)

Hence, the number of available slots at the beginning of period t is t¯bt ∈ N. This hiring policy
yields total hiring utility gn, where

gt ≡
and g0 ≡

ut > 1

ut1{
0.

¯bt}

−

+ gt

−

1

(5)

8

Since this heuristic can’t yield a higher expected utility than the optimal policy, we must have

E( ¯Rn)

≥
¯Rt ≡
w

E(Rn),
¯bt
t −

gt.

where

Hence, I will show that E(Rn) is O(log(n)) by showing that E( ¯Rn) is O(log(n)) as n
1, in which case ¯bt > 0 implies t¯bt ≥

.
→ ∞
1. Accordingly if ¯bt > 0 and ut ≤

To this end, take t

≥

then (2)–(5) yield

(6)

¯bt

1

−

¯Rt = max
0,1
xt

utxt + wψt(¯bt,xt)

1

t
−

−

wψt(¯bt,0)

1

t
−

∈{
= max
0,1
xt
∈{

}

}

utxt + wψt(¯bt,xt)

wψt(¯bt,0)

1

1

t
−

t
−
−
wψt(¯bt,0)
)+ + ¯Rt
−

1

t
−

1

+ wψt(¯bt,0)

1

t
−
¯bt−1
+ w
t
−

1 −

gt

−

gt

−

1

1)ψt(¯bt,0)

(t

−

1 −

Xs=1

+

hs
t
−

1

!

+ ¯Rt
−

1

=(ut + wψt(¯bt,1)

t
−

1
−
1)ψt(¯bt,1)

(t

−

=

ut +

=(ut −

ht¯bt
t
−

Xs=1
1)+ + ¯Rt

hs
t
−

1.

−

Second, if ¯bt > 0 and ut > 1

−

¯bt then an analogous argument yields

¯Rt =(ht¯bt

t
−

1 −

ut)+ + ¯Rt
−

1.

And third, if ¯bt = 0 then we trivially have ¯Rt = ¯Rt
−
implies

1. Now combining these three results inductively

n

¯Rn =

¯rt,

Xt=1

where

¯rt ≡

ht¯bt
1)+ ¯bt > 0
t
−
ut)+ ¯bt > 0

∩

∩
¯bt = 0.

1 −



(ut −
(ht¯bt

t
−


0

(7)

1

ut ≤
ut > 1

¯bt,

¯bt,

−

−

Expression (7) decomposes your total regret into a sum of action-speciﬁc regrets. For example,

¯rt is the ex post regret of your period-t hiring decision. The following lemma characterizes this

variable’s conditional expectation.

9

 
Lemma 1. E(¯rt : ¯bt = b) = b(1

b)/(2t + 2).

−

Finally, combining this result with (6) and (7) yields the desired upper bound.

Proposition 1. The expected regret under the optimal policy is O(log(n)) as n

.

→ ∞

Proof.

E(Rn)

≤

=

≤

=

E( ¯Rn)
n

E(¯rt)

sup
[0,1]

b
∈

sup
[0,1]

b
∈

Xt=1
n

t=1
X
n

Xt=1
n

E(¯rt : ¯bt = b)

tb

1{

b(1
1
}

−

≥

b)/(2t + 2)

<

1/(8t)

t=1
X
(log(n) + 1)/8.

≤

3.3 Lower Bound

I will now show that E(Rn) is Ω(log(n)) as n

Since a threshold policy is clearly optimal, there must exist τ b

τ b
t }

. This optimal threshold policy yields period-t hiring fraction bt, where

→ ∞

if bn converges to some b

(0, 1).
∞ ∈
[0, 1] that satisﬁes πb

t ∈

t = 1{

ut >

bn ≡
1 ≡

−

and bs

bn

ψs(bs, 1{

us > τ bs
s

).
}

10

And with this, a slight modiﬁcation of the argument presented in section 3.2 yields

n

Rn =

rt,

t=1
X

(8)

1)+ bt > 0

htbt
t
∩
−
ut)+ tbt > 0

τ bt
t ,
ut ≤
ut > τ bt
t ,

(ut −
(htbt
t
−

1 −

∩

0

tbt = 0.

where

rt ≡






Moreover, by design, the conditional expectations of rt and ¯rt satisfy the following result.

Lemma 2. E(rt : bt = b)

E(¯rt : ¯bt = b).

≥

Now combining decomposition (8) with lemmas 1 and 2 yields

E(Rn)

n

≥

t=1
X

E(bt(1

bt))

−
2t + 2

.

(9)

I will now lower-bound E(bt(1

bt)). First, deﬁne t
Second, choose n large enough so that (i) ¯t > t, (ii) b

−

≡ ⌈

/2
T deﬁne ξt ≡ ⌈

∞

n2/3

, ¯t
⌉
≡ ⌊
bn ≤
≤
t(3 + b

nb

∞
(1 + b

/t
)/4
⌉

, and T
/2
⌋

t,

· · ·

≡ {

, ¯t
.
}
t(3 +
)/2, and (iii)
⌈
ξ
bn and Ξt ≡ {

∞

∈

∈
Ξt, which means that bn + ξt is a feasible period-t hiring fraction

−

∞

b

/t
)/4
≤
⌉
∞
R : t(bn + ξ)

(4 + b

∞

)/5. Third, for t

∈ N}

. Note that ξt ∈

(i.e., one with a whole number of open positions). Moreover, the conditions we’ve imposed ensure

that

bn −

t

ξt >0,

n
t
−
bn + ξt ≤
and ξt ≥

(4 + b

)/5,

∞

(1

b

∞

−

)/4.

(10)

(11)

Fourth, deﬁne ←−w b
n

t as wb
n
n when we set u1 =

−

equals wb

t when the order of the customers is reversed; in other words, ←−w b
n
t
n−t ξ

−

= ut = 0. By deﬁnition, if ξ

Ξt then wbn+ξ

t

t

−
is

· · ·

∈

bn
+ ←−w
n

−
t
−

the highest achievable utility under the constraint that the period-t hiring fraction equals bn + ξ.
wbn+ξ
Accordingly, the regret is at least ∆ξ
t

bn
t is
−
t
n
−
Ξt—decreasing up until some point and increasing thereafter—which means that

when bt = bn + ξ. Moreover, ∆ξ

− ←−w

n −

t
n−t ξ

t ≡

wbn

bn + ξt and (ii) ∆ξ

t)(bn −

−

t

−

n

t increases in its superscript at ξ = ξt. This latter condition
exceeds the t(bn + ξt)th
, un}

t ξt)th highest value in

ut+1,
{

· · ·

11

U-shaped in ξ
∈
∆ξt
if (i) bt ≥
Rn ≥
t
holds when the (n

highest value in
(n
ht(bn+ξt)
t
n

←−h

u1,
{
t)(bn

−

· · ·
t
n−t ξt)

.
, ut}

In other words, ∆ξ
t
t equals hs
n

, where ←−h s
n

≤

−
t
−

−

−

this together yields the following:

increases in its superscript at ξ = ξt when

t with the reverse applicant order. Putting all

E(Rn)

≥

≥

√n Pr

√n

1

(cid:0)
−

∆ξt

t ≥
Pr

√n

bt ≥
∩
t < √n

∆ξt

bn + ξt ∩
Pr

−

ht(bn+ξt)
t

bt < bn + ξt

Pr

t
n−t ξt)

←−h

(n
n

t)(bn

−

−
t
−
ht(bn+ξt)
t

≤

−

(cid:1)
> ←−h

(n
n

−
t
−

t)(bn

−

t
n−t ξt)

.
(cid:1)(cid:17)

(cid:0)
Moreover, since E(Rn) is O(log(n)), we have E(Rn)

(cid:1)

(cid:0)

(cid:0)

(cid:1)
√n/8 for all suﬃciently large n. And with

(cid:16)

≤

the result above this implies that

Pr

bt < bn + ξt

7/8

−

≥

Pr

∆ξt

t < √n

−

Pr

ht(bn+ξt)
t

> ←−h

t)(bn

−

t
n−t ξt)

(n
n

−
t
−

(cid:0)

(cid:1)

(cid:0)

(cid:1)

(cid:0)

Fifth, Chebyshev’s inequality yields the following two results.

(12)

.

(cid:1)

Lemma 3. Pr(∆ξt

t < √n)

≤

1/16 for suﬃciently large n and t

T .

∈

Lemma 4. Pr

ht(bn+ξt)
t

> ←−h

t)(bn

−

t
n−t ξt)

(n
n

−
t
−

≤

1/16 for suﬃciently large n and t

T .

∈

(cid:0)

(cid:1)

Now combining these lemmas with (10) and (12) yields Pr(bt < (4+b
large n and t

T . And the mirror image argument yields the opposite bound in the other direction:

)/5)

∞

≥

3/4 for all suﬃciently

3/4 for suﬃciently large n and t

∈

≥

T . Thus, for suﬃciently large n and t

∈
/5)

Pr(bt > b
have

∞

T we

∈

(13)

Pr(b

/5

bt ≤

≤

∞

(4 + b

)/5)

∞

≥

1/2.

And now we’re ready to establish our lower bound.

Proposition 2. The expected regret under the optimal policy is Θ(log(n)) as n

.

→ ∞

12

Proof. Combining (9) and (13) yields the following for suﬃciently large n:

E(bt(1

bt))

−
2t + 2

E(Rn)

≥

≥

≥

T
Xt
∈

T
Xt
∈
nb∞/2
⌋
⌊

Pr(b

/5

bt ≤

≤

∞

(4 + b

∞

/5)(1

(b

∞

)/5)

−

(4 + b
4t

∞

)/5)

b

(1

∞

−

∞

b

)/(200t)

n2/3
Xt=
⌈
log(n)/3 + log(b

⌉

≥
(cid:0)

/2)

3

b

(1

b

∞

−

∞

−

∞

)/200.

(cid:1)

4 Online Linear Programming (OLP) Problem

4.1 Setup

backwards from period n

I will now consider a more general online linear programming problem. As before, we will count
∈ N to period 1. In each period an i.i.d. customer arrives and you must
decide whether or not to fulﬁll their demand from your inventory. You begin in period n with
M
+ , so that you have e′jBn units of the jth resource budgeted for the
inventory vector nBn ∈ R
“average” remaining period, where ej is a unit vector indicating the jth position. If you satisfy
the period-n customer then you exchange inventory bundle An ∈ R
begin period n
−

M
+ for utility un, so that you
1). If you reject the period-n

−
customer then you receive no utility and lose no resources, so that you begin period n

1 with resource vector Bn

(nBn −

An)/(n

1 ≡

−

1 with

−

resource vector Bn

1 ≡

−

nBn/(n

−

1). The problem is dynamic because you must wait until the

beginning of period t to learn the period t customer’s variables, ut and At.

The optimal policy yields total expected utility QBn

n , where

max
0,1
∈{

}

Xt

utXt + QΨt(B,Xt)
t
−

1

s. t. XtAt ≤

tB

,

(cid:17)

(14)

QB

t ≡

E

QB

0 ≡

0,

(cid:16)

and Ψt(B, X)

(tB

≡

−

XAt)/(t

1).

−

13

Bellman equation (14) speciﬁes the following optimal action:

ΠB

t ≡

arg max
0,1
Xt

∈{

}

utXt + QΨt(B,Xt)
t
−

1

s. t. XtAt ≤

tB,

(15)

which we take to be unique (without loss of generality). The corresponding realized value is V Bn
n ,

where

V B
t ≡

t ut + V Ψt(B,ΠB
t )
ΠB
0.

t
−

1

and V B

0 ≡

Note that E(V B

t ) = QB

t , by deﬁnition.

If you could observe all customer data upfront then you could extract value W Bn

n ≥

the market, where

W B

t ≡

max
0,1
∈{

t
}

X

t

Xs=1

usXs

s. t.

t

Xs=1

AsXs ≤

tB.

V Bn
n

from

(16)

Your regret is therefore Rn ≡
n

.

→ ∞

W Bn

n −

V Bn
n . Our objective is to show that E(Rn) is Θ(log(n)) as

Since expanding your choice set from

0, 1
}
{

to [0, 1] will not make you worse oﬀ, we have

Z B

t ≥

W B
t ,

where Z B

t ≡

max
∈

[0,1]t

X

= min
M
Y
+

∈R

t

t

usXs

s. t.

s=1
X
t (Y ) and C B
tC B

s=1
X

t (Y )

AsXs ≤

tB

B′Y +

≡

t

s=1
X

(us −

A′sY )+/t.

(17)

(18)

(19)

Note, line (19) is a reconﬁguration of the dual of the linear program in line (18) (see Li and Ye,
2019). The solution to (19) is shadow price vector Y B

tC B

arg minY

M
+

t (Y ).

t ≡

∈R
. In this case, Z Bn
n /n converges to the following

Now suppose that Bn →

B

∞ ∈ R

M
+ as n

→ ∞

deterministic problem:

min
M
Y
+

∈R

C B∞
∞

(Y ) where C B
∞

(Y )

B′Y + E(u1 −

≡

A′1Y )+.

(20)

14

The solution to (20) is shadow price vector Y B
M elements of Y B∞

C B
∞
are strictly positive—i.e., that only the ﬁrst m resource constraints

(Y ). We will assume that only

arg minY

∞ ≡

∈R

M
+

∞

≤

the ﬁrst m
bind in the limit. Going forward, I will use at, bt ∈ R
and use ˜at, ˜bt ∈ R
to refer to their last M
−
1, and use ˜ψt(˜b, x)
(t˜b
to map from bt to bt
−
t , yb
t , cb
t , cb
I will deﬁne vb
∞
∞
n resources and constraints. For example, we have

≡
1) to map from ˜bt to ˜bt
−
, Y B
t , C B
t

x˜at)/(t
≡
t as the analogs of V B
, and πb
t

t , zb
when we disregard the last M

n values. I will also use ψt(b, x)

t , C B
∞

, Z B

, yb

M
+

−

−

m

−

m
+ to refer to the ﬁrst m values of At and Bt
1)

xat)/(t

(tb

−

−
1. And ﬁnally,
, and ΠB
, Y B
t
∞

−

,

(21)

vb
t ≡

zb
t ≡

t ut + vψt(b,πb
t )
πb

1

t
−
t

max
[0,1]t
x
∈

s=1
X

usxs

s. t.

t

s=1
X

asxs ≤

tb,

and cb
∞

(y)

b′y + E(u1 −

≡

a′1y)+.

And since removing constraints can only make you better oﬀ, we have

vb
t ≥

V B
t

and zb

t ≥

Z B
t .

(22)

4.2 Assumptions

We’re now ready for some assumptions.

Assumption 1. The variables are i.i.d.: the n customer vectors,

n
t=1, are drawn indepen-
dently of one another from the same distribution. Random vectors A1 and a1 have general measures

(ut, A′t)′}
{

µA and µa. Random variable u1 is absolutely continuous with respect to Lebesgue measure, with

density function µu

|

A(u1|

A1) conditional on A1 and density function µu

a(u1|

a1) conditional on a1.

|

Assumption 2. The conditional density of u1 is uniformly bounded: there exists ¯µu ∈ R such that
µu

a1) < ¯µu, for all u1, A1, a1 in their respective domains.

A1) < ¯µu and µu

a(u1|

|

a(u1|

|

Assumption 3. The utilities and resource requirements are non-negative: u1 ≥
almost surely.

0 and A1 ≥

0

Assumption 4. The utilities have ﬁnite expectation: E(u1) <

.

Assumption 5. The resource requirements are bounded:

∈ N.
Note that A1 may have point masses, but u1 may not. In contrast, u1 may have an inﬁnite

α, almost surely, for some α

∞
A1|| ≤
||

15

domain, but A1 may not. In fact, we’re guaranteed to have

A1 ≤

αι and a1 ≤

αι,

(23)

where ι is a vector of ones (whose length is context speciﬁc). We’ll use these inequalities extensively.

The ﬁnal four assumptions control our limiting problem.

Assumption 6. The initial resource vector has a ﬁnite and positive limit:

limn

Bn ≡

B

,

∞

→∞

where 0 < B

αι.

∞ ≤

Assumption 7. The limiting problem has a unique solution in a neighborhood of the limiting

resource vector: there exists a B

(20) has a unique solution, Y B
∞

-neighborhood Ω

M
>0 such that if B
, the ﬁrst m elements of which are positive and the rest are zero.

Ω then the problem in

⊂ R

∈

∞

Assumption 8. The limiting problem’s Hessian matrix is full rank at the limiting shadow prices:

(y)

¨c
∞

≡

∂2
∂y2 cb
∞

(y) =

aa′µu

a(a′y

|

a)µa(da) is nonsingular at y = yb∞
|
∞

.

R

Assumption 9. The limiting problem’s Hessian matrix is Lipschitz at the limiting shadow prices:
(y) are Lipschitz in the elements of y in a neighborhood of yb∞
∞

the elements of ¨c

∞

.

All in all, these assumptions constitute quite a general framework. For example, section 3’s

multisecretary problem satisﬁes these assumptions when b

(0, 1). The last three assumptions

∞ ∈

look daunting, but they should almost certainly hold. Assumption 8 basically requires the elements

of at to be “linearly independent,” so that no element in this vector is a deterministic linear

combination of the others. However, this linear independence must still hold when you disregard

values for which µu

|

a(a′tyb∞
∞ |

at) = 0. And assumptions 7 and 9 simply rule out knife edge cases—the

former relating to degenerate constraints and the latter relating to shadow price jumps (see the

conclusion for an example). An arbitrarily small perturbation of B

should resolve any trouble

∞

either of these assumptions cause you.

Finally, let me note one other thing: Hessian matrix ¨c

doesn’t depend on b. However, gradient function ˙cb
∞

(y)

≡

a superscript because it depends on b.

doesn’t take a superscript because it
E(a11{

) takes
}

u1 > a′1y

(y) = b

∞
∂
∂y cb
∞

−

The following lemma organizes several useful regularity conditions implied by our assumptions.

Lemma 5. There exists a convex and open b
neighborhood ˜λ
m

−

M
>0

⊂ R

-neighborhood λ

∞

⊂ R

>0 and a convex and open ˜b
m

-

∞

that satisfy the following conditions, for some constants β, η, ω, ν, θ1, θ2, θ3, σ >

16

0:

λ

×
B

˜λ

Ω,

⊂

2α,

|| ≤

sup
λ

∈

×

B

˜λ ||

b

≥

inf
b
λ
∈
yb
∞|| ≤

βι,

η,

sup
λ ||
b
∈

yb
∞

inf
λ
b
∈
ωι)
}
(cid:1)
2
||

v
)v/
||

>0,

>νι,

θ1,

≥

˜b

˜λ

−

E

inf
λ

∈

×

B

inf
λ
b
∈

v

{

˜a11{
(cid:0)

inf
m : v

∈R
sup
m : v

u1 > a′1(yb

∞ −

v′¨c

(yb
∞

∞

=0

}
v′¨c

∞

v

{

∈R

=0

}

sup
λ
b
∈
inf
λ
b
∈

inf
m : v

=0

v′¨c

∞

}
yb2
||
∞ −

}
+ v)

sup
λ
b1

∈
sup
m :

v

||

v

{

∈R
sup
λ : b2

b2

{

∈

=b1

˙cb
||
∞

(yb
∞

δ

}

||≤
e′1aa′e1µu

¨c
∞

(yb
∞

)v

v
/
||

||

||

−

=0,

a(a′(yb
∞

|

a)µa(da)
+ δe1)
|

σ.

≥

(yb
∞

)−

2

1v/
v
||

||

θ2,

≤

(yb
∞

)−

2

1v/
v
||

||

θ3,

≥

yb1
/
||
∞||

b2 −

b1|| ≤

1/θ1,

lim
0
δ
→

sup
λ
b
∈

v

{

∈R

and

lim
0
δ
→

inf
λ
b
∈

Z

(24)

(25)

(26)

(27)

(28)

(29)

(30)

(31)

(32)

(33)

(34)

The region Λ

˜λ

λ

×

≡

⊂ R

M
>0 is a “zone of sanity” about the limiting resource vector, B

. Our

∞

Λ. To ensure that our resource vector always resides in Λ, we carve out an inner zone

Λ. Accordingly, the policy deﬁned in the next section

∈

problem behaves reasonably so long as B
forces Bt ∈
of sanity, Λt ≡

˜λt, where

λt ×

λt ≡{
b
˜b
and ˜λt ≡{

∈

∈

λ : tb/(t

˜λ : t˜b/(t

1)

1)

λ

˜λ

∩

∩

∈

∈

(tb

(t˜b

−

−

−

−

αι)/(t

−

1)

3αι)/(t

−

∈
1)

λ

}
˜λ

∈

.
}

(35)

By design, Bt ∈
resource vector can’t escape Λ if the period-t resource vector lies in Λt. (The extra 3 in line (35)

Λ, via (23). In other words, the period-(t

Λt implies Bt ∈

Λ and Bt

1 ∈

1)

−

−

accounts for some inventory burning that our upper-bounding policy will indulge in.)

17

6
6
6
6
4.3 Upper Bound

I will now deﬁne a simple heuristic that yields logarithmic expected regret. Let t represent the

current period and B the current resource vector. If B /
∈

Λt then “burn” B units of inventory and

do not fulﬁll the customer’s request.

(You burn inventory by by putting it aside and writing

Λt then burn e′jχt units of resource j
), and then fulﬁll the period t customer’s request if and only if

, where
}

m + 1,

∈ {

, M

· · ·

it oﬀ your books.)
˜b
E(˜a11{
χt ≡
−
.3
ut > a′tyb
∞

If B
∈
u1 > a′1yb

∞}

This heuristic yields period-t utility ut1{

ut > a′ty¯bt

¯Bt ∈

∞}1{

¯Bt, where

¯Bn ≡
¯Bs
1 ≡

−
Φs(B)

≡

Bn,

Φs( ¯Bs),
(φs(B)′, ˜φs(B)′)′,

φs(B)
˜φs(B)

B
b + 1{
≡
˜b + 1{
B
≡

∈

∈

and

Λs}
(cid:0)
Λs}
(cid:0)

ψs(b, 1{
˜ψs(˜b, 1{

us > a′syb
us > a′syb

)
∞}
)
∞}

and period-t resource vector

Λt}

b

,

(cid:1)
χs/(s

1)

−

−

˜b

.

−

−

(cid:1)
Λ implies ¯Bt ∈

By design, this heuristic has two useful properties. First, Bn ∈
¯Bt}
1,
{
{
heuristic as the “martingale policy.”

. Second, the sequence
}

· · ·

, n

∈
n
t=1 follows a martingale. Accordingly, I will refer to this

Λ for all t

The martingale policy yields total value Gn, where

ut > a′ty

ut1{
Gt ≡
0.
and G0 ≡

¯bt
∞}1{

¯Bt ∈

Λt}

+ Gt

−

1

n ), expressions (17) and (22) conﬁrm that E( ¯Rn)
Since E(Gn)
Hence, I will show that E(Rn) is O(log(n)) by showing that E( ¯Rn) is O(log(n)) as n

E(V Bn

≥

≤

E(Rn), where ¯Rt ≡
→ ∞

First, note that b

λt implies at ≤

∈

tb, which implies

zb
t = max
[0,1]
xt

∈

utxt + zψt(b,xt)
t
−

1

.

¯bt
z
t −

Gt.

.

(36)

Moreover, since the shadow price decreases with the inventory level, we have the following for

3Note that χt > 0 when B ∈ Λt, by (28).

18

[0, 1]:

x

∈

zψt(b,x)
t
−
and zψt(b,x)
t
−

1 −

1 −

zψt(b,0)
t
−
zψt(b,1)
t
−

1 ≤ −
(1

1 ≤

xa′tyψt(b,0)

1

t
−

x)a′tyψt(b,1)

1

.

t
−

−

Now expressions (36) and (37) imply that if ¯Bt ∈
utxt + zψt(¯bt,xt)

¯Rt = max
[0,1]
xt

1

t
−

Λt and ut ≤

a′ty¯bt

∞

then

+ zψt(¯bt,0)

1

t
−
¯bt−1
+ z
t
−

1 −

Gt

−

Gt

−

1

zψt(¯bt,0)

1

t
−

−

zψt(¯bt,0)

1

t
−
+ ¯Rt
−

1

∈
= max
[0,1]
xt
∈
max
[0,1]
xt
∈

≤

=(ut −
=(ut −

utxt + zψt(¯bt,xt)

1

t
−

−
xta′tyψt(¯bt,0)

1

t
−
)+ + ¯Rt
−
1.

−

1

utxt −
a′tyψt(¯bt,0)
t
1
−
¯bt−1
a′ty
t
−

1 )+ + ¯Rt

If ¯Bt ∈

Λt and ut > a′ty¯bt

∞

then (36) and (38) analogously yield

And if ¯Bt /
∈

Λt then

¯Rt ≤

(a′ty

¯bt−1
t
−

1 −

ut)+ + ¯Rt
−

1.

¯Rt ≤

t

Xs=1

us + ¯Rt
−

1,

(37)

(38)

(39)

(40)

(41)

because z

¯bt
t can’t exceed the sum of the remaining utilities. Finally, (39)–(41) inductively imply

¯Rn ≤

n

¯rt,

Xt=1

(ut −
(a′ty



a′ty

1 )+ if

¯bt−1
t
−
ut)+ if

where

¯rt ≡



Hence, E( ¯Rn) is O(log(n)) if supN
convergence result with the following four lemmas.

1 −

≥

¯bt−1
t
−
t
s=1 us

if

P
t E(¯rt : n = N ) is O(1/t) as t

(42)

,

,

a′ty¯bt
ut ≤
ut > a′ty¯bt

∞

∞

¯Bt ∈
¯Bt ∈
¯Bt /
∈

Λt ∩
Λt ∩
Λt.

. We will prove this latter

→ ∞

Lemma 6. There exists C > 0 such that supN

t Pr( ¯Bt /
∈

≥

Λt : n = N )

exp(

−

≤

Ct) for all suﬃ-

19

ciently large t.

yb
Lemma 7. There exists C > 0 such that supb
λ Pr(
t −
||
∈
and all suﬃciently small ǫ > 0.

yb
∞||

> ǫ)

exp(

−

≤

Cǫ2t) for all t

∈ N

Lemma 8. For all ǫ > 0 there exists C > 0 such that supb
∈
exp(

Ct) for all suﬃciently large t.

−

λ E(1{||

yb
t −

yb
∞||

> ǫ

yb
t −

}||

yb
∞||

)

≤

Lemma 9. For all suﬃciently small ǫ > 0 there exists C > 0 such that supb
λ E
∈
ǫ

C/t for all t

yb
t −

1{||

yb
∞|| ≤

(cid:0)

yb
t −

}||

2
yb
∞||

≤

∈ N.

Lemmas 6–8 rely on standard concentration of measure bounds. But lemma 9 is more nuanced.

(cid:1)

To establish this result I ﬁrst bound the diﬀerence between yb
limiting gradient, ˙cb
∞
But ˆyb

t and yb
∞
), and its ﬁnite analog, ˙cb
), evaluated at the midway point, ˆyb
(
t (
·
·
˙cb
t (ˆyb
˙cb
t )
||
∞
) is a set of possible ˆyb
expected value of supy
t values. Finally,
I bound the expected value of this supremum with an empirical process result, since the mapping
m is an empirical process (i.e., a random function

t is diﬃcult to work with, so I then bound the expected value of
˙cb
∞

(yb
t +yb
∞
2
with the

with the diﬀerence between the

t ≡
(ˆyb
t )
||

Bǫ(yλ

ǫ(yλ∞) ||

, where

(y)
||

˙cb
t (y)

)/2.

−

−

∈B

∞

2

from y

) to e′j ˙cb
generated from a sample of i.i.d. variables).

∈ Bǫ(yλ

e′j ˙cb
∞

t (y)

(y)

−

∞

∈ R

We now have enough ﬁrepower to establish our upper bound.

Proposition 3. The expected regret under the optimal policy is O(log(n)) as n

.

→ ∞

This proposition’s proof has three parts. First, I consider the scenario in which ¯Bt /
∈

Λt. For

this case, I use lemma 6 to show that the probability of this event falls exponentially in t, whereas

the expectation of ¯rt conditional on this event increases only linearly in t. Second, I consider the
scenario in which ¯Bt ∈
algebra to show that the probability of this event times the expected value of ¯rt conditional on this

> ǫ, for some ǫ > 0. For this case, I use some basic

¯bt−1
∞ ||

¯bt−1
t
−

Λt and

1 −

y
||

y

yb
t
−

λ Pr
event is less than some combination of supb
∈
ǫ
(cid:0)
}||
¯bt−1
I consider the scenario in which ¯Bt ∈
t
−
calculus to show that the probability of this event times the expected value of ¯rt conditional on

. I then use lemmas 7 and 8 to show that this bound falls exponentially in t. Finally,

ǫ. For this case, I use some basic

λ E
and supb
∈

¯bt−1
∞ || ≤

yb
∞||

Λt and

1 −

1 −

1 −

1 −

y
||

1{||

> ǫ

>

y

(cid:1)

(cid:0)

(cid:1)

yb
t
||
−

yb
∞||

yb
∞||

yb
t
−

λ E
this event is less than some expression of supb
∈
lemma 9 to show that this bound falls like 1/t.

(cid:0)

yb
t
−

1{||

yb
∞|| ≤

ǫ

yb
t
−

}||

1 −

1 −

2
yb
∞||

. I then use

(cid:1)

20

4.4 Lower Bound

I will ﬁrst use the following two lemmas to simplify the oracle’s problem from an integer program

that has slack constraints in the limit to a linear program that does not have slack constraints in

the limit.

Lemma 10. There exists C > 0 such that E(Z Bn
n )

E(W Bn
n )

−

≤

C, for suﬃciently large n.

Lemma 11. There exists a B
E(Z B
n )

C, for suﬃciently large n.

≤

-neighborhood Γ

∞

⊂

Λ and a constant C > 0 such that supB

Γ E(zb
n)
∈

−

These lemmas are relatively standard. The former establishes that expanding the action space
n to [0, 1]n increases the expected reward by at most a constant, and the latter establishes
0, 1
}
{

from

that dropping the last M
Together, these results imply that there exists C > 0 such that zbn

−

m constraints increases the expected reward by at most a constant.

n −

W Bn

n ≤

C for all suﬃciently

large n. And with (22) this implies that

Rn ≥
where Rt ≡
bn ≡
1 ≡

and bt

−

C,
vbt
t ,

Rn −
zbt
t −
bn,
ψt(bt, πbt
t ).

Accordingly, I will show that E(Rn) is Ω(log(n)) by showing that E(Rn) is Ω(log(n)).

First, if bt ∈

λt and πbt

t = 0 then expressions (21), (36), and (38) imply

Rt = max
[0,1]
xt

utxt + zψt(bt,xt)
t
−

1

−

1

∈
= max
[0,1]
xt
∈
max
≥
0,1
∈{
}
=(ut + zψt(bt,1)
t
−

utxt + zψt(bt,xt)
t
−
−
utxt + zψt(bt,xt)
t
−
zψt(bt,0)
1
t
−
−
a′tyψt(bt,1)
)+ + Rt
−

(ut −

≥

t
−

xt

1

1

1

1.

zψt(bt,0)
1
t
−
zψt(bt,0)
1
t
−
zψt(bt,0)
1
t
−
−
)+ + Rt
−

1

+ zψt(bt,0)
1
t
−
bt−1
+ z
t
−

1 −

bt
t )

vψt(bt,π
1
t
−

−
bt−1
v
1
t
−

+ Rt

−

1

And if bt ∈

λt and πbt

t = 1 then (21), (36), and (37) analogously yield

Rt ≥

(a′tyψt(bt,0)

1

t
−

ut)+ + Rt
−

1.

−

21

(43)

(44)

(45)

Finally, (44) and (45) inductively imply

Rn ≥

n

t=1
X

rt,

(46)

πbt
t = 0,
πbt
t = 1,

where

rt ≡

1

1

−



t
−

t
−

)+ if

a′tyψt(bt,1)

ut)+ if

bt ∈
bt ∈
bt /
∈

(ut −
(a′tyψt(bt,0)


t E(rt : n = N ) is O(1/t) as t
λt.

if

0

λt ∩
λt ∩
λt.

Hence, E(Rn) is O(log(n)) if inf N
expectation with the following lemma when bt ∈
λt then √t(yb
Lemma 12. If b
(0, ¨c
a′1yb

d
→ N

yb
∞

t −

∈

≥

)

.

∞}
(cid:1)

. We can lower-bound this

→ ∞

∞

(yb
∞

)−

1Σb¨c

∞

(yb
∞

)−

1), where Σb

Cov

≡

u1 >

a11{
(cid:0)

This result is basic, but I haven’t found it elsewhere in the literature. It states that the shadow

prices converge to a multivariate normal. This ﬁnding stems from a textbook empirical processes

result (speciﬁcally, example 3.2.22 of van der Vaart and Wellner (1996)).

Unfortunately, lemma 12 has bite only when bt ∈

λt. So before I can proﬁtably apply it I must

establish that the period-t resource vector has a reasonably high probability of residing in λt under
the optimal policy. To prove this, I will create a few new objects. First, deﬁne ←−z b
n
the order of the customers is reversed; in other words, ←−z b
n
t customers. Note that zbn+ξ

t when
−
n when we disregard the ﬁrst
is the maximum achievable value under the restriction

t equals zb

t as zb
n

t
n−t ξ

−

−

t

+ ←−z

bn
n

−
t
−

that the period-t resource vector equals bn + ξ. Hence, the constraint that the period-t resource
t
n−t ξ
vector equals bn + ξ lowers the total linear-programming reward by ∆ξ
And thus if bt = bn + ξ then the optimal policy must yield a regret of a least ∆ξ
ξ
Ξt ≡ {
bt /
∈

bn + ξ /
∈
λt. The following lemma maintains that the regret is usually high when bt −

bn
zbn+ξ
− ←−z
t
n
t . Finally, deﬁne
bn values, for which

as the set of feasible bt −

m : bn + ξ, bn −

zbn
n −

λt}

t ≡

∈ R

−
t
−

Ξt.

t ξ

≥

∩

0

−

n

.

t

Lemma 13. If T

t,

≡ {

· · ·

, ¯t
, where t
}

log(n)2n3/4

≡ ⌊

and ¯t

⌋

, then Pr
3n/4
⌋

≡ ⌊

√n

≥

2/3 for all suﬃciently large n.

(cid:0)

(cid:1)
This lemma was the hardest result for me to prove. My assumptions only characterize the

process within the strict conﬁnes of λ, so it’s diﬃcult to say anything about the regret when bt /
∈
What’s more, we must wage a two-front war because quantifying ∆ξ
λ and
bn −
that holds uniformly across Ξt.

λ. Finally, ξ could take an uncountable number of values, so we must create a bound

t requires both bn + ξ

t ξ

λ.

∈

∈

−

n

t

22

bn ∈
T inf ξ
mint
∈

Ξt ∆ξ
∈

t ≥

My proof has two parts. First, I deﬁne χ

≡ B2ǫ(0)

\ Bǫ(0) as the “doughnut” of vectors that
λ and

t

n

t ξ

λ, for all t

have length between ǫ and 2ǫ, for ǫ small enough to ensure that ξ
t for all ξ
bn −
some care. First, I cover the space of possible bn + ξ and bn −
that are roughly δ

T . By design, I can bound ∆ξ

t ξ values with a grid of points
3/8 units apart. I then show that there exist constants κ1, κ2, κ3 > 0 that

T . But doing so takes

∈

χ implies bn + ξ

∈
χ and t

n−

∈

∈

∈

∈

−

−

n

t

≡

satisfy

E(u11{

u1 > a′1yb

E(u11{

u1 > a′1yb+δι
)
∞ }

u1 > a′1yb

−
E(u11{
t
n

∞ −

E(u11{
u1 > a′1(yb
∞
t

n

zb+ξ
∞ −

−
n

)
∞}
)
+ δι)
}
t
n−t ξ

b
z
−
∞

δκ1,

≤

δκ2,

≤

κ3.

≥

)
∞}
−
and zb

The last inequality establishes that ∆ξ

t is high in the limit, as n
case, since lemma 7 ensures that yb

→ ∞

. The second inequality maps

case to the n <

n will almost certainly lie
+ δι. And the ﬁrst inequality uniformly extends the result from the ﬁnite

∞

from the n =
between yb
∞

∞
and yb
∞

number of grid points to the uncountable number of Ξt elements, because between every pair
(bn + ξ, bn + ξ + δι) lies a grid point. With this, I show that the expected regret is high if bt −
enters χ at any time t

T . I thus establish that the sample path

bn

bt −
{

bn}t

T normally avoids the
∈

∈

“tube” T

×

χ under the optimal policy.

For the second part of the proof I show that the sample path generally avoids the tube by going

through it, rather than around it—i.e., that it’s more usual for bt −
inside the sphere

bn to spend time horizon T
B2ǫ(0). I proves this by demonstrating that there’s
T for which the regret is unacceptably high when

Bǫ(0) than outside the sphere
a high probability that there is at least one t
∈
bt −

∈ Bǫ(0).

bn /

I establish this result with a benchmark problem that equals the original problem with an extra

constraint that compels the jth element of the resource vector to be less than e′jbn −
H, where H is a binomial(n, 1/2) random variable. I show that this new problem satisﬁes all our

ǫ/√m in period

model assumptions, and hence that we can apply our lemmas to it. (This benchmark problem

would violate assumption 1 if H weren’t a binomial random variable.)

I then use lemma 5 to

calculate the new constraint’s shadow price when n =

and then use lemma 7 to map this back

∞
case. Finally, I integrate this shadow price to compute the total cost imposed by this

to the n <

∞

constraint. I show that any policy that satisﬁes this constraint will probably have a high regret.

I then repeat this exercise to show that the regret is similarly high when the jth element of the

23

resource vector exceeds e′jbn + ǫ/√m in period H. I then repeat for all j
bn||∞
bn||∞
that any policy that yields

> ǫ/√m, and hence

bH −
||

bH −
||

And since H

T with high probability, this implies the result.

∈

1,

, m

to establish

· · ·

∈ {
}
> ǫ, probably high-regret.

We are now ready to assert our lower bound.

Proposition 4. The expected regret under the optimal policy is Ω(log(n)) as n

.

→ ∞

The proof of this proposition is fairly straightforward. Basically, I use lemma 12 to show that
ut)+ are on the order of 1/√t when (i)

the expected values of (ut −
a′tybt
|
that we’re uncertain whether the customer’s utility exceeds the shadow prices of the resources

1/√t, (ii) a′te1 > κ for some κ > 0, and (iii) bt ∈

λt. The ﬁrst condition ensures

)+ and (a′tyψt(bt,0)

a′tyψt(bt,1)

ut| ≤

∞ −

t
−

t
−

−

1

1

they demand, the second condition ensures that the cost of fulﬁlling the customer’s demand is

non-negligible, and the third condition ensures that we’re not subject to any non-zone-of-sanity

weirdness. Second, we show that there’s around a 1/√t probability of satisfying the ﬁrst condition,

a high probability of satisfying the second condition, and a reasonable probability of satisfying
)+ and
the third condition (thanks to lemma 13). Hence, the expected values of (ut −
(a′tyψt(bt,0)
(46) yield the result.

(1/√t) = 1/t. And with this, expressions (43) and

ut)+ are on the order of (1/√t)

a′tyψt(bt,1)

t
−

t
−

−

1

1

·

5 Conclusion

Suppose there are n applicants for nbn open positions and the ﬁrst man you interview has utility

un. Do you classify him as “hired” or “not hired”? Like all classiﬁcation problems, you must

balance between the threat of a Type I error and a Type II error. You make a Type I error when

you extend a job oﬀer and the “shadow price” of an open position exceeds un—in this case, you

took the slot of a more deserving applicant. And you make a Type II error when you don’t extend

an oﬀer and un exceeds the “shadow price” of an open position—in this case, you reserved the

slot for an inferior applicant. The “shadow price” of a position equals the utility of the (nbn)th

best man out of the remaining n
try to anticipate whether or not un exceeds hnbn
−
drops like 1/√n, so we can think of hnbn
−

1. Hence, you must
1. Fortunately, the standard deviation of hnbn
1
−
1 as residing in a “conﬁdence interval” whose length is
on the order of 1/√n. This has two implications. First, you’ll only have around a 1/√n chance

1 candidates, which is order statistic hnbn
−

−

n

n

n

n

of making a hiring mistake, because the optimal action is unambiguous when un falls outside of

the conﬁdence interval. Second, the cost of a hiring mistake is also around 1/√n, because the

24

capability of the man you should have hired and the capability of the man you did hire both reside

in the conﬁdence interval. Thus, the expected regret of your period-n decision will be on the order

of

1/√n

·

1/√n

= 1/n, which means that your total regret grows like the harmonic

mistake probability

mistake cost

series.

| {z }

| {z }

Why does Arlotto and Gurvich’s (2019) result not hold when secretary valuations are continu-

ous? Let me illustrate with an example. Suppose applicant capabilities are drawn uniformly from
∈ N positions to ﬁll. Further, suppose you hire the period-n

and that you start with n/2

3. In this case, the expected ex post regret of your period-n hiring decision is

1,
, 5
{
· · ·
}
man if un ≥

E

(cid:0)

un < 3
}

1{

don’t hire

|

{z

}
≤

hn/2
n
−

(un −

1)+
regret of not hiring.
Pr(hn/2
{z
|
1 ≤
n
−
1
n
−

}

= Pr

+ 1{

un ≥

3
}

(hn/2
n
−

1 −

un)+

hire

regret of hiring (cid:1)

1) + 2 Pr(hn/2
|
{z
n
−

}
1 ≥

|
4)

{z

}

n/2

!

≥

+ 2 Pr

ut = 1
}

1{

Xt=1
binomial(n-1, 1/5)

|

{z

}

n

1

−

ut ≥

4
}

1{

Xt=1
binomial(n-1, 2/5)

.

n/2

!

≥

|

{z

}

And the Chernoﬀ bound ensures that these last two probabilities decrease exponentially in n.

Accordingly, the expected regret of your period-n hiring decision decreases exponentially in n.

Note that hn/2
−

hn/2
n
−

1)+ is positive only when un = 2 and hn/2

1 must be as small as 1 or as large as 4 for you to make a hiring mistake. For
1 = 1. However, if we
= 3. For example,

n
(un −
un < 3
example, 1{
}
with [1, 5] then we can make a hiring mistake for any hn/2
1,
replace
, 5
1 6
· · ·
{
}
−
hn/2
2/√n and hn/2
1)+ is positive when un = 3
(un −
un < 3
n
1 ≤
}
1{
−
−
1/√n with domain [1, 5] than it is to get hn/2
to get hn/2
1 = 1 with domain
3
1 ≤
−
−
1 to be within a O(1/√n) window of 3 under both
is within a O(1/√n) window of 3—

To put it diﬀerently, we should expect hn/2
−

1/√n. And it’s a lot easier

.
, 5
}

1,
{

· · ·

−

−

−

3

−

n

n

n

n

n

n

· · ·

, 5
}

and [1, 5]. However, only one element of

, 5
1,
{
}
namely the number 3 itself. So if valuations are restricted to
you don’t perfectly forecast hn/2
−

1,
{

· · ·

n

1—and hence the probability that you make a hiring mistake—falls
exponentially fast. However, if valuations are uniform across [1, 5] then you will never perfectly
forecast hn/2
−

1. In this case, the magnitude of your forecast errors—and hence the probability that

n

1,
{

· · ·

, 5
}

then the probability that

you make a hiring mistake—falls like 1/√n.

The same principle holds in the more general “online linear programming” (OLP) problem. But

extending the multisecretary problem to the full OLP problem was not a trivial undertaking (as I

hoped it would be). Indeed, the OLP problem took me at least an order of magnitude longer to

25

 
 
solve (even though I had the multisecretary solution to work oﬀ of). The OLP problem oﬀers two

new challenges.

First, resource vector values can be verboten. For example, suppose that ut is drawn uniformly

from [2, 3] and that at ∈ R is drawn uniformly from [0, 1]
shadow price has a 50% chance of being less than 3/4 and a 50% chance of being greater than 2,

[4, 5]. If bn = 1/2 then the resource’s

∪

which means that the “conﬁdence interval” of the shadow price is at least 2 - 3/4 units long. And

since this length doesn’t drop like 1/√n we shouldn’t expect the regret to grow like log(n) in this

case. Accordingly, my argument fails under the b

= 1/2 limiting condition. But it does not fail

∞

for any other limiting value, because my assumptions only require shadow price continuity in a

neighborhood of b

∞

. Since they apply to an arbitrarily small region, these local assumptions are

highly permissive. But to accommodate these weak assumptions I must constrain random walks
n
Bt}
t=1 to a tiny space. For the upper bound, I constrain the process by “burning”
{
inventory at just the right rate to make Bt follow a martingale, which ensures a concentration

n
t=1 and

bt}
{

of measure. For the lower bound, I constrain the process by (i) creating a moat around b

∞

, (ii)

showing that there’s a high probability that the process doesn’t touch this moat over a certain

range of time, and (iii) showing that there’s a high probability that the process spends at least one

period inside the moat (i.e., near b

).

∞

The second diﬃculty of the OLP problem is that there’s no easy way to integrate over its

shadow prices. Computing E(¯rt) and E(rt) requires integrating a non-smooth function over the
joint distribution of ut, at, and either htb
1. This integral is tractable in the multisecretary
t
−
problem because htb
1 has a simple beta distribution, but it’s intractable in the OLP problem
t
−
because yb
1 converges to
t
−
a multivariate normal (with appropriate scaling) requires surprisingly advanced empirical processes

1 doesn’t have a closed-form distribution. In fact, even showing that yb
t
−

1 or yb
t
−

machinery. And this weak convergence result is useless for the upper bound, because it guarantees

nothing about the shadow price’s moments. Instead, for the upper bound I must separately control

(i) the probability that

yb
t −
||
on it exceeding ǫ, and (iii) the second moment of

yb
∞||

yb
t −
||
conditional on it not exceeding ǫ. And

conditional

yb
∞||

exceeds some ǫ > 0, (ii) the ﬁrst moment of

yb
t −
||

yb
∞||

controlling this last element also requires an empirical processes technique.

6 Acknowledgments

Many thanks to Siddhartha Banerjee, Itai Gurvich, Ioannis Stamatopoulos, and three anonymous

reviewers for their very insightful feedback.

26

Proofs

In the following proofs I will use

Bǫ(y)

x :

≡ {

x
||

y

||

−

< ǫ

}

The domain of this ball will be context speciﬁc.

to denote the ǫ-ball about vector y.

I will also use yλ

yb
∞ ∈ R

m
+ : b

λ

}
∞ ≡ {
to the resource vectors in λ. And I will use
that are within ǫ of any the shadow prices in yλ
∞
b

Finally, I will use “super-gradient” ˙cb

∈

t (y)

if cb

t (y) is diﬀerentiable at y.

S
s=1 as1{

t

≡

−

P

to refer to the limiting shadow prices that correspond
Bǫ(yλ
yλ∞ Bǫ(y) to refer to the shadow prices
.

≡

∞

)

∈

y

us > a′sy

/t. Note that ∂
}

∂y cb

t (y) = ˙cb

t(y)

Lemma 1 Proof. If b = 0 then the result holds trivially. And if b > 0 then lemma 14 yields the

result:

E(¯rt : ¯bt = b)

htb
t
−

b

(ut −
}
bt)
(1

−

−

−

−

1)+ + 1{
b)(1

−

b) + (1

−

ut > 1

b

(htb
t
}
−
−
b)2/2

ut)+

1 −

(cid:1)

= E

1

(1

1{

(cid:0)
−

ut ≤
b)(1 + t
2(t + 1)
b)
b(1
−
2t + 2

.

=

=

Lemma 2 Proof. If b = 0 then the result holds trivially. And if b > 0 then lemma 14 yields the

result:

E(rt : bt = b) = E
(1

=

τ b
(ut −
t }
bt)
−

htb
1)+ + 1{
t
−
τ b
t (1

ut > τ b
t }
t )2/2

b) + (τ b

−

−

(htb
t
−

ut)+

1 −

(cid:1)

−

b)(1 + t
2(t + 1)

bt)

−

τ (1

−

−

b) + τ 2/2

1{

(cid:0)
−

ut ≤
b)(1 + t
2(t + 1)
(1

≥

=

inf
τ
[0,1]
∈
b)
b(1
−
2t + 2

= E(¯rt : ¯bt = b).

Lemma 3 Proof. It is straightforward to conﬁrm that

q
s=1 hs

t and

P

P

27

q
s=1 ←−h s

t have mean µq

t and

standard deviation σq

t , where

µq
t ≡

q(2t + 1

−
2(t + 1)
q)

q(2t

−
2t

q)

q(2t

−
2t

1,

−

q)

+ 1

q(q + 1)(4qt + q + 2t + 2
12(t + 1)2(t + 2)

i
−

3q2)

∈

h

and σq

t ≡s

√2t.

≤

Now choose n large enough so that t(1

≥
bounds above with (11) yield the following for all t

−

∞

b

)2/64

3 and t

≥

n2/3/2. In this case, combining the

E(∆ξt

t ) = E

nbn

t(bn+ξt)

hs
n −

hs
t −

T :

∈

t)(bn

(n

−

−

t
n−t ξt)

hs
n

t

−

(cid:17)

s=1
X

s=1
X

(cid:16)
=µnbn

n −
nbn(2n

µt(bn+ξt)
t
nbn)

µ

(n
n

−
t
−

−

t)(bn

−

s=1
X
t
n−t ξt)

t(bn + ξt)(2t

t(bn + ξt))

−
2n

(n

−

−

−
t)(bn −

t

−

n

t ξt)
(cid:0)

−
2t
2(n

t)

−
2(n

−
t)

−

≥

≥

≥

3

tξ2

t /2

−
n2/3(1

)2/27.

b

∞

−

(n

t)(bn −

−

t

−

n

t ξt)
(cid:1)

3

−

Note that we also have

StDv(∆ξt
t )

3 max

StDv

≤

nbn

t(bn+ξt)

, StDv

hs
n

!

s=1
X

t)(bn

−

, σ

(n
n

−
t
−

s=1
X
t
n−t ξt)

(cid:17)

=3 max

n , σt(bn+ξt)
σnbn
(cid:16)
3√2n.

t

≤

, StDv

hs
t

!

t)(bn

(n

−

−

t
n−t ξt)

s=1
X

hs
n

t

−

!!

Accordingly, if we choose n large enough so that √n

n2/3(1

b
∞

−

≤

)2/28 then Chebyshev’s inequality

28

 
 
 
 
implies that

Pr(∆ξt

t ≤

√n)

Pr

≤

∆ξt

t ≤

n2/3(1

)2/28

−

b

∞
2

(cid:1)

)2/28 !

(cid:0)

≤  

n2/3(1

=

32217n−
(1

b

−

∞

3√2n
b

∞

−
1/3
)4 .

And this last expression is less than 1/16 when n is large.

Lemma 4 Proof. Since ht(bn+ξt)

t

and ←−h

t)(bn

−

t
n−t ξt)

(n
n

−
t
−

are independent beta random variables, it’s

straightforward to bound the mean and standard deviation of their diﬀerence. Speciﬁcally, for n

large enough to satisfy t(1

b

∞

−

) > 8bn, expression (11) implies the following for t

T :

∈

E

←−h

and

StDv

(cid:0)

←−h

(cid:0)

(n
n

−
t
−
(n
n

−
t
−

t)(bn

t)(bn

−

−

t
n−t ξt)

t
n−t ξt)

ht(bn+ξt)
t

ht(bn+ξt)
t

(cid:1)

−

−

≥

≤

(1

b

∞

−

)/16

2/

t.

(cid:1)

p

And with these expressions, Chebyshev’s inequality implies that Pr(ht(bn+ξt)

t

0 as n

.

→ ∞

> ←−h

(n
n

−
t
−

t)(bn

−

t
n−t ξt)

)

→

Lemma 5 Proof. First, bounds (24) and (25) follow immediately from assumption 6.

Second, if ¨c

∞

(yb0
∞

) is invertible for some b0 ∈ R

>0 and if yb
m
∞

of b0 then the implicit function theorem establishes that

> 0 for all b in some neighborhood

b=b0,y=y
(cid:12)
(cid:12)

∂b yb∞
∞

=

∂

∂b yb0

∞

=

¨c
∞

−

(y)−

∂b ˙cb
1 ∂

∞

(y)

=

b0
∞

¨c
∞

(yb0
∞

−

)−

1.

(47)

And with this, assumptions 7 and 8 establish that ∂

¨c
∞

(yb∞
∞

−

)−

1. And this implies that we

can set λ small enough so that if b

λ then

∈

yb
∞ −
||

yb∞
b
∞ || ≤ ||

−

b

/θ1,

∞||

(48)

where θ1 is half of the smallest singular value of ¨c

∞

(yb∞
∞

), which is strictly positive, by assumption

Third, assumption 9 ensures that there exists ζ > 0 such that if

8. And with this, it’s straightforward to establish conditions (26) and (27).
yb∞
∞ || ≤
yb∞
∞ || ≤

(y) is at least θ1. Thus, if

y
||
yb
∞ −
||

singular value of ¨c

ζθ1 then

∞|| ≤

b
||

−

−

∞

b

ζ then the smallest

ζ and the smallest

29

singular value of ¨c

(yb
∞
an eigenvalue, which establishes that we can set λ small enough to fulﬁll condition (29). Similar

) is symmetric, its smallest singular value is also

) is at least θ1. Since ¨c

(yb
∞

∞

∞

reasoning yields conditions (30) and (31).

⊂ R

at b = b

∞

Fourth, deﬁne sets ξ

>0 and ˜ξ
m
such that ξ
×
we can choose ω small enough so that yˆb
= yb∞
∞
˜ξ and restrict ˜λ
B(1+2√m)ν(˜b
˜ξ. Since ˜b
−

) and hence ˜b

ν > 0 small enough so that
∈ B(1+2√m)ν (˜b
˜b

∞
2νι

⊂ R

M
>0

2νι

2νι

−

⊂

∈

∞

m

−

)

∞ −

˜ξ
Ω. Since ∂
⊂
2ωι for some ˆb

∂b yb
∞

∈

ξ. Now choose
˜λ then

). In this case, if ˜b

∈

ξ, assumption 7 implies

∈

⊂ Bν(˜b
∈

∞
˜ξ and ˆb

is non-singular

−
that

˜b

2νι

E

−

−

˜a11{

u1 > a′1y

(cid:0)

0,

≥

ˆb
∞}
(cid:1)

because otherwise one of the latter M
yb
∞ −

which with (48) implies that supb
λ ||
∈
yields (28).

−

m constraints would bind. Next, impose λ
yb∞
∞ || ≤

ω. And combining this with the inequality above

⊂ Bωθ1(b

∞

),

Fifth, the convexity of λ ensures that if b1, b2 ∈

λ then (1

−

Thus by (27) we ﬁnd that yb
∞
by (29) and (47) we ﬁnd that ∂

> 0 for all b in some open neighborhood of (1
∂b y(1
which is no more than 1/θ1. And with this we get condition (32):

(y(1
−
∞

γ)b1+γb2

γ)b1+γb2

¨c
∞

)−

−

=

∞

−

γ)b1 + γb2 ∈
−

λ for all γ

[0, 1].

∈

γ)b1 + γb2 and thus
1, the largest singular value of

(cid:12)
(cid:12)
Z
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
Z
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
Z

yb2
∞ −
||

yb1
∞||

=

=

≤

≤

=

1

γ=0
1

γ=0 −
1

∂

∂b y(1

∞

−

γ)b1+γb2

(b2 −

¨c
∞

(y(1
−
∞

γ)b1+γb2

)−

b1)dγ

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
1(b2 −
b1)dγ
(cid:12)
(cid:12)

¨c
∞

(y(1
−
∞

γ)b1+γb2

)−

1(b2 −

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

dγ

b1)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

γ=0
1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
b2 −
γ=0 ||
Z
b2 −
||

b1||

/θ1.

/θ1dγ

b1||

Sixth, assumption 9 implies that there exists r, C > 0 such that if y1, y2 ∈ B2r(yb∞

∞

) then

(¨c
||

∞

(y2)

¨c
∞

−

(y1))v

C

y2 −
||

v
y1||||

||

.

|| ≤

Now impose λ
yb
∞

∈ B2r(yb∞

+ v

⊂ Brθ1(b
∞
), and thus have

), which with (48) implies yb
(yb
∞

+ hv)

(¨c
||

¨c
∞

∞ ∈ Br(yb∞
∞
(yb
hC
))v
|| ≤
∞

−

∞

∞

v
||

||

). Thus, for
2, for h

v
||

< r we have

||
[0, 1]. And since

∈

30

˙cb
∞

(yb
∞

) = 0 for all b

∈

λ, by (27), this implies for

< r:

v
||

||

˙cb
∞

sup
λ ||
b
∈

(yb
∞

+ v)

¨c
∞

(yb
∞

)v

||

−

¨c
∞

(yb
∞

+ hv)vdh

¨c
∞

(yb
∞

)v

−

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

+ hv)

¨c
∞

(yb
∞

−

))v

dh

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1

) +

(yb
∞

h=0

Z
(yb
∞

(¨c

∞

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
v
||

2dh

||

˙cb
∞
1

= sup
λ (cid:12)
b
(cid:12)
∈
(cid:12)
(cid:12)
(cid:12)
(cid:12)
sup
(cid:12)
(cid:12)
λ Z
b
h=0
∈
1

≤

hC

2/2

).

h=0

≤

Z
=C

v
||
||
v
=o(
||

||

And this establishes limit (33).

Finally, (34) follows immediately from assumptions 8 and 9.

Lemma 6 Proof. Choose t large enough so that Bn ∈
policy forces ¯Bt ∈

Λ, and thus expression (24) and assumption 5 force

Λ for all n

≥

t. In this case, the martingale

¯Bt −
||

¯Bt
−

1||∞ ≤

3α/(t

1).

−

(49)

Next, since the sets λt and ˜λt increase in t, we can choose ǫ > 0 small enough so that
Λt holds for all suﬃciently large t and n

⊆
t. And since ¯Bt follows a martingale that satisﬁes

Bǫ( ¯Bn)

e′j
|

¯Bt −

e′j

¯Bt
−

1| ≤

3α/(t

−

1), by (49), the Azuma–Hoeﬀding inequality implies

≥

Pr( ¯Bt /
∈

sup
t
N

≥

Λt : n = N )

≤

sup
t
N

≥

≤

sup
t
N

≥

≤

sup
t
n

≥

Pr( ¯Bt /

∈ Bǫ( ¯Bn) : n = N )

M

Pr

e′j
|
Xj=1
(cid:0)
2M exp

ǫ/√M : n = N

¯Bn −

e′j

M

¯Bt| ≥
2ǫ2
n
s=t+1 9α2/(s
2ǫ2
P
∞s=t 9α2/(s
1)

1)2ds

−

−

(cid:16)

(cid:1)

1)2

(cid:17)

−

(cid:17)

<2M exp

=2M exp

−

−

(cid:16)

(cid:16)

M
2ǫ2(t
R
−
9M α2

.

(cid:17)

31

Lemma 7 Proof. Since it’s symmetric and nonsingular, ¨c
tors vb
1,
· · ·
conﬁrms that gb

m that correspond to strictly positive real eigenvalues gb
1,

θ1 when b

, vb

λ.

∞

(yb
∞

j ≥

∈

) has a set of orthonormal eigenvec-

, gb

m. Expression (29)

· · ·

Expressions (27) and (33) imply that there exists δ > 0 such that for all suﬃciently small ǫ > 0

we have

and

˙cb
||
∞

(yb
∞

+ ǫkvb
j )

−

j vb

j||∞

+ ǫkvb

j >0

yb
∞
ǫkgb

<δǫ/2,

(50)

for all b

λ, j

1,

∈ {

· · ·

, m

∈

C > 0 that satisﬁes for all t

and k
}
∈ N, b

∈ {−
m
+ , j

∈ R

. Furthermore, lemma 18 implies that there exists
1, 1
}

1,

∈ {

, m

, and k
}

· · ·

∈ {−

1, 1
}

Pr

(cid:0)
≤

t (yb
˙cb
||
∞
m

+ ǫkvb
j )

˙cb
∞

(yb
∞

−

+ ǫkvb
j )

Pr

e′ℓ ˙cb
|

t(yb
∞

+ ǫkvb
j )

e′ℓ ˙cb
∞

−

||∞
(yb
∞

> δǫ/2

(cid:1)
+ ǫkvb
) > δǫ/2
j |

(cid:1)

Xℓ=1
m

(cid:0)
2 exp(

−

≤

Xℓ=1
=2m exp(

−

Cδ2ǫ2t/4)

Cδ2ǫ2t/4).

(51)

ǫkgb

j vb

j||∞

.

Now deﬁne

ξb
t ≡

m
max
j=1

max
1,1
∈{−

}

k

t (yb
˙cb
||
∞

+ ǫkvb
j )

−

32

Expressions (50) and (51) imply that for all b

λ we have

∈

Pr(ξb

t > δǫ)
m

≤

≤

≤

Xj=1 Xk
1,1
∈{−
m

}

Xj=1 Xk
1,1
∈{−
m

}

Xj=1 Xk
1,1
∈{−
m

}

Pr

Pr

Pr

t (yb
˙cb
||
∞
(cid:0)

t (yb
˙cb
||
∞
(cid:0)

t (yb
˙cb
||
∞
(cid:0)

+ ǫkvb
j)

−

ǫkgb

j vb

j ||∞

> δǫ

(cid:1)

+ ǫkvb
j)

˙cb
∞

(yb
∞

−

+ ǫkvb
j)

||∞

+

˙cb
||
∞

(yb
∞

+ ǫkvb
j )

−

+ ǫkvb
j)

˙cb
∞

(yb
∞

−

+ ǫkvb
j)

||∞

> δǫ/2)

ǫkgb

j vb

j ||∞

> δǫ

(cid:1)

2m exp(

−

Cδ2ǫ2t/4)

≤

≤

Xj=1 Xk
1,1
∈{−
4m2 exp(

}
Cδ2ǫ2t/4).

−

Next, for b

λ and q

∈ R+ deﬁne the sets

∈

m

Θb

q ≡

ˆΘb

q ≡

and

˜Θq ≡

\j=1 \k
∈{−
m

1,1

} (cid:8)

\j=1 \k
∈{−
m

1,1

} (cid:8)

\j=1 \k
∈{−

1,1

} (cid:8)

x

x

x

m :

ν

[
−

∈

∃

∈ R

q, q]m s.t. (x

m :

ν

[
−

∈

∃

∈ R

q, q]m s.t. (x

m :

ν

[
−

∈

∃

∈ R

q, q]m s.t. (x

−

−

−

kvb

j )′(kgb

j vb

j + ν)

kvb

j )′(kθ1vb

j + ν)

kej)′(kθ1ej + ν)

≤

≤

≤

0

,

(cid:9)

0

,

(cid:9)

0

.

(cid:9)

|| ≤

√m

x
||

||∞ ≤

x :
, vb

x
||
m are orthonormal, the set ˆΘb

Since ˜Θ0 =
x :
1
} ⊂ {
{
Also, since eigenvectors vb
1,
· · ·
means that we also have ˆΘb
2√m
x
. Next, if b
δ ⊆ {
||
}
ˆΘb
δ, and hence that Θb
which implies that Θb
x
δ ⊆ {
|| ≤
||
. If ξb
Now deﬁne hb
0
t (y)
t ≤
}

m
+ : (x

y)′ ˙cb

t (y)

∈ R

δ ⊆

≡ {

|| ≤

x :

x :

≤

−

∈

x

, we can ﬁnd δ > 0 such that ˜Θδ ⊆ {
}

x :

x
||

2√m

.
}
δ is a rotation of the set ˜Θδ, which
,
}

θ1, for all j

j ≥

|| ≤

∈ {

, m

· · ·

1,

λ then gb

t(yb
∞

+ ǫkvb

j )/ǫ

−

kgb

j vb

j ∈

2√m

.
}
δǫ then ˙cb

33

δ, δ]m, which implies that

[
−

m

hb
t(yb
∞

+ ǫkvb
j )

\j=1 \k
∈{−
m

1,1

}

x

m
+ : (x

yb
∞ −

−

ǫkvb

j )′

∈ R

ǫkgb

j vb

j + ( ˙cb

t (yb
∞

+ ǫkvb
j)

ǫkgb

j vb
j )

−

0

≤

(cid:1)

(cid:9)

kvb
j

′

kgb

j vb

(cid:0)
j + ( ˙cb

t (yb
∞

+ ǫkvb

j )/ǫ

kgb

j vb
j )

−

0

≤

(cid:1)

(cid:9)

=

=

1,1

\j=1 \k
∈{−
m
+ :
x

∈ R

} (cid:8)

(x

(cid:8)
x
⊆{

x

⊆{

m
(cid:0)
+ : (x

∈ R

m
+ :

x
||

∈ R

−

−

)/ǫ

yb
∞
)/ǫ

−
yb
∞
yb
∞|| ≤

(cid:1)

−
Θb
δ}
∈
2ǫ√m
.
}

(cid:0)

Moreover, lemma 16 conﬁrms that yb

t ∈

results yields

m
j=1

k

1,1

}

∈{−

t (yb
hb
∞

+ ǫkvb

j), which with the preceding

T

T

yb
Pr(
t −
||

yb
∞||

> 2ǫ√m) = Pr

x

yb
t /
m

∈ {

∈ R

m
+ :

x
||
t (yb
hb
∞

yb
∞|| ≤

−

2ǫ√m

+ ǫkvb

j ) *

x
{

}
(cid:1)
∈ R

m
+ :

x
||

−

yb
∞|| ≤

2ǫ√m
}
(cid:17)

(cid:0)

Pr

(cid:16)
Pr(ξb

\j=1 \k
∈{−
t > δǫ)

1,1

}

4m2 exp(

−

Cδ2ǫ2t/4).

≤

≤

≤

Lemma 8 Proof. Expression (26) implies that for all γ > 0 we have

E(1{||

yb
t −

yb
∞||

> ǫ

yb
t −

}||

yb
∞||

)

sup
λ
b
∈

E

E

1{||
(cid:0)
1{||
(cid:0)
1{||
(cid:0)
γ Pr

≤

≤

≤

sup
λ
b
∈
sup
λ
b
∈
+ E

sup
λ
b
∈

yb
t −

yb
t −

yb
∞||

yb
∞||

> ǫ

yb
(
t ||
||
}

+

yb
∞||
||

)

> ǫ

yb
t ||

}1{||

< γ

yb
t −
yb
t −
||

yb
∞||
yb
∞||

> ǫ

yb
t || ≥

}1{||

γ

> ǫ

+ E

1{||

}||

(cid:1)
yb
t ||
(cid:1)
yb
yb
+ η Pr(
t −
∞||
||
yb
+ η Pr(
t −
||

yb
t ||

}||

yb
t ||

}||
yb
(cid:1)
γ
t || ≥

> ǫ)

(cid:1)

yb
∞||

> ǫ).

(cid:0)
And with this, lemmas 7 and 15 imply the result.

(cid:0)

(cid:1)

Lemma 9 Proof. Identity (29) ensures that (yb

t −

yb
∞

)′¨c

∞

(yb
∞

)(yb

t −

)

yb
∞

θ1||

yb
t −

yb
∞||

≥

2

when b

λ.

∈

34

And identity (33) implies that we can choose ǫ > 0 small enough to ensure that

˙cb
||
∞

(yb
∞

+ (yb

t −

)/2)

yb
∞

¨c
∞

(yb
∞

−

)(yb

t −

yb
∞

)/2

|| ≤

θ1||

yb
t −

yb
∞||

/4

λ and yb

t ∈ Bǫ(yb

∞

). Combining these two results yields for b

∈

λ, yb

t ∈ Bǫ(yb

∞

), and

when b
(yb
ˆyb
t ≡

∈
t + yb
∞

)/2

(yb

t −

(ˆyb
t )

)′ ˙cb
∞

yb
∞
=(yb

=(yb

)/2)

)′ ˙cb
∞

)′¨c

t −

yb
∞
yb
t −
∞
+ (yb

+ (yb

)(yb

(yb
∞
(yb
∞
˙cb
∞

)′

t −
(yb
∞

yb
∞
)/2

t −
yb
∞
+ (yb

∞
yb
∞
2
/2

2

2

/2

−

/4.

t −
yb
∞||
yb
∞||
yb
∞||

≥

θ1||
θ1||
≥
=θ1||

yb
t −
yb
t −
yb
t −

¨c
∞

)/2)

−
+ (yb

t −

yb
∞
(yb
∞

t −
˙cb
∞
2
/4

(cid:0)
− ||

yb
t −
yb
t −

yb
∞||||
yb
∞||

θ1||

)(yb

(yb
∞
)/2)

yb
∞

)/2

yb
∞
(yb
∞

t −
¨c
∞

−

)(yb
(cid:1)

t −

yb
∞

)/2
||

(52)

Next, lemma 16 indicates that (yb

t −

ˆyb
t )′ ˙cb

t (ˆyb
t )

≤

0 and thus that

(yb

t −

yb
∞

)′ ˙cb

t (ˆyt)

0.

≤

Combining this with (52) yields for b

∈

λ and yb

t ∈ Bǫ(yb

∞

)

t (ˆyb
˙cb
t )
||

−

˙cb
∞
yb
t −
= ||
yb
t −
||
(yb
t −
yb
t −
||
(yb
t −
yb
t −
||
yb
θ1||
t −

(ˆyb
t )
||
yb
∞||
yb
∞||
yb
)′
∞
yb
∞|| (cid:0)
yb
)′
˙cb
∞
yb
∞
∞||
yb
∞||

≥

≥

≥

/4.

˙cb
t (ˆyt)
||

˙cb
∞

(ˆyb
t )
||

−

˙cb
∞

(ˆyb
t )

−

t(ˆyb
˙cb
t )

(cid:1)

(ˆyb
t )

35

And with this, lemma 17 establishes that for suﬃciently small ǫ > 0 there exists C > 0 that satisﬁes

sup
λ
b
∈

E

(cid:0)
≤

≤

≤

≤

2

1{

∞

(cid:1)
yb
t −

1{

yb
∞||

t ∈ Bǫ(yb
yb
yb
)
t −
}||
t ∈ Bǫ(yλ
yb
)
E
}||
t ∈ Bǫ(yλ
ˆyb
E
˙cb
sup
t (y)
ǫ(yλ∞) ||

1{

E

∞

∞

(cid:0)

y

sup
b
λ
∈
16/θ2

(cid:0)
1 sup
λ
b
∈
1 sup
λ
b
∈
16C/(tθ2
1).

16/θ2

∈B

(cid:0)

)
}||

2

yb
∞||
(cid:1)
t (ˆyb
˙cb
t )

˙cb
∞

−

(y)
||

−
2

2

˙cb
∞

(ˆyb
t )
||

(cid:1)

(cid:1)

Proposition 3 Proof. Expression (42) establishes that it suﬃces to prove that supN
is O(1/t) as t

.

t E(¯rt : n = N )

≥

First, if Bn ∈

Λ then ¯bt, ¯bt
−
Moreover, assumption 5 and expression (24) imply that

λ, in which case (32) implies that

1 ∈

¯bt−1
∞ −

y
||
¯bt|| ≤

2α/(t

−

y¯bt
∞|| ≤ ||

¯bt
−

¯bt||

/θ1.

1 −
1). Hence, for

¯bt
||
−

1 −

→ ∞

suﬃciently large n we have:

y

¯bt
∞|| ≤
2

2α

θ1(t

1)

−
2α

1 −

y
||

¯bt−1
t
−
¯bt−1
t
−

1 −

y

¯bt
∞||

+

y
||

θ1(t

1)

−
2α

+

y
||
2

and

y
||

y

¯bt−1
∞ ||

¯bt−1
t
1 −
−
¯bt−1
t
−

1 −

2

y

¯bt−1
∞ ||

y
+ 2
||

¯bt−1
t
−

1 −

y

¯bt−1
t
−

1 −

y

¯bt−1
∞ ||

.

(cid:17)
¯bt−1
∞ ||
2

2

(53)

(54)

1)

−
(cid:17)
y
1)2 + 2
||

(cid:16)
2

≤

≤

=

θ1(t
8α2

(cid:16)

θ2
1(t

−

36

Second, (53) yields the following for a given ǫ > 0:

1{

E

(cid:0)

¯Bt ∈
E

≤
= E

(cid:0)

E

(cid:0)

E

(cid:0)

1{

1{

1{

1{

y
Λt}1{||
¯bt ∈
¯bt ∈
¯bt ∈
¯bt ∈
¯bt ∈
Pr

¯bt−1
t
−

1 −
¯bt−1
λt}1{||
y
t
−
¯bt−1
y
λt}1{||
t
−
¯bt−1
λt}1{||
y
t
−
¯bt−1
λt}1{||
y
t
−
y
λt}1{||
¯bt ∈
(cid:0)
¯bt ∈
Pr
sup
λ
b
∈
E

(cid:0)
yb
t
1{||
−
(cid:0)

1{
(cid:0)
1)

(cid:0)
α E

1{
2α2
(cid:0)
θ1(t

1)

−
+ α E
2α2

θ1(t

−
+ α sup
λ
b
∈

≤

≤

≤

≤

≤

y

¯bt−1
∞ ||
y

1 −

1 −

1 −

1 −
¯bt−1
t
−

1 −

> ǫ

ut ≤

}1{

¯rt

}1{

}1{

}1{

¯bt
a′ty
∞}
ut ≤
ut ≤
ut ≤
¯bt
a′ty
∞ −
¯bt−1
t
−

y
}||

1 −

}||
> ǫ

y

y

y

> ǫ

> ǫ

> ǫ

> ǫ

¯bt−1
∞ ||
¯bt−1
∞ ||
¯bt−1
∞ ||
¯bt−1
∞ ||
¯bt−1
y
∞ ||

a′ty

¯bt
(cid:1)
a′ty
∞}
¯bt
∞}
¯bt
∞}

a′ty

)+

(ut −
(ut −
¯bt
(a′ty
∞ −

a′tyψt(¯bt,0)
t
1
−
¯bt−1
1 )+
a′ty
t
−
¯bt−1
1 )+
(cid:1)
a′ty
t
−

(cid:1)

(cid:1)

(cid:1)

¯bt−1
a′ty
t
1 ||
−
¯bt
∞||
(cid:1)

y

> ǫ

λt ∩ ||
y
y
λt}1{||
yb
t
||
−

1 −

1 −

¯bt−1
t
−
¯bt−1
1 −
t
−
yb
∞||

y

¯bt−1
∞ ||
¯bt−1
∞ ||

y

> ǫ

> ǫ

(cid:1)
y
}||

¯bt−1
t
−

1 −

y

¯bt−1
∞ ||
(cid:1)

1 −

yb
∞||

> ǫ

(cid:1)
yb
t
}||
−

yb
∞||

.

1 −

(cid:1)

Note that the last expression is independent of n because it’s independent of ¯bt. And analogous
. Ac-
argument yields the same bound for E

> ǫ

y

¯Bt ∈

y
Λt}1{||

¯bt−1
t
−

1 −

¯bt−1
∞ ||

ut > a′ty¯bt
∞}

¯rt

}1{

cordingly, lemmas 7 and 8 establish that there exist C1, C2 > 0 such that for all suﬃciently small

(cid:1)

1{
(cid:0)

ǫ and large t we have

E

sup
t
N

≥

¯Bt ∈
2α2

1{
(cid:0)

≤

θ1(t

1)

−

y
Λt}1{||

¯bt−1
t
−

1 −

y

¯bt−1
∞ ||

> ǫ

¯rt : n = N
}

exp(

−

C1t) + α exp(

−

C2t).

(cid:1)

(55)

37

Third, expression (54) yields the following:

y
Λt}1{||
¯bt ∈
¯bt ∈
¯bt ∈

1{

1{

1{

ǫ

}1{

y

¯bt−1
∞ || ≤
y

1 −

¯bt−1
t
−

1 −
λt}1{||
y
y
λt}1{||

¯bt−1
t
−
¯bt−1
t
−

1 −

¯bt−1
∞ || ≤
¯bt−1
∞ || ≤

y

ut ≤
ǫ

}1{

ǫ

}1{

y
λt}1{||

¯bt−1
t
−

1 −

y

¯bt−1
∞ || ≤

ǫ

}

Z

¯rt

¯bt
a′ty
∞}
ut ≤
ut ≤
¯bt∞
a′
ty

u=a′

¯bt−1
ty
t−1
¯bt∞
a′
ty

1{

E

(cid:0)

¯Bt ∈
E

≤
= E

= E

(cid:0)

(cid:0)

(cid:16)

¯µu E

¯bt
(cid:1)
a′ty
∞}
¯bt
∞}

a′ty

(ut −
(ut −

a′tyψt(¯bt,0)
t
1
−
¯bt−1
1 )+
a′ty
t
−

)+

(cid:1)

µu

at)(u
a(u
|

|

−

(cid:1)
¯bt−1
a′ty
t
−

1 )du

(cid:17)

y
λt}1{||

¯bt−1
t
−

1 −

y

¯bt−1
∞ || ≤

ǫ

}

u=a′

ty

¯bt−1
t−1

(u

−

a′ty

¯bt−1
t
−

1 )du
(cid:17)

≤

≤

≤

≤

≤

(cid:16)

¯bt ∈
1{
¯bt ∈

¯bt−1
t
−

1 −
y
λt}1{||

¯µu E

1{
(cid:0)
¯µuα2/2 E
4¯µuα4
θ2
1(t
−
4¯µuα4
θ2
1(t

y
λt}1{||
¯bt ∈
1{
(cid:0)
1)2 + ¯µuα2 E
1{
(cid:0)
1)2 + ¯µuα2 sup

E

λ

¯bt ∈

b
∈

−

Z
(a′ty
}

¯bt−1
t
−

y

ǫ

¯bt−1
∞ || ≤
¯bt−1
y
∞ || ≤
¯bt−1
t
−

1 −
y
λt}1{||

¯bt
∞ −
y
}||

ǫ

a′ty

1 −

¯bt−1
t
−
¯bt−1
∞ || ≤

y

1 −

¯bt−1
t
−
y

1 )2/2
2
¯bt−1
(cid:1)
∞ ||

ǫ

y
}||

¯bt−1
(cid:1)
1 −
t
−

y

¯bt−1
∞ ||

2

yb
t
−

1{||

yb
∞|| ≤

ǫ

yb
t
−

}||

1 −

1 −

(cid:0)

2

yb
∞||

.

(cid:1)

(cid:1)

Note that the last expression is independent of n because it’s independent of ¯bt. And an analo-
¯Bt ∈
.
gous argument yields the same bound for E

1 −
Accordingly, lemma 9 establishes that there exists C3 > 0 such that

ut > a′ty¯bt
∞}

¯bt−1
∞ || ≤

y
Λt}1{||

¯bt−1
t
−

}1{

1{

¯rt

y

ǫ

(cid:0)

E

sup
t
N

≥

1{
(cid:0)

¯Bt ∈
4¯µuα4
θ2
1(t

≤

−

y
Λt}1{||

¯bt−1
t
−

1 −

y

¯bt−1
∞ || ≤

ǫ

¯rt : n = N
}

1)2 + ¯µuα2C3/(t

1).

−

(cid:1)

Fourth, lemma 6 asserts that there exists C4 > 0 such that for suﬃciently large t we have

E

sup
t
N

≥

¯Bt /
∈

¯rt : n = N

Λt}

1{
(cid:0)
= sup
t
N

≥

exp(

−

≤

E

¯Bt /
∈

Λt}

1{

(cid:16)
C4t)t E(u1).

(cid:1)

t

Xs=1

us : n = N

(cid:17)

And combining (55)–(57) yields the result.

Lemma 10 Proof. First, the linear program in (18) will partially satisfy at most M customers.

38

(cid:1)

(56)

(57)

Hence, the integer program in (16) with initial resource endowment nBn can fully satisfy all the

customers that the linear program in (18) will fully or partially satisfy with resource endowment
nBn −

M αι. And this implies that

W Bn

n ≥

Z Bn
n

−

M αι/n

.

Second, lemma 11 establishes that there exists K > 0 such that for suﬃciently large n we have

E(Z Bn
n

−

M αι/n

)

E(zbn
n

−

E(zbn
n )

≥

≥

−

M αι/n

)

K

−
M αι′ E(ybn
n

M αι/n

−

K.

)

−

And with expression (22) this yields for suﬃciently large n

E(Z Bn
n )

−

E(W Bn
n )

≤

M αι′ E(ybn
n

−

M αι/n

) + K.

And ﬁnally, lemma 8 establishes that E(ybn
n

−

M αι/n

) is universally bounded in n.

Lemma 11 Proof. First, let n be the largest multiple of M that’s no larger than n. It’s straightfor-

ward to see that

which in turn imply

E(zb
n)

and E(Z B
n )

≤

≥

M E(u1) + E(znb/n

n

)

E(Z nB/n
n

),

E(zb
n)

−

E(Z B
n )

≤

M E(u1) + E(znb/n

n

)

E(Z nB/n
n

).

−

(58)

Second, Pr(znb/n

M > Z nB/n

M ) = 0 implies Pr(znb/n

n

Υ implies Pr(znb/n

neighborhood Υ such that nB/n
∈
If no such Υ exists, then there must exist γ, δ > 0 such that Bγ
where Bγ is the concatenation of bγ
Γ nb/n < bγ and inf B
∈

+ γι and ˜bγ

˜b
∞ −

Γ t˜b/n > ˜bγ hold for suﬃciently large n. Since E(zb
n)
∈

supB

≡

≡

∈

∞

b

> Z nB/n
n
M > Z nB/n

) = 0. Hence, if there exists a B

∞
M ) = 0, then (58) yields the result.
M ) > δ,
γι. Now set Γ small enough so that

Λ and Pr(zbγ

M > Z Bγ

-

E(Z B

n ) increases

−

39

in b and decreases in ˜b, we thus have the following for suﬃciently large n:

E(znb/n
n

)

−

E(Z nB/n
n

)

E(zbγ
n )

−

≤

E(Z Bγ

n ),

sup
Γ
B

∈

Third, since

n

t=1 ˜at1{

ut > a′t(ybγ

ωι/2)

} ≥

n˜bγ implies zbγ

n = Z Bγ

n

n −

we have

P

E(zbγ
n )

−

E(Z Bγ
n )

n

(59)

n
t=1 ut,

and since zb
n

≤

P

Pr(zbγ

n > Z Bγ

n ) E

ut : zbγ

n > Z Bγ

n

≤

Pr

≤

n

(cid:16)

t=1
X

t=1
(cid:16)
X
ut > a′t(ybγ

n −

˜at1{

ωι/2)

} ≥

(cid:17)
n˜bγ

E

n

(cid:17)

(cid:16)

t=1
X

ut : zbγ

n > Z Bγ

n

(60)

.

(cid:17)

Fourth, I will now bound the probability in (60). Since Bγ

Λ, we can use Hoeﬀding’s inequality

∈

with (28) to establish that there exists C1 > 0 such that

n

Pr

(cid:16)

t=1
X

˜at1{

ut > a′t(ybγ

∞ −

ωι)

} ≥

n˜bγ

≤

(cid:17)

exp(

−

C1n).

Moreover, lemma 7 implies that there exists C2 > 0 such that for suﬃciently large n we have

ybγ
Pr(
n −
||

ybγ
∞||

> ω/2)

exp(

−

≤

C2n).

And combining these two results yields

n

Pr

(cid:16)

t=1
X

˜at1{

ut > a′t(ybγ

n −

ωι/2)

} ≥

n˜bγ

≤

(cid:17)

exp(

−

C1n) + exp(

−

C2n),

(61)

for suﬃciently large n.

Fifth, I will now bound the conditional expectation in (60). Let s

N samples of data, where sample si ≡ {
In total, s comprises M N customers. Hence, there are
can draw from s. Let S be an indicator variable that is one if we would get zbγ

M N
n

(ui

N
i=1 be a collection of
≡ {
j , Ai
M
j)
j=1 comprises the variables of M i.i.d. customers.
}
combinations of n customers that we

si}

n > Z Bγ

n under any

(cid:0)

(cid:1)

40

of these

M N
n

(cid:0)

(cid:1)

combination of customers. It’s clear to see that

n

E

(cid:16)

t=1
X

ut : zbγ

n > Z Bγ

n

N

M

E

≤

(cid:17)

(cid:16)

Xi=1

Xj=1

ui
j : S = 1

.

(cid:17)

Furthermore, we have

M N E(u1) = Pr(S = 0) E

N

M

ui
j : S = 0
(cid:17)

(cid:16)

Xi=1

Xj=1

+ Pr(S = 1) E

N

M

ui
j : S = 1
(cid:17)

,

(cid:16)

Xi=1

Xj=1

and thus

n

E

ut : zbγ
n

(cid:16)

t=1
X

≤

(cid:17)

M N E(u1)/ Pr(S = 1).

variable that is one if zbγ

Finally, I will now lower-bound Pr(S = 1). For i
M > Z Bγ
> 1/2 when N

n/M

Pr

M under sample si. By design, we have Pr(hi = 1)
. And since
n/(M δ)
⌉

i=1 hi ≥

≡ ⌈

i=1 hi ≥

N

N

1,

∈ {

, N

, deﬁne hi as an indicator
}

· · ·

δ and hence

≥

n/M implies S = 1, we

thus have
(cid:0) P

(cid:1)

P

n

E

ut : zbγ
n

(cid:16)

Xt=1

(cid:17)

2M

n/(M δ)
⌈
⌉

≤

E(u1).

(62)

Finally, combining (58)–(62) yields the result.

Lemma 12 Proof. I will show that the conditions of Kosorok’s (2008) theorem 2.13 hold. Following

Kosorok’s notation, deﬁne functions

my(a, u)

b′y + (u

≡

a′y)+,

˙m(a)

and

˙m

(a, u)

∞

b
≡||
b

≡

+

||

||

a
||
u > a′yb

− 1{

a.

∞}

−
,

First, the Hessian matrix of E(my(a1, u1)) at y = yb
is ¨c
∞
∞
Second, assumption 5 establishes that E( ˙m(a1)2) and E(
˙m
||

(yb
∞
(a1, u1)
||

∞

), which is non-singular when b

λ.
2) are ﬁnite. Third, functions

∈

41

my and ˙m satisfy Kosorok’s (2008) condition (2.18):

my(a1, u1)
|

mz(a1, u1)
|

−

a′1y)+

b′z

(u1 −

−

a′1z)+

=b′y + (u1 −
y
)
a1||
+
b
(
||
||
≤
||
z
y
= ˙m(a1)
||

−

||

||

.

−
z

||

−

Fourth, functions my and ˙m

∞

satisfy Kosorok’s (2008) condition (2.19):

(a1, u1)′(y

∞

−
a′1y)+
a′1y)2

myb∞(a1, u1)
(u1 −
−
u1 ∈

˙m
−
a′1yb
)+ + 1{
∞
[min(a′1y, a′1yb
∞

1{
a′1y)2
1{
a′1y)2 ¯µu|
α3

u1 ∈
a′1yb

[min(a′1y, a′1yb
∞

∞ −

a′1y

|
(cid:1)

∞}

yb
∞

2
yb
)
−
|
∞
u1 > a′1yb
(cid:1)
a′1(y
), max(a′1y, a′1yb
∞

−
)]
}
), max(a′1y, a′1yb
(cid:1)
)]
}
∞
(cid:1)

2
)
|

(cid:1)

E

my(a1, u1)
|
(cid:0)
= E

∞ −

(u1 −
|
(u1 −
(a′1yb
(a′1yb
∞ −
3
yb
∞||
2
yb
∞||

−

−

= E

(cid:0)

E

(cid:0)

≤

E

(cid:0)

≤
(cid:0)
y
¯µu||
≤
y
=o(
||

).

Finally, we must establish that

and function collection ζ

ζy : y

under the

p. 83-4).

≡ {

∈ R
||| · |||1 function norm, where
If we could show that N[](ν, ζ,

yb
t −
||
m
+ }
f
|||

p
→

(u

yb
∞||
. Let N[](ν, ζ,

0. To this end, deﬁne function ζy(a, u)

a′y)+
||| · |||1) be the ν-bracketing number of set ζ
(see van der Vaart and Wellner, 1996,
|||1 ≡
||| · |||1) is ﬁnite for all ν > 0, then Theorem 2.4.1 of
p
a′y)+/t
0
→

f (a1, u1)
|
|

E(u1 −

a′1y)+

ι′(u

m
+ |

∈R

−

≡

−

−

E

|

van der Vaart and Wellner (1996) would imply that supy
as t

, which with Theorem 2.12 of Kosorok (2008) would imply the result. So all that remains

→ ∞

is establishing the ﬁniteness of N[](ν, ζ,

||| · |||1).

Assumptions 3 and 8 imply that E(a1) > 0. And with this, assumption 4 establishes that there

∈ N that satisﬁes E(u1 −
y
∈ N, deﬁne the grid Gw ≡ {
max

GW : g

a′1y)+ < ν for all y /
∈
[0, w]m : y/δ

∈
m
+ , deﬁne
as the largest gridpoint in GW that’s weakly less than y and deﬁne

−
. And for a given y
}

∈ R

∈ Z

1]m. Now for a given δ

(0, 1/2)

[0, W

∈

m

y

exits W

and w

ℓ(y)

h(y)

≡

≡

g
{
min

g
{

∈

∈

}

≤
GW +1 : g > ℓ(y)
}

as the smallest gridpoint in GW +1 that’s strictly larger than

ℓ(y). Now deﬁne bracketing function collection

F

y
≡ {{1{

∈

[0, W ]m

ζh(y), ζℓ(y)}
}

: y

m
.
+ }

∈ R

42

F has a ﬁnite number of elements, since h(y) and ℓ(y) take a ﬁnite number of distinct values. And

the elements in F are ν-brackets under the

ﬁrst note that if y

[0, W ]m then

∈

||| · |||1 norm when δ < ν/(2√m E(
a1||
||

)). To see this,

y
ζℓ(y) − 1{
|||

∈

[0, W ]m

ζh(y)|||1
}

ζh(y)|||1
ζy+δι|||1
a′1(y

−

=

ζℓ(y) −
|||
ζy
δι −
≤|||
= E((u1 −
2δ E(a′1ι)

−

≤

δι))+

(u1 −

−

a′1(y

−

δι))+)

2δ√m E(
a1||
||

≤
<ν.

)

Second, if y /
∈

[0, W ]m then ℓ(y) /
∈

[0, W

−

1]m and thus

ζℓ(y) − 1{
y
|||

∈

[0, W ]m

ζh(y)|||1 =
}

ζℓ(y)|||1 = E((u1 −
|||

a′1ℓ(y))+) < ν.

Lemma 13 Proof. Choose n large enough and ǫ > 0 small enough so that

B8ǫ(bn)

∈

λ. Since t

→ ∞

T , when n is suﬃciently large.

as n

→ ∞
Deﬁne χ

, we have
≡ B2ǫ(0)

λt for all t

B7ǫ(bn)
∈
\ Bǫ(0). By design, ξ

∈

T . In other words, both bn + ξ and bn −

< 2ǫ and bn + ξ, bn −
t reside in the zone of sanity over the full time
χ. Also, assumption 5 ensures that when n is large it’s impossible for bt, the

χ implies ǫ

ξ
≤ ||

λt, for

t ξ

∈

∈

||

−

−

n

n

t

t

all t

∈

range T when ξ

∈

period-t state vector under a given policy, to travel between
bn
taking values in χ. Hence, for suﬃciently large n any given policy yields either (i) bt ∈ Bǫ(bn) for
T , or (iii) bt ∈ R
all t
T . Accordingly, for

\B2ǫ(bn) without bt −

\ B2ǫ(bn) for all t

Bǫ(bn) and R

χ for some t

bn ∈

∈

∈

m

m

T , (ii) bt −
suﬃciently large n we have

∈

min
T
t
∈

inf
Ξt
ξ
∈

∆ξ

t ≥

min

min
T
t
∈

inf
χ
ξ
∈

∆ξ

t , max
T
t
∈

inf
ξ
||≥

2ǫ

||

∆ξ
t

.

(cid:17)

(cid:16)

(63)

T infξ
I will ﬁrst show that mint
∈

χ ∆ξ
t
∈
t is large with high probability.

2ǫ ∆ξ

T inf
maxt
∈

ξ

||

||≥

is large with high probability and will then show that

43

First, for b > 0 deﬁne

zb
∞ ≡

min
m
y
+
∈R

b′y + E(u1 −

a′1y)+

(yb
∞

)

=cb
∞
=b′yb
∞

+ E(u1 −

= E(u11{

u1 > a′1yb

)+

a′1yb
∞
).

∞}

The envelope theorem establishes that

∂

∂b zb

∞

= ∂
∂b

b′y + E(u1 −

a′1y)+

y=yb∞

= yb
∞

.

Accordingly, if b

∈

λ then (47) establishes that

(cid:0)

(cid:1)(cid:12)
(cid:12)

∂2
∂b2 zb

∞

=

¨c
∞

(yb
∞

−

)−

1.

Also, if b, b + δι

∈

λ for some δ > 0 then (26) and (64) imply that

E(u11{

−

u1 > a′1yb

)
∞}

E(u11{
=

u1 > a′1yb+δι
)
∞ }
1
∂b zb+xδι

δι′

∂

dx

∞

x=0
1

Z

=

Z

x=0
1

≤

x=0

Z
=δκ1,

δι′yb+xδι
∞

dx

δηι′ιdx

where κ1 ≡

ηm.

Next, expressions (64) and (47) yield for b

λ

∈

yb
∞

= ∂

= ∂

= ∂

∞

∂b zb
∂b E(u11{
∂b yb
∞
¨c
∞

−

∂

=

∂y E(u11{
(yb
)−
∞

1 ∂

u1 > a′1yb

)
∞}
u1 > a′1yb

)
∞}
u1 > a′1yb

).

∞}

∂y E(u11{

44

(64)

(65)

(66)

And since the matrix ¨c

∞

(yb
∞

) =

aa′µu

|

a(a′yb

∞|

3, the result above and expression (26) imply the following for y
R

:

yλ
∞

∈

a)µa(da) has no negative elements, by assumption

∂

∂y E(u11{

u1 > a′1y

) =
}

−

¨c
∞

(y)y

(y)ι.

η¨c

∞

≥ −

Hence, if yb
∞

, yb
∞

+ δι

yλ
∞

∈

then (26) and (30) yield

E(u11{
=

u1 > a′1(yb
∞
1

E(u11{

)
+ δι)
}
−
u1 > a′1(yb
∞

δι′

∂

∂y E(u11{

u1 > a′1yb

)
∞}

)dx
+ xδι)
}

δηι′¨c

∞

(yb
∞

+ xδι)ιdx

δηθ2||

yb
∞

+ xδι
||

2

dx

Z

x=0
1

≥

x=0 −
1

Z

x=0 −

≥

Z

δκ2,

≥ −

where κ2 ≡

mη3θ2.

Moving on, if b, b + ξ

∈

λ then (31) and (65) imply

zb+ξ
∞

=zb
∞

+ ξ′

=zb
∞

zb
≤
∞
=zb
∞

+ ξ′

+ ξ′

+ ξ′

1

+

∂

∂b zb

∞

Z

x=0
1

Z

x=0
1

(1

−
2/2.

x=0

Z
ξ
θ3||

||

∂

∂b zb

∞ −

∂

∂b zb

∞ −

∂

∂b zb

∞ −

(1

(1

−

−

x)ξ′

∂2
∂b2 zb+xξ

∞

ξdx

x)ξ′¨c

∞

(yb+xξ
∞

)−

1ξdx

ξ
x)θ3||

||

2dx

And thus if ξ

χ and t

T then

∈

∈

zbn
∞ −

t
n

zbn+ξ
∞ −

n

t

bn

z
∞

−
n

t
n−t ξ

−

≥
where κ3 ≡

κ3,

t
n

θ3ǫ2/2.

(67)

(68)

(69)

Now choose n large enough so that δ

n−
< ǫ, δ(κ1+2κ2)
∈ B7ǫ(bn). Also, deﬁne a grid of points G such that for all b

κ3/2, and yb

yλ
≤
∞
∈ B6ǫ(bn) there exists an
b + δι. This grid has M/δm points, for some

3/8 satisﬁes

δι
||
||

∞±

δι

≡

∈

for all b

upper bounding grid point

b
⌈

⌉

that satisﬁes b

b
≤ ⌈

⌉ ≤

45

universal constant M > 0. With this, expressions (66)–(69) imply that if ξ

χ and t

∈

∈

T then:

E(u11{

u1 > a′1(ybn
)
+ δι)
}
∞
u1 > a′1ybn
)
∞}

−

δκ2

n

t

bn

z
∞
t

−
n
n

+

n

−
n
t

t
n−t ξ

−

−

bn

z
∞
bn

δκ2 + κ3

−
t
n−t ξ+δι

−

t
n−t ξ

⌉

−

bn+ξ

⌉

)
δι)
}

−

≥

+

E(u11{
δκ2

≥
=zbn
∞ −
t
zbn+ξ
n
∞
t
zbn+ξ+δι
n
∞
t
n
t
n

z⌈
∞

bn+ξ

≥

≥

≥

⌉

+

z⌈
∞

a′1(y⌈
∞

−
n
u1 ≥
E(u11{
t
n
E(u11{
+
−
n
a′1(y⌈
u1 ≥
E(u11{
∞
t
n
+
E(u11{
−
n

t
n

≥

bn+ξ

⌉

)
δι)
}

−

δ(κ1 + κ2) + κ3

−

δ(κ1 + κ2) + κ3

u1 ≥

t
n−t ξ

⌉

−

bn

a′1(y⌈
∞

)
δι)
}

−

−

δ(κ1 + 2κ2) + κ3

u1 ≥

bn

a′1(y⌈
∞

t
n−t ξ

⌉

−

) + κ3/2.
δι)
}

−

(70)

Next, for ξ

χ and t

∈

T deﬁne

∈

n

∆
⌈

ξ
t ≡
⌉

s=1
X

us1{

us > a′s(ybn
∞

+ δι)
}

t

us1{

us ≥

bn+ξ

a′s(y⌈
∞

⌉

−

δι)
}

us1{

us ≥

t
n−t ξ

⌉

−

bn

a′s(y⌈
∞

δι)
}

−

−

−

n

s=1
X
n

s=t+1
X

ξ
ts,
⌉

=

∆
⌈
s=1
X
us

ξ
ts ≡ 
⌉


(cid:0)

us

(cid:0)



where

∆
⌈

us > a′s(ybn
∞
us > a′s(ybn
∞

1{

1{

+ δι)

+ δι)

us ≥
us ≥

a′s(y⌈
∞
bn
a′s(y⌈
∞

bn+ξ

⌉

−
t
n−t ξ

−

} − 1{

} − 1{

s

t,

≤
s > t.

⌉

δι)
}
(cid:1)
δι)
}
(cid:1)

−

Assumption 5 and expression (26) ensure that

ξ
ts is strictly bounded. Hence, we can use the
∆
⌉
⌈
Azuma–Hoeﬀding inequality with (70) to conﬁrm that there exists C1 > 0 that satisﬁes for all

46

ξ

∈

χ and t

T

∈

∆
Pr(
⌈

ξ
t < nκ3/4)
⌉

≤

exp(

−

C1n).

(71)

Now deﬁne ←−y b
n
as yb
n

t as the shadow price associated with ←−z b
n

t has the same distribution
t, we can use lemma 7 to establish that there exists C2 > 0 such that for suﬃciently large n

t. Since ←−y b
n

−

−

−

−

we have for all ξ

χ and t

T

∈

∈

Pr

ybn
n −

ybn
∞

> δι

(cid:0)

(cid:1)

Pr

bn+ξ

y⌈
∞

⌉

−

bn+ξ

y⌈
t

⌉

> δι

(cid:0)

(cid:1)

and Pr

t
n−t ξ

⌉

−

bn

y⌈
∞

(cid:0)

− ←−y ⌈

bn
−
t
n

−

t
n−t ξ

⌉

> δι

(cid:1)

exp(

−

exp(

−

exp(

−

exp(

−

exp(

−

exp(

−

exp(

−

exp(

−

≤

≤

≤

≤

≤

≤

≤

≤

Now for ξ

χ and t

∈

∈

T , deﬁne

∆ξ

t ≡

n

s=1
X

us1{

us > a′sybn
n }

t

C2δ2n)

C2n1/4),

C2δ2t)

C2n−

3/4t)

C2 log(n)2/2),

C2δ2(n

t))

−
3/4(n

C2n−

¯t))

−

C2n1/4/4).

(72)

(73)

(74)

us1{

us ≥

a′sybn+ξ
t

}

us1{

us ≥

a′s←−y

t
n−t ξ

bn
n

−
t
−

.
}

Xs=1
n

−

−

s=t+1
X

By design, we have ∆ξ
t ≤
true then we also have ∆ξ

∆ξ

t . And if none of the conditions in the probabilities in (71)–(74) are
χ and t

nκ3/4. Hence, for ξ

T we have

∆

t ≥ ⌈

ξ
t ≥
⌉

∈

∈

Pr(∆ξ

t < n3/4κ3/4)

≤
where pn ≡

pn,

exp(

−
+ exp(

C1n) + exp(

C2n1/4)

−
C2 log(n)2/2) + exp(

−

C2n1/4/4).

−

47

Moreover, the conditions in (71)–(74) depend on ξ only through upper bounding points
. And since there’s no more than M 2/δ2m distinct pairs (
bn −
bn + ξ
⌈
⌈
⌉

and
G2 and no more than n values in T , we thus have

bn −
⌈

,
⌉

t ξ

−

n

t

bn + ξ
⌈
t

⌉
) in
⌉

t ξ

n

−

Pr

min
T
t
∈

inf
χ
ξ
∈

(cid:0)
√n and limn

∆ξ

t < n3/4κ3/4

nM 2pn/δ2m.

≤

(cid:1)

Finally, since n3/4κ3/4

≥

nM 2pn/δ2m = 0, we thus have for suﬃciently large n

→∞

min
T
t
∈

inf
χ
ξ
∈

Pr

(cid:0)

∆ξ

t < √n

1/6.

≤

(cid:1)

(75)

T inf
I will now create an analogous bound for maxt
∈

t . To do so, I will use a benchmark
problem that is the same as our baseline problem, except it has one extra resource and one extra

||≥

ξ

||

2ǫ ∆ξ

constraint (for a total of m + 1 resources and constraints). Every customer in this benchmark

problem ﬂips a fair coin upon arrival; if the coin comes up tails then the customer demands zero

units of the (m + 1)th resource, and if it comes up heads then the customer demands as much of the

(m+1)th resource as they demand of the jth resource. Hence, if the period-t customer has variables

(ut, at) in the baseline problem then they have variables (ut, ˜at) in the benchmark problem, where
˜at ≡
benchmark problem begins with resource vector ˜bδ
In other words, this problem starts with n(e′jbn −
can’t allocate more than this amount of the jth resource to the “heads” customers. Indeed, the

(a′t, hte′jat)′ and ht is an independent Bernoulli random variable with mean 1/2. Also, the
(0, e′j bn).
n ≡
δ)/2 units of the (m + 1)th resource, and hence

(b′n, (e′jbn −

δ)/2)′, for some δ

∈

benchmark problem is equivalent to the baseline problem with an additional constraint that limits

the amount of the jth resource consumed by the H

n
t=1 ht “heads” customers.

≡

The linear programming value of the benchmark problem is

P

˘zδ
n ≡

max
[0,1]n
∈

x

n

t=1
X

utxt

s. t.

n

t=1
X

atxt ≤

nbn

and

n

t=1
X

e′jathtxt ≤

n(e′jbn −

δ)/2.

(76)

Since the coin ﬂips are independent of the customer variables this linear programming value has

48

the same distribution as ˜zδ

n, where

˜zδ
n ≡

max
[0,1]n
∈

x

n

t=1
X

=n min
m
+ ,s
∈R

y

∈R+

n

utxt

s. t.

t=1
X
b′ny + s(e′jbn −

H

t=1
X

atxt ≤

nbn

and

e′jatxt ≤

n(e′jbn −

δ)/2

δ)/2 +

H

t=1
X

(ut −

a′ty

−

e′jats)+/n +

n

Xt=H+1

(ut −

a′ty)+/n.

(77)

By deﬁnition, ˜zδ
being less than n(e′jbn −
a policy that holds less than n(e′jbn/2

n is the highest achievable value subject to the jth element of the resource vector
˜z2δ
n is the minimum regret incurred by

δ)/(2H) in period H. Hence, zbn

n −

δ) units of the jth resource at time H.

Let ˜yδ

n and ˜sδ

−
n be the solution to the problem in (77), so that ˜sδ

to the new constraint. The envelop theorem establishes that this shadow price satisﬁes ∂

n is the shadow price corresponding
n =

∂δ ˜zδ

n˜sδ

n/2. Also, since (i) ˜zδ

n decreases in δ, (ii) ˜sδ

n increases in δ, and (iii) ˜z−∞n = zbn

n , we have

−

∂

∂γ ˜zγ

ndγ

∂

∂γ ˜zγ

ndγ

n˜sγ

n/2dγ

n =zbn
˜z2δ

n +

zbn
n +

≤

=zbn

n −

zbn
n −

≤

2δ

Z

γ=
2δ

−∞

Z

γ=δ
2δ

γ=δ
Z
n˜sδ

nδ/2.

Next, as n

→ ∞

the problem in (77) converges to

˜zδ
∞ ≡

y

min
m
+ ,s

∈R

∈R+

= max
ξ
bn
≤

≤

−

bn

b′ny + s(e′jbn −
/2 + zbn
zbn+ξ
∞
∞

−

ξ

/2

s. t.

e′jξ =

δ.

−

δ)/2 + E(u1 −

a′1y

e′ja1s)+/2 + E(u1 −

−

a′1y)+/2

(78)

(79)

(80)

and ˜sδ
Let ˜yδ
∞
∞
price satisﬁes ∂
∂δ ˜zδ
∞

be the solution to the problem in (79). As before, the new constraint’s shadow

/2. And let ξδ
∞
This solution satisﬁes the following ﬁrst-order conditions, for some Lagrange multiplier

be the solution to the reformulated problem in (80).

˜sδ
∞

−

=

:

δ

L

∞

/2 + z

bn

−

t
n−t ξ

/2

0 = ∂
∂ξ
= ∂

zbn+ξ
∞
∂b zbn+ξδ
(cid:0)
∞
=ybn+ξδ
/2
∞

∞

∞

∞
∂

∂b zbn
∞
ξδ
∞

−

/2

/2

−

−
ybn
∞

ξδ
∞

−

/2

− L

δ

∞
δ

∞

− L
δ
ej.

− L

∞

(e′jξ + δ)

ej

(cid:1)

49

Moreover, the concavity of zb
∞

establishes that

0

L

∞

= 0 and ξ0
∞

= 0. And this latter expression

implies that

0 = ∂

= ∂
∂δ

∞

/2

∂δ 0
δ=0
ybn+ξδ
(cid:12)
(cid:12)
∞
(ybn+ξδ
∞
(ybn
∞

(cid:0)
¨c
∞
¨c
∞

)−

−

−

=

=

ξδ
∞

−

/2

ybn
∞
1 ∂

−
)−

∞

∂δ ξδ

/2

∞
∂
∂δ L

1 ∂

∂δ ξδ

∞ −

δ=0
ξδ
∞

)−

δ

ej

−
δ

− L
∞
(ybn
(cid:1)(cid:12)
¨c
−
(cid:12)
∞
∞
ej
δ=0.
(cid:12)
(cid:12)

∞

Moreover, the constraint in (80) implies that

1 ∂

∂δ ξδ

∞

/2

∂
∂δ L

δ

∞

ej

−

δ=0

(cid:12)
(cid:12)

(81)

e′j

Combining this with (81) yields

∂

∂δ ξδ

∞

= ∂

∂δ e′jξδ

∞

=

−

∂
∂δ δ =

1.

−

And since

0

L

∞

∂

∂δ ξδ

∞

δ=0 =

−

(cid:12)
(cid:12)

¨c
∞
e′j ¨c

(ybn
∞
(ybn
∞

)ej
)ej

∞

and

∂
∂δ L

δ

∞

1
(ybn
∞

.

)ej

e′j ¨c

∞

δ=0 =
(cid:12)
(cid:12)

= 0, we thus have for suﬃciently small δ

δ
∞ ≥

L

δ
(ybn
∞

.

)ej

2e′j ¨c

∞

Accordingly, for suﬃciently small δ we have

˜sδ
∞

=

∂δ ˜zδ
2 ∂

∞

−

= 2

L

δ
∞ ≥

δ
(ybn
∞

.

)ej

e′j ¨c

∞

(82)

(83)

Now for the time being, suppose that for all suﬃciently small δ > 0 there existed C3 > 0 such

that

Pr

′n , ˜sδ

n)′

(˜yδ
||
(cid:16)

(˜yδ
′
∞

, ˜sδ
∞

)′

−

|| ≥

δ
(ybn
∞

2e′j ¨c

∞

≤

)ej

(cid:17)

exp(

−

C3n).

With this, (78) and (83) imply that

zbn
n −

˜z2δ
n ≤

Pr

(cid:16)

δ2n
(ybn
∞

∞

4e′j ¨c

exp(

−

C3n).

≤

)ej

(cid:17)

(84)

(85)

50

Next, since H is a binomial random variable with mean n/2, there exists C4 > 0 such that

Pr

H/n

(cid:16)

e′jbn −
2e′jbn −

2δ
2δ

≤

≤

(cid:17)

exp(

−

C4n).

(86)

(0, ǫ/√m) then

∈

If both of the conditions in the probabilities in (85) and (86) are false for some δ
any policy that holds less than H(e′jbn −
regret of at least δ2n/(4e′j ¨c
(ybn
∞
∞
when the jth element of the resource vector is less than e′jbn −

ǫ/√m in period H.

)ej ). Hence, for large n the regret almost certainly exceeds √n

ǫ/√m) units of the jth resource in period H incurs a

Now modify the benchmark problem so that it is the “tails” customers that consume the (m +

1)th resource.

In this case, the argument above establishes that for large n the regret almost

certainly exceeds √n when the jth element of the resource vector exceeds e′jbn + ǫ/√m in period
, so if bH is the period-H resource vector under
H. And these claims hold for all j
}

∈ {

, m

· · ·

1,

a given policy then the regret almost certainly exceeds √n when

bH −
||
ǫ. Thus, we can choose n large enough so that Pr(inf

when

bn||∞ ≥
ǫ ∆ξ

ξ

H ≥
T ) = 1, we can choose n large enough so that Pr(H

||≥

||

bH −
||
Moreover, since limn

bn|| ≥

Pr(H

∈

→∞

ǫ/√m, and hence

√n)

T )

∈

≥

≥

11/12.

11/12.

And combining these bounds with (63) and (75) yields

min
T
t
∈

inf
Ξt
ξ
∈

Pr

(cid:0)

∆ξ

t < √n

(cid:1)

≤

≤

Pr

inf
χ
ξ
∈

min
T
t
∈
1/6 + Pr(H /
∈

(cid:0)

∆ξ

t < √n

+ Pr

(cid:1)
T ) + Pr

inf
ξ
||≥

||

(cid:0)

ǫ

max
inf
T
t
ξ
∈
||
||≥
(cid:0)
∆ξ
H < √n

2ǫ

∆ξ

t < √n

(cid:1)

(cid:1)

1/6 + 1/12 + 1/12

≤
=1/3.

Finally, I must establish the bound in line (84).

I will do so by showing that an analogous

version of lemma 7 applies to the problem in (77). And for this it suﬃces to show that the problem
in (76) satisﬁes an analogous version of all our model assumptions, since ˜zδ
distribution. The problem in (76) trivially satisﬁes assumptions 1–6, with ˜bδ

n and ˘zδ
n have the same
)′ (i.e.,
(b′

∞ ≡

, e′jb

∞

∞

with δ = 0 in the limit). For assumption 7, note that (80) provides the limit of the problem
in (76). Moreover, ξ0
∞
neighborhood about δ = 0. Hence, ˜yδ
∞
unique and positive value for suﬃciently small δ. And (83) establishes the same for ˜sδ
∞
for assumptions 8 and 9, note that limiting resource vector ˜bδ
∞

= 0 and (82) establish that ξδ
∞
/2 + zbn
= ∂
∞

has a unique and bounded value in a

corresponds with shadow prices

/2) = ybn+ξδ

/2 + ybn
∞

∂b (zbn+ξδ

. Finally,

/2 has a

ξδ
∞

∞

∞

ξδ

−

−

∞

∞

51

˜yδ∞
∞

= yb∞
∞

and ˜sδ∞
∞

= 0. Thus if ˜cδ
∞

(y, s) is the objective in (79) then

∂2
∂y2 ˜cδ
∂2
∂y∂s ˜cδ
∂2
∂s2 ˜cδ

∞

∞

∞

(y, s)

(cid:12)
(y, s)
(cid:12)

(cid:12)
(y, s)
(cid:12)

and

y=yb∞

y=yb∞

∞

∞ ,s=0 =¨cb
∞ ,s=0 =e′j ¨cb
∞ ,s=0 =e′j ¨cb

),

(yb∞
∞
(yb∞
∞
(yb∞
∞

∞

∞

y=yb∞

)/2,

)ej/2.

And with this, it’s straightforward to conﬁrm that the Hessian matrix of ˜cδ
∞
Lipschitz at ˜yδ∞
∞

and ˜sδ∞
∞

.

(cid:12)
(cid:12)

is full rank and

Proposition 4 Proof. First, lemma 20 establishes that there exist constants C1, κ > 0 such that for

suﬃciently large t we have

inf
λt
b
∈

Pr

√t

a′tyb
1
|

∞ −

−

ut| ≤

1

∩

a′te1 > κ

C1/√t

1.

−

≥

(cid:0)

(cid:1)

(87)

And lemma 12 implies that there exit C2 > 0 such that for suﬃciently large t the following holds

for all at in its domain:

Also, if b

λt and t

∈

≥

1 then expressions (24) and (32) yield

(cid:1)

inf
λ
b
∈

(cid:0)
1 + 4α4/θ2

Pr

√t

1a′t(yb
t
−

1 −

)

yb
∞

−

≥

3 : at

≥ 1{

C2.
a′te1 > κ
}

(88)

a′tyψt(b,0)
|
∞

−

a′tyb

∞| ≤

≤

ψt(b, 0)
α
||
2α2/(θ1(t
1

.

/θ1

b

||
1))

−

−

(89)

≤

√t

1

−

52

Thus, if b

∈

λt then (88) and (89) yield the following for suﬃciently large t:

E

(a′tyψt(b,0)
(cid:0)

1 −
min

t
−
E

≥

ut)+ : ut, at
1

1 −

(cid:16)
Pr

√t

t
−

t
−

1
−
a′t(yψt(b,0)
(cid:16)
a′t(yψt(b,0)
(cid:16)
a′t(yψt(b,0)
(cid:16)
a′tyb
|
n

∞ −

t
−

Pr

Pr

1 −

1 −

, a′t(yψt(b,0)
(cid:1)

t
−

1 −

yψt(b,0)
∞

) + (a′tyψt(b,0)

yψt(b,0)
∞

)

yψt(b,0)
∞

)

yψt(b,0)
∞

)

≥

≥

≥

√t

√t

√t

1

1

∞

+

+

−
1

−
a′tyψt(b,0)
|
∞
a′tyb
|
a′tyb
|
1
−
a′t(yψt(b,0)

∞ −

∞ −

−
2

+

1

t
−

1 −

ut|
yψt(b,0)
∞

ut|

ut| ≤

√t

Pr

1

−
1

−

1

1

o

o

a′tyb
|
n

∞ −

ut| ≤

√t

(cid:16)
.
a′te1 > κ
}

1{

(cid:16)
1

≥

√t

≥

√t

≥

√t

1

1

1

−
1

−
1

−
1

1

1

≥

√t

−
C2

≥

√t

1 1

−

+

: ut, at

ut)

(cid:17)
ut|

−

(cid:17)
: ut, at

+

(cid:17)
a′tyψt(b,0)
|
∞

: ut, at

)

(cid:17)
3

≥

√t

1

−

: at

(cid:17)

a′tyb

∞|

−

: ut, at

(cid:17)

And an analogous argument yields the same bound for E

for suﬃciently large t expression (87) implies

(ut −
(cid:0)

a′tyψt(b,1)

1

t
−

)+ : ut, at

. Accordingly,

(cid:1)

E(rt : bt = b)

inf
λt
b
∈

≥

=

≥

E

inf
λt
b
∈
C2

1

.

√t
−
C1C2
1
t

−

C2

1

−
Pr

√t

(cid:16)

inf
λt
b
∈

1

a′tyb
|
n
√t

1

−

1

ut| ≤

∞ −

a′tyb
|

∞ −

a′te1 > κ
}
(cid:17)

√t

−
1
ut| ≤

∩

1

1{

o
a′te1 > κ

(cid:0)

(cid:1)

(90)

Finally lemma 13 implies that there is at least a 50% chance that bt ∈

λt for all t

∈

T , because

otherwise there would be at least a 2/3

−

1/2 = 1/6 chance that the regret exceeds √n. But the

optimal regret cannot be O(√n) because the regret of the martingale policy is only O(log(n)).
Combining the fact that Pr(bt ∈

1/2 with (46) and (90) yields the following for suﬃciently

λt)

≥

53

large n:

E(Rn)

≥

≥

≥

≥

Pr(bt ∈

λt) inf
λt
b
∈

E(rt : bt = b)

C1C2
2(t

1)

−

T
Xt
∈

3n/4
⌋
⌊

log(n)2n3/4
Xt=
⌊
n/2

⌋
C1C2
2(t

1)

−

Xt=n4/5
(log(n)/5

log(2))C1C2/2.

−

Lemma 14. If τ

∈

(0, 1) and tb > 0 then

E

ut ≤

1{

τ

(ut −
}

htb
t
−

(cid:0)

1)++1{
(1
=

ut > τ

(htb
t
}
−
b)(1 + t
2(t + 1)

−

−

1 −
bt)

ut)+

(cid:1)
τ (1

−

−

b) + τ 2/2.

Proof. If f tb
t
−

1 is the probability density function of htb
t
−

1 then

E

(cid:0)

1{

ut ≤
=

τ

(ut −
}

τ

htb
t
−
u

1)+ + 1{
h)f tb
(u
t
−

−

ut > τ

(htb
t
}
−

1(h)dhdu +

1 −
1

ut)+
1
(cid:1)

u=τ Z
Z
1

h=u
1

(u

h)duf tb
t
−

−

1(h)dh +

(h

u)f tb
t
−

−

1(h)dhdu

(h

u)duf tb
t
−

−

1(h)dh

(h2/2

h + 1/2)f tb
t
−

−

(h(1

−

τ ) + τ 2/2

1/2)f tb
t
−

−

1(h)dh

u=τ

h=0 Z
1

Z
1(h)dh +

h=0

Z

u=0 Z
Z
1

h=0
1

h=0 Z
Z
1

u=h

Z

h=0
1

(h2/2

=

=

=

=

=

hτ + τ 2/2)f tb
t
−

1(h)dh

−

h=0
Z
Var(htb
t
−
b)(1 + t
2(t + 1)

−

(1
(cid:0)

1) + E(htb
t
−
bt)

−

1)2

/2

(cid:1)
τ (1

−

−

1) + τ 2/2

τ E(htb
t
−
−
b) + τ 2/2.

Lemma 15. For all suﬃciently large γ > 0 there exists C > 0 such that supb
∈
γ

Ct) for all suﬃciently large t.

exp(

)

λ E(1{||

yb
t || ≥

yb
t ||

}||

≤

−

54

Proof. First, lemma 19 implies that Pr

then

t > γ/√m

e′jyb
(cid:0)

≤

(cid:1)

Pr

e′j ˙cb

t (ejγ/√m)

0

. Thus, if b

λ

∈

≤

(cid:0)

(cid:1)

yb
Pr(
t ||
||

> γ)

≤

≤

=

m

Xj=1
m

Xj=1
m

Xj=1
m

≤

Xj=1

Pr

Pr

Pr

Pr

e′jyb

t > γ/√m

(cid:0)

(cid:0)

(cid:1)
t (ejγ/√m)

e′j ˙cb

t

0

≤

(cid:1)

e′jai1{

ui > e′jaiγ/√m

te′jb

} ≥

(cid:17)

(cid:16)

Xi=1
t

(e′jb/2)1{

e′j ai ≤

e′jb/2
}

Xi=1 (cid:16)

(cid:16)
+ α1{

m

t

Pr

1{

(cid:16)

Xi=1
t

Xj=1

m Pr

1{

(cid:16)

Xi=1
mζt(ρt(γ))ρt(γ),

t

ui > e′jaiγ/√m

}1{

e′j ai > e′jb/2
}
(cid:17)

≥

te′jb

(cid:17)

ui > e′jbγ/(2√m)

} ≥

te′jb
2α

(cid:17)

} ≥

tβ
2α

(cid:17)

ui > βγ/(2√m)

t
k

pk

1(1

−

p)t
−

k

−

(cid:18)

(cid:19)

βt/(2α)
Xk=
⌋
⌊
Pr(u1 > βl/(2√m)).

≤

≤

≤

≡

≡

where

ζt(p)

and ρt(l)

Second, it’s straightforward to show that ∂

p and t

≥

8α/β. Thus, if t

8α/β, γ

γ

≥

≥

≡

∂l ρt(l)
l
inf
{

0 and that ∂
m
+ : ρt(l)

∂p ζt(p)
p

≥
, and b
}

≤

≤

∈ R

0 when p

≤
λ then

∈

min(1/2, β/(8α))

≡

yb
Pr(
t ||
||

> γ)

mζt(ρt(γ))ρt(γ).

≤

Third, ζt(ρt(γ))ρt(γ) equals the probability that a binomial random variable with t trials and

success probability ρt(γ) exceeds

β/(2α)
> β/(8α)
⌋
⌊
≥
bound establishes that there exists constant C1 such that for all t
∈ N we have

. Thus, since
βt/(2α)
⌋
⌊

ρt(γ), a Hoeﬀding

ζt(ρt(γ))ρt(γ)

2 exp(

−

≤

tC1).

55

Fourth, note that

∞

t=0

Z

ρt(γ)dγ =

∞

γ=0

Z

Pr(u1 > βγ/(2√m))dγ

=2√m/β

∞

γ=0

Z

Pr(u1 > γ)dγ

=2√m E(u1)/β.

yb
Fifth, lemma 7 establishes that for suﬃciently large γ there exists C2 > 0 such that supb
λ Pr(
t || ≥
||
∈

γ)

exp(

C2t) for all suﬃciently large t.

−

≤
Now combining these four results yields for all suﬃciently large γ and t:

E(1{||

yb
t || ≥

γ

yb
t ||

}||

sup
λ
b
∈

∞

γ=0

Pr(1{||

yb
t || ≥

γ

yb
t || ≥

}||

γ)dγ

) = sup
λ Z
b
∈
sup
λ
b
∈

≤

γ exp(

−

≤

≤

yb
γ Pr(
t || ≥
||

γ) + sup

∞

yb
Pr(
t || ≥
||

γ)dγ

λ Z
b
∈
C2t) + mζt(ρt(γ))

γ=γ

∞

ρt(γ)dγ

γ exp(

−

C2t) + m

2 exp(

−
ρt(γ)

γ=γ
Z
tC1)

2√m E(u1)/β.

Lemma 16. (yb

t −

y)′ ˙cb

t (y)

Proof. The convexity of cb

≤

0 for all t

∈ N, b
t and optimality of yb

m
+ , and y

m
+ .

∈ R

∈ R

t is diﬀerentiable at y then ∂
y)′ ˙cb

∂y cb

t (y) + o(ǫ), which with the previous result implies the result.

t establishes that cb

t (y + ǫ(yb

t −
t(y), which implies that cb

t(y) = ˙cb

cb
y))
t(y) for all
≤
t (y + ǫ(yb
y)) =

t −

t is not diﬀerentiable at y then choose ǫ > 0 small enough so that for a given s

1,

, t

[0, 1]. If cb

ǫ
∈
cb
t (y) + ǫ(yb
If cb

t −

}
· · ·
t must be
= 0. Accordingly, the argument above implies

∈ {
= 0. Now cb

a′sy and as 6

,
us > a′s(y + ǫι)
}
}
0. This holds for all suﬃciently small ǫ,
t (y)

, for all s
}

us > a′sy

= 1{

∈ {

· · ·

, t

1,

we have us > a′s(y + ǫι) if us > a′sy and us < a′s(y + ǫι) if us ≤
diﬀerentiable at y + ǫι, because us 6
ǫι)′ ˙cb
that (yb
y
t −
t(y + ǫι) = ˙cb
we have ˙cb

= a′s(y + ǫι) if as 6

t (y), and hence (yb

0. And since 1{
y
t −

t (y + ǫι)

ǫι)′ ˙cb

−

≤

≤

−

which implies the result.

Lemma 17. For all suﬃciently small ǫ > 0 there exists C > 0 such that

λ E
supb
∈

supy

(cid:0)

ǫ(yλ∞) ||

∈B

˙cb
t (y)

2

˙cb
∞

(y)
||

−

≤

(cid:1)

C/t for all t

∈ N.

56

, m

, deﬁne function ˙ζ y
Proof. For j
1,
· · ·
∈ {
}
˙ζ y
. Let N[](ν, ˙ζj,
collection ˙ζj ≡ {
m
j : y
+ }
∈ R
f
||| · |||2 function norm, where
|||
m
that for all y
+ we have
∈ R

|||2 ≡

p

j (as, us)

us > a′sy
and deﬁne function
||| · |||2) be the ν-bracketing number of set ˙ζj under the
E(f (as, us)2) (see van der Vaart and Wellner, 1996). Note

e′jas1{

≡

}

˙ζ y
j |||2 ≤
|||

α.

(91)

For a given δ > 0, deﬁne the grid G

deﬁne ℓ(y)

max

g
{

G : g

y

≤

≡

min

g
{
˙ζ h(y)
j

∈
G : g > ℓ(y)
}
∈ Bǫ(yλ
{{
ensures that they are ν-brackets under the

∈
, ˙ζ ℓ(y)
j

)
}

: y

∞

}

}

∈ R
as the largest gridpoint that’s weakly less than y and h(y)

∈ R

∈ Z

. And for a given y
}

y
≡ {

m
+ : y/δ

m

m
+ ,

≡

as the smallest gridpoint that’s strictly larger than ℓ(y). Deﬁne F

≡
as a collection of bracketing functions. Setting δ = ν2/(2√m¯µuα3)

||| · |||2 norm:

˙ζ ℓ(y)
j −
|||

˙ζ h(y)
j

|||2

=

q

≤

q

≤

q

≤
q
=ν.

E

E

e′jas1{
(cid:0)(cid:0)
(e′jas)2

us > a′sℓ(y)

a′s(y + δι)

1{
(e′jas)22δa′sι¯µu

(cid:0)

E

} −

≥

e′jas1{
us > a′s(y

us > a′sh(y)
}
(cid:1)

2

(cid:1)

−

δι)
}
(cid:1)

(cid:0)

2δ√m¯µuα3

(cid:1)

Since

Bǫ(yλ
some constant C0 when ν

∞

) is totally bounded, the number of elements in F is not more than C0/ν2m for

α. Hence, N[](ν, ˙ζj,

≤

||| · |||2)

≤

C0/ν2m when ν

≤

α, which implies that

1 + log N[]

να, ˙ζj,
(cid:16)
1 + log N[]

||| · |||2

dν

(cid:17)

ν, ˙ζj,
(cid:16)

||| · |||2

dν

(cid:17)

1 + log(C0/ν2m)dν

Z

1

=

0 r
1
α
1
α

≤

<

∞

α

Z

0 r
α

0
Z
.

p

With this, theorem 2.14.2 of van der Vaart and Wellner (1996) establishes that there exists

57

constant kj that satisﬁes for all t

∈ N and b

∈ R

m
+

t

kj ≥

E

sup
ǫ(yλ∞)

∈B

y

√t

= E

√t

sup
ǫ(yλ∞)

∈B

y

(cid:16)

˙ζ y
j (as, us)/t

(cid:12)
Xi=1
(cid:12)
(cid:16)
(cid:12)
e′j ˙cb
(cid:12)
t (y)
(cid:12)
|

e′j ˙cb
∞

−

(cid:17)
(y)
|

(cid:17)

E( ˙ζ y

j (as, us))
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

−

.

!

Combining this with (91) and theorem 2.14.5 of van der Vaart and Wellner (1996) establishes that

there exists constant Cj that satisﬁes for all t

∈ N and b

∈ R

m
+

Cj ≥

E

sup
ǫ(yλ∞)

∈B

y

(cid:16)

t

e′j ˙cb
|

t (y)

−

e′j ˙cb
∞

(y)
|

2

.

(cid:17)

And this implies that

m

m

Cj ≥

Xj=1

≥

E

Xj=1
E

y

(cid:16)

y

∈B

(cid:16)
sup
ǫ(yλ∞)

∈B

sup
ǫ(yλ∞)

t

e′j ˙cb
|

t (y)

−

e′j ˙cb
∞

(y)
|

2

(cid:17)

t

˙cb
t (y)
||

−

˙cb
∞

(y)
||

2

.

(cid:17)

Lemma 18. There exist C > 0 such that for all j

1,

∈ {

, m

, t
}

∈ N, b

· · ·

∈ R

m
+ , and y

m
+ we

∈ R

have

e′j ˙cb
Pr(
|

t (y)

−

e′j ˙cb
∞

(y)

| ≥

γ)

≤

2 exp

Cγ2t

.

(cid:1)

−

(cid:0)

Proof. This result follows from theorem 2.6.2 of Vershynin (2020).

Lemma 19. e′jyb

t > γ implies e′j ˙cb

t (γej)

≤

0 for all t

Proof. I will show that assuming e′jyb
ˆy

γ)/2 satisﬁes

ej(e′jyb

yb
t −

≡

t −

t > γ and e′j ˙cb

m
+ , and j

∈ N, b
t (γej) > 0 yields a contradiction. The point

∈ R

∈ {

.
}

, m

· · ·

1,

t)/2

t −

e′jej(e′jyb
(e′jyb

e′j ˆy =e′jyb
=e′jyb
t −
=(e′jyb
t + γ)/2

t −

t −
γ)/2

>γ.

58

 
And this implies that

e′j ˙cb

t (ˆy) =e′j(b

−

−

a1{
a1{
a1{
−
t (γej)

e′j(b

≥

e′j(b
≥
=e′j ˙cb

/t)
u > a′ ˆy
}

/t)
u > a′eje′j ˆy
}
/t)
}

u > a′ejγ

and thus that (yb

t −

ˆy)′ ˙cb

t (ˆy) = ((e′j yb

t −

>0,

γ)/2)e′j ˙cb

t(ˆy) > 0, which violates lemma 16.

a′1yb
Lemma 20. There exists C, κ > 0 such that infb
λ Pr(
|
∈

∞ −

u1| ≤

v

∩

a′1e1 > κ)

≥

Cv for all

suﬃciently small v > 0.

Lemma 20 Proof. Expression (34) implies that there exists ǫ > 0 such that for all δ

ǫ, ǫ] and

[
−

∈

λ we have

b

∈

σ/2

≤

Z

e′1aa′e1µu

a(a′(yb
∞

|

a)µa(da).
+ δe1)
|

Thus, for κ

≡

p

σ/(4¯µu) we have

σ/2

≤

≤

≤

Z

Z

Z

e′1aa′e11{

µu
a′e1 > κ
}

|

a(a′(yb
∞

a)µa(da) +
+ δe1)
|

κ2

a′e1 ≤

1{

¯µuµa(da)
κ
}

Z

e′1aa′e11{
α2

µu
a′e1 > κ
}
a(a′(yb
∞

|

|

µu
a′e1 > κ
}

1{

a(a′(yb
∞

a)µa(da) + σ/4
+ δe1)
|

a)µa(da) + σ/4,
+ δe1)
|

which in turn implies for δ

ǫ, ǫ]

[
−

∈

µu
a′e1 > κ
}

1{

a(a′(yb
∞

|

a)µa(da)
+ δe1)
|

≥

σ/(4α2).

Z

Now deﬁne u(a, δ)

a′(yb
∞

≡

+ δe1). If a′e1 > κ then ∂

∂δ u(a, δ) > κ, which with the result above

59

implies for all b

λ

∈

a′1yb
Pr(
|

∞ −

u1| ≤
a′yb

∞+v

v

∩

a′1e1 > κ)

=

=

κ

≥

= κ

κ

≥

Z Z

u=a′yb∞
−
v/(a′e1)

v

δ=

Z Z

v/(a′ e1)
−
min(ǫ,v/α)

µu
a′e1 > κ
}

1{

a)duµa(da)
a(u
|

|

µu
a′e1 > κ
}

1{

a) ∂
a(u(a, δ)
|

∂δ u(a, δ)dδµa(da)

|

µu
a′e1 > κ
}

1{

a(a′(yb
∞

|

a)dδµa(da)
+ δe1)
|

µu
a′e1 > κ
}

1{

a(a′(yb
∞

|

a)µa(da)dδ
+ δe1)
|

δ=

min(ǫ,v/α)

Z Z

−
min(ǫ,v/α)

δ=

min(ǫ,v/α) Z

−

Z

min(ǫ,v/α)

δ=

Z

−

min(ǫ,v/α)

σ/(4α2)dδ

= κσ/(2α2) min(ǫ, v/α).

References

Arcidiacono, Peter, Robert Miller. 2011. Conditional Choice Probability Estimation of Dynamic

Discrete Choice Models with Unobserved Heterogeneity. Econometrica 79(6) 1823–1867.

Arlotto, Alessandro, Itai Gurvich. 2019. Uniformly Bounded Regret in the Multisecretary Problem.

Stochastic Systems 9(3) 231–260.

Arlotto, Alessandro, Xinchang Xie. 2020. Logarithmic Regret in the Dynamic and Stochastic

Knapsack Problem with Equal Rewards. Stochastic Systems 10(2) 170–191.

Bruss, Thomas. 2000. Sum the Odds to One and Stop. The Annals of Probability 28(3) 1384–1391.

Bumpensanti, Pornpawee, He Wang. 2018. A re-solving heuristic with uniformly bounded loss for

network revenue management. Working Paper 1–44.

Caley, A. 1875. Mathematical questions with their solutions. The Educational Times 23 18–19.

Chen, Guanting, Xiaocheng Li, Yinyu Ye. 2021. How Linear Reward Helps in Online Resource

Allocation 1–41.

Ferguson, Thomas S. 1989. Who solved the secretary problem? Statistical Science 4(3) 282–289.

Freeman, P. R. 1983. The secretary problem and its extensions: A review. International Statistical

Review 51(2) 189–206.

60

Jiang, Jiashuo, Jiawei Zhang. 2020. Online resource allocation with stochastic resource consump-

tion. arXiv (March 2021).

Kleinberg, Robert. 2005. A multiple-choice secretary algorithm with applications to online auctions.

Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms 630–631.

Kosorok, Michael. 2008.

Introduction to Empirical Processes and Semiparametric Inference.

Springer.

Li, Xiaocheng, Yinyu Ye. 2019. Online Linear Programming: Dual Convergence, New Algorithms,

and Regret Bounds .

Lindley, Denis V. 1961. Dynamic programming and decision theory. Journal of the Royal Statistical

Society: Series C (Applied Statistics) 10(1) 39–51.

Mucci, Anthony. 1973. Diﬀerential Equations and Optimal Choice Problems. The Annals of

Statistics 1(1) 104–113.

Sun, Rui, Xinshang Wang, Zijie Zhou. 2021. Near-Optimal Primal-Dual Algorithms for Quantity-

Based Network Revenue Management. SSRN Electronic Journal 1–68.

van der Vaart, Aad W., Jon A. Wellner. 1996. Weak Convergence and Empirical Processes. Springer,

New York.

Vera, Alberto, Siddhartha Banerjee. 2019. The Bayesian Prophet: A Low-Regret Framework for

Online Decision Making. Working Paper 1–25.

Vera, Alberto, Siddhartha Banerjee, Itai Gurvich. 2019. Online Allocation and Pricing: Constant

Regret via Bellman Inequalities. Working Paper 1–41.

Vershynin, Roman. 2020. High-Dimensional Probability: An Introduction with Applications in Data

Science, vol. 20.

61

