Polymorphic dynamic programming by algebraic
shortcut fusion

Max A. Little?,†, Ugur Kayas?

August 20, 2021

?School of Computer Science, University of Birmingham, UK

†MIT, Cambridge, MA, USA

First author contact: maxl@mit.edu1

Dynamic programming (DP) is a broadly applicable algorithmic design paradigm for
the eﬃcient, exact solution of otherwise intractable, combinatorial problems. However,
the design of such algorithms is often presented informally in an ad-hoc manner, and as
a result is often diﬃcult to apply correctly. In this paper, we present a rigorous algebraic
formalism for systematically deriving novel DP algorithms, either from existing DP algo-
rithms or from simple functional recurrences. These derivations lead to algorithms which
are provably correct and polymorphic over any semiring, which means that they can be
applied to the full scope of combinatorial problems expressible in terms of semirings. This
includes, for example: optimization, optimal probability and Viterbi decoding, probabilis-
tic marginalization, logical inference, fuzzy sets, diﬀerentiable softmax, and relational and
provenance queries. The approach, building on many ideas from the existing literature on
constructive algorithmics, exploits generic properties of (semiring) polymorphic functions,
tupling and formal sums (lifting), and algebraic simpliﬁcations arising from constraint al-
gebras. We demonstrate the eﬀectiveness of this formalism for some example applications
arising in signal processing, bioinformatics and reliability engineering.

1 Introduction

Dynamic programming (DP) is one of the most eﬀective and widely used computational tools for
ﬁnding exact solutions to a large range of otherwise intractable combinatorial problems [Kleinberg
and Tardos, 2005]. Typically, the exhaustive (brute-force) solution to problems for which DP is
amenable are of exponential or even factorial, time complexity. Essentially, DP relies on a property of
the problem which enables assembling the ﬁnal solution out of “smaller”, self-similar versions of the
main problem, where smaller is with reference to the value of some parameter [Bellman, 1957]. Thus,
DP computations are normally recursive or stage-wise [Sniedovich, 2011]. Where DP is applicable,
it is often possible to reduce the worst case computational eﬀort required to solve the problem, to
something tractable such as low-order (quasi)-polynomial.

Nonetheless, devising correct and eﬃcient DP algorithms typically relies on special intuition and
insight [de Moor, 1999].
It is also often diﬃcult to prove correctness and gain understanding of
the function of these algorithms from their, sometimes inscrutable, implementations. To address
these shortcomings, a more systematic approach is to start with a (usually exhaustive) high-level

1This work partially funded by NIH grant UR-Udall Center, award number P50 NS108676.

1

speciﬁcation of the combinatorial problem, which is manifestly correct by design, and then compute
In this way,
an eﬃcient implementation of the same, through provably correct derivation steps.
the resulting algorithm is both eﬃcient and guaranteed correct. This approach is exempliﬁed in
constructive algorithmics frameworks described in e.g. Bird and de Moor [1996], de Moor [1991]
and Jeuring [1993]. These start from a very high level of mathematical abstraction and thus require
multiple derivation steps to reach a concrete implementation.

Yet, in many cases we already have a combinatorial recurrence or even an existing DP algorithm
on hand and we wish to quickly modify it in some way to suit a special purpose. Then, a high level of
abstraction may be an unnecessary technical burden. In this paper, we address this gap by introducing
a simple set of algebraic tools which allow such derivation steps to be carried out quite easily. Our
framework is applicable to a wide range of DP problems and we demonstrate its eﬀectiveness on some
practical, novel extensions of classical problems in signal processing, machine learning, computational
statistics and engineering.

Our approach brings together several ideas which have been used separately over many years in
diverse ﬁelds such as machine learning, computational linguistics and automata theory. Semirings
[Golan, 1999] are widely used in special DP applications [Huang, 2008, Goodman, 1999, Mensch and
Blondel, 2018, Li and Eisner, 2009], but lack a rigorous correctness justiﬁcation which we provide
here. This also clariﬁes the conditions under which the computational eﬃciency of semiring DP arises.
Furthermore, we show how semirings can often be combined (tupled) to signiﬁcant computational
advantage such as eliminating the need for backtracking in optimization problems. Algebraic lifting
has also been invoked to create novel algorithms (for example, lifting over monoids, Emoto et al.,
2012) but naive usage of this algebraic trick is computationally ineﬃcient. Here, we demonstrate how
to retain the value of lifting by providing new symbolic manipulations based on the algebraic structure
of the DP recurrence and the lifting algebra, and expanding the scope of this trick to non-standard
algebras which arise in some practical situations.

In Section 2, we detail the main theoretical developments of this paper, and in Section 3 we develop
DP algorithms for applications from several disciplines. Section 4 puts the work into the context
of existing research on DP algorithms in general. We end with a summary and discussion of the
importance, general scope and possible extensions of the work, in Section 5. The appendices con-
tain detailed proofs of the main results in the paper, list some widely-used semirings and simpliﬁed
constraint algebras, and illustrate more complex algorithm derivations involving multple constraints.

2 Theory

In this paper, sets are indicated by the upper case double-strike letters S, T with their corresponding
cardinalities, S = |S| and T = |T|, or the standard sets R, N etc. The Boolean set is given by
B = {T, F } (for true, false respectively). Algebras and objects such as graphs, monoids, groups and
semirings are given as tuples with upper-case caligraphic letters for names, e.g. S and M. Integer
and natural number indices are given by lower case letters n, i etc. Binary algebraic operators are
writen as circled symbols, ⊕, ⊗, (cid:12), and their corresponding identities are i⊕, i⊗,i(cid:12). Subscript notation
fn is used to index vectors, e.g. f ∈ R [N] is the (inﬁnite) vector of real numbers indexed by natural
numbers, f1, f2, . . . and so on, which can also be considered as a function, f : N → R. We also use the
subscript, fG,w, to denote the (polymorphic) function f computed using the algebra G and mapping
function w. Operators are subscripted to indicate lifting, e.g. ⊕M is the ⊕ operator lifted over the
algebra M.

2.1 DP semiring polymorphism via shortcut fusion

All DP solutions yield some form of functional equation known as Bellman’s recursion which relates
one stage of the solution to already-computed stages. This recursive computational structure can
be naturally captured in a weighted directed acyclic graph (DAG), each node of which represents the

2

value of the solution at each stage, the graph edges indicate the weighted dependency of each stage on
previous stages (see Figure 2 for some examples which we describe in detail below). We can therefore
describe DP computations as functional equations on the DAG with node labels V = {1, 2, . . . , N },
edge labels E = V × V and the (set-valued) function P : V → {V} giving the parent nodes which
encode the DAG structure. Given the edge weight map w : E → R, the DP solution fN is obtained
by computing:

f1 = 0
fv = max
v0∈P(v)

(cid:0)fv0 + w (cid:0)v, v0(cid:1)(cid:1)

∀v ∈ V − 1

(1)

Because operators + and max have identities which are the constants 0 and −∞ respectively, and
+ left and right distributes over max, together, they form a semiring on R, which we denote by R =
(R, max, +, −∞, 0) [Golan, 1999]. As is well known to practitioners, it is possible to swap this semiring
in (1) with any other semiring, call it S = (S, ⊕, ⊗, i⊕, i⊗), thereby yielding a solution to a related
DP problem with properties speciﬁc to the semiring and the edge map w [Huang, 2008, Goodman,
1999, Mensch and Blondel, 2018, Li and Eisner, 2009]. For example, the semiring (N, +, ×, 0, 1) with
edge map w (v, v0) = 1, counts the number of paths (lists of edges) in the DAG, which corresponds to
counting the number of possible DP conﬁgurations, determined by the connectivity of the DAG. In
abstract, the DP recurrence over semiring S with edge map w : E → S, is:

f1 = i⊗
fv = M
v0∈P(v)

(cid:0)fv0 ⊗ w (cid:0)v, v0(cid:1)(cid:1)

∀v ∈ V − 1

(2)

which we denote by fS,w. See Appendix C: A selection of semirings for a list of useful semirings.

Why is “semiring substitution” correct? By correct we mean:

it evaluates, using semiring S and
edge map w, all possible DAG paths encoded in P for the associated DP problem. We next develop a
theory to answer this and other related, questions.

There is a special semiring which, when inserted into (2), acts to exhaustively generate all possible
paths in the DAG. We call this special semiring the generator semiring G = ({[E]} , ∪, ◦, ∅, {[ ]}). This
well-known semiring (and variants) arise in several contexts; for example, to computational linguists
it is called the formal language semiring over sets of lists of E, which we denote by {[E]}. The operator
∪ is set union, and x ◦ y is the cross-join of two sets of lists x, y ∈ {[E]}, obtained by concatenating
each list of edges in x with each list in y. To illustrate for edge labels E = N:

{[3, 1] , [5]} ◦ {[8] , [2]} = {[3, 1, 8] , [3, 1, 2] , [5, 8] , [5, 2]}

(3)

As an example, the computational DAG of the hidden Markov model (HMM), called the HMM trellis,
has edges which can be uniquely encoded by their position in a length N sequence of observed states
[1, 2, . . . , N ], accompanied by a hidden state transition between K states {a, b, c, . . .}, one transition
per item in the sequence [Little, 2019]. The HMM DP recursion fG,w0 generates all KN paths in the
trellis, which typically begins:

{[(1, (a, a)) , (2, (a, a)) , . . .] , [(1, (a, b)) , (2, (b, a)) , . . .] , [(1, (b, a)) , (2, (a, b)) , . . .] , [(1, (b, b)) , (2, (b, a)) , . . .]}

(4)
Given the set of all possible generated paths through the DAG, it is clear that the solution to any
DP problem over some other semiring S = (S, ⊕, ⊗, i⊕, i⊗) with associated edge map w : E → S,
can always be computed in a brute-force manner by ﬁrst (a) mapping each element in each generated
path into values of type S, then (b) combining these values with ⊗, and ﬁnally (c) accumulating over
paths with ⊕. This exhaustive computation, which can be written as a function g : {[E]} → S, is a
homomorphism G → S, because it must preserve semiring structure. Speciﬁcally, for all x, y ∈ {[E]}:

3

Figure 1: Informal illustration of the dynamic programming (DP) semiring fusion theorem (6), the basis on which DP
computations in arbitrary semirings is justiﬁed.

g (x ∪ y) = g (x) ⊕ g (y)

g (x ◦ y) = g (x) ⊗ g (y)

g (∅) = i⊕
g ({[ ]}) = i⊗

(5)

along with the requirement that g ({[e]}) = w (e) for all e ∈ E. For example, the most probable HMM
sequence computation, known as Viterbi decoding, uses the homomorphism g : {[E]} → R+ taking
G → (cid:0)R+, max, ×, 0, 1(cid:1), where the edge labels are mapped into the corresponding observation-state
transition probabilities [Little, 2019].

Given this homomorphism g, which maps G together with the edge map w0 (e) = {[e]}, onto an
arbitrary semiring S together with its edge map w : E → S, the following “fundamental” theorem,
which we call DP semiring fusion, holds:

gS,w · fG,w0 = fS,w

(6)

The proof of this theorem, given rigorously in Appendix A: Proof of DP semiring fusion and infor-
mally illustrated in illustrated in Figure 1, is a straightforward application of Wadler’s free theorem
[Wadler, 1989].
Informally, because f is polymorphic (it uses only the semiring operators and the
edge map w), it must behave uniformly across all semirings, and the only remaining “computational
degrees of freedom” available are to rearrange i.e. delete, duplicate, re-order the edge labels. For
purely functional languages such as Haskell, (6) can be derived entirely from the type structure of f .

This elegent and succinct theorem has several very important consequences:

1. As discussed above, any DP problem over semiring S can be solved by ﬁrst exhaustively gener-
ating all possible paths in the corresponding DAG using the generator semiring G, then applying
the semiring S to the result using the homomorphism g. So, this is a (computational) proof by
exhaustion that the DP algorithm is correct (in the sense discussed above).

2. Although correct, this exhaustive implementation is usually computationally intractable since it
requires, as an intermediate step, the generation and storage of all possible DP DAG paths. This
computational intractability ordinarily stems from the fact that G’s operators are ineﬃcient. For
example, computing x ◦ y is quadratic in the size of each set, and the length of the edge lists
they contain. The amount of memory required also grows quadratically with each invocation.
This entirely negates the point of DP algorithms which is that they are eﬃcient solutions to
otherwise intractable combinatorial problems.

3. However, (6) implies that there are two distinct but equal in value, ways of computing the DP
solution, so we are free to implement whichever way is most computationally eﬃcient.
It is
normally the case that semiring S’s operators take vastly less computational eﬀort and memory

4

than G’s. In fact, constant O (1) time and space is typical for the vast majority of practical semir-
ings (consider for instance max and +). Thus, usually, the right hand side of (6) is vastly more
computationally eﬃcient than the left hand side, so this is clearly the preferred implemention.

In the constructive algorithmics literature, theorem (6) is an example of shortcut fusion, so-called
because it bypasses the explicit construction of the intermediate DAG paths, fusing the computation
into a single DP recursion [Hinze, 2010]. A similar theorem to (6) applied to semiring polymorphic
computations over lists, can be found in Emoto et al. [2012].

Of course, the eﬃciency of this computation also fundamentally reﬂects the structural decomposition
of the DP problem, but DP semiring fusion justiﬁes the decoupling of the type of the quantities
computed from the structure of the computation. The proof of (6), which to our knowledge is novel,
serves to formalize this decoupling.

2.2 Constraint lifting

A widely stated, but intuitive observation, is that designing useful DP algorithms boils down to
identifying a structural decomposition which makes frequent re-use of sub-problems [Kleinberg and
Tardos, 2005]. This design principle is easy to state, but often quite tricky to apply in practice, as
it can depend upon a serendipitous discovery of the right way to parameterize the problem. Is there
some way of systematizing this? We turn to addressing this problem next.

As a starting point, consider the problem of ﬁnding the minimum sum subsequence of a list. Al-
though there are 2N such subsequences, semiring distributivity allows us to write down the following
simple O (N ) polymorphic semiring recurrence which, instantiated in the min-sum semiring, allows us
to solve the stated problem:

f0 = i⊗
fn = fn−1 ⊗ (i⊗ ⊕ w (n))

∀n ∈ {1, 2, . . . , N }

(7)

where w : N → S. This is not a DP recurrence, since, save for the immediately previous value, the
second line does not refer to any other “subproblems”. In fact, such a recurrence can be computed in
any order so there is no real, meaningful notion of subproblem here anyway (it is perhaps much closer
to a greedy algorithm than anything else, Bird and de Moor 1996).

Now, let us suppose we want to constrain this algorithm to only compute over subsequences of ﬁxed
length M . A guaranteed correct (but not at all “smart”) solution to this problem is the following
strategy. Firstly, compute all subsequences using the generator semiring G, and then remove (ﬁlter
away) those whose length is not equal to M . Finally, by applying the homomorphism g to the
remaining subsequences, we have a manifestly correct way of solving the constrained problem. The
diﬃculty with this approach is the same as faced above: the exponential complexity of the intermediate
subsequence generation. As a result, this brute-force solution is impractical. How can this computation
be made more eﬃcient?

The strategy we will take is based on the following idea: if we can ﬁnd a new semiring which allows
us to fuse the constraint with the semiring homomorphism (5), then by DP semiring fusion (6), we can
hope to eliminate the ﬁltering step and thus the need to generate the intermediate data structures,
exploiting the eﬃciency of the existing recurrence.

To apply this strategy, we will need constraints expressed in a separable form. Although not entirely
general, many kinds of constraints typically encountered in integer programming problems, are in this
form [Sniedovich, 2011]. Such separable constraints can be formalized using a constraint algebra which
we denote by M = (M, (cid:12), i(cid:12)). The binary operator (cid:12) is, usually accompanied by an identity, i(cid:12) (but
this is not essential in some applications). Then, a typical constraint is expressed as a recurrence hM,v
over a list of DAG edges of length L:

h0 = i(cid:12)
hl = hl−1 (cid:12) v (el)

∀l ∈ {1, 2, . . . , L}

(8)

5

where the constraint map v : E → M maps edges into the constraint set. Example algebras include
arbitrary ﬁnite monoids ((cid:12) is associative) and arbitrary ﬁnite groups (additionally, inverse elements).
To complete the speciﬁcation of the constraint, we deﬁne a Boolean acceptance condition, a : M → B,
whereby a list of edges is retained if a (hL) evaluates to true. Thus, in the formalism of this paper, a
constrained DP problem is expressed as a modiﬁed version of (6):

gS,w · φM,v,a · fG,w0
(9)
where φ is a ﬁltering function mapping {[S]} → {[S]} which, given a set of lists, retains only the lists
which satisfy the acceptance criteria. To illustrate, a speciﬁc, recursive implementation can be written
as [Bird and de Moor, 1996]:

φ (∅) = ∅

φ ({x}) =

({x} a (hM,v (x)) = T
otherwise
∅

φ (x ∪ y) = φ (x) ∪ φ (y)

(10)

To give a concrete example of this constraint formalism, with the additive constraint group M =
(N, +, 0), the constraint with the edge mapping v (x) = 1 computes lengths of DP DAG edge sequences
for any item in the sequence. Indeed, this algebra is just the list length homomorphism deﬁned by the
recursion h0 = 0, hl = hl−1 + 1 [Bird and de Moor, 1996]. Thus, the recurrence (7) coupled with this
constraint group and the condition:

a (m) =

(T m = M

F otherwise

(11)

ﬁnds all sublists of length M , i.e. (6) evaluates semiring computations over list combinations of size
M from lists of length N .

The semiring which solves the above problem is obtained by lifting the original semiring over the
algebra M [Jeuring, 1993, Emoto et al., 2012]. The proof is given in Appendix B: Constraint lifting
proofs. We will argue below that this algebraic lifting “dissolves”, to a large extent, the problem of
how to perform the necessary DP decomposition which solves the constrained problem eﬃciently.

Lifting deﬁnes a vector of semiring values f ∈ S [M] indexed by M, which we can also conceptualize
as functions, f : M → S. The new, composite semiring S [M] = (S [M] , ⊕M, ⊗M, i⊕M, i⊗M) has
binary operators over all x, y ∈ S [M]:

and associated identities:

(x ⊕M y)m = xm ⊕ ym
(x ⊗M y)m = M

(xm0 ⊗ ym00)

m0(cid:12)m00=m
m0,m00∈M

(i⊕M)m = i⊕ ∀m ∈ M
(i⊗ m = i(cid:12)
i⊕ otherwise

(i⊗M)m =

We also need the lifted edge mapping, wM : E [M] → S:

wM (x)m =

(w (x)
i⊕

v (x) = m
otherwise

(12)

(13)

(14)

where w : E → S and v : E → M. Finally, to obtain the solution to (9), we need to project the lifted
vector over M onto B:

6

πS,a (x) = M

xm0

m0∈M:a(m0)=T

(15)

This yields all the ingredients to deﬁne a theorem which we call DP semiring constrained fusion:

gS,w · φM,v,a · fG,w0 = πS,a · fS[M],wM
See Appendix B: Constraint lifting proofs for the proof of this and the claims above it. Several
comments about this theorem are in order:

(16)

1. Constrained fusion allows the creation of new polymorphic DP algorithms from existing recur-
rences. To see this, note that the semiring homomorphism gG,w0 is the identity homomorphism
for the semiring G. Inserting this into (16), we obtain:

gG,w0 · φM,v,a · fG,w0 = φM,v,a · fG,w0
= πG,a · fG[M],w0
= f 0

M

G[M],w0

M

(17)

The new, composite function f 0
is polymorphic in an arbitrary semiring S. It therefore
S[M],wM
satisﬁes the conditions of DP semiring fusion (6), leading to gS,w · f 0
=
πS,a · fS[M],wM. This implies that we can use lifting to apply a constraint, leading to a new
polymorphic DP recurrence computable over any arbitrary semiring.

S[M],wM

G[M],w0

= f 0

M

2. Furthermore, we can repeat this procedure above to derive novel, polymorphic DP recurrences
with multiple constraints. This is possible, essentially, because lifting can always be “nested”, i.e.
lifted semirings can themselves be lifted. This idea is illustrated in Appendix E: Supplementary
algorithm derivations: applying multiple constraints.

3. The eﬀect on the computational and memory complexity of the original recurrence is predictable.
For each value of m ∈ M, the binary operator ⊕M is O (1), and the operator ⊗M is O (cid:0)M 2(cid:1).
Computing the result normally requires one iteration over the constraint set per iteration of the
original recurrence. Thus, in general, applying a constraint increases the worst-case computa-
tional complexity of an existing recurrence multiplicatively by O (cid:0)M 3(cid:1). In terms of memory,
lifting requires storing M values per DP DAG graph node, therefore the memory complexity
increases multiplicatively by O (M ).

4. This approach to constructing DP algorithms may seem rather detached from the usual con-
ceptual approach to DP found in textbooks. Nonetheless, they are intimately related, in the
following way. Implicit to the deﬁnition of the constraint operator (cid:12) is the relationship that
solutions for diﬀerent values of the constraint, have with each other. The lifted product in (12)
combines all solutions at every value of the constraint. However, for each m ∈ M, the condition
m0 (cid:12) m00 = m in the product partitions the solutions in a way which determines how the DP
sub-problems should be combined. In other words, this partitioning, coupled with the pairwise
summation, determines the dependency structure of the (implicit) computational DAG. Inter-
estingly, this also demonstrates that DP decompositions can be performed in ways that are much
more general than the fairly limited descriptions of combining “smaller”, self-similar problems.
Indeed, it is useful to think of DP decomposition as arising from a partitioning of the space of
the constraint under the constraint operator, into two subsets for a given value of m ∈ M.

This “constraint-driven” DP decomposition is a key step in the systematic construction of practical
DP algorithms, but depending upon the size of M, it may not be computationally eﬃcient. The next
section focusses on algebraic optimizations of this decomposition to make it practical.

7

2.3 Simplifying the constraint algebra

The main problem with this construction is that the direct computation of x ⊗M y is quadratic in the
size of M. This is not a problem for small lifting sets, but for many practical problems we want to
apply constraints which can take on a potentially large set of values, which makes the naive application
of constraint lifting, computationally ineﬃcient. We also know that it is often possible to come up
with hand-crafted DP algorithms which are more eﬃcient.

We can, however, substantially improve on this quadratic dependence by noting that for many DP
algorithms, we need to compute terms of the form a ⊗M wM (x) for some general a ∈ S [M]. Since
the lifted mapping function wM (x)m 6= i⊕ only for one value, m00 = v (x), we can simplify the double
summation to a single one:

(a ⊗M wM (x))m = M

(am0 ⊗ wM (x)m00)

m0(cid:12)m00=m
m0,m00∈M


=






M

am0

m0∈M
m0(cid:12)v(x)=m








⊗ w (x)

(18)

Because the operator (cid:12) does not necessarily have inverses, solutions m0 ∈ M to the equation
m0 (cid:12) v (x) = m are not necessarily unique. However, we can ﬂip this around and instead explicitly
compute m = m0 (cid:12) v (x) for each m0 ∈ M. This leads to an obvious iterative algorithm:

z ←
zm(cid:12)v(x) ←

i⊕M
zm(cid:12)v(x) ⊕ (am ⊗ w (x))

∀m ∈ M

(19)

to obtain a ⊗M wM (x) = z at the end of the iteration. Thus the product (18) is an inherently
O (M ) operation. As a result, DP recurrences derived using this simpliﬁcation will have a worst-case
multiplicative increase in time complexity of O (cid:0)M 2(cid:1).

If, additionally, the algebra M has inverses (for example, if the algebra is a group), on ﬁxing
m and m0, there is a unique (and often analytical) solution to m0 (cid:12) m00 = m which we can write as
m00 = (m0)−1(cid:12)m. This also allows us to simplify the lifted semiring product to the O (M ) computation:

(x ⊗M y)m = M
m0∈M

(cid:16)

xm0 ⊗ y(m0)−1(cid:12)m

(cid:17)

(20)

Note that we often have ﬁnite groups where we are not interested in deﬁning inverses for all elements,
for example where we need y(m0)−1(cid:12)m but (m0)−1 (cid:12) m /∈ M. In that case, setting y(m0)−1(cid:12)m = i⊕
suﬃces to appropriately truncate the above product.

For such group lifting algebras, terms of the form a ⊗M wM (x) simplify even further. We can solve
m0 (cid:12) v (x) = m uniquely to ﬁnd m0 = v (x)−1 (cid:12) m, so that the product (18) can, in this situation, now
be computed as:

(a ⊗M wM (x))m =






i⊕
am(cid:12)v(x)−1 ⊗ w (x) otherwise

m (cid:12) v (x)−1 /∈ M

(21)

which is an O (1) time operation. Thus, DP recurrences derived using group lifting constraints,
are often computable with additional, multiplicative time complexity increase of only O (M ). Some
examples of useful, simpliﬁed constraint algebras are listed in Appendix D: Some useful constraint
algebras.

8

(cid:91)
(cid:91)
Algorithm 1 Procedural pseudocode implementation of a polymorphic, O (N M ) time complexity
DP algorithm for subsequence combinations, derived systematically from a polymorphic subsequence
recurrence using constraint lifting and algebraic simpliﬁcations described in the text.

function polycombs (⊕, ⊗, i⊕, i⊗, w, N, M )
f [0, 0] = i⊗
f [0, 1 . . . M ] = i⊕
for n = 1 . . . N

for m = 0 . . . M
if m = 0

f [n, m] = f [n − 1, 0]

else

f [n, m] = f [n − 1, m] ⊕ f [n − 1, m − 1] ⊗ w (n)

return f [N, M ]

2.4 Putting the theory to work: an example

Let us look at a simple application of the theory above. Consider the length constraint for subsequences
with the lifting algebra M = ({1, . . . , M } , +, 0) and the lifted mapping function v (n) = 1. Inserting
the lifted semiring into the subsequence recursion (7), we get:

f0,m = (i⊗M)m
fn,m = (fn−1 ⊗M (i⊗M ⊕M wM (n)))m

The ﬁrst line above becomes:

f0,m =

(i⊗ m = 0
i⊕ otherwise

and the second line can be simpliﬁed as follows:

fn,m = (fn−1 ⊕M fn−1 ⊗M wM (n))m
= fn−1,m ⊕ (fn−1 ⊗M wM (n))m

= fn−1,m ⊕

(i⊕
fn−1,m−1 ⊗ w (n)

m − 1 /∈ M
otherwise

=

(fn−1,0
fn−1,m ⊕ (fn−1,m−1 ⊗ w (n)) otherwise

m = 0

(22)

(23)

(24)

for all n ∈ {1, 2, . . . , N } and m ∈ {1, 2, . . . , M }. With the simple acceptance condition a (m) = T if
m = M , we have πS,a (f ) = fN,M , which leads to a straightforward O (N M ) time polymorphic DP
algorithm for computing arbitrary semiring computations over sublist combinations of length M (for
semirings wherein the operators can be evaluated in constant time). We can also write this in more
imperative style pseudocode, see Algorithm 1. Figure 2 provides an alternative presentation, in terms
of the corresponding DP subproblem DAG, of the above algorithm derivation.

It is instructive to compare this systematically derived algorithm to the textbook presentation
of similar DP algorithms such as the quasi-polynomial knapsack problem [Kleinberg and Tardos,
2005, Emoto et al., 2012]. We have obtained this polymorphic implementation by starting from a
simple and obviously correct recurrence, and by provably correct derivation steps, arrived at the new,
computationally eﬃcient recurrence above which solves the constrained problem. Often, the solutions
obtained this way resemble hand-coded DP algorithms which involve ad-hoc and speciﬁc reasoning,

9

Figure 2: Deriving a polymorphic DP algorithm for subsequence combinations of length m by lifting over the subsequence
length constraint algebra M = (M, (cid:12), i(cid:12)) = ({1, . . . , M } , +, 0) with v (n) = 1, illustrated in terms of the corresponding
DP subproblem DAGs (2). (a) The starting point is the all subsequence algorithm (7) having a trivial graph with no
subproblem sharing/overlap. (b) The constraint algebra is a group (and therefore has inverse elements), so that the
lifted semiring convolution product ⊗M has a simple, computationally eﬃcient, form. (c) The derived subproblem
DAG obtained by lifting algorithm (a) over M, has maximal subproblem sharing and eliminates all redundant DAG
edges implied by naive application of constraint lifting.

and where we have to resort to special case analysis to demonstrate correctness and computational
complexity, after the algorithm is coded.

2.5 Tupling semirings to avoid backtracking

The above cases have demonstrated the use of arbitrary semirings where some scalar-valued, numerical
solution is required.
It is often the case for optimization problems (involving the use of selection
semirings such as max-product or min-plus) that we also want to know which solutions lead to the
optimal (semiring) value. The usual solution to this (in most DP literature) is backtracking, which
retains a list of decisions at each stage and a series of “back pointers” to the previous decision, and
then recovers the unknown decisions by following the sequence of pointers backwards.

In fact, we can avoid the need to do backtracking at all, and gain considerable ﬂexibility at the same
time, if we use an appropriate semiring. In particular we will focus on the generator semiring G. We
can always exploit what is known as the tupling trick to apply two diﬀerent semirings simultaneously
[Bird and de Moor, 1996]. If we map the semiring values used during the DP computations inside a
pair (S, {[S]}), then we can simultaneously update a semiring total while retaining the values selected
in that stage. For example, the arg-max-plus selection, also known as the Viterbi, semiring [Goodman,
1999, Emoto et al., 2012]:

SG = ((S, {[S]}) , ⊕, ⊗, (−∞, ∅) , (0, {[ ]}))

is deﬁned by:

(a, x) ⊕ (b, y) =






(a, x)
(b, y)
(a, x ∪ y) otherwise

a > b
a < b

(25)

(26)

(a, x) ⊗ (b, y) = (a + b, x ◦ y)

with identities i⊕ = (−∞, ∅) and i⊗ = (0, {[ ]}). Furthermore, it is straightforward to construct a
semiring which extends the Viterbi semiring by maintaining a ranked list of optima, i.e. computing
the top k optimal solutions, not merely the single highest scoring one [Goodman, 1999].

10

If we are only interested in ﬁnding a single, rather than potentially multiple, optimal solutions, we

can remove the ambiguities in the selection with a simpler version of the addition operator:

(a, x) ⊕ (b, y) =

((a, x) a ≥ b
a < b

(b, y)

(27)

Clearly, the semiring SG is the tupling of max-plus with G in such a way as to compute both the value
of the optimal solution alongside the values used to compute it.

Backtracking and the simple (Viterbi) tupled semiring are similar in terms of computational com-
plexity. With backtracking, assuming N decisions have been made, these must be traversed which
takes O (N ) time at the end of the DP recursion. For tupled semirings, the complexity is the same as
the DP recursion itself (assuming that the non-ambiguous ⊕ operator (27) is used). However, from an
implementation point of view backtracking requires a way to traverse the DP recurrence correctly in
the reverse order, which is special to each DP recurrence. With tupled semirings, all that is required
is to change the semiring of the DP recursion as described above. Thus we can see that, in terms of
conceptual and often implementation, diﬃculty, classical backtracking is inferior to the ﬂexibility and
simplicity of semiring tupling for sophisticated tracing of optimal DP solutions.

3 Applications

In this section we will investigate some practical applications of the algebraic theory developed above.

3.1 Segmentation

A problem of perennial importance in statistics and signal processing is that of segmentation, or
dividing up a sequence of data items or a time series yn for n ∈ {1, 2, . . . , N }, into contiguous, non-
overlapping intervals (i, j) for i, j ∈ {1, 2, . . . , N } with i ≤ j. An example is the problem of (1D)
piecewise regression, which involves ﬁtting a curve f (n, ai,j) to segments, and minimizing the sum
of model ﬁt errors E (x) = PN
n=i |yn − f (n, ai,j)|p for p > 0 and
i=1 xi,jei,j, where ei,j = 1
p
xi,j ∈ {0, 1} being segment indicators. The optimal model parameters ai,j can be estimated using any
statistical model-ﬁtting procedure [Little, 2019].

Pj

Pj

j=1

We can pose the segmentation selection as the minimization problem ˆE = minxi,j ∈{0,1} E (x). An
O (cid:0)N 2(cid:1) DP algorithm for this problem was devised by Richard Bellman as follows [Kleinberg and
Tardos, 2005]. The optimal segmentation ending at index j can be obtained by combining all the
“smaller” optimal segmentations (. . . , i − 1) with the following segments (i, j), for all i ∈ {1, 2, . . . , j}.
This gives rise to the following recursion:

f0 = 0
fj = min

i∈{1,2,...,j}

[fi−1 + ei,j]

∀j ∈ {1, 2, . . . , N }

(28)

so that ˆE = πS,a (f ) = fN . From the theory in Section 2, we are justiﬁed in calling the polymorphic
version of this recursion the DP segmentation algorithm:

f0 = i⊗
fj = M

i∈{1,2,...,j}

[fi−1 ⊗ w (i, j)]

∀j ∈ {1, 2, . . . , N }

(29)

Using this polymorphic version, we can, for example, obtain the optimal segmentation indices ˆxi,j
using the tupled selection semiring, see Section 2.5.

Since the ei,j are all non-negative and shorter segments are typically more accurately modelled than
larger segments (given the same model structure across segments), the problem as stated above usually
has a “degenerate” optimal solution with only the ‘diagonal’ segments xi,i, i ∈ {1, 2, . . . , N } of length

11

1, selected. To avoid the collapse onto this degenerate solution, we can regularize the sum [Little,
2019]:

ˆE = min

xi,j ∈{0,1}

[E (x) + λC (x)]

(30)

for the regularization constant λ > 0 where C (x) = P
i,j∈{1,2,...,N } xi,j counts the number of selected
segments. Our polymorphic DP recursion (29) can be modiﬁed to include this regularization by setting
w (i, j) = ei,j + λ.

While this regularization approach is simple, it does not oﬀer much control over the segmentation
quality, as the appropriate choice of the single parameter λ can be diﬃcult to obtain. For example,
some choices lead to over and under-ﬁtting in diﬀerent parts of the same signal, see Figure 4(a).
Instead, a more eﬀective level of control can be obtained by directly constraining the segmentation to
a ﬁxed number of segments, which we can express as:

ˆEL = min

xi,j ∈{0,1}
C(x)=L

E (x)

(31)

which can be solved using the algebraic methods described above, as follows.

First, the constraint needs to count the number of segments up to the ﬁxed number of segments
L, which implies we need the lifting algebra M = ({1, 2, . . . , L} , +, 0) and lifted mapping function
v (i, j) = 1, with acceptance condition a (m) = T if m = L. Next, inserting the corresponding lifted
semiring into (29) we obtain:

f0,m = (i⊗M)m
(cid:17)
(cid:16)
[⊕M]i∈{1, 2, . . . j} [fi−1 ⊗M wM (i, j)]
fj,m =

∀j ∈ {1, 2, . . . , N }

m

(32)

As above, the ﬁrst line simpliﬁes to f0,m = i⊗ for m = 0 and i⊕ otherwise, and the second line
becomes:

fj,m = M

[fi−1 ⊗M wM (i, j)]m

i∈{1,2,...,j}

= M

i∈{1,2,...,j}

(i⊕
fi−1,m−1 ⊗ w (i, j) otherwise

m − 1 /∈ M

(33)

(i⊕
L

=

i∈{1,2,...,j} fi−1,m−1 ⊗ w (i, j) otherwise

m = 0

using the group product simpliﬁcation (21) in the second step. Applying the acceptance condition we
get ˆEL = πS,a (f ) = fN,L, obtained in O (cid:0)N 2L(cid:1) time with O (N L) memory. In practice, this algorithm
produces much more predictable results that the basic algorithm, see Figure 4(b). Interestingly, it
is well-known in machine learning circles that the ubiquitous K-means clustering problem [Little,
2019], which is computationally intractable for non-scalar data items and therefore approximated
using heuristic algorithms, can be solved exactly using the algorithm derived above for scalar data
[Gronlund et al., 2018]. However, existing algorithms presented in the literature are not formally
proven correct and are not expressed polymorphically, as we show here.

Furthermore, it is trivial to expand the acceptance criteria a above to e.g. solve constraints of the
form L0 ≤ C (x) ≤ L, giving an upper and lower bound on the number of segments, by modifying
a (m) = T for when L0 ≤ m ≤ L. The optimal solution is thus obtained from the result of the recursion
(33) by computing:

ˆE[L0,L] = πS,a (f ) = M

fN,m

(34)

The segment count constraint above is fairly straightforward and has been (re)-invented in an ad-hoc
manner before [Terzi and Tsaparas, 2006]. We will next show how to derive a segmentation algorithm

L0≤m≤L

12

with more elaborate constraints which would be much more diﬃcult to derive without systematic tools
such as we describe here. While the segment count constraint is certainly very practical, there are
other ways to control the segmentation since we may not know the number of segments in advance.
The length, # (i, j) = j −i+1, of each segment is a property of key practical importance. For example,
it would be extremely useful in many applications to control the minimum length of each segment:

ˆEmin #=L = min

xi,j ∈{0,1}
min #(x)=L
o
n
# (i, j) : (i, j) ∈ {1, 2, . . . , N }2 , xi,j = 1

E (x)

(35)

is the set of lengths of all the selected seg-

where # (x) =
ments.

Following the procedure above, we have the lifting algebra M = ({1, 2, . . . , N } , min, N ) and lift
mapping function v (i, j) = j − i + 1. For the lifted segmentation recursion (32), the ﬁrst line becomes:

f0,m =

(i⊗ m = N
i⊕ otherwise

(36)

We also need the product (18), which becomes:

(a ⊗M wM (i, j))m =








M

m0∈{1,2,...,N }
min(m0,#(i,j))=m








am0

⊗ w (i, j)

(37)

This lifting algebra is a monoid without analytical (and unique) inverses, so, to make progress, we
need to ﬁnd an explicit expression for the set {min (m0, # (i, j)) = m} for m0 ∈ {1, 2, . . . , N }. There
are three cases to consider:

(cid:8)m0 : min (cid:0)m0, # (i, j)(cid:1) = m(cid:9) =






m < # (i, j)
{m}
{m, m + 1, . . . , N } m = # (i, j)
m > # (i, j)
∅

(38)

Inserting this into the product above, we get:

(a ⊗M wM (i, j))m =












am
⊕N
i⊕

m < # (i, j)
m0=mam0 m = # (i, j)
m > # (i, j)







⊗ w (i, j)

(39)

so that the second line of the lifted segmentation recursion (32) can be simpliﬁed:

fj,m = M

i∈{1,2,...,j}

[fi−1 ⊗M wM (i, j)]m

= M

i∈{1,2,...,j}












fi−1,m
⊕N
i⊕

m < # (i, j)
m0=mfi−1,m0 m = # (i, j)
m > # (i, j)







⊗ w (i, j)

(40)

= M

i∈{1,2,...,j}


fi−1,m ⊗ w (i, j)

(cid:16)
⊕m0={m,m+1,...,N }fi−1,m0

i⊕

(cid:17)

m < # (i, j)

⊗ w (i, j) m = # (i, j)

m > # (i, j)

for all j ∈ {1, 2, . . . , N }. Using the acceptance condition a (m) = T if m = L we have an O (cid:0)N 3(cid:1)
time DP algorithm to ﬁnd the required solution, ˆEmin #=L = πS,a (f ) = fN,L. As above, a simple
modiﬁcation of the acceptance function allows, for example, computing optimal segmentations across

13

Figure 3: DP segmentation algorithms derived using our novel algebraic framework for solving constrained, 1D seg-
mented, least-squares linear regression, applied to synthetic, piecewise linear time series with i.i.d. Gaussian noise,
standard deviation σ. Input data yn (grey dots), underlying piecewise constant signal (grey line), segmentation result
(red line). (a) Unconstrained segmentation with regularzation λ = 15, noise σ = 15, (b) with ﬁxed number segments
L = 3, noise σ = 30, (c) with minimum segment length M = 70, noise σ = 60, and (d) for comparison, L1 trend
ﬁltering with regularization λ = 103.

a range of minimum segment lengths. Applied to the scalar K-means problem, this modiﬁcation would
be a viable approach to avoiding the problem of degenerate clusters assigned few or no items [Little,
2019].

We ﬁnd that constrained DP segmented regression, derived using the algebraic methods introduced
here, usually produces very interpretable results, even for problems where the segmentation boundaries
may be quite diﬃcult to determine using other methods, particularly when the signal-to-noise ratio
is low, see Figure 3. For example, methods such as L1 trend ﬁltering [Kim et al., 2009] suﬀer from
the problem that there is often no single, unambiguous segmentation, see for example Figure 3(d) and
Figure 4(d). This is because it is better to consider such L1-based methods as smoothing algorithms
arising from a convex relaxation of the combinatorial segmentation problem. This clearly shows the
advantage of constrained, exact combinatorial optimization in applications such statistical time series
analysis, made practical by the algebraic approach described in this paper.

3.2 Sequence alignment

Our next application focus is sequence alignments, a problem of central importance to computational
biology, natural language processing and signal processing. For example, in genomic sequence analysis,
we are often interested in knowing how closely related two DNA or RNA base pair sequences are, and
this can be assessed by computing the most plausible series of mutations (insertions and deletions)
needed in order to bring the two sequences into alignment. There are usually multiple possible series
of insertions and deletions, so a cost must be attached to each insertion, deletion or match, at each
position in the alignment. This series cost is usually quantiﬁed in terms of the base pair mismatch at
each alignment position. The total cost is the sum of the cost at each position in the alignment.

One of the earliest and most widely used methods for minimizing this cost, is the Needleman-Wunsch
(NW) DP algorithm [Pachter and Sturmfels, 2005], the usual presentation of which is given in the
min-sum semiring:

14

Figure 4: DP segmentation algorithms derived using our novel algebraic framework for solving constrained, 1D seg-
mented, least-squares linear regression, applied to a sample of logarithmically-transformed S&P500 ﬁnancial index
daily values. Input data yn (grey lines), segmentation result (red line). (a) Unconstrained segmentation with regu-
larzation λ = 1.78 × 10−5 , (b) with ﬁxed number segments L = 4, (c) with minimum segment length M = 50 days,
and (d) for comparison, L1 trend ﬁltering with regularization λ = 100.

f0,0 = 0
fi,0 = fi−1,0 + w (i, 0)
f0,j = f0,j−1 + w (0, j)
fi,j = min (fi−1,j−1 + w (i, j) , fi−1,j + w (0, j) , fi,j−1 + w (i, 0))

(41)

for all i ∈ {1, 2, . . . , N } and j ∈ {1, 2, . . . , M }, where w (i, j) is the cost of the alignment of the ﬁrst
sequence at position i, with the second sequence at position j. The polymorphic abstraction of the
above is clear:

f0,0 = i⊗
fi,0 = fi−1,0 ⊗ w (i, 0)
f0,j = f0,j−1 ⊗ w (0, j)
fi,j = (fi−1,j−1 ⊗ w (i, j)) ⊕ (fi−1,j ⊗ w (0, j)) ⊕ (fi,j−1 ⊗ w (i, 0))

(42)

with the result obtained at fN,M .

We can use this for various purposes such as enumerating all possible alignments. While a closed-
form formula for the number of alignments D (N, M ) is not known, substituting the counting semiring
S = (N, +, ×, 0, 1) with w (i, j) = 1 into the above, gives us f0,0 = 1, fi,0 = fi−1,0, f0,j = f0,j−1 and
fi,j = fi−1,j−1 + fi−1,j + fi,j−1, simplifying to the following recurrence for D (N, M ):

D (n, m) =

(1

(n = 0) ∨ (m = 0)

D (n − 1, m − 1) + D (n − 1, m) + D (n, m − 1) otherwise

(43)

This describes the well-known Delannoy numbers which for M = N is Sloane [2021, sequence A001850],
with leading order asymptotic approximation D (N, N ) ≈ 5.8N . Thus, semiring polymorphism allows
us to show that brute-force computation of all alignments would be intractable as it requires ex-
ponential time complexity, whereas the factorized DP implementation has O (N, M ) e.g. quadratic,
computational cost (Figure 5).

One practical problem with the standard NW algorithm is that it places no constraint on how far
the sequences can become out of alignment. After all, any two DNA/RNA sequences are related by an
arbitrary number of insertions/deletions, but this has no biological signiﬁcance in general. It would be

15

useful to bound e.g. the sum of the absolute diﬀerence in sequence positions, so that we can exclude
spurious alignments between sequences which bear no meaningful relationship to each other.

One way to do this using the theory developed above is to set up the simple constraint algebra

v (i, j) = |i − j| and M = (N, +, 0). As this is a group, we can insert this into (21) to obtain:

(a ⊗M wM (i, j))m =

(i⊕
am−|i−j| ⊗ w (i, j)

m < |i − j|
otherwise

which we write as (a (cid:126) w (i, j))m for convenience. Inserting this into (42), we arrive at:

f0,0,m =

(i⊗ m = 0
i⊕ otherwise

fi,0,m = (fi−1,0 (cid:126) w (i, 0))m
f0,j,m = (f0,j−1 (cid:126) w (0, j))m
fi,j,m = (fi−1,j−1 (cid:126) w (i, j))m ⊕ (fi−1,j (cid:126) w (0, j))m ⊕ (fi,j−1 (cid:126) w (i, 0))m

(44)

(45)

for all i ∈ {1, 2, . . . , N } and j ∈ {1, 2, . . . , M }.

Further rearrangements based on case analysis are possible and may improve the readability of the
algorithm, but as they do not generally improve implementation eﬃciency, we do not explore further
here. The length of alignments, lying between max (N, M ) and N + M , should be taken into account
when choosing the acceptance function and thereby bounding the alignment diﬀerence sum. The result
is an O (N M L) time complexity algorithm for maximum sum of absolute alignment diﬀerences L.

Although the alignment diﬀerence sum is convenient algebraically, another constraint which may be
useful is the maximum absolute alignment diﬀerence. Bounding this quantity gives more precise control
over the extent to which the sequences can become misaligned before the sequences are considered
not to be matched at all. To implement this using the algebraic theory developed above, we need the
constraint algebra v (i, j) = |i − j| and M = ({0, 1, . . . , N 0} , max, 0), where N 0 = max (N, M ) is the
upper bound on the possible sequence misalignment. Because M is a monoid, we need to modify the
general lifted product (18):

(a ⊗M wM (i, j))m =








M

m0∈{0,1,...,N 0}
max(m0,|i−j|)=m








am0

⊗ w (i, j)

Now, we need to ﬁnd an explicit expression for the set {max (m0, |i − j|) = m} for m0 ∈ {0, 1, . . . , N 0}.

Similar to the situation with constrained segmentations above, there are three cases to consider:

(cid:8)m0 : max (cid:0)m0, |i − j|(cid:1) = m(cid:9) =





m > |i − j|
{m}
{0, 1, . . . , m} m = |i − j|
m < |i − j|
∅

(46)

which gives rise the following general lifted product:

(a ⊗M wM (i, j))m =






am ⊗ w (i, j)
(cid:16)
⊕m0∈{0,1,...,m}am0
i⊕

(cid:17)

m > |i − j|

⊗ w (i, j) m = |i − j|

m < |i − j|

which we also denote by (a (cid:126) w (i, j))m. Inserting this into (45) gives us a novel, O (N M max (M, N ))
time DP algorithm for NW sequence alignments with an (arbitrary) constraint on the maximum
absolute diﬀerence of misalignments (Figure 5).

16

Figure 5: Computational time (black line) required to solve the Needleman-Wunsch DP sequence alignment algorithm
(left) without constraints and (right) with lifted constraint. The horizontal axis is the length of both sequences and
also the size of the constraint algebra (e.g. N = M = |M|). The vertical axis is on a quadratic (left) and cubic (right)
scale such that exact O (cid:0)N 2(cid:1) and O (cid:0)N 3(cid:1) complexities correspond to a straight line (grey line). Python language
implementation on a quad-core Intel Core i7 3.2GHz, 16Gb DRAM.

3.3 Discrete event combinations

As a ﬁnal application exposition, in many contexts, it is important to be able to compute probabilities
or other quantities over combinations of discrete events, which satisfy certain conditions. As the
number of events becomes large, it is not feasible to perform brute-force enumeration and thereby
compute probabilities over all possible combinations as there are typically O
such combinations.
Therefore, DP can be an extremely useful computational tool if it can be made to tame this exponential
complexity. An important application from reliability engineering, is computing the probability of M -
out-of-N discrete events occurring, such as a combination components failing in a complex engineered
system, when each failure event has a unique probability. A simple polymorphic generator of all
possible sequences of events/non-events, is the following:

2N (cid:17)

(cid:16)

f0 = i⊗
fn = fn−1 ⊗ (w ((0, n)) ⊕ w ((1, n)))

∀n ∈ {1, 2, . . . , N }

(47)

where the tuple (0, n) represents the non-occurrence and (1, n) represents the occurrence, of event
n. In the above example, we want to constrain these subsets so that only M occurrences appear in
each sequence. Note that this is similar to, but subtly diﬀerent from the problem of selecting subset
size as the constraint, (24). So, using our algebraic theory, we have the the simple constraint algebra
v ((u, n)) = u where u ∈ {0, 1} and M = (N, +, 0). Since M is a group, we insert this into (21) to
obtain:

(a ⊗M wM ((u, n)))m =

(i⊕
am−u ⊗ w ((u, n)) otherwise

m < u

which we can then immediately insert into (47) to obtain:

fn,m = (fn−1 ⊗M (w (0, n) ⊕M w (1, n)))m

= ((fn−1 ⊗M w (0, n)) ⊕M (fn−1 ⊗M w (1, n)))m

=

 (i⊕

m < 0

fn−1,m ⊗ w ((0, n)) otherwise

!

⊕

 (i⊕

m < 1

!

fn−1,m−1 ⊗ w ((1, n)) otherwise

= (fn−1,m ⊗ w ((0, n))) ⊕

 (i⊕

m = 0

!

fn−1,m−1 ⊗ w ((1, n)) otherwise

which simpliﬁes to the following polymorphic, O (N M ), DP recursion:

(48)

(49)

17

f0,0 = i⊗
f0,m = i⊕
fn,0 = fn−1,0 ⊗ w ((0, n))
fn,m = (fn−1,m ⊗ w ((0, n))) ⊕ (fn−1,m−1 ⊗ w ((1, n)))

(50)

for all n ∈ {1, 2, . . . , N } and m ∈ {1, 2, . . . , M }.

In the semiring (R, +, ×, 0, 1) with w ((0, n)) = 1 − pn and w ((1, n)) = pn where pn represent the
probability of event n occurring, we obtain an algorithm which is extremely similar to that of Radke and
Evanoﬀ [1994] which was derived through special, ad-hoc reasoning. Of course, being polymorphic, we
can turn our recursion to other useful applications such as determining the most probable component
failure combination (max-product semiring) or using this as a diﬀerential component in a machine
learning system (softmax semiring).

4 Related work

Several formal approaches to DP exist in the literature, at various levels of abstraction. The seminal
work of Karp and Held [1967] is based on representing DP recurrences as discrete sequential deci-
sion processes, where monotonicity justiﬁes optimizing an associated global objective function. This
framework is not polymorphic. The work of de Moor [1991] and others [Bird and de Moor, 1996]
bases an abstraction of DP on category theory and relations such as inequalities, which are natural
operations for optimization applications of DP algorithms. Although polymorphic, it is unclear how to
generalize this relational framework further to arbitrary semirings in order to address important non-
optimization applications of DP, such as computing complete likelihoods for hidden Markov models
(the forward-backward algorithm) [Little, 2019], or expectations for parameter estimation in natural
language processing problems [Li and Eisner, 2009].

An interesting precursor is the model of DP described in Helman and Rosenthal [1985]. This de-
scribes restricted forms of some of the ideas which are precisely formulated and stated in full generality
here, including the key role of the separation of computational structure from the values which are
computed, and a special kind of homomorphic map over structural operators, into “choice-product”
operators. It is not polymorphic. Implicit semiring polymorphism features in DP algorithms found
in many specialized application domains, such as natural language processing over graphs and hy-
pergraphs [Goodman, 1999, Li and Eisner, 2009, Huang, 2008] and more recently in diﬀerentiable
algorithms for machine learning [Mensch and Blondel, 2018]. These studies refer to special DP algo-
rithms and do not address the general DP algorithm derivation problem, as we do here.

Perhaps most closely related to our approach is the semiring ﬁlter fusion model of Emoto et al.
[2012], which, while not explicitly aimed at DP, covers some algorithms which our framework addresses.
While polymorphic, it is restricted to sequential decision processes which can be expressed as free
homomorphisms over associative list joins. To our knowledge, this article was ﬁrst to introduce
algebraic lifting, albeit lacking proof details and in a limited form restricted to monoids, which we
expand in much greater generality and depth here. These limitations of Emoto et al. [2012] appear
to rule out non-sequential DP algorithms e.g. sequence alignment, edit distance and dynamic time
warping, and algorithms requiring constraints based on more ‘exotic’ lifting algebras such as ordered
subsequences.

5 Discussion and conclusions

In this paper we have developed a widely applicable approach to derive novel, correct-by-design,
DP algorithms for eﬃciently solving a very wide class of combinatorial problems. These algorithms
are entirely polymorphic over semirings. Starting with an existing algorithm, usually expressed as a

18

functional recurrence, the method allows the reﬁnement of this existing algorithm with additional com-
binatorial constraints described using an algebra which lifts the semiring. Applying straightforward
algebraic simpliﬁcation steps allows the derivation of new, computationally eﬃcient, polymorphic DP
algorithms which respect these constraints.

While we can always express DP recurrences in a general computer language, to do so over semirings
requires special programming eﬀort and overhead. Modern languages which generalize classical com-
putation to various settings such as probabilistic or weighted logic exist and it would be interesting
to see how to implement the DP framework of this paper in those languages. For example, semiring
programming is a proposed overarching framework which can be considered as a strict generalization
of the polymorphic recurrences presented here [Belle and de Raedt, 2020], although this work does
not address algorithm derivation. Similarly, we can view our polymorphic DP algorithms as special
kinds of sum-product function evaluations [Friesen and Domingos, 2016], although, as with semiring
programming, this only describes a representation framework.

Our approach to the derivation of new DP algorithms from existing recurrences, requires writing
constraints in “separable” form using algebras such as groups, monoids or semigroups. While this is
a very broad formalism, there will be some constraints which cannot be written in this form. Future
work may be able to provide similar algebraic derivations when the separability requirement is relaxed.
Another issue which has not been raised is that of parallel DP implementations. Similar approaches
based on constructive algorithmics demonstrate how to produce algorithms which are inherently par-
allel in the MapReduce framework, but these rely on associative operators and are restricted to the
setting of functional recurrences over free list semiring homomorphisms [Emoto et al., 2012]. While DP
algorithms derived using our framework are not immediately parallelisable in this way, our framework
does not rule out exploiting existing inherently parallel recurrences in the form of free list homomor-
phisms, and for these recurrences, the constraint lifting algebra developed here retains this inherently
parallel structure. The drawback is that, in some cases, it may not be possible to simplify the lifted
semiring product down to constant time complexity as in (21). Future investigations may explore
general DP parallelisation frameworks such as those based on explicit construction of the DP DAG
and performing path-based semiring computations on that structure [Galil and Park, 1994].

A limitation of our approach as developed so far, is that it does not exploit some of the more
“advanced” DP speed-up tricks which have been developed for special situations. A particular example
of this is the situation where the edge mapping function w in segmentation problems satisﬁes a special
concavity/convexity property [Yao, 1980], enabling a reduction in computational complexity from
O (cid:0)N 2(cid:1) to O (N log N ). It will be interesting future work to attempt to incorporate this and other
tricks, in our framework.

As we hope we have been able to persuade, semiring polymorphism is not an abstract curiousity:
it is an extremely useful tool for DP algorithm derivation, as it is in many other areas of computing
[Belle and de Raedt, 2020, Friesen and Domingos, 2016, Goodman, 1999, Huang, 2008, Pachter and
Sturmfels, 2005, Mensch and Blondel, 2018, Sniedovich, 2011]. It oﬀers a simple route to proving DP
algorithm correctness and quantifying computational complexity, and deriving novel algorithms in a
simple, modular way through semiring lifting. It plays a central role in clarifying what we understand
to be the essential conceptual principle of DP, which is the separation of combinatorial structure,
combinatorial constraint and value computation.

Appendix A: Proof of DP semiring fusion

We use the automated free theorem generator Haskell package [Boehme, 2021] to prove (6). Assume
that the DP recursion f is implemented in some pure, lazy functional language (a language without
side eﬀects and without the empty type). The type of f consists of, respectively, two binary operators
⊕, ⊗ : S × S → S, the DP computational DAG edge mapping function w : E → S where E is the set
of edge labels, and the constants i⊕, i⊗ : S, and produces a result of type S:

19

f : (S × S → S) × (S × S → S) × S × S × (E → S) → S

(51)

where S is an arbitrary type. According to Wadler’s free theorem [Wadler, 1989], this type declaration
above implies the following theorem.

Theorem 1. Assume S, S0 are arbitrary types and function g : S0 → S is a map between them. Assume
also the existence of binary operators ⊕0, ⊗0 : S0 × S0 → S0 and ⊕, ⊗ : S × S → S, constants i⊕0, i⊗0 ∈ S0
and i⊕, i⊗ ∈ S and mapping functions w0 : E → S0, w : E → S. If, for all x, y ∈ S0 and e ∈ E, the map
g satisﬁes:

g (cid:0)x ⊕0 y(cid:1) = g (x) ⊕ g (y)
g (cid:0)x ⊗0 y(cid:1) = g (x) ⊗ g (y)

g (i⊕0) = i⊕
g (i⊗0) = i⊗
g (cid:0)w0 (e)(cid:1) = w (e)

then shortcut fusion applies to the function f :

g · f (cid:0)⊕0, ⊗0, i⊕0, i⊗0, w0(cid:1) = f (⊕, ⊗, i⊕, i⊗, w)

If ⊗ left and right distributes over ⊕ and i⊕, i⊗ are the associated identity constants, the algebraic
object S = (⊕, ⊗, i⊕, i⊗) is a semiring. We denote f (S, w) by fS,w and the semiring homomorphism
by gS,w. Theorem 6 is a corollary.

Corollary. DP semiring fusion. Given the generator semiring G = ({[E]} , ∪, ◦, ∅, {[ ]}) with the
mapping function w0 (e) = {[e]} for all e ∈ E, and another, arbitrary semiring S with mapping
function w : E → S, if there exists a homomorphism gS,w mapping G → S which additionally satisﬁes
g ({[e]}) = w (e) for all e ∈ E, then for a function f with type given in (51):

Appendix B: Constraint lifting proofs

gS,w · fG,w0 = fS,w

This section is a generalization of the arguments given in Emoto et al. [2012], whilst providing and
clarifying essential proof details missing from that work. The formulation of DP constraints as single
operator algebras over ﬁnite sets requires the use of (semiring) lifting or formal sums as a structural
tool for deriving DP constrained fusion. This also provides a deﬁnition of the lifted semiring S [M] =
(S [M] , ⊕M, ⊗M, i⊕M, i⊗M).

Given a semiring S = (S, ⊕, ⊗, i⊕, i⊗) and constraint algebra M = (M, (cid:12), i(cid:12)), deﬁne semiring-
valued formal sums x ∈ S [M] as objects indicating that there are xm ∈ S “occurrences” of the element
m ∈ M. By convention, elements xm taking the value i⊕ are not listed. Accordingly, when two such
formal sums are added, the summation acts much like vector addition in the semiring:

(x + y)m = xm ⊕ ym
(52)
for all x, y ∈ S [M]. We take this to deﬁne the lifted semiring sum x ⊕M y elementwise, (x ⊕M y)m =
xm ⊕ ym for all m ∈ M. Clearly, this inherits all the properties of ⊕, including commutativity
and idempotency. The left/right identity constant satisfying x ⊕M i⊕M = i⊕M ⊕M x = x is just
(i⊕M)m = i⊕.

Next, we describe the generic change of variables (pushforward) formula for such formal sums.
Consider an arbitrary function f : M → M acting to transform values from the algebra M. We

20

can ask what happens to a lifted semiring object x ∈ S [M] under this transformation. To do this,
construct the product semiring object on S [M × M]:

where the lifted semiring unit function δm ∈ S [M] is deﬁned as:

xm1,m2 = xm1 ⊗ δm2,f (m1)

δm,m0 =

(i⊗ m0 = m
i⊕ otherwise

(53)

(54)

Then we can “marginalize out” the original variable to arrive at the change of variables formula

(familiar to probability theory):

xm1 ⊗ δm2,f (m1)

xm2 = M
m1∈M
= M

xm1

(55)

= xf −1(m2)
where the last step holds if f has a unique inverse.

m1∈M:m2=f (m1)

A key step in proving the constrained version of DP semiring fusion, is to be able to fuse the
composition of the constraint ﬁltering followed by a semiring homomorphism, into a single semiring
homomorphism. To do this, we will lift the constraint ﬁltering over the set M. Assume the shorthand
g0 : {[E]} → S [M] and φ0
m = φM,v,δm where the acceptance function δm (m0) = T if m0 = m and F
otherwise. We write:

g0
m (x) = (gS,w · φM,v,δm) (x)

(56)

Thus, g0
m (x) denotes the result of ﬁrst ﬁltering the set of lists x to retain any lists on which the
constraint evaluates to m, and then applying the homomorphism gS,w to the remaining lists. Now,
for g0
m to be a semiring homomorphism, it must preserve semiring structure. For it to be consistent
with the ﬁltering, it must also preserve the action of the ﬁltering under φM,v,δm.

Turning to the semiring sum, we have:

m (x ∪ y) = gS,w · φ0
g0
= gS,w · (cid:0)φ0
= (cid:0)gS,w · φ0
m
m (x) ⊕ g0
= g0

m (x ∪ y)
m (x) ∪ φ0

m (y)(cid:1)

(cid:1) (x) ⊕ (cid:0)gS,w · φ0
m
m (y)

(cid:1) (y)

(57)

To explain the second step: note that forming the union of sets of lists has no eﬀect on the com-
putation of the constraint value which determines the result of ﬁltering. Thus, the union of sets of
lists is invariant under the action of the ﬁlter. The third step follows because gS,w is a semiring
homomorphism.

Somewhat more complex is the semiring product, for which we have:

m (x ◦ y) = gS,w · φ0
g0

m (x ◦ y)
[

= gS,w ·

(cid:0)φ0

m0 (x) ◦ φ0

m00 (y)(cid:1)

m0,m00∈M:m0(cid:12)m00=m

=

=

=

M

m0,m00∈M:m0(cid:12)m00=m
M

m0,m00∈M:m0(cid:12)m00=m
M

m0,m00∈M:m0(cid:12)m00=m

gS,w · (cid:0)φ0

m0 (x) ◦ φ0

m00 (y)(cid:1)

(cid:0)gS,w · φ0
m0

(cid:1) (x) ⊗ (cid:0)gS,w · φ0

m00

(cid:1) (y)

m0 (x) ⊗ g0
g0

m00 (y)

21

(58)

Clearly, this motivates the deﬁnition of the lifted semiring product as (x ⊗M y)m = L
ym00.

m0,m00∈M:m0(cid:12)m00=m xm0⊗

The second step above deserves further explanation. We need to be able to push the ﬁlter φ0

m inside
the cross-join, which is critical to deﬁning a semiring homomorphism. Recall that the cross-join x ◦ y
of two sets of lists involves joining together each list in x with each list of y. For general lists l0, l00
whose constraints evaluate to m0 and m00 respectively, then due to the separability of the constraint
algebra, the constraint value of their join l0 ◦ l00 is m0 (cid:12) m00. If we group together into one set s0, all
those lists whose constraints evaluate to m0 and into another set s00, all those lists whose constraints
evaluate to m00, then their cross-join s0 ◦ s00 will consist of sets of lists, all of which have constraints
evaluating to m = m0 (cid:12) m00. Finally, for a given m and without further information on the properties
of (cid:12), we can ﬁnd the values of m0, m00 such that m0 (cid:12) m00 = m by exhaustively considering all possible
pairs. Clearly, if (cid:12) is specialized in some way, particularly with regards to the existence of inverses,
then this exhaustive search can be reduced, and this is the basis of our algebraic simpliﬁcations for
special cases such as group lifting algebras.

A semiring homomorphism must map identities. For empty sets which are the identity for ∪, we

simply require:

g0
m (∅) = i⊕ ∀m ∈ M
Similarly, sets of empty lists act as identities for the cross-join operator. In this case, we must have
m ({[ ]} ◦ x) = g0
g0

m ({[ ]}) = δi(cid:12),m, then we have:

m (x). If we set g0

m (x ◦ {[ ]}) = g0

(59)

g0
m ({[ ]} ◦ x) =

M

δi(cid:12),m0 ⊗ g0

m00 (x)

m0,m00∈M:m0(cid:12)m00=m

M

δi(cid:12),i(cid:12) ⊗ g0

m00 (x)

m00∈M:i(cid:12)(cid:12)m00=m
M

g0
m00 (x)

=

=

m00∈M:i(cid:12)(cid:12)m00=m
m (x)

= g0

(60)

and similarly for g0

m (x ◦ {[ ]}). This shows the lifted semiring identity to be i⊗M = δi(cid:12).
Finally, we need to consider the homomorphic mapping of sets with single lists of single edges,
terms like {[e]}. Under the action of the ﬁlter φM,v,δm, such terms are only retained if the
e.g.
constraint edge mapping v (e) = m, whereupon they contribute a value w (e) to the semiring value of
the homomorphism gS,w. Otherwise, they do not contribute anything to the semiring sum. It follows
that:

g0
m ({[e]}) = δv(e),m ⊗ w (e)

i⊕
which we write as the lifted edge mapping, wM (e)m. To summarize then, (57)-(61) show that g0
a semiring homomorphism performing the lift mapping G → S [M]:

m is

=

(w (e) m = v (e)
otherwise

(61)

gS,w · φM,v,δm = gS[M],wM

(62)

The next step is to reconstruct the result of DP constraint ﬁltering φM,v,a, from the lifted result.
This involves computing the eﬀect of the transformation a : M → B mapping the lifting algebra M
into the value in B of the predicate a, on an arbitrary lifted semiring object x ∈ S [M]. The joint
product function π on M × B is written using the Boolean-semiring unit function:

πm,b (x) = xm ⊗ δb,a(m)

δb,b0 =

(i⊗ b0 = b
i⊕ otherwise

22

(63)

We then project onto the second parameter of π to obtain:

πb (x) = M
m0∈M
= M

xm0 ⊗ δb,a(m0)

xm0

(64)

m0∈M:a(m0)=b

= xa−1(b)

where the last line holds if a has a unique inverse. We use the notation πS,a as a shorthand for πT
over the semiring S and the acceptance criteria a.

Putting everything above together, we can show the following:

gS,w · φM,v,a · fG,w0 = πS,a · gS,w · φM,v,δm · fG,w0

= πS,a · gS[M],wM · fG,w0
= πS,a · fS[M],wM

(65)

which constitutes a proof of theorem (16).

Theorem 2. DP semiring constrained fusion. Given the generator semiring G with the mapping
function w0, and another, arbitrary semiring S with edge mapping function w, the constraint algebra
M = (M, (cid:12), i(cid:12)) with edge mapping function v, acceptance criteria a : M → B, constraint ﬁltering
function φ : (M × M → M) × M × (E → M) × (M → B) and projection function π : (S × S → S) × S ×
(M → B) → S, then for a function f with type (51):

gS,w · φM,v,a · fG,w0 = πS,a · fS[M],wM

Appendix C: A selection of semirings

A table of some useful (numerical) semirings S = (S, ⊕, ⊗, i⊕, i⊗) is given below, for more details on
these and other semirings, the book by Golan [1999] is an excellent reference.

23

Name

Arithmetic
Generator
Boolean

Arithmetic

Tropical

Softmax

Viterbi

Expectation

Bottleneck

Relational

Example
application
Solution counting
Exhaustive listing
Solution
existence
Probabilistic
likelihood
Minimum
negative log
likelihood
Diﬀerentiable
minimum
negative log
likelihood
Minimum
negative log
likelihood with
optimal solution
Expectation-
maximization
Fuzzy constraint
satisfaction
Database queries

Set S

N
{[E]}
B

R

R+

R+

Operations ⊕, ⊗

Identities i⊕, i⊗

+, ×
∪, ◦
∨, ∧

+, ×

min, +

− ln (e−x + e−y) , +

0, 1
∅, {[ ]}
T, F

0, 1

∞, 0

∞, 0

R+ × (cid:8)R+(cid:9)

(min, arg min) , (+, ∪)

(∞, ∅) , (0, ∅)

R × R+

(x + y, p + q) , (py + qx, pq)

(0, 0) , (1, 0)

[0, 1]

SRS

max, min

∪, ./

0, 1

∅, 1R

Appendix D: Some useful constraint algebras

In this section we list some useful example constraints and simpliﬁed expressions for the resulting
lifted semiring products, see (20), along with simpliﬁed expressions for the product against the lifted
single value, see (21).

24

Example
applica-
tion

Algebra
M = (M, (cid:12), i(cid:12))

(a ⊗M b)m (20)

(a ⊗M wM (x))m (21)

Subset size

(N, +, 0)

L

m0∈N

(cid:0)am0 ⊗ bm−m0

(cid:1)

(cid:26)i⊕

m < v (x)
am−v(x) ⊗ w (x) otherwise

Minimum
count

Maximum
count

({1, . . . , M } , min, M )

({1, . . . , M } , max, 0)

Absolute
diﬀerence

({1, . . . , M } ,

|x − y| , 0)

Existence

(B, ∨, F )

For all

(B, ∧, T )

Sequential-
value
ordering

((N, R) ,
(cid:22), z(cid:22))

LM
LM

m0=m

m0=m+1

(am0 ⊗ bm) ⊕
(am ⊗ bm0 )

Lm−1
m0=1
Lm

m0=1

(am0 ⊗ bm) ⊕
(am ⊗ bm0 )

LM −1
m0=m+1
LM −m−1
m0=1

(cid:0)am0 ⊗ bm0−m
(cid:0)am0 ⊗ bm0+m

(cid:1) ⊕
(cid:1)










aF ⊗ bF
m = F
(aF ⊗ bT ) ⊕ (aT ⊗ bF ) m = T
⊕ (aT ⊗ bT )

(aF ⊗ bF ) ⊕ (aT ⊗ bF ) m = F
⊕ (aF ⊗ bT )
aT ⊗ bT

m = T






am ⊗ w (x)
(cid:0)⊕M
m0=mam0
i⊕

m < v (x)
(cid:1) ⊗ w (x) m = v (x)
m > v (x)






am ⊗ w (x)
(cid:0)⊕m
m0=1am0
i⊕

m > v (x)
(cid:1) ⊗ w (x) m = v (x)
m < v (x)

(cid:18)(cid:26)i⊕

m > v (x) − 1

(cid:19)

am−v(x) ⊗ w (x) otherwise

⊕
(cid:19)

m > M − v (x)

(cid:18)(cid:26)i⊕

am+v(x) ⊗ w (x) otherwise

am ⊗ w (x)
(aF ⊕ aT ) ⊗ w (x)
i⊕

v (x) = F
(m = T ) ∧ (v (x) = T )
(m = F ) ∧ (v (x) = T )

am ⊗ w (x)
(aF ⊕ aT ) ⊗ w (x)
i⊕

v (x) = T
(m = F ) ∧ (v (x) = F )
(m = T ) ∧ (v (x) = F )










L

m0∈M:m0(cid:22)m

(am0 ⊗ bm)

(cid:26)(cid:0)⊕m0∈M:m0(cid:22)mam0

i⊕

(cid:1) ⊗ w (x) m = v (x)
otherwise

Appendix E: Supplementary algorithm derivations: applying multiple
constraints

This appendix illustrates the idea of applying two constraints in sequence in order to develop a special
class of algorithms for non-empty subsequences.

Non-empty subsequences

As discussed above, there is a simple (greedy) recurrence for subsequences (7):

f0 = i⊗
fn = fn−1 ⊗ (i⊗ ⊕ w (n))

∀n ∈ {1, 2, . . . , N }

(66)

This is useful but for some applications, there is a need to perform computations over non-empty
subsequences, that is subsequences without the empty subsequence {∅}. The existence constraint
algebra M = (B, ∨, F ) (see Appendix B: Constraint lifting proofs) with the constant lift map v (n) = T
partitions the set of subsequences generated by the above recurrence, into empty m = F and non-

25

empty m = T subsequences:

f0,m =

(i⊗ m = F
i⊕ m = T

fn,m = (fn−1 ⊕M fn−1 ⊗ wM (n))m

= fn−1 ⊕

(w (n) ⊗ (fn−1,F ⊕ fn−1,T ) m = T
m = F
i⊕

The last line can be rewritten:

fn,m =

=

(fn−1,T ⊕ w (n) ⊗ (fn−1,F ⊕ fn−1,T ) m = T
fn−1,F
m = F
(fn−1,T ⊕ (w (n) ⊗ fn−1,F ) ⊕ (w (n) ⊗ fn−1,T ) m = T
m = F
i⊗

(67)

(68)

so that fN,F = i⊗ as expected in the empty subsequence case. Focusing on the case we want, fN,T ,
we have:

fn,T = fn−1,T ⊕ (w (n) ⊗ fn−1,T ) ⊕ w (n)

(69)

which, being expressed entirely in terms of the case m = T , allows us to ignore the lifting altogether
to obtain:

f0 = i⊕
fn = fn−1 ⊕ (fn−1 ⊗ w (n)) ⊕ w (n)

∀n ∈ {1, 2, . . . , N }

(70)

Clearly, this is an O (N ) time complexity recurrence. In the next section, we will build upon this

recurrence to provide a novel class of algorithms for special non-empty subsequences.

Ordered, non-empty subsequences

Algorithms of the kind derived in this subsection include solutions to the longest increasing sub-
sequence problem, which occurs frequently in applications such as computational genomics [Zhang,
2003]. Starting from the non-empty subsequence recurrence developed above, we can augment this
with a constraint that the subsequence elements must be in an ordered chain according to some binary
relation which we write xRy. For example the ordering x < y holds that x must be less than y. Here,
we require a somewhat more complex relation in which both sequence and the value must be ordered,
so that we can deﬁne a lifting algebra using what we call a sequential-value ordering operator:

(i, x) (cid:22) (j, y) =

((j, y)

(i < j) ∧ (x < y)

(∞, ∞) otherwise

(71)

over tuples M = (N, R), where (∞, ∞) = z(cid:22) is a special tuple which act like an annihilator or zero
element. Operator (cid:22) is left but not right, associative and it does not have an identity, so, a lifting
algebra M = (M, (cid:22), z(cid:22)), is not a “standard” algebra (such as a monoid, group or semigroup). The
lack of identity means that it cannot be applied to empty sequences of DP DAG edges. Nonetheless,
the acceptance criteria a (m) = T if m 6= z(cid:22) and T otherwise, allows us to ﬁlter away non-empty
sequences which are not in sequentially increasing order, provided the operator is scanned across the
sequence in left-right order.

To apply this constraint, we can simplify the lifting algebra using this ordering operator:

(a ⊗M wM (n))m =

((⊕m0∈M:m0(cid:22)mam0) ⊗ w (n) m = v (n)
otherwise
i⊕

(72)

26

which, when substituted into (70), gives us:

f0,m = (i⊕M)m

fn,m =

fn−1 ⊕M

 ((cid:0)⊕m0∈M:m0(cid:22)mfn−1,m0

i⊕

(cid:1) ⊗ w (n) m = v (n)
otherwise

!

!

⊕ wM (n)

m

(73)

for all n, m ∈ {1, 2, . . . , N }. The ﬁrst line simpliﬁes to f0,m = i⊕, and the second line can be
manipulated to obtain:

f0,m = i⊕

fn,m =

(fn−1,m ⊕ (cid:0)⊕m0∈M:m0(cid:22)mfn−1,m0
fn−1,m

(cid:1) ⊗ w (n) ⊕ w (n) m = v (n)
otherwise

(74)

To implement this DP recurrence, we next need to choose the lifting set M. In this setting, we will
typically have a (ﬁnite) set of edge values, one value per DAG edge, we will write this as un ∈ R.
Thus, the lifting set consists of the values from this set, e.g. M = {(n, un) , n ∈ {1, 2, . . . , N }}, and
the lift mapping functions merely index this set, e.g. v (n) = (n, un). Note that with this particular
lifting set, there is a one-one mapping between n and any m ∈ M, thus, we can reduce the lifting set
to M = {1, 2, . . . , N } and lift mapping to v (n) = n, so that the ordering operator becomes:

i (cid:22) j =

(j

(i < j) ∧ (ui < uj)

∞ otherwise

These reductions allow us to simplify the above recurrence to:

f0,m = i⊕

fn,n = fn−1,n ⊕

(cid:16)

fn,m = fn−1,m

⊕m0∈{1,2,...,n−1}:(um0 <un)fn−1,m0

(cid:17)

⊗ w (n) ⊕ w (n)

(75)

(76)

Finally, note that, the second line adds a constant term w (n) to each fn,n, ⊕ is associative, and the
value of the ﬁrst line is independent of m, we can move this term from the second line to the ﬁrst,
leading to the following polymorphic DP recursion for increasing sequential subsequences:

f0,m = w (m)

fn,n = fn−1,n ⊕

(cid:16)

fn,m = fn−1,m

⊕m0∈{1,2,...,n−1}:(um0 <un)fn−1,m0

(cid:17)

⊗ w (n)

(77)

with the projection πS,a (fN ) = L
m∈{1,2,...,N } fN,m. In terms of computational complexity, the recur-
rence must be computed for all n, m ∈ {1, 2, . . . , N } and the second requires O (N ) operations. Note
that, the third line does not change the value of fn,m for m 6= n obtained at the previous iteration, so
that, iterating over m, only the term fn,n needs updating in the second line. Thus, the computational
complexity is O (cid:0)N 2(cid:1).

The longest increasing subsequences DP algorithm is obtained as a special case of (77) with the

semiring S = (N, max, +, 0, 1) and the lift mapping w (n) = 1:

f0,m = 1

fn,n = max

fn−1,n,

max
m0∈{1,2,...,n−1}:(um0 <un)

fn−1,m0

+ 1

(78)

!

fn,m = fn−1,m

with πS,a (fN ) = maxm∈{1,2,...,N } fN,m. Compared to existing, classical implementations of this al-
gorithm in the literature [Zhang, 2003], we note that, the algebraic simpliﬁcations aﬀorded by our

27

 
 
approach makes it transparent that there is no need to perform N semiring products ⊗ in the second
line, which may lead to computational savings in practice.

Whilst, for the longest increasing subsequences problem, there are somewhat more eﬃcient algo-
rithms which exploit the special structure of the problem, the generalized ordered subsequences DP
algorithm derived here, (74), being polymorphic, can be applied to any arbitrary binary relation R:

x (cid:12) y =

(y

xRy
z(cid:12) otherwise

(79)

For example, we immediately obtain an algorithm for semiring computations over all non-decreasing
subsequences (ordering x ≤ y), or, for subsequences consisting of sets, all subsequences ordered by
inclusion, x ⊆ y.

References

V. Belle and Luc de Raedt. Semiring programming: A semantic framework for generalized sum product

problems. International Journal of Approximate Reasoning, 126:181–201, 2020.

Richard Bellman. Dynamic Programming. Princeton University Press, 1957.

Richard S. Bird and Oege de Moor. Algebra of Programming. Prentice-Hall, 1996.

S. Boehme. free-theorems: Automatic generation of free theorems, 2021.

Oege de Moor. Categories, Relations and Dynamic Programming. PhD thesis, University of Oxford,

1991.

Oege de Moor. Dynamic programming as a software component. In CSCC 1999, Athens, Greece,

1999.

Kento Emoto, Sebastian Fischer, and Zhenjiang Hu. Filter-embedding semiring fusion for progamming

with MapReduce. Formal Aspects of Computing, (24):623–645, 2012.

A.L. Friesen and P. Domingos. The sum-product theorem: A foundation for learning tractable models.
In Proceedings of the 33rd International Conference on Machine Learning, ICML, volume 48, pages
1909–1918, New York, USA, 2016.

Z. Galil and K. Park. Parallel algorithms for dynamic programming recurrences with more than O(1)

dependency. Journal of Parallel and Distributed Computing, 21(2), 1994.

Jonathan S. Golan. Semirings and their Applications. Springer Netherlands, 1 edition, 1999.

J. Goodman. Semiring parsing. Computational Linguistics, 25(4), 1999.

A. Gronlund, K.G. Larsen, A. Mathiasen, J.S. Nielsen, S. Schneider, and M. Song. Fast exact k-means,

k-medians and Bregman divergence clustering in 1D. arXiv, page arXiv:1701.07204v4, 2018.

P. Helman and A. Rosenthal. A comprehensive model of dynamic programming. SIAM Journal on

Algebraic Discrete Methods, 6(2):319–333, 1985.

R. Hinze. Theory and practice of fusion. In Jurriaan Hage, editor, Proceedings of the 22nd Symposium
on the Implementation and Application of Functional Languages (IFL ’10), pages 402–421, Alphen
aan den Rijn, The Netherlands, 2010.

L. Huang. Advanced dynamic programming in semiring and hypergraph frameworks. In COLING

2008, pages 1–18, Manchester, UK, 2008. Coling 2008 Organizing Committee.

28

J.T. Jeuring. Theories for Algorithm Calculation. PhD thesis, Utrecht University, 1993.

R.M. Karp and M. Held. Finite-state processes and dynamic programming. SIAM Journal on Applied

Mathematics, 15(3):693–718, 1967.

S.-J. Kim, K. Koh, S. Boyd, and D. Gorinevsky. L1 trend ﬁltering. SIAM Rreview, 51(2):339–360,

2009.

Jon Kleinberg and Eva Tardos. Algorithm Design. Addison-Wesley Longman Publishing Co., Inc.,

2005.

Z. Li and J. Eisner. First- and second-order expectation semirings with applications to minimum-risk
In Proceedings of the 2009 Conference on Empirical Methods in

training on translation forests.
Natural Language Processing, pages 40–51, Singapore, 2009. ACL.

Max A. Little. Machine Learning for Signal Processing. Oxford University Press, Oxford, UK, 2019.

A. Mensch and M. Blondel. Diﬀerentiable dynamic programming for structured prediction and atten-
tion. Proceedings of the 35th International Conference on Machine Learning, 80:3462–3471, 2018.

L. Pachter and B. Sturmfels. Algebraic Statistics for Computational Biology. Cambridge University

Press, 2005.

G.E. Radke and J. Evanoﬀ. A fast recursive algorithm to compute the probability of M-out-of-N
events. In Proceedings of Annual Reliability and Maintainability Symposium (RAMS), pages 114–
117, Anaheim, CA, USA, 1994. IEEE.

N.J.A. Sloane. The on-line encyclopedia of integer sequences, 2021.

M. Sniedovich. Dynamic Programming: Foundations and Principles. CRC Press, Boca Raton, US,

2nd edition, 2011.

E. Terzi and P. Tsaparas. Eﬃcient algorithms for sequence segmentation. In Proceedings of the 2006

SIAM International Conference on Data Mining. SIAM, 2006.

Philip Wadler. Theorems for free!

In FPCA ’89: Proceedings of the fourth international conference
on Functional programming languages and computer architecture, London, UK, 1989. Association
for Computing Machinery.

F.F. Yao. Eﬃcient dynamic programming using quadrangle inequalities. In Proceedings of the 12th

Annual ACM Symposium on the Theory of Computing, pages 429–435, 1980.

H. Zhang. Alignment of BLAST high-scoring segment pairs based on the longest increasing subse-

quence algorithm. Bioinformatics, 19(11):1391–1396, 2003.

29

