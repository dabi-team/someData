2
2
0
2

p
e
S
4
1

]
I

A
.
s
c
[

1
v
9
6
5
6
0
.
9
0
2
2
:
v
i
X
r
a

The Embeddings World and Artiﬁcial General
Intelligence

Mostafa Haghir Chehreghani
Department of Computer Engineering
Amirkabir University of Technology (Tehran Polytechnic), Tehran, Iran
mostafa.chehreghani@aut.ac.ir

Abstract

From early days, a key and controversial question inside the artiﬁcial
intelligence community was whether Artiﬁcial General Intelligence (AGI)
is achievable. AGI is the ability of machines and computer programs
to achieve human-level intelligence and do all tasks that a human being
can. While there exist a number of systems in the literature claiming
they realize AGI, several other researchers argue that it is impossible to
achieve it.

In this paper, we take a diﬀerent view to the problem. First, we discuss
that in order to realize AGI, along with building intelligent machines and
programs, an intelligent world should also be constructed which is on the
one hand, an accurate approximation of our world and on the other hand,
a signiﬁcant part of reasoning of intelligent machines is already embedded
in this world. Then we discuss that AGI is not a product or algorithm,
rather it is a continuous process which will become more and more mature
over time (like human civilization and wisdom). Then, we argue that
pre-trained embeddings play a key role in building this intelligent world
and as a result, realizing AGI. We discuss how pre-trained embeddings
facilitate achieving several characteristics of human-level intelligence, such
as embodiment, common sense knowledge, unconscious knowledge and
continuality of learning, by machines.

Keywords. Philosophy of artiﬁcial intelligence; artiﬁcial general intel-
ligence (AGI); embedding (representation); pre-trained embeddings; in-
telligent world; human intelligence; machine intelligence.

1

Introduction

In recent years, advanced machine learning (ML) and artiﬁcial intelligence (AI)
techniques have become very popular, due to their high performance in solving
problems from diﬀerent domains. These techniques are successful in solving one
speciﬁc problem (or a few problems from one speciﬁc domain), such as chess-
playing, car driving and mathematical calculations. However, for example a

1

 
 
 
 
 
 
computer program that can play chess at a very professional level, might not be
capable of playing another game, even at a beginner level. For each individual
and independent task, usually a separate algorithm is needed to be developed.
When the ﬁeld of artiﬁcial intelligence ﬁrst emerged, the original focus of
researchers was, however, Artiﬁcial General Intelligence (AGI). AGI is the abil-
ity of machines and computer programs to solve all the tasks that a human
being can. Searle [29] is one of the ﬁrst researchers who makes a distinction
between: AGI which implies that the intelligent machine does not simulate a
human mind, but actually has a mind and is capable of an intelligence equal
or superior to human beings; and narrow AI which implies that a computer
program is capable of performing only one speciﬁc task or a few relevant tasks1.
From early days, a controversial question inside the AI community was
whether AGI is achievable by machines and computer programs. There are
several attempts in the literature to answer this question, which can be divided
into optimistic and pessimistic viewpoints. A group of researchers, mostly from
AI community, believe that achieving AGI is feasible, and try to develop systems
or algorithms that realize AGI [19, 10, 23, 3, 32]. While most of well-known algo-
rithms are based on reinforcement learning [19, 10], a few others use probabilistic
approaches [23] or deep neural models [3, 32]. However, it is a common belief
that we are still far from the point of having systems that realize AGI and work
in practice. Even known systems such as XIAI [19] or more recent and improved
approaches [10] are not practical. Some other researchers that mostly have a
philosophical view to the problem, criticise AGI and believe that due to char-
acteristics that human intelligence has (embodiment, common sense knowledge,
tacit and unconscious knowledge etc), it is not possible to develop human-level
intelligence for machines and computer programs [29, 13, 14, 15, 34, 27, 11, 17].
However, we believe before trying to answer this question, we should ﬁrst
elaborate on its diﬀerent aspects. First, AGI should not be seen as an algorithm
or a product or a computer program, rather, as a continuous process within
agents and systems become more and more intelligent over time, as human
intelligence is a continuous process. Second, human intelligence is aﬀected by
human’s mental model of the world and as a result, by our world. For example,
a characteristic of human intelligence is unconscious knowledge that consists
of facts such as ”water always ﬂows downward” [11]. However, such facts are
derived from our world and our experiences in this world. So, for example
in a world without gravity, this statement would not be a part of human’s
unconscious intelligence, but rather some meaningless statement. In a similar
way, in order to realize AGI, we ﬁrst need to build an intelligent world which
is on the one hand, an accurate approximation of our world and on the other

1In the literature, researchers use terms such as strong AI and general AI to respectively
refer to human-level intelligence and the capacity of solving many tasks, opposed to weak
AI and narrow AI that respectively refer to an intelligence that do not experience human
In this
consciousness and an intelligence that is applicable to only a very speciﬁc setting.
paper, by AGI we mean an intelligence which is on the one hand capable of solving several
tasks from diﬀerent domains and on the other hand, at least to some degree achieves key
characteristics of human intelligence.

2

hand, a signiﬁcant part of knowledge and reasoning of intelligent machines is
already embedded unconsciously in this world. Machines should be able to
obtain this unconscious knowledge from this world quickly and with almost no
eﬀort. Third, the answer to the above question should not be simply yes or no.
It is more reasonable to provide a list of characteristics that human intelligence
has, and discuss what characteristics are achievable by machine intelligence and
to what extend.

In this paper, we study achievability of AGI, while taking into account these
considerations. First, we introduce the notion of embeddings world consisting of
pre-trained embeddings of objects, as a trained approximation or abstraction of
our world which is proper for machines and computer programs. Embeddings
are vectors in a low-dimensional vector space, that represent objects of a do-
main so that their structural relations are preserved. Pre-trained embeddings
are embeddings that are learned and computed usually using a general-purpose
objective function. Then, they are stored and can be used, as good quality rep-
resentations of real objects, to solve several tasks. Second, we argue that along
with other techniques such as reinforcement learning that are discussed in the
literature, pre-trained embeddings provide a path toward AGI. More precisely,
we discuss how pre-trained embeddings facilitate achieving several character-
istics of human intelligence, such as embodiment, common sense knowledge,
unconscious knowledge, and continuality of learning, by machines.

The rest of this paper is organized as follows. In Section 2, we provide an
overview on related work. In Section 3, we deﬁne the embeddings world and
discuss why it can be useful in realizing AGI. In Section 4, we discuss that
the embeddings world can help machines to achieve several characteristics of
human-level intelligence. Finally, the paper is concluded in Section 5.

2 Literature review

In the literature, on one hand there exist a number of algorithms and systems
that claim that they realize AGI. On the other hand, there are philosophical
discussions that argue that achieving AGI is impossible, or very hard. In this
section, we brieﬂy review these two types of related work.

AIXI [19] is one of famous algorithms for AGI, which is based on reinforce-
ment learning. It maximizes the expected total rewards received from the en-
vironment. In each time step, it checks every possible hypothesis and evaluates
how much reward that hypothesis would generate depending on the next action
taken. This reward is weighted by a belief which is computed from the length
of the hypothesis: a longer hypothesis is considered more complicated than a
shorter one and as a result, less likely. AIXI selects the action that has the
highest expected weighted reward. Since at each step AIXI considers and eval-
uates all possible hypothesizes, it is not computationally practical. Moreover,
the agent may hijack its reward.

The literature includes several improvements of AIXI. One of the most recent
algorithms is the Boxed Myopic Artiﬁcial Intelligence (BoMAI) method [10],

3

which is also based on reinforcement learning and tries to maximize reward,
episodically: it is run on a computer which is placed in a sealed room with an
operator. When the operator leaves the room, the episode ends. The intelligent
agent can perform any task, except hijacking its reward. The authors believe
that this procedure provides a path to AGI, despite the dangerous failure of
reward hijacking. However, similar to AIXI, BoMAI is not practical.

One of recent successes in producing human-quality output by a computer
program is the Generative Pre-trained Transformer 3 (GPT-3) program [3].
GPT-3 is a language model developed by OpenAI, that uses deep learning to
produce human-style text. The quality of the text generated by GPT-3 is high
so that it is diﬃcult to distinguish it from human-written text. The Gato sys-
tem [32] introduced by DeepMind, is a general-purpose system that can perform
604 tasks of diﬀerent types, including captioning images, chatting and conver-
sation, stacking blocks with a real robot arm and playing Atari games. It uses
transformers for learning and inference, which are deep learning models that
use the attention mechanism for weighting the signiﬁcance of each part of the
input data, diﬀerently [32].

Searle is one the ﬁrst scientists who criticizes AGI (and AI in general), and
believes that achieving AGI is impossible [29]. Another famous critic of AGI is
Hubert Dreyfus, who criticises the philosophical foundations of AGI. In his sev-
eral books and writings, including Alchemy and AI [13], What Computers Can’t
Do [14] and Mind over Machine [15], he argues that human intelligence depends
mainly on unconscious knowledge and decision making, rather than conscious
knowledge. He believes that computers and AI programs can never fully capture
this unconscious or background knowledge, and they are unable to perform fast
decision making and problem solving, which is based on unconscious knowledge.
Therefore, computers can never achieve human-level intelligence.

Weizenbaum [34] states that computer intelligence and human reasoning are
fundamentally diﬀerent. Computer power is the ability to perform computations
at a very high speed, whereas human reasoning consists of prudence and wisdom.
Prudence is the ability of making proper decisions in concrete situations, and
wisdom is the ability of seeing the whole picture. These capabilities are not
computational or algorithmic, so, can not be simulated by a computer. In a
similar way, Penrose [27] argues that human thinking is essentially diﬀerent
from computer programs.

Mantaras [11] looks at recent advances in AI, that are based on the analysis
of large volumes of data and big data processing. He discusses challenges and
diﬃculties of this approach and highlights that in order to realize GAI, there
is still the need to provide common sense knowledge to computer programs.
In another recent paper, Fjelland [17] reviews important critiques on AGI and
argues that despite considerable developments of AI for speciﬁc tasks, we have
not come much closer to achieving AGI. The author revives Dreyfus’ argument
that computers are not in the world and therefore, achieving AGI is in principle
impossible.

4

3 The embeddings world

State of the art recent AI and ML techniques for solving diﬀerent problems rely
on learning or computing an embedding (representation) for each data-point
or object. An embedding is a vector in a low-dimensional vector space that
encodes the whole information of an object and its relations to other objects
in the domain, as much as possible2. However, what makes it more eﬀective
than a typical encoding is that it is learned to preserve similarities, properties
and structural relationships among objects. For example, in embedding learn-
ing for words, two words that have similar syntaxes or semantics, ﬁnd similar
embeddings, i.e., are mapped to closer point in the vector space than two words
that are irrelevant. In a similar way, phrases, sentences and documents also ﬁnd
such relation preserving embeddings. As an another example, consider a social
network wherein each person is modeled by a node in a graph and diﬀerent
relationships among people are modeled by graph edges of various types. Nodes
(individuals) that have similar properties (proﬁles, etc) and similar structural
positions in the graph (have same friends, belong to same communities, etc),
ﬁnd similar embeddings.

Embeddings have several advantages that make them useful for AGI.

• First, pre-training them makes them computationally easy and accessible
to use. Pre-training means instead of learning embeddings for a spe-
ciﬁc task, they are trained using a general and task-independent objective
function. This objective function could be deﬁned, for example, using an
encoder and a decoder. The encoder maps an object/data-point to its
embedding and the decoder retrieves it from its embedding. The objec-
tive function, that should be minimized, might be deﬁned as the sum of
the distances between the original objects and their retrieved versions by
the decoder. The generated embeddings are stored and used to represent
objects in diﬀerent learning tasks. Generating and using task-speciﬁc em-
beddings, wherein the embeddings are learned using a speciﬁc objective
function derived from the learning task, usually yields a slightly better
result for that speciﬁc task. However, general-purpose pre-trained em-
beddings address several issues. On the one hand, learning embeddings
can be very time and resource consuming. Using pre-trained embeddings
signiﬁcantly improves the eﬃciency of the learning process. On the other
hand, in supervised tasks such as classiﬁcation, a huge labeled dataset is
required to have a good performance. This labeled data is used to deﬁne
the task-speciﬁc objective function. In pre-training, there is usually no
need to labeled data.

• Second, they provide a good abstraction or approximation of objects in a
speciﬁc domain and their relations. High quality embeddings are gener-
ated in diﬀerent domains, such as (but not limited to):

2Note that there are other notions of embedding in AI, e.g., the notion of embedding in
graph pattern mining [5, 6, 7], that should not be confused with the notion of embedding used
in this paper.

5

– words and other textual objects such as phrases, sentences and doc-

uments using e.g., Bert [26, 12],

– graph objects such as social networks, technological networks, collab-
oration networks and their components (nodes, edges, subgraph) [21,
4],

– images [22], videos [33] and speech [9].

Diﬀerent forms of neural models are usually used to learn or generate
embeddings. They generate multi levels of embeddings, so that each layer
transforms the embedding at one level into an embedding at a higher and
slightly more abstract level [24].

We believe extending domain-speciﬁc embeddings to a general domain will
be feasible in future. Suppose as an example, we have a picture and a pa-
per on a table. The projection of this situation in the embeddings space
consists of three embeddings of the objects picture, paper and table so
that each embedding comes from its own speciﬁc domain. Furthermore,
there should be embeddings that reﬂect the information of relative posi-
tionings of the objects against each other. We may call these embeddings
as connectors and in this example, we will have three of them that depict
the relative positioning of paper and table, the relative positioning of pic-
ture and table and the relative positioning of paper and picture. While
connectors can be simply some codes to distinguish diﬀerent situations,
in a better way they can be learned so that similar connectors ﬁnd sim-
ilar embeddings. In this way, embeddings can ﬁnally provide an almost
exhaustive and accurate model of our world.

• The third advantage of embeddings is that they can be computed induc-
tively. This means we do not need to use the whole of data to learn/compute
embeddings. Also, when some new data arrives or our existing data
changes, we do not always need to redo our embedding learning process,
to ﬁnd embeddings for new data. What we need is that we assume the
embedding of an object/data-point is a parameterized function of its fea-
tures. This function can be deﬁned using e.g., a neural network. Then
the task is to learn the parameters, i.e., ﬁnd proper/optimal values for
them. This can be done using only a part of data. Then, after learning
parameters, for each object/data-point, using its features as the input of
the function and the learned values of the parameters, its embedding is
computed very quickly. In this case, instead of storing embeddings of all
objects/data-points, it is suﬃcient to store the learned values of parame-
ters.

With these pre-trained, general-purpose, exhaustive, accurate and inductive
embeddings in hand, simple algorithms are usually suﬃcient to obtain good
results for diﬀerent learning tasks. In fact, in this type of AI, the main part
of intelligence is laid in the embedding and representation generation phase, to
create an accurate approximation of the world for computer programs. After

6

creation of this world, which we call the embeddings world, computer programs
and algorithms can work eﬃciently and accurately in it, and can be easily ex-
tended to do several diﬀerent tasks.

4 Realizing human intelligence

Researcher pessimistic about AGI believe that human intelligence has charac-
teristics such as embodiment, common sense knowledge and unconscious knowl-
edge, that are dedicated to humans; and machine intelligence can not achieve
them.
In this section, we discuss how pre-trained embeddings may help an
intelligent machine to achieve (at least to some degree) these characteristics.

4.1 Embodiment

One of the strongest critiques of AGI is that computers and intelligent programs
are not embodied and are not in the world [14]. So they work on an abstraction
of the world, codiﬁed by a language that represent the surrounding information,
whereas humans have direct experiences of their surroundings, and actually are
situated in the world. Without a body, those abstract representations have no
semantic content for computer programs or machines [11].

However, we believe there is an important diﬀerence between embeddings
and other encoding methods: embeddings are learned (optimized) to preserve
diﬀerent properties of objects as well as structural and semantic relations among
them. This is not the case for other encodings or representations. As mentioned
in Section 3, pre-trained embeddings create an accurate and intelligent approx-
imation of the world for computer programs wherein they can properly act. So,
each object ﬁnds a body in this world deﬁned by its embedding, and relations
among objects are also embedded. An intelligent machine or agent is situated in
this embeddings world: it itself consists of a set of embeddings and each object
surrounding it is also an embedding and connector embeddings can be used to
identify relative positioning, both explicit and implicit, of objects and agents.

4.2 Common sense knowledge

Common sense knowledge consists of facts that are known for everyone. It is
thought as a result of our lived experiences. Examples include: ”water always
ﬂows downward”, ”knife cuts cheese, but cheese does not cut knife”, and ”a
pigeon ﬂies, but an elephant does not ﬂy”. Humans can easily and quickly
learn and process millions of such common sense knowledge, and use them
for decision making and showing proper reactions. Equipping machines and
computer programs with common sense knowledge is considered as one of the
key challenges in AGI [11].

Pre-trained embeddings, along with other tools such as knowledge graphs,
can be used to provide common sense knowledge for intelligent machines [18]. A
common sense is usually some knowledge about properties of one or more objects

7

or their relationships. Since embeddings are carefully and smartly computed so
that objects’ properties are preserved and relevant objects ﬁnd similar (close)
embeddings, they can carry common sense knowledge. For example, while the
embeddings of words ”water” and ”downward” are close, the embeddings of
words ”water” and ”upward” are far. Therefore, ”water” and ”downward” may
form a common sense knowledge. We may state that in its simple form, in the
embeddings world a common sense knowledge consists of a set embeddings that
are very close to each other.

There are a few key points, here. First, pre-training of embeddings makes it
feasible to quickly ﬁnd close embeddings that form a common sense knowledge.
To obtain common sense knowledge, an intelligent machine may only need to
perform operations such as computing the distance between two embeddings or
ﬁnding embeddings within a given radius. Such operations can be done much
faster than operations such as learning optimal embeddings, not to mention
they can be done within a pre-processing phase too. In the case of pre-trained
parameterized embeddings, embeddings of objects can be computed very quickly
using the learned parameters. So in this case, common sense knowledge will be
available very fast too. This is consistent with an interpretation of common sense
knowledge of human beings, that humans obtain this knowledge instantaneously
so that it is felt that they already have it.

Second, common sense knowledge of humans has characteristics such as: i) it
is not a symmetric relation, e.g., the common sense knowledge that adult people
have about water (or even about babies) is not the same as the common sense
knowledge that water or babies have about adults, ii) it is not necessarily limited
to humans, for example, some animals may also have forms of common sense
knowledge such as ”water ﬂows downward”, and iii) humans (and in general
objects of our world) may have diﬀerent levels of common sense knowledge
about other entities, for example experienced or mature people may have a
higher level of this knowledge. All these characteristics are consistent with
In the
the common sense knowledge obtained from pre-trained embeddings.
embeddings world, for each object or agent an access level can be deﬁned which
determines embeddings accessible to it. It can consist of its own embeddings
and those embeddings that determine its free-will domain or authority domain.
Moreover, the object/agent may actually load, process and use only a fraction
of these accessible embeddings and over time, this fraction may become larger
and larger. So, common sense is not symmetric as the embedding of object O1
might be in the authority domain of object O2, but the embedding of O1 might
not belong to the authority of O1. As soon as the intersection of the authorities
of a group of objects becomes non-empty and some of the embeddings in this
intersection are close enough, the objects ﬁnd common sense knowledge. The
level of common sense knowledge of an object in the embeddings world may
depend on its authority and the fraction of its authority which is loaded and
processed. Also, it may vary over time.

8

4.3 Unconscious knowledge

A characteristics of human intelligence is that in many situations, they take
actions without reasoning and simply choose the appropriate response, without
investigating all alternatives and possibilities. Philosophers such as Dreyfus ar-
gue that in these cases humans’ intuitions are trained to the point that they
can simply ”size up the situation” and show the appropriate reaction. Accord-
ing to Dreyfus, the human’s sense of the situation is based on unconscious and
background knowledge about the world. They use this knowledge to discrim-
inate between what they consider essential and lots of other things that they
are aware of, but they consider inessential. Dreyfus believes that symbolic AI
would have diﬃculties in capturing this unconscious knowledge and doing the
kind of fast problem solving that it allows [15, 14].

We believe pre-trained embeddings can help machines and computer pro-
grams to capture unconscious knowledge. Those pre-trained embeddings inside
the authority of an agent that are frequently accessed/processed by the agent
or are very close to it, can form its background and unconscious knowledge.
These embeddings can be stored on a high speed storage device, to be retrieved
very quickly by the agent. Moreover, the results of frequent learning tasks can
be stored so that the agent does not require to run their algorithm each time.
Note that in general, generating high quality embeddings is the most signiﬁcant
and time consuming step during the learning and reasoning process. Having
high quality embeddings in hand, a simple learning algorithm that can be run
very fast is suﬃcient to produce accurate results [1]. In other words, the whole
learning process is so slow and time consuming, so that in order to have uncon-
scious knowledge and fast problem solving, using pre-trained embeddings seems
to be inevitable. In fact, pre-trained embeddings already carry a considerable
amount of learned knowledge and give it to agents and computer programs.

4.4 Learning and reasoning

State of the art algorithms for learning and reasoning in diﬀerent domains, in-
cluding speech recognition [9, 28] natural language processing [12, 16] and graph
data analysis [21, 4, 2], are based on computing embeddings for input objects.
Instead of computing these embeddings when solving an speciﬁc task, we can
pre-train them using a general-purpose objective function. Then, for each task
a simple method that instead of objects, takes their pre-trained embeddings as
input, usually works ﬁne [1]. Figure 1 shows an example of a neural network
that consists of the input layer, the output layer and a number of hidden layers.
Each layer takes the output of its previous layer as input and using some train-
able parameters, generates an embedding. The hidden layers (or at least some
of them) can be pre-trained, so that only the output layer is trained during an
speciﬁc learning task. This may slightly decrease the quality of the results, but
enormously improves the eﬃciency and run time of the learning process.

A domain that particularly depicts the strength of pre-trained embeddings, is
neuro-symbolic AI. Neuro-symbolic AI states that combining deep neural models

9

Figure 1: In this simple neural network, each hidden layer produces an embed-
ding of the input object. If we produce most of hidden layers during pre-training
(using a general-purpose objective function), one or a few layers will be left for
the learning and reasoning phase, which can be done very eﬃciently.

with classical rules-based symbolic AI can improve the learning and reasoning
process. More precisely, it suggests to use deep learning for feature extraction
and embedding learning, and rule-based symbolic AI to manipulate and reason
with these embeddings [31]. Recent studies [25] show that for tasks such as
visual reasoning [20], neuro-symbolic models outperform deep models, when a
limited training dataset is available. We think one of key reasons for the success
of neuro-symbolic AI is the high quality embeddings that are learned to capture
and encode diﬀerent aspects of objects, and make it easy to reason about them.

4.5 Modeling inﬁnity

One of challenges that AGI encounters, is modeling the environment of an agent.
The environment of an agent which is the whole or part of our world, can
consist of millions of millions and even an inﬁnity many number of objects. This
renders the algorithms ineﬃcient and also, makes storing information required
for modeling such an environment impossible. So, it is required for computer
programs to ﬁnd an eﬃcient feasible solution to deal with this inﬁnite number
of objects.

In pre-training, embeddings are usually generated and stored, so that an
intelligent agent just needs to use them. In some cases, however, the number
of such embeddings can go to inﬁnity as the number of objects is inﬁnite. For
example, the number of words in a language (English for instance) is ﬁnite. Even
sometimes, a dictionary is used that consists only of words in the language that
are important. Then, embeddings are computed and stored for all words or for
words in the dictionary which nevertheless, form a ﬁnite set. However, the set
of all images or the set of all graphs are very large or even inﬁnite. So in such
cases, it is impossible to store the pre-trained embeddings of all images or all
graphs. A technique which is useful in such cases is inductivity. As discussed
in Section 3, in inductive machine learning, part (not the whole) of the training

10

dataset is used for training and ﬁnding optimal values for parameters. Then,
the learned parameters are used for the whole data. In computing embeddings,
each embedding is deﬁned as a parameterized function of some input features.
During inductive parameter learning, the optimal values of these parameters
are learned over some part of the data. Then these values are used to compute
the embedding of any given object from the domain. As a result, in this case,
instead of storing the embeddings themselves, the much smaller ﬁnite set of
parameters that are used to compute embeddings, are stored.

4.6 Continuality of learning

In most of advanced AI systems that use deep neural networks, the knowledge
and intelligence of machines and computer programs are grounded in the train-
ing data, which is static. As a result, they are not able to respond correctly to
questions and tasks that are time-dependent. For example, they might answer
wrongly to questions like: who is the current UN secretary-general? Chen and
Liu [8] consider lifelong or continuous learning as one of the hallmarks of hu-
man intelligence, and mention that current intelligent systems fail to realize it
as their learning is mostly isolated. They deﬁne lifelong learning as a paradigm
wherein the intelligent agent learns continuously, accumulates the knowledge
learned in the past and uses it for future learning and problem solving [8].

In the literature of AI research, AGI is mostly thought as a technique or an
algorithm or a product, which may or may not be realized someday. Rather,
we believe AGI is a process, like human civilization, which will be formed con-
tinuously and during a long period of time, and will become more and more
mature over time. In a similar sense, pre-trained embeddings will be computed
continuously and will become more and more mature over time. Changes in the
world are reﬂected in the embeddings world by computing new and updated
pre-trained embeddings, so that the embeddings world will always reﬂect an
updated and accurate approximation of the world. Moreover, pre-trained em-
beddings can facilitate continual or lifelong learning. As stated in [30], one of
key elements of lifelong learning is the retention or consolidation of learned task
knowledge. Since pre-trained embeddings are learned and stored once and used
repeatedly, they automatically maintain the learned knowledge.

5 Conclusion

In this paper, we ﬁrst stated that in order to realize AGI, along with building
intelligent machines and computer programs, an intelligent world should also
be constructed which is on the one hand, an accurate approximation of our
world and on the other hand, a signiﬁcant part of reasoning and intelligence of
intelligent machines is already embedded in this world. Then we discussed that
AGI is not a product or algorithm or system, rather it is a continuous process
which will become more and more mature over time (like human civilization
and wisdom). Then, we argued that pre-trained embeddings play a key role in

11

building this intelligent world and as a result, realizing AGI. We discussed how
pre-trained embeddings facilitate achieving key characteristics of human-level
intelligence by machines.

Currently, by computing pre-trained embeddings for objects of certain do-
mains such as texts, images, videos and graphs, the process of building the
embeddings world is already started. However, we are just in the beginning of
this process. We believe this endless process will continue and more and more
pre-trained embeddings will be generated in more and more domains, to model
our world for intelligent agents as much as possible. There will be of course sev-
eral challenges in this process, especially in computational and storage aspects,
and it seems too early to talk about technical details of the actual creation of
the embeddings world. Nonetheless, the way we see the future of AI is that
we will have a huge amount of pre-trained embeddings that are continuously
completed and updated over time. Diﬀerent companies will introduce their own
version of the embeddings world, and most of intelligent computer programs
will heavily rely on these embeddings worlds.

References

[1] Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learn-
ing: A review and new perspectives. IEEE Trans. Pattern Anal. Mach.
Intell., 35(8):1798–1828, aug 2013.

[2] Shaked Brody, Uri Alon, and Eran Yahav. How attentive are graph atten-
tion networks? In International Conference on Learning Representations,
2022.

[3] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Ka-
plan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger,
Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeﬀrey
Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz
Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam
McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language
models are few-shot learners. In Hugo Larochelle, Marc’Aurelio Ranzato,
Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, Advances
in Neural Information Processing Systems 33: Annual Conference on Neu-
ral Information Processing Systems 2020, NeurIPS 2020, December 6-12,
2020, virtual, 2020.

[4] Mostafa Haghir Chehreghani. Half a decade of graph convolutional net-

works. Nature Machine Intelligence, 4:1–2, 03 2022.

[5] Mostafa Haghir Chehreghani, Talel Abdessalem, Albert Bifet, and Meriem
Bouzbila. Sampling informative patterns from large single networks. Future
Gener. Comput. Syst., 106:653–658, 2020.

12

[6] Mostafa Haghir Chehreghani and Maurice Bruynooghe. Mining rooted
ordered trees under subtree homeomorphism. Data Min. Knowl. Discov.,
30(5):1249–1272, 2016.

[7] Mostafa Haghir Chehreghani, Morteza Haghir Chehreghani, Caro Lucas,
and Masoud Rahgozar. Oinduced: An eﬃcient algorithm for mining in-
duced patterns from rooted ordered trees. IEEE Trans. Syst. Man Cybern.
Part A, 41(5):1013–1025, 2011.

[8] Z. Chen and B. Liu. Lifelong Machine Learning. Online access: Morgan
and Claypool Synthesis Collection Seven. Morgan and Claypool Publishers,
2016.

[9] Jan Chorowski, Ron J. Weiss, Samy Bengio, and A¨aron van den Oord.
Unsupervised speech representation learning using wavenet autoencoders.
IEEE ACM Trans. Audio Speech Lang. Process., 27(12):2041–2053, 2019.

[10] Michael K. Cohen, Badri N. Vellambi, and Marcus Hutter. Intelligence and
unambitiousness using algorithmic information theory. IEEE J. Sel. Areas
Inf. Theory, 2(2):678–690, 2021.

[11] Ramon Lopez de Mantaras. The Future of Artiﬁcial Intelligence: Toward

Truly Intelligent Artiﬁcial Intelligences. Fundacion BBVA, 2019.

[12] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
BERT: pre-training of deep bidirectional transformers for language under-
standing.
In Jill Burstein, Christy Doran, and Thamar Solorio, editors,
Proceedings of the 2019 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies,
NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1
(Long and Short Papers), pages 4171–4186. Association for Computational
Linguistics, 2019.

[13] Hubert L. Dreyfus. Alchemy and Artiﬁcial Intelligence. RAND Corpora-

tion, Santa Monica, CA, 1965.

[14] Hubert L. Dreyfus. What Computers Still Can’t Do. MIT Press, revised

edition edition, 1992.

[15] Hubert L. Dreyfus, Stuart E. Dreyfus, and Tom Athanasiou. Mind over
Machine: The Power of Human Intuition and Expertise in the Era of the
Computer. The Free Press, USA, 1986.

[16] Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Arivazhagan, and Wei
Wang. Language-agnostic BERT sentence embedding. In Smaranda Mure-
san, Preslav Nakov, and Aline Villavicencio, editors, Proceedings of the 60th
Annual Meeting of the Association for Computational Linguistics (Volume
1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022, pages 878–
891. Association for Computational Linguistics, 2022.

13

[17] Ragnar Fjelland. Why general artiﬁcial intelligence will not be realized.

Palgrave Communications, 7(1):1–9, 2020.

[18] Travis R. Goodwin and Sanda M. Harabagiu. Embedding open-domain
common-sense knowledge from text. In Nicoletta Calzolari, Khalid Choukri,
Thierry Declerck, Sara Goggi, Marko Grobelnik, Bente Maegaard, Joseph
Mariani, H´el`ene Mazo, Asunci´on Moreno, Jan Odijk, and Stelios Piperidis,
editors, Proceedings of the Tenth International Conference on Language Re-
sources and Evaluation LREC 2016, Portoroˇz, Slovenia, May 23-28, 2016.
European Language Resources Association (ELRA), 2016.

[19] Marcus Hutter. Universal Artiﬁcial Intelligence: Sequential Decisions based

on Algorithmic Probability. Springer, Berlin, 2005.

[20] Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei,
C. Lawrence Zitnick, and Ross B. Girshick. CLEVR: A diagnostic dataset
for compositional language and elementary visual reasoning. In 2017 IEEE
Conference on Computer Vision and Pattern Recognition, CVPR 2017,
Honolulu, HI, USA, July 21-26, 2017, pages 1988–1997. IEEE Computer
Society, 2017.

[21] Thomas N. Kipf and Max Welling. Semi-supervised classiﬁcation with
graph convolutional networks. In 5th International Conference on Learning
Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Confer-
ence Track Proceedings. OpenReview.net, 2017.

[22] Alex Krizhevsky, Ilya Sutskever, and Geoﬀrey E. Hinton. Imagenet clas-
siﬁcation with deep convolutional neural networks. In Proceedings of the
25th International Conference on Neural Information Processing Systems -
Volume 1, NIPS’12, pages 1097–1105, Red Hook, NY, USA, 2012. Curran
Associates Inc.

[23] Brenden M. Lake, Ruslan Salakhutdinov, and Joshua B. Tenenbaum.
Human-level concept learning through probabilistic program induction.
Science, 350(6266):1332–1338, December 2015.

[24] Yann LeCun, Yoshua Bengio, and Geoﬀrey Hinton. Deep learning. nature,

521(7553):436, 2015.

[25] Jiayuan Mao, Chuang Gan, Pushmeet Kohli, Joshua B Tenenbaum, and
Jiajun Wu. The Neuro-Symbolic Concept Learner: Interpreting Scenes,
Words, and Sentences From Natural Supervision. In International Confer-
ence on Learning Representations, 2019.

[26] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeﬀrey Dean.
Distributed representations of words and phrases and their compositional-
ity. In Proceedings of the 26th International Conference on Neural Infor-
mation Processing Systems - Volume 2, NIPS’13, pages 3111–3119, Red
Hook, NY, USA, 2013. Curran Associates Inc.

14

[27] Piergiorgio Odifreddi. Roger penrose. shadows of the mind. a search for the
missing science of consciousness. oxford university press, oxford, new york,
and melbourne, 1994, xvi 457 pp. Journal of Symbolic Logic, 62(2):673–675,
1997.

[28] Mirco Ravanelli, Jianyuan Zhong, Santiago Pascual, Pawel Swietojanski,
Jo˜ao Monteiro, Jan Trmal, and Yoshua Bengio. Multi-task self-supervised
learning for robust speech recognition. In 2020 IEEE International Confer-
ence on Acoustics, Speech and Signal Processing, ICASSP 2020, Barcelona,
Spain, May 4-8, 2020, pages 6989–6993. IEEE, 2020.

[29] John R Searle. Minds, brains, and programs. Behavioral and Brain Sci-

ences, 3(3):417–457, 1980.

[30] Daniel L. Silver, Qiang Yang, and Lianghao Li. Lifelong machine learning
systems: Beyond learning algorithms. In Lifelong Machine Learning, Pa-
pers from the 2013 AAAI Spring Symposium, Palo Alto, California, USA,
March 25-27, 2013, volume SS-13-05 of AAAI Technical Report. AAAI,
2013.

[31] Zachary Susskind, Bryce Arden, Lizy K. John, Patrick Stockton, and Eu-
gene B. John. Neuro-symbolic AI: an emerging class of AI workloads and
their characterization. CoRR, abs/2109.06133, 2021.

[32] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you
need.
In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M.
Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett, editors,
Advances in Neural Information Processing Systems 30: Annual Confer-
ence on Neural Information Processing Systems 2017, December 4-9, 2017,
Long Beach, CA, USA, pages 5998–6008, 2017.

[33] Paul Voigtlaender, Yuning Chai, Florian Schroﬀ, Hartwig Adam, Bastian
Leibe, and Liang chieh Chen. Feelvos: Fast end-to-end embedding learning
for video object segmentation. In International Conference on Computer
Vision and Pattern Recognition (CVPR), 2019.

[34] Joseph Weizenbaum. Computer Power and Human Reason: From Judg-
ment to Calculation. W. H. Freeman and Co., USA, 1st edition, 1977.

15

