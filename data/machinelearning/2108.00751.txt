Data-driven model for hydraulic fracturing design optimization. Part II: Inverse problem

V.M. Duplyakova, A.D. Morozova, D.O. Popkova, E.V. Shelb, A.L. Vainshteina, E.V. Burnaeva, A.A. Osiptsova, G.V. Paderinb

aSkolkovo Institute of Science and Technology (Skoltech), 3 Nobel Street, 143026, Moscow, Russian Federation
bGazpromneft Science & Technology Center, 75-79 liter D Moika River emb., St Petersburg, 190000, Russian Federation

1
2
0
2

g
u
A
2

]

G
L
.
s
c
[

1
v
1
5
7
0
0
.
8
0
1
2
:
v
i
X
r
a

Abstract

We describe a stacked model for predicting the cumulative ﬂuid production for an oil well with a multistage-fracture completion
based on a combination of Ridge Regression and CatBoost algorithms. The model is developed based on an extended digital
ﬁeld data base of reservoir, well and fracturing design parameters. The database now includes more than 5000 wells from 23
oilﬁelds of Western Siberia (Russia), with 6687 fracturing operations in total. Starting with 387 parameters characterizing each
well, including construction, reservoir properties, fracturing design features and production, we end up with 38 key parameters
used as input features for each well in the model training process. The model demonstrates physically explainable dependencies
plots of the target on the design parameters (number of stages, proppant mass, average and ﬁnal proppant concentrations and
ﬂuid rate). We developed a set of methods including those based on the use of Euclidean distance and clustering techniques to
perform similar (oﬀset) wells search, which is useful for a ﬁeld engineer to analyze earlier fracturing treatments on similar wells.
These approaches are also adapted for obtaining the optimization parameters boundaries for the particular pilot well, as part of
the ﬁeld testing campaign of the methodology. An inverse problem (selecting an optimum set of fracturing design parameters to
maximize production) is formulated as optimizing a high dimensional black box approximation function constrained by boundaries
and solved with four diﬀerent optimization methods: surrogate-based optimization, sequential least squares programming, particle
swarm optimization and diﬀerential evolution. A recommendation system containing all the above methods is designed to advise a
production stimulation engineer on an optimized fracturing design.

Keywords: hydraulic fracturing, machine learning, predictive modelling, design optimization, gradient-free optimization,
probability of improvement, surrogate optimization, multistage fracturing

1. Introduction and problem formulation

In this paper, we continue the work on the development of
a workﬂow on hydraulic fracturing (HF) design optimization
with machine learning on ﬁeld data, which was initiated in [1].
In Part I of this project, we presented the detailed methodology
for development of a digital database on reservoir and well pa-
rameters, design parameters of multistage fracturing treatments
and production data. We also discussed in detail the forward
problem of production forecast based on reservoir, well and
fracturing design data. Here we continue the eﬀort and now
move on to the development of the optimization workﬂow (in-
verse problem).

Before we move to our results, let us review the recent devel-
opments in the area of machine learning-assisted optimization
of hydraulic fracturing designs. In [1], we made a thorough re-
view of the relevant literature published on this subject, so the
reader is referred to [1] for the state of the art, whereas here we
will only mention new papers appeared after Part I of our study
has been published.

The paper [2] uses candidate selection for refracturing oper-
ations based on data analytics. Gradient boosting is used for
production forecast, and the feature importance analysis indi-
cates the current production (before refracturing) to be the most

Email address: a.osiptsov@skoltech.ru (A.A. Osiptsov)

Preprint submitted to Journal of Petroleum Science & Engineering

important parameter. We would like to emphasize that the prob-
lem of candidate selection for refracturing treatments and the
problem of primary fracturing design optimization are the two
very diﬀerent problems by formulation: the prior production is
known when it comes to refracturing, which makes the task of
predicting subsequent production much easier.

In [3], the multiobjective random forest method is proposed
to predict the dynamic production data for a shale gas well,
with geological and hydraulic fracturing properties used as in-
put features. The performance of multi-objective random for-
est (MORF) and multi-output regression chain (MORC) meth-
ods are compared. A dynamic regression model is constructed
in [4] using a machine learning method referred to as the sliding
window regression. Features of the model are divided into four
groups: integral, local, pressure and autoregressive. The idea of
sliding window is used to obtain a model with stable coeﬃcient
dynamics and ability for long-term forecast.

In [5], variable-length particle-swarm optimization (Modi-
ﬁed Variable-length PSO, MVPSO) was proposed to automat-
ically select the optimal fracturing parameters: the number of
fractures as well as the corresponding fracture properties. Then,
MVPSO was veriﬁed and compared with VPSO by several
benchmarks. In addition, a gas/water two-phase model consid-
ering gas-adsorption and Knudsen-diﬀusion eﬀects was used to
describe the shale-gas ﬂow in matrix and fracture domains.

August 3, 2021

 
 
 
 
 
 
About this work: the paper is organized as follows. The sta-
tus of the development of a digital database is summarized in
Sec. 2. We describe the model for production forecast (forward
problem) in Sec. 3. A study on oﬀset wells selection for ﬁnd-
ing optimization intervals for fracturing design parameters is
presented in Sec. 4. Inverse problem of ﬁnding the optimized
fracturing design parameters is discussed in Sec. 5. Overall dis-
cussion and analysis of the results are given in Sec. 6. The paper
ends up with summary and conclusions in Sec. 7.

2. Data

2.1. Database overview

In this work, we use the version 7.9 of the database. Com-
pared to the database version 5.5 used in our previous publica-
tion [1], the overall architecture and the sources of data used
to compile the database for production forecast have not been
changed. The database still contains information on more than
six thousands miscellaneous fracturing operations (single-stage
and multi-stage, primary and re-fracturing) or about 17 000
injections on 5 425 wells from 23 diﬀerent ﬁelds in Western
Siberia for the period 2013-2019, including well proﬁle, frac-
turing design, geological and production reports. Also, the cen-
tralized approach to data organization is remained unchanged.
Our work on improvements of the database have been contin-
ued and the quality of the preprocessed data was increased so
far through consultations with engineers ingrained in the raw
data collection process.

Current version of the database 7.9 contains the following

changes:

• Target preprocessing is updated: monthly data consoli-
dated in 3-, 6- and 12-months slices are summed also for
all active reservoirs on the well and not only the stimulated
ones. The shape of the target distribution, predictably, has
become smoother by moving the peak from almost 1,000
to near 2,000 cubic metres of ﬂuid, as shown in Fig. 1;

• There was an issue with the lack of standardization in
reservoir’s and well’s namings among the data sources.
Similarity between labels is now achieved through mor-
phological analysis;

• Added new features: proppant properties (grain size and
density of prevailing type by proppant manufacturer);

• Added facies for the dominant ﬁeld. The feature is de-
scribed by ﬁve zones from lithological maps: slope zone,
proximal fan, shallow area, alluvial fan and depocenters.

2.2. Target variable

Selection of the right target variable is crucial for the success
of the entire optimization workﬂow, so we think it deserves a
separate discussion in this subsection. We analyzed the data
made available to us and also discussed in detail the current
strategies of fracturing design development among production
stimulation engineers and come to a conclusion that fracturing

operations are optimized in the ﬁeld based on the metrics of
maximizing reservoir contact: the larger the fracture the better.
Hence, bigger fractures yield larger cumulative volume of re-
covered total ﬂuid (both oil and reservoir water), and there is a
strong correlation. Rarely this consideration takes into account
the fact the excessively large fractures may breakthrough into
upper or lower layers, thereby causing additional production of
water. Thus, a model targeted to predict the cumulative volume
of total produced ﬂuid was trained on existing data with slightly
higher accuracy (as there is a direct correlation between the in-
put parameters characterizing the fracturing design and the total
cumulative produced ﬂuid), as compared to a model targeted on
cumulative oil only, where the prediction accuracy was lower,
as the oil production is not directly correlated with the design
parameters governing the fracture dimensions. The present re-
alization of the model does not take into account (yet) the pres-
ence of water-bearing layers, so the model better predicts the
total volume of produced ﬂuid. During the pilot works, we deal
with the particular oilﬁeld where there are no bottom waters
nearby target formation, so the targets of cumulative total ﬂuid
and cumulative oil are practically equivalent.

At the same time, we realize that generalization of the present
workﬂow to oilﬁelds with the presence of aqueous layers will
require modiﬁcations: we will need to add some features char-
acterizing the presence of upper/lower water bearing formations
to be able to predict the production of oil and water separately,
and also the target variable should be composed of two com-
ponents: maximum total ﬂuid and maximum pure oil (or mini-
mum water cut, which is equivalent).

We use the 3-month cumulative production data to utilize all
the data available, including the most recently fractured wells,
where the production history is short.

An interpolation of the monthly data was used in order to
come up with 90-day production period. This approach is suit-
able, for instance, if a well worked for 20 days in the ﬁrst month
after fracturing treatment and 30 days in the following months,
the desired value is in 80-110 days or 3-4 months range and can
be found through the interpolation.

Figure 1: Target probability distributions for database v. 5.5 used in [1] (red) &
the current database v. 7.9 (blue).

2

2.3. Feature selection

Eventually, we use the following procedure for feature elim-

In the ﬁrst part of this study [1], we made eﬀorts to utilize the
entire database with primary fracturing operations, as well as
refracturing to solve the forward problem of predicting the pro-
duction rate without any preliminary separation of the dataset.
Currently, the database is divided into two parts: primary
and repeated stimulations. We ﬁtted models for prediction of
the ﬂuid production for both these types of operations. Further,
during the ﬁeld tests, we focused only on primary stimulation
treatments optimization.

To construct the models and increase interpretability of the
It can be done

problem we use feature importance analysis.
with or without the involvement of an approximation model.

One method is a sensitivity analysis via Sobol indices [6],
which can be calculated without constructing any approxima-
tion model and decompose the variance of the target variable
into parts attributed to input features. The most important fea-
tures can be seen in Fig. 2.

On the contrary, SHAP method [7] is based on an approx-
imation model, utilizes the concept of Shapley values [8] and
measures features importances in terms of predictive power of
each feature. The use of this method more accurately shows the
true importance of the features [9]. The SHAP values can be
calculated for tree-based models (which we use).

Indeed, the diﬀerence between the two models for primary
stimulation vs refracturing can be seen through the SHAP fea-
ture importance analysis (Figs. 3, 4). (In case of categorical fea-
tures we use one-hot encoding. The corresponding features are
preﬁxed with “cat.”.) Particularly, for refracturing operations
the key feature having major impact on the target is the level
of production before the refracturing treatment (which was not
captured in previous analysis), which is absent in case of pri-
mary operations. Having data on production prior to refractur-
ing makes the production forecast problem easier to solve, com-
pared to the case of production forecast after primary fracturing
operations. This has also been noted in other studies [10].

Based on the analysis, we may conclude that the features de-
scribing proppant properties (introduced in Sec. 2.1) are not im-
portant for predicting the ﬂuid production.

Another way of analyzing parameters is the feature elimina-
tion procedure which implies a reduction of feature space which
in its turn may improve the performance of the approximation
model. Feature elimination can be achieved by applying a pair-
wise correlation of parameters via the Spearman correlation and
by the Recursive Feature Elimination (RFE) method which in-
volves the use of the approximation model. Speaking of the
former, the reason of choosing the Spearman correlation instead
of the Pearson correlation is because most of the features cor-
relations are non-linear. So, by estimating correlations between
features we can remove perfectly correlated features and fea-
tures with zero variance. Regarding the second method, RFE
is a procedure for backward selection of features which works
as follows. First, a model is built on an the entire set of input
features, and features’ importance is calculated. Then, the least
important features are removed. After that, the model is rebuilt
on the reduced set of features and we repeat the process.

ination:

1. Select 3-month slices; (6- and 12-months production &
geological and technical data are removed due to the lack
of data from the latest treatments);

2. Remove parameters which are not relevant for the consid-
ered target variable, or for which more than 80% of the
observations are missing;

3. Estimate Spearman correlations to identify perfectly corre-
lated features; remove features with almost zero variance;
4. Apply RFE to select features, which are the most impor-

tant for the target prediction.

As the result, we reduced our initial set of features from 387

to 38 features.

Figure 2: Sobol sensitivity for the entire database.

Figure 3: SHAP feature importance: refracturing operations.

3. Forward problem of oil production forecast after frac-

turing.

3.1. Problem formulation

In this section, we describe the methods developed for pre-
diction of the cumulative ﬂuid production. Previously [1], we

3

Besides, the model predictions should be physically explain-
able and robust. To check these properties we plotted depen-
dencies of the target on the input design parameters. We expect
the plots to demonstrate smooth and robust behaviour. One can
see in Figure 17 (green line) that CatBoost-based plots are not
smooth, as there is not so much initial data and decision-tree
based algorithms create piece-wise constant approximations.

To correct this behaviour of the model we used a stacking
approach. In the ﬁrst step, we trained a ridge regression model,
then we subtracted predictions of the model from the true tar-
get values and then ﬁtted a CatBoost regression model on the
residuals. Hyperparameters tuning was performed using 5-folds
cross validation. Overall model uses both ridge and CatBoost
regression algorithms, summing the predictions. One can see
the improved dependencies plots in Figure 17 (red line). We
believe that these plots are more physically explainable. To
characterize quality of the model we used scores presented in
Table 1. These metrics were calculated on the hold-out set that
is 30% of the initial data. See also the scatter plot in Fig. 5.

Quality score
R2
MAE
MedianAE
MAPE
Weighted MAPE [11]
MSE
RMSE

Value
0.64
1131
723.7
36.08
29.07
2802631
1674.11

Table 1: Quality scores for the stacked model

Figure 5: Scatter plot for the stacked model

4. Selection of optimization intervals

After constructing the model, the inverse problem is formu-
lated as ﬁnding a set of optimal fracturing design parameters

4

Figure 4: Feature importance: primary fracturing on new wells.

created prediction model based on gradient boosting algorithm
which was based on various features including reservoir param-
eters, well construction and HF design data (which includes
many features like pumping pressure, ﬂuid eﬃciency, fracture
geometry, etc). Those features were useful for predicting the
eﬃciency of HF. However, in this paper, we focus on choosing
the proper HF design only for the new wells. We need to know
the optimal design before the treatment, therefore we cannot
use all the design features, as many of them are known only
after the fracturing. Chosen features for the optimization are:

• Number of stages,

• Pad share,

• Fracturing ﬂuid volume (or average proppant concentra-

tion),

• Proppant mass,

• Fluid rate,

• Final proppant concentration (proppant concentration at

the last stage of pumping).

These parameters are essential for planning the HF treatment.
Through those features one can estimate a pumping schedule
for a particular well.

One may notice the absence of one of the most important
parameters, which determines the fracturing ﬂuid viscosity —
polymer concentration (in water-based polymer gels). This is
due to the very low variability of this parameter in the initial
database.

3.2. Stacking

The most successful algorithms in terms of error metrics
were decision-tree based ones for the problems with heteroge-
neous set of features. For our prediction task, the CatBoost
outperformed all others.

to maximize our target. Since the model is multi-dimensional,
a valid selection of the design parameter values is only possi-
ble if they change within the relevant intervals during the opti-
mization procedure. These intervals are caused by various con-
straints, arising in the ﬁeld.

The additional restrictions on design parameter values can
be divided into geological and technological constraints. Geo-
logical constraints include those related to the geological struc-
ture of the formation. For example, proximity of gas or wa-
ter bearing formations leads to the necessity to limit fracture
height growth, which automatically leads to limitation of the
maximum volume of injected proppant and requires change of
the perforation strategy. Geological constraints can also be re-
lated to waterﬂooding cases. For example, when an injection
well, operating at bottomhole pressures higher than the forma-
tion breakdown pressure, is located relatively close to the pro-
duction well and is in the direction of fracture propagation, it
is necessary to limit the maximum fracture half-length on the
production well.

Technological limitations include those related to the tech-
nical capabilities of the equipment and chemicals used. For
instance, the maximum fracturing pressure (ﬁrst of all, it is
connected with the capabilities of the wellhead equipment and
pumping units) can lead to the restriction on the maximum frac-
ture width. Those limitations at a ﬁrst approximation could be
obtained by oﬀset (similar) well search methods.

In the ﬁeld, a fracturing job is pumped with variable prop-
pant concentration, so another limitation we add is a parameter
characterising the rate of increase in the proppant concentration
in the fracturing ﬂuid from initial (cstart) to ﬁnal (c f in) concen-
tration [kg/m3] with respect to increase to average cavg. The
parameter is denoted as (cid:15) and is deﬁned as:

(cid:15) =

c f in − cstart
cavg − cstart

− 1.

(1)

Boundaries for this parameter are the same for all pilot wells:
from 0.5 to 1.5. This is not a parameter that needs to be op-
timized, we add these bounds as a constraint for optimization
algorithms.

4.1. Clustering for oﬀset wells selection

To ﬁnd optimization intervals for fracturing design parame-
ters we deﬁne a pilot cluster as a set of wells which are sim-
ilar to the pilot one (the same ﬁeld, layer, face and direction).
We estimate design parameters limits as 5th and 95th percentiles
of the values of the parameters for wells, belonging to the
constructed cluster. Thus, we believe, the results of the opti-
mization would be more robust, as we do not use extrapolated
model’s predictions.

Another approach to obtain optimization boundaries for the
speciﬁed pilot well is to utilize unsupervised ML methods like
clustering and dimensionality reduction. The procedure is as
follows (See also ﬁgs. 6, 7):

Figure 6: Cluster procedure: steps 1 – 5, 9

Figure 7: Cluster procedure: steps 6 – 8

1. Remove all features from the database except the environ-
ment parameters: PVT, geomechanics, well log interpre-
tation, well id;

2. Filter the obtained subset by the number of stages, layer id
and face of the pilot well. This step is needed in order to
collect wells technically similar to the pilot well;

3. Apply a clustering algorithm to the environment param-
eters of the ﬁltered data subset. Hyperparameters of the
clustering method are optimized via a gradient-free op-
timization algorithm by maximizing the mean silhouette
coeﬃcient, calculated for a particular cluster as follows:
S i = bi − ai
max(ai, bi)

(2)

,

where ai is a mean intra-cluster distance, bi is a mean
nearest-cluster distance;

4. Find a cluster to which the pilot well belongs to. Assert

this cluster as a pilot well cluster;

5. Using id-s of the objects from the pilot cluster, add the
design parameters values to the objects’ descriptions;
6. Analyze the pilot cluster statistics: minimum, maximum
and mean values of the design parameters. The minimum
values and the maximum values serve as the optimization
boundaries while the mean values of the design parameters
are used as an initialization for the optimization problem.
7. Perform a visual analysis via the t-SNE algorithm based on
the environment parameters. t-SNE can only be applied to
data without missing values. Hence, the missing values
are imputed by the matrix factorization algorithm [1]. Af-
ter that we obtain the t-SNE embedding for the selected

5

subset of data. Here t-SNE embedding is a mapping of the
multidimensional input features to the two-dimensional x
and y coordinates for each observation of the data subset.
These two-dimensional coordinates can be used for visu-
alization of the considered data subset.

8. After that, using the considered subset of the data and the
obtained t-SNE coordinates build an ML regression model
to predict t-SNE x and y coordinates for any new object.
The corresponding ML model takes as input environment
parameters and returns as output t-SNE coordinates x and
y. The reason of predicting the t-SNE coordinates is be-
cause any change in the data like appending a new pilot
well to the data set will require running the t-SNE algo-
rithm from scratch;

9. Predict the t-SNE coordinates x and y for the pilot well us-
ing the constructed regression model. This allows to visu-
alize the position of a new well with respect to the selected
data subset;

10. Create a t-SNE scatter plot from the x and y t-SNE coordi-
nates. Label the corresponding clusters of each object by
some colors and label the pilot well by a star symbol. This
procedure visually veriﬁes how the data is clustered and
how the pilot well is located with respect to the remaining
data set.

The example of this method implementation is shown in Fig. 8.

Figure 8: t-SNE scatter plot for cluster visualization

4.2. Missing pilot parameters imputation

In practice some of the parameters values of a well can be
missing. Imputation is needed for wells parameters values be-
cause gradient-free optimization algorithms are based on con-
structing regression models and so they cannot work with miss-
ing values. For better results, we need to impute these values
not just by ﬁlling them with corresponding mean values, but we
should do it in a smarter way. We propose several strategies

6

to do it. The matrix factorization method was described in the
ﬁrst part of our study [1]. The second method is to impute miss-
ing values by averaging parameters values of the top-N similar
wells. The method to ﬁnd similar wells is described in Sec. 4.3.
Another way to make the imputation is to use the mean pilot
cluster parameters values as described in step 6 of the algorithm
in the previous subsection.

4.3. Oﬀset wells selection by Euclidean distance

Oﬀset wells are the wells, similar to the pilot one in terms
of their geological surroundings. One may look for these wells
both in terms of their geological and geographical (closest wells
within certain radius from the pilot one) similarities. These ana-
logue wells search is very useful for a petroleum engineer as it
allows to analyse fracturing operations, conducted previously,
and the design parameters values, check whether an operation
was successful or not, etc. We can also extract additional fea-
tures from the neighbouring wells, which increase predictive
power of the models [10]. For example, in our work, we used
features, such as average ﬂuid production divided by distance
from the pilot well, using wells within 1 km from the pilot one.
As a similarity metric we can use the Euclidean distance be-
tween the pilot well and the other wells. To calculate it, we
ﬁrstly need to normalize values in the database. We perform a
linear min-max normalization, where min and max values are
the 1st percentile and the 99th percentile respectively. We use
percentiles to discard possible outliers in the initial data set.
Then, the Euclidean distance between two vectors of parame-
ters, characterizing wells, is calculated as

d(p, q) =

(cid:113)

(p1 − q1)2 + · · · + (pn − qn)2,

(3)

where pi and qi are the i-th parameter’s values of the corre-
sponding wells. The distances are calculated between the pilot
well and all other wells, belonging to the same cluster (within
the same ﬁeld, layer and face). The results of such similar wells
search are considered robust and sustainable by ﬁeld geologists.
One can see an example of a result of such search in Fig. 18.

In this work we combine the clustering method for selecting
oﬀset wells with the euclidean distance search. The clustering
is used for obtaining the set of similar wells, then we reduce
the size of this set, leaving only top-N wells by the euclidean
distance. This method allows us to look for optimal values of
the design parameters in a certain vicinity where the prediction
model works well. Also, in some cases the top-N similar wells
can be used for imputing missing parameters for the pilot well.

5. Inverse problem of ﬁnding frac design parameters to

maximize production

5.1. Problem formulation

An inverse problem can be formulated as optimizing a high
dimensional black box (BB) with respect to inputs constrained
by boundaries. In our case BB is a function with unknown ex-
pression or internal structure that, given a list of inputs, returns
corresponding outputs. The high dimensionality of the input

presents an exponential diﬃculty for problem modeling and op-
timization (so-called “curse-of-dimensionality”) [12]. To opti-
mize a high-dimensional computationally expensive black box
(HEB) function, it is required to iteratively evaluate an objective
function, which can be costly and so becomes unacceptable. In
our case, the HEB function is represented by the constructed
ML regression. To optimize HEB, we used the following op-
timization methods: surrogate-based optimization (Sec. 5.3),
sequential least squares programming [13], particle swarm op-
timization [14] and diﬀerential evolution [15] algorithms. The
advantages of these methods are that they make no assumptions
about the problem being optimized and can perform searches in
very large spaces of candidate solutions.

For our methodology, the goal is to maximize the cumulative
ﬂuid production by ﬁnding a set of optimal design parameters
constrained by boundaries (see Sec. 4.1) for the speciﬁed pa-
rameters of the pilot well environment.

5.2. Review of known optimization procedures

There are studies published in open literature on optimization
of HF parameters based on some relatively moderate datasets
with hundreds of wells, e.g., see a study on 570 wells in Clin-
ton sand [16]. The ﬁrst stage is a neural network which takes
as input frac completions data and production history and pre-
dicts post-frac deliverability. The model serves as a screening
tool for excluding “dog wells”, which cannot be considerably
enhanced after a frac job. The second stage is based on a neu-
ral network, where the branch of the network, responsible for
the fracture design parameters, is connected to the optimization
algorithm to obtain the optimized frac design for each well and
the expected post frac deliverability (see Fig. 9).

Figure 9: A schematic diagram of the neuro-genetic approach

The work [17] also utilizes a neuro-genetic algorithm in the
optimization pipeline instead of a computationally complex im-
plicit numerical hydrodynamic model. In particular, the article
presents a case study of neuro-genetic optimization using the
In another paper [18]
example of a cross-ﬂow microturbine.
an ML regression analysis on more than 3500 wells was per-
formed, the authors optimized the design by visual analysis

7

with taking a pair of the most important parameters and select-
ing a region of the most optimal design.

Speaking about other industries, the article [19] uses neu-
ral networks and a hybrid multisubgradient descent method
with adaptive learning rate to solve multicriteria optimization
of multiple tasks (generation of too large droplets and too low
droplet speed) in the ﬁeld of bioprinting. The proposed method
can improve both printing accuracy and stability, and is useful
for realizing precise cell arrays and complex biological func-
tions.

Another application of machine learning and optimization is
the design optimization of thin multilayer solar cells to maxi-
mize external quantum eﬃciency [20]. The authors utilize the
concept of transfer learning which implies the use of experi-
ence gained in solving one problem to solve another, similar
problem. The reason why the transfer learning is applied to
the problem is because the problem involves the change of de-
sign speciﬁcations. Therefore, the transfer learning model acts
as a function of surrogate optimization, which reﬁts the sur-
rogate more eﬃciently. In particular, the procedure improved
the results by 2-3 times using only half of the training samples
compared to the usual model.

5.3. Surrogate-based optimization (SBO)

Surrogate models (approximation models) [21] can be used
with multi-dimensional input design spaces. As we know, the
more parameters the surrogate model takes as input the more
computational resources (training time) it is required to con-
struct the model.

A particular example of Surrogate-based Optimization
(SBO) or sequential model-based global optimization is
Bayesian optimization. The algorithm utilizes a probabilistic
surrogate function which approximates the expensive objective
function and an acquisition function which, in its turn, allows to
select a new candidate input design point within the domain. At
the beginning, a surrogate function is built on a small number
of samples from the original objective function, which provides
a target value. Then, the algorithm maximizes the acquisition
function and the surrogate is updated with a new input point
and its actual output value. After repeating the process, an opti-
mum can be achieved by taking the information about the sam-
ples from the past iterations. A typical choice of the surrogate
is Gaussian processes and random forest, while typical acquisi-
tion functions are the Expected Improvement (EI) and the Prob-
ability of Improvement (PI).

We used the SBO algorithm implemented in the industrial
software [22]. The SBO methodology is based on Gaussian
processes modeling technique [23, 24, 25, 26]. The particu-
lar numerical realization roots in the scientiﬁc works published
in [23].

6. Results and Discussion

During the research, we trained the model on wells from the
ﬁeld of interest only, thereby reducing the database from 6687
to 3308 fracturing operations.

wells search. Color bars represent the average value of the ana-
lyzed parameter for all wells in each of the three groups.

Figure 10: Average optimized production for all wells by diﬀerent optimiza-
tion algorithms

Field tests have been carried out on 21 wells. 9 wells were
horizontal, 7 — vertical multilateral, operating on several lay-
ers simultaneously, the rest 5 wells were regular vertical ones.
We were testing the accuracy of our prediction models, as well
as HF design optimization overall pipeline. This pipeline in-
cludes:

1. Obtaining design parameters optimization boundaries by
similar wells search with DBSCAN clustering (Sec. 4.1);
2. Imputing missing parameters with mean corresponding
parameters values, calculated using top-10 similar wells,
obtained within the pilot cluster via the euclidean distance
search (Sec. 4.3);

3. Performing the design optimization, using the predictive
model (Sec. 3) and optimization algorithms (Sec. 6.2)

6.1. Forward model prediction accuracy test

The production prediction errors are shown in Fig. 19. Here
we see a relatively low percentage error for horizontal wells,
which can be explained by the higher production rates of such
wells. What is important here is the high error for multilat-
eral wells, which is most likely caused by data distortion for
this type of wells. Currently, the data point for a multilateral
well is represented as a multistage fracture treatment with the
number of stages equal to the number of laterals with fractures.
The disadvantages of this method are obvious when hydraulic
fracturing is performed at diﬀerent points in time. In addition,
diﬀerent reservoir parameters must be considered for each op-
erational production formation.

Generally, the accuracy of our model (MAPE = 37.28%,
wMAPE = 27.46%) in ﬁeld tests is close to the hold-out set
accuracy check (MAPE = 36.08%, wMAPE = 29.06%). The
distribution of well types (vertical, horizontal) for ﬁeld tests is
close to that presented in the hold-out set.

6.2. Design optimization test

Overall, we formulated four approaches to the problem of

Figure 11: Average recommended ﬂuid rate for the wells

design optimization:

1. SBO: Surrogate-Based Optimization (Sec. 5.3),
2. SLSQ: Sequential Least Squares Programming,
3. PSO: Particle Swamp Optimization,
4. DE: Diﬀerential Evolution.

We compared these methods with each other in terms of
maximum produced ﬂuid and physically-grounded recommen-
dations for the design parameters for 3 well types: horizontal,
vertical and vertical multilateral.

Comparison of the eﬃciency of optimization algorithms in
Figure 10 shows the average cumulative ﬂuid production across
all pilot wells. A larger value means higher eﬃciency of an al-
gorithm. Figure 21 shows the extended results of the optimiza-
tion for each well individually.

The results of the optimization for design parameters are
shown in Figures 11-16. Here we have indicated the recom-
mended (optimum) values in percentages. 0% is a lower and
100% is an upper bound for each well, obtained by the oﬀset

Figure 12: Average recommended mean proppant concentration for the wells

8

Figure 13: Average recommended proppant masses (per stage) for the wells

Figure 16: Average recommended calculated epsilon

All the methods were operating under similar conditions:
boundaries, constraints, maximum allowable number of func-
tion evaluations (200). Under these conditions, SBO proved to
be the most eﬃcient algorithm in terms of maximizing the ob-
jective function (Figures 10 and 21). It is also possible to draw
conclusions about general optimization trends. First of all, the
most of the approaches for all well types maximized the target
by increasing the proppant mass and reducing the average prop-
pant concentration. It makes sense to increase the amount of
pumping ﬂuid and proppant to get maximum production while
we have neither WOC nor GOC.

We can clearly see the recommendation trends diﬀerence be-
tween horizontal and both types of vertical wells even though
vertical multilateral wells are represented in our database as
multistage fracturing operations (like horizontal wells). Pad
share here is the most interesting parameter, which does not
follow any particular trend. The ﬁnal proppant concentration
is lower for horizontal wells, which can be explained by the
high probability of ineﬀective treatments with high concentra-
tion values in these types of wells, as such ﬂuids are diﬃcult to
pump through well sections with high wellbore curvature. The
value of the ﬂuid ﬂow rate varies widely and is probably not
important for the purpose of maximizing production. This can
be proved by the low feature importance of this parameter, and
may also be due to the fact that the values of this parameter
are chosen properly in most of HF treatments presented in the
database.

Once we have the results of the optimization, we can carry
out a kind of retrospective analysis to ﬁnd out how we can
change usual HF designs to improve its results:
if the value
is below 50% – the optimum value is less than usual one used
during HF treatments and vice versa.

We tested the SBO method to ﬁnd the optimal set of design
parameters for each well from the pilot tests. In addition, we
limited the proppant mass to a value from the actual fracture
design (the actual values of the design parameters have been
chosen by the contractor). We then predicted ﬂuid production
for the optimal parameters and for the actual ones. Optimal
parameters showed a higher production rate, theoretically in-
creased by 38%. (Fig. 20).

Figure 14: Average recommended ﬁnal proppant concentration for the wells

Figure 15: Average recommended pad share for the wells

9

7. Summary and Conclusions

Finally, we plan to perform optimization for each well in the

database to generalize the overall optimization trend.

Since the ﬁrst part of this work was published in [1], both the
digital database and the production forecast model have under-
gone several changes: the database was updated (now v. 7.9,
compare with v. 5.5 in [1]) and new models were developed for
testing. The models for predicting cumulative ﬂuid production
now use a stacked approach with Ridge Regression and Cat-
Boost trained on the residuals to get smooth dependencies of
target values relative to design parameters.

Field test were performed with 21 wells. The accuracy of our
model in pilot tests (MAPE = 37.28%, wMAPE = 27.46%) is
close to the hold-out set accuracy check while model training
(MAPE = 36.08%, wMAPE = 29.06%).

A method for similar wells search was developed. The
method uses a clustering technique and the euclidean distance
as a metric of similarity. The results help engineers to look back
at previously conducted treatments. This method is also used to
estimate the interval limits for the design parameters to be op-
timised. Lower and upper limits are 5th and 95th percentiles of
the cluster parameter values respectively. One can reduce the
size of this set of wells, leaving only top-N wells by the eu-
clidean distance. This allows us to look for optimal values of
the design parameters in a certain vicinity where the prediction
model works well. Also, the top-N similar wells can be used
for imputing missing parameters for the pilot well.

A number of optimization techniques were tested during the
pilot testing: diﬀerential evolution, sequential least squares
programming, particle swarm optimization and surrogate-
based optimization.

The SBO approach on average maximized the 3-month ﬂuid
production better than other methods. General optimization
trend of 21 pilot wells is to increase the amount of fracturing
ﬂuid and proppant mass. Trends for ﬁnal, average proppant
concentration and ﬂuid rate are diﬀerent for each type of well
(horizontal, vertical and vertical multilateral). The calculated
production from the fracturing with the optimal set of design
parameters, compared to the treatments with an actual HF de-
sign, gives a theoretical target improvement of 38%.

In future work, we plan the following extensions of the pre-
sented workﬂow: (i) extend the list of features to include pres-
ence of upper/lower water-bearing layers to be able to predict
separately the production of pure oil and water, and extend the
target to maximum total ﬂuid and maximum pure oil (or min-
imum water cut); (ii) implement economics model to be able
to work under the metrics in terms of Q/CAPEX; (iii) consider
the inﬂuence of injection wells on production rates; (iv) extend
the target further to be able to treat the problem as a multi-
criteria optimization where the goal is to maximize the produc-
tion and to simultaneously minimize the total proppant load.
Furthermore, it can be very useful to combine synthetic data
from fracture design simulations (i.e, using commercial simu-
lators). With primary fracture design and reservoir properties
data, we could simulate fracture propagation and obtain frac-
ture length, width and height, which directly aﬀect production.
This should improve the predictive power of our models.

Acknowledgements

The authors are grateful

to the management of LLC
“Gazpromneft-STC” for organizational and ﬁnancial sup-
The authors are particularly grateful
port of this work.
to M.M. Khasanov, A.A. Pustovskikh, I.G. Fayzullin and
A.S. Margarit for organizational support of this initiative. The
help from P.K. Kabanova and A.R. Mukhametov in data gath-
ering is greatefully appreciated.

We are grateful to the management of the DATADVANCE
company, namely, to S.M. Morozov, and to the engineers of
the company, A. Saratov and Yu. Bogdanova, for the scientiﬁc
support with Surrogate Based Optimization methods from the
pSeven Core Suite, a product of DATADVANCE.

We would like to state it explicitly that the models presented
in this work are solely based on the ﬁeld data provided by JSC
Gazpromneft and we are grateful for the permission to publish.

References

[1] A. D. Morozov, D. O. Popkov, V. M. Duplyakov, R. F. Mutalova, A. A.
Osiptsov, A. L. Vainshtein, E. V. Burnaev, E. V. Shel, G. V. Paderin,
Data-driven model for hydraulic fracturing design optimization: Focus
on building digital database and production forecast, Journal of Petroleum
Science and Engineering 194 (2020) 107504.

[2] A. Azbukhanov, I. Kostrigin, K. Bondarenko, M. Semenova, I. Sereda,
D. Yulmukhametov, et al., Selection of wells for hydraulic fracturing
based on mathematical modeling using machine learning methods (rus-
sian), Oil Industry Journal 2019 (11) (2019) 38–42.

[3] L. Xue, Y. Liu, Y. Xiong, Y. Liu, X. Cui, G. Lei, A data-driven shale gas
production forecasting method based on the multi-objective random forest
regression, Journal of Petroleum Science and Engineering 196 107801.

[4] A. Davtyan, A. Rodin, I. Muchnik, A. Romashkin, Oil production forecast
models based on sliding window regression, Journal of Petroleum Science
and Engineering 195 (2020) 107916.

[5] J. Yao, Z. Li, L. Liu, W. Fan, M. Zhang, K. Zhang, Optimization of frac-
turing parameters by modiﬁed variable-length particle-swarm optimiza-
tion in shale-gas reservoir, SPE Journal (2021) 1–18.

[6] I. Sobol, Global sensitivity indices for nonlinear mathematical models and
their Monte Carlo estimates, Mathematics and Computers in Simulation
doi:10.1016/S0378-4754(00)00270-6.

[7] Lundberg, Scott M., and Su-In Lee, A uniﬁed approach to interpreting
model predictions, Advances in Neural Information Processing Systems.
[8] L. S. Shapley, A value for n-person games, Contributions to the Theory

of Games 2 (28) (1953) 307–317.

[9] E. Song, B. L. Nelson, J. Staum, Shapley eﬀects for global sensitivity
analysis: Theory and computation, SIAM/ASA Journal on Uncertainty
Quantiﬁcation 4 (1) (2016) 1060–1083.

[10] A. Erofeev, D. Orlov, D. Perets, D. Koroteev, AI-Based Estimation of
Hydraulic Fracturing Eﬀect, SPE Journal doi:10.2118/205479-PA.
[11] Stephan Kolassa and Wolfgang Sch¨utz, Advantages of the MAD/Mean
Ratio over the MAPE, Foresight: The International Journal of Applied
Forecasting (6) (2007) 40–43.

[12] R. E. Bellman, S. E. Dreyfus, Applied dynamic programming, Vol. 2050,

Princeton university press, 2015.

[13] Z. Fu, G. Liu, L. Guo, Sequential Quadratic Programming Method for
Nonlinear Least Squares Estimation and Its Application, Mathematical
Problems in Engineering 2019 (2019) 1–8. doi:10.1155/2019/3087949.

[14] M. R. Bonyadi, Z. Michalewicz, Particle swarm optimization for single
objective continuous space problems: A review, Evolutionary Computa-
tion 25 (1) (2017) 1–54. doi:10.1162/EVCO r 00180.

10

[15] R. Storn, K. Price, Diﬀerential evolution - a simple and eﬃcient heuristic
for global optimization over continuous spaces, Journal of Global Opti-
mization 11 (1997) 341–359. doi:10.1023/A:1008202821328.

[16] A. S. Mohaghegh S, Balan B, A hybrid, neuro-genetic approach to hy-

draulic fracture treatment design and optimization.

[17] E. T. Woldemariam, H. G. Lemu, A machine learning based framework
for model approximation followed by design optimization for expensive
numerical simulation-based optimization problems, in: Proceedings of
the Twenty-ninth International Ocean and Polar Engineering Conference
www.isope.org Honolulu, Hawaii, USA, June 16-21, International Soci-
ety of Oﬀshore and Polar Engineers (ISOPE), 2019.

[18] S. Wang, S. Chen, Insights to fracture stimulation design in uncon-
ventional reservoirs based on machine learning modeling, Journal of
Petroleum Science and Engineering.

[19] J. Shi, J. Song, B. Song, W. F. Lu, Multi-objective optimization design
through machine learning for drop-on-demand bioprinting, Engineering
5 (3) (2019) 586 – 593. doi:https://doi.org/10.1016/j.eng.2018.12.009.
[20] M. Kaya, S. Hajimirza, Using a novel transfer learning method for de-
signing thin ﬁlm solar cells with enhanced quantum eﬃciencies, Nature.
[21] M. Belyaev, E. Burnaev, E. Kapushev, M. Panov, P. Prikhodko, D. Vetrov,
D. Yarotsky, Gtapprox: Surrogate modeling for industrial design, Ad-
vances in Engineering Software 102 (2016) 29 – 39.

[22] DATADVANCE© pSeven, Release 6.20, User Manual, 2021.
URL https://www.datadvance.net/product/pseven/

[23] E. Burnaev, M. Panov, Adaptive design of experiments based on gaussian
processes, in: A. Gammerman, V. Vovk, H. Papadopoulos (Eds.), Statisti-
cal Learning and Data Sciences, Springer International Publishing, Cham,
2015, pp. 116–125.

[24] E. Burnaev, M. Panov, A. Zaytsev, Regression on the basis of nonstation-
ary gaussian processes with bayesian regularization, Journal of Commu-
nications Technology and Electronics 61 (6) (2016) 661–671.

[25] A. Zaytsev, E. Burnaev, Large scale variable ﬁdelity surrogate modeling,
Annals of Mathematics and Artiﬁcial Intelligence 81 (1) (2017) 167–186.
[26] E. Burnaev, A. Zaytsev, Surrogate modeling of multiﬁdelity data for large
samples, Journal of Communications Technology and Electronics 60 (12)
(2015) 1348–1355.

11

Appendix

Figure 17: CatBoost (green) vs Stacked (Ridge+CatBoost) dependences

Figure 18: Example of oﬀset wells selection

12

Figure 19: Real vs Predicted production on the real design

Figure 20: Production increase with optimal parameters set

Figure 21: Optimized production comparison between methods

13

