0
2
0
2

l
u
J

4
1

]

G
L
.
s
c
[

1
v
6
7
7
6
0
.
7
0
0
2
:
v
i
X
r
a

Veriﬁcation of ML Systems via Reparameterization

Jean-Baptiste Tristan
Oracle Labs

Joseph Tassarotti
Boston College

Koundinya Vajjha
University of Pittsburgh

Michael L. Wick
Oracle Labs

Anindya Banerjee
IMDEA Software Institute

Abstract

As machine learning is increasingly used in essential systems, it is important to
reduce or eliminate the incidence of serious bugs. A growing body of research
has developed machine learning algorithms with formal guarantees about per-
formance, robustness, or fairness. Yet, the analysis of these algorithms is often
complex, and implementing such systems in practice introduces room for error.
Proof assistants can be used to formally verify machine learning systems by con-
structing machine checked proofs of correctness that rule out such bugs. However,
reasoning about probabilistic claims inside of a proof assistant remains challeng-
ing. We show how a probabilistic program can be automatically represented in
a theorem prover using the concept of reparameterization, and how some of the
tedious proofs of measurability can be generated automatically from the proba-
bilistic program. To demonstrate that this approach is broad enough to handle
rather different types of machine learning systems, we verify both a classic result
from statistical learning theory (PAC-learnability of decision stumps) and prove
that the null model used in a Bayesian hypothesis test satisﬁes a fairness criterion
called demographic parity.

1 Introduction

A machine learning application can fail for many reasons: maybe the training data is insufﬁcient,
maybe there is a ﬂaw in the design of the learning algorithm, or maybe there is an error in the
implementation of the algorithm. Such errors can go unnoticed for long periods of time. This is
particularly worrisome for machine learning applications that, for example, process loan requests or
suggest hiring recommendations.

Thorough testing is one way to help catch such errors. But testing ML applications is challenging
because of their random behavior. Many iterations may be needed to encounter a bug or detect a
statistical irregularity in behavior. And when it comes to adversarial or safety critical scenarios, no
amount of testing may be enough to make a system trustworthy. Moreover, while there has been
much work on developing algorithms that are provably robust or fair, bugs in implementations of
these algorithms may render these guarantees meaningless.

One way to eliminate these kinds of errors is to formally verify a machine learning system with
a machine checked proof of correctness. A formal proof is one in which every step and logical
inference is checked. The computer programs that help write and check such proofs are called proof
assistants. Proof assistants provide a language to express programs and mathematical proofs in
some logic. In recent years, it has become feasible to use proof assistants to verify large, realistic
software systems, including compilers [24], cryptographic primitives [12], ﬁle systems [7], and
microkernels [23].

Preprint.

 
 
 
 
 
 
def majority():

theta = uniform(0, 1)
X = bernoulli(theta)
return (theta, X)

def majority_fun u :=
let u1 := u.fst in
let u2 := u.snd in
let theta := gen_uniform(0,1,u1) in
let X := gen_bernoulli(theta,u2) in
(theta,X)

(a) Python program

def majority :=

push_forward majority_fun pair_uniform(0,1)

(b) Reparameterization in Lean

Figure 1: Demonstration of our automatic reparameterization translation to represent programs in
the proof assistant. Instead of drawing samples, majority_fun takes a pre-sampled pair u of uni-
form [0, 1] variates. The expressions u.fst and u.snd are the ﬁrst and second projections of the
pair.

In principle, proof assistants are expressive enough to represent the mathematics underlying ML
systems and check proofs of their correctness. But in practice, formally verifying ML systems
remains challenging. Prior work has begun to develop formal proofs of correctness for machine
learning software [28, 2]. Although these early results are impressive, representing machine learning
programs and their correctness statements inside a proof assistant remains a major challenge. Proof
assistants only have built-in support for representing “pure” mathematical functions. The approach
taken in the aforementioned works is to deﬁne, within the proof assistant, a small domain-speciﬁc
programming language that has commands for drawing random samples from distributions.

While this approach is feasible, it becomes challenging to use, particularly when reasoning about
samples from continuous probability distributions. In particular, the way past work represents such
programs in the proof assistant is rather different from the way ML researchers usually think about
things in pencil-and-paper proofs.

We propose using an alternative representation that more closely matches the familiar style of paper
proofs. Our approach is to automatically reparameterize parts of a probabilistic program so that
it can be written as a pure, non-randomized, functional program operating over a pre-sampled list
of random inputs. This simpliﬁes reasoning about the resulting program and avoids the foregoing
difﬁculties. We have implemented an automatic translation to perform this reparameterization, so
that we can convert programs from a probabilistic programming language based on Pyro [5] into
input to the theorem prover.

A simple example of our translation is shown in Figure 1. On the left is a Python program that
samples from two distributions and returns a pair as result. On the right is our reparameterized
version of this program in the Lean proof assistant. Background on Lean follows, but for now,
the important point is that in the translation, majority_fun takes as input an argument u that
represents a pair of uniform [0, 1] samples. Then instead of sampling, it uses the inverse CDF
transform to convert the input u into the distributions it needs. Finally, we deﬁne the distribution
represented by this program by taking the pushforward of the input distribution through the function
majority_fun.

To demonstrate our approach, we have veriﬁed two case studies. The ﬁrst is a proof that the class of
decision stumps is PAC-learnable [6], a classic introductory result that appears in many textbooks
on computational learning theory. Formalizing this proof revealed errors and many omitted details
found in several expository accounts of this result. Our second case-study is a proof that a null model
used in a Bayesian hypothesis test, implemented in a probabilistic programming language, correctly
satisﬁes a fairness criterion called demographic parity. The source code for our case studies and
translator are publicly available.1

1https://github.com/jtristan/FormalML

2

2 A Short Introduction to Lean

The Lean theorem prover can be viewed as both a functional programming language (like Haskell)
and a foundation for mathematics, based on dependent type theory. Dependent type theories are an
alternative to Zermelo-Frankel set theory where types are associated with mathematical expressions,
in the same way that types can be used in programming languages, but with much stronger guaran-
tees. Before we introduce the concept of dependent types, it is useful to consider a simple example
of mathematical formalization in Lean.

Using Lean as a programming language, we can deﬁne a function double that takes a natural
number as input and multiplies it by 2.

def double(n: nat): nat := 2 * n
This deﬁnition is similar to what one would ﬁnd in any modern functional programming language.
However, there is one signiﬁcant difference between programming in Lean and those languages: in
order to ensure that Lean is a consistent foundation for mathematics, functions cannot have side
effects (printing on the screen, reading a ﬁle) and they must be proven to always terminate. Next,
we can deﬁne a predicate that formalizes the concept of an even number.

def isEven(n: nat): Prop := exists k: nat, n = 2 * k
This example clearly shows how Lean differs from a programming language. The function we deﬁne
does not return simple data like a number or string, but instead a logical proposition that states that
a natural number n is even if there exists a natural number k such that n = 2 ∗ k.

Proofs with tactics: Finally, Lean lets us specify mathematical properties and prove them. For
example, the following states and proves a lemma called doubleIsEven that says that the result of
double is always even:

lemma doubleIsEven: forall n: nat, isEven (double (n)) :=
begin

intros, unfold isEven, unfold double, existsi n, trivial,

end
The ﬁrst line is the mathematical statement we wish to prove. What follows the “:=” and enclosed
by the keywords “begin” and “end” is a set of commands, called tactics, that describes the proof
in a manner that Lean can check. The programmer constructs this tactic proof interactively: their
IDE displays a list of current assumptions and what remains to be proved. This is represented by
a sequent, which is a tuple of the form Γ ⊢ φ, where Γ is the list of hypotheses and variables
(called the context) and φ is a proposition (called the target). When the proof starts, the sequent
is ∅ ⊢ ∀n : N, isEven(double(n)). Executing the tactic “intros” transforms the sequent into
n : N ⊢ isEven(double(n)) where n is now a ﬁxed but arbitrary natural number. Executing the
tactic “unfold” applied to isEven unfolds the deﬁnition of isEven to give the sequent n : N ⊢
∃k : N, double(n) = 2 ∗ k. Likewise, by unfolding double, we obtain the sequent n : N ⊢
∃k : N, 2 ∗ n = 2 ∗ k. Now we must exhibit a choice for k that satisﬁes the property, for which
we can use the tactic “existi” applied to n, which appears in the context. This gives the sequent
n : N ⊢ 2 ∗ n = 2 ∗ n to which we can apply the “trivial” tactic that ensures that a basic axiom
(namely, that equality is reﬂexive) has been reached.

mathlib library: The mathlib library is a large library of mathematical results formalized in
Lean [31]. In particular, it contains a formalization of measure theory, based on Hölzl and Heller
[16]’s library from the Isabelle theorem prover. Unfortunately, mathlib does not a have a probabil-
ity theory library, and in order to formalize our results, we had to develop one, as a special case of
measure theory. This development accounts for about 2,500 lines of Lean formalization.

Proof by reduction: An important feature of Lean that makes proofs easier is that the proof checker
can automatically execute or reduce parts of programs. For example, suppose at some point we need
to show that the boolean expression (a and false) or (false and b) is always false. In-
stead of using lemmas for the basic rules of boolean algebra, we can instruct Lean to case split on
all the possible values for a and b, evaluate the expression, and then check that all cases reduce to
false. Of course, not all deﬁnitions can be executed or simpliﬁed this way. For example, if we
have a proof involving the Lesbesgue integral from mathlib, we cannot expect Lean to symboli-
cally compute the solution to an arbitrary deﬁnite integral. Deﬁnitions like the integral are marked
noncomputable in Lean, which means they will not be executed.

3

3 Denotational Semantics of Programs

With the probability theory library deﬁned, we next need a way to write down learning algorithms
and probabilistic programs in Lean, so that we can state and prove theorems about them, much as we
did with double above. However, by default, all functions in Lean have to be purely functional (that
is, they have to behave like mathematical functions, with deterministic output and no side-effects).

For that reason, past work on verifying machine learning algorithms has used a denotational se-
mantics in which programs are represented as distributions over the types of values they can return.
Given a type X, we write Meas(X) for this type of probability distributions on X. The ﬁrst step
is to deﬁne the primitive distributions that our programs will need to sample from. Next we need a
way to sequence together multiple steps of sampling and running computations on sampled values.
To do so, we can deﬁne a function called bind of type Meas(X) → (X → Meas(Y )) → Meas(Y ).
That is, bind takes a probability measure on X and a function that transforms values from X into
probability measures over Y , and returns a probability measure on Y . Intuitively, we should read
bind(µ, f) as representing a program which ﬁrst samples from the distribution µ and then passes
the result to f . It is common to use the notation do x ← µ ; g(x) for bind(µ, g), which helps
reinforce the intuition that bind samples from µ and then runs g. We also deﬁne a function ret of
type X → Meas(X). It takes a value from X and returns a probability measure on X.
Functions bind and ret construct probability measures, so their deﬁnitions say what probability
they assign to an event. If A is an event we deﬁne them as:

bind(µ, f )(A) =

f (x)(A)dµ

Zx∈X
ret(x)(A) = χA(x)

(1)

(2)

While the deﬁnitions use standard mathematical notation, our formalization uses the Lean deﬁnition
of the Lebesgue integral, and so on. Here, ret(x) is the δ-Dirac distribution at x. To understand
the deﬁnition of bind, consider the following example. Let µ be a distribution over X and consider
the random variables U ∼ µ and V ∼ f (U ). For example, f could be the function that for an input
l returns the distribution N (l, 0.1). What is the distribution of V ? By the sum rule of probability
u∈X f (u)(A)dµ.
we have Pr(V = v) =
R
Hence, bind(µ, f ) is simply computing the distribution that results from applying f while marginal-
izing over µ.

u∈X Pr(V = v | U = u)dµ. Therefore, Pr(V )(A) =

R

Example. Consider the Python function from the introduction in Figure 1a. The translation of this
program into Lean as we have so far described is:

def majority1 :=

do theta ← uniform(0, 1) ;
do X ← bernoulli(theta) ;
ret (theta, X)

The notation makes this look almost the same as the Python program that we started with. However,
in the Lean code, the “function” actually evaluates to a nested integral representing the distribution
that this procedure encodes. Similarly, in Lean, uniform and bernoulli are not random number
generators, but deﬁnitions of those distributions in terms of their CDF. These bind and ret opera-
tions are an example of a monad. Monads are commonly used in functional languages like Haskell
to represent programs that have side-effects. This probability monad was deﬁned by Giry [13].

The Giry monad representation has some advantages. As we have seen, the denotation of a program
has a structure that mimicks the original source code. However, there are drawbacks when we try
to reason about programs expressed this way, particularly when we want to avoid using axioms or
making restrictions to discrete spaces. First, recall from section 2 that proof by reduction is blocked
when we work with noncomputable deﬁnitions like integrals. Because the Giry monad includes an
integral every time we use bind, Lean cannot reduce such programs very much at all. Second, in
our experience, this monadic semantics is unfamiliar to ML experts, and doesn’t correspond closely
to the style used on paper proofs. In the next section, we describe our approach for alleviating these
issues.

4

4 Reparameterizing to Simplify Semantics

How can we ﬁnd a denotational semantics that would make it easier to reason formally about a
learning or randomized algorithm and avoid the issues with the Giry monad described above? Recall
that a classic result in probability theory is that any distribution on the reals with the Borel sigma
algebra can be constructed as the pushforward of the uniform distribution on [0, 1], which we write
as U. That is, for any distribution µ, there exists a (measurable) function f such that for any event E

µ(E) = L[f −1

(E)]

(3)

Indeed, a more general version of this result is an important lemma in proving the Kolmogorov
Extension Theorem, which is used to show the existence of many stochastic processes.

This fact hints at an alternate denotation for our programs: we could represent a program as some
pure function f , applied to samples from U. That is, we would take the pushforward measure of f
applied to an appropriate input distribution. Because f will be pure, Lean will be able to evaluate it,
enabling us to use proof by reduction. Moreover, once we prove that f is a measurable function, we
can avoid most measure-theoretic issues in the proof. Of course, the theorem above suggests that f
will exist in principle, but we still need a way to construct the function f in a useful form.

In order to help explain how we ﬁnd a simple representation of f , we ﬁrst observe that such a
function f is a reparameterization of the original program. A reparameterization is a transformation
of a probabilistic model that changes how a variable is sampled, often by sampling an additional
variable from an alternate distribution and transforming the result. For example, if X is a random
variable with distribution N (3, 4), we can reparameterize X to deﬁne it as X = 2Z + 3 where Z
is a draw from the standard normal distribution. Reparameterization has many other applications in
ML. For example, it can improve the convergence of MCMC algorithms [14], and enable the use of
stochastic gradient descent in Variational Auto Encoders [22].

We now describe the steps to compute the reparameterization of functions in our setting. We have
implemented this translation for a small probabilistic programming language implemented on top
of Pyro. However, to keep things self-contained, we will explain how the translation works us-
ing simple Python programs, without dynamic looping or recursion. Our majority function from
Figure 1a will serve as a running example.

Transforming primitive distributions: First we extend the probability theory library in Lean to
include reparameterized deﬁnitions of all the primitive distributions that our programs can sample
from. For example, gen_uniform(a, b, u) generates a uniform random variate on the interval
[a, b] by scaling the input u, which is assumed to be a uniform sample from [0, 1]. More generally,
we can implement the inverse CDF transform to convert a sample from the uniform distribution on
[0, 1] into the appropriate distribution.

These primitive translations are added to a dictionary that tracks their input and output types, which
in particular records how many uniform inputs they need. As we translate a function, we replace
sampling from primitive distributions with these translations, and record how many total uniform
samples will be needed. Then, an argument u is added that is a vector of all of the uniform samples
that will be needed. We write u1, u2, u3 etc. for the components of this vector. These are deﬁned
using Lean’s primitive operations fst and snd for extracting the ﬁrst and second element of a pair.

Slicing and Coupling: Next, for each return value of the function, we compute a slice, which
is the subset of expressions in the function that determine that return value. For example, in the
majority example from Figure 1a, there are two return values, theta and X. The slice for theta is
gen_uniform(0,1,u1), and the slice for X is gen_bernoulli(gen_uniform(0, 1, u1), u2).
Note that the re-use of u1 in both the computation of theta and X ensures that we properly capture
the dependence between these two random variables. In general, all dependencies between the vari-
able deﬁnitions are explicitly captured by which inputs are passed to which parameters, so that the
right joint distribution is obtained. Essentially, the inputs are being used to construct an appropriate
coupling [25] between the random variables encoded by the slices. We generate Lean deﬁnitions for
each slice, and then call these to compute each return value in the function. Now, we can perform
standard compiler optimization transforms, such as removing common sub-expressions, to simplify
the function.

Nested functions: After we complete the translation of majority, we can add an entry to the
dictionary of translations tracking its type. When translating a subsequent function g, if a call to

5

def demographic_parity():
[theta,X] = majority()
phi = uniform(0.8 * theta,1)
Y = bernoulli(phi)
return (theta,X,phi,Y)

def demographic_parity_fun u :=

let theta := u.fst.fst in
let X := u.fst.snd in
let u3 := u.snd.fst in
let u4 := u.snd.snd in
let phi := gen_uniform(0.8 * theta,1,u3) in
let Y := gen_bernoulli(phi,u4) in
((theta,X),(phi,Y))

(a) Python program

def demographic_parity :=

pushforward demographic_parity_fun

(prod_measure majority pair_uniform(0,1))

(b) Reparameterization in Lean

Figure 2: Lean translation with nested functions for a Bayesian hypothesis testing example.

majority is encountered in g, we can replace it with a call to the translation and add additional
uniform samples to the vector of inputs to g. Since the pre-translated version of majority takes no
arguments as input, it is also possible to hoist the call to majority out of the body of g, and instead
pass in the pre-sampled results of majority as an argument to g. Figure 2a shows an example,
where majority is called by demographic_parity. The transformed function takes as input both
a sample from majority and a pair of uniform samples, which it uses to generate phi and Y.

Automatic proof generation: In the course of generating the function f , we can also generate
proofs in Lean that the function f , and all the slices used to compute the return values, are measur-
able. To do so, we ﬁrst manually wrote proofs of measurability for all primitive operations in the
language, as well as the transformer functions for the primitive distributions, such as gen_uniform.
Then, using the fact that the composition of two measurable functions is measurable, these proofs for
primitive operations are composed to produce a proof that an entire function, such as majority_fun
is measurable. This proof can then be re-used if majority is called in another function.

Impact of reparameterization on proofs: Our motivation for deﬁning a semantics based on repara-
materization is to simplify formal proofs for learning and randomized algorithms. By embedding
programs as pure functions of random inputs, we make it possible to use Equation (3) to turn a prob-
abilistic statement on random variables into a statement on events, getting the heavy machinery of
measure-theoretic probability theory out of the way. At that point, reasoning about the program boils
down to reasoning about the set of inputs to the program that satisfy some properties, which is usu-
ally very basic, intuitive, and allows us to apply reduction to the function to simplify the reasoning.
We will see an example of this in Section 6.

Generality: A natural question is whether this kind of reparameterization translation can be applied
to more complex, general purpose programs. As we have mentioned, results from measure theory
suggest that in principle this can be performed on a large class of programs. But, for large programs
with complicated control ﬂow and looping, a naive reparameterization translation may make the
program harder to understand. However, even when reparameterization would be unnatural to apply
to the entire program, we believe that it can be useful to apply to subcomponents. For example,
consider a typical implementation of stochastic gradient descent, which is usually structured as a
loop. Within each iteration of the loop, training examples are randomly selected or ordered, and
then gradients and updates are computed. We can factor out and reparameterize the computation of
gradients to be pure functions. Then, use of the Giry monad would be limited to only the remaining
impure parts that glue together iterations of the loop. This way, we would obtain the advantages of
reparameterization for the bulk of the proof.

5 Case Study 1: Decision Stumps

For our ﬁrst case study, we prove in Lean that the concept class of decision stumps is PAC learn-
able. We focus here on how this algorithm is formulated in Lean. More complete details about the
classic pencil-and-paper proof and our formalization are found in an earlier report [30]. Recall that
a decision stump is a classiﬁer that assigns binary labels to real valued points based on whether they
are above or below some threshold value. Points above the threshold are labeled 0, and points ≤ are

6

labeled 1. We assume that there is some unknown distribution µ of examples that the classiﬁer will
have to label, and that the true labels of these examples are determined by some threshold t, which is
also unknown. Training such a classiﬁer is straightforward: we take the maximum of all the training
examples with label 1, and use that as our threshold.

To show that this decision class is PAC learnable, we must prove that for all ǫ, δ ∈ (0, 1), there
is some number n such that with n labeled training examples drawn independently from µ, this
training algorithm gives a stump that achieves error rate below ǫ with probability at least 1 − δ. This
is the one-dimensional version of the problem of learning an axis-aligned rectangle, which is used
as a motivating example and exercise in many introductory texts on learning theory [21, 29, 26].

We ﬁrst express the learning algorithm as a pure Lean function choose, which takes the training
data as a vector of examples, where each example is a pair consisting of the data point and its label.
The algorithm ﬁlters out the non-positive examples, removes the remaining labels, and takes the
maximum. The parameter n below tracks the number of examples in the vector data:

def filter n data := vec_map (λ p, if p.snd then p.fst else 0) n data
def choose n data := max n (filter n data)
The process of training on n can then be described as taking the n-ary product measure on the
input distribution µ, and then ﬁrst pushing-forward a function to assign the true labels, and then
pushing-forward the result with choose.

def denot :=

let η := vec.prob_measure n µ in
let ν := pushforward (label_sample target n) η in
pushforward (choose n) ν

Finally, to make claims about the error rate of this algorithm, we deﬁne an event error_set which
captures whether the label assigned by a classiﬁer h differs from the true label provided by the
unknown target. Finally, the error rate of a classiﬁer is the probability of this set under the
unknown distribution µ of test examples:
def error_set h := {x | label h x = label target x}
def error h := µ (error_set h target)
All of the randomization lies in the process of modeling the training examples as if they have been
sampled from some arbitrary training distribution. Because the training algorithm here is entirely
deterministic, we are able to write down this algorithm directly without using the automated repa-
rameterization we have described. Nevertheless, the experience of working with this formulation
of the algorithm convinced us of the beneﬁts of working with a pure function as much as possible,
which led us to automating reparameteriztion to handle examples such as the one we describe next.

6 Case Study 2: Bayesian Hypothesis Tests

In our next example, we prove a property of a null model used for a Bayesian hypothesis test. Recall
that in Bayesian hypothesis testing, we have models for how a data set may have been generated,
along with prior probabilities for those models. We use Bayes rule to update our probabilities of the
models and then select from among them [20]. In this case study, we consider the use of Bayesian
hypothesis testing to judge whether the output of a selection procedure satisﬁes a fairness property
called the four-ﬁfths rule, which is used as a criterion for disparate impact testing by the U.S. Equal
Employment Opportunity Commission [11]. In particular, the four-ﬁfths rule says that if the se-
lection rate for a protected class is less than 4/5 the rate for the majority group, then this can be
construed as evidence of violating legal standards for adverse impact.

In order to formulate a Bayesian hypothesis test for this criterion, the ﬁrst step is to write down a null
model that is supposed to satisfy the 4/5 test: that is, the selection rate is meant to be at least 4/5 the
majority rate. The demographic_parity example from Figure 2a is this null model. The selection
rate of the majority class is theta, and the selection rate of the minority class is phi. The model
is constructed so that phi is at least 4/5 · theta. Then, X and Y give the results of the selection
procedure on one member of the majority class and the minority class, respectively. A more general
version of this model might draw different numbers of samples from the two classes. By expressing
this model in a probabilistic programming language such as Pyro, and specifying a prior, we could
then compare the posterior probability, given some example data, to an alternative model.

7

Because the null model is supposed to represent a selection procedure that satisﬁes the 4/5 test,
it is important to prove that it in fact does. We use Lean to prove this. We want to show that
0.8 · Pr[X = 1] ≤ Pr[Y = 1]. This follows from conditioning on theta, so that it sufﬁces to show
that for all t ∈ [0, 1], we have 0.8 · Pr[X = 1|theta = t] ≤ Pr[Y = 1|theta = t].2

For the Lean version of the demographic parity model, this is formalized with the following events:

def B(t: [0,1]) := {v | v.fst.fst = t}
def majority_selected := {v | v.fst.snd = 1}
def minority_selected := {v | v.snd.snd = 1}
We can divide the proof into two steps. Consider a Bernoulli random variable Y’ with selection
rate 4/5 · theta, generated using the same u4 that is used to generate Y. First, we can show that
0.8 · Pr[X = 1|theta = t] ≤ Pr[Y’ = 1|theta = t]. This is simpler because having conditioned
on t, the selection rate of Y’ is deterministic.

Second, we show that Pr[Y’ = 1|theta = t] ≤ Pr[Y = 1|theta = t]. The key is that this part
of the proof can be entirely reduced to proving a pure fact about demographic_parity_fun. In
particular, because probabilities are monotone with respect to subset ordering, we just have to show
that the set of random inputs of the function demographic_parity_fun which cause Y’ = 1 is a
subset of the inputs that cause Y = 1. This is captured by the following Lean statement, where we
write f as an abbreviation for demographic_parity_fun:

∀ t≥0, set.prod {a: [0,1] × N | a.fst = t}

(set.prod [0,1] {a: [0,1] | generate_bernoulli(4/5 * t,a) = 1})

⊆ {a: ([0,1] × N) × [0,1] × [0,1] | (f a).snd.snd = 1 ∧ (f a).fst.fst = t}

7 Related Work

Measure-theory in proof assistants: There have been general formalizations of measure-theoretic
probability theory in a few proof assistants. Hurd [18] formalized basic measure theory in the HOL
proof assistant, including a proof of Caratheodory’s extension theorem. Hurd uses a semantics
that is closest to some of the ideas underlying our reparameterization approach, in that he models
randomized programs as having access to an inﬁnite “tape” of pre-sampled random bits. Hölzl and
Heller [16] developed a more substantial library in the Isabelle theorem prover. Avigad et al. [1] use
this library to formalize a proof of the Central Limit Theorem.

Machine-checked proofs for ML: We have already mentioned some more recent work that has
formalized machine learning results. Selsam et al. [28] use Lean to prove the correctness of an op-
timization procedure for stochastic computation graphs. They prove that the random gradients used
in their stochastic backpropagation implementation are unbiased. In their proof, they add axioms to
the system for various mathematical facts. They argue that even if there are errors in these axioms
that could potentially lead to inconsistency, the process of constructing formal proofs for the rest of
the algorithm still helps eliminate mistakes. Bagnall and Stewart [2] give machine-checked proofs
of bounds on generalization errors. They use Hoeffding’s inequality to obtain bounds when the hy-
pothesis space is ﬁnite or there is a separate test-set and apply this result to bound the generalization
error of neural networks with quantized weights. Their proof is restricted to discrete distributions
and adds some results as axioms (Pinsker’s inequality and Gibbs’ inequality). Bentkamp et al. [4]
formalize a result by Cohen et al. [9] which shows that deep convolutional arithmetic circuits are
more expressive than shallow ones. This result deals with what is deterministically representable by
these structures, so their proof does not require probability theory.

Semantics of probabilistic programs: The representation of programs in Lean in the Giry monad
is an example of denotational semantics [13], where the meaning of a program is given in terms of
a mathematical object (here, the distribution on the type of values it can return). We have already
alluded to some of the problems of using the Giry monad and our reparameterization transform on
programs with complicated control ﬂow or looping structure. Deﬁning denotational semantics for
probabilistic programs with arbitrary general recursion and higher-order functions is challenging,
and the subject of much recent research [15, 10].

2We use conditional probability notation to explain the argument. More precisely, we are using a disinte-
grating measure [8]. Because we are conditioning on the ﬁrst projection of the product measure that we are
pushing-forward, the existence of this disintegration is a result of Fubini’s theorem.

8

ML for automated theorem proving: A related but distinct line of work applies machine learning
techniques to automatically construct formal proofs of theorems. By using a pre-existing corpus
of formal proofs, supervised learning algorithms can be trained to select hypotheses and construct
proofs in a formal system [3, 17, 19, 27].

8 Conclusion

We present an approach to simplify reasoning about probabilistic programs in proof assistants. By
reparameterizing these programs to be pure functions of pre-sampled randomized input, we can
exploit more of the native automation and support for reasoning about pure functions found in many
proof assistants. Our case studies show that our approach can be applied to verify programs from a
diverse range of subﬁelds of ML.

References

[1] J. Avigad, J. Hölzl, and L. Seraﬁn. A formally veriﬁed proof of the Central Limit Theorem.

CoRR, abs/1405.7012, 2014. URL http://arxiv.org/abs/1405.7012.

[2] A. Bagnall and G. Stewart. Certifying the true error: Machine learning in Coq with veriﬁed
generalization guarantees. In AAAI’19: The Thirty-Third AAAI Conference on Artiﬁcial Intel-
ligence, 2019.

[3] K. Bansal, S. Loos, M. Rabe, C. Szegedy, and S. J. Wilcox. HOList: An environment for ma-
chine learning of higher order logic theorem proving. In Thirty-sixth International Conference
on Machine Learning (ICML), 2019.

[4] A. Bentkamp, J. C. Blanchette, and D. Klakow. A formal proof of the expressiveness of deep

learning. Journal of Automated Reasoning, 63(2):347–368, 2019.

[5] E. Bingham, J. P. Chen, M. Jankowiak, F. Obermeyer, N. Pradhan, T. Karaletsos,
Pyro: Deep universal proba-
Journal of Machine Learning Research, 20(28):1–6, 2019. URL

R. Singh, P. Szerlip, P. Horsfall, and N. D. Goodman.
bilistic programming.
http://jmlr.org/papers/v20/18-403.html.

[6] A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. Learnability and the Vapnik-

Chervonenkis dimension. Journal of the ACM (JACM), 36(4):929–965, 1989.

[7] T. Chajed, H. Chen, A. Chlipala, M. F. Kaashoek, N. Zeldovich, and D. Ziegler. Certifying a
ﬁle system using crash hoare logic: correctness in the presence of crashes. Commun. ACM, 60
(4):75–84, 2017. doi: 10.1145/3051092. URL https://doi.org/10.1145/3051092.
[8] J. T. Chang and D. Pollard. Conditioning as disintegration. Statistica Neerlandica, 51(3):

287–317, 1997.

[9] N. Cohen, O. Sharir, and A. Shashua.

On the expressive power of deep learn-
the 29th Conference on Learning The-
ing: A tensor analysis.
ory, COLT 2016, New York, USA, June 23-26, 2016, pages 698–728, 2016. URL
http://proceedings.mlr.press/v49/cohen16.html.

In Proceedings of

[10] T. Ehrhard, M. Pagani, and C. Tasson. Measurable cones and stable, measurable functions:
A model for probabilistic higher-order programming. Proc. ACM Program. Lang., 2(POPL),
Dec. 2017. doi: 10.1145/3158147. URL https://doi.org/10.1145/3158147.

[11] Equal Employment Opportunity Commission. Uniform Guidelines On Employee Selection

Procedures.

[12] A. Erbsen, J. Philipoom, J. Gross, R. Sloan, and A. Chlipala. Simple high-level code for
cryptographic arithmetic - with proofs, without compromises. In 2019 IEEE Symposium on
Security and Privacy, SP 2019, San Francisco, CA, USA, May 19-23, 2019, pages 1202–1219,
2019. doi: 10.1109/SP.2019.00005. URL https://doi.org/10.1109/SP.2019.00005.

[13] M. Giry. A categorical approach to probability theory. In B. Banaschewski, editor, Categorical
Aspects of Topology and Analysis, volume 915 of Lecture Notes in Mathematics, pages 68–85,
1982.

[14] M. I. Gorinova, D. Moore, and M. D. Hoffman. Automatic reparameterisation of probabilistic
programs. CoRR, abs/1906.03028, 2019. URL http://arxiv.org/abs/1906.03028.

9

[15] C. Heunen, O. Kammar, S. Staton, and H. Yang. A convenient category for higher-order
In Proceedings of the 32nd Annual ACM/IEEE Symposium on Logic in

probability theory.
Computer Science, LICS ’17. IEEE Press, 2017. ISBN 9781509030187.
[16] J. Hölzl and A. Heller. Three chapters of measure theory in Isabelle/HOL.

In ITP, pages

135–151, 2011.

[17] D. Huang, P. Dhariwal, D. Song, and I. Sutskever. Gamepad: A learning environment for
theorem proving. In 7th International Conference on Learning Representations, ICLR 2019,
New Orleans, LA, USA, May 6-9, 2019, 2019.

[18] J. Hurd. Formal Veriﬁcation of Probabilistic Algorithms. PhD thesis, Cambridge University,

May 2003.

[19] C. Kaliszyk, F. Chollet, and C. Szegedy. HolStep: A machine learning dataset for higher-
order logic theorem proving. In 5th International Conference on Learning Representations,
ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings, 2017. URL
https://openreview.net/forum?id=ryuxYmvel.

[20] R. E. Kass and A. E. Raftery. Bayes factors. Journal of the American Statistical Association,

90(430):773–795, 1995.

[21] M. J. Kearns and U. V. Vazirani. An introduction to computational learning theory. MIT press,

1994.

[22] D. P. Kingma and M. Welling. Auto-encoding variational bayes. In 2nd International Confer-
ence on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Confer-
ence Track Proceedings, 2014. URL http://arxiv.org/abs/1312.6114.

[23] G. Klein, J. Andronick, K. Elphinstone, G. Heiser, D. Cock, P. Derrin, D. Elkaduwe, K. Engel-
hardt, R. Kolanski, M. Norrish, T. Sewell, H. Tuch, and S. Winwood. sel4: formal veriﬁcation
of an operating-system kernel. Commun. ACM, 53(6):107–115, 2010.

[24] X. Leroy. Formal veriﬁcation of a realistic compiler. Communications of the ACM, 52(7):

107–115, 2009.

[25] T. Lindvall. Lectures on the Coupling Method. Dover Books on Mathematics Series. Dover

Publications, Incorporated, 2002. ISBN 9780486421452.

[26] M. Mohri, A. Rostamizadeh, and A. Talwalkar. Foundations of machine learning. MIT press,

2018.

[27] D. Selsam and N. Bjørner. Guiding high-performance SAT solvers with unsat-core predictions.
In Theory and Applications of Satisﬁability Testing - SAT 2019 - 22nd International Conference,
SAT 2019, Lisbon, Portugal, July 9-12, 2019, Proceedings, pages 336–353, 2019.

[28] D. Selsam, P. Liang, and D. Dill. Developing bug-free machine learning systems with formal

mathematics. In International Conference on Machine Learning (ICML), 2017.

[29] S. Shalev-Shwartz and S. Ben-David. Understanding machine learning: From theory to algo-

rithms. Cambridge University Press, 2014.

[30] J. Tassarotti, J.-B. Tristan, and K. Vajjha. A Formal Proof of PAC Learnability for Decision

Stumps. arXiv e-prints, art. arXiv:1911.00385, Nov. 2019.

[31] The mathlib Community. The lean mathematical library. In Proceedings of the 9th ACM SIG-
PLAN International Conference on Certiﬁed Programs and Proofs, CPP 2020, New Orleans,
LA, USA, January 20-21, 2020, pages 367–381, 2020. doi: 10.1145/3372885.3373824. URL
https://doi.org/10.1145/3372885.3373824.

10

