Smoothness Analysis for Probabilistic Programs
with Application to Optimised Variational Inference

2
2
0
2

g
u
A
2
2

]
L
P
.
s
c
[

1
v
0
3
5
0
1
.
8
0
2
2
:
v
i
X
r
a

WONYEOL LEE, Stanford University, USA
XAVIER RIVAL, INRIA Paris, ENS, and CNRS/PSL University, France
HONGSEOK YANG, KAIST, South Korea and Institute for Basic Science (IBS), South Korea

We present a static analysis for discovering differentiable or more generally smooth parts of a given probabilistic
program, and show how the analysis can be used to improve the pathwise gradient estimator, one of the most
popular methods for posterior inference and model learning. Our improvement increases the scope of the
estimator from differentiable models to non-differentiable ones without requiring manual intervention of
the user; the improved estimator automatically identifies differentiable parts of a given probabilistic program
using our static analysis, and applies the pathwise gradient estimator to the identified parts while using a
more general but less efficient estimator, called score estimator, for the rest of the program. Our analysis has a
surprisingly subtle soundness argument, partly due to the misbehaviours of some target smoothness properties
when viewed from the perspective of program analysis designers. For instance, some smoothness properties,
such as partial differentiability and partial continuity, are not preserved by function composition, and this makes
it difficult to analyse sequential composition soundly without heavily sacrificing precision. We formulate five
assumptions on a target smoothness property, prove the soundness of our analysis under those assumptions,
and show that our leading examples satisfy these assumptions. We also show that by using information from our
analysis instantiated for differentiability, our improved gradient estimator satisfies an important differentiability
requirement and thus, under a mild regularity condition, computes the correct estimate on average, i.e., it returns
an unbiased estimate. Our experiments with representative probabilistic programs in the Pyro language show
that our static analysis is capable of identifying smooth parts of those programs accurately, and making our
improved pathwise gradient estimator exploit all the opportunities for high performance in those programs.

Additional Key Words and Phrases: smoothness, static analysis, probabilistic programming, variational inference

1 INTRODUCTION
Probabilistic programs define models from machine learning and statistics, and are used to analyse
datasets from a wide range of applications [2, 4, 13â€“16, 26â€“28, 36, 38â€“41, 48]. These programs are
written in languages with special runtimes, called inference engines, which can be used to answer
probabilistic queries, such as posterior inference and marginal likelihood estimation, or to learn
model parameters in those programs, such as weights of neural networks. Whether a probabilistic
program is useful for, for instance, discovering a hidden pattern in a given dataset or making an
accurate prediction largely lies in these inference engines. These engines should compute accurate
approximations or good model parameters within a fixed time budget. It is, thus, not surprising
that substantial research efforts have been made to develop efficient inference algorithms and their
implementations (as inference engines) [5, 19, 22, 26, 30, 34, 37, 43, 45â€“47, 50].

We are concerned with smoothness1 properties of probabilistic programs, which have been ex-
ploited by performant posterior-inference and model-learning algorithms and engines. For instance,

1In mathematics, â€œsmoothnessâ€ typically refers to the specific property of functions: being infinitely differentiable. In this
paper, we override the term to denote a set of properties of functions describing well-behavedness (e.g., differentiability).

Authorsâ€™ addresses: Wonyeol Lee, Computer Science, Stanford University, USA, wonyeol@cs.stanford.edu; Xavier Rival,
INRIA Paris, ENS, and CNRS/PSL University, France, rival@di.ens.fr; Hongseok Yang, School of Computing and Kim Jaechul
Graduate School of AI, KAIST, South Korea, hongseok.yang@kaist.ac.kr, Discrete Mathematics Group, Institute for Basic
Science (IBS), South Korea.

2022. 2475-1421/2022/8-ART0 $15.00
https://doi.org/

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

 
 
 
 
 
 
0:2

Wonyeol Lee, Xavier Rival, and Hongseok Yang

when probabilistic programs are differentiable (in the sense that they define differentiable unnor-
malised densities), their posteriors can be inferred by Hamiltonian Monte Carlo [29], one of the best
performing MCMC algorithms. Also, in that case, their posteriors and model parameters can be
inferred or learnt using the pathwise gradient estimator [21, 33], a popular technique for estimating
the gradient of a function using samples. We also point out that the need for smoothness arises in a
broader context of machine learning and computer science; Lipschitz continuity is one of the desired
or at least recommended properties for neural networks [1, 20], and also differentiability commonly
features as a requirement for pieces of code inside simulation software and cyber physical systems,
where differential equations are used to specify the environment [31].

We present a static analysis that enables optimised posterior inference and model learning for
probabilistic programs. We develop a static analysis that discovers differentiable or more generally
smooth parts of given probabilistic programs, and show how the analysis can be used to improve the
pathwise gradient estimator. Our improvement increases the scope of the estimator from differen-
tiable to non-differentiable models, without requiring any intervention from the user; the improved
estimator automatically identifies differentiable parts of probabilistic programs using our static
analysis, and applies the pathwise gradient estimator to the identified parts while using a more
general but less efficient estimator, called score estimator [32, 44], for the rest of the programs.

Our static analysis for smoothness has a surprisingly subtle soundness argument, partly due to the
misbehaviours of some target smoothness properties when viewed from the perspective of program
analysis designers. For instance, some smoothness properties, such as partial differentiability and
partial continuity, are not preserved by function composition, and this makes it difficult to analyse
sequential composition soundly without heavily sacrificing precision. In fact, overlooking such
misbehaviours has been a source of errors in published static analyses for continuity [6, 7].2 We
formulate five assumptions that clearly identify what a smoothness property should satisfy in order
to avoid unsound analysis. Interestingly, these assumptions also determine what the property is
allowed to violate. For instance, they reveal that the smoothness property does not have to be closed
under the limits of chains of smooth (partial) functions, although the closure under such limits, called
admissibility, has often been used to justify proof rules about or static analysis of loops. Dispensing
with the admissibility requirement broadens the scope of our program analysis non-trivially; some
useful smoothness properties from mathematics fail to meet the requirement.

Our variant of the pathwise gradient estimator works by program transformation and non-standard
execution. It first transforms given probabilistic programs based on the results of our static analysis,
and then executes the transformed (and original) programs according to a standard (and non-standard)
semantics. During execution, our estimator computes a quantity involving differentiation, which
becomes the estimate of the target gradient. We prove that our estimator satisfies an important differ-
entiability requirement and thus is correct (under a mild regularity condition): the computed estimate
is unbiased, i.e., it is the target gradient when averaged over random choices made during execution.
Our static analysis and variant of the pathwise gradient estimator have been implemented for a
subset of the Pyro probabilistic programming language [2]. They have been successfully applied to
the 13 representative Pyro examples, which include advanced models with deep neural networks,
such as attend-infer-repeat [12] and single-cell annotation using variational inference [49]. For each
of these examples, Pyro provides a default, selective use of the pathwise gradient estimator but

2 The analysis in [6] infers the continuity property for multivariate programs, but it incorrectly joins two input-variable sets if
a program is continuous with respect to each set jointly. Such a rule would hold if separate per-input-variable continuity were
considered, but it does not hold for multivariate joint continuity. Conversely, the analysis in [7] considers a per-input-variable
definition of continuity, but incorrectly assumes that this per-input-variable continuity is preserved by function composition.
See Â§A.1 for more details. We do not claim that these unsoundness issues are hard to fix. Instead, our point is that a similar
issue may be introduced easily and remain undetected due to the subtlety in the soundness of a static analysis.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:3

ğ‘ğ‘š =

ğ‘¥1 := sam("z1", distN (0, 5), ğœ†ğ‘¦.ğ‘¦);
ğ‘¥2 := sam("z2", distN (ğ‘¥1, 3), ğœ†ğ‘¦.ğ‘¦);
if (ğ‘¥2 > 0) {obs(distN (1, 1), 0)}
{obs(distN (âˆ’2, 1), 0)}
else

(cid:170)
(cid:174)
(cid:174)
(cid:174)
(cid:174)
(cid:172)

(cid:169)
(cid:173)
(cid:173)
(cid:173)
(cid:173)
(cid:171)

,

ğ‘ğ‘” =

(cid:18) ğ‘¥1 := sam("z1", distN (ğœƒ1, 1), ğœ†ğ‘¦.ğ‘¦);
ğ‘¥2 := sam("z2", distN (ğœƒ2, 1), ğœ†ğ‘¦.ğ‘¦)

(cid:19)

.

Fig. 1. A model ğ‘ğ‘š and a guide ğ‘ğ‘” in a PPL. Here distN (ğ‘, ğ‘) is the distribution expression, and denotes the
normal distribution with mean ğ‘ and variance ğ‘.

ğ‘ â€²
ğ‘” =

(cid:32) ğ‘¥1 := sam("z1", distN (0, 1) , ğœ†ğ‘¦.ğ‘¦ + ğœƒ1 );
ğ‘¥2 := sam("z2", distN (0, 1) , ğœ†ğ‘¦.ğ‘¦ + ğœƒ2 )

(cid:33)

,

ğ‘ â€²â€²
ğ‘” =

(cid:32) ğ‘¥1 := sam("z1", distN (0, 1) , ğœ†ğ‘¦.ğ‘¦ + ğœƒ1 );
ğ‘¥2 := sam("z2", distN (ğœƒ2, 1), ğœ†ğ‘¦.ğ‘¦)
ğ‘” (or ğ‘ â€²â€²
ğ‘” ).

(cid:33)

.

Fig. 2. A fully (or selectively) reparameterised guide ğ‘ â€²

without any correctness guarantee. Our analysis and improved estimator automatically reproduced
those uses, and proved their correctness (assuming a mild regularity condition), more specifically,
the unbiasedness of the estimator in those use cases.

2 INFORMAL DESCRIPTION OF BASIC CONCEPTS AND OUR APPROACH
We start by describing informally basic concepts and the goal of our approach, which we hope helps
the reader to see the big picture of our technical contributions. To simplify presentation, we use toy
examples in the section. But we emphasise that our approach has been applied to representative
Pyro programs that describe advanced machine-learning models with deep neural networks.

Probabilistic programming and variational inference. In a probabilistic programming lan-
guage (PPL), a program expresses a probabilistic model. As an example, consider the program ğ‘ğ‘š
in Fig. 1, which describes a probabilistic model of the random variables ğ‘§1 and ğ‘§2 in R by specifying
their unnormalised density

ğ‘ğ‘ğ‘š (ğ‘§1, ğ‘§2) = N (ğ‘§1; 0, 5) Â· N (ğ‘§2; ğ‘§1, 3) Â· (1[ğ‘§2>0] Â· N (0; 1, 1) + 1[ğ‘§2 â‰¤0] Â· N (0; âˆ’2, 1)),
where N (ğ‘¥; ğ‘, ğ‘) is the probability density of a normal distribution with mean ğ‘ and variance ğ‘, and
1[ğœ‘ ] is the indicator function that returns 1 if ğœ‘ holds and 0 otherwise. The first two N factors in
the equation come from the sample commands (sam) in ğ‘ğ‘š. They are called prior distributions, and
describe prior knowledge on two random variables named ğ‘§1 and ğ‘§2. The last factor comes from the
if and observe commands (if and obs), which express that an unnamed random variable is sampled
and observed to have 0 and its distribution is distN(1, 1) or distN(âˆ’2, 1) depending on whether ğ‘§2
is positive or not. This factor is called likelihood, and it states information about ğ‘§1 and ğ‘§2 that comes
from an observed data point 0. Ignore the third arguments of the sample commands of ğ‘ğ‘š for now,
which have no effect on ğ‘ğ‘ğ‘š ; they will be explained later.

The purpose of writing ğ‘ğ‘š in a PPL, called model, is to infer its normalised probability density

ğ‘ğ‘ğ‘š (ğ‘§1, ğ‘§2) â‰œ ğ‘ğ‘ğ‘š (ğ‘§1, ğ‘§2)/

âˆ«

ğ‘ğ‘ğ‘š (ğ‘§1, ğ‘§2) ğ‘‘ğ‘§1ğ‘‘ğ‘§2,

also called normalised posterior density. Intuitively, this normalised density brings together two
types of information about ğ‘§1 and ğ‘§2, the first from their prior distributions (expressed in the first
and second lines of ğ‘ğ‘š), and the second from the observed data point 0 that depends on ğ‘§1 and ğ‘§2
(the third and fourth lines of ğ‘ğ‘š). This inference task is called posterior inference problem. Among
a wide range of approaches to the problem, we focus on the approach called variational inference,
which forms the core of the recent combination of PPLs and deep learning.

In variational inference, we posit another program ğ‘ğ‘”, called guide, that is simpler than ğ‘ğ‘š and
parameterised by ğœƒ . Then, we approximate the normalised density of ğ‘ğ‘š by ğ‘ğ‘” with an optimal

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:4

Wonyeol Lee, Xavier Rival, and Hongseok Yang

choice of ğœƒ . For instance, consider the program ğ‘ğ‘” in Fig. 1. The program specifies the following
already-normalised probability density

ğ‘ğ‘ğ‘”,ğœƒ (ğ‘§1, ğ‘§2) = N (ğ‘§1; ğœƒ1, 1) Â· N (ğ‘§2; ğœƒ2, 1).

It can serve as a guide program for ğ‘ğ‘ğ‘š
by ğ‘ğ‘ğ‘”,ğœƒ , variational inference aims
. To best approximate ğ‘ğ‘ğ‘š
at finding ğœƒ that minimises some notion of the discrepancy (called KL divergence) between ğ‘ğ‘ğ‘”,ğœƒ and
, or equivalently that maximises the objective function L (called evidence lower bound):
ğ‘ğ‘ğ‘š

arg max

ğœƒ

L (ğœƒ )

for L (ğœƒ ) â‰œ Eğ‘ğ‘ğ‘”,ğœƒ (ğ‘§1,ğ‘§2) [ğ‘“ğœƒ (ğ‘§1, ğ‘§2)] with ğ‘“ğœƒ (ğ‘§1, ğ‘§2) â‰œ log(ğ‘ğ‘ğ‘š (ğ‘§1, ğ‘§2)/ğ‘ğ‘ğ‘”,ğœƒ (ğ‘§1, ğ‘§2)).

A standard way to solve this optimisation problem is to apply the gradient-ascent algorithm: starting
from an initial value ğœƒ (0) of ğœƒ , compute ğœƒ (ğ‘¡ ) iteratively by ğœƒ (ğ‘¡ +1) â‰œ ğœƒ (ğ‘¡ ) + ğœ‚ Â· âˆ‡ğœƒ L (ğœƒ (ğ‘¡ ) ), and return
ğœƒ (ğ‘‡ ) for a sufficiently large ğ‘‡ âˆˆ N. Here ğœ‚ âˆˆ R>0 denotes a learning rate.

A challenging part in the algorithm is to compute âˆ‡ğœƒ L (ğœƒ ). An exact computation of the gradient
is mostly intractable due to the expectation inside L, which hinders the gradient from having a
closed-form formula. Hence, in practice, we rather estimate (not exactly compute) the gradient via a
Monte Carlo method: draw a random sample ( Ë†ğ‘§1, Ë†ğ‘§2) from some distribution ğ‘ğœƒ , apply some function
ğ‘”ğœƒ to the sample, and use the result as an estimate to the gradient, i.e.,

ğ‘”ğœƒ ( Ë†ğ‘§1, Ë†ğ‘§2) â‰ˆ âˆ‡ğœƒ L (ğœƒ )

for a sample ( Ë†ğ‘§1, Ë†ğ‘§2) drawn from ğ‘ğœƒ ( Ë†ğ‘§1, Ë†ğ‘§2).

(1)

An important desired property of such a gradient estimator is unbiasedness, which states that the
estimate is accurate in expectation: Eğ‘ğœƒ (ğ‘§1,ğ‘§2) [ğ‘”ğœƒ (ğ‘§1, ğ‘§2)] = âˆ‡ğœƒ L (ğœƒ ). This property is desired so as
to ensure that the algorithm converges to a local optimum.

Gradient estimators for variational inference: SCE, PGE, and SPGE. A standard estimator for
âˆ‡ğœƒ L (ğœƒ ) is the score estimator (SCE) [32, 44], which is unbiased under mild conditions. It estimates
âˆ‡ğœƒ L (ğœƒ ) by following the recipe in Eq. (1) with ğ‘ğœƒ (ğ‘§1, ğ‘§2) = ğ‘ğ‘ğ‘”,ğœƒ (ğ‘§1, ğ‘§2) and

ğ‘”ğœƒ (ğ‘§1, ğ‘§2) = ğ‘“ğœƒ (ğ‘§1, ğ‘§2) Â· âˆ‡ğœƒ log ğ‘ğœƒ (ğ‘§1, ğ‘§2).

That is, the estimator draws a sample from the guide distribution ğ‘ğ‘ğ‘”,ğœƒ and applies the above ğ‘”ğœƒ to
obtain a gradient estimate. It is applicable to a wide range of model-guide pairs while remaining
unbiased, but it is known to have a large approximation error (i.e., have a large variance).

The pathwise gradient estimator (PGE) [21, 33] is another standard gradient estimator, which is
known to have a smaller approximation error than the SCE and thus has been a preferred option
ğ‘” that is a ğœƒ -independent reparameter-
against the SCE. The PGE requires an additional program ğ‘ â€²
isation of the guide ğ‘ğ‘”. A program ğ‘ â€² is said to be ğœƒ -independent if the probability densities of the
sampled random variables in ğ‘ â€² are ğœƒ -independent. It is called a reparameterisation of ğ‘ if ğ‘ and ğ‘ â€²
sample the same set of random variables and they have the same semantics on those variables in
the following sense: when there are ğ‘› random variables, for any measurable â„ : Rğ‘› â†’ R, we have
Eğ‘ğ‘ (ğ‘§) [â„(ğ‘£ğ‘ (ğ‘§))] = Eğ‘ğ‘â€² (ğ‘§) [â„(ğ‘£ğ‘â€² (ğ‘§))], where ğ‘ğ‘ : Rğ‘› â†’ R is the probability density of all ğ‘› random
variables inğ‘, and ğ‘£ğ‘ : Rğ‘› â†’ Rğ‘› is the so called value function ofğ‘, which applies the lambda functions
in the third arguments of ğ‘â€™s sample commands to the corresponding random variables. For example,
ğ‘” in Fig. 2 is a ğœƒ -independent reparameterisation of ğ‘ğ‘” for ğœƒ = (ğœƒ1, ğœƒ2). It has the following probability
ğ‘ â€²
density ğ‘ğ‘â€²
ğ‘”,ğœƒ (ğ‘§1, ğ‘§2) = (ğ‘§1 + ğœƒ1, ğ‘§2 + ğœƒ2).
Note that ğ‘ğ‘â€²
does not depend on ğœƒ , as required by the ğœƒ -independence of ğ‘ğ‘”. We can show this ğ‘ â€²
ğ‘”
is a reparameterisation of ğ‘ğ‘” in Fig. 1 by using the fact that ğ‘£ğ‘ğ‘” is the identity function and ğ‘¦ = ğ‘¥ + ğ‘
for ğ‘¥ drawn from N (ğ‘¥; 0, 1) follows the distribution N (ğ‘¦; ğ‘, 1).

ğ‘” (ğ‘§1, ğ‘§2) = N (ğ‘§1; 0, 1) Â· N (ğ‘§2; 0, 1), and the value function ğ‘£ğ‘â€²

ğ‘”

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:5

Given a reparameterised guide ğ‘ â€²
Eq. (1) this time with ğ‘â€²(ğ‘§1, ğ‘§2) = ğ‘ğ‘â€²

ğ‘”, the PGE estimates âˆ‡ğœƒ L (ğœƒ ) by again following the recipe in
ğ‘” (ğ‘§1, ğ‘§2) and
1, ğ‘§ â€²
2)

ğ‘”,ğœƒ (ğ‘§1, ğ‘§2).

2) = ğ‘£ğ‘â€²

for (ğ‘§ â€²

1, ğ‘§ â€²

ğœƒ (ğ‘§1, ğ‘§2) = âˆ‡ğœƒ ğ‘“ğœƒ (ğ‘§ â€²
ğ‘”â€²

ğ‘”

1, ğ‘§ â€²

ğ‘”,ğœƒ .3

This estimator differs from the SCE in two aspects. First, a random sample is drawn from a reparam-
eterised-guide distribution ğ‘ğ‘â€²
computes the deriv-
2) (not with respect to ğœƒ only), since the argument of
ative of ğ‘“ğœƒ (ğ‘§ â€²
1, ğ‘§ â€²
depends on ğœƒ via ğ‘£ğ‘â€²
ğ‘“ğœƒ (âˆ’) in ğ‘”â€²
ğœƒ

, not from ğ‘ğ‘ğ‘”,ğœƒ . Next, the estimation function ğ‘”â€²
ğœƒ

2) with respect to ğœƒ and (ğ‘§ â€²

While having a small approximation error, to ensure the unbiasedness, the PGE requires more
than the SCE. An important additional requirement for the PGE is that (i) ğ‘ğ‘ğ‘š (ğ‘§1, ğ‘§2) and ğ‘ğ‘ğ‘”,ğœƒ (ğ‘§1, ğ‘§2)
ğ‘”,ğœƒ (ğ‘§1, ğ‘§2) be differentiable in ğœƒ for all ğ‘§1, ğ‘§2. The
should be differentiable in ğœƒ and ğ‘§1, ğ‘§2 and (ii) ğ‘£ğ‘â€²
requirement is imposed partly to ensure that no differentiation error arises in computing ğ‘”â€²
. This
ğœƒ
differentiability requirement, however, can be easily violated if a model or a guide starts to use
branches or loops. For instance, it is violated by our example in Figs. 1 and 2 as ğ‘ğ‘ğ‘š (ğ‘§1, ğ‘§2) is not
differentiable in ğ‘§2. This violation makes the PGE biased for the example, i.e.,

Eğ‘â€²

ğœƒ (ğ‘§1,ğ‘§2) [ğ‘”â€²

ğœƒ (ğ‘§1, ğ‘§2)] = (Â· Â· Â· , 1

3 (ğœƒ1 âˆ’ ğœƒ2)) â‰  (Â· Â· Â· , 1

3 (ğœƒ1 âˆ’ ğœƒ2) + 3

2 N (âˆ’ğœƒ2; 0, 1)) = âˆ‡ğœƒ L (ğœƒ ),

and thus causes the gradient-ascent algorithm to converge to a suboptimal ğœƒ : applying the PGE to the
example produces a suboptimal solution ğœƒ = (0, 0), whereas the optimal solution is ğœƒ â‰ˆ (0.95, 1.52).
The selective pathwise gradient estimator (SPGE) [37] combines the two previous gradient estima-
tors to alleviate their limitations: one has a large approximation error, and the other imposes a strong
ğ‘” that is a reparameter-
requirement for unbiasedness. The SPGE requires an additional program ğ‘ â€²â€²
isation of the guide ğ‘ğ‘” but needs not be ğœƒ -independent (unlike the PGE). An instance of ğ‘ â€²â€²
ğ‘” for our
example is given in Fig. 2, which changes the sample command for ğ‘§1 in ğ‘ğ‘” but keeps the one for ğ‘§2.
Note that the changed sample command for ğ‘§1 in ğ‘ â€²â€²
ğ‘” uses a ğœƒ -independent probability distribution.
Typically, ğ‘ â€²â€²
ğ‘” is obtained by selecting a subset of the random variables in ğ‘ğ‘” and changing the sample
commands for the selected variables such that their probability distributions become ğœƒ -independent;
ğ‘” , the SPGE estimates âˆ‡ğœƒ L (ğœƒ )
the sample commands for the unselected remain as they are. Given ğ‘ â€²â€²
by following the recipe in Eq. (1) with ğ‘â€²â€²

ğœƒ (ğ‘§1, ğ‘§2) = ğ‘ğ‘â€²â€²
for (ğ‘§ â€²â€²
1 , ğ‘§ â€²â€²
ğœƒ (ğ‘§1, ğ‘§2) = âˆ‡ğœƒ ğ‘“ğœƒ (ğ‘§ â€²â€²
ğ‘”â€²â€²
consists of two terms, which come from that of the PGE and
Note that the estimation function ğ‘”â€²â€²
ğœƒ
the SCE. The second term adjusts the PGE to correctly account for unchanged random variables (e.g.,
ğ‘§2 in the example of Fig. 2).

ğ‘”,ğœƒ (ğ‘§1, ğ‘§2) and
ğœƒ (ğ‘§1, ğ‘§2)

2 ) Â· âˆ‡ğœƒ log ğ‘â€²â€²

2 ) + ğ‘“ğœƒ (ğ‘§ â€²â€²

ğ‘”,ğœƒ (ğ‘§1, ğ‘§2).

2 ) = ğ‘£ğ‘â€²â€²

1 , ğ‘§ â€²â€²

1 , ğ‘§ â€²â€²

(2)

By allowing a guide that makes only some selected (not all) random variables ğœƒ -independent, the
SPGE offers two advantages at the same time: it achieves a smaller approximation error than the SCE,
and imposes a weaker requirement for unbiasedness than the PGE. In particular, the differentiability
requirement for the SPGE is weaker than that for the PGE, which is as follows for our example in Figs. 1
and 2: (i) ğ‘ğ‘ğ‘š (ğ‘§1, ğ‘§2) and ğ‘ğ‘ğ‘”,ğœƒ (ğ‘§1, ğ‘§2) be differentiable in ğœƒ and ğ‘§1 (but they may be non-differentiable
ğ‘”,ğœƒ (ğ‘§1, ğ‘§2) be differentiable in ğœƒ for all ğ‘§1, ğ‘§2. This requirement holds,
in ğ‘§2); and (ii) ğ‘£ğ‘â€²â€²
and as a result, the SPGE with this ğ‘ â€²â€²
ğ‘” is biased as
seen before).

ğ‘” is unbiased (whereas the PGE with the given ğ‘ â€²

ğ‘”,ğœƒ (ğ‘§1, ğ‘§2) and ğ‘ğ‘â€²â€²

Variable-selection problem for SPGE. To maximize the advantages offered by the SPGE, we
consider the following algorithmic problem:

3By the chain rule,
ğœ•ğ‘“ğœƒ (ğ‘§â€²
1, ğ‘§â€²
2)
ğœ•ğœƒ1

ğœ•ğ‘“ğœƒ (ğ‘¥1, ğ‘¥2)
ğœ•ğœƒ1

=

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(ğ‘¥1,ğ‘¥2,ğœƒ )
1,ğ‘§â€²
=(ğ‘§â€²
2,ğœƒ )

(cid:42)(cid:32) ğœ•ğ‘“ğœƒ (ğ‘¥1, ğ‘¥2)
ğœ•ğ‘¥1

(cid:12)
(cid:12)
(cid:12)
(cid:12)

+

,

(ğ‘¥1,ğ‘¥2,ğœƒ )
1,ğ‘§â€²
=(ğ‘§â€²
2,ğœƒ )

ğœ•ğ‘“ğœƒ (ğ‘¥1, ğ‘¥2)
ğœ•ğ‘¥2

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(ğ‘¥1,ğ‘¥2,ğœƒ )
1,ğ‘§â€²
=(ğ‘§â€²
2,ğœƒ )

(cid:33)

,

(cid:32) ğœ•ğ‘£ğ‘â€²

ğ‘”,ğœƒ (ğ‘¦1, ğ‘¦2)
ğœ•ğœƒ1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(ğ‘¦1,ğ‘¦2,ğœƒ )
=(ğ‘§1,ğ‘§2,ğœƒ )

(cid:33)(cid:43)

.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:6

Wonyeol Lee, Xavier Rival, and Hongseok Yang

Definition 2.1 (SPGE Variable-Selection Problem; Informal). Assume that we are given a model ğ‘ğ‘š,
a guide ğ‘ğ‘”, and a reparameterisation plan ğœ‹, i.e., a map from sample commands to sample commands.
ğœ‹,ğ‘† be the result
Then, find automatically a large subset ğ‘† of random variables such that if we let ğ‘ğ‘”
ğœ‹,ğ‘† is a
of ğœ‹-transforming every sample command in ğ‘ğ‘” that defines a random variable in ğ‘†, then ğ‘ğ‘”
ğœ‹,ğ‘† ) satisfies the differentiability requirement for the SPGE. â–¡
reparameterisation of ğ‘ and (ğ‘ğ‘š, ğ‘ğ‘”, ğ‘ğ‘”

An instantiation of the problem for our example is that ğ‘ğ‘š and ğ‘ğ‘” are programs in Fig. 1 and ğœ‹
transforms commands of the form ğ‘¦ := sam(ğ‘›, distN(ğ‘’ â€², 1), ğœ†ğ‘¦.ğ‘¦) to ğ‘¦ := sam(ğ‘›, distN (0, 1), ğœ†ğ‘¦.ğ‘¦ +ğ‘’ â€²),
while leaving all the other sample commands as they are. In this instantiation, the condition in the
problem is met by ğ‘† = âˆ… and ğ‘† = {ğ‘§1}, and the latter option is preferred due to its size. Note that the
solution ğ‘† = {ğ‘§1} yields the guide ğ‘ â€²â€²

ğ‘” in Fig. 2, that is, ğ‘ğ‘”

ğœ‹,ğ‘† = ğ‘ â€²â€²
ğ‘” .

Existing PPLs, when applying the SPGE, choose an ğ‘† without checking the differentiability require-
ment, and this can make the requirement easily violated. For instance, given a model-guide pair, in
one of its standard settings, Pyro automatically applies the SPGE with ğ‘† being the set of all continuous
random variables in the guide. This choice of ğ‘†, however, does not guarantee the requirement is met.
For our example in Fig. 1, Pyro chooses ğ‘† = {ğ‘§1, ğ‘§2}, but this ğ‘† violates the requirement; due to this,
the SPGE becomes biased and Pyro returns a suboptimal ğœƒ = (0, 0).

In the rest of the paper, we will present our solution to the SPGE variable-selection problem. A
core component of our solution is a general static analysis framework for smoothness properties (Â§5),
such as differentiability, which our solution uses to discharge the differentiability requirement for
the SPGE correctly and automatically. As we briefly mentioned in the introduction, automatically
analysing the smoothness properties of a program in a sound manner is surprisingly subtle. Our
analysis framework identifies five assumptions for smoothness properties, and prove that the analysis
is sound if a target smoothness property satisfies these assumptions.

Our solution for the SPGE variable-selection problem (Â§6) runs the static analysis on given ğ‘ğ‘š
and ğ‘ğ‘”, and computes a maximal set ğ‘† â€² of random variables in which ğ‘ğ‘ğ‘š and ğ‘ğ‘ğ‘”,ğœƒ are differentiable.
ğœ‹,ğ‘†â€² satisfies the
Then, it heuristically searches for a subset of ğ‘† â€² starting from ğ‘† â€² itself such that ğ‘ğ‘”
differentiability requirement. For instance, for our example in Fig. 1, our differentiability analysis
infers that ğ‘ğ‘ğ‘š and ğ‘ğ‘ğ‘”,ğœƒ are differentiable in {ğ‘§1} and {ğ‘§1, ğ‘§2}, respectively. From this, we set ğ‘† â€² = {ğ‘§1},
run our analysis again on ğ‘ğ‘”
and
are differentiable in ğœƒ . Thus, this ğ‘† â€² becomes the final result. In fact, this first-round success
ğ‘£ğ‘ğ‘”
appeared in our experiments; our implementation shows on all tested examples that the initial choice
of ğ‘† â€² is indeed valid in the above sense so that no subset search is necessary (Â§7).

ğœ‹,ğ‘†â€² meets the requirement, i.e., ğ‘ğ‘ğ‘”

ğœ‹,ğ‘†â€², and are confirmed that ğ‘ğ‘”

ğœ‹,ğ‘†â€²,ğœƒ

ğœ‹,ğ‘†â€²,ğœƒ

We point out that to develop and analyse mathematically our solution for the SPGE variable-
selection problem, we formalise the SPGE in the PPL setting and formally derive a sufficient condition
(which includes the differentiability requirement) for its unbiasedness (Â§4).

3 SETUP
We use a simple imperative probabilistic programming language, which models the core of popular
imperative PPLs, such as Pyro. Programs in the language describe densities, which are sometimes
unnormalised (i.e., they do not integrate to 1). In this section, we describe the syntax and semantics
of the language, and also variational inference for the language.

Syntax of a simple imperative PPL. Let PVar be a finite set of program variables, Str be a finite
set of strings, and Fn be a set of function symbols that represent measurable maps of type Rğ‘˜ â†’ R.
The language has the following syntax:

Real Expr. ğ‘’ ::= ğ‘¥ | ğ‘Ÿ | op(ğ‘’1, . . . , ğ‘’ğ‘˜ )

Boolean Expr. ğ‘ ::= true | ğ‘’1 < ğ‘’2 | ğ‘1 âˆ§ ğ‘2 | Â¬ğ‘

Name Expr. ğ‘› ::= name(ğ›¼, ğ‘’)

Distribution Expr. ğ‘‘ ::= distN(ğ‘’, ğ‘’ â€²)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:7

Command ğ‘ ::= skip | ğ‘¥ := ğ‘’ | ğ‘; ğ‘ â€² | if ğ‘ {ğ‘} else {ğ‘ â€²} | while ğ‘ {ğ‘} | ğ‘¥ := sam(ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’) | obs(ğ‘‘, ğ‘Ÿ )
Here ğ‘¥, ğ‘Ÿ , op, and ğ›¼ stand for a program variable in PVar, a real number, a function symbol in Fn, and
a string in Str, respectively.

The language has four kinds of expressions, which denote maps from states to values of appropriate
types. All the real and boolean expressions are standard. The name expressionsğ‘› denote the identifiers
of drawn samples (i.e., random variables). They are built by appending an integer (obtained by the
floor of a real) to a string in Str; e.g., name("z", 3.2) denotes the name ("z", 3). The distribution
expression distN(ğ‘’, ğ‘’ â€²) denotes the normal distribution with mean ğ‘’ and variance ğ‘’ â€². The language
supports standard commands for imperative computation, and additionally has sample and observe
for probabilistic programming. The sample command ğ‘¥ := sam(ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’) creates a random variable
named ğ‘› by drawing a sample ğ‘Ÿ from ğ‘‘; then, it transforms ğ‘Ÿ to ğ‘’ [ğ‘Ÿ /ğ‘¦] and stores the result in the
program variable ğ‘¥. In the programs written by the user of the language, only the identity function
ğœ†ğ‘¦.ğ‘¦ appears as the third argument of the sample commands. But as we explain later, when a program is
constructed from another by a gradient estimator, such as the SPGE, it may contain sample commands
with non-identity function arguments. The observe command obs(ğ‘‘, ğ‘Ÿ ) describes that an unnamed
random variable is drawn from ğ‘‘ and is immediately observed to have the value ğ‘Ÿ . Computationally,
obs(ğ‘‘, ğ‘Ÿ ) calculates the probability density of ğ‘‘ at ğ‘Ÿ and updates a variable that tracks the product of
these probabilities from all the observations, by multiplying the variable with the calculated density.

Density semantics of the PPL. We use a semantics of our language where commands are inter-
preted as calculators for densities, which may be unnormalised. Commands transform states, but
in so doing, they compute densities of sampled random variables. More precisely, in the semantics,
a command starts with an initial state that fixes not just the values of program variables but also
those of all the random variables that are to be sampled during execution. When the command runs,
it calculates the densities of those random variables at their given initial values, and also computes
the probability density of all the observations, called likelihood. The product of all these densities
and the likelihood becomes the so called unnormalised posterior density.

Let N be the set of natural numbers. Fix ğ‘ âˆˆ N with ğ‘ â‰¥ 1. Formally, the semantics uses the states

of the following form:

ğœ‡ âˆˆ Name â‰œ {(ğ›¼, ğ‘–) | ğ›¼ âˆˆ Str, ğ‘– âˆˆ N âˆ© [0, ğ‘ )},
ğ‘ âˆˆ AVar â‰œ {like} âˆª {pr ğœ‡, valğœ‡, cntğœ‡ | ğœ‡ âˆˆ Name},
ğ‘¢, ğ‘£ âˆˆ Var â‰œ Name âŠ PVar âŠ AVar,

ğœ âˆˆ St â‰œ [Var â†’ R],

St[ğ¾] â‰œ [ğ¾ â†’ R] for ğ¾ âŠ† Var.

Here ğœ (ğœ‡) for ğœ‡ âˆˆ Name is the initial value of the random variable ğœ‡, which is used by the sample
command and does not change during execution. For technical simplicity, the set Name has the
restriction that the integer part of a name must be in [0, ğ‘ ).4 The set AVar consists of four types of
auxiliary variables. The auxiliary variable like stores the likelihood (i.e., the probability density of
all the observations), and its value is initialised to 1 and changes whenever the observe command
obs(ğ‘‘, ğ‘Ÿ ) runs; the new value becomes the old times the density of the probability distribution ğ‘‘ at
ğ‘Ÿ . The other auxiliary variables pr ğœ‡, valğœ‡, and cntğœ‡ are associated with a random variable ğœ‡. They
are initialised with N (ğœ (ğœ‡); 0, 1) (i.e., the density of the standard normal distribution at ğœ (ğœ‡)), ğœ (ğœ‡),
and 0, respectively, and get updated by the sample command ğ‘¥ := sam(ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’) where ğ‘› denotes

4This restriction is usually respected by probabilistic programs in practice, since they normally sample random variables
whose number is uniformly bounded over all traces. The uniform bound ğ‘ can often be found by a simple static analysis. This
restriction along with the finiteness of PVar and Str implies the finiteness of Var, and this makes our technical development
simpler since ğœ âˆˆ St becomes a function on a finite-dimensional space; defining differentiability for functions in [Râˆ â†’ R]
requires more technical materials (e.g., Frechet derivative and Hilbert space).

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:8

Wonyeol Lee, Xavier Rival, and Hongseok Yang

ğœ‡. The command increases cntğœ‡ by 1, so as to record the occurrence of a sampling event for ğœ‡. Then,
it looks up the given value ğœ (ğœ‡) of the random variable ğœ‡, transforms the value to ğ‘’ [ğœ (ğœ‡)/ğ‘¦], and
stores the result in ğ‘¥ and valğœ‡. Finally, the command computes the density of the distribution ğ‘‘ at
the looked-up value ğœ (ğœ‡), and updates pr ğœ‡ with this density. The unnormalised posterior density
(i.e., the joint density of all the random variables and observations) is then obtained by multiplying
at the end of program execution the values of like and pr ğœ‡ for all ğœ‡ âˆˆ Name.

The formal semantics of expressions is standard, and has the following types:

: St â†’ R,

ğ‘’
(cid:74)

(cid:75)

: St â†’ B,

ğ‘
(cid:74)

(cid:75)

: St â†’ Name,

ğ‘›
(cid:74)

(cid:75)

: St â†’ D.

ğ‘‘
(cid:74)

(cid:75)

Here B is the set of booleans, i.e., true and false, and D is the set of positive probability-density func-
tions on R, i.e., a subset of [R â†’ (0, âˆ)] whose elements are measurable functions that integrate to 1.
The semantics is defined for a minor extension of the set of expressions where non-program variables
are allowed to appear, such as (ğœ‡ + ğ‘¥). The interpretation of expressions is mostly standard. We
ğœ),
show only the case for the name expressions ğ‘› â‰¡ name(ğ›¼, ğ‘’):
(cid:75)
where create_name is an operator that takes a string-real pair (ğ›¼, ğ‘Ÿ ) âˆˆ Str Ã— R and creates a name
(ğ›¼, ğ‘–) in Name. We assume that create_name(ğ›¼, ğ‘–) = (ğ›¼, ğ‘–) for ğ‘– âˆˆ N âˆ© [0, ğ‘ ), but other than this
assumption, we leave the definition of create_name open.

ğœ â‰œ create_name(ğ›¼,
(cid:75)

name(ğ›¼, ğ‘’)
(cid:74)

ğ‘’
(cid:74)

Note that according to the semantics, the evaluation of an expression always produces a value
of the right type. In particular, it never generates an error. For instance, when an argument of an
operator op or a distribution constructor distN is outside its intended domain as in log(âˆ’3) and
distN (0, âˆ’2), or when the integer part of a name expression is outside [0, ğ‘ ) as in name("z", âˆ’1), our
semantics does not generate an error. Instead, it returns some pre-chosen default value of the right
type. This slightly unusual way of handling errors is also adopted in our semantics of commands to
be presented shortly, and it lets us avoid the complexity caused by error handling when we formalise
variational inference and develop our program analysis for smoothness properties.

The formal semantics of commands is also mostly standard with the handling of errors via default
values, although its interpretation of sample and observe commands deserves special attention.
Let âŠ¥ be an element not in St, and define StâŠ¥ to be the usual lifting of St with âŠ¥. That is, StâŠ¥ is a
partially-ordered set St âŠ {âŠ¥} with the following order: for ğœ‰, ğœ‰ â€² âˆˆ StâŠ¥, we have ğœ‰ âŠ‘ ğœ‰ â€² if and only
if ğœ‰ = âŠ¥ or ğœ‰ = ğœ‰ â€². We write the standard lifting of a function ğ‘“ : St â†’ StâŠ¥ by ğ‘“ â€  : StâŠ¥ â†’ StâŠ¥ (i.e.,
ğ‘“ â€ (ğœ‰) â‰œ if (ğœ‰ = âŠ¥) then ğœ‰ else ğ‘“ (ğœ‰)). The semantics of a command ğ‘ is a map
: St â†’ StâŠ¥, and is
defined inductively as shown below:

ğ‘
(cid:74)

(cid:75)

ğ‘
(cid:74)

ğœ else
(cid:75)

skip
(cid:74)
ğ‘¥ := ğ‘’
(cid:74)
ğ‘; ğ‘ â€²
(cid:74)
if ğ‘ {ğ‘} else {ğ‘ â€²}
(cid:74)
while ğ‘ {ğ‘}
(cid:74)
ğ‘¥ := sam(ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’ â€²)
(cid:74)

ğœ â‰œ ğœ,
(cid:75)
ğœ â‰œ ğœ [ğ‘¥ â†¦â†’
ğœ],
ğ‘’
(cid:75)
(cid:74)
(cid:75)
â€ (
ğ‘ â€²
ğœ â‰œ
ğœ),
ğ‘
(cid:75)
(cid:74)
(cid:75)
(cid:75)
(cid:74)
ğ‘ â€²
ğœ â‰œ if (
ğœ = true) then
ğœ,
ğ‘
(cid:74)
(cid:75)
(cid:75)
(cid:75)
(cid:74)
ğœ = true) then ğ‘“ â€ (
ğœ â‰œ (fix ğ¹ )(ğœ) where ğ¹ (ğ‘“ )(ğœ) â‰œ if (
ğ‘
(cid:74)
(cid:75)
(cid:75)
ğœ â‰œ ğœ [ğ‘¥ â†¦â†’ ğ‘Ÿ, valğœ‡ â†¦â†’ ğ‘Ÿ, pr ğœ‡ â†¦â†’
ğœ (ğœ (ğœ‡)), cntğœ‡ â†¦â†’ ğœ (cntğœ‡) + 1]
ğ‘‘
(cid:75)
(cid:74)
(cid:75)
ğœ and ğ‘Ÿ â‰œ
ğ‘›
(cid:75)
(cid:74)
ğœ â‰œ ğœ [like â†¦â†’ ğœ (like) Â·
ğœ (ğ‘Ÿ )].
ğ‘‘
(cid:75)
(cid:75)
(cid:74)
The interpretation uses the least fixed-point operator fix for continuous maps ğ¹ on the function
space [St â†’ StâŠ¥], where the function space is ordered pointwise and continuity means the one
with respect to this order. According to this interpretation, ğ‘¥ := sam(ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’ â€²) increments the cntğœ‡
variable for the name ğ‘› = ğœ‡ so that the variable, which has 0 initially, records the number of times
that the random variable with the same name ğ‘› is sampled during execution.

ğœ) else ğœ,
(cid:75)

ğ‘’ â€²[ğœ‡/ğ‘¦]
(cid:74)

where ğœ‡ â‰œ

obs(ğ‘‘, ğ‘Ÿ )

ğœ,
(cid:75)

ğ‘
(cid:74)

(cid:74)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:9

Having some cntğœ‡ variable increased by 2 or larger at some point of execution is not an intended
behaviour of a command ğ‘. That is, if ğ‘ is a well-designed command, every random variable with
a fixed name should be sampled at most once during the execution of ğ‘. This intended behaviour of
commands plays an important role in our results, and we refer to it using the following terminology.

Definition 3.1. An always-terminating command ğ‘ does not have a double-sampling error if for any
â–¡

ğœ âˆˆ St, we have

ğ‘
(cid:74)

ğœ (cntğœ‡) âˆ’ ğœ (cntğœ‡) â‰¤ 1 for all ğœ‡ âˆˆ Name.
(cid:75)

Variational inference. We consider the most common form of variational inference for Pyro-like
probabilistic programming languages where we are asked to learn a good approximation of the
posterior of a given model, i.e., the conditional distribution of the model given a dataset. Typically,
a parameterised approximate posterior is given in variational inference, and learning corresponds to
finding good values of those parameters. A popular approach is to measure the quality of parameter
values by the so called evidence lower bound (ELBO), and to optimise ELBO.

To translate what we have described so far to our context, we need to explain a general recipe for
generating a density ğ‘ğ‘ for a command ğ‘, which is in general unnormalised (i.e., does not integrate to
1). The recipe specifies ğ‘ğ‘ as follows:5 for each ğœğœƒ âˆˆ St[ğœƒ ], ğ‘ğ‘,ğœğœƒ : St[Name] â†’ [0, âˆ) is defined by

ğ‘ğ‘,ğœğœƒ (ğœğ‘›) â‰œ

(cid:40)

ğ‘
(cid:74)
0

ğœ (like) Â· (cid:206)ğœ‡ âˆˆName
(cid:75)

ğ‘
(cid:74)

ğœ (pr ğœ‡)
(cid:75)

ğ‘
(cid:74)

if
ğœ âˆˆ St and
(cid:75)
otherwise

ğ‘
(cid:74)

ğœ (cntğœ‡) â‰¤ 1 for all ğœ‡
(cid:75)

(3)

where ğœ = ğœ0 âŠ• ğœğœƒ âŠ• ğœğ‘› âˆˆ St, and the âŠ• operator combines two real-valued maps with disjoint
domains in the standard way. Also, ğœ0 âˆˆ St[(PVar \ ğœƒ ) âŠ AVar] maps like to 1, pr ğœ‡ to N (ğœğ‘› (ğœ‡); 0, 1)
and valğœ‡ to ğœğ‘› (ğœ‡) for every ğœ‡ âˆˆ Name, and all other variables to 0. Here St[Name] is understood as
a measurable space constructed by taking the product of the |Name| copies of the measurable space
R and the integral is taken over the uniform measure on St[Name] (i.e., the product of the |Name|
copies of the Lebesgue measure on R).

In variational inference in our PPL context, we are given two commands ğ‘ğ‘š and ğ‘ğ‘”, called model
and guide. We assume that (i) these commands always terminate and do not have a double-sampling
error, (ii) some variables ğœƒ = {ğœƒ1, . . . , ğœƒğ‘˜ } âŠ† PVar that only appear in ğ‘ğ‘”, not in ğ‘ğ‘š, are identified as
parameters to be optimised, and (iii) the density ğ‘ğ‘ğ‘”,ğœğœƒ of the guide ğ‘ğ‘” integrates to 1 and defines a
probability distribution.6 Given the model-guide pair (ğ‘ğ‘š, ğ‘ğ‘”), a popular approach for variational
inference is to solve the following optimisation problem approximately,
(cid:2)log(ğ‘ğ‘ğ‘š (ğœğ‘›)/ğ‘ğ‘ğ‘”,ğœğœƒ (ğœğ‘›))(cid:3),

(4)

Eğ‘ğ‘ğ‘”,ğœğœƒ (ğœğ‘›)

argmax
ğœğœƒ

when the expectation is well-defined for all ğœğœƒ . The objective of this optimisation is the ELBO that
we mentioned earlier. Here ğ‘ğ‘ğ‘š means ğ‘ğ‘ğ‘š,ğœâ€²
does not matter since
ğ‘ğ‘š does not access the parameters ğœƒ and so ğ‘ğ‘ğ‘š,ğœâ€²

for some/any ğœ â€²
ğœƒ
for all ğœ â€²
ğœƒ = ğ‘ğ‘ğ‘š,ğœâ€²â€²
ğœƒ

; the choice of ğœ â€²
ğœƒ
ğœƒ âˆˆ St[ğœƒ ].
, ğœ â€²â€²

Often variational inference is applied when the model ğ‘ğ‘š is parameterised as well. In those cases,
it asks for finding good parameters of the model ğ‘ğ‘š as well as those of the guide ğ‘ğ‘”. So, an algorithm
for variational inference this time simultaneously learns a good model for given observations and
a good approximate posterior for the learnt model. This more general form of variational inference

ğœƒ

ğœƒ

5To simplify presentation, we use the fact that the language in our formalism uses the normal distributions only and
the densities of these normal distributions are always greater than 0. Our formalism can be generalised to support any
distributions, and our implementation is based on such generalisation.
6In practice, one more assumption is required: the set of random variables sampled from the model should be the same as
that from the guide. This assumption can be checked automatically, e.g., by [24, 25]. In this work, however, this assumption
is always satisfied: all random variables in Name are sampled by a sample command or at the beginning (via initialisation).

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:10

Wonyeol Lee, Xavier Rival, and Hongseok Yang

can be easily accommodated in our setup. We just need to drop the condition that the parameters
may not appear in ğ‘ğ‘š, and to use ğ‘ğ‘ğ‘š,ğœğœƒ instead of ğ‘ğ‘ğ‘š in the optimisation objective in Eq. (4):

argmax
ğœğœƒ

L (ğœğœƒ ) for L (ğœğœƒ ) â‰œ Eğ‘ğ‘ğ‘”,ğœğœƒ (ğœğ‘›)

(cid:2)log(ğ‘ğ‘ğ‘š,ğœğœƒ (ğœğ‘›)/ğ‘ğ‘ğ‘”,ğœğœƒ (ğœğ‘›))(cid:3) .

(5)

The rest of the paper focuses on this general form of variational inference.

4 SELECTIVE PATHWISE GRADIENT ESTIMATOR
We consider a gradient-based algorithm for the optimisation problem in Eq. (5). The algorithm finds
a good ğœğœƒ by repeatedly estimating the gradient of the optimisation objective at the current ğœğœƒ ,

grad_est(ğœğœƒ ) â‰ˆ âˆ‡ğœƒ Eğ‘ğ‘ğ‘”,ğœğœƒ (ğœğ‘›)

(cid:2)log(ğ‘ğ‘ğ‘š,ğœğœƒ (ğœğ‘›)/ğ‘ğ‘ğ‘”,ğœğœƒ (ğœğ‘›))(cid:3),

and updating ğœğœƒ with the estimate under a learning rate ğœ‚ > 0, that is, ğœğœƒ â† ğœğœƒ + ğœ‚ Â· grad_est(ğœğœƒ ).
Note that the core of the algorithm lies in the computation of grad_est(ğœğœƒ ).

In this section, we describe a particular algorithm for the gradient computation, called selective
pathwise gradient estimator (SPGE), which is often regarded as the algorithm of choice and corresponds
to the inference algorithm developed for stochastic computation graphs [37] and implemented for
Pyro. Our description of the SPGE takes the often-ignored aspect of customising the SPGE algorithm
for PPLs seriously, and it is accompanied with a novel formal analysis of the customisation. Our
analysis clearly identifies information about probabilistic programs that is useful for this customised
SPGE algorithm, and prepares the stage for our program analysis for smoothness properties in Â§5.

4.1 Program transformation
We start by describing a program transformation that changes some sample commands in a given
probabilistic program. This transformation is used crucially by the SPGE.

The key component of the transformation is a partial function ğœ‹ called reparameterisation plan,
which has the type NameEx Ã— DistEx Ã— LamEx â‡€ DistEx Ã— LamEx. Here NameEx, DistEx, and
LamEx denote the sets of name expressions, distribution expressions, and lambda expressions of
the form ğœ†ğ‘¦.ğ‘’, respectively. The plan ğœ‹ specifies how we transform sample commands. Concretely,
assume that we are given ğ‘¥ := sam(ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’). We check whether ğœ‹ (ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’) is defined or not. If
not, we keep the original sample command. Otherwise, so that ğœ‹ (ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’) is (ğ‘‘ â€², ğœ†ğ‘¦ â€².ğ‘’ â€²), we replace
the command with ğ‘¥ := sam(ğ‘›, ğ‘‘ â€², ğœ†ğ‘¦ â€².ğ‘’ â€²).

A natural extension of this intended transformation of ğœ‹ leads to the following program trans-

formation for a general command ğ‘, denoted by ğ‘ğœ‹ :

ğœ‹
â‰œ skip,
skip
ğ‘¥ := ğ‘’ğœ‹ â‰œ ğ‘¥ := ğ‘’,
ğœ‹,
ğœ‹ â‰œ ğ‘ğœ‹ ; ğ‘ â€²
ğœ‹

ğ‘; ğ‘ â€²
if ğ‘ {ğ‘} else {ğ‘ â€²}
while ğ‘ {ğ‘}

ğ‘¥ := sam(ğ‘›, ğ‘‘, ğ‘™)

obs(ğ‘‘, ğ‘Ÿ )

ğœ‹

},

â‰œ if ğ‘ {ğ‘ğœ‹ } else {ğ‘ â€²
â‰œ while ğ‘ {ğ‘ğœ‹ },

â‰œ

(cid:26)ğ‘¥ := sam(ğ‘›, ğ‘‘ â€², ğ‘™ â€²)
ğ‘¥ := sam(ğ‘›, ğ‘‘, ğ‘™)

â‰œ obs(ğ‘‘, ğ‘Ÿ ).

ğœ‹

ğœ‹

ğœ‹

if âˆƒ(ğ‘‘ â€², ğ‘™ â€²). ğœ‹ (ğ‘›, ğ‘‘, ğ‘™) = (ğ‘‘ â€², ğ‘™ â€²)
otherwise,

The transformation recursively traverses ğ‘, and applies ğœ‹ to all the sample commands in ğ‘. Note that
for any ğœ‹, there exists a total function ğœ‹ â€² such that ğ‘ğœ‹ = ğ‘ğœ‹ â€² for all ğ‘; the ğœ‹ â€² coincides with ğœ‹ in the
domain of ğœ‹, and outside of this domain, it is the identity function. But such ğœ‹ â€² loses information
about the domain of ğœ‹, which plays a crucial role in our formalisation of the SPGE.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:11

We are primarily interested in semantics-preserving instances of Â· ğœ‹ . The next definition helps

us to identify such instances.

Definition 4.1. A reparameterisation plan ğœ‹ is valid if for all ğ‘› âˆˆ NameEx, ğ‘‘, ğ‘‘ â€² âˆˆ DistEx, and
(ğœ†ğ‘¦.ğ‘’), (ğœ†ğ‘¦ â€².ğ‘’ â€²) âˆˆ LamEx such that ğœ‹ (ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’) = (ğ‘‘ â€², ğœ†ğ‘¦ â€².ğ‘’ â€²), the following condition holds: for all
states ğœ âˆˆ St and measurable subsets ğ´ âŠ† R,

âˆ«

(ğœ [ğ‘¦â†¦â†’ğ‘Ÿ ]) âˆˆğ´] Â·

1[

ğ‘’
(cid:74)

(cid:75)

ğ‘‘
(cid:74)

ğœ (ğ‘Ÿ ) ğ‘‘ğ‘Ÿ =
(cid:75)

âˆ«

(ğœ [ğ‘¦â€²â†¦â†’ğ‘Ÿ ]) âˆˆğ´] Â·

1[

ğ‘’â€²
(cid:74)

(cid:75)

ğ‘‘ â€²
(cid:74)

ğœ (ğ‘Ÿ ) ğ‘‘ğ‘Ÿ .
(cid:75)

â–¡ (6)

âˆš

The condition says that the distribution obtained by sampling from ğ‘‘ and applying ğœ†ğ‘¦.ğ‘’ is the
same as that obtained by sampling from ğ‘‘ â€² and applying ğœ†ğ‘¦ â€².ğ‘’ â€². An example of a widely-used valid
reparameterisation plan maps its input as follows, whenever defined: ğœ‹0(ğ‘›, distN (ğ‘’1, ğ‘’2), ğœ†ğ‘¦.ğ‘’3) =
ğ‘’2+ğ‘’1)/ğ‘¦]), where we assumeğ‘¦ does not appear inğ‘’1 andğ‘’2, the substitution
(distN(0, 1), ğœ†ğ‘¦.ğ‘’3 [(ğ‘¦Ã—
âˆ’ denotes a square-
in ğœ‹0 expresses the composition of two functions ğœ†ğ‘¦.ğ‘’3 and ğœ†ğ‘¦.(ğ‘¦ Ã—
root operator that handles non-positive arguments in the same way as distN (ğ‘’, âˆ’) does: if
ğœ â‰¤ 0
ğ‘’2
(cid:75)
(cid:74)
ğ‘Ÿ2. The above plan satis-
ğœ = ğœ†ğ‘Ÿ . N (ğ‘Ÿ ;
and
ğœ, ğ‘Ÿ2) for some ğ‘Ÿ2 > 0, then
ğœ =
(cid:75)
(cid:75)
(cid:75)
ğ‘Ÿ2 +ğ‘Ÿ1 with a sampleğ‘¦ from N (0, 1) is distributed by N (ğ‘Ÿ1, ğ‘Ÿ2).
fies the condition in Eq. (6), becauseğ‘¦ Ã—
We now show that Â· ğœ‹ with a valid ğœ‹ preserves semantics. For a command ğ‘ and ğœğœƒ âˆˆ St[ğœƒ ], define

distN (ğ‘’1, ğ‘’2)

ğ‘’2 +ğ‘’1), and

ğ‘’1
(cid:74)

ğ‘’2

âˆš

âˆš

âˆš

âˆš

âˆš

(cid:74)

(cid:74)

the value function ğ‘£ğ‘,ğœğœƒ : St[Name] â†’ St[Name] as follows:
ğ‘
(cid:74)

ğ‘£ğ‘,ğœğœƒ (ğœğ‘›)(ğœ‡) â‰œ let ğœ â‰œ ğœ0 âŠ• ğœğœƒ âŠ• ğœğ‘› in

ğœ (valğœ‡)
(cid:75)

(cid:40)

ğ‘
(cid:74)
0

ğœ âˆˆ St and
if
(cid:75)
otherwise

ğ‘
(cid:74)

ğœ (cntğœ‡â€²) â‰¤ 1 for all ğœ‡ â€²
(cid:75)

where ğœ0 âˆˆ St[(PVar \ ğœƒ ) âŠ AVar] maps like to 1, and pr ğœ‡ to N (ğœğ‘› (ğœ‡); 0, 1) and valğœ‡ to ğœğ‘› (ğœ‡) for
every ğœ‡ âˆˆ Name, and it also maps all the other variables to 0. The value function basically applies the
lambda functions in ğ‘â€™s sample commands to the corresponding random variables. The next theorem
proves that if ğœ‹ is valid, the program transformation Â· ğœ‹ preserves the semantics in the sense that
the integral of a function â„ remains the same under ğ‘ and ğ‘ğœ‹ for any ğ‘. Note that the two integrals
in the theorem are connected via the value functions of ğ‘ and ğ‘ğœ‹ .

Theorem 4.2. Let ğœ‹ be a valid reparameterisation plan, and ğ‘ be a command. Then, for all ğœğœƒ âˆˆ St[ğœƒ ]

and all measurable â„ : St[Name] â†’ R, we have
(cid:17)
(cid:16)

âˆ«

ğ‘‘ğœğ‘›

ğ‘ğ‘,ğœğœƒ (ğœğ‘›) Â· â„(ğ‘£ğ‘,ğœğœƒ (ğœğ‘›))

âˆ«

=

(cid:16)

ğ‘‘ğœğ‘›

ğ‘ğ‘ğœ‹ ,ğœğœƒ (ğœğ‘›) Â· â„(ğ‘£ğ‘ğœ‹ ,ğœğœƒ (ğœğ‘›))

(cid:17)

where the left integral is defined if and only if the right integral is defined.
Remark 1. One immediate yet important consequence of the theorem is that if ğ‘ğ‘,ğœğœƒ is a probability
â–¡
density, so is ğ‘ğ‘ğœ‹ ,ğœğœƒ

. This consequence will be used in Â§4.2 and the proof of Theorem 4.4 later.

4.2 Gradient estimator via program transformation
Let ğ‘ be a command that always terminates and does not have a double-sampling error, and let
ğœğœƒ âˆˆ St[ğœƒ ]. We define the partial density function ğ‘ âŸ¨ğ‘† âŸ©
ğ‘,ğœğœƒ of ğ‘ over a subset ğ‘† âŠ† Name as
ğ‘,ğœğœƒ (ğœğ‘›) â‰œ (cid:214)
ğ‘ âŸ¨ğ‘† âŸ©
: St[Name] â†’ (0, âˆ),
ğ‘
ğœ‡ âˆˆğ‘† (cid:74)

(ğœ0 âŠ• ğœğœƒ âŠ• ğœğ‘›)(pr ğœ‡),

ğ‘ âŸ¨ğ‘† âŸ©
ğ‘,ğœğœƒ

where ğœ0 is set as in the definition of ğ‘ğ‘,ğœğœƒ in Eq. (3). The partial density ğ‘ âŸ¨ğ‘† âŸ©
is essentially the full
ğ‘,ğœğœƒ
density ğ‘ğ‘,ğœğœƒ in Eq. (3) with the omission of the factors not mentioned in ğ‘†. Intuitively, it computes
the density of the random variables in ğ‘† conditioned on the random variables outside of ğ‘†.

(7)

(cid:75)

The SPGE computes an approximate gradient of the objective L in Eq. (5) using the program
transformation in the previous subsection. Its inputs are a model ğ‘ğ‘š, a guide ğ‘ğ‘”, parameters ğœƒ to
ğœ‹ always terminate and do not
optimise, and a reparameterisation plan ğœ‹, where (i) ğ‘ğ‘š, ğ‘ğ‘”, and ğ‘ğ‘”

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:12

Wonyeol Lee, Xavier Rival, and Hongseok Yang

have a double-sampling error, and (ii) ğ‘ğ‘” defines the normalised probability density ğ‘ğ‘ğ‘”,ğœğœƒ for all
ğœğœƒ âˆˆ St[ğœƒ ]. Given these inputs, the SPGE computes an approximate gradient in three steps. First,
it defines the set rv(ğœ‹) âŠ† Name of random variables to be reparameterised:

(8)

ğœ‹ ,ğœğœƒ

ğœ‹ , and draws a sample Ë†ğœğ‘› from ğ‘ğ‘ğ‘”

.7 Drawing a sample Ë†ğœğ‘› makes sense here since ğ‘ğ‘ğ‘”

rv(ğœ‹) â‰œ {(ğ›¼, ğ‘–) âˆˆ Name | (name(ğ›¼, _), _, _) âˆˆ dom(ğœ‹)}
where _ means some existentially quantified (meta) variable. Second, the SPGE transforms the guide
ğ‘ğ‘” to ğ‘ğ‘”
ğœ‹ ,ğœğœƒ
is a probability density (i.e., it normalises to 1) by Remark 1. Another important point is that drawing
ğœ‹ in the standard sampling semantics (not in our density
Ë†ğœğ‘› can be done simply by executing ğ‘ğ‘”
semantics), where each sample command is interpreted as a random draw, not as a density calculator.
Third, the SPGE computes the following approximation of âˆ‡ğœƒ L (ğœğœƒ ) and returns it as a result:
ğ‘›)(cid:1) Â· log(ğ‘ğ‘ğ‘š,ğœğœƒ (ğœ â€²
(ğœ â€²
ğ‘›) + âˆ‡ğœƒ log ğ‘ğ‘ğ‘š,ğœğœƒ (ğœ â€²

grad_est(ğœğœƒ, Ë†ğœğ‘›) â‰œ (cid:0)âˆ‡ğœƒ log ğ‘ âŸ¨Name\rv (ğœ‹ ) âŸ©
(ğœ â€²

ğ‘ğ‘”,ğœğœƒ
Recall that if a command ğ‘ always terminates, both the partial density ğ‘ âŸ¨ğ‘† âŸ©
ğ‘,ğœğœƒ (ğœğ‘›) and the full density
ğ‘ğ‘,ğœğœƒ (ğœğ‘›) can be computed simply by executing ğ‘ in our semantics and calculating the defining
formulas of both densities from the final state of the execution. Thus, all the terms in grad_est can
be computed by executing ğ‘ğ‘” and ğ‘ğ‘š according to our density semantics or differentiating the results
of these executions via, for instance, automatic differentiation as done in Pyro. Note that grad_est
applies two non-trivial optimisations, when compared with the (naive) SPGE explained in Eq. (2):
ğœ‹ , and its second term
its first term involves a partial density of ğ‘ğ‘” instead of the full density of ğ‘ğ‘”
involves again a partial density of ğ‘ğ‘” this time instead of the full density of ğ‘ğ‘”.

ğ‘ğ‘”,ğœğœƒ
âˆ’ âˆ‡ğœƒ log ğ‘ âŸ¨rv (ğœ‹ ) âŸ©

ğ‘›)/ğ‘ğ‘ğ‘”,ğœğœƒ (ğœ â€²
ğ‘›),

ğ‘›))
for ğœ â€²

ğœ‹ ,ğœğœƒ ( Ë†ğœğ‘›).

ğ‘› â‰œ ğ‘£ğ‘ğ‘”

(9)

Is the SPGE correct in any sense? The answer depends on its inputs. If the inputs satisfy the
requirements that we will explain soon, the result of the SPGE is precisely âˆ‡ğœƒ L (ğœğœƒ ) on average, that
is, âˆ‡ğœƒ L (ğœğœƒ ) = E[grad_est(ğœğœƒ, Ë†ğœğ‘›)], where the expectation is taken over the sample Ë†ğœğ‘› used by the
SPGE. This property is called unbiasedness, and it plays the crucial role for ensuring that parameters
updated iteratively with estimated gradients converge to a local optimum.

Let us now spell out the requirements on the inputs of the SPGE. To do so, we need to introduce

one further concept for the reparameterisation plans ğœ‹.

Definition 4.3. A reparameterisation plan ğœ‹ is simple if for all (ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’) and (ğ‘›â€², ğ‘‘ â€², ğœ†ğ‘¦ â€².ğ‘’ â€²) in
NameEx Ã— DistEx Ã— LamEx such that ğ‘› and ğ‘›â€² have the same string part, we have (ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’) âˆˆ
â–¡
dom(ğœ‹) â‡â‡’ (ğ‘›â€², ğ‘‘ â€², ğœ†ğ‘¦ â€².ğ‘’ â€²) âˆˆ dom(ğœ‹).

The simplicity is one of the requirements that the SPGE imposes on ğœ‹. It ensures that the set rv(ğœ‹)
computed by the SPGE describes the sample commands in ğ‘ğ‘” to be transformed by Â· ğœ‹ . Specifically, it
forbids ğœ‹ from using any syntax-specific information of the arguments of a sample command when
it decides whether to transform the command or not. All the requirements of the SPGE, including
the simplicity just explained, are summarised in the next theorem.

Theorem 4.4. Let ğ‘ğ‘š, ğ‘ğ‘”, and ğœ‹ be the inputs to the SPGE (which satisfy the assumptions (i) and
(ii) described above in this subsection). Suppose that L (ğœğœƒ ) and âˆ‡ğœƒ L (ğœğœƒ ) are well-defined for every
ğœğœƒ âˆˆ St[ğœƒ ]. Further, assume that every sample command in ğ‘ğ‘” has ğœ†ğ‘¦.ğ‘¦ as its third argument, and ğ‘ğ‘”
does not have observe commands. Then, for all ğœğœƒ âˆˆ St[ğœƒ ],

âˆ‡ğœƒ L (ğœğœƒ ) = Eğ‘ğ‘ğ‘” ğœ‹ ,ğœğœƒ ( Ë†ğœğ‘›) [grad_est(ğœğœƒ, Ë†ğœğ‘›)]

(10)

if ğœ‹ satisfies the following requirements:

7In practice, the SPGE often draws a fixed number of independent samples Ë†ğœ (1)
1
ğ‘€

ğ‘–=1 grad_est(ğœğœƒ , Ë†ğœ (ğ‘– )
(cid:205)ğ‘€

ğ‘› ) as an estimate of âˆ‡ğœƒ L (ğœğœƒ ). The presented results hold for this more general case as well.

ğ‘› , . . . , Ë†ğœ (ğ‘€ )

from ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ

ğ‘›

and computes

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:13

(R1) ğœ‹ is valid and simple.
(R2) The below functions from St[ğœƒ ] Ã— St[Name] to (0, âˆ) are differentiable in ğœƒ âˆª rv(ğœ‹) jointly:

(ğœğœƒ, ğœğ‘›) â†¦âˆ’â†’ ğ‘ğ‘ğ‘š,ğœğœƒ (ğœğ‘›),

(ğœğœƒ, ğœğ‘›) â†¦âˆ’â†’ ğ‘ âŸ¨rv (ğœ‹ ) âŸ©
(R3) For all ğœğ‘› âˆˆ St[Name], the below functions on St[ğœƒ ] are differentiable in ğœƒ jointly:
ğœğœƒ â†¦âˆ’â†’ ğ‘ âŸ¨rv (ğœ‹ ) âŸ©
ğœ‹ ,ğœğœƒ

(ğœğœƒ, ğœğ‘›) â†¦âˆ’â†’ ğ‘ âŸ¨Name\rv (ğœ‹ ) âŸ©

ğœğœƒ â†¦âˆ’â†’ ğ‘£ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›),

(ğœğ‘›),

(ğœğ‘›),

ğ‘ğ‘”,ğœğœƒ

ğ‘ğ‘”,ğœğœƒ

ğœ‹ ,ğœğœƒ

ğ‘ğ‘”

(ğœğ‘›).

(ğœğ‘›).

ğœğœƒ â†¦âˆ’â†’ ğ‘ âŸ¨Name\rv (ğœ‹ ) âŸ©
ğ‘ğ‘”
(ğœğ‘›) = 0.

(R4) For all ğœğœƒ âˆˆ St[ğœƒ ] and ğœğ‘› âˆˆ St[Name], we have âˆ‡ğœƒ ğ‘ âŸ¨rv (ğœ‹ ) âŸ©
ğœ‹ ,ğœğœƒ
(R5) The below equations hold for all ğœğœƒ âˆˆ St[ğœƒ ]:

ğ‘ğ‘”

âˆ«

âˆ‡ğœƒ

(cid:16)

ğ‘‘ğœğ‘›

âˆ«

âˆ‡ğœƒ

(cid:16)

ğ‘‘ğœğ‘›

ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›) Â· log

ğœ‹ ,ğœğœƒ (ğœğ‘›)
ğ‘ğ‘ğ‘”
ğ‘ğ‘ğ‘š,ğœğœƒ (ğœ â€²
ğ‘›)
ğ‘ğ‘ğ‘”,ğœğœƒ (ğœ â€²
ğ‘›)
ğ‘› for ğ‘£ğ‘ğ‘”

âˆ«

âˆ«

(cid:17)

(cid:17)

=

=

(cid:16)

ğ‘‘ğœğ‘›

âˆ‡ğœƒ ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›)

(cid:17)

,

(cid:16)

ğ‘‘ğœğ‘› âˆ‡ğœƒ

ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›) Â· log

ğ‘ğ‘ğ‘š,ğœğœƒ (ğœ â€²
ğ‘›)
ğ‘ğ‘ğ‘”,ğœğœƒ (ğœ â€²
ğ‘›)

(cid:17)

.

In the second equation, we write ğœ â€²

ğœ‹ ,ğœğœƒ (ğœğ‘›).
To be clear, ğ‘“ : St[ğ¾] â†’ Rğ‘› for ğ¾ âŠ† Var is said to be differentiable in ğ¾ â€² âŠ† ğ¾ jointly if for any
ğœ âˆˆ St[ğ¾ \ ğ¾ â€²], ğ‘“ | [ğœ ] : St[ğ¾ â€²] â†’ Rğ‘› is (jointly) differentiable, where ğ‘“ | [ğœ ] (ğœ) â‰œ ğ‘“ (ğœ âŠ• ğœ).

ğœ‹ , and the value function of ğ‘ğ‘”

In this work, we focus on the requirements (R2) and (R3) on smoothness. They require that five
ğœ‹ be differentiable in certain variables.
density functions of ğ‘ğ‘š, ğ‘ğ‘”, and ğ‘ğ‘”
We will develop a program-analysis framework to check these differentiability requirements soundly
and automatically (Â§5), and will describe an algorithm to the SPGE variable-selection problem, using
the developed analysis framework (Â§6). The remaining requirements (R1), (R4) and (R5) are of less
interest in this work. (R1) and (R4) can be guaranteed by simple syntactic checks and our way of
constructing ğœ‹ (Lemma D.1). (R5) follows from (R2) and (R3) and a few more regularity conditions
on densities which are usually satisfied in practice (Theorem D.2).

We point out that Pyro uses the SPGE in their inference engine, but without checking the above
requirements. In particular, its default option simply uses the ğœ‹ that transforms all the continuous
random variables in a guide, and this can easily violate the requirements and make the SPGE biased.

4.3 Local Lipschitzness for relaxed requirements
In Theorem 4.4, we considered the requirements (R2) and (R3) about the differentiability of density
and value functions, as a sufficient condition for the unbiasedness of the SPGE. They are, however,
sometimes too strong to hold in practice due to the use of popular non-differentiable functions
(e.g., ReLU). As we will see in Â§7, the requirements are indeed violated by some representative Pyro
programs even though the conclusion of Theorem 4.4 holds for those programs (i.e., the estimated
gradients by the SPGE for those programs are unbiased).

To validate the unbiasedness of the SPGE for more examples in practice, we consider the following
relaxation of the requirements (R2) and (R3), which changes differentiability to local Lipschitzness:

(R2â€™) The functions in (R2) are locally Lipschitz in ğœƒ âˆª rv(ğœ‹) jointly.
(R3â€™) For every ğœğ‘› âˆˆ St[Name], the functions in (R3) are locally Lipschitz in ğœƒ jointly.

Here ğ‘“ : Rğ‘› â†’ Rğ‘š is Lipschitz if there is ğ¶ > 0 such that âˆ¥ğ‘“ (ğ‘¥) âˆ’ ğ‘“ (ğ‘¥ â€²)âˆ¥2 â‰¤ ğ¶ âˆ¥ğ‘¥ âˆ’ ğ‘¥ â€²âˆ¥2 for all
ğ‘¥, ğ‘¥ â€² âˆˆ Rğ‘›; and ğ‘“ is locally Lipschitz if for all ğ‘¥ âˆˆ Rğ‘›, there is an open neighborhood ğ‘ˆ âŠ† Rğ‘› of ğ‘¥ such
that ğ‘“ |ğ‘ˆ : ğ‘ˆ â†’ Rğ‘š is Lipschitz. Further, ğ‘“ : St[ğ¾] â†’ Rğ‘š for ğ¾ âŠ† Var is locally Lipschitz in ğ¾ â€² âŠ† ğ¾
jointly if for any ğœ âˆˆ St[ğ¾ \ ğ¾ â€²], ğ‘“ | [ğœ ] : St[ğ¾ â€²] â†’ Rğ‘š is locally Lipschitz, where ğ‘“ | [ğœ ] (ğœ) â‰œ ğ‘“ (ğœ âŠ• ğœ).
Although differentiability does not imply local Lipschitzness, continuous differentiability does. Since
most differentiable functions used in practice are continuously differentiable, asking for (R2â€™) and (R3â€™)
amounts to relaxing the requirements of (R2) and (R3) in practice.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:14

Wonyeol Lee, Xavier Rival, and Hongseok Yang

We choose local Lipschitzness as an alternative to differentiability in (R2) and (R3) for two main
reasons. First, local Lipschitzness is satisfied by most functions used in practice, which can even be
non-differentiable (e.g., ReLU). This would allow us to validate the unbiasedness of the SPGE for more
programs, even when they use non-differentiable functions. Second, using local Lipschitzness in (R2)
and (R3) does not break the results given in Â§4.2, even though local Lipschitzness is more practically
permissive than differentiability, as we explained above. To give the reader an intuition on why, we
point out that there are three places where differentiability in (R2) and (R3) has been used crucially
in the results: when we ensure that the gradients in the RHS of Eq. (10) are well-defined, Eq. (10)
holds, and (R5) holds under mild conditions. In these three places, we have used the next properties of
differentiability, respectively: differentiable functions (i) have well-definedness gradients, (ii) satisfy
the chain rule, and (iii) allow the interchange between integration and differentiation under mild
conditions (Theorem D.2). What we prove or observe is that local Lipschitzness satisfies a weaker
version of the three properties that are still strong enough to prove the results in Â§4.2: locally-Lipschitz
functions (iâ€™) have well-defined gradients almost everywhere, (iiâ€™) satisfy the chain rule almost
everywhere in restricted settings (Lemma E.1), and (iiiâ€™) allow the interchange between integration
and differentiation under the same conditions considered in (iii) (Theorem E.2). Based on these results,
we prove that the results in Â§4.2 still hold even when (R2) and (R3) are replaced by (R2â€™) and (R3â€™).
See Theorem E.3 for the precise statement that uses local Lipschitzness instead of differentiability.
As local Lipschitzness property has wider coverage than differentiability in practice while ensuring
that the results in Â§4.2 remain valid, our implementation and experiments consider the option of
using (R2â€™) and (R3â€™) as well as that of using (R2) and (R3); see Â§7 for details. But until then, we will
consider just the latter option for the sake of brevity.

5 PROGRAM ANALYSIS FOR SMOOTHNESS
Recall that our goal is to develop an algorithm for the SPGE variable-selection problem in Defini-
tion 2.1, which asks for finding a large set ğ‘† of random variables with a certain property when given
a model ğ‘ğ‘š, a guide ğ‘ğ‘”, and a reparameterisation plan ğœ‹. When rephrased using the terminologies
that we covered so far, finding such an ğ‘† amounts to finding a restriction ğœ‹0 of the given ğœ‹ such
that (ğ‘ğ‘š, ğ‘ğ‘”, ğœ‹0) satisfies the requirements in Theorem 4.4. Thus, the key for developing a desired
algorithm for the problem lies in constructing an automatic method for proving that the requirements
in Theorem 4.4, in particular, the smoothness requirements (R2) and (R3) are met. In this section,
we propose a program analysis for smoothness properties, which can help find ğœ‹0 that meets the
requirements (R2) and (R3), and which, together with the optimiser in the next section, leads to an
algorithm for solving the SPGE variable-selection problem.

We first define a parametric abstraction for smoothness properties (Â§5.1). We then describe a
program analysis based on this abstraction and prove the soundness of the analysis (Â§5.2). We finally
instantiate the analysis to differentiability and local Lipschitzness (Â§5.3). The results in this section
are not limited to PPLs, but are applicable to general imperative programming languages.

5.1 Parametric abstraction for smoothness properties
At a high level, our parametric abstraction for smoothness properties is built out of two components.
The first is a predicate over commands that expresses a target smoothness property but in a condi-
tional form. The predicate is parameterised by two sets of variables, ğ¾ for the input variables and
ğ¿ for the output variables. Intuitively, the predicate holds for a command if conditioning the input
variables outside of ğ¾ to any fixed values and varying only the ones in ğ¾ makes the command a
smooth function on the output variables in ğ¿. Our program analysis tracks a conditional smoothness
property formalised by this predicate, and in so doing, it identifies a smooth part of a given command,
even when the command fails to be so with respect to some variables.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:15

The second component is also a predicate over commands, but it deals with dependency, instead of
smoothness. It is again parameterised by ğ¾ and ğ¿, and expresses that to compute the output variables
in ğ¿, a command accesses only the input variables in ğ¾. Our program analysis tracks dependency
formalised by this predicate, so as to achieve high precision, especially when handling sequential
composition. To see this, imagine that we want to check the differentiability of a sequence ğ‘; ğ‘ â€². A
natural approach is to use the chain rule. If the dependency-tracking part of our analysis is missing,
in order to establish that the output on a variable ğ‘£ by the sequence is differentiable in an input
variable ğ‘¢, the analysis should show the output on ğ‘£ by the second command ğ‘ â€² is differentiable
in all variables, and the output on any variable by the first command ğ‘ is differentiable in ğ‘¢. This
requirement on ğ‘ and ğ‘ â€² is too strong. Often, ğ‘ â€² uses only a small number of variables to compute
ğ‘£, and it is sufficient to require that just on those used variables, ğ‘ should be differentiable in ğ‘¢.
Similarly, ğ‘ commonly updates only a small number of variables using ğ‘¢, and it is enough to require
that just in those ğ‘¢-dependent variables, the second command ğ‘ â€² is differentiable when computing
the output ğ‘£. The dependency-tracking part lets our analysis carry out such reasoning and achieve
better precision. Formally, this means our analysis uses a version of reduced product [11] between
dependency analysis and the analysis that tracks the target smoothness property.

We now formally describe each of these components as well as their combination.

Family of smoothness predicates. Our program analysis assumes that a target smoothness
5.1.1
property is specified in terms of a family of predicates, ğœ™ = (ğœ™ğ¾,ğ¿ : ğ¾, ğ¿ âŠ† Var), where ğœ™ğ¾,ğ¿ is a set
of partial functions from St[ğ¾] to St[ğ¿] (i.e., ğœ™ğ¾,ğ¿ âŠ† [St[ğ¾] â‡€ St[ğ¿]]).

Example 5.1 (Differentiability). In the instantiation of our program analysis for differentiability,
we use the family ğœ™ (ğ‘‘) where for all ğ¾, ğ¿ âŠ† Var, a partial function ğ‘“ : St[ğ¾] â†’ St[ğ¿] belongs to ğœ™ (ğ‘‘)
ğ¾,ğ¿
â–¡
if and only if (i) dom(ğ‘“ ) is open and (ii) ğ‘“ is (jointly) differentiable in its domain.

At first, one may wonder why we use a family of ğœ™ğ¾,ğ¿ predicates instead of a single predicate ğœ™0
over [St â†’ StâŠ¥]. The reason is that, as mentioned above, the analysis aims at a conditional variant of
the traditional notion of smoothness. For instance, instead of checking that a function ğ‘“ : St â†’ StâŠ¥ is
differentiable on St\ğ‘“ âˆ’1({âŠ¥}), the analysis proves differentiability conditioned on certain variables be-
ing fixed: if we fix the input variables in Var\ğ¾ and vary just those in ğ¾ in the initial state, and look at the
output variables in ğ¿ only, then the function ğ‘“ becomes differentiable, although it might not be so when
all input/output variables are considered. To express this, we need the whole family of ğœ™ğ¾,ğ¿ predicates.
This notion of conditional differentiability is similar to, but not the same as, so called partial
differentiability. Partial differentiability in ğ¾ says that, for every ğ‘£ âˆˆ ğ¾, if we fix all the input vari-
ables except ğ‘£, including those in ğ¾ \ {ğ‘£ }, and consider the output variables in ğ¿ only, ğ‘“ becomes
differentiable. As we will show in Remark 4, the set of partially-differentiable functions is not closed
under a certain operator, but we need the closure to ensure that our program analysis is sound. Our
conditional differentiability does not suffer from this issue.

Smoothness abstraction. Based on the family ğœ™, we build a predicate Î¦ that captures the
5.1.2
smoothness of commands. The Î¦ constrains functions from St to StâŠ¥, unlike ğœ™ğ¾,ğ¿. For ğ¾, ğ¿ âŠ† Var
with ğ¾ âŠ‡ ğ¿, define ğœ‹ğ¾,ğ¿ to be the projection from St[ğ¾] to St[ğ¿].

Definition 5.2. The smoothness abstraction Î¦ is the predicate over a function ğ‘“ âˆˆ [St â†’ StâŠ¥] and
variable sets ğ¾, ğ¿ âŠ† Var. It is satisfied by (ğ‘“ , ğ¾, ğ¿) if for all ğœ âˆˆ St[Var \ ğ¾], the predicate ğœ™ğ¾,ğ¿ holds
for the following partial function ğ‘” : St[ğ¾] â‡€ St[ğ¿]: dom(ğ‘”) â‰œ {ğœ âˆˆ St[ğ¾] | ğ‘“ (ğœ âŠ• ğœ) âˆˆ St} and
ğ‘”(ğœ) â‰œ (ğœ‹Var,ğ¿ â—¦ ğ‘“ )(ğœ âŠ• ğœ) for ğœ âˆˆ dom(ğ‘”). We denote the satisfaction of Î¦ by |= Î¦(ğ‘“ , ğ¾, ğ¿).
â–¡
Note that the function ğ‘” is constructed from ğ‘“ by fixing the Var \ ğ¾ part of the input state to ğœ, and
looking at only the ğ¿ part of the output. This construction is precisely the one used in the informal

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:16

Wonyeol Lee, Xavier Rival, and Hongseok Yang

definition of conditional differentiability described above, and its use reflects the fact that our program
analysis attempts to prove a conditional smoothness property.

5.1.3 Dependency abstraction. Our abstract domain has a component for tracking dependency
between input-output variables. Dependency here means that a given input variable is used for
computing a given output variable. We define a predicate Î” that has a similar format as Î¦. Intuitively,
Î”(ğ‘“ , ğ¾, ğ¿) holds if and only if the ğ¿ part of the output of ğ‘“ depends at most on the ğ¾ part of the input
to ğ‘“ . To define Î” formally, for ğ¾ âŠ† Var, let âˆ¼ğ¾ be the following equivalence relation over states:
ğœ âˆ¼ğ¾ ğœ â€² if and only if ğœ (ğ‘£) = ğœ â€²(ğ‘£) for all ğ‘£ âˆˆ ğ¾.

Definition 5.3. The dependency abstraction Î” is the predicate on ğ‘“ âˆˆ [St â†’ StâŠ¥] and ğ¾, ğ¿ âŠ† Var
that holds if for all ğœ, ğœ â€² âˆˆ St with ğœ âˆ¼ğ¾ ğœ â€², we have (ğ‘“ (ğœ) âˆˆ St â‡â‡’ ğ‘“ (ğœ â€²) âˆˆ St) and (ğ‘“ (ğœ) âˆˆ
St =â‡’ ğ‘“ (ğœ) âˆ¼ğ¿ ğ‘“ (ğœ â€²)). We denote the satisfaction of Î” by |= Î”(ğ‘“ , ğ¾, ğ¿).
â–¡
5.1.4 Combined abstraction. We bring together the two abstractions that we just defined, and
construct the final abstract domain Dâ™¯ used by our program analysis.

Intuitively, each element of Dâ™¯ is a predicate on a function ğ‘“ âˆˆ [St â†’ StâŠ¥] expressed by the
conjunction of the following form: (cid:211)ğ‘š
ğ‘–=1 Î¦(ğ‘“ , ğ¾ğ‘–, ğ¿ğ‘– ) âˆ§ (cid:211)ğ‘›
ğ‘— ). A direct but naive way of
implementing this intuition is to let Dâ™¯ be the collection of all the constraints of this form, but it
permits too many constraints and leads to a costly program analysis. We take a more economical
alternative that further restricts the allowed form of the constraints. The alternative requires that the
conjunction from above should be constructed out of two mappings ğ‘ and ğ‘‘ from output variables
to input variable sets, and a set ğ‘‰ of input variables. The ğ‘ describes smoothness, and the ğ‘‘ and ğ‘‰
dependency. They together encode the constraint
(cid:219)

ğ‘—=1 Î”(ğ‘“ , ğ¾ â€²

ğ‘—, ğ¿â€²

(cid:219)

Î¦(ğ‘“ , ğ‘ (ğ‘£), {ğ‘£ }) âˆ§

Î”(ğ‘“ , ğ‘‘ (ğ‘¢), {ğ‘¢}) âˆ§ Î”(ğ‘“ , ğ‘‰ , âˆ…).

ğ‘£ âˆˆVar

ğ‘¢ âˆˆVar

Thus, a function ğ‘“ âˆˆ [St â†’ StâŠ¥] satisfies the constraint encoded by ğ‘, ğ‘‘, and ğ‘‰ if (i) for every output
variable ğ‘£, when we fix the values of all the input variables outside of ğ‘ (ğ‘£), the (partial) function
ğœ â†¦âˆ’â†’ ğ‘“ (ğœ)(ğ‘£) is smooth (e.g., differentiable); (ii) for every output variable ğ‘¢, the (partial) function
ğœ â†¦âˆ’â†’ ğ‘“ (ğœ)(ğ‘¢) does not access any variable outside of ğ‘‘ (ğ‘¢) to compute the value of ğ‘¢; and (iii) the
values of input variables in ğ‘‰ determine whether ğ‘“ returns âŠ¥ or not.

Definition 5.4. The abstract domain Dâ™¯ consists of triples (ğ‘, ğ‘‘, ğ‘‰ ) âˆˆ [Var â†’ P (Var)]2 Ã— P (Var),
called abstract state, such that ğ‘ (ğ‘£) âŠ‡ ğ‘‘ (ğ‘£)ğ‘ and ğ‘‘ (ğ‘£) âŠ‡ ğ‘‰ for all ğ‘£ âˆˆ Var, where âˆ’ğ‘ is the standard
operation for set complement. That is,

Dâ™¯ â‰œ {(ğ‘, ğ‘‘, ğ‘‰ ) âˆˆ [Var â†’ P (Var)]2 Ã— P (Var) | ğ‘ (ğ‘£) âŠ‡ ğ‘‘ (ğ‘£)ğ‘ and ğ‘‘ (ğ‘£) âŠ‡ ğ‘‰ for all ğ‘£ âˆˆ Var}.
We order abstract states as follows: (ğ‘, ğ‘‘, ğ‘‰ ) âŠ‘ (ğ‘ â€², ğ‘‘ â€², ğ‘‰ â€²) if and only if ğ‘‰ âŠ† ğ‘‰ â€² and for all ğ‘£ âˆˆ Var,
ğ‘ (ğ‘£) âŠ‡ ğ‘ â€²(ğ‘£) and ğ‘‘ (ğ‘£) âŠ† ğ‘‘ â€²(ğ‘£). These abstract states are concretised by ğ›¾ : Dâ™¯ â†’ P ([St â†’ StâŠ¥]):
ğ‘“ âˆˆ ğ›¾ (ğ‘, ğ‘‘, ğ‘‰ ) â‡â‡’ |= Î”(ğ‘“ , ğ‘‰ , âˆ…), |= Î¦(ğ‘“ , ğ‘ (ğ‘£), {ğ‘£ }), and |= Î”(ğ‘“ , ğ‘‘ (ğ‘£), {ğ‘£ }) for all ğ‘£ âˆˆ Var. â–¡ (11)
Note that the definition of Dâ™¯ contains two conditions. The first condition ğ‘ (ğ‘£) âŠ‡ ğ‘‘ (ğ‘£)ğ‘ comes
from our assumption that if a function does not depend on a variable ğ‘¢, it is smooth in ğ‘¢. This and
other assumptions of the analysis will be explained shortly in Â§5.2.2. The other condition ğ‘‘ (ğ‘£) âŠ‡ ğ‘‰
originates from the relationship that if Î”(ğ‘“ , ğ¾, {ğ‘£ }) holds, so does Î”(ğ‘“ , ğ¾, âˆ…).

Example 5.5 (Differentiability). Consider the setup of Example 5.1 and the program ğ‘ â‰¡ (ğ‘¦ :=
ğ‘¥ âˆ— ğ‘¥; if (ğ‘¥ â‰¥ 0) {ğ‘  := 1} else {ğ‘  := âˆ’1}). Let (ğ‘, ğ‘‘, ğ‘‰ ) be the smallest abstract state that describes
the program. In this program, ğ‘  is not differentiable in ğ‘¥, but ğ‘¦ is. So, ğ‘ (ğ‘ ) = Var \ {ğ‘¥ } âŠ‡ {ğ‘¦, ğ‘ } and
ğ‘ (ğ‘¦) = Var âŠ‡ {ğ‘¥, ğ‘¦, ğ‘ }. Note that ğ‘ (ğ‘ ) contains the input variables ğ‘  and ğ‘¦ because by not depending

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:17

on those input variables, the output ğ‘  is differentiable in those variables. For the dependency part,
â–¡
we have ğ‘‘ (ğ‘ ) = ğ‘‘ (ğ‘¦) = {ğ‘¥ } and ğ‘‰ = âˆ….

5.2 Parametric static program analysis
Our program analysis is based on abstract interpretation [10], and computes an approximation of
of a given command ğ‘ using the abstract domain Dâ™¯. We formalise this
the concrete semantics
â™¯ âˆˆ Dâ™¯ by induction on the structure
computation by the abstract semantics of ğ‘, which defines
of commands, and over-approximates

in the sense of the concretization ğ›¾ in Eq. (11).

ğ‘
(cid:74)

ğ‘
(cid:74)

(cid:75)

(cid:75)

ğ‘
(cid:74)

(cid:75)

ğ‘
(cid:74)

â™¯. The overall structure of the
5.2.1 Analysis definition. Fig. 3 shows the abstract semantics of
semantics follows the standard compositional semantics of an imperative language. For instance, the
abstract semantics of sequential composition is defined in terms of those of constituent commands,
and the semantics of a loop is the least fixed point of a monotone operator over Dâ™¯. However, the
specifics of the semantics include non-standard details, and we spell them out by going through the
â™¯.
defining clauses of
ğ‘
(cid:74)
(cid:75)
The definition of
skip
(cid:75)
(cid:74)

â™¯ formalises the effect of skip on smoothness and dependency. The def-
inition says that skip computes each output variable ğ‘£ in a smooth manner in all input variables,
and in so doing, it creates the dependency between the variable ğ‘£ to itself at the input state. The ğ‘‰
part of

â™¯ is the empty set since skip always terminates.

(cid:75)

The next case is ğ‘¥ := ğ‘’. Its abstract semantics records the smoothness and dependency information
of the updated variable ğ‘¥ by analysing the expression ğ‘’. For the smoothness part, the semantics
â™¯ that computes an under-approximation of the set of variables in which
invokes the subroutine
ğ‘’
â™¯ computes the set of all the free variables
(cid:77)
(cid:76)
the expression ğ‘’ is smooth. For the dependency part,
of ğ‘’ so as to get an over-approximation of all variables that may affect the value of ğ‘’. For variables
other than ğ‘¥,

â™¯ behaves like

ğ‘¥ := ğ‘’
(cid:74)

â™¯.

(cid:75)

skip
(cid:74)

(cid:75)

(cid:75)

(cid:75)

ğ‘ â€²
(cid:74)

â™¯ and ğ‘‘ â€² from

The abstract semantics of a sequence ğ‘; ğ‘ â€² composes those of the sub-commands ğ‘ and ğ‘ â€². It uses
the liftings ğ‘“âˆª, ğ‘“âˆ© : P (Var) â†’ P (Var) of functions ğ‘“ of type Var â†’ P (Var), which are defined
â™¯ constructs
as follows: ğ‘“âˆª(ğ‘‰ ) â‰œ (cid:208)ğ‘£ âˆˆğ‘‰ ğ‘“ (ğ‘£) and ğ‘“âˆ© (ğ‘‰ ) â‰œ (cid:209)ğ‘£ âˆˆğ‘‰ ğ‘“ (ğ‘£). The abstract semantics
ğ‘; ğ‘ â€²
â™¯ after lifting the former. Note
(cid:74)
the dependency part ğ‘‘ â€²â€² by composing ğ‘‘ from
ğ‘
(cid:75)
(cid:74)
the inclusion of the set ğ‘‰ in the definition of ğ‘‘ â€²â€². This is to account for the case that ğ‘‘ â€²(ğ‘£) in the
definition is the empty set; in that case, ğ‘‘âˆª (ğ‘‘ â€²(ğ‘£)) is empty as well and does not have any information
â™¯ is more involved, and implements the intuition
about termination. The smoothness part ğ‘ â€²â€² of
ğ‘; ğ‘ â€²
(cid:74)
described briefly in Â§5.1. In order to conclude that input variables in ğ‘‰0 together smoothly affect an
output variable ğ‘£ in the computation of ğ‘; ğ‘ â€², the ğ‘ â€²â€² considers the intermediate state after the first
command ğ‘, and forms two groups of variables at that intermediate state: ğ‘‘ â€²(ğ‘£) and ğ‘ â€²(ğ‘£)ğ‘ . Note that
the desired smoothness property for the input variables in ğ‘‰0 and the output variable ğ‘£ may fail if
the first command ğ‘ uses some variable ğ‘¢0 âˆˆ ğ‘‰0 non-smoothly to update a variable ğ‘¢ â€²
0 in ğ‘‘ â€²(ğ‘£), or it
1 âˆˆ ğ‘ â€²(ğ‘£)ğ‘ . In the former case, the
uses some variable ğ‘¢1 âˆˆ ğ‘‰0 to compute the value of a variable ğ‘¢ â€²
non-smoothness of ğ‘ causes an issue, and in the latter case, the non-smoothness of ğ‘ â€² causes an issue.
The ğ‘ â€²â€² collects the input variables that avoid these two failure modes and also do not influence the
termination of the sequence. As we show in our soundness theorem, doing so is sufficient because
it amounts to using a version of chain rule for the target smoothness property.

(cid:75)

ğ‘¥ := ğ‘’
(cid:74)

(cid:75)

skip
(cid:75)

(cid:74)

The abstract semantics of an if command conservatively assumes that any variable in its condition
ğ‘ may affect the value of any output variable (by influencing whether the true or false branch of the
command gets executed) and this influence is potentially non-smooth. For every output variable
ğ‘£, the smooth set ğ‘ â€²â€²(ğ‘£) for the if command implements this assumption by excluding free variables
in ğ‘, and the computed dependency set does the same but this time by including free variables in ğ‘.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:18

Wonyeol Lee, Xavier Rival, and Hongseok Yang

â™¯ â‰œ (ğœ†ğ‘£.Var, ğœ†ğ‘£.{ğ‘£ }, âˆ…),
â™¯ â‰œ ((ğœ†ğ‘£. ğ‘£ â‰¡ ğ‘¥ ?
ğ‘’
(cid:76)
â™¯ â‰œ let (ğ‘, ğ‘‘, ğ‘‰ ) â‰œ

skip
(cid:75)
(cid:74)
ğ‘¥ := ğ‘’
(cid:74)
ğ‘; ğ‘ â€²
(cid:74)

(cid:75)

â™¯ and (ğ‘ â€², ğ‘‘ â€², ğ‘‰ â€²) â‰œ
where ğ‘ â€²â€²(ğ‘£) â‰œ (ğ‘‰ âˆª ğ‘âˆ© (ğ‘‘ â€²(ğ‘£))ğ‘ âˆª ğ‘‘âˆª(ğ‘ â€²(ğ‘£)ğ‘ ))ğ‘,

(cid:75)
(cid:75)
(cid:75)
ğ‘‘ â€²â€²(ğ‘£) â‰œ ğ‘‰ âˆª ğ‘‘âˆª (ğ‘‘ â€²(ğ‘£)), and ğ‘‰ â€²â€² â‰œ ğ‘‰ âˆª ğ‘‘âˆª (ğ‘‰ â€²),
ğ‘ â€²
ğ‘
(cid:74)
(cid:74)

â™¯ â‰œ let (ğ‘, ğ‘‘, ğ‘‰ ) â‰œ
where ğ‘ â€²â€²(ğ‘£) â‰œ fv(ğ‘)ğ‘ âˆ© ğ‘ (ğ‘£) âˆ© ğ‘ â€²(ğ‘£),

â™¯ and (ğ‘ â€², ğ‘‘ â€², ğ‘‰ â€²) â‰œ

â™¯ : Var), (ğœ†ğ‘£. ğ‘£ â‰¡ ğ‘¥ ? fv(ğ‘’) : {ğ‘£ }), âˆ…),
(cid:77)
ğ‘
(cid:74)

ğ‘ â€²
(cid:74)

â™¯ in (ğ‘ â€²â€², ğ‘‘ â€²â€², ğ‘‰ â€²â€²)

â™¯ in (ğ‘ â€²â€², ğ‘‘ â€²â€², ğ‘‰ â€²â€²)

(cid:75)

(cid:75)
ğ‘‘ â€²â€²(ğ‘£) â‰œ fv(ğ‘) âˆª ğ‘‘ (ğ‘£) âˆª ğ‘‘ â€²(ğ‘£), and ğ‘‰ â€²â€² â‰œ fv(ğ‘) âˆª ğ‘‰ âˆª ğ‘‰ â€²,
â™¯ in fix ğ¹ â™¯

while ğ‘ {ğ‘}

â™¯ â‰œ let (ğ‘, ğ‘‘, ğ‘‰ ) â‰œ
where ğ¹ â™¯ (ğ‘0, ğ‘‘0, ğ‘‰0) â‰œ (ğ‘ â€², ğ‘‘ â€², ğ‘‰ â€²),
(cid:75)
ğ‘ â€²(ğ‘£) â‰œ fv(ğ‘)ğ‘ âˆ© (ğ‘‰ âˆª ğ‘âˆ© (ğ‘‘0(ğ‘£))ğ‘ âˆª ğ‘‘âˆª(ğ‘0(ğ‘£)ğ‘ ))ğ‘,
ğ‘‘ â€²(ğ‘£) â‰œ fv(ğ‘) âˆª (ğ‘‰ âˆª ğ‘‘âˆª (ğ‘‘0(ğ‘£))) âˆª {ğ‘£ }, and ğ‘‰ â€² â‰œ fv(ğ‘) âˆª (ğ‘‰ âˆª ğ‘‘âˆª(ğ‘‰0)),

ğ‘
(cid:74)

(cid:75)

(cid:75)

(cid:74)

if ğ‘ {ğ‘} else {ğ‘ â€²}

(cid:74)

ğ‘¥ := sam(ğ‘›, distN (ğ‘’1, ğ‘’2), ğœ†ğ‘¦.ğ‘’ â€²)
(cid:74)

â™¯â‰œ (ğ‘, ğ‘‘, âˆ…)

for ğ‘› = name(ğ›¼, ğ‘Ÿ ) with ğ‘Ÿ âˆˆ R

(cid:75)

â™¯

â™¯

â™¯

ğ‘ (ğ‘£) â‰œ

where ğœ‡ â‰œ create_name(ğ›¼, ğ‘Ÿ ),
ï£±ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´
ï£³
ï£±ï£´ï£´ï£²
ï£´ï£´
ï£³

ğ‘’ â€²[ğœ‡/ğ‘¦]
(cid:76)
(cid:77)
pdfN (ğœ‡; ğ‘’1, ğ‘’2)
(cid:76)
cntğœ‡ + 1
(cid:76)
(cid:77)
Var
fv(ğ‘’ â€²[ğœ‡/ğ‘¦])
{ğœ‡} âˆª fv(ğ‘’1) âˆª fv(ğ‘’2)
{ğ‘£ }
â™¯ â‰œ (ğ‘, ğ‘‘, âˆ…)

and ğ‘‘ (ğ‘£) â‰œ

(cid:77)

if ğ‘£ âˆˆ {ğ‘¥, valğœ‡ }
if ğ‘£ â‰¡ pr ğœ‡
if ğ‘£ â‰¡ cntğœ‡
otherwise,

if ğ‘£ âˆˆ {ğ‘¥, valğœ‡ }
if ğ‘£ â‰¡ pr ğœ‡
otherwise,

for ğ‘› = name(ğ›¼, ğ‘’) with ğ‘’ âˆ‰ R
â™¯

â™¯

â™¯

â™¯

(cid:77)

(cid:77)

ï£³

where ğ‘ (ğ‘£) â‰œ

fv(ğ‘’)ğ‘ âˆ© (cid:209)ğœ‡=(ğ›¼,_) âˆˆName
ğ‘’ â€²[ğœ‡/ğ‘¦]
ï£±ï£´ï£´ï£´ï£´ï£´ï£´ï£²
fv(ğ‘’)ğ‘ âˆ©
(cid:76)
ğ‘’ â€²[ğœ‡/ğ‘¦]
fv(ğ‘’)ğ‘ âˆ©
(cid:76)
(cid:77)
pdfN (ğœ‡; ğ‘’1, ğ‘’2)
fv(ğ‘’)ğ‘ âˆ©
(cid:76)
ï£´ï£´ï£´ï£´ï£´ï£´
cntğœ‡ + 1
(cid:77)
(cid:76)
Var
fv(ğ‘’) âˆª (cid:208)ğœ‡=(ğ›¼,_) âˆˆName fv(ğ‘’ â€²[ğœ‡/ğ‘¦])
ï£±ï£´ï£´ï£´ï£´ï£´ï£´ï£²
fv(ğ‘’) âˆª {valğœ‡ } âˆª fv(ğ‘’ â€²[ğœ‡/ğ‘¦])
fv(ğ‘’) âˆª {pr ğœ‡, ğœ‡} âˆª fv(ğ‘’1) âˆª fv(ğ‘’2)
ï£´ï£´ï£´ï£´ï£´ï£´
fv(ğ‘’) âˆª {cntğœ‡ }
{ğ‘£ }
â™¯ â‰œ (ğ‘, ğ‘‘, âˆ…)
where ğ‘ (ğ‘£) â‰œ (ğ‘£ â‰¡ like) ?

and ğ‘‘ (ğ‘£) â‰œ

ï£³

(cid:75)

â™¯ : Var,
and ğ‘‘ (ğ‘£) â‰œ (ğ‘£ â‰¡ like) ? {like} âˆª fv(ğ‘’1) âˆª fv(ğ‘’2) : {ğ‘£ }.

like Ã— pdfN (ğ‘Ÿ ; ğ‘’1, ğ‘’2)
(cid:76)

(cid:77)

if ğ‘£ â‰¡ ğ‘¥
if ğ‘£ â‰¡ valğœ‡ for ğœ‡ = (ğ›¼, _)
if ğ‘£ â‰¡ pr ğœ‡ for ğœ‡ = (ğ›¼, _)
if ğ‘£ â‰¡ cntğœ‡ for ğœ‡ = (ğ›¼, _)
otherwise,
if ğ‘£ â‰¡ ğ‘¥
if ğ‘£ â‰¡ valğœ‡ for ğœ‡ = (ğ›¼, _)
if ğ‘£ â‰¡ pr ğœ‡ for ğœ‡ = (ğ›¼, _)
if ğ‘£ â‰¡ cntğœ‡ for ğœ‡ = (ğ›¼, _)
otherwise,

obs(distN (ğ‘’1, ğ‘’2), ğ‘Ÿ )

(cid:74)

Fig. 3. Abstract semantics of commands defining

â™¯ âˆˆ Dâ™¯.

ğ‘
(cid:74)

(cid:75)

The abstract semantics of a loop computes the least fixed point of a monotone operator ğ¹ â™¯ : Dâ™¯ â†’
Dâ™¯ using the standard Kleene iteration. The operator ğ¹ â™¯ describes the effect of one iteration of the
loop, and it is derived from the standard loop unrolling and our abstract semantics of sequencing
and the if command.

The abstract semantics of an observe command obs(distN(ğ‘’1, ğ‘’2), ğ‘Ÿ ) uses the fact that the com-
mand has the same concrete semantics as the assignment like := like Ã— pdfN(ğ‘Ÿ ; ğ‘’1, ğ‘’2), where pdfN

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

ğ‘¥ := sam(ğ‘›, distN (ğ‘’1, ğ‘’2), ğœ†ğ‘¦.ğ‘’ â€²)
(cid:74)

(cid:75)

Smoothness Analysis and Selective Reparameterisation

0:19

is the density function of the normal distribution. The semantics computes (ğ‘, ğ‘‘, ğ‘‰ ) according to
that of the assignment, which we explained earlier.

The final case is the abstract semantics of a sample command. The semantics performs a case
analysis on the first argument of sam. If it is a constant expression not involving any variables, then
the abstract semantics constructs the name ğœ‡ of the sampled random variable, and updates ğ‘, ğ‘‘, and
ğ‘‰ according to the concrete semantics of the command. Otherwise, the abstract semantics acknowl-
edges that the precise name ğœ‡ of the random variable cannot be known statically, and performs so
called weak update by joining two pieces of information before and after the update of the command
in the concrete semantics. Note that the abstract semantics does not require the third argument
of sam should be the identity function. The ability of dealing with a general function in the third
argument is needed since our analysis is intended to be applied to programs after the transformation
of the SPGE, which may introduce such an argument.

The abstract semantics is well-defined under the following relatively weak assumption:

Assumption 1 (Expression analysis and free variables).

â™¯ âŠ‡ fv(ğ‘’)ğ‘ for all expressions ğ‘’.
This assumption is satisfied by the instantiations of the semantics with differentiability and local
Lipschitzness, which are used in our implementation. It will be assumed in the rest of the paper.

ğ‘’
(cid:76)

(cid:77)

â™¯

ğ‘
(cid:74)

(cid:75)

Theorem 5.6. If Assumption 1 holds, then for all commands ğ‘, we have

let (ğ‘, ğ‘‘, ğ‘‰ ) â‰œ

, we have ğ‘ (ğ‘£) âŠ‡ ğ‘‘ (ğ‘£)ğ‘ and ğ‘‘ (ğ‘£) âŠ‡ ğ‘‰ for all variables ğ‘£ âˆˆ Var.

(cid:75)

ğ‘
(cid:74)

â™¯ âˆˆ Dâ™¯, that is, when we

Example 5.7 (Differentiability). Consider the differentiability property and the example program of
Example 5.5. Let (ğ‘1, ğ‘‘1, ğ‘‰1) and (ğ‘2, ğ‘‘2, ğ‘‰2) be the results of analysing the first assignment command
ğ‘¦ := ğ‘¥ âˆ— ğ‘¥ and the following if command of the program. Then,
(ğ‘1, ğ‘‘1, ğ‘‰1) = (ğœ†ğ‘£.Var, ğœ†ğ‘£. (ğ‘£â‰¡ğ‘¦) ? {ğ‘¥ } : {ğ‘£ }, âˆ…), (ğ‘2, ğ‘‘2, ğ‘‰2) = (ğœ†ğ‘£.{ğ‘¥ }ğ‘, ğœ†ğ‘£. (ğ‘£â‰¡ğ‘ ) ? {ğ‘¥ } : {ğ‘¥, ğ‘£ }, {ğ‘¥ }).
Let (ğ‘, ğ‘‘, ğ‘‰ ) be the analysis result for the entire program. Then,

ğ‘ (ğ‘£) = (cid:0)ğ‘‰1 âˆª (ğ‘1)âˆ© (ğ‘‘2(ğ‘£))ğ‘ âˆª (ğ‘‘1)âˆª (ğ‘2(ğ‘£)ğ‘ )(cid:1)ğ‘

= ğ‘‘1(ğ‘¥)ğ‘ = {ğ‘¥ }ğ‘,

ğ‘‰ = ğ‘‰1 âˆª (ğ‘‘1)âˆª(ğ‘‰2) = {ğ‘¥ }.

Also, ğ‘‘ (ğ‘£) = ğ‘‰1 âˆª (ğ‘‘1)âˆª (ğ‘‘2(ğ‘£)) = (if (ğ‘£ â‰¡ ğ‘ ) then {ğ‘¥ } else {ğ‘¥, ğ‘£ }). As shown in Fig. 3, the variable ğ‘¥
that may affect the condition expression of the if command is removed from the smoothness sets,
and ğ‘ (ğ‘ ) = ğ‘ (ğ‘¦) = {ğ‘¥ }ğ‘ . Note that this result is conservative with respect to ğ‘¦.
â–¡
5.2.2 Analysis soundness and assumptions. The soundness of our analysis states that for every
command ğ‘, its abstract semantics
via ğ›¾:
â™¯). The soundness is conditioned on Assumption 1 and six new assumptions. Most of
ğ‘
(cid:74)
these new assumptions are concerned with the predicate family for the target smoothness property
ğœ™ = (ğœ™ğ¾,ğ¿ : ğ¾, ğ¿ âŠ† Var), and say that certain canonical operators are smooth according to ğœ™ so that
using them in the abstract semantics should not cause an issue. In this subsection, we present the
six assumptions one by one, and sketch how those assumptions are related to the soundness.

â™¯ âˆˆ Dâ™¯ over-approximates the concrete semantics

âˆˆ ğ›¾ (

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

(cid:75)

(cid:75)

(cid:75)

(cid:75)

We start with the assumption that the analysis of each expression

set of variables in which the evaluation of ğ‘’ is smooth.

â™¯ under-approximates the

ğ‘’
(cid:76)

(cid:77)

Assumption 2 (Expression analysis soundness). For all expressions ğ‘’, variables ğ‘¥, subsets
and ğ¿ = {ğ‘¥ }, if we let ğ‘” : St[ğ¾] â†’ St[ğ¿]

ğ¾, ğ¿ âŠ† Var, and states ğœ âˆˆ St[Var \ ğ¾] such that ğ¾ =
be the function defined by ğ‘”(ğœ) â‰œ [ğ‘¥ â†¦â†’
This assumption is used in our soundness argument whenever the abstract semantics uses
computing smoothness information about an expression ğ‘’.

(ğœ âŠ• ğœ)], the function ğ‘” satisfies ğœ™ğ¾,ğ¿ (i.e., ğ‘” âˆˆ ğœ™ğ¾,ğ¿).
ğ‘’
(cid:76)

â™¯ for

ğ‘’
(cid:74)

ğ‘’
(cid:76)

(cid:75)

(cid:77)

(cid:77)

â™¯

The next two assumptions assert the smoothness of the standard operators on the product spaces.

Assumption 3 (Projection). For all ğ¾, ğ¿ âŠ† Var with ğ¾ âŠ‡ ğ¿, the projection ğœ‹ğ¾,ğ¿ satisfies ğœ™ğ¾,ğ¿.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:20

Wonyeol Lee, Xavier Rival, and Hongseok Yang

Assumption 4 (Pairing). For all ğ¾, ğ¿, ğ‘€ âŠ† Var with ğ¿ âˆ© ğ‘€ = âˆ…, if ğ‘“ âˆˆ ğœ™ğ¾,ğ¿ and ğ‘” âˆˆ ğœ™ğ¾,ğ‘€ ,
we have âŸ¨ğ‘“ , ğ‘”âŸ© âˆˆ ğœ™ğ¾,ğ¿âˆªğ‘€ , where âŸ¨ğ‘“ , ğ‘”âŸ© is the pairing of two partial functions: âŸ¨ğ‘“ , ğ‘”âŸ©(ğœ) â‰œ if (ğœ âˆˆ
dom(ğ‘“ ) âˆ© dom(ğ‘”)) then ğ‘“ (ğœ) âŠ• ğ‘”(ğœ) else undefined.
Note that St[ğ¿ âˆª ğ‘€] is isomorphic to St[ğ¿] Ã— St[ğ‘€], the product space that we referred to above.
The assumptions say that the projection is smooth, and the pairing of smooth functions is smooth.
Our analysis uses Assumption 3 to deal with variables not modified by a command. For instance,
when analysing an assignment ğ‘¥ := ğ‘’, the analysis uses Assumption 3 and concludes that on every
output variable ğ‘£ other than ğ‘¥, the assignment is smooth in all the input variables. Assumption 4 is
used to justify the handling of a sequence ğ‘; ğ‘ â€² by our analysis, in particular, the part that the analysis
combines smoothness information over multiple output variables after the first command ğ‘.

The projection and pairing assumptions are about how shrinking and expanding output variables
affect the target smoothness property. The next restriction assumption is about shrinking the input
|= Î¦(ğ‘“ , ğ¾, ğ¿), and is used in the abstract
variables. It validates the weakening of the ğ¾ part of
semantics of ğ‘; ğ‘ â€² (and other composite commands).

Assumption 5 (Restriction). For all ğ¾, ğ¾ â€², ğ¿ âŠ† Var with ğ¾ âŠ‡ ğ¾ â€², and ğœ âˆˆ St[ğ¾ \ ğ¾ â€²], if ğ‘“ âˆˆ ğœ™ğ¾,ğ¿,

then we have ğ‘” âˆˆ ğœ™ğ¾ â€²,ğ¿, where ğ‘”(ğœ) â‰œ if (ğœ âŠ• ğœ âˆˆ dom(ğ‘“ )) then ğ‘“ (ğœ âŠ• ğœ) else undefined.

The following assumption says that the function composition preserves smoothness. It is related

to the chain rule for differentiation, and used to justify the abstract semantics of a sequence ğ‘; ğ‘ â€².

Assumption 6 (Composition). For all ğ¾, ğ¿, ğ‘€ âŠ† Var, if ğ‘“ âˆˆ ğœ™ğ¾,ğ¿ andğ‘” âˆˆ ğœ™ğ¿,ğ‘€ , we haveğ‘”â—¦ğ‘“ âˆˆ ğœ™ğ¾,ğ‘€ ,
where ğ‘” â—¦ ğ‘“ is the standard composition of two partial functions: (ğ‘” â—¦ ğ‘“ )(ğœ) â‰œ if (ğœ âˆˆ dom(ğ‘“ ) âˆ§ ğ‘“ (ğœ) âˆˆ
dom(ğ‘”)) then ğ‘”(ğ‘“ (ğœ)) else undefined.

The final assumption lets the analysis infer smoothness information about the completely-

undefined function. It is used to justify the handling of loops by our analysis.

Assumption 7 (Strictness). For all ğ¾, ğ¿ âŠ† Var, we have (ğœ†ğœ âˆˆ St[ğ¾].undefined) âˆˆ ğœ™ğ¾,ğ¿.
Theorem 5.8 (Soundness). If Assumptions 1â€“7 hold, the analysis computes the sound abstraction

of the concrete semantics of commands in the following sense: for all commands ğ‘,

â™¯).

(cid:75)

ğ‘
(cid:74)

ğ‘
(cid:74)

âˆˆ ğ›¾ (
Remark 2. A standard method for proving a property of a loop or more generally a recursively
defined function is so called Scott induction. In this method, we view a property as a set T of state
transformers and a loop as the least fixed point of a continuous function ğ¹ on state transformers.
Then, we prove the three conditions: (i) T contains the least state transformer, (ii) it is closed under
the least upper bound of any increasing sequence of state transformers, and (iii) T is preserved by ğ¹ .
The first and second conditions are called strictness and admissibility, respectively, and these three
conditions imply that the least fixed point of ğ¹ belongs to T .

(cid:75)

Our soundness proof for the loop case deviates slightly from this standard method. If it followed the
method instead, we would need, in addition to the strictness assumption, the following assumption,
which corresponds to the second admissibility condition:

Assumption 8 (Admissibility). Let ğ¾, ğ¿ âŠ† Var, and order partial functions in [St[ğ¾] â‡€ St[ğ¿]]
by the inclusion of the graphs of partial functions. Then, for every increasing sequence {ğ‘“ğ‘› : St[ğ¾] â‡€
St[ğ¿]}ğ‘› âˆˆN (i.e., the graph of ğ‘“ğ‘›+1 includes that of ğ‘“ğ‘› for all ğ‘› âˆˆ N), if every ğ‘“ğ‘› satisfies ğœ™ğ¾,ğ¿, so does the
least upper bound ğ‘“âˆ of the sequence (defined by its graph being the union of the graphs of all ğ‘“ğ‘›â€™s).
The inclusion of this admissibility assumption would, then, limit the applicability of our program
analysis, since some well-known smoothness properties, such as Lipschitz continuity and local

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:21

boundedness, do not satisfy the assumption, although they satisfy our five assumptions (Assump-
tions 3â€“7). On the plus side, the inclusion of the admissibility assumption could enable our analysis
to handle loops more accurately, possibly by tracking the impact of the boolean condition of each
loop on smoothness more precisely. Our soundness proof avoids the admissibility assumption by
exploiting the conservative handling of loop conditions by our analysis and showing intuitively that
â–¡
it is sufficient to consider chains that converge in a finite number of steps.

5.3 Instantiations
Our program analysis requires that the family of smoothness predicates should satisfy Assump-
tions 3â€“7. Although these assumptions are violated by some smoothness properties, such as partial
differentiability and partial continuity, they are met by our leading example ğœ™ (ğ‘‘) for differentiability
(Example 5.1), and also by the predicate family ğœ™ (ğ‘™) for local Lipschitzness, which is used in our
implementation. Recall the definitions of the predicate families ğœ™ (ğ‘‘) and ğœ™ (ğ‘™) : for all ğ¾, ğ¿ âŠ† Var,
ğœ™ (ğ‘‘)
ğ¾,ğ¿ â‰œ {ğ‘“ : St[ğ¾] â‡€ St[ğ¿] | dom(ğ‘“ ) is open and ğ‘“ is (jointly) differentiable in its domain},
ğœ™ (ğ‘™)
ğ¾,ğ¿ â‰œ {ğ‘“ : St[ğ¾] â‡€ St[ğ¿] | dom(ğ‘“ ) is open, and for all ğœ âˆˆ dom(ğ‘“ ), there are ğ¶ > 0 and

an open ğ‘‚ âŠ† dom(ğ‘“ ) s.t. ğœ âˆˆ ğ‘‚ and âˆ¥ ğ‘“ (ğœ0) âˆ’ ğ‘“ (ğœ1)âˆ¥2 â‰¤ ğ¶ âˆ¥ğœ0 âˆ’ ğœ1âˆ¥2 for all ğœ0, ğœ1 âˆˆ ğ‘‚ }.

Theorem 5.9. Both ğœ™ (ğ‘‘) and ğœ™ (ğ‘™) satisfy Assumptions 3â€“7.

Remark 3. The requirement of open domain in ğœ™ (ğ‘‘) is sometimes too constraining and hurts the
accuracy of the analysis. It can, however, be relaxed, and we can generalise ğœ™ (ğ‘‘) to the following
predicate family ğœ™ (ğ‘‘â€²) , which corresponds to the standard definition of differentiability on a manifold
with boundary in differential geometry [23, Chapter 2]:
ğœ™ (ğ‘‘â€²)
ğ¾,ğ¿ â‰œ {ğ‘“ : St[ğ¾] â‡€ St[ğ¿] | for all ğœ âˆˆ dom(ğ‘“ ), there exist an open ğ‘ˆ âŠ† St[ğ¾] and ğ‘” : ğ‘ˆ â†’ St[ğ¿]

such that ğœ âˆˆ ğ‘ˆ , ğ‘“ = ğ‘” on ğ‘ˆ âˆ© dom(ğ‘“ ), and ğ‘” is (jointly) differentiable}.

Note the weakening of open-domain requirement in ğœ™ (ğ‘‘â€²) : the open domain ğ‘ˆ in the above definition
does not have to be included in dom(ğ‘“ ). The family ğœ™ (ğ‘‘â€²) satisfies Assumptions 3â€“7, and can lead to
a more permissive instantiation of our program analysis than the family ğœ™ (ğ‘‘) , especially in handling
â–¡
atomic commands, such as assignment, sample, and observe.

Remark 4. At this point, the reader might feel that Assumptions 3â€“7 are satisfied by nearly all
smoothness properties. This impression is not accurate. For instance, the composition assumption
does not hold for the notions of differentiability of partial functions formalised by the following
ğœ™ (ğ‘‘â€²â€²) and ğœ™ (pd) , nor for the partial continuity formalised by ğœ™ (pc) :

ğœ™ (ğ‘‘â€²â€²)
ğ¾,ğ¿ â‰œ {ğ‘“ : St[ğ¾] â‡€ St[ğ¿] | ğ‘“ is (jointly) differentiable in the interior of its domain},
ğœ™ (pd)
ğ¾,ğ¿ â‰œ {ğ‘“ : St[ğ¾] â‡€ St[ğ¿] | dom(ğ‘“ ) is open, and for all ğ‘£ âˆˆ ğ¾, ğ‘“ is partially differentiable in ğ‘£ },
ğœ™ (pc)
ğ¾,ğ¿ â‰œ {ğ‘“ : St[ğ¾] â‡€ St[ğ¿] | dom(ğ‘“ ) is open, and for all ğ‘£ âˆˆ ğ¾, ğ‘“ is partially continuous in ğ‘£ }.
Table 1 contains counterexamples that show the failure of the composition assumption for these
predicate families. In fact, when instantiated with these families, our program analysis is not sound.
â–¡
The same table shows example programs and incorrect conclusions derived by our analysis.

6 ALGORITHM FOR THE SPGE VARIABLE-SELECTION PROBLEM
We now put together the results from Â§4 and Â§5 to formally define and soundly (yet approximately)
solve the SPGE variable-selection problem. We start with the formal definition of the problem:

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:22

Wonyeol Lee, Xavier Rival, and Hongseok Yang

ğœ™
ğœ™ (ğ‘‘â€²â€²)
ğ¾,ğ¿
ğœ™ (pd)
ğ¾,ğ¿

, ğœ™ (pc)
ğ¾,ğ¿

ğ‘“
ğ‘“ (ğ‘¥) = ğ‘¥ 2 defined on R
ğ‘“ (ğ‘¥) = (ğ‘¥, ğ‘¥) defined on R

ğ‘”
ğ‘”(ğ‘¥) = 1[ğ‘¥ >0] defined on [0, 1]
ğ‘”(ğ‘¥, ğ‘¦) =

(cid:110) ğ‘¥ğ‘¦/(ğ‘¥ 2 + ğ‘¦2) if (ğ‘¥, ğ‘¦) â‰  (0, 0)
0

otherwise

defined on R2

Table 1. Failure cases of the composition assumption. For each given ğœ™, we have ğ‘“ , ğ‘” âˆˆ ğœ™ but ğ‘” â—¦ ğ‘“ âˆ‰ ğœ™, where
ğ‘“ and ğ‘” are interpreted as (total or partial) functions from St[ğ¾] to St[ğ¿]. Let ğ‘1 â‰¡ (ğ‘¦ = ğ‘¥ 2; ğ‘§ = ğ‘”(ğ‘¦)) and
ğ‘2 â‰¡ (ğ‘¦ = ğ‘¥; ğ‘§ = ğ‘”(ğ‘¥, ğ‘¦)). Then, for each ğ‘–-th ğœ™,
incorrectly concludes that ğ‘§ is smooth with respect to ğ‘¥.

â™¯

ğ‘ğ‘–
(cid:74)

(cid:75)

Definition 6.1 (SPGE Variable-Selection Problem; Formal). Assume we are given a model ğ‘ğ‘š, a guide
ğœ‹ always terminate and
ğ‘ğ‘”, and a (initial) simple reparameterisation plan ğœ‹0 such that ğ‘ğ‘š, ğ‘ğ‘”, and ğ‘ğ‘”
have no double-sampling errors for all ğœ‹ âŠ‘ ğœ‹0. Given these ğ‘ğ‘š, ğ‘ğ‘”, and ğœ‹0, find a reparameterisation
plan ğœ‹ âŠ‘ ğœ‹0 such that (i) ğœ‹ is simple and satisfies (R2) and (R3) in Â§4.2, and (ii) |rv(ğœ‹)| is maximised.
We say that ğœ‹ is a sound solution if it satisfies (i), and an optimal solution if it satisfies (i) and (ii). â–¡

Here we write ğœ‹ âŠ‘ ğœ‹ â€² if the graph of ğœ‹ is included in that of ğœ‹ â€².

The input ğœ‹0 in the problem is a newcomer. It fixes a semantics-preserving transformation for all
the sample commands. Typically, ğœ‹0 is defined on the entire NameEx Ã— DistEx Ã— LamEx, and remains
fixed across all input model-guide pairs (ğ‘ğ‘š, ğ‘ğ‘”). More importantly, it is valid so that the change of
any sample command by ğœ‹0 preserves the semantics of the command when we take into account
both the second distribution argument and the third lambda argument of the sample command. The
validity of ğœ‹0 is inherited by any sound solution ğœ‹ of the SPGE variable-selection problem since
validity as a property on reparameterisation plans is down-closed with respect to the âŠ‘ order. In our
setup, ğœ‹0 is fixed to be the following reparameterisation plan from Â§4.1:
âˆš

ğœ‹0(ğ‘›, distN (ğ‘’1, ğ‘’2), ğœ†ğ‘¦.ğ‘’3) â‰œ (distN (0, 1), ğœ†ğ‘¦.ğ‘’3 [(ğ‘¦ Ã—

ğ‘’2 + ğ‘’1)/ğ‘¦])

(12)

for all ğ‘› âˆˆ NameEx and expressions ğ‘’1, ğ‘’2, and ğ‘’3.

As an example of the SPGE variable-selection problem, consider the problem for the ğœ‹0 in
Eq. (12) and the model-guide pair (ğ‘ğ‘š, ğ‘ğ‘”) given in Fig. 1, where "zi" in the figure is interpreted
as name("zi", 0). Then, as discussed in Â§2, the problem has the following optimal solution: ğœ‹ â‰œ
ğœ‹0|ğ‘†Ã—DistExÃ—LamEx for ğ‘† â‰œ {name(ğ›¼, ğ‘’) âˆˆ NameEx | ğ›¼ (cid:46) "z2"}.

We present an algorithm for computing a sound (yet possibly suboptimal) solution to the problem.

(1) By running our program analysis instantiated with differentiability (described in Â§5.2 and Â§5.3),
â™¯, where we use p, d, and V for the

compute (pğ‘š, dğ‘š, Vğ‘š) â‰œ
output of the analysis to distinguish them from densities ğ‘ and distributions ğ‘‘.

â™¯ and (pğ‘”, dğ‘”, Vğ‘”) â‰œ

ğ‘ğ‘š
(cid:74)

ğ‘ğ‘”
(cid:74)

(cid:75)

(cid:75)

(2) Using pğ‘š and pğ‘”, check

ğœƒ âŠ† ğ¾, where ğ¾ â‰œ pğ‘š (like) âˆ©

(cid:217)

ğœ‡ âˆˆName

pğ‘š (pr ğœ‡) âˆ©

(cid:217)

ğœ‡ âˆˆName

pğ‘” (pr ğœ‡).

(13)

If the check fails, return an error message that our program analysis cannot discharge (R2) for
any ğœ‹, since the analysis concludes that the density function ofğ‘ğ‘š orğ‘ğ‘” can be non-differentiable
in ğœƒ (even when rv(ğœ‹) = âˆ…). If the check passes, initialise the set of reparameterised random
variables by

ğ‘† â‰œ {(ğ›¼, ğ‘–) âˆˆ Name | for all ğ‘– â€² âˆˆ N, (ğ›¼, ğ‘– â€²) âˆˆ Name =â‡’ (ğ›¼, ğ‘– â€²) âˆˆ ğ¾ }.

(3) Using ğ‘† and ğœ‹0, construct a reparameterisation plan ğœ‹ âŠ‘ ğœ‹0 by ğœ‹ â‰œ ğœ‹0 [ğ‘†], where ğœ‹0 [ğ‘†] (ğ‘›, ğ‘‘, ğ‘™)
is ğœ‹0(ğ‘›, ğ‘‘, ğ‘™) if (ğ‘›, ğ‘‘, ğ‘™) âˆˆ dom(ğœ‹0), ğ‘› = name(ğ›¼, _), and (ğ›¼, _) âˆˆ ğ‘†; otherwise, it is undefined.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

(4) By running the differentiability analysis on ğ‘ğ‘”

ğœ‹ , compute (pğ‘”, dğ‘”, Vğ‘”) â‰œ

(cid:217)

ğœƒ âŠ†

ğœ‡ âˆˆName

pğ‘” (pr ğœ‡) âˆ©

(cid:217)

ğœ‡ âˆˆName

pğ‘” (valğœ‡).

ğ‘ğ‘”
(cid:74)

ğœ‹

â™¯ and check

(cid:75)

0:23

(14)

If the check passes, return ğœ‹ as the output of the algorithm. If not, updateğ‘† byğ‘† \{(ğ›¼, ğ‘–) âˆˆ Name}
after choosing some (ğ›¼, _) âˆˆ ğ‘†, and then repeat the above procedure (from the step (3), the
point where we construct ğœ‹ using ğ‘†) until ğ‘† becomes empty.

Our algorithm computes a sound solution, because of the soundness of our program analysis:

Theorem 6.2. Let ğ‘ğ‘š, ğ‘ğ‘”, and ğœ‹0 be the inputs to the SPGE variable-selection problem. If the above

algorithm returns ğœ‹ for (ğ‘ğ‘š, ğ‘ğ‘”, ğœ‹0), then ğœ‹ is a sound solution for the problem.

Our algorithm solves the problem only approximately: there is no formal guarantee that it al-
ways computes an optimal solution. The suboptimality may arise due to two approximations: the
overapproximation of our program analysis when it computes differentiability information, and the
heuristic choices made by our algorithm when the algorithm computes the random-variable set ğ‘†.
We demonstrate, however, that our algorithm finds optimal solutions for all the benchmarks in Â§7.
Our algorithm calls our program analysis at most |{ğ›¼ âˆˆ Str | (ğ›¼, _) âˆˆ ğ‘†0}| + 2 times, where ğ‘†0
is the initial value of ğ‘† (i.e., the set of random variables whose sample commands are to be trans-
formed) in the algorithm. However, for all the benchmarks in Â§7, our algorithm terminated with the
initial set ğ‘†0 and thus called our smoothness analysis only 3 times (on the model, the guide, and the
reparameterised guide according to ğ‘†0).

7 EXPERIMENTAL EVALUATION AND RELATED WORKS
In our experiments, we consider two research questions. First, can the analysis proposed in Â§5 be
instantiated and implemented so that it can produce meaningful smoothness results on real-world
probabilistic programs? Second, can the algorithm proposed in Â§6 find near-optimal solutions to the
SPGE variable-selection problem on real-world probabilistic programs? To assess the two questions,
we have implemented a static smoothness analyser for Pyro programs based on Â§5, and a variable
selector based on Â§6 which (approximately) solves the variable-selection problem. Our analyser
and variable selector are implemented in OCaml, and support a subset of the Pyro PPL and two
smoothness properties: differentiability and local Lipschitzness.

Implementation. Although the analysis described in Â§5 may look simple when considering a basic
PPL, real-world PPLs such as Pyro are of a much higher degree of complexity. First, they provide
a large panel of continuous/discrete probability distributions for sample and observe commands, and
library functions for tensors and neural networks. Second, programs in real-world PPLs may fail to be
smooth for reasons other than if-else and while commands. In particular, values sampled from discrete
distributions, and arguments to operators and distribution constructors that are well-defined only on
a strict subset of values, may induce non-smoothness. A straightforward treatment of these will result
in an overly conservative analysis, treating far too many variables as potentially non-smooth. Third,
Pyro programs typically rely on tensors (of large, statically unknown size) to deal with large datasets,
and it is generally infeasible to reason about each (real-valued) element of tensors individually. In
the following, we discuss how our static analyser addresses these issues and provides sound, useful
information about smoothness of Pyro programs.
Distributions and library functions. Our analyser supports 17 distributions (continuous or discrete).
Each distribution is characterized by a pair (ğ‘, ğ‘) for a boolean ğ‘ and an array of booleans ğ‘, where
ğ‘ (or ğ‘ğ‘– ) denotes whether its probability density is differentiable or locally Lipschitz with respect
to the sampled value (or the ğ‘–-th argument) of the distribution. For example, a normal distribution

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Wonyeol Lee, Xavier Rival, and Hongseok Yang

0:24

Name

Probabilistic model
Splitting normal example in Fig. 1

Deep Markov model
Hidden Markov models

spnor
sgdef Deep exponential family
dmm
mhmm
scanvi Single-cell annotation using variational inference
air
cvae

Attend-infer-repeat
Conditional variational autoencoder

LoC while sam obs param
2
12
13
12
21
16
15

16
105
112
137
147
174
205

2
12
2
5
7
6
2

1
1
1
5
2
1
1

0
0
3
1
0
2
0

Table 2. Subset of Pyro examples used in experiments and their key features (see Â§I for the rest). The last
five columns show the total number of code lines (excluding comments), loops, sample commands, observe
commands, and learnable parameters (declared explicitly by pyro.param or implicitly by a neural network
module). Each number is the sum of the counts in the model and guide.

is described by (true,[true,true]) (assuming that the second argument is positive) and a Poisson
distribution by (false,[true]). Similarly, the analyser supports a large number of PyTorch/Pyro
library functions for tensors and neural networks, and assumes the correct smoothness information
about them. For instance, the ReLU function is considered locally Lipschitz but not differentiable.
Refining smoothness information based on safety pre-analysis. Although the expression x/y is generally
non-smooth with respect to y (even if it is well-defined for y=0), if more information is available, for
instance that y always lies in range [1, 10], we can safely consider it smooth with respect to both x and
y. Likewise, the density of a normal distribution is generally non-smooth with respect to the standard
deviation argument ğœ (even if it is well-defined for ğœ â‰¤ 0), so more precise smoothness information
can be produced when ğœ is known to be always positive. Thus, establishing precise smoothness
information requires to first establish safety properties related to program operations. To achieve
this, our tool actually performs two analyses in sequence: (i) a safety pre-analysis infers ranges over
all numerical variables and marks each argument to an operator or a distribution constructor as
either â€œsafeâ€ or â€œpotentially unsafeâ€; (ii) the smoothness analysis formalised in Â§5 utilises information
computed in the first phase to produce precise smoothness information. The first phase boils down
to a forward abstract interpretation based on basic abstract domains like intervals and signs [10].
It logs safety information for each program statement just like static analyses for runtime errors and
undefined behaviors [3]. As formalised in Â§5.2, the second analysis is compositional. Due to their
different nature, the two analyses need to be done in sequence.
Tensors. Pyro programs commonly use nested loops and indexed tensors. As the number of dimensions
of such tensors is often statically unknown, enumerating all dimensions is not feasible; so we rely on
a conservative summarisation of tensor dimensions. Intuitively, this means that when density might
not be smooth with respect to one dimension of a tensor, the analysis conservatively concludes that
it might not be smooth with respect to any dimension. In our experiments, this abstraction does not
result in any precision loss.

Evaluation. We evaluated our analyser and variable selector on 13 representative Pyro examples
from the Pyro webpage [42] that use standard SVI engines and contain explicitly written model-
guide pairs (without AutoGuide). They include advanced models with deep neural networks such
as attend-infer-repeat [12] and single-cell annotation using variational inference [49]. Additionally,
we included the example in Fig. 1, for which Pyro offers an unsound reparameterisation plan. Table 2
lists half of these 14 Pyro examples with their code size and conceptual complexity (see Â§I for the
rest). Experiments were performed on a Macbook Pro with 2.3GHz Core i9 and 32GB RAM.
Smoothness analyser. We assess our smoothness analyser on the 14 Pyro examples for differentiability
and local Lipschitzness (Â§5.3), and show a subset of results in Table 3 (see Â§I for the rest). The results

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:25

Differentiable

Locally Lipschitz

Name

spnor-m
spnor-g
sgdef-m
sgdef-g
dmm-m
dmm-g
mhmm-m
mhmm-g
scanvi-m
scanvi-g
air-m
air-g
cvae-m
cvae-g

Manual Ours Time Manual Ours Time
0.009
0.008
0.006
0.015
0.016
0.020
0.075
0.008
0.032
0.058
0.105
0.072
0.027
0.023

0.006
0.007
0.003
0.016
0.014
0.026
0.063
0.007
0.032
0.052
0.108
0.075
0.025
0.031

1
4
6
18
10
5
10
6
12
15
4
15
8
9

1
4
6
18
10
5
10
6
12
15
4
15
8
9

1
4
6
18
4
4
10
6
6
8
1
3
3
5

1
4
6
18
4
4
10
6
6
8
1
3
3
5

#CRP
2
4
6
18
10
5
10
6
12
15
4
16
8
9

Table 3. Results of smoothness analyses. â€œManualâ€ and â€œOursâ€ denote the number of continuous random
variables and learnable parameters in which the density of the program is smooth, computed by hand and
by our analyser. â€œTimeâ€ denotes the runtime of our analyser in seconds. â€œ#CRPâ€ denotes the total number
of continuous random variables and learnable parameters in the program. -m and -g denote model and guide.
We consider {(ğ›¼, ğ‘–) âˆˆ Name} as one random variable for each ğ›¼ âˆˆ Name.

demonstrate that our analysis can cope successfully with real-world Pyro programs. First, our analysis
is accurate. For all examples, the analysis identifies the exact ground-truth set of random variables
and parameters in which the density of the program is differentiable (or locally Lipschitz). In many of
them, information computed by the pre-analysis is required to achieve these exact results; e.g., some
examples (e.g., dpmm and air) require precise information about which distribution arguments can be
proved to be always in the proper range of values. Second, the runtime of our analysis is low. Typical
probabilistic programming applications are not of a very large size, and conceptual complexity is
generally the main issue, thus the analysis performance presents no scalability concern.

We draw two more observations from the results. First, for spnor-m and air-g, the density of each
program is not locally Lipschitz in one continuous random variable. These non-local-Lipschitznesses
arise as follows: for the former, the random variable ("z2" in Fig. 1) is used in the branch condition
of an if-else command that contains observe commands, thereby creating discontinuity; and for the
latter, the random variable ("z_where") is passed into the denominator of a division operator, thereby
causing a division-by-zero error for some value.

Second, for all the other examples, the density is locally Lipschitz in all continuous random vari-
ables and parameters, but is often non-differentiable in many parameters (and continuous random
variables too); see, for instance, scanvi and cvae. Due to this, the requirement (R2) is not satisfied for
these examples even with the empty reparameterisation plan (corresponding to the score estimator);
that is, if we use the differentiability requirements (R2) and (R3) to validate the unbiasedness of
gradient estimators, even the score estimator cannot be validated for these examples. From manual
inspection, we checked that the non-differentiabilities from these examples all arise by the use of
locally Lipschitz but non-differentiable operators (e.g., relu and grid_sample). Since many practical
models (and guides) use locally Lipschitz but non-differentiable operators, this observation strongly
suggests that a right smoothness requirement for validating gradient estimators is not differentiability
(which has been used as a standard requirement), but rather local Lipschitzness (e.g., (R2â€™) and (R3â€™)).
Variable selector. To evaluate our variable selector, we consider the SPGE variable-selection problem
with local Lipschitzness requirements, i.e., the problem that uses (R2â€™) and (R3â€™) in Â§4.3 instead of
(R2) and (R3) in Â§4.2. We do not consider the original problem (with differentiability requirements),

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:26

Wonyeol Lee, Xavier Rival, and Hongseok Yang

Ours

Time
0.021
0.034
0.054
0.083
0.143
0.247
0.063

Sound
1
6
1
2
3
1
1

Pyro \ Ours
Sound Unsound
1
0
0
0
0
1
0

0
0
0
0
0
0
0

#CR #DR
0
0
0
1
1
2
0

2
6
1
2
3
2
1

Name

spnor
sgdef
dmm
mhmm
scanvi
air
cvae

Table 4. Results of variable selections. â€œOurs-Timeâ€ denote the runtime of our variable selector in seconds.
â€œOurs-Soundâ€ and â€œPyro \ Oursâ€ denote the number of random variables in the example that are in ğœ‹ours, and
that are in ğœ‹0 but not in ğœ‹ours, respectively, where ğœ‹ours and ğœ‹0 denote the reparameterisation plans given by
our variable selector and by Pyro. â€œPyro \ Oursâ€ is partitioned into â€œSoundâ€ and â€œUnsoundâ€: the latter denotes
the number of random variables that make (R2â€™) or (R3â€™) violated when added to ğœ‹ours, and the former denotes
the number of the rest. â€œ#CRâ€ and â€œ#DRâ€ denote the total number of continuous and discrete random variables
in the example. We consider {(ğ›¼, ğ‘–) âˆˆ Name} as one random variable for each ğ›¼ âˆˆ Name.

since for many examples the differentiability requirements are not satisfied even by the empty
reparameterisation plan (i.e., score estimator) as observed above. For an initial reparameterisation
plan ğœ‹0 for the problem, we use the plan given by Pyroâ€™s default variable selector: it is defined for
all continuous random variables and applies standard reparameterisations (e.g., Eq. (12) for a normal
distribution). In this settings, we apply our variable selector to the problem on the 14 Pyro examples.
Table 4 displays the results (only for 7 examples; see Â§I for the rest) and compares them with ğœ‹0.

The results demonstrate that for all examples, our variable selector finds the optimal reparameterisa-
tion plan with a small runtime. We also observe that for all cases, it terminates in the first iteration and
calls our smoothness analyser only three times, as mentioned in Â§6. Note that the reparameterisation
plan given by Pyro is also optimal for all but two examples. We emphasise, however, that our variable
selector not only finds a reparameterisation plan but also verifies the local Lipschitzness requirements
(R2â€™) and (R3â€™), whereas Pyroâ€™s default variable selector does not do so. Indeed, for two examples,
Pyroâ€™s reparameterisation plan is unsound as it violates the local Lipschitzness requirements. Hence,
these results should be interpreted as: for all but two examples, our variable selector (and smoothness
analyser) successfully validate the unbiasedness of the default gradient estimator used by Pyro.

The two examples for which Pyro becomes unsound are spnor and air. Recall that they have two
continuous random variables (one for each) in which their densities are not locally Lipschitz. The
unsoundness of Pyro on these examples stems precisely from the fact that it reparameterises the
two non-locally-Lipschitz random variables without checking any local Lipschitzness requirements.

Related Work. The high-level idea of using program transformation for improved posterior in-
ference and model learning in PPLs has been explored previously [8, 17, 30, 35, 37]. In particular,
Schulman et al. [37] proposed a method for implementing the SPGE for stochastic computation graphs
via graph transformation, and this method was adopted in the implementation of the same estimator
in Pyro and also in our work. However, the method lacks a formal analysis on the implemented
estimator especially in the context of probabilistic programs; it does not have a version of Theorem 4.4,
which formally identifies requirements for the unbiasedness of the estimator. Also, the method does
not check the required smoothness properties of given probabilistic programs. Our work fills in these
gaps. Gorinova et al. [17] proposed an automatic technique to transform models in a PPL using the
same or closely-related transformation of sample commands in the SPGE. The work is, however,
concerned with transforming models and taming their posterior distributions, while ours focuses on
transforming guides. Also, the work does not check smoothness properties of transformed models that

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:27

are required for running efficient inference algorithms, such as Hamiltonian Monte Carlo, on those
models, while our work checks those properties using our program analysis. We also point out that
program analyses or type systems for probabilistic programs have been developed to detect common
errors [24, 25] or infer important probabilistic properties, such as conditional independence [18].

The smoothness properties computed by our program analysis, such as differentiability and local
Lipschitzness, fall in the scope of hyperliveness in the hierarchy of hyperproperties [9]. Intuitively,
hyperliveness properties are those that cannot be refuted based on any finite counterexample (i.e.,
made of finitely-many finite execution traces), and counterexamples for differentiability and local
Lipschitzness should indeed require infinitely-many execution traces due to the use of limit or all
neighbouring inputs in their definitions. Not so many analyses have considered such hyperliveness
properties. Among those, the most relevant to our work are the continuity analyses of Chaudhuri
et al. [6, 7]. It uses a program abstraction that is rather similar to ours, but their analyses suffer from
soundness issues, due to the incorrect joining of continuity sets [6] and also to an unsound rule for
sequential composition [7] (see Â§A.1 for details). We do not claim that these issues are difficult to
fix. Our point is just that developing program analyses for smoothness properties requires special
care. Chaudhuri et al.â€™s work focuses on proving smoothness properties of control software, or
revealing the unexpected continuity of discrete algorithms. On the other hand, our program analysis
is designed to assist variational inference and model learning for probabilistic programs.

ACKNOWLEDGMENTS
We thank Hangyeol Yu for helping us prove an initial version of Theorems 4.2 and 4.4. Lee was
supported by Samsung Scholarship. Yang was supported by the Engineering Research Center Program
through the National Research Foundation of Korea (NRF) funded by the Korean Government MSIT
(NRF-2018R1A5A1059921) and also by the Institute for Basic Science (IBS-R029-C1).

REFERENCES
[1] Martin Arjovsky, Soumith Chintala, and LÃ©on Bottou. Wasserstein generative adversarial networks. In International

Conference on Machine Learning (ICML), pages 214â€“223, 2017.

[2] Eli Bingham, Jonathan P. Chen, Martin Jankowiak, Fritz Obermeyer, Neeraj Pradhan, Theofanis Karaletsos, Rohit Singh,
Paul A. Szerlip, Paul Horsfall, and Noah D. Goodman. Pyro: Deep universal probabilistic programming. Journal of
Machine Learning Research, 20(28):1â€“6, 2019.

[3] B. Blanchet, P. Cousot, R. Cousot, J. Feret, L. Mauborgne, A. MinÃ©, D. Monniaux, and X. Rival. A Static Analyzer for
Large Safety Critical Software. In Programming Languages, Design and Implementation (PLDI), pages 196â€“207, 2003.
[4] Bob Carpenter, Andrew Gelman, Matthew Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker,
Jiqiang Guo, Peter Li, and Allen Riddell. Stan: A probabilistic programming language. Journal of Statistical Software,
76(1):1â€“32, 2017.

[5] Arun Tejasvi Chaganty, Aditya V. Nori, and Sriram K. Rajamani. Efficiently sampling probabilistic programs via program

analysis. In Artificial Intelligence and Statistics (AISTATS), pages 153â€“160, 2013.

[6] Swarat Chaudhuri, Sumit Gulwani, and Roberto Lublinerman. Continuity analysis of programs.

In Principles of

Programming Languages (POPL), pages 57â€“70, 2010.

[7] Swarat Chaudhuri, Sumit Gulwani, and Roberto Lublinerman. Continuity and robustness of programs. Commun. ACM,

55(8):107â€“115, 2012.

[8] Guillaume Claret, Sriram K. Rajamani, Aditya V. Nori, Andrew D. Gordon, and Johannes BorgstrÃ¶m. Bayesian inference

using data flow analysis. In Foundations of Software Engineering (FSE), pages 92â€“102, 2013.

[9] M. R. Clarkson and F. B. Schneider. Hyperproperties. In Computer Security Foundations (CSF), pages 51â€“65, 2008.
[10] Patrick Cousot and Radhia Cousot. Abstract interpretation: A unified lattice model for static analysis of programs

by construction or approximation of fixpoints. In Principles of Programming Languages (POPL), pages 238â€“252, 1977.

[11] Patrick Cousot and Radhia Cousot. Systematic design of program analysis frameworks. In Principles of Programming

Languages (POPL), pages 269â€“282, 1979.

[12] S. M. Ali Eslami, Nicolas Heess, Theophane Weber, Yuval Tassa, David Szepesvari, Koray Kavukcuoglu, and Geoffrey E.
Hinton. Attend, Infer, Repeat: Fast Scene Understanding with Generative Models. In Neural Information Processing
Systems (NIPS), pages 3233â€“3241, 2016.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:28

Wonyeol Lee, Xavier Rival, and Hongseok Yang

[13] Hong Ge, Kai Xu, and Zoubin Ghahramani. Turing: A language for flexible probabilistic inference.

In Artificial

Intelligence and Statistics (AISTATS), pages 1682â€“1690, 2018.

[14] Timon Gehr, Sasa Misailovic, and Martin T. Vechev. PSI: exact symbolic inference for probabilistic programs.

In

Computer Aided Verification (CAV), pages 62â€“83, 2016.

[15] Noah Goodman, Vikash Mansinghka, Daniel M Roy, Keith Bonawitz, and Joshua B Tenenbaum. Church: a language

for generative models. In Uncertainty in Artificial Intelligence (UAI), pages 220â€“229, 2008.

[16] Andrew D. Gordon, Thore Graepel, Nicolas Rolland, Claudio Russo, Johannes Borgstrom, and John Guiver. Tabular: A
schema-driven probabilistic programming language. In Principles of Programming Languages (POPL), pages 321â€“334, 2014.
[17] Maria I. Gorinova, Dave Moore, and Matthew D. Hoffman. Automatic reparameterisation of probabilistic programs.

In International Conference on Machine Learning (ICML), pages 3648â€“3657, 2020.

[18] Maria I. Gorinova, Andrew D. Gordon, Charles Sutton, and Matthijs VÃ¡kÃ¡r. Conditional independence by typing. ACM

Trans. Program. Lang. Syst., 44(1):4:1â€“4:54, 2022.

[19] Steven Holtzen, Guy Van den Broeck, and Todd D. Millstein. Scaling exact inference for discrete probabilistic programs.

Proc. ACM Program. Lang., 4(OOPSLA):140:1â€“140:31, 2020.

[20] Hyunjik Kim, George Papamakarios, and Andriy Mnih. The lipschitz constant of self-attention.

In International

Conference on Machine Learning (ICML), pages 5562â€“5571, 2021.

[21] Diederik P. Kingma and Max Welling. Auto-Encoding Variational Bayes. In International Conference on Learning

Representations (ICLR), 2014.

[22] Alp Kucukelbir, Rajesh Ranganath, Andrew Gelman, and David M. Blei. Automatic variational inference in stan. In

Neural Information Processing Systems (NIPS), pages 568â€“576, 2015.

[23] John M. Lee. Introduction to Smooth Manifolds. Graduate Texts in Mathematics. Springer, second edition, 2012.
[24] Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang. Towards verified stochastic variational inference for

probabilistic programs. Proc. ACM Program. Lang., 4(POPL):16:1â€“16:33, 2020.

[25] Alexander K. Lew, Marco F. Cusumano-Towner, Benjamin Sherman, Michael Carbin, and Vikash K. Mansinghka. Trace
types and denotational semantics for sound programmable inference in probabilistic languages. Proc. ACM Program.
Lang., 4(POPL):19:1â€“19:32, 2020.

[26] Vikash K. Mansinghka, Daniel Selsam, and Yura N. Perov. Venture: a higher-order probabilistic programming platform

with programmable inference. arXiv:1404.0099, 2014.

[27] T. Minka, J.M. Winn, J.P. Guiver, S. Webster, Y. Zaykov, B. Yangel, A. Spengler, and J. Bronskill. Infer.NET 2.6, 2014.

Microsoft Research Cambridge. http://research.microsoft.com/infernet.

[28] Praveen Narayanan, Jacques Carette, Wren Romano, Chung-chieh Shan, and Robert Zinkov. Probabilistic inference by
program transformation in hakaru (system description). In Functional and Logic Programming (FLOPS), pages 62â€“79, 2016.

[29] Radford M. Neal. MCMC using Hamiltonian dynamics. Handbook of Markov Chain Monte Carlo, 54:113â€“162, 2010.
[30] Aditya V. Nori, Chung-Kil Hur, Sriram K. Rajamani, and Selva Samuel. R2: an efficient MCMC sampler for probabilistic

programs. In AAAI Conference on Artificial Intelligence (AAAI), pages 2476â€“2482, 2014.

[31] AndrÃ© Platzer. Logical Foundations of Cyber-Physical Systems. Springer, 2018. ISBN 978-3-319-63587-3.
[32] Rajesh Ranganath, Sean Gerrish, and David M. Blei. Black box variational inference. In Artificial Intelligence and

Statistics (AISTATS), pages 814â€“822, 2014.

[33] Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic Backpropagation and Approximate Inference

in Deep Generative Models. In International Conference on Machine Learning (ICML), 2014.

[34] Daniel Ritchie, Paul Horsfall, and Noah D. Goodman. Deep amortized inference for probabilistic programs.

arXiv:1610.05735, 2016.

[35] Daniel Ritchie, Andreas StuhlmÃ¼ller, and Noah D. Goodman. C3: lightweight incrementalized MCMC for probabilistic
programs using continuations and callsite caching. In Artificial Intelligence and Statistics (AISTATS), pages 28â€“37, 2016.
[36] John Salvatier, Thomas V. Wiecki, and Christopher Fonnesbeck. Probabilistic programming in python using pymc3.

PeerJ Comput. Sci., 2:e55, 2016.

[37] John Schulman, Nicolas Heess, Theophane Weber, and Pieter Abbeel. Gradient estimation using stochastic computation

graphs. In Neural Information Processing Systems (NIPS), pages 3528â€“3536, 2015.

[38] N. Siddharth, Brooks Paige, Jan-Willem van de Meent, Alban Desmaison, Noah D. Goodman, Pushmeet Kohli, Frank
Wood, and Philip Torr. Learning disentangled representations with semi-supervised deep generative models. In Neural
Information Processing Systems (NIPS), pages 5927â€“5937, 2017.

[39] David Tolpin, Jan-Willem van de Meent, Hongseok Yang, and Frank D. Wood. Design and implementation of probabilistic
programming language anglican. In Implementation and Application of Functional Programming Languages (IFL), pages
6:1â€“6:12, 2016.

[40] Dustin Tran, Alp Kucukelbir, Adji B. Dieng, Maja R. Rudolph, Dawen Liang, and David M. Blei. Edward: A library for

probabilistic modeling, inference, and criticism. arXiv:1610.09787, 2016.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:29

[41] Dustin Tran, Matthew D. Hoffman, Dave Moore, Christopher Suter, Srinivas Vasudevan, and Alexey Radul. Simple,
distributed, and accelerated probabilistic programming. In Neural Information Processing Systems (NeurIPS), pages
7609â€“7620, 2018.

[42] Uber AI Labs. Pyro examples. http://pyro.ai/examples/, 2022. Version used: June 18, 2022.
[43] Jan-Willem van de Meent, Brooks Paige, Hongseok Yang, and Frank Wood. An introduction to probabilistic programming.

arXiv:1809.10756, 2018.

[44] Ronald J. Williams. Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning.

Machine Learning, 8(3-4):229â€“256, 1992.

[45] David Wingate and Theophane Weber. Automated variational inference in probabilistic programming. arXiv:1301.1299,

2013.

[46] David Wingate, Noah D. Goodman, Andreas StuhlmÃ¼ller, and Jeffrey Mark Siskind. Nonstandard interpretations of
probabilistic programs for efficient inference. In Neural Information Processing Systems (NIPS), pages 1152â€“1160, 2011.
[47] David Wingate, Andreas StuhlmÃ¼ller, and Noah D. Goodman. Lightweight implementations of probabilistic programming
languages via transformational compilation. In Artificial Intelligence and Statistics (AISTATS), pages 770â€“778, 2011.
[48] Frank Wood, Jan Willem van de Meent, and Vikash Mansinghka. A new approach to probabilistic programming

inference. In Artificial Intelligence and Statistics (AISTATS), pages 1024â€“1032, 2014.

[49] Chenling Xu, Romain Lopez, Edouard Mehlman, Jeffrey Regier, Michael I Jordan, and Nir Yosef. Probabilistic
harmonization and annotation of single-cell transcriptomics data with deep generative models. Molecular systems
biology, 17(1):e9620, 2021.

[50] Yuan Zhou, Hongseok Yang, Yee Whye Teh, and Tom Rainforth. Divide, conquer, and combine: a new inference strategy
for probabilistic programs with stochastic support. In International Conference on Machine Learning (ICML), pages
11534â€“11545, 2020.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:30

Wonyeol Lee, Xavier Rival, and Hongseok Yang

A DEFERRED RESULTS IN Â§1

A.1 Unsoundness of continuity analyses in [6, 7]
The continuity analysis in [6] considers joint continuity, whereas the continuity analysis in [7]
considers partial continuity. That is, given a command ğ‘, an output variable ğ‘£ of ğ‘, and some input
variables ğ‘¢1, . . . , ğ‘¢ğ‘š to ğ‘, the former analyses whether ğ‘£ is continuous in {ğ‘¢1, . . . , ğ‘¢ğ‘š } jointly, whereas
the latter analyses whether ğ‘£ is continuous in ğ‘¢ğ‘– separately for every 1 â‰¤ ğ‘– â‰¤ ğ‘š.

The former analysis contains the rule called Join [6, Figure 3] and the latter analysis contains the
rule called Sequence [7, Figure 1]. The two rules can be rewritten (with some simplifications) as
follows, in terms of functions between Rğ‘›: for any ğ‘“ , ğ‘” : Rğ‘› â†’ Rğ‘› and ğ‘†, ğ‘† â€²,ğ‘‡ , ğ‘ˆ âŠ† {1, . . . , ğ‘›},

For each ğ‘— âˆˆ ğ‘‡ , ğ‘“ğ‘— is continuous in {ğ‘¥ğ‘– | ğ‘– âˆˆ ğ‘† }
For each ğ‘— âˆˆ ğ‘‡ , ğ‘“ğ‘— is continuous in {ğ‘¥ğ‘– | ğ‘– âˆˆ ğ‘† â€²}
For each ğ‘— âˆˆ ğ‘‡ , ğ‘“ğ‘— is continuous in {ğ‘¥ğ‘– | ğ‘– âˆˆ ğ‘† âˆª ğ‘† â€²}

(Join)

For each ğ‘— âˆˆ ğ‘‡ , ğ‘“ğ‘— is continuous in ğ‘¥ğ‘– for each ğ‘– âˆˆ ğ‘†
For each ğ‘˜ âˆˆ ğ‘ˆ , ğ‘”ğ‘˜ is continuous in ğ‘¦ ğ‘— for each ğ‘— âˆˆ ğ‘‡
For each ğ‘˜ âˆˆ ğ‘ˆ , (ğ‘” â—¦ ğ‘“ )ğ‘˜ is continuous in ğ‘¥ğ‘– for each ğ‘– âˆˆ ğ‘†

(Sequence)

where ğ‘“ and ğ‘” are functions of variables ğ‘¥1, . . . , ğ‘¥ğ‘› and ğ‘¦1, . . . , ğ‘¦ğ‘›, respectively, and â„ğ‘– â‰œ projğ‘– â—¦ â„ for
â„ : Rğ‘› â†’ Rğ‘› and ğ‘– âˆˆ {1, . . . , ğ‘›} denotes the ğ‘–-th component of â„. As mentioned above, the Join rule
analyses joint continuity, while the Sequence rule analyses partial continuity. Further, the Join rule
says that joint continuity is preserved under the union of input variables, while the Sequence rule
says that partial continuity is preserved under the composition of functions.

The two rules, however, are unsound with the following counterexamples. Let â„ : R2 â†’ R2 be

the function

(cid:40)

â„(ğ‘¥1, ğ‘¥2) â‰œ

1 + ğ‘¥ 2

2), ğ‘¥2)

(ğ‘¥1ğ‘¥2/(ğ‘¥ 2
(0, ğ‘¥2)

if (ğ‘¥1, ğ‘¥2) â‰  (0, 0)
otherwise.

Note that â„1 is continuous in ğ‘¥1 and in ğ‘¥2 separately, but not in {ğ‘¥1, ğ‘¥2} jointly. First, for the Join rule,
consider the following ğ‘“ : R2 â†’ R2 and ğ‘†, ğ‘† â€²,ğ‘‡ âŠ† {1, 2}:

ğ‘“ (ğ‘¥1, ğ‘¥2) â‰œ â„(ğ‘¥1, ğ‘¥2),

ğ‘† â‰œ {1},

ğ‘† â€² â‰œ {2},

ğ‘‡ â‰œ {1, 2}.

Then, the premise of the Join rule holds, so the conclusion of the rule must hold. But this is not the case
since ğ‘“1 = â„1 is not continuous in {ğ‘¥1, ğ‘¥2}. Hence, the Join rule is unsound. Next, for the Sequence
rule, consider the following ğ‘“ , ğ‘” : R2 â†’ R2 and ğ‘†,ğ‘‡ , ğ‘ˆ âŠ† {1, 2}:

ğ‘“ (ğ‘¥1, ğ‘¥2) â‰œ (ğ‘¥1, ğ‘¥1),

ğ‘”(ğ‘¥1, ğ‘¥2) â‰œ â„(ğ‘¥1, ğ‘¥2),

ğ‘† â‰œ ğ‘‡ â‰œ ğ‘ˆ â‰œ {1, 2}.

Then, the premise of the Sequence rule holds, so the conclusion of the rule must hold. But this is not
the case since (ğ‘” â—¦ ğ‘“ )1 is not continuous in ğ‘¥1 (due to (ğ‘” â—¦ ğ‘“ )1(ğ‘¥1, ğ‘¥2) = 1[ğ‘¥1â‰ 0] Â· 1
2 ). Hence, the Sequence
rule is unsound. These counterexamples show that joint continuity is not preserved under the union
of input variables, and partial continuity is not preserved under the composition of functions.

The two aforementioned counterexamples can be easily translated into programs: the first becomes
ğ‘1 â‰¡ (ğ‘§ := â„1(ğ‘¥, ğ‘¦)) and the second becomesğ‘2 â‰¡ (ğ‘¦ := ğ‘¥; ğ‘§ := â„1(ğ‘¥, ğ‘¦)), where ğ‘¥,ğ‘¦, andğ‘§ are program
variables and â„1 is the binary operator defined above. The analysis in [6] deduces that in ğ‘1, ğ‘§ is con-
tinuous in ğ‘¥ and ğ‘¦ (jointly), and the analysis in [7] deduces that in ğ‘2, ğ‘§ is continuous in ğ‘¥ (separately).
Both deductions, however, are incorrect as seen above, and the two analyses are thus unsound.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:31

ğ‘ğœƒ (ğ‘§)

ğ‘”ğœƒ (ğ‘§)

SCE

PGE

ğ‘ğ‘ğ‘”,ğœƒ (ğ‘§)
ğ‘“ğœƒ (ğ‘§) Â· âˆ‡ğœƒ log ğ‘ğœƒ (ğ‘§) âˆ‡ğœƒ ğ‘“ğœƒ (ğ‘§ â€²)

ğ‘” (ğ‘§)

ğ‘ğ‘â€²

requirements

ğ‘ğ‘ğ‘”,ğœƒ (ğ‘§): diff. in ğœƒ

for ğ‘§ â€² = ğ‘£ğ‘â€²

ğ‘”,ğœƒ (ğ‘§)

â€”
ğ‘ğ‘ğ‘š (ğ‘§): diff. in ğœƒ and ğ‘§
ğ‘ğ‘ğ‘”,ğœƒ (ğ‘§): diff. in ğœƒ and ğ‘§
ğ‘£ğ‘â€²

ğ‘”,ğœƒ (ğ‘§): diff. in ğœƒ

SPGE

ğ‘ğ‘â€²â€²

ğ‘”,ğœƒ (ğ‘§)

âˆ‡ğœƒ ğ‘“ğœƒ (ğ‘§ â€²â€²) + ğ‘“ğœƒ (ğ‘§ â€²â€²) Â· âˆ‡ğœƒ log ğ‘â€²â€²
ğ‘”,ğœƒ (ğ‘§)

ğœƒ (ğ‘§)

for ğ‘§ â€²â€² = ğ‘£ğ‘â€²â€²
ğ‘”,ğœƒ (ğ‘§): diff. in ğœƒ

ğ‘ğ‘â€²â€²
ğ‘ğ‘ğ‘š (ğ‘§): diff. in ğœƒ and changed ğ‘§ğ‘– â€™s
ğ‘ğ‘ğ‘”,ğœƒ (ğ‘§): diff. in ğœƒ and changed ğ‘§ğ‘– â€™s
ğ‘£ğ‘â€²â€²

ğ‘”,ğœƒ (ğ‘§): diff. in ğœƒ

Table 5. Gradient estimators for variational inference. â€œdiff.â€ denotes â€œdifferentiableâ€.

B DEFERRED RESULTS IN Â§2

B.1 Table Summarising Â§2
Table 5 compares key aspects of the three gradient estimators (SCE, PGE, and SPGE) explained in Â§2.

C DEFERRED RESULTS IN Â§4.1

C.1 Proof of Theorem 4.2
We introduce several definitions, state lemmas, and prove Theorem 4.2 using the lemmas. We prove
the lemmas in Â§C.2 and Â§C.3.

Recall the partition Var = PVar âŠ Name âŠ AVar of Var. We use the following letters to denote the
values of each part: ğœğ‘ âˆˆ St[PVar], ğœğ‘› âˆˆ St[Name], and ğœğ‘ âˆˆ St[AVar]. Based on the partition, we
define the next functions:

prs(ğ‘) : St[PVar] Ã— St[Name] Ã— St[AVar] â†’ [0, âˆ),

prs(ğ‘)(ğœğ‘, ğœğ‘›, ğœğ‘) â‰œ

ï£±ï£´ï£´ï£´ï£²
ï£´ï£´ï£´
ï£³

0

(ğœğ‘ âŠ• ğœğ‘› âŠ• ğœğ‘)(like)
ğ‘
(cid:75)
(cid:74)
Â· (cid:206)ğœ‡ âˆˆName
ğ‘
(cid:74)

(cid:75)

(ğœğ‘ âŠ• ğœğ‘› âŠ• ğœğ‘)(pr ğœ‡)

if noerr (ğ‘, ğœğ‘ âŠ• ğœğ‘› âŠ• ğœğ‘)

otherwise,

vals(ğ‘) : St[PVar] Ã— St[Name] Ã— St[AVar] â†’ St[Name],

vals(ğ‘)(ğœğ‘, ğœğ‘›, ğœğ‘) â‰œ

(cid:40)ğœ†ğœ‡ âˆˆ Name.
ğ‘
(cid:74)
ğœ†ğœ‡ âˆˆ Name. 0

(cid:75)

(ğœğ‘ âŠ• ğœğ‘› âŠ• ğœğ‘)(valğœ‡)

if noerr (ğ‘, ğœğ‘ âŠ• ğœğ‘› âŠ• ğœğ‘)
otherwise,

where noerr (ğ‘, ğœ) is a predicate for a command ğ‘ and ğœ âˆˆ St, defined by

noerr (ğ‘, ğœ) â‡â‡’

ğ‘
(cid:74)

ğœ âˆˆ St âˆ§ (cid:0)âˆ€ğœ‡ âˆˆ Name.
(cid:75)

ğ‘
(cid:74)

ğœ (cntğœ‡) âˆ’ ğœ (cntğœ‡) â‰¤ 1(cid:1).
(cid:75)

The predicate noerr (ğ‘, ğœ) says that ğ‘ terminates for ğœ without a double-sampling error. The functions
prs and vals generalise the density function ğ‘ and the value function ğ‘£, respectively; in particular,
they do not assume a particular initial state ğœ0 used in Eq. (3). We consider the generalisation of ğ‘
and ğ‘£ so as to enable inductive proofs.

Although generalising ğ‘ and ğ‘£, the functions prs and vals are not sufficient to enable inductive
proofs since their inputs and outputs contain some unnecessary parts, which stops induction from
working well (especially in the sequential composition case): namely, the part of St[Name] that is
not read during execution, and the part of St[AVar] that is not updated during execution. To exclude

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:32

Wonyeol Lee, Xavier Rival, and Hongseok Yang

those unnecessary parts, we first define the set of substates of St[Name] as follows:

ğœ‰ğ‘› âˆˆ Stâ–¡ [Name] â‰œ (cid:216)
ğ¾ âŠ†Name

St[ğ¾].

Based on these substates, we define the next functions:

prsâ–¡(ğ‘) : St[PVar] Ã— Stâ–¡ [Name] â†’ [0, âˆ),

prsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) â‰œ

ï£±ï£´ï£´ï£´ï£²
ï£´ï£´ï£´
ï£³

0

ğ‘
(ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ )(like)
(cid:75)
(cid:74)
Â· (cid:206)ğœ‡ âˆˆdom(ğœ‰ğ‘›)

ğ‘
(cid:74)

(cid:75)

(ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ )(pr ğœ‡)

if âˆƒğœğ‘Ÿ . used (ğ‘, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›)

otherwise,

valsâ–¡(ğ‘) : St[PVar] Ã— Stâ–¡ [Name] â†’ Stâ–¡ [Name],

valsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) â‰œ

(cid:40)ğœ†ğœ‡ âˆˆ dom(ğœ‰ğ‘›).
ğ‘
(cid:74)
ğœ†ğœ‡ âˆˆ dom(ğœ‰ğ‘›). 0

(cid:75)

(ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ )(valğœ‡)

if âˆƒğœğ‘Ÿ . used (ğ‘, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›)
otherwise,

pvarsâ–¡(ğ‘) : St[PVar] Ã— Stâ–¡ [Name] â†’ St[PVar],

pvarsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) â‰œ

(cid:40)ğœ†ğ‘¥ âˆˆ PVar.
ğ‘
(cid:74)
ğœ†ğ‘¥ âˆˆ PVar. 0

(cid:75)

(ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ )(ğ‘¥)

if âˆƒğœğ‘Ÿ . used (ğ‘, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›)
otherwise,

where used (ğ‘, ğœ, ğœ‰ğ‘›) is a predicate for a command ğ‘, ğœ âˆˆ St, and ğœ‰ğ‘› âˆˆ Stâ–¡ [Name], defined by

used (ğ‘, ğœ, ğœ‰ğ‘›) â‡â‡’ noerr (ğ‘, ğœ) âˆ§ (cid:0)ğœ (like) = 1(cid:1) âˆ§ (cid:0)ğœ‰ğ‘› = ğœ |dom(ğœ‰ğ‘›)

âˆ§ (cid:0)dom(ğœ‰ğ‘›) = {ğœ‡ âˆˆ Name |

(cid:1)
ğœ (cntğœ‡) âˆ’ ğœ (cntğœ‡) = 1}(cid:1).
(cid:75)

ğ‘
(cid:74)

The predicate used (ğ‘, ğœ, ğœ‰ğ‘›) says that ğ‘ terminates for ğœ without a double-sampling error, like is
initialised to 1 in ğœ, and ğœ‰ğ‘› is the Name part of ğœ that is sampled during the execution of ğ‘ from ğœ.
By using used (âˆ’, âˆ’, âˆ’), the three functions do not take the unnecessary part of a state as an input,
and do not return the unnecessary part of a state in the output. The three functions are well-defined.

Lemma C.1. prsâ–¡, valsâ–¡, and pvarsâ–¡ are well-defined, i.e., they do not depend on the choice of ğœğ‘Ÿ .

We now state two main lemmas for Theorem 4.2. The first lemma describes how prs and vals are
connected with prsâ–¡ and valsâ–¡. The second lemma says that a particular integral involving prsâ–¡,
valsâ–¡, and pvarsâ–¡ is the same for ğ‘ and ğ‘ğœ‹ if a reparameterisation plan ğœ‹ is valid.

Lemma C.2. Let ğ‘ be a command, and ğ‘“ğ‘– : R â†’ R for ğ‘– âˆˆ {1, 2, 3} be measurable functions such that

ğ‘“1(ğ‘Ÿ ) â‰¥ 0 for all ğ‘Ÿ âˆˆ R. Define ğ‘“âˆ— : St[Name] â†’ St[AVar] by

ğ‘“âˆ— (ğœğ‘›)(ğ‘) â‰œ

1
ğ‘“1(ğœğ‘› (ğœ‡))
ğ‘“2 (ğœğ‘› (ğœ‡))
ğ‘“3(ğœğ‘› (ğœ‡))

if ğ‘ â‰¡ like
if ğ‘ â‰¡ pr ğœ‡ for ğœ‡ âˆˆ Name
if ğ‘ â‰¡ valğœ‡ for ğœ‡ âˆˆ Name
if ğ‘ â‰¡ cntğœ‡ for ğœ‡ âˆˆ Name.

ï£±ï£´ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£´

ï£³

Then, for all ğœğ‘ âˆˆ St[PVar] and all measurable â„ : St[Name] â†’ R,

âˆ«

(cid:16)

ğ‘‘ğœğ‘›

prs(ğ‘)(ğœğ‘, ğœğ‘›, ğ‘“âˆ— (ğœğ‘›)) Â· â„

(cid:16)

vals(ğ‘)(ğœğ‘, ğœğ‘›, ğ‘“âˆ— (ğœğ‘›))

(cid:17)(cid:17)

âˆ«

=

(cid:16)

ğ‘‘ğœ‰ğ‘›

prsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”

(cid:16)

valsâ–¡(ğ‘)(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:33

where the integral on the LHS is defined if and only if the one on the RHS is defined, and the function
ğ‘” : Stâ–¡ [Name] â†’ R is defined by
(cid:16)

âˆ«

(cid:17)

(cid:16)

(cid:16) (cid:214)

(cid:17)(cid:17)

ğ‘“1(ğœ‰ â€²

ğ‘› (ğœ‡))

Â· â„

ğ‘› âŠ• ğœ†ğœ‡ âˆˆ dom(ğœ‰ â€²
ğœ‰ â€²â€²

ğ‘›). ğ‘“2(ğœ‰ â€²

ğ‘› (ğœ‡))

.

ğ‘”(ğœ‰ â€²â€²

ğ‘› ) =

ğ‘‘ğœ‰ â€²
ğ‘›

1[dom(ğœ‰ â€²â€²

ğ‘›)âŠdom(ğœ‰ â€²

ğ‘›)=Name] Â·

ğœ‡ âˆˆdom(ğœ‰ â€²

ğ‘›)

(15)

Lemma C.3. Let ğ‘ be a command and ğ‘” : St[PVar] Ã— Stâ–¡ [Name] â†’ R be a measurable function.

Then, for all ğœğ‘ âˆˆ St[PVar],

âˆ«

(cid:16)

ğ‘‘ğœ‰ğ‘›

prsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”

(cid:16)

pvarsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›), valsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

âˆ«

=

(cid:16)

ğ‘‘ğœ‰ğ‘›

prsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”

(cid:16)

pvarsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›), valsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

where the integral on the LHS is defined if and only if the one on the RHS is defined.

We now prove Theorem 4.2 using these two lemmas.

Proof of Theorem 4.2. Let ğœ‹ be a valid reparameterisation plan, ğ‘ be a command, ğœğœƒ âˆˆ St[ğœƒ ], and
â„ : St[Name] â†’ R be a measurable function. Suppose that the integral on the LHS of Theorem 4.2
is defined. Recall that for a given ğœğ‘› âˆˆ St[Name], the definitions of ğ‘ and ğ‘£ (in Â§3 and Â§4.1) use the
initial state ğœ â‰œ ğœğœƒ âŠ• ğœğ‘› âŠ• ğœ0 âˆˆ St, where ğœ0 âˆˆ St[(PVar \ ğœƒ ) âˆª AVar] depends on ğœğ‘› and has the
following definition:

ğœ0(ğ‘£) â‰œ

0
1
N (ğœğ‘› (ğœ‡); 0, 1)
ğœğ‘› (ğœ‡)
0

if ğ‘£ âˆˆ PVar \ ğœƒ
if ğ‘£ â‰¡ like
if ğ‘£ â‰¡ pr ğœ‡ for ğœ‡ âˆˆ Name
if ğ‘£ â‰¡ valğœ‡ for ğœ‡ âˆˆ Name
if ğ‘£ â‰¡ cntğœ‡ for ğœ‡ âˆˆ Name.

ï£±ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´

ï£³

The initial state ğœ can be re-expressed as

using the following ğœğ‘ âˆˆ St[PVar] and ğ‘“âˆ— : St[Name] â†’ St[AVar]:

ğœ = ğœğ‘ âŠ• ğœğ‘› âŠ• ğ‘“âˆ— (ğœğ‘›)

(16)

ğœğ‘ (ğ‘¥) â‰œ

(cid:40)ğœğœƒ (ğ‘¥)
0

if ğ‘¥ âˆˆ ğœƒ
if ğ‘¥ âˆˆ PVar \ ğœƒ,

ğ‘“âˆ— (ğœğ‘›)(ğ‘) â‰œ

1
ğ‘“1(ğœğ‘› (ğœ‡))
ğ‘“2(ğœğ‘› (ğœ‡))
ğ‘“3(ğœğ‘› (ğœ‡))

if ğ‘ â‰¡ like
if ğ‘ â‰¡ pr ğœ‡ for ğœ‡ âˆˆ Name
if ğ‘ â‰¡ valğœ‡ for ğœ‡ âˆˆ Name
if ğ‘ â‰¡ cntğœ‡ for ğœ‡ âˆˆ Name,

ï£±ï£´ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£´

ï£³

where ğ‘“1(ğ‘Ÿ ) â‰œ N (ğ‘Ÿ ; 0, 1), ğ‘“2(ğ‘Ÿ ) â‰œ ğ‘Ÿ , and ğ‘“3(ğ‘Ÿ ) â‰œ 0. Using this, we get the desired equation:

âˆ«

(cid:16)

ğ‘‘ğœğ‘›

ğ‘ğ‘,ğœğœƒ (ğœğ‘›) Â· â„

(cid:16)
ğ‘£ğ‘,ğœğœƒ (ğœğ‘›)

(cid:17)(cid:17)

âˆ«

âˆ«

âˆ«

=

=

=

(cid:16)

ğ‘‘ğœğ‘›

prs(ğ‘)(ğœğ‘, ğœğ‘›, ğ‘“âˆ— (ğœğ‘›)) Â· â„

(cid:16)

vals(ğ‘)(ğœğ‘, ğœğ‘›, ğ‘“âˆ— (ğœğ‘›))

(cid:17)(cid:17)

(cid:16)

(cid:16)

ğ‘‘ğœ‰ğ‘›

ğ‘‘ğœ‰ğ‘›

prsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”

(cid:16)

valsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

prsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”

(cid:16)

valsâ–¡(ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:34

Wonyeol Lee, Xavier Rival, and Hongseok Yang

âˆ«

âˆ«

=

=

(cid:16)

ğ‘‘ğœğ‘›

prs(ğ‘ğœ‹ )(ğœğ‘, ğœğ‘›, ğ‘“âˆ— (ğœğ‘›)) Â· â„

(cid:16)

vals(ğ‘ğœ‹ )(ğœğ‘, ğœğ‘›, ğ‘“âˆ— (ğœğ‘›))

(cid:17)(cid:17)

ğ‘‘ğœğ‘›

(cid:16)
ğ‘ğ‘ğœ‹ ,ğœğœƒ (ğœğ‘›) Â· â„

(cid:16)
ğ‘£ğ‘ğœ‹ ,ğœğœƒ (ğœğ‘›)

(cid:17)(cid:17)

where ğ‘” : Stâ–¡ [Name] â†’ R is defined as Eq. (15). The first equality holds by Eq. (16) and the definition
of ğ‘ğ‘,ğœğœƒ , ğ‘£ğ‘,ğœğœƒ , prs, and vals. The second equality holds by Lemma C.2 (applied to ğ‘). The third equality
follows from Lemma C.3. The fourth equality holds by Lemma C.2 (applied to ğ‘ğœ‹ ). The fifth equality
holds by Eq. (16) and the definitions of ğ‘ğ‘ğœ‹ ,ğœğœƒ
, prs, and vals. Note that the same equational
, ğ‘£ğ‘ğœ‹ ,ğœğœƒ
reasoning with the reverse direction can be used to prove the claimed equation of the theorem when
â–¡
the integral on the RHS of the equation is defined.

C.2 Proofs of Lemmas C.1 and C.2

ğ‘Ÿ âˆˆ St[Var \ (dom(ğœğ‘ ) âˆª dom(ğœ‰ğ‘›))] such that used (ğ‘, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœ â€²

Proof of Lemma C.1. Let ğ‘ be a command, ğœğ‘ âˆˆ St[PVar], and ğœ‰ğ‘› âˆˆ Stâ–¡ [Name]. Consider
ğœğ‘Ÿ âˆˆ St[Var \ (dom(ğœğ‘ ) âˆª dom(ğœ‰ğ‘›))] such that used (ğ‘, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›). We want to show that
prsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›), valsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›), and pvarsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) do not depend on the choice of ğœğ‘Ÿ . To do so,
ğ‘Ÿ , ğœ‰ğ‘›). Let ğœ â‰œ ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ
consider ğœ â€²
and ğœ â€² â‰œ ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœ â€²

ğ‘Ÿ . Then, it suffices to show that
ğ‘
(cid:74)
ğ‘
(cid:74)
ğ‘
(cid:74)
Since used (ğ‘, ğœ, ğœ‰ğ‘›) and used (ğ‘, ğœ â€², ğœ‰ğ‘›), we have ğœ (like) = 1 = ğœ â€²(like) and so ğœ |ğ‘‰ = ğœ â€²|ğ‘‰ for
ğ‘‰ = PVar âˆª dom(ğœ‰ğ‘›) âˆª {like}. Using this and used (ğ‘, ğœ, ğœ‰ğ‘›), we can apply Lemma C.6-(3) and -(4) to
ğœ â€²(ğ‘£) for all ğ‘£ âˆˆ PVar âˆª {like} âˆª {pr ğœ‡, valğœ‡ | ğœ‡ âˆˆ dom(ğœ‰ğ‘›)}. Hence, we obtain the
get
ğ‘
(cid:75)
(cid:74)
â–¡
desired equations in Eq. (17).

ğœ â€²(like) Â· (cid:206)ğœ‡ âˆˆdom(ğœ‰ğ‘›)
(cid:75)
ğœ â€²(valğœ‡)
(cid:75)
ğœ â€²(ğ‘¥)
(cid:75)

ğœ (pr ğœ‡) =
(cid:75)
ğœ (valğœ‡) =
(cid:75)
ğœ (ğ‘¥) =
ğ‘
(cid:75)
(cid:74)

ğ‘
(cid:74)
for all ğœ‡ âˆˆ dom(ğœ‰ğ‘›),

ğœ (like) Â· (cid:206)ğœ‡ âˆˆdom(ğœ‰ğ‘›)
(cid:75)

for all ğ‘¥ âˆˆ PVar.

ğœ â€²(pr ğœ‡),
(cid:75)

ğœ (ğ‘£) =
(cid:75)

ğ‘
(cid:74)
ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

(17)

Proof of Lemma C.2. Let ğ‘ be a command, â„ : St[Name] â†’ R be a measurable function,
ğ‘“âˆ— : St[Name] â†’ St[AVar] be the function defined in the statement of this lemma, and ğœğ‘ âˆˆ St[PVar].

We first prove that the following equations hold for any measurable â„â€² : St[Name] â†’ R:

âˆ«

(cid:16)

ğ‘‘ğœğ‘›

1[noerr (ğ‘,ğœğ‘ âŠ•ğœğ‘› âŠ•ğ‘“âˆ— (ğœğ‘›)) ] Â· â„â€²(ğœğ‘›)

(cid:17)

=

=

=

=

âˆ«

(cid:16)

ğ‘‘ğœğ‘›

1[noerr (ğ‘,ğœğ‘ âŠ•ğœğ‘› âŠ•ğ‘“âˆ— (ğœğ‘›)) ] Â· â„â€²(ğœğ‘›) Â·

âˆ‘ï¸

1[used (ğ‘,ğœğ‘ âŠ•ğœğ‘› âŠ•ğ‘“âˆ— (ğœğ‘›),ğœğ‘› |ğ¾ ) ]

âˆ‘ï¸

âˆ«

ğ¾ âŠ†Name
âˆ‘ï¸

âˆ«

ğ¾ âŠ†Name

ğ¾ âŠ†Name
1[used (ğ‘,ğœğ‘ âŠ•ğœğ‘› âŠ•ğ‘“âˆ— (ğœğ‘›),ğœğ‘› |ğ¾ ) ] Â· 1[noerr (ğ‘,ğœğ‘ âŠ•ğœğ‘› âŠ•ğ‘“âˆ— (ğœğ‘›)) ] Â· â„â€²(ğœğ‘›)

(cid:16)

ğ‘‘ğœğ‘›

âˆ«

ğ‘‘ğœ‰ğ‘›

[ğ¾â†’R]

[Name\ğ¾â†’R]

(cid:16)

ğ‘‘ğœ‰ â€²
ğ‘›

1[used (ğ‘,ğœğ‘ âŠ• (ğœ‰ğ‘› âŠ•ğœ‰ â€²

ğ‘›) âŠ•ğ‘“âˆ— (ğœ‰ğ‘› âŠ•ğœ‰ â€²

ğ‘›),ğœ‰ğ‘›) ]

(cid:17)

(cid:17)

Â· 1[noerr (ğ‘,ğœğ‘ âŠ• (ğœ‰ğ‘› âŠ•ğœ‰ â€²

âˆ‘ï¸

âˆ«

ğ‘‘ğœ‰ğ‘›

ğ‘›) âŠ•ğ‘“âˆ— (ğœ‰ğ‘› âŠ•ğœ‰ â€²
âˆ«

(cid:16) âˆ‘ï¸

ğ‘›)) ] Â· â„â€²(ğœ‰ğ‘› âŠ• ğœ‰ â€²
ğ‘›)
(cid:16)

ğ¾ âŠ†Name

[ğ¾â†’R]

ğ¿ âŠ†Name

[ğ¿â†’R]

ğ‘›) âŠ•ğ‘“âˆ— (ğœ‰ğ‘› âŠ•ğœ‰ â€²

ğ‘›)) ] Â· â„â€²(ğœ‰ğ‘› âŠ• ğœ‰ â€²
ğ‘›)

(cid:17)

(cid:17)(cid:17)

Â· 1[noerr (ğ‘,ğœğ‘ âŠ• (ğœ‰ğ‘› âŠ•ğœ‰ â€²
(cid:16)

âˆ«

ğ‘‘ğœ‰ğ‘›

ğ‘‘ğœ‰ â€²
ğ‘›

âˆ«

=

1[dom(ğœ‰ğ‘›)âŠdom(ğœ‰ â€²

ğ‘›)=Name] Â· 1[used (ğ‘,ğœğ‘ âŠ• (ğœ‰ğ‘› âŠ•ğœ‰ â€²

ğ‘›) âŠ•ğ‘“âˆ— (ğœ‰ğ‘› âŠ•ğœ‰ â€²

ğ‘›),ğœ‰ğ‘›) ]

ğ‘‘ğœ‰ â€²
ğ‘›

1[dom(ğœ‰ğ‘›)âŠdom(ğœ‰ â€²

ğ‘›)=Name] Â· 1[used (ğ‘,ğœğ‘ âŠ• (ğœ‰ğ‘› âŠ•ğœ‰ â€²

ğ‘›) âŠ•ğ‘“âˆ— (ğœ‰ğ‘› âŠ•ğœ‰ â€²

ğ‘›),ğœ‰ğ‘›) ]

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:35

Â· 1[noerr (ğ‘,ğœğ‘ âŠ• (ğœ‰ğ‘› âŠ•ğœ‰ â€²

ğ‘›) âŠ•ğ‘“âˆ— (ğœ‰ğ‘› âŠ•ğœ‰ â€²

ğ‘›)) ] Â· â„â€²(ğœ‰ğ‘› âŠ• ğœ‰ â€²
ğ‘›)

(cid:17)

.

All of these equations mean that one side of the equation is defined if and only if the other side
is defined, and when both sides are defined, they are the same. The first equality holds because
noerr (ğ‘, ğœğ‘ âŠ• ğœğ‘› âŠ• ğ‘“âˆ— (ğœğ‘›)) implies that there exists a unique ğ¾ âŠ† Name with used (ğ‘, ğœğ‘ âŠ• ğœğ‘› âŠ•
ğ‘“âˆ—(ğœğ‘›), ğœğ‘› |ğ¾ ); here we use ğ‘“âˆ— (ğœğ‘›)(like) = 1. The second equality holds since Name is finite. The third
equality holds because St[Name] is isomorphic to [ğ¾ â†’ R] Ã— [Name \ ğ¾ â†’ R]. The fourth equality
holds since ğœ‰ â€²
ğ‘›)=Name] = 0. The fifth equality
holds by the definition of Stâ–¡ [Name] and its underlying measure.

ğ‘› âˆˆ [ğ¿ â†’ R] with ğ¿ â‰  Name \ ğ¾ implies 1[dom(ğœ‰ğ‘›)âŠdom(ğœ‰ â€²

Using this result, we obtain the desired equation:

âˆ«

=

=

(cid:16)

âˆ«

âˆ«

ğ‘‘ğœğ‘›

ğ‘‘ğœ‰ğ‘›

(cid:16)

ğ‘‘ğœ‰ â€²
ğ‘›

(cid:16)

ğ‘‘ğœğ‘›

prs(ğ‘)(ğœğ‘, ğœğ‘›, ğ‘“âˆ— (ğœğ‘›)) Â· â„

(cid:16)

vals(ğ‘)(ğœğ‘, ğœğ‘›, ğ‘“âˆ— (ğœğ‘›))

(cid:17)(cid:17)

1[noerr (ğ‘,ğœğ‘ âŠ•ğœğ‘› âŠ•ğ‘“âˆ— (ğœğ‘›)) ] Â· prs(ğ‘)(ğœğ‘, ğœğ‘›, ğ‘“âˆ— (ğœğ‘›)) Â· â„
âˆ«

1[dom(ğœ‰ğ‘›)âŠdom(ğœ‰ â€²

ğ‘›)=Name] Â· 1[used (ğ‘,ğœğ‘ âŠ• (ğœ‰ğ‘› âŠ•ğœ‰ â€²

ğ‘›) âŠ•ğ‘“âˆ— (ğœ‰ğ‘› âŠ•ğœ‰ â€²

ğ‘›),ğœ‰ğ‘›) ]

(cid:16)

vals(ğ‘)(ğœğ‘, ğœğ‘›, ğ‘“âˆ— (ğœğ‘›))

(cid:17)(cid:17)

Â· 1[noerr (ğ‘,ğœğ‘ âŠ• (ğœ‰ğ‘› âŠ•ğœ‰ â€²
Â· prs(ğ‘)(ğœğ‘, ğœ‰ğ‘› âŠ• ğœ‰ â€²

ğ‘›) âŠ•ğ‘“âˆ— (ğœ‰ğ‘› âŠ•ğœ‰ â€²
ğ‘›)) ]
ğ‘›, ğ‘“âˆ— (ğœ‰ğ‘› âŠ• ğœ‰ â€²

ğ‘›)) Â· â„

(cid:16)

vals(ğ‘)(ğœğ‘, ğœ‰ğ‘› âŠ• ğœ‰ â€²

ğ‘›, ğ‘“âˆ— (ğœ‰ğ‘› âŠ• ğœ‰ â€²

ğ‘›))

âˆ«

=

âˆ«

ğ‘‘ğœ‰ğ‘›

(cid:16)

ğ‘‘ğœ‰ â€²
ğ‘›

1[dom(ğœ‰ğ‘›)âŠdom(ğœ‰ â€²

ğ‘›)=Name] Â· 1[used (ğ‘,ğœğ‘ âŠ• (ğœ‰ğ‘› âŠ•ğœ‰ â€²

ğ‘›) âŠ•ğ‘“âˆ— (ğœ‰ğ‘› âŠ•ğœ‰ â€²

ğ‘›),ğœ‰ğ‘›) ]

Â· prs(ğ‘)(ğœğ‘, ğœ‰ğ‘› âŠ• ğœ‰ â€²

ğ‘›, ğ‘“âˆ— (ğœ‰ğ‘› âŠ• ğœ‰ â€²

ğ‘›)) Â· â„

(cid:16)

vals(ğ‘)(ğœğ‘, ğœ‰ğ‘› âŠ• ğœ‰ â€²

ğ‘›, ğ‘“âˆ— (ğœ‰ğ‘› âŠ• ğœ‰ â€²

ğ‘›))

(cid:17)(cid:17)

(cid:17)(cid:17)

âˆ«

=

âˆ«

ğ‘‘ğœ‰ğ‘›

(cid:16)

ğ‘‘ğœ‰ â€²
ğ‘›

1[dom(ğœ‰ğ‘›)âŠdom(ğœ‰ â€²

ğ‘›)=Name] Â· 1[used (ğ‘,ğœğ‘ âŠ• (ğœ‰ğ‘› âŠ•ğœ‰ â€²
(cid:17)

(cid:16)

(cid:16) (cid:214)

Â· prsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) Â·

ğ‘“1(ğœ‰ â€²

ğ‘› (ğœ‡))

Â· â„

valsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) âŠ•

ğ‘›) âŠ•ğ‘“âˆ— (ğœ‰ğ‘› âŠ•ğœ‰ â€²

ğ‘›),ğœ‰ğ‘›) ]

âˆ«

=

âˆ«

ğ‘‘ğœ‰ğ‘›

(cid:16)

ğ‘‘ğœ‰ â€²
ğ‘›

1[dom(ğœ‰ğ‘›)âŠdom(ğœ‰ â€²

ğ‘›)=Name]

ğœ‡ âˆˆdom(ğœ‰ â€²

ğ‘›)

Â· prsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) Â·

(cid:16) (cid:214)

ğ‘“1 (ğœ‰ â€²

ğ‘› (ğœ‡))

(cid:17)

(cid:16)

Â· â„

valsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) âŠ•

âˆ«

=

(cid:16)

ğ‘‘ğœ‰ğ‘›

prsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) Â·

ğœ‡ âˆˆdom(ğœ‰ â€²
ğ‘›)
âˆ«
(cid:16)

ğ‘‘ğœ‰ â€²
ğ‘›

1[dom(valsâ–¡ (ğ‘) (ğœğ‘,ğœ‰ğ‘›))âŠdom(ğœ‰ â€²

ğ‘›)=Name] Â·

(cid:16)

(cid:16)

ğœ†ğœ‡ âˆˆ dom(ğœ‰ â€²

ğ‘›). ğ‘“2(ğœ‰ â€²

ğ‘› (ğœ‡))

ğœ†ğœ‡ âˆˆ dom(ğœ‰ â€²

ğ‘›). ğ‘“2(ğœ‰ â€²

ğ‘› (ğœ‡))

(cid:17)(cid:17)(cid:17)

(cid:17)(cid:17)(cid:17)

(cid:16) (cid:214)

ğ‘“1 (ğœ‰ â€²

ğ‘› (ğœ‡))

(cid:17)

ğœ‡ âˆˆdom(ğœ‰ â€²

ğ‘›)

(cid:16)

Â· â„

valsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) âŠ•

(cid:16)

âˆ«

=

(cid:16)

ğ‘‘ğœ‰ğ‘›

prsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”

(cid:16)

valsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

ğœ†ğœ‡ âˆˆ dom(ğœ‰ â€²

ğ‘›). ğ‘“2(ğœ‰ â€²

ğ‘› (ğœ‡))

(cid:17)(cid:17)(cid:17)(cid:17)

where ğ‘” : Stâ–¡ [Name] â†’ R is defined as in the statement of this lemma, and each equation again
means that one side of it is defined if and only if the other side is defined, and when both sides are
defined, they are the same. The first and third equalities hold because prs(ğ‘)(ğœğ‘, ğœğ‘›, ğ‘“âˆ— (ğœğ‘›)) â‰  0
implies 1[noerr (ğ‘,ğœğ‘ âŠ•ğœğ‘› âŠ•ğ‘“âˆ— (ğœğ‘›)) ] = 1. The second equality uses the equation that we have shown in the
previous paragraph. The fourth equality holds because of the following reason: if

1[dom(ğœ‰ğ‘›)âŠdom(ğœ‰ â€²

ğ‘›)=Name] Â· 1[used (ğ‘,ğœğ‘ âŠ•ğœ‰ğ‘› âŠ•ğœğ‘Ÿ ,ğœ‰ğ‘›) ] = 1

for ğœğ‘Ÿ â‰œ ğœ‰ â€²

ğ‘› âŠ• ğ‘“âˆ— (ğœ‰ğ‘› âŠ• ğœ‰ â€²

ğ‘›),

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:36

then

Wonyeol Lee, Xavier Rival, and Hongseok Yang

prs(ğ‘)(ğœğ‘, ğœ‰ğ‘› âŠ• ğœ‰ â€²

ğ‘›, ğ‘“âˆ—(ğœ‰ğ‘› âŠ• ğœ‰ â€²

ğ‘›)) =
=

ğ‘
(cid:74)
ğ‘
(cid:74)

(cid:75)

(ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ )(like) Â· (cid:206)ğœ‡ âˆˆName
ğ‘
(ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ )(pr ğœ‡)
(cid:74)
(ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ )(like) Â· (cid:206)ğœ‡ âˆˆdom(ğœ‰ğ‘›)
ğ‘
(cid:75)
(cid:75)
(cid:74)
Â· (cid:206)ğœ‡ âˆˆName\dom(ğœ‰ğ‘›) (ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ )(pr ğœ‡)

(ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ )(pr ğœ‡)

(cid:75)

= prsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) Â· (cid:206)ğœ‡ âˆˆName\dom(ğœ‰ğ‘›) (ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ )(pr ğœ‡)
= prsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) Â· (cid:206)ğœ‡ âˆˆdom(ğœ‰ â€²

ğ‘›) ğ‘“1(ğœ‰ â€²

ğ‘› (ğœ‡))

and

vals(ğ‘)(ğœğ‘, ğœ‰ğ‘› âŠ• ğœ‰ â€²

ğ‘›, ğ‘“âˆ— (ğœ‰ğ‘› âŠ• ğœ‰ â€²

ğ‘›)) = ğœ†ğœ‡ âˆˆ Name.

ğ‘
(cid:75)
(cid:74)
= (cid:0)ğœ†ğœ‡ âˆˆ dom(ğœ‰ğ‘›).

(ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ )(valğœ‡)
ğ‘
(cid:74)

(ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ )(valğœ‡)(cid:1)

(cid:75)

âŠ• (cid:0)ğœ†ğœ‡ âˆˆ Name \ dom(ğœ‰ğ‘›). (ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ )(valğœ‡)(cid:1)

= valsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) âŠ• (cid:0)ğœ†ğœ‡ âˆˆ Name \ dom(ğœ‰ â€²
= valsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) âŠ• (cid:0)ğœ†ğœ‡ âˆˆ dom(ğœ‰ â€²
ğ‘›). ğ‘“2(ğœ‰ â€²

ğ‘›). (ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ )(valğœ‡)(cid:1)
ğ‘› (ğœ‡))(cid:1).

These equalities for prs(ğ‘) and vals(ğ‘) themselves hold for the below reasons:

â€¢ The first equalities hold by used (ğ‘, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›) and the definitions of prs(ğ‘) and vals(ğ‘).
â€¢ The second equalities hold by Lemma C.6-(2), which is applicable since used (ğ‘, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›).
â€¢ The third equalities hold by used (ğ‘, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›) and the definitions of prsâ–¡ (ğ‘) and valsâ–¡ (ğ‘).
â€¢ The fourth equalities hold by dom(ğœ‰ğ‘›) âŠ dom(ğœ‰ â€²

ğ‘›) = Name and the definition of ğ‘“âˆ—.

Returning back to the main equations, we point out that the fifth equality comes from the next fact:

(cid:16)

1[dom(ğœ‰ğ‘›)âŠdom(ğœ‰ â€²

ğ‘›)=Name] Â· prsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›)

(cid:17)

â‰  0 =â‡’ 1[used (ğ‘,ğœğ‘ âŠ• (ğœ‰ğ‘› âŠ•ğœ‰ â€²

ğ‘›) âŠ•ğ‘“âˆ— (ğœ‰ğ‘› âŠ•ğœ‰ â€²

ğ‘›),ğœ‰ğ‘›) ] = 1.

The justification for this implication is given below:

â€¢ If the premise holds, then there exists ğœğ‘Ÿ such that used (ğ‘, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›). Since ğœğ‘Ÿ (like) = 1 =
ğ‘›) coincide on PVar âˆª dom(ğœ‰ğ‘›) âˆª {like}.

ğ‘›) âŠ• ğ‘“âˆ— (ğœ‰ğ‘› âŠ• ğœ‰ â€²

ğ‘“âˆ— (âˆ’)(like), ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ and ğœğ‘ âŠ• (ğœ‰ğ‘› âŠ• ğœ‰ â€²
Thus, Lemma C.7 gives the conclusion.

Again back to the main equations, we note that the sixth equality holds since

dom(ğœ‰ğ‘›) = dom(valsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›)),

and the seventh equality follows from the definition of ğ‘”. This completes the proof.

â–¡

Lemma C.4. For all commands ğ‘ and states ğœ âˆˆ St such that

for all ğœ‡ âˆˆ Name.

ğ‘
(cid:74)

ğœ (cntğœ‡) â‰¥ ğœ (cntğœ‡)
(cid:75)

and

ğ‘
(cid:74)

ğœ âˆˆ St, we have
(cid:75)

ğ‘
(cid:74)
ğœ (ğœ‡) = ğœ (ğœ‡)
(cid:75)

Proof. We prove the lemma by induction on the structure of ğ‘. Let ğœ âˆˆ St such that

ğ‘
(cid:74)

Cases ğ‘ â‰¡ skip, or ğ‘ â‰¡ (ğ‘¥ := ğ‘’), or ğ‘ â‰¡ obs(ğ‘‘, ğ‘Ÿ ). In these cases,
ğœ (ğœ‡) = ğœ‡ for all ğœ‡. The claim of the lemma, thus, follows.
(cid:75)
Case ğ‘ â‰¡ (ğ‘¥ := sam(ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’ â€²)). Let ğœ‡ â‰œ

ğ‘›
(cid:74)

ğœ, ğ‘ â‰œ
(cid:75)

ğ‘‘
(cid:74)

ğœ, and ğ‘Ÿ â‰œ
(cid:75)

ğ‘’ â€²[ğœ‡/ğ‘¦]
(cid:74)

ğœ. Then,
(cid:75)

ğ‘
(cid:74)
Thus, the claim of the lemma follows.

ğœ = ğœ [ğ‘¥ â†¦â†’ ğ‘Ÿ, valğœ‡ â†¦â†’ ğ‘Ÿ, pr ğœ‡ â†¦â†’ ğ‘ (ğ‘Ÿ ), cntğœ‡ â†¦â†’ ğœ (cntğœ‡) + 1].
(cid:75)

ğ‘
(cid:74)
ğœ (cntğœ‡) = ğœ (cntğœ‡) and
(cid:75)

ğœ âˆˆ St.
(cid:75)

ğ‘
(cid:74)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:37

Case ğ‘ â‰¡ (ğ‘ â€²; ğ‘ â€²â€²). Pick ğœ‡ âˆˆ Name. Then,
ğ‘ â€²â€²
(cid:74)

ğœ (ğœ‡) =
(cid:75)

ğ‘ â€²; ğ‘ â€²â€²
(cid:74)

(

ğ‘ â€²
(cid:74)

ğœ)(ğœ‡) =
(cid:75)

(cid:75)

ğ‘ â€²
(cid:74)

ğœ (ğœ‡) = ğœ (ğœ‡).
(cid:75)

Here the second and third equalities use induction hypothesis on ğ‘ â€² and ğ‘ â€²â€², respectively. Also,
(cid:17)

(cid:17)

(cid:16)

(cid:16)

ğ‘ â€²; ğ‘ â€²â€²
(cid:74)

ğœ (cntğœ‡) âˆ’ ğœ (cntğœ‡) =
(cid:75)

(

ğ‘ â€²
(cid:74)

ğœ)(cntğœ‡) âˆ’
(cid:75)

ğ‘ â€²
(cid:74)

ğœ (cntğœ‡)
(cid:75)

(cid:75)

+

ğ‘ â€²
(cid:74)

ğœ (cntğœ‡) âˆ’ ğœ (cntğœ‡)
(cid:75)

ğ‘ â€²â€²
(cid:74)
â‰¥ 0.

The inequality here uses induction hypothesis on ğ‘ â€² and ğ‘ â€²â€².

Case ğ‘ â‰¡ (if ğ‘ {ğ‘ â€²} else {ğ‘ â€²â€²}). Assume that

under this assumption. The other case of
by induction hypothesis on ğ‘ â€²,

ğ‘
(cid:74)

(cid:75)

ğœ = true. We will prove the claims of the lemma
(cid:75)
= false can be proved similarly. Pick ğœ‡ âˆˆ Name. Then,

ğ‘
(cid:74)

ğ‘
(cid:74)

ğœ (ğœ‡) =
(cid:75)

ğ‘ â€²
(cid:74)

ğœ (ğœ‡) = ğœ (ğœ‡)
(cid:75)

and

ğ‘
(cid:74)

ğœ (cntğœ‡) =
(cid:75)

â€²

ğœ (cntğœ‡) â‰¥ ğœ (cntğœ‡).
(cid:75)

(cid:74)

Case ğ‘ â‰¡ (while ğ‘ {ğ‘ â€²}). Let T be the following subset of [St â†’ StâŠ¥]:

ğ‘“ âˆˆ T â‡â‡’ âˆ€ğœ âˆˆ St.

(cid:16)

ğ‘“ (ğœ) â‰  âŠ¥ =â‡’ âˆ€ğœ‡ âˆˆ Name. ğ‘“ (ğœ)(ğœ‡) = ğœ (ğœ‡) âˆ§ ğ‘“ (ğœ)(cntğœ‡) â‰¥ ğœ (cntğœ‡)

(cid:17)

.

Let ğ¹ be the operator on [St â†’ StâŠ¥] whose least fixed point becomes the semantics of the loop ğ‘.
The desired conclusion follows if we show that T contains ğœ†ğœ.âŠ¥ and is closed under taking the limit
of a chain in T , and ğ¹ preserves T . The least element ğœ†ğœ.âŠ¥ belongs to T since there are no states
ğœ with (ğœ†ğœ.âŠ¥)(ğœ) â‰  âŠ¥. Consider an increasing sequence ğ‘“0, ğ‘“1, . . . in T , and let ğ‘“âˆ â‰œ (cid:195)ğ‘› âˆˆN ğ‘“ğ‘›. Pick
ğœ such that ğ‘“âˆ (ğœ) â‰  âŠ¥. Then, ğ‘“âˆ (ğœ) = ğ‘“ğ‘š (ğœ) for some ğ‘š âˆˆ N. Since ğ‘“ğ‘š âˆˆ T , we have

ğ‘“ğ‘š (ğœ)(ğœ‡) = ğœ (ğœ‡)

and

ğ‘“ğ‘š (ğœ)(cntğœ‡) â‰¥ ğœ (cntğœ‡)

for all ğœ‡ âˆˆ Name. Since ğ‘“ğ‘š (ğœ) = ğ‘“âˆ (ğœ), we also have, for every ğœ‡ âˆˆ Name, ğ‘“âˆ (ğœ)(ğœ‡) = ğœ (ğœ‡) and
ğ‘“âˆ(ğœ)(cntğœ‡) â‰¥ ğœ (cntğœ‡), as desired. It remains to show that ğ¹ (ğ‘“ ) âˆˆ T for all ğ‘“ âˆˆ T . Pick ğ‘“ âˆˆ T and
ğœ âˆˆ St such that ğ¹ (ğ‘“ )(ğœ) âˆˆ St. If
ğœ = false, we have ğ¹ (ğ‘“ )(ğœ) = ğœ, and the claims of the lemma
(cid:75)
ğœ). Pick ğœ‡ âˆˆ Name. Then, by induction hypothesis on ğ‘ â€² and the
follow. Otherwise, ğ¹ (ğ‘“ )(ğœ) = ğ‘“ (
(cid:75)
membership ğ‘“ âˆˆ T ,
ğ¹ (ğ‘“ )(ğœ)(ğœ‡) = ğ‘“ (

ğ‘
(cid:74)
ğ‘ â€²
(cid:74)

and

ğ¹ (ğ‘“ )(ğœ)(cntğœ‡) = ğ‘“ (

We have just shown that ğ¹ (ğ‘“ ) âˆˆ T , as desired.

ğœ)(ğœ‡) =
(cid:75)

ğ‘ â€²
(cid:74)
ğœ)(cntğœ‡) â‰¥
(cid:75)

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

ğœ (ğœ‡) = ğœ (ğœ‡),
(cid:75)
ğœ (cntğœ‡) â‰¥ ğœ (cntğœ‡).
(cid:75)

ğ‘ â€²
(cid:74)

â–¡

Definition C.5. Define usedâˆ’ as the predicate used but without the condition that like should be

1. That is, for all commands ğ‘, states ğœ âˆˆ St, and ğœ‰ğ‘› âˆˆ Stâ–¡ [Name],

usedâˆ’ (ğ‘, ğœ, ğœ‰ğ‘›) â‡â‡’

ğ‘
(cid:74)

ğœ âˆˆ St âˆ§ (cid:0)
(cid:75)

ğ‘
(cid:74)

ğœ (cntğœ‡) âˆ’ ğœ (cntğœ‡) â‰¤ 1 for all ğœ‡ âˆˆ Name(cid:1)
(cid:75)

âˆ§ ğœ‰ğ‘› = ğœ |dom(ğœ‰ğ‘›)
âˆ§ dom(ğœ‰ğ‘›) = {ğœ‡ âˆˆ Name |
Lemma C.6. Let ğ‘ be a command, ğœ0, ğœ1 âˆˆ St, and ğœ‰ğ‘› âˆˆ Stâ–¡ [Name]. Suppose that usedâˆ’ (ğ‘, ğœ0, ğœ‰ğ‘›)

ğœ (cntğœ‡) âˆ’ ğœ (cntğœ‡) = 1}.
(cid:75)

ğ‘
(cid:74)

and ğœ1|ğ‘‰ = ğœ0|ğ‘‰ for ğ‘‰ â‰œ PVar âˆª dom(ğœ‰ğ‘›). Then, the following properties hold:

(1)
(2)
(3)
(4)
(5)

ğ‘
(cid:74)
ğ‘
(cid:74)
ğ‘
(cid:74)
ğ‘
(cid:74)
ğ‘
(cid:74)

ğœ1 âˆˆ St.
(cid:75)
ğœ1(ğ‘) = ğœ1(ğ‘) for all ğ‘ âˆˆ {pr ğœ‡, valğœ‡, cntğœ‡ | ğœ‡ âˆˆ Name \ dom(ğœ‰ğ‘›)}.
(cid:75)
ğ‘
ğœ1(ğ‘£) =
(cid:75)
(cid:74)
ğœ1(like) =
(cid:75)
ğœ1(ğ‘) âˆ’ ğœ1(ğ‘) =
(cid:75)

ğœ0(ğ‘£) for all ğ‘£ âˆˆ PVar âˆª {pr ğœ‡, valğœ‡ | ğœ‡ âˆˆ dom(ğœ‰ğ‘›)}.
(cid:75)
ğ‘
(cid:74)

ğœ0(ğ‘) âˆ’ ğœ0(ğ‘) for all ğ‘ âˆˆ {cntğœ‡ | ğœ‡ âˆˆ Name}.
(cid:75)

ğœ0(like), if ğœ0(like) = ğœ1(like).
(cid:75)

ğ‘
(cid:74)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:38

Wonyeol Lee, Xavier Rival, and Hongseok Yang

Proof. For ğœ â€²

0, ğœ â€²

1 âˆˆ St and ğœ‰ â€²

ğ‘› âˆˆ Stâ–¡ [Name], write
ğœ â€²
1

ğœ â€²
0 âˆ¼ğœ‰ â€²
1|ğ‘‰ for ğ‘‰ â‰œ PVar âˆª dom(ğœ‰ â€²

ğ‘›

to mean that ğœ â€²
0|ğ‘‰ = ğœ â€²
conditions of the lemma as follows:

ğ‘›). Note that using this notation, we can write the

usedâˆ’ (ğ‘, ğœ0, ğœ‰ğ‘›) âˆ§ ğœ0 âˆ¼ğœ‰ğ‘› ğœ1.
We will prove, by induction on the structure of ğ‘, that these conditions imply the five properties
claimed by the lemma. Our proof will sometimes use a simple observation that the five properties
claimed by the lemma and the relationship ğœ0 âˆ¼ğœ‰ğ‘› ğœ1 imply usedâˆ’ (ğ‘, ğœ1, ğœ‰ğ‘›). One consequence of the
observation is that if our lemma holds, its five properties also hold with ğœ0 and ğœ1 swapped. We will
often use this consequence.

ğ‘
(cid:74)

ğœ0 = ğœ0 and
(cid:75)

Case ğ‘ â‰¡ skip. In this case,

ğœ1 = ğœ1. From these equalities, the claimed prop-
ğ‘
(cid:75)
(cid:74)
erties (1), (2), (4) and (5) follow. For the remaining property (3), we note that dom(ğœ‰ğ‘›) = âˆ… and the
property, thus, follows from ğœ0 âˆ¼ğœ‰ğ‘› ğœ1.
Case ğ‘ â‰¡ (ğ‘¥ := ğ‘’). In this case,

ğœ1]. The results
(cid:75)
are not âŠ¥, and they are identical to the pre-states ğœ0 and ğœ1 as far as auxiliary variables in AVar are
concerned. Also, expressions in commands do not depend on variables other than program variables,
ğœ1(ğ‘¥) for all ğ‘¥ âˆˆ PVar. From all of these
so that ğœ0 âˆ¼ğœ‰ğ‘› ğœ1 gives
ğœ0(ğ‘¥) =
ğœ0 =
ğ‘’
(cid:75)
(cid:75)
(cid:75)
(cid:74)
observations, the claimed properties (1)â€“(5) follow.

ğœ0 = ğœ0 [ğ‘¥ â†¦â†’
(cid:75)

ğœ1 = ğœ1 [ğ‘¥ â†¦â†’
(cid:75)

ğœ0] and
(cid:75)

ğœ1 and
(cid:75)

ğ‘’
(cid:74)

ğ‘’
(cid:74)

ğ‘’
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

Case ğ‘ â‰¡ (ğ‘¥ := sam(ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’ â€²)). Since ğœ0(ğ‘¥) = ğœ1(ğ‘¥) for all ğ‘¥ âˆˆ PVar, we have

and
ğœ0 =
(cid:75)
commands, we have

ğœ1. Let ğœ‡ â‰œ
(cid:75)

ğ‘‘
(cid:74)

ğ‘‘
(cid:74)

ğ‘›
(cid:74)

ğœ0, ğ‘ â‰œ
(cid:75)

ğ‘‘
(cid:74)

ğœ0, and ğ‘Ÿ â‰œ
(cid:75)

ğ‘’ â€²[ğœ‡/ğ‘¦]
(cid:74)

ğœ1
(cid:75)
ğœ0. By the semantics of the sample
(cid:75)

ğœ0 =
(cid:75)

ğ‘›
(cid:74)

ğ‘›
(cid:74)

ğœ0 = ğœ0 [ğ‘¥ â†¦â†’ ğ‘Ÿ, valğœ‡ â†¦â†’ ğ‘Ÿ, pr ğœ‡ â†¦â†’ ğ‘ (ğœ0(ğœ‡)), cntğœ‡ â†¦â†’ ğœ0(cntğœ‡) + 1].
(cid:75)
Since usedâˆ’(ğ‘, ğœ0, ğœ‰ğ‘›) holds, we have ğœ‰ğ‘› = ğœ0| {ğœ‡ }, which in turn implies ğœ0(ğœ‡) = ğœ1(ğœ‡) because
ğœ0 âˆ¼ğœ‰ğ‘› ğœ1. Thus,

ğ‘
(cid:74)

ğ‘’ â€²[ğœ‡/ğ‘¦]
(cid:74)

ğœ0 = ğ‘Ÿ , and
ğ‘’ â€²[ğœ‡/ğ‘¦]
(cid:74)
(cid:75)
ğ‘’ â€²[ğœ‡/ğ‘¦]
ğœ1, valğœ‡ â†¦â†’
(cid:74)
(cid:75)
= ğœ1 [ğ‘¥ â†¦â†’ ğ‘Ÿ, valğœ‡ â†¦â†’ ğ‘Ÿ, pr ğœ‡ â†¦â†’ ğ‘ (ğœ0(ğœ‡)), cntğœ‡ â†¦â†’ ğœ1(cntğœ‡) + 1].

ğœ1 =
(cid:75)
ğ‘’ â€²[ğœ‡/ğ‘¦]
(cid:74)

ğœ1 = ğœ1 [ğ‘¥ â†¦â†’
(cid:75)

ğœ1, pr ğœ‡ â†¦â†’ ğ‘ (ğœ1(ğœ‡)), cntğœ‡ â†¦â†’ ğœ1(cntğœ‡) + 1]
(cid:75)

ğ‘
(cid:74)

The RHS of the last equality implies that the five properties claimed by the lemma hold.

Case ğ‘ â‰¡ obs(ğ‘‘, ğ‘Ÿ ). We have

Then,

ğ‘‘
(cid:74)

ğœ0 =
(cid:75)

ğ‘‘
(cid:74)

ğœ1 since ğœ0(ğ‘¥) = ğœ1(ğ‘¥) for all ğ‘¥ âˆˆ PVar. Let ğ‘ â‰œ
(cid:75)

ğ‘‘
(cid:74)

ğœ0.
(cid:75)

ğ‘
(cid:74)

ğœ0 = ğœ0 [like â†¦â†’ ğœ0(like) Â· ğ‘ (ğ‘Ÿ )]
(cid:75)

and
Also, dom(ğœ‰ğ‘›) = âˆ… since usedâˆ’ (ğ‘, ğœ0, ğœ‰ğ‘›) holds. From what we have proved and also the agreement
of ğœ0 and ğœ1 on program variables, the five properties claimed by the lemma follow.

ğœ1 = ğœ1 [like â†¦â†’ ğœ1(like) Â· ğ‘ (ğ‘Ÿ )].
(cid:75)

ğ‘
(cid:74)

Case ğ‘ â‰¡ (ğ‘ â€²; ğ‘ â€²â€²). Since
ğœ0 =
ğ‘
ğ‘ â€²â€²
(cid:75)
(cid:74)
(cid:74)
ğœ â€²
ğ‘ â€²
0 â‰œ
ğœ0,
(cid:74)
(cid:75)
ğ‘0 â‰œ {ğœ‡ âˆˆ Name |
ğ‘ â€²

(cid:75)

â€  (

ğ‘ â€²â€²
(cid:74)
0 â‰œ {ğœ‡ âˆˆ Name | ğœ â€²
0(cntğœ‡) âˆ’ ğœ0(cntğœ‡) = 1}.

ğœ â€²
0(cntğœ‡) âˆ’ ğœ0(cntğœ‡) = 1},
(cid:75)

ğ‘ â€²
(cid:74)

ğœ0) âˆˆ St, we have
(cid:75)

ğ‘ â€²
(cid:74)

ğœ0 âˆˆ St. Let
(cid:75)

Then, ğ‘0 = dom(ğœ‰ğ‘›) because usedâˆ’ (ğ‘ â€²; ğ‘ â€²â€², ğœ0, ğœ‰ğ‘›) holds. We will prove the following facts:

0 âŠ† ğ‘0.

(1) ğ‘ â€²
(2) Let ğœ‰ â€²
(3)
ğ‘ â€²
(cid:74)

ğ‘› â‰œ ğœ‰ğ‘› |ğ‘ â€²
ğœ1 âˆˆ St.
(cid:75)

0

, and ğœ‰ â€²â€²

ğ‘› â‰œ ğœ‰ğ‘› | (ğ‘0\ğ‘ â€²

0) . Then, usedâˆ’ (ğ‘ â€², ğœ0, ğœ‰ â€²

ğ‘›) and usedâˆ’(ğ‘ â€²â€², ğœ â€²

0, ğœ‰ â€²â€²

ğ‘› ) hold.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:39

(4) Let ğœ â€²

ğœ1. Then, ğœ â€²
(cid:75)

1 â‰œ

ğ‘ â€²
(cid:74)
ğœ1 since dom(ğœ‰ â€²

0 âˆ¼ğœ‰ â€²â€²

ğ‘›

1.
ğœ â€²

ğ‘›

ğ‘›) = ğ‘ â€²

These four facts imply the five properties claimed by the lemma. Here is the reason. Note that
0 âŠ† ğ‘0 = dom(ğœ‰ğ‘›). This relationship between ğœ0 and ğœ1 and the second
ğœ0 âˆ¼ğœ‰ â€²
ğ‘›, ğœ0, ğœ1). Also, the second and fourth facts allow us to
fact let us use induction hypothesis on (ğ‘ â€², ğœ‰ â€²
use induction hypothesis on (ğ‘ â€²â€², ğœ‰ â€²â€²
1). We can derive the five properties from what we get from
these two applications of induction hypothesis:
0, ğœ â€²

ğ‘› , ğœ â€²

ğ‘› , ğœ â€²

0, ğœ â€²

(1) By induction hypothesis on (ğ‘ â€²â€², ğœ‰ â€²â€²
1), we have
(2) For all ğ‘ âˆˆ {pr ğœ‡, valğœ‡, cntğœ‡ | ğœ‡ âˆˆ Name \ dom(ğœ‰ğ‘›)},
1(ğ‘) =

ğ‘ â€²; ğ‘ â€²â€²
(cid:74)

ğœ1(ğ‘) =
(cid:75)

1(ğ‘) = ğœ â€²
ğœ â€²
(cid:75)
The second equality comes from induction hypothesis on (ğ‘ â€²â€², ğœ‰ â€²â€²
dom(ğœ‰ğ‘›), and the fourth equality from induction hypothesis on (ğ‘ â€², ğœ‰ â€²
dom(ğœ‰ğ‘›).

ğœ1(ğ‘) = ğœ1(ğ‘).
(cid:75)
ğ‘› , ğœ â€²

ğ‘ â€²â€²
(cid:74)

ğ‘ â€²
(cid:74)

ğ‘ â€²; ğ‘ â€²â€²
(cid:74)

ğœ1 =
(cid:75)

ğ‘ â€²â€²
(cid:74)

1 âˆˆ St.
ğœ â€²
(cid:75)

0, ğœ â€²

1) and dom(ğœ‰ â€²â€²
ğ‘›, ğœ0, ğœ1) and dom(ğœ‰ â€²

ğ‘› ) âŠ†
ğ‘›) âŠ†

(3) For all ğ‘£ âˆˆ PVar âˆª {pr ğœ‡, valğœ‡ | ğœ‡ âˆˆ dom(ğœ‰ â€²â€²
ğœ â€²
ğ‘ â€²; ğ‘ â€²â€²
1 (ğ‘£) =
(cid:75)
(cid:74)

ğœ1(ğ‘£) =
(cid:75)

ğ‘ â€²â€²
(cid:74)

Also, for all ğ‘ âˆˆ {pr ğœ‡, valğœ‡ | ğœ‡ âˆˆ dom(ğœ‰ â€²
and we can calculate:

ğ‘› )}, by induction hypothesis on (ğ‘ â€²â€², ğœ‰ â€²â€²
ğ‘ â€²; ğ‘ â€²â€²
(cid:74)

ğœ0(ğ‘£).
(cid:75)
ğ‘›)}, we have ğ‘ âˆˆ {pr ğœ‡, valğœ‡ | ğœ‡ âˆˆ Name \ dom(ğœ‰ â€²â€²

ğœ â€²
0 (ğ‘£) =
(cid:75)

ğ‘ â€²â€²
(cid:74)

1),
0, ğœ â€²

ğ‘› , ğœ â€²

ğ‘› )},

ğ‘ â€²; ğ‘ â€²â€²
(cid:74)

ğ‘ â€²â€²
1(ğ‘) = ğœ â€²
ğœ â€²
ğœ1(ğ‘) =
1(ğ‘)
(cid:74)
(cid:75)
(cid:75)
ğ‘ â€²
ğ‘ â€²
ğœ1 (ğ‘) =
ğœ0(ğ‘)
=
(cid:74)
(cid:74)
(cid:75)
(cid:75)
= ğœ â€²
ğœ â€²
ğ‘ â€²â€²
ğ‘ â€²; ğ‘ â€²â€²
0(ğ‘) =
0(ğ‘) =
(cid:75)
(cid:74)
(cid:74)
The second equality uses induction hypothesis on (ğ‘ â€²â€², ğœ‰ â€²â€²
ğ‘› , ğœ â€²
induction hypothesis on (ğ‘ â€², ğœ‰ â€²
applied to (ğ‘ â€²â€², ğœ‰ â€²â€²

ğ‘› , ğœ â€²

0, ğœ â€²

1) and again to the same tuple but with ğœ â€²
ğ‘›, ğœ0, ğœ1),

(4) If ğœ0(like) = ğœ1(like), by induction hypothesis on (ğ‘ â€², ğœ‰ â€²
ğœ â€²
0(like) =

ğ‘ â€²
(cid:74)

ğœ0(like) =
(cid:75)

ğ‘ â€²
(cid:74)

ğœ1(like) = ğœ â€²
(cid:75)
ğ‘› , ğœ â€²

which in turn implies, by induction hypothesis on (ğ‘ â€²â€², ğœ‰ â€²â€²

ğœ0(ğ‘).
(cid:75)
1), and the fourth comes from the
0, ğœ â€²
ğ‘›, ğœ0, ğœ1). The sixth equality follows from induction hypothesis

0 and ğœ â€²

1 swapped.

ğœ â€²
0(like) =
(cid:75)

ğ‘ â€²â€²
(cid:74)

ğœ â€²
1 (like) =
(cid:75)

ğœ1(like).
(cid:75)

1(like),
1),
0, ğœ â€²
ğ‘ â€²; ğ‘ â€²â€²
(cid:74)

ğ‘ â€²; ğ‘ â€²â€²
(cid:74)

ğœ0(like) =
(cid:75)

ğ‘ â€²â€²
(cid:74)
(5) For all ğ‘ âˆˆ {cntğœ‡ | ğœ‡ âˆˆ Name},
ğ‘ â€²; ğ‘ â€²â€²
(cid:74)

ğœ1(ğ‘) âˆ’ ğœ1(ğ‘) =
(cid:75)
=

ğ‘ â€²; ğ‘ â€²â€²
ğ‘ â€²
ğœ1(ğ‘) âˆ’
ğœ1(ğ‘) +
(cid:75)
(cid:74)
(cid:74)
(cid:75)
ğœ â€²
1(ğ‘) âˆ’ ğœ â€²
ğ‘ â€²â€²
ğ‘ â€²
1(ğ‘) +
(cid:75)
(cid:74)
(cid:74)
ğ‘ â€²
0(ğ‘) âˆ’ ğœ â€²
ğœ â€²
ğ‘ â€²â€²
0(ğ‘) +
(cid:74)
(cid:74)
(cid:75)
ğ‘ â€²; ğ‘ â€²â€²
ğœ0(ğ‘) âˆ’ ğœ0(ğ‘).
(cid:75)
(cid:74)
The only non-trivial inequality is the third one, and it follows from induction hypothesis on
(ğ‘ â€², ğœ‰ â€²

ğœ1(ğ‘) âˆ’ ğœ1(ğ‘)
(cid:75)
ğœ1(ğ‘) âˆ’ ğœ1(ğ‘)
(cid:75)
ğœ0(ğ‘) âˆ’ ğœ0(ğ‘)
(cid:75)

ğ‘ â€²
(cid:74)

=

=

1).
ğ‘›, ğœ0, ğœ1) and (ğ‘ â€²â€², ğœ‰ â€²â€²
0, ğœ â€²
We prove the four facts as follows:
(1) Let ğœ‡ âˆˆ ğ‘ â€²

ğ‘› , ğœ â€²

0. Since usedâˆ’ (ğ‘ â€²; ğ‘ â€²â€², ğœ0, ğœ‰ğ‘›), we have
ğœ â€²
0(ğœ‡) âˆ’ ğœ0(ğœ‡) =
(cid:75)

ğ‘ â€²; ğ‘ â€²â€²
ğ‘ â€²â€²
(cid:74)
(cid:74)
0,
Also, by Lemma C.4 and the definition of ğ‘ â€²

ğœ0 âˆ’ ğœ0(ğœ‡) â‰¤ 1.
(cid:75)

0(ğœ‡) âˆ’ ğœ0(ğœ‡) â‰¥ ğœ â€²
ğœ â€²
(cid:75)
0(ğœ‡) âˆ’ ğœ0(ğœ‡) = 1, which implies that ğœ‡ âˆˆ ğ‘0, as desired.
ğœ â€²
(cid:75)

0(ğœ‡) âˆ’ ğœ0(ğœ‡) = 1.

ğ‘ â€²â€²
(cid:74)

Thus,

ğ‘ â€²â€²
(cid:74)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:40

Wonyeol Lee, Xavier Rival, and Hongseok Yang

(2) We should show that usedâˆ’ (ğ‘ â€², ğœ0, ğœ‰ â€²

ğ‘› ) hold. The conjuncts in the defini-
0, ğœ‰ â€²â€²
ğ‘›) except the second follow immediately from usedâˆ’ (ğ‘ â€²; ğ‘ â€²â€², ğœ0, ğœ‰ğ‘›) and the
tion of usedâˆ’ (ğ‘ â€², ğœ0, ğœ‰ â€²
definition of ğœ‰ğ‘›. For the remaining second conjunct, we use Lemma C.4 and usedâˆ’ (ğ‘ â€²; ğ‘ â€²â€², ğœ0, ğœ‰ğ‘›),
and prove the conjunct as shown below: for all ğœ‡ âˆˆ Name,

ğ‘›) and usedâˆ’ (ğ‘ â€²â€², ğœ â€²

ğ‘ â€²
(cid:74)

ğœ0(cntğœ‡) âˆ’ ğœ0 (cntğœ‡) â‰¤
(cid:75)
For usedâˆ’ (ğ‘ â€²â€², ğœ â€²
0, ğœ‰ â€²â€²
consequences of usedâˆ’ (ğ‘ â€²; ğ‘ â€²â€², ğœ0, ğœ‰ğ‘›) and the definition of ğœ‰ â€²â€²
in the definition as follows: for all ğœ‡ âˆˆ Name,

ğ‘› ), we first note that the first and third conjuncts in its definition are direct
ğ‘› . We prove the second conjunct

ğœ0)(cntğœ‡) âˆ’ ğœ0(cntğœ‡) â‰¤ 1.
(cid:75)

ğ‘ â€²â€²
(cid:74)

ğ‘ â€²
(cid:74)

(cid:75)

(

ğ‘ â€²â€²
(cid:74)

0(cntğœ‡) âˆ’ ğœ â€²
ğœ â€²
(cid:75)

ğ‘ â€²
ğ‘ â€²; ğ‘ â€²â€²
ğœ0(cntğœ‡) âˆ’
0(cntğœ‡) =
(cid:74)
(cid:75)
(cid:74)
ğ‘ â€²; ğ‘ â€²â€²
ğœ0 (cntğœ‡) âˆ’ cnt0(cntğœ‡)
â‰¤
(cid:75)
(cid:74)
â‰¤ 1.

cnt0(cntğœ‡)
(cid:75)

The first inequality uses Lemma C.4, and the second comes from usedâˆ’(ğ‘ â€²; ğ‘ â€²â€², ğœ0, ğœ‰ğ‘›). It remains
ğ‘› ), which we do below: for all
to show the fourth conjunct in the definition of usedâˆ’ (ğ‘ â€²â€², ğœ â€²
ğœ‡ âˆˆ Name,

0, ğœ‰ â€²â€²

ğ‘ â€²â€²
(cid:74)

ğ‘ â€²â€²
(cid:74)

0(cntğœ‡) = 1 âˆ§ ğœ â€²

0(cntğœ‡) âˆ’ ğœ â€²
ğœ â€²
0(cntğœ‡) = 1
(cid:75)
ğœ â€²
0(cntğœ‡) âˆ’ ğœ â€²
â‡â‡’
(cid:75)
â‡â‡’ ğœ‡ âˆˆ ğ‘0 âˆ§ ğœ‡ âˆ‰ ğ‘ â€²
0
â‡â‡’ ğœ‡ âˆˆ dom(ğœ‰ â€²â€²
The first equivalence comes from Lemma C.4 and
0(cntğœ‡) âˆ’ ğœ0(cntğœ‡) â‰¤ 1, which holds be-
ğœ â€²
(cid:75)
0.
cause of usedâˆ’ (ğ‘ â€²; ğ‘ â€²â€², ğœ0, ğœ‰ğ‘›). The second equivalence follows from the definitions of ğ‘0 and ğ‘ â€²
ğ‘›), we can apply induction

ğ‘ â€²â€²
(cid:74)
ğœ1 and we have usedâˆ’ (ğ‘ â€², ğœ0, ğœ‰ â€²

0(cntğœ‡) âˆ’ ğœ0(cntğœ‡) = 0

(3) Since ğœ0 âˆ¼ğœ‰ğ‘› ğœ1 implies ğœ0 âˆ¼ğœ‰ â€²

hypothesis to (ğ‘ â€², ğœ‰ â€²

ğœ1 âˆˆ St.
(cid:75)
(4) We continue our reasoning in the previous item, and derive from induction hypothesis on

ğ‘›, ğœ0, ğœ1), and get

ğ‘ â€²
(cid:74)

ğ‘› ).

ğ‘›

(ğ‘ â€², ğœ‰ â€²

ğ‘›, ğœ0, ğœ1) the fact that for all ğ‘¥ âˆˆ PVar,
ğœ â€²
ğœ0(ğ‘¥) =
0(ğ‘¥) =
(cid:75)

ğ‘ â€²
(cid:74)

Also, for all ğœ‡ âˆˆ dom(ğœ‰ â€²â€²

ğ‘› ),

ğ‘ â€²
(cid:74)

ğœ1(ğ‘¥) = ğœ â€²
(cid:75)

1(ğ‘¥).

0(ğœ‡) = ğœ0(ğœ‡) = ğœ1(ğœ‡) = ğœ â€²
ğœ â€²

1(ğœ‡),

ğ‘
(cid:74)

where the first and third equalities come from Lemma C.4, and the second equality follows
from the assumption that ğœ0 âˆ¼ğœ‰ğ‘› ğœ1.
Case ğ‘ â‰¡ (if ğ‘ {ğ‘ â€²} else ğ‘ â€²â€²). Assume that

ğœ0. We prove the five
ğœ0 = true. Then,
(cid:75)
(cid:75)
properties claimed by the lemma under this assumption. The proof for the other possibility, namely,
ğœ0 = false is similar. Since ğœ0 âˆ¼ğœ‰ğ‘› ğœ1, the states ğœ0 and ğœ1 coincide for the values of program
ğ‘
(cid:74)
(cid:75)
ğœ0 as well, it suffices to show
ğœ1. Since
variables. Thus,
(cid:75)
(cid:75)
the five properties claimed by the lemma for (ğ‘ â€², ğœ0, ğœ1, ğœ‰ğ‘›). This sufficient condition follows from
ğœ0 = true imply usedâˆ’(ğ‘ â€², ğœ0, ğœ‰ğ‘›).
induction hypothesis on (ğ‘ â€², ğœ0, ğœ1, ğœ‰ğ‘›), since usedâˆ’ (ğ‘, ğœ0, ğœ‰ğ‘›) and
(cid:75)
Case ğ‘ â‰¡ (while ğ‘ {ğ‘ â€²}). Consider the version of usedâˆ’ where the first parameter can be a state
transformer ğ‘“ : St â†’ StâŠ¥, instead of a command. Similarly, consider the version of the five properties
claimed by the lemma where we use a state transformer ğ‘“ : St â†’ StâŠ¥, again instead of a command.
We denote both versions by usedâˆ’(ğ‘“ , ğœ â€²â€²
1 ). Let T be the subset of St â†’ StâŠ¥
ğ‘› ) and ğœ‘ (ğ‘“ , ğœ‰ â€²â€²
defined by

ğœ1 = true, and
(cid:75)

ğ‘ â€²
(cid:74)
ğ‘
(cid:74)

ğœ0 =
(cid:75)

ğœ1 =
(cid:75)

ğœ0 =
(cid:75)

0 , ğœ â€²â€²

ğ‘› , ğœ â€²â€²

0 , ğœ‰ â€²â€²

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘“ âˆˆ T â‡â‡’ âˆ€ğœ â€²â€²

0 , ğœ â€²â€²

1 âˆˆ St. âˆ€ğœ‰ â€²â€²

ğ‘› âˆˆ Stâ–¡.

(cid:16)(cid:16)

usedâˆ’(ğ‘“ , ğœ â€²â€²

0 , ğœ‰ â€²â€²

ğ‘› ) âˆ§ ğœ â€²â€²

0 âˆ¼ğœ‰ â€²â€²

ğ‘›

(cid:17)

ğœ â€²â€²
1

=â‡’ ğœ‘ (ğ‘“ , ğœ‰ â€²â€²

ğ‘› , ğœ â€²â€²

0 , ğœ â€²â€²
1 )

(cid:17)

,

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

and ğ¹ : [St â†’ StâŠ¥] â†’ [St â†’ StâŠ¥] be the following operator used in the semantics of the loop

0:41

ğ‘
(cid:74)

:
(cid:75)

ğ¹ (ğ‘“ )(ğœ) â‰œ if (

ğ‘
(cid:74)

ğœ = true) then ğ‘“ â€  (
(cid:75)

ğ‘ â€²
(cid:74)

ğœ) else ğœ.
(cid:75)

We will show that T contains ğœ†ğœ. âŠ¥ and is closed under taking the least upper bound of an increasing
chain in [St â†’ StâŠ¥], and the operator ğ¹ preserves T . These three conditions imply that
is in T ,
which in turn gives the five properties claimed by the lemma.
The first condition holds simply because usedâˆ’ ((ğœ†ğœ.âŠ¥), ğœ â€²â€²

ğ‘
(cid:74)
ğ‘› . To prove
0 and ğœ‰ â€²â€²
the closure under the least upper bound of a chain, consider an increasing sequence ğ‘“0, ğ‘“1, . . . in T .
Let ğ‘“âˆ â‰œ (cid:195)ğ‘› âˆˆN ğ‘“ğ‘›. Consider ğœ â€²â€²
ğ‘› ).
0 , ğœ‰ â€²â€²
1 ) holds. By the definition of ğ‘“âˆ, there exists ğ‘š âˆˆ N such that
We should show that ğœ‘ (ğ‘“âˆ, ğœ‰ â€²â€²
ğ‘“âˆ(ğœ0) = ğ‘“ğ‘š (ğœ0). Then, the assumption usedâˆ’(ğ‘“âˆ, ğœ â€²â€²
ğ‘› ). This in turn
ğ‘› ) implies usedâˆ’ (ğ‘“ğ‘š, ğœ â€²â€²
gives ğœ‘ (ğ‘“ğ‘š, ğœ‰ â€²â€²
1 ) because ğ‘“ğ‘š âˆˆ T . By what we have proved and the definition of ğ‘“âˆ, we have

1 âˆˆ St and ğœ‰ â€²â€²
0 , ğœ â€²â€²

1 and usedâˆ’ (ğ‘“âˆ, ğœ â€²â€²
ğœ â€²â€²

ğ‘› âˆˆ Stâ–¡ such that ğœ â€²â€²

ğ‘› ) is false for all ğœ â€²â€²

0 , ğœ â€²â€²
ğ‘› , ğœ â€²â€²

0 , ğœ â€²â€²

0 âˆ¼ğœ‰ â€²â€²

ğ‘› , ğœ â€²â€²

0 , ğœ‰ â€²â€²

0 , ğœ‰ â€²â€²

0 , ğœ‰ â€²â€²

(cid:75)

ğ‘›

ğ‘“ğ‘š (ğœ â€²â€²

0 ) = ğ‘“âˆ (ğœ â€²â€²

0 ) âˆˆ St

and

ğ‘“ğ‘š (ğœ â€²â€²

1 ) = ğ‘“âˆ (ğœ â€²â€²

1 ) âˆˆ St.

ğ‘› , ğœ â€²â€²

0 , ğœ â€²â€²

1 ) entails ğœ‘ (ğ‘“âˆ, ğœ‰ â€²â€²

Thus, ğœ‘ (ğ‘“ğ‘š, ğœ‰ â€²â€²
1 ), as desired. It remains to show that ğ¹ (ğ‘“ ) âˆˆ T for
all ğ‘“ âˆˆ T . Pick ğ‘“ âˆˆ T . We first replay our proof for the sequential-composition case after view-
as the sequential composition of ğ‘ â€² and ğ‘“ . This replay, then, gives the membership
ing ğ‘“ â€  â—¦
ğ‘ â€²
(cid:74)
as the true
âˆˆ T . Next, we replay our proof for the if case on ğ¹ (ğ‘“ ) after viewing ğ‘“ â€  â—¦
ğ‘ â€²
ğ‘“ â€  â—¦
(cid:74)
(cid:75)
â–¡
branch and ğœ†ğœ. ğœ =

as the false branch. This replay implies the required ğ¹ (ğ‘“ ) âˆˆ T .

0 , ğœ â€²â€²

ğ‘› , ğœ â€²â€²

ğ‘ â€²
(cid:74)

(cid:75)

(cid:75)

skip
(cid:75)

(cid:74)

Lemma C.7. Let ğ‘ be a command, ğœ, ğœ â€² âˆˆ St, and ğœ‰ğ‘› âˆˆ Stâ–¡ [Name].
â€¢ If ğœ |ğ‘‰ = ğœ â€²|ğ‘‰ for ğ‘‰ â‰œ PVar âˆª dom(ğœ‰ğ‘›) âˆª {like}, then used (ğ‘, ğœ, ğœ‰ğ‘›) implies used (ğ‘, ğœ â€², ğœ‰ğ‘›).
â€¢ If ğœ |ğ‘ˆ = ğœ â€²|ğ‘ˆ for ğ‘ˆ â‰œ PVar âˆª dom(ğœ‰ğ‘›), then usedâˆ’ (ğ‘, ğœ, ğœ‰ğ‘›) implies usedâˆ’ (ğ‘, ğœ â€², ğœ‰ğ‘›).

Proof. Assume the settings in the statement of this lemma. For the first claim, assume used (ğ‘, ğœ, ğœ‰ğ‘›).

Then, by the definition of used and noerr,

ğœ âˆˆ St âˆ§ (cid:0)âˆ€ğœ‡ âˆˆ Name.
ğ‘
(cid:74)
(cid:75)
âˆ§ (cid:0)ğœ‰ğ‘› = ğœ |dom(ğœ‰ğ‘›)

(cid:1) âˆ§ (cid:0)dom(ğœ‰ğ‘›) = {ğœ‡ âˆˆ Name |

ğœ (cntğœ‡) âˆ’ ğœ (cntğœ‡) â‰¤ 1(cid:1) âˆ§ (cid:0)ğœ (like) = 1(cid:1)
(cid:75)
ğ‘
(cid:74)

ğœ (cntğœ‡) âˆ’ ğœ (cntğœ‡) = 1}(cid:1).
(cid:75)

ğ‘
(cid:74)

From this and Lemma C.6 (which is applicable since used (ğ‘, ğœ, ğœ‰ğ‘›) and ğœ |ğ‘‰ = ğœ â€²|ğ‘‰ ), we obtain

ğœ â€² âˆˆ St âˆ§ (cid:0)âˆ€ğœ‡ âˆˆ Name.
ğ‘
(cid:74)
(cid:75)
âˆ§ (cid:0)ğœ‰ğ‘› = ğœ â€²|dom(ğœ‰ğ‘›)

(cid:1) âˆ§ (cid:0)dom(ğœ‰ğ‘›) = {ğœ‡ âˆˆ Name |

ğœ â€²(cntğœ‡) âˆ’ ğœ â€²(cntğœ‡) â‰¤ 1(cid:1) âˆ§ (cid:0)ğœ â€²(like) = 1(cid:1)
(cid:75)
ğ‘
(cid:74)

ğœ â€²(cntğœ‡) âˆ’ ğœ â€²(cntğœ‡) = 1}(cid:1).
(cid:75)

ğ‘
(cid:74)

Note that we have the first clause by Lemma C.6-(1), the second and fifth clauses by Lemma C.6â€“(5),
and the third and fourth clauses by ğœ |ğ‘‰ = ğœ â€²|ğ‘‰ . Hence, used (ğ‘, ğœ â€², ğœ‰ğ‘›) holds. The proof of the second
claim is exactly the same except that we apply Lemma C.6 to ğœ |ğ‘ˆ = ğœ â€²|ğ‘ˆ to prove only the four
â–¡
clauses of used that exclude ğœ â€²(like) = 1.

C.3 Proof of Lemma C.3

Proof of Lemma C.3. We prove this lemma by induction on the structure of ğ‘. Let ğ‘” : St[PVar] Ã—
Stâ–¡ [Name] â†’ R be a measurable function and ğœğ‘ âˆˆ St[PVar]. In this proof, each equation involving
integrals means (otherwise noted) that one side of the equation is defined if and only if the other
side is defined, and when both sides are defined, they are the same.

Case ğ‘ â‰¡ skip, ğ‘ â‰¡ (ğ‘¥ := ğ‘’), or ğ‘ â‰¡ obs(ğ‘‘, ğ‘Ÿ ). In this case, ğ‘ğœ‹ â‰¡ ğ‘ so the desired equation holds.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:42

Wonyeol Lee, Xavier Rival, and Hongseok Yang

Case ğ‘ â‰¡ (ğ‘¥ := sam(ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’)). If (ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’) âˆ‰ dom(ğœ‹), then ğ‘ğœ‹ â‰¡ ğ‘ and thus the desired
equation holds. So assume that ğœ‹ (ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’) = (ğ‘‘ â€², ğœ†ğ‘¦ â€².ğ‘’ â€²) for some ğ‘‘ â€² and ğœ†ğ‘¦ â€².ğ‘’ â€². Then, ğ‘ğœ‹ â‰¡ (ğ‘¥ :=
sam(ğ‘›, ğ‘‘ â€², ğœ†ğ‘¦ â€².ğ‘’ â€²)).

First, by the validity of ğœ‹, for all states ğœ âˆˆ St and measurable subsets ğ´ âŠ† R,

âˆ«

1[

ğ‘’ [ğ‘Ÿ /ğ‘¦ ]
(cid:74)

ğœ âˆˆğ´] Â·
(cid:75)

ğ‘‘
(cid:74)

ğœ (ğ‘Ÿ ) ğ‘‘ğ‘Ÿ =
(cid:75)

âˆ«

1[

ğ‘’â€² [ğ‘Ÿ /ğ‘¦â€² ]
(cid:74)

ğœ âˆˆğ´] Â·
(cid:75)

ğ‘‘ â€²
(cid:74)

ğœ (ğ‘Ÿ ) ğ‘‘ğ‘Ÿ,
(cid:75)

where both sides are always defined. Using this and the monotone convergence theorem, we can
show that for all measurable ğ‘“ : R â†’ R,

âˆ«

ğ‘“ (

ğ‘’ [ğ‘Ÿ /ğ‘¦]
(cid:74)

ğœ) Â·
(cid:75)

ğ‘‘
(cid:74)

ğœ (ğ‘Ÿ ) ğ‘‘ğ‘Ÿ =
(cid:75)

âˆ«

ğ‘“ (

ğ‘’ â€²[ğ‘Ÿ /ğ‘¦ â€²]
(cid:74)

ğœ) Â·
(cid:75)

ğ‘‘ â€²
(cid:74)

ğœ (ğ‘Ÿ ) ğ‘‘ğ‘Ÿ .
(cid:75)

(18)

Next, choose any ğœğ‘Ÿ0 âˆˆ St[Var \ PVar]. Since fv(ğ‘›) âŠ† PVar, there exists ğœ‡ âˆˆ Name such that

Using this and fv(ğ‘’), fv(ğ‘‘) âŠ† PVar, we obtain the following: for any ğœğ‘Ÿ âˆˆ St[Var \ PVar],

(ğœğ‘ âŠ• ğœğ‘Ÿ ) = ğœ‡

for all ğœğ‘Ÿ âˆˆ St[Var \ PVar].

ğ‘›
(cid:74)

(cid:75)

(ğœğ‘ âŠ• ğœğ‘Ÿ )(ğœğ‘Ÿ (ğœ‡)) =

ğ‘
(cid:74)

(cid:75)
ğ‘
(cid:74)
ğ‘
(cid:74)
ğ‘
(cid:74)

(ğœğ‘ âŠ• ğœğ‘Ÿ )(like) = 1,
ğ‘‘
(ğœğ‘ âŠ• ğœğ‘Ÿ )(pr ğœ‡) =
(cid:74)
(cid:75)
(cid:75)
ğ‘’ [ğœğ‘Ÿ (ğœ‡)/ğ‘¦]
(ğœğ‘ âŠ• ğœğ‘Ÿ )(valğœ‡) =
(cid:74)
(ğœğ‘ âŠ• ğœğ‘Ÿ )(cntğœ‡) = 1,
(cid:75)
ğ‘
(cid:74)

ğ‘
(cid:74)
(ğœğ‘ âŠ• ğœğ‘Ÿ )|PVar = ğœğ‘ [ğ‘¥ â†¦â†’

(cid:75)

ğ‘‘
(cid:74)
(ğœğ‘ âŠ• ğœğ‘Ÿ ) =
(ğœğ‘ âŠ• ğœğ‘Ÿ )(cntğœ‡â€²) = 0
(cid:75)
ğ‘’ [ğœğ‘Ÿ (ğœ‡)/ğ‘¦]
(cid:74)

(cid:75)

(cid:75)

(ğœğ‘ âŠ• ğœğ‘Ÿ0)].
This implies that for any ğœ‰ğ‘› âˆˆ Stâ–¡ [Name], if prsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) â‰  0, then

(cid:75)

(ğœğ‘ âŠ• ğœğ‘Ÿ0)(ğœğ‘Ÿ (ğœ‡)),
(cid:75)
ğ‘’ [ğœğ‘Ÿ (ğœ‡)/ğ‘¦]
(cid:74)

(cid:75)
for ğœ‡ â€² (cid:46) ğœ‡,

(ğœğ‘ âŠ• ğœğ‘Ÿ0),

prsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) = 1 Â·

dom(ğœ‰ğ‘›) = {ğœ‡},
ğ‘‘
(cid:74)

pvarsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) = ğœğ‘ [ğ‘¥ â†¦â†’
valsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) = [ğœ‡ â†¦â†’

(cid:75)

(ğœğ‘ âŠ• ğœğ‘Ÿ0)(ğœ‰ğ‘› (ğœ‡)),
ğ‘’ [ğœ‰ğ‘› (ğœ‡)/ğ‘¦]
(cid:74)

(ğœğ‘ âŠ• ğœğ‘Ÿ0)],

(cid:75)
(ğœğ‘ âŠ• ğœğ‘Ÿ0)].

ğ‘’ [ğœ‰ğ‘› (ğœ‡)/ğ‘¦]
(cid:74)
Note that the same equations hold for ğ‘ğœ‹ , except that we replace ğ‘‘, ğ‘’, and ğ‘¦ in the RHS of the above
equations by ğ‘‘ â€², ğ‘’ â€², and ğ‘¦ â€². Using these, we obtain:

(cid:75)

âˆ«

(cid:16)

ğ‘‘ğœ‰ğ‘›

prsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”

(cid:16)

pvarsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›), valsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

ğ‘’ [ğœ‰ğ‘› (ğœ‡)/ğ‘¦]
(cid:74)

(cid:75)

(ğœğ‘ âŠ• ğœğ‘Ÿ0)

(cid:17)(cid:17)

âˆ«

âˆ«

[ {ğœ‡ }â†’R]
(cid:16)

ğ‘‘ğ‘Ÿ

(cid:16)

ğ‘‘ğ‘Ÿ

R
âˆ«

R
âˆ«

âˆ«

[ {ğœ‡ }â†’R]
(cid:16)

ğ‘‘ğœ‰ğ‘›

ğ‘‘
(cid:74)
(cid:75)
ğ‘‘ â€²
(cid:74)

(cid:16)

ğ‘‘ğœ‰ğ‘›

ğ‘‘
(cid:74)

(cid:16)
ğ‘”
(ğœğ‘ âŠ• ğœğ‘Ÿ0 )(ğœ‰ğ‘› (ğœ‡)) Â· (cid:98)
(cid:75)
(cid:16)
ğ‘”
(ğœğ‘ âŠ• ğœğ‘Ÿ0 )(ğ‘Ÿ ) Â· (cid:98)

ğ‘’ [ğ‘Ÿ /ğ‘¦]
(cid:74)
(cid:16)
ğ‘”
(ğœğ‘ âŠ• ğœğ‘Ÿ0)(ğ‘Ÿ ) Â· (cid:98)

(cid:75)
ğ‘’ â€²[ğ‘Ÿ /ğ‘¦ â€²]
(cid:75)
(cid:74)
(cid:16)
ğ‘”
(ğœğ‘ âŠ• ğœğ‘Ÿ0)(ğœ‰ğ‘› (ğœ‡)) Â· (cid:98)
(cid:16)

ğ‘‘ â€²
(cid:74)

(cid:75)
prsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”

(cid:75)
ğ‘‘ğœ‰ğ‘›

(cid:16)

=

=

=

=

=

(ğœğ‘ âŠ• ğœğ‘Ÿ0)

(cid:17)(cid:17)

(ğœğ‘ âŠ• ğœğ‘Ÿ0)

(cid:17)(cid:17)

ğ‘’ â€²[ğœ‰ğ‘› (ğœ‡)/ğ‘¦ â€²]
(cid:74)

(cid:75)

(ğœğ‘ âŠ• ğœğ‘Ÿ0)

(cid:17)(cid:17)

pvarsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›), valsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

ğ‘” : R â†’ R is defined as
(cid:98)

where
ğ‘”(ğ‘Ÿ ) = ğ‘”(ğœğ‘ [ğ‘¥ â†¦â†’ ğ‘Ÿ ], [ğœ‡ â†¦â†’ ğ‘Ÿ ]). Here the first and fifth equalities use
(cid:98)
the equations proven above, the second and fourth equalities use that [{ğœ‡} â†’ R] is isomorphic to
R, and the third equality uses Eq. (18). This proves the desired equation.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

Case ğ‘ â‰¡ (if ğ‘ {ğ‘ â€²} else ğ‘ â€²â€²). In this case, since ğ‘“ ğ‘£ (ğ‘) âŠ† PVar and ğ‘ğœ‹ â‰¡ if ğ‘ {ğ‘ â€²

have only two subcases:

0:43

ğœ‹

} else ğ‘ â€²â€²

ğœ‹ , we

â€¢ For all ğœğ‘Ÿ âˆˆ St[Var \ PVar],
ğ‘
(cid:74)
â€¢ For all ğœğ‘Ÿ âˆˆ St[Var \ PVar],
ğ‘
(cid:74)
If the first subcase holds, we have

(ğœğ‘ âŠ• ğœğ‘Ÿ ) =
(cid:75)
(ğœğ‘ âŠ• ğœğ‘Ÿ ) =
(cid:75)

ğ‘ â€²
(cid:75)
(cid:74)
ğ‘ â€²â€²
(cid:75)
(cid:74)

(ğœğ‘ âŠ• ğœğ‘Ÿ ) and
(ğœğ‘ âŠ• ğœğ‘Ÿ ) and

ğ‘ğœ‹
(cid:74)
ğ‘ğœ‹
(cid:74)

(ğœğ‘ âŠ• ğœğ‘Ÿ ) =
(cid:75)
(ğœğ‘ âŠ• ğœğ‘Ÿ ) =
(cid:75)

ğœ‹

ğœ‹

ğ‘ â€²
(cid:74)
ğ‘ â€²â€²
(cid:74)

(ğœğ‘ âŠ• ğœğ‘Ÿ ).
(ğœğ‘ âŠ• ğœğ‘Ÿ ).

(cid:75)
(cid:75)

âˆ«

(cid:16)

ğ‘‘ğœ‰ğ‘›

prsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”

(cid:16)

pvarsâ–¡(ğ‘)(ğœğ‘, ğœ‰ğ‘›), valsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

âˆ«

âˆ«

âˆ«

=

=

=

(cid:16)

(cid:16)

(cid:16)

ğ‘‘ğœ‰ğ‘›

ğ‘‘ğœ‰ğ‘›

ğ‘‘ğœ‰ğ‘›

prsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”

(cid:16)

pvarsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ğ‘›), valsâ–¡(ğ‘ â€²)(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

ğœ‹

prsâ–¡ (ğ‘ â€²

)(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”

(cid:16)

pvarsâ–¡(ğ‘ â€²

ğœ‹

)(ğœğ‘, ğœ‰ğ‘›), valsâ–¡ (ğ‘ â€²

ğœ‹

)(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

prsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”

(cid:16)

pvarsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›), valsâ–¡(ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

where the second equality is by IH on ğ‘ â€². If the second subcase holds, we obtain a similar equation
by IH on ğ‘ â€²â€². Hence, the desired equation holds in all subcases.

Case ğ‘ â‰¡ (ğ‘ â€²; ğ‘ â€²â€²). In this case, we obtain the following equation:

âˆ«

(cid:16)

ğ‘‘ğœ‰ğ‘›

prsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”
âˆ«

prsâ–¡(ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›) Â·

(cid:16)

(cid:16)

pvarsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ğ‘›), valsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

(cid:16)

ğ‘‘ğœ‰ â€²â€²
ğ‘›

prsâ–¡ (ğ‘ â€²â€²) (cid:0)pvarsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›), ğœ‰ â€²â€²
ğ‘›

(cid:1) Â· 1[dom(ğœ‰ â€²

ğ‘›)âˆ©dom(ğœ‰ â€²â€²

ğ‘›)=âˆ…]

pvarsâ–¡ (ğ‘ â€²â€²) (cid:0)pvarsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²
(cid:16)

ğ‘›) Â· ğ‘”â€² (cid:16)
prsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²
âˆ«

(cid:16)

ğ‘›), ğœ‰ â€²â€²
ğ‘›

(cid:1), valsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›) âŠ• valsâ–¡ (ğ‘ â€²â€²) (cid:0)pvarsâ–¡(ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›), ğœ‰ â€²â€²
ğ‘›

(cid:1)(cid:17)(cid:17)(cid:17)

pvarsâ–¡(ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›), valsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²
ğ‘›)

(cid:17)(cid:17)

where ğ‘”â€²( (cid:98)ğœ â€²

ğ‘, (cid:98)ğœ‰ â€²

ğ‘›) â‰œ

ğ‘‘ğœ‰ â€²â€²
ğ‘›

prsâ–¡ (ğ‘ â€²â€²)( (cid:98)ğœ â€²

ğ‘, ğœ‰ â€²â€²

ğ‘› ) Â· 1[dom((cid:99)ğœ‰ â€²

ğ‘›)âˆ©dom(ğœ‰ â€²â€²

ğ‘›)=âˆ…]

(cid:16)

Â· ğ‘”

pvarsâ–¡ (ğ‘ â€²â€²)( (cid:98)ğœ â€²

ğ‘, ğœ‰ â€²â€²

ğ‘› ), (cid:98)ğœ‰ â€²

ğ‘› âŠ• valsâ–¡ (ğ‘ â€²â€²)( (cid:98)ğœ â€²

ğ‘, ğœ‰ â€²â€²
ğ‘› )

(cid:17)(cid:17)

(cid:16)

ğ‘‘ğœ‰ â€²
ğ‘›

prsâ–¡ (ğ‘ â€²

ğœ‹

)(ğœğ‘, ğœ‰ â€²

ğ‘›) Â· ğ‘”â€² (cid:16)

pvarsâ–¡ (ğ‘ â€²

ğœ‹

)(ğœğ‘, ğœ‰ â€²

ğ‘›), valsâ–¡ (ğ‘ â€²

ğœ‹

)(ğœğ‘, ğœ‰ â€²
ğ‘›)

(cid:17)(cid:17)

Â· Â· Â·

(âˆ—)

ğ‘‘ğœ‰ â€²
ğ‘›

(cid:16)

Â· ğ‘”

ğ‘‘ğœ‰ â€²
ğ‘›

âˆ«

=

âˆ«

=

âˆ«

=

where the first equality is from Lemma C.9, the second equality uses dom(ğœ‰ â€²
and the third equality is by IH on ğ‘ â€². We now analyse ğ‘”â€²( (cid:98)ğœ â€²
ğ‘”â€²( (cid:98)ğœ â€²
ğ‘, (cid:98)ğœ‰ â€²
ğ‘›)
âˆ«

ğ‘›) as follows:

ğ‘, (cid:98)ğœ‰ â€²

(cid:16)

(cid:16)

=

ğ‘‘ğœ‰ â€²â€²
ğ‘›

prsâ–¡(ğ‘ â€²â€²)( (cid:98)ğœ â€²

ğ‘, ğœ‰ â€²â€²

âˆ«

=

(cid:16)

ğ‘‘ğœ‰ â€²â€²
ğ‘›

prsâ–¡(ğ‘ â€²â€²)( (cid:98)ğœ â€²

ğ‘, ğœ‰ â€²â€²

pvarsâ–¡(ğ‘ â€²â€²)( (cid:98)ğœ â€²

ğ‘, ğœ‰ â€²â€²

ğ‘› ), valsâ–¡ (ğ‘ â€²â€²)( (cid:98)ğœ â€²

ğ‘, ğœ‰ â€²â€²
ğ‘› )

(cid:17)(cid:17)

ğ‘› ) Â· 1[dom((cid:99)ğœ‰ â€²
ğ‘› ) Â· ğ‘”â€²â€² (cid:16)

ğ‘›)âˆ©dom(ğœ‰ â€²â€²

ğ‘›)=âˆ…] Â· ğ‘”

pvarsâ–¡ (ğ‘ â€²â€²)( (cid:98)ğœ â€²

ğ‘, ğœ‰ â€²â€²

ğ‘› ), (cid:98)ğœ‰ â€²

ğ‘› âŠ• valsâ–¡ (ğ‘ â€²â€²)( (cid:98)ğœ â€²

ğ‘, ğœ‰ â€²â€²
ğ‘› )

(cid:17)(cid:17)

ğ‘›) = dom(valsâ–¡(ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›)),

ğ‘ , (cid:99)ğœ‰ â€²â€²

where ğ‘”â€²â€²( (cid:99)ğœ â€²â€²
(cid:16)

ğ‘‘ğœ‰ â€²â€²
ğ‘›

prsâ–¡(ğ‘ â€²â€²

ğ‘› ) â‰œ 1[dom((cid:99)ğœ‰ â€²
ğ‘› ) Â· ğ‘”â€²â€² (cid:16)
ğ‘, ğœ‰ â€²â€²
)( (cid:98)ğœ â€²

âˆ«

âˆ«

=

=

ğœ‹

ğœ‹

(cid:16)

ğ‘‘ğœ‰ â€²â€²
ğ‘›

prsâ–¡(ğ‘ â€²â€²

ğ‘›)âˆ©dom((cid:99)ğœ‰ â€²â€²

ğ‘›)=âˆ…] Â· ğ‘”

(cid:16)
ğ‘ , (cid:98)ğœ‰ â€²
(cid:99)ğœ â€²â€²

ğ‘› âŠ• (cid:99)ğœ‰ â€²â€²
ğ‘›

(cid:17)

pvarsâ–¡ (ğ‘ â€²â€²

ğœ‹

)( (cid:98)ğœ â€²

ğ‘, ğœ‰ â€²â€²

ğ‘› ), valsâ–¡ (ğ‘ â€²â€²

ğœ‹

)( (cid:98)ğœ â€²

ğ‘, ğœ‰ â€²â€²
ğ‘› )

(cid:17)(cid:17)

)( (cid:98)ğœ â€²

ğ‘, ğœ‰ â€²â€²

ğ‘› ) Â· 1[dom((cid:99)ğœ‰ â€²

ğ‘›)âˆ©dom(ğœ‰ â€²â€²

ğ‘›)=âˆ…] Â· ğ‘”

(cid:16)

pvarsâ–¡ (ğ‘ â€²â€²

ğœ‹

)( (cid:98)ğœ â€²

ğ‘, ğœ‰ â€²â€²

ğ‘› ), (cid:98)ğœ‰ â€²

ğ‘› âŠ• valsâ–¡ (ğ‘ â€²â€²

ğœ‹

)( (cid:98)ğœ â€²

ğ‘, ğœ‰ â€²â€²
ğ‘› )

(cid:17)(cid:17)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:44

Wonyeol Lee, Xavier Rival, and Hongseok Yang

where the second and fourth equalities use dom(ğœ‰ â€²â€²
ity is by IH on ğ‘ â€²â€². Using this, we obtain the following equation for the main quantity (âˆ—):

ğ‘› ) = dom(valsâ–¡ (ğ‘ â€²â€²)( (cid:98)ğœ â€²

ğ‘› )), and the third equal-

ğ‘, ğœ‰ â€²â€²

âˆ«

(âˆ—) =

(cid:16)

ğ‘‘ğœ‰ â€²
ğ‘›

ğœ‹

prsâ–¡(ğ‘ â€²

)(ğœğ‘, ğœ‰ â€²

ğ‘›) Â·

âˆ«

(cid:16)

ğ‘‘ğœ‰ â€²â€²
ğ‘›

prsâ–¡ (ğ‘ â€²â€²

ğœ‹

) (cid:0)pvarsâ–¡ (ğ‘ â€²

ğœ‹

)(ğœğ‘, ğœ‰ â€²

ğ‘›), ğœ‰ â€²â€²
ğ‘›

(cid:1) Â· 1[dom(ğœ‰ â€²

ğ‘›)âˆ©dom(ğœ‰ â€²â€²

ğ‘›)=âˆ…]

(cid:16)

Â· ğ‘”

pvarsâ–¡ (ğ‘ â€²â€²
ğœ‹

valsâ–¡ (ğ‘ â€²

ğœ‹

) (cid:0)pvarsâ–¡(ğ‘ â€²

ğœ‹

)(ğœğ‘, ğœ‰ â€²

ğ‘›), ğœ‰ â€²â€²
ğ‘›

(cid:1),

)(ğœğ‘, ğœ‰ â€²

ğ‘›) âŠ• valsâ–¡ (ğ‘ â€²â€²

ğœ‹

) (cid:0)pvarsâ–¡(ğ‘ â€²

ğœ‹

)(ğœğ‘, ğœ‰ â€²

ğ‘›), ğœ‰ â€²â€²
ğ‘›

(cid:1)(cid:17)(cid:17)(cid:17)

âˆ«

=

(cid:16)

ğ‘‘ğœ‰ğ‘›

prsâ–¡ (ğ‘ â€²

ğœ‹ ; ğ‘ â€²â€²

ğœ‹

)(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”

(cid:16)

pvarsâ–¡(ğ‘ â€²

ğœ‹ ; ğ‘ â€²â€²

ğœ‹

)(ğœğ‘, ğœ‰ğ‘›), valsâ–¡(ğ‘ â€²

ğœ‹ ; ğ‘ â€²â€²

ğœ‹

)(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

where the first equality uses dom(ğœ‰ â€²
ğ‘›) = dom(valsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²
ğœ‹
Lemma C.9, as we did above. By ğ‘ â€²; ğ‘ â€²â€²

ğœ‹ , we get the desired equation.

ğœ‹ ; ğ‘ â€²â€²

ğ‘›)), and the second equality is by

â‰¡ ğ‘ â€²

Case ğ‘ â‰¡ (while ğ‘ {ğ‘ â€²}). In this case, ğ‘ğœ‹ â‰¡ (while ğ‘ {ğ‘ â€²

}). Without loss of generality, assume
that ğ‘” is a nonnegative function; we can prove the general case of ğ‘” directly from the nonnegative
case of ğ‘”, by considering the nonnegative part and the negative part of ğ‘” separately.

ğœ‹

Consider the version of prsâ–¡ (âˆ’), pvarsâ–¡(âˆ’), and valsâ–¡ (âˆ’), where the parameter can be a state
transformer ğ‘“ : St â†’ StâŠ¥, instead of a command. We denote the versions by prsâ–¡ (ğ‘“ ), pvarsâ–¡ (ğ‘“ ), and
valsâ–¡ (ğ‘“ ). Define T âŠ† [St â†’ StâŠ¥]2 and ğ‘‡ : [St â†’ StâŠ¥]2 â†’ [St â†’ StâŠ¥]2 by

(ğ‘“ , ğ‘“ ) âˆˆ T â‡â‡’

âˆ«

ğ‘‘ğœ‰ğ‘› ğºğ‘”â€²,ğœâ€²

ğ‘ (ğ‘“ )(ğœ‰ğ‘›) =

âˆ«

ğ‘‘ğœ‰ğ‘› ğºğ‘”â€²,ğœâ€²

ğ‘ (ğ‘“ )(ğœ‰ğ‘›)

for all measurable ğ‘”â€² : St[PVar] Ã— Stâ–¡ [Name] â†’ Râ‰¥0 and ğœ â€²

ğ‘ âˆˆ St[PVar],

ğ‘‡ (ğ‘“ , ğ‘“ ) â‰œ (ğ¹ (ğ‘“ ), ğ¹ (ğ‘“ )),

where ğºğ‘”â€²,ğœâ€²

ğ‘ (ğ‘“ ) âˆˆ Stâ–¡ [Name] â†’ Râ‰¥0 and ğ¹, ğ¹ : [St â†’ StâŠ¥] â†’ [St â†’ StâŠ¥] are defined by

ğºğ‘”â€²,ğœâ€²

ğ¹ (ğ‘“ )(ğœ) â‰œ if (

pvarsâ–¡(ğ‘“ )(ğœ â€²

ğ‘, ğœ‰ğ‘›), valsâ–¡ (ğ‘“ )(ğœ â€²

ğ‘ (ğ‘“ )(ğœ‰ğ‘›) â‰œ prsâ–¡(ğ‘“ )(ğœ â€²
ğ¹ (ğ‘“ )(ğœ) â‰œ if (

ğ‘, ğœ‰ğ‘›) Â· ğ‘”â€² (cid:16)
ğœ = true) then (ğ‘“ â€  â—¦
(cid:75)
ğœ = true) then (ğ‘“ â€  â—¦
(cid:75)
, respectively. We
Note that ğ¹ and ğ¹ are the operators used in the semantics of the loops
will show that T contains (ğœ†ğœ. âŠ¥, ğœ†ğœ. âŠ¥), the operator ğ‘‡ preserves T , and T is closed under taking
the least upper bound of an increasing chain in [St â†’ StâŠ¥]2, where the order on [St â†’ StâŠ¥]2 is
defined as: (ğ‘“0, ğ‘“0) âŠ‘ (ğ‘“1, ğ‘“1) â‡â‡’ ğ‘“0 âŠ‘ ğ‘“1 âˆ§ ğ‘“0 âŠ‘ ğ‘“1. These three conditions imply (
) âˆˆ T ,
(cid:75)
which in turn proves the desired equation:

)(ğœ) else ğœ,
(cid:75)
ğœ‹

)(ğœ) else ğœ.

ğ‘ â€²
(cid:74)
ğ‘ â€²
(cid:74)

ğ‘
(cid:74)
ğ‘
(cid:74)

ğ‘ğœ‹
(cid:74)

ğ‘ğœ‹
(cid:74)

ğ‘, ğœ‰ğ‘›)

ğ‘
(cid:74)

ğ‘
(cid:74)

and

,
(cid:75)

(cid:75)

(cid:75)

(cid:75)

(cid:17)

,

(cid:16)

ğ‘‘ğœ‰ğ‘›

prsâ–¡(ğ‘)(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”

(cid:16)

pvarsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›), valsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

âˆ«

=

=

âˆ«

âˆ«

âˆ«

ğ‘‘ğœ‰ğ‘› ğºğ‘”,ğœğ‘ (

ğ‘‘ğœ‰ğ‘› ğºğ‘”,ğœğ‘ (

)(ğœ‰ğ‘›)
ğ‘
(cid:74)
(cid:75)
ğ‘ğœ‹
(cid:74)

)(ğœ‰ğ‘›)

(cid:75)
prsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”

(cid:16)

(cid:16)

=

ğ‘‘ğœ‰ğ‘›

where the second equality follows from (

pvarsâ–¡(ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›), valsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›)
ğ‘ğœ‹
) âˆˆ T .
(cid:75)
(cid:74)
ğ‘ , and ğœ‰ğ‘›. To show the
ğ‘ (ğœ†ğœ. âŠ¥)(ğœ‰ğ‘›) = 0 for all ğ‘”â€², ğœ â€²
The first condition holds simply because ğºğ‘”â€²,ğœâ€²
second condition, pick (ğ‘“ , ğ‘“ ) âˆˆ T . Our goal is to show ğ‘‡ (ğ‘“ , ğ‘“ ) âˆˆ T . We first replay our proof for

ğ‘
(cid:74)

,
(cid:75)

,

(cid:17)(cid:17)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:45

ğœ‹

ğœ‹

ğœ‹

(cid:75)

(cid:75)

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

the sequential-composition case on (ğ‘“ â€  â—¦
the sequential composition of ğ‘ â€² and ğ‘“ , and of ğ‘ â€²
membership (ğ‘“ â€  â—¦
, ğ‘“ â€  â—¦
ğ‘ â€²
(cid:75)
(cid:74)
after viewing ğ‘“ â€  â—¦
and ğ‘“ â€  â—¦
(cid:75)
This replay implies the required ğ‘‡ (ğ‘“ , ğ‘“ ) = (ğ¹ (ğ‘“ ), ğ¹ (ğ‘“ )) âˆˆ T .

as
ğœ‹ and ğ‘“ , respectively. This replay, then, gives the
) âˆˆ T . Next, we replay our proof for the if case on (ğ¹ (ğ‘“ ), ğ¹ (ğ‘“ )),
ğœ‹
(cid:75)
as the false branch.
ğ‘ â€²
(cid:74)

as the true branches, and ğœ†ğœ. ğœ =

), after viewing ğ‘“ â€  â—¦

, ğ‘“ â€  â—¦
(cid:75)

skip
(cid:75)

ğ‘ â€²
(cid:74)
ğ‘ â€²
(cid:74)

and ğ‘“ â€  â—¦

â‰œ (cid:195)ğ‘˜ âˆˆN ğ‘“ğ‘˜ . Consider a measurable ğ‘”â€² : St[PVar] Ã— Stâ–¡ [Name] â†’ Râ‰¥0 and ğœ â€²

To show the third condition, consider an increasing sequence {(ğ‘“ğ‘˜, ğ‘“ğ‘˜ )}ğ‘˜ âˆˆN in T . Let ğ‘“âˆ â‰œ (cid:195)ğ‘˜ âˆˆN ğ‘“ğ‘˜
ğ‘ âˆˆ St[PVar].
ğ‘ (ğ‘“âˆ)(ğœ‰ğ‘›). Since {ğ‘“ğ‘˜ }ğ‘˜ âˆˆN is increasing, for
ğ‘ (ğ‘“ğ‘˜ )}ğ‘˜ âˆˆN is a

and ğ‘“
ğ‘ (ğ‘“âˆ)(ğœ‰ğ‘›) = âˆ« ğ‘‘ğœ‰ğ‘› ğºğ‘”â€²,ğœâ€²
We should show that âˆ« ğ‘‘ğœ‰ğ‘› ğºğ‘”â€²,ğœâ€²
any ğœ âˆˆ St, ğ‘“ğ‘˜ (ğœ) âˆˆ St implies that ğ‘“ğ‘˜â€² (ğœ) = ğ‘“ğ‘˜ (ğœ) âˆˆ St for all ğ‘˜ â€² â‰¥ ğ‘˜. Hence, {ğºğ‘”â€²,ğœâ€²
pointwise increasing sequence: for all ğœ‰ğ‘› âˆˆ Stâ–¡ [Name],
0 â‰¤ ğºğ‘”â€²,ğœâ€²

for all ğ‘˜ âˆˆ N.

ğ‘ (ğ‘“ğ‘˜ )(ğœ‰ğ‘›) â‰¤ ğºğ‘”â€²,ğœâ€²

ğ‘ (ğ‘“ğ‘˜+1)(ğœ‰ğ‘›)

âˆ

(cid:75)

(cid:74)

(cid:75)

Also, by the definition of ğ‘“âˆ, for any ğœ âˆˆ St, there exists ğ¾ âˆˆ N such that ğ‘“âˆ (ğœ) = ğ‘“ğ¾ (ğœ); thus,
ğºğ‘”â€²,ğœâ€²

ğ‘ (ğ‘“âˆ) is the pointwise limit of {ğºğ‘”â€²,ğœâ€²

ğ‘ (ğ‘“ğ‘˜ )}ğ‘˜ âˆˆN: for all ğœ‰ğ‘› âˆˆ Stâ–¡ [Name],

ğ‘ (ğ‘“âˆ)(ğœ‰ğ‘›) = lim
ğ‘˜â†’âˆ
Note that the corresponding results hold for ğ‘“âˆ and ğ‘“ğ‘˜ . Using these results, we finally obtain the
following as desired:

ğ‘ (ğ‘“ğ‘˜ )(ğœ‰ğ‘›).

ğºğ‘”â€²,ğœâ€²

ğºğ‘”â€²,ğœâ€²

âˆ«

ğ‘‘ğœ‰ğ‘› ğºğ‘”â€²,ğœâ€²

ğ‘ (ğ‘“âˆ)(ğœ‰ğ‘›) = lim
ğ‘˜â†’âˆ

= lim
ğ‘˜â†’âˆ

âˆ«

âˆ«

ğ‘‘ğœ‰ğ‘› ğºğ‘”â€²,ğœâ€²

ğ‘ (ğ‘“ğ‘˜ )(ğœ‰ğ‘›)

ğ‘‘ğœ‰ğ‘› ğºğ‘”â€²,ğœâ€²

ğ‘ (ğ‘“ğ‘˜ )(ğœ‰ğ‘›) =

âˆ«

ğ‘‘ğœ‰ğ‘› ğºğ‘”â€²,ğœâ€²

ğ‘ (ğ‘“âˆ)(ğœ‰ğ‘›).

The first and third equalities follow from the monotone convergence theorem, applied to the above
results. The second equality holds since (ğ‘“ğ‘˜, ğ‘“ğ‘˜ ) âˆˆ T . This completes the proof of the while case. â–¡

Lemma C.8. Let ğ‘ be a command, ğœ0, ğœ1 âˆˆ St, and ğ‘Ÿ0 âˆˆ R. Suppose that ğœ1(like) = ğœ0(like) Â· ğ‘Ÿ0 and

ğœ1|ğ‘‰ = ğœ0|ğ‘‰ for ğ‘‰ â‰œ Var \ {like}. If
ğœ1 âˆˆ St,
(cid:75)

ğœ0 âˆˆ St, then
(cid:75)
ğ‘
ğœ1(like) =
(cid:74)
(cid:75)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğœ0(like) Â· ğ‘Ÿ0,
(cid:75)

(

ğ‘
(cid:74)

ğœ1)|ğ‘‰ = (
(cid:75)

ğ‘
(cid:74)

ğœ0)|ğ‘‰ .
(cid:75)

Proof. Let ğ‘‰ â‰œ Var \ {like}. Pick an arbitrary command ğ‘. We prove the lemma by induction
ğœ0 âˆˆ St, ğœ1(like) = ğœ0(like) Â· ğ‘Ÿ0, and
ğ‘
(cid:75)
(cid:74)
ğœ0|ğ‘‰ .
ğœ0(like) Â· ğ‘Ÿ0, and
ğ‘
ğ‘
(cid:75)
(cid:74)
(cid:75)
(cid:74)

on the structure of ğ‘. Let ğœ0, ğœ1 âˆˆ St and ğ‘Ÿ0 âˆˆ R such that
ğœ1|ğ‘‰ = ğœ0|ğ‘‰ . We should show that
ğœ1(like) =
(cid:75)

Case ğ‘ â‰¡ skip. In this case, what we need to prove is identical to the assumption on (ğœ0, ğœ1, ğ‘Ÿ0).
Case ğ‘ â‰¡ (ğ‘¥ := ğ‘’). By the semantics of the assignments, we have

ğœ1 âˆˆ St,
(cid:75)

ğœ1|ğ‘‰ =
(cid:75)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

The last requirement also holds since

ğ‘’
(cid:74)
Case ğ‘ â‰¡ (ğ‘¥ := sam(ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’ â€²). By the semantics of the sample commands, we have

ğœ1 and ğœ0|ğ‘‰ = ğœ1|ğ‘‰ .
(cid:75)

ğ‘
(cid:74)

ğœ1(like) = ğœ1(like) = ğœ0(like) Â· ğ‘Ÿ0 =
(cid:75)
ğœ0 =
(cid:75)

ğ‘’
(cid:74)

ğ‘
(cid:74)

ğ‘‘
(cid:74)

ğ‘‘
(cid:74)
ğ‘‘
(cid:74)

ğœ1. Let ğœ‡ â‰œ
ğœ0 =
(cid:75)
(cid:75)
ğœ0 and ğ‘Ÿ â‰œ
ğ‘’ â€²[ğœ‡/ğ‘¦]
(cid:74)
(cid:75)

Also, the assignments do not change the value of like, so that
ğœ0(like) Â· ğ‘Ÿ0. It remains to show that
ğ‘
(cid:74)
(cid:75)
and
ğ‘“ â‰œ

ğ‘
(cid:74)
ğœ0. Then, by the same reason,
(cid:75)

ğœ1|ğ‘‰ . Since ğœ0|ğ‘‰ = ğœ1|ğ‘‰ , we have
(cid:75)
ğ‘’ â€²[ğœ‡/ğ‘¦]
(cid:74)
ğœ0. We prove the required equality as follows:
(cid:75)
ğœ0|ğ‘‰ = ğœ0 [ğ‘¥ â†¦â†’ ğ‘Ÿ, valğœ‡ â†¦â†’ ğ‘Ÿ, pr ğœ‡ â†¦â†’ ğ‘“ (ğœ0(ğœ‡)), cntğœ‡ â†¦â†’ ğœ0(cntğœ‡) + 1]|ğ‘‰
(cid:75)
= ğœ1 [ğ‘¥ â†¦â†’ ğ‘Ÿ, valğœ‡ â†¦â†’ ğ‘Ÿ, pr ğœ‡ â†¦â†’ ğ‘“ (ğœ0(ğœ‡)), cntğœ‡ â†¦â†’ ğœ0(cntğœ‡) + 1]|ğ‘‰
= ğœ1 [ğ‘¥ â†¦â†’ ğ‘Ÿ, valğœ‡ â†¦â†’ ğ‘Ÿ, pr ğœ‡ â†¦â†’ ğ‘“ (ğœ1(ğœ‡)), cntğœ‡ â†¦â†’ ğœ1(cntğœ‡) + 1]|ğ‘‰

ğœ0|ğ‘‰ =
(cid:75)

ğœ0 =
(cid:75)

ğ‘›
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğœ1 âˆˆ St.
ğ‘
(cid:74)
(cid:75)
ğœ1 (like) = ğœ1(like) = ğœ0(like) Â· ğ‘Ÿ0 =
(cid:75)
ğ‘›
ğ‘›
ğœ1
ğœ0 =
(cid:75)
(cid:75)
(cid:74)
(cid:74)
ğœ1. Let
ğ‘’ â€²[ğœ‡/ğ‘¦]
(cid:75)
(cid:74)

ğ‘
(cid:74)

ğœ1 âˆˆ St, and
(cid:75)
ğœ0(like) Â· ğ‘Ÿ0.
(cid:75)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:46

Wonyeol Lee, Xavier Rival, and Hongseok Yang

=

ğ‘
(cid:74)

ğœ1|ğ‘‰ .
(cid:75)

Case ğ‘ â‰¡ (obs(ğ‘‘, ğ‘Ÿ )). By the semantics of the observe commands, we have

ğ‘
(cid:74)

ğœ0|ğ‘‰ = ğœ0|ğ‘‰ = ğœ1|ğ‘‰ =
(cid:75)

ğ‘
(cid:74)

ğœ1 âˆˆ St. Also, the
(cid:75)
ğœ1|ğ‘‰ . The
(cid:75)

ğ‘
(cid:74)

observe commands do not change any variable except like. So,
remaining requirement for like can be proved as follows:
ğ‘
(cid:74)

ğœ1(ğ‘Ÿ ) = ğœ0(like) Â· ğ‘Ÿ0 Â·
(cid:75)

ğœ1(like) = ğœ1(like) Â·
(cid:75)
Case ğ‘ â‰¡ (ğ‘ â€²; ğ‘ â€²â€²). We have

ğ‘‘
(cid:74)

(

first to (ğ‘ â€², ğœ0, ğœ1, ğ‘Ÿ0), and then to (ğ‘ â€²â€²,

ğ‘ â€²
(cid:74)

ğœ0 âˆˆ St and
(cid:75)
ğ‘ â€²
ğœ0,
(cid:74)
(cid:75)

ğ‘ â€²
(cid:74)

ğœ1 (ğ‘Ÿ ) = ğœ0(like) Â· ğ‘Ÿ0 Â·
ğ‘‘
(cid:75)
(cid:74)
ğœ0) âˆˆ St. We apply induction hypothesis
ğ‘ â€²â€²
(cid:74)
(cid:75)
ğœ1, ğ‘Ÿ0). Then, we get the requirements of the lemma.
(cid:75)

ğœ0(like) Â· ğ‘Ÿ0.
(cid:75)

ğœ0(ğ‘Ÿ ) =
(cid:75)

ğ‘ â€²
(cid:74)

ğ‘‘
(cid:74)

ğ‘
(cid:74)

(cid:75)

Case ğ‘ â‰¡ (if ğ‘ {ğ‘ â€²} else {ğ‘ â€²â€²}). We deal with the case that
ğœ0 = true, we have
ğœ0 = false can be proved similarly. Since
(cid:75)
(cid:75)

ğ‘
(cid:74)
apply induction hypothesis to ğ‘ â€². If we do so, we get

ğ‘
(cid:74)

ğœ0 = true. The other case of
ğ‘
(cid:75)
(cid:74)
ğœ0 âˆˆ St. Thus, we can
ğœ0 =
ğ‘ â€²
(cid:75)
(cid:75)
(cid:74)

ğ‘
(cid:74)

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

ğœ1 âˆˆ St,
(cid:75)

ğœ0(like) Â· ğ‘Ÿ0,
(cid:75)
This gives the desired conclusion because
ğ‘
ğœ1 =
ğ‘
(cid:74)
(cid:75)
(cid:74)
ğ‘
(cid:74)

ğœ0 =
(cid:75)
Case ğ‘ â‰¡ (while ğ‘ {ğ‘ â€²}). Let ğ¹ be the operator on [St â†’ StâŠ¥] such that

ğ‘ â€²
(cid:74)
ğœ0 = true and so
(cid:75)

ğœ1(like) =
(cid:75)

ğœ1|ğ‘‰ =
(cid:75)

ğœ0.
(cid:75)

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

and

is the least fixed point
of ğ¹ . Define a subset T of [St â†’ StâŠ¥] as follows: a function ğ‘“ âˆˆ [St â†’ StâŠ¥] is in T if and only if
for all ğœ â€²
1(like) = ğœ â€²

ğ‘
(cid:74)
0(like) Â· ğ‘Ÿ0, we have

1 âˆˆ St such that ğœ â€²

0|ğ‘‰ and ğœ â€²

1|ğ‘‰ = ğœ â€²

0, ğœ â€²

(cid:75)

ğ‘ â€²
(cid:74)

ğ‘
(cid:74)

ğœ0|ğ‘‰ .
(cid:75)
ğœ1 =
(cid:75)

ğ‘ â€²
(cid:74)

ğœ1, and
(cid:75)

ğ‘“ (ğœ â€²

0) â‰  âŠ¥ =â‡’

(cid:16)

ğ‘“ (ğœ â€²

1) â‰  âŠ¥ âˆ§ ğ‘“ (ğœ â€²

1)|ğ‘‰ = ğ‘“ (ğœ â€²

0)|ğ‘‰ âˆ§ ğ‘“ (ğœ â€²

1)(like) = ğ‘“ (ğœ â€²

0)(like) Â· ğ‘Ÿ0

(cid:17)

.

The set T contains the least function ğœ†ğœ.âŠ¥, and is closed under the least upper bound of any chain
in [St â†’ StâŠ¥]. It is also closed under ğ¹ . This ğ¹ -closure follows essentially from our arguments for
sequential composition, if command, and skip, and induction hypothesis on ğ‘ â€². What we have shown
for T implies that T contains the least fixed point of ğ¹ , which gives the desired property for ğ‘. â–¡

Lemma C.9. Let ğ‘ â€², ğ‘ â€²â€² be commands and ğ‘” : St[PVar] Ã— Stâ–¡ [Name] â†’ R be a measurable function.

Then, for any ğœğ‘ âˆˆ St[PVar],
âˆ«

(cid:16)

ğ‘‘ğœ‰ğ‘›

prsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”
âˆ«

prsâ–¡(ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›) Â·

(cid:16)

ğ‘‘ğœ‰ â€²
ğ‘›

(cid:16)

pvarsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ğ‘›), valsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

(cid:16)

ğ‘‘ğœ‰ â€²â€²
ğ‘›

prsâ–¡ (ğ‘ â€²â€²)(pvarsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›), ğœ‰ â€²â€²

ğ‘› ) Â· 1[dom(ğœ‰ â€²

ğ‘›)âˆ©dom(ğœ‰ â€²â€²

ğ‘›)=âˆ…]

âˆ«

=

(cid:16)

Â· ğ‘”

pvarsâ–¡ (ğ‘ â€²â€²)(pvarsâ–¡(ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›), ğœ‰ â€²â€²

ğ‘› ), valsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›) âŠ• valsâ–¡ (ğ‘ â€²â€²)(pvarsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›), ğœ‰ â€²â€²
ğ‘› )

(cid:17)(cid:17)(cid:17)

.

Proof. Let ğ‘ â€², ğ‘ â€²â€² be commands, ğ‘” : St[PVar] Ã— Stâ–¡ [Name] â†’ R a measurable function, and
ğœğ‘ âˆˆ St[PVar]. In this proof, each equation involving integrals means (otherwise noted) that one
side of the equation is defined if and only if the other side is defined, and when both sides are defined,
they are the same.

First, to convert a single-integral on ğœ‰ğ‘› to a double-integral on ğœ‰ â€²

ğ‘› as in the desired equation,
we show the following claim: for any measurable ğ‘“ : Stâ–¡ [Name] â†’ St and â„ : Stâ–¡ [Name] â†’ R
such that ğ‘“ (ğœ‰ğ‘›)|dom(ğœ‰ğ‘›) = ğœ‰ğ‘› for all ğœ‰ğ‘› âˆˆ Stâ–¡ [Name], we have
âˆ«

ğ‘› and ğœ‰ â€²â€²

(cid:16)

ğ‘‘ğœ‰ğ‘›

1[used (ğ‘â€²;ğ‘â€²â€²,ğ‘“ (ğœ‰ğ‘›),ğœ‰ğ‘›) ] Â· â„(ğœ‰ğ‘›)

(cid:17)

=

âˆ‘ï¸

âˆ«

ğ¾ âŠ†Name

[ğ¾â†’R]

(cid:16)

ğ‘‘ğœ‰ğ‘›

1[used (ğ‘â€²;ğ‘â€²â€²,ğ‘“ (ğœ‰ğ‘›),ğœ‰ğ‘›) ] Â· â„(ğœ‰ğ‘›)

(cid:17)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

âˆ‘ï¸

âˆ«

ğ¾ âŠ†Name
âˆ‘ï¸

[ğ¾â†’R]
âˆ«

âˆ‘ï¸

(cid:16)

ğ‘‘ğœ‰ğ‘›

1[used (ğ‘â€²;ğ‘â€²â€²,ğ‘“ (ğœ‰ğ‘›),ğœ‰ğ‘›) ] Â· â„(ğœ‰ğ‘›) Â·

âˆ‘ï¸

ğ¿ âŠ†ğ¾

1[used (ğ‘â€²,ğ‘“ (ğœ‰ğ‘›),ğœ‰ğ‘› |ğ¿) ]

(cid:16)

ğ‘‘ğœ‰ğ‘›

1[used (ğ‘â€²,ğ‘“ (ğœ‰ğ‘›),ğœ‰ğ‘› |ğ¿) ] Â· 1[used (ğ‘â€²;ğ‘â€²â€²,ğ‘“ (ğœ‰ğ‘›),ğœ‰ğ‘›) ] Â· â„(ğœ‰ğ‘›)

(cid:17)

(cid:17)

=

=

=

=

=

âˆ«

ğ‘‘ğœ‰ â€²
ğ‘›
[ğ¿â†’R]
âˆ«

ğ‘‘ğœ‰ â€²â€²
ğ‘›
[ğ¾\ğ¿â†’R]
âˆ«

ğ‘‘ğœ‰ â€²
ğ‘›
[ğ¿â€²â†’R]

ğ‘‘ğœ‰ â€²â€²
ğ‘›
[ğ‘€â€²â†’R]

[ğ¾â†’R]

ğ¾ âŠ†Name
âˆ‘ï¸

ğ¿ âŠ†ğ¾
âˆ‘ï¸

âˆ«

ğ¾ âŠ†Name
âˆ‘ï¸

ğ¿â€² âŠ†Name

âˆ‘ï¸

ğ¿ âŠ†ğ¾

âˆ‘ï¸

ğ‘€â€² âŠ†Name
ğ¿â€²âˆ©ğ‘€â€²=âˆ…
âˆ«

ğ¿â€² âŠ†Name

[ğ¿â€²â†’R]

ğ‘‘ğœ‰ â€²
ğ‘›

(cid:16) âˆ‘ï¸

âˆ«

ğ‘€â€² âŠ†Name

[ğ‘€â€²â†’R]

(cid:16)

ğ‘‘ğœ‰ â€²â€²
ğ‘›

1[dom(ğœ‰ â€²

ğ‘›)âˆ©dom(ğœ‰ â€²â€²

ğ‘›)=âˆ…] Â· 1[used (ğ‘â€²,ğ‘“ (ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›),ğœ‰ â€²

ğ‘›) ]

Â· 1[used (ğ‘â€²;ğ‘â€²â€²,ğ‘“ (ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›),ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›) ] Â· â„(ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²
ğ‘› )

(cid:17)(cid:17)

(cid:16)

1[used (ğ‘â€²,ğ‘“ (ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›),ğœ‰ â€²

ğ‘›) ] Â· 1[used (ğ‘â€²;ğ‘â€²â€²,ğ‘“ (ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›),ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›) ] Â· â„(ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²
ğ‘› )

(cid:16)

1[used (ğ‘â€²,ğ‘“ (ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›),ğœ‰ â€²

ğ‘›) ] Â· 1[used (ğ‘â€²;ğ‘â€²â€²,ğ‘“ (ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›),ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›) ] Â· â„(ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²
ğ‘› )

(cid:17)

0:47

(cid:17)

âˆ«

=

âˆ«

ğ‘‘ğœ‰ â€²
ğ‘›

(cid:16)

ğ‘‘ğœ‰ â€²â€²
ğ‘›

1[dom(ğœ‰ â€²

ğ‘›)âˆ©dom(ğœ‰ â€²â€²

ğ‘›)=âˆ…] Â· 1[used (ğ‘â€²,ğ‘“ (ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›),ğœ‰ â€²

ğ‘›) ] Â· 1[used (ğ‘â€²;ğ‘â€²â€²,ğ‘“ (ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›),ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›) ] Â· â„(ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²
ğ‘› )

(cid:17)

.

The first equality uses the definition of Stâ–¡ [Name] and its measure. The second equality uses that
used (ğ‘ â€²; ğ‘ â€²â€², ğœ, ğœ‰ğ‘›) implies a unique existence of ğ¿ âŠ† dom(ğœ‰ğ‘›) such that used (ğ‘ â€², ğœ, ğœ‰ğ‘› |ğ¿); we already
showed the existence of such ğ¿ in the proof of Lemma C.6 (for the sequential composition case), and
the uniqueness follows from the definition of used. The third equality uses that ğ¾ is finite, and the
fourth equality uses that [ğ¾ â†’ R] is isomorphic to [ğ¿ â†’ R] Ã— [ğ¾ \ ğ¿ â†’ R] for any ğ¿ âŠ† ğ¾. The fifth
equality holds uses that {(ğ¿, ğ¾ \ ğ¿) | ğ¾ âŠ† Name, ğ¿ âŠ† ğ¾ } = {(ğ¿â€², ğ‘€ â€²) | ğ¿â€², ğ‘€ â€² âŠ† Name, ğ¿â€² âˆ© ğ‘€ â€² = âˆ…}.
The sixth equality uses that Name is finite, dom(ğœ‰ â€²
ğ‘› ) = ğ‘€ â€². The seventh equality
uses the definition of Stâ–¡ [Name] and its measure.

ğ‘›) = ğ¿â€², and dom(ğœ‰ â€²â€²

Second, to decompose prsâ–¡(ğ‘ â€²; ğ‘ â€²â€²), pvarsâ–¡(ğ‘ â€²; ğ‘ â€²â€²), and valsâ–¡(ğ‘ â€²; ğ‘ â€²â€²) as in the desired equation, we
ğ‘› ) = âˆ…

ğ‘› âˆˆ Stâ–¡ [Name] with dom(ğœ‰ â€²

ğ‘›) âˆ©dom(ğœ‰ â€²â€²

ğ‘›, ğœ‰ â€²â€²

show the following claim. Suppose that ğœ âˆˆ St and ğœ‰ â€²
satisfy used (ğ‘ â€²; ğ‘ â€²â€², ğœ, ğœ‰ â€²
ğ‘› âŠ• ğœ‰ â€²â€²
ğ‘› âŠ• ğœ‰ â€²â€²
prsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœ |PVar, ğœ‰ â€²

ğ‘› ) and used (ğ‘ â€², ğœ, ğœ‰ â€²

ğ‘›). Then, we first get
ğ‘ â€²; ğ‘ â€²â€²
(cid:74)

ğ‘› âŠ•ğœ‰ â€²â€²
ğ‘›)

ğ‘› ) =
=

ğœ (pr ğœ‡)
(cid:75)

(cid:75)

ğœ (like) Â· (cid:206)ğœ‡ âˆˆdom(ğœ‰ â€²
ğ‘ â€²; ğ‘ â€²â€²
(cid:75)
(cid:74)
ğ‘ â€²
ğ‘ â€²â€²
(
(cid:74)
(cid:74)
Â· (cid:206)ğœ‡ âˆˆdom(ğœ‰ â€²
ğ‘›)
ğœ (like) Â·
ğ‘ â€²
(cid:74)
(cid:75)
Â· (cid:206)ğœ‡ âˆˆdom(ğœ‰ â€²
ğ‘›)

ğœ)(like)
(cid:75)
ğ‘ â€²â€²
(cid:74)
ğ‘ â€²â€²
(cid:74)

=

ğ‘ â€²
(
(cid:75)
(cid:74)
(cid:0)(
(cid:75)
ğœ) [like â†¦â†’ 1](cid:1) (pr ğœ‡)
ğœ (pr ğœ‡) Â· (cid:206)ğœ‡ âˆˆdom(ğœ‰ â€²â€²
ğ‘ â€²
ğ‘›)
(cid:74)
(cid:75)
(cid:75)
(cid:1)
ğ‘›) Â· prsâ–¡ (ğ‘ â€²â€²) (cid:0)(
ğœ) [like â†¦â†’ 1]|PVar, ğœ‰ â€²â€²
ğ‘ â€²
= prsâ–¡(ğ‘ â€²)(ğœ |PVar, ğœ‰ â€²
ğ‘›
(cid:75)
(cid:74)
(cid:1).
ğ‘›) Â· prsâ–¡ (ğ‘ â€²â€²) (cid:0)pvarsâ–¡ (ğ‘ â€²)(ğœ |PVar, ğœ‰ â€²
ğ‘›), ğœ‰ â€²â€²
= prsâ–¡(ğ‘ â€²)(ğœ |PVar, ğœ‰ â€²
ğ‘›

ğœ)(pr ğœ‡) Â· (cid:206)ğœ‡ âˆˆdom(ğœ‰ â€²â€²
ğ‘›)
(cid:75)
ğœ) [like â†¦â†’ 1](cid:1) (like)
ğ‘ â€²
(cid:75)
(cid:74)
(cid:0)(
ğ‘ â€²â€²
(cid:74)

ğœ)(pr ğœ‡)
(cid:75)

ğ‘ â€²â€²
(cid:74)

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

(cid:75)

(cid:75)

(

Here is the proof of each equality.

â€¢ The first equality uses used (ğ‘ â€²; ğ‘ â€²â€², ğœ, ğœ‰ â€²
â€¢ The second equality uses noerr (ğ‘ â€²; ğ‘ â€²â€², ğœ), which comes from used (ğ‘ â€²; ğ‘ â€²â€², ğœ, âˆ’).
â€¢ The third equality comes from Lemma C.8, Lemma C.6-(2), and Lemma C.6-(3). The two appli-
ğ‘› ) = âˆ…, where
ğ‘›) by the claim in the

ğ‘› ) and dom(ğœ‰ â€²
ğ‘› ) and used (ğ‘ â€², ğœ, ğœ‰ â€²

ğ‘›) âˆ© dom(ğœ‰ â€²â€²

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› ).

cations of Lemma C.6 are valid since usedâˆ’ (ğ‘ â€²â€²,
ğœ, ğœ‰ â€²â€²
ğ‘ â€²
(cid:74)
(cid:75)
the first predicate follows from used (ğ‘ â€²; ğ‘ â€²â€², ğœ, ğœ‰ â€²
ğ‘› âŠ• ğœ‰ â€²â€²
proof of Lemma C.6 (for the sequential composition case).
â€¢ The fourth equality uses that used (ğ‘ â€², ğœ, ğœ‰ â€²
ğ‘›) and used (ğ‘ â€²â€², (
second predicate follows from usedâˆ’ (ğ‘ â€²â€²,
ğ‘ â€²
(cid:74)

ğœ, ğœ‰ â€²â€²
(cid:75)

ğ‘ â€²
(cid:74)

ğœ) [like â†¦â†’ 1], ğœ‰ â€²â€²
(cid:75)

ğ‘› ) and Lemma C.7.

ğ‘› ), where the

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:48

Wonyeol Lee, Xavier Rival, and Hongseok Yang

â€¢ The fifth equality uses (

ğœ) [like â†¦â†’ 1]|PVar = (
(cid:75)
the second part of the equation comes from used (ğ‘ â€², ğœ, ğœ‰ â€²

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

ğœ)|PVar = pvarsâ–¡ (ğ‘ â€²)(ğœ |PVar, ğœ‰ â€²
(cid:75)

ğ‘›).

ğ‘›), where

By the same argument so far (except that pr ğœ‡ and Ã— are replaced by valğœ‡ and âŠ•), we next get

valsâ–¡(ğ‘ â€²; ğ‘ â€²â€²)(ğœ |PVar, ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› ) = valsâ–¡ (ğ‘ â€²)(ğœ |PVar, ğœ‰ â€²

ğ‘›) âŠ• valsâ–¡(ğ‘ â€²â€²) (cid:0)pvarsâ–¡(ğ‘ â€²)(ğœ |PVar, ğœ‰ â€²

ğ‘›), ğœ‰ â€²â€²
ğ‘›

(cid:1).

By a similar argument, we lastly get

pvarsâ–¡(ğ‘ â€²; ğ‘ â€²â€²)(ğœ |PVar, ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› ) =
=

(cid:75)

ğ‘ â€²; ğ‘ â€²â€²
(cid:74)
ğ‘ â€²â€²
(cid:74)
ğ‘ â€²â€²
(cid:74)

ğœ |PVar
(cid:75)
ğ‘ â€²
ğœ)|PVar
(
(cid:74)
(cid:75)
(cid:0)(
ğœ) [like â†¦â†’ 1](cid:1) |PVar
ğ‘ â€²
=
(cid:74)
(cid:75)
(cid:75)
= pvarsâ–¡(ğ‘ â€²â€²) (cid:0)(
ğœ) [like â†¦â†’ 1]|PVar, ğœ‰ â€²â€²
ğ‘ â€²
ğ‘›
(cid:74)
(cid:75)
(cid:1).
= pvarsâ–¡(ğ‘ â€²â€²) (cid:0)pvarsâ–¡(ğ‘ â€²)(ğœ |PVar, ğœ‰ â€²
ğ‘›), ğœ‰ â€²â€²
ğ‘›

(cid:1)

Here is the proof of each equality.

ğ‘› ).

ğ‘› âŠ• ğœ‰ â€²â€²

â€¢ The first equality uses used (ğ‘ â€²; ğ‘ â€²â€², ğœ, ğœ‰ â€²
â€¢ The second equality uses noerr (ğ‘ â€²; ğ‘ â€²â€², ğœ) (shown above).
â€¢ The third equality uses usedâˆ’ (ğ‘ â€²â€²,
ğ‘ â€²
ğœ, ğœ‰ â€²â€²
(cid:75)
(cid:74)
ğœ) [like â†¦â†’ 1], ğœ‰ â€²â€²
â€¢ The fourth equality uses used (ğ‘ â€²â€², (
ğ‘ â€²
(cid:75)
(cid:74)
ğœ) [like â†¦â†’ 1]|PVar = pvarsâ–¡ (ğ‘ â€²)(ğœ |PVar, ğœ‰ â€²
â€¢ The fifth equality uses (
(cid:75)
Third, to remove some indicator terms that will appear in our derivation, we show the next
ğ‘›) and

ğ‘› ) (shown above) and Lemma C.6-(3).

ğ‘› ) = âˆ…, usedâˆ’ (ğ‘ â€², ğœ, ğœ‰ â€²

ğ‘› ) (shown above).

ğ‘›) (shown above).

ğ‘›) âˆ© dom(ğœ‰ â€²â€²

ğ‘ â€²
(cid:74)
ğ‘› âˆˆ Stâ–¡ [Name] with dom(ğœ‰ â€²
ğ‘›, ğœ‰ â€²â€²
ğ‘› ) imply usedâˆ’ (ğ‘ â€²; ğ‘ â€²â€², ğœ, ğœ‰ â€²
ğ‘› âŠ• ğœ‰ â€²â€²
ğœ âˆˆ St âˆ§ ğœ‰ â€²
(cid:75)

ğ‘ â€²
(cid:74)

claim: for any ğœ âˆˆ St and ğœ‰ â€²
usedâˆ’(ğ‘ â€²â€²,

ğ‘ â€²
(cid:74)

ğœ, ğœ‰ â€²â€²
(cid:75)

ğ‘› ). Assume the premise. Then, we have

ğ‘› = ğœ |dom(ğœ‰ â€²
ğ‘›)
âˆ§ (cid:0)âˆ€ğœ‡ âˆˆ Name.
âˆ§ dom(ğœ‰ â€²
ğ‘› = (

ğ‘ â€²
(cid:74)
ğ‘›) = {ğœ‡ âˆˆ Name |
ğ‘ â€²
ğœ)|dom(ğœ‰ â€²â€²
ğ‘›)
(cid:74)
(cid:75)
âˆ§ (cid:0)âˆ€ğœ‡ âˆˆ Name.
ğ‘ â€²â€²
(
(cid:74)
âˆ§ dom(ğœ‰ â€²â€²
ğ‘› ) = {ğœ‡ âˆˆ Name |

ğ‘ â€²
(cid:74)

(cid:75)

ğœ (cntğœ‡) âˆ’ ğœ (cntğœ‡) â‰¤ 1(cid:1)
(cid:75)

ğ‘ â€²
(cid:74)

ğœ â€²(cntğœ‡) âˆ’ ğœ (cntğœ‡) = 1},
(cid:75)

ğœ)(cntğœ‡) âˆ’
(cid:75)
ğ‘ â€²
ğ‘ â€²â€²
(cid:74)
(cid:74)

(cid:75)

(

ğœ (cntğœ‡) â‰¤ 1(cid:1)
(cid:75)

ğ‘ â€²
(cid:74)
ğœ)(cntğœ‡) âˆ’
(cid:75)

ğ‘ â€²
(cid:74)

ğœ (cntğœ‡) = 1}.
(cid:75)

ğ‘ â€²â€²
(cid:74)

(cid:75)

(

ğ‘ â€²
(cid:74)

ğœ) âˆˆ St âˆ§ ğœ‰ â€²â€²
(cid:75)

We should show

ğ‘ â€²; ğ‘ â€²â€²
(cid:74)

ğœ âˆˆ St âˆ§ ğœ‰ â€²
(cid:75)

ğ‘› = ğœ |dom(ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²
âˆ§ (cid:0)âˆ€ğœ‡ âˆˆ Name.
ğ‘› âŠ• ğœ‰ â€²â€²
âˆ§ dom(ğœ‰ â€²

ğ‘ â€²; ğ‘ â€²â€²
(cid:74)

ğ‘› âŠ•ğœ‰ â€²â€²
ğ‘›)
ğœ (cntğœ‡) âˆ’ ğœ (cntğœ‡) â‰¤ 1(cid:1)
(cid:75)
ğ‘ â€²; ğ‘ â€²â€²
ğ‘› ) = {ğœ‡ âˆˆ Name |
(cid:74)

ğœ â€²(cntğœ‡) âˆ’ ğœ (cntğœ‡) = 1}.
(cid:75)

We obtain the four clauses as follows. The first clause follows from
ğ‘›) and ğœ‰ â€²â€²
clause comes from ğœ‰ â€²
ğ‘›) = ğœ |dom(ğœ‰ â€²â€²
from Lemma C.4. The third and fourth clauses hold by the following:

ğœ)|dom(ğœ‰ â€²â€²
(cid:75)

ğ‘› = ğœ |dom(ğœ‰ â€²

ğ‘› = (

ğ‘ â€²
(cid:74)

(

ğ‘ â€²â€²
(cid:74)

ğœ) âˆˆ St. The second
(cid:75)
ğ‘›) , where the last equality comes

ğ‘ â€²
(cid:74)

(cid:75)

ğœ (cntğœ‡) âˆ’ ğœ (cntğœ‡)
(cid:75)
(

ğ‘ â€²
ğœ)(cntğœ‡) âˆ’ ğœ (cntğœ‡)
(cid:74)
(cid:75)
(cid:75)
ğœ (cntğœ‡) âˆ’ ğœ (cntğœ‡) = 1
ğ‘ â€²
(cid:75)
(cid:74)
ğ‘ â€²
ğœ)(cntğœ‡) âˆ’
ğ‘ â€²â€²
(
(cid:74)
(cid:74)
(cid:75)
(cid:75)
ğœ (cntğœ‡) âˆ’ ğœ (cntğœ‡) = 0

ğ‘ â€²
(cid:74)

ğ‘ â€²; ğ‘ â€²â€²
(cid:74)
ğ‘ â€²â€²
=
(cid:74)
ï£±ï£´ï£´ï£´ï£²
ï£´ï£´ï£´
ï£³

=

ğœ (cntğœ‡) = 1
(cid:75)

if ğœ‡ âˆˆ dom(ğœ‰ â€²
ğ‘›)
if ğœ‡ âˆˆ dom(ğœ‰ â€²â€²
ğ‘› )
if ğœ‡ âˆˆ Name \ (dom(ğœ‰ â€²

ğ‘›) âˆª dom(ğœ‰ â€²â€²

ğ‘› )).

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:49

â€¢ The first case uses Lemma C.6-(2) (applied to usedâˆ’ (ğ‘ â€²â€²,

and the fourth clause of usedâˆ’ (ğ‘ â€², ğœ, ğœ‰ â€²

ğ‘›).

ğ‘ â€²
(cid:74)

ğ‘› ) and dom(ğœ‰ â€²

ğ‘›) âˆ© dom(ğœ‰ â€²â€²

ğ‘› ) = âˆ…)

ğœ, ğœ‰ â€²â€²
(cid:75)

â€¢ The second case uses Lemma C.6-(2) (applied to usedâˆ’ (ğ‘ â€², ğœ, ğœ‰ â€²

ğ‘›) and dom(ğœ‰ â€²

ğ‘›) âˆ© dom(ğœ‰ â€²â€²

ğ‘› ) = âˆ…)

and the fourth clause of usedâˆ’ (ğ‘ â€²â€²,

ğ‘ â€²
(cid:74)

ğ‘› ).

ğœ, ğœ‰ â€²â€²
(cid:75)

â€¢ The third case uses Lemma C.6-(2) (applied to usedâˆ’ (ğ‘ â€²â€²,
Finally, we put the three results together. Define ğ‘“ : Stâ–¡ [Name] â†’ St as ğ‘“ (ğœ‰ğ‘›) â‰œ ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• (ğœ†ğ‘£ âˆˆ

ğ‘› ) and usedâˆ’(ğ‘ â€², ğœ, ğœ‰ â€²

ğœ, ğœ‰ â€²â€²
(cid:75)

ğ‘ â€²
(cid:74)

ğ‘›)).

Var \ (PVar âˆª dom(ğœ‰ğ‘›)). 1). Then, we obtain the desired equation as follows:
âˆ«

prsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”

pvarsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ğ‘›), valsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ğ‘›)

ğ‘‘ğœ‰ğ‘›

(cid:17)(cid:17)

(cid:16)

(cid:16)

(cid:16)

pvarsâ–¡(ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ğ‘›), valsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ğ‘›)

(cid:17)(cid:17)

(cid:16)

âˆ«

âˆ«

=

=

ğ‘‘ğœ‰ğ‘›

ğ‘‘ğœ‰ â€²
ğ‘›

(cid:16)

ğ‘‘ğœ‰ â€²â€²
ğ‘›

1[used (ğ‘â€²;ğ‘â€²â€²,ğ‘“ (ğœ‰ğ‘›),ğœ‰ğ‘›) ] Â· prsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ğ‘›) Â· ğ‘”
âˆ«

1[dom(ğœ‰ â€²

ğ‘›)âˆ©dom(ğœ‰ â€²â€²

ğ‘›)=âˆ…] Â· 1[used (ğ‘â€²,ğ‘“ (ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›),ğœ‰ â€²

ğ‘›) ] Â· 1[used (ğ‘â€²;ğ‘â€²â€²,ğ‘“ (ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›),ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›) ]

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› ) Â· ğ‘”

(cid:16)

pvarsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› ), valsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²
ğ‘› )

(cid:17)(cid:17)

Â· prsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ â€²
(cid:16)

âˆ«

ğ‘‘ğœ‰ â€²â€²
ğ‘›

1[dom(ğœ‰ â€²

ğ‘‘ğœ‰ â€²
ğ‘›

Â· prsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

âˆ«

=

âˆ«

=

ğ‘›)âˆ©dom(ğœ‰ â€²â€²

ğ‘›)=âˆ…] Â· 1[used (ğ‘â€²,ğ‘“ (ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²
ğ‘›) Â· prsâ–¡ (ğ‘ â€²â€²) (cid:0)pvarsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›),ğœ‰ â€²

ğ‘›) ] Â· 1[used (ğ‘â€²;ğ‘â€²â€²,ğ‘“ (ğœ‰ â€²
(cid:1)

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›),ğœ‰ â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›) ]

ğ‘›), ğœ‰ â€²â€²
ğ‘›
(cid:1), valsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›) âŠ• valsâ–¡ (ğ‘ â€²â€²) (cid:0)pvarsâ–¡(ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›), ğœ‰ â€²â€²
ğ‘›

(cid:16)

pvarsâ–¡ (ğ‘ â€²â€²) (cid:0)pvarsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²
Â· ğ‘”
âˆ«

ğ‘›), ğœ‰ â€²â€²
ğ‘›

ğ‘‘ğœ‰ â€²
ğ‘›

(cid:16)

ğ‘‘ğœ‰ â€²â€²
ğ‘›

1[dom(ğœ‰ â€²

ğ‘›)âˆ©dom(ğœ‰ â€²â€²

ğ‘›)=âˆ…] Â· prsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›) Â· prsâ–¡ (ğ‘ â€²â€²) (cid:0)pvarsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›), ğœ‰ â€²â€²
ğ‘›

(cid:1)

(cid:16)

Â· ğ‘”

pvarsâ–¡ (ğ‘ â€²â€²) (cid:0)pvarsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›), ğœ‰ â€²â€²
ğ‘›

(cid:1), valsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›) âŠ• valsâ–¡ (ğ‘ â€²â€²) (cid:0)pvarsâ–¡(ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›), ğœ‰ â€²â€²
ğ‘›

(cid:1)(cid:17)(cid:17)

(cid:1)(cid:17)(cid:17)

.

The first equality uses that prsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ğ‘›) â‰  0 implies 1[used (ğ‘â€²;ğ‘â€²â€²,ğ‘“ (ğœ‰ğ‘›),ğœ‰ğ‘›) ] = 1:

â€¢ Since prsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ğ‘›) â‰  0, there isğœğ‘Ÿ âˆˆ St[Var\(PVarâˆªdom(ğœ‰ğ‘›))] such that used (ğ‘ â€²; ğ‘ â€²â€², ğœğ‘ âŠ•
ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›). Note (ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ )|ğ‘‰ = ğ‘“ (ğœ‰ğ‘›)|ğ‘‰ for ğ‘‰ = PVar âˆª dom(ğœ‰ğ‘›) âˆª {like}. From these
and Lemma C.7, we get used (ğ‘ â€²; ğ‘ â€²â€², ğ‘“ (ğœ‰ğ‘›), ğœ‰ğ‘›).

The second and third equalities use the first and second results we proved above, respectively.
(cid:1) â‰  0 and
The fourth equality uses the next claim: prsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²
ğ‘›), ğœ‰ â€²â€²
ğ‘›
dom(ğœ‰ â€²
ğ‘›) ] = 1. We prove the
ğ‘› ) = âˆ… imply 1[used (ğ‘â€²,ğ‘“ (ğœ‰ â€²
claim using the third result we proved above:

ğ‘›) Â· prsâ–¡(ğ‘ â€²â€²) (cid:0)pvarsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²
ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›) ] Â· 1[used (ğ‘â€²;ğ‘â€²â€²,ğ‘“ (ğœ‰ â€²

ğ‘›) âˆ© dom(ğœ‰ â€²â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘› âŠ•ğœ‰ â€²â€²

ğ‘›),ğœ‰ â€²

ğ‘›),ğœ‰ â€²

â€¢ Assume the premise. From prsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

such that used (ğ‘ â€², ğœğ‘ âŠ• ğœ‰ â€²
PVar âˆª dom(ğœ‰ â€²

ğ‘Ÿ âˆˆ St[Var \ (PVar âˆª dom(ğœ‰ â€²
ğ‘›). Note (ğœğ‘ âŠ• ğœ‰ â€²
ğ‘› âŠ• ğœ‰ â€²â€²
ğ‘Ÿ )|ğ‘‰ â€² = ğ‘“ (ğœ‰ â€²
ğ‘›) âˆª {like}. From these and Lemma C.7, we get used (ğ‘ â€², ğ‘“ (ğœ‰ â€²
ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘›))]
ğ‘› )|ğ‘‰ â€² for ğ‘‰ â€² =
ğ‘›) as desired.
ğ‘› ), ğœ‰ â€²
ğ‘Ÿ âˆˆ St[Var\ (PVarâˆªdom(ğœ‰ â€²â€²
ğ‘› ))] such that

ğ‘›) â‰  0, there is ğœ â€²
ğ‘› âŠ• ğœ â€²

(cid:1) â‰  0, there is ğœ â€²â€²

ğ‘› âŠ• ğœ â€²

ğ‘›), ğœ‰ â€²â€²
ğ‘›

ğ‘Ÿ , ğœ‰ â€²

â€¢ From prsâ–¡ (ğ‘ â€²â€²) (cid:0)pvarsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

used (ğ‘ â€²â€², pvarsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›) âŠ• ğœ‰ â€²â€²

ğ‘› âŠ• ğœ â€²â€²

ğ‘Ÿ , ğœ‰ â€²â€²

ğ‘› ).

Since used (ğ‘ â€², ğ‘“ (ğœ‰ â€²
pvarsâ–¡ (ğ‘ â€²)(ğ‘“ (ğœ‰ â€²
ğœ‰ â€²â€²
ğ‘› ))|dom(ğœ‰ â€²â€²

ğ‘›) . Thus,

ğ‘› âŠ• ğœ‰ â€²â€²
ğ‘› ), ğœ‰ â€²
ğ‘› )|PVar, ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘›), we have
ğ‘ â€²
ğ‘›) =
(cid:74)

(cid:75)

ğ‘ â€²
(cid:74)
(cid:75)
ğ‘› âŠ• ğœ‰ â€²â€²
(ğ‘“ (ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²

(ğ‘“ (ğœ‰ â€²
ğ‘› ))|PVar; also, by Lemma C.4, ğœ‰ â€²â€²

ğ‘› )) âˆˆ St and pvarsâ–¡(ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘› =

(ğ‘“ (ğœ‰ â€²

ğ‘›) =
ğ‘› âŠ•

ğ‘ â€²
(cid:74)

(cid:75)

(pvarsâ–¡(ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğ‘›) âŠ• ğœ‰ â€²â€²

ğ‘› âŠ• ğœ â€²â€²

ğ‘Ÿ )|ğ‘‰ â€²â€² =

(ğ‘“ (ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› ))|ğ‘‰ â€²â€²

ğ‘
(cid:74)

(cid:75)

for ğ‘‰ â€²â€² = PVar âˆª dom(ğœ‰ â€²â€²

ğ‘› ). From these and Lemma C.7, we get usedâˆ’(ğ‘ â€²â€²,

(ğ‘“ (ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› )), ğœ‰ â€²â€²

ğ‘› ).

ğ‘ â€²
(cid:74)

(cid:75)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

â–¡

(19)

(20)

(21)

0:50

Wonyeol Lee, Xavier Rival, and Hongseok Yang

â€¢ From dom(ğœ‰ â€²

ğ‘›) âˆ© dom(ğœ‰ â€²â€²

ğ‘›), and usedâˆ’ (ğ‘ â€²â€²,
ğ‘› ) = âˆ…, usedâˆ’ (ğ‘ â€², ğ‘“ (ğœ‰ â€²
we can apply the third result proved above, and get usedâˆ’ (ğ‘ â€²; ğ‘ â€²â€², ğ‘“ (ğœ‰ â€²
ğ‘“ (ğœ‰ â€²

ğ‘› )(like) = 1, we get used (ğ‘ â€²; ğ‘ â€²â€², ğ‘“ (ğœ‰ â€²

(ğ‘“ (ğœ‰ â€²
ğ‘ â€²
(cid:75)
(cid:74)
ğ‘› ), ğœ‰ â€²
ğ‘› âŠ• ğœ‰ â€²â€²
ğ‘› ) as desired.

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› ), ğœ‰ â€²

ğ‘› ), ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²
ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› ),
ğ‘› )), ğœ‰ â€²â€²
ğ‘› ). Since

ğ‘› âŠ• ğœ‰ â€²â€²
This completes the proof.

D DEFERRED RESULTS IN Â§4.2

D.1 Deferred Statements and Their Proofs

Lemma D.1. Let ğ‘ be a command and ğœ‹ be a simple reparameterisation plan. Suppose that for all

ğ‘› âˆˆ NameEx, ğ‘‘, ğ‘‘ â€² âˆˆ DistEx, and (ğœ†ğ‘¦.ğ‘’) âˆˆ LamEx such that ğœ‹ (ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’) = (ğ‘‘ â€², _), we have
1, ğ‘Ÿ â€²
2)

ğ‘‘ â€² = distN (ğ‘Ÿ â€²

for some ğ‘Ÿ â€²

2 âˆˆ R.

1, ğ‘Ÿ â€²

Further, assume that for all ğœğ‘› âˆˆ St[Name], the function

ğœğœƒ âˆˆ St[ğœƒ ] â†¦âˆ’â†’ ğ‘ âŸ¨rv (ğœ‹ ) âŸ©
ğ‘ğœ‹ ,ğœğœƒ
is continuous. Then, for all ğœğœƒ âˆˆ St[ğœƒ ] and ğœğ‘› âˆˆ St[Name],
(ğœğ‘›) = 0.

âˆ‡ğœƒ ğ‘ âŸ¨rv (ğœ‹ ) âŸ©
ğ‘ğœ‹ ,ğœğœƒ

(ğœğ‘›)

Proof. Consider ğ‘ and ğœ‹ that satisfies the given conditions. Fix ğœğ‘› âˆˆ St[Name]. Let ğ‘“ : St[ğœƒ ] â†’ R
be the function in Eq. (20). Suppose that Eq. (21) does not hold. Then, ğ‘“ is not a constant function.

On the one hand, since ğ‘“ is continuous (by assumption) and not constant, the image of ğ‘“ over its
domain (i.e., ğ‘“ (St[ğœƒ ]) âŠ† R) is an uncountable set. This can be shown as follows: since the image of
a connected set over a continuous function is connected, ğ‘“ (St[ğœƒ ]) is a connected set in R; since ğ‘“
is not constant, ğ‘“ (St[ğœƒ ]) contains at least two points; since ğ‘“ (St[ğœƒ ]) is connected, it should contain
a non-empty interval, so it should be an uncountable set.

On the other hand, since ğœ‹ is simple and satisfies Eq. (19), and since ğ‘ has only finitely many sample
commands, ğ‘“ (St[ğœƒ ]) is a finite set. So this contradicts to that ğ‘“ (St[ğœƒ ]) is an uncountable set. Hence,
â–¡
ğ‘“ should satisfy Eq. (21).

Theorem D.2. Let ğ‘“ : R Ã— Rğ‘› â†’ R be a measurable function that satisfies the next conditions:
â€¢ For all ğ‘¥ âˆˆ Rğ‘›, ğ‘“ (âˆ’, ğ‘¥) : R â†’ R is differentiable.
âˆ«
â€¢ For all ğœƒ âˆˆ R,
Rğ‘› ğ‘“ (ğœƒ, ğ‘¥) ğ‘‘ğ‘¥ is well-defined.
â€¢ For all ğœƒ âˆˆ R, there is an open ğ‘ˆ âŠ† R such that ğœƒ âˆˆ ğ‘ˆ and

âˆ«
Rğ‘› Lip(cid:0)ğ‘“ (âˆ’, ğ‘¥)|ğ‘ˆ (cid:1)ğ‘‘ğ‘¥ is well-defined.

Here Lip(ğ‘”) for a function ğ‘” : ğ‘‰ â†’ R with ğ‘‰ âŠ† R denotes the smallest Lipschitz constant:

Lip(ğ‘”) â‰œ

sup
ğ‘Ÿ,ğ‘Ÿ â€² âˆˆğ‘‰ , ğ‘Ÿ â‰ ğ‘Ÿ â€²

|ğ‘”(ğ‘Ÿ â€²) âˆ’ ğ‘”(ğ‘Ÿ )|
|ğ‘Ÿ â€² âˆ’ ğ‘Ÿ |

.

Then, for all ğœƒ âˆˆ R, both sides of the following are well-defined and equal:
âˆ«

âˆ«

âˆ‡ğœƒ

ğ‘“ (ğœƒ, ğ‘¥) ğ‘‘ğ‘¥ =

âˆ‡ğœƒ ğ‘“ (ğœƒ, ğ‘¥) ğ‘‘ğ‘¥

Rğ‘›

Rğ‘›

where âˆ‡ğœƒ denotes the partial differentiation operator with respect to ğœƒ .

D.2 Proof of Theorem 4.4
The proof of Theorem 4.4 relies on the following two lemmas, which are proven in Â§D.3. The first
lemma states that if a command contains no observe commands, then its (full) density function can
be decomposed into its partial density functions over ğ‘† and Name \ ğ‘† for any ğ‘† âŠ† Name. The second
lemma states that if ğœ‹ is simple and ğ‘ uses only ğœ†ğ‘¦.ğ‘¦ as the third argument of its sample commands,
then the partial density function of ğ‘ğœ‹ over non-transformed random variables (i.e., variables in
Name \ rv(ğœ‹)) is connected to that of ğ‘ via the value function of ğ‘ğœ‹ .

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:51

Lemma D.3. Let ğ‘ be a command. If ğ‘ does not contain observe commands, then, for all ğ‘† âŠ† Name,

ğœğœƒ âˆˆ St[ğœƒ ], and ğœğ‘› âˆˆ St[Name],

ğ‘ğ‘,ğœğœƒ (ğœğ‘›) = ğ‘ âŸ¨ğ‘† âŸ©

ğ‘,ğœğœƒ (ğœğ‘›) Â· ğ‘ âŸ¨Name\ğ‘† âŸ©

ğ‘,ğœğœƒ

(ğœğ‘›).

Lemma D.4. Let ğ‘ be a command and ğœ‹ be a reparameterisation plan. Suppose that every sample com-
mand in ğ‘ has ğœ†ğ‘¦.ğ‘¦ as its third argument. Then, for all ğœğœƒ âˆˆ St[ğœƒ ] and ğœğ‘› âˆˆ St[Name], if ğ‘ğ‘ğœ‹ ,ğœğœƒ (ğœğ‘›) > 0,
then

ğ‘ âŸ¨Name\rv (ğœ‹ ) âŸ©
ğ‘ğœ‹ ,ğœğœƒ

(ğœğ‘›) = ğ‘ âŸ¨Name\rv (ğœ‹ ) âŸ©
ğ‘,ğœğœƒ

(ğ‘£ğ‘ğœ‹ ,ğœğœƒ (ğœğ‘›)).

We now prove Theorem 4.4 using the two lemmas.

Proof of Theorem 4.4. Let ğ‘† = rv(ğœ‹). Before starting the main derivation of the selective gradi-
ent estimator, we show the differentiability of several functions which are to be used in the derivation.
From (R2) and (R3), the next functions over St[ğœƒ ] are differentiable for all ğœğ‘› by the preservation of
differentiability under function composition:
ğœğœƒ â†¦âˆ’â†’ ğ‘ âŸ¨ğ‘† âŸ©
ğœğœƒ â†¦âˆ’â†’ ğ‘ âŸ¨ğ‘† âŸ©
ğ‘ğ‘”

ğœğœƒ â†¦âˆ’â†’ ğ‘ âŸ¨Name\ğ‘† âŸ©
ğœğœƒ â†¦âˆ’â†’ ğ‘ âŸ¨Name\ğ‘† âŸ©
ğ‘ğ‘”

ğœğœƒ â†¦âˆ’â†’ ğ‘ğ‘ğ‘š,ğœğœƒ (ğ‘£ğ‘ğ‘”

(ğ‘£ğ‘ğ‘”
(ğœğ‘›).

ğœ‹ ,ğœğœƒ (ğœğ‘›)),

ğœ‹ ,ğœğœƒ (ğœğ‘›)),

ğœ‹ ,ğœğœƒ (ğœğ‘›)),

ğ‘ğ‘”,ğœğœƒ (ğ‘£ğ‘ğ‘”

(ğœğ‘›),

ğ‘ğ‘”,ğœğœƒ

ğœ‹ ,ğœğœƒ

ğœ‹ ,ğœğœƒ

From this, the next functions over St[ğœƒ ] are also differentiable for all ğœğ‘› by Lemma D.3 with ğ‘ğ‘” and
ğ‘ğ‘”

ğœ‹ and by the fact that the multiplication of differentiable functions is differentiable:

ğœğœƒ â†¦âˆ’â†’ ğ‘ğ‘ğ‘”,ğœğœƒ (ğ‘£ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›)),

ğœğœƒ â†¦âˆ’â†’ ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›).

These differentiability results are required in the below proof to apply several gradients rules (e.g.,
âˆ‡ğœƒ (ğ‘“ (ğœƒ ) + ğ‘”(ğœƒ )) = âˆ‡ğœƒ ğ‘“ (ğœƒ ) + âˆ‡ğœƒğ‘”(ğœƒ )) which may fail for non-differentiable functions.

Fix ğœğœƒ âˆˆ St[ğœƒ ]. Using the above differentiability results, we derive the selective gradient estimator

as follows, where we write ğœ â€²

ğ‘› for ğ‘£ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›):

âˆ‡ğœƒ Lğœƒ

= âˆ‡ğœƒ

= âˆ‡ğœƒ

âˆ«

âˆ«

âˆ«

âˆ«

âˆ«

âˆ«

=

=

=

=

âˆ«

=

(cid:18)
ğ‘ğ‘ğ‘”,ğœğœƒ (ğœğ‘›) Â· log

ğ‘‘ğœğ‘›

(cid:19)

ğ‘ğ‘ğ‘š,ğœğœƒ (ğœğ‘›)
ğ‘ğ‘ğ‘”,ğœğœƒ (ğœğ‘›)

(cid:32)

ğ‘‘ğœğ‘›

ğ‘

ğ‘ğ‘”

ğœ‹ ,ğœğœƒ

(ğœğ‘›) Â· log

ğ‘‘ğœğ‘› âˆ‡ğœƒ

(cid:18)
ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›) Â· log

(cid:18)

ğ‘‘ğœğ‘›

âˆ‡ğœƒ ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›) Â· log

(cid:33)

ğ‘› )

ğ‘ğ‘ğ‘š,ğœğœƒ ( ğœ â€²
ğ‘ğ‘ğ‘”,ğœğœƒ ( ğœ â€²
ğ‘› )
(cid:19)
ğ‘ğ‘ğ‘š,ğœğœƒ (ğœ â€²
ğ‘›)
ğ‘ğ‘ğ‘”,ğœğœƒ (ğœ â€²
ğ‘›)
ğ‘ğ‘ğ‘š,ğœğœƒ (ğœ â€²
ğ‘›)
ğ‘ğ‘ğ‘”,ğœğœƒ (ğœ â€²
ğ‘›)

+ ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›) Â· âˆ‡ğœƒ log

(cid:19)

ğ‘ğ‘ğ‘š,ğœğœƒ (ğœ â€²
ğ‘›)
ğ‘ğ‘ğ‘”,ğœğœƒ (ğœ â€²
ğ‘›)

ğ‘‘ğœğ‘› ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›)

(cid:18)

âˆ‡ğœƒ log ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›) Â· log

ğ‘ğ‘ğ‘š,ğœğœƒ (ğœ â€²
ğ‘›)
ğ‘ğ‘ğ‘”,ğœğœƒ (ğœ â€²
ğ‘›)

âˆ’ âˆ‡ğœƒ log ğ‘ğ‘ğ‘”,ğœğœƒ (ğœ â€²

ğ‘›) + âˆ‡ğœƒ log ğ‘ğ‘ğ‘š,ğœğœƒ (ğœ â€²
ğ‘›)

(cid:19)

ğ‘‘ğœğ‘› ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›)

(cid:20) (cid:16)

âˆ‡ğœƒ log ğ‘ âŸ¨ğ‘† âŸ©
ğ‘ğ‘”

ğœ‹ ,ğœğœƒ

(ğœğ‘›) + âˆ‡ğœƒ log ğ‘ âŸ¨Name\ğ‘† âŸ©

ğ‘ğ‘”

ğœ‹ ,ğœğœƒ

(cid:17)

(ğœğ‘›)

Â· log

ğ‘ğ‘ğ‘š,ğœğœƒ (ğœ â€²
ğ‘›)
ğ‘ğ‘ğ‘”,ğœğœƒ (ğœ â€²
ğ‘›)

(cid:16)

âˆ’

âˆ‡ğœƒ log ğ‘ âŸ¨ğ‘† âŸ©

ğ‘ğ‘”,ğœğœƒ (ğœ â€²

ğ‘›) + âˆ‡ğœƒ log ğ‘ âŸ¨Name\ğ‘† âŸ©

ğ‘ğ‘”,ğœğœƒ

(cid:17)

(ğœ â€²
ğ‘›)

+ âˆ‡ğœƒ log ğ‘ğ‘ğ‘š,ğœğœƒ (ğœ â€²
ğ‘›)

(cid:21)

ğ‘‘ğœğ‘› ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›)

(cid:20)

(cid:0) 0 + âˆ‡ğœƒ log ğ‘ âŸ¨Name\ğ‘† âŸ©

ğ‘ğ‘”

ğœ‹ ,ğœğœƒ

(ğœğ‘›)(cid:1) Â· log

ğ‘ğ‘ğ‘š,ğœğœƒ (ğœ â€²
ğ‘›)
ğ‘ğ‘ğ‘”,ğœğœƒ (ğœ â€²
ğ‘›)

âˆ’ (cid:0)âˆ‡ğœƒ log ğ‘ âŸ¨ğ‘† âŸ©

ğ‘ğ‘”,ğœğœƒ (ğœ â€²

ğ‘›) + 0 (cid:1) + âˆ‡ğœƒ log ğ‘ğ‘ğ‘š,ğœğœƒ (ğœ â€²
ğ‘›)

(cid:21)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:52

âˆ«

=

ğ‘‘ğœğ‘› ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›)

(cid:18)

âˆ‡ğœƒ log ğ‘ âŸ¨Name\ğ‘† âŸ©

ğ‘ğ‘” ,ğœğœƒ

( ğœ â€²

ğ‘› ) Â· log

ğ‘ğ‘ğ‘š,ğœğœƒ (ğœ â€²
ğ‘›)
ğ‘ğ‘ğ‘”,ğœğœƒ (ğœ â€²
ğ‘›)

Wonyeol Lee, Xavier Rival, and Hongseok Yang

âˆ’ âˆ‡ğœƒ log ğ‘ âŸ¨ğ‘† âŸ©

ğ‘ğ‘”,ğœğœƒ (ğœ â€²

ğ‘›) + âˆ‡ğœƒ log ğ‘ğ‘ğ‘š,ğœğœƒ (ğœ â€²
ğ‘›)

(cid:19)

.

We justify key steps of the above derivation below.

â€¢ The second equality comes from Theorem 4.2 and the fact that ğ‘£ğ‘ğ‘”,ğœğœƒ is the identity function

(since the third argument of every sample command in ğ‘ğ‘” is the identity function ğœ†ğ‘¦.ğ‘¦).
â€¢ The third equality holds because differentiation there commutes with integration by (R5).
â€¢ The fourth comes from the product rule for differentiation: âˆ‡ğœƒ (ğ‘“ (ğœƒ ) Â· ğ‘”(ğœƒ )) = âˆ‡ğœƒ ğ‘“ (ğœƒ ) Â· ğ‘”(ğœƒ ) +
ğ‘“ (ğœƒ )Â·âˆ‡ğœƒğ‘”(ğœƒ ) for all differentiable ğ‘“ andğ‘”. Here ğ‘“ andğ‘” in the original equation are differentiable
because differentiability is preserved under division and log for positive-valued functions.
â€¢ The fifth equality holds because âˆ‡ğœƒ ğ‘“ (ğœƒ ) = ğ‘“ (ğœƒ ) Â· âˆ‡ğœƒ log ğ‘“ (ğœƒ ) for all differentiable and positive-

valued ğ‘“ .

â€¢ The sixth equality follows from Lemma D.3 applied to ğ‘ğ‘” and ğ‘ğ‘”

ğœ‹ (both of which do not
contain observe commands), and from the linearity of differentiation: âˆ‡ğœƒ (ğ‘“ (ğœƒ ) + ğ‘”(ğœƒ )) =
âˆ‡ğœƒ ğ‘“ (ğœƒ ) + âˆ‡ğœƒğ‘”(ğœƒ ) for all differentiable ğ‘“ and ğ‘”. Here ğ‘“ and ğ‘” in the original equation are
differentiable because differentiability is preserved under log for positive-valued functions.

â€¢ The seventh equality follows from (R4) and

(cid:2)âˆ‡ğœƒ log ğ‘ âŸ¨Name\ğ‘† âŸ©
The proof of Eq. (22) will be given after we complete this justification of the derivation.

Eğ‘ğ‘ğ‘” ğœ‹ ,ğœğœƒ (ğœğ‘›)

ğ‘›)(cid:3) = 0.

(ğœ â€²

ğ‘ğ‘”,ğœğœƒ

(22)

â€¢ The last equality comes from Lemma D.4 applied to ğ‘ğ‘”.
The only remaining part is to prove Eq. (22). We derive the equation as follows:

ğœ‹ ,ğœğœƒ (ğœğ‘›) Â· âˆ‡ğœƒ log ğ‘ âŸ¨Name\ğ‘† âŸ©

ğ‘ğ‘”,ğœğœƒ

(ğœ â€²

ğ‘›)(cid:1)

ğ‘‘ğœğ‘› (cid:0)ğ‘ğ‘ğ‘”
âˆ«

ğ‘‘ğœğ‘› (cid:0)ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›) Â· âˆ‡ğœƒ log ğ‘ âŸ¨Name\ğ‘† âŸ©

( ğœğ‘› )(cid:1)

ğœ‹ ,ğœğœƒ (ğœğ‘›) Â·

(cid:16)

ğœ‹ ,ğœğœƒ

ğ‘ğ‘”
âˆ‡ğœƒ log ğ‘ âŸ¨Name\ğ‘† âŸ©
ğ‘ğ‘”

ğœ‹ ,ğœğœƒ

ğœ‹ ,ğœğœƒ (ğœğ‘›) Â· âˆ‡ğœƒ log ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›)

(cid:17)

ğ‘‘ğœğ‘›

ğ‘‘ğœğ‘›

(cid:16)
ğ‘ğ‘ğ‘”

(cid:16)
ğ‘ğ‘ğ‘”

âˆ«

=

=

=

=

âˆ«

âˆ«

âˆ«

ğœ‹ ,ğœğœƒ (ğœğ‘›)

ğ‘‘ğœğ‘› âˆ‡ğœƒ ğ‘ğ‘ğ‘”
âˆ«

= âˆ‡ğœƒ

ğ‘‘ğœğ‘› ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ (ğœğ‘›)

(ğœğ‘›) + âˆ‡ğœƒ log ğ‘ âŸ¨ğ‘† âŸ©
ğ‘ğ‘”

ğœ‹ ,ğœğœƒ

(ğœğ‘›)

(cid:17)(cid:17)

= âˆ‡ğœƒ 1 = 0.

Here is the justification of the above derivation:

â€¢ The first equality comes from Lemma D.4 applied to ğ‘ğ‘”.
â€¢ The second equality follows from (R4).
â€¢ The third equality holds because of Lemma D.3 applied to ğ‘ğ‘”

ğœ‹ (which does not contain ob-
serve commands), and the linearity of differentiation: âˆ‡ğœƒ (ğ‘“ (ğœƒ ) + ğ‘”(ğœƒ )) = âˆ‡ğœƒ ğ‘“ (ğœƒ ) + âˆ‡ğœƒğ‘”(ğœƒ )
for all differentiable ğ‘“ and ğ‘”. Here ğ‘“ and ğ‘” in the original equation are differentiable because
differentiability is preserved under log for positive-valued functions.

â€¢ The fourth equality holds because âˆ‡ğœƒ ğ‘“ (ğœƒ ) = ğ‘“ (ğœƒ ) Â· âˆ‡ğœƒ log ğ‘“ (ğœƒ ) for all differentiable and

positive-valued ğ‘“ .

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:53

â€¢ The fifth equality uses (R5), which states the commutativity between differentiation and

integration in the equality.

â€¢ The six equality comes from that ğ‘ğ‘ğ‘”

ğœ‹ ,ğœğœƒ

is a probability density by Remark 1.

This completes the proof.

â–¡

D.3 Proofs of Lemmas D.3 and D.4
We define the partial density version of prs âŸ¨ğ‘† âŸ©

â–¡ (ğ‘) for ğ‘† âŠ† Name:

prs âŸ¨ğ‘† âŸ©

â–¡ (ğ‘) : St[PVar] Ã— Stâ–¡ [Name] â†’ [0, âˆ),

prs âŸ¨ğ‘† âŸ©

â–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) â‰œ

(cid:40)(cid:206)ğœ‡ âˆˆdom(ğœ‰ğ‘›)âˆ©ğ‘†
0

ğ‘
(cid:74)

(cid:75)

(ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ )(pr ğœ‡)

if âˆƒğœğ‘Ÿ . used (ğ‘, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›)
otherwise.

â–¡ (ğ‘) enjoys many of the properties that prsâ–¡(ğ‘) has. For instance, prs âŸ¨ğ‘† âŸ©

prs âŸ¨ğ‘† âŸ©
â–¡ (ğ‘) is a well-defined
function (i.e., its value does not depend on the choice of ğœğ‘Ÿ ), as prsâ–¡ (ğ‘) does. Since the proof of those
properties of prs âŸ¨ğ‘† âŸ©
â–¡ (ğ‘) would be almost identical to that of prsâ–¡(ğ‘), we will use them in the following
proofs without explicitly (re)proving them.

Proof of Lemma D.3. Let ğ‘ be a command that has no observe commands. Let ğ‘† âŠ† Name,
ğœğœƒ âˆˆ St[ğœƒ ], and ğœğ‘› âˆˆ St[Name]. We set ğœ0 as in the definition of ğ‘ğ‘,ğœğœƒ in Eq. (3) (as a function
of ğœğ‘›). Let ğœ = ğœğœƒ âŠ• ğœğ‘› âŠ• ğœ0. If noerr (ğ‘, ğœ) does not hold, then the LHS and RHS of the desired equation
become zero, so the equation holds. If noerr (ğ‘, ğœ) holds, we get the desired equation as follows:

ğ‘,ğœğœƒ (ğœğ‘›) Â· ğ‘ âŸ¨Name\ğ‘† âŸ©
ğ‘ âŸ¨ğ‘† âŸ©

ğ‘,ğœğœƒ

ğœ (pr ğœ‡)(cid:1) Â· (cid:0)
ğ‘
ğ‘
(cid:74)
(cid:75)
(cid:74)
Â· (cid:206)ğœ‡ âˆˆName
ğœ (pr ğœ‡)
ğ‘
(cid:75)
(cid:74)

ğœ (like) Â· (cid:206)ğœ‡ âˆˆğ‘†
(cid:75)
ğœ (like)(cid:1) 2
(cid:75)
ğœ (like) Â· ğ‘ğ‘,ğœğœƒ (ğœğ‘›)
(cid:75)

(ğœğ‘›) = (cid:0)
ğ‘
(cid:74)
= (cid:0)
ğ‘
(cid:74)
ğ‘
=
(cid:74)
= ğœ (like) Â· ğ‘ğ‘,ğœğœƒ (ğœğ‘›)
= ğ‘ğ‘,ğœğœƒ (ğœğ‘›).

ğœ (like) Â· (cid:206)ğœ‡ âˆˆName\ğ‘†
(cid:75)

ğ‘
(cid:74)

ğœ (pr ğœ‡)(cid:1)
(cid:75)

The second last equality uses Lemma D.5, and the last equality uses ğœ (like) = 1 (which holds by the
â–¡
definition of ğœ0). This completes the proof.

Proof of Lemma D.4. Consider a command ğ‘, a reparameterisation plan ğœ‹, ğœğœƒ âˆˆ St[ğœƒ ], and
ğœğ‘› âˆˆ St[Name]. Assume that all the sample commands of ğ‘ have ğœ†ğ‘¦.ğ‘¦ as their third arguments, and
ğ‘ğ‘ğœ‹ ,ğœğœƒ (ğœğ‘›) > 0.

We first define several objects and make observations on them. Let ğ‘† â‰œ Name \ rv(ğœ‹). Define

ğ‘“âˆ— : St[Name] â†’ St[AVar] to be the function for constructing an initial state:
ï£±ï£´ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£´

if ğ‘£ â‰¡ pr ğœ‡ for some ğœ‡
if ğ‘£ â‰¡ valğœ‡ for some ğœ‡
if ğ‘£ â‰¡ cntğœ‡ for some ğœ‡
if ğ‘£ â‰¡ like,

ğ‘“pr (ğœğ‘› (ğœ‡))
ğ‘“val (ğœğ‘› (ğœ‡))
ğ‘“cnt (ğœğ‘› (ğœ‡))
1

ğ‘“âˆ— (ğœğ‘›)(ğ‘£) â‰œ

ï£³

where ğ‘“val (ğ‘Ÿ ) â‰œ ğ‘Ÿ , ğ‘“pr (ğ‘Ÿ ) â‰œ N (ğ‘Ÿ ; 0, 1), and ğ‘“cnt (ğ‘Ÿ ) â‰œ 0. Define initial states ğœ, ğœ âˆˆ St for ğ‘ğ‘ğœ‹ ,ğœğœƒ (ğœğ‘›)
and ğ‘ğ‘,ğœğœƒ (ğ‘£ğ‘ğœ‹ ,ğœğœƒ (ğœğ‘›)), respectively, as

ğœ â‰œ ğœğ‘ âŠ• ğœğ‘› âŠ• ğ‘“âˆ— (ğœğ‘›),

ğœ â‰œ ğœğ‘ âŠ• ğ‘£ğ‘ğœ‹ ,ğœğœƒ (ğœğ‘›) âŠ• ğ‘“âˆ— (ğ‘£ğ‘ğœ‹ ,ğœğœƒ (ğœğ‘›)),

where ğœğ‘ â‰œ ğœğœƒ âŠ• (ğœ†ğ‘£ âˆˆ PVar \ ğœƒ . 0) âˆˆ St[PVar]. Then, the assumption ğ‘ğ‘ğœ‹ ,ğœğœƒ (ğœğ‘›) > 0 implies
noerr (ğ‘ğœ‹, ğœ) by the definition of ğ‘. From this, ğœ (like) = 1, and the definition of used, there exists

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:54

Wonyeol Lee, Xavier Rival, and Hongseok Yang

ğœ‰ğ‘› âˆˆ Stâ–¡ [Name] such that used (ğ‘ğœ‹, ğœ, ğœ‰ğ‘›). From this, we have

ğœ = ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ ,

used (ğ‘ğœ‹, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›),

for some ğœğ‘Ÿ . Next, let

ğœ‰ğ‘› â‰œ valsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›).
We can apply Lemma D.6 to used (ğ‘ğœ‹, ğœ, ğœ‰ğ‘›), since all the sample commands of ğ‘ have ğœ†ğ‘¦.ğ‘¦ in their
third arguments (by assumption). The application of the lemma gives:

âˆ€ğœ â€²

ğ‘Ÿ âˆˆ St[Var \ (PVar âˆª dom(ğœ‰ğ‘›))]. ğœ â€²

ğ‘Ÿ (like) = 1 =â‡’ used (ğ‘, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœ â€²

ğ‘Ÿ , ğœ‰ğ‘›),

prs âŸ¨ğ‘† âŸ©

â–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›) = prs âŸ¨ğ‘† âŸ©

â–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›),

where the for-all part comes from Lemma C.7.

We now show two claims. The first claims is: there exists ğœğ‘Ÿ such that

ğœ = ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ ,

used (ğ‘, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›).

By the definition of ğœ, it suffices to show that ğœ‰ğ‘› = (cid:0)ğ‘£ğ‘ğœ‹ ,ğœğœƒ (ğœğ‘›)(cid:1) |dom(ğœ‰ğ‘›) . This indeed holds as fol-
lows: for any ğœ‡ âˆˆ dom(ğœ‰ğ‘›), ğœ‰ğ‘› (ğœ‡) = valsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›)(ğœ‡) =
ğœ (valğœ‡) = ğ‘£ğ‘ğœ‹ ,ğœğœƒ (ğœğ‘›)(ğœ‡), where the
(cid:75)
second equality uses used (ğ‘ğœ‹, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›). The second claim is: for all ğœ‡ âˆˆ ğ‘† \ dom(ğœ‰ğ‘›),

ğ‘ğœ‹
(cid:74)

ğœ (pr ğœ‡) = ğœ (pr ğœ‡).

Here is the proof of the claim: ğœ (pr ğœ‡) = ğ‘“pr (ğœ (ğœ‡)) = ğ‘“pr (ğ‘£ğ‘ğœ‹ ,ğœğœƒ (ğœğ‘›)(ğœ‡)) = ğ‘“pr (
ğœ (valğœ‡)) =
(cid:75)
ğ‘“pr (ğœ (valğœ‡)) = ğ‘“pr (ğœ (ğœ‡)); and ğœ (pr ğœ‡) = ğ‘“pr (ğœ (ğœ‡)); here the second last equality in the first equation
uses Lemma C.6-(2) with ğœ‡ âˆ‰ dom(ğœ‰ğ‘›) and used (ğ‘ğœ‹, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›), and the last equality in the first
equation uses ğ‘“val (ğ‘Ÿ ) = ğ‘Ÿ .

Based on the observations made so far, we show the desired equation as follows:

ğ‘ğœ‹
(cid:74)

ğ‘ âŸ¨ğ‘† âŸ©
ğ‘ğœ‹ ,ğœğœƒ

(ğœğ‘›) =

(cid:214)
ğœ‡ âˆˆğ‘†âˆ©dom(ğœ‰ğ‘›) (cid:74)

ğ‘ğœ‹

ğœ (pr ğœ‡) Â·
(cid:75)

= prs âŸ¨ğ‘† âŸ©

â–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›) Â·

ğ‘ğœ‹

(cid:214)
ğœ‡ âˆˆğ‘†\dom(ğœ‰ğ‘›) (cid:74)
(cid:214)
ğœ (pr ğœ‡)

ğœ (pr ğœ‡)
(cid:75)

= prs âŸ¨ğ‘† âŸ©

â–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›) Â·

ğœ‡ âˆˆğ‘†\dom(ğœ‰ğ‘›)

(cid:214)

ğœ (pr ğœ‡)

ğœ‡ âˆˆğ‘†\dom(ğœ‰ğ‘›)

=

(cid:214)
ğ‘
ğœ‡ âˆˆğ‘†âˆ©dom(ğœ‰ğ‘›) (cid:74)
ğ‘,ğœğœƒ (ğ‘£ğ‘ğœ‹ ,ğœğœƒ (ğœğ‘›)).

= ğ‘ âŸ¨ğ‘† âŸ©

ğœ (pr ğœ‡) Â·
(cid:75)

(cid:214)
ğ‘
ğœ‡ âˆˆğ‘†\dom(ğœ‰ğ‘›) (cid:74)

ğœ (pr ğœ‡)
(cid:75)

The first and last equalities are by the definition of ğ‘. The second equality uses used (ğ‘ğœ‹, ğœğ‘ âŠ•ğœ‰ğ‘› âŠ•ğœğ‘Ÿ , ğœ‰ğ‘›)
and Lemma C.6-(2) with ğœ‡ âˆ‰ dom(ğœ‰ğ‘›). The third equality uses dom(ğœ‰ğ‘›) = dom(ğœ‰ğ‘›), the observation
made in the first paragraph, and the second claim in the above. The fourth equality uses the first
â–¡
claim in the above, and Lemma C.6-(2) with ğœ‡ âˆ‰ dom(ğœ‰ğ‘›).

Lemma D.5. Let ğ‘ be a command and ğœ âˆˆ St. If ğ‘ has no observe commands and
ğ‘
(cid:74)

ğœ (like) = ğœ (like).
(cid:75)

ğ‘
(cid:74)

ğœ âˆˆ St, then
(cid:75)

Proof. Let ğ‘ be a command that does not contain an observe command. We show the claim of
ğœ âˆˆ St. We will show that
(cid:75)

the lemma by induction on the structure of ğ‘. Pick ğœ âˆˆ St such that
ğ‘
(cid:74)
Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

ğœ (like) = ğœ (like).
(cid:75)

ğ‘
(cid:74)

Smoothness Analysis and Selective Reparameterisation

0:55

ğ‘
(cid:74)

ğœ =
(cid:75)

ğ‘ â€²
(cid:74)

ğœ.
(cid:75)

ğœ (like) = ğœ (like) by the definition of the semantics.
ğ‘
(cid:75)
(cid:74)
ğœ (like) = ğœ (like) by the definition of the semantics.
(cid:75)

Case ğ‘ â‰¡ skip. In this case,
Case ğ‘ â‰¡ (ğ‘¥ := ğ‘’). Again,
ğ‘
(cid:74)
Caseğ‘ â‰¡ (ğ‘¥ := sam(ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’ â€²). Once more,
Case ğ‘ â‰¡ (ğ‘ â€²; ğ‘ â€²â€²). We have
ğœ âˆˆ St and
(cid:75)
ğ‘ â€²
(cid:74)

to (ğ‘ â€², ğœ), and again to (ğ‘ â€²,
ğ‘ â€²; ğ‘ â€²â€²
ğœ (like) =
(cid:75)
(cid:74)

ğ‘ â€²
(cid:74)

ğœ (like) = ğœ (like) by the definition of the semantics.
ğ‘
(cid:74)
(cid:75)
ğœ) âˆˆ St. We apply induction hypothesis first
ğ‘ â€²â€²
ğ‘ â€²
(cid:74)
(cid:75)
(cid:74)
ğœ (like) = ğœ (like), and the second
ğœ). The first application gives
(cid:75)
(cid:75)
ğœ (like). The desired conclusion follows from these two equalities.
(cid:75)

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

(cid:75)

(

Case ğ‘ â‰¡ (if ğ‘ {ğ‘ â€²} else {ğ‘ â€²â€²}). We deal with the case that
ğœ = true, we have
ğœ = false can be proved similarly. Since
(cid:75)
(cid:75)
ğ‘ â€²
(cid:74)

ğ‘
(cid:74)
apply induction hypothesis to ğ‘ â€². If we do so, we get
conclusion because

ğœ = true. The other case of
ğ‘
(cid:75)
(cid:74)
ğœ âˆˆ St. Thus, we can
ğœ =
ğ‘ â€²
(cid:75)
(cid:75)
(cid:74)
ğœ (like) = ğœ (like). This gives the desired
(cid:75)

ğ‘
(cid:74)

ğ‘
(cid:74)

Case ğ‘ â‰¡ (while ğ‘ {ğ‘ â€²}). Let ğ¹ be the operator on [St â†’ StâŠ¥] such that

of ğ¹ . Define a subset T of [St â†’ StâŠ¥] as follows:

is the least fixed point

ğ‘
(cid:74)

(cid:75)

ğ‘“ âˆˆ T â‡â‡’

(cid:16)

âˆ€ğœ â€² âˆˆ St. ğ‘“ (ğœ â€²) âˆˆ St =â‡’ ğ‘“ (ğœ â€²)(like) = ğœ â€²(like).

(cid:17)

The set T contains the least function ğœ†ğœ.âŠ¥, and is closed under the least upper bound of any chain
in [St â†’ StâŠ¥]. It is also closed under ğ¹ . This ğ¹ -closure follows essentially from our arguments for
sequential composition, if command, and skip, and induction hypothesis on ğ‘ â€². What we have shown
for T implies that T contains the least fixed point of ğ¹ , which gives the desired property for ğ‘. â–¡

Lemma D.6. Let ğ‘ be a command and ğœ‹ be a reparameterisation plan. Suppose that every sample
command in ğ‘ has ğœ†ğ‘¦.ğ‘¦ as its third argument. Then, for all ğœğ‘ âˆˆ St[PVar] and ğœ‰ğ‘› âˆˆ Stâ–¡ [Name], if
used (ğ‘ğœ‹, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›) for some ğœğ‘Ÿ , then

âˆƒğœğ‘Ÿ . used (ğ‘, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›),
pvarsâ–¡(ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›) = pvarsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›),
(ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›) = prs âŸ¨Name\rv (ğœ‹ ) âŸ©

â–¡

prs âŸ¨Name\rv (ğœ‹ ) âŸ©

â–¡

(ğ‘)(ğœğ‘, ğœ‰ğ‘›),

where

ğœ‰ğ‘› â‰œ valsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›).
Proof. Fix a reparameterisation plan ğœ‹. The proof proceeds by induction on the structure of ğ‘. Let
ğœğ‘ âˆˆ St[PVar], and ğœ‰ğ‘› âˆˆ Stâ–¡ [Name]. Assume that ğ‘ uses only ğœ†ğ‘¦.ğ‘¦ in the third argument of its sample
commands, and used (ğ‘ğœ‹, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›) for some ğœğ‘Ÿ . Let ğœ â‰œ ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ and ğ‘† â‰œ Name \ rv(ğœ‹).
Then, we simply have used (ğ‘ğœ‹, ğœ, ğœ‰ğ‘›).

Cases ğ‘ â‰¡ skip, ğ‘ â‰¡ (ğ‘¥ := ğ‘’), or ğ‘ â‰¡ obs(ğ‘‘, ğ‘Ÿ ). In this case,

ğœ (cntğœ‡) = ğœ (cntğœ‡) for all ğœ âˆˆ St
(cid:75)
and ğœ‡ âˆˆ Name. So dom(ğœ‰ğ‘›) = dom(ğœ‰ğ‘›) = âˆ… and thus ğœ‰ğ‘› = ğœ‰ğ‘›. We also know ğ‘ğœ‹ â‰¡ ğ‘. From these, all
of the three conclusions follow immediately.

ğ‘
(cid:74)

Case ğ‘ â‰¡ (ğ‘¥ := sam(ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’)). Since fv(ğ‘›) âŠ† PVar, there exists ğœ‡ âˆˆ Name such that

ğœğ‘Ÿ ) = ğœ‡ for all ğœğ‘Ÿ âˆˆ St[Var \ PVar]. So, for all ğœğ‘Ÿ âˆˆ St[Var \ PVar] and ğœ‡ â€² âˆˆ Name \ {ğœ‡},
(cid:40)

(ğœğ‘ âŠ• ğœğ‘Ÿ )(cntğœ‡â€²) =

ğ‘
(cid:74)

(cid:75)

(ğœğ‘ âŠ• ğœğ‘Ÿ )(cntğœ‡â€²) + 1
(ğœğ‘ âŠ• ğœğ‘Ÿ )(cntğœ‡â€²)

if ğœ‡ â€² = ğœ‡
otherwise.

(ğœğ‘ âŠ•

ğ‘›
(cid:74)

(cid:75)

(23)

From this, we get dom(ğœ‰ğ‘›) = dom(ğœ‰ğ‘›) = {ğœ‡}. Further, by assumption, we get ğ‘’ â‰¡ ğ‘¦. We now prove
the three conclusions based on these observations and case analysis on (ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’).

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:56

Wonyeol Lee, Xavier Rival, and Hongseok Yang

First, assume (ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’) âˆ‰ dom(ğœ‹). Then, ğ‘ğœ‹ â‰¡ ğ‘ and

ğœ‰ğ‘› = valsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›) = [ğœ‡ â†¦â†’

ğ‘ğœ‹
(cid:74)

ğœ (valğœ‡)] = [ğœ‡ â†¦â†’
(cid:75)

ğ‘’ [ğœ (ğœ‡)/ğ‘¦]
(cid:74)

ğœ] = [ğœ‡ â†¦â†’ ğœ‰ğ‘› (ğœ‡)] = ğœ‰ğ‘›,
(cid:75)

where the second last equality uses ğ‘’ â‰¡ ğ‘¦. Hence, the three conclusions clearly hold.

Next, assume (ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’) âˆˆ dom(ğœ‹). Suppose that ğœ‹ (ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’) = (ğ‘‘, ğœ†ğ‘¦.ğ‘’). Then, ğ‘ğœ‹ â‰¡ (ğ‘¥ :=

sam(ğ‘›, ğ‘‘, ğœ†ğ‘¦.ğ‘’)) and

ğœ‰ğ‘› = valsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›) = [ğœ‡ â†¦â†’

Since Eq. (23) holds also for

ğ‘ğœ‹
(cid:74)

(cid:75)

ğ‘ğœ‹
(cid:74)

ğœ (valğœ‡)] = [ğœ‡ â†¦â†’
(cid:75)

ğ‘’ [ğœ (ğœ‡)/ğ‘¦]
(cid:74)

ğœ] = [ğœ‡ â†¦â†’
(cid:75)

, and since dom(ğœ‰ğ‘›) = {ğœ‡}, we get the first conclusion:

ğ‘’ [ğœ‰ğ‘› (ğœ‡)/ğ‘¦]
(cid:74)

ğœ].
(cid:75)

used (ğ‘, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›).

To prove the second conclusion, let ğœ = ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ . Then, for all ğ‘£ âˆˆ PVar,

pvarsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›)(ğ‘£) =

ğ‘ğœ‹
(cid:74)

ğœ (ğ‘£) =
(cid:75)

(cid:40)

ğœ =
ğ‘’ [ğœ (ğœ‡)/ğ‘¦]
(cid:74)
(cid:75)
ğœ (ğ‘£) = ğœğ‘ (ğ‘£)

ğ‘’ [ğœ‰ğ‘› (ğœ‡)/ğ‘¦]
(cid:74)

ğœ
(cid:75)

if ğ‘£ â‰¡ ğ‘¥
otherwise,

(cid:40)

ğ‘
(cid:74)

ğœ (ğ‘£) =
(cid:75)

pvarsâ–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›)(ğ‘£) =

ğœ = ğœ‰ğ‘› (ğœ‡) =
ğ‘’ [ğœ (ğœ‡)/ğ‘¦]
(cid:74)
(cid:75)
ğœ (ğ‘£) = ğœğ‘ (ğ‘£),
where the second equation uses ğ‘’ â‰¡ ğ‘¦. Hence, the second conclusion holds. For the third conclusion,
let ğ‘› = name(ğ›¼, _). Then, ğœ‡ = (ğ›¼, _) âˆˆ {(ğ›¼, ğ‘–) âˆˆ Name | ğ‘– âˆˆ N} âŠ† rv(ğœ‹). Thus, dom(ğœ‰ğ‘›) âˆ© ğ‘† =
dom(ğœ‰ğ‘›) âˆ© ğ‘† = {ğœ‡} âˆ© ğ‘† = {ğœ‡} âˆ© (Name \ rv(ğœ‹)) = âˆ…. From this, we get the third conclusion:
â–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›) = 1 = prs âŸ¨ğ‘† âŸ©

ğ‘’ [ğœ‰ğ‘› (ğœ‡)/ğ‘¦]
(cid:74)

if ğ‘£ â‰¡ ğ‘¥
otherwise,

â–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›).

prs âŸ¨ğ‘† âŸ©

ğœ
(cid:75)

Case ğ‘ â‰¡ (ğ‘ â€²; ğ‘ â€²â€²). First, we make several observations necessary to prove the conclusion. By
ğœ‹
ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

used (ğ‘ğœ‹, ğœ, ğœ‰ğ‘›), we have
ğœ â€² â‰œ

ğœ) âˆˆ St. Let
(cid:75)
ğœ â€²
ğ‘ â‰œ ğœ â€²|PVar,

ğœ â€²â€²
ğ‘ â‰œ ğœ â€²â€²|PVar.

(cid:75)

(

ğœ‹

ğœ‹

ğœ‹

ğœ âˆˆ St and
ğ‘ â€²â€²
(cid:74)
(cid:75)
ğœ‹
ğœ â€²â€² â‰œ
ğ‘ â€²â€²
(cid:74)

ğœ â€²,
(cid:75)

Then, by used (ğ‘ğœ‹, ğœ, ğœ‰ğ‘›) and the claim in the proof of Lemma C.6 (for the sequential composition
case), there exist ğœ‰ â€²

ğ‘ â€²
(cid:74)

ğœ,
(cid:75)

ğ‘› and ğœ‰ â€²â€²
ğœ‰ğ‘› = ğœ‰ â€²

ğ‘› such that
ğ‘› ,
ğ‘› âŠ• ğœ‰ â€²â€²

used (ğ‘ â€²

ğœ‹, ğœ, ğœ‰ â€²

ğ‘›),

usedâˆ’ (ğ‘ â€²â€²

ğœ‹, ğœ â€², ğœ‰ â€²â€²
ğ‘› ).

By the latter two, we can apply induction to (ğ‘ â€², ğœğ‘, ğœ‰ â€²

ğ‘›) and (ğ‘ â€²â€², ğœ â€²

ğ‘, ğœ‰ â€²â€²

ğ‘› ), and IH gives the following:

pvarsâ–¡(ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

pvarsâ–¡ (ğ‘ â€²â€²)(ğœ â€²

ğ‘, ğœ‰ â€²â€²

ğœ‹

ğœ‹

ğœ‹

(cid:75)

= (

= (cid:0)

ğ‘›) = pvarsâ–¡ (ğ‘ â€²
ğ‘ â€²
(cid:74)
ğ‘ â€²
(cid:74)
ğ‘› ) = pvarsâ–¡ (ğ‘ â€²â€²
ğ‘ â€²â€²
(cid:74)
ğ‘ â€²â€²
(cid:74)

)(ğœğ‘, ğœ‰ â€²
ğ‘›)
(ğœ [like â†¦â†’ 1])(cid:1) |PVar
ğœ)|PVar = ğœ â€²|PVar = ğœ â€²
ğ‘,
(cid:75)
ğ‘, ğœ‰ â€²â€²
ğ‘› )
(ğœ â€²[like â†¦â†’ 1])(cid:1) |PVar
ğœ â€²)|PVar = ğœ â€²â€²|PVar = ğœ â€²â€²
ğ‘ ,
(cid:75)

)(ğœ â€²

= (cid:0)

= (

(cid:75)

ğœ‹

ğœ‹

ğœ‹

where

[By IH on ğ‘ â€²]
ğœ‹, ğœ, ğœ‰ â€²

ğ‘›)]
[By used (ğ‘ â€²
[By Lemma C.6-(3)]

[By IH on ğ‘ â€²â€²]
ğœ‹, ğœ â€², ğœ‰ â€²â€²

[By usedâˆ’ (ğ‘ â€²â€²

ğ‘› )]
[By Lemma C.6-(3)]

ğœ‹

ğœ‰ â€²
ğ‘› â‰œ valsâ–¡(ğ‘ â€²
By the former equation, we get
ğœ‰ğ‘› = valsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›)

)(ğœğ‘, ğœ‰ â€²

ğ‘›),

ğœ‰ â€²â€²
ğ‘› â‰œ valsâ–¡ (ğ‘ â€²â€²

ğœ‹

)(ğœ â€²

ğ‘, ğœ‰ â€²â€²

ğ‘› ).

= valsâ–¡ (ğ‘ â€²

ğœ‹ ; ğ‘ â€²â€²

ğœ‹

)(ğœğ‘, ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²
ğ‘› )

[By ğœ‰ğ‘› = ğœ‰ â€²

ğ‘› ]
ğ‘› âŠ• ğœ‰ â€²â€²

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:57

)(ğœğ‘, ğœ‰ â€²

)(ğœğ‘, ğœ‰ â€²

ğ‘›) âŠ• valsâ–¡ (ğ‘ â€²â€²
ğ‘›) âŠ• valsâ–¡ (ğ‘ â€²â€²

ğœ‹

)(ğœğ‘, ğœ‰ â€²

ğ‘›), ğœ‰ â€²â€²
ğ‘› )

ğœ‹

ğœ‹

)(pvarsâ–¡ (ğ‘ â€²
)(ğœ â€²
ğ‘, ğœ‰ â€²â€²
ğ‘› )

[By the former equation]

ğœ‹

ğœ‹

= valsâ–¡ (ğ‘ â€²
= valsâ–¡ (ğ‘ â€²
ğ‘› âŠ• ğœ‰ â€²â€²
= ğœ‰ â€²
ğ‘›

where the third equality uses used (ğ‘ â€²
proof of Lemma C.9.

ğœ‹, ğœ, ğœ‰ â€²

ğ‘›), used (ğ‘ â€²

ğœ‹ ; ğ‘ â€²â€²

ğœ‹, ğœ, ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› ), and the second claim in the

We now show the first conclusion. By IH on (ğ‘ â€², ğœğ‘, ğœ‰ â€²

âˆƒğœ â€²

ğ‘Ÿ . used (ğ‘ â€², ğœğ‘ âŠ• ğœ‰ â€²

ğ‘› âŠ• ğœ â€²

ğ‘Ÿ , ğœ‰ â€²

ğ‘›),

ğ‘, ğœ‰ â€²â€²

ğ‘›) and (ğ‘ â€²â€², ğœ â€²
ğ‘Ÿ . used (ğ‘ â€²â€², ğœ â€²

ğ‘› ), we get
ğ‘› âŠ• ğœ â€²â€²
ğ‘ âŠ• ğœ‰ â€²â€²

âˆƒğœ â€²â€²

ğ‘Ÿ , ğœ‰ â€²â€²

ğ‘› ).

Let

Then,

ğ‘ â€²
(cid:74)

ğœ âˆˆ St by used (ğ‘ â€², ğœğ‘ âŠ• ğœ‰ â€²
(cid:75)
ğœ |PVar = ğœğ‘,

(

ğ‘› âŠ• ğœ‰ â€²â€²
ğœ â‰œ ğœğ‘ âŠ• (ğœ‰ â€²
ğ‘Ÿ , ğœ‰ â€²
ğ‘› âŠ• ğœ â€²
ğœ)|PVar = (
(cid:75)

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

(cid:75)

ğ‘› ) âŠ• ğœ â€²

ğ‘Ÿ |dom(ğœâ€²

ğ‘›) .
ğ‘Ÿ )\dom(ğœ‰ â€²â€²

ğ‘›) and Lemma C.6-(1), and we have

(ğœğ‘ âŠ• ğœ‰ â€²

ğ‘› âŠ• ğœ â€²

ğ‘Ÿ ))|PVar
ğ‘›) = ğœ â€²
ğ‘,

(

ğ‘ â€²
ğœ)|dom(ğœ‰ â€²â€²
(cid:75)
(cid:74)
ğ‘Ÿ , ğœ‰ â€²
ğ‘› âŠ• ğœ â€²
used (ğ‘ â€², ğœ, ğœ‰ â€²

ğ‘›), used (ğ‘ â€²â€², ğœ â€²
ğ‘›),

ğ‘›) = ğœ |dom(ğœ‰ â€²â€²
ğ‘ âŠ• ğœ‰ â€²â€²

= pvars(ğ‘ â€²)(ğœğ‘, ğœ‰ â€²
ğ‘›) = ğœ‰ â€²â€²
ğ‘› .
ğ‘Ÿ , ğœ‰ â€²â€²
ğ‘› âŠ• ğœ â€²â€²
usedâˆ’ (ğ‘ â€²â€²,

ğœ |dom(ğœ‰ â€²

ğ‘›) = ğœ‰ â€²
ğ‘›,

By these, used (ğ‘ â€², ğœğ‘ âŠ• ğœ‰ â€²

By these and the third claim in the proof of Lemma C.9, we get

ğ‘› ), and Lemma C.7, we get
ğœ, ğœ‰ â€²â€²
(cid:75)

ğ‘ â€²
(cid:74)

ğ‘› ).

[By Lemma C.6-(3)]

[By the above]

[By Lemma C.4]

used (ğ‘ â€²; ğ‘ â€²â€², ğœ, ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› ).

By this and Lemma C.7, we get the following as desired, since ğœ‰ğ‘› = ğœ‰ â€²
ğœ = ğœğ‘ âŠ• (ğœ‰ â€²

ğ‘› ) âŠ• ğœğ‘Ÿ for some ğœğ‘Ÿ :

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› (shown in the above) and

Next, we show the second conclusion as follows:

used (ğ‘, ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ , ğœ‰ğ‘›).

pvarsâ–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›) = (
ğœ)(cid:1) |PVar
= (cid:0)
(cid:75)
(cid:75)
= ğœ â€²â€²|PVar = ğœ â€²â€²
ğ‘ ,

ğœ)|PVar
ğœ‹
ğœ‹
(cid:75)
ğ‘ â€²
(
(cid:74)

ğ‘ğœ‹
(cid:74)
ğ‘ â€²â€²
(cid:74)

[By used (ğ‘ğœ‹, ğœ, ğœ‰ğ‘›)]

pvarsâ–¡(ğ‘)(ğœğ‘, ğœ‰ğ‘›) = pvarsâ–¡ (ğ‘ â€²; ğ‘ â€²â€²)(ğœğ‘, ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²
ğ‘› )

[By ğœ‰ğ‘› = ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²
ğ‘› ]

= pvarsâ–¡(ğ‘ â€²â€²)(pvarsâ–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²
= pvarsâ–¡(ğ‘ â€²â€²)(ğœ â€²

ğ‘› ) = ğœ â€²â€²
ğ‘ ,

ğ‘›), ğœ‰ â€²â€²
ğ‘› )

ğ‘, ğœ‰ â€²â€²
where the second last equality uses used (ğ‘ â€², ğœ, ğœ‰ â€²
the proof of Lemma C.9.

[By the above]

ğ‘›), used (ğ‘ â€²; ğ‘ â€²â€², ğœ, ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› ), and the second claim in

prs âŸ¨ğ‘† âŸ©

ğœ‹

ğœ‹

)(ğœğ‘, ğœ‰ â€²

Lastly, we show the third conclusion as follows:
â–¡ (ğ‘ğœ‹ )(ğœğ‘, ğœ‰ğ‘›) = prs âŸ¨ğ‘† âŸ©
= prs âŸ¨ğ‘† âŸ©
= prs âŸ¨ğ‘† âŸ©
= prs âŸ¨ğ‘† âŸ©
= prs âŸ¨ğ‘† âŸ©
= prs âŸ¨ğ‘† âŸ©

â–¡ (ğ‘ â€²; ğ‘ â€²â€²
)(ğœğ‘, ğœ‰ â€²
â–¡ (ğ‘ â€²
)(ğœğ‘, ğœ‰ â€²
â–¡ (ğ‘ â€²
â–¡ (ğ‘ â€²)(ğœğ‘, ğœ‰ â€²
â–¡ (ğ‘)(ğœğ‘, ğœ‰ â€²
â–¡ (ğ‘)(ğœğ‘, ğœ‰ğ‘›).

ğ‘› âŠ• ğœ‰ â€²â€²
ğ‘› )
ğ‘›) Â· prs âŸ¨ğ‘† âŸ©
â–¡ (ğ‘ â€²â€²
ğ‘›) Â· prs âŸ¨ğ‘† âŸ©
â–¡ (ğ‘ â€²â€²
ğ‘›) Â· prs âŸ¨ğ‘† âŸ©
â–¡ (ğ‘ â€²â€²)(pvars(ğ‘ â€²)(ğœğ‘, ğœ‰ â€²
ğ‘› âŠ• ğœ‰ â€²â€²
ğ‘› )

)(pvars(ğ‘ â€²
)(ğœğ‘, ğœ‰ â€²
)(pvars(ğ‘ â€²)(ğœğ‘, ğœ‰ â€²

ğœ‹

ğœ‹

ğœ‹

ğœ‹

ğ‘›), ğœ‰ â€²â€²
ğ‘› )
ğ‘›), ğœ‰ â€²â€²
ğ‘› )
ğ‘›), ğœ‰ â€²â€²
ğ‘› )

[By ğœ‰ğ‘› = ğœ‰ â€²

ğ‘› ]
ğ‘› âŠ• ğœ‰ â€²â€²

[By IH on ğ‘ â€²]
[By IH on ğ‘ â€² and ğ‘ â€²â€²]

[By ğœ‰ğ‘› = ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²
ğ‘› ]

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:58

Wonyeol Lee, Xavier Rival, and Hongseok Yang

Here the second and fifth equalities use the second claim in the proof of Lemma C.9 with the following:
used (ğ‘ â€²

ğ‘›), and used (ğ‘ â€²; ğ‘ â€²â€², ğœ, ğœ‰ â€²

ğ‘› ), used (ğ‘ â€², ğœ, ğœ‰ â€²

ğ‘›), used (ğ‘ â€²

ğœ‹, ğœ, ğœ‰ â€²

ğœ‹, ğœ, ğœ‰ â€²

ğ‘› âŠ• ğœ‰ â€²â€²

ğ‘› âŠ• ğœ‰ â€²â€²

ğœ‹ ; ğ‘ â€²â€²

ğ‘› ).

Case ğ‘ â‰¡ (if ğ‘ {ğ‘ â€²} else {ğ‘ â€²â€²}). In this case, ğ‘ğœ‹ â‰¡ (if ğ‘ {ğ‘ â€²
(ğœğ‘ âŠ• ğœğ‘Ÿ ) is constant for all ğœğ‘Ÿ âˆˆ St[Var \ PVar]. Without loss of generality, assume
ğ‘ğœ‹
(cid:74)

ğ‘
(cid:74)
true. Then,
(cid:75)
Hence, by IH on (ğ‘ â€², ğœğ‘, ğœ‰ğ‘›), we get the three conclusions directly.

}). Since fv(ğ‘) âŠ† PVar,
(ğœğ‘ âŠ• ğœğ‘Ÿ ) =
(ğœğ‘ âŠ•ğœğ‘Ÿ ) for all ğœğ‘Ÿ âˆˆ St[Var\PVar].

(ğœğ‘ âŠ•ğœğ‘Ÿ ) and

(ğœğ‘ âŠ•ğœğ‘Ÿ ) =

(ğœğ‘ âŠ•ğœğ‘Ÿ ) =

} else {ğ‘ â€²â€²

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

(cid:75)

(cid:75)

(cid:75)

(cid:75)

(cid:75)

ğœ‹

ğœ‹

ğœ‹

ğœ‹

(cid:75)

(cid:75)

(cid:75)

ğœ‹ â€²

and

ğ‘
(cid:74)

ğ‘ â€²
(cid:74)

ğ‘ğœ‹
(cid:74)

)(ğœ) else ğœ.

(ğ‘“ )(ğœ) â‰œ if (

ğœ = true) then (ğ‘“ â€  â—¦
(cid:75)

Case ğ‘ â‰¡ (while ğ‘ {ğ‘ â€²}). In this case, ğ‘ğœ‹ â‰¡ (while ğ‘ {ğ‘ â€²

}). Consider the version of prsâ–¡ (âˆ’)
where the parameter can be a state transformer ğ‘“ : St â†’ StâŠ¥, instead of a command. Similarly,
consider the version of the three conclusions where we use two state transformers ğ‘“ , ğ‘“ : St â†’ StâŠ¥,
again instead of a command. We denote the versions by prsâ–¡ (ğ‘“ ) and ğœ‘ (ğ‘“ , ğ‘“ , ğœğ‘, ğœ‰ğ‘›). We write ğ‘“ âˆ¼ ğ‘“
if prsâ–¡ (ğ‘“ )(ğœğ‘, ğœ‰ğ‘›) > 0 implies ğœ‘ (ğ‘“ , ğ‘“ , ğœğ‘, ğœ‰ğ‘›) for all ğœğ‘ âˆˆ St[PVar] and ğœ‰ğ‘› âˆˆ Stâ–¡ [Name]. Further, we
define ğ¹ ğœ‹ â€² : [St â†’ StâŠ¥] â†’ [St â†’ StâŠ¥] as
ğ¹ ğœ‹ â€²

ğ‘
(cid:74)
Note that ğ¹ ğœ‹ and ğ¹ ğœ‹0 are the operators used in the semantics of the loops
, respectively,
where ğœ‹0 denotes the empty reparameterisation plan. We will show three claims: ğœ†ğœ.âŠ¥ âˆ¼ ğœ†ğœ.âŠ¥; if
ğ‘“ âˆ¼ ğ‘“ , then ğ¹ ğœ‹ (ğ‘“ ) âˆ¼ ğ¹ ğœ‹0 (ğ‘“ ); and if increasing sequences {ğ‘“ğ‘˜ }ğ‘˜ âˆˆN and {ğ‘“ğ‘˜ }ğ‘˜ âˆˆN satisfy ğ‘“ğ‘˜ âˆ¼ ğ‘“ğ‘˜ for all
ğ‘˜ âˆˆ N, then ğ‘“âˆ âˆ¼ ğ‘“âˆ holds for ğ‘“âˆ = (cid:195)ğ‘˜ âˆˆN ğ‘“ğ‘˜ and ğ‘“âˆ = (cid:195)ğ‘˜ âˆˆN ğ‘“ğ‘˜ . These three claims imply
,
ğ‘
(cid:74)
which in turn proves the desired three conclusions.

as the sequential composition of ğ‘ â€²
ğ‘ â€²
(cid:74)
(cid:75)
and ğ‘“ â€  â—¦
(cid:75)

(cid:75)
The first claim holds simply because prsâ–¡ (ğœ†ğœ.âŠ¥)(âˆ’, âˆ’) is always 0. To show the second claim,
consider ğ‘“ , ğ‘“ : St â†’ StâŠ¥ such that ğ‘“ âˆ¼ ğ‘“ . We first replay our proof for the sequential-composition
ğœ‹ and ğ‘“ , and of
case on (ğ‘“ , ğ‘“ ) after viewing ğ‘“ â€  â—¦
ğ‘ â€²
ğ‘ â€²
(cid:74)
(cid:74)
ğ‘ â€² and ğ‘“ , respectively. This replay, then, gives the relationship ğ‘“ â€  â—¦
. Next, we replay
ğ‘ â€²
ğœ‹
(cid:74)
our proof for the if case on (ğ¹ ğœ‹ (ğ‘“ ), ğ¹ ğœ‹0 (ğ‘“ )), after viewing ğ‘“ â€  â—¦
as the true branches,
ğ‘ â€²
(cid:75)
(cid:74)
as the false branch. This replay implies the required relationship ğ¹ ğœ‹ (ğ‘“ ) âˆ¼ ğ¹ ğœ‹0 (ğ‘“ ).
and ğœ†ğœ. ğœ =
To show the third condition, consider increasing sequences {ğ‘“ğ‘˜ }ğ‘˜ âˆˆN and {ğ‘“ğ‘˜ }ğ‘˜ âˆˆN such that
ğ‘“ğ‘˜ âˆ¼ ğ‘“ğ‘˜ for all ğ‘˜ âˆˆ N. Let ğ‘“âˆ = (cid:195)ğ‘˜ âˆˆN ğ‘“ğ‘˜ and ğ‘“âˆ = (cid:195)ğ‘˜ âˆˆN ğ‘“ğ‘˜ . Consider any ğœğ‘ and ğœ‰ğ‘› such that
prsâ–¡ (ğ‘“âˆ)(ğœğ‘, ğœ‰ğ‘›) > 0. We should show ğœ‘ (ğ‘“âˆ, ğ‘“âˆ, ğœğ‘, ğœ‰ğ‘›). Pick any ğœğ‘Ÿ âˆˆ St[Var \ (PVar âˆª dom(ğœ‰ğ‘›))]
with ğœğ‘Ÿ (like) = 1. Let ğœ = ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ and ğœ = ğœğ‘ âŠ• ğœ‰ğ‘› âŠ• ğœğ‘Ÿ . Note that the value of each term in
ğœ‘ (Â· Â· Â· ) (i.e., used (Â· Â· Â· ), pvarsâ–¡ (Â· Â· Â· ), and prs âŸ¨ğ‘† âŸ©
â–¡ (Â· Â· Â· )) is independent of the choice of ğœğ‘Ÿ by Lemma C.7
and the well-definedness of pvarsâ–¡ and prs âŸ¨ğ‘† âŸ©
â–¡ . Since the two given sequences are increasing, there
exists ğ¾ âˆˆ N such that ğ‘“âˆ (ğœ) = ğ‘“ğ¾ (ğœ) and ğ‘“âˆ (ğœ) = ğ‘“ğ¾ (ğœ). From this and prsâ–¡(ğ‘“âˆ)(ğœğ‘, ğœ‰ğ‘›) > 0,
we have prsâ–¡(ğ‘“ğ¾ )(ğœğ‘, ğœ‰ğ‘›) > 0. This in turn gives ğœ‘ (ğ‘“ğ¾, ğ‘“ğ¾, ğœğ‘, ğœ‰ğ‘›) since ğ‘“ğ¾ âˆ¼ ğ‘“ğ¾ . Lastly, again by
â–¡
ğ‘“âˆ(ğœ) = ğ‘“ğ¾ (ğœ) and ğ‘“âˆ (ğœ) = ğ‘“ğ¾ (ğœ), we obtain ğœ‘ (ğ‘“âˆ, ğ‘“âˆ, ğœğ‘, ğœ‰ğ‘›) as desired.

âˆ¼ ğ‘“ â€  â—¦
ğ‘ â€²
(cid:74)

skip
(cid:75)

and ğ‘“ â€  â—¦

ğ‘ğœ‹
(cid:74)

âˆ¼

(cid:75)

(cid:75)

(cid:75)

(cid:75)

(cid:74)

ğœ‹

ğœ‹

E DEFERRED RESULTS IN Â§4.3

E.1 Deferred Statements and Their Proofs

Lemma E.1. Let ğ‘“ , ğ‘” : Rğ‘› â†’ R be locally Lipschitz functions. Then, the following differentiation rules

hold for almost every ğ‘¥ âˆˆ Rğ‘›:

âˆ‡(ğ‘“ + ğ‘”)(ğ‘¥) = âˆ‡ğ‘“ (ğ‘¥) + âˆ‡ğ‘”(ğ‘¥),
âˆ‡(ğ‘“ Â· ğ‘”)(ğ‘¥) = âˆ‡ğ‘“ (ğ‘¥) Â· ğ‘”(ğ‘¥) + ğ‘“ (ğ‘¥) Â· âˆ‡ğ‘”(ğ‘¥),
âˆ‡ log ğ‘“ (ğ‘¥) = 1/ğ‘“ (ğ‘¥) Â· âˆ‡ğ‘“ (ğ‘¥),

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:59

where for the third rule we assume ğ‘“ (ğ‘¦) > 0 for all ğ‘¦ âˆˆ Rğ‘›.

Proof. Note that the three functions + : R2 â†’ R, Â· : R2 â†’ R, and log : R>0 â†’ R are all
â–¡

differentiable. Hence, applying Lemma E.4 produces the claim.

Theorem E.2. Let ğ‘“ : R Ã— Rğ‘› â†’ R be a measurable function that satisfies the next conditions:
â€¢ For all ğ‘¥ âˆˆ Rğ‘›, ğ‘“ (âˆ’, ğ‘¥) : R â†’ R is locally Lipschitz.
âˆ«
â€¢ For all ğœƒ âˆˆ R,
Rğ‘› ğ‘“ (ğœƒ, ğ‘¥) ğ‘‘ğ‘¥ is well-defined.
â€¢ For all ğœƒ âˆˆ R, âˆ‡ğœƒ ğ‘“ (ğœƒ, ğ‘¥) is well-defined for almost all ğ‘¥ âˆˆ R.
âˆ«
Rğ‘› Lip(cid:0)ğ‘“ (âˆ’, ğ‘¥)|ğ‘ˆ (cid:1)ğ‘‘ğ‘¥ is well-defined.
â€¢ For all ğœƒ âˆˆ R, there is an open ğ‘ˆ âŠ† R such that ğœƒ âˆˆ ğ‘ˆ and
Here â€œalmost allâ€ is with respect to the Lebesgue measure. Then, for all ğœƒ âˆˆ R, both sides of the following
are well-defined and equal:

âˆ‡ğœƒ

âˆ«

Rğ‘›

ğ‘“ (ğœƒ, ğ‘¥) ğ‘‘ğ‘¥ =

âˆ«

Rğ‘›

âˆ‡ğœƒ ğ‘“ (ğœƒ, ğ‘¥) ğ‘‘ğ‘¥ .

Theorem E.3. Let ğ‘ğ‘š, ğ‘ğ‘”, and ğœ‹ be the inputs to the SPGE (which satisfy the assumptions (i) and (ii)
described in Â§4.2). Suppose that L (ğœğœƒ ) and âˆ‡ğœƒ L (ğœğœƒ ) are well-defined for every ğœğœƒ âˆˆ St[ğœƒ ]. Further,
assume that every sample command in ğ‘ğ‘” has ğœ†ğ‘¦.ğ‘¦ as its third argument, and ğ‘ğ‘” does not have observe
commands. Then, for all ğœğœƒ âˆˆ St[ğœƒ ],

if ğœ‹ satisfies the requirements (R1), (R2â€™), (R3â€™), (R4), and (R5).

âˆ‡ğœƒ L (ğœğœƒ ) = Eğ‘ğ‘ğ‘” ğœ‹ ,ğœğœƒ ( Ë†ğœğ‘›) [grad_est(ğœğœƒ, Ë†ğœğ‘›)]

Proof. The proof is essentially the same as the proof of Theorem 4.4, except that we invoke the
following properties of local Lipschitzness (instead of differentiability): the composition of locally
Lipschitz functions is again locally Lipschitz, and the differentiation rules for +, Ã—, and ğ‘™ğ‘œğ‘” hold
â–¡
almost everywhere for locally Lipschitz functions (Lemma E.1).

Lemma E.4. Let ğ‘“ : ğ‘‹1 â†’ ğ‘‹2 and ğ‘” : ğ‘‹2 â†’ ğ‘‹3 for some open sets ğ‘‹ğ‘– âŠ† Rğ‘›ğ‘– . Suppose that ğ‘“ is locally
Lipschitz and ğ‘” is differentiable. Then, ğ‘” â—¦ ğ‘“ : ğ‘‹1 â†’ ğ‘‹3 is differentiable almost everywhere and the
chain rule for ğ‘” â—¦ ğ‘“ holds almost everywhere, i.e.,

ğ· (ğ‘” â—¦ ğ‘“ )(ğ‘¥) = ğ· (ğ‘”)(ğ‘“ (ğ‘¥)) Â· ğ· (ğ‘“ )(ğ‘¥)

for almost every ğ‘¥ âˆˆ ğ‘‹1. Here we use the Lebesgue measure as an underlying measure.

Proof. Since local Lipschitzness is preserved under a function composition, ğ‘” â—¦ ğ‘“ is locally Lip-
schitz and thus differentiable almost everywhere. Since ğ‘“ is also differentiable almost everywhere
and ğ‘” is differentiable everywhere, the set

ğ‘ˆ = ğ‘‹1 \ {ğ‘¥ âˆˆ ğ‘‹1 | (ğ‘” â—¦ ğ‘“ is differentiable at ğ‘¥)

âˆ§ (ğ‘” is differentiable at ğ‘“ (ğ‘¥))
âˆ§ (ğ‘“ is differentiable at ğ‘¥)}

has Lebesgue measure zero. Note that the differentiability of ğ‘” is importantly used here; if ğ‘” is non-
differentiable even at a point, ğ‘ˆ can have positive measure. The chain rule for ğ‘” â—¦ ğ‘“ holds for each
â–¡
ğ‘¥ âˆˆ ğ‘ˆ and this concludes the proof.

F DEFERRED RESULTS IN Â§5.2

F.1 Proof of Theorem 5.6

Proof of Theorem 5.6. We prove the theorem by induction on the structure of ğ‘. Let (ğ‘, ğ‘‘, ğ‘‰ ) â‰œ
â™¯, and pick ğ‘£ âˆˆ Var. We have to show that ğ‘ (ğ‘£) âŠ‡ ğ‘‘ (ğ‘£)ğ‘ and ğ‘‘ (ğ‘£) âŠ‡ ğ‘‰ . We call these two

ğ‘
(cid:74)
requirements as conditions (i) and (ii).

(cid:75)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:60

Wonyeol Lee, Xavier Rival, and Hongseok Yang

Case ğ‘ â‰¡ skip. In this case, ğ‘ (ğ‘£) = Var and ğ‘‰ = âˆ…, from which the conditions (i) and (ii) follow.

Case ğ‘ â‰¡ ğ‘¥ := ğ‘’. In this case, ğ‘‰ = âˆ…. So, the condition (ii) holds. For the proof of the condition (i),
â™¯ and ğ‘‘ (ğ‘£) = fv(ğ‘’). Since
â™¯ âŠ‡ fv(ğ‘’)ğ‘ , the condition holds. If ğ‘£ is different from ğ‘¥, then ğ‘ (ğ‘£) is Var, and so it includes ğ‘‘ (ğ‘£)ğ‘ .

we do case analysis on ğ‘£. If ğ‘£ is the updated variable ğ‘¥, we have ğ‘ (ğ‘£) =
ğ‘’
(cid:76)

(cid:77)
Case ğ‘ â‰¡ obs(distN (ğ‘’1, ğ‘’2), ğ‘Ÿ ). The proof of this case is similar to the one for the assignments.

ğ‘’
(cid:76)

(cid:77)

Since ğ‘‰ = âˆ…, the condition (ii) holds. If ğ‘£ is the variable like, then

ğ‘ (ğ‘£) =

like Ã— pdfN(ğ‘Ÿ ; ğ‘’1, ğ‘’2)
(cid:76)

(cid:77)

â™¯ âŠ‡ fv(like Ã— pdfN(ğ‘Ÿ ; ğ‘’1, ğ‘’2))ğ‘ =

(cid:16)

{like} âˆª fv(ğ‘’1) âˆª fv(ğ‘’2)

(cid:17)ğ‘

= ğ‘‘ (ğ‘£)ğ‘ .

So, the condition (i) holds in this case. If ğ‘£ is not the variable like, then ğ‘ (ğ‘£) = Var, from which the
condition (i) follows.

Case ğ‘ â‰¡ ğ‘¥ := sam(name(ğ›¼, ğ‘’), distN (ğ‘’1, ğ‘’2), ğœ†ğ‘¦.ğ‘’ â€²). In this case, ğ‘‰ = âˆ…, from which the condition
(ii) follows. We do case analysis on whether ğ‘’ is a real constant ğ‘Ÿ or not. During the case analysis,
we use the assumption that fv(ğ‘’)ğ‘ âŠ†

â™¯ for all ğ‘’, without mentioning it explicitly.

First, we deal with the case thatğ‘’ â‰¡ ğ‘Ÿ . Let ğœ‡ â‰œ create_name(ğ›¼, ğ‘Ÿ ). If ğ‘£ is none of ğ‘¥, valğœ‡, pr ğœ‡, and cntğœ‡,
we have ğ‘ (ğ‘£) = Var, which gives the condition (i). If ğ‘£ âˆˆ {ğ‘¥, valğœ‡ }, we prove the condition (i) as follows:

ğ‘’
(cid:76)

(cid:77)

ğ‘‘ (ğ‘£)ğ‘ = fv(ğ‘’ â€²[ğœ‡/ğ‘¦])ğ‘ âŠ†

â™¯

ğ‘’ â€²[ğœ‡/ğ‘¦]
(cid:76)

(cid:77)

= ğ‘ (ğ‘£).

If ğ‘£ â‰¡ pr ğœ‡, we calculate the condition (i) as follows:

ğ‘‘ (pr ğœ‡)ğ‘ = ({ğœ‡} âˆª fv(ğ‘’1) âˆª fv(ğ‘’2))ğ‘ = fv(pdfN (ğœ‡; ğ‘’1, ğ‘’2))ğ‘ âŠ†

pdfN (ğœ‡; ğ‘’1, ğ‘’2)
(cid:76)

(cid:77)

â™¯

= ğ‘ (pr ğœ‡).

If ğ‘£ â‰¡ cntğœ‡, we derive the condition (i) as follows:

ğ‘‘ (cntğœ‡)ğ‘ = {cntğœ‡ }ğ‘ = fv(cntğœ‡ + 1)ğ‘ âŠ†

â™¯

cntğœ‡ + 1
(cid:76)

(cid:77)

= ğ‘ (cntğœ‡).

Next, we handle the case that ğ‘’ is not a real constant. If ğ‘£ is none of ğ‘¥, valğœ‡, pr ğœ‡, and cntğœ‡ for some
ğœ‡ = (ğ›¼, _), we have ğ‘ (ğ‘£) = Var, which implies the condition (i). If ğ‘£ â‰¡ ğ‘¥, we show the condition (i)
as follows:

ğ‘ (ğ‘£) =

(cid:16)

fv(ğ‘’)ğ‘ âˆ©

(cid:217)
ğœ‡=(ğ›¼,_) âˆˆName (cid:76)

ğ‘’ â€²[ğœ‡/ğ‘¦]

(cid:77)

â™¯(cid:17)

(cid:16)

âŠ‡

fv(ğ‘’) âˆª

(cid:216)

fv(ğ‘’ â€²[ğœ‡/ğ‘¦])

(cid:17)ğ‘

= ğ‘‘ (ğ‘£)ğ‘ .

ğœ‡=(ğ›¼,_) âˆˆName

If ğ‘£ â‰¡ valğœ‡ for some ğœ‡ = (ğ›¼, _), we calculate the condition (i) as follows:

ğ‘ (ğ‘£) =

(cid:16)

fv(ğ‘’)ğ‘ âˆ©

â™¯(cid:17)

(cid:16)

âŠ‡

ğ‘’ â€²[ğœ‡/ğ‘¦]
(cid:76)

(cid:77)

fv(ğ‘’) âˆª {valğœ‡ } âˆª fv(ğ‘’ â€²[ğœ‡/ğ‘¦])

(cid:17)ğ‘

= ğ‘‘ (ğ‘£)ğ‘ .

If ğ‘£ â‰¡ pr ğœ‡ for some ğœ‡ = (ğ›¼, _), we prove the condition (i) as follows:

ğ‘ (ğ‘£) = fv(ğ‘’)ğ‘ âˆ©

pdfN(ğœ‡; ğ‘’1, ğ‘’2)

(cid:76)

(cid:77)

â™¯ âŠ‡ fv(ğ‘’)ğ‘ âˆ© fv(pdfN (ğœ‡; ğ‘’1, ğ‘’2))ğ‘

(cid:16)

âŠ‡

fv(ğ‘’) âˆª {ğœ‡, pr ğœ‡ } âˆª fv(ğ‘’1) âˆª fv(ğ‘’2)

(cid:17)ğ‘

= ğ‘ (pr ğœ‡).

Finally, if ğ‘£ â‰¡ cntğœ‡ for some ğœ‡ = (ğ›¼, _), we show the condition (i) as follows:

ğ‘ (ğ‘£) = fv(ğ‘’)ğ‘ âˆ©

cntğœ‡ + 1
(cid:77)
(cid:76)

â™¯ âŠ‡ fv(ğ‘’)ğ‘ âˆ© fv(cntğœ‡ + 1)ğ‘ = (fv(ğ‘’) âˆª {cntğœ‡ })ğ‘ = ğ‘‘ (ğ‘£)ğ‘ .

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:61

Case ğ‘ â‰¡ ğ‘ â€²; ğ‘ â€²â€². Let (ğ‘ â€², ğ‘‘ â€², ğ‘‰ â€²) â‰œ

ğ‘ â€²
(cid:74)

(cid:75)

â™¯ and (ğ‘ â€²â€², ğ‘‘ â€²â€², ğ‘‰ â€²â€²) â‰œ
âˆª(ğ‘‘ â€²â€²(ğ‘£)) âŠ‡ ğ‘‰ â€² âˆª ğ‘‘ â€²

ğ‘ â€²â€²
(cid:74)

(cid:75)
âˆª(ğ‘‰ â€²â€²) = ğ‘‰ .

ğ‘‘ (ğ‘£) = ğ‘‰ â€² âˆª ğ‘‘ â€²

â™¯. The condition (ii) holds since

For the condition (ii), we prove the required subset relationship as follows:

ğ‘‘ (ğ‘£)ğ‘ = (ğ‘‰ â€² âˆª ğ‘‘ â€²

âˆª(ğ‘‘ â€²â€²(ğ‘£)))ğ‘ = (ğ‘‰ â€²)ğ‘ âˆ©

(cid:217)

ğ‘‘ â€²(ğ‘¤)ğ‘

ğ‘¤ âˆˆğ‘‘â€²â€² (ğ‘£)
(cid:217)

âŠ† (ğ‘‰ â€²)ğ‘ âˆ©

ğ‘ â€²(ğ‘¤) âˆ©

(cid:217)

ğ‘‘ â€²(ğ‘¤)ğ‘

(cid:16)
ğ‘‰ â€² âˆª ğ‘ â€²

ğ‘¤ âˆˆğ‘‘â€²â€² (ğ‘£)
âˆ©(ğ‘‘ â€²â€²(ğ‘£))ğ‘ âˆª ğ‘‘ â€²

ğ‘¤ âˆˆğ‘â€²â€² (ğ‘£)ğ‘
(cid:17)ğ‘
âˆª(ğ‘ â€²â€²(ğ‘£)ğ‘ )

=

= ğ‘ (ğ‘£).

The subset relationship in the above derivation holds because ğ‘‘ â€²(ğ‘¤)ğ‘ âŠ† ğ‘ â€²(ğ‘¤) and ğ‘‘ â€²â€²(ğ‘£) âŠ‡ ğ‘ â€²â€²(ğ‘£)ğ‘
by induction hypothesis.

Case ğ‘ â‰¡ if ğ‘ {ğ‘ â€²} else {ğ‘ â€²â€²}. Let (ğ‘ â€², ğ‘‘ â€², ğ‘‰ â€²) â‰œ

tion hypothesis,

â™¯ and (ğ‘ â€²â€², ğ‘‘ â€²â€², ğ‘‰ â€²â€²) â‰œ

ğ‘ â€²
(cid:74)

(cid:75)

ğ‘ â€²â€²
(cid:74)

(cid:75)

â™¯. Then, by induc-

(cid:16)

ğ‘‰ =

fv(ğ‘) âˆª ğ‘‰ â€² âˆª ğ‘‰ â€²â€²(cid:17)
which implies the condition (ii). Also, by induction hypothesis again,
fv(ğ‘)ğ‘ âˆ© ğ‘‘ â€²(ğ‘£)ğ‘ âˆ© ğ‘‘ â€²â€²(ğ‘£)ğ‘ (cid:17)

fv(ğ‘) âˆª ğ‘‘ â€²(ğ‘£) âˆª ğ‘‘ â€²â€²(ğ‘£)

ğ‘‘ (ğ‘£)ğ‘ =

âŠ†

âŠ†

(cid:16)

(cid:16)

(cid:16)

fv(ğ‘)ğ‘ âˆ© ğ‘ â€²(ğ‘£) âˆ© ğ‘ â€²â€²(ğ‘£)

(cid:17)

= ğ‘‘ (ğ‘£),

(cid:17)

= ğ‘ (ğ‘£),

which shows the condition (ii).

(cid:75)

ğ‘ â€²
(cid:74)

Case ğ‘ â‰¡ whileğ‘ {ğ‘ â€²}. Let (ğ‘ â€², ğ‘‘ â€², ğ‘‰ â€²) â‰œ

â™¯, and ğ¹ â™¯ be the operator in the abstract semantics of ğ‘.
Note that the abstract domain Dâ™¯ contains (ğ‘âŠ¥, ğ‘‘âŠ¥, ğ‘‰âŠ¥) = ((ğœ†ğ‘£.Var), (ğœ†ğ‘£.âˆ…), âˆ…). Thus, it is sufficient
to show that ğ¹ â™¯ is a well-defined monotone function on Dâ™¯, because then the least fixed point of
ğ¹ â™¯ is also in Dâ™¯ and satisfies the conditions (i) and (ii). The monotonicity of ğ¹ â™¯ holds because when
(ğ‘1, ğ‘‘1, ğ‘‰1) â‰œ ğ¹ â™¯ (ğ‘0, ğ‘‘0, ğ‘‰0), the inputs ğ‘0, ğ‘‘0, and ğ‘‰0 are used in the right polarity in the definitions
of ğ‘1, ğ‘‘1, and ğ‘‰1; for instance, ğ‘0 is used only in the positive position (with respect to the subset
order) when it is used to define ğ‘1. To prove well-definedness of ğ¹ â™¯, assume that ğ‘0(ğ‘£0) âŠ‡ ğ‘‘0 (ğ‘£0)ğ‘
and ğ‘‘0(ğ‘£0) âŠ‡ ğ‘‰0 for all ğ‘£0 âˆˆ Var, and pick a variable ğ‘£1 âˆˆ Var. Then, since ğ‘‰0 âŠ† ğ‘‘0(ğ‘£1),
(cid:16)

(cid:17)

(cid:16)

ğ‘‰1 =

fv(ğ‘) âˆª ğ‘‘ â€²

âˆª (ğ‘‰0) âˆª ğ‘‰ â€²(cid:17)

âŠ†

fv(ğ‘) âˆª ğ‘‘ â€²

âˆª (ğ‘‘0(ğ‘£1)) âˆª ğ‘‰ â€² âˆª {ğ‘£1}

= ğ‘‘1(ğ‘£1).

Also, by the induction hypothesis on the loop body ğ‘ â€² and the relationship ğ‘‘0(ğ‘£1) âŠ‡ ğ‘0(ğ‘£1)ğ‘ ,

ğ‘‘1 (ğ‘£1)ğ‘ = fv(ğ‘)ğ‘ âˆ© (ğ‘‰ â€²)ğ‘ âˆ©

(cid:217)

ğ‘‘ â€²(ğ‘¤)ğ‘ âˆ© {ğ‘£1}ğ‘

âŠ† fv(ğ‘)ğ‘ âˆ© (ğ‘‰ â€²)ğ‘ âˆ©

ğ‘¤ âˆˆğ‘‘0 (ğ‘£1)
(cid:217)

ğ‘ â€²(ğ‘¤) âˆ©

(cid:217)

ğ‘‘ â€²(ğ‘¤)ğ‘

= fv(ğ‘)ğ‘ âˆ©

Thus, (ğ‘1, ğ‘‘1, ğ‘‰1) is also in Dâ™¯.

(cid:16)
ğ‘‰ â€² âˆª ğ‘ â€²

ğ‘¤ âˆˆğ‘‘0 (ğ‘£1)
âˆ© (ğ‘‘0(ğ‘£1))ğ‘ âˆª ğ‘‘ â€²

ğ‘¤ âˆˆğ‘0 (ğ‘£1)ğ‘
(cid:17)ğ‘
âˆª(ğ‘0(ğ‘£1)ğ‘ )

= ğ‘1(ğ‘£1).

â–¡

F.2 Proof of Theorem 5.8
Our program analysis consists of two parts, one for tracking the dependency information and the
other for tracking the smoothness information. The first part does not depend on the second, although
it is used crucially by the second part. We exploit this one-way relationship between the two parts

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:62

Wonyeol Lee, Xavier Rival, and Hongseok Yang

of our analysis, and prove the soundness of the dependency-tracking part first and then that of the
other smoothness-tracking part. Consider a command ğ‘, and let (ğ‘, ğ‘‘, ğ‘‰ ) â‰œ

â™¯. Then, we have:

Theorem F.1. For all ğ‘£ âˆˆ Var, we have |= Î”(
Theorem F.2. For all ğ‘£ âˆˆ Var, we have |= Î¦(

, ğ‘‘ (ğ‘£), {ğ‘£ }). Also,
(cid:75)
, ğ‘ (ğ‘£), {ğ‘£ }).
(cid:75)
We prove the two soundness results in Â§F.3 and Â§F.4. From these, we immediately obtain the main
soundness theorem:

ğ‘
(cid:74)
ğ‘
(cid:74)

|= Î”(

ğ‘
(cid:74)

ğ‘
(cid:75)
(cid:74)
, ğ‘‰ , âˆ…).
(cid:75)

Proof of Theorem 5.8. Let ğ‘ be a command and (ğ‘, ğ‘‘, ğ‘‰ ) =
|= Î”(

we have |= Î”(
, ğ‘‘ (ğ‘£), {ğ‘£ }),
ğ‘
(cid:74)
(cid:75)
definition of ğ›¾ (i.e., Eq. (11)), we have

ğ‘
â™¯) as desired.
(cid:74)

âˆˆ ğ›¾ (

ğ‘
(cid:74)

ğ‘
(cid:74)

â™¯. Then, by Theorems F.1 and F.2,
, ğ‘ (ğ‘£), {ğ‘£ }) for all ğ‘£ âˆˆ Var. Hence, by the
(cid:75)
â–¡

(cid:75)

, ğ‘‰ , âˆ…), and |= Î¦(
(cid:75)
ğ‘
ğ‘
(cid:74)
(cid:74)

(cid:75)

(cid:75)

F.3 Proof of Theorem F.1

Proof of Theorem F.1. We prove the theorem by induction on the structure of ğ‘. Let (ğ‘, ğ‘‘, ğ‘‰ ) â‰œ
â™¯. Pick a variable ğ‘£ âˆˆ Var and states ğœ, ğœ â€², ğœ0, ğœ â€²

0 âˆˆ St such that

ğ‘
(cid:74)

(cid:75)

ğœ âˆ¼ğ‘‘ (ğ‘£) ğœ â€² and ğœ0 âˆ¼ğ‘‰ ğœ â€²
0.

We will show that (i) if
ğ‘
ğ‘
(cid:74)
(cid:74)
We refer to these two properties as conditions (i) and (ii) in the rest of the proof.

ğœ â€² âˆˆ St, then
ğ‘
(cid:75)
(cid:74)
ğœ â€²(ğ‘£). Since ğ‘‰ âŠ† ğ‘‘ (ğ‘£), these two imply the claim of the theorem.
(cid:75)

ğœ0 âˆˆ St, then
ğ‘
(cid:74)
(cid:75)
ğœ (ğ‘£) =
(cid:75)

0 âˆˆ St, and (ii) if
ğœ â€²
(cid:75)

ğœ âˆˆ St and
(cid:75)

ğœ â€², i.e.,
(cid:75)

ğœ âˆ¼{ğ‘£ }
(cid:75)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

Case ğ‘ â‰¡ skip. In this case, ğ‘‘ (ğ‘£) = {ğ‘£ } and ğ‘‰ = âˆ…. The condition (i) holds since skip always ter-
ğœ â€²â€² = ğœ â€²â€² for all ğœ â€²â€², and the relation âˆ¼ğ‘‘ (ğ‘£) coincides
(cid:75)

minates. The condition (ii) also holds because
with âˆ¼{ğ‘£ }.

ğ‘
(cid:74)

Case ğ‘ â‰¡ (ğ‘¥ := ğ‘’). In this case, ğ‘‰ = âˆ…, and the condition (i) holds since the assignments always

terminate. For the condition (ii), we do case analysis on the variable ğ‘£.
ğ‘’
(cid:74)

ğ‘
(cid:74)
â€¢ Case ğ‘£ (cid:46) ğ‘¥. In this case, ğ‘‘ (ğ‘£) = {ğ‘£ }, and so ğœ (ğ‘£) = ğœ â€²(ğ‘£). This implies that

â€¢ Case ğ‘£ â‰¡ ğ‘¥. In this case, ğ‘‘ (ğ‘£) = fv(ğ‘’). This implies
ğ‘’
(cid:74)
ğœ â€²(ğ‘¥). This implies the desired
ğ‘
ğœ âˆ¼{ğ‘¥ }
(cid:75)
(cid:74)
(cid:75)
ğœ â€²(ğ‘£), which gives the desired relationship.
(cid:75)

ğœ â€² =
ğ‘’
(cid:74)
(cid:75)
ğœ â€²(ğ‘£) =

ğœ â€². Thus,
(cid:75)

ğœ =
(cid:75)
ğœ â€².
(cid:75)

ğ‘
(cid:74)
ğ‘
(cid:74)

ğ‘
(cid:74)

ğœ =
(cid:75)

ğœ (ğ‘¥) =
(cid:75)
ğ‘
(cid:74)

ğ‘’
(cid:74)
ğœ (ğ‘£) = ğœ (ğ‘£) =
(cid:75)

Case ğ‘ â‰¡ obs(distN (ğ‘’1, ğ‘’2), ğ‘Ÿ ). The observe commands always terminate. Thus, the condition (i)
holds. We prove the condition (ii) by case analysis on the variable ğ‘£. If ğ‘£ is not like, then ğ‘‘ (ğ‘£) = {ğ‘£ },
ğœ (ğ‘£) = ğœ (ğ‘£), and
ğœ (ğ‘£) =
ğ‘
ğœ â€²(ğ‘£), as desired. If ğ‘£ is like, then ğ‘‘ (ğ‘£) = fv(ğ‘’1) âˆª fv(ğ‘’2) âˆª {like}, and for some function ğ‘” : R4 â†’ R,
(cid:75)
(cid:74)
(cid:75)
ğ‘
(cid:75)
(cid:74)
ğ‘
(cid:74)

ğœ â€²(ğ‘£) = ğœ â€²(ğ‘£). Thus, in this case, the assumption ğœ âˆ¼ğ‘‘ (ğ‘£) ğœ â€² implies
(cid:75)

ğœ (ğ‘£) = ğ‘”(ğœ (like), ğ‘Ÿ,
(cid:75)

ğœ) and
(cid:75)

ğœ,
(cid:75)

ğ‘’1
(cid:74)

ğ‘’2
(cid:74)

ğ‘’2
(cid:74)

ğ‘’1
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

Therefore, from the assumption ğœ âˆ¼ğ‘‘ (ğ‘£) ğœ â€², it follows that

ğœ â€²(ğ‘£) = ğ‘”(ğœ â€²(like), ğ‘Ÿ,
(cid:75)
ğœ (ğ‘£) =
(cid:75)

ğœ â€²).
(cid:75)
ğœ â€²(ğ‘£), as desired.
(cid:75)

ğœ â€²,
(cid:75)

ğ‘
(cid:74)

ğ‘
(cid:74)

Case ğ‘ â‰¡ (ğ‘¥ := sam(ğ‘›, distN (ğ‘’1, ğ‘’2), ğœ†ğ‘¦.ğ‘’ â€²)). The sample commands always terminate. So, the

condition (i) holds. We prove the condition (ii) by case analysis on ğ‘›.

The first case is thatğ‘› is a constant expression, i.e., it is an expression of the form name(ğ›¼, ğ‘Ÿ ) for some
ğ›¼ âˆˆ Str and real numberğ‘Ÿ . Let ğœ‡ â‰œ create_name(ğ›¼, ğ‘Ÿ ). Ifğ‘£ is not one ofğ‘¥, valğœ‡, and pr ğœ‡, thenğ‘‘ (ğ‘£) = {ğ‘£ },
ğœ (ğ‘£) = ğ‘”(ğœ (ğ‘£)) and
and
ğœ â€²(ğ‘£) = ğ‘”(ğœ â€²(ğ‘£)) for some function ğ‘” : R â†’ R, so that the assumption
ğ‘
ğ‘
(cid:74)
(cid:75)
(cid:74)
(cid:75)
ğœ â€²(ğ‘£), as desired. If ğ‘£ is ğ‘¥ or valğœ‡, then ğ‘‘ (ğ‘£) = fv(ğ‘’ â€²[ğœ‡/ğ‘¦]),
ğœ âˆ¼ğ‘‘ (ğ‘£) ğœ â€² implies that
ğ‘
ğœ (ğ‘£) =
ğ‘
(cid:75)
(cid:75)
(cid:74)
(cid:74)
ğœ â€²(ğ‘£) holds.
ğœ â€², so that the required
ğœ, and
ğ‘’ â€²[ğœ‡/ğ‘¦]
ğœ â€²(ğ‘£) =
ğ‘
ğœ (ğ‘£) =
ğ‘
(cid:74)
(cid:75)
(cid:75)
(cid:74)
(cid:75)
(cid:74)
(cid:75)
(cid:75)
Finally, if ğ‘£ = pr ğœ‡, then ğ‘‘ (ğ‘£) = {ğœ‡} âˆª fv(ğ‘’1) âˆª fv(ğ‘’2), and so, the assumption ğœ âˆ¼ğ‘‘ (ğ‘£) ğœ â€² implies that

ğ‘’ â€²[ğœ‡/ğ‘¦]
(cid:74)

ğœ (ğ‘£) =
(cid:75)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğœ (pr ğœ‡) =
(cid:75)

(cid:74)

pdfN (ğœ‡; ğ‘’1, ğ‘’2)

ğœ =
(cid:75)

pdfN (ğœ‡; ğ‘’1, ğ‘’2)
(cid:74)

ğœ â€² =
(cid:75)

ğ‘
(cid:74)

ğœ â€²(pr ğœ‡),
(cid:75)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:63

which is precisely the equality that we want.

The next case is that ğ‘› is not a constant expression. Let name(ğ›¼, ğ‘’) be the form of ğ‘›. If ğ‘£ is not
ğœ (ğ‘£) = ğœ (ğ‘£), and
one of ğ‘¥, valğœ‡, pr ğœ‡, and cntğœ‡ for some ğœ‡ of the form (ğ›¼, _), then ğ‘‘ (ğ‘£) = {ğ‘£ },
ğ‘
(cid:75)
(cid:74)
ğœ â€²(ğ‘£). Assume
ğœ â€²(ğ‘£) = ğœ â€²(ğ‘£), so that the assumption ğœ âˆ¼ğ‘‘ (ğ‘£) ğœ â€² implies the desired
ğ‘
ğœ (ğ‘£) =
ğ‘
(cid:75)
(cid:74)
(cid:74)
(cid:75)
(cid:75)
0 â‰œ
that ğ‘£ is one of ğ‘¥, valğœ‡, pr ğœ‡, and cntğœ‡ for some ğœ‡ with ğœ‡ = (ğ›¼, _). Let ğœ‡0 â‰œ
ğœ â€².
ğœ and ğœ‡ â€²
ğ‘›
(cid:75)
(cid:75)
(cid:74)
0. If ğ‘£ is ğ‘¥, then
Since ğ‘‘ (ğ‘£) âŠ‡ fv(ğ‘›) in this case, the assumption ğœ âˆ¼ğ‘‘ (ğ‘£) ğœ â€² ensures that ğœ‡0 = ğœ‡ â€²
fv(ğ‘’ â€²[ğœ‡0/ğ‘¦]) âŠ† ğ‘‘ (ğ‘£), so that the assumption ğœ âˆ¼ğ‘‘ (ğ‘£) ğœ â€² gives the desired

ğ‘›
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

0/ğ‘¦]

ğœ =
(cid:75)

ğ‘’ â€²[ğœ‡ â€²
(cid:74)

ğœ (ğ‘£) =
(cid:75)

ğ‘’ â€²[ğœ‡0/ğ‘¦]
(cid:74)

ğœ â€²(ğ‘£).
ğ‘
(cid:75)
(cid:74)
ğœ (cntğœ‡) = ğ‘”(ğœ (cntğœ‡)) and
If ğ‘£ is cntğœ‡ for some ğœ‡ of the form (ğ›¼, _), then cntğœ‡ âˆˆ ğ‘‘ (ğ‘£), and
ğ‘
(cid:74)
(cid:75)
ğœ â€²(ğ‘£), as desired. If ğ‘£ is
ğœ â€²(cntğœ‡) = ğ‘”(ğœ â€²(cntğœ‡)) for some function ğ‘” : R â†’ R, so that
ğ‘
ğœ (ğ‘£) =
ğ‘
(cid:74)
(cid:75)
(cid:75)
(cid:75)
(cid:74)
ğœ, ğœ (valğœ‡)) and
valğœ‡ for ğœ‡ = (ğ›¼, _), then ğ‘‘ (ğ‘£) âŠ‡ {valğœ‡ } âˆª fv(ğ‘’ â€²[ğœ‡/ğ‘¦]), and
ğœ (valğœ‡) = â„(
ğ‘’ â€²[ğœ‡/ğ‘¦]
(cid:74)
(cid:75)
(cid:75)
ğœ â€²(valğœ‡) as
ğœ â€², ğœ â€²(valğœ‡)) for some â„ : R Ã— R â†’ R, so that
ğœ (valğœ‡) =
ğ‘
ğœ â€²(valğœ‡) = â„(
ğ‘
(cid:74)
(cid:75)
(cid:75)
(cid:74)
(cid:75)
(cid:75)
desired. Finally, if ğ‘£ is pr ğœ‡ for some ğœ‡ of the form (ğ›¼, _), then ğ‘‘ (ğ‘£) âŠ‡ {pr ğœ‡, ğœ‡} âˆª fv(ğ‘’1) âˆª fv(ğ‘’2), and
for some ğ‘˜ : R4 â†’ R,

ğ‘’ â€²[ğœ‡/ğ‘¦]
(cid:74)

ğœ â€² =
(cid:75)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğœ (ğ‘£) = ğ‘˜ (ğœ (pr ğœ‡), ğœ (ğœ‡),
(cid:75)

ğ‘
(cid:74)
so that the assumption ğœ âˆ¼ğ‘‘ (ğ‘£) ğœ â€² guarantees that

ğœ) and
(cid:75)

ğœ,
(cid:75)

ğ‘’1
(cid:74)

ğ‘’2
(cid:74)

Case ğ‘ â‰¡ (ğ‘ â€²; ğ‘ â€²â€²). Let (ğ‘ â€², ğ‘‘ â€², ğ‘‰ â€²) â‰œ

ğ‘ â€²
(cid:74)
ğ‘‘ (ğ‘£) = ğ‘‰ â€² âˆª (ğ‘‘ â€²)âˆª (ğ‘‘ â€²â€²(ğ‘£)) = ğ‘‰ â€² âˆª

ğ‘’1
(cid:74)

ğœ â€²,
(cid:75)

ğ‘’2
(cid:74)

ğœ â€²),
(cid:75)

ğœ â€²(ğ‘£) = ğ‘˜ (ğœ â€²(pr ğœ‡), ğœ â€²(ğœ‡),
(cid:75)
ğ‘
(cid:74)

ğœ â€²(ğ‘£), as desired.
ğ‘
ğœ (ğ‘£) =
(cid:75)
(cid:74)
(cid:75)
â™¯ and (ğ‘ â€²â€², ğ‘‘ â€²â€², ğ‘‰ â€²â€²) â‰œ

â™¯. Recall that

ğ‘ â€²â€²
(cid:74)

(cid:75)
(cid:216)

(cid:75)
{ğ‘‘ â€²(ğ‘£ â€²â€²) | ğ‘£ â€²â€² âˆˆ ğ‘‘ â€²â€²(ğ‘£)} and ğ‘‰ = ğ‘‰ â€² âˆª (ğ‘‘ â€²)âˆª (ğ‘‰ â€²â€²).

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

ğœ0 âˆ¼ğ‘‰ â€²â€²
(cid:75)
ğœ and
(cid:75)

ğ‘ â€²; ğ‘ â€²â€²
(cid:74)
ğ‘ â€²
(cid:74)

Let us handle the condition (i) first. Since

0 are âˆ¼ğ‘‰ -related and ğ‘‰ includes ğ‘‰ â€². Thus,

ğœ0 âˆˆ St, we have
(cid:75)
ğ‘ â€²
(cid:74)

ğœ0 âˆˆ St. But ğœ0 âˆ¼ğ‘‰ â€² ğœ â€²
0,
(cid:75)
because ğœ0 and ğœ â€²
0 âˆˆ St as well by induction hypoth-
ğœ â€²
(cid:75)
esis, and it is sufficient to show
0. Note that for every ğ‘£ â€²â€² âˆˆ ğ‘‰ â€²â€², by the definition
ğœ0 âˆ¼ğ‘‰ â€²â€²
ğœ â€²
(cid:75)
(cid:75)
0, which implies, by induction hypothesis, that
of ğ‘‰ , we have ğ‘‰ âŠ‡ ğ‘‘ â€²(ğ‘£ â€²â€²), and so ğœ0 âˆ¼ğ‘‘â€² (ğ‘£â€²â€²) ğœ â€²
0. As a result, we have the desired
0.
ğœ0 âˆ¼{ğ‘£â€²â€² }
ğœ â€²
ğ‘ â€²
ğ‘ â€²
ğœ â€²
ğ‘ â€²
(cid:75)
(cid:74)
(cid:75)
(cid:74)
(cid:74)
(cid:75)
Next, we deal with the condition (ii). Since
ğœ â€² are both in St, there exist
ğ‘ â€²; ğ‘ â€²â€²
ğ‘ â€²; ğ‘ â€²â€²
(cid:74)
(cid:75)
(cid:74)
ğœ = ğœ1 and
1 such that
states ğœ1, ğœ â€²
1. We apply the induction hypothesis to ğ‘ â€² and get
ğœ â€² = ğœ â€²
ğ‘ â€²
ğ‘ â€²
(cid:74)
(cid:75)
(cid:74)
(cid:75)
1 are in St, we apply the induction hypothesis again but this
ğœ1 and
1. Since
ğ‘ â€²â€²
ğ‘ â€²â€²
ğœ1 âˆ¼ğ‘‘â€²â€² (ğ‘£) ğœ â€²
ğœ â€²
(cid:74)
(cid:74)
(cid:75)
(cid:75)
1, and obtain
time to ğ‘ â€²â€², ğœ1, and ğœ â€²
ğœ1 âˆ¼{ğ‘£ }
ğ‘ â€²â€²
(cid:74)
(cid:75)
ğœ (ğ‘£) =
(cid:75)

1, which implies the desired
ğœ â€²
ğ‘ â€²â€²
(cid:74)
(cid:75)
ğœ1(ğ‘£) =
(cid:75)

ğ‘ â€²â€²
ğ‘
(cid:74)
(cid:74)
Case ğ‘ â‰¡ (if ğ‘ {ğ‘ â€²} else {ğ‘ â€²â€²}). Let (ğ‘ â€², ğ‘‘ â€², ğ‘‰ â€²) â‰œ

fv(ğ‘) âˆª ğ‘‘ â€²(ğ‘£) âˆª ğ‘‘ â€²â€²(ğ‘£) and ğ‘‰ = fv(ğ‘) âˆª ğ‘‰ â€² âˆª ğ‘‰ â€²â€².

applies to the other case that
Furthermore, since ğ‘‰ â€² âŠ† ğ‘‰ and so ğœ0 âˆ¼ğ‘‰ â€² ğœ â€²

(cid:75)
We prove the condition (ğ‘–) under the assumption that

ğ‘ â€²â€²
(cid:74)
ğœ0 = true. Essentially the same proof
ğ‘
(cid:74)
(cid:75)
0 = true.
ğœ0 = false. Since ğ‘‰ includes fv(ğ‘), we also have
ğ‘
ğœ â€²
ğ‘
(cid:75)
(cid:74)
(cid:75)
(cid:74)
0 âˆˆ St.
0 by the induction hypothesis, we get that
ğœ â€²
ğ‘ â€²
(cid:75)
(cid:74)
Next we show the condition (ğ‘–ğ‘–) under the assumption that
ğ‘
(cid:74)
ğ‘
(cid:74)

ğœ = true. As before, the proof of
(cid:75)
ğœ = false is essentially the same. Since ğ‘‘ (ğ‘£) includes fv(ğ‘) and ğ‘‘ â€²(ğ‘£), we have
(cid:75)
ğœ and
ğ‘ â€²
ğœ â€²
ğœ â€² =
(cid:75)
(cid:75)
(cid:75)
(cid:74)
ğœ â€², which implies that
ğ‘ â€²
(cid:75)
(cid:74)
ğœ â€²(ğ‘£) =
ğ‘ â€²
(cid:74)
(cid:75)

ğœ â€² = true and ğœ âˆ¼ğ‘‘â€² (ğ‘£) ğœ â€². Also, because
(cid:75)
ğ‘ â€²
(cid:74)
ğ‘ â€²
(cid:74)

the other case
ğ‘
(cid:74)
are in St. Thus, by induction hypothesis,

ğœ â€²
1(ğ‘£) =
(cid:75)
â™¯ and (ğ‘ â€²â€², ğ‘‘ â€²â€², ğ‘‰ â€²â€²) â‰œ
ğ‘ â€²
(cid:74)

ğœ =
ğ‘
(cid:75)
(cid:74)
ğœ âˆ¼{ğ‘£ }
(cid:75)
ğœ (ğ‘£) =
(cid:75)

â™¯. Then, ğ‘‘ (ğ‘£) =

ğœ â€², both
(cid:75)

ğœ (ğ‘£) =
(cid:75)

ğœ â€²(ğ‘£).
(cid:75)

ğœ â€²(ğ‘£),
(cid:75)

ğœ and
(cid:75)

ğ‘ â€²â€²
(cid:74)

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

ğ‘
(cid:74)

(cid:75)

as desired.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:64

Wonyeol Lee, Xavier Rival, and Hongseok Yang

ğ‘
(cid:74)

(cid:75)

Case ğ‘ â‰¡ (while ğ‘ {ğ‘0}). Let (ğ‘‘0, ğ‘0, ğ‘‰0) â‰œ

â™¯, and ğ¹ â™¯ be the operator in the abstract semantics
(cid:75)
of ğ‘ such that (ğ‘, ğ‘‘, ğ‘‰ ) is the least fixed point of ğ¹ â™¯. Also, let ğ¹ be the operator in the concrete semantics
of ğ‘ such that

is the least fixed point of ğ¹ . Now define

ğ‘0
(cid:74)

ğ‘‡ â‰œ {ğ‘“ âˆˆ [St â†’ StâŠ¥] | for all ğ‘£ âˆˆ Var,
â‰œ ğœ†ğœ. undefined, (ii) it is closed under
We will show that (i) ğ‘‡ contains the empty function âŠ¥Stâ†’StâŠ¥
the least upper bounds of increasing chains, and (iii) the function ğ¹ maps functions in ğ‘‡ to some
functions in the same set. These three imply that the least fixed point of ğ¹ , namely,
, is in ğ‘‡ , which
ğ‘
(cid:75)
(cid:74)
gives the desired conclusion.
|= Î”(âŠ¥Stâ†’StâŠ¥
, ğ‘ˆ , ğ‘ˆ â€²) for all

|= Î”(ğ‘“ , ğ‘‘ (ğ‘£), {ğ‘£ }) and |= Î”(ğ‘“ , ğ‘‰ , âˆ…)}.

The membership of âŠ¥Stâ†’StâŠ¥

to ğ‘‡ is immediate, since we have

ğ‘ˆ , ğ‘ˆ â€² âŠ† Var.

0, ğœ, and ğœ â€² such that

To prove the next requirement, namely, the closure under the least upper bounds of increasing
chains, consider a chain (ğ‘“ğ‘›)ğ‘› âˆˆN in ğ‘‡ , i.e., a sequence such that ğ‘“ğ‘› (ğœ) = ğ‘“ğ‘›+1(ğœ) for all ğ‘› âˆˆ N and
ğœ with ğ‘“ğ‘› (ğœ) âˆˆ St. Let ğ‘“âˆ be the least upper bound of the ğ‘“ğ‘›â€™s (i.e., ğ‘“âˆ (ğœ) = ğ‘“ğ‘› (ğœ) if ğ‘“ğ‘› (ğœ) âˆˆ St and
ğ‘“âˆ(ğœ) = âŠ¥ if ğ‘“ğ‘› (ğœ) = âŠ¥ for all ğ‘› âˆˆ N). As in all the other cases so far, we pick an arbitrary variable
ğ‘£ âˆˆ Var and arbitrary states ğœ0, ğœ â€²
ğœ0 âˆ¼ğ‘‰ ğœ â€²
0,
0) âˆˆ St and ğ‘“âˆ (ğœ) âˆ¼{ğ‘£ } ğ‘“âˆ (ğœ â€²), which correspond to what we have called
We will show that ğ‘“âˆ (ğœ â€²
conditions (i) and (ii) in the previous cases. Since ğ‘“âˆ (ğœ0) âˆˆ St, there exists ğ‘› âˆˆ N such that ğ‘“ğ‘› (ğœ0) âˆˆ St.
Because |= Î”(ğ‘“ğ‘›, ğ‘‰ , âˆ…) and ğœ0 âˆ¼ğ‘‰ ğœ â€²
0) âˆˆ St,
as desired. Our proof of the condition (ii) has a similar form. Since both ğ‘“âˆ(ğœ) and ğ‘“âˆ(ğœ â€²) are in St,
there exists ğ‘› âˆˆ N such that ğ‘“âˆ (ğœ) = ğ‘“ğ‘› (ğœ) and ğ‘“âˆ (ğœ â€²) = ğ‘“ğ‘› (ğœ â€²). By assumption, ğœ âˆ¼ğ‘‘ (ğ‘£) ğœ â€², and
ğ‘“ğ‘› âˆˆ ğ‘‡ . Thus, ğ‘“ğ‘› (ğœ) âˆ¼{ğ‘£ } ğ‘“ğ‘› (ğœ â€²), which gives the desired ğ‘“âˆ (ğœ) âˆ¼{ğ‘£ } ğ‘“âˆ (ğœ â€²).

0) âˆˆ St, which implies that ğ‘“âˆ (ğœ â€²

ğ‘“âˆ (ğœ), ğ‘“âˆ (ğœ â€²) âˆˆ St.

0, we have ğ‘“ğ‘› (ğœ â€²

ğ‘“âˆ (ğœ0) âˆˆ St,

ğœ âˆ¼ğ‘‘ (ğ‘£) ğœ â€²,

0) = ğ‘“ğ‘› (ğœ â€²

It remains to show the last requirement, i.e., the closure under ğ¹ . Pick an arbitrary ğ‘“ âˆˆ ğ‘‡ . Consider

a variable ğ‘£ âˆˆ Var and states ğœ0, ğœ â€²
ğœ0 âˆ¼ğ‘‰ ğœ â€²
0,
We will show that ğ¹ (ğ‘“ )(ğœ â€²
properties as conditions (i) and (ii), as we have done before.

0, ğœ, and ğœ â€² such that

ğœ âˆ¼ğ‘‘ (ğ‘£) ğœ â€²,

ğ¹ (ğ‘“ )(ğœ0) âˆˆ St,
0) âˆˆ St and ğ¹ (ğ‘“ )(ğœ) âˆ¼{ğ‘£ } ğ¹ (ğ‘“ )(ğœ â€²), while referring to these two desired

ğ¹ (ğ‘“ )(ğœ), ğ¹ (ğ‘“ )(ğœ â€²) âˆˆ St.

ğ‘
(cid:74)

ğ‘
(cid:74)

Let us handle the condition (i) first. If

ğœ0) âˆˆ St, we have ğ‘“ (
(cid:75)

ğ‘0
(cid:74)
Next, we prove the condition (ii). If

0 = false, because ğœ0 âˆ¼ğ‘‰ ğœ â€²
ğœ â€²
(cid:75)
ğœ0 = true, then
(cid:75)

ğœ0 = false, we have
0 and
ğ‘
(cid:75)
(cid:74)
fv(ğ‘) âŠ† ğ‘‰ . Thus, in this case, ğ¹ (ğ‘“ )(ğœ â€²
0 is also true. Furthermore,
0 âˆˆ St. If
ğœ â€²
ğ‘
0) = ğœ â€²
(cid:75)
(cid:74)
0 âˆˆ St since ğ‘‰ âŠ‡ ğ‘‰0, ğœ0 âˆ¼ğ‘‰ ğœ â€²
in this case, by induction hypothesis,
ğœ0 âˆˆ St. Also, by
0, and
ğ‘0
ğœ â€²
ğ‘0
(cid:75)
(cid:75)
(cid:74)
(cid:74)
induction hypothesis again,
0. Since ğ‘“ âˆˆ ğ‘‡ and
0, since ğ‘‰ âŠ‡ (ğ‘‘0)âˆª (ğ‘‰ ) and ğœ0 âˆ¼ğ‘‰ ğœ â€²
ğ‘0
ğœ â€²
ğ‘0
ğœ0 âˆ¼ğ‘‰
(cid:75)
(cid:74)
(cid:75)
(cid:74)
0) âˆˆ St, which implies that ğ¹ (ğ‘“ )(ğœ â€²
ğœ â€²
ğ‘0
ğ‘“ (
(cid:75)
(cid:74)
ğœ â€² = false since fv(ğ‘) âŠ† ğ‘‘ (ğ‘£) and
ğœ = false, we have
ğ‘
(cid:75)
(cid:75)
(cid:74)
ğœ âˆ¼ğ‘‘ (ğ‘£) ğœ â€². Thus, in this case, ğ¹ (ğ‘“ )(ğœ) = ğœ and ğ¹ (ğ‘“ )(ğœ â€²) = ğœ â€². Also, {ğ‘£ } âŠ† ğ‘‘ (ğ‘£), and so, ğœ âˆ¼ğ‘‘ (ğ‘£) ğœ â€²
ğœ = true. Then,
implies that ğ¹ (ğ‘“ )(ğœ) = ğœ âˆ¼{ğ‘£ } ğœ â€² = ğ¹ (ğ‘“ )(ğœ â€²), as desired. Now assume that
ğ‘
(cid:74)
(cid:75)
ğœ â€² are in St, so
ğœ and
ğ‘0
ğ‘
(cid:74)
(cid:75)
(cid:74)
(cid:75)
ğœ â€²). Furthermore, since ğ‘‘ (ğ‘£) âŠ‡ (ğ‘‘0)âˆª(ğ‘‘ (ğ‘£)) and
ğœ) and ğ¹ (ğ‘“ )(ğœ â€²) = ğ‘“ (
that ğ¹ (ğ‘“ )(ğœ) = ğ‘“ (
ğ‘0
(cid:75)
(cid:75)
(cid:74)
ğœ â€²) âˆˆ St,
ğœ â€². We then use the fact that ğ‘“ âˆˆ ğ‘‡ and ğ‘“ (
ğœ âˆ¼ğ‘‘ (ğ‘£) ğœ â€², we have
ğœ âˆ¼ğ‘‘ (ğ‘£)
ğ‘0
ğœ), ğ‘“ (
ğ‘0
(cid:75)
(cid:75)
(cid:75)
(cid:74)
(cid:75)
(cid:74)
â–¡
ğœ â€²), which gives the desired ğ¹ (ğ‘“ )(ğœ) âˆ¼{ğ‘£ } ğ¹ (ğ‘“ )(ğœ â€²).
and conclude that ğ‘“ (
ğ‘0
ğœ) âˆ¼{ğ‘£ } ğ‘“ (
ğ‘0
(cid:75)
(cid:74)
(cid:75)
(cid:74)

ğœ â€² = true by the reason that fv(ğ‘) âŠ† ğ‘‘ (ğ‘£) and ğœ âˆ¼ğ‘‘ (ğ‘£) ğœ â€². Also,
(cid:75)

0) âˆˆ St, as desired.

ğ‘0
(cid:74)

ğ‘0
(cid:74)

ğ‘0
(cid:74)

ğ‘0
(cid:74)

ğ‘
(cid:74)

F.4 Proof of Theorem F.2
Let seq be the following operator, which models sequential composition:

seq : [St â†’ StâŠ¥] Ã— [St â†’ StâŠ¥] â†’ [St â†’ StâŠ¥]

seq(ğ‘“ , ğ‘”) â‰œ ğ‘”â€  â—¦ ğ‘“ .

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:65

Also, define an operator cond for modelling if commands as follows:

cond : [St â†’ B] Ã— [St â†’ StâŠ¥] Ã— [St â†’ StâŠ¥] â†’ [St â†’ StâŠ¥]

cond (â„, ğ‘“ , ğ‘”)(ğœ) â‰œ

(cid:40)ğ‘“ (ğœ)
ğ‘”(ğœ)

if â„(ğœ) = true,
if â„(ğœ) = false.

Proof of Theorem F.2. We prove the theorem by induction on the structure ofğ‘. Let (ğ‘, ğ‘‘, ğ‘‰ ) â‰œ

Case ğ‘ â‰¡ skip. In this case,

ğ‘
(cid:74)

conclusion, consider ğ‘£ âˆˆ Var and ğœ âˆˆ St[ğ‘ (ğ‘£)ğ‘ ] = St[âˆ…]. We should show ğ‘” âˆˆ ğœ™ğ‘ (ğ‘£),{ğ‘£ }, where

(cid:75)

(cid:75)
(ğœ) = ğœ for all ğœ âˆˆ St, and ğ‘ (ğ‘£) = Var for all ğ‘£ âˆˆ Var. To prove the

â™¯.

ğ‘
(cid:74)

ğ‘”(ğœ) =

(cid:40)

(ğœ‹Var,{ğ‘£ } â—¦
undefined

ğ‘
(cid:74)

(cid:75)

)(ğœ âŠ• ğœ)

(ğœ âŠ• ğœ) âˆˆ St

ğ‘
(cid:74)

if
(cid:75)
otherwise.

Since

ğ‘
(cid:74)

(cid:75)

(ğœ âŠ• ğœ) =

ğ‘
(cid:74)

(cid:75)

(ğœ) = ğœ âˆˆ St for all ğœ âˆˆ St, we have ğ‘” = ğœ‹Var,{ğ‘£ }. Thus, Assumption 3 implies

ğ‘” = ğœ‹Var,{ğ‘£ } âˆˆ ğœ™Var,{ğ‘£ } = ğœ™ğ‘ (ğ‘£),{ğ‘£ }.

Case ğ‘ â‰¡ (ğ‘¥ := ğ‘’). In this case,

â™¯ if ğ‘£ â‰¡ ğ‘¥. Consider ğ‘£ âˆˆ Var and ğœ âˆˆ St[ğ‘ (ğ‘£)ğ‘ ]. We should show ğ‘” âˆˆ ğœ™ğ‘ (ğ‘£),{ğ‘£ }, where

(cid:75)

ğ‘’
(cid:74)

ğœ] for all ğœ âˆˆ St. Also, ğ‘ (ğ‘£) = Var if ğ‘£ (cid:46) ğ‘¥,
(cid:75)

(ğœ) = ğœ [ğ‘¥ â†¦â†’

ğ‘
(cid:74)

and

ğ‘’
(cid:76)

(cid:77)

ğ‘”(ğœ) =

(cid:40)

(ğœ‹Var,{ğ‘£ } â—¦
undefined

ğ‘
(cid:74)

(cid:75)

)(ğœ âŠ• ğœ)

(ğœ âŠ• ğœ) âˆˆ St

ğ‘
(cid:74)

if
(cid:75)
otherwise.

If ğ‘£ (cid:46) ğ‘¥, then ğ‘”(ğœ) = ğœ‹Var,{ğ‘£ } (
(ğœ)) = ğœ‹Var,{ğ‘£ } (ğœ [ğ‘¥ â†¦â†’
the first equality uses ğ‘ (ğ‘£) = Var, and the last uses ğ‘£ (cid:46) ğ‘¥. Hence, Assumption 3 implies

ğœ]) = ğœ‹Var,{ğ‘£ } (ğœ) for all ğœ âˆˆ St, where
(cid:75)

ğ‘’
(cid:74)

ğ‘
(cid:74)

(cid:75)

If ğ‘£ â‰¡ ğ‘¥, then ğ‘”(ğœ) = (ğœ‹Var,{ğ‘¥ } â—¦
for all ğœ âˆˆ St. Since ğœ âˆˆ St[(
ğ‘’
(cid:76)

Case ğ‘ â‰¡ (ğ‘ â€²; ğ‘ â€²â€²). Let (ğ‘ â€², ğ‘‘ â€², ğ‘‰ â€²) â‰œ

(cid:75)

ğ‘” = ğœ‹Var,{ğ‘£ } âˆˆ ğœ™Var,{ğ‘£ } = ğœ™ğ‘ (ğ‘£),{ğ‘£ }.
)(ğœ âŠ• ğœ) = ğœ‹Var,{ğ‘¥ } ((ğœ âŠ• ğœ) [ğ‘¥ â†¦â†’
ğ‘
â™¯)ğ‘ ] and ğ‘ (ğ‘£) =
(cid:74)
ğ‘’
(cid:76)
(cid:77)
(ğœ âŠ• ğœ)] âˆˆ ğœ™
(cid:75)
â™¯ and (ğ‘ â€²â€², ğ‘‘ â€²â€², ğ‘‰ â€²â€²) â‰œ

ğ‘’
(cid:76)

(cid:77)

ğ‘’
(cid:74)

â™¯, Assumption 2 implies

(cid:75)

â™¯,{ğ‘¥ } = ğœ™ğ‘ (ğ‘£),{ğ‘£ }.
ğ‘ â€²â€²
(cid:74)
(cid:17)ğ‘

(cid:75)

â™¯. Then,

ğ‘’
(cid:74)
ğ‘ â€²
(cid:74)

(cid:75)

(cid:77)
ğ‘” = ğœ†ğœ. [ğ‘¥ â†¦â†’

ğ‘ (ğ‘£) =

=

(cid:16)
ğ‘‰ â€² âˆª (ğ‘ â€²)âˆ©(ğ‘‘ â€²â€²(ğ‘£))ğ‘ âˆª (ğ‘‘ â€²)âˆª (ğ‘ â€²â€²(ğ‘£)ğ‘ )
(cid:16)
(cid:16)
ğ‘‰ â€² âˆª (ğ‘‘ â€²)âˆª (ğ‘ â€²â€²(ğ‘£)ğ‘ )

(ğ‘ â€²)âˆ©(ğ‘‘ â€²â€²(ğ‘£))

\

(cid:17)

(cid:17) for all ğ‘£ âˆˆ Var.

(ğœ âŠ• ğœ)]) = [ğ‘¥ â†¦â†’

(ğœ âŠ• ğœ)]

ğ‘’
(cid:74)

(cid:75)

,
(cid:75)

ğ‘ â€²
(cid:74)

ğ‘ â€²â€²
(cid:74)

). To prove the conclusion, let ğ‘£ âˆˆ Var. It suffices to apply Lemma F.7
, ğ¾ = ğ‘ (ğ‘£), ğ¿ = ğ‘‘ â€²â€²(ğ‘£) âˆ© ğ‘ â€²â€²(ğ‘£), ğ¿â€² = ğ‘‘ â€²â€²(ğ‘£), and ğ‘€ = {ğ‘£ }. What remains is to
(cid:75)

(cid:75)

ğ‘
(cid:74)
, ğ‘” =

Also, we have
= seq(
(cid:75)
to ğ‘“ =
ğ‘ â€²â€²
(cid:74)
show the preconditions of the lemma:
, ğ‘ (ğ‘£), ğ‘‘ â€²â€²(ğ‘£) âˆ© ğ‘ â€²â€²(ğ‘£)).
ğ‘ â€²
(cid:74)
(cid:75)
, ğ‘‘ â€²â€²(ğ‘£) âˆ© ğ‘ â€²â€²(ğ‘£), {ğ‘£ }).
ğ‘ â€²â€²
, ğ‘ (ğ‘£)ğ‘, ğ‘‘ â€²â€²(ğ‘£) \ (ğ‘‘ â€²â€²(ğ‘£) âˆ© ğ‘ â€²â€²(ğ‘£))).
(cid:75)
(cid:74)
ğ‘ â€²
(cid:75)
(cid:74)
, ğ‘‘ â€²â€²(ğ‘£), {ğ‘£ }).
ğ‘ â€²â€²
(cid:75)
(cid:74)

ğ‘ â€²
(cid:74)
(cid:75)
|= Î¦(
|= Î¦(
|= Î”(
|= Î”(

(a)
(b)
(c)
(d)

We obtain (b) as follows: by induction hypothesis on ğ‘ â€²â€², we have |= Î¦(
, ğ‘ â€²â€²(ğ‘£), {ğ‘£ }), and by the
(cid:75)
weakening lemma for Î¦ (Lemma F.4), we have (b). We obtain (d) directly by Theorem F.1 on ğ‘ â€²â€². For (a),
consider induction hypothesis on ğ‘ â€², which says that |= Î¦(
, ğ‘ â€²(ğ‘¤), {ğ‘¤ }) for all ğ‘¤ âˆˆ Var. By the
(cid:75)
merging lemma for Î¦ (Lemma F.6), we have |= Î¦(
, (ğ‘ â€²)âˆ© (ğ‘‘ â€²â€²(ğ‘£) âˆ© ğ‘ â€²â€²(ğ‘£)), ğ‘‘ â€²â€²(ğ‘£) âˆ© ğ‘ â€²â€²(ğ‘£)). Since
(cid:75)

ğ‘ â€²
(cid:74)
ğ‘ (ğ‘£) âŠ† (ğ‘ â€²)âˆ©(ğ‘‘ â€²â€²(ğ‘£)) âŠ† (ğ‘ â€²)âˆ©(ğ‘‘ â€²â€²(ğ‘£) âˆ© ğ‘ â€²â€²(ğ‘£)),

ğ‘ â€²â€²
(cid:74)

ğ‘ â€²
(cid:74)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:66

Wonyeol Lee, Xavier Rival, and Hongseok Yang

we obtain (a) by the weakening lemma for Î¦ (Lemma F.4). For (c), observe that

ğ‘ (ğ‘£)ğ‘ âŠ‡ ğ‘‰ â€² âˆª (ğ‘‘ â€²)âˆª (ğ‘ â€²â€²(ğ‘£)ğ‘ ) and ğ‘‘ â€²â€²(ğ‘£) \ (ğ‘‘ â€²â€²(ğ‘£) âˆ© ğ‘ â€²â€²(ğ‘£)) = ğ‘ â€²â€²(ğ‘£)ğ‘

(24)

ğ‘ â€²
(cid:74)

, ğ‘‰ â€², âˆ…) and |= Î”(
(cid:75)

where the second equality follows from ğ‘ â€²â€²(ğ‘£) âŠ‡ ğ‘‘ â€²â€²(ğ‘£)ğ‘ . By Theorem F.1 on ğ‘ â€², we have
|=
, ğ‘‰ â€², ğ‘ â€²â€²(ğ‘£)ğ‘ )
Î”(
holds, and if ğ‘ â€²â€²(ğ‘£)ğ‘ â‰  âˆ…, then |= Î”(
, (ğ‘‘ â€²)âˆª(ğ‘ â€²â€²(ğ‘£)ğ‘ ), ğ‘ â€²â€²(ğ‘£)ğ‘ ) holds by the merging lemma for Î”
(cid:75)
(cid:75)
(Lemma F.5). By Eq. (24) and the weakening lemma for Î” (Lemma F.3), we obtain (c) for both cases.
Note that we crucially used ğ‘ (ğ‘£)ğ‘ âŠ‡ ğ‘‰ â€² to handle the case ğ‘ â€²â€²(ğ‘£)ğ‘ = âˆ….

, ğ‘‘ â€²(ğ‘¤), {ğ‘¤ }) for all ğ‘¤ âˆˆ Var. If ğ‘ â€²â€²(ğ‘£)ğ‘ = âˆ…, then |= Î”(
(cid:75)

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

ğ‘ â€²
(cid:74)

(cid:75)

ğ‘ â€²â€²
(cid:74)

(cid:75)

Case ğ‘ â‰¡ (if ğ‘ {ğ‘ â€²}, else {ğ‘ â€²â€²}). Let (ğ‘ â€², ğ‘‘ â€², ğ‘‰ â€²) â‰œ

â™¯ and (ğ‘ â€²â€², ğ‘‘ â€²â€², ğ‘‰ â€²â€²) â‰œ

â™¯. Then,

Also,
ğ‘“ =

ğ‘ (ğ‘£) = fv(ğ‘)ğ‘ âˆ© ğ‘ â€²(ğ‘£) âˆ© ğ‘ â€²â€²(ğ‘£) for all ğ‘£ âˆˆ Var.
). To prove the conclusion, let ğ‘£ âˆˆ Var. It suffices to apply Lemma F.8 to
ğ‘
ğ‘
ğ‘ â€²â€²
ğ‘ â€²
= cond (
(cid:74)
(cid:74)
(cid:74)
(cid:74)
(cid:75)
, ğ¾ = ğ‘ (ğ‘£), ğ¿ = {ğ‘£ }, and ğ‘. What remains is to show the preconditions of the lemma:
, ğ‘” =
ğ‘ â€²
ğ‘ â€²â€²
(cid:74)
(cid:75)
(cid:74)
(cid:75)
|= Î¦(
(a)
, ğ‘ (ğ‘£), {ğ‘£ }).
ğ‘ â€²
(cid:75)
(cid:74)
|= Î¦(
, ğ‘ (ğ‘£), {ğ‘£ }).
(b)
ğ‘ â€²â€²
(c) ğ‘ (ğ‘£)ğ‘ âŠ‡ fv(ğ‘).
(cid:74)
(cid:75)

(25)

,
(cid:75)

,
(cid:75)

(cid:75)

We obtain (a) and (b) as follows: by induction hypothesis on ğ‘ â€² and ğ‘ â€²â€², we have |= Î¦(
and |= Î¦(
(a) and (b). We obtain (c) directly by Eq. (25).

, ğ‘ â€²(ğ‘£), {ğ‘£ })
(cid:75)
, ğ‘ â€²â€²(ğ‘£), {ğ‘£ }), and by Eq. (25) and the weakening lemma for Î¦ (Lemma F.4), we have
(cid:75)

ğ‘ â€²â€²
(cid:74)

ğ‘ â€²
(cid:74)

Case ğ‘ â‰¡ (while ğ‘ {ğ‘0}). The proof starts by decomposing

and

ğ‘
(cid:74)

(cid:75)

ğ‘
(cid:74)

(cid:75)

â™¯ into smaller pieces. Let

(ğ‘0, ğ‘‘0, ğ‘‰0) â‰œ

â™¯.

ğ‘0
(cid:74)

(cid:75)

Define ğ¹ : [St â†’ StâŠ¥] â†’ [St â†’ StâŠ¥] and ğ¹ â™¯ : Dâ™¯ â†’ Dâ™¯ as in Â§3 and Fig. 3:

if
if

ğ‘0
(cid:74)

ğœ)
(cid:75)

ğ‘
(cid:74)
ğ‘
(cid:74)

Define ğ‘¡ â€²

ğ¹ (ğ‘¡)(ğœ) â‰œ

ğœ = false
(cid:75)
ğœ = true,
(cid:75)

(cid:40)ğœ
ğ‘¡ â€  (
ğœ†ğ‘£. fv(ğ‘)ğ‘ âˆ© (ğ‘‰0 âˆª (ğ‘0)âˆ©(ğ‘‘ (ğ‘£))ğ‘ âˆª (ğ‘‘0)âˆª(ğ‘ (ğ‘£)ğ‘ ))ğ‘,
ğ¹ â™¯ (ğ‘, ğ‘‘, ğ‘‰ ) â‰œ (cid:169)
ğœ†ğ‘£. fv(ğ‘) âˆª ğ‘‰0 âˆª (ğ‘‘0)âˆª(ğ‘‘ (ğ‘£)) âˆª {ğ‘£ },
(cid:173)
fv(ğ‘) âˆª (ğ‘‘0)âˆª (ğ‘‰ ) âˆª ğ‘‰0
(cid:171)
ğ‘› âˆˆ [St â†’ StâŠ¥] and (ğ‘ â€²
ğ‘›, ğ‘‰ â€²
ğ‘›, ğ‘‘ â€²
(cid:40)ğœ†ğœ. ğ¹ ğ‘› (ğ‘¡âŠ¥)(ğœ)
(ğ¹ â™¯)ğ‘› (ğ‘âŠ¥, ğ‘‘âŠ¥, ğ‘‰âŠ¥),
if ğ‘› âˆˆ N
(cid:195)ğ‘– âˆˆN(ğ‘ â€²
(cid:195)ğ‘– âˆˆN ğ‘¡ â€²
if ğ‘› = âˆ,
ğ‘– , ğ‘‘ â€²
ğ‘–
where ğ‘¡âŠ¥ = ğœ†ğœ. âŠ¥ and (ğ‘âŠ¥, ğ‘‘âŠ¥, ğ‘‰âŠ¥) = (ğœ†ğ‘£. Var, ğœ†ğ‘£. âˆ…, âˆ…). Then, we have
= ğ‘¡ â€²

âˆ, ğ‘‰ â€²
(cid:75)
The proof is organized as follows. Define ğ‘‡ ,ğ‘‡ â€² âŠ† [St â†’ StâŠ¥] as

ğ‘› ) âˆˆ Dâ™¯ for ğ‘› âˆˆ N âˆª {âˆ} as

âˆ and

ğ‘– , ğ‘‰ â€²
ğ‘– )

= (ğ‘ â€²

âˆ, ğ‘‘ â€²

ğ‘›, ğ‘‰ â€²

ğ‘› ) â‰œ

ğ‘¡ â€²
ğ‘› â‰œ

ğ‘›, ğ‘‘ â€²

âˆ).

ğ‘
(cid:74)

ğ‘
(cid:74)

(ğ‘ â€²

(cid:40)

(cid:75)

â™¯

.

(cid:170)
(cid:174)
(cid:172)

if ğ‘› âˆˆ N
if ğ‘› = âˆ,

ğ‘‡ â‰œ {ğ‘“ âˆˆ [St â†’ StâŠ¥] | âˆ€ğ‘£ âˆˆ Var.
ğ‘‡ â€² â‰œ {ğ‘“ âˆˆ [St â†’ StâŠ¥] | âˆ€ğ‘£ âˆˆ Var.

In Theorem F.1, we proved

|= Î”(ğ‘“ , ğ‘‘ â€²
|= Î¦(ğ‘“ , ğ‘ â€²

âˆ (ğ‘£), {ğ‘£ }) âˆ§ |= Î”(ğ‘“ , ğ‘‰ â€²
âˆ (ğ‘£), {ğ‘£ })}.

âˆ, âˆ…)},

In this theorem, our goal is to show ğ‘¡ â€²

ğ‘¡ â€²
ğ‘› âˆˆ ğ‘‡ for all ğ‘› âˆˆ N âˆª {âˆ}.
âˆ âˆˆ ğ‘‡ â€². To do so, we prove the next three statements:

(26)

0 âˆˆ ğ‘‡ â€².

(a) ğ‘¡ â€²
(b) If ğ‘¡ â€² âˆˆ ğ‘‡ â€² âˆ© ğ‘‡ , then ğ¹ (ğ‘¡ â€²) âˆˆ ğ‘‡ â€².
ğ‘› âˆˆ ğ‘‡ â€² for all ğ‘› âˆˆ N, then ğ‘¡ â€²
(c) If ğ‘¡ â€²

âˆ âˆˆ ğ‘‡ â€².

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:67

ğ‘› âˆˆ ğ‘‡ â€² for all ğ‘› âˆˆ N, and this and

âˆ (ğ‘£), {ğ‘£ }) for all ğ‘£ âˆˆ Var.

It suffices to prove the three because (a), (b), and Eq. (26) imply ğ‘¡ â€²
âˆ âˆˆ ğ‘‡ â€². We now prove (a), (b), and (c) as follows.
(c) imply ğ‘¡ â€²

First, (a) follows directly from Lemma F.9.
Next, we prove (b). Consider ğ‘¡ â€² âˆˆ ğ‘‡ â€² âˆ©ğ‘‡ . Our goal is to show |= Î¦(ğ¹ (ğ‘¡ â€²), ğ‘ â€²

Observe that

, ğ‘¡ â€²),
(cid:75)
By Theorem F.1 and induction hypothesis on ğ‘0, we have

ğ¹ (ğ‘¡ â€²) = cond (

, seq(
(cid:75)

ğ‘0
(cid:74)

ğ‘
(cid:74)

).

skip
(cid:75)

(cid:74)

and by assumption, we have

âˆˆ ğ›¾ (ğ‘0, ğ‘‘0, ğ‘‰0),

ğ‘0
(cid:74)

(cid:75)

ğ‘¡ â€² âˆˆ ğ›¾ (ğ‘ â€²

âˆ, ğ‘‘ â€²

âˆ, ğ‘‰ â€²

âˆ) = ğ‘‡ â€² âˆ© ğ‘‡ .

By applying to these the proofs of skip, sequential composition, and conditional cases, we have

|= Î¦(ğ¹ (ğ‘¡ â€²), ğ‘ â€²â€²(ğ‘£), {ğ‘£ }) for all ğ‘£ âˆˆ Var

where

ğ‘ â€²â€²(ğ‘£) = fv(ğ‘)ğ‘ âˆ©

(cid:16)
ğ‘‰0 âˆª (ğ‘0)âˆ©(ğ‘‘ â€²

âˆ (ğ‘£)ğ‘ )

(cid:17)ğ‘

âˆ© Var.

âˆ (ğ‘£))ğ‘ âˆª (ğ‘‘0)âˆª (ğ‘ â€²
âˆ, ğ‘‘ â€²

Since ğ‘ â€²â€² is the ğ‘ part of ğ¹ â™¯ (ğ‘ â€²
Hence, we obtain |= Î¦(ğ¹ (ğ‘¡ â€²), ğ‘ â€²

âˆ, ğ‘‰ â€²

âˆ) and (ğ‘ â€²

âˆ, ğ‘‘ â€²
âˆ (ğ‘£), {ğ‘£ }) for all ğ‘£ âˆˆ Var. This completes the proof of (b).

âˆ) is a fixed point of ğ¹ â™¯, we have ğ‘ â€²â€² = ğ‘ â€²
âˆ.

âˆ, ğ‘‰ â€²

Finally, we prove (c). Suppose that ğ‘¡ â€²

ğ‘› âˆˆ ğ‘‡ â€² for all ğ‘› âˆˆ N, and let ğ‘£ âˆˆ Var. Our goal is to show

Observe that Lemma F.10 implies the goal when applied to ğ¾ = ğ‘ â€²
{ğ‘¡ â€²

ğ‘› }ğ‘› âˆˆN. Hence, it suffices to show the three preconditions of the lemma:

âˆ (ğ‘£), ğ¿ = {ğ‘£ }, and {ğ‘“ğ‘› }ğ‘› âˆˆN =

|= Î¦(ğ‘¡ â€²

âˆ, ğ‘ â€²

âˆ (ğ‘£), {ğ‘£ }).

ğ‘› }ğ‘› âˆˆN is an ğœ”-chain.

â€¢ {ğ‘¡ â€²
â€¢ For all ğœ âˆˆ St[ğ‘ â€²
â€¢ For all ğ‘› âˆˆ N, we have |= Î¦(ğ‘¡ â€²

ğ‘›, ğ‘ â€²

âˆ (ğ‘£), {ğ‘£ }).

âˆ (ğ‘£)ğ‘ ] and ğ‘› âˆˆ N, the set {ğœ â€² âˆˆ St[ğ‘ â€²

âˆ (ğ‘£)] | ğ‘¡ â€²

ğ‘› (ğœ â€² âŠ• ğœ) âˆˆ St} is âˆ… or St[ğ‘ â€²

âˆ (ğ‘£)].

The first precondition was already observed in Â§3. The third one holds by the assumption that ğ‘¡ â€²
for all ğ‘› âˆˆ N. For the second one, it is enough to show the next two statements:

ğ‘› âˆˆ ğ‘‡ â€²

(i) For all ğ‘ˆ âŠ† Var with ğ‘ˆ âŠ‡ ğ‘‰ â€²

âˆ, and for all ğœ âˆˆ St[ğ‘ˆ ] and ğ‘› âˆˆ N, the next set is âˆ… or St[ğ‘ˆ ğ‘ ]:
{ğœ â€² âˆˆ St[ğ‘ˆ ğ‘ ] | ğ‘¡ â€²

ğ‘› (ğœ â€² âŠ• ğœ) âˆˆ St}.

(ii) For all ğ‘£ âˆˆ Var,

âˆ (ğ‘£)ğ‘ âŠ‡ ğ‘‰ â€²
ğ‘ â€²
âˆ.
We give the proof of the two statements below. This completes the proof of the while-loop case.

Proof of (ii). We prove a stronger statement: for all ğ‘› âˆˆ N and ğ‘£ âˆˆ Var, ğ‘ â€²
ğ‘› (ğ‘£)ğ‘ âŠ‡ (cid:208)ğ‘› âˆˆN ğ‘‰ â€²

ment implies (ii) because ğ‘ â€²
statement by induction on ğ‘›. For ğ‘› = 0, we have

âˆ (ğ‘£)ğ‘ = ((cid:209)ğ‘› âˆˆN ğ‘ â€²

ğ‘› (ğ‘£))ğ‘ = (cid:208)ğ‘› âˆˆN ğ‘ â€²

ğ‘› (ğ‘£)ğ‘ âŠ‡ ğ‘‰ â€²
ğ‘› = ğ‘‰ â€²

ğ‘› . This state-
âˆ. We prove the

ğ‘› (ğ‘£)ğ‘ = Var
ğ‘ â€²

ğ‘ = âˆ… âŠ‡ âˆ… = ğ‘‰ â€²

ğ‘› for all ğ‘£ âˆˆ Var.

For ğ‘› > 0, let ğ‘£ âˆˆ Var. By induction hypothesis, ğ‘ â€²

ğ‘›âˆ’1(ğ‘£)ğ‘ âŠ‡ ğ‘‰ â€²

ğ‘› (ğ‘£)ğ‘ = fv(ğ‘) âˆª ğ‘‰0 âˆª (ğ‘0)âˆ© (ğ‘‘ â€²
ğ‘ â€²
âŠ‡ fv(ğ‘) âˆª ğ‘‰0 âˆª (ğ‘‘0)âˆª (ğ‘‰ â€²

ğ‘›âˆ’1(ğ‘£))ğ‘ âˆª (ğ‘‘0)âˆª (ğ‘ â€²
ğ‘›âˆ’1) = ğ‘‰ â€²
ğ‘› .

ğ‘›âˆ’1 holds. Using this, we have
ğ‘›âˆ’1(ğ‘£)ğ‘ )

This completes the proof of (ii).

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:68

Wonyeol Lee, Xavier Rival, and Hongseok Yang

Proof of (i). Consider ğ‘ˆ âŠ† Var, ğœ âˆˆ St[ğ‘ˆ ], and ğ‘› âˆˆ N such that ğ‘ˆ âŠ‡ ğ‘‰ â€²

âˆ. Let Î£ â‰œ {ğœ â€² âˆˆ St[ğ‘ˆ ğ‘ ] |
ğ‘› (ğœ â€² âŠ• ğœ) âˆˆ St}. If Î£ = âˆ…, there is nothing left to prove. So assume Î£ â‰  âˆ…. To prove Î£ = St[ğ‘ˆ ğ‘ ], we
ğ‘¡ â€²
need to show that ğ‘¡ â€²
ğ‘› (ğœ â€² âŠ• ğœ) âˆˆ St
using the next two claims:

ğ‘› (ğœ â€² âŠ• ğœ) âˆˆ St for any ğœ â€² âˆˆ St[ğ‘ˆ ğ‘ ]. Choose ğœ â€² âˆˆ St[ğ‘ˆ ğ‘ ]. We show ğ‘¡ â€²

(iii) For all ğ‘› âˆˆ N and ğœ âˆˆ St,

ğ‘¡ â€²
ğ‘› (ğœ) =

(cid:40)

ğ‘ (ğ‘–)
0
(cid:74)
âŠ¥

ğœ
(cid:75)

if ğ‘– âˆˆ ğ¼ğ‘› (ğœ)
otherwise,

where ğ‘ (ğ‘–)

0 â‰œ (skip; ğ‘0; Â· Â· Â· ; ğ‘0) that has ğ‘– copies of ğ‘0, and
ğ‘ (ğ‘–)
0
(cid:74)

ğœ âˆˆ St âˆ§
(cid:75)

ğ¼ğ‘› (ğœ) â‰œ {ğ‘– âˆˆ [0, ğ‘› âˆ’ 1] |

(cid:75)

(

(
(cid:75)
Note that Eq. (27) is well-defined since ğ¼ğ‘› (ğœ) has at most one element.

ğœ) = Â· Â· Â· =
(cid:75)

ğ‘
(cid:74)

âˆ§

(cid:75)

(

ğ‘
(cid:74)
ğ‘
(cid:74)

ğ‘ (ğ‘–)
ğœ) = false
0
(cid:74)
(cid:75)
ğ‘ (ğ‘–âˆ’1)
0
(cid:74)

(27)

ğ‘ (0)
0
(cid:74)

ğœ) = true}.
(cid:75)

(iv) For all ğ‘› âˆˆ N,

|= Î”(

ğ‘ (ğ‘›)
0
(cid:74)

, ğ‘‰ â€²
(cid:75)

âˆ, fv(ğ‘)).

We give the proof of the two claims below, and for now we just assume them.

Since Î£ â‰  âˆ…, there is some ğœ â€²â€² âˆˆ St[ğ‘ˆ ğ‘ ] such that ğ‘¡ â€²

ğ‘› (ğœ â€²â€² âŠ• ğœ) âˆˆ St. Since ğ‘¡ â€²

ğ‘› (ğœ â€²â€² âŠ• ğœ) âˆˆ St, (iii)

implies that

ğ‘› (ğœ â€²â€² âŠ• ğœ) =
ğ‘¡ â€²
for some ğ‘š âˆˆ ğ¼ğ‘› (ğœ â€²â€² âŠ• ğœ). Since ğœ â€² âŠ• ğœ âˆ¼ğ‘‰ â€²
ğ‘ (ğ‘š)
ğ‘– âˆˆ [0, ğ‘š] (by
0
(cid:74)
ğ‘ (ğ‘–)
(ğœ â€² âŠ• ğœ) âˆˆ St and
0
(cid:74)

(cid:75)
(ğœ â€²â€² âŠ• ğœ) âˆˆ St), (iv) implies that

ğ‘ (ğ‘–)
0
(cid:74)

(cid:75)

(cid:75)

(cid:75)

âˆ

for all ğ‘– âˆˆ [0, ğ‘š].
By combining these with ğ‘š âˆˆ ğ¼ğ‘› (ğœ â€²â€² âŠ• ğœ), we get ğ‘š âˆˆ ğ¼ğ‘› (ğœ â€² âŠ• ğœ). Hence, by (iii), we have

(ğœ â€² âŠ• ğœ) âˆ¼fv (ğ‘)

(ğœ â€²â€² âŠ• ğœ)

(cid:75)

ğ‘ (ğ‘–)
0
(cid:74)

ğ‘ (ğ‘š)
(ğœ â€²â€² âŠ• ğœ) âˆˆ St
0
(cid:74)
ğœ â€²â€² âŠ• ğœ (by ğ‘ˆ âŠ‡ ğ‘‰ â€²

âˆ) and

ğ‘ (ğ‘–)
0
(cid:74)

(cid:75)

(ğœ â€²â€² âŠ• ğœ) âˆˆ St for all

This completes the proof of (i).

ğ‘› (ğœ â€² âŠ• ğœ) =
ğ‘¡ â€²

ğ‘ (ğ‘š)
0
(cid:74)

(cid:75)

(ğœ â€² âŠ• ğœ) âˆˆ St.

Proof of (iii). We prove this by induction on ğ‘›. For ğ‘› = 0, ğ‘¡ â€²

ğ‘› (ğœ) = âŠ¥ and ğ¼ğ‘› (ğœ) = âˆ… for all ğœ âˆˆ St.

Hence, Eq. (27) holds. For ğ‘› > 0, we have

ğ‘›âˆ’1)(ğœ)

ğ‘› (ğœ) = ğ¹ (ğ‘¡ â€²
ğ‘¡ â€²
(cid:40)ğœ
(ğ‘¡ â€²
ğ‘›âˆ’1)â€  (

=

=

=

(

(cid:75)

ğœ
ğ‘ (ğ‘–)
0
(cid:74)
âŠ¥
ğ‘ (0)
ğœ
0
(cid:74)
(cid:75)
ğ‘ (ğ‘–+1)
0
(cid:74)
âŠ¥

ï£±ï£´ï£´ï£´ï£²
ï£´ï£´ï£´
ï£³
ï£±ï£´ï£´ï£´ï£²
ï£´ï£´ï£´
ï£³

ğœ
(cid:75)

ğ‘0
(cid:74)

ğœ)
(cid:75)

ğ‘0
(cid:74)

ğœ)
(cid:75)

if
if

ğ‘
(cid:74)
ğ‘
(cid:74)
ğ‘
(cid:74)
ğ‘
(cid:74)

ğœ = false
(cid:75)
ğœ = true
(cid:75)
if
ğœ = false Â· Â· Â· (âˆ—1)
(cid:75)
if
ğœ = true,
(cid:75)
otherwise

ğ‘0
(cid:74)

ğœ âˆˆ St and ğ‘– âˆˆ ğ¼ğ‘›âˆ’1(
(cid:75)

ğ‘0
(cid:74)

ğœ) Â· Â· Â· (âˆ—2)
(cid:75)

if 0 âˆˆ ğ¼ğ‘› (ğœ) Â· Â· Â· (âˆ—â€²
1)
if ğ‘– + 1 âˆˆ ğ¼ğ‘› (ğœ) and ğ‘– + 1 â‰¥ 1 Â· Â· Â· (âˆ—â€²
2)
otherwise.

The second equality is by the definition of ğ¹ , the third by induction hypothesis, and the last by the
following: for any ğœ âˆˆ St and ğ‘— âˆˆ {1, 2}, (âˆ—ğ‘— ) holds iff (âˆ—â€²
ğœ âˆˆ St
ğ‘ (ğ‘–+1)
(cid:75)
implies
ğœ âˆˆ St. Hence, Eq. (27) holds. This
ğœ âˆˆ St implies
(
0
(cid:75)
(cid:75)
(cid:74)
(cid:75)
completes the proof of (iii).

ğ‘— ) holds; and for any ğ‘– âˆˆ N,

ğœ, and
(cid:75)

ğ‘ (ğ‘–+1)
0
(cid:74)

ğœ) =
(cid:75)

ğ‘ (ğ‘–)
0
(cid:74)

ğ‘0
(cid:74)

ğ‘0
(cid:74)

ğ‘0
(cid:74)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:69

Proof of (iv). To prove this, we prove a stronger statement: for all ğ‘› âˆˆ N,

This statement implies (iv) since ğ‘‰ â€²
ğ‘› âŠ† ğ‘‰ â€²
for Î” (Lemma F.3). We prove the statement by induction on ğ‘›. For ğ‘› = 0,
ğ‘›+1 = fv(ğ‘) âˆª ğ‘‰0. By Theorem F.1 on skip, we have |= Î”(
ğ‘‰ â€²
by the merging lemma for Î” (Lemma F.5), we have

ğ‘ (ğ‘›)
ğ‘›+1, fv(ğ‘)).
0
(cid:74)
âˆ for all ğ‘› âˆˆ N and we have the weakening lemma
ğ‘ (ğ‘›)
and
0
(cid:74)
, {ğ‘£ }, {ğ‘£ }) for all ğ‘£ âˆˆ Var, and then
skip
(cid:75)

, ğ‘‰ â€²
(cid:75)
=

skip
(cid:75)

|= Î”(

(cid:75)

(cid:74)

(cid:74)

Since ğ‘‰ â€²
forğ‘› > 0,
on ğ‘0, and induction hypothesis of the theorem (not that of the claim (iv)), we have

ğ‘›+1, fv(ğ‘)) holds by the weakening lemma for Î” (Lemma F.3). Next,
= (ğ‘0, ğ‘‘0, ğ‘‰0), Theorem F.1
ğ‘›+1 = fv(ğ‘) âˆª ğ‘‰0 âˆª (ğ‘‘0)âˆª(ğ‘‰ â€²

ğ‘›+1 âŠ‡ fv(ğ‘),
ğ‘ (ğ‘›)
=
0
(cid:74)

ğ‘ (ğ‘›)
|= Î”(
0
ğ‘0; ğ‘ (ğ‘›âˆ’1)
(cid:74)
0
(cid:74)

, ğ‘‰ â€²
(cid:75)
andğ‘‰ â€²

ğ‘› ). By

ğ‘0
(cid:74)

(cid:75)

(cid:75)

(cid:75)

â™¯

|= Î”(

, fv(ğ‘), fv(ğ‘)).
skip
(cid:75)

(cid:74)

Also, by induction hypothesis of our strengthening of the claim (iv) and the weakening lemma for
Î” (Lemma F.3),

âˆˆ ğ›¾ (ğ‘0, ğ‘‘0, ğ‘‰0).

ğ‘0
(cid:74)

(cid:75)

By applying to these the proof of Theorem F.1 (on the sequential composition case), we have

|= Î”(

ğ‘ (ğ‘›âˆ’1)
0
(cid:74)

, ğ‘‰ â€²
(cid:75)

ğ‘›, {ğ‘£ }) for all ğ‘£ âˆˆ fv(ğ‘).

|= Î”(

ğ‘0; ğ‘ (ğ‘›âˆ’1)
0
(cid:74)

By the merging lemma for Î” (Lemma F.5),
cludes ğ‘‰0 âˆª (ğ‘‘0)âˆª (ğ‘‰ â€²
This completes the proof of (iv).

ğ‘› ), we get |= Î”(

ğ‘› ), {ğ‘£ }) for all ğ‘£ âˆˆ fv(ğ‘).

, ğ‘‰0 âˆª (ğ‘‘0)âˆª (ğ‘‰ â€²
(cid:75)
ğ‘ (ğ‘›)
|= Î”(
ğ‘›+1 in-
0
ğ‘ (ğ‘›)
(cid:74)
ğ‘›+1, fv(ğ‘)) by the weakening lemma for Î” (Lemma F.3).
0
(cid:74)

, ğ‘‰0 âˆª (ğ‘‘0)âˆª(ğ‘‰ â€²
(cid:75)

ğ‘› ), fv(ğ‘)) holds. Since ğ‘‰ â€²

, ğ‘‰ â€²
(cid:75)

Case ğ‘ â‰¡ (ğ‘¥ := sam(name(ğ›¼, ğ‘’), distN (ğ‘’1, ğ‘’2), ğœ†ğ‘¦.ğ‘’ â€²)). To prove the conclusion, consider ğ‘£ âˆˆ Var

and ğœ âˆˆ St[ğ‘ (ğ‘£)ğ‘ ]. We should show ğ‘” âˆˆ ğœ™ğ‘ (ğ‘£),{ğ‘£ }, where

ğ‘”(ğœ) = ğœ‹Var,{ğ‘£ } (

We prove this by case analysis on ğ‘£.

(ğœ âŠ• ğœ)) = [ğ‘£ â†¦â†’

ğ‘
(cid:74)

(cid:75)

(ğœ âŠ• ğœ)(ğ‘£)].

ğ‘
(cid:74)

(cid:75)

First, suppose ğ‘£ âˆ‰ {ğ‘¥ } âˆª {valğœ‡, pr ğœ‡, cntğœ‡ | ğœ‡ âˆˆ Name, ğœ‡ = (ğ›¼, _)}. Then, ğ‘ (ğ‘£) = Var and

ğ‘”(ğœ) = [ğ‘£ â†¦â†’

ğ‘
(cid:74)

ğœ (ğ‘£)] = [ğ‘£ â†¦â†’ ğœ (ğ‘£)] = ğœ‹Var,{ğ‘£ } (ğœ)
(cid:75)

(cid:75)

ğ‘
(cid:74)

for all ğœ âˆˆ St[ğ‘ (ğ‘£)]. Here the first equality follows from ğœ âˆˆ St[âˆ…], and the second equality holds
does not change the value of ğ‘£. Hence, by Assumption 3, ğ‘” = ğœ‹Var,{ğ‘£ } âˆˆ ğœ™Var,{ğ‘£ } = ğœ™ğ‘ (ğ‘£),{ğ‘£ }.
since
Next, suppose ğ‘£ âˆˆ {ğ‘¥ } âˆª {valğœ‡, pr ğœ‡, cntğœ‡ | ğœ‡ âˆˆ Name, ğœ‡ = (ğ›¼, _)}. Then, we have ğ‘ (ğ‘£)ğ‘ âŠ‡ fv(ğ‘’):
if ğ‘’ is a constant, fv(ğ‘’) = âˆ… holds, and if ğ‘’ is not a constant, the definition of ğ‘ (ğ‘£) ensures this. Thus,
there exists ğœ‡0 âˆˆ Name such that create_name(ğ›¼,
(ğœ âŠ• ğœ)) = ğœ‡0 for all ğœ âˆˆ St[ğ‘ (ğ‘£)]. We now do
refined case analysis on ğ‘£ using ğœ‡0.

ğ‘’
(cid:74)

(cid:75)

â€¢ Case ğ‘£ âˆˆ {valğœ‡, pr ğœ‡, cntğœ‡ | ğœ‡ âˆˆ Name, ğœ‡ = (ğ›¼, _), ğœ‡ â‰  ğœ‡0}. In this case,

ğ‘”(ğœ) = [ğ‘£ â†¦â†’ (ğœ âŠ• ğœ)(ğ‘£)] = ğœ‹Var,{ğ‘£ } (ğœ âŠ• ğœ)

does not change the value of ğ‘£. By
for all ğœ âˆˆ St[ğ‘ (ğ‘£)]. Here the first equality holds since
Assumption 3, we have ğœ‹Var,{ğ‘£ } âˆˆ ğœ™Var,{ğ‘£ }. Then, by Assumption 5, we obtain ğ‘” âˆˆ ğœ™ğ‘ (ğ‘£),{ğ‘£ }. Note
â™¯,
that this argument does not depend on the value of ğ‘ (ğ‘£) (which can be Var, fv(ğ‘’)ğ‘ âˆ©
etc., depending on ğ‘’ and ğ‘£).

ğ‘£ + 1
(cid:76)

ğ‘
(cid:74)

(cid:75)

(cid:77)
1 . So, there
1 ] such that ğœ = ğœ1 âŠ• ğœ2. Let â„ : St[ğ¾1] â†’ St[{ğ‘£ }] be

â™¯. Then, ğ‘ (ğ‘£)ğ‘ âŠ‡ (

ğ‘’ â€²[ğœ‡0/ğ‘¦]
(cid:76)

â™¯)ğ‘ = ğ¾ğ‘

(cid:77)

(cid:77)

ğ‘’ â€²[ğœ‡0/ğ‘¦]
(cid:76)

â€¢ Case ğ‘£ âˆˆ {ğ‘¥, valğœ‡0 }. Define ğ¾1 â‰œ

exist ğœ1 âˆˆ St[ğ¾ğ‘
a function defined by

1 ] and ğœ2 âˆˆ St[ğ‘ (ğ‘£)ğ‘ \ ğ¾ğ‘

â„(ğœ â€²) â‰œ [ğ‘£ â†¦â†’

ğ‘’ â€²[ğœ‡0/ğ‘¦]
(cid:74)

(cid:75)

(ğœ â€² âŠ• ğœ1)].

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:70

Then,

ğ‘”(ğœ) = (cid:2)ğ‘£ â†¦â†’

Wonyeol Lee, Xavier Rival, and Hongseok Yang

(ğœ âŠ• ğœ)(cid:3) = â„(ğœ âŠ• ğœ2)

ğ‘’ â€²[ğœ‡0/ğ‘¦]
(cid:74)

(cid:75)

for all ğœ âˆˆ St[ğ‘ (ğ‘£)]. By Assumption 2, we have â„ âˆˆ ğœ™ğ¾1,{ğ‘£ }, Then, by Assumption 5, we obtain
ğ‘” âˆˆ ğœ™ğ‘ (ğ‘£),{ğ‘£ }.
â€¢ Case ğ‘£ â‰¡ pr ğœ‡0

â™¯. Since ğœ âˆˆ St[ğ‘ (ğ‘£)ğ‘ ]
and ğ‘ (ğ‘£)ğ‘ = (ğ¾ \ fv(ğ‘’)ğ‘ ) âŠ ğ¾ğ‘ , there exist ğœ1 âˆˆ St[ğ¾ \ fv(ğ‘’)ğ‘ ] and ğœ2 âˆˆ St[ğ¾ğ‘ ] such that
ğœ = ğœ1 âŠ• ğœ2. Using ğœ1 and ğœ2, we have

. In this case, ğ‘ (ğ‘£) = fv(ğ‘’)ğ‘ âˆ© ğ¾ for ğ¾ =

pdfN (ğœ‡0; ğ‘’1, ğ‘’2)
(cid:76)

(cid:77)

ğ‘”(ğœ) = (cid:2)ğ‘£ â†¦â†’
= (cid:2)ğ‘£ â†¦â†’

distN (ğ‘’1, ğ‘’2)
(cid:75)
pdfN(ğœ‡0; ğ‘’1, ğ‘’2)

(cid:74)

(ğœ âŠ• ğœ) (cid:0)(ğœ âŠ• ğœ)(ğœ‡0)(cid:1)(cid:3)
(ğœ âŠ• ğœ)(cid:3) = â„(ğœ âŠ• ğœ1)

(cid:74)
for all ğœ âˆˆ St[ğ‘ (ğ‘£)], where â„ : St[ğ¾] â†’ St[{ğ‘£ }] is defined by

(cid:75)

â„(ğœ â€²) = [ğ‘£ â†¦â†’

(ğœ â€² âŠ• ğœ2)].

pdfN (ğœ‡0; ğ‘’1, ğ‘’2)
(cid:74)
ğ‘
(cid:74)

(cid:75)
Here the first equality follows from the definition of
, the second equality holds because pdfN
is the density function of a normal distribution, and the third equality comes from ğœ = ğœ1 âŠ• ğœ2.
By Assumption 2, we have â„ âˆˆ ğœ™ğ¾,{ğ‘£ }. Then, by Assumption 5, we obtain ğ‘” âˆˆ ğœ™ğ‘ (ğ‘£),{ğ‘£ }.

â€¢ Case ğ‘£ â‰¡ cntğœ‡0. The proof is similar to the above case ğ‘£ â‰¡ pr ğœ‡0

. In this case, ğ‘ (ğ‘£) = fv(ğ‘’)ğ‘ âˆ© ğ¾
â™¯. As in the above case, there exist ğœ1 âˆˆ St[ğ¾ \ fv(ğ‘’)ğ‘ ] and ğœ2 âˆˆ St[ğ¾ğ‘ ] such

(cid:75)

for ğ¾ =
cntğœ‡0 + 1
that ğœ = ğœ1 âŠ• ğœ2, and we have

(cid:77)

(cid:76)

ğ‘”(ğœ) = [ğ‘£ â†¦â†’ (ğœ âŠ• ğœ)(cntğœ‡0 ) + 1]

for all ğœ âˆˆ St[ğ‘ (ğ‘£)], where â„ : St[ğ¾] â†’ St[{ğ‘£ }] is defined by

= [ğ‘£ â†¦â†’

cntğœ‡0 + 1
(cid:75)
(cid:74)

(ğœ âŠ• ğœ)] = â„(ğœ âŠ• ğœ1)

â„(ğœ â€²) = [ğ‘£ â†¦â†’

cntğœ‡0 + 1

(ğœ â€² âŠ• ğœ2)].

(cid:74)

(cid:75)

By Assumption 2, we have â„ âˆˆ ğœ™ğ¾,{ğ‘£ }. Then, by Assumption 5, we obtain ğ‘” âˆˆ ğœ™ğ‘ (ğ‘£),{ğ‘£ }.
Case ğ‘ â‰¡ obs(distN(ğ‘’1, ğ‘’2), ğ‘Ÿ ). To prove the conclusion, consider ğ‘£ âˆˆ Var and ğœ âˆˆ St[ğ‘ (ğ‘£)ğ‘ ]. We

should show ğ‘” âˆˆ ğœ™ğ‘ (ğ‘£),{ğ‘£ }, where

ğ‘”(ğœ) = ğœ‹Var,{ğ‘£ } (

We prove this by case analysis on ğ‘£.

(ğœ âŠ• ğœ)) = [ğ‘£ â†¦â†’

ğ‘
(cid:74)

(cid:75)

(ğœ âŠ• ğœ)(ğ‘£)].

ğ‘
(cid:74)

(cid:75)

First, suppose ğ‘£ (cid:46) like. Then, ğ‘ (ğ‘£) = Var and

ğ‘”(ğœ) = [ğ‘£ â†¦â†’

ğ‘
(cid:74)

ğœ (ğ‘£)] = [ğ‘£ â†¦â†’ ğœ (ğ‘£)] = ğœ‹Var,{ğ‘£ } (ğœ)
(cid:75)

for all ğœ âˆˆ St[ğ‘ (ğ‘£)]. Here the first equality is by ğœ âˆˆ St[âˆ…], and the second equality holds since
does not change the value of ğ‘£. Hence, by Assumption 3, ğ‘” = ğœ‹Var,{ğ‘£ } âˆˆ ğœ™Var,{ğ‘£ } = ğœ™ğ‘ (ğ‘£),{ğ‘£ }.

ğ‘
(cid:74)

(cid:75)

Next, suppose ğ‘£ â‰¡ like. Then, ğ‘ (ğ‘£) =

like Ã— pdfN(ğ‘Ÿ ; ğ‘’1, ğ‘’2)
(cid:76)

(cid:77)

â™¯ and

ğ‘”(ğœ) = [ğ‘£ â†¦â†’ (ğœ âŠ• ğœ)(like) Â·

distN (ğ‘’1, ğ‘’2)

(ğœ âŠ• ğœ)(ğ‘Ÿ )]

= [ğ‘£ â†¦â†’

like Ã— pdfN(ğ‘Ÿ ; ğ‘’1; ğ‘’2)

(cid:74)

(cid:74)

(cid:75)
(ğœ âŠ• ğœ)]

(cid:75)

for all ğœ âˆˆ St[ğ‘ (ğ‘£)]. Here the first equality is by the definition of
, and the second equality holds
because pdfN is the density function of a normal distribution. Hence, by Assumption 2, we have
â–¡
ğ‘” âˆˆ ğœ™ğ‘ (ğ‘£),{ğ‘£ }.

ğ‘
(cid:74)

(cid:75)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:71

F.5 Proofs of Lemmas for Theorem F.2
Here are the lemmas used to prove Theorem F.2:

Lemma F.3 (Weakening; Î”). Let ğ‘“ âˆˆ [St â†’ StâŠ¥] and ğ¾, ğ¾ â€², ğ¿, ğ¿â€² âŠ† Var. Then,

|= Î”(ğ‘“ , ğ¾, ğ¿) âˆ§ (ğ¾ âŠ† ğ¾ â€²) âˆ§ (ğ¿ âŠ‡ ğ¿â€²) =â‡’ |= Î”(ğ‘“ , ğ¾ â€², ğ¿â€²).

Proof. Consider ğœ, ğœ â€² âˆˆ St with ğœ âˆ¼ğ¾ â€² ğœ â€². Then, ğœ âˆ¼ğ¾ ğœ â€² because ğ¾ âŠ† ğ¾ â€². Since |= Î”(ğ‘“ , ğ¾, ğ¿),

(ğ‘“ (ğœ) âˆˆ St â‡â‡’ ğ‘“ (ğœ â€²) âˆˆ St) and (ğ‘“ (ğœ) âˆˆ St =â‡’ ğ‘“ (ğœ) âˆ¼ğ¿ ğ‘“ (ğœ â€²)).

Note that the conclusion of the second conjunct implies ğ‘“ (ğœ) âˆ¼ğ¿â€² ğ‘“ (ğœ â€²) since ğ¿â€² âŠ† ğ¿. From what
â–¡
we have just shown, the desired conclusion |= Î”(ğ‘“ , ğ¾ â€², ğ¿â€²) follows.

Lemma F.4 (Weakening; Î¦). Let ğ‘“ âˆˆ [St â†’ StâŠ¥] and ğ¾, ğ¾ â€², ğ¿, ğ¿â€² âŠ† Var. Then,

|= Î¦(ğ‘“ , ğ¾, ğ¿) âˆ§ (ğ¾ âŠ‡ ğ¾ â€²) âˆ§ (ğ¿ âŠ‡ ğ¿â€²) =â‡’ |= Î¦(ğ‘“ , ğ¾ â€², ğ¿â€²).

Proof. We prove the lemma using Assumptions 3, 5 and 6. Consider ğœ âˆˆ St[(ğ¾ â€²)ğ‘ ], and let ğ‘” be

the following partial function:

ğ‘” : St[ğ¾ â€²] â‡€ St[ğ¿â€²],

(cid:40)

ğ‘”(ğœ â€²) â‰œ

(ğœ‹Var,ğ¿â€² â—¦ ğ‘“ )(ğœ â€² âŠ• ğœ)
undefined

if ğ‘“ (ğœ â€² âŠ• ğœ) âˆˆ St
otherwise.

We should showğ‘” âˆˆ ğœ™ğ¾ â€²,ğ¿â€². Note that (ğ¾ â€²)ğ‘ âŠ‡ ğ¾ğ‘ . Thus, there existğœ1 âˆˆ St[(ğ¾ â€²)ğ‘ \ğ¾ğ‘ ] andğœ2 âˆˆ St[ğ¾ğ‘ ]
such that ğœ = ğœ1 âŠ• ğœ2. Define a partial function â„ : St[ğ¾] â†’ St[ğ¿] by
(cid:40)

â„(ğœ â€²â€²) â‰œ

(ğœ‹Var,ğ¿ â—¦ ğ‘“ )(ğœ â€²â€² âŠ• ğœ2)
undefined

if ğ‘“ (ğœ â€²â€² âŠ• ğœ2) âˆˆ St
otherwise.

Then, since |= Î¦(ğ‘“ , ğ¾, ğ¿), we have â„ âˆˆ ğœ™ğ¾,ğ¿. Note that for all ğœ â€² âˆˆ St[ğ¾ â€²],

ğ‘”(ğœ â€²) = (ğœ‹ğ¿,ğ¿â€² â—¦ â„)(ğœ â€² âŠ• ğœ1).

By Assumptions 3, 5 and 6, the above equation implies ğ‘” âˆˆ ğœ™ğ¾ â€²,ğ¿â€², as desired.

â–¡

Lemma F.5 (Merging; Î”). Let ğ‘“ âˆˆ [St â†’ StâŠ¥] and ğ¾, ğ¾ â€², ğ¿, ğ¿â€² âŠ† Var. Then,

|= Î”(ğ‘“ , ğ¾, ğ¿) âˆ§ |= Î”(ğ‘“ , ğ¾ â€², ğ¿â€²) =â‡’ |= Î”(ğ‘“ , ğ¾ âˆª ğ¾ â€², ğ¿ âˆª ğ¿â€²).

Proof. Consider ğœ, ğœ â€² âˆˆ St with ğœ âˆ¼ğ¾âˆªğ¾ â€² ğœ â€². Then, ğœ âˆ¼ğ¾ ğœ â€², and by the assumption that

|= Î”(ğ‘“ , ğ¾, ğ¿), we have

ğ‘“ (ğœ) âˆˆ St â‡â‡’ ğ‘“ (ğœ â€²) âˆˆ St.
It remains to show that if ğ‘“ (ğœ), ğ‘“ (ğœ â€²) âˆˆ St, then ğ‘“ (ğœ) âˆ¼ğ¿âˆªğ¿â€² ğ‘“ (ğœ â€²). Assume ğ‘“ (ğœ), ğ‘“ (ğœ â€²) âˆˆ St. Since
ğœ âˆ¼ğ¾âˆªğ¾ â€² ğœ â€² and we have |= Î”(ğ‘“ , ğ¾, ğ¿) and |= Î”(ğ‘“ , ğ¾ â€², ğ¿â€²) by assumption,

ğ‘“ (ğœ) âˆ¼ğ¿ ğ‘“ (ğœ â€²) and ğ‘“ (ğœ) âˆ¼ğ¿â€² ğ‘“ (ğœ â€²).

This implies that ğ‘“ (ğœ) âˆ¼ğ¿âˆªğ¿â€² ğ‘“ (ğœ â€²), as desired.

â–¡

Lemma F.6 (Merging; Î¦). Let ğ‘“ âˆˆ [St â†’ StâŠ¥] and ğ¾, ğ¾ â€², ğ¿, ğ¿â€² âŠ† Var. Then,

|= Î¦(ğ‘“ , ğ¾, ğ¿) âˆ§ |= Î¦(ğ‘“ , ğ¾ â€², ğ¿â€²) =â‡’ |= Î¦(ğ‘“ , ğ¾ âˆ© ğ¾ â€², ğ¿ âˆª ğ¿â€²).

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:72

Wonyeol Lee, Xavier Rival, and Hongseok Yang

Proof. Uses the weakening lemma for Î¦ (Lemma F.4), we have

|= Î¦(ğ‘“ , ğ¾ âˆ© ğ¾ â€², ğ¿) and |= Î¦(ğ‘“ , ğ¾ âˆ© ğ¾ â€², ğ¿â€²).
This and Assumption 4 then imply the desired conclusion. Concretely, for all ğœ âˆˆ St[(ğ¾ âˆ© ğ¾ â€²)ğ‘ ], if
ğ‘”, ğ‘”1, and ğ‘”2 are the following partial functions

ğ‘” : St[ğ¾ âˆ© ğ¾ â€²] â‡€ St[ğ¿ âˆª ğ¿â€²],

ğ‘”(ğœ â€²) â‰œ

ğ‘”1 : St[ğ¾ âˆ© ğ¾ â€²] â‡€ St[ğ¿],

ğ‘”1(ğœ â€²) â‰œ

ğ‘”2 : St[ğ¾ âˆ© ğ¾ â€²] â‡€ St[ğ¿â€²],

ğ‘”2(ğœ â€²) â‰œ

(cid:40)

(cid:40)

(cid:40)

(ğœ‹Var,ğ¿âˆªğ¿â€² â—¦ ğ‘“ )(ğœ â€² âŠ• ğœ)
undefined

if ğ‘“ (ğœ â€² âŠ• ğœ) âˆˆ St
otherwise,

(ğœ‹Var,ğ¿ â—¦ ğ‘“ )(ğœ â€² âŠ• ğœ)
undefined

if ğ‘“ (ğœ â€² âŠ• ğœ) âˆˆ St
otherwise,

(ğœ‹Var,ğ¿â€² â—¦ ğ‘“ )(ğœ â€² âŠ• ğœ)
undefined

if ğ‘“ (ğœ â€² âŠ• ğœ) âˆˆ St
otherwise,

then ğ‘”1 âˆˆ ğœ™ğ¾âˆ©ğ¾ â€²,ğ¿, ğ‘”2 âˆˆ ğœ™ğ¾âˆ©ğ¾ â€²,ğ¿â€², and ğ‘” = âŸ¨ğ‘”1, ğ‘”2âŸ©, so that by Assumption 4, we have ğ‘” âˆˆ ğœ™ğ¾âˆ©ğ¾ â€²,ğ¿âˆªğ¿â€²
â–¡
as desired.

Lemma F.7 (Seqence). Let ğ‘“ , ğ‘” âˆˆ [St â†’ StâŠ¥] and ğ¾, ğ¿, ğ¿â€², ğ‘€ âŠ† Var. Then,
|= Î¦(ğ‘“ , ğ¾, ğ¿) âˆ§ |= Î¦(ğ‘”, ğ¿, ğ‘€) âˆ§ |= Î”(ğ‘“ , ğ¾ğ‘, ğ¿â€² \ ğ¿) âˆ§ |= Î”(ğ‘”, ğ¿â€², ğ‘€) =â‡’ |= Î¦(seq(ğ‘“ , ğ‘”), ğ¾, ğ‘€).
Proof. Consider ğ‘“ , ğ‘” âˆˆ [St â†’ StâŠ¥] and ğ¾, ğ¿, ğ¿â€², ğ‘€ âŠ† Var that satisfy the given conditions:

|= Î¦(ğ‘“ , ğ¾, ğ¿),

|= Î”(ğ‘”, ğ¿â€², ğ‘€).
To prove the conclusion, pick an arbitrary ğœ âˆˆ St[ğ¾ğ‘ ]. We have to show â„ âˆˆ ğœ™ğ¾,ğ‘€ , where

|= Î¦(ğ‘”, ğ¿, ğ‘€),

|= Î”(ğ‘“ , ğ¾ğ‘, ğ¿â€² \ ğ¿),

and

â„(ğœ) =

(cid:40)ğœ‹Var,ğ‘€ ((ğ‘”â€  â—¦ ğ‘“ )(ğœ âŠ• ğœ))
undefined

if (ğ‘”â€  â—¦ ğ‘“ )(ğœ âŠ• ğœ) âˆˆ St
otherwise.

Observe that since |= Î¦(ğ‘“ , ğ¾, ğ¿) and |= Î¦(ğ‘”, ğ¿, ğ‘€), we have â„1 âˆˆ ğœ™ğ¾,ğ¿ and â„2 âˆˆ ğœ™ğ¿,ğ‘€ for any
ğœ1 âˆˆ St[ğ¾ğ‘ ] and ğœ2 âˆˆ St[ğ¿ğ‘ ], where â„1 and â„2 are parameterised by ğœ1 and ğœ2, and defined by

â„1 : St[ğ¾] â‡€ St[ğ¿],

â„1(ğœ) â‰œ

â„2 : St[ğ¿] â‡€ St[ğ‘€],

â„2(ğœ) â‰œ

(cid:40)ğœ‹Var,ğ¿ (ğ‘“ (ğœ âŠ• ğœ1))
undefined
(cid:40)ğœ‹Var,ğ‘€ (ğ‘”(ğœ âŠ• ğœ2))
undefined

if ğ‘“ (ğœ âŠ• ğœ1) âˆˆ St
otherwise,

if ğ‘”(ğœ âŠ• ğœ2) âˆˆ St
otherwise.

Given these, it suffices to show the claim that â„ = â„2 â—¦ â„1 for some ğœ1 and ğœ2: if the claim holds, then
we have â„ = â„2 â—¦ â„1 âˆˆ ğœ™ğ¾,ğ‘€ by Assumption 6, since â„1 âˆˆ ğœ™ğ¾,ğ¿ and â„2 âˆˆ ğœ™ğ¿,ğ‘€ . We prove the claim by
case analysis on ğ‘“ (âˆ’ âŠ• ğœ).

Case ğ‘“ (ğœ âŠ• ğœ) âˆ‰ St for all ğœ âˆˆ St[ğ¾]. In this case, we set ğœ1 â‰œ ğœ and pick any ğœ2 âˆˆ St[ğ¿ğ‘ ]. Then,
for all ğœ âˆˆ St[ğ¾], â„(ğœ) and (â„2 â—¦ â„1)(ğœ) are both undefined, as desired. Note that the latter term is
undefined since â„1(ğœ) is undefined.

Case ğ‘“ (ğœ â€² âŠ• ğœ) âˆˆ St for some ğœ â€² âˆˆ St[ğ¾]. In this case, we set ğœ1 â‰œ ğœ and ğœ2 â‰œ ğœ‹Var,ğ¿ğ‘ (ğ‘“ (ğœ â€² âŠ• ğœ)).
To show â„ = â„2 â—¦ â„1, consider any ğœ âˆˆ St[ğ¾]. If ğ‘“ (ğœ âŠ• ğœ) âˆ‰ St, then by the same argument for the
above case, â„(ğœ) and (â„2 â—¦ â„1)(ğœ) are both undefined. So, assume that ğ‘“ (ğœ âŠ• ğœ) âˆˆ St. Then,

â„(ğœ) =

(cid:40)ğœ‹Var,ğ‘€ (ğ‘”(ğœ1))
undefined

if ğ‘”(ğœ1) âˆˆ St
otherwise,

(â„2 â—¦ â„1)(ğœ) =

(cid:40)ğœ‹Var,ğ‘€ (ğ‘”(ğœ2))
undefined

if ğ‘”(ğœ2) âˆˆ St
otherwise,

(28)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:73

where

ğœ1 = ğ‘“ (ğœ âŠ• ğœ) âˆˆ St,

ğœ2 = ğœ‹Var,ğ¿ (ğ‘“ (ğœ âŠ• ğœ)) âŠ• ğœ‹Var,ğ¿ğ‘ (ğ‘“ (ğœ â€² âŠ• ğœ)) âˆˆ St.

Our goal is to show that â„(ğœ) and (â„2 â—¦ â„1)(ğœ) are both undefined, or they are both defined and
are the same. By |= Î”(ğ‘”, ğ¿â€², ğ‘€) and Eq. (28), it suffices to show ğœ1 âˆ¼ğ¿â€² ğœ2. To prove this, we show
a stronger statement: ğœ1 âˆ¼ğ¿ ğœ2 and ğœ1 âˆ¼ğ¿â€²\ğ¿ ğœ2. The former relation holds since ğœ‹Var,ğ¿ (ğœ1) =
ğœ‹Var,ğ¿ (ğ‘“ (ğœ âŠ• ğœ)) = ğœ‹Var,ğ¿ (ğœ2). The latter relation is equivalent to ğ‘“ (ğœ âŠ• ğœ) âˆ¼ğ¿â€²\ğ¿ ğ‘“ (ğœ â€² âŠ• ğœ), and this
holds by |= Î”(ğ‘“ , ğ¾ğ‘, ğ¿â€² \ ğ¿) and ğœ âŠ• ğœ âˆ¼ğ¾ğ‘ ğœ â€² âŠ• ğœ. Hence, â„ = â„2 â—¦ â„1 as desired.
â–¡

Lemma F.8 (Conditional). Let ğ‘“ , ğ‘“ â€² âˆˆ [St â†’ StâŠ¥] and ğ¾, ğ¿ âŠ† Var. Then, for any boolean expres-

sion ğ‘,

|= Î¦(ğ‘“ , ğ¾, ğ¿) âˆ§ |= Î¦(ğ‘“ â€², ğ¾, ğ¿) âˆ§ (ğ¾ğ‘ âŠ‡ fv(ğ‘)) =â‡’ |= Î¦(cond (

ğ‘
(cid:74)

, ğ‘“ , ğ‘“ â€²), ğ¾, ğ¿).
(cid:75)

Proof. Let ğ‘“ , ğ‘“ â€², ğ¾, ğ¿, and ğ‘ be the functions, sets and a boolean expression such that

|= Î¦(ğ‘“ , ğ¾, ğ¿),

|= Î¦(ğ‘“ â€², ğ¾, ğ¿),

and ğ¾ğ‘ âŠ‡ fv(ğ‘).

Consider ğœ âˆˆ St[ğ¾ğ‘ ]. Define ğ‘“ â€²â€² â‰œ cond (

ğ‘
(cid:74)

, ğ‘“ , ğ‘“ â€²), and also partial functions ğ‘”, ğ‘”â€², and ğ‘”â€²â€² as follows:
(cid:75)

ğ‘” : St[ğ¾] â‡€ St[ğ¿],

ğ‘”(ğœ) â‰œ

ğ‘”â€² : St[ğ¾] â‡€ St[ğ¿],

ğ‘”â€²(ğœ) â‰œ

ğ‘”â€²â€² : St[ğ¾] â‡€ St[ğ¿],

ğ‘”â€²â€²(ğœ) â‰œ

(cid:40)

(ğœ‹Var,ğ¿ â—¦ ğ‘“ )(ğœ âŠ• ğœ)
undefined

if ğ‘“ (ğœ âŠ• ğœ) âˆˆ St
otherwise,

(cid:40)

(cid:40)

(ğœ‹Var,ğ¿ â—¦ ğ‘“ â€²)(ğœ âŠ• ğœ)
undefined

if ğ‘“ â€²(ğœ âŠ• ğœ) âˆˆ St
otherwise,

(ğœ‹Var,ğ¿ â—¦ ğ‘“ )(ğœ âŠ• ğœ)
undefined

if ğ‘“ (ğœ âŠ• ğœ) âˆˆ St
otherwise,

We should show ğ‘”â€²â€² âˆˆ ğœ™ğ¾,ğ¿. Since ğ¾ğ‘ âŠ‡ fv(ğ‘), either
ğ‘
(cid:74)
both ğ‘” and ğ‘”â€² are in ğœ™ğ¾,ğ¿, we have the desired ğ‘”â€²â€² âˆˆ ğœ™ğ¾,ğ¿ in both cases.

(ğœ âŠ• ğœ) = true for all ğœ âˆˆ St[ğ¾] or
(ğœ âŠ• ğœ) = false for all ğœ âˆˆ St[ğ¾]. In the former case, ğ‘”â€²â€² = ğ‘”, and in the latter case, ğ‘”â€²â€² = ğ‘”â€². Since
â–¡

ğ‘
(cid:74)

(cid:75)

(cid:75)

Lemma F.9 (Loop; base). Let ğ¾, ğ¿ âŠ† Var. Then,

|= Î¦((ğœ†ğœ âˆˆ St. âŠ¥), ğ¾, ğ¿).

Proof. Consider ğœ âˆˆ St[ğ¾ğ‘ ]. Define a partial function ğ‘” : St[ğ¾] â‡€ St[ğ¿] by

ğ‘”(ğœ) â‰œ

(cid:40)

(ğœ‹Var,ğ¿ â—¦ (ğœ†ğœ âˆˆ St.âŠ¥))(ğœ)
undefined
= undefined.

if (ğœ†ğœ âˆˆ St.âŠ¥)(ğœ) âˆˆ St
otherwise

Then, ğ‘” âˆˆ ğœ™ğ¾,ğ¿ by Assumption 7.

â–¡

Lemma F.10 (Loop; limit). Let ğ¾, ğ¿ âŠ† Var and {ğ‘“ğ‘› âˆˆ [St â†’ StâŠ¥]}ğ‘› âˆˆN be an ğœ”-chain (i.e., ğ‘“ğ‘› âŠ‘ ğ‘“ğ‘›+1
for all ğ‘› âˆˆ N). Here we write ğ‘“ âŠ‘ ğ‘” if ğ‘“ (ğœ) âŠ‘ ğ‘”(ğœ) for all ğœ âˆˆ St. Suppose that for any ğœ âˆˆ St[ğ¾ğ‘ ] and
ğ‘› âˆˆ N, the set {ğœ âˆˆ St[ğ¾] | ğ‘“ğ‘› (ğœ âŠ• ğœ) âˆˆ St} is either âˆ… or St[ğ¾]. Then,

(cid:219)

ğ‘› âˆˆN

|= Î¦(ğ‘“ğ‘›, ğ¾, ğ¿) =â‡’ |= Î¦(

(cid:196)

ğ‘“ğ‘›, ğ¾, ğ¿).

ğ‘› âˆˆN

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:74

Wonyeol Lee, Xavier Rival, and Hongseok Yang

Proof. Consider an ğœ”-chain {ğ‘“ğ‘› âˆˆ [St â†’ StâŠ¥]}ğ‘› âˆˆN such that

|= Î¦(ğ‘“ğ‘›, ğ¾, ğ¿) for all ğ‘›. Pick an
arbitrary ğœ âˆˆ St[ğ¾ğ‘ ]. Let ğ‘“âˆ â‰œ (cid:195)ğ‘› âˆˆN ğ‘“ğ‘›, and define partial functions ğ‘”âˆ and ğ‘”ğ‘› for all ğ‘› as follows:
(cid:40)

ğ‘”âˆ : St[ğ¾] â‡€ St[ğ¿],

ğ‘”âˆ(ğœ) â‰œ

(ğœ‹Var,ğ¿ â—¦ ğ‘“âˆ)(ğœ âŠ• ğœ)
undefined

if ğ‘“âˆ (ğœ âŠ• ğœ) âˆˆ St
otherwise,

ğ‘”ğ‘› : St[ğ¾] â‡€ St[ğ¿],

ğ‘”ğ‘› (ğœ) â‰œ

(cid:40)

(ğœ‹Var,ğ¿ â—¦ ğ‘“ğ‘›)(ğœ âŠ• ğœ)
undefined

if ğ‘“ğ‘› (ğœ âŠ• ğœ) âˆˆ St
otherwise.

Then, {ğ‘”ğ‘› }ğ‘› âˆˆN is an ğœ”-chain when we order ğ‘”ğ‘›â€™s by graph inclusion, and ğ‘”âˆ is the least upper bound
of this chain for the same order. We will show that ğ‘”âˆ = ğ‘”ğ‘› for some ğ‘› âˆˆ N by case analysis on
Î£ğ‘› â‰œ {ğœ âˆˆ St[ğ¾] | ğ‘“ğ‘› (ğœ âŠ• ğœ) âˆˆ St}. Note that this implies the desired ğ‘”âˆ âˆˆ ğœ™ğ¾,ğ¿ because ğ‘”ğ‘› âˆˆ ğœ™ğ¾,ğ¿
for all ğ‘› âˆˆ N. If Î£ğ‘› = âˆ… for all ğ‘› âˆˆ N, then ğ‘” = ğ‘”ğ‘› for any ğ‘›, since both ğ‘” and ğ‘”ğ‘› are the same empty
partial function. Otherwise, by the assumption of the lemma, Î£ğ‘› = St[ğ¾] for some ğ‘›. This means
that ğ‘”ğ‘› is the total function, and so ğ‘”ğ‘› = ğ‘”ğ‘š for all ğ‘š â‰¥ ğ‘›, which implies that ğ‘” = ğ‘”ğ‘›, as desired. â–¡

G DEFERRED RESULTS IN Â§5.3

G.1 Proof of Theorem 5.9

Proof of Theorem 5.9. We go through the assumptions, and show that they are satisfied by ğœ™ (ğ‘‘)

and ğœ™ (ğ‘™) .

Case of Assumption 3. Let ğ¾, ğ¿ âŠ† Var such that ğ¿ âŠ† ğ¾. The projection ğœ‹ğ¾,ğ¿ is total and has
an open set as its domain. Furthermore, the projection ğœ‹ğ¾,ğ¿ is differentiable and 1-Lipschitz contin-
uous. Since Lipschitz continuity implies local Lipschitz continuity, we have both ğœ‹ğ¾,ğ¿ âˆˆ ğœ™ (ğ‘‘)
ğ¾,ğ¿ and
ğœ‹ğ¾,ğ¿ âˆˆ ğœ™ (ğ‘™)

ğ¾,ğ¿, as desired.

Case of Assumption 4. Let ğ¾, ğ¿0, ğ¿1 âŠ† Var such that ğ¿0 âˆ© ğ¿1 = âˆ…. Consider ğ‘“0, ğ‘”0 âˆˆ [St[ğ¾] â‡€

St[ğ¿0]] and ğ‘“1, ğ‘”1 âˆˆ [St[ğ¾] â‡€ St[ğ¿1]] such that all of the following hold:

ğ‘“0 âˆˆ ğœ™ (ğ‘‘)
ğ¾,ğ¿0

,

ğ‘“1 âˆˆ ğœ™ (ğ‘‘)
ğ¾,ğ¿1

,

ğ‘”0 âˆˆ ğœ™ (ğ‘™)
ğ¾,ğ¿0

,

and

ğ‘”1 âˆˆ ğœ™ (ğ‘™)
ğ¾,ğ¿1

.

Let

ğ¿ â‰œ ğ¿0 âˆª ğ¿1;

ğ‘“ : St[ğ¾] â‡€ St[ğ¿],

ğ‘“ (ğœ) â‰œ

ğ‘” : St[ğ¾] â‡€ St[ğ¿],

ğ‘”(ğœ) â‰œ

(cid:40)ğ‘“0(ğœ) âŠ• ğ‘“1(ğœ)
undefined
(cid:40)ğ‘”0(ğœ) âŠ• ğ‘”1(ğœ)
undefined

if ğœ âˆˆ dom(ğ‘“0) âˆ© dom(ğ‘“1),
otherwise;

if ğœ âˆˆ dom(ğ‘”0) âˆ© dom(ğ‘”1),
otherwise.

We should show that ğ‘“ and ğ‘” satisfy ğœ™ (ğ‘‘)
are the intersections of two open sets, so that they are open as required.

ğ¾,ğ¿ and ğœ™ (ğ‘™)

ğ¾,ğ¿, respectively. In both cases, dom(ğ‘“ ) and dom(ğ‘”)

To prove the differentiability of ğ‘“ , consider ğœ âˆˆ dom(ğ‘“ ). Let â„0 and â„1 be the linear functions in
[St[ğ¾] â‡€ St[ğ¿0]] and [St[ğ¾] â‡€ St[ğ¿1]], respectively, such that their domains are open and contain
0, and for all ğ‘– âˆˆ {0, 1},

lim
ğœâ€²â†’0

âˆ¥ ğ‘“ğ‘– (ğœ + ğœ â€²) âˆ’ ğ‘“ğ‘– (ğœ) âˆ’ â„ğ‘– (ğœ â€²)âˆ¥2
âˆ¥ğœ â€²âˆ¥2

= 0.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

= lim
ğœâ€²â†’0

= lim
ğœâ€²â†’0
âˆšï¸„(cid:18)

=

Smoothness Analysis and Selective Reparameterisation

0:75

Let â„ be the linear function in [St[ğ¾] â‡€ St[ğ¿]] defined by

â„(ğœ) â‰œ

(cid:40)â„0(ğœ) âŠ• â„1(ğœ)
undefined

if ğœ âˆˆ dom(â„0) âˆ© dom(â„1);
otherwise.

Then, dom(â„) is open and contains ğœ. Furthermore,

lim
ğœâ€²â†’0

âˆ¥ğ‘“ (ğœ + ğœ â€²) âˆ’ ğ‘“ (ğœ) âˆ’ â„(ğœ â€²)âˆ¥2
âˆ¥ğœ â€²âˆ¥2

âˆšï¸ƒ

âˆ¥ ğ‘“0(ğœ + ğœ â€²) âˆ’ ğ‘“0(ğœ) âˆ’ â„0(ğœ â€²)âˆ¥2

2 + âˆ¥ ğ‘“1(ğœ + ğœ â€²) âˆ’ ğ‘“1(ğœ) âˆ’ â„1(ğœ â€²)âˆ¥2
2
âˆ¥ğœ â€²âˆ¥2
âˆšï¸„(cid:18) âˆ¥ğ‘“0(ğœ + ğœ â€²) âˆ’ ğ‘“0(ğœ) âˆ’ â„0(ğœ â€²)âˆ¥2
(cid:19) 2
âˆ¥ğœ â€²âˆ¥2

(cid:18) âˆ¥ğ‘“1(ğœ + ğœ â€²) âˆ’ ğ‘“1(ğœ) âˆ’ â„1(ğœ â€²)âˆ¥2
âˆ¥ğœ â€²âˆ¥2

+

(cid:19) 2

âˆ¥ğ‘“0(ğœ + ğœ â€²) âˆ’ ğ‘“0(ğœ) âˆ’ â„0(ğœ â€²)âˆ¥2
âˆ¥ğœ â€²âˆ¥2

(cid:19) 2

(cid:18)

+

lim
ğœâ€²â†’0

âˆ¥ğ‘“1(ğœ + ğœ â€²) âˆ’ ğ‘“1(ğœ) âˆ’ â„1(ğœ â€²)âˆ¥2
âˆ¥ğœ â€²âˆ¥2

(cid:19) 2

lim
ğœâ€²â†’0

= 0.

Thus, ğ‘“ is differentiable at ğœ, as desired.

It remains to prove the local Lipschitzness of ğ‘”. Pick ğœ âˆˆ dom(ğ‘”). Then, ğ‘”0 and ğ‘”1 are defined at
ğœ and they are locally Lipschitz. Thus, there exist open sets ğ‘‚0 âŠ† dom(ğ‘”0) and ğ‘‚1 âŠ† dom(ğ‘”1) and
constants ğµ0, ğµ1 > 0 such that ğœ belongs to both ğ‘‚0 and ğ‘‚1, and for all ğœ0, ğœ â€²
1 âˆˆ ğ‘‚1,

0 âˆˆ ğ‘‚0 and ğœ1, ğœ â€²

âˆ¥ğ‘”0 (ğœ0) âˆ’ ğ‘”0(ğœ â€²

0âˆ¥2
Let ğ‘‚ â‰œ ğ‘‚0 âˆ© ğ‘‚1. The set ğ‘‚ is open, and contains ğœ. Furthermore, for all ğœ â€², ğœ â€²â€² âˆˆ ğ‘‚,

0)âˆ¥2 â‰¤ ğµ0âˆ¥ğœ0 âˆ’ ğœ â€²

âˆ¥ğ‘”1(ğœ1) âˆ’ ğ‘”1(ğœ â€²

1)âˆ¥2 â‰¤ ğµ1âˆ¥ğœ1 âˆ’ ğœ â€²

and

1âˆ¥2.

âˆ¥ğ‘”(ğœ â€²) âˆ’ ğ‘”(ğœ â€²â€²)âˆ¥2 =

âˆšï¸ƒ

âˆ¥ğ‘”0(ğœ â€²) âˆ’ ğ‘”0(ğœ â€²â€²)âˆ¥2

2 + âˆ¥ğ‘”1(ğœ â€²) âˆ’ ğ‘”1(ğœ â€²â€²)âˆ¥2
2

â‰¤

=

Thus, ğ‘” is Lipschitz in ğ‘‚, as desired.

âˆšï¸ƒ

0 âˆ¥ğœ â€² âˆ’ ğœ â€²â€²âˆ¥2
ğµ2

2 + ğµ2

1 âˆ¥ğœ â€² âˆ’ ğœ â€²â€²âˆ¥2

2

âˆšï¸ƒ

ğµ2
0 + ğµ2

1 Â· âˆ¥ğœ â€² âˆ’ ğœ â€²â€²âˆ¥2.

Case of Assumption 5. Consider ğ¾, ğ¾ â€², ğ¿ âŠ† Var with ğ¾ âŠ† ğ¾ â€², and ğœ âˆˆ St[ğ¾ â€² \ ğ¾]. Let ğ‘“ and ğ‘”

be partial functions in [St[ğ¾ â€²] â‡€ St[ğ¿]] such that ğ‘“ âˆˆ ğœ™ (ğ‘‘)

ğ¾ â€²,ğ¿ and ğ‘” âˆˆ ğœ™ (ğ‘™)

ğ¾ â€²,ğ¿. Let

ğ‘“1 : St[ğ¾] â‡€ St[ğ¿],

ğ‘“1(ğœ) â‰œ

ğ‘”1 : St[ğ¾] â‡€ St[ğ¿],

ğ‘”1(ğœ) â‰œ

if ğœ âŠ• ğœ âˆˆ dom(ğ‘“ )

(cid:40)ğ‘“ (ğœ âŠ• ğœ)
undefined otherwise,
(cid:40)ğ‘”(ğœ âŠ• ğœ)
undefined otherwise.

if ğœ âŠ• ğœ âˆˆ dom(ğ‘”)

We should show that ğ‘“1 and ğ‘”1 satisfy ğœ™ (ğ‘‘)

ğ¾,ğ¿ and ğœ™ (ğ‘™)

dom(ğ‘“1) = {ğœ | ğœ âŠ• ğœ âˆˆ dom(ğ‘“ )}

ğ¾,ğ¿, respectively. Note that
and dom(ğ‘”1) = {ğœ | ğœ âŠ• ğœ âˆˆ dom(ğ‘”)}.

These two sets are open since dom(ğ‘“ ) and dom(ğ‘”) are open and for any open ğ‘‚, the slice {ğœ âˆˆ St[ğ¾] |
ğœ âŠ• ğœ âˆˆ ğ‘‚ } is open. Let ğœ0 âˆˆ dom(ğ‘“1) and ğœ1 âˆˆ dom(ğ‘”1). We will show that ğ‘“1 is differentiable at ğœ0,
and ğ‘”1 is Lipschitz in an open neighbourhood of ğœ1.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:76

Wonyeol Lee, Xavier Rival, and Hongseok Yang

Since ğ‘“ is differentiable and ğœ0 âŠ• ğœ âˆˆ dom(ğ‘“ ), there exists a linear map â„ : St[ğ¾ â€²] â‡€ St[ğ¿] such

that dom(â„) is open and contains 0, and

lim
ğœâ€²â†’0

âˆ¥ğ‘“ (ğœ0 âŠ• ğœ + ğœ â€²) âˆ’ ğ‘“ (ğœ0 âŠ• ğœ) âˆ’ â„(ğœ â€²)âˆ¥2
âˆ¥ğœ â€²âˆ¥2

= 0.

Let ğœ0 â‰œ ğœ†ğ‘£ âˆˆ ğ¾ â€² \ ğ¾ . 0, and â„1 be the partial function from St[ğ¾] to St[ğ¿] defined by
(cid:40)â„(ğœ âŠ• ğœ0)
undefined otherwise.

if ğœ âŠ• ğœ0 âˆˆ dom(â„),

â„1(ğœ) â‰œ

Then, â„1 is linear, its domain is open (since taking a slice of an open set in St[ğ¾] (cid:27) R|ğ¾ â€² | by fixing
some coordinate variables gives an open set), and

lim
ğœâ€²â€²â†’0

âˆ¥ğ‘“1(ğœ0 + ğœ â€²â€²) âˆ’ ğ‘“1(ğœ0) âˆ’ â„1(ğœ â€²â€²)âˆ¥2
âˆ¥ğœ â€²â€²âˆ¥2

= lim
ğœâ€²â€²â†’0

= 0.

This means that ğ‘“1 is differentiable at ğœ0.

âˆ¥ğ‘“ (ğœ0 âŠ• ğœ + ğœ â€²â€² âŠ• ğœ0) âˆ’ ğ‘“ (ğœ0 âŠ• ğœ) âˆ’ â„(ğœ â€²â€² âŠ• ğœ0)âˆ¥2
âˆ¥ğœ â€²â€² âŠ• ğœ0âˆ¥2

Since ğ‘” is locally Lipschitz and ğœ1 âŠ• ğœ âˆˆ dom(ğ‘”), there exists an open subset ğ‘‚ of dom(ğ‘”) such

that ğ‘‚ contains ğœ1 âŠ• ğœ and ğ‘” is Lipschitz in ğ‘‚, that is, there exists a real number ğµ > 0 such that

for all ğœ, ğœ â€² âˆˆ ğ‘‚. Let

âˆ¥ğ‘”(ğœ) âˆ’ ğ‘”(ğœ â€²)âˆ¥2 â‰¤ ğµ Â· âˆ¥ğœ âˆ’ ğœ â€²âˆ¥2

ğ‘‚ â€² â‰œ {ğœ âˆˆ St[ğ¾] | ğœ âŠ• ğœ âˆˆ ğ‘‚ }.

Then, ğ‘‚ â€² is open, and it contains ğœ1. Furthermore, for all ğœ, ğœ â€² âˆˆ ğ‘‚ â€²,

âˆ¥ğ‘”1(ğœ) âˆ’ ğ‘”1(ğœ â€²)âˆ¥2 = âˆ¥ğ‘”(ğœ âŠ• ğœ) âˆ’ ğ‘”(ğœ â€² âŠ• ğœ)âˆ¥2 â‰¤ ğµ Â· âˆ¥ğœ âŠ• ğœ âˆ’ ğœ â€² âŠ• ğœ âˆ¥2 = ğµ Â· âˆ¥ğœ âˆ’ ğœ â€²âˆ¥2.

Thus, ğ‘”1 is Lipschitz in ğ‘‚ â€², as desired.

Case of Assumption 6. For the composition condition, we handle the differentiability case only.

The other case can be proved similarly. Consider

ğ¾, ğ¿, ğ‘€ âŠ† Var,

ğ‘“ âˆˆ [St[ğ¾] â‡€ St[ğ¿]],

and ğ‘” âˆˆ [St[ğ¿] â‡€ St[ğ‘€]].

Assume that ğ‘“ âˆˆ ğœ™ (ğ‘‘)
We should show that â„ âˆˆ ğœ™ (ğ‘‘)
Note that

ğ¾,ğ¿ and ğ‘” âˆˆ ğœ™ (ğ‘‘)

ğ¿,ğ‘€ . Let â„ be the standard composition of partial functions ğ‘” and ğ‘“ .
ğ¾,ğ‘€ as well, that is, dom(â„) is open and â„ is differentiable on its domain.

dom(â„) = dom(ğ‘“ ) âˆ© ğ‘“ âˆ’1(dom(ğ‘”)).

ğ¿,ğ‘€ , the set dom(ğ‘”) is open. Because ğ‘“ âˆˆ ğœ™ (ğ‘‘)

Since ğ‘” âˆˆ ğœ™ (ğ‘‘)
ğ¾,ğ¿, dom(ğ‘“ ) is open and ğ‘“ is continuous on its
domain. The latter implies that ğ‘“ âˆ’1(dom(ğ‘”)) is open as well. Thus, the intersection of dom(ğ‘“ ) and
ğ‘“ âˆ’1(dom(ğ‘”)) is open as desired. The differentiability of â„ on its domain holds since the restriction of
ğ‘“ to dom(â„) gives a differentiable total function from dom(â„) to dom(ğ‘”), that of ğ‘” to dom(ğ‘”) is also
a differentiable total function, and the composition of two differentiable functions is differentiable.

Case of Assumption 7. The empty set is open, and the empty function is jointly differentiable and
locally Lipschitz continuous. Thus, the strictness assumption holds for both predicate families. â–¡

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:77

H DEFERRED RESULTS IN Â§6

H.1 Proof of Theorem 6.2

Proof of Theorem 6.2. Suppose that the algorithm returns ğœ‹ (without an error message). We

should show the conclusion that ğœ‹ is simple and satisfies (R2) and (R3).
We make several observations before proving the conclusion. Let

(pğ‘š, dğ‘š, Vğ‘š) â‰œ

â™¯,

(pğ‘”, dğ‘”, Vğ‘”) â‰œ

â™¯,

(pğ‘”, dğ‘”, Vğ‘”) â‰œ

ğ‘ğ‘š
(cid:74)

(cid:75)

ğ‘ğ‘”
(cid:74)

(cid:75)

ğ‘ğ‘”
(cid:74)

ğœ‹

â™¯,

(cid:75)

and ğ¾ âŠ† Var be the set defined in Eq. (13). Also, let ğ‘†ğ‘Ÿ be the set of names that the algorithm uses to
construct the returned reparameterisation plan ğœ‹. Then, by the algorithm, we have the two inclusions
in Eq. (13) and Eq. (14), and also ğœ‹ = ğœ‹0 [ğ‘†ğ‘Ÿ ]. In addition, ğ‘†ğ‘Ÿ âŠ† ğ¾ since

ğ‘†ğ‘Ÿ âŠ† {(ğ›¼, ğ‘–) âˆˆ Name | for all ğ‘– â€² âˆˆ N, (ğ›¼, ğ‘– â€²) âˆˆ Name =â‡’ (ğ›¼, ğ‘– â€²) âˆˆ ğ¾ } âŠ† ğ¾ .

We now prove the conclusion in three parts.

First part: We show that ğœ‹ is simple. To show this, consider (ğ‘›, ğ‘‘, ğ‘™), (ğ‘›â€², ğ‘‘ â€², ğ‘™ â€²) âˆˆ NameEx Ã—
DistExÃ—LamEx such thatğ‘› = name(ğ›¼, ğ‘’) andğ‘›â€² = name(ğ›¼, ğ‘’ â€²) for some ğ›¼ âˆˆ Str,ğ‘’, andğ‘’ â€². Suppose that
(ğ‘›, ğ‘‘, ğ‘™) âˆˆ dom(ğœ‹). We should show (ğ‘›â€², ğ‘‘ â€², ğ‘™ â€²) âˆˆ dom(ğœ‹). Since (ğ‘›, ğ‘‘, ğ‘™) âˆˆ dom(ğœ‹) = dom(ğœ‹0 [ğ‘†ğ‘Ÿ ]),
we have (ğ‘›, ğ‘‘, ğ‘™) âˆˆ dom(ğœ‹0) and (ğ›¼, _) âˆˆ ğ‘†ğ‘Ÿ . This implies that (ğ‘›â€², ğ‘‘ â€², ğ‘™ â€²) âˆˆ dom(ğœ‹0) because ğœ‹0 is
simple. Since ğ‘›â€² = name(ğ›¼, _) and (ğ›¼, _) âˆˆ ğ‘†ğ‘Ÿ , we have (ğ‘›â€², ğ‘‘ â€², ğ‘™ â€²) âˆˆ dom(ğœ‹) as desired.

Second part: We show that ğœ‹ satisfies (R2) in three steps.
First step: We prove ğœƒ âˆª rv(ğœ‹) âŠ† ğ¾. To do so, observe that the ğ‘† in the algorithm always satisfies

the following property:

(ğ›¼, ğ‘–) âˆˆ ğ‘† =â‡’ (ğ›¼, ğ‘– â€²) âˆˆ ğ‘†

for any (ğ›¼, ğ‘–), (ğ›¼, ğ‘– â€²) âˆˆ Name.

(29)

We can prove this by induction: the initial ğ‘† (i.e., ğ‘† = {(ğ›¼, ğ‘–) âˆˆ Name | for all ğ‘– â€² âˆˆ N, (ğ›¼, ğ‘– â€²) âˆˆ
Name =â‡’ (ğ›¼, ğ‘– â€²) âˆˆ ğ¾ }) satisfies the property, and each update of ğ‘† (i.e., ğ‘† â† ğ‘† \ {(ğ›¼, ğ‘–) âˆˆ Name}
for some (ğ›¼, _) âˆˆ ğ‘†) preserves the property. From this, we obtain rv(ğœ‹) = rv(ğœ‹0) âˆ© ğ‘†:

rv(ğœ‹) = rv(ğœ‹0 [ğ‘†])

= {(ğ›¼, ğ‘–) âˆˆ Name | âˆƒğ‘’, ğ‘‘, ğ‘™ . (name(ğ›¼, ğ‘’), ğ‘‘, ğ‘™) âˆˆ dom(ğœ‹0 [ğ‘†])}
= (cid:8)(ğ›¼, ğ‘–) âˆˆ Name | âˆƒğ‘’, ğ‘‘, ğ‘™ . (cid:0)(name(ğ›¼, ğ‘’), ğ‘‘, ğ‘™) âˆˆ dom(ğœ‹0) âˆ§ âˆƒğ‘– â€². (ğ›¼, ğ‘– â€²) âˆˆ ğ‘† (cid:1)(cid:9)
= (cid:8)(ğ›¼, ğ‘–) âˆˆ Name | (cid:0)âˆƒğ‘’, ğ‘‘, ğ‘™ . (cid:0)(name(ğ›¼, ğ‘’), ğ‘‘, ğ‘™) âˆˆ dom(ğœ‹0)(cid:1) âˆ§ (cid:0)âˆƒğ‘– â€². (ğ›¼, ğ‘– â€²) âˆˆ ğ‘† (cid:1) (cid:9)
= {(ğ›¼, ğ‘–) âˆˆ Name | (name(ğ›¼, _), _, _) âˆˆ dom(ğœ‹0)} âˆ© {(ğ›¼, ğ‘–) âˆˆ Name | (ğ›¼, _) âˆˆ ğ‘† }
= rv(ğœ‹0) âˆ© ğ‘†,

where the second and third equalities use the definitions of rv(âˆ’) and ğœ‹0 [ğ‘†], respectively, and the
last equality uses Eq. (29). Since rv(ğœ‹) âŠ† ğ‘† âŠ† ğ¾ and ğœƒ âŠ† ğ¾ by Eq. (13) (the inclusion of ğœƒ ), we get
ğœƒ âˆª rv(ğœ‹) âŠ† ğ¾ as desired.

Second step: We prove that for all ğ‘¢ âˆˆ {like} âˆª {pr ğœ‡ | ğœ‡ âˆˆ Name} and ğ‘£ âˆˆ {pr ğœ‡ | ğœ‡ âˆˆ Name}, the
following functions (which are total since ğ‘ğ‘š and ğ‘ğ‘” always terminate) are differentiable with respect
to the variables in ğœƒ âˆª rv(ğœ‹) jointly:

(ğœğœƒ, ğœğ‘›) âˆˆ St[ğœƒ ] Ã— St[Name] â†¦âˆ’â†’
(ğœğœƒ, ğœğ‘›) âˆˆ St[ğœƒ ] Ã— St[Name] â†¦âˆ’â†’

ğ‘ğ‘š
(cid:74)
ğ‘ğ‘”
(cid:74)
where ğœğ‘\ğœƒ â‰œ (ğœ†ğ‘£ âˆˆ PVar \ ğœƒ . 0) and the function ğ‘” : St[Name] â†’ St[AVar] takes ğœğ‘› and returns
ğœğ‘ such that ğœğ‘ maps like to 1, pr ğœ‡ to N (ğœğ‘› (ğœ‡); 0, 1), valğœ‡ to ğœğ‘› (ğœ‡), and all the other variables to 0.
The state ğœğ‘\ğœƒ âŠ• ğ‘”(ğœğ‘›) is the very initialisation used in Eq. (3). This step consists of two substeps.

(ğœğ‘\ğœƒ âŠ• ğœğœƒ âŠ• ğœğ‘› âŠ• ğ‘”(ğœğ‘›))(ğ‘¢),
(cid:75)
(ğœğ‘\ğœƒ âŠ• ğœğœƒ âŠ• ğœğ‘› âŠ• ğ‘”(ğœğ‘›))(ğ‘£),

(30)

(cid:75)

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:78

Wonyeol Lee, Xavier Rival, and Hongseok Yang

First substep: We first show that for all ğ‘¢ âˆˆ {like} âˆª {pr ğœ‡ | ğœ‡ âˆˆ Name} and ğ‘£ âˆˆ {pr ğœ‡ | ğœ‡ âˆˆ Name},
the functions ğ‘“ğ‘š, ğ‘“ğ‘” : St[ğœƒ ] Ã— St[Name] Ã— St[AVar] â†’ R are differentiable with respect to the
variables in ğœƒ âˆª rv(ğœ‹) jointly:

ğ‘“ğ‘š (ğœğœƒ, ğœğ‘›, ğœğ‘) â‰œ
ğ‘“ğ‘” (ğœğœƒ, ğœğ‘›, ğœğ‘) â‰œ

(ğœğ‘\ğœƒ âŠ• ğœğœƒ âŠ• ğœğ‘› âŠ• ğœğ‘)(ğ‘¢),
(ğœğ‘\ğœƒ âŠ• ğœğœƒ âŠ• ğœğ‘› âŠ• ğœğ‘)(ğ‘£).

(31)

ğ‘ğ‘š
(cid:74)
ğ‘ğ‘”
(cid:74)

(cid:75)

(cid:75)

ğ‘ğ‘”
(cid:74)

Note that in ğ‘“ğ‘š and ğ‘“ğ‘”, the AVar part does not depend on the Name part (unlike in Eq. (30)). For the proof,
pick arbitrary ğ‘¢ âˆˆ {like} âˆª {pr ğœ‡ | ğœ‡ âˆˆ Name} and ğ‘£ âˆˆ {pr ğœ‡ | ğœ‡ âˆˆ Name}. Then, ğœƒ âˆª rv(ğœ‹) âŠ† ğ¾ âŠ†
pğ‘š (ğ‘¢) âˆ© pğ‘” (ğ‘£), where the first inclusion is from the above result and the second from Eq. (13) (the defi-
nition of ğ¾). By the soundness of differentiability analysis (Theorem 5.8),
, pğ‘š (ğ‘¢), {ğ‘¢}) and
(cid:75)
, pğ‘” (ğ‘£), {ğ‘£ }). From this, and by the weakening lemma of Î¦ with ğœƒ âˆª rv(ğœ‹) âŠ† pğ‘š (ğ‘¢) âˆ© pğ‘” (ğ‘£)
|= Î¦(
(cid:75)
(Lemma F.4), we have |= Î¦(
, ğœƒ âˆª rv(ğœ‹), {ğ‘£ }). Hence, the functions
(cid:75)
in Eq. (31) are differentiable with respect to ğœƒ âˆª rv(ğœ‹) jointly as desired, by the definition of Î¦ (Â§5.1)
and the definition of â€œğ‘“ : St[ğ¿] â†’ R for ğ¿ âŠ† Var is differentiable with respect to ğ¿â€² âŠ† ğ¿ jointlyâ€ (Â§4.2).
Second substep: We now prove that the claim of the second step follows from the first substep
just proved. Pick any ğ‘¢ âˆˆ {like} âˆª {pr ğœ‡ | ğœ‡ âˆˆ Name}. We should show that the first function in
Eq. (30) is differentiable with respect to ğœƒ âˆª rv(ğœ‹). Note that we should also show the same for the
second function (for any ğ‘£), but the proof is similar to the first function so we omit this case. To
ğ‘›,0 âˆˆ St[Name \ rv(ğœ‹)] and ğœğ‘,0 âˆˆ St[AVar]. Define
prove the claim for the first function, pick any ğœ‰ â€²
ğ‘“ â€² : St[ğœƒ ] Ã— St[rv(ğœ‹)] Ã— St[AVar] as

, ğœƒ âˆª rv(ğœ‹), {ğ‘¢}) and |= Î¦(
(cid:75)

ğ‘ğ‘š
(cid:74)

ğ‘ğ‘š
(cid:74)

ğ‘ğ‘”
(cid:74)

|= Î¦(

Then, by Lemma C.6-(2) and Lemma C.6-(3),

ğ‘“ â€²(ğœğœƒ, ğœ‰ğ‘›, ğœğ‘) â‰œ ğ‘“ (ğœğœƒ, ğœ‰ğ‘› âŠ• ğœ‰ â€²

ğ‘›,0, ğœğ‘).

ğ‘“ â€²(ğœğœƒ, ğœ‰ğ‘›, ğœğ‘) â‰œ

(cid:40)ğ‘“ (ğœğœƒ, ğœ‰ğ‘› âŠ• ğœ‰ â€²
proj(ğœğ‘)

ğ‘›,0, ğœğ‘,0)

if (ğœğœƒ, ğœ‰ğ‘›) âˆˆ ğ‘ˆ
if (ğœğœƒ, ğœ‰ğ‘›) âˆ‰ ğ‘ˆ

for some ğ‘ˆ âŠ† St[ğœƒ ] Ã— St[rv(ğœ‹)] and some projection map ğ‘ğ‘Ÿğ‘œ ğ‘— : St[AVar] â†’ R. Also, since ğ‘“ is
differentiable with respect to ğœƒ âˆª rv(ğœ‹), ğ‘“ â€²(âˆ’, âˆ’, ğœğ‘) : St[ğœƒ ] Ã— St[rv(ğœ‹)] is differentiable and thus
continuous for all ğœğ‘ âˆˆ St[AVar]. From these, Lemma H.1 is applicable to ğ‘“ â€², implying that ğ‘ˆ should
be either âˆ… or St[ğœƒ ] Ã— St[rv(ğœ‹)]. We now consider ğ‘“ â€²â€² : St[ğœƒ ] Ã— St[rv(ğœ‹)] â†’ R defined by

ğ‘“ â€²â€²(ğœğœƒ, ğœ‰ğ‘›) â‰œ ğ‘“ â€²(ğœğœƒ, ğœ‰ğ‘›, ğ‘”(ğœ‰ğ‘›) âŠ• ğ‘”(ğœ‰ â€²

ğ‘›,0)),

where ğ‘” is extended to accept a substate in Stâ–¡ [Name] and return a substate for the corresponding
auxiliary part. Then, to prove the claim, it suffices to show that ğ‘“ â€²â€² is differentiable (since ğœ‰ â€²
ğ‘›,0 was
chosen arbitrarily). We do case analysis on ğ‘ˆ . If ğ‘ˆ = St[ğœƒ ] Ã— St[rv(ğœ‹)], then
for all ğœğœƒ and ğœ‰ğ‘›;

ğ‘“ â€²â€²(ğœğœƒ, ğœ‰ğ‘›) = ğ‘“ (ğœğœƒ, ğœ‰ğ‘› âŠ• ğœ‰ â€²

ğ‘›,0, ğœğ‘,0)

since ğ‘“ is differentiable with respect to ğœƒ âˆª rv(ğœ‹), ğ‘“ â€²â€² is differentiable. If ğ‘ˆ = âˆ…, then

ğ‘“ â€²â€²(ğœğœƒ, ğœ‰ğ‘›) = proj(ğ‘”(ğœ‰ğ‘›) âŠ• ğ‘”(ğœ‰ â€²

ğ‘›,0))

for all ğœğœƒ and ğœ‰ğ‘›;

sinceğ‘”, âŠ•, and proj are all differentiable (becauseğ‘” only uses projection and the density of the standard
normal distribution), ğ‘“ â€²â€² is differentiable. Hence, ğ‘“ â€²â€² is differentiable in both cases, and this shows
the claim of the second step.

Third step: We prove that ğœ‹ satisfies (R2), i.e., the functions in (R2) are differentiable with respect to
ğœƒ âˆª rv(ğœ‹) jointly. This holds because: ğ‘ğ‘š and ğ‘ğ‘” do not have a double-sampling error, so each function
in (R2) is a multiplication of some of the functions in Eq. (30) (for different ğ‘¢ and ğ‘£); the functions in
Eq. (30) are differentiable with respect to ğœƒ âˆª rv(ğœ‹) jointly (by the above result); and multiplication
preserves differentiability.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

Smoothness Analysis and Selective Reparameterisation

0:79

Third part: We show that ğœ‹ satisfies (R3), i.e., the functions in (R3) are differentiable with re-
spect to ğœƒ jointly. For this, it suffices to show the claim that for all ğ‘£ âˆˆ {pr ğœ‡, valğœ‡ | ğœ‡ âˆˆ Name} and
ğœğ‘› âˆˆ St[Name], the following function is differentiable with respect to ğœƒ jointly:

ğœ‹

(cid:75)

ğ‘ğ‘”
(cid:74)

ğœğœƒ âˆˆ St[ğœƒ ] â†¦âˆ’â†’

(ğœğ‘\ğœƒ âŠ• ğœğœƒ âŠ• ğœğ‘› âŠ• ğ‘”(ğœğ‘›))(ğ‘£).

(32)
ğœ‹ does not have a double-sampling error, so each function in (R2) is either a
This implies (R3) because:ğ‘ğ‘”
multiplication or a pairing of the function in Eq. (32) (for differentğ‘£); and multiplication and pairing pre-
serve differentiability. To show the claim, consider any ğ‘£ âˆˆ {pr ğœ‡, valğœ‡ | ğœ‡ âˆˆ Name}. Then, ğœƒ âŠ† pğ‘” (ğ‘£)
, pğ‘” (ğ‘£), {ğ‘£ }). From
by Eq. (14). By the soundness of differentiability analysis (Theorem 5.8),
ğœ‹
(cid:75)
this, and by the weakening lemma of Î¦ with ğœƒ âŠ† pğ‘” (ğ‘£) (Lemma F.4), we have |= Î¦(
, ğœƒ, {ğ‘£ }).
(cid:75)
Hence, the function in Eq. (32) is differentiable with respect to ğœƒ jointly. This completes the overall
â–¡
proof.

ğ‘ğ‘”
(cid:74)

ğ‘ğ‘”
(cid:74)

|= Î¦(

ğœ‹

Lemma H.1. Let ğ‘“ : Rğ‘› Ã— Rğ‘š â†’ R be a function such that

(cid:40)ğ‘“1(ğ‘¥)
ğ‘“2(ğ‘¦)
for some ğ‘“1 : Rğ‘› â†’ R, ğ‘“2 : Rğ‘š â†’ R, and ğ‘ˆ âŠ† ğ‘…ğ‘›. Suppose that ğ‘“2(Rğ‘š) = R and ğ‘“ (âˆ’, ğ‘¦) : Rğ‘› â†’ R is
continuous for all ğ‘¦ âˆˆ Rğ‘š. Then, ğ‘ˆ is either âˆ… or Rğ‘›.

if ğ‘¥ âˆˆ ğ‘ˆ
if ğ‘¥ âˆ‰ ğ‘ˆ

ğ‘“ (ğ‘¥, ğ‘¦) =

Proof. Here is a sketch of the proof. We prove the lemma by contradiction. Suppose that ğ‘ˆ is
neither âˆ… nor Rğ‘›. Then, the boundary of ğ‘ˆ (i.e., bd(ğ‘ˆ ) âŠ† Rğ‘›) is nonempty, since the boundary of a
set is empty if and only if the set is both open and closed, and since âˆ… and Rğ‘› are the only subsets
of Rğ‘› that are both open and closed. Let ğ‘¥ âˆˆ bd(ğ‘ˆ ) and consider two cases: ğ‘¥ âˆˆ ğ‘ˆ or ğ‘¥ âˆ‰ ğ‘ˆ . In
each of the two cases, we can show that there exists ğ‘¦ âˆˆ Rğ‘š such that ğ‘“ (âˆ’, ğ‘¦) is not continuous at ğ‘¥.
When showing the discontinuity, we use the following: ğ‘¥ âˆˆ bd(ğ‘ˆ ); the specific way that ğ‘“ is defined
(in terms of ğ‘ˆ , ğ‘“1, and ğ‘“2); and the assumption that ğ‘“2(Rğ‘š) = R. By assumption, ğ‘“ (âˆ’, ğ‘¦) should be
continuous over the entire Rğ‘›, so we get contradiction.
â–¡

I DEFERRED RESULTS IN Â§7

I.1 Deferred Experiment Details and Results

Name

Probabilistic model
Dirichlet process mixture models
Variational autoencoder (VAE)
Inference compilation
Bayesian regression
Amortised latent Dirichlet allocation

dpmm
vae
csis
br
lda
prodlda Probabilistic topic modelling
ssvae

Semi-supervised VAE

LoC while sam obs param
4
5
5
5
5
5
7

27
35
38
42
57
58
60

6
2
2
10
8
2
4

0
0
0
0
0
0
0

1
1
2
1
1
1
1

Table 6. Pyro examples used in experiments and their key features (continued from Table 2). The last five
columns show the total number of code lines (excluding comments), loops, sample commands, observe
commands, and learnable parameters (declared explicitly by pyro.param or implicitly by a neural network
module). Each number is the sum of the counts in the model and guide.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

0:80

Wonyeol Lee, Xavier Rival, and Hongseok Yang

Differentiable

Locally Lipschitz

Name

dpmm-m
dpmm-g
vae-m
vae-g
csis-m
csis-g
br-m
br-g
lda-m
lda-g
prodlda-m
prodlda-g
ssvae-m
ssvae-g

Manual Ours Time Manual Ours Time
0.002
0.003
0.003
0.002
0.001
0.004
0.002
0.004
0.002
0.007
0.007
0.006
0.003
0.009

0.002
0.003
0.002
0.002
0.001
0.004
0.002
0.004
0.002
0.007
0.008
0.007
0.004
0.007

2
6
3
4
1
2
5
10
3
7
2
5
3
6

2
6
3
4
1
2
5
10
3
7
2
5
3
6

2
6
3
4
1
6
5
10
3
7
2
5
3
6

2
6
3
4
1
6
5
10
3
7
2
5
3
6

#CRP
2
6
3
4
1
6
5
10
3
7
2
5
3
6

Table 7. Results of smoothness analyses (continued from Table 3). â€œManualâ€ and â€œOursâ€ denote the number
of continuous random variables and learnable parameters in which the density of the program is smooth,
computed by hand and by our analyser. â€œTimeâ€ denotes the runtime of our analyser in seconds. â€œ#CRPâ€ denotes
the total number of continuous random variables and learnable parameters in the program. -m and -g denote
model and guide. We consider {(ğ›¼, ğ‘–) âˆˆ Name} as one random variable for each ğ›¼ âˆˆ Name.

Name

dpmm
vae
csis
br
lda
prodlda
ssvae

Ours

Time
0.007
0.004
0.014
0.009
0.011
0.018
0.013

Sound
2
1
1
5
3
1
1

Pyro \ Ours
Sound Unsound
0
0
0
0
0
0
0

0
0
0
0
0
0
0

#CR #DR
1
0
0
0
2
0
1

2
1
1
5
3
1
1

Table 8. Results of variable selections (continued from Table 4). â€œOurs-Timeâ€ denote the runtime of our variable
selector in seconds. â€œOurs-Soundâ€ and â€œPyro \ Oursâ€ denote the number of random variables in the example that
are in ğœ‹ours, and that are in ğœ‹0 but not in ğœ‹ours, respectively, where ğœ‹ours and ğœ‹0 denote the reparameterisation
plans given by our variable selector and by Pyro. â€œPyro \ Oursâ€ is partitioned into â€œSoundâ€ and â€œUnsoundâ€: the
latter denotes the number of random variables that make (R2â€™) or (R3â€™) violated when added to ğœ‹ours, and the
former denotes the number of the rest. â€œ#CRâ€ and â€œ#DRâ€ denote the total number of continuous and discrete
random variables in the example. We consider {(ğ›¼, ğ‘–) âˆˆ Name} as one random variable for each ğ›¼ âˆˆ Name.

Proc. ACM Program. Lang., Vol. 0, No. 0, Article 0. Publication date: August 2022.

