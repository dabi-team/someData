CombOptNet: Fit the Right NP-Hard Problem by
Learning Integer Programming Constraints

Anselm Paulus 1 Michal Rol´ınek 1 V´ıt Musil 2 Brandon Amos 3 Georg Martius 1

2
2
0
2

r
p
A
1
1

]

G
L
.
s
c
[

2
v
3
4
3
2
0
.
5
0
1
2
:
v
i
X
r
a

Figure 1: CombOptNet as a module in a deep architecture.

Abstract

1. Introduction

Bridging logical and algorithmic reasoning with
modern machine learning techniques is a funda-
mental challenge with potentially transformative
impact. On the algorithmic side, many NP-HARD
problems can be expressed as integer programs, in
which the constraints play the role of their “com-
binatorial specification.” In this work, we aim to
integrate integer programming solvers into neural
network architectures as layers capable of learn-
ing both the cost terms and the constraints. The
resulting end-to-end trainable architectures jointly
extract features from raw data and solve a suitable
(learned) combinatorial problem with state-of-the-
art integer programming solvers. We demonstrate
the potential of such layers with an extensive per-
formance analysis on synthetic data and with a
demonstration on a competitive computer vision
keypoint matching benchmark.

1Max-Planck-Institute for Intelligent Systems, T¨ubingen, Ger-
many 2Masaryk University, Brno, Czechia 3Facebook AI Research,
USA. Correspondence to: Anselm Paulus & Georg Martius <first-
name.lastname@tuebingen.mpg.de>.

Proceedings of the 38 th International Conference on Machine
Learning, PMLR 139, 2021. Copyright 2021 by the author(s).

It is becoming increasingly clear that to advance artificial
intelligence, we need to dramatically enhance the reason-
ing, algorithmic, logical, and symbolic capabilities of data-
driven models. Only then we can aspire to match humans in
their astonishing ability to perform complicated abstract
tasks such as playing chess only based on visual input.
While there are decades worth of research directed at solving
complicated abstract tasks from their abstract formulation, it
seems very difficult to align these methods with deep learn-
ing architectures needed for processing raw inputs. Deep
learning methods often struggle to implicitly acquire the
abstract reasoning capabilities to solve and generalize to
new tasks. Recent work has investigated more structured
paradigms that have more explicit reasoning components,
such as layers capable of convex optimization. In this paper,
we focus on combinatorial optimization, which has been
well-studied and captures nontrivial reasoning capabilities
over discrete objects. Enabling its unrestrained usage in
machine learning models should fundamentally enrich the
set of available components.

On the technical level, the main challenge of incorporating
combinatorial optimization into the model typically amounts
to non-differentiability of methods that operate with discrete
inputs or outputs. Three basic approaches to overcome
this are to a) develop “soft” continuous versions of the dis-
crete algorithms (Wang et al., 2019; Zanfir & Sminchisescu,
2018); b) adjust the topology of neural network architec-
tures to express certain algorithmic behaviour (Graves et al.,

ILPSolver 
 
 
 
 
 
CombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints

2

2014; 2016; Battaglia et al., 2018); c) provide an infor-
mative gradient approximation for the discrete algorithm
(Vlastelica et al., 2020a; Berthet et al., 2020). While the last
strategy requires nontrivial theoretical considerations, it can
resolve the non-differentiability in the strongest possible
sense; without any compromise on the performance of the
original discrete algorithm. We follow this approach.

The most successful generic approach to combinatorial opti-
mization is integer linear programming (ILP). Integrating
ILPs as building blocks of differentiable models is chal-
lenging because of the nontrivial dependency of the solu-
tion on the cost terms and on the constraints. Learning
parametrized cost terms has been addressed in Vlastelica
et al. (2020a); Berthet et al. (2020); Ferber et al. (2020),
the learnability of constraints is, however, unexplored. At
the same time, the constraints of an ILP are of critical in-
terest due to their remarkable expressive power. Only by
modifying the constraints, one can formulate a number of
diverse combinatorial problems (SHORTEST-PATH, MATCH-
ING, MAX-CUT, KNAPSACK, TRAVELLING SALESMAN). In
that sense, learning ILP constraints corresponds to learning
the combinatorial nature of the problem at hand.

In this paper, we propose a backward pass (gradient compu-
tation) for ILPs covering their full specification, allowing
to use blackbox ILPs as combinatorial layers at any point in
the architecture. This layer can jointly learn the cost terms
and the constraints of the integer program, and as such it
aspires to achieve universal combinatorial expressivity.
We demonstrate the potential of this method on multiple
tasks. First, we extensively analyze the performance on
synthetic data. This includes the inverse optimization task
of recovering an unknown set of constraints, and a KNAP-
SACK problem specified in plain text descriptions. Finally,
we demonstrate the applicability to real-world tasks on a
competitive computer vision keypoint matching benchmark.

1.1. Related Work

Learning for combinatorial optimization. Learning
methods can powerfully augment classical combinatorial
optimization methods with data-driven knowledge. This
includes work that learns how to solve combinatorial op-
timization problems to improve upon traditional solvers
that are otherwise computationally expensive or intractable,
e.g. by using reinforcement learning (Zhang & Dietterich,
2000; Bello et al., 2016; Khalil et al., 2017; Nazari et al.,
2018), learning graph-based algorithms (Veliˇckovi´c et al.,
2018; Veliˇckovi´c et al., 2020; Wilder et al., 2019), learn-
ing to branch (Balcan et al., 2018), solving SMT formulas
(Balunovic et al., 2018) and TSP instances (Kool et al.,
2018). Nair et al. (2020) have recently scaled up learned
MIP solvers on non-trivial production datasets. In a more
general computational paradigm, Graves et al. (2014; 2016)

parameterize and learn Turing machines.

Optimization-based modeling for learning.
In the other
direction, optimization serves as a useful modeling
paradigm to improve the applicability of machine learning
models and to add domain-specific structures and priors. In
the continuous setting, differentiating through optimization
problems is a foundational topic as it enables optimization
algorithms to be used as a layer in end-to-end trainable mod-
els (Domke, 2012; Gould et al., 2016). This approach has
been recently studied in the convex setting in OptNet (Amos
& Kolter, 2017) for quadratic programs, and more general
cone programs in Amos (2019, Section 7.3) and Agrawal
et al. (2019a;b). One use of this paradigm is to incorpo-
rate the knowledge of a downstream optimization-based
task into a predictive model (Elmachtoub & Grigas, 2020;
Donti et al., 2017). Extending beyond the convex setting,
optimization-based modeling and differentiable optimiza-
tion are used for sparse structured inference (Niculae et al.,
2018), MAXSAT (Wang et al., 2019), submodular optimiza-
tion (Djolonga & Krause, 2017) mixed integer programming
(Ferber et al., 2020), and discrete and combinational settings
(Vlastelica et al., 2020a; Berthet et al., 2020). Applica-
tions of optimization-based modeling include computer vi-
sion (Rol´ınek et al., 2020b;a), reinforcement learning (Dalal
et al., 2018; Amos & Yarats, 2020; Vlastelica et al., 2020b),
game theory (Ling et al., 2018), and inverse optimization
(Tan et al., 2020), and meta-learning (Bertinetto et al., 2019;
Lee et al., 2019).

2. Problem description

Our goal is to incorporate an ILP as a differentiable layer in
neural networks that inputs both constraints and objective
coefficients and outputs the corresponding ILP solution.

Furthermore, we aim to embed ILPs in a blackbox man-
ner: On the forward pass, we run the unmodified optimized
solver, making no compromise on its performance. The task
is to propose an informative gradient for the solver as it is.
We never modify, relax, or soften the solver.

We assume the following form of a bounded integer pro-
gram:

≤
N, c

min
y∈Y

c

y

·

subject to

Ay

b,

(1)

Rn is the
where Y is a bounded subset of Zn, n
∈
Rm×n
cost vector, y are the variables, A = [a1, . . . , am]
∈
Rm is the
is the matrix of constraint coefficients and b
bias term. The point at which the minimum is attained is
denoted by y(A, b, c).

∈

∈

The task at hand is to provide gradients for the mapping
(A, b, c)
y(A, b, c), in which the triple (A, b, c) is the
specification of the ILP solver containing both the cost and

→

CombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints

3

the constraints, and y(A, b, c)
of the instance.

∈

Y is the optimal solution

Example. The ILP formulation of the KNAPSACK problem
can be written as

unattainable, i.e. y
dy is not a feasible integer point.
Next, we generalize the concept of active constraints. We
substitute the binary information “active/nonactive” by a
continuous proxy based on Euclidean distance.

−

max
y∈{0,1}n

c

y

·

subject to

a

y

·

≤

b,

(2)

where c = [c1, . . . , cn]
a = [a1, . . . , an]
sack capacity.

∈

Rn are the prices of the items,
R the knap-

Rn their weights and b

∈

∈

Similar encodings can be found for many more - often
NP-HARD - combinatorial optimization problems including
those mentioned in the introduction. Despite the apparent
difficulty of solving ILPs, modern highly optimized solvers
(Gurobi Optimization, 2019; Cplex, 2009) can routinely find
optimal solutions to instances with thousands of variables.

2.1. The main difficulty.

Differentiability. Since there are finitely many available
y(A, b, c) is piece-
values of y, the mapping (A, b, c)
wise constant; and as such, its true gradient is zero almost
everywhere. Indeed, a small perturbation of the constraints
or of the cost does typically not cause a change in the op-
timal ILP solution. The zero gradient has to be suitably
supplemented.

→

Gradient surrogates w.r.t. objective coefficients c have been
studied intensively (see e.g. Elmachtoub & Grigas, 2020;
Vlastelica et al., 2020a; Ferber et al., 2020). Here, we focus
on the differentiation w.r.t. constraints coefficients (A, b)
that has been unexplored by prior works.

LP vs. ILP: Active constraints.
In the LP case, the inte-
grality constraint on Y is removed. As a result, in the typical
case, the optimal solution can be written as the unique so-
lution to a linear system determined by the set of active
constraints. This captures the relationship between the con-
straint matrix and the optimal solution. Of course, this
relationship is differentiable.

However, in the case of an ILP the concept of active con-
straints vanishes. There can be optimal solutions for which
no constraint is tight. Providing gradients for nonactive-but-
relevant constraints is the principal difficulty. The com-
plexity of the interaction between the constraint set and the
optimal solution is reflecting the NP-HARD nature of ILPs
and is the reason why relying on the LP case is of little help.

3. Method

First, we reformulate the gradient problem as a descend
direction task. We have to resolve an issue that the suggested
dy to the optimal solution y is typically
gradient update y

−

Descent direction. On the backward pass, the gradient
of the layers following the ILP solver is given. Our aim is
to propose a direction of change to the constraints and to
the cost such that the solution of the updated ILP moves
towards the negated incoming gradient’s direction (i.e. the
descent direction).

Denoting a loss by L, let A, b, c and the incoming gradient
dy = ∂L/∂y at the point y = y(A, b, c) be given. We
are asked to return a gradient corresponding to ∂L/∂A,
∂L/∂b and ∂L/∂c. Our goal is to find directions dA, db
and dc for which the distance between the updated solution
dy decreases
y(A
the most.

dc) and the target y

dA, b

db, c

−

−

−

−

If the mapping y is differentiable, it leads to the correct
gradients ∂L/∂A = ∂L/∂y
∂y/∂A (analogously for b
·
and c). See Proposition 2 in the Supplementary material,
for the precise formulation and for the proof. The main
advantage of this formulation is that it is meaningful even
in the discrete case.

dc)
However, every ILP solution y(A
is restricted to integer points and its ability to approach the
point y
dy is limited unless dy is also an integer point.
To achieve this, let us decompose

dA, b

db, c

−

−

−

−

dy =

n
∑︂

k=1

λk∆k,

(3)

∈ {−

n are some integer points and λk
1, 0, 1
}

where ∆k
≥
0 are scalars. The choice of basis ∆k is discussed in a
separate paragraph, for now it suffices to know that every
point y′
∆k is an integer point neighbour of y
dy”. We then address separate
pointing in a “direction of
−
problems with dy replaced by the integer updates ∆k.

k = y

−

In other words, our goal here is to find an update on A, b, c
∆k. Staying
that eventually pushes the solution closer to y
true to linearity of the standard gradient mapping, we then
aim to compose the final gradient as a linear combination of
the gradients coming from the subproblems.

−

Constraints update. To get a meaningful update for a
realizable change ∆k, we take a gradient of a piecewise
affine local mismatch function Py′
. The definition of Py′
is based on a geometric understanding of the underlying
structure. To that end, we rely on the Euclidean distance
between a point and a hyperplane. Indeed, for any point y
and a given hyperplane, parametrized by vector a and scalar

k

k

CombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints

4

(a) y′

k is feasible but y′

k ̸= y.

(b) y′

k is infeasible.

Figure 2: Geometric interpretation of the suggested con-
straint update. (a) All constraints are satisfied for y′
k. The
proxy minimizes the distance to the nearest (“most active”)
constraint to make y “less feasible”. A possible updated
feasible region is shown in green. (b) The suggested y′
k
satisfies one of three constraints. The proxy minimizes the
distance to violated constraints to make y′
k “more feasible”.

b as x

x

a

·

−

↦→

b, we have:

dist(a, b; y) =

y

a
|

·

b
|

a
/
∥
∥

.

−

(4)

Now, we distinguish the cases based on whether y′
sible, i.e. Ay′
b, or not. The infeasibility of y′
caused by one or more constraints. We then define

k ≤

k is fea-
k can be

Module 1 CombOptNet

function FORWARDPASS(A, b, c)

y := Solver(A, b, c)
save y and A, b, c for backward pass
return y

function BACKWARDPASS(dy)

load y and A, b, c from forward pass
Decompose dy = ∑︁

k λk∆k
// set ∆k as in (9) and λk as in Proposition 1

Calculate the gradients

∂Py′
∂b , dck :=
k

∂Py′
k
∂c

dAk :=
// Py′

k

∂Py′
∂A , dbk :=
k
defined in (5) and (7)
k λk

Compose dA, db, dc := ∑︁

// According to (6)

(︁dAk, dbk, dck)︁

return dA, db, dc

This basis selection plays a role of a “homogenizing hyper-
paramter” (λ in (Vlastelica et al., 2020a) or ε in (Berthet
et al., 2020)). In our case, we explicitly construct a correct
basis and do not need to optimize any additional hyperpa-
rameter.

Py′

k

(A, b) =

⎧

⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎩

minj dist(aj, bj; y)

∑︁
j

0

if y′
aj
·
(cid:74)
if y′
if y′

= y
dist(aj, bj; y′
k)

k is feasible and y′
k ̸
y′
k > bj
k is infeasible
k = y or y′
k /
∈

Y ,

(cid:75)

(cid:74)·(cid:75)

where
is the Iverson bracket. The geometric intuition be-
hind the suggested mismatch function is described in Fig. 2
and its caption. Note that tighter constraints contribute more
to Py′
. In this sense, the mismatch function generalizes
the concept of active constraints. In practice, the mini-
mum is softened to allow multiple constraints to be updated
simultaneously. For details, see the Supplementary material.

k

Imposing linearity and using decomposition (3), we define
the outcoming gradient dA as

(5)

Cost update. Putting aside distinguishing of feasible and
infeasible y′
k, the cost update problem has been addressed
in multiple previous works. We use a simple approach of
setting the mismatch function such that the resulting update
favours y′
k over y in the updated optimization problem, i.e.

Py′

k

(c) =

{︄

c
0

·

(y′

k −

y)
if y′

if y′

k is feasible
k is infeasible or y′

k /
∈

(7)

Y .

The gradient dc is then composed analogously as in (6).

The choice of the basis. Denote by k1, . . . , kn the indices
of the coordinates in the absolute values of dy in decreasing
order, i.e.

dA =

n
∑︂

k=1

λk

∂Py′
k
∂A

(A, b)

(6)

and set

dyk1 | ≥ |
|

dyk2| ≥ · · · ≥ |

dykn |

∆k =

k
∑︂

j=1

sign(dykj )ekj ,

(8)

(9)

and analogously for db, by differentiating with respect to b.
The computation is summarized in Module 1.

↦→

dA, db is homogeneous. It is
Note that our mapping dy
due to the fact that the whole situation is rescaled to one case
(choice of basis) where the gradient is computed and then
rescaled back (scalars λk). The most natural scale agrees
with the situation when the “targets” y′
k are the closest in-
teger neighbors. This ensures that the situation does not
collapse to a trivial solution (zero gradient) and, simultane-
ously, that we do not interfere with very distant values of y.

where ek is the k-th canonical vector. Therefore, ∆k is the
(signed) indicator vector of the first k dominant directions.

|

|

dyℓ

> 0. Then the
Denote by ℓ the largest index for which
first ℓ vectors ∆k’s are linearly independent and they form a
basis of the corresponding subspace. Therefore, there exist
scalars λk’s satisfying decomposition (3).
for j =
If λj =
dykj+1|
dykj | − |
Proposition 1.
|
, then representation (3) holds
dykn |
1, . . . , n
|
−
with ∆k’s as in (9).

1 and λn =

CombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints

5

4. Demonstration & Analysis

We demonstrate the potential and flexibility of our method
on four tasks.

Starting with an extensive performance analysis on syn-
thetic data, we first demonstrate the ability to learn multiple
constraints simultaneously. For this, we learn a static set
of randomly initialized constraints from solved instances,
while using access to the ground-truth cost vector c.

Additionally, we show that the performance of our method
on the synthetic datasets also translates to real classes of
ILPs. For this we consider a similarly structured task as
before, but use the NP-complete WSC problem to generate
the dataset.

Next, we showcase the ability to simultaneously learn the
full ILP specification. For this, we learn a single input-
dependent constraint and the cost vector jointly from the
ground truth solutions of KNAPSACK instances. These in-
stances are encoded as sentence embeddings of their de-
scription in natural language.

Finally, we demonstrate that our method is also applicable to
real-world problems. On the task of keypoint matching, we
show that our method achieves results that are comparable
to state-of-the-art architectures employing dedicated solvers.
In this example, we jointly learn a static set of constraints
and the cost vector from ground-truth matchings.

In all demonstrations, we use GUROBI (Gurobi Optimiza-
tion, 2019) to solve the ILPs during training and evaluation.
Implementation details, a runtime analysis and additional
results, such as ablations, other loss functions and more
metrics, are provided in the Supplementary material. Addi-
tionally, a qualitative analysis of the results for the Knapsack
demonstration is included.

4.1. Random Constraints

Problem formulation. The task is to learn the constraints
(A, b) corresponding to a fixed ILP. The network has only
access to the cost vectors c and the ground-truth ILP solu-
tions y∗. Note that the set of constraints perfectly explaining
the data does not need to be unique.

Dataset. We generate 10 datasets for each cardinality
m = 1, 2, 4, 8 of the ground-truth constraint set while
keeping the dimensionality of the ILP fixed to n = 16.
Each dataset fixes a set of (randomly chosen) constraints
(A, b) specifying the ground-truth feasible region of an
ILP solver. For the constraints (A, b) we then randomly
sample cost vectors c and compute the corresponding ILP
solution y∗ (Fig. 5).

The dataset consists of 1 600 pairs (c, y∗) for training and
1 000 for testing. The solution space Y is either constrained

(a) Constraint representation

(b) Possible constraint update

Figure 4: (a) Each constraint (ak, bk) is parametrized by
its normal vector ak and a distance rk to its own origin ok.
(b) Such a representation allows for easy rotations around
the learnable offset ok instead of rotating around the static
global origin.

An example of a decomposition is shown in Fig. 3. Further
discussion about the choice of basis and various compar-
isons can be found in the Supplementary material.

Figure 3: All basis vectors ∆k (green) point more “towards
the dy direction” compared to the canonical ones (orange).

Constraint parametrization. For learning constraints,
we have to specify their parametrization. The representation
is of great importance, as it determines how the constraints
respond to incoming gradients. Additionally, it affects the
meaning of constraint distance by changing the parameter
space.

We represent each constraint (ak, bk) as a hyperplane de-
scribed by its normal vector ak, distance from the origin rk
and offset ok of the origin in the global coordinate system
as displayed in Fig. 4a. Consequently bk = rk

ok.

ak

−

·

Compared to the plain parametrization which represents the
constraints as a matrix A and a vector b, our slightly over-
parametrized choice allows the constraints to rotate with-
out requiring to traverse large distance in parameter space
(consider e.g. a 180◦ rotation). An illustration is displayed
in Fig. 4b. Comparison of our choice of parametrization to
other encodings and its effect on the performance can be
found in the Supplementary material.

CombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints

6

Figure 5: Dataset generation for the RC demonstration.

−

5, 5]n (dense) or [0, 1]n (binary). During dataset gen-
to [
eration, we performed a suitable rescaling to ensure a suffi-
ciently large set of feasible solutions.

Architecture. The network learns the constraints (A, b)
that specify the ILP solver from ground-truth pairs (c, y∗).
Given c, predicted solution y is compared to y∗ via the
MSE loss and the gradient is backpropagated to the learnable
constraints using CombOptNet (Fig. 6).

(a) Results on the binary datasets.

Figure 6: Architecture design for the RC demonstration.

(b) Results on the dense datasets.

The number of learned constraints matches the number of
constraints used for the dataset generation. Note that if the
ILP has no feasible solution, the CombOptNet layer output
is undefined and any loss or evaluation metric depending on
the solution y is meaningless. In practise, updates (5) push
the constraints outwards from the true solution y∗ leading
to a quick emergence of a feasible region.

Baselines. We compare CombOptNet to three baselines.
Agnostic to any constraints, a simple MLP baseline directly
predicts the solution from the input cost vector as the integer-
rounded output of a neural network. The CVXPY baseline
uses an architecture similar to ours, only the Module 1 of
CombOptNet is replaced with the CVXPY implementation
(Diamond & Boyd, 2016) of an LP solver that provides a
backward pass proposed by Agrawal et al. (2019a). Similar
to our method, it receives constraints and a cost vector and
outputs the solution of the LP solver greedily rounded to a
feasible integer solution. Finally, we report the performance
of always producing the solution of the problem only con-
Y . This baseline does not
strained to the outer region y
involve any training and is purely determined by the dataset.

∈

Figure 7: Results for the Random Constraints demonstration.
We report mean accuracy (y = y∗ in %) over 10 datasets
for 1, 2, 4 and 8 ground truth constraints in 16 dimensions.
By Box-constrained we denote the performance of always
producing the solution of the problem only constrained to
the outer region y
Y , which does not involve any training
∈
and is purely determined by the dataset.

solver. For most cost vectors, CVXPY often predicts the
same solution as the unconstrained one and its ability to use
constraints to improve is marginal. The reason is that the
LP relaxation of the ground truth problem is far from tight
and thus the LP solver proposes many fractional solutions,
which are likely to be rounded incorrectly. This highlights
the increased expressivity of the ILP formulation compared
to the LP formulation.

Even though all methods decrease in performance in the
dense case as the number of possible solutions is increased,
the trend from the binary case continues. With the increased
density of the solution space, the LP relaxation becomes
more similar to the ground truth ILP and hence the gap
between CombOptNet and the CVXPY baseline decreases.

Results. The results are reported in Fig. 7. In the binary,
case we demonstrate a high accuracy of perfectly predicting
the correct solution. The CVXPY baseline is not capable
of matching this, as it is not able to find a set of constraints
for the LP problem that mimics the effect of running an ILP

We conclude that CombOptNet is especially useful, when
the underlying problem is truly difficult (i.e. hard to approx-
imate by an LP). This is not surprising, as CombOptNet
introduces structural priors into the network that are de-
signed for hard combinatorial problems.

ILP SolverILP Solver1248020406080100Box-constrainedCombOptNetCVXPYMLP1248020406080100Box-constrainedCombOptNetCVXPYMLPCombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints

7

4.2. Weighted Set Covering

We show that our performance on the synthetic datasets
also translates to traditional classes of ILPs. Considering a
similarly structured architecture as in the previous section,
we generate the dataset by solving instances of the NP-
complete WSC problem.

C

=

, its covering
}

1, . . . , m
{
C →

of subsets of a uni-
= U . Given
and cost
with

Problem formulation. A family
verse U is called a covering of U if ⋃︁
U =
c :
the lowest total cost ∑︁

R, the task is to find the sub-covering
S∈C′ c(S).
The ILP formulation of this problem consists of m con-
n denotes an
0, 1
straints in n dimensions. Namely, if y
}
and bk = 1
Sj
, akj =
indicator vector of the sets in
(cid:75)
for k = 1, . . . m, then the specification reads as

C
S1, . . . , Sn
}
{
′
⊂ C

∈ {
k
(cid:74)

∈

C

C

C

min
y∈Y

∑︂

j

c(Sj)yj

subject to

Ay

b.

≥

(10)

C

Dataset. We randomly draw n subsets from the m-
element universe to form a covering
. To increase the
variance of solutions, we only allow subsets with no more
than 3 elements. As for the Random Constraints demonstra-
tion, the dataset consists of 1 600 pairs (c, y∗) for training
and 1 000 for testing. Here, c is uniformly sampled positive
cost vector and y∗ denotes the corresponding optimal solu-
tion (Fig. 8). We generate 10 datasets for each universe size
m = 4, 5, 6, 7, 8 with n = 2m subsets.

Figure 8: Dataset generation for the WSC demonstration.

Architecture and Baselines. We use the same architec-
ture and compare to the same baselines as in the Random
Constraints demonstration (Sec. 4.1).

Results. The results are reported in Fig. 9. Our method is
still able to predict the correct solution with high accuracy.
Compared to the previous demonstration, the performance
of the LP relaxation deteriorates. Contrary to the Random
Constraints datasets, the solution to the Weighted Set Cover-
ing problem never matches the solution of the unconstrained
problem, which takes no subset. This prevents the LP relax-
ation from exploiting these simple solutions and ultimately
leads to a performance drop. On the other hand, the MLP
baseline benefits from the enforced positivity of the cost vec-
tor, which leads to an overall reduced number of different
solutions in the dataset.

Figure 9: Results of the WSC demonstration. We report
mean accuracy (y = y∗ in %) over 10 datasets for universe
sizes m = 4, 6, 8, 10 and 2m subsets.

4.3. KNAPSACK from Sentence Description

Problem formulation. The task is inspired by a vin-
tage text-based PC game called “The Knapsack Problem”
(Richardson, 2001) in which a collection of 10 items is
presented to a player including their prices and weights.
The player’s goal is to maximize the total price of selected
items without exceeding the fixed 100-pound capacity of
their knapsack. The aim is to solve instances of the NP-
Hard KNAPSACK problem (2), from their word descriptions.
Here, the cost c and the constraint (a, b) are learned simul-
taneously.

Dataset. Similarly to the game, a KNAPSACK instance
consists of 10 sentences, each describing one item. The sen-
tences are preprocessed via the sentence embedding (Con-
neau et al., 2017) and the 10 resulting 4 096-dimensional
vectors x constitute the input of the dataset. We rely on the
ability of natural language embedding models to capture
numerical values, as the other words in the sentence are
uncorrelated with them (see an analysis of Wallace et al.
(2019)). The indicator vector y∗ of the optimal solution (i.e.
item selection) to a knapsack instance is its corresponding
label (Fig. 10). The dataset contains 4 500 training and 500
test pairs (x, y∗).

Figure 10: Dataset generation for the KNAPSACK problem.

Architecture. We simultaneously extract the learnable
constraint coefficients (a, b) and the cost vector c via an
MLP from the embedding vectors (Fig. 11).

WSC Solver46810020406080100Box-constrainedCombOptNetCVXPYMLPCombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints

8

Figure 11: Architecture design for the KNAPSACK problem.

As only a single learnable constraint is used, which by defi-
nition defines a KNAPSACK problem, the interpretation of
this demonstration is a bit different from the other demon-
strations. Instead of learning the type of combinatorial prob-
lem, we learn which exact KNAPSACK problem in terms of
item-weights and knapsack capacity needs to be solved.

Baselines. We compare to the same baselines as in the
Random Constraints demonstration (Sec. 4.1).

Results. The results are presented in Fig. 12. While
CombOptNet is able to predict the correct items for the
KNAPSACK with good accuracy, the baselines are unable
to match this. Additionally, we evaluate the LP relaxation
on the ground truth weights and prices, providing an upper
bound for results achievable by any method relying on an
LP relaxation. The weak performance of this evaluation
underlines the NP-Hardness of KNAPSACK. The ability
to embed and differentiate through a dedicated ILP solver
leads to surpassing this threshold even when learning from
imperfect raw inputs.

4.4. Deep Keypoint Matching

Problem formulation. Given are a source and target im-
age showing an object of the same class (e.g. airplane), each
labeled with a set of annotated keypoints (e.g. left wing).
The task is to find the correct matching between the sets
of keypoints from visual information without access to the
keypoint annotation. As not every keypoint has to be visible
in both images, some keypoints can also remain unmatched.

As in this task the combinatorial problem is known a priori,
state-of-the-art methods are able to exploit this knowledge
by using dedicated solvers. However, we make the problem
harder by omitting this knowledge. Instead, we simultane-
ously infer the problem specification and train the feature
extractor for the cost vector from data end-to-end.

Dataset. We use the SPair-71k dataset (Min et al., 2019)
which was published in the context of dense image matching
and was used as a benchmark for keypoint matching in
recent literature (Rol´ınek et al., 2020b). It includes 70 958
image pairs prepared from Pascal VOC 2012 and Pascal
3D+ with rich pair-level keypoint annotations. The dataset
is split into 53 340 training pairs, 5 384 validation pairs and
12 234 pairs for testing.

(a) Evaluation accuracy (y = y∗ in %) over training epochs.
LPmax is the maximum achievable LP relaxation accuracy.

(b) Training MSE loss over epochs.

Figure 12: Results or KNAPSACK demonstration. Reported
error bars are over 10 restarts.

State-of-the-art. We compare to a state-of-the-art archi-
tecture BB-GM (Rol´ınek et al., 2020b) that employs a dedi-
cated solver for the quadratic assignment problem. Given
a pair of images and their corresponding sets of keypoint
locations, the method constructs for each image a graph
with the nodes corresponding to the keypoints. A network
then predicts the unary and quadratic costs for matching
the nodes and edges between the two graphs. A heavily
optimized solver for the quadratic ASSIGNMENT problem
then computes a consistent matching of the nodes. When
training the architecture, the incoming gradient is backprop-
agated through the solver to the unary and quadratic costs
via blackbox backpropagation (Vlastelica et al., 2020a).

Architecture. We modify the BB-GM architecture by re-
placing the blackbox backpropagation module employing
the dedicated solver with CombOptNet.

The drop-in replacement comes with a few important con-
siderations. Note that our method relies on a fixed dimen-
sionality n of the problem for learning a static (i.e. not
input-dependent) constraint set. However, in the BB-GM ar-
chitecture the dimensionality of the predicted costs depends
on the number of nodes (i.e. keypoints) p and number of

ILP020406080100020406080100CombOptNetCVXPYMLPLPmax0204060801000.040.060.100.20CombOptNetCVXPYMLPCombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints

9

Table 1: Results for the keypoint matching demonstration.
Reported is the standard per-variable accuracy (%) metric
over 5 restarts. Column p
p corresponds to matching p
source keypoints to p target keypoints. Original BB-GM has
access to unary and quadratic costs; we also report perfor-
mance with access only to unary costs as in CombOptNet.

×

Method

4 × 4

5 × 5

6 × 6

7 × 7

CombOptNet
BB-GM (unary only)
BB-GM (unary & quad.)

83.1
84.3
84.3

80.7
81.6
82.9

78.6
79.0
80.5

76.1
76.5
79.8

edges in each of the two matched graphs. As these quanti-
ties vary over the dataset, the dimensionality varies as well.
To avoid these issues, we resort to a simplified setting.

First, we fix the number of keypoints in both images. For
each p = 4, 5, 6, 7, we generate an augmented dataset by
randomly removing additional keypoints in images with
more than p keypoints. The images with fewer keypoints
than p are dropped. Note that even for a fixed number of
keypoints the number of edges (and hence the quadratic cost
dimensionality) can vary. Therefore, we omit the quadratic
costs as an input to the ILP solver.

These simplifications result in a fixed ILP dimensionality of
n = p2. The number of learnable constraints coincides with
the number of constraints in the corresponding unary AS-
SIGNMENT problem, i.e. the combined number of keypoints
in both images (m = 2p).

The randomly initialized constraint set and the backbone
architecture that produces the cost vectors are learned simul-
taneously from pairs of predicted solutions and ground-truth
matchings using CombOptNet.

Results. We report two results for the BB-GM architec-
ture depending on the information available to the solver. In
the unary setting, the solver utilizes only unary costs, in the
quadratic setting, it utilizes both unary and quadratic costs.
The ILP solver is restricted to the unary setting.

Even though the task-agnostic CombOptNet is uninformed
about the underlying combinatorial problem, its perfor-
mance is very close to the privileged state-of-the-art method
BB-GM, especially when BB-GM is restricted to use the
same information (unary costs only). These results are espe-
cially satisfactory, considering that BB-GM outperforms the
previous state-of-the-art architecture (Fey et al., 2020) by
several percentage points on experiments of this difficulty.
Example matchings are shown in Fig. 13.

Figure 13: Example matchings predicted by CombOptNet.

5. Conclusion

We propose a method for integrating integer linear program
solvers into neural network architectures as layers. This is
enabled by providing gradients for both the cost terms and
the constraints of an ILP. The resulting end-to-end train-
able architectures are able to simultaneously extract features
from raw data and learn a suitable set of constraints that
specify the combinatorial problem. Thus, the architecture
learns to fit the right NP-hard problem needed to solve the
task. In that sense, it strives to achieve universal combinato-
rial expressivity in deep networks—opening many exciting
perspectives.

In the experiments, we demonstrate the flexibility of our
approach, using different input domains, natural language
and images, and different combinatorial problems with the
same CombOptNet module. In particular, for combinato-
rially hard problems we see a strong advantage of the new
architecture.

The potential of our method is highlighted by the demonstra-
tion on the keypoint matching benchmark. Unaware of the
underlying combinatorial problem, CombOptNet achieves a
performance that is not far behind architectures employing
dedicated state-of-the-art solvers.

In future work, we aim to make the number of constraints
flexible and to explore more problems with hybrid combina-
torial complexity and statistical learning aspects.

CombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints

10

Acknowledgements

Georg Martius is a member of the Machine Learn-
ing Cluster of Excellence,
funded by the Deutsche
Forschungsgemeinschaft (DFG, German Research Foun-
dation) under Germany’s Excellence Strategy – EXC
number 2064/1 – Project number 390727645. We ac-
knowledge the support from the German Federal Min-
istry of Education and Research (BMBF) through the
T¨ubingen AI Center (FKZ: 01IS18039B). This work was
supported from Operational Programme Research, De-
velopment and Education – Project Postdoc2MUNI (No.
CZ.02.2.69/0.0/0.0/18 053/0016952)

References

Agrawal, A., Amos, B., Barratt, S., Boyd, S., Diamond,
S., and Kolter, J. Z. Differentiable convex optimization
layers. In Advances in Neural Information Processing
Systems, pp. 9562–9574, 2019a.

Agrawal, A., Barratt, S., Boyd, S., Busseti, E., and Moursi,
W. M. Differentiating through a cone program. J. Appl.
Numer. Optim, 1(2):107–115, 2019b.

Amos, B. Differentiable optimization-based modeling for
machine learning. PhD thesis, PhD thesis. Carnegie Mel-
lon University, 2019.

Amos, B. and Kolter, J. Z. Optnet: Differentiable opti-
mization as a layer in neural networks. In International
Conference on Machine Learning, pp. 136–145, 2017.

Amos, B. and Yarats, D. The differentiable cross-entropy
method. In International Conference on Machine Learn-
ing, pp. 291–302, 2020.

Balcan, M.-F., Dick, T., Sandholm, T., and Vitercik, E.
Learning to branch. In International conference on ma-
chine learning, pp. 344–353, 2018.

Balunovic, M., Bielik, P., and Vechev, M. Learning to
solve SMT formulas. In Advances in Neural Information
Processing Systems, pp. 10317–10328, 2018.

Battaglia, P., Hamrick, J. B. C., Bapst, V., Sanchez, A.,
Zambaldi, V., Malinowski, M., Tacchetti, A., Raposo, D.,
Santoro, A., Faulkner, R., Gulcehre, C., Song, F., Ballard,
A., Gilmer, J., Dahl, G. E., Vaswani, A., Allen, K., Nash,
C., Langston, V. J., Dyer, C., Heess, N., Wierstra, D.,
Kohli, P., Botvinick, M., Vinyals, O., Li, Y., and Pascanu,
R. Relational inductive biases, deep learning, and graph
networks. arXiv:1806.01261, 2018.

Bello, I., Pham, H., Le, Q. V., Norouzi, M., and Bengio,
S. Neural combinatorial optimization with reinforcement
learning. arXiv:1611.09940, 2016.

Berthet, Q., Blondel, M., Teboul, O., Cuturi, M., Vert, J.-P.,
and Bach, F. Learning with differentiable perturbed opti-
mizers. In Advances in Neural Information Processing
Systems, pp. 9508–9519, 2020.

Bertinetto, L., Henriques, J. F., Torr, P. H., and Vedaldi, A.
Meta-learning with differentiable closed-form solvers. In
International Conference on Learning Representations,
2019.

Conneau, A., Kiela, D., Schwenk, H., Barrault, L., and
Bordes, A. Supervised learning of universal sentence
representations from natural language inference data. In
Conference on Empirical Methods in Natural Language
Processing, pp. 670–680, Copenhagen, Denmark, 2017.
Association for Computational Linguistics.

Cplex, I. I. V12. 1: User’s Manual for CPLEX. International
Business Machines Corporation, 46(53):157, 2009.

Dalal, G., Dvijotham, K., Vecerik, M., Hester, T., Paduraru,
C., and Tassa, Y. Safe exploration in continuous action
spaces. arXiv:1801.08757, 2018.

Diamond, S. and Boyd, S. CVXPY: A Python-embedded
modeling language for convex optimization. Journal of
Machine Learning Research, 17(83):1–5, 2016.

Djolonga, J. and Krause, A. Differentiable learning of
submodular models. In Advances in Neural Information
Processing Systems, pp. 1013–1023, 2017.

Domke, J. Generic methods for optimization-based model-
ing. In Artificial Intelligence and Statistics, pp. 318–326,
2012.

Donti, P., Amos, B., and Kolter, J. Z. Task-based end-to-end
model learning in stochastic optimization. In Advances in
Neural Information Processing Systems, pp. 5484–5494,
2017.

Elmachtoub, A. N. and Grigas, P. Smart “predict, then

optimize”. arXiv:1710.08005, 2020.

Ferber, A., Wilder, B., Dilkina, B., and Tambe, M. MIPaaL:
Mixed integer program as a layer. In AAAI Conference on
Artificial Intelligence, volume 34, pp. 1504–1511, 2020.

Fey, M., Lenssen, J. E., Morris, C., Masci, J., and Kriege,
N. M. Deep graph matching consensus. In International
Conference on Learning Representations, 2020.

Gould, S., Fernando, B., Cherian, A., Anderson, P., Cruz,
R. S., and Guo, E. On differentiating parameterized
argmin and argmax problems with application to bi-level
optimization. arXiv:1607.05447, 2016.

Graves, A., Wayne, G., and Danihelka, I. Neural turing

machines. arXiv:1410.5401, 2014.

CombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints

11

Graves, A., Wayne, G., Reynolds, M., Harley, T., Dani-
helka, I., Grabska-Barwi´nska, A., Colmenarejo, S. G.,
Grefenstette, E., Ramalho, T., Agapiou, J., Badia, A. P.,
Hermann, K. M., Zwols, Y., Ostrovski, G., Cain, A.,
King, H., Summerfield, C., Blunsom, P., Kavukcuoglu,
K., and Hassabis, D. Hybrid computing using a neural
network with dynamic external memory. Nature, 538
(7626):471–476, October 2016.

Gurobi Optimization, L. Gurobi optimizer reference manual,

2019. URL http://www.gurobi.com.

Khalil, E., Dai, H., Zhang, Y., Dilkina, B., and Song,
L. Learning combinatorial optimization algorithms over
graphs. In Advances in Neural Information Processing
Systems, pp. 6348–6358, 2017.

Kingma, D. P. and Ba, J. Adam: A method for stochastic
optimization. In International Conference on Learning
Representations, 2014.

Kool, W., van Hoof, H., and Welling, M. Attention, learn to
solve routing problems! In International Conference on
Learning Representations, 2018.

Lee, K., Maji, S., Ravichandran, A., and Soatto, S. Meta-
learning with differentiable convex optimization. In Con-
ference on Computer Vision and Pattern Recognition, pp.
10657–10665, 2019.

Ling, C. K., Fang, F., and Kolter, J. Z. What game are
we playing? End-to-end learning in normal and exten-
sive form games. In International Joint Conference on
Artificial Intelligence, 2018.

Min, J., Lee, J., Ponce, J., and Cho, M. SPair-71k: A
Large-scale Benchmark for Semantic Correspondence.
arXiv:1908.10543, 2019.

Nair, V., Bartunov, S., Gimeno, F., von Glehn, I., Lichocki,
P., Lobov, I., O’Donoghue, B., Sonnerat, N., Tjandraat-
madja, C., Wang, P., Addanki, R., Hapuarachchi, T., Keck,
T., Keeling, J., Kohli, P., Ktena, I., Li, Y., Vinyals, O., and
Zwols, Y. Solving mixed integer programs using neural
networks. arXiv:2012.13349, 2020.

Nazari, M., Oroojlooy, A., Snyder, L., and Tak´ac, M. Rein-
forcement learning for solving the vehicle routing prob-
lem. In Advances in Neural Information Processing Sys-
tems, pp. 9839–9849, 2018.

Niculae, V., Martins, A., Blondel, M., and Cardie, C.
Sparsemap: Differentiable sparse structured inference.
In International Conference on Machine Learning, pp.
3799–3808, 2018.

Richardson, L. The knapsack problem,

the game of
premature optimization, 2001. URL https://www.
crummy.com/software/if/knapsack/.

Rol´ınek, M., Musil, V., Paulus, A., Vlastelica, M., Michaelis,
C., and Martius, G. Optimizing ranking-based metrics
with blackbox differentiation. In Conference on Com-
puter Vision and Pattern Recognition, 2020a.

Rol´ınek, M., Swoboda, P., Zietlow, D., Paulus, A., Musil,
V., and Martius, G. Deep graph matching via blackbox
In European
differentiation of combinatorial solvers.
Conference on Computer Vision, pp. 407–424, 2020b.

Tan, Y., Terekhov, D., and Delong, A. Learning linear
programs from optimal decisions. In Advances in Neural
Information Processing Systems, pp. 19738–19749, 2020.

Veliˇckovi´c, P., Cucurull, G., Casanova, A., Romero, A.,
Lio, P., and Bengio, Y. Graph attention networks. In
International Conference on Learning Representations,
2018.

Veliˇckovi´c, P., Ying, R., Padovano, M., Hadsell, R., and
Blundell, C. Neural execution of graph algorithms. In
International Conference on Learning Representations,
2020.

Vlastelica, M., Paulus, A., Musil, V., Martius, G., and
Rol´ınek, M. Differentiation of blackbox combinatorial
solvers. In International Conference on Learning Repre-
sentations, 2020a.

Vlastelica, M., Rolinek, M., and Martius, G. Discrete plan-
ning with end-to-end trained neuro-algorithmic policies.
ICML 2020, Graph Representation Learning Workshop,
2020b.

Wallace, E., Wang, Y., Li, S., Singh, S., and Gardner, M.
Do NLP models know numbers? Probing numeracy in
embeddings. In Conference on Empirical Methods in
Natural Language Processing and the 9th International
Joint Conference on Natural Language Processing, pp.
5310–5318, 2019.

Wang, P.-W., Donti, P., Wilder, B., and Kolter, Z. SAT-
Net: Bridging deep learning and logical reasoning using
a differentiable satisfiability solver. In International Con-
ference on Machine Learning, pp. 6545–6554, 2019.

Wilder, B., Ewing, E., Dilkina, B., and Tambe, M. End to
end learning and optimization on graphs. In Advances in
Neural Information Processing Systems, pp. 4672–4683,
2019.

Zanfir, A. and Sminchisescu, C. Deep learning of graph
matching. In Conference on Computer Vision and Pattern
Recognition, pp. 2684–2693, 2018.

Zhang, W. and Dietterich, T. G. Solving combinatorial
optimization tasks by reinforcement learning: A general
methodology applied to resource-constrained scheduling.
Journal of Artificial Intelligence Reseach, 1:1–38, 2000.

CombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints

12

A. Demonstrations

The code for all demonstrations is available at

github.com/martius-lab/CombOptNet.

A.1. Implementation Details

When learning multiple constraints, we replace the mini-
mum in definition (5) of mismatch function P∆k with its
softened version. Therefore, not only the single closest con-
straint will shift towards y′
k, but also other constraints close
to y′

k will do. For the softened minimum we use
)︂)︃

(︂

(︃∑︂

softmin(x) =

τ

log

exp

,

(11)

xk
τ

−

−

·

k

which introduces the temperature τ , determining the soften-
ing strength.

In all experiments, we normalize the cost vector c before
we forward it to the CombOptNet module. For the loss we
use the mean squared error between the normalized pre-
dicted solution y and the normalized ground-truth solution
y∗. For normalization we apply the shift and scale that
translates the underlying hypercube of possible solutions
([0, 1]n in binary or [
5, 5]n in dense case) to a normalized
hypercube [

−
0.5, 0.5]n.

−

The hyperparameters for all demonstrations are listed in
Tab. 2. We use Adam (Kingma & Ba, 2014) as the op-
timizer for all demonstrations. Gurobi parameters for all
experiments are kept to default.

Table 2: Hyperparameters for all demonstrations.

WSC & Random
Constraints

Knapsack

Learning rate
Batch size
Train epochs
τ
Backbone lr

5 × 10−4
8
100
0.5
–

5 × 10−4
8
100
0.5
–

Keypoint
Matching

1 × 10−4
8
10
0.5
2.5 × 10−6

Random Constraints. For selecting the set of constraints
for data generation, we uniformly sample constraint ori-
gins ok in the center subcube (halved edge length) of the
underlying hypercube of possible solutions. The constraint
normals ak and the cost vectors c are randomly sampled
normalized vectors and the bias terms are initially set to
bk = 0.2. The signs of the constraint normals ak are flipped
in case the origin is not feasible, ensuring that the prob-
lem has at least one feasible solution. We generate 10 such
datasets for m = 1, 2, 4, 8 constraints in n = 16 dimen-
sions. The size of each dataset is 1 600 train instances and
1 000 test instances.

For learning, the constraints are initialised in the same way
except for the feasibility check, which is skipped since
CombOptNet can deal with infeasible regions itself.

KNAPSACK from Sentence Description. Our method
and CVXPY use a small neural network to extract weights
and prices from the 4 096-dimensional embedding vectors.
We use a two-layer MLP with a hidden dimension of 512,
ReLU nonlinearity on the hidden nodes, and a sigmoid non-
linearity on the output. The output is scaled to the ground-
truth price range [10, 45] for the cost c and to the ground-
truth weight range [15, 35] for the constraint a. The bias
term is fixed to the ground-truth knapsack capacity b = 100.
Item weights and prices as well as the knapsack capacity are
finally multiplied by a factor of 0.01 to produce a reasonable
scale for the constraint parameters and cost vector.

The CVXPY baseline implements a greedy rounding proce-
dure to ensure the feasibility of the predicted integer solution
with respect to the learned constraints. Starting from the
item with the largest predicted (noninteger) value, the proce-
dure adds items to the predicted (integer) solution until no
more items can be added without surpassing the knapsack
capacity.

The MLP baseline employs an MLP consisting of three
layers with dimensionality 100 and ReLU activation on the
hidden nodes. Without using an output nonlinearity, the
output is rounded to the nearest integer point to obtain the
predicted solution.

Deep Keypoint Matching. We initialize a set of con-
straints exactly as in the binary case of the Random Con-
straints demonstration. We use the architecture described by
Rol´ınek et al. (2020b), only replacing the dedicated solver
module with CombOptNet.

We train models for varying numbers of keypoints p =
4, 5, 6, 7 in the source and target image, resulting in varying
dimensionalities n = p2 and number of constraints m =
2p. Consistent with Rol´ınek et al. (2020b), all models are
trained for 10 epochs, each consisting of 400 iterations with
randomly drawn samples from the training set. We discard
samples with fewer keypoints than what is specified for the
model through the dimensionality of the constraint set. If
the sample has more keypoints, we chose a random subset
of the correct size.

After each epoch, we evaluate the trained models on the
validation set. Each model’s highest-scoring validation stage
is then evaluated on the test set for the final results.

A.2. Runtime analysis.

The runtimes of our demonstrations are reported in Tab. 3.
Random Constrains demonstrations have the same runtimes

CombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints

13

Table 3: Average runtime for training and evaluating a
model on a single Tesla-V100 GPU. For Keypoint Matching,
the runtime for the largest model (p = 7) is shown.

Table 5: Weighted set covering demonstration with multiple
learnable constraints.

Weighted
Set Covering

CombOptNet
CVXPY
MLP
BB-GM

1h 30m
1h
10m
–

Knapsack

3h 50m
2h 30m
20m
–

Keypoint
Matching

5h 30m
–
–
55m

as Weighted Set Covering since they share the architecture.

Unsurprisingly, CombOptNet has higher runtimes as it relies
on ILP solvers which are generally slower than LP solvers.
Also, the backward pass of CombOptNet has negligible
runtime compared to the forward-pass runtime. In Random
Constraints, Weighted Set Covering and KNAPSACK demon-
stration, the increased runtime is necessary, as the baselines
simply do not solve a hard enough problem to succeed in
the tasks.

In the Keypoint Matching demonstration, CombOptNet
slightly drops behind BB-GM and requires higher runtime.
Such drawback is outweighed by the benefit of employing
a broad-expressive model that operates without embedded
knowledge of the underlying combinatorial task.

A.3. Additional Results

Random Constraints & Weighted Set Covering. We
provide additional results regarding the increased amount
of learned constraints in Tab. 4 and 5) and the choice of the
loss function Tab. 6.

With a larger set of learnable constraints the model is able

⋆Used in the main demonstrations.

Table 4: Random Constraints demonstration with multiple
learnable constraints. Using a dataset with m ground-truth
constraints, we train a model with k
m learnable con-
straints. Reported is evaluation accuracy (y = y∗ in %) for
m = 1, 2, 4, 8. Statistics are over 20 restarts (2 for each of
the 10 dataset seeds).

×

m

1

2

4

8

y 1 × m⋆ 97.8 ± 0.7 94.2 ± 10.1 77.4 ± 13.5 46.5 ± 12.4
2 × m 97.3 ± 0.9 95.1 ± 1.6 87.8 ± 5.2 63.1 ± 7.0
4 × m 96.9 ± 0.7 95.1 ± 1.2 88.7 ± 2.3 77.7 ± 3.2

r
a
n
i
b

e 1 × m⋆ 87.3 ± 2.5 70.2 ± 11.6 29.6 ± 10.4 2.3 ± 1.2
2.4 ± 0.8
2.9 ± 1.3

2 × m 87.8 ± 1.7 73.4 ± 2.4 32.7 ± 7.6
4 × m 85.0 ± 2.6 64.6 ± 3.9 28.3 ± 2.7

s
n
e
d

k

4

6

8

10

1⋆ 100 ± 0.0
100 ± 0.0
2
100 ± 0.0
4

97.2 ± 6.4
99.5 ± 1.9
99.9 ± 0.0

79.7 ± 12.1
99.3 ± 0.8
97.9 ± 6.4

56.7 ± 14.8
80.4 ± 13.0
85.2 ± 8.1

to construct a more complex feasible region. While in gen-
eral this tends to increase performance and reduce variance
by increasing robustness to bad initializations, it can also
lead to overfitting similarly to a neural net with too many
parameters.

In the dense case, we also compare different loss functions
which is possible because CombOptNet can be used as an
arbitrary layer. As shown in Tab. 6, this choice matters, with
the MSE loss, the L1 loss and the Huber loss outperforming
the L0 loss. This freedom of loss function choice can prove
very helpful for training more complex architectures.
Table 6: Random Constraints dense demonstration with
various loss functions. For the Huber loss we set β = 0.3.
Statistics are over 20 restarts (2 for each of the 10 dataset
seeds).

Loss

MSE⋆
Huber
L0
L1

1

2

4

8

87.3 ± 2.5
88.3 ± 4.0
85.9 ± 3.4
89.2 ± 1.6

70.2 ± 11.6 29.6 ± 10.4
25.0 ± 11.8
75.4 ± 9.3
15.3 ± 4.3
65.8 ± 3.5
75.8 ± 10.8 30.2 ± 16.5

2.3 ± 1.2
2.6 ± 2.7
1.1 ± 0.3
2.1 ± 1.2

KNAPSACK from Sentence Description. As for the Ran-
dom Constraints demonstration, we report the performance
of CombOptNet on the KNAPSACK task for a higher num-
ber of learnable constraints. The results are listed in Tab. 7.
Similar to the binary Random Constraints ablation with
m = 1, increasing the number of learnable constraints does
not result in strongly increased performance.

Additionally, we provide a qualitative analysis of the results
on the KNAPSACK task. In Fig. 14 we compare the total
ground-truth price of the predicted instances to the total
price of the ground-truth solutions on a single evaluation of
the trained models.

Table 7: Knapsack demonstration with more learnable con-
straints. Reported is evaluation accuracy (y = y∗ in %) for
m = 1, 2, 4, 8 constraints. Statistics are over 10 restarts.

1⋆

2

4

8

64.7 ± 2.8 63.5 ± 3.7 65.7 ± 3.1 62.6 ± 4.4

CombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints

14

(a) CombOptNet

(b) CVXPY

(a) CombOptNet

(b) CVXPY

Figure 14: Prices analysis for the KNAPSACK demonstra-
tion. For each test set instance, we plot the total price of the
predicted solution over the total price of the ground-truth
solution. Predicted solutions which total weight exceeds the
knapsack capacity are colored in red (cross).

Figure 15: Qualitative analysis of the errors on weights and
prices in the KNAPSACK demonstration. We plot the relative
error between predicted and ground-truth item prices over
the relative error between predicted and ground-truth item
weights. Colors denote whether the predicted solution is
feasible in terms of ground-truth weights.

The plots show that CombOptNet is achieving much better
results than CVXPY. The total prices of the predictions are
very close to the optimal prices and only a few predictions
are infeasible, while CVXPY tends to predict infeasible
solutions and only a few predictions have objective values
matching the optimum.

In Fig. 15 we compare relative errors on the individual item
weights and prices on the same evaluation of the trained
models as before. Since (I)LP costs are scale invariant, we
normalize predicted price vector to match the size of the
ground-truth price vector before the comparison.

CombOptNet shows relatively small normally distributed
errors on both prices and weights, precisely as expected
from the prediction of a standard network. CVXPY reports
much larger relative errors on both prices and weights (note
the different plot scale). The vertical lines correspond to the
discrete steps of ground-truth item weights in the dataset.
Unsurprisingly, the baseline usually tends to either overesti-
mate the price and underestimate the item weight, or vice
versa, due to similar effects of these errors on the predicted
solution.

A.4. Ablations

We ablate the choices in our architecture and model design
on the Random Constraints (RC) and Weighted Set Cov-
ering (WSC) tasks. In Tab. 8 and 9 we report constraint
parametrization, choice of basis, and minima softening ab-
lations.

The ablations show that our parametrization with learnable
origins is consistently among the best ones. Without learn-
able origins, the performance is highly dependend on the
origin of the coordinate system in which the directly learned
parameters (A, b) are defined.

The choice of basis in the gradient decomposition shows
a large impact on performance. Our basis ∆ (9) is out-
performing the canonical one in the binary RC and WSC
demonstration, while showing performance similar to the
canonical basis in the dense RC case. The canonical basis
produces directions for the computation of y′
k that in many
cases point in very different directions than the incoming
descent direction. As a result, the gradient computation
leads to updates that are very detached from the original
incoming gradient.

Finally, the softened minimum leads to increased perfor-
mance in all demonstrations. This effect is apparent particu-
larly in the case of a binary solution space, as the constraints
can have a relevant impact on the predicted solution y over
large distances. Therefore, only updating the constraint
which is closest to the predicted solution y, as it is the case
for a hard minimum, gives no gradient to constraints that
may potentially have had a huge influence on y.

B. Method

B.1. Fixed Constraints

In the paper we omitted the discussion of the effect of fixed
(i.e. not learnable) constraints on the presented update rules.
In our experiments, we assumed fixed feasible region to be a
Z, l < z. Fixed constraints can
hypercube [l, u]n with l, u
cause problems, as our decomposition only guarantees that
the targets y′
k are integer points, but their feasibility w.r.t.
to the fixed constraints is not guaranteed. Therefore, our
assumption of y′
k being an attainable target can be violated.
In our cases, we ensure the feasibility of the targets by first
projecting y

dy into the hypercube as

∈

−
(y′
proj)i = max(min(yi

dyi, u), l)

(12)

−

100150200PriceofGTsolution100150200Priceofpred.solution100150200PriceofGTsolution100150200optimalfeasibleinfeasible−0.20.00.2Relativeweighterror−0.20.00.2Relativepriceerror−0.50.00.5Relativeweighterror−0.50.00.5feasibleinfeasibleCombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints

15

Table 8: Ablations of CombOptNet on Random Constraints demonstration. Reported is evaluation
accuracy (y = y∗ in %) for m = 1, 2, 4, 8 ground-truth constraints. Statistics are over 20 restarts (2 for
each of the 10 dataset seeds).

Method

. learnable origins⋆
m
a
r
a
p

direct (origin at corner)
direct (origin at center)

y
r
a
n
i
b

s ∆ basis⋆
canonical

i
s
a
b

n
i
m

hard
soft (τ = 0.5)⋆
soft (τ = 1.0)

. learnable origins⋆
m
a
r
a
p

direct (origin at corner)
direct (origin at center)

e
s
n
e
d

s ∆ basis⋆
canonical

i
s
a
b

n
i
m

hard
soft (τ = 0.5)⋆
soft (τ = 1.0)

1

±
±
±

±
±

±

±
±
±

±
±

±

97.8
97.4
98.0

97.8
96.3

97.8

87.3
86.7
83.0

87.3
88.6

89.1

0.7
1.0
0.5

0.7
1.9

0.7

2.5
3.0
6.1

2.5
1.4

2.8

2

±
±
±

±
±

±
±
±

±
±
±

±
±

±
±
±

10.1
7.0
0.6

10.1
4.1

13.2
10.1
2.2

11.6
3.6
13.2

11.6
1.6

15.1
11.6
12.1

94.2
94.9
97.1

94.2
70.8

83.1
94.2
95.7

70.2
74.6
43.8

70.2
71.6

70.8
70.2
73.0

4

±
±
±

±
±

±
±
±

±
±
±

±
±

±
±
±

13.5
26.8
19.1

13.5
3.2

18.9
13.5
14.1

10.4
13.7
3.1

10.4
4.1

10.7
10.4
11.7

77.4
59.0
70.5

77.4
14.4

55.4
77.4
70.2

29.6
32.6
11.6

29.6
26.8

21.4
29.6
31.9

8

±
±
±

±
±

±
±
±

±
±
±

±
±

±
±
±

12.4
10.3
5.9

12.4
0.9

8.7
12.4
9.7

1.2
0.5
0.5

1.2
0.7

2.1
1.2
1.5

46.5
26.9
44.6

46.5
2.7

37.7
46.5
36.0

2.3
2.8
1.1

2.3
4.0

2.2
2.3
2.2

Table 9: Ablations of CombOptNet on Weighted Set Covering. Reported is evaluation accuracy (y = y∗
in %) for m = 4, 6, 8, 10 ground-truth constraints. Statistics are over 20 restarts (2 for each of the 10
dataset seeds).

.

m
a
r
a
p

s
i
s
a
b

n
i
m

Method

learnable origins⋆
direct (origin at corner)
direct (fixed origin at 0)

∆ basis⋆
canonical

hard
soft (τ = 0.5)⋆
soft (τ = 1.0)
soft (τ = 2.0)
soft (τ = 5.0)

4

±
±
±

±
±

±
±
±
±
±

0.0
2.9
0.6

0.0
13.3

13.4
0.0
0.4
3.1
11.1

100
99.4
99.9

100
8.4

88.2
100
99.9
98.8
97.5

6

±
±
±

±
±

±
±
±
±
±

6.4
16.4
6.4

6.4
2.6

14.6
6.4
9.6
14.3
9.1

97.2
94.1
87.6

97.2
2.0

64.3
97.2
95.6
90.6
90.2

8

±
±
±

±
±

±
±
±
±
±

12.1
15.7
11.9

12.1
0.3

14.1
12.1
15.5
12.5
11.8

79.7
78.5
65.3

79.7
0.2

45.1
79.7
70.3
66.4
64.2

10

±
±
±

±
±

±
±
±
±
±

14.8
17.9
11.5

14.8
0.1

17.4
14.8
16.4
9.5
10.4

56.7
47.7
46.7

56.7
0.0

32.3
56.7
51.2
51.2
49.7

CombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints

16

and then decomposing the projected gradient

Proof of Proposition 1. We prove that

dyproj = y

y′

proj

−

(13)

into integer steps as before.

B.2. Decomposition vs. Ground Truth

In the case of direct access to the ground-truth solution
y∗ (i.e. when CombOptNet is the last component in the
architecture), we can always use y∗ as a replacement for our
targets y′
k, and there is no need to decompose the incoming
gradient. In our demonstrations, we do in principle have
access to y∗, but, we still employ our decomposition to
demonstrate the applicability of CombOptNet also in the
general case.

B.3. Proofs

To recover the situation from the method section, set x as
one of the inputs A, b, or c.
Proposition 2. Let y : Rℓ
∈
Rn.
Rℓ and let L : Rn
Denote dy = ∂L/∂y at y. Then the distance between y(x)
and y
dy is minimized along the direction ∂L/∂x, where
∂L/∂x stands for the derivative of L(y(x)) at x.

R be differentiable at y = y(x)

Rn be differentiable at x

→

→

−

∈

Proof. For ξ
y(x

∈

−

ξ) and the target y(x)

dy, i.e.

Rℓ, let φ(ξ) denote the distance between

φ(ξ) = ⃦

⃦y(x

y(x) + dy⃦
⃦.

−

−
There is nothing to prove when dy = 0 as y(x) = y
dy
and there is no room for any improvement. Otherwise, φ is
positive and differentiable in a neighborhood of zero. The
Fr´echet derivative of φ reads as

−

−
ξ)

φ′(ξ) = −

[︁y(x
ξ)
−
⃦
⃦y(x

−
−

hence

y(x) + dy]︁
ξ)

∂y
∂x (x
·
y(x) + dy⃦
⃦

−

ξ)

,

−

φ′(0) =

1
dy
∥

∥

−

∂L
∂y ·

∂y
∂x

=

−

1
dy
∥

∥

∂L
∂x

,

(14)

where the last equality follows by the chain rule. There-
fore, the direction of the steepest descent coincides with the
direction of the derivative ∂L/∂x, as

is a scalar.

dy

∥

∥

n
∑︂

j=ℓ

ujekj =

n
∑︂

j=ℓ

λj∆j

uℓ

|

− |

ℓ−1
∑︂

j=1

sign(uj)ekj

(15)

for every ℓ = 1, . . . , n, where we abbreviate uj = dykj .
The claimed equality (3) then follows from (15) in the spe-
cial case ℓ = 1.
We proceed by induction. In the first step we show (15) for
ℓ = n. Definition of ∆n (9) yields

λn∆n

un

|

− |

n−1
∑︂

j=1

sign(uj)ekj

sign(uj)ekj − |

un

|

n−1
∑︂

j=1

sign(uj)ekj

n
∑︂

=

un
|

|

j=1
= unekn .

Now, assume that (15) holds for ℓ + 1
(15) holds for ℓ as well. Indeed,

≥

2. We show that

n
∑︂

j=ℓ

λj∆j

uℓ

|

− |

ℓ−1
∑︂

j=1

sign(uj)ekj

n
∑︂

=

j=ℓ+1

λj∆j

uℓ+1

− |

ℓ
∑︂

|

j=1

sign(uj)ekj + λℓ∆ℓ

uℓ+1

+

|

ℓ
∑︂

|

j=1

sign(uj)ekj − |

uℓ

|

ℓ−1
∑︂

j=1

sign(uj)ekj

n
∑︂

=

j=ℓ+1

ujekj + (︁

uℓ

|

| − |

uℓ+1

|

ℓ
∑︂

)︁

j=1

sign(uj)ekj

uℓ+1

+

|

ℓ
∑︂

|

j=1

sign(uj)ekj − |

uℓ

|

ℓ−1
∑︂

j=1

sign(uj)ekj

n
∑︂

=

j=ℓ+1

uℓ
ujekj + sign(uℓ)
|

|

ekℓ =

n
∑︂

j=ℓ

ujekj ,

where we used the definitions of ∆ℓ and λℓ.

