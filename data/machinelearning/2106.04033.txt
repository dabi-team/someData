1
2
0
2

n
u
J

8

]
I

A
.
s
c
[

1
v
3
3
0
4
0
.
6
0
1
2
:
v
i
X
r
a

Sample Complexity of Tree Search Conﬁguration:
Cutting Planes and Beyond

Maria-Florina Balcan∗

Siddharth Prasad†

Tuomas Sandholm‡

Ellen Vitercik§

June 9, 2021

Abstract

Cutting-plane methods have enabled remarkable successes in integer programming over the
last few decades. State-of-the-art solvers integrate a myriad of cutting-plane techniques to speed
up the underlying tree-search algorithm used to ﬁnd optimal solutions. In this paper we prove
the ﬁrst guarantees for learning high-performing cut-selection policies tailored to the instance
distribution at hand using samples. We ﬁrst bound the sample complexity of learning cutting
planes from the canonical family of Chv´atal-Gomory cuts. Our bounds handle any number of
waves of any number of cuts and are ﬁne tuned to the magnitudes of the constraint coeﬃcients.
Next, we prove sample complexity bounds for more sophisticated cut selection policies that use
a combination of scoring rules to choose from a family of cuts. Finally, beyond the realm of
cutting planes for integer programming, we develop a general abstraction of tree search that
captures key components such as node selection and variable selection. For this abstraction, we
bound the sample complexity of learning a good policy for building the search tree.

1 Introduction

Integer programming is one of the most broadly-applicable tools in computer science, used to
formulate problems from operations research (such as routing, scheduling, and pricing), machine
learning (such as adversarially-robust learning, MAP estimation, and clustering), and beyond.
Branch-and-cut (B&C) is the most widely-used algorithm for solving integer programs (IPs). B&C
is highly conﬁgurable, and with a deft conﬁguration, it can be used to solve computationally
challenging problems. Finding a good conﬁguration, however, is a notoriously diﬃcult problem.

We study machine learning approaches to conﬁguring policies for selecting cutting planes, which
have an enormous impact on B&C’s performance [4, 11, 12, 17, 33]. At a high level, B&C works
by recursively partitioning the IP’s feasible region, searching for the locally optimal solution within
each set of the partition, until it can verify that it has found the globally optimal solution. An
IP’s feasible region is deﬁned by a set of linear inequalities Ax ≤ b and integer constraints x ∈ Zn,
where n is the number of variables. By dropping the integrality constraints, we obtain the linear
programming (LP) relaxation of the IP, which can be solved eﬃciently. A cutting plane is a
carefully-chosen linear inequality αT x ≤ β which reﬁnes the LP relaxation’s feasible region without
separating any integral point. Intuitively, a well-chosen cutting plane will remove a large portion

∗Computer Science Department, Machine Learning Department, Carnegie Mellon University. ninamf@cs.cmu.edu
†Computer Science Department, Carnegie Mellon University. sprasad2@cs.cmu.edu
‡Computer Science Department, Carnegie Mellon University, Optimized Markets, Inc., Strategic Machine, Inc.,

Strategy Robot, Inc. sandholm@cs.cmu.edu

§Computer Science Department, Carnegie Mellon University. vitercik@cs.cmu.edu

1

 
 
 
 
 
 
of the LP relaxation’s feasible region, speeding up the time it takes B&C to ﬁnd the optimal
solution to the original IP. Cutting plane selection is a crucial task, yet it is challenging because
many cutting planes and cut-selection policies have tunable parameters, and the best conﬁguration
depends intimately on the application domain.

We provide the ﬁrst provable guarantees for learning high-performing cutting planes and cut-
selection policies, tailored to the application at hand. We model the application domain via an
unknown, application-speciﬁc distribution over IPs, as is standard in the literature on using machine
learning for integer programming [e.g., 20, 22, 30, 36, 43]. For example, this could be a distribution
over the routing IPs that a shipping company must solve day after day. The learning algorithm’s
input is a training set sampled from this distribution. The goal is to use this training set to learn
cutting planes and cut-selection policies with strong future performance on problems from the
same application but which are not already in the training set—or more formally, strong expected
performance.

1.1 Summary of main contributions and overview of techniques

As our ﬁrst main contribution, we bound the sample complexity of learning high-performing cutting
planes. Fixing a family of cutting planes, these guarantees bound the number of samples suﬃcient
to ensure that for any sequence of cutting planes from the family, its average performance over
the samples is close to its expected performance. We measure performance in terms of the size of
the search tree B&C builds. Our guarantees apply to the parameterized family of Chv´atal-Gomory
(CG) cuts [11, 17], one of the most widely-used families of cutting planes.

The overriding challenge is that to provide guarantees, we must analyze how the tree size
changes as a function of the cut parameters. This is a sensitive function: slightly shifting the
parameters can cause the tree size to shift from constant to exponential in the number of variables.
Our key technical insight is that as the parameters vary, the entries of the cut (i.e., the vector α
and oﬀset β of the cut αT x ≤ β) are multivariate polynomials of bounded degree. The number of
terms deﬁning the polynomials is exponential in the number of parameters, but we show that the
polynomials can be embedded in a space with dimension sublinear in the number of parameters.
This insight allows us to better understand tree size as a function of the parameters. We then
leverage results by Balcan et al. [9] that show how to use structure exhibited by dual functions
(measuring an algorithm’s performance, such as its tree size, as a function of its parameters) to
derive sample complexity bounds.

Our second main contribution is a sample complexity bound for learning cut-selection policies,
which allow B&C to adaptively select cuts as it solves the input IP. These cut-selection policies
assign a number of real-valued scores to a set of cutting planes and then apply the cut that has
the maximum weighted sum of scores. Tree size is a volatile function of these weights, though we
prove that it is piecewise constant, as illustrated in Figure 1, which allows us to prove our sample
complexity bound.

Finally, as our third main contribution, we provide guarantees for tuning weighted combinations
of scoring rules for other aspects of tree search beyond cut selection, including node and variable
selection. We prove that there is a set of hyperplanes splitting the parameter space into regions
such that if tree search uses any conﬁguration from a single region, it will take the same sequence
of actions. This structure allows us to prove our sample complexity bound. This is the ﬁrst paper
to provide guarantees for tree search conﬁguration that apply simultaneously to multiple diﬀerent
aspects of the algorithm—prior research was speciﬁc to variable selection [6].

2

Figure 1: Two examples of tree size as a function of a SCIP cut-selection parameter µ (the directed
cutoﬀ distance weight, deﬁned in Section 2) on IPs generated from the Combinatorial Auctions
Test Suite [29] (the “regions” generator with 600 bids and 600 goods). SCIP [16] is the leading
open-source IP solver.

1.2 Related work

Applied research on tree search conﬁguration. Over the past decade, a substantial literature
has developed on the use of machine learning for integer programming and tree search [e.g., 2, 8, 10,
13, 19, 22–24, 28, 30–32, 35, 36, 41–43]. This has included research that improves speciﬁc aspects
of B&C such as variable selection [2, 13, 23, 28, 31, 41], node selection [19, 35], and heuristic
scheduling [24]. These papers are applied, whereas we focus on providing theoretical guarantees.

With respect to cutting plane selection, the focus of this paper, Sandholm [36] uses machine
learning techniques to customize B&C for combinatorial auction winner determination, including
cutting plane selection. Tang et al. [37] study machine learning approaches to cutting plane se-
lection. They formulate this problem as a reinforcement learning problem and show that their
approach can outperform human-designed heuristics for a variety of tasks. Meanwhile, the focus
of our paper is to provide the ﬁrst provable guarantees for cutting plane selection via machine
learning.

Ferber et al. [15] study a problem where the IP objective vector c is unknown, but an estimate
ˆc can be obtained from data. Their goal is to optimize the quality of the solutions obtained by
solving the IP deﬁned by ˆc. They do so by formulating the IP as a diﬀerentiable layer in a neural
network. The nonconvex nature of the IP does not allow for straightforward gradient computations,
so they obtain a continuous surrogate using cutting planes.

Provable guarantees for algorithm conﬁguration. Gupta and Roughgarden [18] initiated
the study of sample complexity bounds for algorithm conﬁguration. A chapter by Balcan [5]
provides a comprehensive survey. In research most related to ours, Balcan et al. [6] provide sample
complexity bounds for learning tree search variable selection policies (VSPs). They prove their
bounds by showing that for any IP, hyperplanes partition the VSP parameter space into regions
where the B&C tree size is a constant function of the parameters. The analysis in this paper
requires new techniques because although we prove that the B&C tree size is a piecewise-constant
function of the CG cutting plane parameters, the boundaries between pieces are far more complex
than hyperplanes: they are hypersurfaces deﬁned by multivariate polynomials.

Kleinberg et al. [25, 26] and Weisz et al. [38, 39] design conﬁguration procedures for runtime
minimization that come with theoretical guarantees. Their algorithms are designed for the case
where there are ﬁnitely-many parameter settings to choose from (although they are still able to

3

provide guarantees for inﬁnite parameter spaces by running their procedure on a ﬁnite sample
of conﬁgurations; Balcan et al. [6, 7] analyze when discretization approaches can and cannot be
gainfully employed). In contrast, our guarantees are designed for inﬁnite parameter spaces.

2 Problem formulation

In this section we give a more detailed technical overview of branch-and-cut, as well as an overview
of the tools from learning theory we use to prove sample complexity guarantees.

2.1 Branch-and-cut

We study integer programs (IPs) in canonical form given by

LP ∈ Zn), then the procedure terminates—x∗

max (cid:8)cT x : Ax ≤ b, x ≥ 0, x ∈ Zn(cid:9) ,
(1)
where A ∈ Zm×n, b ∈ Zm, and c ∈ Rn. Branch-and-cut (B&C) works by recursively partitioning the
input IP’s feasible region, searching for the locally optimal solution within each set of the partition
until it can verify that it has found the globally optimal solution. It organizes this partition as
It begins by solving the LP relaxation of
a search tree, with the input IP stored at the root.
the input IP; we denote the solution as x∗
LP satisﬁes the IP’s integrality constraints
(x∗
LP is the globally optimal solution. Otherwise, it uses
a variable selection policy to choose a variable x[i]. In the left child of the root, it stores the original
IP with the additional constraint that x[i] ≤ (cid:98)x∗
LP[i](cid:99), and in the right child, with the additional
constraint that x[i] ≥ (cid:100)x∗
LP[i](cid:101). It then uses a node selection policy to select a leaf of the tree and
repeats this procedure—solving the LP relaxation and branching on a variable. B&C can fathom
a node, meaning that it will stop searching along that branch, if 1) the LP relaxation satisﬁes the
IP’s integrality constraints, 2) the LP relaxation is infeasible, or 3) the objective value of the LP
relaxation’s solution is no better than the best integral solution found thus far. We assume there
is a bound κ on the size of the tree we allow B&C to build before we terminate, as is common in
prior research [6, 20, 25, 26].

LP ∈ Rn. If x∗

Cutting planes are a means of ensuring that at each iteration of B&C, the solution to the LP

relaxation is as close to the optimal integral solution as possible. Formally, let

P = {x ∈ Rn : Ax ≤ b, x ≥ 0}
denote the feasible region obtained by taking the LP relaxation of IP (1). Let PI = conv(P ∩ Zn)
denote the integer hull of P. A valid cutting plane is any hyperplane αT x ≤ β such that if x
is in the integer hull (x ∈ PI ), then x satisﬁes the inequality αT x ≤ β. In other words, a valid
cut does not remove any integral point from the LP relaxation’s feasible region. A valid cutting
plane separates x ∈ P \ PI if it does not satisfy the inequality, or in other words, αT x > β. At
any node of the search tree, B&C can add valid cutting planes that separate the optimal solution
to the node’s LP relaxation, thus improving the solution estimates used to prune the search tree.
However, adding too many cuts will increase the time it takes to solve the LP relaxation at each
node. Therefore, solvers such as SCIP [16], the leading open-source solver, bound the number of
cuts that will be applied.

A famous class of cutting planes is the family of Chv´atal-Gomory (CG) cuts 1 [11, 17], which

are parameterized by vectors u ∈ Rm. The CG cut deﬁned by u ∈ Rm is the hyperplane

(cid:4)uT A(cid:5) x ≤ (cid:4)uT b(cid:5) ,

1The set of CG cuts is equivalent to the set of Gomory (fractional) cuts [12], another commonly studied family of

cutting planes with a slightly diﬀerent parameterization.

4

(a) Eﬃcacy

(b) Better objective
parallelism

(c) Worse objective
parallelism

(d) Better directed
cutoﬀ distance

(e) Worse directed
cutoﬀ distance

Figure 2: Illustration of scoring rules. In each ﬁgure, the blue region is the feasible region, the
black dotted line is the cut in question, the blue solid line is orthogonal to the objective c, the
black dot is the LP optimal solution, and the white dot is the incumbent IP solution. Figure 2a
illustrates eﬃcacy, which is the length of the black solid line between the cut and the LP optimal
solution. The cut in Figure 2b has better objective parallelism than the cut in Figure 2c. The cut
in Figure 2d has a better directed cutoﬀ distance than the cut in Figure 2e, but both have the same
eﬃcacy.

which is guaranteed to be valid. Throughout this paper we primarily restrict our attention to
u ∈ [0, 1)m. This is without loss of generality, since the facets of

P ∩ {x ∈ Rn : (cid:98)uT A(cid:99)x ≤ (cid:98)uT b(cid:99) ∀u ∈ Rm}

can be described by the ﬁnitely many u ∈ [0, 1)m such that uT A ∈ Zn [11].

Some IP solvers such as SCIP use scoring rules to select among cutting planes, which are meant
to measure the quality of a cut. Some commonly-used scoring rules include eﬃcacy [4] (score1),
objective parallelism [1] (score2), directed cutoﬀ distance [16] (score3), and integral support [40]
(score4) (deﬁned in Appendix A). Eﬃcacy measures the distance between the cut αT x ≤ β and
x∗

LP:

score1(αT x ≤ β) =

αT x∗

LP − β

(cid:107)α(cid:107)2

,

as illustrated in Figure 2a. Objective parallelism measures the angle between the objective c and
the cut’s normal vector α:

score2(αT x ≤ β) =

(cid:12)cT α(cid:12)
(cid:12)
(cid:12)
(cid:107)α(cid:107)2 (cid:107)c(cid:107)2

,

as illustrated in Figures 2b and 2c. Directed cutoﬀ distance measures the distance between the LP
optimal solution and the cut in a more relevant direction than the eﬃcacy scoring rule. Speciﬁcally,
let x be the incumbent solution, which is the best-known feasible solution to the input IP. The
directed cutoﬀ distance is the distance between the hyperplane (α, β) and the current LP solution
x∗

LP along the direction of the incumbent x, as illustrated in Figures 2d and 2e:

score3(αT x ≤ β) =

αT x∗
LP − β
(cid:12)
(cid:12)αT (cid:0)x − x∗

LP

(cid:1)(cid:12)
(cid:12)

· (cid:107)x − x∗

LP(cid:107)2 .

SCIP [16] uses the scoring rule

3
5

score1 +

1
10

score2 +

1
2

score3 +

1
10

score4.

5

2.2 Learning theory background

The goal of this paper is to learn cut-selection policies using samples in order to guarantee, with
high probability, that B&C builds a small tree in expectation on unseen IPs. To this end, we rely on
the notion of pseudo-dimension [34], a well-known measure of a function class’s intrinsic complexity.
The pseudo-dimension of a function class F ⊆ RY , denoted Pdim(F ), is the largest integer N for
which there exist N inputs y1, . . . , yN ∈ Y and N thresholds r1, . . . , rN ∈ R such that for every
(σ1, . . . , σN ) ∈ {0, 1}N , there exists f ∈ F such that f (yi) ≥ ri if and only if σi = 1. Function
classes with bounded pseudo-dimension satisfy the following uniform convergence guarantee [3, 34].
Let [−κ, κ] be the range of the functions in F , let

NF (ε, δ) = O

(cid:18)

(cid:18) κ2
ε2

Pdim(F ) + ln

(cid:19)(cid:19)(cid:19)

,

(cid:18) 1
δ

and let N ≥ NF (ε, δ). For all distributions D on Y, with probability 1 − δ over the draw of
y1, . . . , yN ∼ D, for every function f ∈ F , the average value of f over the samples is within ε of its
expected value:

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
N

N
(cid:88)

i=1

f (yi) − E
y∼D

(cid:12)
(cid:12)
(cid:12)
[f (y)]
(cid:12)
(cid:12)

≤ ε.

The quantity NF (ε, δ) is the sample complexity of F .

3 Learning Chv´atal-Gomory cuts

In this section we bound the sample complexity of learning CG cuts at the root node of the B&C
search tree. We warm up by analyzing the case where a single CG cut is added at the root
(Section 3.1), and then build on this analysis to handle W sequential waves of k simultaneous
CG cuts (Section 3.3). This means that all k cuts in the ﬁrst wave are added simultaneously, the
new (larger) LP relaxation is solved, all k cuts in the second wave are added to the new problem
simultaneously, and so on. B&C adds cuts in waves because otherwise the angles between cuts
would become obtuse, leading to numerical instability. Moreover, many commercial IP solvers
only add cuts at the root because those cuts can be leveraged throughout the tree. However, in
Section 5, we also provide guarantees for applying cuts throughout the tree. In this section, we
assume that all aspects of B&C (such as node selection and variable selection) are ﬁxed except for
the cuts applied at the root of the search tree.

3.1 Learning a single cut

To provide sample complexity bounds, as per Section 2.2, we bound the pseudo-dimension of the
set of functions fu for u ∈ [0, 1]m, where fu(c, A, b) is the size of the tree B&C builds when it
applies the CG cut deﬁned by u at the root. To do so, we take advantage of structure exhibited by
the class of dual functions, each of which is deﬁned by a ﬁxed IP (c, A, b) and measures tree size as
c,A,b : [0, 1]m → R is deﬁned
a function of the parameters u. In other words, each dual function f ∗
as f ∗
c,A,b(u) = fu(c, A, b). Our main result in this section is a proof that the dual functions are
well-structured (Lemma 3.2), which then allows us to apply a result by Balcan et al. [9] to bound
Pdim({fu : u ∈ [0, 1]m}) (Theorem 3.3). Proving that the dual functions are well-structured is
challenging because they are volatile: slightly perturbing u can cause the tree size to shift from
constant to exponential in n, as we prove in the following theorem. The full proof is in Appendix B.

6

(a) Cut produced when 1
3 . The
grey solid region is the set of points x such that
x[1] + x[2] ≤ 1.

2 ≤ u[1] − u[2] < 2

(b) Cut produced when 2
3 ≤ u[1] − u[2] < 1. The
grey solid region is the set of points x such that
x[1] + x[2] ≤ 2.

Figure 3: Illustration of Theorem 3.1 when n = 3, projected onto the x[3] = 0 plane. The blue
solid line is the feasible region 2x[1] + 2x[2] = 3. The black dotted lines are the cut.

Theorem 3.1. For any integer n, there exists an integer program (c, A, b) with two constraints
and n variables such that if 1
2n , then applying the CG cut deﬁned by u at the
root causes B&C to terminate immediately. Meanwhile, if n+1
2n ≤ u[1] − u[2] < 1, then applying the
CG cut deﬁned by u at the root causes B&C to build a tree of size at least 2(n−1)/2.

2 ≤ u[1] − u[2] < n+1

Proof sketch. Without loss of generality, assume that n is odd. Consider an IP with constraints
2(x[1] + · · · + x[n]) ≤ n, −2(x[1] + · · · + x[n]) ≤ −n, x ∈ {0, 1}n, and any objective. This IP is
infeasible because n is odd. Jeroslow [21] proved that without the use of cutting planes or heuristics,
2 ≤ u[1]−u[2] < n+1
B&C will build a tree of size 2(n−1)/2 before it terminates. We prove that when 1
2n ,
the CG cut halfspace deﬁned by u = (u[1], u[2]) has an empty intersection with the feasible region
of the IP, causing B&C to terminate immediately. This is illustrated in Figure 3a. On the other
hand, we show that if n+1
2n ≤ u[1] − u[2] < 1, then the CG cut halfspace deﬁned by u contains
the feasible region of the IP, and thus leaves the feasible region unchanged. This is illustrated by
Figure 3b. In this case, due to Jeroslow [21], applying this CG cut at the root will cause B&C to
build a tree of size at least 2(n−1)/2 before it terminates.

This theorem shows that the dual tree-size functions can be extremely sensitive to perturbations
in the CG cut parameters. However, we are able to prove that the dual functions are piecewise-
constant.

Lemma 3.2. For any IP (c, A, b), there are O((cid:107)A(cid:107)1,1 +(cid:107)b(cid:107)1,1 +n) hyperplanes that partition [0, 1]m
into regions where in any one region R, the dual function f ∗
Proof. Let a1, . . . , an ∈ Rm be the columns of A. Let Ai = (cid:107)ai(cid:107)1 and B = (cid:107)b(cid:107)1, so for any
u ∈ [0, 1]m, (cid:4)uT ai

(cid:5) ∈ [−Ai, Ai] and (cid:4)uT b(cid:5) ∈ [−B, B]. For each integer ki ∈ [−Ai, Ai], we have

c,A,b(u) is constant for all u ∈ R.

(cid:4)uT ai

(cid:5) = ki ⇐⇒ ki ≤ uT ai < ki + 1.

There are (cid:80)n
i=1 2Ai + 1 = O((cid:107)A(cid:107)1,1 + n) such halfspaces, plus an additional 2B + 1 halfspaces of
the form kn+1 ≤ uT b < kn+1 + 1 for each kn+1 ∈ {−B, . . . , B}. In any region R deﬁned by the
intersection of these halfspaces, the vector ((cid:98)uT a1(cid:99), . . . , (cid:98)uT an(cid:99), (cid:98)uT b(cid:99)) is constant for all u ∈ R,
and thus so is the resulting cut.

Combined with the main result of Balcan et al. [9], this lemma implies the following bound.

Theorem 3.3. Let Fα,β denote the set of all functions fu for u ∈ [0, 1]m deﬁned on the domain
of IPs (c, A, b) with (cid:107)A(cid:107)1,1 ≤ α and (cid:107)b(cid:107)1 ≤ β. Then, Pdim(Fα,β) = O(m log(m(α + β + n))).

This theorem implies that (cid:101)O(κ2m/ε2) samples are suﬃcient to ensure that with high probability,
for every CG cut, the average size of the tree B&C builds upon applying the cutting plane is within
(cid:15) of the expected size of the tree it builds (the (cid:101)O notation suppresses logarithmic terms).

7

3.2 Learning a sequence of cuts

We now determine the sample complexity of making W sequential CG cuts at the root. The ﬁrst
cut is deﬁned by m parameters u1 ∈ [0, 1]m for each of the m constraints. Its application leads to
the addition of the row (cid:98)uT
1 b(cid:99) to the constraint matrix. The next cut is then deﬁned by
m + 1 parameters u2 ∈ [0, 1]m+1 since there are now m + 1 constraints. Continuing in this fashion,
the W th cut is deﬁned by m + W − 1 parameters uW ∈ [0, 1]m+W −1. Let fu1,...,uW (c, A, b) be the
size of the tree B&C builds when it applies the CG cut deﬁned by u1, then applies the CG cut
deﬁned by u2 to the new IP, and so on, all at the root of the search tree.

1 A(cid:99)x ≤ (cid:98)uT

As in Section 3.1, we bound the pseudo-dimension of the functions fu1,...,uW by analyzing the
structure of the dual functions f ∗
c,A,b, which measure tree size as a function of the parameters
u1, . . . , uW . Speciﬁcally, f ∗
c,A,b(u1, . . . , uW ) =
fu1,...,uW (c, A, b). The analysis in this section is more complex because the wth cut (with w ∈
{2, . . . , W }) depends not only on the parameters uw but also on u1, . . . , uw−1. We prove that the
dual functions are again piecewise-constant, but in this case, the boundaries between pieces are
hypersurfaces deﬁned by multivariate polynomials rather than hyperplanes. The full proof is in
Appendix B.

c,A,b : [0, 1]m × · · · × [0, 1]m+W −1 → R, where f ∗

Lemma 3.4. For any IP (c, A, b), there are O(W 2W (cid:107)A(cid:107)1,1 + 2W (cid:107)b(cid:107)1 + nW ) multivariate polyno-
mials in ≤ W 2 + mW variables of degree ≤ W that partition [0, 1]m × · · · × [0, 1]m+W −1 into regions
where in any one region R, f ∗

c,A,b(u1, . . . , uW ) is constant for all (u1, . . . , uW ) ∈ R.

Proof sketch. Let a1, . . . , an ∈ Rm be the columns of A. For u1 ∈ [0, 1]m, . . . , uW ∈ [0, 1]m+W −1,
deﬁne (cid:101)a1
i ∈ [0, 1]m+W −1 for each i ∈ [n] such that (cid:101)aw
is the ith column of the
constraint matrix after applying cuts u1, . . . , uw−1. Similarly, deﬁne (cid:101)bw to be the constraint vector
after applying the ﬁrst w − 1 cuts. In other words, we have the recurrence relation

i ∈ [0, 1]m, . . . , (cid:101)aW

i

(cid:101)a1
i = ai
(cid:20)

(cid:101)aw
i =

i

(cid:101)aw−1
w−1(cid:101)aw−1
uT

i

(cid:21)

(cid:101)b1 = b
(cid:34)

(cid:101)bw =

(cid:101)bw−1
w−1(cid:101)bw−1

uT

(cid:35)

for w = 2, . . . , W . We prove, by induction, that (cid:4)uT
integer ki in this interval,

w (cid:101)aw

i

(cid:5) ∈ (cid:2)−2w−1 (cid:107)ai(cid:107)1 , 2w−1 (cid:107)ai(cid:107)1

(cid:3) . For each

(cid:4)uT

w (cid:101)aw

i

(cid:5) = ki ⇐⇒ ki ≤ uT

w (cid:101)aw

i < ki + 1.

The boundaries of these surfaces are deﬁned by polynomials over uw in ≤ mw + w2 variables with
degree ≤ w. Counting the total number of such hypersurfaces yields the lemma statement.

We now use this structure to provide a pseudo-dimension bound. The full proof is in Ap-

pendix B.

Theorem 3.5. Let Fα,β denote the set of all functions fu1,...,uW for u1 ∈ [0, 1]m, . . . , uW ∈
[0, 1]m+W −1 deﬁned on the domain of integer programs (c, A, b) with (cid:107)A(cid:107)1,1 ≤ α and (cid:107)b(cid:107)1 ≤ β.
Then, Pdim(Fα,β) = O(mW 2 log(mW (α + β + n))).

Proof sketch. The space of 0/1 classiﬁers induced by the set of degree ≤ W multivariate polyno-
mials in W 2 + mW variables has VC dimension O((W 2 + mW ) log W ) [3]. However, we more

8

carefully examine the structure of the polynomials considered in Lemma 3.4 to give an improved
VC dimension bound of 1 + mW . For each j = 1, . . . , m deﬁne (cid:101)u1[j], . . . , (cid:101)uW [j] recursively as

(cid:101)u1[j] = u1[j]

(cid:101)uw[j] = uw[j] +

w−1
(cid:88)

(cid:96)=1

uw[m + (cid:96)](cid:101)u(cid:96)[j]

for w = 2, . . . , W.

w (cid:101)aw

The space of polynomials induced by the wth cut is contained in span{1, (cid:101)uw[1], . . . , (cid:101)uw[m]}. The
intuition for this is as follows: consider the additional term added by the wth cut to the constraint
matrix, that is, uT
i . The ﬁrst m coordinates (uw[1], . . . , uw[m]) interact only with ai—so uw[j]
collects a coeﬃcient of ai[j]. Each subsequent coordinate uw[m + (cid:96)] interacts with all coordinates
of (cid:101)aw
i arising from the ﬁrst (cid:96) cuts. The term that collects a coeﬃcient of ai[j] is precisely uw[m + (cid:96)]
times the sum of all terms from the ﬁrst (cid:96) cuts with a coeﬃcient of ai[j]. Using standard facts
about the VC dimension of vector spaces and their duals in conjunction with Lemma 3.4 and the
framework of Balcan et al. [9] yields the theorem statement.

The sample complexity of learning W sequential cuts is thus (cid:101)O(κ2mW 2/(cid:15)2).

3.3 Learning waves of simultaneous cuts

W , . . . , uk

W ∈ [0, 1]m+k(W −1), let fu1

We now determine the sample complexity of making W sequential waves of cuts at the root,
1, . . . , uk
each wave consisting of k simultaneous CG cuts. Given vectors u1
1 ∈ [0, 1]m, u1
2 ∈
[0, 1]m+k, . . . , u1
(c, A, b) be the size of the tree
W ,...,uk
W
B&C builds when it applies the CG cuts deﬁned by u1
1, then applies the CG cuts deﬁned by
u1
2 to the new IP, and so on, all at the root of the search tree. The full proof of the following
theorem is in Appendix B, and follows from the observation that W waves of k simultaneous cuts
can be viewed as making kW sequential cuts with the restriction that cuts within each wave assign
nonzero weight only to constraints from previous waves.

1 ,...,u1
1, . . . , uk

2, . . . , uk

2, . . . , uk

1,...,uk

Theorem 3.6. Let Fα,β be the set of all functions fu1
W , . . . , uk
u1
and (cid:107)b(cid:107)1 ≤ β. Then, Pdim(Fα,β) = O(mk2W 2 log(mkW (α + β + n))).

1 ∈ [0, 1]m, . . .,
W ∈ [0, 1]m+k(W −1) deﬁned on the domain of integer programs (c, A, b) with (cid:107)A(cid:107)1,1 ≤ α

1, . . . , uk

W ,...,uk
W

for u1

1 ,...,u1

1,...,uk

This result implies that the sample complexity of learning W waves of k cuts is (cid:101)O(κ2mk2W 2/(cid:15)2).

3.4 Data-dependent guarantees

So far, our guarantees have depended on the maximum possible norms of the constraint matrix and
vector in the domain of IPs under consideration. The uniform convergence result in Section 2.2
for Fα,β only holds for distributions over A and b with norms bounded by α and β, respectively.
In Appendix B.1, we show how to convert these into more broadly applicable data-dependent
guarantees that leverage properties of the distribution over IPs. These guarantees hold without
assumptions on the distribution’s support, and depend on E[maxi (cid:107)Ai(cid:107)1,1] and E[maxi (cid:107)bi(cid:107)1] (where
the expectation is over the draw of N samples), thus giving a sharper sample complexity guarantee
that is tuned to the distribution.

9

4 Learning cut selection policies

In Section 3, we studied the sample complexity of learning waves of speciﬁc cut parameters. In
this section, we bound the sample complexity of learning cut-selection policies at the root, that is,
functions that take as input an IP and output a candidate cut. This is a more nuanced way of
choosing cuts since it allows for the cut parameters to depend on the input IP.

Formally, let Im be the set of IPs with m constraints (the number of variables is always ﬁxed
at n) and let Hm be the set of all hyperplanes in Rm. A scoring rule is a function score :
∪m(Hm × Im) → R≥0. The real value score(αT x ≤ β, (c, A, b)) is a measure of the quality of
the cutting plane αT x ≤ β for the IP (c, A, b). Examples include the scoring rules discussed in
Section 2.1. Given a scoring rule and a family of cuts, a cut-selection policy applies the cut from
the family with maximum score.

Suppose score1, . . . , scored are d diﬀerent scoring rules. We bound the sample complexity of

learning a combination of these scoring rules that guarantees a low expected tree size.

Theorem 4.1. Let C be a set of cutting-plane parameters such that for every IP (c, A, b), there is
a decomposition of C into ≤ r regions such that the cuts generated by any two vectors in the same
region are the same. Let score1, . . . , scored be d scoring rules. For µ ∈ Rd, let fµ(c, A, b) be the
size of the tree B&C builds when it chooses a cut from C to maximize µ[1]score1(·, (c, A, b)) + · · · +
µ[d]scored(·, (c, A, b)). Then, Pdim({fµ : µ ∈ Rd}) = O(d log(rd)).

Proof. Fix an integer program (c, A, b). Let u1, . . . , ur ∈ C be arbitrary cut parameters from each
of the r regions. Consider the hyperplanes

d
(cid:88)

i=1

µ[i]scorei(us) =

d
(cid:88)

i=1

µ[i]scorei(ut)

for each s (cid:54)= t ∈ {1, . . . , r} (suppressing the dependence on c, A, b). These O(r2) hyperplanes
partition Rd into regions such that as µ varies in a given region, the cut chosen from C is invariant.
The desired pseudo-dimension bound follows from the main result of Balcan et al. [9].

Theorem 4.1 can be directly instantiated with the class of CG cuts. Combining Lemma 3.2
with the basic combinatorial fact that k hyperplanes partition Rm into at most km regions, we
get that the pseudo-dimension of {fµ : µ ∈ Rd} deﬁned on IPs with (cid:107)A(cid:107)1,1 ≤ α and (cid:107)b(cid:107)1 ≤ β
is O(dm log(d(α + β + n))).
Instantiating Theorem 4.1 with the set of all sequences of W CG
cuts requires the following extension of scoring rules to sequences of cutting planes. A sequential
scoring rule is a function that takes as input an IP (c, A, b) and a sequence of cutting planes
h1, . . . , hW , where each cut lives in one higher dimension than the previous.
It measures the
quality of this sequence of cutting planes when applied one after the other to the original IP.
Every scoring rule score can be naturally extended to a sequential scoring rule score deﬁned by
score(h1, . . . , hW , (c0, A0, b0)) = (cid:80)d−1
i=0 score(hi+1, (ci, Ai, bi)), where (ci, Ai, bi) is the IP after
applying cuts h1, . . . , hi−1.

Corollary 4.2. Let C = [0, 1]m × · · · × [0, 1]m+W −1 denote the set of possible sequences of W
Chv´atal-Gomory cut parameters. Let score1, . . . , scored : C × Im × · · · × Im+W −1 → R be d
sequential scoring rules and let fµ(c, A, b) be as in Theorem 4.1 for the class C. Then, Pdim({f W
µ :
µ ∈ Rd}) = O(dmW 2 log(dW (α + β + n))).

Proof. In Lemma 3.4 and Theorem 3.5 we showed that there are O(W 2W α+2W β+nW ) multivariate
polynomials that belong to a family of polynomials G with VCdim(G∗) ≤ 1 + mW (G∗ denotes the

10

dual of G) that partition C into regions such that resulting sequence of cuts is invariant in each
region. By Claim 3.5 by Balcan et al. [9], the number of regions is

O(W 2W α + 2W β + nW )VCdim(G∗) ≤ O(W 2W α + 2W β + nW )1+mW .

The corollary then follows from Theorem 4.1.

These results bound the sample complexity of learning cut-selection policies based on scoring

rules, which allow the cuts that B&C selects to depend on the input IP.

5 Sample complexity of generic tree search

In this section, we study the sample complexity of selecting high-performing parameters for generic
tree-based algorithms, which are a generalization of B&C. This abstraction allows us to provide
guarantees for simultaneously optimizing key aspects of tree search beyond cut selection, including
node selection and branching variable selection. We also generalize the previous sections by allowing
actions (such as cut selection) to be taken at any stage of the tree search—not just at the root.

Tree search algorithms take place over a series of κ rounds (analogous to the B&C tree-size cap
κ in the previous sections). There is a sequence of t steps that the algorithm takes on each round.
For example, in B&C, these steps include node selection, cut selection, and variable selection. The
speciﬁc action the algorithm takes during each step (for example, which node to select, which
cut to include, or which variable to branch on) typically depends on a scoring rule. This scoring
rule weights each possible action and the algorithm performs the action with the highest weight.
These actions (deterministically) transition the algorithm from one state to another. This high-
level description of tree search is summarized by Algorithm 1. For each step j ∈ [t], the number
of possible actions is Tj ∈ N. There is a scoring rule scorej, where scorej(k, s) ∈ R is the weight
associated with the action k ∈ [Tj] when the algorithm is in the state s.

Algorithm 1 Tree search
Input: Problem instance, t scoring rules score1, . . . , scoret, number of rounds κ.
1: s1,1 ← Initial state of algorithm
2: for each round i ∈ [κ] do
3:

for each step j ∈ [t] do

4:

5:

6:

Perform the action k ∈ [Tj] that maximizes scorej (k, si,j)
si,j+1 ← New state of algorithm

si+1,1 ← si,t+1

(cid:46) State at beginning of next round equals state at end of this round

Output: Incumbent solution in state sκ,t+1, if one exists.

There are often several scoring rules one could use, and it is not clear which to use in which
scenarios. As in Section 4, we provide guarantees for learning combinations of these scoring rules
for the particular application at hand. More formally, for each step j ∈ [t], rather than just a
single scoring rule scorej as in Step 4, there are dj scoring rules scorej,1, . . . , scorej,dj . Given
parameters µj = (µj[1], . . . , µj[dj]) ∈ Rdj , the algorithm takes the action k ∈ [Tj] that maximizes
(cid:80)dj
i=1 µj[i]scorej,i(k, s). There is a distribution D over inputs x to Algorithm 1. For example, when
this framework is instantiated for B&C, x is an integer program (c, A, b). There is a utility function
fµ(x) ∈ [−H, H] that measures the utility of the algorithm parameterized by µ = (µ1, . . . , µt) on
input x. For example, this utility function might measure the size of the search tree that the

11

algorithm builds (in which case one can take H ≤ κ). We assume that this utility function is
ﬁnal-state-constant:

Deﬁnition 5.1. Let µ = (µ1, . . . , µt) and µ(cid:48) = (µ(cid:48)
that we run Algorithm 1 on input x once using the scoring rule scorej = (cid:80)dj
once using the scoring rule scorej = (cid:80)dj
i=1 µ(cid:48)
same ﬁnal state sκ,t+1. The utility function is ﬁnal-state-constant if fµ(x) = fµ(cid:48)(x).

t) be two parameter vectors. Suppose
i=1 µj[i]scorej,i and
j[i]scorej,i. Suppose that on each run, we obtain the

1, . . . , µ(cid:48)

We provide a sample complexity bound for learning the parameters µ. The full proof is in

Appendix C.

Theorem 5.2. Let d = (cid:80)t
Then,

j=1 dj denote the total number of tunable parameters of tree search.

Pdim({fµ : µ ∈ Rd}) = O

dκ

(cid:32)

(cid:33)

log Tj + d log d

.

t
(cid:88)

j=1

Proof sketch. We prove that there is a set of hyperplanes splitting the parameter space into regions
such that if tree search uses any parameter setting from a single region, it will always take the
same sequence of actions (including node, variable, and cut selection). The main subtlety is an
induction argument to count these hyperplanes that depends on the current step of the tree-search
algorithm.

In the context of integer programming, Theorem 5.2 not only recovers the main result of Balcan
et al. [6] for learning variable selection policies, but also yields a more general bound that simul-
taneously incorporates cutting plane selection, variable selection, and node selection. In B&C, the
ﬁrst action of each round is to select a node. Since there are at most κ nodes expanded by B&C,
T1 ≤ κ. The second action is to choose a cutting plane. As in Theorem 4.1, let C be a family of
cutting planes such that for every IP (c, A, b), there is a decomposition of the parameter space into
≤ r regions such that the cuts generated by any two parameters in the same region are the same.
Therefore, T2 ≤ r. The last action is to choose a variable to branch on at that node, so T3 = n.
Applying Theorem 5.2,

Pdim({fµ : µ ∈ Rd}) = O (dκ(log κ + log r + log n) + d log d) .

Ignoring T1 and T2, thereby only learning the variable selection policy, recovers the O(dκ log n +
d log d) bound of Balcan et al. [6].

6 Conclusions and future research

We provided the ﬁrst provable guarantees for using machine learning to conﬁgure cutting planes
and cut-selection policies. We analyzed the sample complexity of learning cutting planes from the
popular family of Chv´atal-Gomory (CG) cuts. We then provided sample complexity guarantees for
learning parameterized cut-selection policies, which allow the branch-and-cut algorithm to adap-
tively apply cuts as it builds the search tree. We showed that this analysis can be generalized to
simultaneously capture various key aspects of tree search beyond cut selection, such as node and
variable selection.

This paper opens up a variety questions for future research. For example, which other cut
families can we learn over with low sample complexity? Section 3 focused on learning within the
family of CG cuts (Sections 4 and 5 applied more generally). There are many other families, such

12

as Gomory mixed-integer cuts and lift-and-project cuts, and a sample complexity analysis of these
is an interesting direction for future research (and would call for new techniques). In addition, can
we use machine learning to design improved scoring rules and heuristics for cut selection?

Acknowledgements

This material is based on work supported by the National Science Foundation under grants IIS-
1718457, IIS-1901403, IIS-1618714, and CCF-1733556, CCF-1535967, CCF-1910321, and SES-
1919453, the ARO under award W911NF2010081, the Defense Advanced Research Projects Agency
under cooperative agreement HR00112020003, an AWS Machine Learning Research Award, an
Amazon Research Award, a Bloomberg Research Grant, and a Microsoft Research Faculty Fellow-
ship.

References

[1] Tobias Achterberg. Constraint Integer Programming. PhD thesis, Technische Universit¨at

Berlin, 2007.

[2] Alejandro Marcos Alvarez, Quentin Louveaux, and Louis Wehenkel. A machine learning-based
approximation of strong branching. INFORMS Journal on Computing, 29(1):185–195, 2017.

[3] Martin Anthony and Peter Bartlett. Neural Network Learning: Theoretical Foundations. Cam-

bridge University Press, 2009.

[4] Egon Balas, Sebasti´an Ceria, and G´erard Cornu´ejols. Mixed 0-1 programming by lift-and-

project in a branch-and-cut framework. Management Science, 42(9):1229–1246, 1996.

[5] Maria-Florina Balcan. Data-driven algorithm design. In Tim Roughgarden, editor, Beyond

Worst Case Analysis of Algorithms. Cambridge University Press, 2020.

[6] Maria-Florina Balcan, Travis Dick, Tuomas Sandholm, and Ellen Vitercik. Learning to branch.

In International Conference on Machine Learning (ICML), 2018.

[7] Maria-Florina Balcan, Tuomas Sandholm, and Ellen Vitercik. Learning to optimize compu-
tational resources: Frugal training with generalization guarantees. In AAAI Conference on
Artiﬁcial Intelligence, 2020.

[8] Maria-Florina Balcan, Tuomas Sandholm, and Ellen Vitercik. Reﬁned bounds for algorithm
conﬁguration: The knife-edge of dual class approximability. In International Conference on
Machine Learning (ICML), 2020.

[9] Maria-Florina Balcan, Dan DeBlasio, Travis Dick, Carl Kingsford, Tuomas Sandholm, and
Ellen Vitercik. How much data is suﬃcient to learn high-performing algorithms? Gener-
alization guarantees for data-driven algorithm design.
In Annual Symposium on Theory of
Computing (STOC), 2021.

[10] Yoshua Bengio, Andrea Lodi, and Antoine Prouvost. Machine learning for combinatorial
optimization: a methodological tour d’horizon. European Journal of Operational Research,
2020.

[11] Vaˇsek Chv´atal. Edmonds polytopes and a hierarchy of combinatorial problems. Discrete

mathematics, 4(4):305–337, 1973.

13

[12] G´erard Cornu´ejols and Yanjun Li. Elementary closures for integer programs. Operations

Research Letters, 28(1):1–8, 2001.

[13] Giovanni Di Liberto, Serdar Kadioglu, Kevin Leo, and Yuri Malitsky. Dash: Dynamic approach
for switching heuristics. European Journal of Operational Research, 248(3):943–953, 2016.

[14] Richard Dudley. Universal Donsker classes and metric entropy. The Annals of Probability, 15

(4):1306–1326, 1987.

[15] Aaron Ferber, Bryan Wilder, Bistra Dilkina, and Milind Tambe. MIPaaL: Mixed integer

program as a layer. In AAAI Conference on Artiﬁcial Intelligence, 2020.

[16] Gerald Gamrath, Daniel Anderson, Ksenia Bestuzheva, Wei-Kun Chen, Leon Eiﬂer, Maxime
Gasse, Patrick Gemander, Ambros Gleixner, Leona Gottwald, Katrin Halbig, Gregor Hendel,
Christopher Hojny, Thorsten Koch, Pierre Le Bodic, Stephen J. Maher, Frederic Matter,
Matthias Miltenberger, Erik M¨uhmer, Benjamin M¨uller, Marc E. Pfetsch, Franziska Schl¨osser,
Felipe Serrano, Yuji Shinano, Christine Tawﬁk, Stefan Vigerske, Fabian Wegscheider, Dieter
Weninger, and Jakob Witzig. The SCIP Optimization Suite 7.0. Technical report, Optimization
Online, March 2020. URL http://www.optimization-online.org/DB_HTML/2020/03/7705.
html.

[17] Ralph E. Gomory. Outline of an algorithm for integer solutions to linear programs. Bulletin

of the American Mathematical Society, 64(5):275 – 278, 1958.

[18] Rishi Gupta and Tim Roughgarden. A PAC approach to application-speciﬁc algorithm selec-

tion. SIAM Journal on Computing, 46(3):992–1017, 2017.

[19] He He, Hal Daume III, and Jason M Eisner. Learning to search in branch and bound algo-

rithms. In Annual Conference on Neural Information Processing Systems (NeurIPS), 2014.

[20] Frank Hutter, Holger H Hoos, Kevin Leyton-Brown, and Thomas St¨utzle. ParamILS: An
automatic algorithm conﬁguration framework. Journal of Artiﬁcial Intelligence Research, 36
(1):267–306, 2009. ISSN 1076-9757.

[21] Robert G Jeroslow. Trivial integer programs unsolvable by branch-and-bound. Mathematical

Programming, 6(1):105–109, 1974.

[22] Serdar Kadioglu, Yuri Malitsky, Meinolf Sellmann, and Kevin Tierney. ISAC—instance-speciﬁc
algorithm conﬁguration. In European Conference on Artiﬁcial Intelligence (ECAI), 2010.

[23] Elias Khalil, Pierre Le Bodic, Le Song, George Nemhauser, and Bistra Dilkina. Learning to

branch in mixed integer programming. In AAAI Conference on Artiﬁcial Intelligence, 2016.

[24] Elias Khalil, Bistra Dilkina, George Nemhauser, Shabbir Ahmed, and Yufen Shao. Learning
to run heuristics in tree search. In International Joint Conference on Artiﬁcial Intelligence
(IJCAI), 2017.

[25] Robert Kleinberg, Kevin Leyton-Brown, and Brendan Lucier. Eﬃciency through procrasti-
nation: Approximately optimal algorithm conﬁguration with runtime guarantees. In Interna-
tional Joint Conference on Artiﬁcial Intelligence (IJCAI), 2017.

[26] Robert Kleinberg, Kevin Leyton-Brown, Brendan Lucier, and Devon Graham. Procrastinating
with conﬁdence: Near-optimal, anytime, adaptive algorithm conﬁguration. Annual Conference
on Neural Information Processing Systems (NeurIPS), 2019.

14

[27] Vladimir Koltchinskii. Rademacher penalties and structural risk minimization. IEEE Trans-

actions on Information Theory, 47(5):1902–1914, 2001.

[28] Michail G Lagoudakis and Michael L Littman. Learning to select branching rules in the DPLL
procedure for satisﬁability. Electronic Notes in Discrete Mathematics, 9:344–359, 2001.

[29] Kevin Leyton-Brown, Mark Pearson, and Yoav Shoham. Towards a universal test suite for
combinatorial auction algorithms. In ACM Conference on Electronic Commerce (ACM-EC),
pages 66–76, Minneapolis, MN, 2000.

[30] Kevin Leyton-Brown, Eugene Nudelman, and Yoav Shoham. Empirical hardness models:
Methodology and a case study on combinatorial auctions. Journal of the ACM, 56(4):1–52,
2009. ISSN 0004-5411.

[31] Jia Hui Liang, Vijay Ganesh, Pascal Poupart, and Krzysztof Czarnecki. Learning rate based
branching heuristic for sat solvers. In International Conference on Theory and Applications of
Satisﬁability Testing, pages 123–140. Springer, 2016.

[32] Andrea Lodi and Giulia Zarpellon. On learning and branching: a survey. TOP: An Oﬃcial
Journal of the Spanish Society of Statistics and Operations Research, 25(2):207–236, 2017.

[33] George Nemhauser and Laurence Wolsey. Integer and Combinatorial Optimization. John Wiley

& Sons, 1999.

[34] David Pollard. Convergence of Stochastic Processes. Springer, 1984.

[35] Ashish Sabharwal, Horst Samulowitz, and Chandra Reddy. Guiding combinatorial optimiza-
tion with UCT. In International Conference on AI and OR Techniques in Constraint Pro-
gramming for Combinatorial Optimization Problems. Springer, 2012.

[36] Tuomas Sandholm. Very-large-scale generalized combinatorial multi-attribute auctions:
In Zvika Neeman, Alvin Roth, and Nir

Lessons from conducting $60 billion of sourcing.
Vulkan, editors, Handbook of Market Design. Oxford University Press, 2013.

[37] Yunhao Tang, Shipra Agrawal, and Yuri Faenza. Reinforcement learning for integer program-

ming: Learning to cut. International Conference on Machine Learning (ICML), 2020.

[38] Gell´ert Weisz, Andr´as Gy¨orgy, and Csaba Szepesv´ari. LeapsAndBounds: A method for ap-
proximately optimal algorithm conﬁguration. In International Conference on Machine Learn-
ing (ICML), 2018.

[39] Gell´ert Weisz, Andr´es Gy¨orgy, and Csaba Szepesv´ari. CapsAndRuns: An improved method
International Conference on Machine

for approximately optimal algorithm conﬁguration.
Learning (ICML), 2019.

[40] Franz Wesselmann and Uwe Suhl.

Implementing cutting plane management and selection

techniques. Technical report, University of Paderborn, 2012.

[41] Wei Xia and Roland Yap. Learning robust search strategies using a bandit-based approach.

In AAAI Conference on Artiﬁcial Intelligence, 2018.

[42] Lin Xu, Frank Hutter, Holger H Hoos, and Kevin Leyton-Brown. Satzilla: portfolio-based
algorithm selection for SAT. Journal of Artiﬁcial Intelligence Research, 32(1):565–606, 2008.

15

[43] Lin Xu, Frank Hutter, Holger H Hoos, and Kevin Leyton-Brown. Hydra-MIP: Automated
algorithm conﬁguration and selection for mixed integer programming. In RCRA workshop on
Experimental Evaluation of Algorithms for Solving Problems with Combinatorial Explosion at
the International Joint Conference on Artiﬁcial Intelligence (IJCAI), 2011.

A Additional background about cutting planes

Integral support [40]. Let Z be the set of all indices (cid:96) ∈ [n] such that α[(cid:96)] (cid:54)= 0. Let ¯Z be the
set of all indices (cid:96) ∈ Z such that the (cid:96)th variable is constrained to be integral. This scoring rule is
deﬁned as

score4(αT x ≤ β) =

(cid:12) ¯Z(cid:12)
(cid:12)
(cid:12)
|Z|

.

Wesselmann and Suhl [40] write that “one may argue that a cut having non-zero coeﬃcients on
many (possibly fractional) integer variables is preferable to a cut which consists mostly of continuous
variables.”

B Omitted results and proofs from Section 3

Proof of Theorem 3.1. Without loss of generality, we assume that n is odd. We deﬁne the integer
program

0

maximize
subject to 2x[1] + · · · + 2x[n] = n
x ∈ {0, 1}n,

(2)

which is infeasible because n is odd. Jeroslow [21] proved that without the use of cutting planes
or heuristics, B&C will build a tree of size 2(n−1)/2 before it terminates. Rewriting the equality
constraint as 2x[1] + · · · + 2x[n] ≤ n and −2 (x[1] + · · · + x[n]) ≤ −n, a CG cut deﬁned by the
vector u ∈ R2

≥0 will have the form

(cid:98)2(u[1] − u[2])(cid:99) (x[1] + · · · + x[n]) ≤ (cid:98)n (u[1] − u[2])(cid:99) .

Suppose that 1

2 ≤ u[1] − u[2] < n+1

2n . On the left-hand-side of the constraint, (cid:98)2(u[1] − u[2])(cid:99) =
1. On the right-hand-side of the constraint, n (u[1] − u[2]) < n+1
is an
integer, which means that (cid:98)n (u[1] − u[2])(cid:99) ≤ n−1
2 . Therefore, the CG cut deﬁned by u satisﬁes the
inequality x[1] + · · · + x[n] ≤ n−1
2 , as illustrated in Figure 3a. The intersection of this halfspace
with the feasible region of the original integer program (Equation (2)) is empty, so applying this
CG cut at the root will cause B&C to terminate immediately.

2 . Since n is odd, n+1

2

Meanwhile, suppose that n+1

2n ≤ u[1]−u[2] < 1. Then it is still the case that (cid:98)2(u[1] − u[2])(cid:99) = 1.
Also, n (u[1] − u[2]) ≥ n+1
2 . Therefore, the CG cut
deﬁned by u dominates the inequality x[1] + · · · + x[n] ≤ n+1
2 , as illustrated in Figure 3b. The
intersection of this halfspace with the feasible region of the original integer program is equal to the
integer program’s feasible region, so by Jeroslow’s result [21], applying this CG cut at the root will
cause B&C to build a tree of size at least 2(n−1)/2 before it terminates.

2 , which means that (cid:98)n (u[1] − u[2])(cid:99) ≥ n+1

Proof of Lemma 3.4. Let a1, . . . , an ∈ Rm be the columns of A. For u1 ∈ [0, 1]m, . . . , uW ∈
[0, 1]m+W −1, deﬁne (cid:101)a1
is

i ∈ [0, 1]m+W −1 for each i = 1, . . . , n such that (cid:101)aw

i ∈ [0, 1]m, . . . , (cid:101)aW

i

16

the ith column of the constraint matrix after applying cuts u1, . . . , uw−1. In other words, (cid:101)a1
[0, 1]m, . . . , (cid:101)aW

i ∈ [0, 1]m+W −1 are deﬁned recursively as

i ∈

(cid:101)a1
i = ai
(cid:20)
(cid:101)aw
i =

i

(cid:101)aw−1
w−1(cid:101)aw−1
uT

i

(cid:21)

for w = 2, . . . , W . Similarly, deﬁne (cid:101)bw to be the constraint vector after applying the ﬁrst w − 1
cuts:

(cid:101)b1 = b
(cid:34)

(cid:101)bw =

(cid:35)

(cid:101)bw−1
w−1(cid:101)bw−1

uT

for w = 2, . . . , W . (These vectors depend on the cut parameters, but we will suppress this depen-
dence for the sake of readability).

We prove this lemma by showing that there are O(W 2W (cid:107)A(cid:107)1,1 + 2W (cid:107)b(cid:107)1 + nW ) hypersurfaces
determined by polynomials that partition [0, 1]m × · · · × [0, 1]m+W −1 into regions where in any one
region R, the W cuts

n
(cid:88)

i=1

(cid:4)uT

1 (cid:101)a1

i

n
(cid:88)

i=1

(cid:4)uT

W (cid:101)aW

i

(cid:5) x[i] ≤

1 (cid:101)b1(cid:107)
(cid:106)
uT

...

(cid:5) x[i] ≤

W (cid:101)bW (cid:107)
(cid:106)
uT

are invariant across all (u1, . . . , uW ) ∈ R. To this end, let Ai = (cid:107)ai(cid:107)1 and B = (cid:107)b(cid:107)1. For each
w ∈ {1, . . . , W }, we claim that

w (cid:101)aw
We prove this by induction. The base case of w = 1 is immediate since (cid:101)a1
Suppose now that the claim holds for w. By the induction hypothesis,

(cid:5) ∈ (cid:2)−2w−1Ai, 2w−1Ai

(cid:4)uT

(cid:3) .

i

i = ai and u ∈ [0, 1]m.

(cid:13)
(cid:13)(cid:101)aw+1

i

(cid:13)
(cid:13)1 =

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:20)
(cid:101)aw
w (cid:101)aw
uT

i

i

(cid:21)(cid:13)
(cid:13)
(cid:13)
(cid:13)1

= (cid:107)(cid:101)aw

i (cid:107)1 + (cid:12)

(cid:12)uT

w (cid:101)aw

i

(cid:12)
(cid:12) ≤ 2 (cid:107)(cid:101)aw

i (cid:107)1 ≤ 2wAi,

so

(cid:4)uT

w+1(cid:101)aw+1

i

(cid:5) ∈ (cid:2)− (cid:13)

(cid:13)(cid:101)aw+1

i

(cid:13)1 , (cid:13)
(cid:13)

(cid:13)(cid:101)aw+1

i

(cid:13)
(cid:13)1

(cid:3) ⊆ [−2wAi, 2wAi],

as desired. Now, for each integer ki ∈ [−2w−1Ai, 2w−1Ai], we have

(cid:4)uT

w (cid:101)aw

i

(cid:5) = ki ⇐⇒ ki ≤ uT

w (cid:101)aw

i < ki + 1.

is a polynomial in variables u1[1], . . . , u1[m], u2[1], . . . , u2[m+1], . . . , uw[1], . . . , uw[m+w−1],

uT
w (cid:101)aw
for a total of ≤ mw + w2 variables. Its degree is at most w. There are thus a total of

i

W
(cid:88)

n
(cid:88)

w=1

i=1

(2 · 2w−1Ai + 1) = O

(cid:16)

W 2W (cid:107)A(cid:107)1,1 + nW

(cid:17)

17

polynomials each of degree at most W plus an additional (cid:80)W
polynomials of degree at most W corresponding to the hypersurfaces of the form

w=1(2 · 2w−1B + 1) = O(2W B + W )

for each w and each kn+1 ∈ {−2w−1B, . . . , 2w−1B}. This yields a total of O(W 2W (cid:107)A(cid:107)1,1+2W (cid:107)b(cid:107)1+
nW ) polynomials in ≤ mW + W 2 variables of degree ≤ W .

kn+1 ≤ uT

w(cid:101)bw < kn+1 + 1

Proof of Theorem 3.5. The space of polynomials induced by the wth cut, that is, {k + uT
: ai ∈
Rm, k ∈ R}, is a vector space of dimension ≤ 1 + m. This is because for every j = 1, . . . , m, all
monomials that contain a variable uw[j] for some w have the same coeﬃcient (equal to ai[j] for
some 1 ≤ i ≤ n). Explicit spanning sets are given by the following recursion. For each j = 1, . . . , m
deﬁne (cid:101)u1[j], . . . , (cid:101)uW [j] recursively as

w (cid:101)aw

i

(cid:101)u1[j] = u1[j]

(cid:101)uw[j] = uw[j] +

w−1
(cid:88)

(cid:96)=1

uw[m + (cid:96)](cid:101)u(cid:96)[j]

for w = 2, . . . , W . Then, {k + uT
It follows that

w (cid:101)aw

i

: ai ∈ Rm, k ∈ R} is contained in span{1, (cid:101)uw[1], . . . , (cid:101)uw[m]}.

(cid:32) W
(cid:91)

dim

{k + uT

w (cid:101)aw

i

: ai ∈ Rm, k ∈ R}

≤ 1 + mW.

(cid:33)

w=1

The dual space thus also has dimension ≤ 1 + mW . The VC dimension of the family of 0/1
classiﬁers induced by a ﬁnite-dimensional vector space of functions is at most the dimension of
the vector space. Thus, the VC dimension of the set of classiﬁers induced by the dual space is
≤ 1 + mW . Finally, applying the main result of Balcan et al. [9] in conjunction with Lemma 3.4
gives the desired pseudo-dimension bound.

Proof of Theorem 3.6. Applying cuts u1, . . . , uk ∈ [0, 1]m simultaneously is equivalent to sequen-
tially applying the cuts

u1 ∈ [0, 1]m,

(cid:21)

(cid:20)u2
0

∈ [0, 1]m+1,





u3
0
0


 ∈ [0, 1]m+2, . . . ,








∈ [0, 1]m+k−1.








uk
0
...
0

Thus, the set in question is a subset of (cid:8)fu1,...,ukW : u1 ∈ [0, 1]m, . . . , ukW ∈ [0, 1]m+kW −1(cid:9) and has
pseudo-dimension O(mk2W 2 log(mkW (α + β + n))) by Theorem 3.5.

B.1 Data-dependent guarantees

The empirical Rademacher complexity [27] of a function class F ⊆ RY with respect to y1, . . . , yN ∈
Y is the quantity

RF (N ; y1, . . . , yN ) =

E
σ∼{−1,1}N

sup
f ∈F

(cid:34)

(cid:35)

σif (yi)

.

1
N

N
(cid:88)

i=1

The expected Rademacher complexity RF (N ) of F with respect to a distribution D on Y is the
quantity

RF (N ) =

E
y1,...,yN ∼D

[RF (N ; y1, . . . , yN )].

18

Rademacher complexity, like pseudo-dimension, is another measure of the intrinsic complexity of
the function class F . Roughly, it measures how well functions in F can correlate to random labels.
The following uniform convergence guarantee in terms of Rademacher complexity is standard: Let
[−κ, κ] be the range of the functions in F . Then, for all distributions D on Y, with probability
at least 1 − δ over the draw of y1, . . . , yN ∼ D, for all f ∈ F , Ey∼D[f (y)] − 1
i=1 f (yi) ≤
N
2RF (N ) + κ

(cid:80)N

(cid:113) ln(1/δ)
N .

The following result bounds the Rademacher complexity of the class of tree-size functions corre-
sponding to W waves of k CG cuts. The resulting generalization guarantee is more reﬁned than the
pseudo-dimension bounds in the main body of the paper. It is in terms of distribution-dependent
quantities, and unlike the pseudo-dimension-based guarantees requires no boundedness assumptions
on the support of the distribution.

Theorem B.1. Let D be a distribution over integer programs (c, A, b). Let

αN =

E
A1,...,AN ∼D

(cid:20)

(cid:21)

max
1≤i≤N

(cid:107)Ai(cid:107)1,1

and βN =

E
b1,...,bN ∼D

(cid:20)

(cid:21)

max
1≤i≤N

(cid:107)b(cid:107)1

.

The expected Rademacher complexity R(N ) of the class of tree-size functions corresponding to W
waves of k Chv´atal-Gomory cuts with respect to D satisﬁes

(cid:32)

(cid:114)

R(N ) ≤ O

κ

mk2W 2 log(mkW (αN + βN + n))
N

(cid:33)

where κ is a cap on the size of the tree B&C is allowed to build.

Proof of Theorem B.1. Let Fα,β denote the class of tree-size functions corresponding to W waves
of k CG cuts deﬁned on the domain of integer programs with (cid:107)A(cid:107)1,1 ≤ α and (cid:107)b(cid:107)1 ≤ β, and
let F denote the same class of functions without any restrictions on the domain. Applying a
classical result due to Dudley [14], the empirical Rademacher complexity of F with respect to
(c1, A, b), . . . , (cN , A, bN ) satisﬁes the bound

RF (N ; (c1, A, b1), . . . , (cN , A, bN )) ≤ 60κ

(cid:115)

Pdim(cid:0)Fmaxi(cid:107)Ai(cid:107)1,1,maxi(cid:107)bi(cid:107)1
N

(cid:1)

.

Here, κ is a bound on the tree-size function as is common in the algorithm conﬁguration literature [6,
25, 26]. Taking expectation over the sample, we get

(cid:115)

RF (N ) ≤ 60κ

E (cid:2)Pdim(cid:0)Fmaxi(cid:107)Ai(cid:107)1,1,maxi(cid:107)b(cid:107)1,1
N

(cid:1)(cid:3)

(cid:115)

≤ 60κ

(cid:114)

≤ 60κ

E (cid:2)mk2W 2 log(mkW (maxi (cid:107)Ai(cid:107)1,1 + maxi (cid:107)b(cid:107)1 + n))(cid:3)
N

mk2W 2 log(mkW (αN + βN + n))
N

by Theorem 3.6 and Jensen’s inequality.

19

C Omitted proofs from Section 5

(cid:16)

(cid:16)

(cid:17)κ

×t

j=1 T 2

j=1 [Tj]

, there is a set of at most κ (cid:80)t

Proof of Theorem 5.2. Fix an arbitrary problem instance x. In Claim C.1, we prove that for any
j halfspaces in Rd such
sequence of actions σ ∈
that Algorithm 1 when parameterized by µ ∈ Rd will follow the action sequence σ if and only
if µ lies in the intersection of those halfspaces. Let Hσ be the set of hyperplanes corresponding
to those halfspaces, and let H = (cid:83)
j action sequences
j=1 T κ
j . Moreover, by deﬁnition of these
in
j
halfspaces, we know that for any connected component C of Rd \ H, across all µ ∈ C, the sequence
of actions Algorithm 1 follows is invariant. Since the state transitions are deterministic functions
of the algorithm’s actions, this means that the algorithm’s ﬁnal state is also invariant across all
µ ∈ C. Since the utility function is ﬁnal-state-constant, this means that fµ(x) is constant across
all µ ∈ C. Therefore, the sample complexity guarantee follows from our general theorem [9].

σ Hσ. Since there are at most (cid:81)t

, we know that |H| ≤ κ

j=1 [Tj]

j=1 T κ

j=1 T 2

(cid:17) (cid:80)t

(cid:16)(cid:81)t

×t

(cid:17)κ

(cid:16)

(cid:17)κ

j=1 T 2
Claim C.1. Let σ ∈
j
halfspaces in Rd such that Algorithm 1 when parameterized by µ ∈ Rd will follow the action sequence
σ if and only if µ lies in the intersection of those halfspaces.

be an arbitrary sequence of actions. There are at most κ (cid:80)t

j=1 [Tj]

×t

Proof. For each type of action j ∈ [t], let kj,1, . . . , kj,κ ∈ [Tj] be the sequence of action indices taken
over all κ rounds. We will prove the claim by induction on the step of B&C. Let Tτ be the state of
the B&C tree after τ steps. For ease of notation, let T = (cid:80)t
j be the total number of possible
actions squared.

j=1 T 2

Induction hypothesis. For a given step τ ∈ [κt], let κ0 ∈ [κ] be the index of the current round
and t0 ∈ [t] be the index of the current action. There are at most (κ0 − 1) T + (cid:80)t0
j halfspaces
in Rd such that B&C using the scoring rules (cid:80)dj
i=1 µj[i]scorej,i for each action j ∈ [t] builds the
partial search tree Tτ if and only if (µ1, . . . , µt) ∈ Rd lies in the intersection of those halfspaces.

j=1 T 2

In the base case, before the ﬁrst iteration, the set of parameters that will produce
Base case.
the partial search tree consisting of just the root is the entire set of parameters, which vacuously
is the intersection of zero hyperplanes.

Inductive step. For a given step τ ∈ [κt], let κ0 ∈ [κ] be the index of the current round and
t0 ∈ [t] be the index of the current action. Let sτ be the state of B&C at the end of step τ . By the
inductive hypothesis, we know that there exists a set H of at most (κ0 − 1) T + (cid:80)t0
j halfspaces
such that B&C using the scoring rules (cid:80)dj
i=1 µj[i]scorej,i for each action j ∈ [t] will be in state sτ
if and only if (µ1, . . . , µt) ∈ Rd lies in the intersection of those halfspaces. Let κ(cid:48)
0 ∈ [κ] be the index
of the round in step τ + 1 and t(cid:48)

0 ∈ [t] be the index of the action in step τ + 1, so

j=1 T 2

We know B&C will choose the action k∗ ∈

if and only if

(cid:0)κ(cid:48)

0, t(cid:48)
0

(cid:1) =

(cid:40)

(κ0, t0 + 1)
(κ0 + 1, 1)
(cid:104)
Tt(cid:48)

(cid:105)

0

if t0 < t
if t0 = t.

dt(cid:48)
0(cid:88)

i=1

µt(cid:48)

0

[i]scoret(cid:48)

0,i (k∗, sτ ) > max
k(cid:54)=k∗

dt(cid:48)
0(cid:88)

i=1

µt(cid:48)

0

[i]scoret(cid:48)

0,i (k, sτ ) .

20

Since these functions are linear in µt(cid:48)

0

, there are at most T 2
t(cid:48)
0

halfspaces deﬁning the region where

0

= argmax (cid:80)dt(cid:48)

kt(cid:48)
0,κ(cid:48)
0
rule (cid:80)dt(cid:48)
[i]scoret(cid:48)
i=1 µt(cid:48)
intersection of the (κ(cid:48)

0

0

i=1 µt(cid:48)

0

[i]scoret(cid:48)

0,i (k, sτ ). Let H(cid:48) be this set of halfspaces. B&C using the scoring
lies in the

0,i arrives at state sτ +1 after τ + 1 iterations if and only if µt(cid:48)
0 − 1) T + (cid:80)t(cid:48)
j halfspaces in the set H ∪ H(cid:48).

j=1 T 2

0

0

21

