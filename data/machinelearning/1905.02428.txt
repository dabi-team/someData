9
1
0
2

y
a
M
7

]

O
L
.
s
c
[

1
v
8
2
4
2
0
.
5
0
9
1
:
v
i
X
r
a

Integrated Algorithms for HEX-Programs
and Applications in Machine Learning

Tobias Kaminski

Institute of Logic and Computation, TU Wien, Vienna, Austria
kaminski@kr.tuwien.ac.at

Abstract. This paper summarizes my doctoral research on evaluation algorithms
for HEX-programs, which extend Answer Set Programming with means for inter-
facing external computations. The focus is on integrating different subprocesses
of HEX-evaluation, such as solving and external calls as well as grounding, and
on applications of HEX-programs in the area of Machine Learning.

1 Motivation

Due to current trends in distributed systems and information integration, there is an
increasing need for accessing external information sources from within knowledge rep-
resentation formalisms such as Answer Set Programming (ASP) [17]. For instance, it
might be necessary to integrate information derived from a (possibly remote) Descrip-
tion Logic (DL) ontology into the computation of an answer set. If the derivation in
the ontology is relative to information in the ASP part, a bidirectional exchange be-
tween a DL reasoner and an ASP solver is required. This kind of interaction is not
provided by ordinary ASP, and pre-computing all possible derivations from the ontol-
ogy and adding them to the answer set program is often not feasible. Motivated by this,
the HEX-formalism [4] has been developed, where external sources can be referenced
in a program, and are evaluated during solving. The approach is related to SMT, but
the focus is more on techniques for evaluating general external sources represented by
arbitrary computations, i.e. it enables an API-like approach such that a user can deﬁne
plugins without expert knowledge on solver construction.

By employing HEX, a user can, e.g., deﬁne a library function for concatenating
strings, accessed via an external predicate &concat. It could be used as illustrated by
the following rule, where a ﬁrst name and a last name are provided, and &concat returns
the full name: fullname(Full) ← &concat[F, L](Full), ﬁrstname(F), lastname(L).

HEX-programs are very expressive since they enable a bidirectional exchange of
information between a logic program and external sources and thus, encompasses the
formalization of nonmonotonic and recursive aggregates. Consequently, HEX is suited
for a wide range of applications, but also requires sophisticated evaluation algorithms to
deal with the complexity that goes along with the high expressiveness. For this reason,
my thesis work aims at the design and implementation of novel integrated solving tech-
niques for improving the efﬁciency of the formalism in general, as well as for speciﬁc
classes of programs. Another focus of my work is on new applications that leverage the
provided techniques, and in turn push the advancement of the formalism.

 
 
 
 
 
 
2

2 Goals of My PhD Thesis

Challenges regarding efﬁcient evaluation of HEX-programs comprise the lack of a tight
integration of the solving process with the evaluation of external sources and with the
grounding procedure. Accordingly, the main goals of my doctoral research are:

1. to design advanced reasoning techniques that improve the evaluation of HEX-pro-
grams by tightly integrating processes which have so far been treated as mostly
independent sub-problems.

2. to develop innovative applications of HEX-programs that utilize external atoms for
integrating as well as realizing methods from the area of Machine Learning (ML).
3. to implement newly developed evaluation algorithms in the HEX-program solver
DLVHEX [7], and to investigate their performance using benchmark problems.

3 Background

Here, I start by brieﬂy summarizing the work most related to HEX and its applications,
and I introduce the theoretical background which my thesis work is based on.
Related Work. As there are many scenarios where it is more natural, and often more
efﬁcient, to outsource some information or computation in ASP, several approaches
exist for this purpose, realizing different degrees of integration. DLV-EX programs [2]
represent an early approach, which enables bidirectional communication with an exter-
nal source, and allows the introduction of new terms by value invention. The CLINGO
system also provides a mechanism for importing the extension of user-deﬁned predi-
cates via function calls during grounding [16]. In both cases, the interaction is more
restricted than in HEX such that, e.g., nonmonotonic aggregates cannot be expressed.

CLINGO 5 [15] provides generic interfaces for combining theory solving with ASP,
but its semantics differs from HEX and the approach is targeted at system developers.
Besides, there are extensions of ASP towards the integration of speciﬁc sources; e.g.,
the CLINGCON system [23] implements constraint ASP relying on a tailored integration
of a constraint solver. The setting of HEX differs as its goal is to enable a broad range of
users to implement custom external sources and to harness efﬁcient solving techniques.
HEX has been applied to a wide range of use cases. Among them are a framework
for executing scheduled actions in external environments (ActHEX [14]); a system for
merging belief sets based on nested HEX programs (MELD system, [24]); and an artiﬁ-
cial agent able of playing the computer game Angry Birds (AngryHEX, [6]).
HEX-Programs. HEX-programs [4] extend ASP by allowing the use of external atoms
of the form &g[p1, ..., pk](c1, ..., cl) in rule bodies, where &g is an external predicate
name, p1, ..., pk are input predicate names or constants, and c1, ..., cl are output con-
stants. The ground semantics of an external atom &g[p1, ..., pk](c1, ..., cl) is given by
a Boolean 1 + k + l-ary oracle function f&g s.t. an external atom evaluates to true
for a given assignment A over ordinary atoms if the oracle function returns true, i.e.
f&g(A, p1, ..., pk, c1, ..., cl) = t, and to false otherwise. The notion of satisfaction
is extended to HEX-rules and programs in the obvious way. Answer sets of a HEX-
program Π are those assignments A to ordinary atoms which are minimal models of

3

the program consisting of all rules in Π of which the body is satisﬁed under A (the
so-called FLP-reduct [13], an alternative to the well-known GL-reduct).

The basic procedure for computing the answer sets of a HEX-program Π con-
sists in replacing each (ground) external atom &g[p1, ..., pk](c1, ..., cl) by an ordinary
atom of the form e&g[p1,...,pk](c1, ..., cl) and adding a guess e&g[p1,...,pk](c1, ..., cl) ∨
ne&g[p1,...,pk](c1, ..., cl) ← for its evaluation [8]. The result of this translation is an or-
dinary answer set program; and ordinary ASP solvers such as CLASP can be used for
computing model candidates. However, guesses for external atoms must be checked af-
terwards for compatibility with the external semantics. By integrating Conﬂict-Driven
Nogood Learning (CDNL) search into the HEX-algorithm, the input-output relations can
be learned from these checks in form of nogoods to avoid wrong guesses in the future
search. Moreover, even if a model candidate complies with the answers of the corre-
sponding oracle calls, it still needs to be checked for minimality wrt. the FLP-reduct.

4 Research Progress

In this section, I present the research results obtained since I started my PhD studies.

4.1 Integration of Solving and External Evaluations

In the beginning of my doctoral research, I worked on the tighter integration of the solv-
ing process and external calls [11], which required an extension of the oracle semantics.
Before, oracle functions were only deﬁned for complete inputs to external atoms, such
that they could only be evaluated after the whole input was decided. As a result, many
wrong guesses could only be detected late during search and nogoods were large as they
usually entailed the complete input assignment. However, this could not be improved
when using two-valued assignments since external sources might be nonmonotonic, and
they are black boxes such that theory speciﬁc techniques like in SMT cannot be applied.
We have overcome the mentioned challenges by extending the two-valued seman-
tics to three-valued assignments that use the classical values true and false, and the
new value unassigned. Based on partial assignments, we have introduced new evalua-
tion techniques to increase the performance of HEX-evaluation, which can be utilized
in the search for model candidates as well as the search applied during checking min-
imality wrt. the FLP-reduct. First, we have extended two-valued oracle functions to
three-valued ones, which allows evaluation at any point during search under partial in-
put. Second, nogoods now can also be learned under partial assignments, which are
often signiﬁcantly smaller. Moreover, given some input-output nogood, we obtain a set
of minimal nogoods by applying a minimization procedure similar to the one in [23]. As
an alternative, we also incorporated the QUICKXPLAIN algorithm [19] for conﬂict min-
imization, which is more suited for nogoods that contain many irrelevant literals. The
beneﬁt of the new solving techniques has been veriﬁed by experiments using DLVHEX.

4.2 Integration of External Sources and Minimality Checking

In addition to the usual minimality check of ASP, a special minimality check wrt. the
FLP-reduct is required during the evaluation of HEX-programs to avoid cyclic justiﬁca-

4

tions via external sources. The check is a bottleneck in practice as it often accounts for
most of the time required to evaluate HEX-programs. For this reason, syntactic informa-
tion regarding atom dependencies has been used to detect situations where the external
minimality check can be skipped [5]. However, this approach overapproximates the real
dependencies as a result of the black-box nature of external sources.

In our most recent work [10], we considered a tighter integration of minimality
checking and external sources by showing how the real external dependencies can be
approximated more closely by also taking semantic dependency information into ac-
count. The additional dependency information can be provided by a user or even gen-
erated automatically. This brings us closer to a clear-box view of external sources, and
allows us to skip the external minimality check in more cases. Furthermore, we stated
conditions under which the costs for checking and generating semantic dependency
information can be reduced. Using an experimental evaluation, we could verify that
having more ﬁne-grained information about the actual dependencies among atoms is
crucial for applications where otherwise the overestimation makes the minimality check
infeasible.

4.3 Integration of Grounding and Solving

During the second year of my PhD studies, I worked on integrating the lazy-grounding
ASP solver Alpha [26] into the DLVHEX system, with the goal to achieve a tighter inte-
gration of HEX-sovling and grounding. Lazy grounding avoids an exponential blowup
of the grounding by interleaving grounding and solving, whereby rules are grounded
on-the-ﬂy depending on the satisfaction of their bodies. The resulting approach exhibits
promising results for classes of programs where the grounding bottleneck of ASP is an
issue [12]. This issue is even more challenging to tackle within the framework of HEX
due to the need for grounding external atoms; and nonmonotonic dependencies and
value invention (i.e., import of new constants) from external sources make the integra-
tion nontrivial. As a result, we needed to introduce a novel external source interface to
incrementally extend a HEX-program grounding, where new output terms may appear
during solving. This resulted in a novel evaluation algorithm for HEX-programs that can
incorporate lazy-grounding solvers as backend solvers.

4.4 Applications of HEX-Programs in Machine Learning

As HEX allows to integrate different formalisms, it is well-suited for combining diverse
forms of reasoning. In this branch of my research, my goal was to exploit this strength
for two new applications in the area of ML. The ﬁrst one integrates an external statistical
classiﬁer, while the second encodes an existing approach for logic-based ML.

Hybrid Classiﬁcation of Visual Objects A basic task in Statistical Relational Learn-
ing [18] is Collective Classiﬁcation [25], which is simultaneously ﬁnding correct labels
for a number of interrelated objects, e.g., predicting the classes of objects in a complex
visual scene. Even if advanced algorithms for object recognition have been developed,
they may fail unavoidably and yield ambiguous results due to few training data, noisy

5

inputs, or inherent ambiguity of visual appearance. It is then still possible to draw on
further information from the context in which an object occurs to disambiguate its label.
We approached the Collective Classiﬁcation problem in ASP by deﬁning Hybrid
Classiﬁers (HC) that combine a local classiﬁer, which predicts the probability of each
local label based on object features, with context constraints (weighted ASP constraints)
using object relations [9]. At this, external atoms of HEX can be used to interface an
ontology reasoner, a spatial reasoning calculus as well as the local classiﬁer directly
from within the encoding. This has not been realized in the ﬁrst version of the approach,
where the integration was created ad-hoc using a pre-processing step. However, the
usage of external atoms for this purpose will be described in my dissertation.

To obtain a probabilistic semantics, we embedded our encoding into the formalism
LP MLN [21], such that an HC corresponds to an LP MLN program. We showed that
solutions of the resulting HC encoding can be obtained efﬁciently via a backtranslation
from LP MLN into classical ASP with weak constraints [1], and by leveraging combi-
natorial optimization capabilities of ASP solvers. Experiments wrt. object classiﬁcation
in indoor and outdoor scenes exhibit signiﬁcant accuracy improvements compared to
using only a local classiﬁer.

Meta-Interpretive Learning In the area of Inductive Logic Programming (ILP), Meta-
Interpretive Learning (MIL) is a recent approach, introduced by Muggleton et al. [22],
that learns logic programs from examples and background knowledge by instantiating
meta-rules. The Metagol system [3] efﬁciently solves MIL-problems by relying on the
query-driven search of Prolog. Its focus on positive examples, however, effects that
Metagol can detect the derivability of negative examples only at a later check, which can
severely hit performance. Viewing MIL-problems as combinatorial search problems,
they can alternatively be solved by employing ASP, which may result in performance
gains as a result of efﬁcient conﬂict propagation. By employing modern ASP solvers,
violations of negative examples can potentially be propagated earlier.

However, a straightforward ASP-encoding of MIL results in a huge search space
due to a lack of procedural bias and the need for grounding. To address this challenge,
we have encoded MIL in the HEX-formalism [20]. Our encoding utilizes external atoms
to outsource background knowledge that deﬁnes manipulations of complex terms such
as lists and strings, which is easy to realize in Prolog but less supported by ASP. More-
over, we identiﬁed a class of MIL-problems which can be solved efﬁciently by us-
ing our HEX-encodings, and showed empirically that the performance can be increased
compared to Metagol by employing HEX. In addition, by abstracting from term manip-
ulations in the encoding and by exploiting the HEX-interface mechanism, the import of
constants can be entirely avoided in order to mitigate the grounding bottleneck.

5 Future Work

The overarching theme of my thesis is to tightly integrate different mechanisms em-
ployed during HEX-solving, and a number of new evaluation techniques has been de-
veloped for this purpose. However, there are several further ways in which these tech-

6

niques can be combined, extended and exploited for different parts of solving in the
future.

First, while we have only employed simple heuristics for deciding the frequency of
external evaluations during HEX-solving, dynamic heuristics could also be used, where
the frequency is adjusted according to the amount of information gained from previous
calls. Second, our HEX-algorithm that exploits lazy-grounding could be combined with
a pre-grounding algorithm, where the respective grounding mechanisms are applied for
different modules of a HEX-program based on their properties. Moreover, additional
semantic dependency information, which we used for deciding the necessity of the ex-
ternal minimality check, is also valuable for reducing the number of external evaluations
during the model search and grounding, and could be utilized there as well.

References

1. Francesco Buccafurri, Nicola Leone, and Pasquale Rullo. Enhancing disjunctive datalog by

constraints. IEEE Trans. Knowl. Data Eng., 12(5):845–860, 2000.

2. Francesco Calimeri, Susanna Cozza, and Giovambattista Ianni. External sources of knowl-
edge and value invention in logic programming. Ann. Math. Artif. Intell., 50(3-4):333–361,
2007.
3. Andrew

H. Muggleton.

Metagol

Cropper

Stephen

system.

and

https://github.com/metagol/metagol, 2016.

4. Thomas Eiter, Michael Fink, Giovambattista Ianni, Thomas Krennwallner, Christoph Redl,
and Peter Sch¨uller. A model building framework for answer set programming with external
computations. TPLP, 16(4):418–464, 2016.

5. Thomas Eiter, Michael Fink, Thomas Krennwallner, Christoph Redl, and Peter Sch¨uller.
Efﬁcient hex-program evaluation based on unfounded sets. J. Artif. Intell. Res., 49:269–321,
2014.

6. Thomas Eiter, Michael Fink, and Daria Stepanova. Data repair of inconsistent nonmonotonic

description logic programs. Artif. Intell., 239:7–53, 2016.

7. Thomas Eiter, Giovambattista Ianni, Roman Schindlauer, and Hans Tompits. dlvhex: A
In 2006 IEEE / WIC
prover for semantic-web reasoning under the answer-set semantics.
/ ACM International Conference on Web Intelligence (WI 2006), pages 1073–1074. IEEE
Computer Society, 2006.

8. Thomas Eiter, Giovambattista Ianni, Roman Schindlauer, and Hans Tompits. Towards efﬁ-
cient evaluation of HEX programs. In Proceedings of the 11th Workshop on NMR, pages
40–46. Clausthal University of Technology, 2006.

9. Thomas Eiter and Tobias Kaminski. Exploiting contextual knowledge for hybrid classiﬁca-
tion of visual objects. In Loizos Michael and Antonis C. Kakas, editors, Logics in Artiﬁcial
Intelligence - 15th European Conference, JELIA 2016, Proceedings, volume 10021 of Lec-
ture Notes in Computer Science, pages 223–239, 2016.

10. Thomas Eiter and Tobias Kaminski. Pruning external minimality checking for ASP using
In Logic Programming and Nonmonotonic Reasoning - 15th In-
semantic dependencies.
ternational Conference, LPNMR 2019, Proceedings, Lecture Notes in Computer Science.
Springer, 2019. To Appear.

11. Thomas Eiter, Tobias Kaminski, Christoph Redl, and Antonius Weinzierl. Exploiting partial
assignments for efﬁcient evaluation of answer set programs with external source access. J.
Artif. Intell. Res., 62:665–727, 2018.

7

12. Thomas Eiter, Tobias Kaminski, and Antonius Weinzierl. Lazy-grounding for answer set pro-
grams with external source access. In Carles Sierra, editor, Proceedings of the Twenty-Sixth
International Joint Conference on Artiﬁcial Intelligence, IJCAI 2017, pages 1015–1022. ij-
cai.org, 2017.

13. Wolfgang Faber, Nicola Leone, and Gerald Pfeifer. Recursive aggregates in disjunctive logic
programs: Semantics and complexity. In Jos´e J´ulio Alferes and Jo˜ao Alexandre Leite, edi-
tors, Logics in Artiﬁcial Intelligence, 9th European Conference, JELIA 2004, Proceedings,
volume 3229 of Lecture Notes in Computer Science, pages 200–212. Springer, 2004.

14. Michael Fink, Stefano Germano, Giovambattista Ianni, Christoph Redl, and Peter Sch¨uller.
Acthex: Implementing HEX programs with action atoms. In Pedro Cabalar and Tran Cao
Son, editors, Logic Programming and Nonmonotonic Reasoning, 12th International Confer-
ence, LPNMR 2013, Proceedings, volume 8148 of Lecture Notes in Computer Science, pages
317–322. Springer, 2013.

15. Martin Gebser, Roland Kaminski, Benjamin Kaufmann, Max Ostrowski, Torsten Schaub,
and Philipp Wanko. Theory solving made easy with clingo 5.
In Manuel Carro, Andy
King, Neda Saeedloei, and Marina De Vos, editors, Technical Communications of the 32nd
International Conference on Logic Programming, ICLP 2016 TCs, volume 52 of OASICS,
pages 2:1–2:15. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2016.

16. Martin Gebser, Roland Kaminski, Benjamin Kaufmann, and Torsten Schaub. Clingo = ASP

+ control: Preliminary report. CoRR, abs/1405.3694, 2014.

17. Michael Gelfond and Vladimir Lifschitz. Classical negation in logic programs and disjunc-

tive databases. New Generation Comput., 9(3/4):365–386, 1991.

18. Lise Getoor. Introduction to statistical relational learning. MIT press, 2007.
19. Ulrich Junker. QUICKXPLAIN: preferred explanations and relaxations for over-constrained
In Deborah L. McGuinness and George Ferguson, editors, Proceedings of the
problems.
Nineteenth National Conference on Artiﬁcial Intelligence, Sixteenth Conference on Innova-
tive Applications of Artiﬁcial Intelligence, pages 167–172. AAAI Press / The MIT Press,
2004.

20. Tobias Kaminski, Thomas Eiter, and Katsumi Inoue. Exploiting answer set programming

with external sources for meta-interpretive learning. TPLP, 18(3-4):571–588, 2018.

21. Joohyung Lee and Yi Wang. Weighted rules under the stable model semantics. In Chitta
Baral, James P. Delgrande, and Frank Wolter, editors, Principles of Knowledge Representa-
tion and Reasoning: Proceedings of the Fifteenth International Conference, KR 2016, pages
145–154. AAAI Press, 2016.

22. Stephen H. Muggleton, Dianhuan Lin, and Alireza Tamaddoni-Nezhad. Meta-interpretive
learning of higher-order dyadic datalog: predicate invention revisited. Machine Learning,
100(1):49–73, 2015.

23. Max Ostrowski and Torsten Schaub. ASP modulo CSP: the clingcon system. TPLP, 12(4-

5):485–503, 2012.

24. Christoph Redl, Thomas Eiter, and Thomas Krennwallner. Declarative belief set merging
using merging plans. In Ricardo Rocha and John Launchbury, editors, Practical Aspects of
Declarative Languages - 13th International Symposium, PADL 2011, Proceedings, volume
6539 of Lecture Notes in Computer Science, pages 99–114. Springer, 2011.

25. Prithviraj Sen, Galileo Namata, Mustafa Bilgic, and Lise Getoor. Collective classiﬁcation.
In Claude Sammut and Geoffrey I. Webb, editors, Encyclopedia of Machine Learning, pages
189–193. Springer, 2010.

26. Antonius Weinzierl. Blending lazy-grounding and CDNL search for answer-set solving. In
Marcello Balduccini and Tomi Janhunen, editors, Logic Programming and Nonmonotonic
Reasoning - 14th International Conference, LPNMR 2017, Proceedings, volume 10377 of
Lecture Notes in Computer Science, pages 191–204. Springer, 2017.

