0
2
0
2

c
e
D
9

]

C
O
.
h
t
a
m

[

2
v
2
1
0
8
0
.
6
0
0
2
:
v
i
X
r
a

Wasserstein barycenters can be computed in polynomial time in
ﬁxed dimension

Jason M. Altschuler

Enric Boix-Adser`a

December 11, 2020

Abstract

Computing Wasserstein barycenters is a fundamental geometric problem with widespread
applications in machine learning, statistics, and computer graphics. However, it is unknown
whether Wasserstein barycenters can be computed in polynomial time, either exactly or to high
precision (i.e., with polylog(1/ε) runtime dependence). This paper answers these questions in
the aﬃrmative for any ﬁxed dimension. Our approach is to solve an exponential-size linear
programming formulation by eﬃciently implementing the corresponding separation oracle using
techniques from computational geometry.

1

Introduction

Given discrete probability distributions µ1, . . . , µk supported on Rd and a vector λ ∈ Rk of non-
negative weights summing to 1, the corresponding Wasserstein barycenters are the probability
distributions ν minimizing

argmin
ν

k
∑
i=1

λiW(µi, ν),

(1.1)

where above W(⋅, ⋅) denotes the squared 2-Wasserstein distance [1]. Wasserstein barycenters pro-
vide a natural extension of the notion of averaging points to the notion of averaging point clouds.
Importantly, they naturally inherit the ability of optimal transportation to capture geometric prop-
erties of the data.

This desirable property has led to the widespread use of Wasserstein barycenters in many
applications. Applications in statistics and machine learning include for instance the n-coupling
problem [32], constrained clustering [15, 22], fusing measurements from partial sensors [18], and
fusing measurements for scalable Bayesian learning [34]. Applications in image processing and
computer graphics include for instance texture mixing [31] and shape interpolation [33]. For further
applications, see the surveys [29, 30].

Open problem: computing barycenters in polynomial time. Despite considerable algo-
rithmic work, it is an open problem (e.g., [10]) whether Wasserstein barycenters between discrete
distributions can be exactly computed in polynomial time in the input size. A highly related open

The authors are with the Laboratory for Information and Decision Systems (LIDS), Massachusetts Institute of
Technology, Cambridge MA 02139. Work partially supported by NSF Graduate Research Fellowship 1122374, a
TwoSigma PhD Fellowship, and a Siebel PhD Fellowship.

1

 
 
 
 
 
 
problem is whether Wasserstein barycenters can be computed to high accuracy, i.e., whether an
ε-additively approximate solution for (1.1) can be computed in time that is polynomial in the input
size and log(1/ε). This paper answers these questions in the aﬃrmative for any ﬁxed dimension d.
Previous methods require time that depends polynomially on 1/ε in order to compute ε-
approximate barycenters. This means that in practice they can only solve to a few digits of precision.
See the prior work section for details. In many applications, including nearly all of those mentioned
above, Wasserstein barycenters are used as a subroutine in a larger pipeline to solve downstream
data science tasks. Thus, high-precision algorithms are important for downstream performance and
to avoid error propagation, especially in applications which require multiple barycenter computa-
tions.

Key obstacle. The well-documented key obstacle is that a priori, there are nk candidate atoms
for the barycenter’s support, where n is (an upper bound on) the number of atoms in each µi. While
there always exists a barycenter with poly(n, k) atoms, ﬁnding which atoms those are requires
pruning the nk exponentially many candidates.

1.1 Prior work

The literature on computing Wasserstein barycenters is extensive and rapidly growing.1 Existing
algorithms can be partitioned into two categories, depending on how they handle optimizing over
the nk exponentially many candidate atoms for the barycenter support.

Fixed-support. Most existing algorithms work around this exponential complexity by making a
“ﬁxed-support approximation”: they assume that the barycenter is supported on a small guessed
set of points, and then only optimize over the corresponding masses. This reduces the barycenter
problem to a polynomial-size LP, which can then be solved eﬃciently using out-of-the-box LP
solvers, or alternatively using specialized methods such as entropic regularization; see, e.g., [8, 12,
15, 23, 26, 27, 33, 35] among many others. However, the key issue with ﬁxed-support algorithms is
that guessing a reasonable support set for the barycenter requires ε-covering the space. Speciﬁcally,
these algorithms require ﬁxing the support to roughly (R/ε)d points in order to get an ε-additive
approximation to the barycenter2, where R is a bound on the squared diameter of the supports of
the input distributions. This results in poly(n, k, R/ε) ﬁnal runtimes in constant dimension d.

In contrast, our proposed algorithm has poly(n, k, log(R/ε)) runtime which, critically, has poly-
logarithmic dependence on R/ε.3 In practice, this means that our algorithm can often solve up to
machine precision, whereas ﬁxed-support algorithms can only solve up to a few digits of precision—
see §4 for experiments.

Free-support. Achieving our poly(n, k, log(R/ε)) runtime precludes making a ﬁxed-support ap-
proximation. Such algorithms are called “free-support algorithms”. The key obstacle is that, as
mentioned before, this requires optimizing over the support set of the barycenters, which a priori

1We mention in passing that an orthogonal line of work aims to compute barycenters of continuous distributions
(typically restricted to Gaussian distributions so that both µi and ν have compact representations for computational
purposes). See, e.g., [4, 14].

2An alternative is to restrict to the union of the supports of µ1, . . . , µk, which has only nk points. However, this

cannot get arbitrarily close approximations [10].

3This means that our algorithm solves the barycenter problem exactly in polynomial time, whereas previous
algorithms require pseudo-polynomial time. This is because solving the barycenter problem exactly requires ε to be
exponentially small in the bit-complexity of the input.

2

can only be restricted to nk candidate points. All previous free-support algorithms either run in
exponential time, or are heuristics without provable guarantees; see, e.g., [15, 28].

In contrast, we show how to optimize over these nk candidate points in polynomial time by

exploiting the geometric structure of their conﬁguration.

1.2 Contribution

We give the ﬁrst algorithm that, in any ﬁxed dimension d, solves the Wasserstein barycenter
problem exactly or to high precision in polynomial time. For simplicity of notation, throughout d
is a constant; the running time for ﬁxed d is (nk)d times a polynomial in the input size.

Theorem 1.1 (Computing high-precision barycenters). There is an algorithm that, given k dis-
tributions each supported on n atoms in the ball of squared radius R in Rd, a weight vector λ, and an
accuracy ε > 0, computes an ε-additively approximate Wasserstein barycenter in poly(n, k, log(R/ε))
time. Moreover, this barycenter has support size at most nk − k + 1.

Theorem 1.2 (Computing exact barycenters). If the weight vector and distributions are repre-
sented with log U bits of precision, then an exact barycenter can be found in poly(n, k, log U ) time.
Moreover, this barycenter has support size at most nk − k + 1.

Our algorithm is described in §3. Brieﬂy, the high-level idea is as follows. Our starting point is
a well-known LP reformulation of the Wasserstein barycenter problem as a Multimarginal Optimal
Transport (MOT) problem, recalled in the preliminaries section. This is an exponential-size LP
with nk variables, one for each candidate atom. Nevertheless, we show that a sparse solution can
be computed in polynomial time. Our approach consists of two steps. First, by leveraging tools
from combinatorial optimization and exploiting the special structure of the MOT LP, we show
that this problem can be solved eﬃciently if one can eﬃciently implement the separation oracle
for the LP dual of MOT. Second, by leveraging tools from computational geometry such as power
diagrams and the complexity of hyperplane arrangements, we show how to eﬃciently implement
this separation oracle.

In addition to its polynomial runtime, our algorithm has two additional properties that may be
useful in downstream applications. First, the outputted barycenter ν has small support of O(nk)
size, which is much smaller than the a priori nk bound on the support size. In particular, the
support size of ν is at most the maximal sparsity of any vertex of the transportation polytope
between µ1, . . . , µk—which is at most nk − k + 1. Note that Theorem 1.2 is not at odds with the
NP-hardness of ﬁnding the sparsest barycenter [11]: indeed, our algorithm outputs a solution that
albeit sparse is not necessarily the sparsest. Second, as a by-product, our algorithm also produces
sparse solutions to the optimal transport problems W(µi, ν) that are non-mass-splitting maps from
ν to µi. Among other beneﬁts, this enables easy visualization and interpretability of the results—in
comparison to entropic-regularization based approaches which produce “blurry” dense maps.

Although the focus of this work is theoretical, we also provide preliminary numerical experiments
in §4 demonstrating that a slight variant of our algorithm can provide high-precision solutions at
previously intractable problem sizes.

Finally, in §5, we brieﬂy mention that the techniques we develop in this paper extend to solving
several related problems. In particular, this gives the ﬁrst polynomial-time algorithms for comput-
ing geometric medians with respect to the 1-Wasserstein distance (a.k.a. Earth Mover’s distance)
over any of the popular ground metrics (cid:96)1, (cid:96)2, or (cid:96)∞.

3

2 Preliminaries

This section is organized as follows. First, in §2.1, we establish our notation, which is mostly stan-
dard. Then in §2.2, §2.3, §2.4, respectively, we recall relevant background from the machine learning,
combinatorial optimization, and computational geometry literatures—namely, background about
LP formulations of Wasserstein barycenters, algorithms for solving exponential-size LP, and algo-
rithms for manipulating power diagrams.

2.1 Notation

The set {1, . . . , n} is denoted by [n]. The k-fold tensor product space Rn ⊗ ⋅ ⋅ ⋅ ⊗ Rn is denoted
by (Rn)⊗k, and similarly for (Rn
⩾0)⊗k. For shorthand, we often denote a tuple (j1, . . . , jk) ∈ [n]k
by ⃗j. The i-th marginal, i ∈ [k], of a tensor P ∈ (Rn)⊗k is denoted by the vector mi(P ) ∈ Rn,
and has entries [mi(P )](cid:96) ∶= ∑⃗j∈[n]k∶ji=(cid:96) P⃗j. The transportation polytope between µ1, . . . , µk is the
set of joint distributions with one-dimensional marginal distributions µ1, . . . , µk, and is identiﬁed
⩾0)⊗k ∶ mi(P ) = µi, ∀i ∈ [k]}, where we abuse notation
with the set M(µ1, . . . , µk) ∶= {P ∈ (Rn
slightly by identifying µi with its vector of probabilities (in any order). The closure of a set E ⊂ Rd
(with respect to the standard topology) is denoted by E. Throughout, we assume without loss of
generality that each λi is strictly positive, since otherwise µi does not aﬀect the barycenter (see
equation (1.1)).

2.2 LP formulation of Wasserstein barycenters

Our starting point is the known fact (see, e.g., [1, 5, 8]) that a barycenter ν can be found by solving
the Multimarginal Optimal Transport problem

for the cost tensor C ∈ (Rn)⊗k with entries

min
P ∈M(µ1,...,µk)

⟨P, C⟩,

C⃗j = min
y∈Rd

k
∑
i=1

λi∥xi,ji − y∥2,

(MOT)

(2.1)

or equivalently, C⃗j = ∑k
reduction from the Wasserstein barycenter problem to the LP (MOT) is as follows.

(cid:96)=1 λ(cid:96)x(cid:96),j(cid:96)∥2 by optimality of y = ∑k

i=1 λi∥xi,ji − ∑k

(cid:96)=1 λ(cid:96)x(cid:96),j(cid:96). Speciﬁcally, the

Lemma 2.1. If P ∈ M(µ1, . . . , µk) is an optimal solution to (MOT), then the pushforward of P
under the map (X1, . . . , Xk) ↦ ∑k
i=1 λiXi is an optimal barycenter ν. Furthermore, the support size
of ν is at most the support size of P , and also the coupling (∑k
i=1 λiXi, Xj) is a non-mass-splitting
map that solves the Optimal Transport problem from ν to µj.

Notice that applying this pushforward map (X1, . . . , Xk) ↦ ∑k

i=1 λiXi in order to compute ν
from P requires only O(skd) arithmetic operations, where s denotes the support size of P .
In
particular, this takes polynomial time if s is of polynomial size. Therefore it suﬃces to compute a
sparse solution P of the LP (MOT).

Note that the solution P is guaranteed to be sparse if it is a vertex solution. Indeed, since (MOT)
is a standard-form LP whose constraints have rank at most nk − k + 1, each vertex solution has at
most nk − k + 1 non-zero entries.

Lemma 2.2. If P is a vertex of the transportation polytope M(µ1, . . . , µk), then P has at most
nk − k + 1 non-zero entries.

4

An obvious obstacle for computing any solution—let alone a sparse solution—of the LP formu-
lation (MOT) is that it has nk exponentially many variables. An LP that will be useful to us in
the sequel is its dual

max
p1,...,pk∈Rn

k
∑
i=1

⟨pi, µi⟩

subject to C⃗j −

k
∑
i=1

[pi]ji ⩾ 0, ∀⃗j ∈ [n]k.

(MOT-D)

An attractive property of (MOT-D) is that it has only nk polynomially many variables. However, of
course this alone is not enough to make solving (MOT-D) tractable because it has nk exponentially
many constraints. That is, dualizing has transferred the exponential complexity in the number of
variables in (MOT) to the number of constraints in (MOT-D).

2.3 Algorithms for exponential-size LP

It is a classical fact (see, e.g., [9, 21, 24]) that regardless of the number of constraints, an LP with
polynomially many variables can be solved in polynomial time so long as there is a polynomial-time
implementation of the separation oracle for its feasibility set. Here we recall the technical details
of this fact.

First, we recall the deﬁnition of a separation oracle. This deﬁnition is simply an algorithmic
reformulation of the Separating Hyperplane Theorem, which states that for any convex set K ⊆ RN
and any point p ∈ RN , exactly one of two alternatives must hold: either p ∈ K, or there exists a
hyperplane that separates p from K (i.e., there exists a vector h ∈ RN and a scalar g ∈ R such that
⟨h, p⟩ ⩾ g and ⟨h, x⟩ < g for all x ∈ K).

Deﬁnition 2.3. A separation oracle for a convex set K is an algorithm that given a point p, either
outputs that p ∈ K or outputs a hyperplane that separates p from K.

Given a polynomial-time implementation of a separation oracle for a polytope, the Ellipsoid
algorithm can solve an LP over that polytope in polynomial time. This result can be found in [20].

Theorem 2.4. Let log U be an upper bound on the number of bits needed to represent any entry in
A ∈ RM ×N , b ∈ RM , or c ∈ RN . Then the Ellipsoid algorithm ﬁnds a vertex solution to argmin{cT x ∶
x ∈ P} in poly(N, log U ) time and poly(N, log U ) calls to a separation oracle for the polytope
P = {x ∈ RN ∶ Ax ⩽ b}.

2.4 Computational geometry algorithms

A key ingredient in our barycenter algorithm is power diagrams. Here we introduce these objects
and some basic facts about their complexity. Although d is a ﬁxed constant in our ﬁnal results,
we state the explicit dependence on the dimension d in these power diagram complexity bounds to
highlight how and where our algorithm incurs exponential runtime dependence in d.

Deﬁnition 2.5. The power diagram on the spheres S(z1, r1), . . . , S(zn, rn) with centers zj ∈ Rd
and radii rj ⩾ 0 is the cell complex whose cells E1, . . . , En are given by

Ej = {y ∈ Rd ∶ ∥zj − y∥2 − r2

j < ∥zj′ − y∥2 − r2

j′, ∀j′ ≠ j}.

A power diagram “essentially” partitions Rd in the sense that its cells are disjoint and their
closures cover Rd. See Figure 1 for an illustration. Following are two relevant classical facts. The
ﬁrst essentially shows that a power diagram is deﬁned by a small hyperplane arrangement which
can moreover be computed eﬃciently.

5

Figure 1: Two power diagrams on the same n = 9 points with varying weights w. Left: all weights are zero
(so this is a Voronoi diagram). Right: the weight of a point is indicated by the size of the ball around it.
Increasing the weight of a point increases the size of its cell.

Lemma 2.6. (Theorems 1 and 7 of [6], using convex hull algorithm of [13]) A power
diagram on n spheres in Rd has O(n) aﬃne facets of dimension d − 1. Moreover these facets can
be computed in O((n log n + n⌈d/2⌉) ⋅ polylog U ) time, where log U is the number of bits of precision.

The second is about hyperplane arrangements. In the sequel this lets us bound the complexity

of the “intersection” of multiple power diagrams (deﬁned in §3.2).

Lemma 2.7 (Theorem 3.3 of [17]). The cell complex formed by an arrangement of N hyperplanes
in Rd, represented up to log U bits of precision, can be computed in N d ⋅ polylog(N, U ) time.

3 Algorithm

In this section we describe our algorithm and prove our main results (Theorems 1.1 and 1.2). We
begin by overviewing the high-level approach. Let us consider the exact solver in Theorem 1.2, as
the approximate solver in Theorem 1.1 is implemented by exactly solving a rounded problem (see
§3.3 for details).

Recall from §2.2 that it suﬃces to solve the LP formulation (MOT) of the Wasserstein barycen-
ter problem. However, solving this LP presents a computational obstacle since it has nk decision
variables. Moreover, we desire a sparse solution P —rather than a generic solution which has expo-
nentially many non-zero entries—since a polynomial sparsity for P ensures a polynomial support
size for the ﬁnal barycenter ν.

The starting point of our approach is recalling the classical fact from §2.3 that regardless of the
number of constraints, an LP with polynomially many variables can be solved in polynomial time so
long as the corresponding separation oracle can be implemented in polynomial time. While (MOT)
is not such an LP since it has exponentially many variables, this result applies to its dual (MOT-D).
That is, we can eﬃciently solve (MOT-D) so long as we can eﬃciently implement the corresponding
separation oracle.

However, two key obstacles remain. First, recovering a primal solution is non-trivial in that
in general a dual solution does not necessarily “help” to ﬁnd a primal solution [9, Exercise 4.17],
let alone a sparse primal solution. Second, and most importantly, this approach requires an ef-
ﬁcient implementation of the separation oracle for (MOT-D), which does not exist for general
Multimarginal Optimal Transport problems (for concrete NP-hard examples see [2]).

We solve these issues in two steps:

6

1. Reduction to separation oracle. We reduce solving (MOT) in polynomial time to solving the
separation oracle for the dual LP (MOT-D) in polynomial time. (Further, we show how to
ensure the solution is polynomially sparse.)

2. Eﬃcient algorithm for separation oracle. We use tools from computational geometry to solve

the separation oracle for (MOT-D) in polynomial time.

At this point, it is worth remarking what special “structure” of the exponential-size LP (MOT)
we exploit in order to solve it in polynomial time. Step 1 does not extend to general LP, i.e., one
cannot eﬃciently solve an LP given only an eﬃcient separation oracle for its dual [21]. Instead,
step 1 crucially exploits the particular “structure” of the feasibility constraints deﬁning (MOT),
details in §3.1. This extends to arbitrary Multimarginal Optimal Transport problems (i.e., arbitrary
costs C), and therefore may be of independent interest. However, step 1 is of course useless unless
one can eﬃciently solve the separation oracle in step 2. Indeed, as mentioned above, step 2 does
not extend to general Multimarginal Optimal Transport problems, i.e., there does not exist an
eﬃcient implementation of the the separation oracle for (MOT-D) for arbitrary costs C ∈ (Rn)⊗k.
It is here—in step 2, not step 1—that we crucially exploit the remaining “structure” in the LP
reformulation (MOT) of the barycenter problem, namely the cost C deﬁned in (2.1). Intuitively,
this “structure” of C is geometric: the nk entries in C correspond to nk candidate points for the
barycenter’s support, and these points must lie in certain constrained geometric conﬁgurations,
details in §3.2.

Let us now elaborate on steps 1 and 2. To do this, we ﬁrst recast the separation oracle

for (MOT-D) in a convenient way for our algorithmic development.
Deﬁnition 3.1. Given p = (p1, . . . , pk) ∈ Rn×k, the oracle SEP returns a tuple SEP(p) ∈ argmin⃗j∈[n]k C⃗j−
∑k

i=1[pi]ji.

The intuition behind SEP is that it implements4 the separation oracle for (MOT-D) because

given the tuple ⃗j = SEP(p), exactly one of the following two alternatives must hold:

• C⃗j − ∑k

i=1[pi]ji ⩾ 0, in which case this certiﬁes that p is feasible for (MOT-D).

• C⃗j − ∑k

set of (MOT-D).

i=1[pi]ji < 0, in which case this provides a hyperplane that separates p from the feasible

Now, in terms of this oracle SEP, steps 1 and 2 are formally summarized as follows.

Proposition 3.2 (Step 1). Let C ∈ (Rn)⊗k be an arbitrary cost, and let log U be the maximum
number of bits of precision in an entry of C. A vertex solution P ∗ for (MOT) can be found in
poly(n, k, log U ) time and poly(n, k, log U ) calls to SEP.

Proposition 3.3 (Step 2). If the cost C is given by (2.1), the oracle SEP(p) can be implemented in
poly(n, k, log U ) time, where log U is the number of bits of precision needed to represent the points
xi,j ∈ Rd, weights λi ∈ Rk

>0 and potentials p ∈ Rn×k.

The remainder of the section is organized as follows. In §3.1 and §3.2, we detail the algorithms
in steps 1 and 2, respectively, and prove Propositions 3.2 and 3.3. Combining Propositions 3.2
and 3.3 then proves Theorem 1.1 aside from checking bit-complexity details, which is done formally
in §3.3.

4In fact, it can be shown that SEP is polynomial-time equivalent to the separation oracle for (MOT-D), i.e., each
oracle can be implemented using polynomial many calls to the other oracle and polynomial additional computation
time. However, this is not needed in the sequel.

7

3.1 Step 1: reduction to separation oracle

Here we prove Proposition 3.2 and describe the algorithm in it. This algorithm has two steps.
First, it identiﬁes a small set S ⊆ [n]k on which an optimal MOT solution is supported. Second, it
optimizes over distributions supported on S.

Proof of Proposition 3.2. First, we construct a set S ⊂ [n]k as follows. Since SEP(p) implements
a separation oracle for (MOT-D), and since (MOT-D) has N = nk variables, Theorem 2.4 implies
that an optimal solution for (MOT-D) can be found by the Ellipsoid algorithm in poly(N, log U ) =
poly(n, k, log U ) time. Let L denote the number of SEP queries made by the Ellipsoid algorithm.
For l ∈ [L], let p(l) ∈ Rn×k be the argument of the l-th query to SEP, and let ⃗j(l) ∈ [n]k be the
returned tuple. Let S ∶= {⃗j((cid:96))}L
(cid:96)=1 denote the set of all returned tuples.

Next, we show how to compute an optimal vertex solution for (MOT) using S. Let MS(µ1, . . . , µk) =

{P ∈ M(µ1, . . . , µk) ∶ P⃗j = 0 ∀⃗j ∉ S} be the set of distributions in the transportation polytope
supported on S, and let (MOTS) be (MOT) with the decision set M(µ1, . . . , µk) replaced by
MS(µ1, . . . , µk). The key lemma is that it suﬃces to compute an optimal vertex solution for
(MOTS). This is proved below in Lemma 3.4; let us presently show how to use it complete the
proof of the main proposition. Note that since the number of Ellipsoid iterations is poly(n, k, log U )
by Theorem 2.4, the set S has cardinality of size poly(n, k, log U ). Thus (MOTS) is a polynomial
size LP, so we can compute a vertex solution for it in polynomial time with standard LP solvers
(e.g., Theorem 2.4).

We now state the key lemma used in the above proof.

Lemma 3.4. Any vertex solution P for (MOTS) is also a vertex solution for (MOT).

Lemma 3.4 follows directly from the following three observations. Below, let C′ denote the tensor
that agrees with C on S, and equals 2U elsewhere. Also let (MOT′) denote the problem (MOT)
where the cost C is replaced by C′.
Observation 3.5. The optimal values of (MOT) and (MOT′) are equal.

Proof. Since the Ellipsoid algorithm is deterministic and accesses the cost only through the SEP
oracle, an inductive argument shows that all for all l ∈ [L],

min
⃗j∈[n]k

C′
⃗j

−

k
∑
i=1

[p

(l)
i ]ji = min
⃗j∈[n]k

C⃗j −

k
∑
i=1

[p

(l)
i ]ji.

That is, C′ is consistent with C on the SEP queries made by the Ellipsoid algorithm. There-
fore (MOT-D) has the same value with cost C′ or C. We conclude by strong duality.
Observation 3.6. The optimal values of (MOT′) and (MOTS) are equal.
Proof. Since C and C′ agree on S, it suﬃces to show that every optimal solution for (MOT′) is
supported on S. Suppose for contradiction that there exists an optimal solution P for (MOT′) that
is not supported on S. Then we must have ⟨P, C⟩ < ⟨P, C′⟩, since C′ is strictly larger than C on
[n]k ∖ S. However, since P is feasible for (MOT), this implies that the value of (MOT) is strictly
less than that of (MOT′), contradicting Observation 3.5.

Observation 3.7. Every vertex of MS(µ1, . . . , µk) is a vertex of M(µ1, . . . , µk).
Proof. Let P be a vertex of MS(µ1, . . . , µk), and let P = λQ + (1 − λ)R for λ ∈ [0, 1] and Q, R ∈
M(µ1, . . . , µk). It suﬃces to show that Q = R = P . Since P is supported on tuples in S, and since
Q and R are entrywise non-negative, we have that Q and R are also supported on S. Therefore
Q, R ∈ MS(µ1, . . . , µk). But since P is a vertex of MS(µ1, . . . , µk), this implies that Q = R = P .

8

intersect
—————→

Figure 2: Illustrates k = 3 power diagrams {{Ei,j}j∈[n]}i∈[k] each with n = 3 cells, and their intersection
{F⃗j}⃗j∈[n]k . For instance, the red cell in the intersected diagram is F1,2,1 = E1,1 ∩ E2,2 ∩ E3,1, and the purple
cell is F2,3,2 = E1,2 ∩ E2,3 ∩ E3,2. Note that the intersected diagram has only 13 non-empty cells, which is less
than nk = 27 (c.f., Lemma 3.9).

3.2 Step 2: eﬃcient algorithm for the separation oracle

Here we prove Proposition 3.3 and describe the algorithm in it for eﬃciently implementing the SEP
oracle for the cost C in (2.1). Recall that this SEP oracle requires computing an optimal tuple for

argmin
⃗j∈[n]k

min
y∈Rd

g(⃗j, y)

(3.1)

where

g(⃗j, y) ∶=

k
∑
i=1

λi(∥xi,ji − y∥2 − [wi]ji),

and wi denotes pi/λi. At a high level, our approach is to swap the order of minimization, optimize
over y ∈ Rd, and then (easily) recover an optimal tuple from this optimal y. The diﬃculty is
in the optimization over y ∈ Rd. The key to performing this eﬃciently is partitioning the space
Rd into a “cell complex” such that (i) the optimization over y in each cell is easy, and (ii) there
are only polynomially many cells. Operationally, this allows us to reduce the separation oracle
optimization (3.1) to optimizing over only a polynomially sized set of candidate tuples in [n]k—
one for each cell—which we moreover show can be eﬃciently identiﬁed and enumerated.

To formalize this, we make the following key deﬁnitions. Deﬁne for i ∈ [k] and j ∈ [n] the set

Ei,j = {y ∈ Rd ∶ ∥xi,j − y∥2 − [wi]j < ∥xi,j′ − y∥2 − [wi]j′, ∀j′ ≠ j},

and deﬁne for each tuple ⃗j ∈ [n]k the set

F⃗j =

k
⋂
i=1

Ei,ji.

(3.2)

(3.3)

Geometrically, for each i ∈ [k], the cells {Ei,j}j∈[n] form a power diagram (see §2.4) on the spheres
S(xi,1, ri,1), . . . , S(xi,n, ri,n), where the j-th sphere is centered at point xi,j and has radius ri,j ∶=
√
[wi]j − minj′[wi]j′ ⩾ 0. Each power diagram “essentially” partitions Rd in the sense that its
constituent cells are disjoint and their closures cover Rd; see Figure 1 for an illustration. The cell
complex {F⃗j}⃗j∈[n]k is the intersection of these k power diagrams and “essentially” partitions Rd in
the analogous way; see Figure 2 for an illustration.

The heart of our algorithm lies in the following two lemmas. The ﬁrst lemma shows that the
optimization (3.1) over the exponentially many tuples j ∈ [n]k may be restricted to just those whose

9

corresponding cell F⃗j is non-empty, i.e., we may restrict to the tuples in

T ∶= {⃗j ∈ [n]k ∶ F⃗j ≠ ∅}.
The second lemma shows that this candidate set T contains only polynomially many tuples and
moreover can be eﬃciently enumerated. Brieﬂy, the ﬁrst lemma exploits the fact that the opti-
mization over y ∈ Rd is equivalent to optimizing over the cells in F⃗j, and the second lemma exploits
complexity bounds for the intersections of power diagrams. Together, these lemmas are suﬃcient
to eﬃciently solve the separation oracle because for any ﬁxed ⃗j, the value miny∈Rd g(⃗j, y) can be
eﬃciently computed in closed-form (as shown below in (3.5)).
Lemma 3.8. The optimization over ⃗j ∈ [n]k in the separation oracle problem (3.1) can be equiva-
lently restricted to ⃗j ∈ T . That is,

(3.4)

min
⃗j∈[n]k

min
y∈Rd

g(⃗j, y) = min
⃗j∈T

min
y∈Rd

g(⃗j, y).

Proof. The inequality “⩽” is obvious; we show the other inequality “⩾”. By swapping the order of
minimization and using the fact that {F⃗j}⃗j∈T cover Rd modulo closure, we have

g(⃗(cid:96), y) = min
y∈Rd

g(⃗(cid:96), y) = min
⃗j∈T

min
y∈Rd

min
⃗(cid:96)∈[n]k

min
⃗(cid:96)∈[n]k

min
y∈F⃗j
We claim that the inner minimization over ⃗(cid:96) is explicit: ⃗(cid:96) = ⃗j.
Indeed, by separability of g in
the coordinates of ⃗(cid:96) and non-negativity of λi, for each i ∈ [n] the optimal (cid:96)i is a solution of
argmin(cid:96)i∈[n] ∥xi,(cid:96)i − y∥2 − [wi](cid:96)i; and ji is a solution of this by deﬁnition of Ei,ji (see (3.2)) and the
fact that Ei,ji contains y (by deﬁnition of F⃗j, see (3.3)). Therefore
g(⃗j, y).

min
⃗(cid:96)∈[n]k

g(⃗(cid:96), y).

min
⃗j∈T

min
y∈F⃗j

min
⃗(cid:96)∈[n]k

g(⃗(cid:96), y) = min
⃗j∈T

min
y∈F⃗j

Now by enlarging the optimization region, we have the simple bound

min
⃗j∈T

min
y∈F⃗j

g(⃗j, y) ⩾ min
⃗j∈T

min
y∈Rd

g(⃗j, y).

Combining the above three displays completes the proof.

Lemma 3.9. For any ﬁxed dimension d, the set T can be enumerated in poly(n, k, log U ) time.

Proof. By Lemma 2.6, the O(nk) total facets for the k power diagrams {{Ei,j}i∈[n]}j∈[k] can be
computed in poly(n, k, log U ) time. For each facet, compute the (d − 1)-dimensional hyperplane
it lies in. The cell complex H formed by these hyperplanes is a subcomplex of the cell complex
formed by intersecting the power diagrams. By Lemma 2.7, we can enumerate the cells in H
in poly(n, k, log U ) time. For each cell in H, the corresponding tuple ⃗j ∈ [n]k is computable in
O(nk ⋅ polylog U ) time by computing the k coordinates of the tuple separately. Since each non-
empty cell F⃗j contains at least one cell in H, this process enumerates all tuples in T .

We now conclude the desired eﬃcient algorithm for the separation oracle.

Proof of Proposition 3.3. By Lemma 3.8, it suﬃces to output a tuple ⃗j minimizing min⃗j∈T miny∈Rd g(⃗j, y).
Since ∑k

i=1 λixi,ji ∈ argminy∈Rd g(⃗j, y), it therefore suﬃces to solve

argmin
⃗j∈T

k
∑
i=1

λi∥xi,ji∥2 − ∥

k
∑
i=1

λixi,ji∥2 −

k
∑
i=1

λi[wi]ji.

(3.5)

Peform this by enumerating the set T using the algorithm in Lemma 3.9.

10

3.3 Putting the pieces together

Proof of Theorem 1.2. Assume each xi,ji and λi is written to log U bits of precision. Since each
entry of the cost tensor (2.1) requires only O(log k +log U ) bits of precision, and since the parameter
w ∈ Rn×k in each SEP query made by the algorithm in Proposition 3.2 requires only poly(n, k, log U )
bits of precision, it follows that the algorithm in Proposition 3.2 combined with the SEP oracle
implementation in Proposition 3.3 computes a vertex solution P ∗ for (MOT) in poly(n, k, log U )
time. By Lemma 2.2, P ∗ has at most nk − k + 1 non-zero entries. Thus we can recover from P ∗ an
optimal barycenter ν with support size at most nk − k + 1 in time poly(n, k, log U ) by the reduction
in Lemma 2.1.

Proof of Theorem 1.1. By rounding both the weights λi and the coordinates of the atoms xi,j ∈ Rd
to poly(ε/(Rkd)) additive accuracy, it can be ensured that each of these numbers requires only
O(log(Rkd/ε)) bits of precision and also that the objective function ν ↦ ∑k
i=1 λiW(µi, ν) for the
barycenter optimization (1.1) is preserved pointwise to ε additive accuracy. This follows from
a straightforward calculation and the fact (immediate from the deﬁnition of optimal transporta-
tion [36, §1] and an application of H¨older’s inequality) that if the squared Euclidean distance
between each atom of µi and each atom of ν is preserved up to ε′ additive accuracy, then the
squared 2-Wasserstein distance W(µi, ν) is preserved up to ε′ additive accuracy. Now solve the
barycenter problem for the rounded weights and atoms exactly using Theorem 1.2.

4 Numerical implementation

While the focus of this paper is theoretical, here we brieﬂy mention that a slight variant of our algo-
rithm can provide high-precision solutions at previously intractable problem sizes. To demonstrate
this, we implement our algorithm for dimension d = 2 in Python. The only diﬀerence between our
numerical implementation and the theoretical algorithm described above is that we use a standard
cutting-plane method (see, e.g., [9, §6.3]) for the “outer loop” in step 1 rather than the Ellipsoid
algorithm due to its good practical performance. Code and further implementation details are
provided on Github.5

4.1 Computing exact solutions at previously intractable scales

Figure 3 demonstrates that our algorithm solves the barycenter problem (1.1) to machine precision
on an instance with k = 10 uniform distributions each on n = 20 points randomly drawn from
[−1, 1]2 ⊂ R2.
In contrast, existing popular barycenter algorithms which use the ﬁxed-support
assumption can converge faster but only to lower-precision approximations. This is because the
Θ(1/εd) gridsize that they require for ε-additive approximation results in a large-scale LP which
is prohibitive even for relatively low precision ε; see §1.1 for details. Note also that a standard LP
solver requires optimizing over nk = 2010 ≈ 1013 variables for the LP formulation (MOT) and thus
is clearly infeasible at this scale.

4.2 Sharper visualizations

Here we demonstrate that the high-precision solutions computed by our algorithm yield signiﬁcantly
sharper visualizations than the low-precision solutions that were previously computable. Specif-
ically, here we compare our barycenter algorithm against state-of-the-art methods on a standard

5https://github.com/eboix/high_precision_barycenters

11

(a) Comparison with the Iterated Bregman Projec-
tion (IBP) algorithm of [33] using their implementa-
tion https://github.com/gpeyre/2015-SIGGRAPH-
convolutional-ot.

(b) Comparison with the Matrix-based Adaptive Al-
ternating Interior-Point Method (MAAIPM) of [19]
using their implementation https://gitlab.com/
ZXiong/wasserstein-barycenter.

Figure 3: Comparison with state-of-the-art algorithms. The y-axis is the suboptimality for the barycenter
optimization (1.1); note that while standard LP solvers cannot be run at this scale, our algorithm yields an
exact solution (certiﬁed by our separation oracle) which enables plotting this suboptimality. Both compared
algorithms require a ﬁxed-support assumption and are run on uniform grids of increasing sizes. IBP has
an additional parameter: the entropic regularization γ, which signiﬁcantly impacts the algorithm’s accuracy
and numerical stability, see [30, 33]. We provide a generous comparison here for IBP by (i) ﬁne-tuning γ for
it (we binary search for the most accurate γ; note that their code does not always converge for γ small due
to numerical instability); and (ii) exactly computing the Wasserstein distances W(µi, ν) to IBP’s current
barycenter ν in the barycenter objective (1.1) using [16], which is more accurate than IBP’s approximation
(this is slow for large grids but is not counted in IBP’s timing). Our algorithm ﬁnds an exact barycenter
after ∼50 seconds. All experiments are run on a standard 2014 Lenovo Yoga 720-13IKB laptop.

benchmark dataset of images of nested ellipses [15, 23]. This dataset consists of k = 10 images, each
of size 60 × 60. Five of these images are shown in Figure 4.

Figure 5 contains a visual comparison of the exact barycenter computed by our algorithm and
the approximate barycenters produced by the most competitive algorithms tested in the recent
paper [23]. All are ﬁxed-support algorithms except for the algorithm of [28].

Of the compared algorithms, MAAIPM gives the most accurate barycenter approximation. It
uses a 60×60 grid ﬁxed-support assumption. Although MAAIPM solves this ﬁxed-support problem
exactly, the support of an optimal barycenter does not lie on a 60 × 60 grid, and thus MAAIPM
only computes an approximate barycenter. A natural approach is to run MAAIPM on a ﬁner grid
discretization, i.e., ﬁner than 60 × 60. However, this does not work, since MAAIPM does not scale
to much larger grid sizes (see also Figure 3b).

The other two ﬁxed-support algorithms are based on entropic regularization: debiased Sinkhorn

Figure 4: Five sample images from the nested ellipses dataset in [23].

12

100101102Time(seconds)10−910−710−510−310−1101SuboptimalitygapComparisonwithIBPProposedalgorithmIBP25x25grid(γ=0.01)IBP100x100grid(γ=0.01)IBP250x250grid(γ=0.005)100101102103Time(seconds)10−910−710−510−310−1101SuboptimalitygapComparisonwithMAAIPMProposedalgorithmMAAIPM10x10gridMAAIPM40x40gridMAAIPM70x70gridOurs

MAAIPM [19]

Debiased [23]

IBP [33]

Frank-Wolfe [28]

Cost: 0.2666 (exact)

Cost: 0.2671

Cost: 0.2675

Cost: 0.2723

Cost: 0.2790

Figure 5: Comparison of barycenter algorithms on a standard benchmark dataset of ellipse images. Each
barycenter atom is plotted as a disk with area proportional to its probability mass. All compared methods
are run with the code, parameter choices, and dataset of [23].

barycenters [23] and IBP [33]. These use entropic regularization parameter γ = 0.002 and the
same 60 × 60 ﬁxed-support approximation as MAAIPM. Again, these methods produce suboptimal
barycenters. While these methods scale to larger grid sizes than MAAIPM, this results in qualita-
tively similar and blurry visualizations as in this 60 × 60 case due to the entropic regularization.

The ﬁnal compared algorithm is the free-support algorithm of [28], which is based on the Frank-
Wolfe algorithm. Although this method does not make a ﬁxed-support assumption, it still returns
an approximate solution due to the approximate nature of the Frank-Wolfe algorithm.

5 Discussion

Wasserstein barycenters are used in many applications despite the fact that fundamental questions
about their computational complexity are open—in particular, it was previously unknown whether
barycenters can be computed in polynomial time. This paper addresses this issue by giving the
ﬁrst algorithm that, in any ﬁxed dimension d, solves the barycenter problem exactly or to high
precision in polynomial time.

Now, while our result answers the polynomial-time computability of barycenters from a theoret-
ical perspective, from a practical perspective it is still a hard and interesting problem to compute
high-precision barycenters for large-scale inputs. Indeed, our current implementation is not eﬃcient
beyond moderate-scale inputs; and while existing algorithms such as IBP scale to larger inputs,
they have limited accuracy. Moreover, all existing algorithms pay for the curse of dimensionality in
one way or another. We emphasize that our implementation does not contain further optimizations
or heuristics; it is an interesting direction for future work to investigate potential such options
including pruning cutting planes, warm starts, and specially tailored algorithms for the power di-
agram intersections in §3.2 (e.g., in R2 or R3, settings which commonly arise in image processing
and computer graphics applications).

We remark that another research direction suggested by the results of this paper is the possibility
of solving “structured” Multimarginal Optimal Transport problems in poly(n, k) time despite the
fact that they have nk exponentially many variables. Such problems arise in a variety of applications
throughout data science and applied mathematics. However, the context of the application results
in the cost tensor C having diﬀerent types of “structure”, which in turn necessitates developing
diﬀerent techniques for eﬃciently solving the corresponding separation oracle (see the discussion in
§3). We pursue this direction and develop such techniques in upcoming work [3].

13

5.1 Extension to Wasserstein geometric median

We conclude the paper by brieﬂy mentioning that the techniques we develop in this paper extend
to solving several related problems. In particular, this gives the ﬁrst polynomial-time algorithms
for computing the Wasserstein geometric median

inf
ν

k
∑
i=1

λiρ(µi, ν)

(5.1)

of probability measures µ1, . . . , µk, where ρ is the 1-Wasserstein distance ρ (a.k.a., Earth Mover’s
Distance) over any of the popular ground metrics (cid:96)1, (cid:96)2, or (cid:96)∞. See, e.g., [7] and the references
within for background on this problem and its applications.

For brevity, we just state this result for exact computation (i.e., the analog of Theorem 1.2).

The high-precision analog of Theorem 1.1 also holds analogously.

Theorem 5.1. Consider the space Rd endowed with any of the ground metrics (cid:96)1, (cid:96)2, or (cid:96)∞. There
is an algorithm that, given k distributions each supported on n atoms in Rd and a weight vector λ,
computes an exact Wasserstein geometric median in poly(n, k, log U ) time, where log U is the bits
of precision in the input. Moreover, this solution has support size at most nk − k + 1.

Since the proof of this extension is nearly identical, we sketch only the diﬀerences. First, observe
that this geometric median problem (5.1) is identical to the Wasserstein barycenter problem (1.1),
except that it depends on the 1-Wasserstein distance ρ rather than the squared 2-Wasserstein dis-
tance W. It can be shown that the geometric median problem admits an analogous LP formulation
as a Multimarginal Optimal Transport problem, just as in (MOT), except that here the cost tensor
C ∈ (Rn)⊗k has entries

C⃗j = min
y∈Rd

k
∑
i=1

λic(xi,ji, y)

(5.2)

where c(⋅, ⋅) denotes the relevant ground metric. This identical to the cost (2.1) for barycenters,
except that the squared Euclidean distance is replaced by the ground metric c(⋅, ⋅).

Now, since step 1 of our algorithm—i.e., reducing ﬁnding a vertex solution of (MOT) to solving
the separation oracle for (MOT-D)—holds for any Multimarginal Optimal Transport problem (see
the discussion in §3), it remains only to adapt step 2 of our algorithm. That is, it suﬃces to show
that SEP can be eﬃciently implemented for the cost C in (5.2).

This extension requires only one small change: replace power diagrams with the analogous
partitions of space that are deﬁned with ∥x−y∥2 replaced by c(x, y). These diagrams are sometimes
called “additively-weighted Voronoi diagrams with metric c”; for shorthand, we just call them “c-
diagrams” here.

Deﬁnition 5.2 (c-diagram). The c-diagram for points z1, . . . , zn ∈ Rd and radii r1, . . . , rn ⩾ 0 is the
cell complex whose cells E1, . . . , En are given by

Ej = {y ∈ Rd ∶ c(zj, y) − r2

j < c(zj′, y) − r2

j′, ∀j′ ≠ j}.

Speciﬁcally, adapt the deﬁnition (3.2) of the sets Ei,j in this way to {y ∈ Rd ∶ c(xi,j, y) − [wi]j <
c(xi,j′, y) − [wi]j′, ∀j′ ≠ j}. It is straightforward to check that our algorithm for the SEP oracle in
§3.2 and its proof then extend unchanged so long as the ground metric c(⋅, ⋅) satisﬁes the following
basic properties, the ﬁrst three of which are somewhat trivial but needed for rigor:

14

(i) There is a polynomial-time algorithm for evaluating c(x, y) given points x and y.

(ii) There is a polynomial-time algorithm for evaluating the geometric median miny∈Rd ∑k

i=1 λic(xi, y)

given points x1, . . . , xk and weights λ1, . . . , λk.

(iii) The closure of the cells in any c-diagram covers Rd.

(iv) The intersection of any k c-diagrams on n points has poly(n, k) many non-empty subsets that

can be enumerated in polynomial time.

The ﬁrst three properties are trivially satisﬁed by all of the ground metrics c(x, y) = ∥x − y∥1,
∥x − y∥2, and ∥x − y∥∞. Therefore in order to prove Theorem 5.1, it remains only to verify property
(iv). For (cid:96)1 and (cid:96)∞, c-diagrams are cell complexes with polynomially many aﬃne facets which can
moreover be computed in polynomial time [25], and thus the claim follows by Lemma 2.7. For
(cid:96)2, the corresponding c-diagram is an additively-weighted Voronoi diagram, for which the desired
complexity bounds are also known (see section 6.4 of [6]).

Acknowledgements.

We thank Sinho Chewi, Jonathan Niles-Weed, and Pablo Parrilo for helpful conversations.

References

[1] M. Agueh and G. Carlier. Barycenters in the Wasserstein space. SIAM Journal on Mathematical Analysis,

43(2):904–924, 2011.

[2] J. M. Altschuler and E. Boix-Adser`a. Hardness results for Multimarginal Optimal Transport problems. arXiv

pre-print, 2020.

[3] J. M. Altschuler and E. Boix-Adser`a. Polynomial-time algorithms for Multimarginal Optimal Transport problems

with decomposability structure. arXiv pre-print arXiv:2008.03006, 2020.

[4] P. C. ´Alvarez-Esteban, E. Del Barrio, J. Cuesta-Albertos, and C. Matr´an. A ﬁxed-point approach to barycenters

in Wasserstein space. Journal of Mathematical Analysis and Applications, 441(2):744–762, 2016.

[5] E. Anderes, S. Borgwardt, and J. Miller. Discrete Wasserstein barycenters: Optimal transport for discrete data.

Mathematical Methods of Operations Research, 84(2):389–409, 2016.

[6] F. Aurenhammer. Power diagrams: properties, algorithms and applications. SIAM Journal on Computing,

16(1):78–96, 1987.

[7] M. Bac´ak. Computing medians and means in Hadamard spaces. SIAM Journal on Optimization, 24(3):1542–

1566, 2014.

[8] J.-D. Benamou, G. Carlier, M. Cuturi, L. Nenna, and G. Peyr´e. Iterative Bregman projections for regularized

transportation problems. SIAM Journal on Scientiﬁc Computing, 37(2):A1111–A1138, 2015.

[9] D. Bertsimas and J. N. Tsitsiklis. Introduction to linear optimization, volume 6. Athena Scientiﬁc Belmont,

MA, 1997.

[10] S. Borgwardt. Strongly polynomial 2-approximations of discrete Wasserstein barycenters.

arXiv preprint

arXiv:1704.05491, 2017.

[11] S. Borgwardt and S. Patterson. On the computational complexity of ﬁnding a sparse Wasserstein barycenter.

arXiv preprint arXiv:1910.07568, 2019.

[12] G. Carlier, A. Oberman, and E. Oudet. Numerical methods for matching for teams and Wasserstein barycenters.

ESAIM: Mathematical Modelling and Numerical Analysis, 49(6):1621–1642, 2015.

15

[13] B. Chazelle. An optimal convex hull algorithm in any ﬁxed dimension. Discrete & Computational Geometry,

10(4):377–409, 1993.

[14] S. Chewi, T. Maunu, P. Rigollet, and A. J. Stromme. Gradient descent algorithms for Bures-Wasserstein

barycenters. arXiv preprint arXiv:2001.01700, 2020.

[15] M. Cuturi and A. Doucet. Fast computation of Wasserstein barycenters. In International Conference on Machine

Learning, pages 685–693, 2014.

[16] B. Dezs˝o, A. J¨uttner, and P. Kov´acs. LEMON–an open source C++ graph template library. Electronic Notes

in Theoretical Computer Science, 264(5):23–45, 2011.

[17] H. Edelsbrunner, J. O’Rourke, and R. Seidel. Constructing arrangements of lines and hyperplanes with appli-

cations. SIAM Journal on Computing, 15(2):341–363, 1986.

[18] F. Elvander, I. Haasler, A. Jakobsson, and J. Karlsson. Multi-marginal optimal transport using partial informa-

tion with applications in robust localization and sensor fusion. Signal Processing, 171:107474, 2020.

[19] D. Ge, H. Wang, Z. Xiong, and Y. Ye. Interior-point methods strike back: Solving the Wasserstein barycenter

problem. In Advances in Neural Information Processing Systems, pages 6891–6902, 2019.

[20] M. Gr¨otschel, L. Lov´asz, and A. Schrijver. The ellipsoid method and its consequences in combinatorial opti-

mization. Combinatorica, 1(2):169–197, 1981.

[21] M. Gr¨otschel, L. Lov´asz, and A. Schrijver. Geometric algorithms and combinatorial optimization, volume 2.

Springer Science & Business Media, 2012.

[22] N. Ho, X. L. Nguyen, M. Yurochkin, H. H. Bui, V. Huynh, and D. Phung. Multilevel clustering via Wasserstein

means. In International Conference on Machine Learning, pages 1501–1509, 2017.

[23] H. Janati, M. Cuturi, and A. Gramfort. Debiased Sinkhorn barycenters. arXiv preprint arXiv:2006.02575, 2020.

[24] L. G. Khachiyan. Polynomial algorithms in linear programming. USSR Computational Mathematics and Math-

ematical Physics, 20(1):53–72, 1980.

[25] R. Klein. Concrete and abstract Voronoi diagrams, volume 400. Springer Science & Business Media, 1989.

[26] A. Kroshnin, D. Dvinskikh, P. Dvurechensky, A. Gasnikov, N. Tupitsa, and C. Uribe. On the complexity of

approximating Wasserstein barycenter. arXiv preprint arXiv:1901.08686, 2019.

[27] T. Lin, N. Ho, X. Chen, M. Cuturi, and M. Jordan. Fixed-support Wasserstein barycenters: Computational

hardness and fast algorithm. Advances in Neural Information Processing Systems, 33, 2020.

[28] G. Luise, S. Salzo, M. Pontil, and C. Ciliberto. Sinkhorn barycenters with free support via Frank-Wolfe algo-

rithm. In Advances in Neural Information Processing Systems, pages 9322–9333, 2019.

[29] V. M. Panaretos and Y. Zemel. Statistical aspects of Wasserstein distances. Annual review of statistics and its

application, 6:405–431, 2019.

[30] G. Peyr´e and M. Cuturi. Computational optimal transport. Foundations and Trends in Machine Learning, 2017.

[31] J. Rabin, G. Peyr´e, J. Delon, and M. Bernot. Wasserstein barycenter and its application to texture mixing. In
International Conference on Scale Space and Variational Methods in Computer Vision, pages 435–446. Springer,
2011.

[32] L. R¨uschendorf and L. Uckelmann. On the n-coupling problem. Journal of Multivariate Analysis, 81(2):242–258,

2002.

[33] J. Solomon, F. De Goes, G. Peyr´e, M. Cuturi, A. Butscher, A. Nguyen, T. Du, and L. Guibas. Convolutional
Wasserstein distances: Eﬃcient optimal transportation on geometric domains. ACM Transactions on Graphics,
34(4):1–11, 2015.

16

[34] S. Srivastava, C. Li, and D. B. Dunson. Scalable Bayes via barycenter in Wasserstein space. The Journal of

Machine Learning Research, 19(1):312–346, 2018.

[35] M. Staib, S. Claici, J. M. Solomon, and S. Jegelka. Parallel streaming Wasserstein barycenters. In Advances in

Neural Information Processing Systems, pages 2647–2658, 2017.

[36] C. Villani. Topics in optimal transportation. Number 58. American Mathematical Society, 2003.

17

