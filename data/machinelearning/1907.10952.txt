Machine learning manuscript No.
(will be inserted by the editor)

Logical reduction of metarules

Andrew Cropper · Sophie Tourret

9
1
0
2

l
u
J

5
2

]

G
L
.
s
c
[

1
v
2
5
9
0
1
.
7
0
9
1
:
v
i
X
r
a

the date of receipt and acceptance should be inserted later

Abstract Many forms of inductive logic programming (ILP) use metarules, second-order
Horn clauses, to deﬁne the structure of learnable programs and thus the hypothesis
space. Deciding which metarules to use for a given learning task is a major open problem
and is a trade-off between efﬁciency and expressivity: the hypothesis space grows given
more metarules, so we wish to use fewer metarules, but if we use too few metarules
then we lose expressivity. In this paper, we study whether fragments of metarules can be
logically reduced to minimal ﬁnite subsets. We consider two traditional forms of logical
reduction: subsumption and entailment. We also consider a new reduction technique
called derivation reduction, which is based on SLD-resolution. We compute reduced sets
of metarules for fragments relevant to ILP and theoretically show whether these re-
duced sets are reductions for more general inﬁnite fragments. We experimentally com-
pare learning with reduced sets of metarules on three domains: Michalski trains, string
transformations, and game rules. In general, derivation reduced sets of metarules outper-
forms subsumption and entailment reduced sets, both in terms of predictive accuracies
and learning times.

1 Introduction

Many forms of inductive logic programming (ILP) [1, 5, 14, 19–21, 32, 33, 49, 54, 58,
62] use second-order Horn clauses, called metarules1 as a form of declarative bias [53].
Metarules deﬁne the structure of learnable programs which in turn deﬁnes the hypothesis
space. For instance, to learn the grandparent/2 relation given the parent/2 relation, the
chain metarule would be suitable:

A. Cropper
University of Oxford, UK
E-mail: andrew.cropper@cs.ox.ac.uk

Sophie Tourret
Max Planck Institute for Informatics, Germany
E-mail: stourret@mpi-inf.mpg.de

1 Metarules are also called program schemata [21], second-order schemata [54], and clause templates

[1], amongst many other names.

 
 
 
 
 
 
2

Andrew Cropper, Sophie Tourret

P(A, B) ← Q(A, C), R(C, B)

In this metarule2 the letters P, Q, and R denote existentially quantiﬁed second-order vari-
ables (variables that can be bound to predicate symbols) and the letters A, B and C denote
universally quantiﬁed ﬁrst-order variables (variables that can be bound to constant sym-
bols). Given the chain metarule, the background parent/2 relation, and examples of the
grandparent/2 relation, ILP approaches will try to ﬁnd suitable substitutions for the ex-
istentially quantiﬁed second-order variables, such as the substitutions {P/grandparent,
Q/parent, R/parent} to induce the theory:

grandparent(A, B) ← parent(A, C), parent(C, B)

However, despite the widespread use of metarules, there is little work determining which
metarules to use for a given learning task. Instead, suitable metarules are assumed to be
given as part of the background knowledge, and are often used without any theoretical
justiﬁcation. Deciding which metarules to use for a given learning task is a major open
challenge [8, 10] and is a trade-off between efﬁciency and expressivity: the hypothesis
space grows given more metarules [10, 38], so we wish to use fewer metarules, but if
we use too few metarules then we lose expressivity. For instance, it is impossible to learn
the grandparent/2 relation using only metarules with monadic predicates.

In this paper, we study whether potentially inﬁnite fragments of metarules can be
logically reduced to minimal, or irreducible, ﬁnite subsets, where a fragment is a syntac-
tically restricted subset of a logical theory [4].

Cropper and Muggleton [10] ﬁrst studied this problem. They used Progol’s entail-
ment reduction algorithm [45] to identify entailment reduced sets of metarules, where
a clause C is entailment redundant in a clausal theory T ∪ {C} when T |= C. To illustrate
entailment redundancy, consider the following ﬁrst-order clausal theory T1, where p, q,
r, and s are ﬁrst-order predicates:

C1 = p(A, B) ← q(A, B)
C2 = p(A, B) ← q(A, B), r(A)
C3 = p(A, B) ← q(A, B), r(A), s(B, C)

In T1 the clauses C2 and C3 are entailment redundant because they are both logical
consequences of C1, i.e. {C1} |= {C2, C3}. Because {C1} cannot be reduced, it is a minimal
entailment reduction of T1.

Cropper and Muggleton showed that in some cases as few as two metarules are suf-
ﬁcient to entail an inﬁnite fragment of chained3 second-order dyadic Datalog [10]. They
also showed that learning with minimal sets of metarules improves predictive accura-
cies and reduces learning times compared to non-minimal sets. To illustrate how a ﬁnite
subset of metarules could entail an inﬁnite set, consider the set of metarules with only
monadic literals and a single ﬁrst-order variable A:

2 The fully quantiﬁed rule is ∃P∃Q∃R∀A∀B∀C P(A, B) ← Q(A, C ), R(C , B).
3 A chained dyadic Datalog clause has the restriction that every ﬁrst-order variable in a clause appears
in exactly two literals and a path connects every literal in the body of C to the head of C. In other words,
a chained dyadic Datalog clause has the form P0(X0, X1) ← P1(X0, X2), P2(X2, X3), . . . , Pn(X n, X1) where
the order of the arguments in the literals does not matter.

Logical reduction of metarules

3

M1 = P(A) ← T1(A)
M2 = P(A) ← T1(A), T2(A)
M3 = P(A) ← T1(A), T2(A), T3(A)
. . .
Mn = P(A) ← T1(A), T2(A), . . . , Tn(A)
. . .

Although this set is inﬁnite it can be entailment reduced to the single metarule M1 be-
cause it implies the rest of the theory.

However, in this paper, we claim that entailment reduction is not always the most
appropriate form of reduction. For instance, suppose you want to learn the father/2
relation given the background relations parent/2, male/1, and female/1. Then a suitable
hypothesis is:

father(A, B) ← parent(A, B), male(A)

To learn such a hypothesis one would need a metarule of the form P(A, B) ← Q(A, B), R(A).
Now suppose you have the metarules:

M1 = P(A, B) ← Q(A, B)
M2 = P(A, B) ← Q(A, B), R(A)

Running entailment reduction on these metarules would remove M2 because it is a logi-
cal consequence of M1. However, it is impossible to learn the intended father/2 relation
given only M1. As this example shows, entailment reduction can be too strong because
it can remove metarules necessary to specialise a clause, where M2 can be seen as a
specialisation of M1.

To address this issue, we introduce derivation reduction, a new form of reduction
based on derivations, which we claim is a more suitable form of reduction for reducing
sets of metarules. Let ⊢ represent derivability in SLD-resolution4 [34], then a Horn clause
C is derivationally redundant in a Horn theory T ∪ {C} when T ⊢ C. A Horn theory is
derivationally irreducible if it contains no derivationally redundant clauses. To illustrate
the difference between entailment and derivation reduction, consider the metarules:

M1 = P(A, B) ← Q(A, B)
M2 = P(A, B) ← Q(A, B), R(A)
M3 = P(A, B) ← Q(A, B), R(A, B)
M4 = P(A, B) ← Q(A, B), R(A, B), S(A, B)

Running entailment reduction on these metarules would result in the reduction {M1}
because M1 entails the rest of the theory. Likewise, running subsumption reduction [52]
(described in detail in Section 3.5) would also result in the reduction {M1}. By contrast,
running derivation reduction would only remove M4 because it can be derived by self-
resolving M3. The remaining metarules M2 and M3 are not derivationally redundant
because there is no way to derive them from the other metarules.

4 We use ⊢ to represent derivability of both ﬁrst-order and second-order clauses. In practice we reason
about second-order clauses using ﬁrst-order resolution via encapsulation [10], which we describe in
Section 3.3.

4

1.1 Contributions

Andrew Cropper, Sophie Tourret

In the rest of this paper, we study whether fragments of metarules relevant to ILP can be
logically reduced to minimal ﬁnite subsets. We study three forms of reduction: subsump-
tion [55], entailment [45], and derivation. We also study how learning with reduced sets
of metarules affects learning performance. To do so, we supply Metagol [13], a meta-
interpretive learning (MIL) [12, 48, 49] implementation, with different reduced sets of
metarules and measure the resulting learning performance on three domains: Michal-
ski trains [35], string transformations, and game rules [9]. In general, using derivation
reduced sets of metarules outperforms using subsumption and entailment reduced sets,
both in terms of predictive accuracies and learning times. Overall, our speciﬁc contribu-
tions are:

– We describe the logical reduction problem (Section 3).
– We describe subsumption and entailment reduction, and introduce derivation reduc-
tion, the problem of removing derivationally redundant clauses from a clausal theory
(Section 3).

– We study the decidability of the three reduction problems and show, for instance, that
the derivation reduction problem is undecidable for arbitrary Horn theories (Section
3).

– We introduce two general reduction algorithms that take a reduction relation as a

parameter. We also study their complexity (Section 4).

– We run the reduction algorithms on ﬁnite sets of metarules to identify minimal sets

(Section 5).

– We theoretically show whether inﬁnite fragments of metarules can be logically re-

duced to ﬁnite sets (Section 5).

– We experimentally compare the learning performance of Metagol when supplied
with reduced sets of metarules on three domains: Michalski trains, string transfor-
mations, and game rules (Section 6).

2 Related work

This section describes work related to this paper, mostly work on logical reduction tech-
niques. We ﬁrst, however, describe work related to MIL and metarules.

2.1 Meta-interpretive learning

Although the study of metarules has implications for many ILP approaches [1, 5, 14,
19–21, 32, 33, 49, 54, 58, 62], we focus on meta-interpretive learning (MIL), a form of
ILP based on a Prolog meta-interpreter5. The key difference between a MIL learner and
a standard Prolog meta-interpreter is that whereas a standard Prolog meta-interpreter
attempts to prove a goal by repeatedly fetching ﬁrst-order clauses whose heads unify with
a given goal, a MIL learner additionally attempts to prove a goal by fetching second-order
metarules, supplied as background knowledge (BK), whose heads unify with the goal.
The resulting meta-substitutions are saved and can be reused in later proofs. Following
the proof of a set of goals, a logic program is formed by projecting the meta-substitutions

5 Although the MIL problem has also been encoded as an ASP problem [32].

Logical reduction of metarules

5

onto their corresponding metarules, allowing for a form of ILP which supports predicate
invention and learning recursive theories.

Most existing work on MIL has assumed suitable metarules as input to the problem,
or has used metarules without any theoretical justiﬁcation. In this paper, we try to ad-
dress this issue by identifying minimal sets of metarules for interesting fragments of logic,
such as Datalog, from which a MIL system can theoretically learn any logic program.

2.2 Metarules

McCarthy [43] and Lloyd [40] advocated using second-order logic to represent knowl-
edge. Similarly, Muggleton et al. [47] argued that using second-order representations
in ILP provides more ﬂexible ways of representing BK compared to existing methods.
Metarules are second-order Horn clauses and are used as a form of declarative bias
[50, 53] to determine the structure of learnable programs which in turn deﬁnes the hy-
pothesis space. In contrast to other forms of declarative bias, such as modes [45] or
grammars [7], metarules are logical statements that can be reasoned about, such as to
reason about the redundancy of sets of metarules, which we explore in this paper.

Metarules were introduced in the Blip system [19]. Kietz and Wrobel [33] studied
generality measures for metarules in the RDT system. A generality order is necessary be-
cause the RDT system searches the hypothesis space (which is deﬁned by the metarules)
in a top-down general-to-speciﬁc order. A key difference between RDT and MIL is that
whereas RDT requires metarules of increasing complexity (e.g. rules with an increas-
ing number of literals in the body), MIL derives more complex metarules through SLD-
resolution. This point is important because this ability allows MIL to start from smaller
sets of primitive metarules. In this paper we try to identify such primitive sets.

Using metarules to build a logic program is similar to the use of reﬁnement operators
in ILP [51, 57] to build a deﬁnite clause literal-by-literal6. As with reﬁnement operators,
it seems reasonable to ask about completeness and irredundancy of a set of metarules,
which we explore in this paper.

2.3 Logical redundancy

Detecting and eliminating redundancy in a clausal theory is useful in many areas of
computer science. In ILP logically reducing a theory is useful to remove redundancy from
a hypothesis space to improve learning performance [10, 22]. In general, simplifying or
reducing a theory often makes a theory easier to understand and use, and may also have
computational efﬁciency advantages.

2.3.1 Literal redundancy

Plotkin [52] used subsumption to decide whether a literal is redundant in a ﬁrst-order
clause. Joyner [31] independently investigated the same problem, which he called clause
condensation, where a condensation of a clause C is a minimum cardinality subset C ′ of
C such that C ′ |= C. Gottlob and Fermüller [26] improved Joyner’s algorithm and also

6 MIL uses example driven test-incorporation for ﬁnding consistent programs as opposed to the

generate-and-test approach of clause reﬁnement.

6

Andrew Cropper, Sophie Tourret

showed that determining whether a clause is condensed is coNP-complete. In contrast
to removing redundant literals, we focus on removing redundant clauses.

2.3.2 Clause redundancy

Plotkin [52] introduced methods to decide whether a clause is subsumption redundant
in a ﬁrst-order clausal theory. This problem has also been extensively studied in the
context of ﬁrst-order logic with equality due to its application in superposition-based
theorem proving [30, 63]. The same problem, and slight variants, has been extensively
studied in the propositional case [36, 37]. Removing redundant clauses has numerous
applications, such as to improve the efﬁciency of SAT [29]. In contrast to these works,
we focus on reducing theories formed of second-order Horn clauses (without equality),
which to our knowledge has not yet been extensively explored. Another difference is that
we additionally study redundancy based on SLD-derivations.

Cropper and Muggleton [10] used Progol’s entailment-reduction algorithm [45] to
identify irreducible, or minimal, sets of metarules. Their approach removed entailment
redundant clauses from sets of metarules. They identiﬁed theories that are (1) entail-
ment complete for certain fragments of second-order Horn logic, and (2) minimal or
irreducible in that no further reductions are possible. They demonstrated that in some
cases as few as two clauses are sufﬁcient to entail an inﬁnite theory. However, they only
considered small and highly constrained fragments of metarules. In particular, they fo-
cused on an exactly-two-connected fragment of metarules where each literal is dyadic and
each ﬁrst-order variable appears exactly twice in distinct literals. However, as discussed
in the introduction, entailment reduction is not always the most appropriate form of
reduction because it can remove metarules necessary to specialise a clause. Therefore,
in this paper, we go beyond entailment reduction and introduce derivation reduction.
We also consider more general fragments of metarules, such as a fragment of metarules
sufﬁcient to learn Datalog programs.

Cropper and Tourret [16] introduced the derivation reduction problem and stud-
ied whether sets of metarules could be derivationally reduced. They considered the
exactly-two-connected fragment previously considered by Cropper and Muggleton and
a two-connected fragment in which every variable appears at least twice, which is anal-
ogous to our singleton-free fragment (Section 5.3). They used graph theoretic methods
to show that certain fragments could not be completely derivationally reduced. They
demonstrated on the Michalski trains dataset that the partially derivationally reduced
set of metarules outperforms the entailment reduced set. In similar work Cropper and
Tourret elaborated on their graph theoretic techniques and expanded the results to un-
constrained resolution [61].

In this paper, we go beyond the work of Cropper and Tourret in several ways. First,
we consider more general fragments of metarules, including connected and Datalog frag-
ments. We additionally consider fragments with zero arity literals. In all cases we provide
additional theoretical results showing whether certain fragments can be reduced, and,
where possible, show the actual reductions. Second, Cropper and Tourret [61] focused
on derivation reduction modulo ﬁrst-order variable uniﬁcation, i.e. they considered the
case where factorisation [51] was allowed when resolving two clauses, which is not im-
plemented in practice in current MIL systems. For this reason, although Section 5 in [61]
and Section 5.1 in the present paper seemingly consider the same problem, the results
are opposite to one another. Third, in addition to entailment and derivation reduction,
we also consider subsumption reduction. We provide more theoretical results on the

Logical reduction of metarules

7

decidability of the reduction problems, such as showing a decidable case for deriva-
tion reduction (Theorem 4). Fourth, we describe the reduction algorithms and discuss
their computational complexity. Finally, we corroborate the experimental results of Crop-
per and Tourret on Michalski’s train problem [16] and provide additional experimental
results on two more domains: real-world string transformations and inducing Datalog
game rules from observations.

2.3.3 Theory minimisation

We focus on removing clauses from a clausal theory. A related yet distinct topic is theory
minimisation where the goal is to ﬁnd a minimum equivalent formula to a given input
formula. This topic is often studied in propositional logic [28]. The minimisation problem
allows for the introduction of new clauses. By contrast, the reduction problem studied
in this paper does not allow for the introduction of new clauses and instead only allows
for the removal of redundant clauses.

2.3.4 Prime implicates

Implicates of a theory T are the clauses that are entailed by T and are called prime
when they do not themselves entail other implicates of T . This notion differs from the
subsumption and derivation reduction because it focuses on entailment, and it differs
from entailment reduction because (1) the notion of a prime implicate has been studied
only in propositional, ﬁrst-order, and some modal logics [2, 18, 42]; (2) the generation
of prime implicates allows for the introduction of new clauses in the formula.

3 Logical reduction

We now introduce the reduction problem: the problem of ﬁnding redundant clauses in
a theory. We ﬁrst describe the reduction problem starting with preliminaries, and then
describe three instances of the problem. The ﬁrst two instances are based on existing
logical reduction methods: subsumption and entailment. The third instance is a new
form of reduction introduced in [16] based on SLD-derivations.

3.1 Preliminaries

We assume familiarity with logic programming notation [39] but we restate some key
terminology. A clause is a disjunction of literals. A clausal theory is a set of clauses. A
Horn clause is a clause with at most one positive literal. A Horn theory is a set of Horn
clauses. A deﬁnite clause is a Horn clause with exactly one positive literal. A Horn clause
is a Datalog clause if (1) it contains no function symbols, and (2) every variable that
appears in the head of the clause also appears in a positive (i.e. not negated) literal in
the body of the clause7. We denote the powerset of the set S as 2S.

7 Datalog also imposes additional constraints on negation in the body of a clause, but because we

disallow negation in the body we omit these constraints for simplicity.

8

3.1.1 Metarules

Andrew Cropper, Sophie Tourret

Although the reduction problem applies to any clausal theory, we focus on theories
formed of metarules:

Deﬁnition 1 (Metarule) A metarule is a second-order Horn clause of the form:

A0 ← A1, . . . , Am

where each Ai is a literal of the form P(T1, . . . , Tn) where P is either a predicate symbol
or a second-order variable that can be substituted by a predicate symbol, and each Ti is
either a constant symbol or a ﬁrst-order variable that can be substituted by a constant
symbol.

Name
Indent1
DIndent1
Indent2
DIndent2
Precon
Postcon
Curry
Chain

Metarule
P(A) ← Q(A)
P(A) ← Q(A), R(A)
P(A, B) ← Q(A, B)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A), R(A, B)
P(A, B) ← Q(A, B), R(B)
P(A, B) ← Q(A, B, R)
P(A, B) ← Q(A, C), R(C, B)

Table 1: Example metarules. The letters P, Q, and R denote existentially quantiﬁed
second-order variables. The letters A, B, and C denote universally quantiﬁed ﬁrst-order
variables.

Table 1 shows a selection of metarules commonly used in the MIL literature [11, 12, 14,
15, 44]. As Deﬁnition 1 states, metarules may include predicate and constant symbols.
However, we focus on the more general case where metarules only contain variables8.
In addition, although metarules can be any Horn clauses, we focus on deﬁnite clauses
with at least one body literal, i.e. we disallow facts, because their inclusion leads to
uninteresting reductions, where in almost all such cases the theories can be reduced to a
single fact9 We denote the inﬁnite set of all such metarules as M . We focus on fragments
of M , where a fragment is a syntactically restricted subset of a theory [4]:

m) We denote as M a
Deﬁnition 2 (The fragment M a
m the fragment of M where each
literal has arity at most a and each clause has at most m literals in the body. We replace
a by the explicit set of arities when we restrict the allowed arities further.

Example 1 M {2}
at most 2 body literals.

2

is a subset of M where each predicate has arity 2 and each clause has

Example 2 M {2}
at most m body literals.

m is a subset of M where each predicate has arity 2 and each clause has

8 By more general we mean we focus on metarules that are independent of any particular ILP problem

with particular predicate and constant symbols.

9 For instance, the metarule P(A) ← entails and subsumes every metarule with a monadic head.

Logical reduction of metarules

9

Example 3 M {0,2}
m
has at most m body literals.

is a subset of M where each predicate has arity 0 or 2 and each clause

Example 4 M a
clause has either 1 or 2 body literals.

{1,2} is a subset of M where each predicate has arity at most a and each

Let T be a clausal theory. Then we say that T is in the fragment M a
clause in T is in M a
m.

m if and only if each

3.2 Meta-interpretive learning

In Section 6 we conduct experiments to see whether using reduced sets of metarules can
improve learning performance. The primary purpose of the experiments is to test our
claim that entailment reduction is not always the most appropriate form of reduction.
Our experiments focus on MIL. For self-containment, we brieﬂy describe MIL.

Deﬁnition 3 (MIL input) An MIL input is a tuple (B, E+, E−, M ) where:

– B is a set of Horn clauses denoting background knowledge
– E+ and E− are disjoint sets of ground atoms representing positive and negative ex-

amples respectively
– M is a set of metarules

The MIL problem is deﬁned from a MIL input:

Deﬁnition 4 (MIL problem) Given a MIL input (B, E+, E−, M ), the MIL problem is to
return a logic program hypothesis H such that:

– ∀c ∈ H, ∃m ∈ M such that c = mθ , where θ is a substitution that grounds all the

existentially quantiﬁed variables in m

– H ∪ B |= E+
– H ∪ B 6|= E−

We call H a solution to the MIL problem.

The metarules and background deﬁne the hypothesis space. To explain our experimental
results in Section 6, it is important to understand the effect that metarules have on the
size of the MIL hypothesis space, and thus on learning performance. The following result
generalises previous results [12, 38]:

Theorem 1 (MIL hypothesis space) Given p predicate symbols and k metarules in M a
m,
the number of programs expressible with n clauses is at most (pm+1k)n.

Proof The number of ﬁrst-order clauses which can be constructed from a M a
m metarule
given p predicate symbols is at most pm+1 because for a given metarule there are at most
m + 1 predicate variables with at most pm+1 possible substitutions. Therefore the set of
such clauses S which can be formed from k distinct metarules in M a
m using p predicate
symbols has cardinality at most pm+1k. It follows that the number of programs which
can be formed from a selection of n clauses chosen from S is at most (pm+1k)n.
⊓⊔

10

Andrew Cropper, Sophie Tourret

Theorem 1 shows that the MIL hypothesis space increases given more metarules. The
Blumer bound [3]10, says that given two hypothesis spaces, searching the smaller space
will result in fewer errors compared to the larger space, assuming that the target hypoth-
esis is in both spaces. This result suggests that we should consider removing redundant
metarules to improve the learning performance. We explore this idea in the rest of the
paper.

3.3 Encapsulation

To reason about metarules (especially when running the Prolog implementations of the
reduction algorithms), we use a method called encapsulation [10] to transform a second-
order logic program to a ﬁrst-order logic program. We ﬁrst deﬁne encapsulation for
atoms:

Deﬁnition 5 (Atomic encapsulation) Let A be a second-order or ﬁrst-order atom of the
form P(T1, .., Tn). Then enc(A) = enc(P, T1, .., Tn) is the encapsulation of A.

For instance, the encapsulation of the atom parent(ann,andy) is enc(parent,ann,andy).
Note that encapsulation essentially ignores the quantiﬁcation of variables in metarules by
treating all variables, including predicate variables, as ﬁrst-order universally quantiﬁed
variables of the ﬁrst-order enc predicate. In particular, replacing existential quantiﬁers
with universal quantiﬁers on predicate variables is ﬁne for our work because we only rea-
son about the form of metarules, not their semantics, i.e. we treat metarules as templates
for ﬁrst-order clauses. We extend atomic encapsulation to logic programs:

Deﬁnition 6 (Program encapsulation) The logic program enc(P) is the encapsulation
of the logic program P in the case enc(P) is formed by replacing all atoms A in P by
enc(A).

For example, the encapsulation of the metarule P(A, B) ← Q(A, C), R(C, B) is enc(P, A, B) ←
enc(Q, A, C), enc(R, C, B). We extend encapsulation to interpretations [51] of logic pro-
grams:

Deﬁnition 7 (Interpretation encapsulation) Let I be an interpretation over the pred-
icate and constant symbols in a logic program. Then the encapsulated interpretation
enc(I) is formed by replacing each atom A in I by enc(A).

We now have the proposition:

Proposition 1 (Encapsulation models [10]) The second-order logic program P has a
model M if and only if enc(P) has the model enc(M ).

Proof Follows trivially from the deﬁnitions of encapsulated programs and interpreta-
⊓⊔
tions.

We can extend the deﬁnition of entailment to logic programs:

Proposition 2 (Entailment [10]) Let P and Q be second-order logic programs. Then P |=
Q if and only if every model enc(M ) of enc(P) is also a model of enc(Q).

10 The Blumer bound is a reformulation of Lemma 2.1 in [3].

Logical reduction of metarules

Proof Follows immediately from Proposition 1.

11

⊓⊔

These results allow us to reason about metarules using standard ﬁrst-order logic. In
the rest of the paper all the reasoning about second-order theories is performed at the
ﬁrst-order level. However, to aid the readability we continue to write non-encapsulated
metarules in the rest of the paper, i.e. we will continue to refer to sets of metarules as
second-order theories.

3.4 Logical reduction problem

We now describe the logical reduction problem. For the clarity of the paper, and to avoid
repeating deﬁnitions for each form of reduction that we consider (entailment, subsump-
tion, and derivability), we describe a general reduction problem which is parametrised
by a binary relation ⊏ deﬁned over any clausal theory, although in the case of derivabil-
ity, ⊏ is in fact only deﬁned over Horn clauses. Our only constraint on the relation ⊏ is
that if A ⊏ B, A ⊆ A′ and B′ ⊆ B then A′ ⊏ B′. We ﬁrst deﬁne a redundant clause:

Deﬁnition 8 (⊏-redundant clause) The clause C is ⊏-redundant in the clausal theory
T ∪ {C} whenever T ⊏ {C}.

In a slight abuse of notation, we allow Deﬁnition 8 to also refer to a single clause, i.e. in
our notation T ⊏ C is the same as T ⊏ {C}. We deﬁne a reduced theory:

Deﬁnition 9 (⊏-reduced theory) A clausal theory is ⊏-reduced if and only if it is ﬁnite
and it does not contain any ⊏-redundant clauses.

We deﬁne the input to the reduction problem:

Deﬁnition 10 (⊏-reduction input) A reduction input is a pair (T,⊏) where T is a clausal
theory and ⊏ is a binary relation over a clausal theory.

Note that a reduction input may (and often will) be an inﬁnite clausal theory. We deﬁne
the reduction problem:

Deﬁnition 11 (⊏-reduction problem) Let (T,⊏) be a reduction input. Then the ⊏-
reduction problem is to ﬁnd a ﬁnite theory T ′ ⊆ T such that (1) T ′ ⊏ T (i.e. T ′ ⊏ C
for every clause C in T ), and (2) T ′ is ⊏-reduced. We call T ′ a ⊏-reduction.

Although the input to a ⊏-reduction problem may contain an inﬁnite theory, the output
(a ⊏-reduction) must be a ﬁnite theory. We also introduce a variant of the ⊏-reduction
problem where the reduction must obey certain syntactic restrictions:

m-⊏-reduction problem) Let (T ,⊏,M a
Deﬁnition 12 (M a
two elements are as in a standard reduction input and M a
Then the M a
⊏-reduction of T , and (2) T ′ is in M a
m.

m) be a triple, where the ﬁrst
m is a target reduction theory.
m-⊏-reduction problem is to ﬁnd a ﬁnite theory T ′ ⊆ T such that (1) T ′ is a

12

Andrew Cropper, Sophie Tourret

3.5 Subsumption reduction

The ﬁrst form of reduction we consider is based on subsumption, which, as discussed in
Section 2, is often used to eliminate redundancy in a clausal theory:

Deﬁnition 13 (Subsumption) A clause C subsumes a clause D, denoted as C (cid:22) D, if
there exists a substitution θ such that Cθ ⊆ D.

Note that if a clause C subsumes a clause D then C |= D [55]. However, if C |= D
then it does not necessarily follow that C (cid:22) D. Subsumption can therefore be seen as
being weaker than entailment. Whereas checking entailment between clauses is undecid-
able [6], Robinson [55] showed that checking subsumption between clauses is decidable
(although in general deciding subsumption is a NP-complete problem [51]).

If T is a clausal theory then the pair (T, (cid:22)) is an input to the ⊏-reduction problem,
which leads to the subsumption reduction problem (S-reduction problem). We show that
the S-reduction problem is decidable for ﬁnite theories:

Proposition 3 (Finite S-reduction problem decidability) Let T be a ﬁnite theory. Then
the corresponding S-reduction problem is decidable.

Proof We can enumerate each element T ′ of 2T in ascending order on the cardinality
of T ′. For each T ′ we can check whether T ′ subsumes T , which is decidable because
subsumption between clauses is decidable. If T ′ subsumes T then we correctly return
T ′; otherwise we continue to enumerate. Because the set 2T is ﬁnite the enumeration
must halt. Because the set 2T contains T the algorithm will in the worst-case return T .
⊓⊔
Thus the problem is decidable.

3.6 Entailment reduction

As mentioned in the introduction, Cropper and Muggleton [10] previously used entail-
ment reduction [45] to reduce sets of metarules using the notion of an entailment re-
dundant clause:

Deﬁnition 14 (E-redundant clause) The clause C is entailment redundant (E-redundant)
in the clausal theory T ∪ {C} whenever T |= C.

If T is a clausal theory then the pair (T, |=) is an input to the ⊏-reduction problem,
which leads to the entailment reduction problem (E-reduction). We show the relationship
between an E- and a S-reduction:

Proposition 4 Let T be a clausal theory, TS be a S-reduction of T , and TE be an E-reduction
of T . Then TE |= TS.

Proof Assume the opposite, i.e. TE 6|= TS. This assumption implies that there is a clause
C ∈ TS such that TE 6|= C. By the deﬁnition of S-reduction, TS is a subset of T so C
must be in T , which implies that TE 6|= T . But this contradicts the premise that TE is an
E-reduction of T . Therefore the assumption cannot hold, and thus TE |= TS.
⊓⊔

We show that the E-reduction problem is undecidable for arbitrary clausal theories:

Logical reduction of metarules

13

Proposition 5 (E-reduction problem clausal decidability) The E-reduction problem for
clausal theories is undecidable.

Proof Follows from the undecidability of entailment in clausal logic [6].

⊓⊔

The E-reduction problem for Horn theories is also undecidable:

Proposition 6 (E-reduction problem Horn decidability) The E-reduction problem for
Horn theories is undecidable.

Proof Follows from the undecidability of entailment in Horn logic [41].

⊓⊔

The E-reduction problem is, however, decidable for ﬁnite Datalog theories:

Proposition 7 (E-reduction problem Datalog decidability) The E-reduction problem
for ﬁnite Datalog theories is decidable.

Proof Follows from the decidability of entailment in Datalog [17] using a similar algo-
⊓⊔
rithm to the one used in the proof of Proposition 3.

3.7 Derivation reduction

As mentioned in the introduction, entailment reduction can be too strong a form of
reduction. We therefore describe a new form of reduction based on derivability [16,61].
Although our notion of derivation reduction can be deﬁned for any proof system (such
as unconstrained resolution as is done in [61]) we focus on SLD-resolution because we
want to reduce sets of metarules, which are deﬁnite clauses. We deﬁne the function
Rn(T ) of a Horn theory T as:

R0(T ) = T
Rn(T ) = {C|C1 ∈ Rn−1(T ), C2 ∈ T, C is the binary resolvent of C1 and C2}

We use this function to deﬁne the Horn closure of a Horn theory:

Deﬁnition 15 (Horn closure) The Horn closure R∗(T ) of a Horn theory T is:

We state our notion of derivability:

Rn(T )

[
n∈N

Deﬁnition 16 (Derivability) A Horn clause C is derivable from the Horn theory T , writ-
ten T ⊢ C, if and only if C ∈ R∗(T ).

We deﬁne a derivationally redundant (D-redundant) clause:

Deﬁnition 17 (D-redundant clause) A clause C is derivationally redundant in the Horn
theory T ∪ {C} if T ⊢ C.

Let T be a Horn theory, then the pair (T, ⊢) is an input to the ⊏-reduction problem, which
leads to the derivation reduction problem (D-reduction problem). Note that a theory can
have multiple D-reductions. For instance, consider the theory T :

14

Andrew Cropper, Sophie Tourret

C1 = P(A, B) ← Q(B, A)
C2 = P(A, B) ← Q(A, C), R(C, B)
C3 = P(A, B) ← Q(C, A), R(C, B)

One D-reduction of T is {C1, C2} because we can resolve the ﬁrst body literal of C2 with
C1 to derive C3 (up to variable renaming). Another D-reduction of T is {C1, C3} because
we can likewise resolve the ﬁrst body literal of C3 with C1 to derive C2.

We can show the relationship between E- and D-reductions by restating the notion

of a SLD-deduction [51]:

Deﬁnition 18 (SLD-deduction [51]) Let T be a Horn theory and C be a Horn clause.
Then there exists a SLD-deduction of C from T , written T ⊢d C, if C is a tautology or if
there exists a clause D such that T ⊢ D and D subsumes C.

We can use the subsumption theorem [51] to show the relationship between SLD-deductions
and logical entailment:

Theorem 2 (SLD-subsumption theorem [51]) Let T be a Horn theory and C be a Horn
clause. Then T |= C if and only if T ⊢d C.

We can use this result to show the relationship between an E- and a D-reduction:

Proposition 8 Let T be a Horn theory, TE be an E-reduction of T , and TD be a D-reduction
of T . Then TE |= TD.

Proof Follows from the deﬁnitions of E-reduction and D-reduction because an E-reduction
⊓⊔
can be obtained from a D-reduction with an additional subsumption check.

We also use the SLD-subsumption theorem to show that the D-reduction problem is
undecidable for Horn theories:

Theorem 3 (D-reduction problem Horn decidability) The D-reduction problem for
Horn theories is undecidable.

Proof Assume the opposite, that the problem is decidable, which implies that T ⊢ C is
decidable. Since T ⊢ C is decidable and subsumption between Horn clauses is decidable
[24], then ﬁnding a SLD-deduction is also decidable. Therefore, by the SLD-subsumption
theorem, entailment between Horn clauses is decidable. However, entailment between
Horn clauses is undecidable [56], so the assumption cannot hold. Therefore, the problem
⊓⊔
must be undecidable.

However, the D-reduction problem is decidable for any fragment M a
m (e.g. deﬁnite Dat-
alog clauses where each clause has at least one body literal, with additional arity and
body size constraints). To show this result, we ﬁrst introduce two lemmas:

Lemma 1 Let D, C1, and C2 be deﬁnite clauses with md , mc1, and mc2 body literals respec-
tively, where md , mc1, and mc2 > 0. If {C1, C2} ⊢ D then mc1 ≤ md and mc2 ≤ md .

Proof Follows from the deﬁnitions of SLD-resolution [51].

⊓⊔

Note that Lemma 1 does not hold for unconstrained resolution because it allows for
factorisation [51]. Lemma 1 also does not hold when facts (bodyless deﬁnite clauses)
are allowed because they would allow for resolvents that are smaller in body size than
one of the original two clauses.

Logical reduction of metarules

15

Lemma 2 Let M a

m be a fragment of metarules. Then M a

m is ﬁnite up to variable renaming.

Proof Any literal in M a
m has at most a ﬁrst-order variables and 1 second-order variable,
so any literal has at most a + 1 variables. Any metarule has at most m body literals plus
the head literal, so any metarule has at most m+1 literals. Therefore, any metarule has at
most ((a + 1)(m + 1)) variables. We can arrange the variables in at most ((a + 1)(m + 1))!
ways, so there are at most ((a + 1)(m + 1))! metarules in M a
m up to variable renaming.
Thus M a
⊓⊔

m is ﬁnite up to variable renaming.

Note that the bound in the proof of Lemma 2 is a worst-case result. In practice there are
fewer usable metarules because we consider fragments of constrained theories, thus not
all clauses are admissible, and in all cases the order of the body literals is irrelevant. We
use these two lemmas to show that the D-reduction problem is decidable for M a
m:

Theorem 4 (M a
ories included in M a

m is decidable.

m-D-reduction problem decidability) The D-reduction problem for the-

Proof Let T be a ﬁnite clausal theory in M a
m and C be a deﬁnite clause with n > 0 body
literals. The problem is whether T ⊢ C is decidable. By Lemma 1, we cannot derive
C from any clause which has more than n body literals. We can therefore restrict the
resolution closure R∗(T ) to only include clauses with body lengths less than or equal to
n. In addition, by Lemma 2 there are only a ﬁnite number of such clauses so we can
compute the ﬁxed-point of R∗(T ) restricted to clauses of size smaller or equal to n in a
ﬁnite amount of steps and check whether C is in the set. If it is then T ⊢ C; otherwise
⊓⊔
T 6⊢ C.

3.8 k-derivable clauses

Propositions 3 and 7 and Theorem 4 show that the ⊏-reduction problem is decidable
under certain conditions. However, as we will shown in Section 4, even in decidable
cases, solving the ⊏-reduction problem is computationally expensive. We therefore solve
restricted k-bounded versions of the E- and D-reduction problems, which both rely on
SLD-derivations. Speciﬁcally, we focus on resolution depth-limited derivations using the
notion of k-derivability:

Deﬁnition 19 (k-derivability) Let k be a natural number. Then a Horn clause C is k-
derivable from the Horn theory T , written T ⊢k C, if and only if C ∈ Rk(T ).

The deﬁnitions for k-bounded E- and D-reductions follow from this deﬁnition but are
omitted for brevity. In Section 4 we introduce a general algorithm (Algorithm 1) to solve
the S-reduction problem and k-bounded E- and D-reduction problems.

4 Reduction algorithms

In Section 5 we logically reduce sets of metarules. We now describe the reduction algo-
rithms that we use.

16

Andrew Cropper, Sophie Tourret

4.1 ⊏-reduction algorithm

The reduce algorithm (Algorithm 1) shows a general ⊏-reduction algorithm that solves
the ⊏-reduction problem (Deﬁnition 11) when the input theory is ﬁnite11. We ignore
cases where the input is inﬁnite because of the inherent undecidability of the problem.
Algorithm 1 is largely based on Plotkin’s clausal reduction algorithm [52]. Given a ﬁnite
clausal theory T and a binary relation ⊏, the algorithm repeatedly tries to remove a
⊏-redundant clause in T . If it cannot ﬁnd a ⊏-redundant clause, then it returns the ⊏-
reduced theory. Note that since derivation reduction is only deﬁned over Horn theories,
in a ⊢-reduction input (T, ⊢), the theory T has to be Horn. We show total correctness of
the algorithm:

Proposition 9 (Algorithm 1 total correctness) Let (T ,⊏) be a ⊏-reduction input where
T is ﬁnite. Let the corresponding ⊏-reduction problem be decidable. Then Algorithm 1 solves
the ⊏-reduction problem.

Proof Trivial by induction on the size of T .

⊓⊔

Algorithm 1 ⊏-reduction algorithm

1
2
3
4
5
6
7

func reduce(T ,⊏):
if |T | < 2:

return T

else:

return T

if there is a clause C in T such that T \ {C } ⊏ C:

return reduce(T \ {C },⊏)

Note that Proposition 9 assumes that the given reduction problem is decidable and that
the input theory is ﬁnite. If you call Algorithm 1 with an arbitrary clausal theory and the
|= relation then it will not necessarily terminate. We can call Algorithm 1 with speciﬁc
binary relations, where each variation has a different time-complexity. Table 2 shows
different ways of calling Algorithm 1 with their corresponding time complexities, where
we assume ﬁnite theories as input. We show the complexity of calling Algorithm 1 with
the subsumption relation:

Proposition 10 (S-reduction complexity) If T is a ﬁnite clausal theory then calling Al-
gorithm 1 with (T,(cid:22)) requires at most O(|T |3) calls to a subsumption algorithm.

Proof For every clause in T the algorithm checks whether any other clause in T subsumes
C which requires at most O(|T |2) calls to a subsumption algorithm. If any clause C is
found to be S-redundant then the algorithm repeats the procedure on the theory (T \
{C}), so overall the algorithm requires at most O(|T |3) calls to a subsumption algorithm.
⊓⊔

11 In practice we use more efﬁcient algorithms for each approach. For instance, in the derivation reduc-
tion Prolog implementation we use the knowledge gained from Lemma 1 to add pruning so as to ignore
clauses that are too large to be useful to check whether a clause is derivable.

Logical reduction of metarules

17

Relation Output
(cid:22)
|=
|=k
⊢
⊢k

Complexity
O(|T |3)
Undecidable
O(|T |k+2)
Undecidable

S-reduction
E-reduction
k-E-reduction
D-reduction
k-D-reduction O(|T |k+2)

Table 2: Outputs and complexity of Algorithm 1 for different input relations and an
arbitrary ﬁnite clausal theory T . The time complexities are a function of the size of the
given theory, denoted by |T |.

Note that a more detailed analysis of calling Algorithm 1 with the subsumption relation
would depend on the subsumption algorithm used, which is an NP-complete problem
[24]. We show the complexity of calling Algorithm 1 with the k-bounded entailment
relation:

Proposition 11 (k-bounded E-reduction complexity) If T is a ﬁnite Horn theory and
k is a natural number then calling Algorithm 1 with (T,|=k) requires at most O(|T |k+2)
resolutions.

Proof In the worst case the derivation check (line 4) requires searching the whole SLD-
tree which has a maximum branching factor |T | and a maximum depth k and takes
O(|T |k) steps. The algorithm potentially does this step for every clause in T so the com-
plexity of this step is O(|T |k+1). The algorithm has to perform this check for every clause
in T with an overall worst-case complexity O(|T |k+2).
⊓⊔

The complexity of calling Algorithm 1 with the k-derivation relation is identical:

Proposition 12 (k-bounded D-reduction complexity) Let T be a ﬁnite Horn theory
and k be a natural number then calling Algorithm 1 with (T,⊢k) requires at most O(|T |k+2)
resolutions.

Proof Follows using the same reasoning as Proposition 11.

⊓⊔

4.2 M a

m-⊏-reduction algorithm

Although Algorithm 1 solves the ⊏-reduction problem, it does not solve the M a
m-reduction
problem (Deﬁnition 12). For instance, suppose you have the following theory T in M 2
4 :

M1 = P(A, B) ← Q(B, A)
M2 = P(A, B) ← Q(A, A), R(B, B)
M3 = P(A, B) ← Q(A, C), R(B, C)
M4 = P(A, B) ← Q(B, C), R(A, D), S(A, D), T (B, C)

18

Andrew Cropper, Sophie Tourret

Suppose you want to know whether T can be E-reduced to M 2
with (T, |=) (i.e. the entailment relation) will return T ′ = {M1, M4} because: M4 |= M2
M4 |= M3

13, and {M1, M4} cannot be further E-reduced.

2 . Then calling Algorithm 1
12,

Although T ′ is an E-reduction of T , it is not in M 2

2 because M4 is not in M 2

the theory T can be M 2
{M1, M2, M3} cannot be further reduced. In general, let T be a theory in M a
be an E-reduction of T , then T ′ is not necessarily in M a
2 .

2 -E-reduced to {M1, M2, M3} because {M2, M3} |= M4

2 . However,
14, and
m and an T ′

Algorithm 2 overcomes this limitation of Algorithm 1. Given a ﬁnite clausal theory
m, Algorithm 2 determines whether
m. If there is, it returns the reduced theory; otherwise it
m-⊏-reduction problem. We show

T , a binary relation ⊏, and a reduction fragment M a
there is a ⊏-reduction of T in M a
returns false. In other words, Algorithm 2 solves the M a
total correctness of Algorithm 2:

Proposition 13 (Algorithm 2 correctness) Let (T ,⊏,M a
m-⊏-reduction input.
If the corresponding ⊏-reduction problem is decidable then Algorithm 2 solves the corre-
sponding M a

m) be a M a

m-⊏-reduction problem.

Sketch Proof We provide a sketch proof for brevity. We need to show that the function
aux correctly determines whether B ⊏ T , which we can show by induction on the size
of T . Assuming aux is correct, then if T can be reduced to B, the mreduce function calls
Algorithm 1 to reduce B, which is correct by Proposition 9. Otherwise it returns false. ⊓⊔

Algorithm 2 M a

m-⊏-reduction

1
2
3
4
5
6
7
8
9
10
11
12
13
14

function mreduce(T ,⊏,M a
m)
B = {C |C ∈ T ∩ M a
m}
if aux(T ,⊏,B):

return reduce(B,⊏)

return false

function aux(T ,⊏,B)
if |T| == 0:

return true
pick any C in T
T ′ = T \ {C }
if B ⊏ C:

return aux(T ′,⊏,B)

return false

12 Rename the variables in M4 to form M ′
4 = P0(X1, X2) ← P1(X2, X3), P2(X1, X4), P3(X1, X4),
P4(X2, X3). Then M ′
4θ = P(A, B) ← R(B, B), Q(A, A), Q(A, A), R(B, B) where θ = {P0/P, P1/R, P2/Q, P3/Q,
P4/R, X1/A, X2/B, X3/B, X4/A}. It follows that M ′
4θ ⊆ M2, so M4 (cid:22) M2, which in turn implies M4 |= M2.
13 Rename the variables in M4 to form M ′
4 = P0(X1, X2) ← P1(X2, X3), P2(X1, X4), P3(X1, X4),
P4(X2, X3). Then M ′
4θ = P(A, B) ← R(B, C ), Q(A, C ), Q(A, C ), R(B, C ) where θ = {P0/P, P1/R, P2/Q, P3/Q,
P4/R, X1/A, X2/B, X3/C , X4/C }. It follows that M ′
4θ ⊆ M3, so M4 (cid:22) M3, which in turn implies M4 |= M3.
14 Rename the variables in M3 to form M ′
3 = P0(X , Y ) ← P1(X , Z), P2(Y, Z). Resolve the ﬁrst body literal
of M2 with M3 to form R1 = P(A, B) ← P1(A, Z), P2(A, Z), R(B, B). Rename the variables P1 to P3, P2 to P4,
and Z to Z1 in R1 (to standardise apart the variables) to form R2 = P(A, B) ← P3(A, Z1), P4(A, Z1), R(B, B).
Resolve the last body literal of R2 with M ′
3 to form R3 = P(A, B) ← P3(A, Z1), P4(A, Z1), P1(B, Z), P2(B, Z).
Rename the variables Z1 to D, Z t oC , P3 to R, P4 to S, P1 to Q, and P2 to T in R3 to form R4 = P(A, B) ←
R(A, D), S(A, D), Q(B, C ), T (B, C ).Thus, R4 = M4, so it follows that and {M2, M3} |= M4

Logical reduction of metarules

19

Fragment Description

C
D
K
U

connected clauses
connected Datalog clauses
connected Datalog clauses without singleton variables
connected Datalog clauses without duplicate variables

Table 3: The four main fragments of M that we consider.

5 Reduction of metarules

We now logically reduce fragments of metarules. Given a fragment M a
operator ⊏, we have three main goals:

m and a reduction

G1: identify a M a
G2: determine whether M a
2
G3: determine whether M a

⊏ M a
∞

k -⊏-reduction of M a

m for some k as small as possible

∞ has any (ﬁnite) ⊏-reduction

We work on these goals for fragments of M a
m relevant to ILP. Table 3 shows the four
fragments and their main restrictions. The subsequent sections precisely describe the
fragments.

Our ﬁrst goal (G1) is to essentially minimise the number of body literals in a set of
metarules, which can be seen as trying to enforce an Occamist bias. We are particularly
interested reducing sets of metarules to fragments with at most two body literals because
M {2}
augmented with one function symbol has universal Turing machine expressivity
2
[60]. In addition, previous work on MIL has almost exclusively used metarules from the
fragment M 2
2 . Our second goal (G2) is more general and concerns reducing an inﬁnite
set of metarules to M a
2 . Our third goal (G3) is similar, but is about determining whether
an inﬁnite set of metarules has any ﬁnite reduction.

We work on the goals by ﬁrst applying the reduction algorithms described in the
previous section to ﬁnite fragments restricted to 5 body literals (i.e. M a
5 ). This value
gives us a sufﬁciently large set of metarules to reduce but not too large that the re-
duction problem is intractable. When running the E- and D-reduction algorithms (both
k-bounded), we use a resolution-depth bound of 7, which is the largest value for which
the algorithms terminate in reasonable time15. After applying the reduction algorithms
to the ﬁnite fragments, we then try to solve G2 by extrapolating the results to the inﬁnite
case (i.e. M a
∞). In cases where M a
∞, we then try to solve G3 by seeing whether
there exists any natural number k such that M a
k

2 6⊏ M a

⊏ M a

∞.

5.1 Connected (C a

m) results

We ﬁrst consider a general fragment of metarules. The only constraint is that we follow
the standard ILP convention [10, 20, 27, 51] and focus on connected clauses16:

15 The entailment and derivation reduction algorithms often took 4-5 hours to ﬁnd a reduction. How-
ever, in some cases, typically where the fragments contained many metarules, the algorithms took around
12 hours to ﬁnd a reduction. By contrast, the subsumption reduction algorithm typically found a reduc-
tion in 30 minutes.
16 Connected clauses are also known as linked clauses [27].

20

Andrew Cropper, Sophie Tourret

Deﬁnition 20 (Connected clause) A clause is connected if the literals in the clause
cannot be partitioned into two sets such that the variables appearing in the literals of
one set are disjoint from the variables appearing in the literals of the other set.

The following clauses are all connected:

P(A) ← Q(A)
P(A, B) ← Q(A, C)
P(A, B) ← Q(A, B), R(B, D), S(D, B)

By contrast, these clauses are not connected:

P(A) ← Q(B)
P(A, B) ← Q(A), R(C)
P(A, B) ← Q(A, B), S(C)

We denote the connected fragment of M a
m as C a
m. Table 4 shows the maximum body size
and the cardinality of the reductions obtained when applying the reduction algorithms
to C a
5 for different values of a. To give an idea of the scale of the reductions, the fragment
C {1,2}
contains 77398 unique metarules, of which E-reduction removed all but two of
5
them. Table 5 shows the actual reductions for C {1,2}
. Reductions for other connected
fragments are in Appendix A.1.

5

Arities
a
0
1
2
0,1
0,2
1,2
0,1,2

S-reduction

E-reduction

D-reduction

Bodysize
1
1
1
1
1
1
1

Cardinality
1
1
4
3
6
9
12

Bodysize
1
1
1
1
1
1
1

Cardinality
1
1
1
3
3
2
4

Bodysize
2
2
5
2
5
4
5

Cardinality
2
2
6
5
21
8
13

Table 4: Cardinality and maximal body size of the reductions of C a
can be S- and E-reduced to C a

1 but they cannot all be D-reduced to C a
2 .

5 . All the fragments

S-reduction

P(A) ← Q(A)
P(A) ← Q(A, B)
P(A) ← Q(B, A)
P(A, B) ← Q(A)
P(A, B) ← Q(B)
P(A, B) ← Q(A, C)
P(A, B) ← Q(B, C)
P(A, B) ← Q(C, A)
P(A, B) ← Q(C, B)

E-reduction
P(A) ← Q(B, A)
P(A, B) ← Q(A)

D-reduction

P(A) ← Q(B, A)
P(A, A) ← Q(B, A)
P(A, B) ← Q(B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(B, B)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, C), R(B, C)
P(A, B) ← Q(A, C), R(A, D), S(B, C), T (B, D), U(C, D)

Table 5: Reductions of the connected fragment C {1,2}

5

.

As Table 4 shows, all the fragments can be S- and E-reduced to C a
general C a

∞ has a C a

1 -S-reduction:

1 . We show that in

Logical reduction of metarules

21

Theorem 5 (C a

∞ S-reducibility) For all a > 0, the fragment C a

∞ has a C a

1 -S-reduction.

Proof Let C be any clause in C a
∞, where a > 0. By the deﬁnition of connected clauses
there must be at least one body literal in C that shares a variable with the head literal
of C. The clause formed of the head of C with the body literal directly connected to it is
by deﬁnition in C a
⊓⊔

1 and clearly subsumes C. Therefore C a

1 (cid:22) C a
∞.

We likewise show that C a

∞ always has a C a

1 -E-reduction:

Theorem 6 (C a

∞ E-reducibility) For all a > 0, the fragment C a

∞ has a C a

1 -E-reduction.

Proof Follows from Theorem 5 and Proposition 4.

⊓⊔

As Table 4 shows, the fragment C 2
2 when running the
derivation reduction algorithm. However, because we run the derivation reduction algo-
rithm with a maximum derivation depth, this result alone is not enough to guarantee that
the output cannot be further reduced. Therefore, we show that C 2
5 cannot be D-reduced
to C 2
2 :

5 could not be D-reduced to C 2

Proposition 14 (C 2

5 D-irreducibility) The fragment C 2

5 has no C 2

2 -D-reduction.

Proof We denote by P (C) the set of all clauses that can be obtained from a given
clause C by permuting the arguments in its literals up to variable renaming. For ex-
ample if C = P(A, B) ← Q(A, C) then P (C) = {(C), (P(A, B) ← Q(C, A)), (P(B, A) ←
Q(A, C)), (P(B, A) ← Q(C, A))} up to variable renaming.

Let CI denote the clause P(A, B) ← Q(A, C), R(A, D), S(B, C), T (B, D), U(C, D). We
prove that no clause in P (CI ) can be derived from C 2
2 by induction on the length of
derivations. Formally, we show that there exist no derivations of length n from C 2
2 to a
clause in P (CI ). We reason by contradiction and w.l.o.g. we consider only the clause CI .
For the base case n = 0, assume that there is a derivation of length 0 from C 2
2 to CI .
2 , but this clearly cannot hold given the body size

This assumption implies that CI ∈ C 2
of CI .

For the general case, assume that the property holds for all k < n and by contradiction
consider the ﬁnal inference in a derivation of length n of CI from C 2
2 . Let C1 and C2
denote the premises of this inference. Then the literals occurring in CI must occur up to
variable renaming in at least one of C1 and C2. We consider the following cases separately.

– All the literals of CI occur in the same premise: because of Lemma 1, this case is
impossible because this premise would contain more literals than CI (the ones from
CI plus the resolved literal).

– Only one of the literals of CI occurs separately from the others: w.l.o.g., assume that
the literal Q(A, C) occurs alone in C2 (up to variable renaming). Then C2 must be of
the form H(A, C) ← Q(A, C) or H(C, A) ← Q(A, C) for some H, where the H-headed
literal is the resolved literal of the inference that allows the uniﬁcation of A and C
17. In this case, C1 belongs to P (CI) and a derivation of
with their counterparts in C1
C1 from C 2
2 of length smaller than n exists as a strict subset of the derivation to CI
of length n. This contradicts the induction hypothesis, thus the assumed derivation
of C cannot exist.

17 Those are the only options to derive CI .Otherwise, e.g. with C2 = H(A′, C ′) ← Q(A′, D′), the resulting
clause is not CI because D′ is not uniﬁed with any of the variables in C1 (whereas A′ uniﬁes with A and
C ′ with C ), e.g. the result includes the literal Q(A, D′) instead of Q(A, C ) hence it is not CI .

22

Andrew Cropper, Sophie Tourret

– Otherwise, the split of the literals of CI between C1 and C2 is always such that at least
three variables must be uniﬁed during the inference. For example, consider the case
where P(A, B) ← Q(A, C) ⊂ C1 and the set {R(A′, D), S(B′, C ′), T (B′, D), U(C ′, D)}
occurs in the body of C2 (up to variable renaming). Then A′, B′ and C ′ must unify
respectively with A, B and C for CI to be derived (up to variable renaming). However
the inference can at most unify two variable pairs since the resolved literal must be
dyadic at most and thus this inference is impossible, a contradiction.

Thus CI and all of P (CI ) cannot be derived from C 2
neither a subset of C 2
3 nor of C 2
3 and from C 2
from C 2
4 .
We generalise this result to C 2

2 . Note that, since P (CI ) is also
4 , this proof also shows that P (CI) cannot be derived
⊓⊔

∞:

Theorem 7 (C 2

∞ D-irreducibility) The fragment C 2

∞ has no D-reduction.

∞ does not have a C 2

Proof It is enough to prove that C 2
m-D-reduction for an arbitrary
m because any D-reduced theory, being ﬁnite, admits a bound on the body size of the
clauses it contains. Starting from CI as deﬁned in the proof of Proposition 14, apply the
following transformation iteratively for k from 1 to m: replace the literals containing Q
and R (i.e. at ﬁrst Q(A, C) and R(A, D)) with the following set of literals Q(A, Ck), R(A, Dk),
Vk(Ck, Dk), Q k(Ck, C), Rk(Dk, D) where all variables and predicate variables labeled with
. This clause is of body size 3m + 5 and
k are new. Let the resulting clause be denoted CIm
thus does not belong to C 2
m. Moreover, for the same reason that CI cannot be derived
from any C 2
cannot be derived from
any C 2
⊓⊔

m′ with m′ < 5 (see the proof of Proposition 14) CIm

m′ with m′ < 3m + 5. In particular, CIm

cannot be derived from C 2
m.

Another way to generalise Proposition 14 is the following:

Theorem 8 (C a
reduction.

∞ D-irreducibility) For a ≥ 2, the fragment C a

∞ has no C a

a2+a−2-D-

Proof Let Ca denote the clause

Ca = P(A1, . . . , Aa) ←Q1,1(A1, B1,1, . . . , B1,a−1) . . .Q1,a(A1, Ba,1, . . . , Ba,a−1)

. . .
Q a,1(Aa, B1,1, . . . , B1,a−1) . . .Q a,a(Aa, Ba,1, . . . , Ba,a−1)
R1(B1,1, . . . , Ba,1), . . . , Ra−1(B1,a−1, . . . , Ba,a−1)

Note that for a = 2, the clauses Ca and CI from the proof of Proposition 14 coincide.
In fact to show that Ca is irreducible for any a, it is enough to consider the proof of
Proposition 14 where Ca is substituted to CI and where the last case is generalised in the
following way:

– the split of the literals of Ca between C1 and C2 is always such that at least a + 1
variables must be uniﬁed during the inference, which is impossible since the resolved
literal can at most hold a variables.

The reason this proof holds is that any subset of Ca contains at least a + 1 distinct vari-
ables. Since Ca is of body size a2 + a − 1, this counter-example proves that C a
∞ has no
C a
⊓⊔

a2+a−2-D-reduction.

Note that this is enough to conclude that C a
prove that C a
∞ is not D-reducible.

∞ cannot be reduced to C a

2 but it does not

Logical reduction of metarules

23

5.1.1 Summary

∞ can always be S- and E-reduced to C a
∞ cannot be D-reduced to C 2

Table 6 summarises our theoretical results from this section. Theorems 5 and 6 show
that C a
1 respectively. By contrast, Theorem 7
shows that C 2
∞ has no D-
reduction. Theorem 7 has direct (negative) implications for MIL systems such as Metagol
and HEXMIL. We discuss these implications in more detail in Section 7.

2 . In fact, Theorem 7 says that C 2

Arity
1
2
>2

S
D
E
Ø Ø Ø
Ø Ø ×
Ø Ø ×

2 . The symbol Ø denotes that
Table 6: Existence of a S-, E- or D-reduction of C a
the fragment does have a reduction. The symbol × denotes that the fragment does not
have a reduction.

∞ to C a

5.2 Datalog (D a

m) results

We now consider Datalog clauses, which are often used in ILP [1, 12, 20, 32, 49, 58]. The
relevant Datalog restriction is that if a variable appears in the head of a clause then it
must also appear in a body literal. If we look at the S-reductions of C {1,2}
in Table 5
then the clause P(A, B) ← Q(B) is not a Datalog clause because the variable A appears
in the head but not in the body. We denote the Datalog fragment of C a
m as D a
m. Table
7 shows the results of applying the reduction algorithms to D a
5 for different values of
a. Table 8 shows the reductions for the fragment D{1,2}
, which are used in Experiment
3 (Section 6.3) to induce Datalog game rules from observations. Reductions for other
Datalog fragments are in Appendix A.2.

5

5

Arities
a
0
1
2
0,1
0,2
1,2
0,1,2

S-reduction

E-reduction

D-reduction

Bodysize
1
1
2
1
2
2
2

Cardinality
1
1
4
2
5
10
11

Bodysize
1
1
2
1
2
2
2

Cardinality
1
1
2
2
3
3
4

Bodysize
2
2
5
2
5
5
5

Cardinality
2
2
10
5
38
11
14

Table 7: Cardinality and maximal body size of the reductions of D a
can be S- and E-reduced to D a

2 but they cannot all be D-reduced to D a
2 .

5 . All the fragments

We show that D2

∞ can be S-reduced to D2
2 :

Proposition 15 (D2

∞ S-reducibility) The fragment D2

∞ has a D2

2 -S-reduction.

24

Andrew Cropper, Sophie Tourret

E-reduction
P(A) ← Q(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A), R(B)

S-reduction

P(A) ← Q(A)
P(A) ← Q(A, B)
P(A) ← Q(B, A)
P(A, A) ← Q(B, A)
P(A, B) ← Q(A), R(B)
P(A, B) ← Q(A), R(B, C)
P(A, B) ← Q(A, B)
P(A, B) ← Q(B), R(A, C)
P(A, B) ← Q(B, A)
P(A, B) ← Q(B, C), R(A, D)

D-reduction

P(A) ← Q(B, A)
P(A, A) ← Q(A)
P(A, A) ← Q(A, A)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, C), R(B, C)
P(A, B) ← Q(B, C), R(A, D)
P(A, B) ← Q(B, C), R(A, D), S(B, D), T (C, E)
P(A, B) ← Q(A, C), R(A, D), S(B, C), T (B, D), U(C, D)
P(A, B) ← Q(B, C), R(A, D), S(C, E), T (B, F ), U(D, F )
P(A, B) ← Q(B, C), R(B, D), S(C, E), T (A, F ), U(D, F )

Table 8: Reductions of the Datalog fragment D{1,2}

5

.

Proof Follows using the same argument as in Theorem 5 but the reduction is to D2
2
instead of D2
1 . This difference is due to the Datalog constraint that states: if a variable
appears in the head it must also appear in the body. For clauses with dyadic heads, if the
two head argument variables occur in two distinct body literals then the clause cannot
be further reduced beyond D2
⊓⊔
2 .

We show how this result cannot be generalised to D a

∞:

Theorem 9 (D a
reduction.

∞ S-irreducibility) For a > 0, the fragment D a

∞ does not have a D a

a−1-S-

Proof As a counter-example to a D a
a−1-S-reduction, consider Ca = P(X 1, . . . , X a) ← Q1(X 1),
. . . , Q a(X a). The clause Ca does not belong to D a
a−1 and cannot be S-reduced to it because
the removal of any subset of its literals leaves argument variables in the head without
their counterparts in the body. Hence, any subset of Ca does not belong to the Datalog
fragment. Thus Ca cannot be subsumed by a clause in D a
⊓⊔

a−1.

However, we can show that D a

∞ can always be S-reduced to D a
a :

Theorem 10 (D a
reduction.

∞ to D a

a S-reducibility) For a > 0, the fragment D a

∞ has a D a

a -S-

∞ has a D a

∞ has a subclause of body size at most a that is also in D a

Proof To prove that D a
a -S-reduction it is enough to remark that any clause
in D a
∞, the worst case being
clauses such as Ca where all argument variables in the head occur in a distinct literal in
⊓⊔
the body.

We also show that D a

∞ always has a D a

2 -E-reduction, starting with the following lemma:

Lemma 3 For a > 0 and n ∈ {1, . . . , a}, the clause

P0(A1, A2, . . . , An) ← P1(A1), P2(A2), . . . , Pn(An)

is D a

2 -E-reducible.

Proof By induction on n.

– For the base case n = 2, by deﬁnition D a

2 contains P0(A1, A2) ← P1(A1), P2(A2)

Logical reduction of metarules

25

– For the inductive step, assume the claim holds for n−1. We show it holds for n. By def-
inition D a
2 contains the clause D1 = P(A1, A2, . . . , An) ← P0(A1, A2, . . . , An−1), Pn(An).
By the inductive hypothesis, D2 = P0(A1, A2, . . . , An−1) ← P1(A1), . . . , Pn−1(An−1) is
D a−1
2 -E-reducible. Together, D1 and D2 entail D =
2
P0(A1, A2, . . . , An) ← P1(A1), P2(A2), . . . , Pn(An), which can be seen by resolving the
literal P0(A1, A2, . . . , An−1) from D1 with the same literal from D2 to derive D. Thus D
is D a

-E-reducible, and thus also D a

2 -E-reducible.

⊓⊔

Theorem 11 (D a

∞ E-reducibility) For a > 0, the fragment D a

∞ has a D a

2 -E-reduction.

Proof Let C be any clause in D a
∞. We denote the head of C by P(A1, . . . , An), where
0 < n ≤ a. The possibility that some of the Ai are equal does not impact the reasoning.
If n = 1, then by deﬁnition, there exists a literal L1 in the body of C such that A1
occurs in L1. It is enough to consider the clause P(A1) ← L1 to conclude, because P(A1)
is the head of C and L1 belongs to the body of C, thus P(A1) ← L1 entails C, and this
clause belongs to D a
2 .

In the case where n > 1, there must exist literals L1, . . . , Ln in the body of C such that
Ai occurs in Li for i ∈ {1, . . . , n}. Consider the clause C ′ = P(A1, . . . , An) ← L1, . . . , Ln.
There are a few things to stress about C ′:

– The clause C ′ belongs to D a
– Some Li may be identical with each other, since the Ais may occur together in literals

∞.

or simply be equal, but this scenario does not impact the reasoning.

– The clause C ′ entails C because C ′ is equivalent to a subset of C (but this subset may
be distinct from C ′ due to C ′ possibly including some extra duplicated literals).

2 by deﬁnition, thus D a

Now consider the clause D = P(A1, . . . , An) ← P1(A1), . . . , Pn(An). For i ∈ {1, . . . , n},
2 ∪ D ⊢ D′ where D′ =
the clause Pi(Ai) ← Li belongs to D a
2 -E-reducible, hence D′ is also
P(A1, . . . , An) ← L1, . . . , Ln. Moreover, by Lemma 3, D is D a
D a
2 -E-reducible. Note that this notation hides the fact that if a variable occurs in distinct
body literals Li in C ′, this connection is not captured in D′ where distinct variables will
occur instead, thus there is no guarantee that D′ = C ′. For example, if C ′ = P(A1, A2) ←
Q(A1, B, A2), R(A2, B) then D′ = P(A1, A2) ← Q(A1, B, A′
2), R(A2, B′), R(A2, B′)
However, it always holds that D′ |= C ′, because D′ subsumes C ′. In our small example,
it is enough to consider the substitution θ = {B′/B, A′
2/A2} to observe this. Thus by
transitivity of entailment, we can conclude that C is D a

2), Q(A1, B, A′

2 -E-reducible.

⊓⊔

As Table 7 shows, not all of the fragments can be D-reduced to D a
that D2
presented in the proof also belong to D2

2 . In particular, the result
2 -D-reduction follows from Theorem 7 because the counterexamples

∞ has no D2

∞.

5.2.1 Summary

Table 9 summarises our theoretical results from this section. Theorem 9 shows that D a
∞
a−1-S-reduction. This result differs from the connected fragment where C a
never has a D a
∞
could always be S-reduced to C a
2 . However, Theorem 9 shows that D a
∞ can always be S-
reduced to D a
∞ can always
be E-reduced to C a

a . As with the connected fragment, Theorem 11 shows that D a

∞ has no D-reduction follows from Theorem 7.

2 . The result that D2

26

Andrew Cropper, Sophie Tourret

Arity
1
2
>2

S
D
E
Ø Ø Ø
Ø Ø ×
× Ø ×

Table 9: Existence of a S-, E- or D-reduction of D a

∞ to D a
2 .

5.3 Singleton-free (K a

m ) results

It is common in ILP to require that all the variables in a clause appear at least twice
[10, 46, 54], which essentially eliminates singleton variables. We call this fragment the
singleton-free fragment:

Deﬁnition 21 (Singleton-free) A clause is singleton-free if each ﬁrst-order variable ap-
pears at least twice

For example, if we look at the E-reductions of the connected fragment C {1,2}
shown in
Table 5 then the clause P(A) ← Q(B, A) is not singleton-free because the variable B only
appears once. We denote the singleton-free fragment of D a
m . Table 10 shows the
results of applying the reduction algorithms to K a
5 . Table 11 shows the reductions of
K {2}
5

. Reductions for other singleton-free fragments are in Appendix A.3.

m as K a

5

Arities
a
0
1
2
0,1
0,2
1,2
0,1,2

S-reduction

E-reduction

D-reduction

Bodysize
1
1
4
1
5
4
4

Cardinality
1
1
3
2
4
8
9

Bodysize
1
1
2
1
2
2
2

Cardinality
1
1
3
2
3
4
5

Bodysize
2
2
5
2
5
5
5

Cardinality
2
2
7
5
23
8
11

Table 10: Cardinality and maximal body size of the reductions of K a
5 .

S-reduction

P(A, B) ← Q(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(B, C ), R(A, D),
S(A, D), T (B, C )

E-reduction
P(A, B) ← Q(B, A)
P(A, B) ← Q(A, A), R(B, B)
P(A, B) ← Q(A, C ), R(B, C )

D-reduction

P(A, A) ← Q(A, A)
P(A, B) ← Q(B, A)
P(A, A) ← Q(A, B), R(B, B)
P(A, B) ← Q(A, A), R(B, B)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, C ), R(B, C )
P(A, B) ← Q(A, C ), R(A, D),

S(B, C ), T (B, D), U(C , D)

Table 11: Reductions of the singleton-free fragment K {2}

5

Unlike in the connected and Datalog cases, the fragment K {2}
to K {2}
2

∞ cannot be reduced to K 2
2 .

. We show that K 2

5

is no longer S-reducible

Logical reduction of metarules

27

Proposition 16 (K 2

∞ S-reducibility) The fragment K 2

∞ does not have a K 2

2 -S-reduction.

Proof As a counter-example, consider the clause:

C = P(A, B) ← Q(A, D), R(A, D), S(B, C), T (B, C)

Consider removing any non-empty subset of literals from the body of C. Doing so leads to
a singleton variable in the remaining clause, so it is not a singleton-free clause. Moreover,
for any other clause to subsume C it must be more general than C, but that is not possible
again because of the singleton-free constraint18.
⊓⊔

We can likewise show that this result holds in the general case:

Theorem 12 (K a
S-reduction.

∞ S-reducibility) For a ≥ 2, the fragment K a

∞ does not have a K a

2a−1-

Proof We generalise the clause C from the proof of Proposition 16 to deﬁne the clause
Ca = P(A1, . . . , Aa) ← P1(A1, B1), P2(A1, B1), . . . , P2a−1(Aa, Ba), P2a(Aa, Ba). The same rea-
soning applies to Ca as to C(= C2), making Ca irreducible in K a
∞. Moreover Ca is of
body size 2a, thus Ca is a counterexample to a K a
⊓⊔

2a−1-S-reduction of K a
∞.

However, all the fragments can be E-reduced to K a
2 .

Theorem 13 (K a

∞ E-reducibility) For a > 0, the fragment K a

∞ has a K a

2 -E-reduction.

Proof The proof of Theorem 13 is an adaptation of that of Theorem 11. The only dif-
ference is that if n = 1 then P(A1) ← L1, L1 must be considered instead of P(A1) ← L1
to ensure the absence of singleton variables in the body of the clause, and for the same
reason, in the general case, the clause D′ = P(A1, . . . , An) ← L1, ..., Ln must be replaced
by D′ = P(A1, . . . , An) ← L1, L1, . . . , Ln, Ln. Note that C ′ is not modiﬁed and thus may or
may not belong to K a
∞. With these modiﬁcations,
the proof carries from K a
2 , including the results in Lemma 3.
⊓⊔

∞. However, it is enough that C ′ ∈ D a
2 as from D a

∞ to K a

∞ to D a

5.3.1 Summary

∞ does not have a K a

Table 12 summarises our theoretical results from this section. Theorem 12 shows that
for a ≥ 2, the fragment K a
2a−1-S-reduction. This result contrasts
∞ always has a D a
with the Datalog fragment where D a
a -S-reduction. As is becoming clear,
adding more restrictions to a fragment typically results in less S-reducibility. By contrast,
as with the connected and Datalog fragments, Theorem 13 shows that fragment K a
∞
always has a K a
∞ has no D-
reduction for a ≥ 2.

2 -E-reduction. In addition, as with the other fragments, K a

18 Note that this proof also shows that K 2

∞ does not have a K 2

3 -S-reduction.

28

Andrew Cropper, Sophie Tourret

Arity
1
2
>2

S
D
E
Ø Ø Ø
× Ø ×
× Ø ×

Table 12: Existence of a S-, E- or D-reduction of K a

∞ to K a
2 .

5.4 Duplicate-free (U a

m) results

The previous three fragments are general in the sense that they have been widely used in
ILP. By contrast, the ﬁnal fragment that we consider is of particular interest to MIL. Table
1 shows a selection of metarules commonly used in the MIL literature. These metarules
have been successfully used despite no theoretical justiﬁcation. However, if we consider
the reductions of the three fragments so far, the identity, precon, and postcon metarules
do not appear in any reduction. These metarules can be derived from the reductions,
typically using either the P(A) ← Q(A, A) or P(A, A) ← Q(A) metarules. To try to identify
a reduction which more closely matches the metarules shown in Table 1, we consider
a fragment that excludes clauses in which a literal contains multiple occurrences of the
same variable. For instance, this fragment excludes the previously mentioned metarules
and also excludes the metarule P(A, A) ← Q(B, A), which was in the D-reduction shown
in Table 5. We call this fragment duplicate-free. It is a sub-fragment of K a
m and we denote
it as U a
m.

Table 13 shows the reductions for the fragment U {1,2}

. Reductions for other duplicate-
free fragments are in Appendix A.4. As Table 13 shows, the D-reduction of U {1,2}
con-
tains some metarules commonly used in the MIL literature. For instance, it contains the
identity1, didentity2, and precon metarules. We use the metarules shown in Table 13 in
Experiments 1 and 2 (Sections 6.1 and 6.2) to learn Michalski trains solutions and string
transformation programs respectively.

5

5

Table 14 shows the results of applying the reduction algorithms to U a

5 for different
values of a. All the theoretical results that hold for the singleton-free fragments hold
similarly for the duplicate-free fragments for the following reasons:

– (S) The clauses in the proofs of Proposition 16 and Theorem 12 belong to U a
– (E) If the clause C considered initially in the proof of Theorem 13 belongs to U a

∞.

∞,

then all the subsequent clauses in that proof are also duplicate-free.

– (D) In the proof of Theorem 7, the CIm
Thus Table 12 is also a summary of the S-, E- and D-reduction results of U a

family of clauses all belong to U a

∞.
∞ to U a
2 .

5.5 Summary

We started this section with three goals (G1, G2, and G3). Table 15 summarises the
results towards these goals for fragments of metarules relevant to ILP (Table 3). For
G1, our results are mostly empirical, i.e. the results are the outputs of the reduction
algorithms. For G2, Table 15 shows that the results are all positive for E-reduction, but
mostly negative for S- and D-reduction, especially for Datalog fragments. Similarly, for
G3 the results are again positive for E-reduction but negative for S- and D-reduction for
Datalog fragments. We discuss the implications of these results in Section 7.

Logical reduction of metarules

29

E-reduction
P(A) ← Q(A, B), R(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A), R(B)

S-reduction

P(A) ← Q(A)
P(A) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A), R(B)
P(A, B) ← Q(B), R(A, C), S(A, C)
P(A, B) ← Q(A), R(B, C), S(B, C)
P(A, B) ← Q(B, C), R(A, D),
S(A, D), T (B, C)

D-reduction

P(A) ← Q(A)
P(A) ← Q(A), R(A)
P(A) ← Q(A, B), R(B)
P(A) ← Q(A, B), R(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A), R(B)
P(A, B) ← Q(A), R(A, B)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, C), R(B, C)
P(A, B) ← Q(A, C), R(A, D), S(B, C),
T (B, D), U(C, D)

P(A, B) ← Q(B, C), R(A, D), S(B, D)
T (C, E), U(E)
P(A, B) ← Q(B, C), R(A, D), S(B, D),
T (C, E), U(C, E)

Table 13: Reductions of the fragment U {1,2}

5

Arities
a
0
1
2
0,1
0,2
1,2
0,1,2

S-reduction

E-reduction

D-reduction

Bodysize
1
1
4
1
5
4
4

Cardinality
1
1
3
2
4
8
9

Bodysize
1
1
5
1
5
2
2

Cardinality
1
1
2
2
3
3
4

Bodysize
2
2
5
2
5
5
5

Cardinality
2
2
10
5
38
12
16

Table 14: Cardinality and body size of the reductions of U a
5 .

Arities
a
1
2
>2

C a
∞
E

D a
∞
E

K a
∞
E

U a
∞
E

S

D

D

S
D
Ø Ø Ø Ø Ø Ø Ø Ø Ø Ø Ø Ø
Ø Ø × Ø Ø × × Ø × × Ø ×
Ø Ø × × Ø × × Ø × × Ø ×

D

S

S

2 . The symbol Ø denotes that
Table 15: Existence of a S-, E- or D-reduction of M a
the fragment does have such a reduction. The symbol × denotes that the fragment does
not have such a reduction.

∞ to M a

6 Experiments

As explained in Section 1, deciding which metarules to use for a given learning task is
a major open problem. The problem is the trade-off between efﬁciency and expressiv-
ity: the hypothesis space grows given more metarules (Theorem 1), so we wish to use
fewer metarules, but if we use too few metarules then we lose expressivity. In this section
we experimentally explore this trade-off. As described in Section 2, Cropper and Mug-
gleton [10] showed that learning with E-reduced sets of metarules can lead to higher
predictive accuracies and lower learning times compared to learning with non-E-reduced
sets. However, as argued in Section 1, we claim that E-reduction is not always the most
suitable form of reduction because it can remove metarules necessary to learn programs
with the appropriate speciﬁcity. To test this claim, we now conduct experiments that

30

Andrew Cropper, Sophie Tourret

compare the learning performance of Metagol 2.3.019, the main MIL implementation,
when given different reduced sets of metarules20. We test the null hypothesis:

Null hypothesis 1 There is no difference in the learning performance of Metagol when

using different reduced sets of metarules

To test this null hypothesis, we consider three domains: Michalski trains, string transfor-
mations, and game rules.

6.1 Michalski trains

In the Michalski trains problems [35] the task is to induce a program that distinguishes
eastbound trains from westbound trains. Figure 1 shows an example target program,
where the target concept (f/1) is that the train has a long carriage with two wheels and
another with three wheels.

f(X):-

has_car(X,C1),
long(C1),
two_wheels(C1),
has_car(X,C2),
long(C2),
three_wheels(C2).

Fig. 1: An example Michalski trains target program. In the Michalski trains domain, a
carriage (car) can be long or short. A short carriage always has two wheels. A long
carriage has either two or three wheels.

6.1.1 Materials

To obtain the experimental data, we ﬁrst generated 8 random target train programs
where the programs are progressively more difﬁcult, where difﬁculty is measured by
the number of literals in the generated program from the easiest task T1 to the most
difﬁcult task T8. Figure 2 shows the background predicates available to Metagol. We
vary the metarules given to Metagol. We use the S-, E-, and D-reductions of the fragment
U {1,2}
fragment of the D-reduction
5
of U {1,2}
, i.e. a subset of the D-reduction consisting only of metarules with at most two
5
body literals. This fragment, which we denote as D∗, contains three fewer metarules than
the D-reduction of U {1,2}

(Table 13). In addition, we also consider the U {1,2}

. Table 16 shows this fragment.

2

5

19 https://github.com/metagol/metagol/releases/tag/2.3.0
20 Experimental data is available at http://github.com/andrewcropper/mlj19-reduce

Logical reduction of metarules

31

has_car/2
short/1
two_wheels/1
roof_open/1
zero_load/1
two_load/1
triangle/1

has_load/2
long/1
three_wheels/1
roof_closed/1
one_load/1
circle/1
rectangle/1

Fig. 2: Background relations available in the trains experiment.

P(A) ← Q(A)
P(A) ← Q(A), R(A)
P(A) ← Q(A, B), R(B)
P(A) ← Q(A, B), R(A, B)

P(A, B) ← Q(B, A)
P(A, B) ← Q(A), R(B)
P(A, B) ← Q(A), R(A, B)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, C), R(B, C)

Table 16: The D∗ fragment, which is the D-reduction of the fragment U {1,2}
the fragment U {1,2}

.

5

2

restricted to

6.1.2 Method

For each train task ti in {T1, . . . , T8}:
1. Generate 10 training examples of ti, half positive and half negative
2. Generate 200 testing examples of ti, half positive and half negative
3. For each set of metarules m in the S-, E-, D-, and D∗-reductions:

(a) Learn a program for task ti using the training examples and metarules m
(b) Measure the predictive accuracy of the learned program using the testing exam-

ples

If a program is not found in 10 minutes then no program is returned and every test-
ing example is deemed to have failed. We measure mean predictive accuracies, mean
learning times, and standard errors over 10 repetitions.

Task
T1
T2
T3
T4
T5
T6
T7
T8
mean

S
100 ± 0
100 ± 0
68 ± 5
75 ± 6
92 ± 4
52 ± 2
95 ± 3
55 ± 3
80 ± 1

E
100 ± 0
100 ± 0
62 ± 5
75 ± 6
78 ± 6
50 ± 0
65 ± 5
52 ± 2
73 ± 2

D
100 ± 0
100 ± 0
100 ± 0
100 ± 0
78 ± 6
70 ± 6
82 ± 5
72 ± 6
88 ± 2

D∗
100 ± 0
100 ± 0
100 ± 0
100 ± 0
100 ± 0
100 ± 0
100 ± 0
98 ± 2
100 ± 0

Table 17: Predictive accuracies when using different reduced sets of metarules on the
Michalski trains problems.

32

Andrew Cropper, Sophie Tourret

Task
T1
T2
T3
T4
T5
T6
T7
T8
mean

S
0 ± 0
0 ± 0
424 ± 59
322 ± 64
226 ± 48
583 ± 17
226 ± 44
550 ± 35
292 ± 16

E
0 ± 0
0 ± 0
461 ± 56
340 ± 61
320 ± 59
600 ± 0
446 ± 55
570 ± 30
342 ± 17

D
0 ± 0
0 ± 0
0 ± 0
0 ± 0
361 ± 59
429 ± 51
243 ± 61
361 ± 64
174 ± 16

D∗
0 ± 0
0 ± 0
0 ± 0
0 ± 0
5 ± 2
7 ± 2
6 ± 1
183 ± 40
25 ± 5

Table 18: Learning times in seconds when using different reduced sets of metarules on
the Michalski trains problems. Note that the values are rounded, so 0 represents that a
solution was found in under half a second.

f(A):-has_car(A,B),f1(A,B).
f1(A,B):-three_wheels(B),has_car(A,C),f2(A,C).
f2(A,B):-roof_open(B),has_car(A,C),has_car(A,C).
S program

f(A):-has_car(A,B),f1(A,B).
f1(A,B):-f2(A),three_wheels(B).
f2(A):-has_car(A,B),has_car(A,B).
E program

f(A):-f1(A),f2(A).
f1(A):-has_car(A,B),roof_open(B).
f2(A):-has_car(A,B),three_wheels(B).
D program

f(A):-f1(A),f2(A).
f1(A):-has_car(A,B),three_wheels(B).
f2(A):-has_car(A,B),f3(B).
f3(A):-long(A),two_wheels(A).

D∗ program

Fig. 3: Example programs learned by Metagol when varying the metarule set. The target
program is shown in Figure 1.

6.1.3 Results

Table 17 shows the predictive accuracies when learning with the different sets of metarules.
The D set generally outperforms the S and E sets with a higher mean accuracy of 88%
vs 80% and 73% respectively. Moreover, the D∗ set easily outperforms them all with a

Logical reduction of metarules

33

mean accuracy of 100%. A McNemar’s test21 on the D and D∗ accuracies conﬁrmed the
signiﬁcance at the p < 0.01 level.

Table 18 shows the corresponding learning times when using different reduces sets
of metarules. The D set outperforms (has lower mean learning time) the S and E sets,
and again the D∗ set outperforms them all. A paired t-test22 on the D and D∗ learning
times conﬁrmed the signiﬁcance at the p < 0.01 level.

The D∗ set performs particularly well on the more difﬁcult tasks. The poor perfor-
mance of the S and E sets on the more difﬁcult tasks is for one of two reasons. The
ﬁrst reason is that the S- and E-reduction algorithms have removed the metarules neces-
sary to express the target concept. This observation strongly corroborates our claim that
E-reduction can be too strong because it can remove metarules necessary to specialise
a clause. The second reason is that the S- and E-reduction algorithms produce sets of
metarules that are still sufﬁcient to express the target theory but doing so requires a
much larger and more complex program, measured by the number of clauses needed.

The performance discrepancy between the D and D∗ sets of metarules can be ex-
plained by comparing the hypothesis spaces searched. For instance, when searching for
a program with 3 clauses, Theorem 1 shows that when using the D set of metarules the
hypothesis space contains approximately 1024 programs. By contrast, when using the
D∗ set of metarules the hypothesis space contains approximately 1014 programs. As ex-
plained in Section 3.2, assuming that the target hypothesis is in both hypothesis spaces,
the Blumer bound [3] tells us that searching the smaller hypothesis space will result in
less error, which helps to explain these empirical results. Of course, there is the potential
for the D∗ set to perform worse than the D set when the target theory requires the three
removed metarules, but we did not observe this situation in this experiment.

Figure 3 shows the target program for T8 and example programs learned by Metagol
using the various reduced sets of metarules. Only the D∗ program is success set equiv-
alent23 to the target program when restricted to the target predicate f/1. In all three
cases Metagol discovered that if a carriage has three wheels then it is a long carriage,
i.e. Metagol discovered that the literal long(C2) is redundant in the target program. In-
deed, if we unfold the D∗ program to remove the invented predicates then the resulting
single clause program is one literal shorter than the target program.

Overall, the results from this experiment suggest that we can reject the null hypoth-

esis, both in terms of predictive accuracies and learning times.

6.2 String transformations

In [38] and [14] the authors evaluate Metagol on 17 real-world string transformation
tasks using a predeﬁned (hand-crafted) set of metarules. In this experiment, we compare
learning with different metarules on an expanded dataset with 250 string transformation
tasks.

21 A statistical test on paired nominal data https://en.wikipedia.org/wiki/McNemar%27s_test
22 A statistical test on paired ordinal data http://www.biostathandbook.com/pairedttest.html
23 The success set of a logic program P is the set of ground atoms {A ∈ hb(P)|P ∪
{¬A} has a SLD-refutation}, where hb(P) represents the Herband base of the logic program P. The suc-
cess set restricted to a speciﬁc predicate symbol p is the subset of the success set restricted to atoms
containing the predicate symbol p.

34

6.2.1 Materials

Andrew Cropper, Sophie Tourret

Each string transformation task has 10 examples. Each example is an atom of the form
f (x, y) where f
is the task name and x and y are strings. Figure 4 shows task p6
where the goal is to learn a program that ﬁlters the capital letters from the input. We
supply Metagol with dyadic background predicates, such as tail, dropLast, reverse,
filter_letter, filter_uppercase, dropWhile_not_letter, takeWhile_uppercase. The
full details can be found in the code repository. We vary the metarules given to Metagol.
We use the S-, E-, and D-reductions of the fragment U {2}
. We again also use the D-
reduction of the fragment U {2}
, which is again denoted
as D∗.

restricted to the fragment U {2}

2

5

5

Input
Arthur Joe Juan
Jose Larry Scott
Kevin Jason Matthew
Donald Steven George
Raymond Frank Timothy

Output
AJJ
JLS
KJM
DSG
RFT

Fig. 4: Examples of the p6 string transformation problem input-output pairs.

6.2.2 Method

Our experimental method is:

1. Sample 50 tasks Ts from the set {p1, . . . , p250}
2. For each t ∈ Ts:

(a) Sample 5 training examples and use the remaining examples as testing examples
(b) For each set of metarules m in the S-, E-, D, and D∗-reductions:

i. Learn a program p for task t using the training examples and metarules m
ii. Measure the predictive accuracy of p using the testing examples

If a program is not found in 10 minutes then no program is returned and every test-
ing example is deemed to have failed. We measure mean predictive accuracies, mean
learning times, and standard errors over 10 repetitions.

6.2.3 Results

Table 19 shows the mean predictive accuracies and learning times when learning with
the different sets of metarules. Note that we are not interested in the absolute predictive
accuracy, which is limited by factors such as the low timeout and insufﬁciency of the
BK. We are instead interested in the relative accuracies. Table 19 shows that the D set
outperforms the S and E sets, with a higher mean accuracy of 33%, vs 22% and 22%
respectively. The D∗ set outperforms them all with a mean accuracy of 56%. A McNemar’s
test on the D and D∗ accuracies conﬁrmed the signiﬁcance at the p < 0.01 level.

Table 19 shows the corresponding learning times when varying the metarules. Again,
the D set outperforms the S and E sets, and again the D∗ set outperforms them all. A

Logical reduction of metarules

35

paired t-test on the D and D∗ learning times conﬁrmed the signiﬁcance at the p < 0.01
level.

Overall, the results from this experiment give further evidence to reject the null hy-

pothesis, both in terms of predictive accuracies and learning times.

Mean predictive accuracy (%)
Mean learning time (seconds)

S
22 ± 0
467 ± 1

E
22 ± 0
467 ± 1

D
32 ± 0
407 ± 3

D∗
56 ± 1
270 ± 3

Table 19: Experimental results on the string transformation problems.

6.3 Inducing game rules

The general game playing (GGP) framework [25] is a system for evaluating an agent’s
general intelligence across a wide range of tasks. In the GGP competition, agents are
tested on games they have never seen before. In each round, the agents are given the
rules of a new game. The rules are described symbolically as a logic program. The agents
are given a few seconds to think, to process the rules of the game, and to then start
playing, thus producing game traces. The winner of the competition is the agent who gets
the best total score over all the games. In this experiment, we use the IGGP dataset [9]
which inverts the GGP task: an ILP system is given game traces and the task is to learn
a set of rules (a logic program) that could have produced these traces.

6.3.1 Materials

The IGGP dataset contains problems drawn from 50 games. We focus on the eight games
shown in Figure 5 which contain BK compatible with the metarule fragments we consider
(i.e. the BK contains predicates in the fragment M 2
m). The other games contain predi-
cates with arity greater than two. Each game has four target predicates legal, next,
goal, and terminal, where the arities depend on the game. Figure 6 shows the target
solution for the next predicate for the minimal decay game. Each game contains train-
ing/validate/test data, composed of sets of ground atoms, in a 4:1:1 split. We vary the
metarules given to Metagol. We use the S-, E-, and D-reductions of the fragment D{1,2}
.
We again also use the D-reduction of the fragment D{1,2}
restricted to the fragment D{1,2}
,
which is again denoted as D∗.

5

5

2

GT attrition
GT prisoner
Minimal even
Scissors paper stone Untwisty corridor

GT chicken
Minimal decay
Multiple buttons and lights

Fig. 5: IGGP games used in the experiments.

36

Andrew Cropper, Sophie Tourret

next_value(X):-

true_value(Y),
succ(X,Y),
does_player(noop).

next_value(5):-

does_player(pressButton).

Fig. 6: Target solution for the next predicate for the minimal decay game.

6.3.2 Method

The majority of game examples are negative. We therefore use balanced accuracy to eval-
uate the approaches. Given background knowledge B, sets of positive E+ and negative
E− testing examples, and a logic program H, we deﬁne the number of positive examples
as p = |E+|, the number of negative examples as n = |E−|, the number of true positives
as t p = |{e ∈ E+|B ∪ H |= e}|, the number of true negatives as t n = |{e ∈ E−|B ∪ H 6|= e}|,
and the balanced accuracy ba = (t p/p + t n/n)/2.

Our experimental method is as follows. For each game g, each task gt , and each set

of metarules m in the S-, E-, D-, and D∗-reductions:

1. Learn a program p using all the training examples for gt using the metarules m with

a timeout of 10 minutes

2. Measure the balanced accuracy of p using the testing examples

If no program is found in 10 minutes then no program is returned and every testing
example is deemed to have failed.

6.3.3 Results

Table 20 shows the balanced accuracies when learning with the different sets of metarules.
Again, we are not interested in the absolute accuracies only the relative differences when
learning using different sets of metarules. The D set outperforms the S and E sets with
a higher mean accuracy of 72%, vs 66% and 66% respectively. The D∗ set again out-
performs them all with a mean accuracy of 73%. A McNemar’s test on the D and D∗
accuracies conﬁrmed the signiﬁcance at the p < 0.01 level. Table 20 shows the corre-
sponding learning times when varying the metarules. Again, the D set outperforms the
S and E sets, and again the D∗ set outperforms them all. However, a paired t-test on
the D and D∗ learning times conﬁrmed the signiﬁcance only at the p < 0.08 level, so
the difference in learning times is insigniﬁcant. Overall, the results from this experiment
suggest that we can reject the null hypothesis in terms of predictive accuracies but not
learning times.

Balanced accuracy (%)
Learning time (seconds)

S
66
316

E
66
316

D
72
327

D∗
73
296

Table 20: Experimental results on the IGGP data.

Logical reduction of metarules

37

7 Conclusions and further work

As stated in Section 1, despite the widespread use of metarules, there is little work deter-
mining which metarules to use for a given learning task. Instead, suitable metarules are
assumed to be given as part of the background knowledge, or are used without any theo-
retical justiﬁcation. Deciding which metarules to use for a given learning task is a major
open challenge [8,10] and is a trade-off between efﬁciency and expressivity: the hypoth-
esis space grows given more metarules [10, 38], so we wish to use fewer metarules, but
if we use too few metarules then we lose expressivity. To address this issue, Cropper and
Muggleton [10] used E-reduction on sets of metarules and showed that learning with
E-reduced sets of metarules can lead to higher predictive accuracies and lower learning
times compared to learning with non-E-reduced sets. However, as we claimed in Sec-
tion 1, E-reduction is not always the most appropriate form of reduction because it can
remove metarules necessary to learn programs with the necessary speciﬁcity.

To support our claim, we have compared three forms of logical reduction: S-, E-,
and D-reduction, where the latter is a new form of reduction based on SLD-derivations.
We have used the reduction algorithms to reduce ﬁnite sets of metarules. Table 15 sum-
marises the results. We have shown that many sets of metarules relevant to ILP do not
have ﬁnite reductions (Theorem 7). These negative results have direct (negative) impli-
cations for MIL. Speciﬁcally, our results mean that, in certain cases, a MIL system, such
as Metagol or HEXMIL [32], cannot be given a ﬁnite set of metarules from which it can
learn any program, such as when learning arbitrary Datalog programs. The results will
also likely have implications for other forms of ILP which rely on metarules.

Our experiments compared learning the performance of Metagol when using the
different reduced sets of metarules. In general, using the D-reduced set outperforms
both the S- and E-reduced sets in terms of predictive accuracy and learning time. Our
experimental results give strong evidence to our claim. We also compared a D∗-reduced
set, a subset of the D-reduced metarules, which, although derivationally incomplete,
outperforms the other two sets in terms of predictive accuracies and learning times.

7.1 Limitations and future work

Theorem 7 shows that certain fragments of metarules do not have ﬁnite D-reductions.
However, our experimental results show that using D-reduced sets of metarules leads
to higher predictive accuracies and lower learning times compared to the other forms
of reduction. Therefore, our work now opens up a new challenge of overcoming this
negative theoretical result. One idea is to explore whether special metarules, such as a
currying metarule [12], could alleviate the issue.

In future work we would also like reduce more general fragments of logic, such as
triadic logics, which would allow us to tackle a wider variety or problems, such as more
of the games in the IGGP dataset.

We have compared the learning performance of Metagol when using different re-
duced sets of metarules. However, we have not investigated whether these reductions
are optimal. For instance, when considering derivation reductions, it may, in some cases,
be beneﬁcial to re-add redundant metarules to the reduced sets to avoid having to derive
them through SLD-resolution. In future work, we would like to investigate identifying an
optimal set of metarules for a given learning task, or preferably learning which metarules
to use for a given learning task.

38

Andrew Cropper, Sophie Tourret

We have shown that although incomplete the D∗-reduced set of metarules outper-
forms the other reductions. In future work we would like to explore other methods which
sacriﬁce completeness for efﬁciency.

We have used the logical reduction techniques to remove redundant metarules. It
may also be beneﬁcial to simultaneously reduce metarules and standard background
knowledge. The idea of purposely removing background predicates is similar to dimen-
sionality reduction, widely used in other forms of machine learning [59], but which
has been under researched in ILP [23]. Initial experiments indicate that this is possi-
ble [8, 10], and we aim to develop this idea in future work.

Acknowledgements The authors thank Stephen Muggleton and Katsumi Inoue for discussions on this
topic. We especially thank Rolf Morel for valuable feedback on the paper.

References

1. Aws Albarghouthi, Paraschos Koutris, Mayur Naik, and Calvin Smith. Constraint-based synthesis of
Datalog programs. In J. Christopher Beck, editor, Principles and Practice of Constraint Programming
- 23rd International Conference, CP 2017, Melbourne, VIC, Australia, August 28 - September 1, 2017,
Proceedings, volume 10416 of Lecture Notes in Computer Science, pages 689–706. Springer, 2017.

2. Meghyn Bienvenu.

In Proceedings of
Prime implicates and prime implicants in modal logic.
the Twenty-Second AAAI Conference on Artiﬁcial Intelligence, July 22-26, 2007, Vancouver, British
Columbia, Canada, pages 379–384. AAAI Press, 2007.

3. Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K. Warmuth. Occam’s razor. Inf.

Process. Lett., 24(6):377–380, 1987.

4. Aaron R. Bradley and Zohar Manna. The calculus of computation - decision procedures with applica-

tions to veriﬁcation. Springer, 2007.

5. A. Campero, A. Pareja, T. Klinger, J. Tenenbaum, and S. Riedel. Logical Rule Induction and Theory

Learning Using Neural Theorem Proving. ArXiv e-prints, September 2018.

6. Alonzo Church. A note on the Entscheidungsproblem. J. Symb. Log., 1(1):40–41, 1936.
7. William W. Cohen. Grammatically biased learning: Learning logic programs using an explicit an-

tecedent description language. Artif. Intell., 68(2):303–366, 1994.

8. Andrew Cropper. Efﬁciently learning efﬁcient programs. PhD thesis, Imperial College London, UK,

2017.

9. Andrew Cropper, Richard Evans, and Mark Law.

Inductive general game playing. arXiv e-prints,

page arXiv:1906.09627, Jun 2019.

10. Andrew Cropper and Stephen H. Muggleton. Logical minimisation of meta-rules within meta-
interpretive learning. In Jesse Davis and Jan Ramon, editors, Inductive Logic Programming - 24th
International Conference, ILP 2014, Nancy, France, September 14-16, 2014, Revised Selected Papers,
volume 9046 of Lecture Notes in Computer Science, pages 62–75. Springer, 2014.

11. Andrew Cropper and Stephen H. Muggleton. Learning efﬁcient logical robot strategies involving
In Qiang Yang and Michael Wooldridge, editors, Proceedings of the Twenty-
composable objects.
Fourth International Joint Conference on Artiﬁcial Intelligence, IJCAI 2015, Buenos Aires, Argentina,
July 25-31, 2015, pages 3423–3429. AAAI Press, 2015.

12. Andrew Cropper and Stephen H. Muggleton. Learning higher-order logic programs through abstrac-
tion and invention. In Subbarao Kambhampati, editor, Proceedings of the Twenty-Fifth International
Joint Conference on Artiﬁcial Intelligence, IJCAI 2016, New York, NY, USA, 9-15 July 2016, pages
1418–1424. IJCAI/AAAI Press, 2016.

13. Andrew

Cropper

and

Stephen

H.

Muggleton.

Metagol

system.

https://github.com/metagol/metagol, 2016.

14. Andrew Cropper and Stephen H. Muggleton. Learning efﬁcient logic programs. Machine Learning,

108(7):1063–1083, 2019.

15. Andrew Cropper, Alireza Tamaddoni-Nezhad, and Stephen H. Muggleton. Meta-interpretive learn-
ing of data transformation programs. In Katsumi Inoue, Hayato Ohwada, and Akihiro Yamamoto,
editors, Inductive Logic Programming - 25th International Conference, ILP 2015, Kyoto, Japan, August
20-22, 2015, Revised Selected Papers, volume 9575 of Lecture Notes in Computer Science, pages 46–59.
Springer, 2015.

Logical reduction of metarules

39

16. Andrew Cropper and Sophie Tourret. Derivation reduction of metarules in meta-interpretive learn-
In Fabrizio Riguzzi, Elena Bellodi, and Riccardo Zese, editors, Inductive Logic Programming
ing.
- 28th International Conference, ILP 2018, Ferrara, Italy, September 2-4, 2018, Proceedings, volume
11105 of Lecture Notes in Computer Science, pages 1–21. Springer, 2018.

17. Evgeny Dantsin, Thomas Eiter, Georg Gottlob, and Andrei Voronkov. Complexity and expressive

power of logic programming. ACM Comput. Surv., 33(3):374–425, 2001.

18. Mnacho Echenim, Nicolas Peltier, and Sophie Tourret. Quantiﬁer-free equational logic and prime
implicate generation. In Amy P. Felty and Aart Middeldorp, editors, Automated Deduction - CADE-25
- 25th International Conference on Automated Deduction, Berlin, Germany, August 1-7, 2015, Proceed-
ings, volume 9195 of Lecture Notes in Computer Science, pages 311–325. Springer, 2015.

19. Werner Emde, Christopher Habel, and Claus-Rainer Rollinger. The discovery of the equator or con-
cept driven learning. In Alan Bundy, editor, Proceedings of the 8th International Joint Conference on
Artiﬁcial Intelligence. Karlsruhe, FRG, August 1983, pages 455–458. William Kaufmann, 1983.
20. Richard Evans and Edward Grefenstette. Learning explanatory rules from noisy data. J. Artif. Intell.

Res., 61:1–64, 2018.

21. Pierre Flener.

Inductive logic program synthesis with DIALOGS.

In Stephen Muggleton, editor,
Inductive Logic Programming, 6th International Workshop, ILP-96, Stockholm, Sweden, August 26-28,
1996, Selected Papers, volume 1314 of Lecture Notes in Computer Science, pages 175–198. Springer,
1996.

22. Nuno A. Fonseca, Vítor Santos Costa, Fernando M. A. Silva, and Rui Camacho. On avoiding redun-
dancy in inductive logic programming. In Rui Camacho, Ross D. King, and Ashwin Srinivasan, edi-
tors, Inductive Logic Programming, 14th International Conference, ILP 2004, Porto, Portugal, September
6-8, 2004, Proceedings, volume 3194 of Lecture Notes in Computer Science, pages 132–146. Springer,
2004.

23. Johannes Fürnkranz. Dimensionality reduction in ILP: A call to arms. In Proceedings of the IJCAI-97

Workshop on Frontiers of Inductive Logic Programming, pages 81–86, 1997.

24. M. R. Garey and David S. Johnson. Computers and Intractability: A Guide to the Theory of NP-

Completeness. W. H. Freeman, 1979.

25. Michael R. Genesereth, Nathaniel Love, and Barney Pell. General game playing: Overview of the

AAAI competition. AI Magazine, 26(2):62–72, 2005.

26. Georg Gottlob and Christian G. Fermüller. Removing redundancy from a clause. Artif. Intell.,

61(2):263–289, 1993.

27. Georg Gottlob, Nicola Leone, and Francesco Scarcello. On the complexity of some inductive logic
programming problems. In Nada Lavrac and Saso Dzeroski, editors, Inductive Logic Programming, 7th
International Workshop, ILP-97, Prague, Czech Republic, September 17-20, 1997, Proceedings, volume
1297 of Lecture Notes in Computer Science, pages 17–32. Springer, 1997.

28. Edith Hemaspaandra and Henning Schnoor. Minimization for generalized boolean formulas.

In
Toby Walsh, editor, IJCAI 2011, Proceedings of the 22nd International Joint Conference on Artiﬁcial
Intelligence, Barcelona, Catalonia, Spain, July 16-22, 2011, pages 566–571. IJCAI/AAAI, 2011.
29. Marijn Heule, Matti Järvisalo, Florian Lonsing, Martina Seidl, and Armin Biere. Clause elimination

for SAT and QSAT. J. Artif. Intell. Res., 53:127–168, 2015.

30. Thomas Hillenbrand, Ruzica Piskac, Uwe Waldmann, and Christoph Weidenbach. From search to
computation: Redundancy criteria and simpliﬁcation at work. In Andrei Voronkov and Christoph
Weidenbach, editors, Programming Logics - Essays in Memory of Harald Ganzinger, volume 7797 of
Lecture Notes in Computer Science, pages 169–193. Springer, 2013.

31. William H. Joyner Jr. Resolution strategies as decision procedures. J. ACM, 23(3):398–417, 1976.
32. Tobias Kaminski, Thomas Eiter, and Katsumi Inoue. Exploiting answer set programming with exter-

nal sources for meta-interpretive learning. TPLP, 18(3-4):571–588, 2018.

33. Jörg-Uwe Kietz and Stefan Wrobel. Controlling the complexity of learning in logic through syntactic

and task-oriented models. In Inductive logic programming. Citeseer, 1992.

34. Robert A. Kowalski. Predicate logic as programming language.

In IFIP Congress, pages 569–574,

1974.

35. J. Larson and Ryszard S. Michalski. Inductive inference of VL decision rules. SIGART Newsletter,

63:38–44, 1977.

36. Paolo Liberatore. Redundancy in logic I: CNF propositional formulae. Artif. Intell., 163(2):203–232,

2005.

37. Paolo Liberatore. Redundancy in logic II: 2CNF and Horn propositional formulae. Artif. Intell.,

172(2-3):265–299, 2008.

38. Dianhuan Lin, Eyal Dechter, Kevin Ellis, Joshua B. Tenenbaum, and Stephen Muggleton. Bias re-
formulation for one-shot function induction. In ECAI 2014 - 21st European Conference on Artiﬁcial
Intelligence, 18-22 August 2014, Prague, Czech Republic - Including Prestigious Applications of Intelli-
gent Systems (PAIS 2014), pages 525–530, 2014.

40

Andrew Cropper, Sophie Tourret

39. John W. Lloyd. Foundations of Logic Programming, 2nd Edition. Springer, 1987.
40. J.W. Lloyd. Logic for Learning. Springer, Berlin, 2003.
41. Jerzy Marcinkowski and Leszek Pacholski. Undecidability of the Horn-clause implication problem.
In 33rd Annual Symposium on Foundations of Computer Science, Pittsburgh, Pennsylvania, USA, 24-27
October 1992, pages 354–362, 1992.

42. Pierre Marquis. Consequence ﬁnding algorithms. In Handbook of Defeasible Reasoning and Uncer-

tainty Management Systems, pages 41–145. Springer, 2000.

43. John McCarthy. Making robots conscious of their mental states. In Machine Intelligence 15, Intelligent

Agents [St. Catherine’s College, Oxford, July 1995], pages 3–17, 1995.

44. Rolf Morel, Andrew Cropper, and C.-H. Luke Ong. Typed meta-interpretive learning of logic pro-
In Francesco Calimeri, Nicola Leone, and Marco Manna, editors, Logics in Artiﬁcial Intel-
grams.
ligence - 16th European Conference, JELIA 2019, Rende, Italy, May 7-11, 2019, Proceedings, volume
11468 of Lecture Notes in Computer Science, pages 198–213. Springer, 2019.

45. Stephen Muggleton. Inverse entailment and Progol. New Generation Comput., 13(3&4):245–286,

1995.

46. Stephen Muggleton and Cao Feng. Efﬁcient induction of logic programs. In Algorithmic Learning
Theory, First International Workshop, ALT ’90, Tokyo, Japan, October 8-10, 1990, Proceedings, pages
368–381, 1990.

47. Stephen Muggleton, Luc De Raedt, David Poole, Ivan Bratko, Peter A. Flach, Katsumi Inoue, and
Ashwin Srinivasan. ILP turns 20 - biography and future challenges. Machine Learning, 86(1):3–23,
2012.

48. Stephen H. Muggleton, Dianhuan Lin, Niels Pahlavi, and Alireza Tamaddoni-Nezhad. Meta-
interpretive learning: application to grammatical inference. Machine Learning, 94(1):25–49, 2014.
49. Stephen H. Muggleton, Dianhuan Lin, and Alireza Tamaddoni-Nezhad. Meta-interpretive learning of
higher-order dyadic Datalog: predicate invention revisited. Machine Learning, 100(1):49–73, 2015.
50. Claire Nédellec, Céline Rouveirol, Hilde Adé, Francesco Bergadano, and Birgit Tausend. Declarative

bias in ILP. Advances in inductive logic programming, 32:82–103, 1996.

51. Shan-Hwei Nienhuys-Cheng and Ronald de Wolf. Foundations of Inductive Logic Programming.

Springer-Verlag New York, Inc., Secaucus, NJ, USA, 1997.

52. G.D. Plotkin. Automatic Methods of Inductive Inference. PhD thesis, Edinburgh University, August

1971.

53. Luc De Raedt. Declarative modeling for machine learning and data mining. In Algorithmic Learning
Theory - 23rd International Conference, ALT 2012, Lyon, France, October 29-31, 2012. Proceedings,
page 12, 2012.

54. Luc De Raedt and Maurice Bruynooghe. Interactive concept-learning and constructive induction by

analogy. Machine Learning, 8:107–150, 1992.

55. John Alan Robinson. A machine-oriented logic based on the resolution principle. J. ACM, 12(1):23–

41, 1965.

56. Manfred Schmidt-Schauß. Implication of clauses is undecidable. Theor. Comput. Sci., 59:287–296,

1988.

57. E.Y. Shapiro. Algorithmic program debugging. MIT Press, 1983.
58. Xujie Si, Woosuk Lee, Richard Zhang, Aws Albarghouthi, Paraschos Koutris, and Mayur Naik. Syntax-
guided synthesis of Datalog programs. In Gary T. Leavens, Alessandro Garcia, and Corina S. Pasare-
anu, editors, Proceedings of the 2018 ACM Joint Meeting on European Software Engineering Conference
and Symposium on the Foundations of Software Engineering, ESEC/SIGSOFT FSE 2018, Lake Buena
Vista, FL, USA, November 04-09, 2018, pages 515–527. ACM, 2018.

59. David Skillicorn. Understanding complex datasets: data mining with matrix decompositions. Chapman

and Hall/CRC, 2007.

60. Sten-Åke Tärnlund. Horn clause computability. BIT, 17(2):215–226, 1977.
61. Sophie Tourret and Andrew Cropper. SLD-resolution reduction of second-order Horn fragments. In
Francesco Calimeri, Nicola Leone, and Marco Manna, editors, Logics in Artiﬁcial Intelligence - 16th
European Conference, JELIA 2019, Rende, Italy, May 7-11, 2019, Proceedings, volume 11468 of Lecture
Notes in Computer Science, pages 259–276. Springer, 2019.

62. William Yang Wang, Kathryn Mazaitis, and William W. Cohen. Structure learning via parameter
learning. In Jianzhong Li, Xiaoyang Sean Wang, Minos N. Garofalakis, Ian Soboroff, Torsten Suel,
and Min Wang, editors, Proceedings of the 23rd ACM International Conference on Conference on In-
formation and Knowledge Management, CIKM 2014, Shanghai, China, November 3-7, 2014, pages
1199–1208. ACM, 2014.

63. Christoph Weidenbach and Patrick Wischnewski. Subterm contextual rewriting. AI Commun., 23(2-

3):97–109, 2010.

Logical reduction of metarules

41

A Detailed Reduction Results

A.1 Connected (C a

m) reductions

S-reduction
P(A, B) ← Q(A, C )
P(A, B) ← Q(B, C )
P(A, B) ← Q(C , A)
P(A, B) ← Q(C , B)

E-reduction
P(A, B) ← Q(B, C )

D-reduction

P(A, A) ← Q(B, A)
P(A, B) ← Q(B, A)
P(A, B) ← Q(B, B)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, C ), R(B, C )
P(A, B) ← Q(A, C ), R(A, D), S(B, C ), T (B, D), U(C , D)

Table 21: Reductions of the connected fragment C {2}

5

S-reduction

P(A) ← Q(A)
P(A) ← Q(A, B)
P(A) ← Q(B, A)
P(A, B) ← Q(A)
P(A, B) ← Q(B)
P(A, B) ← Q(A, C )
P(A, B) ← Q(B, C )
P(A, B) ← Q(C , A)
P(A, B) ← Q(C , B)

E-reduction
P(A) ← Q(B, A)
P(A, B) ← Q(A)

D-reduction

P(A) ← Q(B, A)
P(A, A) ← Q(B, A)
P(A, B) ← Q(B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(B, B)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, C ), R(B, C )
P(A, B) ← Q(A, C ), R(A, D), S(B, C ), T (B, D), U(C , D)

Table 22: Reductions of the connected fragment C {1,2}

5

42

Andrew Cropper, Sophie Tourret

A.2 Datalog (D a

m) reductions

S-reduction

P ← Q
P(A) ← Q(A)
P(A) ← Q(A, B)
P(A) ← Q(B, A)
P(A, A) ← Q(B, A)
P(A, B) ← Q(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A), R(B)
P(A, B) ← Q(A), R(B, C )
P(A, B) ← Q(B), R(A, C )
P(A, B) ← Q(B, C ), R(A, D)

E-reduction

P ← Q
P(A) ← Q(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A), R(B)

D-reduction

P ← Q
P ← Q, R
P(A) ← Q(B, A)
P(A, A) ← Q(A)
P(A, A) ← Q(A, A)
P(A, B) ← Q(B, A)
P(A, B) ← Q, R(A, B)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, C ), R(B, C )
P(A, B) ← Q(B, C ), R(A, D)
P(A, B) ← Q(B, C ), R(A, D), S(B, D), T (C , E)
P(A, B) ← Q(A, C ), R(A, D), S(B, C ), T (B, D), U(C , D)
P(A, B) ← Q(B, C ), R(A, D), S(C , E), T (B, F ), U(D, F )
P(A, B) ← Q(B, C ), R(B, D), S(C , E), T (A, F ), U(D, F )

Table 23: Reductions of the Datalog fragment D{0,1,2}

5

E-reduction
P(A) ← Q(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A), R(B)

S-reduction

P(A) ← Q(A)
P(A) ← Q(A, B)
P(A) ← Q(B, A)
P(A, A) ← Q(B, A)
P(A, B) ← Q(A), R(B)
P(A, B) ← Q(A), R(B, C )
P(A, B) ← Q(A, B)
P(A, B) ← Q(B), R(A, C )
P(A, B) ← Q(B, A)
P(A, B) ← Q(B, C ), R(A, D)

D-reduction

P(A) ← Q(B, A)
P(A, A) ← Q(A)
P(A, A) ← Q(A, A)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, C ), R(B, C )
P(A, B) ← Q(B, C ), R(A, D)
P(A, B) ← Q(B, C ), R(A, D), S(B, D), T (C , E)
P(A, B) ← Q(A, C ), R(A, D), S(B, C ), T (B, D), U(C , D)
P(A, B) ← Q(B, C ), R(A, D), S(C , E), T (B, F ), U(D, F )
P(A, B) ← Q(B, C ), R(B, D), S(C , E), T (A, F ), U(D, F )

Table 24: Reductions of the Datalog fragment D{1,2}

5

S-reduction

P(A, A) ← Q(B, A)
P(A, B) ← Q(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(B, C ), R(A, D)

E-reduction

P(A, A) ← Q(B, A)
P(A, B) ← Q(B, C ), R(A, D)

D-reduction

P(A, A) ← Q(A, A)
P(A, A) ← Q(B, A)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, C ), R(B, C )
P(A, B) ← Q(B, C ), R(A, D)
P(A, B) ← Q(B, C ), R(A, D), S(B, D), T (C , E)
P(A, B) ← Q(A, C ), R(A, D), S(B, C ), T (B, D), U(C , D)
P(A, B) ← Q(B, C ), R(A, D), S(C , E), T (B, F ), U(D, F )
P(A, B) ← Q(B, C ), R(B, D), S(C , E), T (A, F ), U(D, F )

Table 25: Reductions of the Datalog fragment D{2}

5

Logical reduction of metarules

43

A.3 Singleton-free (K a

m) results

S-reduction

P(A, B) ← Q(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(B, C ), R(A, D), S(A, D), T (B, C )

E-reduction
P(A, B) ← Q(B, A)
P(A, B) ← Q(A, A), R(B, B)
P(A, B) ← Q(A, C ), R(B, C )

D-reduction

P(A, A) ← Q(A, A)
P(A, B) ← Q(B, A)
P(A, A) ← Q(A, B), R(B, B)
P(A, B) ← Q(A, A), R(B, B)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, C ), R(B, C )
P(A, B) ← Q(A, C ), R(A, D), S(B, C ), T (B, D), U(C , D)

Table 26: Reductions of the singleton-free fragment K {2}

5

S-reduction

P(A) ← Q(A)
P(A) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A), R(B)
P(A, B) ← Q(A), R(B, C ), S(B, C )
P(A, B) ← Q(B), R(A, C ), S(A, C )
P(A, B) ← Q(B, C ), R(A, D), S(A, D), T (B, C )

E-reduction

P(A) ← Q(A, A)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A), R(B)
P(A, B) ← Q(A, C ), R(B, C )

D-reduction

P(A) ← Q(A, A)
P(A, A) ← Q(A)
P(A, B) ← Q(B, A)
P(A, A) ← Q(A, B), R(B, B)
P(A, B) ← Q(A, A), R(B, B)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, C ), R(B, C )
P(A, B) ← Q(A, C ), R(A, D), S(B, C ), T (B, D), U(C , D)

Table 27: Reductions of the singleton-free fragment K {1,2}

5

S-reduction

P ← Q
P(A) ← Q(A)
P(A) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A), R(B)
P(A, B) ← Q(A), R(B, C ), S(B, C )
P(A, B) ← Q(B), R(A, C ), S(A, C )
P(A, B) ← Q(B, C ), R(A, D), S(A, D), T (B, C )

E-reduction

P ← Q
P(A) ← Q(A, A)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A), R(B)
P(A, B) ← Q(A, C ), R(B, C )

D-reduction

P ← Q
P ← Q, R
P(A) ← Q(A, A)
P(A, A) ← Q(A)
P(A, B) ← Q(B, A)
P(A, A) ← Q(A, B), R(B, B)
P(A, B) ← Q, R(A, B)
P(A, B) ← Q(A, A), R(B, B)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, C ), R(B, C )
P(A, B) ← Q(A, C ), R(A, D), S(B, C ), T (B, D), U(C , D)

Table 28: Reductions of the singleton-free fragment K {0,1,2}

5

44

Andrew Cropper, Sophie Tourret

A.4 Duplicate-free (U a

m) results

S-reduction

P(A, B) ← Q(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(B, C), R(A, D), S(A, D), T (B, C)

E-reduction

P(A, B) ← Q(B, A)
P(A, B) ← Q(B, C), R(A, D),
S(A, D), T (B, C)

D-reduction

P(A, B) ← Q(B, A)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, C), R(B, C)
P(A, B) ← Q(A, B), R(A, C), S(A, C)
P(A, B) ← Q(A, B), R(A, C), S(C, D), T (C, D)
P(A, B) ← Q(B, C), R(A, D), S(A, D), T (B, C)
P(A, B) ← Q(B, C), R(A, D), S(B, C), T (B, D)
P(A, B) ← Q(A, C), R(A, D), S(B, C), T (B, D), U(C, D)
P(A, B) ← Q(B, C), R(A, D), S(B, D), T (C, E), U(C, E)
P(A, B) ← Q(B, C), R(C, D), S(A, E), T (B, E), U(C, D)

Table 29: Reductions of the fragment U {2}

5

S-reduction

P(A) ← Q(A)
P(A) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A), R(B)
P(A, B) ← Q(B), R(A, C), S(A, C)
P(A, B) ← Q(A), R(B, C), S(B, C)
P(A, B) ← Q(B, C), R(A, D), S(A, D), T (B, C)

E-reduction
P(A) ← Q(A, B), R(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A), R(B)

D-reduction

P(A) ← Q(A)
P(A) ← Q(A), R(A)
P(A) ← Q(A, B), R(B)
P(A) ← Q(A, B), R(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A), R(B)
P(A, B) ← Q(A), R(A, B)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, C), R(B, C)
P(A, B) ← Q(A, C), R(A, D), S(B, C), T (B, D), U(C, D)
P(A, B) ← Q(B, C), R(A, D), S(B, D), T (C, E), U(E)
P(A, B) ← Q(B, C), R(A, D), S(B, D), T (C, E), U(C, E)

Table 30: Reductions of the fragment U {1,2}

5

S-reduction

P ← Q
P(A) ← Q(A)
P(A) ← Q(A, B), R(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A, B)
P(A, B) ← Q(A), R(B)
P(A, B) ← Q(A), R(B, C), S(B, C)
P(A, B) ← Q(B), R(A, C), S(A, C)
P(A, B) ← Q(B, C), R(A, D), S(A, D), T (B, C)

E-reduction

P ← Q
P(A) ← Q(A, B), R(A, B)
P(A, B) ← Q(B, A)
P(A, B) ← Q(A), R(B)

D-reduction

P ← Q
P(A) ← Q(A)
P(A, B) ← Q(B, A)
P ← Q, R
P(A) ← Q, R(A)
P(A) ← Q(A), R(A)
P(A) ← Q(A, B), R(B)
P(A) ← Q(A, B), R(A, B)
P(A, B) ← Q, R(A, B)
P(A, B) ← Q(A), R(B)
P(A, B) ← Q(A), R(A, B)
P(A, B) ← Q(A, B), R(A, B)
P(A, B) ← Q(A, C), R(B, C)
P(A, B) ← Q(A, C), R(A, D), S(B, C), T (B, D), U(C, D)
P(A, B) ← Q(B, C), R(A, D), S(B, D), T (C, E), U(E)
P(A, B) ← Q(B, C), R(A, D), S(B, D), T (C, E), U(C, E)

Table 31: Reductions of the fragment U {0,1,2}

5

