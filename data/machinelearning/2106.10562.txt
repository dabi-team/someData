1
2
0
2

p
e
S
9
1

]
I

A
.
s
c
[

2
v
2
6
5
0
1
.
6
0
1
2
:
v
i
X
r
a

Score-Based Explanations in Data Management
and Machine Learning: An Answer-Set
Programming Approach to Counterfactual
Analysis

Leopoldo Bertossi

Universidad Adolfo Ib´a˜nez
Faculty of Engineering and Sciences
and
Millennium Inst. for Foundational Research on Data (IMFD)
Santiago, Chile
leopoldo.bertossi@uai.cl

Abstract. We describe some recent approaches to score-based expla-
nations for query answers in databases and outcomes from classiﬁcation
models in machine learning. The focus is on work done by the author
and collaborators. Special emphasis is placed on declarative approaches
based on answer-set programming to the use of counterfactual reasoning
for score speciﬁcation and computation. Several examples that illustrate
the ﬂexibility of these methods are shown.

1

Introduction

In data management and machine learning one wants explanations for certain
results. For example, for query results from databases, and for outcomes of clas-
siﬁcation models in machine learning (ML). Explanations, that may come in
diﬀerent forms, have been the subject of philosophical enquires for a long time,
but, closer to our discipline, they appear under diﬀerent forms in model-based
diagnosis and in causality as developed in artiﬁcial intelligence.

In the last few years, explanations that are based on numerical scores assigned
to elements of a model that may contribute to an outcome have become popular.
These scores attempt to capture the degree of contribution of those components
to an outcome, e.g. answering questions like these: What is the contribution of
this tuple to the answer to this query? What is the contribution of this feature
value of an entity to the displayed classiﬁcation of the latter?

For an example, consider a ﬁnancial institution that uses a learned classiﬁer,
C, e.g. a decision tree, to determine if clients should be granted loans or not,
returning labels 0 or 1, resp. A particular client, represented as an entity e,
applies for a loan, and the classiﬁer returns C(e) = 1, i.e. the loan is rejected.
The client requests an explanation.

A common approach consists in giving scores to the feature values in e, to
quantify their relevance in relation to the classiﬁcation outcome. The higher the

 
 
 
 
 
 
score of a feature value, the more explanatory is that value. For example, the fact
that the client has value “5” for feature Age (in years) could have the highest
score. That is, the rejection of the loan application is due mostly to the client’s
very young age.

In the context of explainable AI [39], diﬀerent scores have been proposed in
the literature, and some that have a relatively older history have been applied.
Among the latter we ﬁnd the general responsibility score as found in actual
causality [26, 19]. For a particular kind of application, one has to deﬁne the right
causality setting, and then apply the responsibility measure to the participating
variables (see [27] for a newer treatment of the subject). In particular, in data
management, responsibility has been used to quantify the strength of a tuple as
a cause for a query result [36, 5]. The Shapley value, as found in coalition game
theory [45], has been used for the same purpose [30]. Deﬁning the right game
function, the Shapley value assigned to a player reﬂects its contribution to the
wealth function, which in databases corresponds to the query result.

In the context of explanations to outcomes from classiﬁcation models in ML,
the Shapley value has been used to assign scores to the feature values taken
by an entity that has been classiﬁed. With a particular game function, it has
taken the form of the Shap score, which has become quite popular and inﬂuential
[34, 35].

Also recently, a responsibility score, Resp, has been introduced and investi-
gated for the same purpose in [9]. It is based on the notions of counterfactual
intervention as appearing in actual causality, and causal responsibility. More
speciﬁcally, (potential) executions of counterfactual interventions on a structural
logico-probabilistic model
[26] are investigated, with the purpose of answering
hypothetical questions of the form: What would happen if we change ...?.

Counterfactual interventions can be used to deﬁne diﬀerent forms of score-
based explanations. This is the case of causal responsibility in databases (c.f.
Section 12). In explainable AI, and more commonly with classiﬁcation models
of ML, counterfactual interventions become hypothetical changes on the entity
whose classiﬁcation is being explained, to detect possible changes in the outcome
(c.f. [11, Sec. 8] for a more detailed discussion and references).

Score-based explanations can also be deﬁned in the absence of a model,
and with or without explicit counterfactual interventions. Actually, explanation
scores such as Shap and Resp can be applied with black-box models, in that they
use, in principle, only the input/output relation that represents the classiﬁer,
without having access to the internal components of the model. In this category
we could ﬁnd classiﬁers based on complex neural networks, or XGBoost [33].
They are opaque enough to be treated as black-box models.

The Shap and Resp scores can also be applied with open-box models, with ex-
plicit models. Without having access to the elements of the classiﬁcation model,
the computation of both Shap and Resp is in general intractable, by their sheer
deﬁnitions, and the possibly large number of counterfactual combinations that
have to be considered in the computation. However, for certain classes of classi-
ﬁers, e.g. decision trees, having access to the mathematical model may make the

2

computation of Shap tractable, as shown in [3, 48], where it is also shown that for
other classes of explicit models, its computation is still intractable. Something
similar applies to Resp [9].

Other explanation scores used in machine learning appeal to the components
of the mathematical model behind the classiﬁer. There can be all kinds of explicit
models, and some are easier to understand or interpret or use for this purpose.
For example, the FICO score proposed in [18], for the FICO dataset about
loan requests, depends on the internal outputs and displayed coeﬃcients of two
nested logistic regression models. Decision trees [38], random forests [12], rule-
based classiﬁers, etc., could be seen as relatively easy to understand and use for
providing explanations.
In [9], the Shap and Resp scores were experimentally
compared with each other, and also with the FICO score.

One can specify in declarative terms the counterfactual versions of tuples
in databases and of feature values in entities under classiﬁcation. On this basis
one can analyze diverse alternative counterfactuals, reason about them, and also
specify the associated explanation scores. In these notes we do this for respon-
sibility scores in databases and classiﬁcations models. More speciﬁcally, we use
answer-set programming, a modern logic-programming paradigm that has be-
come useful in many applications [13, 24]. We show examples run with the DLV
system and its extensions [29]. An important advantage of using declarative spec-
iﬁcations resides in the possibility of adding diﬀerent forms of domain knowledge
and semantic constraints. Doing this with purely procedural approaches would
require changing the code accordingly.

The answer-set programs (ASPs) we use are inﬂuenced by, and sometimes
derived from, repair programs. These are ASPs that specify and compute the
possible repairs of a database that is inconsistent with respect to a given set
of integrity constraints [4]. A useful connection between database repairs and
actual causality in databases was established in [5]. Hence, the use of repairs
and repair programs.

In this article we survey some of the recent advances on the use and computa-
tion of the above mentioned score-based explanations, both for query answering
in databases and for classiﬁcation in ML. This is not intended to be an exhaus-
tive survey of the area. Instead, it is heavily inﬂuenced by our latest research.
Special emphasis is placed on the use of ASPs (for many more details on this
see [11]). Taking advantage of the introduced repair programs, we also show how
to specify and compute a numerical measure of inconsistency of database [7]. In
this case, this would be a global score, in contrast with the local scores applied
to individual tuples in a database or feature values in an entity. To introduce
the concepts and techniques we will use mostly examples, trying to convey the
main intuitions and issues.

This paper is structured as follows. In Section 2 we provide some background
material on databases and answer-set programs. In Section 3 we concentrate on
causal explanations in databases, the responsibility score, and also the causal-
eﬀect score [44], as an alternative to the latter. In Section 4, we present the
causality-repair connection and repair programs for causality and responsibility

3

computation. In Section 5, we consider causality in databases at the attribute
level, as opposed to the tuple level. In Section 6, we introduce causality and
responsibility in databases that are subject to integrity constraints. In Section
7 we present the global inconsistency measure for a database and the ASPs to
compute it. In Section 8, we describe the use of the Shapley value to provide
explanation scores in databases. In Section 8, we describe in general terms score-
based explanations for classiﬁcation results. In Section 10 we introduce and
study the x-Resp score, a simpler version of the more general Resp score that we
introduce in Section 12. In Section 11 we introduce counterfactual intervention
programs (CIP), which are ASPs that specify counterfactuals and the x-Resp
score. In Section 13, and for completeness, we brieﬂy present the Shap score. We
end in Section 14 with some ﬁnal conclusions.

2 Background

2.1 Basics of Relational Databases

A relational schema R contains a domain of constants, C, and a set of predicates
of ﬁnite arities, P. R gives rise to a language L(R) of ﬁrst-order (FO) predicate
logic with built-in equality, =. Variables are usually denoted with x, y, z, ...; and
ﬁnite sequences thereof with ¯x, ...; and constants with a, b, c, ..., etc. An atom is
of the form P (t1, . . . , tn), with n-ary P ∈ P and t1, . . . , tn terms, i.e. constants,
or variables. An atom is ground (a.k.a. a tuple) if it contains no variables. A
database (instance), D, for R is a ﬁnite set of ground atoms; and it serves as an
interpretation structure for L(R).

A conjunctive query (CQ) is a FO formula, Q(¯x), of the form ∃¯y (P1(¯x1) ∧
· · · ∧ Pm(¯xm)), with Pi ∈ P, and (distinct) free variables ¯x := ((cid:83) ¯xi) (cid:114) ¯y. If Q
has n (free) variables, ¯c ∈ Cn is an answer to Q from D if D |= Q[¯c], i.e. Q[¯c]
is true in D when the variables in ¯x are componentwise replaced by the values
in ¯c. Q(D) denotes the set of answers to Q from D. Q is a Boolean conjunctive
query (BCQ) when ¯x is empty; and when true in D, Q(D) := {true}. Otherwise,
it is false, and Q(D) := ∅. Sometimes CQs are written in Datalog notation as
follows: Q(¯x) ← P1(¯x1), . . . , Pm(¯xm).

We consider as integrity constraints (ICs), i.e. sentences of L(R): (a) denial
constraints (DCs), i.e. of the form κ : ¬∃¯x(P1(¯x1)∧· · ·∧Pm(¯xm)), where Pi ∈ P,
and ¯x = (cid:83) ¯xi; and (b) functional dependencies
(FDs), i.e. of the form ϕ :
¬∃¯x(P (¯v, ¯y1, z1)∧P (¯v, ¯y2, z2)∧z1 (cid:54)= z2).1 Here, ¯x = ¯y1 ∪ ¯y2 ∪¯v∪{z1, z2}, and z1 (cid:54)=
z2 is an abbreviation for ¬z1 = z2. A key constraint (KC) is a conjunction of FDs:
(cid:86)k
2), with k = | ¯y1| = |¯y2|, and generically yj
stands for the jth variable in ¯y. For example, ∀x∀y∀z(Emp(x, y) ∧ Emp(x, z) →
y = z), is an FD (and also a KC) that could say that an employee (x) can have
at most one salary. This FD is usually written as EmpName → EmpSalary. In
the following, we will include FDs and key constraints among the DCs.

j=1 ¬∃¯x(P (¯v, ¯y1) ∧ P (¯v, ¯y2) ∧ yj

1 (cid:54)= yj

1 The variables in ¯v do not have to go ﬁrst in the atomic formulas; what matters is

keeping the correspondences between the variables in those formulas.

4

We will also consider inclusion dependencies (INDs), which are constraints

of the form ∀¯x∃¯y(P1(¯x) → P2(¯x(cid:48), ¯y)), where P1, P2 ∈ P, and ¯x(cid:48) ⊆ ¯x.

If an instance D does not satisfy the set Σ of ICs associated to the schema,

we say that D is inconsistent, which is denoted with D (cid:54)|= Σ.

2.2 Basics of Answer-Set Programming

We will give now a brief review of the basics of answer-set programs (ASPs). As
customary, when we talk about ASPs, we refer to disjunctive Datalog programs
with weak negation and stable model semantics [23, 24]. For this reason we will,
for a given program, use the terms “stable model” (or simply, “model”) and
“answer-set” interchangeably. An answer-set program Π consists of a ﬁnite
number of rules of the form

A1 ∨ . . . ∨ An ← P1, . . . , Pm, not N1, . . . , not Nk,

(1)

where 0 ≤ n, m, k, and Ai, Pj, Ns are (positive) atoms, i.e. of the form Q(¯t),
where Q is a predicate of a ﬁxed arity, say, (cid:96), and ¯t is a sequence of length
(cid:96) of variables or constants. In rule (6), A1, . . . , not Nk are called literals, with
A1 positive, and not Nk, negative. All the variables in the Ai, Ns appear among
those in the Pj. The left-hand side of a rule is called the head, and the right-hand
side, the body. A rule can be seen as a (partial) deﬁnition of the predicates in
the head (there may be other rules with the same predicates in the head).

The constants in program Π form the (ﬁnite) Herbrand universe H of the
program. The ground version of program Π, gr (Π), is obtained by instantiating
the variables in Π in all possible ways using values from H. The Herbrand base,
HB , of Π contains all the atoms obtained as instantiations of predicates in Π
with constants in H.

A subset M of HB is a model of Π if it satisﬁes gr (Π), i.e.: For every ground
rule A1 ∨ . . . ∨ An ← P1, . . . , Pm, not N1, . . . , not Nk of gr (Π), if {P1, . . . , Pm}
⊆ M and {N1, . . . , Nk} ∩ M = ∅, then {A1, . . . , An} ∩ M (cid:54)= ∅. M is a minimal
model of Π if it is a model of Π, and Π has no model that is properly contained
in M . MM (Π) denotes the class of minimal models of Π. Now, for S ⊆ HB (Π),
transform gr (Π) into a new, positive program gr (Π)S (i.e. without not), as
follows: Delete every rule A1 ∨ . . . ∨ An ← P1, . . . , Pm, not N1, . . . , not Nk for
which {N1, . . . , Nk}∩S (cid:54)= ∅. Next, transform each remaining rule A1 ∨. . .∨An ←
P1, . . . , Pm, not N1, . . . , not Nk into A1 ∨ . . . ∨ An ← P1, . . . , Pm. Now, S is a
stable model of Π if S ∈ MM (gr (Π)S). Every stable model of Π is also a minimal
model of Π. Stable models are also commonly called answer sets, and so are we
going to do most of the time.

A program is unstratiﬁed if there is a cyclic, recursive deﬁnition of a predicate
that involves negation. For example, the program consisting of the rules a ∨ b ←
c, not d; d ← e, and e ← b is unstratiﬁed, because there is a negation in the
mutually recursive deﬁnitions of b and e. The program in Example 8 below is not
unstratiﬁed, i.e. it is stratiﬁed. A good property of stratiﬁed programs is that
the models can be upwardly computed following strata (layers) starting from

5

the facts, that is from the ground instantiations of rules with empty bodies (in
which case the arrow is usually omitted). We refer the reader to [24] for more
details.

Query answering under the ASPs comes in two forms. Under the brave se-
mantics, a query posed to the program obtains as answers those that hold in
some model of the program. However, under the skeptical (or cautious) seman-
tics, only the answers that simultaneously hold in all the models are returned.
Both are useful depending on the application at hand.

Example 1. Consider the following program Π that is already ground.

a ∨ b ← c

d ← b

a ∨ b ← e, notf

e ←

The program has two stable mod-

els: S1 = {e, a} and S2 = {e, b, d}.

Each of them expresses that the
atoms in it are true, and any other
atom that does not belong to it, is false.

These models are incomparable under set inclusion, and are minimal models
in that any proper subset of any of them is not a model of the program (i.e. does
(cid:3)
not satisfy the program).

3 Causal Explanations in Databases

In data management we need to understand and compute why certain results
are obtained or not, e.g. query answers, violations of semantic conditions, etc.;
and we expect a database system to provide explanations.

3.1 Causal responsibility

Here, we will consider causality-based explanations [36, 37], which we will illus-
trate by means of an example.

Example 2. Consider the database D, and the Boolean conjunctive query (BCQ)

R A B
a b
c d
b b

S C
a
c
b

Q : ∃x∃y(S(x) ∧ R(x, y) ∧ S(y)). (2)

It holds: D |= Q, i.e. the query is true
in D.

We ask about the causes for Q to be true: A tuple τ ∈ D is counterfactual
cause for Q (being true in D) if D |= Q and D (cid:114) {τ } (cid:54)|= Q. In this example,
S(b) is a counterfactual cause for Q: If S(b) is removed from D, Q is no longer
true.

Removing a single tuple may not be enough to invalidate the query. Accord-
ingly, a tuple τ ∈ D is an actual cause for Q if there is a contingency set Γ ⊆ D,
such that τ is a counterfactual cause for Q in D (cid:114) Γ . In this example, R(a, b)
If R(a, b) is removed
is an actual cause for Q with contingency set {R(b, b)}:
(cid:3)
from D, Q is still true, but further removing R(b, b) makes Q false.

6

Notice that every counterfactual cause is also an actual cause, with empty
contingent set. Actual causes that are not counterfactual causes need company
to invalidate a query result. Now we ask how strong are tuples as actual causes.
To answer this question, we appeal to the responsibility of an actual cause τ for
Q [36], deﬁned by:

ρD(τ ) :=

1
|Γ | + 1

,

where |Γ | is the size of a smallest contingency set, Γ , for τ , and 0, otherwise.

Example 3.
smallest contingency sets have all size 1).

(ex. 2 cont.) The responsibility of R(a, b) is 1

2 = 1

1+1 (its several

R(b, b) and S(a) are also actual causes with responsibility 1

actual (counterfactual) cause with responsibility 1 = 1

1+0 .

2 ; and S(b) is
(cid:3)

High responsibility tuples provide more interesting explanations. Causes in
this case are tuples that come with their responsibilities as “scores”. All tu-
ples can be seen as actual causes, but only those with non-zero responsibility
score matter. Causality and responsibility in databases can be extended to the
attribute-value level [5, 8] (c.f. Section 5).

As we will see in Section 4.1, there is a connection between database causal-
ity and repairs of databases w.r.t. integrity constraints (ICs) [4]. There are also
connections to consistency-based diagnosis and abductive diagnosis, that are
two forms of model-based diagnosis [46]. These connections have led to new com-
plexity and algorithmic results for causality and responsibility [5, 6]. Actually,
the latter turns out to be intractable (c.f. Section 4.1). In [6], causality under
ICs was introduced and investigated. This allows to bring semantic and domain
knowledge into causality in databases (c.f. Section 6).

Model-based diagnosis is an older area of knowledge representation where
explanations form the subject of investigation. In general, the diagnosis analysis
is performed on a logic-based model, and certain elements of the model are iden-
tiﬁed as explanations. Causality-based explanations are somehow more recent.
In this case, still a model is used, which is, in general, a more complex than a
database with a query. In the case of databases, actually there is an underly-
ing logical model, the lineage or provenance of the query [14, 47] that we will
illustrate in Section 3.2, but it is still a relatively simple model.

3.2 The causal-eﬀect score

Sometimes, as we will see right here below, responsibility does not provide intu-
itive or expected results, which led to the consideration of an alternative score,
the causal-eﬀect score. We show the issues and the score by means of an example.

Example 4. Consider the database E that represents the graph below, and the
Boolean Datalog query Π that is true in E if there is a path from a to b. Here,
E ∪ Π |= yes. Tuples have global tuple identiﬁers (tids) in the left-most column,
which is not essential, but convenient.

7

E A B
t1 a b
t2 a c
t3 c b
t4 a d
t5 d e
t6 e b

yes ← P (a, b)

P (x, y) ← E(x, y)

P (x, y) ← P (x, z), E(z, y)

All tuples are actual causes since every tuple appears in a path from a to
3 , which may be
(cid:3)

b. Also, all the tuples have the same causal responsibility, 1
counterintuitive, considering that t1 provides a direct path from a to b.

In [44], the notion causal eﬀect was introduced. It is based on three main
ideas, namely, the transformation, for auxiliary purposes, of the database into a
probabilistic database, the expected value of a query, and interventions on the
lineage of the query. The lineage of a query represents, by means of a propo-
sitional formula, all the ways in which the query can be true in terms of the
potential database tuples, and their combinations. Here, “potential” refers to
tuples that can be built with the database predicates and the database (ﬁnite)
domain. These tuples may belong to the database at hand or not. For a given
database, D, some of those atoms become true, and others false, which leads
to the instantiation of the lineage (formula) o D. This is all shown in the next
example.

Example 5. Consider the database D below, and a BCQ.

R A B
a b
a c
c b

S C
b
c

Q : ∃x∃y(R(x, y) ∧ S(y)), which
true in D.

is

For the database D in our example, the lineage of the query instantiated on

D is given by the propositional formula:

ΦQ(D) = (XR(a,b) ∧ XS(b)) ∨ (XR(a,c) ∧ XS(c)) ∨ (XR(c,b) ∧ XS(b)),

(3)

where Xτ is a propositional variable that is true iﬀ τ ∈ D. Here, ΦQ(D) takes
value 1 in D.

Now, for illustration, we want to quantify the contribution of tuple S(b) to
the query answer. For this purpose, we assign, uniformly and independently,
probabilities to the tuples in D, obtaining a probabilistic database Dp [47].
Potential tuples outside D get probability 0.

Rp A B prob
a b
a c
c b

1
2
1
2
1
2

Sp C prob
b
c

1
2
1
2

8

The Xτ ’s become independent, identically distributed Boolean random vari-
ables; and Q becomes a Boolean random variable. Accordingly, we can ask
about the probability that Q takes the truth value 1 (or 0) when an intervention
is performed on D.

Interventions are of the form do(X = x), meaning making X take value x,
with x ∈ {0, 1}, in the structural model, in this case, the lineage. That is, we ask,
for {y, x} ⊆ {0, 1}, about the conditional probability P (Q = y | do(Xτ = x)),
i.e. conditioned to making Xτ false or true.

For example, with do(XS(b) = 0) and do(XS(b) = 1), the lineage in (3) be-

comes, resp., and abusing the notation a bit:

ΦQ(D|do(XS(b) = 0) := (XR(a,c) ∧ XS(c)).
ΦQ(D|do(XS(b) = 1) := XR(a,b) ∨ (XR(a,c) ∧ XS(c)) ∨ XR(c,b).

On the basis of these lineages and Dp, when XS(b) is made false, the probability
that the instantiated lineage becomes true in Dp is:

P (Q = 1 | do(XS(b) = 0)) = P (XR(a,c) = 1) × P (XS(c) = 1) = 1
4 .

Similarly, when XS(b) is made true, the probability of the lineage becoming

true in Dp is:
P (Q = 1 | do(XS(b) = 1)) = P (XR(a,b) ∨ (XR(a,c) ∧ XS(c)) ∨ XR(c,b) = 1)= 13
16 .

The causal eﬀect of a tuple τ is deﬁned by:

CE D,Q(τ ) := E(Q | do(Xτ = 1)) − E(Q | do(Xτ = 0)).

In particular, using the probabilities computed so far:

E(Q | do(XS(b) = 0)) = P (Q = 1 | do(XS(b) = 0)) =

E(Q | do(XS(b) = 1)) = P (Q = 1 | do(XS(b) = 1)) =

,

1
4
13
16

.

Then, the causal eﬀect for the tuple S(b) is: CE D,Q(S(b)) = 13

16 > 0,
showing that the tuple is relevant for the query result, with a relevance score
(cid:3)
provided by the causal eﬀect, of 9
16 .

16 − 1

4 = 9

Let us now retake the initial example of this section.

Example 6.
lineage: ΦQ(D) = Xt1 ∨ (Xt2 ∧ Xt3 ) ∨ (Xt4 ∧ Xt5 ∧ Xt6). It holds:

(ex. 4 cont.) The Datalog query, here as a union of BCQs, has the

CE D,Q(t1) = 0.65625,
CE D,Q(t2) = CE D,Q(t3) = 0.21875,
CE D,Q(t4) = CE D,Q(t5) = CE D,Q(t6) = 0.09375.

The causal eﬀects are diﬀerent for diﬀerent tuples, and the scores are much
(cid:3)

more intuitive than the responsibility scores.

9

The deﬁnition of the causal-eﬀect score may look rather ad hoc and arbitrary.
We will revisit it in Section 8, where we will have yet another explanation score in
databases; namely one that takes a new approach, measuring the contribution of
a database tuple to a query answer through the use of the Shapley value, which is
ﬁrmly established in game theory, and is also used in several other areas [45, 43].
The main idea is that several tuples together, much like players in a coali-
tion game, are necessary to violate an IC or produce a query result. Some may
contribute more than others to the wealth distribution function (or simply, game
function), which in this case becomes the query result, namely 1 or 0 if the query
is Boolean, or a number if the query is an aggregation. The Shapley value of a
tuple can be used to assign a score to its contribution. This was done in [30],
and will be retaken in Section 8. But ﬁrst things ﬁrst.

4 Answer-Set Programs for Causality in Databases

In this section we will ﬁrst establish a useful connection between database repairs
and causes as tuples in a database. Next, we provide the basics of answer-set
programs ASPs. Then, we use ASPs, taking the form of repair programs, to
specify and compute database repairs and tuples as causes for query answers.
We end this section with a fully developed example using the DLV system and
its extensions [29].

4.1 The repair connection

The notion of repair of a relational database was introduced in order to formalize
the notion of consistent query answering (CQA), as shown in Figure 4.1: If a
database D is inconsistent in the sense that is does not satisfy a given set of
integrity constraints, ICs, and a query Q is posed to D (left-hand side of Figure
4.1), what are the meaningful, or consistent, answers to Q from D? They are
sanctioned as those that hold (are returned as answers) from all the repairs of
D. The repairs of D are consistent instances D(cid:48) (over the same schema of D),
i.e. D(cid:48) |= ICs, and minimally depart from D [2, 4] (right-hand side of Figure
4.1).

(cid:54)|= ICs

|= ICs

Fig. 1. Database repairs and consistent query answers

10

D ICsQ    ICsQrepairs of D(different repair semantics)?Notice that: (a) We have now a possible-world semantics for (consistent) query
answering; and (b) we may use in principle any reasonable notion of distance
between database instances, with each choice deﬁning a particular repair se-
mantics. In the rest of this section we will illustrate two classes of repairs, which
have been used and investigated the most in the literature. Actually, repairs in
general have got a life of their own, beyond consistent query answering.

Example 7. Let us consider the following set of denial constraints (DCs) and a
database D, whose relations (tables) are shown right here below. D is inconsis-
tent, because it violates the DCs: it satisﬁes the joins that are prohibited by the
DCs.

¬∃x∃y(P (x) ∧ Q(x, y))

¬∃x∃y(P (x) ∧ R(x, y))

P A
a
e

Q A B
a b

R A C
a c

We want to repair the original instance by deleting tuples from relations.
Notice that, for DCs, insertions of new tuple will not restore consistency. We
could change (update) attribute values though, a possibility we will consider in
Section 5.

Here we have two subset repairs, a.k.a. S-repairs. They are subset-maximal
consistent subinstances of D: D1 = {P (e), Q(a, b), R(a, c)} and D2 = {P (e),
P (a)}. They are consistent, subinstances of D, and any proper superset of them
(still contained in D) is inconsistent. (In general, we will represent database
relations as set of tuples.)

We also have cardinality repairs, a.k.a. C-repairs. They are consistent subin-
stances of D that minimize the number of tuples by which they diﬀer from D.
That is, they are maximum-cardinality consistent subinstances. In this case, only
D1 is a C-repair. Every C-repair is an S-repair, but not necessarily the other
(cid:3)
way around (as this example shows).

Let us now consider a BCQ

Q : ∃¯x(P1(¯x1) ∧ · · · ∧ Pm(¯xm)),

(4)

which we assume is true in a database D. It turns out that we can obtain the
causes for Q to be true D, and their contingency sets from database repairs. In
order to do this, notice that ¬Q becomes a DC

κ(Q) : ¬∃¯x(P1(¯x1) ∧ · · · ∧ Pm(¯xm));

(5)

and that Q holds in D iﬀ D is inconsistent w.r.t. κ(Q).

It holds that S-repairs are associated to causes with minimal contingency
sets, while C-repairs are associated to causes for Q with minimum contingency
sets, and maximum responsibilities [5]. In fact, for a database tuple τ ∈ D:

(a) τ is actual cause for Q with subset-minimal contingency set Γ iﬀ D (cid:114) (Γ ∪
1
1+|Γ | .

{τ }) is an S-repair (w.r.t. κ(Q)), in which case, its responsibility is

11

(b) τ is actual cause with minimum-cardinality contingency set Γ iﬀ D (cid:114) (Γ ∪
{τ }) is C-repair, in which case, τ is a maximum-responsibility actual cause.

Conversely, repairs can be obtained from causes and their contingency sets [5].
These results can be extended to unions of BCQs (UBCQs), or equivalently, to
sets of denial constraints.

One can exploit the connection between causes and repairs to understand
the computational complexity of the former by leveraging existing results for the
latter. Beyond the fact that computing or deciding actual causes can be done
in polynomial time in data for CQs and UCQs [36, 5], one can show that most
computational problems related to responsibility are hard, because they are also
hard for repairs, in particular, for C-repairs (all this in data complexity) [32]. In
particular, one can prove [5]: (a) The responsibility problem, about deciding if a
tuple has responsibility above a certain threshold, is NP -complete for UCQs. (b)
Computing ρD(τ ) is FP NP(log(n))-complete for BCQs. This the functional, non-
decision, version of the responsibility problem. The complexity class involved
is that of computational problems that use polynomial time with a logarithmic
number of calls to an oracle in NP. (c) Deciding if a tuple τ is a most responsible
cause is P NP(log(n))-complete for BCQs. The complexity class is as the previous
one, but for decision problems [1].

4.2 Answer-set programs

We will give now a brief review of the basics of answer-set programs (ASPs). As
customary, when we talk about ASPs, we refer to disjunctive Datalog programs
with weak negation and stable model semantics [23, 24]. For this reason we will,
for a given program, use the terms “stable model” (or simply, “model”) and
“answer-set” interchangeably. An answer-set program Π consists of a ﬁnite
number of rules of the form

A1 ∨ . . . ∨ An ← P1, . . . , Pm, not N1, . . . , not Nk,

(6)

where 0 ≤ n, m, k, and Ai, Pj, Ns are (positive) atoms, i.e. of the form Q(¯t),
where Q is a predicate of a ﬁxed arity, say, (cid:96), and ¯t is a sequence of length
(cid:96) of variables or constants. In rule (6), A1, . . . , not Nk are called literals, with
A1 positive, and not Nk, negative. All the variables in the Ai, Ns appear among
those in the Pj. The left-hand side of a rule is called the head, and the right-hand
side, the body. A rule can be seen as a (partial) deﬁnition of the predicates in
the head (there may be other rules with the same predicates in the head).

The constants in program Π form the (ﬁnite) Herbrand universe H of the
program. The ground version of program Π, gr (Π), is obtained by instantiating
the variables in Π in all possible ways using values from H. The Herbrand base,
HB , of Π contains all the atoms obtained as instantiations of predicates in Π
with constants in H.

A subset M of HB is a model of Π if it satisﬁes gr (Π), i.e.: For every ground
rule A1 ∨ . . . ∨ An ← P1, . . . , Pm, not N1, . . . , not Nk of gr (Π), if {P1, . . . , Pm}

12

⊆ M and {N1, . . . , Nk} ∩ M = ∅, then {A1, . . . , An} ∩ M (cid:54)= ∅. M is a minimal
model of Π if it is a model of Π, and Π has no model that is properly contained
in M . MM (Π) denotes the class of minimal models of Π. Now, for S ⊆ HB (Π),
transform gr (Π) into a new, positive program gr (Π)S (i.e. without not), as
follows: Delete every rule A1 ∨ . . . ∨ An ← P1, . . . , Pm, not N1, . . . , not Nk for
which {N1, . . . , Nk}∩S (cid:54)= ∅. Next, transform each remaining rule A1 ∨. . .∨An ←
P1, . . . , Pm, not N1, . . . , not Nk into A1 ∨ . . . ∨ An ← P1, . . . , Pm. Now, S is a
stable model of Π if S ∈ MM (gr (Π)S). Every stable model of Π is also a minimal
model of Π. Stable models are also commonly called answer sets, and so are we
going to do most of the time.

A program is unstratiﬁed if there is a cyclic, recursive deﬁnition of a predicate
that involves negation. For example, the program consisting of the rules a ∨ b ←
c, not d; d ← e, and e ← b is unstratiﬁed, because there is a negation in the
mutually recursive deﬁnitions of b and e. The program in Example 8 below is not
unstratiﬁed, i.e. it is stratiﬁed. A good property of stratiﬁed programs is that
the models can be upwardly computed following strata (layers) starting from
the facts, that is from the ground instantiations of rules with empty bodies (in
which case the arrow is usually omitted). We refer the reader to [24] for more
details.

Query answering under the ASPs comes in two forms. Under the brave se-
mantics, a query posed to the program obtains as answers those that hold in
some model of the program. However, under the skeptical (or cautious) seman-
tics, only the answers that simultaneously hold in all the models are returned.
Both are useful depending on the application at hand.

Example 8. Consider the following program Π that is already ground.

a ∨ b ← c

d ← b

a ∨ b ← e, notf

e ←

The program has two stable mod-

els: S1 = {e, a} and S2 = {e, b, d}.

Each of them expresses that the
atoms in it are true, and any other
atom that does not belong to it, is false.

These models are incomparable under set inclusion, and are minimal models
in that any proper subset of any of them is not a model of the program (i.e. does
(cid:3)
not satisfy the program).

4.3 Repair-programs for causality in databases

Answer-set programs (ASPs) can be used to specify, compute and query S- and
C-repairs. These ASPs are called “repair programs”. We will show the main
ideas behind them by means of an example. For a more complete treatment see
[17, 4].

Example 9.
Q in (2): κ(Q) : ¬∃x∃y(S(x) ∧ R(x, y) ∧ S(y)).

(example 2 cont.) Let us consider the DC associated to the query

13

The given database is inconsistent w.r.t. κ(Q), and we may consider its re-
Its repair program contains the D as set of facts, now (only for con-
pairs.
venience) with global tuple identiﬁers (tids) in the ﬁrst attribute: R(1, a, b),
R(2, c, d), R(3, b, b), S(4, a), S(5, c), S(6, b).

The main rule is the properly repair rule:

S(cid:48)(t1, x, d) ∨ R(cid:48)(t2, x, y, d) ∨ S(cid:48)(t3, y, d) ←− S(t1, x), R(t2, x, y), S(t3, y).

Here, d is an annotation constant for “tuple deleted”. This rule detects in its
body (its right-hand side) a violation of the DC. If this happens, its head (its
left-hand-side) instructs the deletion of one of the tuples participating in the
violation. The semantics of the program forces the choice of only one atom in
the head (unless forced otherwise by other rules in the program, which does not
occur in repair programs). Diﬀerent choices will lead to diﬀerent models of the
program, and then, to diﬀerent repairs.

In order to “build” the repairs, we need the collection rules:

S(cid:48)(t, x, s) ←− S(t, x), not S(cid:48)(t, x, d).

etc.

s is an annotation for “tuple stays in repair”; and the rule collects the

Here,
tuples in the original instance that have not been deleted.

There is a one-to-one correspondence between the answer-sets of the repair
program and the database repairs. Actually, a model M of the program deter-
:= {R(¯c) | R(cid:48)(t, ¯c, s) ∈ M }. Conversely,
mines an S-repair D(cid:48) of D, as D(cid:48)
every S-repair can obtained in this way.

In this example, the S-repair, D1 = {R(a, b), R(c, d), R(b, b), S(a), S(c)},
can be obtained from the model M1 = {R(cid:48)(1, a, b, s), R(cid:48)(2, c, d, s), R(cid:48)(3, b, b, s),
S(cid:48)(4, a, s), S(cid:48)(5, c, s), S(cid:48)(6, b, d), . . .}. Actually, D1 is a C-repair.

There is another S-repair, D2 = {R(c, d), S(a), S(c), S(b)}, that is asso-
ciated to the model M2 = {R(cid:48)(1, a, b, d), R(cid:48)(2, c, d, s), R(cid:48)(3, b, b, d), S(cid:48)(4, a, s),
(cid:3)
S(cid:48)(5, c, s), S(cid:48)(6, b, s), . . .}. This is not a C-repair.

For sets of DCs, repair programs can be made normal, i.e. non-disjunctive
[17]. CQA becomes query answering under the cautious or skeptical semantics
of ASPs (i.e. true in all repairs), which, for normal programs, is NP -complete
(in data). This matches the data complexity of consistent QA under DCs (c.f.
[4] for references to complexity of CQA).

Now, if we want to obtain from the program only those models that corre-
spond to C-repairs, we can add weak program constraints (WCs), as shown in
the example.

Example 10. (example 9 cont.) Let us add to the program the WCs

:∼ R(t, ¯x), R(cid:48)(t, ¯x, d)
:∼ S(t, ¯x), S(cid:48)(t, ¯x, d).

A (hard) program constraint in a program [29], usually denoted as

:− P1(¯x1), . . . , P1(¯xn),

14

leads to discarding all the models where the join in the RHS of the constraint
holds. Weak program constraints, now preceded by a “:∼”, may be violated by a
model, buy only the models where the number of violations of them is minimized
are kept. In our example, the WCs have the eﬀect of minimizing the number of
deleted tuples. In this way, we obtain as models only C-repairs.

In our example, we obtain C-repair D1, corresponding to model M1, but not
S-repair D2, because it is associated to model M2 that is discarded due to the
(cid:3)
WCs.

As we already mentioned, C-repairs are those that can be used to obtain
most-responsible actual causes. Accordingly, the latter task can be accomplished
through the use of repair programs with weak constraints. We illustrate this by
means of our example (c.f. [8] for a detailed treatment). Actually, cause and re-
sponsibility computation become query answering on extended repair programs.
In them, causes will be represented by means of the tids we introduced for repair
programs.

Example 11.
predicate, deﬁned by the rules

(example 10 cont.) The causes can be obtained through a new

Cause(t) ←− R(cid:48)(t, x, y, d),
Cause(t) ←− S(cid:48)(t, x, d),

because they correspond to deleted tuples in a repair. If we want to obtain them,
it is good enough to pose a query under the brave semantics, which returns what
is true in some model: Π |=brave Cause(t)?

However, we would like to obtain contingency sets (for causes) and responsi-
bilities. We will concentrate on maximum-responsibility causes and their (max-
imum) responsibilities, for which we assume the repair program has weak con-
straints, as above (c.f. [8] for non-maximum responsibility causes).

We ﬁrst introduce a new binary predicate, to collect a cause and an associated
contingency tuple (which is deleted together with the tuple-cause in a same
repair). This predicate is of the form CauCon(t, t(cid:48)), indicating that t is actual
cause, and t(cid:48)
is a member of the former’s contingency set. For this, for each pair
of predicates Pi, Pj, not necessarily diﬀerent, in the DC κ(Q), we introduce the
rule:

CauCon(t, t(cid:48)) ←− P (cid:48)

i (t, ¯xi, d), P (cid:48)

j(t(cid:48), ¯xj, d), t (cid:54)= t(cid:48).

This will make t(cid:48) a member of t’s contingency set. In our example, we have the
rule:

CauCon(t, t(cid:48)) ←− S(cid:48)(t, x, d), R(cid:48)(t(cid:48), u, v, d),

where the inequality is not needed (for having diﬀerent predicates), but also,
among others,

CauCon(t, t(cid:48)) ←− S(cid:48)(t, x, d), S(cid:48)(t(cid:48), u, d), t (cid:54)= t(cid:48).

In model M1, corresponding to C-repair D1, where there is no pair of simul-
taneously deleted tuples, we have no CauCon atoms. Had model M2 not been

15

discarded due to the WCs, we would ﬁnd in it (actually in its extension) the
(cid:3)
atoms: CauCon(1, 3) and CauCon(3, 1).

Contingency sets, which is what we want next, are sets, which in general are
not returned as objects from an ASP. However, there are extensions of ASP and
their implementations, such as DLV [29], that, trough aggregations, support set
construction. This is the case of DLV-Complex [15, 16], that we have used in
for running repair programs and their extensions. We do this as follows (in the
program below , t, t(cid:48) are variables).

preCon(t, {}) ← Cause(t), not Aux 1(t)

Aux 1(t) ← CauCon(t, t(cid:48))
preCon(t, {t(cid:48)}) ← CauCon(t, t(cid:48))
preCon(t, #union(C, {t(cid:48)(cid:48)})) ← CauCon(t, t(cid:48)(cid:48)), preCon(t, C),

not #member (t(cid:48)(cid:48), C)

Con(t, C) ← preCon(t, C), not Aux 2(t, C)
Aux 2(t, C) ← CauCon(t, t(cid:48)), #member (t(cid:48), C)

(7)

(8)

(9)

(10)

(11)

The auxiliary predicate in rule (2) is used to avoid a non-safe negation. That
predicate is deﬁned by rule (8). We are capturing here causes that do not have
contingency companions, and then, they have an empty contingency set. Rule
(9 is indeed redundant, but shows the main idea: a contingency companion of a
cause is taken as element into the latter’s pre-contingency set. In rule (11) we
have an auxiliary predicate for the same reason as in the ﬁrst rule. The main
idea is to stepwise keep adding by means of set union (c.f. rule (10), a contingent
element to a possibly partial contingency set, until there is nothing left to add.
These maximal contingency sets are obtained with rule (11).

In each model of the program with WCs, these contingency sets will have
the same minimum size, and will lead to maximum responsibility causes. Re-
sponsibility computation can be done, with numerical aggregation supported by
DLV-Complex, as follows:

pre-rho(t, n) ← #count{t(cid:48) : CauCon(t, t(cid:48))} = n
rho(t, m) ← m ∗ (pre-rho(t, m) + 1) = 1

The ﬁrst rule gives us the (minimum) size, n, of contingency sets, which leads
1
1+n . The responsibility of a (maximum responsibility)
to a responsibility of
cause t can be obtained through a query to the extended program: Π e |=brave
rho(t, X)?.

ASP with WCs computation has exactly the required expressive power or
computational complexity needed for maximum-responsibility computation [8].

4.4 The example with DLV-Complex

In this section we show in detail the running example in Section 4.3, fully spec-
iﬁed and executed with the DLV-Complex system [15, 16]. C.f. [8] for more
details.

16

Example 12. (ex. 9 cont.) The ﬁrst fragment of the DLV program below, shows
facts for database D, and the disjunctive repair rule for the DC κ(Q). In it, and
in the rest of this section, R_a, S_a, ... stand for R(cid:48), S(cid:48), ... used before, with
the subscript _a for “auxiliary”. We recall that the ﬁrst attribute of a predicate
holds a variable or a constant for a tid; and the last attribute of R_a, etc. holds
an annotation constant, d or s, for “deleted” (from the database) or “stays”
in a repair, resp. (In DLV programs, variables start with a capital letter, and
constants, with lower-case.)

R(1,a,b). R(2,c,d). R(3,b,b). S(4,a). S(5,c). S(6,b).

S_a(T1,X,d) v R_a(T2,X,Y,d) v S_a(T3,Y,d) :- S(T1,X),R(T2,X,Y), S(T3,Y).
S_a(T,X,s)
R_a(T,X,Y,s) :- R(T,X,Y), not R_a(T,X,Y,d).

:- S(T,X), not S_a(T,X,d).

DLV returns the stable models of the program, as follows:

{S_a(6,b,d), R_a(1,a,b,s), R_a(2,c,d,s), R_a(3,b,b,s),

S_a(4,a,s), S_a(5,c,s)}

{R_a(1,a,b,d), R_a(3,b,b,d), R_a(2,c,d,s), S_a(4,a,s),
S_a(5,c,s), S_a(6,b,s)}

{S_a(4,a,d), R_a(3,b,b,d), R_a(1,a,b,s), R_a(2,c,d,s),

S_a(5,c,s), S_a(6,b,s)}

These three stable models (that do not show here the original EDB) are
associated to the S-repairs D1, D2, D3, resp. Only tuples with tids 1, 3, 4, 6 are
at some point deleted. In particular, the ﬁrst model corresponds to the C-repair
D1 = {R(s4, s3), R(s2, s1), R(s3, s3), S(s4), S(s2)}.

Now, to compute causes and their accompanying deleted tuples we add to

the program the rules deﬁning Cause and CauCont:

cause(T) :- S_a(T,X,d).
cause(T) :- R_a(T,X,Y,d).

cauCont(T,TC) :- S_a(T,X,d), S_a(TC,U,d), T != TC.
cauCont(T,TC) :- R_a(T,X,Y,d), R_a(TC,U,V,d), T != TC.
cauCont(T,TC) :- S_a(T,X,d), R_a(TC,U,V,d).
cauCont(T,TC) :- R_a(T,X,Y,d), S_a(TC,U,d).

Next, contingency sets can be computed by means of DLV-Complex, on the

basis of the rules deﬁning predicates cause and cauCont above:

preCont(T,{TC}) :- cauCont(T,TC).

preCont(T,#union(C,{TC})) :- cauCont(T,TC), preCont(T,C),

not #member(TC,C).

cont(T,C)
HoleIn(T,C) :- preCont(T,C), cauCont(T,TC),

:- preCont(T,C), not HoleIn(T,C).

not #member(TC,C).

tmpCont(T)
cont(T,{})

:- cont(T,C), not #card(C,0).
:- cause(T), not tmpCont(T).

17

The last two rules associate the empty contingency set to counterfactual

causes.

The three stable models obtained above will now be extended with cause-
and cont-atoms, among others (unless otherwise stated, preCont-, tmpCont-,
and HoleIn-atoms will be ﬁltered out from the output); as follows:

{S_a(4,a,d), R_a(3,b,b,d), R_a(1,a,b,s), R_a(2,c,d,s),

S_a(5,c,s), S_a(6,b,s), cause(4), cause(3), cauCont(4,3),
cauCont(3,4), cont(3,{4}), cont(4,{3})}

{R_a(1,a,b,d), R_a(3,b,b,d), R_a(2,c,d,s), S_a(4,a,s),

S_a(5,c,s), S_a(6,b,s), cause(1), cause(3), cauCont(1,3),
cauCont(3,1), cont(1,{3}), cont(3,{1})}

{S_a(6,b,d), R_a(1,a,b,s), R_a(2,c,d,s), R_a(3,b,b,s),

S_a(4,a,s), S_a(5,c,s), cause(6), cont(6,{})}

The ﬁrst two models above show tuple 3 as an actual cause, with one con-
tingency set per each of the models where it appears as a cause. The last line of
the third model shows that cause (with tid) 6 is the only counterfactual cause
(its contingency set is empty).

The responsibility ρ can be computed via predicate preRho(T, N ) that re-
turns N = 1
ρ , that is the inverse of the responsibility, for each tuple with tid
T and local to a model that shows T as a cause. We concentrate on the com-
putation of preRho in order to compute with integer numbers, as supported
by DLV-Complex, which requires setting an upper integer bound by means of
maxint, in this case, at least as large as the largest tid:

#maxint = 100.
preRho(T,N + 1) :- cause(T), #int(N), #count{TC: cauCont(T,TC)} = N.

where the local (pre)responsibility of a cause (with tid) T within a repair is
obtained by counting how many instances of cauCont(T, ?) exist in the model,
which is the size of the local contingency set for T plus 1. We obtain the following
(ﬁltered) output:

{S_a(4,a,d), R_a(3,b,b,d), cause(4), cause(3),

preRho(3,2), preRho(4,2), cont(3,{4}), cont(4,{3})}

{R_a(1,a,b,d), R_a(3,b,b,d), cause(1), cause(3),

preRho(1,2), preRho(3,2), cont(1,{3}), cont(3,{1})}

{S_a(6,b,d), cause(6), preRho(6,1), cont(6,{})}

The ﬁrst model shows causes 3 and 4 with a pre-rho value of 2. The second
one, causes 3 and 1 with a pre-rho value of 2. The last model shows cause 6
with a pre-rho value of 1. This is also a maximum-responsibility cause, actually
associated to a C-repair. Inspecting the three models, we can see that the overall
pre-responsibility of cause 3 (the minimum of its pre-rho values) is 2, similarly
for cause 1. For cause 6 the overall pre-responsibility value is 1.

18

Now, if we want only maximum-responsibility causes, we add weak program

constraints to the program above, to minimize the number of deletions:

:~ S_a(T,X,d).
:~ R_a(T,X,Y,d).

DLV shows only repairs with the least number of deletions, in this case:

Best model: {S_a(6,b,d), R_a(1,a,b,s), R_a(2,c,d,s), R_a(3,b,b,s),

S_a(4,a,s), S_a(5,c,s), cause(6), preRho(6,1), cont(6,{})}

Cost ([Weight:Level]): <[1:1]>

As expected, only repair D1 is obtained, where only S(6, s3) is a cause, and
(cid:3)

with responsibility 1, making it a maximum-responsibility cause.

5 Causal Explanations in Databases: Attribute-Level

In Section 4.1 we saw that: (a) there are diﬀerent database repair-semantics; and
(b) tuples as causes for query answering can be obtained from S- and C-repairs.
We can extrapolate from this, and deﬁne, as opposed to only reobtain, notions
of causality on the basis of a repair semantics. This is what we will do next in
order to deﬁne attribute-level causes for query answering in databases.

We may start with a repair-semantics S for databases under, say denial
constraints (this is the case we need here, but we could have more general ICs).
Now, we have a database D and a true BCQ Q. As before, we have an associated
(and violated) denial constraint κ(Q). There will be S-repairs, i.e. sanctioned as
such by the repair semantics S. More precisely, the repair-semantics S identiﬁes
a class RepS(D, κ(Q)) of admissible and consistent instances that “minimally”
depart from D. On this basis, S-causes can be deﬁned as in Section 4.1(a)-(b).
Of course, “minimality” has to be deﬁned, and comes with S.

We will develop this idea, at the light of an example, with a particular repair-
semantics, and we will apply it to deﬁne attribute-level causes for query answer-
ing, i.e. we are interested in attribute values in tuples rather than in whole tuples.
The repair semantics we use here is natural, but others could be used instead.

Example 13. Consider the database D, with tids, and query Q : ∃x∃y(S(x) ∧
R(x, y) ∧ S(y)), of Example 2 and the associated denial constraint κ(Q) :
¬∃x∃y(S(x) ∧ R(x, y) ∧ S(y)).

R A B
t1 a b
t2 c d
t3 b b

S C
t4 a
t5 c
t6 b

Since D (cid:54)|= κ(Q), we need to consider
repairs of D w.r.t. κ(Q).

Repairs will be obtained by “minimally” changing attribute values by NULL,
as in SQL databases, which cannot be used to satisfy a join. In this case, min-
imality means that the set of values changed by NULL is minimal under set
inclusion. These are two diﬀerent minimal-repairs:

19

R A B
t1 a b
t2 c d
t3 b b

S C
a
t4
t5
c
t6 NULL

R A B
t1 a NULL
t2 c
t3 b NULL

d

S C
t4 a
t5 c
t6 b

It is easy to check that they do not satisfy κ(Q). If we denote the changed val-
ues by the tid with the position where the changed occurred, then the ﬁrst repair
is characterized by the set {t6[1]}, whereas the second, by the set {t1[2], t3[2]}.
Both are minimal since none of them is contained in the other.

Now, we could also introduce a notion of cardinality-repair, keeping those
where the number of changes is a minimum. In this case, the ﬁrst repair qualiﬁes,
but not the second.

These repairs identify (actually, deﬁne) the value in t6[1] as a maximum-
responsibility cause for Q to be true (with responsibility 1). Similarly, t1[2] and
t3[2] become actual causes, that do need contingent companion values, which
(cid:3)
makes them take a responsibility of 1
2 each.

We should emphasize that, under this semantics, we are considering attribute
values participating in joins as interesting causes. A detailed treatment can be
found in [8]. Of course, one could also consider as causes other attribute values
in a tuple that participate in a query (being true), e.g. that in t3[1], but making
them non-prioritized causes. One could also think of adjusting the responsibility
measure in order to give to these causes a lower score.

5.1 ASPs for attribute-level causality

So as in Sections 4.3 and 4.4, we can specify attribute-level causes via attribute-
based repairs, and their ASPs. We show this at the light of an example that is
given directly using DLV code (c.f. [8] for more details).

Example 14. Consider the database instance

D = {S(a), S(b), R(b, c), R(b, d), R(b, e)},

and the BCQ Q : ∃x∃y(S(x) ∧ R(x, z)), which is true in D, and for which we
want to ﬁnd attribute-level causes.

We consider the DC corresponding to the negation of query, namely

κ : ¬∃x∃y(S(x) ∧ R(x, z)).

Since D (cid:54)|= κ, D is inconsistent. The updated instance

D2 = {S(a), S(NULL), R(b, c), R(b, d), R(b, e)}

is consistent (among others obtained by updates with NULL), i.e. D2 |= κ.

In the DLV program below, R_a, and S_a are the auxiliary predicates associ-
ated to R and S. They accommodate annotation constants in their last argument.
The annotation constants tr, u, fu and s stand for “in transition” (i.e. initial

20

or updated tuple, that could be further updated), “has been updated”, “is ﬁnal
update”, and “stays in repair”, resp. The tuples already contain tuple-ids. Here,
T, T2, X, Y, ... are variables.

S(1,a).

S(2,b).

R(3,b,c).

R(4,b,d).

R(5,b,e).

S_a(T,X,tr) :- S(T,X).
S_a(T,X,tr) :- S_a(T,X,u).

R_a(T,X,Y,tr) :- R(T,X,Y).
R_a(T,X,Y,tr) :- R_a(T,X,Y,u).

This part of the program so far provides, as facts, the tuples in the database
with their tids. It also deﬁnes each of these tuples as “in transition”. The same
for those that have been updated.

The updates themselves come in the following portion of the program. In it,
null is treated as any other constant, and can be compared with other constants
(as opposed to their occurrence as NULL in SQL, where any comparison involving
it is considered to be false).

The ﬁrst two rules capture, in the ﬁrst three atoms in the body, a violation
of the constraints, i.e. a join through a non-null value, for X. The last atom in
the body of the ﬁrst rule says that the value for X in R is not updated to null ,
then, as speciﬁed in the head of the rule, it has to be updated in S. The second
rule is similar, but the other way around.2

S_a(T,null,u) :- S_a(T,X,tr), R_a(T2,X,Y,tr), X != null,
not R_a(T2,null,Y,u).
R_a(T,null,Y,u) :- R_a(T,X,Y,tr), S_a(T2,X,tr), X != null,
not S_a(T2,null,u).

In R_a(t,m,n,fu) below, annotation fu means that the atom with tid t has
reached its ﬁnal update (during the program evaluation). In particular, R(t,m,n)
has already been updated, and annotation u should appear in the new, updated
atom, say R_a(t,m1,n1,u), and this tuple cannot be updated any further (be-
cause relevant updateable attribute values have already been replaced by null
if necessary). This is captured by the next ﬁve rules:

S_a(T,X,fu) :- S_a(T,X,u), not auxS1(T,X).

auxS1(T,X) :- S(T,X), S_a(T,null,u), X != null.

R_a(T,X,Y,fu) :- R_a(T,X,Y,u), not auxR1(T,X,Y), not auxR2(T,X,Y).

auxR1(T,X,Y) :- R(T,X,Y), R_a(T,null,Y,u), X != null.
auxR2(T,X,Y) :- R(T,X,Y), R_a(T,X,null,u), Y != null.

The ﬁnal six rules collect what stays in a repair, as annotated with s:

2 Those two normal rules could be replaced by a single disjunctive rule:

S a(T, null , u) ∨ R a(T, null , Y, u) ← S a(T, X, tr ), R a(T 2, X, Y, tr ), X (cid:54)= null . For
this kind of disjunctive repair programs one can show that the normal and disjunc-
tive versions are equivalent, i.e. they have the same models. This is because, the
disjunctive program becomes head-cycle free [20].

21

S_a(T,X,s) :- S_a(T,X,fu).
S_a(T,X,s) :- S(T,X), not auxS(T).

auxS(T) :- S_a(T,X,u).

R_a(T,X,Y,s) :- R_a(T,X,Y,fu).
R_a(T,X,Y,s) :- R(T,X,Y), not auxR(T).

auxR(T) :- R_a(T,X,Y,u).

Two stable models are returned, corresponding to two attribute-based re-

pairs: (we skip the atoms without annotation s)

{S_a(1,a,s), S_a(2,b,s), R_a(3,null,c,s), R_a(5,null,e,s), R_a(4,null,d,s)}
{S_a(1,a,s), R_a(3,b,c,s), R_a(4,b,d,s), R_a(5,b,e,s), S_a(2,null,s)}

The second model corresponds to the repair D2 given at the beginning of

this example.

We could extend the program with rules to collect the attribute values that

are causes for the query to be true:

cause(T,1,X) :- R(T,X,Y), R_a(T,null,Z,s).
cause(T,2,Y) :- R(T,X,Y), R_a(T,Z,null,s).
cause(T,1,X) :- S(T,X), S_a(T,null,s).

Here, the second argument indicates the position where the cause, as a value,
appears in a tuple. Remember that the tids are global, so having them in the
ﬁrst body atom in these rules will always make these rules to be evaluated with
diﬀerent tids, which come from the original database.

Here, we are assuming the original database does not have nulls. If it does,
it is good enough to add the extra condition X != null in the body of the ﬁrst
rule, and similarly for the other rules. Each model will return some causes. If we
want them all, and we have no interest in the repairs or the complete models, we
can just pose a query under the brave semantics: :- cause(U,V,W)? We will
obtain all the cause-atoms that appear in some of the models of the extended
program, e.g. cause(3,1,b), i.e. the value b in the ﬁrst attribute, “1”, of tuple
(cid:3)
with id 3.

6 Causes under Integrity Constraints

In this section we consider tuples as causes for query answering in the more
general setting where databases are subject to integrity constraints (ICs). In
this scenario, and in comparison with Section 3.1, not every intervention on the
database is admissible, because the ICs have to be satisﬁed. As a consequence,
the deﬁnitions of cause and responsibility have to be modiﬁed accordingly. We
illustrate the issues by means of an example. More details can be found in [6, 8].
We start assuming that a database D satisﬁes a set of ICs, Σ, i.e. D |= Σ. If
we concentrate on BCQs, or more, generally on monotone queries, and consider
causes at the tuple level, only instances obtained from D by interventions that
are tuple deletions have to be considered; and they should satisfy the ICs. More
precisely, for τ to be actual cause for Q, with a contingency set Γ , it must hold
[6]:

22

(a) D (cid:114) Γ |= Σ, and D (cid:114) Γ |= Q.
(b) D (cid:114) (Γ ∪ {τ }) |= Σ, and D (cid:114) (Γ ∪ {τ }) (cid:54)|= Q.

The responsibility of τ , denoted ρD,Σ
minimum-size contingency sets.

Q(¯a)

(τ ),

is deﬁned as in Section 3.1, through

Example 15. Consider the database instance D as below, initially without ad-
ditional ICs.

Course CName TStaﬀ DName

Dep DName TStaﬀ
t1 Computing John
t2 Philosophy Patrick
Kevin
t3

Math

COM08 John Computing

t4
t5 Math01 Kevin
t6
t7 Math08
t8

Eli

Math

Math

HIST02 Patrick Philosophy

COM01 John Computing

Let us ﬁrst consider the following open query: (The fact that it is open is
not particularly relevant, because we can instantiate the query with the answer,
obtaining a Boolean query.)

Q(x) : ∃y∃z(Dep(y, x) ∧ Course(z , x , y)).

(12)

In this case, we get answers other that yes or no. Actually, (cid:104)John(cid:105) ∈ Q(D),
the set of answers to Q, and we look for causes for this particular answer. It
holds: (a) t1 is a counterfactual cause; (b) t4 is actual cause with single minimal
contingency set Γ1 = {t8}; (c) t8 is actual cause with single minimal contingency
set Γ2 = {t4}.

Let us now impose on D the inclusion dependency (IND):

ψ :

∀x∀y (Dep(x, y) → ∃u Course(u, y, x)),

(13)

which is satisﬁed by D. Now, t4 t8 are not actual causes anymore; and t1 is
still a counterfactual cause.

Let us now consider the query

Q1(x) : ∃y Dep(y, x).

(14)

Now, (cid:104)John(cid:105) ∈ Q1(D), and under the IND (13), we obtain the same causes as
for Q, which is not surprising considering that Q ≡ψ Q1, i.e. the two queries
are logically equivalent under (13).
And now, consider the query:

Q2(x) : ∃y∃zCourse(z, x, y),

(15)

for which (cid:104)John(cid:105) ∈ Q2(D).

For this query we consider the two scenarios, with and without imposing
t4 and t8 are the only actual causes, with

the IND. Without imposing (13),
contingency sets Γ1 = {t8} and Γ2 = {t4}, resp.

However, imposing (13),

t4 and t8 are still actual causes, but we lose their
smallest contingency sets Γ1 and Γ2 we had before: D (cid:114) (Γ1 ∪ {t4}) (cid:54)|= ψ,

23

D (cid:114) (Γ2 ∪ {t8}) (cid:54)|= ψ. Actually, the smallest contingency set for t4 is Γ3 =
{t8, t1}; and for t8, Γ4 = {t4, t1}.

We can see that under the IND, the responsibilities of t4 and t8 decrease:
3 . Tuple t1 is not an actual cause, but it
(cid:3)

ρD
2 , but ρD,ψ
Q2(John)
aﬀects the responsibility of actual causes.

(t4) = 1

(t4) = 1

Q2(John)

Some results about causality under ICs can be obtained [6]:

(a) Causes
are preserved under logical equivalence of queries under ICs, (b) Without ICs,
deciding causality for BCQs is tractable, but their presence may make complexity
grow. More precisely, there are a BCQ and an inclusion dependency for which
deciding if a tuple is an actual cause is NP -complete in data.

6.1 Specifying and computing causes under integrity constraints

ASPs for computation of causes and responsibilities under ICs can be produced.
However, Example 15 shows that contingency sets may be aﬀected by the pres-
ence of ICs.

Example 16. (ex. 15 cont.) Database D violates the DC κ2 : ¬∃zCourse(z,
John) associated to query Q2 and its answer John. Without considering ψ,
its only minimal repair is D(cid:48) = D (cid:114) {τ4, τ8}. However, if we accept minimal
repairs that also satisfy ψ (when D already did), then the only minimal repair
(cid:3)
is D(cid:48)(cid:48) = D (cid:114) {τ1, τ4, τ8}.

This example shows that, in the presence of a set of hard ICs Ψ , the repairs
w.r.t. to another set of ICs Σ that also satisfy Ψ may not be among the repairs
w.r.t. Σ without consideration for Ψ . So, it is not only a matter of discarding
some of the unwanted repairs w.r.t. Σ alone.

The example also shows that, in the presence of a hard set of ICs Ψ , the
characterization of causes in terms of repairs (as in Section 3.1) has to be revised.
Doing this should be relatively straightforward for repairs of D w.r.t. the DCs
Σ that have origin in UBCQs, and are maximally contained in D under set-
inclusion, and also satisfy the hard constraints Ψ . Instead of giving a general
approach, we show how a repair-program could be used to reobtain the results
obtained in Example 15, where an inclusion dependency is our IC.

Example 17. (exs. 15 and 16 cont.) Without considering the IC ψ, the repair-
program for D w.r.t. the DC κ2 is:

1. The extensional database as a set of facts corresponding to the table. For

example, Dept(1, computing, john), etc.

2. Repair rule for κ2: Course (cid:48)(t, z, john, d) ← Course(t, z, john).
3. Persistence rule: Course (cid:48)(t, x, y, s) ← Course(t, x, y), not Course (cid:48)(t, x, y, d).

We have to add to this program, rules that take care of repairing w.r.t. ψ in case
it is violated via deletions from Course:

4. Dept (cid:48)(t(cid:48), x, y, d) ← Dept(t(cid:48), x, y), not aux (y)

24

5. aux (y) ← Course (cid:48)(t, x, y, s).
6. Dept (cid:48)(t, x, y, s) ← Dept(t, x, y), not Dept (cid:48)(t, x, y, d).

Notice that violations of the inclusion dependency that may arise from deletions
from Course are being repaired through deletions from Dept. The only stable
(cid:3)
model of this program corresponds to the repair in Example 16.

Notice that the deﬁnition of actual cause under ICs opens the ground for
a deﬁnition of a notion of underlying (hidden, latent) cause. In Example 15, τ1
could be such a cause. It is not strictly an actual cause, but it has to appear
in every minimal contingency set. Similarly, Example 16 shows that τ1 has to
appear in the diﬀerence between the original instance and every minimal repair.

7 Measuring Database Inconsistency and ASPs

A database D is expected to satisfy a given set of integrity constraints (ICs), Σ,
that come with the database schema. However, databases may be inconsistent
in that those ICs are not satisﬁed. A natural question is: To what extent, or
how much inconsistent is D w.r.t. Σ, in quantitative terms?. This problem
is about deﬁning a global numerical score for the database, to capture its “de-
gree of inconsistency”. This number can be interesting per se, as a measure of
data quality (or a certain aspect of it), and could also be used to compare two
databases (for the same schema) w.r.t. (in)consistency.

Scores for individual tuples in relation to their contribution to inconsistency
can be obtain through responsibility scores for query answering, because every
IC gives rise to a violation view; and a tuple contained in it can be scored. Also
Shapley values can be applied (c.f. Section 8; see also [31]).

Inconsistency measures have been introduced and investigated in knowledge
representation, but mainly for propositional theories; and, in the ﬁrst-order case
through grounding. In databases, it is more natural to consider the diﬀerent
nature of the combination of a database, as a structure, and ICs, as a set of
ﬁrst-order formulas. It is also important to consider the asymmetry: databases
are inconsistent or not, not the combination. Furthermore, the relevant issues
that are usually related to data management have to do with algorithms and
computational complexity; actually, in terms of the database and its size. Notice
that ICs are usually few and ﬁxed, whereas databases can be huge.

In [7], a particular and natural inconsistency measure (IM) was introduced
and investigated. Maybe more important than the particular measure, the re-
search program to be developed around such an IM is particularly relevant. More
speciﬁcally, the measure was inspired by one used for functional dependencies
(FDs), and reformulated and generalized in terms of a class of database repairs.
In addition to algorithms, complexity results, approximations for hard cases of
IM computation, and the dynamics of the IM under updates, ASPs were pro-
posed for the computation of this measure. We concentrate on this part in the
rest of this section. We use the notions and notation introduced in Section 4.1
and its Example 7.

25

For a database D and a set of denial constraints Σ (this is not essential, but
to ﬁx ideas), we have the classes of subset-repairs (or S-repairs), and cardinality-
repairs (or C-repairs), denoted Srep(D, Σ) and Crep(D, Σ), resp. The following
IMs are introduced:

inc-degS(D, Σ) :=

|D| − max {|D(cid:48)|

inc-degC(D, Σ) :=

|D| − max {|D(cid:48)|

: D(cid:48) ∈ Srep(D, Σ)}
|D|
: D(cid:48) ∈ Crep(D, Σ)}
|D|

,

.

We can see that it is good enough to concentrate on inc-degC(D, Σ) since it
gives the same value as inc-degS(D, Σ). Actually, to compute it, one C-repair
is good enough. It is clear that 0 ≤ inc-degC(D, Σ) ≤ 1, with value 0 when D
consistent. Notice that one could use other repair semantics instead of C-repairs
[7].

Example 18. (example 7 cont.) Here, Srep(D, Σ) = {D1, D2} and Crep(D, Σ) =
{D1}. It holds: inc-degS(D, Σ) = 4−|D1|

4 = inc-degC(D, Σ) = 4−|D1|

4 = 1
4 .

(cid:3)

The complexity of computing inc-degC(D, Σ) for DCs belongs to FP NP(log(n)),

in data complexity. Furthermore, there is a relational schema and a set of DCs
Σ for which computing inc-degC(D, Σ) is FP NP(log(n))-complete.

It turns out that complexity and eﬃcient computation results can be obtained
via C-repairs, and we end up confronting graph-theoretic problems. Actually, C-
repairs are in one-to-one correspondence with maximum-size independent sets
in hypergraphs [32].

Example 19. Consider the database D = {A(a), B(a), C(a), D(a), E(a)}, which
is inconsistent w.r.t. the set of DS:

Σ = {¬∃x(B(x) ∧ E(x)), ¬∃x(B(x) ∧ C(x) ∧ D(x)), ¬∃x(A(x) ∧ C(x))}.

We obtain the following conﬂict hyper-graph (CHG), where tuples are the

nodes, and a hyperedge connects tuples that together violate a DC:

sets:

S-repairs are maximal

indepen-
D1 = {B(a), C(a)},
dent
D2 = {C(a), D(a), E(a)},
D3 =
{A(a), B(a), D(a)}; and the C-repairs
(cid:3)
are D2, D3.

There is a connection between C-repairs and hitting-sets (HS) of the hyper-
edges of the CHG: The removal from D of the vertices in a minimum-size HS
produces a C-repair. The connections between hitting-sets in hypergraphs and

26

E(a)B(a)C(a)A(a)D(a)C-repairs can be exploited for algorithmic purposes, and to obtain complexity
and approximation results [7].

It turns out that the IM can be computed via ASPs, and not surprisingly by

now, via speciﬁcation of C-repairs.

Example 20.
tids)

(example 13 cont.) Consider the following DC and database (with

κ :

¬∃x∃y(S(x) ∧ R(x, y) ∧ S(y)),

D = {R(1, a, b), R(2, c, d), R(3, b, b), S(4, a), S(5, c), S(6, b)}.

The repair-ASP specifying C-repairs contains the DB D, plus the rules:

S(cid:48)(t1, x, d) ∨ R(cid:48)(t2, x, y, d) ∨ S(cid:48)(t3, y, d) ← S(t1, x), R(t2, x, y), S(t3, y),

S(cid:48)(t, x, s) ← S(t, x), not S(cid:48)(t, x, d),
R(cid:48)(t, x, y, s) ← R(t, x, y), not R(cid:48)(t, x, y, d),

and weak program constraints (c.f. Example 10):

:∼ R(¯x), R(cid:48)(¯x, d),
:∼ S(¯x), S(cid:48)(¯x, d).

With them, we keep the models that minimize the number of deleted tuples.
The C-repair D1 is represented by the model

M1 = {R(cid:48)(1, a, b, s), R(cid:48)(2, c, d, s), R(cid:48)(3, b, b, s), S(cid:48)(4, a, s), S(cid:48)(5, c, s), S(cid:48)(6, b, d), . . .}.

Now, the IM can be computed via |D (cid:114) D(cid:48)|

for some (or any) C-repair D(cid:48).

In this case, D1.

With a system like DLV-Complex, we can specify this set diﬀerence and
compute its cardinality as a simple aggregation. More precisely, we add to the
program above the rules:

Del (t) ← S(cid:48)(t, x, d),
Del (t) ← R(cid:48)(t, x, y, d),

NumDel (n) ← #count{t : Del(t)} = n.

The ﬁrst two rules collect the tids of deleted tuples. The value for NumDel
deﬁned by the third rule is the number of deleted tuples (that already takes a
minimum due to the weak constraints). This number is all we need to compute
the IM. All the models, corresponding to C-repairs, will return the same number.
For this reason, there is no need to explicitly compute all stable models, their
sizes, and compare them. Actually, this value can be obtained by means of a
query posed to the program: “:− NumDel (x)?”, that can be answered under
the brave semantics (returning answers that hold in some of the stable models).
In [7, Appendix A] one can ﬁnd an extended example that uses DLV-Complex
(cid:3)
[15, 16] for this computation.

27

8 The Shapley Value in Databases

The Shapley value was proposed in game theory by Lloyd Shapley in 1953 [45],
to quantify the contribution of a player to a coalition game where players share
a wealth function.3 It has been applied in many disciplines. In particular, it
has been investigated in computer science under algorithmic game theory [40],
and it has been applied to many and diﬀerent computational problems. The
computation of the Shapley value is, in general, intractable. In many scenarios
where it is applied its computation turns out to be #P -hard [22, 21]. Here, the
class #P contains the problems of counting the solutions for problems in NP . A
typical problem in the class, actually, hard for the class, is #SAT , about counting
the number of satisfying assignments for a propositional formula. Clearly, this
problem cannot be easier than SAT , because a solution for #SAT immediately
gives a solution for SAT [1].

In particular, the Shapley value has been used in knowledge representation,
to measure the degree of inconsistency of a propositional knowledge base [28];
in machine learning to provide explanations for the outcomes of classiﬁcation
models on the basis of numerical scores assigned to the participating feature
values [35] (c.f. Section 13); and in data management to measure the contribution
of a tuple to a query answer [30], which we brieﬂy review in this section.

Consider a set of players D, and a game function, G : P(D) → R, where

P(D) the power set of D. The Shapley value of player p in D es deﬁned by:

Shapley(D, G, p) :=

(cid:88)

S⊆D\{p}

|S|!(|D| − |S| − 1)!
|D|!

(G(S ∪ {p}) − G(S)).

(16)

Notice that here, |S|!(|D| − |S| − 1)! is the number of permutations of D with all
players in S coming ﬁrst, then p, and then all the others. That is, this quantity
is the expected contribution of player p under all possible additions of p to a
partial random sequence of players followed by a random sequence of the rests
of the players. Notice the counterfactual ﬂavor, in that there is a comparison
between what happens having p vs. not having it. The Shapley value is the only
function that satisﬁes certain natural properties in relation to games. So, it is a
result of a categorical set of axioms or conditions [43].

Back to query answering in databases, the players are tuples in the database
D. We also have a Boolean query Q, which becomes a game function, as follows:
For S ⊆ D,

Q(S) =

(cid:26) 1 if S |= Q,
0 if S (cid:54)|= Q.

With these elements we can deﬁne the Shapley value of a database tuple τ :

Shapley(D, Q, τ ) :=

(cid:88)

S⊆D\{τ }

|S|!(|D| − |S| − 1)!
|D|!

(Q(S ∪ {τ }) − Q(S)).

3 The original paper and related ones on the Shapley value can be found in the book
edited by Alvin Roth [43]. Shapley and Roth shared the Nobel Prize in Economic
Sciences 2012.

28

If the query is monotone, i.e. its set of answers never shrinks when new tuples
are added to the database, which is the case of conjunctive queries (CQs), among
others, the diﬀerence Q(S ∪ {τ }) − Q(S) is always 1 or 0, and the average in
the deﬁnition of the Shapley value returns a value between 0 and 1. This value
quantiﬁes the contribution of tuple τ to the query result. It was introduced and
investigated in [30], for BCQs and some aggregate queries deﬁned over CQs. We
report on some of the ﬁndings in the rest of this section. The analysis has been
extended to queries with negated atoms in CQs [41].

A main result obtained in [30] is about the complexity of computing this
Shapley score. The following Dichotomy Theorem holds: For Q a BCQ with-
out self-joins, if Q is hierarchical, then Shapley(D, Q, τ ) can be computed in
polynomial-time (in the size of D); otherwise, the problem is #P -complete.

Here, Q is hierarchical if for every two existential variables x and y, it
(a) Atoms(x) ⊆ Atoms(y), or Atoms(y) ⊆ Atoms(x), or Atoms(x) ∩
holds:
Atoms(y) = ∅. For example, Q : ∃x∃y∃z(R(x, y) ∧ S(x, z)), for which Atoms(x)
= {R(x, y), S(x, z)}, Atoms(y) = {R(x, y)}, Atoms(z) = {S(x, z)}, is hier-
archical. However, Qnh : ∃x∃y(R(x) ∧ S(x, y) ∧ T (y)), for which Atoms(x) =
{R(x), S(x, y)}, Atoms(y) = {S(x, y), T (y)}, is not hierarchical.

These are the same criteria for (in)tractability that apply to evaluation of
BCQs over probabilistic databases [47]. However, the same proofs do not apply,
at least not straightforwardly. The intractability result uses query Qnh above,
and a reduction from counting independent sets in a bipartite graph.

The dichotomy results can be extended to summation over CQs, with the
same conditions and cases. This is because the Shapley value, as an expectation,
is linear. Hardness extends to aggregates max, min, and avg over non-hierarchical
queries.

For the hard cases, there is, as established in [30], an approximation result:
For every ﬁxed BCQ Q (or summation over a CQ), there is a multiplicative
fully-polynomial randomized approximation scheme (FPRAS) [1], A, with

P (τ ∈ D |

Shapley(D, Q, τ )
1 + (cid:15)

≤ A(τ, (cid:15), δ) ≤ (1 + (cid:15))Shapley(D, Q, τ )}) ≥ 1 − δ.

A related and popular score, in coalition games and other areas, is the
Bahnzhaf Power Index, which is similar to the Shapley value, but the order
of players is ignored, by considering subsets of players rather than permutations
thereof. It is deﬁned by:

Banzhaf (D, Q, τ ) :=

1
2|D|−1

·

(cid:88)

(Q(S ∪ {τ }) − Q(S)).

S⊆(D\{τ })

The Bahnzhaf-index is also diﬃcult to compute; provably #P-hard in general.
The results in [30] carry over to this index when applied to query answering. In
[30] it was proved that the causal-eﬀect score of Section 3.2 coincides with the
Banzhaf-index, which gives to the former an additional justiﬁcation.

29

9 Score-Based Explanations for Classiﬁcation

Let us consider, as in Figure 2, a classiﬁer, C, that receives as input the repre-
sentation of a entity, e = (cid:104)x1, . . . , xn(cid:105), as a record of feature values, and returns
as an output a label, L(e), corresponding to the classiﬁcation of input e. In prin-
ciple, we could see C as a black-box, in the sense that only by direct interaction
with it, we have access to its input/output relation. That is, we may have no
access to the mathematical classiﬁcation model inside C.

Fig. 2. A black-box classiﬁer

To simplify the presentation, we will assume that the classiﬁer is binary, that
is, for every entity e, L(e) takes one of two possible values, e.g. in {0, 1}. For
example, a client of a ﬁnancial institution requests a loan, but the classiﬁer, on
the basis of his/her feature values (e.g. for EdLevel, Income, Age, etc.) assigns
the label 1, for rejection. An explanation may be requested by the client, in-
dependently from the kind of classiﬁer that is being used. The latter could be
an explicit classiﬁcation model, e.g. a classiﬁcation tree or a logistic regression
model. In these cases, we might be in a better position to given an explanation,
because we can inspect the internals of the model [42]. However, we will put
ourselves in the “worst scenario” in which we do not have access to the internal
model. That is, we are confronted to a black-box classiﬁer.

An approach to explanations that has become popular, specially in the ab-
sence of the model, assigns numerical scores to the feature values for an entity,
trying to answer the question about which of the feature values contribute the
most to the received label.

Example 21. Reusing a popular example from [38], let us consider the set of
features F = {Outlook, Humidity, Wind}, with Dom(Outlook) = {sunny, overcast,
rain}, Dom(Humidity) = {high, normal}, Dom(Wind) = {strong, weak}. An en-
tity under classiﬁcation has a value for each of the features, e.g. e = ent(sunny,
normal, weak), and represents a particular weather condition. The problem con-
sists in deciding about playing tennis or not under the conditions represented by
that entity, which can be captured as a classiﬁcation problem, with labels “yes”
or “no”.

30

eL(e)CFig. 3. A Decision Tree

In this case, the binary classiﬁer is given as a decision-tree, as shown in Figure
3. It could be displayed by double-clicking on the black box in Figure 2. The
decision is computed by following the feature values along the branches of the
(cid:3)
tree. The entity e at hand gets label yes.

Score-based methodologies are sometimes based on counterfactual interven-
tions: What would happen with the label if we change this particular value,
leaving the others ﬁxed? Or the other way around: What if we leave this value
ﬁxed, and change the others? The resulting labels from these counterfactual in-
terventions can be aggregated in diﬀerent ways, leading to a score for the feature
value under inspection.

A be more concrete, we can use the previous example, to detect and quan-
tify the relevance (technically, the responsibility) of a feature value in e =
ent(sunny, normal, weak), say for feature Humidity (underlined), by hypothetically
intervening its value. In this case, if we change it from normal to high, we obtain a
new entity e(cid:48) = ent(sunny, high, weak), a counterfactual version of e. If we input
this entity into the classiﬁer, we now obtain the label no. This is an indication
that the original feature value for Humidity is indeed relevant for the original
classiﬁcation.

In the next two sections we brieﬂy introduce two scores. Both can be applied
with open-box or black-box models.
In both cases, we consider a ﬁnite set of
features F, with each feature F ∈ F having a ﬁnite domain, Dom(F ), where F ,
as function, takes its values. The features are applied to entities e in a population
E of them. Actually, we identify the entity e with the record (or tuple) formed
by the values the features take on it: e = (cid:104)F1(e), . . . , Fn(e)(cid:105). Now, entities
in E go through a binary classiﬁer, C, that returns labels for them. We will
assume the labels are 1 or 0. For example, the bank could have a classiﬁer that
automatically decides, for an entity, if it is worthy of a loan (0) or not (1).

10 The x-Resp Score

Assume that an entity e has received the label 1 by the classiﬁer C, and we want
to explain this outcome by assigning numerical scores to e’s feature values, in

31

CHAPTER 3 DECISION TREE LEARNING 53 Noma1 Strong Weak No \ Yes / No \ Yes FIGURE 3.1 A decision tree for the concept PlayTennis. An example is classified by sorting it through the tree to the appropriate leaf node, then returning the classification associated with this leaf (in this case, Yes or No). This tree classifies Saturday mornings according to whether or not they are suitable for playing tennis. from that node corresponds to one of the possible values for this attribute. An instance is classified by starting at the root node of the tree, testing the attribute specified by this node, then moving down the tree branch corresponding to the value of the attribute in the given example. This process is then repeated for the subtree rooted at the new node. Figure 3.1 illustrates a typical learned decision tree. This decision tree clas- sifies Saturday mornings according to whether they are suitable for playing tennis. For example, the instance (Outlook = Sunny, Temperature = Hot, Humidity = High, Wind = Strong) would be sorted down the leftmost branch of this decision tree and would therefore be classified as a negative instance (i.e., the tree predicts that PlayTennis = no). This tree and the example used in Table 3.2 to illustrate the ID3 learning algorithm are adapted from (Quinlan 1986). In general, decision trees represent a disjunction of conjunctions of con- straints on the attribute values of instances. Each path from the tree root to a leaf corresponds to a conjunction of attribute tests, and the tree itself to a disjunc- tion of these conjunctions. For example, the decision tree shown in Figure 3.1 corresponds to the expression (Outlook = Sunny A Humidity = Normal) V (Outlook = Overcast) v (Outlook = Rain A Wind = Weak) such a way, that a higher score for a feature value reﬂects that it has been im-
portant for the outcome. We do this now using the x-Resp score, whose deﬁnition
we illustrate by means of an example (c.f. [10, 11] for detailed treatments). For
simplicity and for the moment, we will assume the features are also binary, i.e.
they propositional, taking the values true or false (or 1 and 0, resp.) In Section
12, we consider a more general case.

Fig. 4. Classiﬁed entity and its counterfactual versions

Example 22. In Figure 4, the black box is the classiﬁer C. An entity e has gone
through it obtaining label 1, shown in the ﬁrst row in the ﬁgure. We want
to assign a score to the feature value x for a feature F ∈ F. We proceed,
counterfactually, changing the value x into x(cid:48), obtaining a counterfactual version
e1 of e. We classify e1, and we still get the outcome 1 (second row in the ﬁgure).
In between, we may counterfactually change other feature values, y, z in e, into
y(cid:48), z(cid:48), but keeping x, obtaining entity e2, and the outcome does not change (third
row). However, if we change in e2, x into x(cid:48), the outcome does change (fourth
row).

This shows that the value x is relevant for the original output, but, for this
outcome, it needs company, say of the feature values y, z in e. Proceeding as in
actual causality as applied to tuples in a database in relation to query answering
(c.f. Section 3.1), we can say that the feature value x in e is an actual cause for
the classiﬁcation, that needs a contingency set formed by the values y, z in e. In
this case, the contingency set has size 2. If we found a contingency set for x of
(cid:3)
size 1 in e, we would consider x even more relevant for the output.

On this basis, we can deﬁne [10, 11]: (a) x is a counterfactual explanation
x(cid:48) ) = 0, for some x(cid:48) ∈ Dom(F ) (the domain of feature F ).
x(cid:48) for the entity obtained by replacing x
(b) x is an actual explanation for L(e) = 1 if there is a set of
Y(cid:48) ) = 1

for L(e) = 1 if L(e x
(Here we use the common notation e x
by x(cid:48) in e.)
values Y in e, with x /∈ Y, and new values Y(cid:48) ∪ {x(cid:48)}, such that L(e Y
and L(e xY

x(cid:48)Y(cid:48) ) = 0.

32

-xe1x’1---xy’z’1z’y’x’0{z,y} contingency set for xxactual cause for 1zyzyContingency sets may come in sizes from 0 to n − 1 for feature values in
records of length n. Accordingly, we can deﬁne for the actual cause x: If Y is
a minimum-size contingency set for x, x-Resp(x) := 1
1+|Y| ; and as 0 when x is
not an actual cause.

We will reserve the notion of counterfactual explanation for (or counterfac-
tual version of ) an input entity e for any entity e(cid:48) obtained from e by modifying
feature values in e and that leads to a diﬀerent label, i.e. L(e) (cid:54)= L(e(cid:48)). Notice
that from such an e(cid:48) we can read oﬀ actual causes for L(e) as feature values,
and contingency sets for those actual causes. It suﬃces to compare e with e(cid:48).

In Section 11 we give a detailed example that illustrates these notions, and
also show the use of ASPs for the speciﬁcation and computation of counterfactual
versions of a given entity, and the latter’s x-Resp score.

11 Counterfactual-Intervention Programs

Together with illustrating the notions introduced in Section 10, we will introduce,
by means of an example, Counterfactual Intervention Programs (CIPs). They
are ASPs that specify the counterfactual versions of a given entity, and also,
if so desired, only the maximum-responsibility counterfactual explanations, i.e.
counterfactual versions that lead to a maximum x-Resp score. See [11] for many
more details and examples.

Example 23. (example 21 continued) We present now the CIP for the classi-
ﬁer based on the decision-tree, in DLV-Complex notation. We use annotation
constants o, for “original entity”, do, for “do a counterfactual intervention” (a
single change of feature value), tr, for “entity in transition”, and s, for “stop,
the label has changed”. We explain the program as we present it, and also by
inserting comments in the DLV code.

Notice that after the facts, that include the domains and the input entity,
we ﬁnd the rule-based speciﬁcation of the decision tree. The ent predicate, for
“entity”, uses an entity identiﬁer (eid) in its ﬁrst argument.

% facts:

dom1(sunny). dom1(overcast). dom1(rain). dom2(high). dom2(normal).
dom3(strong). dom3(weak).
ent(e,sunny,normal,weak,o).

% original entity at hand

% specification of the decision-tree classifier:

cls(X,Y,Z,1) :- Y = normal, X = sunny, dom1(X), dom3(Z).
cls(X,Y,Z,1) :- X = overcast, dom2(Y), dom3(Z).
cls(X,Y,Z,1) :- Z = weak, X = rain, dom2(Y).
cls(X,Y,Z,0) :- dom1(X), dom2(Y), dom3(Z), not cls(X,Y,Z,1).

% transition rules: the initial entity or one affected by a value change

ent(E,X,Y,Z,tr) :- ent(E,X,Y,Z,o).
ent(E,X,Y,Z,tr) :- ent(E,X,Y,Z,do).

33

% counterfactual rule: alternative single-value changes

ent(E,Xp,Y,Z,do) v ent(E,X,Yp,Z,do) v ent(E,X,Y,Zp,do) :-

ent(E,X,Y,Z,tr), cls(X,Y,Z,1), dom1(Xp), dom2(Yp),
dom3(Zp), X != Xp, Y != Yp, Z!= Zp,
chosen1(X,Y,Z,Xp), chosen2(X,Y,Z,Yp),
chosen3(X,Y,Z,Zp).

In this rule’s body we ﬁnd the “choice operator”. It is a predicate (to de
deﬁned next in the program), say chosen 1(x, y, z, x(cid:48)), that, for each combination
of values (x, y, z) “chooses” a single value for x(cid:48). This new value can be used to
replace a value in the ﬁrst argument of the entity. Similarly for chosen 2(x, y, z, y(cid:48))
and chosen 3(x, y, z, z(cid:48)). They can be deﬁned by means of the next rules in the
program [25].

% definitions of "chosen" predicates:

chosen1(X,Y,Z,U) :- ent(E,X,Y,Z,tr), cls(X,Y,Z,1), dom1(U), U != X,

not diffchoice1(X,Y,Z,U).

diffchoice1(X,Y,Z, U) :- chosen1(X,Y,Z, Up), U != Up, dom1(U).
chosen2(X,Y,Z,U) :- ent(E,X,Y,Z,tr), cls(X,Y,Z,1), dom2(U), U != Y,

not diffchoice2(X,Y,Z,U).

diffchoice2(X,Y,Z, U) :- chosen2(X,Y,Z, Up), U != Up, dom2(U).
chosen3(X,Y,Z,U) :- ent(E,X,Y,Z,tr), cls(X,Y,Z,1), dom3(U), U != Z,

diffchoice3(X,Y,Z, U) :- chosen3(X,Y,Z, Up), U != Up, dom3(U).

not diffchoice3(X,Y,Z,U).

% Not going back to initial entity (program constraint):

:- ent(E,X,Y,Z,do), ent(E,X,Y,Z,o).

The last rule is a (hard) program constraint that avoids going back to the
initial entity by performing value changes. This constraint makes the ASP eval-
uation engine discard those models where this happen [29].

% stop when label has been changed:

ent(E,X,Y,Z,s) :- ent(E,X,Y,Z,do), cls(X,Y,Z,0).

% collecting changed values for each feature:

expl(E,outlook,X)
expl(E,humidity,Y)
expl(E,wind,Z)

:- ent(E,X,Y,Z,o), ent(E,Xp,Yp,Zp,s), X != Xp.
:- ent(E,X,Y,Z,o), ent(E,Xp,Yp,Zp,s), Y != Yp.
:- ent(E,X,Y,Z,o), ent(E,Xp,Yp,Zp,s), Z != Zp.

entAux(E) :- ent(E,X,Y,Z,s).

:- ent(E,X,Y,Z,o), not entAux(E).

% auxiliary predicate to
% avoid unsafe negation
% in the constraint below
% discard models where
% label does not change

% computing the inverse of x-Resp:

invResp(E,M) :- #count{I: expl(E,I,_)} = M, #int(M), E = e.

34

The last rule returns, for a given entity, the number of values that have been
changed in order to reach a counterfactual version of that entity. The inverse of
this value can be used to compute a x-Resp score (the

1+|Y| in Section 12).

1

Two counterfactual versions of e are obtained, as represented by the two
essentially diﬀerent stable models of the program, and determined by the atoms
with the annotation s (below, we keep in them only the most relevant atoms,
omitting initial facts and choice-related atoms):

{ent(e,sunny,normal,weak,o), cls(sunny,normal,strong,1),
cls(sunny,normal,weak,1), cls(overcast,high,strong,1),
cls(overcast,high,weak,1), cls(rain,high,weak,1),
cls(overcast,normal,weak,1), cls(rain,normal,weak,1),
cls(overcast,normal,strong,1), cls(sunny,high,strong,0),
cls(sunny,high,weak,0), cls(rain,high,strong,0),
cls(rain,normal,strong,0), ent(e,sunny,high,weak,do),
ent(e,sunny,high,weak,tr), ent(e,sunny,high,weak,s),
expl(e,humidity,normal),invResp(e,1)}

{ent(e,sunny,normal,weak,o), cls(sunny,normal,strong,1),...,

cls(rain,normal,strong,0), ent(e,rain,normal,strong,do),
ent(e,rain,normal,strong,tr), ent(e,rain,normal,strong,s),
expl(e,outlook,sunny), expl(e,wind,weak), invResp(e,2)}

The ﬁrst model shows the classiﬁers as a set of atoms, and, in its second last
line, that ent(e,sunny,high,weak,s) is a counterfactual version (with label 0)
of the original entity e, and is obtained from the latter by means of changes of val-
ues in feature Humidity, leading to an inverse score of 1. The second model shows
a diﬀerent counterfactual version of e, namely ent(e,rain,normal,strong,s),
now obtained by changing values for features Outlook and Wind, leading to an
inverse score of 2.

Let us now add, at the end of the program the following weak constraints:

% Weak constraints to minimize number of changes:
:~ ent(E,X,Y,Z,o), ent(E,Xp,Yp,Zp,s), X != Xp.
:~ ent(E,X,Y,Z,o), ent(E,Xp,Yp,Zp,s), Y != Yp.
:~ ent(E,X,Y,Z,o), ent(E,Xp,Yp,Zp,s), Z != Zp.

(*)

If we run the program with them, the number of changes is minimized, and we
basically obtain only the ﬁrst model above, corresponding to the counterfactual
entity e(cid:48) = ent(sunny, high, weak). This is a maximum-responsibility counterfac-
(cid:3)
tual explanation.

As can be seen at the light of this example, more complex rule-based classiﬁers
could be deﬁned inside a CIP. It is also possible to invoke the classiﬁer as an
external predicate [11].

11.1 Bringing-in domain knowledge

The CIP-based speciﬁcations we have considered so far allow all kinds of coun-
terfactual interventions on feature values. However, this may be undesirable or

35

unrealistic in certain applications. For, example, we may not end up producing,
and even less, using for score computation, some entities representing people who
have the combination of values yes and yes for the propositional features Married
and YoungerThan5. Declarative approaches to speciﬁcation and computation of
counterfactual explanations have the nice feature that domain knowledge and
semantic constraints can be easily integrated with the base speciﬁcation. Pro-
cedural approaches may, most likely, require changing the underlying code. We
use an example to illustrate the point. For more details and a discussion see [11].

Example 24. (example 23 continued) It could be that in a particular geographic
region, “raining with a strong wind at the same time” is never possible. When
producing counterfactual interventions for the entity e, such a combination
should not be produced or considered.

This can be done by imposing a hard program constraint

% hard constraint disallowing a particular combination

:- ent(E,rain,X,strong,tr).

that we add to the program in Example 23, from which we previously remove
the weak constraints we had in (*) (in order not to discard any model for
cardinality reasons).
If we run the new program with DLV, we obtain only
the ﬁrst model in Example 23, corresponding to the counterfactual entity e(cid:48) =
(cid:3)
ent(sunny, high, weak).

12 The Generalized Resp Score

If we want to assign a numerical score to a feature value, say v = F (e), where
F has a relatively large domain, Dom(F ), it could be the case that counterfac-
tually changing v into v(cid:48) ∈ Dom(F ) changes the label (while leaving the other
feature values ﬁxed). However, it could be that for nearly all the other values in
Dom(F )(cid:114){v, v(cid:48)}, the label does not change. In this case, we might consider that
maybe v is not such a strong reason for the originally obtained label, despite
the fact that v is still a counterfactual explanation (with empty contingency set)
according to Section 10.

For this reason, it might be better to consider all the possible alternative
values for F , and deﬁne and compute the score in terms of an average of the
label values, or an expected value for the label in case we have an underlying
probability distribution P on the entity population E. Such a general version
of the x-Resp score was introduced and investigated in [9]. We brieﬂy describe
it starting with the simpler case of counterfactual explanations, i.e. without
considering contingency sets. Next, we further generalize the score to consider
the latter. So, in the following, the features do not have to be binary.

Assume that entity e has gone through a classiﬁer and we have obtained
label 1, which we would like to explain. Then, for a feature F (cid:63) ∈ F, we may
consider as a score:

Counter(e, F (cid:63)) := L(e) − E(L(e(cid:48)) | e(cid:48)

F(cid:114){F (cid:63) } = eF(cid:114){F (cid:63)} ).

(17)

36

Here, eS , for S ⊆ F is the entity e restricted to the features in S. This score
measures the expected diﬀerence between the label for e and those for entities
that coincide in feature values everywhere with e but on feature F (cid:63). Notice the
essential counterfactual nature of this score, which is reﬂected in all the possible
hypothetical changes of values for F (cid:63) in e.

A problem with Counter is that changing a single value, no matter how, may
not switch the original label, in which case no explanations are obtained. In order
to address this problem, we can bring in contingency sets of feature values, which
leads to the Resp score introduced in [9].

Again, consider e ∈ E, an entity under classiﬁcation, for which L(e) = 1, and

a feature F (cid:63) ∈ F. Assume we have:
1. Γ ⊆ F (cid:114) {F (cid:63)}, a set of features that may end up accompanying feature

F (cid:63).

2. ¯w = (wF )F ∈Γ , wF ∈ Dom(F ), wF (cid:54)= eF , i.e. new values for features in Γ .
3. e(cid:48) := e[Γ := ¯w], i.e. reset e’s values for Γ as in ¯w.
4. L(e(cid:48)) = L(e) = 1, i.e. there is no label change with ¯w (but maybe with an

extra change for F (cid:63), in next item).

5. There is v ∈ Dom(F (cid:63)), with v (cid:54)= F (cid:63)(e) and e(cid:48)(cid:48) := e[Γ := ¯w, F (cid:63) := v].

if L(e) (cid:54)= L(e(cid:48)(cid:48)) = 0, F (cid:63)(e) is an actual causal explanation
As in Section 10,
for L(e) = 1, with “contingency set” (cid:104)Γ, eΓ (cid:105), where eΓ is the projection of e on
Γ .

In order to deﬁne the “local” responsibility score, make v vary randomly

under conditions 1.-5.:

Resp(e, F (cid:63), Γ, ¯w) :=

L(e(cid:48)) − E[L(e(cid:48)(cid:48)) | e(cid:48)(cid:48)

F (cid:114){F (cid:63)} = e(cid:48)

F (cid:114){F (cid:63)}]

1 + |Γ |

.

(18)

If, as so far, label 1 is what has to be explained, then L(e(cid:48)) = 1, and the
numerator is a number between 0 and 1. Here, Γ is ﬁxed. Now, we can minimize
its size, obtaining the (generalized) responsibility score as the maximum local
value; everything relative to distribution P :

Respe,F (cid:63) (F (cid:63)(e)) := max Resp(e, F (cid:63), Γ, ¯w)

(19)

|Γ | min., (18) > 0

(cid:104)Γ, ¯w(cid:105) |= 1.−4.

This score was introduced in [9], where experiments and comparisons with other
scores, namely Shap (c.f. Section 13) and the FICO score [18], are shown. Fur-
thermore, diﬀerent probability distributions are considered. Notice that, in order
to compute this score, there is no need to access the internals of the classiﬁcation
model.

13 The Shap Score

In the context of classiﬁcation, the Shapley value (c.f. Section 8) has taken
the form of the Shap score [34], which we brieﬂy introduce. Given the binary

37

classiﬁer, C, on binary entities, it becomes crucial to identify a suitable game
function. In this case, it will be expressed in terms of expected values (not unlike
the causal-eﬀect score), which requires an underlying probability space on the
population of entities, E. We will consider, to ﬁx ideas, the uniform probability
space on E. Since we will consider only binary feature values, taking values 0 or 1,
this is the uniform distribution on E = {0, 1}n, assigning probability P u(e) = 1
2n
to e ∈ E. One could consider other distributions [9, 3].

Given a set of features F = {F1, . . . , Fn}, and an entity e whose label is to be
explained, the set of players D in the game is F(e) := {F (e) | F ∈ F}, i.e. the
set of feature values of e. Equivalently, if e = (cid:104)x1, . . . , xn(cid:105), then xi = Fi(e). We
assume these values have implicit feature identiﬁers, so that duplicates do not
collapse, i.e. |F(e)| = n. The game function is deﬁned as follows. For S ⊆ F(e),

Ge(S) := E(L(e(cid:48)) | e(cid:48)

S = eS),

where eS: is the projection of e on S. This is the expected value of the label
for entities e(cid:48) when their feature values are ﬁxed and equal to those in S for e.
Other than that, the feature values of e(cid:48) may independently vary over {0, 1}.

Now, one can instantiate the general expression for the Shapley value in (16),
using this particular game function, as Shapley(F(e), Ge, F (e)), obtaining, for a
particular feature value F (e):

Shap(F(e), Ge, F (e)) :=

(cid:88)

S⊆F (e)\{F (e)}

|S|!(n − |S| − 1)!
n!

×

(E(L(e(cid:48)|e(cid:48)

S∪{F (e)} = eS∪{F (e)}) − E(L(e(cid:48))|e(cid:48)

S = eS)).

Here, the label L acts as a Bernoulli random variable that takes values through
the classiﬁer. We can see that the Shap score is a weighted average of diﬀerences
of expected values of the labels [34]. We may notice that counterfactual versions
of the initial entity are implicitly considered.

The Shap score can be applied with black-box classiﬁers. Under those cir-
cumstances its computation takes exponential time in that all permutations of
subsets of features are involved. However, sometimes, when the classiﬁer is explic-
itly available, the computation cost can be brought down, even to polynomial
time. This is the case for several classes of Boolean circuits that can be used
as classiﬁers, and in particular, for decision trees [34, 3, 48]. For other explicit
Boolean circuit-based classiﬁers, the computation of Shap is still #P -hard [3, 48].

14 Final Remarks

Explainable data management and explainable AI (XAI) are eﬀervescent areas
of research. The relevance of explanations can only grow, as observed from- and
due to the legislation and regulations that are being produced and enforced in
relation to explainability, transparency and fairness of data management and
AI/ML systems.

38

There are diﬀerent approaches and methodologies in relation to explanations,
with causality, counterfactuals and scores being prominent approaches that have
a relevant role to play. Much research is still needed on the use of contextual,
semantic and domain knowledge. Some approaches may be more appropriate in
this direction, and we argue that declarative, logic-based speciﬁcations can be
successfully exploited [11].

Still fundamental research is needed in relation to the notions of explanation
and interpretation. An always present question is: What is a good explanation?.
This is not a new question, and in AI (and other areas and disciplines) it has
been investigated. In particular in AI, areas such as diagnosis and causality have
much to contribute.

Now, in relation to explanations scores, there is still a question to be an-
swered: What are the desired properties of an explanation score?. The question
makes a lot of sense, and may not be beyond an answer. After all, the general
Shapley value emerged from a list of desiderata in relation to coalition games, as
the only measure that satisﬁes certain explicit properties [45, 43]. Although the
Shapley value is being used in XAI, in particular in its Shap incarnation, there
could be a diﬀerent and speciﬁc set of desired properties of explanation scores
that could lead to a still undiscovered explanation score.

Acknowledgments: L. Bertossi has been a member of the Academic Network
of RelationalAI Inc., where his interest in explanations in ML started. Part
of this work was funded by ANID - Millennium Science Initiative Program -
Code ICN17002. Help from Jessica Zangari and Mario Alviano with information
about DLV2, and from Gabriela Reyes with the DLV program runs is much
appreciated. We are grateful to an anonymous reviewer for valuable comments.

References

[1] Arora, S. and Barak, B. Computational Complexity. Cambridge University Press,

2009.

[2] Arenas, M., Bertossi, L. and Chomicki, J. Consistent Query Answers in Incon-

sistent Databases. In Proc. ACM PODS 1999, pp. 68-79.

[3] Arenas, M., Pablo Barcel´o, P., Bertossi, L. and Monet, M. The Tractability
of SHAP-Scores over Deterministic and Decomposable Boolean Circuits. Proc.
AAAI 2021, pp. 6670-6678.

[4] Bertossi. L. Database Repairing and Consistent Query Answering. Synthesis

Lectures in Data Management. Morgan & Claypool, 2011.

[5] Bertossi, L. and Salimi, B. From Causes for Database Queries to Repairs and
Model-Based Diagnosis and Back. Theory of Computing Systems, 2017, 61(1):191-
232.

[6] Bertossi, L. and Salimi, B. Causes for Query Answers from Databases: Data-
Int. J. Approximate

log Abduction, View-Updates, and Integrity Constraints.
Reasoning, 2017, 90:226-252.

[7] Bertossi, L. Repair-Based Degrees of Database Inconsistency. Proc. LPNMR

2019, Springer LNCS 11481, pp. 195-209.

39

[8] Bertossi, L. Specifying and Computing Causes for Query Answers in Databases
via Database Repairs and Repair Programs. Knowledge and Information Systems,
2021, 63(1):199-231.

[9] Bertossi, L., Li, J., Schleich, M., Suciu, D. and Vagena, Z. Causality-Based
Explanation of Classiﬁcation Outcomes. In Proceedings of the Fourth Workshop on
Data Management for End-To-End Machine Learning, DEEM@SIGMOD 2020,
pages 6:1-6:10, 2020.

[10] Bertossi, L. An ASP-Based Approach to Counterfactual Explanations for Clas-

siﬁcation. In Proc. RuleML-RR 2020, Springer LNCS 12173, pp. 70-81.

[11] Bertossi, L. Declarative Approaches to Counterfactual Explanations for Classiﬁ-

cation. arXiv Paper 2011.07423, 2020. Journal submission after revisions.

[12] Breiman, L., Friedman, J., Stone, C. J. and Olshen,R. A. Classiﬁcation and

Regression Trees. CRC press, 1984.

[13] Brewka, G., Eiter, T. and Truszczynski, M. Answer Set Programming at a Glance.

Commun. ACM, 2011, 54(12):92-103.

[14] Buneman, P., Khanna, S. and Tan, W. C. Why and Where: A Characterization

of Data Provenance. Proc. ICDT, 2001, pp. 316-330.

[15] Calimeri, F., Cozza, S., Ianni, G. and Leone, N. Computable Functions in ASP:
Theory and Implementation. Proc. ICLP 2008, Springer LNCS 5366, pp. 407-424.
[16] Calimeri, F., Cozza, S., Ianni, G. and Leone, N. An ASP System with Functions,

Lists,and Sets. Proc. LPNMR 2009, Springer LNCS 5753, pp. 483-489.

[17] Caniupan, M. and Bertossi, L. The Consistency Extractor System: Answer Set
Programs for Consistent Query Answering in Databases. Data & Knowledge
Engineering, 2010, 69(6):545-572.

[18] Chen, C., Lin, K., Rudin, C., Shaposhnik, Y., Wang, S. and Wang, T. An In-
terpretable Model with Globally Consistent Explanations for Credit Risk. CoRR,
abs/1811.12615, 2018.

[19] Chockler, H. and Halpern, J. Responsibility and Blame: A Structural-Model

Approach. J. Artif. Intell. Res., 2004, 22:93-115.

[20] Dantsin, E., Eiter, T., Gottlob, G. and Voronkov, A. Complexity and Expressive
Power of Logic Programming, ACM Computing Surveys, 2001, 33(3):374-425.
[21] Deng, X. and Papadimitriou, C. On the Complexity of Cooperative Solution

Concepts. Math. Oper. Res., 1994, 19(2):257-266.

[22] Faigle, U. and Kern, W. The Shapley Value for Cooperative Games under Prece-
dence Constraints. International Journal of Game Theory, 1992, 21:249-266.
[23] Gelfond, M. and Lifschitz, V. Classical Negation in Logic Programs and Disjunc-

tive Databases. New Generation Computing, 1991, 9:365-385.

[24] Gelfond, M. and Kahl, Y. Knowledge Representation and Reasoning, and the

Design of Intelligent Agents. Cambridge Univ. Press, 2014.

[25] Giannotti, F., Greco, S., Sacca, D. and Zaniolo, C. Programming with Non-
Determinism in Deductive Databases. Annals of Mathematics in Artiﬁcial Intel-
ligence, 1997, 19(1-2):97-125.

[26] Halpern, J. and Pearl, J. Causes and Explanations: A Structural-Model Ap-
proach. Part I: Causes. The British journal for the philosophy of science, 2005,
56(4):843-887.

[27] Halpern, J. Y. A Modiﬁcation of the Halpern-Pearl Deﬁnition of Causality. In

Proc. IJCAI 2015, pp. 3022-3033.

[28] Hunter, A. and Konieczny, S. On the Measure of Conﬂicts: Shapley Inconsistency

Values. Artif. Intell., 174(14):1007–1026, 2010.

40

[29] Leone, N., Pfeifer, G., Faber, W., Eiter, T., Gottlob, G., Perri, S. and Scarcello, F.
The DLV System for Knowledge Representation and Reasoning. ACM Transac-
tions on Computational Logic, 2006, 7(3):499-562.

[30] Livshits, E., Bertossi, L., Kimelfeld, B. and Sebag, M. The Shapley Value of

Tuples in Query Answering. In Proc. ICDT 2020, pp. 20:1-20:19.

[31] Livshits, E. and Kimelfeld, B. The Shapley Value of Inconsistency Measures for

Functional Dependencies. Proc. ICDT 2021, pp. 15:1-15:19.

[32] Lopatenko, A. and Bertossi, L. Complexity of Consistent Query Answering in
Databases under Cardinality-Based and Incremental Repair Semantics. Proc.
ICDT 2007, Springer LNCS 4353, pp. 179-193.

[33] Lucic, A., Haned, H. and de Rijke, M. Explaining Predictions from Tree-Based

Boosting Ensembles. CoRR, abs/1907.02582, 2019.

[34] Lundberg, S., Erion, G., Chen, H., DeGrave, A., Prutkin, J., Nair, B., Katz, R.,
Himmelfarb, J., Bansal, N. and Lee, S.-I. From Local Explanations to Global
Understanding with Explainable AI for Trees. Nature Machine Intelligence, 2020,
2(1):2522-5839.

[35] Lundberg, S. and Lee, S. A Uniﬁed Approach to Interpreting Model Predictions.
In Proc. Advances in Neural Information Processing Systems, 2017, pp. 4765-4774.
[36] Meliou, A., Gatterbauer, W., Moore, K. F. and Suciu, D. The Complexity of
Causality and Responsibility for Query Answers and Non-Answers. Proc. VLDB
2010, pp. 34-41.

[37] Meliou, A., Gatterbauer, W., Halpern, J.Y., Koch, C., Moore, K. F. and Suciu, D.
Causality in Databases. IEEE Data Engineering Bulletin, 2010, 33(3):59-67.

[38] Mitchell, T. M. Machine Learning. McGraw-Hill, 1997.
[39] Molnar, C. Interpretable Machine Learning: A Guide for Making Black Box Mod-
els Explainable. https://christophm.github.io/interpretable-ml-book, 2020.
[40] Nisan, N., Roughgarden, T., Tardos, E. and Vazirani, V. V. (eds.) Algorithmic

Game Theory. Cambridge University Press, 2007.

[41] Reshef, A., Kimelfeld, B. and Livshits, E. The Impact of Negation on the Com-
plexity of the Shapley Value in Conjunctive Queries. Proc. PODS 2020, pp. 285-
297.

[42] Rudin, C. Stop Explaining Black Box Machine Learning Models for High Stakes
Decisions and Use Interpretable Models Instead. Nature Machine Intelligence,
2019, 1:206-215. Also arXiv:1811.10154,2018.

[43] Roth, A. E. (ed.) The Shapley Value: Essays in Honor of Lloyd S. Shapley.

Cambridge University Press, 1988.

[44] Salimi, B., Bertossi, L., Suciu, D. and Van den Broeck, G. Quantifying Causal
Eﬀects on Query Answering in Databases. Proc. 8th USENIX Workshop on the
Theory and Practice of Provenance (TaPP), 2016.

[45] Shapley, L. S. A Value for n-Person Games. Contributions to the Theory of

Games, 1953, 2(28):307-317.

[46] Struss, P. Model-Based Problem Solving. In Handbook of Knowledge Represen-

tation, Chap. 4. Elsevier, 2008, pp. 395-465.

[47] Suciu, D., Olteanu, D., Re, C. and Koch, C. Probabilistic Databases. Synthesis

Lectures on Data Management, Morgan & Claypool, 2011.

[48] Van den Broeck, G., Lykov, A., Schleich, M. and Suciu, D. On the Tractability

of SHAP Explanations. Proc. AAAI 2021, pp. 6505-6513.

41

