2
2
0
2

r
a

M
9
2

]
h
p
-
t
n
a
u
q
[

2
v
8
3
1
2
0
.
1
0
1
2
:
v
i
X
r
a

Connecting ansatz expressibility to gradient magnitudes and barren plateaus

Zoë Holmes,1 Kunal Sharma,2, 3 M. Cerezo,3, 4 and Patrick J. Coles3
1Information Sciences, Los Alamos National Laboratory, Los Alamos, NM, USA.
2Hearne Institute for Theoretical Physics, Department of Physics and Astronomy,
and Center for Computation and Technology, Louisiana State University, Baton Rouge, Louisiana 70803, USA
3Theoretical Division, Los Alamos National Laboratory, Los Alamos, NM 87545, USA
4Center for Nonlinear Studies, Los Alamos National Laboratory, Los Alamos, NM, USA

Parameterized quantum circuits serve as ansätze for solving variational problems and provide a
ﬂexible paradigm for programming near-term quantum computers. Ideally, such ansätze should be
highly expressive so that a close approximation of the desired solution can be accessed. On the other
hand, the ansatz must also have suﬃciently large gradients to allow for training. Here, we derive
a fundamental relationship between these two essential properties: expressibility and trainability.
This is done by extending the well established barren plateau phenomenon, which holds for ansätze
that form exact 2-designs, to arbitrary ansätze. Speciﬁcally, we calculate the variance in the cost
gradient in terms of the expressibility of the ansatz, as measured by its distance from being a 2-
design. Our resulting bounds indicate that highly expressive ansätze exhibit ﬂatter cost landscapes
and therefore will be harder to train. Furthermore, we provide numerics illustrating the eﬀect of
expressiblity on gradient scalings, and we discuss the implications for designing strategies to avoid
barren plateaus.

I.

Introduction

While quantum hardware is rapidly reaching the stage
where it can outperform classical supercomputers [1], we
remain in the Noisy Intermediate-Scale Quantum (NISQ)
era in which the available devices are relatively small
and prone to errors [2]. Variational quantum algorithms
have gathered attention as a computational strategy that
is well suited to the constraints imposed by NISQ de-
vices [3–20]. In VQAs a problem-speciﬁc cost function
is eﬃciently evaluated on a quantum computer, while a
classical optimizer trains a parameterized quantum cir-
cuit to minimize this cost. The beneﬁt of this paradigm
is that it adapts to the qubit and connectivity constraints
of NISQ devices, while keeping the circuit depth short to
mitigate quantum hardware noise.

Central to the success of VQAs is the construction of a
parameterized quantum circuit, which serves as an ansatz
with which to explore the space of solutions to the target
problem. Some noteworthy ansätze include the quan-
tum alternating operator ansatz [5, 21], coupled cluster
ansatz [22–24], Hamiltonian variational ansatz [25], and
hardware eﬃcient ansatz [26]. To successfully ﬁnd an
optimal solution, the ansatz should ideally be both ex-
pressive and trainable. Speciﬁcally, the ansatz must be
suﬃciently expressive such that it contains a circuit that
well-approximates the optimal solution. Concurrently,
the cost landscape must be suﬃciently featured to be able
to train the parameters to ﬁnd this optimal solution.

Recently, it was shown that VQAs can exhibit barren
plateaus, where under certain conditions the gradient of
the cost function vanishes exponentially with the size of
the system [27–36]. In particular, Ref. [27] demonstrated
that if an ansatz is suﬃciently random that it matches
the uniform distribution of unitaries up to the second mo-
ment (i.e., forms a 2-design), then the variance in the cost
gradient will vanish exponentially with the number of

qubits. Several strategies have been proposed to address
this issue [37–46], such as clever parameter initialization
or ansatz construction, while more research is needed to
test these strategies on various problems.

In broad terms, the expressibility of an ansatz is de-
termined by how uniformly it explores the unitary space.
Thus the distance between the distribution of unitaries
generated by an ansatz and the maximally expressive uni-
form distribution of unitaries is a natural measure of its
expressibility [47]. Using such a measure, Ref. [48] calcu-
lated the expressiblity for several commonly used ansätze
and, by using the cost gradients obtained in [28], sug-
gested that in some cases it is possible for an ansatz to
be both expressive and trainable. Additionally, Ref. [49]
noted a numerical correlation between expressibility and
trainability for analog systems. However, given that both
expressibility and trainability are closely related to ran-
domness, one might expect to be able to draw a more
fundamental and general relationship between express-
ibility and trainability.

Here we demonstrate that this is indeed the case by an-
alytically relating the trainability of an ansatz to its ex-
pressibility. This is done by extending the barren plateau
phenomenon introduced in [27], which holds for ansätze
that form exact 2-designs, to arbitrary ansätze. Speciﬁ-
cally, we upper bound the variance in the cost gradient
in terms of the distance the ansatz is from being a 2-
design. Since the degree to which an ansatz is a 2-design
is a measure of its expressibility, this allows us to relate
the gradient of the cost landscape to the expressibility of
the ansatz. We ﬁnd that the more expressive the ansatz,
the smaller the variance in the cost gradient and hence
the ﬂatter the landscape. We note that an ansatz does
not strictly need to be highly expressive to be used suc-
cessfully, rather it just needs to contain a solution to the
problem at hand. Thus our result highlights the impor-
tance of developing trainable problem-inspired ansatze.

 
 
 
 
 
 
Our main results can be summarized in Fig. 1. Given
an ansatz, we analyze the space of unitaries accessi-
ble when sampling the parameters (Fig. 1(A)) of a
parametrized quantum circuit.
Inexpressive ansätze,
such as the one shown in Fig. 1(B), access a small region
of the unitary group and can include the space of uni-
taries that solve certain problems but not the space that
solve others. Our results do not preclude inexpressive an-
sätze having trainability issues, such as barren plateaus.
On the other hand, highly expressive ansätze, which are
generically used for many problems as they can access a
much larger space (Fig. 1(C)), are shown to lead to small
gradients, and hence can have trainability issues.

Since our analytic bounds are upper bounds, they leave
open the questions of how reducing the expressiblity of
an ansatz changes the cost landscape, and hence how re-
ducing the expressibility can be used to avoid the barren
plateau phenomenon. To address these questions we pro-
vide extensive numerics studying the eﬀect that tuning
the expressibility of an ansatz may have on the scaling of
gradient magnitudes. Speciﬁcally, we consider the eﬀects
of decreasing the depth of the circuits, correlating circuit
parameters, and restricting either the direction or angle
of rotations. We ﬁnd that strongly correlating param-
eters [37] and/or initializing close to the solution (and
then restricting the ansatz to explore the region close to
the initialization [38]) to be the most eﬀective approaches
to avoid exponentially vanishing cost gradients.

II. Preliminaries

A. General framework

Variational Quantum Algorithms (VQAs) encode an
optimization task in a cost function whose minimum cor-
responds to the solution of the problem. Here we consider
cost functions of the form1

Cρ,H (θ) = Tr[HU (θ)ρU (θ)†] ,

(1)

where ρ is an n-qubit input state, H is a Hermitian op-
erator, and U (θ) is a parametrized quantum circuit de-
pending on trainable parameters θ. The value of the
cost Cρ,H (θ) (or of its gradient) are estimated on a
quantum computer, and then are fed into a classical op-
timizer which attempts to solve the optimization task
arg minθ Cρ,H (θ).

The success of the VQA hinges on several factors.
First, it is necessary to ﬁnd an operator H such that
the resulting cost is faithful for the given problem. That

1 In Appendix D we extend our results to more general costs of the
form Cgen = (cid:80)
i Tr[HiU (θ)ρiU (θ)†]. This cost allows for multi-
ple input states
, opening
{
up quantum machine learning approaches that employ training
data [50–53].

and measurement operators

Hi

ρi

{

}

}

2

FIG. 1. Schematic representation of main results. (A)
Variational quantum algorithms (VQAs) train the parame-
ters θ in a parameterized quantum circuit to minimize a cost
function as in Eq. (1). Each set of parameters corresponds
to a unitary U (θ) being produced. The set of unitaries U
accessible by U (θ) is a subset of the unitary group U(d), and
the VQA can be successful if U overlaps with the space of
solution unitaries Us that (approximately) minimize the cost.
The expressibility of an ansatz quantiﬁes the degree to which
it uniformly explores the unitary group U(d). Given prob-
s and UB
lems A and B, we denote their solution spaces as UA
s
respectively.
(B) A low-expressibility ansatz contains solu-
tions to problem A but not to B, while a high-expressibility
ansatz as in (C) contains solutions to both problems. Low-
expressibility ansätze can lead to both small and large cost
gradients. On the other hand, high-expressibility ansätze lead
to predominantly ﬂat cost landscapes, and thus are generally
hard to train.

is, we require the minimum of Cρ,H (θ) to correspond to
the solution of the optimization task. Evidently, for some
applications, there may be multiple choices in H corre-
sponding to faithful costs and therefore other factors will
determine which to use. One such factor is how easily
H can be measured on a quantum computer. Another
relevant feature, as discussed further in Section II D, is
the locality of H, i.e., the number of qubits it acts non-
trivially on. We say that the cost function is global if
H acts non-trivially on all qubits, while we use the term
k-local for costs where H acts non-trivially on at most k
qubits.

A second aspect that determines the success of a VQA
is the choice in ansatz for U (θ). While discrete param-
eterizations are possible, usually θ are continuous pa-
rameters, such as gate rotation angles, in a parametrized

quantum circuit. Generally, U (θ) is expressed as

U (θ) =

D
(cid:89)

j=1

Uj(θj)Wj.

(2)

Here {Wj}N
j=1 is a chosen set of ﬁxed unitaries and Uj =
iθj Vj is a rotation of angle θj generated by a Hermitian
e−
operator Vj such that (Vj)2 = 1. The rotation angles
{θj} are typically assumed to be independent.

Once an ansatz has been ﬁxed for the parametrized
quantum circuit, then, as sketched in Fig. 1(A), each
possible vector of parameters θ corresponds to a unitary
U (θ) that is produced. For concreteness, given a set of
diﬀerent parameters {θ(1), ...θ(2), ..., θ(y)} we obtain the
corresponding ensemble of unitaries

U = {U (1), U (2), ..., U (y)},

(3)

where U (j) := U (θ(j)). Here, U ⊆ U(d), where U(d) is
the unitary group U(d) of degree d = 2n.

B. Expressibility

For a VQA to be successful, a solution (i.e., a unitary
which is by some measure close to the unitary that mini-
mizes the cost) needs to be contained within the ensemble
of unitaries generated by the ansatz. Speciﬁcally, deﬁn-
ing Us as the set of solution unitaries, then the VQA will
(cid:84) U (cid:54)= ∅. When this condition is
be successful only if Us
satisﬁed the ansatz is said to be complete for the given
problem.

In the absence of prior knowledge about where the so-
lution unitaries Us lie, the likelihood that the ansatz is
complete can be maximized by using an ansatz that ex-
plores the total space of unitaries as fully and as uni-
formally as possible. Such ansätze are known as expres-
sive ansätze. For example, consider having two problems
(problem A, and problem B), with solution spaces re-
s and UB
spectively denoted as UA
s . Figure 1(B) sketches
U for an inexpressive ansatz which is complete with re-
spect to problem A but incomplete with respect to B.
Conversely, Fig. 1(C) shows U for an expressive ansatz
which is complete with respect to both problems.

For many applications, information about the problem
can be encoded in the ansatz. For instance, the quantum
alternating operator ansatz [21] (or the Hamiltonian vari-
ational ansatz [25]), encode information of an appropriate
adiabatic transformation. Such problem-inspired ansätze
may be complete but inexpressive (e.g., Fig. 1(B) could
denote a problem-inspired ansatz for problem A). How-
ever, problem-agnostic ansätze, which can be used for a
wide range of problems, need to be suﬃciently expressive
to guarantee their completeness.

The expressibility of an ansatz,

i.e., the degree to
which it uniformly explores the unitary group U(d), can
be quantiﬁed by comparing the uniform distribution of

3

unitaries obtained from the ensemble U to the maxi-
mally expressive uniform (Haar) distribution of unitaries
from U(d). More concretely, the expressibility of a cir-
cuit can be deﬁned in terms of the following super-
operator [47, 48]:

(cid:90)

A(t)

U (·) :=

(d)

U

dµ(V )V ⊗

t( · )(V †)⊗

t

(cid:90)

−

U

dU U ⊗

t( · )(U †)⊗

t ,

(4)

where dµ(V ) is the volume element of the Haar mea-
sure and dU is the volume element corresponding to the
uniform distribution over U in Eq. (3). If A(t)
U (X) = 0
for all operators X, then averaging over elements of U
agrees with averaging over elements of the Haar distri-
bution over U(d) up to the t-th moment, and thus U
forms a t-design [54–58]. For our purposes it suﬃces to
consider the behavior of A(t)
U for t = 2. Henceforth we
drop the t-superscript, i.e., AU ≡ A(2)
U .

In the context of minimizing a generic cost Cρ,H (θ)
of the form speciﬁed by Eq. (1), we are interested in the
expressibility of the circuit with respect to both the initial
state ρ and the measurement operator H. The following
quantities respectively capture these notions:

ερ
U := ||AU(ρ⊗
εH
U := ||AU(H ⊗

2)||2
2)||2 .

(5)

(6)

U and εH

Small values of ερ
U indicate that the ansatz is
highly expressive. These measures generalize the notion
of expressibility introduced in [47] where the expressiblity
was deﬁned in terms of ερ

U for ρ = |0(cid:105)(cid:104)0|.
While the ρ and H dependence of ερ

U make
them natural measures of the expressibility in the context
of minimizing a cost Cρ,H (θ), cost function-independent
measures of expressibility may allow the expected perfor-
mance of diﬀerent ansätze to be more easily compared.
With this in mind, one could alternatively quantify the
expressiblity directly in terms of the diamond norm of
AU,

U and εH

ε(cid:5)
U := ||AU||
(cid:5)

,

(7)

which is an operationally meaningful distance measure
to distinguish two quantum operations. We use the
diamond norm here in line with the literature on ε-
approximate unitary designs [59]; however, alternative
norms can be used (for a discussion, see [57]). For com-
pleteness we will formulate our results in terms of ε(cid:5)
U, as
well as the quantities ερ
U and εH
U .

C. Gradient Magnitudes

For a variational quantum algorithm to run success-
fully it is not suﬃcient that the ansatz contains the solu-
tion; the cost landscape must also exhibit large enough
cost gradients to enable this solution to be found.

The component of the gradient corresponding to the
parameter θk is determined by the partial derivative
∂kC := ∂Cρ,H (θ)
. For a generic ansatz of the form speci-
ﬁed by Eq. (2), the average of ∂kC over all parameters θ
vanishes

∂θk

where

UL(θ) =

D
(cid:89)

j=k+1

Uj(θj)Wj

and UR(θ) =

4

k
(cid:89)

j=1

Uj(θj)Wj .

(12)

(cid:104)∂kC(cid:105) = 0 ∀ k .

(8)

That is, the cost gradients are not biased in any single
direction but rather average out to zero. Intuitively, this
lack of bias can be understood as following from the fact
that the average of a rotation exp(−iθkVk) is zero when
V 2
k = 11. We show this in Appendix C, where we prove
that (cid:104)∂kC(cid:105) = 0 by explicitly integrating over θk.

However an unbiased cost landscape can be either
trainable or untrainable, depending on the extent to
which the gradient ﬂuctuates away from zero. There-
fore, to assess the trainability of an ansatz U (θ), we now
recall the Chebyshev inequality. This inequality bounds
the probability that the partial derivative of the cost de-
viates from its average of zero,

P (|∂kC| (cid:62) δ) (cid:54) Var[∂kC]

δ2

,

(9)

in terms of the variance

Var[∂kC] =

(cid:68)

(∂kC)2(cid:69)

− (cid:104)∂kC(cid:105)2 ,

(10)

where the expectation value is taken over the parameters
θ. Hence if the variance of the partial derivative is small
for all θk, then the probability that the partial derivative
is non-zero is small for all θk. On such landscapes, (po-
tentially untenably) precise measurements are required
to detect the path of steepest descent to navigate to the
minimum.

D. Barren Plateaus

There is a growing awareness of the so called bar-
ren plateau phenomenon for variational quantum algo-
rithms [27–36]. For a given ansatz U (θ), a cost C is said
to exhibit a barren plateau if its gradients vanish expo-
nentially with the number of qubits n. This is typically
relaxed to a probabilistic deﬁnition, where the gradient
vanishes exponentially with high probability. This would
follow from Chebyshevs inequality, Eq. (9), if the vari-
ance in the partial derivative vanishes exponentially, i.e.,
pn) for any integer p > 0. For costs
if Var[∂kC] ∈ O(2−
that exhibit barren plateaus, exponentially precise mea-
surements may be required to determine the minimiza-
tion direction, and hence the cost is eﬀectively untrain-
able for large problem sizes.

To elucidate the conditions under which a layered pa-
rameterized ansatz U (θ), of the form of Eq. (2), gives
rise to barren plateaus, consider a bipartite cut of U (θ)
and write

U (θ) = UL(θ)UR(θ)

(11)

Note that since we suppose the parameters θj are uncor-
related, the circuits UL and UR are independent. These
circuits are pertinent when quantifying gradients since
taking the partial derivative of a circuit, as shown in Ap-
pendix D, eﬀectively splits a circuit in two.

Ref. [27] then demonstrated that if the ensemble of uni-
taries generated by the ansatz U (θ) is suﬃciently random
(i.e., expressive) such that the ensembles UL or UR (as-
sociated with the circuits UL(θ) and UR(θ) respectively)
form 2-designs, then the variance in the cost gradient
vanishes exponentially with n. Speciﬁcally, let us denote
the variance of the cost when just UR, just UL, and both
UR and UL form 2-designs as VarR∂kC, VarL∂kC, and
VarR,L∂kC, respectively. From Ref. [27] it follows that
for x = R, x = L and x = R, L,

Varx∂kC =

gx(ρ, H, U )
22n − 1

,

(13)

where we have pulled out the n-dependent scaling factor
explicitly. The prefactor gx(ρ, H, U ), which we deﬁne
explicitly in Appendix E, is in O(2n) for typical choices
in Vk and H. Thus if UL or UR form a 2-design, the
variance in the gradient vanishes exponentially in n. In
other words, maximally expressive ansätze exhibit barren
plateaus.

III. Main Results

A. Analytic Bounds

In this section, we study the gradient of a generic cost
Cρ,H (θ), Eq. (1), with an ansatz U (θ), Eq. (2), but relax
the assumption that UL or UR forms a 2-design. By
doing so, we extend the results on barren plateaus from
Ref. [27] to arbitrary ansätze. As will become clear, this
generalization enables us to relate the variance of the cost
function partial derivative to the expressiblity of U (θ) in
Eq. (4).

Let us start by noting that while maximally expressive
ansätze exhibit barren plateaus, the converse is not nec-
essarily true. In other words, highly inexpressive ansätze
need not always experience large cost gradients, and in
fact they may exhibit vanishing gradients. A trivial ex-
ample of this phenomenon is provided by an ansatz com-
posed of rotations that commute with the measurement
operator [U (θ), H] = 0. Such an ansatz will leave the
cost unchanged for any θ and so the variance in gradient
in the cost of such an ansatz is necessarily zero. A more
subtle example is an ansatz composed of a tensor prod-
uct of single qubit rotations. Since this ansatz does not

generate entanglement it is inexpressive; however, it has
also been shown to exhibit a barren plateau for global
cost functions [7, 28]. It follows from these observations
that it is not possible to meaningfully lower bound the
gradients of an ansatz in terms of its expressiblity.

Therefore to relate cost gradients to expressibility we
instead derive an upper bound. Speciﬁcally, our main re-
sult consists of a non-trivial upper bound for the variance
of the cost function partial derivative for a general ansatz
U (θ) in terms of the expressibility in (4). This bound is
in terms of: (1) the variance of the cost gradient when
either UL or UR form a 2-design, and (2) the expressibil-
ity of the ansatz as measured by the distance UL and UR
are from being 2-designs. As shown in Appendix D, we
prove the following.

Theorem 1. Consider a generic cost function Cρ,H (θ),
Eq. (1), using a layered ansatz U (θ) of the general form
in Eq. (2). The variance of the cost partial derivative
obeys the following bounds:

Var ∂kC (cid:54) VarR ∂kC + 4ερ
Var ∂kC (cid:54) VarL ∂kC + 4εH
Var ∂kC (cid:54) VarR,L ∂kC + f (ερ

R||H||2
2 ,
L ||ρ||2
2 ,
R, εH
L ) .

(14)

(15)

(16)

Here we used the shorthand ερ
and we have deﬁned

R := ερ
UR

and εH

L := εH
UL

,

f (x, y) := 4xy +

2n+2 (cid:0)x||H||2

2 + y||ρ||2
2

22n − 1

(cid:1)

.

(17)

.

Theorem 1 establishes a formal relationship between
the gradient of the cost landscape and the expressibility
of the ansatz used. Namely, the higher the expressibility
of the ansatz, that is the smaller εH
R, the smaller the
upper bound on the variance of the cost partial deriva-
tive. This, in combination with the fact that the cost
gradient is unbiased, demonstrates that highly expressive
ansätze will have ﬂatter landscapes and consequently be
harder to train.

L or ερ

In contrast to the bounds speciﬁed by Eqs. (13), which
hold for three distinct cases (i.e., when UL is a 2-design,
when UR is a 2-design, and when both UL and UR are
2-design), the bounds in Eqs. (14)–(16) all hold for any
generic ansatz of the form in Eq. (2). Thus any single
bound would suﬃce to bound the variance in the cost
function partial derivative for an arbitrary ansatz.

We include all three bounds despite this fact since in
any instance one bound may be tighter than the others
and hence more informative. In particular, the relative
tightness of the bounds depends on which parameter we
are taking the derivative with respect to. This follows
from the fact that Eq. (14) becomes an equality in the
limit that UR tends to a 2-design, where as Eq. (15) be-
comes an equality in the limit that UL is a 2-design and
Eq. (16) becomes an equality in the limit that both UL
and UR are 2-designs. If we are looking at the derivative

5

with respect to the ﬁnal layer then UR is typically closer
to being a 2-design than UL and so (14) will be tight-
est. Conversely, if we are most interested in the partial
derivative with respect to a parameter in the ﬁrst layer
then (15) will be tightest. On the other hand, for param-
eters in a layer close to the middle (i.e. at depth D/2)
and (16) will be tightest since, as shown in Appendix D,
the derivation of this bound uses the most information
about the ansatz.

In Appendix D, we extend Theorem 1 to cost functions
of the form Cgen = (cid:80)
i Tr[HiU (θ)ρiU (θ)†], which allow
for multiple input states and measurements. Thus our re-
sults also apply to quantum machine learning approaches
that utilize training data [50–53].

Generalizing the Barren Plateau phenomenon. The-
orem 1 may be viewed as an extension of the barren
plateau phenomenon introduced in Ref. [27] to ansätze
that form approximate, rather, than exact 2-designs. By
combining Eq. (13) and Eq. (16), we ﬁnd that the vari-
ance in the partial derivative for an arbitrary ansatz is
bounded as

Var ∂kC (cid:54) gL,R(ρ, H, U )

+ f (εH

L , ερ

R) .

(18)

22n − 1
Here the ﬁrst term on the right is the variance of a max-
imally expressive ansatz (namely, one that forms a 2-
design) and f (εH
R) is the expressiblity dependent cor-
rection term deﬁned in Eq. (17). Expressions similar to
Eq. (18) are obtainable from Eq. (14) and Eq. (15).

L , ερ

L , ερ

For perfectly expressive ansätze, f (εH

R) vanishes
and Eq. (18) reduces to Eq. (13), regaining the result
of Ref. [27].
In this case, the variance in the gradient
vanishes exponentially with the size of the system n, i.e.,
the ansatz exhibits a barren plateau. Similarly, if the
expressibility of an ansatz increases exponentially with
(cid:1) for
the size of the problem, i.e., if f (εH
k > 0, then Var ∂kC again vanishes exponentially and the
ansatz exhibits a barren plateau. However, more gener-
ally, when f (εH
R) scales non-exponentially the upper
bound allows for the variance in the partial derivative to
be non-vanishing. Thus, there is leeway for imperfectly
expressive ansätze to avoid barren plateaus.

R) ∈ O (cid:0) 1

L , ερ

L , ερ

2kn

In Ref. [60] it was proven that the barren plateau phe-
nomenon is necessarily associated with the concentration
of cost functions values about their mean. More con-
cretely, it was shown that the probability that the cost
function deviates from its mean is determined by the
variation in the gradient of the cost. Thus our bounds
also imply that the degree to which the cost concentrates
about its mean increases with increasing expressibility.
In Appendix F, we provide an alternative proof of this
following on from the results of Ref. [33].

Diamond Norm Reformulation. For local costs the
term ||H||2
2 scales exponentially with the size of the sys-
tem and therefore for large systems (14) becomes expo-
nentially loose. This issue can be mitigated by reformu-
lating Theorem 1 in terms of ε(cid:5)U, Eq. (7). We obtain the
following theorem in Appendix D.

6

such ways: decreasing the depth of the circuits, correlat-
ing circuit parameters, and restricting either the direc-
tion or angle of rotations. We then numerically investi-
gate the eﬀect these have on the cost gradient scaling.

1σz

For completeness, in our numerics we consider both a
2-local cost where the measurement operator is composed
of Pauli-z measurements on the ﬁrst and second qubits,
HL = σz
2, and a global cost where the measurement op-
erator consists of Pauli-z measurements across all qubits,
HG = (cid:78)n
i [28]. In both cases, following [27], the sys-
n where
tem is prepared in the pure state, ρ = |ψ0(cid:105)(cid:104)ψ0|⊗
|ψ0(cid:105) = exp(−i(π/8)σY )|0(cid:105). We further consider a layered
hardware eﬃcient ansatz,

i=1 σz

U (kl, θl, D) :=

D
(cid:89)

l=1

W V (kl, θl) ,

(22)

consisting of D alternating layers of random single qubit
gates and entangling gates as shown in Fig. 2. Speciﬁ-
cally, the entangling layer,

W =

n
1
(cid:89)
−

i=1

C-Phasei,i+1 ,

(23)

is composed of a ladder of controlled-phase operations,
C-Phase, between adjacent qubits in a 1-dimensional ar-
ray. The single-qubit layer consists of a series of random
single qubit rotations

V (kl, θl) =

n
(cid:89)

i=1

Rki

l

(θi

l ) ,

(24)

l

l ) is a rotation of the ith qubit by an angle θi
(θi
where Rki
l
about the ki
l = x, y or z axis. In the maximally expressive
version of the ansatz the x, y or z rotation directions {ki
l }
for each qubit on each layer are chosen independently
and with equal probability, and the rotation angles {θi
l }
are independently and randomly chosen in the range 0
to 2π. Our numerics are implemented using TensorFlow
Quantum [61].

Circuit depth. One of the simplest ways of reducing
the expressiblity of an ansatz is reducing the depth D of
the circuit. It was shown in [28] that global costs with
a hardware eﬃcient ansatz experience barren plateaus
irrespective of the depth of the circuit. However, local
costs only exhibit barren plateaus for deep circuits (D ∈
Ω(poly(n)) but are trainable for shallow circuits (D ∈
O(log(n)).

We obtain similar results here. As shown in Fig. 3(A),
for the global cost the variance in the partial deriva-
tive is seemingly independent of the depth of the circuit
and vanishes exponentially with the size of the system
n. Conversely for local costs, as shown in Fig. 3(D), ex-
ponentially vanishing partial derivatives are observed for
systems up to 12 qubits for depths D (cid:39) 100. However
shallow circuits D (cid:47) 50 exhibit an approximately con-
stant scaling for n (cid:39) 8.

FIG. 2. Ansatz employed in numerical simulations.
The ansatz is composed of alternating random single qubit
rotations and ladders of C-Phase operations. The colored
boxes indicate the gates which are ﬁxed to rotate by the same
angle and in the same direction when we correlate the ansatz
layers (yellow), correlate qubits (blue) and correlate both the
layers and qubits (green).

Theorem 2. Consider a generic cost function Cρ,H (θ),
Eq. (1), using a layered ansatz U (θ) of the general form
in Eq. (2). The variance of the cost partial derivative
obeys the following bounds:

Var ∂kC (cid:54) VarR ∂kC + 4||H||2
ε(cid:5)
R ,
∞
Var ∂kC (cid:54) VarL ∂kC + 4||ρ||2
(cid:107)H(cid:107)1 ε(cid:5)
L ,
∞
R, (cid:107)H(cid:107)1ε(cid:5)
f (ε(cid:5)
L)
2n

Var ∂kC (cid:54) VarR,L ∂kC +

,

(19)

(20)

(21)

where we use the shorthand ε(cid:5)
with f (x, y) deﬁned in Eq. (17).

R = ε(cid:5)UR

and ε(cid:5)

L = ε(cid:5)UL

and

Again, Theorem 2 formally establishes that highly ex-
pressive ansätze experience ﬂatter cost landscapes. Fur-
thermore, a relation similar to (18) can be derived from
Theorem 2. Hence, Theorem 2 also provides an extension
of the barren plateau result of Ref. [27]. However, since
||H||2
∈ O(1) for all H, (19) does not experience the
∞
same looseness for local costs of large systems as (14).
On the other hand, since ||H||1 may scale exponentially
in n, (20) may become loose for large systems and there-
fore we expect (15) to generally be more useful than (20).

B. Numerical Simulations

Since the analytic bounds in the previous section are
upper bounds, we have no guarantee that inexpressive
ansätze will exhibit larger cost gradients. The bounds
thus leave open the question of whether/how reducing
the expressiblity of an ansatz changes the cost landscape.
Moreover, they leave open the question of how one can
avoid the barren plateau phenomenon that is observed
for maximally expressive ansätzes.

One can conceive of numerous ways in which the ex-
pressibility of an ansatz can be tuned, each of which could
have a diﬀerent impact. In this section, we consider four

Cor. Qubits Cor. Qubits and Layers Cor.Layers 7

FIG. 3. Partial derivative scalings for diﬀerent expressiblities. The variance in the partial derivative of a global cost
with HG = (cid:78)n
2 (bottom) as a function of the number of qubits n (in both cases
ρ = |ψ0(cid:105)(cid:104)ψ0|⊗n where |ψ0(cid:105) = exp(−i(π/8)σY )|0(cid:105)). In the left panel we vary the circuit depth D of a hardware eﬃcient ansatz.
In the middle (right)

i (top) and 2-local cost with HL = σz

i=1 σz

1 σz

panel we consider the eﬀect of correlating parameters (restricting the directions of rotation) of a hardware eﬃcient ansatz
with D = 150 with the choices of correlations (rotations) indicated in the ﬁgure legend. In all cases the derivative is taken
with respect to θ1
1, the rotation angle of the ﬁrst qubit in the ﬁrst layer, and the variance is taken over an ensemble of 1000

unitaries.

Correlating parameters. A more sophisticated means
of reducing the expressibility of the ansatz is to correlate
the rotation angles [37]. Here we consider three diﬀerent
means of correlating parameters, as sketched in Fig. 2,
and plot the corresponding variance in the cost partial
derivative in the central panel of Fig. 3.
In the ﬁrst,
shown in yellow, we correlate the qubits (but allow the
angles to vary between layers), i.e., ki
l =
θi(cid:48)
for any two qubits i and i(cid:48). In the second (plotted
l
in green) we correlate the diﬀerent layers (but not the
qubits), i.e., ki
l(cid:48) for any two layers l
and l(cid:48). Finally, as shown in blue, we correlate both the
In this case all the qubits rotate in
qubits and layers.
same direction and by the same angle, i.e., ki
l(cid:48) and
l = θi(cid:48)
θi
l(cid:48) for any two qubits i and i(cid:48) and layers l and l(cid:48).
In other words, all parameters are correlated. The data
for only y (x) rotations is indicated by the solid (dashed)
lines respectively.

l and θi

l(cid:48) and θi

l = ki(cid:48)

l = ki(cid:48)

l = ki

l = θi

In contrast to varying circuit depth, here we obtain
similar results irrespective of whether a local or global
cost is used. Correlating both the qubits and the lay-
ers results in the least expressive ansatz and correspond-
ingly the largest variation in cost gradients is observed.
Indeed, in this case the variance in the cost gradient is
approximately constant. In contrast, correlating just the
qubits, or just the layers, increases the cost gradients and
reduces the scaling of the cost gradient with system size
but an exponential scaling is still observed.

Restricting rotation direction. One might also con-
sider reducing the expressibility of the ansatz by reducing
the single qubit rotation gates to a subset of directions.
We explore this in the right panel of Fig. 3. In blue we

plot the variance when only rotations in a single direc-
tion, namely in the x (dark blue) or y (light blue) direc-
tion, are implemented. We do not plot the case when
only z rotations are implemented since in that case U
commutes with HL = σz
i , and so
the cost landscape is entirely ﬂat. For a local cost, re-
ducing the expressibility of the ansatz by restricting to
single direction rotations seemingly removes the expo-
nential gradient scaling. However, for a global cost the
scaling remains exponential.

2 and HG = (cid:78)n

i=1 σz

1σz

l , ˜θi

l by at most 2πr.

l + 2πr] where ˜θi

Restricting rotation angles. A ﬁnal way to reduce the
expressiblity of an ansatz is by reducing the range the ro-
tation angles θ are chosen from. That is, choosing the θi
l
in the range [˜θi
l is a ﬁxed initialization
point. For r = 1 the ansatz explores the entire solution
space but for r < 1 the ansatz is constrained to exploring
a subset of the solution space where the rotation angles
l deviate from ˜θi
θi
However, with a little thought, it is clear that, in con-
trast to the previous three approaches we have discussed,
restricting the rotation angles of the ansatz does not
change the cost landscape but rather limits the region
of the landscape explored by the ansatz. Thus, in gen-
eral, reducing the rotation angles does not eﬀect the cost
gradients experienced. This intuition is conﬁrmed by the
numerical results displayed in the top panel of Fig. 4.
Here we randomly initialize the parameters by randomly
choosing ˜θi
in the range [0, 2π]. We ﬁnd the the cost
l
partial derivatives for diﬀerent r values perfectly overlap
in this case, i.e., for a random initialization, restricting
the ansatz to a limited range of rotation angles does not
change the partial derivatives observed.

10−410−310−210−1Var∂θC(A)CircuitDepthGlobalCostD=10D=25D=50D=75D=100D=125D=15010−710−410−1102105(B)CorrelatingParametersUncor.Cor.QubitsCor.LayersCor.Qubits&Layers(solid=y,dashed=x)10010−110−210−310−410−5(C)RestrictingRotationDirectionsyxxyz24681012NumberofQubits,n10−410−310−210−1Var∂θC(D)LocalCost24681012NumberofQubits,n10−710−410−1102105(E)24681012NumberofQubits,n10010−110−210−310−410−5(F)On the other hand, if the parameters are initialized
close to the solution, varying r has a substantial eﬀect
on the observed partial derivatives for local costs, and a
reduced eﬀect for global costs. This is seen in (B) and (C)
of Fig. 4 where we initialize to identity, i.e., pick ˜θi
l = 0
for all i, which is close to the solution for this simple
problem. In this case, for r close to 1 (as shown in red
and yellow) the variance in the partial derivative again
vanishes exponentially with n. However, for small angle
ranges, r (cid:47) 0.1, as shown in blue, we ﬁnd that the partial
derivative of a local cost ceases to exhibit an exponential
scaling. To some degree, a similar eﬀect is displayed for
global costs; however, the eﬀect is reduced and is only
visible in the data here for r ≈ 0.025.

This change in partial derivative scaling for small r
for initializations close to the solution is plausibly ex-
plained by the fact that the global minimum of costs
exhibiting barren plateaus tend to sit within a steep and
narrow gorge [28], as sketched in Fig. 1(C). By initializ-
ing close to the solution we are likely to be initializing
within the narrow gorge.
In this case, when r is close
to 1 the ansatz still explores the entire cost landscape
and therefore the variance in the partial derivative will
be unchanged. However, for smaller r the ansatz is con-
strained to the region around the the narrow gorge itself,
and hence a larger variance in partial derivatives is ob-
served.

Outlook for ansatz design. Figure 3 suggests that re-
ducing the depth of a circuit and correlating parameters
are the most eﬀective strategies for amplifying the ob-
served cost gradients. However, the optimal solution,
of course, may not lie within a shallow or highly cor-
related ansatz. When deep and/or uncorrelated circuits
are required, as is expected to be the case for many prob-
lems of interest, then a perturbative strategy may instead
be eﬀective. That is, one could start the variational al-
gorithm using a shallow, highly correlated ansatz and
as the cost is iteratively minimized gradually grow the
ansatz [8, 15, 38] and decorrelate the parameters [37].

Restricting the angle range also appears to provide an
eﬀective strategy for increasing cost gradients, but for it
to be practical it is necessary to initialize close to the
solution. This, of course, requires either prior knowledge
of an approximate solution to the problem at hand or an
eﬀective pre-training strategy to obtain such an approx-
imate solution. The viability of either of these options
warrants further investigation.

Correlation and tightness of bounds.

In Fig. 6 we
study the correlation between the cost gradients and our
upper bounds. To quantify this correlation we include the
Spearman correlation coeﬃcient [63], as well as its corre-
sponding p-value, which approximately gives the proba-
bility of uncorrelated data generating a Spearman coef-
ﬁcient at least as large as the one found. For local costs
we obtain a Spearman value of at least 0.9 with a p-value
of less than 0.05 in all cases, indicating a strong corre-
lation between our upper bound and the actual variance

8

l , ˜θi

FIG. 4. Partial derivative scalings for restricted angle
ranges. The scaling of the variance in the partial deriva-
tive when the rotation angles θi
l are randomly chosen from
the range [˜θi
l + 2πr], such that for r = 1 (red) the ansatz
explores the entire solution space but for r (cid:28) 1 (blue) the
ansatz is constrained to exploring close to the initialization
point deﬁned by {˜θi
l } are a ﬁxed
(randomly chosen) initialization point away from the solution
(here we consider a local cost but the data for a global cost is
essentially unchanged). In (B) and (C), which correspond to
global and local costs respectively, the angles ˜θi
l = 0 for all l
and i, which is close to the global minimum of the cost. In all
cases the derivative is taken with respect to θ1
1, the rotation
angle of the ﬁrst qubit in the ﬁrst layer and the variance is
taken over an ensemble of 1000 unitaries.

In (A), the angles {˜θi

l }.

in the gradient. The correlation is weaker in the case of
global costs, highlighting that in the case of a global cost
expressibility is not the only phenomenon that may in-
duce a barren plateau. This is to be expected given the
results of Ref. [28], which show even very shallow and/or
non-entangling circuits (i.e. highly inexpressive circuits)
may exhibit barren plateaus when using global costs. For
completeness, the results presented here are extended in
Appendix G, where we study directly the correlation be-
tween cost gradient and the expressibility measures ερ
R
and εH

L , with similar correlations observed.

Figure 6 additionally highlights that, as expected, the
bounds are tightest for higher expressibility ansätze but
may be relatively loose for lower expressibilities. More
speciﬁcally, in all cases considered here, the bounds are

10−410−310−210−1Var∂θC(A)RandomInitialization,LocalCostr=0.025r=0.05r=0.1r=0.15r=0.2r=0.25r=0.5r=110−410−310−210−1Var∂θC(B)InitializationNearSolution,GlobalCost24681012NumberofQubits,n10−410−310−210−1Var∂θC(C)InitializationNearSolution,LocalCost9

The key to our extension was to consider the expressib-
lity of the ansatz. This can be precisely deﬁned in terms
of the distance of the ensemble of unitaries accessible by
the ansatz from being a 2-design. Hence, our extension
linked two key properties of ansätze: their expressiblity
and their gradient magnitudes. Our bounds demonstrate
that increasing the expressibility of an ansatz can result
in smaller cost gradients. We believe that this connection
is very interesting, and there is certainly much more to
be explored along these lines. For example, it would be
interesting to connect our ﬁndings to recent results on the
role of the growth of entanglement in generating barren
plateaus. In particular, since highly expressive ansätze
are necessarily highly entangling, our results would seem
to imply those in Refs. [33, 44].

To go beyond our bounds and look at the precise
relation between expressiblity and gradients, we per-
formed extensive numerics. We considered several dif-
ferent strategies by which one can vary the expressib-
lity. As highlighted in Fig. 6 and Fig. 5, we typically
observed a strong correlation (especially for local cost
functions) between the expressiblity and the variance of
the gradient. However, the bounds are not perfectly
tight. This may arise from the repeated use of the tri-
angle and Cauchy-Schwarz inequalities in the derivation
(Appendix D). Thus a natural question to ask is whether
our bounds can be further tightened. Another direction
would be to explore the nature of barren plateaus for
global costs where the numerics suggest that the correla-
tion between expressibility and cost gradients is weaker.
We remark that the numerical results presented here
are necessarily problem speciﬁc, since they depend both
on the choice in cost function and ansatz. Further work
is required to ascertain the extent to which the trends
observed here are universally observed. In particular it
would be valuable to investigate whether any analytic
results can be obtained to support them.

Nevertheless, there are several interesting trends shown
in our numerics that even suggest potential strategies
of avoiding or mitigating barren plateaus. As discussed
above, correlating parameters and restricting rotation
angles (especially when initializing near the solution)
are two strategies that signiﬁcantly mitigated barren
plateaus in our numerics. Further exploring these and
other strategies will be an important direction for future
research.

Acknowledgments

ZH and PJC were supported by the Los Alamos Na-
tional Laboratory (LANL) ASC Beyond Moore’s Law
project. KS was supported by the Laboratory Directed
Research and Development (LDRD) program of LANL
under project number 20190065DR. MC was initially
supported by the LDRD program of LANL under project
number 20180628ECR, and also supported by the Cen-
ter for Nonlinear Studies at LANL. This work was also

FIG. 5. Comparison of scaling of bound and gradi-
ents. The scaling of the bound on the variance in the gra-
dient (blue), Eq. (16), and variance in the partial derivative
(green) as a function of the ansatz depth for n = 8 qubits.
The dashed line indicates the predicted variance in the partial
derivative for a perfect 2-design from Ref [62]. The derivative
is taken with respect to θ1
D/2, the rotation angle of the ﬁrst
qubit in the middle layer (D/2) and the variance is taken over
an ensemble of 1000 unitaries. We chose to show the state and
Hamiltonian dependent bound here, Eq. (16), because as we
are looking at the gradient with respect to θ1
D/2 this bound is
tightest.

tight to within a couple of orders of magnitude, with
the bounds tightest for ansätze that are high depth, un-
correlated and use the full range of rotation directions2.
This phenomenon is more clearly demonstrated in Fig. 5
where we plot both the variance in the partial derivative
of the cost and the Hamiltonian and state dependent ex-
pressiblity bound, Eq. (16), as a function of ansatz depth
for the 8 qubit local cost. The bound captures the qual-
itative behaviour of the cost gradients, decreasing with
increased circuit depth. While moderately loose at low
depths, the bound becomes tight for deep circuits.

IV. Discussion

In this work, we extended the well-known barren
plateau result. This result was restricted to ansätze that
form 2-designs [27], while we extended it to arbitrary
ansätze in our Theorems 1 and 2. In practice, this ex-
tension may prove to be quite useful, since many an-
sätze of interest are not exact 2-designs but rather are
some approximate notion of this [59, 64–66]. Our results
can potentially provide useful bounds on the variance of
the gradient in this realistic scenario of approximate 2-
designs.

2 We note that for highly correlated circuits the variance in the
gradient can in fact be larger than allowed by our bounds which
were derived for uncorrelated circuits. In future work, it would be
interesting to investigate whether our bounds can be generalised
to account for such correlations.

4080120160200240CircuitDepth10−310−210−1100Var∂θC,BoundExpressibilityBoundVarianceinCostGradientVarianceforexact2design10

1 σz

2 (top) and global cost with H = (cid:81)n

FIG. 6. Correlations between cost partial derivatives and bounds. The variance in the partial derivative of a 2-local
cost with H = σz
i (bottom) as a function of the state-dependent expressibility upper
bound on the variance in the partial derivative speciﬁed by Eq. (14) (A - F) and the Hamiltonian-dependent expressibility
upper bound on the variance in the partial derivative speciﬁed by Eq. (15) (G - L). In both cases ρ = |ψ0(cid:105)(cid:104)ψ0|⊗n where
|ψ0(cid:105) = exp(−i(π/8)σY )|0(cid:105). In the left panel we vary the circuit depth D of a hardware eﬃcient ansatz. In the right (middle)
panel we consider the eﬀect of correlating parameters (restricting the directions of rotation) of a hardware eﬃcient ansatz with
D = 100 with the choices of correlations (rotations) indicated in the ﬁgure legend. In (A-F) the derivative is taken with respect
to θ1
D. In all cases n = 4 and the expressibility measures are estimated
using an ensemble of 5000 unitaries.

1 and in (G-L) the derivative is taken with respect to θ1

i=1 σz

supported by the U.S. Department of Energy (DOE), Of-
ﬁce of Science, Oﬃce of Advanced Scientiﬁc Computing

Research, under the Accelerated Research in Quantum
Computing (ARQC) program.

[1] Frank Arute, Kunal Arya, Ryan Babbush, Dave Bacon,
Joseph C Bardin, Rami Barends, Rupak Biswas, Sergio
Boixo, Fernando GSL Brandao, David A Buell, et al.,
“Quantum supremacy using a programmable supercon-
ducting processor,” Nature 574, 505–510 (2019).

[2] John Preskill, “Quantum Computing in the NISQ era and

beyond,” Quantum 2, 79 (2018).

[3] A. Peruzzo, J. McClean, P. Shadbolt, M.-H. Yung, X.-Q.
Zhou, P. J. Love, A. Aspuru-Guzik, and J. L. O’Brien,
“A variational eigenvalue solver on a photonic quantum
processor,” Nature Communications 5, 4213 (2014).
[4] Jarrod R McClean, Jonathan Romero, Ryan Babbush,

and Alán Aspuru-Guzik,
“The theory of variational
hybrid quantum-classical algorithms,” New Journal of
Physics 18, 023023 (2016).

[5] Edward Farhi, Jeﬀrey Goldstone, and Sam Gutmann,
“A quantum approximate optimization algorithm,” arXiv
preprint arXiv:1411.4028 (2014).

[6] J. Romero, J. P. Olson, and A. Aspuru-Guzik, “Quantum
autoencoders for eﬃcient compression of quantum data,”
Quantum Science and Technology 2, 045001 (2017).
[7] Sumeet Khatri, Ryan LaRose, Alexander Poremba,
Lukasz Cincio, Andrew T Sornborger,
and Patrick J
Coles, “Quantum-assisted quantum compiling,” Quan-

tum 3, 140 (2019).

[8] R. LaRose, A. Tikku, É. O’Neel-Judy, L. Cincio, and
P. J. Coles, “Variational quantum state diagonalization,”
npj Quantum Information 5, 1–10 (2018).

[9] Andrew Arrasmith, Lukasz Cincio, Andrew T Sorn-
borger, Wojciech H Zurek, and Patrick J Coles, “Vari-
ational consistent histories as a hybrid algorithm for
quantum foundations,” Nature communications 10, 1–7
(2019).

[10] M. Cerezo, Alexander Poremba, Lukasz Cincio,

and
Patrick J Coles, “Variational quantum ﬁdelity estima-
tion,” Quantum 4, 248 (2020).

[11] Kunal Sharma, Sumeet Khatri, M. Cerezo, and Patrick J
Coles, “Noise resilience of variational quantum compil-
ing,” New Journal of Physics 22, 043006 (2020).

[12] Carlos Bravo-Prieto, Ryan LaRose, Marco Cerezo, Yigit
Subasi, Lukasz Cincio, and Patrick Coles, “Variational
quantum linear solver,” arXiv preprint arXiv:1909.05820
(2019).

[13] M Cerezo, Kunal Sharma, Andrew Arrasmith,

and
Patrick J Coles, “Variational quantum state eigensolver,”
arXiv preprint arXiv:2004.01372 (2020).

[14] Kentaro Heya, Ken M Nakanishi, Kosuke Mitarai, and
Keisuke Fujii, “Subspace variational quantum simulator,”
arXiv preprint arXiv:1904.08566 (2019).

[15] Cristina Cirstoiu, Zoe Holmes, Joseph Iosue, Lukasz Cin-
and Andrew Sornborger, “Vari-
cio, Patrick J Coles,
ational fast forwarding for quantum simulation beyond
the coherence time,” npj Quantum Information 6, 1–10
(2020).

[16] Benjamin Commeau, M. Cerezo, Zoë Holmes, Lukasz
and Andrew Sornborger,
Cincio, Patrick J Coles,
“Variational hamiltonian diagonalization for dynamical
quantum simulation,” arXiv preprint arXiv:2009.02559
(2020).

[17] Ying Li and Simon C Benjamin, “Eﬃcient variational
quantum simulator incorporating active error minimiza-
tion,” Physical Review X 7, 021050 (2017).

[18] Suguru Endo, Jinzhao Sun, Ying Li, Simon C Benjamin,
and Xiao Yuan, “Variational quantum simulation of gen-
eral processes,” Physical Review Letters 125, 010501
(2020).

[19] Xiao Yuan, Suguru Endo, Qi Zhao, Ying Li, and Si-
mon C Benjamin, “Theory of variational quantum simu-
lation,” Quantum 3, 191 (2019).

[20] M. Cerezo, Andrew Arrasmith, Ryan Babbush, Simon C
Benjamin, Suguru Endo, Keisuke Fujii, Jarrod R Mc-
Clean, Kosuke Mitarai, Xiao Yuan, Lukasz Cincio, and
Patrick J Coles, “Variational quantum algorithms,” arXiv
preprint arXiv:2012.09265 (2020).

[21] Stuart Hadﬁeld, Zhihui Wang, Bryan O’Gorman,
Eleanor G Rieﬀel, Davide Venturelli, and Rupak Biswas,
“From the quantum approximate optimization algorithm
to a quantum alternating operator ansatz,” Algorithms
12, 34 (2019).

[22] Rodney J Bartlett and Monika Musiał, “Coupled-cluster
theory in quantum chemistry,” Reviews of Modern
Physics 79, 291 (2007).

[23] Joonho Lee, William J Huggins, Martin Head-Gordon,
and K Birgitta Whaley, “Generalized unitary coupled
cluster wave functions for quantum computation,” Jour-
nal of chemical theory and computation 15, 311–324
(2018).

[24] Yudong Cao, Jonathan Romero, Jonathan P Olson,

11

Matthias Degroote, Peter D Johnson, Mária Kieferová,
Ian D Kivlichan, Tim Menke, Borja Peropadre, Nico-
las PD Sawaya, et al., “Quantum chemistry in the age
of quantum computing,” Chemical reviews 119, 10856–
10915 (2019).

[25] Dave Wecker, Matthew B Hastings,

and Matthias
Troyer, “Progress towards practical quantum variational
algorithms,” Physical Review A 92, 042303 (2015).
[26] A. Kandala, A. Mezzacapo, K. Temme, M. Takita,
M. Brink, J. M. Chow,
and J. M. Gambetta,
“Hardware-eﬃcient variational quantum eigensolver for
small molecules and quantum magnets,” Nature 549, 242
(2017).

[27] Jarrod R McClean, Sergio Boixo, Vadim N Smelyanskiy,
Ryan Babbush, and Hartmut Neven, “Barren plateaus
in quantum neural network training landscapes,” Nature
communications 9, 4812 (2018).

[28] M. Cerezo, Akira Sone, Tyler Volkoﬀ, Lukasz Cincio,
and Patrick J Coles, “Cost-function-dependent barren
plateaus in shallow quantum neural networks,” arXiv
preprint arXiv:2001.00550 (2020).

[29] Kunal Sharma, M. Cerezo, Lukasz Cincio,

and
Patrick J Coles, “Trainability of dissipative perceptron-
based quantum neural networks,”
arXiv preprint
arXiv:2005.12458 (2020).

[30] Samson Wang, Enrico Fontana, M. Cerezo, Kunal
Sharma, Akira Sone, Lukasz Cincio, and Patrick J Coles,
“Noise-induced barren plateaus in variational quantum
algorithms,” arXiv preprint arXiv:2007.14384 (2020).

[31] M. Cerezo and Patrick J Coles,

“Impact of barren
plateaus on the hessian and higher order derivatives,”
arXiv preprint arXiv:2008.07454 (2020).

[32] Zoë Holmes, Andrew Arrasmith, Bin Yan, Patrick J
Coles, Andreas Albrecht,
and Andrew T Sornborger,
“Barren plateaus preclude learning scramblers,” arXiv
preprint arXiv:2009.14808 (2020).

[33] Carlos Ortiz Marrero, Mária Kieferová,

and Nathan
Wiebe, “Entanglement induced barren plateaus,” arXiv
preprint arXiv:2010.15968 (2020).

[34] Alexey Uvarov and Jacob Biamonte, “On barren plateaus
and cost function locality in variational quantum algo-
rithms,” arXiv preprint arXiv:2011.10530 (2020).
[35] Andrew Arrasmith, M. Cerezo, Piotr Czarnik, Lukasz
Cincio,
“Eﬀect of barren
plateaus on gradient-free optimization,” arXiv preprint
arXiv:2011.12245 (2020).

and Patrick J Coles,

[36] Amira Abbas, David Sutter, Christa Zoufal, Aurélien
Lucchi, Alessio Figalli,
“The
power of quantum neural networks,” arXiv preprint
arXiv:2011.00027 (2020).

and Stefan Woerner,

[37] Tyler Volkoﬀ and Patrick J Coles, “Large gradients via
correlation in random parameterized quantum circuits,”
Quantum Science and Technology 6, 025008 (2021).
[38] Edward Grant, Leonard Wossnig, Mateusz Ostaszewski,
and Marcello Benedetti, “An initialization strategy for
addressing barren plateaus in parametrized quantum cir-
cuits,” Quantum 3, 214 (2019).

[39] Guillaume Verdon, Michael Broughton, Jarrod R Mc-
Clean, Kevin J Sung, Ryan Babbush, Zhang Jiang, Hart-
mut Neven, and Masoud Mohseni, “Learning to learn
with quantum neural networks via classical neural net-
works,” arXiv preprint arXiv:1907.05415 (2019).

[40] Andrea Skolik, Jarrod R McClean, Masoud Mohseni,
and Martin Leib, “Layerwise

Patrick van der Smagt,

learning for quantum neural networks,” arXiv preprint
arXiv:2006.14904 (2020).

[41] Arthur Pesah, M. Cerezo, Samson Wang, Tyler Volkoﬀ,
Andrew T Sornborger, and Patrick J Coles, “Absence
of barren plateaus in quantum convolutional neural net-
works,” arXiv preprint arXiv:2011.02966 (2020).

[42] Kaining Zhang, Min-Hsiu Hsieh, Liu Liu, and Dacheng
Tao, “Toward trainability of quantum neural networks,”
arXiv preprint arXiv:2011.06258 (2020).

[43] Ernesto Campos, Aly Nasrallah, and Jacob Biamonte,
“Abrupt transitions in variational quantum circuit train-
ing,” arXiv preprint arXiv:2010.09720 (2020).
[44] Taylor L Patti, Khadijeh Najaﬁ, Xun Gao,

and Su-
sanne F Yelin, “Entanglement devised barren plateau
mitigation,” arXiv preprint arXiv:2012.12658 (2020).
[45] Kishor Bharti and Tobias Haug, “Iterative quantum
assisted eigensolver,” arXiv preprint arXiv:2010.05638
(2020).

[46] Kishor Bharti and Tobias Haug, “Quantum assisted sim-

ulator,” arXiv preprint arXiv:2011.06911 (2020).

[47] Sukin Sim, Peter D. Johnson, and Alán Aspuru-Guzik,
“Expressibility and entangling capability of parameter-
ized quantum circuits for hybrid quantum-classical al-
gorithms,” Advanced Quantum Technologies 2, 1900070
(2019).

[48] Kouhei Nakaji and Naoki Yamamoto, “Expressibility of
the alternating layered ansatz for quantum computa-
tion,” arXiv preprint arXiv:2005.12537 (2020).

[49] Jirawat Tangpanitanon, Supanut Thanasilp, Ninnat
Dangniam, Marc-Antoine Lemonde, and Dimitris G An-
gelakis, “Expressibility and trainability of parameterized
analog quantum systems for machine learning applica-
tions,” arXiv preprint arXiv:2005.11222 (2020).

[50] Jacob Biamonte, Peter Wittek, Nicola Pancotti, Patrick
Rebentrost, Nathan Wiebe, and Seth Lloyd, “Quantum
machine learning,” Nature 549, 195–202 (2017).

[51] Maria Schuld, Ilya Sinayskiy, and Francesco Petruccione,
“An introduction to quantum machine learning,” Con-
temporary Physics 56, 172–185 (2015).

[52] Kyle Poland, Kerstin Beer, and Tobias J Osborne, “No
free lunch for quantum machine learning,” arXiv preprint
arXiv:2003.14103 (2020).

[53] Kunal Sharma, M Cerezo, Zoë Holmes, Lukasz Cincio,
Andrew Sornborger, and Patrick J Coles, “Reformula-
tion of the no-free-lunch theorem for entangled data sets,”
arXiv preprint arXiv:2007.04900 (2020).

[54] D. P. DiVincenzo, D. W. Leung,

and B. M. Terhal,
“Quantum data hiding,” IEEE Transactions on Informa-
tion Theory 48, 580–598 (2002).

12

tributed unitaries: On the structure of unitary designs,”
Journal of Mathematical Physics 48, 052104 (2007).
[56] Daniel A. Roberts and Beni Yoshida, “Chaos and com-
plexity by design,” Journal of High Energy Physics 2017,
121 (2017).

[57] Richard A. Low, Pseudo-randomness and Learning in

Quantum Computation, Ph.D. thesis, - (2010).

[58] Nicholas Hunter-Jones, “Unitary designs from statistical
mechanics in random quantum circuits,” arXiv preprint
arXiv:1905.12053 (2019).

[59] Aram W. Harrow and Richard A. Low, “Random quan-
tum circuits are approximate 2-designs,” Communica-
tions in Mathematical Physics 291, 257–302 (2009).

[60] Andrew Arrasmith, Zoë Holmes, M Cerezo,

and
Patrick J Coles, “Equivalence of quantum barren plateaus
to cost concentration and narrow gorges,” arXiv preprint
arXiv:2104.05868 (2021).

[61] Michael Broughton, Guillaume Verdon, Trevor McCourt,
Antonio J Martinez, Jae Hyeon Yoo, Sergei V Isakov,
Philip Massey, Murphy Yuezhen Niu, Ramin Halavati,
Evan Peters, et al.,
“Tensorﬂow quantum: A soft-
ware framework for quantum machine learning,” arXiv
preprint arXiv:2003.02989 (2020).

[62] Jarrod R. McClean, Sergio Boixo, Vadim N. Smelyanskiy,
Ryan Babbush, and Hartmut Neven, “Barren plateaus
in quantum neural network training landscapes,” Nature
Communications 9, 4812 (2018).
[63] Jerome L Myers, Arnold D Well,

and Robert F
Lorch Jr, Research design and statistical analysis (Rout-
ledge, 2013).
[64] Winton Brown

“Scrambling
speed of random quantum circuits,” arXiv preprint
arXiv:1210.6644 (2012).

and Omar Fawzi,

[65] Aram Harrow and Saeed Mehraban, “Approximate uni-
tary t-designs by short random quantum circuits using
nearest-neighbor and long-range gates,” arXiv preprint
arXiv:1809.06957 (2018).

[66] Fernando G. S. L. Brandão, Aram W. Harrow,

and
Michał Horodecki, “Local random quantum circuits are
approximate polynomial-designs,” Communications in
Mathematical Physics 346, 397–434 (2016).

[67] Zbigniew Puchała and Jaroslaw Adam Miszczak, “Sym-
bolic integration with respect to the haar measure on
the unitary groups,” Bulletin of the Polish Academy of
Sciences Technical Sciences 65, 21–27 (2017).

[68] S Popescu, AJ Short,

and A Winter, “The founda-
tions of statistical mechanics from entanglement: Indi-
vidual states vs. averages. eprint,” arXiv preprint quant-
ph/0511225 (2005).

[55] D. Gross, K. Audenaert,

and J. Eisert, “Evenly dis-

[69] SC Choi, “Tests of equality of dependent correlation co-

eﬃcients,” Biometrika 64, 645–647 (1977).

Appendices

13

We begin by reviewing some deﬁnitions and prior results relevant for the rest of the appendices. We then provide

proofs for the main results and theorems.

A. Preliminaries

Operator Norms. Let D(H) denote the set of density operators acting on a Hilbert space H, i.e., those that are
positive semi-deﬁnite with unit trace. Let L(H) denote the space of square linear operators acting on H. The trace
norm or Schatten 1-norm (cid:107)Ω(cid:107)1 of an operator Ω ∈ L(H) is deﬁned as (cid:107)Ω(cid:107)1 := Tr[|Ω|], where |Ω| :=
Ω†Ω. More
generally, the Schatten p-norm of an operator Ω can be deﬁned as (cid:107)Ω(cid:107)p = (Tr[|Ω|p])1/p, which satisﬁes (cid:107)Ω(cid:107)p (cid:54) (cid:107)Ω(cid:107)q
for p (cid:62) q. The diamond norm of a Hermiticity preserving linear map SA is deﬁned as

√

(cid:107)SA(cid:107)
(cid:5)

= sup

n

sup
ΩAB

=0

(cid:107)(SA ⊗ I (n)

B )(ΩAB)(cid:107)1

(cid:107)ΩAB(cid:107)1

,

(A1)

is a measure of the distinguishability of two quantum operations N and M.

B denote an identity channel acting on an n-dimensional system B. The diamond-

where ΩAB ∈ L(HA ⊗ HB) and I (n)
norm distance (cid:107)N − M(cid:107)
(cid:5)
Properties of the Haar measure. Let U(d) denote the unitary group of degree d = 2n. Let dµH (V ) = dµ(V ) be
the volume element of the Haar measure, where V ∈ U(d). The volume of the Haar measure is ﬁnite: (cid:82)
(d) dµ(V ) < ∞.
The Haar measure is uniquely deﬁned up to a multiplicative constant factor. Let dζ(V ) be an invariant measure.
Then there exists a constant c such that dζ(V ) = c · dµ(V ). The Haar measure is left- and right-invariant under the
action of the unitary group of degree d, i.e., for any integrable function g(V ), the following holds:

U

(cid:90)

(d)

U

dµ(V )g(W V ) =

dµ(V )g(V W ) =

dµ(V )g(V ),

(cid:90)

(cid:90)

(d)

U

(d)

U

(A2)

where W ∈ U(d).
Symbolic integration. We recall formulas which allow for the symbolical integration with respect to the Haar
measure on a unitary group [67]. For any V ∈ U(d) the following expressions are valid for the ﬁrst two moments:

(cid:90)

dµ(V )vijv∗

pk =

(cid:90)

dµ(V )vi1j1 vi2j2 v∗
1j(cid:48)
i(cid:48)
1

v∗
2j(cid:48)
i(cid:48)
2

=

,

δipδjk
d
δi1i(cid:48)

1

δi2i(cid:48)

2

δj1j(cid:48)

1

δj2j(cid:48)

+ δi1i(cid:48)

2

2
d2 − 1

δi2i(cid:48)

1

δj1j(cid:48)

2

δj2j(cid:48)

1

δi1i(cid:48)

1

δi2i(cid:48)

2

δj1j(cid:48)

2

−

δj2j(cid:48)

+ δi1i(cid:48)
d(d2 − 1)

1

2

δi2i(cid:48)

1

δj1j(cid:48)

1

δj2j(cid:48)

2

,

(A3)

where vij are the matrix elements of V . Assuming d = 2n, we use the notation i = (i1, . . . in) to denote a bitstring of
length n such that i1, i2, . . . , in ∈ {0, 1}.
Useful Identities. We use the following identities, which can be derived using Eq. (A3) (see [28] for a review):

(cid:90)

dµ(W ) Tr

(cid:104)

W AW †B

(cid:90)

(cid:104)

dµ(W ) Tr

W AW †BW CW †D

(cid:105)

(cid:105)

=

=

Tr[A] Tr[B]
d

,

(A4)

Tr[A] Tr[C] Tr[BD] + Tr[AC] Tr[B] Tr[D]
d2 − 1

−

Tr[AC] Tr[BD] + Tr[A] Tr[B] Tr[C] Tr[D]
d (d2 − 1)

,

(A5)

(cid:90)

dµ(W ) Tr

(cid:104)
W AW †B

(cid:105)

Tr

(cid:104)

W CW †D

(cid:105)

=

Tr[A] Tr[B] Tr[C] Tr[D] + Tr[AC] + Tr[BD]
d2 − 1

−

Tr[AC] Tr[B] Tr[D] + Tr[A] Tr[C] Tr[BD]
d (d2 − 1)

,

where A, B, C, and D are linear operators on a d-dimensional Hilbert space.

Let A ∈ L(H) and B ∈ L(H(cid:48)). Then the following identity holds:

Tr[A]Tr[B] = Tr[A ⊗ B].

(A6)

(A7)

Let A, B ∈ L(H), where H is a d2-dimensional Hilbert space. Then from Eq. (A3), we derive the following integral:

(cid:90)

dµ(U )Tr[AU ⊗

2BU †⊗

2] =

Tr[A]Tr[B] + Tr[AW ]Tr[BW ]
d2 − 1

−

Tr[AW ]Tr[B] + Tr[A]Tr[BW ]
d(d2 − 1)

(A8)

where W is the subsystem swap operator, i.e., W |i(cid:105)|j(cid:105) = |j(cid:105)|i(cid:105).

(cid:54)
B. Deﬁnitions of Expressibility

14

In broad terms a parameterized quantum circuit can be considered expressive if the circuit can be used to uniformly
explore the unitary group U(d). Thus, the expressiblity of a circuit can be deﬁned in terms of the following super-
operator

(cid:90)

A(t)

U (·) :=

(d)

U

dµ(V )V ⊗

t( · )(V †)⊗

t −

(cid:90)

U

dU U ⊗

t( · )(U †)⊗

t

(B1)

where dµ(V ) is the volume element of the Haar measure and dU is the volume element corresponding to the uniform
distribution over U. If A(t)
U (X) = 0 for all operators X then the averaging over elements of U agrees with averaging
over the Haar distribution up to the t-th moment. In this case U is said to form a t-design. For our purposes it suﬃces
to consider the behavior of A(t)
U (·) as AU(·). In the
context of minimizing a generic cost C of the form speciﬁed by Eq. (1), we are interested in the quantities

U for t = 2. Henceforth, we drop the t-superscript and denote A(2)

ερ
U := ||AU(ρ⊗
εH
U := ||AU(H ⊗

2)||2
2)||2 .

(B2)

(B3)

The quantities ερ

U and εH

U may be more readily computed by relating them to a generalization of the frame potential.

To demonstrate how, let us ﬁrst recall that the frame potential [48, 56] of an ensemble U may be deﬁned as

FU :=

(cid:90)

(cid:90)

U

U

dU dV |(cid:104)0|(U V †)|0(cid:105)|4 ,

(B4)

where dU and dV are volume elements corresponding to the distribution over U. We then note that the quantity
||AU(|0(cid:105)(cid:104)0|)||2

2 can be rewritten in terms of FU as follows

||AU(|0(cid:105)(cid:104)0|)||2

2 =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:90)

(cid:90)

U
(cid:90)

(d)

dµ(V ) V ⊗

2(|0(cid:105)(cid:104)0|)(V †)⊗

2 −

(cid:90)

dU dV |(cid:104)0|(U V †)|0(cid:105)|4 − 2

dU dV |(cid:104)0|(U V †)|0(cid:105)|4 −

U

(d)
(cid:90)

(cid:90)

dU U ⊗

2(|0(cid:105)(cid:104)0|)(U †)⊗

2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2

2

dµ(V )dU |(cid:104)0|(U V †)|0(cid:105)|4 +

(cid:90)

U
(cid:90)

U

dµ(U )dµ(V )|(cid:104)0|(U V †)|0(cid:105)|4

(d)

U

(d)

U

=

=

U

U

(cid:90)

(cid:90)

U

U

= FU − FHaar ,

(cid:90)

(cid:90)

(d)

U

(d)

U

dµ(U )dµ(V )|(cid:104)0|(U V †)|0(cid:105)|4

where we use the left and right invariance of the Haar measure, i.e. Eq. (A2), as in Ref. [56], and where we deﬁned

(B5)

FHaar :=

(cid:90)

(cid:90)

(d)

U

(d)

U

dµ(U )dµ(V )|(cid:104)0|(U V †)|0(cid:105)|4 =

1
(2n + 1)2n

1 .

−

(B6)

In the context of the expressibility of a VQA we are interested in the more general quantity ||AU(X ⊗

is a quantum state ρ or Hamiltonian H. Following the same approach as in Eq. (B5), we note that ||AU(X ⊗
be rewritten as

2)||2 where X
2)||2 can

||AU(X ⊗

2)||2 =

(cid:113)

F (X)

U − F (X)

Haar ,

where we have deﬁned the operator dependent frame-potential as

F (X)
U

:=

(cid:90)

(cid:90)

U

U

dU dV Tr[XU †V XV †U ]2

and

F (X)

Haar :=

U
The latter can be evaluated using Eq. (A6) to give

U

(d)

(d)

(cid:90)

(cid:90)

dµ(U )dµ(V )Tr[XU †V XV †U ]2 .

F (X)

Haar =

Tr[X]4 + Tr[X 2]2
22n − 1

−

2Tr[X 2]Tr[X]2
2n(22n − 1)

.

(B7)

(B8)

(B9)

(B10)

Thus our expressibility measures can be related to state and Hamiltonian dependent frame potentials via

ερ
U := ||AU(ρ⊗

2)||2 =

εH
U := ||AU(H ⊗

2)||2 =

(cid:113)

F (ρ)
(cid:113)

U − F (ρ)
Haar
U − F (H)

F (H)

Haar .

15

(B11)

(B12)

We will use these expressions to evaluate the expressiblity of diﬀerent ansätze in Appendix G

C. Proof for Eq. (8)

For a random layered parametrized ansatz of the form Eq. (2) and Eqs. (11)–(12), and the generic cost deﬁned in

Eq. (1), we now show that (cid:104)∂kC(cid:105)U = 0 for all k and therefore the cost landscape is unbiased.

To do so, let us ﬁrst note that the cost function can be expressed as

where we introduce the shorthand

C = Tr[Uk(θk)(cid:101)ρUk(θk)† (cid:101)H].

(cid:101)ρ = Wk





Uj(θj)Wj

 ρ




k
1
(cid:89)
−



j=1

k
1
(cid:89)
−

j=1



†

Uj(θj)Wj



W †k ,

(cid:101)H = UL(θ)†HUL(θ).

(C1)

(C2)

(C3)

This rewriting emphasises the dependence of C on Uk(θk), the rotation we are taking the partial derivative with
respect to, by associating UL with the Hamiltonian H and

with ρ.

(cid:16)(cid:81)k

(cid:17)

1

j=1 Uj(θj)Wj
−

It follows that that

∂kC = −iTr[VkUk(θk)(cid:101)ρUk(θk)† (cid:101)H] + iTr[Uk(θk)(cid:101)ρUk(θk)†Vk (cid:101)H]

= −iTr[Vk(cos(θk) − i sin(θk)Vk)(cid:101)ρ(cos(θk) + i sin(θk)Vk) (cid:101)H]

(cid:16)

= −i

+ iTr[(cos(θk) − i sin(θk)Vk)(cid:101)ρ(cos(θk) + i sin(θk)Vk)Vk (cid:101)H]

(cid:17)
(cos(θk)2 − sin(θk)2)(Tr[Vk (cid:101)ρ (cid:101)H] − Tr[(cid:101)ρVk (cid:101)H]) + i sin(2θk)(Tr[Vk (cid:101)ρVk (cid:101)H] − Tr[(cid:101)ρ (cid:101)H])

.

Since (cid:82) 2π
0

sin(2θk) = 0 and (cid:82) 2π

0

cos(θk)2 = (cid:82) 2π

0

sin(θk)2, uniform averaging of ∂kC over θk leads to

which implies that (cid:104)∂kC(cid:105)U = 0.

1
2π

(cid:90) 2π

0

dθk∂kC = 0,

(C4)

(C5)

(C6)

(C7)

D. Variance of the partial derivative derivation

For a random layered parametrized ansatz of the form Eqs. (2) and (11)–(12), and the generic cost deﬁned in

Eq. (1), then since

where UL and UR are deﬁned in Eq. (12), it follows that the partial derivative of the cost can be written as

∂kU (θ) = −iULVkUR

∂kC :=

∂C
∂θk

= iTr[URρU †R[Vk, U †LHUL]] .

Since the average derivative of the cost vanishes, as discussed in Appendix C, its variance is given by

Var ∂kC = (cid:104)(∂kC)2(cid:105)U .

Eq. (D2) and Eq. (D3) provide the starting point to derive the bounds Eqs. (14)–(16) and Eqs. (19)–(21).

(D1)

(D2)

(D3)

1. Bound in Eq. (14).

16

Note that two diﬀerent ensembles UL and UR can be generated using UL(θ) and UR(θ), respectively, as deﬁned in
Eq. (11). Let dUL and dUR denote volume elements corresponding distributions over UL and UR, respectively. Since
UL and UR are independent, from the deﬁnition of dU and from Eq. (11), we get that dU = dULdUR.

Then by substituting Eq. (D2) into Eq. (D3) and using Eq. (A7), we get

Var∂kC = −

(cid:90)

(cid:90)

dUL

UL

UR

dURTr[U ⊗

2
R ρ⊗

2U †R

2

⊗

X ⊗

2
Lk ]

where

Next we substitute in AR(ρ⊗

2) to give

XLk := [Vk, U †LHUL].

Var∂kC = −

(cid:90)

UL

(cid:90)

dUL

= VarR∂kC +

(d)

U
(cid:90)

UL

dµ(U )Tr[U ⊗

2
Haarρ⊗

2U †⊗

2
HaarX ⊗

2
Lk ] +

(cid:90)

UL

dULTr[AR(ρ⊗

2
2)X ⊗
Lk ]

dULTr[AR(ρ⊗

2)X ⊗

2
Lk ]

(D4)

(D5)

(D6)

where in the second line we use the explicit deﬁnition of VarR∂kC, the variance in the partial derivative of the cost
when UR forms a 2-design, i.e.,

VarR∂kC := −

(cid:90)

UL

(cid:90)

dUL

(d)

U

Rearranging we are left with

dµ(U )Tr[U ⊗

2
Haarρ⊗

2U †⊗

2
HaarX ⊗

2
Lk ] .

|Var ∂kC − VarR∂kC| (cid:54)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:90)

UL

dULTr[AR(ρ⊗

2)X ⊗

2
Lk ]

(cid:12)
(cid:12)
(cid:12)
(cid:12)

which on using the triangle inequality followed by the Cauchy-Schwarz inequality reduces to

|Var ∂kC − VarR∂kC| (cid:54)

(cid:54)

(cid:90)

UL

(cid:90)

UL

dUL|Tr[AR(ρ⊗

2
2)X ⊗
Lk ]|

dUL||X ⊗

Lk ||2||AR(ρ⊗

2

2)||2 .

The term ||X ⊗

Lk ||2 can be bounded as follows. First we note that X †Lk = −XLk, which implies that

2

2

||X ⊗

Lk ||2 =

(cid:113)

Tr[X ⊗

2
2
Lk ] =
Lk X ⊗

(cid:113)

Tr[X 2

Lk ⊗ X 2

Lk] = |Tr[X 2

Lk]| = |Tr[[Vk, U †LHUL]2]| .

(D7)

(D8)

(D9)

(D10)

Let A = Vk and B = U †LHUL. Since A and B are Hermitian, from the triangle inequality and the Cauchy-Schwarz
inequality, we get

|Tr[[A, B]2]| = 2|Tr[ABAB]−Tr[A2B2]| (cid:54) 2[|Tr[ABAB]|+|Tr[B2]|] (cid:54) 2

(cid:112)

Tr[ABAABA]Tr[B2]+2|Tr[B2]| = 4|Tr[B2]| .
(D11)

Therefore, we ﬁnd that

||X ⊗

2

Lk ||2 (cid:54) 4Tr[(U †LHUL)2] = 4Tr[H 2] = 4||H||2
2 .

Hence the bound takes the form

|Var ∂kC − VarR∂kC| (cid:54) 4

(cid:90)

UL

dUL||AR(ρ⊗

which completes the proof.

2)||2||H||2

2 = 4||AR(ρ⊗

2)||2||H||2
2 ,

(D12)

(D13)

Extension to generalized cost. This result can be further extended to cost functions of the following form

C(θ) =

(cid:88)

m

Tr[HmU (θ)ρmU (θ)†] ,

for which the derivative with respect to the parameter θk can be written as

∂kC = i

(cid:88)

m

Tr[URρmU †R[Vk, U †LHmUL]] .

Therefore, from Eq. (D7) it follows that

Var∂kC = −

(cid:90)

(cid:88)

m,n

UL

dUL

(cid:90)

UR

dURTr[U ⊗

R (ρm ⊗ ρn)(U †R)⊗

2

2X m

Lk ⊗ X n

Lk],

where X m

Lk is deﬁned in Eq. (D5) with H = Hm.

After substituting AR(ρj ⊗ ρk), we get

Var∂kC = VarR∂kC +

(cid:90)

(cid:88)

m,n

UL

dULTr[AR(ρm ⊗ ρn)(X m

Lk ⊗ X n

Lk)],

which implies that

|Var ∂kC − VarR∂kC| (cid:54) (cid:88)

m,n
(cid:54) (cid:88)
m,n
(cid:54) (cid:88)
m,n

(cid:90)

UL

(cid:90)

UL

dUL|Tr[AR(ρm ⊗ ρn)(X m

Lk ⊗ X n

Lk)]|

dUL(cid:107)AR(ρm ⊗ ρn)(cid:107)2(cid:107)(X m

Lk ⊗ X n

Lk)(cid:107)2

(cid:107)AR(ρm ⊗ ρn)(cid:107)2

(cid:113)

Tr[(X m

Lk)2]Tr[(X n

Lk)2]

(cid:54) 4

(cid:88)

m,n

(cid:107)AR(ρm ⊗ ρn)(cid:107)2(cid:107)Hm(cid:107)2(cid:107)Hn(cid:107)2 ,

where we used steps similar to those used in deriving Eqs. (D10)–(D13).

2. Bound in Eq. (15).

Substituting Eq. (D2) into Eq. (D3), using Eq. (A7), and the cyclicity of the trace operation, we ﬁnd that

Var∂kC =

(cid:90)

(cid:90)

dUL

UL

UR

2
L H ⊗
dURTr[U †⊗

2UL⊗

2Y ⊗

2
Rk ]

17

(D14)

(D15)

(D16)

(D17)

(D18)

(D19)

(D20)

(D21)

(D22)

where YRk := [URρU †R, Vk]. The rest of the derivation proceeds in the same manner as for the bound in Eq. (14).

Extension to generalized cost. Similar to Eq. (D21), the bound in Eq. (15) can be extended for the cost functions

of the form in Eq. (D14). In particular, we ﬁnd that

|Var∂kC − VarL∂kC| (cid:54) 4

(cid:88)

m,n

(cid:107)AL(Hm ⊗ Hn)(cid:107)2(cid:107)ρm(cid:107)2(cid:107)ρn(cid:107)2 .

(D23)

To derive Eq. (16) we start by substituting Eq. (D2) into Eq. (D3), using Eq. (A7), and the cyclicity of the trace

3. Bound in Eq. (16).

operation to ﬁnd that

Var∂kC = −

(cid:90)

(cid:90)

dUL

UL

UR

dURTr[ρ⊗

2

R (V ⊗

2
k H ⊗

L + H ⊗

2
2
L V ⊗

k − 2(Vk ⊗ 1)H ⊗

L (1 ⊗ Vk))]

2

2

(D24)

where we have introduced the short hand ρR := URρU †R and HL := U †LHUL. Next we substitute in AL(H ⊗
AR(ρ⊗

2) to ﬁnd that the variance is given by

Var∂kC = VarL,R∂kC − Tr[AR(ρ⊗

2)ZLk] + I1 + I2 .

Here we deﬁned

Zxk := (V ⊗

k Ax(ωx) + Ax(ωx)V ⊗

2

k − 2(Vk ⊗ 1)Ax(ωx)(1 ⊗ Vk))

2

for x = L and x = R, and where ωR = ρ and ωL = H. The integrals I1 and I2 are given by

(cid:90)

I1 =

I2 =

(d)

U

(cid:90)

(d)

U

dµ(U )Tr[ZLk ˜ρ⊗

2]

dµ(U )Tr[AR(ρ⊗

2)(V ⊗
k

2

˜H ⊗

2 + ˜H ⊗

2
2V ⊗

k − 2(Vk ⊗ 1) ˜H ⊗

2(1 ⊗ Vk)] .

with ˜ρ = U ρU † and ˜H = U †HU .

The integrals I1 and I2 can be evaluated using Eq. (A8) as follows:

I1 =

I2 =

1
d2 − 1
1
d2 − 1

Tr[ZLkW ]Tr[ρ2] −

Tr[ZLkW ] ,

Tr[ZRkW ]Tr[H 2] −

Tr[ZRkW ]Tr[H]2,

1
d(d2 − 1)
1
d(d2 − 1)

18

2) and

(D25)

(D26)

(D27)

(D28)

where we used the fact that Tr[ZLk] = Tr[ZRk] = 0, Tr[ρ⊗

2W ] = Tr[ρ2], and Tr[H ⊗

2W ] = Tr[H 2].

Substituting these integrals, Eq. (D28), back into Eq. (D25) and then using the triangle inequality gives

|Var ∂kC − VarR,L∂kC| (cid:54) 1

d2 − 1

((Tr[ρ2] − 1/d)|Tr[ZLkW ]| + (Tr[H 2] − Tr[H]2/d)|Tr[ZRkW ]|) + |Tr[AR(ρ⊗

2)ZL,k]| .
(D29)

Using Cauchy-Schwarz this reduces to

|Var ∂kC − VarR,L∂kC| (cid:54) d

d2 − 1

((||ρ||2

2 − 1/d)||ZLk||2 + (||H||2

2 − Tr[H]2/d)||ZRk||2) + ||AR(ρ⊗

2)||2||ZLk||2 . (D30)

where we have used ||W ||2 = d. Finally, by expanding ||Zxk||2, using the triangle inequality and the fact that V 2
we ﬁnd that

k = 1

||Zxk||2 (cid:54) 4||Ax(ωx)||2

(D31)

for x = L and x = R, and where ωR = ρ and ωL = H. Thus we are left with

|Var ∂kC − VarR,L∂kC|

(cid:54) 4||AR(ρ⊗

2)||2||AL(H ⊗

2)||2 +

2n+2
22n − 1

(cid:18)

||AR(ρ⊗

2)||2(||H||2

2 −

1
d

Tr[H]2) + ||AL(H ⊗

2)||2(||ρ||2

2 −

(cid:19)
)

1
d

. (D32)

Extension to generalized cost. Similar to Eqs. (D21) and (D23), the bound in Eq. (16) can be extended for the

cost functions of the form in Eq. (D14). In particular, we ﬁnd that

|Var ∂kC − VarR,L∂kC|
(cid:88)

(cid:54) 4

||AR(ρm ⊗ ρn)||2||AL(Hm ⊗ Hn)||2

m,n

+

2n+2
22n − 1

(cid:88)

m,n

(cid:18)

(cid:18)

||AR(ρm ⊗ ρn)||2

Tr[HmHn] −

1
d

(cid:19)

(cid:18)

Tr[Hm]Tr[Hn]

+ ||AL(Hm ⊗ Hn)||2

Tr[ρmρn] −

(cid:19)(cid:19)

.

1
d

(D33)

4. Reformulating bounds using the diamond norm.

Here we derive bounds Eqs. (19)-(21), in which the expressiblity is quantiﬁed in terms of the diamond norm. This is
a natural alternative way of formulating the bounds, since the diamond norm is an operationally meaningful measure
of the distinguishability of two quantum operations that is often used to deﬁne ε-approximate t-designs.

To derive Eq. (19) we start with Eq. (D9) and invoke the Hölder’s inequality as follows:

19

|Var ∂kC − VarR∂kC| (cid:54)

(cid:54)

(cid:90)

UL

(cid:90)

UL

dUL|Tr[AR(ρ⊗

2)X ⊗

2
Lk ]|

dUL||X ⊗

2
Lk ||

∞

||AR(ρ⊗

2)||1 .

(D34)

The term ||X ⊗
and sub-multiplicativity of the inﬁnity norm that

∞

2
Lk ||

can now be bounded as follows. Given that X †Lk = −XLk, it follows from the unitary invariance

2
||X ⊗
Lk ||
We additionally note that ||E(X)||1 (cid:54) (cid:107)X(cid:107)1||E||

= (||XLk||

)2 (cid:54) (2||Vk||

∞

∞

||U †LHUL||

∞

)2 = (2||Vk||

∞

||H||

∞

)2 (cid:54) 4||H||2
∞

∞

for any channel E and operator X, therefore

(cid:5)

Thus we are now left with

||AR(ρ⊗

2)||1 (cid:54) (cid:107)ρ(cid:107)1||AUR ||
(cid:5)

= ||AUR ||
(cid:5)

:= ε(cid:5)R .

|Var ∂kC − VarR∂kC| (cid:54) 4||H||2
∞

ε(cid:5)R .

(D35)

(D36)

(D37)

The derivation of Eq. (20) is entirely analogous.

To derive Eq. (21) we start with Eq. (D29) and again use Hölder’s inequality in terms of the inﬁnity and one norm

to ﬁnd
|Var ∂kC − VarR,L∂kC| (cid:54) 1

d2 − 1

((||ρ||2

2 − 1/d)||ZLk||1 + (||H||2

2 − Tr[H]2/d)||ZRk||1) + ||AR(ρ⊗

2)||1||ZLk||

∞

, (D38)

where we have used ||W ||
k = 1 we ﬁnd that
V 2

∞

= 1. Finally, by expanding ||Zxk||

∞

, using the triangle inequality and and the fact that

||Zxk||

∞

k Ax(ωx)||
||

(cid:54) ||V ⊗
2
(cid:54) 2||V ⊗
k
∞
(cid:54) 4||Ax(ωx)||

2

∞

∞
||Ax(ωx)||

+ ||Ax(ωx)V ⊗
k
+ 2||(Vk ⊗ 1)||

∞

||

2

∞

+ 2||(Vk ⊗ 1)Ax(ωx)(1 ⊗ Vk)||

||Ax(ωx)||

∞

||(1 ⊗ Vk)||

∞

∞

∞

(D39)

for any channel E and operator X, therefore,

for x = L and x = R. We additionally note that ||E(X)||1 (cid:54) (cid:107)X(cid:107)1||E||
(cid:54) ||AR(ρ⊗

||AR(ρ⊗
2)||

2)||
∞
(cid:54) ||AL(H ⊗

∞

||AL(H ⊗

(cid:5)
2)||1 (cid:54) ε(cid:5)R
2)||1 (cid:54) (cid:107)H(cid:107)1ε(cid:5)L

(D40)

(D41)

Thus we are left with
|Var ∂kC−VarR,L∂kC| (cid:54) 4

d2 − 1

or alternatively

((||ρ||2

2−1/d)||AL(H)||

∞

+(||H||2

2−Tr[H]2/d)||AR(ρ⊗

2)||

∞

)+4||AR(ρ)||1||AL(H ⊗

2)||
∞
(D42)

|Var ∂kC − VarR,L∂kC| (cid:54) 4

d2 − 1

((||ρ||2

2 − 1/d)(cid:107)H(cid:107)1ε(cid:5)

L + (||H||2

2 − Tr[H]2/d)ε(cid:5)

R) + 4(cid:107)H(cid:107)1 ε(cid:5)

Rε(cid:5)

L .

(D43)

E. Variance in partial derivative for exact 2-designs.

In this Appendix, we provide the explicit expressions and the derivation of the variance in the partial derivative
for a random layered parametrized ansatz of the form Eqs. (2) and (11)–(12), and the generic cost deﬁned in Eq. (1).
These quantities have been investigated in [27]; however, only the highest order terms in n were given. Here we
provide higher order terms for completeness.

Explicit expressions Let us denote the variance of the cost when just UR, just UL, and both UR and UL form

2-designs as VarR∂kC, VarL∂kC, and VarR,L∂kC, respectively. These variances are given by

20

where

gR(ρ, H, U ) = −

gL(ρ, H, U ) = −

(cid:18)

Tr(ρ2) −

(cid:18)

Tr(H 2) −

gR,L(ρ, H, U ) = −2

(cid:16)

Tr(ρ2) −

−

1
2n(22n − 1)

Derivation From Eq. (D2), we have

(cid:19) (cid:90)

1
2n
Tr[H]2
2n
1
2n

(cid:17)(cid:16)

Varx∂kC =

gx(ρ, H, U )
22n − 1

,

dULTr([Vk, U †LHUL]2)
(cid:19) (cid:90)

dURTr([Vk, U †RHUR]2)

[Tr(Vk)2Tr(H 2) + Tr(V 2

1
22n − 1
k )Tr(H 2) + Tr(Vk)2Tr(H)2] −

[Tr(V 2

k )Tr(H)2]

1
2n Tr(V 2

k )Tr(H 2)

(cid:17)

∂kC :=

∂C
∂θk

= iTr[URρU †R[Vk, U †LHUL]] .

Since the cost gradient is unbiased, as in Eq. (8), the variance in the partial derivative is given by

Var∂kC = −

(cid:90)

(cid:90)

dUL

dURTr(URρU †R[Vk, U †LHUL])2.

Then VarR∂kC, VarL∂kC, and VarR,L∂kC can be calculated by the integration in Eq. (E6) over UR, UL, and both

UR and UL, respectively.

Integrating over only UR gives

VarR∂kC = −

(cid:90)

1
d2 − 1

dUL(Tr(ρ)2Tr([Vk, U †LHUL])2 + Tr(ρ2)Tr([Vk, U †LHUL]2))

(cid:90)

dUL(Tr(ρ2)Tr([Vk, U †LHUL])2 + Tr(ρ)2Tr([Vk, U †LHUL]2))

dULTr(ρ2)Tr([Vk, U †LHUL]2) +
(cid:19) (cid:90)

(cid:19) (cid:18) 1

d2 − 1

dULTr([Vk, U †LHUL]2) ,

(cid:90)

1
d(d2 − 1)

dULTr([Vk, U †LHUL]2)

+

1
d(d2 − 1)
(cid:90)
1
d2 − 1
(cid:18)

Tr(ρ2) −

1
d

= −

= −

where the ﬁrst equality follows from Eq. (A6) and the second equality follows from the fact that the trace of a
commutator is always zero.

Form the cyclicity of the trace operation and the arguments similar to Eqs. (E7) and (E8), we get

VarL∂kC = −

(cid:18)

Tr(H 2) −

Tr[H]2
d

(cid:19) (cid:18) 1

(cid:19) (cid:90)

d2 − 1

dURTr([Vk, U †RHUR]2) .

(E10)

In order to calculate VarR,L∂kC, we note that Tr([Vk, U †LHUL]2) in Eq. (E9) can be written as

Tr([Vk, U †LHUL]2) = 2[Tr(ULVkU †LHULVkU †LH) − Tr(ULV 2

k U †LH 2)] .

(E11)

The integral of the ﬁrst term over UL in Eq. (E11) can be calculated using Eq. (A5) as follows:

(cid:90)

dULTr(ULVkU †LHULVkU †LH)

=

1
d2 − 1

[Tr(Vk)2Tr(H 2) + Tr(V 2

k )Tr(H)2] −

1
d(d2 − 1)

[Tr(V 2

k )Tr(H 2) + Tr(Vk)2Tr(H)2]. (E12)

(E1)

(E2)

(E3)

(E4)

(E5)

(E6)

(E7)

(E8)

(E9)

The integral of the second term in Eq. (E11) can be calculated using Eq. (A4) as follows:

(cid:90)

dULTr[ULV 2

k U †LH 2] =

Tr(V 2

k )Tr(H 2)

d

.

Finally, after combining everything we get

VarR,L∂kC = −

(cid:16)

Tr(ρ2) −

(cid:17)(cid:16)

1
d

2
d2 − 1

(cid:17)(cid:16)

1
d2 − 1

[Tr(Vk)2Tr(H 2) + Tr(V 2

k )Tr(H)2]
(cid:17)
k )Tr(H 2)

Tr(V 2

−

1
d(d2 − 1)

[Tr(V 2

k )Tr(H 2) + Tr(Vk)2Tr(H)2] −

1
d

F. Concentration of measure

21

(E13)

(E14)

In Ref. [33] it was shown that for ansätze where the reduced state on the measured qubits obeys a volume law,
typical local cost function values concentrate exponentially fast in n to its mean. This result was complemented by
a proof that for ansätze that form 2-designs, i.e. maximally expressive ansätze, local costs concentrate exponentially
fast to a ﬁxed value. Here we show that this proof may be generalised to non-perfectly expressive ansätze.

Speciﬁcally we show that for a k-local cost Ck we have that

(cid:104)|Ck − Tr((Hk ⊗ 1)1/d)|(cid:105) (cid:54) ||Hk||

∞

(cid:32)(cid:115)(cid:90)

dUHaarTr((U ⊗ U )(σ ⊗ σ)(U † ⊗ U †)(W ⊗ 1)))

(cid:33)

+ ||Hk||

∞

√

χ(cid:15) ,

(F1)

where

(cid:32)(cid:115)(cid:90)

dUHaarTr((U ⊗ U )(σ ⊗ σ)(U † ⊗ U †)(W ⊗ 1)))

∈ O

(cid:33)

(cid:32)(cid:114)

(cid:33)

.

2k
2n

Here χ(cid:15) is an expressibility dependent correction deﬁned as

χ(cid:15) := Tr(AU(|0(cid:105)(cid:104)0|)(W ⊗ 1))) ,

where, as previously, W is the subsystem permuation operator.

Proof. The start of the proof of is identical to Ref. [33].

(cid:104)|Ck − Tr((Hk ⊗ 1)1/d)|(cid:105) =

(cid:90)

dU |((Hk ⊗ 1) (cid:0)U |0(cid:105)(cid:104)0|U † − 1/d(cid:1))|

(cid:90)

(cid:115)

(cid:54) ||Hk||

∞

(cid:54) ||Hk||

∞

dU ||Trk((cid:0)U |0(cid:105)(cid:104)0|U † − 1/d(cid:1))||1

(cid:90)

2k

dU ||Trk((U |0(cid:105)(cid:104)0|U † − 1/d))||2

2

(cid:115)(cid:90)

(cid:115)(cid:90)

= ||Hk||

∞

= ||Hk||

∞

dU Tr((U |0(cid:105)(cid:104)0|U † − 1/d) ⊗ (U |0(cid:105)(cid:104)0|U † − 1/d) (W ⊗ 1)))

dU Tr((U ⊗ U )(σ ⊗ σ)(U † ⊗ U †)(W ⊗ 1)))

(F2)

(F3)

(F4)

where σ = |0(cid:105)(cid:104)0| − 1/d. The ﬁrst inequality follows from Hölder’s inequality. For the second inequality, we used the
relation between the trace norm and the Hilbert-Schmidt norm and invoked Jensen’s inequality. We used k to denote
qubits that are not measured for deﬁning the cost function Ck.
We now substitute in the deﬁnition of AU(|0(cid:105)(cid:104)0|) to get that

(cid:90)

dU Tr((U ⊗U )(σ⊗σ)(U † ⊗U †)(W ⊗1))) =

(cid:90)

dUHaarTr((U ⊗U )(σ⊗σ)(U † ⊗U †)(W ⊗1)))+Tr(AU(|0(cid:105)(cid:104)0|)(W ⊗1))) .
(F5)

22

Introducing the short hand Tr(AU(|0(cid:105)(cid:104)0|)(W ⊗ 1))) = χ(cid:15) to denote the expressibility dependent correction we can
then write

(cid:104)|Ck − Tr((Hk ⊗ 1)1/d)|(cid:105) (cid:54) ||Hk||

∞

(cid:115)(cid:90)

dUHaarTr((U ⊗ U )(σ ⊗ σ)(U † ⊗ U †)(W ⊗ 1))) + χ(cid:15)

(cid:32)(cid:115)(cid:90)

(cid:54) ||Hk||

∞

dUHaarTr((U ⊗ U )(σ ⊗ σ)(U † ⊗ U †)(W ⊗ 1))) +

(F6)

(cid:33)

√

χ(cid:15)

where we have used
proof.

√

a + b (cid:54)

√

√

a +

b. Moreover, Eq. F2 follows from Theorem 2 in [68], which completes the

G. Numerically studying the correlations between expressibility and cost partial derivatives

In this Appendix we present numerical results on the correlations between the cost gradient and expressibility.
Speciﬁcally, we consider the layered parametrized ansatz detailed in Section III B of the main text and plot the
variance in the PQC gradients as a function of its expressibility.

We can calculate the expressibility measures ερ
and F (H)

L via their reformulation in terms of the state and Hamiltonian
dependent frame potentials F (ρ)
given in Eq. (B11). However, since it follows from Eq. (B10)
Haar (F (H)
that the state (Hamiltonian) dependent frame potential for the Haar distribution F (ρ)
Haar) is exponentially small,
Haar), it follows that ερ
and ερ
R (εH
L ) may also
be exponentially small. We therefore ﬁnd the ratio of the true frame potential to the Haar frame potential more
insightful to plot. That is, we consider the ratios

L ) measures the diﬀerence between F (ρ)

R and εH
:= F (ρ)
UL

R and F (ρ)

R := F (ρ)
UR

Haar (F (H)

and F (H)

R (εH

L

L

F (ρ)
R
F (ρ)
Haar
F (H)
L
F (H)
Haar

=

=

(ερ
U )2
F (ρ)
Haar
(εH
U )2
F (H)
Haar

+ 1

+ 1 .

(G1)

(G2)

The larger these ratios, the more inexpressive the ansatz, with the ratios tending to 1 for maximally expressive ansätze
(exact 2-designs).

(ρ)
R
(ρ)
Haar

(H)
and F
L
(H)
Haar
F

respectively. Inline

In Fig. 7 and Fig. 8 we plot the variance in the partial derivative as a function of F
F

with Section III B of the main text, we focus on three diﬀerent ways of tuning the expressibility of an ansatz; namely
decreasing the depth of the circuits, correlating circuit parameters, and restricting either the direction of rotations.

To numerically quantify the degree of correlations between the variance in the partial derivative of the cost and the
expressibility we include in Fig. 7 and Fig. 8 the Spearman correlation coeﬃcient [69] and its corresponding p-value.
Overall we ﬁnd a clear correlation between partial derivatives of the cost and expressibility, with the variance in
the derivatives increasing with increasing F (ρ)
L . Speciﬁcally, combining all the diﬀerent ways of tuning the
expressibility, the Spearman coeﬃcient for the correlation between the variance in the partial derivative of the cost
and the (cid:15)ρ was found to be 0.78 with a p-value of 1.19 × 10−
7. Similarly, for the correlations with (cid:15)H was 0.80 with
a p-value of 1.18 × 10−

R and F (H)

7.

It is noteworthy that the Hamiltonian dependent frame potential captures the eﬀect of locality on cost gradients
as the circuit depth is tuned. As observed in Section III B, increasing the depth of the circuit reduces cost partial
derivatives for a local cost but not a global cost. The state dependent frame potential cannot capture this eﬀect since
it is independent of the choice in measurement operator H and therefore necessarily independent of the locality of H.
Conversely, the while the Hamiltonian frame potential for a local cost decreases with increasing depth, inline with the
decreasing variance in partial derivatives, the Hamiltonian dependent frame potential for the global cost is eﬀectively
constant (even as the depth of the circuit substantially increases) reﬂecting the eﬀectively constant variance in partial
derivatives.

Nonetheless, the correlation between the variance in the cost partial derivative and the expressibility is not perfect,
as is clear for example, from Fig. 8(F). This is entirely compatible with our analytical bounds, which are upper bounds
and therefore do not enforce perfect correlation between the variance in the partial derivative and the expressibility.
Thus while Fig. 7 and Fig. 8 demonstrate a clear correlation between the variance in the partial derivative of the cost
and expressibility, further work is required to understand the intricacies of this correlation.

23

FIG. 7. Correlations between cost partial derivatives and the state-dependent frame potential. The variance in
the partial derivative of a global cost with H = (cid:81)n
2 (bottom) as a function of the
expressibility measure F
(in both cases ρ = |ψ0(cid:105)(cid:104)ψ0|⊗n where |ψ0(cid:105) = exp(−i(π/8)σY )|0(cid:105)). In the left panel we vary the
F

i (top) and 2-local cost with H = σz

i=1 σz

1 σz

(ρ)
R
(ρ)
Haar

circuit depth D of a hardware eﬃcient ansatz. In the right (middle) panel we consider the eﬀect of correlating parameters
(restricting the directions of rotation) of a hardware eﬃcient ansatz with D = 100 with the choices of correlations (rotations)
In all cases n = 4, the derivative is taken with respect to θ1
D and the variance and frame
indicated in the ﬁgure legend.
potentials are estimated using an ensemble of 5000 unitaries.

FIG. 8. Correlations between cost partial derivative and the Hamiltonian-dependent frame potential. This
setting here is entirely equivalent to that described in Fig. 7; however, here we plot the variance in the partial derivative as a
function of the ratio of Hamiltonian-dependent frame potentials F
F

and the derivative is taken with respect to θ1
1.

(H)
L
(H)
Haar

1.01.11.21.31.40.010.040.09Var[∂θC]CircuitDepth(A)Spearman:0.92,p-value:0.0011LocalCostD=2D=4D=8D=16D=25D=50D=100D=1501.01.21.41.60.010.040.090.160.25RestrictingRotationDirections(B)Spearman:1.0,p-value:0.0xyzxy510150.011.00100.00CorrelatingParameters(C)Spearman:0.90,p-value:0.037UncorrelatedCor.QubitsCor.LayersCor.QubitsandLayers(x)Cor.QubitsandLayers(y)1.01.11.21.31.4F(ρ)R/F(ρ)Haar0.010.040.09Var[∂θC](D)Spearman:-0.92,p-value:0.0011GlobalCost1.01.21.41.6F(ρ)R/F(ρ)Haar0.010.040.09(E)Spearman:1,p-value:051015F(ρ)R/F(ρ)Haar0.011.00100.00(F)Spearman:0.90,p-value:0.03724681012140.010.030.050.070.09Var[∂θC]CircuitDepth(a)Spearman:0.96,p-value:10−4LocalCostD=2D=4D=8D=16D=25D=50D=75D=1000102030400.010.030.050.070.09RestrictingRotationDirections(b)Spearman:1.0,p-value:0.0xyzxy051015200.011.00100.00CorrelatingParameters(c)Spearman:0.9,p-value:0.037Uncor.Cor.QubitsCor.LayersCor.Qubits&Layers(x)Cor.Qubits&Layers(y)2468101214F(H)L/F(H)Haar0.010.030.050.070.09Var[∂θC](d)Spearman:0,p-value:0.48GlobalCost010203040F(H)L/F(H)Haar0.010.030.050.070.09(e)Spearman:0.5,p-value:0.6705101520F(H)L/F(H)Haar0.011.00100.00(f)Spearman:1,p-value:0.0