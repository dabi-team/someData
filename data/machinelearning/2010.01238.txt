0
2
0
2

t
c
O
3

]

V
C
.
s
c
[

1
v
8
3
2
1
0
.
0
1
0
2
:
v
i
X
r
a

A Deep Genetic Programming based
Methodology for Art Media Classiﬁcation
Robust to Adversarial Perturbations

Gustavo Olague1, Gerardo Ibarra-V´azquez2, Mariana Chan-Ley1, Cesar
Puente2, Carlos Soubervielle-Montalvo2, and Axel Martinez1

1

EvoVisi´on Laboratory, CICESE Research Center. Carretera Ensenada-Tijuana
3918, Zona Playitas, 22860, Ensenada, B.C., M´exico
Universidad Aut´onoma de San Luis Potos´ı, Facultad de Ingenier´ıa. Dr. Manuel
Nava 8, Col. Zona Universitaria Poniente, 78290, San Luis Potos´ı, S.L.P., M´exico

2

Abstract. Art Media Classiﬁcation problem is a current research area
that has attracted attention due to the complex extraction and analy-
sis of features of high-value art pieces. The perception of the attributes
can not be subjective, as humans sometimes follow a biased interpreta-
tion of artworks while ensuring automated observation’s trustworthiness.
Machine Learning has outperformed many areas through its learning
process of artiﬁcial feature extraction from images instead of designing
handcrafted feature detectors. However, a major concern related to its
reliability has brought attention because, with small perturbations made
intentionally in the input image (adversarial attack), its prediction can be
completely changed. In this manner, we foresee two ways of approaching
the situation: (1) solve the problem of adversarial attacks in current neu-
ral networks methodologies, or (2) propose a diﬀerent approach that can
challenge deep learning without the eﬀects of adversarial attacks. The
ﬁrst one has not been solved yet, and adversarial attacks have become
even more complex to defend. Therefore, this work presents a Deep Ge-
netic Programming method, called Brain Programming, that competes
with deep learning and studies the transferability of adversarial attacks
using two artworks databases made by art experts. The results show that
the Brain Programming method preserves its performance in comparison
with AlexNet, making it robust to these perturbations and competing to
the performance of Deep Learning.

Keywords: Brain Programming · Deep Learning · Symbolic Learning ·
Art Media Classiﬁcation · Adversarial Attacks.

1

Introduction

Art media refers to the materials and techniques used by an artist to create
an artwork. The categorization problem of visual art media is an open research
area with challenging tasks, such as the classiﬁcation of ﬁne art pieces, which is
extremely diﬃcult due to the selection of features that distinguish each medium.

 
 
 
 
 
 
2

G. Olague et al.

For example, an art expert analyzes the style, genre, and media from artworks
to classify them.

The artwork style is associated with the author’s school and is usually de-
scribed by its distinctive visual elements, techniques, and methods. Recognition
of the form is related to the localization of features at diﬀerent levels. The
classical hierarchy of genres ranks history-painting and portrait as high, while
landscapes and still-life are low because they did not contain persons. There-
fore, handling these many aspects of an automated classiﬁcation system is a big
challenge.

The recent progress of Machine Learning (ML) in Computer Vision (CV)
tasks has made methodologies such as Deep Learning (DL) adaptable to many
research areas like the categorization problem of art media. Commonly, these
methodologies learn from the visual content and contextual information of the
image to assign the class or category to which it belongs. DL is known to achieve
exemplary performance in many areas. However, recent studies have demon-
strated that Adversarial Attacks (AA) pose a predicting threat to DL’s success
because with small perturbations intentionally created, they could lead to incor-
rect outputs to a model.

In this matter, AA is a popular research topic covering all aspects of the
attack architectures and defense mechanisms to diminish the attack damage.
Nevertheless, despite signiﬁcant eﬀorts to solve this problem, attacks have be-
come more complex and challenging to defend. Today, researchers study AA
from diﬀerent viewpoints. On the one hand, white-box attacks refer to when
the targeted model is known, including its parameter values, architecture, and
training method. On the other hand, black-box attacks are when AA generates
adversarial examples or perturbed images with no information on the targeted
architecture model during learning [1]. Another feature of the attacks is that
it can be speciﬁcally designed to predict a desirable class (targeted attack) or
produce an incorrect output no matter the class (untargeted attack). Further-
more, it has been reported that AA can be transferable from an ML model
to others. Hence, we foresee two ways to approach the situation: (1) solve the
problem of adversarial attacks in current neural networks methodologies, or (2)
propose a diﬀerent approach that can challenge deep learning by being immune
to adversarial attacks.

This article presents a study of the transferability and the eﬀects of adver-
sarial attacks made for deep learning to an approach that solves the problem
of image classiﬁcation through a genetic programming based (GP-like) method-
ology called “Brain Programming” (BP) (explained in Section 4). Extend the
study of the eﬀects of adversarial attacks on a diﬀerent approach for image clas-
siﬁcation would highlight the diﬀerences between performance and robustness
to these perturbations.

2 Related Research

The categorization problem of art media in CV has arisen from the need to
have automatic systems for identifying valuable artwork pieces to have a trust-

A Deep GP Methodology Robust to Adversarial Perturbations

3

worthy analysis that can not be subjective as humans are prone to be. Firstly,
handcrafted feature extraction approaches were used to solve the problem. One
of the ﬁrst approaches [8] proposed a Discrete Cosine Transform (DCT) co-
eﬃcients scheme for feature extraction for painter identiﬁcation by classifying
the artist’s style. They were able to ﬁnd ﬁve painters among 30 artworks with
encouraging but not perfect results.

Later, wavelets were used to analyze several features from artworks like tex-
ture, geometry, style, brush strokes, and contours. In [13], artist classiﬁcation
was made using wavelets of brush strokes drawn on ancient paintings. In [7],
wavelets were used with several classiﬁcation algorithms such as support vector
machines (SVM), hidden Markov models, among others for artist identiﬁcation
of 101 high-resolution grayscale paintings. In [2], it is presented a comparative
study of diﬀerent classiﬁcation methodologies based handcrafted features such as
semantic-level features with an SVM, color SIFT (Scale-Invariant Feature Trans-
form) and opponent SIFT with bag-of-words and latent Dirichlet allocation with
a generative bag-of-words topic model for ﬁne-art genre classiﬁcation.

Recently, ML approaches beneﬁt from the learning process to acquire features
from the images’ visual content. For example, in [9], they proposed a GP method
that uses transform-based evolvable features to evolve features that are evalu-
ated through a standard classiﬁer. In [4,15], authors reported using a GP-like
methodology that aims to emulate the behavior of the brain based on neuro-
science knowledge for art media categorization having competitive results with
a DL model. Nevertheless, approaches based on convolutional neural network
(CNN) became famous because of their outstanding performances in many ar-
eas. Bar et al[3] proposed a compact binary representation combined with the
PiCoDes descriptors from a deep neural network to identify artistic styles in
paintings showing exceptional results on a large-scale collection of paintings. In
[17], they employ a deep CNN to recognize artistic media from artworks and
classify them into several categories such as oil-paint brush, pastel, pencil, and
watercolor. They compare their results with that of trained humans having com-
parable results.

Thus, even CNN architectures have classiﬁed large-scale sets of images with
multiple classes with similar results that trained humans, the security concerns
about these architectures make them unreliable. The brittleness is because, with
small perturbations produced on the image, DL can be intentionally fooled. For
example, there are critical areas in museums and galleries such as artist identi-
ﬁcation and forgery detection, where the conﬁdence of the prediction must not
depend on a system that can be manipulated by an imperceptible perturbation.
This catastrophic scenario could lead to forgeries to circulate on the market or
be misattributed to a speciﬁc artist.

3 Problem Statement

In this section, we detail the serious problem in the DL structure to the adver-
sarial attacks. First, given an input image x and its corresponding label y, DL
establish a relationship within the data by the following equation:

4

G. Olague et al.

y = f (x) = w⊺x ,

(1)

where function f () is the DL model, whose associated weights parameters
are w. However, an erroneous behavior is notable when the input image suﬀers
a small change in its pixels xρ = x + ρ such that:

f (x) 6= f (xρ)
||x − xρ||p < α

(2)
(3)

where p ∈ N, p ≥ 1, α ∈ R, α ≥ 0. So, it can be deﬁned an Adversarial
Example as an intentional modiﬁed input xρ that is classiﬁed diﬀerently than x
by the DCNN model, with a limited level of change in the pixels of ||x−xρ||p < α,
so that it may be imperceptible to a human eye.

The simplest explanation of how adversarial examples works to attack DL
models is that most digital images use 8-bit per channel per pixel. So, each
step of 1/255 limits the data representation; the information in between is not
used. Therefore, if every element of a perturbation ρ is smaller than the data
resolution, it is coherent for the linear model to predict distinct given an input x
than to an adversarial input xρ = x+ρ. We assume that forasmuch as ||ρ||∞ < α,
where α is too small to be discarded, the classiﬁers should predict the same class
to x and xρ.

Nonetheless, after applying the weight matrix w ∈ RM×N to the adversarial
example, we obtain the dot product deﬁned by w⊺xρ = w⊺x + w⊺ρ. Hence, the
adversarial example will grow the activation by w⊺ρ. Note that the dimensional-
ity of the problem does not grow with ||ρ||∞; thus, the activation change caused
by perturbation ρ can grow linearly with n. As a result, the perturbation can
make many imperceptible changes to the input to obtain big output changes.

DL’s behavior is hugely linear to be immune to adversarial examples, and
nonlinear models such as sigmoid networks are set up to be in the non-saturating
most of the time, becoming them more like a linear model. Hence, every per-
turbation as accessible or challenging to compute should also aﬀect deep neural
networks. Therefore, when a model is aﬀected by an adversarial example, this
image often aﬀects another model, no matter if the two models have diﬀerent
architectures or were trained with diﬀerent databases. They just have to be set
up for the same task to change the result [5].

4 Methodology

The experiment consists of studying the transferability of an AA from CNN to
BP. This problem’s methodology considers unconventional training, validation,
and test databases since we apply two diﬀerent image databases compiled by
art experts. Training and validation databases are constructed from the Kaggle
database, while testing uses a standard database WikiArt (See Table 1). The

A Deep GP Methodology Robust to Adversarial Perturbations

5

aim is to emulate a real-world scenario where the trained models are tested with
an unseen standard benchmark compiled by a diﬀerent group of experts.

Validation and test databases are used to compute adversarial examples us-
ing the fast gradient signed method (FGSM) and AlexNet architecture using
standard values for scale ǫ = 2, 4, 8, 16, 32 to build the perturbations. The imple-
mentation of the FGSM was made on Pytorch v1.1. AlexNet was trained using
transfer learning with the pre-trained model from Pytorch, and BP utilizes the
models reported in [4,15].

We formulate the art media classiﬁcation problem in terms of a binary clas-
siﬁcation, whose main goal is to ﬁnd the class elements. Also, we employ classi-
ﬁcation accuracy as a measure of performance for the classiﬁers, which is simply
the rate of correct classiﬁcations given by the following formula:

Accuracy =

1
N

N

X
n=1

d(y′n, yn)

where N is the total of test images, y′n is the predicted label for the image n, yn
is the original label for the image n, and d(x, y) = 1 if x = y and 0 otherwise. In
the following sections, the methods used for the experiment are brieﬂy explained.

4.1 Brain Programming

BP is an evolutionary paradigm for solving CV problems that is reported in
[6,14,16]. This methodology extracts characteristics from images through a hi-
erarchical structure inspired by the brain’s functioning. BP proposes a GP-like
method, using a multi-tree representation for individuals. The main goal is to
obtain a set of evolutionary visual operators (EV Os), also called visual operators
(V Os), which are embedded within a hierarchical structure called the artiﬁcial
visual cortex (AVC).

BP can be summarized in two steps: ﬁrst, the evolutionary process whose
primary purpose is to discover functions to optimize complex models by adjusting
the operations within them. Second, the AVC, a hierarchical structure inspired
by the human visual cortex, uses the concept of composition of functions to
extract features from images. The model can be adapted depending on the task,
whether it is trying to solve the focus of attention for saliency problems or
the complete AVC for categorization/classiﬁcation problems. In this section, we
brieﬂy described the BP workﬂow (see Figure 1), but further details are explained
in [4].

Initialization First, we set the parameters of the evolutionary process of BP
and establish the image databases. Next, a random initial population is created
to evolve the population. In BP, an individual is a computer program represented
by syntactic trees embedded into a hierarchical structure.

Individuals within the population contain a variable number of syntactic
trees, ranging from 4 to 12, one for each evolutionary visual operator (V OO,
V OC , V OS, V OI ) regarding orientation, color, shape, and intensity; and at

6

G. Olague et al.

Fig. 1: Brain Programming workﬂow

least one tree to merge the visual maps produced and generate the Mental Maps
(MM). Details about the usage of these visual operators are explained in detail
in [6,14,4].

Functions within each V O are deﬁned with expert knowledge to attend char-
acteristics related to the dimension they represent and updated through genetic
operations. After creating the ﬁrst generation, the AVC model is used to evaluate
the population’s ﬁtness, as shown in Figure 1.

Fitness function: Artiﬁcial Virtual Cortex (AVC) The evolutionary loop
starts evaluating each individual by using the V Os generated in the previous
step to extract features from input images through the AVC structure depicted
in Figure 1. The result of this procedure is a descriptor vector that encodes the
object. Then, BP uses an SVM to calculate the classiﬁcation rate for a given
training image database. We explain the detailed steps below. The entrance to
the system is an RGB image that belongs to a predeﬁned class. This system
follows a function-based instead of data-based paradigm; hence, we deﬁne an
image I as the graph-of-a-function.

Deﬁnition 1. Image as the graph of a function. Let f be a function
f : U ⊂ R2 → R. The graph or image I of f is the subset of R3 that consist
of the points (x, y, f (x, y)), in which the ordered pair (x, y) is a point in U and
f (x, y) is the value at that point. Symbolically, the image I = {(x, y, f (x, y)) ∈
R3|(x, y) ∈ U }.

This deﬁnition is based on the fact that the images result from the impression

of variations in light intensity along the two-dimensional plane.

A Deep GP Methodology Robust to Adversarial Perturbations

7

Visual Maps Each input image is transformed to build the set Icolor = {Ir,
Ig, Ib, Ic, Im, Iy, Ik, Ih, Is, Iv}, where each element corresponds to the color
components of the RGB (red, green, blue), CMYK (Cyan, Magenta, Yellow,
and black) and HSV (Hue, Saturation, and Value) color spaces. Elements on
Icolor are the inputs to four V Os deﬁned by each individual. It is important to
note that each solution in the population should be understood as a complete
system and not only as a list of three-based programs. Individuals represent
a possible conﬁguration for feature extraction that describes input images and
are optimized through the evolutionary process. Each V O is a function applied
to the input image to extract speciﬁc features from it, along with information
streams of color, orientation, shape, and intensity; each of these properties is
called a dimension. The output to V O is an image called Visual Map (V M ) for
each dimension.

Conspicuity Maps The next step is the center-surround process; it eﬃciently
combines the information from the V M s and is useful for detecting scale invari-
ance in each of the dimensions. This process is performed by applying a Gaussian
smoothing over the V M at nine scales; this processing reduces the visual map’s
size by half on each level forming a pyramid. Subsequently, the six levels of the
pyramid are extracted and combined. Since the levels have diﬀerent sizes, each
level is normalized and scaled to the visual map’s dimension using polynomial
interpolation. This technique simulates the center-surround process of the bi-
ological system. After extracting features, the brain receives stimuli from the
vision center and compares it with the receptive ﬁeld’s surrounding information.
The goal is to process the images so that the results are independent of scale
changes. The entire process ensures that the image regions are responding to the
indicated area. This process is carried out for each characteristic dimension; the
results are called Conspicuity Maps (CM ), focusing only on the searched object
by highlighting the most salient features.

Mental Maps Following the AVC ﬂowchart, all information obtained is synthe-
sized to build maps that discriminate against the unwanted information previ-
ously computed by the CM s. These new maps are called Mental Maps (M M s).
The AVC model uses a set-of-functions to extract the images’ discriminant
characteristics; it uses a functional approach. Thus, a set of k V Os is applied
to the CM s for the construction of the M M s. These V Os correspond to the
remaining part of the individual that has not been used. Unlike the operators
used for the V M s, the operators’ whole set is the same for all the dimensions.
These operators ﬁlter the visual information and extract the information that
characterizes the object of interest. Then, using Equation (4), where d is the
dimension, and k represents the cardinality of the set of V OMMk , we apply the
M M s for each dimension.

M Md =

k

X
i=1

V OMMi (CMd)

(4)

8

G. Olague et al.

Descriptor vector and classiﬁcation The following stage in the model is
the construction of the image descriptor vector (DV ). The system concatenates
the four M M s and uses a max operation to extract the n highest values; these
values are used to construct the DV . Once we get the descriptor vectors of all
the images in the database, the system trains an SVM. The classiﬁcation score
obtained by the SVM indicates the ﬁtness of the individual.

Selection and Reproduction A set of individuals is selected from the pop-
ulation with a probability based on ﬁtness to participate in the genetic recom-
bination, and the best individual is retained for further processing. The new
individual of the population is created from the selected individual by applying
genetic operators. Like genetic algorithms, BP executes the crossover between
two selected parents at the chromosome level using a ”cut-and-splice” crossover.
Thus, all data beyond the selected crossover point is swapped between both par-
ents A and B. The result of applying a crossover at the gene level is performed by
randomly selecting two subtree crossover points between both parents. The se-
lected genes are swapped with the corresponding subtree in the other parent. The
chromosome level mutation leads to selecting a random gene of a given parent to
replace such substructure with a new randomly mutated gene. The mutation at
the gene level is calculated by applying a subtree mutation to a probabilistically
selected gene; the subtree after that point is removed and replaced with a new
subtree.

Stop Criteria The evolutionary loop is terminated until one of these two con-
ditions is reached: (1) an acceptable classiﬁcation rate, or (2) the total number
of generations.

4.2 Convolutional Neural Networks

The ML community introduced the idea of designing DL models that build
features from images. LeCun et al. [12] presented the modern framework of CNN,
but the ﬁrst time that CNN starts attracting attention was with the development
of the AlexNet model [10]. The authors participated in the ImageNet Large-Scale
Visual Recognition Challenge 2012, where they reduced by half the error rate
on the image classiﬁcation task.

AlexNet layer-architecture consists of 5 convolutional, three max-pooling,
two normalization, and three fully connected layers (the last with 1000 softmax
outputs), 60 Million parameters in 500,000 neurons. Additionally, Alex et al. [10]
introduced the use of ReLU (Rectiﬁed Linear Unit) as an activation function
with the beneﬁts of much faster training than using tanh or sigmoid functions.
To prevent overﬁtting, they also introduced the dropout and data augmentation
methods.

A Deep GP Methodology Robust to Adversarial Perturbations

9

4.3 Adversarial Attack

The FGSM [5] is the most popular, easy, and widely used method for computing
adversarial examples from an input image, see Figure 2. It increases the loss of
the classiﬁer by solving the following equation: ρ = ǫ sign(∇J(θ, x, yl)), where
∇J() computes the gradient of the cost function around the current value of
the model parameters θ with the respect to the image x and the target label yl.
sign() denotes the sign function which ensures that the magnitude of the loss
is maximized and ǫ is a small scalar value that restricts the norm L∞ of the
perturbation.

The perturbations generated by FGSM take advantage of the linearity of
the deep learning models in the higher dimensional space to make the model
misclassify the image. The implication of the linearity of deep learning models
discovered by FSGM is that it exists transferability between models. Kurakin et
al. in [11] reported that after using the ImageNet database, the top-1 error rate
using the perturbations generated by FGSM is around 63-69% for ǫ ∈ [2, 32].

Drawings

Engraving

Engraving

Color

B&W

Iconography

Painting

Sculpture

Fig. 2: Illustrations of adversarial examples from each class generated using
FGSM. The ﬁrst row shows an image from each class. In the second row, the
perturbations computed by the FGSM are presented. The third row shows the
resulting adversarial example at ǫ = 32, the strongest perturbation.

4.4 Database Collection

We follow the protocol and databases from the experiment of the art media cat-
egorization problem reported in [4]. The training and validation set of images
are obtained from the digitized artwork database downloaded from the Kaggle

10

G. Olague et al.

website. This database comprises ﬁve categories of art media: drawing, paint-
ing, iconography, engraving, and sculpture. For class engraving, there were two
diﬀerent kinds of engravings. Most of them were engravings with only one color
deﬁning the art piece. The other style was Japanese engravings, which intro-
duce color to the images. Therefore, the engraving class was split into engraving
grayscale and color. For testing, a standard database WikiArt is used from which
it was selected images of the same categories. Since the Wikiart engraving class
is grayscale, the ukiyo-e class (Japanese engravings) from Wikiart was used as
the engraving color class. Also, the set of images of the category landscapes,
which are paintings from renowned artists, is added to test the painting class.
Table 1 provides the number of images for each database.

Table 1: Total number of images per class obtained from Kaggle and Wikiart
Databases

Drawings

553
553
204

Train
Validation
Wikiart
Wikiart
Landscapes

Engraving
gray scale
426
284
695

Engraving
color
30
19
1167

Painting

Iconography Sculpture Caltech

1021
1021
2089
136

1038
1038
251

868
868
116

Background
233
233
233

5 Results

In this section, we present and discuss the experimental results summarized
in Tables 2 and 3. Table 2 provides results for the ﬁve classes of the Kaggle
database. Each method presents its performance for training, validation, and
the adversarial examples from the FGSM computed with the validation database
using ǫ = 2, 4, 8, 16, 32. Table 3 shows the result for the Wikiart images where
both methods were tested. It is shown the outcome of the model for the clean
images as well as the adversarial examples.

We observe in Table 2 that AlexNet surpassed BP in almost every class when
considering the validation database except for the painting class. However, as
we add perturbations to the validation images, the eﬀect of AA becomes more
notable. It is shown how the performance of AlexNet deteriorates in proportion
to the AA. In the worst-case–Engraving color images–there is a drop in per-
formance from 94.72% to 17.22% of classiﬁcation accuracy. On the other hand,
BP preserves its performance on all experiments even when we added the most
substantial perturbation of ǫ = 32. Hence, if we look at each of the comparisons
(bold numbers), BP outperforms AlexNet.

For the testing part (see Table 3), we have that BP obtained notable better
results for painting, painting landscapes, and drawings. In contrast, AlexNet ob-
tained superior performance on engraving grayscale, engraving color, and iconog-
raphy. We should mention that in any case, the results of both methods are very

A Deep GP Methodology Robust to Adversarial Perturbations

11

good. For the sculpture class, BP matches the performance of AlexNet with a
diﬀerence of around 0.6%. Then again, the susceptibility of AlexNet to the AA
is a signiﬁcant problem. Its accounts fall abruptly on all classes; meanwhile, the
BP output remains steady.

Table 2: Results obtained after applying BP and AlexNet on the Kaggle
database. Each method presents its classiﬁcation accuracy for training, vali-
dation, and the adversarial examples using FGSM computed from the validation
database at ǫ = 2, 4, 8, 16, 32

ǫ4

Brain Programming (BP)
ǫ2
train val
93.26 92.79 92.79 92.79 92.79 92.79 92.79 99.36 95.78 90.93 90.93 63.24 27.5 14.57
Sculpture
99.68 99.04 98.25 98.25 98.48 98.41 98.48 98.96 97.69 93.46 93.46 83.01 66.99 69.30
Painting
Engraving gray scale 89.76 92.05 92.23 92.23 92.23 91.70 91.87 99.76 99.29 96.11 96.11 78.62 56.71 47.88
98.33 97.37 97.37 97.37 97.37 97.37 97.37 100 100
73.68 73.68 23.68 13.16 15.79
Engraving color
92.84 91.42 91.42 91.42 91.42 91.42 91.42 99.61 98.66 96.30 96.30 83.24 52.26 38.39
Iconography
96.56 90.59 90.59 90.59 90.59 90.59 90.59 96.44 91.35 85.75 85.75 66.79 44.91 35.62
Drawings

AlexNet
train val

ǫ32

ǫ32

ǫ16

ǫ16

ǫ8

ǫ4

ǫ2

ǫ8

Table 3: Results obtained after applying BP and AlexNet on the Wikiart
database. Each method presents its classiﬁcation accuracy for testing, and
the adversarial examples using FGSM computed from the test database at
ǫ = 2, 4, 8, 16, 32

ǫ4

ǫ8

ǫ2

ǫ16

Brain Programming (BP)
test
90.54 90.83 90.83 90.83 90.83 90.83 91.15 87.61 87.61 65.49 44.25 36.87
Sculpture
95.65 95.65 95.65 95.65 95.65 94.06 90.57 90.57 64.64 41.04 41.00
100
Painting
100
100
Painting Landscapes 100
93.77 86.99 86.99 61.25 41.46 35.77
Engraving gray scale 91.55 92.64 92.64 91.97 91.72 91.63 98.58 94.06 94.06 75.06 57.32 54.64
89.92 89.68 89.68 89.74 89.86 89.80 94.72 73.55 73.55 25.49 12.30 17.22
Engraving color
91.74 91.66 91.66 91.82 91.74 91.74 96.07 93.39 93.39 70.04 37.40 28.72
Iconography
94.05 94.28 94.28 93.59 93.81 94.50 86.73 77.8
57.21 41.19 32.72
Drawings

AlexNet
ǫ2
test

77.8

ǫ32

ǫ32

ǫ16

100

100

100

ǫ8

ǫ4

6 Conclusions and Future work

In conclusion, AA are a severe threat to the security of DL models. Their per-
formance can be extremely weakened with such small perturbations. With tradi-
tional CV approaches, it is not easy to obtain results comparable to DL models.
However, we propose a GP-like methodology inspired by the brain’s behavior to
solve art media classiﬁcation. This work innovates compared with a DL model
by considering performance and robustness against adversarial attacks. Also,
we want to extend the robustness to adversarial attacks using CV mainstream
approaches from image classiﬁcation for future work. Furthermore, we will in-
crease the number of adversarial attacks to assess the classiﬁers’ performance
under various conditions.

12

G. Olague et al.

References

1. Akhtar, N., Mian, A.: Threat of adversarial attacks on deep learning in computer

vision: A survey. IEEE Access 6, 14410–14430 (2018)

2. Arora, R.S., Elgammal, A.: Towards automated classiﬁcation of ﬁne-art painting
style: A comparative study. In: Proceedings of the 21st International Conference
on Pattern Recognition (ICPR2012). pp. 3541–3544. IEEE (2012)

3. Bar, Y., Levy, N., Wolf, L.: Classiﬁcation of artistic styles using binarized features
derived from a deep neural network. In: European conference on computer vision.
pp. 71–84. Springer (2014)

4. Chan-Ley, M., Olague, G.: Categorization of digitized artworks by media with

brain programming. Applied optics 59 14, 4437–4447 (2020)

5. Goodfellow, I.J., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial
examples. 3rd International Conference on Learning Representations, ICLR 2015,
Conference Track Proceedings p. 11 (2015)

6. Hern´andez, D.E., Clemente, E., Olague, G., Brise˜no, J.L.: Evolutionary multi-
objective visual cortex for object classiﬁcation in natural images. Journal of Com-
putational Science 17, 216 – 233 (2016). https://doi.org/10.1016/j.jocs.2015.10.011
I.J., Brevdo, E., Hughes, S.M.,
Daubechies, I., Li, J., Postma, E., Wang, J.Z.: Image processing for artist identiﬁ-
cation. IEEE Signal Processing Magazine 25(4), 37–48 (2008)

7. Johnson, C.R., Hendriks, E., Berezhnoy,

8. Keren, D.: Painter identiﬁcation using local features and naive bayes. In: Object
recognition supported by user interaction for service robots. vol. 2, pp. 474–477.
IEEE (2002)

9. Kowaliw, T., McCormack, J., Dorin, A.: Evolutionary automated recognition and
characterization of an individual’s artistic style. In: IEEE Congress on Evolutionary
Computation. pp. 1–8. IEEE (2010)

10. Krizhevsky, A., Sutskever,

I., Hinton, G.E.:

deep convolutional neural networks.
tou, L., Weinberger, K.Q.
cessing
pp.
http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf

(eds.) Advances
1097–1105. Curran Associates,

Imagenet classiﬁcation with
In: Pereira, F., Burges, C.J.C., Bot-
Information Pro-
(2012),

in Neural

Systems

Inc.

25,

11. Kurakin, A., Goodfellow, I.J., Bengio, S.: Adversarial machine learning at scale.
5th International Conference on Learning Representations, ICLR 2017, Conference
Track Proceedings p. 17 (2017)

12. LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W.,
Jackel, L.D.: Backpropagation applied to handwritten zip code recognition. Neural
computation 1(4), 541–551 (1989)

13. Li, J., Wang, J.Z.: Studying digital imagery of ancient paintings by mixtures of
stochastic models. IEEE Transactions on Image Processing 13(3), 340–353 (2004)
14. Olague, G., Clemente, E., Hern´andez, D.E., Barrera, A., Chan-Ley, M., Bakshi, S.:
Artiﬁcial visual cortex and random search for object categorization. IEEE Access
7, 54054–54072 (2019)

15. Olague, G., Chan-Ley, M.: Hands-on

programming.

brain
tice XVII.
227–253.
https://doi.org/10.1007/978-3-030-39958-0_12

In: Genetic

Springer

pp.

artiﬁcial
Programming Theory

evolution

and

International Publishing

through
Prac-
(2020),

16. Olague, G., Hern´andez, D.E., Llamas, P., Clemente, E., Brise˜no, J.L.: Brain pro-
gramming as a new strategy to create visual routines for object tracking. Multi-
media Tools and Applications 78(5), 5881–5918 (2019)

A Deep GP Methodology Robust to Adversarial Perturbations

13

17. Yang, H., Min, K.: Classiﬁcation of basic artistic media based on a deep convolu-

tional approach. The Visual Computer 36(3), 559–578 (2020)

