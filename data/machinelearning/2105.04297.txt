How could Neural Networks understand Programs?

Dinglan Peng 1 Shuxin Zheng 2 Yatao Li 2 Guolin Ke 2 Di He 2 Tie-Yan Liu 2

Abstract

1. Introduction

1
2
0
2

y
a
M
1
3

]
L
P
.
s
c
[

2
v
7
9
2
4
0
.
5
0
1
2
:
v
i
X
r
a

Semantic understanding of programs is a funda-
mental problem for programming language pro-
cessing (PLP). Recent works that learn represen-
tations of code based on pre-training techniques
in NLP have pushed the frontiers in this direc-
tion. However, the semantics of PL and NL have
essential differences. These being ignored, we
believe it is difﬁcult to build a model to better
understand programs, by either directly applying
off-the-shelf NLP pre-training techniques to the
source code, or adding features to the model by
the heuristic. In fact, the semantics of a program
can be rigorously deﬁned by formal semantics
in PL theory. For example, the operational se-
mantics, describes the meaning of a valid pro-
gram as updating the environment (i.e., the mem-
ory address-value function) through fundamental
operations, such as memory I/O and conditional
branching. Inspired by this, we propose a novel
program semantics learning paradigm, that the
model should learn from information composed of
(1) the representations which align well with the
fundamental operations in operational semantics,
and (2) the information of environment transition,
which is indispensable for program understand-
ing. To validate our proposal, we present a hi-
erarchical Transformer-based pre-training model
called OSCAR to better facilitate the understand-
ing of programs. OSCAR learns from interme-
diate representation (IR) and an encoded rep-
resentation derived from static analysis, which
are used for representing the fundamental oper-
ations and approximating the environment tran-
sitions respectively. OSCAR empirically shows
the outstanding capability of program semantics
understanding on many practical software engi-
neering tasks. Code and models are released at:
https://github.com/pdlan/OSCAR.

1University of Science and Technology of China 2Microsoft
Research Asia. Correspondence to: Shuxin Zheng, Yatao Li, Di
He <{shuz,yatli,dihe}@microsoft.com>.

Modern software typically contains tons of code, functions,
and modules with overwhelmingly complex structure or or-
ganization scheme. It poses great challenges for writing,
maintaining, and analyzing such programs. Fortunately, a
series of deep learning-based productivity tools were de-
veloped to automatically help programmers by analyzing
program (Ding et al., 2019; Duan et al., 2020; Yu et al.,
2020a), security auditing (Zhou et al., 2019; Buratti et al.,
2020), code retrieval (Luan et al., 2019; Ye et al., 2020;
Cummins et al., 2020b), and so on.

Inspired by the success of pre-trained representation for
semantics understanding of natural language (Devlin et al.,
2019; Brown et al., 2020; Xiong et al., 2020), there are many
recent attempts to graft the conventional NLP pre-training
techniques to source code (Buratti et al., 2020; Feng et al.,
2020; Lachaux et al., 2020; Guo et al., 2020; Yu et al.,
2020a), in which the code representation is obtained by cap-
turing contextual information from a substantial amount of
source code text, and is then used for a variety of down-
stream software engineering tasks after ﬁne-tuning. For
instance, CuBERT (Kanade et al., 2020) leverages the pow-
erful pre-training contextual embedding model BERT (De-
vlin et al., 2019) to learn informative representations on
a Python corpus; CodeBERT (Feng et al., 2020) learns
general-purpose representations to bridge natural language
(NL) and high-level programming language (PL) by pre-
training on NL-PL pairs. Furthermore, features designed by
experts (e.g., data ﬂow graph) (Guo et al., 2020) are added
to the pre-training model, aiming to provide additional in-
formation for program semantics understanding.

However, programming languages have many fundamental
differences in essence with natural languages. For example,
the same program may exhibit different behaviors against
its input and memory state, while there is no such explicit
concept in natural language. Therefore, we argue that the
current approaches that attempt to capture the semantic
proprieties directly from the source code, will limit the
semantics understanding of programs, be it applying off-the-
shelf NLP pre-training techniques, or adding features to the
model by the heuristic.

Proceedings of the 38 th International Conference on Machine
Learning, PMLR 139, 2021. Copyright 2021 by the author(s).

Indeed, the rigorous mathematical account of the meaning
(i.e., the semantics) of programming languages (Gunter,

 
 
 
 
 
 
How could Neural Networks understand Programs?

1992), has been well-studied by formal semantics (Winskel,
1993) in programming language theory. For instance, the
operational semantics (van Wijngaarden et al., 2012), which
is a widely used branch of formal semantics, captures the
meaning of a programming language by deﬁning rules for
how its programs execute on an abstract machine. These
rules reﬂect the environment transitions according to the in-
structions, where the environment (Stuart, 2013) is formally
deﬁned as a function mapping all memory addresses to their
values1, and one instruction conducts a rigorously deﬁned
operation, such as reading/writing the memory, basic arith-
metic, boolean logic, or conditional branching.

Inspired by the programming language theory, we propose
a code representation learning paradigm which could make
a model better understand programs. In particular, a code
representation should be learned from (1) a translation of
the source code text that aligns well with those fundamen-
tal operations deﬁned in operational semantics; (2) the in-
formation of environment transition, which is obviously
indispensable for program understanding.

In order to verify the effectiveness of our proposal, we
further present a novel pre-training model called Opera-
tional Semantics for Code Abstract Representation (OS-
CAR) based on a hierarchical Transformer (Vaswani et al.,
2017), which is designed to capture the contextual infor-
mation among long sequences of code. On one hand, to
represent the fundamental operations, OSCAR utilizes in-
termediate representation (IR), which is more applicable
for learning code representation rather than high-level pro-
gramming languages, since the IR is modeled on an abstract
machine with a ﬁnite instruction set, which can be mapped
to the operational semantics almost perfectly. In particular,
the IR can be easily acquired by translation from binary or
source code of a target program. On the other hand, ob-
taining concrete and precise information of the environment
transition requires plenty of actual executions and calcu-
lations, which would be impractical and risky. Therefore,
OSCAR alternatively uses abstract information, which can
be obtained by abstract interpretation inspired static program
analysis without difﬁculty. Abstract interpretation (Cousot
& Cousot, 1977; 1979) describes program semantics by a
mathematical characterization of possible behaviors of the
program instead of modeling the behaviors after many ac-
tual execution trails of the program. In addition, to capture
the control structure of a target program or code snippet, we
develop a novel Positional Condition Encoding (PCE) to
encode the control ﬂow information into the model.

Furthermore, to ensure the desired capacity of pre-trained
representation, we design a compact and effective objec-
tive function by combining two respective components: a

1For simplicity, we consider that all the values are stored in

memory, e.g., LLVM values.

variant of MLM loss (Devlin et al., 2019) masking entire in-
structions, and a contrastive loss with different compilation
optimization techniques. With instruction tokens as input,
the model could capture token-level contextual knowledge
by optimizing the variant of MLM loss. Meanwhile, by gen-
erating syntactically diverse but functionally equivalent IRs
through different compilation optimization techniques, e.g.,
strength reduction, loop unrolling, and inline expansion, the
contrastive loss could provide informative self-supervision,
to help the model to efﬁciently capture the program- or code
snippet-level semantic knowledge.

Our contributions are concluded as follows:

• We propose a new learning paradigm that suggests
the pre-training model could learn code representation
from both the superﬁcial instructions and the underly-
ing environment transitions, which alleviates the afore-
mentioned limitations of semantics understanding of
program according to operational semantics.

• We demonstrate our proposal by presenting OSCAR, a
hierarchical Transformer which represents the funda-
mental operations by IR and approximates the environ-
ment transitions by an encoded representation derived
from static analysis. We also design efﬁcient training
objectives for OSCAR to largely facilitate the program
semantics understanding.

• OSCAR signiﬁcantly boosts the performance of se-
mantics understanding of program on a wide range
of downstream practical software engineering tasks.
Moreover, OSCAR shows remarkable zero-shot ability,
i.e., without ﬁne-tuning the parameters, comparing to
state-of-the-art pre-training methods.

2. Related Work

Inspired by the great success of deep learning on natural lan-
guage understanding, there is a growing body of exploratory
work on programming language understanding by incorpo-
rating code structure into DNN, such as abstract syntax tree
(AST) (Alon et al., 2020; Rabinovich et al., 2017; Yin &
Neubig, 2017; Wei & Li, 2017; Chen et al., 2018; Alon
et al., 2018; Mou et al., 2016; Alon et al., 2019; Zhang et al.,
2019; Bui et al., 2020) or graph (Brockschmidt et al., 2018;
Wang et al., 2020; Allamanis et al., 2018; Hellendoorn et al.,
2019; Duan et al., 2020; Cummins et al., 2020a; Ye et al.,
2020; Hellendoorn et al., 2019; David et al., 2020; Wang &
Su, 2020).

As the most commonly used architectures in NLP, the Trans-
former (Vaswani et al., 2017) has also been widely adopted
in code understanding tasks. Kim et al. (2020) achieve high
accuracy of next token prediction on code by feeding AST
to Transformer. Svyatkovskiy et al. (2020) propose to train

How could Neural Networks understand Programs?

a variant of GPT-2 (Radford et al., 2019) from scratch on
source code to improve the performance of code comple-
tion. Recent works employ pre-training on large-scale code
corpus and achieve promising results of code representa-
tion. Kanade et al. (2020) pre-train a BERT model on a
massive corpus of Python source code and get outstanding
performance on ﬁve code intelligence tasks. Buratti et al.
(2020) present C-BERT, which is a transformer-based model
pre-trained on a large collection of corpus written in C. Feng
et al. (2020) propose a cross-modal BERT called CodeBERT
between source codes and comments, written in program-
ming language and natural language respectively, and gain
excellent achievements on NL-PL tasks, such as code search
by natural language and code generation from comments.
By introducing the data ﬂow to the model, Guo et al. (2020)
further improve the performance of CodeBERT. Ahmad
et al. (2021) present PLBART, which is also pre-trained on
a cross-modal corpus of programming language and nat-
ural language via denoising autoencoding. BinaryAI (Yu
et al., 2020a) leverage a BERT model pre-trained on binary
code to construct a hybrid model by combining with GNN
and CNN, and achieves excellent performance on binary
code similarity detection. Yu et al. (2020b) further introduce
a novel CNN as a feature extractor for source code, and
improve the performance of binary-source code matching.

To our best knowledge, the proposed OSCAR is the ﬁrst at-
tempt for code representation using our PL theory-inspired
learning strategy that considers both the superﬁcial program-
ming language and the underlying environment transitions,
to improve the performance of program and code under-
standing.

are

There

Intermediate Representation
prior
works (Ben-Nun et al., 2018; VenkataKeerthy et al.,
2020; Cummins et al., 2020b) that attempt to understand
code on IR language with different motivations. For
example, Ben-Nun et al. (2018) argues that training model
on a speciﬁc source programming language (or machine
code for optimization) could not generalize to other
languages, and suggests that training on IR language is
better since it accepts code in various source languages.
Similarly, Cummins et al. (2020b) aims to produce a
language-agnostic, compiler-independent representation for
the program by leveraging a corpus of LLVM IR covering
six source programming languages.

Different from the motivations of previous methods, we
suggest that the IR is more applicable for learning code rep-
resentation rather than high-level PL since the IR is modeled
on an abstract machine with a ﬁnite instruction set, which
can be well mapped to operational semantics.

Contrastive Learning
In recent years, contrastive learn-
ing (Hadsell et al., 2006; Chen et al., 2020; He et al., 2020)
shows promising results on unsupervised visual represen-

tation learning. Inspired by this, Jain et al. (2020) present
ContraCode, which applies contrastive learning on code rep-
resentation learning by adopting several source-to-source
transformations, such as variable renaming, dead code elim-
ination, and dead code insertion. The functionality of the
program would not be changed after the transformations,
therefore the underlying representations should be the same.

Different from ContraCode, we generate syntactically di-
verse but functionally equivalent IRs with different opti-
mization techniques in compilers. Unlike the transforma-
tions in ContraCode, different optimizations would lead
to huge differences in the syntax and structure of the IR,
such as strength reduction, loop unrolling, and inline ex-
pansion. This kind of diversity could provide informative
self-supervision in helping the model to efﬁciently capture
the program- or code snippet-level semantic knowledge.

3. Method

As mentioned above, operational semantics (van Wijngaar-
den et al., 2012; Stuart, 2013) captures the meaning of an
executable program by the environment transitions accord-
ing to the instructions on an abstract machine. To be more
concrete, we illustrate our motivation by structural oper-
ational semantics (Plotkin, 1981; Hennessy, 1990). The
meaning of assignment and composition on a simpliﬁed
abstract machine can be represented respectively as

(cid:104)E, s(cid:105) =⇒ V
(cid:104)L := E, s(cid:105) → (s (cid:93) (L (cid:55)→ V ))

,

(cid:104)C1, s(cid:105) −→ s(cid:48)
(cid:104)C1; C2, s(cid:105) → (cid:104)C2, s(cid:48)(cid:105)

,

where E, L, V denote expression, memory location and
value respectively, s ∈ S denotes environment function
mapping all memory locations to values, and C represents
code snippet. Therefore, the meaning of assignment can
be explained as “the program L := E will update the envi-
ronment function s with L = V if the expression E in the
environment s reduces to V ”. Similarly, the composition
can be explained as “if the code snippet C1 in environment
s ﬁnishes in s(cid:48), then the composed code snippet C1; C2 in
environment s can reduce to execute C2 in s(cid:48)”.

Obviously, the semantics of a code snippet depends on two
parts: the instructions and the information of environment
transitions on the abstract machine. Therefore, we propose
that a good code representation would be sufﬁciently learned
from these two parts to better understand the semantics of
programs. In the following, we will present OSCAR, which
is a hierarchical model that learns code representation from
these two aspects.

How could Neural Networks understand Programs?

Figure 1. An illustration of the model architecture of OSCAR.

3.1. Input Representations

3.1.2. ABSTRACT ENVIRONMENT INFORMATION

3.1.1. INTERMEDIATE REPRESENTATION (IR)

Learning representation directly from high-level PLs has
been widely adopted by existing program understanding
methods. However, the gap between the textual represen-
tation of source or binary code versus the actual computa-
tional meaning becomes larger along with the development
of modern programming languages and compilers. This non-
negligible gap increases the difﬁculty of code understanding
for existing models.

In general, in order to better analyze and optimize a pro-
gram, a modern compiler will translate the source code into
IR before it generates machine code for a target architecture.
IR is modeled after an abstract machine that is typically
designed so that each instruction represents exactly one fun-
damental operation. With this characteristic, IR becomes
a more accurate and appropriate representation of the in-
struction in operational semantics instead of high-level PLs.
We collect a large corpus of real-world programs (Details
in Appendix F.1) and translate them into LLVM IR as our
pre-training data. LLVM IR is one of the most commonly
used IR forms, and supports a wide variety of languages.

There is an additional advantage for using IR: if the target
code snippet is binary or assembly, the textual information
would be easily preserved when translating binary code to
IR, unless the binary is generated from strong obfuscation,
e.g., executable packing. Meanwhile, translating binary or
assembly back to source code (aka. decompilation) would
totally change the distribution and legibility of tokens, which
would deeply hurt the performance of source code-based
methods.

We leverage the structural operational semantics to illustrate
how we encode the information of environment transitions
into the model. The inductive nature of structural opera-
tional semantics requires a properly deﬁned initial condition,
which is described by the initial environment function. The
transitions can then be inferred step-by-step based on the
sequencing rules (i.e., composition, transformation, and con-
ditioning, please refer to Plotkin (1981); Hennessy (1990)).
To fully capture the concrete and precise information of
environment transitions, one has to iterate through many
possible combinations of input values and initial conditions,
and infer the transitions by actually execute the program
with the sequencing rules. This is obviously infeasible since
actual executions are quite time-consuming and risky, e.g.,
analysis for large software projects or malicious software.

Therefore, we alternatively use the abstract environment
information obtained from static program analysis, instead
of the concrete one. The abstract environment informa-
tion is inspired by the abstract interpretation (Cousot &
Cousot, 1977; 1979), and describes program semantics by
a mathematical characterization of possible behaviors of
the program instead of modeling the behaviors after many
actual execution trails of the program. Applying this idea to
structural operational semantics, each expression can reduce
to not only a concrete value, but also a relation or a possible
range in the value space.

Speciﬁcally, we extract three types of relational constraints
of the environment from the instructions: those governed
by static single assignment (SSA), those by memory reads,
and those by memory writes. This information can be easily
obtained by LLVM built-in analytic features, e.g., Memo-
rySSA. In addition, to better model the range constraints of
the environment , we extract auxiliary information from the

How could Neural Networks understand Programs?

control ﬂow graph, i.e., the depth of loop, via LLVM Loop-
Info. Detailed descriptions about the extraction of abstract
environment information can be found in Appendix A.

3.2. Model

3.2.1. ARCHITECTURE

The model architecture of OSCAR is a hierarchical multi-
layer Transformer encoder, which is illustrated in Fig.1. In
particular, OSCAR consists of two levels of encoders. The
lower level is composed of two token-level encoders, which
are used to process tokens from IR and abstract environment
information, respectively. The upper level is an instruction-
level encoder, which aims to extract features further based
on the lower-level layer’s outputs. The implementation of
each level of encoders is identical to BERT (Devlin et al.,
2019). We call the two token-level encoders as IR and Env.
encoder, and the instruction-level encoder as Inst. encoder.

Typically, the token sequence of a practical program is
long. If we simply feed the sequence to a standard Trans-
former, the time and space cost will be extremely high
since the attention module suffers from quadratic computa-
tion and memory requirements with respect to the sequence
length. Most previous methods truncate the long input se-
quence (Kanade et al., 2020; Feng et al., 2020) to a short
one, such as 512 tokens. But obviously, a 512-long token
sequence will lose a signiﬁcant amount of information in
the program or code snippet.

The hierarchical architecture of OSCAR is designed to better
solve this problem. We partition the instructions of the
input program into groups by every K instructions as one
group, and the IR (or abstract environment information)
tokens of each group would be fed into parameter-shared IR
(or Env.) encoders separately. The output representations
coming from one instruction of the token-level encoders,
would be averagely pooled, to aggregate the information at
the instruction level. Then, those instruction-level hidden
representations will be fed to the Inst. encoder for further
feature extraction. We set K = 4 in our experiments.

Similar to Dai et al. (2020), we up-sample the output se-
quences of the instruction-level encoder by repeating each
hidden vector multiple times so that the length is enlarged
to the original token sequence. After up-sampling, con-
secutive vectors of each instruction would be exactly the
same and lost the detailed token-level signals. To involve
the uncompressed token-level signal, we adopt a residual
connection between uncompressed token-level hidden repre-
sentations and the up-sampling vectors. After that, another
two token-level encoders would try to recover the original
token sequences on the positions of the instruction masks.

3.2.2. POSITIONAL CONDITION ENCODING

Since the Transformer is developed to solve the problem of
sequence transduction in natural language, it cannot well
capture the complicated control structure of programming
languages, such as iteration logic and selection logic. How-
ever, the control ﬂow information is indispensable for un-
derstanding the semantics of a program. To overcome this
problem, incorporating the control ﬂow graph (CFG) into
Transformer has been widely adopted in prior works (Hel-
lendoorn et al., 2019; David et al., 2020).

In this paper, we design a more simple but effective method
called Positional Condition Encoding (PCE), to encode the
control ﬂow information into the model through positional
encoding. PCE assigns three learnable embedding vectors
to the position of each instruction in the target program or
code snippet, representing the instruction’s current position,
and target positions after conditionally jumping with true
and false, respectively. Fig.2 shows the illustration of PCE
corresponding to the code snippet and the control ﬂow graph,
where pi, p1
i denote the learnable embedding at the
current position, true-jumping position, and false-jumping
position, of the instruction at position i separately.

i and p0

Figure 2. An illustration of PCE. PCE could encode the informa-
tion of control ﬂow graph into the model. Please note that the
example code snippet is written in C++ for readability.

To be more concrete, let hi ∈ Rd be the instruction-level
hidden representation at position i, and W V ∈ Rd×d de-
notes learnable projection matrix. The output zi of the ﬁrst
self-attention module in the Inst. encoder can be written as

zi =

n
(cid:88)

j=1

exp(αij)
j(cid:48)=1 exp(αij(cid:48))

(cid:80)n

(hjW V ).

(1)

Similar to Ke et al. (2020), we propose to model the relation-
ship between positions with different projection matrices.
Then, the correlation term αij in Eq.1 is calculated as

(hiW Q)(hjW K )T +

(piU Q)(pjU K )T

1
√
4d
i U 1,Q)(p1

(p1

αij =

+

1
√
4d

j U 1,K )T +

1
√
4d

1
√
4d
i U 0,Q)(p0

(p0

j U 0,K )T ,

(2)

where W Q, W K ∈ Rd×d are the projection matrices for
the hidden representation h, U Q, U K ∈ Rd×d are the pro-
jection matrices for the current positional embedding p, and
U 1,Q, U 1,K, U 0,Q, U 0,K ∈ Rd×d are for the true-jumping

How could Neural Networks understand Programs?

and false-jumping position embedding p1 and p0. The scal-
ing coefﬁcient

maintains the magnitude of αij.

1√

4d

From Fig.2 we can see that PCE can incorporate the infor-
mation about outgoing edges of the nodes in the CFG into
the attention module, and the information about incoming
edges would also be captured after the calculation of posi-
tional correlation in Eq.2. This indicates that OSCAR could
capture all information of the CFG with PCE even that the
CFG has not been explicitly fed into the model.

3.3. Pre-training Objectives

Masked Instruction LM Predicting the masked tokens
is the most commonly used objective function in previous
BERT-based code representation methods (Kanade et al.,
2020; Feng et al., 2020; Guo et al., 2020). It’s essential to
OSCAR that captures the token-level contextual knowledge
from optimizing MLM loss during pre-training. However,
since both IR and abstract environment information are si-
multaneously provided to our model, it’s trivial to derive
particular tokens in the IR through the environment which
comes from the same instruction, and vice versa. To prevent
such potential information leakage, we propose to mask
consecutive tokens of an entire instruction. Specially, we
sample randomly 15% instructions from IR and paired envi-
ronment. We replace the instructions with [MASK] tokens
80% of the time, with random instructions 10% of the time,
and leave them unchanged 10% of the time.

Contrastive Learning with Optimization Techniques
How to effectively capture the program- or code snippet-
level semantic knowledge during pre-training is certainly
essential for code representation models. However, it has
not been well-studied by prior works.

Actually, modern compilers support versatile compilation
options for different demands of optimizations, e.g., mini-
mize execution time, memory footprint, storage size, etc. A
single source code snippet could be translated to contrasting
IR with different optimization techniques, but the meaning
of the code would not be changed. Naturally, the differ-
ent combinations of multiple optimizations can be used as
a method of data augmentation for source code (Details
in Appendix E). Motivated by this, we propose to employ
an objective on [CLS] token of contrastive learning with
a momentum encoder (He et al., 2020) as OSCAR’s self-
supervised task to better facilitate the semantics understand-
ing from program level, which is illustrated in Fig.1.

4. Experiments

We conduct the pre-training of OSCAR on a large corpus
of real-world programs from publicly available open-source
GitHub repositories, which covers a broad range of disci-
plines from operating systems and compilers, to machine

learning systems and linear algebra subprograms (Details
in Appendix F.1). We evaluate the performance of OSCAR
on several semantics understanding tasks for programs in
this section. We ﬁrst perform our model on a practical and
important software engineering task, i.e., binary difﬁng. It
is a very fundamental task in reverse engineering and has
been widely used to enable different kinds of critical se-
curity analysis. After that, we evaluate the performance
of OSCAR for high-level PL understanding on the algo-
rithm classiﬁcation task. Furthermore, as a pre-training
method, we investigate the performance of OSCAR in zero-
shot learning, where the parameters of OSCAR are ﬁxed.
Finally, we analyze the components of our model in the
ablation study. Unless otherwise speciﬁed, all experiments
are conducted on a 12-layer OSCAR model which is com-
posed sequentially of three token-level encoder layers, six
instruction-level encoder layers, and three token-level en-
coder layers. We follow RoBERTa-base (Liu et al., 2019)
to set other model conﬁgurations (Details in Appendix B),
e.g., the dimensionality of hidden representation d is set to
768. The total sequence length of Inst. encoder is set to 512,
where the IR and Env. encoders each account for 256 in-
structions. Detailed descriptions of all downstream datasets
and optimization strategies of pre-training and ﬁne-tuning
could be found in Appendix G and H respectively.

4.1. Binary Difﬁng

Binary code differential analysis, a.k.a. binary difﬁng, is
a fundamental analysis capability, which aims to measure
the function-level similarity between two given binaries.
We evaluate the performance of OSCAR on binary difﬁng
by following the setting and the dataset described in Ding
et al. (2019). In addition to Asm2vec (Ding et al., 2019),
we further compare OSCAR with two baseline techniques:
BinDiff (Dullien & Rolles, 2005), which is the de facto
standard binary difﬁng tool based on graph isomorphism
detection; and BinaryAI (Yu et al., 2020a;b), which is a
most recently proposed binary code feature extractor based
on a hybrid model of neural network with BERT, CNN and
GNN, and achieves state-of-the-art performance on code
similarity detection.

Following Ding et al. (2019), we evaluate baseline tech-
niques and OSCAR on ﬁve commonly used programs using
Recall@1. All ﬁve programs are compiled with GCC 7.5.0
against four different optimization levels. The results are
given in Tab.1. As shown, OSCAR consistently outperforms
BinDiff, Asm2vec, and BinaryAI across all optimization
levels of ﬁve programs in terms of recall, by a large margin.
For example, in the most difﬁcult matching situation, i.e.
difﬁng between the O0 and O3 optimization levels, OSCAR
improves the recall over all baseline techniques on every
program.

How could Neural Networks understand Programs?

Table 1. Binary code similarity detection using the Recall at position 1 (Recall@1) metric on popular software across different
optimization levels.

Software

Methods

O0-O1 O0-O3 O1-O3 O2-O3

Avg.

SQLite

zlib

Libcurl

BusyBox

LibTomCrypt

BinDiff (Dullien & Rolles, 2005)
Asm2vec (Ding et al., 2019)
BinaryAI (Yu et al., 2020a;b)
OSCAR
BinDiff (Dullien & Rolles, 2005)
Asm2vec (Ding et al., 2019)
BinaryAI (Yu et al., 2020a;b)
OSCAR
BinDiff (Dullien & Rolles, 2005)
Asm2vec (Ding et al., 2019)
BinaryAI (Yu et al., 2020a;b)
OSCAR
BinDiff (Dullien & Rolles, 2005)
Asm2vec (Ding et al., 2019)
BinaryAI (Yu et al., 2020a;b)
OSCAR
BinDiff (Dullien & Rolles, 2005)
Asm2vec (Ding et al., 2019)
BinaryAI (Yu et al., 2020a;b)
OSCAR

0.4360
0.2407
0.8245
0.8063
0.7143
0.1805
0.9023
0.9023
0.5464
0.4911
0.8550
0.8560
0.5364
0.3236
0.8541
0.8764
0.1096
0.4345
0.4906
0.6483

0.0419
0.2084
0.5563
0.6467
0.1237
0.2371
0.6392
0.7423
0.1893
0.4916
0.7282
0.7405
0.2939
0.3767
0.7907
0.8183
0.0257
0.4319
0.4835
0.5404

0.1600
0.4270
0.6667
0.7148
0.1959
0.3814
0.7010
0.7835
0.4831
0.6012
0.7991
0.8190
0.6304
0.6163
0.9023
0.8883
0.1768
0.6869
0.6114
0.6630

0.6455
0.5520
0.8107
0.8198
0.4271
0.5104
0.7708
0.8229
0.8190
0.6426
0.8620
0.8512
0.9658
0.6907
0.9478
0.9520
0.6956
0.7454
0.7491
0.7583

0.3209
0.2371
0.7146
0.7469
0.3653
0.3274
0.7533
0.8128
0.5095
0.5566
0.8111
0.8167
0.6066
0.5018
0.8737
0.8838
0.2519
0.5747
0.5837
0.6525

4.2. Algorithm Classiﬁcation

In this subsection, we study the performance of OSCAR
on high-level programming language understanding. We
conduct the experiments on POJ-104 dataset (Mou et al.,
2016), which contains 104 algorithm problems that were
submitted to an online judge system. All samples were
written in C/C++ by students. The dataset has around 500
samples per algorithm. The experimental setting we used
is exactly same with ProGraML (Cummins et al., 2020a;b),
which achieves state-of-the-art classiﬁcation accuracy on
this dataset.

Table 2. Classiﬁcation error on POJ-104 test dataset. The per-
formance of all baseline methods is cited from Cummins et al.
(2020b).

Methods

Error(%)

TBCNN (Mou et al., 2016)
NCC (Ben-Nun et al., 2018)
XFG (Ben-Nun et al., 2018)
XFG w/o inst2vec vocab
ProGraML (Cummins et al., 2020a;b)

OSCAR

6.00
5.17
4.56
4.29
3.38

1.92

Tab.2 shows the results of classiﬁcation error. According

to the table, our model achieves signiﬁcant improvement
comparing with all previous methods by a large margin,
which indicates that OSCAR could well understand the
semantics of source code written in high-level PLs.

4.3. Zero-Shot Learning

In the previous subsection, we show that after ﬁne-tuning
the parameters on downstream tasks, OSCAR could out-
perform prior methods on both binary code or high-level
programming language. In this subsection, we further in-
vestigate the performance of pre-trained OSCAR in the
zero-shot learning setting, i.e., evaluate OSCAR without
modifying the parameters. In the comparison, we choose
CodeBERT (Feng et al., 2020) as a baseline which shows
promising zero-shot ability in the PL-NL probing task. We
conduct the empirical study on the code similarity task by
leveraging the POJ-104 dataset described above. Follow-
ing Ye et al. (2020), we label two programs as similar if they
are solutions to the same problem, and use mean average
precision (MAP) as the evaluation metric. The difference
is that we only evaluate our model on the testing dataset
without using the training and validation sets.

Since there is no supervision on [CLS] token in CodeBERT
during pre-training, it’s potentially unfair to only use the rep-
resentation on [CLS] token in this task. Following Reimers

How could Neural Networks understand Programs?

Table 3. Mean average precision (MAP) on POJ-104 test
dataset. The performance of all baselines is cited from Ye et al.
(2020).The pre-trained model of † is downloaded from the ofﬁcial
release of Feng et al. (2020).

Table 4. Ablation study on the components of OSCAR.
Avg. Recall@1

Methods

OSCAR

w/o PCE
w/o contrastive loss

MAP(%)

CuBERT (Kanade et al., 2020) w/ IR

0.8838
0.8662
0.8267
0.4650

Trianing-based

Methods

code2vec (Alon et al., 2019)
NCC (Ben-Nun et al., 2018)
NCC w/o inst2vec
Aroma-Dot (Luan et al., 2019)
Aroma-Cos
MISIM (Ye et al., 2020)

Pre-training
w/o ﬁne-tuning

CodeBERT-[CLS] (Feng et al., 2020)†
CodeBERT-avg. of outputs†
OSCAR1−6−1
OSCAR

1.90
39.95
54.19
52.09
55.12
82.45

10.38
9.62
45.24
49.17

et al. (2019), we additionally calculate the average of the
outputs on all tokens of CodeBERT as the representation
in comparison. Furthermore, despite that both CodeBERT
and OSCAR have 12 transformer layers, OSCAR has more
parameters (163M) than CodeBERT (125M) since there are
two simultaneous token-level encoders, i.e., IR encoder and
Env. encoder. For a fair comparison, we also report the
MAP of a shallow OSCAR with only one token-level en-
coder layer before and after the six instruction-level encoder
layers, which is called OSCAR1−6−1 and has only 107M
parameters.

As shown in Tab.3, without further modifying the parame-
ters, the pre-trained OSCAR and OSCAR1−6−1 both show
promising performance on code similarity detection, com-
paring to other pre-trained models. This indicates that OS-
CAR has the potential of transferability on downstream
tasks without ﬁne-tuning.

Please note, although OSCAR optimizes a similarity loss
function (See Sec.3.3) in the pre-training phase, the deﬁ-
nitions of two data samples as similar are totally different
between pre-training and this task: one labels two IRs as
similar if they are generated from the same code snippet
with different optimization techniques, and the other labels
two programs written by different students as similar if they
are solutions to the same OJ problem. Therefore, the ob-
jectives of OSCAR pre-training and this task are not the
same, and the pre-trained OSCAR model demonstrates the
capability of semantics understanding of program in the
zero-shot learning setting.

the effects of the two components of OSCAR: contrastive
loss and PCE. As shown in the ﬁgure, all components are
beneﬁcial, improving the recall on the binary difﬁng task.
Meanwhile, we further train a BERT on IR corpus, which
is similar to CuBERT (Kanade et al., 2020) because they
share exactly the same architecture, and the only difference
is that CuBERT is pre-trained on Python corpus. The result
shows that, CuBERT with IR performs not well on the bi-
nary difﬁng task, which reﬂects the hierarchical architecture
of OSCAR is also signiﬁcantly beneﬁcial.

5. Discussion

In this section, we discuss a few potential drawbacks of our
method, which are left for future work.

Real-time Code Analysis Currently, we analyze the tar-
get code snippet relying on compiler and static program
analysis, which requires that the target code snippet should
be compilable. This dependence may limit the applications
of OSCAR on real-time code analysis, such as in the modern
integrated development environment (IDE). However, there
are many alternatives to choose for real-time IR translation
and environment information extraction. For example, the
interpreter can translate interpreted language (e.g., Python
interpreter) into IR in an interactive style; and even for some
compiled languages, interactive interpreters are also been
developed (e.g., Cling2 for C++) which support just-in-time
(JIT) compilation. With these technologies, there is no need
to require the target code snippet to be a compilable pro-
gram, but only a complete basic block.

Token Semantics Analysis of Source Code When com-
pilers translate source code to IR, partial semantics of tokens
is lost since all variables’ names would be automatically
normalized and replaced by LLVM value identiﬁer. It may
lead to a failure of semantics analysis as important infor-
mation is contained in the variable name. For example,
CuBERT (Kanade et al., 2020) claims that it can detect the
following code written in Python is buggy:

num_batches = batch_size / num_examples

4.4. Ablation Study

In this subsection, we investigate the effects of each compo-
nent in OSCAR on binary difﬁng task using BusyBox, and
the experimental setting is identical to above. Tab.4 ablates

where OSCAR may fail in handling this case with high
probability. It may be well-solved by keeping the original
tokens in IR. We leave it for future work.

2https://github.com/root-project/cling.

How could Neural Networks understand Programs?

6. Conclusion

In this paper, we propose a novel pre-training model called
OSCAR to learn better code representation. Motivated by
operational semantics, we suggest that, instead of learn-
ing representation directly from high-level programming
languages, the intermediate representation is a better ab-
straction of the semantics of instructions; meanwhile, to
well understand the meaning of a program, we propose
the abstract environment information should be necessar-
ily considered. Besides, we introduce two additional tech-
niques to make up the OSCAR. First, we incorporate the
control ﬂow information into the model through a novel
positional encoding called PCE. Second, to provide a code
snippet-level self-supervision during pre-training, we intro-
duce contrastive loss by generating syntactically diverse
but functionally equivalent IRs with different optimization
techniques. OSCAR empirically shows promising results on
practical software engineering tasks, including both binary
code and high-level programming language understanding,
and also demonstrates the transferability on downstream
tasks without modifying the parameters of the pre-trained
model.

References

Ahmad, W. U., Chakraborty, S., Ray, B., and Chang, K.-W. Uniﬁed
pre-training for program understanding and generation. arXiv
preprint arXiv:2103.06333, 2021.

Allamanis, M., Brockschmidt, M., and Khademi, M. Learning to
represent programs with graphs. In International Conference
on Learning Representations, 2018.

Alon, U., Brody, S., Levy, O., and Yahav, E. code2seq: Gener-
ating sequences from structured representations of code. In
International Conference on Learning Representations, 2018.

Alon, U., Zilberstein, M., Levy, O., and Yahav, E. code2vec:
Learning distributed representations of code. Proceedings of
the ACM on Programming Languages, 3(POPL):1–29, 2019.

Alon, U., Sadaka, R., Levy, O., and Yahav, E. Structural lan-
guage models of code. In International Conference on Machine
Learning, pp. 245–256. PMLR, 2020.

Ben-Nun, T., Jakobovits, A. S., and Hoeﬂer, T. Neural code
comprehension: A learnable representation of code semantics.
Advances in Neural Information Processing Systems, 31:3585–
3597, 2018.

Brockschmidt, M., Allamanis, M., Gaunt, A. L., and Polozov,
O. Generative code modeling with graphs. arXiv preprint
arXiv:1805.08490, 2018.

Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.,
Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A.,
et al. Language models are few-shot learners. arXiv preprint
arXiv:2005.14165, 2020.

Bui, N. D., Yu, Y., and Jiang, L.

Infercode: Self-supervised
learning of code representations by predicting subtrees. arXiv
e-prints, pp. arXiv–2012, 2020.

Buratti, L., Pujar, S., Bornea, M., McCarley, S., Zheng, Y.,
Rossiello, G., Morari, A., Laredo, J., Thost, V., Zhuang, Y.,
et al. Exploring software naturalness throughneural language
models. arXiv preprint arXiv:2006.12641, 2020.

Chen, T., Kornblith, S., Norouzi, M., and Hinton, G. A simple
framework for contrastive learning of visual representations. In
International conference on machine learning, pp. 1597–1607.
PMLR, 2020.

Chen, X., Liu, C., and Song, D. Tree-to-tree neural networks
for program translation. In Proceedings of the 32nd Interna-
tional Conference on Neural Information Processing Systems,
pp. 2552–2562, 2018.

Cousot, P. and Cousot, R. Abstract interpretation: a uniﬁed lat-
tice model for static analysis of programs by construction or
approximation of ﬁxpoints. In Proceedings of the 4th ACM
SIGACT-SIGPLAN symposium on Principles of programming
languages, pp. 238–252, 1977.

Cousot, P. and Cousot, R. Systematic design of program analysis
frameworks. In Proceedings of the 6th ACM SIGACT-SIGPLAN
symposium on Principles of programming languages, pp. 269–
282, 1979.

Cummins, C., Fisches, Z. V., Ben-Nun, T., Hoeﬂer, T., and Leather,
H. Programl: Graph-based deep learning for program optimiza-
tion and analysis. arXiv preprint arXiv:2003.10536, 2020a.

Cummins, C., Leather, H., Fisches, Z., Ben-Nun, T., Hoeﬂer, T.,
and O’Boyle, M. Deep data ﬂow analysis. arXiv preprint
arXiv:2012.01470, 2020b.

Dai, Z., Lai, G., Yang, Y., and Le, Q. V. Funnel-transformer: Filter-
ing out sequential redundancy for efﬁcient language processing.
arXiv preprint arXiv:2006.03236, 2020.

David, Y., Alon, U., and Yahav, E. Neural reverse engineering
of stripped binaries using augmented control ﬂow graphs. Pro-
ceedings of the ACM on Programming Languages, 4(OOPSLA):
1–28, 2020.

Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. Bert: Pre-
training of deep bidirectional transformers for language under-
standing. In NAACL-HLT (1), 2019.

Ding, S. H., Fung, B. C., and Charland, P. Asm2vec: Boosting
static representation robustness for binary clone search against
code obfuscation and compiler optimization. In 2019 IEEE
Symposium on Security and Privacy (SP), pp. 472–489. IEEE,
2019.

Duan, Y., Li, X., Wang, J., and Yin, H. Deepbindiff: Learning
program-wide code representations for binary difﬁng. 2020.

Dullien, T. and Rolles, R. Graph-based comparison of executable

objects (english version). Sstic, 5(1):3, 2005.

Feng, Z., Guo, D., Tang, D., Duan, N., Feng, X., Gong, M., Shou,
L., Qin, B., Liu, T., Jiang, D., et al. Codebert: A pre-trained
model for programming and natural languages. arXiv preprint
arXiv:2002.08155, 2020.

Gunter, C. A. Semantics of programming languages: structures

and techniques. MIT press, 1992.

How could Neural Networks understand Programs?

Guo, D., Ren, S., Lu, S., Feng, Z., Tang, D., Liu, S., Zhou,
L., Duan, N., Yin, J., Jiang, D., et al. Graphcodebert: Pre-
training code representations with data ﬂow. arXiv preprint
arXiv:2009.08366, 2020.

Hadsell, R., Chopra, S., and LeCun, Y. Dimensionality reduction
by learning an invariant mapping. In 2006 IEEE Computer So-
ciety Conference on Computer Vision and Pattern Recognition
(CVPR’06), volume 2, pp. 1735–1742. IEEE, 2006.

He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R. Momentum
In
contrast for unsupervised visual representation learning.
Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pp. 9729–9738, 2020.

Hellendoorn, V. J., Sutton, C., Singh, R., Maniatis, P., and Bieber,
D. Global relational models of source code. In International
conference on learning representations, 2019.

Hennessy, M. The semantics of programming languages: an
elementary introduction using structural operational semantics.
John Wiley & Sons, 1990.

Jain, P., Jain, A., Zhang, T., Abbeel, P., Gonzalez, J. E., and Stoica,
I. Contrastive code representation learning. arXiv preprint
arXiv:2007.04973, 2020.

Kanade, A., Maniatis, P., Balakrishnan, G., and Shi, K. Learning
and evaluating contextual embedding of source code. 2020.

Ke, G., He, D., and Liu, T.-Y. Rethinking the positional encoding
in language pre-training. arXiv preprint arXiv:2006.15595,
2020.

Kim, S., Zhao, J., Tian, Y., and Chandra, S. Code prediction by
feeding trees to transformers. arXiv preprint arXiv:2003.13848,
2020.

Lachaux, M.-A., Roziere, B., Chanussot, L., and Lample, G. Unsu-
pervised translation of programming languages. arXiv preprint
arXiv:2006.03511, 2020.

Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy,
O., Lewis, M., Zettlemoyer, L., and Stoyanov, V. Roberta: A
robustly optimized bert pretraining approach. arXiv preprint
arXiv:1907.11692, 2019.

Luan, S., Yang, D., Barnaby, C., Sen, K., and Chandra, S. Aroma:
Code recommendation via structural code search. Proceedings
of the ACM on Programming Languages, 3(OOPSLA):1–28,
2019.

Mou, L., Li, G., Zhang, L., Wang, T., and Jin, Z. Convolutional
neural networks over tree structures for programming language
processing. In Proceedings of the AAAI Conference on Artiﬁcial
Intelligence, volume 30, 2016.

Plotkin, G. D. A structural approach to operational semantics.

1981.

Rabinovich, M., Stern, M., and Klein, D. Abstract syntax net-
works for code generation and semantic parsing. arXiv preprint
arXiv:1704.07535, 2017.

Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and
Sutskever, I. Language models are unsupervised multitask
learners. OpenAI blog, 1(8):9, 2019.

Reimers, N., Gurevych, I., Reimers, N., Gurevych, I., Thakur,
N., Reimers, N., Daxenberger, J., and Gurevych, I. Sentence-
bert: Sentence embeddings using siamese bert-networks. In
Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing. Association for Computational
Linguistics, 2019.

Stuart, T. Understanding Computation: From Simple Machines to

Impossible Programs. ” O’Reilly Media, Inc.”, 2013.

Svyatkovskiy, A., Deng, S. K., Fu, S., and Sundaresan, N. Intel-
licode compose: Code generation using transformer. In Pro-
ceedings of the 28th ACM Joint Meeting on European Software
Engineering Conference and Symposium on the Foundations of
Software Engineering, pp. 1433–1443, 2020.

van Wijngaarden, A., Mailloux, B. J., Peck, J. E. L., Koster, C. H.,
Lindsey, C., Sintzoff, M., Meertens, L. G., and Fisker, R. Re-
vised report on the algorithmic language Algol 68. Springer
Science & Business Media, 2012.

Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L.,
Gomez, A. N., Kaiser, Ł., and Polosukhin, I. Attention is all
you need. In Advances in neural information processing systems,
pp. 5998–6008, 2017.

VenkataKeerthy, S., Aggarwal, R., Jain, S., Desarkar, M. S.,
Ir2vec: Llvm ir based scal-
Upadrasta, R., and Srikant, Y.
able program embeddings. ACM Transactions on Architecture
and Code Optimization (TACO), 17(4):1–27, 2020.

Wang, K. and Su, Z. Blended, precise semantic program embed-
dings. In Proceedings of the 41st ACM SIGPLAN Conference
on Programming Language Design and Implementation, pp.
121–134, 2020.

Wang, W., Li, G., Ma, B., Xia, X., and Jin, Z. Detecting code
clones with graph neural network and ﬂow-augmented abstract
syntax tree. In 2020 IEEE 27th International Conference on
Software Analysis, Evolution and Reengineering (SANER), pp.
261–271. IEEE, 2020.

Wei, H. and Li, M. Supervised deep features for software func-
tional clone detection by exploiting lexical and syntactical in-
formation in source code. In IJCAI, pp. 3034–3040, 2017.

Winskel, G. The formal semantics of programming languages: an

introduction. MIT press, 1993.

Xiong, R., Yang, Y., He, D., Zheng, K., Zheng, S., Xing, C., Zhang,
H., Lan, Y., Wang, L., and Liu, T. On layer normalization in
the transformer architecture. In International Conference on
Machine Learning, pp. 10524–10533. PMLR, 2020.

Ye, F., Zhou, S., Venkat, A., Marucs, R., Tatbul, N., Tithi, J. J.,
Petersen, P., Mattson, T., Kraska, T., Dubey, P., et al. Misim:
An end-to-end neural code similarity system. arXiv preprint
arXiv:2006.05265, 2020.

Yin, P. and Neubig, G. A syntactic neural model for general-
purpose code generation. In Proceedings of the 55th Annual
Meeting of the Association for Computational Linguistics (Vol-
ume 1: Long Papers), pp. 440–450, 2017.

Yu, Z., Cao, R., Tang, Q., Nie, S., Huang, J., and Wu, S. Order
matters: semantic-aware neural networks for binary code sim-
ilarity detection. In Proceedings of the AAAI Conference on
Artiﬁcial Intelligence, volume 34, pp. 1145–1152, 2020a.

How could Neural Networks understand Programs?

Yu, Z., Zheng, W., Wang, J., Tang, Q., Nie, S., and Wu, S.
Codecmr: Cross-modal retrieval for function-level binary source
code matching. Advances in Neural Information Processing
Systems, 33, 2020b.

Zhang, J., Wang, X., Zhang, H., Sun, H., Wang, K., and Liu, X.
A novel neural source code representation based on abstract
syntax tree. In 2019 IEEE/ACM 41st International Conference
on Software Engineering (ICSE), pp. 783–794. IEEE, 2019.

Zhou, Y., Liu, S., Siow, J., Du, X., and Liu, Y. Devign: Effective
vulnerability identiﬁcation by learning comprehensive program
semantics via graph neural networks. In Advances in neural
information processing systems, 2019.

A. Details of Abstract Environment

A.4. Other Constraints

How could Neural Networks understand Programs?

Information

We develop a LLVM pass to produce the environment in-
formation. In the environment information, arguments of
the functions are named ai, i = 0, 1, 2, ..., NArguments − 1;
SSA values are named vi, i = 0, 1, 2, ..., NValues − 1;
stack variable allocated by alloca instruction are named
mi, i = 0, 1, 2, ..., NStackVariables − 1. There may be one or
more constraints of environment for every instruction, and
constraints are separated by semicolon.

A.1. Constraints of Arithmetic and Logical Operations

Constraints of arithmetic and logical operations can be rep-
resented as follows: vi = x op y or vi = op x, where vi
is the SSA value of the result of the operation, x, y can be
SSA values, arguments or constants, and op can be binary
or unary operators such as +, −, ∗, / or trunc, fptoint.

A.2. Constraints of Memory Operations

For allocating memory for stack variables, the constraint
can be represented as vi = reference mj, where vi is the
address of the allocated stack variable mj.

For memory load, the constraint can be represented as vi ←
mj = y0, y1, ... or vi ← dereference x = y0, y1, ..., where
vi is loaded value and mj is the loaded stack variable name
if the memory address points to a stack variable, otherwise x
is the memory address to load. y0, y1, ... are possible values
loaded from the memory address analyzed by MemorySSA
pass.

For memory store, the constraint can be represented as vi →
mj or vi → dereference x, where vi is the value to store
in the memory and mj is the stack variable to be stored if
the memory address points to a stack variable, otherwise
x is the memory address, which can be either SSA values,
arguments or constants.

For getting element pointer, the constraint can be repre-
sented as vi = gep x y0, y1, ..., where base pointer x can
be SSA values, arguments, stack variables or constants, and
indices yi can be vi, ai or constants.

A.3. Constraints of Selection

For PHI node, the constraint can be represented as vi =
x0, x1, ..., where x0, x1, ... are possible values of vi.

For selecting value by condition value, the constraint can
be represented as vi = select x y0 y1, where x is a boolean
condition value, and y0, y1 are selected values when x is
true or false respectively.

For return value, the constraint can be represented as ret =
x, which means that the return value of the function is x.

For loop depth, the constraint can be represented as loop =
0, 1, 2, ..., which shows the loop depth of the current instruc-
tion analyzed by LoopInfo pass.

B. Details of Architecture

We have two separated positional condition encoding for IR
and Env.. For three kinds of IR encoding, there is a special
code for [CLS]. And for true encoding and false encoding,
there is a special code −1 for the unknown position. The
unknown code is for the instructions like switch or call, for
which we cannot decide the next position or there are more
than two target positions. A switch instruction can also be
converted to a sequence of branches to prevent unknown
position code in this case. For Env. encoding, it is similar
except that [CLS] is replaced by [SEP]. The hidden state
of [CLS] in the last layer of the instruction-level trans-
former is connected to a MoCo head. The dimension of
the MoCo head is 256 and the length of the MoCo queue is
65536. Finally, when applying masked language model, an
IR instruction and its corresponding Env. constraints won’t
be masked at the same time.

C. The inﬂuence of K

In the section of experiments, we set K = 4 as constant,
which means that each IR and Env. Transformer encoder
would process sequences with a length of 32 and 16 tokens.
Larger K would lead to signiﬁcant computation increment
and memory consumption since the complexity of attention
layers is quadratic (i.e., O(L2)). But in the meanwhile,
larger k would also improve the capability of capturing the
contextual information among long sequences. In this sec-
tion, we investigate the performance gap between different
choices of K in Table.5.

Table 5. Classiﬁcation error
test dataset.
ASTNN (Zhang et al., 2019) could access the symbol names in
source code, which will be normalized in other IR-based methods.

on POJ-104

Methods

Error(%)

ASTNN (Zhang et al., 2019)
OSCAR (K = 4)
OSCAR (K = 16)

1.8
1.92
1.72

D. Hardware-related Program Semantics

F. Pre-training Data and Pre-Processing

Understanding

In this section, we investigate whether OSCAR performs
well on hardware-related semantics understanding. We con-
duct experiments on two widely-used tasks: device mapping
and coarsening threads predictions. We exactly follow the
same experimental settings with (Ben-Nun et al., 2018;
Cummins et al., 2020b). The results have shown in Table.6
and 7. In both experiments, OSCAR performs well com-
paring to baseline methods, and shows good capabilities
of program semantics understanding on hardware-related
tasks.

Table 6. Error rate (%) on device mapping task.

DeepTuneIR
inst2vec(Ben-Nun et al., 2018)
ProGraML(Cummins et al., 2020b)
OSCAR

AMD NVIDIA
26.9
19.7
13.4
11.2

31.6
21.5
20.0
10.3

Table 7. Speedups achieved by coarsening threads
inst2vec
1.37
1.10
1.07
1.06

DeepTuneIR
1.17
1.23
1.14
0.93

1.28
1.18
1.11
1.00

Cypress
Tahiti
Fermi
Kapler

1.35
1.30
1.27
1.12

inst2vec-imm OSCAR

E. Compliant Options for Constrative

Learning

We totally generate 19 variants for every function from dif-
ferent sequences of LLVM passes. Firstly, we generate
three variants using opt of the LLVM toolchain with stan-
dard passes of -O1/2/3. Then for every LLVM IR assembly
ﬁle, we randomly drop and shufﬂe the passes of the -O2
optimization level and use opt to generate the variants. The
standard -O2 optimization passes are shown in Tab.8. The
algorithm for generating the passes is as follows:

Algorithm 1 Generating LLVM passes
Input: List of the standard -O2 optimization passes P , max-

imal shufﬂed items M which is even.
Output: List of the generated optimization passes P (cid:48)

1 Generate a random integer N ∈ [0, len(P )];
2 Randomly select N items P (cid:48) from P ;
3 Generate a random even integer m ∈ [0, M ];
4 Randomly select m unique items S from {0, 1, ..., N − 1};
5 for i ← 0 to m − 2 by 2 do
P (cid:48)[S[i]] ↔ P (cid:48)[S[i + 1]];
6
7 end

In our case, we set M = 20.

F.1. Pre-training Data

We assembled a large corpus of real-world programs for
pre-training from publicly available open-source non-fork
GitHub repositories, summarized in Table.9. The software
covers a broad range of disciplines from operating systems
and compilers, to machine learning systems and linear al-
gebra subprograms. After collecting the corpus, we ﬁrst
compile them into LLVM IRs using Clang 11 with -O0
optimization level3. Then, for each program, we further gen-
erate 19 variants with the same functionality (20 in total), by
random arrangement and combination of different LLVM
optimization passes. After that, we sample about 500k func-
tions from the dataset. In the pre-training phase, we sample
several functions from the dataset to form a mini-batch as
the training data for each iteration.

F.2. Pre-Processing

Firstly, we use wllvm4 with Clang 11 to compile the source
code to LLVM IR. For every object ﬁle, wllvm will generate
an LLVM IR bitcode ﬁle, which can be then converted to
an LLVM IR assembly ﬁle. For every LLVM IR assembly
ﬁle, we extract the functions which occur in all 20 variants
of the ﬁle.

Then we use the above-mentioned LLVM pass to ﬁlter out
the functions which exceed the maximal instructions as
well as generate PCE, environment information, and IR
instructions with normalized identiﬁer names.

After that, we tokenize the LLVM IR assembly code and
process the names of functions and types as follows:

1. If an identiﬁer name is a mangled C++ symbol, de-
mangle it and remove extra information. Only function
names will be retained. Also, for type names, extra
information such as template arguments or namespaces
will be removed.

2. Split the names into words by underscore and case.

3. Use byte pair encoding to break down the words into

subwords.

Literal constants will also be split into subwords using BPE.

Finally, we convert IR instructions and environment infor-
mation into raw text and split them into the training set and
the validation set with the ratio of 19:1.

3Except for Linux Kernels which could only be built with -O1

or above.

4https://github.com/travitch/

whole-program-llvm

How could Neural Networks understand Programs?

G. Downstream Dataset

G.1. Binary Difﬁng

We collected several programs and libraries. The numbers
of the programs in the training/validation/testing dataset are
13, 2, and 5. Firstly, we compile them using GCC 7.5.0 with
debug information and four different optimizations levels
(-O0/1/2/3). Then, we use debug information to generate
the ground truth of matched functions in different variants
of binaries and then stripped the debug information out of
the binaries as well as replace the function symbols with
meaningless strings. We only treat two binary functions as
equivalent if their function names and source code ﬁlenames
in the debug information are both the same. In this way, we
can ensure that the ground truth collected is correct, though
it may not be exhaustive. After that, we use retdec5 decom-
piler to convert the binaries to LLVM IR, and then process
the IR to generate raw text input in the above-mentioned
way.

For the training and validation set, only the functions that
occur in all four variants of a binary will be used. However,
for the test set, all the functions will be included as we need
to retrieve a function from all the functions of another binary.
The numbers of the functions in the training/validation/test-
ing dataset are 71000, 5804, and 40791.

Before matching the functions using BinDiff(Dullien &
Rolles, 2005), we remove the names of the functions in
IDA except for the exported symbols as BinDiff will match
two functions if they have the same name, which results in
invalid results.

We use Recall@1 as the evaluation metrics, which can be
computed in this manner:

1 → B(cid:48)

1 ⊆ B1, B(cid:48)

For binaries B1, B2 as the sets of binary functions, we
have a ground truth mapping f1 : B(cid:48)
2, where
B(cid:48)
2 ⊆ B2. For every x1 ∈ B(cid:48)
1, we also ﬁnd
a x2 = f2(x1) ∈ B2 which maximizes similarity(x1, x2)
computed by our model, which is the cosine similarity of the
[CLS] feature vectors of these two functions. MoCo(He
et al., 2020) head is not involved in the computation of the
feature vectors. Then, we have:

Recall@1 =

|f1 ∩ f2|
|f1|

G.2. POJ-104

POJ-104 dataset(Mou et al., 2016) is collected from an
online judge platform, which contains 104 program classes
written by 500 different people randomly selected per class,
so there are a total of 52000 samples in the dataset. We
use the dataset for the task of clone detection and algorithm

classiﬁcation.

For the POJ-104 clone detection task, we compile the code
of the POJ-104 dataset to LLVM IR assembly ﬁles with
Clang 11 and -O0 optimization level. To compile the code
successfully, we prepend following statements before the
code:

#include <bits/stdc++.h>
using namespace std;

Then, we replace void main with int main and disable all the
warnings to compile the source code. After that, we extract
the IR instructions, environment information , and PCE
information from the produced LLVM IR assembly ﬁles in
the above-mentioned way. We concatenate the functions in
an LLVM IR assembly ﬁle into a single input sequence and
truncate it to 255 instructions.

Finally, we split the dataset according to the labels. 64
classes of programs are used for training; 16 classes of
programs are used for validation; 24 classes of programs are
used for testing.

For the algorithm classiﬁcation task, we use the compiled
IR ﬁles from the dataset processed by NCC(Ben-Nun et al.,
2018)6. The dataset is split by 3:1:1 for training, validation,
and testing. To successfully compile the programs, #in-
clude statements are also prepended before the source code.
Data augmentation is applied on the training set by com-
piling each ﬁle 8 times with different optimization options
(-OO/1/2/3 and w/ or w/o -ffast-math). We keep up to four
functions per source code ﬁle and truncate each function to
255 instructions.

We use MAP@R as the evaluation metrics of the clone
detection task. MAP@R is deﬁned as the mean of average
precision scores, each of which is evaluated for retrieving R
most similar samples given a query. In our case some source
code ﬁles (˜3%) are not compilable, so we only retrieve
Ri most similar samples for every query where Ri is the
number of the valid samples of the same class with the query
si. Detailed information of how to compute our evaluation
metrics is as follows.

We denote the set of all the samples as S = {si | i =
0, 1, 2, ..., N − 1}, where N is the number of the samples.
And the label of si is l(si). Then, we denote the similarity
scores between si and sj computed by our model f as
similarity(si, sj) = cos(f (si), f (sj)). The feature vectors
f (si) and f (sj) computed by our model are the output of
the two-layer MLP of the MoCo head.

For every si ∈ S,
l(si), sj

l(sj) =
let Si = {sj ∈ S |
(cid:54)= si}, and Ri = |Si|. We retrieve Ri most

6https://github.com/spcl/ncc/tree/master/

5https://retdec.com/

task

How could Neural Networks understand Programs?

similar samples as Qi from S − {si} by similarity scores
similarity(si, sj), sj ∈ S − {si}. Then, we have:

is 0.2; dropout and attention dropout is 0.1; batch size is 48
and update frequency is 1.

Precisioni =

|Qi ∩ Si|
|Si|

MAP@R =

1
N

N −1
(cid:88)

i=0

Precisioni

H. Training Details

H.1. Pre-training

The loss for the pre-training task is:

L = λLMLM + µLMoCo

where λ is MLM loss coefﬁcient and µ is MoCo loss co-
efﬁcient. We strictly follow the algorithm of MoCo, ex-
cept that xkey is an augmented image in MoCo, while
xkey = [xIRkey : xEnvKey] is the augmented IR instruc-
tion and its environment information in our model.

We pretrain the model on 8 V100 GPUs with the hyper-
parameters shown in Tab.10.

H.2. Binary Difﬁng

We use BinDiff, Asm2vec(Ding et al., 2019)7 and Bina-
ryAI(Yu et al., 2020a;b)8 v2 API as the baseline. All hyper-
parameters of Asm2vec are default. BinaryAI uses IDA Pro
and its Hex-Rays decompiler to generate C-like pseudo-code
for binary functions, and then upload it to Tencent’s server
to compute the similarity of the functions. Also, Asm2vec
and BinDiff both depend on IDA Pro and its dissembler or
decompiler. As the Hex-Rays decompiler is considered bet-
ter than the retdec decompiler, we think that the comparison
between OSCAR and BinaryAI is reasonable.

H.3. Code Classiﬁcation

We ﬁrstly sum the [CLS] vectors of each function in an
LLVM IR assembly ﬁle to get the representation of the sam-
ple. Then the feature vectors are feed into a fully connected
layer followed by a projection layer and a softmax layer. Af-
ter that, we use the cross-entropy loss for the classiﬁcation
task.

We train the model on 8 V100 GPUs for 100000 steps with
10000 warm-up steps. Peak learning rate is 0.00005; weight
decay is 0.01; dropout and attention dropout is 0.1; batch
size is 8 and update frequency is 4.

When training OSCAR for the binary difﬁng task, we
ﬁrstly sample a mini-batch of triplets of two samples
vi, v+
i (i = 0, 1, 2, ..., N − 1,N is the size of the mini-
batch) of the same label, i.e. from the binary functions
generated by different optimizations with the same source
code function, and one sample of another label v−
i (i =
0, 1, ..., N − 1). The feature vectors of the triplets are de-
noted v0, v+
N −1. The
label of vi is l(vi), and we have l(vi) = l(v+
i ) (cid:54)= l(v−
i ).
The loss L of the mini-batch is computed as follows:
√

1 ; ...; vN −1, v+

0 ; v1, v+

N −1, v−

1 , v−

0 , v−

√

τ =

d =

768

pi = exp(vi · v+
sij = exp(vi · vj/τ ) + exp(vi · v+

i /τ )

j /τ )

ni = exp(vi · v−

i /τ ) +

N −1
(cid:88)

sij

j=0; l(vj )(cid:54)=l(vi)

L = −

1
N

N −1
(cid:88)

i=0

log

pi
pi + ni

The feature vectors are the last-layer hidden states of the
[CLS] tokens in the instruction-level transformer. MoCo
head including the two-layer MLP is dropped. We train
the model on 4 V100 GPUs for 128000 steps with 6400
warm-up steps. Peak learning rate is 0.00002; weight decay

7https://github.com/McGill-DMaS/

Kam1n0-Community

8https://github.com/binaryai/sdk

How could Neural Networks understand Programs?

Table 8. -O2 optimization passes

-scoped-noalias
-inferattrs
-called-value-propagation
-globalopt
-deadargelim
-simplifycfg
-functionattrs
-early-cse-memssa
-jump-threading
-simplifycfg
-instcombine
-pgo-memop-opt
-simplifycfg
-loop-simplify
-scalar-evolution
-licm
-simplifycfg
-loop-simplify
-scalar-evolution
-loop-idiom
-loop-unroll
-phi-values
-phi-values
-sccp
-bdce
-jump-threading
-phi-values
-loop-simplify
-scalar-evolution
-adce
-instcombine
-elim-avail-extern
-globalopt
-ﬂoat2int
-loop-simplify
-scalar-evolution
-loop-distribute
-demanded-bits
-loop-simplify
-loop-load-elim
-simplifycfg
-demanded-bits
-instcombine
-lcssa
-loop-unroll
-loop-simplify
-scalar-evolution
-transform-warning

-tbaa
-forceattrs
-ipsccp
-attributor
-mem2reg
-instcombine
-prune-eh
-sroa
-speculative-execution
-correlated-propagation
-domtree
-libcalls-shrinkwrap
-tailcallelim
-reassociate
-lcssa
-loop-rotate
-loop-unswitch
-instcombine
-lcssa
-indvars
-loop-deletion
-mldst-motion
-gvn
-memcpyopt
-demanded-bits
-instcombine
-correlated-propagation
-dse
-lcssa
-licm
-simplifycfg
-barrier
-rpo-functionattrs
-globaldce
-lower-constant-intrinsics
-lcssa
-loop-rotate
-scalar-evolution
-loop-vectorize
-scalar-evolution
-instcombine
-scalar-evolution
-slp-vectorizer
-loop-simplify
-scalar-evolution
-instcombine
-lcssa
-licm
-alignment-from-assumptions -strip-dead-prototypes
-globaldce
-loop-simplify
-scalar-evolution
-instsimplify
-simplifycfg

-constmerge
-lcssa
-loop-sink
-div-rem-pairs

Table 9. The eleven sources of LLVM IR used to produce pre-
training dataset. All software is downloaded from Github.

Software

Domain

#instructions #functions

Linux Kernel
Linux Kernel
Compiler
Multimedia
BLAS
Database
Web Server
3-D Creation

Linux-vmlinux
Linux-modules
GCC
MPlayer
OpenBLAS
PostgreSQL
Apache
Blender
ImageMagcick Image Processing
Machine Learning
Tensorﬂow
Browser
Firefox

2,930,372
16,509,892
1,816,782
1,223,068
515,985
939,199
390,135
5,925,801
440,265
12,041,852
5,290,430

45,368
229,942
22,383
12,747
5,415
12,807
5,519
123,689
7,182
294,553
96,187

Total

48,023,781

855,792

Table 10. Hyper-parameters for pre-training.

Hyper-parameter

Training steps
Warm-up steps
Peak LR
Batch size
Update frequency
Dropout
Attention dropout
Weight decay
MoCo dimension
MoCo temperature
MoCo momentum
MoCo queue length
MLM loss coefﬁcient
MoCo loss coefﬁcient

Value

1000000
30000
0.0001
16
4
0.1
0.1
0.01
256
0.02
0.999
65536
1
1000

